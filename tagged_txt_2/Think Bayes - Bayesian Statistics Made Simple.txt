think	O
bayes	O
bayesian	O
statistics	O
made	O
simple	O
version	O
think	O
bayes	O
bayesian	O
statistics	O
made	O
simple	O
version	O
allen	O
b	O
downey	O
green	O
tea	O
press	O
needham	O
massachusetts	O
copyright	O
allen	O
b	O
downey	O
green	O
tea	O
press	O
washburn	O
ave	O
needham	O
ma	O
permission	O
is	O
granted	O
to	O
copy	O
distribute	O
andor	O
modify	O
this	O
document	O
under	O
the	O
terms	O
of	O
the	O
creative	O
commons	O
attribution-noncommercial	O
unported	O
license	O
which	O
is	O
available	O
at	O
httpcreativecommons	O
org	O
preface	O
my	O
theory	O
which	O
is	O
mine	O
the	O
premise	O
of	O
this	O
book	O
and	O
the	O
other	O
books	O
in	O
the	O
think	O
x	O
series	O
is	O
that	O
if	O
you	O
know	O
how	O
to	O
program	O
you	O
can	O
use	O
that	O
skill	O
to	O
learn	O
other	O
topics	O
most	O
books	O
on	O
bayesian	O
statistics	O
use	O
mathematical	O
notation	O
and	O
present	O
ideas	O
in	O
terms	O
of	O
mathematical	O
concepts	O
like	O
calculus	O
this	O
book	O
uses	O
python	O
code	O
instead	O
of	O
math	O
and	O
discrete	O
approximations	O
instead	O
of	O
continuous	O
mathematics	O
as	O
a	O
result	O
what	O
would	O
be	O
an	O
integral	O
in	O
a	O
math	O
book	O
becomes	O
a	O
summation	O
and	O
most	O
operations	B
on	O
probability	B
distributions	O
are	O
simple	O
loops	O
i	O
think	O
this	O
presentation	O
is	O
easier	O
to	O
understand	O
at	O
least	O
for	O
people	O
with	O
programming	O
skills	O
it	O
is	O
also	O
more	O
general	O
because	O
when	O
we	O
make	O
modeling	B
decisions	O
we	O
can	O
choose	O
the	O
most	O
appropriate	O
model	O
without	O
worrying	O
too	O
much	O
about	O
whether	O
the	O
model	O
lends	O
itself	O
to	O
conventional	O
analysis	O
also	O
it	O
provides	O
a	O
smooth	O
development	O
path	O
from	O
simple	O
examples	O
to	O
realworld	O
problems	O
chapter	O
is	O
a	O
good	O
example	O
it	O
starts	O
with	O
a	O
simple	O
example	O
involving	O
dice	B
one	O
of	O
the	O
staples	O
of	O
basic	O
probability	B
from	O
there	O
it	O
proceeds	O
in	O
small	O
steps	O
to	O
the	O
locomotive	B
problem	I
which	O
i	O
borrowed	O
from	O
mosteller	B
s	O
fifty	O
challenging	O
problems	O
in	O
probability	B
with	O
solutions	O
and	O
from	O
there	O
to	O
the	O
german	B
tank	I
problem	I
a	O
famously	O
successful	O
application	O
of	O
bayesian	O
methods	O
during	O
world	O
war	O
ii	O
modeling	B
and	O
approximation	O
most	O
chapters	O
in	O
this	O
book	O
are	O
motivated	O
by	O
a	O
real-world	O
problem	O
so	O
they	O
involve	O
some	O
degree	O
of	O
modeling	B
before	O
we	O
can	O
apply	O
bayesian	O
methods	O
any	O
other	O
analysis	O
we	O
have	O
to	O
make	O
decisions	O
about	O
which	O
parts	O
of	O
the	O
vi	O
chapter	O
preface	O
real-world	O
system	B
to	O
include	O
in	O
the	O
model	O
and	O
which	O
details	O
we	O
can	O
abstract	O
away	O
for	O
example	O
in	O
chapter	O
the	O
motivating	O
problem	O
is	O
to	O
predict	O
the	O
winner	O
of	O
a	O
hockey	B
game	O
i	O
model	O
goal-scoring	O
as	O
a	O
poisson	B
process	B
which	O
implies	O
that	O
a	O
goal	O
is	O
equally	O
likely	O
at	O
any	O
point	O
in	O
the	O
game	O
that	O
is	O
not	O
exactly	O
true	O
but	O
it	O
is	O
probably	O
a	O
good	O
enough	O
model	O
for	O
most	O
purposes	O
in	O
chapter	O
the	O
motivating	O
problem	O
is	O
interpreting	O
sat	B
scores	O
sat	B
is	O
a	O
standardized	B
test	I
used	O
for	O
college	O
admissions	O
in	O
the	O
united	O
states	O
i	O
start	O
with	O
a	O
simple	O
model	O
that	O
assumes	O
that	O
all	O
sat	B
questions	O
are	O
equally	O
difficult	O
but	O
in	O
fact	O
the	O
designers	O
of	O
the	O
sat	B
deliberately	O
include	O
some	O
questions	O
that	O
are	O
relatively	O
easy	O
and	O
some	O
that	O
are	O
relatively	O
hard	O
i	O
present	O
a	O
second	O
model	O
that	O
accounts	O
for	O
this	O
aspect	O
of	O
the	O
design	O
and	O
show	O
that	O
it	O
doesn	O
t	O
have	O
a	O
big	O
effect	O
on	O
the	O
results	O
after	O
all	O
i	O
think	O
it	O
is	O
important	O
to	O
include	O
modeling	B
as	O
an	O
explicit	O
part	O
of	O
problem	O
solving	O
because	O
it	O
reminds	O
us	O
to	O
think	O
about	O
modeling	B
errors	O
is	O
errors	O
due	O
to	O
simplifications	O
and	O
assumptions	O
of	O
the	O
model	O
many	O
of	O
the	O
methods	O
in	O
this	O
book	O
are	O
based	O
on	O
discrete	O
distributions	O
which	O
makes	O
some	O
people	O
worry	O
about	O
numerical	O
errors	O
but	O
for	O
real-world	O
problems	O
numerical	O
errors	O
are	O
almost	O
always	O
smaller	O
than	O
modeling	B
errors	O
furthermore	O
the	O
discrete	O
approach	O
often	O
allows	O
better	O
modeling	B
decisions	O
and	O
i	O
would	O
rather	O
have	O
an	O
approximate	O
solution	O
to	O
a	O
good	O
model	O
than	O
an	O
exact	O
solution	O
to	O
a	O
bad	O
model	O
on	O
the	O
other	O
hand	O
continuous	O
methods	O
sometimes	O
yield	O
performance	O
advantages	O
for	O
example	O
by	O
replacing	O
a	O
linear-	O
or	O
quadratic-time	O
computation	O
with	O
a	O
constant-time	O
solution	O
so	O
i	O
recommend	O
a	O
general	O
process	B
with	O
these	O
steps	O
while	O
you	O
are	O
exploring	O
a	O
problem	O
start	O
with	O
simple	O
models	O
and	O
implement	O
them	O
in	O
code	O
that	O
is	O
clear	O
readable	O
and	O
demonstrably	O
correct	O
focus	O
your	O
attention	O
on	O
good	O
modeling	B
decisions	O
not	O
optimization	B
once	O
you	O
have	O
a	O
simple	O
model	O
working	O
identify	O
the	O
biggest	O
sources	O
of	O
error	B
you	O
might	O
need	O
to	O
increase	O
the	O
number	O
of	O
values	O
in	O
a	O
discrete	O
approximation	O
or	O
increase	O
the	O
number	O
of	O
iterations	O
in	O
a	O
monte	O
carlo	O
simulation	B
or	O
add	O
details	O
to	O
the	O
model	O
if	O
the	O
performance	O
of	O
your	O
solution	O
is	O
good	O
enough	O
for	O
your	O
application	O
you	O
might	O
not	O
have	O
to	O
do	O
any	O
optimization	B
but	O
if	O
you	O
do	O
there	O
are	O
two	O
approaches	O
to	O
consider	O
you	O
can	O
review	O
your	O
code	O
and	O
look	O
working	O
with	O
the	O
code	O
vii	O
for	O
optimizations	O
for	O
example	O
if	O
you	O
cache	B
previously	O
computed	O
results	O
you	O
might	O
be	O
able	O
to	O
avoid	O
redundant	O
computation	O
or	O
you	O
can	O
look	O
for	O
analytic	O
methods	O
that	O
yield	O
computational	O
shortcuts	O
one	O
benefit	O
of	O
this	O
process	B
is	O
that	O
steps	O
and	O
tend	O
to	O
be	O
fast	O
so	O
you	O
can	O
explore	O
several	O
alternative	O
models	O
before	O
investing	O
heavily	O
in	O
any	O
of	O
them	O
another	O
benefit	O
is	O
that	O
if	O
you	O
get	O
to	O
step	O
you	O
will	O
be	O
starting	O
with	O
a	O
reference	O
implementation	B
that	O
is	O
likely	O
to	O
be	O
correct	O
which	O
you	O
can	O
use	O
for	O
regression	B
testing	I
is	O
checking	O
that	O
the	O
optimized	O
code	O
yields	O
the	O
same	O
results	O
at	O
least	O
approximately	O
working	O
with	O
the	O
code	O
the	O
code	O
and	O
sound	O
samples	O
used	O
in	O
this	O
book	O
are	O
available	O
from	O
https	O
github	O
comallendowneythinkbayes	O
git	O
is	O
a	O
version	O
control	O
system	B
that	O
allows	O
you	O
to	O
keep	O
track	O
of	O
the	O
files	O
that	O
make	O
up	O
a	O
project	O
a	O
collection	O
of	O
files	O
under	O
git	O
s	O
control	O
is	O
called	O
a	O
repository	O
github	O
is	O
a	O
hosting	O
service	O
that	O
provides	O
storage	O
for	O
git	O
repositories	O
and	O
a	O
convenient	O
web	O
interface	B
the	O
github	O
homepage	O
for	O
my	O
repository	O
provides	O
several	O
ways	O
to	O
work	O
with	O
the	O
code	O
you	O
can	O
create	O
a	O
copy	O
of	O
my	O
repository	O
on	O
github	O
by	O
pressing	O
the	O
fork	O
button	O
if	O
you	O
don	O
t	O
already	O
have	O
a	O
github	O
account	O
you	O
ll	O
need	O
to	O
create	O
one	O
after	O
forking	O
you	O
ll	O
have	O
your	O
own	O
repository	O
on	O
github	O
that	O
you	O
can	O
use	O
to	O
keep	O
track	O
of	O
code	O
you	O
write	O
while	O
working	O
on	O
this	O
book	O
then	O
you	O
can	O
clone	O
the	O
repo	O
which	O
means	O
that	O
you	O
copy	O
the	O
files	O
to	O
your	O
computer	O
or	O
you	O
could	O
clone	O
my	O
repository	O
you	O
don	O
t	O
need	O
a	O
github	O
account	O
to	O
do	O
this	O
but	O
you	O
won	O
t	O
be	O
able	O
to	O
write	O
your	O
changes	O
back	O
to	O
github	O
if	O
you	O
don	O
t	O
want	O
to	O
use	O
git	O
at	O
all	O
you	O
can	O
download	O
the	O
files	O
in	O
a	O
zip	O
file	O
using	O
the	O
button	O
in	O
the	O
lower-right	O
corner	O
of	O
the	O
github	O
page	O
the	O
code	O
for	O
the	O
first	O
edition	O
of	O
the	O
book	O
works	O
with	O
python	O
if	O
you	O
are	O
using	O
python	O
you	O
might	O
want	O
to	O
use	O
the	O
updated	O
code	O
in	O
https	O
instead	O
i	O
developed	O
this	O
book	O
using	O
anaconda	O
from	O
continuum	O
analytics	O
which	O
is	O
a	O
free	O
python	O
distribution	B
that	O
includes	O
all	O
the	O
packages	O
you	O
ll	O
need	O
to	O
viii	O
chapter	O
preface	O
run	O
the	O
code	O
lots	O
more	O
i	O
found	O
anaconda	O
easy	O
to	O
install	O
by	O
default	O
it	O
does	O
a	O
user-level	O
installation	O
not	O
system-level	O
so	O
you	O
don	O
t	O
need	O
administrative	O
privileges	O
you	O
can	O
download	O
anaconda	O
from	O
httpcontinuum	O
iodownloads	O
if	O
you	O
don	O
t	O
want	O
to	O
use	O
anaconda	O
you	O
will	O
need	O
the	O
following	O
packages	O
numpy	B
for	O
basic	O
numerical	O
computation	O
httpwww	O
numpy	B
org	O
scipy	B
for	O
scientific	O
computation	O
httpwww	O
scipy	B
org	O
matplotlib	O
for	O
visualization	O
httpmatplotlib	O
org	O
although	O
these	O
are	O
commonly	O
used	O
packages	O
they	O
are	O
not	O
included	O
with	O
all	O
python	O
installations	O
and	O
they	O
can	O
be	O
hard	O
to	O
install	O
in	O
some	O
environments	O
if	O
you	O
have	O
trouble	O
installing	O
them	O
i	O
recommend	O
using	O
anaconda	O
or	O
one	O
of	O
the	O
other	O
python	O
distributions	O
that	O
include	O
these	O
packages	O
many	O
of	O
the	O
examples	O
in	O
this	O
book	O
use	O
classes	O
and	O
functions	O
defined	O
in	O
thinkbayes	O
py	O
some	O
of	O
them	O
also	O
use	O
thinkplot	O
py	O
which	O
provides	O
wrappers	O
for	O
some	O
of	O
the	O
functions	O
in	O
pyplot	O
which	O
is	O
part	O
of	O
matplotlib	O
code	O
style	O
experienced	O
python	O
programmers	O
will	O
notice	O
that	O
the	O
code	O
in	O
this	O
book	O
does	O
not	O
comply	O
with	O
pep	O
which	O
is	O
the	O
most	O
common	O
style	O
guide	O
for	O
python	O
specifically	O
pep	O
calls	O
for	O
lowercase	O
function	O
names	O
with	O
underscores	O
between	O
words	O
like	O
this	O
in	O
this	O
book	O
and	O
the	O
accompanying	O
code	O
function	O
and	O
method	O
names	O
begin	O
with	O
a	O
capital	O
letter	O
and	O
use	O
camel	O
case	O
likethis	O
i	O
broke	O
this	O
rule	O
because	O
i	O
developed	O
some	O
of	O
the	O
code	O
while	O
i	O
was	O
a	O
visiting	O
scientist	O
at	O
google	O
so	O
i	O
followed	O
the	O
google	O
style	O
guide	O
which	O
deviates	O
from	O
pep	O
in	O
a	O
few	O
places	O
once	O
i	O
got	O
used	O
to	O
google	O
style	O
i	O
found	O
that	O
i	O
liked	O
it	O
and	O
at	O
this	O
point	O
it	O
would	O
be	O
too	O
much	O
trouble	O
to	O
change	O
also	O
on	O
the	O
topic	O
of	O
style	O
i	O
write	O
bayes	O
s	O
theorem	O
with	O
an	O
s	O
after	O
the	O
apostrophe	O
which	O
is	O
preferred	O
in	O
some	O
style	O
guides	O
and	O
deprecated	O
in	O
others	O
i	O
don	O
t	O
have	O
a	O
strong	O
preference	O
i	O
had	O
to	O
choose	O
one	O
and	O
this	O
is	O
the	O
one	O
i	O
chose	O
and	O
finally	O
one	O
typographical	O
note	O
throughout	O
the	O
book	O
i	O
use	O
pmf	B
and	O
cdf	B
for	O
the	O
mathematical	O
concept	O
of	O
a	O
probability	B
mass	I
function	I
or	O
cumulative	B
distribution	B
function	I
and	O
pmf	B
and	O
cdf	B
to	O
refer	O
to	O
the	O
python	O
objects	O
i	O
use	O
to	O
represent	O
them	O
prerequisites	O
prerequisites	O
ix	O
there	O
are	O
several	O
excellent	O
modules	O
for	O
doing	O
bayesian	O
statistics	O
in	O
python	O
including	O
pymc	O
and	O
openbugs	O
i	O
chose	O
not	O
to	O
use	O
them	O
for	O
this	O
book	O
because	O
you	O
need	O
a	O
fair	O
amount	O
of	O
background	O
knowledge	O
to	O
get	O
started	O
with	O
these	O
modules	O
and	O
i	O
want	O
to	O
keep	O
the	O
prerequisites	O
minimal	O
if	O
you	O
know	O
python	O
and	O
a	O
little	O
bit	O
about	O
probability	B
you	O
are	O
ready	O
to	O
start	O
this	O
book	O
chapter	O
is	O
about	O
probability	B
and	O
bayes	O
s	O
theorem	O
it	O
has	O
no	O
code	O
chapter	O
introduces	O
pmf	B
a	O
thinly	O
disguised	O
python	O
dictionary	O
i	O
use	O
to	O
represent	O
a	O
probability	B
mass	I
function	I
then	O
chapter	O
introduces	O
suite	B
a	O
kind	O
of	O
pmf	B
that	O
provides	O
a	O
framework	O
for	O
doing	O
bayesian	O
updates	O
in	O
some	O
of	O
the	O
later	O
chapters	O
i	O
use	O
analytic	O
distributions	O
including	O
the	O
gaussian	B
distribution	B
the	O
exponential	O
and	O
poisson	O
distributions	O
and	O
the	O
beta	B
distribution	B
in	O
chapter	O
i	O
break	O
out	O
the	O
less-common	O
dirichlet	B
distribution	B
but	O
i	O
explain	O
it	O
as	O
i	O
go	O
along	O
if	O
you	O
are	O
not	O
familiar	O
with	O
these	O
distributions	O
you	O
can	O
read	O
about	O
them	O
on	O
wikipedia	O
you	O
could	O
also	O
read	O
the	O
companion	O
to	O
this	O
book	O
think	O
stats	O
or	O
an	O
introductory	O
statistics	O
book	O
i	O
m	O
afraid	O
most	O
of	O
them	O
take	O
a	O
mathematical	O
approach	O
that	O
is	O
not	O
particularly	O
helpful	O
for	O
practical	O
purposes	O
contributor	O
list	O
if	O
you	O
have	O
a	O
suggestion	O
or	O
downeyallendowney	O
com	O
i	O
will	O
add	O
you	O
to	O
the	O
contributor	O
list	O
you	O
ask	O
to	O
be	O
omitted	O
to	O
if	O
i	O
make	O
a	O
change	O
based	O
on	O
your	O
feedback	O
correction	O
please	O
send	O
email	O
if	O
you	O
include	O
at	O
least	O
part	O
of	O
the	O
sentence	O
the	O
error	B
appears	O
in	O
that	O
makes	O
it	O
easy	O
for	O
me	O
to	O
search	O
page	O
and	O
section	O
numbers	O
are	O
fine	O
too	O
but	O
not	O
as	O
easy	O
to	O
work	O
with	O
thanks	O
first	O
i	O
have	O
to	O
acknowledge	O
david	O
mackay	B
s	O
excellent	O
book	O
information	O
theory	O
inference	O
and	O
learning	O
algorithms	O
which	O
is	O
where	O
i	O
first	O
came	O
to	O
understand	O
bayesian	O
methods	O
with	O
his	O
permission	O
i	O
use	O
several	O
problems	O
from	O
his	O
book	O
as	O
examples	O
this	O
book	O
also	O
benefited	O
from	O
my	O
interactions	O
with	O
sanjoy	O
mahajan	O
especially	O
in	O
fall	O
when	O
i	O
audited	O
his	O
class	O
on	O
bayesian	O
inference	O
at	O
olin	B
college	I
i	O
wrote	O
parts	O
of	O
this	O
book	O
during	O
project	O
nights	O
with	O
the	O
boston	B
python	O
user	O
group	O
so	O
i	O
would	O
like	O
to	O
thank	O
them	O
for	O
their	O
company	O
and	O
pizza	O
x	O
chapter	O
preface	O
olivier	O
yiptong	O
sent	O
several	O
helpful	O
suggestions	O
yuriy	O
pasichnyk	O
found	O
several	O
errors	O
kristopher	O
overholt	O
sent	O
a	O
long	O
list	O
of	O
corrections	O
and	O
suggestions	O
max	O
hailperin	O
suggested	O
a	O
clarification	O
in	O
chapter	O
markus	O
dobler	O
pointed	O
out	O
that	O
drawing	O
cookies	O
from	O
a	O
bowl	O
with	O
replace	O
ment	O
is	O
an	O
unrealistic	O
scenario	O
in	O
spring	O
students	O
in	O
my	O
class	O
computational	O
bayesian	O
statistics	O
made	O
many	O
helpful	O
corrections	O
and	O
suggestions	O
kai	O
austin	O
claire	O
barnes	O
kari	O
bender	O
rachel	O
boy	O
kat	O
mendoza	O
arjun	O
iyer	O
ben	O
kroop	O
nathan	O
lintz	O
kyle	O
mcconnaughay	O
alec	O
radford	O
brendan	O
ritter	O
and	O
evan	O
simpson	O
greg	O
marra	O
and	O
matt	O
aasted	O
helped	O
me	O
clarify	O
the	O
discussion	O
of	O
the	O
price	B
is	I
right	I
problem	O
marcus	O
ogren	O
pointed	O
out	O
that	O
the	O
original	O
statement	O
of	O
the	O
locomotive	O
prob	B
lem	O
was	O
ambiguous	O
jasmine	O
kwityn	O
and	O
dan	O
fauxsmith	O
at	O
o	O
reilly	O
media	O
proofread	O
the	O
book	O
and	O
found	O
many	O
opportunities	O
for	O
improvement	O
linda	O
pescatore	O
found	O
a	O
typo	O
and	O
made	O
some	O
helpful	O
suggestions	O
tomasz	O
mi	O
asko	O
sent	O
many	O
excellent	O
corrections	O
and	O
suggestions	O
other	O
people	O
who	O
spotted	O
typos	O
and	O
small	O
errors	O
include	O
tom	O
pollard	O
paul	O
a	O
giannaros	O
jonathan	O
edwards	O
george	O
purkins	O
robert	O
marcus	O
ram	O
limbu	O
james	O
lawry	O
ben	O
kahle	O
jeffrey	O
law	O
and	O
alvaro	O
sanchez	O
contents	O
preface	O
my	O
theory	O
which	O
is	O
mine	O
modeling	B
and	O
approximation	O
v	O
v	O
v	O
working	O
with	O
the	O
code	O
vii	O
code	O
style	O
viii	O
prerequisites	O
ix	O
bayes	O
s	O
theorem	O
conditional	B
probability	B
conjoint	B
probability	B
the	O
cookie	B
problem	I
bayes	O
s	O
theorem	O
the	O
diachronic	B
interpretation	I
the	O
mm	O
problem	O
the	O
monty	B
hall	I
problem	I
discussion	O
computational	O
statistics	O
distributions	O
the	O
cookie	B
problem	I
xii	O
contents	O
the	O
bayesian	B
framework	I
the	O
monty	B
hall	I
problem	I
encapsulating	O
the	O
framework	O
the	O
mm	O
problem	O
discussion	O
exercises	O
estimation	O
the	O
dice	B
problem	I
the	O
locomotive	B
problem	I
what	O
about	O
that	O
prior	B
an	O
alternative	O
prior	B
credible	O
intervals	O
cumulative	O
distribution	B
functions	O
the	O
german	B
tank	I
problem	I
discussion	O
exercises	O
more	O
estimation	O
the	O
euro	B
problem	I
summarizing	O
the	O
posterior	B
swamping	B
the	I
priors	I
optimization	B
the	O
beta	B
distribution	B
discussion	O
exercises	O
contents	O
odds	B
and	O
addends	O
xiii	O
odds	B
the	O
odds	B
form	I
of	O
bayes	O
s	O
theorem	O
oliver	O
s	O
blood	O
addends	O
maxima	O
mixtures	O
discussion	O
decision	B
analysis	I
the	O
price	B
is	I
right	I
problem	O
the	O
prior	B
probability	B
density	B
functions	O
representing	O
pdfs	O
modeling	B
the	O
contestants	O
likelihood	B
update	B
optimal	O
bidding	O
discussion	O
prediction	O
the	O
boston	B
bruins	I
problem	O
poisson	O
processes	O
the	O
posteriors	O
the	O
distribution	B
of	O
goals	O
the	O
probability	B
of	O
winning	O
sudden	B
death	I
discussion	O
exercises	O
xiv	O
observer	B
bias	I
contents	O
the	O
red	B
line	I
problem	I
the	O
model	O
wait	O
times	O
predicting	O
wait	O
times	O
estimating	O
the	O
arrival	B
rate	I
incorporating	O
uncertainty	B
two	O
dimensions	O
decision	B
analysis	I
discussion	O
exercises	O
paintball	O
the	O
suite	B
trigonometry	B
likelihood	B
joint	B
distributions	O
conditional	B
distributions	O
credible	O
intervals	O
discussion	O
exercises	O
approximate	O
bayesian	O
computation	O
the	O
variability	B
hypothesis	I
mean	O
and	O
standard	O
deviation	O
update	B
the	O
posterior	B
distribution	B
of	O
cv	O
contents	O
xv	O
underflow	O
log-likelihood	B
a	O
little	O
optimization	B
abc	B
robust	B
estimation	I
who	O
is	O
more	O
variable	O
discussion	O
exercises	O
hypothesis	B
testing	I
back	O
to	O
the	O
euro	B
problem	I
making	O
a	O
fair	O
comparison	O
the	O
triangle	O
prior	B
discussion	O
exercises	O
evidence	O
interpreting	O
sat	B
scores	O
the	O
scale	O
the	O
prior	B
posterior	B
a	O
better	O
model	O
calibration	B
posterior	B
distribution	B
of	O
efficacy	B
predictive	B
distribution	B
discussion	O
xvi	O
simulation	B
contents	O
the	O
kidney	B
tumor	I
problem	I
a	O
simple	O
model	O
a	O
more	O
general	O
model	O
implementation	B
caching	O
the	O
joint	B
distribution	B
conditional	B
distributions	O
serial	B
correlation	I
discussion	O
a	O
hierarchical	B
model	I
the	O
geiger	B
counter	I
problem	I
start	O
simple	O
make	O
it	O
hierarchical	O
a	O
little	O
optimization	B
extracting	O
the	O
posteriors	O
discussion	O
exercises	O
dealing	O
with	O
dimensions	O
belly	B
button	I
bacteria	B
lions	B
and	I
tigers	I
and	I
bears	I
the	O
hierarchical	O
version	O
random	O
sampling	O
optimization	B
collapsing	O
the	O
hierarchy	O
one	O
more	O
problem	O
contents	O
xvii	O
we	O
re	O
not	O
done	O
yet	O
the	O
belly	B
button	I
data	O
predictive	O
distributions	O
joint	B
posterior	B
coverage	B
discussion	O
xviii	O
contents	O
chapter	O
bayes	O
s	O
theorem	O
conditional	B
probability	B
the	O
fundamental	O
idea	O
behind	O
all	O
bayesian	O
statistics	O
is	O
bayes	O
s	O
theorem	O
which	O
is	O
surprisingly	O
easy	O
to	O
derive	O
provided	O
that	O
you	O
understand	O
conditional	B
probability	B
so	O
we	O
ll	O
start	O
with	O
probability	B
then	O
conditional	B
probability	B
then	O
bayes	O
s	O
theorem	O
and	O
on	O
to	O
bayesian	O
statistics	O
a	O
probability	B
is	O
a	O
number	O
between	O
and	O
both	O
that	O
represents	O
a	O
degree	B
of	I
belief	I
in	O
a	O
fact	O
or	O
prediction	O
the	O
value	O
represents	O
certainty	O
that	O
a	O
fact	O
is	O
true	O
or	O
that	O
a	O
prediction	O
will	O
come	O
true	O
the	O
value	O
represents	O
certainty	O
that	O
the	O
fact	O
is	O
false	O
intermediate	O
values	O
represent	O
degrees	O
of	O
certainty	O
the	O
value	O
often	O
written	O
as	O
means	O
that	O
a	O
predicted	O
outcome	O
is	O
as	O
likely	O
to	O
happen	O
as	O
not	O
for	O
example	O
the	O
probability	B
that	O
a	O
tossed	O
coin	O
lands	O
face	O
up	O
is	O
very	O
close	O
to	O
a	O
conditional	B
probability	B
is	O
a	O
probability	B
based	O
on	O
some	O
background	O
information	O
for	O
example	O
i	O
want	O
to	O
know	O
the	O
probability	B
that	O
i	O
will	O
have	O
a	O
heart	B
attack	I
in	O
the	O
next	O
year	O
according	O
to	O
the	O
cdc	B
every	O
year	O
about	O
americans	O
have	O
a	O
first	O
coronary	O
attack	O
heartdiseasefacts	O
htm	O
the	O
u	O
s	O
population	O
is	O
about	O
million	O
so	O
the	O
probability	B
that	O
a	O
randomly	O
chosen	O
american	O
will	O
have	O
a	O
heart	B
attack	I
in	O
the	O
next	O
year	O
is	O
roughly	O
but	O
i	O
am	O
not	O
a	O
randomly	O
chosen	O
american	O
epidemiologists	O
have	O
identified	O
many	O
factors	O
that	O
affect	O
the	O
risk	O
of	O
heart	O
attacks	O
depending	O
on	O
those	O
factors	O
my	O
risk	O
might	O
be	O
higher	O
or	O
lower	O
than	O
average	O
chapter	O
bayes	O
s	O
theorem	O
i	O
am	O
male	O
years	O
old	O
and	O
i	O
have	O
borderline	O
high	O
cholesterol	O
those	O
factors	O
increase	O
my	O
chances	O
however	O
i	O
have	O
low	O
blood	O
pressure	O
and	O
i	O
don	O
t	O
smoke	O
and	O
those	O
factors	O
decrease	O
my	O
chances	O
plugging	O
everything	O
into	O
the	O
online	O
calculator	O
at	O
httpcvdrisk	O
nhlbi	O
nih	O
govcalculator	O
asp	O
i	O
find	O
that	O
my	O
risk	O
of	O
a	O
heart	B
attack	I
in	O
the	O
next	O
year	O
is	O
about	O
less	O
than	O
the	O
national	O
average	O
that	O
value	O
is	O
a	O
conditional	B
probability	B
because	O
it	O
is	O
based	O
on	O
a	O
number	O
of	O
factors	O
that	O
make	O
up	O
my	O
condition	O
the	O
usual	O
notation	O
for	O
conditional	B
probability	B
is	O
pab	O
which	O
is	O
the	O
probability	B
of	O
a	O
given	O
that	O
b	O
is	O
true	O
in	O
this	O
example	O
a	O
represents	O
the	O
prediction	O
that	O
i	O
will	O
have	O
a	O
heart	B
attack	I
in	O
the	O
next	O
year	O
and	O
b	O
is	O
the	O
set	O
of	O
conditions	O
i	O
listed	O
conjoint	B
probability	B
conjoint	B
probability	B
is	O
a	O
fancy	O
way	O
to	O
say	O
the	O
probability	B
that	O
two	O
things	O
are	O
true	O
i	O
write	O
pa	O
and	O
b	O
to	O
mean	O
the	O
probability	B
that	O
a	O
and	O
b	O
are	O
both	O
true	O
if	O
you	O
learned	O
about	O
probability	B
in	O
the	O
context	O
of	O
coin	O
tosses	O
and	O
dice	B
you	O
might	O
have	O
learned	O
the	O
following	O
formula	O
pa	O
and	O
b	O
pa	O
pb	O
warning	O
not	O
always	O
true	O
for	O
example	O
if	O
i	O
toss	O
two	O
coins	O
and	O
a	O
means	O
the	O
first	O
coin	O
lands	O
face	O
up	O
and	O
b	O
means	O
the	O
second	O
coin	O
lands	O
face	O
up	O
then	O
pa	O
pb	O
and	O
sure	O
enough	O
pa	O
and	O
b	O
pa	O
pb	O
but	O
this	O
formula	O
only	O
works	O
because	O
in	O
this	O
case	O
a	O
and	O
b	O
are	O
independent	O
that	O
is	O
knowing	O
the	O
outcome	O
of	O
the	O
first	O
event	O
does	O
not	O
change	O
the	O
probability	B
of	O
the	O
second	O
or	O
more	O
formally	O
pba	O
pb	O
here	O
is	O
a	O
different	O
example	O
where	O
the	O
events	O
are	O
not	O
independent	O
suppose	O
that	O
a	O
means	O
that	O
it	O
rains	O
today	O
and	O
b	O
means	O
that	O
it	O
rains	O
tomorrow	O
if	O
i	O
know	O
that	O
it	O
rained	O
today	O
it	O
is	O
more	O
likely	O
that	O
it	O
will	O
rain	O
tomorrow	O
so	O
pba	O
pb	O
in	O
general	O
the	O
probability	B
of	O
a	O
conjunction	B
is	O
pa	O
and	O
b	O
pa	O
pba	O
the	O
cookie	B
problem	I
for	O
any	O
a	O
and	O
b	O
so	O
if	O
the	O
chance	O
of	O
rain	O
on	O
any	O
given	O
day	O
is	O
the	O
chance	O
of	O
rain	O
on	O
two	O
consecutive	O
days	O
is	O
not	O
but	O
probably	O
a	O
bit	O
higher	O
the	O
cookie	B
problem	I
we	O
ll	O
get	O
to	O
bayes	O
s	O
theorem	O
soon	O
but	O
i	O
want	O
to	O
motivate	O
it	O
with	O
an	O
example	O
called	O
the	O
cookie	O
suppose	O
there	O
are	O
two	O
bowls	O
of	O
cookies	O
bowl	O
contains	O
vanilla	O
cookies	O
and	O
chocolate	O
cookies	O
bowl	O
contains	O
of	O
each	O
now	O
suppose	O
you	O
choose	O
one	O
of	O
the	O
bowls	O
at	O
random	O
and	O
without	O
looking	O
select	O
a	O
cookie	O
at	O
random	O
the	O
cookie	O
is	O
vanilla	O
what	O
is	O
the	O
probability	B
that	O
it	O
came	O
from	O
bowl	O
this	O
is	O
a	O
conditional	B
probability	B
we	O
want	O
pbowl	O
but	O
it	O
is	O
not	O
obvious	O
how	O
to	O
compute	O
it	O
if	O
i	O
asked	O
a	O
different	O
question	O
the	O
probability	B
of	O
a	O
vanilla	O
cookie	O
given	O
bowl	O
it	O
would	O
be	O
easy	O
pvanillabowl	O
sadly	O
pab	O
is	O
not	O
the	O
same	O
as	O
pba	O
but	O
there	O
is	O
a	O
way	O
to	O
get	O
from	O
one	O
to	O
the	O
other	O
bayes	O
s	O
theorem	O
bayes	O
s	O
theorem	O
at	O
this	O
point	O
we	O
have	O
everything	O
we	O
need	O
to	O
derive	O
bayes	O
s	O
theorem	O
we	O
ll	O
start	O
with	O
the	O
observation	O
that	O
conjunction	B
is	O
commutative	O
that	O
is	O
pa	O
and	O
b	O
pb	O
and	O
a	O
for	O
any	O
events	O
a	O
and	O
b	O
next	O
we	O
write	O
the	O
probability	B
of	O
a	O
conjunction	B
pa	O
and	O
b	O
pa	O
pba	O
since	O
we	O
have	O
not	O
said	O
anything	O
about	O
what	O
a	O
and	O
b	O
mean	O
they	O
are	O
interchangeable	O
interchanging	O
them	O
yields	O
pb	O
and	O
a	O
pb	O
pab	O
on	O
an	O
example	O
from	O
httpen	O
wikipedia	O
orgwikibayes	O
theorem	O
that	O
is	O
no	O
longer	O
there	O
chapter	O
bayes	O
s	O
theorem	O
that	O
s	O
all	O
we	O
need	O
pulling	O
those	O
pieces	O
together	O
we	O
get	O
pb	O
pab	O
pa	O
pba	O
which	O
means	O
there	O
are	O
two	O
ways	O
to	O
compute	O
the	O
conjunction	B
if	O
you	O
have	O
pa	O
you	O
multiply	O
by	O
the	O
conditional	B
probability	B
pba	O
or	O
you	O
can	O
do	O
it	O
the	O
other	O
way	O
around	O
if	O
you	O
know	O
pb	O
you	O
multiply	O
by	O
pab	O
either	O
way	O
you	O
should	O
get	O
the	O
same	O
thing	O
finally	O
we	O
can	O
divide	O
through	O
by	O
pb	O
pab	O
pa	O
pba	O
pb	O
and	O
that	O
s	O
bayes	O
s	O
theorem	O
it	O
might	O
not	O
look	O
like	O
much	O
but	O
it	O
turns	O
out	O
to	O
be	O
surprisingly	O
powerful	O
for	O
example	O
we	O
can	O
use	O
it	O
to	O
solve	O
the	O
cookie	B
problem	I
i	O
ll	O
write	O
for	O
the	O
hypothesis	O
that	O
the	O
cookie	O
came	O
from	O
bowl	O
and	O
v	O
for	O
the	O
vanilla	O
cookie	O
plugging	O
in	O
bayes	O
s	O
theorem	O
we	O
get	O
pv	O
the	O
term	O
on	O
the	O
left	O
is	O
what	O
we	O
want	O
the	O
probability	B
of	O
bowl	O
given	O
that	O
we	O
chose	O
a	O
vanilla	O
cookie	O
the	O
terms	O
on	O
the	O
right	O
are	O
this	O
is	O
the	O
probability	B
that	O
we	O
chose	O
bowl	O
unconditioned	O
by	O
what	O
kind	O
of	O
cookie	O
we	O
got	O
since	O
the	O
problem	O
says	O
we	O
chose	O
a	O
bowl	O
at	O
random	O
we	O
can	O
assume	O
this	O
is	O
the	O
probability	B
of	O
getting	O
a	O
vanilla	O
cookie	O
from	O
bowl	O
which	O
is	O
pv	O
this	O
is	O
the	O
probability	B
of	O
drawing	O
a	O
vanilla	O
cookie	O
from	O
either	O
bowl	O
since	O
we	O
had	O
an	O
equal	O
chance	O
of	O
choosing	O
either	O
bowl	O
and	O
the	O
bowls	O
contain	O
the	O
same	O
number	O
of	O
cookies	O
we	O
had	O
the	O
same	O
chance	O
of	O
choosing	O
any	O
cookie	O
between	O
the	O
two	O
bowls	O
there	O
are	O
vanilla	O
and	O
chocolate	O
cookies	O
so	O
pv	O
putting	O
it	O
together	O
we	O
have	O
the	O
diachronic	B
interpretation	I
which	O
reduces	O
to	O
so	O
the	O
vanilla	O
cookie	O
is	O
evidence	O
in	O
favor	O
of	O
the	O
hypothesis	O
that	O
we	O
chose	O
bowl	O
because	O
vanilla	O
cookies	O
are	O
more	O
likely	O
to	O
come	O
from	O
bowl	O
this	O
example	O
demonstrates	O
one	O
use	O
of	O
bayes	O
s	O
theorem	O
it	O
provides	O
a	O
strategy	O
to	O
get	O
from	O
pba	O
to	O
pab	O
this	O
strategy	O
is	O
useful	O
in	O
cases	O
like	O
the	O
cookie	B
problem	I
where	O
it	O
is	O
easier	O
to	O
compute	O
the	O
terms	O
on	O
the	O
right	O
side	O
of	O
bayes	O
s	O
theorem	O
than	O
the	O
term	O
on	O
the	O
left	O
the	O
diachronic	B
interpretation	I
there	O
is	O
another	O
way	O
to	O
think	O
of	O
bayes	O
s	O
theorem	O
it	O
gives	O
us	O
a	O
way	O
to	O
update	B
the	O
probability	B
of	O
a	O
hypothesis	O
h	O
in	O
light	O
of	O
some	O
body	O
of	O
data	O
d	O
this	O
way	O
of	O
thinking	O
about	O
bayes	O
s	O
theorem	O
is	O
called	O
the	O
diachronic	B
interpretation	I
diachronic	O
means	O
that	O
something	O
is	O
happening	O
over	O
time	O
in	O
this	O
case	O
the	O
probability	B
of	O
the	O
hypotheses	O
changes	O
over	O
time	O
as	O
we	O
see	O
new	O
data	O
rewriting	O
bayes	O
s	O
theorem	O
with	O
h	O
and	O
d	O
yields	O
ph	O
pdh	O
phd	O
pd	O
in	O
this	O
interpretation	O
each	O
term	O
has	O
a	O
name	O
ph	O
is	O
the	O
probability	B
of	O
the	O
hypothesis	O
before	O
we	O
see	O
the	O
data	O
called	O
the	O
prior	B
probability	B
or	O
just	O
prior	B
phd	O
is	O
what	O
we	O
want	O
to	O
compute	O
the	O
probability	B
of	O
the	O
hypothesis	O
after	O
we	O
see	O
the	O
data	O
called	O
the	O
posterior	B
pdh	O
is	O
the	O
probability	B
of	O
the	O
data	O
under	O
the	O
hypothesis	O
called	O
the	O
likelihood	B
pd	O
is	O
the	O
probability	B
of	O
the	O
data	O
under	O
any	O
hypothesis	O
called	O
the	O
normalizing	B
constant	I
sometimes	O
we	O
can	O
compute	O
the	O
prior	B
based	O
on	O
background	O
information	O
for	O
example	O
the	O
cookie	B
problem	I
specifies	O
that	O
we	O
choose	O
a	O
bowl	O
at	O
random	O
with	O
equal	O
probability	B
chapter	O
bayes	O
s	O
theorem	O
in	O
other	O
cases	O
the	O
prior	B
is	O
subjective	O
that	O
is	O
reasonable	O
people	O
might	O
disagree	O
either	O
because	O
they	O
use	O
different	O
background	O
information	O
or	O
because	O
they	O
interpret	O
the	O
same	O
information	O
differently	O
the	O
likelihood	B
is	O
usually	O
the	O
easiest	O
part	O
to	O
compute	O
in	O
the	O
cookie	B
problem	I
if	O
we	O
know	O
which	O
bowl	O
the	O
cookie	O
came	O
from	O
we	O
find	O
the	O
probability	B
of	O
a	O
vanilla	O
cookie	O
by	O
counting	O
the	O
normalizing	B
constant	I
can	O
be	O
tricky	O
it	O
is	O
supposed	O
to	O
be	O
the	O
probability	B
of	O
seeing	O
the	O
data	O
under	O
any	O
hypothesis	O
at	O
all	O
but	O
in	O
the	O
most	O
general	O
case	O
it	O
is	O
hard	O
to	O
nail	O
down	O
what	O
that	O
means	O
most	O
often	O
we	O
simplify	O
things	O
by	O
specifying	O
a	O
set	O
of	O
hypotheses	O
that	O
are	O
mutually	B
exclusive	I
at	O
most	O
one	O
hypothesis	O
in	O
the	O
set	O
can	O
be	O
true	O
and	O
collectively	B
exhaustive	I
there	O
are	O
no	O
other	O
possibilities	O
at	O
least	O
one	O
of	O
the	O
hypotheses	O
has	O
to	O
be	O
true	O
i	O
use	O
the	O
word	O
suite	B
for	O
a	O
set	O
of	O
hypotheses	O
that	O
has	O
these	O
properties	O
in	O
the	O
cookie	B
problem	I
there	O
are	O
only	O
two	O
hypotheses	O
the	O
cookie	O
came	O
from	O
bowl	O
or	O
bowl	O
and	O
they	O
are	O
mutually	B
exclusive	I
and	O
collectively	B
exhaustive	I
in	O
that	O
case	O
we	O
can	O
compute	O
pd	O
using	O
the	O
law	O
of	O
total	B
probability	B
which	O
says	O
that	O
if	O
there	O
are	O
two	O
exclusive	O
ways	O
that	O
something	O
might	O
happen	O
you	O
can	O
add	O
up	O
the	O
probabilities	O
like	O
this	O
pd	O
plugging	O
in	O
the	O
values	O
from	O
the	O
cookie	B
problem	I
we	O
have	O
pd	O
which	O
is	O
what	O
we	O
computed	O
earlier	O
by	O
mentally	O
combining	O
the	O
two	O
bowls	O
the	O
mm	O
problem	O
mm	O
s	O
are	O
small	O
candy-coated	O
chocolates	O
that	O
come	O
in	O
a	O
variety	O
of	O
colors	O
mars	O
inc	O
which	O
makes	O
mm	O
s	O
changes	O
the	O
mixture	B
of	O
colors	O
from	O
time	O
to	O
time	O
the	O
mm	O
problem	O
in	O
they	O
introduced	O
blue	O
mm	O
s	O
before	O
then	O
the	O
color	O
mix	O
in	O
a	O
bag	O
of	O
plain	O
mm	O
s	O
was	O
brown	O
yellow	O
red	O
green	O
orange	O
tan	O
afterward	O
it	O
was	O
blue	O
green	O
orange	O
yellow	O
red	O
brown	O
suppose	O
a	O
friend	O
of	O
mine	O
has	O
two	O
bags	O
of	O
mm	O
s	O
and	O
he	O
tells	O
me	O
that	O
one	O
is	O
from	O
and	O
one	O
from	O
he	O
won	O
t	O
tell	O
me	O
which	O
is	O
which	O
but	O
he	O
gives	O
me	O
one	O
mm	O
from	O
each	O
bag	O
one	O
is	O
yellow	O
and	O
one	O
is	O
green	O
what	O
is	O
the	O
probability	B
that	O
the	O
yellow	O
one	O
came	O
from	O
the	O
bag	O
this	O
problem	O
is	O
similar	O
to	O
the	O
cookie	B
problem	I
with	O
the	O
twist	O
that	O
i	O
draw	O
one	O
sample	O
from	O
each	O
bowlbag	O
this	O
problem	O
also	O
gives	O
me	O
a	O
chance	O
to	O
demonstrate	O
the	O
table	B
method	I
which	O
is	O
useful	O
for	O
solving	O
problems	O
like	O
this	O
on	O
paper	O
in	O
the	O
next	O
chapter	O
we	O
will	O
solve	O
them	O
computationally	O
the	O
first	O
step	O
is	O
to	O
enumerate	O
the	O
hypotheses	O
the	O
bag	O
the	O
yellow	O
mm	O
came	O
from	O
i	O
ll	O
call	O
bag	O
i	O
ll	O
call	O
the	O
other	O
bag	O
so	O
the	O
hypotheses	O
are	O
a	O
bag	O
is	O
from	O
which	O
implies	O
that	O
bag	O
is	O
from	O
b	O
bag	O
is	O
from	O
and	O
bag	O
from	O
now	O
we	O
construct	O
a	O
table	O
with	O
a	O
row	O
for	O
each	O
hypothesis	O
and	O
a	O
column	O
for	O
each	O
term	O
in	O
bayes	O
s	O
theorem	O
prior	B
likelihood	B
pdh	O
ph	O
a	O
b	O
ph	O
pdh	O
posterior	B
phd	O
the	O
first	O
column	O
has	O
the	O
priors	O
based	O
on	O
the	O
statement	O
of	O
the	O
problem	O
it	O
is	O
reasonable	O
to	O
choose	O
pa	O
pb	O
the	O
second	O
column	O
has	O
the	O
likelihoods	O
which	O
follow	O
from	O
the	O
information	O
in	O
the	O
problem	O
for	O
example	O
if	O
a	O
is	O
true	O
the	O
yellow	O
mm	O
came	O
from	O
the	O
bag	O
with	O
probability	B
and	O
the	O
green	O
came	O
from	O
the	O
bag	O
with	O
probability	B
if	O
b	O
is	O
true	O
the	O
yellow	O
mm	O
came	O
from	O
the	O
bag	O
with	O
probability	B
and	O
the	O
green	O
came	O
from	O
the	O
bag	O
with	O
probability	B
because	O
the	O
selections	O
are	O
independent	O
we	O
get	O
the	O
conjoint	B
probability	B
by	O
multiplying	O
the	O
third	O
column	O
is	O
just	O
the	O
product	O
of	O
the	O
previous	O
two	O
the	O
sum	O
of	O
this	O
column	O
is	O
the	O
normalizing	B
constant	I
to	O
get	O
the	O
last	O
column	O
which	O
chapter	O
bayes	O
s	O
theorem	O
contains	O
the	O
posteriors	O
we	O
divide	O
the	O
third	O
column	O
by	O
the	O
normalizing	B
constant	I
that	O
s	O
it	O
simple	O
right	O
well	O
you	O
might	O
be	O
bothered	O
by	O
one	O
detail	O
i	O
write	O
pdh	O
in	O
terms	O
of	O
percentages	O
not	O
probabilities	O
which	O
means	O
it	O
is	O
off	O
by	O
a	O
factor	O
of	O
but	O
that	O
cancels	O
out	O
when	O
we	O
divide	O
through	O
by	O
the	O
normalizing	B
constant	I
so	O
it	O
doesn	O
t	O
affect	O
the	O
result	O
when	O
the	O
set	O
of	O
hypotheses	O
is	O
mutually	B
exclusive	I
and	O
collectively	B
exhaustive	I
you	O
can	O
multiply	O
the	O
likelihoods	O
by	O
any	O
factor	O
if	O
it	O
is	O
convenient	O
as	O
long	O
as	O
you	O
apply	O
the	O
same	O
factor	O
to	O
the	O
entire	O
column	O
the	O
monty	B
hall	I
problem	I
the	O
monty	B
hall	I
problem	I
might	O
be	O
the	O
most	O
contentious	O
question	O
in	O
the	O
history	O
of	O
probability	B
the	O
scenario	O
is	O
simple	O
but	O
the	O
correct	O
answer	O
is	O
so	O
counterintuitive	O
that	O
many	O
people	O
just	O
can	O
t	O
accept	O
it	O
and	O
many	O
smart	O
people	O
have	O
embarrassed	O
themselves	O
not	O
just	O
by	O
getting	O
it	O
wrong	O
but	O
by	O
arguing	O
the	O
wrong	O
side	O
aggressively	O
in	O
public	O
monty	O
hall	O
was	O
the	O
original	O
host	O
of	O
the	O
game	O
show	O
let	O
s	O
make	O
a	O
deal	O
the	O
monty	B
hall	I
problem	I
is	O
based	O
on	O
one	O
of	O
the	O
regular	O
games	O
on	O
the	O
show	O
if	O
you	O
are	O
on	O
the	O
show	O
here	O
s	O
what	O
happens	O
monty	O
shows	O
you	O
three	O
closed	O
doors	O
and	O
tells	O
you	O
that	O
there	O
is	O
a	O
prize	O
behind	O
each	O
door	O
one	O
prize	O
is	O
a	O
car	O
the	O
other	O
two	O
are	O
less	O
valuable	O
prizes	O
like	O
peanut	O
butter	O
and	O
fake	O
finger	O
nails	O
the	O
prizes	O
are	O
arranged	O
at	O
random	O
the	O
object	O
of	O
the	O
game	O
is	O
to	O
guess	O
which	O
door	O
has	O
the	O
car	O
if	O
you	O
guess	O
right	O
you	O
get	O
to	O
keep	O
the	O
car	O
you	O
pick	O
a	O
door	O
which	O
we	O
will	O
call	O
door	O
a	O
we	O
ll	O
call	O
the	O
other	O
doors	O
b	O
and	O
c	O
before	O
opening	O
the	O
door	O
you	O
chose	O
monty	O
increases	O
the	O
suspense	O
by	O
opening	O
either	O
door	O
b	O
or	O
c	O
whichever	O
does	O
not	O
have	O
the	O
car	O
the	O
car	O
is	O
actually	O
behind	O
door	O
a	O
monty	O
can	O
safely	O
open	O
b	O
or	O
c	O
so	O
he	O
chooses	O
one	O
at	O
random	O
then	O
monty	O
offers	O
you	O
the	O
option	O
to	O
stick	B
with	O
your	O
original	O
choice	O
or	O
switch	B
to	O
the	O
one	O
remaining	O
unopened	O
door	O
the	O
monty	B
hall	I
problem	I
the	O
question	O
is	O
should	O
you	O
stick	B
or	O
switch	B
or	O
does	O
it	O
make	O
no	O
difference	O
most	O
people	O
have	O
the	O
strong	O
intuition	B
that	O
it	O
makes	O
no	O
difference	O
there	O
are	O
two	O
doors	O
left	O
they	O
reason	O
so	O
the	O
chance	O
that	O
the	O
car	O
is	O
behind	O
door	O
a	O
is	O
but	O
that	O
is	O
wrong	O
in	O
fact	O
the	O
chance	O
of	O
winning	O
if	O
you	O
stick	B
with	O
door	O
a	O
is	O
only	O
if	O
you	O
switch	B
your	O
chances	O
are	O
by	O
applying	O
bayes	O
s	O
theorem	O
we	O
can	O
break	O
this	O
problem	O
into	O
simple	O
pieces	O
and	O
maybe	O
convince	O
ourselves	O
that	O
the	O
correct	O
answer	O
is	O
in	O
fact	O
correct	O
to	O
start	O
we	O
should	O
make	O
a	O
careful	O
statement	O
of	O
the	O
data	O
in	O
this	O
case	O
d	O
consists	O
of	O
two	O
parts	O
monty	O
chooses	O
door	O
b	O
and	O
there	O
is	O
no	O
car	O
there	O
next	O
we	O
define	O
three	O
hypotheses	O
a	O
b	O
and	O
c	O
represent	O
the	O
hypothesis	O
that	O
the	O
car	O
is	O
behind	O
door	O
a	O
door	O
b	O
or	O
door	O
c	O
again	O
let	O
s	O
apply	O
the	O
table	B
method	I
prior	B
likelihood	B
pdh	O
ph	O
a	O
b	O
c	O
ph	O
pdh	O
posterior	B
phd	O
filling	O
in	O
the	O
priors	O
is	O
easy	O
because	O
we	O
are	O
told	O
that	O
the	O
prizes	O
are	O
arranged	O
at	O
random	O
which	O
suggests	O
that	O
the	O
car	O
is	O
equally	O
likely	O
to	O
be	O
behind	O
any	O
door	O
figuring	O
out	O
the	O
likelihoods	O
takes	O
some	O
thought	O
but	O
with	O
reasonable	O
care	O
we	O
can	O
be	O
confident	O
that	O
we	O
have	O
it	O
right	O
if	O
the	O
car	O
is	O
actually	O
behind	O
a	O
monty	O
could	O
safely	O
open	O
doors	O
b	O
or	O
c	O
so	O
the	O
probability	B
that	O
he	O
chooses	O
b	O
is	O
and	O
since	O
the	O
car	O
is	O
actually	O
behind	O
a	O
the	O
probability	B
that	O
the	O
car	O
is	O
not	O
behind	O
b	O
is	O
if	O
the	O
car	O
is	O
actually	O
behind	O
b	O
monty	O
has	O
to	O
open	O
door	O
c	O
so	O
the	O
prob	B
ability	O
that	O
he	O
opens	O
door	O
b	O
is	O
finally	O
if	O
the	O
car	O
is	O
behind	O
door	O
c	O
monty	O
opens	O
b	O
with	O
probability	B
and	O
finds	O
no	O
car	O
there	O
with	O
probability	B
now	O
the	O
hard	O
part	O
is	O
over	O
the	O
rest	O
is	O
just	O
arithmetic	O
the	O
sum	O
of	O
the	O
third	O
column	O
is	O
dividing	O
through	O
yields	O
pad	O
and	O
pcd	O
so	O
you	O
are	O
better	O
off	O
switching	O
chapter	O
bayes	O
s	O
theorem	O
there	O
are	O
many	O
variations	O
of	O
the	O
monty	B
hall	I
problem	I
one	O
of	O
the	O
strengths	O
of	O
the	O
bayesian	O
approach	O
is	O
that	O
it	O
generalizes	O
to	O
handle	O
these	O
variations	O
for	O
example	O
suppose	O
that	O
monty	O
always	O
chooses	O
b	O
if	O
he	O
can	O
and	O
only	O
chooses	O
c	O
if	O
he	O
has	O
to	O
the	O
car	O
is	O
behind	O
b	O
in	O
that	O
case	O
the	O
revised	O
table	O
is	O
ph	O
pdh	O
posterior	B
phd	O
prior	B
likelihood	B
pdh	O
ph	O
a	O
b	O
c	O
the	O
only	O
change	O
is	O
pda	O
if	O
the	O
car	O
is	O
behind	O
a	O
monty	O
can	O
choose	O
to	O
open	O
b	O
or	O
c	O
but	O
in	O
this	O
variation	O
he	O
always	O
chooses	O
b	O
so	O
pda	O
as	O
a	O
result	O
the	O
likelihoods	O
are	O
the	O
same	O
for	O
a	O
and	O
c	O
and	O
the	O
posteriors	O
are	O
the	O
same	O
pad	O
pcd	O
in	O
this	O
case	O
the	O
fact	O
that	O
monty	O
chose	O
b	O
reveals	O
no	O
information	O
about	O
the	O
location	O
of	O
the	O
car	O
so	O
it	O
doesn	O
t	O
matter	O
whether	O
the	O
contestant	O
sticks	O
or	O
switches	O
on	O
the	O
other	O
hand	O
if	O
he	O
had	O
opened	O
c	O
we	O
would	O
know	O
pbd	O
i	O
included	O
the	O
monty	B
hall	I
problem	I
in	O
this	O
chapter	O
because	O
i	O
think	O
it	O
is	O
fun	O
and	O
because	O
bayes	O
s	O
theorem	O
makes	O
the	O
complexity	O
of	O
the	O
problem	O
a	O
little	O
more	O
manageable	O
but	O
it	O
is	O
not	O
a	O
typical	O
use	O
of	O
bayes	O
s	O
theorem	O
so	O
if	O
you	O
found	O
it	O
confusing	O
don	O
t	O
worry	O
discussion	O
for	O
many	O
problems	O
involving	O
conditional	B
probability	B
bayes	O
s	O
theorem	O
provides	O
a	O
divide-and-conquer	B
strategy	O
if	O
pab	O
is	O
hard	O
to	O
compute	O
or	O
hard	O
to	O
measure	O
experimentally	O
check	O
whether	O
it	O
might	O
be	O
easier	O
to	O
compute	O
the	O
other	O
terms	O
in	O
bayes	O
s	O
theorem	O
pba	O
pa	O
and	O
pb	O
if	O
the	O
monty	B
hall	I
problem	I
is	O
your	O
idea	O
of	O
fun	O
i	O
have	O
collected	O
a	O
number	O
of	O
similar	O
problems	O
in	O
an	O
article	O
called	O
all	O
your	O
bayes	O
are	O
belong	O
to	O
us	O
which	O
you	O
can	O
read	O
at	O
all-your-bayes-are-belong-to-us	O
html	O
chapter	O
computational	O
statistics	O
distributions	O
in	O
statistics	O
a	O
distribution	B
is	O
a	O
set	O
of	O
values	O
and	O
their	O
corresponding	O
probabilities	O
for	O
example	O
if	O
you	O
roll	O
a	O
six-sided	O
die	O
the	O
set	O
of	O
possible	O
values	O
is	O
the	O
numbers	O
to	O
and	O
the	O
probability	B
associated	O
with	O
each	O
value	O
is	O
as	O
another	O
example	O
you	O
might	O
be	O
interested	O
in	O
how	O
many	O
times	O
each	O
word	O
appears	O
in	O
common	O
english	O
usage	O
you	O
could	O
build	O
a	O
distribution	B
that	O
includes	O
each	O
word	O
and	O
how	O
many	O
times	O
it	O
appears	O
to	O
represent	O
a	O
distribution	B
in	O
python	O
you	O
could	O
use	O
a	O
dictionary	O
that	O
maps	O
from	O
each	O
value	O
to	O
its	O
probability	B
i	O
have	O
written	O
a	O
class	O
called	O
pmf	B
that	O
uses	O
a	O
python	O
dictionary	O
in	O
exactly	O
that	O
way	O
and	O
provides	O
a	O
number	O
of	O
useful	O
methods	O
i	O
called	O
the	O
class	O
pmf	B
in	O
reference	O
to	O
a	O
probability	B
mass	I
function	I
which	O
is	O
a	O
way	O
to	O
represent	O
a	O
distribution	B
mathematically	O
pmf	B
is	O
defined	O
in	O
a	O
python	O
module	O
i	O
wrote	O
to	O
accompany	O
this	O
book	O
thinkbayes	O
py	O
you	O
can	O
download	O
it	O
from	O
httpthinkbayes	O
com	O
thinkbayes	O
py	O
for	O
more	O
information	O
see	O
section	O
to	O
use	O
pmf	B
you	O
can	O
import	O
it	O
like	O
this	O
from	O
thinkbayes	O
import	O
pmf	B
the	O
following	O
code	O
builds	O
a	O
pmf	B
to	O
represent	O
the	O
distribution	B
of	O
outcomes	O
for	O
a	O
six-sided	O
die	O
pmf	B
pmf	B
for	O
x	O
in	O
pmf	B
setx	O
chapter	O
computational	O
statistics	O
pmf	B
creates	O
an	O
empty	O
pmf	B
with	O
no	O
values	O
the	O
set	O
method	O
sets	O
the	O
probability	B
associated	O
with	O
each	O
value	O
to	O
here	O
s	O
another	O
example	O
that	O
counts	O
the	O
number	O
of	O
times	O
each	O
word	O
appears	O
in	O
a	O
sequence	O
pmf	B
pmf	B
for	O
word	O
in	O
word	O
list	O
pmf	B
incrword	O
incr	O
increases	O
the	O
probability	B
associated	O
with	O
each	O
word	O
by	O
if	O
a	O
word	O
is	O
not	O
already	O
in	O
the	O
pmf	B
it	O
is	O
added	O
i	O
put	O
probability	B
in	O
quotes	O
because	O
in	O
this	O
example	O
the	O
probabilities	O
are	O
not	O
normalized	O
that	O
is	O
they	O
do	O
not	O
add	O
up	O
to	O
so	O
they	O
are	O
not	O
true	O
probabilities	O
but	O
in	O
this	O
example	O
the	O
word	O
counts	O
are	O
proportional	O
to	O
the	O
probabilities	O
so	O
after	O
we	O
count	O
all	O
the	O
words	O
we	O
can	O
compute	O
probabilities	O
by	O
dividing	O
through	O
by	O
the	O
total	O
number	O
of	O
words	O
pmf	B
provides	O
a	O
method	O
normalize	B
that	O
does	O
exactly	O
that	O
pmf	B
normalize	B
once	O
you	O
have	O
a	O
pmf	B
object	O
you	O
can	O
ask	O
for	O
the	O
probability	B
associated	O
with	O
any	O
value	O
print	O
pmf	B
probthe	O
and	O
that	O
would	O
print	O
the	O
frequency	O
of	O
the	O
word	O
the	O
as	O
a	O
fraction	O
of	O
the	O
words	O
in	O
the	O
list	O
pmf	B
uses	O
a	O
python	O
dictionary	O
to	O
store	O
the	O
values	O
and	O
their	O
probabilities	O
so	O
the	O
values	O
in	O
the	O
pmf	B
can	O
be	O
any	O
hashable	O
type	O
the	O
probabilities	O
can	O
be	O
any	O
numerical	O
type	O
but	O
they	O
are	O
usually	O
floating-point	O
numbers	O
float	O
the	O
cookie	B
problem	I
in	O
the	O
context	O
of	O
bayes	O
s	O
theorem	O
it	O
is	O
natural	O
to	O
use	O
a	O
pmf	B
to	O
map	O
from	O
each	O
hypothesis	O
to	O
its	O
probability	B
in	O
the	O
cookie	B
problem	I
the	O
hypotheses	O
are	O
and	O
in	O
python	O
i	O
represent	O
them	O
with	O
strings	O
pmf	B
pmf	B
pmf	B
setbowl	O
pmf	B
setbowl	O
the	O
bayesian	B
framework	I
this	O
distribution	B
which	O
contains	O
the	O
priors	O
for	O
each	O
hypothesis	O
is	O
called	O
for	O
it	O
the	O
prior	B
distribution	B
to	O
update	B
the	O
distribution	B
based	O
on	O
new	O
data	O
vanilla	O
cookie	O
we	O
multiply	O
each	O
prior	B
by	O
the	O
corresponding	O
likelihood	B
the	O
likelihood	B
of	O
drawing	O
a	O
vanilla	O
cookie	O
from	O
bowl	O
is	O
the	O
likelihood	B
for	O
bowl	O
is	O
pmf	B
multbowl	O
pmf	B
multbowl	O
mult	B
does	O
what	O
you	O
would	O
expect	O
it	O
gets	O
the	O
probability	B
for	O
the	O
given	O
hypothesis	O
and	O
multiplies	O
by	O
the	O
given	O
likelihood	B
after	O
this	O
update	B
the	O
distribution	B
is	O
no	O
longer	O
normalized	O
but	O
because	O
these	O
hypotheses	O
are	O
mutually	B
exclusive	I
and	O
collectively	B
exhaustive	I
we	O
can	O
renormalize	B
pmf	B
normalize	B
the	O
result	O
is	O
a	O
distribution	B
that	O
contains	O
the	O
posterior	B
probability	B
for	O
each	O
hypothesis	O
which	O
is	O
called	O
now	O
the	O
posterior	B
distribution	B
finally	O
we	O
can	O
get	O
the	O
posterior	B
probability	B
for	O
bowl	O
print	O
pmf	B
probbowl	O
and	O
the	O
answer	O
is	O
you	O
can	O
download	O
this	O
example	O
from	O
http	O
thinkbayes	O
comcookie	O
py	O
for	O
more	O
information	O
see	O
section	O
the	O
bayesian	B
framework	I
before	O
we	O
go	O
on	O
to	O
other	O
problems	O
i	O
want	O
to	O
rewrite	O
the	O
code	O
from	O
the	O
previous	O
section	O
to	O
make	O
it	O
more	O
general	O
first	O
i	O
ll	O
define	O
a	O
class	O
to	O
encapsulate	O
the	O
code	O
related	O
to	O
this	O
problem	O
class	O
cookiepmf	O
def	O
hypos	O
pmf	B
init	O
self	O
for	O
hypo	O
in	O
hypos	O
self	O
sethypo	O
self	O
normalize	B
a	O
cookie	O
object	O
is	O
a	O
pmf	B
that	O
maps	O
from	O
hypotheses	O
to	O
their	O
probabilities	O
the	O
method	O
gives	O
each	O
hypothesis	O
the	O
same	O
prior	B
probability	B
as	O
in	O
the	O
previous	O
section	O
there	O
are	O
two	O
hypotheses	O
chapter	O
computational	O
statistics	O
hypos	O
pmf	B
cookiehypos	O
cookie	O
provides	O
an	O
update	B
method	O
that	O
takes	O
data	O
as	O
a	O
parameter	B
and	O
updates	O
the	O
probabilities	O
def	O
updateself	O
data	O
for	O
hypo	O
in	O
self	O
values	O
like	O
self	O
likelihooddata	O
hypo	O
self	O
multhypo	O
like	O
self	O
normalize	B
update	B
loops	O
through	O
each	O
hypothesis	O
in	O
the	O
suite	B
and	O
multiplies	O
its	O
probability	B
by	O
the	O
likelihood	B
of	O
the	O
data	O
under	O
the	O
hypothesis	O
which	O
is	O
computed	O
by	O
likelihood	B
mixes	O
def	O
likelihoodself	O
data	O
hypo	O
mix	O
self	O
mixeshypo	O
like	O
mixdata	O
return	O
like	O
likelihood	B
uses	O
mixes	O
which	O
is	O
a	O
dictionary	O
that	O
maps	O
from	O
the	O
name	O
of	O
a	O
bowl	O
to	O
the	O
mix	O
of	O
cookies	O
in	O
the	O
bowl	O
here	O
s	O
what	O
the	O
update	B
looks	O
like	O
pmf	B
updatevanilla	O
and	O
then	O
we	O
can	O
print	O
the	O
posterior	B
probability	B
of	O
each	O
hypothesis	O
for	O
hypo	O
prob	B
in	O
pmf	B
items	O
print	O
hypo	O
prob	B
the	O
result	O
is	O
bowl	O
bowl	O
which	O
is	O
the	O
same	O
as	O
what	O
we	O
got	O
before	O
this	O
code	O
is	O
more	O
complicated	O
than	O
what	O
we	O
saw	O
in	O
the	O
previous	O
section	O
one	O
advantage	O
is	O
that	O
it	O
generalizes	O
to	O
the	O
case	O
where	O
we	O
draw	O
more	O
than	O
one	O
cookie	O
from	O
the	O
same	O
bowl	O
replacement	O
dataset	O
for	O
data	O
in	O
dataset	O
pmf	B
updatedata	O
the	O
monty	B
hall	I
problem	I
the	O
other	O
advantage	O
is	O
that	O
it	O
provides	O
a	O
framework	O
for	O
solving	O
many	O
similar	O
problems	O
in	O
the	O
next	O
section	O
we	O
ll	O
solve	O
the	O
monty	B
hall	I
problem	I
computationally	O
and	O
then	O
see	O
what	O
parts	O
of	O
the	O
framework	O
are	O
the	O
same	O
the	O
code	O
in	O
this	O
section	O
is	O
available	O
from	O
py	O
for	O
more	O
information	O
see	O
section	O
the	O
monty	B
hall	I
problem	I
to	O
solve	O
the	O
monty	B
hall	I
problem	I
i	O
ll	O
define	O
a	O
new	O
class	O
class	O
montypmf	O
def	O
hypos	O
pmf	B
init	O
self	O
for	O
hypo	O
in	O
hypos	O
self	O
sethypo	O
self	O
normalize	B
so	O
far	O
monty	O
and	O
cookie	O
are	O
exactly	O
the	O
same	O
and	O
the	O
code	O
that	O
creates	O
the	O
pmf	B
is	O
the	O
same	O
too	O
except	O
for	O
the	O
names	O
of	O
the	O
hypotheses	O
hypos	O
pmf	B
montyhypos	O
calling	O
update	B
is	O
pretty	O
much	O
the	O
same	O
data	O
pmf	B
updatedata	O
and	O
the	O
implementation	B
of	O
update	B
is	O
exactly	O
the	O
same	O
def	O
updateself	O
data	O
for	O
hypo	O
in	O
self	O
values	O
like	O
self	O
likelihooddata	O
hypo	O
self	O
multhypo	O
like	O
self	O
normalize	B
the	O
only	O
part	O
that	O
requires	O
some	O
work	O
is	O
likelihood	B
def	O
likelihoodself	O
data	O
hypo	O
if	O
hypo	O
data	O
return	O
elif	O
hypo	O
return	O
else	O
return	O
chapter	O
computational	O
statistics	O
finally	O
printing	O
the	O
results	O
is	O
the	O
same	O
for	O
hypo	O
prob	B
in	O
pmf	B
items	O
print	O
hypo	O
prob	B
and	O
the	O
answer	O
is	O
a	O
b	O
c	O
in	O
this	O
example	O
writing	O
likelihood	B
is	O
a	O
little	O
complicated	O
but	O
the	O
framework	O
of	O
the	O
bayesian	O
update	B
is	O
simple	O
the	O
code	O
in	O
this	O
section	O
is	O
available	O
from	O
httpthinkbayes	O
commonty	O
py	O
for	O
more	O
information	O
see	O
section	O
encapsulating	O
the	O
framework	O
now	O
that	O
we	O
see	O
what	O
elements	O
of	O
the	O
framework	O
are	O
the	O
same	O
we	O
can	O
encapsulate	O
them	O
in	O
an	O
object	O
a	O
suite	B
is	O
a	O
pmf	B
that	O
provides	O
update	B
and	O
print	O
class	O
suitepmf	O
a	O
suite	B
of	O
hypotheses	O
and	O
their	O
probabilities	O
def	O
hypotuple	O
the	O
distribution	B
def	O
updateself	O
data	O
each	O
hypothesis	O
based	O
on	O
the	O
data	O
def	O
printself	O
the	O
hypotheses	O
and	O
their	O
probabilities	O
the	O
implementation	B
of	O
suite	B
is	O
in	O
thinkbayes	O
py	O
to	O
use	O
suite	B
you	O
should	O
write	O
a	O
class	O
that	O
inherits	O
from	O
it	O
and	O
provides	O
likelihood	B
for	O
example	O
here	O
is	O
the	O
solution	O
to	O
the	O
monty	B
hall	I
problem	I
rewritten	O
to	O
use	O
suite	B
from	O
thinkbayes	O
import	O
suite	B
class	I
montysuite	O
def	O
likelihoodself	O
data	O
hypo	O
if	O
hypo	O
data	O
return	O
the	O
mm	O
problem	O
elif	O
hypo	O
return	O
else	O
return	O
and	O
here	O
s	O
the	O
code	O
that	O
uses	O
this	O
class	O
suite	B
montyabc	O
suite	B
updateb	O
suite	B
print	O
you	O
can	O
download	O
this	O
example	O
from	O
for	O
more	O
information	O
see	O
section	O
the	O
mm	O
problem	O
we	O
can	O
use	O
the	O
suite	B
framework	O
to	O
solve	O
the	O
mm	O
problem	O
writing	O
the	O
likelihood	B
function	I
is	O
tricky	O
but	O
everything	O
else	O
is	O
straightforward	O
first	O
i	O
need	O
to	O
encode	O
the	O
color	O
mixes	O
from	O
before	O
and	O
after	O
then	O
i	O
have	O
to	O
encode	O
the	O
hypotheses	O
hypoa	O
hypob	O
hypoa	O
represents	O
the	O
hypothesis	O
that	O
bag	O
is	O
from	O
and	O
bag	O
from	O
hypob	O
is	O
the	O
other	O
way	O
around	O
next	O
i	O
map	O
from	O
the	O
name	O
of	O
the	O
hypothesis	O
to	O
the	O
representation	O
hypotheses	O
dictahypoa	O
bhypob	O
chapter	O
computational	O
statistics	O
and	O
finally	O
i	O
can	O
write	O
likelihood	B
in	O
this	O
case	O
the	O
hypothesis	O
hypo	O
is	O
a	O
string	O
either	O
a	O
or	O
b	O
the	O
data	O
is	O
a	O
tuple	B
that	O
specifies	O
a	O
bag	O
and	O
a	O
color	O
def	O
likelihoodself	O
data	O
hypo	O
bag	O
color	O
data	O
mix	O
self	O
hypotheseshypobag	O
like	O
mixcolor	O
return	O
like	O
here	O
s	O
the	O
code	O
that	O
creates	O
the	O
suite	B
and	O
updates	O
it	O
suite	B
m	O
and	O
mab	O
suite	B
print	O
and	O
here	O
s	O
the	O
result	O
a	O
b	O
the	O
posterior	B
probability	B
of	O
a	O
is	O
approximately	O
which	O
is	O
what	O
we	O
got	O
before	O
the	O
code	O
in	O
this	O
section	O
is	O
available	O
from	O
httpthinkbayes	O
comm	O
and	O
m	O
py	O
for	O
more	O
information	O
see	O
section	O
discussion	O
this	O
chapter	O
presents	O
the	O
suite	B
class	I
which	O
encapsulates	O
the	O
bayesian	O
update	B
framework	O
suite	B
is	O
an	O
abstract	B
type	I
which	O
means	O
that	O
it	O
defines	O
the	O
interface	B
a	O
suite	B
is	O
supposed	O
to	O
have	O
but	O
does	O
not	O
provide	O
a	O
complete	O
implementation	B
the	O
suite	B
interface	B
includes	O
update	B
and	O
likelihood	B
but	O
the	O
suite	B
class	I
only	O
provides	O
an	O
implementation	B
of	O
update	B
not	O
likelihood	B
a	O
concrete	B
type	I
is	O
a	O
class	O
that	O
extends	O
an	O
abstract	O
parent	O
class	O
and	O
provides	O
an	O
implementation	B
of	O
the	O
missing	O
methods	O
for	O
example	O
monty	O
extends	O
suite	B
so	O
it	O
inherits	O
update	B
and	O
provides	O
likelihood	B
if	O
you	O
are	O
familiar	O
with	O
design	O
patterns	O
you	O
might	O
recognize	O
this	O
as	O
an	O
example	O
of	O
the	O
template	B
method	I
pattern	I
you	O
can	O
read	O
about	O
this	O
pattern	O
at	O
httpen	O
wikipedia	O
orgwikitemplate	O
method	O
pattern	O
exercises	O
most	O
of	O
the	O
examples	O
in	O
the	O
following	O
chapters	O
follow	O
the	O
same	O
pattern	O
for	O
each	O
problem	O
we	O
define	O
a	O
new	O
class	O
that	O
extends	O
suite	B
inherits	O
update	B
and	O
provides	O
likelihood	B
in	O
a	O
few	O
cases	O
we	O
override	O
update	B
usually	O
to	O
improve	O
performance	O
exercises	O
exercise	O
in	O
section	O
i	O
said	O
that	O
the	O
solution	O
to	O
the	O
cookie	B
problem	I
generalizes	O
to	O
the	O
case	O
where	O
we	O
draw	O
multiple	O
cookies	O
with	O
replacement	O
but	O
in	O
the	O
more	O
likely	O
scenario	O
where	O
we	O
eat	O
the	O
cookies	O
we	O
draw	O
the	O
likelihood	B
of	O
each	O
draw	O
depends	O
on	O
the	O
previous	O
draws	O
modify	O
the	O
solution	O
in	O
this	O
chapter	O
to	O
handle	O
selection	O
without	O
replacement	O
hint	O
add	O
instance	O
variables	O
to	O
cookie	O
to	O
represent	O
the	O
hypothetical	O
state	O
of	O
the	O
bowls	O
and	O
modify	O
likelihood	B
accordingly	O
you	O
might	O
want	O
to	O
define	O
a	O
bowl	O
object	O
chapter	O
computational	O
statistics	O
chapter	O
estimation	O
the	O
dice	B
problem	I
suppose	O
i	O
have	O
a	O
box	O
of	O
dice	B
that	O
contains	O
a	O
die	O
a	O
die	O
an	O
die	O
a	O
die	O
and	O
a	O
die	O
if	O
you	O
have	O
ever	O
played	O
dungeons	O
dragons	O
you	O
know	O
what	O
i	O
am	O
talking	O
about	O
suppose	O
i	O
select	O
a	O
die	O
from	O
the	O
box	O
at	O
random	O
roll	O
it	O
and	O
get	O
a	O
what	O
is	O
the	O
probability	B
that	O
i	O
rolled	O
each	O
die	O
let	O
me	O
suggest	O
a	O
three-step	O
strategy	O
for	O
approaching	O
a	O
problem	O
like	O
this	O
choose	O
a	O
representation	O
for	O
the	O
hypotheses	O
choose	O
a	O
representation	O
for	O
the	O
data	O
write	O
the	O
likelihood	B
function	I
in	O
previous	O
examples	O
i	O
used	O
strings	O
to	O
represent	O
hypotheses	O
and	O
data	O
but	O
for	O
the	O
die	O
problem	O
i	O
ll	O
use	O
numbers	O
specifically	O
i	O
ll	O
use	O
the	O
integers	O
and	O
to	O
represent	O
hypotheses	O
suite	B
and	O
integers	O
from	O
to	O
for	O
the	O
data	O
these	O
representations	O
make	O
it	O
easy	O
to	O
write	O
the	O
likelihood	B
function	I
class	O
dicesuite	O
def	O
likelihoodself	O
data	O
hypo	O
if	O
hypo	O
data	O
return	O
else	O
return	O
chapter	O
estimation	O
here	O
s	O
how	O
likelihood	B
works	O
if	O
hypodata	O
that	O
means	O
the	O
roll	O
is	O
greater	O
than	O
the	O
number	O
of	O
sides	O
on	O
the	O
die	O
that	O
can	O
t	O
happen	O
so	O
the	O
likelihood	B
is	O
otherwise	O
the	O
question	O
is	O
given	O
that	O
there	O
are	O
hypo	O
sides	O
what	O
is	O
the	O
chance	O
of	O
rolling	O
data	O
the	O
answer	O
is	O
regardless	O
of	O
data	O
here	O
is	O
the	O
statement	O
that	O
does	O
the	O
update	B
i	O
roll	O
a	O
and	O
here	O
is	O
the	O
posterior	B
distribution	B
after	O
we	O
roll	O
a	O
the	O
probability	B
for	O
the	O
die	O
is	O
the	O
most	O
likely	O
alternative	O
is	O
the	O
die	O
but	O
there	O
is	O
still	O
almost	O
a	O
chance	O
for	O
the	O
die	O
what	O
if	O
we	O
roll	O
a	O
few	O
more	O
times	O
and	O
get	O
and	O
for	O
roll	O
in	O
suite	B
updateroll	O
with	O
this	O
data	O
the	O
die	O
is	O
eliminated	O
and	O
the	O
die	O
seems	O
quite	O
likely	O
here	O
are	O
the	O
results	O
now	O
the	O
probability	B
is	O
that	O
we	O
are	O
rolling	O
the	O
die	O
and	O
less	O
than	O
for	O
the	O
die	O
the	O
dice	B
problem	I
is	O
based	O
on	O
an	O
example	O
i	O
saw	O
in	O
sanjoy	O
mahajan	O
s	O
class	O
on	O
bayesian	O
inference	O
you	O
can	O
download	O
the	O
code	O
in	O
this	O
section	O
from	O
http	O
for	O
more	O
information	O
see	O
section	O
the	O
locomotive	B
problem	I
i	O
found	O
the	O
locomotive	B
problem	I
in	O
frederick	O
mosteller	B
s	O
fifty	O
challenging	O
problems	O
in	O
probability	B
with	O
solutions	O
the	O
locomotive	B
problem	I
figure	O
posterior	B
distribution	B
for	O
the	O
locomotive	B
problem	I
based	O
on	O
a	O
uniform	O
prior	B
a	O
railroad	O
numbers	O
its	O
locomotives	O
in	O
order	O
one	O
day	O
you	O
see	O
a	O
locomotive	O
with	O
the	O
number	O
estimate	O
how	O
many	O
locomotives	O
the	O
railroad	O
has	O
based	O
on	O
this	O
observation	O
we	O
know	O
the	O
railroad	O
has	O
or	O
more	O
locomotives	O
but	O
how	O
many	O
more	O
to	O
apply	O
bayesian	O
reasoning	O
we	O
can	O
break	O
this	O
problem	O
into	O
two	O
steps	O
what	O
did	O
we	O
know	O
about	O
n	O
before	O
we	O
saw	O
the	O
data	O
for	O
any	O
given	O
value	O
of	O
n	O
what	O
is	O
the	O
likelihood	B
of	O
seeing	O
the	O
data	O
locomotive	O
with	O
number	O
the	O
answer	O
to	O
the	O
first	O
question	O
is	O
the	O
prior	B
the	O
answer	O
to	O
the	O
second	O
is	O
the	O
likelihood	B
we	O
don	O
t	O
have	O
much	O
basis	O
to	O
choose	O
a	O
prior	B
but	O
we	O
can	O
start	O
with	O
something	O
simple	O
and	O
then	O
consider	O
alternatives	O
let	O
s	O
assume	O
that	O
n	O
is	O
equally	O
likely	O
to	O
be	O
any	O
value	O
from	O
to	O
hypos	O
now	O
all	O
we	O
need	O
is	O
a	O
likelihood	B
function	I
in	O
a	O
hypothetical	O
fleet	O
of	O
n	O
locomotives	O
what	O
is	O
the	O
probability	B
that	O
we	O
would	O
see	O
number	O
if	O
we	O
assume	O
that	O
there	O
is	O
only	O
one	O
train-operating	O
company	O
only	O
one	O
we	O
care	O
about	O
and	O
that	O
we	O
are	O
equally	O
likely	O
to	O
see	O
any	O
of	O
its	O
locomotives	O
then	O
the	O
chance	O
of	O
seeing	O
any	O
particular	O
locomotive	O
is	O
here	O
s	O
the	O
likelihood	B
function	I
of	O
chapter	O
estimation	O
class	O
trainsuite	O
def	O
likelihoodself	O
data	O
hypo	O
if	O
hypo	O
data	O
return	O
else	O
return	O
this	O
might	O
look	O
familiar	O
the	O
likelihood	B
functions	O
for	O
the	O
locomotive	B
problem	I
and	O
the	O
dice	B
problem	I
are	O
identical	O
here	O
s	O
the	O
update	B
suite	B
trainhypos	O
there	O
are	O
too	O
many	O
hypotheses	O
to	O
print	O
so	O
i	O
plotted	O
the	O
results	O
in	O
figure	O
not	O
surprisingly	O
all	O
values	O
of	O
n	O
below	O
have	O
been	O
eliminated	O
the	O
most	O
likely	O
value	O
if	O
you	O
had	O
to	O
guess	O
is	O
that	O
might	O
not	O
seem	O
like	O
a	O
very	O
good	O
guess	O
after	O
all	O
what	O
are	O
the	O
chances	O
that	O
you	O
just	O
happened	O
to	O
see	O
the	O
train	O
with	O
the	O
highest	O
number	O
nevertheless	O
if	O
you	O
want	O
to	O
maximize	O
the	O
chance	O
of	O
getting	O
the	O
answer	O
exactly	O
right	O
you	O
should	O
guess	O
but	O
maybe	O
that	O
s	O
not	O
the	O
right	O
goal	O
an	O
alternative	O
is	O
to	O
compute	O
the	O
mean	O
of	O
the	O
posterior	B
distribution	B
def	O
meansuite	O
total	O
for	O
hypo	O
prob	B
in	O
suite	B
items	O
total	O
hypo	O
prob	B
return	O
total	O
print	O
meansuite	O
or	O
you	O
could	O
use	O
the	O
very	O
similar	O
method	O
provided	O
by	O
pmf	B
print	O
suite	B
mean	O
the	O
mean	O
of	O
the	O
posterior	B
is	O
so	O
that	O
might	O
be	O
a	O
good	O
guess	O
if	O
you	O
wanted	O
to	O
minimize	O
error	B
if	O
you	O
played	O
this	O
guessing	O
game	O
over	O
and	O
over	O
using	O
the	O
mean	O
of	O
the	O
posterior	B
as	O
your	O
estimate	O
would	O
minimize	O
the	O
mean	B
squared	I
error	B
over	O
the	O
long	O
run	O
httpen	O
wikipedia	O
org	O
wikiminimum	O
mean	O
square	O
error	B
you	O
can	O
download	O
this	O
example	O
from	O
httpthinkbayes	O
comtrain	O
py	O
for	O
more	O
information	O
see	O
section	O
what	O
about	O
that	O
prior	B
what	O
about	O
that	O
prior	B
to	O
make	O
any	O
progress	O
on	O
the	O
locomotive	B
problem	I
we	O
had	O
to	O
make	O
assumptions	O
and	O
some	O
of	O
them	O
were	O
pretty	O
arbitrary	O
in	O
particular	O
we	O
chose	O
a	O
uniform	O
prior	B
from	O
to	O
without	O
much	O
justification	O
for	O
choosing	O
or	O
for	O
choosing	O
a	O
uniform	B
distribution	B
it	O
is	O
not	O
crazy	O
to	O
believe	O
that	O
a	O
railroad	O
company	O
might	O
operate	O
locomotives	O
but	O
a	O
reasonable	O
person	O
might	O
guess	O
more	O
or	O
fewer	O
so	O
we	O
might	O
wonder	O
whether	O
the	O
posterior	B
distribution	B
is	O
sensitive	O
to	O
these	O
assumptions	O
with	O
so	O
little	O
data	O
only	O
one	O
observation	O
it	O
probably	O
is	O
recall	O
that	O
with	O
a	O
uniform	O
prior	B
from	O
to	O
the	O
mean	O
of	O
the	O
posterior	B
is	O
with	O
an	O
upper	O
bound	O
of	O
we	O
get	O
a	O
posterior	B
mean	O
of	O
and	O
with	O
an	O
upper	O
bound	O
of	O
the	O
posterior	B
mean	O
is	O
so	O
that	O
s	O
bad	O
there	O
are	O
two	O
ways	O
to	O
proceed	O
get	O
more	O
data	O
get	O
more	O
background	O
information	O
with	O
more	O
data	O
posterior	B
distributions	O
based	O
on	O
different	O
priors	O
tend	O
to	O
converge	O
for	O
example	O
suppose	O
that	O
in	O
addition	O
to	O
train	O
we	O
also	O
see	O
trains	O
and	O
we	O
can	O
update	B
the	O
distribution	B
like	O
this	O
for	O
data	O
in	O
suite	B
updatedata	O
with	O
these	O
data	O
the	O
means	O
of	O
the	O
posteriors	O
are	O
upper	O
posterior	B
bound	O
mean	O
so	O
the	O
differences	O
are	O
smaller	O
an	O
alternative	O
prior	B
if	O
more	O
data	O
are	O
not	O
available	O
another	O
option	O
is	O
to	O
improve	O
the	O
priors	O
by	O
gathering	O
more	O
background	O
information	O
it	O
is	O
probably	O
not	O
reasonable	O
to	O
assume	O
that	O
a	O
train-operating	O
company	O
with	O
locomotives	O
is	O
just	O
as	O
likely	O
as	O
a	O
company	O
with	O
only	O
chapter	O
estimation	O
figure	O
posterior	B
distribution	B
based	O
on	O
a	O
power	B
law	I
prior	B
compared	O
to	O
a	O
uniform	O
prior	B
with	O
some	O
effort	O
we	O
could	O
probably	O
find	O
a	O
list	O
of	O
companies	O
that	O
operate	O
locomotives	O
in	O
the	O
area	O
of	O
observation	O
or	O
we	O
could	O
interview	O
an	O
expert	O
in	O
rail	O
shipping	O
to	O
gather	O
information	O
about	O
the	O
typical	O
size	O
of	O
companies	O
but	O
even	O
without	O
getting	O
into	O
the	O
specifics	O
of	O
railroad	O
economics	O
we	O
can	O
make	O
some	O
educated	O
guesses	O
in	O
most	O
fields	O
there	O
are	O
many	O
small	O
companies	O
fewer	O
medium-sized	O
companies	O
and	O
only	O
one	O
or	O
two	O
very	O
large	O
companies	O
in	O
fact	O
the	O
distribution	B
of	O
company	O
sizes	O
tends	O
to	O
follow	O
a	O
power	B
law	I
as	O
robert	O
axtell	B
reports	O
in	O
science	O
httpwww	O
sciencemag	O
org	O
this	O
law	O
suggests	O
that	O
if	O
there	O
are	O
companies	O
with	O
fewer	O
than	O
locomotives	O
there	O
might	O
be	O
companies	O
with	O
locomotives	O
companies	O
with	O
and	O
possibly	O
one	O
company	O
with	O
locomotives	O
mathematically	O
a	O
power	B
law	I
means	O
that	O
the	O
number	O
of	O
companies	O
with	O
a	O
given	O
size	O
is	O
inversely	O
proportional	O
to	O
size	O
or	O
pmfx	O
x	O
where	O
pmfx	O
is	O
the	O
probability	B
mass	I
function	I
of	O
x	O
and	O
is	O
a	O
parameter	B
that	O
is	O
often	O
near	O
we	O
can	O
construct	O
a	O
power	B
law	I
prior	B
like	O
this	O
class	O
traindice	O
of	O
law	O
credible	O
intervals	O
def	O
hypos	O
pmf	B
init	O
self	O
for	O
hypo	O
in	O
hypos	O
self	O
sethypo	O
hypo-alpha	O
self	O
normalize	B
and	O
here	O
s	O
the	O
code	O
that	O
constructs	O
the	O
prior	B
hypos	O
suite	B
trainhypos	O
again	O
the	O
upper	O
bound	O
is	O
arbitrary	O
but	O
with	O
a	O
power	B
law	I
prior	B
the	O
posterior	B
is	O
less	O
sensitive	O
to	O
this	O
choice	O
figure	O
shows	O
the	O
new	O
posterior	B
based	O
on	O
the	O
power	B
law	I
compared	O
to	O
the	O
posterior	B
based	O
on	O
the	O
uniform	O
prior	B
using	O
the	O
background	O
information	O
represented	O
in	O
the	O
power	B
law	I
prior	B
we	O
can	O
all	O
but	O
eliminate	O
values	O
of	O
n	O
greater	O
than	O
if	O
we	O
start	O
with	O
this	O
prior	B
and	O
observe	O
trains	O
and	O
the	O
means	O
of	O
the	O
posteriors	O
are	O
upper	O
posterior	B
bound	O
mean	O
now	O
the	O
differences	O
are	O
much	O
smaller	O
in	O
fact	O
with	O
an	O
arbitrarily	O
large	O
upper	O
bound	O
the	O
mean	O
converges	O
on	O
so	O
the	O
power	B
law	I
prior	B
is	O
more	O
realistic	O
because	O
it	O
is	O
based	O
on	O
general	O
information	O
about	O
the	O
size	O
of	O
companies	O
and	O
it	O
behaves	O
better	O
in	O
practice	O
you	O
can	O
download	O
the	O
examples	O
in	O
this	O
section	O
from	O
httpthinkbayes	O
for	O
more	O
information	O
see	O
section	O
credible	O
intervals	O
once	O
you	O
have	O
computed	O
a	O
posterior	B
distribution	B
it	O
is	O
often	O
useful	O
to	O
summarize	O
the	O
results	O
with	O
a	O
single	O
point	O
estimate	O
or	O
an	O
interval	O
for	O
point	O
estimates	O
it	O
is	O
common	O
to	O
use	O
the	O
mean	O
median	B
or	O
the	O
value	O
with	O
maximum	B
likelihood	B
chapter	O
estimation	O
for	O
intervals	O
we	O
usually	O
report	O
two	O
values	O
computed	O
so	O
that	O
there	O
is	O
a	O
chance	O
that	O
the	O
unknown	O
value	O
falls	O
between	O
them	O
any	O
other	O
probability	B
these	O
values	O
define	O
a	O
credible	B
interval	I
a	O
simple	O
way	O
to	O
compute	O
a	O
credible	B
interval	I
is	O
to	O
add	O
up	O
the	O
probabilities	O
in	O
the	O
posterior	B
distribution	B
and	O
record	O
the	O
values	O
that	O
correspond	O
to	O
probabilities	O
and	O
in	O
other	O
words	O
the	O
and	O
percentiles	O
thinkbayes	O
provides	O
a	O
function	O
that	O
computes	O
percentiles	O
def	O
percentilepmf	O
percentage	O
p	O
percentage	O
total	O
for	O
val	O
prob	B
in	O
pmf	B
items	O
total	O
prob	B
if	O
total	O
p	O
return	O
val	O
and	O
here	O
s	O
the	O
code	O
that	O
uses	O
it	O
interval	O
percentilesuite	O
percentilesuite	O
print	O
interval	O
for	O
the	O
previous	O
example	O
the	O
locomotive	B
problem	I
with	O
a	O
power	B
law	I
prior	B
and	O
three	O
trains	O
the	O
credible	B
interval	I
is	O
the	O
width	O
of	O
this	O
range	O
suggests	O
correctly	O
that	O
we	O
are	O
still	O
quite	O
uncertain	O
about	O
how	O
many	O
locomotives	O
there	O
are	O
cumulative	O
distribution	B
functions	O
in	O
the	O
previous	O
section	O
we	O
computed	O
percentiles	O
by	O
iterating	O
through	O
the	O
values	O
and	O
probabilities	O
in	O
a	O
pmf	B
if	O
we	O
need	O
to	O
compute	O
more	O
than	O
a	O
few	O
percentiles	O
it	O
is	O
more	O
efficient	O
to	O
use	O
a	O
cumulative	B
distribution	B
function	I
or	O
cdf	B
cdfs	O
and	O
pmfs	O
are	O
equivalent	O
in	O
the	O
sense	O
that	O
they	O
contain	O
the	O
same	O
information	O
about	O
the	O
distribution	B
and	O
you	O
can	O
always	O
convert	O
from	O
one	O
to	O
the	O
other	O
the	O
advantage	O
of	O
the	O
cdf	B
is	O
that	O
you	O
can	O
compute	O
percentiles	O
more	O
efficiently	O
thinkbayes	O
provides	O
a	O
cdf	B
class	O
that	O
represents	O
a	O
cumulative	B
distribution	B
function	I
pmf	B
provides	O
a	O
method	O
that	O
makes	O
the	O
corresponding	O
cdf	B
cdf	B
suite	B
makecdf	O
and	O
cdf	B
provides	O
a	O
function	O
named	O
percentile	B
the	O
german	B
tank	I
problem	I
interval	O
converting	O
from	O
a	O
pmf	B
to	O
a	O
cdf	B
takes	O
time	O
proportional	O
to	O
the	O
number	O
of	O
values	O
lenpmf	O
the	O
cdf	B
stores	O
the	O
values	O
and	O
probabilities	O
in	O
sorted	O
lists	O
so	O
looking	O
up	O
a	O
probability	B
to	O
get	O
the	O
corresponding	O
value	O
takes	O
log	O
time	O
that	O
is	O
time	O
proportional	O
to	O
the	O
logarithm	B
of	O
the	O
number	O
of	O
values	O
looking	O
up	O
a	O
value	O
to	O
get	O
the	O
corresponding	O
probability	B
is	O
also	O
logarithmic	O
so	O
cdfs	O
are	O
efficient	O
for	O
many	O
calculations	O
the	O
examples	O
in	O
this	O
section	O
are	O
in	O
for	O
more	O
information	O
see	O
section	O
the	O
german	B
tank	I
problem	I
during	O
world	O
war	O
ii	O
the	O
economic	O
warfare	O
division	O
of	O
the	O
american	O
embassy	O
in	O
london	O
used	O
statistical	O
analysis	O
to	O
estimate	O
german	O
production	O
of	O
tanks	O
and	O
other	O
the	O
western	O
allies	O
had	O
captured	O
log	O
books	O
inventories	O
and	O
repair	O
records	O
that	O
included	O
chassis	O
and	O
engine	O
serial	O
numbers	O
for	O
individual	O
tanks	O
analysis	O
of	O
these	O
records	O
indicated	O
that	O
serial	O
numbers	O
were	O
allocated	O
by	O
manufacturer	O
and	O
tank	O
type	O
in	O
blocks	O
of	O
numbers	O
that	O
numbers	O
in	O
each	O
block	O
were	O
used	O
sequentially	O
and	O
that	O
not	O
all	O
numbers	O
in	O
each	O
block	O
were	O
used	O
so	O
the	O
problem	O
of	O
estimating	O
german	O
tank	O
production	O
could	O
be	O
reduced	O
within	O
each	O
block	O
of	O
numbers	O
to	O
a	O
form	O
of	O
the	O
locomotive	B
problem	I
based	O
on	O
this	O
insight	O
american	O
and	O
british	O
analysts	O
produced	O
estimates	O
substantially	O
lower	O
than	O
estimates	O
from	O
other	O
forms	O
of	O
intelligence	O
and	O
after	O
the	O
war	O
records	O
indicated	O
that	O
they	O
were	O
substantially	O
more	O
accurate	O
they	O
performed	O
similar	O
analyses	O
for	O
tires	O
trucks	O
rockets	O
and	O
other	O
equipment	O
yielding	O
accurate	O
and	O
actionable	O
economic	O
intelligence	O
the	O
german	B
tank	I
problem	I
is	O
historically	O
interesting	O
it	O
is	O
also	O
a	O
nice	O
example	O
of	O
real-world	O
application	O
of	O
statistical	O
estimation	O
so	O
far	O
many	O
of	O
the	O
examples	O
in	O
this	O
book	O
have	O
been	O
toy	O
problems	O
but	O
it	O
will	O
not	O
be	O
long	O
before	O
we	O
start	O
solving	O
real	O
problems	O
i	O
think	O
it	O
is	O
an	O
advantage	O
of	O
bayesian	O
analysis	O
especially	O
with	O
the	O
computational	O
approach	O
we	O
are	O
taking	O
that	O
it	O
provides	O
such	O
a	O
short	O
path	O
from	O
a	O
basic	O
introduction	O
to	O
the	O
research	O
frontier	O
and	O
brodie	O
an	O
empirical	O
approach	O
to	O
economic	O
intelligence	O
in	O
world	O
war	O
ii	O
journal	O
of	O
the	O
american	O
statistical	O
association	O
vol	O
no	O
discussion	O
chapter	O
estimation	O
among	O
bayesians	O
there	O
are	O
two	O
approaches	O
to	O
choosing	O
prior	B
distributions	O
some	O
recommend	O
choosing	O
the	O
prior	B
that	O
best	O
represents	O
background	O
information	O
about	O
the	O
problem	O
in	O
that	O
case	O
the	O
prior	B
is	O
said	O
to	O
be	O
informative	O
the	O
problem	O
with	O
using	O
an	O
informative	B
prior	B
is	O
that	O
people	O
might	O
use	O
different	O
background	O
information	O
interpret	O
it	O
differently	O
so	O
informative	O
priors	O
often	O
seem	O
subjective	O
the	O
alternative	O
is	O
a	O
so-called	O
uninformative	B
prior	B
which	O
is	O
intended	O
to	O
be	O
as	O
unrestricted	O
as	O
possible	O
in	O
order	O
to	O
let	O
the	O
data	O
speak	O
for	O
themselves	O
in	O
some	O
cases	O
you	O
can	O
identify	O
a	O
unique	O
prior	B
that	O
has	O
some	O
desirable	O
property	O
like	O
representing	O
minimal	O
prior	B
information	O
about	O
the	O
estimated	O
quantity	O
uninformative	O
priors	O
are	O
appealing	O
because	O
they	O
seem	O
more	O
objective	O
but	O
i	O
am	O
generally	O
in	O
favor	O
of	O
using	O
informative	O
priors	O
why	O
first	O
bayesian	O
analysis	O
is	O
always	O
based	O
on	O
modeling	B
decisions	O
choosing	O
the	O
prior	B
is	O
one	O
of	O
those	O
decisions	O
but	O
it	O
is	O
not	O
the	O
only	O
one	O
and	O
it	O
might	O
not	O
even	O
be	O
the	O
most	O
subjective	O
so	O
even	O
if	O
an	O
uninformative	B
prior	B
is	O
more	O
objective	O
the	O
entire	O
analysis	O
is	O
still	O
subjective	O
also	O
for	O
most	O
practical	O
problems	O
you	O
are	O
likely	O
to	O
be	O
in	O
one	O
of	O
two	O
regimes	O
either	O
you	O
have	O
a	O
lot	O
of	O
data	O
or	O
not	O
very	O
much	O
if	O
you	O
have	O
a	O
lot	O
of	O
data	O
the	O
choice	O
of	O
the	O
prior	B
doesn	O
t	O
matter	O
very	O
much	O
informative	O
and	O
uninformative	O
priors	O
yield	O
almost	O
the	O
same	O
results	O
we	O
ll	O
see	O
an	O
example	O
like	O
this	O
in	O
the	O
next	O
chapter	O
but	O
if	O
as	O
in	O
the	O
locomotive	B
problem	I
you	O
don	O
t	O
have	O
much	O
data	O
using	O
relevant	O
background	O
information	O
the	O
power	B
law	I
distribution	B
makes	O
a	O
big	O
difference	O
and	O
if	O
as	O
in	O
the	O
german	B
tank	I
problem	I
you	O
have	O
to	O
make	O
life-and-death	O
decisions	O
based	O
on	O
your	O
results	O
you	O
should	O
probably	O
use	O
all	O
of	O
the	O
information	O
at	O
your	O
disposal	O
rather	O
than	O
maintaining	O
the	O
illusion	O
of	O
objectivity	B
by	O
pretending	O
to	O
know	O
less	O
than	O
you	O
do	O
exercises	O
exercise	O
to	O
write	O
a	O
likelihood	B
function	I
for	O
the	O
locomotive	B
problem	I
we	O
had	O
to	O
answer	O
this	O
question	O
if	O
the	O
railroad	O
has	O
n	O
locomotives	O
what	O
is	O
the	O
probability	B
that	O
we	O
see	O
number	O
exercises	O
the	O
answer	O
depends	O
on	O
what	O
sampling	O
process	B
we	O
use	O
when	O
we	O
observe	O
the	O
locomotive	O
in	O
this	O
chapter	O
i	O
resolved	O
the	O
ambiguity	O
by	O
specifying	O
that	O
there	O
is	O
only	O
one	O
train-operating	O
company	O
only	O
one	O
that	O
we	O
care	O
about	O
but	O
suppose	O
instead	O
that	O
there	O
are	O
many	O
companies	O
with	O
different	O
numbers	O
of	O
trains	O
and	O
suppose	O
that	O
you	O
are	O
equally	O
likely	O
to	O
see	O
any	O
train	O
operated	O
by	O
any	O
company	O
in	O
that	O
case	O
the	O
likelihood	B
function	I
is	O
different	O
because	O
you	O
are	O
more	O
likely	O
to	O
see	O
a	O
train	O
operated	O
by	O
a	O
large	O
company	O
as	O
an	O
exercise	O
implement	O
the	O
likelihood	B
function	I
for	O
this	O
variation	O
of	O
the	O
locomotive	B
problem	I
and	O
compare	O
the	O
results	O
chapter	O
estimation	O
chapter	O
more	O
estimation	O
the	O
euro	B
problem	I
in	O
information	O
theory	O
inference	O
and	O
learning	O
algorithms	O
david	O
mackay	B
poses	O
this	O
problem	O
a	O
statistical	O
statement	O
appeared	O
in	O
the	O
guardian	O
on	O
friday	O
january	O
when	O
spun	O
on	O
edge	O
times	O
a	O
belgian	O
one-euro	O
coin	O
came	O
up	O
heads	O
times	O
and	O
tails	O
it	O
looks	O
very	O
suspicious	O
to	O
me	O
said	O
barry	O
blight	O
a	O
statistics	O
lecturer	O
at	O
the	O
london	O
school	O
of	O
economics	O
if	O
the	O
coin	O
were	O
unbiased	O
the	O
chance	O
of	O
getting	O
a	O
result	O
as	O
extreme	O
as	O
that	O
would	O
be	O
less	O
than	O
but	O
do	O
these	O
data	O
give	O
evidence	O
that	O
the	O
coin	O
is	O
biased	O
rather	O
than	O
fair	O
to	O
answer	O
that	O
question	O
we	O
ll	O
proceed	O
in	O
two	O
steps	O
the	O
first	O
is	O
to	O
estimate	O
the	O
probability	B
that	O
the	O
coin	O
lands	O
face	O
up	O
the	O
second	O
is	O
to	O
evaluate	O
whether	O
the	O
data	O
support	O
the	O
hypothesis	O
that	O
the	O
coin	O
is	O
biased	O
you	O
can	O
download	O
the	O
code	O
in	O
this	O
section	O
from	O
httpthinkbayes	O
com	O
euro	O
py	O
for	O
more	O
information	O
see	O
section	O
any	O
given	O
coin	O
has	O
some	O
probability	B
x	O
of	O
landing	O
heads	O
up	O
when	O
spun	O
on	O
edge	O
it	O
seems	O
reasonable	O
to	O
believe	O
that	O
the	O
value	O
of	O
x	O
depends	O
on	O
some	O
physical	O
characteristics	O
of	O
the	O
coin	O
primarily	O
the	O
distribution	B
of	O
weight	O
chapter	O
more	O
estimation	O
figure	O
posterior	B
distribution	B
for	O
the	O
euro	B
problem	I
on	O
a	O
uniform	O
prior	B
if	O
a	O
coin	O
is	O
perfectly	O
balanced	O
we	O
expect	O
x	O
to	O
be	O
close	O
to	O
but	O
for	O
a	O
lopsided	O
coin	O
x	O
might	O
be	O
substantially	O
different	O
we	O
can	O
use	O
bayes	O
s	O
theorem	O
and	O
the	O
observed	O
data	O
to	O
estimate	O
x	O
let	O
s	O
define	O
hypotheses	O
where	O
hx	O
is	O
the	O
hypothesis	O
that	O
the	O
probability	B
of	O
heads	O
is	O
x	O
for	O
values	O
from	O
to	O
i	O
ll	O
start	O
with	O
a	O
uniform	O
prior	B
where	O
the	O
probability	B
of	O
hx	O
is	O
the	O
same	O
for	O
all	O
x	O
we	O
ll	O
come	O
back	O
later	O
to	O
consider	O
other	O
priors	O
the	O
likelihood	B
function	I
is	O
relatively	O
easy	O
if	O
hx	O
is	O
true	O
the	O
probability	B
of	O
heads	O
is	O
and	O
the	O
probability	B
of	O
tails	O
is	O
class	O
eurosuite	O
def	O
likelihoodself	O
data	O
hypo	O
x	O
hypo	O
if	O
data	O
return	O
else	O
return	O
here	O
s	O
the	O
code	O
that	O
makes	O
the	O
suite	B
and	O
updates	O
it	O
suite	B
dataset	O
for	O
data	O
in	O
dataset	O
suite	B
updatedata	O
the	O
result	O
is	O
in	O
figure	O
summarizing	O
the	O
posterior	B
summarizing	O
the	O
posterior	B
again	O
there	O
are	O
several	O
ways	O
to	O
summarize	O
the	O
posterior	B
distribution	B
one	O
option	O
is	O
to	O
find	O
the	O
most	O
likely	O
value	O
in	O
the	O
posterior	B
distribution	B
thinkbayes	O
provides	O
a	O
function	O
that	O
does	O
that	O
def	O
maximumlikelihoodpmf	O
the	O
value	O
with	O
the	O
highest	O
probability	B
prob	B
val	O
maxprob	O
val	O
for	O
val	O
prob	B
in	O
pmf	B
items	O
return	O
val	O
in	O
this	O
case	O
the	O
result	O
is	O
which	O
is	O
also	O
the	O
observed	O
percentage	O
of	O
heads	O
so	O
that	O
suggests	O
that	O
the	O
observed	O
percentage	O
is	O
the	O
maximum	B
likelihood	B
estimator	O
for	O
the	O
population	O
we	O
might	O
also	O
summarize	O
the	O
posterior	B
by	O
computing	O
the	O
mean	O
and	O
median	B
print	O
suite	B
mean	O
print	O
thinkbayes	O
percentilesuite	O
the	O
mean	O
is	O
the	O
median	B
is	O
finally	O
we	O
can	O
compute	O
a	O
credible	B
interval	I
print	O
thinkbayes	O
credibleintervalsuite	O
the	O
result	O
is	O
now	O
getting	O
back	O
to	O
the	O
original	O
question	O
we	O
would	O
like	O
to	O
know	O
whether	O
the	O
coin	O
is	O
fair	O
we	O
observe	O
that	O
the	O
posterior	B
credible	B
interval	I
does	O
not	O
include	O
which	O
suggests	O
that	O
the	O
coin	O
is	O
not	O
fair	O
but	O
that	O
is	O
not	O
exactly	O
the	O
question	O
we	O
started	O
with	O
mackay	B
asked	O
do	O
these	O
data	O
give	O
evidence	O
that	O
the	O
coin	O
is	O
biased	O
rather	O
than	O
fair	O
to	O
answer	O
that	O
question	O
we	O
will	O
have	O
to	O
be	O
more	O
precise	O
about	O
what	O
it	O
means	O
to	O
say	O
that	O
data	O
constitute	O
evidence	O
for	O
a	O
hypothesis	O
and	O
that	O
is	O
the	O
subject	O
of	O
the	O
next	O
chapter	O
but	O
before	O
we	O
go	O
on	O
i	O
want	O
to	O
address	O
one	O
possible	O
source	O
of	O
confusion	O
since	O
we	O
want	O
to	O
know	O
whether	O
the	O
coin	O
is	O
fair	O
it	O
might	O
be	O
tempting	O
to	O
ask	O
for	O
the	O
probability	B
that	O
x	O
is	O
print	O
the	O
result	O
is	O
but	O
that	O
value	O
is	O
almost	O
meaningless	O
the	O
decision	O
to	O
evaluate	O
hypotheses	O
was	O
arbitrary	O
we	O
could	O
have	O
divided	O
the	O
range	O
into	O
more	O
or	O
fewer	O
pieces	O
and	O
if	O
we	O
had	O
the	O
probability	B
for	O
any	O
given	O
hypothesis	O
would	O
be	O
greater	O
or	O
less	O
chapter	O
more	O
estimation	O
figure	O
uniform	O
and	O
triangular	O
priors	O
for	O
the	O
euro	B
problem	I
swamping	B
the	I
priors	I
we	O
started	O
with	O
a	O
uniform	O
prior	B
but	O
that	O
might	O
not	O
be	O
a	O
good	O
choice	O
i	O
can	O
believe	O
that	O
if	O
a	O
coin	O
is	O
lopsided	O
x	O
might	O
deviate	O
substantially	O
from	O
but	O
it	O
seems	O
unlikely	O
that	O
the	O
belgian	O
euro	O
coin	O
is	O
so	O
imbalanced	O
that	O
x	O
is	O
or	O
it	O
might	O
be	O
more	O
reasonable	O
to	O
choose	O
a	O
prior	B
that	O
gives	O
higher	O
probability	B
to	O
values	O
of	O
x	O
near	O
and	O
lower	O
probability	B
to	O
extreme	O
values	O
as	O
an	O
example	O
i	O
constructed	O
a	O
triangular	O
prior	B
shown	O
in	O
figure	O
here	O
s	O
the	O
code	O
that	O
constructs	O
the	O
prior	B
def	O
triangleprior	O
suite	B
euro	O
for	O
x	O
in	O
suite	B
setx	O
x	O
for	O
x	O
in	O
suite	B
setx	O
suite	B
normalize	B
figure	O
shows	O
the	O
result	O
the	O
uniform	O
prior	B
for	O
comparison	O
updating	O
this	O
prior	B
with	O
the	O
same	O
dataset	O
yields	O
the	O
posterior	B
distribution	B
shown	O
in	O
figure	O
even	O
with	O
substantially	O
different	O
priors	O
the	O
posterior	B
distributions	O
are	O
very	O
similar	O
the	O
medians	O
and	O
the	O
credible	O
intervals	O
are	O
identical	O
the	O
means	O
differ	O
by	O
less	O
than	O
this	O
is	O
an	O
example	O
of	O
swamping	B
the	I
priors	I
with	O
enough	O
data	O
people	O
who	O
start	O
with	O
different	O
priors	O
will	O
tend	O
to	O
converge	O
on	O
the	O
same	O
posterior	B
optimization	B
figure	O
posterior	B
distributions	O
for	O
the	O
euro	B
problem	I
optimization	B
the	O
code	O
i	O
have	O
shown	O
so	O
far	O
is	O
meant	O
to	O
be	O
easy	O
to	O
read	O
but	O
it	O
is	O
not	O
very	O
efficient	O
in	O
general	O
i	O
like	O
to	O
develop	O
code	O
that	O
is	O
demonstrably	O
correct	O
then	O
check	O
whether	O
it	O
is	O
fast	O
enough	O
for	O
my	O
purposes	O
if	O
so	O
there	O
is	O
no	O
need	O
to	O
optimize	O
for	O
this	O
example	O
if	O
we	O
care	O
about	O
run	O
time	O
there	O
are	O
several	O
ways	O
we	O
can	O
speed	O
it	O
up	O
the	O
first	O
opportunity	O
is	O
to	O
reduce	O
the	O
number	O
of	O
times	O
we	O
normalize	B
the	O
suite	B
in	O
the	O
original	O
code	O
we	O
call	O
update	B
once	O
for	O
each	O
spin	O
dataset	O
heads	O
tails	O
for	O
data	O
in	O
dataset	O
suite	B
updatedata	O
and	O
here	O
s	O
what	O
update	B
looks	O
like	O
def	O
updateself	O
data	O
for	O
hypo	O
in	O
self	O
values	O
like	O
self	O
likelihooddata	O
hypo	O
self	O
multhypo	O
like	O
return	O
self	O
normalize	B
each	O
update	B
iterates	O
through	O
the	O
hypotheses	O
then	O
calls	O
normalize	B
which	O
iterates	O
through	O
the	O
hypotheses	O
again	O
we	O
can	O
save	O
some	O
time	O
by	O
doing	O
all	O
of	O
the	O
updates	O
before	O
normalizing	O
suite	B
provides	O
a	O
method	O
called	O
updateset	O
that	O
does	O
exactly	O
that	O
here	O
it	O
is	O
chapter	O
more	O
estimation	O
def	O
updatesetself	O
dataset	O
for	O
data	O
in	O
dataset	O
for	O
hypo	O
in	O
self	O
values	O
like	O
self	O
likelihooddata	O
hypo	O
self	O
multhypo	O
like	O
return	O
self	O
normalize	B
and	O
here	O
s	O
how	O
we	O
can	O
invoke	O
it	O
dataset	O
heads	O
tails	O
suite	B
updatesetdataset	O
this	O
optimization	B
speeds	O
things	O
up	O
but	O
the	O
run	O
time	O
is	O
still	O
proportional	O
to	O
the	O
amount	O
of	O
data	O
we	O
can	O
speed	O
things	O
up	O
even	O
more	O
by	O
rewriting	O
likelihood	B
to	O
process	B
the	O
entire	O
dataset	O
rather	O
than	O
one	O
spin	O
at	O
a	O
time	O
in	O
the	O
original	O
version	O
data	O
is	O
a	O
string	O
that	O
encodes	O
either	O
heads	O
or	O
tails	O
def	O
likelihoodself	O
data	O
hypo	O
x	O
hypo	O
if	O
data	O
return	O
x	O
else	O
return	O
as	O
an	O
alternative	O
we	O
could	O
encode	O
the	O
dataset	O
as	O
a	O
tuple	B
of	O
two	O
integers	O
the	O
number	O
of	O
heads	O
and	O
tails	O
in	O
that	O
case	O
likelihood	B
looks	O
like	O
this	O
def	O
likelihoodself	O
data	O
hypo	O
x	O
hypo	O
heads	O
tails	O
data	O
like	O
xheads	O
return	O
like	O
and	O
then	O
we	O
can	O
call	O
update	B
like	O
this	O
heads	O
tails	O
suite	B
updateheads	O
tails	O
since	O
we	O
have	O
replaced	O
repeated	O
multiplication	O
with	O
exponentiation	B
this	O
version	O
takes	O
the	O
same	O
time	O
for	O
any	O
number	O
of	O
spins	O
the	O
beta	B
distribution	B
there	O
is	O
one	O
more	O
optimization	B
that	O
solves	O
this	O
problem	O
even	O
faster	O
the	O
beta	B
distribution	B
so	O
far	O
we	O
have	O
used	O
a	O
pmf	B
object	O
to	O
represent	O
a	O
discrete	O
set	O
of	O
values	O
for	O
x	O
now	O
we	O
will	O
use	O
a	O
continuous	B
distribution	B
specifically	O
the	O
beta	B
distribution	B
httpen	O
wikipedia	O
orgwikibeta	O
distribution	B
the	O
beta	B
distribution	B
is	O
defined	O
on	O
the	O
interval	O
from	O
to	O
both	O
so	O
it	O
is	O
a	O
natural	O
choice	O
for	O
describing	O
proportions	O
and	O
probabilities	O
but	O
wait	O
it	O
gets	O
better	O
it	O
turns	O
out	O
that	O
if	O
you	O
do	O
a	O
bayesian	O
update	B
with	O
a	O
binomial	B
likelihood	B
function	I
which	O
is	O
what	O
we	O
did	O
in	O
the	O
previous	O
section	O
the	O
beta	B
distribution	B
is	O
a	O
conjugate	B
prior	B
that	O
means	O
that	O
if	O
the	O
prior	B
distribution	B
for	O
x	O
is	O
a	O
beta	B
distribution	B
the	O
posterior	B
is	O
also	O
a	O
beta	B
distribution	B
but	O
wait	O
it	O
gets	O
even	O
better	O
the	O
shape	O
of	O
the	O
beta	B
distribution	B
depends	O
on	O
two	O
parameters	O
written	O
and	O
or	O
alpha	O
and	O
beta	O
if	O
the	O
prior	B
is	O
a	O
beta	B
distribution	B
with	O
parameters	O
alpha	O
and	O
beta	O
and	O
we	O
see	O
data	O
with	O
h	O
heads	O
and	O
t	O
tails	O
the	O
posterior	B
is	O
a	O
beta	B
distribution	B
with	O
parameters	O
alphah	O
and	O
betat	O
in	O
other	O
words	O
we	O
can	O
do	O
an	O
update	B
with	O
two	O
additions	O
so	O
that	O
s	O
great	O
but	O
it	O
only	O
works	O
if	O
we	O
can	O
find	O
a	O
beta	B
distribution	B
that	O
is	O
a	O
good	O
choice	O
for	O
a	O
prior	B
fortunately	O
for	O
many	O
realistic	O
priors	O
there	O
is	O
a	O
beta	B
distribution	B
that	O
is	O
at	O
least	O
a	O
good	O
approximation	O
and	O
for	O
a	O
uniform	O
prior	B
there	O
is	O
a	O
perfect	O
match	O
the	O
beta	B
distribution	B
with	O
and	O
is	O
uniform	O
from	O
to	O
let	O
s	O
see	O
how	O
we	O
can	O
take	O
advantage	O
of	O
all	O
this	O
thinkbayes	O
py	O
provides	O
a	O
class	O
that	O
represents	O
a	O
beta	B
distribution	B
class	O
betaobject	O
def	O
self	O
alpha	O
alpha	O
self	O
beta	O
beta	O
by	O
default	O
makes	O
a	O
uniform	B
distribution	B
update	B
performs	O
a	O
bayesian	O
update	B
def	O
updateself	O
data	O
heads	O
tails	O
data	O
self	O
alpha	O
heads	O
self	O
beta	O
tails	O
data	O
is	O
a	O
pair	O
of	O
integers	O
representing	O
the	O
number	O
of	O
heads	O
and	O
tails	O
so	O
we	O
have	O
yet	O
another	O
way	O
to	O
solve	O
the	O
euro	B
problem	I
chapter	O
more	O
estimation	O
beta	O
thinkbayes	O
beta	O
print	O
beta	O
mean	O
beta	O
provides	O
mean	O
which	O
computes	O
a	O
simple	O
function	O
of	O
alpha	O
and	O
beta	O
def	O
meanself	O
return	O
floatself	O
alpha	O
self	O
beta	O
for	O
the	O
euro	B
problem	I
the	O
posterior	B
mean	O
is	O
which	O
is	O
the	O
same	O
result	O
we	O
got	O
using	O
pmfs	O
beta	O
also	O
provides	O
evalpdf	O
which	O
evaluates	O
the	O
probability	B
density	B
function	I
of	O
the	O
beta	B
distribution	B
def	O
evalpdfself	O
x	O
return	O
finally	O
beta	O
provides	O
makepmf	O
which	O
uses	O
evalpdf	O
to	O
generate	O
a	O
discrete	O
approximation	O
of	O
the	O
beta	B
distribution	B
discussion	O
in	O
this	O
chapter	O
we	O
solved	O
the	O
same	O
problem	O
with	O
two	O
different	O
priors	O
and	O
found	O
that	O
with	O
a	O
large	O
dataset	O
the	O
priors	O
get	O
swamped	O
if	O
two	O
people	O
start	O
with	O
different	O
prior	B
beliefs	O
they	O
generally	O
find	O
as	O
they	O
see	O
more	O
data	O
that	O
their	O
posterior	B
distributions	O
converge	O
at	O
some	O
point	O
the	O
difference	O
between	O
their	O
distributions	O
is	O
small	O
enough	O
that	O
it	O
has	O
no	O
practical	O
effect	O
when	O
this	O
happens	O
it	O
relieves	O
some	O
of	O
the	O
worry	O
about	O
objectivity	B
that	O
i	O
discussed	O
in	O
the	O
previous	O
chapter	O
and	O
for	O
many	O
real-world	O
problems	O
even	O
stark	O
prior	B
beliefs	O
can	O
eventually	O
be	O
reconciled	O
by	O
data	O
but	O
that	O
is	O
not	O
always	O
the	O
case	O
first	O
remember	O
that	O
all	O
bayesian	O
analysis	O
is	O
based	O
on	O
modeling	B
decisions	O
if	O
you	O
and	O
i	O
do	O
not	O
choose	O
the	O
same	O
model	O
we	O
might	O
interpret	O
data	O
differently	O
so	O
even	O
with	O
the	O
same	O
data	O
we	O
would	O
compute	O
different	O
likelihoods	O
and	O
our	O
posterior	B
beliefs	O
might	O
not	O
converge	O
also	O
notice	O
that	O
in	O
a	O
bayesian	O
update	B
we	O
multiply	O
each	O
prior	B
probability	B
by	O
a	O
likelihood	B
so	O
if	O
ph	O
is	O
phd	O
is	O
also	O
regardless	O
of	O
d	O
in	O
the	O
euro	B
problem	I
if	O
you	O
are	O
convinced	O
that	O
x	O
is	O
less	O
than	O
and	O
you	O
assign	O
probability	B
to	O
all	O
other	O
hypotheses	O
no	O
amount	O
of	O
data	O
will	O
convince	O
you	O
otherwise	O
exercises	O
this	O
observation	O
is	O
the	O
basis	O
of	O
cromwell	B
s	O
rule	O
which	O
is	O
the	O
recommendation	O
that	O
you	O
should	O
avoid	O
giving	O
a	O
prior	B
probability	B
of	O
to	O
any	O
hypothesis	O
that	O
is	O
even	O
remotely	O
possible	O
httpen	O
wikipedia	O
orgwiki	O
cromwells	O
rule	O
cromwell	B
s	O
rule	O
is	O
named	O
after	O
oliver	O
cromwell	B
who	O
wrote	O
i	O
beseech	O
you	O
in	O
the	O
bowels	O
of	O
christ	O
think	O
it	O
possible	O
that	O
you	O
may	O
be	O
mistaken	O
for	O
bayesians	O
this	O
turns	O
out	O
to	O
be	O
good	O
advice	O
if	O
it	O
s	O
a	O
little	O
overwrought	O
exercises	O
exercise	O
suppose	O
that	O
instead	O
of	O
observing	O
coin	O
tosses	O
directly	O
you	O
measure	O
the	O
outcome	O
using	O
an	O
instrument	O
that	O
is	O
not	O
always	O
correct	O
specifically	O
suppose	O
there	O
is	O
a	O
probability	B
y	O
that	O
an	O
actual	O
heads	O
is	O
reported	O
as	O
tails	O
or	O
actual	O
tails	O
reported	O
as	O
heads	O
write	O
a	O
class	O
that	O
estimates	O
the	O
bias	O
of	O
a	O
coin	O
given	O
a	O
series	O
of	O
outcomes	O
and	O
the	O
value	O
of	O
y	O
how	O
does	O
the	O
spread	O
of	O
the	O
posterior	B
distribution	B
depend	O
on	O
y	O
exercise	O
this	O
exercise	O
is	O
inspired	O
by	O
a	O
question	O
posted	O
by	O
a	O
redditor	O
named	O
dominosci	O
on	O
reddit	B
s	O
statistics	O
subreddit	O
at	O
http	O
reddit	B
com	O
r	O
statistics	O
reddit	B
is	O
an	O
online	O
forum	O
with	O
many	O
interest	O
groups	O
called	O
subreddits	O
users	O
called	O
redditors	O
post	O
links	O
to	O
online	O
content	O
and	O
other	O
web	O
pages	O
other	O
redditors	O
vote	O
on	O
the	O
links	O
giving	O
an	O
upvote	O
to	O
high-quality	O
links	O
and	O
a	O
downvote	O
to	O
links	O
that	O
are	O
bad	O
or	O
irrelevant	O
a	O
problem	O
identified	O
by	O
dominosci	O
is	O
that	O
some	O
redditors	O
are	O
more	O
reliable	O
than	O
others	O
and	O
reddit	B
does	O
not	O
take	O
this	O
into	O
account	O
the	O
challenge	O
is	O
to	O
devise	O
a	O
system	B
so	O
that	O
when	O
a	O
redditor	O
casts	O
a	O
vote	O
the	O
estimated	O
quality	O
of	O
the	O
link	O
is	O
updated	O
in	O
accordance	O
with	O
the	O
reliability	O
of	O
the	O
redditor	O
and	O
the	O
estimated	O
reliability	O
of	O
the	O
redditor	O
is	O
updated	O
in	O
accordance	O
with	O
the	O
quality	O
of	O
the	O
link	O
one	O
approach	O
is	O
to	O
model	O
the	O
quality	O
of	O
the	O
link	O
as	O
the	O
probability	B
of	O
garnering	O
an	O
upvote	O
and	O
to	O
model	O
the	O
reliability	O
of	O
the	O
redditor	O
as	O
the	O
probability	B
of	O
correctly	O
giving	O
an	O
upvote	O
to	O
a	O
high-quality	O
item	O
write	O
class	O
definitions	O
for	O
redditors	O
and	O
links	O
and	O
an	O
update	B
function	O
that	O
updates	O
both	O
objects	O
whenever	O
a	O
redditor	O
casts	O
a	O
vote	O
chapter	O
more	O
estimation	O
chapter	O
odds	B
and	O
addends	O
odds	B
one	O
way	O
to	O
represent	O
a	O
probability	B
is	O
with	O
a	O
number	O
between	O
and	O
but	O
that	O
s	O
not	O
the	O
only	O
way	O
if	O
you	O
have	O
ever	O
bet	O
on	O
a	O
football	O
game	O
or	O
a	O
horse	O
race	O
you	O
have	O
probably	O
encountered	O
another	O
representation	O
of	O
probability	B
called	O
odds	B
you	O
might	O
have	O
heard	O
expressions	O
like	O
the	O
odds	B
are	O
three	O
to	O
one	O
but	O
you	O
might	O
not	O
know	O
what	O
that	O
means	O
the	O
odds	B
in	O
favor	O
of	O
an	O
event	O
are	O
the	O
ratio	O
of	O
the	O
probability	B
it	O
will	O
occur	O
to	O
the	O
probability	B
that	O
it	O
will	O
not	O
so	O
if	O
i	O
think	O
my	O
team	O
has	O
a	O
chance	O
of	O
winning	O
i	O
would	O
say	O
that	O
the	O
odds	B
in	O
their	O
favor	O
are	O
three	O
to	O
one	O
because	O
the	O
chance	O
of	O
winning	O
is	O
three	O
times	O
the	O
chance	O
of	O
losing	O
you	O
can	O
write	O
odds	B
in	O
decimal	O
form	O
but	O
it	O
is	O
most	O
common	O
to	O
write	O
them	O
as	O
a	O
ratio	O
of	O
integers	O
so	O
three	O
to	O
one	O
is	O
written	O
when	O
probabilities	O
are	O
low	O
it	O
is	O
more	O
common	O
to	O
report	O
the	O
odds	B
against	O
rather	O
than	O
the	O
odds	B
in	O
favor	O
for	O
example	O
if	O
i	O
think	O
my	O
horse	O
has	O
a	O
chance	O
of	O
winning	O
i	O
would	O
say	O
that	O
the	O
odds	B
against	O
are	O
probabilities	O
and	O
odds	B
are	O
different	O
representations	O
of	O
the	O
same	O
information	O
given	O
a	O
probability	B
you	O
can	O
compute	O
the	O
odds	B
like	O
this	O
def	O
oddsp	O
return	O
p	O
given	O
the	O
odds	B
in	O
favor	O
in	O
decimal	O
form	O
you	O
can	O
convert	O
to	O
probability	B
like	O
this	O
chapter	O
odds	B
and	O
addends	O
def	O
probabilityo	O
return	O
o	O
if	O
you	O
represent	O
odds	B
with	O
a	O
numerator	O
and	O
denominator	O
you	O
can	O
convert	O
to	O
probability	B
like	O
this	O
def	O
no	O
return	O
yes	O
no	O
when	O
i	O
work	O
with	O
odds	B
in	O
my	O
head	O
i	O
find	O
it	O
helpful	O
to	O
picture	O
people	O
at	O
the	O
track	O
if	O
of	O
them	O
think	O
my	O
horse	O
will	O
win	O
then	O
of	O
them	O
don	O
t	O
so	O
the	O
odds	B
in	O
favor	O
are	O
or	O
if	O
the	O
odds	B
are	O
against	O
my	O
horse	O
then	O
five	O
out	O
of	O
six	O
people	O
think	O
she	O
will	O
lose	O
so	O
the	O
probability	B
of	O
winning	O
is	O
the	O
odds	B
form	I
of	O
bayes	O
s	O
theorem	O
in	O
chapter	O
i	O
wrote	O
bayes	O
s	O
theorem	O
in	O
the	O
probability	B
form	O
phd	O
ph	O
pdh	O
pd	O
if	O
we	O
have	O
two	O
hypotheses	O
a	O
and	O
b	O
we	O
can	O
write	O
the	O
ratio	O
of	O
posterior	B
probabilities	O
like	O
this	O
pad	O
pbd	O
pa	O
pda	O
pb	O
pdb	O
notice	O
that	O
the	O
normalizing	B
constant	I
pd	O
drops	O
out	O
of	O
this	O
equation	O
if	O
a	O
and	O
b	O
are	O
mutually	B
exclusive	I
and	O
collectively	B
exhaustive	I
that	O
means	O
pb	O
pa	O
so	O
we	O
can	O
rewrite	O
the	O
ratio	O
of	O
the	O
priors	O
and	O
the	O
ratio	O
of	O
the	O
posteriors	O
as	O
odds	B
writing	O
oa	O
for	O
odds	B
in	O
favor	O
of	O
a	O
we	O
get	O
oad	O
oa	O
pda	O
pdb	O
in	O
words	O
this	O
says	O
that	O
the	O
posterior	B
odds	B
are	O
the	O
prior	B
odds	B
times	O
the	O
likelihood	B
ratio	I
this	O
is	O
the	O
odds	B
form	I
of	O
bayes	O
s	O
theorem	O
this	O
form	O
is	O
most	O
convenient	O
for	O
computing	O
a	O
bayesian	O
update	B
on	O
paper	O
or	O
in	O
your	O
head	O
for	O
example	O
let	O
s	O
go	O
back	O
to	O
the	O
cookie	B
problem	I
oliver	O
s	O
blood	O
suppose	O
there	O
are	O
two	O
bowls	O
of	O
cookies	O
bowl	O
contains	O
vanilla	O
cookies	O
and	O
chocolate	O
cookies	O
bowl	O
contains	O
of	O
each	O
now	O
suppose	O
you	O
choose	O
one	O
of	O
the	O
bowls	O
at	O
random	O
and	O
without	O
looking	O
select	O
a	O
cookie	O
at	O
random	O
the	O
cookie	O
is	O
vanilla	O
what	O
is	O
the	O
probability	B
that	O
it	O
came	O
from	O
bowl	O
the	O
prior	B
probability	B
is	O
so	O
the	O
prior	B
odds	B
are	O
or	O
just	O
the	O
hood	O
ratio	O
is	O
or	O
so	O
the	O
posterior	B
odds	B
are	O
which	O
corresponds	O
to	O
probability	B
oliver	O
s	O
blood	O
here	O
is	O
another	O
problem	O
from	O
mackay	B
s	O
information	O
theory	O
inference	O
and	O
learning	O
algorithms	O
two	O
people	O
have	O
left	O
traces	O
of	O
their	O
own	O
blood	O
at	O
the	O
scene	O
of	O
a	O
crime	O
a	O
suspect	O
oliver	O
is	O
tested	O
and	O
found	O
to	O
have	O
type	O
o	O
blood	O
the	O
blood	O
groups	O
of	O
the	O
two	O
traces	O
are	O
found	O
to	O
be	O
of	O
type	O
o	O
common	O
type	O
in	O
the	O
local	O
population	O
having	O
frequency	O
and	O
of	O
type	O
ab	O
rare	O
type	O
with	O
frequency	O
do	O
these	O
data	O
traces	O
found	O
at	O
the	O
scene	O
give	O
evidence	O
in	O
favor	O
of	O
the	O
proposition	O
that	O
oliver	O
was	O
one	O
of	O
the	O
people	O
left	O
blood	O
at	O
the	O
scene	O
to	O
answer	O
this	O
question	O
we	O
need	O
to	O
think	O
about	O
what	O
it	O
means	O
for	O
data	O
to	O
give	O
evidence	O
in	O
favor	O
of	O
against	O
a	O
hypothesis	O
intuitively	O
we	O
might	O
say	O
that	O
data	O
favor	O
a	O
hypothesis	O
if	O
the	O
hypothesis	O
is	O
more	O
likely	O
in	O
light	O
of	O
the	O
data	O
than	O
it	O
was	O
before	O
in	O
the	O
cookie	B
problem	I
the	O
prior	B
odds	B
are	O
or	O
probability	B
the	O
posterior	B
odds	B
are	O
or	O
probability	B
so	O
we	O
could	O
say	O
that	O
the	O
vanilla	O
cookie	O
is	O
evidence	O
in	O
favor	O
of	O
bowl	O
the	O
odds	B
form	I
of	O
bayes	O
s	O
theorem	O
provides	O
a	O
way	O
to	O
make	O
this	O
intuition	B
more	O
precise	O
again	O
oad	O
oa	O
pda	O
pdb	O
or	O
dividing	O
through	O
by	O
oa	O
oad	O
oa	O
pda	O
pdb	O
chapter	O
odds	B
and	O
addends	O
the	O
term	O
on	O
the	O
left	O
is	O
the	O
ratio	O
of	O
the	O
posterior	B
and	O
prior	B
odds	B
the	O
term	O
on	O
the	O
right	O
is	O
the	O
likelihood	B
ratio	I
also	O
called	O
the	O
bayes	B
factor	I
if	O
the	O
bayes	B
factor	I
value	O
is	O
greater	O
than	O
that	O
means	O
that	O
the	O
data	O
were	O
more	O
likely	O
under	O
a	O
than	O
under	O
b	O
and	O
since	O
the	O
odds	B
ratio	O
is	O
also	O
greater	O
than	O
that	O
means	O
that	O
the	O
odds	B
are	O
greater	O
in	O
light	O
of	O
the	O
data	O
than	O
they	O
were	O
before	O
if	O
the	O
bayes	B
factor	I
is	O
less	O
than	O
that	O
means	O
the	O
data	O
were	O
less	O
likely	O
under	O
a	O
than	O
under	O
b	O
so	O
the	O
odds	B
in	O
favor	O
of	O
a	O
go	O
down	O
finally	O
if	O
the	O
bayes	B
factor	I
is	O
exactly	O
the	O
data	O
are	O
equally	O
likely	O
under	O
either	O
hypothesis	O
so	O
the	O
odds	B
do	O
not	O
change	O
if	O
oliver	O
is	O
one	O
of	O
now	O
we	O
can	O
get	O
back	O
to	O
the	O
oliver	O
s	O
blood	O
problem	O
the	O
people	O
who	O
left	O
blood	O
at	O
the	O
crime	O
scene	O
then	O
he	O
accounts	O
for	O
the	O
o	O
sample	O
so	O
the	O
probability	B
of	O
the	O
data	O
is	O
just	O
the	O
probability	B
that	O
a	O
random	O
member	O
of	O
the	O
population	O
has	O
type	O
ab	O
blood	O
which	O
is	O
if	O
oliver	O
did	O
not	O
leave	O
blood	O
at	O
the	O
scene	O
then	O
we	O
have	O
two	O
samples	O
to	O
account	O
for	O
if	O
we	O
choose	O
two	O
random	O
people	O
from	O
the	O
population	O
what	O
is	O
the	O
chance	O
of	O
finding	O
one	O
with	O
type	O
o	O
and	O
one	O
with	O
type	O
ab	O
well	O
there	O
are	O
two	O
ways	O
it	O
might	O
happen	O
the	O
first	O
person	O
we	O
choose	O
might	O
have	O
type	O
o	O
and	O
the	O
second	O
ab	O
or	O
the	O
other	O
way	O
around	O
so	O
the	O
total	B
probability	B
is	O
the	O
likelihood	B
of	O
the	O
data	O
is	O
slightly	O
higher	O
if	O
oliver	O
is	O
not	O
one	O
of	O
the	O
people	O
who	O
left	O
blood	O
at	O
the	O
scene	O
so	O
the	O
blood	O
data	O
is	O
actually	O
evidence	O
against	O
oliver	O
s	O
guilt	O
this	O
example	O
is	O
a	O
little	O
contrived	O
but	O
it	O
is	O
an	O
example	O
of	O
the	O
counterintuitive	O
result	O
that	O
data	O
consistent	O
with	O
a	O
hypothesis	O
are	O
not	O
necessarily	O
in	O
favor	O
of	O
the	O
hypothesis	O
if	O
this	O
result	O
is	O
so	O
counterintuitive	O
that	O
it	O
bothers	O
you	O
this	O
way	O
of	O
thinking	O
might	O
help	O
the	O
data	O
consist	O
of	O
a	O
common	O
event	O
type	O
o	O
blood	O
and	O
a	O
rare	O
event	O
type	O
ab	O
blood	O
if	O
oliver	O
accounts	O
for	O
the	O
common	O
event	O
that	O
leaves	O
the	O
rare	O
event	O
still	O
unexplained	O
if	O
oliver	O
doesn	O
t	O
account	O
for	O
the	O
o	O
blood	O
then	O
we	O
have	O
two	O
chances	O
to	O
find	O
someone	O
in	O
the	O
population	O
with	O
ab	O
blood	O
and	O
that	O
factor	O
of	O
two	O
makes	O
the	O
difference	O
addends	O
the	O
fundamental	O
operation	O
of	O
bayesian	O
statistics	O
is	O
update	B
which	O
takes	O
a	O
prior	B
distribution	B
and	O
a	O
set	O
of	O
data	O
and	O
produces	O
a	O
posterior	B
distribution	B
addends	O
but	O
solving	O
real	O
problems	O
usually	O
involves	O
a	O
number	O
of	O
other	O
operations	B
including	O
scaling	O
addition	O
and	O
other	O
arithmetic	O
operations	B
max	O
and	O
min	O
and	O
mixtures	O
this	O
chapter	O
presents	O
addition	O
and	O
max	O
i	O
will	O
present	O
other	O
operations	B
as	O
we	O
need	O
them	O
the	O
first	O
example	O
is	O
based	O
on	O
dungeons	O
dragons	O
a	O
role-playing	O
game	O
where	O
the	O
results	O
of	O
players	O
decisions	O
are	O
usually	O
determined	O
by	O
rolling	O
dice	B
in	O
fact	O
before	O
game	O
play	O
starts	O
players	O
generate	O
each	O
attribute	O
of	O
their	O
characters	O
strength	O
intelligence	O
wisdom	O
dexterity	O
constitution	O
and	O
charisma	O
by	O
rolling	O
three	O
dice	B
and	O
adding	O
them	O
up	O
so	O
you	O
might	O
be	O
curious	O
to	O
know	O
the	O
distribution	B
of	O
this	O
sum	O
there	O
are	O
two	O
ways	O
you	O
might	O
compute	O
it	O
simulation	B
given	O
a	O
pmf	B
that	O
represents	O
the	O
distribution	B
for	O
a	O
single	O
die	O
you	O
can	O
draw	O
random	O
samples	O
add	O
them	O
up	O
and	O
accumulate	O
the	O
distribution	B
of	O
simulated	O
sums	O
enumeration	B
given	O
two	O
pmfs	O
you	O
can	O
enumerate	O
all	O
possible	O
pairs	O
of	O
val	O
ues	O
and	O
compute	O
the	O
distribution	B
of	O
the	O
sums	O
thinkbayes	O
provides	O
functions	O
for	O
both	O
here	O
s	O
an	O
example	O
of	O
the	O
first	O
approach	O
first	O
i	O
ll	O
define	O
a	O
class	O
to	O
represent	O
a	O
single	O
die	O
as	O
a	O
pmf	B
class	I
diethinkbayes	O
pmf	B
def	O
sides	O
thinkbayes	O
pmf	B
init	O
self	O
for	O
x	O
in	O
self	O
setx	O
self	O
normalize	B
now	O
i	O
can	O
create	O
a	O
die	O
and	O
use	O
thinkbayes	O
samplesum	O
to	O
generate	O
a	O
sample	O
of	O
rolls	O
dice	B
three	O
thinkbayes	O
samplesumdice	O
samplesum	O
takes	O
list	O
of	O
distributions	O
pmf	B
or	O
cdf	B
objects	O
and	O
the	O
sample	O
size	O
n	O
it	O
generates	O
n	O
random	O
sums	O
and	O
returns	O
their	O
distribution	B
as	O
a	O
pmf	B
object	O
chapter	O
odds	B
and	O
addends	O
def	O
samplesumdists	O
n	O
pmf	B
makepmffromlistrandomsumdists	O
for	O
i	O
in	O
xrangen	O
return	O
pmf	B
samplesum	O
uses	O
randomsum	O
also	O
in	O
thinkbayes	O
py	O
def	O
randomsumdists	O
total	O
sumdist	O
random	O
for	O
dist	O
in	O
dists	O
return	O
total	O
randomsum	O
invokes	O
random	O
on	O
each	O
distribution	B
and	O
adds	O
up	O
the	O
results	O
the	O
drawback	O
of	O
simulation	B
is	O
that	O
the	O
result	O
is	O
only	O
approximately	O
correct	O
as	O
n	O
gets	O
larger	O
it	O
gets	O
more	O
accurate	O
but	O
of	O
course	O
the	O
run	O
time	O
increases	O
as	O
well	O
the	O
other	O
approach	O
is	O
to	O
enumerate	O
all	O
pairs	O
of	O
values	O
and	O
compute	O
the	O
sum	O
and	O
probability	B
of	O
each	O
pair	O
this	O
is	O
implemented	O
in	O
pmf	B
add	O
class	O
pmf	B
def	O
other	O
pmf	B
pmf	B
for	O
in	O
self	O
items	O
for	O
in	O
other	O
items	O
return	O
pmf	B
self	O
is	O
a	O
pmf	B
of	O
course	O
other	O
can	O
be	O
a	O
pmf	B
or	O
anything	O
else	O
that	O
provides	O
items	O
the	O
result	O
is	O
a	O
new	O
pmf	B
the	O
time	O
to	O
run	O
depends	O
on	O
the	O
number	O
of	O
items	O
in	O
self	O
and	O
other	O
it	O
is	O
proportional	O
to	O
lenself	O
lenother	O
and	O
here	O
s	O
how	O
it	O
s	O
used	O
three	O
exact	O
when	O
you	O
apply	O
the	O
operator	O
to	O
a	O
pmf	B
python	O
invokes	O
in	O
this	O
example	O
is	O
invoked	O
twice	O
figure	O
shows	O
an	O
approximate	O
result	O
generated	O
by	O
simulation	B
and	O
the	O
exact	O
result	O
computed	O
by	O
enumeration	B
pmf	B
add	O
is	O
based	O
on	O
the	O
assumption	O
that	O
the	O
random	O
selections	O
from	O
each	O
pmf	B
are	O
independent	O
in	O
the	O
example	O
of	O
rolling	O
several	O
dice	B
this	O
assumption	O
is	O
pretty	O
good	O
in	O
other	O
cases	O
we	O
would	O
have	O
to	O
extend	O
this	O
method	O
to	O
use	O
conditional	B
probabilities	O
the	O
code	O
from	O
this	O
section	O
is	O
available	O
from	O
httpthinkbayes	O
com	O
dungeons	O
py	O
for	O
more	O
information	O
see	O
section	O
maxima	O
figure	O
approximate	O
and	O
exact	O
distributions	O
for	O
the	O
sum	O
of	O
three	O
dice	B
maxima	O
when	O
you	O
generate	O
a	O
dungeons	O
dragons	O
character	O
you	O
are	O
particularly	O
interested	O
in	O
the	O
character	O
s	O
best	O
attributes	O
so	O
you	O
might	O
like	O
to	O
know	O
the	O
distribution	B
of	O
the	O
maximum	B
attribute	O
there	O
are	O
three	O
ways	O
to	O
compute	O
the	O
distribution	B
of	O
a	O
maximum	B
simulation	B
given	O
a	O
pmf	B
that	O
represents	O
the	O
distribution	B
for	O
a	O
single	O
selection	O
you	O
can	O
generate	O
random	O
samples	O
find	O
the	O
maximum	B
and	O
accumulate	O
the	O
distribution	B
of	O
simulated	O
maxima	O
enumeration	B
given	O
two	O
pmfs	O
you	O
can	O
enumerate	O
all	O
possible	O
pairs	O
of	O
val	O
ues	O
and	O
compute	O
the	O
distribution	B
of	O
the	O
maximum	B
exponentiation	B
if	O
we	O
convert	O
a	O
pmf	B
to	O
a	O
cdf	B
there	O
is	O
a	O
simple	O
and	O
efficient	O
algorithm	O
for	O
finding	O
the	O
cdf	B
of	O
the	O
maximum	B
the	O
code	O
to	O
simulate	O
maxima	O
is	O
almost	O
identical	O
to	O
the	O
code	O
for	O
simulating	O
sums	O
def	O
randommaxdists	O
total	O
maxdist	O
random	O
for	O
dist	O
in	O
dists	O
return	O
total	O
def	O
samplemaxdists	O
n	O
pmf	B
makepmffromlistrandommaxdists	O
for	O
i	O
in	O
xrangen	O
return	O
pmf	B
of	O
three	O
chapter	O
odds	B
and	O
addends	O
figure	O
distribution	B
of	O
the	O
maximum	B
of	O
six	O
rolls	O
of	O
three	O
dice	B
all	O
i	O
did	O
was	O
replace	O
sum	O
with	O
max	O
and	O
the	O
code	O
for	O
enumeration	B
is	O
almost	O
identical	O
too	O
def	O
res	O
thinkbayes	O
pmf	B
for	O
in	O
for	O
in	O
return	O
res	O
in	O
fact	O
you	O
could	O
generalize	O
this	O
function	O
by	O
taking	O
the	O
appropriate	O
operator	O
as	O
a	O
parameter	B
the	O
only	O
problem	O
with	O
this	O
algorithm	O
is	O
that	O
if	O
each	O
pmf	B
has	O
m	O
values	O
the	O
run	O
time	O
is	O
proportional	O
to	O
and	O
if	O
we	O
want	O
the	O
maximum	B
of	O
k	O
selections	O
it	O
takes	O
time	O
proportional	O
to	O
if	O
we	O
convert	O
the	O
pmfs	O
to	O
cdfs	O
we	O
can	O
do	O
the	O
same	O
calculation	O
much	O
faster	O
the	O
key	O
is	O
to	O
remember	O
the	O
definition	O
of	O
the	O
cumulative	B
distribution	B
function	I
cdfx	O
px	O
x	O
where	O
x	O
is	O
a	O
random	O
variable	O
that	O
means	O
a	O
value	O
chosen	O
randomly	O
from	O
this	O
distribution	B
so	O
for	O
example	O
is	O
the	O
probability	B
that	O
a	O
value	O
from	O
this	O
distribution	B
is	O
less	O
than	O
or	O
equal	O
to	O
if	O
i	O
draw	O
x	O
from	O
and	O
y	O
from	O
and	O
compute	O
the	O
maximum	B
z	O
maxx	O
y	O
what	O
is	O
the	O
chance	O
that	O
z	O
is	O
less	O
than	O
or	O
equal	O
to	O
well	O
in	O
that	O
case	O
both	O
x	O
and	O
y	O
must	O
be	O
less	O
than	O
or	O
equal	O
to	O
of	O
three	O
mixtures	O
if	O
the	O
selections	O
of	O
x	O
and	O
y	O
are	O
independent	O
where	O
is	O
the	O
distribution	B
of	O
z	O
i	O
chose	O
the	O
value	O
because	O
i	O
think	O
it	O
makes	O
the	O
formulas	O
easy	O
to	O
read	O
but	O
we	O
can	O
generalize	O
for	O
any	O
value	O
of	O
z	O
in	O
the	O
special	O
case	O
where	O
we	O
draw	O
k	O
values	O
from	O
the	O
same	O
distribution	B
cdfkz	O
so	O
to	O
find	O
the	O
distribution	B
of	O
the	O
maximum	B
of	O
k	O
values	O
we	O
can	O
enumerate	O
the	O
probabilities	O
in	O
the	O
given	O
cdf	B
and	O
raise	O
them	O
to	O
the	O
kth	O
power	O
cdf	B
provides	O
a	O
method	O
that	O
does	O
just	O
that	O
class	O
cdf	B
def	O
maxself	O
k	O
cdf	B
self	O
copy	O
cdf	B
ps	O
for	O
p	O
in	O
cdf	B
ps	O
return	O
cdf	B
max	O
takes	O
the	O
number	O
of	O
selections	O
k	O
and	O
returns	O
a	O
new	O
cdf	B
that	O
represents	O
the	O
distribution	B
of	O
the	O
maximum	B
of	O
k	O
selections	O
the	O
run	O
time	O
for	O
this	O
method	O
is	O
proportional	O
to	O
m	O
the	O
number	O
of	O
items	O
in	O
the	O
cdf	B
pmf	B
max	O
does	O
the	O
same	O
thing	O
for	O
pmfs	O
it	O
has	O
to	O
do	O
a	O
little	O
more	O
work	O
to	O
convert	O
the	O
pmf	B
to	O
a	O
cdf	B
so	O
the	O
run	O
time	O
is	O
proportional	O
to	O
m	O
log	O
m	O
but	O
that	O
s	O
still	O
better	O
than	O
quadratic	O
finally	O
here	O
s	O
an	O
example	O
that	O
computes	O
the	O
distribution	B
of	O
a	O
character	O
s	O
best	O
attribute	O
best	O
attr	O
cdf	B
best	O
attr	O
pmf	B
best	O
attr	O
cdf	B
makepmf	O
where	O
three	O
exact	O
is	O
defined	O
in	O
the	O
previous	O
section	O
if	O
we	O
print	O
the	O
results	O
we	O
see	O
that	O
the	O
chance	O
of	O
generating	O
a	O
character	O
with	O
at	O
least	O
one	O
attribute	O
of	O
is	O
about	O
figure	O
shows	O
the	O
distribution	B
mixtures	O
let	O
s	O
do	O
one	O
more	O
example	O
from	O
dungeons	O
dragons	O
suppose	O
i	O
have	O
a	O
box	O
of	O
dice	B
with	O
the	O
following	O
inventory	O
chapter	O
odds	B
and	O
addends	O
figure	O
distribution	B
outcome	O
for	O
random	O
die	O
from	O
a	O
box	O
dice	B
dice	B
dice	B
dice	B
die	O
i	O
choose	O
a	O
die	O
from	O
the	O
box	O
and	O
roll	O
it	O
what	O
is	O
the	O
distribution	B
of	O
the	O
outcome	O
if	O
you	O
know	O
which	O
die	O
it	O
is	O
the	O
answer	O
is	O
easy	O
a	O
die	O
with	O
n	O
sides	O
yields	O
a	O
uniform	B
distribution	B
from	O
to	O
n	O
including	O
both	O
but	O
if	O
we	O
don	O
t	O
know	O
which	O
die	O
it	O
is	O
the	O
resulting	O
distribution	B
is	O
a	O
mixture	B
of	O
uniform	O
distributions	O
with	O
different	O
bounds	O
in	O
general	O
this	O
kind	O
of	O
mixture	B
does	O
not	O
fit	O
any	O
simple	O
mathematical	O
model	O
but	O
it	O
is	O
straightforward	O
to	O
compute	O
the	O
distribution	B
in	O
the	O
form	O
of	O
a	O
pmf	B
as	O
always	O
one	O
option	O
is	O
to	O
simulate	O
the	O
scenario	O
generate	O
a	O
random	B
sample	I
and	O
compute	O
the	O
pmf	B
of	O
the	O
sample	O
this	O
approach	O
is	O
simple	O
and	O
it	O
generates	O
an	O
approximate	O
solution	O
quickly	O
but	O
if	O
we	O
want	O
an	O
exact	O
solution	O
we	O
need	O
a	O
different	O
approach	O
let	O
s	O
start	O
with	O
a	O
simple	O
version	O
of	O
the	O
problem	O
where	O
there	O
are	O
only	O
two	O
dice	B
one	O
with	O
sides	O
and	O
one	O
with	O
we	O
can	O
make	O
a	O
pmf	B
to	O
represent	O
each	O
die	O
then	O
we	O
create	O
a	O
pmf	B
to	O
represent	O
the	O
mixture	B
mixtures	O
mix	O
thinkbayes	O
pmf	B
for	O
die	O
in	O
for	O
outcome	O
prob	B
in	O
die	O
items	O
mix	O
incroutcome	O
prob	B
mix	O
normalize	B
the	O
first	O
loop	O
enumerates	O
the	O
dice	B
the	O
second	O
enumerates	O
the	O
outcomes	O
and	O
their	O
probabilities	O
inside	O
the	O
loop	O
pmf	B
incr	O
adds	O
up	O
the	O
contributions	O
from	O
the	O
two	O
distributions	O
this	O
code	O
assumes	O
that	O
the	O
two	O
dice	B
are	O
equally	O
likely	O
more	O
generally	O
we	O
need	O
to	O
know	O
the	O
probability	B
of	O
each	O
die	O
so	O
we	O
can	O
weight	O
the	O
outcomes	O
accordingly	O
first	O
we	O
create	O
a	O
pmf	B
that	O
maps	O
from	O
each	O
die	O
to	O
the	O
probability	B
it	O
is	O
selected	O
pmf	B
dice	B
thinkbayes	O
pmf	B
pmf	B
dice	B
normalize	B
next	O
we	O
need	O
a	O
more	O
general	O
version	O
of	O
the	O
mixture	B
algorithm	O
mix	O
thinkbayes	O
pmf	B
for	O
die	O
weight	O
in	O
pmf	B
dice	B
items	O
for	O
outcome	O
prob	B
in	O
die	O
items	O
mix	O
incroutcome	O
weightprob	O
now	O
each	O
die	O
has	O
a	O
weight	O
associated	O
with	O
it	O
makes	O
it	O
a	O
weighted	O
die	O
i	O
suppose	O
when	O
we	O
add	O
each	O
outcome	O
to	O
the	O
mixture	B
its	O
probability	B
is	O
multiplied	O
by	O
weight	O
figure	O
shows	O
the	O
result	O
as	O
expected	O
values	O
through	O
are	O
the	O
most	O
likely	O
because	O
any	O
die	O
can	O
produce	O
them	O
values	O
above	O
are	O
unlikely	O
because	O
there	O
is	O
only	O
one	O
die	O
in	O
the	O
box	O
that	O
can	O
produce	O
them	O
it	O
does	O
so	O
less	O
than	O
half	O
the	O
time	O
thinkbayes	O
provides	O
a	O
function	O
named	O
makemixture	B
that	O
encapsulates	O
this	O
algorithm	O
so	O
we	O
could	O
have	O
written	O
mix	O
thinkbayes	O
makemixturepmf	O
dice	B
we	O
ll	O
use	O
makemixture	B
again	O
in	O
chapters	O
and	O
chapter	O
odds	B
and	O
addends	O
discussion	O
other	O
than	O
the	O
odds	B
form	I
of	O
bayes	O
s	O
theorem	O
this	O
chapter	O
is	O
not	O
specifically	O
bayesian	O
but	O
bayesian	O
analysis	O
is	O
all	O
about	O
distributions	O
so	O
it	O
is	O
important	O
to	O
understand	O
the	O
concept	O
of	O
a	O
distribution	B
well	O
from	O
a	O
computational	O
point	O
of	O
view	O
a	O
distribution	B
is	O
any	O
data	O
structure	O
that	O
represents	O
a	O
set	O
of	O
values	O
outcomes	O
of	O
a	O
random	O
process	B
and	O
their	O
probabilities	O
we	O
have	O
seen	O
two	O
representations	O
of	O
distributions	O
pmfs	O
and	O
cdfs	O
these	O
representations	O
are	O
equivalent	O
in	O
the	O
sense	O
that	O
they	O
contain	O
the	O
same	O
information	O
so	O
you	O
can	O
convert	O
from	O
one	O
to	O
the	O
other	O
the	O
primary	O
difference	O
between	O
them	O
is	O
performance	O
some	O
operations	B
are	O
faster	O
and	O
easier	O
with	O
a	O
pmf	B
others	O
are	O
faster	O
with	O
a	O
cdf	B
the	O
other	O
goal	O
of	O
this	O
chapter	O
is	O
to	O
introduce	O
operations	B
that	O
act	O
on	O
distributions	O
like	O
pmf	B
add	O
cdf	B
max	O
and	O
thinkbayes	O
makemixture	B
we	O
will	O
use	O
these	O
operations	B
later	O
but	O
i	O
introduce	O
them	O
now	O
to	O
encourage	O
you	O
to	O
think	O
of	O
a	O
distribution	B
as	O
a	O
fundamental	O
unit	O
of	O
computation	O
not	O
just	O
a	O
container	O
for	O
values	O
and	O
probabilities	O
chapter	O
decision	B
analysis	I
the	O
price	B
is	I
right	I
problem	O
on	O
november	O
contestants	O
named	O
letia	O
and	O
nathaniel	O
appeared	O
on	O
the	O
price	B
is	I
right	I
an	O
american	O
game	O
show	O
they	O
competed	O
in	O
a	O
game	O
called	O
the	O
showcase	B
where	O
the	O
objective	O
is	O
to	O
guess	O
the	O
price	O
of	O
a	O
showcase	B
of	O
prizes	O
the	O
contestant	O
who	O
comes	O
closest	O
to	O
the	O
actual	O
price	O
of	O
the	O
showcase	B
without	O
going	O
over	O
wins	O
the	O
prizes	O
nathaniel	O
went	O
first	O
his	O
showcase	B
included	O
a	O
dishwasher	O
a	O
wine	O
cabinet	O
a	O
laptop	O
computer	O
and	O
a	O
car	O
he	O
bid	O
letia	O
s	O
showcase	B
included	O
a	O
pinball	O
machine	O
a	O
video	O
arcade	O
game	O
a	O
pool	O
table	O
and	O
a	O
cruise	O
of	O
the	O
bahamas	O
she	O
bid	O
the	O
actual	O
price	O
of	O
nathaniel	O
s	O
showcase	B
was	O
his	O
bid	O
was	O
too	O
high	O
so	O
he	O
lost	O
the	O
actual	O
price	O
of	O
letia	O
s	O
showcase	B
was	O
she	O
was	O
only	O
off	O
by	O
so	O
she	O
won	O
her	O
showcase	B
and	O
because	O
her	O
bid	O
was	O
off	O
by	O
less	O
than	O
she	O
also	O
won	O
nathaniel	O
s	O
showcase	B
for	O
a	O
bayesian	O
thinker	O
this	O
scenario	O
suggests	O
several	O
questions	O
before	O
seeing	O
the	O
prizes	O
what	O
prior	B
beliefs	O
should	O
the	O
contestant	O
have	O
about	O
the	O
price	O
of	O
the	O
showcase	B
after	O
seeing	O
the	O
prizes	O
how	O
should	O
the	O
contestant	O
update	B
those	O
be	O
liefs	O
based	O
on	O
the	O
posterior	B
distribution	B
what	O
should	O
the	O
contestant	O
bid	O
chapter	O
decision	B
analysis	I
figure	O
distribution	B
of	O
prices	O
for	O
showcases	O
on	O
the	O
price	B
is	I
right	I
the	O
third	O
question	O
demonstrates	O
a	O
common	O
use	O
of	O
bayesian	O
analysis	O
decision	B
analysis	I
given	O
a	O
posterior	B
distribution	B
we	O
can	O
choose	O
the	O
bid	O
that	O
maximizes	O
the	O
contestant	O
s	O
expected	O
return	O
this	O
problem	O
is	O
inspired	O
by	O
an	O
example	O
in	O
cameron	O
davidson-pilon	B
s	O
book	O
bayesian	O
methods	O
for	O
hackers	O
the	O
code	O
i	O
wrote	O
for	O
this	O
chapter	O
is	O
available	O
from	O
httpthinkbayes	O
comprice	O
py	O
it	O
reads	O
data	O
files	O
you	O
can	O
download	O
from	O
and	O
http	O
for	O
more	O
information	O
see	O
section	O
the	O
prior	B
to	O
choose	O
a	O
prior	B
distribution	B
of	O
prices	O
we	O
can	O
take	O
advantage	O
of	O
data	O
from	O
previous	O
episodes	O
fortunately	O
fans	O
of	O
the	O
show	O
keep	O
detailed	O
records	O
when	O
i	O
corresponded	O
with	O
mr	O
davidson-pilon	B
about	O
his	O
book	O
he	O
sent	O
me	O
data	O
collected	O
by	O
steve	O
gee	B
at	O
it	O
includes	O
the	O
price	O
of	O
each	O
showcase	B
from	O
the	O
and	O
seasons	O
and	O
the	O
bids	O
offered	O
by	O
the	O
contestants	O
figure	O
shows	O
the	O
distribution	B
of	O
prices	O
for	O
these	O
showcases	O
the	O
most	O
common	O
value	O
for	O
both	O
showcases	O
is	O
around	O
but	O
the	O
first	O
showcase	B
has	O
a	O
second	O
mode	O
near	O
and	O
the	O
second	O
showcase	B
is	O
occasionally	O
worth	O
more	O
than	O
these	O
distributions	O
are	O
based	O
on	O
actual	O
data	O
but	O
they	O
have	O
been	O
smoothed	O
probability	B
density	B
functions	O
by	O
gaussian	O
kernel	B
density	B
estimation	I
before	O
we	O
go	O
on	O
i	O
want	O
to	O
take	O
a	O
detour	O
to	O
talk	O
about	O
probability	B
density	B
functions	O
and	O
kde	B
probability	B
density	B
functions	O
so	O
far	O
we	O
have	O
been	O
working	O
with	O
probability	B
mass	O
functions	O
or	O
pmfs	O
a	O
pmf	B
is	O
a	O
map	O
from	O
each	O
possible	O
value	O
to	O
its	O
probability	B
in	O
my	O
implementation	B
a	O
pmf	B
object	O
provides	O
a	O
method	O
named	O
prob	B
that	O
takes	O
a	O
value	O
and	O
returns	O
a	O
probability	B
also	O
known	O
as	O
a	O
probability	B
mass	O
a	O
probability	B
density	B
function	I
or	O
pdf	B
is	O
the	O
continuous	O
version	O
of	O
a	O
pmf	B
where	O
the	O
possible	O
values	O
make	O
up	O
a	O
continuous	O
range	O
rather	O
than	O
a	O
discrete	O
set	O
in	O
mathematical	O
notation	O
pdfs	O
are	O
usually	O
written	O
as	O
functions	O
for	O
example	O
here	O
is	O
the	O
pdf	B
of	O
a	O
gaussian	B
distribution	B
with	O
mean	O
and	O
standard	O
deviation	O
f	O
exp	O
for	O
a	O
given	O
value	O
of	O
x	O
this	O
function	O
computes	O
a	O
probability	B
density	B
a	O
density	B
is	O
similar	O
to	O
a	O
probability	B
mass	O
in	O
the	O
sense	O
that	O
a	O
higher	O
density	B
indicates	O
that	O
a	O
value	O
is	O
more	O
likely	O
but	O
a	O
density	B
is	O
not	O
a	O
probability	B
a	O
density	B
can	O
be	O
or	O
any	O
positive	O
value	O
it	O
is	O
not	O
bounded	O
like	O
a	O
probability	B
between	O
and	O
if	O
you	O
integrate	O
a	O
density	B
over	O
a	O
continuous	O
range	O
the	O
result	O
is	O
a	O
probability	B
but	O
for	O
the	O
applications	O
in	O
this	O
book	O
we	O
seldom	O
have	O
to	O
do	O
that	O
instead	O
we	O
primarily	O
use	O
probability	B
densities	O
as	O
part	O
of	O
a	O
likelihood	B
function	I
we	O
will	O
see	O
an	O
example	O
soon	O
representing	O
pdfs	O
to	O
represent	O
pdfs	O
in	O
python	O
thinkbayes	O
py	O
provides	O
a	O
class	O
named	O
pdf	B
pdf	B
is	O
an	O
abstract	B
type	I
which	O
means	O
that	O
it	O
defines	O
the	O
interface	B
a	O
pdf	B
is	O
supposed	O
to	O
have	O
but	O
does	O
not	O
provide	O
a	O
complete	O
implementation	B
the	O
pdf	B
interface	B
includes	O
two	O
methods	O
density	B
and	O
makepmf	O
class	O
pdfobject	O
chapter	O
decision	B
analysis	I
def	O
densityself	O
x	O
raise	O
unimplementedmethodexception	O
def	O
makepmfself	O
xs	O
pmf	B
pmf	B
for	O
x	O
in	O
xs	O
pmf	B
setx	O
self	O
densityx	O
pmf	B
normalize	B
return	O
pmf	B
density	B
takes	O
a	O
value	O
x	O
and	O
returns	O
the	O
corresponding	O
density	B
makepmf	O
makes	O
a	O
discrete	O
approximation	O
to	O
the	O
pdf	B
pdf	B
provides	O
an	O
implementation	B
of	O
makepmf	O
but	O
not	O
density	B
which	O
has	O
to	O
be	O
provided	O
by	O
a	O
child	O
class	O
a	O
concrete	B
type	I
is	O
a	O
child	O
class	O
that	O
extends	O
an	O
abstract	B
type	I
and	O
provides	O
an	O
implementation	B
of	O
the	O
missing	O
methods	O
for	O
example	O
gaussianpdf	O
extends	O
pdf	B
and	O
provides	O
density	B
class	O
gaussianpdfpdf	O
def	O
mu	O
sigma	O
self	O
mu	O
mu	O
self	O
sigma	O
sigma	O
def	O
densityself	O
x	O
return	O
scipy	B
stats	O
norm	O
pdfx	O
self	O
mu	O
self	O
sigma	O
takes	O
mu	O
and	O
sigma	O
which	O
are	O
the	O
mean	O
and	O
standard	O
deviation	O
of	O
the	O
distribution	B
and	O
stores	O
them	O
as	O
attributes	O
density	B
uses	O
a	O
function	O
from	O
scipy	B
stats	O
to	O
evaluate	O
the	O
gaussian	B
pdf	B
the	O
function	O
is	O
called	O
norm	O
pdf	B
because	O
the	O
gaussian	B
distribution	B
is	O
also	O
called	O
the	O
normal	B
distribution	B
the	O
gaussian	B
pdf	B
is	O
defined	O
by	O
a	O
simple	O
mathematical	O
function	O
so	O
it	O
is	O
easy	O
to	O
evaluate	O
and	O
it	O
is	O
useful	O
because	O
many	O
quantities	O
in	O
the	O
real	O
world	O
have	O
distributions	O
that	O
are	O
approximately	O
gaussian	O
but	O
with	O
real	O
data	O
there	O
is	O
no	O
guarantee	O
that	O
the	O
distribution	B
is	O
gaussian	O
or	O
any	O
other	O
simple	O
mathematical	O
function	O
in	O
that	O
case	O
we	O
can	O
use	O
a	O
sample	O
to	O
estimate	O
the	O
pdf	B
of	O
the	O
whole	O
population	O
for	O
example	O
in	O
the	O
price	B
is	I
right	I
data	O
we	O
have	O
prices	O
for	O
the	O
first	O
showcase	B
we	O
can	O
think	O
of	O
these	O
values	O
as	O
a	O
sample	O
from	O
the	O
population	O
of	O
all	O
possible	O
showcase	B
prices	O
representing	O
pdfs	O
this	O
sample	O
includes	O
the	O
following	O
values	O
order	O
in	O
the	O
sample	O
no	O
values	O
appear	O
between	O
and	O
but	O
there	O
is	O
no	O
reason	O
to	O
think	O
that	O
these	O
values	O
are	O
impossible	O
based	O
on	O
our	O
background	O
information	O
we	O
expect	O
all	O
values	O
in	O
this	O
range	O
to	O
be	O
equally	O
likely	O
in	O
other	O
words	O
we	O
expect	O
the	O
pdf	B
to	O
be	O
fairly	O
smooth	O
kernel	B
density	B
estimation	I
is	O
an	O
algorithm	O
that	O
takes	O
a	O
sample	O
and	O
finds	O
an	O
appropriately	O
smooth	O
pdf	B
that	O
fits	O
the	O
data	O
you	O
can	O
read	O
details	O
at	O
httpen	O
wikipedia	O
orgwikikernel	O
density	B
estimation	O
scipy	B
provides	O
an	O
implementation	B
of	O
kde	B
and	O
thinkbayes	O
provides	O
a	O
class	O
called	O
estimatedpdf	O
that	O
uses	O
it	O
class	O
estimatedpdfpdf	O
def	O
sample	O
self	O
kde	B
scipy	B
stats	O
gaussian	O
kdesample	O
def	O
densityself	O
x	O
return	O
self	O
kde	B
evaluatex	O
takes	O
a	O
sample	O
and	O
computes	O
a	O
kernel	O
density	B
estimate	O
the	O
result	O
is	O
a	O
gaussian	O
kde	B
object	O
that	O
provides	O
an	O
evaluate	O
method	O
density	B
takes	O
a	O
value	O
calls	O
gaussian	O
kde	B
evaluate	O
and	O
returns	O
the	O
resulting	O
density	B
finally	O
here	O
s	O
an	O
outline	O
of	O
the	O
code	O
i	O
used	O
to	O
generate	O
figure	O
prices	O
readdata	O
pdf	B
thinkbayes	O
estimatedpdfprices	O
low	O
high	O
n	O
xs	O
numpy	B
linspacelow	O
high	O
n	O
pmf	B
pdf	B
makepmfxs	O
pdf	B
is	O
a	O
pdf	B
object	O
estimated	O
by	O
kde	B
pmf	B
is	O
a	O
pmf	B
object	O
that	O
approximates	O
the	O
pdf	B
by	O
evaluating	O
the	O
density	B
at	O
a	O
sequence	O
of	O
equally	O
spaced	O
values	O
linspace	B
stands	O
for	O
linear	O
space	O
it	O
takes	O
a	O
range	O
low	O
and	O
high	O
and	O
the	O
number	O
of	O
points	O
n	O
and	O
returns	O
a	O
new	O
numpy	B
array	O
with	O
n	O
elements	O
equally	O
spaced	O
between	O
low	O
and	O
high	O
including	O
both	O
and	O
now	O
back	O
to	O
the	O
price	B
is	I
right	I
chapter	O
decision	B
analysis	I
figure	O
cumulative	O
distribution	B
of	O
the	O
difference	O
between	O
the	O
contestant	O
s	O
bid	O
and	O
the	O
actual	O
price	O
modeling	B
the	O
contestants	O
the	O
pdfs	O
in	O
figure	O
estimate	O
the	O
distribution	B
of	O
possible	O
prices	O
if	O
you	O
were	O
a	O
contestant	O
on	O
the	O
show	O
you	O
could	O
use	O
this	O
distribution	B
to	O
quantify	O
your	O
prior	B
belief	O
about	O
the	O
price	O
of	O
each	O
showcase	B
you	O
see	O
the	O
prizes	O
to	O
update	B
these	O
priors	O
we	O
have	O
to	O
answer	O
these	O
questions	O
what	O
data	O
should	O
we	O
consider	O
and	O
how	O
should	O
we	O
quantify	O
it	O
can	O
we	O
compute	O
a	O
likelihood	B
function	I
that	O
is	O
for	O
each	O
hypothetical	O
value	O
of	O
price	O
can	O
we	O
compute	O
the	O
conditional	B
likelihood	B
of	O
the	O
data	O
to	O
answer	O
these	O
questions	O
i	O
am	O
going	O
to	O
model	O
the	O
contestant	O
as	O
a	O
priceguessing	O
instrument	O
with	O
known	O
error	B
characteristics	O
in	O
other	O
words	O
when	O
the	O
contestant	O
sees	O
the	O
prizes	O
he	O
or	O
she	O
guesses	O
the	O
price	O
of	O
each	O
prize	O
ideally	O
without	O
taking	O
into	O
consideration	O
the	O
fact	O
that	O
the	O
prize	O
is	O
part	O
of	O
a	O
showcase	B
and	O
adds	O
up	O
the	O
prices	O
let	O
s	O
call	O
this	O
total	O
guess	O
under	O
this	O
model	O
the	O
question	O
we	O
have	O
to	O
answer	O
is	O
if	O
the	O
actual	O
price	O
is	O
price	O
what	O
is	O
the	O
likelihood	B
that	O
the	O
contestant	O
s	O
estimate	O
would	O
be	O
guess	O
or	O
if	O
we	O
define	O
error	B
price	O
guess	O
modeling	B
the	O
contestants	O
then	O
we	O
could	O
ask	O
what	O
is	O
the	O
likelihood	B
that	O
the	O
contestant	O
s	O
estimate	O
is	O
off	O
by	O
error	B
to	O
answer	O
this	O
question	O
we	O
can	O
use	O
the	O
historical	O
data	O
again	O
figure	O
shows	O
the	O
cumulative	O
distribution	B
of	O
diff	O
the	O
difference	O
between	O
the	O
contestant	O
s	O
bid	O
and	O
the	O
actual	O
price	O
of	O
the	O
showcase	B
the	O
definition	O
of	O
diff	O
is	O
diff	O
price	O
bid	O
when	O
diff	O
is	O
negative	O
the	O
bid	O
is	O
too	O
high	O
as	O
an	O
aside	O
we	O
can	O
use	O
this	O
distribution	B
to	O
compute	O
the	O
probability	B
that	O
the	O
contestants	O
overbid	O
the	O
first	O
contestant	O
overbids	O
of	O
the	O
time	O
the	O
second	O
contestant	O
overbids	O
of	O
the	O
time	O
we	O
can	O
also	O
see	O
that	O
the	O
bids	O
are	O
biased	O
that	O
is	O
they	O
are	O
more	O
likely	O
to	O
be	O
too	O
low	O
than	O
too	O
high	O
and	O
that	O
makes	O
sense	O
given	O
the	O
rules	O
of	O
the	O
game	O
finally	O
we	O
can	O
use	O
this	O
distribution	B
to	O
estimate	O
the	O
reliability	O
of	O
the	O
contestants	O
guesses	O
this	O
step	O
is	O
a	O
little	O
tricky	O
because	O
we	O
don	O
t	O
actually	O
know	O
the	O
contestant	O
s	O
guesses	O
we	O
only	O
know	O
what	O
they	O
bid	O
so	O
we	O
ll	O
have	O
to	O
make	O
some	O
assumptions	O
specifically	O
i	O
assume	O
that	O
the	O
distribution	B
of	O
error	B
is	O
gaussian	O
with	O
mean	O
and	O
the	O
same	O
variance	O
as	O
diff	O
the	O
player	O
class	O
implements	O
this	O
model	O
class	O
playerobject	O
def	O
prices	O
bids	O
diffs	O
self	O
pdf	B
price	O
thinkbayes	O
estimatedpdfprices	O
self	O
cdf	B
diff	O
thinkbayes	O
makecdffromlistdiffs	O
mu	O
sigma	O
numpy	B
stddiffs	O
self	O
pdf	B
error	B
thinkbayes	O
gaussianpdfmu	O
sigma	O
prices	O
is	O
a	O
sequence	O
of	O
showcase	B
prices	O
bids	O
is	O
a	O
sequence	O
of	O
bids	O
and	O
diffs	O
is	O
a	O
sequence	O
of	O
diffs	O
where	O
again	O
diff	O
price	O
bid	O
pdf	B
price	O
is	O
the	O
smoothed	O
pdf	B
of	O
prices	O
estimated	O
by	O
kde	B
cdf	B
diff	O
is	O
the	O
cumulative	O
distribution	B
of	O
diff	O
which	O
we	O
saw	O
in	O
figure	O
and	O
pdf	B
error	B
is	O
the	O
pdf	B
that	O
characterizes	O
the	O
distribution	B
of	O
errors	O
where	O
error	B
price	O
guess	O
chapter	O
decision	B
analysis	I
again	O
we	O
use	O
the	O
variance	O
of	O
diff	O
to	O
estimate	O
the	O
variance	O
of	O
error	B
this	O
estimate	O
is	O
not	O
perfect	O
because	O
contestants	O
bids	O
are	O
sometimes	O
strategic	O
for	O
example	O
if	O
player	O
thinks	O
that	O
player	O
has	O
overbid	O
player	O
might	O
make	O
a	O
very	O
low	O
bid	O
in	O
that	O
case	O
diff	O
does	O
not	O
reflect	O
error	B
if	O
this	O
happens	O
a	O
lot	O
the	O
observed	O
variance	O
in	O
diff	O
might	O
overestimate	O
the	O
variance	O
in	O
error	B
nevertheless	O
i	O
think	O
it	O
is	O
a	O
reasonable	O
modeling	B
decision	O
as	O
an	O
alternative	O
someone	O
preparing	O
to	O
appear	O
on	O
the	O
show	O
could	O
estimate	O
their	O
own	O
distribution	B
of	O
error	B
by	O
watching	O
previous	O
shows	O
and	O
recording	O
their	O
guesses	O
and	O
the	O
actual	O
prices	O
likelihood	B
now	O
we	O
are	O
ready	O
to	O
write	O
the	O
likelihood	B
function	I
as	O
usual	O
i	O
define	O
a	O
new	O
class	O
that	O
extends	O
thinkbayes	O
suite	B
class	I
pricethinkbayes	O
suite	B
def	O
pmf	B
player	O
thinkbayes	O
suite	B
init	O
self	O
pmf	B
self	O
player	O
player	O
pmf	B
represents	O
the	O
prior	B
distribution	B
and	O
player	O
is	O
a	O
player	O
object	O
as	O
described	O
in	O
the	O
previous	O
section	O
here	O
s	O
likelihood	B
def	O
likelihoodself	O
data	O
hypo	O
price	O
hypo	O
guess	O
data	O
error	B
price	O
guess	O
like	O
self	O
player	O
errordensityerror	O
return	O
like	O
hypo	O
is	O
the	O
hypothetical	O
price	O
of	O
the	O
showcase	B
data	O
is	O
the	O
contestant	O
s	O
best	O
guess	O
at	O
the	O
price	O
error	B
is	O
the	O
difference	O
and	O
like	O
is	O
the	O
likelihood	B
of	O
the	O
data	O
given	O
the	O
hypothesis	O
errordensity	O
is	O
defined	O
in	O
player	O
class	O
player	O
def	O
errordensityself	O
error	B
return	O
self	O
pdf	B
error	B
densityerror	O
update	B
figure	O
prior	B
and	O
posterior	B
distributions	O
for	O
player	O
based	O
on	O
a	O
best	O
guess	O
of	O
errordensity	O
works	O
by	O
evaluating	O
pdf	B
error	B
at	O
the	O
given	O
value	O
of	O
error	B
the	O
result	O
is	O
a	O
probability	B
density	B
so	O
it	O
is	O
not	O
really	O
a	O
probability	B
but	O
remember	O
that	O
likelihood	B
doesn	O
t	O
need	O
to	O
compute	O
a	O
probability	B
it	O
only	O
has	O
to	O
compute	O
something	O
proportional	O
to	O
a	O
probability	B
as	O
long	O
as	O
the	O
constant	O
of	O
proportionality	O
is	O
the	O
same	O
for	O
all	O
likelihoods	O
it	O
gets	O
canceled	O
out	O
when	O
we	O
normalize	B
the	O
posterior	B
distribution	B
and	O
therefore	O
a	O
probability	B
density	B
is	O
a	O
perfectly	O
good	O
likelihood	B
update	B
player	O
provides	O
a	O
method	O
that	O
takes	O
the	O
contestant	O
s	O
guess	O
and	O
computes	O
the	O
posterior	B
distribution	B
class	O
player	O
def	O
makebeliefsself	O
guess	O
pmf	B
self	O
pmfprice	O
self	O
prior	B
pricepmf	O
self	O
self	O
posterior	B
self	O
prior	B
copy	O
self	O
posterior	B
updateguess	O
pmfprice	O
generates	O
a	O
discrete	O
approximation	O
to	O
the	O
pdf	B
of	O
price	O
which	O
we	O
use	O
to	O
construct	O
the	O
prior	B
pmfprice	O
uses	O
makepmf	O
which	O
evaluates	O
pdf	B
price	O
at	O
a	O
sequence	O
of	O
values	O
class	O
player	O
chapter	O
decision	B
analysis	I
n	O
price	O
xs	O
n	O
def	O
pmfpriceself	O
return	O
self	O
pdf	B
price	O
makepmfself	O
price	O
xs	O
to	O
construct	O
the	O
posterior	B
we	O
make	O
a	O
copy	O
of	O
the	O
prior	B
and	O
then	O
invoke	O
update	B
which	O
invokes	O
likelihood	B
for	O
each	O
hypothesis	O
multiplies	O
the	O
priors	O
by	O
the	O
likelihoods	O
and	O
renormalizes	O
so	O
let	O
s	O
get	O
back	O
to	O
the	O
original	O
scenario	O
suppose	O
you	O
are	O
player	O
and	O
when	O
you	O
see	O
your	O
showcase	B
your	O
best	O
guess	O
is	O
that	O
the	O
total	O
price	O
of	O
the	O
prizes	O
is	O
figure	O
shows	O
prior	B
and	O
posterior	B
beliefs	O
about	O
the	O
actual	O
price	O
the	O
posterior	B
is	O
shifted	O
to	O
the	O
left	O
because	O
your	O
guess	O
is	O
on	O
the	O
low	O
end	O
of	O
the	O
prior	B
range	O
on	O
one	O
level	O
this	O
result	O
makes	O
sense	O
the	O
most	O
likely	O
value	O
in	O
the	O
prior	B
is	O
your	O
best	O
guess	O
is	O
and	O
the	O
mean	O
of	O
the	O
posterior	B
is	O
somewhere	O
in	O
between	O
on	O
another	O
level	O
you	O
might	O
find	O
this	O
result	O
bizarre	O
because	O
it	O
suggests	O
that	O
if	O
you	O
think	O
the	O
price	O
is	O
then	O
you	O
should	O
believe	O
the	O
price	O
is	O
to	O
resolve	O
this	O
apparent	O
paradox	O
remember	O
that	O
you	O
are	O
combining	O
two	O
sources	O
of	O
information	O
historical	O
data	O
about	O
past	O
showcases	O
and	O
guesses	O
about	O
the	O
prizes	O
you	O
see	O
we	O
are	O
treating	O
the	O
historical	O
data	O
as	O
the	O
prior	B
and	O
updating	O
it	O
based	O
on	O
your	O
guesses	O
but	O
we	O
could	O
equivalently	O
use	O
your	O
guess	O
as	O
a	O
prior	B
and	O
update	B
it	O
based	O
on	O
historical	O
data	O
if	O
you	O
think	O
of	O
it	O
that	O
way	O
maybe	O
it	O
is	O
less	O
surprising	O
that	O
the	O
most	O
likely	O
value	O
in	O
the	O
posterior	B
is	O
not	O
your	O
original	O
guess	O
optimal	O
bidding	O
now	O
that	O
we	O
have	O
a	O
posterior	B
distribution	B
we	O
can	O
use	O
it	O
to	O
compute	O
the	O
optimal	O
bid	O
which	O
i	O
define	O
as	O
the	O
bid	O
that	O
maximizes	O
expected	O
return	O
httpen	O
wikipedia	O
orgwikiexpected	O
return	O
optimal	O
bidding	O
i	O
m	O
going	O
to	O
present	O
the	O
methods	O
in	O
this	O
section	O
top-down	O
which	O
means	O
i	O
will	O
show	O
you	O
how	O
they	O
are	O
used	O
before	O
i	O
show	O
you	O
how	O
they	O
work	O
if	O
you	O
see	O
an	O
unfamiliar	O
method	O
don	O
t	O
worry	O
the	O
definition	O
will	O
be	O
along	O
shortly	O
to	O
compute	O
optimal	O
bids	O
i	O
wrote	O
a	O
class	O
called	O
gaincalculator	O
class	O
gaincalculatorobject	O
def	O
player	O
opponent	O
self	O
player	O
player	O
self	O
opponent	O
opponent	O
player	O
and	O
opponent	O
are	O
player	O
objects	O
gaincalculator	O
provides	O
expectedgains	O
which	O
computes	O
a	O
sequence	O
of	O
bids	O
and	O
the	O
expected	O
gain	O
for	O
each	O
bid	O
def	O
expectedgainsself	O
bids	O
numpy	B
linspacelow	O
high	O
n	O
gains	O
for	O
bid	O
in	O
bids	O
return	O
bids	O
gains	O
low	O
and	O
high	O
specify	O
the	O
range	O
of	O
possible	O
bids	O
n	O
is	O
the	O
number	O
of	O
bids	O
to	O
try	O
expectedgains	O
calls	O
expectedgain	O
which	O
computes	O
expected	O
gain	O
for	O
a	O
given	O
bid	O
def	O
expectedgainself	O
bid	O
suite	B
self	O
player	O
posterior	B
total	O
for	O
price	O
prob	B
in	O
sortedsuite	O
items	O
gain	O
self	O
gainbid	O
price	O
total	O
prob	B
gain	O
return	O
total	O
expectedgain	O
loops	O
through	O
the	O
values	O
in	O
the	O
posterior	B
and	O
computes	O
the	O
gain	O
for	O
each	O
bid	O
given	O
the	O
actual	O
prices	O
of	O
the	O
showcase	B
it	O
weights	O
each	O
gain	O
with	O
the	O
corresponding	O
probability	B
and	O
returns	O
the	O
total	O
expectedgain	O
invokes	O
gain	O
which	O
takes	O
a	O
bid	O
and	O
an	O
actual	O
price	O
and	O
returns	O
the	O
expected	O
gain	O
def	O
gainself	O
bid	O
price	O
if	O
bid	O
price	O
return	O
chapter	O
decision	B
analysis	I
figure	O
expected	O
gain	O
versus	O
bid	O
in	O
a	O
scenario	O
where	O
player	O
s	O
best	O
guess	O
is	O
and	O
player	O
s	O
best	O
guess	O
is	O
diff	O
price	O
bid	O
prob	B
self	O
probwindiff	O
if	O
diff	O
return	O
price	O
prob	B
else	O
return	O
price	O
prob	B
if	O
you	O
overbid	O
you	O
get	O
nothing	O
otherwise	O
we	O
compute	O
the	O
difference	O
between	O
your	O
bid	O
and	O
the	O
price	O
which	O
determines	O
your	O
probability	B
of	O
winning	O
if	O
diff	O
is	O
less	O
than	O
you	O
win	O
both	O
showcases	O
for	O
simplicity	O
i	O
assume	O
that	O
both	O
showcases	O
have	O
the	O
same	O
price	O
since	O
this	O
outcome	O
is	O
rare	O
it	O
doesn	O
t	O
make	O
much	O
difference	O
finally	O
we	O
have	O
to	O
compute	O
the	O
probability	B
of	O
winning	O
based	O
on	O
diff	O
def	O
probwinself	O
diff	O
prob	B
self	O
opponent	O
probworsethandiff	O
return	O
prob	B
if	O
your	O
opponent	O
overbids	O
you	O
win	O
otherwise	O
you	O
have	O
to	O
hope	O
that	O
your	O
opponent	O
is	O
off	O
by	O
more	O
than	O
diff	O
player	O
provides	O
methods	O
to	O
compute	O
both	O
probabilities	O
class	O
player	O
gain	O
discussion	O
def	O
proboverbidself	O
return	O
def	O
probworsethanself	O
diff	O
return	O
self	O
cdf	B
diff	O
probdiff	O
this	O
code	O
might	O
be	O
confusing	O
because	O
the	O
computation	O
is	O
now	O
from	O
the	O
point	O
of	O
view	O
of	O
the	O
opponent	O
who	O
is	O
computing	O
what	O
is	O
the	O
probability	B
that	O
i	O
overbid	O
and	O
what	O
is	O
the	O
probability	B
that	O
my	O
bid	O
is	O
off	O
by	O
more	O
than	O
diff	O
both	O
answers	O
are	O
based	O
on	O
the	O
cdf	B
of	O
diff	O
if	O
the	O
opponent	O
s	O
diff	O
is	O
less	O
than	O
or	O
equal	O
to	O
you	O
win	O
if	O
the	O
opponent	O
s	O
diff	O
is	O
worse	O
than	O
yours	O
you	O
win	O
otherwise	O
you	O
lose	O
finally	O
here	O
s	O
the	O
code	O
that	O
computes	O
optimal	O
bids	O
class	O
player	O
def	O
optimalbidself	O
guess	O
opponent	O
self	O
makebeliefsguess	O
calc	O
gaincalculatorself	O
opponent	O
bids	O
gains	O
calc	O
expectedgains	O
gain	O
bid	O
maxzipgains	O
bids	O
return	O
bid	O
gain	O
given	O
a	O
guess	O
and	O
an	O
opponent	O
optimalbid	O
computes	O
the	O
posterior	B
distribution	B
instantiates	O
a	O
gaincalculator	O
computes	O
expected	O
gains	O
for	O
a	O
range	O
of	O
bids	O
and	O
returns	O
the	O
optimal	O
bid	O
and	O
expected	O
gain	O
whew	O
figure	O
shows	O
the	O
results	O
for	O
both	O
players	O
based	O
on	O
a	O
scenario	O
where	O
player	O
s	O
best	O
guess	O
is	O
and	O
player	O
s	O
best	O
guess	O
is	O
for	O
player	O
the	O
optimal	O
bid	O
is	O
yielding	O
an	O
expected	O
return	O
of	O
almost	O
this	O
is	O
a	O
case	O
turns	O
out	O
to	O
be	O
unusual	O
where	O
the	O
optimal	O
bid	O
is	O
actually	O
higher	O
than	O
the	O
contestant	O
s	O
best	O
guess	O
for	O
player	O
the	O
optimal	O
bid	O
is	O
yielding	O
an	O
expected	O
return	O
of	O
almost	O
this	O
is	O
the	O
more	O
typical	O
case	O
where	O
the	O
optimal	O
bid	O
is	O
less	O
than	O
the	O
best	O
guess	O
discussion	O
one	O
of	O
the	O
features	O
of	O
bayesian	O
estimation	O
is	O
that	O
the	O
result	O
comes	O
in	O
the	O
form	O
of	O
a	O
posterior	B
distribution	B
classical	B
estimation	I
usually	O
generates	O
a	O
chapter	O
decision	B
analysis	I
single	O
point	O
estimate	O
or	O
a	O
confidence	O
interval	O
which	O
is	O
sufficient	O
if	O
estimation	O
is	O
the	O
last	O
step	O
in	O
the	O
process	B
but	O
if	O
you	O
want	O
to	O
use	O
an	O
estimate	O
as	O
an	O
input	O
to	O
a	O
subsequent	O
analysis	O
point	O
estimates	O
and	O
intervals	O
are	O
often	O
not	O
much	O
help	O
in	O
this	O
example	O
we	O
use	O
the	O
posterior	B
distribution	B
to	O
compute	O
an	O
optimal	O
bid	O
the	O
return	O
on	O
a	O
given	O
bid	O
is	O
asymmetric	O
and	O
discontinuous	O
you	O
overbid	O
you	O
lose	O
so	O
it	O
would	O
be	O
hard	O
to	O
solve	O
this	O
problem	O
analytically	O
but	O
it	O
is	O
relatively	O
simple	O
to	O
do	O
computationally	O
newcomers	O
to	O
bayesian	O
thinking	O
are	O
often	O
tempted	O
to	O
summarize	O
the	O
posterior	B
distribution	B
by	O
computing	O
the	O
mean	O
or	O
the	O
maximum	B
likelihood	B
estimate	O
these	O
summaries	O
can	O
be	O
useful	O
but	O
if	O
that	O
s	O
all	O
you	O
need	O
then	O
you	O
probably	O
don	O
t	O
need	O
bayesian	O
methods	O
in	O
the	O
first	O
place	O
bayesian	O
methods	O
are	O
most	O
useful	O
when	O
you	O
can	O
carry	O
the	O
posterior	B
distribution	B
into	O
the	O
next	O
step	O
of	O
the	O
analysis	O
to	O
perform	O
some	O
kind	O
of	O
decision	B
analysis	I
as	O
we	O
did	O
in	O
this	O
chapter	O
or	O
some	O
kind	O
of	O
prediction	O
as	O
we	O
see	O
in	O
the	O
next	O
chapter	O
chapter	O
prediction	O
the	O
boston	B
bruins	I
problem	O
in	O
the	O
national	B
hockey	B
league	I
finals	O
my	O
beloved	O
boston	B
bruins	I
played	O
a	O
best-of-seven	O
championship	O
series	O
against	O
the	O
despised	O
vancouver	B
canucks	I
boston	B
lost	O
the	O
first	O
two	O
games	O
and	O
then	O
won	O
the	O
next	O
two	O
games	O
and	O
at	O
this	O
point	O
in	O
the	O
series	O
what	O
is	O
the	O
probability	B
that	O
boston	B
will	O
win	O
the	O
next	O
game	O
and	O
what	O
is	O
their	O
probability	B
of	O
winning	O
the	O
championship	O
as	O
always	O
to	O
answer	O
a	O
question	O
like	O
this	O
we	O
need	O
to	O
make	O
some	O
assumptions	O
first	O
it	O
is	O
reasonable	O
to	O
believe	O
that	O
goal	O
scoring	O
in	O
hockey	B
is	O
at	O
least	O
approximately	O
a	O
poisson	B
process	B
which	O
means	O
that	O
it	O
is	O
equally	O
likely	O
for	O
a	O
goal	O
to	O
be	O
scored	O
at	O
any	O
time	O
during	O
a	O
game	O
second	O
we	O
can	O
assume	O
that	O
against	O
a	O
particular	O
opponent	O
each	O
team	O
has	O
some	O
long-term	O
average	O
goals	O
per	O
game	O
denoted	O
given	O
these	O
assumptions	O
my	O
strategy	O
for	O
answering	O
this	O
question	O
is	O
use	O
statistics	O
from	O
previous	O
games	O
to	O
choose	O
a	O
prior	B
distribution	B
for	O
use	O
the	O
score	O
from	O
the	O
first	O
four	O
games	O
to	O
estimate	O
for	O
each	O
team	O
use	O
the	O
posterior	B
distributions	O
of	O
to	O
compute	O
distribution	B
of	O
goals	O
for	O
each	O
team	O
the	O
distribution	B
of	O
the	O
goal	O
differential	O
and	O
the	O
probability	B
that	O
each	O
team	O
wins	O
the	O
next	O
game	O
compute	O
the	O
probability	B
that	O
each	O
team	O
wins	O
the	O
series	O
chapter	O
prediction	O
to	O
choose	O
a	O
prior	B
distribution	B
i	O
got	O
some	O
statistics	O
from	O
httpwww	O
nhl	B
com	O
specifically	O
the	O
average	O
goals	O
per	O
game	O
for	O
each	O
team	O
in	O
the	O
season	O
the	O
distribution	B
is	O
roughly	O
gaussian	O
with	O
mean	O
and	O
standard	O
deviation	O
the	O
gaussian	B
distribution	B
is	O
continuous	O
but	O
we	O
ll	O
approximate	O
it	O
with	O
a	O
discrete	O
pmf	B
thinkbayes	O
provides	O
makegaussianpmf	O
to	O
do	O
exactly	O
that	O
def	O
makegaussianpmfmu	O
sigma	O
num	O
sigmas	O
pmf	B
pmf	B
low	O
mu	O
num	O
sigmassigma	O
high	O
mu	O
num	O
sigmassigma	O
for	O
x	O
in	O
numpy	B
linspacelow	O
high	O
n	O
p	O
scipy	B
stats	O
norm	O
pdfx	O
mu	O
sigma	O
pmf	B
setx	O
p	O
pmf	B
normalize	B
return	O
pmf	B
mu	O
and	O
sigma	O
are	O
the	O
mean	O
and	O
standard	O
deviation	O
of	O
the	O
gaussian	B
distribution	B
num	O
sigmas	O
is	O
the	O
number	O
of	O
standard	O
deviations	O
above	O
and	O
below	O
the	O
mean	O
that	O
the	O
pmf	B
will	O
span	O
and	O
n	O
is	O
the	O
number	O
of	O
values	O
in	O
the	O
pmf	B
again	O
we	O
use	O
numpy	B
linspace	B
to	O
make	O
an	O
array	O
of	O
n	O
equally	O
spaced	O
values	O
between	O
low	O
and	O
high	O
including	O
both	O
norm	O
pdf	B
evaluates	O
the	O
gaussian	O
probability	B
density	B
function	I
getting	O
back	O
to	O
the	O
hockey	B
problem	O
here	O
s	O
the	O
definition	O
for	O
a	O
suite	B
of	O
hypotheses	O
about	O
the	O
value	O
of	O
class	O
hockeythinkbayes	O
suite	B
def	O
pmf	B
thinkbayes	O
suite	B
init	O
self	O
pmf	B
so	O
the	O
prior	B
distribution	B
is	O
gaussian	O
with	O
mean	O
standard	O
deviation	O
and	O
it	O
spans	O
sigmas	O
above	O
and	O
below	O
the	O
mean	O
as	O
always	O
we	O
have	O
to	O
decide	O
how	O
to	O
represent	O
each	O
hypothesis	O
in	O
this	O
case	O
i	O
represent	O
the	O
hypothesis	O
that	O
x	O
with	O
the	O
floating-point	O
value	O
x	O
poisson	O
processes	O
poisson	O
processes	O
in	O
mathematical	O
statistics	O
a	O
process	B
is	O
a	O
stochastic	O
model	O
of	O
a	O
physical	O
system	B
stochastic	O
means	O
that	O
the	O
model	O
has	O
some	O
kind	O
of	O
randomness	O
in	O
it	O
for	O
example	O
a	O
bernoulli	B
process	B
is	O
a	O
model	O
of	O
a	O
sequence	O
of	O
events	O
called	O
trials	O
in	O
which	O
each	O
trial	O
has	O
two	O
possible	O
outcomes	O
like	O
success	O
and	O
failure	O
so	O
a	O
bernoulli	B
process	B
is	O
a	O
natural	O
model	O
for	O
a	O
series	O
of	O
coin	O
flips	O
or	O
a	O
series	O
of	O
shots	O
on	O
goal	O
a	O
poisson	B
process	B
is	O
the	O
continuous	O
version	O
of	O
a	O
bernoulli	B
process	B
where	O
an	O
event	O
can	O
occur	O
at	O
any	O
point	O
in	O
time	O
with	O
equal	O
probability	B
poisson	O
processes	O
can	O
be	O
used	O
to	O
model	O
customers	O
arriving	O
in	O
a	O
store	O
buses	O
arriving	O
at	O
a	O
bus	O
stop	O
or	O
goals	O
scored	O
in	O
a	O
hockey	B
game	O
in	O
many	O
real	O
systems	O
the	O
probability	B
of	O
an	O
event	O
changes	O
over	O
time	O
customers	O
are	O
more	O
likely	O
to	O
go	O
to	O
a	O
store	O
at	O
certain	O
times	O
of	O
day	O
buses	O
are	O
supposed	O
to	O
arrive	O
at	O
fixed	O
intervals	O
and	O
goals	O
are	O
more	O
or	O
less	O
likely	O
at	O
different	O
times	O
during	O
a	O
game	O
but	O
all	O
models	O
are	O
based	O
on	O
simplifications	O
and	O
in	O
this	O
case	O
modeling	B
a	O
hockey	B
game	O
with	O
a	O
poisson	B
process	B
is	O
a	O
reasonable	O
choice	O
heuer	B
m	O
ller	O
and	O
rubner	O
analyze	O
scoring	O
in	O
a	O
german	O
soccer	O
league	O
and	O
come	O
to	O
the	O
same	O
conclusion	O
see	O
poisson	O
pdf	B
the	O
benefit	O
of	O
using	O
this	O
model	O
is	O
that	O
we	O
can	O
compute	O
the	O
distribution	B
of	O
goals	O
per	O
game	O
efficiently	O
as	O
well	O
as	O
the	O
distribution	B
of	O
time	O
between	O
goals	O
specifically	O
if	O
the	O
average	O
number	O
of	O
goals	O
in	O
a	O
game	O
is	O
lam	O
the	O
distribution	B
of	O
goals	O
per	O
game	O
is	O
given	O
by	O
the	O
poisson	O
pmf	B
def	O
evalpoissonpmfk	O
lam	O
return	O
math	O
exp-lam	O
math	O
factorialk	O
and	O
the	O
distribution	B
of	O
time	O
between	O
goals	O
is	O
given	O
by	O
the	O
exponential	O
pdf	B
def	O
evalexponentialpdfx	O
lam	O
return	O
lam	O
math	O
exp-lam	O
x	O
i	O
use	O
the	O
variable	O
lam	O
because	O
lambda	O
is	O
a	O
reserved	O
keyword	O
in	O
python	O
both	O
of	O
these	O
functions	O
are	O
in	O
thinkbayes	O
py	O
the	O
posteriors	O
now	O
we	O
can	O
compute	O
the	O
likelihood	B
that	O
a	O
team	O
with	O
a	O
hypothetical	O
value	O
of	O
lam	O
scores	O
k	O
goals	O
in	O
a	O
game	O
chapter	O
prediction	O
figure	O
posterior	B
distribution	B
of	O
the	O
number	O
of	O
goals	O
per	O
game	O
class	O
hockey	B
def	O
likelihoodself	O
data	O
hypo	O
lam	O
hypo	O
k	O
data	O
like	O
thinkbayes	O
evalpoissonpmfk	O
lam	O
return	O
like	O
each	O
hypothesis	O
is	O
a	O
possible	O
value	O
of	O
data	O
is	O
the	O
observed	O
number	O
of	O
goals	O
k	O
with	O
the	O
likelihood	B
function	I
in	O
place	O
we	O
can	O
make	O
a	O
suite	B
for	O
each	O
team	O
and	O
update	B
them	O
with	O
the	O
scores	O
from	O
the	O
first	O
four	O
games	O
hockeybruins	O
hockeycanucks	O
figure	O
shows	O
the	O
resulting	O
posterior	B
distributions	O
for	O
lam	O
based	O
on	O
the	O
first	O
four	O
games	O
the	O
most	O
likely	O
values	O
for	O
lam	O
are	O
for	O
the	O
canucks	O
and	O
for	O
the	O
bruins	O
the	O
distribution	B
of	O
goals	O
to	O
compute	O
the	O
probability	B
that	O
each	O
team	O
wins	O
the	O
next	O
game	O
we	O
need	O
to	O
compute	O
the	O
distribution	B
of	O
goals	O
for	O
each	O
team	O
per	O
the	O
distribution	B
of	O
goals	O
figure	O
distribution	B
of	O
goals	O
in	O
a	O
single	O
game	O
if	O
we	O
knew	O
the	O
value	O
of	O
lam	O
exactly	O
we	O
could	O
use	O
the	O
poisson	B
distribution	B
again	O
thinkbayes	O
provides	O
a	O
method	O
that	O
computes	O
a	O
truncated	O
approximation	O
of	O
a	O
poisson	B
distribution	B
def	O
makepoissonpmflam	O
high	O
pmf	B
pmf	B
for	O
k	O
in	O
p	O
evalpoissonpmfk	O
lam	O
pmf	B
setk	O
p	O
pmf	B
normalize	B
return	O
pmf	B
the	O
range	O
of	O
values	O
in	O
the	O
computed	O
pmf	B
is	O
from	O
to	O
high	O
so	O
if	O
the	O
value	O
of	O
lam	O
were	O
exactly	O
we	O
would	O
compute	O
lam	O
goal	O
dist	O
thinkbayes	O
makepoissonpmflam	O
i	O
chose	O
the	O
upper	O
bound	O
because	O
the	O
probability	B
of	O
scoring	O
more	O
than	O
goals	O
in	O
a	O
game	O
is	O
quite	O
low	O
that	O
s	O
simple	O
enough	O
so	O
far	O
the	O
problem	O
is	O
that	O
we	O
don	O
t	O
know	O
the	O
value	O
of	O
lam	O
exactly	O
instead	O
we	O
have	O
a	O
distribution	B
of	O
possible	O
values	O
for	O
lam	O
for	O
each	O
value	O
of	O
lam	O
the	O
distribution	B
of	O
goals	O
is	O
poisson	O
so	O
the	O
overall	O
distribution	B
of	O
goals	O
is	O
a	O
mixture	B
of	O
these	O
poisson	O
distributions	O
weighted	O
according	O
to	O
the	O
probabilities	O
in	O
the	O
distribution	B
of	O
lam	O
given	O
the	O
posterior	B
distribution	B
of	O
lam	O
here	O
s	O
the	O
code	O
that	O
makes	O
the	O
distribution	B
of	O
goals	O
chapter	O
prediction	O
figure	O
distribution	B
of	O
time	O
between	O
goals	O
def	O
makegoalpmfsuite	O
metapmf	O
thinkbayes	O
pmf	B
for	O
lam	O
prob	B
in	O
suite	B
items	O
pmf	B
thinkbayes	O
makepoissonpmflam	O
metapmf	O
setpmf	O
prob	B
mix	O
thinkbayes	O
makemixturemetapmf	O
return	O
mix	O
for	O
each	O
value	O
of	O
lam	O
we	O
make	O
a	O
poisson	O
pmf	B
and	O
add	O
it	O
to	O
the	O
meta-pmf	B
i	O
call	O
it	O
a	O
meta-pmf	B
because	O
it	O
is	O
a	O
pmf	B
that	O
contains	O
pmfs	O
as	O
its	O
values	O
then	O
we	O
use	O
makemixture	B
to	O
compute	O
the	O
mixture	B
saw	O
makemixture	B
in	O
section	O
figure	O
shows	O
the	O
resulting	O
distribution	B
of	O
goals	O
for	O
the	O
bruins	O
and	O
canucks	O
the	O
bruins	O
are	O
less	O
likely	O
to	O
score	O
goals	O
or	O
fewer	O
in	O
the	O
next	O
game	O
and	O
more	O
likely	O
to	O
score	O
or	O
more	O
the	O
probability	B
of	O
winning	O
to	O
get	O
the	O
probability	B
of	O
winning	O
first	O
we	O
compute	O
the	O
distribution	B
of	O
the	O
goal	O
differential	O
diff	O
until	O
sudden	B
death	I
the	O
subtraction	O
operator	O
invokes	O
pmf	B
sub	O
which	O
enumerates	O
pairs	O
of	O
values	O
and	O
computes	O
the	O
difference	O
subtracting	O
two	O
distributions	O
is	O
almost	O
the	O
same	O
as	O
adding	O
which	O
we	O
saw	O
in	O
section	O
if	O
the	O
goal	O
differential	O
is	O
positive	O
the	O
bruins	O
win	O
if	O
negative	O
the	O
canucks	O
win	O
if	O
it	O
s	O
a	O
tie	O
p	O
win	O
p	O
loss	O
p	O
tie	O
with	O
the	O
distributions	O
from	O
the	O
previous	O
section	O
p	O
win	O
is	O
p	O
loss	O
is	O
and	O
p	O
tie	O
is	O
in	O
the	O
event	O
of	O
a	O
tie	O
at	O
the	O
end	O
of	O
regulation	O
play	O
the	O
teams	O
play	O
overtime	B
periods	O
until	O
one	O
team	O
scores	O
since	O
the	O
game	O
ends	O
immediately	O
when	O
the	O
first	O
goal	O
is	O
scored	O
this	O
overtime	B
format	O
is	O
known	O
as	O
sudden	B
death	I
sudden	B
death	I
to	O
compute	O
the	O
probability	B
of	O
winning	O
in	O
a	O
sudden	B
death	I
overtime	B
the	O
important	O
statistic	O
is	O
not	O
goals	O
per	O
game	O
but	O
time	O
until	O
the	O
first	O
goal	O
the	O
assumption	O
that	O
goal-scoring	O
is	O
a	O
poisson	B
process	B
implies	O
that	O
the	O
time	O
between	O
goals	O
is	O
exponentially	O
distributed	O
given	O
lam	O
we	O
can	O
compute	O
the	O
time	O
between	O
goals	O
like	O
this	O
lam	O
time	O
dist	O
thinkbayes	O
makeexponentialpmflam	O
high	O
is	O
the	O
upper	O
bound	O
of	O
the	O
distribution	B
in	O
this	O
case	O
i	O
chose	O
because	O
the	O
probability	B
of	O
going	O
more	O
than	O
two	O
games	O
without	O
scoring	O
is	O
small	O
n	O
is	O
the	O
number	O
of	O
values	O
in	O
the	O
pmf	B
if	O
we	O
know	O
lam	O
exactly	O
that	O
s	O
all	O
there	O
is	O
to	O
it	O
but	O
we	O
don	O
t	O
instead	O
we	O
have	O
a	O
posterior	B
distribution	B
of	O
possible	O
values	O
so	O
as	O
we	O
did	O
with	O
the	O
distribution	B
of	O
goals	O
we	O
make	O
a	O
meta-pmf	B
and	O
compute	O
a	O
mixture	B
of	O
pmfs	O
def	O
makegoaltimepmfsuite	O
metapmf	O
thinkbayes	O
pmf	B
for	O
lam	O
prob	B
in	O
suite	B
items	O
pmf	B
thinkbayes	O
makeexponentialpmflam	O
metapmf	O
setpmf	O
prob	B
chapter	O
prediction	O
mix	O
thinkbayes	O
makemixturemetapmf	O
return	O
mix	O
figure	O
shows	O
the	O
resulting	O
distributions	O
for	O
time	O
values	O
less	O
than	O
one	O
period	O
third	O
of	O
a	O
game	O
the	O
bruins	O
are	O
more	O
likely	O
to	O
score	O
the	O
time	O
until	O
the	O
canucks	O
score	O
is	O
more	O
likely	O
to	O
be	O
longer	O
i	O
set	O
the	O
number	O
of	O
values	O
n	O
fairly	O
high	O
in	O
order	O
to	O
minimize	O
the	O
number	O
of	O
ties	O
since	O
it	O
is	O
not	O
possible	O
for	O
both	O
teams	O
to	O
score	O
simultaneously	O
now	O
we	O
compute	O
the	O
probability	B
that	O
the	O
bruins	O
score	O
first	O
p	O
overtime	B
for	O
the	O
bruins	O
the	O
probability	B
of	O
winning	O
in	O
overtime	B
is	O
finally	O
the	O
total	B
probability	B
of	O
winning	O
is	O
the	O
chance	O
of	O
winning	O
at	O
the	O
end	O
of	O
regulation	O
play	O
plus	O
the	O
probability	B
of	O
winning	O
in	O
overtime	B
p	O
tie	O
p	O
overtime	B
p	O
win	O
p	O
tie	O
p	O
overtime	B
for	O
the	O
bruins	O
the	O
overall	O
chance	O
of	O
winning	O
the	O
next	O
game	O
is	O
to	O
win	O
the	O
series	O
the	O
bruins	O
can	O
either	O
win	O
the	O
next	O
two	O
games	O
or	O
split	O
the	O
next	O
two	O
and	O
win	O
the	O
third	O
again	O
we	O
can	O
compute	O
the	O
total	B
probability	B
win	O
the	O
next	O
two	O
p	O
series	O
split	O
the	O
next	O
two	O
win	O
the	O
third	O
p	O
series	O
p	O
win	O
p	O
win	O
the	O
bruins	O
chance	O
of	O
winning	O
the	O
series	O
is	O
and	O
in	O
they	O
did	O
discussion	O
as	O
always	O
the	O
analysis	O
in	O
this	O
chapter	O
is	O
based	O
on	O
modeling	B
decisions	O
and	O
modeling	B
is	O
almost	O
always	O
an	O
iterative	O
process	B
in	O
general	O
you	O
want	O
to	O
start	O
with	O
something	O
simple	O
that	O
yields	O
an	O
approximate	O
answer	O
identify	O
likely	O
sources	O
of	O
error	B
and	O
look	O
for	O
opportunities	O
for	O
improvement	O
in	O
this	O
example	O
i	O
would	O
consider	O
these	O
options	O
discussion	O
i	O
chose	O
a	O
prior	B
based	O
on	O
the	O
average	O
goals	O
per	O
game	O
for	O
each	O
team	O
but	O
this	O
statistic	O
is	O
averaged	O
across	O
all	O
opponents	O
against	O
a	O
particular	O
opponent	O
we	O
might	O
expect	O
more	O
variability	O
for	O
example	O
if	O
the	O
team	O
with	O
the	O
best	O
offense	O
plays	O
the	O
team	O
with	O
the	O
worst	O
defense	O
the	O
expected	O
goals	O
per	O
game	O
might	O
be	O
several	O
standard	O
deviations	O
above	O
the	O
mean	O
for	O
data	O
i	O
used	O
only	O
the	O
first	O
four	O
games	O
of	O
the	O
championship	O
series	O
if	O
the	O
same	O
teams	O
played	O
each	O
other	O
during	O
the	O
regular	O
season	O
i	O
could	O
use	O
the	O
results	O
from	O
those	O
games	O
as	O
well	O
one	O
complication	O
is	O
that	O
the	O
composition	O
of	O
teams	O
changes	O
during	O
the	O
season	O
due	O
to	O
trades	O
and	O
injuries	O
so	O
it	O
might	O
be	O
best	O
to	O
give	O
more	O
weight	O
to	O
recent	O
games	O
to	O
take	O
advantage	O
of	O
all	O
available	O
information	O
we	O
could	O
use	O
results	O
from	O
all	O
regular	O
season	O
games	O
to	O
estimate	O
each	O
team	O
s	O
goal	O
scoring	O
rate	O
possibly	O
adjusted	O
by	O
estimating	O
an	O
additional	O
factor	O
for	O
each	O
pairwise	O
match-up	O
this	O
approach	O
would	O
be	O
more	O
complicated	O
but	O
it	O
is	O
still	O
feasible	O
for	O
the	O
first	O
option	O
we	O
could	O
use	O
the	O
results	O
from	O
the	O
regular	O
season	O
to	O
estimate	O
the	O
variability	O
across	O
all	O
pairwise	O
match-ups	O
thanks	O
to	O
dirk	O
hoag	B
at	O
httpforechecker	O
blogspot	O
com	O
i	O
was	O
able	O
to	O
get	O
the	O
number	O
of	O
goals	O
scored	O
during	O
regulation	O
play	O
overtime	B
for	O
each	O
game	O
in	O
the	O
regular	O
season	O
teams	O
in	O
different	O
conferences	O
only	O
play	O
each	O
other	O
one	O
or	O
two	O
times	O
in	O
the	O
regular	O
season	O
so	O
i	O
focused	O
on	O
pairs	O
that	O
played	O
each	O
other	O
times	O
for	O
each	O
pair	O
i	O
computed	O
the	O
average	O
goals	O
per	O
game	O
which	O
is	O
an	O
estimate	O
of	O
then	O
plotted	O
the	O
distribution	B
of	O
these	O
estimates	O
the	O
mean	O
of	O
these	O
estimates	O
is	O
again	O
but	O
the	O
standard	O
deviation	O
is	O
substantially	O
higher	O
than	O
what	O
we	O
got	O
computing	O
one	O
estimate	O
for	O
each	O
team	O
if	O
we	O
run	O
the	O
analysis	O
again	O
with	O
the	O
higher-variance	O
prior	B
the	O
probability	B
that	O
the	O
bruins	O
win	O
the	O
series	O
is	O
substantially	O
higher	O
than	O
the	O
result	O
with	O
the	O
low-variance	O
prior	B
so	O
it	O
turns	O
out	O
that	O
the	O
results	O
are	O
sensitive	O
to	O
the	O
prior	B
which	O
makes	O
sense	O
considering	O
how	O
little	O
data	O
we	O
have	O
to	O
work	O
with	O
based	O
on	O
the	O
difference	O
between	O
the	O
low-variance	O
model	O
and	O
the	O
high-variable	O
model	O
it	O
seems	O
worthwhile	O
to	O
put	O
some	O
effort	O
into	O
getting	O
the	O
prior	B
right	O
chapter	O
prediction	O
the	O
code	O
and	O
data	O
for	O
this	O
chapter	O
are	O
available	O
from	O
httpthinkbayes	O
comhockey	O
py	O
and	O
httpthinkbayes	O
comhockey	O
data	O
csv	O
for	O
more	O
information	O
see	O
section	O
exercises	O
exercise	O
if	O
buses	O
arrive	O
at	O
a	O
bus	O
stop	O
every	O
minutes	O
and	O
you	O
arrive	O
at	O
the	O
bus	O
stop	O
at	O
a	O
random	O
time	O
your	O
wait	O
time	O
until	O
the	O
bus	O
arrives	O
is	O
uniformly	O
distributed	O
from	O
to	O
minutes	O
but	O
in	O
reality	O
there	O
is	O
variability	O
in	O
the	O
time	O
between	O
buses	O
suppose	O
you	O
are	O
waiting	O
for	O
a	O
bus	O
and	O
you	O
know	O
the	O
historical	O
distribution	B
of	O
time	O
between	O
buses	O
compute	O
your	O
distribution	B
of	O
wait	O
times	O
hint	O
suppose	O
that	O
the	O
time	O
between	O
buses	O
is	O
either	O
or	O
minutes	O
with	O
equal	O
probability	B
what	O
is	O
the	O
probability	B
that	O
you	O
arrive	O
during	O
one	O
of	O
the	O
minute	O
intervals	O
i	O
solve	O
a	O
version	O
of	O
this	O
problem	O
in	O
the	O
next	O
chapter	O
exercise	O
suppose	O
that	O
passengers	O
arriving	O
at	O
the	O
bus	O
stop	O
are	O
well-modeled	O
by	O
a	O
poisson	B
process	B
with	O
parameter	B
if	O
you	O
arrive	O
at	O
the	O
stop	O
and	O
find	O
people	O
waiting	O
what	O
is	O
your	O
posterior	B
distribution	B
for	O
the	O
time	O
since	O
the	O
last	O
bus	O
arrived	O
i	O
solve	O
a	O
version	O
of	O
this	O
problem	O
in	O
the	O
next	O
chapter	O
exercise	O
suppose	O
that	O
you	O
are	O
an	O
ecologist	O
sampling	O
the	O
insect	O
population	O
in	O
a	O
new	O
environment	O
you	O
deploy	O
traps	O
in	O
a	O
test	O
area	O
and	O
come	O
back	O
the	O
next	O
day	O
to	O
check	O
on	O
them	O
you	O
find	O
that	O
traps	O
have	O
been	O
triggered	O
trapping	O
an	O
insect	O
inside	O
once	O
a	O
trap	O
triggers	O
it	O
cannot	O
trap	O
another	O
insect	O
until	O
it	O
has	O
been	O
reset	O
if	O
you	O
reset	O
the	O
traps	O
and	O
come	O
back	O
in	O
two	O
days	O
how	O
many	O
traps	O
do	O
you	O
expect	O
to	O
find	O
triggered	O
compute	O
a	O
posterior	B
predictive	B
distribution	B
for	O
the	O
number	O
of	O
traps	O
exercise	O
suppose	O
you	O
are	O
the	O
manager	O
of	O
an	O
apartment	O
building	O
with	O
light	O
bulbs	O
in	O
common	O
areas	O
it	O
is	O
your	O
responsibility	O
to	O
replace	O
light	O
bulbs	O
when	O
they	O
break	O
on	O
january	O
all	O
bulbs	O
are	O
working	O
when	O
you	O
inspect	O
them	O
on	O
february	O
you	O
find	O
light	O
bulbs	O
out	O
if	O
you	O
come	O
back	O
on	O
april	O
how	O
many	O
light	O
bulbs	O
do	O
you	O
expect	O
to	O
find	O
broken	O
in	O
the	O
previous	O
exercise	O
you	O
could	O
reasonably	O
assume	O
that	O
an	O
event	O
is	O
equally	O
likely	O
at	O
any	O
time	O
for	O
light	O
bulbs	O
the	O
likelihood	B
of	O
failure	O
depends	O
on	O
the	O
age	O
of	O
the	O
exercises	O
bulb	O
specifically	O
old	O
bulbs	O
have	O
an	O
increasing	O
failure	O
rate	O
due	O
to	O
evaporation	O
of	O
the	O
filament	O
this	O
problem	O
is	O
more	O
open-ended	O
than	O
some	O
you	O
will	O
have	O
to	O
make	O
modeling	B
decisions	O
you	O
might	O
want	O
to	O
read	O
about	O
the	O
weibull	B
distribution	B
en	O
wikipedia	O
org	O
wiki	O
weibull	B
distribution	B
or	O
you	O
might	O
want	O
to	O
look	O
around	O
for	O
information	O
about	O
light	O
bulb	O
survival	O
curves	O
chapter	O
prediction	O
chapter	O
observer	B
bias	I
the	O
red	B
line	I
problem	I
in	O
massachusetts	O
the	O
red	O
line	O
is	O
a	O
subway	O
that	O
connects	O
cambridge	O
and	O
boston	B
when	O
i	O
was	O
working	O
in	O
cambridge	O
i	O
took	O
the	O
red	O
line	O
from	O
kendall	O
square	O
to	O
south	O
station	O
and	O
caught	O
the	O
commuter	O
rail	O
to	O
needham	O
during	O
rush	O
hour	O
red	O
line	O
trains	O
run	O
every	O
minutes	O
on	O
average	O
when	O
i	O
arrived	O
at	O
the	O
station	O
i	O
could	O
estimate	O
the	O
time	O
until	O
the	O
next	O
train	O
based	O
on	O
the	O
number	O
of	O
passengers	O
on	O
the	O
platform	O
if	O
there	O
were	O
only	O
a	O
few	O
people	O
i	O
inferred	O
that	O
i	O
just	O
missed	O
a	O
train	O
and	O
expected	O
to	O
wait	O
about	O
minutes	O
if	O
there	O
were	O
more	O
passengers	O
i	O
expected	O
the	O
train	O
to	O
arrive	O
sooner	O
but	O
if	O
there	O
were	O
a	O
large	O
number	O
of	O
passengers	O
i	O
suspected	O
that	O
trains	O
were	O
not	O
running	O
on	O
schedule	O
so	O
i	O
would	O
go	O
back	O
to	O
the	O
street	O
level	O
and	O
get	O
a	O
taxi	O
while	O
i	O
was	O
waiting	O
for	O
trains	O
i	O
thought	O
about	O
how	O
bayesian	O
estimation	O
could	O
help	O
predict	O
my	O
wait	O
time	O
and	O
decide	O
when	O
i	O
should	O
give	O
up	O
and	O
take	O
a	O
taxi	O
this	O
chapter	O
presents	O
the	O
analysis	O
i	O
came	O
up	O
with	O
this	O
chapter	O
is	O
based	O
on	O
a	O
project	O
by	O
brendan	O
ritter	O
and	O
kai	O
austin	O
who	O
took	O
a	O
class	O
with	O
me	O
at	O
olin	B
college	I
the	O
code	O
in	O
this	O
chapter	O
is	O
available	O
from	O
httpthinkbayes	O
comredline	O
py	O
the	O
code	O
i	O
used	O
to	O
collect	O
data	O
is	O
in	O
httpthinkbayes	O
comredline	O
data	O
py	O
for	O
more	O
information	O
see	O
section	O
chapter	O
observer	B
bias	I
figure	O
pmf	B
of	O
gaps	O
between	O
trains	O
based	O
on	O
collected	O
data	O
smoothed	O
by	O
kde	B
z	O
is	O
the	O
actual	O
distribution	B
zb	O
is	O
the	O
biased	O
distribution	B
seen	O
by	O
passengers	O
the	O
model	O
before	O
we	O
get	O
to	O
the	O
analysis	O
we	O
have	O
to	O
make	O
some	O
modeling	B
decisions	O
first	O
i	O
will	O
treat	O
passenger	O
arrivals	O
as	O
a	O
poisson	B
process	B
which	O
means	O
i	O
assume	O
that	O
passengers	O
are	O
equally	O
likely	O
to	O
arrive	O
at	O
any	O
time	O
and	O
that	O
they	O
arrive	O
at	O
an	O
unknown	O
rate	O
measured	O
in	O
passengers	O
per	O
minute	O
since	O
i	O
observe	O
passengers	O
during	O
a	O
short	O
period	O
of	O
time	O
and	O
at	O
the	O
same	O
time	O
every	O
day	O
i	O
assume	O
that	O
is	O
constant	O
on	O
the	O
other	O
hand	O
the	O
arrival	O
process	B
for	O
trains	O
is	O
not	O
poisson	O
trains	O
to	O
boston	B
are	O
supposed	O
to	O
leave	O
from	O
the	O
end	O
of	O
the	O
line	O
station	O
every	O
minutes	O
during	O
peak	O
times	O
but	O
by	O
the	O
time	O
they	O
get	O
to	O
kendall	O
square	O
the	O
time	O
between	O
trains	O
varies	O
between	O
and	O
minutes	O
to	O
gather	O
data	O
on	O
the	O
time	O
between	O
trains	O
i	O
wrote	O
a	O
script	O
that	O
downloads	O
real-time	O
data	O
from	O
httpwww	O
mbta	O
comrider	O
toolsdevelopers	O
selects	O
south-bound	O
trains	O
arriving	O
at	O
kendall	O
square	O
and	O
records	O
their	O
arrival	O
times	O
in	O
a	O
database	O
i	O
ran	O
the	O
script	O
from	O
to	O
every	O
weekday	O
for	O
days	O
and	O
recorded	O
about	O
arrivals	O
per	O
day	O
then	O
i	O
computed	O
the	O
time	O
between	O
consecutive	O
arrivals	O
the	O
distribution	B
of	O
these	O
gaps	O
is	O
shown	O
in	O
figure	O
labeled	O
z	O
if	O
you	O
stood	O
on	O
the	O
platform	O
from	O
to	O
and	O
recorded	O
the	O
time	O
between	O
trains	O
this	O
is	O
the	O
distribution	B
you	O
would	O
see	O
but	O
if	O
you	O
arrive	O
at	O
some	O
random	O
time	O
regard	O
to	O
the	O
train	O
schedule	O
you	O
would	O
see	O
a	O
wait	O
times	O
different	O
distribution	B
the	O
average	O
time	O
between	O
trains	O
as	O
seen	O
by	O
a	O
random	O
passenger	O
is	O
substantially	O
higher	O
than	O
the	O
true	O
average	O
why	O
because	O
a	O
passenger	O
is	O
more	O
like	O
to	O
arrive	O
during	O
a	O
large	O
interval	O
than	O
a	O
small	O
one	O
consider	O
a	O
simple	O
example	O
suppose	O
that	O
the	O
time	O
between	O
trains	O
is	O
either	O
minutes	O
or	O
minutes	O
with	O
equal	O
probability	B
in	O
that	O
case	O
the	O
average	O
time	O
between	O
trains	O
is	O
minutes	O
but	O
a	O
passenger	O
is	O
more	O
likely	O
to	O
arrive	O
during	O
a	O
minute	O
gap	O
than	O
a	O
minute	O
gap	O
in	O
fact	O
twice	O
as	O
likely	O
if	O
we	O
surveyed	O
arriving	O
passengers	O
we	O
would	O
find	O
that	O
of	O
them	O
arrived	O
during	O
a	O
minute	O
gap	O
and	O
only	O
during	O
a	O
minute	O
gap	O
so	O
the	O
average	O
time	O
between	O
trains	O
as	O
seen	O
by	O
an	O
arriving	O
passenger	O
is	O
minutes	O
this	O
kind	O
of	O
observer	B
bias	I
appears	O
in	O
many	O
contexts	O
students	O
think	O
that	O
classes	O
are	O
bigger	O
than	O
they	O
are	O
because	O
more	O
of	O
them	O
are	O
in	O
the	O
big	O
classes	O
airline	O
passengers	O
think	O
that	O
planes	O
are	O
fuller	O
than	O
they	O
are	O
because	O
more	O
of	O
them	O
are	O
on	O
full	O
flights	O
in	O
each	O
case	O
values	O
from	O
the	O
actual	O
distribution	B
are	O
oversampled	O
in	O
proportion	O
to	O
their	O
value	O
in	O
the	O
red	O
line	O
example	O
a	O
gap	O
that	O
is	O
twice	O
as	O
big	O
is	O
twice	O
as	O
likely	O
to	O
be	O
observed	O
so	O
given	O
the	O
actual	O
distribution	B
of	O
gaps	O
we	O
can	O
compute	O
the	O
distribution	B
of	O
gaps	O
as	O
seen	O
by	O
passengers	O
biaspmf	O
does	O
this	O
computation	O
def	O
biaspmfpmf	O
new	O
pmf	B
pmf	B
copy	O
for	O
x	O
p	O
in	O
pmf	B
items	O
new	O
pmf	B
multx	O
x	O
new	O
pmf	B
normalize	B
return	O
new	O
pmf	B
pmf	B
is	O
the	O
actual	O
distribution	B
new	O
pmf	B
is	O
the	O
biased	O
distribution	B
inside	O
the	O
loop	O
we	O
multiply	O
the	O
probability	B
of	O
each	O
value	O
x	O
by	O
the	O
likelihood	B
it	O
will	O
be	O
observed	O
which	O
is	O
proportional	O
to	O
x	O
then	O
we	O
normalize	B
the	O
result	O
figure	O
shows	O
the	O
actual	O
distribution	B
of	O
gaps	O
labeled	O
z	O
and	O
the	O
distribution	B
of	O
gaps	O
seen	O
by	O
passengers	O
labeled	O
zb	O
for	O
z	O
biased	O
chapter	O
observer	B
bias	I
figure	O
cdf	B
of	O
z	O
zb	O
and	O
the	O
wait	O
time	O
seen	O
by	O
passengers	O
y	O
wait	O
times	O
wait	O
time	O
which	O
i	O
call	O
y	O
is	O
the	O
time	O
between	O
the	O
arrival	O
of	O
a	O
passenger	O
and	O
the	O
next	O
arrival	O
of	O
a	O
train	O
elapsed	O
time	O
which	O
i	O
call	O
x	O
is	O
the	O
time	O
between	O
the	O
arrival	O
of	O
the	O
previous	O
train	O
and	O
the	O
arrival	O
of	O
a	O
passenger	O
i	O
chose	O
these	O
definitions	O
so	O
that	O
zb	O
x	O
y	O
given	O
the	O
distribution	B
of	O
zb	O
we	O
can	O
compute	O
the	O
distribution	B
of	O
y	O
i	O
ll	O
start	O
with	O
a	O
simple	O
case	O
and	O
then	O
generalize	O
suppose	O
as	O
in	O
the	O
previous	O
example	O
that	O
zb	O
is	O
either	O
minutes	O
with	O
probability	B
or	O
minutes	O
with	O
probability	B
if	O
we	O
arrive	O
at	O
a	O
random	O
time	O
during	O
a	O
minute	O
gap	O
y	O
is	O
uniform	O
from	O
to	O
minutes	O
if	O
we	O
arrive	O
during	O
a	O
minute	O
gap	O
y	O
is	O
uniform	O
from	O
to	O
so	O
the	O
overall	O
distribution	B
is	O
a	O
mixture	B
of	O
uniform	O
distributions	O
weighted	O
according	O
to	O
the	O
probability	B
of	O
each	O
gap	O
the	O
following	O
function	O
takes	O
the	O
distribution	B
of	O
zb	O
and	O
computes	O
the	O
distribution	B
of	O
y	O
def	O
pmfofwaittimepmf	O
zb	O
metapmf	O
thinkbayes	O
pmf	B
for	O
gap	O
prob	B
in	O
pmf	B
zb	O
items	O
uniform	O
gap	O
metapmf	O
setuniform	O
prob	B
pmf	B
y	O
thinkbayes	O
makemixturemetapmf	O
return	O
pmf	B
y	O
wait	O
times	O
pmfofwaittime	O
makes	O
a	O
meta-pmf	B
that	O
maps	O
from	O
each	O
uniform	B
distribution	B
to	O
its	O
probability	B
then	O
it	O
uses	O
makemixture	B
which	O
we	O
saw	O
in	O
section	O
to	O
compute	O
the	O
mixture	B
pmfofwaittime	O
also	O
uses	O
makeuniformpmf	O
defined	O
here	O
def	O
makeuniformpmflow	O
high	O
pmf	B
thinkbayes	O
pmf	B
for	O
x	O
in	O
makerangelowlow	O
highhigh	O
pmf	B
setx	O
pmf	B
normalize	B
return	O
pmf	B
low	O
and	O
high	O
are	O
the	O
range	O
of	O
the	O
uniform	B
distribution	B
ends	O
included	O
finally	O
makeuniformpmf	O
uses	O
makerange	O
defined	O
here	O
def	O
makerangelow	O
high	O
return	O
rangelow	O
highskip	O
skip	O
makerange	O
defines	O
a	O
set	O
of	O
possible	O
values	O
for	O
wait	O
time	O
in	O
seconds	O
by	O
default	O
it	O
divides	O
the	O
range	O
into	O
second	O
intervals	O
to	O
encapsulate	O
the	O
process	B
of	O
computing	O
these	O
distributions	O
i	O
created	O
a	O
class	O
called	O
waittimecalculator	O
class	O
waittimecalculatorobject	O
def	O
pmf	B
z	O
self	O
pmf	B
z	O
pmf	B
z	O
self	O
pmf	B
zb	O
biaspmfpmf	O
self	O
pmf	B
y	O
self	O
pmfofwaittimeself	O
pmf	B
zb	O
self	O
pmf	B
x	O
self	O
pmf	B
y	O
the	O
parameter	B
pmf	B
z	O
is	O
the	O
unbiased	O
distribution	B
of	O
z	O
pmf	B
zb	O
is	O
the	O
biased	O
distribution	B
of	O
gap	O
time	O
as	O
seen	O
by	O
passengers	O
pmf	B
y	O
is	O
the	O
distribution	B
of	O
wait	O
time	O
pmf	B
x	O
is	O
the	O
distribution	B
of	O
elapsed	O
time	O
which	O
is	O
the	O
same	O
as	O
the	O
distribution	B
of	O
wait	O
time	O
to	O
see	O
why	O
remember	O
that	O
for	O
a	O
particular	O
value	O
of	O
zp	O
the	O
distribution	B
of	O
y	O
is	O
uniform	O
from	O
to	O
zp	O
also	O
x	O
zp	O
y	O
so	O
the	O
distribution	B
of	O
x	O
is	O
also	O
uniform	O
from	O
to	O
zp	O
figure	O
shows	O
the	O
distribution	B
of	O
z	O
zb	O
and	O
y	O
based	O
on	O
the	O
data	O
i	O
collected	O
from	O
the	O
red	O
line	O
web	O
site	O
chapter	O
observer	B
bias	I
figure	O
prior	B
and	O
posterior	B
of	O
x	O
and	O
predicted	O
y	O
to	O
present	O
these	O
distributions	O
i	O
am	O
switching	O
from	O
pmfs	O
to	O
cdfs	O
most	O
people	O
are	O
more	O
familiar	O
with	O
pmfs	O
but	O
i	O
think	O
cdfs	O
are	O
easier	O
to	O
interpret	O
once	O
you	O
get	O
used	O
to	O
them	O
and	O
if	O
you	O
want	O
to	O
plot	O
several	O
distributions	O
on	O
the	O
same	O
axes	O
cdfs	O
are	O
the	O
way	O
to	O
go	O
the	O
mean	O
of	O
z	O
is	O
minutes	O
the	O
mean	O
of	O
zb	O
is	O
minutes	O
about	O
higher	O
the	O
mean	O
of	O
y	O
is	O
half	O
the	O
mean	O
of	O
zb	O
as	O
an	O
aside	O
the	O
red	O
line	O
schedule	O
reports	O
that	O
trains	O
run	O
every	O
minutes	O
during	O
peak	O
times	O
this	O
is	O
close	O
to	O
the	O
average	O
of	O
zb	O
but	O
higher	O
than	O
the	O
average	O
of	O
z	O
i	O
exchanged	O
email	O
with	O
a	O
representative	O
of	O
the	O
mbta	O
who	O
confirmed	O
that	O
the	O
reported	O
time	O
between	O
trains	O
is	O
deliberately	O
conservative	O
in	O
order	O
to	O
account	O
for	O
variability	O
predicting	O
wait	O
times	O
let	O
s	O
get	O
back	O
to	O
the	O
motivating	O
question	O
suppose	O
that	O
when	O
i	O
arrive	O
at	O
the	O
platform	O
i	O
see	O
people	O
waiting	O
how	O
long	O
should	O
i	O
expect	O
to	O
wait	O
until	O
the	O
next	O
train	O
arrives	O
as	O
always	O
let	O
s	O
start	O
with	O
the	O
easiest	O
version	O
of	O
the	O
problem	O
and	O
work	O
our	O
way	O
up	O
suppose	O
we	O
are	O
given	O
the	O
actual	O
distribution	B
of	O
z	O
and	O
we	O
know	O
that	O
the	O
passenger	O
arrival	B
rate	I
is	O
passengers	O
per	O
minute	O
in	O
that	O
case	O
we	O
can	O
use	O
the	O
distribution	B
of	O
z	O
to	O
compute	O
the	O
prior	B
distribution	B
of	O
zp	O
the	O
time	O
between	O
trains	O
as	O
seen	O
by	O
a	O
passenger	O
xposterior	O
xpred	O
y	O
predicting	O
wait	O
times	O
then	O
we	O
can	O
use	O
the	O
number	O
of	O
passengers	O
to	O
estimate	O
the	O
distribution	B
of	O
x	O
the	O
elapsed	O
time	O
since	O
the	O
last	O
train	O
finally	O
we	O
use	O
the	O
relation	O
y	O
zp	O
x	O
to	O
get	O
the	O
distribution	B
of	O
y	O
the	O
first	O
step	O
is	O
to	O
create	O
a	O
waittimecalculator	O
that	O
encapsulates	O
the	O
distributions	O
of	O
zp	O
x	O
and	O
y	O
prior	B
to	O
taking	O
into	O
account	O
the	O
number	O
of	O
passengers	O
wtc	O
waittimecalculatorpmf	O
z	O
pmf	B
z	O
is	O
the	O
given	O
distribution	B
of	O
gap	O
times	O
the	O
next	O
step	O
is	O
to	O
make	O
an	O
elapsedtimeestimator	O
below	O
which	O
encapsulates	O
the	O
posterior	B
distribution	B
of	O
x	O
and	O
the	O
predictive	B
distribution	B
of	O
y	O
ete	O
elapsedtimeestimatorwtc	O
the	O
parameters	O
are	O
the	O
waittimecalculator	O
the	O
passenger	O
arrival	B
rate	I
lam	O
in	O
passengers	O
per	O
second	O
and	O
the	O
observed	O
number	O
of	O
passengers	O
let	O
s	O
say	O
here	O
is	O
the	O
definition	O
of	O
elapsedtimeestimator	O
class	O
elapsedtimeestimatorobject	O
def	O
wtc	O
lam	O
num	O
passengers	O
self	O
prior	B
x	O
elapsedwtc	O
pmf	B
x	O
self	O
post	O
x	O
self	O
prior	B
x	O
copy	O
self	O
post	O
x	O
updatelam	O
num	O
passengers	O
self	O
pmf	B
y	O
predictwaittimewtc	O
pmf	B
zb	O
self	O
post	O
x	O
prior	B
x	O
and	O
posterior	B
x	O
are	O
the	O
prior	B
and	O
posterior	B
distributions	O
of	O
elapsed	O
time	O
pmf	B
y	O
is	O
the	O
predictive	B
distribution	B
of	O
wait	O
time	O
elapsedtimeestimator	O
uses	O
elapsed	O
and	O
predictwaittime	O
defined	O
below	O
elapsed	O
is	O
a	O
suite	B
that	O
represents	O
the	O
hypothetical	O
distribution	B
of	O
x	O
the	O
prior	B
distribution	B
of	O
x	O
comes	O
straight	O
from	O
the	O
waittimecalculator	O
then	O
we	O
use	O
the	O
data	O
which	O
consists	O
of	O
the	O
arrival	B
rate	I
lam	O
and	O
the	O
number	O
of	O
passengers	O
on	O
the	O
platform	O
to	O
compute	O
the	O
posterior	B
distribution	B
here	O
s	O
the	O
definition	O
of	O
elapsed	O
chapter	O
observer	B
bias	I
class	O
elapsedthinkbayes	O
suite	B
def	O
likelihoodself	O
data	O
hypo	O
x	O
hypo	O
lam	O
k	O
data	O
like	O
thinkbayes	O
evalpoissonpmfk	O
lam	O
x	O
return	O
like	O
as	O
always	O
likelihood	B
takes	O
a	O
hypothesis	O
and	O
data	O
and	O
computes	O
the	O
likelihood	B
of	O
the	O
data	O
under	O
the	O
hypothesis	O
in	O
this	O
case	O
hypo	O
is	O
the	O
elapsed	O
time	O
since	O
the	O
last	O
train	O
and	O
data	O
is	O
a	O
tuple	B
of	O
lam	O
and	O
the	O
number	O
of	O
passengers	O
the	O
likelihood	B
of	O
the	O
data	O
is	O
the	O
probability	B
of	O
getting	O
k	O
arrivals	O
in	O
x	O
time	O
given	O
arrival	B
rate	I
lam	O
we	O
compute	O
that	O
using	O
the	O
pmf	B
of	O
the	O
poisson	B
distribution	B
finally	O
here	O
s	O
the	O
definition	O
of	O
predictwaittime	O
def	O
predictwaittimepmf	O
zb	O
pmf	B
x	O
pmf	B
y	O
pmf	B
zb	O
pmf	B
x	O
removenegativespmf	O
y	O
return	O
pmf	B
y	O
pmf	B
zb	O
is	O
the	O
distribution	B
of	O
gaps	O
between	O
trains	O
pmf	B
x	O
is	O
the	O
distribution	B
of	O
elapsed	O
time	O
based	O
on	O
the	O
observed	O
number	O
of	O
passengers	O
since	O
y	O
zb	O
x	O
we	O
can	O
compute	O
pmf	B
y	O
pmf	B
zb	O
pmf	B
x	O
the	O
subtraction	O
operator	O
invokes	O
pmf	B
sub	O
which	O
enumerates	O
all	O
pairs	O
of	O
zb	O
and	O
x	O
computes	O
the	O
differences	O
and	O
adds	O
the	O
results	O
to	O
pmf	B
y	O
the	O
resulting	O
pmf	B
includes	O
some	O
negative	O
values	O
which	O
we	O
know	O
are	O
impossible	O
for	O
example	O
if	O
you	O
arrive	O
during	O
a	O
gap	O
of	O
minutes	O
you	O
can	O
t	O
wait	O
more	O
than	O
minutes	O
removenegatives	O
removes	O
the	O
impossible	O
values	O
from	O
the	O
distribution	B
and	O
renormalizes	O
def	O
removenegativespmf	O
for	O
val	O
in	O
pmf	B
values	O
if	O
val	O
pmf	B
removeval	O
pmf	B
normalize	B
figure	O
shows	O
the	O
results	O
the	O
prior	B
distribution	B
of	O
x	O
is	O
the	O
same	O
as	O
the	O
distribution	B
of	O
y	O
in	O
figure	O
the	O
posterior	B
distribution	B
of	O
x	O
shows	O
that	O
after	O
seeing	O
passengers	O
on	O
the	O
platform	O
we	O
believe	O
that	O
the	O
time	O
since	O
estimating	O
the	O
arrival	B
rate	I
figure	O
prior	B
and	O
posterior	B
distributions	O
of	O
lam	O
based	O
on	O
five	O
days	O
of	O
passenger	O
data	O
the	O
last	O
train	O
is	O
probably	O
minutes	O
the	O
predictive	B
distribution	B
of	O
y	O
indicates	O
that	O
we	O
expect	O
the	O
next	O
train	O
in	O
less	O
than	O
minutes	O
with	O
about	O
confidence	O
estimating	O
the	O
arrival	B
rate	I
the	O
analysis	O
so	O
far	O
has	O
been	O
based	O
on	O
the	O
assumption	O
that	O
we	O
know	O
the	O
distribution	B
of	O
gaps	O
and	O
the	O
passenger	O
arrival	B
rate	I
now	O
we	O
are	O
ready	O
to	O
relax	O
the	O
second	O
assumption	O
suppose	O
that	O
you	O
just	O
moved	O
to	O
boston	B
so	O
you	O
don	O
t	O
know	O
much	O
about	O
the	O
passenger	O
arrival	B
rate	I
on	O
the	O
red	O
line	O
after	O
a	O
few	O
days	O
of	O
commuting	O
you	O
could	O
make	O
a	O
guess	O
at	O
least	O
qualitatively	O
with	O
a	O
little	O
more	O
effort	O
you	O
could	O
estimate	O
quantitatively	O
each	O
day	O
when	O
you	O
arrive	O
at	O
the	O
platform	O
you	O
should	O
note	O
the	O
time	O
and	O
the	O
number	O
of	O
passengers	O
waiting	O
the	O
platform	O
is	O
too	O
big	O
you	O
could	O
choose	O
a	O
sample	O
area	O
then	O
you	O
should	O
record	O
your	O
wait	O
time	O
and	O
the	O
number	O
of	O
new	O
arrivals	O
while	O
you	O
are	O
waiting	O
after	O
five	O
days	O
you	O
might	O
have	O
data	O
like	O
this	O
y	O
rate	O
chapter	O
observer	B
bias	I
where	O
is	O
the	O
number	O
of	O
passengers	O
waiting	O
when	O
you	O
arrive	O
y	O
is	O
your	O
wait	O
time	O
in	O
minutes	O
and	O
is	O
the	O
number	O
of	O
passengers	O
who	O
arrive	O
while	O
you	O
are	O
waiting	O
over	O
the	O
course	O
of	O
one	O
week	O
you	O
waited	O
minutes	O
and	O
saw	O
passengers	O
arrive	O
so	O
you	O
would	O
estimate	O
that	O
the	O
arrival	B
rate	I
is	O
passengers	O
per	O
minute	O
for	O
practical	O
purposes	O
that	O
estimate	O
is	O
good	O
enough	O
but	O
for	O
the	O
sake	O
of	O
completeness	O
i	O
will	O
compute	O
a	O
posterior	B
distribution	B
for	O
and	O
show	O
how	O
to	O
use	O
that	O
distribution	B
in	O
the	O
rest	O
of	O
the	O
analysis	O
arrivalrate	O
is	O
a	O
suite	B
that	O
represents	O
hypotheses	O
about	O
as	O
always	O
likelihood	B
takes	O
a	O
hypothesis	O
and	O
data	O
and	O
computes	O
the	O
likelihood	B
of	O
the	O
data	O
under	O
the	O
hypothesis	O
in	O
this	O
case	O
the	O
hypothesis	O
is	O
a	O
value	O
of	O
the	O
data	O
is	O
a	O
pair	O
y	O
k	O
where	O
y	O
is	O
a	O
wait	O
time	O
and	O
k	O
is	O
the	O
number	O
of	O
passengers	O
that	O
arrived	O
class	O
arrivalratethinkbayes	O
suite	B
def	O
likelihoodself	O
data	O
hypo	O
lam	O
hypo	O
y	O
k	O
data	O
like	O
thinkbayes	O
evalpoissonpmfk	O
lam	O
y	O
return	O
like	O
look	O
familiar	O
to	O
identical	O
this	O
likelihood	B
might	O
in	O
that	O
elapsed	O
likelihood	B
in	O
section	O
in	O
elapsed	O
time	O
elapsed	O
likelihood	B
the	O
hypothesis	O
arrivalrate	O
likelihood	B
the	O
hypothesis	O
is	O
lam	O
the	O
arrival	B
rate	I
but	O
in	O
both	O
cases	O
the	O
likelihood	B
is	O
the	O
probability	B
of	O
seeing	O
k	O
arrivals	O
in	O
some	O
period	O
of	O
time	O
given	O
lam	O
it	O
the	O
difference	O
is	O
is	O
almost	O
is	O
x	O
the	O
arrivalrateestimator	O
encapsulates	O
the	O
process	B
of	O
estimating	O
the	O
parameter	B
passenger	O
data	O
is	O
a	O
list	O
of	O
y	O
tuples	O
as	O
in	O
the	O
table	O
above	O
class	O
arrivalrateestimatorobject	O
def	O
passenger	O
data	O
low	O
high	O
n	O
incorporating	O
uncertainty	B
figure	O
predictive	O
distributions	O
of	O
y	O
for	O
possible	O
values	O
of	O
lam	O
hypos	O
numpy	B
linspacelow	O
high	O
n	O
self	O
prior	B
lam	O
arrivalratehypos	O
self	O
post	O
lam	O
self	O
prior	B
lam	O
copy	O
for	O
y	O
in	O
passenger	O
data	O
self	O
post	O
lam	O
updatey	O
builds	O
hypos	O
which	O
is	O
a	O
sequence	O
of	O
hypothetical	O
values	O
for	O
lam	O
then	O
builds	O
the	O
prior	B
distribution	B
prior	B
lam	O
the	O
for	O
loop	O
updates	O
the	O
prior	B
with	O
data	O
yielding	O
the	O
posterior	B
distribution	B
post	O
lam	O
figure	O
shows	O
the	O
prior	B
and	O
posterior	B
distributions	O
as	O
expected	O
the	O
mean	O
and	O
median	B
of	O
the	O
posterior	B
are	O
near	O
the	O
observed	O
rate	O
passengers	O
per	O
minute	O
but	O
the	O
spread	O
of	O
the	O
posterior	B
distribution	B
captures	O
our	O
uncertainty	B
about	O
based	O
on	O
a	O
small	O
sample	O
incorporating	O
uncertainty	B
whenever	O
there	O
is	O
uncertainty	B
about	O
one	O
of	O
the	O
inputs	O
to	O
an	O
analysis	O
we	O
can	O
take	O
it	O
into	O
account	O
by	O
a	O
process	B
like	O
this	O
implement	O
the	O
analysis	O
based	O
on	O
a	O
deterministic	O
value	O
of	O
the	O
uncertain	O
parameter	B
this	O
case	O
compute	O
the	O
distribution	B
of	O
the	O
uncertain	O
parameter	B
time	O
chapter	O
observer	B
bias	I
run	O
the	O
analysis	O
for	O
each	O
value	O
of	O
the	O
parameter	B
and	O
generate	O
a	O
set	O
of	O
predictive	O
distributions	O
compute	O
a	O
mixture	B
of	O
the	O
predictive	O
distributions	O
using	O
the	O
weights	O
from	O
the	O
distribution	B
of	O
the	O
parameter	B
we	O
have	O
already	O
done	O
steps	O
and	O
waitmixtureestimator	O
to	O
handle	O
steps	O
and	O
class	O
waitmixtureestimatorobject	O
i	O
wrote	O
a	O
class	O
called	O
def	O
wtc	O
are	O
self	O
metapmf	O
thinkbayes	O
pmf	B
for	O
lam	O
prob	B
in	O
sortedare	O
post	O
lam	O
items	O
ete	O
elapsedtimeestimatorwtc	O
lam	O
num	O
passengers	O
self	O
metapmf	O
setete	O
pmf	B
y	O
prob	B
self	O
mixture	B
thinkbayes	O
makemixtureself	O
metapmf	O
wtc	O
is	O
the	O
waittimecalculator	O
that	O
contains	O
the	O
distribution	B
of	O
zb	O
are	O
is	O
the	O
arrivaltimeestimator	O
that	O
contains	O
the	O
distribution	B
of	O
lam	O
the	O
first	O
line	O
makes	O
a	O
meta-pmf	B
that	O
maps	O
from	O
each	O
possible	O
distribution	B
of	O
y	O
to	O
its	O
probability	B
for	O
each	O
value	O
of	O
lam	O
we	O
use	O
elapsedtimeestimator	O
to	O
compute	O
the	O
corresponding	O
distribution	B
of	O
y	O
and	O
store	O
it	O
in	O
the	O
meta-pmf	B
then	O
we	O
use	O
makemixture	B
to	O
compute	O
the	O
mixture	B
figure	O
shows	O
the	O
results	O
the	O
shaded	O
lines	O
in	O
the	O
background	O
are	O
the	O
distributions	O
of	O
y	O
for	O
each	O
value	O
of	O
lam	O
with	O
line	O
thickness	O
that	O
represents	O
likelihood	B
the	O
dark	O
line	O
is	O
the	O
mixture	B
of	O
these	O
distributions	O
in	O
this	O
case	O
we	O
could	O
get	O
a	O
very	O
similar	O
result	O
using	O
a	O
single	O
point	O
estimate	O
of	O
lam	O
so	O
it	O
was	O
not	O
necessary	O
for	O
practical	O
purposes	O
to	O
include	O
the	O
uncertainty	B
of	O
the	O
estimate	O
in	O
general	O
it	O
is	O
important	O
to	O
include	O
variability	O
if	O
the	O
system	B
response	O
is	O
non-linear	B
that	O
is	O
if	O
small	O
changes	O
in	O
the	O
input	O
can	O
cause	O
big	O
changes	O
in	O
the	O
output	O
in	O
this	O
case	O
posterior	B
variability	O
in	O
lam	O
is	O
small	O
and	O
the	O
system	B
response	O
is	O
approximately	O
linear	O
for	O
small	O
perturbations	O
decision	B
analysis	I
at	O
this	O
point	O
we	O
can	O
use	O
the	O
number	O
of	O
passengers	O
on	O
the	O
platform	O
to	O
predict	O
the	O
distribution	B
of	O
wait	O
times	O
now	O
let	O
s	O
get	O
to	O
the	O
second	O
part	O
of	O
the	O
decision	B
analysis	I
figure	O
probability	B
that	O
wait	O
time	O
exceeds	O
minutes	O
as	O
a	O
function	O
of	O
the	O
number	O
of	O
passengers	O
on	O
the	O
platform	O
question	O
when	O
should	O
i	O
stop	O
waiting	O
for	O
the	O
train	O
and	O
go	O
catch	O
a	O
taxi	O
remember	O
that	O
in	O
the	O
original	O
scenario	O
i	O
am	O
trying	O
to	O
get	O
to	O
south	O
station	O
to	O
catch	O
the	O
commuter	O
rail	O
suppose	O
i	O
leave	O
the	O
office	O
with	O
enough	O
time	O
that	O
i	O
can	O
wait	O
minutes	O
and	O
still	O
make	O
my	O
connection	O
at	O
south	O
station	O
in	O
that	O
case	O
i	O
would	O
like	O
to	O
know	O
the	O
probability	B
that	O
y	O
exceeds	O
minutes	O
as	O
a	O
function	O
of	O
num	O
passengers	O
it	O
is	O
easy	O
enough	O
to	O
use	O
the	O
analysis	O
from	O
section	O
and	O
run	O
it	O
for	O
a	O
range	O
of	O
num	O
passengers	O
but	O
there	O
s	O
a	O
problem	O
the	O
analysis	O
is	O
sensitive	O
to	O
the	O
frequency	O
of	O
long	O
delays	O
and	O
because	O
long	O
delays	O
are	O
rare	O
it	O
is	O
hard	O
to	O
estimate	O
their	O
frequency	O
i	O
only	O
have	O
data	O
from	O
one	O
week	O
and	O
the	O
longest	O
delay	O
i	O
observed	O
was	O
minutes	O
so	O
i	O
can	O
t	O
estimate	O
the	O
frequency	O
of	O
longer	O
delays	O
accurately	O
however	O
i	O
can	O
use	O
previous	O
observations	O
to	O
make	O
at	O
least	O
a	O
coarse	O
estimate	O
when	O
i	O
commuted	O
by	O
red	O
line	O
for	O
a	O
year	O
i	O
saw	O
three	O
long	O
delays	O
caused	O
by	O
a	O
signaling	O
problem	O
a	O
power	O
outage	O
and	O
police	O
activity	O
at	O
another	O
stop	O
so	O
i	O
estimate	O
that	O
there	O
are	O
about	O
major	O
delays	O
per	O
year	O
but	O
remember	O
that	O
my	O
observations	O
are	O
biased	O
i	O
am	O
more	O
likely	O
to	O
observe	O
long	O
delays	O
because	O
they	O
affect	O
a	O
large	O
number	O
of	O
passengers	O
so	O
we	O
should	O
treat	O
my	O
observations	O
as	O
a	O
sample	O
of	O
zb	O
rather	O
than	O
z	O
here	O
s	O
how	O
we	O
can	O
do	O
that	O
during	O
my	O
year	O
of	O
commuting	O
i	O
took	O
the	O
red	O
line	O
home	O
about	O
times	O
so	O
i	O
take	O
the	O
observed	O
gap	O
times	O
gap	O
times	O
generate	O
a	O
sample	O
of	O
gaps	O
and	O
compute	O
their	O
pmf	B
min	O
chapter	O
observer	B
bias	I
n	O
cdf	B
z	O
thinkbayes	O
makecdffromlistgap	O
times	O
sample	O
z	O
cdf	B
z	O
samplen	O
pmf	B
z	O
thinkbayes	O
makepmffromlistsample	O
z	O
next	O
i	O
bias	O
pmf	B
z	O
to	O
get	O
the	O
distribution	B
of	O
zb	O
draw	O
a	O
sample	O
and	O
then	O
add	O
in	O
delays	O
of	O
and	O
minutes	O
in	O
seconds	O
cdf	B
zp	O
biaspmfpmf	O
z	O
makecdf	O
sample	O
zb	O
cdf	B
zp	O
samplen	O
cdf	B
sample	O
is	O
more	O
efficient	O
than	O
pmf	B
sample	O
so	O
it	O
is	O
usually	O
faster	O
to	O
convert	O
a	O
pmf	B
to	O
a	O
cdf	B
before	O
sampling	O
next	O
i	O
use	O
the	O
sample	O
of	O
zb	O
to	O
estimate	O
a	O
pdf	B
using	O
kde	B
and	O
then	O
convert	O
the	O
pdf	B
to	O
a	O
pmf	B
pdf	B
zb	O
thinkbayes	O
estimatedpdfsample	O
zb	O
xs	O
pmf	B
zb	O
pdf	B
zb	O
makepmfxs	O
finally	O
i	O
unbias	O
the	O
distribution	B
of	O
zb	O
to	O
get	O
the	O
distribution	B
of	O
z	O
which	O
i	O
use	O
to	O
create	O
the	O
waittimecalculator	O
pmf	B
z	O
unbiaspmfpmf	O
zb	O
wtc	O
waittimecalculatorpmf	O
z	O
this	O
process	B
is	O
complicated	O
but	O
all	O
of	O
the	O
steps	O
are	O
operations	B
we	O
have	O
seen	O
before	O
now	O
we	O
are	O
ready	O
to	O
compute	O
the	O
probability	B
of	O
a	O
long	O
wait	O
def	O
problongwaitnum	O
passengers	O
minutes	O
ete	O
elapsedtimeestimatorwtc	O
lam	O
num	O
passengers	O
cdf	B
y	O
ete	O
pmf	B
y	O
makecdf	O
prob	B
cdf	B
y	O
probminutes	O
given	O
the	O
number	O
of	O
passengers	O
on	O
the	O
platform	O
problongwait	O
makes	O
an	O
elapsedtimeestimator	O
extracts	O
the	O
distribution	B
of	O
wait	O
time	O
and	O
computes	O
the	O
probability	B
that	O
wait	O
time	O
exceeds	O
minutes	O
figure	O
shows	O
the	O
result	O
when	O
the	O
number	O
of	O
passengers	O
is	O
less	O
than	O
we	O
infer	O
that	O
the	O
system	B
is	O
operating	O
normally	O
so	O
the	O
probability	B
of	O
a	O
long	O
delay	O
is	O
small	O
if	O
there	O
are	O
passengers	O
we	O
estimate	O
that	O
it	O
has	O
been	O
minutes	O
since	O
the	O
last	O
train	O
that	O
s	O
longer	O
than	O
a	O
normal	O
delay	O
so	O
we	O
infer	O
that	O
something	O
is	O
wrong	O
and	O
expect	O
longer	O
delays	O
if	O
we	O
are	O
willing	O
to	O
accept	O
a	O
chance	O
of	O
missing	O
the	O
connection	O
at	O
south	O
station	O
we	O
should	O
stay	O
and	O
wait	O
as	O
long	O
as	O
there	O
are	O
fewer	O
than	O
passengers	O
and	O
take	O
a	O
taxi	O
if	O
there	O
are	O
more	O
discussion	O
or	O
to	O
take	O
this	O
analysis	O
one	O
step	O
further	O
we	O
could	O
quantify	O
the	O
cost	O
of	O
missing	O
the	O
connection	O
and	O
the	O
cost	O
of	O
taking	O
a	O
taxi	O
then	O
choose	O
the	O
threshold	O
that	O
minimizes	O
expected	O
cost	O
discussion	O
the	O
analysis	O
so	O
far	O
has	O
been	O
based	O
on	O
the	O
assumption	O
that	O
the	O
arrival	B
rate	I
of	O
passengers	O
is	O
the	O
same	O
every	O
day	O
for	O
a	O
commuter	O
train	O
during	O
rush	O
hour	O
that	O
might	O
not	O
be	O
a	O
bad	O
assumption	O
but	O
there	O
are	O
some	O
obvious	O
exceptions	O
for	O
example	O
if	O
there	O
is	O
a	O
special	O
event	O
nearby	O
a	O
large	O
number	O
of	O
people	O
might	O
arrive	O
at	O
the	O
same	O
time	O
in	O
that	O
case	O
the	O
estimate	O
of	O
lam	O
would	O
be	O
too	O
low	O
so	O
the	O
estimates	O
of	O
x	O
and	O
y	O
would	O
be	O
too	O
high	O
if	O
special	O
events	O
are	O
as	O
common	O
as	O
major	O
delays	O
it	O
would	O
be	O
important	O
to	O
include	O
them	O
in	O
the	O
model	O
we	O
could	O
do	O
that	O
by	O
extending	O
the	O
distribution	B
of	O
lam	O
to	O
include	O
occasional	O
large	O
values	O
we	O
started	O
with	O
the	O
assumption	O
that	O
we	O
know	O
distribution	B
of	O
z	O
as	O
an	O
alternative	O
a	O
passenger	O
could	O
estimate	O
z	O
but	O
it	O
would	O
not	O
be	O
easy	O
as	O
a	O
passenger	O
you	O
only	O
observe	O
only	O
your	O
own	O
wait	O
time	O
y	O
unless	O
you	O
skip	O
the	O
first	O
train	O
and	O
wait	O
for	O
the	O
second	O
you	O
don	O
t	O
observe	O
the	O
gap	O
between	O
trains	O
z	O
however	O
we	O
could	O
make	O
some	O
inferences	O
about	O
zb	O
if	O
we	O
note	O
the	O
number	O
of	O
passengers	O
waiting	O
when	O
we	O
arrive	O
we	O
can	O
estimate	O
the	O
elapsed	O
time	O
since	O
the	O
last	O
train	O
x	O
then	O
we	O
observe	O
y	O
if	O
we	O
add	O
the	O
posterior	B
distribution	B
of	O
x	O
to	O
the	O
observed	O
y	O
we	O
get	O
a	O
distribution	B
that	O
represents	O
our	O
posterior	B
belief	O
about	O
the	O
observed	O
value	O
of	O
zb	O
we	O
can	O
use	O
this	O
distribution	B
to	O
update	B
our	O
beliefs	O
about	O
the	O
distribution	B
of	O
zb	O
finally	O
we	O
can	O
compute	O
the	O
inverse	O
of	O
biaspmf	O
to	O
get	O
from	O
the	O
distribution	B
of	O
zb	O
to	O
the	O
distribution	B
of	O
z	O
i	O
leave	O
this	O
analysis	O
as	O
an	O
exercise	O
for	O
the	O
reader	O
one	O
suggestion	O
you	O
should	O
read	O
chapter	O
first	O
you	O
can	O
find	O
the	O
outline	O
of	O
a	O
solution	O
in	O
httpthinkbayes	O
comredline	O
py	O
for	O
more	O
information	O
see	O
section	O
exercises	O
exercise	O
this	O
exercise	O
is	O
from	O
mackay	B
information	O
theory	O
inference	O
and	O
learning	O
algorithms	O
chapter	O
observer	B
bias	I
unstable	O
particles	O
are	O
emitted	O
from	O
a	O
source	O
and	O
decay	O
at	O
a	O
distance	O
x	O
a	O
real	O
number	O
that	O
has	O
an	O
exponential	O
probability	B
distribution	B
with	O
decay	O
events	O
can	O
only	O
be	O
observed	O
if	O
they	O
occur	O
in	O
a	O
window	O
extending	O
from	O
x	O
cm	O
to	O
x	O
cm	O
n	O
decays	O
are	O
observed	O
at	O
locations	O
cm	O
what	O
is	O
the	O
posterior	B
distribution	B
of	O
you	O
can	O
download	O
a	O
solution	O
to	O
this	O
exercise	O
from	O
http	O
thinkbayes	O
com	O
decay	O
py	O
chapter	O
two	O
dimensions	O
paintball	O
paintball	O
is	O
a	O
sport	O
in	O
which	O
competing	O
teams	O
try	O
to	O
shoot	O
each	O
other	O
with	O
guns	O
that	O
fire	O
paint-filled	O
pellets	O
that	O
break	O
on	O
impact	O
leaving	O
a	O
colorful	O
mark	O
on	O
the	O
target	O
it	O
is	O
usually	O
played	O
in	O
an	O
arena	O
decorated	O
with	O
barriers	O
and	O
other	O
objects	O
that	O
can	O
be	O
used	O
as	O
cover	O
suppose	O
you	O
are	O
playing	O
paintball	O
in	O
an	O
indoor	O
arena	O
feet	O
wide	O
and	O
feet	O
long	O
you	O
are	O
standing	O
near	O
one	O
of	O
the	O
foot	O
walls	O
and	O
you	O
suspect	O
that	O
one	O
of	O
your	O
opponents	O
has	O
taken	O
cover	O
nearby	O
along	O
the	O
wall	O
you	O
see	O
several	O
paint	O
spatters	O
all	O
the	O
same	O
color	O
that	O
you	O
think	O
your	O
opponent	O
fired	O
recently	O
the	O
spatters	O
are	O
at	O
and	O
feet	O
measured	O
from	O
the	O
lower-left	O
corner	O
of	O
the	O
room	O
based	O
on	O
these	O
data	O
where	O
do	O
you	O
think	O
your	O
opponent	O
is	O
hiding	O
figure	O
shows	O
a	O
diagram	O
of	O
the	O
arena	O
using	O
the	O
lower-left	O
corner	O
of	O
the	O
room	O
as	O
the	O
origin	O
i	O
denote	O
the	O
unknown	O
location	O
of	O
the	O
shooter	O
with	O
coordinates	O
and	O
or	O
alpha	O
and	O
beta	O
the	O
location	O
of	O
a	O
spatter	O
is	O
labeled	O
x	O
the	O
angle	O
the	O
opponent	O
shoots	O
at	O
is	O
or	O
theta	O
the	O
paintball	B
problem	I
is	O
a	O
modified	O
version	O
of	O
the	O
lighthouse	O
problem	O
a	O
common	O
example	O
of	O
bayesian	O
analysis	O
my	O
notation	O
follows	O
the	O
presentation	O
of	O
the	O
problem	O
in	O
d	O
s	O
sivia	B
s	O
data	O
analysis	O
a	O
bayesian	O
tutorial	O
second	O
edition	O
you	O
can	O
download	O
the	O
code	O
in	O
this	O
chapter	O
from	O
httpthinkbayes	O
com	O
paintball	O
py	O
for	O
more	O
information	O
see	O
section	O
chapter	O
two	O
dimensions	O
figure	O
diagram	O
of	O
the	O
layout	O
for	O
the	O
paintball	B
problem	I
the	O
suite	B
to	O
get	O
started	O
we	O
need	O
a	O
suite	B
that	O
represents	O
a	O
set	O
of	O
hypotheses	O
about	O
the	O
location	O
of	O
the	O
opponent	O
each	O
hypothesis	O
is	O
a	O
pair	O
of	O
coordinates	O
beta	O
here	O
is	O
the	O
definition	O
of	O
the	O
paintball	O
suite	B
class	I
paintballthinkbayes	O
suite	B
thinkbayes	O
joint	B
def	O
alphas	O
betas	O
locations	O
self	O
locations	O
locations	O
pairs	O
beta	O
for	O
alpha	O
in	O
alphas	O
for	O
beta	O
in	O
betas	O
thinkbayes	O
suite	B
init	O
self	O
pairs	O
paintball	O
inherits	O
from	O
suite	B
which	O
we	O
have	O
seen	O
before	O
and	O
joint	B
which	O
i	O
will	O
explain	O
soon	O
alphas	O
is	O
the	O
list	O
of	O
possible	O
values	O
for	O
alpha	O
betas	O
is	O
the	O
list	O
of	O
values	O
for	O
beta	O
pairs	O
is	O
a	O
list	O
of	O
all	O
beta	O
pairs	O
locations	O
is	O
a	O
list	O
of	O
possible	O
locations	O
along	O
the	O
wall	O
it	O
is	O
stored	O
for	O
use	O
in	O
likelihood	B
the	O
room	O
is	O
feet	O
wide	O
and	O
feet	O
long	O
so	O
here	O
s	O
the	O
code	O
that	O
creates	O
the	O
suite	B
alphas	O
xshooterwall	O
trigonometry	B
figure	O
posterior	B
cdfs	O
for	O
alpha	O
and	O
beta	O
given	O
the	O
data	O
betas	O
locations	O
suite	B
paintballalphas	O
betas	O
locations	O
this	O
prior	B
distribution	B
assumes	O
that	O
all	O
locations	O
in	O
the	O
room	O
are	O
equally	O
likely	O
given	O
a	O
map	O
of	O
the	O
room	O
we	O
might	O
choose	O
a	O
more	O
detailed	O
prior	B
but	O
we	O
ll	O
start	O
simple	O
trigonometry	B
now	O
we	O
need	O
a	O
likelihood	B
function	I
which	O
means	O
we	O
have	O
to	O
figure	O
out	O
the	O
likelihood	B
of	O
hitting	O
any	O
spot	O
along	O
the	O
wall	O
given	O
the	O
location	O
of	O
the	O
opponent	O
as	O
a	O
simple	O
model	O
imagine	O
that	O
the	O
opponent	O
is	O
like	O
a	O
rotating	O
turret	O
equally	O
likely	O
to	O
shoot	O
in	O
any	O
direction	O
in	O
that	O
case	O
he	O
is	O
most	O
likely	O
to	O
hit	O
the	O
wall	O
at	O
location	O
alpha	O
and	O
less	O
likely	O
to	O
hit	O
the	O
wall	O
far	O
away	O
from	O
alpha	O
with	O
a	O
little	O
trigonometry	B
we	O
can	O
compute	O
the	O
probability	B
of	O
hitting	O
any	O
spot	O
along	O
the	O
wall	O
imagine	O
that	O
the	O
shooter	O
fires	O
a	O
shot	O
at	O
angle	O
the	O
pellet	O
would	O
hit	O
the	O
wall	O
at	O
location	O
x	O
where	O
x	O
tan	O
chapter	O
two	O
dimensions	O
figure	O
pmf	B
of	O
location	O
given	O
for	O
several	O
values	O
of	O
beta	O
solving	O
this	O
equation	O
for	O
yields	O
tan	O
x	O
so	O
given	O
a	O
location	O
on	O
the	O
wall	O
we	O
can	O
find	O
taking	O
the	O
derivative	O
of	O
the	O
first	O
equation	O
with	O
respect	O
to	O
yields	O
dx	O
d	O
this	O
derivative	O
is	O
what	O
i	O
ll	O
call	O
the	O
strafing	B
speed	I
which	O
is	O
the	O
speed	O
of	O
the	O
target	O
location	O
along	O
the	O
wall	O
as	O
increases	O
the	O
probability	B
of	O
hitting	O
a	O
given	O
point	O
on	O
the	O
wall	O
is	O
inversely	O
related	O
to	O
strafing	B
speed	I
if	O
we	O
know	O
the	O
coordinates	O
of	O
the	O
shooter	O
and	O
a	O
location	O
along	O
the	O
wall	O
we	O
can	O
compute	O
strafing	B
speed	I
def	O
strafingspeedalpha	O
beta	O
x	O
theta	O
alpha	O
beta	O
speed	O
beta	O
return	O
speed	O
alpha	O
and	O
beta	O
are	O
the	O
coordinates	O
of	O
the	O
shooter	O
x	O
is	O
the	O
location	O
of	O
a	O
spatter	O
the	O
result	O
is	O
the	O
derivative	O
of	O
x	O
with	O
respect	O
to	O
theta	O
now	O
we	O
can	O
compute	O
a	O
pmf	B
that	O
represents	O
the	O
probability	B
of	O
hitting	O
any	O
location	O
on	O
the	O
wall	O
makelocationpmf	O
takes	O
alpha	O
and	O
beta	O
the	O
coordinates	O
of	O
the	O
shooter	O
and	O
locations	O
a	O
list	O
of	O
possible	O
values	O
of	O
x	O
likelihood	B
def	O
makelocationpmfalpha	O
beta	O
locations	O
pmf	B
thinkbayes	O
pmf	B
for	O
x	O
in	O
locations	O
prob	B
strafingspeedalpha	O
beta	O
x	O
pmf	B
setx	O
prob	B
pmf	B
normalize	B
return	O
pmf	B
makelocationpmf	O
computes	O
the	O
probability	B
of	O
hitting	O
each	O
location	O
which	O
is	O
inversely	O
related	O
to	O
strafing	B
speed	I
the	O
result	O
is	O
a	O
pmf	B
of	O
locations	O
and	O
their	O
probabilities	O
figure	O
shows	O
the	O
pmf	B
of	O
location	O
with	O
alpha	O
and	O
a	O
range	O
of	O
values	O
for	O
beta	O
for	O
all	O
values	O
of	O
beta	O
the	O
most	O
likely	O
spatter	O
location	O
is	O
x	O
as	O
beta	O
increases	O
so	O
does	O
the	O
spread	O
of	O
the	O
pmf	B
likelihood	B
now	O
all	O
we	O
need	O
is	O
a	O
likelihood	B
function	I
we	O
can	O
use	O
makelocationpmf	O
to	O
compute	O
the	O
likelihood	B
of	O
any	O
value	O
of	O
x	O
given	O
the	O
coordinates	O
of	O
the	O
opponent	O
def	O
likelihoodself	O
data	O
hypo	O
alpha	O
beta	O
hypo	O
x	O
data	O
pmf	B
makelocationpmfalpha	O
beta	O
self	O
locations	O
like	O
pmf	B
probx	O
return	O
like	O
again	O
alpha	O
and	O
beta	O
are	O
the	O
hypothetical	O
coordinates	O
of	O
the	O
shooter	O
and	O
x	O
is	O
the	O
location	O
of	O
an	O
observed	O
spatter	O
pmf	B
contains	O
the	O
probability	B
of	O
each	O
location	O
given	O
the	O
coordinates	O
of	O
the	O
shooter	O
from	O
this	O
pmf	B
we	O
select	O
the	O
probability	B
of	O
the	O
observed	O
location	O
and	O
we	O
re	O
done	O
to	O
update	B
the	O
suite	B
we	O
can	O
use	O
updateset	O
which	O
is	O
inherited	O
from	O
suite	B
the	O
result	O
is	O
a	O
distribution	B
that	O
maps	O
each	O
beta	O
pair	O
to	O
a	O
posterior	B
probability	B
joint	B
distributions	O
chapter	O
two	O
dimensions	O
when	O
each	O
value	O
in	O
a	O
distribution	B
is	O
a	O
tuple	B
of	O
variables	O
it	O
is	O
called	O
a	O
joint	B
distribution	B
because	O
it	O
represents	O
the	O
distributions	O
of	O
the	O
variables	O
together	O
that	O
is	O
jointly	O
a	O
joint	B
distribution	B
contains	O
the	O
distributions	O
of	O
the	O
variables	O
as	O
well	O
information	O
about	O
the	O
relationships	O
among	O
them	O
given	O
a	O
joint	B
distribution	B
we	O
can	O
compute	O
the	O
distributions	O
of	O
each	O
variable	O
independently	O
which	O
are	O
called	O
the	O
marginal	O
distributions	O
thinkbayes	O
joint	B
provides	O
a	O
method	O
that	O
computes	O
marginal	O
distributions	O
class	O
joint	B
def	O
marginalself	O
i	O
pmf	B
pmf	B
for	O
vs	O
prob	B
in	O
self	O
items	O
pmf	B
incrvsi	O
prob	B
return	O
pmf	B
i	O
is	O
the	O
index	O
of	O
the	O
variable	O
we	O
want	O
in	O
this	O
example	O
indicates	O
the	O
distribution	B
of	O
alpha	O
and	O
indicates	O
the	O
distribution	B
of	O
beta	O
here	O
s	O
the	O
code	O
that	O
extracts	O
the	O
marginal	O
distributions	O
marginal	O
alpha	O
marginal	O
beta	O
figure	O
shows	O
the	O
results	O
to	O
cdfs	O
the	O
median	B
value	O
for	O
alpha	O
is	O
near	O
the	O
center	O
of	O
mass	O
of	O
the	O
observed	O
spatters	O
for	O
beta	O
the	O
most	O
likely	O
values	O
are	O
close	O
to	O
the	O
wall	O
but	O
beyond	O
feet	O
the	O
distribution	B
is	O
almost	O
uniform	O
which	O
indicates	O
that	O
the	O
data	O
do	O
not	O
distinguish	O
strongly	O
between	O
these	O
possible	O
locations	O
given	O
the	O
posterior	B
marginals	O
we	O
can	O
compute	O
credible	O
intervals	O
for	O
each	O
coordinate	O
independently	O
print	O
ci	O
print	O
ci	O
the	O
credible	O
intervals	O
are	O
for	O
alpha	O
and	O
for	O
beta	O
so	O
the	O
data	O
provide	O
evidence	O
that	O
the	O
shooter	O
is	O
in	O
the	O
near	O
side	O
of	O
the	O
room	O
but	O
it	O
is	O
not	O
strong	O
evidence	O
the	O
credible	O
intervals	O
cover	O
most	O
of	O
the	O
room	O
conditional	B
distributions	O
figure	O
posterior	B
distributions	O
for	O
alpha	O
conditioned	O
on	O
several	O
values	O
of	O
beta	O
conditional	B
distributions	O
the	O
marginal	O
distributions	O
contain	O
information	O
about	O
the	O
variables	O
independently	O
but	O
they	O
do	O
not	O
capture	O
the	O
dependence	B
between	O
variables	O
if	O
any	O
one	O
way	O
to	O
visualize	O
dependence	B
is	O
by	O
computing	O
conditional	B
distributions	O
thinkbayes	O
joint	B
provides	O
a	O
method	O
that	O
does	O
that	O
def	O
conditionalself	O
i	O
j	O
val	O
pmf	B
pmf	B
for	O
vs	O
prob	B
in	O
self	O
items	O
if	O
vsj	O
val	O
continue	O
pmf	B
incrvsi	O
prob	B
pmf	B
normalize	B
return	O
pmf	B
again	O
i	O
is	O
the	O
index	O
of	O
the	O
variable	O
we	O
want	O
j	O
is	O
the	O
index	O
of	O
the	O
conditioning	O
variable	O
and	O
val	O
is	O
the	O
conditional	B
value	O
the	O
result	O
is	O
the	O
distribution	B
of	O
the	O
ith	O
variable	O
under	O
the	O
condition	O
that	O
the	O
jth	O
variable	O
is	O
val	O
for	O
example	O
the	O
following	O
code	O
computes	O
the	O
conditional	B
distributions	O
of	O
alpha	O
for	O
a	O
range	O
of	O
values	O
of	O
beta	O
betas	O
chapter	O
two	O
dimensions	O
figure	O
credible	O
intervals	O
for	O
the	O
coordinates	O
of	O
the	O
opponent	O
for	O
beta	O
in	O
betas	O
cond	O
beta	O
figure	O
shows	O
the	O
results	O
which	O
we	O
could	O
fully	O
describe	O
as	O
posterior	B
conditional	B
marginal	O
distributions	O
whew	O
if	O
the	O
variables	O
were	O
independent	O
the	O
conditional	B
distributions	O
would	O
all	O
be	O
the	O
same	O
since	O
they	O
are	O
all	O
different	O
we	O
can	O
tell	O
the	O
variables	O
are	O
dependent	O
for	O
example	O
if	O
we	O
know	O
that	O
beta	O
the	O
conditional	B
distribution	B
of	O
alpha	O
is	O
fairly	O
narrow	O
for	O
larger	O
values	O
of	O
beta	O
the	O
distribution	B
of	O
alpha	O
is	O
wider	O
credible	O
intervals	O
another	O
way	O
to	O
visualize	O
the	O
posterior	B
joint	B
distribution	B
is	O
to	O
compute	O
credible	O
intervals	O
when	O
we	O
looked	O
at	O
credible	O
intervals	O
in	O
section	O
i	O
skipped	O
over	O
a	O
subtle	O
point	O
for	O
a	O
given	O
distribution	B
there	O
are	O
many	O
intervals	O
with	O
the	O
same	O
level	O
of	O
credibility	O
for	O
example	O
if	O
you	O
want	O
a	O
credible	B
interval	I
you	O
could	O
choose	O
any	O
set	O
of	O
values	O
whose	O
probability	B
adds	O
up	O
to	O
when	O
the	O
values	O
are	O
one-dimensional	O
it	O
is	O
most	O
common	O
to	O
choose	O
the	O
central	B
credible	B
interval	I
for	O
example	O
the	O
central	B
credible	B
interval	I
contains	O
all	O
values	O
between	O
the	O
and	O
percentiles	O
in	O
multiple	O
dimensions	O
it	O
is	O
less	O
obvious	O
what	O
the	O
right	O
credible	B
interval	I
should	O
be	O
the	O
best	O
choice	O
might	O
depend	O
on	O
context	O
but	O
one	O
common	O
credible	O
intervals	O
choice	O
is	O
the	O
maximum	B
likelihood	B
credible	B
interval	I
which	O
contains	O
the	O
most	O
likely	O
values	O
that	O
add	O
up	O
to	O
some	O
other	O
percentage	O
thinkbayes	O
joint	B
provides	O
a	O
method	O
that	O
computes	O
maximum	B
likelihood	B
credible	O
intervals	O
class	O
joint	B
def	O
maxlikeintervalself	O
interval	O
total	O
t	O
val	O
for	O
val	O
prob	B
in	O
self	O
items	O
t	O
sortreversetrue	O
for	O
prob	B
val	O
in	O
t	O
interval	O
appendval	O
total	O
prob	B
if	O
total	O
break	O
return	O
interval	O
the	O
first	O
step	O
is	O
to	O
make	O
a	O
list	O
of	O
the	O
values	O
in	O
the	O
suite	B
sorted	O
in	O
descending	O
order	O
by	O
probability	B
next	O
we	O
traverse	O
the	O
list	O
adding	O
each	O
value	O
to	O
the	O
interval	O
until	O
the	O
total	B
probability	B
exceeds	O
percentage	O
the	O
result	O
is	O
a	O
list	O
of	O
values	O
from	O
the	O
suite	B
notice	O
that	O
this	O
set	O
of	O
values	O
is	O
not	O
necessarily	O
contiguous	O
to	O
visualize	O
the	O
intervals	O
i	O
wrote	O
a	O
function	O
that	O
colors	O
each	O
value	O
according	O
to	O
how	O
many	O
intervals	O
it	O
appears	O
in	O
def	O
makecredibleplotsuite	O
d	O
dictpair	O
for	O
pair	O
in	O
suite	B
values	O
percentages	O
for	O
p	O
in	O
percentages	O
interval	O
suite	B
maxlikeintervalp	O
for	O
pair	O
in	O
interval	O
dpair	O
return	O
d	O
d	O
is	O
a	O
dictionary	O
that	O
maps	O
from	O
each	O
value	O
in	O
the	O
suite	B
to	O
the	O
number	O
of	O
intervals	O
it	O
appears	O
in	O
the	O
loop	O
computes	O
intervals	O
for	O
several	O
percentages	O
and	O
modifies	O
d	O
chapter	O
two	O
dimensions	O
figure	O
shows	O
the	O
result	O
the	O
credible	B
interval	I
is	O
the	O
darkest	O
region	O
near	O
the	O
bottom	O
wall	O
for	O
higher	O
percentages	O
the	O
credible	B
interval	I
is	O
bigger	O
of	O
course	O
and	O
skewed	O
toward	O
the	O
right	O
side	O
of	O
the	O
room	O
discussion	O
this	O
chapter	O
shows	O
that	O
the	O
bayesian	B
framework	I
from	O
the	O
previous	O
chapters	O
can	O
be	O
extended	O
to	O
handle	O
a	O
two-dimensional	O
parameter	B
space	O
the	O
only	O
difference	O
is	O
that	O
each	O
hypothesis	O
is	O
represented	O
by	O
a	O
tuple	B
of	O
parameters	O
i	O
also	O
presented	O
joint	B
which	O
is	O
a	O
parent	O
class	O
that	O
provides	O
methods	O
that	O
apply	O
to	O
joint	B
distributions	O
marginal	O
conditional	B
and	O
makelikeinterval	O
in	O
object-oriented	O
terms	O
joint	B
is	O
a	O
mixin	O
http	O
there	O
is	O
a	O
lot	O
of	O
new	O
vocabulary	O
in	O
this	O
chapter	O
so	O
let	O
s	O
review	O
joint	B
distribution	B
a	O
distribution	B
that	O
represents	O
all	O
possible	O
values	O
in	O
a	O
multidimensional	O
space	O
and	O
their	O
probabilities	O
the	O
example	O
in	O
this	O
chapter	O
is	O
a	O
two-dimensional	O
space	O
made	O
up	O
of	O
the	O
coordinates	O
alpha	O
and	O
beta	O
the	O
joint	B
distribution	B
represents	O
the	O
probability	B
of	O
each	O
beta	O
pair	O
marginal	B
distribution	B
the	O
distribution	B
of	O
one	O
parameter	B
in	O
a	O
joint	B
distribution	B
treating	O
the	O
other	O
parameters	O
as	O
unknown	O
for	O
example	O
figure	O
shows	O
the	O
distributions	O
of	O
alpha	O
and	O
beta	O
independently	O
conditional	B
distribution	B
the	O
distribution	B
of	O
one	O
parameter	B
in	O
a	O
joint	B
distribution	B
conditioned	O
on	O
one	O
or	O
more	O
of	O
the	O
other	O
parameters	O
figure	O
several	O
distributions	O
for	O
alpha	O
conditioned	O
on	O
different	O
values	O
of	O
beta	O
given	O
the	O
joint	B
distribution	B
you	O
can	O
compute	O
marginal	O
and	O
conditional	B
distributions	O
with	O
enough	O
conditional	B
distributions	O
you	O
could	O
re-create	O
the	O
joint	B
distribution	B
at	O
least	O
approximately	O
but	O
given	O
the	O
marginal	O
distributions	O
you	O
cannot	O
re-create	O
the	O
joint	B
distribution	B
because	O
you	O
have	O
lost	O
information	O
about	O
the	O
dependence	B
between	O
variables	O
if	O
there	O
are	O
n	O
possible	O
values	O
for	O
each	O
of	O
two	O
parameters	O
most	O
operations	B
on	O
the	O
joint	B
distribution	B
take	O
time	O
proportional	O
to	O
if	O
there	O
are	O
d	O
parameters	O
run	O
time	O
is	O
proportional	O
to	O
nd	O
which	O
quickly	O
becomes	O
impractical	O
as	O
the	O
number	O
of	O
dimensions	O
increases	O
exercises	O
if	O
you	O
can	O
process	B
a	O
million	O
hypotheses	O
in	O
a	O
reasonable	O
amount	O
of	O
time	O
you	O
could	O
handle	O
two	O
dimensions	O
with	O
values	O
for	O
each	O
parameter	B
or	O
three	O
dimensions	O
with	O
values	O
each	O
or	O
six	O
dimensions	O
with	O
values	O
each	O
if	O
you	O
need	O
more	O
dimensions	O
or	O
more	O
values	O
per	O
dimension	O
there	O
are	O
optimizations	O
you	O
can	O
try	O
i	O
present	O
an	O
example	O
in	O
chapter	O
you	O
can	O
download	O
the	O
code	O
in	O
this	O
chapter	O
from	O
httpthinkbayes	O
com	O
paintball	O
py	O
for	O
more	O
information	O
see	O
section	O
exercises	O
exercise	O
in	O
our	O
simple	O
model	O
the	O
opponent	O
is	O
equally	O
likely	O
to	O
shoot	O
in	O
any	O
direction	O
as	O
an	O
exercise	O
let	O
s	O
consider	O
improvements	O
to	O
this	O
model	O
the	O
analysis	O
in	O
this	O
chapter	O
suggests	O
that	O
a	O
shooter	O
is	O
most	O
likely	O
to	O
hit	O
the	O
closest	O
wall	O
but	O
in	O
reality	O
if	O
the	O
opponent	O
is	O
close	O
to	O
a	O
wall	O
he	O
is	O
unlikely	O
to	O
shoot	O
at	O
the	O
wall	O
because	O
he	O
is	O
unlikely	O
to	O
see	O
a	O
target	O
between	O
himself	O
and	O
the	O
wall	O
design	O
an	O
improved	O
model	O
that	O
takes	O
this	O
behavior	O
into	O
account	O
try	O
to	O
find	O
a	O
model	O
that	O
is	O
more	O
realistic	O
but	O
not	O
too	O
complicated	O
chapter	O
two	O
dimensions	O
chapter	O
approximate	O
bayesian	O
computation	O
the	O
variability	B
hypothesis	I
i	O
have	O
a	O
soft	O
spot	O
for	O
crank	B
science	I
recently	O
i	O
visited	O
norumbega	O
tower	O
which	O
is	O
an	O
enduring	O
monument	O
to	O
the	O
crackpot	O
theories	O
of	O
eben	O
norton	O
horsford	B
inventor	O
of	O
double-acting	O
baking	O
powder	O
and	O
fake	O
history	O
but	O
that	O
s	O
not	O
what	O
this	O
chapter	O
is	O
about	O
this	O
chapter	O
is	O
about	O
the	O
variability	B
hypothesis	I
which	O
in	O
the	O
early	O
nineteenth	O
century	O
with	O
johann	O
meckel	B
who	O
argued	O
that	O
males	O
have	O
a	O
greater	O
range	O
of	O
ability	O
than	O
females	O
especially	O
in	O
intelligence	O
in	O
other	O
words	O
he	O
believed	O
that	O
most	O
geniuses	O
and	O
most	O
mentally	O
retarded	O
people	O
are	O
men	O
because	O
he	O
considered	O
males	O
to	O
be	O
the	O
superior	O
animal	O
meckel	B
concluded	O
that	O
females	O
lack	O
of	O
variation	O
was	O
a	O
sign	O
of	O
inferiority	O
from	O
hypothesis	O
httpen	O
wikipedia	O
orgwikivariability	O
i	O
particularly	O
like	O
that	O
last	O
part	O
because	O
i	O
suspect	O
that	O
if	O
it	O
turns	O
out	O
that	O
women	O
are	O
actually	O
more	O
variable	O
meckel	B
would	O
take	O
that	O
as	O
a	O
sign	O
of	O
inferiority	O
too	O
anyway	O
you	O
will	O
not	O
be	O
surprised	O
to	O
hear	O
that	O
the	O
evidence	O
for	O
the	O
variability	B
hypothesis	I
is	O
weak	O
nevertheless	O
it	O
came	O
up	O
in	O
my	O
class	O
recently	O
when	O
we	O
looked	O
at	O
data	O
from	O
the	O
cdc	B
s	O
behavioral	O
risk	O
factor	O
surveillance	O
system	B
specifically	O
chapter	O
approximate	O
bayesian	O
computation	O
the	O
self-reported	O
heights	O
of	O
adult	O
american	O
men	O
and	O
women	O
the	O
dataset	O
includes	O
responses	O
from	O
men	O
and	O
women	O
here	O
s	O
what	O
we	O
found	O
the	O
average	O
height	B
for	O
men	O
is	O
cm	O
the	O
average	O
height	B
for	O
women	O
is	O
cm	O
so	O
men	O
are	O
taller	O
on	O
average	O
no	O
surprise	O
there	O
for	O
men	O
the	O
standard	O
deviation	O
is	O
cm	O
for	O
women	O
it	O
is	O
cm	O
so	O
in	O
absolute	O
terms	O
men	O
s	O
heights	O
are	O
more	O
variable	O
but	O
to	O
compare	O
variability	O
between	O
groups	O
it	O
is	O
more	O
meaningful	O
to	O
use	O
the	O
coefficient	B
of	I
variation	I
which	O
is	O
the	O
standard	O
deviation	O
divided	O
by	O
the	O
mean	O
it	O
is	O
a	O
dimensionless	O
measure	O
of	O
variability	O
relative	O
to	O
scale	O
for	O
men	O
cv	O
is	O
for	O
women	O
it	O
is	O
that	O
s	O
very	O
close	O
so	O
we	O
could	O
conclude	O
that	O
this	O
dataset	O
provides	O
weak	O
evidence	O
against	O
the	O
variability	B
hypothesis	I
but	O
we	O
can	O
use	O
bayesian	O
methods	O
to	O
make	O
that	O
conclusion	O
more	O
precise	O
and	O
answering	O
this	O
question	O
gives	O
me	O
a	O
chance	O
to	O
demonstrate	O
some	O
techniques	O
for	O
working	O
with	O
large	O
datasets	O
i	O
will	O
proceed	O
in	O
a	O
few	O
steps	O
we	O
ll	O
start	O
with	O
the	O
simplest	O
implementation	B
but	O
it	O
only	O
works	O
for	O
datasets	O
smaller	O
than	O
values	O
by	O
computing	O
probabilities	O
under	O
a	O
log	B
transform	I
we	O
can	O
scale	O
up	O
to	O
the	O
full	O
size	O
of	O
the	O
dataset	O
but	O
the	O
computation	O
gets	O
slow	O
finally	O
we	O
speed	O
things	O
up	O
substantially	O
with	O
approximate	O
bayesian	O
computation	O
also	O
known	O
as	O
abc	B
you	O
can	O
download	O
the	O
code	O
in	O
this	O
chapter	O
from	O
httpthinkbayes	O
com	O
variability	O
py	O
for	O
more	O
information	O
see	O
section	O
mean	O
and	O
standard	O
deviation	O
in	O
chapter	O
we	O
estimated	O
two	O
parameters	O
simultaneously	O
using	O
a	O
joint	B
distribution	B
in	O
this	O
chapter	O
we	O
use	O
the	O
same	O
method	O
to	O
estimate	O
the	O
parameters	O
of	O
a	O
gaussian	B
distribution	B
the	O
mean	O
mu	O
and	O
the	O
standard	O
deviation	O
sigma	O
for	O
this	O
problem	O
i	O
define	O
a	O
suite	B
called	O
height	B
that	O
represents	O
a	O
map	O
from	O
each	O
mu	O
sigma	O
pair	O
to	O
its	O
probability	B
mean	O
and	O
standard	O
deviation	O
class	O
heightthinkbayes	O
suite	B
thinkbayes	O
joint	B
def	O
mus	O
sigmas	O
pairs	O
sigma	O
for	O
mu	O
in	O
mus	O
for	O
sigma	O
in	O
sigmas	O
thinkbayes	O
suite	B
init	O
self	O
pairs	O
mus	O
is	O
a	O
sequence	O
of	O
possible	O
values	O
for	O
mu	O
sigmas	O
is	O
a	O
sequence	O
of	O
values	O
for	O
sigma	O
the	O
prior	B
distribution	B
is	O
uniform	O
over	O
all	O
mu	O
sigma	O
pairs	O
the	O
likelihood	B
function	I
is	O
easy	O
given	O
hypothetical	O
values	O
of	O
mu	O
and	O
sigma	O
we	O
compute	O
the	O
likelihood	B
of	O
a	O
particular	O
value	O
x	O
that	O
s	O
what	O
evalgaussianpdf	O
does	O
so	O
all	O
we	O
have	O
to	O
do	O
is	O
use	O
it	O
class	O
height	B
def	O
likelihoodself	O
data	O
hypo	O
x	O
data	O
mu	O
sigma	O
hypo	O
like	O
thinkbayes	O
evalgaussianpdfx	O
mu	O
sigma	O
return	O
like	O
if	O
you	O
have	O
studied	O
statistics	O
from	O
a	O
mathematical	O
perspective	O
you	O
know	O
that	O
when	O
you	O
evaluate	O
a	O
pdf	B
you	O
get	O
a	O
probability	B
density	B
in	O
order	O
to	O
get	O
a	O
probability	B
you	O
have	O
to	O
integrate	O
probability	B
densities	O
over	O
some	O
range	O
but	O
for	O
our	O
purposes	O
we	O
don	O
t	O
need	O
a	O
probability	B
we	O
just	O
need	O
something	O
proportional	O
to	O
the	O
probability	B
we	O
want	O
a	O
probability	B
density	B
does	O
that	O
job	O
nicely	O
the	O
hardest	O
part	O
of	O
this	O
problem	O
turns	O
out	O
to	O
be	O
choosing	O
appropriate	O
ranges	O
for	O
mus	O
and	O
sigmas	O
if	O
the	O
range	O
is	O
too	O
small	O
we	O
omit	O
some	O
possibilities	O
with	O
non-negligible	O
probability	B
and	O
get	O
the	O
wrong	O
answer	O
if	O
the	O
range	O
is	O
too	O
big	O
we	O
get	O
the	O
right	O
answer	O
but	O
waste	O
computational	O
power	O
so	O
this	O
is	O
an	O
opportunity	O
to	O
use	O
classical	B
estimation	I
to	O
make	O
bayesian	O
techniques	O
more	O
efficient	O
specifically	O
we	O
can	O
use	O
classical	O
estimators	O
to	O
find	O
a	O
likely	O
location	O
for	O
mu	O
and	O
sigma	O
and	O
use	O
the	O
standard	O
errors	O
of	O
those	O
estimates	O
to	O
choose	O
a	O
likely	O
spread	O
if	O
the	O
true	O
parameters	O
of	O
the	O
distribution	B
are	O
and	O
and	O
we	O
take	O
a	O
sample	O
of	O
n	O
values	O
an	O
estimator	O
of	O
is	O
the	O
sample	O
mean	O
m	O
and	O
an	O
estimator	O
of	O
is	O
the	O
sample	O
standard	O
variance	O
s	O
chapter	O
approximate	O
bayesian	O
computation	O
estimated	O
is	O
the	O
standard	O
error	B
of	O
the	O
estimated	O
is	O
s	O
n	O
and	O
the	O
standard	O
error	B
of	O
the	O
here	O
s	O
the	O
code	O
to	O
compute	O
all	O
that	O
def	O
findpriorrangesxs	O
num	O
points	O
compute	O
m	O
and	O
s	O
n	O
lenxs	O
m	O
numpy	B
meanxs	O
s	O
numpy	B
stdxs	O
compute	O
ranges	O
for	O
m	O
and	O
s	O
stderr	O
m	O
s	O
math	O
sqrtn	O
mus	O
makerangem	O
stderr	O
m	O
num	O
stderrs	O
stderr	O
s	O
s	O
sigmas	O
makeranges	O
stderr	O
s	O
num	O
stderrs	O
return	O
mus	O
sigmas	O
xs	O
is	O
the	O
dataset	O
num	O
points	O
is	O
the	O
desired	O
number	O
of	O
values	O
in	O
the	O
range	O
num	O
stderrs	O
is	O
the	O
width	O
of	O
the	O
range	O
on	O
each	O
side	O
of	O
the	O
estimate	O
in	O
number	O
of	O
standard	O
errors	O
the	O
return	O
value	O
is	O
a	O
pair	O
of	O
sequences	O
mus	O
and	O
sigmas	O
here	O
s	O
makerange	O
def	O
makerangeestimate	O
stderr	O
num	O
stderrs	O
spread	O
stderr	O
num	O
stderrs	O
array	O
numpy	B
linspaceestimate-spread	O
estimatespread	O
num	O
points	O
return	O
array	O
numpy	B
linspace	B
makes	O
an	O
array	O
of	O
equally	O
spaced	O
elements	O
between	O
estimate-spread	O
and	O
estimatespread	O
including	O
both	O
update	B
finally	O
here	O
s	O
the	O
code	O
to	O
make	O
and	O
update	B
the	O
suite	B
mus	O
sigmas	O
findpriorrangesxs	O
num	O
points	O
suite	B
heightmus	O
sigmas	O
the	O
posterior	B
distribution	B
of	O
cv	O
suite	B
updatesetxs	O
print	O
suite	B
maximumlikelihood	O
this	O
process	B
might	O
seem	O
bogus	B
because	O
we	O
use	O
the	O
data	O
to	O
choose	O
the	O
range	O
of	O
the	O
prior	B
distribution	B
and	O
then	O
use	O
the	O
data	O
again	O
to	O
do	O
the	O
update	B
in	O
general	O
using	O
the	O
same	O
data	O
twice	O
is	O
in	O
fact	O
bogus	B
but	O
in	O
this	O
case	O
it	O
is	O
ok	O
really	O
we	O
use	O
the	O
data	O
to	O
choose	O
the	O
range	O
for	O
the	O
prior	B
but	O
only	O
to	O
avoid	O
computing	O
a	O
lot	O
of	O
probabilities	O
that	O
would	O
have	O
been	O
very	O
small	O
anyway	O
with	O
the	O
range	O
is	O
big	O
enough	O
to	O
cover	O
all	O
values	O
with	O
non-negligible	O
likelihood	B
after	O
that	O
making	O
it	O
bigger	O
has	O
no	O
effect	O
on	O
the	O
results	O
in	O
effect	O
the	O
prior	B
is	O
uniform	O
over	O
all	O
values	O
of	O
mu	O
and	O
sigma	O
but	O
for	O
computational	O
efficiency	O
we	O
ignore	O
all	O
the	O
values	O
that	O
don	O
t	O
matter	O
the	O
posterior	B
distribution	B
of	O
cv	O
once	O
we	O
have	O
the	O
posterior	B
joint	B
distribution	B
of	O
mu	O
and	O
sigma	O
we	O
can	O
compute	O
the	O
distribution	B
of	O
cv	O
for	O
men	O
and	O
women	O
and	O
then	O
the	O
probability	B
that	O
one	O
exceeds	O
the	O
other	O
to	O
compute	O
the	O
distribution	B
of	O
cv	O
we	O
enumerate	O
pairs	O
of	O
mu	O
and	O
sigma	O
def	O
coefvariationsuite	O
pmf	B
thinkbayes	O
pmf	B
for	O
sigma	O
p	O
in	O
suite	B
items	O
pmf	B
incrsigmamu	O
p	O
return	O
pmf	B
then	O
we	O
use	O
thinkbayes	O
pmfprobgreater	O
to	O
compute	O
the	O
probability	B
that	O
men	O
are	O
more	O
variable	O
the	O
analysis	O
itself	O
is	O
simple	O
but	O
there	O
are	O
two	O
more	O
issues	O
we	O
have	O
to	O
deal	O
with	O
as	O
the	O
size	O
of	O
the	O
dataset	O
increases	O
we	O
run	O
into	O
a	O
series	O
of	O
computa	O
tional	O
problems	O
due	O
to	O
the	O
limitations	O
of	O
floating-point	O
arithmetic	O
the	O
dataset	O
contains	O
a	O
number	O
of	O
extreme	O
values	O
that	O
are	O
almost	O
certainly	O
errors	O
we	O
will	O
need	O
to	O
make	O
the	O
estimation	O
process	B
robust	O
in	O
the	O
presence	O
of	O
these	O
outliers	O
the	O
following	O
sections	O
explain	O
these	O
problems	O
and	O
their	O
solutions	O
chapter	O
approximate	O
bayesian	O
computation	O
underflow	O
if	O
we	O
select	O
the	O
first	O
values	O
from	O
the	O
brfss	B
dataset	O
and	O
run	O
the	O
analysis	O
i	O
just	O
described	O
it	O
runs	O
without	O
errors	O
and	O
we	O
get	O
posterior	B
distributions	O
that	O
look	O
reasonable	O
if	O
we	O
select	O
the	O
first	O
values	O
and	O
run	O
the	O
program	O
again	O
we	O
get	O
an	O
error	B
in	O
pmf	B
normalize	B
valueerror	O
total	B
probability	B
is	O
zero	O
the	O
problem	O
is	O
that	O
we	O
are	O
using	O
probability	B
densities	O
to	O
compute	O
likelihoods	O
and	O
densities	O
from	O
continuous	O
distributions	O
tend	O
to	O
be	O
small	O
and	O
if	O
you	O
take	O
small	O
values	O
and	O
multiply	O
them	O
together	O
the	O
result	O
is	O
very	O
small	O
in	O
this	O
case	O
it	O
is	O
so	O
small	O
it	O
can	O
t	O
be	O
represented	O
by	O
a	O
floating-point	O
number	O
so	O
it	O
gets	O
rounded	O
down	O
to	O
zero	O
which	O
is	O
called	O
underflow	O
and	O
if	O
all	O
probabilities	O
in	O
the	O
distribution	B
are	O
it	O
s	O
not	O
a	O
distribution	B
any	O
more	O
a	O
possible	O
solution	O
is	O
to	O
renormalize	B
the	O
pmf	B
after	O
each	O
update	B
or	O
after	O
each	O
batch	O
of	O
that	O
would	O
work	O
but	O
it	O
would	O
be	O
slow	O
a	O
better	O
alternative	O
is	O
to	O
compute	O
likelihoods	O
under	O
a	O
log	B
transform	I
that	O
way	O
instead	O
of	O
multiplying	O
small	O
values	O
we	O
can	O
add	O
up	O
log	O
likelihoods	O
pmf	B
provides	O
methods	O
log	O
logupdateset	O
and	O
exp	O
to	O
make	O
this	O
process	B
easy	O
log	O
computes	O
the	O
log	O
of	O
the	O
probabilities	O
in	O
a	O
pmf	B
class	I
pmf	B
def	O
logself	O
m	O
self	O
maxlike	O
for	O
x	O
p	O
in	O
self	O
d	O
iteritems	O
if	O
p	O
self	O
setx	O
math	O
logpm	O
else	O
self	O
removex	O
before	O
applying	O
the	O
log	B
transform	I
log	O
uses	O
maxlike	O
to	O
find	O
m	O
the	O
highest	O
probability	B
in	O
the	O
pmf	B
it	O
divide	O
all	O
probabilities	O
by	O
m	O
so	O
the	O
highest	O
probability	B
gets	O
normalized	O
to	O
which	O
yields	O
a	O
log	O
of	O
the	O
other	O
log	O
probabilities	O
are	O
all	O
negative	O
if	O
there	O
are	O
any	O
values	O
in	O
the	O
pmf	B
with	O
probability	B
they	O
are	O
removed	O
while	O
the	O
pmf	B
is	O
under	O
a	O
log	B
transform	I
we	O
can	O
t	O
use	O
update	B
updateset	O
or	O
normalize	B
the	O
result	O
would	O
be	O
nonsensical	O
if	O
you	O
try	O
pmf	B
raises	O
an	O
exception	B
instead	O
we	O
have	O
to	O
use	O
logupdate	O
and	O
logupdateset	O
log-likelihood	B
here	O
s	O
the	O
implementation	B
of	O
logupdateset	O
class	O
suite	B
def	O
logupdatesetself	O
dataset	O
for	O
data	O
in	O
dataset	O
self	O
logupdatedata	O
logupdateset	O
loops	O
through	O
the	O
data	O
and	O
calls	O
logupdate	O
class	O
suite	B
def	O
logupdateself	O
data	O
for	O
hypo	O
in	O
self	O
values	O
like	O
self	O
loglikelihooddata	O
hypo	O
self	O
incrhypo	O
like	O
logupdate	O
is	O
just	O
like	O
update	B
except	O
that	O
it	O
calls	O
loglikelihood	O
instead	O
of	O
likelihood	B
and	O
incr	O
instead	O
of	O
mult	B
using	O
log-likelihoods	O
avoids	O
the	O
problem	O
with	O
underflow	O
but	O
while	O
the	O
pmf	B
is	O
under	O
the	O
log	B
transform	I
there	O
s	O
not	O
much	O
we	O
can	O
do	O
with	O
it	O
we	O
have	O
to	O
use	O
exp	O
to	O
invert	O
the	O
transform	O
class	O
pmf	B
def	O
expself	O
m	O
self	O
maxlike	O
for	O
x	O
p	O
in	O
self	O
d	O
iteritems	O
self	O
setx	O
math	O
expp-m	O
if	O
the	O
log-likelihoods	O
are	O
large	O
negative	O
numbers	O
the	O
resulting	O
likelihoods	O
might	O
underflow	O
so	O
exp	O
finds	O
the	O
maximum	B
log-likelihood	B
m	O
and	O
shifts	O
all	O
the	O
likelihoods	O
up	O
by	O
m	O
the	O
resulting	O
distribution	B
has	O
a	O
maximum	B
likelihood	B
of	O
this	O
process	B
inverts	O
the	O
log	B
transform	I
with	O
minimal	O
loss	O
of	O
precision	O
log-likelihood	B
now	O
all	O
we	O
need	O
is	O
loglikelihood	O
class	O
height	B
def	O
loglikelihoodself	O
data	O
hypo	O
x	O
data	O
chapter	O
approximate	O
bayesian	O
computation	O
mu	O
sigma	O
hypo	O
loglike	O
scipy	B
stats	O
norm	O
logpdfx	O
mu	O
sigma	O
return	O
loglike	O
norm	O
logpdf	O
computes	O
the	O
log-likelihood	B
of	O
the	O
gaussian	B
pdf	B
here	O
s	O
what	O
the	O
whole	O
update	B
process	B
looks	O
like	O
suite	B
log	O
suite	B
logupdatesetxs	O
suite	B
exp	O
suite	B
normalize	B
to	O
review	O
log	O
puts	O
the	O
suite	B
under	O
a	O
log	B
transform	I
logupdateset	O
calls	O
logupdate	O
which	O
calls	O
loglikelihood	O
logupdate	O
uses	O
pmf	B
incr	O
because	O
adding	O
a	O
log-likelihood	B
is	O
the	O
same	O
as	O
multiplying	O
by	O
a	O
likelihood	B
after	O
the	O
update	B
the	O
log-likelihoods	O
are	O
large	O
negative	O
numbers	O
so	O
exp	O
shifts	O
them	O
up	O
before	O
inverting	O
the	O
transform	O
which	O
is	O
how	O
we	O
avoid	O
underflow	O
once	O
the	O
suite	B
is	O
transformed	O
back	O
the	O
probabilities	O
are	O
linear	O
again	O
which	O
means	O
not	O
logarithmic	O
so	O
we	O
can	O
use	O
normalize	B
again	O
using	O
this	O
algorithm	O
we	O
can	O
process	B
the	O
entire	O
dataset	O
without	O
underflow	O
but	O
it	O
is	O
still	O
slow	O
on	O
my	O
computer	O
it	O
might	O
take	O
an	O
hour	O
we	O
can	O
do	O
better	O
a	O
little	O
optimization	B
this	O
section	O
uses	O
math	O
and	O
computational	O
optimization	B
to	O
speed	O
things	O
up	O
by	O
a	O
factor	O
of	O
but	O
the	O
following	O
section	O
presents	O
an	O
algorithm	O
that	O
is	O
even	O
faster	O
so	O
if	O
you	O
want	O
to	O
get	O
right	O
to	O
the	O
good	O
stuff	O
feel	O
free	O
to	O
skip	O
this	O
section	O
suite	B
logupdateset	O
calls	O
logupdate	O
once	O
for	O
each	O
data	O
point	O
we	O
can	O
speed	O
it	O
up	O
by	O
computing	O
the	O
log-likelihood	B
of	O
the	O
entire	O
dataset	O
at	O
once	O
x	O
x	O
log	O
we	O
ll	O
start	O
with	O
the	O
gaussian	B
pdf	B
exp	O
and	O
compute	O
the	O
log	O
the	O
constant	O
term	O
a	O
little	O
optimization	B
given	O
a	O
sequence	O
of	O
values	O
xi	O
the	O
total	O
log-likelihood	B
is	O
xi	O
i	O
log	O
pulling	O
out	O
the	O
terms	O
that	O
don	O
t	O
depend	O
on	O
i	O
we	O
get	O
n	O
log	O
i	O
which	O
we	O
can	O
translate	O
into	O
python	O
class	O
height	B
def	O
logupdatesetfastself	O
data	O
xs	O
tupledata	O
n	O
lenxs	O
for	O
hypo	O
in	O
self	O
values	O
mu	O
sigma	O
hypo	O
total	O
summationxs	O
mu	O
loglike	O
math	O
logsigma	O
total	O
self	O
incrhypo	O
loglike	O
by	O
itself	O
this	O
would	O
be	O
a	O
small	O
improvement	O
but	O
it	O
creates	O
an	O
opportunity	O
for	O
a	O
bigger	O
one	O
notice	O
that	O
the	O
summation	O
only	O
depends	O
on	O
mu	O
not	O
sigma	O
so	O
we	O
only	O
have	O
to	O
compute	O
it	O
once	O
for	O
each	O
value	O
of	O
mu	O
to	O
avoid	O
recomputing	O
i	O
factor	O
out	O
a	O
function	O
that	O
computes	O
the	O
summation	O
and	O
memoize	O
it	O
so	O
it	O
stores	O
previously	O
computed	O
results	O
in	O
a	O
dictionary	O
httpen	O
wikipedia	O
orgwikimemoization	O
def	O
summationxs	O
mu	O
cache	B
try	O
return	O
cachexs	O
mu	O
except	O
keyerror	O
ds	O
for	O
x	O
in	O
xs	O
total	O
sumds	O
cachexs	O
mu	O
total	O
return	O
total	O
cache	B
stores	O
previously	O
computed	O
sums	O
the	O
try	O
statement	O
returns	O
a	O
result	O
from	O
the	O
cache	B
if	O
possible	O
otherwise	O
it	O
computes	O
the	O
summation	O
then	O
caches	O
and	O
returns	O
the	O
result	O
the	O
only	O
catch	O
is	O
that	O
we	O
can	O
t	O
use	O
a	O
list	O
as	O
a	O
key	O
in	O
the	O
cache	B
because	O
it	O
is	O
chapter	O
approximate	O
bayesian	O
computation	O
not	O
a	O
hashable	O
type	O
that	O
s	O
why	O
logupdatesetfast	O
converts	O
the	O
dataset	O
to	O
a	O
tuple	B
this	O
optimization	B
speeds	O
up	O
the	O
computation	O
by	O
about	O
a	O
factor	O
of	O
processing	O
the	O
entire	O
dataset	O
men	O
and	O
women	O
in	O
less	O
than	O
a	O
minute	O
on	O
my	O
not-very-fast	O
computer	O
abc	B
but	O
maybe	O
you	O
don	O
t	O
have	O
that	O
kind	O
of	O
time	O
in	O
that	O
case	O
approximate	O
bayesian	O
computation	O
might	O
be	O
the	O
way	O
to	O
go	O
the	O
motivation	O
behind	O
abc	B
is	O
that	O
the	O
likelihood	B
of	O
any	O
particular	O
dataset	O
is	O
very	O
small	O
especially	O
for	O
large	O
datasets	O
which	O
is	O
why	O
we	O
had	O
to	O
use	O
the	O
log	B
transform	I
expensive	O
to	O
compute	O
which	O
is	O
why	O
we	O
had	O
to	O
do	O
so	O
much	O
optimiza	O
tion	B
and	O
not	O
really	O
what	O
we	O
want	O
anyway	O
we	O
don	O
t	O
really	O
care	O
about	O
the	O
likelihood	B
of	O
seeing	O
the	O
exact	O
dataset	O
we	O
saw	O
especially	O
for	O
continuous	O
variables	O
we	O
care	O
about	O
the	O
likelihood	B
of	O
seeing	O
any	O
dataset	O
like	O
the	O
one	O
we	O
saw	O
for	O
example	O
in	O
the	O
euro	B
problem	I
we	O
don	O
t	O
care	O
about	O
the	O
order	O
of	O
the	O
coin	O
flips	O
only	O
the	O
total	O
number	O
of	O
heads	O
and	O
tails	O
and	O
in	O
the	O
locomotive	B
problem	I
we	O
don	O
t	O
care	O
about	O
which	O
particular	O
trains	O
were	O
seen	O
only	O
the	O
number	O
of	O
trains	O
and	O
the	O
maximum	B
of	O
the	O
serial	O
numbers	O
similarly	O
in	O
the	O
brfss	B
sample	O
we	O
don	O
t	O
really	O
want	O
to	O
know	O
the	O
probability	B
of	O
seeing	O
one	O
particular	O
set	O
of	O
values	O
since	O
there	O
are	O
hundreds	O
of	O
thousands	O
of	O
them	O
it	O
is	O
more	O
relevant	O
to	O
ask	O
if	O
we	O
sample	O
people	O
from	O
a	O
population	O
with	O
hypothetical	O
values	O
of	O
and	O
what	O
would	O
be	O
the	O
chance	O
of	O
collecting	O
a	O
sample	O
with	O
the	O
observed	O
mean	O
and	O
variance	O
for	O
samples	O
from	O
a	O
gaussian	B
distribution	B
we	O
can	O
answer	O
this	O
question	O
efficiently	O
because	O
we	O
can	O
find	O
the	O
distribution	B
of	O
the	O
sample	B
statistics	I
analytically	O
in	O
fact	O
we	O
already	O
did	O
it	O
when	O
we	O
computed	O
the	O
range	O
of	O
the	O
prior	B
if	O
you	O
draw	O
n	O
values	O
from	O
a	O
gaussian	B
distribution	B
with	O
parameters	O
and	O
and	O
compute	O
the	O
sample	O
mean	O
m	O
the	O
distribution	B
of	O
m	O
is	O
gaussian	O
with	O
parameters	O
and	O
n	O
robust	B
estimation	I
with	O
parameters	O
and	O
similarly	O
the	O
distribution	B
of	O
the	O
sample	O
standard	O
deviation	O
s	O
is	O
gaussian	O
we	O
can	O
use	O
these	O
sample	O
distributions	O
to	O
compute	O
the	O
likelihood	B
of	O
the	O
sample	B
statistics	I
m	O
and	O
s	O
given	O
hypothetical	O
values	O
for	O
and	O
here	O
s	O
a	O
new	O
version	O
of	O
logupdateset	O
that	O
does	O
it	O
def	O
logupdatesetabcself	O
data	O
xs	O
data	O
n	O
lenxs	O
compute	O
sample	B
statistics	I
m	O
numpy	B
meanxs	O
s	O
numpy	B
stdxs	O
for	O
hypo	O
in	O
sortedself	O
values	O
mu	O
sigma	O
hypo	O
compute	O
log	O
likelihood	B
of	O
m	O
given	O
hypo	O
stderr	O
m	O
sigma	O
math	O
sqrtn	O
loglike	O
evalgaussianlogpdfm	O
mu	O
stderr	O
m	O
log	O
likelihood	B
of	O
s	O
given	O
hypo	O
stderr	O
s	O
sigma	O
loglike	O
evalgaussianlogpdfs	O
sigma	O
stderr	O
s	O
self	O
incrhypo	O
loglike	O
on	O
my	O
computer	O
this	O
function	O
processes	O
the	O
entire	O
dataset	O
in	O
about	O
a	O
second	O
and	O
the	O
result	O
agrees	O
with	O
the	O
exact	O
result	O
with	O
about	O
digits	O
of	O
precision	O
robust	B
estimation	I
we	O
are	O
almost	O
ready	O
to	O
look	O
at	O
results	O
but	O
we	O
have	O
one	O
more	O
problem	O
to	O
deal	O
with	O
there	O
are	O
a	O
number	O
of	O
outliers	O
in	O
this	O
dataset	O
that	O
are	O
almost	O
certainly	O
errors	O
for	O
example	O
there	O
are	O
three	O
adults	O
with	O
reported	O
height	B
of	O
cm	O
which	O
would	O
place	O
them	O
among	O
the	O
shortest	O
living	O
adults	O
in	O
the	O
world	O
at	O
the	O
other	O
end	O
there	O
are	O
four	O
women	O
with	O
reported	O
height	B
cm	O
just	O
short	O
of	O
the	O
tallest	O
women	O
in	O
the	O
world	O
it	O
is	O
not	O
impossible	O
that	O
these	O
values	O
are	O
correct	O
but	O
it	O
is	O
unlikely	O
which	O
makes	O
it	O
hard	O
to	O
know	O
how	O
to	O
deal	O
with	O
them	O
and	O
we	O
have	O
to	O
get	O
it	O
chapter	O
approximate	O
bayesian	O
computation	O
figure	O
contour	O
plot	O
of	O
the	O
posterior	B
joint	B
distribution	B
of	O
mean	O
and	O
standard	O
deviation	O
of	O
height	B
for	O
men	O
in	O
the	O
u	O
s	O
figure	O
contour	O
plot	O
of	O
the	O
posterior	B
joint	B
distribution	B
of	O
mean	O
and	O
standard	O
deviation	O
of	O
height	B
for	O
women	O
in	O
the	O
u	O
s	O
height	B
joint	B
height	B
joint	B
distribution	B
robust	B
estimation	I
right	O
because	O
these	O
extreme	O
values	O
have	O
a	O
disproportionate	O
effect	O
on	O
the	O
estimated	O
variability	O
because	O
abc	B
is	O
based	O
on	O
summary	O
statistics	O
rather	O
than	O
the	O
entire	O
dataset	O
we	O
can	O
make	O
it	O
more	O
robust	O
by	O
choosing	O
summary	O
statistics	O
that	O
are	O
robust	O
in	O
the	O
presence	O
of	O
outliers	O
for	O
example	O
rather	O
than	O
use	O
the	O
sample	O
mean	O
and	O
standard	O
deviation	O
we	O
could	O
use	O
the	O
median	B
and	O
inter-quartile	B
range	I
which	O
is	O
the	O
difference	O
between	O
the	O
and	O
percentiles	O
more	O
generally	O
we	O
could	O
compute	O
an	O
inter-percentile	O
range	O
that	O
spans	O
any	O
given	O
fraction	O
of	O
the	O
distribution	B
p	O
def	O
medianiprxs	O
p	O
cdf	B
thinkbayes	O
makecdffromlistxs	O
median	B
alpha	O
ipr	O
cdf	B
valuealpha	O
return	O
median	B
ipr	O
xs	O
is	O
a	O
sequence	O
of	O
values	O
p	O
is	O
the	O
desired	O
range	O
for	O
example	O
yields	O
the	O
inter-quartile	B
range	I
medianipr	O
works	O
by	O
computing	O
the	O
cdf	B
of	O
xs	O
then	O
extracting	O
the	O
median	B
and	O
the	O
difference	O
between	O
two	O
percentiles	O
we	O
can	O
convert	O
from	O
ipr	O
to	O
an	O
estimate	O
of	O
sigma	O
using	O
the	O
gaussian	O
cdf	B
to	O
compute	O
the	O
fraction	O
of	O
the	O
distribution	B
covered	O
by	O
a	O
given	O
number	O
of	O
standard	O
deviations	O
for	O
example	O
it	O
is	O
a	O
well-known	O
rule	O
of	O
thumb	O
that	O
of	O
a	O
gaussian	B
distribution	B
falls	O
within	O
one	O
standard	O
deviation	O
of	O
the	O
mean	O
which	O
leaves	O
in	O
each	O
tail	O
if	O
we	O
compute	O
the	O
range	O
between	O
the	O
and	O
percentiles	O
we	O
expect	O
the	O
result	O
to	O
be	O
sigma	O
so	O
we	O
can	O
estimate	O
sigma	O
by	O
computing	O
the	O
ipr	O
and	O
dividing	O
by	O
more	O
generally	O
we	O
could	O
use	O
any	O
number	O
of	O
sigmas	O
medians	O
performs	O
the	O
more	O
general	O
version	O
of	O
this	O
computation	O
def	O
mediansxs	O
num	O
sigmas	O
half	O
p	O
thinkbayes	O
standardgaussiancdfnum	O
sigmas	O
median	B
ipr	O
medianiprxs	O
half	O
p	O
s	O
ipr	O
num	O
sigmas	O
return	O
median	B
s	O
chapter	O
approximate	O
bayesian	O
computation	O
figure	O
posterior	B
distributions	O
of	O
cv	O
for	O
men	O
and	O
women	O
based	O
on	O
robust	O
estimators	O
again	O
xs	O
is	O
the	O
sequence	O
of	O
values	O
num	O
sigmas	O
is	O
the	O
number	O
of	O
standard	O
deviations	O
the	O
results	O
should	O
be	O
based	O
on	O
the	O
result	O
is	O
median	B
which	O
estimates	O
and	O
s	O
which	O
estimates	O
finally	O
in	O
logupdatesetabc	O
we	O
can	O
replace	O
the	O
sample	O
mean	O
and	O
standard	O
deviation	O
with	O
median	B
and	O
s	O
and	O
that	O
pretty	O
much	O
does	O
it	O
it	O
might	O
seem	O
odd	O
that	O
we	O
are	O
using	O
observed	O
percentiles	O
to	O
estimate	O
and	O
but	O
it	O
is	O
an	O
example	O
of	O
the	O
flexibility	O
of	O
the	O
bayesian	O
approach	O
in	O
effect	O
we	O
are	O
asking	O
given	O
hypothetical	O
values	O
for	O
and	O
and	O
a	O
sampling	O
process	B
that	O
has	O
some	O
chance	O
of	O
introducing	O
errors	O
what	O
is	O
the	O
likelihood	B
of	O
generating	O
a	O
given	O
set	O
of	O
sample	B
statistics	I
we	O
are	O
free	O
to	O
choose	O
any	O
sample	B
statistics	I
we	O
like	O
up	O
to	O
a	O
point	O
and	O
determine	O
the	O
location	O
and	O
spread	O
of	O
a	O
distribution	B
so	O
we	O
need	O
to	O
choose	O
statistics	O
that	O
capture	O
those	O
characteristics	O
for	O
example	O
if	O
we	O
chose	O
the	O
and	O
percentiles	O
we	O
would	O
get	O
very	O
little	O
information	O
about	O
spread	O
so	O
it	O
would	O
leave	O
the	O
estimate	O
of	O
relatively	O
unconstrained	O
by	O
the	O
data	O
all	O
values	O
of	O
sigma	O
would	O
have	O
nearly	O
the	O
same	O
likelihood	B
of	O
producing	O
the	O
observed	O
values	O
so	O
the	O
posterior	B
distribution	B
of	O
sigma	O
would	O
look	O
a	O
lot	O
like	O
the	O
prior	B
who	O
is	O
more	O
variable	O
finally	O
we	O
are	O
ready	O
to	O
answer	O
the	O
question	O
we	O
started	O
with	O
is	O
the	O
coefficient	B
of	I
variation	I
greater	O
for	O
men	O
than	O
for	O
women	O
of	O
discussion	O
using	O
abc	B
based	O
on	O
the	O
median	B
and	O
ipr	O
with	O
i	O
computed	O
posterior	B
joint	B
distributions	O
for	O
mu	O
and	O
sigma	O
figures	O
and	O
show	O
the	O
results	O
as	O
a	O
contour	O
plot	O
with	O
mu	O
on	O
the	O
x-axis	O
sigma	O
on	O
the	O
y-axis	O
and	O
probability	B
on	O
the	O
z-axis	O
for	O
each	O
joint	B
distribution	B
i	O
computed	O
the	O
posterior	B
distribution	B
of	O
cv	O
figure	O
shows	O
these	O
distributions	O
for	O
men	O
and	O
women	O
the	O
mean	O
for	O
men	O
is	O
for	O
women	O
it	O
is	O
since	O
there	O
is	O
no	O
overlap	O
between	O
the	O
distributions	O
we	O
conclude	O
with	O
near	O
certainty	O
that	O
women	O
are	O
more	O
variable	O
in	O
height	B
than	O
men	O
so	O
is	O
that	O
the	O
end	O
of	O
the	O
variability	B
hypothesis	I
it	O
turns	O
out	O
that	O
this	O
result	O
depends	O
on	O
the	O
choice	O
of	O
the	O
inter-percentile	O
range	O
with	O
we	O
conclude	O
that	O
women	O
are	O
more	O
variable	O
but	O
with	O
we	O
conclude	O
with	O
equal	O
confidence	O
that	O
men	O
are	O
more	O
variable	O
sadly	O
no	O
the	O
reason	O
for	O
the	O
difference	O
is	O
that	O
there	O
are	O
more	O
men	O
of	O
short	O
stature	O
and	O
their	O
distance	O
from	O
the	O
mean	O
is	O
greater	O
so	O
our	O
evaluation	O
of	O
the	O
variability	B
hypothesis	I
depends	O
on	O
the	O
interpretation	O
of	O
variability	O
with	O
we	O
focus	O
on	O
people	O
near	O
the	O
mean	O
as	O
we	O
increase	O
num	O
sigmas	O
we	O
give	O
more	O
weight	O
to	O
the	O
extremes	O
to	O
decide	O
which	O
emphasis	O
is	O
appropriate	O
we	O
would	O
need	O
a	O
more	O
precise	O
statement	O
of	O
the	O
hypothesis	O
as	O
it	O
is	O
the	O
variability	B
hypothesis	I
may	O
be	O
too	O
vague	O
to	O
evaluate	O
nevertheless	O
it	O
helped	O
me	O
demonstrate	O
several	O
new	O
ideas	O
and	O
i	O
hope	O
you	O
agree	O
it	O
makes	O
an	O
interesting	O
example	O
discussion	O
there	O
are	O
two	O
ways	O
you	O
might	O
think	O
of	O
abc	B
one	O
interpretation	O
is	O
that	O
it	O
is	O
as	O
the	O
name	O
suggests	O
an	O
approximation	O
that	O
is	O
faster	O
to	O
compute	O
than	O
the	O
exact	O
value	O
but	O
remember	O
that	O
bayesian	O
analysis	O
is	O
always	O
based	O
on	O
modeling	B
decisions	O
which	O
implies	O
that	O
there	O
is	O
no	O
exact	O
solution	O
for	O
any	O
interesting	O
physical	O
system	B
there	O
are	O
many	O
possible	O
models	O
and	O
each	O
model	O
yields	O
different	O
results	O
to	O
interpret	O
the	O
results	O
we	O
have	O
to	O
evaluate	O
the	O
models	O
chapter	O
approximate	O
bayesian	O
computation	O
so	O
another	O
interpretation	O
of	O
abc	B
is	O
that	O
it	O
represents	O
an	O
alternative	O
model	O
of	O
the	O
likelihood	B
when	O
we	O
compute	O
pdh	O
we	O
are	O
asking	O
what	O
is	O
the	O
likelihood	B
of	O
the	O
data	O
under	O
a	O
given	O
hypothesis	O
for	O
large	O
datasets	O
the	O
likelihood	B
of	O
the	O
data	O
is	O
very	O
small	O
which	O
is	O
a	O
hint	O
that	O
we	O
might	O
not	O
be	O
asking	O
the	O
right	O
question	O
what	O
we	O
really	O
want	O
to	O
know	O
is	O
the	O
likelihood	B
of	O
any	O
outcome	O
like	O
the	O
data	O
where	O
the	O
definition	O
of	O
like	O
is	O
yet	O
another	O
modeling	B
decision	O
the	O
underlying	O
idea	O
of	O
abc	B
is	O
that	O
two	O
datasets	O
are	O
alike	O
if	O
they	O
yield	O
the	O
same	O
summary	O
statistics	O
but	O
in	O
some	O
cases	O
like	O
the	O
example	O
in	O
this	O
chapter	O
it	O
is	O
not	O
obvious	O
which	O
summary	O
statistics	O
to	O
choose	O
you	O
can	O
download	O
the	O
code	O
in	O
this	O
chapter	O
from	O
httpthinkbayes	O
com	O
variability	O
py	O
for	O
more	O
information	O
see	O
section	O
exercises	O
exercise	O
an	O
effect	O
size	O
is	O
a	O
statistic	O
intended	O
to	O
measure	O
the	O
difference	O
between	O
two	O
groups	O
http	O
en	O
wikipedia	O
org	O
wiki	O
effect	O
size	O
for	O
example	O
we	O
could	O
use	O
data	O
from	O
the	O
brfss	B
to	O
estimate	O
the	O
difference	O
in	O
height	B
between	O
men	O
and	O
women	O
by	O
sampling	O
values	O
from	O
the	O
posterior	B
distributions	O
of	O
and	O
we	O
could	O
generate	O
the	O
posterior	B
distribution	B
of	O
this	O
difference	O
but	O
it	O
might	O
be	O
better	O
to	O
use	O
a	O
dimensionless	O
measure	O
of	O
effect	O
size	O
rather	O
than	O
a	O
difference	O
measured	O
in	O
cm	O
one	O
option	O
is	O
to	O
use	O
divide	O
through	O
by	O
the	O
standard	O
deviation	O
to	O
what	O
we	O
did	O
with	O
the	O
coefficient	B
of	I
variation	I
if	O
the	O
parameters	O
for	O
group	O
are	O
and	O
the	O
parameters	O
for	O
group	O
are	O
the	O
dimensionless	O
effect	O
size	O
is	O
write	O
a	O
function	O
that	O
takes	O
joint	B
distributions	O
of	O
mu	O
and	O
sigma	O
for	O
two	O
groups	O
and	O
returns	O
the	O
posterior	B
distribution	B
of	O
effect	O
size	O
hint	O
if	O
enumerating	O
all	O
pairs	O
from	O
the	O
two	O
distributions	O
takes	O
too	O
long	O
consider	O
random	O
sampling	O
chapter	O
hypothesis	B
testing	I
back	O
to	O
the	O
euro	B
problem	I
in	O
section	O
i	O
presented	O
a	O
problem	O
from	O
mackay	B
s	O
information	O
theory	O
inference	O
and	O
learning	O
algorithms	O
a	O
statistical	O
statement	O
appeared	O
in	O
the	O
guardian	O
on	O
friday	O
january	O
when	O
spun	O
on	O
edge	O
times	O
a	O
belgian	O
one-euro	O
coin	O
came	O
up	O
heads	O
times	O
and	O
tails	O
it	O
looks	O
very	O
suspicious	O
to	O
me	O
said	O
barry	O
blight	O
a	O
statistics	O
lecturer	O
at	O
the	O
london	O
school	O
of	O
economics	O
if	O
the	O
coin	O
were	O
unbiased	O
the	O
chance	O
of	O
getting	O
a	O
result	O
as	O
extreme	O
as	O
that	O
would	O
be	O
less	O
than	O
but	O
do	O
these	O
data	O
give	O
evidence	O
that	O
the	O
coin	O
is	O
biased	O
rather	O
than	O
fair	O
we	O
estimated	O
the	O
probability	B
that	O
the	O
coin	O
would	O
land	O
face	O
up	O
but	O
we	O
didn	O
t	O
really	O
answer	O
mackay	B
s	O
question	O
do	O
the	O
data	O
give	O
evidence	O
that	O
the	O
coin	O
is	O
biased	O
in	O
chapter	O
i	O
proposed	O
that	O
data	O
are	O
in	O
favor	O
of	O
a	O
hypothesis	O
if	O
the	O
data	O
are	O
more	O
likely	O
under	O
the	O
hypothesis	O
than	O
under	O
the	O
alternative	O
or	O
equivalently	O
if	O
the	O
bayes	B
factor	I
is	O
greater	O
than	O
in	O
the	O
euro	O
example	O
we	O
have	O
two	O
hypotheses	O
to	O
consider	O
i	O
ll	O
use	O
f	O
for	O
the	O
hypothesis	O
that	O
the	O
coin	O
is	O
fair	O
and	O
b	O
for	O
the	O
hypothesis	O
that	O
it	O
is	O
biased	O
if	O
the	O
coin	O
is	O
fair	O
it	O
is	O
easy	O
to	O
compute	O
the	O
likelihood	B
of	O
the	O
data	O
pdf	B
in	O
fact	O
we	O
already	O
wrote	O
the	O
function	O
that	O
does	O
it	O
chapter	O
hypothesis	B
testing	I
def	O
likelihoodself	O
data	O
hypo	O
x	O
hypo	O
head	O
tails	O
data	O
like	O
xheads	O
return	O
like	O
to	O
use	O
it	O
we	O
can	O
create	O
a	O
euro	O
suite	B
and	O
invoke	O
likelihood	B
suite	B
euro	O
likelihood	B
suite	B
likelihooddata	O
pdf	B
is	O
which	O
doesn	O
t	O
tell	O
us	O
much	O
except	O
that	O
the	O
probability	B
of	O
seeing	O
any	O
particular	O
dataset	O
is	O
very	O
small	O
it	O
takes	O
two	O
likelihoods	O
to	O
make	O
a	O
ratio	O
so	O
we	O
also	O
have	O
to	O
compute	O
pdb	O
it	O
is	O
not	O
obvious	O
how	O
to	O
compute	O
the	O
likelihood	B
of	O
b	O
because	O
it	O
s	O
not	O
obvious	O
what	O
biased	O
means	O
one	O
possibility	O
is	O
to	O
cheat	O
and	O
look	O
at	O
the	O
data	O
before	O
we	O
define	O
the	O
hypothesis	O
in	O
that	O
case	O
we	O
would	O
say	O
that	O
biased	O
means	O
that	O
the	O
probability	B
of	O
heads	O
is	O
actual	O
percent	O
likelihood	B
suite	B
likelihooddata	O
actual	O
percent	O
this	O
version	O
of	O
b	O
i	O
call	O
b	O
cheat	O
the	O
likelihood	B
of	O
b	O
cheat	O
is	O
and	O
the	O
likelihood	B
ratio	I
is	O
so	O
we	O
would	O
say	O
that	O
the	O
data	O
are	O
evidence	O
in	O
favor	O
of	O
this	O
version	O
of	O
b	O
but	O
using	O
the	O
data	O
to	O
formulate	O
the	O
hypothesis	O
is	O
obviously	O
bogus	B
by	O
that	O
definition	O
any	O
dataset	O
would	O
be	O
evidence	O
in	O
favor	O
of	O
b	O
unless	O
the	O
observed	O
percentage	O
of	O
heads	O
is	O
exactly	O
making	O
a	O
fair	O
comparison	O
to	O
make	O
a	O
legitimate	O
comparison	O
we	O
have	O
to	O
define	O
b	O
without	O
looking	O
at	O
the	O
data	O
so	O
let	O
s	O
try	O
a	O
different	O
definition	O
if	O
you	O
inspect	O
a	O
belgian	O
euro	O
coin	O
you	O
might	O
notice	O
that	O
the	O
heads	O
side	O
is	O
more	O
prominent	O
than	O
the	O
tails	O
side	O
you	O
might	O
expect	O
the	O
shape	O
to	O
have	O
some	O
effect	O
on	O
x	O
but	O
be	O
unsure	O
whether	O
it	O
makes	O
heads	O
more	O
or	O
less	O
likely	O
so	O
you	O
might	O
say	O
i	O
think	O
the	O
coin	O
is	O
biased	O
so	O
that	O
x	O
is	O
either	O
or	O
but	O
i	O
am	O
not	O
sure	O
which	O
we	O
can	O
think	O
of	O
this	O
version	O
which	O
i	O
ll	O
call	O
b	O
two	O
as	O
a	O
hypothesis	O
made	O
up	O
of	O
two	O
sub-hypotheses	O
we	O
can	O
compute	O
the	O
likelihood	B
for	O
each	O
subhypothesis	O
and	O
then	O
compute	O
the	O
average	O
likelihood	B
making	O
a	O
fair	O
comparison	O
suite	B
likelihooddata	O
suite	B
likelihooddata	O
likelihood	B
the	O
likelihood	B
ratio	I
bayes	B
factor	I
for	O
b	O
two	O
is	O
which	O
means	O
the	O
data	O
provide	O
weak	O
evidence	O
in	O
favor	O
of	O
b	O
two	O
more	O
generally	O
suppose	O
you	O
suspect	O
that	O
the	O
coin	O
is	O
biased	O
but	O
you	O
have	O
no	O
clue	O
about	O
the	O
value	O
of	O
x	O
in	O
that	O
case	O
you	O
might	O
build	O
a	O
suite	B
which	O
i	O
call	O
b	O
uniform	O
to	O
represent	O
sub-hypotheses	O
from	O
to	O
b	O
uniform	O
b	O
uniform	O
normalize	B
i	O
initialize	O
b	O
uniform	O
with	O
values	O
from	O
to	O
i	O
removed	O
the	O
subhypothesis	O
that	O
x	O
is	O
because	O
if	O
x	O
is	O
the	O
coin	O
is	O
fair	O
but	O
it	O
has	O
almost	O
no	O
effect	O
on	O
the	O
result	O
whether	O
you	O
remove	O
it	O
or	O
not	O
to	O
compute	O
the	O
likelihood	B
of	O
b	O
uniform	O
we	O
compute	O
the	O
likelihood	B
of	O
each	O
sub-hypothesis	O
and	O
accumulate	O
a	O
weighted	O
average	O
def	O
suitelikelihoodsuite	O
data	O
total	O
for	O
hypo	O
prob	B
in	O
suite	B
items	O
like	O
suite	B
likelihooddata	O
hypo	O
total	O
prob	B
like	O
return	O
total	O
the	O
likelihood	B
ratio	I
for	O
b	O
uniform	O
is	O
which	O
means	O
that	O
the	O
data	O
are	O
weak	O
evidence	O
against	O
b	O
uniform	O
compared	O
to	O
f	O
if	O
you	O
think	O
about	O
the	O
computation	O
performed	O
by	O
suitelikelihood	O
you	O
might	O
notice	O
that	O
it	O
is	O
similar	O
to	O
an	O
update	B
to	O
refresh	O
your	O
memory	O
here	O
s	O
the	O
update	B
function	O
def	O
updateself	O
data	O
for	O
hypo	O
in	O
self	O
values	O
like	O
self	O
likelihooddata	O
hypo	O
self	O
multhypo	O
like	O
return	O
self	O
normalize	B
and	O
here	O
s	O
normalize	B
def	O
normalizeself	O
total	O
self	O
total	O
factor	O
total	O
chapter	O
hypothesis	B
testing	I
for	O
x	O
in	O
self	O
d	O
self	O
dx	O
factor	O
return	O
total	O
the	O
return	O
value	O
from	O
normalize	B
is	O
the	O
total	O
of	O
the	O
probabilities	O
in	O
the	O
suite	B
which	O
is	O
the	O
average	O
of	O
the	O
likelihoods	O
for	O
the	O
sub-hypotheses	O
weighted	O
by	O
the	O
prior	B
probabilities	O
and	O
update	B
passes	O
this	O
value	O
along	O
so	O
instead	O
of	O
using	O
suitelikelihood	O
we	O
could	O
compute	O
the	O
likelihood	B
of	O
b	O
uniform	O
like	O
this	O
likelihood	B
b	O
uniform	O
updatedata	O
the	O
triangle	O
prior	B
in	O
chapter	O
we	O
also	O
considered	O
a	O
triangle-shaped	O
prior	B
that	O
gives	O
higher	O
probability	B
to	O
values	O
of	O
x	O
near	O
if	O
we	O
think	O
of	O
this	O
prior	B
as	O
a	O
suite	B
of	O
sub-hypotheses	O
we	O
can	O
compute	O
its	O
likelihood	B
like	O
this	O
b	O
triangle	O
triangleprior	O
likelihood	B
b	O
triangle	O
updatedata	O
the	O
likelihood	B
ratio	I
for	O
b	O
triangle	O
is	O
compared	O
to	O
f	O
so	O
again	O
we	O
would	O
say	O
that	O
the	O
data	O
are	O
weak	O
evidence	O
against	O
b	O
the	O
following	O
table	O
shows	O
the	O
priors	O
we	O
have	O
considered	O
the	O
likelihood	B
of	O
each	O
and	O
the	O
likelihood	B
ratio	I
bayes	B
factor	I
relative	O
to	O
f	O
hypothesis	O
likelihood	B
bayes	B
factor	I
f	O
b	O
cheat	O
b	O
two	O
b	O
uniform	O
b	O
triangle	O
depending	O
on	O
which	O
definition	O
we	O
choose	O
the	O
data	O
might	O
provide	O
evidence	O
for	O
or	O
against	O
the	O
hypothesis	O
that	O
the	O
coin	O
is	O
biased	O
but	O
in	O
either	O
case	O
it	O
is	O
relatively	O
weak	O
evidence	O
in	O
summary	O
we	O
can	O
use	O
bayesian	O
hypothesis	B
testing	I
to	O
compare	O
the	O
likelihood	B
of	O
f	O
and	O
b	O
but	O
we	O
have	O
to	O
do	O
some	O
work	O
to	O
specify	O
precisely	O
what	O
b	O
means	O
this	O
specification	O
depends	O
on	O
background	O
information	O
about	O
coins	O
and	O
their	O
behavior	O
when	O
spun	O
so	O
people	O
could	O
reasonably	O
disagree	O
about	O
the	O
right	O
definition	O
discussion	O
my	O
presentation	O
of	O
this	O
example	O
follows	O
david	O
mackay	B
s	O
discussion	O
and	O
comes	O
to	O
the	O
same	O
conclusion	O
you	O
can	O
download	O
the	O
code	O
i	O
used	O
in	O
this	O
chapter	O
from	O
for	O
more	O
information	O
see	O
section	O
discussion	O
the	O
bayes	B
factor	I
for	O
b	O
uniform	O
is	O
which	O
means	O
that	O
the	O
data	O
provide	O
evidence	O
against	O
this	O
hypothesis	O
compared	O
to	O
f	O
in	O
the	O
previous	O
section	O
i	O
characterized	O
this	O
evidence	O
as	O
weak	O
but	O
didn	O
t	O
say	O
why	O
part	O
of	O
the	O
answer	O
is	O
historical	O
harold	O
jeffreys	O
an	O
early	O
proponent	O
of	O
bayesian	O
statistics	O
suggested	O
a	O
scale	O
for	O
interpreting	O
bayes	O
factors	O
strength	O
bayes	B
factor	I
very	O
strong	O
barely	O
worth	O
mentioning	O
substantial	O
strong	O
decisive	O
in	O
the	O
example	O
the	O
bayes	B
factor	I
is	O
in	O
favor	O
of	O
b	O
uniform	O
so	O
it	O
is	O
in	O
favor	O
of	O
f	O
which	O
jeffreys	O
would	O
consider	O
barely	O
worth	O
mentioning	O
other	O
authors	O
have	O
suggested	O
variations	O
on	O
the	O
wording	O
to	O
avoid	O
arguing	O
about	O
adjectives	O
we	O
could	O
think	O
about	O
odds	B
instead	O
if	O
your	O
prior	B
odds	B
are	O
and	O
you	O
see	O
evidence	O
with	O
bayes	B
factor	I
your	O
posterior	B
odds	B
are	O
in	O
terms	O
of	O
probability	B
the	O
data	O
changed	O
your	O
degree	B
of	I
belief	I
from	O
to	O
for	O
most	O
real	O
world	O
problems	O
that	O
change	O
would	O
be	O
small	O
relative	O
to	O
modeling	B
errors	O
and	O
other	O
sources	O
of	O
uncertainty	B
on	O
the	O
other	O
hand	O
if	O
you	O
had	O
seen	O
evidence	O
with	O
bayes	B
factor	I
your	O
posterior	B
odds	B
would	O
be	O
or	O
more	O
than	O
whether	O
or	O
not	O
you	O
agree	O
that	O
such	O
evidence	O
is	O
decisive	O
it	O
is	O
certainly	O
strong	O
exercises	O
exercise	O
some	O
people	O
believe	O
in	O
the	O
existence	O
of	O
extra-sensory	B
perception	I
for	O
example	O
the	O
ability	O
of	O
some	O
people	O
to	O
guess	O
the	O
value	O
of	O
an	O
unseen	O
playing	O
card	O
with	O
probability	B
better	O
than	O
chance	O
chapter	O
hypothesis	B
testing	I
what	O
is	O
your	O
prior	B
degree	B
of	I
belief	I
in	O
this	O
kind	O
of	O
esp	B
do	O
you	O
think	O
it	O
is	O
as	O
likely	O
to	O
exist	O
as	O
not	O
or	O
are	O
you	O
more	O
skeptical	O
about	O
it	O
write	O
down	O
your	O
prior	B
odds	B
now	O
compute	O
the	O
strength	O
of	O
the	O
evidence	O
it	O
would	O
take	O
to	O
convince	O
you	O
that	O
esp	B
is	O
at	O
least	O
likely	O
to	O
exist	O
what	O
bayes	B
factor	I
would	O
be	O
needed	O
to	O
make	O
you	O
sure	O
that	O
esp	B
exists	O
exercise	O
suppose	O
that	O
your	O
answer	O
to	O
the	O
previous	O
question	O
is	O
that	O
is	O
evidence	O
with	O
bayes	B
factor	I
in	O
favor	O
of	O
esp	B
would	O
be	O
sufficient	O
to	O
change	O
your	O
mind	O
now	O
suppose	O
that	O
you	O
read	O
a	O
paper	O
in	O
a	O
respectable	O
peer-reviewed	O
scientific	O
journal	O
that	O
presents	O
evidence	O
with	O
bayes	B
factor	I
in	O
favor	O
of	O
esp	B
would	O
that	O
change	O
your	O
mind	O
if	O
not	O
how	O
do	O
you	O
resolve	O
the	O
apparent	O
contradiction	O
you	O
might	O
find	O
it	O
helpful	O
to	O
read	O
about	O
david	O
hume	B
s	O
article	O
of	O
miracles	O
at	O
http	O
en	O
wikipedia	O
org	O
wiki	O
of	O
miracles	O
chapter	O
evidence	O
interpreting	O
sat	B
scores	O
suppose	O
you	O
are	O
the	O
dean	O
of	O
admission	O
at	O
a	O
small	O
engineering	O
college	O
in	O
massachusetts	O
and	O
you	O
are	O
considering	O
two	O
candidates	O
alice	O
and	O
bob	O
whose	O
qualifications	O
are	O
similar	O
in	O
many	O
ways	O
with	O
the	O
exception	B
that	O
alice	O
got	O
a	O
higher	O
score	O
on	O
the	O
math	O
portion	O
of	O
the	O
sat	B
a	O
standardized	B
test	I
intended	O
to	O
measure	O
preparation	O
for	O
college-level	O
work	O
in	O
mathematics	O
if	O
alice	O
got	O
and	O
bob	O
got	O
a	O
of	O
a	O
possible	O
you	O
might	O
want	O
to	O
know	O
whether	O
that	O
difference	O
is	O
evidence	O
that	O
alice	O
is	O
better	O
prepared	O
than	O
bob	O
and	O
what	O
the	O
strength	O
of	O
that	O
evidence	O
is	O
now	O
in	O
reality	O
both	O
scores	O
are	O
very	O
good	O
and	O
both	O
candidates	O
are	O
probably	O
well	O
prepared	O
for	O
college	O
math	O
so	O
the	O
real	O
dean	O
of	O
admission	O
would	O
probably	O
suggest	O
that	O
we	O
choose	O
the	O
candidate	O
who	O
best	O
demonstrates	O
the	O
other	O
skills	O
and	O
attitudes	O
we	O
look	O
for	O
in	O
students	O
but	O
as	O
an	O
example	O
of	O
bayesian	O
hypothesis	B
testing	I
let	O
s	O
stick	B
with	O
a	O
narrower	O
question	O
how	O
strong	O
is	O
the	O
evidence	O
that	O
alice	O
is	O
better	O
prepared	O
than	O
bob	O
to	O
answer	O
that	O
question	O
we	O
need	O
to	O
make	O
some	O
modeling	B
decisions	O
i	O
ll	O
start	O
with	O
a	O
simplification	O
i	O
know	O
is	O
wrong	O
then	O
we	O
ll	O
come	O
back	O
and	O
improve	O
the	O
model	O
i	O
pretend	O
temporarily	O
that	O
all	O
sat	B
questions	O
are	O
equally	O
difficult	O
actually	O
the	O
designers	O
of	O
the	O
sat	B
choose	O
questions	O
with	O
a	O
range	O
of	O
difficulty	O
because	O
that	O
improves	O
the	O
ability	O
to	O
measure	O
statistical	O
differences	O
between	O
test-takers	O
but	O
if	O
we	O
choose	O
a	O
model	O
where	O
all	O
questions	O
are	O
equally	O
difficult	O
we	O
can	O
define	O
a	O
characteristic	O
p	O
correct	O
for	O
each	O
test-taker	O
which	O
is	O
the	O
probabil	O
chapter	O
evidence	O
ity	O
of	O
answering	O
any	O
question	O
correctly	O
this	O
simplification	O
makes	O
it	O
easy	O
to	O
compute	O
the	O
likelihood	B
of	O
a	O
given	O
score	O
the	O
scale	O
in	O
order	O
to	O
understand	O
sat	B
scores	O
we	O
have	O
to	O
understand	O
the	O
scoring	O
and	O
scaling	O
process	B
each	O
test-taker	O
gets	O
a	O
raw	B
score	I
based	O
on	O
the	O
number	O
of	O
correct	O
and	O
incorrect	O
questions	O
the	O
raw	B
score	I
is	O
converted	O
to	O
a	O
scaled	B
score	I
in	O
the	O
range	O
in	O
there	O
were	O
questions	O
on	O
the	O
math	O
sat	B
the	O
raw	B
score	I
for	O
each	O
test-taker	O
is	O
the	O
number	O
of	O
questions	O
answered	O
correctly	O
minus	O
a	O
penalty	O
of	O
point	O
for	O
each	O
question	O
answered	O
incorrectly	O
the	O
college	B
board	I
which	O
administers	O
the	O
sat	B
publishes	O
the	O
map	O
from	O
raw	O
scores	O
to	O
scaled	O
scores	O
i	O
have	O
downloaded	O
that	O
data	O
and	O
wrapped	O
it	O
in	O
an	O
interpolator	O
object	O
that	O
provides	O
a	O
forward	O
lookup	O
raw	B
score	I
to	O
scaled	O
and	O
a	O
reverse	O
lookup	O
scaled	B
score	I
to	O
raw	O
you	O
can	O
download	O
the	O
code	O
for	O
this	O
example	O
from	O
httpthinkbayes	O
com	O
sat	B
py	O
for	O
more	O
information	O
see	O
section	O
the	O
prior	B
the	O
college	B
board	I
also	O
publishes	O
the	O
distribution	B
of	O
scaled	O
scores	O
for	O
all	O
test-takers	O
if	O
we	O
convert	O
each	O
scaled	B
score	I
to	O
a	O
raw	B
score	I
and	O
divide	O
by	O
the	O
number	O
of	O
questions	O
the	O
result	O
is	O
an	O
estimate	O
of	O
p	O
correct	O
so	O
we	O
can	O
use	O
the	O
distribution	B
of	O
raw	O
scores	O
to	O
model	O
the	O
prior	B
distribution	B
of	O
p	O
correct	O
here	O
is	O
the	O
code	O
that	O
reads	O
and	O
processes	O
the	O
data	O
class	O
examobject	O
def	O
self	O
scale	O
readscale	O
scores	O
readranks	O
score	O
pmf	B
thinkbayes	O
makepmffromdictdictscores	O
self	O
raw	O
self	O
reversescalescore	O
pmf	B
self	O
max	O
score	O
maxself	O
raw	O
values	O
self	O
prior	B
dividevaluesself	O
raw	O
self	O
max	O
score	O
the	O
prior	B
figure	O
prior	B
distribution	B
of	O
p	O
correct	O
for	O
sat	B
test-takers	O
exam	O
encapsulates	O
the	O
information	O
we	O
have	O
about	O
the	O
exam	O
readscale	O
and	O
readranks	O
read	O
files	O
and	O
return	O
objects	O
that	O
contain	O
the	O
data	O
self	O
scale	O
is	O
the	O
interpolator	O
that	O
converts	O
from	O
raw	O
to	O
scaled	O
scores	O
and	O
back	O
scores	O
is	O
a	O
list	O
of	O
frequency	O
pairs	O
score	O
pmf	B
is	O
the	O
pmf	B
of	O
scaled	O
scores	O
self	O
raw	O
is	O
the	O
pmf	B
of	O
raw	O
scores	O
and	O
self	O
prior	B
is	O
the	O
pmf	B
of	O
p	O
correct	O
figure	O
shows	O
the	O
prior	B
distribution	B
of	O
p	O
correct	O
this	O
distribution	B
is	O
approximately	O
gaussian	O
but	O
it	O
is	O
compressed	O
at	O
the	O
extremes	O
by	O
design	O
the	O
sat	B
has	O
the	O
most	O
power	O
to	O
discriminate	O
between	O
test-takers	O
within	O
two	O
standard	O
deviations	O
of	O
the	O
mean	O
and	O
less	O
power	O
outside	O
that	O
range	O
for	O
each	O
test-taker	O
i	O
define	O
a	O
suite	B
called	O
sat	B
that	O
represents	O
the	O
distribution	B
of	O
p	O
correct	O
here	O
s	O
the	O
definition	O
class	O
satthinkbayes	O
suite	B
def	O
exam	O
score	O
thinkbayes	O
suite	B
init	O
self	O
self	O
exam	O
exam	O
self	O
score	O
score	O
start	O
with	O
the	O
prior	B
distribution	B
for	O
p	O
correct	O
prob	B
in	O
exam	O
prior	B
items	O
self	O
setp	O
correct	O
prob	B
chapter	O
evidence	O
figure	O
posterior	B
distributions	O
of	O
p	O
correct	O
for	O
alice	O
and	O
bob	O
update	B
based	O
on	O
an	O
exam	O
score	O
self	O
updatescore	O
takes	O
an	O
exam	O
object	O
and	O
a	O
scaled	B
score	I
it	O
makes	O
a	O
copy	O
of	O
the	O
prior	B
distribution	B
and	O
then	O
updates	O
itself	O
based	O
on	O
the	O
exam	O
score	O
as	O
usual	O
we	O
inherit	O
update	B
from	O
suite	B
and	O
provide	O
likelihood	B
def	O
likelihoodself	O
data	O
hypo	O
p	O
correct	O
hypo	O
score	O
data	O
k	O
self	O
exam	O
reversescore	O
n	O
self	O
exam	O
max	O
score	O
like	O
thinkbayes	O
evalbinomialpmfk	O
n	O
p	O
correct	O
return	O
like	O
hypo	O
is	O
a	O
hypothetical	O
value	O
of	O
p	O
correct	O
and	O
data	O
is	O
a	O
scaled	B
score	I
to	O
keep	O
things	O
simple	O
i	O
interpret	O
the	O
raw	B
score	I
as	O
the	O
number	O
of	O
correct	O
answers	O
ignoring	O
the	O
penalty	O
for	O
wrong	O
answers	O
with	O
this	O
simplification	O
the	O
likelihood	B
is	O
given	O
by	O
the	O
binomial	B
distribution	B
which	O
computes	O
the	O
probability	B
of	O
k	O
correct	O
responses	O
out	O
of	O
n	O
questions	O
posterior	B
figure	O
shows	O
the	O
posterior	B
distributions	O
of	O
p	O
correct	O
for	O
alice	O
and	O
bob	O
based	O
on	O
their	O
exam	O
scores	O
we	O
can	O
see	O
that	O
they	O
overlap	O
so	O
it	O
is	O
possible	O
that	O
p	O
correct	O
is	O
actually	O
higher	O
for	O
bob	O
but	O
it	O
seems	O
unlikely	O
posterior	B
which	O
brings	O
us	O
back	O
to	O
the	O
original	O
question	O
how	O
strong	O
is	O
the	O
evidence	O
that	O
alice	O
is	O
better	O
prepared	O
than	O
bob	O
we	O
can	O
use	O
the	O
posterior	B
distributions	O
of	O
p	O
correct	O
to	O
answer	O
this	O
question	O
to	O
formulate	O
the	O
question	O
in	O
terms	O
of	O
bayesian	O
hypothesis	B
testing	I
i	O
define	O
two	O
hypotheses	O
a	O
p	O
correct	O
is	O
higher	O
for	O
alice	O
than	O
for	O
bob	O
b	O
p	O
correct	O
is	O
higher	O
for	O
bob	O
than	O
for	O
alice	O
to	O
compute	O
the	O
likelihood	B
of	O
a	O
we	O
can	O
enumerate	O
all	O
pairs	O
of	O
values	O
from	O
the	O
posterior	B
distributions	O
and	O
add	O
up	O
the	O
total	B
probability	B
of	O
the	O
cases	O
where	O
p	O
correct	O
is	O
higher	O
for	O
alice	O
than	O
for	O
bob	O
and	O
we	O
already	O
have	O
a	O
function	O
thinkbayes	O
pmfprobgreater	O
that	O
does	O
that	O
so	O
we	O
can	O
define	O
a	O
suite	B
that	O
computes	O
the	O
posterior	B
probabilities	O
of	O
a	O
and	O
b	O
class	O
toplevelthinkbayes	O
suite	B
def	O
updateself	O
data	O
a	O
sat	B
b	O
sat	B
data	O
a	O
like	O
thinkbayes	O
pmfprobgreatera	O
sat	B
b	O
sat	B
b	O
like	O
thinkbayes	O
pmfproblessa	O
sat	B
b	O
sat	B
c	O
like	O
thinkbayes	O
pmfprobequala	O
sat	B
b	O
sat	B
a	O
like	O
c	O
like	O
b	O
like	O
c	O
like	O
self	O
multa	O
a	O
like	O
self	O
multb	O
b	O
like	O
self	O
normalize	B
usually	O
when	O
we	O
define	O
a	O
new	O
suite	B
we	O
inherit	O
update	B
and	O
provide	O
likelihood	B
in	O
this	O
case	O
i	O
override	O
update	B
because	O
it	O
is	O
easier	O
to	O
evaluate	O
the	O
likelihood	B
of	O
both	O
hypotheses	O
at	O
the	O
same	O
time	O
the	O
data	O
passed	O
to	O
update	B
are	O
sat	B
objects	O
that	O
represent	O
the	O
posterior	B
distributions	O
of	O
p	O
correct	O
a	O
like	O
is	O
the	O
total	B
probability	B
that	O
p	O
correct	O
is	O
higher	O
for	O
alice	O
b	O
like	O
is	O
that	O
probability	B
that	O
it	O
is	O
higher	O
for	O
bob	O
chapter	O
evidence	O
c	O
like	O
is	O
the	O
probability	B
that	O
they	O
are	O
equal	O
but	O
this	O
equality	O
is	O
an	O
artifact	O
of	O
the	O
decision	O
to	O
model	O
p	O
correct	O
with	O
a	O
set	O
of	O
discrete	O
values	O
if	O
we	O
use	O
more	O
values	O
c	O
like	O
is	O
smaller	O
and	O
in	O
the	O
extreme	O
if	O
p	O
correct	O
is	O
continuous	O
c	O
like	O
is	O
zero	O
so	O
i	O
treat	O
c	O
like	O
as	O
a	O
kind	O
of	O
round-off	O
error	B
and	O
split	O
it	O
evenly	O
between	O
a	O
like	O
and	O
b	O
like	O
here	O
is	O
the	O
code	O
that	O
creates	O
toplevel	O
and	O
updates	O
it	O
exam	O
exam	O
a	O
sat	B
satexam	O
b	O
sat	B
satexam	O
top	O
toplevelab	O
top	O
updatea	O
sat	B
b	O
sat	B
top	O
print	O
the	O
likelihood	B
of	O
a	O
is	O
and	O
the	O
likelihood	B
of	O
b	O
is	O
the	O
likelihood	B
ratio	I
bayes	B
factor	I
is	O
which	O
means	O
that	O
these	O
test	O
scores	O
are	O
evidence	O
that	O
alice	O
is	O
better	O
than	O
bob	O
at	O
answering	O
sat	B
questions	O
if	O
we	O
believed	O
before	O
seeing	O
the	O
test	O
scores	O
that	O
a	O
and	O
b	O
were	O
equally	O
likely	O
then	O
after	O
seeing	O
the	O
scores	O
we	O
should	O
believe	O
that	O
the	O
probability	B
of	O
a	O
is	O
which	O
means	O
there	O
is	O
still	O
a	O
chance	O
that	O
bob	O
is	O
actually	O
better	O
prepared	O
a	O
better	O
model	O
remember	O
that	O
the	O
analysis	O
we	O
have	O
done	O
so	O
far	O
is	O
based	O
on	O
the	O
simplification	O
that	O
all	O
sat	B
questions	O
are	O
equally	O
difficult	O
in	O
reality	O
some	O
are	O
easier	O
than	O
others	O
which	O
means	O
that	O
the	O
difference	O
between	O
alice	O
and	O
bob	O
might	O
be	O
even	O
smaller	O
but	O
how	O
big	O
is	O
the	O
modeling	B
error	B
if	O
it	O
is	O
small	O
we	O
conclude	O
that	O
the	O
first	O
model	O
based	O
on	O
the	O
simplification	O
that	O
all	O
questions	O
are	O
equally	O
difficult	O
is	O
good	O
enough	O
if	O
it	O
s	O
large	O
we	O
need	O
a	O
better	O
model	O
in	O
the	O
next	O
few	O
sections	O
i	O
develop	O
a	O
better	O
model	O
and	O
discover	O
alert	O
that	O
the	O
modeling	B
error	B
is	O
small	O
so	O
if	O
you	O
are	O
satisfied	O
with	O
the	O
simple	O
model	O
you	O
can	O
skip	O
to	O
the	O
next	O
chapter	O
if	O
you	O
want	O
to	O
see	O
how	O
the	O
more	O
realistic	O
model	O
works	O
read	O
on	O
assume	O
that	O
each	O
test-taker	O
has	O
some	O
degree	O
of	O
efficacy	B
which	O
mea	O
sures	O
their	O
ability	O
to	O
answer	O
sat	B
questions	O
assume	O
that	O
each	O
question	O
has	O
some	O
level	O
of	O
difficulty	O
a	O
better	O
model	O
finally	O
assume	O
that	O
the	O
chance	O
that	O
a	O
test-taker	O
answers	O
a	O
question	O
correctly	O
is	O
related	O
to	O
efficacy	B
and	O
difficulty	O
according	O
to	O
this	O
function	O
def	O
probcorrectefficacy	O
difficulty	O
return	O
math	O
exp-a	O
difficulty	O
this	O
function	O
is	O
a	O
simplified	O
version	O
of	O
the	O
curve	O
used	O
in	O
item	B
response	I
theory	I
which	O
you	O
can	O
read	O
about	O
at	O
httpen	O
wikipedia	O
orgwikiitem	O
response	O
theory	O
efficacy	B
and	O
difficulty	O
are	O
considered	O
to	O
be	O
on	O
the	O
same	O
scale	O
and	O
the	O
probability	B
of	O
getting	O
a	O
question	O
right	O
depends	O
only	O
on	O
the	O
difference	O
between	O
them	O
when	O
efficacy	B
and	O
difficulty	O
are	O
equal	O
the	O
probability	B
of	O
getting	O
the	O
question	O
right	O
is	O
as	O
efficacy	B
increases	O
this	O
probability	B
approaches	O
as	O
it	O
decreases	O
as	O
difficulty	O
increases	O
the	O
probability	B
approaches	O
given	O
the	O
distribution	B
of	O
efficacy	B
across	O
test-takers	O
and	O
the	O
distribution	B
of	O
difficulty	O
across	O
questions	O
we	O
can	O
compute	O
the	O
expected	O
distribution	B
of	O
raw	O
scores	O
we	O
ll	O
do	O
that	O
in	O
two	O
steps	O
first	O
for	O
a	O
person	O
with	O
given	O
efficacy	B
we	O
ll	O
compute	O
the	O
distribution	B
of	O
raw	O
scores	O
def	O
pmfcorrectefficacy	O
difficulties	O
ps	O
diff	O
for	O
diff	O
in	O
difficulties	O
pmfs	O
for	O
p	O
in	O
ps	O
dist	O
sumpmfs	O
return	O
dist	O
difficulties	O
is	O
a	O
list	O
of	O
difficulties	O
one	O
for	O
each	O
question	O
ps	O
is	O
a	O
list	O
of	O
probabilities	O
and	O
pmfs	O
is	O
a	O
list	O
of	O
two-valued	O
pmf	B
objects	O
here	O
s	O
the	O
function	O
that	O
makes	O
them	O
def	O
binarypmfp	O
pmf	B
thinkbayes	O
pmf	B
p	O
return	O
pmf	B
dist	O
is	O
the	O
sum	O
of	O
these	O
pmfs	O
remember	O
from	O
section	O
that	O
when	O
we	O
add	O
up	O
pmf	B
objects	O
the	O
result	O
is	O
the	O
distribution	B
of	O
the	O
sums	O
in	O
order	O
to	O
use	O
python	O
s	O
sum	O
to	O
add	O
up	O
pmfs	O
we	O
have	O
to	O
provide	O
which	O
is	O
the	O
identity	O
for	O
pmfs	O
so	O
pmf	B
is	O
always	O
pmf	B
chapter	O
evidence	O
if	O
we	O
know	O
a	O
person	O
s	O
efficacy	B
we	O
can	O
compute	O
their	O
distribution	B
of	O
raw	O
scores	O
for	O
a	O
group	O
of	O
people	O
with	O
a	O
different	O
efficacies	O
the	O
resulting	O
distribution	B
of	O
raw	O
scores	O
is	O
a	O
mixture	B
here	O
s	O
the	O
code	O
that	O
computes	O
the	O
mixture	B
class	O
exam	O
def	O
makerawscoredistself	O
efficacies	O
pmfs	O
thinkbayes	O
pmf	B
for	O
efficacy	B
prob	B
in	O
efficacies	O
items	O
scores	O
pmfcorrectefficacy	O
self	O
difficulties	O
pmfs	O
setscores	O
prob	B
mix	O
thinkbayes	O
makemixturepmfs	O
return	O
mix	O
makerawscoredist	O
takes	O
efficacies	O
which	O
is	O
a	O
pmf	B
that	O
represents	O
the	O
distribution	B
of	O
efficacy	B
across	O
test-takers	O
i	O
assume	O
it	O
is	O
gaussian	O
with	O
mean	O
and	O
standard	O
deviation	O
this	O
choice	O
is	O
mostly	O
arbitrary	O
the	O
probability	B
of	O
getting	O
a	O
question	O
correct	O
depends	O
on	O
the	O
difference	O
between	O
efficacy	B
and	O
difficulty	O
so	O
we	O
can	O
choose	O
the	O
units	O
of	O
efficacy	B
and	O
then	O
calibrate	O
the	O
units	O
of	O
difficulty	O
accordingly	O
pmfs	O
is	O
a	O
meta-pmf	B
that	O
contains	O
one	O
pmf	B
for	O
each	O
level	O
of	O
efficacy	B
and	O
maps	O
to	O
the	O
fraction	O
of	O
test-takers	O
at	O
that	O
level	O
makemixture	B
takes	O
the	O
meta-pmf	B
and	O
computes	O
the	O
distribution	B
of	O
the	O
mixture	B
section	O
calibration	B
if	O
we	O
were	O
given	O
the	O
distribution	B
of	O
difficulty	O
we	O
could	O
use	O
makerawscoredist	O
to	O
compute	O
the	O
distribution	B
of	O
raw	O
scores	O
but	O
for	O
us	O
the	O
problem	O
is	O
the	O
other	O
way	O
around	O
we	O
are	O
given	O
the	O
distribution	B
of	O
raw	O
scores	O
and	O
we	O
want	O
to	O
infer	O
the	O
distribution	B
of	O
difficulty	O
i	O
assume	O
that	O
the	O
distribution	B
of	O
difficulty	O
is	O
uniform	O
with	O
parameters	O
center	O
and	O
width	O
makedifficulties	O
makes	O
a	O
list	O
of	O
difficulties	O
with	O
these	O
parameters	O
def	O
makedifficultiescenter	O
width	O
n	O
low	O
high	O
center-width	O
centerwidth	O
return	O
numpy	B
linspacelow	O
high	O
n	O
by	O
trying	O
out	O
a	O
few	O
combinations	O
i	O
found	O
that	O
and	O
yield	O
a	O
distribution	B
of	O
raw	O
scores	O
similar	O
to	O
the	O
actual	O
data	O
as	O
shown	O
in	O
figure	O
posterior	B
distribution	B
of	O
efficacy	B
figure	O
actual	O
distribution	B
of	O
raw	O
scores	O
and	O
a	O
model	O
to	O
fit	O
it	O
so	O
assuming	O
that	O
the	O
distribution	B
of	O
difficulty	O
is	O
uniform	O
its	O
range	O
is	O
approximately	O
to	O
given	O
that	O
efficacy	B
is	O
gaussian	O
with	O
mean	O
and	O
standard	O
deviation	O
the	O
following	O
table	O
shows	O
the	O
range	O
of	O
probcorrect	O
for	O
test-takers	O
at	O
different	O
levels	O
of	O
efficacy	B
difficulty	O
efficacy	B
someone	O
with	O
efficacy	B
standard	O
deviations	O
above	O
the	O
mean	O
has	O
a	O
chance	O
of	O
answering	O
the	O
easiest	O
questions	O
on	O
the	O
exam	O
and	O
a	O
chance	O
of	O
answering	O
the	O
hardest	O
on	O
the	O
other	O
end	O
of	O
the	O
range	O
someone	O
two	O
standard	O
deviations	O
below	O
the	O
mean	O
has	O
only	O
a	O
chance	O
of	O
answering	O
the	O
easiest	O
questions	O
posterior	B
distribution	B
of	O
efficacy	B
now	O
that	O
the	O
model	O
is	O
calibrated	O
we	O
can	O
compute	O
the	O
posterior	B
distribution	B
of	O
efficacy	B
for	O
alice	O
and	O
bob	O
here	O
is	O
a	O
version	O
of	O
the	O
sat	B
class	O
that	O
uses	O
the	O
new	O
model	O
chapter	O
evidence	O
figure	O
posterior	B
distributions	O
of	O
efficacy	B
for	O
alice	O
and	O
bob	O
class	O
def	O
exam	O
score	O
self	O
exam	O
exam	O
self	O
score	O
score	O
start	O
with	O
the	O
gaussian	O
prior	B
efficacies	O
thinkbayes	O
suite	B
init	O
self	O
efficacies	O
update	B
based	O
on	O
an	O
exam	O
score	O
self	O
updatescore	O
update	B
invokes	O
likelihood	B
which	O
computes	O
the	O
likelihood	B
of	O
a	O
given	O
test	O
score	O
for	O
a	O
hypothetical	O
level	O
of	O
efficacy	B
def	O
likelihoodself	O
data	O
hypo	O
efficacy	B
hypo	O
score	O
data	O
raw	O
self	O
exam	O
reversescore	O
pmf	B
self	O
exam	O
pmfcorrectefficacy	O
like	O
pmf	B
probraw	O
return	O
like	O
pmf	B
is	O
the	O
distribution	B
of	O
raw	O
scores	O
for	O
a	O
test-taker	O
with	O
the	O
given	O
efficacy	B
like	O
is	O
the	O
probability	B
of	O
the	O
observed	O
score	O
predictive	B
distribution	B
figure	O
shows	O
the	O
posterior	B
distributions	O
of	O
efficacy	B
for	O
alice	O
and	O
bob	O
as	O
expected	O
the	O
location	O
of	O
alice	O
s	O
distribution	B
is	O
farther	O
to	O
the	O
right	O
but	O
again	O
there	O
is	O
some	O
overlap	O
using	O
toplevel	O
again	O
we	O
compare	O
a	O
the	O
hypothesis	O
that	O
alice	O
s	O
efficacy	B
is	O
higher	O
and	O
b	O
the	O
hypothesis	O
that	O
bob	O
s	O
is	O
higher	O
the	O
likelihood	B
ratio	I
is	O
a	O
bit	O
smaller	O
than	O
what	O
we	O
got	O
from	O
the	O
simple	O
model	O
so	O
this	O
model	O
indicates	O
that	O
the	O
data	O
are	O
evidence	O
in	O
favor	O
of	O
a	O
but	O
a	O
little	O
weaker	O
than	O
the	O
previous	O
estimate	O
if	O
our	O
prior	B
belief	O
is	O
that	O
a	O
and	O
b	O
are	O
equally	O
likely	O
then	O
in	O
light	O
of	O
this	O
evidence	O
we	O
would	O
give	O
a	O
a	O
posterior	B
probability	B
of	O
leaving	O
a	O
chance	O
that	O
bob	O
s	O
efficacy	B
is	O
higher	O
predictive	B
distribution	B
the	O
analysis	O
we	O
have	O
done	O
so	O
far	O
generates	O
estimates	O
for	O
alice	O
and	O
bob	O
s	O
efficacy	B
but	O
since	O
efficacy	B
is	O
not	O
directly	O
observable	O
it	O
is	O
hard	O
to	O
validate	O
the	O
results	O
to	O
give	O
the	O
model	O
predictive	O
power	O
we	O
can	O
use	O
it	O
to	O
answer	O
a	O
related	O
question	O
if	O
alice	O
and	O
bob	O
take	O
the	O
math	O
sat	B
again	O
what	O
is	O
the	O
chance	O
that	O
alice	O
will	O
do	O
better	O
again	O
we	O
ll	O
answer	O
this	O
question	O
in	O
two	O
steps	O
we	O
ll	O
use	O
the	O
posterior	B
distribution	B
of	O
efficacy	B
to	O
generate	O
a	O
predictive	B
distribution	B
of	O
raw	B
score	I
for	O
each	O
test-taker	O
we	O
ll	O
compare	O
the	O
two	O
predictive	O
distributions	O
to	O
compute	O
the	O
proba	O
bility	O
that	O
alice	O
gets	O
a	O
higher	O
score	O
again	O
we	O
already	O
have	O
most	O
of	O
the	O
code	O
we	O
need	O
to	O
compute	O
the	O
predictive	O
distributions	O
we	O
can	O
use	O
makerawscoredist	O
again	O
exam	O
exam	O
a	O
sat	B
satexam	O
b	O
sat	B
satexam	O
a	O
pred	O
exam	O
makerawscoredista	O
sat	B
b	O
pred	O
exam	O
makerawscoredistb	O
sat	B
then	O
we	O
can	O
find	O
the	O
likelihood	B
that	O
alice	O
does	O
better	O
on	O
the	O
second	O
test	O
bob	O
does	O
better	O
or	O
they	O
tie	O
chapter	O
evidence	O
figure	O
joint	B
posterior	B
distribution	B
of	O
p	O
correct	O
for	O
alice	O
and	O
bob	O
a	O
like	O
thinkbayes	O
pmfprobgreatera	O
pred	O
b	O
pred	O
b	O
like	O
thinkbayes	O
pmfproblessa	O
pred	O
b	O
pred	O
c	O
like	O
thinkbayes	O
pmfprobequala	O
pred	O
b	O
pred	O
the	O
probability	B
that	O
alice	O
does	O
better	O
on	O
the	O
second	O
exam	O
is	O
which	O
means	O
that	O
bob	O
has	O
a	O
chance	O
of	O
doing	O
as	O
well	O
or	O
better	O
notice	O
that	O
we	O
have	O
more	O
confidence	O
about	O
alice	O
s	O
efficacy	B
than	O
we	O
do	O
about	O
the	O
outcome	O
of	O
the	O
next	O
test	O
the	O
posterior	B
odds	B
are	O
that	O
alice	O
s	O
efficacy	B
is	O
higher	O
but	O
only	O
that	O
alice	O
will	O
do	O
better	O
on	O
the	O
next	O
exam	O
discussion	O
we	O
started	O
this	O
chapter	O
with	O
the	O
question	O
how	O
strong	O
is	O
the	O
evidence	O
that	O
alice	O
is	O
better	O
prepared	O
than	O
bob	O
on	O
the	O
face	O
of	O
it	O
that	O
sounds	O
like	O
we	O
want	O
to	O
test	O
two	O
hypotheses	O
either	O
alice	O
is	O
more	O
prepared	O
or	O
bob	O
is	O
but	O
in	O
order	O
to	O
compute	O
likelihoods	O
for	O
these	O
hypotheses	O
we	O
have	O
to	O
solve	O
an	O
estimation	O
problem	O
for	O
each	O
test-taker	O
we	O
have	O
to	O
find	O
the	O
posterior	B
distribution	B
of	O
either	O
p	O
correct	O
or	O
efficacy	B
values	O
like	O
this	O
are	O
called	O
nuisance	O
parameters	O
because	O
we	O
don	O
t	O
care	O
what	O
they	O
are	O
but	O
we	O
have	O
to	O
estimate	O
them	O
to	O
answer	O
the	O
question	O
we	O
care	O
about	O
one	O
way	O
to	O
visualize	O
the	O
analysis	O
we	O
did	O
in	O
this	O
chapter	O
is	O
to	O
plot	O
the	O
space	O
of	O
these	O
parameters	O
thinkbayes	O
makejoint	O
takes	O
two	O
pmfs	O
com	O
bob	O
discussion	O
putes	O
their	O
joint	B
distribution	B
and	O
returns	O
a	O
joint	B
pmf	B
of	O
each	O
possible	O
pair	O
of	O
values	O
and	O
its	O
probability	B
def	O
joint	B
joint	B
for	O
in	O
for	O
in	O
return	O
joint	B
this	O
function	O
assumes	O
that	O
the	O
two	O
distributions	O
are	O
independent	O
figure	O
shows	O
the	O
joint	B
posterior	B
distribution	B
of	O
p	O
correct	O
for	O
alice	O
and	O
bob	O
the	O
diagonal	O
line	O
indicates	O
the	O
part	O
of	O
the	O
space	O
where	O
p	O
correct	O
is	O
the	O
same	O
for	O
alice	O
and	O
bob	O
to	O
the	O
right	O
of	O
this	O
line	O
alice	O
is	O
more	O
prepared	O
to	O
the	O
left	O
bob	O
is	O
more	O
prepared	O
in	O
toplevel	O
update	B
when	O
we	O
compute	O
the	O
likelihoods	O
of	O
a	O
and	O
b	O
we	O
add	O
up	O
the	O
probability	B
mass	O
on	O
each	O
side	O
of	O
this	O
line	O
for	O
the	O
cells	O
that	O
fall	O
on	O
the	O
line	O
we	O
add	O
up	O
the	O
total	O
mass	O
and	O
split	O
it	O
between	O
a	O
and	O
b	O
the	O
process	B
we	O
used	O
in	O
this	O
chapter	O
estimating	O
nuisance	O
parameters	O
in	O
order	O
to	O
evaluate	O
the	O
likelihood	B
of	O
competing	O
hypotheses	O
is	O
a	O
common	O
bayesian	O
approach	O
to	O
problems	O
like	O
this	O
chapter	O
evidence	O
chapter	O
simulation	B
in	O
this	O
chapter	O
i	O
describe	O
my	O
solution	O
to	O
a	O
problem	O
posed	O
by	O
a	O
patient	O
with	O
a	O
kidney	O
tumor	O
i	O
think	O
the	O
problem	O
is	O
important	O
and	O
relevant	O
to	O
patients	O
with	O
these	O
tumors	O
and	O
doctors	O
treating	O
them	O
and	O
i	O
think	O
the	O
solution	O
is	O
interesting	O
because	O
although	O
it	O
is	O
a	O
bayesian	O
approach	O
to	O
the	O
problem	O
the	O
use	O
of	O
bayes	O
s	O
theorem	O
is	O
implicit	O
i	O
present	O
the	O
solution	O
and	O
my	O
code	O
at	O
the	O
end	O
of	O
the	O
chapter	O
i	O
will	O
explain	O
the	O
bayesian	O
part	O
if	O
you	O
want	O
more	O
technical	O
detail	O
than	O
i	O
present	O
here	O
you	O
can	O
read	O
my	O
paper	O
on	O
this	O
work	O
at	O
the	O
kidney	B
tumor	I
problem	I
i	O
am	O
a	O
frequent	O
reader	O
and	O
occasional	O
contributor	O
to	O
the	O
online	O
statistics	O
forum	O
at	O
httpreddit	O
comrstatistics	O
in	O
november	O
i	O
read	O
the	O
following	O
message	O
have	O
stage	O
iv	O
kidney	O
cancer	O
and	O
am	O
trying	O
to	O
determine	O
if	O
the	O
cancer	O
formed	O
before	O
i	O
retired	O
from	O
the	O
military	O
given	O
the	O
dates	O
of	O
retirement	O
and	O
detection	O
is	O
it	O
possible	O
to	O
determine	O
when	O
there	O
was	O
a	O
chance	O
that	O
i	O
developed	O
the	O
disease	O
is	O
it	O
possible	O
to	O
determine	O
the	O
probability	B
on	O
the	O
retirement	O
date	O
my	O
tumor	O
was	O
cm	O
x	O
cm	O
at	O
detection	O
grade	O
ii	O
i	O
contacted	O
the	O
author	O
of	O
the	O
message	O
and	O
got	O
more	O
information	O
i	O
learned	O
that	O
veterans	O
get	O
different	O
benefits	O
if	O
it	O
is	O
likely	O
than	O
not	O
that	O
a	O
tumor	O
formed	O
while	O
they	O
were	O
in	O
military	O
service	O
other	O
considerations	O
chapter	O
simulation	B
figure	O
cdf	B
of	O
rdt	O
in	O
doublings	O
per	O
year	O
because	O
renal	O
tumors	O
grow	O
slowly	O
and	O
often	O
do	O
not	O
cause	O
symptoms	O
they	O
are	O
sometimes	O
left	O
untreated	O
as	O
a	O
result	O
doctors	O
can	O
observe	O
the	O
rate	O
of	O
growth	O
for	O
untreated	O
tumors	O
by	O
comparing	O
scans	O
from	O
the	O
same	O
patient	O
at	O
different	O
times	O
several	O
papers	O
have	O
reported	O
these	O
growth	O
rates	O
i	O
collected	O
data	O
from	O
a	O
paper	O
by	O
zhang	O
et	O
i	O
contacted	O
the	O
authors	O
to	O
see	O
if	O
i	O
could	O
get	O
raw	O
data	O
but	O
they	O
refused	O
on	O
grounds	O
of	O
medical	O
privacy	O
nevertheless	O
i	O
was	O
able	O
to	O
extract	O
the	O
data	O
i	O
needed	O
by	O
printing	O
one	O
of	O
their	O
graphs	O
and	O
measuring	O
it	O
with	O
a	O
ruler	O
they	O
report	O
growth	O
rates	O
in	O
reciprocal	O
doubling	B
time	I
which	O
is	O
in	O
units	O
of	O
doublings	O
per	O
year	O
so	O
a	O
tumor	O
with	O
rdt	O
doubles	O
in	O
volume	B
each	O
year	O
with	O
rdt	O
it	O
quadruples	O
in	O
the	O
same	O
time	O
and	O
with	O
rdt	O
it	O
halves	O
figure	O
shows	O
the	O
distribution	B
of	O
rdt	O
for	O
patients	O
the	O
squares	O
are	O
the	O
data	O
points	O
from	O
the	O
paper	O
the	O
line	O
is	O
a	O
model	O
i	O
fit	O
to	O
the	O
data	O
the	O
positive	O
tail	O
fits	O
an	O
exponential	B
distribution	B
well	O
so	O
i	O
used	O
a	O
mixture	B
of	O
two	O
exponentials	O
a	O
simple	O
model	O
it	O
is	O
usually	O
a	O
good	O
idea	O
to	O
start	O
with	O
a	O
simple	O
model	O
before	O
trying	O
something	O
more	O
challenging	O
sometimes	O
the	O
simple	O
model	O
is	O
sufficient	O
for	O
the	O
et	O
al	O
distribution	B
of	O
renal	O
tumor	O
growth	O
rates	O
determined	O
by	O
using	O
serial	O
volumetric	O
ct	O
measurements	O
january	O
radiology	O
doublings	O
per	O
of	O
rdtmodeldata	O
a	O
simple	O
model	O
problem	O
at	O
hand	O
and	O
if	O
not	O
you	O
can	O
use	O
it	O
to	O
validate	O
the	O
more	O
complex	O
model	O
for	O
my	O
simple	O
model	O
i	O
assume	O
that	O
tumors	O
grow	O
with	O
a	O
constant	O
doubling	B
time	I
and	O
that	O
they	O
are	O
three-dimensional	O
in	O
the	O
sense	O
that	O
if	O
the	O
maximum	B
linear	O
measurement	O
doubles	O
the	O
volume	B
is	O
multiplied	O
by	O
eight	O
i	O
learned	O
from	O
my	O
correspondent	O
that	O
the	O
time	O
between	O
his	O
discharge	O
from	O
the	O
military	O
and	O
his	O
diagnosis	O
was	O
days	O
years	O
so	O
my	O
first	O
calculation	O
was	O
if	O
this	O
tumor	O
grew	O
at	O
the	O
median	B
rate	O
how	O
big	O
would	O
it	O
have	O
been	O
at	O
the	O
date	O
of	O
discharge	O
the	O
median	B
volume	B
doubling	B
time	I
reported	O
by	O
zhang	O
et	O
al	O
is	O
days	O
assuming	O
geometry	O
the	O
doubling	B
time	I
for	O
a	O
linear	O
measure	O
is	O
three	O
times	O
longer	O
time	O
between	O
discharge	O
and	O
diagnosis	O
in	O
days	O
interval	O
doubling	B
time	I
in	O
linear	O
measure	O
is	O
doubling	B
time	I
in	O
volume	B
dt	O
number	O
of	O
doublings	O
since	O
discharge	O
doublings	O
interval	O
dt	O
how	O
big	O
was	O
the	O
tumor	O
at	O
time	O
of	O
discharge	O
in	O
cm	O
doublings	O
you	O
can	O
download	O
the	O
code	O
in	O
this	O
chapter	O
from	O
httpthinkbayes	O
com	O
kidney	O
py	O
for	O
more	O
information	O
see	O
section	O
the	O
result	O
is	O
about	O
cm	O
so	O
if	O
this	O
tumor	O
formed	O
after	O
the	O
date	O
of	O
discharge	O
it	O
must	O
have	O
grown	O
substantially	O
faster	O
than	O
the	O
median	B
rate	O
therefore	O
i	O
concluded	O
that	O
it	O
is	O
more	O
likely	O
than	O
not	O
that	O
this	O
tumor	O
formed	O
before	O
the	O
date	O
of	O
discharge	O
in	O
addition	O
i	O
computed	O
the	O
growth	B
rate	I
that	O
would	O
be	O
implied	O
if	O
this	O
tumor	O
had	O
formed	O
after	O
the	O
date	O
of	O
discharge	O
if	O
we	O
assume	O
an	O
initial	O
size	O
of	O
cm	O
we	O
can	O
compute	O
the	O
number	O
of	O
doublings	O
to	O
get	O
to	O
a	O
final	O
size	O
of	O
cm	O
assume	O
an	O
initial	O
linear	O
measure	O
of	O
cm	O
chapter	O
simulation	B
how	O
many	O
doublings	O
would	O
it	O
take	O
to	O
get	O
from	O
to	O
doublings	O
what	O
linear	O
doubling	B
time	I
does	O
that	O
imply	O
dt	O
interval	O
doublings	O
compute	O
the	O
volumetric	O
doubling	B
time	I
and	O
rdt	O
vdt	O
dt	O
rdt	O
vdt	O
dt	O
is	O
linear	O
doubling	B
time	I
so	O
vdt	O
is	O
volumetric	O
doubling	B
time	I
and	O
rdt	O
is	O
reciprocal	O
doubling	B
time	I
the	O
number	O
of	O
doublings	O
in	O
linear	O
measure	O
is	O
which	O
implies	O
an	O
rdt	O
of	O
in	O
the	O
data	O
from	O
zhang	O
et	O
al	O
only	O
of	O
tumors	O
grew	O
this	O
fast	O
during	O
a	O
period	O
of	O
observation	O
so	O
again	O
i	O
concluded	O
that	O
is	O
more	O
likely	O
than	O
not	O
that	O
the	O
tumor	O
formed	O
prior	B
to	O
the	O
date	O
of	O
discharge	O
these	O
calculations	O
are	O
sufficient	O
to	O
answer	O
the	O
question	O
as	O
posed	O
and	O
on	O
behalf	O
of	O
my	O
correspondent	O
i	O
wrote	O
a	O
letter	O
explaining	O
my	O
conclusions	O
to	O
the	O
veterans	O
benefit	O
administration	O
later	O
i	O
told	O
a	O
friend	O
who	O
is	O
an	O
oncologist	O
about	O
my	O
results	O
he	O
was	O
surprised	O
by	O
the	O
growth	O
rates	O
observed	O
by	O
zhang	O
et	O
al	O
and	O
by	O
what	O
they	O
imply	O
about	O
the	O
ages	O
of	O
these	O
tumors	O
he	O
suggested	O
that	O
the	O
results	O
might	O
be	O
interesting	O
to	O
researchers	O
and	O
doctors	O
but	O
in	O
order	O
to	O
make	O
them	O
useful	O
i	O
wanted	O
a	O
more	O
general	O
model	O
of	O
the	O
relationship	O
between	O
age	O
and	O
size	O
a	O
more	O
general	O
model	O
given	O
the	O
size	O
of	O
a	O
tumor	O
at	O
time	O
of	O
diagnosis	O
it	O
would	O
be	O
most	O
useful	O
to	O
know	O
the	O
probability	B
that	O
the	O
tumor	O
formed	O
before	O
any	O
given	O
date	O
in	O
other	O
words	O
the	O
distribution	B
of	O
ages	O
to	O
find	O
it	O
i	O
run	O
simulations	O
of	O
tumor	O
growth	O
to	O
get	O
the	O
distribution	B
of	O
size	O
conditioned	O
on	O
age	O
then	O
we	O
can	O
use	O
a	O
bayesian	O
approach	O
to	O
get	O
the	O
distribution	B
of	O
age	O
conditioned	O
on	O
size	O
the	O
simulation	B
starts	O
with	O
a	O
small	O
tumor	O
and	O
runs	O
these	O
steps	O
choose	O
a	O
growth	B
rate	I
from	O
the	O
distribution	B
of	O
rdt	O
a	O
more	O
general	O
model	O
figure	O
simulations	O
of	O
tumor	O
growth	O
size	O
vs	O
time	O
compute	O
the	O
size	O
of	O
the	O
tumor	O
at	O
the	O
end	O
of	O
an	O
interval	O
record	O
the	O
size	O
of	O
the	O
tumor	O
at	O
each	O
interval	O
repeat	O
until	O
the	O
tumor	O
exceeds	O
the	O
maximum	B
relevant	O
size	O
for	O
the	O
initial	O
size	O
i	O
chose	O
cm	O
because	O
carcinomas	O
smaller	O
than	O
that	O
are	O
less	O
likely	O
to	O
be	O
invasive	O
and	O
less	O
likely	O
to	O
have	O
the	O
blood	O
supply	O
needed	O
for	O
rapid	O
growth	O
httpen	O
wikipedia	O
orgwikicarcinoma	O
in	O
situ	O
i	O
chose	O
an	O
interval	O
of	O
days	O
months	O
because	O
that	O
is	O
the	O
median	B
time	O
between	O
measurements	O
in	O
the	O
data	O
source	O
for	O
the	O
maximum	B
size	O
i	O
chose	O
cm	O
in	O
the	O
data	O
source	O
the	O
range	O
of	O
observed	O
sizes	O
is	O
to	O
cm	O
so	O
we	O
are	O
extrapolating	O
beyond	O
the	O
observed	O
range	O
at	O
each	O
end	O
but	O
not	O
by	O
far	O
and	O
not	O
in	O
a	O
way	O
likely	O
to	O
have	O
a	O
strong	O
effect	O
on	O
the	O
results	O
the	O
simulation	B
is	O
based	O
on	O
one	O
big	O
simplification	O
the	O
growth	B
rate	I
is	O
chosen	O
independently	O
during	O
each	O
interval	O
so	O
it	O
does	O
not	O
depend	O
on	O
age	O
size	O
or	O
growth	B
rate	I
during	O
previous	O
intervals	O
in	O
section	O
i	O
review	O
these	O
assumptions	O
and	O
consider	O
more	O
detailed	O
models	O
but	O
first	O
let	O
s	O
look	O
at	O
some	O
examples	O
figure	O
shows	O
the	O
size	O
of	O
simulated	O
tumors	O
as	O
a	O
function	O
of	O
age	O
the	O
dashed	O
line	O
at	O
cm	O
shows	O
the	O
range	O
of	O
ages	O
for	O
tumors	O
at	O
that	O
size	O
the	O
fastest-growing	O
tumor	O
gets	O
there	O
in	O
years	O
the	O
slowest	O
takes	O
more	O
than	O
age	O
log	O
scalesimulations	O
of	O
tumor	O
growth	O
chapter	O
simulation	B
i	O
am	O
presenting	O
results	O
in	O
terms	O
of	O
linear	O
measurements	O
but	O
the	O
calculations	O
are	O
in	O
terms	O
of	O
volume	B
to	O
convert	O
from	O
one	O
to	O
the	O
other	O
again	O
i	O
use	O
the	O
volume	B
of	O
a	O
sphere	B
with	O
the	O
given	O
diameter	O
implementation	B
here	O
is	O
the	O
kernel	O
of	O
the	O
simulation	B
def	O
makesequencerdt	O
seq	O
seq	O
age	O
for	O
rdt	O
in	O
rdt	O
seq	O
age	O
interval	O
final	O
seq	O
extendsequenceage	O
seq	O
rdt	O
interval	O
if	O
final	O
vmax	O
break	O
return	O
seq	O
rdt	O
seq	O
is	O
an	O
iterator	B
that	O
yields	O
random	O
values	O
from	O
the	O
cdf	B
of	O
growth	B
rate	I
is	O
the	O
initial	O
volume	B
in	O
ml	O
interval	O
is	O
the	O
time	O
step	O
in	O
years	O
vmax	O
is	O
the	O
final	O
volume	B
corresponding	O
to	O
a	O
linear	O
measurement	O
of	O
cm	O
volume	B
converts	O
from	O
linear	O
measurement	O
in	O
cm	O
to	O
volume	B
in	O
ml	O
based	O
on	O
the	O
simplification	O
that	O
the	O
tumor	O
is	O
a	O
sphere	B
def	O
volumediameter	O
return	O
factor	O
extendsequence	O
computes	O
the	O
volume	B
of	O
the	O
tumor	O
at	O
the	O
end	O
of	O
the	O
interval	O
def	O
extendsequenceage	O
seq	O
rdt	O
interval	O
initial	O
doublings	O
rdt	O
interval	O
final	O
initial	O
new	O
seq	O
seq	O
cache	B
addage	O
new	O
seq	O
rdt	O
return	O
final	O
new	O
seq	O
age	O
is	O
the	O
age	O
of	O
the	O
tumor	O
at	O
the	O
end	O
of	O
the	O
interval	O
seq	O
is	O
a	O
tuple	B
that	O
contains	O
the	O
volumes	O
so	O
far	O
rdt	O
is	O
the	O
growth	B
rate	I
during	O
the	O
interval	O
in	O
doublings	O
per	O
year	O
interval	O
is	O
the	O
size	O
of	O
the	O
time	O
step	O
in	O
years	O
caching	O
the	O
joint	B
distribution	B
figure	O
joint	B
distribution	B
of	O
age	O
and	O
tumor	O
size	O
the	O
return	O
values	O
are	O
final	O
the	O
volume	B
of	O
the	O
tumor	O
at	O
the	O
end	O
of	O
the	O
interval	O
and	O
new	O
seq	O
a	O
new	O
tuple	B
containing	O
the	O
volumes	O
in	O
seq	O
plus	O
the	O
new	O
volume	B
final	O
cache	B
add	O
records	O
the	O
age	O
and	O
size	O
of	O
each	O
tumor	O
at	O
the	O
end	O
of	O
each	O
interval	O
as	O
explained	O
in	O
the	O
next	O
section	O
caching	O
the	O
joint	B
distribution	B
here	O
s	O
how	O
the	O
cache	B
works	O
class	O
cacheobject	O
def	O
self	O
joint	B
thinkbayes	O
joint	B
joint	B
is	O
a	O
joint	B
pmf	B
that	O
records	O
the	O
frequency	O
of	O
each	O
age-size	O
pair	O
so	O
it	O
approximates	O
the	O
joint	B
distribution	B
of	O
age	O
and	O
size	O
at	O
the	O
end	O
of	O
each	O
simulated	O
interval	O
extendsequence	O
calls	O
add	O
class	O
cache	B
def	O
addself	O
age	O
seq	O
final	O
cm	O
diameterfinal	O
bucket	B
roundcmtobucketcm	O
self	O
joint	B
incrage	O
bucket	B
log	B
scale	I
chapter	O
simulation	B
figure	O
distributions	O
of	O
age	O
conditioned	O
on	O
size	O
again	O
age	O
is	O
the	O
age	O
of	O
the	O
tumor	O
and	O
seq	O
is	O
the	O
sequence	O
of	O
volumes	O
so	O
far	O
before	O
adding	O
the	O
new	O
data	O
to	O
the	O
joint	B
distribution	B
we	O
use	O
diameter	O
to	O
convert	O
from	O
volume	B
to	O
diameter	O
in	O
centimeters	O
def	O
diametervolume	O
return	O
volume	B
exp	O
and	O
cmtobucket	O
to	O
convert	O
from	O
centimeters	O
to	O
a	O
discrete	O
bucket	B
number	O
def	O
cmtobucketx	O
return	O
factor	O
math	O
logx	O
the	O
buckets	O
are	O
equally	O
spaced	O
on	O
a	O
log	B
scale	I
using	O
yields	O
a	O
reasonable	O
number	O
of	O
buckets	O
for	O
example	O
cm	O
maps	O
to	O
bucket	B
and	O
cm	O
maps	O
to	O
bucket	B
after	O
running	O
the	O
simulations	O
we	O
can	O
plot	O
the	O
joint	B
distribution	B
as	O
a	O
pseudocolor	B
plot	I
where	O
each	O
cell	O
represents	O
the	O
number	O
of	O
tumors	O
observed	O
at	O
a	O
given	O
size-age	O
pair	O
figure	O
shows	O
the	O
joint	B
distribution	B
after	O
simulations	O
conditional	B
distributions	O
by	O
taking	O
a	O
vertical	O
slice	O
from	O
the	O
joint	B
distribution	B
we	O
can	O
get	O
the	O
distribution	B
of	O
sizes	O
for	O
any	O
given	O
age	O
by	O
taking	O
a	O
horizontal	O
slice	O
we	O
can	O
get	O
the	O
distribution	B
of	O
ages	O
conditioned	O
on	O
size	O
age	O
of	O
age	O
for	O
several	O
cm	O
conditional	B
distributions	O
figure	O
percentiles	O
of	O
tumor	O
age	O
as	O
a	O
function	O
of	O
size	O
here	O
s	O
the	O
code	O
that	O
reads	O
the	O
joint	B
distribution	B
and	O
builds	O
the	O
conditional	B
distribution	B
for	O
a	O
given	O
size	O
class	O
cache	B
def	O
conditionalcdfself	O
bucket	B
pmf	B
bucket	B
cdf	B
pmf	B
makecdf	O
return	O
cdf	B
bucket	B
is	O
the	O
integer	O
bucket	B
number	O
corresponding	O
to	O
tumor	O
size	O
joint	B
conditional	B
computes	O
the	O
pmf	B
of	O
age	O
conditioned	O
on	O
bucket	B
the	O
result	O
is	O
the	O
cdf	B
of	O
age	O
conditioned	O
on	O
bucket	B
figure	O
shows	O
several	O
of	O
these	O
cdfs	O
for	O
a	O
range	O
of	O
sizes	O
to	O
summarize	O
these	O
distributions	O
we	O
can	O
compute	O
percentiles	O
as	O
a	O
function	O
of	O
size	O
percentiles	O
for	O
bucket	B
in	O
cache	B
getbuckets	O
cdf	B
conditionalcdfbucket	O
ps	O
for	O
p	O
in	O
percentiles	O
figure	O
shows	O
these	O
percentiles	O
for	O
each	O
size	O
bucket	B
the	O
data	O
points	O
are	O
computed	O
from	O
the	O
estimated	O
joint	B
distribution	B
in	O
the	O
model	O
size	O
and	O
time	O
are	O
discrete	O
which	O
contributes	O
numerical	O
errors	O
so	O
i	O
also	O
show	O
a	O
least	B
squares	I
fit	I
for	O
each	O
sequence	O
of	O
percentiles	O
log	O
age	O
interval	O
for	O
age	O
vs	O
diameter	O
chapter	O
simulation	B
serial	B
correlation	I
the	O
results	O
so	O
far	O
are	O
based	O
on	O
a	O
number	O
of	O
modeling	B
decisions	O
let	O
s	O
review	O
them	O
and	O
consider	O
which	O
ones	O
are	O
the	O
most	O
likely	O
sources	O
of	O
error	B
to	O
convert	O
from	O
linear	O
measure	O
to	O
volume	B
we	O
assume	O
that	O
tumors	O
are	O
approximately	O
spherical	O
this	O
assumption	O
is	O
probably	O
fine	O
for	O
tumors	O
up	O
to	O
a	O
few	O
centimeters	O
but	O
not	O
for	O
very	O
large	O
tumors	O
the	O
distribution	B
of	O
growth	O
rates	O
in	O
the	O
simulations	O
are	O
based	O
on	O
a	O
continuous	O
model	O
we	O
chose	O
to	O
fit	O
the	O
data	O
reported	O
by	O
zhang	O
et	O
al	O
which	O
is	O
based	O
on	O
patients	O
the	O
fit	O
is	O
only	O
approximate	O
and	O
more	O
importantly	O
a	O
larger	O
sample	O
would	O
yield	O
a	O
different	O
distribution	B
the	O
growth	O
model	O
does	O
not	O
take	O
into	O
account	O
tumor	O
subtype	O
or	O
grade	O
this	O
assumption	O
is	O
consistent	O
with	O
the	O
conclusion	O
of	O
zhang	O
et	O
al	O
growth	O
rates	O
in	O
renal	O
tumors	O
of	O
different	O
sizes	O
subtypes	O
and	O
grades	O
represent	O
a	O
wide	O
range	O
and	O
overlap	O
substantially	O
but	O
with	O
a	O
larger	O
sample	O
a	O
difference	O
might	O
become	O
apparent	O
the	O
distribution	B
of	O
growth	B
rate	I
does	O
not	O
depend	O
on	O
the	O
size	O
of	O
the	O
tumor	O
this	O
assumption	O
would	O
not	O
be	O
realistic	O
for	O
very	O
small	O
and	O
very	O
large	O
tumors	O
whose	O
growth	O
is	O
limited	O
by	O
blood	O
supply	O
but	O
tumors	O
observed	O
by	O
zhang	O
et	O
al	O
ranged	O
from	O
to	O
cm	O
and	O
they	O
found	O
no	O
statistically	O
significant	O
relationship	O
between	O
size	O
and	O
growth	B
rate	I
so	O
if	O
there	O
is	O
a	O
relationship	O
it	O
is	O
likely	O
to	O
be	O
weak	O
at	O
least	O
in	O
this	O
size	O
range	O
in	O
the	O
simulations	O
growth	B
rate	I
during	O
each	O
interval	O
is	O
independent	O
of	O
previous	O
growth	O
rates	O
in	O
reality	O
it	O
is	O
plausible	O
that	O
tumors	O
that	O
have	O
grown	O
quickly	O
in	O
the	O
past	O
are	O
more	O
likely	O
to	O
grow	O
quickly	O
in	O
other	O
words	O
there	O
is	O
probably	O
a	O
serial	B
correlation	I
in	O
growth	B
rate	I
of	O
these	O
the	O
first	O
and	O
last	O
seem	O
the	O
most	O
problematic	O
i	O
ll	O
investigate	O
serial	B
correlation	I
first	O
then	O
come	O
back	O
to	O
spherical	O
geometry	O
to	O
simulate	O
correlated	O
growth	O
i	O
wrote	O
a	O
that	O
yields	O
a	O
correlated	O
series	O
from	O
a	O
given	O
cdf	B
here	O
s	O
how	O
the	O
algorithm	O
works	O
generate	O
correlated	O
values	O
from	O
a	O
gaussian	B
distribution	B
this	O
is	O
easy	O
to	O
do	O
because	O
we	O
can	O
compute	O
the	O
distribution	B
of	O
the	O
next	O
value	O
conditioned	O
on	O
the	O
previous	O
value	O
you	O
are	O
not	O
familiar	O
with	O
python	O
generators	O
see	O
httpwiki	O
python	O
orgmoin	O
generators	O
serial	B
correlation	I
transform	O
each	O
value	O
to	O
its	O
cumulative	B
probability	B
using	O
the	O
gaussian	O
cdf	B
transform	O
each	O
cumulative	B
probability	B
to	O
the	O
corresponding	O
value	O
us	O
ing	O
the	O
given	O
cdf	B
here	O
s	O
what	O
that	O
looks	O
like	O
in	O
code	O
def	O
correlatedgeneratorcdf	O
rho	O
x	O
yield	O
transformx	O
sigma	O
while	O
true	O
x	O
random	O
gaussx	O
rho	O
sigma	O
yield	O
transformx	O
cdf	B
is	O
the	O
desired	O
cdf	B
rho	O
is	O
the	O
desired	O
correlation	O
the	O
values	O
of	O
x	O
are	O
gaussian	O
transform	O
converts	O
them	O
to	O
the	O
desired	O
distribution	B
the	O
first	O
value	O
of	O
x	O
is	O
gaussian	O
with	O
mean	O
and	O
standard	O
deviation	O
for	O
subsequent	O
values	O
the	O
mean	O
and	O
standard	O
deviation	O
depend	O
on	O
the	O
previous	O
value	O
given	O
the	O
previous	O
x	O
the	O
mean	O
of	O
the	O
next	O
value	O
is	O
x	O
rho	O
and	O
the	O
variance	O
is	O
transform	O
maps	O
from	O
each	O
gaussian	O
value	O
x	O
to	O
a	O
value	O
from	O
the	O
given	O
cdf	B
y	O
def	O
transformx	O
p	O
thinkbayes	O
gaussiancdfx	O
y	O
cdf	B
valuep	O
return	O
y	O
gaussiancdf	O
computes	O
the	O
cdf	B
of	O
the	O
standard	O
gaussian	B
distribution	B
at	O
x	O
returning	O
a	O
cumulative	B
probability	B
cdf	B
value	O
maps	O
from	O
a	O
cumulative	B
probability	B
to	O
the	O
corresponding	O
value	O
in	O
cdf	B
depending	O
on	O
the	O
shape	O
of	O
cdf	B
information	O
can	O
be	O
lost	O
in	O
transformation	O
so	O
the	O
actual	O
correlation	O
might	O
be	O
lower	O
than	O
rho	O
for	O
example	O
when	O
i	O
generate	O
values	O
from	O
the	O
distribution	B
of	O
growth	O
rates	O
with	O
the	O
actual	O
correlation	O
is	O
but	O
since	O
we	O
are	O
guessing	O
at	O
the	O
right	O
correlation	O
anyway	O
that	O
s	O
close	O
enough	O
remember	O
that	O
makesequence	O
takes	O
an	O
iterator	B
as	O
an	O
argument	O
that	O
interface	B
allows	O
it	O
to	O
work	O
with	O
different	O
generators	O
chapter	O
simulation	B
serial	B
correlation	I
diameter	O
percentiles	O
of	O
age	O
table	O
percentiles	O
of	O
tumor	O
age	O
conditioned	O
on	O
size	O
iterator	B
uncorrelatedgeneratorcdf	O
makesequenceiterator	O
iterator	B
correlatedgeneratorcdf	O
rho	O
makesequenceiterator	O
in	O
this	O
example	O
and	O
are	O
drawn	O
from	O
the	O
same	O
distribution	B
but	O
the	O
values	O
in	O
are	O
uncorrelated	O
and	O
the	O
values	O
in	O
are	O
correlated	O
with	O
a	O
coefficient	O
of	O
approximately	O
rho	O
now	O
we	O
can	O
see	O
what	O
effect	O
serial	B
correlation	I
has	O
on	O
the	O
results	O
the	O
following	O
table	O
shows	O
percentiles	O
of	O
age	O
for	O
a	O
cm	O
tumor	O
using	O
the	O
uncorrelated	O
generator	B
and	O
a	O
correlated	O
generator	B
with	O
target	O
correlation	O
makes	O
the	O
fastest	O
growing	O
tumors	O
faster	O
and	O
the	O
slowest	O
slower	O
so	O
the	O
range	O
of	O
ages	O
is	O
wider	O
the	O
difference	O
is	O
modest	O
for	O
low	O
percentiles	O
but	O
for	O
the	O
percentile	B
it	O
is	O
more	O
than	O
years	O
to	O
compute	O
these	O
percentiles	O
precisely	O
we	O
would	O
need	O
a	O
better	O
estimate	O
of	O
the	O
actual	O
serial	B
correlation	I
however	O
this	O
model	O
is	O
sufficient	O
to	O
answer	O
the	O
question	O
we	O
started	O
with	O
given	O
a	O
tumor	O
with	O
a	O
linear	O
dimension	O
of	O
cm	O
what	O
is	O
the	O
probability	B
that	O
it	O
formed	O
more	O
than	O
years	O
ago	O
here	O
s	O
the	O
code	O
class	O
cache	B
def	O
probolderself	O
cm	O
age	O
bucket	B
cmtobucketcm	O
cdf	B
self	O
conditionalcdfbucket	O
p	O
cdf	B
probage	O
return	O
cm	O
is	O
the	O
size	O
of	O
the	O
tumor	O
age	O
is	O
the	O
age	O
threshold	O
in	O
years	O
probolder	O
converts	O
size	O
to	O
a	O
bucket	B
number	O
gets	O
the	O
cdf	B
of	O
age	O
conditioned	O
on	O
bucket	B
and	O
computes	O
the	O
probability	B
that	O
age	O
exceeds	O
the	O
given	O
value	O
discussion	O
with	O
no	O
serial	B
correlation	I
the	O
probability	B
that	O
a	O
cm	O
tumor	O
is	O
older	O
than	O
years	O
is	O
or	O
almost	O
certain	O
with	O
correlation	O
faster-growing	O
tumors	O
are	O
more	O
likely	O
but	O
the	O
probability	B
is	O
still	O
even	O
with	O
correlation	O
the	O
probability	B
is	O
another	O
likely	O
source	O
of	O
error	B
is	O
the	O
assumption	O
that	O
tumors	O
are	O
approximately	O
spherical	O
for	O
a	O
tumor	O
with	O
linear	O
dimensions	O
x	O
cm	O
this	O
assumption	O
is	O
probably	O
not	O
valid	O
if	O
as	O
seems	O
likely	O
a	O
tumor	O
this	O
size	O
is	O
relatively	O
flat	O
it	O
might	O
have	O
the	O
same	O
volume	B
as	O
a	O
cm	O
sphere	B
with	O
this	O
smaller	O
volume	B
and	O
correlation	O
the	O
probability	B
of	O
age	O
greater	O
than	O
is	O
still	O
so	O
even	O
taking	O
into	O
account	O
modeling	B
errors	O
it	O
is	O
unlikely	O
that	O
such	O
a	O
large	O
tumor	O
could	O
have	O
formed	O
less	O
than	O
years	O
prior	B
to	O
the	O
date	O
of	O
diagnosis	O
discussion	O
well	O
we	O
got	O
through	O
a	O
whole	O
chapter	O
without	O
using	O
bayes	O
s	O
theorem	O
or	O
the	O
suite	B
class	I
that	O
encapsulates	O
bayesian	O
updates	O
what	O
happened	O
one	O
way	O
to	O
think	O
about	O
bayes	O
s	O
theorem	O
is	O
as	O
an	O
algorithm	O
for	O
inverting	O
conditional	B
probabilities	O
given	O
pba	O
we	O
can	O
compute	O
pab	O
provided	O
we	O
know	O
pa	O
and	O
pb	O
of	O
course	O
this	O
algorithm	O
is	O
only	O
useful	O
if	O
for	O
some	O
reason	O
it	O
is	O
easier	O
to	O
compute	O
pba	O
than	O
pab	O
in	O
this	O
example	O
it	O
is	O
by	O
running	O
simulations	O
we	O
can	O
estimate	O
the	O
distribution	B
of	O
size	O
conditioned	O
on	O
age	O
or	O
psizeage	O
but	O
it	O
is	O
harder	O
to	O
get	O
the	O
distribution	B
of	O
age	O
conditioned	O
on	O
size	O
or	O
pagesize	O
so	O
this	O
seems	O
like	O
a	O
perfect	O
opportunity	O
to	O
use	O
bayes	O
s	O
theorem	O
the	O
reason	O
i	O
didn	O
t	O
is	O
computational	O
efficiency	O
to	O
estimate	O
psizeage	O
for	O
any	O
given	O
size	O
you	O
have	O
to	O
run	O
a	O
lot	O
of	O
simulations	O
along	O
the	O
way	O
you	O
end	O
up	O
computing	O
psizeage	O
for	O
a	O
lot	O
of	O
sizes	O
in	O
fact	O
you	O
end	O
up	O
computing	O
the	O
entire	O
joint	B
distribution	B
of	O
size	O
and	O
age	O
psize	O
age	O
and	O
once	O
you	O
have	O
the	O
joint	B
distribution	B
you	O
don	O
t	O
really	O
need	O
bayes	O
s	O
theorem	O
you	O
can	O
extract	O
pagesize	O
by	O
taking	O
slices	O
from	O
the	O
joint	B
distribution	B
as	O
demonstrated	O
in	O
conditionalcdf	O
so	O
we	O
side-stepped	O
bayes	O
but	O
he	O
was	O
with	O
us	O
in	O
spirit	O
chapter	O
simulation	B
chapter	O
a	O
hierarchical	B
model	I
the	O
geiger	B
counter	I
problem	I
i	O
got	O
the	O
idea	O
for	O
the	O
following	O
problem	O
from	O
tom	O
campbell-ricketts	B
author	O
of	O
the	O
maximum	B
entropy	O
blog	O
at	O
httpmaximum-entropy-blog	O
blogspot	O
com	O
and	O
he	O
got	O
the	O
idea	O
from	O
e	O
t	O
jaynes	B
author	O
of	O
the	O
classic	O
probability	B
theory	O
the	O
logic	O
of	O
science	O
suppose	O
that	O
a	O
radioactive	O
source	O
emits	O
particles	O
toward	O
a	O
geiger	O
counter	O
at	O
an	O
average	O
rate	O
of	O
r	O
particles	O
per	O
second	O
but	O
the	O
counter	O
only	O
registers	O
a	O
fraction	O
f	O
of	O
the	O
particles	O
that	O
hit	O
it	O
if	O
f	O
is	O
and	O
the	O
counter	O
registers	O
particles	O
in	O
a	O
one	O
second	O
interval	O
what	O
is	O
the	O
posterior	B
distribution	B
of	O
n	O
the	O
actual	O
number	O
of	O
particles	O
that	O
hit	O
the	O
counter	O
and	O
r	O
the	O
average	O
rate	O
particles	O
are	O
emitted	O
to	O
get	O
started	O
on	O
a	O
problem	O
like	O
this	O
think	O
about	O
the	O
chain	O
of	O
causation	B
that	O
starts	O
with	O
the	O
parameters	O
of	O
the	O
system	B
and	O
ends	O
with	O
the	O
observed	O
data	O
the	O
source	O
emits	O
particles	O
at	O
an	O
average	O
rate	O
r	O
during	O
any	O
given	O
second	O
the	O
source	O
emits	O
n	O
particles	O
toward	O
the	O
counter	O
out	O
of	O
those	O
n	O
particles	O
some	O
number	O
k	O
get	O
counted	O
the	O
probability	B
that	O
an	O
atom	O
decays	O
is	O
the	O
same	O
at	O
any	O
point	O
in	O
time	O
so	O
radioactive	B
decay	I
is	O
well	O
modeled	O
by	O
a	O
poisson	B
process	B
given	O
r	O
the	O
distribution	B
of	O
n	O
is	O
poisson	B
distribution	B
with	O
parameter	B
r	O
chapter	O
a	O
hierarchical	B
model	I
figure	O
posterior	B
distribution	B
of	O
n	O
for	O
three	O
values	O
of	O
r	O
and	O
if	O
we	O
assume	O
that	O
the	O
probability	B
of	O
detection	O
for	O
each	O
particle	O
is	O
independent	O
of	O
the	O
others	O
the	O
distribution	B
of	O
k	O
is	O
the	O
binomial	B
distribution	B
with	O
parameters	O
n	O
and	O
f	O
given	O
the	O
parameters	O
of	O
the	O
system	B
we	O
can	O
find	O
the	O
distribution	B
of	O
the	O
data	O
so	O
we	O
can	O
solve	O
what	O
is	O
called	O
the	O
forward	B
problem	I
now	O
we	O
want	O
to	O
go	O
the	O
other	O
way	O
given	O
the	O
data	O
we	O
want	O
the	O
distribution	B
of	O
the	O
parameters	O
this	O
is	O
called	O
the	O
inverse	B
problem	I
and	O
if	O
you	O
can	O
solve	O
the	O
forward	B
problem	I
you	O
can	O
use	O
bayesian	O
methods	O
to	O
solve	O
the	O
inverse	B
problem	I
start	O
simple	O
let	O
s	O
start	O
with	O
a	O
simple	O
version	O
of	O
the	O
problem	O
where	O
we	O
know	O
the	O
value	O
of	O
r	O
we	O
are	O
given	O
the	O
value	O
of	O
f	O
so	O
all	O
we	O
have	O
to	O
do	O
is	O
estimate	O
n	O
i	O
define	O
a	O
suite	B
called	O
detector	O
that	O
models	O
the	O
behavior	O
of	O
the	O
detector	O
and	O
estimates	O
n	O
class	O
detectorthinkbayes	O
suite	B
def	O
r	O
f	O
pmf	B
thinkbayes	O
makepoissonpmfr	O
high	O
stepstep	O
thinkbayes	O
suite	B
init	O
self	O
pmf	B
namer	O
self	O
r	O
r	O
self	O
f	O
f	O
of	O
particles	O
make	O
it	O
hierarchical	O
if	O
the	O
average	O
emission	O
rate	O
is	O
r	O
particles	O
per	O
second	O
the	O
distribution	B
of	O
n	O
is	O
poisson	O
with	O
parameter	B
r	O
high	O
and	O
step	O
determine	O
the	O
upper	O
bound	O
for	O
n	O
and	O
the	O
step	O
size	O
between	O
hypothetical	O
values	O
now	O
we	O
need	O
a	O
likelihood	B
function	I
class	O
detector	O
def	O
likelihoodself	O
data	O
hypo	O
k	O
data	O
n	O
hypo	O
p	O
self	O
f	O
return	O
thinkbayes	O
evalbinomialpmfk	O
n	O
p	O
data	O
is	O
the	O
number	O
of	O
particles	O
detected	O
and	O
hypo	O
is	O
the	O
hypothetical	O
number	O
of	O
particles	O
emitted	O
n	O
if	O
there	O
are	O
actually	O
n	O
particles	O
and	O
the	O
probability	B
of	O
detecting	O
any	O
one	O
of	O
them	O
is	O
f	O
the	O
probability	B
of	O
detecting	O
k	O
particles	O
is	O
given	O
by	O
the	O
binomial	B
distribution	B
that	O
s	O
it	O
for	O
the	O
detector	O
we	O
can	O
try	O
it	O
out	O
for	O
a	O
range	O
of	O
values	O
of	O
r	O
f	O
k	O
for	O
r	O
in	O
suite	B
detectorr	O
f	O
suite	B
updatek	O
print	O
suite	B
maximumlikelihood	O
figure	O
shows	O
the	O
posterior	B
distribution	B
of	O
n	O
for	O
several	O
given	O
values	O
of	O
r	O
make	O
it	O
hierarchical	O
in	O
the	O
previous	O
section	O
we	O
assume	O
r	O
is	O
known	O
now	O
let	O
s	O
relax	O
that	O
assumption	O
i	O
define	O
another	O
suite	B
called	O
emitter	O
that	O
models	O
the	O
behavior	O
of	O
the	O
emitter	O
and	O
estimates	O
r	O
class	O
emitterthinkbayes	O
suite	B
def	O
rs	O
detectors	O
f	O
for	O
r	O
in	O
rs	O
thinkbayes	O
suite	B
init	O
self	O
detectors	O
chapter	O
a	O
hierarchical	B
model	I
rs	O
is	O
a	O
sequence	O
of	O
hypothetical	O
value	O
for	O
r	O
detectors	O
is	O
a	O
sequence	O
of	O
detector	O
objects	O
one	O
for	O
each	O
value	O
of	O
r	O
the	O
values	O
in	O
the	O
suite	B
are	O
detectors	O
so	O
emitter	O
is	O
a	O
meta-suite	B
that	O
is	O
a	O
suite	B
that	O
contains	O
other	O
suites	O
as	O
values	O
to	O
update	B
the	O
emitter	O
we	O
have	O
to	O
compute	O
the	O
likelihood	B
of	O
the	O
data	O
under	O
each	O
hypothetical	O
value	O
of	O
r	O
but	O
each	O
value	O
of	O
r	O
is	O
represented	O
by	O
a	O
detector	O
that	O
contains	O
a	O
range	O
of	O
values	O
for	O
n	O
to	O
compute	O
the	O
likelihood	B
of	O
the	O
data	O
for	O
a	O
given	O
detector	O
we	O
loop	O
through	O
the	O
values	O
of	O
n	O
and	O
add	O
up	O
the	O
total	B
probability	B
of	O
k	O
that	O
s	O
what	O
suitelikelihood	O
does	O
class	O
detector	O
def	O
suitelikelihoodself	O
data	O
total	O
for	O
hypo	O
prob	B
in	O
self	O
items	O
like	O
self	O
likelihooddata	O
hypo	O
total	O
prob	B
like	O
return	O
total	O
now	O
we	O
can	O
write	O
the	O
likelihood	B
function	I
for	O
the	O
emitter	O
class	O
emitter	O
def	O
likelihoodself	O
data	O
hypo	O
detector	O
hypo	O
like	O
detector	O
suitelikelihooddata	O
return	O
like	O
each	O
hypo	O
is	O
a	O
detector	O
so	O
we	O
can	O
invoke	O
suitelikelihood	O
to	O
get	O
the	O
likelihood	B
of	O
the	O
data	O
under	O
the	O
hypothesis	O
after	O
we	O
update	B
the	O
emitter	O
we	O
have	O
to	O
update	B
each	O
of	O
the	O
detectors	O
too	O
class	O
emitter	O
def	O
updateself	O
data	O
thinkbayes	O
suite	B
updateself	O
data	O
for	O
detector	O
in	O
self	O
values	O
detector	O
update	B
a	O
model	O
like	O
this	O
with	O
multiple	O
levels	O
of	O
suites	O
is	O
called	O
hierarchical	O
a	O
little	O
optimization	B
figure	O
posterior	B
distributions	O
of	O
n	O
and	O
r	O
a	O
little	O
optimization	B
you	O
might	O
recognize	O
suitelikelihood	O
we	O
saw	O
it	O
in	O
section	O
at	O
the	O
time	O
i	O
pointed	O
out	O
that	O
we	O
didn	O
t	O
really	O
need	O
it	O
because	O
the	O
total	B
probability	B
computed	O
by	O
suitelikelihood	O
is	O
exactly	O
the	O
normalizing	B
constant	I
computed	O
and	O
returned	O
by	O
update	B
so	O
instead	O
of	O
updating	O
the	O
emitter	O
and	O
then	O
updating	O
the	O
detectors	O
we	O
can	O
do	O
both	O
steps	O
at	O
the	O
same	O
time	O
using	O
the	O
result	O
from	O
detector	O
update	B
as	O
the	O
likelihood	B
of	O
emitter	O
here	O
s	O
the	O
streamlined	O
version	O
of	O
emitter	O
likelihood	B
class	O
emitter	O
def	O
likelihoodself	O
data	O
hypo	O
return	O
hypo	O
updatedata	O
and	O
with	O
this	O
version	O
of	O
likelihood	B
we	O
can	O
use	O
the	O
default	O
version	O
of	O
update	B
so	O
this	O
version	O
has	O
fewer	O
lines	O
of	O
code	O
and	O
it	O
runs	O
faster	O
because	O
it	O
does	O
not	O
compute	O
the	O
normalizing	B
constant	I
twice	O
extracting	O
the	O
posteriors	O
after	O
we	O
update	B
the	O
emitter	O
we	O
can	O
get	O
the	O
posterior	B
distribution	B
of	O
r	O
by	O
looping	O
through	O
the	O
detectors	O
and	O
their	O
probabilities	O
rposterior	O
n	O
chapter	O
a	O
hierarchical	B
model	I
class	O
emitter	O
def	O
distofrself	O
items	O
prob	B
for	O
detector	O
prob	B
in	O
self	O
items	O
return	O
thinkbayes	O
makepmffromitemsitems	O
items	O
is	O
a	O
list	O
of	O
values	O
of	O
r	O
and	O
their	O
probabilities	O
the	O
result	O
is	O
the	O
pmf	B
of	O
r	O
to	O
get	O
the	O
posterior	B
distribution	B
of	O
n	O
we	O
have	O
to	O
compute	O
the	O
mixture	B
of	O
the	O
detectors	O
we	O
can	O
use	O
thinkbayes	O
makemixture	B
which	O
takes	O
a	O
metapmf	O
that	O
maps	O
from	O
each	O
distribution	B
to	O
its	O
probability	B
and	O
that	O
s	O
exactly	O
what	O
the	O
emitter	O
is	O
class	O
emitter	O
def	O
distofnself	O
return	O
thinkbayes	O
makemixtureself	O
figure	O
shows	O
the	O
results	O
not	O
surprisingly	O
the	O
most	O
likely	O
value	O
for	O
n	O
is	O
given	O
f	O
and	O
n	O
the	O
expected	O
count	O
is	O
k	O
f	O
n	O
so	O
given	O
f	O
and	O
k	O
the	O
expected	O
value	O
of	O
n	O
is	O
k	O
f	O
which	O
is	O
and	O
if	O
particles	O
are	O
emitted	O
in	O
one	O
second	O
the	O
most	O
likely	O
value	O
of	O
r	O
is	O
particles	O
per	O
second	O
so	O
the	O
posterior	B
distribution	B
of	O
r	O
is	O
also	O
centered	O
on	O
the	O
posterior	B
distributions	O
of	O
r	O
and	O
n	O
are	O
similar	O
the	O
only	O
difference	O
is	O
that	O
we	O
are	O
slightly	O
less	O
certain	O
about	O
n	O
in	O
general	O
we	O
can	O
be	O
more	O
certain	O
about	O
the	O
long-range	O
emission	O
rate	O
r	O
than	O
about	O
the	O
number	O
of	O
particles	O
emitted	O
in	O
any	O
particular	O
second	O
n	O
you	O
can	O
download	O
the	O
code	O
in	O
this	O
chapter	O
from	O
httpthinkbayes	O
com	O
jaynes	B
py	O
for	O
more	O
information	O
see	O
section	O
discussion	O
the	O
geiger	B
counter	I
problem	I
demonstrates	O
the	O
connection	O
between	O
causation	B
and	O
hierarchical	O
modeling	B
in	O
the	O
example	O
the	O
emission	O
rate	O
r	O
has	O
a	O
causal	O
effect	O
on	O
the	O
number	O
of	O
particles	O
n	O
which	O
has	O
a	O
causal	O
effect	O
on	O
the	O
particle	O
count	O
k	O
the	O
hierarchical	B
model	I
reflects	O
the	O
structure	O
of	O
the	O
system	B
with	O
causes	O
at	O
the	O
top	O
and	O
effects	O
at	O
the	O
bottom	O
exercises	O
at	O
the	O
top	O
level	O
we	O
start	O
with	O
a	O
range	O
of	O
hypothetical	O
values	O
for	O
r	O
for	O
each	O
value	O
of	O
r	O
we	O
have	O
a	O
range	O
of	O
values	O
for	O
n	O
and	O
the	O
prior	B
distribution	B
of	O
n	O
depends	O
on	O
r	O
when	O
we	O
update	B
the	O
model	O
we	O
go	O
bottom-up	O
we	O
compute	O
a	O
posterior	B
distribution	B
of	O
n	O
for	O
each	O
value	O
of	O
r	O
then	O
compute	O
the	O
posterior	B
distribution	B
of	O
r	O
so	O
causal	O
information	O
flows	O
down	O
the	O
hierarchy	O
and	O
inference	O
flows	O
up	O
exercises	O
exercise	O
this	O
exercise	O
is	O
also	O
inspired	O
by	O
an	O
example	O
in	O
jaynes	B
probability	B
theory	O
suppose	O
you	O
buy	O
a	O
mosquito	O
trap	O
that	O
is	O
supposed	O
to	O
reduce	O
the	O
population	O
of	O
mosquitoes	O
near	O
your	O
house	O
each	O
week	O
you	O
empty	O
the	O
trap	O
and	O
count	O
the	O
number	O
of	O
mosquitoes	O
captured	O
after	O
the	O
first	O
week	O
you	O
count	O
mosquitoes	O
after	O
the	O
second	O
week	O
you	O
count	O
mosquitoes	O
estimate	O
the	O
percentage	O
change	O
in	O
the	O
number	O
of	O
mosquitoes	O
in	O
your	O
yard	O
to	O
answer	O
this	O
question	O
you	O
have	O
to	O
make	O
some	O
modeling	B
decisions	O
here	O
are	O
some	O
suggestions	O
suppose	O
that	O
each	O
week	O
a	O
large	O
number	O
of	O
mosquitoes	O
n	O
is	O
bred	O
in	O
a	O
wetland	O
near	O
your	O
home	O
during	O
the	O
week	O
some	O
fraction	O
of	O
them	O
wander	O
into	O
your	O
yard	O
and	O
of	O
those	O
some	O
fraction	O
are	O
caught	O
in	O
the	O
trap	O
your	O
solution	O
should	O
take	O
into	O
account	O
your	O
prior	B
belief	O
about	O
how	O
much	O
n	O
is	O
likely	O
to	O
change	O
from	O
one	O
week	O
to	O
the	O
next	O
you	O
can	O
do	O
that	O
by	O
adding	O
a	O
level	O
to	O
the	O
hierarchy	O
to	O
model	O
the	O
percent	O
change	O
in	O
n	O
chapter	O
a	O
hierarchical	B
model	I
chapter	O
dealing	O
with	O
dimensions	O
belly	B
button	I
bacteria	B
belly	B
button	I
biodiversity	B
is	O
a	O
nation-wide	O
citizen	O
science	O
project	O
with	O
the	O
goal	O
of	O
identifying	O
bacterial	O
species	B
that	O
can	O
be	O
found	O
in	O
human	O
navels	O
the	O
project	O
might	O
seem	O
whimsical	O
but	O
it	O
is	O
part	O
of	O
an	O
increasing	O
interest	O
in	O
the	O
human	O
microbiome	B
the	O
set	O
of	O
microorganisms	O
that	O
live	O
on	O
human	O
skin	O
and	O
parts	O
of	O
the	O
body	O
in	O
their	O
pilot	O
study	O
researchers	O
collected	O
swabs	O
from	O
the	O
navels	O
of	O
volunteers	O
used	O
multiplex	O
pyrosequencing	B
to	O
extract	O
and	O
sequence	O
fragments	O
of	O
rdna	B
then	O
identified	O
the	O
species	B
or	O
genus	O
the	O
fragments	O
came	O
from	O
each	O
identified	O
fragment	O
is	O
called	O
a	O
read	O
we	O
can	O
use	O
these	O
data	O
to	O
answer	O
several	O
related	O
questions	O
based	O
on	O
the	O
number	O
of	O
species	B
observed	O
can	O
we	O
estimate	O
the	O
total	O
number	O
of	O
species	B
in	O
the	O
environment	O
can	O
we	O
estimate	O
the	O
prevalence	B
of	O
each	O
species	B
that	O
is	O
the	O
fraction	O
of	O
the	O
total	O
population	O
belonging	O
to	O
each	O
species	B
if	O
we	O
are	O
planning	O
to	O
collect	O
additional	O
samples	O
can	O
we	O
predict	O
how	O
many	O
new	O
species	B
we	O
are	O
likely	O
to	O
discover	O
how	O
many	O
additional	O
reads	O
are	O
needed	O
to	O
increase	O
the	O
fraction	O
of	O
ob	O
served	O
species	B
to	O
a	O
given	O
threshold	O
these	O
questions	O
make	O
up	O
what	O
is	O
called	O
the	O
unseen	B
species	B
problem	I
chapter	O
dealing	O
with	O
dimensions	O
lions	B
and	I
tigers	I
and	I
bears	I
i	O
ll	O
start	O
with	O
a	O
simplified	O
version	O
of	O
the	O
problem	O
where	O
we	O
know	O
that	O
there	O
are	O
exactly	O
three	O
species	B
let	O
s	O
call	O
them	O
lions	O
tigers	O
and	O
bears	O
suppose	O
we	O
visit	O
a	O
wild	O
animal	O
preserve	O
and	O
see	O
lions	O
tigers	O
and	O
one	O
bear	O
if	O
we	O
have	O
an	O
equal	O
chance	O
of	O
observing	O
any	O
animal	O
in	O
the	O
preserve	O
the	O
number	O
of	O
each	O
species	B
we	O
see	O
is	O
governed	O
by	O
the	O
multinomial	B
distribution	B
if	O
the	O
prevalence	B
of	O
lions	B
and	I
tigers	I
and	I
bears	I
is	O
p	O
lion	O
and	O
p	O
tiger	O
and	O
p	O
bear	O
the	O
likelihood	B
of	O
seeing	O
lions	O
tigers	O
and	O
one	O
bear	O
is	O
proportional	O
to	O
an	O
approach	O
that	O
is	O
tempting	O
but	O
not	O
correct	O
is	O
to	O
use	O
beta	O
distributions	O
as	O
in	O
section	O
to	O
describe	O
the	O
prevalence	B
of	O
each	O
species	B
separately	O
for	O
example	O
we	O
saw	O
lions	O
and	O
non-lions	O
if	O
we	O
think	O
of	O
that	O
as	O
heads	O
and	O
tails	O
then	O
the	O
posterior	B
distribution	B
of	O
p	O
lion	O
is	O
beta	O
thinkbayes	O
beta	O
print	O
beta	O
maximumlikelihood	O
the	O
maximum	B
likelihood	B
estimate	O
for	O
p	O
lion	O
is	O
the	O
observed	O
rate	O
similarly	O
the	O
mles	O
for	O
p	O
tiger	O
and	O
p	O
bear	O
are	O
and	O
but	O
there	O
are	O
two	O
problems	O
we	O
have	O
implicitly	O
used	O
a	O
prior	B
for	O
each	O
species	B
that	O
is	O
uniform	O
from	O
to	O
but	O
since	O
we	O
know	O
that	O
there	O
are	O
three	O
species	B
that	O
prior	B
is	O
not	O
correct	O
the	O
right	O
prior	B
should	O
have	O
a	O
mean	O
of	O
and	O
there	O
should	O
be	O
zero	O
likelihood	B
that	O
any	O
species	B
has	O
a	O
prevalence	B
of	O
the	O
distributions	O
for	O
each	O
species	B
are	O
not	O
independent	O
because	O
the	O
prevalences	O
have	O
to	O
add	O
up	O
to	O
to	O
capture	O
this	O
dependence	B
we	O
need	O
a	O
joint	B
distribution	B
for	O
the	O
three	O
prevalences	O
we	O
can	O
use	O
a	O
dirichlet	B
distribution	B
to	O
solve	O
both	O
of	O
these	O
problems	O
httpen	O
wikipedia	O
orgwikidirichlet	O
distribution	B
in	O
the	O
same	O
way	O
we	O
used	O
the	O
beta	B
distribution	B
to	O
describe	O
the	O
distribution	B
of	O
bias	O
for	O
a	O
coin	O
we	O
can	O
use	O
a	O
dirichlet	B
distribution	B
to	O
describe	O
the	O
joint	B
distribution	B
of	O
p	O
lion	O
p	O
tiger	O
and	O
p	O
bear	O
the	O
dirichlet	B
distribution	B
is	O
the	O
multi-dimensional	O
generalization	O
of	O
the	O
beta	B
distribution	B
instead	O
of	O
two	O
possible	O
outcomes	O
like	O
heads	O
and	O
tails	O
lions	B
and	I
tigers	I
and	I
bears	I
the	O
dirichlet	B
distribution	B
handles	O
any	O
number	O
of	O
outcomes	O
in	O
this	O
example	O
three	O
species	B
if	O
there	O
are	O
n	O
outcomes	O
the	O
dirichlet	B
distribution	B
is	O
described	O
by	O
n	O
parameters	O
written	O
through	O
n	O
here	O
s	O
the	O
definition	O
from	O
thinkbayes	O
py	O
of	O
a	O
class	O
that	O
represents	O
a	O
dirichlet	B
distribution	B
class	O
dirichletobject	O
def	O
n	O
self	O
n	O
n	O
self	O
params	O
numpy	B
onesn	O
dtypenumpy	O
int	O
n	O
is	O
the	O
number	O
of	O
dimensions	O
initially	O
the	O
parameters	O
are	O
all	O
i	O
use	O
a	O
numpy	B
array	O
to	O
store	O
the	O
parameters	O
so	O
i	O
can	O
take	O
advantage	O
of	O
array	O
operations	B
given	O
a	O
dirichlet	B
distribution	B
the	O
marginal	B
distribution	B
for	O
each	O
prevalence	B
is	O
a	O
beta	B
distribution	B
which	O
we	O
can	O
compute	O
like	O
this	O
def	O
marginalbetaself	O
i	O
self	O
params	O
sum	O
alpha	O
self	O
paramsi	O
return	O
betaalpha	O
i	O
is	O
the	O
index	O
of	O
the	O
marginal	B
distribution	B
we	O
want	O
is	O
the	O
sum	O
of	O
the	O
parameters	O
alpha	O
is	O
the	O
parameter	B
for	O
the	O
given	O
species	B
in	O
the	O
example	O
the	O
prior	B
marginal	B
distribution	B
for	O
each	O
species	B
is	O
we	O
can	O
compute	O
the	O
prior	B
means	O
like	O
this	O
dirichlet	O
for	O
i	O
in	O
beta	O
dirichlet	O
marginalbetai	O
print	O
beta	O
mean	O
as	O
expected	O
the	O
prior	B
mean	O
prevalence	B
for	O
each	O
species	B
is	O
to	O
update	B
the	O
dirichlet	B
distribution	B
we	O
add	O
the	O
observations	O
to	O
the	O
parameters	O
like	O
this	O
def	O
updateself	O
data	O
m	O
lendata	O
self	O
paramsm	O
data	O
here	O
data	O
is	O
a	O
sequence	O
of	O
counts	O
in	O
the	O
same	O
order	O
as	O
params	O
so	O
in	O
this	O
example	O
it	O
should	O
be	O
the	O
number	O
of	O
lions	O
tigers	O
and	O
bears	O
chapter	O
dealing	O
with	O
dimensions	O
figure	O
distribution	B
of	O
prevalences	O
for	O
three	O
species	B
data	O
can	O
be	O
shorter	O
than	O
params	O
in	O
that	O
case	O
there	O
are	O
some	O
species	B
that	O
have	O
not	O
been	O
observed	O
here	O
s	O
code	O
that	O
updates	O
dirichlet	O
with	O
the	O
observed	O
data	O
and	O
computes	O
the	O
posterior	B
marginal	O
distributions	O
data	O
dirichlet	O
updatedata	O
for	O
i	O
in	O
beta	O
dirichlet	O
marginalbetai	O
pmf	B
beta	O
makepmf	O
print	O
i	O
pmf	B
mean	O
figure	O
shows	O
the	O
results	O
the	O
posterior	B
mean	O
prevalences	O
are	O
and	O
the	O
hierarchical	O
version	O
we	O
have	O
solved	O
a	O
simplified	O
version	O
of	O
the	O
problem	O
if	O
we	O
know	O
how	O
many	O
species	B
there	O
are	O
we	O
can	O
estimate	O
the	O
prevalence	B
of	O
each	O
now	O
let	O
s	O
get	O
back	O
to	O
the	O
original	O
problem	O
estimating	O
the	O
total	O
number	O
of	O
species	B
to	O
solve	O
this	O
problem	O
i	O
ll	O
define	O
a	O
meta-suite	B
which	O
is	O
a	O
suite	B
that	O
contains	O
other	O
suites	O
as	O
hypotheses	O
in	O
this	O
case	O
the	O
top-level	O
suite	B
contains	O
hypotheses	O
about	O
the	O
number	O
of	O
species	B
the	O
bottom	O
level	O
contains	O
hypotheses	O
about	O
prevalences	O
the	O
hierarchical	O
version	O
here	O
s	O
the	O
class	O
definition	O
class	O
speciesthinkbayes	O
suite	B
def	O
ns	O
hypos	O
for	O
n	O
in	O
ns	O
thinkbayes	O
suite	B
init	O
self	O
hypos	O
takes	O
a	O
list	O
of	O
possible	O
values	O
for	O
n	O
and	O
makes	O
a	O
list	O
of	O
dirichlet	O
objects	O
here	O
s	O
the	O
code	O
that	O
creates	O
the	O
top-level	O
suite	B
ns	O
suite	B
speciesns	O
ns	O
is	O
the	O
list	O
of	O
possible	O
values	O
for	O
n	O
we	O
have	O
seen	O
species	B
so	O
there	O
have	O
to	O
be	O
at	O
least	O
that	O
many	O
i	O
chose	O
an	O
upper	O
bound	O
that	O
seems	O
reasonable	O
but	O
we	O
will	O
check	O
later	O
that	O
the	O
probability	B
of	O
exceeding	O
this	O
bound	O
is	O
low	O
and	O
at	O
least	O
initially	O
we	O
assume	O
that	O
any	O
value	O
in	O
this	O
range	O
is	O
equally	O
likely	O
to	O
update	B
a	O
hierarchical	B
model	I
you	O
have	O
to	O
update	B
all	O
levels	O
usually	O
you	O
have	O
to	O
update	B
the	O
bottom	O
level	O
first	O
and	O
work	O
up	O
but	O
in	O
this	O
case	O
we	O
can	O
update	B
the	O
top	O
level	O
first	O
species	B
def	O
updateself	O
data	O
thinkbayes	O
suite	B
updateself	O
data	O
for	O
hypo	O
in	O
self	O
values	O
hypo	O
updatedata	O
species	B
update	B
invokes	O
update	B
in	O
the	O
parent	O
class	O
then	O
loops	O
through	O
the	O
sub-hypotheses	O
and	O
updates	O
them	O
now	O
all	O
we	O
need	O
is	O
a	O
likelihood	B
function	I
class	O
species	B
def	O
likelihoodself	O
data	O
hypo	O
dirichlet	O
hypo	O
like	O
for	O
i	O
in	O
like	O
dirichlet	O
likelihooddata	O
return	O
like	O
chapter	O
dealing	O
with	O
dimensions	O
data	O
is	O
a	O
sequence	O
of	O
observed	O
counts	O
hypo	O
is	O
a	O
dirichlet	O
object	O
species	B
likelihood	B
calls	O
dirichlet	O
likelihood	B
times	O
and	O
returns	O
the	O
total	O
why	O
call	O
it	O
times	O
because	O
dirichlet	O
likelihood	B
doesn	O
t	O
actually	O
compute	O
the	O
likelihood	B
of	O
the	O
data	O
under	O
the	O
whole	O
dirichlet	B
distribution	B
instead	O
it	O
draws	O
one	O
sample	O
from	O
the	O
hypothetical	O
distribution	B
and	O
computes	O
the	O
likelihood	B
of	O
the	O
data	O
under	O
the	O
sampled	O
set	O
of	O
prevalences	O
here	O
s	O
what	O
it	O
looks	O
like	O
class	O
dirichlet	O
def	O
likelihoodself	O
data	O
m	O
lendata	O
if	O
self	O
n	O
m	O
return	O
x	O
data	O
p	O
self	O
random	O
q	O
pmx	O
return	O
q	O
prod	O
the	O
length	O
of	O
data	O
is	O
the	O
number	O
of	O
species	B
observed	O
if	O
we	O
see	O
more	O
species	B
than	O
we	O
thought	O
existed	O
the	O
likelihood	B
is	O
otherwise	O
we	O
select	O
a	O
random	O
set	O
of	O
prevalences	O
p	O
and	O
compute	O
the	O
multinomial	O
pmf	B
which	O
is	O
cx	O
pxn	O
n	O
pi	O
is	O
the	O
prevalence	B
of	O
the	O
ith	O
species	B
and	O
xi	O
is	O
the	O
observed	O
number	O
the	O
first	O
term	O
cx	O
is	O
the	O
multinomial	B
coefficient	I
i	O
leave	O
it	O
out	O
of	O
the	O
computation	O
because	O
it	O
is	O
a	O
multiplicative	O
factor	O
that	O
depends	O
only	O
on	O
the	O
data	O
not	O
the	O
hypothesis	O
so	O
it	O
gets	O
normalized	O
away	O
httpen	O
wikipedia	O
org	O
wikimultinomial	O
distribution	B
m	O
is	O
the	O
number	O
of	O
observed	O
species	B
we	O
only	O
need	O
the	O
first	O
m	O
elements	O
of	O
p	O
for	O
the	O
others	O
xi	O
is	O
so	O
pxi	O
is	O
and	O
we	O
can	O
leave	O
them	O
out	O
of	O
the	O
product	O
i	O
random	O
sampling	O
there	O
are	O
two	O
ways	O
to	O
generate	O
a	O
random	B
sample	I
from	O
a	O
dirichlet	B
distribution	B
one	O
is	O
to	O
use	O
the	O
marginal	O
beta	O
distributions	O
but	O
in	O
that	O
case	O
you	O
have	O
to	O
select	O
one	O
at	O
a	O
time	O
and	O
scale	O
the	O
rest	O
so	O
they	O
add	O
up	O
to	O
random	O
sampling	O
figure	O
posterior	B
distribution	B
of	O
n	O
httpen	O
wikipedia	O
orgwikidirichlet	O
distributionrandom	O
number	O
generation	O
a	O
less	O
obvious	O
but	O
faster	O
way	O
is	O
to	O
select	O
values	O
from	O
n	O
gamma	O
distributions	O
then	O
normalize	B
by	O
dividing	O
through	O
by	O
the	O
total	O
here	O
s	O
the	O
code	O
class	O
dirichlet	O
def	O
randomself	O
p	O
numpy	B
random	O
gammaself	O
params	O
return	O
p	O
p	O
sum	O
now	O
we	O
re	O
ready	O
to	O
look	O
at	O
some	O
results	O
here	O
is	O
the	O
code	O
that	O
extracts	O
the	O
posterior	B
distribution	B
of	O
n	O
def	O
distofnself	O
pmf	B
thinkbayes	O
pmf	B
for	O
hypo	O
prob	B
in	O
self	O
items	O
pmf	B
sethypo	O
n	O
prob	B
return	O
pmf	B
distofn	O
iterates	O
through	O
the	O
top-level	O
hypotheses	O
and	O
accumulates	O
the	O
probability	B
of	O
each	O
n	O
figure	O
shows	O
the	O
result	O
the	O
most	O
likely	O
value	O
is	O
values	O
from	O
to	O
are	O
reasonably	O
likely	O
after	O
that	O
the	O
probabilities	O
drop	O
off	O
quickly	O
the	O
probability	B
that	O
there	O
are	O
species	B
is	O
low	O
enough	O
to	O
be	O
negligible	O
if	O
we	O
chose	O
a	O
higher	O
bound	O
we	O
would	O
get	O
nearly	O
the	O
same	O
result	O
of	O
chapter	O
dealing	O
with	O
dimensions	O
remember	O
that	O
this	O
result	O
is	O
based	O
on	O
a	O
uniform	O
prior	B
for	O
n	O
if	O
we	O
have	O
background	O
information	O
about	O
the	O
number	O
of	O
species	B
in	O
the	O
environment	O
we	O
might	O
choose	O
a	O
different	O
prior	B
optimization	B
i	O
have	O
to	O
admit	O
that	O
i	O
am	O
proud	O
of	O
this	O
example	O
the	O
unseen	B
species	B
problem	I
is	O
not	O
easy	O
and	O
i	O
think	O
this	O
solution	O
is	O
simple	O
and	O
clear	O
and	O
takes	O
surprisingly	O
few	O
lines	O
of	O
code	O
so	O
far	O
the	O
only	O
problem	O
is	O
that	O
it	O
is	O
slow	O
it	O
s	O
good	O
enough	O
for	O
the	O
example	O
with	O
only	O
observed	O
species	B
but	O
not	O
good	O
enough	O
for	O
the	O
belly	B
button	I
data	O
with	O
more	O
than	O
species	B
in	O
some	O
samples	O
the	O
next	O
few	O
sections	O
present	O
a	O
series	O
of	O
optimizations	O
we	O
need	O
to	O
make	O
this	O
solution	O
scale	O
before	O
we	O
get	O
into	O
the	O
details	O
here	O
s	O
a	O
road	O
map	O
the	O
first	O
step	O
is	O
to	O
recognize	O
that	O
if	O
we	O
update	B
the	O
dirichlet	O
distributions	O
with	O
the	O
same	O
data	O
the	O
first	O
m	O
parameters	O
are	O
the	O
same	O
for	O
all	O
of	O
them	O
the	O
only	O
difference	O
is	O
the	O
number	O
of	O
hypothetical	O
unseen	O
species	B
so	O
we	O
don	O
t	O
really	O
need	O
n	O
dirichlet	O
objects	O
we	O
can	O
store	O
the	O
parameters	O
in	O
the	O
top	O
level	O
of	O
the	O
hierarchy	O
implements	O
this	O
optimization	B
also	O
uses	O
the	O
same	O
set	O
of	O
random	O
values	O
for	O
all	O
of	O
the	O
hypotheses	O
this	O
saves	O
time	O
generating	O
random	O
values	O
but	O
it	O
has	O
a	O
second	O
benefit	O
that	O
turns	O
out	O
to	O
be	O
more	O
important	O
by	O
giving	O
all	O
hypotheses	O
the	O
same	O
selection	O
from	O
the	O
sample	O
space	O
we	O
make	O
the	O
comparison	O
between	O
the	O
hypotheses	O
more	O
fair	O
so	O
it	O
takes	O
fewer	O
iterations	O
to	O
converge	O
even	O
with	O
these	O
changes	O
there	O
is	O
a	O
major	O
performance	O
problem	O
as	O
the	O
number	O
of	O
observed	O
species	B
increases	O
the	O
array	O
of	O
random	O
prevalences	O
gets	O
bigger	O
and	O
the	O
chance	O
of	O
choosing	O
one	O
that	O
is	O
approximately	O
right	O
becomes	O
small	O
so	O
the	O
vast	O
majority	O
of	O
iterations	O
yield	O
small	O
likelihoods	O
that	O
don	O
t	O
contribute	O
much	O
to	O
the	O
total	O
and	O
don	O
t	O
discriminate	O
between	O
hypotheses	O
the	O
solution	O
is	O
to	O
do	O
the	O
updates	O
one	O
species	B
at	O
a	O
time	O
is	O
a	O
simple	O
implementation	B
of	O
this	O
strategy	O
using	O
dirichlet	O
objects	O
to	O
represent	O
the	O
sub-hypotheses	O
collapsing	O
the	O
hierarchy	O
finally	O
combines	O
the	O
sub-hypotheses	O
into	O
the	O
top	O
level	O
and	O
uses	O
numpy	B
array	O
operations	B
to	O
speed	O
things	O
up	O
if	O
you	O
are	O
not	O
interested	O
in	O
the	O
details	O
feel	O
free	O
to	O
skip	O
to	O
section	O
where	O
we	O
look	O
at	O
results	O
from	O
the	O
belly	B
button	I
data	O
collapsing	O
the	O
hierarchy	O
all	O
of	O
the	O
bottom-level	O
dirichlet	O
distributions	O
are	O
updated	O
with	O
the	O
same	O
data	O
so	O
the	O
first	O
m	O
parameters	O
are	O
the	O
same	O
for	O
all	O
of	O
them	O
we	O
can	O
eliminate	O
them	O
and	O
merge	O
the	O
parameters	O
into	O
the	O
top-level	O
suite	B
implements	O
this	O
optimization	B
class	O
def	O
ns	O
self	O
ns	O
ns	O
self	O
probs	O
numpy	B
oneslenns	O
dtypenumpy	O
double	O
self	O
params	O
numpy	B
onesself	O
high	O
dtypenumpy	O
int	O
ns	O
is	O
the	O
list	O
of	O
hypothetical	O
values	O
for	O
n	O
probs	O
is	O
the	O
list	O
of	O
corresponding	O
probabilities	O
and	O
params	O
is	O
the	O
sequence	O
of	O
dirichlet	O
parameters	O
initially	O
all	O
updates	O
both	O
levels	O
of	O
the	O
hierarchy	O
first	O
the	O
probability	B
for	O
each	O
value	O
of	O
n	O
then	O
the	O
dirichlet	O
parameters	O
class	O
def	O
updateself	O
data	O
like	O
numpy	B
zeroslenself	O
ns	O
dtypenumpy	O
double	O
for	O
i	O
in	O
like	O
self	O
samplelikelihooddata	O
self	O
probs	O
like	O
self	O
probs	O
self	O
probs	O
sum	O
m	O
lendata	O
self	O
paramsm	O
data	O
samplelikelihood	O
returns	O
an	O
array	O
of	O
likelihoods	O
one	O
for	O
each	O
value	O
of	O
n	O
like	O
accumulates	O
the	O
total	O
likelihood	B
for	O
samples	O
self	O
probs	O
is	O
multiplied	O
by	O
the	O
total	O
likelihood	B
then	O
normalized	O
the	O
last	O
two	O
lines	O
which	O
update	B
the	O
parameters	O
are	O
the	O
same	O
as	O
in	O
dirichlet	O
update	B
chapter	O
dealing	O
with	O
dimensions	O
now	O
let	O
s	O
look	O
at	O
samplelikelihood	O
there	O
are	O
two	O
opportunities	O
for	O
optimization	B
here	O
when	O
the	O
hypothetical	O
number	O
of	O
species	B
n	O
exceeds	O
the	O
observed	O
number	O
m	O
we	O
only	O
need	O
the	O
first	O
m	O
terms	O
of	O
the	O
multinomial	O
pmf	B
the	O
rest	O
are	O
if	O
the	O
number	O
of	O
species	B
is	O
large	O
the	O
likelihood	B
of	O
the	O
data	O
might	O
be	O
too	O
small	O
for	O
floating-point	O
so	O
it	O
is	O
safer	O
to	O
compute	O
loglikelihoods	O
again	O
the	O
multinomial	O
pmf	B
is	O
cx	O
pxn	O
n	O
so	O
the	O
log-likelihood	B
is	O
log	O
cx	O
log	O
xn	O
log	O
pn	O
which	O
is	O
fast	O
and	O
easy	O
to	O
compute	O
again	O
cx	O
it	O
is	O
the	O
same	O
for	O
all	O
hypotheses	O
so	O
we	O
can	O
drop	O
it	O
here	O
s	O
the	O
code	O
class	O
def	O
samplelikelihoodself	O
data	O
gammas	O
numpy	B
random	O
gammaself	O
params	O
m	O
lendata	O
row	O
gammasm	O
col	O
numpy	B
cumsumgammas	O
log	O
likes	O
for	O
n	O
in	O
self	O
ns	O
ps	O
row	O
terms	O
data	O
numpy	B
logps	O
log	O
like	O
terms	O
sum	O
log	O
likes	O
appendlog	O
like	O
log	O
likes	O
numpy	B
maxlog	O
likes	O
likes	O
numpy	B
explog	O
likes	O
coefs	O
m	O
for	O
n	O
in	O
self	O
ns	O
likes	O
coefs	O
one	O
more	O
problem	O
return	O
likes	O
gammas	O
is	O
an	O
array	O
of	O
values	O
from	O
a	O
gamma	B
distribution	B
its	O
length	O
is	O
the	O
largest	O
hypothetical	O
value	O
of	O
n	O
row	O
is	O
just	O
the	O
first	O
m	O
elements	O
of	O
gammas	O
since	O
these	O
are	O
the	O
only	O
elements	O
that	O
depend	O
on	O
the	O
data	O
they	O
are	O
the	O
only	O
ones	O
we	O
need	O
for	O
each	O
value	O
of	O
n	O
we	O
need	O
to	O
divide	O
row	O
by	O
the	O
total	O
of	O
the	O
first	O
n	O
values	O
from	O
gamma	O
cumsum	O
computes	O
these	O
cumulative	O
sums	O
and	O
stores	O
them	O
in	O
col	O
the	O
loop	O
iterates	O
through	O
the	O
values	O
of	O
n	O
and	O
accumulates	O
a	O
list	O
of	O
loglikelihoods	O
inside	O
the	O
loop	O
ps	O
contains	O
the	O
row	O
of	O
probabilities	O
normalized	O
with	O
the	O
appropriate	O
cumulative	B
sum	I
terms	O
contains	O
the	O
terms	O
of	O
the	O
summation	O
xi	O
log	O
pi	O
and	O
log	O
like	O
contains	O
their	O
sum	O
after	O
the	O
loop	O
we	O
want	O
to	O
convert	O
the	O
log-likelihoods	O
to	O
linear	O
likelihoods	O
but	O
first	O
it	O
s	O
a	O
good	O
idea	O
to	O
shift	O
them	O
so	O
the	O
largest	O
log-likelihood	B
is	O
that	O
way	O
the	O
linear	O
likelihoods	O
are	O
not	O
too	O
small	O
finally	O
before	O
we	O
return	O
the	O
likelihood	B
we	O
have	O
to	O
apply	O
a	O
correction	O
factor	O
which	O
is	O
the	O
number	O
of	O
ways	O
we	O
could	O
have	O
observed	O
these	O
m	O
species	B
if	O
the	O
total	O
number	O
of	O
species	B
is	O
n	O
binomialcoefficient	O
computes	O
n	O
choose	O
m	O
which	O
is	O
written	O
n	O
m	O
as	O
often	O
happens	O
the	O
optimized	O
version	O
is	O
less	O
readable	O
and	O
more	O
errorprone	O
than	O
the	O
original	O
but	O
that	O
s	O
one	O
reason	O
i	O
think	O
it	O
is	O
a	O
good	O
idea	O
to	O
start	O
with	O
the	O
simple	O
version	O
we	O
can	O
use	O
it	O
for	O
regression	B
testing	I
i	O
plotted	O
results	O
from	O
both	O
versions	O
and	O
confirmed	O
that	O
they	O
are	O
approximately	O
equal	O
and	O
that	O
they	O
converge	O
as	O
the	O
number	O
of	O
iterations	O
increases	O
one	O
more	O
problem	O
there	O
s	O
more	O
we	O
could	O
do	O
to	O
optimize	O
this	O
code	O
but	O
there	O
s	O
another	O
problem	O
we	O
need	O
to	O
fix	O
first	O
as	O
the	O
number	O
of	O
observed	O
species	B
increases	O
this	O
version	O
gets	O
noisier	O
and	O
takes	O
more	O
iterations	O
to	O
converge	O
on	O
a	O
good	O
answer	O
the	O
problem	O
is	O
that	O
if	O
the	O
prevalences	O
we	O
choose	O
from	O
the	O
dirichlet	B
distribution	B
the	O
ps	O
are	O
not	O
at	O
least	O
approximately	O
right	O
the	O
likelihood	B
of	O
the	O
observed	O
data	O
is	O
close	O
to	O
zero	O
and	O
almost	O
equally	O
bad	O
for	O
all	O
values	O
of	O
n	O
chapter	O
dealing	O
with	O
dimensions	O
so	O
most	O
iterations	O
don	O
t	O
provide	O
any	O
useful	O
contribution	O
to	O
the	O
total	O
likelihood	B
and	O
as	O
the	O
number	O
of	O
observed	O
species	B
m	O
gets	O
large	O
the	O
probability	B
of	O
choosing	O
ps	O
with	O
non-negligible	O
likelihood	B
gets	O
small	O
really	O
small	O
fortunately	O
there	O
is	O
a	O
solution	O
remember	O
that	O
if	O
you	O
observe	O
a	O
set	O
of	O
data	O
you	O
can	O
update	B
the	O
prior	B
distribution	B
with	O
the	O
entire	O
dataset	O
or	O
you	O
can	O
break	O
it	O
up	O
into	O
a	O
series	O
of	O
updates	O
with	O
subsets	O
of	O
the	O
data	O
and	O
the	O
result	O
is	O
the	O
same	O
either	O
way	O
for	O
this	O
example	O
the	O
key	O
is	O
to	O
perform	O
the	O
updates	O
one	O
species	B
at	O
a	O
time	O
that	O
way	O
when	O
we	O
generate	O
a	O
random	O
set	O
of	O
ps	O
only	O
one	O
of	O
them	O
affects	O
the	O
computed	O
likelihood	B
so	O
the	O
chance	O
of	O
choosing	O
a	O
good	O
one	O
is	O
much	O
better	O
here	O
s	O
a	O
new	O
version	O
that	O
updates	O
one	O
species	B
at	O
a	O
time	O
class	O
def	O
updateself	O
data	O
m	O
lendata	O
for	O
i	O
in	O
rangem	O
one	O
onei	O
datai	O
species	B
updateself	O
one	O
this	O
version	O
inherits	O
from	O
species	B
so	O
it	O
represents	O
the	O
hypotheses	O
as	O
a	O
list	O
of	O
dirichlet	O
objects	O
update	B
loops	O
through	O
the	O
observed	O
species	B
and	O
makes	O
an	O
array	O
one	O
with	O
all	O
zeros	O
and	O
one	O
species	B
count	O
then	O
it	O
calls	O
update	B
in	O
the	O
parent	O
class	O
which	O
computes	O
the	O
likelihoods	O
and	O
updates	O
the	O
sub-hypotheses	O
so	O
in	O
the	O
running	O
example	O
we	O
do	O
three	O
updates	O
the	O
first	O
is	O
something	O
like	O
i	O
have	O
seen	O
three	O
lions	O
the	O
second	O
is	O
i	O
have	O
seen	O
two	O
tigers	O
and	O
no	O
additional	O
lions	O
and	O
the	O
third	O
is	O
i	O
have	O
seen	O
one	O
bear	O
and	O
no	O
more	O
lions	O
and	O
tigers	O
here	O
s	O
the	O
new	O
version	O
of	O
likelihood	B
class	O
def	O
likelihoodself	O
data	O
hypo	O
dirichlet	O
hypo	O
like	O
for	O
i	O
in	O
rangeself	O
iterations	O
we	O
re	O
not	O
done	O
yet	O
like	O
dirichlet	O
likelihooddata	O
correct	O
for	O
the	O
number	O
of	O
unseen	O
species	B
the	O
new	O
one	O
could	O
have	O
been	O
m	O
lendata	O
num	O
unseen	O
dirichlet	O
n	O
m	O
like	O
num	O
unseen	O
return	O
like	O
this	O
is	O
almost	O
the	O
same	O
as	O
species	B
likelihood	B
the	O
difference	O
is	O
the	O
factor	O
num	O
unseen	O
this	O
correction	O
is	O
necessary	O
because	O
each	O
time	O
we	O
see	O
a	O
species	B
for	O
the	O
first	O
time	O
we	O
have	O
to	O
consider	O
that	O
there	O
were	O
some	O
number	O
of	O
other	O
unseen	O
species	B
that	O
we	O
might	O
have	O
seen	O
for	O
larger	O
values	O
of	O
n	O
there	O
are	O
more	O
unseen	O
species	B
that	O
we	O
could	O
have	O
seen	O
which	O
increases	O
the	O
likelihood	B
of	O
the	O
data	O
this	O
is	O
a	O
subtle	O
point	O
and	O
i	O
have	O
to	O
admit	O
that	O
i	O
did	O
not	O
get	O
it	O
right	O
the	O
first	O
time	O
but	O
again	O
i	O
was	O
able	O
to	O
validate	O
this	O
version	O
by	O
comparing	O
it	O
to	O
the	O
previous	O
versions	O
we	O
re	O
not	O
done	O
yet	O
performing	O
the	O
updates	O
one	O
species	B
at	O
a	O
time	O
solves	O
one	O
problem	O
but	O
it	O
creates	O
another	O
each	O
update	B
takes	O
time	O
proportional	O
to	O
km	O
where	O
k	O
is	O
the	O
number	O
of	O
hypotheses	O
and	O
m	O
is	O
the	O
number	O
of	O
observed	O
species	B
so	O
if	O
we	O
do	O
m	O
updates	O
the	O
total	O
run	O
time	O
is	O
proportional	O
to	O
but	O
we	O
can	O
speed	O
things	O
up	O
using	O
the	O
same	O
trick	O
we	O
used	O
in	O
section	O
we	O
ll	O
get	O
rid	O
of	O
the	O
dirichlet	O
objects	O
and	O
collapse	O
the	O
two	O
levels	O
of	O
the	O
hierarchy	O
into	O
a	O
single	O
object	O
so	O
here	O
s	O
yet	O
another	O
version	O
of	O
species	B
class	O
def	O
updateself	O
data	O
m	O
lendata	O
for	O
i	O
in	O
rangem	O
datai	O
self	O
paramsi	O
datai	O
this	O
version	O
inherits	O
from	O
so	O
it	O
uses	O
ns	O
and	O
probs	O
to	O
represent	O
the	O
distribution	B
of	O
n	O
and	O
params	O
to	O
represent	O
the	O
parameters	O
of	O
the	O
dirichlet	B
distribution	B
chapter	O
dealing	O
with	O
dimensions	O
update	B
is	O
similar	O
to	O
what	O
we	O
saw	O
in	O
the	O
previous	O
section	O
it	O
loops	O
through	O
the	O
observed	O
species	B
and	O
calls	O
updateone	O
class	O
def	O
updateoneself	O
i	O
count	O
likes	O
numpy	B
zeroslenself	O
ns	O
dtypenumpy	O
double	O
for	O
i	O
in	O
rangeself	O
iterations	O
likes	O
self	O
samplelikelihoodi	O
count	O
unseen	O
species	B
for	O
n	O
in	O
self	O
ns	O
likes	O
unseen	O
species	B
self	O
probs	O
likes	O
self	O
probs	O
self	O
probs	O
sum	O
this	O
function	O
is	O
similar	O
to	O
with	O
two	O
changes	O
the	O
interface	B
is	O
different	O
instead	O
of	O
the	O
whole	O
dataset	O
we	O
get	O
i	O
the	O
index	O
of	O
the	O
observed	O
species	B
and	O
count	O
how	O
many	O
of	O
that	O
species	B
we	O
ve	O
seen	O
we	O
have	O
to	O
apply	O
a	O
correction	O
factor	O
for	O
the	O
number	O
of	O
unseen	O
species	B
as	O
in	O
the	O
difference	O
here	O
is	O
that	O
we	O
update	B
all	O
of	O
the	O
likelihoods	O
at	O
once	O
with	O
array	O
multiplication	O
finally	O
here	O
s	O
samplelikelihood	O
class	O
def	O
samplelikelihoodself	O
i	O
count	O
gammas	O
numpy	B
random	O
gammaself	O
params	O
sums	O
ps	O
sums	O
log	O
likes	O
numpy	B
logps	O
count	O
log	O
likes	O
numpy	B
maxlog	O
likes	O
likes	O
numpy	B
explog	O
likes	O
return	O
likes	O
this	O
is	O
similar	O
to	O
the	O
difference	O
is	O
that	O
each	O
update	B
only	O
includes	O
a	O
single	O
species	B
so	O
we	O
don	O
t	O
need	O
a	O
loop	O
the	O
belly	B
button	I
data	O
the	O
runtime	O
of	O
this	O
function	O
is	O
proportional	O
to	O
the	O
number	O
of	O
hypotheses	O
k	O
it	O
runs	O
m	O
times	O
so	O
the	O
run	O
time	O
of	O
the	O
update	B
is	O
proportional	O
to	O
km	O
and	O
the	O
number	O
of	O
iterations	O
we	O
need	O
to	O
get	O
an	O
accurate	O
result	O
is	O
usually	O
small	O
the	O
belly	B
button	I
data	O
that	O
s	O
enough	O
about	O
lions	B
and	I
tigers	I
and	I
bears	I
let	O
s	O
get	O
back	O
to	O
belly	O
buttons	O
to	O
get	O
a	O
sense	O
of	O
what	O
the	O
data	O
look	O
like	O
consider	O
subject	O
whose	O
sample	O
of	O
reads	O
yielded	O
species	B
with	O
the	O
following	O
counts	O
there	O
are	O
a	O
few	O
dominant	O
species	B
that	O
make	O
up	O
a	O
large	O
fraction	O
of	O
the	O
whole	O
but	O
many	O
species	B
that	O
yielded	O
only	O
a	O
single	O
read	O
the	O
number	O
of	O
these	O
singletons	O
suggests	O
that	O
there	O
are	O
likely	O
to	O
be	O
at	O
least	O
a	O
few	O
unseen	O
species	B
in	O
the	O
example	O
with	O
lions	O
and	O
tigers	O
we	O
assume	O
that	O
each	O
animal	O
in	O
the	O
preserve	O
is	O
equally	O
likely	O
to	O
be	O
observed	O
similarly	O
for	O
the	O
belly	B
button	I
data	O
we	O
assume	O
that	O
each	O
bacterium	O
is	O
equally	O
likely	O
to	O
yield	O
a	O
read	O
in	O
reality	O
each	O
step	O
in	O
the	O
data-collection	O
process	B
might	O
introduce	O
biases	O
some	O
species	B
might	O
be	O
more	O
likely	O
to	O
be	O
picked	O
up	O
by	O
a	O
swab	O
or	O
to	O
yield	O
identifiable	O
amplicons	O
so	O
when	O
we	O
talk	O
about	O
the	O
prevalence	B
of	O
each	O
species	B
we	O
should	O
remember	O
this	O
source	O
of	O
error	B
i	O
should	O
also	O
acknowledge	O
that	O
i	O
am	O
using	O
the	O
term	O
species	B
loosely	O
first	O
bacterial	O
species	B
are	O
not	O
well	O
defined	O
second	O
some	O
reads	O
identify	O
a	O
particular	O
species	B
others	O
only	O
identify	O
a	O
genus	O
to	O
be	O
more	O
precise	O
i	O
should	O
say	O
operational	B
taxonomic	I
unit	I
or	O
otu	B
now	O
let	O
s	O
process	B
some	O
of	O
the	O
belly	B
button	I
data	O
subject	O
to	O
represent	O
information	O
about	O
each	O
subject	O
in	O
the	O
study	O
class	O
subjectobject	O
i	O
define	O
a	O
class	O
called	O
def	O
code	O
self	O
code	O
code	O
self	O
species	B
each	O
subject	O
has	O
a	O
string	O
code	O
like	O
and	O
a	O
list	O
of	O
species	B
name	O
pairs	O
sorted	O
in	O
increasing	O
order	O
by	O
count	O
subject	O
provides	O
several	O
chapter	O
dealing	O
with	O
dimensions	O
figure	O
distribution	B
of	O
n	O
for	O
subject	O
methods	O
to	O
make	O
it	O
easy	O
to	O
access	O
these	O
counts	O
and	O
species	B
names	O
you	O
can	O
see	O
the	O
details	O
in	O
httpthinkbayes	O
comspecies	O
py	O
for	O
more	O
information	O
see	O
section	O
subject	O
provides	O
a	O
method	O
named	O
process	B
that	O
creates	O
and	O
updates	O
a	O
suite	B
which	O
represents	O
the	O
distributions	O
of	O
n	O
and	O
the	O
prevalences	O
and	O
provides	O
distofn	O
which	O
returns	O
the	O
posterior	B
distribution	B
of	O
n	O
class	O
def	O
distnself	O
items	O
zipself	O
ns	O
self	O
probs	O
pmf	B
thinkbayes	O
makepmffromitemsitems	O
return	O
pmf	B
figure	O
shows	O
the	O
distribution	B
of	O
n	O
for	O
subject	O
the	O
probability	B
that	O
there	O
are	O
exactly	O
species	B
and	O
no	O
unseen	O
species	B
is	O
nearly	O
zero	O
the	O
most	O
likely	O
value	O
is	O
with	O
credible	B
interval	I
to	O
at	O
the	O
high	O
end	O
it	O
is	O
unlikely	O
that	O
there	O
are	O
as	O
many	O
as	O
species	B
next	O
we	O
compute	O
the	O
posterior	B
distribution	B
of	O
prevalence	B
for	O
each	O
species	B
provides	O
distofprevalence	O
class	O
def	O
distofprevalenceself	O
index	O
metapmf	O
thinkbayes	O
pmf	B
of	O
the	O
belly	B
button	I
data	O
figure	O
distribution	B
of	O
prevalences	O
for	O
subject	O
for	O
n	O
prob	B
in	O
zipself	O
ns	O
self	O
probs	O
beta	O
self	O
marginalbetan	O
index	O
pmf	B
beta	O
makepmf	O
metapmf	O
setpmf	O
prob	B
mix	O
thinkbayes	O
makemixturemetapmf	O
return	O
metapmf	O
mix	O
index	O
indicates	O
which	O
species	B
we	O
want	O
for	O
each	O
n	O
we	O
have	O
a	O
different	O
posterior	B
distribution	B
of	O
prevalence	B
the	O
loop	O
iterates	O
through	O
the	O
possible	O
values	O
of	O
n	O
and	O
their	O
probabilities	O
for	O
each	O
value	O
of	O
n	O
it	O
gets	O
a	O
beta	B
object	I
representing	O
the	O
marginal	B
distribution	B
for	O
the	O
indicated	O
species	B
remember	O
that	O
beta	O
objects	O
contain	O
the	O
parameters	O
alpha	O
and	O
beta	O
they	O
don	O
t	O
have	O
values	O
and	O
probabilities	O
like	O
a	O
pmf	B
but	O
they	O
provide	O
makepmf	O
which	O
generates	O
a	O
discrete	O
approximation	O
to	O
the	O
continuous	O
beta	B
distribution	B
metapmf	O
is	O
a	O
meta-pmf	B
that	O
contains	O
the	O
distributions	O
of	O
prevalence	B
conditioned	O
on	O
n	O
makemixture	B
combines	O
the	O
meta-pmf	B
into	O
mix	O
which	O
combines	O
the	O
conditional	B
distributions	O
into	O
a	O
single	O
distribution	B
of	O
prevalence	B
figure	O
shows	O
results	O
for	O
the	O
five	O
species	B
with	O
the	O
most	O
reads	O
the	O
most	O
prevalent	O
species	B
accounts	O
for	O
of	O
the	O
reads	O
but	O
since	O
there	O
are	O
almost	O
certainly	O
unseen	O
species	B
the	O
most	O
likely	O
estimate	O
for	O
its	O
prevalence	B
is	O
with	O
credible	B
interval	I
between	O
and	O
chapter	O
dealing	O
with	O
dimensions	O
figure	O
simulated	O
rarefaction	O
curves	O
for	O
subject	O
predictive	O
distributions	O
i	O
introduced	O
the	O
hidden	O
species	B
problem	O
in	O
the	O
form	O
of	O
four	O
related	O
questions	O
we	O
have	O
answered	O
the	O
first	O
two	O
by	O
computing	O
the	O
posterior	B
distribution	B
for	O
n	O
and	O
the	O
prevalence	B
of	O
each	O
species	B
the	O
other	O
two	O
questions	O
are	O
if	O
we	O
are	O
planning	O
to	O
collect	O
additional	O
reads	O
can	O
we	O
predict	O
how	O
many	O
new	O
species	B
we	O
are	O
likely	O
to	O
discover	O
how	O
many	O
additional	O
reads	O
are	O
needed	O
to	O
increase	O
the	O
fraction	O
of	O
ob	O
served	O
species	B
to	O
a	O
given	O
threshold	O
to	O
answer	O
predictive	O
questions	O
like	O
this	O
we	O
can	O
use	O
the	O
posterior	B
distributions	O
to	O
simulate	O
possible	O
future	O
events	O
and	O
compute	O
predictive	O
distributions	O
for	O
the	O
number	O
of	O
species	B
and	O
fraction	O
of	O
the	O
total	O
we	O
are	O
likely	O
to	O
see	O
the	O
kernel	O
of	O
these	O
simulations	O
looks	O
like	O
this	O
choose	O
n	O
from	O
its	O
posterior	B
distribution	B
choose	O
a	O
prevalence	B
for	O
each	O
species	B
species	B
using	O
the	O
dirichlet	B
distribution	B
including	O
possible	O
unseen	O
generate	O
a	O
random	O
sequence	O
of	O
future	O
observations	O
species	B
predictive	O
distributions	O
compute	O
the	O
number	O
of	O
new	O
species	B
num	O
new	O
as	O
a	O
function	O
of	O
the	O
number	O
of	O
additional	O
reads	O
k	O
repeat	O
the	O
previous	O
steps	O
and	O
accumulate	O
the	O
joint	B
distribution	B
of	O
num	O
new	O
and	O
k	O
and	O
here	O
s	O
the	O
code	O
runsimulation	O
runs	O
a	O
single	O
simulation	B
class	O
subject	O
def	O
runsimulationself	O
num	O
reads	O
m	O
seen	O
self	O
getseenspecies	O
n	O
observations	O
self	O
generateobservationsnum	O
reads	O
curve	O
for	O
k	O
obs	O
in	O
enumerateobservations	O
seen	O
addobs	O
num	O
new	O
lenseen	O
m	O
num	O
new	O
return	O
curve	O
num	O
reads	O
is	O
the	O
number	O
of	O
additional	O
reads	O
to	O
simulate	O
m	O
is	O
the	O
number	O
of	O
seen	O
species	B
and	O
seen	O
is	O
a	O
set	O
of	O
strings	O
with	O
a	O
unique	O
name	O
for	O
each	O
species	B
n	O
is	O
a	O
random	O
value	O
from	O
the	O
posterior	B
distribution	B
and	O
observations	O
is	O
a	O
random	O
sequence	O
of	O
species	B
names	O
each	O
time	O
through	O
the	O
loop	O
we	O
add	O
the	O
new	O
observation	O
to	O
seen	O
and	O
record	O
the	O
number	O
of	O
reads	O
and	O
the	O
number	O
of	O
new	O
species	B
so	O
far	O
the	O
result	O
of	O
runsimulation	O
is	O
a	O
rarefaction	B
curve	I
represented	O
as	O
a	O
list	O
of	O
pairs	O
with	O
the	O
number	O
of	O
reads	O
and	O
the	O
number	O
of	O
new	O
species	B
the	O
before	O
we	O
generateobservations	O
see	O
subject	O
results	O
let	O
s	O
look	O
at	O
getseenspecies	O
and	O
def	O
getseenspeciesself	O
names	O
self	O
getnames	O
m	O
lennames	O
seen	O
setspeciesgeneratornames	O
m	O
return	O
m	O
seen	O
chapter	O
dealing	O
with	O
dimensions	O
getnames	O
returns	O
the	O
list	O
of	O
species	B
names	O
that	O
appear	O
in	O
the	O
data	O
files	O
but	O
for	O
many	O
subjects	O
these	O
names	O
are	O
not	O
unique	O
so	O
i	O
use	O
speciesgenerator	O
to	O
extend	O
each	O
name	O
with	O
a	O
serial	O
number	O
def	O
speciesgeneratornames	O
num	O
i	O
for	O
name	O
in	O
names	O
yield	O
i	O
i	O
while	O
i	O
num	O
yield	O
i	O
i	O
given	O
a	O
name	O
when	O
the	O
list	O
of	O
names	O
is	O
exhausted	O
names	O
like	O
corynebacterium	O
like	O
speciesgenerator	O
yields	O
it	O
yields	O
here	O
is	O
generateobservations	O
class	O
subject	O
def	O
generateobservationsself	O
num	O
reads	O
n	O
prevalences	O
self	O
suite	B
sampleposterior	O
names	O
self	O
getnames	O
name	O
iter	O
speciesgeneratornames	O
n	O
d	O
dictzipname	O
iter	O
prevalences	O
cdf	B
thinkbayes	O
makecdffromdictd	O
observations	O
cdf	B
samplenum	O
reads	O
return	O
n	O
observations	O
again	O
num	O
reads	O
is	O
the	O
number	O
of	O
additional	O
reads	O
to	O
generate	O
n	O
and	O
prevalences	O
are	O
samples	O
from	O
the	O
posterior	B
distribution	B
cdf	B
is	O
a	O
cdf	B
object	O
that	O
maps	O
species	B
names	O
including	O
the	O
unseen	O
to	O
cumulative	O
probabilities	O
using	O
a	O
cdf	B
makes	O
it	O
efficient	O
to	O
generate	O
a	O
random	O
sequence	O
of	O
species	B
names	O
finally	O
here	O
is	O
def	O
sampleposteriorself	O
pmf	B
self	O
distofn	O
n	O
pmf	B
random	O
joint	B
posterior	B
figure	O
distributions	O
of	O
the	O
number	O
of	O
new	O
species	B
conditioned	O
on	O
the	O
number	O
of	O
additional	O
reads	O
prevalences	O
self	O
sampleprevalencesn	O
return	O
n	O
prevalences	O
and	O
sampleprevalences	O
which	O
generates	O
a	O
sample	O
of	O
prevalences	O
conditioned	O
on	O
n	O
class	O
def	O
sampleprevalencesself	O
n	O
params	O
self	O
paramsn	O
gammas	O
numpy	B
random	O
gammaparams	O
gammas	O
gammas	O
sum	O
return	O
gammas	O
we	O
saw	O
this	O
algorithm	O
for	O
generating	O
random	O
values	O
from	O
a	O
dirichlet	B
distribution	B
in	O
section	O
figure	O
shows	O
simulated	O
rarefaction	O
curves	O
for	O
subject	O
the	O
curves	O
are	O
jittered	O
that	O
is	O
i	O
shifted	O
each	O
curve	O
by	O
a	O
random	O
offset	O
so	O
they	O
would	O
not	O
all	O
overlap	O
by	O
inspection	O
we	O
can	O
estimate	O
that	O
after	O
more	O
reads	O
we	O
are	O
likely	O
to	O
find	O
new	O
species	B
joint	B
posterior	B
we	O
can	O
use	O
these	O
simulations	O
to	O
estimate	O
the	O
joint	B
distribution	B
of	O
num	O
new	O
and	O
k	O
and	O
from	O
that	O
we	O
can	O
get	O
the	O
distribution	B
of	O
num	O
new	O
conditioned	O
on	O
any	O
value	O
of	O
k	O
new	O
chapter	O
dealing	O
with	O
dimensions	O
def	O
makejointpredictivecurves	O
joint	B
thinkbayes	O
joint	B
for	O
curve	O
in	O
curves	O
for	O
k	O
num	O
new	O
in	O
curve	O
joint	B
incrk	O
num	O
new	O
joint	B
normalize	B
return	O
joint	B
makejointpredictive	O
makes	O
a	O
joint	B
object	I
which	O
is	O
a	O
pmf	B
whose	O
values	O
are	O
tuples	O
curves	O
is	O
a	O
list	O
of	O
rarefaction	O
curves	O
created	O
by	O
runsimulation	O
each	O
curve	O
contains	O
a	O
list	O
of	O
pairs	O
of	O
k	O
and	O
num	O
new	O
the	O
resulting	O
joint	B
distribution	B
is	O
a	O
map	O
from	O
each	O
pair	O
to	O
its	O
probability	B
of	O
occurring	O
given	O
the	O
joint	B
distribution	B
we	O
can	O
use	O
joint	B
conditional	B
get	O
the	O
distribution	B
of	O
num	O
new	O
conditioned	O
on	O
k	O
section	O
subject	O
makeconditionals	O
takes	O
a	O
list	O
of	O
ks	O
and	O
computes	O
the	O
conditional	B
distribution	B
of	O
num	O
new	O
for	O
each	O
k	O
the	O
result	O
is	O
a	O
list	O
of	O
cdf	B
objects	O
def	O
makeconditionalscurves	O
ks	O
joint	B
makejointpredictivecurves	O
cdfs	O
for	O
k	O
in	O
ks	O
pmf	B
k	O
pmf	B
name	O
k	O
cdf	B
pmf	B
makecdf	O
cdfs	O
appendcdf	O
return	O
cdfs	O
figure	O
shows	O
the	O
results	O
after	O
reads	O
the	O
median	B
predicted	O
number	O
of	O
new	O
species	B
is	O
the	O
credible	B
interval	I
is	O
to	O
after	O
reads	O
we	O
expect	O
to	O
see	O
to	O
new	O
species	B
coverage	B
the	O
last	O
question	O
we	O
want	O
to	O
answer	O
is	O
how	O
many	O
additional	O
reads	O
are	O
needed	O
to	O
increase	O
the	O
fraction	O
of	O
observed	O
species	B
to	O
a	O
given	O
threshold	O
to	O
answer	O
this	O
question	O
we	O
need	O
a	O
version	O
of	O
runsimulation	O
that	O
computes	O
the	O
fraction	O
of	O
observed	O
species	B
rather	O
than	O
the	O
number	O
of	O
new	O
species	B
coverage	B
figure	O
complementary	B
cdf	B
of	O
coverage	B
for	O
a	O
range	O
of	O
additional	O
reads	O
class	O
subject	O
def	O
runsimulationself	O
num	O
reads	O
m	O
seen	O
self	O
getseenspecies	O
n	O
observations	O
self	O
generateobservationsnum	O
reads	O
curve	O
for	O
k	O
obs	O
in	O
enumerateobservations	O
seen	O
addobs	O
frac	O
seen	O
lenseen	O
floatn	O
frac	O
seen	O
return	O
curve	O
next	O
we	O
loop	O
through	O
each	O
curve	O
and	O
make	O
a	O
dictionary	O
d	O
that	O
maps	O
from	O
the	O
number	O
of	O
additional	O
reads	O
k	O
to	O
a	O
list	O
of	O
fracs	O
that	O
is	O
a	O
list	O
of	O
values	O
for	O
the	O
coverage	B
achieved	O
after	O
k	O
reads	O
def	O
makefraccdfsself	O
curves	O
d	O
for	O
curve	O
in	O
curves	O
for	O
k	O
frac	O
in	O
curve	O
d	O
setdefaultk	O
cdfs	O
for	O
k	O
fracs	O
in	O
d	O
iteritems	O
of	O
species	B
chapter	O
dealing	O
with	O
dimensions	O
cdf	B
thinkbayes	O
makecdffromlistfracs	O
cdfsk	O
cdf	B
return	O
cdfs	O
then	O
for	O
each	O
value	O
of	O
k	O
we	O
make	O
a	O
cdf	B
of	O
fracs	O
this	O
cdf	B
represents	O
the	O
distribution	B
of	O
coverage	B
after	O
k	O
reads	O
remember	O
that	O
the	O
cdf	B
tells	O
you	O
the	O
probability	B
of	O
falling	O
below	O
a	O
given	O
threshold	O
so	O
the	O
complementary	B
cdf	B
tells	O
you	O
the	O
probability	B
of	O
exceeding	O
it	O
figure	O
shows	O
complementary	O
cdfs	O
for	O
a	O
range	O
of	O
values	O
of	O
k	O
to	O
read	O
this	O
figure	O
select	O
the	O
level	O
of	O
coverage	B
you	O
want	O
to	O
achieve	O
along	O
the	O
x-axis	O
as	O
an	O
example	O
choose	O
now	O
you	O
can	O
read	O
up	O
the	O
chart	O
to	O
find	O
the	O
probability	B
of	O
achieving	O
coverage	B
after	O
k	O
reads	O
for	O
example	O
with	O
reads	O
you	O
have	O
about	O
a	O
chance	O
of	O
getting	O
coverage	B
with	O
reads	O
you	O
have	O
a	O
chance	O
of	O
getting	O
coverage	B
with	O
that	O
we	O
have	O
answered	O
the	O
four	O
questions	O
that	O
make	O
up	O
the	O
unseen	B
species	B
problem	I
to	O
validate	O
the	O
algorithms	O
in	O
this	O
chapter	O
with	O
real	O
data	O
i	O
had	O
to	O
deal	O
with	O
a	O
few	O
more	O
details	O
but	O
this	O
chapter	O
is	O
already	O
too	O
long	O
so	O
i	O
won	O
t	O
discuss	O
them	O
here	O
read	O
about	O
you	O
can	O
them	O
belly-button-biodiversity-end-game	O
html	O
at	O
problems	O
the	O
addressed	O
and	O
how	O
i	O
you	O
can	O
download	O
the	O
code	O
in	O
this	O
chapter	O
from	O
httpthinkbayes	O
com	O
species	B
py	O
for	O
more	O
information	O
see	O
section	O
discussion	O
the	O
unseen	B
species	B
problem	I
is	O
an	O
area	O
of	O
active	O
research	O
and	O
i	O
believe	O
the	O
algorithm	O
in	O
this	O
chapter	O
is	O
a	O
novel	O
contribution	O
so	O
in	O
fewer	O
than	O
pages	O
we	O
have	O
made	O
it	O
from	O
the	O
basics	O
of	O
probability	B
to	O
the	O
research	O
frontier	O
i	O
m	O
very	O
happy	O
about	O
that	O
my	O
goal	O
for	O
this	O
book	O
is	O
to	O
present	O
three	O
related	O
ideas	O
bayesian	O
thinking	O
the	O
foundation	O
of	O
bayesian	O
analysis	O
is	O
the	O
idea	O
of	O
using	O
probability	B
distributions	O
to	O
represent	O
uncertain	O
beliefs	O
using	O
data	O
to	O
update	B
those	O
distributions	O
and	O
using	O
the	O
results	O
to	O
make	O
predictions	O
and	O
inform	O
decisions	O
discussion	O
a	O
computational	O
approach	O
the	O
premise	O
of	O
this	O
book	O
is	O
that	O
it	O
is	O
easier	O
to	O
understand	O
bayesian	O
analysis	O
using	O
computation	O
rather	O
than	O
math	O
and	O
easier	O
to	O
implement	O
bayesian	O
methods	O
with	O
reusable	O
building	O
blocks	O
that	O
can	O
be	O
rearranged	O
to	O
solve	O
real-world	O
problems	O
quickly	O
iterative	B
modeling	B
most	O
real-world	O
problems	O
involve	O
modeling	B
decisions	O
and	O
trade-offs	O
between	O
realism	O
and	O
complexity	O
it	O
is	O
often	O
impossible	O
to	O
know	O
ahead	O
of	O
time	O
what	O
factors	O
should	O
be	O
included	O
in	O
the	O
model	O
and	O
which	O
can	O
be	O
abstracted	O
away	O
the	O
best	O
approach	O
is	O
to	O
iterate	O
starting	O
with	O
simple	O
models	O
and	O
adding	O
complexity	O
gradually	O
using	O
each	O
model	O
to	O
validate	O
the	O
others	O
these	O
ideas	O
are	O
versatile	O
and	O
powerful	O
they	O
are	O
applicable	O
to	O
problems	O
in	O
every	O
area	O
of	O
science	O
and	O
engineering	O
from	O
simple	O
examples	O
to	O
topics	O
of	O
current	O
research	O
if	O
you	O
made	O
it	O
this	O
far	O
you	O
should	O
be	O
prepared	O
to	O
apply	O
these	O
tools	O
to	O
new	O
problems	O
relevant	O
to	O
your	O
work	O
i	O
hope	O
you	O
find	O
them	O
useful	O
let	O
me	O
know	O
how	O
it	O
goes	O
index	O
abc	B
abstract	B
type	I
anaconda	O
viii	O
approximate	O
bayesian	O
computa	O
tion	B
arrival	B
rate	I
axtell	B
robert	O
bacteria	B
bayes	B
factor	I
bayes	O
s	O
theorem	O
derivation	B
odds	B
form	I
bayesian	B
framework	I
behavioral	O
risk	O
factor	O
surveillance	O
system	B
belly	B
button	I
bernoulli	B
process	B
beta	B
distribution	B
beta	B
object	I
biased	B
coin	I
binomial	B
coefficient	I
binomial	B
distribution	B
binomial	B
likelihood	B
function	I
biodiversity	B
bogus	B
boston	B
boston	B
bruins	I
brfss	B
bucket	B
bus	B
stop	I
problem	I
cache	B
calibration	B
campbell-ricketts	B
tom	O
carcinoma	B
causation	B
cdc	B
cdf	B
centers	B
for	I
disease	I
control	I
central	B
credible	B
interval	I
classical	B
estimation	I
clone	O
vii	O
coefficient	B
of	I
variation	I
coin	B
toss	I
collectively	B
exhaustive	I
college	B
board	I
complementary	B
cdf	B
concrete	B
type	I
conditional	B
distribution	B
conditional	B
probability	B
conjoint	B
probability	B
conjugate	B
prior	B
conjunction	B
continuous	B
distribution	B
contributors	O
ix	O
convergence	B
cookie	B
problem	I
cookie	O
py	O
correlated	B
random	I
value	I
coverage	B
crank	B
science	I
credible	B
interval	I
cromwell	B
s	O
rule	O
cromwell	B
oliver	O
cumulative	B
distribution	B
function	I
cumulative	B
probability	B
index	O
cumulative	B
sum	I
davidson-pilon	B
cameron	O
decision	B
analysis	I
degree	B
of	I
belief	I
density	B
dependence	B
diachronic	B
interpretation	I
dice	B
dice	B
problem	I
dice	B
problem	I
dirichlet	B
distribution	B
distribution	B
operations	B
divide-and-conquer	B
doubling	B
time	I
dungeons	B
and	I
dragons	I
efficacy	B
enumeration	B
error	B
esp	B
euro	B
problem	I
evidence	O
exception	B
exponential	B
distribution	B
exponentiation	B
extra-sensory	B
perception	I
fair	B
coin	I
fork	O
vii	O
forward	B
problem	I
gamma	B
distribution	B
gaussian	B
distribution	B
gaussian	B
pdf	B
gee	B
steve	O
geiger	B
counter	I
problem	I
generator	B
german	B
tank	I
problem	I
git	O
vii	O
github	O
vii	O
growth	B
rate	I
heart	B
attack	I
height	B
heuer	B
andreas	O
hierarchical	B
model	I
hoag	B
dirk	O
hockey	B
horse	B
racing	I
horsford	B
eben	O
norton	O
hume	B
david	O
hypothesis	B
testing	I
implementation	B
independence	B
informative	B
prior	B
insect	B
sampling	I
problem	I
installation	O
viii	O
inter-quartile	B
range	I
interface	B
intuition	B
inverse	B
problem	I
iqr	B
item	B
response	I
theory	I
iterative	B
modeling	B
iterator	B
jaynes	B
e	O
t	O
joint	B
joint	B
distribution	B
joint	B
object	I
joint	B
pmf	B
kde	B
kernel	B
density	B
estimation	I
kidney	B
tumor	I
problem	I
least	B
squares	I
fit	I
light	B
bulb	I
problem	I
index	O
likelihood	B
likelihood	B
likelihood	B
function	I
likelihood	B
ratio	I
linspace	B
lions	B
and	I
tigers	I
and	I
bears	I
locomotive	B
problem	I
log	B
scale	I
log	B
transform	I
log-likelihood	B
logarithm	B
m	B
and	I
m	I
problem	I
mackay	B
david	O
makemixture	B
marginal	B
distribution	B
matplotlib	O
viii	O
maximum	B
maximum	B
likelihood	B
mean	B
squared	I
error	B
meckel	B
johann	O
median	B
memoization	B
meta-pmf	B
meta-suite	B
microbiome	B
mixture	B
modeling	B
vi	O
modeling	B
error	B
monty	B
hall	I
problem	I
mosteller	B
frederick	O
mult	B
multinomial	B
coefficient	I
multinomial	B
distribution	B
mutually	B
exclusive	I
national	B
hockey	B
league	I
navel	B
nhl	B
non-linear	B
normal	B
distribution	B
normalize	B
normalizing	B
constant	I
nuisance	B
parameter	B
numpy	B
viii	O
numpy	B
objectivity	B
observer	B
bias	I
odds	B
olin	B
college	I
oliver	O
s	O
blood	O
problem	O
operational	B
taxonomic	I
unit	I
optimization	B
otu	B
overtime	B
paintball	B
problem	I
parameter	B
pdf	B
pdf	B
pep	O
viii	O
percentile	B
pmf	B
pmf	B
class	I
pmf	B
methods	I
poisson	B
distribution	B
poisson	B
process	B
vi	O
posterior	B
posterior	B
distribution	B
power	B
law	I
predictive	B
distribution	B
prevalence	B
price	B
is	I
right	I
prior	B
prior	B
distribution	B
suite	B
suite	B
class	I
summary	B
statistic	I
swamping	B
the	I
priors	I
switch	B
table	B
method	I
template	B
method	I
pattern	I
total	B
probability	B
triangle	B
distribution	B
trigonometry	B
tumor	B
type	I
tuple	B
uncertainty	B
underflow	O
uniform	B
distribution	B
uniform	B
distribution	B
uninformative	B
prior	B
unseen	B
species	B
problem	I
update	B
vancouver	B
canucks	I
variability	B
hypothesis	I
veterans	O
benefit	O
administration	O
volume	B
weibull	B
distribution	B
word	B
frequency	I
index	O
prob	B
probability	B
conditional	B
conjoint	B
probability	B
density	B
probability	B
density	B
function	I
probability	B
mass	I
function	I
process	B
pseudocolor	B
plot	I
pyrosequencing	B
radioactive	B
decay	I
random	B
sample	I
rarefaction	B
curve	I
raw	B
score	I
rdna	B
red	B
line	I
problem	I
reddit	B
regression	B
testing	I
vii	O
renormalize	B
repository	O
vii	O
robust	B
estimation	I
sample	B
bias	I
sample	B
statistics	I
sat	B
scaled	B
score	I
scipy	B
viii	O
scipy	B
serial	B
correlation	I
showcase	B
simulation	B
sivia	B
d	O
s	O
species	B
sphere	B
standardized	B
test	I
stick	B
strafing	B
speed	I
subjective	B
prior	B
subjectivity	B
sudden	B
death	I
