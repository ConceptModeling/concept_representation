deep	O
learning	O
ian	O
goodfellow	O
yoshua	O
bengio	O
aaron	O
courville	O
contents	O
website	O
acknowledgments	O
notation	O
introduction	O
who	O
should	O
read	O
this	O
book	O
historical	O
trends	O
in	O
deep	O
learning	O
i	O
applied	O
math	O
and	O
machine	B
learning	I
basics	O
linear	O
algebra	O
scalars	O
vectors	O
matrices	O
and	O
tensors	O
multiplying	O
matrices	O
and	O
vectors	O
identity	O
and	O
inverse	O
matrices	O
linear	B
dependence	I
and	O
span	O
norms	O
special	O
kinds	O
of	O
matrices	O
and	O
vectors	O
eigendecomposition	B
singular	B
value	I
decomposition	O
the	O
moore-penrose	O
pseudoinverse	O
the	O
trace	B
operator	I
the	O
determinant	O
example	B
principal	O
components	O
analysis	O
probability	O
and	O
information	O
theory	O
why	O
probability	O
i	O
vii	O
viii	O
xi	O
contents	O
random	O
variables	O
probability	O
distributions	O
marginal	B
probability	I
conditional	B
probability	I
the	O
chain	O
rule	O
of	O
conditional	O
probabilities	O
independence	O
and	O
conditional	O
independence	O
expectation	B
variance	O
and	O
covariance	O
common	O
probability	O
distributions	O
useful	O
properties	O
of	O
common	O
functions	O
bayes	O
rule	O
technical	O
details	O
of	O
continuous	O
variables	O
information	O
theory	O
structured	O
probabilistic	O
models	O
numerical	O
computation	O
overflow	O
and	O
underflow	O
poor	O
conditioning	O
gradient-based	O
optimization	O
constrained	O
optimization	O
example	B
linear	O
least	O
squares	O
machine	B
learning	I
basics	O
learning	O
algorithms	O
capacity	O
overfitting	O
and	O
underfitting	O
hyperparameters	O
and	O
validation	O
sets	O
estimators	O
bias	O
and	O
variance	O
maximum	B
likelihood	I
estimation	O
bayesian	B
statistics	I
supervised	B
learning	I
algorithms	O
unsupervised	O
learning	O
algorithms	O
stochastic	O
gradient	B
descent	O
building	O
a	O
machine	B
learning	I
algorithm	O
challenges	O
motivating	O
deep	O
learning	O
ii	O
deep	O
networks	O
modern	O
practices	O
deep	O
feedforward	O
networks	O
example	B
learning	O
xor	O
gradient-based	O
learning	O
ii	O
contents	O
hidden	O
units	O
architecture	O
design	O
back-propagation	B
and	O
other	O
differentiation	O
algorithms	O
historical	O
notes	O
regularization	O
for	O
deep	O
learning	O
parameter	O
norm	O
penalties	O
norm	O
penalties	O
as	O
constrained	O
optimization	O
regularization	O
and	O
under-constrained	O
problems	O
dataset	B
augmentation	O
noise	O
robustness	O
semi-supervised	B
learning	I
multi-task	O
learning	O
early	O
stopping	O
parameter	O
tying	O
and	O
parameter	O
sharing	O
sparse	O
representations	O
bagging	B
and	O
other	O
ensemble	B
methods	I
dropout	O
adversarial	O
training	O
tangent	B
distance	I
tangent	B
prop	I
and	O
manifold	B
tangent	I
classifier	I
optimization	O
for	O
training	O
deep	O
models	O
how	O
learning	O
differs	O
from	O
pure	O
optimization	O
challenges	O
in	O
neural	B
network	I
optimization	O
basic	O
algorithms	O
parameter	O
initialization	B
strategies	O
algorithms	O
with	O
adaptive	O
learning	O
rates	O
approximate	O
second-order	O
methods	O
optimization	O
strategies	O
and	O
meta-algorithms	O
convolutional	O
networks	O
the	O
convolution	O
operation	B
motivation	O
pooling	O
convolution	O
and	O
pooling	O
as	O
an	O
infinitely	O
strong	O
prior	O
variants	O
of	O
the	O
basic	O
convolution	O
function	O
structured	O
outputs	O
data	O
types	O
efficient	O
convolution	O
algorithms	O
random	O
or	O
unsupervised	O
features	O
iii	O
contents	O
the	O
neuroscientific	O
basis	O
for	O
convolutional	O
networks	O
convolutional	O
networks	O
and	O
the	O
history	O
of	O
deep	O
learning	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
unfolding	O
computational	O
graphs	O
recurrent	O
neural	O
networks	O
bidirectional	O
rnns	O
encoder-decoder	O
sequence-to-sequence	O
architectures	O
deep	O
recurrent	O
networks	O
recursive	O
neural	O
networks	O
the	O
challenge	B
of	O
long-term	O
dependencies	O
echo	O
state	O
networks	O
leaky	B
units	I
and	O
other	O
strategies	O
for	O
multiple	O
time	O
scales	O
the	O
long	O
short-term	O
memory	O
and	O
other	O
gated	O
rnns	O
optimization	O
for	O
long-term	O
dependencies	O
explicit	O
memory	O
practical	O
methodology	O
performance	O
metrics	O
default	O
baseline	O
models	O
determining	O
whether	O
to	O
gather	O
more	O
data	O
selecting	O
hyperparameters	O
debugging	O
strategies	O
example	B
multi-digit	O
number	O
recognition	O
applications	O
large-scale	O
deep	O
learning	O
computer	B
vision	I
speech	O
recognition	O
natural	B
language	I
processing	I
other	O
applications	O
iii	O
deep	O
learning	O
research	O
linear	B
factor	I
models	I
probabilistic	O
pca	O
and	O
factor	B
analysis	I
independent	B
component	I
analysis	I
slow	B
feature	B
analysis	I
sparse	O
coding	O
iv	O
contents	O
manifold	B
interpretation	O
of	O
pca	O
autoencoders	O
undercomplete	O
autoencoders	O
regularized	O
autoencoders	O
representational	O
power	O
layer	O
size	O
and	O
depth	O
stochastic	O
encoders	O
and	O
decoders	O
denoising	O
autoencoders	O
learning	O
manifolds	O
with	O
autoencoders	O
contractive	O
autoencoders	O
predictive	B
sparse	I
decomposition	I
applications	O
of	O
autoencoders	O
representation	B
learning	I
greedy	O
layer-wise	O
unsupervised	B
pretraining	I
transfer	B
learning	I
and	O
domain	B
adaptation	I
semi-supervised	O
disentangling	O
of	O
causal	O
factors	O
distributed	O
representation	O
exponential	O
gains	O
from	O
depth	O
providing	O
clues	O
to	O
discover	O
underlying	O
causes	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
the	O
challenge	B
of	O
unstructured	O
modeling	O
using	O
graphs	O
to	O
describe	O
model	O
structure	O
sampling	O
from	O
graphical	O
models	O
advantages	O
of	O
structured	O
modeling	O
learning	O
about	O
dependencies	O
inference	O
and	O
approximate	B
inference	I
the	O
deep	O
learning	O
approach	O
to	O
structured	O
probabilistic	O
models	O
monte	O
carlo	O
methods	O
sampling	O
and	O
monte	O
carlo	O
methods	O
importance	O
sampling	O
markov	B
chain	I
monte	I
carlo	I
methods	O
gibbs	O
sampling	O
the	O
challenge	B
of	O
mixing	O
between	O
separated	O
modes	O
confronting	O
the	O
partition	O
function	O
the	O
log-likelihood	O
gradient	B
stochastic	O
maximum	B
likelihood	I
and	O
contrastive	O
divergence	O
v	O
contents	O
pseudolikelihood	B
score	O
matching	O
and	O
ratio	B
matching	I
denoising	B
score	I
matching	I
noise-contrastive	B
estimation	I
estimating	O
the	O
partition	O
function	O
approximate	B
inference	I
inference	O
as	O
optimization	O
expectation	B
maximization	I
map	O
inference	O
and	O
sparse	O
coding	O
variational	O
inference	O
and	O
learning	O
learned	O
approximate	B
inference	I
deep	O
generative	O
models	O
boltzmann	O
machines	O
restricted	O
boltzmann	O
machines	O
deep	O
belief	O
networks	O
deep	O
boltzmann	O
machines	O
boltzmann	O
machines	O
for	O
real-valued	O
data	O
convolutional	O
boltzmann	O
machines	O
boltzmann	O
machines	O
for	O
structured	O
or	O
sequential	O
outputs	O
other	O
boltzmann	O
machines	O
back-propagation	B
through	O
random	O
operations	O
directed	O
generative	O
nets	O
drawing	O
samples	O
from	O
autoencoders	O
generative	O
stochastic	O
networks	O
other	O
generation	O
schemes	O
evaluating	O
generative	O
models	O
conclusion	O
bibliography	O
index	O
vi	O
website	O
www	O
deeplearningbook	O
org	O
this	O
book	O
is	O
accompanied	O
by	O
the	O
above	O
website	O
the	O
website	O
provides	O
a	O
variety	O
of	O
supplementary	O
material	O
including	O
exercises	O
lecture	O
slides	O
corrections	O
of	O
mistakes	O
and	O
other	O
resources	O
that	O
should	O
be	O
useful	O
to	O
both	O
readers	O
and	O
instructors	O
vii	O
acknowledgments	O
this	O
book	O
would	O
not	O
have	O
been	O
possible	O
without	O
the	O
contributions	O
of	O
many	O
people	O
we	O
would	O
like	O
to	O
thank	O
those	O
who	O
commented	O
on	O
our	O
proposal	O
for	O
the	O
book	O
and	O
helped	O
plan	O
its	O
contents	O
and	O
organization	O
guillaume	O
alain	O
kyunghyun	O
cho	O
a	O
lar	O
g	O
l	O
ehre	O
david	O
krueger	O
hugo	O
larochelle	O
razvan	O
pascanu	O
and	O
thomas	O
roh	O
e	O
we	O
would	O
like	O
to	O
thank	O
the	O
people	O
who	O
offered	O
feedback	O
on	O
the	O
content	O
of	O
the	O
book	O
itself	O
some	O
offered	O
feedback	O
on	O
many	O
chapters	O
mart	O
n	O
abadi	O
guillaume	O
alain	O
ion	O
androutsopoulos	O
fred	O
bertsch	O
olexa	O
bilaniuk	O
ufuk	O
can	O
bi	O
ici	O
matko	O
bo	O
njak	O
john	O
boersma	O
greg	O
brockman	O
alexandre	O
de	O
br	O
bisson	O
pierre	O
luc	O
carrier	O
sarath	O
chandar	O
pawel	O
chilinski	O
mark	O
daoust	O
oleg	O
dashevskii	O
laurent	O
dinh	O
stephan	O
dreseitl	O
jim	O
fan	O
miao	O
fan	O
meire	O
fortunato	O
fr	O
d	O
ric	O
francis	O
nando	O
de	O
freitas	O
a	O
lar	O
g	O
l	O
ehre	O
jurgen	O
van	O
gael	O
javier	O
alonso	O
garc	O
a	O
jonathan	O
hunt	O
gopi	O
jeyaram	O
chingiz	O
kabytayev	O
lukasz	O
kaiser	O
varun	O
kanade	O
asifullah	O
khan	O
akiel	O
khan	O
john	O
king	O
diederik	O
p	O
kingma	O
yann	O
lecun	O
rudolf	O
mathey	O
mat	O
as	O
mattamala	O
abhinav	O
maurya	O
kevin	O
murphy	O
oleg	O
m	O
rk	O
roman	O
novak	O
augustus	O
q	O
odena	O
simon	O
pavlik	O
karl	O
pichotta	O
eddie	O
pierce	O
kari	O
pulli	O
roussel	O
rahman	O
tapani	O
raiko	O
anurag	O
ranjan	O
johannes	O
roith	O
mihaela	O
rosca	O
halis	O
sak	O
c	O
sar	O
salgado	O
grigory	O
sapunov	O
yoshinori	O
sasaki	O
mike	O
schuster	O
julian	O
serban	O
nir	O
shabat	O
ken	O
shirriff	O
andre	O
simpelo	O
scott	O
stanley	O
david	O
sussillo	O
ilya	O
sutskever	O
carles	O
gelada	O
s	O
ez	O
graham	O
taylor	O
valentin	O
tolmer	O
massimiliano	O
tomassoli	O
an	O
tran	O
shubhendu	O
trivedi	O
alexey	O
umnov	O
vincent	O
vanhoucke	O
marco	O
visentini-scarzanella	O
martin	O
vita	O
david	O
warde-farley	O
dustin	O
webb	O
kelvin	O
xu	O
wei	O
xue	O
ke	O
yang	O
li	O
yao	O
zygmunt	O
zaj	O
c	O
and	O
ozan	O
a	O
layan	O
we	O
would	O
also	O
like	O
to	O
thank	O
those	O
who	O
provided	O
us	O
with	O
useful	O
feedback	O
on	O
individual	O
chapters	O
notation	O
zhang	O
yuanhang	O
chapter	O
introduction	O
yusuf	O
akgul	O
sebastien	O
bratieres	O
samira	O
ebrahimi	O
viii	O
contents	O
charlie	O
gorichanaz	O
brendan	O
loudermilk	O
eric	O
morris	O
cosmin	O
p	O
rvulescu	O
and	O
alfredo	O
solano	O
linear	O
algebra	O
chapter	O
amjad	O
almahairi	O
nikola	O
bani	O
kevin	O
bennett	O
philippe	O
castonguay	O
oscar	O
chang	O
eric	O
fosler-lussier	O
andrey	O
khalyavin	O
sergey	O
oreshkov	O
istv	O
n	O
petr	O
s	O
dennis	O
prangle	O
thomas	O
roh	O
e	O
gitanjali	O
gulve	O
sehgal	O
colby	O
toland	O
alessandro	O
vitale	O
and	O
bob	O
welland	O
probability	O
and	O
information	O
theory	O
chapter	O
john	O
philip	O
anderson	O
kai	O
arulkumaran	O
vincent	O
dumoulin	O
rui	O
fa	O
stephan	O
gouws	O
artem	O
oboturov	O
antti	O
rasmus	O
alexey	O
surkov	O
and	O
volker	O
tresp	O
chapter	O
yuhuang	O
numerical	O
computation	O
tran	O
lam	O
anian	O
fischer	O
and	O
hu	O
machine	B
learning	I
basics	O
chapter	O
dzmitry	O
bahdanau	O
justin	O
domingue	O
nikhil	O
garg	O
makoto	O
otsuka	O
bob	O
pepin	O
philip	O
popien	O
emmanuel	O
rayner	O
peter	O
shepard	O
kee-bong	O
song	O
zheng	O
sun	O
and	O
andy	O
wu	O
chapter	O
deep	O
feedforward	O
networks	O
uriel	O
berdugo	O
fabrizio	O
bottarel	O
elizabeth	O
burl	O
ishan	O
durugkar	O
jeff	O
hlywa	O
jong	O
wook	O
kim	O
david	O
krueger	O
and	O
aditya	O
kumar	O
praharaj	O
chapter	O
inkyu	O
lee	O
sunil	O
mohan	O
hai	O
phong	O
phan	O
and	O
joshua	O
salisbury	O
regularization	O
for	O
deep	O
learning	O
morten	O
kolb	O
k	O
kshitij	O
lauria	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
marcel	O
ackermann	O
peter	O
armitage	O
rowel	O
atienza	O
andrew	O
brock	O
tegan	O
maharaj	O
james	O
martens	O
kashif	O
rasul	O
klaus	O
strobl	O
and	O
nicholas	O
turner	O
chapter	O
convolutional	O
networks	O
mart	O
n	O
arjovsky	O
eugene	O
brevdo	O
konstantin	O
divilov	O
eric	O
jensen	O
mehdi	O
mirza	O
alex	O
paino	O
marjorie	O
sayer	O
ryan	O
stout	O
and	O
wentao	O
wu	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
g	O
k	O
en	O
eraslan	O
steven	O
hickson	O
razvan	O
pascanu	O
lorenzo	O
von	O
ritter	O
rui	O
rodrigues	O
dmitriy	O
serdyuk	O
dongyu	O
shi	O
and	O
kaiyu	O
yang	O
chapter	O
chapter	O
roscher	O
practical	O
methodology	O
daniel	O
beckstein	O
applications	O
george	O
dahl	O
vladimir	O
nekrasov	O
and	O
ribana	O
chapter	O
linear	B
factor	I
models	I
jayanth	O
koushik	O
ix	O
contents	O
chapter	O
representation	B
learning	I
kunal	O
ghosh	O
chapter	O
and	O
anton	O
varfolom	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
minh	O
l	O
chapter	O
confronting	O
the	O
partition	O
function	O
sam	O
bowman	O
chapter	O
approximate	B
inference	I
yujia	O
bao	O
chapter	O
wenming	O
ma	O
fady	O
medhat	O
shakir	O
mohamed	O
and	O
gr	O
goire	O
montavon	O
deep	O
generative	O
models	O
nicolas	O
chapados	O
daniel	O
galvez	O
bibliography	O
lukas	O
michelbacher	O
and	O
leslie	O
n	O
smith	O
we	O
also	O
want	O
to	O
thank	O
those	O
who	O
allowed	O
us	O
to	O
reproduce	O
images	O
figures	O
or	O
data	O
from	O
their	O
publications	O
we	O
indicate	O
their	O
contributions	O
in	O
the	O
figure	O
captions	O
throughout	O
the	O
text	O
we	O
would	O
like	O
to	O
thank	O
lu	O
wang	O
for	O
writing	O
which	O
we	O
used	O
to	O
make	O
the	O
web	O
version	O
of	O
the	O
book	O
and	O
for	O
offering	O
support	O
to	O
improve	O
the	O
quality	O
of	O
the	O
resulting	O
html	O
we	O
would	O
like	O
to	O
thank	O
ian	O
s	O
wife	O
daniela	O
flori	O
goodfellow	O
for	O
patiently	O
supporting	O
ian	O
during	O
the	O
writing	O
of	O
the	O
book	O
as	O
well	O
as	O
for	O
help	O
with	O
proofreading	O
we	O
would	O
like	O
to	O
thank	O
the	O
google	O
brain	O
team	O
for	O
providing	O
an	O
intellectual	O
environment	O
where	O
ian	O
could	O
devote	O
a	O
tremendous	O
amount	O
of	O
time	O
to	O
writing	O
this	O
book	O
and	O
receive	O
feedback	O
and	O
guidance	O
from	O
colleagues	O
we	O
would	O
especially	O
like	O
to	O
thank	O
ian	O
s	O
former	O
manager	O
greg	O
corrado	O
and	O
his	O
current	O
manager	O
samy	O
bengio	O
for	O
their	O
support	O
of	O
this	O
project	O
finally	O
we	O
would	O
like	O
to	O
thank	O
geoffrey	O
hinton	O
for	O
encouragement	O
when	O
writing	O
was	O
difficult	O
x	O
notation	O
this	O
section	O
provides	O
a	O
concise	O
reference	O
describing	O
the	O
notation	O
used	O
throughout	O
this	O
book	O
if	O
you	O
are	O
unfamiliar	O
with	O
any	O
of	O
the	O
corresponding	O
mathematical	O
concepts	O
we	O
describe	O
most	O
of	O
these	O
ideas	O
in	O
chapters	O
a	O
a	O
a	O
a	O
in	O
i	O
e	O
numbers	O
and	O
arrays	O
a	O
scalar	O
or	O
real	O
a	O
vector	O
a	O
matrix	O
a	O
tensor	O
identity	B
matrix	I
with	O
n	O
rows	O
and	O
n	O
columns	O
identity	B
matrix	I
with	O
dimensionality	O
implied	O
by	O
context	O
standard	O
basis	O
vector	O
with	O
a	O
at	O
position	O
i	O
diag	O
a	O
square	O
diagonal	B
matrix	I
with	O
diagonal	O
entries	O
given	O
by	O
a	O
a	O
scalar	O
random	B
variable	I
a	O
vector-valued	O
random	B
variable	I
a	O
matrix-valued	O
random	B
variable	I
a	O
a	O
a	O
xi	O
contents	O
a	O
a	O
set	O
sets	O
and	O
graphs	O
r	O
n	O
b	O
b	O
a	O
b	O
g	O
the	O
set	O
of	O
real	O
numbers	O
the	O
set	O
containing	O
and	O
the	O
set	O
of	O
all	O
integers	O
between	O
and	O
n	O
the	O
real	O
interval	O
including	O
a	O
and	O
b	O
the	O
real	O
interval	O
excluding	O
a	O
but	O
including	O
b	O
set	O
subtraction	O
i	O
e	O
the	O
set	O
containing	O
the	O
elements	O
of	O
that	O
are	O
not	O
in	O
a	O
b	O
a	O
graph	O
p	O
agxi	O
the	O
parents	O
of	O
xi	O
in	O
g	O
indexing	O
ai	O
a	O
i	O
aij	O
element	O
i	O
of	O
vector	O
a	O
with	O
indexing	O
starting	O
at	O
all	O
elements	O
of	O
vector	O
a	O
except	O
for	O
element	O
i	O
element	O
i	O
j	O
of	O
matrix	O
a	O
ai	O
row	O
of	O
matrix	O
i	O
a	O
ai	O
column	O
of	O
matrix	O
i	O
a	O
aijk	O
element	O
i	O
j	O
k	O
of	O
a	O
tensor	O
a	O
a	O
ai	O
a	O
a	O
a	O
b	O
slice	O
of	O
a	O
tensor	O
element	O
of	O
the	O
random	O
vector	O
i	O
a	O
linear	O
algebra	O
operations	O
transpose	O
of	O
matrix	O
a	O
moore-penrose	O
pseudoinverse	O
of	O
a	O
element-wise	O
product	O
of	O
anda	O
b	O
det	O
determinant	O
of	O
a	O
xii	O
contents	O
dy	O
dx	O
y	O
x	O
xy	O
x	O
y	O
y	O
x	O
f	O
x	O
xf	O
calculus	O
derivative	B
of	O
with	O
respect	O
to	O
y	O
x	O
partial	B
derivative	B
of	O
with	O
respect	O
to	O
y	O
x	O
gradient	B
of	O
with	O
respect	O
to	O
y	O
x	O
matrix	O
derivatives	O
of	O
with	O
respect	O
to	O
y	O
x	O
tensor	O
containing	O
derivatives	O
of	O
y	O
with	O
respect	O
to	O
x	O
jacobian	O
matrix	O
j	O
m	O
n	O
r	O
m	O
r	O
n	O
of	O
f	O
r	O
the	O
hessian	B
matrix	O
of	O
f	O
at	O
input	O
point	O
x	O
x	O
or	O
h	O
f	O
f	O
x	O
d	O
definite	O
integral	O
over	O
the	O
entire	O
domain	O
of	O
x	O
f	O
x	O
d	O
definite	O
integral	O
with	O
respect	O
to	O
x	O
over	O
the	O
set	O
s	O
s	O
a	O
b	O
a	O
b	O
c	O
p	O
p	O
a	O
p	O
probability	O
and	O
information	O
theory	O
the	O
random	O
variables	O
a	O
and	O
b	O
are	O
independent	O
they	O
are	O
conditionally	O
independent	O
given	O
c	O
a	O
probability	B
distribution	I
over	O
a	O
discrete	O
variable	O
a	O
probability	B
distribution	I
over	O
a	O
continuous	O
variable	O
or	O
over	O
a	O
variable	O
whose	O
type	O
has	O
not	O
been	O
specified	O
random	B
variable	I
a	O
has	O
distribution	O
p	O
p	O
ex	O
f	O
x	O
or	O
ef	O
x	O
expectation	B
of	O
f	O
x	O
with	O
respect	O
to	O
p	O
x	O
var	O
f	O
x	O
variance	O
of	O
f	O
x	O
under	O
x	O
p	O
cov	O
f	O
x	O
g	O
x	O
h	O
p	O
q	O
dkl	O
n	O
x	O
covariance	O
of	O
f	O
x	O
and	O
g	O
x	O
under	O
x	O
p	O
shannon	O
entropy	O
of	O
the	O
random	B
variable	I
x	O
kullback-leibler	B
divergence	I
of	O
p	O
and	O
q	O
gaussian	O
distribution	O
over	O
x	O
with	O
mean	O
and	O
covariance	O
xiii	O
contents	O
g	O
f	O
a	O
f	O
functions	O
b	O
the	O
function	O
with	O
domain	O
f	O
and	O
range	O
b	O
a	O
composition	O
of	O
the	O
functions	O
f	O
and	O
g	O
f	O
a	O
function	O
of	O
x	O
parametrized	O
by	O
we	O
write	O
fx	O
and	O
omit	O
the	O
argument	O
to	O
lighten	O
notation	O
log	O
x	O
x	O
x	O
x	O
p	O
x	O
x	O
natural	O
logarithm	O
of	O
x	O
logistic	O
sigmoid	O
exp	O
x	O
softplus	O
exp	O
x	O
lp	B
norm	I
of	O
x	O
norm	O
of	O
x	O
positive	O
part	O
of	O
x	O
i	O
e	O
x	O
is	O
if	O
the	O
condition	O
is	O
true	O
otherwise	O
sometimes	O
we	O
use	O
a	O
function	O
f	O
whose	O
argument	O
is	O
a	O
scalar	O
but	O
apply	O
it	O
to	O
a	O
vector	O
matrix	O
or	O
tensor	O
f	O
fx	O
or	O
f	O
this	O
denotes	O
the	O
application	O
of	O
f	O
to	O
the	O
array	O
element-wise	O
for	O
example	B
if	O
c	O
then	O
c	O
ijk	O
for	O
all	O
valid	O
values	O
of	O
and	O
k	O
i	O
j	O
pdata	O
pdata	O
x	O
x	O
y	O
or	O
y	O
x	O
datasets	O
and	O
distributions	O
the	O
data	O
generating	O
distribution	O
the	O
empirical	B
distribution	I
defined	O
by	O
the	O
training	O
set	O
a	O
set	O
of	O
training	O
examples	O
the	O
example	B
from	O
a	O
dataset	B
i	O
the	O
target	O
associated	O
with	O
x	O
for	O
supervised	B
learning	I
the	O
m	O
n	O
xi	O
matrix	O
with	O
input	O
example	B
x	O
in	O
row	O
xiv	O
chapter	O
introduction	O
inventors	O
have	O
long	O
dreamed	O
of	O
creating	O
machines	O
that	O
think	O
this	O
desire	O
dates	O
back	O
to	O
at	O
least	O
the	O
time	O
of	O
ancient	O
greece	O
the	O
mythical	O
figures	O
pygmalion	O
daedalus	O
and	O
hephaestus	O
may	O
all	O
be	O
interpreted	O
as	O
legendary	O
inventors	O
and	O
galatea	O
talos	O
and	O
pandora	O
may	O
all	O
be	O
regarded	O
as	O
artificial	O
life	O
ovid	O
and	O
martin	O
sparkes	O
tandy	O
when	O
programmable	O
computers	O
were	O
first	O
conceived	O
people	O
wondered	O
whether	O
such	O
machines	O
might	O
become	O
intelligent	O
over	O
a	O
hundred	O
years	O
before	O
one	O
was	O
built	O
today	O
artificial	B
intelligence	I
is	O
a	O
thriving	O
field	O
with	O
many	O
practical	O
applications	O
and	O
active	O
research	O
topics	O
we	O
look	O
to	O
intelligent	O
software	O
to	O
automate	O
routine	O
labor	O
understand	O
speech	O
or	O
images	O
make	O
diagnoses	O
in	O
medicine	O
and	O
support	O
basic	O
scientific	O
research	O
in	O
the	O
early	O
days	O
of	O
artificial	B
intelligence	I
the	O
field	O
rapidly	O
tackled	O
and	O
solved	O
problems	O
that	O
are	O
intellectually	O
difficult	O
for	O
human	O
beings	O
but	O
relatively	O
straightforward	O
for	O
computers	O
problems	O
that	O
can	O
be	O
described	O
by	O
a	O
list	O
of	O
formal	O
mathematical	O
rules	O
the	O
true	O
challenge	B
to	O
artificial	B
intelligence	I
proved	O
to	O
be	O
solving	O
the	O
tasks	O
that	O
are	O
easy	O
for	O
people	O
to	O
perform	O
but	O
hard	O
for	O
people	O
to	O
describe	O
formally	O
problems	O
that	O
we	O
solve	O
intuitively	O
that	O
feel	O
automatic	O
like	O
recognizing	O
spoken	O
words	O
or	O
faces	O
in	O
images	O
this	O
book	O
is	O
about	O
a	O
solution	O
to	O
these	O
more	O
intuitive	O
problems	O
this	O
solution	O
is	O
to	O
allow	O
computers	O
to	O
learn	O
from	O
experience	O
and	O
understand	O
the	O
world	O
in	O
terms	O
of	O
a	O
hierarchy	O
of	O
concepts	O
with	O
each	O
concept	O
defined	O
in	O
terms	O
of	O
its	O
relation	O
to	O
simpler	O
concepts	O
by	O
gathering	O
knowledge	O
from	O
experience	O
this	O
approach	O
avoids	O
the	O
need	O
for	O
human	O
operators	O
to	O
formally	O
specify	O
all	O
of	O
the	O
knowledge	O
that	O
the	O
computer	O
needs	O
the	O
hierarchy	O
of	O
concepts	O
allows	O
the	O
computer	O
to	O
learn	O
complicated	O
concepts	O
by	O
building	O
them	O
out	O
of	O
simpler	O
ones	O
if	O
we	O
draw	O
a	O
graph	O
showing	O
how	O
these	O
chapter	O
introduction	O
concepts	O
are	O
built	O
on	O
top	O
of	O
each	O
other	O
the	O
graph	O
is	O
deep	O
with	O
many	O
layers	O
for	O
this	O
reason	O
we	O
call	O
this	O
approach	O
to	O
ai	O
deep	O
learning	O
many	O
of	O
the	O
early	O
successes	O
of	O
ai	O
took	O
place	O
in	O
relatively	O
sterile	O
and	O
formal	O
environments	O
and	O
did	O
not	O
require	O
computers	O
to	O
have	O
much	O
knowledge	O
about	O
the	O
world	O
for	O
example	B
ibm	O
s	O
deep	B
blue	I
chess-playing	O
system	O
defeated	O
world	O
champion	O
garry	O
kasparov	O
in	O
chess	B
is	O
of	O
course	O
a	O
very	O
simple	O
world	O
containing	O
only	O
sixty-four	O
locations	O
and	O
thirty-two	O
pieces	O
that	O
can	O
move	O
in	O
only	O
rigidly	O
circumscribed	O
ways	O
devising	O
a	O
successful	O
chess	B
strategy	O
is	O
a	O
tremendous	O
accomplishment	O
but	O
the	O
challenge	B
is	O
not	O
due	O
to	O
the	O
difficulty	O
of	O
describing	O
the	O
set	O
of	O
chess	B
pieces	O
and	O
allowable	O
moves	O
to	O
the	O
computer	O
chess	B
can	O
be	O
completely	O
described	O
by	O
a	O
very	O
brief	O
list	O
of	O
completely	O
formal	O
rules	O
easily	O
provided	O
ahead	O
of	O
time	O
by	O
the	O
programmer	O
hsu	O
ironically	O
abstract	O
and	O
formal	O
tasks	O
that	O
are	O
among	O
the	O
most	O
difficult	O
mental	O
undertakings	O
for	O
a	O
human	O
being	O
are	O
among	O
the	O
easiest	O
for	O
a	O
computer	O
computers	O
have	O
long	O
been	O
able	O
to	O
defeat	O
even	O
the	O
best	O
human	O
chess	B
player	O
but	O
are	O
only	O
recently	O
matching	O
some	O
of	O
the	O
abilities	O
of	O
average	O
human	O
beings	O
to	O
recognize	O
objects	O
or	O
speech	O
a	O
person	O
s	O
everyday	O
life	O
requires	O
an	O
immense	O
amount	O
of	O
knowledge	O
about	O
the	O
world	O
much	O
of	O
this	O
knowledge	O
is	O
subjective	O
and	O
intuitive	O
and	O
therefore	O
difficult	O
to	O
articulate	O
in	O
a	O
formal	O
way	O
computers	O
need	O
to	O
capture	O
this	O
same	O
knowledge	O
in	O
order	O
to	O
behave	O
in	O
an	O
intelligent	O
way	O
one	O
of	O
the	O
key	O
challenges	O
in	O
artificial	B
intelligence	I
is	O
how	O
to	O
get	O
this	O
informal	O
knowledge	O
into	O
a	O
computer	O
several	O
artificial	B
intelligence	I
projects	O
have	O
sought	O
to	O
hard-code	O
knowledge	O
about	O
the	O
world	O
in	O
formal	O
languages	O
a	O
computer	O
can	O
reason	O
about	O
statements	O
in	O
these	O
formal	O
languages	O
automatically	O
using	O
logical	O
inference	O
rules	O
this	O
is	O
known	O
as	O
the	O
knowledge	O
base	O
approach	O
to	O
artificial	B
intelligence	I
none	O
of	O
these	O
projects	O
has	O
led	O
to	O
a	O
major	O
success	O
one	O
of	O
the	O
most	O
famous	O
such	O
projects	O
is	O
cyc	B
lenat	O
and	O
guha	O
cyc	B
is	O
an	O
inference	O
engine	O
and	O
a	O
database	O
of	O
statements	O
in	O
a	O
language	O
called	O
cycl	O
these	O
statements	O
are	O
entered	O
by	O
a	O
staff	O
of	O
human	O
supervisors	O
it	O
is	O
an	O
unwieldy	O
process	O
people	O
struggle	O
to	O
devise	O
formal	O
rules	O
with	O
enough	O
complexity	O
to	O
accurately	O
describe	O
the	O
world	O
for	O
example	B
cyc	B
failed	O
to	O
understand	O
a	O
story	O
about	O
a	O
person	O
named	O
fred	O
shaving	O
in	O
the	O
morning	O
its	O
inference	O
engine	O
detected	O
an	O
inconsistency	O
in	O
the	O
story	O
it	O
knew	O
that	O
people	O
do	O
not	O
have	O
electrical	O
parts	O
but	O
because	O
fred	O
was	O
holding	O
an	O
electric	O
razor	O
it	O
believed	O
the	O
entity	O
fredwhileshaving	O
contained	O
electrical	O
parts	O
it	O
therefore	O
asked	O
whether	O
fred	O
was	O
still	O
a	O
person	O
while	O
he	O
was	O
shaving	O
linde	O
the	O
difficulties	O
faced	O
by	O
systems	O
relying	O
on	O
hard-coded	O
knowledge	O
suggest	O
that	O
ai	O
systems	O
need	O
the	O
ability	O
to	O
acquire	O
their	O
own	O
knowledge	O
by	O
extracting	O
patterns	O
from	O
raw	O
data	O
this	O
capability	O
is	O
known	O
as	O
machine	B
learning	I
the	O
chapter	O
introduction	O
introduction	O
of	O
machine	B
learning	I
allowed	O
computers	O
to	O
tackle	O
problems	O
involving	O
knowledge	O
of	O
the	O
real	O
world	O
and	O
make	O
decisions	O
that	O
appear	O
subjective	O
a	O
simple	O
machine	B
learning	I
algorithm	O
called	O
logistic	O
regression	B
can	O
determine	O
whether	O
to	O
recommend	O
cesarean	O
delivery	O
a	O
simple	O
machine	B
learning	I
algorithm	O
called	O
naive	B
bayes	I
can	O
separate	O
legitimate	O
e-mail	O
from	O
spam	O
e-mail	O
et	O
al	O
the	O
performance	O
of	O
these	O
simple	O
machine	B
learning	I
algorithms	O
depends	O
heavily	O
on	O
the	O
representation	O
of	O
the	O
data	O
they	O
are	O
given	O
for	O
example	B
when	O
logistic	O
regression	B
is	O
used	O
to	O
recommend	O
cesarean	O
delivery	O
the	O
ai	O
system	O
does	O
not	O
examine	O
the	O
patient	O
directly	O
instead	O
the	O
doctor	O
tells	O
the	O
system	O
several	O
pieces	O
of	O
relevant	O
information	O
such	O
as	O
the	O
presence	O
or	O
absence	O
of	O
a	O
uterine	O
scar	O
each	O
piece	O
of	O
information	O
included	O
in	O
the	O
representation	O
of	O
the	O
patient	O
is	O
known	O
as	O
a	O
feature	B
logistic	O
regression	B
learns	O
how	O
each	O
of	O
these	O
features	O
of	O
the	O
patient	O
correlates	O
with	O
various	O
outcomes	O
however	O
it	O
cannot	O
influence	O
the	O
way	O
that	O
the	O
features	O
are	O
defined	O
in	O
any	O
way	O
if	O
logistic	O
regression	B
was	O
given	O
an	O
mri	O
scan	O
of	O
the	O
patient	O
rather	O
than	O
the	O
doctor	O
s	O
formalized	O
report	O
it	O
would	O
not	O
be	O
able	O
to	O
make	O
useful	O
predictions	O
individual	O
pixels	O
in	O
an	O
mri	O
scan	O
have	O
negligible	O
correlation	B
with	O
any	O
complications	O
that	O
might	O
occur	O
during	O
delivery	O
this	O
dependence	O
on	O
representations	O
is	O
a	O
general	O
phenomenon	O
that	O
appears	O
throughout	O
computer	O
science	O
and	O
even	O
daily	O
life	O
in	O
computer	O
science	O
operations	O
such	O
as	O
searching	O
a	O
collection	O
of	O
data	O
can	O
proceed	O
exponentially	O
faster	O
if	O
the	O
collection	O
is	O
structured	O
and	O
indexed	O
intelligently	O
people	O
can	O
easily	O
perform	O
arithmetic	O
on	O
arabic	O
numerals	O
but	O
find	O
arithmetic	O
on	O
roman	O
numerals	O
much	O
more	O
time-consuming	O
it	O
is	O
not	O
surprising	O
that	O
the	O
choice	O
of	O
representation	O
has	O
an	O
enormous	O
effect	O
on	O
the	O
performance	O
of	O
machine	B
learning	I
algorithms	O
for	O
a	O
simple	O
visual	O
example	B
see	O
figure	O
many	O
artificial	B
intelligence	I
tasks	O
can	O
be	O
solved	O
by	O
designing	O
the	O
right	O
set	O
of	O
features	O
to	O
extract	O
for	O
that	O
task	O
then	O
providing	O
these	O
features	O
to	O
a	O
simple	O
machine	B
learning	I
algorithm	O
for	O
example	B
a	O
useful	O
feature	B
for	O
speaker	O
identification	O
from	O
sound	O
is	O
an	O
estimate	O
of	O
the	O
size	O
of	O
speaker	O
s	O
vocal	O
tract	O
it	O
therefore	O
gives	O
a	O
strong	O
clue	O
as	O
to	O
whether	O
the	O
speaker	O
is	O
a	O
man	O
woman	O
or	O
child	O
however	O
for	O
many	O
tasks	O
it	O
is	O
difficult	O
to	O
know	O
what	O
features	O
should	O
be	O
extracted	O
for	O
example	B
suppose	O
that	O
we	O
would	O
like	O
to	O
write	O
a	O
program	O
to	O
detect	O
cars	O
in	O
photographs	O
we	O
know	O
that	O
cars	O
have	O
wheels	O
so	O
we	O
might	O
like	O
to	O
use	O
the	O
presence	O
of	O
a	O
wheel	O
as	O
a	O
feature	B
unfortunately	O
it	O
is	O
difficult	O
to	O
describe	O
exactly	O
what	O
a	O
wheel	O
looks	O
like	O
in	O
terms	O
of	O
pixel	O
values	O
a	O
wheel	O
has	O
a	O
simple	O
geometric	O
shape	O
but	O
its	O
image	O
may	O
be	O
complicated	O
by	O
shadows	O
falling	O
on	O
the	O
wheel	O
the	O
sun	O
glaring	O
off	O
the	O
metal	O
parts	O
of	O
the	O
wheel	O
the	O
fender	O
of	O
the	O
car	O
or	O
an	O
object	O
in	O
the	O
foreground	O
obscuring	O
part	O
of	O
the	O
wheel	O
and	O
so	O
on	O
chapter	O
introduction	O
figure	O
example	B
of	O
different	O
representations	O
suppose	O
we	O
want	O
to	O
separate	O
two	O
categories	O
of	O
data	O
by	O
drawing	O
a	O
line	O
between	O
them	O
in	O
a	O
scatterplot	O
in	O
the	O
plot	O
on	O
the	O
left	O
we	O
represent	O
some	O
data	O
using	O
cartesian	O
coordinates	O
and	O
the	O
task	O
is	O
impossible	O
in	O
the	O
plot	O
on	O
the	O
right	O
we	O
represent	O
the	O
data	O
with	O
polar	O
coordinates	O
and	O
the	O
task	O
becomes	O
simple	O
to	O
solve	O
with	O
a	O
vertical	O
line	O
figure	O
produced	O
in	O
collaboration	O
with	O
david	O
warde-farley	O
one	O
solution	O
to	O
this	O
problem	O
is	O
to	O
use	O
machine	B
learning	I
to	O
discover	O
not	O
only	O
the	O
mapping	O
from	O
representation	O
to	O
output	O
but	O
also	O
the	O
representation	O
itself	O
this	O
approach	O
is	O
known	O
as	O
representation	B
learning	I
learned	O
representations	O
often	O
result	O
in	O
much	O
better	O
performance	O
than	O
can	O
be	O
obtained	O
with	O
hand-designed	O
representations	O
they	O
also	O
allow	O
ai	O
systems	O
to	O
rapidly	O
adapt	O
to	O
new	O
tasks	O
with	O
minimal	O
human	O
intervention	O
a	O
representation	B
learning	I
algorithm	O
can	O
discover	O
a	O
good	O
set	O
of	O
features	O
for	O
a	O
simple	O
task	O
in	O
minutes	O
or	O
a	O
complex	O
task	O
in	O
hours	O
to	O
months	O
manually	O
designing	O
features	O
for	O
a	O
complex	O
task	O
requires	O
a	O
great	O
deal	O
of	O
human	O
time	O
and	O
effort	O
it	O
can	O
take	O
decades	O
for	O
an	O
entire	O
community	O
of	O
researchers	O
the	O
quintessential	O
example	B
of	O
a	O
representation	B
learning	I
algorithm	O
is	O
the	O
autoencoder	O
an	O
autoencoder	O
is	O
the	O
combination	O
of	O
an	O
encoder	B
function	O
that	O
converts	O
the	O
input	O
data	O
into	O
a	O
different	O
representation	O
and	O
a	O
decoder	B
function	O
that	O
converts	O
the	O
new	O
representation	O
back	O
into	O
the	O
original	O
format	O
autoencoders	O
are	O
trained	O
to	O
preserve	O
as	O
much	O
information	O
as	O
possible	O
when	O
an	O
input	O
is	O
run	O
through	O
the	O
encoder	B
and	O
then	O
the	O
decoder	B
but	O
are	O
also	O
trained	O
to	O
make	O
the	O
new	O
representation	O
have	O
various	O
nice	O
properties	O
different	O
kinds	O
of	O
autoencoders	O
aim	O
to	O
achieve	O
different	O
kinds	O
of	O
properties	O
when	O
designing	O
features	O
or	O
algorithms	O
for	O
learning	O
features	O
our	O
goal	O
is	O
usually	O
to	O
separate	O
the	O
factors	B
of	I
variation	I
that	O
explain	O
the	O
observed	O
data	O
in	O
this	O
context	O
we	O
use	O
the	O
word	O
factors	O
simply	O
to	O
refer	O
to	O
separate	O
sources	O
of	O
influence	O
the	O
factors	O
are	O
usually	O
not	O
combined	O
by	O
multiplication	O
such	O
factors	O
are	O
often	O
not	O
chapter	O
introduction	O
quantities	O
that	O
are	O
directly	O
observed	O
instead	O
they	O
may	O
exist	O
either	O
as	O
unobserved	O
objects	O
or	O
unobserved	O
forces	O
in	O
the	O
physical	O
world	O
that	O
affect	O
observable	O
quantities	O
they	O
may	O
also	O
exist	O
as	O
constructs	O
in	O
the	O
human	O
mind	O
that	O
provide	O
useful	O
simplifying	O
explanations	O
or	O
inferred	O
causes	O
of	O
the	O
observed	O
data	O
they	O
can	O
be	O
thought	O
of	O
as	O
concepts	O
or	O
abstractions	O
that	O
help	O
us	O
make	O
sense	O
of	O
the	O
rich	O
variability	O
in	O
the	O
data	O
when	O
analyzing	O
a	O
speech	O
recording	O
the	O
factors	B
of	I
variation	I
include	O
the	O
speaker	O
s	O
age	O
their	O
sex	O
their	O
accent	O
and	O
the	O
words	O
that	O
they	O
are	O
speaking	O
when	O
analyzing	O
an	O
image	O
of	O
a	O
car	O
the	O
factors	B
of	I
variation	I
include	O
the	O
position	O
of	O
the	O
car	O
its	O
color	O
and	O
the	O
angle	O
and	O
brightness	O
of	O
the	O
sun	O
a	O
major	O
source	O
of	O
difficulty	O
in	O
many	O
real-world	O
artificial	B
intelligence	I
applications	O
is	O
that	O
many	O
of	O
the	O
factors	B
of	I
variation	I
influence	O
every	O
single	O
piece	O
of	O
data	O
we	O
are	O
able	O
to	O
observe	O
the	O
individual	O
pixels	O
in	O
an	O
image	O
of	O
a	O
red	O
car	O
might	O
be	O
very	O
close	O
to	O
black	O
at	O
night	O
the	O
shape	O
of	O
the	O
car	O
s	O
silhouette	O
depends	O
on	O
the	O
viewing	O
angle	O
most	O
applications	O
require	O
us	O
to	O
the	O
factors	B
of	I
variation	I
and	O
discard	O
the	O
ones	O
that	O
we	O
do	O
not	O
care	O
about	O
disentangle	O
of	O
course	O
it	O
can	O
be	O
very	O
difficult	O
to	O
extract	O
such	O
high-level	O
abstract	O
features	O
from	O
raw	O
data	O
many	O
of	O
these	O
factors	B
of	I
variation	I
such	O
as	O
a	O
speaker	O
s	O
accent	O
can	O
be	O
identified	O
only	O
using	O
sophisticated	O
nearly	O
human-level	O
understanding	O
of	O
the	O
data	O
when	O
it	O
is	O
nearly	O
as	O
difficult	O
to	O
obtain	O
a	O
representation	O
as	O
to	O
solve	O
the	O
original	O
problem	O
representation	B
learning	I
does	O
not	O
at	O
first	O
glance	O
seem	O
to	O
help	O
us	O
deep	O
learning	O
solves	O
this	O
central	O
problem	O
in	O
representation	B
learning	I
by	O
introducing	O
representations	O
that	O
are	O
expressed	O
in	O
terms	O
of	O
other	O
simpler	O
representations	O
deep	O
learning	O
allows	O
the	O
computer	O
to	O
build	O
complex	O
concepts	O
out	O
of	O
simpler	O
concepts	O
figure	O
shows	O
how	O
a	O
deep	O
learning	O
system	O
can	O
represent	O
the	O
concept	O
of	O
an	O
image	O
of	O
a	O
person	O
by	O
combining	O
simpler	O
concepts	O
such	O
as	O
corners	O
and	O
contours	O
which	O
are	O
in	O
turn	O
defined	O
in	O
terms	O
of	O
edges	O
the	O
quintessential	O
example	B
of	O
a	O
deep	O
learning	O
model	O
is	O
the	O
feedforward	O
deep	O
network	O
or	O
multilayer	B
perceptron	I
a	O
multilayer	B
perceptron	I
is	O
just	O
a	O
mathematical	O
function	O
mapping	O
some	O
set	O
of	O
input	O
values	O
to	O
output	O
values	O
the	O
function	O
is	O
formed	O
by	O
composing	O
many	O
simpler	O
functions	O
we	O
can	O
think	O
of	O
each	O
application	O
of	O
a	O
different	O
mathematical	O
function	O
as	O
providing	O
a	O
new	O
representation	O
of	O
the	O
input	O
the	O
idea	O
of	O
learning	O
the	O
right	O
representation	O
for	O
the	O
data	O
provides	O
one	O
perspective	O
on	O
deep	O
learning	O
another	O
perspective	O
on	O
deep	O
learning	O
is	O
that	O
depth	O
allows	O
the	O
computer	O
to	O
learn	O
a	O
multi-step	O
computer	O
program	O
each	O
layer	O
of	O
the	O
representation	O
can	O
be	O
thought	O
of	O
as	O
the	O
state	O
of	O
the	O
computer	O
s	O
memory	O
after	O
executing	O
another	O
set	O
of	O
instructions	O
in	O
parallel	O
networks	O
with	O
greater	O
depth	O
can	O
execute	O
more	O
instructions	O
in	O
sequence	O
sequential	O
instructions	O
offer	O
great	O
power	O
because	O
later	O
chapter	O
introduction	O
car	O
person	O
animal	O
output	O
identity	O
hidden	B
layer	I
parts	O
hidden	B
layer	I
and	O
contours	O
hidden	B
layer	I
visible	B
layer	I
pixels	O
figure	O
illustration	O
of	O
a	O
deep	O
learning	O
model	O
it	O
is	O
difficult	O
for	O
a	O
computer	O
to	O
understand	O
the	O
meaning	O
of	O
raw	O
sensory	O
input	O
data	O
such	O
as	O
this	O
image	O
represented	O
as	O
a	O
collection	O
of	O
pixel	O
values	O
the	O
function	O
mapping	O
from	O
a	O
set	O
of	O
pixels	O
to	O
an	O
object	O
identity	O
is	O
very	O
complicated	O
learning	O
or	O
evaluating	O
this	O
mapping	O
seems	O
insurmountable	O
if	O
tackled	O
directly	O
deep	O
learning	O
resolves	O
this	O
difficulty	O
by	O
breaking	O
the	O
desired	O
complicated	O
mapping	O
into	O
a	O
series	O
of	O
nested	O
simple	O
mappings	O
each	O
described	O
by	O
a	O
different	O
layer	O
of	O
the	O
model	O
the	O
input	O
is	O
presented	O
at	O
the	O
visible	B
layer	I
so	O
named	O
because	O
it	O
contains	O
the	O
variables	O
that	O
we	O
are	O
able	O
to	O
observe	O
then	O
a	O
series	O
of	O
hidden	O
layers	O
extracts	O
increasingly	O
abstract	O
features	O
from	O
the	O
image	O
these	O
layers	O
are	O
called	O
hidden	O
because	O
their	O
values	O
are	O
not	O
given	O
in	O
the	O
data	O
instead	O
the	O
model	O
must	O
determine	O
which	O
concepts	O
are	O
useful	O
for	O
explaining	O
the	O
relationships	O
in	O
the	O
observed	O
data	O
the	O
images	O
here	O
are	O
visualizations	O
of	O
the	O
kind	O
of	O
feature	B
represented	O
by	O
each	O
hidden	O
unit	O
given	O
the	O
pixels	O
the	O
first	O
layer	O
can	O
easily	O
identify	O
edges	O
by	O
comparing	O
the	O
brightness	O
of	O
neighboring	O
pixels	O
given	O
the	O
first	O
hidden	B
layer	I
s	O
description	O
of	O
the	O
edges	O
the	O
second	O
hidden	B
layer	I
can	O
easily	O
search	O
for	O
corners	O
and	O
extended	O
contours	O
which	O
are	O
recognizable	O
as	O
collections	O
of	O
edges	O
given	O
the	O
second	O
hidden	B
layer	I
s	O
description	O
of	O
the	O
image	O
in	O
terms	O
of	O
corners	O
and	O
contours	O
the	O
third	O
hidden	B
layer	I
can	O
detect	O
entire	O
parts	O
of	O
specific	O
objects	O
by	O
finding	O
specific	O
collections	O
of	O
contours	O
and	O
corners	O
finally	O
this	O
description	O
of	O
the	O
image	O
in	O
terms	O
of	O
the	O
object	O
parts	O
it	O
contains	O
can	O
be	O
used	O
to	O
recognize	O
the	O
objects	O
present	O
in	O
the	O
image	O
images	O
reproduced	O
with	O
permission	O
from	O
zeiler	O
and	O
fergus	O
chapter	O
introduction	O
element	O
set	O
logistic	O
logistic	O
regression	B
regression	B
element	O
set	O
ww	O
xx	O
figure	O
illustration	O
of	O
computational	O
graphs	O
mapping	O
an	O
input	O
to	O
an	O
output	O
where	O
each	O
node	O
performs	O
an	O
operation	B
depth	O
is	O
the	O
length	O
of	O
the	O
longest	O
path	O
from	O
input	O
to	O
output	O
but	O
depends	O
on	O
the	O
definition	O
of	O
what	O
constitutes	O
a	O
possible	O
computational	O
step	O
the	O
computation	O
depicted	O
in	O
these	O
graphs	O
is	O
the	O
output	O
of	O
a	O
logistic	O
regression	B
model	O
x	O
where	O
is	O
the	O
logistic	O
sigmoid	O
function	O
if	O
we	O
use	O
addition	O
multiplication	O
and	O
logistic	O
sigmoids	O
as	O
the	O
elements	O
of	O
our	O
computer	O
language	O
then	O
this	O
model	O
has	O
depth	O
three	O
if	O
we	O
view	O
logistic	O
regression	B
as	O
an	O
element	O
itself	O
then	O
this	O
model	O
has	O
depth	O
one	O
instructions	O
can	O
refer	O
back	O
to	O
the	O
results	O
of	O
earlier	O
instructions	O
according	O
to	O
this	O
view	O
of	O
deep	O
learning	O
not	O
all	O
of	O
the	O
information	O
in	O
a	O
layer	O
s	O
activations	O
necessarily	O
encodes	O
factors	B
of	I
variation	I
that	O
explain	O
the	O
input	O
the	O
representation	O
also	O
stores	O
state	O
information	O
that	O
helps	O
to	O
execute	O
a	O
program	O
that	O
can	O
make	O
sense	O
of	O
the	O
input	O
this	O
state	O
information	O
could	O
be	O
analogous	O
to	O
a	O
counter	O
or	O
pointer	O
in	O
a	O
traditional	O
computer	O
program	O
it	O
has	O
nothing	O
to	O
do	O
with	O
the	O
content	O
of	O
the	O
input	O
specifically	O
but	O
it	O
helps	O
the	O
model	O
to	O
organize	O
its	O
processing	O
there	O
are	O
two	O
main	O
ways	O
of	O
measuring	O
the	O
depth	O
of	O
a	O
model	O
the	O
first	O
view	O
is	O
based	O
on	O
the	O
number	O
of	O
sequential	O
instructions	O
that	O
must	O
be	O
executed	O
to	O
evaluate	O
the	O
architecture	O
we	O
can	O
think	O
of	O
this	O
as	O
the	O
length	O
of	O
the	O
longest	O
path	O
through	O
a	O
flow	O
chart	O
that	O
describes	O
how	O
to	O
compute	O
each	O
of	O
the	O
model	O
s	O
outputs	O
given	O
its	O
inputs	O
just	O
as	O
two	O
equivalent	O
computer	O
programs	O
will	O
have	O
different	O
lengths	O
depending	O
on	O
which	O
language	O
the	O
program	O
is	O
written	O
in	O
the	O
same	O
function	O
may	O
be	O
drawn	O
as	O
a	O
flowchart	O
with	O
different	O
depths	O
depending	O
on	O
which	O
functions	O
we	O
allow	O
to	O
be	O
used	O
as	O
individual	O
steps	O
in	O
the	O
flowchart	O
figure	O
illustrates	O
how	O
this	O
choice	O
of	O
language	O
can	O
give	O
two	O
different	O
measurements	O
for	O
the	O
same	O
architecture	O
another	O
approach	O
used	O
by	O
deep	O
probabilistic	O
models	O
regards	O
the	O
depth	O
of	O
a	O
model	O
as	O
being	O
not	O
the	O
depth	O
of	O
the	O
computational	B
graph	I
but	O
the	O
depth	O
of	O
the	O
graph	O
describing	O
how	O
concepts	O
are	O
related	O
to	O
each	O
other	O
in	O
this	O
case	O
the	O
depth	O
chapter	O
introduction	O
of	O
the	O
flowchart	O
of	O
the	O
computations	O
needed	O
to	O
compute	O
the	O
representation	O
of	O
each	O
concept	O
may	O
be	O
much	O
deeper	O
than	O
the	O
graph	O
of	O
the	O
concepts	O
themselves	O
this	O
is	O
because	O
the	O
system	O
s	O
understanding	O
of	O
the	O
simpler	O
concepts	O
can	O
be	O
refined	O
given	O
information	O
about	O
the	O
more	O
complex	O
concepts	O
for	O
example	B
an	O
ai	O
system	O
observing	O
an	O
image	O
of	O
a	O
face	O
with	O
one	O
eye	O
in	O
shadow	O
may	O
initially	O
only	O
see	O
one	O
eye	O
after	O
detecting	O
that	O
a	O
face	O
is	O
present	O
it	O
can	O
then	O
infer	O
that	O
a	O
second	O
eye	O
is	O
probably	O
present	O
as	O
well	O
in	O
this	O
case	O
the	O
graph	O
of	O
concepts	O
only	O
includes	O
two	O
layers	O
a	O
layer	O
for	O
eyes	O
and	O
a	O
layer	O
for	O
faces	O
but	O
the	O
graph	O
of	O
computations	O
includes	O
layers	O
if	O
we	O
refine	O
our	O
estimate	O
of	O
each	O
concept	O
given	O
the	O
other	O
times	O
n	O
because	O
it	O
is	O
not	O
always	O
clear	O
which	O
of	O
these	O
two	O
views	O
the	O
depth	O
of	O
the	O
computational	B
graph	I
or	O
the	O
depth	O
of	O
the	O
probabilistic	O
modeling	O
graph	O
is	O
most	O
relevant	O
and	O
because	O
different	O
people	O
choose	O
different	O
sets	O
of	O
smallest	O
elements	O
from	O
which	O
to	O
construct	O
their	O
graphs	O
there	O
is	O
no	O
single	O
correct	O
value	O
for	O
the	O
depth	O
of	O
an	O
architecture	O
just	O
as	O
there	O
is	O
no	O
single	O
correct	O
value	O
for	O
the	O
length	O
of	O
a	O
computer	O
program	O
nor	O
is	O
there	O
a	O
consensus	O
about	O
how	O
much	O
depth	O
a	O
model	O
requires	O
to	O
qualify	O
as	O
deep	O
however	O
deep	O
learning	O
can	O
safely	O
be	O
regarded	O
as	O
the	O
study	O
of	O
models	O
that	O
either	O
involve	O
a	O
greater	O
amount	O
of	O
composition	O
of	O
learned	O
functions	O
or	O
learned	O
concepts	O
than	O
traditional	O
machine	B
learning	I
does	O
to	O
summarize	O
deep	O
learning	O
the	O
subject	O
of	O
this	O
book	O
is	O
an	O
approach	O
to	O
ai	O
specifically	O
it	O
is	O
a	O
type	O
of	O
machine	B
learning	I
a	O
technique	O
that	O
allows	O
computer	O
systems	O
to	O
improve	O
with	O
experience	O
and	O
data	O
according	O
to	O
the	O
authors	O
of	O
this	O
book	O
machine	B
learning	I
is	O
the	O
only	O
viable	O
approach	O
to	O
building	O
ai	O
systems	O
that	O
can	O
operate	O
in	O
complicated	O
real-world	O
environments	O
deep	O
learning	O
is	O
a	O
particular	O
kind	O
of	O
machine	B
learning	I
that	O
achieves	O
great	O
power	O
and	O
flexibility	O
by	O
learning	O
to	O
represent	O
the	O
world	O
as	O
a	O
nested	O
hierarchy	O
of	O
concepts	O
with	O
each	O
concept	O
defined	O
in	O
relation	O
to	O
simpler	O
concepts	O
and	O
more	O
abstract	O
representations	O
computed	O
in	O
terms	O
of	O
less	O
abstract	O
ones	O
figure	O
illustrates	O
the	O
relationship	O
between	O
these	O
different	O
ai	O
disciplines	O
figure	O
gives	O
a	O
high-level	O
schematic	O
of	O
how	O
each	O
works	O
who	O
should	O
read	O
this	O
book	O
this	O
book	O
can	O
be	O
useful	O
for	O
a	O
variety	O
of	O
readers	O
but	O
we	O
wrote	O
it	O
with	O
two	O
main	O
target	O
audiences	O
in	O
mind	O
one	O
of	O
these	O
target	O
audiences	O
is	O
university	O
students	O
or	O
graduate	O
learning	O
about	O
machine	B
learning	I
including	O
those	O
who	O
are	O
beginning	O
a	O
career	O
in	O
deep	O
learning	O
and	O
artificial	B
intelligence	I
research	O
the	O
other	O
target	O
audience	O
is	O
software	O
engineers	O
who	O
do	O
not	O
have	O
a	O
machine	B
learning	I
or	O
statistics	O
background	O
but	O
want	O
to	O
rapidly	O
acquire	O
one	O
and	O
begin	O
using	O
deep	O
learning	O
in	O
their	O
product	O
or	O
platform	O
deep	O
learning	O
has	O
already	O
proven	O
useful	O
in	O
chapter	O
introduction	O
deep	O
learning	O
example	B
mlps	O
example	B
shallow	O
autoencoders	O
example	B
logistic	O
regression	B
example	B
knowledge	O
bases	O
representation	B
learning	I
machine	B
learning	I
ai	O
figure	O
a	O
venn	O
diagram	O
showing	O
how	O
deep	O
learning	O
is	O
a	O
kind	O
of	O
representation	B
learning	I
which	O
is	O
in	O
turn	O
a	O
kind	O
of	O
machine	B
learning	I
which	O
is	O
used	O
for	O
many	O
but	O
not	O
all	O
approaches	O
to	O
ai	O
each	O
section	O
of	O
the	O
venn	O
diagram	O
includes	O
an	O
example	B
of	O
an	O
ai	O
technology	O
chapter	O
introduction	O
output	O
output	O
output	O
mapping	O
from	O
features	O
output	O
mapping	O
from	O
mapping	O
from	O
layers	O
of	O
more	O
additional	O
features	O
features	O
abstract	O
features	O
hand	O
designed	O
program	O
hand	O
designed	O
features	O
features	O
simple	O
features	O
input	O
input	O
input	O
input	O
rule-based	O
systems	O
classic	O
machine	B
learning	I
deep	O
learning	O
representation	B
learning	I
figure	O
flowcharts	O
showing	O
how	O
the	O
different	O
parts	O
of	O
an	O
ai	O
system	O
relate	O
to	O
each	O
other	O
within	O
different	O
ai	O
disciplines	O
shaded	O
boxes	O
indicate	O
components	O
that	O
are	O
able	O
to	O
learn	O
from	O
data	O
chapter	O
introduction	O
many	O
software	O
disciplines	O
including	O
computer	B
vision	I
speech	O
and	O
audio	O
processing	O
natural	B
language	I
processing	I
robotics	O
bioinformatics	O
and	O
chemistry	O
video	O
games	O
search	O
engines	O
online	O
advertising	O
and	O
finance	O
this	O
book	O
has	O
been	O
organized	O
into	O
three	O
parts	O
in	O
order	O
to	O
best	O
accommodate	O
a	O
introduces	O
basic	O
mathematical	O
tools	O
and	O
machine	B
learning	I
describes	O
the	O
most	O
established	O
deep	O
learning	O
algorithms	O
that	O
are	O
describes	O
more	O
speculative	O
ideas	O
that	O
are	O
variety	O
of	O
readers	O
part	O
concepts	O
part	O
essentially	O
solved	O
technologies	O
part	O
widely	O
believed	O
to	O
be	O
important	O
for	O
future	O
research	O
in	O
deep	O
learning	O
iii	O
ii	O
i	O
readers	O
should	O
feel	O
free	O
to	O
skip	O
parts	O
that	O
are	O
not	O
relevant	O
given	O
their	O
interests	O
or	O
background	O
readers	O
familiar	O
with	O
linear	O
algebra	O
probability	O
and	O
fundamental	O
machine	B
learning	I
concepts	O
can	O
skip	O
part	O
for	O
example	B
while	O
readers	O
who	O
just	O
want	O
to	O
implement	O
a	O
working	O
system	O
need	O
not	O
read	O
beyond	O
part	O
to	O
help	O
choose	O
which	O
provides	O
a	O
flowchart	O
showing	O
the	O
high-level	O
organization	O
chapters	O
to	O
read	O
figure	O
of	O
the	O
book	O
ii	O
i	O
we	O
do	O
assume	O
that	O
all	O
readers	O
come	O
from	O
a	O
computer	O
science	O
background	O
we	O
assume	O
familiarity	O
with	O
programming	O
a	O
basic	O
understanding	O
of	O
computational	O
performance	O
issues	O
complexity	O
theory	O
introductory	O
level	O
calculus	O
and	O
some	O
of	O
the	O
terminology	O
of	O
graph	O
theory	O
historical	O
trends	O
in	O
deep	O
learning	O
it	O
is	O
easiest	O
to	O
understand	O
deep	O
learning	O
with	O
some	O
historical	O
context	O
rather	O
than	O
providing	O
a	O
detailed	O
history	O
of	O
deep	O
learning	O
we	O
identify	O
a	O
few	O
key	O
trends	O
deep	O
learning	O
has	O
had	O
a	O
long	O
and	O
rich	O
history	O
but	O
has	O
gone	O
by	O
many	O
names	O
reflecting	O
different	O
philosophical	O
viewpoints	O
and	O
has	O
waxed	O
and	O
waned	O
in	O
popularity	O
deep	O
learning	O
has	O
become	O
more	O
useful	O
as	O
the	O
amount	O
of	O
available	O
training	O
data	O
has	O
increased	O
deep	O
learning	O
models	O
have	O
grown	O
in	O
size	O
over	O
time	O
as	O
computer	O
infrastructure	O
hardware	O
and	O
software	O
for	O
deep	O
learning	O
has	O
improved	O
deep	O
learning	O
has	O
solved	O
increasingly	O
complicated	O
applications	O
with	O
increasing	O
accuracy	B
over	O
time	O
chapter	O
introduction	O
introduction	O
part	O
i	O
applied	O
math	O
and	O
machine	B
learning	I
basics	O
linear	O
algebra	O
probability	O
and	O
information	O
theory	O
numerical	O
computation	O
machine	B
learning	I
basics	O
part	O
ii	O
deep	O
networks	O
modern	O
practices	O
deep	O
feedforward	O
networks	O
regularization	O
optimization	O
cnns	O
rnns	O
practical	O
methodology	O
applications	O
part	O
iii	O
deep	O
learning	O
research	O
linear	B
factor	I
models	I
autoencoders	O
representation	B
learning	I
structured	O
probabilistic	O
models	O
inference	O
monte	O
carlo	O
methods	O
partition	O
function	O
deep	O
generative	O
models	O
figure	O
the	O
high-level	O
organization	O
of	O
the	O
book	O
an	O
arrow	O
from	O
one	O
chapter	O
to	O
another	O
indicates	O
that	O
the	O
former	O
chapter	O
is	O
prerequisite	O
material	O
for	O
understanding	O
the	O
latter	O
chapter	O
introduction	O
the	O
many	O
names	O
and	O
changing	O
fortunes	O
of	O
neural	O
net	O
works	O
we	O
expect	O
that	O
many	O
readers	O
of	O
this	O
book	O
have	O
heard	O
of	O
deep	O
learning	O
as	O
an	O
exciting	O
new	O
technology	O
and	O
are	O
surprised	O
to	O
see	O
a	O
mention	O
of	O
history	O
in	O
a	O
book	O
about	O
an	O
emerging	O
field	O
in	O
fact	O
deep	O
learning	O
dates	O
back	O
to	O
the	O
deep	O
learning	O
only	O
appears	O
to	O
be	O
new	O
because	O
it	O
was	O
relatively	O
unpopular	O
for	O
several	O
years	O
preceding	O
its	O
current	O
popularity	O
and	O
because	O
it	O
has	O
gone	O
through	O
many	O
different	O
names	O
and	O
has	O
only	O
recently	O
become	O
called	O
deep	O
learning	O
the	O
field	O
has	O
been	O
rebranded	O
many	O
times	O
reflecting	O
the	O
influence	O
of	O
different	O
researchers	O
and	O
different	O
perspectives	O
a	O
comprehensive	O
history	O
of	O
deep	O
learning	O
is	O
beyond	O
the	O
scope	O
of	O
this	O
textbook	O
however	O
some	O
basic	O
context	O
is	O
useful	O
for	O
understanding	O
deep	O
learning	O
broadly	O
speaking	O
there	O
have	O
been	O
three	O
waves	O
of	O
development	O
of	O
deep	O
learning	O
deep	O
learning	O
known	O
as	O
cybernetics	O
in	O
the	O
deep	O
learning	O
known	O
as	O
connectionism	B
in	O
the	O
and	O
the	O
current	O
resurgence	O
under	O
the	O
name	O
deep	O
learning	O
beginning	O
in	O
this	O
is	O
quantitatively	O
illustrated	O
in	O
figure	O
some	O
of	O
the	O
earliest	O
learning	O
algorithms	O
we	O
recognize	O
today	O
were	O
intended	O
to	O
be	O
computational	O
models	O
of	O
biological	O
learning	O
i	O
e	O
models	O
of	O
how	O
learning	O
happens	O
or	O
could	O
happen	O
in	O
the	O
brain	O
as	O
a	O
result	O
one	O
of	O
the	O
names	O
that	O
deep	O
learning	O
has	O
gone	O
by	O
is	O
artificial	O
neural	O
networks	O
the	O
corresponding	O
perspective	O
on	O
deep	O
learning	O
models	O
is	O
that	O
they	O
are	O
engineered	O
systems	O
inspired	O
by	O
the	O
biological	O
brain	O
the	O
human	O
brain	O
or	O
the	O
brain	O
of	O
another	O
animal	O
while	O
the	O
kinds	O
of	O
neural	O
networks	O
used	O
for	O
machine	B
learning	I
have	O
sometimes	O
been	O
used	O
to	O
understand	O
brain	O
function	O
they	O
are	O
generally	O
not	O
designed	O
to	O
be	O
realistic	O
models	O
of	O
biological	O
function	O
the	O
neural	O
perspective	O
on	O
deep	O
learning	O
is	O
motivated	O
by	O
two	O
main	O
ideas	O
one	O
idea	O
is	O
that	O
the	O
brain	O
provides	O
a	O
proof	O
by	O
example	B
that	O
intelligent	O
behavior	O
is	O
possible	O
and	O
a	O
conceptually	O
straightforward	O
path	O
to	O
building	O
intelligence	O
is	O
to	O
reverse	O
engineer	O
the	O
computational	O
principles	O
behind	O
the	O
brain	O
and	O
duplicate	O
its	O
functionality	O
another	O
perspective	O
is	O
that	O
it	O
would	O
be	O
deeply	O
interesting	O
to	O
understand	O
the	O
brain	O
and	O
the	O
principles	O
that	O
underlie	O
human	O
intelligence	O
so	O
machine	B
learning	I
models	O
that	O
shed	O
light	O
on	O
these	O
basic	O
scientific	O
questions	O
are	O
useful	O
apart	O
from	O
their	O
ability	O
to	O
solve	O
engineering	O
applications	O
hinton	O
and	O
shallice	O
the	O
modern	O
term	O
deep	O
learning	O
goes	O
beyond	O
the	O
neuroscientific	O
perspective	O
on	O
the	O
current	O
breed	O
of	O
machine	B
learning	I
models	O
it	O
appeals	O
to	O
a	O
more	O
general	O
principle	O
of	O
learning	O
multiple	O
levels	O
of	O
composition	O
which	O
can	O
be	O
applied	O
in	O
machine	B
learning	I
frameworks	O
that	O
are	O
not	O
necessarily	O
neurally	O
inspired	O
chapter	O
introduction	O
e	O
s	O
a	O
r	O
h	O
p	O
r	O
o	O
d	O
r	O
o	O
w	O
f	O
o	O
y	O
c	O
n	O
e	O
u	O
q	O
e	O
r	O
f	O
cybernetics	O
neural	O
networks	O
year	O
mcculloch	O
and	O
pitts	O
hebb	O
figure	O
the	O
figure	O
shows	O
two	O
of	O
the	O
three	O
historical	O
waves	O
of	O
artificial	O
neural	O
nets	O
research	O
as	O
measured	O
by	O
the	O
frequency	O
of	O
the	O
phrases	O
cybernetics	O
and	O
connectionism	B
or	O
neural	O
networks	O
according	O
to	O
google	O
books	O
third	O
wave	O
is	O
too	O
recent	O
to	O
appear	O
the	O
first	O
wave	O
started	O
with	O
cybernetics	O
in	O
the	O
with	O
the	O
development	O
of	O
theories	O
of	O
biological	O
learning	O
and	O
implementations	O
of	O
the	O
first	O
models	O
such	O
as	O
the	O
perceptron	O
allowing	O
the	O
training	O
of	O
a	O
single	O
neuron	O
the	O
second	O
wave	O
started	O
with	O
the	O
connectionist	O
approach	O
of	O
the	O
period	O
with	O
back-propagation	B
to	O
train	O
a	O
neural	B
network	I
with	O
one	O
or	O
two	O
hidden	O
layers	O
the	O
current	O
and	O
third	O
wave	O
deep	O
learning	O
started	O
around	O
and	O
is	O
just	O
now	O
appearing	O
in	O
book	O
et	O
al	O
form	O
as	O
of	O
the	O
other	O
two	O
waves	O
similarly	O
appeared	O
in	O
book	O
form	O
much	O
later	O
than	O
the	O
corresponding	O
scientific	O
activity	O
occurred	O
ranzato	O
rumelhart	O
et	O
al	O
et	O
al	O
bengio	O
et	O
al	O
chapter	O
introduction	O
the	O
earliest	O
predecessors	O
of	O
modern	O
deep	O
learning	O
were	O
simple	O
linear	O
models	O
motivated	O
from	O
a	O
neuroscientific	O
perspective	O
these	O
models	O
were	O
designed	O
to	O
take	O
a	O
set	O
of	O
n	O
input	O
values	O
xn	O
and	O
associate	O
them	O
with	O
an	O
output	O
y	O
these	O
models	O
would	O
learn	O
a	O
set	O
of	O
weights	B
wn	O
and	O
compute	O
their	O
output	O
fx	O
w	O
xnwn	O
this	O
first	O
wave	O
of	O
neural	O
networks	O
research	O
was	O
known	O
as	O
cybernetics	O
as	O
illustrated	O
in	O
figure	O
mcculloch	O
and	O
pitts	O
the	O
mcculloch-pitts	O
neuron	O
was	O
an	O
early	O
model	O
of	O
brain	O
function	O
this	O
linear	O
model	O
could	O
recognize	O
two	O
different	O
categories	O
of	O
inputs	O
by	O
testing	O
whether	O
f	O
w	O
is	O
positive	O
or	O
negative	O
of	O
course	O
for	O
the	O
model	O
to	O
correspond	O
to	O
the	O
desired	O
definition	O
of	O
the	O
categories	O
the	O
weights	B
needed	O
to	O
be	O
set	O
correctly	O
these	O
weights	B
could	O
be	O
set	O
by	O
the	O
human	O
operator	O
in	O
the	O
the	O
perceptron	O
became	O
the	O
first	O
model	O
that	O
could	O
learn	O
the	O
weights	B
defining	O
the	O
categories	O
given	O
examples	O
of	O
inputs	O
from	O
each	O
category	O
the	O
adaptive	O
linear	O
element	O
which	O
dates	O
from	O
about	O
the	O
same	O
time	O
simply	O
returned	O
the	O
value	O
of	O
f	O
itself	O
to	O
predict	O
a	O
real	O
number	O
and	O
hoff	O
and	O
could	O
also	O
learn	O
to	O
predict	O
these	O
numbers	O
from	O
data	O
these	O
simple	O
learning	O
algorithms	O
greatly	O
affected	O
the	O
modern	O
landscape	O
of	O
machine	B
learning	I
the	O
training	O
algorithm	O
used	O
to	O
adapt	O
the	O
weights	B
of	O
the	O
adaline	O
was	O
a	O
special	O
case	O
of	O
an	O
algorithm	O
called	O
stochastic	O
gradient	B
descent	O
slightly	O
modified	O
versions	O
of	O
the	O
stochastic	O
gradient	B
descent	O
algorithm	O
remain	O
the	O
dominant	O
training	O
algorithms	O
for	O
deep	O
learning	O
models	O
today	O
models	O
based	O
on	O
the	O
fx	O
w	O
used	O
by	O
the	O
perceptron	O
and	O
adaline	O
are	O
called	O
linear	O
models	O
these	O
models	O
remain	O
some	O
of	O
the	O
most	O
widely	O
used	O
machine	B
learning	I
models	O
though	O
in	O
many	O
cases	O
they	O
are	O
trained	O
in	O
different	O
ways	O
than	O
the	O
original	O
models	O
were	O
trained	O
linear	O
models	O
have	O
many	O
limitations	O
most	O
famously	O
they	O
cannot	O
learn	O
the	O
xor	O
function	O
where	O
f	O
w	O
and	O
w	O
but	O
w	O
and	O
f	O
w	O
critics	O
who	O
observed	O
these	O
flaws	O
in	O
linear	O
models	O
caused	O
a	O
backlash	O
against	O
biologically	O
inspired	O
learning	O
in	O
general	O
and	O
papert	O
this	O
was	O
the	O
first	O
major	O
dip	O
in	O
the	O
popularity	O
of	O
neural	O
networks	O
today	O
neuroscience	B
is	O
regarded	O
as	O
an	O
important	O
source	O
of	O
inspiration	O
for	O
deep	O
learning	O
researchers	O
but	O
it	O
is	O
no	O
longer	O
the	O
predominant	O
guide	O
for	O
the	O
field	O
the	O
main	O
reason	O
for	O
the	O
diminished	O
role	O
of	O
neuroscience	B
in	O
deep	O
learning	O
research	O
today	O
is	O
that	O
we	O
simply	O
do	O
not	O
have	O
enough	O
information	O
about	O
the	O
brain	O
to	O
use	O
it	O
as	O
a	O
guide	O
to	O
obtain	O
a	O
deep	O
understanding	O
of	O
the	O
actual	O
algorithms	O
used	O
by	O
the	O
brain	O
we	O
would	O
need	O
to	O
be	O
able	O
to	O
monitor	O
the	O
activity	O
of	O
the	O
very	O
least	O
thousands	O
of	O
interconnected	O
neurons	O
simultaneously	O
because	O
we	O
are	O
not	O
able	O
to	O
do	O
this	O
we	O
are	O
far	O
from	O
understanding	O
even	O
some	O
of	O
the	O
most	O
simple	O
and	O
chapter	O
introduction	O
well-studied	O
parts	O
of	O
the	O
brain	O
olshausen	O
and	O
field	O
neuroscience	B
has	O
given	O
us	O
a	O
reason	O
to	O
hope	O
that	O
a	O
single	O
deep	O
learning	O
algorithm	O
can	O
solve	O
many	O
different	O
tasks	O
neuroscientists	O
have	O
found	O
that	O
ferrets	O
can	O
learn	O
to	O
see	O
with	O
the	O
auditory	O
processing	O
region	O
of	O
their	O
brain	O
if	O
their	O
brains	O
are	O
rewired	O
to	O
send	O
visual	O
signals	O
to	O
that	O
area	O
melchner	O
this	O
suggests	O
that	O
much	O
of	O
the	O
mammalian	O
brain	O
might	O
use	O
a	O
single	O
algorithm	O
to	O
solve	O
most	O
of	O
the	O
different	O
tasks	O
that	O
the	O
brain	O
solves	O
before	O
this	O
hypothesis	O
machine	B
learning	I
research	O
was	O
more	O
fragmented	O
with	O
different	O
communities	O
of	O
researchers	O
studying	O
natural	B
language	I
processing	I
vision	O
motion	O
planning	O
and	O
speech	O
recognition	O
today	O
these	O
application	O
communities	O
are	O
still	O
separate	O
but	O
it	O
is	O
common	O
for	O
deep	O
learning	O
research	O
groups	O
to	O
study	O
many	O
or	O
even	O
all	O
of	O
these	O
application	O
areas	O
simultaneously	O
et	O
al	O
lecun	O
et	O
al	O
we	O
are	O
able	O
to	O
draw	O
some	O
rough	O
guidelines	O
from	O
neuroscience	B
the	O
basic	O
idea	O
of	O
having	O
many	O
computational	O
units	O
that	O
become	O
intelligent	O
only	O
via	O
their	O
interactions	O
with	O
each	O
other	O
is	O
inspired	O
by	O
the	O
brain	O
the	O
neocognitron	O
introduced	O
a	O
powerful	O
model	O
architecture	O
for	O
processing	O
images	O
that	O
was	O
inspired	O
by	O
the	O
structure	O
of	O
the	O
mammalian	O
visual	O
system	O
and	O
later	O
became	O
the	O
basis	O
for	O
the	O
modern	O
convolutional	B
network	I
as	O
we	O
will	O
see	O
in	O
most	O
neural	O
networks	O
today	O
are	O
based	O
on	O
a	O
model	O
neuron	O
called	O
section	O
the	O
rectified	O
linear	O
unit	O
the	O
original	O
cognitron	O
introduced	O
a	O
more	O
complicated	O
version	O
that	O
was	O
highly	O
inspired	O
by	O
our	O
knowledge	O
of	O
brain	O
function	O
the	O
simplified	O
modern	O
version	O
was	O
developed	O
incorporating	O
ideas	O
from	O
many	O
viewpoints	O
with	O
citing	O
neuroscience	B
as	O
an	O
influence	O
and	O
citing	O
more	O
engineeringoriented	O
influences	O
while	O
neuroscience	B
is	O
an	O
important	O
source	O
of	O
inspiration	O
it	O
need	O
not	O
be	O
taken	O
as	O
a	O
rigid	O
guide	O
we	O
know	O
that	O
actual	O
neurons	O
compute	O
very	O
different	O
functions	O
than	O
modern	O
rectified	O
linear	O
units	O
but	O
greater	O
neural	O
realism	O
has	O
not	O
yet	O
led	O
to	O
an	O
improvement	O
in	O
machine	B
learning	I
performance	O
also	O
while	O
neuroscience	B
has	O
successfully	O
inspired	O
several	O
neural	B
network	I
architectures	O
we	O
do	O
not	O
yet	O
know	O
enough	O
about	O
biological	O
learning	O
for	O
neuroscience	B
to	O
offer	O
much	O
guidance	O
for	O
the	O
learning	O
algorithms	O
we	O
use	O
to	O
train	O
these	O
architectures	O
nair	O
and	O
hinton	O
jarrett	O
et	O
al	O
glorot	O
et	O
al	O
and	O
media	O
accounts	O
often	O
emphasize	O
the	O
similarity	O
of	O
deep	O
learning	O
to	O
the	O
brain	O
while	O
it	O
is	O
true	O
that	O
deep	O
learning	O
researchers	O
are	O
more	O
likely	O
to	O
cite	O
the	O
brain	O
as	O
an	O
influence	O
than	O
researchers	O
working	O
in	O
other	O
machine	B
learning	I
fields	O
such	O
as	O
kernel	O
machines	O
or	O
bayesian	B
statistics	I
one	O
should	O
not	O
view	O
deep	O
learning	O
as	O
an	O
attempt	O
to	O
simulate	O
the	O
brain	O
modern	O
deep	O
learning	O
draws	O
inspiration	O
from	O
many	O
fields	O
especially	O
applied	O
math	O
fundamentals	O
like	O
linear	O
algebra	O
probability	O
information	O
theory	O
and	O
numerical	O
optimization	O
while	O
some	O
deep	O
learning	O
researchers	O
cite	O
neuroscience	B
as	O
an	O
important	O
source	O
of	O
inspiration	O
others	O
are	O
not	O
concerned	O
with	O
chapter	O
introduction	O
neuroscience	B
at	O
all	O
it	O
is	O
worth	O
noting	O
that	O
the	O
effort	O
to	O
understand	O
how	O
the	O
brain	O
works	O
on	O
an	O
algorithmic	O
level	O
is	O
alive	O
and	O
well	O
this	O
endeavor	O
is	O
primarily	O
known	O
as	O
computational	O
neuroscience	B
and	O
is	O
a	O
separate	O
field	O
of	O
study	O
from	O
deep	O
learning	O
it	O
is	O
common	O
for	O
researchers	O
to	O
move	O
back	O
and	O
forth	O
between	O
both	O
fields	O
the	O
field	O
of	O
deep	O
learning	O
is	O
primarily	O
concerned	O
with	O
how	O
to	O
build	O
computer	O
systems	O
that	O
are	O
able	O
to	O
successfully	O
solve	O
tasks	O
requiring	O
intelligence	O
while	O
the	O
field	O
of	O
computational	O
neuroscience	B
is	O
primarily	O
concerned	O
with	O
building	O
more	O
accurate	O
models	O
of	O
how	O
the	O
brain	O
actually	O
works	O
rumelhart	O
et	O
al	O
mcclelland	O
et	O
al	O
in	O
the	O
the	O
second	O
wave	O
of	O
neural	B
network	I
research	O
emerged	O
in	O
great	O
part	O
via	O
a	O
movement	O
called	O
connectionism	B
or	O
parallel	B
distributed	I
processing	I
connectionism	B
arose	O
in	O
the	O
context	O
of	O
cognitive	O
science	O
cognitive	O
science	O
is	O
an	O
interdisciplinary	O
approach	O
to	O
understanding	O
the	O
mind	O
combining	O
multiple	O
different	O
levels	O
of	O
analysis	O
during	O
the	O
early	O
most	O
cognitive	O
scientists	O
studied	O
models	O
of	O
symbolic	O
reasoning	O
despite	O
their	O
popularity	O
symbolic	O
models	O
were	O
difficult	O
to	O
explain	O
in	O
terms	O
of	O
how	O
the	O
brain	O
could	O
actually	O
implement	O
them	O
using	O
neurons	O
the	O
connectionists	O
began	O
to	O
study	O
models	O
of	O
cognition	O
that	O
could	O
actually	O
be	O
grounded	O
in	O
neural	O
implementations	O
and	O
minton	O
reviving	O
many	O
ideas	O
dating	O
back	O
to	O
the	O
work	O
of	O
psychologist	O
donald	O
hebb	O
in	O
the	O
hebb	O
the	O
central	O
idea	O
in	O
connectionism	B
is	O
that	O
a	O
large	O
number	O
of	O
simple	O
computational	O
units	O
can	O
achieve	O
intelligent	O
behavior	O
when	O
networked	O
together	O
this	O
insight	O
applies	O
equally	O
to	O
neurons	O
in	O
biological	O
nervous	O
systems	O
and	O
to	O
hidden	O
units	O
in	O
computational	O
models	O
several	O
key	O
concepts	O
arose	O
during	O
the	O
connectionism	B
movement	O
of	O
the	O
that	O
remain	O
central	O
to	O
today	O
s	O
deep	O
learning	O
one	O
of	O
these	O
concepts	O
is	O
that	O
of	O
distributed	O
representation	O
et	O
al	O
this	O
is	O
the	O
idea	O
that	O
each	O
input	O
to	O
a	O
system	O
should	O
be	O
represented	O
by	O
many	O
features	O
and	O
each	O
feature	B
should	O
be	O
involved	O
in	O
the	O
representation	O
of	O
many	O
possible	O
inputs	O
for	O
example	B
suppose	O
we	O
have	O
a	O
vision	O
system	O
that	O
can	O
recognize	O
cars	O
trucks	O
and	O
birds	O
and	O
these	O
objects	O
can	O
each	O
be	O
red	O
green	O
or	O
blue	O
one	O
way	O
of	O
representing	O
these	O
inputs	O
would	O
be	O
to	O
have	O
a	O
separate	O
neuron	O
or	O
hidden	O
unit	O
that	O
activates	O
for	O
each	O
of	O
the	O
nine	O
possible	O
combinations	O
red	O
truck	O
red	O
car	O
red	O
bird	O
green	O
truck	O
and	O
so	O
on	O
this	O
requires	O
nine	O
different	O
neurons	O
and	O
each	O
neuron	O
must	O
independently	O
learn	O
the	O
concept	O
of	O
color	O
and	O
object	O
identity	O
one	O
way	O
to	O
improve	O
on	O
this	O
situation	O
is	O
to	O
use	O
a	O
distributed	O
representation	O
with	O
three	O
neurons	O
describing	O
the	O
color	O
and	O
three	O
neurons	O
describing	O
the	O
object	O
identity	O
this	O
requires	O
only	O
six	O
neurons	O
total	O
instead	O
of	O
nine	O
and	O
the	O
neuron	O
describing	O
redness	O
is	O
able	O
to	O
chapter	O
introduction	O
learn	O
about	O
redness	O
from	O
images	O
of	O
cars	O
trucks	O
and	O
birds	O
not	O
only	O
from	O
images	O
of	O
one	O
specific	O
category	O
of	O
objects	O
the	O
concept	O
of	O
distributed	O
representation	O
is	O
central	O
to	O
this	O
book	O
and	O
will	O
be	O
described	O
in	O
greater	O
detail	O
in	O
chapter	O
another	O
major	O
accomplishment	O
of	O
the	O
connectionist	O
movement	O
was	O
the	O
successful	O
use	O
of	O
back-propagation	B
to	O
train	O
deep	O
neural	O
networks	O
with	O
internal	O
representations	O
and	O
the	O
popularization	O
of	O
the	O
back-propagation	B
algorithm	O
et	O
al	O
this	O
algorithm	O
has	O
waxed	O
and	O
waned	O
in	O
popularity	O
but	O
as	O
of	O
this	O
writing	O
is	O
currently	O
the	O
dominant	O
approach	O
to	O
training	O
deep	O
models	O
lecun	O
hochreiter	O
during	O
the	O
researchers	O
made	O
important	O
advances	O
in	O
modeling	O
sequences	O
identified	O
some	O
of	O
with	O
neural	O
networks	O
the	O
fundamental	O
mathematical	O
difficulties	O
in	O
modeling	O
long	O
sequences	O
described	O
in	O
section	O
introduced	O
the	O
long	O
short-term	O
memory	O
or	O
lstm	O
network	O
to	O
resolve	O
some	O
of	O
these	O
difficulties	O
today	O
the	O
lstm	O
is	O
widely	O
used	O
for	O
many	O
sequence	O
modeling	O
tasks	O
including	O
many	O
natural	B
language	I
processing	I
tasks	O
at	O
google	O
hochreiter	O
and	O
schmidhuber	O
bengio	O
et	O
al	O
and	O
the	O
second	O
wave	O
of	O
neural	O
networks	O
research	O
lasted	O
until	O
the	O
ventures	O
based	O
on	O
neural	O
networks	O
and	O
other	O
ai	O
technologies	O
began	O
to	O
make	O
unrealistically	O
ambitious	O
claims	O
while	O
seeking	O
investments	O
when	O
ai	O
research	O
did	O
not	O
fulfill	O
these	O
unreasonable	O
expectations	O
investors	O
were	O
disappointed	O
simultaneously	O
other	O
fields	O
of	O
machine	B
learning	I
made	O
advances	O
kernel	O
machines	O
boser	O
et	O
al	O
cortes	O
and	O
vapnik	O
sch	O
lkopf	O
jor	O
both	O
achieved	O
good	O
results	O
on	O
many	O
important	O
tasks	O
these	O
two	O
factors	O
dan	O
led	O
to	O
a	O
decline	O
in	O
the	O
popularity	O
of	O
neural	O
networks	O
that	O
lasted	O
until	O
and	O
graphical	O
models	O
et	O
al	O
lecun	O
et	O
al	O
bengio	O
et	O
al	O
during	O
this	O
time	O
neural	O
networks	O
continued	O
to	O
obtain	O
impressive	O
performance	O
the	O
canadian	O
institute	O
on	O
some	O
tasks	O
for	O
advanced	O
research	O
helped	O
to	O
keep	O
neural	O
networks	O
research	O
alive	O
via	O
its	O
neural	O
computation	O
and	O
adaptive	O
perception	O
research	O
initiative	O
this	O
program	O
united	O
machine	B
learning	I
research	O
groups	O
led	O
by	O
geoffrey	O
hinton	O
at	O
university	O
of	O
toronto	O
yoshua	O
bengio	O
at	O
university	O
of	O
montreal	O
and	O
yann	O
lecun	O
at	O
new	O
york	O
university	O
the	O
cifar	O
ncap	O
research	O
initiative	O
had	O
a	O
multi-disciplinary	O
nature	O
that	O
also	O
included	O
neuroscientists	O
and	O
experts	O
in	O
human	O
and	O
computer	B
vision	I
at	O
this	O
point	O
in	O
time	O
deep	O
networks	O
were	O
generally	O
believed	O
to	O
be	O
very	O
difficult	O
to	O
train	O
we	O
now	O
know	O
that	O
algorithms	O
that	O
have	O
existed	O
since	O
the	O
work	O
quite	O
well	O
but	O
this	O
was	O
not	O
apparent	O
circa	O
the	O
issue	O
is	O
perhaps	O
simply	O
that	O
these	O
algorithms	O
were	O
too	O
computationally	O
costly	O
to	O
allow	O
much	O
experimentation	O
with	O
the	O
hardware	O
available	O
at	O
the	O
time	O
the	O
third	O
wave	O
of	O
neural	O
networks	O
research	O
began	O
with	O
a	O
breakthrough	O
in	O
chapter	O
introduction	O
et	O
al	O
hinton	O
et	O
al	O
which	O
will	O
be	O
described	O
in	O
more	O
detail	O
in	O
section	O
geoffrey	O
hinton	O
showed	O
that	O
a	O
kind	O
of	O
neural	B
network	I
called	O
a	O
deep	O
belief	O
network	O
could	O
be	O
efficiently	O
trained	O
using	O
a	O
strategy	O
called	O
greedy	O
layer-wise	O
pretraining	O
the	O
other	O
cifar-affiliated	O
research	O
groups	O
quickly	O
showed	O
that	O
the	O
same	O
strategy	O
could	O
be	O
used	O
to	O
train	O
many	O
other	O
kinds	O
of	O
deep	O
networks	O
bengio	O
et	O
al	O
ranzato	O
and	O
systematically	O
helped	O
to	O
improve	O
generalization	B
on	O
test	O
examples	O
this	O
wave	O
of	O
neural	O
networks	O
research	O
popularized	O
the	O
use	O
of	O
the	O
term	O
deep	O
learning	O
to	O
emphasize	O
that	O
researchers	O
were	O
now	O
able	O
to	O
train	O
deeper	O
neural	O
networks	O
than	O
had	O
been	O
possible	O
before	O
and	O
to	O
focus	O
attention	O
on	O
the	O
theoretical	O
importance	O
of	O
depth	O
bengio	O
and	O
lecun	O
delalleau	O
and	O
bengio	O
pascanu	O
at	O
this	O
time	O
deep	O
neural	O
networks	O
outperformed	O
competing	O
ai	O
systems	O
based	O
on	O
other	O
machine	B
learning	I
technologies	O
as	O
well	O
as	O
hand-designed	O
functionality	O
this	O
third	O
wave	O
of	O
popularity	O
of	O
neural	O
networks	O
continues	O
to	O
the	O
time	O
of	O
this	O
writing	O
though	O
the	O
focus	O
of	O
deep	O
learning	O
research	O
has	O
changed	O
dramatically	O
within	O
the	O
time	O
of	O
this	O
wave	O
the	O
third	O
wave	O
began	O
with	O
a	O
focus	O
on	O
new	O
unsupervised	O
learning	O
techniques	O
and	O
the	O
ability	O
of	O
deep	O
models	O
to	O
generalize	O
well	O
from	O
small	O
datasets	O
but	O
today	O
there	O
is	O
more	O
interest	O
in	O
much	O
older	O
supervised	B
learning	I
algorithms	O
and	O
the	O
ability	O
of	O
deep	O
models	O
to	O
leverage	O
large	O
labeled	O
datasets	O
et	O
al	O
montufar	O
et	O
al	O
increasing	O
dataset	B
sizes	O
one	O
may	O
wonder	O
why	O
deep	O
learning	O
has	O
only	O
recently	O
become	O
recognized	O
as	O
a	O
crucial	O
technology	O
though	O
the	O
first	O
experiments	O
with	O
artificial	O
neural	O
networks	O
were	O
conducted	O
in	O
the	O
deep	O
learning	O
has	O
been	O
successfully	O
used	O
in	O
commercial	O
applications	O
since	O
the	O
but	O
was	O
often	O
regarded	O
as	O
being	O
more	O
of	O
an	O
art	O
than	O
a	O
technology	O
and	O
something	O
that	O
only	O
an	O
expert	O
could	O
use	O
until	O
recently	O
it	O
is	O
true	O
that	O
some	O
skill	O
is	O
required	O
to	O
get	O
good	O
performance	O
from	O
a	O
deep	O
learning	O
algorithm	O
fortunately	O
the	O
amount	O
of	O
skill	O
required	O
reduces	O
as	O
the	O
amount	O
of	O
training	O
data	O
increases	O
the	O
learning	O
algorithms	O
reaching	O
human	O
performance	O
on	O
complex	O
tasks	O
today	O
are	O
nearly	O
identical	O
to	O
the	O
learning	O
algorithms	O
that	O
struggled	O
to	O
solve	O
toy	O
problems	O
in	O
the	O
though	O
the	O
models	O
we	O
train	O
with	O
these	O
algorithms	O
have	O
undergone	O
changes	O
that	O
simplify	O
the	O
training	O
of	O
very	O
deep	O
architectures	O
the	O
most	O
important	O
new	O
development	O
is	O
that	O
today	O
we	O
can	O
provide	O
these	O
algorithms	O
with	O
the	O
resources	O
they	O
need	O
to	O
succeed	O
figure	O
shows	O
how	O
the	O
size	O
of	O
benchmark	O
datasets	O
has	O
increased	O
remarkably	O
over	O
time	O
this	O
trend	O
is	O
driven	O
by	O
the	O
increasing	O
digitization	O
of	O
society	O
as	O
more	O
and	O
more	O
of	O
our	O
activities	O
take	O
place	O
on	O
computers	O
more	O
and	O
more	O
of	O
what	O
we	O
do	O
is	O
recorded	O
as	O
our	O
computers	O
are	O
increasingly	O
networked	O
together	O
it	O
becomes	O
easier	O
to	O
centralize	O
these	O
records	O
and	O
curate	O
them	O
chapter	O
introduction	O
into	O
a	O
dataset	B
appropriate	O
for	O
machine	B
learning	I
applications	O
the	O
age	O
of	O
big	O
data	O
has	O
made	O
machine	B
learning	I
much	O
easier	O
because	O
the	O
key	O
burden	O
of	O
statistical	O
estimation	O
generalizing	O
well	O
to	O
new	O
data	O
after	O
observing	O
only	O
a	O
small	O
amount	O
of	O
data	O
has	O
been	O
considerably	O
lightened	O
as	O
of	O
a	O
rough	O
rule	O
of	O
thumb	O
is	O
that	O
a	O
supervised	O
deep	O
learning	O
algorithm	O
will	O
generally	O
achieve	O
acceptable	O
performance	O
with	O
around	O
labeled	O
examples	O
per	O
category	O
and	O
will	O
match	O
or	O
exceed	O
human	O
performance	O
when	O
trained	O
with	O
a	O
dataset	B
containing	O
at	O
least	O
million	O
labeled	O
examples	O
working	O
successfully	O
with	O
datasets	O
smaller	O
than	O
this	O
is	O
an	O
important	O
research	O
area	O
focusing	O
in	O
particular	O
on	O
how	O
we	O
can	O
take	O
advantage	O
of	O
large	O
quantities	O
of	O
unlabeled	O
examples	O
with	O
unsupervised	O
or	O
semi-supervised	B
learning	I
increasing	O
model	O
sizes	O
another	O
key	O
reason	O
that	O
neural	O
networks	O
are	O
wildly	O
successful	O
today	O
after	O
enjoying	O
comparatively	O
little	O
success	O
since	O
the	O
is	O
that	O
we	O
have	O
the	O
computational	O
resources	O
to	O
run	O
much	O
larger	O
models	O
today	O
one	O
of	O
the	O
main	O
insights	O
of	O
connectionism	B
is	O
that	O
animals	O
become	O
intelligent	O
when	O
many	O
of	O
their	O
neurons	O
work	O
together	O
an	O
individual	O
neuron	O
or	O
small	O
collection	O
of	O
neurons	O
is	O
not	O
particularly	O
useful	O
biological	O
neurons	O
are	O
not	O
especially	O
densely	O
connected	O
as	O
seen	O
in	O
figure	O
our	O
machine	B
learning	I
models	O
have	O
had	O
a	O
number	O
of	O
connections	O
per	O
neuron	O
that	O
was	O
within	O
an	O
order	O
of	O
magnitude	O
of	O
even	O
mammalian	O
brains	O
for	O
decades	O
in	O
terms	O
of	O
the	O
total	O
number	O
of	O
neurons	O
neural	O
networks	O
have	O
been	O
astonishingly	O
small	O
until	O
quite	O
recently	O
as	O
shown	O
in	O
figure	O
since	O
the	O
introduction	O
of	O
hidden	O
units	O
artificial	O
neural	O
networks	O
have	O
doubled	O
in	O
size	O
roughly	O
every	O
years	O
this	O
growth	O
is	O
driven	O
by	O
faster	O
computers	O
with	O
larger	O
memory	O
and	O
by	O
the	O
availability	O
of	O
larger	O
datasets	O
larger	O
networks	O
are	O
able	O
to	O
achieve	O
higher	O
accuracy	B
on	O
more	O
complex	O
tasks	O
this	O
trend	O
looks	O
set	O
to	O
continue	O
for	O
decades	O
unless	O
new	O
technologies	O
allow	O
faster	O
scaling	O
artificial	O
neural	O
networks	O
will	O
not	O
have	O
the	O
same	O
number	O
of	O
neurons	O
as	O
the	O
human	O
brain	O
until	O
at	O
least	O
the	O
biological	O
neurons	O
may	O
represent	O
more	O
complicated	O
functions	O
than	O
current	O
artificial	O
neurons	O
so	O
biological	O
neural	O
networks	O
may	O
be	O
even	O
larger	O
than	O
this	O
plot	O
portrays	O
in	O
retrospect	O
it	O
is	O
not	O
particularly	O
surprising	O
that	O
neural	O
networks	O
with	O
fewer	O
neurons	O
than	O
a	O
leech	O
were	O
unable	O
to	O
solve	O
sophisticated	O
artificial	B
intelligence	I
problems	O
even	O
today	O
s	O
networks	O
which	O
we	O
consider	O
quite	O
large	O
from	O
a	O
computational	O
systems	O
point	O
of	O
view	O
are	O
smaller	O
than	O
the	O
nervous	O
system	O
of	O
even	O
relatively	O
primitive	O
vertebrate	O
animals	O
like	O
frogs	O
the	O
increase	O
in	O
model	O
size	O
over	O
time	O
due	O
to	O
the	O
availability	O
of	O
faster	O
cpus	O
chapter	O
introduction	O
s	O
e	O
l	O
p	O
m	O
a	O
x	O
e	O
r	O
e	O
b	O
m	O
u	O
n	O
e	O
z	O
i	O
s	O
t	O
e	O
s	O
a	O
t	O
a	O
d	O
canadian	O
hansard	O
wmt	O
public	O
svhn	O
criminals	O
imagenet	O
ilsvrc	O
mnist	O
t	O
vs	O
g	O
vs	O
f	O
rotated	O
t	O
vs	O
c	O
iris	O
year	O
et	O
al	O
figure	O
dataset	B
sizes	O
have	O
increased	O
greatly	O
over	O
time	O
in	O
the	O
early	O
statisticians	O
studied	O
datasets	O
using	O
hundreds	O
or	O
thousands	O
of	O
manually	O
compiled	O
measurements	O
garson	O
in	O
the	O
through	O
the	O
pioneers	O
gosset	O
anderson	O
fisher	O
of	O
biologically	O
inspired	O
machine	B
learning	I
often	O
worked	O
with	O
small	O
synthetic	O
datasets	O
such	O
as	O
low-resolution	O
bitmaps	O
of	O
letters	O
that	O
were	O
designed	O
to	O
incur	O
low	O
computational	O
cost	O
and	O
demonstrate	O
that	O
neural	O
networks	O
were	O
able	O
to	O
learn	O
specific	O
kinds	O
of	O
functions	O
and	O
hoff	O
rumelhart	O
in	O
the	O
and	O
machine	B
learning	I
became	O
more	O
statistical	O
in	O
nature	O
and	O
began	O
to	O
leverage	O
larger	O
datasets	O
containing	O
tens	O
of	O
thousands	O
of	O
examples	O
such	O
as	O
the	O
mnist	O
dataset	B
in	O
figure	O
of	O
scans	O
of	O
handwritten	O
numbers	O
in	O
the	O
first	O
decade	O
of	O
the	O
more	O
sophisticated	O
datasets	O
of	O
this	O
same	O
size	O
such	O
as	O
the	O
dataset	B
and	O
hinton	O
continued	O
to	O
be	O
produced	O
toward	O
the	O
end	O
of	O
that	O
decade	O
and	O
throughout	O
the	O
first	O
half	O
of	O
the	O
significantly	O
larger	O
datasets	O
containing	O
hundreds	O
of	O
thousands	O
to	O
tens	O
of	O
millions	O
of	O
examples	O
completely	O
changed	O
what	O
was	O
possible	O
with	O
deep	O
learning	O
these	O
datasets	O
included	O
the	O
public	O
street	O
view	O
house	O
numbers	O
dataset	B
netzer	O
et	O
al	O
various	O
versions	O
of	O
the	O
imagenet	O
dataset	B
deng	O
et	O
al	O
russakovsky	O
at	O
the	O
top	O
of	O
the	O
et	O
al	O
graph	O
we	O
see	O
that	O
datasets	O
of	O
translated	O
sentences	O
such	O
as	O
ibm	O
s	O
dataset	B
constructed	O
from	O
the	O
canadian	O
hansard	O
and	O
the	O
wmt	O
english	O
to	O
french	O
dataset	B
are	O
typically	O
far	O
ahead	O
of	O
other	O
dataset	B
sizes	O
and	O
the	O
dataset	B
lecun	O
et	O
al	O
brown	O
et	O
al	O
et	O
al	O
karpathy	O
chapter	O
introduction	O
figure	O
example	B
inputs	O
from	O
the	O
mnist	O
dataset	B
the	O
nist	O
stands	O
for	O
national	O
institute	O
of	O
standards	O
and	O
technology	O
the	O
agency	O
that	O
originally	O
collected	O
this	O
data	O
the	O
m	O
stands	O
for	O
modified	O
since	O
the	O
data	O
has	O
been	O
preprocessed	O
for	O
easier	O
use	O
with	O
machine	B
learning	I
algorithms	O
the	O
mnist	O
dataset	B
consists	O
of	O
scans	O
of	O
handwritten	O
digits	O
and	O
associated	O
labels	O
describing	O
which	O
digit	O
is	O
contained	O
in	O
each	O
image	O
this	O
simple	O
classification	B
problem	O
is	O
one	O
of	O
the	O
simplest	O
and	O
most	O
widely	O
used	O
tests	O
in	O
deep	O
learning	O
research	O
it	O
remains	O
popular	O
despite	O
being	O
quite	O
easy	O
for	O
modern	O
techniques	O
to	O
solve	O
geoffrey	O
hinton	O
has	O
described	O
it	O
as	O
the	O
drosophila	O
of	O
machine	B
learning	I
meaning	O
that	O
it	O
allows	O
machine	B
learning	I
researchers	O
to	O
study	O
their	O
algorithms	O
in	O
controlled	O
laboratory	O
conditions	O
much	O
as	O
biologists	O
often	O
study	O
fruit	O
flies	O
chapter	O
introduction	O
faster	O
network	O
the	O
advent	O
of	O
general	O
purpose	O
gpus	O
in	O
section	O
connectivity	O
and	O
better	O
software	O
infrastructure	O
for	O
distributed	O
computing	O
is	O
one	O
of	O
the	O
most	O
important	O
trends	O
in	O
the	O
history	O
of	O
deep	O
learning	O
this	O
trend	O
is	O
generally	O
expected	O
to	O
continue	O
well	O
into	O
the	O
future	O
increasing	O
accuracy	B
complexity	O
and	O
real-world	O
impact	O
since	O
the	O
deep	O
learning	O
has	O
consistently	O
improved	O
in	O
its	O
ability	O
to	O
provide	O
accurate	O
recognition	O
or	O
prediction	O
moreover	O
deep	O
learning	O
has	O
consistently	O
been	O
applied	O
with	O
success	O
to	O
broader	O
and	O
broader	O
sets	O
of	O
applications	O
rumelhart	O
et	O
al	O
the	O
earliest	O
deep	O
models	O
were	O
used	O
to	O
recognize	O
individual	O
objects	O
in	O
tightly	O
cropped	O
extremely	O
small	O
images	O
since	O
then	O
there	O
has	O
been	O
a	O
gradual	O
increase	O
in	O
the	O
size	O
of	O
images	O
neural	O
networks	O
could	O
process	O
modern	O
object	B
recognition	I
networks	O
process	O
rich	O
high-resolution	O
photographs	O
and	O
do	O
not	O
have	O
a	O
requirement	O
that	O
the	O
photo	O
be	O
cropped	O
near	O
the	O
object	O
to	O
be	O
recognized	O
krizhevsky	O
et	O
al	O
similarly	O
the	O
earliest	O
networks	O
could	O
only	O
recognize	O
two	O
kinds	O
of	O
objects	O
in	O
some	O
cases	O
the	O
absence	O
or	O
presence	O
of	O
a	O
single	O
kind	O
of	O
object	O
while	O
these	O
modern	O
networks	O
typically	O
recognize	O
at	O
least	O
different	O
categories	O
of	O
objects	O
the	O
largest	O
contest	O
in	O
object	B
recognition	I
is	O
the	O
imagenet	O
large	O
scale	O
visual	O
recognition	O
challenge	B
held	O
each	O
year	O
a	O
dramatic	O
moment	O
in	O
the	O
meteoric	O
rise	O
of	O
deep	O
learning	O
came	O
when	O
a	O
convolutional	B
network	I
won	O
this	O
challenge	B
for	O
the	O
first	O
time	O
and	O
by	O
a	O
wide	O
margin	O
bringing	O
down	O
the	O
state-of-the-art	O
error	O
rate	O
from	O
to	O
krizhevsky	O
et	O
al	O
meaning	O
that	O
the	O
convolutional	B
network	I
produces	O
a	O
ranked	O
list	O
of	O
possible	O
categories	O
for	O
each	O
image	O
and	O
the	O
correct	O
category	O
appeared	O
in	O
the	O
first	O
five	O
entries	O
of	O
this	O
list	O
for	O
all	O
but	O
of	O
the	O
test	O
examples	O
since	O
then	O
these	O
competitions	O
are	O
consistently	O
won	O
by	O
deep	O
convolutional	O
nets	O
and	O
as	O
of	O
this	O
writing	O
advances	O
in	O
deep	O
learning	O
have	O
brought	O
the	O
latest	O
error	O
rate	O
in	O
this	O
contest	O
down	O
to	O
as	O
shown	O
in	O
figure	O
deep	O
learning	O
has	O
also	O
had	O
a	O
dramatic	O
impact	O
on	O
speech	O
recognition	O
after	O
improving	O
throughout	O
the	O
the	O
error	O
rates	O
for	O
speech	O
recognition	O
stagnated	O
starting	O
in	O
about	O
the	O
introduction	O
of	O
deep	O
learning	O
dahl	O
et	O
al	O
deng	O
et	O
al	O
to	O
speech	O
recognition	O
resulted	O
in	O
a	O
sudden	O
drop	O
of	O
error	O
rates	O
with	O
some	O
error	O
rates	O
cut	O
in	O
half	O
we	O
will	O
explore	O
this	O
history	O
in	O
more	O
detail	O
in	O
section	O
hinton	O
seide	O
et	O
al	O
et	O
al	O
deep	O
networks	O
have	O
also	O
had	O
spectacular	O
successes	O
for	O
pedestrian	O
detection	O
and	O
image	O
segmentation	O
et	O
al	O
and	O
yielded	O
superhuman	O
performance	O
in	O
traffic	O
sign	O
classification	B
sermanet	O
et	O
al	O
farabet	O
couprie	O
et	O
al	O
chapter	O
introduction	O
n	O
o	O
r	O
u	O
e	O
n	O
r	O
e	O
p	O
s	O
n	O
o	O
i	O
t	O
c	O
e	O
n	O
n	O
o	O
c	O
human	O
cat	O
mouse	O
fruit	O
fly	O
year	O
figure	O
initially	O
the	O
number	O
of	O
connections	O
between	O
neurons	O
in	O
artificial	O
neural	O
networks	O
was	O
limited	O
by	O
hardware	O
capabilities	O
today	O
the	O
number	O
of	O
connections	O
between	O
neurons	O
is	O
mostly	O
a	O
design	O
consideration	O
some	O
artificial	O
neural	O
networks	O
have	O
nearly	O
as	O
many	O
connections	O
per	O
neuron	O
as	O
a	O
cat	O
and	O
it	O
is	O
quite	O
common	O
for	O
other	O
neural	O
networks	O
to	O
have	O
as	O
many	O
connections	O
per	O
neuron	O
as	O
smaller	O
mammals	O
like	O
mice	O
even	O
the	O
human	O
brain	O
does	O
not	O
have	O
an	O
exorbitant	O
amount	O
of	O
connections	O
per	O
neuron	O
biological	O
neural	B
network	I
sizes	O
from	O
wikipedia	O
adaptive	O
linear	O
element	O
widrow	O
and	O
hoff	O
neocognitron	O
gpu-accelerated	O
convolutional	B
network	I
chellapilla	O
et	O
al	O
deep	O
boltzmann	O
machine	O
and	O
hinton	O
unsupervised	O
convolutional	B
network	I
jarrett	O
et	O
al	O
gpu-accelerated	O
multilayer	B
perceptron	I
ciresan	O
et	O
al	O
distributed	O
autoencoder	O
le	O
et	O
al	O
multi-gpu	O
convolutional	B
network	I
krizhevsky	O
et	O
al	O
cots	O
hpc	O
unsupervised	O
convolutional	B
network	I
coates	O
et	O
al	O
googlenet	O
szegedy	O
et	O
al	O
chapter	O
introduction	O
et	O
al	O
at	O
the	O
same	O
time	O
that	O
the	O
scale	O
and	O
accuracy	B
of	O
deep	O
networks	O
has	O
increased	O
so	O
has	O
the	O
complexity	O
of	O
the	O
tasks	O
that	O
they	O
can	O
solve	O
goodfellow	O
et	O
al	O
showed	O
that	O
neural	O
networks	O
could	O
learn	O
to	O
output	O
an	O
entire	O
sequence	O
of	O
characters	O
transcribed	O
from	O
an	O
image	O
rather	O
than	O
just	O
identifying	O
a	O
single	O
object	O
previously	O
it	O
was	O
widely	O
believed	O
that	O
this	O
kind	O
of	O
learning	O
required	O
labeling	O
of	O
the	O
individual	O
elements	O
of	O
the	O
sequence	O
recurrent	O
neural	O
networks	O
such	O
as	O
the	O
lstm	O
sequence	O
model	O
mentioned	O
above	O
are	O
now	O
used	O
to	O
model	O
relationships	O
between	O
sequences	O
rather	O
than	O
just	O
fixed	O
inputs	O
this	O
sequence-to-sequence	O
learning	O
seems	O
to	O
be	O
on	O
the	O
cusp	O
of	O
revolutionizing	O
another	O
application	O
machine	B
translation	I
et	O
al	O
g	O
l	O
ehre	O
and	O
bengio	O
bahdanau	O
and	O
other	O
sequences	O
et	O
al	O
this	O
trend	O
of	O
increasing	O
complexity	O
has	O
been	O
pushed	O
to	O
its	O
logical	O
conclusion	O
with	O
the	O
introduction	O
of	O
neural	O
turing	O
machines	O
that	O
learn	O
to	O
read	O
from	O
memory	O
cells	O
and	O
write	O
arbitrary	O
content	O
to	O
memory	O
cells	O
such	O
neural	O
networks	O
can	O
learn	O
simple	O
programs	O
from	O
examples	O
of	O
desired	O
behavior	O
for	O
example	B
they	O
can	O
learn	O
to	O
sort	O
lists	O
of	O
numbers	O
given	O
examples	O
of	O
scrambled	O
and	O
sorted	O
sequences	O
this	O
self-programming	O
technology	O
is	O
in	O
its	O
infancy	O
but	O
in	O
the	O
future	O
could	O
in	O
principle	O
be	O
applied	O
to	O
nearly	O
any	O
task	O
et	O
al	O
another	O
crowning	O
achievement	O
of	O
deep	O
learning	O
is	O
its	O
extension	O
to	O
the	O
domain	O
of	O
reinforcement	O
learning	O
in	O
the	O
context	O
of	O
reinforcement	O
learning	O
an	O
autonomous	O
agent	O
must	O
learn	O
to	O
perform	O
a	O
task	O
by	O
trial	O
and	O
error	O
without	O
any	O
guidance	O
from	O
the	O
human	O
operator	O
deepmind	O
demonstrated	O
that	O
a	O
reinforcement	O
learning	O
system	O
based	O
on	O
deep	O
learning	O
is	O
capable	O
of	O
learning	O
to	O
play	O
atari	O
video	O
games	O
reaching	O
human-level	O
performance	O
on	O
many	O
tasks	O
deep	O
learning	O
has	O
also	O
significantly	O
improved	O
the	O
performance	O
of	O
reinforcement	O
learning	O
for	O
robotics	O
finn	O
et	O
al	O
mnih	O
et	O
al	O
many	O
of	O
these	O
applications	O
of	O
deep	O
learning	O
are	O
highly	O
profitable	O
deep	O
learning	O
is	O
now	O
used	O
by	O
many	O
top	O
technology	O
companies	O
including	O
google	O
microsoft	O
facebook	O
ibm	O
baidu	O
apple	O
adobe	O
netflix	O
nvidia	O
and	O
nec	O
advances	O
in	O
deep	O
learning	O
have	O
also	O
depended	O
heavily	O
on	O
advances	O
in	O
software	O
bergstra	O
et	O
al	O
bastien	O
and	O
have	O
all	O
supported	O
important	O
research	O
projects	O
or	O
infrastructure	O
software	O
libraries	O
such	O
as	O
theano	O
et	O
al	O
distbelief	O
tensorflow	O
commercial	O
products	O
collobert	O
et	O
al	O
chen	O
et	O
al	O
dean	O
et	O
al	O
torch	O
mxnet	O
abadi	O
et	O
al	O
et	O
al	O
goodfellow	O
caffe	O
jia	O
deep	O
learning	O
has	O
also	O
made	O
contributions	O
back	O
to	O
other	O
sciences	O
modern	O
convolutional	O
networks	O
for	O
object	B
recognition	I
provide	O
a	O
model	O
of	O
visual	O
processing	O
chapter	O
introduction	O
dicarlo	O
deep	O
learning	O
also	O
provides	O
useful	O
that	O
neuroscientists	O
can	O
study	O
tools	O
for	O
processing	O
massive	O
amounts	O
of	O
data	O
and	O
making	O
useful	O
predictions	O
in	O
scientific	O
fields	O
it	O
has	O
been	O
successfully	O
used	O
to	O
predict	O
how	O
molecules	O
will	O
interact	O
in	O
order	O
to	O
help	O
pharmaceutical	O
companies	O
design	O
new	O
drugs	O
to	O
search	O
for	O
subatomic	O
particles	O
and	O
to	O
automatically	O
parse	O
microscope	O
images	O
used	O
to	O
construct	O
a	O
map	O
of	O
the	O
human	O
brain	O
we	O
expect	O
deep	O
learning	O
to	O
appear	O
in	O
more	O
and	O
more	O
scientific	O
fields	O
in	O
the	O
future	O
baldi	O
et	O
al	O
dahl	O
et	O
al	O
et	O
al	O
in	O
summary	O
deep	O
learning	O
is	O
an	O
approach	O
to	O
machine	B
learning	I
that	O
has	O
drawn	O
heavily	O
on	O
our	O
knowledge	O
of	O
the	O
human	O
brain	O
statistics	O
and	O
applied	O
math	O
as	O
it	O
developed	O
over	O
the	O
past	O
several	O
decades	O
in	O
recent	O
years	O
it	O
has	O
seen	O
tremendous	O
growth	O
in	O
its	O
popularity	O
and	O
usefulness	O
due	O
in	O
large	O
part	O
to	O
more	O
powerful	O
computers	O
larger	O
datasets	O
and	O
techniques	O
to	O
train	O
deeper	O
networks	O
the	O
years	O
ahead	O
are	O
full	O
of	O
challenges	O
and	O
opportunities	O
to	O
improve	O
deep	O
learning	O
even	O
further	O
and	O
bring	O
it	O
to	O
new	O
frontiers	O
chapter	O
introduction	O
e	O
l	O
a	O
c	O
s	O
c	O
i	O
m	O
h	O
t	O
i	O
r	O
a	O
g	O
o	O
l	O
s	O
n	O
o	O
r	O
u	O
e	O
n	O
f	O
o	O
r	O
e	O
b	O
m	O
u	O
n	O
year	O
human	O
octopus	O
frog	O
bee	O
ant	O
leech	O
roundworm	O
sponge	O
figure	O
since	O
the	O
introduction	O
of	O
hidden	O
units	O
artificial	O
neural	O
networks	O
have	O
doubled	O
in	O
size	O
roughly	O
every	O
years	O
biological	O
neural	B
network	I
sizes	O
from	O
wikipedia	O
perceptron	O
rosenblatt	O
adaptive	O
linear	O
element	O
widrow	O
and	O
hoff	O
neocognitron	O
early	O
back-propagation	B
network	O
rumelhart	O
et	O
al	O
recurrent	B
neural	B
network	I
for	O
speech	O
recognition	O
and	O
fallside	O
multilayer	B
perceptron	I
for	O
speech	O
recognition	O
mean	O
field	O
sigmoid	B
belief	I
network	I
saul	O
et	O
al	O
bengio	O
et	O
al	O
lecun	O
et	O
al	O
echo	O
state	O
network	O
jaeger	O
and	O
haas	O
deep	O
belief	O
network	O
hinton	O
et	O
al	O
gpu-accelerated	O
convolutional	B
network	I
chellapilla	O
et	O
al	O
deep	O
boltzmann	O
machine	O
and	O
hinton	O
gpu-accelerated	O
deep	O
belief	O
network	O
unsupervised	O
convolutional	B
network	I
raina	O
et	O
al	O
jarrett	O
et	O
al	O
gpu-accelerated	O
multilayer	B
perceptron	I
ciresan	O
et	O
al	O
network	O
coates	O
and	O
ng	O
distributed	O
autoencoder	O
le	O
et	O
al	O
multi-gpu	O
convolutional	B
network	I
krizhevsky	O
et	O
al	O
cots	O
hpc	O
unsupervised	O
convolutional	B
network	I
coates	O
et	O
al	O
googlenet	O
szegedy	O
et	O
al	O
chapter	O
introduction	O
e	O
t	O
a	O
r	O
r	O
o	O
r	O
r	O
e	O
n	O
o	O
i	O
t	O
a	O
c	O
fi	O
i	O
s	O
s	O
a	O
l	O
c	O
c	O
r	O
v	O
s	O
l	O
i	O
year	O
figure	O
since	O
deep	O
networks	O
reached	O
the	O
scale	O
necessary	O
to	O
compete	O
in	O
the	O
imagenet	O
large	O
scale	O
visual	O
recognition	O
challenge	B
they	O
have	O
consistently	O
won	O
the	O
competition	O
every	O
year	O
and	O
yielded	O
lower	O
and	O
lower	O
error	O
rates	O
each	O
time	O
data	O
from	O
russakovsky	O
et	O
al	O
and	O
he	O
et	O
al	O
part	O
i	O
applied	O
math	O
and	O
machine	B
learning	I
basics	O
this	O
part	O
of	O
the	O
book	O
introduces	O
the	O
basic	O
mathematical	O
concepts	O
needed	O
to	O
understand	O
deep	O
learning	O
we	O
begin	O
with	O
general	O
ideas	O
from	O
applied	O
math	O
that	O
allow	O
us	O
to	O
define	O
functions	O
of	O
many	O
variables	O
find	O
the	O
highest	O
and	O
lowest	O
points	O
on	O
these	O
functions	O
and	O
quantify	O
degrees	O
of	O
belief	O
next	O
we	O
describe	O
the	O
fundamental	O
goals	O
of	O
machine	B
learning	I
we	O
describe	O
how	O
to	O
accomplish	O
these	O
goals	O
by	O
specifying	O
a	O
model	O
that	O
represents	O
certain	O
beliefs	O
designing	O
a	O
cost	O
function	O
that	O
measures	O
how	O
well	O
those	O
beliefs	O
correspond	O
with	O
reality	O
and	O
using	O
a	O
training	O
algorithm	O
to	O
minimize	O
that	O
cost	O
function	O
this	O
elementary	O
framework	O
is	O
the	O
basis	O
for	O
a	O
broad	O
variety	O
of	O
machine	B
learning	I
algorithms	O
including	O
approaches	O
to	O
machine	B
learning	I
that	O
are	O
not	O
deep	O
in	O
the	O
subsequent	O
parts	O
of	O
the	O
book	O
we	O
develop	O
deep	O
learning	O
algorithms	O
within	O
this	O
framework	O
chapter	O
linear	O
algebra	O
linear	O
algebra	O
is	O
a	O
branch	O
of	O
mathematics	O
that	O
is	O
widely	O
used	O
throughout	O
science	O
and	O
engineering	O
however	O
because	O
linear	O
algebra	O
is	O
a	O
form	O
of	O
continuous	O
rather	O
than	O
discrete	O
mathematics	O
many	O
computer	O
scientists	O
have	O
little	O
experience	O
with	O
it	O
a	O
good	O
understanding	O
of	O
linear	O
algebra	O
is	O
essential	O
for	O
understanding	O
and	O
working	O
with	O
many	O
machine	B
learning	I
algorithms	O
especially	O
deep	O
learning	O
algorithms	O
we	O
therefore	O
precede	O
our	O
introduction	O
to	O
deep	O
learning	O
with	O
a	O
focused	O
presentation	O
of	O
the	O
key	O
linear	O
algebra	O
prerequisites	O
if	O
you	O
are	O
already	O
familiar	O
with	O
linear	O
algebra	O
feel	O
free	O
to	O
skip	O
this	O
chapter	O
if	O
you	O
have	O
previous	O
experience	O
with	O
these	O
concepts	O
but	O
need	O
a	O
detailed	O
reference	O
sheet	O
to	O
review	O
key	O
formulas	O
we	O
recommend	O
the	O
matrix	O
cookbook	O
and	O
pedersen	O
if	O
you	O
have	O
no	O
exposure	O
at	O
all	O
to	O
linear	O
algebra	O
this	O
chapter	O
will	O
teach	O
you	O
enough	O
to	O
read	O
this	O
book	O
but	O
we	O
highly	O
recommend	O
that	O
you	O
also	O
consult	O
another	O
resource	O
focused	O
exclusively	O
on	O
teaching	O
linear	O
algebra	O
such	O
as	O
shilov	O
this	O
chapter	O
will	O
completely	O
omit	O
many	O
important	O
linear	O
algebra	O
topics	O
that	O
are	O
not	O
essential	O
for	O
understanding	O
deep	O
learning	O
scalars	O
vectors	O
matrices	O
and	O
tensors	O
the	O
study	O
of	O
linear	O
algebra	O
involves	O
several	O
types	O
of	O
mathematical	O
objects	O
scalars	O
a	O
scalar	O
is	O
just	O
a	O
single	O
number	O
in	O
contrast	B
to	O
most	O
of	O
the	O
other	O
objects	O
studied	O
in	O
linear	O
algebra	O
which	O
are	O
usually	O
arrays	O
of	O
multiple	O
numbers	O
we	O
write	O
scalars	O
in	O
italics	O
we	O
usually	O
give	O
scalars	O
lower-case	O
variable	O
names	O
when	O
we	O
introduce	O
them	O
we	O
specify	O
what	O
kind	O
of	O
number	O
they	O
are	O
for	O
chapter	O
linear	O
algebra	O
example	B
we	O
might	O
say	O
let	O
s	O
real-valued	O
scalar	O
or	O
let	O
n	O
natural	O
number	O
scalar	O
r	O
be	O
the	O
slope	O
of	O
the	O
line	O
while	O
defining	O
a	O
n	O
be	O
the	O
number	O
of	O
units	O
while	O
defining	O
a	O
vectors	O
a	O
vector	O
is	O
an	O
array	O
of	O
numbers	O
the	O
numbers	O
are	O
arranged	O
in	O
order	O
we	O
can	O
identify	O
each	O
individual	O
number	O
by	O
its	O
index	O
in	O
that	O
ordering	O
typically	O
we	O
give	O
vectors	O
lower	O
case	O
names	O
written	O
in	O
bold	O
typeface	O
such	O
as	O
x	O
the	O
elements	O
of	O
the	O
vector	O
are	O
identified	O
by	O
writing	O
its	O
name	O
in	O
italic	O
typeface	O
with	O
a	O
subscript	O
the	O
first	O
element	O
of	O
x	O
is	O
the	O
second	O
element	O
is	O
and	O
so	O
on	O
we	O
also	O
need	O
to	O
say	O
what	O
kind	O
of	O
numbers	O
are	O
stored	O
in	O
the	O
vector	O
if	O
each	O
element	O
is	O
in	O
r	O
and	O
the	O
vector	O
has	O
n	O
elements	O
then	O
the	O
vector	O
lies	O
in	O
the	O
set	O
formed	O
by	O
taking	O
the	O
cartesian	O
product	O
of	O
r	O
n	O
times	O
n	O
when	O
we	O
need	O
to	O
explicitly	O
identify	O
the	O
elements	O
of	O
a	O
vector	O
denoted	O
as	O
r	O
we	O
write	O
them	O
as	O
a	O
column	O
enclosed	O
in	O
square	O
brackets	O
x	O
xn	O
we	O
can	O
think	O
of	O
vectors	O
as	O
identifying	O
points	O
in	O
space	O
with	O
each	O
element	O
giving	O
the	O
coordinate	O
along	O
a	O
different	O
axis	O
sometimes	O
we	O
need	O
to	O
index	O
a	O
set	O
of	O
elements	O
of	O
a	O
vector	O
in	O
this	O
case	O
we	O
define	O
a	O
set	O
containing	O
the	O
indices	O
and	O
write	O
the	O
set	O
as	O
a	O
subscript	O
for	O
example	B
to	O
access	O
and	O
we	O
define	O
the	O
set	O
s	O
and	O
write	O
xs	O
we	O
use	O
the	O
is	O
the	O
vector	O
containing	O
all	O
elements	O
of	O
x	O
except	O
for	O
and	O
x	O
s	O
is	O
the	O
vector	O
containing	O
all	O
of	O
the	O
elements	O
of	O
and	O
sign	O
to	O
index	O
the	O
complement	O
of	O
a	O
set	O
for	O
example	B
x	O
except	O
for	O
x	O
matrices	O
a	O
matrix	O
is	O
a	O
array	O
of	O
numbers	O
so	O
each	O
element	O
is	O
identified	O
by	O
two	O
indices	O
instead	O
of	O
just	O
one	O
we	O
usually	O
give	O
matrices	O
upper-case	O
variable	O
names	O
with	O
bold	O
typeface	O
such	O
as	O
a	O
if	O
a	O
real-valued	O
matrix	O
a	O
has	O
a	O
height	O
of	O
m	O
and	O
a	O
width	O
of	O
n	O
then	O
we	O
say	O
that	O
a	O
we	O
usually	O
identify	O
the	O
elements	O
of	O
a	O
matrix	O
using	O
its	O
name	O
in	O
italic	O
but	O
not	O
bold	O
font	O
and	O
the	O
indices	O
are	O
listed	O
with	O
separating	O
commas	O
for	O
example	B
is	O
the	O
upper	O
left	O
entry	O
of	O
a	O
and	O
amn	O
is	O
the	O
bottom	O
right	O
entry	O
we	O
can	O
identify	O
all	O
of	O
the	O
numbers	O
with	O
vertical	O
coordinate	O
i	O
by	O
writing	O
a	O
for	O
the	O
horizontal	O
coordinate	O
for	O
example	B
ai	O
denotes	O
the	O
horizontal	O
cross	O
section	O
of	O
a	O
with	O
vertical	O
coordinate	O
i	O
this	O
is	O
known	O
as	O
the	O
i-th	O
row	O
of	O
a	O
likewise	O
ai	O
is	O
m	O
n	O
r	O
chapter	O
linear	O
algebra	O
a	O
a	O
figure	O
the	O
transpose	O
of	O
the	O
matrix	O
can	O
be	O
thought	O
of	O
as	O
a	O
mirror	O
image	O
across	O
the	O
main	B
diagonal	I
i	O
column	O
a	O
the	O
a	O
matrix	O
we	O
write	O
them	O
as	O
an	O
array	O
enclosed	O
in	O
square	O
brackets	O
when	O
we	O
need	O
to	O
explicitly	O
identify	O
the	O
elements	O
of	O
of	O
a	O
a	O
sometimes	O
we	O
may	O
need	O
to	O
index	O
matrix-valued	O
expressions	O
that	O
are	O
not	O
just	O
a	O
single	O
letter	O
in	O
this	O
case	O
we	O
use	O
subscripts	O
after	O
the	O
expression	O
but	O
do	O
not	O
convert	O
anything	O
to	O
lower	O
case	O
for	O
example	B
f	O
gives	O
element	O
j	O
of	O
the	O
matrix	O
computed	O
by	O
applying	O
the	O
function	O
f	O
a	O
to	O
tensors	O
in	O
some	O
cases	O
we	O
will	O
need	O
an	O
array	O
with	O
more	O
than	O
two	O
axes	O
in	O
the	O
general	O
case	O
an	O
array	O
of	O
numbers	O
arranged	O
on	O
a	O
regular	O
grid	O
with	O
a	O
variable	O
number	O
of	O
axes	O
is	O
known	O
as	O
a	O
tensor	O
we	O
denote	O
a	O
tensor	O
named	O
a	O
with	O
this	O
typeface	O
a	O
we	O
identify	O
the	O
element	O
of	O
a	O
at	O
coordinates	O
j	O
k	O
by	O
writing	O
aijk	O
one	O
important	O
operation	B
on	O
matrices	O
is	O
the	O
transpose	O
the	O
transpose	O
of	O
a	O
matrix	O
is	O
the	O
mirror	O
image	O
of	O
the	O
matrix	O
across	O
a	O
diagonal	O
line	O
called	O
the	O
main	B
diagonal	I
running	O
down	O
and	O
to	O
the	O
right	O
starting	O
from	O
its	O
upper	O
left	O
corner	O
see	O
figure	O
for	O
a	O
graphical	O
depiction	O
of	O
this	O
operation	B
we	O
denote	O
the	O
transpose	O
of	O
a	O
matrix	O
and	O
it	O
is	O
defined	O
such	O
that	O
asa	O
a	O
aji	O
vectors	O
can	O
be	O
thought	O
of	O
as	O
matrices	O
that	O
contain	O
only	O
one	O
column	O
the	O
transpose	O
of	O
a	O
vector	O
is	O
therefore	O
a	O
matrix	O
with	O
only	O
one	O
row	O
sometimes	O
we	O
chapter	O
linear	O
algebra	O
define	O
a	O
vector	O
by	O
writing	O
out	O
its	O
elements	O
in	O
the	O
text	O
inline	O
as	O
a	O
row	O
matrix	O
then	O
using	O
the	O
transpose	O
operator	O
to	O
turn	O
it	O
into	O
a	O
standard	O
column	O
vector	O
e	O
g	O
x	O
a	O
scalar	O
can	O
be	O
thought	O
of	O
as	O
a	O
matrix	O
with	O
only	O
a	O
single	O
entry	O
from	O
this	O
we	O
can	O
see	O
that	O
a	O
scalar	O
is	O
its	O
own	O
transpose	O
a	O
a	O
we	O
can	O
add	O
matrices	O
to	O
each	O
other	O
as	O
long	O
as	O
they	O
have	O
the	O
same	O
shape	O
just	O
by	O
adding	O
their	O
corresponding	O
elements	O
c	O
a	O
b	O
where	O
cij	O
aij	O
b	O
ij	O
we	O
can	O
also	O
add	O
a	O
scalar	O
to	O
a	O
matrix	O
or	O
multiply	O
a	O
matrix	O
by	O
a	O
scalar	O
just	O
b	O
c	O
where	O
by	O
performing	O
that	O
operation	B
on	O
each	O
element	O
of	O
a	O
matrix	O
d	O
a	O
dij	O
a	O
b	O
ij	O
c	O
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
also	O
use	O
some	O
less	O
conventional	O
notation	O
we	O
allow	O
the	O
addition	O
of	O
matrix	O
and	O
a	O
vector	O
yielding	O
another	O
matrix	O
c	O
a	O
b	O
where	O
cij	O
aij	O
bj	O
in	O
other	O
words	O
the	O
vector	O
b	O
is	O
added	O
to	O
each	O
row	O
of	O
the	O
matrix	O
this	O
shorthand	O
eliminates	O
the	O
need	O
to	O
define	O
a	O
matrix	O
with	O
b	O
copied	O
into	O
each	O
row	O
before	O
doing	O
the	O
addition	O
this	O
implicit	O
copying	O
of	O
b	O
to	O
many	O
locations	O
is	O
called	O
broadcasting	B
multiplying	O
matrices	O
and	O
vectors	O
one	O
of	O
the	O
most	O
important	O
operations	O
involving	O
matrices	O
is	O
multiplication	O
of	O
two	O
matrices	O
the	O
matrix	B
product	I
of	O
matrices	O
a	O
and	O
b	O
is	O
a	O
third	O
matrix	O
c	O
in	O
order	O
for	O
this	O
product	O
to	O
be	O
defined	O
a	O
must	O
have	O
the	O
same	O
number	O
of	O
columns	O
as	O
b	O
has	O
rows	O
if	O
a	O
is	O
of	O
shape	O
m	O
n	O
p	O
then	O
c	O
is	O
of	O
shape	O
m	O
p	O
we	O
can	O
write	O
the	O
matrix	B
product	I
just	O
by	O
placing	O
two	O
or	O
more	O
matrices	O
together	O
e	O
g	O
and	O
b	O
is	O
of	O
shape	O
n	O
c	O
ab	O
the	O
product	O
operation	B
is	O
defined	O
by	O
cij	O
aikbkj	O
k	O
note	O
that	O
the	O
standard	O
product	O
of	O
two	O
matrices	O
is	O
just	O
a	O
matrix	O
containing	O
the	O
product	O
of	O
the	O
individual	O
elements	O
such	O
an	O
operation	B
exists	O
and	O
is	O
called	O
the	O
element-wise	O
product	O
hadamard	O
product	O
and	O
is	O
denoted	O
as	O
a	O
b	O
not	O
or	O
the	O
dot	O
product	O
between	O
two	O
vectors	O
x	O
and	O
y	O
of	O
the	O
same	O
dimensionality	O
y	O
we	O
can	O
think	O
of	O
the	O
matrix	B
product	I
c	O
ab	O
as	O
is	O
the	O
matrix	B
product	I
x	O
computing	O
cij	O
as	O
the	O
dot	O
product	O
between	O
row	O
of	O
and	O
column	O
j	O
b	O
of	O
i	O
a	O
chapter	O
linear	O
algebra	O
matrix	B
product	I
operations	O
have	O
many	O
useful	O
properties	O
that	O
make	O
mathematical	O
analysis	O
of	O
matrices	O
more	O
convenient	O
for	O
example	B
matrix	O
multiplication	O
is	O
distributive	O
a	O
b	O
c	O
ab	O
ac	O
it	O
is	O
also	O
associative	O
a	O
bc	O
ab	O
c	O
ab	O
ba	O
does	O
not	O
matrix	O
multiplication	O
is	O
always	O
hold	O
unlike	O
scalar	O
multiplication	O
however	O
the	O
dot	O
product	O
between	O
two	O
vectors	O
is	O
commutative	O
commutative	O
condition	O
not	O
the	O
transpose	O
of	O
a	O
matrix	B
product	I
has	O
a	O
simple	O
form	O
x	O
y	O
y	O
x	O
b	O
a	O
this	O
allows	O
us	O
to	O
demonstrate	O
equation	O
of	O
such	O
a	O
product	O
is	O
a	O
scalar	O
and	O
therefore	O
equal	O
to	O
its	O
own	O
transpose	O
by	O
exploiting	O
the	O
fact	O
that	O
the	O
value	O
x	O
y	O
y	O
x	O
y	O
x	O
since	O
the	O
focus	O
of	O
this	O
textbook	O
is	O
not	O
linear	O
algebra	O
we	O
do	O
not	O
attempt	O
to	O
develop	O
a	O
comprehensive	O
list	O
of	O
useful	O
properties	O
of	O
the	O
matrix	B
product	I
here	O
but	O
the	O
reader	O
should	O
be	O
aware	O
that	O
many	O
more	O
exist	O
we	O
now	O
know	O
enough	O
linear	O
algebra	O
notation	O
to	O
write	O
down	O
a	O
system	O
of	O
linear	O
equations	O
m	O
n	O
ax	O
b	O
r	O
is	O
a	O
known	O
matrix	O
b	O
n	O
is	O
a	O
where	O
a	O
vector	O
of	O
unknown	O
variables	O
we	O
would	O
like	O
to	O
solve	O
for	O
each	O
element	O
xi	O
of	O
x	O
is	O
one	O
of	O
these	O
unknown	O
variables	O
each	O
row	O
of	O
a	O
and	O
each	O
element	O
of	O
b	O
provide	O
another	O
constraint	O
we	O
can	O
rewrite	O
equation	O
m	O
is	O
a	O
known	O
vector	O
and	O
x	O
as	O
r	O
r	O
x	O
x	O
amx	O
bm	O
or	O
even	O
more	O
explicitly	O
as	O
chapter	O
linear	O
algebra	O
figure	O
example	B
identity	B
matrix	I
this	O
is	O
i	O
a	O
a	O
mnxn	O
bm	O
matrix-vector	O
product	O
notation	O
provides	O
a	O
more	O
compact	O
representation	O
for	O
equations	O
of	O
this	O
form	O
identity	O
and	O
inverse	O
matrices	O
linear	O
algebra	O
offers	O
a	O
powerful	O
tool	O
called	O
matrix	O
inversion	O
that	O
allows	O
us	O
to	O
analytically	O
solve	O
equation	O
for	O
many	O
values	O
of	O
a	O
to	O
describe	O
matrix	O
inversion	O
we	O
first	O
need	O
to	O
define	O
the	O
concept	O
of	O
an	O
identity	B
matrix	I
an	O
identity	B
matrix	I
is	O
a	O
matrix	O
that	O
does	O
not	O
change	O
any	O
vector	O
when	O
we	O
multiply	O
that	O
vector	O
by	O
that	O
matrix	O
we	O
denote	O
the	O
identity	B
matrix	I
that	O
preserves	O
n-dimensional	O
vectors	O
as	O
in	O
formally	O
i	O
n	O
n	O
n	O
and	O
r	O
x	O
r	O
n	O
inx	O
x	O
the	O
structure	O
of	O
the	O
identity	B
matrix	I
is	O
simple	O
all	O
of	O
the	O
entries	O
along	O
the	O
main	B
diagonal	I
are	O
while	O
all	O
of	O
the	O
other	O
entries	O
are	O
zero	O
see	O
figure	O
for	O
an	O
example	B
and	O
it	O
is	O
defined	O
as	O
the	O
matrix	O
the	O
matrix	B
inverse	I
of	O
a	O
is	O
denoted	O
as	O
a	O
such	O
that	O
i	O
n	O
a	O
we	O
can	O
now	O
solve	O
equation	O
by	O
the	O
following	O
steps	O
a	O
ax	O
b	O
a	O
inx	O
a	O
chapter	O
linear	O
algebra	O
x	O
a	O
we	O
discuss	O
of	O
course	O
this	O
process	O
depends	O
on	O
it	O
being	O
possible	O
to	O
find	O
a	O
in	O
the	O
following	O
section	O
the	O
conditions	O
for	O
the	O
existence	O
of	O
a	O
exists	O
several	O
different	O
algorithms	O
exist	O
for	O
finding	O
it	O
in	O
closed	O
form	O
when	O
a	O
in	O
theory	O
the	O
same	O
inverse	O
matrix	O
can	O
then	O
be	O
used	O
to	O
solve	O
the	O
equation	O
many	O
is	O
primarily	O
useful	O
as	O
a	O
theoretical	O
times	O
for	O
different	O
values	O
of	O
b	O
however	O
a	O
tool	O
and	O
should	O
not	O
actually	O
be	O
used	O
in	O
practice	O
for	O
most	O
software	O
applications	O
can	O
be	O
represented	O
with	O
only	O
limited	O
precision	B
on	O
a	O
digital	O
computer	O
because	O
a	O
algorithms	O
that	O
make	O
use	O
of	O
the	O
value	O
of	O
b	O
can	O
usually	O
obtain	O
more	O
accurate	O
estimates	O
of	O
linear	B
dependence	I
and	O
span	O
to	O
exist	O
equation	O
in	O
order	O
for	O
a	O
must	O
have	O
exactly	O
one	O
solution	O
for	O
every	O
value	O
of	O
b	O
however	O
it	O
is	O
also	O
possible	O
for	O
the	O
system	O
of	O
equations	O
to	O
have	O
no	O
solutions	O
or	O
infinitely	O
many	O
solutions	O
for	O
some	O
values	O
of	O
b	O
it	O
is	O
not	O
possible	O
to	O
have	O
more	O
than	O
one	O
but	O
less	O
than	O
infinitely	O
many	O
solutions	O
for	O
a	O
particular	O
b	O
if	O
both	O
are	O
solutions	O
then	O
and	O
x	O
y	O
y	O
is	O
also	O
a	O
solution	O
for	O
any	O
real	O
z	O
x	O
to	O
analyze	O
how	O
many	O
solutions	O
the	O
equation	O
has	O
we	O
can	O
think	O
of	O
the	O
columns	O
of	O
a	O
as	O
specifying	O
different	O
directions	O
we	O
can	O
travel	O
from	O
the	O
origin	O
point	O
specified	O
by	O
the	O
vector	O
of	O
all	O
zeros	O
and	O
determine	O
how	O
many	O
ways	O
there	O
are	O
of	O
reaching	O
b	O
in	O
this	O
view	O
each	O
element	O
of	O
x	O
specifies	O
how	O
far	O
we	O
should	O
travel	O
in	O
each	O
of	O
these	O
directions	O
with	O
xi	O
specifying	O
how	O
far	O
to	O
move	O
in	O
the	O
direction	O
of	O
column	O
ax	O
xiai	O
i	O
in	O
general	O
this	O
kind	O
of	O
operation	B
is	O
called	O
a	O
linear	B
combination	I
formally	O
a	O
linear	B
combination	I
of	O
some	O
set	O
of	O
vectors	O
is	O
given	O
by	O
multiplying	O
each	O
vector	O
v	O
by	O
a	O
corresponding	O
scalar	O
coefficient	O
and	O
adding	O
the	O
results	O
v	O
civ	O
i	O
the	O
span	O
of	O
a	O
set	O
of	O
vectors	O
is	O
the	O
set	O
of	O
all	O
points	O
obtainable	O
by	O
linear	B
combination	I
of	O
the	O
original	O
vectors	O
chapter	O
linear	O
algebra	O
determining	O
whether	O
ax	O
b	O
has	O
a	O
solution	O
thus	O
amounts	O
to	O
testing	O
whether	O
b	O
is	O
in	O
the	O
span	O
of	O
the	O
columns	O
of	O
a	O
this	O
particular	O
span	O
is	O
known	O
as	O
the	O
column	O
space	O
range	O
or	O
the	O
of	O
r	O
m	O
if	O
any	O
point	O
in	O
r	O
m	O
m	O
in	O
order	O
for	O
the	O
system	O
ax	O
b	O
to	O
have	O
a	O
solution	O
for	O
all	O
values	O
of	O
b	O
we	O
therefore	O
require	O
that	O
the	O
column	O
space	O
of	O
a	O
be	O
all	O
of	O
r	O
is	O
excluded	O
from	O
the	O
column	O
space	O
that	O
point	O
is	O
a	O
potential	O
value	O
of	O
b	O
that	O
has	O
no	O
solution	O
the	O
requirement	O
that	O
the	O
column	O
space	O
of	O
a	O
be	O
all	O
of	O
r	O
m	O
implies	O
immediately	O
that	O
a	O
must	O
have	O
at	O
least	O
m	O
columns	O
i	O
e	O
n	O
m	O
otherwise	O
the	O
dimensionality	O
of	O
the	O
column	O
space	O
would	O
be	O
less	O
than	O
m	O
for	O
example	B
consider	O
a	O
matrix	O
the	O
target	O
b	O
is	O
but	O
x	O
is	O
only	O
so	O
modifying	O
the	O
value	O
of	O
x	O
the	O
equation	O
has	O
a	O
solution	O
at	O
best	O
allows	O
us	O
to	O
trace	O
out	O
a	O
plane	O
within	O
r	O
if	O
and	O
only	O
if	O
lies	O
on	O
that	O
plane	O
b	O
having	O
n	O
m	O
is	O
only	O
a	O
necessary	O
condition	O
for	O
every	O
point	O
to	O
have	O
a	O
solution	O
it	O
is	O
not	O
a	O
sufficient	O
condition	O
because	O
it	O
is	O
possible	O
for	O
some	O
of	O
the	O
columns	O
to	O
matrix	O
where	O
both	O
of	O
the	O
columns	O
are	O
identical	O
be	O
redundant	O
consider	O
a	O
this	O
has	O
the	O
same	O
column	O
space	O
as	O
a	O
matrix	O
containing	O
only	O
one	O
copy	O
of	O
the	O
replicated	O
column	O
in	O
other	O
words	O
the	O
column	O
space	O
is	O
still	O
just	O
a	O
line	O
and	O
fails	O
to	O
encompass	O
all	O
of	O
r	O
even	O
though	O
there	O
are	O
two	O
columns	O
formally	O
this	O
kind	O
of	O
redundancy	O
is	O
known	O
as	O
linear	B
dependence	I
a	O
set	O
of	O
vectors	O
is	O
linearly	O
independent	O
if	O
no	O
vector	O
in	O
the	O
set	O
is	O
a	O
linear	B
combination	I
of	O
the	O
other	O
vectors	O
if	O
we	O
add	O
a	O
vector	O
to	O
a	O
set	O
that	O
is	O
a	O
linear	B
combination	I
of	O
the	O
other	O
vectors	O
in	O
the	O
set	O
the	O
new	O
vector	O
does	O
not	O
add	O
any	O
points	O
to	O
the	O
set	O
s	O
m	O
span	O
this	O
means	O
that	O
for	O
the	O
column	O
space	O
of	O
the	O
matrix	O
to	O
encompass	O
all	O
of	O
r	O
the	O
matrix	O
must	O
contain	O
at	O
least	O
one	O
set	O
of	O
m	O
linearly	O
independent	O
columns	O
this	O
condition	O
is	O
both	O
necessary	O
and	O
sufficient	O
for	O
equation	O
to	O
have	O
a	O
solution	O
for	O
every	O
value	O
of	O
b	O
note	O
that	O
the	O
requirement	O
is	O
for	O
a	O
set	O
to	O
have	O
exactly	O
m	O
linear	O
independent	O
columns	O
not	O
at	O
least	O
m	O
no	O
set	O
of	O
m-dimensional	O
vectors	O
can	O
have	O
more	O
than	O
m	O
mutually	O
linearly	O
independent	O
columns	O
but	O
a	O
matrix	O
with	O
more	O
than	O
m	O
columns	O
may	O
have	O
more	O
than	O
one	O
such	O
set	O
in	O
order	O
for	O
the	O
matrix	O
to	O
have	O
an	O
inverse	O
we	O
additionally	O
need	O
to	O
ensure	O
that	O
b	O
to	O
do	O
so	O
we	O
need	O
to	O
equation	O
ensure	O
that	O
the	O
matrix	O
has	O
at	O
most	O
m	O
columns	O
otherwise	O
there	O
is	O
more	O
than	O
one	O
way	O
of	O
parametrizing	O
each	O
solution	O
one	O
solution	O
for	O
each	O
value	O
of	O
at	O
most	O
has	O
together	O
this	O
means	O
that	O
the	O
matrix	O
must	O
be	O
square	O
that	O
is	O
we	O
require	O
that	O
m	O
n	O
and	O
that	O
all	O
of	O
the	O
columns	O
must	O
be	O
linearly	O
independent	O
a	O
square	B
matrix	I
with	O
linearly	O
dependent	O
columns	O
is	O
known	O
as	O
singular	O
if	O
a	O
is	O
not	O
square	O
or	O
is	O
square	O
but	O
singular	O
it	O
can	O
still	O
be	O
possible	O
to	O
solve	O
the	O
equation	O
however	O
we	O
can	O
not	O
use	O
the	O
method	O
of	O
matrix	O
inversion	O
to	O
find	O
the	O
chapter	O
linear	O
algebra	O
solution	O
so	O
far	O
we	O
have	O
discussed	O
matrix	O
inverses	O
as	O
being	O
multiplied	O
on	O
the	O
left	O
it	O
is	O
also	O
possible	O
to	O
define	O
an	O
inverse	O
that	O
is	O
multiplied	O
on	O
the	O
right	O
i	O
aa	O
for	O
square	O
matrices	O
the	O
left	O
inverse	O
and	O
right	O
inverse	O
are	O
equal	O
norms	O
sometimes	O
we	O
need	O
to	O
measure	O
the	O
size	O
of	O
a	O
vector	O
in	O
machine	B
learning	I
we	O
usually	O
measure	O
the	O
size	O
of	O
vectors	O
using	O
a	O
function	O
called	O
a	O
norm	O
formally	O
the	O
lp	B
norm	I
is	O
given	O
by	O
x	O
p	O
x	O
i	O
p	O
p	O
p	O
r	O
for	O
p	O
i	O
norms	O
including	O
the	O
lp	B
norm	I
are	O
functions	O
mapping	O
vectors	O
to	O
non-negative	O
values	O
on	O
an	O
intuitive	O
level	O
the	O
norm	O
of	O
a	O
vector	O
x	O
measures	O
the	O
distance	O
from	O
the	O
origin	O
to	O
the	O
point	O
x	O
more	O
rigorously	O
a	O
norm	O
is	O
any	O
function	O
f	O
that	O
satisfies	O
the	O
following	O
properties	O
x	O
f	O
f	O
x	O
y	O
x	O
f	O
f	O
r	O
f	O
x	O
f	O
triangle	B
inequality	I
the	O
norm	O
with	O
p	O
is	O
known	O
as	O
the	O
euclidean	B
norm	I
it	O
is	O
simply	O
the	O
euclidean	O
distance	O
from	O
the	O
origin	O
to	O
the	O
point	O
identified	O
by	O
x	O
the	O
l	O
norm	O
is	O
x	O
with	O
used	O
so	O
frequently	O
in	O
machine	B
learning	I
that	O
it	O
is	O
often	O
denoted	O
simply	O
as	O
omitted	O
it	O
is	O
also	O
common	O
to	O
measure	O
the	O
size	O
of	O
a	O
vector	O
using	O
the	O
subscript	O
the	O
squared	O
norm	O
which	O
can	O
be	O
calculated	O
simply	O
as	O
x	O
x	O
the	O
squared	O
norm	O
is	O
more	O
convenient	O
to	O
work	O
with	O
mathematically	O
and	O
computationally	O
than	O
the	O
l	O
norm	O
itself	O
for	O
example	B
the	O
derivatives	O
of	O
the	O
squared	O
norm	O
with	O
respect	O
to	O
each	O
element	O
of	O
x	O
each	O
depend	O
only	O
on	O
the	O
corresponding	O
element	O
of	O
x	O
while	O
all	O
of	O
the	O
derivatives	O
of	O
the	O
norm	O
depend	O
on	O
the	O
entire	O
vector	O
in	O
many	O
contexts	O
the	O
squared	O
norm	O
may	O
be	O
undesirable	O
in	O
several	O
machine	B
learning	I
because	O
it	O
increases	O
very	O
slowly	O
near	O
the	O
origin	O
chapter	O
linear	O
algebra	O
applications	O
it	O
is	O
important	O
to	O
discriminate	O
between	O
elements	O
that	O
are	O
exactly	O
zero	O
and	O
elements	O
that	O
are	O
small	O
but	O
nonzero	O
in	O
these	O
cases	O
we	O
turn	O
to	O
a	O
function	O
that	O
grows	O
at	O
the	O
same	O
rate	O
in	O
all	O
locations	O
but	O
retains	O
mathematical	O
simplicity	O
the	O
norm	O
the	O
norm	O
may	O
be	O
simplified	O
to	O
x	O
xi	O
the	O
norm	O
is	O
commonly	O
used	O
in	O
machine	B
learning	I
when	O
the	O
difference	O
between	O
zero	O
and	O
nonzero	O
elements	O
is	O
very	O
important	O
every	O
time	O
an	O
element	O
of	O
x	O
moves	O
away	O
from	O
by	O
the	O
norm	O
increases	O
by	O
i	O
we	O
sometimes	O
measure	O
the	O
size	O
of	O
the	O
vector	O
by	O
counting	O
its	O
number	O
of	O
nonzero	O
elements	O
some	O
authors	O
refer	O
to	O
this	O
function	O
as	O
the	O
norm	O
but	O
this	O
is	O
incorrect	O
terminology	O
the	O
number	O
of	O
non-zero	O
entries	O
in	O
a	O
vector	O
is	O
not	O
a	O
norm	O
because	O
scaling	O
the	O
vector	O
by	O
does	O
not	O
change	O
the	O
number	O
of	O
nonzero	O
entries	O
the	O
norm	O
is	O
often	O
used	O
as	O
a	O
substitute	O
for	O
the	O
number	O
of	O
nonzero	O
entries	O
one	O
other	O
norm	O
that	O
commonly	O
arises	O
in	O
machine	B
learning	I
is	O
the	O
l	O
norm	O
also	O
known	O
as	O
the	O
max	B
norm	I
this	O
norm	O
simplifies	O
to	O
the	O
absolute	O
value	O
of	O
the	O
element	O
with	O
the	O
largest	O
magnitude	O
in	O
the	O
vector	O
x	O
max	O
xi	O
i	O
a	O
f	O
sometimes	O
we	O
may	O
also	O
wish	O
to	O
measure	O
the	O
size	O
of	O
a	O
matrix	O
in	O
the	O
context	O
of	O
deep	O
learning	O
the	O
most	O
common	O
way	O
to	O
do	O
this	O
is	O
with	O
the	O
otherwise	O
obscure	O
frobenius	B
norm	I
a	O
ij	O
ij	O
which	O
is	O
analogous	O
to	O
the	O
l	O
norm	O
of	O
a	O
vector	O
the	O
dot	O
product	O
of	O
two	O
vectors	O
can	O
be	O
rewritten	O
in	O
terms	O
of	O
norms	O
specifically	O
x	O
y	O
x	O
y	O
cos	O
where	O
is	O
the	O
angle	O
between	O
x	O
and	O
y	O
special	O
kinds	O
of	O
matrices	O
and	O
vectors	O
some	O
special	O
kinds	O
of	O
matrices	O
and	O
vectors	O
are	O
particularly	O
useful	O
diagonal	O
matrices	O
consist	O
mostly	O
of	O
zeros	O
and	O
have	O
non-zero	O
entries	O
only	O
along	O
the	O
main	B
diagonal	I
formally	O
a	O
matrix	O
d	O
is	O
diagonal	O
if	O
and	O
only	O
if	O
dij	O
for	O
chapter	O
linear	O
algebra	O
all	O
i	O
j	O
we	O
have	O
already	O
seen	O
one	O
example	B
of	O
a	O
diagonal	B
matrix	I
the	O
identity	B
matrix	I
where	O
all	O
of	O
the	O
diagonal	O
entries	O
are	O
we	O
write	O
diagv	O
to	O
denote	O
a	O
square	O
diagonal	B
matrix	I
whose	O
diagonal	O
entries	O
are	O
given	O
by	O
the	O
entries	O
of	O
the	O
vector	O
v	O
diagonal	O
matrices	O
are	O
of	O
interest	O
in	O
part	O
because	O
multiplying	O
by	O
a	O
diagonal	B
matrix	I
is	O
very	O
computationally	O
efficient	O
to	O
compute	O
diagvx	O
we	O
only	O
need	O
to	O
scale	O
each	O
element	O
xi	O
by	O
vi	O
in	O
other	O
words	O
diagvx	O
v	O
x	O
inverting	O
a	O
square	O
diagonal	B
matrix	I
is	O
also	O
efficient	O
the	O
inverse	O
exists	O
only	O
if	O
every	O
diagonal	O
entry	O
is	O
nonzero	O
and	O
in	O
that	O
case	O
diagv	O
in	O
many	O
cases	O
we	O
may	O
derive	O
some	O
very	O
general	O
machine	B
learning	I
algorithm	O
in	O
terms	O
of	O
arbitrary	O
matrices	O
but	O
obtain	O
a	O
less	O
expensive	O
less	O
descriptive	O
algorithm	O
by	O
restricting	O
some	O
matrices	O
to	O
be	O
diagonal	O
not	O
all	O
diagonal	O
matrices	O
need	O
be	O
square	O
it	O
is	O
possible	O
to	O
construct	O
a	O
rectangular	O
diagonal	B
matrix	I
non-square	O
diagonal	O
matrices	O
do	O
not	O
have	O
inverses	O
but	O
it	O
is	O
still	O
possible	O
to	O
multiply	O
by	O
them	O
cheaply	O
for	O
a	O
non-square	O
diagonal	B
matrix	I
d	O
the	O
product	O
dx	O
will	O
involve	O
scaling	O
each	O
element	O
of	O
x	O
and	O
either	O
concatenating	O
some	O
zeros	O
to	O
the	O
result	O
if	O
d	O
is	O
taller	O
than	O
it	O
is	O
wide	O
or	O
discarding	O
some	O
of	O
the	O
last	O
elements	O
of	O
the	O
vector	O
if	O
is	O
wider	O
than	O
it	O
is	O
tall	O
d	O
a	O
symmetric	O
matrix	O
is	O
any	O
matrix	O
that	O
is	O
equal	O
to	O
its	O
own	O
transpose	O
a	O
a	O
symmetric	O
matrices	O
often	O
arise	O
when	O
the	O
entries	O
are	O
generated	O
by	O
some	O
function	O
of	O
two	O
arguments	O
that	O
does	O
not	O
depend	O
on	O
the	O
order	O
of	O
the	O
arguments	O
for	O
example	B
if	O
a	O
is	O
a	O
matrix	O
of	O
distance	O
measurements	O
with	O
aij	O
giving	O
the	O
distance	O
from	O
point	O
i	O
to	O
point	O
aij	O
aji	O
because	O
distance	O
functions	O
are	O
symmetric	O
then	O
j	O
a	O
unit	B
vector	I
is	O
a	O
vector	O
with	O
unit	B
norm	I
x	O
a	O
vector	O
x	O
and	O
a	O
vector	O
y	O
are	O
orthogonal	O
to	O
each	O
other	O
if	O
x	O
y	O
if	O
both	O
vectors	O
have	O
nonzero	O
norm	O
this	O
means	O
that	O
they	O
are	O
at	O
a	O
degree	O
angle	O
to	O
each	O
n	O
at	O
most	O
n	O
vectors	O
may	O
be	O
mutually	O
orthogonal	O
with	O
nonzero	O
norm	O
other	O
in	O
r	O
if	O
the	O
vectors	O
are	O
not	O
only	O
orthogonal	O
but	O
also	O
have	O
unit	B
norm	I
we	O
call	O
them	O
orthonormal	O
an	O
orthogonal	B
matrix	I
is	O
a	O
square	B
matrix	I
whose	O
rows	O
are	O
mutually	O
orthonor	O
mal	O
and	O
whose	O
columns	O
are	O
mutually	O
orthonormal	O
a	O
aa	O
a	O
i	O
chapter	O
linear	O
algebra	O
this	O
implies	O
that	O
a	O
a	O
so	O
orthogonal	O
matrices	O
are	O
of	O
interest	O
because	O
their	O
inverse	O
is	O
very	O
cheap	O
to	O
compute	O
pay	O
careful	O
attention	O
to	O
the	O
definition	O
of	O
orthogonal	O
matrices	O
counterintuitively	O
their	O
rows	O
are	O
not	O
merely	O
orthogonal	O
but	O
fully	O
orthonormal	O
there	O
is	O
no	O
special	O
term	O
for	O
a	O
matrix	O
whose	O
rows	O
or	O
columns	O
are	O
orthogonal	O
but	O
not	O
orthonormal	O
eigendecomposition	B
many	O
mathematical	O
objects	O
can	O
be	O
understood	O
better	O
by	O
breaking	O
them	O
into	O
constituent	O
parts	O
or	O
finding	O
some	O
properties	O
of	O
them	O
that	O
are	O
universal	O
not	O
caused	O
by	O
the	O
way	O
we	O
choose	O
to	O
represent	O
them	O
for	O
example	B
integers	O
can	O
be	O
decomposed	O
into	O
prime	O
factors	O
the	O
way	O
we	O
will	O
change	O
depending	O
on	O
whether	O
we	O
write	O
it	O
in	O
base	O
ten	O
from	O
this	O
representation	O
is	O
not	O
divisible	O
by	O
or	O
that	O
any	O
represent	O
the	O
number	O
or	O
in	O
binary	O
but	O
it	O
will	O
always	O
be	O
true	O
that	O
we	O
can	O
conclude	O
useful	O
properties	O
such	O
as	O
that	O
integer	O
multiple	O
of	O
will	O
be	O
divisible	O
by	O
much	O
as	O
we	O
can	O
discover	O
something	O
about	O
the	O
true	O
nature	O
of	O
an	O
integer	O
by	O
decomposing	O
it	O
into	O
prime	O
factors	O
we	O
can	O
also	O
decompose	O
matrices	O
in	O
ways	O
that	O
show	O
us	O
information	O
about	O
their	O
functional	O
properties	O
that	O
is	O
not	O
obvious	O
from	O
the	O
representation	O
of	O
the	O
matrix	O
as	O
an	O
array	O
of	O
elements	O
one	O
of	O
the	O
most	O
widely	O
used	O
kinds	O
of	O
matrix	O
decomposition	O
is	O
called	O
eigendecomposition	B
in	O
which	O
we	O
decompose	O
a	O
matrix	O
into	O
a	O
set	O
of	O
eigenvectors	O
and	O
eigenvalues	O
an	O
eigenvector	B
of	O
a	O
square	B
matrix	I
a	O
is	O
a	O
non-zero	O
vector	O
v	O
such	O
that	O
multi	O
plication	O
by	O
a	O
alters	O
only	O
the	O
scale	O
of	O
v	O
av	O
v	O
the	O
scalar	O
is	O
known	O
as	O
the	O
eigenvalue	B
corresponding	O
to	O
this	O
eigenvector	B
can	O
also	O
find	O
a	O
left	O
eigenvector	B
such	O
that	O
v	O
but	O
we	O
are	O
usually	O
concerned	O
with	O
right	O
eigenvectors	O
a	O
v	O
if	O
v	O
is	O
an	O
eigenvector	B
of	O
a	O
then	O
so	O
is	O
any	O
rescaled	O
vector	O
sv	O
for	O
s	O
moreover	O
sv	O
still	O
has	O
the	O
same	O
eigenvalue	B
for	O
this	O
reason	O
we	O
usually	O
only	O
look	O
for	O
unit	O
eigenvectors	O
s	O
r	O
suppose	O
that	O
a	O
matrix	O
a	O
has	O
n	O
linearly	O
independent	O
eigenvectors	O
v	O
with	O
corresponding	O
eigenvalues	O
we	O
may	O
concatenate	O
all	O
of	O
the	O
n	O
chapter	O
linear	O
algebra	O
figure	O
an	O
example	B
of	O
the	O
effect	O
of	O
eigenvectors	O
and	O
eigenvalues	O
here	O
we	O
have	O
a	O
matrix	O
a	O
with	O
two	O
orthonormal	O
eigenvectors	O
with	O
eigenvalue	B
and	O
v	O
with	O
eigenvalue	B
plot	O
the	O
set	O
of	O
all	O
unit	O
vectors	O
u	O
as	O
a	O
unit	O
circle	O
plot	O
the	O
set	O
of	O
all	O
points	O
au	O
by	O
observing	O
the	O
way	O
that	O
a	O
distorts	O
the	O
unit	O
circle	O
we	O
can	O
see	O
that	O
it	O
scales	O
space	O
in	O
direction	O
v	O
by	O
i	O
r	O
eigenvectors	O
to	O
form	O
a	O
matrix	O
v	O
with	O
one	O
eigenvector	B
per	O
column	O
v	O
v	O
likewise	O
we	O
can	O
concatenate	O
the	O
eigenvalues	O
to	O
form	O
a	O
vector	O
n	O
the	O
eigendecomposition	B
a	O
is	O
then	O
given	O
by	O
of	O
a	O
v	O
diag	O
v	O
we	O
have	O
seen	O
that	O
constructing	O
matrices	O
with	O
specific	O
eigenvalues	O
and	O
eigenvectors	O
allows	O
us	O
to	O
stretch	O
space	O
in	O
desired	O
directions	O
however	O
we	O
often	O
want	O
to	O
decompose	O
matrices	O
into	O
their	O
eigenvalues	O
and	O
eigenvectors	O
doing	O
so	O
can	O
help	O
us	O
to	O
analyze	O
certain	O
properties	O
of	O
the	O
matrix	O
much	O
as	O
decomposing	O
an	O
integer	O
into	O
its	O
prime	O
factors	O
can	O
help	O
us	O
understand	O
the	O
behavior	O
of	O
that	O
integer	O
not	O
every	O
matrix	O
can	O
be	O
decomposed	O
into	O
eigenvalues	O
and	O
eigenvectors	O
in	O
some	O
chapter	O
linear	O
algebra	O
cases	O
the	O
decomposition	O
exists	O
but	O
may	O
involve	O
complex	O
rather	O
than	O
real	O
numbers	O
fortunately	O
in	O
this	O
book	O
we	O
usually	O
need	O
to	O
decompose	O
only	O
a	O
specific	O
class	O
of	O
matrices	O
that	O
have	O
a	O
simple	O
decomposition	O
specifically	O
every	O
real	O
symmetric	O
matrix	O
can	O
be	O
decomposed	O
into	O
an	O
expression	O
using	O
only	O
real-valued	O
eigenvectors	O
and	O
eigenvalues	O
a	O
q	O
q	O
where	O
q	O
is	O
an	O
orthogonal	B
matrix	I
composed	O
of	O
eigenvectors	O
of	O
a	O
and	O
is	O
a	O
diagonal	B
matrix	I
the	O
eigenvalue	B
ii	O
is	O
associated	O
with	O
the	O
eigenvector	B
in	O
column	O
i	O
of	O
q	O
denoted	O
as	O
qi	O
because	O
q	O
is	O
an	O
orthogonal	B
matrix	I
we	O
can	O
think	O
of	O
a	O
as	O
scaling	O
space	O
by	O
i	O
in	O
direction	O
v	O
see	O
figure	O
for	O
an	O
example	B
while	O
any	O
real	O
symmetric	O
matrix	O
a	O
is	O
guaranteed	O
to	O
have	O
an	O
eigendecomposition	B
the	O
eigendecomposition	B
may	O
not	O
be	O
unique	O
if	O
any	O
two	O
or	O
more	O
eigenvectors	O
share	O
the	O
same	O
eigenvalue	B
then	O
any	O
set	O
of	O
orthogonal	O
vectors	O
lying	O
in	O
their	O
span	O
are	O
also	O
eigenvectors	O
with	O
that	O
eigenvalue	B
and	O
we	O
could	O
equivalently	O
choose	O
a	O
q	O
using	O
those	O
eigenvectors	O
instead	O
by	O
convention	O
we	O
usually	O
sort	O
the	O
entries	O
of	O
in	O
descending	O
order	O
under	O
this	O
convention	O
the	O
eigendecomposition	B
is	O
unique	O
only	O
if	O
all	O
of	O
the	O
eigenvalues	O
are	O
unique	O
the	O
eigendecomposition	B
of	O
a	O
matrix	O
tells	O
us	O
many	O
useful	O
facts	O
about	O
the	O
matrix	O
the	O
matrix	O
is	O
singular	O
if	O
and	O
only	O
if	O
any	O
of	O
the	O
eigenvalues	O
are	O
zero	O
the	O
eigendecomposition	B
of	O
a	O
real	O
symmetric	O
matrix	O
can	O
also	O
be	O
used	O
to	O
optimize	O
quadratic	O
expressions	O
of	O
the	O
form	O
fx	O
x	O
x	O
whenever	O
x	O
is	O
equal	O
to	O
an	O
eigenvector	B
of	O
a	O
f	O
takes	O
on	O
the	O
value	O
of	O
the	O
corresponding	O
eigenvalue	B
the	O
maximum	O
value	O
of	O
f	O
within	O
the	O
constraint	O
region	O
is	O
the	O
maximum	O
eigenvalue	B
and	O
its	O
minimum	O
value	O
within	O
the	O
constraint	O
region	O
is	O
the	O
minimum	O
eigenvalue	B
ax	O
subject	O
to	O
a	O
matrix	O
whose	O
eigenvalues	O
are	O
all	O
positive	O
is	O
called	O
positive	B
definite	I
a	O
matrix	O
whose	O
eigenvalues	O
are	O
all	O
positive	O
or	O
zero-valued	O
is	O
called	O
positive	O
semidefinite	O
likewise	O
if	O
all	O
eigenvalues	O
are	O
negative	O
the	O
matrix	O
is	O
negative	B
definite	I
and	O
if	O
all	O
eigenvalues	O
are	O
negative	O
or	O
zero-valued	O
it	O
is	O
negative	O
semidefinite	O
positive	O
semidefinite	O
matrices	O
are	O
interesting	O
because	O
they	O
guarantee	O
that	O
positive	B
definite	I
matrices	O
additionally	O
guarantee	O
that	O
x	O
x	O
x	O
ax	O
ax	O
x	O
singular	B
value	I
decomposition	O
in	O
section	O
we	O
saw	O
how	O
to	O
decompose	O
a	O
matrix	O
into	O
eigenvectors	O
and	O
eigenvalues	O
the	O
singular	B
value	I
decomposition	O
provides	O
another	O
way	O
to	O
factorize	O
a	O
matrix	O
into	O
singular	O
vectors	O
and	O
singular	O
values	O
the	O
svd	O
allows	O
us	O
to	O
discover	O
some	O
of	O
the	O
same	O
kind	O
of	O
information	O
as	O
the	O
eigendecomposition	B
however	O
chapter	O
linear	O
algebra	O
the	O
svd	O
is	O
more	O
generally	O
applicable	O
every	O
real	O
matrix	O
has	O
a	O
singular	B
value	I
decomposition	O
but	O
the	O
same	O
is	O
not	O
true	O
of	O
the	O
eigenvalue	B
decomposition	O
for	O
example	B
if	O
a	O
matrix	O
is	O
not	O
square	O
the	O
eigendecomposition	B
is	O
not	O
defined	O
and	O
we	O
must	O
use	O
a	O
singular	B
value	I
decomposition	O
instead	O
recall	B
that	O
the	O
eigendecomposition	B
involves	O
analyzing	O
a	O
matrix	O
a	O
to	O
discover	O
a	O
matrix	O
v	O
of	O
eigenvectors	O
and	O
a	O
vector	O
of	O
eigenvalues	O
such	O
that	O
we	O
can	O
rewrite	O
a	O
as	O
a	O
v	O
diag	O
v	O
the	O
singular	B
value	I
decomposition	O
is	O
similar	O
except	O
this	O
time	O
we	O
will	O
write	O
a	O
as	O
a	O
product	O
of	O
three	O
matrices	O
a	O
u	O
dv	O
suppose	O
that	O
a	O
is	O
an	O
m	O
n	O
to	O
be	O
an	O
matrix	O
and	O
m	O
n	O
d	O
matrix	O
then	O
u	O
is	O
defined	O
to	O
be	O
an	O
m	O
m	O
v	O
to	O
be	O
an	O
matrix	O
n	O
n	O
matrix	O
each	O
of	O
these	O
matrices	O
is	O
defined	O
to	O
have	O
a	O
special	O
structure	O
the	O
matrices	O
u	O
and	O
v	O
are	O
both	O
defined	O
to	O
be	O
orthogonal	O
matrices	O
the	O
matrix	O
d	O
is	O
defined	O
to	O
be	O
a	O
diagonal	B
matrix	I
note	O
that	O
is	O
not	O
necessarily	O
square	O
d	O
the	O
elements	O
along	O
the	O
diagonal	O
of	O
d	O
are	O
known	O
as	O
the	O
singular	O
values	O
of	O
the	O
matrix	O
a	O
the	O
columns	O
of	O
u	O
are	O
known	O
as	O
the	O
left-singular	O
vectors	O
the	O
columns	O
of	O
right-singular	O
vectors	O
are	O
known	O
as	O
as	O
the	O
v	O
we	O
can	O
actually	O
interpret	O
the	O
singular	B
value	I
decomposition	O
of	O
a	O
in	O
terms	O
of	O
the	O
eigendecomposition	B
of	O
functions	O
of	O
a	O
the	O
left-singular	O
vectors	O
of	O
a	O
are	O
the	O
a	O
the	O
right-singular	O
vectors	O
of	O
a	O
are	O
the	O
eigenvectors	O
of	O
a	O
eigenvectors	O
of	O
aa	O
the	O
non-zero	O
singular	O
values	O
of	O
a	O
are	O
the	O
square	O
roots	O
of	O
the	O
eigenvalues	O
of	O
a	O
a	O
the	O
same	O
is	O
true	O
for	O
aa	O
perhaps	O
the	O
most	O
useful	O
feature	B
of	O
the	O
svd	O
is	O
that	O
we	O
can	O
use	O
it	O
to	O
partially	O
generalize	O
matrix	O
inversion	O
to	O
non-square	O
matrices	O
as	O
we	O
will	O
see	O
in	O
the	O
next	O
section	O
the	O
moore-penrose	O
pseudoinverse	O
matrix	O
inversion	O
is	O
not	O
defined	O
for	O
matrices	O
that	O
are	O
not	O
square	O
suppose	O
we	O
want	O
to	O
make	O
a	O
left-inverse	O
so	O
that	O
we	O
can	O
solve	O
a	O
linear	O
equation	O
of	O
a	O
matrix	O
a	O
b	O
ax	O
y	O
chapter	O
linear	O
algebra	O
by	O
left-multiplying	O
each	O
side	O
to	O
obtain	O
x	O
by	O
depending	O
on	O
the	O
structure	O
of	O
the	O
problem	O
it	O
may	O
not	O
be	O
possible	O
to	O
design	O
a	O
unique	O
mapping	O
from	O
to	O
a	O
b	O
if	O
a	O
is	O
taller	O
than	O
it	O
is	O
wide	O
then	O
it	O
is	O
possible	O
for	O
this	O
equation	O
to	O
have	O
no	O
solution	O
if	O
a	O
is	O
wider	O
than	O
it	O
is	O
tall	O
then	O
there	O
could	O
be	O
multiple	O
possible	O
solutions	O
the	O
moore-penrose	O
pseudoinverse	O
allows	O
us	O
to	O
make	O
some	O
headway	O
in	O
these	O
cases	O
the	O
pseudoinverse	O
of	O
a	O
is	O
defined	O
as	O
a	O
matrix	O
a	O
lim	O
a	O
i	O
practical	O
algorithms	O
for	O
computing	O
the	O
pseudoinverse	O
are	O
not	O
based	O
on	O
this	O
definition	O
but	O
rather	O
the	O
formula	O
a	O
v	O
d	O
where	O
u	O
d	O
and	O
v	O
are	O
the	O
singular	B
value	I
decomposition	O
of	O
a	O
and	O
the	O
pseudoinverse	O
d	O
of	O
a	O
diagonal	B
matrix	I
d	O
is	O
obtained	O
by	O
taking	O
the	O
reciprocal	O
of	O
its	O
non-zero	O
elements	O
then	O
taking	O
the	O
transpose	O
of	O
the	O
resulting	O
matrix	O
when	O
a	O
has	O
more	O
columns	O
than	O
rows	O
then	O
solving	O
a	O
linear	O
equation	O
using	O
the	O
pseudoinverse	O
provides	O
one	O
of	O
the	O
many	O
possible	O
solutions	O
specifically	O
it	O
provides	O
the	O
solution	O
x	O
a	O
y	O
with	O
minimal	O
euclidean	B
norm	I
x	O
among	O
all	O
possible	O
solutions	O
when	O
a	O
has	O
more	O
rows	O
than	O
columns	O
it	O
is	O
possible	O
for	O
there	O
to	O
be	O
no	O
solution	O
in	O
this	O
case	O
using	O
the	O
pseudoinverse	O
gives	O
us	O
the	O
x	O
for	O
which	O
ax	O
is	O
as	O
close	O
as	O
possible	O
to	O
in	O
terms	O
of	O
euclidean	B
norm	I
ax	O
y	O
y	O
the	O
trace	B
operator	I
the	O
trace	B
operator	I
gives	O
the	O
sum	O
of	O
all	O
of	O
the	O
diagonal	O
entries	O
of	O
a	O
matrix	O
tr	O
aii	O
i	O
the	O
trace	B
operator	I
is	O
useful	O
for	O
a	O
variety	O
of	O
reasons	O
some	O
operations	O
that	O
are	O
difficult	O
to	O
specify	O
without	O
resorting	O
to	O
summation	O
notation	O
can	O
be	O
specified	O
using	O
chapter	O
linear	O
algebra	O
matrix	O
products	O
and	O
the	O
trace	B
operator	I
for	O
example	B
the	O
trace	B
operator	I
provides	O
an	O
alternative	O
way	O
of	O
writing	O
the	O
frobenius	B
norm	I
of	O
a	O
matrix	O
a	O
f	O
traa	O
writing	O
an	O
expression	O
in	O
terms	O
of	O
the	O
trace	B
operator	I
opens	O
up	O
opportunities	O
to	O
manipulate	O
the	O
expression	O
using	O
many	O
useful	O
identities	O
for	O
example	B
the	O
trace	B
operator	I
is	O
invariant	O
to	O
the	O
transpose	O
operator	O
a	O
tr	O
tr	O
a	O
the	O
trace	O
of	O
a	O
square	B
matrix	I
composed	O
of	O
many	O
factors	O
is	O
also	O
invariant	O
to	O
moving	O
the	O
last	O
factor	O
into	O
the	O
first	O
position	O
if	O
the	O
shapes	O
of	O
the	O
corresponding	O
matrices	O
allow	O
the	O
resulting	O
product	O
to	O
be	O
defined	O
tr	O
abc	O
tr	O
cab	O
tr	O
bca	O
or	O
more	O
generally	O
n	O
n	O
tr	O
f	O
trf	O
f	O
this	O
invariance	B
to	O
cyclic	O
permutation	O
holds	O
even	O
if	O
the	O
resulting	O
product	O
has	O
a	O
different	O
shape	O
for	O
example	B
for	O
a	O
we	O
have	O
m	O
n	O
n	O
m	O
and	O
b	O
r	O
r	O
even	O
though	O
ab	O
m	O
m	O
r	O
tr	O
ab	O
tr	O
ba	O
n	O
n	O
r	O
and	O
ba	O
another	O
useful	O
fact	O
to	O
keep	O
in	O
mind	O
is	O
that	O
a	O
scalar	O
is	O
its	O
own	O
trace	O
a	O
tra	O
the	O
determinant	O
the	O
determinant	O
of	O
a	O
square	B
matrix	I
denoted	O
deta	O
is	O
a	O
function	O
mapping	O
matrices	O
to	O
real	O
scalars	O
the	O
determinant	O
is	O
equal	O
to	O
the	O
product	O
of	O
all	O
the	O
eigenvalues	O
of	O
the	O
matrix	O
the	O
absolute	O
value	O
of	O
the	O
determinant	O
can	O
be	O
thought	O
of	O
as	O
a	O
measure	O
of	O
how	O
much	O
multiplication	O
by	O
the	O
matrix	O
expands	O
or	O
contracts	O
space	O
if	O
the	O
determinant	O
is	O
then	O
space	O
is	O
contracted	O
completely	O
along	O
at	O
least	O
one	O
dimension	O
causing	O
it	O
to	O
lose	O
all	O
of	O
its	O
volume	O
if	O
the	O
determinant	O
is	O
then	O
the	O
transformation	O
preserves	O
volume	O
chapter	O
linear	O
algebra	O
example	B
principal	O
components	O
analysis	O
one	O
simple	O
machine	B
learning	I
algorithm	O
principal	O
components	O
analysis	O
or	O
pca	O
can	O
be	O
derived	O
using	O
only	O
knowledge	O
of	O
basic	O
linear	O
algebra	O
suppose	O
we	O
have	O
a	O
collection	O
of	O
m	O
points	O
n	O
suppose	O
we	O
would	O
like	O
to	O
apply	O
lossy	O
compression	O
to	O
these	O
points	O
lossy	O
compression	O
means	O
storing	O
the	O
points	O
in	O
a	O
way	O
that	O
requires	O
less	O
memory	O
but	O
may	O
lose	O
some	O
precision	B
we	O
would	O
like	O
to	O
lose	O
as	O
little	O
precision	B
as	O
possible	O
in	O
r	O
x	O
one	O
way	O
we	O
can	O
encode	O
these	O
points	O
is	O
to	O
represent	O
a	O
lower-dimensional	O
version	O
l	O
of	O
them	O
for	O
each	O
point	O
x	O
if	O
l	O
is	O
smaller	O
than	O
n	O
it	O
will	O
take	O
less	O
memory	O
to	O
store	O
the	O
code	O
points	O
than	O
the	O
original	O
data	O
we	O
will	O
want	O
to	O
find	O
some	O
encoding	O
function	O
that	O
produces	O
the	O
code	O
for	O
an	O
input	O
fx	O
c	O
and	O
a	O
decoding	O
function	O
that	O
produces	O
the	O
reconstructed	O
input	O
given	O
its	O
code	O
n	O
we	O
will	O
find	O
a	O
corresponding	O
code	O
vector	O
c	O
g	O
f	O
x	O
x	O
r	O
r	O
pca	O
is	O
defined	O
by	O
our	O
choice	O
of	O
the	O
decoding	O
function	O
specifically	O
to	O
make	O
the	O
decoder	B
very	O
simple	O
we	O
choose	O
to	O
use	O
matrix	O
multiplication	O
to	O
map	O
the	O
code	O
back	O
into	O
r	O
is	O
the	O
matrix	O
defining	O
the	O
decoding	O
c	O
dc	O
where	O
g	O
n	O
let	O
n	O
l	O
d	O
r	O
computing	O
the	O
optimal	O
code	O
for	O
this	O
decoder	B
could	O
be	O
a	O
difficult	O
problem	O
to	O
keep	O
the	O
encoding	O
problem	O
easy	O
pca	O
constrains	O
the	O
columns	O
of	O
d	O
to	O
be	O
orthogonal	O
to	O
each	O
other	O
that	O
d	O
is	O
still	O
not	O
technically	O
an	O
orthogonal	B
matrix	I
unless	O
l	O
n	O
with	O
the	O
problem	O
as	O
described	O
so	O
far	O
many	O
solutions	O
are	O
possible	O
because	O
we	O
can	O
increase	O
the	O
scale	O
of	O
di	O
if	O
we	O
decrease	O
ci	O
proportionally	O
for	O
all	O
points	O
to	O
give	O
the	O
problem	O
a	O
unique	O
solution	O
we	O
constrain	O
all	O
of	O
the	O
columns	O
of	O
to	O
have	O
unit	B
norm	I
d	O
in	O
order	O
to	O
turn	O
this	O
basic	O
idea	O
into	O
an	O
algorithm	O
we	O
can	O
implement	O
the	O
first	O
thing	O
we	O
need	O
to	O
do	O
is	O
figure	O
out	O
how	O
to	O
generate	O
the	O
optimal	O
code	O
point	O
c	O
for	O
each	O
input	O
point	O
x	O
one	O
way	O
to	O
do	O
this	O
is	O
to	O
minimize	O
the	O
distance	O
between	O
the	O
input	O
point	O
x	O
and	O
its	O
reconstruction	O
gc	O
we	O
can	O
measure	O
this	O
distance	O
using	O
a	O
norm	O
in	O
the	O
principal	O
components	O
algorithm	O
we	O
use	O
the	O
norm	O
c	O
arg	O
min	O
c	O
x	O
g	O
we	O
can	O
switch	O
to	O
the	O
squared	O
l	O
norm	O
instead	O
of	O
the	O
norm	O
itself	O
because	O
both	O
are	O
minimized	O
by	O
the	O
same	O
value	O
of	O
c	O
both	O
are	O
minimized	O
by	O
the	O
same	O
value	O
of	O
c	O
because	O
the	O
norm	O
is	O
non-negative	O
and	O
the	O
squaring	O
operation	B
is	O
chapter	O
linear	O
algebra	O
monotonically	O
increasing	O
for	O
non-negative	O
arguments	O
x	O
g	O
arg	O
min	O
c	O
c	O
the	O
function	O
being	O
minimized	O
simplifies	O
to	O
x	O
x	O
g	O
c	O
g	O
c	O
the	O
definition	O
of	O
the	O
norm	O
equation	O
x	O
x	O
x	O
g	O
g	O
x	O
c	O
g	O
the	O
distributive	O
property	O
x	O
x	O
x	O
g	O
g	O
g	O
the	O
scalar	O
g	O
x	O
is	O
equal	O
to	O
the	O
transpose	O
of	O
itself	O
we	O
can	O
now	O
change	O
the	O
function	O
being	O
minimized	O
again	O
to	O
omit	O
the	O
first	O
term	O
since	O
this	O
term	O
does	O
not	O
depend	O
on	O
arg	O
min	O
c	O
g	O
g	O
g	O
c	O
to	O
make	O
further	O
progress	O
we	O
must	O
substitute	O
in	O
the	O
definition	O
of	O
c	O
arg	O
min	O
c	O
arg	O
min	O
c	O
dc	O
d	O
c	O
dc	O
dc	O
c	O
il	O
c	O
the	O
orthogonality	B
and	O
unit	B
norm	I
constraints	O
on	O
dc	O
c	O
c	O
arg	O
min	O
c	O
g	O
we	O
can	O
solve	O
this	O
optimization	O
problem	O
using	O
vector	O
calculus	O
section	O
if	O
you	O
do	O
not	O
know	O
how	O
to	O
do	O
this	O
c	O
x	O
dc	O
c	O
c	O
x	O
c	O
c	O
d	O
x	O
chapter	O
linear	O
algebra	O
this	O
makes	O
the	O
algorithm	O
efficient	O
we	O
can	O
optimally	O
encode	O
x	O
just	O
using	O
a	O
matrix-vector	O
operation	B
to	O
encode	O
a	O
vector	O
we	O
apply	O
the	O
encoder	B
function	O
f	O
x	O
d	O
x	O
using	O
a	O
further	O
matrix	O
multiplication	O
we	O
can	O
also	O
define	O
the	O
pca	O
reconstruction	O
operation	B
r	O
x	O
g	O
f	O
x	O
dd	O
x	O
next	O
we	O
need	O
to	O
choose	O
the	O
encoding	O
matrix	O
d	O
to	O
do	O
so	O
we	O
revisit	O
the	O
idea	O
of	O
minimizing	O
the	O
l	O
distance	O
between	O
inputs	O
and	O
reconstructions	O
since	O
we	O
will	O
use	O
the	O
same	O
matrix	O
d	O
to	O
decode	O
all	O
of	O
the	O
points	O
we	O
can	O
no	O
longer	O
consider	O
the	O
points	O
in	O
isolation	O
instead	O
we	O
must	O
minimize	O
the	O
frobenius	B
norm	I
of	O
the	O
matrix	O
of	O
errors	O
computed	O
over	O
all	O
dimensions	O
and	O
all	O
points	O
d	O
arg	O
min	O
d	O
ij	O
x	O
j	O
rx	O
subject	O
to	O
d	O
d	O
i	O
l	O
to	O
derive	O
the	O
algorithm	O
for	O
finding	O
d	O
we	O
will	O
start	O
by	O
considering	O
the	O
case	O
where	O
l	O
in	O
this	O
case	O
d	O
is	O
just	O
a	O
single	O
vector	O
d	O
substituting	O
equation	O
into	O
equation	O
into	O
the	O
problem	O
reduces	O
to	O
and	O
simplifying	O
d	O
d	O
d	O
arg	O
min	O
d	O
i	O
x	O
x	O
dd	O
subject	O
to	O
d	O
the	O
above	O
formulation	O
is	O
the	O
most	O
direct	O
way	O
of	O
performing	O
the	O
substitution	O
but	O
is	O
not	O
the	O
most	O
stylistically	O
pleasing	O
way	O
to	O
write	O
the	O
equation	O
it	O
places	O
the	O
x	O
on	O
the	O
right	O
of	O
the	O
vector	O
d	O
it	O
is	O
more	O
conventional	O
to	O
write	O
scalar	O
value	O
d	O
scalar	O
coefficients	O
on	O
the	O
left	O
of	O
vector	O
they	O
operate	O
on	O
we	O
therefore	O
usually	O
write	O
such	O
a	O
formula	O
as	O
d	O
arg	O
min	O
d	O
x	O
d	O
x	O
d	O
subject	O
to	O
d	O
i	O
or	O
exploiting	O
the	O
fact	O
that	O
a	O
scalar	O
is	O
its	O
own	O
transpose	O
as	O
d	O
x	O
x	O
dd	O
arg	O
min	O
subject	O
to	O
d	O
d	O
i	O
the	O
reader	O
should	O
aim	O
to	O
become	O
familiar	O
with	O
such	O
cosmetic	O
rearrangements	O
chapter	O
linear	O
algebra	O
at	O
this	O
point	O
it	O
can	O
be	O
helpful	O
to	O
rewrite	O
the	O
problem	O
in	O
terms	O
of	O
a	O
single	O
design	B
matrix	I
of	O
examples	O
rather	O
than	O
as	O
a	O
sum	O
over	O
separate	O
example	B
vectors	O
this	O
will	O
allow	O
us	O
to	O
use	O
more	O
compact	O
notation	O
let	O
x	O
be	O
the	O
matrix	O
defined	O
by	O
stacking	O
all	O
of	O
the	O
vectors	O
describing	O
the	O
points	O
such	O
that	O
xi	O
x	O
we	O
can	O
now	O
rewrite	O
the	O
problem	O
as	O
x	O
xdd	O
f	O
subject	O
to	O
d	O
arg	O
min	O
m	O
n	O
d	O
d	O
r	O
disregarding	O
the	O
constraint	O
for	O
the	O
moment	O
we	O
can	O
simplify	O
the	O
frobenius	B
norm	I
portion	O
as	O
follows	O
d	O
f	O
x	O
xdd	O
arg	O
min	O
d	O
x	O
xdd	O
x	O
xdd	O
xdd	O
x	O
arg	O
min	O
d	O
tr	O
equation	O
arg	O
min	O
trx	O
d	O
arg	O
min	O
d	O
trx	O
arg	O
min	O
trx	O
x	O
x	O
x	O
tr	O
x	O
xdd	O
xdd	O
tr	O
dd	O
tr	O
x	O
x	O
dd	O
dd	O
x	O
x	O
xdd	O
x	O
trdd	O
xdd	O
dd	O
x	O
trdd	O
x	O
xdd	O
x	O
d	O
terms	O
not	O
involving	O
trx	O
arg	O
min	O
d	O
do	O
not	O
affect	O
the	O
xdd	O
trdd	O
x	O
xdd	O
arg	O
min	O
d	O
we	O
can	O
cycle	O
the	O
order	O
of	O
the	O
matrices	O
inside	O
a	O
trace	O
equation	O
trx	O
xdd	O
trx	O
xdd	O
dd	O
arg	O
min	O
d	O
the	O
same	O
property	O
again	O
at	O
this	O
point	O
we	O
re-introduce	O
the	O
constraint	O
xdd	O
trx	O
trx	O
arg	O
min	O
d	O
arg	O
min	O
trx	O
xdd	O
dd	O
subject	O
to	O
d	O
d	O
xdd	O
trx	O
subject	O
to	O
d	O
xdd	O
d	O
d	O
to	O
the	O
constraint	O
arg	O
min	O
d	O
xdd	O
subject	O
to	O
d	O
d	O
trx	O
chapter	O
linear	O
algebra	O
xdd	O
x	O
xd	O
trx	O
trd	O
subject	O
to	O
d	O
d	O
subject	O
to	O
d	O
d	O
arg	O
max	O
d	O
arg	O
max	O
d	O
this	O
optimization	O
problem	O
may	O
be	O
solved	O
using	O
eigendecomposition	B
specifically	O
x	O
corresponding	O
to	O
the	O
largest	O
the	O
optimal	O
d	O
is	O
given	O
by	O
the	O
eigenvector	B
of	O
x	O
eigenvalue	B
this	O
derivation	O
is	O
specific	O
to	O
the	O
case	O
of	O
l	O
and	O
recovers	O
only	O
the	O
first	O
principal	O
component	O
more	O
generally	O
when	O
we	O
wish	O
to	O
recover	O
a	O
basis	O
of	O
principal	O
components	O
the	O
matrix	O
d	O
is	O
given	O
by	O
the	O
l	O
eigenvectors	O
corresponding	O
to	O
the	O
largest	O
eigenvalues	O
this	O
may	O
be	O
shown	O
using	O
proof	O
by	O
induction	O
we	O
recommend	O
writing	O
this	O
proof	O
as	O
an	O
exercise	O
linear	O
algebra	O
is	O
one	O
of	O
the	O
fundamental	O
mathematical	O
disciplines	O
that	O
is	O
necessary	O
to	O
understand	O
deep	O
learning	O
another	O
key	O
area	O
of	O
mathematics	O
that	O
is	O
ubiquitous	O
in	O
machine	B
learning	I
is	O
probability	O
theory	O
presented	O
next	O
chapter	O
probability	O
and	O
information	O
theory	O
in	O
this	O
chapter	O
we	O
describe	O
probability	O
theory	O
and	O
information	O
theory	O
probability	O
theory	O
is	O
a	O
mathematical	O
framework	O
for	O
representing	O
uncertain	O
statements	O
it	O
provides	O
a	O
means	O
of	O
quantifying	O
uncertainty	O
and	O
axioms	O
for	O
deriving	O
new	O
uncertain	O
statements	O
in	O
artificial	B
intelligence	I
applications	O
we	O
use	O
probability	O
theory	O
in	O
two	O
major	O
ways	O
first	O
the	O
laws	O
of	O
probability	O
tell	O
us	O
how	O
ai	O
systems	O
should	O
reason	O
so	O
we	O
design	O
our	O
algorithms	O
to	O
compute	O
or	O
approximate	O
various	O
expressions	O
derived	O
using	O
probability	O
theory	O
second	O
we	O
can	O
use	O
probability	O
and	O
statistics	O
to	O
theoretically	O
analyze	O
the	O
behavior	O
of	O
proposed	O
ai	O
systems	O
probability	O
theory	O
is	O
a	O
fundamental	O
tool	O
of	O
many	O
disciplines	O
of	O
science	O
and	O
engineering	O
we	O
provide	O
this	O
chapter	O
to	O
ensure	O
that	O
readers	O
whose	O
background	O
is	O
primarily	O
in	O
software	O
engineering	O
with	O
limited	O
exposure	O
to	O
probability	O
theory	O
can	O
understand	O
the	O
material	O
in	O
this	O
book	O
while	O
probability	O
theory	O
allows	O
us	O
to	O
make	O
uncertain	O
statements	O
and	O
reason	O
in	O
the	O
presence	O
of	O
uncertainty	O
information	O
theory	O
allows	O
us	O
to	O
quantify	O
the	O
amount	O
of	O
uncertainty	O
in	O
a	O
probability	B
distribution	I
if	O
you	O
are	O
already	O
familiar	O
with	O
probability	O
theory	O
and	O
information	O
theory	O
you	O
may	O
wish	O
to	O
skip	O
all	O
of	O
this	O
chapter	O
except	O
for	O
section	O
which	O
describes	O
the	O
graphs	O
we	O
use	O
to	O
describe	O
structured	O
probabilistic	O
models	O
for	O
machine	B
learning	I
if	O
you	O
have	O
absolutely	O
no	O
prior	O
experience	O
with	O
these	O
subjects	O
this	O
chapter	O
should	O
be	O
sufficient	O
to	O
successfully	O
carry	O
out	O
deep	O
learning	O
research	O
projects	O
but	O
we	O
do	O
suggest	O
that	O
you	O
consult	O
an	O
additional	O
resource	O
such	O
as	O
jaynes	O
chapter	O
probability	O
and	O
information	O
theory	O
why	O
probability	O
many	O
branches	O
of	O
computer	O
science	O
deal	O
mostly	O
with	O
entities	O
that	O
are	O
entirely	O
deterministic	O
and	O
certain	O
a	O
programmer	O
can	O
usually	O
safely	O
assume	O
that	O
a	O
cpu	O
will	O
execute	O
each	O
machine	O
instruction	O
flawlessly	O
errors	O
in	O
hardware	O
do	O
occur	O
but	O
are	O
rare	O
enough	O
that	O
most	O
software	O
applications	O
do	O
not	O
need	O
to	O
be	O
designed	O
to	O
account	O
for	O
them	O
given	O
that	O
many	O
computer	O
scientists	O
and	O
software	O
engineers	O
work	O
in	O
a	O
relatively	O
clean	O
and	O
certain	O
environment	O
it	O
can	O
be	O
surprising	O
that	O
machine	B
learning	I
makes	O
heavy	O
use	O
of	O
probability	O
theory	O
this	O
is	O
because	O
machine	B
learning	I
must	O
always	O
deal	O
with	O
uncertain	O
quantities	O
and	O
sometimes	O
may	O
also	O
need	O
to	O
deal	O
with	O
stochastic	O
quantities	O
uncertainty	O
and	O
stochasticity	O
can	O
arise	O
from	O
many	O
sources	O
researchers	O
have	O
made	O
compelling	O
arguments	O
for	O
quantifying	O
uncertainty	O
using	O
probability	O
since	O
at	O
least	O
the	O
many	O
of	O
the	O
arguments	O
presented	O
here	O
are	O
summarized	O
from	O
or	O
inspired	O
by	O
pearl	O
nearly	O
all	O
activities	O
require	O
some	O
ability	O
to	O
reason	O
in	O
the	O
presence	O
of	O
uncertainty	O
in	O
fact	O
beyond	O
mathematical	O
statements	O
that	O
are	O
true	O
by	O
definition	O
it	O
is	O
difficult	O
to	O
think	O
of	O
any	O
proposition	O
that	O
is	O
absolutely	O
true	O
or	O
any	O
event	O
that	O
is	O
absolutely	O
guaranteed	O
to	O
occur	O
there	O
are	O
three	O
possible	O
sources	O
of	O
uncertainty	O
inherent	O
stochasticity	O
in	O
the	O
system	O
being	O
modeled	O
for	O
example	B
most	O
interpretations	O
of	O
quantum	O
mechanics	O
describe	O
the	O
dynamics	O
of	O
subatomic	O
particles	O
as	O
being	O
probabilistic	O
we	O
can	O
also	O
create	O
theoretical	O
scenarios	O
that	O
we	O
postulate	O
to	O
have	O
random	O
dynamics	O
such	O
as	O
a	O
hypothetical	O
card	O
game	O
where	O
we	O
assume	O
that	O
the	O
cards	O
are	O
truly	O
shu	O
ed	O
into	O
a	O
random	O
order	O
incomplete	O
observability	O
even	O
deterministic	O
systems	O
can	O
appear	O
stochastic	O
when	O
we	O
cannot	O
observe	O
all	O
of	O
the	O
variables	O
that	O
drive	O
the	O
behavior	O
of	O
the	O
system	O
for	O
example	B
in	O
the	O
monty	O
hall	O
problem	O
a	O
game	O
show	O
contestant	O
is	O
asked	O
to	O
choose	O
between	O
three	O
doors	O
and	O
wins	O
a	O
prize	O
held	O
behind	O
the	O
chosen	O
door	O
two	O
doors	O
lead	O
to	O
a	O
goat	O
while	O
a	O
third	O
leads	O
to	O
a	O
car	O
the	O
outcome	O
given	O
the	O
contestant	O
s	O
choice	O
is	O
deterministic	O
but	O
from	O
the	O
contestant	O
s	O
point	O
of	O
view	O
the	O
outcome	O
is	O
uncertain	O
incomplete	O
modeling	O
when	O
we	O
use	O
a	O
model	O
that	O
must	O
discard	O
some	O
of	O
the	O
information	O
we	O
have	O
observed	O
the	O
discarded	O
information	O
results	O
in	O
uncertainty	O
in	O
the	O
model	O
s	O
predictions	O
for	O
example	B
suppose	O
we	O
build	O
a	O
robot	O
that	O
can	O
exactly	O
observe	O
the	O
location	O
of	O
every	O
object	O
around	O
it	O
if	O
the	O
chapter	O
probability	O
and	O
information	O
theory	O
robot	O
discretizes	O
space	O
when	O
predicting	O
the	O
future	O
location	O
of	O
these	O
objects	O
then	O
the	O
discretization	O
makes	O
the	O
robot	O
immediately	O
become	O
uncertain	O
about	O
the	O
precise	O
position	O
of	O
objects	O
each	O
object	O
could	O
be	O
anywhere	O
within	O
the	O
discrete	O
cell	O
that	O
it	O
was	O
observed	O
to	O
occupy	O
in	O
many	O
cases	O
it	O
is	O
more	O
practical	O
to	O
use	O
a	O
simple	O
but	O
uncertain	O
rule	O
rather	O
than	O
a	O
complex	O
but	O
certain	O
one	O
even	O
if	O
the	O
true	O
rule	O
is	O
deterministic	O
and	O
our	O
modeling	O
system	O
has	O
the	O
fidelity	O
to	O
accommodate	O
a	O
complex	O
rule	O
for	O
example	B
the	O
simple	O
rule	O
most	O
birds	O
fly	O
is	O
cheap	O
to	O
develop	O
and	O
is	O
broadly	O
useful	O
while	O
a	O
rule	O
of	O
the	O
form	O
birds	O
fly	O
except	O
for	O
very	O
young	O
birds	O
that	O
have	O
not	O
yet	O
learned	O
to	O
fly	O
sick	O
or	O
injured	O
birds	O
that	O
have	O
lost	O
the	O
ability	O
to	O
fly	O
flightless	O
species	O
of	O
birds	O
including	O
the	O
cassowary	O
ostrich	O
and	O
kiwi	O
is	O
expensive	O
to	O
develop	O
maintain	O
and	O
communicate	O
and	O
after	O
all	O
of	O
this	O
effort	O
is	O
still	O
very	O
brittle	O
and	O
prone	O
to	O
failure	O
while	O
it	O
should	O
be	O
clear	O
that	O
we	O
need	O
a	O
means	O
of	O
representing	O
and	O
reasoning	O
about	O
uncertainty	O
it	O
is	O
not	O
immediately	O
obvious	O
that	O
probability	O
theory	O
can	O
provide	O
all	O
of	O
the	O
tools	O
we	O
want	O
for	O
artificial	B
intelligence	I
applications	O
probability	O
theory	O
was	O
originally	O
developed	O
to	O
analyze	O
the	O
frequencies	O
of	O
events	O
it	O
is	O
easy	O
to	O
see	O
how	O
probability	O
theory	O
can	O
be	O
used	O
to	O
study	O
events	O
like	O
drawing	O
a	O
certain	O
hand	O
of	O
cards	O
in	O
a	O
game	O
of	O
poker	O
these	O
kinds	O
of	O
events	O
are	O
often	O
repeatable	O
when	O
we	O
say	O
that	O
an	O
outcome	O
has	O
a	O
probability	O
p	O
of	O
occurring	O
it	O
means	O
that	O
if	O
we	O
repeated	O
the	O
experiment	O
draw	O
a	O
hand	O
of	O
cards	O
infinitely	O
many	O
times	O
then	O
proportion	O
p	O
of	O
the	O
repetitions	O
would	O
result	O
in	O
that	O
outcome	O
this	O
kind	O
of	O
reasoning	O
does	O
not	O
seem	O
immediately	O
applicable	O
to	O
propositions	O
that	O
are	O
not	O
repeatable	O
if	O
a	O
doctor	O
analyzes	O
a	O
patient	O
and	O
says	O
that	O
the	O
patient	O
has	O
a	O
chance	O
of	O
having	O
the	O
flu	O
this	O
means	O
something	O
very	O
different	O
we	O
can	O
not	O
make	O
infinitely	O
many	O
replicas	O
of	O
the	O
patient	O
nor	O
is	O
there	O
any	O
reason	O
to	O
believe	O
that	O
different	O
replicas	O
of	O
the	O
patient	O
would	O
present	O
with	O
the	O
same	O
symptoms	O
yet	O
have	O
varying	O
underlying	O
conditions	O
in	O
the	O
case	O
of	O
the	O
doctor	O
diagnosing	O
the	O
patient	O
we	O
use	O
probability	O
to	O
represent	O
a	O
degree	O
of	O
belief	O
with	O
indicating	O
absolute	O
certainty	O
that	O
the	O
patient	O
has	O
the	O
flu	O
and	O
indicating	O
absolute	O
certainty	O
that	O
the	O
patient	O
does	O
not	O
have	O
the	O
flu	O
the	O
former	O
kind	O
of	O
probability	O
related	O
directly	O
to	O
the	O
rates	O
at	O
which	O
events	O
occur	O
is	O
known	O
as	O
frequentist	B
probability	I
while	O
the	O
latter	O
related	O
to	O
qualitative	O
levels	O
of	O
certainty	O
is	O
known	O
as	O
bayesian	B
probability	I
if	O
we	O
list	O
several	O
properties	O
that	O
we	O
expect	O
common	O
sense	O
reasoning	O
about	O
uncertainty	O
to	O
have	O
then	O
the	O
only	O
way	O
to	O
satisfy	O
those	O
properties	O
is	O
to	O
treat	O
bayesian	O
probabilities	O
as	O
behaving	O
exactly	O
the	O
same	O
as	O
frequentist	O
probabilities	O
for	O
example	B
if	O
we	O
want	O
to	O
compute	O
the	O
probability	O
that	O
a	O
player	O
will	O
win	O
a	O
poker	O
game	O
given	O
that	O
she	O
has	O
a	O
certain	O
set	O
of	O
cards	O
we	O
use	O
exactly	O
the	O
same	O
formulas	O
as	O
when	O
we	O
compute	O
the	O
probability	O
that	O
a	O
patient	O
has	O
a	O
disease	O
given	O
that	O
she	O
chapter	O
probability	O
and	O
information	O
theory	O
has	O
certain	O
symptoms	O
for	O
more	O
details	O
about	O
why	O
a	O
small	O
set	O
of	O
common	O
sense	O
assumptions	O
implies	O
that	O
the	O
same	O
axioms	O
must	O
control	O
both	O
kinds	O
of	O
probability	O
see	O
ramsey	O
probability	O
can	O
be	O
seen	O
as	O
the	O
extension	O
of	O
logic	O
to	O
deal	O
with	O
uncertainty	O
logic	O
provides	O
a	O
set	O
of	O
formal	O
rules	O
for	O
determining	O
what	O
propositions	O
are	O
implied	O
to	O
be	O
true	O
or	O
false	O
given	O
the	O
assumption	O
that	O
some	O
other	O
set	O
of	O
propositions	O
is	O
true	O
or	O
false	O
probability	O
theory	O
provides	O
a	O
set	O
of	O
formal	O
rules	O
for	O
determining	O
the	O
likelihood	O
of	O
a	O
proposition	O
being	O
true	O
given	O
the	O
likelihood	O
of	O
other	O
propositions	O
random	O
variables	O
a	O
random	B
variable	I
is	O
a	O
variable	O
that	O
can	O
take	O
on	O
different	O
values	O
randomly	O
we	O
typically	O
denote	O
the	O
random	B
variable	I
itself	O
with	O
a	O
lower	O
case	O
letter	O
in	O
plain	O
typeface	O
and	O
the	O
values	O
it	O
can	O
take	O
on	O
with	O
lower	O
case	O
script	O
letters	O
for	O
example	B
and	O
are	O
both	O
possible	O
values	O
that	O
the	O
random	B
variable	I
x	O
can	O
take	O
on	O
for	O
vector-valued	O
variables	O
we	O
would	O
write	O
the	O
random	B
variable	I
as	O
x	O
and	O
one	O
of	O
its	O
values	O
as	O
x	O
on	O
its	O
own	O
a	O
random	B
variable	I
is	O
just	O
a	O
description	O
of	O
the	O
states	O
that	O
are	O
possible	O
it	O
must	O
be	O
coupled	O
with	O
a	O
probability	B
distribution	I
that	O
specifies	O
how	O
likely	O
each	O
of	O
these	O
states	O
are	O
random	O
variables	O
may	O
be	O
discrete	O
or	O
continuous	O
a	O
discrete	O
random	B
variable	I
is	O
one	O
that	O
has	O
a	O
finite	O
or	O
countably	O
infinite	O
number	O
of	O
states	O
note	O
that	O
these	O
states	O
are	O
not	O
necessarily	O
the	O
integers	O
they	O
can	O
also	O
just	O
be	O
named	O
states	O
that	O
are	O
not	O
considered	O
to	O
have	O
any	O
numerical	O
value	O
a	O
continuous	O
random	B
variable	I
is	O
associated	O
with	O
a	O
real	O
value	O
probability	O
distributions	O
a	O
probability	B
distribution	I
is	O
a	O
description	O
of	O
how	O
likely	O
a	O
random	B
variable	I
or	O
set	O
of	O
random	O
variables	O
is	O
to	O
take	O
on	O
each	O
of	O
its	O
possible	O
states	O
the	O
way	O
we	O
describe	O
probability	O
distributions	O
depends	O
on	O
whether	O
the	O
variables	O
are	O
discrete	O
or	O
continuous	O
discrete	O
variables	O
and	O
probability	O
mass	O
functions	O
a	O
probability	B
distribution	I
over	O
discrete	O
variables	O
may	O
be	O
described	O
using	O
a	O
probability	B
mass	I
function	I
we	O
typically	O
denote	O
probability	O
mass	O
functions	O
with	O
a	O
capital	O
p	O
often	O
we	O
associate	O
each	O
random	B
variable	I
with	O
a	O
different	O
probability	O
chapter	O
probability	O
and	O
information	O
theory	O
mass	O
function	O
and	O
the	O
reader	O
must	O
infer	O
which	O
probability	B
mass	I
function	I
to	O
use	O
based	O
on	O
the	O
identity	O
of	O
the	O
random	B
variable	I
rather	O
than	O
the	O
name	O
of	O
the	O
function	O
p	O
is	O
usually	O
not	O
the	O
same	O
as	O
p	O
the	O
probability	B
mass	I
function	I
maps	O
from	O
a	O
state	O
of	O
a	O
random	B
variable	I
to	O
the	O
probability	O
of	O
that	O
random	B
variable	I
taking	O
on	O
that	O
state	O
the	O
probability	O
that	O
x	O
x	O
is	O
denoted	O
as	O
p	O
with	O
a	O
probability	O
of	O
indicating	O
that	O
x	O
x	O
is	O
certain	O
and	O
a	O
probability	O
of	O
indicating	O
that	O
x	O
x	O
is	O
impossible	O
sometimes	O
to	O
disambiguate	O
which	O
pmf	O
to	O
use	O
we	O
write	O
the	O
name	O
of	O
the	O
random	B
variable	I
explicitly	O
p	O
x	O
sometimes	O
we	O
define	O
a	O
variable	O
first	O
then	O
use	O
notation	O
to	O
specify	O
which	O
distribution	O
it	O
follows	O
later	O
x	O
x	O
p	O
probability	O
mass	O
functions	O
can	O
act	O
on	O
many	O
variables	O
at	O
the	O
same	O
time	O
such	O
a	O
probability	B
distribution	I
over	O
many	O
variables	O
is	O
known	O
as	O
a	O
joint	B
probability	B
distribution	I
p	O
x	O
y	O
y	O
denotes	O
the	O
probability	O
that	O
x	O
x	O
and	O
y	O
y	O
simultaneously	O
we	O
may	O
also	O
write	O
for	O
brevity	O
p	O
x	O
y	O
to	O
be	O
a	O
probability	B
mass	I
function	I
on	O
a	O
random	B
variable	I
x	O
a	O
function	O
p	O
must	O
satisfy	O
the	O
following	O
properties	O
the	O
domain	O
of	O
must	O
be	O
the	O
set	O
of	O
all	O
possible	O
states	O
of	O
x	O
p	O
x	O
x	O
p	O
an	O
impossible	O
event	O
has	O
probability	O
and	O
no	O
state	O
can	O
be	O
less	O
probable	O
than	O
that	O
likewise	O
an	O
event	O
that	O
is	O
guaranteed	O
to	O
happen	O
has	O
probability	O
and	O
no	O
state	O
can	O
have	O
a	O
greater	O
chance	O
of	O
occurring	O
x	O
x	O
p	O
we	O
refer	O
to	O
this	O
property	O
as	O
being	O
normalized	O
without	O
this	O
property	O
we	O
could	O
obtain	O
probabilities	O
greater	O
than	O
one	O
by	O
computing	O
the	O
probability	O
of	O
one	O
of	O
many	O
events	O
occurring	O
for	O
example	B
consider	O
a	O
single	O
discrete	O
random	B
variable	I
x	O
with	O
k	O
different	O
states	O
we	O
can	O
place	O
a	O
uniform	B
distribution	I
on	O
x	O
that	O
is	O
make	O
each	O
of	O
its	O
states	O
equally	O
likely	O
by	O
setting	O
its	O
probability	B
mass	I
function	I
to	O
p	O
x	O
x	O
i	O
k	O
for	O
all	O
i	O
we	O
can	O
see	O
that	O
this	O
fits	O
the	O
requirements	O
for	O
a	O
probability	B
mass	I
function	I
the	O
value	O
k	O
is	O
a	O
positive	O
integer	O
we	O
also	O
see	O
that	O
is	O
positive	O
because	O
k	O
p	O
x	O
i	O
x	O
i	O
i	O
k	O
k	O
k	O
so	O
the	O
distribution	O
is	O
properly	O
normalized	O
chapter	O
probability	O
and	O
information	O
theory	O
continuous	O
variables	O
and	O
probability	O
density	O
functions	O
when	O
working	O
with	O
continuous	O
random	O
variables	O
we	O
describe	O
probability	O
distributions	O
using	O
a	O
probability	B
density	I
function	I
rather	O
than	O
a	O
probability	B
mass	I
function	I
to	O
be	O
a	O
probability	B
density	I
function	I
a	O
function	O
p	O
must	O
satisfy	O
the	O
following	O
properties	O
the	O
domain	O
of	O
must	O
be	O
the	O
set	O
of	O
all	O
possible	O
states	O
of	O
x	O
p	O
note	O
that	O
we	O
do	O
not	O
require	O
p	O
x	O
x	O
x	O
p	O
x	O
p	O
x	O
dx	O
a	O
probability	B
density	I
function	I
px	O
does	O
not	O
give	O
the	O
probability	O
of	O
a	O
specific	O
state	O
directly	O
instead	O
the	O
probability	O
of	O
landing	O
inside	O
an	O
infinitesimal	O
region	O
with	O
volume	O
is	O
given	O
by	O
p	O
x	O
x	O
x	O
we	O
can	O
integrate	O
the	O
density	O
function	O
to	O
find	O
the	O
actual	O
probability	O
mass	O
of	O
a	O
set	O
of	O
points	O
specifically	O
the	O
probability	O
that	O
x	O
lies	O
in	O
some	O
set	O
s	O
is	O
given	O
by	O
the	O
integral	O
of	O
p	O
over	O
that	O
set	O
in	O
the	O
univariate	O
example	B
the	O
probability	O
that	O
x	O
lies	O
in	O
the	O
interval	O
is	O
given	O
by	O
p	O
x	O
dx	O
b	O
for	O
an	O
example	B
of	O
a	O
probability	B
density	I
function	I
corresponding	O
to	O
a	O
specific	O
probability	O
density	O
over	O
a	O
continuous	O
random	B
variable	I
consider	O
a	O
uniform	B
distribution	I
on	O
an	O
interval	O
of	O
the	O
real	O
numbers	O
we	O
can	O
do	O
this	O
with	O
a	O
function	O
ux	O
a	O
b	O
where	O
a	O
and	O
b	O
are	O
the	O
endpoints	O
of	O
the	O
interval	O
with	O
b	O
a	O
the	O
notation	O
means	O
parametrized	O
by	O
we	O
consider	O
x	O
to	O
be	O
the	O
argument	O
of	O
the	O
function	O
while	O
a	O
and	O
b	O
are	O
parameters	O
that	O
define	O
the	O
function	O
to	O
ensure	O
that	O
there	O
is	O
no	O
probability	O
mass	O
outside	O
the	O
interval	O
we	O
say	O
ux	O
a	O
b	O
for	O
all	O
x	O
within	O
a	O
b	O
we	O
can	O
see	O
that	O
this	O
is	O
nonnegative	O
everywhere	O
additionally	O
it	O
u	O
x	O
a	O
b	O
b	O
a	O
integrates	O
to	O
we	O
often	O
denote	O
that	O
x	O
follows	O
the	O
uniform	B
distribution	I
on	O
b	O
by	O
writing	O
x	O
u	O
a	O
b	O
b	O
marginal	B
probability	I
sometimes	O
we	O
know	O
the	O
probability	B
distribution	I
over	O
a	O
set	O
of	O
variables	O
and	O
we	O
want	O
to	O
know	O
the	O
probability	B
distribution	I
over	O
just	O
a	O
subset	O
of	O
them	O
the	O
probability	B
distribution	I
over	O
the	O
subset	O
is	O
known	O
as	O
the	O
distribution	O
marginal	B
probability	I
for	O
example	B
suppose	O
we	O
have	O
discrete	O
random	O
variables	O
x	O
and	O
y	O
and	O
we	O
know	O
p	O
y	O
we	O
can	O
find	O
x	O
with	O
the	O
sum	O
rule	O
p	O
x	O
x	O
p	O
x	O
p	O
x	O
x	O
y	O
y	O
y	O
chapter	O
probability	O
and	O
information	O
theory	O
the	O
name	O
marginal	B
probability	I
comes	O
from	O
the	O
process	O
of	O
computing	O
marginal	O
probabilities	O
on	O
paper	O
when	O
the	O
values	O
of	O
p	O
y	O
are	O
written	O
in	O
a	O
grid	O
with	O
different	O
values	O
of	O
x	O
in	O
rows	O
and	O
different	O
values	O
of	O
y	O
in	O
columns	O
it	O
is	O
natural	O
to	O
sum	O
across	O
a	O
row	O
of	O
the	O
grid	O
then	O
write	O
px	O
in	O
the	O
margin	O
of	O
the	O
paper	O
just	O
to	O
the	O
right	O
of	O
the	O
row	O
for	O
continuous	O
variables	O
we	O
need	O
to	O
use	O
integration	O
instead	O
of	O
summation	O
p	O
x	O
p	O
x	O
y	O
dy	O
conditional	B
probability	I
in	O
many	O
cases	O
we	O
are	O
interested	O
in	O
the	O
probability	O
of	O
some	O
event	O
given	O
that	O
some	O
other	O
event	O
has	O
happened	O
this	O
is	O
called	O
a	O
conditional	B
probability	I
we	O
denote	O
x	O
x	O
this	O
the	O
conditional	B
probability	I
that	O
y	O
y	O
given	O
x	O
x	O
as	O
py	O
y	O
conditional	B
probability	I
can	O
be	O
computed	O
with	O
the	O
formula	O
p	O
y	O
y	O
x	O
x	O
p	O
y	O
y	O
x	O
x	O
x	O
p	O
x	O
the	O
conditional	B
probability	I
is	O
only	O
defined	O
when	O
px	O
x	O
we	O
cannot	O
compute	O
the	O
conditional	B
probability	I
conditioned	O
on	O
an	O
event	O
that	O
never	O
happens	O
it	O
is	O
important	O
not	O
to	O
confuse	O
conditional	B
probability	I
with	O
computing	O
what	O
would	O
happen	O
if	O
some	O
action	O
were	O
undertaken	O
the	O
conditional	B
probability	I
that	O
a	O
person	O
is	O
from	O
germany	O
given	O
that	O
they	O
speak	O
german	O
is	O
quite	O
high	O
but	O
if	O
a	O
randomly	O
selected	O
person	O
is	O
taught	O
to	O
speak	O
german	O
their	O
country	O
of	O
origin	O
does	O
not	O
change	O
computing	O
the	O
consequences	O
of	O
an	O
action	O
is	O
called	O
making	O
an	O
intervention	O
query	O
intervention	O
queries	O
are	O
the	O
domain	O
of	O
causal	O
modeling	O
which	O
we	O
do	O
not	O
explore	O
in	O
this	O
book	O
the	O
chain	O
rule	O
of	O
conditional	O
probabilities	O
any	O
joint	B
probability	B
distribution	I
over	O
many	O
random	O
variables	O
may	O
be	O
decomposed	O
into	O
conditional	O
distributions	O
over	O
only	O
one	O
variable	O
i	O
x	O
p	O
x	O
n	O
this	O
observation	O
is	O
known	O
as	O
the	O
chain	O
rule	O
or	O
product	O
rule	O
of	O
probability	O
it	O
follows	O
immediately	O
from	O
the	O
definition	O
of	O
conditional	B
probability	I
in	O
equation	O
chapter	O
probability	O
and	O
information	O
theory	O
for	O
example	B
applying	O
the	O
definition	O
twice	O
we	O
get	O
p	O
b	O
c	O
c	O
p	O
p	O
b	O
c	O
p	O
p	O
p	O
b	O
c	O
c	O
p	O
b	O
c	O
p	O
b	O
c	O
b	O
p	O
c	O
p	O
independence	O
and	O
conditional	O
independence	O
two	O
random	O
variables	O
x	O
and	O
y	O
are	O
independent	O
if	O
their	O
probability	B
distribution	I
can	O
be	O
expressed	O
as	O
a	O
product	O
of	O
two	O
factors	O
one	O
involving	O
only	O
x	O
and	O
one	O
involving	O
only	O
y	O
x	O
x	O
y	O
y	O
p	O
x	O
p	O
p	O
x	O
y	O
x	O
y	O
y	O
two	O
random	O
variables	O
x	O
and	O
y	O
are	O
conditionally	O
independent	O
given	O
a	O
random	B
variable	I
z	O
if	O
the	O
conditional	B
probability	B
distribution	I
over	O
x	O
and	O
y	O
factorizes	O
in	O
this	O
way	O
for	O
every	O
value	O
of	O
z	O
x	O
x	O
y	O
y	O
z	O
z	O
p	O
x	O
y	O
z	O
x	O
y	O
p	O
x	O
z	O
x	O
z	O
z	O
p	O
y	O
z	O
y	O
we	O
can	O
denote	O
independence	O
and	O
conditional	O
independence	O
with	O
compact	O
means	O
that	O
x	O
means	O
that	O
x	O
and	O
y	O
are	O
independent	O
while	O
x	O
y	O
z	O
notation	O
x	O
y	O
and	O
y	O
are	O
conditionally	O
independent	O
given	O
z	O
expectation	B
variance	O
and	O
covariance	O
the	O
expectation	B
or	O
expected	O
value	O
of	O
some	O
function	O
fx	O
with	O
respect	O
to	O
a	O
probability	B
distribution	I
p	O
is	O
the	O
average	O
or	O
mean	O
value	O
that	O
f	O
takes	O
on	O
when	O
x	O
is	O
drawn	O
from	O
for	O
discrete	O
variables	O
this	O
can	O
be	O
computed	O
with	O
a	O
summation	O
p	O
x	O
p	O
ex	O
f	O
x	O
p	O
x	O
f	O
x	O
while	O
for	O
continuous	O
variables	O
it	O
is	O
computed	O
with	O
an	O
integral	O
p	O
ex	O
f	O
x	O
p	O
x	O
f	O
x	O
dx	O
chapter	O
probability	O
and	O
information	O
theory	O
when	O
the	O
identity	O
of	O
the	O
distribution	O
is	O
clear	O
from	O
the	O
context	O
we	O
may	O
simply	O
write	O
the	O
name	O
of	O
the	O
random	B
variable	I
that	O
the	O
expectation	B
is	O
over	O
as	O
in	O
exf	O
if	O
it	O
is	O
clear	O
which	O
random	B
variable	I
the	O
expectation	B
is	O
over	O
we	O
may	O
omit	O
the	O
subscript	O
entirely	O
as	O
in	O
ef	O
by	O
default	O
we	O
can	O
assume	O
that	O
e	O
averages	O
over	O
the	O
values	O
of	O
all	O
the	O
random	O
variables	O
inside	O
the	O
brackets	O
likewise	O
when	O
there	O
is	O
no	O
ambiguity	O
we	O
may	O
omit	O
the	O
square	O
brackets	O
expectations	O
are	O
linear	O
for	O
example	B
ex	O
f	O
x	O
g	O
x	O
ex	O
f	O
x	O
ex	O
g	O
x	O
when	O
and	O
are	O
not	O
dependent	O
on	O
x	O
the	O
variance	O
gives	O
a	O
measure	O
of	O
how	O
much	O
the	O
values	O
of	O
a	O
function	O
of	O
a	O
random	B
variable	I
x	O
vary	O
as	O
we	O
sample	O
different	O
values	O
of	O
x	O
from	O
its	O
probability	B
distribution	I
var	O
f	O
x	O
e	O
f	O
x	O
e	O
f	O
x	O
when	O
the	O
variance	O
is	O
low	O
the	O
values	O
of	O
f	O
cluster	O
near	O
their	O
expected	O
value	O
the	O
square	O
root	O
of	O
the	O
variance	O
is	O
known	O
as	O
the	O
standard	B
deviation	I
the	O
covariance	O
gives	O
some	O
sense	O
of	O
how	O
much	O
two	O
values	O
are	O
linearly	O
related	O
to	O
each	O
other	O
as	O
well	O
as	O
the	O
scale	O
of	O
these	O
variables	O
cov	O
f	O
x	O
g	O
y	O
e	O
f	O
x	O
e	O
f	O
x	O
g	O
y	O
e	O
g	O
y	O
high	O
absolute	O
values	O
of	O
the	O
covariance	O
mean	O
that	O
the	O
values	O
change	O
very	O
much	O
and	O
are	O
both	O
far	O
from	O
their	O
respective	O
means	O
at	O
the	O
same	O
time	O
if	O
the	O
sign	O
of	O
the	O
covariance	O
is	O
positive	O
then	O
both	O
variables	O
tend	O
to	O
take	O
on	O
relatively	O
high	O
values	O
simultaneously	O
if	O
the	O
sign	O
of	O
the	O
covariance	O
is	O
negative	O
then	O
one	O
variable	O
tends	O
to	O
take	O
on	O
a	O
relatively	O
high	O
value	O
at	O
the	O
times	O
that	O
the	O
other	O
takes	O
on	O
a	O
relatively	O
low	O
value	O
and	O
vice	O
versa	O
other	O
measures	O
such	O
as	O
correlation	B
normalize	O
the	O
contribution	O
of	O
each	O
variable	O
in	O
order	O
to	O
measure	O
only	O
how	O
much	O
the	O
variables	O
are	O
related	O
rather	O
than	O
also	O
being	O
affected	O
by	O
the	O
scale	O
of	O
the	O
separate	O
variables	O
the	O
notions	O
of	O
covariance	O
and	O
dependence	O
are	O
related	O
but	O
are	O
in	O
fact	O
distinct	O
concepts	O
they	O
are	O
related	O
because	O
two	O
variables	O
that	O
are	O
independent	O
have	O
zero	O
covariance	O
and	O
two	O
variables	O
that	O
have	O
non-zero	O
covariance	O
are	O
dependent	O
however	O
independence	O
is	O
a	O
distinct	O
property	O
from	O
covariance	O
for	O
two	O
variables	O
to	O
have	O
zero	O
covariance	O
there	O
must	O
be	O
no	O
linear	B
dependence	I
between	O
them	O
independence	O
is	O
a	O
stronger	O
requirement	O
than	O
zero	O
covariance	O
because	O
independence	O
also	O
excludes	O
nonlinear	O
relationships	O
it	O
is	O
possible	O
for	O
two	O
variables	O
to	O
be	O
dependent	O
but	O
have	O
zero	O
covariance	O
for	O
example	B
suppose	O
we	O
first	O
sample	O
a	O
real	O
number	O
x	O
from	O
a	O
we	O
next	O
sample	O
a	O
random	B
variable	I
uniform	B
distribution	I
over	O
the	O
interval	O
chapter	O
probability	O
and	O
information	O
theory	O
s	O
with	O
probability	O
we	O
choose	O
the	O
value	O
of	O
s	O
to	O
be	O
otherwise	O
we	O
choose	O
the	O
value	O
of	O
s	O
to	O
be	O
we	O
can	O
then	O
generate	O
a	O
random	B
variable	I
y	O
by	O
assigning	O
y	O
sx	O
clearly	O
x	O
and	O
y	O
are	O
not	O
independent	O
because	O
x	O
completely	O
determines	O
the	O
magnitude	O
of	O
however	O
cov	O
x	O
y	O
y	O
n	O
is	O
an	O
n	O
r	O
the	O
covariance	B
matrix	I
of	O
a	O
random	O
vector	O
x	O
that	O
the	O
diagonal	O
elements	O
of	O
the	O
covariance	O
give	O
the	O
variance	O
cov	O
ij	O
covxi	O
x	O
j	O
covxi	O
xi	O
varxi	O
common	O
probability	O
distributions	O
n	O
matrix	O
such	O
several	O
simple	O
probability	O
distributions	O
are	O
useful	O
in	O
many	O
contexts	O
in	O
machine	B
learning	I
bernoulli	B
distribution	I
the	O
bernoulli	B
distribution	I
is	O
a	O
distribution	O
over	O
a	O
single	O
binary	O
random	B
variable	I
which	O
gives	O
the	O
probability	O
of	O
the	O
it	O
is	O
controlled	O
by	O
a	O
single	O
parameter	O
random	B
variable	I
being	O
equal	O
to	O
it	O
has	O
the	O
following	O
properties	O
p	O
p	O
x	O
x	O
p	O
x	O
x	O
x	O
x	O
ex	O
x	O
var	O
x	O
multinoulli	B
distribution	I
the	O
multinoulli	O
or	O
categorical	O
distribution	O
is	O
a	O
distribution	O
over	O
a	O
single	O
discrete	O
variable	O
with	O
k	O
different	O
states	O
where	O
k	O
is	O
the	O
multinoulli	B
distribution	I
is	O
multinoulli	O
is	O
a	O
term	O
that	O
was	O
recently	O
coined	O
by	O
gustavo	O
lacerdo	O
and	O
popularized	O
by	O
the	O
multinoulli	B
distribution	I
is	O
a	O
special	O
case	O
of	O
the	O
multinomial	B
distribution	I
murphy	O
k	O
representing	O
how	O
many	O
a	O
multinomial	B
distribution	I
is	O
the	O
distribution	O
over	O
vectors	O
in	O
times	O
each	O
of	O
the	O
k	O
categories	O
is	O
visited	O
when	O
n	O
samples	O
are	O
drawn	O
from	O
a	O
multinoulli	B
distribution	I
many	O
texts	O
use	O
the	O
term	O
multinomial	O
to	O
refer	O
to	O
multinoulli	O
distributions	O
without	O
clarifying	O
that	O
they	O
refer	O
only	O
to	O
the	O
n	O
n	O
case	O
chapter	O
probability	O
and	O
information	O
theory	O
parametrized	O
by	O
a	O
vector	O
p	O
where	O
pi	O
gives	O
the	O
probability	O
of	O
the	O
i-th	O
p	O
note	O
that	O
we	O
must	O
state	O
the	O
final	O
k-th	O
state	O
s	O
probability	O
is	O
given	O
by	O
constrain	O
multinoulli	O
distributions	O
are	O
often	O
used	O
to	O
refer	O
to	O
distributions	O
over	O
categories	O
of	O
objects	O
so	O
we	O
do	O
not	O
usually	O
assume	O
that	O
state	O
has	O
numerical	O
value	O
etc	O
for	O
this	O
reason	O
we	O
do	O
not	O
usually	O
need	O
to	O
compute	O
the	O
expectation	B
or	O
variance	O
of	O
multinoulli-distributed	O
random	O
variables	O
p	O
the	O
bernoulli	O
and	O
multinoulli	O
distributions	O
are	O
sufficient	O
to	O
describe	O
any	O
distribution	O
over	O
their	O
domain	O
they	O
are	O
able	O
to	O
describe	O
any	O
distribution	O
over	O
their	O
domain	O
not	O
so	O
much	O
because	O
they	O
are	O
particularly	O
powerful	O
but	O
rather	O
because	O
their	O
domain	O
is	O
simple	O
they	O
model	O
discrete	O
variables	O
for	O
which	O
it	O
is	O
feasible	O
to	O
enumerate	O
all	O
of	O
the	O
states	O
when	O
dealing	O
with	O
continuous	O
variables	O
there	O
are	O
uncountably	O
many	O
states	O
so	O
any	O
distribution	O
described	O
by	O
a	O
small	O
number	O
of	O
parameters	O
must	O
impose	O
strict	O
limits	O
on	O
the	O
distribution	O
gaussian	O
distribution	O
the	O
most	O
commonly	O
used	O
distribution	O
over	O
real	O
numbers	O
is	O
the	O
normal	O
distribution	O
also	O
known	O
as	O
the	O
gaussian	O
distribution	O
exp	O
n	O
x	O
see	O
figure	O
for	O
a	O
plot	O
of	O
the	O
density	O
function	O
the	O
two	O
parameters	O
control	O
the	O
normal	O
distribution	O
the	O
parameter	O
gives	O
the	O
coordinate	O
of	O
the	O
central	O
peak	O
this	O
is	O
also	O
the	O
mean	O
of	O
the	O
distribution	O
ex	O
the	O
standard	B
deviation	I
of	O
the	O
distribution	O
is	O
given	O
by	O
and	O
the	O
variance	O
by	O
r	O
and	O
when	O
we	O
evaluate	O
the	O
pdf	O
we	O
need	O
to	O
square	O
and	O
invert	O
when	O
we	O
need	O
to	O
frequently	O
evaluate	O
the	O
pdf	O
with	O
different	O
parameter	O
values	O
a	O
more	O
efficient	O
way	O
of	O
parametrizing	O
the	O
distribution	O
is	O
to	O
use	O
a	O
parameter	O
to	O
control	O
the	O
precision	B
or	O
inverse	O
variance	O
of	O
the	O
distribution	O
x	O
exp	O
n	O
normal	O
distributions	O
are	O
a	O
sensible	O
choice	O
for	O
many	O
applications	O
in	O
the	O
absence	O
of	O
prior	O
knowledge	O
about	O
what	O
form	O
a	O
distribution	O
over	O
the	O
real	O
numbers	O
should	O
take	O
the	O
normal	O
distribution	O
is	O
a	O
good	O
default	O
choice	O
for	O
two	O
major	O
reasons	O
chapter	O
probability	O
and	O
information	O
theory	O
x	O
p	O
maximum	O
at	O
x	O
inflection	O
points	O
at	O
x	O
figure	O
the	O
normal	O
distribution	O
the	O
normal	O
distribution	O
exhibits	O
a	O
classic	O
bell	O
curve	O
shape	O
with	O
the	O
x	O
coordinate	O
of	O
its	O
central	O
peak	O
given	O
by	O
and	O
the	O
width	O
of	O
its	O
peak	O
controlled	O
by	O
in	O
this	O
example	B
we	O
depict	O
the	O
standard	O
normal	O
distribution	O
with	O
and	O
n	O
first	O
many	O
distributions	O
we	O
wish	O
to	O
model	O
are	O
truly	O
close	O
to	O
being	O
normal	O
distributions	O
the	O
central	B
limit	I
theorem	I
shows	O
that	O
the	O
sum	O
of	O
many	O
independent	O
random	O
variables	O
is	O
approximately	O
normally	O
distributed	O
this	O
means	O
that	O
in	O
practice	O
many	O
complicated	O
systems	O
can	O
be	O
modeled	O
successfully	O
as	O
normally	O
distributed	O
noise	O
even	O
if	O
the	O
system	O
can	O
be	O
decomposed	O
into	O
parts	O
with	O
more	O
structured	O
behavior	O
x	O
second	O
out	O
of	O
all	O
possible	O
probability	O
distributions	O
with	O
the	O
same	O
variance	O
the	O
normal	O
distribution	O
encodes	O
the	O
maximum	O
amount	O
of	O
uncertainty	O
over	O
the	O
real	O
numbers	O
we	O
can	O
thus	O
think	O
of	O
the	O
normal	O
distribution	O
as	O
being	O
the	O
one	O
that	O
inserts	O
the	O
least	O
amount	O
of	O
prior	O
knowledge	O
into	O
a	O
model	O
fully	O
developing	O
and	O
justifying	O
this	O
idea	O
requires	O
more	O
mathematical	O
tools	O
and	O
is	O
postponed	O
to	O
section	O
the	O
normal	O
distribution	O
generalizes	O
to	O
r	O
n	O
in	O
which	O
case	O
it	O
is	O
known	O
as	O
the	O
multivariate	O
normal	O
distribution	O
it	O
may	O
be	O
parametrized	O
with	O
a	O
positive	B
definite	I
symmetric	O
matrix	O
n	O
x	O
ndet	O
exp	O
x	O
x	O
chapter	O
probability	O
and	O
information	O
theory	O
the	O
parameter	O
still	O
gives	O
the	O
mean	O
of	O
the	O
distribution	O
though	O
now	O
it	O
is	O
vector-valued	O
the	O
parameter	O
gives	O
the	O
covariance	B
matrix	I
of	O
the	O
distribution	O
as	O
in	O
the	O
univariate	O
case	O
when	O
we	O
wish	O
to	O
evaluate	O
the	O
pdf	O
several	O
times	O
for	O
many	O
different	O
values	O
of	O
the	O
parameters	O
the	O
covariance	O
is	O
not	O
a	O
computationally	O
efficient	O
way	O
to	O
parametrize	O
the	O
distribution	O
since	O
we	O
need	O
to	O
invert	O
to	O
evaluate	O
the	O
pdf	O
we	O
can	O
instead	O
use	O
a	O
precision	B
matrix	O
n	O
det	O
n	O
exp	O
x	O
x	O
we	O
often	O
fix	O
the	O
covariance	B
matrix	I
to	O
be	O
a	O
diagonal	B
matrix	I
an	O
even	O
simpler	O
version	O
is	O
the	O
isotropic	B
gaussian	O
distribution	O
whose	O
covariance	B
matrix	I
is	O
a	O
scalar	O
times	O
the	O
identity	B
matrix	I
exponential	O
and	O
laplace	O
distributions	O
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
often	O
want	O
to	O
have	O
a	O
probability	B
distribution	I
with	O
a	O
sharp	O
point	O
at	O
x	O
to	O
accomplish	O
this	O
we	O
can	O
use	O
the	O
exponential	B
distribution	I
x	O
exp	O
p	O
x	O
the	O
exponential	B
distribution	I
uses	O
the	O
indicator	O
function	O
to	O
assign	O
probability	O
zero	O
to	O
all	O
negative	O
values	O
of	O
a	O
closely	O
related	O
probability	B
distribution	I
that	O
allows	O
us	O
to	O
place	O
a	O
sharp	O
peak	O
of	O
probability	O
mass	O
at	O
an	O
arbitrary	O
point	O
is	O
the	O
laplace	O
distribution	O
x	O
laplace	O
x	O
exp	O
the	O
dirac	O
distribution	O
and	O
empirical	B
distribution	I
in	O
some	O
cases	O
we	O
wish	O
to	O
specify	O
that	O
all	O
of	O
the	O
mass	O
in	O
a	O
probability	B
distribution	I
clusters	O
around	O
a	O
single	O
point	O
this	O
can	O
be	O
accomplished	O
by	O
defining	O
a	O
pdf	O
using	O
the	O
dirac	B
delta	I
function	I
x	O
p	O
x	O
x	O
the	O
dirac	B
delta	I
function	I
is	O
defined	O
such	O
that	O
it	O
is	O
zero-valued	O
everywhere	O
except	O
yet	O
integrates	O
to	O
the	O
dirac	B
delta	I
function	I
is	O
not	O
an	O
ordinary	O
function	O
that	O
associates	O
each	O
value	O
x	O
with	O
a	O
real-valued	O
output	O
instead	O
it	O
is	O
a	O
different	O
kind	O
of	O
chapter	O
probability	O
and	O
information	O
theory	O
mathematical	O
object	O
called	O
a	O
generalized	O
function	O
that	O
is	O
defined	O
in	O
terms	O
of	O
its	O
properties	O
when	O
integrated	O
we	O
can	O
think	O
of	O
the	O
dirac	B
delta	I
function	I
as	O
being	O
the	O
limit	O
point	O
of	O
a	O
series	O
of	O
functions	O
that	O
put	O
less	O
and	O
less	O
mass	O
on	O
all	O
points	O
other	O
than	O
zero	O
we	O
obtain	O
an	O
infinitely	O
narrow	O
and	O
by	O
defining	O
px	O
to	O
be	O
shifted	O
by	O
infinitely	O
high	O
peak	O
of	O
probability	O
mass	O
where	O
x	O
a	O
common	O
use	O
of	O
the	O
dirac	O
delta	O
distribution	O
is	O
as	O
a	O
component	O
of	O
an	O
empirical	B
distribution	I
p	O
m	O
m	O
x	O
on	O
each	O
of	O
the	O
m	O
points	O
x	O
which	O
puts	O
probability	O
mass	O
forming	O
a	O
m	O
given	O
dataset	B
or	O
collection	O
of	O
samples	O
the	O
dirac	O
delta	O
distribution	O
is	O
only	O
necessary	O
to	O
define	O
the	O
empirical	B
distribution	I
over	O
continuous	O
variables	O
for	O
discrete	O
variables	O
the	O
situation	O
is	O
simpler	O
an	O
empirical	B
distribution	I
can	O
be	O
conceptualized	O
as	O
a	O
multinoulli	B
distribution	I
with	O
a	O
probability	O
associated	O
to	O
each	O
possible	O
input	O
value	O
that	O
is	O
simply	O
equal	O
to	O
the	O
empirical	O
frequency	O
of	O
that	O
value	O
in	O
the	O
training	O
set	O
we	O
can	O
view	O
the	O
empirical	B
distribution	I
formed	O
from	O
a	O
dataset	B
of	O
training	O
examples	O
as	O
specifying	O
the	O
distribution	O
that	O
we	O
sample	O
from	O
when	O
we	O
train	O
a	O
model	O
on	O
this	O
dataset	B
another	O
important	O
perspective	O
on	O
the	O
empirical	B
distribution	I
is	O
that	O
it	O
is	O
the	O
probability	O
density	O
that	O
maximizes	O
the	O
likelihood	O
of	O
the	O
training	O
data	O
section	O
mixtures	O
of	O
distributions	O
it	O
is	O
also	O
common	O
to	O
define	O
probability	O
distributions	O
by	O
combining	O
other	O
simpler	O
probability	O
distributions	O
one	O
common	O
way	O
of	O
combining	O
distributions	O
is	O
to	O
construct	O
a	O
mixture	B
distribution	I
a	O
mixture	B
distribution	I
is	O
made	O
up	O
of	O
several	O
component	O
distributions	O
on	O
each	O
trial	O
the	O
choice	O
of	O
which	O
component	O
distribution	O
generates	O
the	O
sample	O
is	O
determined	O
by	O
sampling	O
a	O
component	O
identity	O
from	O
a	O
multinoulli	B
distribution	I
x	O
c	O
c	O
i	O
p	O
i	O
p	O
p	O
i	O
where	O
p	O
c	O
is	O
the	O
multinoulli	B
distribution	I
over	O
component	O
identities	O
we	O
have	O
already	O
seen	O
one	O
example	B
of	O
a	O
mixture	B
distribution	I
the	O
empirical	B
distribution	I
over	O
real-valued	O
variables	O
is	O
a	O
mixture	B
distribution	I
with	O
one	O
dirac	O
component	O
for	O
each	O
training	O
example	B
chapter	O
probability	O
and	O
information	O
theory	O
the	O
mixture	O
model	O
is	O
one	O
simple	O
strategy	O
for	O
combining	O
probability	O
distributions	O
we	O
explore	O
the	O
art	O
of	O
building	O
complex	O
to	O
create	O
a	O
richer	O
distribution	O
in	O
chapter	O
probability	O
distributions	O
from	O
simple	O
ones	O
in	O
more	O
detail	O
the	O
mixture	O
model	O
allows	O
us	O
to	O
briefly	O
glimpse	O
a	O
concept	O
that	O
will	O
be	O
of	O
paramount	O
importance	O
later	O
the	O
latent	B
variable	I
a	O
latent	B
variable	I
is	O
a	O
random	B
variable	I
that	O
we	O
cannot	O
observe	O
directly	O
the	O
component	O
identity	O
variable	O
c	O
of	O
the	O
mixture	O
model	O
provides	O
an	O
example	B
latent	O
variables	O
may	O
be	O
related	O
to	O
x	O
through	O
the	O
distribution	O
p	O
the	O
joint	O
distribution	O
in	O
this	O
case	O
p	O
c	O
p	O
c	O
over	O
the	O
latent	B
variable	I
and	O
the	O
distribution	O
px	O
c	O
relating	O
the	O
latent	O
variables	O
to	O
the	O
visible	O
variables	O
determines	O
the	O
shape	O
of	O
the	O
distribution	O
p	O
even	O
though	O
it	O
is	O
possible	O
to	O
describe	O
p	O
without	O
reference	O
to	O
the	O
latent	B
variable	I
latent	O
variables	O
are	O
discussed	O
further	O
in	O
section	O
a	O
very	O
powerful	O
and	O
common	O
type	O
of	O
mixture	O
model	O
is	O
the	O
gaussian	O
mixture	O
c	O
i	O
are	O
gaussians	O
each	O
component	O
has	O
model	O
in	O
which	O
the	O
components	O
px	O
a	O
separately	O
parametrized	O
mean	O
and	O
covariance	O
some	O
mixtures	O
can	O
have	O
more	O
constraints	O
for	O
example	B
the	O
covariances	O
could	O
be	O
shared	O
across	O
components	O
via	O
the	O
constraint	O
as	O
with	O
a	O
single	O
gaussian	O
distribution	O
the	O
mixture	O
of	O
gaussians	O
might	O
constrain	O
the	O
covariance	B
matrix	I
for	O
each	O
component	O
to	O
be	O
diagonal	O
or	O
isotropic	B
i	O
in	O
addition	O
to	O
the	O
means	O
and	O
covariances	O
the	O
parameters	O
of	O
a	O
gaussian	O
mixture	O
specify	O
the	O
prior	O
probability	O
i	O
pc	O
i	O
given	O
to	O
each	O
component	O
i	O
the	O
word	O
prior	O
indicates	O
that	O
it	O
expresses	O
the	O
model	O
s	O
beliefs	O
about	O
c	O
before	O
it	O
has	O
observed	O
x	O
by	O
comparison	O
pc	O
x	O
is	O
a	O
posterior	O
probability	O
because	O
it	O
is	O
computed	O
after	O
observation	O
of	O
x	O
a	O
gaussian	O
mixture	O
model	O
is	O
a	O
universal	B
approximator	I
of	O
densities	O
in	O
the	O
sense	O
that	O
any	O
smooth	O
density	O
can	O
be	O
approximated	O
with	O
any	O
specific	O
non-zero	O
amount	O
of	O
error	O
by	O
a	O
gaussian	O
mixture	O
model	O
with	O
enough	O
components	O
figure	O
shows	O
samples	O
from	O
a	O
gaussian	O
mixture	O
model	O
useful	O
properties	O
of	O
common	O
functions	O
certain	O
functions	O
arise	O
often	O
while	O
working	O
with	O
probability	O
distributions	O
especially	O
the	O
probability	O
distributions	O
used	O
in	O
deep	O
learning	O
models	O
one	O
of	O
these	O
functions	O
is	O
the	O
logistic	O
sigmoid	O
x	O
exp	O
x	O
the	O
logistic	O
sigmoid	O
is	O
commonly	O
used	O
to	O
produce	O
the	O
parameter	O
of	O
a	O
bernoulli	O
chapter	O
probability	O
and	O
information	O
theory	O
x	O
figure	O
samples	O
from	O
a	O
gaussian	O
mixture	O
model	O
in	O
this	O
example	B
there	O
are	O
three	O
components	O
from	O
left	O
to	O
right	O
the	O
first	O
component	O
has	O
an	O
isotropic	B
covariance	B
matrix	I
meaning	O
it	O
has	O
the	O
same	O
amount	O
of	O
variance	O
in	O
each	O
direction	O
the	O
second	O
has	O
a	O
diagonal	O
covariance	B
matrix	I
meaning	O
it	O
can	O
control	O
the	O
variance	O
separately	O
along	O
each	O
axis-aligned	O
direction	O
this	O
example	B
has	O
more	O
variance	O
along	O
the	O
x	O
axis	O
than	O
along	O
the	O
axis	O
the	O
third	O
component	O
has	O
a	O
full-rank	O
covariance	B
matrix	I
allowing	O
it	O
to	O
control	O
the	O
variance	O
separately	O
along	O
an	O
arbitrary	O
basis	O
of	O
directions	O
distribution	O
because	O
its	O
range	O
is	O
which	O
lies	O
within	O
the	O
valid	O
range	O
of	O
values	O
for	O
the	O
parameter	O
see	O
figure	O
for	O
a	O
graph	O
of	O
the	O
sigmoid	O
function	O
the	O
sigmoid	O
function	O
saturates	O
when	O
its	O
argument	O
is	O
very	O
positive	O
or	O
very	O
negative	O
meaning	O
that	O
the	O
function	O
becomes	O
very	O
flat	O
and	O
insensitive	O
to	O
small	O
changes	O
in	O
its	O
input	O
another	O
commonly	O
encountered	O
function	O
is	O
the	O
softplus	O
function	O
dugas	O
et	O
al	O
x	O
x	O
log	O
exp	O
the	O
softplus	O
function	O
can	O
be	O
useful	O
for	O
producing	O
the	O
or	O
parameter	O
of	O
a	O
normal	O
distribution	O
because	O
its	O
range	O
is	O
it	O
also	O
arises	O
commonly	O
when	O
manipulating	O
expressions	O
involving	O
sigmoids	O
the	O
name	O
of	O
the	O
softplus	O
function	O
comes	O
from	O
the	O
fact	O
that	O
it	O
is	O
a	O
smoothed	O
or	O
softened	O
version	O
of	O
x	O
x	O
see	O
figure	O
for	O
a	O
graph	O
of	O
the	O
softplus	O
function	O
the	O
following	O
properties	O
are	O
all	O
useful	O
enough	O
that	O
you	O
may	O
wish	O
to	O
memorize	O
them	O
chapter	O
probability	O
and	O
information	O
theory	O
x	O
figure	O
the	O
logistic	O
sigmoid	O
function	O
x	O
x	O
x	O
figure	O
the	O
softplus	O
function	O
chapter	O
probability	O
and	O
information	O
theory	O
x	O
exp	O
x	O
exp	O
d	O
dx	O
x	O
x	O
x	O
log	O
x	O
x	O
x	O
x	O
d	O
dx	O
x	O
x	O
x	O
x	O
log	O
x	O
log	O
x	O
x	O
x	O
x	O
x	O
x	O
x	O
y	O
dy	O
x	O
x	O
is	O
called	O
the	O
logit	O
in	O
statistics	O
but	O
this	O
term	O
is	O
more	O
rarely	O
the	O
function	O
used	O
in	O
machine	B
learning	I
x	O
equation	O
provides	O
extra	O
justification	O
for	O
the	O
name	O
softplus	O
the	O
softplus	O
function	O
is	O
intended	O
as	O
a	O
smoothed	O
version	O
of	O
the	O
positive	O
part	O
function	O
x	O
the	O
positive	O
part	O
function	O
is	O
the	O
counterpart	O
of	O
the	O
negative	O
part	O
max	O
function	O
x	O
to	O
obtain	O
a	O
smooth	O
function	O
that	O
is	O
analogous	O
to	O
the	O
x	O
just	O
as	O
x	O
can	O
be	O
recovered	O
from	O
its	O
positive	O
part	O
negative	O
part	O
one	O
can	O
use	O
and	O
negative	O
part	O
via	O
the	O
identity	O
x	O
x	O
it	O
is	O
also	O
possible	O
to	O
recover	O
x	O
using	O
the	O
same	O
relationship	O
between	O
as	O
shown	O
in	O
equation	O
x	O
max	O
x	O
x	O
and	O
x	O
bayes	O
rule	O
we	O
often	O
find	O
ourselves	O
in	O
a	O
situation	O
where	O
we	O
know	O
p	O
y	O
x	O
p	O
y	O
using	O
bayes	O
rule	O
and	O
need	O
to	O
know	O
fortunately	O
if	O
we	O
also	O
know	O
p	O
we	O
can	O
compute	O
the	O
desired	O
quantity	O
x	O
y	O
p	O
y	O
x	O
p	O
p	O
p	O
note	O
that	O
while	O
p	O
appears	O
in	O
the	O
formula	O
it	O
is	O
usually	O
feasible	O
to	O
compute	O
p	O
so	O
we	O
do	O
not	O
need	O
to	O
begin	O
with	O
knowledge	O
of	O
x	O
p	O
x	O
p	O
x	O
p	O
chapter	O
probability	O
and	O
information	O
theory	O
bayes	O
rule	O
is	O
straightforward	O
to	O
derive	O
from	O
the	O
definition	O
of	O
conditional	B
probability	I
but	O
it	O
is	O
useful	O
to	O
know	O
the	O
name	O
of	O
this	O
formula	O
since	O
many	O
texts	O
refer	O
to	O
it	O
by	O
name	O
it	O
is	O
named	O
after	O
the	O
reverend	O
thomas	O
bayes	O
who	O
first	O
discovered	O
a	O
special	O
case	O
of	O
the	O
formula	O
the	O
general	O
version	O
presented	O
here	O
was	O
independently	O
discovered	O
by	O
pierre-simon	O
laplace	O
technical	O
details	O
of	O
continuous	O
variables	O
a	O
proper	O
formal	O
understanding	O
of	O
continuous	O
random	O
variables	O
and	O
probability	O
density	O
functions	O
requires	O
developing	O
probability	O
theory	O
in	O
terms	O
of	O
a	O
branch	O
of	O
mathematics	O
known	O
as	O
measure	B
theory	I
measure	B
theory	I
is	O
beyond	O
the	O
scope	O
of	O
this	O
textbook	O
but	O
we	O
can	O
briefly	O
sketch	O
some	O
of	O
the	O
issues	O
that	O
measure	B
theory	I
is	O
employed	O
to	O
resolve	O
px	O
in	O
section	O
we	O
saw	O
that	O
the	O
probability	O
of	O
a	O
continuous	O
vector-valued	O
x	O
lying	O
in	O
some	O
set	O
s	O
is	O
given	O
by	O
the	O
integral	O
of	O
px	O
over	O
the	O
set	O
s	O
some	O
choices	O
of	O
set	O
s	O
can	O
produce	O
paradoxes	O
for	O
example	B
it	O
is	O
possible	O
to	O
construct	O
two	O
sets	O
and	O
such	O
that	O
px	O
these	O
sets	O
are	O
generally	O
constructed	O
making	O
very	O
heavy	O
use	O
of	O
the	O
infinite	O
precision	B
of	O
real	O
numbers	O
for	O
example	B
by	O
making	O
fractal-shaped	O
sets	O
or	O
sets	O
that	O
are	O
defined	O
by	O
transforming	O
the	O
set	O
of	O
rational	O
one	O
of	O
the	O
key	O
contributions	O
of	O
measure	B
theory	I
is	O
to	O
provide	O
a	O
characterization	O
of	O
the	O
set	O
of	O
sets	O
that	O
we	O
can	O
compute	O
the	O
probability	O
of	O
without	O
encountering	O
paradoxes	O
in	O
this	O
book	O
we	O
only	O
integrate	O
over	O
sets	O
with	O
relatively	O
simple	O
descriptions	O
so	O
this	O
aspect	O
of	O
measure	B
theory	I
never	O
becomes	O
a	O
relevant	O
concern	O
but	O
for	O
our	O
purposes	O
measure	B
theory	I
is	O
more	O
useful	O
for	O
describing	O
theorems	O
that	O
n	O
but	O
do	O
not	O
apply	O
to	O
some	O
corner	O
cases	O
measure	B
theory	I
apply	O
to	O
most	O
points	O
in	O
r	O
provides	O
a	O
rigorous	O
way	O
of	O
describing	O
that	O
a	O
set	O
of	O
points	O
is	O
negligibly	O
small	O
such	O
a	O
set	O
is	O
said	O
to	O
have	O
measure	B
zero	I
we	O
do	O
not	O
formally	O
define	O
this	O
concept	O
in	O
this	O
textbook	O
for	O
our	O
purposes	O
it	O
is	O
sufficient	O
to	O
understand	O
the	O
intuition	O
that	O
a	O
set	O
of	O
measure	B
zero	I
occupies	O
no	O
volume	O
in	O
the	O
space	O
we	O
are	O
measuring	O
for	O
example	B
a	O
line	O
has	O
measure	B
zero	I
while	O
a	O
filled	O
polygon	O
has	O
positive	O
measure	O
within	O
r	O
likewise	O
an	O
individual	O
point	O
has	O
measure	B
zero	I
any	O
union	O
of	O
countably	O
many	O
sets	O
that	O
each	O
have	O
measure	B
zero	I
also	O
has	O
measure	B
zero	I
the	O
set	O
of	O
all	O
the	O
rational	O
numbers	O
has	O
measure	B
zero	I
for	O
instance	O
another	O
useful	O
term	O
from	O
measure	B
theory	I
is	O
almost	B
everywhere	I
a	O
property	O
that	O
holds	O
almost	B
everywhere	I
holds	O
throughout	O
all	O
of	O
space	O
except	O
for	O
on	O
a	O
set	O
of	O
banach-tarski	O
theorem	O
provides	O
a	O
fun	O
example	B
of	O
such	O
sets	O
chapter	O
probability	O
and	O
information	O
theory	O
measure	B
zero	I
because	O
the	O
exceptions	O
occupy	O
a	O
negligible	O
amount	O
of	O
space	O
they	O
can	O
be	O
safely	O
ignored	O
for	O
many	O
applications	O
some	O
important	O
results	O
in	O
probability	O
theory	O
hold	O
for	O
all	O
discrete	O
values	O
but	O
only	O
hold	O
almost	B
everywhere	I
for	O
continuous	O
values	O
another	O
technical	O
detail	O
of	O
continuous	O
variables	O
relates	O
to	O
handling	O
continuous	O
random	O
variables	O
that	O
are	O
deterministic	O
functions	O
of	O
one	O
another	O
suppose	O
we	O
have	O
two	O
random	O
variables	O
x	O
and	O
y	O
such	O
that	O
y	O
gx	O
where	O
g	O
is	O
an	O
invertible	O
con	O
tinuous	O
differentiable	O
transformation	O
one	O
might	O
expect	O
that	O
py	O
pxg	O
this	O
is	O
actually	O
not	O
the	O
case	O
as	O
a	O
simple	O
example	B
suppose	O
we	O
have	O
scalar	O
random	O
variables	O
x	O
and	O
y	O
suppose	O
if	O
we	O
use	O
the	O
rule	O
py	O
px	O
then	O
py	O
will	O
be	O
on	O
this	O
interval	O
this	O
means	O
y	O
x	O
everywhere	O
except	O
the	O
interval	O
and	O
it	O
will	O
be	O
and	O
x	O
py	O
y	O
dy	O
which	O
violates	O
the	O
definition	O
of	O
a	O
probability	B
distribution	I
this	O
is	O
a	O
common	O
mistake	O
the	O
problem	O
with	O
this	O
approach	O
is	O
that	O
it	O
fails	O
to	O
account	O
for	O
the	O
distortion	O
of	O
space	O
introduced	O
by	O
the	O
function	O
g	O
recall	B
that	O
the	O
probability	O
of	O
x	O
lying	O
in	O
an	O
infinitesimally	O
small	O
region	O
with	O
volume	O
x	O
is	O
given	O
by	O
p	O
x	O
since	O
g	O
can	O
expand	O
or	O
contract	O
space	O
the	O
infinitesimal	O
volume	O
surrounding	O
x	O
in	O
x	O
space	O
may	O
have	O
different	O
volume	O
in	O
space	O
y	O
to	O
see	O
how	O
to	O
correct	O
the	O
problem	O
we	O
return	O
to	O
the	O
scalar	O
case	O
we	O
need	O
to	O
preserve	O
the	O
property	O
py	O
g	O
x	O
dy	O
solving	O
from	O
this	O
we	O
obtain	O
py	O
y	O
pxg	O
or	O
equivalently	O
px	O
dx	O
x	O
y	O
g	O
x	O
x	O
px	O
x	O
py	O
g	O
x	O
in	O
higher	O
dimensions	O
the	O
derivative	B
generalizes	O
to	O
the	O
determinant	O
of	O
the	O
jacobian	O
matrix	O
the	O
matrix	O
with	O
jij	O
xi	O
yj	O
thus	O
for	O
real-valued	O
vectors	O
and	O
y	O
x	O
px	O
x	O
py	O
g	O
x	O
det	O
g	O
x	O
chapter	O
probability	O
and	O
information	O
theory	O
information	O
theory	O
information	O
theory	O
is	O
a	O
branch	O
of	O
applied	O
mathematics	O
that	O
revolves	O
around	O
quantifying	O
how	O
much	O
information	O
is	O
present	O
in	O
a	O
signal	O
it	O
was	O
originally	O
invented	O
to	O
study	O
sending	O
messages	O
from	O
discrete	O
alphabets	O
over	O
a	O
noisy	O
channel	O
such	O
as	O
communication	O
via	O
radio	O
transmission	O
in	O
this	O
context	O
information	O
theory	O
tells	O
how	O
to	O
design	O
optimal	O
codes	O
and	O
calculate	O
the	O
expected	O
length	O
of	O
messages	O
sampled	O
from	O
specific	O
probability	O
distributions	O
using	O
various	O
encoding	O
schemes	O
in	O
the	O
context	O
of	O
machine	B
learning	I
we	O
can	O
also	O
apply	O
information	O
theory	O
to	O
continuous	O
variables	O
where	O
some	O
of	O
these	O
message	O
length	O
interpretations	O
do	O
not	O
apply	O
this	O
field	O
is	O
fundamental	O
to	O
many	O
areas	O
of	O
electrical	O
engineering	O
and	O
computer	O
science	O
in	O
this	O
textbook	O
we	O
mostly	O
use	O
a	O
few	O
key	O
ideas	O
from	O
information	O
theory	O
to	O
characterize	O
probability	O
distributions	O
or	O
quantify	O
similarity	O
between	O
probability	O
distributions	O
for	O
more	O
detail	O
on	O
information	O
theory	O
see	O
cover	O
and	O
thomas	O
mackay	O
or	O
the	O
basic	O
intuition	O
behind	O
information	O
theory	O
is	O
that	O
learning	O
that	O
an	O
unlikely	O
event	O
has	O
occurred	O
is	O
more	O
informative	O
than	O
learning	O
that	O
a	O
likely	O
event	O
has	O
occurred	O
a	O
message	O
saying	O
the	O
sun	O
rose	O
this	O
morning	O
is	O
so	O
uninformative	O
as	O
to	O
be	O
unnecessary	O
to	O
send	O
but	O
a	O
message	O
saying	O
there	O
was	O
a	O
solar	O
eclipse	O
this	O
morning	O
is	O
very	O
informative	O
we	O
would	O
like	O
to	O
quantify	O
information	O
in	O
a	O
way	O
that	O
formalizes	O
this	O
intuition	O
specifically	O
likely	O
events	O
should	O
have	O
low	O
information	O
content	O
and	O
in	O
the	O
extreme	O
case	O
events	O
that	O
are	O
guaranteed	O
to	O
happen	O
should	O
have	O
no	O
information	O
content	O
whatsoever	O
less	O
likely	O
events	O
should	O
have	O
higher	O
information	O
content	O
independent	O
events	O
should	O
have	O
additive	O
information	O
for	O
example	B
finding	O
out	O
that	O
a	O
tossed	O
coin	O
has	O
come	O
up	O
as	O
heads	O
twice	O
should	O
convey	O
twice	O
as	O
much	O
information	O
as	O
finding	O
out	O
that	O
a	O
tossed	O
coin	O
has	O
come	O
up	O
as	O
heads	O
once	O
in	O
order	O
to	O
satisfy	O
all	O
three	O
of	O
these	O
properties	O
we	O
define	O
the	O
self-information	B
of	O
an	O
event	O
x	O
x	O
to	O
be	O
i	O
x	O
log	O
p	O
x	O
in	O
this	O
book	O
we	O
always	O
use	O
log	O
to	O
mean	O
the	O
natural	O
logarithm	O
with	O
base	O
e	O
our	O
definition	O
of	O
i	O
is	O
therefore	O
written	O
in	O
units	O
of	O
nats	O
one	O
nat	B
is	O
the	O
amount	O
of	O
chapter	O
probability	O
and	O
information	O
theory	O
information	O
gained	O
by	O
observing	O
an	O
event	O
of	O
probability	O
other	O
texts	O
use	O
e	O
logarithms	O
and	O
units	O
called	O
bits	O
or	O
shannons	O
information	O
measured	O
in	O
bits	O
is	O
just	O
a	O
rescaling	O
of	O
information	O
measured	O
in	O
nats	O
when	O
x	O
is	O
continuous	O
we	O
use	O
the	O
same	O
definition	O
of	O
information	O
by	O
analogy	O
but	O
some	O
of	O
the	O
properties	O
from	O
the	O
discrete	O
case	O
are	O
lost	O
for	O
example	B
an	O
event	O
with	O
unit	O
density	O
still	O
has	O
zero	O
information	O
despite	O
not	O
being	O
an	O
event	O
that	O
is	O
guaranteed	O
to	O
occur	O
self-information	B
deals	O
only	O
with	O
a	O
single	O
outcome	O
we	O
can	O
quantify	O
the	O
amount	O
of	O
uncertainty	O
in	O
an	O
entire	O
probability	B
distribution	I
using	O
the	O
shannon	O
entropy	O
p	O
ex	O
i	O
x	O
h	O
x	O
p	O
p	O
x	O
ex	O
also	O
denoted	O
hp	O
in	O
other	O
words	O
the	O
shannon	O
entropy	O
of	O
a	O
distribution	O
is	O
the	O
expected	O
amount	O
of	O
information	O
in	O
an	O
event	O
drawn	O
from	O
that	O
distribution	O
it	O
gives	O
a	O
lower	O
bound	B
on	O
the	O
number	O
of	O
bits	O
the	O
logarithm	O
is	O
base	O
otherwise	O
the	O
units	O
are	O
different	O
needed	O
on	O
average	O
to	O
encode	O
symbols	O
drawn	O
from	O
a	O
distribution	O
p	O
distributions	O
that	O
are	O
nearly	O
deterministic	O
the	O
outcome	O
is	O
nearly	O
certain	O
have	O
low	O
entropy	O
distributions	O
that	O
are	O
closer	O
to	O
uniform	O
have	O
high	O
entropy	O
see	O
figure	O
x	O
is	O
continuous	O
the	O
shannon	O
entropy	O
is	O
known	O
as	O
the	O
differential	O
entropy	O
for	O
a	O
demonstration	O
when	O
if	O
we	O
have	O
two	O
separate	O
probability	O
distributions	O
p	O
and	O
q	O
over	O
the	O
same	O
random	B
variable	I
x	O
we	O
can	O
measure	O
how	O
different	O
these	O
two	O
distributions	O
are	O
using	O
the	O
kullback-leibler	B
divergence	I
p	O
q	O
d	O
kl	O
ex	O
p	O
log	O
p	O
x	O
q	O
x	O
p	O
p	O
x	O
e	O
x	O
log	O
q	O
x	O
in	O
the	O
case	O
of	O
discrete	O
variables	O
it	O
is	O
the	O
extra	O
amount	O
of	O
information	O
logarithm	O
but	O
in	O
machine	B
learning	I
we	O
usually	O
use	O
nats	O
in	O
bits	O
if	O
we	O
use	O
the	O
base	O
and	O
the	O
natural	O
logarithm	O
needed	O
to	O
send	O
a	O
message	O
containing	O
symbols	O
drawn	O
from	O
probability	B
distribution	I
p	O
when	O
we	O
use	O
a	O
code	O
that	O
was	O
designed	O
to	O
minimize	O
the	O
length	O
of	O
messages	O
drawn	O
from	O
probability	B
distribution	I
the	O
kl	O
divergence	O
has	O
many	O
useful	O
properties	O
most	O
notably	O
that	O
it	O
is	O
nonnegative	O
the	O
kl	O
divergence	O
is	O
if	O
and	O
only	O
if	O
p	O
and	O
q	O
are	O
the	O
same	O
distribution	O
in	O
the	O
case	O
of	O
discrete	O
variables	O
or	O
equal	O
almost	B
everywhere	I
in	O
the	O
case	O
of	O
continuous	O
variables	O
because	O
the	O
kl	O
divergence	O
is	O
non-negative	O
and	O
measures	O
the	O
difference	O
between	O
two	O
distributions	O
it	O
is	O
often	O
conceptualized	O
as	O
measuring	O
some	O
sort	O
of	O
distance	O
between	O
these	O
distributions	O
however	O
it	O
is	O
not	O
a	O
true	O
distance	O
measure	O
because	O
it	O
is	O
not	O
symmetric	O
dklp	O
q	O
for	O
some	O
p	O
and	O
q	O
this	O
dklq	O
p	O
chapter	O
probability	O
and	O
information	O
theory	O
s	O
t	O
a	O
n	O
n	O
i	O
y	O
p	O
o	O
r	O
t	O
n	O
e	O
n	O
o	O
n	O
n	O
a	O
h	O
s	O
p	O
figure	O
this	O
plot	O
shows	O
how	O
distributions	O
that	O
are	O
closer	O
to	O
deterministic	O
have	O
low	O
shannon	O
entropy	O
while	O
distributions	O
that	O
are	O
close	O
to	O
uniform	O
have	O
high	O
shannon	O
entropy	O
on	O
the	O
horizontal	O
axis	O
we	O
plot	O
p	O
the	O
probability	O
of	O
a	O
binary	O
random	B
variable	I
being	O
equal	O
to	O
the	O
entropy	O
is	O
given	O
by	O
log	O
when	O
p	O
is	O
near	O
the	O
distribution	O
is	O
nearly	O
deterministic	O
because	O
the	O
random	B
variable	I
is	O
nearly	O
always	O
when	O
p	O
is	O
near	O
the	O
distribution	O
is	O
nearly	O
deterministic	O
because	O
the	O
random	B
variable	I
is	O
nearly	O
always	O
when	O
p	O
the	O
entropy	O
is	O
maximal	O
because	O
the	O
distribution	O
is	O
uniform	O
over	O
the	O
two	O
outcomes	O
p	O
p	O
p	O
asymmetry	O
means	O
that	O
there	O
are	O
important	O
consequences	O
to	O
the	O
choice	O
of	O
whether	O
to	O
use	O
dkl	O
for	O
more	O
detail	O
see	O
figure	O
a	O
quantity	O
that	O
is	O
closely	O
related	O
to	O
the	O
kl	O
divergence	O
is	O
the	O
cross-entropy	B
which	O
is	O
similar	O
to	O
the	O
kl	O
divergence	O
but	O
lacking	O
p	O
q	O
p	O
hp	O
q	O
h	O
dkl	O
q	O
the	O
term	O
on	O
the	O
left	O
or	O
dkl	O
h	O
p	O
q	O
p	O
log	O
x	O
ex	O
minimizing	O
the	O
cross-entropy	B
with	O
respect	O
to	O
q	O
is	O
equivalent	O
to	O
minimizing	O
the	O
kl	O
divergence	O
because	O
does	O
not	O
participate	O
in	O
the	O
omitted	O
term	O
q	O
when	O
computing	O
many	O
of	O
these	O
quantities	O
it	O
is	O
common	O
to	O
encounter	O
expressions	O
of	O
the	O
form	O
log	O
by	O
convention	O
in	O
the	O
context	O
of	O
information	O
theory	O
we	O
treat	O
these	O
expressions	O
as	O
limx	O
log	O
x	O
x	O
structured	O
probabilistic	O
models	O
machine	B
learning	I
algorithms	O
often	O
involve	O
probability	O
distributions	O
over	O
a	O
very	O
large	O
number	O
of	O
random	O
variables	O
often	O
these	O
probability	O
distributions	O
involve	O
direct	O
interactions	O
between	O
relatively	O
few	O
variables	O
using	O
a	O
single	O
function	O
to	O
chapter	O
probability	O
and	O
information	O
theory	O
q	O
argminqdkl	O
q	O
q	O
argminqdkl	O
q	O
p	O
y	O
t	O
i	O
s	O
n	O
e	O
d	O
y	O
t	O
i	O
l	O
i	O
b	O
a	O
b	O
o	O
r	O
p	O
p	O
x	O
q	O
y	O
t	O
i	O
s	O
n	O
e	O
d	O
y	O
t	O
i	O
l	O
i	O
b	O
a	O
b	O
o	O
r	O
p	O
p	O
q	O
x	O
x	O
or	O
dkl	O
p	O
figure	O
the	O
kl	O
divergence	O
is	O
asymmetric	O
suppose	O
we	O
have	O
a	O
distribution	O
px	O
and	O
wish	O
to	O
approximate	O
it	O
with	O
another	O
distribution	O
qx	O
we	O
have	O
the	O
choice	O
of	O
minimizing	O
either	O
dkl	O
q	O
we	O
illustrate	O
the	O
effect	O
of	O
this	O
choice	O
using	O
a	O
mixture	O
of	O
two	O
gaussians	O
for	O
p	O
and	O
a	O
single	O
gaussian	O
for	O
q	O
the	O
choice	O
of	O
which	O
direction	O
of	O
the	O
kl	O
divergence	O
to	O
use	O
is	O
problem-dependent	O
some	O
applications	O
require	O
an	O
approximation	O
that	O
usually	O
places	O
high	O
probability	O
anywhere	O
that	O
the	O
true	O
distribution	O
places	O
high	O
probability	O
while	O
other	O
applications	O
require	O
an	O
approximation	O
that	O
rarely	O
places	O
high	O
probability	O
anywhere	O
that	O
the	O
true	O
distribution	O
places	O
low	O
probability	O
the	O
choice	O
of	O
the	O
direction	O
of	O
the	O
kl	O
divergence	O
reflects	O
which	O
of	O
these	O
considerations	O
takes	O
priority	O
for	O
each	O
application	O
effect	O
of	O
minimizing	O
dklp	O
q	O
in	O
this	O
case	O
we	O
select	O
a	O
q	O
that	O
has	O
high	O
probability	O
where	O
p	O
has	O
high	O
probability	O
when	O
p	O
has	O
multiple	O
modes	O
q	O
chooses	O
to	O
blur	O
the	O
modes	O
together	O
in	O
order	O
to	O
put	O
high	O
probability	O
mass	O
on	O
all	O
of	O
them	O
effect	O
of	O
minimizing	O
dklq	O
p	O
in	O
this	O
case	O
we	O
select	O
a	O
q	O
that	O
has	O
low	O
probability	O
where	O
p	O
has	O
low	O
probability	O
when	O
p	O
has	O
multiple	O
modes	O
that	O
are	O
sufficiently	O
widely	O
separated	O
as	O
in	O
this	O
figure	O
the	O
kl	O
divergence	O
is	O
minimized	O
by	O
choosing	O
a	O
single	O
mode	O
in	O
order	O
to	O
avoid	O
putting	O
probability	O
mass	O
in	O
the	O
low-probability	O
areas	O
between	O
modes	O
of	O
p	O
here	O
we	O
illustrate	O
the	O
outcome	O
when	O
q	O
is	O
chosen	O
to	O
emphasize	O
the	O
left	O
mode	O
we	O
could	O
also	O
have	O
achieved	O
an	O
equal	O
value	O
of	O
the	O
kl	O
divergence	O
by	O
choosing	O
the	O
right	O
mode	O
if	O
the	O
modes	O
are	O
not	O
separated	O
by	O
a	O
sufficiently	O
strong	O
low	O
probability	O
region	O
then	O
this	O
direction	O
of	O
the	O
kl	O
divergence	O
can	O
still	O
choose	O
to	O
blur	O
the	O
modes	O
chapter	O
probability	O
and	O
information	O
theory	O
describe	O
the	O
entire	O
joint	B
probability	B
distribution	I
can	O
be	O
very	O
inefficient	O
computationally	O
and	O
statistically	O
instead	O
of	O
using	O
a	O
single	O
function	O
to	O
represent	O
a	O
probability	B
distribution	I
we	O
can	O
split	O
a	O
probability	B
distribution	I
into	O
many	O
factors	O
that	O
we	O
multiply	O
together	O
for	O
example	B
suppose	O
we	O
have	O
three	O
random	O
variables	O
a	O
b	O
and	O
c	O
suppose	O
that	O
a	O
influences	O
the	O
value	O
of	O
b	O
and	O
b	O
influences	O
the	O
value	O
of	O
c	O
but	O
that	O
a	O
and	O
c	O
are	O
independent	O
given	O
b	O
we	O
can	O
represent	O
the	O
probability	B
distribution	I
over	O
all	O
three	O
variables	O
as	O
a	O
product	O
of	O
probability	O
distributions	O
over	O
two	O
variables	O
p	O
b	O
c	O
p	O
c	O
b	O
b	O
a	O
p	O
p	O
these	O
factorizations	O
can	O
greatly	O
reduce	O
the	O
number	O
of	O
parameters	O
needed	O
to	O
describe	O
the	O
distribution	O
each	O
factor	O
uses	O
a	O
number	O
of	O
parameters	O
that	O
is	O
exponential	O
in	O
the	O
number	O
of	O
variables	O
in	O
the	O
factor	O
this	O
means	O
that	O
we	O
can	O
greatly	O
reduce	O
the	O
cost	O
of	O
representing	O
a	O
distribution	O
if	O
we	O
are	O
able	O
to	O
find	O
a	O
factorization	O
into	O
distributions	O
over	O
fewer	O
variables	O
we	O
can	O
describe	O
these	O
kinds	O
of	O
factorizations	O
using	O
graphs	O
here	O
we	O
use	O
the	O
word	O
graph	O
in	O
the	O
sense	O
of	O
graph	O
theory	O
a	O
set	O
of	O
vertices	O
that	O
may	O
be	O
connected	O
to	O
each	O
other	O
with	O
edges	O
when	O
we	O
represent	O
the	O
factorization	O
of	O
a	O
probability	B
distribution	I
with	O
a	O
graph	O
we	O
call	O
it	O
a	O
structured	O
probabilistic	O
model	O
or	O
graphical	O
model	O
there	O
are	O
two	O
main	O
kinds	O
of	O
structured	O
probabilistic	O
models	O
directed	O
and	O
undirected	O
both	O
kinds	O
of	O
graphical	O
models	O
use	O
a	O
graph	O
in	O
which	O
each	O
node	O
in	O
the	O
graph	O
corresponds	O
to	O
a	O
random	B
variable	I
and	O
an	O
edge	O
connecting	O
two	O
random	O
variables	O
means	O
that	O
the	O
probability	B
distribution	I
is	O
able	O
to	O
represent	O
direct	O
interactions	O
between	O
those	O
two	O
random	O
variables	O
g	O
directed	O
models	O
use	O
graphs	O
with	O
directed	O
edges	O
and	O
they	O
represent	O
factorizations	O
into	O
conditional	B
probability	I
distributions	O
as	O
in	O
the	O
example	B
above	O
specifically	O
a	O
directed	O
model	O
contains	O
one	O
factor	O
for	O
every	O
random	B
variable	I
xi	O
in	O
the	O
distribution	O
and	O
that	O
factor	O
consists	O
of	O
the	O
conditional	O
distribution	O
over	O
xi	O
given	O
the	O
parents	O
of	O
xi	O
denoted	O
p	O
agxi	O
p	O
p	O
i	O
p	O
ag	O
see	O
figure	O
distributions	O
it	O
represents	O
for	O
an	O
example	B
of	O
a	O
directed	O
graph	O
and	O
the	O
factorization	O
of	O
probability	O
undirected	O
models	O
use	O
graphs	O
with	O
undirected	O
edges	O
and	O
they	O
represent	O
factorizations	O
into	O
a	O
set	O
of	O
functions	O
unlike	O
in	O
the	O
directed	O
case	O
these	O
functions	O
chapter	O
probability	O
and	O
information	O
theory	O
aa	O
bb	O
dd	O
cc	O
ee	O
figure	O
a	O
directed	O
graphical	O
model	O
over	O
random	O
variables	O
a	O
b	O
c	O
d	O
and	O
e	O
this	O
graph	O
corresponds	O
to	O
probability	O
distributions	O
that	O
can	O
be	O
factored	O
as	O
b	O
c	O
d	O
e	O
p	O
p	O
p	O
b	O
a	O
a	O
p	O
e	O
c	O
d	O
b	O
p	O
b	O
p	O
this	O
graph	O
allows	O
us	O
to	O
quickly	O
see	O
some	O
properties	O
of	O
the	O
distribution	O
for	O
example	B
a	O
and	O
c	O
interact	O
directly	O
but	O
a	O
and	O
e	O
interact	O
only	O
indirectly	O
via	O
c	O
g	O
are	O
usually	O
not	O
probability	O
distributions	O
of	O
any	O
kind	O
any	O
set	O
of	O
nodes	O
that	O
are	O
all	O
c	O
connected	O
to	O
each	O
other	O
in	O
in	O
an	O
undirected	B
model	I
is	O
associated	O
with	O
a	O
factor	O
these	O
factors	O
are	O
just	O
functions	O
not	O
probability	O
distributions	O
the	O
output	O
of	O
each	O
factor	O
must	O
be	O
non-negative	O
but	O
there	O
is	O
no	O
constraint	O
that	O
the	O
factor	O
must	O
sum	O
or	O
integrate	O
to	O
like	O
a	O
probability	B
distribution	I
is	O
called	O
a	O
clique	O
each	O
clique	O
c	O
the	O
probability	O
of	O
a	O
configuration	O
of	O
random	O
variables	O
is	O
proportional	O
to	O
the	O
product	O
of	O
all	O
of	O
these	O
factors	O
assignments	O
that	O
result	O
in	O
larger	O
factor	O
values	O
are	O
more	O
likely	O
of	O
course	O
there	O
is	O
no	O
guarantee	O
that	O
this	O
product	O
will	O
sum	O
to	O
we	O
therefore	O
divide	O
by	O
a	O
normalizing	O
constant	O
z	O
defined	O
to	O
be	O
the	O
sum	O
or	O
integral	O
over	O
all	O
states	O
of	O
the	O
product	O
of	O
the	O
functions	O
in	O
order	O
to	O
obtain	O
a	O
normalized	O
probability	B
distribution	I
c	O
p	O
z	O
i	O
see	O
figure	O
probability	O
distributions	O
it	O
represents	O
for	O
an	O
example	B
of	O
an	O
undirected	O
graph	O
and	O
the	O
factorization	O
of	O
keep	O
in	O
mind	O
that	O
these	O
graphical	O
representations	O
of	O
factorizations	O
are	O
a	O
language	O
for	O
describing	O
probability	O
distributions	O
they	O
are	O
not	O
mutually	O
exclusive	O
families	O
of	O
probability	O
distributions	O
being	O
directed	O
or	O
undirected	O
is	O
not	O
a	O
property	O
of	O
a	O
probability	B
distribution	I
it	O
is	O
a	O
property	O
of	O
a	O
particular	O
description	O
of	O
a	O
chapter	O
probability	O
and	O
information	O
theory	O
aa	O
bb	O
dd	O
cc	O
ee	O
figure	O
an	O
undirected	O
graphical	O
model	O
over	O
random	O
variables	O
a	O
b	O
c	O
d	O
and	O
e	O
this	O
graph	O
corresponds	O
to	O
probability	O
distributions	O
that	O
can	O
be	O
factored	O
as	O
b	O
c	O
d	O
e	O
p	O
z	O
a	O
b	O
c	O
d	O
e	O
this	O
graph	O
allows	O
us	O
to	O
quickly	O
see	O
some	O
properties	O
of	O
the	O
distribution	O
for	O
example	B
a	O
and	O
c	O
interact	O
directly	O
but	O
a	O
and	O
e	O
interact	O
only	O
indirectly	O
via	O
c	O
probability	B
distribution	I
but	O
any	O
probability	B
distribution	I
may	O
be	O
described	O
in	O
both	O
ways	O
i	O
ii	O
and	O
throughout	O
parts	O
of	O
this	O
book	O
we	O
will	O
use	O
structured	O
probabilistic	O
models	O
merely	O
as	O
a	O
language	O
to	O
describe	O
which	O
direct	O
probabilistic	O
relationships	O
different	O
machine	B
learning	I
algorithms	O
choose	O
to	O
represent	O
no	O
further	O
understanding	O
of	O
structured	O
probabilistic	O
models	O
is	O
needed	O
until	O
the	O
discussion	O
of	O
research	O
topics	O
in	O
part	O
where	O
we	O
will	O
explore	O
structured	O
probabilistic	O
models	O
in	O
much	O
greater	O
detail	O
iii	O
this	O
chapter	O
has	O
reviewed	O
the	O
basic	O
concepts	O
of	O
probability	O
theory	O
that	O
are	O
most	O
relevant	O
to	O
deep	O
learning	O
one	O
more	O
set	O
of	O
fundamental	O
mathematical	O
tools	O
remains	O
numerical	O
methods	O
chapter	O
numerical	O
computation	O
machine	B
learning	I
algorithms	O
usually	O
require	O
a	O
high	O
amount	O
of	O
numerical	O
computation	O
this	O
typically	O
refers	O
to	O
algorithms	O
that	O
solve	O
mathematical	O
problems	O
by	O
methods	O
that	O
update	O
estimates	O
of	O
the	O
solution	O
via	O
an	O
iterative	O
process	O
rather	O
than	O
analytically	O
deriving	O
a	O
formula	O
providing	O
a	O
symbolic	O
expression	O
for	O
the	O
correct	O
solution	O
common	O
operations	O
include	O
optimization	O
the	O
value	O
of	O
an	O
argument	O
that	O
minimizes	O
or	O
maximizes	O
a	O
function	O
and	O
solving	O
systems	O
of	O
linear	O
equations	O
even	O
just	O
evaluating	O
a	O
mathematical	O
function	O
on	O
a	O
digital	O
computer	O
can	O
be	O
difficult	O
when	O
the	O
function	O
involves	O
real	O
numbers	O
which	O
cannot	O
be	O
represented	O
precisely	O
using	O
a	O
finite	O
amount	O
of	O
memory	O
overflow	O
and	O
underflow	O
the	O
fundamental	O
difficulty	O
in	O
performing	O
continuous	O
math	O
on	O
a	O
digital	O
computer	O
is	O
that	O
we	O
need	O
to	O
represent	O
infinitely	O
many	O
real	O
numbers	O
with	O
a	O
finite	O
number	O
of	O
bit	O
patterns	O
this	O
means	O
that	O
for	O
almost	O
all	O
real	O
numbers	O
we	O
incur	O
some	O
approximation	O
error	O
when	O
we	O
represent	O
the	O
number	O
in	O
the	O
computer	O
in	O
many	O
cases	O
this	O
is	O
just	O
rounding	O
error	O
rounding	O
error	O
is	O
problematic	O
especially	O
when	O
it	O
compounds	O
across	O
many	O
operations	O
and	O
can	O
cause	O
algorithms	O
that	O
work	O
in	O
theory	O
to	O
fail	O
in	O
practice	O
if	O
they	O
are	O
not	O
designed	O
to	O
minimize	O
the	O
accumulation	O
of	O
rounding	O
error	O
one	O
form	O
of	O
rounding	O
error	O
that	O
is	O
particularly	O
devastating	O
is	O
underflow	O
underflow	O
occurs	O
when	O
numbers	O
near	O
zero	O
are	O
rounded	O
to	O
zero	O
many	O
functions	O
behave	O
qualitatively	O
differently	O
when	O
their	O
argument	O
is	O
zero	O
rather	O
than	O
a	O
small	O
positive	O
number	O
for	O
example	B
we	O
usually	O
want	O
to	O
avoid	O
division	O
by	O
zero	O
chapter	O
numerical	O
computation	O
software	O
environments	O
will	O
raise	O
exceptions	O
when	O
this	O
occurs	O
others	O
will	O
return	O
a	O
result	O
with	O
a	O
placeholder	O
not-a-number	O
value	O
or	O
taking	O
the	O
logarithm	O
of	O
zero	O
is	O
usually	O
treated	O
as	O
which	O
then	O
becomes	O
not-a-number	O
if	O
it	O
is	O
used	O
for	O
many	O
further	O
arithmetic	O
operations	O
another	O
highly	O
damaging	O
form	O
of	O
numerical	O
error	O
is	O
overflow	O
overflow	O
occurs	O
further	O
when	O
numbers	O
with	O
large	O
magnitude	O
are	O
approximated	O
as	O
arithmetic	O
will	O
usually	O
change	O
these	O
infinite	O
values	O
into	O
not-a-number	O
values	O
or	O
one	O
example	B
of	O
a	O
function	O
that	O
must	O
be	O
stabilized	O
against	O
underflow	O
and	O
overflow	O
is	O
the	O
softmax	O
function	O
the	O
softmax	O
function	O
is	O
often	O
used	O
to	O
predict	O
the	O
probabilities	O
associated	O
with	O
a	O
multinoulli	B
distribution	I
the	O
softmax	O
function	O
is	O
defined	O
to	O
be	O
softmax	O
i	O
expxi	O
n	O
expxj	O
consider	O
what	O
happens	O
when	O
all	O
of	O
the	O
xi	O
are	O
equal	O
to	O
some	O
constant	O
c	O
analytically	O
we	O
can	O
see	O
that	O
all	O
of	O
the	O
outputs	O
should	O
be	O
equal	O
to	O
numerically	O
this	O
may	O
n	O
not	O
occur	O
when	O
c	O
has	O
large	O
magnitude	O
if	O
c	O
is	O
very	O
negative	O
then	O
expc	O
will	O
underflow	O
this	O
means	O
the	O
denominator	O
of	O
the	O
softmax	O
will	O
become	O
so	O
the	O
final	O
result	O
is	O
undefined	O
when	O
c	O
is	O
very	O
large	O
and	O
positive	O
expc	O
will	O
overflow	O
again	O
resulting	O
in	O
the	O
expression	O
as	O
a	O
whole	O
being	O
undefined	O
both	O
of	O
these	O
difficulties	O
can	O
be	O
resolved	O
by	O
instead	O
evaluating	O
softmaxz	O
where	O
z	O
x	O
maxi	O
xi	O
simple	O
algebra	O
shows	O
that	O
the	O
value	O
of	O
the	O
softmax	O
function	O
is	O
not	O
changed	O
analytically	O
by	O
adding	O
or	O
subtracting	O
a	O
scalar	O
from	O
the	O
input	O
vector	O
subtracting	O
maxi	O
xi	O
results	O
in	O
the	O
largest	O
argument	O
to	O
exp	O
being	O
which	O
rules	O
out	O
the	O
possibility	O
of	O
overflow	O
likewise	O
at	O
least	O
one	O
term	O
in	O
the	O
denominator	O
has	O
a	O
value	O
of	O
which	O
rules	O
out	O
the	O
possibility	O
of	O
underflow	O
in	O
the	O
denominator	O
leading	O
to	O
a	O
division	O
by	O
zero	O
there	O
is	O
still	O
one	O
small	O
problem	O
underflow	O
in	O
the	O
numerator	O
can	O
still	O
cause	O
the	O
expression	O
as	O
a	O
whole	O
to	O
evaluate	O
to	O
zero	O
this	O
means	O
that	O
if	O
we	O
implement	O
log	O
softmaxx	O
by	O
first	O
running	O
the	O
softmax	O
subroutine	O
then	O
passing	O
the	O
result	O
to	O
the	O
log	O
function	O
we	O
could	O
erroneously	O
obtain	O
instead	O
we	O
must	O
implement	O
a	O
separate	O
function	O
that	O
calculates	O
log	O
softmax	O
in	O
a	O
numerically	O
stable	O
way	O
the	O
log	O
softmax	O
function	O
can	O
be	O
stabilized	O
using	O
the	O
same	O
trick	B
as	O
we	O
used	O
to	O
stabilize	O
the	O
function	O
softmax	O
for	O
the	O
most	O
part	O
we	O
do	O
not	O
explicitly	O
detail	O
all	O
of	O
the	O
numerical	O
considerations	O
involved	O
in	O
implementing	O
the	O
various	O
algorithms	O
described	O
in	O
this	O
book	O
developers	O
of	O
low-level	O
libraries	O
should	O
keep	O
numerical	O
issues	O
in	O
mind	O
when	O
implementing	O
deep	O
learning	O
algorithms	O
most	O
readers	O
of	O
this	O
book	O
can	O
simply	O
rely	O
on	O
lowlevel	O
libraries	O
that	O
provide	O
stable	O
implementations	O
in	O
some	O
cases	O
it	O
is	O
possible	O
to	O
implement	O
a	O
new	O
algorithm	O
and	O
have	O
the	O
new	O
implementation	O
automatically	O
chapter	O
numerical	O
computation	O
is	O
an	O
example	B
stabilized	O
theano	O
of	O
a	O
software	O
package	O
that	O
automatically	O
detects	O
and	O
stabilizes	O
many	O
common	O
numerically	O
unstable	O
expressions	O
that	O
arise	O
in	O
the	O
context	O
of	O
deep	O
learning	O
bergstra	O
et	O
al	O
bastien	O
et	O
al	O
poor	O
conditioning	O
conditioning	O
refers	O
to	O
how	O
rapidly	O
a	O
function	O
changes	O
with	O
respect	O
to	O
small	O
changes	O
in	O
its	O
inputs	O
functions	O
that	O
change	O
rapidly	O
when	O
their	O
inputs	O
are	O
perturbed	O
slightly	O
can	O
be	O
problematic	O
for	O
scientific	O
computation	O
because	O
rounding	O
errors	O
in	O
the	O
inputs	O
can	O
result	O
in	O
large	O
changes	O
in	O
the	O
output	O
max	O
ij	O
i	O
j	O
consider	O
the	O
function	O
fx	O
a	O
decomposition	O
its	O
condition	B
number	I
is	O
when	O
a	O
n	O
n	O
r	O
has	O
an	O
eigenvalue	B
this	O
is	O
the	O
ratio	O
of	O
the	O
magnitude	O
of	O
the	O
largest	O
and	O
smallest	O
eigenvalue	B
when	O
this	O
number	O
is	O
large	O
matrix	O
inversion	O
is	O
particularly	O
sensitive	O
to	O
error	O
in	O
the	O
input	O
this	O
sensitivity	O
is	O
an	O
intrinsic	O
property	O
of	O
the	O
matrix	O
itself	O
not	O
the	O
result	O
of	O
rounding	O
error	O
during	O
matrix	O
inversion	O
poorly	O
conditioned	O
matrices	O
amplify	O
pre-existing	O
errors	O
when	O
we	O
multiply	O
by	O
the	O
true	O
matrix	B
inverse	I
in	O
practice	O
the	O
error	O
will	O
be	O
compounded	O
further	O
by	O
numerical	O
errors	O
in	O
the	O
inversion	O
process	O
itself	O
gradient-based	O
optimization	O
most	O
deep	O
learning	O
algorithms	O
involve	O
optimization	O
of	O
some	O
sort	O
optimization	O
refers	O
to	O
the	O
task	O
of	O
either	O
minimizing	O
or	O
maximizing	O
some	O
function	O
fx	O
by	O
altering	O
x	O
we	O
usually	O
phrase	O
most	O
optimization	O
problems	O
in	O
terms	O
of	O
minimizing	O
f	O
maximization	O
may	O
be	O
accomplished	O
via	O
a	O
minimization	O
algorithm	O
by	O
minimizing	O
f	O
the	O
function	O
we	O
want	O
to	O
minimize	O
or	O
maximize	O
is	O
called	O
the	O
objective	B
function	I
or	O
criterion	O
when	O
we	O
are	O
minimizing	O
it	O
we	O
may	O
also	O
call	O
it	O
the	O
cost	O
function	O
loss	O
function	O
or	O
error	O
function	O
in	O
this	O
book	O
we	O
use	O
these	O
terms	O
interchangeably	O
though	O
some	O
machine	B
learning	I
publications	O
assign	O
special	O
meaning	O
to	O
some	O
of	O
these	O
terms	O
we	O
often	O
denote	O
the	O
value	O
that	O
minimizes	O
or	O
maximizes	O
a	O
function	O
with	O
a	O
superscript	O
for	O
example	B
we	O
might	O
say	O
x	O
f	O
x	O
arg	O
min	O
chapter	O
numerical	O
computation	O
global	O
minimum	O
at	O
since	O
f	O
descent	O
halts	O
here	O
gradient	B
x	O
x	O
x	O
for	O
we	O
have	O
so	O
we	O
can	O
decrease	O
moving	O
rightward	O
x	O
f	O
byf	O
x	O
for	O
we	O
have	O
so	O
we	O
can	O
decrease	O
moving	O
leftward	O
x	O
f	O
byf	O
f	O
x	O
x	O
x	O
f	O
x	O
figure	O
an	O
illustration	O
of	O
how	O
the	O
gradient	B
descent	O
algorithm	O
uses	O
the	O
derivatives	O
of	O
a	O
function	O
can	O
be	O
used	O
to	O
follow	O
the	O
function	O
downhill	O
to	O
a	O
minimum	O
we	O
assume	O
the	O
reader	O
is	O
already	O
familiar	O
with	O
calculus	O
but	O
provide	O
a	O
brief	O
review	O
of	O
how	O
calculus	O
concepts	O
relate	O
to	O
optimization	O
here	O
suppose	O
we	O
have	O
a	O
function	O
y	O
f	O
where	O
both	O
x	O
and	O
y	O
are	O
real	O
numbers	O
the	O
derivative	B
of	O
this	O
function	O
is	O
denoted	O
as	O
f	O
gives	O
the	O
slope	O
of	O
f	O
at	O
the	O
point	O
x	O
in	O
other	O
words	O
it	O
specifies	O
how	O
to	O
scale	O
a	O
small	O
change	O
in	O
the	O
input	O
in	O
order	O
to	O
obtain	O
the	O
corresponding	O
change	O
in	O
the	O
output	O
f	O
x	O
or	O
as	O
dy	O
dx	O
the	O
derivative	B
f	O
f	O
x	O
f	O
the	O
derivative	B
is	O
therefore	O
useful	O
for	O
minimizing	O
a	O
function	O
because	O
it	O
tells	O
us	O
how	O
to	O
change	O
x	O
in	O
order	O
to	O
make	O
a	O
small	O
improvement	O
in	O
y	O
for	O
example	B
we	O
know	O
that	O
f	O
is	O
less	O
than	O
f	O
for	O
small	O
enough	O
we	O
can	O
thus	O
reduce	O
f	O
by	O
moving	O
x	O
in	O
small	O
steps	O
with	O
opposite	O
sign	O
of	O
the	O
derivative	B
this	O
technique	O
is	O
called	O
gradient	B
descent	O
for	O
an	O
example	B
of	O
this	O
technique	O
see	O
figure	O
signf	O
when	O
f	O
the	O
derivative	B
provides	O
no	O
information	O
about	O
which	O
direction	O
to	O
move	O
points	O
where	O
f	O
are	O
known	O
as	O
critical	O
points	O
or	O
stationary	O
points	O
a	O
local	O
minimum	O
is	O
a	O
point	O
where	O
f	O
is	O
lower	O
than	O
at	O
all	O
neighboring	O
points	O
so	O
it	O
is	O
no	O
longer	O
possible	O
to	O
decrease	O
fx	O
by	O
making	O
infinitesimal	O
steps	O
a	O
local	O
maximum	O
is	O
a	O
point	O
where	O
f	O
is	O
higher	O
than	O
at	O
all	O
neighboring	O
points	O
chapter	O
numerical	O
computation	O
minimum	O
maximum	O
saddle	O
point	O
figure	O
examples	O
of	O
each	O
of	O
the	O
three	O
types	O
of	O
critical	O
points	O
in	O
a	O
critical	O
point	O
is	O
a	O
point	O
with	O
zero	O
slope	O
such	O
a	O
point	O
can	O
either	O
be	O
a	O
local	O
minimum	O
which	O
is	O
lower	O
than	O
the	O
neighboring	O
points	O
a	O
local	O
maximum	O
which	O
is	O
higher	O
than	O
the	O
neighboring	O
points	O
or	O
a	O
saddle	O
point	O
which	O
has	O
neighbors	O
that	O
are	O
both	O
higher	O
and	O
lower	O
than	O
the	O
point	O
itself	O
so	O
it	O
is	O
not	O
possible	O
to	O
increase	O
f	O
by	O
making	O
infinitesimal	O
steps	O
some	O
critical	O
points	O
are	O
neither	O
maxima	O
nor	O
minima	O
these	O
are	O
known	O
as	O
saddle	B
points	I
see	O
figure	O
for	O
examples	O
of	O
each	O
type	O
of	O
critical	O
point	O
a	O
point	O
that	O
obtains	O
the	O
absolute	O
lowest	O
value	O
of	O
f	O
is	O
a	O
global	O
minimum	O
it	O
is	O
possible	O
for	O
there	O
to	O
be	O
only	O
one	O
global	O
minimum	O
or	O
multiple	O
global	O
minima	O
of	O
the	O
function	O
it	O
is	O
also	O
possible	O
for	O
there	O
to	O
be	O
local	O
minima	O
that	O
are	O
not	O
globally	O
optimal	O
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
optimize	O
functions	O
that	O
may	O
have	O
many	O
local	O
minima	O
that	O
are	O
not	O
optimal	O
and	O
many	O
saddle	B
points	I
surrounded	O
by	O
very	O
flat	O
regions	O
all	O
of	O
this	O
makes	O
optimization	O
very	O
difficult	O
especially	O
when	O
the	O
input	O
to	O
the	O
function	O
is	O
multidimensional	O
we	O
therefore	O
usually	O
settle	O
for	O
finding	O
a	O
value	O
of	O
f	O
that	O
is	O
very	O
low	O
but	O
not	O
necessarily	O
minimal	O
in	O
any	O
formal	O
sense	O
see	O
figure	O
for	O
an	O
example	B
we	O
often	O
minimize	O
functions	O
that	O
have	O
multiple	O
inputs	O
f	O
r	O
n	O
r	O
for	O
the	O
concept	O
of	O
minimization	O
to	O
make	O
sense	O
there	O
must	O
still	O
be	O
only	O
one	O
output	O
for	O
functions	O
with	O
multiple	O
inputs	O
we	O
must	O
make	O
use	O
of	O
the	O
concept	O
of	O
partial	O
derivatives	O
the	O
partial	B
derivative	B
fx	O
measures	O
how	O
f	O
changes	O
as	O
only	O
the	O
xi	O
variable	O
xi	O
increases	O
at	O
point	O
x	O
the	O
gradient	B
generalizes	O
the	O
notion	O
of	O
derivative	B
to	O
the	O
case	O
where	O
the	O
derivative	B
is	O
with	O
respect	O
to	O
a	O
vector	O
the	O
gradient	B
of	O
f	O
is	O
the	O
xf	O
element	O
i	O
of	O
the	O
vector	O
containing	O
all	O
of	O
the	O
partial	O
derivatives	O
denoted	O
gradient	B
is	O
the	O
partial	B
derivative	B
of	O
f	O
with	O
respect	O
to	O
xi	O
in	O
multiple	O
dimensions	O
chapter	O
numerical	O
computation	O
this	O
local	O
minimum	O
performs	O
nearly	O
as	O
well	O
as	O
the	O
global	O
one	O
so	O
it	O
is	O
an	O
acceptable	O
halting	O
point	O
ideally	O
we	O
would	O
like	O
x	O
to	O
arrive	O
at	O
the	O
global	O
f	O
minimum	O
but	O
this	O
might	O
not	O
be	O
possible	O
this	O
local	O
minimum	O
performs	O
poorly	O
and	O
should	O
be	O
avoided	O
x	O
figure	O
optimization	O
algorithms	O
may	O
fail	O
to	O
find	O
a	O
global	O
minimum	O
when	O
there	O
are	O
multiple	O
local	O
minima	O
or	O
plateaus	O
present	O
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
generally	O
accept	O
such	O
solutions	O
even	O
though	O
they	O
are	O
not	O
truly	O
minimal	O
so	O
long	O
as	O
they	O
correspond	O
to	O
significantly	O
low	O
values	O
of	O
the	O
cost	O
function	O
critical	O
points	O
are	O
points	O
where	O
every	O
element	O
of	O
the	O
gradient	B
is	O
equal	O
to	O
zero	O
the	O
directional	B
derivative	B
in	O
direction	O
unit	B
vector	I
is	O
the	O
slope	O
of	O
the	O
function	O
f	O
in	O
direction	O
u	O
in	O
other	O
words	O
the	O
directional	B
derivative	B
is	O
the	O
derivative	B
of	O
the	O
function	O
f	O
u	O
with	O
respect	O
to	O
evaluated	O
at	O
using	O
the	O
chain	O
rule	O
we	O
can	O
see	O
that	O
u	O
evaluates	O
to	O
u	O
when	O
x	O
f	O
u	O
f	O
to	O
minimize	O
f	O
we	O
would	O
like	O
to	O
find	O
the	O
direction	O
in	O
which	O
f	O
decreases	O
the	O
fastest	O
we	O
can	O
do	O
this	O
using	O
the	O
directional	B
derivative	B
u	O
min	O
u	O
u	O
u	O
min	O
xf	O
cos	O
x	O
f	O
u	O
u	O
where	O
is	O
the	O
angle	O
between	O
u	O
and	O
the	O
gradient	B
substituting	O
in	O
u	O
and	O
ignoring	O
factors	O
that	O
do	O
not	O
depend	O
on	O
u	O
this	O
simplifies	O
to	O
minu	O
cos	O
this	O
is	O
minimized	O
when	O
u	O
points	O
in	O
the	O
opposite	O
direction	O
as	O
the	O
gradient	B
in	O
other	O
words	O
the	O
gradient	B
points	O
directly	O
uphill	O
and	O
the	O
negative	O
gradient	B
points	O
directly	O
downhill	O
we	O
can	O
decrease	O
f	O
by	O
moving	O
in	O
the	O
direction	O
of	O
the	O
negative	O
gradient	B
this	O
is	O
known	O
as	O
the	O
method	O
of	O
steepest	O
descent	O
gradient	B
descent	O
or	O
steepest	O
descent	O
proposes	O
a	O
new	O
point	O
x	O
x	O
x	O
f	O
chapter	O
numerical	O
computation	O
where	O
is	O
the	O
learning	B
rate	I
a	O
positive	O
scalar	O
determining	O
the	O
size	O
of	O
the	O
step	O
we	O
can	O
choose	O
in	O
several	O
different	O
ways	O
a	O
popular	O
approach	O
is	O
to	O
set	O
to	O
a	O
small	O
constant	O
sometimes	O
we	O
can	O
solve	O
for	O
the	O
step	O
size	O
that	O
makes	O
the	O
directional	O
xf	O
for	O
several	O
derivative	B
vanish	O
another	O
approach	O
is	O
to	O
evaluate	O
f	O
values	O
of	O
and	O
choose	O
the	O
one	O
that	O
results	O
in	O
the	O
smallest	O
objective	B
function	I
value	O
this	O
last	O
strategy	O
is	O
called	O
a	O
line	O
search	O
steepest	O
descent	O
converges	O
when	O
every	O
element	O
of	O
the	O
gradient	B
is	O
zero	O
in	O
practice	O
very	O
close	O
to	O
zero	O
in	O
some	O
cases	O
we	O
may	O
be	O
able	O
to	O
avoid	O
running	O
this	O
iterative	O
algorithm	O
and	O
just	O
jump	O
directly	O
to	O
the	O
critical	O
point	O
by	O
solving	O
the	O
equation	O
x	O
f	O
for	O
x	O
although	O
gradient	B
descent	O
is	O
limited	O
to	O
optimization	O
in	O
continuous	O
spaces	O
the	O
general	O
concept	O
of	O
repeatedly	O
making	O
a	O
small	O
move	O
is	O
approximately	O
the	O
best	O
small	O
move	O
towards	O
better	O
configurations	O
can	O
be	O
generalized	O
to	O
discrete	O
spaces	O
ascending	O
an	O
objective	B
function	I
of	O
discrete	O
parameters	O
is	O
called	O
hill	B
climbing	I
russel	O
and	O
norvig	O
beyond	O
the	O
gradient	B
jacobian	O
and	O
hessian	B
matrices	O
sometimes	O
we	O
need	O
to	O
find	O
all	O
of	O
the	O
partial	O
derivatives	O
of	O
a	O
function	O
whose	O
input	O
and	O
output	O
are	O
both	O
vectors	O
the	O
matrix	O
containing	O
all	O
such	O
partial	O
derivatives	O
is	O
n	O
known	O
as	O
a	O
jacobian	O
matrix	O
specifically	O
if	O
we	O
have	O
a	O
function	O
f	O
r	O
then	O
the	O
jacobian	O
matrix	O
j	O
is	O
defined	O
such	O
that	O
n	O
m	O
m	O
r	O
f	O
i	O
of	O
f	O
r	O
j	O
ij	O
xj	O
xi	O
xj	O
f	O
by	O
f	O
we	O
are	O
also	O
sometimes	O
interested	O
in	O
a	O
derivative	B
of	O
a	O
derivative	B
this	O
is	O
known	O
r	O
the	O
derivative	B
f	O
n	O
as	O
a	O
second	B
derivative	B
for	O
example	B
for	O
a	O
function	O
f	O
r	O
with	O
respect	O
to	O
xi	O
of	O
the	O
derivative	B
of	O
f	O
with	O
respect	O
to	O
xj	O
is	O
denoted	O
as	O
in	O
a	O
single	O
dimension	O
we	O
can	O
denote	O
the	O
second	B
derivative	B
tells	O
us	O
how	O
the	O
first	O
derivative	B
will	O
change	O
as	O
we	O
vary	O
the	O
input	O
this	O
is	O
important	O
because	O
it	O
tells	O
us	O
whether	O
a	O
gradient	B
step	O
will	O
cause	O
as	O
much	O
of	O
an	O
improvement	O
as	O
we	O
would	O
expect	O
based	O
on	O
the	O
gradient	B
alone	O
we	O
can	O
think	O
of	O
the	O
second	B
derivative	B
as	O
measuring	O
curvature	O
suppose	O
we	O
have	O
a	O
quadratic	O
function	O
functions	O
that	O
arise	O
in	O
practice	O
are	O
not	O
quadratic	O
but	O
can	O
be	O
approximated	O
well	O
as	O
quadratic	O
at	O
least	O
locally	O
if	O
such	O
a	O
function	O
has	O
a	O
second	B
derivative	B
of	O
zero	O
then	O
there	O
is	O
no	O
curvature	O
it	O
is	O
a	O
perfectly	O
flat	O
line	O
and	O
its	O
value	O
can	O
be	O
predicted	O
using	O
only	O
the	O
gradient	B
if	O
the	O
gradient	B
is	O
along	O
the	O
negative	O
gradient	B
and	O
the	O
cost	O
function	O
will	O
decrease	O
by	O
if	O
the	O
second	B
derivative	B
is	O
negative	O
the	O
function	O
curves	O
downward	O
so	O
the	O
cost	O
function	O
will	O
actually	O
decrease	O
by	O
more	O
than	O
finally	O
if	O
the	O
second	B
derivative	B
is	O
positive	O
the	O
function	O
curves	O
upward	O
so	O
the	O
cost	O
function	O
can	O
decrease	O
by	O
less	O
than	O
see	O
then	O
we	O
can	O
make	O
a	O
step	O
of	O
size	O
chapter	O
numerical	O
computation	O
negative	O
curvature	O
no	O
curvature	O
positive	O
curvature	O
x	O
f	O
x	O
f	O
x	O
f	O
x	O
x	O
x	O
figure	O
the	O
second	B
derivative	B
determines	O
the	O
curvature	O
of	O
a	O
function	O
here	O
we	O
show	O
quadratic	O
functions	O
with	O
various	O
curvature	O
the	O
dashed	O
line	O
indicates	O
the	O
value	O
of	O
the	O
cost	O
function	O
we	O
would	O
expect	O
based	O
on	O
the	O
gradient	B
information	O
alone	O
as	O
we	O
make	O
a	O
gradient	B
step	O
downhill	O
in	O
the	O
case	O
of	O
negative	O
curvature	O
the	O
cost	O
function	O
actually	O
decreases	O
faster	O
than	O
the	O
gradient	B
predicts	O
in	O
the	O
case	O
of	O
no	O
curvature	O
the	O
gradient	B
predicts	O
the	O
decrease	O
correctly	O
in	O
the	O
case	O
of	O
positive	O
curvature	O
the	O
function	O
decreases	O
slower	O
than	O
expected	O
and	O
eventually	O
begins	O
to	O
increase	O
so	O
steps	O
that	O
are	O
too	O
large	O
can	O
actually	O
increase	O
the	O
function	O
inadvertently	O
figure	O
the	O
value	O
of	O
the	O
cost	O
function	O
predicted	O
by	O
the	O
gradient	B
and	O
the	O
true	O
value	O
to	O
see	O
how	O
different	O
forms	O
of	O
curvature	O
affect	O
the	O
relationship	O
between	O
when	O
our	O
function	O
has	O
multiple	O
input	O
dimensions	O
there	O
are	O
many	O
second	O
derivatives	O
these	O
derivatives	O
can	O
be	O
collected	O
together	O
into	O
a	O
matrix	O
called	O
the	O
hessian	B
matrix	O
the	O
hessian	B
matrix	O
is	O
defined	O
such	O
that	O
h	O
x	O
h	O
x	O
xi	O
xj	O
f	O
equivalently	O
the	O
hessian	B
is	O
the	O
jacobian	O
of	O
the	O
gradient	B
anywhere	O
that	O
the	O
second	O
partial	O
derivatives	O
are	O
continuous	O
the	O
differential	O
operators	O
are	O
commutative	O
i	O
e	O
their	O
order	O
can	O
be	O
swapped	O
xi	O
xj	O
f	O
x	O
j	O
xi	O
f	O
this	O
implies	O
that	O
hij	O
h	O
ji	O
so	O
the	O
hessian	B
matrix	O
is	O
symmetric	O
at	O
such	O
points	O
most	O
of	O
the	O
functions	O
we	O
encounter	O
in	O
the	O
context	O
of	O
deep	O
learning	O
have	O
a	O
symmetric	O
hessian	B
almost	B
everywhere	I
because	O
the	O
hessian	B
matrix	O
is	O
real	O
and	O
symmetric	O
we	O
can	O
decompose	O
it	O
into	O
a	O
set	O
of	O
real	O
eigenvalues	O
and	O
an	O
orthogonal	O
basis	O
of	O
chapter	O
numerical	O
computation	O
eigenvectors	O
the	O
second	B
derivative	B
in	O
a	O
specific	O
direction	O
represented	O
by	O
a	O
unit	B
vector	I
d	O
is	O
given	O
by	O
d	O
hd	O
when	O
d	O
is	O
an	O
eigenvector	B
of	O
h	O
the	O
second	B
derivative	B
in	O
that	O
direction	O
is	O
given	O
by	O
the	O
corresponding	O
eigenvalue	B
for	O
other	O
directions	O
of	O
d	O
the	O
directional	O
second	B
derivative	B
is	O
a	O
weighted	O
average	O
of	O
all	O
of	O
the	O
eigenvalues	O
with	O
weights	B
between	O
and	O
and	O
eigenvectors	O
that	O
have	O
smaller	O
angle	O
with	O
d	O
receiving	O
more	O
weight	O
the	O
maximum	O
eigenvalue	B
determines	O
the	O
maximum	O
second	B
derivative	B
and	O
the	O
minimum	O
eigenvalue	B
determines	O
the	O
minimum	O
second	B
derivative	B
the	O
second	B
derivative	B
tells	O
us	O
how	O
well	O
we	O
can	O
expect	O
a	O
gradient	B
descent	O
step	O
to	O
perform	O
we	O
can	O
make	O
a	O
second-order	O
taylor	O
series	O
approximation	O
to	O
the	O
function	O
around	O
the	O
current	O
point	O
f	O
x	O
f	O
f	O
g	O
x	O
x	O
h	O
x	O
x	O
where	O
g	O
is	O
the	O
gradient	B
and	O
h	O
is	O
the	O
hessian	B
at	O
if	O
we	O
use	O
a	O
learning	B
rate	I
of	O
then	O
the	O
new	O
point	O
x	O
will	O
be	O
given	O
by	O
g	O
substituting	O
this	O
into	O
our	O
approximation	O
we	O
obtain	O
f	O
f	O
g	O
hg	O
g	O
g	O
g	O
there	O
are	O
three	O
terms	O
here	O
the	O
original	O
value	O
of	O
the	O
function	O
the	O
expected	O
improvement	O
due	O
to	O
the	O
slope	O
of	O
the	O
function	O
and	O
the	O
correction	O
we	O
must	O
apply	O
to	O
account	O
for	O
the	O
curvature	O
of	O
the	O
function	O
when	O
this	O
last	O
term	O
is	O
too	O
large	O
the	O
hg	O
is	O
zero	O
or	O
negative	O
gradient	B
descent	O
step	O
can	O
actually	O
move	O
uphill	O
when	O
g	O
the	O
taylor	O
series	O
approximation	O
predicts	O
that	O
increasing	O
forever	O
will	O
decrease	O
f	O
forever	O
in	O
practice	O
the	O
taylor	O
series	O
is	O
unlikely	O
to	O
remain	O
accurate	O
for	O
large	O
so	O
one	O
must	O
resort	O
to	O
more	O
heuristic	O
choices	O
of	O
in	O
this	O
case	O
when	O
g	O
hg	O
is	O
positive	O
solving	O
for	O
the	O
optimal	O
step	O
size	O
that	O
decreases	O
the	O
taylor	O
series	O
approximation	O
of	O
the	O
function	O
the	O
most	O
yields	O
g	O
g	O
g	O
hg	O
in	O
the	O
worst	O
case	O
when	O
g	O
aligns	O
with	O
the	O
eigenvector	B
of	O
h	O
corresponding	O
to	O
the	O
maximal	O
eigenvalue	B
max	O
then	O
this	O
optimal	O
step	O
size	O
is	O
given	O
by	O
to	O
the	O
extent	O
that	O
the	O
function	O
we	O
minimize	O
can	O
be	O
approximated	O
well	O
by	O
a	O
quadratic	O
function	O
the	O
eigenvalues	O
of	O
the	O
hessian	B
thus	O
determine	O
the	O
scale	O
of	O
the	O
learning	B
rate	I
max	O
the	O
second	B
derivative	B
can	O
be	O
used	O
to	O
determine	O
whether	O
a	O
critical	O
point	O
is	O
a	O
local	O
maximum	O
a	O
local	O
minimum	O
or	O
saddle	O
point	O
recall	B
that	O
on	O
a	O
critical	O
point	O
f	O
increases	O
as	O
we	O
move	O
to	O
the	O
right	O
and	O
decreases	O
as	O
we	O
move	O
to	O
the	O
left	O
this	O
means	O
the	O
first	O
derivative	B
f	O
when	O
the	O
second	B
derivative	B
f	O
chapter	O
numerical	O
computation	O
and	O
f	O
for	O
small	O
enough	O
in	O
other	O
words	O
as	O
we	O
move	O
f	O
right	O
the	O
slope	O
begins	O
to	O
point	O
uphill	O
to	O
the	O
right	O
and	O
as	O
we	O
move	O
left	O
the	O
slope	O
we	O
can	O
begins	O
to	O
point	O
uphill	O
to	O
the	O
left	O
thus	O
when	O
f	O
conclude	O
that	O
x	O
is	O
a	O
local	O
minimum	O
similarly	O
when	O
f	O
we	O
can	O
conclude	O
that	O
x	O
is	O
a	O
local	O
maximum	O
this	O
is	O
known	O
as	O
the	O
second	B
derivative	B
test	I
unfortunately	O
when	O
f	O
the	O
test	O
is	O
inconclusive	O
in	O
this	O
case	O
x	O
may	O
be	O
a	O
saddle	O
point	O
or	O
a	O
part	O
of	O
a	O
flat	O
region	O
and	O
f	O
and	O
f	O
in	O
multiple	O
dimensions	O
we	O
need	O
to	O
examine	O
all	O
of	O
the	O
second	O
derivatives	O
of	O
the	O
function	O
using	O
the	O
eigendecomposition	B
of	O
the	O
hessian	B
matrix	O
we	O
can	O
generalize	O
the	O
second	B
derivative	B
test	I
to	O
multiple	O
dimensions	O
at	O
a	O
critical	O
point	O
where	O
xf	O
we	O
can	O
examine	O
the	O
eigenvalues	O
of	O
the	O
hessian	B
to	O
determine	O
whether	O
the	O
critical	O
point	O
is	O
a	O
local	O
maximum	O
local	O
minimum	O
or	O
saddle	O
point	O
when	O
the	O
hessian	B
is	O
positive	B
definite	I
its	O
eigenvalues	O
are	O
positive	O
the	O
point	O
is	O
a	O
local	O
minimum	O
this	O
can	O
be	O
seen	O
by	O
observing	O
that	O
the	O
directional	O
second	B
derivative	B
in	O
any	O
direction	O
must	O
be	O
positive	O
and	O
making	O
reference	O
to	O
the	O
univariate	O
second	B
derivative	B
test	I
likewise	O
when	O
the	O
hessian	B
is	O
negative	B
definite	I
its	O
eigenvalues	O
are	O
negative	O
the	O
point	O
is	O
a	O
local	O
maximum	O
in	O
multiple	O
dimensions	O
it	O
is	O
actually	O
possible	O
to	O
find	O
positive	O
evidence	O
of	O
saddle	B
points	I
in	O
some	O
cases	O
when	O
at	O
least	O
one	O
eigenvalue	B
is	O
positive	O
and	O
at	O
least	O
one	O
eigenvalue	B
is	O
negative	O
we	O
know	O
that	O
x	O
is	O
a	O
local	O
maximum	O
on	O
one	O
cross	O
section	O
of	O
f	O
but	O
a	O
local	O
minimum	O
on	O
another	O
cross	O
section	O
see	O
figure	O
for	O
an	O
example	B
finally	O
the	O
multidimensional	O
second	B
derivative	B
test	I
can	O
be	O
inconclusive	O
just	O
like	O
the	O
univariate	O
version	O
the	O
test	O
is	O
inconclusive	O
whenever	O
all	O
of	O
the	O
non-zero	O
eigenvalues	O
have	O
the	O
same	O
sign	O
but	O
at	O
least	O
one	O
eigenvalue	B
is	O
zero	O
this	O
is	O
because	O
the	O
univariate	O
second	B
derivative	B
test	I
is	O
inconclusive	O
in	O
the	O
cross	O
section	O
corresponding	O
to	O
the	O
zero	O
eigenvalue	B
in	O
multiple	O
dimensions	O
there	O
is	O
a	O
different	O
second	B
derivative	B
for	O
each	O
direction	O
at	O
a	O
single	O
point	O
the	O
condition	B
number	I
of	O
the	O
hessian	B
at	O
this	O
point	O
measures	O
how	O
much	O
the	O
second	O
derivatives	O
differ	O
from	O
each	O
other	O
when	O
the	O
hessian	B
has	O
a	O
poor	O
condition	B
number	I
gradient	B
descent	O
performs	O
poorly	O
this	O
is	O
because	O
in	O
one	O
direction	O
the	O
derivative	B
increases	O
rapidly	O
while	O
in	O
another	O
direction	O
it	O
increases	O
slowly	O
gradient	B
descent	O
is	O
unaware	O
of	O
this	O
change	O
in	O
the	O
derivative	B
so	O
it	O
does	O
not	O
know	O
that	O
it	O
needs	O
to	O
explore	O
preferentially	O
in	O
the	O
direction	O
where	O
the	O
derivative	B
remains	O
negative	O
for	O
longer	O
it	O
also	O
makes	O
it	O
difficult	O
to	O
choose	O
a	O
good	O
step	O
size	O
the	O
step	O
size	O
must	O
be	O
small	O
enough	O
to	O
avoid	O
overshooting	O
the	O
minimum	O
and	O
going	O
uphill	O
in	O
directions	O
with	O
strong	O
positive	O
curvature	O
this	O
usually	O
means	O
that	O
the	O
step	O
size	O
is	O
too	O
small	O
to	O
make	O
significant	O
progress	O
in	O
other	O
directions	O
with	O
less	O
curvature	O
see	O
figure	O
for	O
an	O
example	B
this	O
issue	O
can	O
be	O
resolved	O
by	O
using	O
information	O
from	O
the	O
hessian	B
matrix	O
to	O
guide	O
chapter	O
numerical	O
computation	O
figure	O
a	O
saddle	O
point	O
containing	O
both	O
positive	O
and	O
negative	O
curvature	O
the	O
function	O
in	O
this	O
example	B
is	O
f	O
along	O
the	O
axis	O
corresponding	O
to	O
the	O
function	O
curves	O
upward	O
this	O
axis	O
is	O
an	O
eigenvector	B
of	O
the	O
hessian	B
and	O
has	O
a	O
positive	O
eigenvalue	B
along	O
the	O
axis	O
corresponding	O
to	O
the	O
function	O
curves	O
downward	O
this	O
direction	O
is	O
an	O
eigenvector	B
of	O
the	O
hessian	B
with	O
negative	O
eigenvalue	B
the	O
name	O
saddle	O
point	O
derives	O
from	O
the	O
saddle-like	O
shape	O
of	O
this	O
function	O
this	O
is	O
the	O
quintessential	O
example	B
of	O
a	O
function	O
with	O
a	O
saddle	O
point	O
in	O
more	O
than	O
one	O
dimension	O
it	O
is	O
not	O
necessary	O
to	O
have	O
an	O
eigenvalue	B
of	O
in	O
order	O
to	O
get	O
a	O
saddle	O
point	O
it	O
is	O
only	O
necessary	O
to	O
have	O
both	O
positive	O
and	O
negative	O
eigenvalues	O
we	O
can	O
think	O
of	O
a	O
saddle	O
point	O
with	O
both	O
signs	O
of	O
eigenvalues	O
as	O
being	O
a	O
local	O
maximum	O
within	O
one	O
cross	O
section	O
and	O
a	O
local	O
minimum	O
within	O
another	O
cross	O
section	O
chapter	O
numerical	O
computation	O
x	O
and	O
the	O
least	O
curvature	O
is	O
in	O
the	O
direction	O
figure	O
gradient	B
descent	O
fails	O
to	O
exploit	O
the	O
curvature	O
information	O
contained	O
in	O
the	O
hessian	B
matrix	O
here	O
we	O
use	O
gradient	B
descent	O
to	O
minimize	O
a	O
quadratic	O
function	O
f	O
x	O
whose	O
hessian	B
matrix	O
has	O
condition	B
number	I
this	O
means	O
that	O
the	O
direction	O
of	O
most	O
curvature	O
has	O
five	O
times	O
more	O
curvature	O
than	O
the	O
direction	O
of	O
least	O
curvature	O
in	O
this	O
case	O
the	O
most	O
curvature	O
is	O
in	O
the	O
direction	O
the	O
red	O
lines	O
indicate	O
the	O
path	O
followed	O
by	O
gradient	B
descent	O
this	O
very	O
elongated	O
quadratic	O
function	O
resembles	O
a	O
long	O
canyon	O
gradient	B
descent	O
wastes	O
time	O
repeatedly	O
descending	O
canyon	O
walls	O
because	O
they	O
are	O
the	O
steepest	O
feature	B
because	O
the	O
step	O
size	O
is	O
somewhat	O
too	O
large	O
it	O
has	O
a	O
tendency	O
to	O
overshoot	O
the	O
bottom	O
of	O
the	O
function	O
and	O
thus	O
needs	O
to	O
descend	O
the	O
opposite	O
canyon	O
wall	O
on	O
the	O
next	O
iteration	O
the	O
large	O
positive	O
eigenvalue	B
of	O
the	O
hessian	B
corresponding	O
to	O
the	O
eigenvector	B
pointed	O
in	O
this	O
direction	O
indicates	O
that	O
this	O
directional	B
derivative	B
is	O
rapidly	O
increasing	O
so	O
an	O
optimization	O
algorithm	O
based	O
on	O
the	O
hessian	B
could	O
predict	O
that	O
the	O
steepest	O
direction	O
is	O
not	O
actually	O
a	O
promising	O
search	O
direction	O
in	O
this	O
context	O
chapter	O
numerical	O
computation	O
the	O
search	O
the	O
simplest	O
method	O
for	O
doing	O
so	O
is	O
known	O
as	O
newton	O
s	O
method	O
newton	O
s	O
method	O
is	O
based	O
on	O
using	O
a	O
second-order	O
taylor	O
series	O
expansion	O
to	O
approximate	O
x	O
f	O
f	O
f	O
near	O
some	O
point	O
x	O
xf	O
x	O
x	O
h	O
x	O
if	O
we	O
then	O
solve	O
for	O
the	O
critical	O
point	O
of	O
this	O
function	O
we	O
obtain	O
x	O
h	O
x	O
xf	O
when	O
f	O
is	O
a	O
positive	B
definite	I
quadratic	O
function	O
newton	O
s	O
method	O
consists	O
of	O
applying	O
equation	O
once	O
to	O
jump	O
to	O
the	O
minimum	O
of	O
the	O
function	O
directly	O
when	O
f	O
is	O
not	O
truly	O
quadratic	O
but	O
can	O
be	O
locally	O
approximated	O
as	O
a	O
positive	B
definite	I
quadratic	O
newton	O
s	O
method	O
consists	O
of	O
applying	O
equation	O
multiple	O
times	O
iteratively	O
updating	O
the	O
approximation	O
and	O
jumping	O
to	O
the	O
minimum	O
of	O
the	O
approximation	O
can	O
reach	O
the	O
critical	O
point	O
much	O
faster	O
than	O
gradient	B
descent	O
would	O
this	O
is	O
a	O
useful	O
property	O
near	O
a	O
local	O
minimum	O
but	O
it	O
can	O
be	O
a	O
harmful	O
property	O
near	O
a	O
saddle	O
point	O
as	O
discussed	O
in	O
section	O
newton	O
s	O
method	O
is	O
only	O
appropriate	O
when	O
the	O
nearby	O
critical	O
point	O
is	O
a	O
minimum	O
the	O
eigenvalues	O
of	O
the	O
hessian	B
are	O
positive	O
whereas	O
gradient	B
descent	O
is	O
not	O
attracted	O
to	O
saddle	B
points	I
unless	O
the	O
gradient	B
points	O
toward	O
them	O
optimization	O
algorithms	O
that	O
use	O
only	O
the	O
gradient	B
such	O
as	O
gradient	B
descent	O
are	O
called	O
first-order	O
optimization	O
algorithms	O
optimization	O
algorithms	O
that	O
also	O
use	O
the	O
hessian	B
matrix	O
such	O
as	O
newton	O
s	O
method	O
are	O
called	O
second-order	O
optimization	O
algorithms	O
and	O
wright	O
the	O
optimization	O
algorithms	O
employed	O
in	O
most	O
contexts	O
in	O
this	O
book	O
are	O
applicable	O
to	O
a	O
wide	O
variety	O
of	O
functions	O
but	O
come	O
with	O
almost	O
no	O
guarantees	O
deep	O
learning	O
algorithms	O
tend	O
to	O
lack	O
guarantees	O
because	O
the	O
family	O
of	O
functions	O
used	O
in	O
deep	O
learning	O
is	O
quite	O
complicated	O
in	O
many	O
other	O
fields	O
the	O
dominant	O
approach	O
to	O
optimization	O
is	O
to	O
design	O
optimization	O
algorithms	O
for	O
a	O
limited	O
family	O
of	O
functions	O
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
sometimes	O
gain	O
some	O
guarantees	O
by	O
restricting	O
ourselves	O
to	O
functions	O
that	O
are	O
either	O
lipschitz	B
continuous	I
or	O
have	O
lipschitz	B
continuous	I
derivatives	O
a	O
lipschitz	B
continuous	I
function	O
is	O
a	O
function	O
f	O
whose	O
rate	O
of	O
change	O
is	O
bounded	O
by	O
a	O
lipschitz	B
constant	I
l	O
x	O
y	O
f	O
l	O
x	O
y	O
f	O
this	O
property	O
is	O
useful	O
because	O
it	O
allows	O
us	O
to	O
quantify	O
our	O
assumption	O
that	O
a	O
small	O
change	O
in	O
the	O
input	O
made	O
by	O
an	O
algorithm	O
such	O
as	O
gradient	B
descent	O
will	O
have	O
chapter	O
numerical	O
computation	O
a	O
small	O
change	O
in	O
the	O
output	O
lipschitz	O
continuity	O
is	O
also	O
a	O
fairly	O
weak	O
constraint	O
and	O
many	O
optimization	O
problems	O
in	O
deep	O
learning	O
can	O
be	O
made	O
lipschitz	B
continuous	I
with	O
relatively	O
minor	O
modifications	O
perhaps	O
the	O
most	O
successful	O
field	O
of	O
specialized	O
optimization	O
is	O
convex	B
optimization	I
convex	B
optimization	I
algorithms	O
are	O
able	O
to	O
provide	O
many	O
more	O
guarantees	O
by	O
making	O
stronger	O
restrictions	O
convex	B
optimization	I
algorithms	O
are	O
applicable	O
only	O
to	O
convex	O
functions	O
functions	O
for	O
which	O
the	O
hessian	B
is	O
positive	O
semidefinite	O
everywhere	O
such	O
functions	O
are	O
well-behaved	O
because	O
they	O
lack	O
saddle	B
points	I
and	O
all	O
of	O
their	O
local	O
minima	O
are	O
necessarily	O
global	O
minima	O
however	O
most	O
problems	O
in	O
deep	O
learning	O
are	O
difficult	O
to	O
express	O
in	O
terms	O
of	O
convex	B
optimization	I
convex	B
optimization	I
is	O
used	O
only	O
as	O
a	O
subroutine	O
of	O
some	O
deep	O
learning	O
algorithms	O
ideas	O
from	O
the	O
analysis	O
of	O
convex	B
optimization	I
algorithms	O
can	O
be	O
useful	O
for	O
proving	O
the	O
convergence	O
of	O
deep	O
learning	O
algorithms	O
however	O
in	O
general	O
the	O
importance	O
of	O
convex	B
optimization	I
is	O
greatly	O
diminished	O
in	O
the	O
context	O
of	O
deep	O
learning	O
for	O
more	O
information	O
about	O
convex	B
optimization	I
see	O
boyd	O
and	O
vandenberghe	O
or	O
rockafellar	O
constrained	O
optimization	O
sometimes	O
we	O
wish	O
not	O
only	O
to	O
maximize	O
or	O
minimize	O
a	O
function	O
fx	O
over	O
all	O
possible	O
values	O
of	O
x	O
instead	O
we	O
may	O
wish	O
to	O
find	O
the	O
maximal	O
or	O
minimal	O
value	O
of	O
f	O
for	O
values	O
of	O
x	O
in	O
some	O
set	O
s	O
this	O
is	O
known	O
as	O
constrained	O
optimization	O
points	O
x	O
that	O
lie	O
within	O
the	O
set	O
s	O
are	O
called	O
feasible	O
points	O
in	O
constrained	O
optimization	O
terminology	O
we	O
often	O
wish	O
to	O
find	O
a	O
solution	O
that	O
is	O
small	O
in	O
some	O
sense	O
a	O
common	O
approach	O
in	O
such	O
situations	O
is	O
to	O
impose	O
a	O
norm	O
constraint	O
such	O
as	O
x	O
one	O
simple	O
approach	O
to	O
constrained	O
optimization	O
is	O
simply	O
to	O
modify	O
gradient	B
descent	O
taking	O
the	O
constraint	O
into	O
account	O
if	O
we	O
use	O
a	O
small	O
constant	O
step	O
size	O
we	O
can	O
make	O
gradient	B
descent	O
steps	O
then	O
project	O
the	O
result	O
back	O
into	O
s	O
if	O
we	O
use	O
a	O
line	O
search	O
we	O
can	O
search	O
only	O
over	O
step	O
sizes	O
that	O
yield	O
new	O
x	O
points	O
that	O
are	O
feasible	O
or	O
we	O
can	O
project	O
each	O
point	O
on	O
the	O
line	O
back	O
into	O
the	O
constraint	O
region	O
when	O
possible	O
this	O
method	O
can	O
be	O
made	O
more	O
efficient	O
by	O
projecting	O
the	O
gradient	B
into	O
the	O
tangent	O
space	O
of	O
the	O
feasible	O
region	O
before	O
taking	O
the	O
step	O
or	O
beginning	O
the	O
line	O
search	O
rosen	O
a	O
more	O
sophisticated	O
approach	O
is	O
to	O
design	O
a	O
different	O
unconstrained	O
optimization	O
problem	O
whose	O
solution	O
can	O
be	O
converted	O
into	O
a	O
solution	O
to	O
the	O
original	O
constrained	O
optimization	O
problem	O
for	O
example	B
if	O
we	O
want	O
to	O
minimize	O
fx	O
for	O
chapter	O
numerical	O
computation	O
r	O
sin	O
with	O
x	O
constrained	O
to	O
have	O
exactly	O
unit	B
norm	I
we	O
can	O
instead	O
minimize	O
x	O
g	O
f	O
as	O
the	O
solution	O
to	O
the	O
original	O
problem	O
this	O
approach	O
requires	O
creativity	O
the	O
transformation	O
between	O
optimization	O
problems	O
must	O
be	O
designed	O
specifically	O
for	O
each	O
case	O
we	O
encounter	O
with	O
respect	O
to	O
then	O
return	O
sin	O
the	O
karush	O
kuhn	O
tucker	O
provides	O
a	O
very	O
general	O
solution	O
to	O
constrained	O
optimization	O
with	O
the	O
kkt	O
approach	O
we	O
introduce	O
a	O
new	O
function	O
called	O
the	O
generalized	B
lagrangian	I
or	O
generalized	O
lagrange	O
function	O
to	O
define	O
the	O
lagrangian	O
we	O
first	O
need	O
to	O
describe	O
s	O
in	O
terms	O
of	O
equations	O
and	O
inequalities	O
we	O
want	O
a	O
description	O
of	O
s	O
in	O
terms	O
of	O
m	O
functions	O
g	O
and	O
n	O
functions	O
h	O
the	O
equations	O
involving	O
g	O
are	O
called	O
the	O
equality	O
constraints	O
and	O
the	O
inequalities	O
involving	O
h	O
are	O
called	O
j	O
h	O
inequality	O
constraints	O
i	O
g	O
and	O
x	O
so	O
that	O
s	O
we	O
introduce	O
new	O
variables	O
i	O
and	O
j	O
for	O
each	O
constraint	O
these	O
are	O
called	O
the	O
kkt	O
multipliers	O
the	O
generalized	B
lagrangian	I
is	O
then	O
defined	O
as	O
l	O
f	O
i	O
g	O
j	O
h	O
i	O
j	O
we	O
can	O
now	O
solve	O
a	O
constrained	O
minimization	O
problem	O
using	O
unconstrained	O
optimization	O
of	O
the	O
generalized	B
lagrangian	I
observe	O
that	O
so	O
long	O
as	O
at	O
least	O
one	O
feasible	O
point	O
exists	O
and	O
is	O
not	O
permitted	O
to	O
have	O
value	O
then	O
f	O
min	O
x	O
max	O
max	O
l	O
has	O
the	O
same	O
optimal	O
objective	B
function	I
value	O
and	O
set	O
of	O
optimal	O
points	O
asx	O
this	O
follows	O
because	O
any	O
time	O
the	O
constraints	O
are	O
satisfied	O
f	O
min	O
x	O
s	O
max	O
max	O
l	O
f	O
while	O
any	O
time	O
a	O
constraint	O
is	O
violated	O
max	O
max	O
l	O
kkt	O
approach	O
generalizes	O
the	O
method	O
of	O
lagrange	O
multipliers	O
which	O
allows	O
equality	O
constraints	O
but	O
not	O
inequality	O
constraints	O
chapter	O
numerical	O
computation	O
these	O
properties	O
guarantee	O
that	O
no	O
infeasible	O
point	O
can	O
be	O
optimal	O
and	O
that	O
the	O
optimum	O
within	O
the	O
feasible	O
points	O
is	O
unchanged	O
to	O
perform	O
constrained	O
maximization	O
we	O
can	O
construct	O
the	O
generalized	O
la	O
grange	O
function	O
of	O
which	O
leads	O
to	O
this	O
optimization	O
problem	O
f	O
f	O
min	O
max	O
x	O
max	O
i	O
ig	O
jh	O
j	O
we	O
may	O
also	O
convert	O
this	O
to	O
a	O
problem	O
with	O
maximization	O
in	O
the	O
outer	O
loop	B
max	O
x	O
min	O
min	O
f	O
ig	O
jh	O
i	O
j	O
the	O
sign	O
of	O
the	O
term	O
for	O
the	O
equality	O
constraints	O
does	O
not	O
matter	O
we	O
may	O
define	O
it	O
with	O
addition	O
or	O
subtraction	O
as	O
we	O
wish	O
because	O
the	O
optimization	O
is	O
free	O
to	O
choose	O
any	O
sign	O
for	O
each	O
i	O
the	O
inequality	O
constraints	O
are	O
particularly	O
interesting	O
we	O
say	O
that	O
a	O
constraint	O
h	O
is	O
active	O
if	O
h	O
if	O
a	O
constraint	O
is	O
not	O
active	O
then	O
the	O
solution	O
to	O
the	O
problem	O
found	O
using	O
that	O
constraint	O
would	O
remain	O
at	O
least	O
a	O
local	O
solution	O
if	O
that	O
constraint	O
were	O
removed	O
it	O
is	O
possible	O
that	O
an	O
inactive	O
constraint	O
excludes	O
other	O
solutions	O
for	O
example	B
a	O
convex	O
problem	O
with	O
an	O
entire	O
region	O
of	O
globally	O
optimal	O
points	O
wide	O
flat	O
region	O
of	O
equal	O
cost	O
could	O
have	O
a	O
subset	O
of	O
this	O
region	O
eliminated	O
by	O
constraints	O
or	O
a	O
non-convex	O
problem	O
could	O
have	O
better	O
local	O
stationary	O
points	O
excluded	O
by	O
a	O
constraint	O
that	O
is	O
inactive	O
at	O
convergence	O
however	O
the	O
point	O
found	O
at	O
convergence	O
remains	O
a	O
stationary	O
point	O
whether	O
or	O
not	O
the	O
inactive	O
constraints	O
are	O
included	O
because	O
an	O
inactive	O
h	O
has	O
negative	O
value	O
then	O
the	O
solution	O
to	O
minx	O
max	O
max	O
will	O
have	O
i	O
we	O
can	O
thus	O
lx	O
in	O
other	O
words	O
for	O
all	O
i	O
we	O
know	O
observe	O
that	O
at	O
the	O
solution	O
h	O
that	O
at	O
least	O
one	O
of	O
the	O
constraints	O
i	O
must	O
be	O
active	O
at	O
the	O
solution	O
to	O
gain	O
some	O
intuition	O
for	O
this	O
idea	O
we	O
can	O
say	O
that	O
either	O
the	O
solution	O
is	O
on	O
the	O
boundary	O
imposed	O
by	O
the	O
inequality	O
and	O
we	O
must	O
use	O
its	O
kkt	O
multiplier	O
to	O
influence	O
the	O
solution	O
to	O
x	O
or	O
the	O
inequality	O
has	O
no	O
influence	O
on	O
the	O
solution	O
and	O
we	O
represent	O
this	O
by	O
zeroing	O
out	O
its	O
kkt	O
multiplier	O
and	O
h	O
a	O
simple	O
set	O
of	O
properties	O
describe	O
the	O
optimal	O
points	O
of	O
constrained	O
optimization	O
problems	O
these	O
properties	O
are	O
called	O
the	O
karush-kuhn-tucker	O
conditions	O
they	O
are	O
necessary	O
conditions	O
but	O
not	O
always	O
sufficient	O
conditions	O
for	O
a	O
point	O
to	O
be	O
optimal	O
the	O
conditions	O
are	O
karush	O
kuhn	O
and	O
tucker	O
the	O
gradient	B
of	O
the	O
generalized	B
lagrangian	I
is	O
zero	O
all	O
constraints	O
on	O
both	O
x	O
and	O
the	O
kkt	O
multipliers	O
are	O
satisfied	O
chapter	O
numerical	O
computation	O
the	O
inequality	O
constraints	O
exhibit	O
complementary	O
slackness	O
h	O
for	O
more	O
information	O
about	O
the	O
kkt	O
approach	O
see	O
nocedal	O
and	O
wright	O
example	B
linear	O
least	O
squares	O
suppose	O
we	O
want	O
to	O
find	O
the	O
value	O
of	O
x	O
f	O
that	O
minimizes	O
ax	O
b	O
there	O
are	O
specialized	O
linear	O
algebra	O
algorithms	O
that	O
can	O
solve	O
this	O
problem	O
efficiently	O
however	O
we	O
can	O
also	O
explore	O
how	O
to	O
solve	O
it	O
using	O
gradient-based	O
optimization	O
as	O
a	O
simple	O
example	B
of	O
how	O
these	O
techniques	O
work	O
first	O
we	O
need	O
to	O
obtain	O
the	O
gradient	B
ax	O
b	O
x	O
a	O
x	O
f	O
a	O
ax	O
a	O
b	O
we	O
can	O
then	O
follow	O
this	O
gradient	B
downhill	O
taking	O
small	O
steps	O
see	O
algorithm	O
for	O
details	O
algorithm	O
an	O
algorithm	O
to	O
minimize	O
fx	O
using	O
gradient	B
descent	O
starting	O
from	O
an	O
arbitrary	O
value	O
of	O
with	O
respect	O
to	O
x	O
ax	O
b	O
set	O
the	O
step	O
size	O
and	O
tolerance	O
to	O
small	O
positive	O
numbers	O
while	O
do	O
a	O
b	O
ax	O
a	O
ax	O
a	O
a	O
b	O
x	O
x	O
end	O
while	O
one	O
can	O
also	O
solve	O
this	O
problem	O
using	O
newton	O
s	O
method	O
in	O
this	O
case	O
because	O
the	O
true	O
function	O
is	O
quadratic	O
the	O
quadratic	O
approximation	O
employed	O
by	O
newton	O
s	O
method	O
is	O
exact	O
and	O
the	O
algorithm	O
converges	O
to	O
the	O
global	O
minimum	O
in	O
a	O
single	O
step	O
now	O
suppose	O
we	O
wish	O
to	O
minimize	O
the	O
same	O
function	O
but	O
subject	O
to	O
the	O
constraint	O
x	O
x	O
to	O
do	O
so	O
we	O
introduce	O
the	O
lagrangian	O
l	O
f	O
x	O
x	O
we	O
can	O
now	O
solve	O
the	O
problem	O
min	O
x	O
max	O
l	O
chapter	O
numerical	O
computation	O
the	O
smallest-norm	O
solution	O
to	O
the	O
unconstrained	O
least	O
squares	O
problem	O
may	O
be	O
found	O
using	O
the	O
moore-penrose	O
pseudoinverse	O
x	O
a	O
b	O
if	O
this	O
point	O
is	O
feasible	O
then	O
it	O
is	O
the	O
solution	O
to	O
the	O
constrained	O
problem	O
otherwise	O
we	O
must	O
find	O
a	O
solution	O
where	O
the	O
constraint	O
is	O
active	O
by	O
differentiating	O
the	O
lagrangian	O
with	O
respect	O
to	O
we	O
obtain	O
the	O
equation	O
x	O
a	O
ax	O
a	O
b	O
x	O
this	O
tells	O
us	O
that	O
the	O
solution	O
will	O
take	O
the	O
form	O
x	O
a	O
i	O
a	O
b	O
the	O
magnitude	O
of	O
must	O
be	O
chosen	O
such	O
that	O
the	O
result	O
obeys	O
the	O
constraint	O
we	O
can	O
find	O
this	O
value	O
by	O
performing	O
gradient	B
ascent	O
on	O
to	O
do	O
so	O
observe	O
l	O
x	O
x	O
when	O
the	O
norm	O
of	O
x	O
exceeds	O
this	O
derivative	B
is	O
positive	O
so	O
to	O
follow	O
the	O
derivative	B
uphill	O
and	O
increase	O
the	O
lagrangian	O
with	O
respect	O
to	O
we	O
increase	O
because	O
the	O
coefficient	O
on	O
the	O
x	O
x	O
penalty	O
has	O
increased	O
solving	O
the	O
linear	O
equation	O
for	O
x	O
will	O
now	O
yield	O
a	O
solution	O
with	O
smaller	O
norm	O
the	O
process	O
of	O
solving	O
the	O
linear	O
equation	O
and	O
adjusting	O
continues	O
until	O
x	O
has	O
the	O
correct	O
norm	O
and	O
the	O
derivative	B
on	O
is	O
this	O
concludes	O
the	O
mathematical	O
preliminaries	O
that	O
we	O
use	O
to	O
develop	O
machine	B
learning	I
algorithms	O
we	O
are	O
now	O
ready	O
to	O
build	O
and	O
analyze	O
some	O
full-fledged	O
learning	O
systems	O
chapter	O
machine	B
learning	I
basics	O
deep	O
learning	O
is	O
a	O
specific	O
kind	O
of	O
machine	B
learning	I
in	O
order	O
to	O
understand	O
deep	O
learning	O
well	O
one	O
must	O
have	O
a	O
solid	O
understanding	O
of	O
the	O
basic	O
principles	O
of	O
machine	B
learning	I
this	O
chapter	O
provides	O
a	O
brief	O
course	O
in	O
the	O
most	O
important	O
general	O
principles	O
that	O
will	O
be	O
applied	O
throughout	O
the	O
rest	O
of	O
the	O
book	O
novice	O
readers	O
or	O
those	O
who	O
want	O
a	O
wider	O
perspective	O
are	O
encouraged	O
to	O
consider	O
machine	B
learning	I
textbooks	O
with	O
a	O
more	O
comprehensive	O
coverage	B
of	O
the	O
fundamentals	O
such	O
as	O
murphy	O
if	O
you	O
are	O
already	O
familiar	O
with	O
machine	B
learning	I
basics	O
feel	O
free	O
to	O
skip	O
ahead	O
to	O
section	O
that	O
section	O
covers	O
some	O
perspectives	O
on	O
traditional	O
machine	B
learning	I
techniques	O
that	O
have	O
strongly	O
influenced	O
the	O
development	O
of	O
deep	O
learning	O
algorithms	O
bishop	O
or	O
we	O
begin	O
with	O
a	O
definition	O
of	O
what	O
a	O
learning	O
algorithm	O
is	O
and	O
present	O
an	O
example	B
the	O
linear	O
regression	B
algorithm	O
we	O
then	O
proceed	O
to	O
describe	O
how	O
the	O
challenge	B
of	O
fitting	O
the	O
training	O
data	O
differs	O
from	O
the	O
challenge	B
of	O
finding	O
patterns	O
that	O
generalize	O
to	O
new	O
data	O
most	O
machine	B
learning	I
algorithms	O
have	O
settings	O
called	O
hyperparameters	O
that	O
must	O
be	O
determined	O
external	O
to	O
the	O
learning	O
algorithm	O
itself	O
we	O
discuss	O
how	O
to	O
set	O
these	O
using	O
additional	O
data	O
machine	B
learning	I
is	O
essentially	O
a	O
form	O
of	O
applied	O
statistics	O
with	O
increased	O
emphasis	O
on	O
the	O
use	O
of	O
computers	O
to	O
statistically	O
estimate	O
complicated	O
functions	O
and	O
a	O
decreased	O
emphasis	O
on	O
proving	O
confidence	O
intervals	O
around	O
these	O
functions	O
we	O
therefore	O
present	O
the	O
two	O
central	O
approaches	O
to	O
statistics	O
frequentist	O
estimators	O
and	O
bayesian	O
inference	O
most	O
machine	B
learning	I
algorithms	O
can	O
be	O
divided	O
into	O
the	O
categories	O
of	O
supervised	B
learning	I
and	O
unsupervised	O
learning	O
we	O
describe	O
these	O
categories	O
and	O
give	O
some	O
examples	O
of	O
simple	O
learning	O
algorithms	O
from	O
each	O
category	O
most	O
deep	O
learning	O
algorithms	O
are	O
based	O
on	O
an	O
optimization	O
algorithm	O
called	O
stochastic	O
gradient	B
descent	O
we	O
describe	O
how	O
to	O
combine	O
various	O
algorithm	O
components	O
such	O
as	O
chapter	O
machine	B
learning	I
basics	O
an	O
optimization	O
algorithm	O
a	O
cost	O
function	O
a	O
model	O
and	O
a	O
dataset	B
to	O
build	O
a	O
machine	B
learning	I
algorithm	O
finally	O
in	O
section	O
we	O
describe	O
some	O
of	O
the	O
factors	O
that	O
have	O
limited	O
the	O
ability	O
of	O
traditional	O
machine	B
learning	I
to	O
generalize	O
these	O
challenges	O
have	O
motivated	O
the	O
development	O
of	O
deep	O
learning	O
algorithms	O
that	O
overcome	O
these	O
obstacles	O
learning	O
algorithms	O
a	O
machine	B
learning	I
algorithm	O
is	O
an	O
algorithm	O
that	O
is	O
able	O
to	O
learn	O
from	O
data	O
but	O
what	O
do	O
we	O
mean	O
by	O
learning	O
mitchell	O
provides	O
the	O
definition	O
a	O
computer	O
program	O
is	O
said	O
to	O
learn	O
from	O
experience	O
e	O
with	O
respect	O
to	O
some	O
class	O
of	O
tasks	O
t	O
and	O
performance	O
measure	O
p	O
if	O
its	O
performance	O
at	O
tasks	O
in	O
t	O
as	O
measured	O
by	O
p	O
improves	O
with	O
experience	O
e	O
one	O
can	O
imagine	O
a	O
very	O
wide	O
variety	O
of	O
experiences	O
e	O
tasks	O
t	O
and	O
performance	O
measures	O
p	O
and	O
we	O
do	O
not	O
make	O
any	O
attempt	O
in	O
this	O
book	O
to	O
provide	O
a	O
formal	O
definition	O
of	O
what	O
may	O
be	O
used	O
for	O
each	O
of	O
these	O
entities	O
instead	O
the	O
following	O
sections	O
provide	O
intuitive	O
descriptions	O
and	O
examples	O
of	O
the	O
different	O
kinds	O
of	O
tasks	O
performance	O
measures	O
and	O
experiences	O
that	O
can	O
be	O
used	O
to	O
construct	O
machine	B
learning	I
algorithms	O
the	O
task	O
t	O
machine	B
learning	I
allows	O
us	O
to	O
tackle	O
tasks	O
that	O
are	O
too	O
difficult	O
to	O
solve	O
with	O
fixed	O
programs	O
written	O
and	O
designed	O
by	O
human	O
beings	O
from	O
a	O
scientific	O
and	O
philosophical	O
point	O
of	O
view	O
machine	B
learning	I
is	O
interesting	O
because	O
developing	O
our	O
understanding	O
of	O
machine	B
learning	I
entails	O
developing	O
our	O
understanding	O
of	O
the	O
principles	O
that	O
underlie	O
intelligence	O
in	O
this	O
relatively	O
formal	O
definition	O
of	O
the	O
word	O
task	O
the	O
process	O
of	O
learning	O
itself	O
is	O
not	O
the	O
task	O
learning	O
is	O
our	O
means	O
of	O
attaining	O
the	O
ability	O
to	O
perform	O
the	O
task	O
for	O
example	B
if	O
we	O
want	O
a	O
robot	O
to	O
be	O
able	O
to	O
walk	O
then	O
walking	O
is	O
the	O
task	O
we	O
could	O
program	O
the	O
robot	O
to	O
learn	O
to	O
walk	O
or	O
we	O
could	O
attempt	O
to	O
directly	O
write	O
a	O
program	O
that	O
specifies	O
how	O
to	O
walk	O
manually	O
machine	B
learning	I
tasks	O
are	O
usually	O
described	O
in	O
terms	O
of	O
how	O
the	O
machine	B
learning	I
system	O
should	O
process	O
an	O
example	B
an	O
example	B
is	O
a	O
collection	O
of	O
features	O
that	O
have	O
been	O
quantitatively	O
measured	O
from	O
some	O
object	O
or	O
event	O
that	O
we	O
want	O
the	O
machine	B
learning	I
system	O
to	O
process	O
we	O
typically	O
represent	O
an	O
example	B
as	O
a	O
n	O
where	O
each	O
entry	O
xi	O
of	O
the	O
vector	O
is	O
another	O
feature	B
for	O
example	B
vector	O
x	O
the	O
features	O
of	O
an	O
image	O
are	O
usually	O
the	O
values	O
of	O
the	O
pixels	O
in	O
the	O
image	O
r	O
chapter	O
machine	B
learning	I
basics	O
many	O
kinds	O
of	O
tasks	O
can	O
be	O
solved	O
with	O
machine	B
learning	I
some	O
of	O
the	O
most	O
common	O
machine	B
learning	I
tasks	O
include	O
the	O
following	O
k	O
classification	B
in	O
this	O
type	O
of	O
task	O
the	O
computer	O
program	O
is	O
asked	O
to	O
specify	O
which	O
of	O
k	O
categories	O
some	O
input	O
belongs	O
to	O
to	O
solve	O
this	O
task	O
the	O
learning	O
n	O
algorithm	O
is	O
usually	O
asked	O
to	O
produce	O
a	O
function	O
f	O
r	O
when	O
y	O
f	O
the	O
model	O
assigns	O
an	O
input	O
described	O
by	O
vector	O
x	O
to	O
a	O
category	O
identified	O
by	O
numeric	O
code	O
y	O
there	O
are	O
other	O
variants	O
of	O
the	O
classification	B
task	O
for	O
example	B
where	O
f	O
outputs	O
a	O
probability	B
distribution	I
over	O
classes	O
an	O
example	B
of	O
a	O
classification	B
task	O
is	O
object	B
recognition	I
where	O
the	O
input	O
is	O
an	O
image	O
described	O
as	O
a	O
set	O
of	O
pixel	O
brightness	O
values	O
and	O
the	O
output	O
is	O
a	O
numeric	O
code	O
identifying	O
the	O
object	O
in	O
the	O
image	O
for	O
example	B
the	O
willow	O
garage	O
robot	O
is	O
able	O
to	O
act	O
as	O
a	O
waiter	O
that	O
can	O
recognize	O
different	O
kinds	O
of	O
drinks	O
and	O
deliver	O
them	O
to	O
people	O
on	O
command	O
modern	O
object	B
recognition	I
is	O
best	O
accomplished	O
with	O
fellow	O
deep	O
learning	O
object	B
recognition	I
is	O
the	O
same	O
basic	O
technology	O
that	O
allows	O
computers	O
to	O
recognize	O
faces	O
which	O
can	O
be	O
used	O
to	O
automatically	O
tag	O
people	O
in	O
photo	O
collections	O
and	O
allow	O
computers	O
to	O
interact	O
more	O
naturally	O
with	O
their	O
users	O
krizhevsky	O
et	O
al	O
ioffe	O
and	O
szegedy	O
et	O
al	O
et	O
al	O
set	O
single	O
classification	B
with	O
missing	B
inputs	I
classification	B
becomes	O
more	O
challenging	O
if	O
the	O
computer	O
program	O
is	O
not	O
guaranteed	O
that	O
every	O
measurement	O
in	O
its	O
input	O
vector	O
will	O
always	O
be	O
provided	O
in	O
order	O
to	O
solve	O
the	O
classification	B
task	O
the	O
learning	O
algorithm	O
only	O
has	O
to	O
define	O
a	O
function	O
mapping	O
from	O
a	O
vector	O
input	O
to	O
a	O
categorical	O
output	O
when	O
some	O
of	O
the	O
inputs	O
may	O
be	O
missing	O
rather	O
than	O
providing	O
a	O
single	O
classification	B
function	O
the	O
learning	O
algorithm	O
must	O
learn	O
a	O
of	O
functions	O
each	O
function	O
corresponds	O
to	O
classifying	O
x	O
with	O
a	O
different	O
subset	O
of	O
its	O
inputs	O
missing	O
this	O
kind	O
of	O
situation	O
arises	O
frequently	O
in	O
medical	O
diagnosis	O
because	O
many	O
kinds	O
of	O
medical	O
tests	O
are	O
expensive	O
or	O
invasive	O
one	O
way	O
to	O
efficiently	O
define	O
such	O
a	O
large	O
set	O
of	O
functions	O
is	O
to	O
learn	O
a	O
probability	B
distribution	I
over	O
all	O
of	O
the	O
relevant	O
variables	O
then	O
solve	O
the	O
classification	B
task	O
by	O
marginalizing	O
out	O
the	O
missing	O
variables	O
with	O
n	O
input	O
variables	O
we	O
can	O
now	O
obtain	O
all	O
different	O
classification	B
functions	O
needed	O
for	O
each	O
possible	O
set	O
of	O
missing	B
inputs	I
but	O
we	O
only	O
need	O
to	O
learn	O
a	O
single	O
function	O
describing	O
the	O
joint	B
probability	B
distribution	I
see	O
goodfellow	O
for	O
an	O
example	B
of	O
a	O
deep	O
probabilistic	O
model	O
applied	O
to	O
such	O
a	O
task	O
in	O
this	O
way	O
many	O
of	O
the	O
other	O
tasks	O
described	O
in	O
this	O
section	O
can	O
also	O
be	O
generalized	O
to	O
work	O
with	O
missing	B
inputs	I
classification	B
with	O
missing	B
inputs	I
is	O
just	O
one	O
example	B
of	O
what	O
machine	B
learning	I
can	O
do	O
et	O
al	O
chapter	O
machine	B
learning	I
basics	O
regression	B
in	O
this	O
type	O
of	O
task	O
the	O
computer	O
program	O
is	O
asked	O
to	O
predict	O
a	O
numerical	O
value	O
given	O
some	O
input	O
to	O
solve	O
this	O
task	O
the	O
learning	O
algorithm	O
n	O
is	O
asked	O
to	O
output	O
a	O
function	O
f	O
r	O
r	O
this	O
type	O
of	O
task	O
is	O
similar	O
to	O
classification	B
except	O
that	O
the	O
format	O
of	O
output	O
is	O
different	O
an	O
example	B
of	O
a	O
regression	B
task	O
is	O
the	O
prediction	O
of	O
the	O
expected	O
claim	O
amount	O
that	O
an	O
insured	O
person	O
will	O
make	O
to	O
set	O
insurance	O
premiums	O
or	O
the	O
prediction	O
of	O
future	O
prices	O
of	O
securities	O
these	O
kinds	O
of	O
predictions	O
are	O
also	O
used	O
for	O
algorithmic	O
trading	O
transcription	B
in	O
this	O
type	O
of	O
task	O
the	O
machine	B
learning	I
system	O
is	O
asked	O
to	O
observe	O
a	O
relatively	O
unstructured	O
representation	O
of	O
some	O
kind	O
of	O
data	O
and	O
transcribe	O
it	O
into	O
discrete	O
textual	O
form	O
for	O
example	B
in	O
optical	O
character	O
recognition	O
the	O
computer	O
program	O
is	O
shown	O
a	O
photograph	O
containing	O
an	O
image	O
of	O
text	O
and	O
is	O
asked	O
to	O
return	O
this	O
text	O
in	O
the	O
form	O
of	O
a	O
sequence	O
of	O
characters	O
in	O
ascii	O
or	O
unicode	O
format	O
google	O
street	O
view	O
uses	O
deep	O
learning	O
to	O
process	O
address	O
numbers	O
in	O
this	O
way	O
goodfellow	O
et	O
al	O
another	O
example	B
is	O
speech	O
recognition	O
where	O
the	O
computer	O
program	O
is	O
provided	O
an	O
audio	O
waveform	O
and	O
emits	O
a	O
sequence	O
of	O
characters	O
or	O
word	O
id	O
codes	O
describing	O
the	O
words	O
that	O
were	O
spoken	O
in	O
the	O
audio	O
recording	O
deep	O
learning	O
is	O
a	O
crucial	O
component	O
of	O
modern	O
speech	O
recognition	O
systems	O
used	O
at	O
major	O
companies	O
including	O
microsoft	O
ibm	O
and	O
google	O
hinton	O
et	O
al	O
machine	B
translation	I
in	O
a	O
machine	B
translation	I
task	O
the	O
input	O
already	O
consists	O
of	O
a	O
sequence	O
of	O
symbols	O
in	O
some	O
language	O
and	O
the	O
computer	O
program	O
must	O
convert	O
this	O
into	O
a	O
sequence	O
of	O
symbols	O
in	O
another	O
language	O
this	O
is	O
commonly	O
applied	O
to	O
natural	O
languages	O
such	O
as	O
translating	O
from	O
english	O
to	O
french	O
deep	O
learning	O
has	O
recently	O
begun	O
to	O
have	O
an	O
important	O
impact	O
on	O
this	O
kind	O
of	O
task	O
bahdanau	O
et	O
al	O
et	O
al	O
structured	O
output	O
structured	O
output	O
tasks	O
involve	O
any	O
task	O
where	O
the	O
output	O
is	O
a	O
vector	O
other	O
data	O
structure	O
containing	O
multiple	O
values	O
with	O
important	O
relationships	O
between	O
the	O
different	O
elements	O
this	O
is	O
a	O
broad	O
category	O
and	O
subsumes	O
the	O
transcription	B
and	O
translation	O
tasks	O
described	O
above	O
but	O
also	O
many	O
other	O
tasks	O
one	O
example	B
is	O
parsing	O
mapping	O
a	O
natural	O
language	O
sentence	O
into	O
a	O
tree	O
that	O
describes	O
its	O
grammatical	O
structure	O
and	O
tagging	O
nodes	O
of	O
the	O
trees	O
as	O
being	O
verbs	O
nouns	O
or	O
adverbs	O
and	O
so	O
on	O
see	O
for	O
an	O
example	B
of	O
deep	O
learning	O
applied	O
to	O
a	O
parsing	O
task	O
another	O
example	B
is	O
pixel-wise	O
segmentation	O
of	O
images	O
where	O
the	O
computer	O
program	O
assigns	O
every	O
pixel	O
in	O
an	O
image	O
to	O
a	O
specific	O
category	O
for	O
collobert	O
chapter	O
machine	B
learning	I
basics	O
example	B
deep	O
learning	O
can	O
be	O
used	O
to	O
annotate	O
the	O
locations	O
of	O
roads	O
in	O
aerial	O
photographs	O
and	O
hinton	O
the	O
output	O
need	O
not	O
have	O
its	O
form	O
mirror	O
the	O
structure	O
of	O
the	O
input	O
as	O
closely	O
as	O
in	O
these	O
annotation-style	O
tasks	O
for	O
example	B
in	O
image	O
captioning	O
the	O
computer	O
program	O
observes	O
an	O
image	O
and	O
outputs	O
a	O
natural	O
language	O
sentence	O
describing	O
the	O
image	O
et	O
al	O
these	O
tasks	O
are	O
karpathy	O
and	O
li	O
fang	O
called	O
structured	O
output	O
tasks	O
because	O
the	O
program	O
must	O
output	O
several	O
values	O
that	O
are	O
all	O
tightly	O
inter-related	O
for	O
example	B
the	O
words	O
produced	O
by	O
an	O
image	O
captioning	O
program	O
must	O
form	O
a	O
valid	O
sentence	O
donahue	O
b	O
mao	O
vinyals	O
et	O
al	O
et	O
al	O
xu	O
et	O
al	O
et	O
al	O
et	O
al	O
anomaly	O
detection	O
in	O
this	O
type	O
of	O
task	O
the	O
computer	O
program	O
sifts	O
through	O
a	O
set	O
of	O
events	O
or	O
objects	O
and	O
flags	O
some	O
of	O
them	O
as	O
being	O
unusual	O
or	O
atypical	O
an	O
example	B
of	O
an	O
anomaly	O
detection	O
task	O
is	O
credit	O
card	O
fraud	O
detection	O
by	O
modeling	O
your	O
purchasing	O
habits	O
a	O
credit	O
card	O
company	O
can	O
detect	O
misuse	O
of	O
your	O
cards	O
if	O
a	O
thief	O
steals	O
your	O
credit	O
card	O
or	O
credit	O
card	O
information	O
the	O
thief	O
s	O
purchases	O
will	O
often	O
come	O
from	O
a	O
different	O
probability	B
distribution	I
over	O
purchase	O
types	O
than	O
your	O
own	O
the	O
credit	O
card	O
company	O
can	O
prevent	O
fraud	O
by	O
placing	O
a	O
hold	O
on	O
an	O
account	O
as	O
soon	O
as	O
that	O
card	O
has	O
been	O
used	O
for	O
an	O
uncharacteristic	O
purchase	O
see	O
for	O
a	O
survey	O
of	O
anomaly	O
detection	O
methods	O
chandola	O
et	O
al	O
synthesis	O
and	O
sampling	O
in	O
this	O
type	O
of	O
task	O
the	O
machine	B
learning	I
algorithm	O
is	O
asked	O
to	O
generate	O
new	O
examples	O
that	O
are	O
similar	O
to	O
those	O
in	O
the	O
training	O
data	O
synthesis	O
and	O
sampling	O
via	O
machine	B
learning	I
can	O
be	O
useful	O
for	O
media	O
applications	O
where	O
it	O
can	O
be	O
expensive	O
or	O
boring	O
for	O
an	O
artist	O
to	O
generate	O
large	O
volumes	O
of	O
content	O
by	O
hand	O
for	O
example	B
video	O
games	O
can	O
automatically	O
generate	O
textures	O
for	O
large	O
objects	O
or	O
landscapes	O
rather	O
than	O
requiring	O
an	O
artist	O
to	O
manually	O
label	O
each	O
pixel	O
in	O
some	O
cases	O
we	O
want	O
the	O
sampling	O
or	O
synthesis	O
procedure	O
to	O
generate	O
some	O
specific	O
kind	O
of	O
output	O
given	O
the	O
input	O
for	O
example	B
in	O
a	O
speech	O
synthesis	O
task	O
we	O
provide	O
a	O
written	O
sentence	O
and	O
ask	O
the	O
program	O
to	O
emit	O
an	O
audio	O
waveform	O
containing	O
a	O
spoken	O
version	O
of	O
that	O
sentence	O
this	O
is	O
a	O
kind	O
of	O
structured	O
output	O
task	O
but	O
with	O
the	O
added	O
qualification	O
that	O
there	O
is	O
no	O
single	O
correct	O
output	O
for	O
each	O
input	O
and	O
we	O
explicitly	O
desire	O
a	O
large	O
amount	O
of	O
variation	O
in	O
the	O
output	O
in	O
order	O
for	O
the	O
output	O
to	O
seem	O
more	O
natural	O
and	O
realistic	O
luo	O
et	O
al	O
imputation	O
of	O
missing	O
values	O
in	O
this	O
type	O
of	O
task	O
the	O
machine	B
learning	I
n	O
but	O
with	O
some	O
entries	O
xi	O
of	O
x	O
algorithm	O
is	O
given	O
a	O
new	O
example	B
x	O
missing	O
the	O
algorithm	O
must	O
provide	O
a	O
prediction	O
of	O
the	O
values	O
of	O
the	O
missing	O
entries	O
r	O
chapter	O
machine	B
learning	I
basics	O
denoising	O
in	O
this	O
type	O
of	O
task	O
the	O
machine	B
learning	I
algorithm	O
is	O
given	O
in	O
n	O
obtained	O
by	O
an	O
unknown	O
corruption	O
process	O
input	O
a	O
corrupted	O
example	B
x	O
n	O
the	O
learner	O
must	O
predict	O
the	O
clean	O
example	B
from	O
a	O
clean	O
example	B
x	O
x	O
from	O
its	O
corrupted	O
version	O
x	O
or	O
more	O
generally	O
predict	O
the	O
conditional	B
probability	B
distribution	I
px	O
x	O
r	O
r	O
n	O
density	B
estimation	I
or	O
probability	B
mass	I
function	I
estimation	I
in	O
the	O
density	B
estimation	I
problem	O
the	O
machine	B
learning	I
algorithm	O
is	O
asked	O
to	O
learn	O
a	O
function	O
pmodel	O
r	O
r	O
where	O
pmodelx	O
can	O
be	O
interpreted	O
as	O
a	O
probability	B
density	I
function	I
x	O
is	O
continuous	O
or	O
a	O
probability	B
mass	I
function	I
x	O
is	O
discrete	O
on	O
the	O
space	O
that	O
the	O
examples	O
were	O
drawn	O
from	O
to	O
do	O
such	O
a	O
task	O
well	O
will	O
specify	O
exactly	O
what	O
that	O
means	O
when	O
we	O
discuss	O
performance	O
measures	O
p	O
the	O
algorithm	O
needs	O
to	O
learn	O
the	O
structure	O
of	O
the	O
data	O
it	O
has	O
seen	O
it	O
must	O
know	O
where	O
examples	O
cluster	O
tightly	O
and	O
where	O
they	O
are	O
unlikely	O
to	O
occur	O
most	O
of	O
the	O
tasks	O
described	O
above	O
require	O
the	O
learning	O
algorithm	O
to	O
at	O
least	O
implicitly	O
capture	O
the	O
structure	O
of	O
the	O
probability	B
distribution	I
density	B
estimation	I
allows	O
us	O
to	O
explicitly	O
capture	O
that	O
distribution	O
in	O
principle	O
we	O
can	O
then	O
perform	O
computations	O
on	O
that	O
distribution	O
in	O
order	O
to	O
solve	O
the	O
other	O
tasks	O
as	O
well	O
for	O
example	B
if	O
we	O
have	O
performed	O
density	B
estimation	I
to	O
obtain	O
a	O
probability	B
distribution	I
px	O
we	O
can	O
use	O
that	O
distribution	O
to	O
solve	O
the	O
missing	O
value	O
imputation	O
task	O
if	O
a	O
value	O
xi	O
is	O
missing	O
and	O
all	O
of	O
the	O
other	O
values	O
denoted	O
x	O
i	O
are	O
given	O
then	O
we	O
know	O
the	O
distribution	O
over	O
it	O
is	O
given	O
by	O
pxi	O
i	O
in	O
practice	O
density	B
estimation	I
does	O
not	O
always	O
allow	O
us	O
to	O
solve	O
all	O
of	O
these	O
related	O
tasks	O
because	O
in	O
many	O
cases	O
the	O
required	O
operations	O
on	O
p	O
x	O
are	O
computationally	O
intractable	O
x	O
of	O
course	O
many	O
other	O
tasks	O
and	O
types	O
of	O
tasks	O
are	O
possible	O
the	O
types	O
of	O
tasks	O
we	O
list	O
here	O
are	O
intended	O
only	O
to	O
provide	O
examples	O
of	O
what	O
machine	B
learning	I
can	O
do	O
not	O
to	O
define	O
a	O
rigid	O
taxonomy	O
of	O
tasks	O
the	O
performance	O
measure	O
p	O
in	O
order	O
to	O
evaluate	O
the	O
abilities	O
of	O
a	O
machine	B
learning	I
algorithm	O
we	O
must	O
design	O
a	O
quantitative	O
measure	O
of	O
its	O
performance	O
usually	O
this	O
performance	O
measure	O
p	O
is	O
specific	O
to	O
the	O
task	O
being	O
carried	O
out	O
by	O
the	O
system	O
t	O
for	O
tasks	O
such	O
as	O
classification	B
classification	B
with	O
missing	B
inputs	I
and	O
transcription	B
we	O
often	O
measure	O
the	O
accuracy	B
of	O
the	O
model	O
accuracy	B
is	O
just	O
the	O
proportion	O
of	O
examples	O
for	O
which	O
the	O
model	O
produces	O
the	O
correct	O
output	O
we	O
can	O
chapter	O
machine	B
learning	I
basics	O
also	O
obtain	O
equivalent	O
information	O
by	O
measuring	O
the	O
error	O
rate	O
the	O
proportion	O
of	O
examples	O
for	O
which	O
the	O
model	O
produces	O
an	O
incorrect	O
output	O
we	O
often	O
refer	O
to	O
the	O
error	O
rate	O
as	O
the	O
expected	O
loss	O
the	O
loss	O
on	O
a	O
particular	O
example	B
is	O
if	O
it	O
is	O
correctly	O
classified	O
and	O
if	O
it	O
is	O
not	O
for	O
tasks	O
such	O
as	O
density	B
estimation	I
it	O
does	O
not	O
make	O
sense	O
to	O
measure	O
accuracy	B
error	O
rate	O
or	O
any	O
other	O
kind	O
of	O
loss	O
instead	O
we	O
must	O
use	O
a	O
different	O
performance	O
metric	O
that	O
gives	O
the	O
model	O
a	O
continuous-valued	O
score	O
for	O
each	O
example	B
the	O
most	O
common	O
approach	O
is	O
to	O
report	O
the	O
average	O
log-probability	O
the	O
model	O
assigns	O
to	O
some	O
examples	O
usually	O
we	O
are	O
interested	O
in	O
how	O
well	O
the	O
machine	B
learning	I
algorithm	O
performs	O
on	O
data	O
that	O
it	O
has	O
not	O
seen	O
before	O
since	O
this	O
determines	O
how	O
well	O
it	O
will	O
work	O
when	O
deployed	O
in	O
the	O
real	O
world	O
we	O
therefore	O
evaluate	O
these	O
performance	O
measures	O
using	O
a	O
test	B
set	I
of	O
data	O
that	O
is	O
separate	O
from	O
the	O
data	O
used	O
for	O
training	O
the	O
machine	B
learning	I
system	O
the	O
choice	O
of	O
performance	O
measure	O
may	O
seem	O
straightforward	O
and	O
objective	O
but	O
it	O
is	O
often	O
difficult	O
to	O
choose	O
a	O
performance	O
measure	O
that	O
corresponds	O
well	O
to	O
the	O
desired	O
behavior	O
of	O
the	O
system	O
in	O
some	O
cases	O
this	O
is	O
because	O
it	O
is	O
difficult	O
to	O
decide	O
what	O
should	O
be	O
measured	O
for	O
example	B
when	O
performing	O
a	O
transcription	B
task	O
should	O
we	O
measure	O
the	O
accuracy	B
of	O
the	O
system	O
at	O
transcribing	O
entire	O
sequences	O
or	O
should	O
we	O
use	O
a	O
more	O
fine-grained	O
performance	O
measure	O
that	O
gives	O
partial	O
credit	O
for	O
getting	O
some	O
elements	O
of	O
the	O
sequence	O
correct	O
when	O
performing	O
a	O
regression	B
task	O
should	O
we	O
penalize	O
the	O
system	O
more	O
if	O
it	O
frequently	O
makes	O
medium-sized	O
mistakes	O
or	O
if	O
it	O
rarely	O
makes	O
very	O
large	O
mistakes	O
these	O
kinds	O
of	O
design	O
choices	O
depend	O
on	O
the	O
application	O
in	O
other	O
cases	O
we	O
know	O
what	O
quantity	O
we	O
would	O
ideally	O
like	O
to	O
measure	O
but	O
measuring	O
it	O
is	O
impractical	O
for	O
example	B
this	O
arises	O
frequently	O
in	O
the	O
context	O
of	O
density	B
estimation	I
many	O
of	O
the	O
best	O
probabilistic	O
models	O
represent	O
probability	O
distributions	O
only	O
implicitly	O
computing	O
the	O
actual	O
probability	O
value	O
assigned	O
to	O
a	O
specific	O
point	O
in	O
space	O
in	O
many	O
such	O
models	O
is	O
intractable	O
in	O
these	O
cases	O
one	O
must	O
design	O
an	O
alternative	O
criterion	O
that	O
still	O
corresponds	O
to	O
the	O
design	O
objectives	O
or	O
design	O
a	O
good	O
approximation	O
to	O
the	O
desired	O
criterion	O
the	O
experience	O
e	O
machine	B
learning	I
algorithms	O
can	O
be	O
broadly	O
categorized	O
as	O
unsupervised	O
or	O
supervised	O
by	O
what	O
kind	O
of	O
experience	O
they	O
are	O
allowed	O
to	O
have	O
during	O
the	O
learning	O
process	O
most	O
of	O
the	O
learning	O
algorithms	O
in	O
this	O
book	O
can	O
be	O
understood	O
as	O
being	O
allowed	O
to	O
experience	O
an	O
entire	O
dataset	B
a	O
dataset	B
is	O
a	O
collection	O
of	O
many	O
examples	O
as	O
chapter	O
machine	B
learning	I
basics	O
defined	O
in	O
section	O
sometimes	O
we	O
will	O
also	O
call	O
examples	O
data	O
points	O
fisher	O
one	O
of	O
the	O
oldest	O
datasets	O
studied	O
by	O
statisticians	O
and	O
machine	B
learning	I
researchers	O
is	O
the	O
iris	O
dataset	B
it	O
is	O
a	O
collection	O
of	O
measurements	O
of	O
different	O
parts	O
of	O
iris	O
plants	O
each	O
individual	O
plant	O
corresponds	O
to	O
one	O
example	B
the	O
features	O
within	O
each	O
example	B
are	O
the	O
measurements	O
of	O
each	O
of	O
the	O
parts	O
of	O
the	O
plant	O
the	O
sepal	O
length	O
sepal	O
width	O
petal	O
length	O
and	O
petal	O
width	O
the	O
dataset	B
also	O
records	O
which	O
species	O
each	O
plant	O
belonged	O
to	O
three	O
different	O
species	O
are	O
represented	O
in	O
the	O
dataset	B
unsupervised	O
learning	O
algorithms	O
experience	O
a	O
dataset	B
containing	O
many	O
features	O
then	O
learn	O
useful	O
properties	O
of	O
the	O
structure	O
of	O
this	O
dataset	B
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
usually	O
want	O
to	O
learn	O
the	O
entire	O
probability	B
distribution	I
that	O
generated	O
a	O
dataset	B
whether	O
explicitly	O
as	O
in	O
density	B
estimation	I
or	O
implicitly	O
for	O
tasks	O
like	O
synthesis	O
or	O
denoising	O
some	O
other	O
unsupervised	O
learning	O
algorithms	O
perform	O
other	O
roles	O
like	O
clustering	O
which	O
consists	O
of	O
dividing	O
the	O
dataset	B
into	O
clusters	O
of	O
similar	O
examples	O
supervised	B
learning	I
algorithms	O
experience	O
a	O
dataset	B
containing	O
features	O
but	O
each	O
example	B
is	O
also	O
associated	O
with	O
a	O
label	O
or	O
target	O
for	O
example	B
the	O
iris	O
dataset	B
is	O
annotated	O
with	O
the	O
species	O
of	O
each	O
iris	O
plant	O
a	O
supervised	B
learning	I
algorithm	O
can	O
study	O
the	O
iris	O
dataset	B
and	O
learn	O
to	O
classify	O
iris	O
plants	O
into	O
three	O
different	O
species	O
based	O
on	O
their	O
measurements	O
roughly	O
speaking	O
unsupervised	O
learning	O
involves	O
observing	O
several	O
examples	O
of	O
a	O
random	O
vector	O
x	O
and	O
attempting	O
to	O
implicitly	O
or	O
explicitly	O
learn	O
the	O
probability	B
distribution	I
px	O
or	O
some	O
interesting	O
properties	O
of	O
that	O
distribution	O
while	O
supervised	B
learning	I
involves	O
observing	O
several	O
examples	O
of	O
a	O
random	O
vector	O
x	O
and	O
an	O
associated	O
value	O
or	O
vector	O
y	O
and	O
learning	O
to	O
predict	O
y	O
from	O
x	O
usually	O
by	O
estimating	O
py	O
x	O
the	O
term	O
supervised	B
learning	I
originates	O
from	O
the	O
view	O
of	O
the	O
target	O
y	O
being	O
provided	O
by	O
an	O
instructor	O
or	O
teacher	O
who	O
shows	O
the	O
machine	B
learning	I
system	O
what	O
to	O
do	O
in	O
unsupervised	O
learning	O
there	O
is	O
no	O
instructor	O
or	O
teacher	O
and	O
the	O
algorithm	O
must	O
learn	O
to	O
make	O
sense	O
of	O
the	O
data	O
without	O
this	O
guide	O
unsupervised	O
learning	O
and	O
supervised	B
learning	I
are	O
not	O
formally	O
defined	O
terms	O
the	O
lines	O
between	O
them	O
are	O
often	O
blurred	O
many	O
machine	B
learning	I
technologies	O
can	O
be	O
used	O
to	O
perform	O
both	O
tasks	O
for	O
example	B
the	O
chain	B
rule	I
of	I
probability	I
states	O
that	O
for	O
a	O
vector	O
x	O
n	O
the	O
joint	O
distribution	O
can	O
be	O
decomposed	O
as	O
r	O
n	O
p	O
pxi	O
x	O
xi	O
this	O
decomposition	O
means	O
that	O
we	O
can	O
solve	O
the	O
ostensibly	O
unsupervised	O
problem	O
of	O
modeling	O
px	O
by	O
splitting	O
it	O
into	O
n	O
supervised	B
learning	I
problems	O
alternatively	O
we	O
chapter	O
machine	B
learning	I
basics	O
x	O
by	O
using	O
traditional	O
can	O
solve	O
the	O
supervised	B
learning	I
problem	O
of	O
learning	O
py	O
unsupervised	O
learning	O
technologies	O
to	O
learn	O
the	O
joint	O
distribution	O
px	O
y	O
and	O
inferring	O
p	O
y	O
x	O
p	O
y	O
p	O
y	O
y	O
though	O
unsupervised	O
learning	O
and	O
supervised	B
learning	I
are	O
not	O
completely	O
formal	O
or	O
distinct	O
concepts	O
they	O
do	O
help	O
to	O
roughly	O
categorize	O
some	O
of	O
the	O
things	O
we	O
do	O
with	O
machine	B
learning	I
algorithms	O
traditionally	O
people	O
refer	O
to	O
regression	B
classification	B
and	O
structured	O
output	O
problems	O
as	O
supervised	B
learning	I
density	B
estimation	I
in	O
support	O
of	O
other	O
tasks	O
is	O
usually	O
considered	O
unsupervised	O
learning	O
other	O
variants	O
of	O
the	O
learning	O
paradigm	O
are	O
possible	O
for	O
example	B
in	O
semisupervised	O
learning	O
some	O
examples	O
include	O
a	O
supervision	O
target	O
but	O
others	O
do	O
not	O
in	O
multi-instance	O
learning	O
an	O
entire	O
collection	O
of	O
examples	O
is	O
labeled	O
as	O
containing	O
or	O
not	O
containing	O
an	O
example	B
of	O
a	O
class	O
but	O
the	O
individual	O
members	O
of	O
the	O
collection	O
are	O
not	O
labeled	O
for	O
a	O
recent	O
example	B
of	O
multi-instance	O
learning	O
with	O
deep	O
models	O
see	O
kotzias	O
et	O
al	O
some	O
machine	B
learning	I
algorithms	O
do	O
not	O
just	O
experience	O
a	O
fixed	O
dataset	B
for	O
example	B
reinforcement	O
learning	O
algorithms	O
interact	O
with	O
an	O
environment	O
so	O
there	O
is	O
a	O
feedback	O
loop	B
between	O
the	O
learning	O
system	O
and	O
its	O
experiences	O
such	O
algorithms	O
are	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
please	O
see	O
sutton	O
and	O
barto	O
or	O
bertsekas	O
and	O
tsitsiklis	O
for	O
information	O
about	O
reinforcement	O
learning	O
for	O
the	O
deep	O
learning	O
approach	O
to	O
reinforcement	O
learning	O
and	O
mnih	O
et	O
al	O
most	O
machine	B
learning	I
algorithms	O
simply	O
experience	O
a	O
dataset	B
a	O
dataset	B
can	O
be	O
described	O
in	O
many	O
ways	O
in	O
all	O
cases	O
a	O
dataset	B
is	O
a	O
collection	O
of	O
examples	O
which	O
are	O
in	O
turn	O
collections	O
of	O
features	O
one	O
common	O
way	O
of	O
describing	O
a	O
dataset	B
is	O
with	O
a	O
a	O
design	B
matrix	I
is	O
a	O
matrix	O
containing	O
a	O
different	O
example	B
in	O
each	O
row	O
each	O
column	O
of	O
the	O
matrix	O
corresponds	O
to	O
a	O
different	O
feature	B
for	O
instance	O
the	O
iris	O
dataset	B
contains	O
examples	O
with	O
four	O
features	O
for	O
each	O
example	B
this	O
means	O
we	O
can	O
represent	O
the	O
dataset	B
with	O
a	O
design	B
matrix	I
x	O
where	O
is	O
the	O
sepal	O
length	O
of	O
plant	O
i	O
is	O
the	O
sepal	O
width	O
of	O
plant	O
i	O
etc	O
we	O
will	O
describe	O
most	O
of	O
the	O
learning	O
algorithms	O
in	O
this	O
book	O
in	O
terms	O
of	O
how	O
they	O
operate	O
on	O
design	B
matrix	I
datasets	O
design	B
matrix	I
r	O
of	O
course	O
to	O
describe	O
a	O
dataset	B
as	O
a	O
design	B
matrix	I
it	O
must	O
be	O
possible	O
to	O
describe	O
each	O
example	B
as	O
a	O
vector	O
and	O
each	O
of	O
these	O
vectors	O
must	O
be	O
the	O
same	O
size	O
this	O
is	O
not	O
always	O
possible	O
for	O
example	B
if	O
you	O
have	O
a	O
collection	O
of	O
photographs	O
with	O
different	O
widths	O
and	O
heights	O
then	O
different	O
photographs	O
will	O
contain	O
different	O
numbers	O
of	O
pixels	O
so	O
not	O
all	O
of	O
the	O
photographs	O
may	O
be	O
described	O
with	O
the	O
same	O
describe	O
how	O
to	O
handle	O
different	O
length	O
of	O
vector	O
section	O
and	O
chapter	O
chapter	O
machine	B
learning	I
basics	O
types	O
of	O
such	O
heterogeneous	O
data	O
in	O
cases	O
like	O
these	O
rather	O
than	O
describing	O
the	O
dataset	B
as	O
a	O
matrix	O
with	O
m	O
rows	O
we	O
will	O
describe	O
it	O
as	O
a	O
set	O
containing	O
m	O
elements	O
x	O
this	O
notation	O
does	O
not	O
imply	O
that	O
any	O
two	O
example	B
vectors	O
x	O
and	O
x	O
have	O
the	O
same	O
size	O
in	O
the	O
case	O
of	O
supervised	B
learning	I
the	O
example	B
contains	O
a	O
label	O
or	O
target	O
as	O
well	O
as	O
a	O
collection	O
of	O
features	O
for	O
example	B
if	O
we	O
want	O
to	O
use	O
a	O
learning	O
algorithm	O
to	O
perform	O
object	B
recognition	I
from	O
photographs	O
we	O
need	O
to	O
specify	O
which	O
object	O
appears	O
in	O
each	O
of	O
the	O
photos	O
we	O
might	O
do	O
this	O
with	O
a	O
numeric	O
code	O
with	O
signifying	O
a	O
person	O
signifying	O
a	O
car	O
signifying	O
a	O
cat	O
etc	O
often	O
when	O
working	O
with	O
a	O
dataset	B
containing	O
a	O
design	B
matrix	I
of	O
feature	B
observations	O
x	O
we	O
also	O
provide	O
a	O
vector	O
of	O
labels	O
yi	O
providing	O
the	O
label	O
for	O
example	B
with	O
y	O
of	O
course	O
sometimes	O
the	O
label	O
may	O
be	O
more	O
than	O
just	O
a	O
single	O
number	O
for	O
example	B
if	O
we	O
want	O
to	O
train	O
a	O
speech	O
recognition	O
system	O
to	O
transcribe	O
entire	O
sentences	O
then	O
the	O
label	O
for	O
each	O
example	B
sentence	O
is	O
a	O
sequence	O
of	O
words	O
just	O
as	O
there	O
is	O
no	O
formal	O
definition	O
of	O
supervised	O
and	O
unsupervised	O
learning	O
there	O
is	O
no	O
rigid	O
taxonomy	O
of	O
datasets	O
or	O
experiences	O
the	O
structures	O
described	O
here	O
cover	O
most	O
cases	O
but	O
it	O
is	O
always	O
possible	O
to	O
design	O
new	O
ones	O
for	O
new	O
applications	O
example	B
linear	O
regression	B
our	O
definition	O
of	O
a	O
machine	B
learning	I
algorithm	O
as	O
an	O
algorithm	O
that	O
is	O
capable	O
of	O
improving	O
a	O
computer	O
program	O
s	O
performance	O
at	O
some	O
task	O
via	O
experience	O
is	O
somewhat	O
abstract	O
to	O
make	O
this	O
more	O
concrete	O
we	O
present	O
an	O
example	B
of	O
a	O
simple	O
machine	B
learning	I
algorithm	O
linear	O
regression	B
we	O
will	O
return	O
to	O
this	O
example	B
repeatedly	O
as	O
we	O
introduce	O
more	O
machine	B
learning	I
concepts	O
that	O
help	O
to	O
understand	O
its	O
behavior	O
as	O
the	O
name	O
implies	O
linear	O
regression	B
solves	O
a	O
regression	B
problem	O
in	O
other	O
n	O
as	O
input	O
and	O
words	O
the	O
goal	O
is	O
to	O
build	O
a	O
system	O
that	O
can	O
take	O
a	O
vector	O
x	O
predict	O
the	O
value	O
of	O
a	O
scalar	O
y	O
r	O
as	O
its	O
output	O
in	O
the	O
case	O
of	O
linear	O
regression	B
the	O
output	O
is	O
a	O
linear	O
function	O
of	O
the	O
input	O
let	O
y	O
be	O
the	O
value	O
that	O
our	O
model	O
predicts	O
should	O
take	O
on	O
we	O
define	O
the	O
output	O
to	O
be	O
r	O
y	O
where	O
w	O
y	O
w	O
n	O
is	O
a	O
vector	O
of	O
r	O
parameters	O
x	O
parameters	O
are	O
values	O
that	O
control	O
the	O
behavior	O
of	O
the	O
system	O
in	O
this	O
case	O
wi	O
is	O
the	O
coefficient	O
that	O
we	O
multiply	O
by	O
feature	B
xi	O
before	O
summing	O
up	O
the	O
contributions	O
from	O
all	O
the	O
features	O
we	O
can	O
think	O
of	O
w	O
as	O
a	O
set	O
of	O
weights	B
that	O
determine	O
how	O
each	O
feature	B
affects	O
the	O
prediction	O
if	O
a	O
feature	B
xi	O
receives	O
a	O
positive	O
weight	O
wi	O
chapter	O
machine	B
learning	I
basics	O
then	O
increasing	O
the	O
value	O
of	O
that	O
feature	B
increases	O
the	O
value	O
of	O
our	O
prediction	O
y	O
if	O
a	O
feature	B
receives	O
a	O
negative	O
weight	O
then	O
increasing	O
the	O
value	O
of	O
that	O
feature	B
decreases	O
the	O
value	O
of	O
our	O
prediction	O
if	O
a	O
feature	B
s	O
weight	O
is	O
large	O
in	O
magnitude	O
then	O
it	O
has	O
a	O
large	O
effect	O
on	O
the	O
prediction	O
if	O
a	O
feature	B
s	O
weight	O
is	O
zero	O
it	O
has	O
no	O
effect	O
on	O
the	O
prediction	O
we	O
thus	O
have	O
a	O
definition	O
of	O
our	O
task	O
t	O
to	O
predict	O
y	O
from	O
x	O
by	O
outputting	O
y	O
w	O
x	O
next	O
we	O
need	O
a	O
definition	O
of	O
our	O
performance	O
measure	O
suppose	O
that	O
we	O
have	O
a	O
design	B
matrix	I
of	O
m	O
example	B
inputs	O
that	O
we	O
will	O
not	O
use	O
for	O
training	O
only	O
for	O
evaluating	O
how	O
well	O
the	O
model	O
performs	O
we	O
also	O
have	O
a	O
vector	O
of	O
regression	B
targets	O
providing	O
the	O
correct	O
value	O
of	O
y	O
for	O
each	O
of	O
these	O
examples	O
because	O
this	O
dataset	B
will	O
only	O
be	O
used	O
for	O
evaluation	O
we	O
call	O
it	O
the	O
test	O
test	O
and	O
the	O
vector	O
of	O
regression	B
set	O
we	O
refer	O
to	O
the	O
design	B
matrix	I
of	O
inputs	O
as	O
x	O
targets	O
as	O
y	O
test	O
one	O
way	O
of	O
measuring	O
the	O
performance	O
of	O
the	O
model	O
is	O
to	O
compute	O
the	O
mean	O
test	O
gives	O
the	O
predictions	O
of	O
the	O
squared	O
error	O
of	O
the	O
model	O
on	O
the	O
test	B
set	I
if	O
y	O
model	O
on	O
the	O
test	B
set	I
then	O
the	O
mean	B
squared	I
error	I
is	O
given	O
by	O
msetest	O
m	O
i	O
test	O
y	O
y	O
test	O
i	O
intuitively	O
one	O
can	O
see	O
that	O
this	O
error	O
measure	O
decreases	O
to	O
when	O
y	O
we	O
can	O
also	O
see	O
that	O
test	O
y	O
test	O
msetest	O
m	O
test	O
y	O
test	O
y	O
so	O
the	O
error	O
increases	O
whenever	O
the	O
euclidean	O
distance	O
between	O
the	O
predictions	O
and	O
the	O
targets	O
increases	O
to	O
make	O
a	O
machine	B
learning	I
algorithm	O
we	O
need	O
to	O
design	O
an	O
algorithm	O
that	O
will	O
improve	O
the	O
weights	B
w	O
in	O
a	O
way	O
that	O
reduces	O
msetest	O
when	O
the	O
algorithm	O
train	O
one	O
is	O
allowed	O
to	O
gain	O
experience	O
by	O
observing	O
a	O
training	O
set	O
intuitive	O
way	O
of	O
doing	O
this	O
we	O
will	O
justify	O
later	O
in	O
section	O
is	O
just	O
to	O
minimize	O
the	O
mean	B
squared	I
error	I
on	O
the	O
training	O
set	O
msetrain	O
train	O
y	O
to	O
minimize	O
mse	O
train	O
we	O
can	O
simply	O
solve	O
for	O
where	O
its	O
gradient	B
is	O
wmsetrain	O
train	O
train	O
y	O
y	O
train	O
train	O
w	O
y	O
m	O
x	O
w	O
m	O
w	O
chapter	O
machine	B
learning	I
basics	O
y	O
linear	O
regression	B
example	B
n	O
i	O
a	O
r	O
t	O
e	O
s	O
m	O
optimization	O
of	O
w	O
figure	O
a	O
linear	O
regression	B
problem	O
with	O
a	O
training	O
set	O
consisting	O
of	O
ten	O
data	O
points	O
each	O
containing	O
one	O
feature	B
because	O
there	O
is	O
only	O
one	O
feature	B
the	O
weight	O
vector	O
w	O
contains	O
only	O
a	O
single	O
parameter	O
to	O
learn	O
that	O
linear	O
regression	B
learns	O
to	O
set	O
such	O
that	O
the	O
line	O
y	O
comes	O
as	O
close	O
as	O
possible	O
to	O
passing	O
through	O
all	O
the	O
training	O
points	O
found	O
by	O
the	O
normal	O
equations	O
which	O
we	O
can	O
see	O
minimizes	O
the	O
mean	B
squared	I
error	I
on	O
the	O
training	O
set	O
the	O
plotted	O
point	O
indicates	O
the	O
value	O
of	O
train	O
w	O
y	O
train	O
train	O
w	O
w	O
x	O
x	O
train	O
w	O
w	O
x	O
x	O
train	O
train	O
w	O
y	O
train	O
train	O
y	O
train	O
train	O
y	O
w	O
x	O
train	O
y	O
train	O
w	O
x	O
train	O
train	O
train	O
train	O
x	O
train	O
train	O
y	O
x	O
y	O
w	O
x	O
x	O
the	O
system	O
of	O
equations	O
whose	O
solution	O
is	O
given	O
by	O
equation	O
is	O
known	O
as	O
constitutes	O
a	O
simple	O
learning	O
the	O
normal	O
equations	O
evaluating	O
equation	O
algorithm	O
for	O
an	O
example	B
of	O
the	O
linear	O
regression	B
learning	O
algorithm	O
in	O
action	O
see	O
figure	O
it	O
is	O
worth	O
noting	O
that	O
the	O
term	O
linear	O
regression	B
is	O
often	O
used	O
to	O
refer	O
to	O
a	O
slightly	O
more	O
sophisticated	O
model	O
with	O
one	O
additional	O
parameter	O
an	O
intercept	O
term	O
in	O
this	O
model	O
b	O
y	O
w	O
x	O
b	O
so	O
the	O
mapping	O
from	O
parameters	O
to	O
predictions	O
is	O
still	O
a	O
linear	O
function	O
but	O
the	O
mapping	O
from	O
features	O
to	O
predictions	O
is	O
now	O
an	O
affine	B
function	O
this	O
extension	O
to	O
affine	B
functions	O
means	O
that	O
the	O
plot	O
of	O
the	O
model	O
s	O
predictions	O
still	O
looks	O
like	O
a	O
line	O
but	O
it	O
need	O
not	O
pass	O
through	O
the	O
origin	O
instead	O
of	O
adding	O
the	O
bias	B
parameter	I
chapter	O
machine	B
learning	I
basics	O
b	O
one	O
can	O
continue	O
to	O
use	O
the	O
model	O
with	O
only	O
weights	B
but	O
augment	O
x	O
with	O
an	O
extra	O
entry	O
that	O
is	O
always	O
set	O
to	O
the	O
weight	O
corresponding	O
to	O
the	O
extra	O
entry	O
plays	O
the	O
role	O
of	O
the	O
bias	B
parameter	I
we	O
will	O
frequently	O
use	O
the	O
term	O
linear	O
when	O
referring	O
to	O
affine	B
functions	O
throughout	O
this	O
book	O
the	O
intercept	O
term	O
b	O
is	O
often	O
called	O
the	O
bias	B
parameter	I
of	O
the	O
affine	B
transformation	O
this	O
terminology	O
derives	O
from	O
the	O
point	O
of	O
view	O
that	O
the	O
output	O
of	O
the	O
transformation	O
is	O
biased	O
toward	O
being	O
b	O
in	O
the	O
absence	O
of	O
any	O
input	O
this	O
term	O
is	O
different	O
from	O
the	O
idea	O
of	O
a	O
statistical	O
bias	O
in	O
which	O
a	O
statistical	O
estimation	O
algorithm	O
s	O
expected	O
estimate	O
of	O
a	O
quantity	O
is	O
not	O
equal	O
to	O
the	O
true	O
quantity	O
linear	O
regression	B
is	O
of	O
course	O
an	O
extremely	O
simple	O
and	O
limited	O
learning	O
algorithm	O
but	O
it	O
provides	O
an	O
example	B
of	O
how	O
a	O
learning	O
algorithm	O
can	O
work	O
in	O
the	O
subsequent	O
sections	O
we	O
will	O
describe	O
some	O
of	O
the	O
basic	O
principles	O
underlying	O
learning	O
algorithm	O
design	O
and	O
demonstrate	O
how	O
these	O
principles	O
can	O
be	O
used	O
to	O
build	O
more	O
complicated	O
learning	O
algorithms	O
capacity	O
overfitting	O
and	O
underfitting	O
the	O
central	O
challenge	B
in	O
machine	B
learning	I
is	O
that	O
we	O
must	O
perform	O
well	O
on	O
new	O
previously	O
unseen	O
inputs	O
not	O
just	O
those	O
on	O
which	O
our	O
model	O
was	O
trained	O
the	O
ability	O
to	O
perform	O
well	O
on	O
previously	O
unobserved	O
inputs	O
is	O
called	O
generalization	B
typically	O
when	O
training	O
a	O
machine	B
learning	I
model	O
we	O
have	O
access	O
to	O
a	O
training	O
set	O
we	O
can	O
compute	O
some	O
error	O
measure	O
on	O
the	O
training	O
set	O
called	O
the	O
training	B
error	I
and	O
we	O
reduce	O
this	O
training	B
error	I
so	O
far	O
what	O
we	O
have	O
described	O
is	O
simply	O
an	O
optimization	O
problem	O
what	O
separates	O
machine	B
learning	I
from	O
optimization	O
is	O
that	O
we	O
want	O
the	O
generalization	B
error	O
also	O
called	O
the	O
test	O
error	O
to	O
be	O
low	O
as	O
well	O
the	O
generalization	B
error	O
is	O
defined	O
as	O
the	O
expected	O
value	O
of	O
the	O
error	O
on	O
a	O
new	O
input	O
here	O
the	O
expectation	B
is	O
taken	O
across	O
different	O
possible	O
inputs	O
drawn	O
from	O
the	O
distribution	O
of	O
inputs	O
we	O
expect	O
the	O
system	O
to	O
encounter	O
in	O
practice	O
we	O
typically	O
estimate	O
the	O
generalization	B
error	O
of	O
a	O
machine	B
learning	I
model	O
by	O
measuring	O
its	O
performance	O
on	O
a	O
test	B
set	I
of	O
examples	O
that	O
were	O
collected	O
separately	O
from	O
the	O
training	O
set	O
in	O
our	O
linear	O
regression	B
example	B
we	O
trained	O
the	O
model	O
by	O
minimizing	O
the	O
training	B
error	I
train	O
m	O
x	O
train	O
w	O
y	O
but	O
we	O
actually	O
care	O
about	O
the	O
test	O
error	O
test	O
m	O
train	O
x	O
test	O
w	O
y	O
test	O
how	O
can	O
we	O
affect	O
performance	O
on	O
the	O
test	B
set	I
when	O
we	O
get	O
to	O
observe	O
only	O
the	O
chapter	O
machine	B
learning	I
basics	O
training	O
set	O
the	O
field	O
of	O
statistical	B
learning	I
theory	I
provides	O
some	O
answers	O
if	O
the	O
training	O
and	O
the	O
test	B
set	I
are	O
collected	O
arbitrarily	O
there	O
is	O
indeed	O
little	O
we	O
can	O
do	O
if	O
we	O
are	O
allowed	O
to	O
make	O
some	O
assumptions	O
about	O
how	O
the	O
training	O
and	O
test	B
set	I
are	O
collected	O
then	O
we	O
can	O
make	O
some	O
progress	O
the	O
train	O
and	O
test	O
data	O
are	O
generated	O
by	O
a	O
probability	B
distribution	I
over	O
datasets	O
called	O
the	O
data	B
generating	I
process	I
we	O
typically	O
make	O
a	O
set	O
of	O
assumptions	O
known	O
collectively	O
as	O
the	O
i	O
i	O
d	O
assumptions	O
these	O
assumptions	O
are	O
that	O
the	O
examples	O
in	O
each	O
dataset	B
are	O
independent	O
from	O
each	O
other	O
and	O
that	O
the	O
train	O
set	O
and	O
test	B
set	I
are	O
identically	O
distributed	O
drawn	O
from	O
the	O
same	O
probability	B
distribution	I
as	O
each	O
other	O
this	O
assumption	O
allows	O
us	O
to	O
describe	O
the	O
data	B
generating	I
process	I
with	O
a	O
probability	B
distribution	I
over	O
a	O
single	O
example	B
the	O
same	O
distribution	O
is	O
then	O
used	O
to	O
generate	O
every	O
train	O
example	B
and	O
every	O
test	O
example	B
we	O
call	O
that	O
shared	O
underlying	O
distribution	O
the	O
data	O
generating	O
distribution	O
denoted	O
pdata	O
this	O
probabilistic	O
framework	O
and	O
the	O
i	O
i	O
d	O
assumptions	O
allow	O
us	O
to	O
mathematically	O
study	O
the	O
relationship	O
between	O
training	B
error	I
and	O
test	O
error	O
one	O
immediate	O
connection	O
we	O
can	O
observe	O
between	O
the	O
training	O
and	O
test	O
error	O
is	O
that	O
the	O
expected	O
training	B
error	I
of	O
a	O
randomly	O
selected	O
model	O
is	O
equal	O
to	O
the	O
expected	O
test	O
error	O
of	O
that	O
model	O
suppose	O
we	O
have	O
a	O
probability	B
distribution	I
px	O
y	O
and	O
we	O
sample	O
from	O
it	O
repeatedly	O
to	O
generate	O
the	O
train	O
set	O
and	O
the	O
test	B
set	I
for	O
some	O
fixed	O
value	O
w	O
the	O
expected	O
training	O
set	O
error	O
is	O
exactly	O
the	O
same	O
as	O
the	O
expected	O
test	B
set	I
error	O
because	O
both	O
expectations	O
are	O
formed	O
using	O
the	O
same	O
dataset	B
sampling	O
process	O
the	O
only	O
difference	O
between	O
the	O
two	O
conditions	O
is	O
the	O
name	O
we	O
assign	O
to	O
the	O
dataset	B
we	O
sample	O
of	O
course	O
when	O
we	O
use	O
a	O
machine	B
learning	I
algorithm	O
we	O
do	O
not	O
fix	O
the	O
parameters	O
ahead	O
of	O
time	O
then	O
sample	O
both	O
datasets	O
we	O
sample	O
the	O
training	O
set	O
then	O
use	O
it	O
to	O
choose	O
the	O
parameters	O
to	O
reduce	O
training	O
set	O
error	O
then	O
sample	O
the	O
test	B
set	I
under	O
this	O
process	O
the	O
expected	O
test	O
error	O
is	O
greater	O
than	O
or	O
equal	O
to	O
the	O
expected	O
value	O
of	O
training	B
error	I
the	O
factors	O
determining	O
how	O
well	O
a	O
machine	B
learning	I
algorithm	O
will	O
perform	O
are	O
its	O
ability	O
to	O
make	O
the	O
training	B
error	I
small	O
make	O
the	O
gap	O
between	O
training	O
and	O
test	O
error	O
small	O
these	O
two	O
factors	O
correspond	O
to	O
the	O
two	O
central	O
challenges	O
in	O
machine	B
learning	I
underfitting	O
and	O
overfitting	O
underfitting	O
occurs	O
when	O
the	O
model	O
is	O
not	O
able	O
to	O
obtain	O
a	O
sufficiently	O
low	O
error	O
value	O
on	O
the	O
training	O
set	O
overfitting	O
occurs	O
when	O
the	O
gap	O
between	O
the	O
training	B
error	I
and	O
test	O
error	O
is	O
too	O
large	O
we	O
can	O
control	O
whether	O
a	O
model	O
is	O
more	O
likely	O
to	O
overfit	O
or	O
underfit	O
by	O
altering	O
its	O
capacity	O
informally	O
a	O
model	O
s	O
capacity	O
is	O
its	O
ability	O
to	O
fit	O
a	O
wide	O
variety	O
of	O
chapter	O
machine	B
learning	I
basics	O
functions	O
models	O
with	O
low	O
capacity	O
may	O
struggle	O
to	O
fit	O
the	O
training	O
set	O
models	O
with	O
high	O
capacity	O
can	O
overfit	O
by	O
memorizing	O
properties	O
of	O
the	O
training	O
set	O
that	O
do	O
not	O
serve	O
them	O
well	O
on	O
the	O
test	B
set	I
one	O
way	O
to	O
control	O
the	O
capacity	O
of	O
a	O
learning	O
algorithm	O
is	O
by	O
choosing	O
its	O
hypothesis	O
space	O
the	O
set	O
of	O
functions	O
that	O
the	O
learning	O
algorithm	O
is	O
allowed	O
to	O
select	O
as	O
being	O
the	O
solution	O
for	O
example	B
the	O
linear	O
regression	B
algorithm	O
has	O
the	O
set	O
of	O
all	O
linear	O
functions	O
of	O
its	O
input	O
as	O
its	O
hypothesis	O
space	O
we	O
can	O
generalize	O
linear	O
regression	B
to	O
include	O
polynomials	O
rather	O
than	O
just	O
linear	O
functions	O
in	O
its	O
hypothesis	O
space	O
doing	O
so	O
increases	O
the	O
model	O
s	O
capacity	O
a	O
polynomial	O
of	O
degree	O
one	O
gives	O
us	O
the	O
linear	O
regression	B
model	O
with	O
which	O
we	O
are	O
already	O
familiar	O
with	O
prediction	O
y	O
b	O
wx	O
by	O
introducing	O
as	O
another	O
feature	B
provided	O
to	O
the	O
linear	O
regression	B
model	O
we	O
can	O
learn	O
a	O
model	O
that	O
is	O
quadratic	O
as	O
a	O
function	O
of	O
y	O
w	O
b	O
w	O
the	O
output	O
is	O
though	O
this	O
model	O
implements	O
a	O
quadratic	O
function	O
of	O
its	O
still	O
a	O
linear	O
function	O
of	O
the	O
parameters	O
so	O
we	O
can	O
still	O
use	O
the	O
normal	O
equations	O
to	O
train	O
the	O
model	O
in	O
closed	O
form	O
we	O
can	O
continue	O
to	O
add	O
more	O
powers	O
of	O
x	O
as	O
additional	O
features	O
for	O
example	B
to	O
obtain	O
a	O
polynomial	O
of	O
degree	O
input	O
y	O
b	O
wixi	O
machine	B
learning	I
algorithms	O
will	O
generally	O
perform	O
best	O
when	O
their	O
capacity	O
is	O
appropriate	O
for	O
the	O
true	O
complexity	O
of	O
the	O
task	O
they	O
need	O
to	O
perform	O
and	O
the	O
amount	O
of	O
training	O
data	O
they	O
are	O
provided	O
with	O
models	O
with	O
insufficient	O
capacity	O
are	O
unable	O
to	O
solve	O
complex	O
tasks	O
models	O
with	O
high	O
capacity	O
can	O
solve	O
complex	O
tasks	O
but	O
when	O
their	O
capacity	O
is	O
higher	O
than	O
needed	O
to	O
solve	O
the	O
present	O
task	O
they	O
may	O
overfit	O
figure	O
shows	O
this	O
principle	O
in	O
action	O
we	O
compare	O
a	O
linear	O
quadratic	O
and	O
predictor	O
attempting	O
to	O
fit	O
a	O
problem	O
where	O
the	O
true	O
underlying	O
function	O
is	O
quadratic	O
the	O
linear	O
function	O
is	O
unable	O
to	O
capture	O
the	O
curvature	O
in	O
the	O
true	O
underlying	O
problem	O
so	O
it	O
underfits	O
the	O
predictor	O
is	O
capable	O
of	O
representing	O
the	O
correct	O
function	O
but	O
it	O
is	O
also	O
capable	O
of	O
representing	O
infinitely	O
many	O
other	O
functions	O
that	O
pass	O
exactly	O
through	O
the	O
training	O
points	O
because	O
we	O
chapter	O
machine	B
learning	I
basics	O
have	O
more	O
parameters	O
than	O
training	O
examples	O
we	O
have	O
little	O
chance	O
of	O
choosing	O
a	O
solution	O
that	O
generalizes	O
well	O
when	O
so	O
many	O
wildly	O
different	O
solutions	O
exist	O
in	O
this	O
example	B
the	O
quadratic	O
model	O
is	O
perfectly	O
matched	O
to	O
the	O
true	O
structure	O
of	O
the	O
task	O
so	O
it	O
generalizes	O
well	O
to	O
new	O
data	O
figure	O
we	O
fit	O
three	O
models	O
to	O
this	O
example	B
training	O
set	O
the	O
training	O
data	O
was	O
generated	O
synthetically	O
by	O
randomly	O
sampling	O
x	O
values	O
and	O
choosing	O
y	O
deterministically	O
by	O
evaluating	O
a	O
quadratic	O
function	O
linear	O
function	O
fit	O
to	O
the	O
data	O
suffers	O
from	O
underfitting	O
it	O
cannot	O
capture	O
the	O
curvature	O
that	O
is	O
present	O
in	O
the	O
data	O
a	O
quadratic	O
function	O
fit	O
to	O
the	O
data	O
generalizes	O
well	O
to	O
unseen	O
points	O
it	O
does	O
not	O
suffer	O
from	O
a	O
significant	O
amount	O
of	O
overfitting	O
or	O
underfitting	O
a	O
polynomial	O
of	O
degree	O
fit	O
to	O
the	O
data	O
suffers	O
from	O
overfitting	O
here	O
we	O
used	O
the	O
moore-penrose	O
pseudoinverse	O
to	O
solve	O
the	O
underdetermined	O
normal	O
equations	O
the	O
solution	O
passes	O
through	O
all	O
of	O
the	O
training	O
points	O
exactly	O
but	O
we	O
have	O
not	O
been	O
lucky	O
enough	O
for	O
it	O
to	O
extract	O
the	O
correct	O
structure	O
it	O
now	O
has	O
a	O
deep	O
valley	O
in	O
between	O
two	O
training	O
points	O
that	O
does	O
not	O
appear	O
in	O
the	O
true	O
underlying	O
function	O
it	O
also	O
increases	O
sharply	O
on	O
the	O
left	O
side	O
of	O
the	O
data	O
while	O
the	O
true	O
function	O
decreases	O
in	O
this	O
area	O
so	O
far	O
we	O
have	O
described	O
only	O
one	O
way	O
of	O
changing	O
a	O
model	O
s	O
capacity	O
by	O
changing	O
the	O
number	O
of	O
input	O
features	O
it	O
has	O
and	O
simultaneously	O
adding	O
new	O
parameters	O
associated	O
with	O
those	O
features	O
there	O
are	O
in	O
fact	O
many	O
ways	O
of	O
changing	O
a	O
model	O
s	O
capacity	O
capacity	O
is	O
not	O
determined	O
only	O
by	O
the	O
choice	O
of	O
model	O
the	O
model	O
specifies	O
which	O
family	O
of	O
functions	O
the	O
learning	O
algorithm	O
can	O
choose	O
from	O
when	O
varying	O
the	O
parameters	O
in	O
order	O
to	O
reduce	O
a	O
training	O
objective	O
this	O
is	O
called	O
the	O
representational	B
capacity	I
of	O
the	O
model	O
in	O
many	O
cases	O
finding	O
the	O
best	O
function	O
within	O
this	O
family	O
is	O
a	O
very	O
difficult	O
optimization	O
problem	O
in	O
practice	O
the	O
learning	O
algorithm	O
does	O
not	O
actually	O
find	O
the	O
best	O
function	O
but	O
merely	O
one	O
that	O
significantly	O
reduces	O
the	O
training	B
error	I
these	O
additional	O
limitations	O
such	O
as	O
chapter	O
machine	B
learning	I
basics	O
the	O
imperfection	O
of	O
the	O
optimization	O
algorithm	O
mean	O
that	O
the	O
learning	O
algorithm	O
s	O
effective	B
capacity	I
may	O
be	O
less	O
than	O
the	O
representational	B
capacity	I
of	O
the	O
model	O
family	O
our	O
modern	O
ideas	O
about	O
improving	O
the	O
generalization	B
of	O
machine	B
learning	I
models	O
are	O
refinements	O
of	O
thought	O
dating	O
back	O
to	O
philosophers	O
at	O
least	O
as	O
early	O
as	O
ptolemy	O
many	O
early	O
scholars	O
invoke	O
a	O
principle	O
of	O
parsimony	O
that	O
is	O
now	O
most	O
widely	O
known	O
as	O
occam	O
s	O
razor	O
this	O
principle	O
states	O
that	O
among	O
competing	O
hypotheses	O
that	O
explain	O
known	O
observations	O
equally	O
well	O
one	O
should	O
choose	O
the	O
simplest	O
one	O
this	O
idea	O
was	O
formalized	O
and	O
made	O
more	O
precise	O
in	O
the	O
century	O
by	O
the	O
founders	O
of	O
statistical	B
learning	I
theory	I
and	O
chervonenkis	O
vapnik	O
blumer	O
vapnik	O
et	O
al	O
statistical	B
learning	I
theory	I
provides	O
various	O
means	O
of	O
quantifying	O
model	O
capacity	O
among	O
these	O
the	O
most	O
well-known	O
is	O
the	O
vapnik-chervonenkis	B
dimension	I
or	O
vc	O
dimension	O
the	O
vc	O
dimension	O
measures	O
the	O
capacity	O
of	O
a	O
binary	O
classifier	O
the	O
vc	O
dimension	O
is	O
defined	O
as	O
being	O
the	O
largest	O
possible	O
value	O
of	O
m	O
for	O
which	O
there	O
exists	O
a	O
training	O
set	O
of	O
m	O
different	O
x	O
points	O
that	O
the	O
classifier	O
can	O
label	O
arbitrarily	O
quantifying	O
the	O
capacity	O
of	O
the	O
model	O
allows	O
statistical	B
learning	I
theory	I
to	O
make	O
quantitative	O
predictions	O
the	O
most	O
important	O
results	O
in	O
statistical	B
learning	I
theory	I
show	O
that	O
the	O
discrepancy	O
between	O
training	B
error	I
and	O
generalization	B
error	O
is	O
bounded	O
from	O
above	O
by	O
a	O
quantity	O
that	O
grows	O
as	O
the	O
model	O
capacity	O
grows	O
but	O
shrinks	O
as	O
the	O
number	O
of	O
training	O
examples	O
increases	O
and	O
chervonenkis	O
vapnik	O
blumer	O
these	O
bounds	O
provide	O
intellectual	O
justification	O
that	O
machine	B
learning	I
algorithms	O
can	O
work	O
but	O
they	O
are	O
rarely	O
used	O
in	O
practice	O
when	O
working	O
with	O
deep	O
learning	O
algorithms	O
this	O
is	O
in	O
part	O
because	O
the	O
bounds	O
are	O
often	O
quite	O
loose	O
and	O
in	O
part	O
because	O
it	O
can	O
be	O
quite	O
difficult	O
to	O
determine	O
the	O
capacity	O
of	O
deep	O
learning	O
algorithms	O
the	O
problem	O
of	O
determining	O
the	O
capacity	O
of	O
a	O
deep	O
learning	O
model	O
is	O
especially	O
difficult	O
because	O
the	O
effective	B
capacity	I
is	O
limited	O
by	O
the	O
capabilities	O
of	O
the	O
optimization	O
algorithm	O
and	O
we	O
have	O
little	O
theoretical	O
understanding	O
of	O
the	O
very	O
general	O
non-convex	O
optimization	O
problems	O
involved	O
in	O
deep	O
learning	O
vapnik	O
et	O
al	O
we	O
must	O
remember	O
that	O
while	O
simpler	O
functions	O
are	O
more	O
likely	O
to	O
generalize	O
have	O
a	O
small	O
gap	O
between	O
training	O
and	O
test	O
error	O
we	O
must	O
still	O
choose	O
a	O
sufficiently	O
complex	O
hypothesis	O
to	O
achieve	O
low	O
training	B
error	I
typically	O
training	B
error	I
decreases	O
until	O
it	O
asymptotes	O
to	O
the	O
minimum	O
possible	O
error	O
value	O
as	O
model	O
capacity	O
increases	O
the	O
error	O
measure	O
has	O
a	O
minimum	O
value	O
typically	O
generalization	B
error	O
has	O
a	O
u-shaped	O
curve	O
as	O
a	O
function	O
of	O
model	O
capacity	O
this	O
is	O
illustrated	O
in	O
figure	O
to	O
reach	O
the	O
most	O
extreme	O
case	O
of	O
arbitrarily	O
high	O
capacity	O
we	O
introduce	O
chapter	O
machine	B
learning	I
basics	O
underfitting	O
zone	O
overfitting	O
zone	O
training	B
error	I
generalization	B
error	O
r	O
o	O
r	O
r	O
e	O
optimal	O
capacity	O
capacity	O
generalization	B
gap	O
figure	O
typical	O
relationship	O
between	O
capacity	O
and	O
error	O
training	O
and	O
test	O
error	O
behave	O
differently	O
at	O
the	O
left	O
end	O
of	O
the	O
graph	O
training	B
error	I
and	O
generalization	B
error	O
are	O
both	O
high	O
this	O
is	O
the	O
underfitting	O
regime	O
as	O
we	O
increase	O
capacity	O
training	B
error	I
decreases	O
but	O
the	O
gap	O
between	O
training	O
and	O
generalization	B
error	O
increases	O
eventually	O
the	O
size	O
of	O
this	O
gap	O
outweighs	O
the	O
decrease	O
in	O
training	B
error	I
and	O
we	O
enter	O
the	O
overfitting	O
regime	O
where	O
capacity	O
is	O
too	O
large	O
above	O
the	O
optimal	O
capacity	O
the	O
concept	O
of	O
non-parametric	O
models	O
so	O
far	O
we	O
have	O
seen	O
only	O
parametric	O
models	O
such	O
as	O
linear	O
regression	B
parametric	O
models	O
learn	O
a	O
function	O
described	O
by	O
a	O
parameter	O
vector	O
whose	O
size	O
is	O
finite	O
and	O
fixed	O
before	O
any	O
data	O
is	O
observed	O
non-parametric	O
models	O
have	O
no	O
such	O
limitation	O
sometimes	O
non-parametric	O
models	O
are	O
just	O
theoretical	O
abstractions	O
as	O
an	O
algorithm	O
that	O
searches	O
over	O
all	O
possible	O
probability	O
distributions	O
that	O
cannot	O
be	O
implemented	O
in	O
practice	O
however	O
we	O
can	O
also	O
design	O
practical	O
non-parametric	O
models	O
by	O
making	O
their	O
complexity	O
a	O
function	O
of	O
the	O
training	O
set	O
size	O
one	O
example	B
of	O
such	O
an	O
algorithm	O
is	O
nearest	B
neighbor	I
regression	B
unlike	O
linear	O
regression	B
which	O
has	O
a	O
fixed-length	O
vector	O
of	O
weights	B
the	O
nearest	B
neighbor	I
regression	B
model	O
simply	O
stores	O
the	O
x	O
and	O
y	O
from	O
the	O
training	O
set	O
when	O
asked	O
to	O
classify	O
a	O
test	O
point	O
x	O
the	O
model	O
looks	O
up	O
the	O
nearest	O
entry	O
in	O
the	O
training	O
set	O
and	O
returns	O
the	O
x	O
associated	O
regression	B
target	O
in	O
other	O
words	O
y	O
yi	O
where	O
i	O
arg	O
min	O
the	O
algorithm	O
can	O
also	O
be	O
generalized	O
to	O
distance	O
metrics	O
other	O
than	O
the	O
norm	O
such	O
as	O
learned	O
distance	O
metrics	O
if	O
the	O
algorithm	O
is	O
allowed	O
to	O
break	O
ties	O
by	O
averaging	O
the	O
yi	O
values	O
for	O
all	O
xi	O
that	O
are	O
tied	O
for	O
nearest	O
then	O
this	O
algorithm	O
is	O
able	O
to	O
achieve	O
the	O
minimum	O
possible	O
training	B
error	I
might	O
be	O
greater	O
than	O
zero	O
if	O
two	O
identical	O
inputs	O
are	O
associated	O
with	O
different	O
outputs	O
on	O
any	O
regression	B
dataset	B
goldberger	O
et	O
al	O
xi	O
finally	O
we	O
can	O
also	O
create	O
a	O
non-parametric	O
learning	O
algorithm	O
by	O
wrapping	O
a	O
chapter	O
machine	B
learning	I
basics	O
parametric	O
learning	O
algorithm	O
inside	O
another	O
algorithm	O
that	O
increases	O
the	O
number	O
of	O
parameters	O
as	O
needed	O
for	O
example	B
we	O
could	O
imagine	O
an	O
outer	O
loop	B
of	O
learning	O
that	O
changes	O
the	O
degree	O
of	O
the	O
polynomial	O
learned	O
by	O
linear	O
regression	B
on	O
top	O
of	O
a	O
polynomial	O
expansion	O
of	O
the	O
input	O
the	O
ideal	O
model	O
is	O
an	O
oracle	O
that	O
simply	O
knows	O
the	O
true	O
probability	B
distribution	I
that	O
generates	O
the	O
data	O
even	O
such	O
a	O
model	O
will	O
still	O
incur	O
some	O
error	O
on	O
many	O
problems	O
because	O
there	O
may	O
still	O
be	O
some	O
noise	O
in	O
the	O
distribution	O
in	O
the	O
case	O
of	O
supervised	B
learning	I
the	O
mapping	O
from	O
x	O
to	O
y	O
may	O
be	O
inherently	O
stochastic	O
or	O
y	O
may	O
be	O
a	O
deterministic	O
function	O
that	O
involves	O
other	O
variables	O
besides	O
those	O
included	O
in	O
x	O
the	O
error	O
incurred	O
by	O
an	O
oracle	O
making	O
predictions	O
from	O
the	O
true	O
distribution	O
bayes	B
error	I
is	O
called	O
the	O
p	O
y	O
training	O
and	O
generalization	B
error	O
vary	O
as	O
the	O
size	O
of	O
the	O
training	O
set	O
varies	O
expected	O
generalization	B
error	O
can	O
never	O
increase	O
as	O
the	O
number	O
of	O
training	O
examples	O
increases	O
for	O
non-parametric	O
models	O
more	O
data	O
yields	O
better	O
generalization	B
until	O
the	O
best	O
possible	O
error	O
is	O
achieved	O
any	O
fixed	O
parametric	B
model	I
with	O
less	O
than	O
optimal	O
capacity	O
will	O
asymptote	O
to	O
an	O
error	O
value	O
that	O
exceeds	O
the	O
bayes	B
error	I
see	O
figure	O
for	O
an	O
illustration	O
note	O
that	O
it	O
is	O
possible	O
for	O
the	O
model	O
to	O
have	O
optimal	O
capacity	O
and	O
yet	O
still	O
have	O
a	O
large	O
gap	O
between	O
training	O
and	O
generalization	B
error	O
in	O
this	O
situation	O
we	O
may	O
be	O
able	O
to	O
reduce	O
this	O
gap	O
by	O
gathering	O
more	O
training	O
examples	O
the	O
no	B
free	I
lunch	I
theorem	I
learning	O
theory	O
claims	O
that	O
a	O
machine	B
learning	I
algorithm	O
can	O
generalize	O
well	O
from	O
a	O
finite	O
training	O
set	O
of	O
examples	O
this	O
seems	O
to	O
contradict	O
some	O
basic	O
principles	O
of	O
logic	O
inductive	O
reasoning	O
or	O
inferring	O
general	O
rules	O
from	O
a	O
limited	O
set	O
of	O
examples	O
is	O
not	O
logically	O
valid	O
to	O
logically	O
infer	O
a	O
rule	O
describing	O
every	O
member	O
of	O
a	O
set	O
one	O
must	O
have	O
information	O
about	O
every	O
member	O
of	O
that	O
set	O
in	O
part	O
machine	B
learning	I
avoids	O
this	O
problem	O
by	O
offering	O
only	O
probabilistic	O
rules	O
rather	O
than	O
the	O
entirely	O
certain	O
rules	O
used	O
in	O
purely	O
logical	O
reasoning	O
machine	B
learning	I
promises	O
to	O
find	O
rules	O
that	O
are	O
probably	O
members	O
of	O
the	O
set	O
they	O
concern	O
correct	O
about	O
most	O
unfortunately	O
even	O
this	O
does	O
not	O
resolve	O
the	O
entire	O
problem	O
the	O
no	O
free	O
states	O
that	O
averaged	O
over	O
lunch	O
theorem	O
for	O
machine	B
learning	I
all	O
possible	O
data	O
generating	O
distributions	O
every	O
classification	B
algorithm	O
has	O
the	O
same	O
error	O
rate	O
when	O
classifying	O
previously	O
unobserved	O
points	O
in	O
other	O
words	O
in	O
some	O
sense	O
no	O
machine	B
learning	I
algorithm	O
is	O
universally	O
any	O
better	O
than	O
any	O
other	O
the	O
most	O
sophisticated	O
algorithm	O
we	O
can	O
conceive	O
of	O
has	O
the	O
same	O
average	O
chapter	O
machine	B
learning	I
basics	O
figure	O
the	O
effect	O
of	O
the	O
training	O
dataset	B
size	O
on	O
the	O
train	O
and	O
test	O
error	O
as	O
well	O
as	O
on	O
the	O
optimal	O
model	O
capacity	O
we	O
constructed	O
a	O
synthetic	O
regression	B
problem	O
based	O
on	O
adding	O
a	O
moderate	O
amount	O
of	O
noise	O
to	O
a	O
polynomial	O
generated	O
a	O
single	O
test	B
set	I
and	O
then	O
generated	O
several	O
different	O
sizes	O
of	O
training	O
set	O
for	O
each	O
size	O
we	O
generated	O
different	O
training	O
sets	O
in	O
order	O
to	O
plot	O
error	O
bars	O
showing	O
percent	O
confidence	O
intervals	O
mse	O
on	O
the	O
training	O
and	O
test	B
set	I
for	O
two	O
different	O
models	O
a	O
quadratic	O
model	O
and	O
a	O
model	O
with	O
degree	O
chosen	O
to	O
minimize	O
the	O
test	O
error	O
both	O
are	O
fit	O
in	O
closed	O
form	O
for	O
the	O
quadratic	O
model	O
the	O
training	B
error	I
increases	O
as	O
the	O
size	O
of	O
the	O
training	O
set	O
increases	O
this	O
is	O
because	O
larger	O
datasets	O
are	O
harder	O
to	O
fit	O
simultaneously	O
the	O
test	O
error	O
decreases	O
because	O
fewer	O
incorrect	O
hypotheses	O
are	O
consistent	O
with	O
the	O
training	O
data	O
the	O
quadratic	O
model	O
does	O
not	O
have	O
enough	O
capacity	O
to	O
solve	O
the	O
task	O
so	O
its	O
test	O
error	O
asymptotes	O
to	O
a	O
high	O
value	O
the	O
test	O
error	O
at	O
optimal	O
capacity	O
asymptotes	O
to	O
the	O
bayes	B
error	I
the	O
training	B
error	I
can	O
fall	O
below	O
the	O
bayes	B
error	I
due	O
to	O
the	O
ability	O
of	O
the	O
training	O
algorithm	O
to	O
memorize	O
specific	O
instances	O
of	O
the	O
training	O
set	O
as	O
the	O
training	O
size	O
increases	O
to	O
infinity	O
the	O
training	B
error	I
of	O
any	O
fixed-capacity	O
model	O
the	O
quadratic	O
model	O
must	O
rise	O
to	O
at	O
least	O
the	O
bayes	B
error	I
as	O
the	O
training	O
set	O
size	O
increases	O
the	O
optimal	O
capacity	O
here	O
as	O
the	O
degree	O
of	O
the	O
optimal	O
polynomial	O
regressor	O
increases	O
the	O
optimal	O
capacity	O
plateaus	O
after	O
reaching	O
sufficient	O
complexity	O
to	O
solve	O
the	O
task	O
chapter	O
machine	B
learning	I
basics	O
performance	O
all	O
possible	O
tasks	O
as	O
merely	O
predicting	O
that	O
every	O
point	O
belongs	O
to	O
the	O
same	O
class	O
fortunately	O
these	O
results	O
hold	O
only	O
when	O
we	O
average	O
over	O
possible	O
data	O
generating	O
distributions	O
if	O
we	O
make	O
assumptions	O
about	O
the	O
kinds	O
of	O
probability	O
distributions	O
we	O
encounter	O
in	O
real-world	O
applications	O
then	O
we	O
can	O
design	O
learning	O
algorithms	O
that	O
perform	O
well	O
on	O
these	O
distributions	O
all	O
this	O
means	O
that	O
the	O
goal	O
of	O
machine	B
learning	I
research	O
is	O
not	O
to	O
seek	O
a	O
universal	O
learning	O
algorithm	O
or	O
the	O
absolute	O
best	O
learning	O
algorithm	O
instead	O
our	O
goal	O
is	O
to	O
understand	O
what	O
kinds	O
of	O
distributions	O
are	O
relevant	O
to	O
the	O
real	O
world	O
that	O
an	O
ai	O
agent	O
experiences	O
and	O
what	O
kinds	O
of	O
machine	B
learning	I
algorithms	O
perform	O
well	O
on	O
data	O
drawn	O
from	O
the	O
kinds	O
of	O
data	O
generating	O
distributions	O
we	O
care	O
about	O
regularization	O
the	O
no	B
free	I
lunch	I
theorem	I
implies	O
that	O
we	O
must	O
design	O
our	O
machine	B
learning	I
algorithms	O
to	O
perform	O
well	O
on	O
a	O
specific	O
task	O
we	O
do	O
so	O
by	O
building	O
a	O
set	O
of	O
preferences	O
into	O
the	O
learning	O
algorithm	O
when	O
these	O
preferences	O
are	O
aligned	O
with	O
the	O
learning	O
problems	O
we	O
ask	O
the	O
algorithm	O
to	O
solve	O
it	O
performs	O
better	O
so	O
far	O
the	O
only	O
method	O
of	O
modifying	O
a	O
learning	O
algorithm	O
that	O
we	O
have	O
discussed	O
concretely	O
is	O
to	O
increase	O
or	O
decrease	O
the	O
model	O
s	O
representational	B
capacity	I
by	O
adding	O
or	O
removing	O
functions	O
from	O
the	O
hypothesis	O
space	O
of	O
solutions	O
the	O
learning	O
algorithm	O
is	O
able	O
to	O
choose	O
we	O
gave	O
the	O
specific	O
example	B
of	O
increasing	O
or	O
decreasing	O
the	O
degree	O
of	O
a	O
polynomial	O
for	O
a	O
regression	B
problem	O
the	O
view	O
we	O
have	O
described	O
so	O
far	O
is	O
oversimplified	O
the	O
behavior	O
of	O
our	O
algorithm	O
is	O
strongly	O
affected	O
not	O
just	O
by	O
how	O
large	O
we	O
make	O
the	O
set	O
of	O
functions	O
allowed	O
in	O
its	O
hypothesis	O
space	O
but	O
by	O
the	O
specific	O
identity	O
of	O
those	O
functions	O
the	O
learning	O
algorithm	O
we	O
have	O
studied	O
so	O
far	O
linear	O
regression	B
has	O
a	O
hypothesis	O
space	O
consisting	O
of	O
the	O
set	O
of	O
linear	O
functions	O
of	O
its	O
input	O
these	O
linear	O
functions	O
can	O
be	O
very	O
useful	O
for	O
problems	O
where	O
the	O
relationship	O
between	O
inputs	O
and	O
outputs	O
truly	O
is	O
close	O
to	O
linear	O
they	O
are	O
less	O
useful	O
for	O
problems	O
that	O
behave	O
in	O
a	O
very	O
nonlinear	O
fashion	O
for	O
example	B
linear	O
regression	B
would	O
not	O
perform	O
very	O
well	O
if	O
we	O
tried	O
to	O
use	O
it	O
to	O
predict	O
sinx	O
from	O
x	O
we	O
can	O
thus	O
control	O
the	O
performance	O
of	O
our	O
algorithms	O
by	O
choosing	O
what	O
kind	O
of	O
functions	O
we	O
allow	O
them	O
to	O
draw	O
solutions	O
from	O
as	O
well	O
as	O
by	O
controlling	O
the	O
amount	O
of	O
these	O
functions	O
we	O
can	O
also	O
give	O
a	O
learning	O
algorithm	O
a	O
preference	O
for	O
one	O
solution	O
in	O
its	O
hypothesis	O
space	O
to	O
another	O
this	O
means	O
that	O
both	O
functions	O
are	O
eligible	O
but	O
one	O
is	O
preferred	O
the	O
unpreferred	O
solution	O
will	O
be	O
chosen	O
only	O
if	O
it	O
fits	O
the	O
training	O
chapter	O
machine	B
learning	I
basics	O
data	O
significantly	O
better	O
than	O
the	O
preferred	O
solution	O
for	O
example	B
we	O
can	O
modify	O
the	O
training	O
criterion	O
for	O
linear	O
regression	B
to	O
include	O
weight	O
decay	O
to	O
perform	O
linear	O
regression	B
with	O
weight	O
decay	O
we	O
minimize	O
a	O
sum	O
comprising	O
both	O
the	O
mean	B
squared	I
error	I
on	O
the	O
training	O
and	O
a	O
criterion	O
j	O
that	O
expresses	O
a	O
preference	O
for	O
the	O
weights	B
to	O
have	O
smaller	O
squared	O
norm	O
specifically	O
w	O
msetrain	O
w	O
j	O
w	O
where	O
is	O
a	O
value	O
chosen	O
ahead	O
of	O
time	O
that	O
controls	O
the	O
strength	O
of	O
our	O
preference	O
for	O
smaller	O
weights	B
when	O
we	O
impose	O
no	O
preference	O
and	O
larger	O
forces	O
the	O
weights	B
to	O
become	O
smaller	O
minimizing	O
j	O
results	O
in	O
a	O
choice	O
of	O
weights	B
that	O
make	O
a	O
tradeoff	O
between	O
fitting	O
the	O
training	O
data	O
and	O
being	O
small	O
this	O
gives	O
us	O
solutions	O
that	O
have	O
a	O
smaller	O
slope	O
or	O
put	O
weight	O
on	O
fewer	O
of	O
the	O
features	O
as	O
an	O
example	B
of	O
how	O
we	O
can	O
control	O
a	O
model	O
s	O
tendency	O
to	O
overfit	O
or	O
underfit	O
via	O
weight	O
decay	O
we	O
can	O
train	O
a	O
high-degree	O
polynomial	O
regression	B
model	O
with	O
different	O
values	O
of	O
for	O
the	O
results	O
see	O
figure	O
figure	O
we	O
fit	O
a	O
high-degree	O
polynomial	O
regression	B
model	O
to	O
our	O
example	B
training	O
set	O
from	O
figure	O
the	O
true	O
function	O
is	O
quadratic	O
but	O
here	O
we	O
use	O
only	O
models	O
with	O
degree	O
we	O
vary	O
the	O
amount	O
of	O
weight	O
decay	O
to	O
prevent	O
these	O
high-degree	O
models	O
from	O
overfitting	O
very	O
large	O
we	O
can	O
force	O
the	O
model	O
to	O
learn	O
a	O
function	O
with	O
no	O
slope	O
at	O
all	O
this	O
underfits	O
because	O
it	O
can	O
only	O
represent	O
a	O
constant	O
function	O
with	O
a	O
medium	O
value	O
of	O
the	O
learning	O
algorithm	O
recovers	O
a	O
curve	O
with	O
the	O
right	O
general	O
shape	O
even	O
though	O
the	O
model	O
is	O
capable	O
of	O
representing	O
functions	O
with	O
much	O
more	O
complicated	O
shape	O
weight	O
decay	O
has	O
encouraged	O
it	O
to	O
use	O
a	O
simpler	O
function	O
described	O
by	O
smaller	O
coefficients	O
with	O
weight	O
decay	O
approaching	O
zero	O
using	O
the	O
moore-penrose	O
pseudoinverse	O
to	O
solve	O
the	O
underdetermined	O
problem	O
with	O
minimal	O
regularization	O
the	O
polynomial	O
overfits	O
significantly	O
as	O
we	O
saw	O
in	O
figure	O
chapter	O
machine	B
learning	I
basics	O
more	O
generally	O
we	O
can	O
regularize	O
a	O
model	O
that	O
learns	O
a	O
function	O
fx	O
by	O
adding	O
a	O
penalty	O
called	O
a	O
regularizer	B
to	O
the	O
cost	O
function	O
in	O
the	O
case	O
of	O
weight	O
decay	O
the	O
regularizer	B
is	O
w	O
we	O
will	O
see	O
that	O
many	O
other	O
regularizers	O
are	O
possible	O
w	O
in	O
chapter	O
expressing	O
preferences	O
for	O
one	O
function	O
over	O
another	O
is	O
a	O
more	O
general	O
way	O
of	O
controlling	O
a	O
model	O
s	O
capacity	O
than	O
including	O
or	O
excluding	O
members	O
from	O
the	O
hypothesis	O
space	O
we	O
can	O
think	O
of	O
excluding	O
a	O
function	O
from	O
a	O
hypothesis	O
space	O
as	O
expressing	O
an	O
infinitely	O
strong	O
preference	O
against	O
that	O
function	O
in	O
our	O
weight	O
decay	O
example	B
we	O
expressed	O
our	O
preference	O
for	O
linear	O
functions	O
defined	O
with	O
smaller	O
weights	B
explicitly	O
via	O
an	O
extra	O
term	O
in	O
the	O
criterion	O
we	O
minimize	O
there	O
are	O
many	O
other	O
ways	O
of	O
expressing	O
preferences	O
for	O
different	O
solutions	O
both	O
implicitly	O
and	O
explicitly	O
together	O
these	O
different	O
approaches	O
are	O
known	O
as	O
regularization	O
regularization	O
is	O
any	O
modification	O
we	O
make	O
to	O
a	O
learning	O
algorithm	O
that	O
is	O
intended	O
to	O
reduce	O
its	O
generalization	B
error	O
but	O
not	O
its	O
training	B
error	I
regularization	O
is	O
one	O
of	O
the	O
central	O
concerns	O
of	O
the	O
field	O
of	O
machine	B
learning	I
rivaled	O
in	O
its	O
importance	O
only	O
by	O
optimization	O
the	O
no	B
free	I
lunch	I
theorem	I
has	O
made	O
it	O
clear	O
that	O
there	O
is	O
no	O
best	O
machine	B
learning	I
algorithm	O
and	O
in	O
particular	O
no	O
best	O
form	O
of	O
regularization	O
instead	O
we	O
must	O
choose	O
a	O
form	O
of	O
regularization	O
that	O
is	O
well-suited	O
to	O
the	O
particular	O
task	O
we	O
want	O
to	O
solve	O
the	O
philosophy	O
of	O
deep	O
learning	O
in	O
general	O
and	O
this	O
book	O
in	O
particular	O
is	O
that	O
a	O
very	O
wide	O
range	O
of	O
tasks	O
as	O
all	O
of	O
the	O
intellectual	O
tasks	O
that	O
people	O
can	O
do	O
may	O
all	O
be	O
solved	O
effectively	O
using	O
very	O
general-purpose	O
forms	O
of	O
regularization	O
hyperparameters	O
and	O
validation	O
sets	O
most	O
machine	B
learning	I
algorithms	O
have	O
several	O
settings	O
that	O
we	O
can	O
use	O
to	O
control	O
the	O
behavior	O
of	O
the	O
learning	O
algorithm	O
these	O
settings	O
are	O
called	O
hyperparameters	O
the	O
values	O
of	O
hyperparameters	O
are	O
not	O
adapted	O
by	O
the	O
learning	O
algorithm	O
itself	O
we	O
can	O
design	O
a	O
nested	O
learning	O
procedure	O
where	O
one	O
learning	O
algorithm	O
learns	O
the	O
best	O
hyperparameters	O
for	O
another	O
learning	O
algorithm	O
in	O
the	O
polynomial	O
regression	B
example	B
we	O
saw	O
in	O
figure	O
there	O
is	O
a	O
single	O
hyperparameter	O
the	O
degree	O
of	O
the	O
polynomial	O
which	O
acts	O
as	O
a	O
capacity	O
hyperparameter	O
the	O
value	O
used	O
to	O
control	O
the	O
strength	O
of	O
weight	O
decay	O
is	O
another	O
example	B
of	O
a	O
hyperparameter	O
sometimes	O
a	O
setting	O
is	O
chosen	O
to	O
be	O
a	O
hyperparameter	O
that	O
the	O
learning	O
algorithm	O
does	O
not	O
learn	O
because	O
it	O
is	O
difficult	O
to	O
optimize	O
more	O
frequently	O
the	O
chapter	O
machine	B
learning	I
basics	O
setting	O
must	O
be	O
a	O
hyperparameter	O
because	O
it	O
is	O
not	O
appropriate	O
to	O
learn	O
that	O
hyperparameter	O
on	O
the	O
training	O
set	O
this	O
applies	O
to	O
all	O
hyperparameters	O
that	O
control	O
model	O
capacity	O
if	O
learned	O
on	O
the	O
training	O
set	O
such	O
hyperparameters	O
would	O
always	O
choose	O
the	O
maximum	O
possible	O
model	O
capacity	O
resulting	O
in	O
overfitting	O
to	O
figure	O
for	O
example	B
we	O
can	O
always	O
fit	O
the	O
training	O
set	O
better	O
with	O
a	O
higher	O
degree	O
polynomial	O
and	O
a	O
weight	O
decay	O
setting	O
of	O
than	O
we	O
could	O
with	O
a	O
lower	O
degree	O
polynomial	O
and	O
a	O
positive	O
weight	O
decay	O
setting	O
to	O
solve	O
this	O
problem	O
we	O
need	O
a	O
validation	O
set	O
of	O
examples	O
that	O
the	O
training	O
algorithm	O
does	O
not	O
observe	O
earlier	O
we	O
discussed	O
how	O
a	O
held-out	O
test	B
set	I
composed	O
of	O
examples	O
coming	O
from	O
the	O
same	O
distribution	O
as	O
the	O
training	O
set	O
can	O
be	O
used	O
to	O
estimate	O
the	O
generalization	B
error	O
of	O
a	O
learner	O
after	O
the	O
learning	O
process	O
has	O
completed	O
it	O
is	O
important	O
that	O
the	O
test	O
examples	O
are	O
not	O
used	O
in	O
any	O
way	O
to	O
make	O
choices	O
about	O
the	O
model	O
including	O
its	O
hyperparameters	O
for	O
this	O
reason	O
no	O
example	B
from	O
the	O
test	B
set	I
can	O
be	O
used	O
in	O
the	O
validation	O
set	O
therefore	O
we	O
always	O
construct	O
the	O
validation	O
set	O
from	O
the	O
training	O
data	O
specifically	O
we	O
split	O
the	O
training	O
data	O
into	O
two	O
disjoint	O
subsets	O
one	O
of	O
these	O
subsets	O
is	O
used	O
to	O
learn	O
the	O
parameters	O
the	O
other	O
subset	O
is	O
our	O
validation	O
set	O
used	O
to	O
estimate	O
the	O
generalization	B
error	O
during	O
or	O
after	O
training	O
allowing	O
for	O
the	O
hyperparameters	O
to	O
be	O
updated	O
accordingly	O
the	O
subset	O
of	O
data	O
used	O
to	O
learn	O
the	O
parameters	O
is	O
still	O
typically	O
called	O
the	O
training	O
set	O
even	O
though	O
this	O
may	O
be	O
confused	O
with	O
the	O
larger	O
pool	O
of	O
data	O
used	O
for	O
the	O
entire	O
training	O
process	O
the	O
subset	O
of	O
data	O
used	O
to	O
guide	O
the	O
selection	O
of	O
hyperparameters	O
is	O
called	O
the	O
validation	O
set	O
typically	O
one	O
uses	O
about	O
of	O
the	O
training	O
data	O
for	O
training	O
and	O
for	O
validation	O
since	O
the	O
validation	O
set	O
is	O
used	O
to	O
train	O
the	O
hyperparameters	O
the	O
validation	O
set	O
error	O
will	O
underestimate	O
the	O
generalization	B
error	O
though	O
typically	O
by	O
a	O
smaller	O
amount	O
than	O
the	O
training	B
error	I
after	O
all	O
hyperparameter	B
optimization	I
is	O
complete	O
the	O
generalization	B
error	O
may	O
be	O
estimated	O
using	O
the	O
test	B
set	I
in	O
practice	O
when	O
the	O
same	O
test	B
set	I
has	O
been	O
used	O
repeatedly	O
to	O
evaluate	O
performance	O
of	O
different	O
algorithms	O
over	O
many	O
years	O
and	O
especially	O
if	O
we	O
consider	O
all	O
the	O
attempts	O
from	O
the	O
scientific	O
community	O
at	O
beating	O
the	O
reported	O
state-ofthe-art	O
performance	O
on	O
that	O
test	B
set	I
we	O
end	O
up	O
having	O
optimistic	O
evaluations	O
with	O
the	O
test	B
set	I
as	O
well	O
benchmarks	O
can	O
thus	O
become	O
stale	O
and	O
then	O
do	O
not	O
reflect	O
the	O
true	O
field	O
performance	O
of	O
a	O
trained	O
system	O
thankfully	O
the	O
community	O
tends	O
to	O
move	O
on	O
to	O
new	O
usually	O
more	O
ambitious	O
and	O
larger	O
benchmark	O
datasets	O
chapter	O
machine	B
learning	I
basics	O
cross-validation	B
dividing	O
the	O
dataset	B
into	O
a	O
fixed	O
training	O
set	O
and	O
a	O
fixed	O
test	B
set	I
can	O
be	O
problematic	O
if	O
it	O
results	O
in	O
the	O
test	B
set	I
being	O
small	O
a	O
small	O
test	B
set	I
implies	O
statistical	O
uncertainty	O
around	O
the	O
estimated	O
average	O
test	O
error	O
making	O
it	O
difficult	O
to	O
claim	O
that	O
algorithm	O
a	O
works	O
better	O
than	O
algorithm	O
on	O
the	O
given	O
task	O
b	O
when	O
the	O
dataset	B
has	O
hundreds	O
of	O
thousands	O
of	O
examples	O
or	O
more	O
this	O
is	O
not	O
a	O
serious	O
issue	O
when	O
the	O
dataset	B
is	O
too	O
small	O
are	O
alternative	O
procedures	O
enable	O
one	O
to	O
use	O
all	O
of	O
the	O
examples	O
in	O
the	O
estimation	O
of	O
the	O
mean	O
test	O
error	O
at	O
the	O
price	O
of	O
increased	O
computational	O
cost	O
these	O
procedures	O
are	O
based	O
on	O
the	O
idea	O
of	O
repeating	O
the	O
training	O
and	O
testing	O
computation	O
on	O
different	O
randomly	O
chosen	O
subsets	O
or	O
splits	O
of	O
the	O
original	O
dataset	B
the	O
most	O
common	O
of	O
these	O
is	O
the	O
k-fold	O
cross-validation	B
procedure	O
shown	O
in	O
algorithm	O
in	O
which	O
a	O
partition	O
of	O
the	O
dataset	B
is	O
formed	O
by	O
splitting	O
it	O
into	O
k	O
non-overlapping	O
subsets	O
the	O
test	O
error	O
may	O
then	O
be	O
estimated	O
by	O
taking	O
the	O
average	O
test	O
error	O
across	O
k	O
trials	O
on	O
trial	O
i	O
the	O
i	O
subset	O
of	O
the	O
data	O
is	O
used	O
as	O
the	O
test	B
set	I
and	O
the	O
rest	O
of	O
the	O
data	O
is	O
used	O
as	O
the	O
training	O
set	O
one	O
problem	O
is	O
that	O
there	O
exist	O
no	O
unbiased	B
estimators	O
of	O
the	O
variance	O
of	O
such	O
average	O
error	O
estimators	O
and	O
grandvalet	O
but	O
approximations	O
are	O
typically	O
used	O
estimators	O
bias	O
and	O
variance	O
the	O
field	O
of	O
statistics	O
gives	O
us	O
many	O
tools	O
that	O
can	O
be	O
used	O
to	O
achieve	O
the	O
machine	B
learning	I
goal	O
of	O
solving	O
a	O
task	O
not	O
only	O
on	O
the	O
training	O
set	O
but	O
also	O
to	O
generalize	O
foundational	O
concepts	O
such	O
as	O
parameter	O
estimation	O
bias	O
and	O
variance	O
are	O
useful	O
to	O
formally	O
characterize	O
notions	O
of	O
generalization	B
underfitting	O
and	O
overfitting	O
point	O
estimation	O
point	O
estimation	O
is	O
the	O
attempt	O
to	O
provide	O
the	O
single	O
best	O
prediction	O
of	O
some	O
quantity	O
of	O
interest	O
in	O
general	O
the	O
quantity	O
of	O
interest	O
can	O
be	O
a	O
single	O
parameter	O
or	O
a	O
vector	O
of	O
parameters	O
in	O
some	O
parametric	B
model	I
such	O
as	O
the	O
weights	B
in	O
our	O
linear	O
regression	B
example	B
in	O
section	O
but	O
it	O
can	O
also	O
be	O
a	O
whole	O
function	O
in	O
order	O
to	O
distinguish	O
estimates	O
of	O
parameters	O
from	O
their	O
true	O
value	O
our	O
convention	O
will	O
be	O
to	O
denote	O
a	O
point	O
estimate	O
of	O
a	O
parameter	O
by	O
x	O
let	O
be	O
a	O
set	O
of	O
m	O
independent	O
and	O
identically	O
distributed	O
chapter	O
machine	B
learning	I
basics	O
algorithm	O
the	O
k-fold	O
cross-validation	B
algorithm	O
it	O
can	O
be	O
used	O
to	O
estimate	O
generalization	B
error	O
of	O
a	O
learning	O
algorithm	O
a	O
when	O
the	O
given	O
dataset	B
d	O
is	O
too	O
small	O
for	O
a	O
simple	O
traintest	O
or	O
trainvalid	O
split	O
to	O
yield	O
accurate	O
estimation	O
of	O
generalization	B
error	O
because	O
the	O
mean	O
of	O
a	O
loss	O
l	O
on	O
a	O
small	O
test	B
set	I
may	O
have	O
too	O
high	O
variance	O
the	O
dataset	B
d	O
contains	O
as	O
elements	O
the	O
abstract	O
examples	O
z	O
the	O
i-th	O
example	B
which	O
could	O
stand	O
for	O
an	O
pair	O
z	O
y	O
in	O
the	O
case	O
of	O
supervised	B
learning	I
or	O
for	O
just	O
an	O
input	O
z	O
x	O
in	O
the	O
case	O
of	O
unsupervised	O
learning	O
the	O
algorithm	O
returns	O
the	O
vector	O
of	O
errors	O
e	O
for	O
each	O
example	B
in	O
d	O
whose	O
mean	O
is	O
the	O
estimated	O
generalization	B
error	O
the	O
errors	O
on	O
individual	O
examples	O
can	O
be	O
used	O
to	O
compute	O
a	O
confidence	O
interval	O
around	O
the	O
mean	O
while	O
these	O
confidence	O
intervals	O
are	O
not	O
well-justified	O
after	O
the	O
use	O
of	O
cross-validation	B
it	O
is	O
still	O
common	O
practice	O
to	O
use	O
them	O
to	O
declare	O
that	O
algorithm	O
a	O
is	O
better	O
than	O
algorithm	O
b	O
only	O
if	O
the	O
confidence	O
interval	O
of	O
the	O
error	O
of	O
algorithm	O
a	O
lies	O
below	O
and	O
does	O
not	O
intersect	O
the	O
confidence	O
interval	O
of	O
algorithm	O
b	O
define	O
kfoldxv	O
require	O
d	O
the	O
given	O
dataset	B
with	O
elements	O
z	O
require	O
a	O
the	O
learning	O
algorithm	O
seen	O
as	O
a	O
function	O
that	O
takes	O
a	O
dataset	B
as	O
d	O
a	O
l	O
k	O
input	O
and	O
outputs	O
a	O
learned	O
function	O
require	O
l	O
the	O
loss	O
function	O
seen	O
as	O
a	O
function	O
from	O
a	O
learned	O
function	O
f	O
and	O
an	O
example	B
z	O
d	O
to	O
a	O
scalar	O
r	O
require	O
k	O
the	O
number	O
of	O
folds	O
into	O
mutually	O
exclusive	O
subsets	O
di	O
whose	O
union	O
is	O
do	O
split	O
i	O
for	O
k	O
d	O
from	O
k	O
fi	O
d	O
d	O
i	O
for	O
z	O
in	O
d	O
i	O
do	O
ej	O
fi	O
z	O
end	O
for	O
end	O
for	O
return	O
e	O
chapter	O
machine	B
learning	I
basics	O
data	O
points	O
a	O
point	B
estimator	I
or	O
statistic	B
is	O
any	O
function	O
of	O
the	O
data	O
m	O
x	O
the	O
definition	O
does	O
not	O
require	O
that	O
g	O
return	O
a	O
value	O
that	O
is	O
close	O
to	O
the	O
true	O
or	O
even	O
that	O
the	O
range	O
of	O
g	O
is	O
the	O
same	O
as	O
the	O
set	O
of	O
allowable	O
values	O
of	O
this	O
definition	O
of	O
a	O
point	B
estimator	I
is	O
very	O
general	O
and	O
allows	O
the	O
designer	O
of	O
an	O
estimator	O
great	O
flexibility	O
while	O
almost	O
any	O
function	O
thus	O
qualifies	O
as	O
an	O
estimator	O
a	O
good	O
estimator	O
is	O
a	O
function	O
whose	O
output	O
is	O
close	O
to	O
the	O
true	O
underlying	O
that	O
generated	O
the	O
training	O
data	O
for	O
now	O
we	O
take	O
the	O
frequentist	O
perspective	O
on	O
statistics	O
that	O
is	O
we	O
assume	O
that	O
the	O
true	O
parameter	O
value	O
is	O
fixed	O
but	O
unknown	O
while	O
the	O
point	O
estimate	O
is	O
a	O
function	O
of	O
the	O
data	O
since	O
the	O
data	O
is	O
drawn	O
from	O
a	O
random	O
process	O
any	O
function	O
of	O
the	O
data	O
is	O
random	O
therefore	O
is	O
a	O
random	B
variable	I
point	O
estimation	O
can	O
also	O
refer	O
to	O
the	O
estimation	O
of	O
the	O
relationship	O
between	O
input	O
and	O
target	O
variables	O
we	O
refer	O
to	O
these	O
types	O
of	O
point	O
estimates	O
as	O
function	O
estimators	O
function	O
estimation	O
as	O
we	O
mentioned	O
above	O
sometimes	O
we	O
are	O
interested	O
in	O
performing	O
function	O
estimation	O
function	O
approximation	O
here	O
we	O
are	O
trying	O
to	O
predict	O
a	O
variable	O
y	O
given	O
an	O
input	O
vector	O
x	O
we	O
assume	O
that	O
there	O
is	O
a	O
function	O
f	O
that	O
describes	O
the	O
approximate	O
relationship	O
between	O
y	O
and	O
x	O
for	O
example	B
we	O
may	O
assume	O
that	O
y	O
fx	O
where	O
stands	O
for	O
the	O
part	O
of	O
y	O
that	O
is	O
not	O
predictable	O
from	O
x	O
in	O
function	O
estimation	O
we	O
are	O
interested	O
in	O
approximating	O
f	O
with	O
a	O
model	O
or	O
estimate	O
f	O
function	O
estimation	O
is	O
really	O
just	O
the	O
same	O
as	O
estimating	O
a	O
parameter	O
the	O
function	O
estimator	O
f	O
is	O
simply	O
a	O
point	B
estimator	I
in	O
function	O
space	O
the	O
linear	O
regression	B
example	B
above	O
in	O
section	O
and	O
the	O
polynomial	O
regression	B
example	B
in	O
section	O
are	O
both	O
examples	O
of	O
scenarios	O
that	O
may	O
be	O
interpreted	O
either	O
as	O
estimating	O
a	O
parameter	O
w	O
or	O
estimating	O
a	O
function	O
f	O
mapping	O
from	O
tox	O
y	O
we	O
now	O
review	O
the	O
most	O
commonly	O
studied	O
properties	O
of	O
point	O
estimators	O
and	O
discuss	O
what	O
they	O
tell	O
us	O
about	O
these	O
estimators	O
bias	O
the	O
bias	O
of	O
an	O
estimator	O
is	O
defined	O
as	O
bias	O
m	O
m	O
chapter	O
machine	B
learning	I
basics	O
where	O
the	O
expectation	B
is	O
over	O
the	O
data	O
as	O
samples	O
from	O
a	O
random	B
variable	I
and	O
is	O
the	O
true	O
underlying	O
value	O
of	O
used	O
to	O
define	O
the	O
data	O
generating	O
distribution	O
an	O
estimator	O
m	O
is	O
said	O
to	O
be	O
unbiased	B
if	O
bias	O
m	O
which	O
implies	O
that	O
e	O
m	O
an	O
estimator	O
m	O
is	O
said	O
to	O
be	O
asymptotically	B
unbiased	B
if	O
limm	O
bias	O
m	O
which	O
implies	O
that	O
limm	O
e	O
m	O
example	B
bernoulli	B
distribution	I
consider	O
a	O
set	O
of	O
samples	O
that	O
are	O
independently	O
and	O
identically	O
distributed	O
according	O
to	O
a	O
bernoulli	B
distribution	I
with	O
mean	O
p	O
x	O
x	O
x	O
a	O
common	O
estimator	O
for	O
the	O
parameter	O
of	O
this	O
distribution	O
is	O
the	O
mean	O
of	O
the	O
training	O
samples	O
x	O
m	O
x	O
to	O
determine	O
whether	O
this	O
estimator	O
is	O
biased	O
we	O
can	O
substitute	O
equation	O
into	O
equation	O
bias	O
m	O
m	O
m	O
m	O
e	O
x	O
x	O
m	O
m	O
m	O
m	O
m	O
m	O
m	O
m	O
e	O
x	O
x	O
x	O
x	O
since	O
bias	O
we	O
say	O
that	O
our	O
estimator	O
is	O
unbiased	B
example	B
gaussian	O
distribution	O
estimator	O
of	O
the	O
mean	O
now	O
consider	O
that	O
are	O
independently	O
and	O
identically	O
distributed	O
a	O
set	O
of	O
samples	O
according	O
to	O
a	O
gaussian	O
distribution	O
px	O
m	O
where	O
i	O
x	O
n	O
chapter	O
machine	B
learning	I
basics	O
recall	B
that	O
the	O
gaussian	O
probability	B
density	I
function	I
is	O
given	O
by	O
p	O
x	O
exp	O
a	O
common	O
estimator	O
of	O
the	O
gaussian	O
mean	O
parameter	O
is	O
known	O
as	O
the	O
sample	B
mean	I
m	O
to	O
determine	O
the	O
bias	O
of	O
the	O
sample	B
mean	I
we	O
are	O
again	O
interested	O
in	O
calculating	O
its	O
expectation	B
bias	O
m	O
e	O
m	O
m	O
m	O
x	O
m	O
m	O
x	O
e	O
m	O
m	O
m	O
x	O
e	O
m	O
thus	O
we	O
find	O
that	O
the	O
sample	B
mean	I
is	O
an	O
unbiased	B
estimator	O
of	O
gaussian	O
mean	O
parameter	O
example	B
estimators	O
of	O
the	O
variance	O
of	O
a	O
gaussian	O
distribution	O
as	O
an	O
example	B
we	O
compare	O
two	O
different	O
estimators	O
of	O
the	O
variance	O
parameter	O
of	O
a	O
gaussian	O
distribution	O
we	O
are	O
interested	O
in	O
knowing	O
if	O
either	O
estimator	O
is	O
biased	O
the	O
first	O
estimator	O
of	O
we	O
consider	O
is	O
known	O
as	O
the	O
sample	O
variance	O
m	O
m	O
m	O
x	O
m	O
where	O
m	O
is	O
the	O
sample	B
mean	I
defined	O
above	O
more	O
formally	O
we	O
are	O
interested	O
in	O
computing	O
bias	O
m	O
e	O
m	O
chapter	O
machine	B
learning	I
basics	O
we	O
begin	O
by	O
evaluating	O
the	O
term	O
e	O
m	O
e	O
m	O
m	O
m	O
m	O
m	O
x	O
m	O
therefore	O
m	O
is	O
returning	O
to	O
equation	O
the	O
sample	O
variance	O
is	O
a	O
biased	O
estimator	O
we	O
conclude	O
that	O
the	O
bias	O
of	O
the	O
unbiased	B
sample	O
variance	O
estimator	O
m	O
m	O
m	O
x	O
m	O
provides	O
an	O
alternative	O
approach	O
as	O
the	O
name	O
suggests	O
this	O
estimator	O
is	O
unbiased	B
that	O
is	O
we	O
find	O
that	O
e	O
m	O
e	O
m	O
e	O
m	O
m	O
m	O
m	O
m	O
m	O
m	O
x	O
m	O
m	O
m	O
we	O
have	O
two	O
estimators	O
one	O
is	O
biased	O
and	O
the	O
other	O
is	O
not	O
while	O
unbiased	B
estimators	O
are	O
clearly	O
desirable	O
they	O
are	O
not	O
always	O
the	O
best	O
estimators	O
as	O
we	O
will	O
see	O
we	O
often	O
use	O
biased	O
estimators	O
that	O
possess	O
other	O
important	O
properties	O
variance	O
and	O
standard	B
error	I
another	O
property	O
of	O
the	O
estimator	O
that	O
we	O
might	O
want	O
to	O
consider	O
is	O
how	O
much	O
we	O
expect	O
it	O
to	O
vary	O
as	O
a	O
function	O
of	O
the	O
data	O
sample	O
just	O
as	O
we	O
computed	O
the	O
expectation	B
of	O
the	O
estimator	O
to	O
determine	O
its	O
bias	O
we	O
can	O
compute	O
its	O
variance	O
the	O
variance	O
of	O
an	O
estimator	O
is	O
simply	O
the	O
variance	O
var	O
where	O
the	O
random	B
variable	I
is	O
the	O
training	O
set	O
alternately	O
the	O
square	O
root	O
of	O
the	O
variance	O
is	O
called	O
the	O
standard	B
error	I
denoted	O
se	O
chapter	O
machine	B
learning	I
basics	O
the	O
variance	O
or	O
the	O
standard	B
error	I
of	O
an	O
estimator	O
provides	O
a	O
measure	O
of	O
how	O
we	O
would	O
expect	O
the	O
estimate	O
we	O
compute	O
from	O
data	O
to	O
vary	O
as	O
we	O
independently	O
resample	O
the	O
dataset	B
from	O
the	O
underlying	O
data	B
generating	I
process	I
just	O
as	O
we	O
might	O
like	O
an	O
estimator	O
to	O
exhibit	O
low	O
bias	O
we	O
would	O
also	O
like	O
it	O
to	O
have	O
relatively	O
low	O
variance	O
when	O
we	O
compute	O
any	O
statistic	B
using	O
a	O
finite	O
number	O
of	O
samples	O
our	O
estimate	O
of	O
the	O
true	O
underlying	O
parameter	O
is	O
uncertain	O
in	O
the	O
sense	O
that	O
we	O
could	O
have	O
obtained	O
other	O
samples	O
from	O
the	O
same	O
distribution	O
and	O
their	O
statistics	O
would	O
have	O
been	O
different	O
the	O
expected	O
degree	O
of	O
variation	O
in	O
any	O
estimator	O
is	O
a	O
source	O
of	O
error	O
that	O
we	O
want	O
to	O
quantify	O
the	O
standard	B
error	I
of	O
the	O
mean	O
is	O
given	O
by	O
se	O
m	O
var	O
m	O
m	O
x	O
m	O
where	O
is	O
the	O
true	O
variance	O
of	O
the	O
samples	O
xi	O
the	O
standard	B
error	I
is	O
often	O
estimated	O
by	O
using	O
an	O
estimate	O
of	O
unfortunately	O
neither	O
the	O
square	O
root	O
of	O
the	O
sample	O
variance	O
nor	O
the	O
square	O
root	O
of	O
the	O
unbiased	B
estimator	O
of	O
the	O
variance	O
provide	O
an	O
unbiased	B
estimate	O
of	O
the	O
standard	B
deviation	I
both	O
approaches	O
tend	O
to	O
underestimate	O
the	O
true	O
standard	B
deviation	I
but	O
are	O
still	O
used	O
in	O
practice	O
the	O
square	O
root	O
of	O
the	O
unbiased	B
estimator	O
of	O
the	O
variance	O
is	O
less	O
of	O
an	O
underestimate	O
for	O
large	O
the	O
approximation	O
is	O
quite	O
reasonable	O
m	O
the	O
standard	B
error	I
of	O
the	O
mean	O
is	O
very	O
useful	O
in	O
machine	B
learning	I
experiments	O
we	O
often	O
estimate	O
the	O
generalization	B
error	O
by	O
computing	O
the	O
sample	B
mean	I
of	O
the	O
error	O
on	O
the	O
test	B
set	I
the	O
number	O
of	O
examples	O
in	O
the	O
test	B
set	I
determines	O
the	O
accuracy	B
of	O
this	O
estimate	O
taking	O
advantage	O
of	O
the	O
central	B
limit	I
theorem	I
which	O
tells	O
us	O
that	O
the	O
mean	O
will	O
be	O
approximately	O
distributed	O
with	O
a	O
normal	O
distribution	O
we	O
can	O
use	O
the	O
standard	B
error	I
to	O
compute	O
the	O
probability	O
that	O
the	O
true	O
expectation	B
falls	O
in	O
any	O
chosen	O
interval	O
for	O
example	B
the	O
confidence	O
interval	O
centered	O
on	O
the	O
mean	O
m	O
is	O
m	O
m	O
m	O
m	O
under	O
the	O
normal	O
distribution	O
with	O
mean	O
m	O
and	O
variance	O
se	O
in	O
machine	B
learning	I
experiments	O
it	O
is	O
common	O
to	O
say	O
that	O
algorithm	O
a	O
is	O
better	O
than	O
algorithm	O
b	O
if	O
the	O
upper	O
bound	B
of	O
the	O
confidence	O
interval	O
for	O
the	O
error	O
of	O
algorithm	O
a	O
is	O
less	O
than	O
the	O
lower	O
bound	B
of	O
the	O
confidence	O
interval	O
for	O
the	O
error	O
of	O
algorithm	O
b	O
chapter	O
machine	B
learning	I
basics	O
example	B
bernoulli	B
distribution	I
we	O
once	O
again	O
consider	O
a	O
set	O
of	O
samples	O
x	O
drawn	O
independently	O
and	O
identically	O
from	O
a	O
bernoulli	B
distribution	I
x	O
this	O
time	O
we	O
are	O
interested	O
in	O
computing	O
px	O
x	O
the	O
variance	O
of	O
the	O
estimator	O
m	O
m	O
var	O
m	O
var	O
x	O
m	O
x	O
m	O
m	O
m	O
m	O
var	O
x	O
m	O
m	O
the	O
variance	O
of	O
the	O
estimator	O
decreases	O
as	O
a	O
function	O
of	O
m	O
the	O
number	O
of	O
examples	O
in	O
the	O
dataset	B
this	O
is	O
a	O
common	O
property	O
of	O
popular	O
estimators	O
that	O
we	O
will	O
return	O
to	O
when	O
we	O
discuss	O
consistency	O
section	O
trading	O
off	O
bias	O
and	O
variance	O
to	O
minimize	O
mean	B
squared	I
error	I
bias	O
and	O
variance	O
measure	O
two	O
different	O
sources	O
of	O
error	O
in	O
an	O
estimator	O
bias	O
measures	O
the	O
expected	O
deviation	O
from	O
the	O
true	O
value	O
of	O
the	O
function	O
or	O
parameter	O
variance	O
on	O
the	O
other	O
hand	O
provides	O
a	O
measure	O
of	O
the	O
deviation	O
from	O
the	O
expected	O
estimator	O
value	O
that	O
any	O
particular	O
sampling	O
of	O
the	O
data	O
is	O
likely	O
to	O
cause	O
what	O
happens	O
when	O
we	O
are	O
given	O
a	O
choice	O
between	O
two	O
estimators	O
one	O
with	O
more	O
bias	O
and	O
one	O
with	O
more	O
variance	O
how	O
do	O
we	O
choose	O
between	O
them	O
for	O
example	B
imagine	O
that	O
we	O
are	O
interested	O
in	O
approximating	O
the	O
function	O
shown	O
in	O
figure	O
and	O
we	O
are	O
only	O
offered	O
the	O
choice	O
between	O
a	O
model	O
with	O
large	O
bias	O
and	O
one	O
that	O
suffers	O
from	O
large	O
variance	O
how	O
do	O
we	O
choose	O
between	O
them	O
the	O
most	O
common	O
way	O
to	O
negotiate	O
this	O
trade-off	O
is	O
to	O
use	O
cross-validation	B
empirically	O
cross-validation	B
is	O
highly	O
successful	O
on	O
many	O
real-world	O
tasks	O
alternatively	O
we	O
can	O
also	O
compare	O
the	O
mean	B
squared	I
error	I
of	O
the	O
estimates	O
mse	O
m	O
bias	O
var	O
m	O
chapter	O
machine	B
learning	I
basics	O
the	O
mse	O
measures	O
the	O
overall	O
expected	O
deviation	O
in	O
a	O
squared	O
error	O
sense	O
between	O
the	O
estimator	O
and	O
the	O
true	O
value	O
of	O
the	O
parameter	O
as	O
is	O
clear	O
from	O
equation	O
evaluating	O
the	O
mse	O
incorporates	O
both	O
the	O
bias	O
and	O
the	O
variance	O
desirable	O
estimators	O
are	O
those	O
with	O
small	O
mse	O
and	O
these	O
are	O
estimators	O
that	O
manage	O
to	O
keep	O
both	O
their	O
bias	O
and	O
variance	O
somewhat	O
in	O
check	O
underfitting	O
zone	O
overfitting	O
zone	O
bias	O
generalization	B
error	O
optimal	O
capacity	O
variance	O
capacity	O
figure	O
as	O
capacity	O
increases	O
bias	O
tends	O
to	O
decrease	O
and	O
variance	O
tends	O
to	O
increase	O
yielding	O
another	O
u-shaped	O
curve	O
for	O
generalization	B
error	O
curve	O
if	O
we	O
vary	O
capacity	O
along	O
one	O
axis	O
there	O
is	O
an	O
optimal	O
capacity	O
with	O
underfitting	O
when	O
the	O
capacity	O
is	O
below	O
this	O
optimum	O
and	O
overfitting	O
when	O
it	O
is	O
above	O
this	O
relationship	O
is	O
similar	O
to	O
the	O
relationship	O
between	O
capacity	O
underfitting	O
and	O
overfitting	O
discussed	O
in	O
section	O
and	O
figure	O
the	O
relationship	O
between	O
bias	O
and	O
variance	O
is	O
tightly	O
linked	O
to	O
the	O
machine	B
learning	I
concepts	O
of	O
capacity	O
underfitting	O
and	O
overfitting	O
in	O
the	O
case	O
where	O
generalization	B
error	O
is	O
measured	O
by	O
the	O
mse	O
bias	O
and	O
variance	O
are	O
meaningful	O
components	O
of	O
generalization	B
error	O
increasing	O
capacity	O
tends	O
to	O
increase	O
variance	O
and	O
decrease	O
bias	O
this	O
is	O
illustrated	O
in	O
figure	O
where	O
we	O
see	O
again	O
the	O
u-shaped	O
curve	O
of	O
generalization	B
error	O
as	O
a	O
function	O
of	O
capacity	O
consistency	O
so	O
far	O
we	O
have	O
discussed	O
the	O
properties	O
of	O
various	O
estimators	O
for	O
a	O
training	O
set	O
of	O
fixed	O
size	O
usually	O
we	O
are	O
also	O
concerned	O
with	O
the	O
behavior	O
of	O
an	O
estimator	O
as	O
the	O
amount	O
of	O
training	O
data	O
grows	O
in	O
particular	O
we	O
usually	O
wish	O
that	O
as	O
the	O
number	O
of	O
data	O
points	O
m	O
in	O
our	O
dataset	B
increases	O
our	O
point	O
estimates	O
converge	O
to	O
the	O
true	O
chapter	O
machine	B
learning	I
basics	O
value	O
of	O
the	O
corresponding	O
parameters	O
more	O
formally	O
we	O
would	O
like	O
that	O
plimm	O
m	O
m	O
as	O
m	O
the	O
symbol	O
plim	O
indicates	O
convergence	O
in	O
probability	O
meaning	O
that	O
for	O
any	O
p	O
is	O
known	O
as	O
consistency	O
it	O
is	O
sometimes	O
referred	O
to	O
as	O
weak	O
consistency	O
with	O
strong	O
consistency	O
referring	O
to	O
the	O
almost	B
sure	I
convergence	I
of	O
to	O
almost	B
sure	I
convergence	I
of	O
a	O
sequence	O
of	O
random	O
variables	O
x	O
x	O
to	O
a	O
value	O
x	O
occurs	O
when	O
plimm	O
the	O
condition	O
described	O
by	O
equation	O
x	O
x	O
consistency	O
ensures	O
that	O
the	O
bias	O
induced	O
by	O
the	O
estimator	O
diminishes	O
as	O
the	O
number	O
of	O
data	O
examples	O
grows	O
however	O
the	O
reverse	O
is	O
not	O
true	O
asymptotic	O
unbiasedness	O
does	O
not	O
imply	O
consistency	O
for	O
example	B
consider	O
estimating	O
the	O
with	O
a	O
dataset	B
consisting	O
mean	O
parameter	O
of	O
a	O
normal	O
distribution	O
we	O
could	O
use	O
the	O
first	O
sample	O
x	O
of	O
the	O
dataset	B
of	O
m	O
samples	O
as	O
an	O
unbiased	B
estimator	O
in	O
that	O
case	O
e	O
m	O
so	O
the	O
estimator	O
is	O
unbiased	B
no	O
matter	O
how	O
many	O
data	O
points	O
are	O
seen	O
this	O
of	O
course	O
implies	O
that	O
the	O
estimate	O
is	O
asymptotically	B
unbiased	B
however	O
this	O
is	O
not	O
a	O
consistent	O
estimator	O
as	O
it	O
is	O
x	O
the	O
case	O
that	O
mas	O
n	O
not	O
m	O
maximum	B
likelihood	I
estimation	O
previously	O
we	O
have	O
seen	O
some	O
definitions	O
of	O
common	O
estimators	O
and	O
analyzed	O
their	O
properties	O
but	O
where	O
did	O
these	O
estimators	O
come	O
from	O
rather	O
than	O
guessing	O
that	O
some	O
function	O
might	O
make	O
a	O
good	O
estimator	O
and	O
then	O
analyzing	O
its	O
bias	O
and	O
variance	O
we	O
would	O
like	O
to	O
have	O
some	O
principle	O
from	O
which	O
we	O
can	O
derive	O
specific	O
functions	O
that	O
are	O
good	O
estimators	O
for	O
different	O
models	O
the	O
most	O
common	O
such	O
principle	O
is	O
the	O
maximum	B
likelihood	I
principle	O
consider	O
a	O
set	O
of	O
m	O
examples	O
x	O
x	O
drawn	O
independently	O
from	O
the	O
true	O
but	O
unknown	O
data	O
generating	O
distribution	O
pdata	O
let	O
pmodelx	O
be	O
a	O
parametric	O
family	O
of	O
probability	O
distributions	O
over	O
the	O
same	O
space	O
indexed	O
by	O
in	O
other	O
words	O
pmodelx	O
maps	O
any	O
configuration	O
x	O
to	O
a	O
real	O
number	O
estimating	O
the	O
true	O
probability	O
pdata	O
the	O
maximum	B
likelihood	I
estimator	O
for	O
is	O
then	O
defined	O
as	O
ml	O
arg	O
max	O
pmodel	O
m	O
arg	O
max	O
pmodelx	O
chapter	O
machine	B
learning	I
basics	O
this	O
product	O
over	O
many	O
probabilities	O
can	O
be	O
inconvenient	O
for	O
a	O
variety	O
of	O
reasons	O
for	O
example	B
it	O
is	O
prone	O
to	O
numerical	O
underflow	O
to	O
obtain	O
a	O
more	O
convenient	O
but	O
equivalent	O
optimization	O
problem	O
we	O
observe	O
that	O
taking	O
the	O
logarithm	O
of	O
the	O
likelihood	O
does	O
not	O
change	O
its	O
arg	O
max	O
but	O
does	O
conveniently	O
transform	O
a	O
product	O
into	O
a	O
sum	O
m	O
ml	O
arg	O
max	O
log	O
pmodelx	O
because	O
the	O
arg	O
max	O
does	O
not	O
change	O
when	O
we	O
rescale	O
the	O
cost	O
function	O
we	O
can	O
divide	O
by	O
m	O
to	O
obtain	O
a	O
version	O
of	O
the	O
criterion	O
that	O
is	O
expressed	O
as	O
an	O
expectation	B
with	O
respect	O
to	O
the	O
empirical	B
distribution	I
pdata	O
defined	O
by	O
the	O
training	O
data	O
ml	O
arg	O
max	O
pdata	O
ex	O
log	O
pmodel	O
one	O
way	O
to	O
interpret	O
maximum	B
likelihood	I
estimation	O
is	O
to	O
view	O
it	O
as	O
minimizing	O
the	O
dissimilarity	O
between	O
the	O
empirical	B
distribution	I
pdata	O
defined	O
by	O
the	O
training	O
set	O
and	O
the	O
model	O
distribution	O
with	O
the	O
degree	O
of	O
dissimilarity	O
between	O
the	O
two	O
measured	O
by	O
the	O
kl	O
divergence	O
the	O
kl	O
divergence	O
is	O
given	O
by	O
dkl	O
pdata	O
pmodel	O
e	O
x	O
pdata	O
pdata	O
x	O
log	O
pmodel	O
the	O
term	O
on	O
the	O
left	O
is	O
a	O
function	O
only	O
of	O
the	O
data	B
generating	I
process	I
not	O
the	O
model	O
this	O
means	O
when	O
we	O
train	O
the	O
model	O
to	O
minimize	O
the	O
kl	O
divergence	O
we	O
need	O
only	O
minimize	O
pmodel	O
ex	O
pdata	O
which	O
is	O
of	O
course	O
the	O
same	O
as	O
the	O
maximization	O
in	O
equation	O
minimizing	O
this	O
kl	O
divergence	O
corresponds	O
exactly	O
to	O
minimizing	O
the	O
crossentropy	O
between	O
the	O
distributions	O
many	O
authors	O
use	O
the	O
term	O
cross-entropy	B
to	O
identify	O
specifically	O
the	O
negative	O
log-likelihood	O
of	O
a	O
bernoulli	O
or	O
softmax	O
distribution	O
but	O
that	O
is	O
a	O
misnomer	O
any	O
loss	O
consisting	O
of	O
a	O
negative	O
log-likelihood	O
is	O
a	O
crossentropy	O
between	O
the	O
empirical	B
distribution	I
defined	O
by	O
the	O
training	O
set	O
and	O
the	O
probability	B
distribution	I
defined	O
by	O
model	O
for	O
example	B
mean	B
squared	I
error	I
is	O
the	O
cross-entropy	B
between	O
the	O
empirical	B
distribution	I
and	O
a	O
gaussian	O
model	O
we	O
can	O
thus	O
see	O
maximum	B
likelihood	I
as	O
an	O
attempt	O
to	O
make	O
the	O
model	O
distribution	O
match	O
the	O
empirical	B
distribution	I
pdata	O
ideally	O
we	O
would	O
like	O
to	O
match	O
the	O
true	O
data	O
generating	O
distribution	O
pdata	O
but	O
we	O
have	O
no	O
direct	O
access	O
to	O
this	O
distribution	O
while	O
the	O
optimal	O
is	O
the	O
same	O
regardless	O
of	O
whether	O
we	O
are	O
maximizing	O
the	O
likelihood	O
or	O
minimizing	O
the	O
kl	O
divergence	O
the	O
values	O
of	O
the	O
objective	O
functions	O
ml	O
arg	O
max	O
p	O
y	O
x	O
chapter	O
machine	B
learning	I
basics	O
are	O
different	O
in	O
software	O
we	O
often	O
phrase	O
both	O
as	O
minimizing	O
a	O
cost	O
function	O
maximum	B
likelihood	I
thus	O
becomes	O
minimization	O
of	O
the	O
negative	O
log-likelihood	O
or	O
equivalently	O
minimization	O
of	O
the	O
cross	O
entropy	O
the	O
perspective	O
of	O
maximum	B
likelihood	I
as	O
minimum	O
kl	O
divergence	O
becomes	O
helpful	O
in	O
this	O
case	O
because	O
the	O
kl	O
divergence	O
has	O
a	O
known	O
minimum	O
value	O
of	O
zero	O
the	O
negative	O
log-likelihood	O
can	O
actually	O
become	O
negative	O
when	O
is	O
real-valued	O
x	O
conditional	O
log-likelihood	O
and	O
mean	B
squared	I
error	I
the	O
maximum	B
likelihood	I
estimator	O
can	O
readily	O
be	O
generalized	O
to	O
the	O
case	O
where	O
our	O
goal	O
is	O
to	O
estimate	O
a	O
conditional	B
probability	I
py	O
x	O
in	O
order	O
to	O
predict	O
y	O
given	O
x	O
this	O
is	O
actually	O
the	O
most	O
common	O
situation	O
because	O
it	O
forms	O
the	O
basis	O
for	O
most	O
supervised	B
learning	I
if	O
x	O
represents	O
all	O
our	O
inputs	O
and	O
y	O
all	O
our	O
observed	O
targets	O
then	O
the	O
conditional	O
maximum	B
likelihood	I
estimator	O
is	O
if	O
the	O
examples	O
are	O
assumed	O
to	O
be	O
i	O
i	O
d	O
then	O
this	O
can	O
be	O
decomposed	O
into	O
m	O
ml	O
arg	O
max	O
log	O
y	O
x	O
example	B
linear	O
regression	B
as	O
maximum	B
likelihood	I
linear	O
regression	B
introduced	O
earlier	O
in	O
section	O
may	O
be	O
justified	O
as	O
a	O
maximum	B
likelihood	I
procedure	O
previously	O
we	O
motivated	O
linear	O
regression	B
as	O
an	O
algorithm	O
that	O
learns	O
to	O
take	O
an	O
input	O
x	O
and	O
produce	O
an	O
output	O
value	O
y	O
the	O
mapping	O
from	O
x	O
to	O
y	O
is	O
chosen	O
to	O
minimize	O
mean	B
squared	I
error	I
a	O
criterion	O
that	O
we	O
introduced	O
more	O
or	O
less	O
arbitrarily	O
we	O
now	O
revisit	O
linear	O
regression	B
from	O
the	O
point	O
of	O
view	O
of	O
maximum	B
likelihood	I
estimation	O
instead	O
of	O
producing	O
a	O
single	O
prediction	O
y	O
we	O
now	O
think	O
of	O
the	O
model	O
as	O
producing	O
a	O
conditional	O
distribution	O
py	O
x	O
we	O
can	O
imagine	O
that	O
with	O
an	O
infinitely	O
large	O
training	O
set	O
we	O
might	O
see	O
several	O
training	O
examples	O
with	O
the	O
same	O
input	O
value	O
x	O
but	O
different	O
values	O
of	O
y	O
the	O
goal	O
of	O
the	O
learning	O
algorithm	O
is	O
now	O
to	O
fit	O
the	O
distribution	O
p	O
x	O
to	O
all	O
of	O
those	O
different	O
y	O
values	O
n	O
that	O
are	O
all	O
compatible	O
with	O
x	O
to	O
derive	O
the	O
same	O
linear	O
regression	B
algorithm	O
yx	O
w	O
the	O
function	O
yx	O
w	O
we	O
obtained	O
before	O
we	O
define	O
py	O
gives	O
the	O
prediction	O
of	O
the	O
mean	O
of	O
the	O
gaussian	O
in	O
this	O
example	B
we	O
assume	O
that	O
the	O
variance	O
is	O
fixed	O
to	O
some	O
constant	O
chosen	O
by	O
the	O
user	O
we	O
will	O
see	O
that	O
this	O
choice	O
of	O
the	O
functional	O
form	O
of	O
py	O
x	O
causes	O
the	O
maximum	B
likelihood	I
estimation	O
procedure	O
to	O
yield	O
the	O
same	O
learning	O
algorithm	O
as	O
we	O
developed	O
before	O
since	O
the	O
x	O
m	O
log	O
y	O
x	O
m	O
log	O
m	O
m	O
y	O
y	O
is	O
chapter	O
machine	B
learning	I
basics	O
examples	O
are	O
assumed	O
to	O
be	O
i	O
i	O
d	O
the	O
conditional	O
log-likelihood	O
given	O
by	O
where	O
y	O
is	O
the	O
output	O
of	O
the	O
linear	O
regression	B
on	O
the	O
i-th	O
input	O
x	O
and	O
m	O
is	O
the	O
number	O
of	O
the	O
training	O
examples	O
comparing	O
the	O
log-likelihood	O
with	O
the	O
mean	B
squared	I
error	I
msetrain	O
m	O
m	O
y	O
y	O
we	O
immediately	O
see	O
that	O
maximizing	O
the	O
log-likelihood	O
with	O
respect	O
to	O
w	O
yields	O
the	O
same	O
estimate	O
of	O
the	O
parameters	O
w	O
as	O
does	O
minimizing	O
the	O
mean	B
squared	I
error	I
the	O
two	O
criteria	O
have	O
different	O
values	O
but	O
the	O
same	O
location	O
of	O
the	O
optimum	O
this	O
justifies	O
the	O
use	O
of	O
the	O
mse	O
as	O
a	O
maximum	B
likelihood	I
estimation	O
procedure	O
as	O
we	O
will	O
see	O
the	O
maximum	B
likelihood	I
estimator	O
has	O
several	O
desirable	O
properties	O
properties	O
of	O
maximum	B
likelihood	I
the	O
main	O
appeal	O
of	O
the	O
maximum	B
likelihood	I
estimator	O
is	O
that	O
it	O
can	O
be	O
shown	O
to	O
be	O
the	O
best	O
estimator	O
asymptotically	O
as	O
the	O
number	O
of	O
examples	O
m	O
in	O
terms	O
of	O
its	O
rate	O
of	O
convergence	O
as	O
increases	O
m	O
under	O
appropriate	O
conditions	O
the	O
maximum	B
likelihood	I
estimator	O
has	O
the	O
property	O
of	O
consistency	O
section	O
above	O
meaning	O
that	O
as	O
the	O
number	O
of	O
training	O
examples	O
approaches	O
infinity	O
the	O
maximum	B
likelihood	I
estimate	O
of	O
a	O
parameter	O
converges	O
to	O
the	O
true	O
value	O
of	O
the	O
parameter	O
these	O
conditions	O
are	O
the	O
true	O
distribution	O
pdata	O
must	O
lie	O
within	O
the	O
model	O
family	O
pmodel	O
otherwise	O
no	O
estimator	O
can	O
recover	O
pdata	O
the	O
true	O
distribution	O
pdata	O
must	O
correspond	O
to	O
exactly	O
one	O
value	O
of	O
otherwise	O
maximum	B
likelihood	I
can	O
recover	O
the	O
correct	O
pdata	O
but	O
will	O
not	O
be	O
able	O
to	O
determine	O
which	O
value	O
of	O
was	O
used	O
by	O
the	O
data	O
generating	O
processing	O
there	O
are	O
other	O
inductive	O
principles	O
besides	O
the	O
maximum	B
likelihood	I
estimator	O
many	O
of	O
which	O
share	O
the	O
property	O
of	O
being	O
consistent	O
estimators	O
however	O
chapter	O
machine	B
learning	I
basics	O
consistent	O
estimators	O
can	O
differ	O
in	O
their	O
statistic	B
efficiency	O
meaning	O
that	O
one	O
consistent	O
estimator	O
may	O
obtain	O
lower	O
generalization	B
error	O
for	O
a	O
fixed	O
number	O
of	O
samples	O
m	O
or	O
equivalently	O
may	O
require	O
fewer	O
examples	O
to	O
obtain	O
a	O
fixed	O
level	O
of	O
generalization	B
error	O
statistical	O
efficiency	O
is	O
typically	O
studied	O
in	O
the	O
parametric	O
case	O
in	O
linear	O
regression	B
where	O
our	O
goal	O
is	O
to	O
estimate	O
the	O
value	O
of	O
a	O
parameter	O
assuming	O
it	O
is	O
possible	O
to	O
identify	O
the	O
true	O
parameter	O
not	O
the	O
value	O
of	O
a	O
function	O
a	O
way	O
to	O
measure	O
how	O
close	O
we	O
are	O
to	O
the	O
true	O
parameter	O
is	O
by	O
the	O
expected	O
mean	B
squared	I
error	I
computing	O
the	O
squared	O
difference	O
between	O
the	O
estimated	O
and	O
true	O
parameter	O
values	O
where	O
the	O
expectation	B
is	O
over	O
m	O
training	O
samples	O
from	O
the	O
data	O
generating	O
distribution	O
that	O
parametric	O
mean	B
squared	I
error	I
decreases	O
as	O
m	O
increases	O
and	O
for	O
m	O
large	O
the	O
cram	O
r-rao	O
lower	O
bound	B
shows	O
that	O
no	O
consistent	O
estimator	O
has	O
a	O
lower	O
mean	B
squared	I
error	I
than	O
the	O
maximum	B
likelihood	I
estimator	O
rao	O
cram	O
r	O
for	O
these	O
reasons	O
and	O
efficiency	O
maximum	B
likelihood	I
is	O
often	O
considered	O
the	O
preferred	O
estimator	O
to	O
use	O
for	O
machine	B
learning	I
when	O
the	O
number	O
of	O
examples	O
is	O
small	O
enough	O
to	O
yield	O
overfitting	O
behavior	O
regularization	O
strategies	O
such	O
as	O
weight	O
decay	O
may	O
be	O
used	O
to	O
obtain	O
a	O
biased	O
version	O
of	O
maximum	B
likelihood	I
that	O
has	O
less	O
variance	O
when	O
training	O
data	O
is	O
limited	O
bayesian	B
statistics	I
so	O
far	O
we	O
have	O
discussed	O
frequentist	B
statistics	I
and	O
approaches	O
based	O
on	O
estimating	O
a	O
single	O
value	O
of	O
then	O
making	O
all	O
predictions	O
thereafter	O
based	O
on	O
that	O
one	O
estimate	O
another	O
approach	O
is	O
to	O
consider	O
all	O
possible	O
values	O
of	O
when	O
making	O
a	O
prediction	O
the	O
latter	O
is	O
the	O
domain	O
of	O
bayesian	B
statistics	I
as	O
discussed	O
in	O
section	O
the	O
frequentist	O
perspective	O
is	O
that	O
the	O
true	O
parameter	O
value	O
is	O
fixed	O
but	O
unknown	O
while	O
the	O
point	O
estimate	O
is	O
a	O
random	B
variable	I
on	O
account	O
of	O
it	O
being	O
a	O
function	O
of	O
the	O
dataset	B
is	O
seen	O
as	O
random	O
the	O
bayesian	O
perspective	O
on	O
statistics	O
is	O
quite	O
different	O
the	O
bayesian	O
uses	O
probability	O
to	O
reflect	O
degrees	O
of	O
certainty	O
of	O
states	O
of	O
knowledge	O
the	O
dataset	B
is	O
directly	O
observed	O
and	O
so	O
is	O
not	O
random	O
on	O
the	O
other	O
hand	O
the	O
true	O
parameter	O
is	O
unknown	O
or	O
uncertain	O
and	O
thus	O
is	O
represented	O
as	O
a	O
random	B
variable	I
before	O
observing	O
the	O
data	O
we	O
represent	O
our	O
knowledge	O
of	O
using	O
the	O
prior	B
probability	B
distribution	I
p	O
referred	O
to	O
as	O
simply	O
the	O
prior	O
generally	O
the	O
machine	B
learning	I
practitioner	O
selects	O
a	O
prior	O
distribution	O
that	O
is	O
quite	O
broad	O
with	O
high	O
entropy	O
to	O
reflect	O
a	O
high	O
degree	O
of	O
uncertainty	O
in	O
the	O
chapter	O
machine	B
learning	I
basics	O
value	O
of	O
before	O
observing	O
any	O
data	O
for	O
example	B
one	O
might	O
assume	O
that	O
lies	O
in	O
some	O
finite	O
range	O
or	O
volume	O
with	O
a	O
uniform	B
distribution	I
many	O
priors	O
instead	O
reflect	O
a	O
preference	O
for	O
simpler	O
solutions	O
as	O
smaller	O
magnitude	O
coefficients	O
or	O
a	O
function	O
that	O
is	O
closer	O
to	O
being	O
constant	O
x	O
we	O
can	O
recover	O
the	O
effect	O
of	O
data	O
on	O
our	O
belief	O
about	O
by	O
combining	O
the	O
data	O
likelihood	O
p	O
x	O
x	O
now	O
consider	O
that	O
we	O
have	O
a	O
set	O
of	O
data	O
samples	O
with	O
the	O
prior	O
via	O
bayes	O
rule	O
a	O
priori	O
p	O
x	O
x	O
p	O
x	O
x	O
p	O
x	O
x	O
in	O
the	O
scenarios	O
where	O
bayesian	O
estimation	O
is	O
typically	O
used	O
the	O
prior	O
begins	O
as	O
a	O
relatively	O
uniform	O
or	O
gaussian	O
distribution	O
with	O
high	O
entropy	O
and	O
the	O
observation	O
of	O
the	O
data	O
usually	O
causes	O
the	O
posterior	O
to	O
lose	O
entropy	O
and	O
concentrate	O
around	O
a	O
few	O
highly	O
likely	O
values	O
of	O
the	O
parameters	O
relative	O
to	O
maximum	B
likelihood	I
estimation	O
bayesian	O
estimation	O
offers	O
two	O
important	O
differences	O
first	O
unlike	O
the	O
maximum	B
likelihood	I
approach	O
that	O
makes	O
predictions	O
using	O
a	O
point	O
estimate	O
of	O
the	O
bayesian	O
approach	O
is	O
to	O
make	O
predictions	O
using	O
a	O
full	O
distribution	O
over	O
for	O
example	B
after	O
observing	O
m	O
examples	O
the	O
predicted	O
distribution	O
over	O
the	O
next	O
data	O
sample	O
x	O
is	O
given	O
by	O
p	O
x	O
x	O
p	O
x	O
x	O
d	O
here	O
each	O
value	O
of	O
with	O
positive	O
probability	O
density	O
contributes	O
to	O
the	O
prediction	O
of	O
the	O
next	O
example	B
with	O
the	O
contribution	O
weighted	O
by	O
the	O
posterior	O
density	O
itself	O
after	O
having	O
observed	O
if	O
we	O
are	O
still	O
quite	O
uncertain	O
about	O
the	O
value	O
of	O
then	O
this	O
uncertainty	O
is	O
incorporated	O
directly	O
into	O
any	O
predictions	O
we	O
might	O
make	O
x	O
in	O
section	O
we	O
discussed	O
how	O
the	O
frequentist	O
approach	O
addresses	O
the	O
uncertainty	O
in	O
a	O
given	O
point	O
estimate	O
of	O
by	O
evaluating	O
its	O
variance	O
the	O
variance	O
of	O
the	O
estimator	O
is	O
an	O
assessment	O
of	O
how	O
the	O
estimate	O
might	O
change	O
with	O
alternative	O
samplings	O
of	O
the	O
observed	O
data	O
the	O
bayesian	O
answer	O
to	O
the	O
question	O
of	O
how	O
to	O
deal	O
with	O
the	O
uncertainty	O
in	O
the	O
estimator	O
is	O
to	O
simply	O
integrate	O
over	O
it	O
which	O
tends	O
to	O
protect	O
well	O
against	O
overfitting	O
this	O
integral	O
is	O
of	O
course	O
just	O
an	O
application	O
of	O
the	O
laws	O
of	O
probability	O
making	O
the	O
bayesian	O
approach	O
simple	O
to	O
justify	O
while	O
the	O
frequentist	O
machinery	O
for	O
constructing	O
an	O
estimator	O
is	O
based	O
on	O
the	O
rather	O
ad	O
hoc	O
decision	O
to	O
summarize	O
all	O
knowledge	O
contained	O
in	O
the	O
dataset	B
with	O
a	O
single	O
point	O
estimate	O
the	O
second	O
important	O
difference	O
between	O
the	O
bayesian	O
approach	O
to	O
estimation	O
and	O
the	O
maximum	B
likelihood	I
approach	O
is	O
due	O
to	O
the	O
contribution	O
of	O
the	O
bayesian	O
chapter	O
machine	B
learning	I
basics	O
prior	O
distribution	O
the	O
prior	O
has	O
an	O
influence	O
by	O
shifting	O
probability	O
mass	O
density	O
towards	O
regions	O
of	O
the	O
parameter	O
space	O
that	O
are	O
preferred	O
in	O
practice	O
the	O
prior	O
often	O
expresses	O
a	O
preference	O
for	O
models	O
that	O
are	O
simpler	O
or	O
more	O
smooth	O
critics	O
of	O
the	O
bayesian	O
approach	O
identify	O
the	O
prior	O
as	O
a	O
source	O
of	O
subjective	O
human	O
judgment	O
impacting	O
the	O
predictions	O
a	O
priori	O
bayesian	O
methods	O
typically	O
generalize	O
much	O
better	O
when	O
limited	O
training	O
data	O
is	O
available	O
but	O
typically	O
suffer	O
from	O
high	O
computational	O
cost	O
when	O
the	O
number	O
of	O
training	O
examples	O
is	O
large	O
example	B
bayesian	O
linear	O
regression	B
here	O
we	O
consider	O
the	O
bayesian	O
estimation	O
approach	O
to	O
learning	O
the	O
linear	O
regression	B
parameters	O
in	O
linear	O
regression	B
we	O
learn	O
a	O
linear	O
mapping	O
from	O
an	O
input	O
vector	O
x	O
n	O
to	O
predict	O
the	O
value	O
of	O
a	O
scalar	O
the	O
prediction	O
is	O
parametrized	O
by	O
the	O
vector	O
w	O
r	O
y	O
n	O
r	O
r	O
given	O
a	O
set	O
of	O
m	O
training	O
samples	O
of	O
over	O
the	O
entire	O
training	O
set	O
as	O
y	O
train	O
y	O
train	O
we	O
can	O
express	O
the	O
prediction	O
y	O
w	O
x	O
y	O
train	O
x	O
train	O
w	O
n	O
y	O
exp	O
expressed	O
as	O
a	O
gaussian	O
conditional	O
distribution	O
on	O
y	O
train	O
we	O
have	O
train	O
py	O
x	O
train	O
w	O
train	O
x	O
train	O
w	O
i	O
train	O
x	O
train	O
w	O
train	O
x	O
train	O
w	O
where	O
we	O
follow	O
the	O
standard	O
mse	O
formulation	O
in	O
assuming	O
that	O
the	O
gaussian	O
variance	O
on	O
y	O
is	O
one	O
in	O
what	O
follows	O
to	O
reduce	O
the	O
notational	O
burden	O
we	O
refer	O
to	O
as	O
simply	O
x	O
y	O
train	O
y	O
train	O
to	O
determine	O
the	O
posterior	O
distribution	O
over	O
the	O
model	O
parameter	O
vector	O
w	O
we	O
first	O
need	O
to	O
specify	O
a	O
prior	O
distribution	O
the	O
prior	O
should	O
reflect	O
our	O
naive	O
belief	O
about	O
the	O
value	O
of	O
these	O
parameters	O
while	O
it	O
is	O
sometimes	O
difficult	O
or	O
unnatural	O
to	O
express	O
our	O
prior	O
beliefs	O
in	O
terms	O
of	O
the	O
parameters	O
of	O
the	O
model	O
in	O
practice	O
we	O
typically	O
assume	O
a	O
fairly	O
broad	O
distribution	O
expressing	O
a	O
high	O
degree	O
of	O
uncertainty	O
about	O
for	O
real-valued	O
parameters	O
it	O
is	O
common	O
to	O
use	O
a	O
gaussian	O
as	O
a	O
prior	O
distribution	O
n	O
w	O
p	O
w	O
exp	O
chapter	O
machine	B
learning	I
basics	O
where	O
and	O
are	O
the	O
prior	O
distribution	O
mean	O
vector	O
and	O
covariance	B
matrix	I
respectively	O
distribution	O
over	O
the	O
model	O
parameters	O
with	O
the	O
prior	O
thus	O
specified	O
we	O
can	O
now	O
proceed	O
in	O
determining	O
the	O
posterior	O
p	O
x	O
y	O
p	O
x	O
exp	O
p	O
w	O
y	O
xw	O
y	O
xw	O
exp	O
exp	O
xw	O
w	O
x	O
xw	O
w	O
w	O
w	O
we	O
now	O
define	O
m	O
using	O
these	O
new	O
variables	O
we	O
find	O
that	O
the	O
posterior	O
may	O
be	O
rewritten	O
as	O
a	O
gaussian	O
distribution	O
x	O
x	O
x	O
and	O
m	O
m	O
y	O
y	O
p	O
x	O
exp	O
exp	O
m	O
m	O
m	O
m	O
m	O
m	O
m	O
m	O
m	O
all	O
terms	O
that	O
do	O
not	O
include	O
the	O
parameter	O
vector	O
w	O
have	O
been	O
omitted	O
they	O
are	O
implied	O
by	O
the	O
fact	O
that	O
the	O
distribution	O
must	O
be	O
normalized	O
to	O
integrate	O
to	O
equation	O
shows	O
how	O
to	O
normalize	O
a	O
multivariate	O
gaussian	O
distribution	O
examining	O
this	O
posterior	O
distribution	O
allows	O
us	O
to	O
gain	O
some	O
intuition	O
for	O
the	O
effect	O
of	O
bayesian	O
inference	O
in	O
most	O
situations	O
we	O
set	O
to	O
if	O
we	O
set	O
i	O
then	O
m	O
gives	O
the	O
same	O
estimate	O
of	O
w	O
as	O
does	O
frequentist	O
linear	O
regression	B
with	O
a	O
weight	O
decay	O
penalty	O
of	O
w	O
w	O
one	O
difference	O
is	O
that	O
the	O
bayesian	O
estimate	O
is	O
undefined	O
if	O
is	O
set	O
to	O
zero	O
are	O
not	O
allowed	O
to	O
begin	O
the	O
bayesian	O
learning	O
process	O
with	O
an	O
infinitely	O
wide	O
prior	O
on	O
w	O
the	O
more	O
important	O
difference	O
is	O
that	O
the	O
bayesian	O
estimate	O
provides	O
a	O
covariance	B
matrix	I
showing	O
how	O
likely	O
all	O
the	O
different	O
values	O
of	O
are	O
rather	O
than	O
providing	O
only	O
the	O
estimate	O
w	O
m	O
maximum	O
a	O
posteriori	O
estimation	O
while	O
the	O
most	O
principled	O
approach	O
is	O
to	O
make	O
predictions	O
using	O
the	O
full	O
bayesian	O
posterior	O
distribution	O
over	O
the	O
parameter	O
it	O
is	O
still	O
often	O
desirable	O
to	O
have	O
a	O
unless	O
there	O
is	O
a	O
reason	O
to	O
assume	O
a	O
particular	O
covariance	O
structure	O
we	O
typically	O
assume	O
a	O
diagonal	O
covariance	B
matrix	I
diag	O
chapter	O
machine	B
learning	I
basics	O
map	O
arg	O
max	O
x	O
p	O
p	O
x	O
single	O
point	O
estimate	O
one	O
common	O
reason	O
for	O
desiring	O
a	O
point	O
estimate	O
is	O
that	O
most	O
operations	O
involving	O
the	O
bayesian	O
posterior	O
for	O
most	O
interesting	O
models	O
are	O
intractable	O
and	O
a	O
point	O
estimate	O
offers	O
a	O
tractable	O
approximation	O
rather	O
than	O
simply	O
returning	O
to	O
the	O
maximum	B
likelihood	I
estimate	O
we	O
can	O
still	O
gain	O
some	O
of	O
the	O
benefit	O
of	O
the	O
bayesian	O
approach	O
by	O
allowing	O
the	O
prior	O
to	O
influence	O
the	O
choice	O
of	O
the	O
point	O
estimate	O
one	O
rational	O
way	O
to	O
do	O
this	O
is	O
to	O
choose	O
the	O
maximum	O
a	O
posteriori	O
point	O
estimate	O
the	O
map	O
estimate	O
chooses	O
the	O
point	O
of	O
maximal	O
posterior	O
probability	O
maximal	O
probability	O
density	O
in	O
the	O
more	O
common	O
case	O
of	O
continuous	O
arg	O
max	O
log	O
log	O
p	O
we	O
recognize	O
above	O
on	O
the	O
right	O
hand	O
side	O
log	O
px	O
likelihood	O
term	O
and	O
corresponding	O
to	O
the	O
prior	O
distribution	O
log	O
i	O
e	O
the	O
standard	O
log	O
n	O
as	O
an	O
example	B
consider	O
a	O
linear	O
regression	B
model	O
with	O
a	O
gaussian	O
prior	O
on	O
i	O
then	O
the	O
log-prior	O
term	O
in	O
the	O
weights	B
w	O
if	O
this	O
prior	O
is	O
given	O
by	O
w	O
weight	O
decay	O
penalty	O
plus	O
a	O
equation	O
term	O
that	O
does	O
not	O
depend	O
on	O
w	O
and	O
does	O
not	O
affect	O
the	O
learning	O
process	O
map	O
bayesian	O
inference	O
with	O
a	O
gaussian	O
prior	O
on	O
the	O
weights	B
thus	O
corresponds	O
to	O
weight	O
decay	O
is	O
proportional	O
to	O
the	O
familiar	O
w	O
as	O
with	O
full	O
bayesian	O
inference	O
map	O
bayesian	O
inference	O
has	O
the	O
advantage	O
of	O
leveraging	O
information	O
that	O
is	O
brought	O
by	O
the	O
prior	O
and	O
cannot	O
be	O
found	O
in	O
the	O
training	O
data	O
this	O
additional	O
information	O
helps	O
to	O
reduce	O
the	O
variance	O
in	O
the	O
map	O
point	O
estimate	O
comparison	O
to	O
the	O
ml	O
estimate	O
however	O
it	O
does	O
so	O
at	O
the	O
price	O
of	O
increased	O
bias	O
many	O
regularized	O
estimation	O
strategies	O
such	O
as	O
maximum	B
likelihood	I
learning	O
regularized	O
with	O
weight	O
decay	O
can	O
be	O
interpreted	O
as	O
making	O
the	O
map	O
approximation	O
to	O
bayesian	O
inference	O
this	O
view	O
applies	O
when	O
the	O
regularization	O
consists	O
of	O
adding	O
an	O
extra	O
term	O
to	O
the	O
objective	B
function	I
that	O
corresponds	O
to	O
log	O
p	O
not	O
all	O
regularization	O
penalties	O
correspond	O
to	O
map	O
bayesian	O
inference	O
for	O
example	B
some	O
regularizer	B
terms	O
may	O
not	O
be	O
the	O
logarithm	O
of	O
a	O
probability	B
distribution	I
other	O
regularization	O
terms	O
depend	O
on	O
the	O
data	O
which	O
of	O
course	O
a	O
prior	B
probability	B
distribution	I
is	O
not	O
allowed	O
to	O
do	O
map	O
bayesian	O
inference	O
provides	O
a	O
straightforward	O
way	O
to	O
design	O
complicated	O
yet	O
interpretable	O
regularization	O
terms	O
for	O
example	B
a	O
more	O
complicated	O
penalty	O
term	O
can	O
be	O
derived	O
by	O
using	O
a	O
mixture	O
of	O
gaussians	O
rather	O
than	O
a	O
single	O
gaussian	O
distribution	O
as	O
the	O
prior	O
and	O
hinton	O
chapter	O
machine	B
learning	I
basics	O
supervised	B
learning	I
algorithms	O
recall	B
from	O
section	O
that	O
supervised	B
learning	I
algorithms	O
are	O
roughly	O
speaking	O
learning	O
algorithms	O
that	O
learn	O
to	O
associate	O
some	O
input	O
with	O
some	O
output	O
given	O
a	O
training	O
set	O
of	O
examples	O
of	O
inputs	O
x	O
and	O
outputs	O
y	O
in	O
many	O
cases	O
the	O
outputs	O
y	O
may	O
be	O
difficult	O
to	O
collect	O
automatically	O
and	O
must	O
be	O
provided	O
by	O
a	O
human	O
supervisor	O
but	O
the	O
term	O
still	O
applies	O
even	O
when	O
the	O
training	O
set	O
targets	O
were	O
collected	O
automatically	O
probabilistic	O
supervised	B
learning	I
most	O
supervised	B
learning	I
algorithms	O
in	O
this	O
book	O
are	O
based	O
on	O
estimating	O
a	O
probability	B
distribution	I
p	O
y	O
x	O
we	O
can	O
do	O
this	O
simply	O
by	O
using	O
maximum	B
likelihood	I
estimation	O
to	O
find	O
the	O
best	O
parameter	O
vector	O
for	O
a	O
parametric	O
family	O
of	O
distributions	O
x	O
p	O
y	O
we	O
have	O
already	O
seen	O
that	O
linear	O
regression	B
corresponds	O
to	O
the	O
family	O
n	O
x	O
p	O
y	O
y	O
x	O
i	O
we	O
can	O
generalize	O
linear	O
regression	B
to	O
the	O
classification	B
scenario	O
by	O
defining	O
a	O
different	O
family	O
of	O
probability	O
distributions	O
if	O
we	O
have	O
two	O
classes	O
class	O
and	O
class	O
then	O
we	O
need	O
only	O
specify	O
the	O
probability	O
of	O
one	O
of	O
these	O
classes	O
the	O
probability	O
of	O
class	O
determines	O
the	O
probability	O
of	O
class	O
because	O
these	O
two	O
values	O
must	O
add	O
up	O
to	O
the	O
normal	O
distribution	O
over	O
real-valued	O
numbers	O
that	O
we	O
used	O
for	O
linear	O
regression	B
is	O
parametrized	O
in	O
terms	O
of	O
a	O
mean	O
any	O
value	O
we	O
supply	O
for	O
this	O
mean	O
is	O
valid	O
a	O
distribution	O
over	O
a	O
binary	O
variable	O
is	O
slightly	O
more	O
complicated	O
because	O
its	O
mean	O
must	O
always	O
be	O
between	O
and	O
one	O
way	O
to	O
solve	O
this	O
problem	O
is	O
to	O
use	O
the	O
logistic	O
sigmoid	O
function	O
to	O
squash	O
the	O
output	O
of	O
the	O
linear	O
function	O
into	O
the	O
interval	O
and	O
interpret	O
that	O
value	O
as	O
a	O
probability	O
p	O
y	O
x	O
x	O
this	O
approach	O
is	O
known	O
as	O
logistic	O
regression	B
somewhat	O
strange	O
name	O
since	O
we	O
use	O
the	O
model	O
for	O
classification	B
rather	O
than	O
regression	B
in	O
the	O
case	O
of	O
linear	O
regression	B
we	O
were	O
able	O
to	O
find	O
the	O
optimal	O
weights	B
by	O
solving	O
the	O
normal	O
equations	O
logistic	O
regression	B
is	O
somewhat	O
more	O
difficult	O
there	O
is	O
no	O
closed-form	O
solution	O
for	O
its	O
optimal	O
weights	B
instead	O
we	O
must	O
search	O
for	O
them	O
by	O
maximizing	O
the	O
log-likelihood	O
we	O
can	O
do	O
this	O
by	O
minimizing	O
the	O
negative	O
log-likelihood	O
using	O
gradient	B
descent	O
chapter	O
machine	B
learning	I
basics	O
this	O
same	O
strategy	O
can	O
be	O
applied	O
to	O
essentially	O
any	O
supervised	B
learning	I
problem	O
by	O
writing	O
down	O
a	O
parametric	O
family	O
of	O
conditional	B
probability	I
distributions	O
over	O
the	O
right	O
kind	O
of	O
input	O
and	O
output	O
variables	O
support	O
vector	O
machines	O
boser	O
et	O
al	O
cortes	O
and	O
vapnik	O
one	O
of	O
the	O
most	O
influential	O
approaches	O
to	O
supervised	B
learning	I
is	O
the	O
support	O
vector	O
this	O
model	O
is	O
similar	O
to	O
machine	O
logistic	O
regression	B
in	O
that	O
it	O
is	O
driven	O
by	O
a	O
linear	O
function	O
w	O
x	O
b	O
unlike	O
logistic	O
regression	B
the	O
support	B
vector	I
machine	I
does	O
not	O
provide	O
probabilities	O
but	O
only	O
outputs	O
a	O
class	O
identity	O
the	O
svm	O
predicts	O
that	O
the	O
positive	O
class	O
is	O
present	O
when	O
x	O
b	O
is	O
positive	O
likewise	O
it	O
predicts	O
that	O
the	O
negative	O
class	O
is	O
present	O
when	O
w	O
w	O
x	O
b	O
is	O
negative	O
one	O
key	O
innovation	O
associated	O
with	O
support	O
vector	O
machines	O
is	O
the	O
kernel	B
trick	B
the	O
kernel	B
trick	B
consists	O
of	O
observing	O
that	O
many	O
machine	B
learning	I
algorithms	O
can	O
be	O
written	O
exclusively	O
in	O
terms	O
of	O
dot	O
products	O
between	O
examples	O
for	O
example	B
it	O
can	O
be	O
shown	O
that	O
the	O
linear	O
function	O
used	O
by	O
the	O
support	B
vector	I
machine	I
can	O
be	O
re-written	O
as	O
w	O
x	O
b	O
b	O
ix	O
m	O
x	O
where	O
x	O
is	O
a	O
training	O
example	B
and	O
is	O
a	O
vector	O
of	O
coefficients	O
rewriting	O
the	O
learning	O
algorithm	O
this	O
way	O
allows	O
us	O
to	O
replace	O
x	O
by	O
the	O
output	O
of	O
a	O
given	O
feature	B
called	O
function	O
and	O
the	O
dot	O
product	O
with	O
a	O
function	O
kx	O
x	O
a	O
kernel	O
the	O
for	O
some	O
feature	B
spaces	O
we	O
may	O
not	O
use	O
literally	O
the	O
vector	O
inner	O
product	O
in	O
some	O
infinite	O
dimensional	O
spaces	O
we	O
need	O
to	O
use	O
other	O
kinds	O
of	O
inner	O
products	O
for	O
example	B
inner	O
products	O
based	O
on	O
integration	O
rather	O
than	O
summation	O
a	O
complete	O
development	O
of	O
these	O
kinds	O
of	O
inner	O
products	O
is	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
operator	O
represents	O
an	O
inner	O
product	O
analogous	O
to	O
after	O
replacing	O
dot	O
products	O
with	O
kernel	O
evaluations	O
we	O
can	O
make	O
predictions	O
using	O
the	O
function	O
f	O
b	O
x	O
ik	O
x	O
i	O
this	O
function	O
is	O
nonlinear	O
with	O
respect	O
to	O
x	O
but	O
the	O
relationship	O
between	O
and	O
f	O
is	O
linear	O
also	O
the	O
relationship	O
between	O
and	O
fx	O
is	O
linear	O
the	O
kernel-based	O
function	O
is	O
exactly	O
equivalent	O
to	O
preprocessing	B
the	O
data	O
by	O
applying	O
to	O
all	O
inputs	O
then	O
learning	O
a	O
linear	O
model	O
in	O
the	O
new	O
transformed	O
space	O
the	O
kernel	B
trick	B
is	O
powerful	O
for	O
two	O
reasons	O
first	O
it	O
allows	O
us	O
to	O
learn	O
models	O
that	O
are	O
nonlinear	O
as	O
a	O
function	O
of	O
x	O
using	O
convex	B
optimization	I
techniques	O
that	O
are	O
chapter	O
machine	B
learning	I
basics	O
guaranteed	O
to	O
converge	O
efficiently	O
this	O
is	O
possible	O
because	O
we	O
consider	O
fixed	O
and	O
optimize	O
only	O
i	O
e	O
the	O
optimization	O
algorithm	O
can	O
view	O
the	O
decision	O
function	O
as	O
being	O
linear	O
in	O
a	O
different	O
space	O
second	O
the	O
kernel	O
function	O
k	O
often	O
admits	O
an	O
implementation	O
that	O
is	O
significantly	O
more	O
computational	O
efficient	O
than	O
naively	O
constructing	O
two	O
vectors	O
and	O
explicitly	O
taking	O
their	O
dot	O
product	O
in	O
some	O
cases	O
can	O
even	O
be	O
infinite	O
dimensional	O
which	O
would	O
result	O
in	O
an	O
infinite	O
computational	O
cost	O
for	O
the	O
naive	O
explicit	O
approach	O
in	O
many	O
cases	O
is	O
a	O
nonlinear	O
tractable	O
function	O
of	O
x	O
even	O
when	O
is	O
intractable	O
as	O
kx	O
x	O
an	O
example	B
of	O
an	O
infinite-dimensional	O
feature	B
space	O
with	O
a	O
tractable	O
kernel	O
we	O
construct	O
a	O
feature	B
mapping	O
over	O
the	O
non-negative	O
integers	O
x	O
suppose	O
that	O
this	O
mapping	O
returns	O
a	O
vector	O
containing	O
x	O
ones	O
followed	O
by	O
infinitely	O
many	O
zeros	O
we	O
can	O
write	O
a	O
kernel	O
function	O
kx	O
x	O
minx	O
x	O
that	O
is	O
exactly	O
equivalent	O
to	O
the	O
corresponding	O
infinite-dimensional	O
dot	O
product	O
the	O
most	O
commonly	O
used	O
kernel	O
is	O
the	O
gaussian	B
kernel	I
k	O
v	O
n	O
u	O
v	O
n	O
is	O
the	O
standard	O
normal	O
density	O
this	O
kernel	O
is	O
also	O
known	O
as	O
where	O
the	O
radial	B
basis	I
function	I
kernel	O
because	O
its	O
value	O
decreases	O
along	O
lines	O
in	O
v	O
space	O
radiating	O
outward	O
from	O
u	O
the	O
gaussian	B
kernel	I
corresponds	O
to	O
a	O
dot	O
product	O
in	O
an	O
infinite-dimensional	O
space	O
but	O
the	O
derivation	O
of	O
this	O
space	O
is	O
less	O
straightforward	O
than	O
in	O
our	O
example	B
of	O
the	O
kernel	O
over	O
the	O
integers	O
min	O
we	O
can	O
think	O
of	O
the	O
gaussian	B
kernel	I
as	O
performing	O
a	O
kind	O
of	O
template	B
matching	I
a	O
training	O
example	B
x	O
associated	O
with	O
training	O
label	O
y	O
becomes	O
a	O
template	O
is	O
near	O
x	O
according	O
to	O
euclidean	O
distance	O
the	O
for	O
class	O
y	O
when	O
a	O
test	O
point	O
x	O
gaussian	B
kernel	I
has	O
a	O
large	O
response	O
indicating	O
that	O
x	O
is	O
very	O
similar	O
to	O
the	O
x	O
template	O
the	O
model	O
then	O
puts	O
a	O
large	O
weight	O
on	O
the	O
associated	O
training	O
label	O
y	O
overall	O
the	O
prediction	O
will	O
combine	O
many	O
such	O
training	O
labels	O
weighted	O
by	O
the	O
similarity	O
of	O
the	O
corresponding	O
training	O
examples	O
support	O
vector	O
machines	O
are	O
not	O
the	O
only	O
algorithm	O
that	O
can	O
be	O
enhanced	O
using	O
the	O
kernel	B
trick	B
many	O
other	O
linear	O
models	O
can	O
be	O
enhanced	O
in	O
this	O
way	O
the	O
category	O
of	O
algorithms	O
that	O
employ	O
the	O
kernel	B
trick	B
is	O
known	O
as	O
kernel	O
machines	O
or	O
kernel	O
methods	O
williams	O
and	O
rasmussen	O
sch	O
lkopf	O
et	O
al	O
a	O
major	O
drawback	O
to	O
kernel	O
machines	O
is	O
that	O
the	O
cost	O
of	O
evaluating	O
the	O
decision	O
function	O
is	O
linear	O
in	O
the	O
number	O
of	O
training	O
examples	O
because	O
the	O
i-th	O
example	B
to	O
the	O
decision	O
function	O
support	O
vector	O
machines	O
contributes	O
a	O
term	O
ikx	O
x	O
are	O
able	O
to	O
mitigate	O
this	O
by	O
learning	O
an	O
vector	O
that	O
contains	O
mostly	O
zeros	O
classifying	O
a	O
new	O
example	B
then	O
requires	O
evaluating	O
the	O
kernel	O
function	O
only	O
for	O
the	O
training	O
examples	O
that	O
have	O
non-zero	O
i	O
these	O
training	O
examples	O
are	O
known	O
chapter	O
machine	B
learning	I
basics	O
as	O
support	O
vectors	O
kernel	O
machines	O
also	O
suffer	O
from	O
a	O
high	O
computational	O
cost	O
of	O
training	O
when	O
kernel	O
machines	O
with	O
the	O
dataset	B
is	O
large	O
we	O
will	O
revisit	O
this	O
idea	O
in	O
section	O
the	O
generic	O
kernels	O
struggle	O
to	O
generalize	O
well	O
we	O
will	O
explain	O
why	O
in	O
section	O
modern	O
incarnation	O
of	O
deep	O
learning	O
was	O
designed	O
to	O
overcome	O
these	O
limitations	O
of	O
kernel	O
machines	O
the	O
current	O
deep	O
learning	O
renaissance	O
began	O
when	O
hinton	O
et	O
al	O
demonstrated	O
that	O
a	O
neural	B
network	I
could	O
outperform	O
the	O
rbf	B
kernel	O
svm	O
on	O
the	O
mnist	O
benchmark	O
other	O
simple	O
supervised	B
learning	I
algorithms	O
we	O
have	O
already	O
briefly	O
encountered	O
another	O
non-probabilistic	O
supervised	B
learning	I
algorithm	O
nearest	B
neighbor	I
regression	B
more	O
generally	O
k-nearest	O
neighbors	O
is	O
a	O
family	O
of	O
techniques	O
that	O
can	O
be	O
used	O
for	O
classification	B
or	O
regression	B
as	O
a	O
non-parametric	O
learning	O
algorithm	O
k-nearest	O
neighbors	O
is	O
not	O
restricted	O
to	O
a	O
fixed	O
number	O
of	O
parameters	O
we	O
usually	O
think	O
of	O
the	O
k-nearest	O
neighbors	O
algorithm	O
as	O
not	O
having	O
any	O
parameters	O
but	O
rather	O
implementing	O
a	O
simple	O
function	O
of	O
the	O
training	O
data	O
in	O
fact	O
there	O
is	O
not	O
even	O
really	O
a	O
training	O
stage	O
or	O
learning	O
process	O
instead	O
at	O
test	O
time	O
when	O
we	O
want	O
to	O
produce	O
an	O
output	O
y	O
for	O
a	O
new	O
test	O
input	O
x	O
we	O
find	O
the	O
k-nearest	O
neighbors	O
to	O
x	O
in	O
the	O
training	O
data	O
x	O
we	O
then	O
return	O
the	O
average	O
of	O
the	O
corresponding	O
y	O
values	O
in	O
the	O
training	O
set	O
this	O
works	O
for	O
essentially	O
any	O
kind	O
of	O
supervised	B
learning	I
where	O
we	O
can	O
define	O
an	O
average	O
over	O
y	O
values	O
in	O
the	O
case	O
of	O
classification	B
we	O
can	O
average	O
over	O
one-hot	O
code	O
vectors	O
c	O
with	O
cy	O
and	O
ci	O
for	O
all	O
other	O
values	O
of	O
i	O
we	O
can	O
then	O
interpret	O
the	O
average	O
over	O
these	O
one-hot	O
codes	O
as	O
giving	O
a	O
probability	B
distribution	I
over	O
classes	O
as	O
a	O
non-parametric	O
learning	O
algorithm	O
k-nearest	O
neighbor	O
can	O
achieve	O
very	O
high	O
capacity	O
for	O
example	B
suppose	O
we	O
have	O
a	O
multiclass	O
classification	B
task	O
and	O
measure	O
performance	O
with	O
loss	O
in	O
this	O
setting	O
neighbor	O
converges	O
to	O
double	O
the	O
bayes	B
error	I
as	O
the	O
number	O
of	O
training	O
examples	O
approaches	O
infinity	O
the	O
error	O
in	O
excess	O
of	O
the	O
bayes	B
error	I
results	O
from	O
choosing	O
a	O
single	O
neighbor	O
by	O
breaking	O
ties	O
between	O
equally	O
distant	O
neighbors	O
randomly	O
when	O
there	O
is	O
infinite	O
training	O
data	O
all	O
test	O
points	O
x	O
will	O
have	O
infinitely	O
many	O
training	O
set	O
neighbors	O
at	O
distance	O
zero	O
if	O
we	O
allow	O
the	O
algorithm	O
to	O
use	O
all	O
of	O
these	O
neighbors	O
to	O
vote	O
rather	O
than	O
randomly	O
choosing	O
one	O
of	O
them	O
the	O
procedure	O
converges	O
to	O
the	O
bayes	B
error	I
rate	O
the	O
high	O
capacity	O
of	O
k-nearest	O
neighbors	O
allows	O
it	O
to	O
obtain	O
high	O
accuracy	B
given	O
a	O
large	O
training	O
set	O
however	O
it	O
does	O
so	O
at	O
high	O
computational	O
cost	O
and	O
it	O
may	O
generalize	O
very	O
badly	O
given	O
a	O
small	O
finite	O
training	O
set	O
one	O
weakness	O
of	O
k-nearest	O
neighbors	O
is	O
that	O
it	O
cannot	O
learn	O
that	O
one	O
feature	B
is	O
more	O
discriminative	O
than	O
another	O
for	O
example	B
drawn	O
from	O
an	O
isotropic	B
gaussian	O
imagine	O
we	O
have	O
a	O
regression	B
task	O
with	O
x	O
r	O
chapter	O
machine	B
learning	I
basics	O
distribution	O
but	O
only	O
a	O
single	O
variable	O
is	O
relevant	O
to	O
the	O
output	O
suppose	O
further	O
that	O
this	O
feature	B
simply	O
encodes	O
the	O
output	O
directly	O
i	O
e	O
that	O
y	O
in	O
all	O
cases	O
nearest	B
neighbor	I
regression	B
will	O
not	O
be	O
able	O
to	O
detect	O
this	O
simple	O
pattern	O
the	O
nearest	O
neighbor	O
of	O
most	O
points	O
x	O
will	O
be	O
determined	O
by	O
the	O
large	O
number	O
of	O
features	O
through	O
not	O
by	O
the	O
lone	O
feature	B
thus	O
the	O
output	O
on	O
small	O
training	O
sets	O
will	O
essentially	O
be	O
random	O
chapter	O
machine	B
learning	I
basics	O
figure	O
diagrams	O
describing	O
how	O
a	O
decision	O
tree	O
works	O
node	O
of	O
the	O
tree	O
chooses	O
to	O
send	O
the	O
input	O
example	B
to	O
the	O
child	O
node	O
on	O
the	O
left	O
or	O
or	O
the	O
child	O
node	O
on	O
the	O
right	O
internal	O
nodes	O
are	O
drawn	O
as	O
circles	O
and	O
leaf	O
nodes	O
as	O
squares	O
each	O
node	O
is	O
displayed	O
with	O
a	O
binary	O
string	O
identifier	O
corresponding	O
to	O
its	O
position	O
in	O
the	O
tree	O
obtained	O
by	O
appending	O
a	O
bit	O
to	O
its	O
parent	O
identifier	O
left	O
or	O
top	O
right	O
or	O
bottom	O
tree	O
divides	O
space	O
into	O
regions	O
the	O
plane	O
shows	O
how	O
a	O
decision	O
tree	O
might	O
divide	O
r	O
the	O
nodes	O
of	O
the	O
tree	O
are	O
plotted	O
in	O
this	O
plane	O
with	O
each	O
internal	O
node	O
drawn	O
along	O
the	O
dividing	O
line	O
it	O
uses	O
to	O
categorize	O
examples	O
and	O
leaf	O
nodes	O
drawn	O
in	O
the	O
center	O
of	O
the	O
region	O
of	O
examples	O
they	O
receive	O
the	O
result	O
is	O
a	O
piecewise-constant	O
function	O
with	O
one	O
piece	O
per	O
leaf	O
each	O
leaf	O
requires	O
at	O
least	O
one	O
training	O
example	B
to	O
define	O
so	O
it	O
is	O
not	O
possible	O
for	O
the	O
decision	O
tree	O
to	O
learn	O
a	O
function	O
that	O
has	O
more	O
local	O
maxima	O
than	O
the	O
number	O
of	O
training	O
examples	O
chapter	O
machine	B
learning	I
basics	O
another	O
type	O
of	O
learning	O
algorithm	O
that	O
also	O
breaks	O
the	O
input	O
space	O
into	O
regions	O
breiman	O
et	O
al	O
and	O
has	O
separate	O
parameters	O
for	O
each	O
region	O
is	O
the	O
decision	O
tree	O
and	O
its	O
many	O
variants	O
as	O
shown	O
in	O
figure	O
each	O
node	O
of	O
the	O
decision	O
tree	O
is	O
associated	O
with	O
a	O
region	O
in	O
the	O
input	O
space	O
and	O
internal	O
nodes	O
break	O
that	O
region	O
into	O
one	O
sub-region	O
for	O
each	O
child	O
of	O
the	O
node	O
using	O
an	O
axis-aligned	O
cut	O
space	O
is	O
thus	O
sub-divided	O
into	O
non-overlapping	O
regions	O
with	O
a	O
one-to-one	O
correspondence	O
between	O
leaf	O
nodes	O
and	O
input	O
regions	O
each	O
leaf	O
node	O
usually	O
maps	O
every	O
point	O
in	O
its	O
input	O
region	O
to	O
the	O
same	O
output	O
decision	O
trees	O
are	O
usually	O
trained	O
with	O
specialized	O
algorithms	O
that	O
are	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
the	O
learning	O
algorithm	O
can	O
be	O
considered	O
non-parametric	O
if	O
it	O
is	O
allowed	O
to	O
learn	O
a	O
tree	O
of	O
arbitrary	O
size	O
though	O
decision	O
trees	O
are	O
usually	O
regularized	O
with	O
size	O
constraints	O
that	O
turn	O
them	O
into	O
parametric	O
models	O
in	O
practice	O
decision	O
trees	O
as	O
they	O
are	O
typically	O
used	O
with	O
axis-aligned	O
splits	O
and	O
constant	O
outputs	O
within	O
each	O
node	O
struggle	O
to	O
solve	O
some	O
problems	O
that	O
are	O
easy	O
even	O
for	O
logistic	O
regression	B
for	O
example	B
if	O
we	O
have	O
a	O
two-class	O
problem	O
and	O
the	O
positive	O
class	O
occurs	O
wherever	O
the	O
decision	O
boundary	O
is	O
not	O
axis-aligned	O
the	O
decision	O
tree	O
will	O
thus	O
need	O
to	O
approximate	O
the	O
decision	O
boundary	O
with	O
many	O
nodes	O
implementing	O
a	O
step	O
function	O
that	O
constantly	O
walks	O
back	O
and	O
forth	O
across	O
the	O
true	O
decision	O
function	O
with	O
axis-aligned	O
steps	O
as	O
we	O
have	O
seen	O
nearest	O
neighbor	O
predictors	O
and	O
decision	O
trees	O
have	O
many	O
limitations	O
nonetheless	O
they	O
are	O
useful	O
learning	O
algorithms	O
when	O
computational	O
resources	O
are	O
constrained	O
we	O
can	O
also	O
build	O
intuition	O
for	O
more	O
sophisticated	O
learning	O
algorithms	O
by	O
thinking	O
about	O
the	O
similarities	O
and	O
differences	O
between	O
sophisticated	O
algorithms	O
and	O
or	O
decision	O
tree	O
baselines	O
k	O
see	O
murphy	O
bishop	O
hastie	O
et	O
al	O
or	O
other	O
machine	B
learning	I
textbooks	O
for	O
more	O
material	O
on	O
traditional	O
supervised	B
learning	I
algorithms	O
unsupervised	O
learning	O
algorithms	O
recall	B
from	O
section	O
that	O
unsupervised	O
algorithms	O
are	O
those	O
that	O
experience	O
only	O
features	O
but	O
not	O
a	O
supervision	O
signal	O
the	O
distinction	O
between	O
supervised	O
and	O
unsupervised	O
algorithms	O
is	O
not	O
formally	O
and	O
rigidly	O
defined	O
because	O
there	O
is	O
no	O
objective	O
test	O
for	O
distinguishing	O
whether	O
a	O
value	O
is	O
a	O
feature	B
or	O
a	O
target	O
provided	O
by	O
a	O
supervisor	O
informally	O
unsupervised	O
learning	O
refers	O
to	O
most	O
attempts	O
to	O
extract	O
information	O
from	O
a	O
distribution	O
that	O
do	O
not	O
require	O
human	O
labor	O
to	O
annotate	O
examples	O
the	O
term	O
is	O
usually	O
associated	O
with	O
density	B
estimation	I
learning	O
to	O
draw	O
samples	O
from	O
a	O
distribution	O
learning	O
to	O
denoise	O
data	O
from	O
some	O
distribution	O
finding	O
a	O
manifold	B
that	O
the	O
data	O
lies	O
near	O
or	O
clustering	O
the	O
data	O
into	O
groups	O
of	O
chapter	O
machine	B
learning	I
basics	O
related	O
examples	O
a	O
classic	O
unsupervised	O
learning	O
task	O
is	O
to	O
find	O
the	O
best	O
representation	O
of	O
the	O
data	O
by	O
best	O
we	O
can	O
mean	O
different	O
things	O
but	O
generally	O
speaking	O
we	O
are	O
looking	O
for	O
a	O
representation	O
that	O
preserves	O
as	O
much	O
information	O
about	O
x	O
as	O
possible	O
while	O
obeying	O
some	O
penalty	O
or	O
constraint	O
aimed	O
at	O
keeping	O
the	O
representation	O
or	O
more	O
accessible	O
than	O
simpler	O
itself	O
x	O
simpler	O
there	O
are	O
multiple	O
ways	O
of	O
defining	O
a	O
representation	O
three	O
of	O
the	O
most	O
common	O
include	O
lower	O
dimensional	O
representations	O
sparse	O
representations	O
and	O
independent	O
representations	O
low-dimensional	O
representations	O
attempt	O
to	O
compress	O
as	O
much	O
information	O
about	O
x	O
as	O
possible	O
in	O
a	O
smaller	O
representation	O
sparse	O
representations	O
barlow	O
olshausen	O
and	O
field	O
hinton	O
and	O
ghahramani	O
embed	O
the	O
dataset	B
into	O
a	O
representation	O
whose	O
entries	O
are	O
mostly	O
zeroes	O
for	O
most	O
inputs	O
the	O
use	O
of	O
sparse	O
representations	O
typically	O
requires	O
increasing	O
the	O
dimensionality	O
of	O
the	O
representation	O
so	O
that	O
the	O
representation	O
becoming	O
mostly	O
zeroes	O
does	O
not	O
discard	O
too	O
much	O
information	O
this	O
results	O
in	O
an	O
overall	O
structure	O
of	O
the	O
representation	O
that	O
tends	O
to	O
distribute	O
data	O
along	O
the	O
axes	O
of	O
the	O
representation	O
space	O
independent	O
representations	O
attempt	O
to	O
disentangle	O
the	O
sources	O
of	O
variation	O
underlying	O
the	O
data	O
distribution	O
such	O
that	O
the	O
dimensions	O
of	O
the	O
representation	O
are	O
statistically	O
independent	O
of	O
course	O
these	O
three	O
criteria	O
are	O
certainly	O
not	O
mutually	O
exclusive	O
lowdimensional	O
representations	O
often	O
yield	O
elements	O
that	O
have	O
fewer	O
or	O
weaker	O
dependencies	O
than	O
the	O
original	O
high-dimensional	O
data	O
this	O
is	O
because	O
one	O
way	O
to	O
reduce	O
the	O
size	O
of	O
a	O
representation	O
is	O
to	O
find	O
and	O
remove	O
redundancies	O
identifying	O
and	O
removing	O
more	O
redundancy	O
allows	O
the	O
dimensionality	O
reduction	O
algorithm	O
to	O
achieve	O
more	O
compression	O
while	O
discarding	O
less	O
information	O
the	O
notion	O
of	O
representation	O
is	O
one	O
of	O
the	O
central	O
themes	O
of	O
deep	O
learning	O
and	O
therefore	O
one	O
of	O
the	O
central	O
themes	O
in	O
this	O
book	O
in	O
this	O
section	O
we	O
develop	O
some	O
simple	O
examples	O
of	O
representation	B
learning	I
algorithms	O
together	O
these	O
example	B
algorithms	O
show	O
how	O
to	O
operationalize	O
all	O
three	O
of	O
the	O
criteria	O
above	O
most	O
of	O
the	O
remaining	O
chapters	O
introduce	O
additional	O
representation	B
learning	I
algorithms	O
that	O
develop	O
these	O
criteria	O
in	O
different	O
ways	O
or	O
introduce	O
other	O
criteria	O
principal	O
components	O
analysis	O
in	O
section	O
we	O
saw	O
that	O
the	O
principal	O
components	O
analysis	O
algorithm	O
provides	O
a	O
means	O
of	O
compressing	O
data	O
we	O
can	O
also	O
view	O
pca	O
as	O
an	O
unsupervised	O
learning	O
algorithm	O
that	O
learns	O
a	O
representation	O
of	O
data	O
this	O
representation	O
is	O
based	O
on	O
two	O
of	O
the	O
criteria	O
for	O
a	O
simple	O
representation	O
described	O
above	O
pca	O
learns	O
a	O
chapter	O
machine	B
learning	I
basics	O
x	O
z	O
figure	O
pca	O
learns	O
a	O
linear	O
projection	O
that	O
aligns	O
the	O
direction	O
of	O
greatest	O
variance	O
with	O
the	O
axes	O
of	O
the	O
new	O
space	O
original	O
data	O
consists	O
of	O
samples	O
of	O
x	O
in	O
this	O
space	O
the	O
variance	O
might	O
occur	O
along	O
directions	O
that	O
are	O
not	O
axis-aligned	O
transformed	O
data	O
z	O
x	O
w	O
now	O
varies	O
most	O
along	O
the	O
axis	O
the	O
direction	O
of	O
second	O
most	O
variance	O
is	O
now	O
along	O
representation	O
that	O
has	O
lower	O
dimensionality	O
than	O
the	O
original	O
input	O
it	O
also	O
learns	O
a	O
representation	O
whose	O
elements	O
have	O
no	O
linear	O
correlation	B
with	O
each	O
other	O
this	O
is	O
a	O
first	O
step	O
toward	O
the	O
criterion	O
of	O
learning	O
representations	O
whose	O
elements	O
are	O
statistically	O
independent	O
to	O
achieve	O
full	O
independence	O
a	O
representation	B
learning	I
algorithm	O
must	O
also	O
remove	O
the	O
nonlinear	O
relationships	O
between	O
variables	O
pca	O
learns	O
an	O
orthogonal	O
linear	O
transformation	O
of	O
the	O
data	O
that	O
projects	O
an	O
input	O
x	O
to	O
a	O
representation	O
z	O
as	O
shown	O
in	O
figure	O
we	O
saw	O
that	O
we	O
could	O
learn	O
a	O
one-dimensional	O
representation	O
that	O
best	O
reconstructs	O
the	O
original	O
data	O
the	O
sense	O
of	O
mean	B
squared	I
error	I
and	O
that	O
this	O
representation	O
actually	O
corresponds	O
to	O
the	O
first	O
principal	O
component	O
of	O
the	O
data	O
thus	O
we	O
can	O
use	O
pca	O
as	O
a	O
simple	O
and	O
effective	O
dimensionality	O
reduction	O
method	O
that	O
preserves	O
as	O
much	O
of	O
the	O
information	O
in	O
the	O
data	O
as	O
possible	O
as	O
measured	O
by	O
least-squares	O
reconstruction	O
error	O
in	O
the	O
following	O
we	O
will	O
study	O
how	O
the	O
pca	O
representation	O
decorrelates	O
the	O
original	O
data	O
representation	O
in	O
section	O
let	O
us	O
consider	O
the	O
m	O
n	O
design	B
matrix	I
x	O
we	O
will	O
assume	O
that	O
the	O
data	O
has	O
a	O
mean	O
of	O
zero	O
ex	O
if	O
this	O
is	O
not	O
the	O
case	O
the	O
data	O
can	O
easily	O
be	O
centered	O
by	O
subtracting	O
the	O
mean	O
from	O
all	O
examples	O
in	O
a	O
preprocessing	B
step	O
the	O
unbiased	B
sample	O
covariance	B
matrix	I
associated	O
with	O
x	O
is	O
given	O
by	O
var	O
x	O
m	O
x	O
chapter	O
machine	B
learning	I
basics	O
pca	O
finds	O
a	O
representation	O
linear	O
transformation	O
z	O
x	O
var	O
is	O
diagonal	O
w	O
where	O
in	O
section	O
we	O
saw	O
that	O
the	O
principal	O
components	O
of	O
a	O
design	B
matrix	I
x	O
are	O
given	O
by	O
the	O
eigenvectors	O
of	O
x	O
x	O
from	O
this	O
view	O
x	O
x	O
w	O
w	O
in	O
this	O
section	O
we	O
exploit	O
an	O
alternative	O
derivation	O
of	O
the	O
principal	O
components	O
the	O
principal	O
components	O
may	O
also	O
be	O
obtained	O
via	O
the	O
singular	B
value	I
decomposition	O
specifically	O
they	O
are	O
the	O
right	O
singular	O
vectors	O
of	O
x	O
to	O
see	O
this	O
let	O
w	O
be	O
the	O
right	O
singular	O
vectors	O
in	O
the	O
decomposition	O
x	O
u	O
w	O
we	O
then	O
recover	O
the	O
original	O
eigenvector	B
equation	O
with	O
x	O
x	O
u	O
w	O
w	O
as	O
the	O
eigenvector	B
basis	O
u	O
w	O
w	O
the	O
svd	O
is	O
helpful	O
to	O
show	O
that	O
pca	O
results	O
in	O
a	O
diagonal	O
var	O
using	O
the	O
svd	O
of	O
x	O
we	O
can	O
express	O
the	O
variance	O
of	O
x	O
var	O
x	O
as	O
x	O
m	O
m	O
m	O
m	O
w	O
w	O
u	O
u	O
w	O
u	O
w	O
w	O
w	O
is	O
diagonal	O
as	O
required	O
u	O
i	O
because	O
the	O
u	O
matrix	O
of	O
the	O
singular	B
value	I
w	O
where	O
we	O
use	O
the	O
fact	O
that	O
u	O
decomposition	O
is	O
defined	O
to	O
be	O
orthogonal	O
this	O
shows	O
that	O
if	O
we	O
take	O
z	O
x	O
we	O
can	O
ensure	O
that	O
the	O
covariance	O
of	O
z	O
xw	O
w	O
z	O
w	O
var	O
w	O
w	O
x	O
m	O
m	O
m	O
z	O
m	O
w	O
i	O
again	O
from	O
the	O
definition	O
of	O
the	O
where	O
this	O
time	O
we	O
use	O
the	O
fact	O
that	O
w	O
svd	O
chapter	O
machine	B
learning	I
basics	O
the	O
above	O
analysis	O
shows	O
that	O
when	O
we	O
project	O
the	O
data	O
x	O
to	O
z	O
via	O
the	O
linear	O
transformation	O
w	O
the	O
resulting	O
representation	O
has	O
a	O
diagonal	O
covariance	B
matrix	I
given	O
by	O
which	O
immediately	O
implies	O
that	O
the	O
individual	O
elements	O
of	O
z	O
are	O
mutually	O
uncorrelated	O
this	O
ability	O
of	O
pca	O
to	O
transform	O
data	O
into	O
a	O
representation	O
where	O
the	O
elements	O
are	O
mutually	O
uncorrelated	O
is	O
a	O
very	O
important	O
property	O
of	O
pca	O
it	O
is	O
a	O
simple	O
example	B
of	O
a	O
representation	O
that	O
attempts	O
to	O
disentangle	O
the	O
unknown	O
factors	B
of	I
variation	I
underlying	O
the	O
data	O
in	O
the	O
case	O
of	O
pca	O
this	O
disentangling	O
takes	O
the	O
form	O
of	O
finding	O
a	O
rotation	O
of	O
the	O
input	O
space	O
by	O
w	O
that	O
aligns	O
the	O
principal	O
axes	O
of	O
variance	O
with	O
the	O
basis	O
of	O
the	O
new	O
representation	O
space	O
associated	O
with	O
while	O
correlation	B
is	O
an	O
important	O
category	O
of	O
dependency	O
between	O
elements	O
of	O
the	O
data	O
we	O
are	O
also	O
interested	O
in	O
learning	O
representations	O
that	O
disentangle	O
more	O
complicated	O
forms	O
of	O
feature	B
dependencies	O
for	O
this	O
we	O
will	O
need	O
more	O
than	O
what	O
can	O
be	O
done	O
with	O
a	O
simple	O
linear	O
transformation	O
k	O
clustering	O
another	O
example	B
of	O
a	O
simple	O
representation	B
learning	I
algorithm	O
is	O
k	O
clustering	O
the	O
k-means	O
clustering	O
algorithm	O
divides	O
the	O
training	O
set	O
into	O
k	O
different	O
clusters	O
of	O
examples	O
that	O
are	O
near	O
each	O
other	O
we	O
can	O
thus	O
think	O
of	O
the	O
algorithm	O
as	O
providing	O
a	O
k-dimensional	O
one-hot	O
code	O
vector	O
h	O
representing	O
an	O
input	O
x	O
if	O
x	O
belongs	O
to	O
cluster	O
i	O
then	O
h	O
i	O
and	O
all	O
other	O
entries	O
of	O
the	O
representation	O
h	O
are	O
zero	O
the	O
one-hot	O
code	O
provided	O
by	O
k-means	O
clustering	O
is	O
an	O
example	B
of	O
a	O
sparse	O
representation	O
because	O
the	O
majority	O
of	O
its	O
entries	O
are	O
zero	O
for	O
every	O
input	O
later	O
we	O
will	O
develop	O
other	O
algorithms	O
that	O
learn	O
more	O
flexible	O
sparse	O
representations	O
where	O
more	O
than	O
one	O
entry	O
can	O
be	O
non-zero	O
for	O
each	O
input	O
x	O
one-hot	O
codes	O
are	O
an	O
extreme	O
example	B
of	O
sparse	O
representations	O
that	O
lose	O
many	O
of	O
the	O
benefits	O
of	O
a	O
distributed	O
representation	O
the	O
one-hot	O
code	O
still	O
confers	O
some	O
statistical	O
advantages	O
naturally	O
conveys	O
the	O
idea	O
that	O
all	O
examples	O
in	O
the	O
same	O
cluster	O
are	O
similar	O
to	O
each	O
other	O
and	O
it	O
confers	O
the	O
computational	O
advantage	O
that	O
the	O
entire	O
representation	O
may	O
be	O
captured	O
by	O
a	O
single	O
integer	O
to	O
different	O
values	O
then	O
alternating	O
between	O
two	O
different	O
steps	O
until	O
convergence	O
in	O
one	O
step	O
each	O
training	O
example	B
is	O
assigned	O
to	O
cluster	O
i	O
where	O
i	O
is	O
the	O
index	O
of	O
the	O
nearest	O
centroid	O
in	O
the	O
other	O
step	O
each	O
centroid	O
is	O
updated	O
to	O
the	O
mean	O
of	O
all	O
training	O
examples	O
x	O
assigned	O
to	O
cluster	O
the	O
k-means	O
algorithm	O
works	O
by	O
initializing	O
k	O
different	O
centroids	O
chapter	O
machine	B
learning	I
basics	O
one	O
difficulty	O
pertaining	O
to	O
clustering	O
is	O
that	O
the	O
clustering	O
problem	O
is	O
inherently	O
ill-posed	O
in	O
the	O
sense	O
that	O
there	O
is	O
no	O
single	O
criterion	O
that	O
measures	O
how	O
well	O
a	O
clustering	O
of	O
the	O
data	O
corresponds	O
to	O
the	O
real	O
world	O
we	O
can	O
measure	O
properties	O
of	O
the	O
clustering	O
such	O
as	O
the	O
average	O
euclidean	O
distance	O
from	O
a	O
cluster	O
centroid	O
to	O
the	O
members	O
of	O
the	O
cluster	O
this	O
allows	O
us	O
to	O
tell	O
how	O
well	O
we	O
are	O
able	O
to	O
reconstruct	O
the	O
training	O
data	O
from	O
the	O
cluster	O
assignments	O
we	O
do	O
not	O
know	O
how	O
well	O
the	O
cluster	O
assignments	O
correspond	O
to	O
properties	O
of	O
the	O
real	O
world	O
moreover	O
there	O
may	O
be	O
many	O
different	O
clusterings	O
that	O
all	O
correspond	O
well	O
to	O
some	O
property	O
of	O
the	O
real	O
world	O
we	O
may	O
hope	O
to	O
find	O
a	O
clustering	O
that	O
relates	O
to	O
one	O
feature	B
but	O
obtain	O
a	O
different	O
equally	O
valid	O
clustering	O
that	O
is	O
not	O
relevant	O
to	O
our	O
task	O
for	O
example	B
suppose	O
that	O
we	O
run	O
two	O
clustering	O
algorithms	O
on	O
a	O
dataset	B
consisting	O
of	O
images	O
of	O
red	O
trucks	O
images	O
of	O
red	O
cars	O
images	O
of	O
gray	O
trucks	O
and	O
images	O
of	O
gray	O
cars	O
if	O
we	O
ask	O
each	O
clustering	O
algorithm	O
to	O
find	O
two	O
clusters	O
one	O
algorithm	O
may	O
find	O
a	O
cluster	O
of	O
cars	O
and	O
a	O
cluster	O
of	O
trucks	O
while	O
another	O
may	O
find	O
a	O
cluster	O
of	O
red	O
vehicles	O
and	O
a	O
cluster	O
of	O
gray	O
vehicles	O
suppose	O
we	O
also	O
run	O
a	O
third	O
clustering	O
algorithm	O
which	O
is	O
allowed	O
to	O
determine	O
the	O
number	O
of	O
clusters	O
this	O
may	O
assign	O
the	O
examples	O
to	O
four	O
clusters	O
red	O
cars	O
red	O
trucks	O
gray	O
cars	O
and	O
gray	O
trucks	O
this	O
new	O
clustering	O
now	O
at	O
least	O
captures	O
information	O
about	O
both	O
attributes	O
but	O
it	O
has	O
lost	O
information	O
about	O
similarity	O
red	O
cars	O
are	O
in	O
a	O
different	O
cluster	O
from	O
gray	O
cars	O
just	O
as	O
they	O
are	O
in	O
a	O
different	O
cluster	O
from	O
gray	O
trucks	O
the	O
output	O
of	O
the	O
clustering	O
algorithm	O
does	O
not	O
tell	O
us	O
that	O
red	O
cars	O
are	O
more	O
similar	O
to	O
gray	O
cars	O
than	O
they	O
are	O
to	O
gray	O
trucks	O
they	O
are	O
different	O
from	O
both	O
things	O
and	O
that	O
is	O
all	O
we	O
know	O
these	O
issues	O
illustrate	O
some	O
of	O
the	O
reasons	O
that	O
we	O
may	O
prefer	O
a	O
distributed	O
representation	O
to	O
a	O
one-hot	O
representation	O
a	O
distributed	O
representation	O
could	O
have	O
two	O
attributes	O
for	O
each	O
vehicle	O
one	O
representing	O
its	O
color	O
and	O
one	O
representing	O
whether	O
it	O
is	O
a	O
car	O
or	O
a	O
truck	O
it	O
is	O
still	O
not	O
entirely	O
clear	O
what	O
the	O
optimal	O
distributed	O
representation	O
is	O
can	O
the	O
learning	O
algorithm	O
know	O
whether	O
the	O
two	O
attributes	O
we	O
are	O
interested	O
in	O
are	O
color	O
and	O
car-versus-truck	O
rather	O
than	O
manufacturer	O
and	O
age	O
but	O
having	O
many	O
attributes	O
reduces	O
the	O
burden	O
on	O
the	O
algorithm	O
to	O
guess	O
which	O
single	O
attribute	O
we	O
care	O
about	O
and	O
allows	O
us	O
to	O
measure	O
similarity	O
between	O
objects	O
in	O
a	O
fine-grained	O
way	O
by	O
comparing	O
many	O
attributes	O
instead	O
of	O
just	O
testing	O
whether	O
one	O
attribute	O
matches	O
stochastic	O
gradient	B
descent	O
nearly	O
all	O
of	O
deep	O
learning	O
is	O
powered	O
by	O
one	O
very	O
important	O
algorithm	O
stochastic	O
gradient	B
descent	O
or	O
sgd	O
stochastic	O
gradient	B
descent	O
is	O
an	O
extension	O
of	O
the	O
chapter	O
machine	B
learning	I
basics	O
gradient	B
descent	O
algorithm	O
introduced	O
in	O
section	O
a	O
recurring	O
problem	O
in	O
machine	B
learning	I
is	O
that	O
large	O
training	O
sets	O
are	O
necessary	O
for	O
good	O
generalization	B
but	O
large	O
training	O
sets	O
are	O
also	O
more	O
computationally	O
expensive	O
the	O
cost	O
function	O
used	O
by	O
a	O
machine	B
learning	I
algorithm	O
often	O
decomposes	O
as	O
a	O
sum	O
over	O
training	O
examples	O
of	O
some	O
per-example	O
loss	O
function	O
for	O
example	B
the	O
negative	O
conditional	O
log-likelihood	O
of	O
the	O
training	O
data	O
can	O
be	O
written	O
as	O
m	O
j	O
exy	O
pdata	O
where	O
l	O
is	O
the	O
per-example	O
loss	O
m	O
l	O
y	O
log	O
p	O
y	O
x	O
l	O
y	O
lx	O
y	O
for	O
these	O
additive	O
cost	O
functions	O
gradient	B
descent	O
requires	O
computing	O
j	O
m	O
m	O
lx	O
y	O
the	O
computational	O
cost	O
of	O
this	O
operation	B
is	O
om	O
as	O
the	O
training	O
set	O
size	O
grows	O
to	O
billions	O
of	O
examples	O
the	O
time	O
to	O
take	O
a	O
single	O
gradient	B
step	O
becomes	O
prohibitively	O
long	O
xm	O
the	O
insight	O
of	O
stochastic	O
gradient	B
descent	O
is	O
that	O
the	O
gradient	B
is	O
an	O
expectation	B
the	O
expectation	B
may	O
be	O
approximately	O
estimated	O
using	O
a	O
small	O
set	O
of	O
samples	O
specifically	O
on	O
each	O
step	O
of	O
the	O
algorithm	O
we	O
can	O
sample	O
a	O
minibatch	B
of	O
examples	O
b	O
drawn	O
uniformly	O
from	O
the	O
training	O
set	O
the	O
minibatch	B
size	O
m	O
is	O
typically	O
chosen	O
to	O
be	O
a	O
relatively	O
small	O
number	O
of	O
examples	O
ranging	O
from	O
to	O
a	O
few	O
hundred	O
crucially	O
m	O
is	O
usually	O
held	O
fixed	O
as	O
the	O
training	O
set	O
size	O
m	O
grows	O
we	O
may	O
fit	O
a	O
training	O
set	O
with	O
billions	O
of	O
examples	O
using	O
updates	O
computed	O
on	O
only	O
a	O
hundred	O
examples	O
the	O
estimate	O
of	O
the	O
gradient	B
is	O
formed	O
as	O
g	O
m	O
m	O
lx	O
y	O
using	O
examples	O
from	O
the	O
minibatch	B
the	O
stochastic	O
gradient	B
descent	O
algorithm	O
then	O
follows	O
the	O
estimated	O
gradient	B
downhill	O
b	O
g	O
where	O
is	O
the	O
learning	B
rate	I
chapter	O
machine	B
learning	I
basics	O
gradient	B
descent	O
in	O
general	O
has	O
often	O
been	O
regarded	O
as	O
slow	O
or	O
unreliable	O
in	O
the	O
past	O
the	O
application	O
of	O
gradient	B
descent	O
to	O
non-convex	O
optimization	O
problems	O
was	O
regarded	O
as	O
foolhardy	O
or	O
unprincipled	O
today	O
we	O
know	O
that	O
the	O
machine	B
learning	I
models	O
described	O
in	O
part	O
work	O
very	O
well	O
when	O
trained	O
with	O
gradient	B
descent	O
the	O
optimization	O
algorithm	O
may	O
not	O
be	O
guaranteed	O
to	O
arrive	O
at	O
even	O
a	O
local	O
minimum	O
in	O
a	O
reasonable	O
amount	O
of	O
time	O
but	O
it	O
often	O
finds	O
a	O
very	O
low	O
value	O
of	O
the	O
cost	O
function	O
quickly	O
enough	O
to	O
be	O
useful	O
ii	O
stochastic	O
gradient	B
descent	O
has	O
many	O
important	O
uses	O
outside	O
the	O
context	O
of	O
deep	O
learning	O
it	O
is	O
the	O
main	O
way	O
to	O
train	O
large	O
linear	O
models	O
on	O
very	O
large	O
datasets	O
for	O
a	O
fixed	O
model	O
size	O
the	O
cost	O
per	O
sgd	O
update	O
does	O
not	O
depend	O
on	O
the	O
training	O
set	O
size	O
m	O
in	O
practice	O
we	O
often	O
use	O
a	O
larger	O
model	O
as	O
the	O
training	O
set	O
size	O
increases	O
but	O
we	O
are	O
not	O
forced	O
to	O
do	O
so	O
the	O
number	O
of	O
updates	O
required	O
to	O
reach	O
convergence	O
usually	O
increases	O
with	O
training	O
set	O
size	O
however	O
as	O
m	O
approaches	O
infinity	O
the	O
model	O
will	O
eventually	O
converge	O
to	O
its	O
best	O
possible	O
test	O
error	O
before	O
sgd	O
has	O
sampled	O
every	O
example	B
in	O
the	O
training	O
set	O
increasing	O
m	O
further	O
will	O
not	O
extend	O
the	O
amount	O
of	O
training	O
time	O
needed	O
to	O
reach	O
the	O
model	O
s	O
best	O
possible	O
test	O
error	O
from	O
this	O
point	O
of	O
view	O
one	O
can	O
argue	O
that	O
the	O
asymptotic	O
cost	O
of	O
training	O
a	O
model	O
with	O
sgd	O
is	O
as	O
a	O
function	O
of	O
m	O
prior	O
to	O
the	O
advent	O
of	O
deep	O
learning	O
the	O
main	O
way	O
to	O
learn	O
nonlinear	O
models	O
was	O
to	O
use	O
the	O
kernel	B
trick	B
in	O
combination	O
with	O
a	O
linear	O
model	O
many	O
kernel	O
learning	O
matrix	O
gij	O
kx	O
x	O
constructing	O
algorithms	O
require	O
constructing	O
an	O
m	O
m	O
this	O
matrix	O
has	O
computational	O
cost	O
o	O
which	O
is	O
clearly	O
undesirable	O
for	O
datasets	O
with	O
billions	O
of	O
examples	O
in	O
academia	O
starting	O
in	O
deep	O
learning	O
was	O
initially	O
interesting	O
because	O
it	O
was	O
able	O
to	O
generalize	O
to	O
new	O
examples	O
better	O
than	O
competing	O
algorithms	O
when	O
trained	O
on	O
medium-sized	O
datasets	O
with	O
tens	O
of	O
thousands	O
of	O
examples	O
soon	O
after	O
deep	O
learning	O
garnered	O
additional	O
interest	O
in	O
industry	O
because	O
it	O
provided	O
a	O
scalable	O
way	O
of	O
training	O
nonlinear	O
models	O
on	O
large	O
datasets	O
stochastic	O
gradient	B
descent	O
and	O
many	O
enhancements	O
to	O
it	O
are	O
described	O
further	O
in	O
chapter	O
building	O
a	O
machine	B
learning	I
algorithm	O
nearly	O
all	O
deep	O
learning	O
algorithms	O
can	O
be	O
described	O
as	O
particular	O
instances	O
of	O
a	O
fairly	O
simple	O
recipe	O
combine	O
a	O
specification	O
of	O
a	O
dataset	B
a	O
cost	O
function	O
an	O
optimization	O
procedure	O
and	O
a	O
model	O
for	O
example	B
the	O
linear	O
regression	B
algorithm	O
combines	O
a	O
dataset	B
consisting	O
of	O
chapter	O
machine	B
learning	I
basics	O
x	O
and	O
the	O
cost	O
function	O
y	O
j	O
b	O
exy	O
pdata	O
n	O
log	O
pmodel	O
y	O
x	O
the	O
model	O
specification	O
pmodely	O
w	O
b	O
and	O
in	O
most	O
cases	O
the	O
optimization	O
algorithm	O
defined	O
by	O
solving	O
for	O
where	O
the	O
gradient	B
of	O
the	O
cost	O
is	O
zero	O
using	O
the	O
normal	O
equations	O
x	O
x	O
by	O
realizing	O
that	O
we	O
can	O
replace	O
any	O
of	O
these	O
components	O
mostly	O
independently	O
from	O
the	O
others	O
we	O
can	O
obtain	O
a	O
very	O
wide	O
variety	O
of	O
algorithms	O
the	O
cost	O
function	O
typically	O
includes	O
at	O
least	O
one	O
term	O
that	O
causes	O
the	O
learning	O
process	O
to	O
perform	O
statistical	O
estimation	O
the	O
most	O
common	O
cost	O
function	O
is	O
the	O
negative	O
log-likelihood	O
so	O
that	O
minimizing	O
the	O
cost	O
function	O
causes	O
maximum	B
likelihood	I
estimation	O
the	O
cost	O
function	O
may	O
also	O
include	O
additional	O
terms	O
such	O
as	O
regularization	O
terms	O
for	O
example	B
we	O
can	O
add	O
weight	O
decay	O
to	O
the	O
linear	O
regression	B
cost	O
function	O
to	O
obtain	O
j	O
b	O
w	O
exy	O
pdata	O
log	O
pmodel	O
y	O
x	O
this	O
still	O
allows	O
closed-form	O
optimization	O
if	O
we	O
change	O
the	O
model	O
to	O
be	O
nonlinear	O
then	O
most	O
cost	O
functions	O
can	O
no	O
longer	O
be	O
optimized	O
in	O
closed	O
form	O
this	O
requires	O
us	O
to	O
choose	O
an	O
iterative	O
numerical	O
optimization	O
procedure	O
such	O
as	O
gradient	B
descent	O
the	O
recipe	O
for	O
constructing	O
a	O
learning	O
algorithm	O
by	O
combining	O
models	O
costs	O
and	O
optimization	O
algorithms	O
supports	O
both	O
supervised	O
and	O
unsupervised	O
learning	O
the	O
linear	O
regression	B
example	B
shows	O
how	O
to	O
support	O
supervised	B
learning	I
unsupervised	O
learning	O
can	O
be	O
supported	O
by	O
defining	O
a	O
dataset	B
that	O
contains	O
only	O
x	O
and	O
providing	O
an	O
appropriate	O
unsupervised	O
cost	O
and	O
model	O
for	O
example	B
we	O
can	O
obtain	O
the	O
first	O
pca	O
vector	O
by	O
specifying	O
that	O
our	O
loss	O
function	O
is	O
j	O
w	O
pdata	O
ex	O
x	O
r	O
x	O
w	O
while	O
our	O
model	O
is	O
defined	O
to	O
have	O
w	O
with	O
norm	O
one	O
and	O
reconstruction	O
function	O
r	O
xw	O
w	O
x	O
in	O
some	O
cases	O
the	O
cost	O
function	O
may	O
be	O
a	O
function	O
that	O
we	O
cannot	O
actually	O
evaluate	O
for	O
computational	O
reasons	O
in	O
these	O
cases	O
we	O
can	O
still	O
approximately	O
minimize	O
it	O
using	O
iterative	O
numerical	O
optimization	O
so	O
long	O
as	O
we	O
have	O
some	O
way	O
of	O
approximating	O
its	O
gradients	O
most	O
machine	B
learning	I
algorithms	O
make	O
use	O
of	O
this	O
recipe	O
though	O
it	O
may	O
not	O
immediately	O
be	O
obvious	O
if	O
a	O
machine	B
learning	I
algorithm	O
seems	O
especially	O
unique	O
or	O
chapter	O
machine	B
learning	I
basics	O
hand-designed	O
it	O
can	O
usually	O
be	O
understood	O
as	O
using	O
a	O
special-case	O
optimizer	O
some	O
models	O
such	O
as	O
decision	O
trees	O
or	O
k-means	O
require	O
special-case	O
optimizers	O
because	O
their	O
cost	O
functions	O
have	O
flat	O
regions	O
that	O
make	O
them	O
inappropriate	O
for	O
minimization	O
by	O
gradient-based	O
optimizers	O
recognizing	O
that	O
most	O
machine	B
learning	I
algorithms	O
can	O
be	O
described	O
using	O
this	O
recipe	O
helps	O
to	O
see	O
the	O
different	O
algorithms	O
as	O
part	O
of	O
a	O
taxonomy	O
of	O
methods	O
for	O
doing	O
related	O
tasks	O
that	O
work	O
for	O
similar	O
reasons	O
rather	O
than	O
as	O
a	O
long	O
list	O
of	O
algorithms	O
that	O
each	O
have	O
separate	O
justifications	O
challenges	O
motivating	O
deep	O
learning	O
the	O
simple	O
machine	B
learning	I
algorithms	O
described	O
in	O
this	O
chapter	O
work	O
very	O
well	O
on	O
a	O
wide	O
variety	O
of	O
important	O
problems	O
however	O
they	O
have	O
not	O
succeeded	O
in	O
solving	O
the	O
central	O
problems	O
in	O
ai	O
such	O
as	O
recognizing	O
speech	O
or	O
recognizing	O
objects	O
the	O
development	O
of	O
deep	O
learning	O
was	O
motivated	O
in	O
part	O
by	O
the	O
failure	O
of	O
traditional	O
algorithms	O
to	O
generalize	O
well	O
on	O
such	O
ai	O
tasks	O
this	O
section	O
is	O
about	O
how	O
the	O
challenge	B
of	O
generalizing	O
to	O
new	O
examples	O
becomes	O
exponentially	O
more	O
difficult	O
when	O
working	O
with	O
high-dimensional	O
data	O
and	O
how	O
the	O
mechanisms	O
used	O
to	O
achieve	O
generalization	B
in	O
traditional	O
machine	B
learning	I
are	O
insufficient	O
to	O
learn	O
complicated	O
functions	O
in	O
high-dimensional	O
spaces	O
such	O
spaces	O
also	O
often	O
impose	O
high	O
computational	O
costs	O
deep	O
learning	O
was	O
designed	O
to	O
overcome	O
these	O
and	O
other	O
obstacles	O
the	O
curse	B
of	I
dimensionality	I
many	O
machine	B
learning	I
problems	O
become	O
exceedingly	O
difficult	O
when	O
the	O
number	O
of	O
dimensions	O
in	O
the	O
data	O
is	O
high	O
this	O
phenomenon	O
is	O
known	O
as	O
the	O
curse	B
of	I
dimensionality	I
of	O
particular	O
concern	O
is	O
that	O
the	O
number	O
of	O
possible	O
distinct	O
configurations	O
of	O
a	O
set	O
of	O
variables	O
increases	O
exponentially	O
as	O
the	O
number	O
of	O
variables	O
increases	O
chapter	O
machine	B
learning	I
basics	O
figure	O
as	O
the	O
number	O
of	O
relevant	O
dimensions	O
of	O
the	O
data	O
increases	O
left	O
to	O
right	O
the	O
number	O
of	O
configurations	O
of	O
interest	O
may	O
grow	O
exponentially	O
this	O
one-dimensional	O
example	B
we	O
have	O
one	O
variable	O
for	O
which	O
we	O
only	O
care	O
to	O
distinguish	O
regions	O
of	O
interest	O
with	O
enough	O
examples	O
falling	O
within	O
each	O
of	O
these	O
regions	O
region	O
corresponds	O
to	O
a	O
cell	O
in	O
the	O
illustration	O
learning	O
algorithms	O
can	O
easily	O
generalize	O
correctly	O
a	O
straightforward	O
way	O
to	O
generalize	O
is	O
to	O
estimate	O
the	O
value	O
of	O
the	O
target	O
function	O
within	O
each	O
region	O
possibly	O
interpolate	O
between	O
neighboring	O
regions	O
with	O
dimensions	O
it	O
is	O
more	O
difficult	O
to	O
distinguish	O
different	O
values	O
of	O
each	O
variable	O
we	O
need	O
to	O
keep	O
track	O
of	O
up	O
to	O
regions	O
and	O
we	O
need	O
at	O
least	O
that	O
many	O
examples	O
to	O
cover	O
all	O
those	O
regions	O
regions	O
and	O
at	O
least	O
that	O
many	O
examples	O
for	O
d	O
dimensions	O
and	O
v	O
values	O
to	O
be	O
distinguished	O
along	O
each	O
axis	O
we	O
seem	O
to	O
need	O
ov	O
d	O
regions	O
and	O
examples	O
this	O
is	O
an	O
instance	O
of	O
the	O
curse	B
of	I
dimensionality	I
figure	O
graciously	O
provided	O
by	O
nicolas	O
chapados	O
with	O
dimensions	O
this	O
grows	O
to	O
the	O
curse	B
of	I
dimensionality	I
arises	O
in	O
many	O
places	O
in	O
computer	O
science	O
and	O
especially	O
so	O
in	O
machine	B
learning	I
one	O
challenge	B
posed	O
by	O
the	O
curse	B
of	I
dimensionality	I
is	O
a	O
statistical	O
challenge	B
as	O
illustrated	O
in	O
figure	O
a	O
statistical	O
challenge	B
arises	O
because	O
the	O
number	O
of	O
possible	O
configurations	O
of	O
x	O
is	O
much	O
larger	O
than	O
the	O
number	O
of	O
training	O
examples	O
to	O
understand	O
the	O
issue	O
let	O
us	O
consider	O
that	O
the	O
input	O
space	O
is	O
organized	O
into	O
a	O
grid	O
like	O
in	O
the	O
figure	O
we	O
can	O
describe	O
low-dimensional	O
space	O
with	O
a	O
low	O
number	O
of	O
grid	O
cells	O
that	O
are	O
mostly	O
occupied	O
by	O
the	O
data	O
when	O
generalizing	O
to	O
a	O
new	O
data	O
point	O
we	O
can	O
usually	O
tell	O
what	O
to	O
do	O
simply	O
by	O
inspecting	O
the	O
training	O
examples	O
that	O
lie	O
in	O
the	O
same	O
cell	O
as	O
the	O
new	O
input	O
for	O
example	B
if	O
estimating	O
the	O
probability	O
density	O
at	O
some	O
point	O
x	O
we	O
can	O
just	O
return	O
the	O
number	O
of	O
training	O
examples	O
in	O
the	O
same	O
unit	O
volume	O
cell	O
as	O
x	O
divided	O
by	O
the	O
total	O
number	O
of	O
training	O
examples	O
if	O
we	O
wish	O
to	O
classify	O
an	O
example	B
we	O
can	O
return	O
the	O
most	O
common	O
class	O
of	O
training	O
examples	O
in	O
the	O
same	O
cell	O
if	O
we	O
are	O
doing	O
regression	B
we	O
can	O
average	O
the	O
target	O
values	O
observed	O
over	O
the	O
examples	O
in	O
that	O
cell	O
but	O
what	O
about	O
the	O
cells	O
for	O
which	O
we	O
have	O
seen	O
no	O
example	B
because	O
in	O
high-dimensional	O
spaces	O
the	O
number	O
of	O
configurations	O
is	O
huge	O
much	O
larger	O
than	O
our	O
number	O
of	O
examples	O
a	O
typical	O
grid	O
cell	O
has	O
no	O
training	O
example	B
associated	O
with	O
it	O
how	O
could	O
we	O
possibly	O
say	O
something	O
chapter	O
machine	B
learning	I
basics	O
meaningful	O
about	O
these	O
new	O
configurations	O
many	O
traditional	O
machine	B
learning	I
algorithms	O
simply	O
assume	O
that	O
the	O
output	O
at	O
a	O
new	O
point	O
should	O
be	O
approximately	O
the	O
same	O
as	O
the	O
output	O
at	O
the	O
nearest	O
training	O
point	O
local	O
constancy	O
and	O
smoothness	O
regularization	O
in	O
order	O
to	O
generalize	O
well	O
machine	B
learning	I
algorithms	O
need	O
to	O
be	O
guided	O
by	O
prior	O
beliefs	O
about	O
what	O
kind	O
of	O
function	O
they	O
should	O
learn	O
previously	O
we	O
have	O
seen	O
these	O
priors	O
incorporated	O
as	O
explicit	O
beliefs	O
in	O
the	O
form	O
of	O
probability	O
distributions	O
over	O
parameters	O
of	O
the	O
model	O
more	O
informally	O
we	O
may	O
also	O
discuss	O
prior	O
beliefs	O
as	O
directly	O
influencing	O
the	O
itself	O
and	O
only	O
indirectly	O
acting	O
on	O
the	O
parameters	O
via	O
their	O
effect	O
on	O
the	O
function	O
additionally	O
we	O
informally	O
discuss	O
prior	O
beliefs	O
as	O
being	O
expressed	O
implicitly	O
by	O
choosing	O
algorithms	O
that	O
are	O
biased	O
toward	O
choosing	O
some	O
class	O
of	O
functions	O
over	O
another	O
even	O
though	O
these	O
biases	O
may	O
not	O
be	O
expressed	O
even	O
possible	O
to	O
express	O
in	O
terms	O
of	O
a	O
probability	B
distribution	I
representing	O
our	O
degree	O
of	O
belief	O
in	O
various	O
functions	O
function	O
among	O
the	O
most	O
widely	O
used	O
of	O
these	O
implicit	O
priors	O
is	O
the	O
smoothness	O
prior	O
or	O
local	O
constancy	O
prior	O
this	O
prior	O
states	O
that	O
the	O
function	O
we	O
learn	O
should	O
not	O
change	O
very	O
much	O
within	O
a	O
small	O
region	O
many	O
simpler	O
algorithms	O
rely	O
exclusively	O
on	O
this	O
prior	O
to	O
generalize	O
well	O
and	O
as	O
a	O
result	O
they	O
fail	O
to	O
scale	O
to	O
the	O
statistical	O
challenges	O
involved	O
in	O
solving	O
ailevel	O
tasks	O
throughout	O
this	O
book	O
we	O
will	O
describe	O
how	O
deep	O
learning	O
introduces	O
additional	O
and	O
implicit	O
priors	O
in	O
order	O
to	O
reduce	O
the	O
generalization	B
error	O
on	O
sophisticated	O
tasks	O
here	O
we	O
explain	O
why	O
the	O
smoothness	O
prior	O
alone	O
is	O
insufficient	O
for	O
these	O
tasks	O
there	O
are	O
many	O
different	O
ways	O
to	O
implicitly	O
or	O
explicitly	O
express	O
a	O
prior	O
belief	O
that	O
the	O
learned	O
function	O
should	O
be	O
smooth	O
or	O
locally	O
constant	O
all	O
of	O
these	O
different	O
methods	O
are	O
designed	O
to	O
encourage	O
the	O
learning	O
process	O
to	O
learn	O
a	O
function	O
f	O
that	O
satisfies	O
the	O
condition	O
x	O
f	O
x	O
f	O
for	O
most	O
configurations	O
x	O
and	O
small	O
change	O
in	O
other	O
words	O
if	O
we	O
know	O
a	O
good	O
answer	O
for	O
an	O
input	O
x	O
example	B
if	O
x	O
is	O
a	O
labeled	O
training	O
example	B
then	O
that	O
answer	O
is	O
probably	O
good	O
in	O
the	O
neighborhood	O
of	O
x	O
if	O
we	O
have	O
several	O
good	O
answers	O
in	O
some	O
neighborhood	O
we	O
would	O
combine	O
them	O
some	O
form	O
of	O
averaging	O
or	O
interpolation	O
to	O
produce	O
an	O
answer	O
that	O
agrees	O
with	O
as	O
many	O
of	O
them	O
as	O
much	O
as	O
possible	O
an	O
extreme	O
example	B
of	O
the	O
local	O
constancy	O
approach	O
is	O
the	O
k-nearest	O
neighbors	O
family	O
of	O
learning	O
algorithms	O
these	O
predictors	O
are	O
literally	O
constant	O
over	O
each	O
chapter	O
machine	B
learning	I
basics	O
region	O
containing	O
all	O
the	O
points	O
x	O
that	O
have	O
the	O
same	O
set	O
of	O
k	O
nearest	O
neighbors	O
in	O
the	O
training	O
set	O
for	O
k	O
the	O
number	O
of	O
distinguishable	O
regions	O
cannot	O
be	O
more	O
than	O
the	O
number	O
of	O
training	O
examples	O
while	O
the	O
k-nearest	O
neighbors	O
algorithm	O
copies	O
the	O
output	O
from	O
nearby	O
training	O
examples	O
most	O
kernel	O
machines	O
interpolate	O
between	O
training	O
set	O
outputs	O
associated	O
with	O
nearby	O
training	O
examples	O
an	O
important	O
class	O
of	O
kernels	O
is	O
the	O
family	O
of	O
local	O
kernels	O
where	O
ku	O
v	O
is	O
large	O
when	O
u	O
v	O
and	O
decreases	O
as	O
u	O
and	O
v	O
grow	O
farther	O
apart	O
from	O
each	O
other	O
a	O
local	O
kernel	O
can	O
be	O
thought	O
of	O
as	O
a	O
similarity	O
function	O
that	O
performs	O
template	B
matching	I
by	O
measuring	O
how	O
closely	O
a	O
test	O
example	B
x	O
resembles	O
each	O
training	O
example	B
x	O
much	O
of	O
the	O
modern	O
motivation	O
for	O
deep	O
learning	O
is	O
derived	O
from	O
studying	O
the	O
limitations	O
of	O
local	O
template	B
matching	I
and	O
how	O
deep	O
models	O
are	O
able	O
to	O
succeed	O
in	O
cases	O
where	O
local	O
template	B
matching	I
fails	O
bengio	O
et	O
al	O
decision	O
trees	O
also	O
suffer	O
from	O
the	O
limitations	O
of	O
exclusively	O
smoothness-based	O
learning	O
because	O
they	O
break	O
the	O
input	O
space	O
into	O
as	O
many	O
regions	O
as	O
there	O
are	O
leaves	O
and	O
use	O
a	O
separate	O
parameter	O
sometimes	O
many	O
parameters	O
for	O
extensions	O
of	O
decision	O
trees	O
in	O
each	O
region	O
if	O
the	O
target	O
function	O
requires	O
a	O
tree	O
with	O
at	O
least	O
n	O
leaves	O
to	O
be	O
represented	O
accurately	O
then	O
at	O
least	O
n	O
training	O
examples	O
are	O
required	O
to	O
fit	O
the	O
tree	O
a	O
multiple	O
of	O
n	O
is	O
needed	O
to	O
achieve	O
some	O
level	O
of	O
statistical	O
confidence	O
in	O
the	O
predicted	O
output	O
in	O
general	O
to	O
distinguish	O
ok	O
regions	O
in	O
input	O
space	O
all	O
of	O
these	O
methods	O
require	O
ok	O
examples	O
typically	O
there	O
are	O
o	O
parameters	O
with	O
parameters	O
associated	O
with	O
each	O
of	O
the	O
ok	O
regions	O
the	O
case	O
of	O
a	O
nearest	O
neighbor	O
scenario	O
where	O
each	O
training	O
example	B
can	O
be	O
used	O
to	O
define	O
at	O
most	O
one	O
region	O
is	O
illustrated	O
in	O
figure	O
is	O
there	O
a	O
way	O
to	O
represent	O
a	O
complex	O
function	O
that	O
has	O
many	O
more	O
regions	O
to	O
be	O
distinguished	O
than	O
the	O
number	O
of	O
training	O
examples	O
clearly	O
assuming	O
only	O
smoothness	O
of	O
the	O
underlying	O
function	O
will	O
not	O
allow	O
a	O
learner	O
to	O
do	O
that	O
for	O
example	B
imagine	O
that	O
the	O
target	O
function	O
is	O
a	O
kind	O
of	O
checkerboard	O
a	O
checkerboard	O
contains	O
many	O
variations	O
but	O
there	O
is	O
a	O
simple	O
structure	O
to	O
them	O
imagine	O
what	O
happens	O
when	O
the	O
number	O
of	O
training	O
examples	O
is	O
substantially	O
smaller	O
than	O
the	O
number	O
of	O
black	O
and	O
white	O
squares	O
on	O
the	O
checkerboard	O
based	O
on	O
only	O
local	O
generalization	B
and	O
the	O
smoothness	O
or	O
local	O
constancy	O
prior	O
we	O
would	O
be	O
guaranteed	O
to	O
correctly	O
guess	O
the	O
color	O
of	O
a	O
new	O
point	O
if	O
it	O
lies	O
within	O
the	O
same	O
checkerboard	O
square	O
as	O
a	O
training	O
example	B
there	O
is	O
no	O
guarantee	O
that	O
the	O
learner	O
could	O
correctly	O
extend	O
the	O
checkerboard	O
pattern	O
to	O
points	O
lying	O
in	O
squares	O
that	O
do	O
not	O
contain	O
training	O
examples	O
with	O
this	O
prior	O
alone	O
the	O
only	O
information	O
that	O
an	O
example	B
tells	O
us	O
is	O
the	O
color	O
of	O
its	O
square	O
and	O
the	O
only	O
way	O
to	O
get	O
the	O
colors	O
of	O
the	O
chapter	O
machine	B
learning	I
basics	O
figure	O
illustration	O
of	O
how	O
the	O
nearest	O
neighbor	O
algorithm	O
breaks	O
up	O
the	O
input	O
space	O
into	O
regions	O
an	O
example	B
here	O
by	O
a	O
circle	O
within	O
each	O
region	O
defines	O
the	O
region	O
boundary	O
here	O
by	O
the	O
lines	O
the	O
y	O
value	O
associated	O
with	O
each	O
example	B
defines	O
what	O
the	O
output	O
should	O
be	O
for	O
all	O
points	O
within	O
the	O
corresponding	O
region	O
the	O
regions	O
defined	O
by	O
nearest	O
neighbor	O
matching	O
form	O
a	O
geometric	O
pattern	O
called	O
a	O
voronoi	O
diagram	O
the	O
number	O
of	O
these	O
contiguous	O
regions	O
cannot	O
grow	O
faster	O
than	O
the	O
number	O
of	O
training	O
examples	O
while	O
this	O
figure	O
illustrates	O
the	O
behavior	O
of	O
the	O
nearest	O
neighbor	O
algorithm	O
specifically	O
other	O
machine	B
learning	I
algorithms	O
that	O
rely	O
exclusively	O
on	O
the	O
local	O
smoothness	O
prior	O
for	O
generalization	B
exhibit	O
similar	O
behaviors	O
each	O
training	O
example	B
only	O
informs	O
the	O
learner	O
about	O
how	O
to	O
generalize	O
in	O
some	O
neighborhood	O
immediately	O
surrounding	O
that	O
example	B
chapter	O
machine	B
learning	I
basics	O
entire	O
checkerboard	O
right	O
is	O
to	O
cover	O
each	O
of	O
its	O
cells	O
with	O
at	O
least	O
one	O
example	B
the	O
smoothness	O
assumption	O
and	O
the	O
associated	O
non-parametric	O
learning	O
algorithms	O
work	O
extremely	O
well	O
so	O
long	O
as	O
there	O
are	O
enough	O
examples	O
for	O
the	O
learning	O
algorithm	O
to	O
observe	O
high	O
points	O
on	O
most	O
peaks	O
and	O
low	O
points	O
on	O
most	O
valleys	O
of	O
the	O
true	O
underlying	O
function	O
to	O
be	O
learned	O
this	O
is	O
generally	O
true	O
when	O
the	O
function	O
to	O
be	O
learned	O
is	O
smooth	O
enough	O
and	O
varies	O
in	O
few	O
enough	O
dimensions	O
in	O
high	O
dimensions	O
even	O
a	O
very	O
smooth	O
function	O
can	O
change	O
smoothly	O
but	O
in	O
a	O
different	O
way	O
along	O
each	O
dimension	O
if	O
the	O
function	O
additionally	O
behaves	O
differently	O
in	O
different	O
regions	O
it	O
can	O
become	O
extremely	O
complicated	O
to	O
describe	O
with	O
a	O
set	O
of	O
training	O
examples	O
if	O
the	O
function	O
is	O
complicated	O
want	O
to	O
distinguish	O
a	O
huge	O
number	O
of	O
regions	O
compared	O
to	O
the	O
number	O
of	O
examples	O
is	O
there	O
any	O
hope	O
to	O
generalize	O
well	O
the	O
answer	O
to	O
both	O
of	O
these	O
questions	O
whether	O
it	O
is	O
possible	O
to	O
represent	O
a	O
complicated	O
function	O
efficiently	O
and	O
whether	O
it	O
is	O
possible	O
for	O
the	O
estimated	O
function	O
to	O
generalize	O
well	O
to	O
new	O
inputs	O
is	O
yes	O
the	O
key	O
insight	O
is	O
that	O
a	O
very	O
large	O
number	O
of	O
regions	O
e	O
g	O
can	O
be	O
defined	O
with	O
ok	O
examples	O
so	O
long	O
as	O
we	O
introduce	O
some	O
dependencies	O
between	O
the	O
regions	O
via	O
additional	O
assumptions	O
about	O
the	O
underlying	O
data	O
generating	O
distribution	O
in	O
this	O
way	O
we	O
can	O
actually	O
generalize	O
non-locally	O
many	O
different	O
deep	O
learning	O
algorithms	O
provide	O
implicit	O
or	O
explicit	O
assumptions	O
that	O
are	O
reasonable	O
for	O
a	O
broad	O
range	O
of	O
ai	O
tasks	O
in	O
order	O
to	O
capture	O
these	O
advantages	O
bengio	O
and	O
monperrus	O
bengio	O
et	O
al	O
other	O
approaches	O
to	O
machine	B
learning	I
often	O
make	O
stronger	O
task-specific	O
assumptions	O
for	O
example	B
we	O
could	O
easily	O
solve	O
the	O
checkerboard	O
task	O
by	O
providing	O
the	O
assumption	O
that	O
the	O
target	O
function	O
is	O
periodic	O
usually	O
we	O
do	O
not	O
include	O
such	O
strong	O
task-specific	O
assumptions	O
into	O
neural	O
networks	O
so	O
that	O
they	O
can	O
generalize	O
to	O
a	O
much	O
wider	O
variety	O
of	O
structures	O
ai	O
tasks	O
have	O
structure	O
that	O
is	O
much	O
too	O
complex	O
to	O
be	O
limited	O
to	O
simple	O
manually	O
specified	O
properties	O
such	O
as	O
periodicity	O
so	O
we	O
want	O
learning	O
algorithms	O
that	O
embody	O
more	O
general-purpose	O
assumptions	O
the	O
core	O
idea	O
in	O
deep	O
learning	O
is	O
that	O
we	O
assume	O
that	O
the	O
data	O
was	O
generated	O
by	O
the	O
composition	O
of	O
factors	O
or	O
features	O
potentially	O
at	O
multiple	O
levels	O
in	O
a	O
hierarchy	O
many	O
other	O
similarly	O
generic	O
assumptions	O
can	O
further	O
improve	O
deep	O
learning	O
algorithms	O
these	O
apparently	O
mild	O
assumptions	O
allow	O
an	O
exponential	O
gain	O
in	O
the	O
relationship	O
between	O
the	O
number	O
of	O
examples	O
and	O
the	O
number	O
of	O
regions	O
that	O
can	O
be	O
distinguished	O
these	O
exponential	O
gains	O
are	O
described	O
more	O
precisely	O
in	O
sections	O
the	O
exponential	O
advantages	O
conferred	O
by	O
the	O
use	O
of	O
deep	O
distributed	O
representations	O
counter	O
the	O
exponential	O
challenges	O
posed	O
by	O
the	O
curse	B
of	I
dimensionality	I
and	O
chapter	O
machine	B
learning	I
basics	O
manifold	B
learning	I
an	O
important	O
concept	O
underlying	O
many	O
ideas	O
in	O
machine	B
learning	I
is	O
that	O
of	O
a	O
manifold	B
a	O
manifold	B
is	O
a	O
connected	O
region	O
mathematically	O
it	O
is	O
a	O
set	O
of	O
points	O
associated	O
with	O
a	O
neighborhood	O
around	O
each	O
point	O
from	O
any	O
given	O
point	O
the	O
manifold	B
locally	O
appears	O
to	O
be	O
a	O
euclidean	O
space	O
in	O
everyday	O
life	O
we	O
experience	O
the	O
surface	O
of	O
the	O
world	O
as	O
a	O
plane	O
but	O
it	O
is	O
in	O
fact	O
a	O
spherical	O
manifold	B
in	O
space	O
the	O
definition	O
of	O
a	O
neighborhood	O
surrounding	O
each	O
point	O
implies	O
the	O
existence	O
of	O
transformations	O
that	O
can	O
be	O
applied	O
to	O
move	O
on	O
the	O
manifold	B
from	O
one	O
position	O
to	O
a	O
neighboring	O
one	O
in	O
the	O
example	B
of	O
the	O
world	O
s	O
surface	O
as	O
a	O
manifold	B
one	O
can	O
walk	O
north	O
south	O
east	O
or	O
west	O
although	O
there	O
is	O
a	O
formal	O
mathematical	O
meaning	O
to	O
the	O
term	O
manifold	B
in	O
machine	B
learning	I
it	O
tends	O
to	O
be	O
used	O
more	O
loosely	O
to	O
designate	O
a	O
connected	O
set	O
of	O
points	O
that	O
can	O
be	O
approximated	O
well	O
by	O
considering	O
only	O
a	O
small	O
number	O
of	O
degrees	O
of	O
freedom	O
or	O
dimensions	O
embedded	O
in	O
a	O
higher-dimensional	O
space	O
each	O
dimension	O
corresponds	O
to	O
a	O
local	O
direction	O
of	O
variation	O
see	O
figure	O
for	O
an	O
example	B
of	O
training	O
data	O
lying	O
near	O
a	O
one-dimensional	O
manifold	B
embedded	O
in	O
twodimensional	O
space	O
in	O
the	O
context	O
of	O
machine	B
learning	I
we	O
allow	O
the	O
dimensionality	O
of	O
the	O
manifold	B
to	O
vary	O
from	O
one	O
point	O
to	O
another	O
this	O
often	O
happens	O
when	O
a	O
manifold	B
intersects	O
itself	O
for	O
example	B
a	O
figure	O
eight	O
is	O
a	O
manifold	B
that	O
has	O
a	O
single	O
dimension	O
in	O
most	O
places	O
but	O
two	O
dimensions	O
at	O
the	O
intersection	O
at	O
the	O
center	O
figure	O
data	O
sampled	O
from	O
a	O
distribution	O
in	O
a	O
two-dimensional	O
space	O
that	O
is	O
actually	O
concentrated	O
near	O
a	O
one-dimensional	O
manifold	B
like	O
a	O
twisted	O
string	O
the	O
solid	O
line	O
indicates	O
the	O
underlying	O
manifold	B
that	O
the	O
learner	O
should	O
infer	O
chapter	O
machine	B
learning	I
basics	O
many	O
machine	B
learning	I
problems	O
seem	O
hopeless	O
if	O
we	O
expect	O
the	O
machine	O
n	O
learning	O
algorithm	O
to	O
learn	O
functions	O
with	O
interesting	O
variations	O
across	O
all	O
of	O
r	O
manifold	B
learning	I
algorithms	O
surmount	O
this	O
obstacle	O
by	O
assuming	O
that	O
most	O
n	O
consists	O
of	O
invalid	O
inputs	O
and	O
that	O
interesting	O
inputs	O
occur	O
only	O
along	O
of	O
r	O
a	O
collection	O
of	O
manifolds	O
containing	O
a	O
small	O
subset	O
of	O
points	O
with	O
interesting	O
variations	O
in	O
the	O
output	O
of	O
the	O
learned	O
function	O
occurring	O
only	O
along	O
directions	O
that	O
lie	O
on	O
the	O
manifold	B
or	O
with	O
interesting	O
variations	O
happening	O
only	O
when	O
we	O
move	O
from	O
one	O
manifold	B
to	O
another	O
manifold	B
learning	I
was	O
introduced	O
in	O
the	O
case	O
of	O
continuous-valued	O
data	O
and	O
the	O
unsupervised	O
learning	O
setting	O
although	O
this	O
probability	O
concentration	O
idea	O
can	O
be	O
generalized	O
to	O
both	O
discrete	O
data	O
and	O
the	O
supervised	B
learning	I
setting	O
the	O
key	O
assumption	O
remains	O
that	O
probability	O
mass	O
is	O
highly	O
concentrated	O
the	O
assumption	O
that	O
the	O
data	O
lies	O
along	O
a	O
low-dimensional	O
manifold	B
may	O
not	O
always	O
be	O
correct	O
or	O
useful	O
we	O
argue	O
that	O
in	O
the	O
context	O
of	O
ai	O
tasks	O
such	O
as	O
those	O
that	O
involve	O
processing	O
images	O
sounds	O
or	O
text	O
the	O
manifold	B
assumption	O
is	O
at	O
least	O
approximately	O
correct	O
the	O
evidence	O
in	O
favor	O
of	O
this	O
assumption	O
consists	O
of	O
two	O
categories	O
of	O
observations	O
the	O
first	O
observation	O
in	O
favor	O
of	O
the	O
manifold	B
hypothesis	I
is	O
that	O
the	O
probability	B
distribution	I
over	O
images	O
text	O
strings	O
and	O
sounds	O
that	O
occur	O
in	O
real	O
life	O
is	O
highly	O
concentrated	O
uniform	O
noise	O
essentially	O
never	O
resembles	O
structured	O
inputs	O
from	O
these	O
domains	O
figure	O
shows	O
how	O
instead	O
uniformly	O
sampled	O
points	O
look	O
like	O
the	O
patterns	O
of	O
static	O
that	O
appear	O
on	O
analog	O
television	O
sets	O
when	O
no	O
signal	O
is	O
available	O
similarly	O
if	O
you	O
generate	O
a	O
document	O
by	O
picking	O
letters	O
uniformly	O
at	O
random	O
what	O
is	O
the	O
probability	O
that	O
you	O
will	O
get	O
a	O
meaningful	O
english-language	O
text	O
almost	O
zero	O
again	O
because	O
most	O
of	O
the	O
long	O
sequences	O
of	O
letters	O
do	O
not	O
correspond	O
to	O
a	O
natural	O
language	O
sequence	O
the	O
distribution	O
of	O
natural	O
language	O
sequences	O
occupies	O
a	O
very	O
small	O
volume	O
in	O
the	O
total	O
space	O
of	O
sequences	O
of	O
letters	O
chapter	O
machine	B
learning	I
basics	O
figure	O
sampling	O
images	O
uniformly	O
at	O
random	O
randomly	O
picking	O
each	O
pixel	O
according	O
to	O
a	O
uniform	B
distribution	I
gives	O
rise	O
to	O
noisy	O
images	O
although	O
there	O
is	O
a	O
nonzero	O
probability	O
to	O
generate	O
an	O
image	O
of	O
a	O
face	O
or	O
any	O
other	O
object	O
frequently	O
encountered	O
in	O
ai	O
applications	O
we	O
never	O
actually	O
observe	O
this	O
happening	O
in	O
practice	O
this	O
suggests	O
that	O
the	O
images	O
encountered	O
in	O
ai	O
applications	O
occupy	O
a	O
negligible	O
proportion	O
of	O
the	O
volume	O
of	O
image	O
space	O
of	O
course	O
concentrated	O
probability	O
distributions	O
are	O
not	O
sufficient	O
to	O
show	O
that	O
the	O
data	O
lies	O
on	O
a	O
reasonably	O
small	O
number	O
of	O
manifolds	O
we	O
must	O
also	O
establish	O
that	O
the	O
examples	O
we	O
encounter	O
are	O
connected	O
to	O
each	O
other	O
by	O
other	O
chapter	O
machine	B
learning	I
basics	O
examples	O
with	O
each	O
example	B
surrounded	O
by	O
other	O
highly	O
similar	O
examples	O
that	O
may	O
be	O
reached	O
by	O
applying	O
transformations	O
to	O
traverse	O
the	O
manifold	B
the	O
second	O
argument	O
in	O
favor	O
of	O
the	O
manifold	B
hypothesis	I
is	O
that	O
we	O
can	O
also	O
imagine	O
such	O
neighborhoods	O
and	O
transformations	O
at	O
least	O
informally	O
in	O
the	O
case	O
of	O
images	O
we	O
can	O
certainly	O
think	O
of	O
many	O
possible	O
transformations	O
that	O
allow	O
us	O
to	O
trace	O
out	O
a	O
manifold	B
in	O
image	O
space	O
we	O
can	O
gradually	O
dim	O
or	O
brighten	O
the	O
lights	O
gradually	O
move	O
or	O
rotate	O
objects	O
in	O
the	O
image	O
gradually	O
alter	O
the	O
colors	O
on	O
the	O
surfaces	O
of	O
objects	O
etc	O
it	O
remains	O
likely	O
that	O
there	O
are	O
multiple	O
manifolds	O
involved	O
in	O
most	O
applications	O
for	O
example	B
the	O
manifold	B
of	O
images	O
of	O
human	O
faces	O
may	O
not	O
be	O
connected	O
to	O
the	O
manifold	B
of	O
images	O
of	O
cat	O
faces	O
these	O
thought	O
experiments	O
supporting	O
the	O
manifold	B
hypotheses	O
convey	O
some	O
intuitive	O
reasons	O
supporting	O
it	O
more	O
rigorous	O
experiments	O
narayanan	O
and	O
mitter	O
sch	O
lkopf	O
et	O
al	O
brand	O
belkin	O
and	O
niyogi	O
donoho	O
and	O
grimes	O
weinberger	O
and	O
saul	O
clearly	O
support	O
the	O
hypothesis	O
for	O
a	O
large	O
class	O
of	O
datasets	O
of	O
interest	O
in	O
ai	O
roweis	O
and	O
saul	O
tenenbaum	O
et	O
al	O
when	O
the	O
data	O
lies	O
on	O
a	O
low-dimensional	O
manifold	B
it	O
can	O
be	O
most	O
natural	O
for	O
machine	B
learning	I
algorithms	O
to	O
represent	O
the	O
data	O
in	O
terms	O
of	O
coordinates	O
on	O
the	O
manifold	B
rather	O
than	O
in	O
terms	O
of	O
coordinates	O
in	O
r	O
n	O
in	O
everyday	O
life	O
we	O
can	O
think	O
of	O
roads	O
as	O
manifolds	O
embedded	O
in	O
space	O
we	O
give	O
directions	O
to	O
specific	O
addresses	O
in	O
terms	O
of	O
address	O
numbers	O
along	O
these	O
roads	O
not	O
in	O
terms	O
of	O
coordinates	O
in	O
space	O
extracting	O
these	O
manifold	B
coordinates	O
is	O
challenging	O
but	O
holds	O
the	O
promise	O
to	O
improve	O
many	O
machine	B
learning	I
algorithms	O
this	O
general	O
principle	O
is	O
applied	O
in	O
many	O
contexts	O
figure	O
shows	O
the	O
manifold	B
structure	O
of	O
a	O
dataset	B
consisting	O
of	O
faces	O
by	O
the	O
end	O
of	O
this	O
book	O
we	O
will	O
have	O
developed	O
the	O
methods	O
necessary	O
to	O
learn	O
such	O
a	O
manifold	B
structure	O
in	O
figure	O
we	O
will	O
see	O
how	O
a	O
machine	B
learning	I
algorithm	O
can	O
successfully	O
accomplish	O
this	O
goal	O
this	O
concludes	O
part	O
which	O
has	O
provided	O
the	O
basic	O
concepts	O
in	O
mathematics	O
and	O
machine	B
learning	I
which	O
are	O
employed	O
throughout	O
the	O
remaining	O
parts	O
of	O
the	O
book	O
you	O
are	O
now	O
prepared	O
to	O
embark	O
upon	O
your	O
study	O
of	O
deep	O
learning	O
i	O
chapter	O
machine	B
learning	I
basics	O
gong	O
et	O
al	O
figure	O
training	O
examples	O
from	O
the	O
qmul	O
multiview	O
face	O
dataset	B
for	O
which	O
the	O
subjects	O
were	O
asked	O
to	O
move	O
in	O
such	O
a	O
way	O
as	O
to	O
cover	O
the	O
two-dimensional	O
manifold	B
corresponding	O
to	O
two	O
angles	O
of	O
rotation	O
we	O
would	O
like	O
learning	O
algorithms	O
to	O
be	O
able	O
to	O
discover	O
and	O
disentangle	O
such	O
manifold	B
coordinates	O
figure	O
illustrates	O
such	O
a	O
feat	O
part	O
ii	O
deep	O
networks	O
modern	O
practices	O
this	O
part	O
of	O
the	O
book	O
summarizes	O
the	O
state	O
of	O
modern	O
deep	O
learning	O
as	O
it	O
is	O
used	O
to	O
solve	O
practical	O
applications	O
deep	O
learning	O
has	O
a	O
long	O
history	O
and	O
many	O
aspirations	O
several	O
approaches	O
have	O
been	O
proposed	O
that	O
have	O
yet	O
to	O
entirely	O
bear	O
fruit	O
several	O
ambitious	O
goals	O
have	O
yet	O
to	O
be	O
realized	O
these	O
less-developed	O
branches	O
of	O
deep	O
learning	O
appear	O
in	O
the	O
final	O
part	O
of	O
the	O
book	O
this	O
part	O
focuses	O
only	O
on	O
those	O
approaches	O
that	O
are	O
essentially	O
working	O
tech	O
nologies	O
that	O
are	O
already	O
used	O
heavily	O
in	O
industry	O
modern	O
deep	O
learning	O
provides	O
a	O
very	O
powerful	O
framework	O
for	O
supervised	B
learning	I
by	O
adding	O
more	O
layers	O
and	O
more	O
units	O
within	O
a	O
layer	O
a	O
deep	O
network	O
can	O
represent	O
functions	O
of	O
increasing	O
complexity	O
most	O
tasks	O
that	O
consist	O
of	O
mapping	O
an	O
input	O
vector	O
to	O
an	O
output	O
vector	O
and	O
that	O
are	O
easy	O
for	O
a	O
person	O
to	O
do	O
rapidly	O
can	O
be	O
accomplished	O
via	O
deep	O
learning	O
given	O
sufficiently	O
large	O
models	O
and	O
sufficiently	O
large	O
datasets	O
of	O
labeled	O
training	O
examples	O
other	O
tasks	O
that	O
can	O
not	O
be	O
described	O
as	O
associating	O
one	O
vector	O
to	O
another	O
or	O
that	O
are	O
difficult	O
enough	O
that	O
a	O
person	O
would	O
require	O
time	O
to	O
think	O
and	O
reflect	O
in	O
order	O
to	O
accomplish	O
the	O
task	O
remain	O
beyond	O
the	O
scope	O
of	O
deep	O
learning	O
for	O
now	O
this	O
part	O
of	O
the	O
book	O
describes	O
the	O
core	O
parametric	O
function	O
approximation	O
technology	O
that	O
is	O
behind	O
nearly	O
all	O
modern	O
practical	O
applications	O
of	O
deep	O
learning	O
we	O
begin	O
by	O
describing	O
the	O
feedforward	O
deep	O
network	O
model	O
that	O
is	O
used	O
to	O
represent	O
these	O
functions	O
next	O
we	O
present	O
advanced	O
techniques	O
for	O
regularization	O
and	O
optimization	O
of	O
such	O
models	O
scaling	O
these	O
models	O
to	O
large	O
inputs	O
such	O
as	O
high	O
resolution	O
images	O
or	O
long	O
temporal	O
sequences	O
requires	O
specialization	O
we	O
introduce	O
the	O
convolutional	B
network	I
for	O
scaling	O
to	O
large	O
images	O
and	O
the	O
recurrent	B
neural	B
network	I
for	O
processing	O
temporal	O
sequences	O
finally	O
we	O
present	O
general	O
guidelines	O
for	O
the	O
practical	O
methodology	O
involved	O
in	O
designing	O
building	O
and	O
configuring	O
an	O
application	O
involving	O
deep	O
learning	O
and	O
review	O
some	O
of	O
the	O
applications	O
of	O
deep	O
learning	O
these	O
chapters	O
are	O
the	O
most	O
important	O
for	O
a	O
practitioner	O
someone	O
who	O
wants	O
to	O
begin	O
implementing	O
and	O
using	O
deep	O
learning	O
algorithms	O
to	O
solve	O
real-world	O
problems	O
today	O
chapter	O
deep	O
feedforward	O
networks	O
deep	O
feedforward	O
networks	O
also	O
often	O
called	O
feedforward	O
neural	O
networks	O
or	O
multilayer	O
perceptrons	O
are	O
the	O
quintessential	O
deep	O
learning	O
models	O
the	O
goal	O
of	O
a	O
feedforward	O
network	O
is	O
to	O
approximate	O
some	O
function	O
f	O
for	O
example	B
for	O
a	O
classifier	O
y	O
f	O
maps	O
an	O
input	O
x	O
to	O
a	O
category	O
y	O
a	O
feedforward	O
network	O
defines	O
a	O
mapping	O
y	O
f	O
and	O
learns	O
the	O
value	O
of	O
the	O
parameters	O
that	O
result	O
in	O
the	O
best	O
function	O
approximation	O
these	O
models	O
are	O
called	O
feedforward	O
because	O
information	O
flows	O
through	O
the	O
function	O
being	O
evaluated	O
from	O
x	O
through	O
the	O
intermediate	O
computations	O
used	O
to	O
define	O
f	O
and	O
finally	O
to	O
the	O
output	O
y	O
there	O
are	O
no	O
feedback	O
connections	O
in	O
which	O
outputs	O
of	O
the	O
model	O
are	O
fed	O
back	O
into	O
itself	O
when	O
feedforward	O
neural	O
networks	O
are	O
extended	O
to	O
include	O
feedback	O
connections	O
they	O
are	O
called	O
recurrent	O
neural	O
networks	O
presented	O
in	O
chapter	O
feedforward	O
networks	O
are	O
of	O
extreme	O
importance	O
to	O
machine	B
learning	I
practitioners	O
they	O
form	O
the	O
basis	O
of	O
many	O
important	O
commercial	O
applications	O
for	O
example	B
the	O
convolutional	O
networks	O
used	O
for	O
object	B
recognition	I
from	O
photos	O
are	O
a	O
specialized	O
kind	O
of	O
feedforward	O
network	O
feedforward	O
networks	O
are	O
a	O
conceptual	O
stepping	O
stone	O
on	O
the	O
path	O
to	O
recurrent	O
networks	O
which	O
power	O
many	O
natural	O
language	O
applications	O
feedforward	O
neural	O
networks	O
are	O
called	O
networks	O
because	O
they	O
are	O
typically	O
represented	O
by	O
composing	O
together	O
many	O
different	O
functions	O
the	O
model	O
is	O
associated	O
with	O
a	O
directed	O
acyclic	O
graph	O
describing	O
how	O
the	O
functions	O
are	O
composed	O
together	O
for	O
example	B
we	O
might	O
have	O
three	O
functions	O
f	O
f	O
and	O
f	O
connected	O
in	O
a	O
chain	O
to	O
form	O
fx	O
f	O
these	O
chain	O
structures	O
are	O
the	O
most	O
commonly	O
used	O
structures	O
of	O
neural	O
networks	O
in	O
this	O
case	O
f	O
is	O
called	O
the	O
first	O
layer	O
of	O
the	O
network	O
f	O
is	O
called	O
the	O
second	O
layer	O
and	O
so	O
on	O
the	O
overall	O
chapter	O
deep	O
feedforward	O
networks	O
length	O
of	O
the	O
chain	O
gives	O
the	O
depth	O
of	O
the	O
model	O
it	O
is	O
from	O
this	O
terminology	O
that	O
the	O
name	O
deep	O
learning	O
arises	O
the	O
final	O
layer	O
of	O
a	O
feedforward	O
network	O
is	O
called	O
the	O
output	O
layer	O
during	O
neural	B
network	I
training	O
we	O
drive	O
f	O
to	O
match	O
f	O
evaluated	O
the	O
training	O
data	O
provides	O
us	O
with	O
noisy	O
approximate	O
examples	O
of	O
f	O
at	O
different	O
training	O
points	O
each	O
example	B
x	O
is	O
accompanied	O
by	O
a	O
label	O
y	O
f	O
the	O
training	O
examples	O
specify	O
directly	O
what	O
the	O
output	O
layer	O
must	O
do	O
at	O
each	O
point	O
x	O
it	O
must	O
produce	O
a	O
value	O
that	O
is	O
close	O
to	O
y	O
the	O
behavior	O
of	O
the	O
other	O
layers	O
is	O
not	O
directly	O
specified	O
by	O
the	O
training	O
data	O
the	O
learning	O
algorithm	O
must	O
decide	O
how	O
to	O
use	O
those	O
layers	O
to	O
produce	O
the	O
desired	O
output	O
but	O
the	O
training	O
data	O
does	O
not	O
say	O
what	O
each	O
individual	O
layer	O
should	O
do	O
instead	O
the	O
learning	O
algorithm	O
must	O
decide	O
how	O
to	O
use	O
these	O
layers	O
to	O
best	O
implement	O
an	O
approximation	O
of	O
f	O
because	O
the	O
training	O
data	O
does	O
not	O
show	O
the	O
desired	O
output	O
for	O
each	O
of	O
these	O
layers	O
these	O
layers	O
are	O
called	O
hidden	O
layers	O
finally	O
these	O
networks	O
are	O
called	O
neural	O
because	O
they	O
are	O
loosely	O
inspired	O
by	O
neuroscience	B
each	O
hidden	B
layer	I
of	O
the	O
network	O
is	O
typically	O
vector-valued	O
the	O
dimensionality	O
of	O
these	O
hidden	O
layers	O
determines	O
the	O
width	O
of	O
the	O
model	O
each	O
element	O
of	O
the	O
vector	O
may	O
be	O
interpreted	O
as	O
playing	O
a	O
role	O
analogous	O
to	O
a	O
neuron	O
rather	O
than	O
thinking	O
of	O
the	O
layer	O
as	O
representing	O
a	O
single	O
vector-to-vector	O
function	O
we	O
can	O
also	O
think	O
of	O
the	O
layer	O
as	O
consisting	O
of	O
many	O
units	O
that	O
act	O
in	O
parallel	O
each	O
representing	O
a	O
vector-to-scalar	O
function	O
each	O
unit	O
resembles	O
a	O
neuron	O
in	O
the	O
sense	O
that	O
it	O
receives	O
input	O
from	O
many	O
other	O
units	O
and	O
computes	O
its	O
own	O
activation	O
value	O
the	O
idea	O
of	O
using	O
many	O
layers	O
of	O
vector-valued	O
representation	O
is	O
drawn	O
from	O
neuroscience	B
the	O
choice	O
of	O
the	O
functions	O
f	O
used	O
to	O
compute	O
these	O
representations	O
is	O
also	O
loosely	O
guided	O
by	O
neuroscientific	O
observations	O
about	O
the	O
functions	O
that	O
biological	O
neurons	O
compute	O
however	O
modern	O
neural	B
network	I
research	O
is	O
guided	O
by	O
many	O
mathematical	O
and	O
engineering	O
disciplines	O
and	O
the	O
goal	O
of	O
neural	O
networks	O
is	O
not	O
to	O
perfectly	O
model	O
the	O
brain	O
it	O
is	O
best	O
to	O
think	O
of	O
feedforward	O
networks	O
as	O
function	O
approximation	O
machines	O
that	O
are	O
designed	O
to	O
achieve	O
statistical	O
generalization	B
occasionally	O
drawing	O
some	O
insights	O
from	O
what	O
we	O
know	O
about	O
the	O
brain	O
rather	O
than	O
as	O
models	O
of	O
brain	O
function	O
one	O
way	O
to	O
understand	O
feedforward	O
networks	O
is	O
to	O
begin	O
with	O
linear	O
models	O
and	O
consider	O
how	O
to	O
overcome	O
their	O
limitations	O
linear	O
models	O
such	O
as	O
logistic	O
regression	B
and	O
linear	O
regression	B
are	O
appealing	O
because	O
they	O
may	O
be	O
fit	O
efficiently	O
and	O
reliably	O
either	O
in	O
closed	O
form	O
or	O
with	O
convex	B
optimization	I
linear	O
models	O
also	O
have	O
the	O
obvious	O
defect	O
that	O
the	O
model	O
capacity	O
is	O
limited	O
to	O
linear	O
functions	O
so	O
the	O
model	O
cannot	O
understand	O
the	O
interaction	O
between	O
any	O
two	O
input	O
variables	O
to	O
extend	O
linear	O
models	O
to	O
represent	O
nonlinear	O
functions	O
of	O
x	O
we	O
can	O
apply	O
the	O
linear	O
model	O
not	O
to	O
x	O
itself	O
but	O
to	O
a	O
transformed	O
input	O
where	O
is	O
a	O
chapter	O
deep	O
feedforward	O
networks	O
nonlinear	O
transformation	O
equivalently	O
we	O
can	O
apply	O
the	O
kernel	B
trick	B
described	O
in	O
section	O
to	O
obtain	O
a	O
nonlinear	O
learning	O
algorithm	O
based	O
on	O
implicitly	O
applying	O
the	O
mapping	O
we	O
can	O
think	O
of	O
as	O
providing	O
a	O
set	O
of	O
features	O
describing	O
x	O
or	O
as	O
providing	O
a	O
new	O
representation	O
for	O
the	O
question	O
is	O
then	O
how	O
to	O
choose	O
the	O
mapping	O
one	O
option	O
is	O
to	O
use	O
a	O
very	O
generic	O
such	O
as	O
the	O
infinite-dimensional	O
that	O
is	O
implicitly	O
used	O
by	O
kernel	O
machines	O
based	O
on	O
the	O
rbf	B
kernel	O
if	O
is	O
of	O
high	O
enough	O
dimension	O
we	O
can	O
always	O
have	O
enough	O
capacity	O
to	O
fit	O
the	O
training	O
set	O
but	O
generalization	B
to	O
the	O
test	B
set	I
often	O
remains	O
poor	O
very	O
generic	O
feature	B
mappings	O
are	O
usually	O
based	O
only	O
on	O
the	O
principle	O
of	O
local	O
smoothness	O
and	O
do	O
not	O
encode	O
enough	O
prior	O
information	O
to	O
solve	O
advanced	O
problems	O
another	O
option	O
is	O
to	O
manually	O
engineer	O
until	O
the	O
advent	O
of	O
deep	O
learning	O
this	O
was	O
the	O
dominant	O
approach	O
this	O
approach	O
requires	O
decades	O
of	O
human	O
effort	O
for	O
each	O
separate	O
task	O
with	O
practitioners	O
specializing	O
in	O
different	O
domains	O
such	O
as	O
speech	O
recognition	O
or	O
computer	B
vision	I
and	O
with	O
little	O
transfer	O
between	O
domains	O
the	O
strategy	O
of	O
deep	O
learning	O
is	O
to	O
learn	O
in	O
this	O
approach	O
we	O
have	O
a	O
model	O
y	O
fx	O
w	O
w	O
we	O
now	O
have	O
parameters	O
that	O
we	O
use	O
to	O
learn	O
from	O
a	O
broad	O
class	O
of	O
functions	O
and	O
parameters	O
w	O
that	O
map	O
from	O
to	O
the	O
desired	O
output	O
this	O
is	O
an	O
example	B
of	O
a	O
deep	O
feedforward	O
network	O
with	O
defining	O
a	O
hidden	B
layer	I
this	O
approach	O
is	O
the	O
only	O
one	O
of	O
the	O
three	O
that	O
gives	O
up	O
on	O
the	O
convexity	O
of	O
the	O
training	O
problem	O
but	O
the	O
benefits	O
outweigh	O
the	O
harms	O
in	O
this	O
approach	O
we	O
parametrize	O
the	O
representation	O
as	O
and	O
use	O
the	O
optimization	O
algorithm	O
to	O
find	O
the	O
that	O
corresponds	O
to	O
a	O
good	O
representation	O
if	O
we	O
wish	O
this	O
approach	O
can	O
capture	O
the	O
benefit	O
of	O
the	O
first	O
approach	O
by	O
being	O
highly	O
generic	O
we	O
do	O
so	O
by	O
using	O
a	O
very	O
broad	O
family	O
this	O
approach	O
can	O
also	O
capture	O
the	O
benefit	O
of	O
the	O
second	O
approach	O
human	O
practitioners	O
can	O
encode	O
their	O
knowledge	O
to	O
help	O
generalization	B
by	O
designing	O
families	O
that	O
they	O
expect	O
will	O
perform	O
well	O
the	O
advantage	O
is	O
that	O
the	O
human	O
designer	O
only	O
needs	O
to	O
find	O
the	O
right	O
general	O
function	O
family	O
rather	O
than	O
finding	O
precisely	O
the	O
right	O
function	O
this	O
general	O
principle	O
of	O
improving	O
models	O
by	O
learning	O
features	O
extends	O
beyond	O
the	O
feedforward	O
networks	O
described	O
in	O
this	O
chapter	O
it	O
is	O
a	O
recurring	O
theme	O
of	O
deep	O
learning	O
that	O
applies	O
to	O
all	O
of	O
the	O
kinds	O
of	O
models	O
described	O
throughout	O
this	O
book	O
feedforward	O
networks	O
are	O
the	O
application	O
of	O
this	O
principle	O
to	O
learning	O
deterministic	O
chapter	O
deep	O
feedforward	O
networks	O
mappings	O
from	O
x	O
to	O
y	O
that	O
lack	O
feedback	O
connections	O
other	O
models	O
presented	O
later	O
will	O
apply	O
these	O
principles	O
to	O
learning	O
stochastic	O
mappings	O
learning	O
functions	O
with	O
feedback	O
and	O
learning	O
probability	O
distributions	O
over	O
a	O
single	O
vector	O
we	O
begin	O
this	O
chapter	O
with	O
a	O
simple	O
example	B
of	O
a	O
feedforward	O
network	O
next	O
we	O
address	O
each	O
of	O
the	O
design	O
decisions	O
needed	O
to	O
deploy	O
a	O
feedforward	O
network	O
first	O
training	O
a	O
feedforward	O
network	O
requires	O
making	O
many	O
of	O
the	O
same	O
design	O
decisions	O
as	O
are	O
necessary	O
for	O
a	O
linear	O
model	O
choosing	O
the	O
optimizer	O
the	O
cost	O
function	O
and	O
the	O
form	O
of	O
the	O
output	O
units	O
we	O
review	O
these	O
basics	O
of	O
gradient-based	O
learning	O
then	O
proceed	O
to	O
confront	O
some	O
of	O
the	O
design	O
decisions	O
that	O
are	O
unique	O
to	O
feedforward	O
networks	O
feedforward	O
networks	O
have	O
introduced	O
the	O
concept	O
of	O
a	O
hidden	B
layer	I
and	O
this	O
requires	O
us	O
to	O
choose	O
the	O
activation	O
functions	O
that	O
will	O
be	O
used	O
to	O
compute	O
the	O
hidden	B
layer	I
values	O
we	O
must	O
also	O
design	O
the	O
architecture	O
of	O
the	O
network	O
including	O
how	O
many	O
layers	O
the	O
network	O
should	O
contain	O
how	O
these	O
layers	O
should	O
be	O
connected	O
to	O
each	O
other	O
and	O
how	O
many	O
units	O
should	O
be	O
in	O
each	O
layer	O
learning	O
in	O
deep	O
neural	O
networks	O
requires	O
computing	O
the	O
gradients	O
of	O
complicated	O
functions	O
we	O
present	O
the	O
back-propagation	B
algorithm	O
and	O
its	O
modern	O
generalizations	O
which	O
can	O
be	O
used	O
to	O
efficiently	O
compute	O
these	O
gradients	O
finally	O
we	O
close	O
with	O
some	O
historical	O
perspective	O
example	B
learning	O
xor	O
to	O
make	O
the	O
idea	O
of	O
a	O
feedforward	O
network	O
more	O
concrete	O
we	O
begin	O
with	O
an	O
example	B
of	O
a	O
fully	O
functioning	O
feedforward	O
network	O
on	O
a	O
very	O
simple	O
task	O
learning	O
the	O
xor	O
function	O
the	O
xor	O
function	O
exclusive	O
or	O
is	O
an	O
operation	B
on	O
two	O
binary	O
values	O
and	O
when	O
exactly	O
one	O
of	O
these	O
binary	O
values	O
is	O
equal	O
to	O
the	O
xor	O
function	O
otherwise	O
it	O
returns	O
the	O
xor	O
function	O
provides	O
the	O
target	O
function	O
returns	O
y	O
f	O
that	O
we	O
want	O
to	O
learn	O
our	O
model	O
provides	O
a	O
function	O
y	O
fx	O
and	O
our	O
learning	O
algorithm	O
will	O
adapt	O
the	O
parameters	O
to	O
make	O
f	O
as	O
similar	O
as	O
possible	O
to	O
f	O
in	O
this	O
simple	O
example	B
we	O
will	O
not	O
be	O
concerned	O
with	O
statistical	O
generalization	B
we	O
will	O
train	O
the	O
network	O
on	O
all	O
four	O
of	O
these	O
points	O
the	O
we	O
want	O
our	O
network	O
to	O
perform	O
correctly	O
on	O
the	O
four	O
points	O
x	O
only	O
challenge	B
is	O
to	O
fit	O
the	O
training	O
set	O
and	O
we	O
can	O
treat	O
this	O
problem	O
as	O
a	O
regression	B
problem	O
and	O
use	O
a	O
mean	B
squared	I
error	I
loss	O
function	O
we	O
choose	O
this	O
loss	O
function	O
to	O
simplify	O
the	O
math	O
for	O
this	O
example	B
as	O
much	O
as	O
possible	O
in	O
practical	O
applications	O
mse	O
is	O
usually	O
not	O
an	O
chapter	O
deep	O
feedforward	O
networks	O
appropriate	O
cost	O
function	O
for	O
modeling	O
binary	O
data	O
more	O
appropriate	O
approaches	O
are	O
described	O
in	O
section	O
evaluated	O
on	O
our	O
whole	O
training	O
set	O
the	O
mse	O
loss	O
function	O
is	O
x	O
f	O
x	O
j	O
x	O
x	O
now	O
we	O
must	O
choose	O
the	O
form	O
of	O
our	O
model	O
f	O
suppose	O
that	O
we	O
choose	O
a	O
linear	O
model	O
with	O
consisting	O
of	O
w	O
and	O
our	O
model	O
is	O
defined	O
to	O
be	O
b	O
w	O
b	O
f	O
w	O
x	O
b	O
we	O
can	O
minimize	O
j	O
in	O
closed	O
form	O
with	O
respect	O
to	O
w	O
and	O
b	O
using	O
the	O
normal	O
equations	O
after	O
solving	O
the	O
normal	O
equations	O
we	O
obtain	O
w	O
and	O
b	O
the	O
linear	O
model	O
simply	O
outputs	O
everywhere	O
why	O
does	O
this	O
happen	O
figure	O
shows	O
how	O
a	O
linear	O
model	O
is	O
not	O
able	O
to	O
represent	O
the	O
xor	O
function	O
one	O
way	O
to	O
solve	O
this	O
problem	O
is	O
to	O
use	O
a	O
model	O
that	O
learns	O
a	O
different	O
feature	B
space	O
in	O
which	O
a	O
linear	O
model	O
is	O
able	O
to	O
represent	O
the	O
solution	O
specifically	O
we	O
will	O
introduce	O
a	O
very	O
simple	O
feedforward	O
network	O
with	O
one	O
hidden	B
layer	I
containing	O
two	O
hidden	O
units	O
see	O
figure	O
for	O
an	O
illustration	O
of	O
this	O
model	O
this	O
feedforward	O
network	O
has	O
a	O
vector	O
of	O
hidden	O
units	O
h	O
that	O
are	O
computed	O
by	O
a	O
function	O
f	O
w	O
c	O
the	O
values	O
of	O
these	O
hidden	O
units	O
are	O
then	O
used	O
as	O
the	O
input	O
for	O
a	O
second	O
layer	O
the	O
second	O
layer	O
is	O
the	O
output	O
layer	O
of	O
the	O
network	O
the	O
output	O
layer	O
is	O
still	O
just	O
a	O
linear	O
regression	B
model	O
but	O
now	O
it	O
is	O
applied	O
to	O
h	O
rather	O
than	O
to	O
x	O
the	O
network	O
now	O
contains	O
two	O
functions	O
chained	O
together	O
h	O
f	O
w	O
c	O
and	O
y	O
f	O
w	O
b	O
with	O
the	O
complete	O
model	O
being	O
f	O
w	O
c	O
w	O
b	O
f	O
what	O
function	O
should	O
f	O
compute	O
linear	O
models	O
have	O
served	O
us	O
well	O
so	O
far	O
and	O
it	O
may	O
be	O
tempting	O
to	O
make	O
f	O
be	O
linear	O
as	O
well	O
unfortunately	O
if	O
were	O
linear	O
then	O
the	O
feedforward	O
network	O
as	O
a	O
whole	O
would	O
remain	O
a	O
linear	O
function	O
of	O
its	O
input	O
ignoring	O
the	O
intercept	O
terms	O
for	O
the	O
moment	O
suppose	O
f	O
w	O
x	O
and	O
f	O
h	O
x	O
we	O
could	O
represent	O
this	O
function	O
as	O
f	O
w	O
then	O
f	O
w	O
where	O
w	O
w	O
w	O
w	O
x	O
w	O
x	O
clearly	O
we	O
must	O
use	O
a	O
nonlinear	O
function	O
to	O
describe	O
the	O
features	O
most	O
neural	O
networks	O
do	O
so	O
using	O
an	O
affine	B
transformation	O
controlled	O
by	O
learned	O
parameters	O
followed	O
by	O
a	O
fixed	O
nonlinear	O
function	O
called	O
an	O
activation	B
function	I
we	O
use	O
that	O
strategy	O
here	O
by	O
defining	O
h	O
gw	O
x	O
c	O
where	O
w	O
provides	O
the	O
weights	B
of	O
a	O
linear	O
transformation	O
and	O
c	O
the	O
biases	O
previously	O
to	O
describe	O
a	O
linear	O
regression	B
chapter	O
deep	O
feedforward	O
networks	O
original	O
x	O
space	O
learned	O
h	O
space	O
x	O
h	O
h	O
figure	O
solving	O
the	O
xor	O
problem	O
by	O
learning	O
a	O
representation	O
the	O
bold	O
numbers	O
printed	O
on	O
the	O
plot	O
indicate	O
the	O
value	O
that	O
the	O
learned	O
function	O
must	O
output	O
at	O
each	O
point	O
linear	O
model	O
applied	O
directly	O
to	O
the	O
original	O
input	O
cannot	O
implement	O
the	O
xor	O
function	O
when	O
the	O
model	O
s	O
output	O
must	O
increase	O
as	O
increases	O
when	O
the	O
model	O
s	O
output	O
must	O
decrease	O
as	O
increases	O
a	O
linear	O
model	O
must	O
apply	O
a	O
fixed	O
coefficient	O
to	O
the	O
linear	O
model	O
therefore	O
cannot	O
use	O
the	O
value	O
of	O
to	O
change	O
the	O
coefficient	O
on	O
and	O
cannot	O
solve	O
this	O
problem	O
the	O
transformed	O
space	O
represented	O
by	O
the	O
features	O
extracted	O
by	O
a	O
neural	B
network	I
a	O
linear	O
model	O
can	O
now	O
solve	O
have	O
been	O
the	O
problem	O
in	O
our	O
example	B
solution	O
the	O
two	O
points	O
that	O
must	O
have	O
output	O
collapsed	O
into	O
a	O
single	O
point	O
in	O
feature	B
space	O
in	O
other	O
words	O
the	O
nonlinear	O
features	O
have	O
mapped	O
both	O
x	O
the	O
linear	O
model	O
can	O
now	O
describe	O
the	O
function	O
as	O
increasing	O
in	O
and	O
decreasing	O
in	O
in	O
this	O
example	B
the	O
motivation	O
for	O
learning	O
the	O
feature	B
space	O
is	O
only	O
to	O
make	O
the	O
model	O
capacity	O
greater	O
so	O
that	O
it	O
can	O
fit	O
the	O
training	O
set	O
in	O
more	O
realistic	O
applications	O
learned	O
representations	O
can	O
also	O
help	O
the	O
model	O
to	O
generalize	O
to	O
a	O
single	O
point	O
in	O
feature	B
space	O
h	O
and	O
x	O
chapter	O
deep	O
feedforward	O
networks	O
yy	O
yy	O
hh	O
xx	O
w	O
w	O
figure	O
an	O
example	B
of	O
a	O
feedforward	O
network	O
drawn	O
in	O
two	O
different	O
styles	O
specifically	O
this	O
is	O
the	O
feedforward	O
network	O
we	O
use	O
to	O
solve	O
the	O
xor	O
example	B
it	O
has	O
a	O
single	O
hidden	B
layer	I
containing	O
two	O
units	O
this	O
style	O
we	O
draw	O
every	O
unit	O
as	O
a	O
node	O
in	O
the	O
graph	O
this	O
style	O
is	O
very	O
explicit	O
and	O
unambiguous	O
but	O
for	O
networks	O
larger	O
than	O
this	O
example	B
it	O
can	O
consume	O
too	O
much	O
space	O
in	O
this	O
style	O
we	O
draw	O
a	O
node	O
in	O
the	O
graph	O
for	O
each	O
entire	O
vector	O
representing	O
a	O
layer	O
s	O
activations	O
this	O
style	O
is	O
much	O
more	O
compact	O
sometimes	O
we	O
annotate	O
the	O
edges	O
in	O
this	O
graph	O
with	O
the	O
name	O
of	O
the	O
parameters	O
that	O
describe	O
the	O
relationship	O
between	O
two	O
layers	O
here	O
we	O
indicate	O
that	O
a	O
matrix	O
w	O
describes	O
the	O
mapping	O
from	O
x	O
to	O
h	O
and	O
a	O
vector	O
w	O
describes	O
the	O
mapping	O
from	O
h	O
to	O
y	O
we	O
typically	O
omit	O
the	O
intercept	O
parameters	O
associated	O
with	O
each	O
layer	O
when	O
labeling	O
this	O
kind	O
of	O
drawing	O
model	O
we	O
used	O
a	O
vector	O
of	O
weights	B
and	O
a	O
scalar	O
bias	B
parameter	I
to	O
describe	O
an	O
affine	B
transformation	O
from	O
an	O
input	O
vector	O
to	O
an	O
output	O
scalar	O
now	O
we	O
describe	O
an	O
affine	B
transformation	O
from	O
a	O
vector	O
x	O
to	O
a	O
vector	O
h	O
so	O
an	O
entire	O
vector	O
of	O
bias	O
parameters	O
is	O
needed	O
the	O
activation	B
function	I
g	O
is	O
typically	O
chosen	O
to	O
be	O
a	O
function	O
that	O
is	O
applied	O
element-wise	O
with	O
hi	O
gx	O
wi	O
ci	O
in	O
modern	O
neural	O
networks	O
the	O
default	O
recommendation	O
is	O
to	O
use	O
the	O
rectified	O
linear	O
unit	O
or	O
relu	O
et	O
al	O
defined	O
by	O
the	O
activation	B
function	I
nair	O
and	O
hinton	O
glorot	O
max	O
g	O
z	O
depicted	O
in	O
figure	O
et	O
al	O
z	O
we	O
can	O
now	O
specify	O
our	O
complete	O
network	O
as	O
w	O
c	O
w	O
w	O
b	O
f	O
max	O
w	O
x	O
c	O
b	O
we	O
can	O
now	O
specify	O
a	O
solution	O
to	O
the	O
xor	O
problem	O
let	O
w	O
c	O
chapter	O
deep	O
feedforward	O
networks	O
z	O
x	O
a	O
m	O
z	O
g	O
z	O
figure	O
the	O
rectified	O
linear	O
activation	B
function	I
this	O
activation	B
function	I
is	O
the	O
default	O
activation	B
function	I
recommended	O
for	O
use	O
with	O
most	O
feedforward	O
neural	O
networks	O
applying	O
this	O
function	O
to	O
the	O
output	O
of	O
a	O
linear	O
transformation	O
yields	O
a	O
nonlinear	O
transformation	O
however	O
the	O
function	O
remains	O
very	O
close	O
to	O
linear	O
in	O
the	O
sense	O
that	O
is	O
a	O
piecewise	O
linear	O
function	O
with	O
two	O
linear	O
pieces	O
because	O
rectified	O
linear	O
units	O
are	O
nearly	O
linear	O
they	O
preserve	O
many	O
of	O
the	O
properties	O
that	O
make	O
linear	O
models	O
easy	O
to	O
optimize	O
with	O
gradientbased	O
methods	O
they	O
also	O
preserve	O
many	O
of	O
the	O
properties	O
that	O
make	O
linear	O
models	O
generalize	O
well	O
a	O
common	O
principle	O
throughout	O
computer	O
science	O
is	O
that	O
we	O
can	O
build	O
complicated	O
systems	O
from	O
minimal	O
components	O
much	O
as	O
a	O
turing	O
machine	O
s	O
memory	O
needs	O
only	O
to	O
be	O
able	O
to	O
store	O
or	O
states	O
we	O
can	O
build	O
a	O
universal	O
function	O
approximator	O
from	O
rectified	O
linear	O
functions	O
chapter	O
deep	O
feedforward	O
networks	O
w	O
and	O
b	O
we	O
can	O
now	O
walk	O
through	O
the	O
way	O
that	O
the	O
model	O
processes	O
a	O
batch	O
of	O
inputs	O
let	O
x	O
be	O
the	O
design	B
matrix	I
containing	O
all	O
four	O
points	O
in	O
the	O
binary	O
input	O
space	O
with	O
one	O
example	B
per	O
row	O
x	O
the	O
first	O
step	O
in	O
the	O
neural	B
network	I
is	O
to	O
multiply	O
the	O
input	O
matrix	O
by	O
the	O
first	O
layer	O
s	O
weight	O
matrix	O
xw	O
to	O
obtain	O
next	O
we	O
add	O
the	O
bias	O
vector	O
c	O
in	O
this	O
space	O
all	O
of	O
the	O
examples	O
lie	O
along	O
a	O
line	O
with	O
slope	O
as	O
we	O
move	O
along	O
this	O
line	O
the	O
output	O
needs	O
to	O
begin	O
at	O
then	O
rise	O
to	O
then	O
drop	O
back	O
down	O
to	O
a	O
linear	O
model	O
cannot	O
implement	O
such	O
a	O
function	O
to	O
finish	O
computing	O
the	O
value	O
of	O
for	O
each	O
example	B
we	O
apply	O
the	O
rectified	O
linear	O
transformation	O
h	O
this	O
transformation	O
has	O
changed	O
the	O
relationship	O
between	O
the	O
examples	O
they	O
no	O
longer	O
lie	O
on	O
a	O
single	O
line	O
as	O
shown	O
in	O
figure	O
they	O
now	O
lie	O
in	O
a	O
space	O
where	O
a	O
linear	O
model	O
can	O
solve	O
the	O
problem	O
we	O
finish	O
by	O
multiplying	O
by	O
the	O
weight	O
vector	O
chapter	O
deep	O
feedforward	O
networks	O
the	O
neural	B
network	I
has	O
obtained	O
the	O
correct	O
answer	O
for	O
every	O
example	B
in	O
the	O
batch	O
in	O
this	O
example	B
we	O
simply	O
specified	O
the	O
solution	O
then	O
showed	O
that	O
it	O
obtained	O
zero	O
error	O
in	O
a	O
real	O
situation	O
there	O
might	O
be	O
billions	O
of	O
model	O
parameters	O
and	O
billions	O
of	O
training	O
examples	O
so	O
one	O
cannot	O
simply	O
guess	O
the	O
solution	O
as	O
we	O
did	O
here	O
instead	O
a	O
gradient-based	O
optimization	O
algorithm	O
can	O
find	O
parameters	O
that	O
produce	O
very	O
little	O
error	O
the	O
solution	O
we	O
described	O
to	O
the	O
xor	O
problem	O
is	O
at	O
a	O
global	O
minimum	O
of	O
the	O
loss	O
function	O
so	O
gradient	B
descent	O
could	O
converge	O
to	O
this	O
point	O
there	O
are	O
other	O
equivalent	O
solutions	O
to	O
the	O
xor	O
problem	O
that	O
gradient	B
descent	O
could	O
also	O
find	O
the	O
convergence	O
point	O
of	O
gradient	B
descent	O
depends	O
on	O
the	O
initial	O
values	O
of	O
the	O
parameters	O
in	O
practice	O
gradient	B
descent	O
would	O
usually	O
not	O
find	O
clean	O
easily	O
understood	O
integer-valued	O
solutions	O
like	O
the	O
one	O
we	O
presented	O
here	O
gradient-based	O
learning	O
designing	O
and	O
training	O
a	O
neural	B
network	I
is	O
not	O
much	O
different	O
from	O
training	O
any	O
other	O
machine	B
learning	I
model	O
with	O
gradient	B
descent	O
in	O
section	O
we	O
described	O
how	O
to	O
build	O
a	O
machine	B
learning	I
algorithm	O
by	O
specifying	O
an	O
optimization	O
procedure	O
a	O
cost	O
function	O
and	O
a	O
model	O
family	O
the	O
largest	O
difference	O
between	O
the	O
linear	O
models	O
we	O
have	O
seen	O
so	O
far	O
and	O
neural	O
networks	O
is	O
that	O
the	O
nonlinearity	O
of	O
a	O
neural	B
network	I
causes	O
most	O
interesting	O
loss	O
functions	O
to	O
become	O
non-convex	O
this	O
means	O
that	O
neural	O
networks	O
are	O
usually	O
trained	O
by	O
using	O
iterative	O
gradient-based	O
optimizers	O
that	O
merely	O
drive	O
the	O
cost	O
function	O
to	O
a	O
very	O
low	O
value	O
rather	O
than	O
the	O
linear	O
equation	O
solvers	O
used	O
to	O
train	O
linear	O
regression	B
models	O
or	O
the	O
convex	B
optimization	I
algorithms	O
with	O
global	O
convergence	O
guarantees	O
used	O
to	O
train	O
logistic	O
regression	B
or	O
svms	O
convex	B
optimization	I
converges	O
starting	O
from	O
any	O
initial	O
parameters	O
theory	O
in	O
practice	O
it	O
is	O
very	O
robust	O
but	O
can	O
encounter	O
numerical	O
problems	O
stochastic	O
gradient	B
descent	O
applied	O
to	O
non-convex	O
loss	O
functions	O
has	O
no	O
such	O
convergence	O
guarantee	O
and	O
is	O
sensitive	O
to	O
the	O
values	O
of	O
the	O
initial	O
parameters	O
for	O
feedforward	O
neural	O
networks	O
it	O
is	O
important	O
to	O
initialize	O
all	O
weights	B
to	O
small	O
random	O
values	O
the	O
biases	O
may	O
be	O
initialized	O
to	O
zero	O
or	O
to	O
small	O
positive	O
values	O
the	O
iterative	O
gradient-based	O
optimization	O
algorithms	O
used	O
to	O
train	O
feedforward	O
networks	O
and	O
almost	O
all	O
other	O
deep	O
models	O
will	O
be	O
described	O
in	O
detail	O
in	O
chapter	O
with	O
parameter	O
initialization	B
in	O
particular	O
discussed	O
in	O
section	O
for	O
the	O
moment	O
it	O
suffices	O
to	O
understand	O
that	O
the	O
training	O
algorithm	O
is	O
almost	O
always	O
based	O
on	O
using	O
the	O
gradient	B
to	O
descend	O
the	O
cost	O
function	O
in	O
one	O
way	O
or	O
another	O
the	O
specific	O
algorithms	O
are	O
improvements	O
and	O
and	O
refinements	O
on	O
the	O
ideas	O
of	O
gradient	B
descent	O
introduced	O
in	O
section	O
chapter	O
deep	O
feedforward	O
networks	O
more	O
specifically	O
are	O
most	O
often	O
improvements	O
of	O
the	O
stochastic	O
gradient	B
descent	O
algorithm	O
introduced	O
in	O
section	O
we	O
can	O
of	O
course	O
train	O
models	O
such	O
as	O
linear	O
regression	B
and	O
support	O
vector	O
machines	O
with	O
gradient	B
descent	O
too	O
and	O
in	O
fact	O
this	O
is	O
common	O
when	O
the	O
training	O
set	O
is	O
extremely	O
large	O
from	O
this	O
point	O
of	O
view	O
training	O
a	O
neural	B
network	I
is	O
not	O
much	O
different	O
from	O
training	O
any	O
other	O
model	O
computing	O
the	O
gradient	B
is	O
slightly	O
more	O
complicated	O
for	O
a	O
neural	B
network	I
but	O
can	O
still	O
be	O
done	O
efficiently	O
and	O
exactly	O
section	O
will	O
describe	O
how	O
to	O
obtain	O
the	O
gradient	B
using	O
the	O
back-propagation	B
algorithm	O
and	O
modern	O
generalizations	O
of	O
the	O
back-propagation	B
algorithm	O
as	O
with	O
other	O
machine	B
learning	I
models	O
to	O
apply	O
gradient-based	O
learning	O
we	O
must	O
choose	O
a	O
cost	O
function	O
and	O
we	O
must	O
choose	O
how	O
to	O
represent	O
the	O
output	O
of	O
the	O
model	O
we	O
now	O
revisit	O
these	O
design	O
considerations	O
with	O
special	O
emphasis	O
on	O
the	O
neural	O
networks	O
scenario	O
cost	O
functions	O
an	O
important	O
aspect	O
of	O
the	O
design	O
of	O
a	O
deep	O
neural	B
network	I
is	O
the	O
choice	O
of	O
the	O
cost	O
function	O
fortunately	O
the	O
cost	O
functions	O
for	O
neural	O
networks	O
are	O
more	O
or	O
less	O
the	O
same	O
as	O
those	O
for	O
other	O
parametric	O
models	O
such	O
as	O
linear	O
models	O
in	O
most	O
cases	O
our	O
parametric	B
model	I
defines	O
a	O
distribution	O
py	O
x	O
and	O
we	O
simply	O
use	O
the	O
principle	O
of	O
maximum	B
likelihood	I
this	O
means	O
we	O
use	O
the	O
cross-entropy	B
between	O
the	O
training	O
data	O
and	O
the	O
model	O
s	O
predictions	O
as	O
the	O
cost	O
function	O
sometimes	O
we	O
take	O
a	O
simpler	O
approach	O
where	O
rather	O
than	O
predicting	O
a	O
complete	O
probability	B
distribution	I
over	O
y	O
we	O
merely	O
predict	O
some	O
statistic	B
of	O
y	O
conditioned	O
on	O
specialized	O
loss	O
functions	O
allow	O
us	O
to	O
train	O
a	O
predictor	O
of	O
these	O
estimates	O
x	O
the	O
total	O
cost	O
function	O
used	O
to	O
train	O
a	O
neural	B
network	I
will	O
often	O
combine	O
one	O
of	O
the	O
primary	O
cost	O
functions	O
described	O
here	O
with	O
a	O
regularization	O
term	O
we	O
have	O
already	O
seen	O
some	O
simple	O
examples	O
of	O
regularization	O
applied	O
to	O
linear	O
models	O
in	O
section	O
the	O
weight	O
decay	O
approach	O
used	O
for	O
linear	O
models	O
is	O
also	O
directly	O
applicable	O
to	O
deep	O
neural	O
networks	O
and	O
is	O
among	O
the	O
most	O
popular	O
regularization	O
strategies	O
more	O
advanced	O
regularization	O
strategies	O
for	O
neural	O
networks	O
will	O
be	O
described	O
in	O
chapter	O
learning	O
conditional	O
distributions	O
with	O
maximum	B
likelihood	I
most	O
modern	O
neural	O
networks	O
are	O
trained	O
using	O
maximum	B
likelihood	I
this	O
means	O
that	O
the	O
cost	O
function	O
is	O
simply	O
the	O
negative	O
log-likelihood	O
equivalently	O
described	O
chapter	O
deep	O
feedforward	O
networks	O
as	O
the	O
cross-entropy	B
between	O
the	O
training	O
data	O
and	O
the	O
model	O
distribution	O
this	O
cost	O
function	O
is	O
given	O
by	O
log	O
pmodel	O
y	O
x	O
j	O
ex	O
y	O
pdata	O
the	O
specific	O
form	O
of	O
the	O
cost	O
function	O
changes	O
from	O
model	O
to	O
model	O
depending	O
on	O
the	O
specific	O
form	O
of	O
log	O
pmodel	O
the	O
expansion	O
of	O
the	O
above	O
equation	O
typically	O
yields	O
some	O
terms	O
that	O
do	O
not	O
depend	O
on	O
the	O
model	O
parameters	O
and	O
may	O
be	O
disy	O
fx	O
i	O
carded	O
for	O
example	B
as	O
we	O
saw	O
in	O
section	O
then	O
we	O
recover	O
the	O
mean	B
squared	I
error	I
cost	O
y	O
f	O
const	O
pmodely	O
x	O
j	O
n	O
if	O
x	O
y	O
pdata	O
up	O
to	O
a	O
scaling	O
factor	O
of	O
and	O
a	O
term	O
that	O
does	O
not	O
depend	O
on	O
the	O
discarded	O
constant	O
is	O
based	O
on	O
the	O
variance	O
of	O
the	O
gaussian	O
distribution	O
which	O
in	O
this	O
case	O
we	O
chose	O
not	O
to	O
parametrize	O
previously	O
we	O
saw	O
that	O
the	O
equivalence	O
between	O
maximum	B
likelihood	I
estimation	O
with	O
an	O
output	O
distribution	O
and	O
minimization	O
of	O
mean	B
squared	I
error	I
holds	O
for	O
a	O
linear	O
model	O
but	O
in	O
fact	O
the	O
equivalence	O
holds	O
regardless	O
of	O
the	O
used	O
to	O
predict	O
the	O
mean	O
of	O
the	O
gaussian	O
f	O
an	O
advantage	O
of	O
this	O
approach	O
of	O
deriving	O
the	O
cost	O
function	O
from	O
maximum	B
likelihood	I
is	O
that	O
it	O
removes	O
the	O
burden	O
of	O
designing	O
cost	O
functions	O
for	O
each	O
model	O
specifying	O
a	O
model	O
py	O
x	O
automatically	O
determines	O
a	O
cost	O
function	O
log	O
py	O
x	O
one	O
recurring	O
theme	O
throughout	O
neural	B
network	I
design	O
is	O
that	O
the	O
gradient	B
of	O
the	O
cost	O
function	O
must	O
be	O
large	O
and	O
predictable	O
enough	O
to	O
serve	O
as	O
a	O
good	O
guide	O
for	O
the	O
learning	O
algorithm	O
functions	O
that	O
saturate	O
very	O
flat	O
undermine	O
this	O
objective	O
because	O
they	O
make	O
the	O
gradient	B
become	O
very	O
small	O
in	O
many	O
cases	O
this	O
happens	O
because	O
the	O
activation	O
functions	O
used	O
to	O
produce	O
the	O
output	O
of	O
the	O
hidden	O
units	O
or	O
the	O
output	O
units	O
saturate	O
the	O
negative	O
log-likelihood	O
helps	O
to	O
avoid	O
this	O
problem	O
for	O
many	O
models	O
many	O
output	O
units	O
involve	O
an	O
exp	O
function	O
that	O
can	O
saturate	O
when	O
its	O
argument	O
is	O
very	O
negative	O
the	O
log	O
function	O
in	O
the	O
negative	O
log-likelihood	O
cost	O
function	O
undoes	O
the	O
exp	O
of	O
some	O
output	O
units	O
we	O
will	O
discuss	O
the	O
interaction	O
between	O
the	O
cost	O
function	O
and	O
the	O
choice	O
of	O
output	O
unit	O
in	O
section	O
one	O
unusual	O
property	O
of	O
the	O
cross-entropy	B
cost	O
used	O
to	O
perform	O
maximum	B
likelihood	I
estimation	O
is	O
that	O
it	O
usually	O
does	O
not	O
have	O
a	O
minimum	O
value	O
when	O
applied	O
to	O
the	O
models	O
commonly	O
used	O
in	O
practice	O
for	O
discrete	O
output	O
variables	O
most	O
models	O
are	O
parametrized	O
in	O
such	O
a	O
way	O
that	O
they	O
cannot	O
represent	O
a	O
probability	O
of	O
zero	O
or	O
one	O
but	O
can	O
come	O
arbitrarily	O
close	O
to	O
doing	O
so	O
logistic	O
regression	B
is	O
an	O
example	B
of	O
such	O
a	O
model	O
for	O
real-valued	O
output	O
variables	O
if	O
the	O
model	O
chapter	O
deep	O
feedforward	O
networks	O
can	O
control	O
the	O
density	O
of	O
the	O
output	O
distribution	O
example	B
by	O
learning	O
the	O
variance	O
parameter	O
of	O
a	O
gaussian	O
output	O
distribution	O
then	O
it	O
becomes	O
possible	O
to	O
assign	O
extremely	O
high	O
density	O
to	O
the	O
correct	O
training	O
set	O
outputs	O
resulting	O
in	O
cross-entropy	B
approaching	O
negative	O
infinity	O
regularization	O
techniques	O
described	O
in	O
chapter	O
provide	O
several	O
different	O
ways	O
of	O
modifying	O
the	O
learning	O
problem	O
so	O
that	O
the	O
model	O
cannot	O
reap	O
unlimited	O
reward	O
in	O
this	O
way	O
learning	O
conditional	O
statistics	O
instead	O
of	O
learning	O
a	O
full	O
probability	B
distribution	I
py	O
x	O
just	O
one	O
conditional	O
statistic	B
of	O
given	O
x	O
y	O
we	O
often	O
want	O
to	O
learn	O
for	O
example	B
we	O
may	O
have	O
a	O
predictor	O
fx	O
that	O
we	O
wish	O
to	O
predict	O
the	O
mean	O
of	O
if	O
we	O
use	O
a	O
sufficiently	O
powerful	O
neural	B
network	I
we	O
can	O
think	O
of	O
the	O
neural	B
network	I
as	O
being	O
able	O
to	O
represent	O
any	O
function	O
f	O
from	O
a	O
wide	O
class	O
of	O
functions	O
with	O
this	O
class	O
being	O
limited	O
only	O
by	O
features	O
such	O
as	O
continuity	O
and	O
boundedness	O
rather	O
than	O
by	O
having	O
a	O
specific	O
parametric	O
form	O
from	O
this	O
point	O
of	O
view	O
we	O
can	O
view	O
the	O
cost	O
function	O
as	O
being	O
a	O
functional	O
rather	O
than	O
just	O
a	O
function	O
a	O
functional	O
is	O
a	O
mapping	O
from	O
functions	O
to	O
real	O
numbers	O
we	O
can	O
thus	O
think	O
of	O
learning	O
as	O
choosing	O
a	O
function	O
rather	O
than	O
merely	O
choosing	O
a	O
set	O
of	O
parameters	O
we	O
can	O
design	O
our	O
cost	O
functional	O
to	O
have	O
its	O
minimum	O
occur	O
at	O
some	O
specific	O
function	O
we	O
desire	O
for	O
example	B
we	O
can	O
design	O
the	O
cost	O
functional	O
to	O
have	O
its	O
minimum	O
lie	O
on	O
the	O
function	O
that	O
maps	O
x	O
to	O
the	O
expected	O
value	O
of	O
y	O
given	O
x	O
solving	O
an	O
optimization	O
problem	O
with	O
respect	O
to	O
a	O
function	O
requires	O
a	O
mathematical	O
tool	O
called	O
calculus	B
of	I
variations	I
described	O
in	O
section	O
it	O
is	O
not	O
necessary	O
to	O
understand	O
calculus	B
of	I
variations	I
to	O
understand	O
the	O
content	O
of	O
this	O
chapter	O
at	O
the	O
moment	O
it	O
is	O
only	O
necessary	O
to	O
understand	O
that	O
calculus	B
of	I
variations	I
may	O
be	O
used	O
to	O
derive	O
the	O
following	O
two	O
results	O
our	O
first	O
result	O
derived	O
using	O
calculus	B
of	I
variations	I
is	O
that	O
solving	O
the	O
optimiza	O
tion	B
problem	O
yields	O
f	O
arg	O
min	O
f	O
pdata	O
ex	O
y	O
y	O
f	O
f	O
x	O
ey	O
pdata	O
x	O
so	O
long	O
as	O
this	O
function	O
lies	O
within	O
the	O
class	O
we	O
optimize	O
over	O
in	O
other	O
words	O
if	O
we	O
could	O
train	O
on	O
infinitely	O
many	O
samples	O
from	O
the	O
true	O
data	O
generating	O
distribution	O
minimizing	O
the	O
mean	B
squared	I
error	I
cost	O
function	O
gives	O
a	O
function	O
that	O
predicts	O
the	O
mean	O
of	O
for	O
each	O
value	O
of	O
x	O
y	O
chapter	O
deep	O
feedforward	O
networks	O
different	O
cost	O
functions	O
give	O
different	O
statistics	O
a	O
second	O
result	O
derived	O
using	O
calculus	B
of	I
variations	I
is	O
that	O
f	O
arg	O
min	O
f	O
pdata	O
ex	O
y	O
y	O
f	O
yields	O
a	O
function	O
that	O
predicts	O
the	O
median	O
value	O
of	O
y	O
for	O
each	O
x	O
so	O
long	O
as	O
such	O
a	O
function	O
may	O
be	O
described	O
by	O
the	O
family	O
of	O
functions	O
we	O
optimize	O
over	O
this	O
cost	O
function	O
is	O
commonly	O
called	O
mean	O
absolute	O
error	O
unfortunately	O
mean	B
squared	I
error	I
and	O
mean	O
absolute	O
error	O
often	O
lead	O
to	O
poor	O
results	O
when	O
used	O
with	O
gradient-based	O
optimization	O
some	O
output	O
units	O
that	O
saturate	O
produce	O
very	O
small	O
gradients	O
when	O
combined	O
with	O
these	O
cost	O
functions	O
this	O
is	O
one	O
reason	O
that	O
the	O
cross-entropy	B
cost	O
function	O
is	O
more	O
popular	O
than	O
mean	B
squared	I
error	I
or	O
mean	O
absolute	O
error	O
even	O
when	O
it	O
is	O
not	O
necessary	O
to	O
estimate	O
an	O
entire	O
distribution	O
y	O
x	O
p	O
output	O
units	O
the	O
choice	O
of	O
cost	O
function	O
is	O
tightly	O
coupled	O
with	O
the	O
choice	O
of	O
output	O
unit	O
most	O
of	O
the	O
time	O
we	O
simply	O
use	O
the	O
cross-entropy	B
between	O
the	O
data	O
distribution	O
and	O
the	O
model	O
distribution	O
the	O
choice	O
of	O
how	O
to	O
represent	O
the	O
output	O
then	O
determines	O
the	O
form	O
of	O
the	O
cross-entropy	B
function	O
any	O
kind	O
of	O
neural	B
network	I
unit	O
that	O
may	O
be	O
used	O
as	O
an	O
output	O
can	O
also	O
be	O
used	O
as	O
a	O
hidden	O
unit	O
here	O
we	O
focus	O
on	O
the	O
use	O
of	O
these	O
units	O
as	O
outputs	O
of	O
the	O
model	O
but	O
in	O
principle	O
they	O
can	O
be	O
used	O
internally	O
as	O
well	O
we	O
revisit	O
these	O
units	O
with	O
additional	O
detail	O
about	O
their	O
use	O
as	O
hidden	O
units	O
in	O
section	O
throughout	O
this	O
section	O
we	O
suppose	O
that	O
the	O
feedforward	O
network	O
provides	O
a	O
set	O
of	O
hidden	O
features	O
defined	O
by	O
h	O
f	O
the	O
role	O
of	O
the	O
output	O
layer	O
is	O
then	O
to	O
provide	O
some	O
additional	O
transformation	O
from	O
the	O
features	O
to	O
complete	O
the	O
task	O
that	O
the	O
network	O
must	O
perform	O
linear	O
units	O
for	O
gaussian	O
output	O
distributions	O
one	O
simple	O
kind	O
of	O
output	O
unit	O
is	O
an	O
output	O
unit	O
based	O
on	O
an	O
affine	B
transformation	O
with	O
no	O
nonlinearity	O
these	O
are	O
often	O
just	O
called	O
linear	O
units	O
given	O
features	O
h	O
a	O
layer	O
of	O
linear	O
output	O
units	O
produces	O
a	O
vector	O
y	O
w	O
hb	O
linear	O
output	O
layers	O
are	O
often	O
used	O
to	O
produce	O
the	O
mean	O
of	O
a	O
conditional	O
gaussian	O
distribution	O
n	O
p	O
y	O
x	O
y	O
y	O
i	O
chapter	O
deep	O
feedforward	O
networks	O
maximizing	O
the	O
log-likelihood	O
is	O
then	O
equivalent	O
to	O
minimizing	O
the	O
mean	B
squared	I
error	I
the	O
maximum	B
likelihood	I
framework	O
makes	O
it	O
straightforward	O
to	O
learn	O
the	O
covariance	O
of	O
the	O
gaussian	O
too	O
or	O
to	O
make	O
the	O
covariance	O
of	O
the	O
gaussian	O
be	O
a	O
function	O
of	O
the	O
input	O
however	O
the	O
covariance	O
must	O
be	O
constrained	O
to	O
be	O
a	O
positive	B
definite	I
matrix	O
for	O
all	O
inputs	O
it	O
is	O
difficult	O
to	O
satisfy	O
such	O
constraints	O
with	O
a	O
linear	O
output	O
layer	O
so	O
typically	O
other	O
output	O
units	O
are	O
used	O
to	O
parametrize	O
the	O
covariance	O
approaches	O
to	O
modeling	O
the	O
covariance	O
are	O
described	O
shortly	O
in	O
section	O
because	O
linear	O
units	O
do	O
not	O
saturate	O
they	O
pose	O
little	O
difficulty	O
for	O
gradientbased	O
optimization	O
algorithms	O
and	O
may	O
be	O
used	O
with	O
a	O
wide	O
variety	O
of	O
optimization	O
algorithms	O
sigmoid	O
units	O
for	O
bernoulli	O
output	O
distributions	O
many	O
tasks	O
require	O
predicting	O
the	O
value	O
of	O
a	O
binary	O
variable	O
y	O
classification	B
problems	O
with	O
two	O
classes	O
can	O
be	O
cast	O
in	O
this	O
form	O
the	O
maximum-likelihood	O
approach	O
is	O
to	O
define	O
a	O
bernoulli	B
distribution	I
over	O
y	O
conditioned	O
on	O
a	O
bernoulli	B
distribution	I
is	O
defined	O
by	O
just	O
a	O
single	O
number	O
the	O
neural	O
net	O
x	O
for	O
this	O
number	O
to	O
be	O
a	O
valid	O
probability	O
it	O
needs	O
to	O
predict	O
only	O
py	O
must	O
lie	O
in	O
the	O
interval	O
satisfying	O
this	O
constraint	O
requires	O
some	O
careful	O
design	O
effort	O
suppose	O
we	O
were	O
to	O
use	O
a	O
linear	O
unit	O
and	O
threshold	O
its	O
value	O
to	O
obtain	O
a	O
valid	O
probability	O
p	O
y	O
x	O
max	O
min	O
w	O
h	O
b	O
this	O
would	O
indeed	O
define	O
a	O
valid	O
conditional	O
distribution	O
but	O
we	O
would	O
not	O
be	O
able	O
to	O
train	O
it	O
very	O
effectively	O
with	O
gradient	B
descent	O
any	O
time	O
that	O
w	O
h	O
b	O
strayed	O
outside	O
the	O
unit	O
interval	O
the	O
gradient	B
of	O
the	O
output	O
of	O
the	O
model	O
with	O
respect	O
to	O
its	O
parameters	O
would	O
be	O
a	O
gradient	B
of	O
is	O
typically	O
problematic	O
because	O
the	O
learning	O
algorithm	O
no	O
longer	O
has	O
a	O
guide	O
for	O
how	O
to	O
improve	O
the	O
corresponding	O
parameters	O
instead	O
it	O
is	O
better	O
to	O
use	O
a	O
different	O
approach	O
that	O
ensures	O
there	O
is	O
always	O
a	O
strong	O
gradient	B
whenever	O
the	O
model	O
has	O
the	O
wrong	O
answer	O
this	O
approach	O
is	O
based	O
on	O
using	O
sigmoid	O
output	O
units	O
combined	O
with	O
maximum	B
likelihood	I
a	O
sigmoid	O
output	O
unit	O
is	O
defined	O
by	O
y	O
w	O
h	O
b	O
chapter	O
deep	O
feedforward	O
networks	O
where	O
is	O
the	O
logistic	O
sigmoid	O
function	O
described	O
in	O
section	O
we	O
can	O
think	O
of	O
the	O
sigmoid	O
output	O
unit	O
as	O
having	O
two	O
components	O
first	O
it	O
h	O
b	O
next	O
it	O
uses	O
the	O
sigmoid	O
activation	O
uses	O
a	O
linear	O
layer	O
to	O
compute	O
z	O
w	O
function	O
to	O
convert	O
into	O
a	O
probability	O
z	O
we	O
omit	O
the	O
dependence	O
on	O
x	O
for	O
the	O
moment	O
to	O
discuss	O
how	O
to	O
define	O
a	O
probability	B
distribution	I
over	O
y	O
using	O
the	O
value	O
z	O
the	O
sigmoid	O
can	O
be	O
motivated	O
by	O
constructing	O
an	O
unnormalized	B
probability	B
distribution	I
py	O
which	O
does	O
not	O
sum	O
to	O
we	O
can	O
then	O
divide	O
by	O
an	O
appropriate	O
constant	O
to	O
obtain	O
a	O
valid	O
probability	B
distribution	I
if	O
we	O
begin	O
with	O
the	O
assumption	O
that	O
the	O
unnormalized	O
log	O
probabilities	O
are	O
linear	O
in	O
y	O
and	O
z	O
we	O
can	O
exponentiate	O
to	O
obtain	O
the	O
unnormalized	O
probabilities	O
we	O
then	O
normalize	O
to	O
see	O
that	O
this	O
yields	O
a	O
bernoulli	B
distribution	I
controlled	O
by	O
a	O
sigmoidal	O
transformation	O
of	O
yz	O
log	O
p	O
y	O
p	O
y	O
exp	O
yz	O
exp	O
expy	O
y	O
y	O
z	O
z	O
p	O
y	O
p	O
y	O
probability	O
distributions	O
based	O
on	O
exponentiation	O
and	O
normalization	O
are	O
common	O
throughout	O
the	O
statistical	O
modeling	O
literature	O
the	O
z	O
variable	O
defining	O
such	O
a	O
distribution	O
over	O
binary	O
variables	O
is	O
called	O
a	O
logit	O
this	O
approach	O
to	O
predicting	O
the	O
probabilities	O
in	O
log-space	O
is	O
natural	O
to	O
use	O
with	O
maximum	B
likelihood	I
learning	O
because	O
the	O
cost	O
function	O
used	O
with	O
maximum	O
x	O
the	O
log	O
in	O
the	O
cost	O
function	O
undoes	O
the	O
exp	O
of	O
the	O
likelihood	O
is	O
sigmoid	O
without	O
this	O
effect	O
the	O
saturation	O
of	O
the	O
sigmoid	O
could	O
prevent	O
gradientbased	O
learning	O
from	O
making	O
good	O
progress	O
the	O
loss	O
function	O
for	O
maximum	B
likelihood	I
learning	O
of	O
a	O
bernoulli	O
parametrized	O
by	O
a	O
sigmoid	O
is	O
log	O
py	O
j	O
p	O
y	O
x	O
log	O
log	O
y	O
y	O
z	O
z	O
this	O
derivation	O
makes	O
use	O
of	O
some	O
properties	O
from	O
section	O
by	O
rewriting	O
the	O
loss	O
in	O
terms	O
of	O
the	O
softplus	O
function	O
we	O
can	O
see	O
that	O
it	O
saturates	O
only	O
when	O
is	O
very	O
negative	O
saturation	O
thus	O
occurs	O
only	O
when	O
the	O
model	O
already	O
has	O
the	O
right	O
answer	O
when	O
y	O
and	O
z	O
is	O
very	O
positive	O
or	O
y	O
and	O
z	O
is	O
very	O
negative	O
when	O
z	O
has	O
the	O
wrong	O
sign	O
the	O
argument	O
to	O
the	O
softplus	O
function	O
chapter	O
deep	O
feedforward	O
networks	O
z	O
as	O
may	O
be	O
simplified	O
to	O
z	O
becomes	O
large	O
while	O
z	O
has	O
the	O
wrong	O
sign	O
z	O
the	O
the	O
softplus	O
function	O
asymptotes	O
toward	O
simply	O
returning	O
its	O
argument	O
derivative	B
with	O
respect	O
to	O
z	O
asymptotes	O
to	O
signz	O
so	O
in	O
the	O
limit	O
of	O
extremely	O
incorrect	O
z	O
the	O
softplus	O
function	O
does	O
not	O
shrink	O
the	O
gradient	B
at	O
all	O
this	O
property	O
is	O
very	O
useful	O
because	O
it	O
means	O
that	O
gradient-based	O
learning	O
can	O
act	O
to	O
quickly	O
correct	O
a	O
mistaken	O
when	O
we	O
use	O
other	O
loss	O
functions	O
such	O
as	O
mean	B
squared	I
error	I
the	O
loss	O
can	O
saturate	O
anytime	O
saturates	O
the	O
sigmoid	O
activation	B
function	I
saturates	O
to	O
when	O
z	O
becomes	O
very	O
negative	O
and	O
saturates	O
to	O
when	O
z	O
becomes	O
very	O
positive	O
the	O
gradient	B
can	O
shrink	O
too	O
small	O
to	O
be	O
useful	O
for	O
learning	O
whenever	O
this	O
happens	O
whether	O
the	O
model	O
has	O
the	O
correct	O
answer	O
or	O
the	O
incorrect	O
answer	O
for	O
this	O
reason	O
maximum	B
likelihood	I
is	O
almost	O
always	O
the	O
preferred	O
approach	O
to	O
training	O
sigmoid	O
output	O
units	O
analytically	O
the	O
logarithm	O
of	O
the	O
sigmoid	O
is	O
always	O
defined	O
and	O
finite	O
because	O
the	O
sigmoid	O
returns	O
values	O
restricted	O
to	O
the	O
open	O
interval	O
rather	O
than	O
using	O
the	O
entire	O
closed	O
interval	O
of	O
valid	O
probabilities	O
in	O
software	O
implementations	O
to	O
avoid	O
numerical	O
problems	O
it	O
is	O
best	O
to	O
write	O
the	O
negative	O
log-likelihood	O
as	O
a	O
function	O
of	O
z	O
rather	O
than	O
as	O
a	O
function	O
of	O
y	O
if	O
the	O
sigmoid	O
function	O
underflows	O
to	O
zero	O
then	O
taking	O
the	O
logarithm	O
of	O
y	O
yields	O
negative	O
infinity	O
softmax	O
units	O
for	O
multinoulli	O
output	O
distributions	O
any	O
time	O
we	O
wish	O
to	O
represent	O
a	O
probability	B
distribution	I
over	O
a	O
discrete	O
variable	O
with	O
n	O
possible	O
values	O
we	O
may	O
use	O
the	O
softmax	O
function	O
this	O
can	O
be	O
seen	O
as	O
a	O
generalization	B
of	O
the	O
sigmoid	O
function	O
which	O
was	O
used	O
to	O
represent	O
a	O
probability	B
distribution	I
over	O
a	O
binary	O
variable	O
softmax	O
functions	O
are	O
most	O
often	O
used	O
as	O
the	O
output	O
of	O
a	O
classifier	O
to	O
represent	O
the	O
probability	B
distribution	I
over	O
n	O
different	O
classes	O
more	O
rarely	O
softmax	O
functions	O
can	O
be	O
used	O
inside	O
the	O
model	O
itself	O
if	O
we	O
wish	O
the	O
model	O
to	O
choose	O
between	O
one	O
of	O
n	O
different	O
options	O
for	O
some	O
internal	O
variable	O
in	O
the	O
case	O
of	O
binary	O
variables	O
we	O
wished	O
to	O
produce	O
a	O
single	O
number	O
p	O
y	O
y	O
x	O
and	O
and	O
because	O
we	O
wanted	O
the	O
because	O
this	O
number	O
needed	O
to	O
lie	O
between	O
logarithm	O
of	O
the	O
number	O
to	O
be	O
well-behaved	O
for	O
gradient-based	O
optimization	O
of	O
the	O
log-likelihood	O
we	O
chose	O
to	O
instead	O
predict	O
a	O
number	O
z	O
log	O
py	O
x	O
exponentiating	O
and	O
normalizing	O
gave	O
us	O
a	O
bernoulli	B
distribution	I
controlled	O
by	O
the	O
sigmoid	O
function	O
chapter	O
deep	O
feedforward	O
networks	O
to	O
generalize	O
to	O
the	O
case	O
of	O
a	O
discrete	O
variable	O
with	O
n	O
values	O
we	O
now	O
need	O
x	O
we	O
require	O
not	O
only	O
that	O
each	O
to	O
produce	O
a	O
vector	O
y	O
with	O
yi	O
p	O
i	O
element	O
of	O
yi	O
be	O
between	O
so	O
that	O
it	O
represents	O
a	O
valid	O
probability	B
distribution	I
the	O
same	O
approach	O
that	O
worked	O
for	O
the	O
bernoulli	B
distribution	I
generalizes	O
to	O
the	O
multinoulli	B
distribution	I
first	O
a	O
linear	O
layer	O
predicts	O
unnormalized	O
log	O
probabilities	O
and	O
but	O
also	O
that	O
the	O
entire	O
vector	O
sums	O
to	O
z	O
w	O
h	O
b	O
where	O
zi	O
log	O
p	O
i	O
normalize	O
z	O
x	O
the	O
softmax	O
function	O
can	O
then	O
exponentiate	O
and	O
to	O
obtain	O
the	O
desired	O
y	O
formally	O
the	O
softmax	O
function	O
is	O
given	O
by	O
softmax	O
i	O
expzi	O
j	O
expzj	O
as	O
with	O
the	O
logistic	O
sigmoid	O
the	O
use	O
of	O
the	O
exp	O
function	O
works	O
very	O
well	O
when	O
training	O
the	O
softmax	O
to	O
output	O
a	O
target	O
value	O
y	O
using	O
maximum	O
log-likelihood	O
in	O
this	O
case	O
we	O
wish	O
to	O
maximize	O
log	O
p	O
i	O
z	O
log	O
softmax	O
defining	O
the	O
softmax	O
in	O
terms	O
of	O
exp	O
is	O
natural	O
because	O
the	O
log	O
in	O
the	O
log-likelihood	O
can	O
undo	O
the	O
of	O
the	O
softmax	O
exp	O
log	O
softmax	O
i	O
zi	O
log	O
expzj	O
j	O
shows	O
that	O
the	O
input	O
the	O
first	O
term	O
of	O
equation	O
z	O
i	O
always	O
has	O
a	O
direct	O
contribution	O
to	O
the	O
cost	O
function	O
because	O
this	O
term	O
cannot	O
saturate	O
we	O
know	O
that	O
learning	O
can	O
proceed	O
even	O
if	O
the	O
contribution	O
of	O
zi	O
to	O
the	O
second	O
term	O
of	O
equation	O
becomes	O
very	O
small	O
when	O
maximizing	O
the	O
log-likelihood	O
the	O
first	O
term	O
encourages	O
z	O
i	O
to	O
be	O
pushed	O
up	O
while	O
the	O
second	O
term	O
encourages	O
all	O
of	O
z	O
to	O
be	O
pushed	O
down	O
to	O
gain	O
some	O
intuition	O
for	O
the	O
second	O
term	O
log	O
j	O
expzj	O
observe	O
that	O
this	O
term	O
can	O
be	O
roughly	O
approximated	O
by	O
maxj	O
zj	O
this	O
approximation	O
is	O
based	O
on	O
the	O
idea	O
that	O
expzk	O
is	O
insignificant	O
for	O
any	O
zk	O
that	O
is	O
noticeably	O
less	O
than	O
maxj	O
zj	O
the	O
intuition	O
we	O
can	O
gain	O
from	O
this	O
approximation	O
is	O
that	O
the	O
negative	O
log-likelihood	O
cost	O
function	O
always	O
strongly	O
penalizes	O
the	O
most	O
active	O
incorrect	O
prediction	O
if	O
the	O
correct	O
answer	O
already	O
has	O
the	O
largest	O
input	O
to	O
the	O
softmax	O
then	O
maxj	O
zj	O
zi	O
terms	O
will	O
roughly	O
cancel	O
the	O
this	O
example	B
will	O
then	O
contribute	O
little	O
to	O
the	O
overall	O
training	O
cost	O
which	O
will	O
be	O
dominated	O
by	O
other	O
examples	O
that	O
are	O
not	O
yet	O
correctly	O
classified	O
zi	O
term	O
and	O
the	O
log	O
j	O
expz	O
j	O
so	O
far	O
we	O
have	O
discussed	O
only	O
a	O
single	O
example	B
overall	O
unregularized	O
maximum	B
likelihood	I
will	O
drive	O
the	O
model	O
to	O
learn	O
parameters	O
that	O
drive	O
the	O
softmax	O
to	O
predict	O
chapter	O
deep	O
feedforward	O
networks	O
the	O
fraction	O
of	O
counts	O
of	O
each	O
outcome	O
observed	O
in	O
the	O
training	O
set	O
softmax	O
z	O
x	O
i	O
m	O
m	O
x	O
because	O
maximum	B
likelihood	I
is	O
a	O
consistent	O
estimator	O
this	O
is	O
guaranteed	O
to	O
happen	O
so	O
long	O
as	O
the	O
model	O
family	O
is	O
capable	O
of	O
representing	O
the	O
training	O
distribution	O
in	O
practice	O
limited	O
model	O
capacity	O
and	O
imperfect	O
optimization	O
will	O
mean	O
that	O
the	O
model	O
is	O
only	O
able	O
to	O
approximate	O
these	O
fractions	O
many	O
objective	O
functions	O
other	O
than	O
the	O
log-likelihood	O
do	O
not	O
work	O
as	O
well	O
with	O
the	O
softmax	O
function	O
specifically	O
objective	O
functions	O
that	O
do	O
not	O
use	O
a	O
log	O
to	O
undo	O
the	O
exp	O
of	O
the	O
softmax	O
fail	O
to	O
learn	O
when	O
the	O
argument	O
to	O
the	O
exp	O
becomes	O
very	O
negative	O
causing	O
the	O
gradient	B
to	O
vanish	O
in	O
particular	O
squared	O
error	O
is	O
a	O
poor	O
loss	O
function	O
for	O
softmax	O
units	O
and	O
can	O
fail	O
to	O
train	O
the	O
model	O
to	O
change	O
its	O
output	O
even	O
when	O
the	O
model	O
makes	O
highly	O
confident	O
incorrect	O
predictions	O
bridle	O
to	O
understand	O
why	O
these	O
other	O
loss	O
functions	O
can	O
fail	O
we	O
need	O
to	O
examine	O
the	O
softmax	O
function	O
itself	O
like	O
the	O
sigmoid	O
the	O
softmax	O
activation	O
can	O
saturate	O
the	O
sigmoid	O
function	O
has	O
a	O
single	O
output	O
that	O
saturates	O
when	O
its	O
input	O
is	O
extremely	O
negative	O
or	O
extremely	O
positive	O
in	O
the	O
case	O
of	O
the	O
softmax	O
there	O
are	O
multiple	O
output	O
values	O
these	O
output	O
values	O
can	O
saturate	O
when	O
the	O
differences	O
between	O
input	O
values	O
become	O
extreme	O
when	O
the	O
softmax	O
saturates	O
many	O
cost	O
functions	O
based	O
on	O
the	O
softmax	O
also	O
saturate	O
unless	O
they	O
are	O
able	O
to	O
invert	O
the	O
saturating	O
activating	O
function	O
to	O
see	O
that	O
the	O
softmax	O
function	O
responds	O
to	O
the	O
difference	O
between	O
its	O
inputs	O
observe	O
that	O
the	O
softmax	O
output	O
is	O
invariant	O
to	O
adding	O
the	O
same	O
scalar	O
to	O
all	O
of	O
its	O
inputs	O
softmax	O
softmax	O
c	O
z	O
z	O
using	O
this	O
property	O
we	O
can	O
derive	O
a	O
numerically	O
stable	O
variant	O
of	O
the	O
softmax	O
softmax	O
softmax	O
z	O
z	O
max	O
i	O
zi	O
the	O
reformulated	O
version	O
allows	O
us	O
to	O
evaluate	O
softmax	O
with	O
only	O
small	O
numerical	O
errors	O
even	O
when	O
z	O
contains	O
extremely	O
large	O
or	O
extremely	O
negative	O
numbers	O
examining	O
the	O
numerically	O
stable	O
variant	O
we	O
see	O
that	O
the	O
softmax	O
function	O
is	O
driven	O
by	O
the	O
amount	O
that	O
its	O
arguments	O
deviate	O
from	O
maxi	O
zi	O
an	O
output	O
softmaxzi	O
saturates	O
to	O
when	O
the	O
corresponding	O
input	O
is	O
maximal	O
maxi	O
zi	O
and	O
zi	O
is	O
much	O
greater	O
than	O
all	O
of	O
the	O
other	O
inputs	O
the	O
output	O
softmaxzi	O
can	O
also	O
saturate	O
to	O
when	O
zi	O
is	O
not	O
maximal	O
and	O
the	O
maximum	O
is	O
much	O
greater	O
this	O
is	O
a	O
generalization	B
of	O
the	O
way	O
that	O
sigmoid	O
units	O
saturate	O
and	O
chapter	O
deep	O
feedforward	O
networks	O
can	O
cause	O
similar	O
difficulties	O
for	O
learning	O
if	O
the	O
loss	O
function	O
is	O
not	O
designed	O
to	O
compensate	O
for	O
it	O
the	O
argument	O
z	O
to	O
the	O
softmax	O
function	O
can	O
be	O
produced	O
in	O
two	O
different	O
ways	O
the	O
most	O
common	O
is	O
simply	O
to	O
have	O
an	O
earlier	O
layer	O
of	O
the	O
neural	B
network	I
output	O
every	O
element	O
of	O
z	O
as	O
described	O
above	O
using	O
the	O
linear	O
layer	O
z	O
w	O
h	O
b	O
while	O
straightforward	O
this	O
approach	O
actually	O
overparametrizes	O
the	O
distribution	O
the	O
constraint	O
that	O
the	O
n	O
outputs	O
must	O
sum	O
to	O
means	O
that	O
only	O
parameters	O
are	O
necessary	O
the	O
probability	O
of	O
the	O
n-th	O
value	O
may	O
be	O
obtained	O
by	O
subtracting	O
the	O
first	O
n	O
probabilities	O
from	O
we	O
can	O
thus	O
impose	O
a	O
requirement	O
that	O
one	O
element	O
of	O
z	O
be	O
fixed	O
for	O
example	B
we	O
can	O
require	O
that	O
zn	O
indeed	O
this	O
is	O
exactly	O
x	O
is	O
equivalent	O
to	O
defining	O
what	O
the	O
sigmoid	O
unit	O
does	O
defining	O
p	O
p	O
argument	O
and	O
the	O
n	O
argument	O
approaches	O
to	O
the	O
softmax	O
can	O
describe	O
the	O
same	O
set	O
of	O
probability	O
distributions	O
but	O
have	O
different	O
learning	O
dynamics	O
in	O
practice	O
there	O
is	O
rarely	O
much	O
difference	O
between	O
using	O
the	O
overparametrized	O
version	O
or	O
the	O
restricted	O
version	O
and	O
it	O
is	O
simpler	O
to	O
implement	O
the	O
overparametrized	O
version	O
x	O
with	O
a	O
two-dimensional	O
z	O
and	O
both	O
the	O
n	O
n	O
from	O
a	O
neuroscientific	O
point	O
of	O
view	O
it	O
is	O
interesting	O
to	O
think	O
of	O
the	O
softmax	O
as	O
a	O
way	O
to	O
create	O
a	O
form	O
of	O
competition	O
between	O
the	O
units	O
that	O
participate	O
in	O
it	O
the	O
softmax	O
outputs	O
always	O
sum	O
to	O
so	O
an	O
increase	O
in	O
the	O
value	O
of	O
one	O
unit	O
necessarily	O
corresponds	O
to	O
a	O
decrease	O
in	O
the	O
value	O
of	O
others	O
this	O
is	O
analogous	O
to	O
the	O
lateral	O
inhibition	O
that	O
is	O
believed	O
to	O
exist	O
between	O
nearby	O
neurons	O
in	O
the	O
cortex	O
at	O
the	O
extreme	O
the	O
difference	O
between	O
the	O
maximal	O
ai	O
and	O
the	O
others	O
is	O
large	O
in	O
magnitude	O
it	O
becomes	O
a	O
form	O
of	O
winner-take-all	O
of	O
the	O
outputs	O
is	O
nearly	O
and	O
the	O
others	O
are	O
nearly	O
the	O
name	O
softmax	O
can	O
be	O
somewhat	O
confusing	O
the	O
function	O
is	O
more	O
closely	O
related	O
to	O
the	O
arg	O
max	O
function	O
than	O
the	O
max	O
function	O
the	O
term	O
soft	O
derives	O
from	O
the	O
fact	O
that	O
the	O
softmax	O
function	O
is	O
continuous	O
and	O
differentiable	O
the	O
arg	O
max	O
function	O
with	O
its	O
result	O
represented	O
as	O
a	O
one-hot	O
vector	O
is	O
not	O
continuous	O
or	O
differentiable	O
the	O
softmax	O
function	O
thus	O
provides	O
a	O
softened	O
version	O
of	O
the	O
arg	O
max	O
the	O
corresponding	O
soft	O
version	O
of	O
the	O
maximum	O
function	O
is	O
softmaxz	O
z	O
it	O
would	O
perhaps	O
be	O
better	O
to	O
call	O
the	O
softmax	O
function	O
softargmax	O
but	O
the	O
current	O
name	O
is	O
an	O
entrenched	O
convention	O
other	O
output	O
types	O
the	O
linear	O
sigmoid	O
and	O
softmax	O
output	O
units	O
described	O
above	O
are	O
the	O
most	O
common	O
neural	O
networks	O
can	O
generalize	O
to	O
almost	O
any	O
kind	O
of	O
output	O
layer	O
that	O
we	O
wish	O
the	O
principle	O
of	O
maximum	B
likelihood	I
provides	O
a	O
guide	O
for	O
how	O
to	O
design	O
chapter	O
deep	O
feedforward	O
networks	O
a	O
good	O
cost	O
function	O
for	O
nearly	O
any	O
kind	O
of	O
output	O
layer	O
in	O
general	O
if	O
we	O
define	O
a	O
conditional	O
distribution	O
py	O
x	O
the	O
principle	O
of	O
maximum	B
likelihood	I
suggests	O
we	O
use	O
log	O
y	O
x	O
as	O
our	O
cost	O
function	O
in	O
general	O
we	O
can	O
think	O
of	O
the	O
neural	B
network	I
as	O
representing	O
a	O
function	O
fx	O
the	O
outputs	O
of	O
this	O
function	O
are	O
not	O
direct	O
predictions	O
of	O
the	O
value	O
y	O
instead	O
f	O
provides	O
the	O
parameters	O
for	O
a	O
distribution	O
over	O
y	O
our	O
loss	O
function	O
can	O
then	O
be	O
interpreted	O
as	O
p	O
y	O
x	O
log	O
for	O
example	B
we	O
may	O
wish	O
to	O
learn	O
the	O
variance	O
of	O
a	O
conditional	O
gaussian	O
for	O
y	O
given	O
x	O
in	O
the	O
simple	O
case	O
where	O
the	O
variance	O
is	O
a	O
constant	O
there	O
is	O
a	O
closed	O
form	O
expression	O
because	O
the	O
maximum	B
likelihood	I
estimator	O
of	O
variance	O
is	O
simply	O
the	O
empirical	O
mean	O
of	O
the	O
squared	O
difference	O
between	O
observations	O
y	O
and	O
their	O
expected	O
value	O
a	O
computationally	O
more	O
expensive	O
approach	O
that	O
does	O
not	O
require	O
writing	O
special-case	O
code	O
is	O
to	O
simply	O
include	O
the	O
variance	O
as	O
one	O
of	O
the	O
properties	O
of	O
the	O
distribution	O
py	O
x	O
that	O
is	O
controlled	O
by	O
fx	O
the	O
negative	O
log-likelihood	O
log	O
py	O
will	O
then	O
provide	O
a	O
cost	O
function	O
with	O
the	O
appropriate	O
terms	O
necessary	O
to	O
make	O
our	O
optimization	O
procedure	O
incrementally	O
learn	O
the	O
variance	O
in	O
the	O
simple	O
case	O
where	O
the	O
standard	B
deviation	I
does	O
not	O
depend	O
on	O
the	O
input	O
we	O
can	O
make	O
a	O
new	O
parameter	O
in	O
the	O
network	O
that	O
is	O
copied	O
directly	O
into	O
this	O
new	O
parameter	O
might	O
be	O
itself	O
or	O
could	O
be	O
a	O
parameter	O
v	O
representing	O
or	O
it	O
could	O
be	O
a	O
parameter	O
representing	O
depending	O
on	O
how	O
we	O
choose	O
to	O
parametrize	O
the	O
distribution	O
we	O
may	O
wish	O
our	O
model	O
to	O
predict	O
a	O
different	O
amount	O
of	O
variance	O
in	O
y	O
for	O
different	O
values	O
of	O
x	O
this	O
is	O
called	O
a	O
heteroscedastic	B
model	O
in	O
the	O
heteroscedastic	B
case	O
we	O
simply	O
make	O
the	O
specification	O
of	O
the	O
variance	O
be	O
one	O
of	O
the	O
values	O
output	O
by	O
fx	O
a	O
typical	O
way	O
to	O
do	O
this	O
is	O
to	O
formulate	O
the	O
gaussian	O
distribution	O
using	O
precision	B
rather	O
than	O
variance	O
as	O
described	O
in	O
equation	O
in	O
the	O
multivariate	O
case	O
it	O
is	O
most	O
common	O
to	O
use	O
a	O
diagonal	O
precision	B
matrix	O
diag	O
this	O
formulation	O
works	O
well	O
with	O
gradient	B
descent	O
because	O
the	O
formula	O
for	O
the	O
log-likelihood	O
of	O
the	O
gaussian	O
distribution	O
parametrized	O
by	O
involves	O
only	O
multiplication	O
by	O
i	O
and	O
addition	O
of	O
log	O
i	O
the	O
gradient	B
of	O
multiplication	O
addition	O
and	O
logarithm	O
operations	O
is	O
well-behaved	O
by	O
comparison	O
if	O
we	O
parametrized	O
the	O
output	O
in	O
terms	O
of	O
variance	O
we	O
would	O
need	O
to	O
use	O
division	O
the	O
division	O
function	O
becomes	O
arbitrarily	O
steep	O
near	O
zero	O
while	O
large	O
gradients	O
can	O
help	O
learning	O
arbitrarily	O
large	O
gradients	O
usually	O
result	O
in	O
instability	O
if	O
we	O
parametrized	O
the	O
output	O
in	O
terms	O
of	O
standard	B
deviation	I
the	O
log-likelihood	O
would	O
still	O
involve	O
division	O
and	O
would	O
also	O
involve	O
squaring	O
the	O
gradient	B
through	O
the	O
squaring	O
operation	B
can	O
vanish	O
near	O
zero	O
making	O
it	O
difficult	O
to	O
learn	O
parameters	O
that	O
are	O
squared	O
chapter	O
deep	O
feedforward	O
networks	O
regardless	O
of	O
whether	O
we	O
use	O
standard	B
deviation	I
variance	O
or	O
precision	B
we	O
must	O
ensure	O
that	O
the	O
covariance	B
matrix	I
of	O
the	O
gaussian	O
is	O
positive	B
definite	I
because	O
the	O
eigenvalues	O
of	O
the	O
precision	B
matrix	O
are	O
the	O
reciprocals	O
of	O
the	O
eigenvalues	O
of	O
the	O
covariance	B
matrix	I
this	O
is	O
equivalent	O
to	O
ensuring	O
that	O
the	O
precision	B
matrix	O
is	O
positive	B
definite	I
if	O
we	O
use	O
a	O
diagonal	B
matrix	I
or	O
a	O
scalar	O
times	O
the	O
diagonal	B
matrix	I
then	O
the	O
only	O
condition	O
we	O
need	O
to	O
enforce	O
on	O
the	O
output	O
of	O
the	O
model	O
is	O
positivity	O
if	O
we	O
suppose	O
that	O
a	O
is	O
the	O
raw	O
activation	O
of	O
the	O
model	O
used	O
to	O
determine	O
the	O
diagonal	O
precision	B
we	O
can	O
use	O
the	O
softplus	O
function	O
to	O
obtain	O
a	O
positive	O
precision	B
vector	O
this	O
same	O
strategy	O
applies	O
equally	O
if	O
using	O
variance	O
or	O
standard	B
deviation	I
rather	O
than	O
precision	B
or	O
if	O
using	O
a	O
scalar	O
times	O
identity	O
rather	O
than	O
diagonal	B
matrix	I
it	O
is	O
rare	O
to	O
learn	O
a	O
covariance	O
or	O
precision	B
matrix	O
with	O
richer	O
structure	O
than	O
diagonal	O
if	O
the	O
covariance	O
is	O
full	O
and	O
conditional	O
then	O
a	O
parametrization	O
must	O
be	O
chosen	O
that	O
guarantees	O
positive-definiteness	O
of	O
the	O
predicted	O
covariance	B
matrix	I
this	O
can	O
be	O
achieved	O
by	O
writing	O
where	O
b	O
is	O
an	O
unconstrained	O
square	B
matrix	I
one	O
practical	O
issue	O
if	O
the	O
matrix	O
is	O
full	O
rank	O
is	O
that	O
computing	O
the	O
matrix	O
requiring	O
computation	O
for	O
the	O
likelihood	O
is	O
expensive	O
with	O
a	O
d	O
determinant	O
and	O
inverse	O
of	O
equivalently	O
and	O
more	O
commonly	O
done	O
its	O
eigendecomposition	B
or	O
that	O
of	O
x	O
b	O
x	O
b	O
b	O
x	O
d	O
we	O
often	O
want	O
to	O
perform	O
multimodal	O
regression	B
that	O
is	O
to	O
predict	O
real	O
values	O
that	O
come	O
from	O
a	O
conditional	O
distribution	O
py	O
x	O
that	O
can	O
have	O
several	O
different	O
peaks	O
in	O
y	O
space	O
for	O
the	O
same	O
value	O
of	O
x	O
in	O
this	O
case	O
a	O
gaussian	O
mixture	O
is	O
a	O
natural	O
representation	O
for	O
the	O
output	O
neural	O
networks	O
with	O
gaussian	O
mixtures	O
as	O
their	O
output	O
are	O
often	O
called	O
mixture	B
density	I
networks	I
a	O
gaussian	O
mixture	O
output	O
with	O
n	O
components	O
is	O
defined	O
by	O
the	O
conditional	B
probability	B
distribution	I
jacobs	O
et	O
al	O
bishop	O
p	O
y	O
x	O
n	O
x	O
p	O
c	O
i	O
n	O
the	O
neural	B
network	I
must	O
have	O
three	O
outputs	O
a	O
vector	O
defining	O
pc	O
i	O
x	O
a	O
matrix	O
providing	O
for	O
all	O
i	O
and	O
a	O
tensor	O
providing	O
x	O
for	O
all	O
i	O
these	O
outputs	O
must	O
satisfy	O
different	O
constraints	O
mixture	O
components	O
pc	O
i	O
x	O
these	O
form	O
a	O
multinoulli	B
distribution	I
over	O
the	O
n	O
different	O
components	O
associated	O
with	O
latent	O
c	O
and	O
can	O
consider	O
c	O
to	O
be	O
latent	O
because	O
we	O
do	O
not	O
observe	O
it	O
in	O
the	O
data	O
given	O
input	O
x	O
and	O
target	O
y	O
it	O
is	O
not	O
possible	O
to	O
know	O
with	O
certainty	O
which	O
gaussian	O
component	O
was	O
responsible	O
for	O
y	O
but	O
we	O
can	O
imagine	O
that	O
y	O
was	O
generated	O
by	O
picking	O
one	O
of	O
them	O
and	O
make	O
that	O
unobserved	O
choice	O
a	O
random	B
variable	I
chapter	O
deep	O
feedforward	O
networks	O
typically	O
be	O
obtained	O
by	O
a	O
softmax	O
over	O
an	O
n-dimensional	O
vector	O
to	O
guarantee	O
that	O
these	O
outputs	O
are	O
positive	O
and	O
sum	O
to	O
d	O
means	O
these	O
indicate	O
the	O
center	O
or	O
mean	O
associated	O
with	O
the	O
i-th	O
gaussian	O
component	O
and	O
are	O
unconstrained	O
with	O
no	O
nonlinearity	O
at	O
all	O
for	O
these	O
output	O
units	O
if	O
y	O
is	O
a	O
d-vector	O
then	O
the	O
network	O
must	O
output	O
an	O
n	O
matrix	O
containing	O
all	O
n	O
of	O
these	O
d-dimensional	O
vectors	O
learning	O
these	O
means	O
with	O
maximum	B
likelihood	I
is	O
slightly	O
more	O
complicated	O
than	O
learning	O
the	O
means	O
of	O
a	O
distribution	O
with	O
only	O
one	O
output	O
mode	O
we	O
only	O
want	O
to	O
update	O
the	O
mean	O
for	O
the	O
component	O
that	O
actually	O
produced	O
the	O
observation	O
in	O
practice	O
we	O
do	O
not	O
know	O
which	O
component	O
produced	O
each	O
observation	O
the	O
expression	O
for	O
the	O
negative	O
log-likelihood	O
naturally	O
weights	B
each	O
example	B
s	O
contribution	O
to	O
the	O
loss	O
for	O
each	O
component	O
by	O
the	O
probability	O
that	O
the	O
component	O
produced	O
the	O
example	B
covariances	O
these	O
specify	O
the	O
covariance	B
matrix	I
for	O
each	O
component	O
i	O
as	O
when	O
learning	O
a	O
single	O
gaussian	O
component	O
we	O
typically	O
use	O
a	O
diagonal	B
matrix	I
to	O
avoid	O
needing	O
to	O
compute	O
determinants	O
as	O
with	O
learning	O
the	O
means	O
of	O
the	O
mixture	O
maximum	B
likelihood	I
is	O
complicated	O
by	O
needing	O
to	O
assign	O
partial	O
responsibility	O
for	O
each	O
point	O
to	O
each	O
mixture	O
component	O
gradient	B
descent	O
will	O
automatically	O
follow	O
the	O
correct	O
process	O
if	O
given	O
the	O
correct	O
specification	O
of	O
the	O
negative	O
log-likelihood	O
under	O
the	O
mixture	O
model	O
it	O
has	O
been	O
reported	O
that	O
gradient-based	O
optimization	O
of	O
conditional	O
gaussian	O
mixtures	O
the	O
output	O
of	O
neural	O
networks	O
can	O
be	O
unreliable	O
in	O
part	O
because	O
one	O
gets	O
divisions	O
the	O
variance	O
which	O
can	O
be	O
numerically	O
unstable	O
some	O
variance	O
gets	O
to	O
be	O
small	O
for	O
a	O
particular	O
example	B
yielding	O
very	O
large	O
gradients	O
one	O
solution	O
is	O
to	O
clip	O
gradients	O
section	O
while	O
another	O
is	O
to	O
scale	O
the	O
gradients	O
heuristically	O
murray	O
and	O
larochelle	O
or	O
movements	O
of	O
physical	O
objects	O
gaussian	O
mixture	O
outputs	O
are	O
particularly	O
effective	O
in	O
generative	O
models	O
of	O
speech	O
the	O
mixture	O
density	O
strategy	O
gives	O
a	O
way	O
for	O
the	O
network	O
to	O
represent	O
multiple	O
output	O
modes	O
and	O
to	O
control	O
the	O
variance	O
of	O
its	O
output	O
which	O
is	O
crucial	O
for	O
obtaining	O
a	O
high	O
degree	O
of	O
quality	O
in	O
these	O
real-valued	O
domains	O
an	O
example	B
of	O
a	O
mixture	O
density	O
network	O
is	O
shown	O
in	O
figure	O
in	O
general	O
we	O
may	O
wish	O
to	O
continue	O
to	O
model	O
larger	O
vectors	O
y	O
containing	O
more	O
variables	O
and	O
to	O
impose	O
richer	O
and	O
richer	O
structures	O
on	O
these	O
output	O
variables	O
for	O
example	B
we	O
may	O
wish	O
for	O
our	O
neural	B
network	I
to	O
output	O
a	O
sequence	O
of	O
characters	O
that	O
forms	O
a	O
sentence	O
in	O
these	O
cases	O
we	O
may	O
continue	O
to	O
use	O
the	O
principle	O
of	O
maximum	B
likelihood	I
applied	O
to	O
our	O
model	O
p	O
y	O
but	O
the	O
model	O
we	O
use	O
chapter	O
deep	O
feedforward	O
networks	O
y	O
x	O
figure	O
samples	O
drawn	O
from	O
a	O
neural	B
network	I
with	O
a	O
mixture	O
density	O
output	O
layer	O
the	O
input	O
x	O
is	O
sampled	O
from	O
a	O
uniform	B
distribution	I
and	O
the	O
output	O
y	O
is	O
sampled	O
from	O
the	O
neural	B
network	I
is	O
able	O
to	O
learn	O
nonlinear	O
mappings	O
from	O
the	O
input	O
to	O
pmodely	O
x	O
the	O
parameters	O
of	O
the	O
output	O
distribution	O
these	O
parameters	O
include	O
the	O
probabilities	O
governing	O
which	O
of	O
three	O
mixture	O
components	O
will	O
generate	O
the	O
output	O
as	O
well	O
as	O
the	O
parameters	O
for	O
each	O
mixture	O
component	O
each	O
mixture	O
component	O
is	O
gaussian	O
with	O
predicted	O
mean	O
and	O
variance	O
all	O
of	O
these	O
aspects	O
of	O
the	O
output	O
distribution	O
are	O
able	O
to	O
vary	O
with	O
respect	O
to	O
the	O
input	O
and	O
to	O
do	O
so	O
in	O
nonlinear	O
ways	O
x	O
to	O
describe	O
y	O
becomes	O
complex	O
enough	O
to	O
be	O
beyond	O
the	O
scope	O
of	O
this	O
chapter	O
chapter	O
describes	O
how	O
to	O
use	O
recurrent	O
neural	O
networks	O
to	O
define	O
such	O
models	O
over	O
sequences	O
and	O
part	O
describes	O
advanced	O
techniques	O
for	O
modeling	O
arbitrary	O
probability	O
distributions	O
iii	O
hidden	O
units	O
so	O
far	O
we	O
have	O
focused	O
our	O
discussion	O
on	O
design	O
choices	O
for	O
neural	O
networks	O
that	O
are	O
common	O
to	O
most	O
parametric	O
machine	B
learning	I
models	O
trained	O
with	O
gradientbased	O
optimization	O
now	O
we	O
turn	O
to	O
an	O
issue	O
that	O
is	O
unique	O
to	O
feedforward	O
neural	O
networks	O
how	O
to	O
choose	O
the	O
type	O
of	O
hidden	O
unit	O
to	O
use	O
in	O
the	O
hidden	O
layers	O
of	O
the	O
model	O
the	O
design	O
of	O
hidden	O
units	O
is	O
an	O
extremely	O
active	O
area	O
of	O
research	O
and	O
does	O
not	O
yet	O
have	O
many	O
definitive	O
guiding	O
theoretical	O
principles	O
rectified	O
linear	O
units	O
are	O
an	O
excellent	O
default	O
choice	O
of	O
hidden	O
unit	O
many	O
other	O
types	O
of	O
hidden	O
units	O
are	O
available	O
it	O
can	O
be	O
difficult	O
to	O
determine	O
when	O
to	O
use	O
which	O
kind	O
rectified	O
linear	O
units	O
are	O
usually	O
an	O
acceptable	O
choice	O
we	O
chapter	O
deep	O
feedforward	O
networks	O
describe	O
here	O
some	O
of	O
the	O
basic	O
intuitions	O
motivating	O
each	O
type	O
of	O
hidden	O
units	O
these	O
intuitions	O
can	O
help	O
decide	O
when	O
to	O
try	O
out	O
each	O
of	O
these	O
units	O
it	O
is	O
usually	O
impossible	O
to	O
predict	O
in	O
advance	O
which	O
will	O
work	O
best	O
the	O
design	O
process	O
consists	O
of	O
trial	O
and	O
error	O
intuiting	O
that	O
a	O
kind	O
of	O
hidden	O
unit	O
may	O
work	O
well	O
and	O
then	O
training	O
a	O
network	O
with	O
that	O
kind	O
of	O
hidden	O
unit	O
and	O
evaluating	O
its	O
performance	O
on	O
a	O
validation	O
set	O
these	O
ideas	O
will	O
be	O
described	O
further	O
in	O
chapter	O
some	O
of	O
the	O
hidden	O
units	O
included	O
in	O
this	O
list	O
are	O
not	O
actually	O
differentiable	O
at	O
all	O
input	O
points	O
for	O
example	B
the	O
rectified	O
linear	O
function	O
g	O
max	O
is	O
not	O
z	O
differentiable	O
at	O
z	O
this	O
may	O
seem	O
like	O
it	O
invalidates	O
g	O
for	O
use	O
with	O
a	O
gradientbased	O
learning	O
algorithm	O
in	O
practice	O
gradient	B
descent	O
still	O
performs	O
well	O
enough	O
for	O
these	O
models	O
to	O
be	O
used	O
for	O
machine	B
learning	I
tasks	O
this	O
is	O
in	O
part	O
because	O
neural	B
network	I
training	O
algorithms	O
do	O
not	O
usually	O
arrive	O
at	O
a	O
local	O
minimum	O
of	O
the	O
cost	O
function	O
but	O
instead	O
merely	O
reduce	O
its	O
value	O
significantly	O
as	O
shown	O
in	O
figure	O
because	O
we	O
do	O
not	O
expect	O
training	O
to	O
actually	O
reach	O
a	O
point	O
where	O
the	O
gradient	B
is	O
it	O
is	O
acceptable	O
for	O
the	O
minima	O
of	O
the	O
cost	O
function	O
to	O
correspond	O
to	O
points	O
with	O
undefined	O
gradient	B
hidden	O
units	O
that	O
are	O
not	O
differentiable	O
are	O
usually	O
non-differentiable	O
at	O
only	O
a	O
small	O
number	O
of	O
points	O
in	O
general	O
a	O
function	O
gz	O
has	O
a	O
left	O
derivative	B
defined	O
by	O
the	O
slope	O
of	O
the	O
function	O
immediately	O
to	O
the	O
left	O
of	O
z	O
and	O
a	O
right	O
derivative	B
defined	O
by	O
the	O
slope	O
of	O
the	O
function	O
immediately	O
to	O
the	O
right	O
of	O
z	O
a	O
function	O
is	O
differentiable	O
at	O
z	O
only	O
if	O
both	O
the	O
left	O
derivative	B
and	O
the	O
right	O
derivative	B
are	O
defined	O
and	O
equal	O
to	O
each	O
other	O
the	O
functions	O
used	O
in	O
the	O
context	O
of	O
neural	O
networks	O
usually	O
have	O
defined	O
left	O
derivatives	O
and	O
defined	O
right	O
derivatives	O
in	O
the	O
case	O
of	O
gz	O
max	O
and	O
the	O
right	O
derivative	B
is	O
software	O
implementations	O
of	O
neural	B
network	I
training	O
usually	O
return	O
one	O
of	O
the	O
one-sided	O
derivatives	O
rather	O
than	O
reporting	O
that	O
the	O
derivative	B
is	O
undefined	O
or	O
raising	O
an	O
error	O
this	O
may	O
be	O
heuristically	O
justified	O
by	O
observing	O
that	O
gradientbased	O
optimization	O
on	O
a	O
digital	O
computer	O
is	O
subject	O
to	O
numerical	O
error	O
anyway	O
when	O
a	O
function	O
is	O
asked	O
to	O
evaluate	O
it	O
is	O
very	O
unlikely	O
that	O
the	O
underlying	O
that	O
was	O
rounded	O
value	O
truly	O
was	O
to	O
in	O
some	O
contexts	O
more	O
theoretically	O
pleasing	O
justifications	O
are	O
available	O
but	O
these	O
usually	O
do	O
not	O
apply	O
to	O
neural	B
network	I
training	O
the	O
important	O
point	O
is	O
that	O
in	O
practice	O
one	O
can	O
safely	O
disregard	O
the	O
non-differentiability	O
of	O
the	O
hidden	O
unit	O
activation	O
functions	O
described	O
below	O
instead	O
it	O
was	O
likely	O
to	O
be	O
some	O
small	O
value	O
z	O
the	O
left	O
derivative	B
at	O
z	O
unless	O
indicated	O
otherwise	O
most	O
hidden	O
units	O
can	O
be	O
described	O
as	O
accepting	O
a	O
vector	O
of	O
inputs	O
x	O
computing	O
an	O
affine	B
transformation	O
z	O
w	O
x	O
b	O
and	O
then	O
applying	O
an	O
element-wise	O
nonlinear	O
function	O
gz	O
most	O
hidden	O
units	O
are	O
distinguished	O
from	O
each	O
other	O
only	O
by	O
the	O
choice	O
of	O
the	O
form	O
of	O
the	O
activation	B
function	I
g	O
chapter	O
deep	O
feedforward	O
networks	O
max	O
g	O
z	O
z	O
rectified	O
linear	O
units	O
and	O
their	O
generalizations	O
rectified	O
linear	O
units	O
use	O
the	O
activation	B
function	I
rectified	O
linear	O
units	O
are	O
easy	O
to	O
optimize	O
because	O
they	O
are	O
so	O
similar	O
to	O
linear	O
units	O
the	O
only	O
difference	O
between	O
a	O
linear	O
unit	O
and	O
a	O
rectified	O
linear	O
unit	O
is	O
that	O
a	O
rectified	O
linear	O
unit	O
outputs	O
zero	O
across	O
half	O
its	O
domain	O
this	O
makes	O
the	O
derivatives	O
through	O
a	O
rectified	O
linear	O
unit	O
remain	O
large	O
whenever	O
the	O
unit	O
is	O
active	O
the	O
gradients	O
are	O
not	O
only	O
large	O
but	O
also	O
consistent	O
the	O
second	B
derivative	B
of	O
the	O
rectifying	O
operation	B
is	O
almost	B
everywhere	I
and	O
the	O
derivative	B
of	O
the	O
rectifying	O
operation	B
is	O
everywhere	O
that	O
the	O
unit	O
is	O
active	O
this	O
means	O
that	O
the	O
gradient	B
direction	O
is	O
far	O
more	O
useful	O
for	O
learning	O
than	O
it	O
would	O
be	O
with	O
activation	O
functions	O
that	O
introduce	O
second-order	O
effects	O
rectified	O
linear	O
units	O
are	O
typically	O
used	O
on	O
top	O
of	O
an	O
affine	B
transformation	O
h	O
w	O
x	O
b	O
when	O
initializing	O
the	O
parameters	O
of	O
the	O
affine	B
transformation	O
it	O
can	O
be	O
a	O
good	O
practice	O
to	O
set	O
all	O
elements	O
of	O
b	O
to	O
a	O
small	O
positive	O
value	O
such	O
as	O
this	O
makes	O
it	O
very	O
likely	O
that	O
the	O
rectified	O
linear	O
units	O
will	O
be	O
initially	O
active	O
for	O
most	O
inputs	O
in	O
the	O
training	O
set	O
and	O
allow	O
the	O
derivatives	O
to	O
pass	O
through	O
several	O
generalizations	O
of	O
rectified	O
linear	O
units	O
exist	O
most	O
of	O
these	O
generalizations	O
perform	O
comparably	O
to	O
rectified	O
linear	O
units	O
and	O
occasionally	O
perform	O
better	O
one	O
drawback	O
to	O
rectified	O
linear	O
units	O
is	O
that	O
they	O
cannot	O
learn	O
via	O
gradientbased	O
methods	O
on	O
examples	O
for	O
which	O
their	O
activation	O
is	O
zero	O
a	O
variety	O
of	O
generalizations	O
of	O
rectified	O
linear	O
units	O
guarantee	O
that	O
they	O
receive	O
gradient	B
everywhere	O
three	O
generalizations	O
of	O
rectified	O
linear	O
units	O
are	O
based	O
on	O
using	O
a	O
non-zero	O
zi	O
i	O
zi	O
absolute	O
value	O
slope	O
i	O
when	O
zi	O
hi	O
gz	O
z	O
it	O
is	O
used	O
for	O
object	B
recognition	I
rectification	O
fixes	O
i	O
from	O
images	O
where	O
it	O
makes	O
sense	O
to	O
seek	O
features	O
that	O
are	O
invariant	O
under	O
a	O
polarity	O
reversal	O
of	O
the	O
input	O
illumination	O
other	O
generalizations	O
of	O
rectified	O
linear	O
units	O
are	O
more	O
broadly	O
applicable	O
a	O
leaky	B
relu	I
maas	O
et	O
al	O
fixes	O
i	O
to	O
a	O
small	O
value	O
like	O
while	O
a	O
parametric	B
relu	I
or	O
prelu	O
treats	O
i	O
as	O
a	O
learnable	O
parameter	O
to	O
obtain	O
g	O
z	O
jarrett	O
et	O
al	O
he	O
et	O
al	O
maxout	O
units	O
generalize	O
rectified	O
linear	O
units	O
further	O
instead	O
of	O
applying	O
an	O
element-wise	O
function	O
gz	O
maxout	O
units	O
divide	O
z	O
into	O
groups	O
of	O
k	O
values	O
each	O
maxout	O
unit	O
then	O
outputs	O
the	O
maximum	O
element	O
of	O
goodfellow	O
et	O
al	O
chapter	O
deep	O
feedforward	O
networks	O
one	O
of	O
these	O
groups	O
g	O
i	O
max	O
where	O
g	O
this	O
provides	O
a	O
way	O
of	O
learning	O
a	O
piecewise	O
linear	O
function	O
that	O
responds	O
to	O
multiple	O
directions	O
in	O
the	O
input	O
is	O
the	O
set	O
of	O
indices	O
into	O
the	O
inputs	O
for	O
group	O
i	O
ik	O
space	O
zj	O
j	O
g	O
x	O
a	O
maxout	O
unit	O
can	O
learn	O
a	O
piecewise	O
linear	O
convex	O
function	O
with	O
up	O
to	O
k	O
pieces	O
maxout	O
units	O
can	O
thus	O
be	O
seen	O
as	O
learning	O
the	O
activation	B
function	I
itself	O
rather	O
than	O
just	O
the	O
relationship	O
between	O
units	O
with	O
large	O
enough	O
k	O
a	O
maxout	O
unit	O
can	O
learn	O
to	O
approximate	O
any	O
convex	O
function	O
with	O
arbitrary	O
fidelity	O
in	O
particular	O
a	O
maxout	O
layer	O
with	O
two	O
pieces	O
can	O
learn	O
to	O
implement	O
the	O
same	O
function	O
of	O
the	O
input	O
x	O
as	O
a	O
traditional	O
layer	O
using	O
the	O
rectified	O
linear	O
activation	B
function	I
absolute	B
value	I
rectification	I
function	O
or	O
the	O
leaky	O
or	O
parametric	B
relu	I
or	O
can	O
learn	O
to	O
implement	O
a	O
totally	O
different	O
function	O
altogether	O
the	O
maxout	O
layer	O
will	O
of	O
course	O
be	O
parametrized	O
differently	O
from	O
any	O
of	O
these	O
other	O
layer	O
types	O
so	O
the	O
learning	O
dynamics	O
will	O
be	O
different	O
even	O
in	O
the	O
cases	O
where	O
maxout	O
learns	O
to	O
implement	O
the	O
same	O
function	O
of	O
as	O
one	O
of	O
the	O
other	O
layer	O
types	O
x	O
each	O
maxout	O
unit	O
is	O
now	O
parametrized	O
by	O
k	O
weight	O
vectors	O
instead	O
of	O
just	O
one	O
so	O
maxout	O
units	O
typically	O
need	O
more	O
regularization	O
than	O
rectified	O
linear	O
units	O
they	O
can	O
work	O
well	O
without	O
regularization	O
if	O
the	O
training	O
set	O
is	O
large	O
and	O
the	O
number	O
of	O
pieces	O
per	O
unit	O
is	O
kept	O
low	O
cai	O
et	O
al	O
maxout	O
units	O
have	O
a	O
few	O
other	O
benefits	O
in	O
some	O
cases	O
one	O
can	O
gain	O
some	O
statistical	O
and	O
computational	O
advantages	O
by	O
requiring	O
fewer	O
parameters	O
specifically	O
if	O
the	O
features	O
captured	O
by	O
n	O
different	O
linear	O
filters	O
can	O
be	O
summarized	O
without	O
losing	O
information	O
by	O
taking	O
the	O
max	O
over	O
each	O
group	O
of	O
k	O
features	O
then	O
the	O
next	O
layer	O
can	O
get	O
by	O
with	O
times	O
fewer	O
weights	B
k	O
because	O
each	O
unit	O
is	O
driven	O
by	O
multiple	O
filters	O
maxout	O
units	O
have	O
some	O
redundancy	O
that	O
helps	O
them	O
to	O
resist	O
a	O
phenomenon	O
called	O
catastrophic	O
forgetting	O
in	O
which	O
neural	O
networks	O
forget	O
how	O
to	O
perform	O
tasks	O
that	O
they	O
were	O
trained	O
on	O
in	O
the	O
past	O
goodfellow	O
et	O
al	O
rectified	O
linear	O
units	O
and	O
all	O
of	O
these	O
generalizations	O
of	O
them	O
are	O
based	O
on	O
the	O
principle	O
that	O
models	O
are	O
easier	O
to	O
optimize	O
if	O
their	O
behavior	O
is	O
closer	O
to	O
linear	O
this	O
same	O
general	O
principle	O
of	O
using	O
linear	O
behavior	O
to	O
obtain	O
easier	O
optimization	O
also	O
applies	O
in	O
other	O
contexts	O
besides	O
deep	O
linear	O
networks	O
recurrent	O
networks	O
can	O
learn	O
from	O
sequences	O
and	O
produce	O
a	O
sequence	O
of	O
states	O
and	O
outputs	O
when	O
training	O
them	O
one	O
needs	O
to	O
propagate	O
information	O
through	O
several	O
time	O
steps	O
which	O
is	O
much	O
easier	O
when	O
some	O
linear	O
computations	O
some	O
directional	O
derivatives	O
being	O
of	O
magnitude	O
near	O
are	O
involved	O
one	O
of	O
the	O
best-performing	O
recurrent	B
network	I
chapter	O
deep	O
feedforward	O
networks	O
architectures	O
the	O
lstm	O
propagates	O
information	O
through	O
time	O
via	O
summation	O
a	O
particular	O
straightforward	O
kind	O
of	O
such	O
linear	O
activation	O
this	O
is	O
discussed	O
further	O
in	O
section	O
logistic	O
sigmoid	O
and	O
hyperbolic	O
tangent	O
prior	O
to	O
the	O
introduction	O
of	O
rectified	O
linear	O
units	O
most	O
neural	O
networks	O
used	O
the	O
logistic	O
sigmoid	O
activation	B
function	I
g	O
z	O
z	O
or	O
the	O
hyperbolic	O
tangent	O
activation	B
function	I
g	O
z	O
tanh	O
z	O
these	O
activation	O
functions	O
are	O
closely	O
related	O
because	O
tanh	O
z	O
z	O
we	O
have	O
already	O
seen	O
sigmoid	O
units	O
as	O
output	O
units	O
used	O
to	O
predict	O
the	O
probability	O
that	O
a	O
binary	O
variable	O
is	O
unlike	O
piecewise	O
linear	O
units	O
sigmoidal	O
units	O
saturate	O
across	O
most	O
of	O
their	O
domain	O
they	O
saturate	O
to	O
a	O
high	O
value	O
when	O
z	O
is	O
very	O
positive	O
saturate	O
to	O
a	O
low	O
value	O
when	O
z	O
is	O
very	O
negative	O
and	O
are	O
only	O
strongly	O
sensitive	O
to	O
their	O
input	O
when	O
z	O
is	O
near	O
the	O
widespread	O
saturation	O
of	O
sigmoidal	O
units	O
can	O
make	O
gradient-based	O
learning	O
very	O
difficult	O
for	O
this	O
reason	O
their	O
use	O
as	O
hidden	O
units	O
in	O
feedforward	O
networks	O
is	O
now	O
discouraged	O
their	O
use	O
as	O
output	O
units	O
is	O
compatible	O
with	O
the	O
use	O
of	O
gradient-based	O
learning	O
when	O
an	O
appropriate	O
cost	O
function	O
can	O
undo	O
the	O
saturation	O
of	O
the	O
sigmoid	O
in	O
the	O
output	O
layer	O
when	O
a	O
sigmoidal	O
activation	B
function	I
must	O
be	O
used	O
the	O
hyperbolic	O
tangent	O
activation	B
function	I
typically	O
performs	O
better	O
than	O
the	O
logistic	O
sigmoid	O
it	O
resembles	O
the	O
identity	O
function	O
more	O
closely	O
in	O
the	O
sense	O
that	O
while	O
because	O
tanh	O
is	O
similar	O
to	O
the	O
identity	O
function	O
near	O
training	O
a	O
deep	O
neural	B
network	I
y	O
w	O
x	O
resembles	O
training	O
a	O
linear	O
model	O
y	O
w	O
x	O
so	O
long	O
as	O
the	O
activations	O
of	O
the	O
network	O
can	O
be	O
kept	O
small	O
this	O
makes	O
training	O
the	O
network	O
easier	O
tanhu	O
tanhv	O
tanh	O
u	O
v	O
sigmoidal	O
activation	O
functions	O
are	O
more	O
common	O
in	O
settings	O
other	O
than	O
feedforward	O
networks	O
recurrent	O
networks	O
many	O
probabilistic	O
models	O
and	O
some	O
autoencoders	O
have	O
additional	O
requirements	O
that	O
rule	O
out	O
the	O
use	O
of	O
piecewise	O
linear	O
activation	O
functions	O
and	O
make	O
sigmoidal	O
units	O
more	O
appealing	O
despite	O
the	O
drawbacks	O
of	O
saturation	O
chapter	O
deep	O
feedforward	O
networks	O
other	O
hidden	O
units	O
many	O
other	O
types	O
of	O
hidden	O
units	O
are	O
possible	O
but	O
are	O
used	O
less	O
frequently	O
in	O
general	O
a	O
wide	O
variety	O
of	O
differentiable	O
functions	O
perform	O
perfectly	O
well	O
many	O
unpublished	O
activation	O
functions	O
perform	O
just	O
as	O
well	O
as	O
the	O
popular	O
ones	O
to	O
provide	O
a	O
concrete	O
example	B
the	O
authors	O
tested	O
a	O
feedforward	O
network	O
using	O
h	O
cosw	O
x	O
b	O
on	O
the	O
mnist	O
dataset	B
and	O
obtained	O
an	O
error	O
rate	O
of	O
less	O
than	O
which	O
is	O
competitive	O
with	O
results	O
obtained	O
using	O
more	O
conventional	O
activation	O
functions	O
during	O
research	O
and	O
development	O
of	O
new	O
techniques	O
it	O
is	O
common	O
to	O
test	O
many	O
different	O
activation	O
functions	O
and	O
find	O
that	O
several	O
variations	O
on	O
standard	O
practice	O
perform	O
comparably	O
this	O
means	O
that	O
usually	O
new	O
hidden	O
unit	O
types	O
are	O
published	O
only	O
if	O
they	O
are	O
clearly	O
demonstrated	O
to	O
provide	O
a	O
significant	O
improvement	O
new	O
hidden	O
unit	O
types	O
that	O
perform	O
roughly	O
comparably	O
to	O
known	O
types	O
are	O
so	O
common	O
as	O
to	O
be	O
uninteresting	O
it	O
would	O
be	O
impractical	O
to	O
list	O
all	O
of	O
the	O
hidden	O
unit	O
types	O
that	O
have	O
appeared	O
in	O
the	O
literature	O
we	O
highlight	O
a	O
few	O
especially	O
useful	O
and	O
distinctive	O
ones	O
one	O
possibility	O
is	O
to	O
not	O
have	O
an	O
activation	O
g	O
at	O
all	O
one	O
can	O
also	O
think	O
of	O
this	O
as	O
using	O
the	O
identity	O
function	O
as	O
the	O
activation	B
function	I
we	O
have	O
already	O
seen	O
that	O
a	O
linear	O
unit	O
can	O
be	O
useful	O
as	O
the	O
output	O
of	O
a	O
neural	B
network	I
it	O
may	O
also	O
be	O
used	O
as	O
a	O
hidden	O
unit	O
if	O
every	O
layer	O
of	O
the	O
neural	B
network	I
consists	O
of	O
only	O
linear	O
transformations	O
then	O
the	O
network	O
as	O
a	O
whole	O
will	O
be	O
linear	O
however	O
it	O
is	O
acceptable	O
for	O
some	O
layers	O
of	O
the	O
neural	B
network	I
to	O
be	O
purely	O
linear	O
consider	O
a	O
neural	B
network	I
layer	O
with	O
n	O
inputs	O
and	O
p	O
outputs	O
h	O
gw	O
x	O
b	O
we	O
may	O
replace	O
this	O
with	O
two	O
layers	O
with	O
one	O
layer	O
using	O
weight	O
matrix	O
u	O
and	O
the	O
other	O
using	O
weight	O
matrix	O
v	O
if	O
the	O
first	O
layer	O
has	O
no	O
activation	B
function	I
then	O
we	O
have	O
essentially	O
factored	O
the	O
weight	O
matrix	O
of	O
the	O
original	O
layer	O
based	O
on	O
w	O
the	O
factored	O
approach	O
is	O
to	O
compute	O
h	O
g	O
v	O
x	O
b	O
if	O
u	O
produces	O
q	O
outputs	O
then	O
u	O
and	O
v	O
together	O
contain	O
only	O
pq	O
parameters	O
while	O
w	O
contains	O
np	O
parameters	O
for	O
small	O
q	O
this	O
can	O
be	O
a	O
considerable	O
saving	O
in	O
parameters	O
it	O
comes	O
at	O
the	O
cost	O
of	O
constraining	O
the	O
linear	O
transformation	O
to	O
be	O
low-rank	O
but	O
these	O
low-rank	O
relationships	O
are	O
often	O
sufficient	O
linear	O
hidden	O
units	O
thus	O
offer	O
an	O
effective	O
way	O
of	O
reducing	O
the	O
number	O
of	O
parameters	O
in	O
a	O
network	O
u	O
softmax	O
units	O
are	O
another	O
kind	O
of	O
unit	O
that	O
is	O
usually	O
used	O
as	O
an	O
output	O
described	O
in	O
section	O
but	O
may	O
sometimes	O
be	O
used	O
as	O
a	O
hidden	O
unit	O
softmax	O
units	O
naturally	O
represent	O
a	O
probability	B
distribution	I
over	O
a	O
discrete	O
variable	O
with	O
k	O
possible	O
values	O
so	O
they	O
may	O
be	O
used	O
as	O
a	O
kind	O
of	O
switch	O
these	O
kinds	O
of	O
hidden	O
units	O
are	O
usually	O
only	O
used	O
in	O
more	O
advanced	O
architectures	O
that	O
explicitly	O
learn	O
to	O
manipulate	O
memory	O
described	O
in	O
section	O
chapter	O
deep	O
feedforward	O
networks	O
a	O
few	O
other	O
reasonably	O
common	O
hidden	O
unit	O
types	O
include	O
wi	O
radial	B
basis	I
function	I
or	O
rbf	B
unit	O
hi	O
exp	O
this	O
function	O
becomes	O
more	O
active	O
as	O
x	O
approaches	O
a	O
template	O
wi	O
because	O
it	O
saturates	O
to	O
it	O
can	O
be	O
difficult	O
to	O
optimize	O
x	O
for	O
most	O
i	O
x	O
dugas	O
et	O
al	O
glorot	O
et	O
al	O
for	O
function	O
approximation	O
and	O
by	O
softplus	O
ga	O
ea	O
this	O
is	O
a	O
smooth	O
version	O
of	O
the	O
rectifier	O
introduced	O
by	O
nair	O
for	O
the	O
conditional	O
distributions	O
of	O
undirected	O
probabilistic	O
and	O
hinton	O
models	O
compared	O
the	O
softplus	O
and	O
rectifier	O
and	O
found	O
better	O
results	O
with	O
the	O
latter	O
the	O
use	O
of	O
the	O
softplus	O
is	O
generally	O
discouraged	O
the	O
softplus	O
demonstrates	O
that	O
the	O
performance	O
of	O
hidden	O
unit	O
types	O
can	O
be	O
very	O
counterintuitive	O
one	O
might	O
expect	O
it	O
to	O
have	O
an	O
advantage	O
over	O
the	O
rectifier	O
due	O
to	O
being	O
differentiable	O
everywhere	O
or	O
due	O
to	O
saturating	O
less	O
completely	O
but	O
empirically	O
it	O
does	O
not	O
hard	O
tanh	O
this	O
is	O
shaped	O
similarly	O
to	O
the	O
tanh	O
and	O
the	O
rectifier	O
but	O
unlike	O
the	O
latter	O
it	O
is	O
bounded	O
ga	O
max	O
it	O
was	O
introduced	O
by	O
collobert	O
a	O
hidden	O
unit	O
design	O
remains	O
an	O
active	O
area	O
of	O
research	O
and	O
many	O
useful	O
hidden	O
unit	O
types	O
remain	O
to	O
be	O
discovered	O
architecture	O
design	O
another	O
key	O
design	O
consideration	O
for	O
neural	O
networks	O
is	O
determining	O
the	O
architecture	O
the	O
word	O
architecture	O
refers	O
to	O
the	O
overall	O
structure	O
of	O
the	O
network	O
how	O
many	O
units	O
it	O
should	O
have	O
and	O
how	O
these	O
units	O
should	O
be	O
connected	O
to	O
each	O
other	O
most	O
neural	O
networks	O
are	O
organized	O
into	O
groups	O
of	O
units	O
called	O
layers	O
most	O
neural	B
network	I
architectures	O
arrange	O
these	O
layers	O
in	O
a	O
chain	O
structure	O
with	O
each	O
layer	O
being	O
a	O
function	O
of	O
the	O
layer	O
that	O
preceded	O
it	O
in	O
this	O
structure	O
the	O
first	O
layer	O
is	O
given	O
by	O
w	O
x	O
b	O
the	O
second	O
layer	O
is	O
given	O
by	O
h	O
w	O
and	O
so	O
on	O
chapter	O
deep	O
feedforward	O
networks	O
in	O
these	O
chain-based	O
architectures	O
the	O
main	O
architectural	O
considerations	O
are	O
to	O
choose	O
the	O
depth	O
of	O
the	O
network	O
and	O
the	O
width	O
of	O
each	O
layer	O
as	O
we	O
will	O
see	O
a	O
network	O
with	O
even	O
one	O
hidden	B
layer	I
is	O
sufficient	O
to	O
fit	O
the	O
training	O
set	O
deeper	O
networks	O
often	O
are	O
able	O
to	O
use	O
far	O
fewer	O
units	O
per	O
layer	O
and	O
far	O
fewer	O
parameters	O
and	O
often	O
generalize	O
to	O
the	O
test	B
set	I
but	O
are	O
also	O
often	O
harder	O
to	O
optimize	O
the	O
ideal	O
network	O
architecture	O
for	O
a	O
task	O
must	O
be	O
found	O
via	O
experimentation	O
guided	O
by	O
monitoring	O
the	O
validation	O
set	O
error	O
universal	O
approximation	O
properties	O
and	O
depth	O
a	O
linear	O
model	O
mapping	O
from	O
features	O
to	O
outputs	O
via	O
matrix	O
multiplication	O
can	O
by	O
definition	O
represent	O
only	O
linear	O
functions	O
it	O
has	O
the	O
advantage	O
of	O
being	O
easy	O
to	O
train	O
because	O
many	O
loss	O
functions	O
result	O
in	O
convex	B
optimization	I
problems	O
when	O
applied	O
to	O
linear	O
models	O
unfortunately	O
we	O
often	O
want	O
to	O
learn	O
nonlinear	O
functions	O
cybenko	O
at	O
first	O
glance	O
we	O
might	O
presume	O
that	O
learning	O
a	O
nonlinear	O
function	O
requires	O
designing	O
a	O
specialized	O
model	O
family	O
for	O
the	O
kind	O
of	O
nonlinearity	O
we	O
want	O
to	O
learn	O
fortunately	O
feedforward	O
networks	O
with	O
hidden	O
layers	O
provide	O
a	O
universal	O
approximation	O
framework	O
specifically	O
the	O
universal	B
approximation	I
theorem	I
et	O
al	O
states	O
that	O
a	O
feedforward	O
network	O
with	O
a	O
linear	O
output	O
layer	O
and	O
at	O
least	O
one	O
hidden	B
layer	I
with	O
any	O
squashing	O
activation	B
function	I
as	O
the	O
logistic	O
sigmoid	O
activation	B
function	I
can	O
approximate	O
any	O
borel	O
measurable	O
function	O
from	O
one	O
finite-dimensional	O
space	O
to	O
another	O
with	O
any	O
desired	O
non-zero	O
amount	O
of	O
error	O
provided	O
that	O
the	O
network	O
is	O
given	O
enough	O
hidden	O
units	O
the	O
derivatives	O
of	O
the	O
feedforward	O
network	O
can	O
also	O
approximate	O
the	O
derivatives	O
of	O
the	O
function	O
arbitrarily	O
well	O
the	O
concept	O
of	O
borel	O
measurability	O
is	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
for	O
our	O
purposes	O
it	O
suffices	O
to	O
say	O
that	O
any	O
continuous	O
function	O
on	O
a	O
closed	O
and	O
bounded	O
subset	O
of	O
r	O
n	O
is	O
borel	O
measurable	O
and	O
therefore	O
may	O
be	O
approximated	O
by	O
a	O
neural	B
network	I
a	O
neural	B
network	I
may	O
also	O
approximate	O
any	O
function	O
mapping	O
from	O
any	O
finite	O
dimensional	O
discrete	O
space	O
to	O
another	O
while	O
the	O
original	O
theorems	O
were	O
first	O
stated	O
in	O
terms	O
of	O
units	O
with	O
activation	O
functions	O
that	O
saturate	O
both	O
for	O
very	O
negative	O
and	O
for	O
very	O
positive	O
arguments	O
universal	O
approximation	O
theorems	O
have	O
also	O
been	O
proved	O
for	O
a	O
wider	O
class	O
of	O
activation	O
functions	O
which	O
includes	O
the	O
now	O
commonly	O
used	O
rectified	O
linear	O
unit	O
hornik	O
et	O
al	O
leshno	O
et	O
al	O
the	O
universal	B
approximation	I
theorem	I
means	O
that	O
regardless	O
of	O
what	O
function	O
we	O
are	O
trying	O
to	O
learn	O
we	O
know	O
that	O
a	O
large	O
mlp	O
will	O
be	O
able	O
to	O
represent	O
this	O
function	O
however	O
we	O
are	O
not	O
guaranteed	O
that	O
the	O
training	O
algorithm	O
will	O
be	O
able	O
to	O
learn	O
that	O
function	O
even	O
if	O
the	O
mlp	O
is	O
able	O
to	O
represent	O
the	O
function	O
learning	O
can	O
fail	O
for	O
two	O
different	O
reasons	O
first	O
the	O
optimization	O
algorithm	O
used	O
for	O
training	O
chapter	O
deep	O
feedforward	O
networks	O
may	O
not	O
be	O
able	O
to	O
find	O
the	O
value	O
of	O
the	O
parameters	O
that	O
corresponds	O
to	O
the	O
desired	O
function	O
second	O
the	O
training	O
algorithm	O
might	O
choose	O
the	O
wrong	O
function	O
due	O
to	O
overfitting	O
recall	B
from	O
section	O
that	O
the	O
no	B
free	I
lunch	I
theorem	I
shows	O
that	O
there	O
is	O
no	O
universally	O
superior	O
machine	B
learning	I
algorithm	O
feedforward	O
networks	O
provide	O
a	O
universal	O
system	O
for	O
representing	O
functions	O
in	O
the	O
sense	O
that	O
given	O
a	O
function	O
there	O
exists	O
a	O
feedforward	O
network	O
that	O
approximates	O
the	O
function	O
there	O
is	O
no	O
universal	O
procedure	O
for	O
examining	O
a	O
training	O
set	O
of	O
specific	O
examples	O
and	O
choosing	O
a	O
function	O
that	O
will	O
generalize	O
to	O
points	O
not	O
in	O
the	O
training	O
set	O
barron	O
the	O
universal	B
approximation	I
theorem	I
says	O
that	O
there	O
exists	O
a	O
network	O
large	O
enough	O
to	O
achieve	O
any	O
degree	O
of	O
accuracy	B
we	O
desire	O
but	O
the	O
theorem	O
does	O
not	O
say	O
how	O
large	O
this	O
network	O
will	O
be	O
provides	O
some	O
bounds	O
on	O
the	O
size	O
of	O
a	O
single-layer	O
network	O
needed	O
to	O
approximate	O
a	O
broad	O
class	O
of	O
functions	O
unfortunately	O
in	O
the	O
worse	O
case	O
an	O
exponential	O
number	O
of	O
hidden	O
units	O
with	O
one	O
hidden	O
unit	O
corresponding	O
to	O
each	O
input	O
configuration	O
that	O
needs	O
to	O
be	O
distinguished	O
may	O
be	O
required	O
this	O
is	O
easiest	O
to	O
see	O
in	O
the	O
binary	O
case	O
the	O
n	O
is	O
n	O
and	O
selecting	O
number	O
of	O
possible	O
binary	O
functions	O
on	O
vectors	O
v	O
one	O
such	O
function	O
requires	O
bits	O
which	O
will	O
in	O
general	O
require	O
n	O
degrees	O
of	O
freedom	O
in	O
summary	O
a	O
feedforward	O
network	O
with	O
a	O
single	O
layer	O
is	O
sufficient	O
to	O
represent	O
any	O
function	O
but	O
the	O
layer	O
may	O
be	O
infeasibly	O
large	O
and	O
may	O
fail	O
to	O
learn	O
and	O
generalize	O
correctly	O
in	O
many	O
circumstances	O
using	O
deeper	O
models	O
can	O
reduce	O
the	O
number	O
of	O
units	O
required	O
to	O
represent	O
the	O
desired	O
function	O
and	O
can	O
reduce	O
the	O
amount	O
of	O
generalization	B
error	O
there	O
exist	O
families	O
of	O
functions	O
which	O
can	O
be	O
approximated	O
efficiently	O
by	O
an	O
architecture	O
with	O
depth	O
greater	O
than	O
some	O
value	O
d	O
but	O
which	O
require	O
a	O
much	O
larger	O
model	O
if	O
depth	O
is	O
restricted	O
to	O
be	O
less	O
than	O
or	O
equal	O
to	O
d	O
in	O
many	O
cases	O
the	O
number	O
of	O
hidden	O
units	O
required	O
by	O
the	O
shallow	O
model	O
is	O
exponential	O
in	O
n	O
such	O
results	O
were	O
first	O
proved	O
for	O
models	O
that	O
do	O
not	O
resemble	O
the	O
continuous	O
differentiable	O
neural	O
networks	O
used	O
for	O
machine	B
learning	I
but	O
have	O
since	O
been	O
extended	O
to	O
these	O
models	O
the	O
first	O
results	O
were	O
for	O
circuits	O
of	O
logic	O
gates	O
later	O
work	O
extended	O
these	O
results	O
to	O
linear	O
threshold	O
units	O
with	O
non-negative	O
weights	B
h	O
stad	O
and	O
goldmann	O
hajnal	O
et	O
al	O
and	O
then	O
to	O
networks	O
with	O
many	O
modern	O
continuous-valued	O
activations	O
neural	O
networks	O
use	O
rectified	O
linear	O
units	O
demonstrated	O
that	O
shallow	O
networks	O
with	O
a	O
broad	O
family	O
of	O
non-polynomial	O
activation	O
functions	O
including	O
rectified	O
linear	O
units	O
have	O
universal	O
approximation	O
properties	O
but	O
these	O
results	O
do	O
not	O
address	O
the	O
questions	O
of	O
depth	O
or	O
efficiency	O
they	O
specify	O
only	O
that	O
a	O
sufficiently	O
wide	O
rectifier	O
network	O
could	O
represent	O
any	O
function	O
montufar	O
et	O
al	O
maass	O
maass	O
et	O
al	O
leshno	O
et	O
al	O
h	O
stad	O
chapter	O
deep	O
feedforward	O
networks	O
showed	O
that	O
functions	O
representable	O
with	O
a	O
deep	O
rectifier	O
net	O
can	O
require	O
an	O
exponential	O
number	O
of	O
hidden	O
units	O
with	O
a	O
shallow	O
hidden	B
layer	I
network	O
more	O
precisely	O
they	O
showed	O
that	O
piecewise	O
linear	O
networks	O
can	O
be	O
obtained	O
from	O
rectifier	O
nonlinearities	O
or	O
maxout	O
units	O
can	O
represent	O
functions	O
with	O
a	O
number	O
of	O
regions	O
that	O
is	O
exponential	O
in	O
the	O
depth	O
of	O
the	O
network	O
figure	O
illustrates	O
how	O
a	O
network	O
with	O
absolute	B
value	I
rectification	I
creates	O
mirror	O
images	O
of	O
the	O
function	O
computed	O
on	O
top	O
of	O
some	O
hidden	O
unit	O
with	O
respect	O
to	O
the	O
input	O
of	O
that	O
hidden	O
unit	O
each	O
hidden	O
unit	O
specifies	O
where	O
to	O
fold	O
the	O
input	O
space	O
in	O
order	O
to	O
create	O
mirror	O
responses	O
both	O
sides	O
of	O
the	O
absolute	O
value	O
nonlinearity	O
by	O
composing	O
these	O
folding	O
operations	O
we	O
obtain	O
an	O
exponentially	O
large	O
number	O
of	O
piecewise	O
linear	O
regions	O
which	O
can	O
capture	O
all	O
kinds	O
of	O
regular	O
repeating	O
patterns	O
montufar	O
et	O
al	O
figure	O
an	O
intuitive	O
geometric	O
explanation	O
of	O
the	O
exponential	O
advantage	O
of	O
deeper	O
rectifier	O
networks	O
formally	O
by	O
absolute	B
value	I
rectification	I
unit	O
has	O
the	O
same	O
output	O
for	O
every	O
pair	O
of	O
mirror	O
points	O
in	O
its	O
input	O
the	O
mirror	O
axis	O
of	O
symmetry	O
is	O
given	O
by	O
the	O
hyperplane	O
defined	O
by	O
the	O
weights	B
and	O
bias	O
of	O
the	O
unit	O
a	O
function	O
computed	O
on	O
top	O
of	O
that	O
unit	O
green	O
decision	O
surface	O
will	O
be	O
a	O
mirror	O
image	O
the	O
function	O
can	O
be	O
obtained	O
of	O
a	O
simpler	O
pattern	O
across	O
that	O
axis	O
of	O
symmetry	O
by	O
folding	O
the	O
space	O
around	O
the	O
axis	O
of	O
symmetry	O
another	O
repeating	O
pattern	O
can	O
be	O
folded	O
on	O
top	O
of	O
the	O
first	O
another	O
downstream	O
unit	O
to	O
obtain	O
another	O
symmetry	O
is	O
now	O
repeated	O
four	O
times	O
with	O
two	O
hidden	O
layers	O
figure	O
reproduced	O
with	O
permission	O
from	O
montufar	O
et	O
al	O
more	O
precisely	O
the	O
main	O
theorem	O
in	O
states	O
that	O
the	O
number	O
of	O
linear	O
regions	O
carved	O
out	O
by	O
a	O
deep	O
rectifier	O
network	O
with	O
d	O
inputs	O
depth	O
and	O
units	O
per	O
hidden	B
layer	I
is	O
montufar	O
et	O
al	O
n	O
l	O
o	O
i	O
e	O
exponential	O
in	O
the	O
depth	O
in	O
the	O
case	O
of	O
maxout	O
networks	O
with	O
unit	O
the	O
number	O
of	O
linear	O
regions	O
is	O
l	O
k	O
filters	O
per	O
d	O
l	O
nd	O
n	O
d	O
l	O
k	O
d	O
o	O
chapter	O
deep	O
feedforward	O
networks	O
of	O
course	O
there	O
is	O
no	O
guarantee	O
that	O
the	O
kinds	O
of	O
functions	O
we	O
want	O
to	O
learn	O
in	O
applications	O
of	O
machine	B
learning	I
in	O
particular	O
for	O
ai	O
share	O
such	O
a	O
property	O
we	O
may	O
also	O
want	O
to	O
choose	O
a	O
deep	O
model	O
for	O
statistical	O
reasons	O
any	O
time	O
we	O
choose	O
a	O
specific	O
machine	B
learning	I
algorithm	O
we	O
are	O
implicitly	O
stating	O
some	O
set	O
of	O
prior	O
beliefs	O
we	O
have	O
about	O
what	O
kind	O
of	O
function	O
the	O
algorithm	O
should	O
learn	O
choosing	O
a	O
deep	O
model	O
encodes	O
a	O
very	O
general	O
belief	O
that	O
the	O
function	O
we	O
want	O
to	O
learn	O
should	O
involve	O
composition	O
of	O
several	O
simpler	O
functions	O
this	O
can	O
be	O
interpreted	O
from	O
a	O
representation	B
learning	I
point	O
of	O
view	O
as	O
saying	O
that	O
we	O
believe	O
the	O
learning	O
problem	O
consists	O
of	O
discovering	O
a	O
set	O
of	O
underlying	O
factors	B
of	I
variation	I
that	O
can	O
in	O
turn	O
be	O
described	O
in	O
terms	O
of	O
other	O
simpler	O
underlying	O
factors	B
of	I
variation	I
alternately	O
we	O
can	O
interpret	O
the	O
use	O
of	O
a	O
deep	O
architecture	O
as	O
expressing	O
a	O
belief	O
that	O
the	O
function	O
we	O
want	O
to	O
learn	O
is	O
a	O
computer	O
program	O
consisting	O
of	O
multiple	O
steps	O
where	O
each	O
step	O
makes	O
use	O
of	O
the	O
previous	O
step	O
s	O
output	O
these	O
intermediate	O
outputs	O
are	O
not	O
necessarily	O
factors	B
of	I
variation	I
but	O
can	O
instead	O
be	O
analogous	O
to	O
counters	O
or	O
pointers	O
that	O
the	O
network	O
uses	O
to	O
organize	O
its	O
internal	O
processing	O
empirically	O
greater	O
depth	O
does	O
seem	O
to	O
result	O
in	O
better	O
generalization	B
for	O
a	O
wide	O
variety	O
of	O
tasks	O
bengio	O
et	O
al	O
erhan	O
et	O
al	O
bengio	O
ciresan	O
mesnil	O
et	O
al	O
et	O
al	O
et	O
al	O
couprie	O
farabet	O
et	O
al	O
goodfellow	O
et	O
al	O
szegedy	O
et	O
al	O
for	O
examples	O
of	O
some	O
of	O
these	O
empirical	O
results	O
this	O
suggests	O
that	O
using	O
deep	O
architectures	O
does	O
indeed	O
express	O
a	O
useful	O
prior	O
over	O
the	O
space	O
of	O
functions	O
the	O
model	O
learns	O
sermanet	O
krizhevsky	O
kahou	O
and	O
figure	O
see	O
figure	O
et	O
al	O
et	O
al	O
et	O
al	O
other	O
architectural	O
considerations	O
so	O
far	O
we	O
have	O
described	O
neural	O
networks	O
as	O
being	O
simple	O
chains	O
of	O
layers	O
with	O
the	O
main	O
considerations	O
being	O
the	O
depth	O
of	O
the	O
network	O
and	O
the	O
width	O
of	O
each	O
layer	O
in	O
practice	O
neural	O
networks	O
show	O
considerably	O
more	O
diversity	O
many	O
neural	B
network	I
architectures	O
have	O
been	O
developed	O
for	O
specific	O
tasks	O
specialized	O
architectures	O
for	O
computer	B
vision	I
called	O
convolutional	O
networks	O
are	O
feedforward	O
networks	O
may	O
also	O
be	O
generalized	O
to	O
the	O
described	O
in	O
chapter	O
recurrent	O
neural	O
networks	O
for	O
sequence	O
processing	O
described	O
in	O
chapter	O
which	O
have	O
their	O
own	O
architectural	O
considerations	O
in	O
general	O
the	O
layers	O
need	O
not	O
be	O
connected	O
in	O
a	O
chain	O
even	O
though	O
this	O
is	O
the	O
most	O
common	O
practice	O
many	O
architectures	O
build	O
a	O
main	O
chain	O
but	O
then	O
add	O
extra	O
architectural	O
features	O
to	O
it	O
such	O
as	O
skip	O
connections	O
going	O
from	O
layer	O
i	O
to	O
layer	O
i	O
or	O
higher	O
these	O
skip	O
connections	O
make	O
it	O
easier	O
for	O
the	O
gradient	B
to	O
flow	O
from	O
output	O
layers	O
to	O
layers	O
nearer	O
the	O
input	O
chapter	O
deep	O
feedforward	O
networks	O
t	O
n	O
e	O
c	O
r	O
e	O
p	O
y	O
c	O
a	O
r	O
u	O
c	O
c	O
a	O
t	O
s	O
e	O
t	O
number	O
of	O
hidden	O
layers	O
figure	O
empirical	O
results	O
showing	O
that	O
deeper	O
networks	O
generalize	O
better	O
when	O
used	O
to	O
transcribe	O
multi-digit	O
numbers	O
from	O
photographs	O
of	O
addresses	O
data	O
from	O
goodfellow	O
the	O
test	B
set	I
accuracy	B
consistently	O
increases	O
with	O
increasing	O
depth	O
see	O
et	O
al	O
figure	O
for	O
a	O
control	O
experiment	O
demonstrating	O
that	O
other	O
increases	O
to	O
the	O
model	O
size	O
do	O
not	O
yield	O
the	O
same	O
effect	O
another	O
key	O
consideration	O
of	O
architecture	O
design	O
is	O
exactly	O
how	O
to	O
connect	O
a	O
pair	O
of	O
layers	O
to	O
each	O
other	O
in	O
the	O
default	O
neural	B
network	I
layer	O
described	O
by	O
a	O
linear	O
transformation	O
via	O
a	O
matrix	O
w	O
every	O
input	O
unit	O
is	O
connected	O
to	O
every	O
output	O
unit	O
many	O
specialized	O
networks	O
in	O
the	O
chapters	O
ahead	O
have	O
fewer	O
connections	O
so	O
that	O
each	O
unit	O
in	O
the	O
input	O
layer	O
is	O
connected	O
to	O
only	O
a	O
small	O
subset	O
of	O
units	O
in	O
the	O
output	O
layer	O
these	O
strategies	O
for	O
reducing	O
the	O
number	O
of	O
connections	O
reduce	O
the	O
number	O
of	O
parameters	O
and	O
the	O
amount	O
of	O
computation	O
required	O
to	O
evaluate	O
the	O
network	O
but	O
are	O
often	O
highly	O
problem-dependent	O
for	O
example	B
convolutional	O
networks	O
described	O
in	O
chapter	O
use	O
specialized	O
patterns	O
of	O
sparse	O
connections	O
that	O
are	O
very	O
effective	O
for	O
computer	B
vision	I
problems	O
in	O
this	O
chapter	O
it	O
is	O
difficult	O
to	O
give	O
much	O
more	O
specific	O
advice	O
concerning	O
the	O
architecture	O
of	O
a	O
generic	O
neural	B
network	I
subsequent	O
chapters	O
develop	O
the	O
particular	O
architectural	O
strategies	O
that	O
have	O
been	O
found	O
to	O
work	O
well	O
for	O
different	O
application	O
domains	O
chapter	O
deep	O
feedforward	O
networks	O
t	O
n	O
e	O
c	O
r	O
e	O
p	O
y	O
c	O
a	O
r	O
u	O
c	O
c	O
a	O
t	O
s	O
e	O
t	O
number	O
of	O
parameters	O
convolutional	O
fully	O
connected	O
convolutional	O
et	O
al	O
figure	O
deeper	O
models	O
tend	O
to	O
perform	O
better	O
this	O
is	O
not	O
merely	O
because	O
the	O
model	O
is	O
larger	O
this	O
experiment	O
from	O
goodfellow	O
shows	O
that	O
increasing	O
the	O
number	O
of	O
parameters	O
in	O
layers	O
of	O
convolutional	O
networks	O
without	O
increasing	O
their	O
depth	O
is	O
not	O
nearly	O
as	O
effective	O
at	O
increasing	O
test	B
set	I
performance	O
the	O
legend	O
indicates	O
the	O
depth	O
of	O
network	O
used	O
to	O
make	O
each	O
curve	O
and	O
whether	O
the	O
curve	O
represents	O
variation	O
in	O
the	O
size	O
of	O
the	O
convolutional	O
or	O
the	O
fully	O
connected	O
layers	O
we	O
observe	O
that	O
shallow	O
models	O
in	O
this	O
context	O
overfit	O
at	O
around	O
million	O
parameters	O
while	O
deep	O
ones	O
can	O
benefit	O
from	O
having	O
over	O
million	O
this	O
suggests	O
that	O
using	O
a	O
deep	O
model	O
expresses	O
a	O
useful	O
preference	O
over	O
the	O
space	O
of	O
functions	O
the	O
model	O
can	O
learn	O
specifically	O
it	O
expresses	O
a	O
belief	O
that	O
the	O
function	O
should	O
consist	O
of	O
many	O
simpler	O
functions	O
composed	O
together	O
this	O
could	O
result	O
either	O
in	O
learning	O
a	O
representation	O
that	O
is	O
composed	O
in	O
turn	O
of	O
simpler	O
representations	O
corners	O
defined	O
in	O
terms	O
of	O
edges	O
or	O
in	O
learning	O
a	O
program	O
with	O
sequentially	O
dependent	O
steps	O
first	O
locate	O
a	O
set	O
of	O
objects	O
then	O
segment	O
them	O
from	O
each	O
other	O
then	O
recognize	O
them	O
chapter	O
deep	O
feedforward	O
networks	O
back-propagation	B
and	O
other	O
differentiation	O
algo	O
rithms	O
when	O
we	O
use	O
a	O
feedforward	B
neural	B
network	I
to	O
accept	O
an	O
input	O
x	O
and	O
produce	O
an	O
output	O
y	O
information	O
flows	O
forward	O
through	O
the	O
network	O
the	O
inputs	O
x	O
provide	O
the	O
initial	O
information	O
that	O
then	O
propagates	O
up	O
to	O
the	O
hidden	O
units	O
at	O
each	O
layer	O
and	O
finally	O
produces	O
y	O
this	O
is	O
called	O
forward	B
propagation	I
during	O
training	O
forward	B
propagation	I
can	O
continue	O
onward	O
until	O
it	O
produces	O
a	O
scalar	O
cost	O
j	O
the	O
back-propagation	B
algorithm	O
often	O
simply	O
called	O
backprop	O
allows	O
the	O
information	O
from	O
the	O
cost	O
to	O
then	O
flow	O
backwards	O
through	O
the	O
network	O
in	O
order	O
to	O
compute	O
the	O
gradient	B
rumelhart	O
et	O
al	O
computing	O
an	O
analytical	O
expression	O
for	O
the	O
gradient	B
is	O
straightforward	O
but	O
numerically	O
evaluating	O
such	O
an	O
expression	O
can	O
be	O
computationally	O
expensive	O
the	O
back-propagation	B
algorithm	O
does	O
so	O
using	O
a	O
simple	O
and	O
inexpensive	O
procedure	O
the	O
term	O
back-propagation	B
is	O
often	O
misunderstood	O
as	O
meaning	O
the	O
whole	O
learning	O
algorithm	O
for	O
multi-layer	O
neural	O
networks	O
actually	O
back-propagation	B
refers	O
only	O
to	O
the	O
method	O
for	O
computing	O
the	O
gradient	B
while	O
another	O
algorithm	O
such	O
as	O
stochastic	O
gradient	B
descent	O
is	O
used	O
to	O
perform	O
learning	O
using	O
this	O
gradient	B
furthermore	O
back-propagation	B
is	O
often	O
misunderstood	O
as	O
being	O
specific	O
to	O
multilayer	O
neural	O
networks	O
but	O
in	O
principle	O
it	O
can	O
compute	O
derivatives	O
of	O
any	O
function	O
some	O
functions	O
the	O
correct	O
response	O
is	O
to	O
report	O
that	O
the	O
derivative	B
of	O
the	O
function	O
is	O
undefined	O
specifically	O
we	O
will	O
describe	O
how	O
to	O
compute	O
the	O
gradient	B
x	O
fx	O
y	O
for	O
an	O
arbitrary	O
function	O
f	O
where	O
x	O
is	O
a	O
set	O
of	O
variables	O
whose	O
derivatives	O
are	O
desired	O
and	O
y	O
is	O
an	O
additional	O
set	O
of	O
variables	O
that	O
are	O
inputs	O
to	O
the	O
function	O
but	O
whose	O
derivatives	O
are	O
not	O
required	O
in	O
learning	O
algorithms	O
the	O
gradient	B
we	O
most	O
often	O
require	O
is	O
the	O
gradient	B
of	O
the	O
cost	O
function	O
with	O
respect	O
to	O
the	O
parameters	O
j	O
many	O
machine	B
learning	I
tasks	O
involve	O
computing	O
other	O
derivatives	O
either	O
as	O
part	O
of	O
the	O
learning	O
process	O
or	O
to	O
analyze	O
the	O
learned	O
model	O
the	O
backpropagation	O
algorithm	O
can	O
be	O
applied	O
to	O
these	O
tasks	O
as	O
well	O
and	O
is	O
not	O
restricted	O
to	O
computing	O
the	O
gradient	B
of	O
the	O
cost	O
function	O
with	O
respect	O
to	O
the	O
parameters	O
the	O
idea	O
of	O
computing	O
derivatives	O
by	O
propagating	O
information	O
through	O
a	O
network	O
is	O
very	O
general	O
and	O
can	O
be	O
used	O
to	O
compute	O
values	O
such	O
as	O
the	O
jacobian	O
of	O
a	O
function	O
f	O
with	O
multiple	O
outputs	O
we	O
restrict	O
our	O
description	O
here	O
to	O
the	O
most	O
commonly	O
used	O
case	O
where	O
has	O
a	O
single	O
output	O
f	O
chapter	O
deep	O
feedforward	O
networks	O
computational	O
graphs	O
so	O
far	O
we	O
have	O
discussed	O
neural	O
networks	O
with	O
a	O
relatively	O
informal	O
graph	O
language	O
to	O
describe	O
the	O
back-propagation	B
algorithm	O
more	O
precisely	O
it	O
is	O
helpful	O
to	O
have	O
a	O
more	O
precise	O
computational	B
graph	I
language	O
many	O
ways	O
of	O
formalizing	O
computation	O
as	O
graphs	O
are	O
possible	O
here	O
we	O
use	O
each	O
node	O
in	O
the	O
graph	O
to	O
indicate	O
a	O
variable	O
the	O
variable	O
may	O
be	O
a	O
scalar	O
vector	O
matrix	O
tensor	O
or	O
even	O
a	O
variable	O
of	O
another	O
type	O
to	O
formalize	O
our	O
graphs	O
we	O
also	O
need	O
to	O
introduce	O
the	O
idea	O
of	O
an	O
operation	B
an	O
operation	B
is	O
a	O
simple	O
function	O
of	O
one	O
or	O
more	O
variables	O
our	O
graph	O
language	O
is	O
accompanied	O
by	O
a	O
set	O
of	O
allowable	O
operations	O
functions	O
more	O
complicated	O
than	O
the	O
operations	O
in	O
this	O
set	O
may	O
be	O
described	O
by	O
composing	O
many	O
operations	O
together	O
without	O
loss	O
of	O
generality	O
we	O
define	O
an	O
operation	B
to	O
return	O
only	O
a	O
single	O
output	O
variable	O
this	O
does	O
not	O
lose	O
generality	O
because	O
the	O
output	O
variable	O
can	O
have	O
multiple	O
entries	O
such	O
as	O
a	O
vector	O
software	O
implementations	O
of	O
back-propagation	B
usually	O
support	O
operations	O
with	O
multiple	O
outputs	O
but	O
we	O
avoid	O
this	O
case	O
in	O
our	O
description	O
because	O
it	O
introduces	O
many	O
extra	O
details	O
that	O
are	O
not	O
important	O
to	O
conceptual	O
understanding	O
if	O
a	O
variable	O
y	O
is	O
computed	O
by	O
applying	O
an	O
operation	B
to	O
a	O
variable	O
x	O
then	O
we	O
draw	O
a	O
directed	O
edge	O
from	O
x	O
to	O
y	O
we	O
sometimes	O
annotate	O
the	O
output	O
node	O
with	O
the	O
name	O
of	O
the	O
operation	B
applied	O
and	O
other	O
times	O
omit	O
this	O
label	O
when	O
the	O
operation	B
is	O
clear	O
from	O
context	O
examples	O
of	O
computational	O
graphs	O
are	O
shown	O
in	O
figure	O
chain	O
rule	O
of	O
calculus	O
the	O
chain	O
rule	O
of	O
calculus	O
to	O
be	O
confused	O
with	O
the	O
chain	B
rule	I
of	I
probability	I
is	O
used	O
to	O
compute	O
the	O
derivatives	O
of	O
functions	O
formed	O
by	O
composing	O
other	O
functions	O
whose	O
derivatives	O
are	O
known	O
back-propagation	B
is	O
an	O
algorithm	O
that	O
computes	O
the	O
chain	O
rule	O
with	O
a	O
specific	O
order	O
of	O
operations	O
that	O
is	O
highly	O
efficient	O
let	O
x	O
be	O
a	O
real	O
number	O
and	O
let	O
f	O
and	O
g	O
both	O
be	O
functions	O
mapping	O
from	O
a	O
real	O
number	O
to	O
a	O
real	O
number	O
suppose	O
that	O
y	O
gx	O
and	O
z	O
fgx	O
f	O
then	O
the	O
chain	O
rule	O
states	O
that	O
dz	O
dx	O
dz	O
dy	O
dy	O
dx	O
we	O
can	O
generalize	O
this	O
beyond	O
the	O
scalar	O
case	O
suppose	O
that	O
x	O
m	O
y	O
r	O
n	O
r	O
chapter	O
deep	O
feedforward	O
networks	O
y	O
y	O
dot	O
zz	O
xx	O
yy	O
xx	O
ww	O
bb	O
hh	O
relu	O
u	O
u	O
matmul	O
xx	O
ww	O
bb	O
sum	O
dot	O
sqr	O
ww	O
y	O
y	O
xx	O
y	O
x	O
the	O
graph	O
using	O
the	O
the	O
graph	O
for	O
the	O
logistic	O
regression	B
prediction	O
figure	O
examples	O
of	O
computational	O
graphs	O
operation	B
to	O
compute	O
z	O
xy	O
w	O
b	O
some	O
of	O
the	O
intermediate	O
expressions	O
do	O
not	O
have	O
names	O
in	O
the	O
algebraic	O
expression	O
but	O
need	O
names	O
in	O
the	O
graph	O
we	O
simply	O
name	O
the	O
i-th	O
such	O
variable	O
u	O
the	O
which	O
computes	O
a	O
design	O
computational	B
graph	I
for	O
the	O
expression	O
h	O
max	O
matrix	O
of	O
rectified	O
linear	O
unit	O
activations	O
h	O
given	O
a	O
design	B
matrix	I
containing	O
a	O
minibatch	B
of	O
inputs	O
x	O
examples	O
a	O
c	O
applied	O
at	O
most	O
one	O
operation	B
to	O
each	O
variable	O
but	O
it	O
is	O
possible	O
to	O
apply	O
more	O
than	O
one	O
operation	B
here	O
we	O
show	O
a	O
computation	O
graph	O
that	O
applies	O
more	O
than	O
one	O
operation	B
to	O
the	O
weights	B
w	O
of	O
a	O
linear	O
regression	B
model	O
the	O
weights	B
are	O
used	O
to	O
make	O
both	O
the	O
prediction	O
y	O
and	O
the	O
weight	O
decay	O
penalty	O
xw	O
b	O
i	O
i	O
g	O
maps	O
from	O
r	O
m	O
to	O
r	O
n	O
and	O
f	O
maps	O
from	O
r	O
n	O
to	O
r	O
if	O
y	O
gx	O
and	O
z	O
fy	O
then	O
z	O
yj	O
yj	O
xi	O
z	O
xi	O
in	O
vector	O
notation	O
this	O
may	O
be	O
equivalently	O
written	O
as	O
xz	O
y	O
x	O
y	O
z	O
j	O
chapter	O
deep	O
feedforward	O
networks	O
n	O
m	O
is	O
the	O
where	O
y	O
x	O
jacobian	O
matrix	O
of	O
g	O
from	O
this	O
we	O
see	O
that	O
the	O
gradient	B
of	O
a	O
variable	O
x	O
can	O
be	O
obtained	O
by	O
multiplying	O
a	O
jacobian	O
matrix	O
y	O
yz	O
the	O
back-propagation	B
algorithm	O
consists	O
x	O
of	O
performing	O
such	O
a	O
jacobian-gradient	O
product	O
for	O
each	O
operation	B
in	O
the	O
graph	O
by	O
a	O
gradient	B
usually	O
we	O
do	O
not	O
apply	O
the	O
back-propagation	B
algorithm	O
merely	O
to	O
vectors	O
but	O
rather	O
to	O
tensors	O
of	O
arbitrary	O
dimensionality	O
conceptually	O
this	O
is	O
exactly	O
the	O
same	O
as	O
back-propagation	B
with	O
vectors	O
the	O
only	O
difference	O
is	O
how	O
the	O
numbers	O
are	O
arranged	O
in	O
a	O
grid	O
to	O
form	O
a	O
tensor	O
we	O
could	O
imagine	O
flattening	O
each	O
tensor	O
into	O
a	O
vector	O
before	O
we	O
run	O
back-propagation	B
computing	O
a	O
vector-valued	O
gradient	B
and	O
then	O
reshaping	O
the	O
gradient	B
back	O
into	O
a	O
tensor	O
in	O
this	O
rearranged	O
view	O
back-propagation	B
is	O
still	O
just	O
multiplying	O
jacobians	O
by	O
gradients	O
to	O
denote	O
the	O
gradient	B
of	O
a	O
value	O
z	O
with	O
respect	O
to	O
a	O
tensor	O
x	O
we	O
write	O
z	O
just	O
as	O
if	O
x	O
were	O
a	O
vector	O
the	O
indices	O
into	O
x	O
now	O
have	O
multiple	O
coordinates	O
for	O
example	B
a	O
tensor	O
is	O
indexed	O
by	O
three	O
coordinates	O
we	O
can	O
abstract	O
this	O
away	O
by	O
using	O
a	O
single	O
variable	O
i	O
to	O
represent	O
the	O
complete	O
tuple	O
of	O
indices	O
for	O
all	O
zi	O
gives	O
z	O
possible	O
index	O
tuples	O
i	O
this	O
is	O
exactly	O
the	O
same	O
as	O
how	O
for	O
all	O
xi	O
x	O
zi	O
gives	O
z	O
possible	O
integer	O
indices	O
i	O
into	O
a	O
vector	O
using	O
this	O
notation	O
we	O
x	O
i	O
then	O
can	O
write	O
the	O
chain	O
rule	O
as	O
it	O
applies	O
to	O
tensors	O
if	O
x	O
f	O
and	O
y	O
z	O
x	O
x	O
x	O
z	O
j	O
xyj	O
z	O
yj	O
recursively	O
applying	O
the	O
chain	O
rule	O
to	O
obtain	O
backprop	O
using	O
the	O
chain	O
rule	O
it	O
is	O
straightforward	O
to	O
write	O
down	O
an	O
algebraic	O
expression	O
for	O
the	O
gradient	B
of	O
a	O
scalar	O
with	O
respect	O
to	O
any	O
node	O
in	O
the	O
computational	B
graph	I
that	O
produced	O
that	O
scalar	O
however	O
actually	O
evaluating	O
that	O
expression	O
in	O
a	O
computer	O
introduces	O
some	O
extra	O
considerations	O
specifically	O
many	O
subexpressions	O
may	O
be	O
repeated	O
several	O
times	O
within	O
the	O
overall	O
expression	O
for	O
the	O
gradient	B
any	O
procedure	O
that	O
computes	O
the	O
gradient	B
chapter	O
deep	O
feedforward	O
networks	O
will	O
need	O
to	O
choose	O
whether	O
to	O
store	O
these	O
subexpressions	O
or	O
to	O
recompute	O
them	O
several	O
times	O
an	O
example	B
of	O
how	O
these	O
repeated	O
subexpressions	O
arise	O
is	O
given	O
in	O
figure	O
in	O
some	O
cases	O
computing	O
the	O
same	O
subexpression	O
twice	O
would	O
simply	O
be	O
wasteful	O
for	O
complicated	O
graphs	O
there	O
can	O
be	O
exponentially	O
many	O
of	O
these	O
wasted	O
computations	O
making	O
a	O
naive	O
implementation	O
of	O
the	O
chain	O
rule	O
infeasible	O
in	O
other	O
cases	O
computing	O
the	O
same	O
subexpression	O
twice	O
could	O
be	O
a	O
valid	O
way	O
to	O
reduce	O
memory	O
consumption	O
at	O
the	O
cost	O
of	O
higher	O
runtime	O
along	O
with	O
algorithm	O
we	O
first	O
begin	O
by	O
a	O
version	O
of	O
the	O
back-propagation	B
algorithm	O
that	O
specifies	O
the	O
actual	O
gradient	B
computation	O
directly	O
for	O
the	O
associated	O
forward	O
computation	O
in	O
the	O
order	O
it	O
will	O
actually	O
be	O
done	O
and	O
according	O
to	O
the	O
recursive	O
application	O
of	O
chain	O
rule	O
one	O
could	O
either	O
directly	O
perform	O
these	O
computations	O
or	O
view	O
the	O
description	O
of	O
the	O
algorithm	O
as	O
a	O
symbolic	O
specification	O
of	O
the	O
computational	B
graph	I
for	O
computing	O
the	O
back-propagation	B
however	O
this	O
formulation	O
does	O
not	O
make	O
explicit	O
the	O
manipulation	O
and	O
the	O
construction	O
of	O
the	O
symbolic	O
graph	O
that	O
performs	O
the	O
gradient	B
computation	O
such	O
a	O
formulation	O
is	O
presented	O
below	O
in	O
section	O
with	O
algorithm	O
where	O
we	O
also	O
generalize	O
to	O
nodes	O
that	O
contain	O
arbitrary	O
tensors	O
first	O
consider	O
a	O
computational	B
graph	I
describing	O
how	O
to	O
compute	O
a	O
single	O
scalar	O
u	O
the	O
loss	O
on	O
a	O
training	O
example	B
this	O
scalar	O
is	O
the	O
quantity	O
whose	O
gradient	B
we	O
want	O
to	O
obtain	O
with	O
respect	O
to	O
the	O
ni	O
input	O
nodes	O
to	O
uni	O
in	O
other	O
words	O
we	O
wish	O
to	O
compute	O
u	O
in	O
the	O
application	O
u	O
of	O
back-propagation	B
to	O
computing	O
gradients	O
for	O
gradient	B
descent	O
over	O
parameters	O
u	O
will	O
be	O
the	O
cost	O
associated	O
with	O
an	O
example	B
or	O
a	O
minibatch	B
while	O
to	O
uni	O
correspond	O
to	O
the	O
parameters	O
of	O
the	O
model	O
ni	O
for	O
all	O
i	O
we	O
will	O
assume	O
that	O
the	O
nodes	O
of	O
the	O
graph	O
have	O
been	O
ordered	O
in	O
such	O
a	O
way	O
that	O
we	O
can	O
compute	O
their	O
output	O
one	O
after	O
the	O
other	O
starting	O
at	O
uni	O
and	O
going	O
up	O
to	O
u	O
as	O
defined	O
in	O
algorithm	O
each	O
node	O
is	O
associated	O
with	O
an	O
operation	B
f	O
and	O
is	O
computed	O
by	O
evaluating	O
the	O
function	O
u	O
where	O
a	O
is	O
the	O
set	O
of	O
all	O
nodes	O
that	O
are	O
parents	O
of	O
u	O
u	O
a	O
g	O
b	O
that	O
algorithm	O
specifies	O
the	O
forward	B
propagation	I
computation	O
which	O
we	O
could	O
in	O
order	O
to	O
perform	O
back-propagation	B
we	O
can	O
construct	O
a	O
and	O
adds	O
to	O
it	O
an	O
extra	O
set	O
of	O
nodes	O
these	O
b	O
proceeds	O
in	O
computes	O
associated	O
with	O
the	O
forward	O
graph	O
node	O
u	O
this	O
is	O
done	O
put	O
in	O
a	O
graph	O
computational	B
graph	I
that	O
depends	O
on	O
form	O
a	O
subgraph	O
exactly	O
the	O
reverse	O
of	O
the	O
order	O
of	O
computation	O
in	O
the	O
derivative	B
u	O
u	O
g	O
computation	O
in	O
with	O
one	O
node	O
per	O
node	O
of	O
and	O
each	O
node	O
of	O
b	O
g	O
g	O
chapter	O
deep	O
feedforward	O
networks	O
that	O
comprises	O
the	O
values	O
of	O
previous	O
nodes	O
u	O
j	O
i	O
with	O
j	O
p	O
a	O
algorithm	O
a	O
procedure	O
that	O
performs	O
the	O
computations	O
mapping	O
ni	O
inputs	O
to	O
u	O
to	O
an	O
output	O
u	O
this	O
defines	O
a	O
computational	B
graph	I
where	O
each	O
node	O
computes	O
numerical	O
value	O
u	O
by	O
applying	O
a	O
function	O
f	O
to	O
the	O
set	O
of	O
arguments	O
the	O
a	O
input	O
to	O
the	O
computational	B
graph	I
is	O
the	O
vector	O
x	O
and	O
is	O
set	O
into	O
the	O
first	O
ni	O
nodes	O
to	O
uni	O
the	O
output	O
of	O
the	O
computational	B
graph	I
is	O
read	O
off	O
the	O
last	O
node	O
u	O
i	O
do	O
for	O
i	O
u	O
n	O
xi	O
end	O
for	O
for	O
i	O
a	O
u	O
n	O
i	O
n	O
do	O
j	O
p	O
a	O
u	O
u	O
f	O
end	O
for	O
return	O
u	O
using	O
the	O
chain	O
rule	O
with	O
respect	O
to	O
scalar	O
output	O
u	O
u	O
u	O
i	O
j	O
p	O
a	O
u	O
u	O
u	O
b	O
u	O
u	O
g	O
the	O
edge	O
from	O
u	O
to	O
u	O
contains	O
exactly	O
one	O
edge	O
for	O
each	O
as	O
specified	O
by	O
algorithm	O
the	O
subgraph	O
edge	O
from	O
node	O
u	O
to	O
node	O
u	O
of	O
is	O
associated	O
with	O
the	O
computation	O
of	O
u	O
in	O
addition	O
a	O
dot	O
product	O
is	O
performed	O
for	O
each	O
node	O
u	O
between	O
the	O
gradient	B
already	O
computed	O
with	O
respect	O
to	O
nodes	O
u	O
that	O
are	O
children	O
of	O
u	O
and	O
the	O
vector	O
containing	O
the	O
partial	O
derivatives	O
u	O
for	O
the	O
same	O
children	O
u	O
nodes	O
u	O
to	O
summarize	O
the	O
amount	O
of	O
computation	O
required	O
for	O
performing	O
the	O
back-propagation	B
scales	O
linearly	O
with	O
the	O
number	O
of	O
edges	O
in	O
where	O
the	O
computation	O
for	O
each	O
edge	O
corresponds	O
to	O
computing	O
a	O
partial	B
derivative	B
one	O
node	O
with	O
respect	O
to	O
one	O
of	O
its	O
parents	O
as	O
well	O
as	O
performing	O
one	O
multiplication	O
and	O
one	O
addition	O
below	O
we	O
generalize	O
this	O
analysis	O
to	O
tensor-valued	O
nodes	O
which	O
is	O
just	O
a	O
way	O
to	O
group	O
multiple	O
scalar	O
values	O
in	O
the	O
same	O
node	O
and	O
enable	O
more	O
efficient	O
implementations	O
g	O
the	O
back-propagation	B
algorithm	O
is	O
designed	O
to	O
reduce	O
the	O
number	O
of	O
common	O
subexpressions	O
without	O
regard	O
to	O
memory	O
specifically	O
it	O
performs	O
on	O
the	O
order	O
of	O
one	O
jacobian	O
product	O
per	O
node	O
in	O
the	O
graph	O
this	O
can	O
be	O
seen	O
from	O
the	O
fact	O
u	O
to	O
node	O
u	O
of	O
that	O
backprop	O
the	O
graph	O
exactly	O
once	O
in	O
order	O
to	O
obtain	O
the	O
associated	O
partial	B
derivative	B
u	O
u	O
visits	O
each	O
edge	O
from	O
node	O
chapter	O
deep	O
feedforward	O
networks	O
algorithm	O
simplified	O
version	O
of	O
the	O
back-propagation	B
algorithm	O
for	O
computing	O
the	O
derivatives	O
of	O
u	O
with	O
respect	O
to	O
the	O
variables	O
in	O
the	O
graph	O
this	O
example	B
is	O
intended	O
to	O
further	O
understanding	O
by	O
showing	O
a	O
simplified	O
case	O
where	O
all	O
variables	O
are	O
scalars	O
and	O
we	O
wish	O
to	O
compute	O
the	O
derivatives	O
with	O
respect	O
to	O
u	O
this	O
simplified	O
version	O
computes	O
the	O
derivatives	O
of	O
all	O
nodes	O
in	O
the	O
graph	O
the	O
computational	O
cost	O
of	O
this	O
algorithm	O
is	O
proportional	O
to	O
the	O
number	O
of	O
edges	O
in	O
the	O
graph	O
assuming	O
that	O
the	O
partial	B
derivative	B
associated	O
with	O
each	O
edge	O
requires	O
a	O
constant	O
time	O
this	O
is	O
of	O
the	O
same	O
order	O
as	O
the	O
number	O
of	O
computations	O
for	O
the	O
forward	B
propagation	I
each	O
u	O
is	O
a	O
function	O
of	O
the	O
parents	O
u	O
of	O
u	O
thus	O
u	O
linking	O
the	O
nodes	O
of	O
the	O
forward	O
graph	O
to	O
those	O
added	O
for	O
the	O
back-propagation	B
graph	O
for	O
this	O
example	B
to	O
obtain	O
the	O
activa	O
run	O
forward	B
propagation	I
tions	O
of	O
the	O
network	O
initialize	O
grad	O
table	O
a	O
data	O
structure	O
that	O
will	O
store	O
the	O
derivatives	O
that	O
have	O
will	O
store	O
the	O
computed	O
value	O
of	O
been	O
computed	O
the	O
entry	O
grad	O
table	O
u	O
u	O
grad	O
table	O
for	O
j	O
n	O
do	O
using	O
stored	O
values	O
down	O
to	O
the	O
next	O
line	O
computes	O
u	O
u	O
grad	O
table	O
end	O
for	O
return	O
grad	O
table	O
i	O
ni	O
i	O
j	O
p	O
a	O
u	O
u	O
u	O
u	O
u	O
u	O
u	O
i	O
j	O
p	O
a	O
u	O
grad	O
table	O
back-propagation	B
thus	O
avoids	O
the	O
exponential	O
explosion	O
in	O
repeated	O
subexpressions	O
however	O
other	O
algorithms	O
may	O
be	O
able	O
to	O
avoid	O
more	O
subexpressions	O
by	O
performing	O
simplifications	O
on	O
the	O
computational	B
graph	I
or	O
may	O
be	O
able	O
to	O
conserve	O
memory	O
by	O
recomputing	O
rather	O
than	O
storing	O
some	O
subexpressions	O
we	O
will	O
revisit	O
these	O
ideas	O
after	O
describing	O
the	O
back-propagation	B
algorithm	O
itself	O
back-propagation	B
computation	O
in	O
fully-connected	O
mlp	O
to	O
clarify	O
the	O
above	O
definition	O
of	O
the	O
back-propagation	B
computation	O
let	O
us	O
consider	O
the	O
specific	O
graph	O
associated	O
with	O
a	O
fully-connected	O
multi-layer	O
mlp	O
algorithm	O
the	O
supervised	O
loss	O
l	O
y	O
y	O
y	O
first	O
shows	O
the	O
forward	B
propagation	I
which	O
maps	O
parameters	O
to	O
associated	O
with	O
a	O
single	O
training	O
example	B
with	O
y	O
the	O
output	O
of	O
the	O
neural	B
network	I
when	O
x	O
is	O
provided	O
in	O
input	O
algorithm	O
then	O
shows	O
the	O
corresponding	O
computation	O
to	O
be	O
done	O
for	O
chapter	O
deep	O
feedforward	O
networks	O
f	O
f	O
f	O
zz	O
yy	O
xx	O
ww	O
figure	O
a	O
computational	B
graph	I
that	O
results	O
in	O
repeated	O
subexpressions	O
when	O
computing	O
the	O
gradient	B
let	O
w	O
r	O
as	O
the	O
operation	B
that	O
we	O
apply	O
at	O
every	O
step	O
of	O
a	O
chain	O
x	O
fw	O
y	O
f	O
x	O
z	O
f	O
y	O
to	O
compute	O
z	O
w	O
r	O
be	O
the	O
input	O
to	O
the	O
graph	O
we	O
use	O
the	O
same	O
function	O
f	O
r	O
we	O
apply	O
equation	O
and	O
obtain	O
z	O
w	O
z	O
y	O
y	O
x	O
f	O
f	O
f	O
w	O
f	O
x	O
w	O
f	O
f	O
w	O
f	O
suggests	O
an	O
implementation	O
in	O
which	O
we	O
compute	O
the	O
value	O
of	O
f	O
only	O
equation	O
once	O
and	O
store	O
it	O
in	O
the	O
variable	O
x	O
this	O
is	O
the	O
approach	O
taken	O
by	O
the	O
back-propagation	B
algorithm	O
an	O
alternative	O
approach	O
is	O
suggested	O
by	O
equation	O
where	O
the	O
subexpression	O
fw	O
appears	O
more	O
than	O
once	O
in	O
the	O
alternative	O
approach	O
f	O
is	O
recomputed	O
each	O
time	O
it	O
is	O
needed	O
when	O
the	O
memory	O
required	O
to	O
store	O
the	O
value	O
of	O
these	O
expressions	O
is	O
low	O
the	O
back-propagation	B
approach	O
of	O
equation	O
is	O
clearly	O
preferable	O
because	O
of	O
its	O
reduced	O
runtime	O
however	O
equation	O
is	O
also	O
a	O
valid	O
implementation	O
of	O
the	O
chain	O
rule	O
and	O
is	O
useful	O
when	O
memory	O
is	O
limited	O
chapter	O
deep	O
feedforward	O
networks	O
applying	O
the	O
back-propagation	B
algorithm	O
to	O
this	O
graph	O
algorithms	O
are	O
demonstrations	O
that	O
are	O
chosen	O
to	O
be	O
simple	O
and	O
straightforward	O
to	O
understand	O
however	O
they	O
are	O
specialized	O
to	O
one	O
specific	O
problem	O
and	O
modern	O
software	O
implementations	O
are	O
based	O
on	O
the	O
generalized	O
form	O
of	O
backpropagation	O
described	O
in	O
section	O
below	O
which	O
can	O
accommodate	O
any	O
computational	B
graph	I
by	O
explicitly	O
manipulating	O
a	O
data	O
structure	O
for	O
representing	O
symbolic	O
computation	O
algorithm	O
forward	B
propagation	I
through	O
a	O
typical	O
deep	O
neural	B
network	I
and	O
the	O
computation	O
of	O
the	O
cost	O
function	O
the	O
loss	O
l	O
y	O
y	O
depends	O
on	O
the	O
output	O
y	O
and	O
on	O
the	O
target	O
y	O
section	O
for	O
examples	O
of	O
loss	O
functions	O
to	O
obtain	O
the	O
total	O
cost	O
j	O
the	O
loss	O
may	O
be	O
added	O
to	O
a	O
regularizer	B
where	O
contains	O
all	O
the	O
parameters	O
and	O
biases	O
algorithm	O
shows	O
how	O
to	O
compute	O
gradients	O
of	O
j	O
with	O
respect	O
to	O
parameters	O
w	O
and	O
b	O
for	O
simplicity	O
this	O
demonstration	O
uses	O
only	O
a	O
single	O
input	O
example	B
x	O
practical	O
applications	O
should	O
use	O
a	O
minibatch	B
see	O
section	O
require	O
network	O
depth	O
l	O
require	O
w	O
i	O
l	O
require	O
b	O
i	O
l	O
require	O
x	O
the	O
input	O
to	O
process	O
require	O
y	O
the	O
target	O
output	O
for	O
a	O
more	O
realistic	O
demonstration	O
the	O
bias	O
parameters	O
of	O
the	O
model	O
the	O
weight	O
matrices	O
of	O
the	O
model	O
x	O
for	O
k	O
do	O
l	O
a	O
b	O
w	O
h	O
k	O
h	O
a	O
end	O
for	O
y	O
j	O
h	O
l	O
y	O
y	O
symbol-to-symbol	O
derivatives	O
algebraic	O
expressions	O
and	O
computational	O
graphs	O
both	O
operate	O
on	O
symbols	O
or	O
variables	O
that	O
do	O
not	O
have	O
specific	O
values	O
these	O
algebraic	O
and	O
graph-based	O
representations	O
are	O
called	O
symbolic	O
representations	O
when	O
we	O
actually	O
use	O
or	O
train	O
a	O
neural	B
network	I
we	O
must	O
assign	O
specific	O
values	O
to	O
these	O
symbols	O
we	O
replace	O
a	O
symbolic	O
input	O
to	O
the	O
network	O
x	O
with	O
a	O
specific	O
numeric	O
value	O
such	O
as	O
chapter	O
deep	O
feedforward	O
networks	O
algorithm	O
backward	O
computation	O
for	O
the	O
deep	O
neural	B
network	I
of	O
algox	O
a	O
target	O
y	O
this	O
computation	O
rithm	O
which	O
uses	O
in	O
addition	O
to	O
the	O
input	O
yields	O
the	O
gradients	O
on	O
the	O
activations	O
a	O
for	O
each	O
layer	O
k	O
starting	O
from	O
the	O
output	O
layer	O
and	O
going	O
backwards	O
to	O
the	O
first	O
hidden	B
layer	I
from	O
these	O
gradients	O
which	O
can	O
be	O
interpreted	O
as	O
an	O
indication	O
of	O
how	O
each	O
layer	O
s	O
output	O
should	O
change	O
to	O
reduce	O
error	O
one	O
can	O
obtain	O
the	O
gradient	B
on	O
the	O
parameters	O
of	O
each	O
layer	O
the	O
gradients	O
on	O
weights	B
and	O
biases	O
can	O
be	O
immediately	O
used	O
as	O
part	O
of	O
a	O
stochastic	O
gradient	B
update	O
the	O
update	O
right	O
after	O
the	O
gradients	O
have	O
been	O
computed	O
or	O
used	O
with	O
other	O
gradient-based	O
optimization	O
methods	O
after	O
the	O
forward	O
computation	O
compute	O
the	O
gradient	B
on	O
the	O
output	O
layer	O
g	O
for	O
yj	O
y	O
l	O
y	O
y	O
do	O
l	O
l	O
k	O
g	O
a	O
j	O
f	O
convert	O
the	O
gradient	B
on	O
the	O
layer	O
s	O
output	O
into	O
a	O
gradient	B
into	O
the	O
pre	O
nonlinearity	O
activation	O
multiplication	O
if	O
g	O
compute	O
gradients	O
on	O
weights	B
and	O
biases	O
the	O
regularization	O
term	O
where	O
needed	O
b	O
j	O
b	O
w	O
j	O
g	O
h	O
k	O
w	O
propagate	O
the	O
gradients	O
w	O
r	O
t	O
the	O
next	O
lower-level	O
hidden	B
layer	I
s	O
activations	O
j	O
w	O
g	O
is	O
element-wise	O
f	O
k	O
h	O
end	O
for	O
g	O
chapter	O
deep	O
feedforward	O
networks	O
f	O
f	O
f	O
zz	O
yy	O
xx	O
ww	O
f	O
f	O
f	O
zz	O
yy	O
xx	O
ww	O
f	O
f	O
f	O
dz	O
dz	O
dy	O
dy	O
dy	O
dy	O
dx	O
dx	O
dx	O
dx	O
dw	O
dw	O
dz	O
dz	O
dx	O
dx	O
dz	O
dz	O
dw	O
dw	O
figure	O
an	O
example	B
of	O
the	O
symbol-to-symbol	O
approach	O
to	O
computing	O
derivatives	O
in	O
this	O
approach	O
the	O
back-propagation	B
algorithm	O
does	O
not	O
need	O
to	O
ever	O
access	O
any	O
actual	O
specific	O
numeric	O
values	O
instead	O
it	O
adds	O
nodes	O
to	O
a	O
computational	B
graph	I
describing	O
how	O
to	O
compute	O
these	O
derivatives	O
a	O
generic	O
graph	O
evaluation	O
engine	O
can	O
later	O
compute	O
the	O
derivatives	O
for	O
any	O
specific	O
numeric	O
values	O
this	O
example	B
we	O
begin	O
with	O
a	O
graph	O
we	O
run	O
the	O
back-propagation	B
algorithm	O
instructing	O
representing	O
z	O
f	O
it	O
to	O
construct	O
the	O
graph	O
for	O
the	O
expression	O
corresponding	O
to	O
dz	O
in	O
this	O
example	B
we	O
do	O
dw	O
not	O
explain	O
how	O
the	O
back-propagation	B
algorithm	O
works	O
the	O
purpose	O
is	O
only	O
to	O
illustrate	O
what	O
the	O
desired	O
result	O
is	O
a	O
computational	B
graph	I
with	O
a	O
symbolic	O
description	O
of	O
the	O
derivative	B
some	O
approaches	O
to	O
back-propagation	B
take	O
a	O
computational	B
graph	I
and	O
a	O
set	O
of	O
numerical	O
values	O
for	O
the	O
inputs	O
to	O
the	O
graph	O
then	O
return	O
a	O
set	O
of	O
numerical	O
values	O
describing	O
the	O
gradient	B
at	O
those	O
input	O
values	O
we	O
call	O
this	O
approach	O
symbolto-number	O
differentiation	O
this	O
is	O
the	O
approach	O
used	O
by	O
libraries	O
such	O
as	O
torch	O
collobert	O
et	O
al	O
and	O
caffe	O
jia	O
another	O
approach	O
is	O
to	O
take	O
a	O
computational	B
graph	I
and	O
add	O
additional	O
nodes	O
to	O
the	O
graph	O
that	O
provide	O
a	O
symbolic	O
description	O
of	O
the	O
desired	O
derivatives	O
this	O
is	O
the	O
approach	O
taken	O
by	O
theano	O
bergstra	O
et	O
al	O
bastien	O
et	O
al	O
and	O
tensorflow	O
abadi	O
et	O
al	O
an	O
example	B
of	O
how	O
this	O
approach	O
works	O
is	O
illustrated	O
in	O
figure	O
the	O
primary	O
advantage	O
of	O
this	O
approach	O
is	O
that	O
the	O
derivatives	O
are	O
described	O
in	O
the	O
same	O
language	O
as	O
the	O
original	O
expression	O
because	O
the	O
derivatives	O
are	O
just	O
another	O
computational	B
graph	I
it	O
is	O
possible	O
to	O
run	O
back-propagation	B
again	O
differentiating	O
the	O
derivatives	O
in	O
order	O
to	O
obtain	O
higher	O
derivatives	O
computation	O
of	O
higher-order	O
derivatives	O
is	O
described	O
in	O
section	O
we	O
will	O
use	O
the	O
latter	O
approach	O
and	O
describe	O
the	O
back-propagation	B
algorithm	O
in	O
chapter	O
deep	O
feedforward	O
networks	O
terms	O
of	O
constructing	O
a	O
computational	B
graph	I
for	O
the	O
derivatives	O
any	O
subset	O
of	O
the	O
graph	O
may	O
then	O
be	O
evaluated	O
using	O
specific	O
numerical	O
values	O
at	O
a	O
later	O
time	O
this	O
allows	O
us	O
to	O
avoid	O
specifying	O
exactly	O
when	O
each	O
operation	B
should	O
be	O
computed	O
instead	O
a	O
generic	O
graph	O
evaluation	O
engine	O
can	O
evaluate	O
every	O
node	O
as	O
soon	O
as	O
its	O
parents	O
values	O
are	O
available	O
the	O
description	O
of	O
the	O
symbol-to-symbol	O
based	O
approach	O
subsumes	O
the	O
symbolto-number	O
approach	O
the	O
symbol-to-number	O
approach	O
can	O
be	O
understood	O
as	O
performing	O
exactly	O
the	O
same	O
computations	O
as	O
are	O
done	O
in	O
the	O
graph	O
built	O
by	O
the	O
symbol-to-symbol	O
approach	O
the	O
key	O
difference	O
is	O
that	O
the	O
symbol-to-number	O
approach	O
does	O
not	O
expose	O
the	O
graph	O
general	O
back-propagation	B
the	O
back-propagation	B
algorithm	O
is	O
very	O
simple	O
to	O
compute	O
the	O
gradient	B
of	O
some	O
scalar	O
z	O
with	O
respect	O
to	O
one	O
of	O
its	O
ancestors	O
x	O
in	O
the	O
graph	O
we	O
begin	O
by	O
observing	O
that	O
the	O
gradient	B
with	O
respect	O
to	O
z	O
is	O
given	O
by	O
dz	O
we	O
can	O
then	O
compute	O
dz	O
the	O
gradient	B
with	O
respect	O
to	O
each	O
parent	O
of	O
z	O
in	O
the	O
graph	O
by	O
multiplying	O
the	O
current	O
gradient	B
by	O
the	O
jacobian	O
of	O
the	O
operation	B
that	O
produced	O
z	O
we	O
continue	O
multiplying	O
by	O
jacobians	O
traveling	O
backwards	O
through	O
the	O
graph	O
in	O
this	O
way	O
until	O
we	O
reach	O
x	O
for	O
any	O
node	O
that	O
may	O
be	O
reached	O
by	O
going	O
backwards	O
from	O
z	O
through	O
two	O
or	O
more	O
paths	O
we	O
simply	O
sum	O
the	O
gradients	O
arriving	O
from	O
different	O
paths	O
at	O
that	O
node	O
more	O
formally	O
each	O
node	O
in	O
the	O
graph	O
corresponds	O
to	O
a	O
variable	O
to	O
achieve	O
maximum	O
generality	O
we	O
describe	O
this	O
variable	O
as	O
being	O
a	O
tensor	O
v	O
tensor	O
can	O
in	O
general	O
have	O
any	O
number	O
of	O
dimensions	O
they	O
subsume	O
scalars	O
vectors	O
and	O
matrices	O
g	O
we	O
assume	O
that	O
each	O
variable	O
is	O
associated	O
with	O
the	O
following	O
subroutines	O
v	O
this	O
returns	O
the	O
operation	B
that	O
computes	O
v	O
repreget	O
operation	B
sented	O
by	O
the	O
edges	O
coming	O
into	O
v	O
in	O
the	O
computational	B
graph	I
for	O
example	B
there	O
may	O
be	O
a	O
python	O
or	O
c	O
class	O
representing	O
the	O
matrix	O
multiplication	O
operation	B
and	O
the	O
get	O
operation	B
function	O
suppose	O
we	O
have	O
a	O
variable	O
that	O
is	O
created	O
by	O
matrix	O
multiplication	O
c	O
ab	O
then	O
get	O
operation	B
v	O
returns	O
a	O
pointer	O
to	O
an	O
instance	O
of	O
the	O
corresponding	O
c	O
class	O
g	O
g	O
g	O
get	O
consumers	O
v	O
in	O
the	O
computational	B
graph	I
g	O
get	O
inputs	O
in	O
the	O
computational	B
graph	I
this	O
returns	O
the	O
list	O
of	O
variables	O
that	O
are	O
children	O
of	O
this	O
returns	O
the	O
list	O
of	O
variables	O
that	O
are	O
parents	O
of	O
v	O
chapter	O
deep	O
feedforward	O
networks	O
each	O
operation	B
op	O
is	O
also	O
associated	O
with	O
a	O
bprop	O
operation	B
this	O
bprop	O
operation	B
can	O
compute	O
a	O
jacobian-vector	O
product	O
as	O
described	O
by	O
equation	O
this	O
is	O
how	O
the	O
back-propagation	B
algorithm	O
is	O
able	O
to	O
achieve	O
great	O
generality	O
each	O
operation	B
is	O
responsible	O
for	O
knowing	O
how	O
to	O
back-propagate	O
through	O
the	O
edges	O
in	O
the	O
graph	O
that	O
it	O
participates	O
in	O
for	O
example	B
we	O
might	O
use	O
a	O
matrix	O
multiplication	O
operation	B
to	O
create	O
a	O
variable	O
c	O
ab	O
suppose	O
that	O
the	O
gradient	B
of	O
a	O
scalar	O
z	O
with	O
respect	O
to	O
c	O
is	O
given	O
by	O
g	O
the	O
matrix	O
multiplication	O
operation	B
is	O
responsible	O
for	O
defining	O
two	O
back-propagation	B
rules	O
one	O
for	O
each	O
of	O
its	O
input	O
arguments	O
if	O
we	O
call	O
the	O
bprop	O
method	O
to	O
request	O
the	O
gradient	B
with	O
respect	O
to	O
a	O
given	O
that	O
the	O
gradient	B
on	O
the	O
output	O
is	O
g	O
then	O
the	O
bprop	O
method	O
of	O
the	O
matrix	O
multiplication	O
operation	B
must	O
state	O
that	O
the	O
gradient	B
with	O
respect	O
to	O
a	O
is	O
given	O
by	O
gb	O
likewise	O
if	O
we	O
call	O
the	O
bprop	O
method	O
to	O
request	O
the	O
gradient	B
with	O
respect	O
to	O
b	O
then	O
the	O
matrix	O
operation	B
is	O
responsible	O
for	O
implementing	O
the	O
bprop	O
method	O
and	O
specifying	O
that	O
the	O
desired	O
gradient	B
is	O
given	O
by	O
a	O
g	O
the	O
back-propagation	B
algorithm	O
itself	O
does	O
not	O
need	O
to	O
know	O
any	O
differentiation	O
rules	O
it	O
only	O
needs	O
to	O
call	O
each	O
operation	B
s	O
bprop	O
rules	O
with	O
the	O
right	O
arguments	O
formally	O
op	O
bprop	O
inputs	O
g	O
must	O
return	O
op	O
f	O
inputs	O
i	O
gi	O
x	O
i	O
which	O
is	O
just	O
an	O
implementation	O
of	O
the	O
chain	O
rule	O
as	O
expressed	O
in	O
equation	O
here	O
inputs	O
is	O
a	O
list	O
of	O
inputs	O
that	O
are	O
supplied	O
to	O
the	O
operation	B
op	O
f	O
is	O
the	O
mathematical	O
function	O
that	O
the	O
operation	B
implements	O
x	O
is	O
the	O
input	O
whose	O
gradient	B
we	O
wish	O
to	O
compute	O
and	O
is	O
the	O
gradient	B
on	O
the	O
output	O
of	O
the	O
operation	B
g	O
the	O
op	O
bprop	O
method	O
should	O
always	O
pretend	O
that	O
all	O
of	O
its	O
inputs	O
are	O
distinct	O
from	O
each	O
other	O
even	O
if	O
they	O
are	O
not	O
for	O
example	B
if	O
the	O
mul	O
operator	O
is	O
passed	O
two	O
copies	O
of	O
x	O
to	O
compute	O
the	O
op	O
bprop	O
method	O
should	O
still	O
return	O
x	O
as	O
the	O
derivative	B
with	O
respect	O
to	O
both	O
inputs	O
the	O
back-propagation	B
algorithm	O
will	O
later	O
add	O
both	O
of	O
these	O
arguments	O
together	O
to	O
obtain	O
which	O
is	O
the	O
correct	O
total	O
derivative	B
on	O
software	O
implementations	O
of	O
back-propagation	B
usually	O
provide	O
both	O
the	O
operations	O
and	O
their	O
bprop	O
methods	O
so	O
that	O
users	O
of	O
deep	O
learning	O
software	O
libraries	O
are	O
able	O
to	O
back-propagate	O
through	O
graphs	O
built	O
using	O
common	O
operations	O
like	O
matrix	O
multiplication	O
exponents	O
logarithms	O
and	O
so	O
on	O
software	O
engineers	O
who	O
build	O
a	O
new	O
implementation	O
of	O
back-propagation	B
or	O
advanced	O
users	O
who	O
need	O
to	O
add	O
their	O
own	O
operation	B
to	O
an	O
existing	O
library	O
must	O
usually	O
derive	O
the	O
op	O
bprop	O
method	O
for	O
any	O
new	O
operations	O
manually	O
the	O
back-propagation	B
algorithm	O
is	O
formally	O
described	O
in	O
algorithm	O
chapter	O
deep	O
feedforward	O
networks	O
build	O
grad	O
algorithm	O
the	O
outermost	O
skeleton	O
of	O
the	O
back-propagation	B
algorithm	O
this	O
portion	O
does	O
simple	O
setup	O
and	O
cleanup	O
work	O
most	O
of	O
the	O
important	O
work	O
happens	O
in	O
the	O
require	O
t	O
the	O
target	O
set	O
of	O
variables	O
whose	O
gradients	O
must	O
be	O
computed	O
require	O
g	O
require	O
z	O
the	O
variable	O
to	O
be	O
differentiated	O
g	O
the	O
computational	B
graph	I
g	O
subroutine	O
of	O
algorithm	O
pruned	O
to	O
contain	O
only	O
nodes	O
that	O
are	O
ancestors	O
of	O
z	O
and	O
descendents	O
grad	O
table	O
a	O
data	O
structure	O
associating	O
tensors	O
to	O
their	O
gradients	O
be	O
let	O
of	O
nodes	O
in	O
initialize	O
grad	O
table	O
for	O
z	O
do	O
build	O
grad	O
v	O
in	O
t	O
g	O
g	O
grad	O
table	O
end	O
for	O
return	O
grad	O
table	O
restricted	O
to	O
t	O
in	O
section	O
we	O
explained	O
that	O
back-propagation	B
was	O
developed	O
in	O
order	O
to	O
avoid	O
computing	O
the	O
same	O
subexpression	O
in	O
the	O
chain	O
rule	O
multiple	O
times	O
the	O
naive	O
algorithm	O
could	O
have	O
exponential	O
runtime	O
due	O
to	O
these	O
repeated	O
subexpressions	O
now	O
that	O
we	O
have	O
specified	O
the	O
back-propagation	B
algorithm	O
we	O
can	O
understand	O
its	O
computational	O
cost	O
if	O
we	O
assume	O
that	O
each	O
operation	B
evaluation	O
has	O
roughly	O
the	O
same	O
cost	O
then	O
we	O
may	O
analyze	O
the	O
computational	O
cost	O
in	O
terms	O
of	O
the	O
number	O
of	O
operations	O
executed	O
keep	O
in	O
mind	O
here	O
that	O
we	O
refer	O
to	O
an	O
operation	B
as	O
the	O
fundamental	O
unit	O
of	O
our	O
computational	B
graph	I
which	O
might	O
actually	O
consist	O
of	O
very	O
many	O
arithmetic	O
operations	O
example	B
we	O
might	O
have	O
a	O
graph	O
that	O
treats	O
matrix	O
multiplication	O
as	O
a	O
single	O
operation	B
computing	O
a	O
gradient	B
in	O
a	O
graph	O
with	O
n	O
nodes	O
will	O
never	O
execute	O
more	O
than	O
operations	O
or	O
store	O
the	O
output	O
of	O
more	O
than	O
on	O
operations	O
here	O
we	O
are	O
counting	O
operations	O
in	O
the	O
computational	B
graph	I
not	O
individual	O
operations	O
executed	O
by	O
the	O
underlying	O
hardware	O
so	O
it	O
is	O
important	O
to	O
remember	O
that	O
the	O
runtime	O
of	O
each	O
operation	B
may	O
be	O
highly	O
variable	O
for	O
example	B
multiplying	O
two	O
matrices	O
that	O
each	O
contain	O
millions	O
of	O
entries	O
might	O
correspond	O
to	O
a	O
single	O
operation	B
in	O
the	O
graph	O
we	O
can	O
see	O
that	O
computing	O
the	O
gradient	B
requires	O
as	O
most	O
operations	O
because	O
the	O
forward	B
propagation	I
stage	O
will	O
at	O
worst	O
execute	O
all	O
n	O
nodes	O
in	O
the	O
original	O
graph	O
on	O
which	O
values	O
we	O
want	O
to	O
compute	O
we	O
may	O
not	O
need	O
to	O
execute	O
the	O
entire	O
graph	O
the	O
back-propagation	B
algorithm	O
adds	O
one	O
jacobian-vector	O
product	O
which	O
should	O
be	O
expressed	O
with	O
nodes	O
per	O
edge	O
in	O
the	O
original	O
graph	O
because	O
the	O
computational	B
graph	I
is	O
a	O
directed	O
acyclic	O
graph	O
it	O
has	O
at	O
most	O
edges	O
for	O
the	O
kinds	O
of	O
graphs	O
that	O
are	O
commonly	O
used	O
in	O
practice	O
the	O
situation	O
is	O
even	O
better	O
most	O
neural	B
network	I
cost	O
functions	O
are	O
chapter	O
deep	O
feedforward	O
networks	O
g	O
g	O
of	O
algorithm	O
the	O
inner	O
loop	B
subroutine	O
build	O
grad	O
the	O
back-propagation	B
algorithm	O
called	O
by	O
the	O
back-propagation	B
algorithm	O
defined	O
in	O
algorithm	O
require	O
v	O
the	O
variable	O
whose	O
gradient	B
should	O
be	O
added	O
to	O
require	O
to	O
nodes	O
that	O
participate	O
in	O
the	O
gradient	B
require	O
require	O
grad	O
table	O
a	O
data	O
structure	O
mapping	O
nodes	O
to	O
their	O
gradients	O
g	O
g	O
g	O
the	O
graph	O
to	O
modify	O
the	O
restriction	O
of	O
grad	O
table	O
grad	O
table	O
and	O
g	O
if	O
then	O
v	O
is	O
in	O
grad	O
table	O
return	O
grad	O
table	O
end	O
if	O
i	O
in	O
for	O
c	O
op	O
g	O
i	O
consumers	O
v	O
g	O
g	O
get	O
operation	B
build	O
grad	O
c	O
i	O
end	O
for	O
d	O
op	O
bprop	O
get	O
inputs	O
i	O
g	O
g	O
v	O
grad	O
table	O
insert	O
g	O
return	O
g	O
g	O
g	O
do	O
grad	O
table	O
d	O
g	O
and	O
the	O
operations	O
creating	O
it	O
into	O
g	O
roughly	O
chain-structured	O
causing	O
back-propagation	B
to	O
have	O
on	O
cost	O
this	O
is	O
far	O
better	O
than	O
the	O
naive	O
approach	O
which	O
might	O
need	O
to	O
execute	O
exponentially	O
many	O
nodes	O
this	O
potentially	O
exponential	O
cost	O
can	O
be	O
seen	O
by	O
expanding	O
and	O
rewriting	O
the	O
recursive	O
chain	O
rule	O
non-recursively	O
u	O
u	O
t	O
path	O
t	O
from	O
toj	O
tn	O
u	O
k	O
u	O
k	O
since	O
the	O
number	O
of	O
paths	O
from	O
node	O
j	O
to	O
node	O
n	O
can	O
grow	O
exponentially	O
in	O
the	O
length	O
of	O
these	O
paths	O
the	O
number	O
of	O
terms	O
in	O
the	O
above	O
sum	O
which	O
is	O
the	O
number	O
of	O
such	O
paths	O
can	O
grow	O
exponentially	O
with	O
the	O
depth	O
of	O
the	O
forward	B
propagation	I
graph	O
this	O
large	O
cost	O
would	O
be	O
incurred	O
because	O
the	O
same	O
computation	O
for	O
u	O
would	O
be	O
redone	O
many	O
times	O
to	O
avoid	O
such	O
recomputation	O
we	O
can	O
think	O
u	O
of	O
back-propagation	B
as	O
a	O
table-filling	O
algorithm	O
that	O
takes	O
advantage	O
of	O
storing	O
intermediate	O
results	O
u	O
each	O
node	O
in	O
the	O
graph	O
has	O
a	O
corresponding	O
slot	O
in	O
a	O
u	O
table	O
to	O
store	O
the	O
gradient	B
for	O
that	O
node	O
by	O
filling	O
in	O
these	O
table	O
entries	O
in	O
order	O
chapter	O
deep	O
feedforward	O
networks	O
back-propagation	B
avoids	O
repeating	O
many	O
common	O
subexpressions	O
this	O
table-filling	O
strategy	O
is	O
sometimes	O
called	O
dynamic	O
programming	O
example	B
back-propagation	B
for	O
mlp	O
training	O
as	O
an	O
example	B
we	O
walk	O
through	O
the	O
back-propagation	B
algorithm	O
as	O
it	O
is	O
used	O
to	O
train	O
a	O
multilayer	B
perceptron	I
here	O
we	O
develop	O
a	O
very	O
simple	O
multilayer	B
perception	I
with	O
a	O
single	O
hidden	B
layer	I
to	O
train	O
this	O
model	O
we	O
will	O
use	O
minibatch	B
stochastic	O
gradient	B
descent	O
the	O
back-propagation	B
algorithm	O
is	O
used	O
to	O
compute	O
the	O
gradient	B
of	O
the	O
cost	O
on	O
a	O
single	O
minibatch	B
specifically	O
we	O
use	O
a	O
minibatch	B
of	O
examples	O
from	O
the	O
training	O
set	O
formatted	O
as	O
a	O
design	B
matrix	I
x	O
and	O
a	O
vector	O
of	O
associated	O
class	O
labels	O
y	O
xw	O
the	O
network	O
computes	O
a	O
layer	O
of	O
hidden	O
features	O
h	O
max	O
to	O
simplify	O
the	O
presentation	O
we	O
do	O
not	O
use	O
biases	O
in	O
this	O
model	O
we	O
assume	O
that	O
our	O
graph	O
language	O
includes	O
a	O
relu	O
operation	B
that	O
can	O
compute	O
max	O
elementwise	O
the	O
predictions	O
of	O
the	O
unnormalized	O
log	O
probabilities	O
over	O
classes	O
are	O
then	O
given	O
by	O
hw	O
we	O
assume	O
that	O
our	O
graph	O
language	O
includes	O
a	O
cross	O
entropy	O
operation	B
that	O
computes	O
the	O
cross-entropy	B
between	O
the	O
targets	O
y	O
and	O
the	O
probability	B
distribution	I
defined	O
by	O
these	O
unnormalized	O
log	O
probabilities	O
the	O
resulting	O
crossentropy	O
defines	O
the	O
cost	O
jmle	O
minimizing	O
this	O
cross-entropy	B
performs	O
maximum	B
likelihood	I
estimation	O
of	O
the	O
classifier	O
however	O
to	O
make	O
this	O
example	B
more	O
realistic	O
we	O
also	O
include	O
a	O
regularization	O
term	O
the	O
total	O
cost	O
z	O
j	O
j	O
mle	O
w	O
ij	O
w	O
ij	O
ij	O
ij	O
consists	O
of	O
the	O
cross-entropy	B
and	O
a	O
weight	O
decay	O
term	O
with	O
coefficient	O
the	O
computational	B
graph	I
is	O
illustrated	O
in	O
figure	O
the	O
computational	B
graph	I
for	O
the	O
gradient	B
of	O
this	O
example	B
is	O
large	O
enough	O
that	O
it	O
would	O
be	O
tedious	O
to	O
draw	O
or	O
to	O
read	O
this	O
demonstrates	O
one	O
of	O
the	O
benefits	O
of	O
the	O
back-propagation	B
algorithm	O
which	O
is	O
that	O
it	O
can	O
automatically	O
generate	O
gradients	O
that	O
would	O
be	O
straightforward	O
but	O
tedious	O
for	O
a	O
software	O
engineer	O
to	O
derive	O
manually	O
we	O
can	O
roughly	O
trace	O
out	O
the	O
behavior	O
of	O
the	O
back-propagation	B
algorithm	O
to	O
train	O
we	O
wish	O
by	O
looking	O
at	O
the	O
forward	B
propagation	I
graph	O
in	O
figure	O
w	O
j	O
there	O
are	O
two	O
different	O
paths	O
leading	O
to	O
compute	O
both	O
backward	O
from	O
j	O
to	O
the	O
weights	B
one	O
through	O
the	O
cross-entropy	B
cost	O
and	O
one	O
through	O
the	O
weight	O
decay	O
cost	O
the	O
weight	O
decay	O
cost	O
is	O
relatively	O
simple	O
it	O
will	O
always	O
contribute	O
w	O
to	O
the	O
gradient	B
on	O
w	O
w	O
and	O
chapter	O
deep	O
feedforward	O
networks	O
j	O
mle	O
j	O
mle	O
cross	O
entropy	O
jj	O
u	O
yy	O
matmul	O
relu	O
hh	O
w	O
sqr	O
u	O
sum	O
u	O
matmul	O
xx	O
w	O
sqr	O
u	O
sum	O
figure	O
the	O
computational	B
graph	I
used	O
to	O
compute	O
the	O
cost	O
used	O
to	O
train	O
our	O
example	B
of	O
a	O
single-layer	O
mlp	O
using	O
the	O
cross-entropy	B
loss	O
and	O
weight	O
decay	O
the	O
other	O
path	O
through	O
the	O
cross-entropy	B
cost	O
is	O
slightly	O
more	O
complicated	O
let	O
g	O
be	O
the	O
gradient	B
on	O
the	O
unnormalized	O
log	O
probabilities	O
u	O
provided	O
by	O
the	O
cross	O
entropy	O
operation	B
the	O
back-propagation	B
algorithm	O
now	O
needs	O
to	O
explore	O
two	O
different	O
branches	O
on	O
the	O
shorter	O
branch	O
it	O
adds	O
h	O
g	O
to	O
the	O
gradient	B
on	O
w	O
using	O
the	O
back-propagation	B
rule	O
for	O
the	O
second	O
argument	O
to	O
the	O
matrix	O
multiplication	O
operation	B
the	O
other	O
branch	O
corresponds	O
to	O
the	O
longer	O
chain	O
descending	O
further	O
along	O
the	O
network	O
first	O
the	O
back-propagation	B
algorithm	O
computes	O
using	O
the	O
back-propagation	B
rule	O
for	O
the	O
first	O
argument	O
to	O
the	O
matrix	O
multiplication	O
operation	B
next	O
the	O
relu	O
operation	B
uses	O
its	O
backpropagation	O
rule	O
to	O
zero	O
out	O
components	O
of	O
the	O
gradient	B
corresponding	O
to	O
entries	O
of	O
u	O
that	O
were	O
less	O
than	O
let	O
the	O
result	O
be	O
called	O
the	O
last	O
step	O
of	O
the	O
back-propagation	B
algorithm	O
is	O
to	O
use	O
the	O
back-propagation	B
rule	O
for	O
the	O
second	O
argument	O
of	O
the	O
hj	O
gw	O
to	O
the	O
gradient	B
on	O
w	O
g	O
matmul	O
operation	B
to	O
add	O
x	O
g	O
after	O
these	O
gradients	O
have	O
been	O
computed	O
it	O
is	O
the	O
responsibility	O
of	O
the	O
gradient	B
descent	O
algorithm	O
or	O
another	O
optimization	O
algorithm	O
to	O
use	O
these	O
gradients	O
to	O
update	O
the	O
parameters	O
for	O
the	O
mlp	O
the	O
computational	O
cost	O
is	O
dominated	O
by	O
the	O
cost	O
of	O
matrix	O
multiplication	O
during	O
the	O
forward	B
propagation	I
stage	O
we	O
multiply	O
by	O
each	O
weight	O
chapter	O
deep	O
feedforward	O
networks	O
matrix	O
resulting	O
in	O
ow	O
multiply-adds	O
where	O
w	O
is	O
the	O
number	O
of	O
weights	B
during	O
the	O
backward	O
propagation	O
stage	O
we	O
multiply	O
by	O
the	O
transpose	O
of	O
each	O
weight	O
matrix	O
which	O
has	O
the	O
same	O
computational	O
cost	O
the	O
main	O
memory	O
cost	O
of	O
the	O
algorithm	O
is	O
that	O
we	O
need	O
to	O
store	O
the	O
input	O
to	O
the	O
nonlinearity	O
of	O
the	O
hidden	B
layer	I
this	O
value	O
is	O
stored	O
from	O
the	O
time	O
it	O
is	O
computed	O
until	O
the	O
backward	O
pass	O
has	O
returned	O
to	O
the	O
same	O
point	O
the	O
memory	O
cost	O
is	O
thus	O
omnh	O
where	O
m	O
is	O
the	O
number	O
of	O
examples	O
in	O
the	O
minibatch	B
and	O
nh	O
is	O
the	O
number	O
of	O
hidden	O
units	O
complications	O
our	O
description	O
of	O
the	O
back-propagation	B
algorithm	O
here	O
is	O
simpler	O
than	O
the	O
implementations	O
actually	O
used	O
in	O
practice	O
as	O
noted	O
above	O
we	O
have	O
restricted	O
the	O
definition	O
of	O
an	O
operation	B
to	O
be	O
a	O
function	O
that	O
returns	O
a	O
single	O
tensor	O
most	O
software	O
implementations	O
need	O
to	O
support	O
operations	O
that	O
can	O
return	O
more	O
than	O
one	O
tensor	O
for	O
example	B
if	O
we	O
wish	O
to	O
compute	O
both	O
the	O
maximum	O
value	O
in	O
a	O
tensor	O
and	O
the	O
index	O
of	O
that	O
value	O
it	O
is	O
best	O
to	O
compute	O
both	O
in	O
a	O
single	O
pass	O
through	O
memory	O
so	O
it	O
is	O
most	O
efficient	O
to	O
implement	O
this	O
procedure	O
as	O
a	O
single	O
operation	B
with	O
two	O
outputs	O
we	O
have	O
not	O
described	O
how	O
to	O
control	O
the	O
memory	O
consumption	O
of	O
backpropagation	O
back-propagation	B
often	O
involves	O
summation	O
of	O
many	O
tensors	O
together	O
in	O
the	O
naive	O
approach	O
each	O
of	O
these	O
tensors	O
would	O
be	O
computed	O
separately	O
then	O
all	O
of	O
them	O
would	O
be	O
added	O
in	O
a	O
second	O
step	O
the	O
naive	O
approach	O
has	O
an	O
overly	O
high	O
memory	O
bottleneck	O
that	O
can	O
be	O
avoided	O
by	O
maintaining	O
a	O
single	O
buffer	O
and	O
adding	O
each	O
value	O
to	O
that	O
buffer	O
as	O
it	O
is	O
computed	O
real-world	O
implementations	O
of	O
back-propagation	B
also	O
need	O
to	O
handle	O
various	O
data	O
types	O
such	O
as	O
floating	O
point	O
floating	O
point	O
and	O
integer	O
values	O
the	O
policy	B
for	O
handling	O
each	O
of	O
these	O
types	O
takes	O
special	O
care	O
to	O
design	O
some	O
operations	O
have	O
undefined	O
gradients	O
and	O
it	O
is	O
important	O
to	O
track	O
these	O
cases	O
and	O
determine	O
whether	O
the	O
gradient	B
requested	O
by	O
the	O
user	O
is	O
undefined	O
various	O
other	O
technicalities	O
make	O
real-world	O
differentiation	O
more	O
complicated	O
these	O
technicalities	O
are	O
not	O
insurmountable	O
and	O
this	O
chapter	O
has	O
described	O
the	O
key	O
intellectual	O
tools	O
needed	O
to	O
compute	O
derivatives	O
but	O
it	O
is	O
important	O
to	O
be	O
aware	O
that	O
many	O
more	O
subtleties	O
exist	O
differentiation	O
outside	O
the	O
deep	O
learning	O
community	O
the	O
deep	O
learning	O
community	O
has	O
been	O
somewhat	O
isolated	O
from	O
the	O
broader	O
computer	O
science	O
community	O
and	O
has	O
largely	O
developed	O
its	O
own	O
cultural	O
attitudes	O
chapter	O
deep	O
feedforward	O
networks	O
concerning	O
how	O
to	O
perform	O
differentiation	O
more	O
generally	O
the	O
field	O
of	O
automatic	O
differentiation	O
is	O
concerned	O
with	O
how	O
to	O
compute	O
derivatives	O
algorithmically	O
the	O
back-propagation	B
algorithm	O
described	O
here	O
is	O
only	O
one	O
approach	O
to	O
automatic	O
differentiation	O
it	O
is	O
a	O
special	O
case	O
of	O
a	O
broader	O
class	O
of	O
techniques	O
called	O
reverse	O
mode	O
accumulation	O
other	O
approaches	O
evaluate	O
the	O
subexpressions	O
of	O
the	O
chain	O
rule	O
in	O
different	O
orders	O
in	O
general	O
determining	O
the	O
order	O
of	O
evaluation	O
that	O
results	O
in	O
the	O
lowest	O
computational	O
cost	O
is	O
a	O
difficult	O
problem	O
finding	O
the	O
optimal	O
sequence	O
of	O
operations	O
to	O
compute	O
the	O
gradient	B
is	O
np-complete	O
in	O
the	O
sense	O
that	O
it	O
may	O
require	O
simplifying	O
algebraic	O
expressions	O
into	O
their	O
least	O
expensive	O
form	O
naumann	O
for	O
example	B
suppose	O
we	O
have	O
variables	O
pn	O
representing	O
probabilities	O
and	O
variables	O
zn	O
representing	O
unnormalized	O
log	O
probabilities	O
suppose	O
we	O
define	O
qi	O
expzi	O
i	O
expzi	O
g	O
where	O
we	O
build	O
the	O
softmax	O
function	O
out	O
of	O
exponentiation	O
summation	O
and	O
division	O
i	O
pi	O
log	O
qi	O
a	O
human	O
operations	O
and	O
construct	O
a	O
cross-entropy	B
loss	O
j	O
mathematician	O
can	O
observe	O
that	O
the	O
derivative	B
of	O
j	O
with	O
respect	O
to	O
zi	O
takes	O
a	O
very	O
pi	O
the	O
back-propagation	B
algorithm	O
is	O
not	O
capable	O
of	O
simplifying	O
simple	O
form	O
qi	O
the	O
gradient	B
this	O
way	O
and	O
will	O
instead	O
explicitly	O
propagate	O
gradients	O
through	O
all	O
of	O
the	O
logarithm	O
and	O
exponentiation	O
operations	O
in	O
the	O
original	O
graph	O
some	O
software	O
libraries	O
such	O
as	O
theano	O
are	O
able	O
to	O
perform	O
some	O
kinds	O
of	O
algebraic	O
substitution	O
to	O
improve	O
over	O
the	O
graph	O
proposed	O
by	O
the	O
pure	O
back-propagation	B
algorithm	O
bergstra	O
et	O
al	O
bastien	O
et	O
al	O
when	O
the	O
forward	O
graph	O
because	O
each	O
local	O
partial	B
derivative	B
has	O
a	O
single	O
output	O
node	O
and	O
each	O
partial	B
derivative	B
u	O
can	O
be	O
computed	O
with	O
a	O
constant	O
amount	O
of	O
computation	O
back-propagation	B
u	O
guarantees	O
that	O
the	O
number	O
of	O
computations	O
for	O
the	O
gradient	B
computation	O
is	O
of	O
the	O
same	O
order	O
as	O
the	O
number	O
of	O
computations	O
for	O
the	O
forward	O
computation	O
this	O
can	O
be	O
seen	O
in	O
algorithm	O
needs	O
to	O
be	O
computed	O
only	O
once	O
along	O
with	O
an	O
associated	O
multiplication	O
and	O
addition	O
for	O
the	O
recursive	O
chain-rule	O
formulation	O
the	O
overall	O
computation	O
is	O
therefore	O
o	O
edges	O
however	O
it	O
can	O
potentially	O
be	O
reduced	O
by	O
simplifying	O
the	O
computational	B
graph	I
constructed	O
by	O
back-propagation	B
and	O
this	O
is	O
an	O
np-complete	O
task	O
implementations	O
such	O
as	O
theano	O
and	O
tensorflow	O
use	O
heuristics	O
based	O
on	O
matching	O
known	O
simplification	O
patterns	O
in	O
order	O
to	O
iteratively	O
attempt	O
to	O
simplify	O
the	O
graph	O
we	O
defined	O
back-propagation	B
only	O
for	O
the	O
computation	O
of	O
a	O
gradient	B
of	O
a	O
scalar	O
output	O
but	O
back-propagation	B
can	O
be	O
extended	O
to	O
compute	O
a	O
jacobian	O
of	O
k	O
different	O
scalar	O
nodes	O
in	O
the	O
graph	O
or	O
of	O
a	O
tensor-valued	O
node	O
containing	O
k	O
values	O
a	O
naive	O
implementation	O
may	O
then	O
need	O
k	O
times	O
more	O
computation	O
for	O
u	O
u	O
chapter	O
deep	O
feedforward	O
networks	O
each	O
scalar	O
internal	O
node	O
in	O
the	O
original	O
forward	O
graph	O
the	O
naive	O
implementation	O
computes	O
k	O
gradients	O
instead	O
of	O
a	O
single	O
gradient	B
when	O
the	O
number	O
of	O
outputs	O
of	O
the	O
graph	O
is	O
larger	O
than	O
the	O
number	O
of	O
inputs	O
it	O
is	O
sometimes	O
preferable	O
to	O
use	O
another	O
form	O
of	O
automatic	O
differentiation	O
called	O
forward	O
mode	O
accumulation	O
forward	O
mode	O
computation	O
has	O
been	O
proposed	O
for	O
obtaining	O
real-time	O
computation	O
of	O
gradients	O
in	O
recurrent	O
networks	O
for	O
example	B
this	O
also	O
avoids	O
the	O
need	O
to	O
store	O
the	O
values	O
and	O
gradients	O
for	O
the	O
whole	O
graph	O
trading	O
off	O
computational	O
efficiency	O
for	O
memory	O
the	O
relationship	O
between	O
forward	O
mode	O
and	O
backward	O
mode	O
is	O
analogous	O
to	O
the	O
relationship	O
between	O
left-multiplying	O
versus	O
right-multiplying	O
a	O
sequence	O
of	O
matrices	O
such	O
as	O
williams	O
and	O
zipser	O
abcd	O
where	O
the	O
matrices	O
can	O
be	O
thought	O
of	O
as	O
jacobian	O
matrices	O
for	O
example	B
if	O
d	O
is	O
a	O
column	O
vector	O
while	O
a	O
has	O
many	O
rows	O
this	O
corresponds	O
to	O
a	O
graph	O
with	O
a	O
single	O
output	O
and	O
many	O
inputs	O
and	O
starting	O
the	O
multiplications	O
from	O
the	O
end	O
and	O
going	O
backwards	O
only	O
requires	O
matrix-vector	O
products	O
this	O
corresponds	O
to	O
the	O
backward	O
mode	O
instead	O
starting	O
to	O
multiply	O
from	O
the	O
left	O
would	O
involve	O
a	O
series	O
of	O
matrix-matrix	O
products	O
which	O
makes	O
the	O
whole	O
computation	O
much	O
more	O
expensive	O
however	O
if	O
a	O
has	O
fewer	O
rows	O
than	O
d	O
has	O
columns	O
it	O
is	O
cheaper	O
to	O
run	O
the	O
multiplications	O
left-to-right	O
corresponding	O
to	O
the	O
forward	O
mode	O
in	O
many	O
communities	O
outside	O
of	O
machine	B
learning	I
it	O
is	O
more	O
common	O
to	O
implement	O
differentiation	O
software	O
that	O
acts	O
directly	O
on	O
traditional	O
programming	O
language	O
code	O
such	O
as	O
python	O
or	O
c	O
code	O
and	O
automatically	O
generates	O
programs	O
that	O
differentiate	O
functions	O
written	O
in	O
these	O
languages	O
in	O
the	O
deep	O
learning	O
community	O
computational	O
graphs	O
are	O
usually	O
represented	O
by	O
explicit	O
data	O
structures	O
created	O
by	O
specialized	O
libraries	O
the	O
specialized	O
approach	O
has	O
the	O
drawback	O
of	O
requiring	O
the	O
library	O
developer	O
to	O
define	O
the	O
bprop	O
methods	O
for	O
every	O
operation	B
and	O
limiting	O
the	O
user	O
of	O
the	O
library	O
to	O
only	O
those	O
operations	O
that	O
have	O
been	O
defined	O
however	O
the	O
specialized	O
approach	O
also	O
has	O
the	O
benefit	O
of	O
allowing	O
customized	O
back-propagation	B
rules	O
to	O
be	O
developed	O
for	O
each	O
operation	B
allowing	O
the	O
developer	O
to	O
improve	O
speed	O
or	O
stability	O
in	O
non-obvious	O
ways	O
that	O
an	O
automatic	O
procedure	O
would	O
presumably	O
be	O
unable	O
to	O
replicate	O
back-propagation	B
is	O
therefore	O
not	O
the	O
only	O
way	O
or	O
the	O
optimal	O
way	O
of	O
computing	O
the	O
gradient	B
but	O
it	O
is	O
a	O
very	O
practical	O
method	O
that	O
continues	O
to	O
serve	O
the	O
deep	O
learning	O
community	O
very	O
well	O
in	O
the	O
future	O
differentiation	O
technology	O
for	O
deep	O
networks	O
may	O
improve	O
as	O
deep	O
learning	O
practitioners	O
become	O
more	O
aware	O
of	O
advances	O
in	O
the	O
broader	O
field	O
of	O
automatic	O
differentiation	O
chapter	O
deep	O
feedforward	O
networks	O
higher-order	O
derivatives	O
some	O
software	O
frameworks	O
support	O
the	O
use	O
of	O
higher-order	O
derivatives	O
among	O
the	O
deep	O
learning	O
software	O
frameworks	O
this	O
includes	O
at	O
least	O
theano	O
and	O
tensorflow	O
these	O
libraries	O
use	O
the	O
same	O
kind	O
of	O
data	O
structure	O
to	O
describe	O
the	O
expressions	O
for	O
derivatives	O
as	O
they	O
use	O
to	O
describe	O
the	O
original	O
function	O
being	O
differentiated	O
this	O
means	O
that	O
the	O
symbolic	O
differentiation	O
machinery	O
can	O
be	O
applied	O
to	O
derivatives	O
in	O
the	O
context	O
of	O
deep	O
learning	O
it	O
is	O
rare	O
to	O
compute	O
a	O
single	O
second	B
derivative	B
of	O
a	O
scalar	O
function	O
instead	O
we	O
are	O
usually	O
interested	O
in	O
properties	O
of	O
the	O
hessian	B
n	O
matrix	O
if	O
we	O
have	O
a	O
function	O
f	O
r	O
r	O
then	O
the	O
hessian	B
matrix	O
is	O
of	O
size	O
n	O
n	O
in	O
typical	O
deep	O
learning	O
applications	O
n	O
will	O
be	O
the	O
number	O
of	O
parameters	O
in	O
the	O
model	O
which	O
could	O
easily	O
number	O
in	O
the	O
billions	O
the	O
entire	O
hessian	B
matrix	O
is	O
thus	O
infeasible	O
to	O
even	O
represent	O
instead	O
of	O
explicitly	O
computing	O
the	O
hessian	B
the	O
typical	O
deep	O
learning	O
approach	O
is	O
to	O
use	O
krylov	B
methods	I
krylov	B
methods	I
are	O
a	O
set	O
of	O
iterative	O
techniques	O
for	O
performing	O
various	O
operations	O
like	O
approximately	O
inverting	O
a	O
matrix	O
or	O
finding	O
approximations	O
to	O
its	O
eigenvectors	O
or	O
eigenvalues	O
without	O
using	O
any	O
operation	B
other	O
than	O
matrix-vector	O
products	O
in	O
order	O
to	O
use	O
krylov	B
methods	I
on	O
the	O
hessian	B
we	O
only	O
need	O
to	O
be	O
able	O
to	O
compute	O
the	O
product	O
between	O
the	O
hessian	B
matrix	O
h	O
and	O
an	O
arbitrary	O
vector	O
v	O
a	O
straightforward	O
technique	O
for	O
doing	O
so	O
is	O
to	O
compute	O
christianson	O
hv	O
x	O
xf	O
x	O
v	O
both	O
of	O
the	O
gradient	B
computations	O
in	O
this	O
expression	O
may	O
be	O
computed	O
automatically	O
by	O
the	O
appropriate	O
software	O
library	O
note	O
that	O
the	O
outer	O
gradient	B
expression	O
takes	O
the	O
gradient	B
of	O
a	O
function	O
of	O
the	O
inner	O
gradient	B
expression	O
if	O
v	O
is	O
itself	O
a	O
vector	O
produced	O
by	O
a	O
computational	B
graph	I
it	O
is	O
important	O
to	O
specify	O
that	O
the	O
automatic	O
differentiation	O
software	O
should	O
not	O
differentiate	O
through	O
the	O
graph	O
that	O
produced	O
while	O
computing	O
the	O
hessian	B
is	O
usually	O
not	O
advisable	O
it	O
is	O
possible	O
to	O
do	O
with	O
for	O
all	O
i	O
n	O
where	O
hessian	B
vector	O
products	O
one	O
simply	O
computes	O
he	O
e	O
is	O
the	O
one-hot	O
vector	O
with	O
e	O
i	O
and	O
all	O
other	O
entries	O
equal	O
to	O
historical	O
notes	O
feedforward	O
networks	O
can	O
be	O
seen	O
as	O
efficient	O
nonlinear	O
function	O
approximators	O
based	O
on	O
using	O
gradient	B
descent	O
to	O
minimize	O
the	O
error	O
in	O
a	O
function	O
approximation	O
chapter	O
deep	O
feedforward	O
networks	O
from	O
this	O
point	O
of	O
view	O
the	O
modern	O
feedforward	O
network	O
is	O
the	O
culmination	O
of	O
centuries	O
of	O
progress	O
on	O
the	O
general	O
function	O
approximation	O
task	O
the	O
chain	O
rule	O
that	O
underlies	O
the	O
back-propagation	B
algorithm	O
was	O
invented	O
calculus	O
and	O
algebra	O
have	O
in	O
the	O
century	O
long	O
been	O
used	O
to	O
solve	O
optimization	O
problems	O
in	O
closed	O
form	O
but	O
gradient	B
descent	O
was	O
not	O
introduced	O
as	O
a	O
technique	O
for	O
iteratively	O
approximating	O
the	O
solution	O
to	O
optimization	O
problems	O
until	O
the	O
century	O
leibniz	O
l	O
h	O
pital	O
beginning	O
in	O
the	O
these	O
function	O
approximation	O
techniques	O
were	O
used	O
to	O
motivate	O
machine	B
learning	I
models	O
such	O
as	O
the	O
perceptron	O
however	O
the	O
earliest	O
models	O
were	O
based	O
on	O
linear	O
models	O
critics	O
including	O
marvin	O
minsky	O
pointed	O
out	O
several	O
of	O
the	O
flaws	O
of	O
the	O
linear	O
model	O
family	O
such	O
as	O
its	O
inability	O
to	O
learn	O
the	O
xor	O
function	O
which	O
led	O
to	O
a	O
backlash	O
against	O
the	O
entire	O
neural	B
network	I
approach	O
linnainmaa	O
werbos	O
learning	O
nonlinear	O
functions	O
required	O
the	O
development	O
of	O
a	O
multilayer	B
perceptron	I
and	O
a	O
means	O
of	O
computing	O
the	O
gradient	B
through	O
such	O
a	O
model	O
efficient	O
applications	O
of	O
the	O
chain	O
rule	O
based	O
on	O
dynamic	O
programming	O
began	O
to	O
appear	O
in	O
the	O
and	O
mostly	O
for	O
control	O
applications	O
kelley	O
bryson	O
and	O
denham	O
dreyfus	O
bryson	O
and	O
ho	O
dreyfus	O
but	O
also	O
for	O
sensitivity	O
analysis	O
proposed	O
applying	O
these	O
techniques	O
to	O
training	O
artificial	O
neural	O
networks	O
the	O
idea	O
was	O
finally	O
developed	O
in	O
practice	O
after	O
being	O
independently	O
rediscovered	O
in	O
different	O
ways	O
lecun	O
parker	O
rumelhart	O
the	O
book	O
parallel	B
distributed	I
processing	I
presented	O
the	O
results	O
of	O
some	O
of	O
the	O
first	O
successful	O
experiments	O
with	O
back-propagation	B
in	O
a	O
chapter	O
that	O
contributed	O
greatly	O
to	O
the	O
popularization	O
of	O
back-propagation	B
and	O
initiated	O
a	O
very	O
active	O
period	O
of	O
research	O
in	O
multi-layer	O
neural	O
networks	O
however	O
the	O
ideas	O
put	O
forward	O
by	O
the	O
authors	O
of	O
that	O
book	O
and	O
in	O
particular	O
by	O
rumelhart	O
and	O
hinton	O
go	O
much	O
beyond	O
back-propagation	B
they	O
include	O
crucial	O
ideas	O
about	O
the	O
possible	O
computational	O
implementation	O
of	O
several	O
central	O
aspects	O
of	O
cognition	O
and	O
learning	O
which	O
came	O
under	O
the	O
name	O
of	O
connectionism	B
because	O
of	O
the	O
importance	O
this	O
school	O
of	O
thought	O
places	O
on	O
the	O
connections	O
between	O
neurons	O
as	O
the	O
locus	O
of	O
learning	O
and	O
memory	O
in	O
particular	O
these	O
ideas	O
include	O
the	O
notion	O
of	O
distributed	O
representation	O
et	O
al	O
rumelhart	O
et	O
al	O
et	O
al	O
following	O
the	O
success	O
of	O
back-propagation	B
neural	B
network	I
research	O
gained	O
popularity	O
and	O
reached	O
a	O
peak	O
in	O
the	O
early	O
afterwards	O
other	O
machine	B
learning	I
techniques	O
became	O
more	O
popular	O
until	O
the	O
modern	O
deep	O
learning	O
renaissance	O
that	O
began	O
in	O
the	O
core	O
ideas	O
behind	O
modern	O
feedforward	O
networks	O
have	O
not	O
changed	O
substantially	O
since	O
the	O
the	O
same	O
back-propagation	B
algorithm	O
and	O
the	O
same	O
chapter	O
deep	O
feedforward	O
networks	O
approaches	O
to	O
gradient	B
descent	O
are	O
still	O
in	O
use	O
most	O
of	O
the	O
improvement	O
in	O
neural	B
network	I
performance	O
from	O
to	O
can	O
be	O
attributed	O
to	O
two	O
factors	O
first	O
larger	O
datasets	O
have	O
reduced	O
the	O
degree	O
to	O
which	O
statistical	O
generalization	B
is	O
a	O
challenge	B
for	O
neural	O
networks	O
second	O
neural	O
networks	O
have	O
become	O
much	O
larger	O
due	O
to	O
more	O
powerful	O
computers	O
and	O
better	O
software	O
infrastructure	O
however	O
a	O
small	O
number	O
of	O
algorithmic	O
changes	O
have	O
improved	O
the	O
performance	O
of	O
neural	O
networks	O
noticeably	O
one	O
of	O
these	O
algorithmic	O
changes	O
was	O
the	O
replacement	O
of	O
mean	B
squared	I
error	I
with	O
the	O
cross-entropy	B
family	O
of	O
loss	O
functions	O
mean	B
squared	I
error	I
was	O
popular	O
in	O
the	O
and	O
but	O
was	O
gradually	O
replaced	O
by	O
cross-entropy	B
losses	O
and	O
the	O
principle	O
of	O
maximum	B
likelihood	I
as	O
ideas	O
spread	O
between	O
the	O
statistics	O
community	O
and	O
the	O
machine	B
learning	I
community	O
the	O
use	O
of	O
cross-entropy	B
losses	O
greatly	O
improved	O
the	O
performance	O
of	O
models	O
with	O
sigmoid	O
and	O
softmax	O
outputs	O
which	O
had	O
previously	O
suffered	O
from	O
saturation	O
and	O
slow	O
learning	O
when	O
using	O
the	O
mean	B
squared	I
error	I
loss	O
z	O
the	O
other	O
major	O
algorithmic	O
change	O
that	O
has	O
greatly	O
improved	O
the	O
performance	O
of	O
feedforward	O
networks	O
was	O
the	O
replacement	O
of	O
sigmoid	O
hidden	O
units	O
with	O
piecewise	O
linear	O
hidden	O
units	O
such	O
as	O
rectified	O
linear	O
units	O
rectification	O
using	O
the	O
max	O
function	O
was	O
introduced	O
in	O
early	O
neural	B
network	I
models	O
and	O
dates	O
back	O
at	O
least	O
as	O
far	O
as	O
the	O
cognitron	O
and	O
neocognitron	O
these	O
early	O
models	O
did	O
not	O
use	O
rectified	O
linear	O
units	O
but	O
instead	O
applied	O
rectification	O
to	O
nonlinear	O
functions	O
despite	O
the	O
early	O
popularity	O
of	O
rectification	O
rectification	O
was	O
largely	O
replaced	O
by	O
sigmoids	O
in	O
the	O
perhaps	O
because	O
sigmoids	O
perform	O
better	O
when	O
neural	O
networks	O
are	O
very	O
small	O
as	O
of	O
the	O
early	O
rectified	O
linear	O
units	O
were	O
avoided	O
due	O
to	O
a	O
somewhat	O
superstitious	O
belief	O
that	O
activation	O
functions	O
with	O
non-differentiable	O
points	O
must	O
be	O
avoided	O
this	O
began	O
to	O
change	O
in	O
about	O
jarrett	O
observed	O
that	O
using	O
a	O
rectifying	O
nonlinearity	O
is	O
the	O
single	O
most	O
important	O
factor	O
in	O
improving	O
the	O
performance	O
of	O
a	O
recognition	O
system	O
among	O
several	O
different	O
factors	O
of	O
neural	B
network	I
architecture	O
design	O
et	O
al	O
for	O
small	O
datasets	O
jarrett	O
et	O
al	O
observed	O
that	O
using	O
rectifying	O
nonlinearities	O
is	O
even	O
more	O
important	O
than	O
learning	O
the	O
weights	B
of	O
the	O
hidden	O
layers	O
random	O
weights	B
are	O
sufficient	O
to	O
propagate	O
useful	O
information	O
through	O
a	O
rectified	O
linear	O
network	O
allowing	O
the	O
classifier	O
layer	O
at	O
the	O
top	O
to	O
learn	O
how	O
to	O
map	O
different	O
feature	B
vectors	O
to	O
class	O
identities	O
when	O
more	O
data	O
is	O
available	O
learning	O
begins	O
to	O
extract	O
enough	O
useful	O
knowledge	O
to	O
exceed	O
the	O
performance	O
of	O
randomly	O
chosen	O
parameters	O
glorot	O
et	O
al	O
showed	O
that	O
learning	O
is	O
far	O
easier	O
in	O
deep	O
rectified	O
linear	O
networks	O
than	O
in	O
deep	O
networks	O
that	O
have	O
curvature	O
or	O
two-sided	O
saturation	O
in	O
their	O
activation	O
functions	O
chapter	O
deep	O
feedforward	O
networks	O
glorot	O
et	O
al	O
rectified	O
linear	O
units	O
are	O
also	O
of	O
historical	O
interest	O
because	O
they	O
show	O
that	O
neuroscience	B
has	O
continued	O
to	O
have	O
an	O
influence	O
on	O
the	O
development	O
of	O
deep	O
learning	O
algorithms	O
motivate	O
rectified	O
linear	O
units	O
from	O
biological	O
considerations	O
the	O
half-rectifying	O
nonlinearity	O
was	O
intended	O
to	O
capture	O
these	O
properties	O
of	O
biological	O
neurons	O
for	O
some	O
inputs	O
biological	O
neurons	O
are	O
completely	O
inactive	O
for	O
some	O
inputs	O
a	O
biological	O
neuron	O
s	O
output	O
is	O
proportional	O
to	O
its	O
input	O
most	O
of	O
the	O
time	O
biological	O
neurons	O
operate	O
in	O
the	O
regime	O
where	O
they	O
are	O
inactive	O
they	O
should	O
have	O
sparse	O
activations	O
when	O
the	O
modern	O
resurgence	O
of	O
deep	O
learning	O
began	O
in	O
feedforward	O
networks	O
continued	O
to	O
have	O
a	O
bad	O
reputation	O
from	O
about	O
it	O
was	O
widely	O
believed	O
that	O
feedforward	O
networks	O
would	O
not	O
perform	O
well	O
unless	O
they	O
were	O
assisted	O
by	O
other	O
models	O
such	O
as	O
probabilistic	O
models	O
today	O
it	O
is	O
now	O
known	O
that	O
with	O
the	O
right	O
resources	O
and	O
engineering	O
practices	O
feedforward	O
networks	O
perform	O
very	O
well	O
today	O
gradient-based	O
learning	O
in	O
feedforward	O
networks	O
is	O
used	O
as	O
a	O
tool	O
to	O
develop	O
probabilistic	O
models	O
such	O
as	O
the	O
variational	O
autoencoder	O
and	O
generative	O
adversarial	O
networks	O
described	O
in	O
chapter	O
rather	O
than	O
being	O
viewed	O
as	O
an	O
unreliable	O
technology	O
that	O
must	O
be	O
supported	O
by	O
other	O
techniques	O
gradient-based	O
learning	O
in	O
feedforward	O
networks	O
has	O
been	O
viewed	O
since	O
as	O
a	O
powerful	O
technology	O
that	O
may	O
be	O
applied	O
to	O
many	O
other	O
machine	B
learning	I
tasks	O
in	O
the	O
community	O
used	O
unsupervised	O
learning	O
to	O
support	O
supervised	B
learning	I
and	O
now	O
ironically	O
it	O
is	O
more	O
common	O
to	O
use	O
supervised	B
learning	I
to	O
support	O
unsupervised	O
learning	O
feedforward	O
networks	O
continue	O
to	O
have	O
unfulfilled	O
potential	O
in	O
the	O
future	O
we	O
expect	O
they	O
will	O
be	O
applied	O
to	O
many	O
more	O
tasks	O
and	O
that	O
advances	O
in	O
optimization	O
algorithms	O
and	O
model	O
design	O
will	O
improve	O
their	O
performance	O
even	O
further	O
this	O
chapter	O
has	O
primarily	O
described	O
the	O
neural	B
network	I
family	O
of	O
models	O
in	O
the	O
subsequent	O
chapters	O
we	O
turn	O
to	O
how	O
to	O
use	O
these	O
models	O
how	O
to	O
regularize	O
and	O
train	O
them	O
chapter	O
regularization	O
for	O
deep	O
learning	O
a	O
central	O
problem	O
in	O
machine	B
learning	I
is	O
how	O
to	O
make	O
an	O
algorithm	O
that	O
will	O
perform	O
well	O
not	O
just	O
on	O
the	O
training	O
data	O
but	O
also	O
on	O
new	O
inputs	O
many	O
strategies	O
used	O
in	O
machine	B
learning	I
are	O
explicitly	O
designed	O
to	O
reduce	O
the	O
test	O
error	O
possibly	O
at	O
the	O
expense	O
of	O
increased	O
training	B
error	I
these	O
strategies	O
are	O
known	O
collectively	O
as	O
regularization	O
as	O
we	O
will	O
see	O
there	O
are	O
a	O
great	O
many	O
forms	O
of	O
regularization	O
available	O
to	O
the	O
deep	O
learning	O
practitioner	O
in	O
fact	O
developing	O
more	O
effective	O
regularization	O
strategies	O
has	O
been	O
one	O
of	O
the	O
major	O
research	O
efforts	O
in	O
the	O
field	O
chapter	O
introduced	O
the	O
basic	O
concepts	O
of	O
generalization	B
underfitting	O
overfitting	O
bias	O
variance	O
and	O
regularization	O
if	O
you	O
are	O
not	O
already	O
familiar	O
with	O
these	O
notions	O
please	O
refer	O
to	O
that	O
chapter	O
before	O
continuing	O
with	O
this	O
one	O
in	O
this	O
chapter	O
we	O
describe	O
regularization	O
in	O
more	O
detail	O
focusing	O
on	O
regularization	O
strategies	O
for	O
deep	O
models	O
or	O
models	O
that	O
may	O
be	O
used	O
as	O
building	O
blocks	O
to	O
form	O
deep	O
models	O
some	O
sections	O
of	O
this	O
chapter	O
deal	O
with	O
standard	O
concepts	O
in	O
machine	B
learning	I
if	O
you	O
are	O
already	O
familiar	O
with	O
these	O
concepts	O
feel	O
free	O
to	O
skip	O
the	O
relevant	O
sections	O
however	O
most	O
of	O
this	O
chapter	O
is	O
concerned	O
with	O
the	O
extension	O
of	O
these	O
basic	O
concepts	O
to	O
the	O
particular	O
case	O
of	O
neural	O
networks	O
in	O
section	O
we	O
defined	O
regularization	O
as	O
any	O
modification	O
we	O
make	O
to	O
a	O
learning	O
algorithm	O
that	O
is	O
intended	O
to	O
reduce	O
its	O
generalization	B
error	O
but	O
not	O
its	O
training	B
error	I
there	O
are	O
many	O
regularization	O
strategies	O
some	O
put	O
extra	O
constraints	O
on	O
a	O
machine	B
learning	I
model	O
such	O
as	O
adding	O
restrictions	O
on	O
the	O
parameter	O
values	O
some	O
add	O
extra	O
terms	O
in	O
the	O
objective	B
function	I
that	O
can	O
be	O
thought	O
of	O
as	O
corresponding	O
to	O
a	O
soft	O
constraint	O
on	O
the	O
parameter	O
values	O
if	O
chosen	O
carefully	O
these	O
extra	O
constraints	O
and	O
penalties	O
can	O
lead	O
to	O
improved	O
performance	O
chapter	O
regularization	O
for	O
deep	O
learning	O
on	O
the	O
test	B
set	I
sometimes	O
these	O
constraints	O
and	O
penalties	O
are	O
designed	O
to	O
encode	O
specific	O
kinds	O
of	O
prior	O
knowledge	O
other	O
times	O
these	O
constraints	O
and	O
penalties	O
are	O
designed	O
to	O
express	O
a	O
generic	O
preference	O
for	O
a	O
simpler	O
model	O
class	O
in	O
order	O
to	O
promote	O
generalization	B
sometimes	O
penalties	O
and	O
constraints	O
are	O
necessary	O
to	O
make	O
an	O
underdetermined	O
problem	O
determined	O
other	O
forms	O
of	O
regularization	O
known	O
as	O
ensemble	B
methods	I
combine	O
multiple	O
hypotheses	O
that	O
explain	O
the	O
training	O
data	O
in	O
the	O
context	O
of	O
deep	O
learning	O
most	O
regularization	O
strategies	O
are	O
based	O
on	O
regularizing	O
estimators	O
regularization	O
of	O
an	O
estimator	O
works	O
by	O
trading	O
increased	O
bias	O
for	O
reduced	O
variance	O
an	O
effective	O
regularizer	B
is	O
one	O
that	O
makes	O
a	O
profitable	O
trade	O
reducing	O
variance	O
significantly	O
while	O
not	O
overly	O
increasing	O
the	O
bias	O
when	O
we	O
discussed	O
generalization	B
and	O
overfitting	O
in	O
chapter	O
we	O
focused	O
on	O
three	O
situations	O
where	O
the	O
model	O
family	O
being	O
trained	O
either	O
excluded	O
the	O
true	O
data	B
generating	I
process	I
corresponding	O
to	O
underfitting	O
and	O
inducing	O
bias	O
or	O
matched	O
the	O
true	O
data	B
generating	I
process	I
or	O
included	O
the	O
generating	O
process	O
but	O
also	O
many	O
other	O
possible	O
generating	O
processes	O
the	O
overfitting	O
regime	O
where	O
variance	O
rather	O
than	O
bias	O
dominates	O
the	O
estimation	O
error	O
the	O
goal	O
of	O
regularization	O
is	O
to	O
take	O
a	O
model	O
from	O
the	O
third	O
regime	O
into	O
the	O
second	O
regime	O
in	O
practice	O
an	O
overly	O
complex	O
model	O
family	O
does	O
not	O
necessarily	O
include	O
the	O
target	O
function	O
or	O
the	O
true	O
data	B
generating	I
process	I
or	O
even	O
a	O
close	O
approximation	O
of	O
either	O
we	O
almost	O
never	O
have	O
access	O
to	O
the	O
true	O
data	B
generating	I
process	I
so	O
we	O
can	O
never	O
know	O
for	O
sure	O
if	O
the	O
model	O
family	O
being	O
estimated	O
includes	O
the	O
generating	O
process	O
or	O
not	O
however	O
most	O
applications	O
of	O
deep	O
learning	O
algorithms	O
are	O
to	O
domains	O
where	O
the	O
true	O
data	B
generating	I
process	I
is	O
almost	O
certainly	O
outside	O
the	O
model	O
family	O
deep	O
learning	O
algorithms	O
are	O
typically	O
applied	O
to	O
extremely	O
complicated	O
domains	O
such	O
as	O
images	O
audio	O
sequences	O
and	O
text	O
for	O
which	O
the	O
true	O
generation	O
process	O
essentially	O
involves	O
simulating	O
the	O
entire	O
universe	O
to	O
some	O
extent	O
we	O
are	O
always	O
trying	O
to	O
fit	O
a	O
square	O
peg	O
data	B
generating	I
process	I
into	O
a	O
round	O
hole	O
model	O
family	O
what	O
this	O
means	O
is	O
that	O
controlling	O
the	O
complexity	O
of	O
the	O
model	O
is	O
not	O
a	O
simple	O
matter	O
of	O
finding	O
the	O
model	O
of	O
the	O
right	O
size	O
with	O
the	O
right	O
number	O
of	O
parameters	O
instead	O
we	O
might	O
find	O
and	O
indeed	O
in	O
practical	O
deep	O
learning	O
scenarios	O
we	O
almost	O
always	O
do	O
find	O
that	O
the	O
best	O
fitting	O
model	O
the	O
sense	O
of	O
minimizing	O
generalization	B
error	O
is	O
a	O
large	O
model	O
that	O
has	O
been	O
regularized	O
appropriately	O
we	O
now	O
review	O
several	O
strategies	O
for	O
how	O
to	O
create	O
such	O
a	O
large	O
deep	O
regularized	O
model	O
chapter	O
regularization	O
for	O
deep	O
learning	O
parameter	O
norm	O
penalties	O
regularization	O
has	O
been	O
used	O
for	O
decades	O
prior	O
to	O
the	O
advent	O
of	O
deep	O
learning	O
linear	O
models	O
such	O
as	O
linear	O
regression	B
and	O
logistic	O
regression	B
allow	O
simple	O
straightforward	O
and	O
effective	O
regularization	O
strategies	O
many	O
regularization	O
approaches	O
are	O
based	O
on	O
limiting	O
the	O
capacity	O
of	O
models	O
such	O
as	O
neural	O
networks	O
linear	O
regression	B
or	O
logistic	O
regression	B
by	O
adding	O
a	O
parameter	O
norm	O
penalty	O
to	O
the	O
objective	B
function	I
j	O
we	O
denote	O
the	O
regularized	O
objective	B
function	I
by	O
j	O
j	O
x	O
y	O
x	O
y	O
j	O
relative	O
to	O
the	O
standard	O
objective	B
function	I
where	O
is	O
a	O
hyperparameter	O
that	O
weights	B
the	O
relative	O
contribution	O
of	O
the	O
j	O
setting	O
to	O
norm	O
penalty	O
term	O
results	O
in	O
no	O
regularization	O
larger	O
values	O
of	O
correspond	O
to	O
more	O
regularization	O
when	O
our	O
training	O
algorithm	O
minimizes	O
the	O
regularized	O
objective	B
function	I
j	O
it	O
will	O
decrease	O
both	O
the	O
original	O
objective	O
j	O
on	O
the	O
training	O
data	O
and	O
some	O
measure	O
of	O
the	O
size	O
of	O
the	O
parameters	O
some	O
subset	O
of	O
the	O
parameters	O
different	O
choices	O
for	O
the	O
parameter	O
norm	O
can	O
result	O
in	O
different	O
solutions	O
being	O
preferred	O
in	O
this	O
section	O
we	O
discuss	O
the	O
effects	O
of	O
the	O
various	O
norms	O
when	O
used	O
as	O
penalties	O
on	O
the	O
model	O
parameters	O
only	O
the	O
weights	B
before	O
delving	O
into	O
the	O
regularization	O
behavior	O
of	O
different	O
norms	O
we	O
note	O
that	O
that	O
for	O
neural	O
networks	O
we	O
typically	O
choose	O
to	O
use	O
a	O
parameter	O
norm	O
penalty	O
penalizes	O
of	O
the	O
affine	B
transformation	O
at	O
each	O
layer	O
and	O
leaves	O
the	O
biases	O
unregularized	O
the	O
biases	O
typically	O
require	O
less	O
data	O
to	O
fit	O
accurately	O
than	O
the	O
weights	B
each	O
weight	O
specifies	O
how	O
two	O
variables	O
interact	O
fitting	O
the	O
weight	O
well	O
requires	O
observing	O
both	O
variables	O
in	O
a	O
variety	O
of	O
conditions	O
each	O
bias	O
controls	O
only	O
a	O
single	O
variable	O
this	O
means	O
that	O
we	O
do	O
not	O
induce	O
too	O
much	O
variance	O
by	O
leaving	O
the	O
biases	O
unregularized	O
also	O
regularizing	O
the	O
bias	O
parameters	O
can	O
introduce	O
a	O
significant	O
amount	O
of	O
underfitting	O
we	O
therefore	O
use	O
the	O
vector	O
w	O
to	O
indicate	O
all	O
of	O
the	O
weights	B
that	O
should	O
be	O
affected	O
by	O
a	O
norm	O
penalty	O
while	O
the	O
vector	O
denotes	O
all	O
of	O
the	O
parameters	O
including	O
both	O
w	O
and	O
the	O
unregularized	O
parameters	O
in	O
the	O
context	O
of	O
neural	O
networks	O
it	O
is	O
sometimes	O
desirable	O
to	O
use	O
a	O
separate	O
penalty	O
with	O
a	O
different	O
coefficient	O
for	O
each	O
layer	O
of	O
the	O
network	O
because	O
it	O
can	O
be	O
expensive	O
to	O
search	O
for	O
the	O
correct	O
value	O
of	O
multiple	O
hyperparameters	O
it	O
is	O
still	O
reasonable	O
to	O
use	O
the	O
same	O
weight	O
decay	O
at	O
all	O
layers	O
just	O
to	O
reduce	O
the	O
size	O
of	O
search	O
space	O
chapter	O
regularization	O
for	O
deep	O
learning	O
l	O
parameter	O
regularization	O
we	O
have	O
already	O
seen	O
in	O
section	O
one	O
of	O
the	O
simplest	O
and	O
most	O
common	O
kinds	O
of	O
parameter	O
norm	O
penalty	O
the	O
parameter	O
norm	O
penalty	O
commonly	O
known	O
as	O
weight	O
decay	O
this	O
regularization	O
strategy	O
drives	O
the	O
weights	B
closer	O
to	O
the	O
by	O
adding	O
a	O
regularization	O
term	O
to	O
the	O
objective	B
function	I
in	O
other	O
academic	O
communities	O
regularization	O
is	O
also	O
known	O
as	O
ridge	O
regression	B
or	O
tikhonov	O
regularization	O
w	O
we	O
can	O
gain	O
some	O
insight	O
into	O
the	O
behavior	O
of	O
weight	O
decay	O
regularization	O
by	O
studying	O
the	O
gradient	B
of	O
the	O
regularized	O
objective	B
function	I
to	O
simplify	O
the	O
presentation	O
we	O
assume	O
no	O
bias	B
parameter	I
so	O
is	O
just	O
w	O
such	O
a	O
model	O
has	O
the	O
following	O
total	O
objective	B
function	I
j	O
x	O
y	O
w	O
w	O
w	O
x	O
y	O
with	O
the	O
corresponding	O
parameter	O
gradient	B
w	O
j	O
x	O
y	O
w	O
wj	O
x	O
y	O
to	O
take	O
a	O
single	O
gradient	B
step	O
to	O
update	O
the	O
weights	B
we	O
perform	O
this	O
update	O
w	O
w	O
w	O
wj	O
x	O
y	O
written	O
another	O
way	O
the	O
update	O
is	O
w	O
w	O
wj	O
x	O
y	O
we	O
can	O
see	O
that	O
the	O
addition	O
of	O
the	O
weight	O
decay	O
term	O
has	O
modified	O
the	O
learning	O
rule	O
to	O
multiplicatively	O
shrink	O
the	O
weight	O
vector	O
by	O
a	O
constant	O
factor	O
on	O
each	O
step	O
just	O
before	O
performing	O
the	O
usual	O
gradient	B
update	O
this	O
describes	O
what	O
happens	O
in	O
a	O
single	O
step	O
but	O
what	O
happens	O
over	O
the	O
entire	O
course	O
of	O
training	O
we	O
will	O
further	O
simplify	O
the	O
analysis	O
by	O
making	O
a	O
quadratic	O
approximation	O
to	O
the	O
objective	B
function	I
in	O
the	O
neighborhood	O
of	O
the	O
value	O
of	O
the	O
weights	B
that	O
obtains	O
minimal	O
unregularized	O
training	O
cost	O
w	O
arg	O
minw	O
jw	O
if	O
the	O
objective	B
function	I
is	O
truly	O
quadratic	O
as	O
in	O
the	O
case	O
of	O
fitting	O
a	O
linear	O
regression	B
model	O
with	O
generally	O
we	O
could	O
regularize	O
the	O
parameters	O
to	O
be	O
near	O
any	O
specific	O
point	O
in	O
space	O
and	O
surprisingly	O
still	O
get	O
a	O
regularization	O
effect	O
but	O
better	O
results	O
will	O
be	O
obtained	O
for	O
a	O
value	O
closer	O
to	O
the	O
true	O
one	O
with	O
zero	O
being	O
a	O
default	O
value	O
that	O
makes	O
sense	O
when	O
we	O
do	O
not	O
know	O
if	O
the	O
correct	O
value	O
should	O
be	O
positive	O
or	O
negative	O
since	O
it	O
is	O
far	O
more	O
common	O
to	O
regularize	O
the	O
model	O
parameters	O
towards	O
zero	O
we	O
will	O
focus	O
on	O
this	O
special	O
case	O
in	O
our	O
exposition	O
chapter	O
regularization	O
for	O
deep	O
learning	O
mean	B
squared	I
error	I
then	O
the	O
approximation	O
is	O
perfect	O
the	O
approximation	O
j	O
is	O
given	O
by	O
j	O
j	O
w	O
h	O
w	O
w	O
where	O
h	O
is	O
the	O
hessian	B
matrix	O
of	O
j	O
with	O
respect	O
to	O
w	O
evaluated	O
at	O
w	O
no	O
first-order	O
term	O
in	O
this	O
quadratic	O
approximation	O
because	O
w	O
minimum	O
where	O
the	O
gradient	B
vanishes	O
likewise	O
because	O
w	O
minimum	O
of	O
is	O
positive	O
semidefinite	O
we	O
can	O
conclude	O
that	O
there	O
is	O
is	O
defined	O
to	O
be	O
a	O
is	O
the	O
location	O
of	O
a	O
h	O
j	O
the	O
minimum	O
of	O
j	O
occurs	O
where	O
its	O
gradient	B
w	O
h	O
w	O
w	O
j	O
is	O
equal	O
to	O
w	O
to	O
study	O
the	O
effect	O
of	O
weight	O
decay	O
we	O
modify	O
equation	O
by	O
adding	O
the	O
weight	O
decay	O
gradient	B
we	O
can	O
now	O
solve	O
for	O
the	O
minimum	O
of	O
the	O
regularized	O
version	O
of	O
j	O
we	O
use	O
the	O
variable	O
w	O
to	O
represent	O
the	O
location	O
of	O
the	O
minimum	O
w	O
h	O
w	O
w	O
h	O
i	O
w	O
hw	O
w	O
h	O
i	O
as	O
approaches	O
the	O
regularized	O
solution	O
w	O
approaches	O
w	O
but	O
what	O
happens	O
as	O
grows	O
because	O
h	O
is	O
real	O
and	O
symmetric	O
we	O
can	O
decompose	O
it	O
into	O
a	O
diagonal	B
matrix	I
and	O
an	O
orthonormal	O
basis	O
of	O
eigenvectors	O
q	O
such	O
that	O
h	O
q	O
q	O
we	O
obtain	O
q	O
applying	O
the	O
decomposition	O
to	O
equation	O
w	O
q	O
q	O
q	O
i	O
i	O
q	O
q	O
q	O
q	O
w	O
w	O
w	O
q	O
i	O
we	O
see	O
that	O
the	O
effect	O
of	O
weight	O
decay	O
is	O
to	O
rescale	O
w	O
the	O
eigenvectors	O
of	O
h	O
specifically	O
the	O
component	O
of	O
w	O
i-th	O
eigenvector	B
of	O
h	O
is	O
rescaled	O
by	O
a	O
factor	O
of	O
how	O
this	O
kind	O
of	O
scaling	O
works	O
first	O
explained	O
in	O
figure	O
i	O
i	O
along	O
the	O
axes	O
defined	O
by	O
that	O
is	O
aligned	O
with	O
the	O
may	O
wish	O
to	O
review	O
along	O
the	O
directions	O
where	O
the	O
eigenvalues	O
of	O
h	O
are	O
relatively	O
large	O
for	O
example	B
the	O
effect	O
of	O
regularization	O
is	O
relatively	O
small	O
however	O
components	O
will	O
be	O
shrunk	O
to	O
have	O
nearly	O
zero	O
magnitude	O
this	O
effect	O
is	O
illustrated	O
where	O
i	O
with	O
i	O
in	O
figure	O
chapter	O
regularization	O
for	O
deep	O
learning	O
w	O
w	O
w	O
figure	O
an	O
illustration	O
of	O
the	O
effect	O
of	O
weight	O
decay	O
regularization	O
on	O
the	O
value	O
of	O
the	O
optimal	O
w	O
the	O
solid	O
ellipses	O
represent	O
contours	O
of	O
equal	O
value	O
of	O
the	O
unregularized	O
objective	O
the	O
dotted	O
circles	O
represent	O
contours	O
of	O
equal	O
value	O
of	O
the	O
regularizer	B
at	O
the	O
point	O
w	O
these	O
competing	O
objectives	O
reach	O
an	O
equilibrium	O
in	O
the	O
first	O
dimension	O
the	O
eigenvalue	B
of	O
the	O
hessian	B
of	O
j	O
is	O
small	O
the	O
objective	B
function	I
does	O
not	O
increase	O
much	O
when	O
moving	O
horizontally	O
away	O
from	O
w	O
because	O
the	O
objective	B
function	I
does	O
not	O
express	O
a	O
strong	O
preference	O
along	O
this	O
direction	O
the	O
regularizer	B
has	O
a	O
strong	O
effect	O
on	O
this	O
axis	O
the	O
regularizer	B
pulls	O
w	O
close	O
to	O
zero	O
in	O
the	O
second	O
dimension	O
the	O
objective	B
function	I
is	O
very	O
sensitive	O
to	O
movements	O
away	O
from	O
w	O
the	O
corresponding	O
eigenvalue	B
is	O
large	O
indicating	O
high	O
curvature	O
as	O
a	O
result	O
weight	O
decay	O
affects	O
the	O
position	O
of	O
relatively	O
little	O
only	O
directions	O
along	O
which	O
the	O
parameters	O
contribute	O
significantly	O
to	O
reducing	O
the	O
objective	B
function	I
are	O
preserved	O
relatively	O
intact	O
in	O
directions	O
that	O
do	O
not	O
contribute	O
to	O
reducing	O
the	O
objective	B
function	I
a	O
small	O
eigenvalue	B
of	O
the	O
hessian	B
tells	O
us	O
that	O
movement	O
in	O
this	O
direction	O
will	O
not	O
significantly	O
increase	O
the	O
gradient	B
components	O
of	O
the	O
weight	O
vector	O
corresponding	O
to	O
such	O
unimportant	O
directions	O
are	O
decayed	O
away	O
through	O
the	O
use	O
of	O
the	O
regularization	O
throughout	O
training	O
so	O
far	O
we	O
have	O
discussed	O
weight	O
decay	O
in	O
terms	O
of	O
its	O
effect	O
on	O
the	O
optimization	O
of	O
an	O
abstract	O
general	O
quadratic	O
cost	O
function	O
how	O
do	O
these	O
effects	O
relate	O
to	O
machine	B
learning	I
in	O
particular	O
we	O
can	O
find	O
out	O
by	O
studying	O
linear	O
regression	B
a	O
model	O
for	O
which	O
the	O
true	O
cost	O
function	O
is	O
quadratic	O
and	O
therefore	O
amenable	O
to	O
the	O
same	O
kind	O
of	O
analysis	O
we	O
have	O
used	O
so	O
far	O
applying	O
the	O
analysis	O
again	O
we	O
will	O
be	O
able	O
to	O
obtain	O
a	O
special	O
case	O
of	O
the	O
same	O
results	O
but	O
with	O
the	O
solution	O
now	O
phrased	O
in	O
terms	O
of	O
the	O
training	O
data	O
for	O
linear	O
regression	B
the	O
cost	O
function	O
is	O
chapter	O
regularization	O
for	O
deep	O
learning	O
the	O
sum	O
of	O
squared	O
errors	O
xw	O
y	O
xw	O
y	O
when	O
we	O
add	O
regularization	O
the	O
objective	B
function	I
changes	O
to	O
xw	O
y	O
xw	O
y	O
w	O
w	O
this	O
changes	O
the	O
normal	O
equations	O
for	O
the	O
solution	O
from	O
w	O
x	O
x	O
y	O
w	O
x	O
x	O
i	O
y	O
to	O
x	O
in	O
equation	O
is	O
proportional	O
to	O
the	O
covariance	B
matrix	I
x	O
the	O
matrix	O
x	O
using	O
regularization	O
replaces	O
this	O
matrix	O
with	O
the	O
new	O
matrix	O
is	O
the	O
same	O
as	O
the	O
original	O
one	O
but	O
with	O
the	O
addition	O
of	O
to	O
the	O
diagonal	O
the	O
diagonal	O
entries	O
of	O
this	O
matrix	O
correspond	O
to	O
the	O
variance	O
of	O
each	O
input	O
feature	B
we	O
can	O
see	O
that	O
regularization	O
causes	O
the	O
learning	O
algorithm	O
to	O
perceive	O
the	O
input	O
x	O
as	O
having	O
higher	O
variance	O
which	O
makes	O
it	O
shrink	O
the	O
weights	B
on	O
features	O
whose	O
covariance	O
with	O
the	O
output	O
target	O
is	O
low	O
compared	O
to	O
this	O
added	O
variance	O
x	O
in	O
equation	O
x	O
i	O
x	O
m	O
l	O
regularization	O
while	O
l	O
weight	O
decay	O
is	O
the	O
most	O
common	O
form	O
of	O
weight	O
decay	O
there	O
are	O
other	O
ways	O
to	O
penalize	O
the	O
size	O
of	O
the	O
model	O
parameters	O
another	O
option	O
is	O
to	O
use	O
l	O
regularization	O
formally	O
regularization	O
on	O
the	O
model	O
parameter	O
w	O
wi	O
w	O
is	O
defined	O
as	O
i	O
that	O
is	O
as	O
the	O
sum	O
of	O
absolute	O
values	O
of	O
the	O
individual	O
we	O
will	O
now	O
discuss	O
the	O
effect	O
of	O
regularization	O
on	O
the	O
simple	O
linear	O
regression	B
model	O
with	O
no	O
bias	B
parameter	I
that	O
we	O
studied	O
in	O
our	O
analysis	O
of	O
regularization	O
in	O
particular	O
we	O
are	O
interested	O
in	O
delineating	O
the	O
differences	O
between	O
and	O
forms	O
with	O
regularization	O
we	O
could	O
regularize	O
the	O
parameters	O
towards	O
a	O
value	O
that	O
is	O
not	O
in	O
that	O
case	O
the	O
regularization	O
would	O
zero	O
but	O
instead	O
towards	O
some	O
parameter	O
value	O
w	O
introduce	O
the	O
term	O
wi	O
w	O
w	O
w	O
i	O
i	O
chapter	O
regularization	O
for	O
deep	O
learning	O
of	O
regularization	O
as	O
with	O
weight	O
decay	O
weight	O
decay	O
controls	O
the	O
strength	O
of	O
the	O
regularization	O
by	O
scaling	O
the	O
penalty	O
thus	O
the	O
regularized	O
objective	B
function	I
j	O
x	O
y	O
is	O
given	O
by	O
w	O
using	O
a	O
positive	O
hyperparameter	O
j	O
x	O
y	O
j	O
w	O
x	O
y	O
with	O
the	O
corresponding	O
gradient	B
sub-gradient	O
w	O
j	O
x	O
y	O
sign	O
y	O
w	O
wj	O
where	O
sign	O
is	O
simply	O
the	O
sign	O
of	O
w	O
applied	O
element-wise	O
by	O
inspecting	O
equation	O
we	O
can	O
see	O
immediately	O
that	O
the	O
effect	O
of	O
l	O
regularization	O
is	O
quite	O
different	O
from	O
that	O
of	O
regularization	O
specifically	O
we	O
can	O
see	O
that	O
the	O
regularization	O
contribution	O
to	O
the	O
gradient	B
no	O
longer	O
scales	O
linearly	O
with	O
each	O
wi	O
instead	O
it	O
is	O
a	O
constant	O
factor	O
with	O
a	O
sign	O
equal	O
to	O
signwi	O
one	O
consequence	O
of	O
this	O
form	O
of	O
the	O
gradient	B
is	O
that	O
we	O
will	O
not	O
necessarily	O
see	O
clean	O
w	O
as	O
we	O
did	O
for	O
l	O
algebraic	O
solutions	O
to	O
quadratic	O
approximations	O
of	O
j	O
y	O
regularization	O
our	O
simple	O
linear	O
model	O
has	O
a	O
quadratic	O
cost	O
function	O
that	O
we	O
can	O
represent	O
via	O
its	O
taylor	O
series	O
alternately	O
we	O
could	O
imagine	O
that	O
this	O
is	O
a	O
truncated	O
taylor	O
series	O
approximating	O
the	O
cost	O
function	O
of	O
a	O
more	O
sophisticated	O
model	O
the	O
gradient	B
in	O
this	O
setting	O
is	O
given	O
by	O
w	O
w	O
h	O
w	O
w	O
j	O
where	O
again	O
h	O
is	O
the	O
hessian	B
matrix	O
of	O
with	O
respect	O
to	O
j	O
w	O
evaluated	O
at	O
w	O
because	O
the	O
penalty	O
does	O
not	O
admit	O
clean	O
algebraic	O
expressions	O
in	O
the	O
case	O
of	O
a	O
fully	O
general	O
hessian	B
we	O
will	O
also	O
make	O
the	O
further	O
simplifying	O
assumption	O
that	O
the	O
hessian	B
is	O
diagonal	O
h	O
hnn	O
where	O
each	O
hii	O
this	O
assumption	O
holds	O
if	O
the	O
data	O
for	O
the	O
linear	O
regression	B
problem	O
has	O
been	O
preprocessed	O
to	O
remove	O
all	O
correlation	B
between	O
the	O
input	O
features	O
which	O
may	O
be	O
accomplished	O
using	O
pca	O
our	O
quadratic	O
approximation	O
of	O
the	O
regularized	O
objective	B
function	I
decom	O
poses	O
into	O
a	O
sum	O
over	O
the	O
parameters	O
j	O
x	O
y	O
j	O
y	O
i	O
i	O
w	O
w	O
i	O
h	O
iiwi	O
the	O
problem	O
of	O
minimizing	O
this	O
approximate	O
cost	O
function	O
has	O
an	O
analytical	O
solution	O
each	O
dimension	O
with	O
the	O
following	O
form	O
i	O
i	O
max	O
wi	O
signw	O
w	O
i	O
hii	O
chapter	O
regularization	O
for	O
deep	O
learning	O
consider	O
the	O
situation	O
where	O
w	O
i	O
for	O
all	O
there	O
are	O
two	O
possible	O
outcomes	O
i	O
hii	O
the	O
case	O
where	O
w	O
here	O
the	O
optimal	O
value	O
of	O
wi	O
under	O
the	O
regularized	O
objective	O
is	O
simply	O
wi	O
this	O
occurs	O
because	O
the	O
contribution	O
of	O
jw	O
x	O
y	O
to	O
the	O
regularized	O
objective	O
j	O
x	O
y	O
is	O
overwhelmed	O
in	O
direction	O
i	O
by	O
the	O
regularization	O
which	O
pushes	O
the	O
value	O
of	O
wi	O
to	O
zero	O
i	O
i	O
hii	O
the	O
case	O
where	O
w	O
in	O
this	O
case	O
the	O
regularization	O
does	O
not	O
move	O
the	O
optimal	O
value	O
of	O
wi	O
to	O
zero	O
but	O
instead	O
it	O
just	O
shifts	O
it	O
in	O
that	O
direction	O
by	O
a	O
distance	O
equal	O
to	O
h	O
ii	O
a	O
similar	O
process	O
happens	O
when	O
w	O
negative	O
by	O
hii	O
or	O
i	O
but	O
with	O
the	O
penalty	O
making	O
wi	O
less	O
in	O
comparison	O
to	O
l	O
regularization	O
regularization	O
results	O
in	O
a	O
solution	O
that	O
is	O
more	O
sparse	O
sparsity	O
in	O
this	O
context	O
refers	O
to	O
the	O
fact	O
that	O
some	O
parameters	O
have	O
an	O
optimal	O
value	O
of	O
zero	O
the	O
sparsity	O
of	O
regularization	O
is	O
a	O
qualitatively	O
different	O
behavior	O
than	O
arises	O
with	O
l	O
regularization	O
equation	O
gave	O
the	O
solution	O
w	O
for	O
regularization	O
if	O
we	O
revisit	O
that	O
equation	O
using	O
the	O
assumption	O
of	O
a	O
diagonal	O
and	O
positive	B
definite	I
hessian	B
h	O
that	O
we	O
introduced	O
for	O
our	O
analysis	O
of	O
regularization	O
we	O
find	O
that	O
wi	O
hii	O
i	O
was	O
nonzero	O
then	O
wi	O
remains	O
h	O
ii	O
nonzero	O
this	O
demonstrates	O
that	O
regularization	O
does	O
not	O
cause	O
the	O
parameters	O
to	O
become	O
sparse	O
while	O
regularization	O
may	O
do	O
so	O
for	O
large	O
enough	O
i	O
if	O
w	O
w	O
the	O
sparsity	O
property	O
induced	O
by	O
regularization	O
has	O
been	O
used	O
extensively	O
as	O
a	O
feature	B
selection	I
mechanism	O
feature	B
selection	I
simplifies	O
a	O
machine	B
learning	I
problem	O
by	O
choosing	O
which	O
subset	O
of	O
the	O
available	O
features	O
should	O
be	O
used	O
in	O
particular	O
the	O
well	O
known	O
lasso	O
absolute	O
shrinkage	O
and	O
selection	O
operator	O
model	O
integrates	O
an	O
penalty	O
with	O
a	O
linear	O
model	O
and	O
a	O
least	O
squares	O
cost	O
function	O
the	O
penalty	O
causes	O
a	O
subset	O
of	O
the	O
weights	B
to	O
become	O
zero	O
suggesting	O
that	O
the	O
corresponding	O
features	O
may	O
safely	O
be	O
discarded	O
tibshirani	O
in	O
section	O
we	O
saw	O
that	O
many	O
regularization	O
strategies	O
can	O
be	O
interpreted	O
as	O
map	O
bayesian	O
inference	O
and	O
that	O
in	O
particular	O
regularization	O
is	O
equivalent	O
to	O
map	O
bayesian	O
inference	O
with	O
a	O
gaussian	O
prior	O
on	O
the	O
weights	B
for	O
regularization	O
the	O
penalty	O
used	O
to	O
regularize	O
a	O
cost	O
function	O
is	O
equivalent	O
to	O
the	O
log-prior	O
term	O
that	O
is	O
maximized	O
by	O
map	O
bayesian	O
inference	O
n	O
when	O
the	O
prior	O
is	O
an	O
isotropic	B
laplace	O
distribution	O
wi	O
over	O
w	O
i	O
r	O
n	O
log	O
log	O
p	O
w	O
log	O
laplacew	O
i	O
i	O
w	O
log	O
n	O
chapter	O
regularization	O
for	O
deep	O
learning	O
from	O
the	O
point	O
of	O
view	O
of	O
learning	O
via	O
maximization	O
with	O
respect	O
to	O
w	O
we	O
can	O
ignore	O
the	O
terms	O
because	O
they	O
do	O
not	O
depend	O
on	O
log	O
log	O
w	O
norm	O
penalties	O
as	O
constrained	O
optimization	O
consider	O
the	O
cost	O
function	O
regularized	O
by	O
a	O
parameter	O
norm	O
penalty	O
j	O
x	O
y	O
x	O
y	O
j	O
recall	B
from	O
section	O
that	O
we	O
can	O
minimize	O
a	O
function	O
subject	O
to	O
constraints	O
by	O
constructing	O
a	O
generalized	O
lagrange	O
function	O
consisting	O
of	O
the	O
original	O
objective	B
function	I
plus	O
a	O
set	O
of	O
penalties	O
each	O
penalty	O
is	O
a	O
product	O
between	O
a	O
coefficient	O
called	O
a	O
karush	O
kuhn	O
tucker	O
multiplier	O
and	O
a	O
function	O
representing	O
whether	O
the	O
constraint	O
is	O
satisfied	O
if	O
we	O
wanted	O
to	O
constrain	O
to	O
be	O
less	O
than	O
some	O
constant	O
we	O
could	O
construct	O
a	O
generalized	O
lagrange	O
function	O
k	O
l	O
x	O
y	O
j	O
x	O
y	O
k	O
the	O
solution	O
to	O
the	O
constrained	O
problem	O
is	O
given	O
by	O
arg	O
min	O
max	O
l	O
as	O
described	O
in	O
section	O
solving	O
this	O
problem	O
requires	O
modifying	O
both	O
provides	O
a	O
worked	O
example	B
of	O
linear	O
regression	B
with	O
an	O
l	O
and	O
section	O
constraint	O
many	O
different	O
procedures	O
are	O
possible	O
some	O
may	O
use	O
gradient	B
descent	O
while	O
others	O
may	O
use	O
analytical	O
solutions	O
for	O
where	O
the	O
gradient	B
is	O
zero	O
but	O
in	O
all	O
procedures	O
must	O
increase	O
whenever	O
k	O
and	O
decrease	O
whenever	O
k	O
all	O
positive	O
encourage	O
to	O
shrink	O
the	O
optimal	O
value	O
will	O
encourage	O
become	O
less	O
than	O
to	O
shrink	O
but	O
not	O
so	O
strongly	O
to	O
make	O
k	O
to	O
gain	O
some	O
insight	O
into	O
the	O
effect	O
of	O
the	O
constraint	O
we	O
can	O
fix	O
and	O
view	O
the	O
problem	O
as	O
just	O
a	O
function	O
of	O
l	O
arg	O
min	O
j	O
x	O
y	O
arg	O
min	O
this	O
is	O
exactly	O
the	O
same	O
as	O
the	O
regularized	O
training	O
problem	O
of	O
minimizing	O
j	O
we	O
can	O
thus	O
think	O
of	O
a	O
parameter	O
norm	O
penalty	O
as	O
imposing	O
a	O
constraint	O
on	O
the	O
norm	O
then	O
the	O
weights	B
are	O
constrained	O
to	O
lie	O
in	O
an	O
l	O
weights	B
if	O
norm	O
then	O
the	O
weights	B
are	O
constrained	O
to	O
lie	O
in	O
a	O
region	O
of	O
ball	O
if	O
is	O
the	O
is	O
the	O
chapter	O
regularization	O
for	O
deep	O
learning	O
limited	O
norm	O
usually	O
we	O
do	O
not	O
know	O
the	O
size	O
of	O
the	O
constraint	O
region	O
that	O
we	O
impose	O
by	O
using	O
weight	O
decay	O
with	O
coefficient	O
does	O
not	O
directly	O
tell	O
us	O
the	O
value	O
of	O
k	O
in	O
principle	O
one	O
can	O
solve	O
for	O
k	O
but	O
the	O
relationship	O
between	O
k	O
and	O
depends	O
on	O
the	O
form	O
of	O
j	O
while	O
we	O
do	O
not	O
know	O
the	O
exact	O
size	O
of	O
the	O
constraint	O
region	O
we	O
can	O
control	O
it	O
roughly	O
by	O
increasing	O
or	O
decreasing	O
in	O
order	O
to	O
grow	O
or	O
shrink	O
the	O
constraint	O
region	O
larger	O
will	O
result	O
in	O
a	O
smaller	O
constraint	O
region	O
smaller	O
will	O
result	O
in	O
a	O
larger	O
constraint	O
region	O
because	O
the	O
value	O
of	O
sometimes	O
we	O
may	O
wish	O
to	O
use	O
explicit	O
constraints	O
rather	O
than	O
penalties	O
as	O
described	O
in	O
section	O
we	O
can	O
modify	O
algorithms	O
such	O
as	O
stochastic	O
gradient	B
descent	O
to	O
take	O
a	O
step	O
downhill	O
on	O
j	O
and	O
then	O
project	O
back	O
to	O
the	O
nearest	O
point	O
that	O
satisfies	O
k	O
this	O
can	O
be	O
useful	O
if	O
we	O
have	O
an	O
idea	O
of	O
what	O
value	O
of	O
k	O
is	O
appropriate	O
and	O
do	O
not	O
want	O
to	O
spend	O
time	O
searching	O
for	O
the	O
value	O
of	O
that	O
corresponds	O
to	O
this	O
another	O
reason	O
to	O
use	O
explicit	O
constraints	O
and	O
reprojection	O
rather	O
than	O
enforcing	O
constraints	O
with	O
penalties	O
is	O
that	O
penalties	O
can	O
cause	O
non-convex	O
optimization	O
procedures	O
to	O
get	O
stuck	O
in	O
local	O
minima	O
corresponding	O
to	O
small	O
when	O
training	O
neural	O
networks	O
this	O
usually	O
manifests	O
as	O
neural	O
networks	O
that	O
train	O
with	O
several	O
dead	O
units	O
these	O
are	O
units	O
that	O
do	O
not	O
contribute	O
much	O
to	O
the	O
behavior	O
of	O
the	O
function	O
learned	O
by	O
the	O
network	O
because	O
the	O
weights	B
going	O
into	O
or	O
out	O
of	O
them	O
are	O
all	O
very	O
small	O
when	O
training	O
with	O
a	O
penalty	O
on	O
the	O
norm	O
of	O
the	O
weights	B
these	O
configurations	O
can	O
be	O
locally	O
optimal	O
even	O
if	O
it	O
is	O
possible	O
to	O
significantly	O
reduce	O
j	O
by	O
making	O
the	O
weights	B
larger	O
explicit	O
constraints	O
implemented	O
by	O
re-projection	O
can	O
work	O
much	O
better	O
in	O
these	O
cases	O
because	O
they	O
do	O
not	O
encourage	O
the	O
weights	B
to	O
approach	O
the	O
origin	O
explicit	O
constraints	O
implemented	O
by	O
re-projection	O
only	O
have	O
an	O
effect	O
when	O
the	O
weights	B
become	O
large	O
and	O
attempt	O
to	O
leave	O
the	O
constraint	O
region	O
finally	O
explicit	O
constraints	O
with	O
reprojection	O
can	O
be	O
useful	O
because	O
they	O
impose	O
some	O
stability	O
on	O
the	O
optimization	O
procedure	O
when	O
using	O
high	O
learning	O
rates	O
it	O
is	O
possible	O
to	O
encounter	O
a	O
positive	O
feedback	O
loop	B
in	O
which	O
large	O
weights	B
induce	O
large	O
gradients	O
which	O
then	O
induce	O
a	O
large	O
update	O
to	O
the	O
weights	B
if	O
these	O
updates	O
consistently	O
increase	O
the	O
size	O
of	O
the	O
weights	B
then	O
rapidly	O
moves	O
away	O
from	O
the	O
origin	O
until	O
numerical	O
overflow	O
occurs	O
explicit	O
constraints	O
with	O
reprojection	O
prevent	O
this	O
feedback	O
loop	B
from	O
continuing	O
to	O
increase	O
the	O
magnitude	O
of	O
the	O
weights	B
without	O
bound	B
recommend	O
using	O
constraints	O
combined	O
with	O
a	O
high	O
learning	B
rate	I
to	O
allow	O
rapid	O
exploration	B
of	O
parameter	O
space	O
while	O
maintaining	O
some	O
stability	O
hinton	O
et	O
al	O
in	O
particular	O
hinton	O
and	O
shraibman	O
et	O
al	O
recommend	O
a	O
strategy	O
introduced	O
by	O
srebro	O
constraining	O
the	O
norm	O
of	O
each	O
column	O
of	O
the	O
weight	O
matrix	O
chapter	O
regularization	O
for	O
deep	O
learning	O
of	O
a	O
neural	O
net	O
layer	O
rather	O
than	O
constraining	O
the	O
frobenius	B
norm	I
of	O
the	O
entire	O
weight	O
matrix	O
constraining	O
the	O
norm	O
of	O
each	O
column	O
separately	O
prevents	O
any	O
one	O
hidden	O
unit	O
from	O
having	O
very	O
large	O
weights	B
if	O
we	O
converted	O
this	O
constraint	O
into	O
a	O
penalty	O
in	O
a	O
lagrange	O
function	O
it	O
would	O
be	O
similar	O
to	O
weight	O
decay	O
but	O
with	O
a	O
separate	O
kkt	O
multiplier	O
for	O
the	O
weights	B
of	O
each	O
hidden	O
unit	O
each	O
of	O
these	O
kkt	O
multipliers	O
would	O
be	O
dynamically	O
updated	O
separately	O
to	O
make	O
each	O
hidden	O
unit	O
obey	O
the	O
constraint	O
in	O
practice	O
column	O
norm	O
limitation	O
is	O
always	O
implemented	O
as	O
an	O
explicit	O
constraint	O
with	O
reprojection	O
regularization	O
and	O
under-constrained	O
problems	O
in	O
some	O
cases	O
regularization	O
is	O
necessary	O
for	O
machine	B
learning	I
problems	O
to	O
be	O
properly	O
defined	O
many	O
linear	O
models	O
in	O
machine	B
learning	I
including	O
linear	O
regression	B
and	O
pca	O
depend	O
on	O
inverting	O
the	O
matrix	O
x	O
x	O
this	O
is	O
not	O
possible	O
whenever	O
x	O
x	O
is	O
singular	O
this	O
matrix	O
can	O
be	O
singular	O
whenever	O
the	O
data	O
generating	O
distribution	O
truly	O
has	O
no	O
variance	O
in	O
some	O
direction	O
or	O
when	O
no	O
variance	O
is	O
observed	O
in	O
some	O
direction	O
because	O
there	O
are	O
fewer	O
examples	O
of	O
x	O
than	O
input	O
features	O
of	O
x	O
in	O
this	O
case	O
many	O
forms	O
of	O
regularization	O
correspond	O
to	O
inverting	O
x	O
i	O
instead	O
this	O
regularized	O
matrix	O
is	O
guaranteed	O
to	O
be	O
invertible	O
x	O
these	O
linear	O
problems	O
have	O
closed	O
form	O
solutions	O
when	O
the	O
relevant	O
matrix	O
is	O
invertible	O
it	O
is	O
also	O
possible	O
for	O
a	O
problem	O
with	O
no	O
closed	O
form	O
solution	O
to	O
be	O
underdetermined	O
an	O
example	B
is	O
logistic	O
regression	B
applied	O
to	O
a	O
problem	O
where	O
the	O
classes	O
are	O
linearly	O
separable	O
if	O
a	O
weight	O
vector	O
w	O
is	O
able	O
to	O
achieve	O
perfect	O
classification	B
then	O
will	O
also	O
achieve	O
perfect	O
classification	B
and	O
higher	O
likelihood	O
an	O
iterative	O
optimization	O
procedure	O
like	O
stochastic	O
gradient	B
descent	O
will	O
continually	O
increase	O
the	O
magnitude	O
of	O
w	O
and	O
in	O
theory	O
will	O
never	O
halt	O
in	O
practice	O
a	O
numerical	O
implementation	O
of	O
gradient	B
descent	O
will	O
eventually	O
reach	O
sufficiently	O
large	O
weights	B
to	O
cause	O
numerical	O
overflow	O
at	O
which	O
point	O
its	O
behavior	O
will	O
depend	O
on	O
how	O
the	O
programmer	O
has	O
decided	O
to	O
handle	O
values	O
that	O
are	O
not	O
real	O
numbers	O
most	O
forms	O
of	O
regularization	O
are	O
able	O
to	O
guarantee	O
the	O
convergence	O
of	O
iterative	O
methods	O
applied	O
to	O
underdetermined	O
problems	O
for	O
example	B
weight	O
decay	O
will	O
cause	O
gradient	B
descent	O
to	O
quit	O
increasing	O
the	O
magnitude	O
of	O
the	O
weights	B
when	O
the	O
slope	O
of	O
the	O
likelihood	O
is	O
equal	O
to	O
the	O
weight	O
decay	O
coefficient	O
the	O
idea	O
of	O
using	O
regularization	O
to	O
solve	O
underdetermined	O
problems	O
extends	O
beyond	O
machine	B
learning	I
the	O
same	O
idea	O
is	O
useful	O
for	O
several	O
basic	O
linear	O
algebra	O
problems	O
as	O
we	O
saw	O
in	O
section	O
we	O
can	O
solve	O
underdetermined	O
linear	O
equations	O
using	O
chapter	O
regularization	O
for	O
deep	O
learning	O
the	O
moore-penrose	O
pseudoinverse	O
recall	B
that	O
one	O
definition	O
of	O
the	O
pseudoinverse	O
x	O
of	O
a	O
matrix	O
isx	O
i	O
x	O
lim	O
x	O
we	O
can	O
now	O
recognize	O
equation	O
as	O
performing	O
linear	O
regression	B
with	O
weight	O
decay	O
specifically	O
equation	O
as	O
the	O
regularization	O
coefficient	O
shrinks	O
to	O
zero	O
we	O
can	O
thus	O
interpret	O
the	O
pseudoinverse	O
as	O
stabilizing	O
underdetermined	O
problems	O
using	O
regularization	O
is	O
the	O
limit	O
of	O
equation	O
dataset	B
augmentation	O
the	O
best	O
way	O
to	O
make	O
a	O
machine	B
learning	I
model	O
generalize	O
better	O
is	O
to	O
train	O
it	O
on	O
more	O
data	O
of	O
course	O
in	O
practice	O
the	O
amount	O
of	O
data	O
we	O
have	O
is	O
limited	O
one	O
way	O
to	O
get	O
around	O
this	O
problem	O
is	O
to	O
create	O
fake	O
data	O
and	O
add	O
it	O
to	O
the	O
training	O
set	O
for	O
some	O
machine	B
learning	I
tasks	O
it	O
is	O
reasonably	O
straightforward	O
to	O
create	O
new	O
fake	O
data	O
this	O
approach	O
is	O
easiest	O
for	O
classification	B
a	O
classifier	O
needs	O
to	O
take	O
a	O
complicated	O
high	O
dimensional	O
input	O
x	O
and	O
summarize	O
it	O
with	O
a	O
single	O
category	O
identity	O
y	O
this	O
means	O
that	O
the	O
main	O
task	O
facing	O
a	O
classifier	O
is	O
to	O
be	O
invariant	O
to	O
a	O
wide	O
variety	O
of	O
transformations	O
we	O
can	O
generate	O
new	O
x	O
y	O
pairs	O
easily	O
just	O
by	O
transforming	O
the	O
inputs	O
in	O
our	O
training	O
set	O
x	O
this	O
approach	O
is	O
not	O
as	O
readily	O
applicable	O
to	O
many	O
other	O
tasks	O
for	O
example	B
it	O
is	O
difficult	O
to	O
generate	O
new	O
fake	O
data	O
for	O
a	O
density	B
estimation	I
task	O
unless	O
we	O
have	O
already	O
solved	O
the	O
density	B
estimation	I
problem	O
dataset	B
augmentation	O
has	O
been	O
a	O
particularly	O
effective	O
technique	O
for	O
a	O
specific	O
classification	B
problem	O
object	B
recognition	I
images	O
are	O
high	O
dimensional	O
and	O
include	O
an	O
enormous	O
variety	O
of	O
factors	B
of	I
variation	I
many	O
of	O
which	O
can	O
be	O
easily	O
simulated	O
operations	O
like	O
translating	O
the	O
training	O
images	O
a	O
few	O
pixels	O
in	O
each	O
direction	O
can	O
often	O
greatly	O
improve	O
generalization	B
even	O
if	O
the	O
model	O
has	O
already	O
been	O
designed	O
to	O
be	O
partially	O
translation	O
invariant	O
by	O
using	O
the	O
convolution	O
and	O
pooling	O
techniques	O
described	O
in	O
chapter	O
many	O
other	O
operations	O
such	O
as	O
rotating	O
the	O
image	O
or	O
scaling	O
the	O
image	O
have	O
also	O
proven	O
quite	O
effective	O
one	O
must	O
be	O
careful	O
not	O
to	O
apply	O
transformations	O
that	O
would	O
change	O
the	O
correct	O
class	O
for	O
example	B
optical	O
character	O
recognition	O
tasks	O
require	O
recognizing	O
the	O
difference	O
between	O
b	O
and	O
d	O
and	O
the	O
difference	O
between	O
and	O
so	O
horizontal	O
flips	O
and	O
rotations	O
are	O
not	O
appropriate	O
ways	O
of	O
augmenting	O
datasets	O
for	O
these	O
tasks	O
chapter	O
regularization	O
for	O
deep	O
learning	O
there	O
are	O
also	O
transformations	O
that	O
we	O
would	O
like	O
our	O
classifiers	O
to	O
be	O
invariant	O
to	O
but	O
which	O
are	O
not	O
easy	O
to	O
perform	O
for	O
example	B
out-of-plane	O
rotation	O
can	O
not	O
be	O
implemented	O
as	O
a	O
simple	O
geometric	O
operation	B
on	O
the	O
input	O
pixels	O
dataset	B
augmentation	O
is	O
effective	O
for	O
speech	O
recognition	O
tasks	O
as	O
well	O
and	O
hinton	O
injecting	O
noise	O
in	O
the	O
input	O
to	O
a	O
neural	B
network	I
and	O
dow	O
can	O
also	O
be	O
seen	O
as	O
a	O
form	O
of	O
data	O
augmentation	O
for	O
many	O
classification	B
and	O
even	O
some	O
regression	B
tasks	O
the	O
task	O
should	O
still	O
be	O
possible	O
to	O
solve	O
even	O
if	O
small	O
random	O
noise	O
is	O
added	O
to	O
the	O
input	O
neural	O
networks	O
prove	O
not	O
to	O
be	O
very	O
robust	O
to	O
noise	O
however	O
and	O
eliasmith	O
one	O
way	O
to	O
improve	O
the	O
robustness	O
of	O
neural	O
networks	O
is	O
simply	O
to	O
train	O
them	O
with	O
random	O
noise	O
applied	O
to	O
their	O
inputs	O
input	O
noise	O
injection	O
is	O
part	O
of	O
some	O
unsupervised	O
learning	O
algorithms	O
such	O
as	O
the	O
denoising	O
autoencoder	O
noise	O
injection	O
also	O
works	O
when	O
the	O
noise	O
is	O
applied	O
to	O
the	O
hidden	O
units	O
which	O
can	O
be	O
seen	O
as	O
doing	O
dataset	B
augmentation	O
at	O
multiple	O
levels	O
of	O
abstraction	O
poole	O
recently	O
showed	O
that	O
this	O
approach	O
can	O
be	O
highly	O
effective	O
provided	O
that	O
the	O
magnitude	O
of	O
the	O
noise	O
is	O
carefully	O
tuned	O
dropout	O
a	O
powerful	O
regularization	O
strategy	O
that	O
will	O
be	O
described	O
in	O
section	O
can	O
be	O
seen	O
as	O
a	O
process	O
of	O
constructing	O
new	O
inputs	O
by	O
multiplying	O
by	O
noise	O
et	O
al	O
et	O
al	O
when	O
comparing	O
machine	B
learning	I
benchmark	O
results	O
it	O
is	O
important	O
to	O
take	O
the	O
effect	O
of	O
dataset	B
augmentation	O
into	O
account	O
often	O
hand-designed	O
dataset	B
augmentation	O
schemes	O
can	O
dramatically	O
reduce	O
the	O
generalization	B
error	O
of	O
a	O
machine	B
learning	I
technique	O
to	O
compare	O
the	O
performance	O
of	O
one	O
machine	B
learning	I
algorithm	O
to	O
another	O
it	O
is	O
necessary	O
to	O
perform	O
controlled	O
experiments	O
when	O
comparing	O
machine	B
learning	I
algorithm	O
a	O
and	O
machine	B
learning	I
algorithm	O
b	O
it	O
is	O
necessary	O
to	O
make	O
sure	O
that	O
both	O
algorithms	O
were	O
evaluated	O
using	O
the	O
same	O
hand-designed	O
dataset	B
augmentation	O
schemes	O
suppose	O
that	O
algorithm	O
a	O
performs	O
poorly	O
with	O
no	O
dataset	B
augmentation	O
and	O
algorithm	O
b	O
performs	O
well	O
when	O
combined	O
with	O
numerous	O
synthetic	O
transformations	O
of	O
the	O
input	O
in	O
such	O
a	O
case	O
it	O
is	O
likely	O
the	O
synthetic	O
transformations	O
caused	O
the	O
improved	O
performance	O
rather	O
than	O
the	O
use	O
of	O
machine	B
learning	I
algorithm	O
b	O
sometimes	O
deciding	O
whether	O
an	O
experiment	O
has	O
been	O
properly	O
controlled	O
requires	O
subjective	O
judgment	O
for	O
example	B
machine	B
learning	I
algorithms	O
that	O
inject	O
noise	O
into	O
the	O
input	O
are	O
performing	O
a	O
form	O
of	O
dataset	B
augmentation	O
usually	O
operations	O
that	O
are	O
generally	O
applicable	O
as	O
adding	O
gaussian	O
noise	O
to	O
the	O
input	O
are	O
considered	O
part	O
of	O
the	O
machine	B
learning	I
algorithm	O
while	O
operations	O
that	O
are	O
specific	O
to	O
one	O
application	O
domain	O
as	O
randomly	O
cropping	O
an	O
image	O
are	O
considered	O
to	O
be	O
separate	O
pre-processing	O
steps	O
chapter	O
regularization	O
for	O
deep	O
learning	O
noise	O
robustness	O
section	O
has	O
motivated	O
the	O
use	O
of	O
noise	O
applied	O
to	O
the	O
inputs	O
as	O
a	O
dataset	B
augmentation	O
strategy	O
for	O
some	O
models	O
the	O
addition	O
of	O
noise	O
with	O
infinitesimal	O
variance	O
at	O
the	O
input	O
of	O
the	O
model	O
is	O
equivalent	O
to	O
imposing	O
a	O
penalty	O
on	O
the	O
norm	O
of	O
the	O
weights	B
in	O
the	O
general	O
case	O
it	O
is	O
important	O
to	O
remember	O
that	O
noise	O
injection	O
can	O
be	O
much	O
more	O
powerful	O
than	O
simply	O
shrinking	O
the	O
parameters	O
especially	O
when	O
the	O
noise	O
is	O
added	O
to	O
the	O
hidden	O
units	O
noise	O
applied	O
to	O
the	O
hidden	O
units	O
is	O
such	O
an	O
important	O
topic	O
that	O
it	O
merit	O
its	O
own	O
separate	O
discussion	O
the	O
dropout	O
algorithm	O
described	O
in	O
section	O
is	O
the	O
main	O
development	O
of	O
that	O
approach	O
bishop	O
b	O
another	O
way	O
that	O
noise	O
has	O
been	O
used	O
in	O
the	O
service	O
of	O
regularizing	O
models	O
is	O
by	O
adding	O
it	O
to	O
the	O
weights	B
this	O
technique	O
has	O
been	O
used	O
primarily	O
in	O
the	O
context	O
of	O
recurrent	O
neural	O
networks	O
this	O
can	O
be	O
interpreted	O
as	O
a	O
stochastic	O
implementation	O
of	O
bayesian	O
inference	O
over	O
the	O
weights	B
the	O
bayesian	O
treatment	O
of	O
learning	O
would	O
consider	O
the	O
model	O
weights	B
to	O
be	O
uncertain	O
and	O
representable	O
via	O
a	O
probability	B
distribution	I
that	O
reflects	O
this	O
uncertainty	O
adding	O
noise	O
to	O
the	O
weights	B
is	O
a	O
practical	O
stochastic	O
way	O
to	O
reflect	O
this	O
uncertainty	O
jim	O
et	O
al	O
graves	O
noise	O
applied	O
to	O
the	O
weights	B
can	O
also	O
be	O
interpreted	O
as	O
equivalent	O
some	O
assumptions	O
to	O
a	O
more	O
traditional	O
form	O
of	O
regularization	O
encouraging	O
stability	O
of	O
the	O
function	O
to	O
be	O
learned	O
consider	O
the	O
regression	B
setting	O
where	O
we	O
wish	O
to	O
train	O
a	O
function	O
yx	O
that	O
maps	O
a	O
set	O
of	O
features	O
x	O
to	O
a	O
scalar	O
using	O
the	O
least-squares	O
cost	O
function	O
between	O
the	O
model	O
predictions	O
y	O
and	O
the	O
true	O
values	O
j	O
ep	O
xy	O
y	O
y	O
the	O
training	O
set	O
consists	O
of	O
m	O
labeled	O
examples	O
x	O
y	O
n	O
we	O
now	O
assume	O
that	O
with	O
each	O
input	O
presentation	O
we	O
also	O
include	O
a	O
random	O
i	O
of	O
the	O
network	O
weights	B
let	O
us	O
imagine	O
that	O
we	O
perturbation	O
w	O
have	O
a	O
standard	O
l-layer	O
mlp	O
we	O
denote	O
the	O
perturbed	O
model	O
as	O
y	O
despite	O
the	O
injection	O
of	O
noise	O
we	O
are	O
still	O
interested	O
in	O
minimizing	O
the	O
squared	O
error	O
of	O
the	O
output	O
of	O
the	O
network	O
the	O
objective	B
function	I
thus	O
becomes	O
w	O
jw	O
ep	O
ep	O
w	O
w	O
w	O
y	O
y	O
w	O
x	O
y	O
x	O
yy	O
y	O
w	O
for	O
small	O
the	O
minimization	O
of	O
j	O
with	O
added	O
weight	O
noise	O
covariance	O
i	O
is	O
equivalent	O
to	O
minimization	O
of	O
j	O
with	O
an	O
additional	O
regularization	O
term	O
chapter	O
regularization	O
for	O
deep	O
learning	O
w	O
y	O
ep	O
this	O
form	O
of	O
regularization	O
encourages	O
the	O
parameters	O
to	O
go	O
to	O
regions	O
of	O
parameter	O
space	O
where	O
small	O
perturbations	O
of	O
the	O
weights	B
have	O
a	O
relatively	O
small	O
influence	O
on	O
the	O
output	O
in	O
other	O
words	O
it	O
pushes	O
the	O
model	O
into	O
regions	O
where	O
the	O
model	O
is	O
relatively	O
insensitive	O
to	O
small	O
variations	O
in	O
the	O
weights	B
finding	O
points	O
that	O
are	O
not	O
merely	O
minima	O
but	O
minima	O
surrounded	O
by	O
flat	O
regions	O
and	O
schmidhuber	O
in	O
the	O
simplified	O
case	O
of	O
linear	O
x	O
b	O
this	O
regularization	O
term	O
collapses	O
regression	B
for	O
instance	O
yx	O
w	O
into	O
ep	O
which	O
is	O
not	O
a	O
function	O
of	O
parameters	O
and	O
therefore	O
does	O
not	O
contribute	O
to	O
the	O
gradient	B
of	O
jw	O
with	O
respect	O
to	O
the	O
model	O
parameters	O
x	O
injecting	O
noise	O
at	O
the	O
output	O
targets	O
most	O
datasets	O
have	O
some	O
amount	O
of	O
mistakes	O
in	O
the	O
y	O
labels	O
it	O
can	O
be	O
harmful	O
to	O
maximize	O
log	O
py	O
x	O
when	O
y	O
is	O
a	O
mistake	O
one	O
way	O
to	O
prevent	O
this	O
is	O
to	O
explicitly	O
model	O
the	O
noise	O
on	O
the	O
labels	O
for	O
example	B
we	O
can	O
assume	O
that	O
for	O
some	O
small	O
constant	O
the	O
training	O
set	O
label	O
y	O
is	O
correct	O
with	O
probability	O
and	O
otherwise	O
any	O
of	O
the	O
other	O
possible	O
labels	O
might	O
be	O
correct	O
this	O
assumption	O
is	O
easy	O
to	O
incorporate	O
into	O
the	O
cost	O
function	O
analytically	O
rather	O
than	O
by	O
explicitly	O
drawing	O
noise	O
samples	O
for	O
example	B
label	B
smoothing	I
regularizes	O
a	O
model	O
based	O
on	O
a	O
softmax	O
with	O
k	O
output	O
values	O
by	O
replacing	O
the	O
hard	O
classification	B
targets	O
respectively	O
the	O
standard	O
cross-entropy	B
loss	O
may	O
with	O
targets	O
of	O
then	O
be	O
used	O
with	O
these	O
soft	O
targets	O
maximum	B
likelihood	I
learning	O
with	O
a	O
softmax	O
classifier	O
and	O
hard	O
targets	O
may	O
actually	O
never	O
converge	O
the	O
softmax	O
can	O
never	O
predict	O
a	O
probability	O
of	O
exactly	O
or	O
exactly	O
so	O
it	O
will	O
continue	O
to	O
learn	O
larger	O
and	O
larger	O
weights	B
making	O
more	O
extreme	O
predictions	O
forever	O
it	O
is	O
possible	O
to	O
prevent	O
this	O
scenario	O
using	O
other	O
regularization	O
strategies	O
like	O
weight	O
decay	O
label	B
smoothing	I
has	O
the	O
advantage	O
of	O
preventing	O
the	O
pursuit	O
of	O
hard	O
probabilities	O
without	O
discouraging	O
correct	O
classification	B
this	O
strategy	O
has	O
been	O
used	O
since	O
the	O
and	O
continues	O
to	O
be	O
featured	O
prominently	O
in	O
modern	O
neural	O
networks	O
et	O
al	O
k	O
and	O
and	O
semi-supervised	B
learning	I
in	O
the	O
paradigm	O
of	O
semi-supervised	B
learning	I
both	O
unlabeled	O
examples	O
from	O
p	O
and	O
labeled	O
examples	O
from	O
p	O
y	O
or	O
predict	O
y	O
from	O
x	O
are	O
used	O
to	O
estimate	O
p	O
x	O
in	O
the	O
context	O
of	O
deep	O
learning	O
semi-supervised	B
learning	I
usually	O
refers	O
to	O
learning	O
a	O
representation	O
h	O
f	O
the	O
goal	O
is	O
to	O
learn	O
a	O
representation	O
so	O
chapter	O
regularization	O
for	O
deep	O
learning	O
that	O
examples	O
from	O
the	O
same	O
class	O
have	O
similar	O
representations	O
unsupervised	O
learning	O
can	O
provide	O
useful	O
cues	O
for	O
how	O
to	O
group	O
examples	O
in	O
representation	O
space	O
examples	O
that	O
cluster	O
tightly	O
in	O
the	O
input	O
space	O
should	O
be	O
mapped	O
to	O
similar	O
representations	O
a	O
linear	O
classifier	O
in	O
the	O
new	O
space	O
may	O
achieve	O
better	O
generalization	B
in	O
many	O
cases	O
and	O
niyogi	O
chapelle	O
a	O
long-standing	O
variant	O
of	O
this	O
approach	O
is	O
the	O
application	O
of	O
principal	O
components	O
analysis	O
as	O
a	O
pre-processing	O
step	O
before	O
applying	O
a	O
classifier	O
the	O
projected	O
data	O
et	O
al	O
log	O
p	O
or	O
log	O
p	O
x	O
instead	O
of	O
having	O
separate	O
unsupervised	O
and	O
supervised	O
components	O
in	O
the	O
model	O
one	O
can	O
construct	O
models	O
in	O
which	O
a	O
generative	O
model	O
of	O
either	O
p	O
or	O
p	O
y	O
shares	O
parameters	O
with	O
a	O
discriminative	O
model	O
of	O
py	O
x	O
one	O
can	O
then	O
trade-off	O
the	O
supervised	O
criterion	O
with	O
the	O
unsupervised	O
or	O
the	O
generative	O
criterion	O
then	O
generative	O
one	O
as	O
expresses	O
a	O
particular	O
form	O
of	O
prior	O
belief	O
about	O
the	O
solution	O
to	O
the	O
supervised	O
p	O
is	O
learning	O
problem	O
connected	O
to	O
the	O
structure	O
of	O
py	O
x	O
in	O
a	O
way	O
that	O
is	O
captured	O
by	O
the	O
shared	O
parametrization	O
by	O
controlling	O
how	O
much	O
of	O
the	O
generative	O
criterion	O
is	O
included	O
in	O
the	O
total	O
criterion	O
one	O
can	O
find	O
a	O
better	O
trade-off	O
than	O
with	O
a	O
purely	O
generative	O
or	O
a	O
purely	O
discriminative	O
training	O
criterion	O
lasserre	O
et	O
al	O
larochelle	O
and	O
bengio	O
namely	O
that	O
the	O
structure	O
of	O
lasserre	O
et	O
al	O
log	O
p	O
y	O
salakhutdinov	O
and	O
hinton	O
describe	O
a	O
method	O
for	O
learning	O
the	O
kernel	O
function	O
of	O
a	O
kernel	B
machine	I
used	O
for	O
regression	B
in	O
which	O
the	O
usage	O
of	O
unlabeled	O
examples	O
for	O
modeling	O
quite	O
significantly	O
y	O
x	O
improves	O
p	O
p	O
see	O
chapelle	O
et	O
al	O
for	O
more	O
information	O
about	O
semi-supervised	B
learning	I
multi-task	O
learning	O
caruana	O
multi-task	O
learning	O
is	O
a	O
way	O
to	O
improve	O
generalization	B
by	O
pooling	O
the	O
examples	O
can	O
be	O
seen	O
as	O
soft	O
constraints	O
imposed	O
on	O
the	O
parameters	O
arising	O
out	O
of	O
several	O
tasks	O
in	O
the	O
same	O
way	O
that	O
additional	O
training	O
examples	O
put	O
more	O
pressure	O
on	O
the	O
parameters	O
of	O
the	O
model	O
towards	O
values	O
that	O
generalize	O
well	O
when	O
part	O
of	O
a	O
model	O
is	O
shared	O
across	O
tasks	O
that	O
part	O
of	O
the	O
model	O
is	O
more	O
constrained	O
towards	O
good	O
values	O
the	O
sharing	O
is	O
justified	O
often	O
yielding	O
better	O
generalization	B
figure	O
illustrates	O
a	O
very	O
common	O
form	O
of	O
multi-task	O
learning	O
in	O
which	O
different	O
supervised	O
tasks	O
y	O
given	O
x	O
share	O
the	O
same	O
input	O
x	O
as	O
well	O
as	O
some	O
intermediate-level	O
representation	O
hshared	O
capturing	O
a	O
common	O
pool	O
of	O
chapter	O
regularization	O
for	O
deep	O
learning	O
factors	O
the	O
model	O
can	O
generally	O
be	O
divided	O
into	O
two	O
kinds	O
of	O
parts	O
and	O
associated	O
parameters	O
task-specific	O
parameters	O
only	O
benefit	O
from	O
the	O
examples	O
of	O
their	O
task	O
to	O
achieve	O
good	O
generalization	B
these	O
are	O
the	O
upper	O
layers	O
of	O
the	O
neural	B
network	I
in	O
figure	O
generic	O
parameters	O
shared	O
across	O
all	O
the	O
tasks	O
benefit	O
from	O
the	O
pooled	O
data	O
of	O
all	O
the	O
tasks	O
these	O
are	O
the	O
lower	O
layers	O
of	O
the	O
neural	B
network	I
in	O
figure	O
y	O
hshared	O
hshared	O
xx	O
figure	O
multi-task	O
learning	O
can	O
be	O
cast	O
in	O
several	O
ways	O
in	O
deep	O
learning	O
frameworks	O
and	O
this	O
figure	O
illustrates	O
the	O
common	O
situation	O
where	O
the	O
tasks	O
share	O
a	O
common	O
input	O
but	O
involve	O
different	O
target	O
random	O
variables	O
the	O
lower	O
layers	O
of	O
a	O
deep	O
network	O
it	O
is	O
supervised	O
and	O
feedforward	O
or	O
includes	O
a	O
generative	O
component	O
with	O
downward	O
arrows	O
can	O
be	O
shared	O
across	O
such	O
tasks	O
while	O
task-specific	O
parameters	O
respectively	O
with	O
the	O
weights	B
into	O
and	O
from	O
and	O
can	O
be	O
learned	O
on	O
top	O
of	O
those	O
yielding	O
a	O
shared	O
representation	O
hshared	O
the	O
underlying	O
assumption	O
is	O
that	O
there	O
exists	O
a	O
common	O
pool	O
of	O
factors	O
that	O
explain	O
the	O
variations	O
in	O
the	O
input	O
x	O
while	O
each	O
task	O
is	O
associated	O
with	O
a	O
subset	O
of	O
these	O
factors	O
in	O
this	O
example	B
it	O
is	O
additionally	O
assumed	O
that	O
top-level	O
hidden	O
units	O
and	O
are	O
specialized	O
to	O
each	O
task	O
predicting	O
and	O
y	O
while	O
some	O
intermediate-level	O
representation	O
hshared	O
is	O
shared	O
across	O
all	O
tasks	O
in	O
the	O
unsupervised	O
learning	O
context	O
it	O
makes	O
sense	O
for	O
some	O
of	O
the	O
top-level	O
factors	O
to	O
be	O
associated	O
with	O
none	O
of	O
the	O
output	O
tasks	O
these	O
are	O
the	O
factors	O
that	O
explain	O
some	O
of	O
the	O
input	O
variations	O
but	O
are	O
not	O
relevant	O
for	O
predicting	O
or	O
improved	O
generalization	B
and	O
generalization	B
error	O
bounds	O
can	O
be	O
achieved	O
because	O
of	O
the	O
shared	O
parameters	O
for	O
which	O
statistical	O
strength	O
can	O
be	O
baxter	O
chapter	O
regularization	O
for	O
deep	O
learning	O
d	O
o	O
o	O
h	O
i	O
l	O
e	O
k	O
i	O
l	O
g	O
o	O
l	O
e	O
v	O
i	O
t	O
a	O
g	O
e	O
n	O
s	O
s	O
o	O
l	O
training	O
set	O
loss	O
validation	O
set	O
loss	O
time	O
figure	O
learning	O
curves	O
showing	O
how	O
the	O
negative	O
log-likelihood	O
loss	O
changes	O
over	O
time	O
as	O
number	O
of	O
training	O
iterations	O
over	O
the	O
dataset	B
or	O
epochs	O
in	O
this	O
example	B
we	O
train	O
a	O
maxout	O
network	O
on	O
mnist	O
observe	O
that	O
the	O
training	O
objective	O
decreases	O
consistently	O
over	O
time	O
but	O
the	O
validation	O
set	O
average	O
loss	O
eventually	O
begins	O
to	O
increase	O
again	O
forming	O
an	O
asymmetric	O
u-shaped	O
curve	O
greatly	O
improved	O
proportion	O
with	O
the	O
increased	O
number	O
of	O
examples	O
for	O
the	O
shared	O
parameters	O
compared	O
to	O
the	O
scenario	O
of	O
single-task	O
models	O
of	O
course	O
this	O
will	O
happen	O
only	O
if	O
some	O
assumptions	O
about	O
the	O
statistical	O
relationship	O
between	O
the	O
different	O
tasks	O
are	O
valid	O
meaning	O
that	O
there	O
is	O
something	O
shared	O
across	O
some	O
of	O
the	O
tasks	O
from	O
the	O
point	O
of	O
view	O
of	O
deep	O
learning	O
the	O
underlying	O
prior	O
belief	O
is	O
the	O
following	O
among	O
the	O
factors	O
that	O
explain	O
the	O
variations	O
observed	O
in	O
the	O
data	O
associated	O
with	O
the	O
different	O
tasks	O
some	O
are	O
shared	O
across	O
two	O
or	O
more	O
tasks	O
early	O
stopping	O
when	O
training	O
large	O
models	O
with	O
sufficient	O
representational	B
capacity	I
to	O
overfit	O
the	O
task	O
we	O
often	O
observe	O
that	O
training	B
error	I
decreases	O
steadily	O
over	O
time	O
but	O
validation	O
set	O
error	O
begins	O
to	O
rise	O
again	O
see	O
figure	O
for	O
an	O
example	B
of	O
this	O
behavior	O
this	O
behavior	O
occurs	O
very	O
reliably	O
this	O
means	O
we	O
can	O
obtain	O
a	O
model	O
with	O
better	O
validation	O
set	O
error	O
thus	O
hopefully	O
better	O
test	B
set	I
error	O
by	O
returning	O
to	O
the	O
parameter	O
setting	O
at	O
the	O
point	O
in	O
time	O
with	O
the	O
lowest	O
validation	O
set	O
error	O
every	O
time	O
the	O
error	O
on	O
the	O
validation	O
set	O
improves	O
we	O
store	O
a	O
copy	O
of	O
the	O
model	O
parameters	O
when	O
the	O
training	O
algorithm	O
terminates	O
we	O
return	O
these	O
parameters	O
rather	O
than	O
the	O
latest	O
parameters	O
the	O
chapter	O
regularization	O
for	O
deep	O
learning	O
algorithm	O
terminates	O
when	O
no	O
parameters	O
have	O
improved	O
over	O
the	O
best	O
recorded	O
validation	O
error	O
for	O
some	O
pre-specified	O
number	O
of	O
iterations	O
this	O
procedure	O
is	O
specified	O
more	O
formally	O
in	O
algorithm	O
algorithm	O
the	O
early	O
stopping	O
meta-algorithm	O
for	O
determining	O
the	O
best	O
amount	O
of	O
time	O
to	O
train	O
this	O
meta-algorithm	O
is	O
a	O
general	O
strategy	O
that	O
works	O
well	O
with	O
a	O
variety	O
of	O
training	O
algorithms	O
and	O
ways	O
of	O
quantifying	O
error	O
on	O
the	O
validation	O
set	O
n	O
o	O
be	O
the	O
number	O
of	O
steps	O
between	O
evaluations	O
let	O
let	O
p	O
be	O
the	O
patience	O
the	O
number	O
of	O
times	O
to	O
observe	O
worsening	O
validation	O
set	O
error	O
before	O
giving	O
up	O
let	O
o	O
be	O
the	O
initial	O
parameters	O
i	O
j	O
v	O
i	O
i	O
while	O
update	O
i	O
i	O
validationseterror	O
v	O
if	O
v	O
v	O
then	O
j	O
i	O
i	O
v	O
v	O
else	O
j	O
do	O
by	O
running	O
the	O
training	O
algorithm	O
for	O
j	O
p	O
n	O
n	O
steps	O
j	O
end	O
if	O
end	O
while	O
best	O
parameters	O
are	O
best	O
number	O
of	O
training	O
steps	O
is	O
i	O
this	O
strategy	O
is	O
known	O
as	O
early	O
stopping	O
it	O
is	O
probably	O
the	O
most	O
commonly	O
used	O
form	O
of	O
regularization	O
in	O
deep	O
learning	O
its	O
popularity	O
is	O
due	O
both	O
to	O
its	O
effectiveness	O
and	O
its	O
simplicity	O
one	O
way	O
to	O
think	O
of	O
early	O
stopping	O
is	O
as	O
a	O
very	O
efficient	O
hyperparameter	O
selection	O
algorithm	O
in	O
this	O
view	O
the	O
number	O
of	O
training	O
steps	O
is	O
just	O
another	O
hyperparameter	O
that	O
this	O
hyperparameter	O
has	O
a	O
u-shaped	O
validation	O
set	O
we	O
can	O
see	O
in	O
figure	O
chapter	O
regularization	O
for	O
deep	O
learning	O
performance	O
curve	O
most	O
hyperparameters	O
that	O
control	O
model	O
capacity	O
have	O
such	O
a	O
u-shaped	O
validation	O
set	O
performance	O
curve	O
as	O
illustrated	O
in	O
figure	O
in	O
the	O
case	O
of	O
early	O
stopping	O
we	O
are	O
controlling	O
the	O
effective	B
capacity	I
of	O
the	O
model	O
by	O
determining	O
how	O
many	O
steps	O
it	O
can	O
take	O
to	O
fit	O
the	O
training	O
set	O
most	O
hyperparameters	O
must	O
be	O
chosen	O
using	O
an	O
expensive	O
guess	O
and	O
check	O
process	O
where	O
we	O
set	O
a	O
hyperparameter	O
at	O
the	O
start	O
of	O
training	O
then	O
run	O
training	O
for	O
several	O
steps	O
to	O
see	O
its	O
effect	O
the	O
training	O
time	O
hyperparameter	O
is	O
unique	O
in	O
that	O
by	O
definition	O
a	O
single	O
run	O
of	O
training	O
tries	O
out	O
many	O
values	O
of	O
the	O
hyperparameter	O
the	O
only	O
significant	O
cost	O
to	O
choosing	O
this	O
hyperparameter	O
automatically	O
via	O
early	O
stopping	O
is	O
running	O
the	O
validation	O
set	O
evaluation	O
periodically	O
during	O
training	O
ideally	O
this	O
is	O
done	O
in	O
parallel	O
to	O
the	O
training	O
process	O
on	O
a	O
separate	O
machine	O
separate	O
cpu	O
or	O
separate	O
gpu	O
from	O
the	O
main	O
training	O
process	O
if	O
such	O
resources	O
are	O
not	O
available	O
then	O
the	O
cost	O
of	O
these	O
periodic	O
evaluations	O
may	O
be	O
reduced	O
by	O
using	O
a	O
validation	O
set	O
that	O
is	O
small	O
compared	O
to	O
the	O
training	O
set	O
or	O
by	O
evaluating	O
the	O
validation	O
set	O
error	O
less	O
frequently	O
and	O
obtaining	O
a	O
lower	O
resolution	O
estimate	O
of	O
the	O
optimal	O
training	O
time	O
an	O
additional	O
cost	O
to	O
early	O
stopping	O
is	O
the	O
need	O
to	O
maintain	O
a	O
copy	O
of	O
the	O
best	O
parameters	O
this	O
cost	O
is	O
generally	O
negligible	O
because	O
it	O
is	O
acceptable	O
to	O
store	O
these	O
parameters	O
in	O
a	O
slower	O
and	O
larger	O
form	O
of	O
memory	O
example	B
training	O
in	O
gpu	O
memory	O
but	O
storing	O
the	O
optimal	O
parameters	O
in	O
host	O
memory	O
or	O
on	O
a	O
disk	O
drive	O
since	O
the	O
best	O
parameters	O
are	O
written	O
to	O
infrequently	O
and	O
never	O
read	O
during	O
training	O
these	O
occasional	O
slow	O
writes	O
have	O
little	O
effect	O
on	O
the	O
total	O
training	O
time	O
early	O
stopping	O
is	O
a	O
very	O
unobtrusive	O
form	O
of	O
regularization	O
in	O
that	O
it	O
requires	O
almost	O
no	O
change	O
in	O
the	O
underlying	O
training	O
procedure	O
the	O
objective	B
function	I
or	O
the	O
set	O
of	O
allowable	O
parameter	O
values	O
this	O
means	O
that	O
it	O
is	O
easy	O
to	O
use	O
early	O
stopping	O
without	O
damaging	O
the	O
learning	O
dynamics	O
this	O
is	O
in	O
contrast	B
to	O
weight	O
decay	O
where	O
one	O
must	O
be	O
careful	O
not	O
to	O
use	O
too	O
much	O
weight	O
decay	O
and	O
trap	O
the	O
network	O
in	O
a	O
bad	O
local	O
minimum	O
corresponding	O
to	O
a	O
solution	O
with	O
pathologically	O
small	O
weights	B
early	O
stopping	O
may	O
be	O
used	O
either	O
alone	O
or	O
in	O
conjunction	O
with	O
other	O
regularization	O
strategies	O
even	O
when	O
using	O
regularization	O
strategies	O
that	O
modify	O
the	O
objective	B
function	I
to	O
encourage	O
better	O
generalization	B
it	O
is	O
rare	O
for	O
the	O
best	O
generalization	B
to	O
occur	O
at	O
a	O
local	O
minimum	O
of	O
the	O
training	O
objective	O
early	O
stopping	O
requires	O
a	O
validation	O
set	O
which	O
means	O
some	O
training	O
data	O
is	O
not	O
fed	O
to	O
the	O
model	O
to	O
best	O
exploit	O
this	O
extra	O
data	O
one	O
can	O
perform	O
extra	O
training	O
after	O
the	O
initial	O
training	O
with	O
early	O
stopping	O
has	O
completed	O
in	O
the	O
second	O
extra	O
training	O
step	O
all	O
of	O
the	O
training	O
data	O
is	O
included	O
there	O
are	O
two	O
basic	O
strategies	O
one	O
can	O
use	O
for	O
this	O
second	O
training	O
procedure	O
one	O
strategy	O
is	O
to	O
initialize	O
the	O
model	O
again	O
and	O
retrain	O
on	O
all	O
chapter	O
regularization	O
for	O
deep	O
learning	O
of	O
the	O
data	O
in	O
this	O
second	O
training	O
pass	O
we	O
train	O
for	O
the	O
same	O
number	O
of	O
steps	O
as	O
the	O
early	O
stopping	O
procedure	O
determined	O
was	O
optimal	O
in	O
the	O
first	O
pass	O
there	O
are	O
some	O
subtleties	O
associated	O
with	O
this	O
procedure	O
for	O
example	B
there	O
is	O
not	O
a	O
good	O
way	O
of	O
knowing	O
whether	O
to	O
retrain	O
for	O
the	O
same	O
number	O
of	O
parameter	O
updates	O
or	O
the	O
same	O
number	O
of	O
passes	O
through	O
the	O
dataset	B
on	O
the	O
second	O
round	O
of	O
training	O
each	O
pass	O
through	O
the	O
dataset	B
will	O
require	O
more	O
parameter	O
updates	O
because	O
the	O
training	O
set	O
is	O
bigger	O
algorithm	O
a	O
meta-algorithm	O
for	O
using	O
early	O
stopping	O
to	O
determine	O
how	O
long	O
to	O
train	O
then	O
retraining	O
on	O
all	O
the	O
data	O
train	O
and	O
y	O
subtrain	O
yvalid	O
into	O
train	O
and	O
y	O
train	O
and	O
y	O
subtrain	O
x	O
train	O
be	O
the	O
training	O
set	O
let	O
x	O
split	O
x	O
respectively	O
run	O
early	O
stopping	O
starting	O
from	O
random	O
y	O
returns	O
i	O
set	O
train	O
on	O
x	O
the	O
optimal	O
number	O
of	O
steps	O
to	O
random	O
values	O
again	O
train	O
for	O
i	O
train	O
and	O
y	O
steps	O
subtrain	O
and	O
subtrain	O
for	O
training	O
data	O
and	O
xvalid	O
and	O
yvalid	O
for	O
validation	O
data	O
this	O
using	O
x	O
another	O
strategy	O
for	O
using	O
all	O
of	O
the	O
data	O
is	O
to	O
keep	O
the	O
parameters	O
obtained	O
from	O
the	O
first	O
round	O
of	O
training	O
and	O
then	O
continue	O
training	O
but	O
now	O
using	O
all	O
of	O
the	O
data	O
at	O
this	O
stage	O
we	O
now	O
no	O
longer	O
have	O
a	O
guide	O
for	O
when	O
to	O
stop	O
in	O
terms	O
of	O
a	O
number	O
of	O
steps	O
instead	O
we	O
can	O
monitor	O
the	O
average	O
loss	O
function	O
on	O
the	O
validation	O
set	O
and	O
continue	O
training	O
until	O
it	O
falls	O
below	O
the	O
value	O
of	O
the	O
training	O
set	O
objective	O
at	O
which	O
the	O
early	O
stopping	O
procedure	O
halted	O
this	O
strategy	O
avoids	O
the	O
high	O
cost	O
of	O
retraining	O
the	O
model	O
from	O
scratch	O
but	O
is	O
not	O
as	O
well-behaved	O
for	O
example	B
there	O
is	O
not	O
any	O
guarantee	O
that	O
the	O
objective	O
on	O
the	O
validation	O
set	O
will	O
ever	O
reach	O
the	O
target	O
value	O
so	O
this	O
strategy	O
is	O
not	O
even	O
guaranteed	O
to	O
terminate	O
this	O
procedure	O
is	O
presented	O
more	O
formally	O
in	O
algorithm	O
early	O
stopping	O
is	O
also	O
useful	O
because	O
it	O
reduces	O
the	O
computational	O
cost	O
of	O
the	O
training	O
procedure	O
besides	O
the	O
obvious	O
reduction	O
in	O
cost	O
due	O
to	O
limiting	O
the	O
number	O
of	O
training	O
iterations	O
it	O
also	O
has	O
the	O
benefit	O
of	O
providing	O
regularization	O
without	O
requiring	O
the	O
addition	O
of	O
penalty	O
terms	O
to	O
the	O
cost	O
function	O
or	O
the	O
computation	O
of	O
the	O
gradients	O
of	O
such	O
additional	O
terms	O
how	O
early	O
stopping	O
acts	O
as	O
a	O
regularizer	B
so	O
far	O
we	O
have	O
stated	O
that	O
early	O
stopping	O
a	O
regularization	O
strategy	O
but	O
we	O
have	O
supported	O
this	O
claim	O
only	O
by	O
showing	O
learning	O
curves	O
where	O
the	O
validation	O
set	O
error	O
has	O
a	O
u-shaped	O
curve	O
what	O
is	O
chapter	O
regularization	O
for	O
deep	O
learning	O
algorithm	O
meta-algorithm	O
using	O
early	O
stopping	O
to	O
determine	O
at	O
what	O
objective	O
value	O
we	O
start	O
to	O
overfit	O
then	O
continue	O
training	O
until	O
that	O
value	O
is	O
reached	O
train	O
into	O
train	O
and	O
y	O
train	O
and	O
y	O
subtrain	O
x	O
train	O
be	O
the	O
training	O
set	O
let	O
x	O
split	O
x	O
respectively	O
run	O
early	O
stopping	O
starting	O
from	O
random	O
subtrain	O
and	O
subtrain	O
for	O
training	O
data	O
and	O
xvalid	O
and	O
yvalid	O
for	O
validation	O
data	O
this	O
y	O
updates	O
j	O
while	O
j	O
xvalid	O
y	O
do	O
train	O
for	O
subtrain	O
yvalid	O
train	O
on	O
x	O
train	O
and	O
y	O
using	O
x	O
subtrain	O
y	O
subtrain	O
and	O
y	O
x	O
steps	O
n	O
end	O
while	O
and	O
sj	O
berg	O
and	O
ljung	O
is	O
the	O
actual	O
mechanism	O
by	O
which	O
early	O
stopping	O
regularizes	O
the	O
model	O
bishop	O
argued	O
that	O
early	O
stopping	O
has	O
the	O
effect	O
of	O
restricting	O
the	O
optimization	O
procedure	O
to	O
a	O
relatively	O
small	O
volume	O
of	O
parameter	O
space	O
in	O
the	O
neighborhood	O
of	O
the	O
initial	O
parameter	O
value	O
o	O
as	O
illustrated	O
in	O
optimization	O
steps	O
figure	O
to	O
training	O
iterations	O
and	O
with	O
learning	B
rate	I
we	O
can	O
view	O
the	O
product	O
as	O
a	O
measure	O
of	O
effective	B
capacity	I
assuming	O
the	O
gradient	B
is	O
bounded	O
restricting	O
both	O
the	O
number	O
of	O
iterations	O
and	O
the	O
learning	B
rate	I
limits	O
the	O
volume	O
of	O
parameter	O
space	O
reachable	O
from	O
o	O
in	O
this	O
sense	O
behaves	O
as	O
if	O
it	O
were	O
the	O
reciprocal	O
of	O
the	O
coefficient	O
used	O
for	O
weight	O
decay	O
more	O
specifically	O
imagine	O
taking	O
indeed	O
we	O
can	O
show	O
how	O
in	O
the	O
case	O
of	O
a	O
simple	O
linear	O
model	O
with	O
a	O
quadratic	O
error	O
function	O
and	O
simple	O
gradient	B
descent	O
early	O
stopping	O
is	O
equivalent	O
to	O
l	O
regularization	O
in	O
order	O
to	O
compare	O
with	O
classical	O
regularization	O
we	O
examine	O
a	O
simple	O
setting	O
where	O
the	O
only	O
parameters	O
are	O
linear	O
weights	B
w	O
we	O
can	O
model	O
the	O
cost	O
function	O
j	O
with	O
a	O
quadratic	O
approximation	O
in	O
the	O
neighborhood	O
of	O
the	O
empirically	O
optimal	O
value	O
of	O
the	O
weights	B
w	O
w	O
h	O
w	O
w	O
j	O
j	O
where	O
h	O
is	O
the	O
hessian	B
matrix	O
of	O
j	O
with	O
respect	O
to	O
w	O
evaluated	O
at	O
w	O
assumption	O
that	O
w	O
under	O
a	O
local	O
taylor	O
series	O
approximation	O
the	O
gradient	B
is	O
given	O
by	O
given	O
the	O
is	O
a	O
minimum	O
of	O
jw	O
we	O
know	O
that	O
h	O
is	O
positive	O
semidefinite	O
j	O
w	O
w	O
h	O
w	O
w	O
chapter	O
regularization	O
for	O
deep	O
learning	O
w	O
w	O
w	O
w	O
w	O
w	O
figure	O
an	O
illustration	O
of	O
the	O
effect	O
of	O
early	O
stopping	O
solid	O
contour	O
lines	O
indicate	O
the	O
contours	O
of	O
the	O
negative	O
log-likelihood	O
the	O
dashed	O
line	O
indicates	O
the	O
trajectory	O
taken	O
by	O
sgd	O
beginning	O
from	O
the	O
origin	O
rather	O
than	O
stopping	O
at	O
the	O
point	O
w	O
that	O
minimizes	O
the	O
cost	O
early	O
stopping	O
results	O
in	O
the	O
trajectory	O
stopping	O
at	O
an	O
earlier	O
point	O
w	O
illustration	O
of	O
the	O
effect	O
of	O
regularization	O
for	O
comparison	O
the	O
dashed	O
circles	O
indicate	O
the	O
contours	O
of	O
the	O
penalty	O
which	O
causes	O
the	O
minimum	O
of	O
the	O
total	O
cost	O
to	O
lie	O
nearer	O
the	O
origin	O
than	O
the	O
minimum	O
of	O
the	O
unregularized	O
cost	O
we	O
are	O
going	O
to	O
study	O
the	O
trajectory	O
followed	O
by	O
the	O
parameter	O
vector	O
during	O
training	O
for	O
simplicity	O
let	O
us	O
set	O
the	O
initial	O
parameter	O
vector	O
to	O
the	O
that	O
is	O
w	O
let	O
us	O
study	O
the	O
approximate	O
behavior	O
of	O
gradient	B
descent	O
on	O
j	O
by	O
analyzing	O
gradient	B
descent	O
on	O
j	O
w	O
w	O
w	O
w	O
h	O
w	O
i	O
h	O
w	O
w	O
jw	O
w	O
w	O
w	O
let	O
us	O
now	O
rewrite	O
this	O
expression	O
in	O
the	O
space	O
of	O
the	O
eigenvectors	O
of	O
h	O
exploiting	O
the	O
eigendecomposition	B
of	O
h	O
h	O
q	O
q	O
where	O
is	O
a	O
diagonal	B
matrix	I
and	O
q	O
is	O
an	O
orthonormal	O
basis	O
of	O
eigenvectors	O
w	O
q	O
q	O
q	O
w	O
w	O
w	O
w	O
q	O
i	O
neural	O
networks	O
to	O
obtain	O
symmetry	O
breaking	O
between	O
hidden	O
units	O
we	O
cannot	O
initialize	O
however	O
the	O
argument	O
holds	O
for	O
any	O
other	O
all	O
the	O
parameters	O
to	O
as	O
discussed	O
in	O
section	O
initial	O
value	O
w	O
chapter	O
regularization	O
for	O
deep	O
learning	O
i	O
assuming	O
that	O
w	O
and	O
that	O
is	O
chosen	O
to	O
be	O
small	O
enough	O
to	O
guarantee	O
the	O
parameter	O
trajectory	O
during	O
training	O
after	O
parameter	O
updates	O
is	O
as	O
follows	O
q	O
w	O
i	O
i	O
w	O
now	O
the	O
expression	O
for	O
q	O
ranged	O
as	O
w	O
in	O
equation	O
for	O
regularization	O
can	O
be	O
rear	O
q	O
q	O
w	O
q	O
i	O
i	O
w	O
w	O
i	O
w	O
and	O
equation	O
we	O
see	O
that	O
if	O
the	O
hyperparameters	O
i	O
i	O
comparing	O
equation	O
and	O
are	O
chosen	O
such	O
that	O
then	O
regularization	O
and	O
early	O
stopping	O
can	O
be	O
seen	O
to	O
be	O
equivalent	O
least	O
under	O
the	O
quadratic	O
approximation	O
of	O
the	O
objective	B
function	I
going	O
even	O
further	O
by	O
taking	O
logarithms	O
and	O
using	O
the	O
series	O
expansion	O
for	O
x	O
we	O
can	O
conclude	O
that	O
if	O
all	O
i	O
are	O
small	O
is	O
i	O
then	O
and	O
i	O
that	O
is	O
under	O
these	O
assumptions	O
the	O
number	O
of	O
training	O
iterations	O
plays	O
a	O
role	O
inversely	O
proportional	O
to	O
the	O
regularization	O
parameter	O
and	O
the	O
inverse	O
of	O
plays	O
the	O
role	O
of	O
the	O
weight	O
decay	O
coefficient	O
parameter	O
values	O
corresponding	O
to	O
directions	O
of	O
significant	O
curvature	O
the	O
objective	B
function	I
are	O
regularized	O
less	O
than	O
directions	O
of	O
less	O
curvature	O
of	O
course	O
in	O
the	O
context	O
of	O
early	O
stopping	O
this	O
really	O
means	O
that	O
parameters	O
that	O
correspond	O
to	O
directions	O
of	O
significant	O
curvature	O
tend	O
to	O
learn	O
early	O
relative	O
to	O
parameters	O
corresponding	O
to	O
directions	O
of	O
less	O
curvature	O
the	O
derivations	O
in	O
this	O
section	O
have	O
shown	O
that	O
a	O
trajectory	O
of	O
length	O
ends	O
at	O
a	O
point	O
that	O
corresponds	O
to	O
a	O
minimum	O
of	O
the	O
objective	O
early	O
stopping	O
is	O
of	O
course	O
more	O
than	O
the	O
mere	O
restriction	O
of	O
the	O
trajectory	O
length	O
instead	O
early	O
stopping	O
typically	O
involves	O
monitoring	O
the	O
validation	O
set	O
error	O
in	O
order	O
to	O
stop	O
the	O
trajectory	O
at	O
a	O
particularly	O
good	O
point	O
in	O
space	O
early	O
stopping	O
therefore	O
has	O
the	O
advantage	O
over	O
weight	O
decay	O
that	O
early	O
stopping	O
automatically	O
determines	O
the	O
correct	O
amount	O
of	O
regularization	O
while	O
weight	O
decay	O
requires	O
many	O
training	O
experiments	O
with	O
different	O
values	O
of	O
its	O
hyperparameter	O
chapter	O
regularization	O
for	O
deep	O
learning	O
parameter	O
tying	O
and	O
parameter	O
sharing	O
thus	O
far	O
in	O
this	O
chapter	O
when	O
we	O
have	O
discussed	O
adding	O
constraints	O
or	O
penalties	O
to	O
the	O
parameters	O
we	O
have	O
always	O
done	O
so	O
with	O
respect	O
to	O
a	O
fixed	O
region	O
or	O
point	O
for	O
example	B
regularization	O
weight	O
decay	O
penalizes	O
model	O
parameters	O
for	O
deviating	O
from	O
the	O
fixed	O
value	O
of	O
zero	O
however	O
sometimes	O
we	O
may	O
need	O
other	O
ways	O
to	O
express	O
our	O
prior	O
knowledge	O
about	O
suitable	O
values	O
of	O
the	O
model	O
parameters	O
sometimes	O
we	O
might	O
not	O
know	O
precisely	O
what	O
values	O
the	O
parameters	O
should	O
take	O
but	O
we	O
know	O
from	O
knowledge	O
of	O
the	O
domain	O
and	O
model	O
architecture	O
that	O
there	O
should	O
be	O
some	O
dependencies	O
between	O
the	O
model	O
parameters	O
a	O
common	O
type	O
of	O
dependency	O
that	O
we	O
often	O
want	O
to	O
express	O
is	O
that	O
certain	O
parameters	O
should	O
be	O
close	O
to	O
one	O
another	O
consider	O
the	O
following	O
scenario	O
we	O
have	O
two	O
models	O
performing	O
the	O
same	O
classification	B
task	O
the	O
same	O
set	O
of	O
classes	O
but	O
with	O
somewhat	O
different	O
input	O
distributions	O
formally	O
we	O
have	O
model	O
a	O
with	O
parameters	O
w	O
and	O
model	O
b	O
with	O
parameters	O
w	O
the	O
two	O
models	O
map	O
the	O
input	O
to	O
two	O
different	O
but	O
related	O
outputs	O
y	O
fw	O
x	O
and	O
y	O
w	O
x	O
i	O
w	O
let	O
us	O
imagine	O
that	O
the	O
tasks	O
are	O
similar	O
enough	O
with	O
similar	O
input	O
and	O
output	O
distributions	O
that	O
we	O
believe	O
the	O
model	O
parameters	O
should	O
be	O
close	O
to	O
each	O
other	O
we	O
can	O
leverage	O
this	O
information	O
through	O
regularization	O
specifically	O
we	O
can	O
use	O
a	O
parameter	O
norm	O
penalty	O
of	O
the	O
form	O
w	O
here	O
we	O
used	O
an	O
penalty	O
but	O
other	O
choices	O
are	O
also	O
possible	O
should	O
be	O
close	O
to	O
w	O
i	O
w	O
i	O
w	O
this	O
kind	O
of	O
approach	O
was	O
proposed	O
by	O
who	O
regularized	O
the	O
parameters	O
of	O
one	O
model	O
trained	O
as	O
a	O
classifier	O
in	O
a	O
supervised	O
paradigm	O
to	O
be	O
close	O
to	O
the	O
parameters	O
of	O
another	O
model	O
trained	O
in	O
an	O
unsupervised	O
paradigm	O
capture	O
the	O
distribution	O
of	O
the	O
observed	O
input	O
data	O
the	O
architectures	O
were	O
constructed	O
such	O
that	O
many	O
of	O
the	O
parameters	O
in	O
the	O
classifier	O
model	O
could	O
be	O
paired	O
to	O
corresponding	O
parameters	O
in	O
the	O
unsupervised	O
model	O
lasserre	O
et	O
al	O
while	O
a	O
parameter	O
norm	O
penalty	O
is	O
one	O
way	O
to	O
regularize	O
parameters	O
to	O
be	O
close	O
to	O
one	O
another	O
the	O
more	O
popular	O
way	O
is	O
to	O
use	O
constraints	O
to	O
force	O
sets	O
of	O
parameters	O
to	O
be	O
equal	O
this	O
method	O
of	O
regularization	O
is	O
often	O
referred	O
to	O
as	O
parameter	O
sharing	O
because	O
we	O
interpret	O
the	O
various	O
models	O
or	O
model	O
components	O
as	O
sharing	O
a	O
unique	O
set	O
of	O
parameters	O
a	O
significant	O
advantage	O
of	O
parameter	O
sharing	O
over	O
regularizing	O
the	O
parameters	O
to	O
be	O
close	O
a	O
norm	O
penalty	O
is	O
that	O
only	O
a	O
subset	O
of	O
the	O
parameters	O
unique	O
set	O
need	O
to	O
be	O
stored	O
in	O
memory	O
in	O
certain	O
models	O
such	O
as	O
the	O
convolutional	O
neural	B
network	I
this	O
can	O
lead	O
to	O
significant	O
reduction	O
in	O
the	O
memory	O
footprint	O
of	O
the	O
model	O
chapter	O
regularization	O
for	O
deep	O
learning	O
convolutional	O
neural	O
networks	O
by	O
far	O
the	O
most	O
popular	O
and	O
extensive	O
use	O
of	O
parameter	O
sharing	O
occurs	O
in	O
convolutional	O
neural	O
networks	O
applied	O
to	O
computer	B
vision	I
natural	O
images	O
have	O
many	O
statistical	O
properties	O
that	O
are	O
invariant	O
to	O
translation	O
for	O
example	B
a	O
photo	O
of	O
a	O
cat	O
remains	O
a	O
photo	O
of	O
a	O
cat	O
if	O
it	O
is	O
translated	O
one	O
pixel	O
to	O
the	O
right	O
cnns	O
take	O
this	O
property	O
into	O
account	O
by	O
sharing	O
parameters	O
across	O
multiple	O
image	O
locations	O
the	O
same	O
feature	B
hidden	O
unit	O
with	O
the	O
same	O
weights	B
is	O
computed	O
over	O
different	O
locations	O
in	O
the	O
input	O
this	O
means	O
that	O
we	O
can	O
find	O
a	O
cat	O
with	O
the	O
same	O
cat	O
detector	O
whether	O
the	O
cat	O
appears	O
at	O
column	O
i	O
or	O
column	O
i	O
in	O
the	O
image	O
parameter	O
sharing	O
has	O
allowed	O
cnns	O
to	O
dramatically	O
lower	O
the	O
number	O
of	O
unique	O
model	O
parameters	O
and	O
to	O
significantly	O
increase	O
network	O
sizes	O
without	O
requiring	O
a	O
corresponding	O
increase	O
in	O
training	O
data	O
it	O
remains	O
one	O
of	O
the	O
best	O
examples	O
of	O
how	O
to	O
effectively	O
incorporate	O
domain	O
knowledge	O
into	O
the	O
network	O
architecture	O
cnns	O
will	O
be	O
discussed	O
in	O
more	O
detail	O
in	O
chapter	O
sparse	O
representations	O
weight	O
decay	O
acts	O
by	O
placing	O
a	O
penalty	O
directly	O
on	O
the	O
model	O
parameters	O
another	O
strategy	O
is	O
to	O
place	O
a	O
penalty	O
on	O
the	O
activations	O
of	O
the	O
units	O
in	O
a	O
neural	B
network	I
encouraging	O
their	O
activations	O
to	O
be	O
sparse	O
this	O
indirectly	O
imposes	O
a	O
complicated	O
penalty	O
on	O
the	O
model	O
parameters	O
we	O
have	O
already	O
discussed	O
section	O
penalization	O
induces	O
a	O
sparse	O
parametrization	O
meaning	O
that	O
many	O
of	O
the	O
parameters	O
become	O
zero	O
close	O
to	O
zero	O
representational	O
sparsity	O
on	O
the	O
other	O
hand	O
describes	O
a	O
representation	O
where	O
many	O
of	O
the	O
elements	O
of	O
the	O
representation	O
are	O
zero	O
close	O
to	O
zero	O
a	O
simplified	O
view	O
of	O
this	O
distinction	O
can	O
be	O
illustrated	O
in	O
the	O
context	O
of	O
linear	O
regression	B
how	O
x	O
r	O
n	O
m	O
y	O
r	O
m	O
n	O
r	O
a	O
chapter	O
regularization	O
for	O
deep	O
learning	O
r	O
y	O
m	O
h	O
r	O
n	O
b	O
m	O
n	O
r	O
in	O
the	O
first	O
expression	O
we	O
have	O
an	O
example	B
of	O
a	O
sparsely	O
parametrized	O
linear	O
regression	B
model	O
in	O
the	O
second	O
we	O
have	O
linear	O
regression	B
with	O
a	O
sparse	O
representation	O
h	O
of	O
the	O
data	O
x	O
that	O
is	O
h	O
is	O
a	O
function	O
of	O
x	O
that	O
in	O
some	O
sense	O
represents	O
the	O
information	O
present	O
in	O
but	O
does	O
so	O
with	O
a	O
sparse	O
vector	O
x	O
representational	O
regularization	O
is	O
accomplished	O
by	O
the	O
same	O
sorts	O
of	O
mechanisms	O
that	O
we	O
have	O
used	O
in	O
parameter	O
regularization	O
norm	O
penalty	O
regularization	O
of	O
representations	O
is	O
performed	O
by	O
adding	O
to	O
the	O
loss	O
function	O
j	O
a	O
norm	O
penalty	O
on	O
the	O
representation	O
this	O
penalty	O
is	O
denoted	O
as	O
before	O
we	O
denote	O
the	O
regularized	O
loss	O
function	O
by	O
j	O
j	O
x	O
y	O
x	O
y	O
j	O
i	O
where	O
larger	O
values	O
of	O
weights	B
the	O
relative	O
contribution	O
of	O
the	O
norm	O
penalty	O
term	O
with	O
corresponding	O
to	O
more	O
regularization	O
hi	O
h	O
just	O
as	O
an	O
penalty	O
on	O
the	O
parameters	O
induces	O
parameter	O
sparsity	O
an	O
l	O
penalty	O
on	O
the	O
elements	O
of	O
the	O
representation	O
induces	O
representational	O
sparsity	O
of	O
course	O
the	O
penalty	O
is	O
only	O
one	O
choice	O
of	O
penalty	O
that	O
can	O
result	O
in	O
a	O
sparse	O
representation	O
others	O
include	O
the	O
penalty	O
derived	O
from	O
a	O
student-t	O
prior	O
on	O
the	O
representation	O
olshausen	O
and	O
field	O
bergstra	O
and	O
kl	O
divergence	O
penalties	O
that	O
are	O
especially	O
useful	O
for	O
representations	O
with	O
elements	O
constrained	O
to	O
lie	O
on	O
the	O
unit	O
interval	O
lee	O
both	O
provide	O
examples	O
of	O
strategies	O
based	O
on	O
regularizing	O
the	O
average	O
activation	O
across	O
several	O
examples	O
i	O
h	O
to	O
m	O
be	O
near	O
some	O
target	O
value	O
such	O
as	O
a	O
vector	O
with	O
for	O
each	O
entry	O
larochelle	O
and	O
bengio	O
goodfellow	O
et	O
al	O
et	O
al	O
and	O
other	O
approaches	O
obtain	O
representational	O
sparsity	O
with	O
a	O
hard	O
constraint	O
on	O
the	O
activation	O
values	O
for	O
example	B
orthogonal	O
matching	O
pursuit	O
et	O
al	O
encodes	O
an	O
input	O
x	O
with	O
the	O
representation	O
h	O
that	O
solves	O
the	O
constrained	O
optimization	O
problem	O
h	O
is	O
the	O
number	O
of	O
non-zero	O
entries	O
of	O
h	O
this	O
problem	O
can	O
be	O
solved	O
where	O
efficiently	O
when	O
w	O
is	O
constrained	O
to	O
be	O
orthogonal	O
this	O
method	O
is	O
often	O
called	O
x	O
w	O
h	O
arg	O
min	O
h	O
h	O
chapter	O
regularization	O
for	O
deep	O
learning	O
omp-k	O
with	O
the	O
value	O
of	O
k	O
specified	O
to	O
indicate	O
the	O
number	O
of	O
non-zero	O
features	O
allowed	O
demonstrated	O
that	O
omp-	O
can	O
be	O
a	O
very	O
effective	O
feature	B
extractor	O
for	O
deep	O
architectures	O
coates	O
and	O
ng	O
essentially	O
any	O
model	O
that	O
has	O
hidden	O
units	O
can	O
be	O
made	O
sparse	O
throughout	O
this	O
book	O
we	O
will	O
see	O
many	O
examples	O
of	O
sparsity	O
regularization	O
used	O
in	O
a	O
variety	O
of	O
contexts	O
bagging	B
and	O
other	O
ensemble	B
methods	I
bagging	B
for	O
bootstrap	O
aggregating	O
is	O
a	O
technique	O
for	O
reducing	O
generalization	B
error	O
by	O
combining	O
several	O
models	O
the	O
idea	O
is	O
to	O
train	O
several	O
different	O
models	O
separately	O
then	O
have	O
all	O
of	O
the	O
models	O
vote	O
on	O
the	O
output	O
for	O
test	O
examples	O
this	O
is	O
an	O
example	B
of	O
a	O
general	O
strategy	O
in	O
machine	B
learning	I
called	O
model	B
averaging	I
techniques	O
employing	O
this	O
strategy	O
are	O
known	O
as	O
ensemble	B
methods	I
breiman	O
the	O
reason	O
that	O
model	B
averaging	I
works	O
is	O
that	O
different	O
models	O
will	O
usually	O
not	O
make	O
all	O
the	O
same	O
errors	O
on	O
the	O
test	B
set	I
consider	O
for	O
example	B
a	O
set	O
of	O
k	O
regression	B
models	O
suppose	O
that	O
each	O
model	O
makes	O
an	O
error	O
i	O
on	O
each	O
example	B
with	O
the	O
errors	O
drawn	O
from	O
a	O
zero-mean	O
multivariate	O
normal	O
distribution	O
with	O
variances	O
e	O
i	O
v	O
and	O
covariances	O
e	O
i	O
j	O
c	O
then	O
the	O
error	O
made	O
by	O
the	O
average	O
prediction	O
of	O
all	O
the	O
ensemble	O
models	O
is	O
k	O
i	O
i	O
the	O
expected	O
squared	O
error	O
of	O
the	O
ensemble	O
predictor	O
is	O
e	O
k	O
i	O
i	O
e	O
k	O
v	O
k	O
i	O
k	O
i	O
i	O
j	O
j	O
i	O
c	O
in	O
the	O
case	O
where	O
the	O
errors	O
are	O
perfectly	O
correlated	O
and	O
c	O
v	O
the	O
mean	B
squared	I
error	I
reduces	O
to	O
v	O
so	O
the	O
model	B
averaging	I
does	O
not	O
help	O
at	O
all	O
in	O
the	O
case	O
where	O
the	O
errors	O
are	O
perfectly	O
uncorrelated	O
and	O
c	O
the	O
expected	O
squared	O
error	O
of	O
the	O
ensemble	O
is	O
only	O
v	O
this	O
means	O
that	O
the	O
expected	O
squared	O
error	O
of	O
the	O
ensemble	O
k	O
decreases	O
linearly	O
with	O
the	O
ensemble	O
size	O
in	O
other	O
words	O
on	O
average	O
the	O
ensemble	O
will	O
perform	O
at	O
least	O
as	O
well	O
as	O
any	O
of	O
its	O
members	O
and	O
if	O
the	O
members	O
make	O
independent	O
errors	O
the	O
ensemble	O
will	O
perform	O
significantly	O
better	O
than	O
its	O
members	O
different	O
ensemble	B
methods	I
construct	O
the	O
ensemble	O
of	O
models	O
in	O
different	O
ways	O
for	O
example	B
each	O
member	O
of	O
the	O
ensemble	O
could	O
be	O
formed	O
by	O
training	O
a	O
completely	O
chapter	O
regularization	O
for	O
deep	O
learning	O
original	O
dataset	B
first	O
resampled	O
dataset	B
first	O
ensemble	O
member	O
second	O
resampled	O
dataset	B
second	O
ensemble	O
member	O
figure	O
a	O
cartoon	O
depiction	O
of	O
how	O
bagging	B
works	O
suppose	O
we	O
train	O
an	O
detector	O
on	O
the	O
dataset	B
depicted	O
above	O
containing	O
an	O
a	O
and	O
a	O
suppose	O
we	O
make	O
two	O
different	O
resampled	O
datasets	O
the	O
bagging	B
training	O
procedure	O
is	O
to	O
construct	O
each	O
of	O
these	O
datasets	O
by	O
sampling	O
with	O
replacement	O
the	O
first	O
dataset	B
omits	O
the	O
and	O
repeats	O
the	O
on	O
this	O
dataset	B
the	O
detector	O
learns	O
that	O
a	O
loop	B
on	O
top	O
of	O
the	O
digit	O
corresponds	O
to	O
an	O
on	O
the	O
second	O
dataset	B
we	O
repeat	O
the	O
and	O
omit	O
the	O
in	O
this	O
case	O
the	O
detector	O
learns	O
that	O
a	O
loop	B
on	O
the	O
bottom	O
of	O
the	O
digit	O
corresponds	O
to	O
an	O
each	O
of	O
these	O
individual	O
classification	B
rules	O
is	O
brittle	O
but	O
if	O
we	O
average	O
their	O
output	O
then	O
the	O
detector	O
is	O
robust	O
achieving	O
maximal	O
confidence	O
only	O
when	O
both	O
loops	O
of	O
the	O
are	O
present	O
different	O
kind	O
of	O
model	O
using	O
a	O
different	O
algorithm	O
or	O
objective	B
function	I
bagging	B
is	O
a	O
method	O
that	O
allows	O
the	O
same	O
kind	O
of	O
model	O
training	O
algorithm	O
and	O
objective	B
function	I
to	O
be	O
reused	O
several	O
times	O
specifically	O
bagging	B
involves	O
constructing	O
k	O
different	O
datasets	O
each	O
dataset	B
has	O
the	O
same	O
number	O
of	O
examples	O
as	O
the	O
original	O
dataset	B
but	O
each	O
dataset	B
is	O
constructed	O
by	O
sampling	O
with	O
replacement	O
from	O
the	O
original	O
dataset	B
this	O
means	O
that	O
with	O
high	O
probability	O
each	O
dataset	B
is	O
missing	O
some	O
of	O
the	O
examples	O
from	O
the	O
original	O
dataset	B
and	O
also	O
contains	O
several	O
duplicate	O
examples	O
average	O
around	O
of	O
the	O
examples	O
from	O
the	O
original	O
dataset	B
are	O
found	O
in	O
the	O
resulting	O
training	O
set	O
if	O
it	O
has	O
the	O
same	O
size	O
as	O
the	O
original	O
model	O
i	O
is	O
then	O
trained	O
on	O
dataset	B
i	O
the	O
differences	O
between	O
which	O
examples	O
are	O
included	O
in	O
each	O
dataset	B
result	O
in	O
differences	O
between	O
the	O
trained	O
models	O
see	O
figure	O
for	O
an	O
example	B
neural	O
networks	O
reach	O
a	O
wide	O
enough	O
variety	O
of	O
solution	O
points	O
that	O
they	O
can	O
often	O
benefit	O
from	O
model	B
averaging	I
even	O
if	O
all	O
of	O
the	O
models	O
are	O
trained	O
on	O
the	O
same	O
dataset	B
differences	O
in	O
random	O
initialization	B
random	O
selection	O
of	O
minibatches	O
differences	O
in	O
hyperparameters	O
or	O
different	O
outcomes	O
of	O
non-deterministic	O
implementations	O
of	O
neural	O
networks	O
are	O
often	O
enough	O
to	O
cause	O
different	O
members	O
of	O
the	O
chapter	O
regularization	O
for	O
deep	O
learning	O
ensemble	O
to	O
make	O
partially	O
independent	O
errors	O
model	B
averaging	I
is	O
an	O
extremely	O
powerful	O
and	O
reliable	O
method	O
for	O
reducing	O
generalization	B
error	O
its	O
use	O
is	O
usually	O
discouraged	O
when	O
benchmarking	O
algorithms	O
for	O
scientific	O
papers	O
because	O
any	O
machine	B
learning	I
algorithm	O
can	O
benefit	O
substantially	O
from	O
model	B
averaging	I
at	O
the	O
price	O
of	O
increased	O
computation	O
and	O
memory	O
for	O
this	O
reason	O
benchmark	O
comparisons	O
are	O
usually	O
made	O
using	O
a	O
single	O
model	O
machine	B
learning	I
contests	O
are	O
usually	O
won	O
by	O
methods	O
using	O
model	B
averaging	I
over	O
dozens	O
of	O
models	O
a	O
recent	O
prominent	O
example	B
is	O
the	O
netflix	O
grand	O
prize	O
not	O
all	O
techniques	O
for	O
constructing	O
ensembles	O
are	O
designed	O
to	O
make	O
the	O
ensemble	O
more	O
regularized	O
than	O
the	O
individual	O
models	O
for	O
example	B
a	O
technique	O
called	O
boosting	O
and	O
schapire	O
a	O
constructs	O
an	O
ensemble	O
with	O
higher	O
capacity	O
than	O
the	O
individual	O
models	O
boosting	O
has	O
been	O
applied	O
to	O
build	O
ensembles	O
of	O
neural	O
networks	O
and	O
bengio	O
by	O
incrementally	O
adding	O
neural	O
networks	O
to	O
the	O
ensemble	O
boosting	O
has	O
also	O
been	O
applied	O
interpreting	O
an	O
individual	O
neural	B
network	I
as	O
an	O
ensemble	O
incrementally	O
adding	O
hidden	O
units	O
to	O
the	O
neural	B
network	I
bengio	O
et	O
al	O
dropout	O
et	O
al	O
provides	O
a	O
computationally	O
inexpensive	O
but	O
dropout	O
powerful	O
method	O
of	O
regularizing	O
a	O
broad	O
family	O
of	O
models	O
to	O
a	O
first	O
approximation	O
dropout	O
can	O
be	O
thought	O
of	O
as	O
a	O
method	O
of	O
making	O
bagging	B
practical	O
for	O
ensembles	O
of	O
very	O
many	O
large	O
neural	O
networks	O
bagging	B
involves	O
training	O
multiple	O
models	O
and	O
evaluating	O
multiple	O
models	O
on	O
each	O
test	O
example	B
this	O
seems	O
impractical	O
when	O
each	O
model	O
is	O
a	O
large	O
neural	B
network	I
since	O
training	O
and	O
evaluating	O
such	O
networks	O
is	O
costly	O
in	O
terms	O
of	O
runtime	O
and	O
memory	O
it	O
is	O
common	O
to	O
use	O
ensembles	O
of	O
five	O
to	O
ten	O
neural	O
networks	O
used	O
six	O
to	O
win	O
the	O
ilsvrc	O
but	O
more	O
than	O
this	O
rapidly	O
becomes	O
unwieldy	O
dropout	O
provides	O
an	O
inexpensive	O
approximation	O
to	O
training	O
and	O
evaluating	O
a	O
bagged	O
ensemble	O
of	O
exponentially	O
many	O
neural	O
networks	O
szegedy	O
et	O
al	O
specifically	O
dropout	O
trains	O
the	O
ensemble	O
consisting	O
of	O
all	O
sub-networks	O
that	O
can	O
be	O
formed	O
by	O
removing	O
non-output	O
units	O
from	O
an	O
underlying	O
base	O
network	O
as	O
illustrated	O
in	O
figure	O
in	O
most	O
modern	O
neural	O
networks	O
based	O
on	O
a	O
series	O
of	O
affine	B
transformations	O
and	O
nonlinearities	O
we	O
can	O
effectively	O
remove	O
a	O
unit	O
from	O
a	O
network	O
by	O
multiplying	O
its	O
output	O
value	O
by	O
zero	O
this	O
procedure	O
requires	O
some	O
slight	O
modification	O
for	O
models	O
such	O
as	O
radial	B
basis	I
function	I
networks	O
which	O
take	O
chapter	O
regularization	O
for	O
deep	O
learning	O
the	O
difference	O
between	O
the	O
unit	O
s	O
state	O
and	O
some	O
reference	O
value	O
here	O
we	O
present	O
the	O
dropout	O
algorithm	O
in	O
terms	O
of	O
multiplication	O
by	O
zero	O
for	O
simplicity	O
but	O
it	O
can	O
be	O
trivially	O
modified	O
to	O
work	O
with	O
other	O
operations	O
that	O
remove	O
a	O
unit	O
from	O
the	O
network	O
recall	B
that	O
to	O
learn	O
with	O
bagging	B
we	O
define	O
k	O
different	O
models	O
construct	O
k	O
different	O
datasets	O
by	O
sampling	O
from	O
the	O
training	O
set	O
with	O
replacement	O
and	O
then	O
train	O
model	O
i	O
on	O
dataset	B
i	O
dropout	O
aims	O
to	O
approximate	O
this	O
process	O
but	O
with	O
an	O
exponentially	O
large	O
number	O
of	O
neural	O
networks	O
specifically	O
to	O
train	O
with	O
dropout	O
we	O
use	O
a	O
minibatch-based	O
learning	O
algorithm	O
that	O
makes	O
small	O
steps	O
such	O
as	O
stochastic	O
gradient	B
descent	O
each	O
time	O
we	O
load	O
an	O
example	B
into	O
a	O
minibatch	B
we	O
randomly	O
sample	O
a	O
different	O
binary	O
mask	O
to	O
apply	O
to	O
all	O
of	O
the	O
input	O
and	O
hidden	O
units	O
in	O
the	O
network	O
the	O
mask	O
for	O
each	O
unit	O
is	O
sampled	O
independently	O
from	O
all	O
of	O
the	O
others	O
the	O
probability	O
of	O
sampling	O
a	O
mask	O
value	O
of	O
one	O
a	O
unit	O
to	O
be	O
included	O
is	O
a	O
hyperparameter	O
fixed	O
before	O
training	O
begins	O
it	O
is	O
not	O
a	O
function	O
of	O
the	O
current	O
value	O
of	O
the	O
model	O
parameters	O
or	O
the	O
input	O
example	B
typically	O
an	O
input	O
unit	O
is	O
included	O
with	O
probability	O
and	O
a	O
hidden	O
unit	O
is	O
included	O
with	O
probability	O
we	O
then	O
run	O
forward	B
propagation	I
back-propagation	B
and	O
the	O
learning	O
update	O
as	O
usual	O
figure	O
illustrates	O
how	O
to	O
run	O
forward	B
propagation	I
with	O
dropout	O
more	O
formally	O
suppose	O
that	O
a	O
mask	O
vector	O
specifies	O
which	O
units	O
to	O
include	O
defines	O
the	O
cost	O
of	O
the	O
model	O
defined	O
by	O
parameters	O
and	O
mask	O
and	O
j	O
then	O
dropout	O
training	O
consists	O
in	O
minimizing	O
e	O
j	O
the	O
expectation	B
contains	O
exponentially	O
many	O
terms	O
but	O
we	O
can	O
obtain	O
an	O
unbiased	B
estimate	O
of	O
its	O
gradient	B
by	O
sampling	O
values	O
of	O
dropout	O
training	O
is	O
not	O
quite	O
the	O
same	O
as	O
bagging	B
training	O
in	O
the	O
case	O
of	O
bagging	B
the	O
models	O
are	O
all	O
independent	O
in	O
the	O
case	O
of	O
dropout	O
the	O
models	O
share	O
parameters	O
with	O
each	O
model	O
inheriting	O
a	O
different	O
subset	O
of	O
parameters	O
from	O
the	O
parent	O
neural	B
network	I
this	O
parameter	O
sharing	O
makes	O
it	O
possible	O
to	O
represent	O
an	O
exponential	O
number	O
of	O
models	O
with	O
a	O
tractable	O
amount	O
of	O
memory	O
in	O
the	O
case	O
of	O
bagging	B
each	O
model	O
is	O
trained	O
to	O
convergence	O
on	O
its	O
respective	O
training	O
set	O
in	O
the	O
case	O
of	O
dropout	O
typically	O
most	O
models	O
are	O
not	O
explicitly	O
trained	O
at	O
all	O
usually	O
the	O
model	O
is	O
large	O
enough	O
that	O
it	O
would	O
be	O
infeasible	O
to	O
sample	O
all	O
possible	O
subnetworks	O
within	O
the	O
lifetime	O
of	O
the	O
universe	O
instead	O
a	O
tiny	O
fraction	O
of	O
the	O
possible	O
sub-networks	O
are	O
each	O
trained	O
for	O
a	O
single	O
step	O
and	O
the	O
parameter	O
sharing	O
causes	O
the	O
remaining	O
sub-networks	O
to	O
arrive	O
at	O
good	O
settings	O
of	O
the	O
parameters	O
these	O
are	O
the	O
only	O
differences	O
beyond	O
these	O
dropout	O
follows	O
the	O
bagging	B
algorithm	O
for	O
example	B
the	O
training	O
set	O
encountered	O
by	O
each	O
sub-network	O
is	O
indeed	O
a	O
subset	O
of	O
the	O
original	O
training	O
set	O
sampled	O
with	O
replacement	O
chapter	O
regularization	O
for	O
deep	O
learning	O
yy	O
h	O
x	O
h	O
x	O
base	O
network	O
h	O
yy	O
yy	O
h	O
x	O
h	O
x	O
yy	O
yy	O
h	O
h	O
h	O
x	O
x	O
x	O
h	O
x	O
h	O
yy	O
yy	O
yy	O
yy	O
x	O
x	O
h	O
h	O
h	O
x	O
h	O
x	O
yy	O
yy	O
yy	O
yy	O
h	O
x	O
h	O
x	O
h	O
x	O
yy	O
yy	O
yy	O
yy	O
h	O
x	O
x	O
x	O
ensemble	O
of	O
subnetworks	O
figure	O
dropout	O
trains	O
an	O
ensemble	O
consisting	O
of	O
all	O
sub-networks	O
that	O
can	O
be	O
constructed	O
by	O
removing	O
non-output	O
units	O
from	O
an	O
underlying	O
base	O
network	O
here	O
we	O
begin	O
with	O
a	O
base	O
network	O
with	O
two	O
visible	O
units	O
and	O
two	O
hidden	O
units	O
there	O
are	O
sixteen	O
possible	O
subsets	O
of	O
these	O
four	O
units	O
we	O
show	O
all	O
sixteen	O
subnetworks	O
that	O
may	O
be	O
formed	O
by	O
dropping	O
out	O
different	O
subsets	O
of	O
units	O
from	O
the	O
original	O
network	O
in	O
this	O
small	O
example	B
a	O
large	O
proportion	O
of	O
the	O
resulting	O
networks	O
have	O
no	O
input	O
units	O
or	O
no	O
path	O
connecting	O
the	O
input	O
to	O
the	O
output	O
this	O
problem	O
becomes	O
insignificant	O
for	O
networks	O
with	O
wider	O
layers	O
where	O
the	O
probability	O
of	O
dropping	O
all	O
possible	O
paths	O
from	O
inputs	O
to	O
outputs	O
becomes	O
smaller	O
chapter	O
regularization	O
for	O
deep	O
learning	O
h	O
x	O
h	O
x	O
yy	O
yy	O
h	O
h	O
h	O
h	O
h	O
h	O
x	O
x	O
figure	O
an	O
example	B
of	O
forward	B
propagation	I
through	O
a	O
feedforward	O
network	O
using	O
dropout	O
this	O
example	B
we	O
use	O
a	O
feedforward	O
network	O
with	O
two	O
input	O
units	O
one	O
hidden	B
layer	I
with	O
two	O
hidden	O
units	O
and	O
one	O
output	O
unit	O
to	O
perform	O
forward	B
propagation	I
with	O
dropout	O
we	O
randomly	O
sample	O
a	O
vector	O
with	O
one	O
entry	O
for	O
each	O
input	O
or	O
hidden	O
unit	O
in	O
the	O
network	O
the	O
entries	O
of	O
are	O
binary	O
and	O
are	O
sampled	O
independently	O
from	O
each	O
other	O
the	O
probability	O
of	O
each	O
entry	O
being	O
for	O
the	O
hidden	O
layers	O
and	O
for	O
the	O
input	O
each	O
unit	O
in	O
the	O
network	O
is	O
multiplied	O
by	O
the	O
corresponding	O
mask	O
and	O
then	O
forward	B
propagation	I
continues	O
through	O
the	O
rest	O
of	O
the	O
network	O
as	O
usual	O
this	O
is	O
equivalent	O
to	O
randomly	O
selecting	O
one	O
of	O
the	O
sub-networks	O
from	O
figure	O
and	O
running	O
forward	B
propagation	I
through	O
it	O
is	O
a	O
hyperparameter	O
usually	O
chapter	O
regularization	O
for	O
deep	O
learning	O
to	O
make	O
a	O
prediction	O
a	O
bagged	O
ensemble	O
must	O
accumulate	O
votes	O
from	O
all	O
of	O
its	O
members	O
we	O
refer	O
to	O
this	O
process	O
as	O
inference	O
in	O
this	O
context	O
so	O
far	O
our	O
description	O
of	O
bagging	B
and	O
dropout	O
has	O
not	O
required	O
that	O
the	O
model	O
be	O
explicitly	O
probabilistic	O
now	O
we	O
assume	O
that	O
the	O
model	O
s	O
role	O
is	O
to	O
output	O
a	O
probability	B
distribution	I
in	O
the	O
case	O
of	O
bagging	B
each	O
model	O
i	O
produces	O
a	O
probability	B
distribution	I
p	O
x	O
the	O
prediction	O
of	O
the	O
ensemble	O
is	O
given	O
by	O
the	O
arithmetic	O
mean	O
of	O
all	O
of	O
these	O
distributions	O
x	O
k	O
p	O
y	O
k	O
p	O
p	O
y	O
in	O
the	O
case	O
of	O
dropout	O
each	O
sub-model	O
defined	O
by	O
mask	O
vector	O
defines	O
a	O
probability	B
distribution	I
py	O
x	O
the	O
arithmetic	O
mean	O
over	O
all	O
masks	O
is	O
given	O
by	O
x	O
where	O
p	O
is	O
the	O
probability	B
distribution	I
that	O
was	O
used	O
to	O
sample	O
at	O
training	O
time	O
because	O
this	O
sum	O
includes	O
an	O
exponential	O
number	O
of	O
terms	O
it	O
is	O
intractable	O
to	O
evaluate	O
except	O
in	O
cases	O
where	O
the	O
structure	O
of	O
the	O
model	O
permits	O
some	O
form	O
of	O
simplification	O
so	O
far	O
deep	O
neural	O
nets	O
are	O
not	O
known	O
to	O
permit	O
any	O
tractable	O
simplification	O
instead	O
we	O
can	O
approximate	O
the	O
inference	O
with	O
sampling	O
by	O
averaging	O
together	O
the	O
output	O
from	O
many	O
masks	O
even	O
masks	O
are	O
often	O
sufficient	O
to	O
obtain	O
good	O
performance	O
however	O
there	O
is	O
an	O
even	O
better	O
approach	O
that	O
allows	O
us	O
to	O
obtain	O
a	O
good	O
approximation	O
to	O
the	O
predictions	O
of	O
the	O
entire	O
ensemble	O
at	O
the	O
cost	O
of	O
only	O
one	O
forward	B
propagation	I
to	O
do	O
so	O
we	O
change	O
to	O
using	O
the	O
geometric	O
mean	O
rather	O
than	O
the	O
arithmetic	O
mean	O
of	O
the	O
ensemble	O
members	O
predicted	O
distributions	O
wardefarley	O
present	O
arguments	O
and	O
empirical	O
evidence	O
that	O
the	O
geometric	O
mean	O
performs	O
comparably	O
to	O
the	O
arithmetic	O
mean	O
in	O
this	O
context	O
et	O
al	O
the	O
geometric	O
mean	O
of	O
multiple	O
probability	O
distributions	O
is	O
not	O
guaranteed	O
to	O
be	O
a	O
probability	B
distribution	I
to	O
guarantee	O
that	O
the	O
result	O
is	O
a	O
probability	B
distribution	I
we	O
impose	O
the	O
requirement	O
that	O
none	O
of	O
the	O
sub-models	O
assigns	O
probability	O
to	O
any	O
event	O
and	O
we	O
renormalize	O
the	O
resulting	O
distribution	O
the	O
unnormalized	B
probability	B
distribution	I
defined	O
directly	O
by	O
the	O
geometric	O
mean	O
is	O
given	O
by	O
pensemble	O
y	O
x	O
p	O
y	O
x	O
where	O
d	O
is	O
the	O
number	O
of	O
units	O
that	O
may	O
be	O
dropped	O
here	O
we	O
use	O
a	O
uniform	B
distribution	I
over	O
to	O
simplify	O
the	O
presentation	O
but	O
non-uniform	O
distributions	O
are	O
chapter	O
regularization	O
for	O
deep	O
learning	O
also	O
possible	O
to	O
make	O
predictions	O
we	O
must	O
re-normalize	O
the	O
ensemble	O
x	O
pensemble	O
y	O
pensemble	O
y	O
pensembley	O
y	O
x	O
x	O
a	O
key	O
insight	O
hinton	O
et	O
al	O
involved	O
in	O
dropout	O
is	O
that	O
we	O
can	O
approxi	O
mate	O
pensemble	O
by	O
evaluating	O
py	O
x	O
in	O
one	O
model	O
the	O
model	O
with	O
all	O
units	O
but	O
with	O
the	O
weights	B
going	O
out	O
of	O
unit	O
i	O
multiplied	O
by	O
the	O
probability	O
of	O
including	O
unit	O
i	O
the	O
motivation	O
for	O
this	O
modification	O
is	O
to	O
capture	O
the	O
right	O
expected	O
value	O
of	O
the	O
output	O
from	O
that	O
unit	O
we	O
call	O
this	O
approach	O
the	O
weight	O
scaling	O
inference	O
rule	O
there	O
is	O
not	O
yet	O
any	O
theoretical	O
argument	O
for	O
the	O
accuracy	B
of	O
this	O
approximate	B
inference	I
rule	O
in	O
deep	O
nonlinear	O
networks	O
but	O
empirically	O
it	O
performs	O
very	O
well	O
because	O
we	O
usually	O
use	O
an	O
inclusion	O
probability	O
of	O
the	O
weight	O
scaling	O
rule	O
usually	O
amounts	O
to	O
dividing	O
the	O
weights	B
by	O
at	O
the	O
end	O
of	O
training	O
and	O
then	O
using	O
the	O
model	O
as	O
usual	O
another	O
way	O
to	O
achieve	O
the	O
same	O
result	O
is	O
to	O
multiply	O
the	O
states	O
of	O
the	O
units	O
by	O
during	O
training	O
either	O
way	O
the	O
goal	O
is	O
to	O
make	O
sure	O
that	O
the	O
expected	O
total	O
input	O
to	O
a	O
unit	O
at	O
test	O
time	O
is	O
roughly	O
the	O
same	O
as	O
the	O
expected	O
total	O
input	O
to	O
that	O
unit	O
at	O
train	O
time	O
even	O
though	O
half	O
the	O
units	O
at	O
train	O
time	O
are	O
missing	O
on	O
average	O
for	O
many	O
classes	O
of	O
models	O
that	O
do	O
not	O
have	O
nonlinear	O
hidden	O
units	O
the	O
weight	O
scaling	O
inference	O
rule	O
is	O
exact	O
for	O
a	O
simple	O
example	B
consider	O
a	O
softmax	O
regression	B
classifier	O
with	O
input	O
variables	O
represented	O
by	O
the	O
vector	O
v	O
n	O
p	O
y	O
y	O
v	O
softmax	O
w	O
v	O
b	O
y	O
we	O
can	O
index	O
into	O
the	O
family	O
of	O
sub-models	O
by	O
element-wise	O
multiplication	O
of	O
the	O
input	O
with	O
a	O
binary	O
vector	O
p	O
y	O
y	O
v	O
d	O
softmax	O
w	O
d	O
v	O
b	O
y	O
the	O
ensemble	O
predictor	O
is	O
defined	O
by	O
re-normalizing	O
the	O
geometric	O
mean	O
over	O
all	O
ensemble	O
members	O
predictions	O
pensemble	O
y	O
y	O
v	O
y	O
pensemble	O
y	O
pensemble	O
y	O
y	O
y	O
v	O
v	O
where	O
pensemble	O
y	O
y	O
v	O
v	O
p	O
y	O
y	O
d	O
n	O
chapter	O
regularization	O
for	O
deep	O
learning	O
to	O
see	O
that	O
the	O
weight	O
scaling	O
rule	O
is	O
exact	O
we	O
can	O
simplify	O
pensemble	O
pensemble	O
y	O
y	O
p	O
y	O
y	O
v	O
softmax	O
d	O
d	O
n	O
n	O
n	O
d	O
n	O
exp	O
d	O
n	O
v	O
y	O
w	O
exp	O
exp	O
d	O
exp	O
y	O
w	O
d	O
n	O
d	O
n	O
d	O
v	O
b	O
y	O
by	O
by	O
v	O
v	O
y	O
d	O
d	O
w	O
y	O
y	O
d	O
y	O
v	O
w	O
d	O
v	O
w	O
b	O
y	O
by	O
n	O
d	O
y	O
w	O
exp	O
v	O
by	O
d	O
y	O
pensemble	O
y	O
y	O
v	O
exp	O
n	O
exp	O
yv	O
by	O
w	O
v	O
by	O
because	O
p	O
will	O
be	O
normalized	O
we	O
can	O
safely	O
ignore	O
multiplication	O
by	O
factors	O
that	O
are	O
constant	O
with	O
respect	O
to	O
substituting	O
this	O
back	O
into	O
equation	O
we	O
obtain	O
a	O
softmax	O
classifier	O
with	O
weights	B
the	O
weight	O
scaling	O
rule	O
is	O
also	O
exact	O
in	O
other	O
settings	O
including	O
regression	B
networks	O
with	O
conditionally	O
normal	O
outputs	O
and	O
deep	O
networks	O
that	O
have	O
hidden	O
layers	O
without	O
nonlinearities	O
however	O
the	O
weight	O
scaling	O
rule	O
is	O
only	O
an	O
approximation	O
for	O
deep	O
models	O
that	O
have	O
nonlinearities	O
though	O
the	O
approximation	O
has	O
not	O
been	O
theoretically	O
characterized	O
it	O
often	O
works	O
well	O
empirically	O
goodfellow	O
et	O
al	O
found	O
experimentally	O
that	O
the	O
weight	O
scaling	O
approximation	O
can	O
work	O
better	O
terms	O
of	O
classification	B
accuracy	B
than	O
monte	O
carlo	O
approximations	O
to	O
the	O
ensemble	O
predictor	O
this	O
held	O
true	O
even	O
when	O
the	O
monte	O
carlo	O
approximation	O
was	O
allowed	O
to	O
sample	O
up	O
to	O
sub-networks	O
found	O
that	O
some	O
models	O
obtain	O
better	O
classification	B
accuracy	B
using	O
twenty	O
samples	O
and	O
gal	O
and	O
ghahramani	O
chapter	O
regularization	O
for	O
deep	O
learning	O
the	O
monte	O
carlo	O
approximation	O
it	O
appears	O
that	O
the	O
optimal	O
choice	O
of	O
inference	O
approximation	O
is	O
problem-dependent	O
et	O
al	O
srivastava	O
showed	O
that	O
dropout	O
is	O
more	O
effective	O
than	O
other	O
standard	O
computationally	O
inexpensive	O
regularizers	O
such	O
as	O
weight	O
decay	O
filter	O
norm	O
constraints	O
and	O
sparse	O
activity	O
regularization	O
dropout	O
may	O
also	O
be	O
combined	O
with	O
other	O
forms	O
of	O
regularization	O
to	O
yield	O
a	O
further	O
improvement	O
one	O
advantage	O
of	O
dropout	O
is	O
that	O
it	O
is	O
very	O
computationally	O
cheap	O
using	O
dropout	O
during	O
training	O
requires	O
only	O
on	O
computation	O
per	O
example	B
per	O
update	O
to	O
generate	O
n	O
random	O
binary	O
numbers	O
and	O
multiply	O
them	O
by	O
the	O
state	O
depending	O
on	O
the	O
implementation	O
it	O
may	O
also	O
require	O
on	O
memory	O
to	O
store	O
these	O
binary	O
numbers	O
until	O
the	O
back-propagation	B
stage	O
running	O
inference	O
in	O
the	O
trained	O
model	O
has	O
the	O
same	O
cost	O
per-example	O
as	O
if	O
dropout	O
were	O
not	O
used	O
though	O
we	O
must	O
pay	O
the	O
cost	O
of	O
dividing	O
the	O
weights	B
by	O
once	O
before	O
beginning	O
to	O
run	O
inference	O
on	O
examples	O
another	O
significant	O
advantage	O
of	O
dropout	O
is	O
that	O
it	O
does	O
not	O
significantly	O
limit	O
the	O
type	O
of	O
model	O
or	O
training	O
procedure	O
that	O
can	O
be	O
used	O
it	O
works	O
well	O
with	O
nearly	O
any	O
model	O
that	O
uses	O
a	O
distributed	O
representation	O
and	O
can	O
be	O
trained	O
with	O
stochastic	O
gradient	B
descent	O
this	O
includes	O
feedforward	O
neural	O
networks	O
probabilistic	O
models	O
such	O
as	O
restricted	O
boltzmann	O
machines	O
and	O
recurrent	O
neural	O
networks	O
and	O
osendorfer	O
pascanu	O
many	O
other	O
regularization	O
strategies	O
of	O
comparable	O
power	O
impose	O
more	O
severe	O
restrictions	O
on	O
the	O
architecture	O
of	O
the	O
model	O
et	O
al	O
et	O
al	O
though	O
the	O
cost	O
per-step	O
of	O
applying	O
dropout	O
to	O
a	O
specific	O
model	O
is	O
negligible	O
the	O
cost	O
of	O
using	O
dropout	O
in	O
a	O
complete	O
system	O
can	O
be	O
significant	O
because	O
dropout	O
is	O
a	O
regularization	O
technique	O
it	O
reduces	O
the	O
effective	B
capacity	I
of	O
a	O
model	O
to	O
offset	O
this	O
effect	O
we	O
must	O
increase	O
the	O
size	O
of	O
the	O
model	O
typically	O
the	O
optimal	O
validation	O
set	O
error	O
is	O
much	O
lower	O
when	O
using	O
dropout	O
but	O
this	O
comes	O
at	O
the	O
cost	O
of	O
a	O
much	O
larger	O
model	O
and	O
many	O
more	O
iterations	O
of	O
the	O
training	O
algorithm	O
for	O
very	O
large	O
datasets	O
regularization	O
confers	O
little	O
reduction	O
in	O
generalization	B
error	O
in	O
these	O
cases	O
the	O
computational	O
cost	O
of	O
using	O
dropout	O
and	O
larger	O
models	O
may	O
outweigh	O
the	O
benefit	O
of	O
regularization	O
when	O
extremely	O
few	O
labeled	O
training	O
examples	O
are	O
available	O
dropout	O
is	O
less	O
outperform	O
dropout	O
on	O
the	O
where	O
fewer	O
than	O
examples	O
when	O
additional	O
unlabeled	O
data	O
is	O
available	O
effective	O
bayesian	O
neural	O
networks	O
alternative	O
splicing	O
dataset	B
are	O
available	O
et	O
al	O
unsupervised	O
feature	B
learning	O
can	O
gain	O
an	O
advantage	O
over	O
dropout	O
xiong	O
et	O
al	O
neal	O
wager	O
showed	O
that	O
when	O
applied	O
to	O
linear	O
regression	B
dropout	O
is	O
equivalent	O
to	O
weight	O
decay	O
with	O
a	O
different	O
weight	O
decay	O
coefficient	O
for	O
et	O
al	O
chapter	O
regularization	O
for	O
deep	O
learning	O
each	O
input	O
feature	B
the	O
magnitude	O
of	O
each	O
feature	B
s	O
weight	O
decay	O
coefficient	O
is	O
determined	O
by	O
its	O
variance	O
similar	O
results	O
hold	O
for	O
other	O
linear	O
models	O
for	O
deep	O
models	O
dropout	O
is	O
not	O
equivalent	O
to	O
weight	O
decay	O
the	O
stochasticity	O
used	O
while	O
training	O
with	O
dropout	O
is	O
not	O
necessary	O
for	O
the	O
approach	O
s	O
success	O
it	O
is	O
just	O
a	O
means	O
of	O
approximating	O
the	O
sum	O
over	O
all	O
submodels	O
wang	O
and	O
manning	O
derived	O
analytical	O
approximations	O
to	O
this	O
marginalization	O
their	O
approximation	O
known	O
as	O
fast	O
dropout	O
resulted	O
in	O
faster	O
convergence	O
time	O
due	O
to	O
the	O
reduced	O
stochasticity	O
in	O
the	O
computation	O
of	O
the	O
gradient	B
this	O
method	O
can	O
also	O
be	O
applied	O
at	O
test	O
time	O
as	O
a	O
more	O
principled	O
also	O
more	O
computationally	O
expensive	O
approximation	O
to	O
the	O
average	O
over	O
all	O
sub-networks	O
than	O
the	O
weight	O
scaling	O
approximation	O
fast	O
dropout	O
has	O
been	O
used	O
to	O
nearly	O
match	O
the	O
performance	O
of	O
standard	O
dropout	O
on	O
small	O
neural	B
network	I
problems	O
but	O
has	O
not	O
yet	O
yielded	O
a	O
significant	O
improvement	O
or	O
been	O
applied	O
to	O
a	O
large	O
problem	O
et	O
al	O
just	O
as	O
stochasticity	O
is	O
not	O
necessary	O
to	O
achieve	O
the	O
regularizing	O
effect	O
of	O
dropout	O
it	O
is	O
also	O
not	O
sufficient	O
to	O
demonstrate	O
this	O
warde-farley	O
designed	O
control	O
experiments	O
using	O
a	O
method	O
called	O
dropout	O
boosting	O
that	O
they	O
designed	O
to	O
use	O
exactly	O
the	O
same	O
mask	O
noise	O
as	O
traditional	O
dropout	O
but	O
lack	O
its	O
regularizing	O
effect	O
dropout	O
boosting	O
trains	O
the	O
entire	O
ensemble	O
to	O
jointly	O
maximize	O
the	O
log-likelihood	O
on	O
the	O
training	O
set	O
in	O
the	O
same	O
sense	O
that	O
traditional	O
dropout	O
is	O
analogous	O
to	O
bagging	B
this	O
approach	O
is	O
analogous	O
to	O
boosting	O
as	O
intended	O
experiments	O
with	O
dropout	O
boosting	O
show	O
almost	O
no	O
regularization	O
effect	O
compared	O
to	O
training	O
the	O
entire	O
network	O
as	O
a	O
single	O
model	O
this	O
demonstrates	O
that	O
the	O
interpretation	O
of	O
dropout	O
as	O
bagging	B
has	O
value	O
beyond	O
the	O
interpretation	O
of	O
dropout	O
as	O
robustness	O
to	O
noise	O
the	O
regularization	O
effect	O
of	O
the	O
bagged	O
ensemble	O
is	O
only	O
achieved	O
when	O
the	O
stochastically	O
sampled	O
ensemble	O
members	O
are	O
trained	O
to	O
perform	O
well	O
independently	O
of	O
each	O
other	O
dropout	O
has	O
inspired	O
other	O
stochastic	O
approaches	O
to	O
training	O
exponentially	O
large	O
ensembles	O
of	O
models	O
that	O
share	O
weights	B
dropconnect	B
is	O
a	O
special	O
case	O
of	O
dropout	O
where	O
each	O
product	O
between	O
a	O
single	O
scalar	O
weight	O
and	O
a	O
single	O
hidden	O
unit	O
state	O
is	O
considered	O
a	O
unit	O
that	O
can	O
be	O
dropped	O
stochastic	O
et	O
al	O
pooling	O
is	O
a	O
form	O
of	O
randomized	O
pooling	O
section	O
for	O
building	O
ensembles	O
of	O
convolutional	O
networks	O
with	O
each	O
convolutional	B
network	I
attending	O
to	O
different	O
spatial	O
locations	O
of	O
each	O
feature	B
map	O
so	O
far	O
dropout	O
remains	O
the	O
most	O
widely	O
used	O
implicit	O
ensemble	O
method	O
one	O
of	O
the	O
key	O
insights	O
of	O
dropout	O
is	O
that	O
training	O
a	O
network	O
with	O
stochastic	O
behavior	O
and	O
making	O
predictions	O
by	O
averaging	O
over	O
multiple	O
stochastic	O
decisions	O
implements	O
a	O
form	O
of	O
bagging	B
with	O
parameter	O
sharing	O
earlier	O
we	O
described	O
chapter	O
regularization	O
for	O
deep	O
learning	O
dropout	O
as	O
bagging	B
an	O
ensemble	O
of	O
models	O
formed	O
by	O
including	O
or	O
excluding	O
units	O
however	O
there	O
is	O
no	O
need	O
for	O
this	O
model	B
averaging	I
strategy	O
to	O
be	O
based	O
on	O
inclusion	O
and	O
exclusion	O
in	O
principle	O
any	O
kind	O
of	O
random	O
modification	O
is	O
admissible	O
in	O
practice	O
we	O
must	O
choose	O
modification	O
families	O
that	O
neural	O
networks	O
are	O
able	O
to	O
learn	O
to	O
resist	O
ideally	O
we	O
should	O
also	O
use	O
model	O
families	O
that	O
allow	O
a	O
fast	O
approximate	B
inference	I
rule	O
we	O
can	O
think	O
of	O
any	O
form	O
of	O
modification	O
parametrized	O
by	O
a	O
vector	O
as	O
training	O
an	O
ensemble	O
consisting	O
of	O
py	O
x	O
for	O
all	O
possible	O
values	O
of	O
there	O
is	O
no	O
requirement	O
that	O
have	O
a	O
finite	O
number	O
of	O
values	O
for	O
example	B
can	O
be	O
real-valued	O
srivastava	O
showed	O
that	O
multiplying	O
the	O
weights	B
by	O
i	O
can	O
outperform	O
dropout	O
based	O
on	O
binary	O
masks	O
because	O
e	O
the	O
standard	O
network	O
automatically	O
implements	O
approximate	B
inference	I
in	O
the	O
ensemble	O
without	O
needing	O
any	O
weight	O
scaling	O
n	O
et	O
al	O
so	O
far	O
we	O
have	O
described	O
dropout	O
purely	O
as	O
a	O
means	O
of	O
performing	O
efficient	O
approximate	O
bagging	B
however	O
there	O
is	O
another	O
view	O
of	O
dropout	O
that	O
goes	O
further	O
than	O
this	O
dropout	O
trains	O
not	O
just	O
a	O
bagged	O
ensemble	O
of	O
models	O
but	O
an	O
ensemble	O
of	O
models	O
that	O
share	O
hidden	O
units	O
this	O
means	O
each	O
hidden	O
unit	O
must	O
be	O
able	O
to	O
perform	O
well	O
regardless	O
of	O
which	O
other	O
hidden	O
units	O
are	O
in	O
the	O
model	O
hidden	O
units	O
must	O
be	O
prepared	O
to	O
be	O
swapped	O
and	O
interchanged	O
between	O
models	O
hinton	O
et	O
al	O
were	O
inspired	O
by	O
an	O
idea	O
from	O
biology	O
sexual	O
reproduction	O
which	O
involves	O
swapping	O
genes	O
between	O
two	O
different	O
organisms	O
creates	O
evolutionary	O
pressure	O
for	O
genes	O
to	O
become	O
not	O
just	O
good	O
but	O
to	O
become	O
readily	O
swapped	O
between	O
different	O
organisms	O
such	O
genes	O
and	O
such	O
features	O
are	O
very	O
robust	O
to	O
changes	O
in	O
their	O
environment	O
because	O
they	O
are	O
not	O
able	O
to	O
incorrectly	O
adapt	O
to	O
unusual	O
features	O
of	O
any	O
one	O
organism	O
or	O
model	O
dropout	O
thus	O
regularizes	O
each	O
hidden	O
unit	O
to	O
be	O
not	O
merely	O
a	O
good	O
feature	B
but	O
a	O
feature	B
that	O
is	O
good	O
in	O
many	O
contexts	O
wardefarley	O
compared	O
dropout	O
training	O
to	O
training	O
of	O
large	O
ensembles	O
and	O
concluded	O
that	O
dropout	O
offers	O
additional	O
improvements	O
to	O
generalization	B
error	O
beyond	O
those	O
obtained	O
by	O
ensembles	O
of	O
independent	O
models	O
et	O
al	O
it	O
is	O
important	O
to	O
understand	O
that	O
a	O
large	O
portion	O
of	O
the	O
power	O
of	O
dropout	O
arises	O
from	O
the	O
fact	O
that	O
the	O
masking	O
noise	O
is	O
applied	O
to	O
the	O
hidden	O
units	O
this	O
can	O
be	O
seen	O
as	O
a	O
form	O
of	O
highly	O
intelligent	O
adaptive	O
destruction	O
of	O
the	O
information	O
content	O
of	O
the	O
input	O
rather	O
than	O
destruction	O
of	O
the	O
raw	O
values	O
of	O
the	O
input	O
for	O
example	B
if	O
the	O
model	O
learns	O
a	O
hidden	O
unit	O
hi	O
that	O
detects	O
a	O
face	O
by	O
finding	O
the	O
nose	O
then	O
dropping	O
h	O
i	O
corresponds	O
to	O
erasing	O
the	O
information	O
that	O
there	O
is	O
a	O
nose	O
in	O
the	O
image	O
the	O
model	O
must	O
learn	O
another	O
h	O
i	O
either	O
that	O
redundantly	O
encodes	O
the	O
presence	O
of	O
a	O
nose	O
or	O
that	O
detects	O
the	O
face	O
by	O
another	O
feature	B
such	O
as	O
the	O
mouth	O
traditional	O
noise	O
injection	O
techniques	O
that	O
add	O
unstructured	O
noise	O
at	O
the	O
input	O
are	O
not	O
able	O
to	O
randomly	O
erase	O
the	O
information	O
about	O
a	O
nose	O
from	O
an	O
image	O
of	O
a	O
face	O
unless	O
the	O
magnitude	O
of	O
the	O
noise	O
is	O
so	O
great	O
that	O
nearly	O
all	O
of	O
the	O
information	O
in	O
chapter	O
regularization	O
for	O
deep	O
learning	O
the	O
image	O
is	O
removed	O
destroying	O
extracted	O
features	O
rather	O
than	O
original	O
values	O
allows	O
the	O
destruction	O
process	O
to	O
make	O
use	O
of	O
all	O
of	O
the	O
knowledge	O
about	O
the	O
input	O
distribution	O
that	O
the	O
model	O
has	O
acquired	O
so	O
far	O
another	O
important	O
aspect	O
of	O
dropout	O
is	O
that	O
the	O
noise	O
is	O
multiplicative	O
if	O
the	O
noise	O
were	O
additive	O
with	O
fixed	O
scale	O
then	O
a	O
rectified	O
linear	O
hidden	O
unit	O
hi	O
with	O
added	O
noise	O
could	O
simply	O
learn	O
to	O
have	O
h	O
i	O
become	O
very	O
large	O
in	O
order	O
to	O
make	O
the	O
added	O
noise	O
insignificant	O
by	O
comparison	O
multiplicative	O
noise	O
does	O
not	O
allow	O
such	O
a	O
pathological	O
solution	O
to	O
the	O
noise	O
robustness	O
problem	O
another	O
deep	O
learning	O
algorithm	O
batch	O
normalization	O
reparametrizes	O
the	O
model	O
in	O
a	O
way	O
that	O
introduces	O
both	O
additive	O
and	O
multiplicative	O
noise	O
on	O
the	O
hidden	O
units	O
at	O
training	O
time	O
the	O
primary	O
purpose	O
of	O
batch	O
normalization	O
is	O
to	O
improve	O
optimization	O
but	O
the	O
noise	O
can	O
have	O
a	O
regularizing	O
effect	O
and	O
sometimes	O
makes	O
dropout	O
unnecessary	O
batch	O
normalization	O
is	O
described	O
further	O
in	O
section	O
adversarial	O
training	O
in	O
many	O
cases	O
neural	O
networks	O
have	O
begun	O
to	O
reach	O
human	O
performance	O
when	O
evaluated	O
on	O
an	O
i	O
i	O
d	O
test	B
set	I
it	O
is	O
natural	O
therefore	O
to	O
wonder	O
whether	O
these	O
models	O
have	O
obtained	O
a	O
true	O
human-level	O
understanding	O
of	O
these	O
tasks	O
in	O
order	O
to	O
probe	O
the	O
level	O
of	O
understanding	O
a	O
network	O
has	O
of	O
the	O
underlying	O
task	O
we	O
can	O
search	O
for	O
examples	O
that	O
the	O
model	O
misclassifies	O
found	O
that	O
even	O
neural	O
networks	O
that	O
perform	O
at	O
human	O
level	O
accuracy	B
have	O
a	O
nearly	O
error	O
rate	O
on	O
examples	O
that	O
are	O
intentionally	O
constructed	O
by	O
using	O
an	O
optimization	O
procedure	O
to	O
search	O
for	O
an	O
input	O
x	O
near	O
a	O
data	O
point	O
x	O
such	O
that	O
the	O
model	O
output	O
is	O
very	O
different	O
at	O
x	O
can	O
be	O
so	O
similar	O
to	O
x	O
that	O
a	O
human	O
observer	O
cannot	O
tell	O
the	O
difference	O
between	O
the	O
original	O
example	B
and	O
the	O
adversarial	B
example	B
but	O
the	O
network	O
can	O
make	O
highly	O
different	O
predictions	O
see	O
figure	O
in	O
many	O
cases	O
x	O
szegedy	O
et	O
al	O
for	O
an	O
example	B
adversarial	O
examples	O
have	O
many	O
implications	O
for	O
example	B
in	O
computer	O
security	O
that	O
are	O
beyond	O
the	O
scope	O
of	O
this	O
chapter	O
however	O
they	O
are	O
interesting	O
in	O
the	O
context	O
of	O
regularization	O
because	O
one	O
can	O
reduce	O
the	O
error	O
rate	O
on	O
the	O
original	O
i	O
i	O
d	O
test	B
set	I
via	O
adversarial	O
training	O
training	O
on	O
adversarially	O
perturbed	O
examples	O
from	O
the	O
training	O
set	O
szegedy	O
et	O
al	O
goodfellow	O
et	O
al	O
et	O
al	O
goodfellow	O
showed	O
that	O
one	O
of	O
the	O
primary	O
causes	O
of	O
these	O
adversarial	O
examples	O
is	O
excessive	O
linearity	O
neural	O
networks	O
are	O
built	O
out	O
of	O
primarily	O
linear	O
building	O
blocks	O
in	O
some	O
experiments	O
the	O
overall	O
function	O
they	O
implement	O
proves	O
to	O
be	O
highly	O
linear	O
as	O
a	O
result	O
these	O
linear	O
functions	O
are	O
easy	O
chapter	O
regularization	O
for	O
deep	O
learning	O
sign	O
xj	O
x	O
y	O
x	O
xj	O
x	O
y	O
sign	O
nematode	O
w	O
confidence	O
gibbon	O
w	O
confidence	O
x	O
y	O
panda	O
w	O
confidence	O
figure	O
a	O
demonstration	O
of	O
adversarial	B
example	B
generation	O
applied	O
to	O
googlenet	O
szegedy	O
et	O
al	O
on	O
imagenet	O
by	O
adding	O
an	O
imperceptibly	O
small	O
vector	O
whose	O
elements	O
are	O
equal	O
to	O
the	O
sign	O
of	O
the	O
elements	O
of	O
the	O
gradient	B
of	O
the	O
cost	O
function	O
with	O
respect	O
to	O
the	O
input	O
we	O
can	O
change	O
googlenet	O
s	O
classification	B
of	O
the	O
image	O
reproduced	O
with	O
permission	O
from	O
goodfellow	O
et	O
al	O
to	O
optimize	O
unfortunately	O
the	O
value	O
of	O
a	O
linear	O
function	O
can	O
change	O
very	O
rapidly	O
if	O
it	O
has	O
numerous	O
inputs	O
if	O
we	O
change	O
each	O
input	O
by	O
then	O
a	O
linear	O
function	O
w	O
which	O
can	O
be	O
a	O
very	O
large	O
with	O
weights	B
w	O
can	O
change	O
by	O
as	O
much	O
as	O
amount	O
if	O
w	O
is	O
high-dimensional	O
adversarial	O
training	O
discourages	O
this	O
highly	O
sensitive	O
locally	O
linear	O
behavior	O
by	O
encouraging	O
the	O
network	O
to	O
be	O
locally	O
constant	O
in	O
the	O
neighborhood	O
of	O
the	O
training	O
data	O
this	O
can	O
be	O
seen	O
as	O
a	O
way	O
of	O
explicitly	O
introducing	O
a	O
local	O
constancy	O
prior	O
into	O
supervised	O
neural	O
nets	O
adversarial	O
training	O
helps	O
to	O
illustrate	O
the	O
power	O
of	O
using	O
a	O
large	O
function	O
family	O
in	O
combination	O
with	O
aggressive	O
regularization	O
purely	O
linear	O
models	O
like	O
logistic	O
regression	B
are	O
not	O
able	O
to	O
resist	O
adversarial	O
examples	O
because	O
they	O
are	O
forced	O
to	O
be	O
linear	O
neural	O
networks	O
are	O
able	O
to	O
represent	O
functions	O
that	O
can	O
range	O
from	O
nearly	O
linear	O
to	O
nearly	O
locally	O
constant	O
and	O
thus	O
have	O
the	O
flexibility	O
to	O
capture	O
linear	O
trends	O
in	O
the	O
training	O
data	O
while	O
still	O
learning	O
to	O
resist	O
local	O
perturbation	O
adversarial	O
examples	O
also	O
provide	O
a	O
means	O
of	O
accomplishing	O
semi-supervised	B
learning	I
at	O
a	O
point	O
x	O
that	O
is	O
not	O
associated	O
with	O
a	O
label	O
in	O
the	O
dataset	B
the	O
model	O
itself	O
assigns	O
some	O
label	O
y	O
the	O
model	O
s	O
label	O
y	O
may	O
not	O
be	O
the	O
true	O
label	O
but	O
if	O
the	O
model	O
is	O
high	O
quality	O
then	O
y	O
has	O
a	O
high	O
probability	O
of	O
providing	O
the	O
true	O
label	O
we	O
can	O
seek	O
an	O
adversarial	B
example	B
x	O
that	O
causes	O
the	O
classifier	O
to	O
output	O
a	O
label	O
y	O
y	O
adversarial	O
examples	O
generated	O
using	O
not	O
the	O
true	O
label	O
but	O
a	O
label	O
provided	O
by	O
a	O
trained	O
model	O
are	O
called	O
virtual	B
adversarial	I
examples	I
the	O
classifier	O
may	O
then	O
be	O
trained	O
to	O
assign	O
the	O
same	O
label	O
to	O
x	O
and	O
x	O
this	O
encourages	O
the	O
classifier	O
to	O
learn	O
a	O
function	O
that	O
is	O
with	O
y	O
et	O
al	O
chapter	O
regularization	O
for	O
deep	O
learning	O
robust	O
to	O
small	O
changes	O
anywhere	O
along	O
the	O
manifold	B
where	O
the	O
unlabeled	O
data	O
lies	O
the	O
assumption	O
motivating	O
this	O
approach	O
is	O
that	O
different	O
classes	O
usually	O
lie	O
on	O
disconnected	O
manifolds	O
and	O
a	O
small	O
perturbation	O
should	O
not	O
be	O
able	O
to	O
jump	O
from	O
one	O
class	O
manifold	B
to	O
another	O
class	O
manifold	B
tangent	B
distance	I
tangent	B
prop	I
and	O
manifold	B
tangent	I
classifier	I
many	O
machine	B
learning	I
algorithms	O
aim	O
to	O
overcome	O
the	O
curse	B
of	I
dimensionality	I
by	O
assuming	O
that	O
the	O
data	O
lies	O
near	O
a	O
low-dimensional	O
manifold	B
as	O
described	O
in	O
section	O
simard	O
et	O
al	O
one	O
of	O
the	O
early	O
attempts	O
to	O
take	O
advantage	O
of	O
the	O
manifold	B
hypothesis	I
is	O
the	O
tangent	B
distance	I
algorithm	O
it	O
is	O
a	O
non-parametric	O
nearest-neighbor	O
algorithm	O
in	O
which	O
the	O
metric	O
used	O
is	O
not	O
the	O
generic	O
euclidean	O
distance	O
but	O
one	O
that	O
is	O
derived	O
from	O
knowledge	O
of	O
the	O
manifolds	O
near	O
which	O
probability	O
concentrates	O
it	O
is	O
assumed	O
that	O
we	O
are	O
trying	O
to	O
classify	O
examples	O
and	O
that	O
examples	O
on	O
the	O
same	O
manifold	B
share	O
the	O
same	O
category	O
since	O
the	O
classifier	O
should	O
be	O
invariant	O
to	O
the	O
local	O
factors	B
of	I
variation	I
that	O
correspond	O
to	O
movement	O
on	O
the	O
manifold	B
it	O
would	O
make	O
sense	O
to	O
use	O
as	O
nearest-neighbor	O
distance	O
between	O
points	O
and	O
the	O
distance	O
between	O
the	O
manifolds	O
and	O
to	O
which	O
they	O
respectively	O
belong	O
although	O
that	O
may	O
be	O
computationally	O
difficult	O
would	O
require	O
solving	O
an	O
optimization	O
problem	O
to	O
find	O
the	O
nearest	O
pair	O
of	O
points	O
on	O
and	O
a	O
cheap	O
alternative	O
that	O
makes	O
sense	O
locally	O
is	O
to	O
approximate	O
mi	O
by	O
its	O
tangent	B
plane	I
at	O
xi	O
and	O
measure	O
the	O
distance	O
between	O
the	O
two	O
tangents	O
or	O
between	O
a	O
tangent	B
plane	I
and	O
a	O
point	O
that	O
can	O
be	O
achieved	O
by	O
solving	O
a	O
low-dimensional	O
linear	O
system	O
the	O
dimension	O
of	O
the	O
manifolds	O
of	O
course	O
this	O
algorithm	O
requires	O
one	O
to	O
specify	O
the	O
tangent	O
vectors	O
simard	O
et	O
al	O
in	O
a	O
related	O
spirit	O
the	O
tangent	B
prop	I
algorithm	O
trains	O
a	O
neural	O
net	O
classifier	O
with	O
an	O
extra	O
penalty	O
to	O
make	O
each	O
output	O
fx	O
of	O
the	O
neural	O
net	O
locally	O
invariant	O
to	O
known	O
factors	B
of	I
variation	I
these	O
factors	B
of	I
variation	I
correspond	O
to	O
movement	O
along	O
the	O
manifold	B
near	O
which	O
examples	O
of	O
the	O
same	O
class	O
concentrate	O
local	O
invariance	B
is	O
achieved	O
by	O
requiring	O
xf	O
to	O
be	O
orthogonal	O
to	O
the	O
known	O
manifold	B
tangent	O
vectors	O
v	O
at	O
x	O
or	O
equivalently	O
that	O
the	O
directional	B
derivative	B
of	O
f	O
at	O
x	O
in	O
the	O
directions	O
v	O
be	O
small	O
by	O
adding	O
a	O
regularization	O
penalty	O
i	O
v	O
xf	O
chapter	O
regularization	O
for	O
deep	O
learning	O
this	O
regularizer	B
can	O
of	O
course	O
be	O
scaled	O
by	O
an	O
appropriate	O
hyperparameter	O
and	O
for	O
most	O
neural	O
networks	O
we	O
would	O
need	O
to	O
sum	O
over	O
many	O
outputs	O
rather	O
than	O
the	O
lone	O
output	O
fx	O
described	O
here	O
for	O
simplicity	O
as	O
with	O
the	O
tangent	B
distance	I
algorithm	O
the	O
tangent	O
vectors	O
are	O
derived	O
a	O
priori	O
usually	O
from	O
the	O
formal	O
knowledge	O
of	O
the	O
effect	O
of	O
transformations	O
such	O
as	O
translation	O
rotation	O
and	O
scaling	O
in	O
images	O
tangent	B
prop	I
has	O
been	O
used	O
not	O
just	O
for	O
supervised	B
learning	I
simard	O
et	O
al	O
but	O
also	O
in	O
the	O
context	O
of	O
reinforcement	O
learning	O
thrun	O
tangent	O
propagation	O
is	O
closely	O
related	O
to	O
dataset	B
augmentation	O
in	O
both	O
cases	O
the	O
user	O
of	O
the	O
algorithm	O
encodes	O
his	O
or	O
her	O
prior	O
knowledge	O
of	O
the	O
task	O
by	O
specifying	O
a	O
set	O
of	O
transformations	O
that	O
should	O
not	O
alter	O
the	O
output	O
of	O
the	O
network	O
the	O
difference	O
is	O
that	O
in	O
the	O
case	O
of	O
dataset	B
augmentation	O
the	O
network	O
is	O
explicitly	O
trained	O
to	O
correctly	O
classify	O
distinct	O
inputs	O
that	O
were	O
created	O
by	O
applying	O
more	O
than	O
an	O
infinitesimal	O
amount	O
of	O
these	O
transformations	O
tangent	O
propagation	O
does	O
not	O
require	O
explicitly	O
visiting	O
a	O
new	O
input	O
point	O
instead	O
it	O
analytically	O
regularizes	O
the	O
model	O
to	O
resist	O
perturbation	O
in	O
the	O
directions	O
corresponding	O
to	O
the	O
specified	O
transformation	O
while	O
this	O
analytical	O
approach	O
is	O
intellectually	O
elegant	O
it	O
has	O
two	O
major	O
drawbacks	O
first	O
it	O
only	O
regularizes	O
the	O
model	O
to	O
resist	O
infinitesimal	O
perturbation	O
explicit	O
dataset	B
augmentation	O
confers	O
resistance	O
to	O
larger	O
perturbations	O
second	O
the	O
infinitesimal	O
approach	O
poses	O
difficulties	O
for	O
models	O
based	O
on	O
rectified	O
linear	O
units	O
these	O
models	O
can	O
only	O
shrink	O
their	O
derivatives	O
by	O
turning	O
units	O
off	O
or	O
shrinking	O
their	O
weights	B
they	O
are	O
not	O
able	O
to	O
shrink	O
their	O
derivatives	O
by	O
saturating	O
at	O
a	O
high	O
value	O
with	O
large	O
weights	B
as	O
sigmoid	O
or	O
tanh	O
units	O
can	O
dataset	B
augmentation	O
works	O
well	O
with	O
rectified	O
linear	O
units	O
because	O
different	O
subsets	O
of	O
rectified	O
units	O
can	O
activate	O
for	O
different	O
transformed	O
versions	O
of	O
each	O
original	O
input	O
szegedy	O
et	O
al	O
goodfellow	O
et	O
al	O
tangent	O
propagation	O
is	O
also	O
related	O
to	O
double	B
backprop	I
and	O
lecun	O
and	O
adversarial	O
training	O
double	B
backprop	I
regularizes	O
the	O
jacobian	O
to	O
be	O
small	O
while	O
adversarial	O
training	O
finds	O
inputs	O
near	O
the	O
original	O
inputs	O
and	O
trains	O
the	O
model	O
to	O
produce	O
the	O
same	O
output	O
on	O
these	O
as	O
on	O
the	O
original	O
inputs	O
tangent	O
propagation	O
and	O
dataset	B
augmentation	O
using	O
manually	O
specified	O
transformations	O
both	O
require	O
that	O
the	O
model	O
should	O
be	O
invariant	O
to	O
certain	O
specified	O
directions	O
of	O
change	O
in	O
the	O
input	O
double	B
backprop	I
and	O
adversarial	O
training	O
both	O
require	O
that	O
the	O
model	O
should	O
be	O
invariant	O
to	O
directions	O
of	O
change	O
in	O
the	O
input	O
so	O
long	O
as	O
the	O
change	O
is	O
small	O
just	O
as	O
dataset	B
augmentation	O
is	O
the	O
non-infinitesimal	O
version	O
of	O
tangent	O
propagation	O
adversarial	O
training	O
is	O
the	O
non-infinitesimal	O
version	O
of	O
double	B
backprop	I
all	O
the	O
manifold	B
tangent	I
classifier	I
rifai	O
et	O
al	O
know	O
the	O
tangent	O
vectors	O
a	O
priori	O
as	O
we	O
will	O
see	O
in	O
chapter	O
eliminates	O
the	O
need	O
to	O
autoencoders	O
can	O
chapter	O
regularization	O
for	O
deep	O
learning	O
x	O
normal	O
tangent	O
et	O
al	O
and	O
manifold	B
tangent	I
classifier	I
figure	O
illustration	O
of	O
the	O
main	O
idea	O
of	O
the	O
tangent	B
prop	I
algorithm	O
simard	O
et	O
al	O
which	O
both	O
regularize	O
the	O
classifier	O
output	O
function	O
fx	O
each	O
curve	O
represents	O
the	O
manifold	B
for	O
a	O
different	O
class	O
illustrated	O
here	O
as	O
a	O
one-dimensional	O
manifold	B
embedded	O
in	O
a	O
two-dimensional	O
space	O
on	O
one	O
curve	O
we	O
have	O
chosen	O
a	O
single	O
point	O
and	O
drawn	O
a	O
vector	O
that	O
is	O
tangent	O
to	O
the	O
class	O
manifold	B
to	O
and	O
touching	O
the	O
manifold	B
and	O
a	O
vector	O
that	O
is	O
normal	O
to	O
the	O
class	O
manifold	B
to	O
the	O
manifold	B
in	O
multiple	O
dimensions	O
there	O
may	O
be	O
many	O
tangent	O
directions	O
and	O
many	O
normal	O
directions	O
we	O
expect	O
the	O
classification	B
function	O
to	O
change	O
rapidly	O
as	O
it	O
moves	O
in	O
the	O
direction	O
normal	O
to	O
the	O
manifold	B
and	O
not	O
to	O
change	O
as	O
it	O
moves	O
along	O
the	O
class	O
manifold	B
both	O
tangent	O
propagation	O
and	O
the	O
manifold	B
tangent	I
classifier	I
regularize	O
fx	O
to	O
not	O
change	O
very	O
much	O
as	O
x	O
moves	O
along	O
the	O
manifold	B
tangent	O
propagation	O
requires	O
the	O
user	O
to	O
manually	O
specify	O
functions	O
that	O
compute	O
the	O
tangent	O
directions	O
as	O
specifying	O
that	O
small	O
translations	O
of	O
images	O
remain	O
in	O
the	O
same	O
class	O
manifold	B
while	O
the	O
manifold	B
tangent	I
classifier	I
estimates	O
the	O
manifold	B
tangent	O
directions	O
by	O
training	O
an	O
autoencoder	O
to	O
fit	O
the	O
training	O
data	O
the	O
use	O
of	O
autoencoders	O
to	O
estimate	O
manifolds	O
will	O
be	O
described	O
in	O
chapter	O
rifai	O
estimate	O
the	O
manifold	B
tangent	O
vectors	O
the	O
manifold	B
tangent	I
classifier	I
makes	O
use	O
of	O
this	O
technique	O
to	O
avoid	O
needing	O
user-specified	O
tangent	O
vectors	O
as	O
illustrated	O
in	O
figure	O
these	O
estimated	O
tangent	O
vectors	O
go	O
beyond	O
the	O
classical	O
invariants	O
that	O
arise	O
out	O
of	O
the	O
geometry	O
of	O
images	O
as	O
translation	O
rotation	O
and	O
scaling	O
and	O
include	O
factors	O
that	O
must	O
be	O
learned	O
because	O
they	O
are	O
object-specific	O
as	O
moving	O
body	O
parts	O
the	O
algorithm	O
proposed	O
with	O
the	O
manifold	B
tangent	I
classifier	I
is	O
therefore	O
simple	O
use	O
an	O
autoencoder	O
to	O
learn	O
the	O
manifold	B
structure	O
by	O
unsupervised	O
learning	O
and	O
use	O
these	O
tangents	O
to	O
regularize	O
a	O
neural	O
net	O
classifier	O
as	O
in	O
tangent	B
prop	I
this	O
chapter	O
has	O
described	O
most	O
of	O
the	O
general	O
strategies	O
used	O
to	O
regularize	O
neural	O
networks	O
regularization	O
is	O
a	O
central	O
theme	O
of	O
machine	B
learning	I
and	O
as	O
such	O
chapter	O
regularization	O
for	O
deep	O
learning	O
will	O
be	O
revisited	O
periodically	O
by	O
most	O
of	O
the	O
remaining	O
chapters	O
another	O
central	O
theme	O
of	O
machine	B
learning	I
is	O
optimization	O
described	O
next	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
deep	O
learning	O
algorithms	O
involve	O
optimization	O
in	O
many	O
contexts	O
for	O
example	B
performing	O
inference	O
in	O
models	O
such	O
as	O
pca	O
involves	O
solving	O
an	O
optimization	O
problem	O
we	O
often	O
use	O
analytical	O
optimization	O
to	O
write	O
proofs	O
or	O
design	O
algorithms	O
of	O
all	O
of	O
the	O
many	O
optimization	O
problems	O
involved	O
in	O
deep	O
learning	O
the	O
most	O
difficult	O
is	O
neural	B
network	I
training	O
it	O
is	O
quite	O
common	O
to	O
invest	O
days	O
to	O
months	O
of	O
time	O
on	O
hundreds	O
of	O
machines	O
in	O
order	O
to	O
solve	O
even	O
a	O
single	O
instance	O
of	O
the	O
neural	B
network	I
training	O
problem	O
because	O
this	O
problem	O
is	O
so	O
important	O
and	O
so	O
expensive	O
a	O
specialized	O
set	O
of	O
optimization	O
techniques	O
have	O
been	O
developed	O
for	O
solving	O
it	O
this	O
chapter	O
presents	O
these	O
optimization	O
techniques	O
for	O
neural	B
network	I
training	O
if	O
you	O
are	O
unfamiliar	O
with	O
the	O
basic	O
principles	O
of	O
gradient-based	O
optimization	O
we	O
suggest	O
reviewing	O
chapter	O
that	O
chapter	O
includes	O
a	O
brief	O
overview	O
of	O
numerical	O
optimization	O
in	O
general	O
this	O
chapter	O
focuses	O
on	O
one	O
particular	O
case	O
of	O
optimization	O
finding	O
the	O
parameters	O
of	O
a	O
neural	B
network	I
that	O
significantly	O
reduce	O
a	O
cost	O
function	O
j	O
which	O
typically	O
includes	O
a	O
performance	O
measure	O
evaluated	O
on	O
the	O
entire	O
training	O
set	O
as	O
well	O
as	O
additional	O
regularization	O
terms	O
we	O
begin	O
with	O
a	O
description	O
of	O
how	O
optimization	O
used	O
as	O
a	O
training	O
algorithm	O
for	O
a	O
machine	B
learning	I
task	O
differs	O
from	O
pure	O
optimization	O
next	O
we	O
present	O
several	O
of	O
the	O
concrete	O
challenges	O
that	O
make	O
optimization	O
of	O
neural	O
networks	O
difficult	O
we	O
then	O
define	O
several	O
practical	O
algorithms	O
including	O
both	O
optimization	O
algorithms	O
themselves	O
and	O
strategies	O
for	O
initializing	O
the	O
parameters	O
more	O
advanced	O
algorithms	O
adapt	O
their	O
learning	O
rates	O
during	O
training	O
or	O
leverage	O
information	O
contained	O
in	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
the	O
second	O
derivatives	O
of	O
the	O
cost	O
function	O
finally	O
we	O
conclude	O
with	O
a	O
review	O
of	O
several	O
optimization	O
strategies	O
that	O
are	O
formed	O
by	O
combining	O
simple	O
optimization	O
algorithms	O
into	O
higher-level	O
procedures	O
how	O
learning	O
differs	O
from	O
pure	O
optimization	O
optimization	O
algorithms	O
used	O
for	O
training	O
of	O
deep	O
models	O
differ	O
from	O
traditional	O
optimization	O
algorithms	O
in	O
several	O
ways	O
machine	B
learning	I
usually	O
acts	O
indirectly	O
in	O
most	O
machine	B
learning	I
scenarios	O
we	O
care	O
about	O
some	O
performance	O
measure	O
p	O
that	O
is	O
defined	O
with	O
respect	O
to	O
the	O
test	B
set	I
and	O
may	O
also	O
be	O
intractable	O
we	O
therefore	O
optimize	O
p	O
only	O
indirectly	O
we	O
reduce	O
a	O
different	O
cost	O
function	O
j	O
in	O
the	O
hope	O
that	O
doing	O
so	O
will	O
improve	O
p	O
this	O
is	O
in	O
contrast	B
to	O
pure	O
optimization	O
where	O
minimizing	O
j	O
is	O
a	O
goal	O
in	O
and	O
of	O
itself	O
optimization	O
algorithms	O
for	O
training	O
deep	O
models	O
also	O
typically	O
include	O
some	O
specialization	O
on	O
the	O
specific	O
structure	O
of	O
machine	B
learning	I
objective	O
functions	O
typically	O
the	O
cost	O
function	O
can	O
be	O
written	O
as	O
an	O
average	O
over	O
the	O
training	O
set	O
such	O
as	O
j	O
e	O
xy	O
pdata	O
l	O
f	O
y	O
where	O
l	O
is	O
the	O
per-example	O
loss	O
function	O
f	O
is	O
the	O
predicted	O
output	O
when	O
the	O
input	O
is	O
x	O
pdata	O
is	O
the	O
empirical	B
distribution	I
in	O
the	O
supervised	B
learning	I
case	O
y	O
is	O
the	O
target	O
output	O
throughout	O
this	O
chapter	O
we	O
develop	O
the	O
unregularized	O
supervised	O
case	O
where	O
the	O
arguments	O
to	O
l	O
are	O
fx	O
and	O
y	O
however	O
it	O
is	O
trivial	O
to	O
extend	O
this	O
development	O
for	O
example	B
to	O
include	O
or	O
x	O
as	O
arguments	O
or	O
to	O
exclude	O
y	O
as	O
arguments	O
in	O
order	O
to	O
develop	O
various	O
forms	O
of	O
regularization	O
or	O
unsupervised	O
learning	O
equation	O
defines	O
an	O
objective	B
function	I
with	O
respect	O
to	O
the	O
training	O
set	O
we	O
would	O
usually	O
prefer	O
to	O
minimize	O
the	O
corresponding	O
objective	B
function	I
where	O
the	O
expectation	B
is	O
taken	O
across	O
the	O
data	O
generating	O
distribution	O
pdata	O
rather	O
than	O
just	O
over	O
the	O
finite	O
training	O
set	O
j	O
pdata	O
e	O
l	O
f	O
y	O
empirical	B
risk	B
minimization	I
the	O
goal	O
of	O
a	O
machine	B
learning	I
algorithm	O
is	O
to	O
reduce	O
the	O
expected	O
generalization	B
error	O
given	O
by	O
equation	O
risk	B
we	O
emphasize	O
here	O
that	O
the	O
expectation	B
is	O
taken	O
over	O
the	O
true	O
underlying	O
distribution	O
pdata	O
if	O
we	O
knew	O
the	O
true	O
distribution	O
pdatax	O
y	O
risk	B
minimization	O
would	O
be	O
an	O
optimization	O
task	O
this	O
quantity	O
is	O
known	O
as	O
the	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
solvable	O
by	O
an	O
optimization	O
algorithm	O
however	O
when	O
we	O
do	O
not	O
know	O
pdatax	O
y	O
but	O
only	O
have	O
a	O
training	O
set	O
of	O
samples	O
we	O
have	O
a	O
machine	B
learning	I
problem	O
the	O
simplest	O
way	O
to	O
convert	O
a	O
machine	B
learning	I
problem	O
back	O
into	O
an	O
optimization	O
problem	O
is	O
to	O
minimize	O
the	O
expected	O
loss	O
on	O
the	O
training	O
set	O
this	O
means	O
replacing	O
the	O
true	O
distribution	O
px	O
y	O
with	O
the	O
empirical	B
distribution	I
px	O
y	O
defined	O
by	O
the	O
training	O
set	O
we	O
now	O
minimize	O
the	O
empirical	B
risk	B
exy	O
pdata	O
l	O
f	O
x	O
y	O
m	O
m	O
l	O
f	O
y	O
where	O
m	O
is	O
the	O
number	O
of	O
training	O
examples	O
the	O
training	O
process	O
based	O
on	O
minimizing	O
this	O
average	O
training	B
error	I
is	O
known	O
as	O
empirical	B
risk	B
minimization	I
in	O
this	O
setting	O
machine	B
learning	I
is	O
still	O
very	O
similar	O
to	O
straightforward	O
optimization	O
rather	O
than	O
optimizing	O
the	O
risk	B
directly	O
we	O
optimize	O
the	O
empirical	B
risk	B
and	O
hope	O
that	O
the	O
risk	B
decreases	O
significantly	O
as	O
well	O
a	O
variety	O
of	O
theoretical	O
results	O
establish	O
conditions	O
under	O
which	O
the	O
true	O
risk	B
can	O
be	O
expected	O
to	O
decrease	O
by	O
various	O
amounts	O
however	O
empirical	B
risk	B
minimization	I
is	O
prone	O
to	O
overfitting	O
models	O
with	O
high	O
capacity	O
can	O
simply	O
memorize	O
the	O
training	O
set	O
in	O
many	O
cases	O
empirical	B
risk	B
minimization	I
is	O
not	O
really	O
feasible	O
the	O
most	O
effective	O
modern	O
optimization	O
algorithms	O
are	O
based	O
on	O
gradient	B
descent	O
but	O
many	O
useful	O
loss	O
functions	O
such	O
as	O
loss	O
have	O
no	O
useful	O
derivatives	O
derivative	B
is	O
either	O
zero	O
or	O
undefined	O
everywhere	O
these	O
two	O
problems	O
mean	O
that	O
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
rarely	O
use	O
empirical	B
risk	B
minimization	I
instead	O
we	O
must	O
use	O
a	O
slightly	O
different	O
approach	O
in	O
which	O
the	O
quantity	O
that	O
we	O
actually	O
optimize	O
is	O
even	O
more	O
different	O
from	O
the	O
quantity	O
that	O
we	O
truly	O
want	O
to	O
optimize	O
surrogate	O
loss	O
functions	O
and	O
early	O
stopping	O
sometimes	O
the	O
loss	O
function	O
we	O
actually	O
care	O
about	O
classification	B
error	O
is	O
not	O
one	O
that	O
can	O
be	O
optimized	O
efficiently	O
for	O
example	B
exactly	O
minimizing	O
expected	O
loss	O
is	O
typically	O
intractable	O
in	O
the	O
input	O
dimension	O
even	O
for	O
a	O
linear	O
classifier	O
and	O
savard	O
in	O
such	O
situations	O
one	O
typically	O
optimizes	O
a	O
surrogate	B
loss	I
function	I
instead	O
which	O
acts	O
as	O
a	O
proxy	O
but	O
has	O
advantages	O
for	O
example	B
the	O
negative	O
log-likelihood	O
of	O
the	O
correct	O
class	O
is	O
typically	O
used	O
as	O
a	O
surrogate	O
for	O
the	O
loss	O
the	O
negative	O
log-likelihood	O
allows	O
the	O
model	O
to	O
estimate	O
the	O
conditional	B
probability	I
of	O
the	O
classes	O
given	O
the	O
input	O
and	O
if	O
the	O
model	O
can	O
do	O
that	O
well	O
then	O
it	O
can	O
pick	O
the	O
classes	O
that	O
yield	O
the	O
least	O
classification	B
error	O
in	O
expectation	B
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
in	O
some	O
cases	O
a	O
surrogate	B
loss	I
function	I
actually	O
results	O
in	O
being	O
able	O
to	O
learn	O
more	O
for	O
example	B
the	O
test	B
set	I
loss	O
often	O
continues	O
to	O
decrease	O
for	O
a	O
long	O
time	O
after	O
the	O
training	O
set	O
loss	O
has	O
reached	O
zero	O
when	O
training	O
using	O
the	O
log-likelihood	O
surrogate	O
this	O
is	O
because	O
even	O
when	O
the	O
expected	O
loss	O
is	O
zero	O
one	O
can	O
improve	O
the	O
robustness	O
of	O
the	O
classifier	O
by	O
further	O
pushing	O
the	O
classes	O
apart	O
from	O
each	O
other	O
obtaining	O
a	O
more	O
confident	O
and	O
reliable	O
classifier	O
thus	O
extracting	O
more	O
information	O
from	O
the	O
training	O
data	O
than	O
would	O
have	O
been	O
possible	O
by	O
simply	O
minimizing	O
the	O
average	O
loss	O
on	O
the	O
training	O
set	O
a	O
very	O
important	O
difference	O
between	O
optimization	O
in	O
general	O
and	O
optimization	O
as	O
we	O
use	O
it	O
for	O
training	O
algorithms	O
is	O
that	O
training	O
algorithms	O
do	O
not	O
usually	O
halt	O
at	O
a	O
local	O
minimum	O
instead	O
a	O
machine	B
learning	I
algorithm	O
usually	O
minimizes	O
a	O
surrogate	B
loss	I
function	I
but	O
halts	O
when	O
a	O
convergence	O
criterion	O
based	O
on	O
early	O
stopping	O
is	O
satisfied	O
typically	O
the	O
early	O
stopping	O
criterion	O
is	O
based	O
on	O
the	O
true	O
underlying	O
loss	O
function	O
such	O
as	O
loss	O
measured	O
on	O
a	O
validation	O
set	O
and	O
is	O
designed	O
to	O
cause	O
the	O
algorithm	O
to	O
halt	O
whenever	O
overfitting	O
begins	O
to	O
occur	O
training	O
often	O
halts	O
while	O
the	O
surrogate	B
loss	I
function	I
still	O
has	O
large	O
derivatives	O
which	O
is	O
very	O
different	O
from	O
the	O
pure	O
optimization	O
setting	O
where	O
an	O
optimization	O
algorithm	O
is	O
considered	O
to	O
have	O
converged	O
when	O
the	O
gradient	B
becomes	O
very	O
small	O
batch	O
and	O
minibatch	B
algorithms	O
one	O
aspect	O
of	O
machine	B
learning	I
algorithms	O
that	O
separates	O
them	O
from	O
general	O
optimization	O
algorithms	O
is	O
that	O
the	O
objective	B
function	I
usually	O
decomposes	O
as	O
a	O
sum	O
over	O
the	O
training	O
examples	O
optimization	O
algorithms	O
for	O
machine	B
learning	I
typically	O
compute	O
each	O
update	O
to	O
the	O
parameters	O
based	O
on	O
an	O
expected	O
value	O
of	O
the	O
cost	O
function	O
estimated	O
using	O
only	O
a	O
subset	O
of	O
the	O
terms	O
of	O
the	O
full	O
cost	O
function	O
for	O
example	B
maximum	B
likelihood	I
estimation	O
problems	O
when	O
viewed	O
in	O
log	O
space	O
decompose	O
into	O
a	O
sum	O
over	O
each	O
example	B
ml	O
arg	O
max	O
log	O
pmodelx	O
y	O
m	O
maximizing	O
this	O
sum	O
is	O
equivalent	O
to	O
maximizing	O
the	O
expectation	B
over	O
the	O
empirical	B
distribution	I
defined	O
by	O
the	O
training	O
set	O
j	O
exy	O
pdata	O
log	O
pmodel	O
x	O
y	O
most	O
of	O
the	O
properties	O
of	O
the	O
objective	B
function	I
j	O
used	O
by	O
most	O
of	O
our	O
optimization	O
algorithms	O
are	O
also	O
expectations	O
over	O
the	O
training	O
set	O
for	O
example	B
the	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
most	O
commonly	O
used	O
property	O
is	O
the	O
gradient	B
j	O
exy	O
pdata	O
log	O
pmodel	O
x	O
y	O
computing	O
this	O
expectation	B
exactly	O
is	O
very	O
expensive	O
because	O
it	O
requires	O
evaluating	O
the	O
model	O
on	O
every	O
example	B
in	O
the	O
entire	O
dataset	B
in	O
practice	O
we	O
can	O
compute	O
these	O
expectations	O
by	O
randomly	O
sampling	O
a	O
small	O
number	O
of	O
examples	O
from	O
the	O
dataset	B
then	O
taking	O
the	O
average	O
over	O
only	O
those	O
examples	O
recall	B
that	O
the	O
standard	B
error	I
of	O
the	O
mean	O
n	O
n	O
where	O
is	O
the	O
true	O
standard	B
deviation	I
of	O
the	O
value	O
of	O
samples	O
is	O
given	O
by	O
n	O
shows	O
that	O
there	O
are	O
less	O
than	O
linear	O
returns	O
the	O
samples	O
the	O
denominator	O
of	O
to	O
using	O
more	O
examples	O
to	O
estimate	O
the	O
gradient	B
compare	O
two	O
hypothetical	O
estimates	O
of	O
the	O
gradient	B
one	O
based	O
on	O
examples	O
and	O
another	O
based	O
on	O
examples	O
the	O
latter	O
requires	O
times	O
more	O
computation	O
than	O
the	O
former	O
but	O
reduces	O
the	O
standard	B
error	I
of	O
the	O
mean	O
only	O
by	O
a	O
factor	O
of	O
most	O
optimization	O
algorithms	O
converge	O
much	O
faster	O
terms	O
of	O
total	O
computation	O
not	O
in	O
terms	O
of	O
number	O
of	O
updates	O
if	O
they	O
are	O
allowed	O
to	O
rapidly	O
compute	O
approximate	O
estimates	O
of	O
the	O
gradient	B
rather	O
than	O
slowly	O
computing	O
the	O
exact	O
gradient	B
estimated	O
from	O
another	O
consideration	O
motivating	O
statistical	O
estimation	O
of	O
the	O
gradient	B
from	O
a	O
small	O
number	O
of	O
samples	O
is	O
redundancy	O
in	O
the	O
training	O
set	O
in	O
the	O
worst	O
case	O
all	O
m	O
samples	O
in	O
the	O
training	O
set	O
could	O
be	O
identical	O
copies	O
of	O
each	O
other	O
a	O
samplingbased	O
estimate	O
of	O
the	O
gradient	B
could	O
compute	O
the	O
correct	O
gradient	B
with	O
a	O
single	O
sample	O
using	O
m	O
times	O
less	O
computation	O
than	O
the	O
naive	O
approach	O
in	O
practice	O
we	O
are	O
unlikely	O
to	O
truly	O
encounter	O
this	O
worst-case	O
situation	O
but	O
we	O
may	O
find	O
large	O
numbers	O
of	O
examples	O
that	O
all	O
make	O
very	O
similar	O
contributions	O
to	O
the	O
gradient	B
optimization	O
algorithms	O
that	O
use	O
the	O
entire	O
training	O
set	O
are	O
called	O
batch	O
or	O
deterministic	O
gradient	B
methods	O
because	O
they	O
process	O
all	O
of	O
the	O
training	O
examples	O
simultaneously	O
in	O
a	O
large	O
batch	O
this	O
terminology	O
can	O
be	O
somewhat	O
confusing	O
because	O
the	O
word	O
batch	O
is	O
also	O
often	O
used	O
to	O
describe	O
the	O
minibatch	B
used	O
by	O
minibatch	B
stochastic	O
gradient	B
descent	O
typically	O
the	O
term	O
batch	O
gradient	B
descent	O
implies	O
the	O
use	O
of	O
the	O
full	O
training	O
set	O
while	O
the	O
use	O
of	O
the	O
term	O
batch	O
to	O
describe	O
a	O
group	O
of	O
examples	O
does	O
not	O
for	O
example	B
it	O
is	O
very	O
common	O
to	O
use	O
the	O
term	O
batch	O
size	O
to	O
describe	O
the	O
size	O
of	O
a	O
minibatch	B
optimization	O
algorithms	O
that	O
use	O
only	O
a	O
single	O
example	B
at	O
a	O
time	O
are	O
sometimes	O
called	O
stochastic	O
or	O
sometimes	O
online	O
methods	O
the	O
term	O
online	O
is	O
usually	O
reserved	O
for	O
the	O
case	O
where	O
the	O
examples	O
are	O
drawn	O
from	O
a	O
stream	O
of	O
continually	O
created	O
examples	O
rather	O
than	O
from	O
a	O
fixed-size	O
training	O
set	O
over	O
which	O
several	O
passes	O
are	O
made	O
most	O
algorithms	O
used	O
for	O
deep	O
learning	O
fall	O
somewhere	O
in	O
between	O
using	O
more	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
than	O
one	O
but	O
less	O
than	O
all	O
of	O
the	O
training	O
examples	O
these	O
were	O
traditionally	O
called	O
minibatch	B
or	O
minibatch	B
stochastic	O
methods	O
and	O
it	O
is	O
now	O
common	O
to	O
simply	O
call	O
them	O
stochastic	O
methods	O
the	O
canonical	O
example	B
of	O
a	O
stochastic	O
method	O
is	O
stochastic	O
gradient	B
descent	O
presented	O
in	O
detail	O
in	O
section	O
minibatch	B
sizes	O
are	O
generally	O
driven	O
by	O
the	O
following	O
factors	O
larger	O
batches	O
provide	O
a	O
more	O
accurate	O
estimate	O
of	O
the	O
gradient	B
but	O
with	O
less	O
than	O
linear	O
returns	O
multicore	O
architectures	O
are	O
usually	O
underutilized	O
by	O
extremely	O
small	O
batches	O
this	O
motivates	O
using	O
some	O
absolute	O
minimum	O
batch	O
size	O
below	O
which	O
there	O
is	O
no	O
reduction	O
in	O
the	O
time	O
to	O
process	O
a	O
minibatch	B
if	O
all	O
examples	O
in	O
the	O
batch	O
are	O
to	O
be	O
processed	O
in	O
parallel	O
is	O
typically	O
the	O
case	O
then	O
the	O
amount	O
of	O
memory	O
scales	O
with	O
the	O
batch	O
size	O
for	O
many	O
hardware	O
setups	O
this	O
is	O
the	O
limiting	O
factor	O
in	O
batch	O
size	O
some	O
kinds	O
of	O
hardware	O
achieve	O
better	O
runtime	O
with	O
specific	O
sizes	O
of	O
arrays	O
especially	O
when	O
using	O
gpus	O
it	O
is	O
common	O
for	O
power	O
of	O
batch	O
sizes	O
to	O
offer	O
better	O
runtime	O
typical	O
power	O
of	O
batch	O
sizes	O
range	O
from	O
to	O
with	O
sometimes	O
being	O
attempted	O
for	O
large	O
models	O
wilson	O
and	O
martinez	O
small	O
batches	O
can	O
offer	O
a	O
regularizing	O
effect	O
perhaps	O
due	O
to	O
the	O
noise	O
they	O
add	O
to	O
the	O
learning	O
process	O
generalization	B
error	O
is	O
often	O
best	O
for	O
a	O
batch	O
size	O
of	O
training	O
with	O
such	O
a	O
small	O
batch	O
size	O
might	O
require	O
a	O
small	O
learning	B
rate	I
to	O
maintain	O
stability	O
due	O
to	O
the	O
high	O
variance	O
in	O
the	O
estimate	O
of	O
the	O
gradient	B
the	O
total	O
runtime	O
can	O
be	O
very	O
high	O
due	O
to	O
the	O
need	O
to	O
make	O
more	O
steps	O
both	O
because	O
of	O
the	O
reduced	O
learning	B
rate	I
and	O
because	O
it	O
takes	O
more	O
steps	O
to	O
observe	O
the	O
entire	O
training	O
set	O
different	O
kinds	O
of	O
algorithms	O
use	O
different	O
kinds	O
of	O
information	O
from	O
the	O
minibatch	B
in	O
different	O
ways	O
some	O
algorithms	O
are	O
more	O
sensitive	O
to	O
sampling	O
error	O
than	O
others	O
either	O
because	O
they	O
use	O
information	O
that	O
is	O
difficult	O
to	O
estimate	O
accurately	O
with	O
few	O
samples	O
or	O
because	O
they	O
use	O
information	O
in	O
ways	O
that	O
amplify	O
sampling	O
errors	O
more	O
methods	O
that	O
compute	O
updates	O
based	O
only	O
on	O
the	O
gradient	B
g	O
are	O
usually	O
relatively	O
robust	O
and	O
can	O
handle	O
smaller	O
batch	O
sizes	O
like	O
second-order	O
methods	O
which	O
use	O
also	O
the	O
hessian	B
matrix	O
h	O
and	O
compute	O
updates	O
such	O
as	O
typically	O
require	O
much	O
larger	O
batch	O
sizes	O
like	O
these	O
large	O
batch	O
h	O
suppose	O
sizes	O
are	O
required	O
to	O
minimize	O
fluctuations	O
in	O
the	O
estimates	O
of	O
h	O
that	O
h	O
is	O
estimated	O
perfectly	O
but	O
has	O
a	O
poor	O
condition	B
number	I
multiplication	O
by	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
h	O
or	O
its	O
inverse	O
amplifies	O
pre-existing	O
errors	O
in	O
this	O
case	O
estimation	O
errors	O
in	O
g	O
very	O
small	O
changes	O
in	O
the	O
estimate	O
of	O
g	O
can	O
thus	O
cause	O
large	O
changes	O
in	O
the	O
update	O
even	O
if	O
h	O
were	O
estimated	O
perfectly	O
of	O
course	O
h	O
will	O
be	O
estimated	O
only	O
h	O
will	O
contain	O
even	O
more	O
error	O
than	O
we	O
would	O
approximately	O
so	O
the	O
update	O
h	O
predict	O
from	O
applying	O
a	O
poorly	O
conditioned	O
operation	B
to	O
the	O
estimate	O
of	O
it	O
is	O
also	O
crucial	O
that	O
the	O
minibatches	O
be	O
selected	O
randomly	O
computing	O
an	O
unbiased	B
estimate	O
of	O
the	O
expected	O
gradient	B
from	O
a	O
set	O
of	O
samples	O
requires	O
that	O
those	O
samples	O
be	O
independent	O
we	O
also	O
wish	O
for	O
two	O
subsequent	O
gradient	B
estimates	O
to	O
be	O
independent	O
from	O
each	O
other	O
so	O
two	O
subsequent	O
minibatches	O
of	O
examples	O
should	O
also	O
be	O
independent	O
from	O
each	O
other	O
many	O
datasets	O
are	O
most	O
naturally	O
arranged	O
in	O
a	O
way	O
where	O
successive	O
examples	O
are	O
highly	O
correlated	O
for	O
example	B
we	O
might	O
have	O
a	O
dataset	B
of	O
medical	O
data	O
with	O
a	O
long	O
list	O
of	O
blood	O
sample	O
test	O
results	O
this	O
list	O
might	O
be	O
arranged	O
so	O
that	O
first	O
we	O
have	O
five	O
blood	O
samples	O
taken	O
at	O
different	O
times	O
from	O
the	O
first	O
patient	O
then	O
we	O
have	O
three	O
blood	O
samples	O
taken	O
from	O
the	O
second	O
patient	O
then	O
the	O
blood	O
samples	O
from	O
the	O
third	O
patient	O
and	O
so	O
on	O
if	O
we	O
were	O
to	O
draw	O
examples	O
in	O
order	O
from	O
this	O
list	O
then	O
each	O
of	O
our	O
minibatches	O
would	O
be	O
extremely	O
biased	O
because	O
it	O
would	O
represent	O
primarily	O
one	O
patient	O
out	O
of	O
the	O
many	O
patients	O
in	O
the	O
dataset	B
in	O
cases	O
such	O
as	O
these	O
where	O
the	O
order	O
of	O
the	O
dataset	B
holds	O
some	O
significance	O
it	O
is	O
necessary	O
to	O
shu	O
e	O
the	O
examples	O
before	O
selecting	O
minibatches	O
for	O
very	O
large	O
datasets	O
for	O
example	B
datasets	O
containing	O
billions	O
of	O
examples	O
in	O
a	O
data	O
center	O
it	O
can	O
be	O
impractical	O
to	O
sample	O
examples	O
truly	O
uniformly	O
at	O
random	O
every	O
time	O
we	O
want	O
to	O
construct	O
a	O
minibatch	B
fortunately	O
in	O
practice	O
it	O
is	O
usually	O
sufficient	O
to	O
shu	O
e	O
the	O
order	O
of	O
the	O
dataset	B
once	O
and	O
then	O
store	O
it	O
in	O
shu	O
ed	O
fashion	O
this	O
will	O
impose	O
a	O
fixed	O
set	O
of	O
possible	O
minibatches	O
of	O
consecutive	O
examples	O
that	O
all	O
models	O
trained	O
thereafter	O
will	O
use	O
and	O
each	O
individual	O
model	O
will	O
be	O
forced	O
to	O
reuse	O
this	O
ordering	O
every	O
time	O
it	O
passes	O
through	O
the	O
training	O
data	O
however	O
this	O
deviation	O
from	O
true	O
random	O
selection	O
does	O
not	O
seem	O
to	O
have	O
a	O
significant	O
detrimental	O
effect	O
failing	O
to	O
ever	O
shu	O
e	O
the	O
examples	O
in	O
any	O
way	O
can	O
seriously	O
reduce	O
the	O
effectiveness	O
of	O
the	O
algorithm	O
many	O
optimization	O
problems	O
in	O
machine	B
learning	I
decompose	O
over	O
examples	O
well	O
enough	O
that	O
we	O
can	O
compute	O
entire	O
separate	O
updates	O
over	O
different	O
examples	O
in	O
parallel	O
in	O
other	O
words	O
we	O
can	O
compute	O
the	O
update	O
that	O
minimizes	O
j	O
for	O
one	O
minibatch	B
of	O
examples	O
x	O
at	O
the	O
same	O
time	O
that	O
we	O
compute	O
the	O
update	O
for	O
several	O
other	O
minibatches	O
such	O
asynchronous	O
parallel	O
distributed	O
approaches	O
are	O
discussed	O
further	O
in	O
section	O
an	O
interesting	O
motivation	O
for	O
minibatch	B
stochastic	O
gradient	B
descent	O
is	O
that	O
it	O
follows	O
the	O
gradient	B
of	O
the	O
true	O
generalization	B
error	O
so	O
long	O
as	O
no	O
examples	O
are	O
repeated	O
most	O
implementations	O
of	O
minibatch	B
stochastic	O
gradient	B
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
descent	O
shu	O
e	O
the	O
dataset	B
once	O
and	O
then	O
pass	O
through	O
it	O
multiple	O
times	O
on	O
the	O
first	O
pass	O
each	O
minibatch	B
is	O
used	O
to	O
compute	O
an	O
unbiased	B
estimate	O
of	O
the	O
true	O
generalization	B
error	O
on	O
the	O
second	O
pass	O
the	O
estimate	O
becomes	O
biased	O
because	O
it	O
is	O
formed	O
by	O
re-sampling	O
values	O
that	O
have	O
already	O
been	O
used	O
rather	O
than	O
obtaining	O
new	O
fair	O
samples	O
from	O
the	O
data	O
generating	O
distribution	O
the	O
fact	O
that	O
stochastic	O
gradient	B
descent	O
minimizes	O
generalization	B
error	O
is	O
easiest	O
to	O
see	O
in	O
the	O
online	O
learning	O
case	O
where	O
examples	O
or	O
minibatches	O
are	O
drawn	O
from	O
a	O
stream	O
of	O
data	O
in	O
other	O
words	O
instead	O
of	O
receiving	O
a	O
fixed-size	O
training	O
set	O
the	O
learner	O
is	O
similar	O
to	O
a	O
living	O
being	O
who	O
sees	O
a	O
new	O
example	B
at	O
each	O
instant	O
with	O
every	O
example	B
y	O
coming	O
from	O
the	O
data	O
generating	O
distribution	O
pdatax	O
y	O
in	O
this	O
scenario	O
examples	O
are	O
never	O
repeated	O
every	O
experience	O
is	O
a	O
fair	O
sample	O
from	O
p	O
data	O
the	O
equivalence	O
is	O
easiest	O
to	O
derive	O
when	O
both	O
x	O
and	O
y	O
are	O
discrete	O
in	O
this	O
case	O
the	O
generalization	B
error	O
can	O
be	O
written	O
as	O
a	O
sum	O
x	O
y	O
j	O
pdata	O
x	O
y	O
l	O
f	O
x	O
y	O
with	O
the	O
exact	O
gradient	B
g	O
j	O
y	O
pdata	O
x	O
y	O
l	O
f	O
y	O
and	O
equation	O
we	O
have	O
already	O
seen	O
the	O
same	O
fact	O
demonstrated	O
for	O
the	O
log-likelihood	O
in	O
equal	O
tion	B
besides	O
the	O
likelihood	O
a	O
similar	O
result	O
can	O
be	O
derived	O
when	O
x	O
and	O
y	O
are	O
continuous	O
under	O
mild	O
assumptions	O
regarding	O
pdata	O
and	O
we	O
observe	O
now	O
that	O
this	O
holds	O
for	O
other	O
functions	O
hence	O
we	O
can	O
obtain	O
an	O
unbiased	B
estimator	O
of	O
the	O
exact	O
gradient	B
of	O
the	O
with	O
corfrom	O
the	O
data	O
generating	O
distribution	O
pdata	O
and	O
computing	O
generalization	B
error	O
by	O
sampling	O
a	O
minibatch	B
of	O
examples	O
responding	O
targets	O
y	O
the	O
gradient	B
of	O
the	O
loss	O
with	O
respect	O
to	O
the	O
parameters	O
for	O
that	O
minibatch	B
x	O
x	O
m	O
g	O
i	O
l	O
f	O
y	O
updating	O
in	O
the	O
direction	O
of	O
g	O
performs	O
sgd	O
on	O
the	O
generalization	B
error	O
of	O
course	O
this	O
interpretation	O
only	O
applies	O
when	O
examples	O
are	O
not	O
reused	O
nonetheless	O
it	O
is	O
usually	O
best	O
to	O
make	O
several	O
passes	O
through	O
the	O
training	O
set	O
unless	O
the	O
training	O
set	O
is	O
extremely	O
large	O
when	O
multiple	O
such	O
epochs	O
are	O
used	O
only	O
the	O
first	O
epoch	B
follows	O
the	O
unbiased	B
gradient	B
of	O
the	O
generalization	B
error	O
but	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
of	O
course	O
the	O
additional	O
epochs	O
usually	O
provide	O
enough	O
benefit	O
due	O
to	O
decreased	O
training	B
error	I
to	O
offset	O
the	O
harm	O
they	O
cause	O
by	O
increasing	O
the	O
gap	O
between	O
training	B
error	I
and	O
test	O
error	O
with	O
some	O
datasets	O
growing	O
rapidly	O
in	O
size	O
faster	O
than	O
computing	O
power	O
it	O
is	O
becoming	O
more	O
common	O
for	O
machine	B
learning	I
applications	O
to	O
use	O
each	O
training	O
example	B
only	O
once	O
or	O
even	O
to	O
make	O
an	O
incomplete	O
pass	O
through	O
the	O
training	O
set	O
when	O
using	O
an	O
extremely	O
large	O
training	O
set	O
overfitting	O
is	O
not	O
an	O
issue	O
so	O
underfitting	O
and	O
computational	O
efficiency	O
become	O
the	O
predominant	O
concerns	O
see	O
also	O
for	O
a	O
discussion	O
of	O
the	O
effect	O
of	O
computational	O
bottlenecks	O
on	O
generalization	B
error	O
as	O
the	O
number	O
of	O
training	O
examples	O
grows	O
bottou	O
and	O
bousquet	O
challenges	O
in	O
neural	B
network	I
optimization	O
optimization	O
in	O
general	O
is	O
an	O
extremely	O
difficult	O
task	O
traditionally	O
machine	B
learning	I
has	O
avoided	O
the	O
difficulty	O
of	O
general	O
optimization	O
by	O
carefully	O
designing	O
the	O
objective	B
function	I
and	O
constraints	O
to	O
ensure	O
that	O
the	O
optimization	O
problem	O
is	O
convex	O
when	O
training	O
neural	O
networks	O
we	O
must	O
confront	O
the	O
general	O
non-convex	O
case	O
even	O
convex	B
optimization	I
is	O
not	O
without	O
its	O
complications	O
in	O
this	O
section	O
we	O
summarize	O
several	O
of	O
the	O
most	O
prominent	O
challenges	O
involved	O
in	O
optimization	O
for	O
training	O
deep	O
models	O
ill-conditioning	O
some	O
challenges	O
arise	O
even	O
when	O
optimizing	O
convex	O
functions	O
of	O
these	O
the	O
most	O
prominent	O
is	O
ill-conditioning	O
of	O
the	O
hessian	B
matrix	O
h	O
this	O
is	O
a	O
very	O
general	O
problem	O
in	O
most	O
numerical	O
optimization	O
convex	O
or	O
otherwise	O
and	O
is	O
described	O
in	O
more	O
detail	O
in	O
section	O
the	O
ill-conditioning	O
problem	O
is	O
generally	O
believed	O
to	O
be	O
present	O
in	O
neural	B
network	I
training	O
problems	O
ill-conditioning	O
can	O
manifest	O
by	O
causing	O
sgd	O
to	O
get	O
stuck	O
in	O
the	O
sense	O
that	O
even	O
very	O
small	O
steps	O
increase	O
the	O
cost	O
function	O
recall	B
from	O
equation	O
that	O
a	O
second-order	O
taylor	O
series	O
expansion	O
of	O
the	O
cost	O
function	O
predicts	O
that	O
a	O
gradient	B
descent	O
step	O
of	O
will	O
add	O
g	O
hg	O
g	O
g	O
to	O
the	O
cost	O
ill-conditioning	O
of	O
the	O
gradient	B
becomes	O
a	O
problem	O
when	O
exceeds	O
g	O
network	O
training	O
task	O
one	O
can	O
monitor	O
the	O
squared	O
gradient	B
norm	O
g	O
hg	O
g	O
to	O
determine	O
whether	O
ill-conditioning	O
is	O
detrimental	O
to	O
a	O
neural	O
g	O
and	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
m	O
r	O
o	O
n	O
t	O
n	O
e	O
i	O
d	O
a	O
r	O
g	O
e	O
t	O
a	O
r	O
r	O
o	O
r	O
r	O
e	O
n	O
o	O
i	O
t	O
a	O
c	O
fi	O
i	O
s	O
s	O
a	O
l	O
c	O
training	O
time	O
training	O
time	O
figure	O
gradient	B
descent	O
often	O
does	O
not	O
arrive	O
at	O
a	O
critical	O
point	O
of	O
any	O
kind	O
in	O
this	O
example	B
the	O
gradient	B
norm	O
increases	O
throughout	O
training	O
of	O
a	O
convolutional	B
network	I
used	O
for	O
object	B
detection	I
scatterplot	O
showing	O
how	O
the	O
norms	O
of	O
individual	O
gradient	B
evaluations	O
are	O
distributed	O
over	O
time	O
to	O
improve	O
legibility	O
only	O
one	O
gradient	B
norm	O
is	O
plotted	O
per	O
epoch	B
the	O
running	O
average	O
of	O
all	O
gradient	B
norms	O
is	O
plotted	O
as	O
a	O
solid	O
curve	O
the	O
gradient	B
norm	O
clearly	O
increases	O
over	O
time	O
rather	O
than	O
decreasing	O
as	O
we	O
would	O
expect	O
if	O
the	O
training	O
process	O
converged	O
to	O
a	O
critical	O
point	O
despite	O
the	O
increasing	O
gradient	B
the	O
training	O
process	O
is	O
reasonably	O
successful	O
the	O
validation	O
set	O
classification	B
error	O
decreases	O
to	O
a	O
low	O
level	O
hg	O
term	O
in	O
many	O
cases	O
the	O
gradient	B
norm	O
does	O
not	O
shrink	O
significantly	O
the	O
g	O
throughout	O
learning	O
but	O
the	O
g	O
hg	O
term	O
grows	O
by	O
more	O
than	O
an	O
order	O
of	O
magnitude	O
the	O
result	O
is	O
that	O
learning	O
becomes	O
very	O
slow	O
despite	O
the	O
presence	O
of	O
a	O
strong	O
gradient	B
because	O
the	O
learning	B
rate	I
must	O
be	O
shrunk	O
to	O
compensate	O
for	O
even	O
stronger	O
curvature	O
figure	O
shows	O
an	O
example	B
of	O
the	O
gradient	B
increasing	O
significantly	O
during	O
the	O
successful	O
training	O
of	O
a	O
neural	B
network	I
though	O
ill-conditioning	O
is	O
present	O
in	O
other	O
settings	O
besides	O
neural	B
network	I
training	O
some	O
of	O
the	O
techniques	O
used	O
to	O
combat	O
it	O
in	O
other	O
contexts	O
are	O
less	O
applicable	O
to	O
neural	O
networks	O
for	O
example	B
newton	O
s	O
method	O
is	O
an	O
excellent	O
tool	O
for	O
minimizing	O
convex	O
functions	O
with	O
poorly	O
conditioned	O
hessian	B
matrices	O
but	O
in	O
the	O
subsequent	O
sections	O
we	O
will	O
argue	O
that	O
newton	O
s	O
method	O
requires	O
significant	O
modification	O
before	O
it	O
can	O
be	O
applied	O
to	O
neural	O
networks	O
local	O
minima	O
one	O
of	O
the	O
most	O
prominent	O
features	O
of	O
a	O
convex	B
optimization	I
problem	O
is	O
that	O
it	O
can	O
be	O
reduced	O
to	O
the	O
problem	O
of	O
finding	O
a	O
local	O
minimum	O
any	O
local	O
minimum	O
is	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
guaranteed	O
to	O
be	O
a	O
global	O
minimum	O
some	O
convex	O
functions	O
have	O
a	O
flat	O
region	O
at	O
the	O
bottom	O
rather	O
than	O
a	O
single	O
global	O
minimum	O
point	O
but	O
any	O
point	O
within	O
such	O
a	O
flat	O
region	O
is	O
an	O
acceptable	O
solution	O
when	O
optimizing	O
a	O
convex	O
function	O
we	O
know	O
that	O
we	O
have	O
reached	O
a	O
good	O
solution	O
if	O
we	O
find	O
a	O
critical	O
point	O
of	O
any	O
kind	O
with	O
non-convex	O
functions	O
such	O
as	O
neural	O
nets	O
it	O
is	O
possible	O
to	O
have	O
many	O
local	O
minima	O
indeed	O
nearly	O
any	O
deep	O
model	O
is	O
essentially	O
guaranteed	O
to	O
have	O
an	O
extremely	O
large	O
number	O
of	O
local	O
minima	O
however	O
as	O
we	O
will	O
see	O
this	O
is	O
not	O
necessarily	O
a	O
major	O
problem	O
neural	O
networks	O
and	O
any	O
models	O
with	O
multiple	O
equivalently	O
parametrized	O
latent	O
variables	O
all	O
have	O
multiple	O
local	O
minima	O
because	O
of	O
the	O
model	B
identifiability	I
problem	O
a	O
model	O
is	O
said	O
to	O
be	O
identifiable	O
if	O
a	O
sufficiently	O
large	O
training	O
set	O
can	O
rule	O
out	O
all	O
but	O
one	O
setting	O
of	O
the	O
model	O
s	O
parameters	O
models	O
with	O
latent	O
variables	O
are	O
often	O
not	O
identifiable	O
because	O
we	O
can	O
obtain	O
equivalent	O
models	O
by	O
exchanging	O
latent	O
variables	O
with	O
each	O
other	O
for	O
example	B
we	O
could	O
take	O
a	O
neural	B
network	I
and	O
modify	O
layer	O
by	O
swapping	O
the	O
incoming	O
weight	O
vector	O
for	O
unit	O
i	O
with	O
the	O
incoming	O
weight	O
vector	O
for	O
unit	O
j	O
then	O
doing	O
the	O
same	O
for	O
the	O
outgoing	O
weight	O
vectors	O
if	O
we	O
have	O
m	O
layers	O
with	O
n	O
units	O
each	O
then	O
there	O
are	O
n	O
m	O
ways	O
of	O
arranging	O
the	O
hidden	O
units	O
this	O
kind	O
of	O
non-identifiability	O
is	O
known	O
as	O
weight	B
space	I
symmetry	I
in	O
addition	O
to	O
weight	B
space	I
symmetry	I
many	O
kinds	O
of	O
neural	O
networks	O
have	O
additional	O
causes	O
of	O
non-identifiability	O
for	O
example	B
in	O
any	O
rectified	O
linear	O
or	O
maxout	O
network	O
we	O
can	O
scale	O
all	O
of	O
the	O
incoming	O
weights	B
and	O
biases	O
of	O
a	O
unit	O
by	O
if	O
we	O
also	O
scale	O
all	O
of	O
its	O
outgoing	O
weights	B
by	O
this	O
means	O
that	O
if	O
the	O
cost	O
function	O
does	O
not	O
include	O
terms	O
such	O
as	O
weight	O
decay	O
that	O
depend	O
directly	O
on	O
the	O
weights	B
rather	O
than	O
the	O
models	O
outputs	O
every	O
local	O
minimum	O
of	O
a	O
rectified	O
linear	O
or	O
maxout	O
network	O
lies	O
on	O
an	O
n	O
hyperbola	O
of	O
equivalent	O
local	O
minima	O
these	O
model	B
identifiability	I
issues	O
mean	O
that	O
there	O
can	O
be	O
an	O
extremely	O
large	O
or	O
even	O
uncountably	O
infinite	O
amount	O
of	O
local	O
minima	O
in	O
a	O
neural	B
network	I
cost	O
function	O
however	O
all	O
of	O
these	O
local	O
minima	O
arising	O
from	O
non-identifiability	O
are	O
equivalent	O
to	O
each	O
other	O
in	O
cost	O
function	O
value	O
as	O
a	O
result	O
these	O
local	O
minima	O
are	O
not	O
a	O
problematic	O
form	O
of	O
non-convexity	O
local	O
minima	O
can	O
be	O
problematic	O
if	O
they	O
have	O
high	O
cost	O
in	O
comparison	O
to	O
the	O
global	O
minimum	O
one	O
can	O
construct	O
small	O
neural	O
networks	O
even	O
without	O
hidden	O
units	O
that	O
have	O
local	O
minima	O
with	O
higher	O
cost	O
than	O
the	O
global	O
minimum	O
and	O
sussman	O
brady	O
if	O
local	O
minima	O
with	O
high	O
cost	O
are	O
common	O
this	O
could	O
pose	O
a	O
serious	O
problem	O
for	O
gradient-based	O
optimization	O
algorithms	O
gori	O
and	O
tesi	O
et	O
al	O
it	O
remains	O
an	O
open	O
question	O
whether	O
there	O
are	O
many	O
local	O
minima	O
of	O
high	O
cost	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
for	O
networks	O
of	O
practical	O
interest	O
and	O
whether	O
optimization	O
algorithms	O
encounter	O
them	O
for	O
many	O
years	O
most	O
practitioners	O
believed	O
that	O
local	O
minima	O
were	O
a	O
common	O
problem	O
plaguing	O
neural	B
network	I
optimization	O
today	O
that	O
does	O
not	O
appear	O
to	O
be	O
the	O
case	O
the	O
problem	O
remains	O
an	O
active	O
area	O
of	O
research	O
but	O
experts	O
now	O
suspect	O
that	O
for	O
sufficiently	O
large	O
neural	O
networks	O
most	O
local	O
minima	O
have	O
a	O
low	O
cost	O
function	O
value	O
and	O
that	O
it	O
is	O
not	O
important	O
to	O
find	O
a	O
true	O
global	O
minimum	O
rather	O
than	O
to	O
find	O
a	O
point	O
in	O
parameter	O
space	O
that	O
has	O
low	O
but	O
not	O
minimal	O
cost	O
saxe	O
et	O
al	O
dauphin	O
et	O
al	O
goodfellow	O
et	O
al	O
choromanska	O
et	O
al	O
many	O
practitioners	O
attribute	O
nearly	O
all	O
difficulty	O
with	O
neural	B
network	I
optimization	O
to	O
local	O
minima	O
we	O
encourage	O
practitioners	O
to	O
carefully	O
test	O
for	O
specific	O
problems	O
a	O
test	O
that	O
can	O
rule	O
out	O
local	O
minima	O
as	O
the	O
problem	O
is	O
to	O
plot	O
the	O
norm	O
of	O
the	O
gradient	B
over	O
time	O
if	O
the	O
norm	O
of	O
the	O
gradient	B
does	O
not	O
shrink	O
to	O
insignificant	O
size	O
the	O
problem	O
is	O
neither	O
local	O
minima	O
nor	O
any	O
other	O
kind	O
of	O
critical	O
point	O
this	O
kind	O
of	O
negative	O
test	O
can	O
rule	O
out	O
local	O
minima	O
in	O
high	O
dimensional	O
spaces	O
it	O
can	O
be	O
very	O
difficult	O
to	O
positively	O
establish	O
that	O
local	O
minima	O
are	O
the	O
problem	O
many	O
structures	O
other	O
than	O
local	O
minima	O
also	O
have	O
small	O
gradients	O
plateaus	O
saddle	B
points	I
and	O
other	O
flat	O
regions	O
for	O
many	O
high-dimensional	O
non-convex	O
functions	O
local	O
minima	O
maxima	O
are	O
in	O
fact	O
rare	O
compared	O
to	O
another	O
kind	O
of	O
point	O
with	O
zero	O
gradient	B
a	O
saddle	O
point	O
some	O
points	O
around	O
a	O
saddle	O
point	O
have	O
greater	O
cost	O
than	O
the	O
saddle	O
point	O
while	O
others	O
have	O
a	O
lower	O
cost	O
at	O
a	O
saddle	O
point	O
the	O
hessian	B
matrix	O
has	O
both	O
positive	O
and	O
negative	O
eigenvalues	O
points	O
lying	O
along	O
eigenvectors	O
associated	O
with	O
positive	O
eigenvalues	O
have	O
greater	O
cost	O
than	O
the	O
saddle	O
point	O
while	O
points	O
lying	O
along	O
negative	O
eigenvalues	O
have	O
lower	O
value	O
we	O
can	O
think	O
of	O
a	O
saddle	O
point	O
as	O
being	O
a	O
local	O
minimum	O
along	O
one	O
cross-section	O
of	O
the	O
cost	O
function	O
and	O
a	O
local	O
maximum	O
along	O
another	O
cross-section	O
see	O
figure	O
for	O
an	O
illustration	O
many	O
classes	O
of	O
random	O
functions	O
exhibit	O
the	O
following	O
behavior	O
in	O
low	O
dimensional	O
spaces	O
local	O
minima	O
are	O
common	O
in	O
higher	O
dimensional	O
spaces	O
local	O
n	O
minima	O
are	O
rare	O
and	O
saddle	B
points	I
are	O
more	O
common	O
for	O
a	O
function	O
f	O
r	O
r	O
of	O
this	O
type	O
the	O
expected	O
ratio	O
of	O
the	O
number	O
of	O
saddle	B
points	I
to	O
local	O
minima	O
grows	O
exponentially	O
with	O
n	O
to	O
understand	O
the	O
intuition	O
behind	O
this	O
behavior	O
observe	O
that	O
the	O
hessian	B
matrix	O
at	O
a	O
local	O
minimum	O
has	O
only	O
positive	O
eigenvalues	O
the	O
hessian	B
matrix	O
at	O
a	O
saddle	O
point	O
has	O
a	O
mixture	O
of	O
positive	O
and	O
negative	O
eigenvalues	O
imagine	O
that	O
the	O
sign	O
of	O
each	O
eigenvalue	B
is	O
generated	O
by	O
flipping	O
a	O
coin	O
in	O
a	O
single	O
dimension	O
it	O
is	O
easy	O
to	O
obtain	O
a	O
local	O
minimum	O
by	O
tossing	O
a	O
coin	O
and	O
getting	O
heads	O
once	O
in	O
n-dimensional	O
space	O
it	O
is	O
exponentially	O
unlikely	O
that	O
all	O
n	O
coin	O
tosses	O
will	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
be	O
heads	O
see	O
dauphin	O
et	O
al	O
for	O
a	O
review	O
of	O
the	O
relevant	O
theoretical	O
work	O
an	O
amazing	O
property	O
of	O
many	O
random	O
functions	O
is	O
that	O
the	O
eigenvalues	O
of	O
the	O
hessian	B
become	O
more	O
likely	O
to	O
be	O
positive	O
as	O
we	O
reach	O
regions	O
of	O
lower	O
cost	O
in	O
our	O
coin	O
tossing	O
analogy	O
this	O
means	O
we	O
are	O
more	O
likely	O
to	O
have	O
our	O
coin	O
come	O
up	O
heads	O
n	O
times	O
if	O
we	O
are	O
at	O
a	O
critical	O
point	O
with	O
low	O
cost	O
this	O
means	O
that	O
local	O
minima	O
are	O
much	O
more	O
likely	O
to	O
have	O
low	O
cost	O
than	O
high	O
cost	O
critical	O
points	O
with	O
high	O
cost	O
are	O
far	O
more	O
likely	O
to	O
be	O
saddle	B
points	I
critical	O
points	O
with	O
extremely	O
high	O
cost	O
are	O
more	O
likely	O
to	O
be	O
local	O
maxima	O
baldi	O
and	O
hornik	O
this	O
happens	O
for	O
many	O
classes	O
of	O
random	O
functions	O
does	O
it	O
happen	O
for	O
neural	O
showed	O
theoretically	O
that	O
shallow	O
autoencoders	O
networks	O
networks	O
trained	O
to	O
copy	O
their	O
input	O
to	O
their	O
output	O
described	O
in	O
chapter	O
with	O
no	O
nonlinearities	O
have	O
global	O
minima	O
and	O
saddle	B
points	I
but	O
no	O
local	O
minima	O
with	O
higher	O
cost	O
than	O
the	O
global	O
minimum	O
they	O
observed	O
without	O
proof	O
that	O
these	O
results	O
extend	O
to	O
deeper	O
networks	O
without	O
nonlinearities	O
the	O
output	O
of	O
such	O
networks	O
is	O
a	O
linear	O
function	O
of	O
their	O
input	O
but	O
they	O
are	O
useful	O
to	O
study	O
as	O
a	O
model	O
of	O
nonlinear	O
neural	O
networks	O
because	O
their	O
loss	O
function	O
is	O
a	O
non-convex	O
function	O
of	O
their	O
parameters	O
such	O
networks	O
are	O
essentially	O
just	O
multiple	O
matrices	O
composed	O
together	O
provided	O
exact	O
solutions	O
to	O
the	O
complete	O
learning	O
dynamics	O
in	O
such	O
networks	O
and	O
showed	O
that	O
learning	O
in	O
these	O
models	O
captures	O
many	O
of	O
the	O
qualitative	O
features	O
observed	O
in	O
the	O
training	O
of	O
deep	O
models	O
with	O
nonlinear	O
activation	O
functions	O
showed	O
experimentally	O
that	O
real	O
neural	O
networks	O
also	O
have	O
loss	O
functions	O
that	O
contain	O
very	O
many	O
high-cost	O
saddle	B
points	I
choromanska	O
provided	O
additional	O
theoretical	O
arguments	O
showing	O
that	O
another	O
class	O
of	O
high-dimensional	O
random	O
functions	O
related	O
to	O
neural	O
networks	O
does	O
so	O
as	O
well	O
dauphin	O
et	O
al	O
saxe	O
et	O
al	O
et	O
al	O
what	O
are	O
the	O
implications	O
of	O
the	O
proliferation	O
of	O
saddle	B
points	I
for	O
training	O
algorithms	O
for	O
first-order	O
optimization	O
algorithms	O
that	O
use	O
only	O
gradient	B
information	O
the	O
situation	O
is	O
unclear	O
the	O
gradient	B
can	O
often	O
become	O
very	O
small	O
near	O
a	O
saddle	O
point	O
on	O
the	O
other	O
hand	O
gradient	B
descent	O
empirically	O
seems	O
to	O
be	O
able	O
to	O
escape	O
saddle	B
points	I
in	O
many	O
cases	O
provided	O
visualizations	O
of	O
several	O
learning	O
trajectories	O
of	O
state-of-the-art	O
neural	O
networks	O
with	O
an	O
example	B
given	O
in	O
figure	O
these	O
visualizations	O
show	O
a	O
flattening	O
of	O
the	O
cost	O
function	O
near	O
a	O
prominent	O
saddle	O
point	O
where	O
the	O
weights	B
are	O
all	O
zero	O
but	O
they	O
also	O
show	O
the	O
gradient	B
descent	O
trajectory	O
rapidly	O
escaping	O
this	O
region	O
goodfellow	O
et	O
al	O
also	O
argue	O
that	O
continuous-time	O
gradient	B
descent	O
may	O
be	O
shown	O
analytically	O
to	O
be	O
repelled	O
from	O
rather	O
than	O
attracted	O
to	O
a	O
nearby	O
saddle	O
point	O
but	O
the	O
situation	O
may	O
be	O
different	O
for	O
more	O
realistic	O
uses	O
of	O
gradient	B
descent	O
goodfellow	O
et	O
al	O
for	O
newton	O
s	O
method	O
it	O
is	O
clear	O
that	O
saddle	B
points	I
constitute	O
a	O
problem	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
j	O
projection	O
of	O
f	O
o	O
n	O
t	O
i	O
o	O
c	O
e	O
j	O
o	O
p	O
r	O
et	O
al	O
figure	O
a	O
visualization	O
of	O
the	O
cost	O
function	O
of	O
a	O
neural	B
network	I
image	O
adapted	O
with	O
permission	O
from	O
goodfellow	O
these	O
visualizations	O
appear	O
similar	O
for	O
feedforward	O
neural	O
networks	O
convolutional	O
networks	O
and	O
recurrent	O
networks	O
applied	O
to	O
real	O
object	B
recognition	I
and	O
natural	B
language	I
processing	I
tasks	O
surprisingly	O
these	O
visualizations	O
usually	O
do	O
not	O
show	O
many	O
conspicuous	O
obstacles	O
prior	O
to	O
the	O
success	O
of	O
stochastic	O
gradient	B
descent	O
for	O
training	O
very	O
large	O
models	O
beginning	O
in	O
roughly	O
neural	O
net	O
cost	O
function	O
surfaces	O
were	O
generally	O
believed	O
to	O
have	O
much	O
more	O
non-convex	O
structure	O
than	O
is	O
revealed	O
by	O
these	O
projections	O
the	O
primary	O
obstacle	O
revealed	O
by	O
this	O
projection	O
is	O
a	O
saddle	O
point	O
of	O
high	O
cost	O
near	O
where	O
the	O
parameters	O
are	O
initialized	O
but	O
as	O
indicated	O
by	O
the	O
blue	O
path	O
the	O
sgd	O
training	O
trajectory	O
escapes	O
this	O
saddle	O
point	O
readily	O
most	O
of	O
training	O
time	O
is	O
spent	O
traversing	O
the	O
relatively	O
flat	O
valley	O
of	O
the	O
cost	O
function	O
which	O
may	O
be	O
due	O
to	O
high	O
noise	O
in	O
the	O
gradient	B
poor	O
conditioning	O
of	O
the	O
hessian	B
matrix	O
in	O
this	O
region	O
or	O
simply	O
the	O
need	O
to	O
circumnavigate	O
the	O
tall	O
mountain	O
visible	O
in	O
the	O
figure	O
via	O
an	O
indirect	O
arcing	O
path	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
gradient	B
descent	O
is	O
designed	O
to	O
move	O
downhill	O
and	O
is	O
not	O
explicitly	O
designed	O
to	O
seek	O
a	O
critical	O
point	O
newton	O
s	O
method	O
however	O
is	O
designed	O
to	O
solve	O
for	O
a	O
point	O
where	O
the	O
gradient	B
is	O
zero	O
without	O
appropriate	O
modification	O
it	O
can	O
jump	O
to	O
a	O
saddle	O
point	O
the	O
proliferation	O
of	O
saddle	B
points	I
in	O
high	O
dimensional	O
spaces	O
presumably	O
explains	O
why	O
second-order	O
methods	O
have	O
not	O
succeeded	O
in	O
replacing	O
gradient	B
descent	O
for	O
neural	B
network	I
training	O
introduced	O
a	O
saddle-free	O
newton	O
method	O
for	O
second-order	O
optimization	O
and	O
showed	O
that	O
it	O
improves	O
significantly	O
over	O
the	O
traditional	O
version	O
second-order	O
methods	O
remain	O
difficult	O
to	O
scale	O
to	O
large	O
neural	O
networks	O
but	O
this	O
saddle-free	O
approach	O
holds	O
promise	O
if	O
it	O
could	O
be	O
scaled	O
dauphin	O
et	O
al	O
there	O
are	O
other	O
kinds	O
of	O
points	O
with	O
zero	O
gradient	B
besides	O
minima	O
and	O
saddle	B
points	I
there	O
are	O
also	O
maxima	O
which	O
are	O
much	O
like	O
saddle	B
points	I
from	O
the	O
perspective	O
of	O
optimization	O
many	O
algorithms	O
are	O
not	O
attracted	O
to	O
them	O
but	O
unmodified	O
newton	O
s	O
method	O
is	O
maxima	O
of	O
many	O
classes	O
of	O
random	O
functions	O
become	O
exponentially	O
rare	O
in	O
high	O
dimensional	O
space	O
just	O
like	O
minima	O
do	O
there	O
may	O
also	O
be	O
wide	O
flat	O
regions	O
of	O
constant	O
value	O
in	O
these	O
locations	O
the	O
gradient	B
and	O
also	O
the	O
hessian	B
are	O
all	O
zero	O
such	O
degenerate	O
locations	O
pose	O
major	O
problems	O
for	O
all	O
numerical	O
optimization	O
algorithms	O
in	O
a	O
convex	O
problem	O
a	O
wide	O
flat	O
region	O
must	O
consist	O
entirely	O
of	O
global	O
minima	O
but	O
in	O
a	O
general	O
optimization	O
problem	O
such	O
a	O
region	O
could	O
correspond	O
to	O
a	O
high	O
value	O
of	O
the	O
objective	B
function	I
cliffs	O
and	O
exploding	O
gradients	O
neural	O
networks	O
with	O
many	O
layers	O
often	O
have	O
extremely	O
steep	O
regions	O
resembling	O
cliffs	O
as	O
illustrated	O
in	O
figure	O
these	O
result	O
from	O
the	O
multiplication	O
of	O
several	O
large	O
weights	B
together	O
on	O
the	O
face	O
of	O
an	O
extremely	O
steep	O
cliff	O
structure	O
the	O
gradient	B
update	O
step	O
can	O
move	O
the	O
parameters	O
extremely	O
far	O
usually	O
jumping	O
off	O
of	O
the	O
cliff	O
structure	O
altogether	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
figure	O
the	O
objective	B
function	I
for	O
highly	O
nonlinear	O
deep	O
neural	O
networks	O
or	O
for	O
recurrent	O
neural	O
networks	O
often	O
contains	O
sharp	O
nonlinearities	O
in	O
parameter	O
space	O
resulting	O
from	O
the	O
multiplication	O
of	O
several	O
parameters	O
these	O
nonlinearities	O
give	O
rise	O
to	O
very	O
high	O
derivatives	O
in	O
some	O
places	O
when	O
the	O
parameters	O
get	O
close	O
to	O
such	O
a	O
cliff	O
region	O
a	O
gradient	B
descent	O
update	O
can	O
catapult	O
the	O
parameters	O
very	O
far	O
possibly	O
losing	O
most	O
of	O
the	O
optimization	O
work	O
that	O
had	O
been	O
done	O
figure	O
adapted	O
with	O
permission	O
from	O
pascanu	O
et	O
al	O
the	O
cliff	O
can	O
be	O
dangerous	O
whether	O
we	O
approach	O
it	O
from	O
above	O
or	O
from	O
below	O
but	O
fortunately	O
its	O
most	O
serious	O
consequences	O
can	O
be	O
avoided	O
using	O
the	O
gradient	B
clipping	O
heuristic	O
described	O
in	O
section	O
the	O
basic	O
idea	O
is	O
to	O
recall	B
that	O
the	O
gradient	B
does	O
not	O
specify	O
the	O
optimal	O
step	O
size	O
but	O
only	O
the	O
optimal	O
direction	O
within	O
an	O
infinitesimal	O
region	O
when	O
the	O
traditional	O
gradient	B
descent	O
algorithm	O
proposes	O
to	O
make	O
a	O
very	O
large	O
step	O
the	O
gradient	B
clipping	O
heuristic	O
intervenes	O
to	O
reduce	O
the	O
step	O
size	O
to	O
be	O
small	O
enough	O
that	O
it	O
is	O
less	O
likely	O
to	O
go	O
outside	O
the	O
region	O
where	O
the	O
gradient	B
indicates	O
the	O
direction	O
of	O
approximately	O
steepest	O
descent	O
cliff	O
structures	O
are	O
most	O
common	O
in	O
the	O
cost	O
functions	O
for	O
recurrent	O
neural	O
networks	O
because	O
such	O
models	O
involve	O
a	O
multiplication	O
of	O
many	O
factors	O
with	O
one	O
factor	O
for	O
each	O
time	O
step	O
long	O
temporal	O
sequences	O
thus	O
incur	O
an	O
extreme	O
amount	O
of	O
multiplication	O
long-term	O
dependencies	O
another	O
difficulty	O
that	O
neural	B
network	I
optimization	O
algorithms	O
must	O
overcome	O
arises	O
when	O
the	O
computational	B
graph	I
becomes	O
extremely	O
deep	O
feedforward	O
networks	O
with	O
many	O
layers	O
have	O
such	O
deep	O
computational	O
graphs	O
so	O
do	O
recurrent	O
networks	O
described	O
in	O
chapter	O
which	O
construct	O
very	O
deep	O
computational	O
graphs	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
by	O
repeatedly	O
applying	O
the	O
same	O
operation	B
at	O
each	O
time	O
step	O
of	O
a	O
long	O
temporal	O
sequence	O
repeated	O
application	O
of	O
the	O
same	O
parameters	O
gives	O
rise	O
to	O
especially	O
pronounced	O
difficulties	O
for	O
example	B
suppose	O
that	O
a	O
computational	B
graph	I
contains	O
a	O
path	O
that	O
consists	O
of	O
repeatedly	O
multiplying	O
by	O
a	O
matrix	O
w	O
after	O
t	O
steps	O
this	O
is	O
equivalent	O
to	O
mul	O
tiplying	O
by	O
w	O
t	O
suppose	O
that	O
w	O
has	O
an	O
eigendecomposition	B
w	O
v	O
diag	O
in	O
this	O
simple	O
case	O
it	O
is	O
straightforward	O
to	O
see	O
that	O
w	O
t	O
v	O
diag	O
v	O
t	O
v	O
diag	O
tv	O
any	O
eigenvalues	O
i	O
that	O
are	O
not	O
near	O
an	O
absolute	O
value	O
of	O
will	O
either	O
explode	O
if	O
they	O
are	O
greater	O
than	O
in	O
magnitude	O
or	O
vanish	O
if	O
they	O
are	O
less	O
than	O
in	O
magnitude	O
the	O
vanishing	O
and	O
exploding	O
gradient	B
problem	O
refers	O
to	O
the	O
fact	O
that	O
gradients	O
through	O
such	O
a	O
graph	O
are	O
also	O
scaled	O
according	O
to	O
diag	O
vanishing	O
gradients	O
make	O
it	O
difficult	O
to	O
know	O
which	O
direction	O
the	O
parameters	O
should	O
move	O
to	O
improve	O
the	O
cost	O
function	O
while	O
exploding	O
gradients	O
can	O
make	O
learning	O
unstable	O
the	O
cliff	O
structures	O
described	O
earlier	O
that	O
motivate	O
gradient	B
clipping	O
are	O
an	O
example	B
of	O
the	O
exploding	O
gradient	B
phenomenon	O
the	O
repeated	O
multiplication	O
by	O
w	O
at	O
each	O
time	O
step	O
described	O
here	O
is	O
very	O
similar	O
to	O
the	O
power	O
method	O
algorithm	O
used	O
to	O
find	O
the	O
largest	O
eigenvalue	B
of	O
a	O
matrix	O
w	O
and	O
the	O
corresponding	O
eigenvector	B
from	O
this	O
point	O
of	O
view	O
it	O
is	O
not	O
surprising	O
that	O
x	O
w	O
t	O
will	O
eventually	O
discard	O
all	O
components	O
of	O
x	O
that	O
are	O
orthogonal	O
to	O
the	O
principal	O
eigenvector	B
of	O
recurrent	O
networks	O
use	O
the	O
same	O
matrix	O
w	O
at	O
each	O
time	O
step	O
but	O
feedforward	O
networks	O
do	O
not	O
so	O
even	O
very	O
deep	O
feedforward	O
networks	O
can	O
largely	O
avoid	O
the	O
vanishing	O
and	O
exploding	O
gradient	B
problem	O
sussillo	O
we	O
defer	O
a	O
further	O
discussion	O
of	O
the	O
challenges	O
of	O
training	O
recurrent	O
networks	O
until	O
section	O
after	O
recurrent	O
networks	O
have	O
been	O
described	O
in	O
more	O
detail	O
inexact	O
gradients	O
most	O
optimization	O
algorithms	O
are	O
designed	O
with	O
the	O
assumption	O
that	O
we	O
have	O
access	O
to	O
the	O
exact	O
gradient	B
or	O
hessian	B
matrix	O
in	O
practice	O
we	O
usually	O
only	O
have	O
a	O
noisy	O
or	O
even	O
biased	O
estimate	O
of	O
these	O
quantities	O
nearly	O
every	O
deep	O
learning	O
algorithm	O
relies	O
on	O
sampling-based	O
estimates	O
at	O
least	O
insofar	O
as	O
using	O
a	O
minibatch	B
of	O
training	O
examples	O
to	O
compute	O
the	O
gradient	B
in	O
other	O
cases	O
the	O
objective	B
function	I
we	O
want	O
to	O
minimize	O
is	O
actually	O
intractable	O
when	O
the	O
objective	B
function	I
is	O
intractable	O
typically	O
its	O
gradient	B
is	O
intractable	O
as	O
well	O
in	O
such	O
cases	O
we	O
can	O
only	O
approximate	O
the	O
gradient	B
these	O
issues	O
mostly	O
arise	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
for	O
example	B
contrastive	O
divergence	O
with	O
the	O
more	O
advanced	O
models	O
in	O
part	O
gives	O
a	O
technique	O
for	O
approximating	O
the	O
gradient	B
of	O
the	O
intractable	O
log-likelihood	O
of	O
a	O
boltzmann	O
machine	O
iii	O
various	O
neural	B
network	I
optimization	O
algorithms	O
are	O
designed	O
to	O
account	O
for	O
imperfections	O
in	O
the	O
gradient	B
estimate	O
one	O
can	O
also	O
avoid	O
the	O
problem	O
by	O
choosing	O
a	O
surrogate	B
loss	I
function	I
that	O
is	O
easier	O
to	O
approximate	O
than	O
the	O
true	O
loss	O
poor	O
correspondence	O
between	O
local	O
and	O
global	O
structure	O
many	O
of	O
the	O
problems	O
we	O
have	O
discussed	O
so	O
far	O
correspond	O
to	O
properties	O
of	O
the	O
loss	O
function	O
at	O
a	O
single	O
point	O
it	O
can	O
be	O
difficult	O
to	O
make	O
a	O
single	O
step	O
if	O
j	O
is	O
poorly	O
conditioned	O
at	O
the	O
current	O
point	O
or	O
if	O
lies	O
on	O
a	O
cliff	O
or	O
if	O
is	O
a	O
saddle	O
point	O
hiding	O
the	O
opportunity	O
to	O
make	O
progress	O
downhill	O
from	O
the	O
gradient	B
it	O
is	O
possible	O
to	O
overcome	O
all	O
of	O
these	O
problems	O
at	O
a	O
single	O
point	O
and	O
still	O
perform	O
poorly	O
if	O
the	O
direction	O
that	O
results	O
in	O
the	O
most	O
improvement	O
locally	O
does	O
not	O
point	O
toward	O
distant	O
regions	O
of	O
much	O
lower	O
cost	O
et	O
al	O
goodfellow	O
argue	O
that	O
much	O
of	O
the	O
runtime	O
of	O
training	O
is	O
due	O
to	O
the	O
length	O
of	O
the	O
trajectory	O
needed	O
to	O
arrive	O
at	O
the	O
solution	O
figure	O
shows	O
that	O
the	O
learning	O
trajectory	O
spends	O
most	O
of	O
its	O
time	O
tracing	O
out	O
a	O
wide	O
arc	O
around	O
a	O
mountain-shaped	O
structure	O
log	O
p	O
y	O
much	O
of	O
research	O
into	O
the	O
difficulties	O
of	O
optimization	O
has	O
focused	O
on	O
whether	O
training	O
arrives	O
at	O
a	O
global	O
minimum	O
a	O
local	O
minimum	O
or	O
a	O
saddle	O
point	O
but	O
in	O
practice	O
neural	O
networks	O
do	O
not	O
arrive	O
at	O
a	O
critical	O
point	O
of	O
any	O
kind	O
figure	O
shows	O
that	O
neural	O
networks	O
often	O
do	O
not	O
arrive	O
at	O
a	O
region	O
of	O
small	O
gradient	B
indeed	O
such	O
critical	O
points	O
do	O
not	O
even	O
necessarily	O
exist	O
for	O
example	B
the	O
loss	O
function	O
x	O
can	O
lack	O
a	O
global	O
minimum	O
point	O
and	O
instead	O
asymptotically	O
approach	O
some	O
value	O
as	O
the	O
model	O
becomes	O
more	O
confident	O
for	O
a	O
classifier	O
with	O
discrete	O
y	O
and	O
py	O
x	O
provided	O
by	O
a	O
softmax	O
the	O
negative	O
log-likelihood	O
can	O
become	O
arbitrarily	O
close	O
to	O
zero	O
if	O
the	O
model	O
is	O
able	O
to	O
correctly	O
classify	O
every	O
example	B
in	O
the	O
training	O
set	O
but	O
it	O
is	O
impossible	O
to	O
actually	O
reach	O
the	O
value	O
of	O
zero	O
likewise	O
a	O
model	O
of	O
real	O
values	O
py	O
can	O
have	O
negative	O
log-likelihood	O
that	O
asymptotes	O
to	O
negative	O
infinity	O
if	O
f	O
is	O
able	O
to	O
correctly	O
predict	O
the	O
value	O
of	O
all	O
training	O
set	O
y	O
targets	O
the	O
learning	O
algorithm	O
will	O
increase	O
without	O
bound	B
see	O
figure	O
for	O
an	O
example	B
of	O
a	O
failure	O
of	O
local	O
optimization	O
to	O
find	O
a	O
good	O
cost	O
function	O
value	O
even	O
in	O
the	O
absence	O
of	O
any	O
local	O
minima	O
or	O
saddle	B
points	I
f	O
x	O
n	O
future	O
research	O
will	O
need	O
to	O
develop	O
further	O
understanding	O
of	O
the	O
factors	O
that	O
influence	O
the	O
length	O
of	O
the	O
learning	O
trajectory	O
and	O
better	O
characterize	O
the	O
outcome	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
j	O
figure	O
optimization	O
based	O
on	O
local	O
downhill	O
moves	O
can	O
fail	O
if	O
the	O
local	O
surface	O
does	O
not	O
point	O
toward	O
the	O
global	O
solution	O
here	O
we	O
provide	O
an	O
example	B
of	O
how	O
this	O
can	O
occur	O
even	O
if	O
there	O
are	O
no	O
saddle	B
points	I
and	O
no	O
local	O
minima	O
this	O
example	B
cost	O
function	O
contains	O
only	O
asymptotes	O
toward	O
low	O
values	O
not	O
minima	O
the	O
main	O
cause	O
of	O
difficulty	O
in	O
this	O
case	O
is	O
being	O
initialized	O
on	O
the	O
wrong	O
side	O
of	O
the	O
mountain	O
and	O
not	O
being	O
able	O
to	O
traverse	O
it	O
in	O
higher	O
dimensional	O
space	O
learning	O
algorithms	O
can	O
often	O
circumnavigate	O
such	O
mountains	O
but	O
the	O
trajectory	O
associated	O
with	O
doing	O
so	O
may	O
be	O
long	O
and	O
result	O
in	O
excessive	O
training	O
time	O
as	O
illustrated	O
in	O
figure	O
of	O
the	O
process	O
many	O
existing	O
research	O
directions	O
are	O
aimed	O
at	O
finding	O
good	O
initial	O
points	O
for	O
problems	O
that	O
have	O
difficult	O
global	O
structure	O
rather	O
than	O
developing	O
algorithms	O
that	O
use	O
non-local	O
moves	O
gradient	B
descent	O
and	O
essentially	O
all	O
learning	O
algorithms	O
that	O
are	O
effective	O
for	O
training	O
neural	O
networks	O
are	O
based	O
on	O
making	O
small	O
local	O
moves	O
the	O
previous	O
sections	O
have	O
primarily	O
focused	O
on	O
how	O
the	O
correct	O
direction	O
of	O
these	O
local	O
moves	O
can	O
be	O
difficult	O
to	O
compute	O
we	O
may	O
be	O
able	O
to	O
compute	O
some	O
properties	O
of	O
the	O
objective	B
function	I
such	O
as	O
its	O
gradient	B
only	O
approximately	O
with	O
bias	O
or	O
variance	O
in	O
our	O
estimate	O
of	O
the	O
correct	O
direction	O
in	O
these	O
cases	O
local	O
descent	O
may	O
or	O
may	O
not	O
define	O
a	O
reasonably	O
short	O
path	O
to	O
a	O
valid	O
solution	O
but	O
we	O
are	O
not	O
actually	O
able	O
to	O
follow	O
the	O
local	O
descent	O
path	O
the	O
objective	B
function	I
may	O
have	O
issues	O
such	O
as	O
poor	O
conditioning	O
or	O
discontinuous	O
gradients	O
causing	O
the	O
region	O
where	O
the	O
gradient	B
provides	O
a	O
good	O
model	O
of	O
the	O
objective	B
function	I
to	O
be	O
very	O
small	O
in	O
these	O
cases	O
local	O
descent	O
with	O
steps	O
of	O
size	O
may	O
define	O
a	O
reasonably	O
short	O
path	O
to	O
the	O
solution	O
but	O
we	O
are	O
only	O
able	O
to	O
compute	O
the	O
local	O
descent	O
direction	O
with	O
steps	O
of	O
size	O
in	O
these	O
cases	O
local	O
descent	O
may	O
or	O
may	O
not	O
define	O
a	O
path	O
to	O
the	O
solution	O
but	O
the	O
path	O
contains	O
many	O
steps	O
so	O
following	O
the	O
path	O
incurs	O
a	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
high	O
computational	O
cost	O
sometimes	O
local	O
information	O
provides	O
us	O
no	O
guide	O
when	O
the	O
function	O
has	O
a	O
wide	O
flat	O
region	O
or	O
if	O
we	O
manage	O
to	O
land	O
exactly	O
on	O
a	O
critical	O
point	O
this	O
latter	O
scenario	O
only	O
happens	O
to	O
methods	O
that	O
solve	O
explicitly	O
for	O
critical	O
points	O
such	O
as	O
newton	O
s	O
method	O
in	O
these	O
cases	O
local	O
descent	O
does	O
not	O
define	O
a	O
path	O
to	O
a	O
solution	O
at	O
all	O
in	O
other	O
cases	O
local	O
moves	O
can	O
be	O
too	O
greedy	O
and	O
lead	O
us	O
along	O
a	O
path	O
that	O
moves	O
downhill	O
but	O
away	O
from	O
any	O
solution	O
as	O
in	O
figure	O
currently	O
we	O
do	O
not	O
understand	O
which	O
of	O
these	O
problems	O
are	O
most	O
relevant	O
to	O
making	O
neural	B
network	I
optimization	O
difficult	O
and	O
this	O
is	O
an	O
active	O
area	O
of	O
research	O
or	O
along	O
an	O
unnecessarily	O
long	O
trajectory	O
to	O
the	O
solution	O
as	O
in	O
figure	O
regardless	O
of	O
which	O
of	O
these	O
problems	O
are	O
most	O
significant	O
all	O
of	O
them	O
might	O
be	O
avoided	O
if	O
there	O
exists	O
a	O
region	O
of	O
space	O
connected	O
reasonably	O
directly	O
to	O
a	O
solution	O
by	O
a	O
path	O
that	O
local	O
descent	O
can	O
follow	O
and	O
if	O
we	O
are	O
able	O
to	O
initialize	O
learning	O
within	O
that	O
well-behaved	O
region	O
this	O
last	O
view	O
suggests	O
research	O
into	O
choosing	O
good	O
initial	O
points	O
for	O
traditional	O
optimization	O
algorithms	O
to	O
use	O
theoretical	O
limits	O
of	O
optimization	O
several	O
theoretical	O
results	O
show	O
that	O
there	O
are	O
limits	O
on	O
the	O
performance	O
of	O
any	O
optimization	O
algorithm	O
we	O
might	O
design	O
for	O
neural	O
networks	O
and	O
rivest	O
judd	O
wolpert	O
and	O
macready	O
typically	O
these	O
results	O
have	O
little	O
bearing	O
on	O
the	O
use	O
of	O
neural	O
networks	O
in	O
practice	O
some	O
theoretical	O
results	O
apply	O
only	O
to	O
the	O
case	O
where	O
the	O
units	O
of	O
a	O
neural	B
network	I
output	O
discrete	O
values	O
however	O
most	O
neural	B
network	I
units	O
output	O
smoothly	O
increasing	O
values	O
that	O
make	O
optimization	O
via	O
local	O
search	O
feasible	O
some	O
theoretical	O
results	O
show	O
that	O
there	O
exist	O
problem	O
classes	O
that	O
are	O
intractable	O
but	O
it	O
can	O
be	O
difficult	O
to	O
tell	O
whether	O
a	O
particular	O
problem	O
falls	O
into	O
that	O
class	O
other	O
results	O
show	O
that	O
finding	O
a	O
solution	O
for	O
a	O
network	O
of	O
a	O
given	O
size	O
is	O
intractable	O
but	O
in	O
practice	O
we	O
can	O
find	O
a	O
solution	O
easily	O
by	O
using	O
a	O
larger	O
network	O
for	O
which	O
many	O
more	O
parameter	O
settings	O
correspond	O
to	O
an	O
acceptable	O
solution	O
moreover	O
in	O
the	O
context	O
of	O
neural	B
network	I
training	O
we	O
usually	O
do	O
not	O
care	O
about	O
finding	O
the	O
exact	O
minimum	O
of	O
a	O
function	O
but	O
seek	O
only	O
to	O
reduce	O
its	O
value	O
sufficiently	O
to	O
obtain	O
good	O
generalization	B
error	O
theoretical	O
analysis	O
of	O
whether	O
an	O
optimization	O
algorithm	O
can	O
accomplish	O
this	O
goal	O
is	O
extremely	O
difficult	O
developing	O
more	O
realistic	O
bounds	O
on	O
the	O
performance	O
of	O
optimization	O
algorithms	O
therefore	O
remains	O
an	O
important	O
goal	O
for	O
machine	B
learning	I
research	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
basic	O
algorithms	O
we	O
have	O
previously	O
introduced	O
the	O
gradient	B
descent	O
algorithm	O
that	O
follows	O
the	O
gradient	B
of	O
an	O
entire	O
training	O
set	O
downhill	O
this	O
may	O
be	O
accelerated	O
considerably	O
by	O
using	O
stochastic	O
gradient	B
descent	O
to	O
follow	O
the	O
gradient	B
of	O
randomly	O
selected	O
minibatches	O
downhill	O
as	O
discussed	O
in	O
section	O
and	O
section	O
stochastic	O
gradient	B
descent	O
stochastic	O
gradient	B
descent	O
and	O
its	O
variants	O
are	O
probably	O
the	O
most	O
used	O
optimization	O
algorithms	O
for	O
machine	B
learning	I
in	O
general	O
and	O
for	O
deep	O
learning	O
in	O
particular	O
as	O
discussed	O
in	O
section	O
it	O
is	O
possible	O
to	O
obtain	O
an	O
unbiased	B
estimate	O
of	O
the	O
gradient	B
by	O
taking	O
the	O
average	O
gradient	B
on	O
a	O
minibatch	B
of	O
m	O
examples	O
drawn	O
i	O
i	O
d	O
from	O
the	O
data	O
generating	O
distribution	O
algorithm	O
shows	O
how	O
to	O
follow	O
this	O
estimate	O
of	O
the	O
gradient	B
downhill	O
algorithm	O
stochastic	O
gradient	B
descent	O
update	O
at	O
training	O
iteration	O
k	O
require	O
learning	B
rate	I
k	O
require	O
initial	O
parameter	O
while	O
stopping	O
criterion	O
not	O
met	O
do	O
sample	O
a	O
minibatch	B
of	O
m	O
examples	O
from	O
the	O
training	O
set	O
corresponding	O
targets	O
y	O
compute	O
gradient	B
estimate	O
g	O
apply	O
update	O
m	O
g	O
i	O
l	O
f	O
y	O
x	O
with	O
end	O
while	O
a	O
crucial	O
parameter	O
for	O
the	O
sgd	O
algorithm	O
is	O
the	O
learning	B
rate	I
previously	O
we	O
have	O
described	O
sgd	O
as	O
using	O
a	O
fixed	O
learning	B
rate	I
in	O
practice	O
it	O
is	O
necessary	O
to	O
gradually	O
decrease	O
the	O
learning	B
rate	I
over	O
time	O
so	O
we	O
now	O
denote	O
the	O
learning	B
rate	I
at	O
iteration	O
ask	O
k	O
this	O
is	O
because	O
the	O
sgd	O
gradient	B
estimator	O
introduces	O
a	O
source	O
of	O
noise	O
random	O
sampling	O
of	O
m	O
training	O
examples	O
that	O
does	O
not	O
vanish	O
even	O
when	O
we	O
arrive	O
at	O
a	O
minimum	O
by	O
comparison	O
the	O
true	O
gradient	B
of	O
the	O
total	O
cost	O
function	O
becomes	O
small	O
and	O
then	O
when	O
we	O
approach	O
and	O
reach	O
a	O
minimum	O
using	O
batch	O
gradient	B
descent	O
so	O
batch	O
gradient	B
descent	O
can	O
use	O
a	O
fixed	O
learning	B
rate	I
a	O
sufficient	O
condition	O
to	O
guarantee	O
convergence	O
of	O
sgd	O
is	O
that	O
k	O
and	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
k	O
in	O
practice	O
it	O
is	O
common	O
to	O
decay	O
the	O
learning	B
rate	I
linearly	O
until	O
iteration	O
k	O
with	O
k	O
after	O
iteration	O
it	O
is	O
common	O
to	O
leave	O
constant	O
the	O
value	O
of	O
the	O
learning	B
rate	I
may	O
be	O
chosen	O
by	O
trial	O
and	O
error	O
but	O
it	O
is	O
usually	O
best	O
to	O
choose	O
it	O
by	O
monitoring	O
learning	O
curves	O
that	O
plot	O
the	O
objective	B
function	I
as	O
a	O
function	O
of	O
time	O
this	O
is	O
more	O
of	O
an	O
art	O
than	O
a	O
science	O
and	O
most	O
guidance	O
on	O
this	O
subject	O
should	O
be	O
regarded	O
with	O
some	O
skepticism	O
when	O
using	O
the	O
linear	O
schedule	O
the	O
parameters	O
to	O
choose	O
are	O
and	O
usually	O
may	O
be	O
set	O
to	O
the	O
number	O
of	O
iterations	O
required	O
to	O
make	O
a	O
few	O
hundred	O
passes	O
through	O
the	O
training	O
set	O
usually	O
should	O
be	O
set	O
to	O
roughly	O
the	O
main	O
question	O
is	O
how	O
to	O
set	O
if	O
it	O
is	O
too	O
large	O
the	O
learning	O
curve	O
will	O
show	O
violent	O
oscillations	O
with	O
the	O
cost	O
function	O
often	O
increasing	O
significantly	O
gentle	O
oscillations	O
are	O
fine	O
especially	O
if	O
training	O
with	O
a	O
stochastic	O
cost	O
function	O
such	O
as	O
the	O
cost	O
function	O
arising	O
from	O
the	O
use	O
of	O
dropout	O
if	O
the	O
learning	B
rate	I
is	O
too	O
low	O
learning	O
proceeds	O
slowly	O
and	O
if	O
the	O
initial	O
learning	B
rate	I
is	O
too	O
low	O
learning	O
may	O
become	O
stuck	O
with	O
a	O
high	O
cost	O
value	O
typically	O
the	O
optimal	O
initial	O
learning	B
rate	I
in	O
terms	O
of	O
total	O
training	O
time	O
and	O
the	O
final	O
cost	O
value	O
is	O
higher	O
than	O
the	O
learning	B
rate	I
that	O
yields	O
the	O
best	O
performance	O
after	O
the	O
first	O
iterations	O
or	O
so	O
therefore	O
it	O
is	O
usually	O
best	O
to	O
monitor	O
the	O
first	O
several	O
iterations	O
and	O
use	O
a	O
learning	B
rate	I
that	O
is	O
higher	O
than	O
the	O
best-performing	O
learning	B
rate	I
at	O
this	O
time	O
but	O
not	O
so	O
high	O
that	O
it	O
causes	O
severe	O
instability	O
the	O
most	O
important	O
property	O
of	O
sgd	O
and	O
related	O
minibatch	B
or	O
online	O
gradientbased	O
optimization	O
is	O
that	O
computation	O
time	O
per	O
update	O
does	O
not	O
grow	O
with	O
the	O
number	O
of	O
training	O
examples	O
this	O
allows	O
convergence	O
even	O
when	O
the	O
number	O
of	O
training	O
examples	O
becomes	O
very	O
large	O
for	O
a	O
large	O
enough	O
dataset	B
sgd	O
may	O
converge	O
to	O
within	O
some	O
fixed	O
tolerance	O
of	O
its	O
final	O
test	B
set	I
error	O
before	O
it	O
has	O
processed	O
the	O
entire	O
training	O
set	O
to	O
study	O
the	O
convergence	O
rate	O
of	O
an	O
optimization	O
algorithm	O
it	O
is	O
common	O
to	O
measure	O
the	O
excess	O
error	O
j	O
min	O
j	O
which	O
is	O
the	O
amount	O
that	O
the	O
current	O
cost	O
function	O
exceeds	O
the	O
minimum	O
possible	O
cost	O
when	O
sgd	O
is	O
applied	O
to	O
a	O
convex	O
problem	O
the	O
excess	O
error	O
is	O
o	O
after	O
k	O
iterations	O
while	O
in	O
the	O
strongly	O
convex	O
case	O
it	O
is	O
o	O
these	O
bounds	O
cannot	O
be	O
improved	O
unless	O
extra	O
conditions	O
are	O
k	O
assumed	O
batch	O
gradient	B
descent	O
enjoys	O
better	O
convergence	O
rates	O
than	O
stochastic	O
gradient	B
descent	O
in	O
theory	O
however	O
the	O
cram	O
r-rao	O
bound	B
cram	O
r	O
rao	O
states	O
that	O
generalization	B
error	O
cannot	O
decrease	O
faster	O
than	O
bottou	O
k	O
k	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
argue	O
that	O
it	O
therefore	O
may	O
not	O
be	O
worthwhile	O
to	O
pursue	O
and	O
bousquet	O
an	O
optimization	O
algorithm	O
that	O
converges	O
faster	O
than	O
o	O
for	O
machine	B
learning	I
k	O
tasks	O
faster	O
convergence	O
presumably	O
corresponds	O
to	O
overfitting	O
moreover	O
the	O
asymptotic	O
analysis	O
obscures	O
many	O
advantages	O
that	O
stochastic	O
gradient	B
descent	O
has	O
after	O
a	O
small	O
number	O
of	O
steps	O
with	O
large	O
datasets	O
the	O
ability	O
of	O
sgd	O
to	O
make	O
rapid	O
initial	O
progress	O
while	O
evaluating	O
the	O
gradient	B
for	O
only	O
very	O
few	O
examples	O
outweighs	O
its	O
slow	O
asymptotic	O
convergence	O
most	O
of	O
the	O
algorithms	O
described	O
in	O
the	O
remainder	O
of	O
this	O
chapter	O
achieve	O
benefits	O
that	O
matter	O
in	O
practice	O
but	O
are	O
lost	O
in	O
the	O
constant	O
factors	O
obscured	O
by	O
the	O
o	O
k	O
asymptotic	O
analysis	O
one	O
can	O
also	O
trade	O
off	O
the	O
benefits	O
of	O
both	O
batch	O
and	O
stochastic	O
gradient	B
descent	O
by	O
gradually	O
increasing	O
the	O
minibatch	B
size	O
during	O
the	O
course	O
of	O
learning	O
for	O
more	O
information	O
on	O
sgd	O
see	O
momentum	O
bottou	O
while	O
stochastic	O
gradient	B
descent	O
remains	O
a	O
very	O
popular	O
optimization	O
strategy	O
learning	O
with	O
it	O
can	O
sometimes	O
be	O
slow	O
the	O
method	O
of	O
momentum	O
is	O
designed	O
to	O
accelerate	O
learning	O
especially	O
in	O
the	O
face	O
of	O
high	O
curvature	O
small	O
but	O
consistent	O
gradients	O
or	O
noisy	O
gradients	O
the	O
momentum	O
algorithm	O
accumulates	O
an	O
exponentially	O
decaying	O
moving	O
average	O
of	O
past	O
gradients	O
and	O
continues	O
to	O
move	O
in	O
their	O
direction	O
the	O
effect	O
of	O
momentum	O
is	O
illustrated	O
in	O
figure	O
formally	O
the	O
momentum	O
algorithm	O
introduces	O
a	O
variable	O
v	O
that	O
plays	O
the	O
role	O
of	O
velocity	O
it	O
is	O
the	O
direction	O
and	O
speed	O
at	O
which	O
the	O
parameters	O
move	O
through	O
parameter	O
space	O
the	O
velocity	O
is	O
set	O
to	O
an	O
exponentially	O
decaying	O
average	O
of	O
the	O
negative	O
gradient	B
the	O
name	O
momentum	O
derives	O
from	O
a	O
physical	O
analogy	O
in	O
which	O
the	O
negative	O
gradient	B
is	O
a	O
force	O
moving	O
a	O
particle	O
through	O
parameter	O
space	O
according	O
to	O
newton	O
s	O
laws	O
of	O
motion	O
momentum	O
in	O
physics	O
is	O
mass	O
times	O
velocity	O
in	O
the	O
momentum	O
learning	O
algorithm	O
we	O
assume	O
unit	O
mass	O
so	O
the	O
velocity	O
vector	O
v	O
may	O
also	O
be	O
regarded	O
as	O
the	O
momentum	O
of	O
the	O
particle	O
a	O
hyperparameter	O
determines	O
how	O
quickly	O
the	O
contributions	O
of	O
previous	O
gradients	O
exponentially	O
decay	O
the	O
update	O
rule	O
is	O
given	O
by	O
v	O
v	O
v	O
m	O
m	O
l	O
x	O
y	O
m	O
l	O
x	O
y	O
the	O
velocity	O
v	O
accumulates	O
the	O
gradient	B
elements	O
the	O
larger	O
is	O
relative	O
to	O
the	O
more	O
previous	O
gradients	O
affect	O
the	O
current	O
direction	O
the	O
sgd	O
algorithm	O
with	O
momentum	O
is	O
given	O
in	O
algorithm	O
m	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
figure	O
momentum	O
aims	O
primarily	O
to	O
solve	O
two	O
problems	O
poor	O
conditioning	O
of	O
the	O
hessian	B
matrix	O
and	O
variance	O
in	O
the	O
stochastic	O
gradient	B
here	O
we	O
illustrate	O
how	O
momentum	O
overcomes	O
the	O
first	O
of	O
these	O
two	O
problems	O
the	O
contour	O
lines	O
depict	O
a	O
quadratic	O
loss	O
function	O
with	O
a	O
poorly	O
conditioned	O
hessian	B
matrix	O
the	O
red	O
path	O
cutting	O
across	O
the	O
contours	O
indicates	O
the	O
path	O
followed	O
by	O
the	O
momentum	O
learning	O
rule	O
as	O
it	O
minimizes	O
this	O
function	O
at	O
each	O
step	O
along	O
the	O
way	O
we	O
draw	O
an	O
arrow	O
indicating	O
the	O
step	O
that	O
gradient	B
descent	O
would	O
take	O
at	O
that	O
point	O
we	O
can	O
see	O
that	O
a	O
poorly	O
conditioned	O
quadratic	O
objective	O
looks	O
like	O
a	O
long	O
narrow	O
valley	O
or	O
canyon	O
with	O
steep	O
sides	O
momentum	O
correctly	O
traverses	O
the	O
canyon	O
lengthwise	O
while	O
gradient	B
steps	O
waste	O
time	O
moving	O
back	O
and	O
forth	O
across	O
the	O
narrow	O
axis	O
of	O
the	O
canyon	O
compare	O
also	O
figure	O
which	O
shows	O
the	O
behavior	O
of	O
gradient	B
descent	O
without	O
momentum	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
previously	O
the	O
size	O
of	O
the	O
step	O
was	O
simply	O
the	O
norm	O
of	O
the	O
gradient	B
multiplied	O
by	O
the	O
learning	B
rate	I
now	O
the	O
size	O
of	O
the	O
step	O
depends	O
on	O
how	O
large	O
and	O
how	O
aligned	O
a	O
sequence	O
of	O
gradients	O
are	O
the	O
step	O
size	O
is	O
largest	O
when	O
many	O
successive	O
gradients	O
point	O
in	O
exactly	O
the	O
same	O
direction	O
if	O
the	O
momentum	O
algorithm	O
always	O
observes	O
gradient	B
g	O
then	O
it	O
will	O
accelerate	O
in	O
the	O
direction	O
of	O
g	O
until	O
reaching	O
a	O
terminal	O
velocity	O
where	O
the	O
size	O
of	O
each	O
step	O
is	O
g	O
it	O
is	O
thus	O
helpful	O
to	O
think	O
of	O
the	O
momentum	O
hyperparameter	O
in	O
terms	O
of	O
example	B
corresponds	O
to	O
multiplying	O
the	O
maximum	O
speed	O
by	O
the	O
gradient	B
descent	O
algorithm	O
for	O
relative	O
to	O
common	O
values	O
of	O
used	O
in	O
practice	O
include	O
and	O
like	O
the	O
learning	B
rate	I
may	O
also	O
be	O
adapted	O
over	O
time	O
typically	O
it	O
begins	O
with	O
a	O
small	O
value	O
and	O
is	O
later	O
raised	O
it	O
is	O
less	O
important	O
to	O
adapt	O
over	O
time	O
than	O
to	O
shrink	O
over	O
time	O
algorithm	O
stochastic	O
gradient	B
descent	O
with	O
momentum	O
require	O
learning	B
rate	I
momentum	O
parameter	O
require	O
initial	O
parameter	O
initial	O
velocity	O
v	O
while	O
stopping	O
criterion	O
not	O
met	O
do	O
x	O
with	O
sample	O
a	O
minibatch	B
of	O
m	O
examples	O
from	O
the	O
training	O
set	O
corresponding	O
targets	O
y	O
compute	O
gradient	B
estimate	O
g	O
compute	O
velocity	O
update	O
v	O
apply	O
update	O
m	O
v	O
g	O
v	O
i	O
l	O
f	O
y	O
end	O
while	O
we	O
can	O
view	O
the	O
momentum	O
algorithm	O
as	O
simulating	O
a	O
particle	O
subject	O
to	O
continuous-time	O
newtonian	O
dynamics	O
the	O
physical	O
analogy	O
can	O
help	O
to	O
build	O
intuition	O
for	O
how	O
the	O
momentum	O
and	O
gradient	B
descent	O
algorithms	O
behave	O
the	O
position	O
of	O
the	O
particle	O
at	O
any	O
point	O
in	O
time	O
is	O
given	O
by	O
the	O
particle	O
experiences	O
net	O
force	O
f	O
this	O
force	O
causes	O
the	O
particle	O
to	O
accelerate	O
f	O
rather	O
than	O
viewing	O
this	O
as	O
a	O
second-order	O
differential	O
equation	O
of	O
the	O
position	O
we	O
can	O
introduce	O
the	O
variable	O
vt	O
representing	O
the	O
velocity	O
of	O
the	O
particle	O
at	O
time	O
t	O
and	O
rewrite	O
the	O
newtonian	O
dynamics	O
as	O
a	O
first-order	O
differential	O
equation	O
v	O
t	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
f	O
t	O
v	O
the	O
momentum	O
algorithm	O
then	O
consists	O
of	O
solving	O
the	O
differential	O
equations	O
via	O
numerical	O
simulation	O
a	O
simple	O
numerical	O
method	O
for	O
solving	O
differential	O
equations	O
is	O
euler	O
s	O
method	O
which	O
simply	O
consists	O
of	O
simulating	O
the	O
dynamics	O
defined	O
by	O
the	O
equation	O
by	O
taking	O
small	O
finite	O
steps	O
in	O
the	O
direction	O
of	O
each	O
gradient	B
this	O
explains	O
the	O
basic	O
form	O
of	O
the	O
momentum	O
update	O
but	O
what	O
specifically	O
are	O
the	O
forces	O
one	O
force	O
is	O
proportional	O
to	O
the	O
negative	O
gradient	B
of	O
the	O
cost	O
function	O
j	O
this	O
force	O
pushes	O
the	O
particle	O
downhill	O
along	O
the	O
cost	O
function	O
surface	O
the	O
gradient	B
descent	O
algorithm	O
would	O
simply	O
take	O
a	O
single	O
step	O
based	O
on	O
each	O
gradient	B
but	O
the	O
newtonian	O
scenario	O
used	O
by	O
the	O
momentum	O
algorithm	O
instead	O
uses	O
this	O
force	O
to	O
alter	O
the	O
velocity	O
of	O
the	O
particle	O
we	O
can	O
think	O
of	O
the	O
particle	O
as	O
being	O
like	O
a	O
hockey	O
puck	O
sliding	O
down	O
an	O
icy	O
surface	O
whenever	O
it	O
descends	O
a	O
steep	O
part	O
of	O
the	O
surface	O
it	O
gathers	O
speed	O
and	O
continues	O
sliding	O
in	O
that	O
direction	O
until	O
it	O
begins	O
to	O
go	O
uphill	O
again	O
one	O
other	O
force	O
is	O
necessary	O
if	O
the	O
only	O
force	O
is	O
the	O
gradient	B
of	O
the	O
cost	O
function	O
then	O
the	O
particle	O
might	O
never	O
come	O
to	O
rest	O
imagine	O
a	O
hockey	O
puck	O
sliding	O
down	O
one	O
side	O
of	O
a	O
valley	O
and	O
straight	O
up	O
the	O
other	O
side	O
oscillating	O
back	O
and	O
forth	O
forever	O
assuming	O
the	O
ice	O
is	O
perfectly	O
frictionless	O
to	O
resolve	O
this	O
problem	O
we	O
add	O
one	O
vt	O
in	O
physics	O
terminology	O
this	O
force	O
corresponds	O
other	O
force	O
proportional	O
to	O
to	O
viscous	O
drag	O
as	O
if	O
the	O
particle	O
must	O
push	O
through	O
a	O
resistant	O
medium	O
such	O
as	O
syrup	O
this	O
causes	O
the	O
particle	O
to	O
gradually	O
lose	O
energy	O
over	O
time	O
and	O
eventually	O
converge	O
to	O
a	O
local	O
minimum	O
vt	O
and	O
viscous	O
drag	O
in	O
particular	O
part	O
of	O
the	O
reason	O
to	O
why	O
do	O
we	O
use	O
vt	O
is	O
mathematical	O
convenience	O
an	O
integer	O
power	O
of	O
the	O
velocity	O
is	O
easy	O
use	O
to	O
work	O
with	O
however	O
other	O
physical	O
systems	O
have	O
other	O
kinds	O
of	O
drag	O
based	O
on	O
other	O
integer	O
powers	O
of	O
the	O
velocity	O
for	O
example	B
a	O
particle	O
traveling	O
through	O
the	O
air	O
experiences	O
turbulent	O
drag	O
with	O
force	O
proportional	O
to	O
the	O
square	O
of	O
the	O
velocity	O
while	O
a	O
particle	O
moving	O
along	O
the	O
ground	O
experiences	O
dry	O
friction	O
with	O
a	O
force	O
of	O
constant	O
magnitude	O
we	O
can	O
reject	O
each	O
of	O
these	O
options	O
turbulent	O
drag	O
proportional	O
to	O
the	O
square	O
of	O
the	O
velocity	O
becomes	O
very	O
weak	O
when	O
the	O
velocity	O
is	O
small	O
it	O
is	O
not	O
powerful	O
enough	O
to	O
force	O
the	O
particle	O
to	O
come	O
to	O
rest	O
a	O
particle	O
with	O
a	O
non-zero	O
initial	O
velocity	O
that	O
experiences	O
only	O
the	O
force	O
of	O
turbulent	O
drag	O
will	O
move	O
away	O
from	O
its	O
initial	O
position	O
forever	O
with	O
the	O
distance	O
from	O
the	O
starting	O
point	O
growing	O
like	O
olog	O
t	O
we	O
must	O
therefore	O
use	O
a	O
lower	O
power	O
of	O
the	O
velocity	O
if	O
we	O
use	O
a	O
power	O
of	O
zero	O
representing	O
dry	O
friction	O
then	O
the	O
force	O
is	O
too	O
strong	O
when	O
the	O
force	O
due	O
to	O
the	O
gradient	B
of	O
the	O
cost	O
function	O
is	O
small	O
but	O
non-zero	O
the	O
constant	O
force	O
due	O
to	O
friction	O
can	O
cause	O
the	O
particle	O
to	O
come	O
to	O
rest	O
before	O
reaching	O
a	O
local	O
minimum	O
viscous	O
drag	O
avoids	O
both	O
of	O
these	O
problems	O
it	O
is	O
weak	O
enough	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
that	O
the	O
gradient	B
can	O
continue	O
to	O
cause	O
motion	O
until	O
a	O
minimum	O
is	O
reached	O
but	O
strong	O
enough	O
to	O
prevent	O
motion	O
if	O
the	O
gradient	B
does	O
not	O
justify	O
moving	O
nesterov	B
momentum	I
et	O
al	O
sutskever	O
inspired	O
by	O
nesterov	O
s	O
accelerated	O
gradient	B
method	O
update	O
rules	O
in	O
this	O
case	O
are	O
given	O
by	O
introduced	O
a	O
variant	O
of	O
the	O
momentum	O
algorithm	O
that	O
was	O
the	O
nesterov	O
v	O
v	O
v	O
m	O
m	O
l	O
f	O
x	O
v	O
y	O
where	O
the	O
parameters	O
and	O
play	O
a	O
similar	O
role	O
as	O
in	O
the	O
standard	O
momentum	O
method	O
the	O
difference	O
between	O
nesterov	B
momentum	I
and	O
standard	O
momentum	O
is	O
where	O
the	O
gradient	B
is	O
evaluated	O
with	O
nesterov	B
momentum	I
the	O
gradient	B
is	O
evaluated	O
after	O
the	O
current	O
velocity	O
is	O
applied	O
thus	O
one	O
can	O
interpret	O
nesterov	B
momentum	I
as	O
attempting	O
to	O
add	O
a	O
correction	O
factor	O
to	O
the	O
standard	O
method	O
of	O
momentum	O
the	O
complete	O
nesterov	B
momentum	I
algorithm	O
is	O
presented	O
in	O
algorithm	O
in	O
the	O
convex	O
batch	O
gradient	B
case	O
nesterov	B
momentum	I
brings	O
the	O
rate	O
of	O
convergence	O
of	O
the	O
excess	O
error	O
from	O
k	O
steps	O
to	O
as	O
shown	O
by	O
nesterov	O
unfortunately	O
in	O
the	O
stochastic	O
gradient	B
case	O
nesterov	B
momentum	I
does	O
not	O
improve	O
the	O
rate	O
of	O
convergence	O
algorithm	O
stochastic	O
gradient	B
descent	O
with	O
nesterov	B
momentum	I
require	O
learning	B
rate	I
momentum	O
parameter	O
require	O
initial	O
parameter	O
initial	O
velocity	O
v	O
while	O
stopping	O
criterion	O
not	O
met	O
do	O
sample	O
a	O
minibatch	B
of	O
m	O
examples	O
from	O
the	O
training	O
set	O
corresponding	O
labels	O
y	O
apply	O
interim	O
update	O
compute	O
gradient	B
interim	O
point	O
g	O
compute	O
velocity	O
update	O
v	O
g	O
apply	O
update	O
v	O
m	O
v	O
v	O
x	O
with	O
i	O
l	O
f	O
y	O
end	O
while	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
parameter	O
initialization	B
strategies	O
some	O
optimization	O
algorithms	O
are	O
not	O
iterative	O
by	O
nature	O
and	O
simply	O
solve	O
for	O
a	O
solution	O
point	O
other	O
optimization	O
algorithms	O
are	O
iterative	O
by	O
nature	O
but	O
when	O
applied	O
to	O
the	O
right	O
class	O
of	O
optimization	O
problems	O
converge	O
to	O
acceptable	O
solutions	O
in	O
an	O
acceptable	O
amount	O
of	O
time	O
regardless	O
of	O
initialization	B
deep	O
learning	O
training	O
algorithms	O
usually	O
do	O
not	O
have	O
either	O
of	O
these	O
luxuries	O
training	O
algorithms	O
for	O
deep	O
learning	O
models	O
are	O
usually	O
iterative	O
in	O
nature	O
and	O
thus	O
require	O
the	O
user	O
to	O
specify	O
some	O
initial	O
point	O
from	O
which	O
to	O
begin	O
the	O
iterations	O
moreover	O
training	O
deep	O
models	O
is	O
a	O
sufficiently	O
difficult	O
task	O
that	O
most	O
algorithms	O
are	O
strongly	O
affected	O
by	O
the	O
choice	O
of	O
initialization	B
the	O
initial	O
point	O
can	O
determine	O
whether	O
the	O
algorithm	O
converges	O
at	O
all	O
with	O
some	O
initial	O
points	O
being	O
so	O
unstable	O
that	O
the	O
algorithm	O
encounters	O
numerical	O
difficulties	O
and	O
fails	O
altogether	O
when	O
learning	O
does	O
converge	O
the	O
initial	O
point	O
can	O
determine	O
how	O
quickly	O
learning	O
converges	O
and	O
whether	O
it	O
converges	O
to	O
a	O
point	O
with	O
high	O
or	O
low	O
cost	O
also	O
points	O
of	O
comparable	O
cost	O
can	O
have	O
wildly	O
varying	O
generalization	B
error	O
and	O
the	O
initial	O
point	O
can	O
affect	O
the	O
generalization	B
as	O
well	O
modern	O
initialization	B
strategies	O
are	O
simple	O
and	O
heuristic	O
designing	O
improved	O
initialization	B
strategies	O
is	O
a	O
difficult	O
task	O
because	O
neural	B
network	I
optimization	O
is	O
not	O
yet	O
well	O
understood	O
most	O
initialization	B
strategies	O
are	O
based	O
on	O
achieving	O
some	O
nice	O
properties	O
when	O
the	O
network	O
is	O
initialized	O
however	O
we	O
do	O
not	O
have	O
a	O
good	O
understanding	O
of	O
which	O
of	O
these	O
properties	O
are	O
preserved	O
under	O
which	O
circumstances	O
after	O
learning	O
begins	O
to	O
proceed	O
a	O
further	O
difficulty	O
is	O
that	O
some	O
initial	O
points	O
may	O
be	O
beneficial	O
from	O
the	O
viewpoint	O
of	O
optimization	O
but	O
detrimental	O
from	O
the	O
viewpoint	O
of	O
generalization	B
our	O
understanding	O
of	O
how	O
the	O
initial	O
point	O
affects	O
generalization	B
is	O
especially	O
primitive	O
offering	O
little	O
to	O
no	O
guidance	O
for	O
how	O
to	O
select	O
the	O
initial	O
point	O
perhaps	O
the	O
only	O
property	O
known	O
with	O
complete	O
certainty	O
is	O
that	O
the	O
initial	O
parameters	O
need	O
to	O
break	O
symmetry	O
between	O
different	O
units	O
if	O
two	O
hidden	O
units	O
with	O
the	O
same	O
activation	B
function	I
are	O
connected	O
to	O
the	O
same	O
inputs	O
then	O
these	O
units	O
must	O
have	O
different	O
initial	O
parameters	O
if	O
they	O
have	O
the	O
same	O
initial	O
parameters	O
then	O
a	O
deterministic	O
learning	O
algorithm	O
applied	O
to	O
a	O
deterministic	O
cost	O
and	O
model	O
will	O
constantly	O
update	O
both	O
of	O
these	O
units	O
in	O
the	O
same	O
way	O
even	O
if	O
the	O
model	O
or	O
training	O
algorithm	O
is	O
capable	O
of	O
using	O
stochasticity	O
to	O
compute	O
different	O
updates	O
for	O
different	O
units	O
example	B
if	O
one	O
trains	O
with	O
dropout	O
it	O
is	O
usually	O
best	O
to	O
initialize	O
each	O
unit	O
to	O
compute	O
a	O
different	O
function	O
from	O
all	O
of	O
the	O
other	O
units	O
this	O
may	O
help	O
to	O
make	O
sure	O
that	O
no	O
input	O
patterns	O
are	O
lost	O
in	O
the	O
null	O
space	O
of	O
forward	B
propagation	I
and	O
no	O
gradient	B
patterns	O
are	O
lost	O
in	O
the	O
null	O
space	O
of	O
back-propagation	B
the	O
goal	O
of	O
having	O
each	O
unit	O
compute	O
a	O
different	O
function	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
motivates	O
random	O
initialization	B
of	O
the	O
parameters	O
we	O
could	O
explicitly	O
search	O
for	O
a	O
large	O
set	O
of	O
basis	O
functions	O
that	O
are	O
all	O
mutually	O
different	O
from	O
each	O
other	O
but	O
this	O
often	O
incurs	O
a	O
noticeable	O
computational	O
cost	O
for	O
example	B
if	O
we	O
have	O
at	O
most	O
as	O
many	O
outputs	O
as	O
inputs	O
we	O
could	O
use	O
gram-schmidt	O
orthogonalization	O
on	O
an	O
initial	O
weight	O
matrix	O
and	O
be	O
guaranteed	O
that	O
each	O
unit	O
computes	O
a	O
very	O
different	O
function	O
from	O
each	O
other	O
unit	O
random	O
initialization	B
from	O
a	O
high-entropy	O
distribution	O
over	O
a	O
high-dimensional	O
space	O
is	O
computationally	O
cheaper	O
and	O
unlikely	O
to	O
assign	O
any	O
units	O
to	O
compute	O
the	O
same	O
function	O
as	O
each	O
other	O
typically	O
we	O
set	O
the	O
biases	O
for	O
each	O
unit	O
to	O
heuristically	O
chosen	O
constants	O
and	O
initialize	O
only	O
the	O
weights	B
randomly	O
extra	O
parameters	O
for	O
example	B
parameters	O
encoding	O
the	O
conditional	O
variance	O
of	O
a	O
prediction	O
are	O
usually	O
set	O
to	O
heuristically	O
chosen	O
constants	O
much	O
like	O
the	O
biases	O
are	O
we	O
almost	O
always	O
initialize	O
all	O
the	O
weights	B
in	O
the	O
model	O
to	O
values	O
drawn	O
randomly	O
from	O
a	O
gaussian	O
or	O
uniform	B
distribution	I
the	O
choice	O
of	O
gaussian	O
or	O
uniform	B
distribution	I
does	O
not	O
seem	O
to	O
matter	O
very	O
much	O
but	O
has	O
not	O
been	O
exhaustively	O
studied	O
the	O
scale	O
of	O
the	O
initial	O
distribution	O
however	O
does	O
have	O
a	O
large	O
effect	O
on	O
both	O
the	O
outcome	O
of	O
the	O
optimization	O
procedure	O
and	O
on	O
the	O
ability	O
of	O
the	O
network	O
to	O
generalize	O
larger	O
initial	O
weights	B
will	O
yield	O
a	O
stronger	O
symmetry	O
breaking	O
effect	O
helping	O
to	O
avoid	O
redundant	O
units	O
they	O
also	O
help	O
to	O
avoid	O
losing	O
signal	O
during	O
forward	O
or	O
back-propagation	B
through	O
the	O
linear	O
component	O
of	O
each	O
layer	O
larger	O
values	O
in	O
the	O
matrix	O
result	O
in	O
larger	O
outputs	O
of	O
matrix	O
multiplication	O
initial	O
weights	B
that	O
are	O
too	O
large	O
may	O
however	O
result	O
in	O
exploding	O
values	O
during	O
forward	B
propagation	I
or	O
back-propagation	B
in	O
recurrent	O
networks	O
large	O
weights	B
can	O
also	O
result	O
in	O
chaos	O
extreme	O
sensitivity	O
to	O
small	O
perturbations	O
of	O
the	O
input	O
that	O
the	O
behavior	O
of	O
the	O
deterministic	O
forward	B
propagation	I
procedure	O
appears	O
random	O
to	O
some	O
extent	O
the	O
exploding	O
gradient	B
problem	O
can	O
be	O
mitigated	O
by	O
gradient	B
clipping	O
the	O
values	O
of	O
the	O
gradients	O
before	O
performing	O
a	O
gradient	B
descent	O
step	O
large	O
weights	B
may	O
also	O
result	O
in	O
extreme	O
values	O
that	O
cause	O
the	O
activation	B
function	I
to	O
saturate	O
causing	O
complete	O
loss	O
of	O
gradient	B
through	O
saturated	O
units	O
these	O
competing	O
factors	O
determine	O
the	O
ideal	O
initial	O
scale	O
of	O
the	O
weights	B
the	O
perspectives	O
of	O
regularization	O
and	O
optimization	O
can	O
give	O
very	O
different	O
insights	O
into	O
how	O
we	O
should	O
initialize	O
a	O
network	O
the	O
optimization	O
perspective	O
suggests	O
that	O
the	O
weights	B
should	O
be	O
large	O
enough	O
to	O
propagate	O
information	O
successfully	O
but	O
some	O
regularization	O
concerns	O
encourage	O
making	O
them	O
smaller	O
the	O
use	O
of	O
an	O
optimization	O
algorithm	O
such	O
as	O
stochastic	O
gradient	B
descent	O
that	O
makes	O
small	O
incremental	O
changes	O
to	O
the	O
weights	B
and	O
tends	O
to	O
halt	O
in	O
areas	O
that	O
are	O
nearer	O
to	O
the	O
initial	O
parameters	O
due	O
to	O
getting	O
stuck	O
in	O
a	O
region	O
of	O
low	O
gradient	B
or	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
due	O
to	O
triggering	O
some	O
early	O
stopping	O
criterion	O
based	O
on	O
overfitting	O
expresses	O
a	O
prior	O
that	O
the	O
final	O
parameters	O
should	O
be	O
close	O
to	O
the	O
initial	O
parameters	O
recall	B
from	O
section	O
that	O
gradient	B
descent	O
with	O
early	O
stopping	O
is	O
equivalent	O
to	O
weight	O
decay	O
for	O
some	O
models	O
in	O
the	O
general	O
case	O
gradient	B
descent	O
with	O
early	O
stopping	O
is	O
not	O
the	O
same	O
as	O
weight	O
decay	O
but	O
does	O
provide	O
a	O
loose	O
analogy	O
for	O
thinking	O
about	O
the	O
effect	O
of	O
initialization	B
we	O
can	O
think	O
of	O
initializing	O
the	O
parameters	O
to	O
as	O
being	O
similar	O
to	O
imposing	O
a	O
gaussian	O
prior	O
p	O
with	O
mean	O
from	O
this	O
point	O
of	O
view	O
it	O
makes	O
sense	O
to	O
choose	O
to	O
be	O
near	O
this	O
prior	O
says	O
that	O
it	O
is	O
more	O
likely	O
that	O
units	O
do	O
not	O
interact	O
with	O
each	O
other	O
than	O
that	O
they	O
do	O
interact	O
units	O
interact	O
only	O
if	O
the	O
likelihood	O
term	O
of	O
the	O
objective	B
function	I
expresses	O
a	O
strong	O
preference	O
for	O
them	O
to	O
interact	O
on	O
the	O
other	O
hand	O
if	O
we	O
initialize	O
to	O
large	O
values	O
then	O
our	O
prior	O
specifies	O
which	O
units	O
should	O
interact	O
with	O
each	O
other	O
and	O
how	O
they	O
should	O
interact	O
some	O
heuristics	O
are	O
available	O
for	O
choosing	O
the	O
initial	O
scale	O
of	O
the	O
weights	B
one	O
heuristic	O
is	O
to	O
initialize	O
the	O
weights	B
of	O
a	O
fully	O
connected	O
layer	O
with	O
m	O
inputs	O
and	O
n	O
outputs	O
by	O
sampling	O
each	O
weight	O
from	O
u	O
while	O
glorot	O
and	O
bengio	O
normalized	B
initialization	B
suggest	O
using	O
the	O
m	O
m	O
u	O
wij	O
m	O
n	O
m	O
n	O
this	O
latter	O
heuristic	O
is	O
designed	O
to	O
compromise	O
between	O
the	O
goal	O
of	O
initializing	O
all	O
layers	O
to	O
have	O
the	O
same	O
activation	O
variance	O
and	O
the	O
goal	O
of	O
initializing	O
all	O
layers	O
to	O
have	O
the	O
same	O
gradient	B
variance	O
the	O
formula	O
is	O
derived	O
using	O
the	O
assumption	O
that	O
the	O
network	O
consists	O
only	O
of	O
a	O
chain	O
of	O
matrix	O
multiplications	O
with	O
no	O
nonlinearities	O
real	O
neural	O
networks	O
obviously	O
violate	O
this	O
assumption	O
but	O
many	O
strategies	O
designed	O
for	O
the	O
linear	O
model	O
perform	O
reasonably	O
well	O
on	O
its	O
nonlinear	O
counterparts	O
saxe	O
et	O
al	O
recommend	O
initializing	O
to	O
random	O
orthogonal	O
matrices	O
with	O
a	O
carefully	O
chosen	O
scaling	O
or	O
gain	O
factor	O
g	O
that	O
accounts	O
for	O
the	O
nonlinearity	O
applied	O
at	O
each	O
layer	O
they	O
derive	O
specific	O
values	O
of	O
the	O
scaling	O
factor	O
for	O
different	O
types	O
of	O
nonlinear	O
activation	O
functions	O
this	O
initialization	B
scheme	O
is	O
also	O
motivated	O
by	O
a	O
model	O
of	O
a	O
deep	O
network	O
as	O
a	O
sequence	O
of	O
matrix	O
multiplies	O
without	O
nonlinearities	O
under	O
such	O
a	O
model	O
this	O
initialization	B
scheme	O
guarantees	O
that	O
the	O
total	O
number	O
of	O
training	O
iterations	O
required	O
to	O
reach	O
convergence	O
is	O
independent	O
of	O
depth	O
increasing	O
the	O
scaling	O
factor	O
g	O
pushes	O
the	O
network	O
toward	O
the	O
regime	O
where	O
activations	O
increase	O
in	O
norm	O
as	O
they	O
propagate	O
forward	O
through	O
the	O
network	O
and	O
gradients	O
increase	O
in	O
norm	O
as	O
they	O
propagate	O
backward	O
showed	O
that	O
setting	O
the	O
gain	O
factor	O
correctly	O
is	O
sufficient	O
to	O
train	O
networks	O
as	O
deep	O
as	O
sussillo	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
layers	O
without	O
needing	O
to	O
use	O
orthogonal	O
initializations	O
a	O
key	O
insight	O
of	O
this	O
approach	O
is	O
that	O
in	O
feedforward	O
networks	O
activations	O
and	O
gradients	O
can	O
grow	O
or	O
shrink	O
on	O
each	O
step	O
of	O
forward	O
or	O
back-propagation	B
following	O
a	O
random	O
walk	O
behavior	O
this	O
is	O
because	O
feedforward	O
networks	O
use	O
a	O
different	O
weight	O
matrix	O
at	O
each	O
layer	O
if	O
this	O
random	O
walk	O
is	O
tuned	O
to	O
preserve	O
norms	O
then	O
feedforward	O
networks	O
can	O
mostly	O
avoid	O
the	O
vanishing	O
and	O
exploding	O
gradients	O
problem	O
that	O
arises	O
when	O
the	O
same	O
weight	O
matrix	O
is	O
used	O
at	O
each	O
step	O
described	O
in	O
section	O
unfortunately	O
these	O
optimal	O
criteria	O
for	O
initial	O
weights	B
often	O
do	O
not	O
lead	O
to	O
optimal	O
performance	O
this	O
may	O
be	O
for	O
three	O
different	O
reasons	O
first	O
we	O
may	O
be	O
using	O
the	O
wrong	O
criteria	O
it	O
may	O
not	O
actually	O
be	O
beneficial	O
to	O
preserve	O
the	O
norm	O
of	O
a	O
signal	O
throughout	O
the	O
entire	O
network	O
second	O
the	O
properties	O
imposed	O
at	O
initialization	B
may	O
not	O
persist	O
after	O
learning	O
has	O
begun	O
to	O
proceed	O
third	O
the	O
criteria	O
might	O
succeed	O
at	O
improving	O
the	O
speed	O
of	O
optimization	O
but	O
inadvertently	O
increase	O
generalization	B
error	O
in	O
practice	O
we	O
usually	O
need	O
to	O
treat	O
the	O
scale	O
of	O
the	O
weights	B
as	O
a	O
hyperparameter	O
whose	O
optimal	O
value	O
lies	O
somewhere	O
roughly	O
near	O
but	O
not	O
exactly	O
equal	O
to	O
the	O
theoretical	O
predictions	O
m	O
martens	O
one	O
drawback	O
to	O
scaling	O
rules	O
that	O
set	O
all	O
of	O
the	O
initial	O
weights	B
to	O
have	O
the	O
is	O
that	O
every	O
individual	O
weight	O
becomes	O
same	O
standard	B
deviation	I
such	O
as	O
introduced	O
an	O
extremely	O
small	O
when	O
the	O
layers	O
become	O
large	O
alternative	O
initialization	B
scheme	O
called	O
sparse	O
initialization	B
in	O
which	O
each	O
unit	O
is	O
initialized	O
to	O
have	O
exactly	O
k	O
non-zero	O
weights	B
the	O
idea	O
is	O
to	O
keep	O
the	O
total	O
amount	O
of	O
input	O
to	O
the	O
unit	O
independent	O
from	O
the	O
number	O
of	O
inputs	O
m	O
without	O
making	O
the	O
magnitude	O
of	O
individual	O
weight	O
elements	O
shrink	O
with	O
m	O
sparse	O
initialization	B
helps	O
to	O
achieve	O
more	O
diversity	O
among	O
the	O
units	O
at	O
initialization	B
time	O
however	O
it	O
also	O
imposes	O
a	O
very	O
strong	O
prior	O
on	O
the	O
weights	B
that	O
are	O
chosen	O
to	O
have	O
large	O
gaussian	O
values	O
because	O
it	O
takes	O
a	O
long	O
time	O
for	O
gradient	B
descent	O
to	O
shrink	O
incorrect	O
large	O
values	O
this	O
initialization	B
scheme	O
can	O
cause	O
problems	O
for	O
units	O
such	O
as	O
maxout	O
units	O
that	O
have	O
several	O
filters	O
that	O
must	O
be	O
carefully	O
coordinated	O
with	O
each	O
other	O
when	O
computational	O
resources	O
allow	O
it	O
it	O
is	O
usually	O
a	O
good	O
idea	O
to	O
treat	O
the	O
initial	O
scale	O
of	O
the	O
weights	B
for	O
each	O
layer	O
as	O
a	O
hyperparameter	O
and	O
to	O
choose	O
these	O
scales	O
using	O
a	O
hyperparameter	O
search	O
algorithm	O
described	O
in	O
section	O
such	O
as	O
random	B
search	I
the	O
choice	O
of	O
whether	O
to	O
use	O
dense	O
or	O
sparse	O
initialization	B
can	O
also	O
be	O
made	O
a	O
hyperparameter	O
alternately	O
one	O
can	O
manually	O
search	O
for	O
the	O
best	O
initial	O
scales	O
a	O
good	O
rule	O
of	O
thumb	O
for	O
choosing	O
the	O
initial	O
scales	O
is	O
to	O
look	O
at	O
the	O
range	O
or	O
standard	B
deviation	I
of	O
activations	O
or	O
gradients	O
on	O
a	O
single	O
minibatch	B
of	O
data	O
if	O
the	O
weights	B
are	O
too	O
small	O
the	O
range	O
of	O
activations	O
across	O
the	O
minibatch	B
will	O
shrink	O
as	O
the	O
activations	O
propagate	O
forward	O
through	O
the	O
network	O
by	O
repeatedly	O
identifying	O
the	O
first	O
layer	O
with	O
unacceptably	O
small	O
activations	O
and	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
increasing	O
its	O
weights	B
it	O
is	O
possible	O
to	O
eventually	O
obtain	O
a	O
network	O
with	O
reasonable	O
initial	O
activations	O
throughout	O
if	O
learning	O
is	O
still	O
too	O
slow	O
at	O
this	O
point	O
it	O
can	O
be	O
useful	O
to	O
look	O
at	O
the	O
range	O
or	O
standard	B
deviation	I
of	O
the	O
gradients	O
as	O
well	O
as	O
the	O
activations	O
this	O
procedure	O
can	O
in	O
principle	O
be	O
automated	O
and	O
is	O
generally	O
less	O
computationally	O
costly	O
than	O
hyperparameter	B
optimization	I
based	O
on	O
validation	O
set	O
error	O
because	O
it	O
is	O
based	O
on	O
feedback	O
from	O
the	O
behavior	O
of	O
the	O
initial	O
model	O
on	O
a	O
single	O
batch	O
of	O
data	O
rather	O
than	O
on	O
feedback	O
from	O
a	O
trained	O
model	O
on	O
the	O
validation	O
set	O
while	O
long	O
used	O
heuristically	O
this	O
protocol	O
has	O
recently	O
been	O
specified	O
more	O
formally	O
and	O
studied	O
by	O
mishkin	O
and	O
matas	O
so	O
far	O
we	O
have	O
focused	O
on	O
the	O
initialization	B
of	O
the	O
weights	B
fortunately	O
initialization	B
of	O
other	O
parameters	O
is	O
typically	O
easier	O
the	O
approach	O
for	O
setting	O
the	O
biases	O
must	O
be	O
coordinated	O
with	O
the	O
approach	O
for	O
settings	O
the	O
weights	B
setting	O
the	O
biases	O
to	O
zero	O
is	O
compatible	O
with	O
most	O
weight	O
initialization	B
schemes	O
there	O
are	O
a	O
few	O
situations	O
where	O
we	O
may	O
set	O
some	O
biases	O
to	O
non-zero	O
values	O
if	O
a	O
bias	O
is	O
for	O
an	O
output	O
unit	O
then	O
it	O
is	O
often	O
beneficial	O
to	O
initialize	O
the	O
bias	O
to	O
obtain	O
the	O
right	O
marginal	O
statistics	O
of	O
the	O
output	O
to	O
do	O
this	O
we	O
assume	O
that	O
the	O
initial	O
weights	B
are	O
small	O
enough	O
that	O
the	O
output	O
of	O
the	O
unit	O
is	O
determined	O
only	O
by	O
the	O
bias	O
this	O
justifies	O
setting	O
the	O
bias	O
to	O
the	O
inverse	O
of	O
the	O
activation	B
function	I
applied	O
to	O
the	O
marginal	O
statistics	O
of	O
the	O
output	O
in	O
the	O
training	O
set	O
for	O
example	B
if	O
the	O
output	O
is	O
a	O
distribution	O
over	O
classes	O
and	O
this	O
distribution	O
is	O
a	O
highly	O
skewed	O
distribution	O
with	O
the	O
marginal	B
probability	I
of	O
class	O
i	O
given	O
by	O
element	O
ci	O
of	O
some	O
vector	O
c	O
then	O
we	O
can	O
set	O
the	O
bias	O
vector	O
b	O
by	O
solving	O
the	O
equation	O
softmaxb	O
c	O
this	O
applies	O
not	O
only	O
to	O
classifiers	O
but	O
also	O
to	O
models	O
we	O
will	O
encounter	O
in	O
part	O
such	O
as	O
autoencoders	O
and	O
boltzmann	O
machines	O
these	O
models	O
have	O
layers	O
whose	O
output	O
should	O
resemble	O
the	O
input	O
data	O
x	O
and	O
it	O
can	O
be	O
very	O
helpful	O
to	O
initialize	O
the	O
biases	O
of	O
such	O
layers	O
to	O
match	O
the	O
marginal	O
distribution	O
over	O
iii	O
sometimes	O
we	O
may	O
want	O
to	O
choose	O
the	O
bias	O
to	O
avoid	O
causing	O
too	O
much	O
saturation	O
at	O
initialization	B
for	O
example	B
we	O
may	O
set	O
the	O
bias	O
of	O
a	O
relu	O
hidden	O
unit	O
to	O
rather	O
than	O
to	O
avoid	O
saturating	O
the	O
relu	O
at	O
initialization	B
this	O
approach	O
is	O
not	O
compatible	O
with	O
weight	O
initialization	B
schemes	O
that	O
do	O
not	O
expect	O
strong	O
input	O
from	O
the	O
biases	O
though	O
for	O
example	B
it	O
is	O
not	O
recommended	O
for	O
use	O
with	O
random	O
walk	O
initialization	B
sussillo	O
sometimes	O
a	O
unit	O
controls	O
whether	O
other	O
units	O
are	O
able	O
to	O
participate	O
in	O
a	O
function	O
in	O
such	O
situations	O
we	O
have	O
a	O
unit	O
with	O
output	O
u	O
and	O
another	O
unit	O
and	O
they	O
are	O
multiplied	O
together	O
to	O
produce	O
an	O
output	O
uh	O
we	O
h	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
u	O
can	O
view	O
h	O
as	O
a	O
gate	O
that	O
determines	O
whether	O
uh	O
in	O
these	O
situations	O
we	O
want	O
to	O
set	O
the	O
bias	O
for	O
h	O
so	O
that	O
h	O
most	O
of	O
the	O
time	O
at	O
initialization	B
otherwise	O
u	O
does	O
not	O
have	O
a	O
chance	O
to	O
learn	O
for	O
example	B
jozefowicz	O
for	O
the	O
forget	B
gate	I
of	O
the	O
lstm	O
model	O
described	O
in	O
section	O
advocate	O
setting	O
the	O
bias	O
to	O
et	O
al	O
or	O
uh	O
another	O
common	O
type	O
of	O
parameter	O
is	O
a	O
variance	O
or	O
precision	B
parameter	O
for	O
example	B
we	O
can	O
perform	O
linear	O
regression	B
with	O
a	O
conditional	O
variance	O
estimate	O
using	O
the	O
model	O
n	O
x	O
p	O
y	O
y	O
wt	O
x	O
b	O
where	O
is	O
a	O
precision	B
parameter	O
we	O
can	O
usually	O
initialize	O
variance	O
or	O
precision	B
parameters	O
to	O
safely	O
another	O
approach	O
is	O
to	O
assume	O
the	O
initial	O
weights	B
are	O
close	O
enough	O
to	O
zero	O
that	O
the	O
biases	O
may	O
be	O
set	O
while	O
ignoring	O
the	O
effect	O
of	O
the	O
weights	B
then	O
set	O
the	O
biases	O
to	O
produce	O
the	O
correct	O
marginal	O
mean	O
of	O
the	O
output	O
and	O
set	O
the	O
variance	O
parameters	O
to	O
the	O
marginal	O
variance	O
of	O
the	O
output	O
in	O
the	O
training	O
set	O
iii	O
besides	O
these	O
simple	O
constant	O
or	O
random	O
methods	O
of	O
initializing	O
model	O
parameters	O
it	O
is	O
possible	O
to	O
initialize	O
model	O
parameters	O
using	O
machine	B
learning	I
a	O
common	O
strategy	O
discussed	O
in	O
part	O
of	O
this	O
book	O
is	O
to	O
initialize	O
a	O
supervised	O
model	O
with	O
the	O
parameters	O
learned	O
by	O
an	O
unsupervised	O
model	O
trained	O
on	O
the	O
same	O
inputs	O
one	O
can	O
also	O
perform	O
supervised	O
training	O
on	O
a	O
related	O
task	O
even	O
performing	O
supervised	O
training	O
on	O
an	O
unrelated	O
task	O
can	O
sometimes	O
yield	O
an	O
initialization	B
that	O
offers	O
faster	O
convergence	O
than	O
a	O
random	O
initialization	B
some	O
of	O
these	O
initialization	B
strategies	O
may	O
yield	O
faster	O
convergence	O
and	O
better	O
generalization	B
because	O
they	O
encode	O
information	O
about	O
the	O
distribution	O
in	O
the	O
initial	O
parameters	O
of	O
the	O
model	O
others	O
apparently	O
perform	O
well	O
primarily	O
because	O
they	O
set	O
the	O
parameters	O
to	O
have	O
the	O
right	O
scale	O
or	O
set	O
different	O
units	O
to	O
compute	O
different	O
functions	O
from	O
each	O
other	O
algorithms	O
with	O
adaptive	O
learning	O
rates	O
neural	B
network	I
researchers	O
have	O
long	O
realized	O
that	O
the	O
learning	B
rate	I
was	O
reliably	O
one	O
of	O
the	O
hyperparameters	O
that	O
is	O
the	O
most	O
difficult	O
to	O
set	O
because	O
it	O
has	O
a	O
significant	O
impact	O
on	O
model	O
performance	O
as	O
we	O
have	O
discussed	O
in	O
sections	O
the	O
cost	O
is	O
often	O
highly	O
sensitive	O
to	O
some	O
directions	O
in	O
parameter	O
space	O
and	O
insensitive	O
to	O
others	O
the	O
momentum	O
algorithm	O
can	O
mitigate	O
these	O
issues	O
somewhat	O
but	O
does	O
so	O
at	O
the	O
expense	O
of	O
introducing	O
another	O
hyperparameter	O
in	O
the	O
face	O
of	O
this	O
it	O
is	O
natural	O
to	O
ask	O
if	O
there	O
is	O
another	O
way	O
if	O
we	O
believe	O
that	O
the	O
directions	O
of	O
sensitivity	O
are	O
somewhat	O
axis-aligned	O
it	O
can	O
make	O
sense	O
to	O
use	O
a	O
separate	O
learning	O
and	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
rate	O
for	O
each	O
parameter	O
and	O
automatically	O
adapt	O
these	O
learning	O
rates	O
throughout	O
the	O
course	O
of	O
learning	O
the	O
algorithm	O
jacobs	O
delta-bar-delta	O
is	O
an	O
early	O
heuristic	O
approach	O
to	O
adapting	O
individual	O
learning	O
rates	O
for	O
model	O
parameters	O
during	O
training	O
the	O
approach	O
is	O
based	O
on	O
a	O
simple	O
idea	O
if	O
the	O
partial	B
derivative	B
of	O
the	O
loss	O
with	O
respect	O
to	O
a	O
given	O
model	O
parameter	O
remains	O
the	O
same	O
sign	O
then	O
the	O
learning	B
rate	I
should	O
increase	O
if	O
the	O
partial	B
derivative	B
with	O
respect	O
to	O
that	O
parameter	O
changes	O
sign	O
then	O
the	O
learning	B
rate	I
should	O
decrease	O
of	O
course	O
this	O
kind	O
of	O
rule	O
can	O
only	O
be	O
applied	O
to	O
full	O
batch	O
optimization	O
more	O
recently	O
a	O
number	O
of	O
incremental	O
mini-batch-based	O
methods	O
have	O
been	O
introduced	O
that	O
adapt	O
the	O
learning	O
rates	O
of	O
model	O
parameters	O
this	O
section	O
will	O
briefly	O
review	O
a	O
few	O
of	O
these	O
algorithms	O
adagrad	B
the	O
adagrad	B
algorithm	O
shown	O
in	O
algorithm	O
individually	O
adapts	O
the	O
learning	O
rates	O
of	O
all	O
model	O
parameters	O
by	O
scaling	O
them	O
inversely	O
proportional	O
to	O
the	O
square	O
root	O
of	O
the	O
sum	O
of	O
all	O
of	O
their	O
historical	O
squared	O
values	O
the	O
parameters	O
with	O
the	O
largest	O
partial	B
derivative	B
of	O
the	O
loss	O
have	O
a	O
correspondingly	O
rapid	O
decrease	O
in	O
their	O
learning	B
rate	I
while	O
parameters	O
with	O
small	O
partial	O
derivatives	O
have	O
a	O
relatively	O
small	O
decrease	O
in	O
their	O
learning	B
rate	I
the	O
net	O
effect	O
is	O
greater	O
progress	O
in	O
the	O
more	O
gently	O
sloped	O
directions	O
of	O
parameter	O
space	O
duchi	O
et	O
al	O
in	O
the	O
context	O
of	O
convex	B
optimization	I
the	O
adagrad	B
algorithm	O
enjoys	O
some	O
desirable	O
theoretical	O
properties	O
however	O
empirically	O
it	O
has	O
been	O
found	O
that	O
for	O
training	O
deep	O
neural	B
network	I
models	O
the	O
accumulation	O
of	O
squared	O
gradients	O
from	O
the	O
beginning	O
of	O
training	O
can	O
result	O
in	O
a	O
premature	O
and	O
excessive	O
decrease	O
in	O
the	O
effective	O
learning	B
rate	I
adagrad	B
performs	O
well	O
for	O
some	O
but	O
not	O
all	O
deep	O
learning	O
models	O
rmsprop	O
hinton	O
the	O
rmsprop	O
algorithm	O
modifies	O
adagrad	B
to	O
perform	O
better	O
in	O
the	O
non-convex	O
setting	O
by	O
changing	O
the	O
gradient	B
accumulation	O
into	O
an	O
exponentially	O
weighted	O
moving	O
average	O
adagrad	B
is	O
designed	O
to	O
converge	O
rapidly	O
when	O
applied	O
to	O
a	O
convex	O
function	O
when	O
applied	O
to	O
a	O
non-convex	O
function	O
to	O
train	O
a	O
neural	B
network	I
the	O
learning	O
trajectory	O
may	O
pass	O
through	O
many	O
different	O
structures	O
and	O
eventually	O
arrive	O
at	O
a	O
region	O
that	O
is	O
a	O
locally	O
convex	O
bowl	O
adagrad	B
shrinks	O
the	O
learning	B
rate	I
according	O
to	O
the	O
entire	O
history	O
of	O
the	O
squared	O
gradient	B
and	O
may	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
algorithm	O
the	O
adagrad	B
algorithm	O
require	O
global	O
learning	B
rate	I
require	O
initial	O
parameter	O
require	O
small	O
constant	O
perhaps	O
initialize	O
gradient	B
accumulation	O
variable	O
r	O
while	O
stopping	O
criterion	O
not	O
met	O
do	O
for	O
numerical	O
stability	O
x	O
with	O
sample	O
a	O
minibatch	B
of	O
m	O
examples	O
from	O
the	O
training	O
set	O
corresponding	O
targets	O
y	O
compute	O
gradient	B
g	O
m	O
accumulate	O
squared	O
gradient	B
r	O
compute	O
update	O
r	O
element-wise	O
apply	O
update	O
i	O
l	O
f	O
y	O
r	O
g	O
g	O
g	O
and	O
square	O
root	O
applied	O
end	O
while	O
have	O
made	O
the	O
learning	B
rate	I
too	O
small	O
before	O
arriving	O
at	O
such	O
a	O
convex	O
structure	O
rmsprop	O
uses	O
an	O
exponentially	O
decaying	O
average	O
to	O
discard	O
history	O
from	O
the	O
extreme	O
past	O
so	O
that	O
it	O
can	O
converge	O
rapidly	O
after	O
finding	O
a	O
convex	O
bowl	O
as	O
if	O
it	O
were	O
an	O
instance	O
of	O
the	O
adagrad	B
algorithm	O
initialized	O
within	O
that	O
bowl	O
rmsprop	O
is	O
shown	O
in	O
its	O
standard	O
form	O
in	O
algorithm	O
and	O
combined	O
with	O
nesterov	B
momentum	I
in	O
algorithm	O
compared	O
to	O
adagrad	B
the	O
use	O
of	O
the	O
moving	O
average	O
introduces	O
a	O
new	O
hyperparameter	O
that	O
controls	O
the	O
length	O
scale	O
of	O
the	O
moving	O
average	O
empirically	O
rmsprop	O
has	O
been	O
shown	O
to	O
be	O
an	O
effective	O
and	O
practical	O
optimization	O
algorithm	O
for	O
deep	O
neural	O
networks	O
it	O
is	O
currently	O
one	O
of	O
the	O
go-to	O
optimization	O
methods	O
being	O
employed	O
routinely	O
by	O
deep	O
learning	O
practitioners	O
adam	O
kingma	O
and	O
ba	O
is	O
yet	O
another	O
adaptive	O
learning	B
rate	I
optimization	O
adam	O
the	O
name	O
adam	O
derives	O
from	O
algorithm	O
and	O
is	O
presented	O
in	O
algorithm	O
the	O
phrase	O
adaptive	O
moments	O
in	O
the	O
context	O
of	O
the	O
earlier	O
algorithms	O
it	O
is	O
perhaps	O
best	O
seen	O
as	O
a	O
variant	O
on	O
the	O
combination	O
of	O
rmsprop	O
and	O
momentum	O
with	O
a	O
few	O
important	O
distinctions	O
first	O
in	O
adam	O
momentum	O
is	O
incorporated	O
directly	O
as	O
an	O
estimate	O
of	O
the	O
first	O
order	O
moment	O
exponential	O
weighting	O
of	O
the	O
gradient	B
the	O
most	O
straightforward	O
way	O
to	O
add	O
momentum	O
to	O
rmsprop	O
is	O
to	O
apply	O
momentum	O
to	O
the	O
rescaled	O
gradients	O
the	O
use	O
of	O
momentum	O
in	O
combination	O
with	O
rescaling	O
does	O
not	O
have	O
a	O
clear	O
theoretical	O
motivation	O
second	O
adam	O
includes	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
algorithm	O
the	O
rmsprop	O
algorithm	O
require	O
global	O
learning	B
rate	I
decay	O
rate	O
require	O
initial	O
parameter	O
require	O
small	O
constant	O
usually	O
used	O
to	O
stabilize	O
division	O
by	O
small	O
numbers	O
initialize	O
accumulation	O
variables	O
r	O
while	O
stopping	O
criterion	O
not	O
met	O
do	O
sample	O
a	O
minibatch	B
of	O
m	O
examples	O
from	O
the	O
training	O
set	O
corresponding	O
targets	O
y	O
compute	O
gradient	B
g	O
m	O
accumulate	O
squared	O
gradient	B
r	O
compute	O
parameter	O
update	O
apply	O
update	O
i	O
l	O
f	O
y	O
g	O
r	O
g	O
g	O
x	O
with	O
applied	O
element-wise	O
end	O
while	O
bias	O
corrections	O
to	O
the	O
estimates	O
of	O
both	O
the	O
first-order	O
moments	O
momentum	O
term	O
and	O
the	O
second-order	O
moments	O
to	O
account	O
for	O
their	O
initialization	B
at	O
the	O
origin	O
algorithm	O
rmsprop	O
also	O
incorporates	O
an	O
estimate	O
of	O
the	O
second-order	O
moment	O
however	O
it	O
lacks	O
the	O
correction	O
factor	O
thus	O
unlike	O
in	O
adam	O
the	O
rmsprop	O
second-order	O
moment	O
estimate	O
may	O
have	O
high	O
bias	O
early	O
in	O
training	O
adam	O
is	O
generally	O
regarded	O
as	O
being	O
fairly	O
robust	O
to	O
the	O
choice	O
of	O
hyperparameters	O
though	O
the	O
learning	B
rate	I
sometimes	O
needs	O
to	O
be	O
changed	O
from	O
the	O
suggested	O
default	O
choosing	O
the	O
right	O
optimization	O
algorithm	O
in	O
this	O
section	O
we	O
discussed	O
a	O
series	O
of	O
related	O
algorithms	O
that	O
each	O
seek	O
to	O
address	O
the	O
challenge	B
of	O
optimizing	O
deep	O
models	O
by	O
adapting	O
the	O
learning	B
rate	I
for	O
each	O
model	O
parameter	O
at	O
this	O
point	O
a	O
natural	O
question	O
is	O
which	O
algorithm	O
should	O
one	O
choose	O
unfortunately	O
there	O
is	O
currently	O
no	O
consensus	O
on	O
this	O
point	O
schaul	O
et	O
al	O
presented	O
a	O
valuable	O
comparison	O
of	O
a	O
large	O
number	O
of	O
optimization	O
algorithms	O
across	O
a	O
wide	O
range	O
of	O
learning	O
tasks	O
while	O
the	O
results	O
suggest	O
that	O
the	O
family	O
of	O
algorithms	O
with	O
adaptive	O
learning	O
rates	O
by	O
rmsprop	O
and	O
adadelta	O
performed	O
fairly	O
robustly	O
no	O
single	O
best	O
algorithm	O
has	O
emerged	O
currently	O
the	O
most	O
popular	O
optimization	O
algorithms	O
actively	O
in	O
use	O
include	O
sgd	O
sgd	O
with	O
momentum	O
rmsprop	O
rmsprop	O
with	O
momentum	O
adadelta	O
and	O
adam	O
the	O
choice	O
of	O
which	O
algorithm	O
to	O
use	O
at	O
this	O
point	O
seems	O
to	O
depend	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
algorithm	O
rmsprop	O
algorithm	O
with	O
nesterov	B
momentum	I
require	O
global	O
learning	B
rate	I
decay	O
rate	O
momentum	O
coefficient	O
require	O
initial	O
parameter	O
initial	O
velocity	O
v	O
initialize	O
accumulation	O
variable	O
r	O
while	O
stopping	O
criterion	O
not	O
met	O
do	O
sample	O
a	O
minibatch	B
of	O
m	O
examples	O
from	O
the	O
training	O
set	O
corresponding	O
targets	O
y	O
compute	O
interim	O
update	O
compute	O
gradient	B
g	O
accumulate	O
gradient	B
r	O
r	O
compute	O
velocity	O
update	O
v	O
v	O
apply	O
update	O
v	O
i	O
l	O
f	O
y	O
g	O
g	O
g	O
m	O
v	O
r	O
r	O
x	O
with	O
applied	O
element-wise	O
end	O
while	O
largely	O
on	O
the	O
user	O
s	O
familiarity	O
with	O
the	O
algorithm	O
ease	O
of	O
hyperparameter	O
tuning	O
approximate	O
second-order	O
methods	O
in	O
this	O
section	O
we	O
discuss	O
the	O
application	O
of	O
second-order	O
methods	O
to	O
the	O
training	O
of	O
deep	O
networks	O
see	O
for	O
an	O
earlier	O
treatment	O
of	O
this	O
subject	O
for	O
simplicity	O
of	O
exposition	O
the	O
only	O
objective	B
function	I
we	O
examine	O
is	O
the	O
empirical	B
risk	B
lecun	O
et	O
al	O
j	O
exy	O
pdata	O
l	O
f	O
x	O
y	O
m	O
m	O
l	O
f	O
y	O
however	O
the	O
methods	O
we	O
discuss	O
here	O
extend	O
readily	O
to	O
more	O
general	O
objective	O
functions	O
that	O
for	O
instance	O
include	O
parameter	O
regularization	O
terms	O
such	O
as	O
those	O
discussed	O
in	O
chapter	O
newton	O
s	O
method	O
we	O
introduced	O
second-order	O
gradient	B
methods	O
in	O
contrast	B
to	O
firstin	O
section	O
order	O
methods	O
second-order	O
methods	O
make	O
use	O
of	O
second	O
derivatives	O
to	O
improve	O
optimization	O
the	O
most	O
widely	O
used	O
second-order	O
method	O
is	O
newton	O
s	O
method	O
we	O
now	O
describe	O
newton	O
s	O
method	O
in	O
more	O
detail	O
with	O
emphasis	O
on	O
its	O
application	O
to	O
neural	B
network	I
training	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
algorithm	O
the	O
adam	O
algorithm	O
require	O
step	O
size	O
require	O
exponential	O
decay	O
rates	O
for	O
moment	O
estimates	O
and	O
in	O
default	O
defaults	O
and	O
respectively	O
require	O
small	O
constant	O
used	O
for	O
numerical	O
stabilization	O
default	O
require	O
initial	O
parameters	O
initialize	O
and	O
moment	O
variables	O
initialize	O
time	O
step	O
t	O
while	O
stopping	O
criterion	O
not	O
met	O
do	O
s	O
r	O
t	O
sample	O
a	O
minibatch	B
of	O
m	O
examples	O
from	O
the	O
training	O
set	O
corresponding	O
targets	O
y	O
compute	O
gradient	B
g	O
m	O
t	O
update	O
biased	O
first	O
moment	O
estimate	O
s	O
update	O
biased	O
second	O
moment	O
estimate	O
r	O
correct	O
bias	O
in	O
first	O
moment	O
s	O
correct	O
bias	O
in	O
second	O
moment	O
r	O
i	O
l	O
f	O
y	O
s	O
t	O
r	O
t	O
compute	O
update	O
apply	O
update	O
s	O
r	O
x	O
with	O
g	O
applied	O
element-wise	O
end	O
while	O
newton	O
s	O
method	O
is	O
an	O
optimization	O
scheme	O
based	O
on	O
using	O
a	O
second-order	O
taylor	O
series	O
expansion	O
to	O
approximate	O
j	O
near	O
some	O
point	O
ignoring	O
derivatives	O
of	O
higher	O
order	O
h	O
j	O
j	O
j	O
where	O
h	O
is	O
the	O
hessian	B
of	O
j	O
with	O
respect	O
to	O
evaluated	O
at	O
if	O
we	O
then	O
solve	O
for	O
the	O
critical	O
point	O
of	O
this	O
function	O
we	O
obtain	O
the	O
newton	O
parameter	O
update	O
rule	O
h	O
j	O
thus	O
for	O
a	O
locally	O
quadratic	O
function	O
positive	B
definite	I
h	O
by	O
rescaling	O
newton	O
s	O
method	O
jumps	O
directly	O
to	O
the	O
minimum	O
if	O
the	O
the	O
gradient	B
by	O
h	O
objective	B
function	I
is	O
convex	O
but	O
not	O
quadratic	O
are	O
higher-order	O
terms	O
this	O
update	O
can	O
be	O
iterated	O
yielding	O
the	O
training	O
algorithm	O
associated	O
with	O
newton	O
s	O
method	O
given	O
in	O
algorithm	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
newton	O
s	O
method	O
with	O
objective	O
j	O
m	O
l	O
f	O
y	O
algorithm	O
m	O
require	O
initial	O
parameter	O
require	O
training	O
set	O
of	O
while	O
stopping	O
criterion	O
not	O
met	O
compute	O
gradient	B
g	O
compute	O
hessian	B
h	O
compute	O
hessian	B
inverse	O
h	O
g	O
compute	O
update	O
h	O
apply	O
update	O
m	O
m	O
m	O
examples	O
do	O
i	O
l	O
f	O
y	O
i	O
l	O
f	O
y	O
end	O
while	O
for	O
surfaces	O
that	O
are	O
not	O
quadratic	O
as	O
long	O
as	O
the	O
hessian	B
remains	O
positive	B
definite	I
newton	O
s	O
method	O
can	O
be	O
applied	O
iteratively	O
this	O
implies	O
a	O
two-step	O
iterative	O
procedure	O
first	O
update	O
or	O
compute	O
the	O
inverse	O
hessian	B
by	O
updating	O
the	O
quadratic	O
approximation	O
second	O
update	O
the	O
parameters	O
according	O
to	O
equation	O
in	O
section	O
we	O
discussed	O
how	O
newton	O
s	O
method	O
is	O
appropriate	O
only	O
when	O
the	O
hessian	B
is	O
positive	B
definite	I
in	O
deep	O
learning	O
the	O
surface	O
of	O
the	O
objective	B
function	I
is	O
typically	O
non-convex	O
with	O
many	O
features	O
such	O
as	O
saddle	B
points	I
that	O
are	O
problematic	O
for	O
newton	O
s	O
method	O
if	O
the	O
eigenvalues	O
of	O
the	O
hessian	B
are	O
not	O
all	O
positive	O
for	O
example	B
near	O
a	O
saddle	O
point	O
then	O
newton	O
s	O
method	O
can	O
actually	O
cause	O
updates	O
to	O
move	O
in	O
the	O
wrong	O
direction	O
this	O
situation	O
can	O
be	O
avoided	O
by	O
regularizing	O
the	O
hessian	B
common	O
regularization	O
strategies	O
include	O
adding	O
a	O
constant	O
along	O
the	O
diagonal	O
of	O
the	O
hessian	B
the	O
regularized	O
update	O
becomes	O
f	O
i	O
f	O
this	O
regularization	O
strategy	O
is	O
used	O
in	O
approximations	O
to	O
newton	O
s	O
method	O
such	O
as	O
the	O
levenberg	O
marquardt	O
algorithm	O
marquardt	O
and	O
works	O
fairly	O
well	O
as	O
long	O
as	O
the	O
negative	O
eigenvalues	O
of	O
the	O
hessian	B
are	O
still	O
relatively	O
close	O
to	O
zero	O
in	O
cases	O
where	O
there	O
are	O
more	O
extreme	O
directions	O
of	O
curvature	O
the	O
value	O
of	O
would	O
have	O
to	O
be	O
sufficiently	O
large	O
to	O
offset	O
the	O
negative	O
eigenvalues	O
however	O
as	O
increases	O
in	O
size	O
the	O
hessian	B
becomes	O
dominated	O
by	O
the	O
i	O
diagonal	O
and	O
the	O
direction	O
chosen	O
by	O
newton	O
s	O
method	O
converges	O
to	O
the	O
standard	O
gradient	B
divided	O
by	O
when	O
strong	O
negative	O
curvature	O
is	O
present	O
may	O
need	O
to	O
be	O
so	O
large	O
that	O
newton	O
s	O
method	O
would	O
make	O
smaller	O
steps	O
than	O
gradient	B
descent	O
with	O
a	O
properly	O
chosen	O
learning	B
rate	I
beyond	O
the	O
challenges	O
created	O
by	O
certain	O
features	O
of	O
the	O
objective	B
function	I
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
such	O
as	O
saddle	B
points	I
the	O
application	O
of	O
newton	O
s	O
method	O
for	O
training	O
large	O
neural	O
networks	O
is	O
limited	O
by	O
the	O
significant	O
computational	O
burden	O
it	O
imposes	O
the	O
number	O
of	O
elements	O
in	O
the	O
hessian	B
is	O
squared	O
in	O
the	O
number	O
of	O
parameters	O
so	O
with	O
k	O
parameters	O
for	O
even	O
very	O
small	O
neural	O
networks	O
the	O
number	O
of	O
parameters	O
k	O
can	O
be	O
in	O
the	O
millions	O
newton	O
s	O
method	O
would	O
require	O
the	O
inversion	O
of	O
a	O
k	O
k	O
matrix	O
with	O
computational	O
complexity	O
of	O
also	O
since	O
the	O
parameters	O
will	O
change	O
with	O
every	O
update	O
the	O
inverse	O
hessian	B
has	O
to	O
be	O
computed	O
at	O
every	O
training	O
iteration	O
as	O
a	O
consequence	O
only	O
networks	O
with	O
a	O
very	O
small	O
number	O
of	O
parameters	O
can	O
be	O
practically	O
trained	O
via	O
newton	O
s	O
method	O
in	O
the	O
remainder	O
of	O
this	O
section	O
we	O
will	O
discuss	O
alternatives	O
that	O
attempt	O
to	O
gain	O
some	O
of	O
the	O
advantages	O
of	O
newton	O
s	O
method	O
while	O
side-stepping	O
the	O
computational	O
hurdles	O
conjugate	O
gradients	O
conjugate	O
gradients	O
is	O
a	O
method	O
to	O
efficiently	O
avoid	O
the	O
calculation	O
of	O
the	O
inverse	O
hessian	B
by	O
iteratively	O
descending	O
conjugate	O
directions	O
the	O
inspiration	O
for	O
this	O
approach	O
follows	O
from	O
a	O
careful	O
study	O
of	O
the	O
weakness	O
of	O
the	O
method	O
of	O
steepest	O
for	O
details	O
where	O
line	O
searches	O
are	O
applied	O
iteratively	O
in	O
descent	O
section	O
the	O
direction	O
associated	O
with	O
the	O
gradient	B
figure	O
illustrates	O
how	O
the	O
method	O
of	O
steepest	O
descent	O
when	O
applied	O
in	O
a	O
quadratic	O
bowl	O
progresses	O
in	O
a	O
rather	O
ineffective	O
back-and-forth	O
zig-zag	O
pattern	O
this	O
happens	O
because	O
each	O
line	O
search	O
direction	O
when	O
given	O
by	O
the	O
gradient	B
is	O
guaranteed	O
to	O
be	O
orthogonal	O
to	O
the	O
previous	O
line	O
search	O
direction	O
let	O
the	O
previous	O
search	O
direction	O
be	O
dt	O
at	O
the	O
minimum	O
where	O
the	O
line	O
j	O
search	O
terminates	O
the	O
directional	B
derivative	B
is	O
zero	O
in	O
direction	O
dt	O
dt	O
since	O
the	O
gradient	B
at	O
this	O
point	O
defines	O
the	O
current	O
search	O
direction	O
thus	O
dt	O
is	O
orthogonal	O
j	O
will	O
have	O
no	O
contribution	O
in	O
the	O
direction	O
dt	O
dt	O
to	O
dt	O
this	O
relationship	O
between	O
dt	O
for	O
and	O
d	O
t	O
is	O
illustrated	O
in	O
figure	O
multiple	O
iterations	O
of	O
steepest	O
descent	O
as	O
demonstrated	O
in	O
the	O
figure	O
the	O
choice	O
of	O
orthogonal	O
directions	O
of	O
descent	O
do	O
not	O
preserve	O
the	O
minimum	O
along	O
the	O
previous	O
search	O
directions	O
this	O
gives	O
rise	O
to	O
the	O
zig-zag	O
pattern	O
of	O
progress	O
where	O
by	O
descending	O
to	O
the	O
minimum	O
in	O
the	O
current	O
gradient	B
direction	O
we	O
must	O
re-minimize	O
the	O
objective	O
in	O
the	O
previous	O
gradient	B
direction	O
thus	O
by	O
following	O
the	O
gradient	B
at	O
the	O
end	O
of	O
each	O
line	O
search	O
we	O
are	O
in	O
a	O
sense	O
undoing	O
progress	O
we	O
have	O
already	O
made	O
in	O
the	O
direction	O
of	O
the	O
previous	O
line	O
search	O
the	O
method	O
of	O
conjugate	O
gradients	O
seeks	O
to	O
address	O
this	O
problem	O
in	O
the	O
method	O
of	O
conjugate	O
gradients	O
we	O
seek	O
to	O
find	O
a	O
search	O
direction	O
that	O
is	O
conjugate	O
to	O
the	O
previous	O
line	O
search	O
direction	O
i	O
e	O
it	O
will	O
not	O
undo	O
progress	O
made	O
in	O
that	O
direction	O
at	O
training	O
iteration	O
t	O
the	O
next	O
search	O
direction	O
dt	O
takes	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
figure	O
the	O
method	O
of	O
steepest	O
descent	O
applied	O
to	O
a	O
quadratic	O
cost	O
surface	O
the	O
method	O
of	O
steepest	O
descent	O
involves	O
jumping	O
to	O
the	O
point	O
of	O
lowest	O
cost	O
along	O
the	O
line	O
defined	O
by	O
the	O
gradient	B
at	O
the	O
initial	O
point	O
on	O
each	O
step	O
this	O
resolves	O
some	O
of	O
the	O
problems	O
seen	O
with	O
using	O
a	O
fixed	O
learning	B
rate	I
in	O
figure	O
but	O
even	O
with	O
the	O
optimal	O
step	O
size	O
the	O
algorithm	O
still	O
makes	O
back-and-forth	O
progress	O
toward	O
the	O
optimum	O
by	O
definition	O
at	O
the	O
minimum	O
of	O
the	O
objective	O
along	O
a	O
given	O
direction	O
the	O
gradient	B
at	O
the	O
final	O
point	O
is	O
orthogonal	O
to	O
that	O
direction	O
the	O
form	O
j	O
dt	O
tdt	O
where	O
t	O
is	O
a	O
coefficient	O
whose	O
magnitude	O
controls	O
how	O
much	O
of	O
the	O
direction	O
dt	O
we	O
should	O
add	O
back	O
to	O
the	O
current	O
search	O
direction	O
two	O
directions	O
dt	O
and	O
dt	O
are	O
defined	O
as	O
conjugate	O
if	O
d	O
t	O
hdt	O
where	O
h	O
is	O
the	O
hessian	B
matrix	O
the	O
straightforward	O
way	O
to	O
impose	O
conjugacy	O
would	O
involve	O
calculation	O
of	O
the	O
eigenvectors	O
of	O
h	O
to	O
choose	O
t	O
which	O
would	O
not	O
satisfy	O
our	O
goal	O
of	O
developing	O
a	O
method	O
that	O
is	O
more	O
computationally	O
viable	O
than	O
newton	O
s	O
method	O
for	O
large	O
problems	O
can	O
we	O
calculate	O
the	O
conjugate	O
directions	O
without	O
resorting	O
to	O
these	O
calculations	O
fortunately	O
the	O
answer	O
to	O
that	O
is	O
yes	O
two	O
popular	O
methods	O
for	O
computing	O
the	O
t	O
are	O
fletcher-reeves	O
j	O
t	O
j	O
t	O
j	O
t	O
j	O
t	O
t	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
polak-ribi	O
re	O
j	O
t	O
j	O
t	O
j	O
t	O
j	O
t	O
j	O
t	O
t	O
for	O
a	O
quadratic	O
surface	O
the	O
conjugate	O
directions	O
ensure	O
that	O
the	O
gradient	B
along	O
the	O
previous	O
direction	O
does	O
not	O
increase	O
in	O
magnitude	O
we	O
therefore	O
stay	O
at	O
the	O
minimum	O
along	O
the	O
previous	O
directions	O
as	O
a	O
consequence	O
in	O
a	O
k-dimensional	O
parameter	O
space	O
the	O
conjugate	O
gradient	B
method	O
requires	O
at	O
most	O
k	O
line	O
searches	O
to	O
achieve	O
the	O
minimum	O
the	O
conjugate	O
gradient	B
algorithm	O
is	O
given	O
in	O
algorithm	O
algorithm	O
the	O
conjugate	O
gradient	B
method	O
require	O
initial	O
parameters	O
require	O
training	O
set	O
of	O
examples	O
m	O
do	O
t	O
g	O
gt	O
m	O
re	O
i	O
l	O
f	O
y	O
stopping	O
criterion	O
not	O
met	O
initialize	O
the	O
gradient	B
gt	O
compute	O
gradient	B
gt	O
compute	O
t	O
t	O
gt	O
t	O
conjugate	O
gradient	B
optionally	O
reset	O
t	O
to	O
zero	O
for	O
example	B
if	O
t	O
is	O
a	O
multiple	O
of	O
some	O
constant	O
such	O
as	O
k	O
k	O
gt	O
t	O
t	O
compute	O
search	O
direction	O
t	O
perform	O
line	O
search	O
to	O
find	O
m	O
a	O
truly	O
quadratic	O
cost	O
function	O
analytically	O
solve	O
for	O
explicitly	O
searching	O
for	O
it	O
apply	O
update	O
t	O
t	O
m	O
l	O
f	O
t	O
t	O
y	O
argmin	O
rather	O
than	O
initialize	O
initialize	O
initialize	O
t	O
while	O
t	O
end	O
while	O
nonlinear	O
conjugate	O
gradients	O
so	O
far	O
we	O
have	O
discussed	O
the	O
method	O
of	O
conjugate	O
gradients	O
as	O
it	O
is	O
applied	O
to	O
quadratic	O
objective	O
functions	O
of	O
course	O
our	O
primary	O
interest	O
in	O
this	O
chapter	O
is	O
to	O
explore	O
optimization	O
methods	O
for	O
training	O
neural	O
networks	O
and	O
other	O
related	O
deep	O
learning	O
models	O
where	O
the	O
corresponding	O
objective	B
function	I
is	O
far	O
from	O
quadratic	O
perhaps	O
surprisingly	O
the	O
method	O
of	O
conjugate	O
gradients	O
is	O
still	O
applicable	O
in	O
this	O
setting	O
though	O
with	O
some	O
modification	O
without	O
any	O
assurance	O
that	O
the	O
objective	O
is	O
quadratic	O
the	O
conjugate	O
directions	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
are	O
no	O
longer	O
assured	O
to	O
remain	O
at	O
the	O
minimum	O
of	O
the	O
objective	O
for	O
previous	O
directions	O
as	O
a	O
result	O
the	O
nonlinear	O
conjugate	O
gradients	O
algorithm	O
includes	O
occasional	O
resets	O
where	O
the	O
method	O
of	O
conjugate	O
gradients	O
is	O
restarted	O
with	O
line	O
search	O
along	O
the	O
unaltered	O
gradient	B
practitioners	O
report	O
reasonable	O
results	O
in	O
applications	O
of	O
the	O
nonlinear	O
conjugate	O
gradients	O
algorithm	O
to	O
training	O
neural	O
networks	O
though	O
it	O
is	O
often	O
beneficial	O
to	O
initialize	O
the	O
optimization	O
with	O
a	O
few	O
iterations	O
of	O
stochastic	O
gradient	B
descent	O
before	O
commencing	O
nonlinear	O
conjugate	O
gradients	O
also	O
while	O
the	O
conjugate	O
gradients	O
algorithm	O
has	O
traditionally	O
been	O
cast	O
as	O
a	O
batch	O
method	O
minibatch	B
versions	O
have	O
been	O
used	O
successfully	O
for	O
the	O
training	O
of	O
neural	O
networks	O
le	O
et	O
al	O
adaptations	O
of	O
conjugate	O
gradients	O
specifically	O
for	O
neural	O
networks	O
have	O
been	O
proposed	O
earlier	O
such	O
as	O
the	O
scaled	O
conjugate	O
gradients	O
algorithm	O
moller	O
bfgs	B
the	O
broyden	O
fletcher	O
goldfarb	O
shanno	O
algorithm	O
attempts	O
to	O
bring	O
some	O
of	O
the	O
advantages	O
of	O
newton	O
s	O
method	O
without	O
the	O
computational	O
burden	O
in	O
that	O
respect	O
bfgs	B
is	O
similar	O
to	O
the	O
conjugate	O
gradient	B
method	O
however	O
bfgs	B
takes	O
a	O
more	O
direct	O
approach	O
to	O
the	O
approximation	O
of	O
newton	O
s	O
update	O
recall	B
that	O
newton	O
s	O
update	O
is	O
given	O
by	O
h	O
j	O
where	O
h	O
is	O
the	O
hessian	B
of	O
j	O
with	O
respect	O
to	O
evaluated	O
at	O
the	O
primary	O
computational	O
difficulty	O
in	O
applying	O
newton	O
s	O
update	O
is	O
the	O
calculation	O
of	O
the	O
the	O
approach	O
adopted	O
by	O
quasi-newton	O
methods	O
which	O
inverse	O
hessian	B
h	O
the	O
bfgs	B
algorithm	O
is	O
the	O
most	O
prominent	O
is	O
to	O
approximate	O
the	O
inverse	O
with	O
a	O
matrix	O
mt	O
that	O
is	O
iteratively	O
refined	O
by	O
low	O
rank	O
updates	O
to	O
become	O
a	O
better	O
approximation	O
of	O
h	O
the	O
specification	O
and	O
derivation	O
of	O
the	O
bfgs	B
approximation	O
is	O
given	O
in	O
many	O
textbooks	O
on	O
optimization	O
including	O
luenberger	O
once	O
the	O
inverse	O
hessian	B
approximation	O
mt	O
is	O
updated	O
the	O
direction	O
of	O
descent	O
t	O
is	O
determined	O
by	O
t	O
mtgt	O
a	O
line	O
search	O
is	O
performed	O
in	O
this	O
direction	O
to	O
determine	O
the	O
size	O
of	O
the	O
step	O
taken	O
in	O
this	O
direction	O
the	O
final	O
update	O
to	O
the	O
parameters	O
is	O
given	O
by	O
t	O
t	O
like	O
the	O
method	O
of	O
conjugate	O
gradients	O
the	O
bfgs	B
algorithm	O
iterates	O
a	O
series	O
of	O
line	O
searches	O
with	O
the	O
direction	O
incorporating	O
second-order	O
information	O
however	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
unlike	O
conjugate	O
gradients	O
the	O
success	O
of	O
the	O
approach	O
is	O
not	O
heavily	O
dependent	O
on	O
the	O
line	O
search	O
finding	O
a	O
point	O
very	O
close	O
to	O
the	O
true	O
minimum	O
along	O
the	O
line	O
thus	O
relative	O
to	O
conjugate	O
gradients	O
bfgs	B
has	O
the	O
advantage	O
that	O
it	O
can	O
spend	O
less	O
time	O
refining	O
each	O
line	O
search	O
on	O
the	O
other	O
hand	O
the	O
bfgs	B
algorithm	O
must	O
store	O
the	O
inverse	O
hessian	B
matrix	O
m	O
that	O
requires	O
memory	O
making	O
bfgs	B
impractical	O
for	O
most	O
modern	O
deep	O
learning	O
models	O
that	O
typically	O
have	O
millions	O
of	O
parameters	O
limited	O
memory	O
bfgs	B
l-bfgs	O
the	O
memory	O
costs	O
of	O
the	O
bfgs	B
algorithm	O
can	O
be	O
significantly	O
decreased	O
by	O
avoiding	O
storing	O
the	O
complete	O
inverse	O
hessian	B
approximation	O
m	O
the	O
l-bfgs	O
algorithm	O
computes	O
the	O
approximation	O
m	O
using	O
the	O
same	O
method	O
as	O
the	O
bfgs	B
algorithm	O
but	O
beginning	O
with	O
the	O
assumption	O
t	O
that	O
m	O
is	O
the	O
identity	B
matrix	I
rather	O
than	O
storing	O
the	O
approximation	O
from	O
one	O
step	O
to	O
the	O
next	O
if	O
used	O
with	O
exact	O
line	O
searches	O
the	O
directions	O
defined	O
by	O
l-bfgs	O
are	O
mutually	O
conjugate	O
however	O
unlike	O
the	O
method	O
of	O
conjugate	O
gradients	O
this	O
procedure	O
remains	O
well	O
behaved	O
when	O
the	O
minimum	O
of	O
the	O
line	O
search	O
is	O
reached	O
only	O
approximately	O
the	O
l-bfgs	O
strategy	O
with	O
no	O
storage	O
described	O
here	O
can	O
be	O
generalized	O
to	O
include	O
more	O
information	O
about	O
the	O
hessian	B
by	O
storing	O
some	O
of	O
the	O
vectors	O
used	O
to	O
update	O
at	O
each	O
time	O
step	O
which	O
costs	O
only	O
per	O
step	O
m	O
o	O
n	O
optimization	O
strategies	O
and	O
meta-algorithms	O
many	O
optimization	O
techniques	O
are	O
not	O
exactly	O
algorithms	O
but	O
rather	O
general	O
templates	O
that	O
can	O
be	O
specialized	O
to	O
yield	O
algorithms	O
or	O
subroutines	O
that	O
can	O
be	O
incorporated	O
into	O
many	O
different	O
algorithms	O
batch	O
normalization	O
ioffe	O
and	O
szegedy	O
batch	O
normalization	O
is	O
one	O
of	O
the	O
most	O
exciting	O
recent	O
innovations	O
in	O
optimizing	O
deep	O
neural	O
networks	O
and	O
it	O
is	O
actually	O
not	O
an	O
optimization	O
algorithm	O
at	O
all	O
instead	O
it	O
is	O
a	O
method	O
of	O
adaptive	O
reparametrization	O
motivated	O
by	O
the	O
difficulty	O
of	O
training	O
very	O
deep	O
models	O
very	O
deep	O
models	O
involve	O
the	O
composition	O
of	O
several	O
functions	O
or	O
layers	O
the	O
gradient	B
tells	O
how	O
to	O
update	O
each	O
parameter	O
under	O
the	O
assumption	O
that	O
the	O
other	O
layers	O
do	O
not	O
change	O
in	O
practice	O
we	O
update	O
all	O
of	O
the	O
layers	O
simultaneously	O
when	O
we	O
make	O
the	O
update	O
unexpected	O
results	O
can	O
happen	O
because	O
many	O
functions	O
composed	O
together	O
are	O
changed	O
simultaneously	O
using	O
updates	O
that	O
were	O
computed	O
under	O
the	O
assumption	O
that	O
the	O
other	O
functions	O
remain	O
constant	O
as	O
a	O
simple	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
example	B
suppose	O
we	O
have	O
a	O
deep	O
neural	B
network	I
that	O
has	O
only	O
one	O
unit	O
per	O
layer	O
and	O
does	O
not	O
use	O
an	O
activation	B
function	I
at	O
each	O
hidden	B
layer	I
y	O
wl	O
here	O
wi	O
provides	O
the	O
weight	O
used	O
by	O
layer	O
i	O
the	O
output	O
of	O
layer	O
i	O
is	O
h	O
i	O
hi	O
the	O
output	O
y	O
is	O
a	O
linear	O
function	O
of	O
the	O
input	O
x	O
but	O
a	O
nonlinear	O
function	O
of	O
the	O
y	O
so	O
we	O
wish	O
to	O
weights	B
wi	O
suppose	O
our	O
cost	O
function	O
has	O
put	O
a	O
gradient	B
of	O
decrease	O
y	O
slightly	O
the	O
back-propagation	B
algorithm	O
can	O
then	O
compute	O
a	O
gradient	B
g	O
w	O
y	O
consider	O
what	O
happens	O
when	O
we	O
make	O
an	O
update	O
w	O
w	O
the	O
g	O
first-order	O
taylor	O
series	O
approximation	O
of	O
y	O
predicts	O
that	O
the	O
value	O
of	O
y	O
will	O
decrease	O
g	O
if	O
we	O
wanted	O
to	O
decrease	O
y	O
by	O
this	O
first-order	O
information	O
available	O
in	O
by	O
g	O
the	O
gradient	B
suggests	O
we	O
could	O
set	O
the	O
learning	B
rate	I
to	O
however	O
the	O
actual	O
g	O
update	O
will	O
include	O
second-order	O
and	O
third-order	O
effects	O
on	O
up	O
to	O
effects	O
of	O
order	O
l	O
the	O
new	O
value	O
of	O
y	O
is	O
given	O
by	O
g	O
x	O
w	O
g	O
wl	O
gl	O
through	O
l	O
an	O
example	B
of	O
one	O
second-order	O
term	O
arising	O
from	O
this	O
update	O
is	O
wi	O
l	O
i	O
is	O
small	O
or	O
might	O
be	O
exponentially	O
large	O
this	O
term	O
might	O
be	O
negligible	O
if	O
l	O
are	O
greater	O
than	O
this	O
makes	O
it	O
very	O
hard	O
if	O
the	O
weights	B
on	O
layers	O
to	O
choose	O
an	O
appropriate	O
learning	B
rate	I
because	O
the	O
effects	O
of	O
an	O
update	O
to	O
the	O
parameters	O
for	O
one	O
layer	O
depends	O
so	O
strongly	O
on	O
all	O
of	O
the	O
other	O
layers	O
second-order	O
optimization	O
algorithms	O
address	O
this	O
issue	O
by	O
computing	O
an	O
update	O
that	O
takes	O
these	O
second-order	O
interactions	O
into	O
account	O
but	O
we	O
can	O
see	O
that	O
in	O
very	O
deep	O
networks	O
even	O
higher-order	O
interactions	O
can	O
be	O
significant	O
even	O
second-order	O
optimization	O
algorithms	O
are	O
expensive	O
and	O
usually	O
require	O
numerous	O
approximations	O
that	O
prevent	O
them	O
from	O
truly	O
accounting	O
for	O
all	O
significant	O
second-order	O
interactions	O
building	O
an	O
n-th	O
order	O
optimization	O
algorithm	O
for	O
n	O
thus	O
seems	O
hopeless	O
what	O
can	O
we	O
do	O
instead	O
batch	O
normalization	O
provides	O
an	O
elegant	O
way	O
of	O
reparametrizing	O
almost	O
any	O
deep	O
network	O
the	O
reparametrization	O
significantly	O
reduces	O
the	O
problem	O
of	O
coordinating	O
updates	O
across	O
many	O
layers	O
batch	O
normalization	O
can	O
be	O
applied	O
to	O
any	O
input	O
or	O
hidden	B
layer	I
in	O
a	O
network	O
let	O
h	O
be	O
a	O
minibatch	B
of	O
activations	O
of	O
the	O
layer	O
to	O
normalize	O
arranged	O
as	O
a	O
design	B
matrix	I
with	O
the	O
activations	O
for	O
each	O
example	B
appearing	O
in	O
a	O
row	O
of	O
the	O
matrix	O
to	O
normalize	O
we	O
replace	O
it	O
with	O
h	O
h	O
h	O
where	O
is	O
a	O
vector	O
containing	O
the	O
mean	O
of	O
each	O
unit	O
and	O
is	O
a	O
vector	O
containing	O
the	O
standard	B
deviation	I
of	O
each	O
unit	O
the	O
arithmetic	O
here	O
is	O
based	O
on	O
broadcasting	B
the	O
vector	O
and	O
the	O
vector	O
to	O
be	O
applied	O
to	O
every	O
row	O
of	O
the	O
matrix	O
h	O
within	O
each	O
row	O
the	O
arithmetic	O
is	O
element-wise	O
so	O
hij	O
is	O
normalized	O
by	O
subtracting	O
j	O
at	O
training	O
time	O
and	O
i	O
m	O
m	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
and	O
dividing	O
by	O
j	O
the	O
rest	O
of	O
the	O
network	O
then	O
operates	O
on	O
h	O
same	O
way	O
that	O
the	O
original	O
network	O
operated	O
on	O
in	O
exactly	O
the	O
hi	O
h	O
i	O
i	O
imposed	O
to	O
avoid	O
encountering	O
where	O
is	O
a	O
small	O
positive	O
value	O
such	O
as	O
z	O
at	O
z	O
crucially	O
we	O
back-propagate	O
through	O
the	O
undefined	O
gradient	B
of	O
these	O
operations	O
for	O
computing	O
the	O
mean	O
and	O
the	O
standard	B
deviation	I
and	O
for	O
applying	O
them	O
to	O
normalize	O
h	O
this	O
means	O
that	O
the	O
gradient	B
will	O
never	O
propose	O
an	O
operation	B
that	O
acts	O
simply	O
to	O
increase	O
the	O
standard	B
deviation	I
or	O
mean	O
of	O
hi	O
the	O
normalization	O
operations	O
remove	O
the	O
effect	O
of	O
such	O
an	O
action	O
and	O
zero	O
out	O
its	O
component	O
in	O
the	O
gradient	B
this	O
was	O
a	O
major	O
innovation	O
of	O
the	O
batch	O
normalization	O
approach	O
previous	O
approaches	O
had	O
involved	O
adding	O
penalties	O
to	O
the	O
cost	O
function	O
to	O
encourage	O
units	O
to	O
have	O
normalized	O
activation	O
statistics	O
or	O
involved	O
intervening	O
to	O
renormalize	O
unit	O
statistics	O
after	O
each	O
gradient	B
descent	O
step	O
the	O
former	O
approach	O
usually	O
resulted	O
in	O
imperfect	O
normalization	O
and	O
the	O
latter	O
usually	O
resulted	O
in	O
significant	O
wasted	O
time	O
as	O
the	O
learning	O
algorithm	O
repeatedly	O
proposed	O
changing	O
the	O
mean	O
and	O
variance	O
and	O
the	O
normalization	O
step	O
repeatedly	O
undid	O
this	O
change	O
batch	O
normalization	O
reparametrizes	O
the	O
model	O
to	O
make	O
some	O
units	O
always	O
be	O
standardized	O
by	O
definition	O
deftly	O
sidestepping	O
both	O
problems	O
at	O
test	O
time	O
and	O
may	O
be	O
replaced	O
by	O
running	O
averages	O
that	O
were	O
collected	O
during	O
training	O
time	O
this	O
allows	O
the	O
model	O
to	O
be	O
evaluated	O
on	O
a	O
single	O
example	B
without	O
needing	O
to	O
use	O
definitions	O
of	O
and	O
that	O
depend	O
on	O
an	O
entire	O
minibatch	B
revisiting	O
the	O
y	O
wl	O
example	B
we	O
see	O
that	O
we	O
can	O
mostly	O
resolve	O
the	O
difficulties	O
in	O
learning	O
this	O
model	O
by	O
normalizing	O
hl	O
suppose	O
that	O
x	O
is	O
drawn	O
from	O
a	O
unit	O
gaussian	O
then	O
hl	O
will	O
also	O
come	O
from	O
a	O
gaussian	O
because	O
the	O
transformation	O
from	O
x	O
to	O
hl	O
is	O
linear	O
however	O
h	O
l	O
will	O
no	O
longer	O
have	O
zero	O
mean	O
and	O
unit	O
variance	O
after	O
applying	O
batch	O
normalization	O
we	O
obtain	O
the	O
normalized	O
hl	O
that	O
restores	O
the	O
zero	O
mean	O
and	O
unit	O
variance	O
properties	O
for	O
almost	O
any	O
update	O
to	O
the	O
lower	O
layers	O
hl	O
will	O
remain	O
a	O
unit	O
gaussian	O
the	O
output	O
y	O
may	O
h	O
l	O
then	O
be	O
learned	O
as	O
a	O
simple	O
linear	O
function	O
y	O
wl	O
learning	O
in	O
this	O
model	O
is	O
now	O
very	O
simple	O
because	O
the	O
parameters	O
at	O
the	O
lower	O
layers	O
simply	O
do	O
not	O
have	O
an	O
effect	O
in	O
most	O
cases	O
their	O
output	O
is	O
always	O
renormalized	O
to	O
a	O
unit	O
gaussian	O
in	O
some	O
corner	O
cases	O
the	O
lower	O
layers	O
can	O
have	O
an	O
effect	O
changing	O
one	O
of	O
the	O
lower	O
can	O
make	O
the	O
output	O
become	O
degenerate	O
and	O
changing	O
the	O
sign	O
layer	O
weights	B
to	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
of	O
one	O
of	O
the	O
lower	O
weights	B
can	O
flip	O
the	O
relationship	O
between	O
hl	O
and	O
y	O
these	O
situations	O
are	O
very	O
rare	O
without	O
normalization	O
nearly	O
every	O
update	O
would	O
have	O
an	O
extreme	O
effect	O
on	O
the	O
statistics	O
of	O
hl	O
batch	O
normalization	O
has	O
thus	O
made	O
this	O
model	O
significantly	O
easier	O
to	O
learn	O
in	O
this	O
example	B
the	O
ease	O
of	O
learning	O
of	O
course	O
came	O
at	O
the	O
cost	O
of	O
making	O
the	O
lower	O
layers	O
useless	O
in	O
our	O
linear	O
example	B
the	O
lower	O
layers	O
no	O
longer	O
have	O
any	O
harmful	O
effect	O
but	O
they	O
also	O
no	O
longer	O
have	O
any	O
beneficial	O
effect	O
this	O
is	O
because	O
we	O
have	O
normalized	O
out	O
the	O
first	O
and	O
second	O
order	O
statistics	O
which	O
is	O
all	O
that	O
a	O
linear	O
network	O
can	O
influence	O
in	O
a	O
deep	O
neural	B
network	I
with	O
nonlinear	O
activation	O
functions	O
the	O
lower	O
layers	O
can	O
perform	O
nonlinear	O
transformations	O
of	O
the	O
data	O
so	O
they	O
remain	O
useful	O
batch	O
normalization	O
acts	O
to	O
standardize	O
only	O
the	O
mean	O
and	O
variance	O
of	O
each	O
unit	O
in	O
order	O
to	O
stabilize	O
learning	O
but	O
allows	O
the	O
relationships	O
between	O
units	O
and	O
the	O
nonlinear	O
statistics	O
of	O
a	O
single	O
unit	O
to	O
change	O
because	O
the	O
final	O
layer	O
of	O
the	O
network	O
is	O
able	O
to	O
learn	O
a	O
linear	O
transformation	O
we	O
may	O
actually	O
wish	O
to	O
remove	O
all	O
linear	O
relationships	O
between	O
units	O
within	O
a	O
layer	O
indeed	O
this	O
is	O
the	O
approach	O
taken	O
by	O
who	O
provided	O
the	O
inspiration	O
for	O
batch	O
normalization	O
unfortunately	O
eliminating	O
all	O
linear	O
interactions	O
is	O
much	O
more	O
expensive	O
than	O
standardizing	O
the	O
mean	O
and	O
standard	B
deviation	I
of	O
each	O
individual	O
unit	O
and	O
so	O
far	O
batch	O
normalization	O
remains	O
the	O
most	O
practical	O
approach	O
desjardins	O
et	O
al	O
rather	O
than	O
simply	O
the	O
normalized	O
h	O
normalizing	O
the	O
mean	O
and	O
standard	B
deviation	I
of	O
a	O
unit	O
can	O
reduce	O
the	O
expressive	O
power	O
of	O
the	O
neural	B
network	I
containing	O
that	O
unit	O
in	O
order	O
to	O
maintain	O
the	O
expressive	O
power	O
of	O
the	O
network	O
it	O
is	O
common	O
to	O
replace	O
the	O
batch	O
of	O
hidden	O
unit	O
activations	O
h	O
with	O
h	O
the	O
variables	O
and	O
are	O
learned	O
parameters	O
that	O
allow	O
the	O
new	O
variable	O
to	O
have	O
any	O
mean	O
and	O
standard	B
deviation	I
at	O
first	O
glance	O
this	O
may	O
seem	O
useless	O
why	O
did	O
we	O
set	O
the	O
mean	O
to	O
and	O
then	O
introduce	O
a	O
parameter	O
that	O
allows	O
it	O
to	O
be	O
set	O
back	O
to	O
any	O
arbitrary	O
value	O
the	O
answer	O
is	O
that	O
the	O
new	O
parametrization	O
can	O
represent	O
the	O
same	O
family	O
of	O
functions	O
of	O
the	O
input	O
as	O
the	O
old	O
parametrization	O
but	O
the	O
new	O
parametrization	O
has	O
different	O
learning	O
dynamics	O
in	O
the	O
old	O
parametrization	O
the	O
mean	O
of	O
h	O
was	O
determined	O
by	O
a	O
complicated	O
interaction	O
between	O
the	O
parameters	O
in	O
the	O
layers	O
below	O
h	O
in	O
the	O
new	O
parametrization	O
the	O
mean	O
of	O
h	O
is	O
determined	O
solely	O
by	O
the	O
new	O
parametrization	O
is	O
much	O
easier	O
to	O
learn	O
with	O
gradient	B
descent	O
most	O
neural	B
network	I
layers	O
take	O
the	O
form	O
of	O
b	O
where	O
is	O
some	O
fixed	O
nonlinear	O
activation	B
function	I
such	O
as	O
the	O
rectified	O
linear	O
transformation	O
it	O
is	O
natural	O
to	O
wonder	O
whether	O
we	O
should	O
apply	O
batch	O
normalization	O
to	O
the	O
input	O
x	O
or	O
to	O
the	O
transformed	O
value	O
xw	O
b	O
recommend	O
ioffe	O
and	O
szegedy	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
the	O
latter	O
more	O
specifically	O
xw	O
b	O
should	O
be	O
replaced	O
by	O
a	O
normalized	O
version	O
of	O
xw	O
the	O
bias	O
term	O
should	O
be	O
omitted	O
because	O
it	O
becomes	O
redundant	O
with	O
the	O
parameter	O
applied	O
by	O
the	O
batch	O
normalization	O
reparametrization	O
the	O
input	O
to	O
a	O
layer	O
is	O
usually	O
the	O
output	O
of	O
a	O
nonlinear	O
activation	B
function	I
such	O
as	O
the	O
rectified	O
linear	O
function	O
in	O
a	O
previous	O
layer	O
the	O
statistics	O
of	O
the	O
input	O
are	O
thus	O
more	O
non-gaussian	O
and	O
less	O
amenable	O
to	O
standardization	O
by	O
linear	O
operations	O
in	O
convolutional	O
networks	O
described	O
in	O
chapter	O
it	O
is	O
important	O
to	O
apply	O
the	O
same	O
normalizing	O
and	O
at	O
every	O
spatial	O
location	O
within	O
a	O
feature	B
map	O
so	O
that	O
the	O
statistics	O
of	O
the	O
feature	B
map	O
remain	O
the	O
same	O
regardless	O
of	O
spatial	O
location	O
coordinate	O
descent	O
in	O
some	O
cases	O
it	O
may	O
be	O
possible	O
to	O
solve	O
an	O
optimization	O
problem	O
quickly	O
by	O
breaking	O
it	O
into	O
separate	O
pieces	O
if	O
we	O
minimize	O
fx	O
with	O
respect	O
to	O
a	O
single	O
variable	O
xi	O
then	O
minimize	O
it	O
with	O
respect	O
to	O
another	O
variable	O
xj	O
and	O
so	O
on	O
repeatedly	O
cycling	O
through	O
all	O
variables	O
we	O
are	O
guaranteed	O
to	O
arrive	O
at	O
a	O
minimum	O
this	O
practice	O
is	O
known	O
as	O
coordinate	O
descent	O
because	O
we	O
optimize	O
one	O
coordinate	O
at	O
a	O
time	O
more	O
generally	O
block	O
coordinate	O
descent	O
refers	O
to	O
minimizing	O
with	O
respect	O
to	O
a	O
subset	O
of	O
the	O
variables	O
simultaneously	O
the	O
term	O
coordinate	O
descent	O
is	O
often	O
used	O
to	O
refer	O
to	O
block	O
coordinate	O
descent	O
as	O
well	O
as	O
the	O
strictly	O
individual	O
coordinate	O
descent	O
coordinate	O
descent	O
makes	O
the	O
most	O
sense	O
when	O
the	O
different	O
variables	O
in	O
the	O
optimization	O
problem	O
can	O
be	O
clearly	O
separated	O
into	O
groups	O
that	O
play	O
relatively	O
isolated	O
roles	O
or	O
when	O
optimization	O
with	O
respect	O
to	O
one	O
group	O
of	O
variables	O
is	O
significantly	O
more	O
efficient	O
than	O
optimization	O
with	O
respect	O
to	O
all	O
of	O
the	O
variables	O
for	O
example	B
consider	O
the	O
cost	O
function	O
j	O
w	O
hij	O
ij	O
ij	O
x	O
w	O
h	O
ij	O
this	O
function	O
describes	O
a	O
learning	O
problem	O
called	O
sparse	O
coding	O
where	O
the	O
goal	O
is	O
to	O
find	O
a	O
weight	O
matrix	O
w	O
that	O
can	O
linearly	O
decode	O
a	O
matrix	O
of	O
activation	O
values	O
h	O
to	O
reconstruct	O
the	O
training	O
set	O
x	O
most	O
applications	O
of	O
sparse	O
coding	O
also	O
involve	O
weight	O
decay	O
or	O
a	O
constraint	O
on	O
the	O
norms	O
of	O
the	O
columns	O
of	O
w	O
in	O
order	O
to	O
prevent	O
the	O
pathological	O
solution	O
with	O
extremely	O
small	O
and	O
large	O
w	O
h	O
the	O
function	O
j	O
is	O
not	O
convex	O
however	O
we	O
can	O
divide	O
the	O
inputs	O
to	O
the	O
training	O
algorithm	O
into	O
two	O
sets	O
the	O
dictionary	O
parameters	O
w	O
and	O
the	O
code	O
representations	O
h	O
minimizing	O
the	O
objective	B
function	I
with	O
respect	O
to	O
either	O
one	O
of	O
these	O
sets	O
of	O
variables	O
is	O
a	O
convex	O
problem	O
block	O
coordinate	O
descent	O
thus	O
gives	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
us	O
an	O
optimization	O
strategy	O
that	O
allows	O
us	O
to	O
use	O
efficient	O
convex	B
optimization	I
algorithms	O
by	O
alternating	O
between	O
optimizing	O
w	O
with	O
h	O
fixed	O
then	O
optimizing	O
h	O
wwith	O
fixed	O
x	O
coordinate	O
descent	O
is	O
not	O
a	O
very	O
good	O
strategy	O
when	O
the	O
value	O
of	O
one	O
variable	O
strongly	O
influences	O
the	O
optimal	O
value	O
of	O
another	O
variable	O
as	O
in	O
the	O
function	O
f	O
where	O
is	O
a	O
positive	O
constant	O
the	O
first	O
term	O
encourages	O
the	O
two	O
variables	O
to	O
have	O
similar	O
value	O
while	O
the	O
second	O
term	O
encourages	O
them	O
to	O
be	O
near	O
zero	O
the	O
solution	O
is	O
to	O
set	O
both	O
to	O
zero	O
newton	O
s	O
method	O
can	O
solve	O
the	O
problem	O
in	O
a	O
single	O
step	O
because	O
it	O
is	O
a	O
positive	B
definite	I
quadratic	O
problem	O
however	O
for	O
small	O
coordinate	O
descent	O
will	O
make	O
very	O
slow	O
progress	O
because	O
the	O
first	O
term	O
does	O
not	O
allow	O
a	O
single	O
variable	O
to	O
be	O
changed	O
to	O
a	O
value	O
that	O
differs	O
significantly	O
from	O
the	O
current	O
value	O
of	O
the	O
other	O
variable	O
polyak	O
averaging	O
consists	O
of	O
averaging	O
together	O
several	O
polyak	O
averaging	O
and	O
juditsky	O
points	O
in	O
the	O
trajectory	O
through	O
parameter	O
space	O
visited	O
by	O
an	O
optimization	O
algorithm	O
if	O
t	O
iterations	O
of	O
gradient	B
descent	O
visit	O
points	O
then	O
the	O
output	O
of	O
the	O
polyak	O
averaging	O
algorithm	O
is	O
i	O
on	O
some	O
problem	O
t	O
classes	O
such	O
as	O
gradient	B
descent	O
applied	O
to	O
convex	O
problems	O
this	O
approach	O
has	O
strong	O
convergence	O
guarantees	O
when	O
applied	O
to	O
neural	O
networks	O
its	O
justification	O
is	O
more	O
heuristic	O
but	O
it	O
performs	O
well	O
in	O
practice	O
the	O
basic	O
idea	O
is	O
that	O
the	O
optimization	O
algorithm	O
may	O
leap	O
back	O
and	O
forth	O
across	O
a	O
valley	O
several	O
times	O
without	O
ever	O
visiting	O
a	O
point	O
near	O
the	O
bottom	O
of	O
the	O
valley	O
the	O
average	O
of	O
all	O
of	O
the	O
locations	O
on	O
either	O
side	O
should	O
be	O
close	O
to	O
the	O
bottom	O
of	O
the	O
valley	O
though	O
in	O
non-convex	O
problems	O
the	O
path	O
taken	O
by	O
the	O
optimization	O
trajectory	O
can	O
be	O
very	O
complicated	O
and	O
visit	O
many	O
different	O
regions	O
including	O
points	O
in	O
parameter	O
space	O
from	O
the	O
distant	O
past	O
that	O
may	O
be	O
separated	O
from	O
the	O
current	O
point	O
by	O
large	O
barriers	O
in	O
the	O
cost	O
function	O
does	O
not	O
seem	O
like	O
a	O
useful	O
behavior	O
as	O
a	O
result	O
when	O
applying	O
polyak	O
averaging	O
to	O
non-convex	O
problems	O
it	O
is	O
typical	O
to	O
use	O
an	O
exponentially	O
decaying	O
running	O
average	O
t	O
the	O
running	O
average	O
approach	O
is	O
used	O
in	O
numerous	O
applications	O
see	O
szegedy	O
et	O
al	O
for	O
a	O
recent	O
example	B
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
supervised	O
pretraining	O
sometimes	O
directly	O
training	O
a	O
model	O
to	O
solve	O
a	O
specific	O
task	O
can	O
be	O
too	O
ambitious	O
if	O
the	O
model	O
is	O
complex	O
and	O
hard	O
to	O
optimize	O
or	O
if	O
the	O
task	O
is	O
very	O
difficult	O
it	O
is	O
sometimes	O
more	O
effective	O
to	O
train	O
a	O
simpler	O
model	O
to	O
solve	O
the	O
task	O
then	O
make	O
the	O
model	O
more	O
complex	O
it	O
can	O
also	O
be	O
more	O
effective	O
to	O
train	O
the	O
model	O
to	O
solve	O
a	O
simpler	O
task	O
then	O
move	O
on	O
to	O
confront	O
the	O
final	O
task	O
these	O
strategies	O
that	O
involve	O
training	O
simple	O
models	O
on	O
simple	O
tasks	O
before	O
confronting	O
the	O
challenge	B
of	O
training	O
the	O
desired	O
model	O
to	O
perform	O
the	O
desired	O
task	O
are	O
collectively	O
known	O
as	O
pretraining	O
greedy	O
algorithms	O
break	O
a	O
problem	O
into	O
many	O
components	O
then	O
solve	O
for	O
the	O
optimal	O
version	O
of	O
each	O
component	O
in	O
isolation	O
unfortunately	O
combining	O
the	O
individually	O
optimal	O
components	O
is	O
not	O
guaranteed	O
to	O
yield	O
an	O
optimal	O
complete	O
solution	O
however	O
greedy	O
algorithms	O
can	O
be	O
computationally	O
much	O
cheaper	O
than	O
algorithms	O
that	O
solve	O
for	O
the	O
best	O
joint	O
solution	O
and	O
the	O
quality	O
of	O
a	O
greedy	O
solution	O
is	O
often	O
acceptable	O
if	O
not	O
optimal	O
greedy	O
algorithms	O
may	O
also	O
be	O
followed	O
by	O
a	O
fine-tuning	B
stage	O
in	O
which	O
a	O
joint	O
optimization	O
algorithm	O
searches	O
for	O
an	O
optimal	O
solution	O
to	O
the	O
full	O
problem	O
initializing	O
the	O
joint	O
optimization	O
algorithm	O
with	O
a	O
greedy	O
solution	O
can	O
greatly	O
speed	O
it	O
up	O
and	O
improve	O
the	O
quality	O
of	O
the	O
solution	O
it	O
finds	O
pretraining	O
and	O
especially	O
greedy	O
pretraining	O
algorithms	O
are	O
ubiquitous	O
in	O
deep	O
learning	O
in	O
this	O
section	O
we	O
describe	O
specifically	O
those	O
pretraining	O
algorithms	O
that	O
break	O
supervised	B
learning	I
problems	O
into	O
other	O
simpler	O
supervised	B
learning	I
problems	O
this	O
approach	O
is	O
known	O
as	O
greedy	B
supervised	I
pretraining	I
in	O
the	O
original	O
bengio	O
et	O
al	O
version	O
of	O
greedy	B
supervised	I
pretraining	I
each	O
stage	O
consists	O
of	O
a	O
supervised	B
learning	I
training	O
task	O
involving	O
only	O
a	O
subset	O
of	O
the	O
layers	O
in	O
the	O
final	O
neural	B
network	I
an	O
example	B
of	O
greedy	B
supervised	I
pretraining	I
is	O
illustrated	O
in	O
figure	O
in	O
which	O
each	O
added	O
hidden	B
layer	I
is	O
pretrained	O
as	O
part	O
of	O
a	O
shallow	O
supervised	O
mlp	O
taking	O
as	O
input	O
the	O
output	O
of	O
the	O
previously	O
trained	O
hidden	B
layer	I
instead	O
of	O
pretraining	O
one	O
layer	O
at	O
a	O
time	O
simonyan	O
and	O
zisserman	O
pretrain	O
a	O
deep	O
convolutional	B
network	I
weight	O
layers	O
and	O
then	O
use	O
the	O
first	O
four	O
and	O
last	O
three	O
layers	O
from	O
this	O
network	O
to	O
initialize	O
even	O
deeper	O
networks	O
up	O
to	O
nineteen	O
layers	O
of	O
weights	B
the	O
middle	O
layers	O
of	O
the	O
new	O
very	O
deep	O
network	O
are	O
initialized	O
randomly	O
the	O
new	O
network	O
is	O
then	O
jointly	O
trained	O
another	O
option	O
explored	O
by	O
yu	O
of	O
the	O
previously	O
trained	O
mlps	O
as	O
well	O
as	O
the	O
raw	O
input	O
as	O
inputs	O
for	O
each	O
added	O
stage	O
is	O
to	O
use	O
the	O
outputs	O
et	O
al	O
why	O
would	O
greedy	B
supervised	I
pretraining	I
help	O
the	O
hypothesis	O
initially	O
is	O
that	O
it	O
helps	O
to	O
provide	O
better	O
guidance	O
to	O
the	O
bengio	O
et	O
al	O
discussed	O
by	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
yy	O
xx	O
yy	O
yy	O
xx	O
yy	O
xx	O
y	O
yy	O
xx	O
bengio	O
et	O
al	O
figure	O
illustration	O
of	O
one	O
form	O
of	O
greedy	B
supervised	I
pretraining	I
start	O
by	O
training	O
a	O
sufficiently	O
shallow	O
architecture	O
another	O
drawing	O
of	O
the	O
same	O
architecture	O
we	O
keep	O
only	O
the	O
input-to-hidden	O
layer	O
of	O
the	O
original	O
network	O
and	O
discard	O
the	O
hidden-to-output	O
layer	O
we	O
send	O
the	O
output	O
of	O
the	O
first	O
hidden	B
layer	I
as	O
input	O
to	O
another	O
supervised	O
single	O
hidden	B
layer	I
mlp	O
that	O
is	O
trained	O
with	O
the	O
same	O
objective	O
as	O
the	O
first	O
network	O
was	O
thus	O
adding	O
a	O
second	O
hidden	B
layer	I
this	O
can	O
be	O
repeated	O
for	O
as	O
many	O
layers	O
as	O
desired	O
another	O
drawing	O
of	O
the	O
result	O
viewed	O
as	O
a	O
feedforward	O
network	O
to	O
further	O
improve	O
the	O
optimization	O
we	O
can	O
jointly	O
fine-tune	O
all	O
the	O
layers	O
either	O
only	O
at	O
the	O
end	O
or	O
at	O
each	O
stage	O
of	O
this	O
process	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
intermediate	O
levels	O
of	O
a	O
deep	O
hierarchy	O
in	O
general	O
pretraining	O
may	O
help	O
both	O
in	O
terms	O
of	O
optimization	O
and	O
in	O
terms	O
of	O
generalization	B
et	O
al	O
an	O
approach	O
related	O
to	O
supervised	O
pretraining	O
extends	O
the	O
idea	O
to	O
the	O
context	O
pretrain	O
a	O
deep	O
convolutional	O
net	O
with	O
of	O
transfer	B
learning	I
yosinski	O
layers	O
of	O
weights	B
on	O
a	O
set	O
of	O
tasks	O
subset	O
of	O
the	O
imagenet	O
object	O
categories	O
and	O
then	O
initialize	O
a	O
same-size	O
network	O
with	O
the	O
first	O
k	O
layers	O
of	O
the	O
first	O
net	O
all	O
the	O
layers	O
of	O
the	O
second	O
network	O
the	O
upper	O
layers	O
initialized	O
randomly	O
are	O
then	O
jointly	O
trained	O
to	O
perform	O
a	O
different	O
set	O
of	O
tasks	O
subset	O
of	O
the	O
imagenet	O
object	O
categories	O
with	O
fewer	O
training	O
examples	O
than	O
for	O
the	O
first	O
set	O
of	O
tasks	O
other	O
approaches	O
to	O
transfer	B
learning	I
with	O
neural	O
networks	O
are	O
discussed	O
in	O
section	O
romero	O
et	O
al	O
another	O
related	O
line	O
of	O
work	O
is	O
the	O
fitnets	O
approach	O
this	O
approach	O
begins	O
by	O
training	O
a	O
network	O
that	O
has	O
low	O
enough	O
depth	O
and	O
great	O
enough	O
width	O
of	O
units	O
per	O
layer	O
to	O
be	O
easy	O
to	O
train	O
this	O
network	O
then	O
becomes	O
a	O
teacher	O
for	O
a	O
second	O
network	O
designated	O
the	O
student	O
the	O
student	O
network	O
is	O
much	O
deeper	O
and	O
thinner	O
to	O
nineteen	O
layers	O
and	O
would	O
be	O
difficult	O
to	O
train	O
with	O
sgd	O
under	O
normal	O
circumstances	O
the	O
training	O
of	O
the	O
student	O
network	O
is	O
made	O
easier	O
by	O
training	O
the	O
student	O
network	O
not	O
only	O
to	O
predict	O
the	O
output	O
for	O
the	O
original	O
task	O
but	O
also	O
to	O
predict	O
the	O
value	O
of	O
the	O
middle	O
layer	O
of	O
the	O
teacher	O
network	O
this	O
extra	O
task	O
provides	O
a	O
set	O
of	O
hints	O
about	O
how	O
the	O
hidden	O
layers	O
should	O
be	O
used	O
and	O
can	O
simplify	O
the	O
optimization	O
problem	O
additional	O
parameters	O
are	O
introduced	O
to	O
regress	O
the	O
middle	O
layer	O
of	O
the	O
teacher	O
network	O
from	O
the	O
middle	O
layer	O
of	O
the	O
deeper	O
student	O
network	O
however	O
instead	O
of	O
predicting	O
the	O
final	O
classification	B
target	O
the	O
objective	O
is	O
to	O
predict	O
the	O
middle	O
hidden	B
layer	I
of	O
the	O
teacher	O
network	O
the	O
lower	O
layers	O
of	O
the	O
student	O
networks	O
thus	O
have	O
two	O
objectives	O
to	O
help	O
the	O
outputs	O
of	O
the	O
student	O
network	O
accomplish	O
their	O
task	O
as	O
well	O
as	O
to	O
predict	O
the	O
intermediate	O
layer	O
of	O
the	O
teacher	O
network	O
although	O
a	O
thin	O
and	O
deep	O
network	O
appears	O
to	O
be	O
more	O
difficult	O
to	O
train	O
than	O
a	O
wide	O
and	O
shallow	O
network	O
the	O
thin	O
and	O
deep	O
network	O
may	O
generalize	O
better	O
and	O
certainly	O
has	O
lower	O
computational	O
cost	O
if	O
it	O
is	O
thin	O
enough	O
to	O
have	O
far	O
fewer	O
parameters	O
without	O
the	O
hints	O
on	O
the	O
hidden	B
layer	I
the	O
student	O
network	O
performs	O
very	O
poorly	O
in	O
the	O
experiments	O
both	O
on	O
the	O
training	O
and	O
test	B
set	I
hints	O
on	O
middle	O
layers	O
may	O
thus	O
be	O
one	O
of	O
the	O
tools	O
to	O
help	O
train	O
neural	O
networks	O
that	O
otherwise	O
seem	O
difficult	O
to	O
train	O
but	O
other	O
optimization	O
techniques	O
or	O
changes	O
in	O
the	O
architecture	O
may	O
also	O
solve	O
the	O
problem	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
designing	O
models	O
to	O
aid	O
optimization	O
to	O
improve	O
optimization	O
the	O
best	O
strategy	O
is	O
not	O
always	O
to	O
improve	O
the	O
optimization	O
algorithm	O
instead	O
many	O
improvements	O
in	O
the	O
optimization	O
of	O
deep	O
models	O
have	O
come	O
from	O
designing	O
the	O
models	O
to	O
be	O
easier	O
to	O
optimize	O
in	O
principle	O
we	O
could	O
use	O
activation	O
functions	O
that	O
increase	O
and	O
decrease	O
in	O
jagged	O
non-monotonic	O
patterns	O
however	O
this	O
would	O
make	O
optimization	O
extremely	O
difficult	O
in	O
practice	O
it	O
is	O
more	O
important	O
to	O
choose	O
a	O
model	O
family	O
that	O
is	O
easy	O
to	O
optimize	O
than	O
to	O
use	O
a	O
powerful	O
optimization	O
algorithm	O
most	O
of	O
the	O
advances	O
in	O
neural	B
network	I
learning	O
over	O
the	O
past	O
years	O
have	O
been	O
obtained	O
by	O
changing	O
the	O
model	O
family	O
rather	O
than	O
changing	O
the	O
optimization	O
procedure	O
stochastic	O
gradient	B
descent	O
with	O
momentum	O
which	O
was	O
used	O
to	O
train	O
neural	O
networks	O
in	O
the	O
remains	O
in	O
use	O
in	O
modern	O
state	O
of	O
the	O
art	O
neural	B
network	I
applications	O
specifically	O
modern	O
neural	O
networks	O
reflect	O
a	O
design	O
choice	O
to	O
use	O
linear	O
transformations	O
between	O
layers	O
and	O
activation	O
functions	O
that	O
are	O
differentiable	O
almost	B
everywhere	I
and	O
have	O
significant	O
slope	O
in	O
large	O
portions	O
of	O
their	O
domain	O
in	O
particular	O
model	O
innovations	O
like	O
the	O
lstm	O
rectified	O
linear	O
units	O
and	O
maxout	O
units	O
have	O
all	O
moved	O
toward	O
using	O
more	O
linear	O
functions	O
than	O
previous	O
models	O
like	O
deep	O
networks	O
based	O
on	O
sigmoidal	O
units	O
these	O
models	O
have	O
nice	O
properties	O
that	O
make	O
optimization	O
easier	O
the	O
gradient	B
flows	O
through	O
many	O
layers	O
provided	O
that	O
the	O
jacobian	O
of	O
the	O
linear	O
transformation	O
has	O
reasonable	O
singular	O
values	O
moreover	O
linear	O
functions	O
consistently	O
increase	O
in	O
a	O
single	O
direction	O
so	O
even	O
if	O
the	O
model	O
s	O
output	O
is	O
very	O
far	O
from	O
correct	O
it	O
is	O
clear	O
simply	O
from	O
computing	O
the	O
gradient	B
which	O
direction	O
its	O
output	O
should	O
move	O
to	O
reduce	O
the	O
loss	O
function	O
in	O
other	O
words	O
modern	O
neural	O
nets	O
have	O
been	O
designed	O
so	O
that	O
their	O
local	O
gradient	B
information	O
corresponds	O
reasonably	O
well	O
to	O
moving	O
toward	O
a	O
distant	O
solution	O
other	O
model	O
design	O
strategies	O
can	O
help	O
to	O
make	O
optimization	O
easier	O
for	O
example	B
linear	O
paths	O
or	O
skip	O
connections	O
between	O
layers	O
reduce	O
the	O
length	O
of	O
the	O
shortest	O
path	O
from	O
the	O
lower	O
layer	O
s	O
parameters	O
to	O
the	O
output	O
and	O
thus	O
mitigate	O
the	O
vanishing	O
gradient	B
problem	O
a	O
related	O
idea	O
to	O
skip	O
connections	O
is	O
adding	O
extra	O
copies	O
of	O
the	O
output	O
that	O
are	O
attached	O
to	O
the	O
intermediate	O
hidden	O
layers	O
of	O
the	O
network	O
as	O
in	O
googlenet	O
szegedy	O
et	O
al	O
and	O
deeply-supervised	O
nets	O
these	O
auxiliary	O
heads	O
are	O
trained	O
to	O
perform	O
the	O
same	O
task	O
as	O
the	O
primary	O
output	O
at	O
the	O
top	O
of	O
the	O
network	O
in	O
order	O
to	O
ensure	O
that	O
the	O
lower	O
layers	O
receive	O
a	O
large	O
gradient	B
when	O
training	O
is	O
complete	O
the	O
auxiliary	O
heads	O
may	O
be	O
discarded	O
this	O
is	O
an	O
alternative	O
to	O
the	O
pretraining	O
strategies	O
which	O
were	O
introduced	O
in	O
the	O
previous	O
section	O
in	O
this	O
way	O
one	O
can	O
train	O
jointly	O
all	O
the	O
layers	O
in	O
a	O
single	O
phase	O
but	O
change	O
the	O
architecture	O
so	O
that	O
intermediate	O
layers	O
the	O
lower	O
ones	O
can	O
get	O
some	O
hints	O
about	O
what	O
they	O
lee	O
et	O
al	O
et	O
al	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
should	O
do	O
via	O
a	O
shorter	O
path	O
these	O
hints	O
provide	O
an	O
error	O
signal	O
to	O
lower	O
layers	O
continuation	B
methods	I
and	O
curriculum	B
learning	I
as	O
argued	O
in	O
section	O
many	O
of	O
the	O
challenges	O
in	O
optimization	O
arise	O
from	O
the	O
global	O
structure	O
of	O
the	O
cost	O
function	O
and	O
cannot	O
be	O
resolved	O
merely	O
by	O
making	O
better	O
estimates	O
of	O
local	O
update	O
directions	O
the	O
predominant	O
strategy	O
for	O
overcoming	O
this	O
problem	O
is	O
to	O
attempt	O
to	O
initialize	O
the	O
parameters	O
in	O
a	O
region	O
that	O
is	O
connected	O
to	O
the	O
solution	O
by	O
a	O
short	O
path	O
through	O
parameter	O
space	O
that	O
local	O
descent	O
can	O
discover	O
continuation	B
methods	I
are	O
a	O
family	O
of	O
strategies	O
that	O
can	O
make	O
optimization	O
easier	O
by	O
choosing	O
initial	O
points	O
to	O
ensure	O
that	O
local	O
optimization	O
spends	O
most	O
of	O
its	O
time	O
in	O
well-behaved	O
regions	O
of	O
space	O
the	O
idea	O
behind	O
continuation	B
methods	I
is	O
to	O
construct	O
a	O
series	O
of	O
objective	O
functions	O
over	O
the	O
same	O
parameters	O
in	O
order	O
to	O
j	O
j	O
minimize	O
a	O
cost	O
function	O
j	O
we	O
will	O
construct	O
new	O
cost	O
functions	O
these	O
cost	O
functions	O
are	O
designed	O
to	O
be	O
increasingly	O
difficult	O
with	O
j	O
being	O
fairly	O
easy	O
to	O
minimize	O
and	O
j	O
the	O
most	O
difficult	O
being	O
j	O
the	O
true	O
cost	O
function	O
motivating	O
the	O
entire	O
process	O
when	O
we	O
say	O
that	O
j	O
we	O
mean	O
that	O
it	O
is	O
well	O
behaved	O
over	O
more	O
of	O
space	O
a	O
random	O
initialization	B
is	O
more	O
likely	O
to	O
land	O
in	O
the	O
region	O
where	O
local	O
descent	O
can	O
minimize	O
the	O
cost	O
function	O
successfully	O
because	O
this	O
region	O
is	O
larger	O
the	O
series	O
of	O
cost	O
functions	O
are	O
designed	O
so	O
that	O
a	O
solution	O
to	O
one	O
is	O
a	O
good	O
initial	O
point	O
of	O
the	O
next	O
we	O
thus	O
begin	O
by	O
solving	O
an	O
easy	O
problem	O
then	O
refine	O
the	O
solution	O
to	O
solve	O
incrementally	O
harder	O
problems	O
until	O
we	O
arrive	O
at	O
a	O
solution	O
to	O
the	O
true	O
underlying	O
problem	O
is	O
easier	O
than	O
j	O
i	O
traditional	O
continuation	B
methods	I
the	O
use	O
of	O
continuation	B
methods	I
for	O
neural	B
network	I
training	O
are	O
usually	O
based	O
on	O
smoothing	O
the	O
objective	B
function	I
see	O
wu	O
for	O
an	O
example	B
of	O
such	O
a	O
method	O
and	O
a	O
review	O
of	O
some	O
related	O
methods	O
continuation	B
methods	I
are	O
also	O
closely	O
related	O
to	O
simulated	O
annealing	O
which	O
adds	O
noise	O
to	O
the	O
parameters	O
continuation	B
methods	I
have	O
been	O
extremely	O
successful	O
in	O
recent	O
years	O
see	O
mobahi	O
and	O
fisher	O
for	O
an	O
overview	O
of	O
recent	O
literature	O
especially	O
for	O
ai	O
applications	O
et	O
al	O
continuation	B
methods	I
traditionally	O
were	O
mostly	O
designed	O
with	O
the	O
goal	O
of	O
overcoming	O
the	O
challenge	B
of	O
local	O
minima	O
specifically	O
they	O
were	O
designed	O
to	O
reach	O
a	O
global	O
minimum	O
despite	O
the	O
presence	O
of	O
many	O
local	O
minima	O
to	O
do	O
so	O
these	O
continuation	B
methods	I
would	O
construct	O
easier	O
cost	O
functions	O
by	O
blurring	O
the	O
original	O
cost	O
function	O
this	O
blurring	O
operation	B
can	O
be	O
done	O
by	O
approximating	O
j	O
e	O
n	O
via	O
sampling	O
the	O
intuition	O
for	O
this	O
approach	O
is	O
that	O
some	O
non-convex	O
functions	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
become	O
approximately	O
convex	O
when	O
blurred	O
in	O
many	O
cases	O
this	O
blurring	O
preserves	O
enough	O
information	O
about	O
the	O
location	O
of	O
a	O
global	O
minimum	O
that	O
we	O
can	O
find	O
the	O
global	O
minimum	O
by	O
solving	O
progressively	O
less	O
blurred	O
versions	O
of	O
the	O
problem	O
this	O
approach	O
can	O
break	O
down	O
in	O
three	O
different	O
ways	O
first	O
it	O
might	O
successfully	O
define	O
a	O
series	O
of	O
cost	O
functions	O
where	O
the	O
first	O
is	O
convex	O
and	O
the	O
optimum	O
tracks	O
from	O
one	O
function	O
to	O
the	O
next	O
arriving	O
at	O
the	O
global	O
minimum	O
but	O
it	O
might	O
require	O
so	O
many	O
incremental	O
cost	O
functions	O
that	O
the	O
cost	O
of	O
the	O
entire	O
procedure	O
remains	O
high	O
np-hard	O
optimization	O
problems	O
remain	O
np-hard	O
even	O
when	O
continuation	B
methods	I
are	O
applicable	O
the	O
other	O
two	O
ways	O
that	O
continuation	B
methods	I
fail	O
both	O
correspond	O
to	O
the	O
method	O
not	O
being	O
applicable	O
first	O
the	O
function	O
might	O
not	O
become	O
convex	O
no	O
matter	O
how	O
much	O
it	O
is	O
blurred	O
consider	O
for	O
example	B
the	O
function	O
j	O
second	O
the	O
function	O
may	O
become	O
convex	O
as	O
a	O
result	O
of	O
blurring	O
but	O
the	O
minimum	O
of	O
this	O
blurred	O
function	O
may	O
track	O
to	O
a	O
local	O
rather	O
than	O
a	O
global	O
minimum	O
of	O
the	O
original	O
cost	O
function	O
though	O
continuation	B
methods	I
were	O
mostly	O
originally	O
designed	O
to	O
deal	O
with	O
the	O
problem	O
of	O
local	O
minima	O
local	O
minima	O
are	O
no	O
longer	O
believed	O
to	O
be	O
the	O
primary	O
problem	O
for	O
neural	B
network	I
optimization	O
fortunately	O
continuation	B
methods	I
can	O
still	O
help	O
the	O
easier	O
objective	O
functions	O
introduced	O
by	O
the	O
continuation	O
method	O
can	O
eliminate	O
flat	O
regions	O
decrease	O
variance	O
in	O
gradient	B
estimates	O
improve	O
conditioning	O
of	O
the	O
hessian	B
matrix	O
or	O
do	O
anything	O
else	O
that	O
will	O
either	O
make	O
local	O
updates	O
easier	O
to	O
compute	O
or	O
improve	O
the	O
correspondence	O
between	O
local	O
update	O
directions	O
and	O
progress	O
toward	O
a	O
global	O
solution	O
bengio	O
et	O
al	O
skinner	O
peterson	O
krueger	O
and	O
dayan	O
solomonoff	O
elman	O
sanger	O
observed	O
that	O
an	O
approach	O
called	O
curriculum	B
learning	I
or	O
shaping	O
can	O
be	O
interpreted	O
as	O
a	O
continuation	O
method	O
curriculum	B
learning	I
is	O
based	O
on	O
the	O
idea	O
of	O
planning	O
a	O
learning	O
process	O
to	O
begin	O
by	O
learning	O
simple	O
concepts	O
and	O
progress	O
to	O
learning	O
more	O
complex	O
concepts	O
that	O
depend	O
on	O
these	O
simpler	O
concepts	O
this	O
basic	O
strategy	O
was	O
previously	O
known	O
to	O
accelerate	O
progress	O
in	O
animal	O
training	O
and	O
machine	B
learning	I
bengio	O
et	O
al	O
justified	O
this	O
strategy	O
as	O
a	O
continuation	O
method	O
where	O
earlier	O
j	O
are	O
made	O
easier	O
by	O
increasing	O
the	O
influence	O
of	O
simpler	O
examples	O
by	O
assigning	O
their	O
contributions	O
to	O
the	O
cost	O
function	O
larger	O
coefficients	O
or	O
by	O
sampling	O
them	O
more	O
frequently	O
and	O
experimentally	O
demonstrated	O
that	O
better	O
results	O
could	O
be	O
obtained	O
by	O
following	O
a	O
curriculum	O
on	O
a	O
large-scale	O
neural	O
language	O
modeling	O
task	O
curriculum	B
learning	I
has	O
been	O
successful	O
on	O
a	O
wide	O
range	O
of	O
natural	O
language	O
and	O
computer	O
collobert	O
vision	O
kumar	O
et	O
al	O
lee	O
and	O
grauman	O
supancic	O
and	O
ramanan	O
tasks	O
curriculum	B
learning	I
was	O
also	O
verified	O
as	O
being	O
consistent	O
with	O
the	O
way	O
in	O
teachers	O
start	O
by	O
showing	O
easier	O
and	O
which	O
humans	O
teach	O
tu	O
and	O
honavar	O
mikolov	O
khan	O
et	O
al	O
et	O
al	O
et	O
al	O
et	O
al	O
chapter	O
optimization	O
for	O
training	O
deep	O
models	O
more	O
prototypical	O
examples	O
and	O
then	O
help	O
the	O
learner	O
refine	O
the	O
decision	O
surface	O
with	O
the	O
less	O
obvious	O
cases	O
curriculum-based	O
strategies	O
are	O
more	O
effective	O
for	O
teaching	O
humans	O
than	O
strategies	O
based	O
on	O
uniform	O
sampling	O
of	O
examples	O
and	O
can	O
also	O
increase	O
the	O
effectiveness	O
of	O
other	O
teaching	O
strategies	O
basu	O
and	O
christensen	O
another	O
important	O
contribution	O
to	O
research	O
on	O
curriculum	B
learning	I
arose	O
in	O
the	O
context	O
of	O
training	O
recurrent	O
neural	O
networks	O
to	O
capture	O
long-term	O
dependencies	O
zaremba	O
and	O
sutskever	O
found	O
that	O
much	O
better	O
results	O
were	O
obtained	O
with	O
a	O
stochastic	O
curriculum	O
in	O
which	O
a	O
random	O
mix	O
of	O
easy	O
and	O
difficult	O
examples	O
is	O
always	O
presented	O
to	O
the	O
learner	O
but	O
where	O
the	O
average	O
proportion	O
of	O
the	O
more	O
difficult	O
examples	O
those	O
with	O
longer-term	O
dependencies	O
is	O
gradually	O
increased	O
with	O
a	O
deterministic	O
curriculum	O
no	O
improvement	O
over	O
the	O
baseline	O
training	O
from	O
the	O
full	O
training	O
set	O
was	O
observed	O
we	O
have	O
now	O
described	O
the	O
basic	O
family	O
of	O
neural	B
network	I
models	O
and	O
how	O
to	O
regularize	O
and	O
optimize	O
them	O
in	O
the	O
chapters	O
ahead	O
we	O
turn	O
to	O
specializations	O
of	O
the	O
neural	B
network	I
family	O
that	O
allow	O
neural	O
networks	O
to	O
scale	O
to	O
very	O
large	O
sizes	O
and	O
process	O
input	O
data	O
that	O
has	O
special	O
structure	O
the	O
optimization	O
methods	O
discussed	O
in	O
this	O
chapter	O
are	O
often	O
directly	O
applicable	O
to	O
these	O
specialized	O
architectures	O
with	O
little	O
or	O
no	O
modification	O
chapter	O
convolutional	O
networks	O
lecun	O
also	O
known	O
as	O
convolutional	O
networks	O
convolutional	O
neural	O
networks	O
or	O
cnns	O
are	O
a	O
specialized	O
kind	O
of	O
neural	B
network	I
for	O
processing	O
data	O
that	O
has	O
a	O
known	O
grid-like	O
topology	O
examples	O
include	O
time-series	O
data	O
which	O
can	O
be	O
thought	O
of	O
as	O
a	O
grid	O
taking	O
samples	O
at	O
regular	O
time	O
intervals	O
and	O
image	O
data	O
which	O
can	O
be	O
thought	O
of	O
as	O
a	O
grid	O
of	O
pixels	O
convolutional	O
networks	O
have	O
been	O
tremendously	O
successful	O
in	O
practical	O
applications	O
the	O
name	O
convolutional	O
neural	B
network	I
indicates	O
that	O
the	O
network	O
employs	O
a	O
mathematical	O
operation	B
called	O
convolution	O
convolution	O
is	O
a	O
specialized	O
kind	O
of	O
linear	O
operation	B
convolutional	O
networks	O
are	O
simply	O
neural	O
networks	O
that	O
use	O
convolution	O
in	O
place	O
of	O
general	O
matrix	O
multiplication	O
in	O
at	O
least	O
one	O
of	O
their	O
layers	O
in	O
this	O
chapter	O
we	O
will	O
first	O
describe	O
what	O
convolution	O
is	O
next	O
we	O
will	O
explain	O
the	O
motivation	O
behind	O
using	O
convolution	O
in	O
a	O
neural	B
network	I
we	O
will	O
then	O
describe	O
an	O
operation	B
called	O
pooling	O
which	O
almost	O
all	O
convolutional	O
networks	O
employ	O
usually	O
the	O
operation	B
used	O
in	O
a	O
convolutional	O
neural	B
network	I
does	O
not	O
correspond	O
precisely	O
to	O
the	O
definition	O
of	O
convolution	O
as	O
used	O
in	O
other	O
fields	O
such	O
as	O
engineering	O
or	O
pure	O
mathematics	O
we	O
will	O
describe	O
several	O
variants	O
on	O
the	O
convolution	O
function	O
that	O
are	O
widely	O
used	O
in	O
practice	O
for	O
neural	O
networks	O
we	O
will	O
also	O
show	O
how	O
convolution	O
may	O
be	O
applied	O
to	O
many	O
kinds	O
of	O
data	O
with	O
different	O
numbers	O
of	O
dimensions	O
we	O
then	O
discuss	O
means	O
of	O
making	O
convolution	O
more	O
efficient	O
convolutional	O
networks	O
stand	O
out	O
as	O
an	O
example	B
of	O
neuroscientific	O
principles	O
influencing	O
deep	O
learning	O
we	O
will	O
discuss	O
these	O
neuroscientific	O
principles	O
then	O
conclude	O
with	O
comments	O
about	O
the	O
role	O
convolutional	O
networks	O
have	O
played	O
in	O
the	O
history	O
of	O
deep	O
learning	O
one	O
topic	O
this	O
chapter	O
does	O
not	O
address	O
is	O
how	O
to	O
choose	O
the	O
architecture	O
of	O
your	O
convolutional	B
network	I
the	O
goal	O
of	O
this	O
chapter	O
is	O
to	O
describe	O
the	O
kinds	O
of	O
tools	O
that	O
convolutional	O
networks	O
provide	O
while	O
chapter	O
chapter	O
convolutional	O
networks	O
describes	O
general	O
guidelines	O
for	O
choosing	O
which	O
tools	O
to	O
use	O
in	O
which	O
circumstances	O
research	O
into	O
convolutional	B
network	I
architectures	O
proceeds	O
so	O
rapidly	O
that	O
a	O
new	O
best	O
architecture	O
for	O
a	O
given	O
benchmark	O
is	O
announced	O
every	O
few	O
weeks	O
to	O
months	O
rendering	O
it	O
impractical	O
to	O
describe	O
the	O
best	O
architecture	O
in	O
print	O
however	O
the	O
best	O
architectures	O
have	O
consistently	O
been	O
composed	O
of	O
the	O
building	O
blocks	O
described	O
here	O
the	O
convolution	O
operation	B
in	O
its	O
most	O
general	O
form	O
convolution	O
is	O
an	O
operation	B
on	O
two	O
functions	O
of	O
a	O
realvalued	O
argument	O
to	O
motivate	O
the	O
definition	O
of	O
convolution	O
we	O
start	O
with	O
examples	O
of	O
two	O
functions	O
we	O
might	O
use	O
suppose	O
we	O
are	O
tracking	O
the	O
location	O
of	O
a	O
spaceship	O
with	O
a	O
laser	O
sensor	O
our	O
laser	O
sensor	O
provides	O
a	O
single	O
output	O
xt	O
the	O
position	O
of	O
the	O
spaceship	O
at	O
time	O
t	O
both	O
x	O
and	O
t	O
are	O
real-valued	O
i	O
e	O
we	O
can	O
get	O
a	O
different	O
reading	O
from	O
the	O
laser	O
sensor	O
at	O
any	O
instant	O
in	O
time	O
now	O
suppose	O
that	O
our	O
laser	O
sensor	O
is	O
somewhat	O
noisy	O
to	O
obtain	O
a	O
less	O
noisy	O
estimate	O
of	O
the	O
spaceship	O
s	O
position	O
we	O
would	O
like	O
to	O
average	O
together	O
several	O
measurements	O
of	O
course	O
more	O
recent	O
measurements	O
are	O
more	O
relevant	O
so	O
we	O
will	O
want	O
this	O
to	O
be	O
a	O
weighted	O
average	O
that	O
gives	O
more	O
weight	O
to	O
recent	O
measurements	O
we	O
can	O
do	O
this	O
with	O
a	O
weighting	O
function	O
wa	O
where	O
a	O
is	O
the	O
age	O
of	O
a	O
measurement	O
if	O
we	O
apply	O
such	O
a	O
weighted	O
average	O
operation	B
at	O
every	O
moment	O
we	O
obtain	O
a	O
new	O
function	O
providing	O
a	O
smoothed	O
estimate	O
of	O
the	O
position	O
of	O
the	O
spaceship	O
s	O
s	O
t	O
x	O
a	O
w	O
t	O
a	O
da	O
this	O
operation	B
is	O
called	O
convolution	O
the	O
convolution	O
operation	B
is	O
typically	O
denoted	O
with	O
an	O
asterisk	O
x	O
w	O
t	O
s	O
t	O
in	O
our	O
example	B
w	O
needs	O
to	O
be	O
a	O
valid	O
probability	B
density	I
function	I
or	O
the	O
output	O
is	O
not	O
a	O
weighted	O
average	O
also	O
w	O
needs	O
to	O
be	O
for	O
all	O
negative	O
arguments	O
or	O
it	O
will	O
look	O
into	O
the	O
future	O
which	O
is	O
presumably	O
beyond	O
our	O
capabilities	O
these	O
limitations	O
are	O
particular	O
to	O
our	O
example	B
though	O
in	O
general	O
convolution	O
is	O
defined	O
for	O
any	O
functions	O
for	O
which	O
the	O
above	O
integral	O
is	O
defined	O
and	O
may	O
be	O
used	O
for	O
other	O
purposes	O
besides	O
taking	O
weighted	O
averages	O
in	O
convolutional	B
network	I
terminology	O
the	O
first	O
argument	O
this	O
example	B
the	O
function	O
x	O
to	O
the	O
convolution	O
is	O
often	O
referred	O
to	O
as	O
the	O
input	O
and	O
the	O
second	O
chapter	O
convolutional	O
networks	O
argument	O
this	O
example	B
the	O
function	O
w	O
as	O
the	O
kernel	O
the	O
output	O
is	O
sometimes	O
referred	O
to	O
as	O
the	O
feature	B
map	O
in	O
our	O
example	B
the	O
idea	O
of	O
a	O
laser	O
sensor	O
that	O
can	O
provide	O
measurements	O
at	O
every	O
instant	O
in	O
time	O
is	O
not	O
realistic	O
usually	O
when	O
we	O
work	O
with	O
data	O
on	O
a	O
computer	O
time	O
will	O
be	O
discretized	O
and	O
our	O
sensor	O
will	O
provide	O
data	O
at	O
regular	O
intervals	O
in	O
our	O
example	B
it	O
might	O
be	O
more	O
realistic	O
to	O
assume	O
that	O
our	O
laser	O
provides	O
a	O
measurement	O
once	O
per	O
second	O
the	O
time	O
index	O
t	O
can	O
then	O
take	O
on	O
only	O
integer	O
values	O
if	O
we	O
now	O
assume	O
that	O
x	O
and	O
w	O
are	O
defined	O
only	O
on	O
integer	O
t	O
we	O
can	O
define	O
the	O
discrete	O
convolution	O
x	O
w	O
t	O
s	O
t	O
x	O
a	O
w	O
t	O
a	O
a	O
in	O
machine	B
learning	I
applications	O
the	O
input	O
is	O
usually	O
a	O
multidimensional	O
array	O
of	O
data	O
and	O
the	O
kernel	O
is	O
usually	O
a	O
multidimensional	O
array	O
of	O
parameters	O
that	O
are	O
adapted	O
by	O
the	O
learning	O
algorithm	O
we	O
will	O
refer	O
to	O
these	O
multidimensional	O
arrays	O
as	O
tensors	O
because	O
each	O
element	O
of	O
the	O
input	O
and	O
kernel	O
must	O
be	O
explicitly	O
stored	O
separately	O
we	O
usually	O
assume	O
that	O
these	O
functions	O
are	O
zero	O
everywhere	O
but	O
the	O
finite	O
set	O
of	O
points	O
for	O
which	O
we	O
store	O
the	O
values	O
this	O
means	O
that	O
in	O
practice	O
we	O
can	O
implement	O
the	O
infinite	O
summation	O
as	O
a	O
summation	O
over	O
a	O
finite	O
number	O
of	O
array	O
elements	O
finally	O
we	O
often	O
use	O
convolutions	O
over	O
more	O
than	O
one	O
axis	O
at	O
a	O
time	O
for	O
example	B
if	O
we	O
use	O
a	O
two-dimensional	O
image	O
i	O
as	O
our	O
input	O
we	O
probably	O
also	O
want	O
to	O
use	O
a	O
two-dimensional	O
kernel	O
s	O
i	O
j	O
i	O
k	O
i	O
j	O
i	O
m	O
n	O
k	O
i	O
m	O
j	O
n	O
m	O
n	O
m	O
n	O
convolution	O
is	O
commutative	O
meaning	O
we	O
can	O
equivalently	O
write	O
s	O
i	O
j	O
k	O
i	O
i	O
j	O
i	O
i	O
m	O
j	O
n	O
k	O
m	O
n	O
usually	O
the	O
latter	O
formula	O
is	O
more	O
straightforward	O
to	O
implement	O
in	O
a	O
machine	B
learning	I
library	O
because	O
there	O
is	O
less	O
variation	O
in	O
the	O
range	O
of	O
valid	O
values	O
of	O
m	O
and	O
the	O
commutative	O
property	O
of	O
convolution	O
arises	O
because	O
we	O
have	O
flipped	O
the	O
kernel	O
relative	O
to	O
the	O
input	O
in	O
the	O
sense	O
that	O
as	O
m	O
increases	O
the	O
index	O
into	O
the	O
input	O
increases	O
but	O
the	O
index	O
into	O
the	O
kernel	O
decreases	O
the	O
only	O
reason	O
to	O
flip	O
the	O
kernel	O
is	O
to	O
obtain	O
the	O
commutative	O
property	O
while	O
the	O
commutative	O
property	O
chapter	O
convolutional	O
networks	O
is	O
useful	O
for	O
writing	O
proofs	O
it	O
is	O
not	O
usually	O
an	O
important	O
property	O
of	O
a	O
neural	B
network	I
implementation	O
instead	O
many	O
neural	B
network	I
libraries	O
implement	O
a	O
related	O
function	O
called	O
the	O
cross-correlation	B
which	O
is	O
the	O
same	O
as	O
convolution	O
but	O
without	O
flipping	O
the	O
kernel	O
s	O
i	O
j	O
i	O
k	O
i	O
j	O
i	O
i	O
m	O
j	O
m	O
n	O
n	O
k	O
m	O
n	O
many	O
machine	B
learning	I
libraries	O
implement	O
cross-correlation	B
but	O
call	O
it	O
convolution	O
in	O
this	O
text	O
we	O
will	O
follow	O
this	O
convention	O
of	O
calling	O
both	O
operations	O
convolution	O
and	O
specify	O
whether	O
we	O
mean	O
to	O
flip	O
the	O
kernel	O
or	O
not	O
in	O
contexts	O
where	O
kernel	O
flipping	O
is	O
relevant	O
in	O
the	O
context	O
of	O
machine	B
learning	I
the	O
learning	O
algorithm	O
will	O
learn	O
the	O
appropriate	O
values	O
of	O
the	O
kernel	O
in	O
the	O
appropriate	O
place	O
so	O
an	O
algorithm	O
based	O
on	O
convolution	O
with	O
kernel	O
flipping	O
will	O
learn	O
a	O
kernel	O
that	O
is	O
flipped	O
relative	O
to	O
the	O
kernel	O
learned	O
by	O
an	O
algorithm	O
without	O
the	O
flipping	O
it	O
is	O
also	O
rare	O
for	O
convolution	O
to	O
be	O
used	O
alone	O
in	O
machine	B
learning	I
instead	O
convolution	O
is	O
used	O
simultaneously	O
with	O
other	O
functions	O
and	O
the	O
combination	O
of	O
these	O
functions	O
does	O
not	O
commute	O
regardless	O
of	O
whether	O
the	O
convolution	O
operation	B
flips	O
its	O
kernel	O
or	O
not	O
see	O
figure	O
to	O
a	O
tensor	O
for	O
an	O
example	B
of	O
convolution	O
kernel	O
flipping	O
applied	O
discrete	O
convolution	O
can	O
be	O
viewed	O
as	O
multiplication	O
by	O
a	O
matrix	O
however	O
the	O
matrix	O
has	O
several	O
entries	O
constrained	O
to	O
be	O
equal	O
to	O
other	O
entries	O
for	O
example	B
for	O
univariate	O
discrete	O
convolution	O
each	O
row	O
of	O
the	O
matrix	O
is	O
constrained	O
to	O
be	O
equal	O
to	O
the	O
row	O
above	O
shifted	O
by	O
one	O
element	O
this	O
is	O
known	O
as	O
a	O
toeplitz	B
matrix	I
in	O
two	O
dimensions	O
a	O
doubly	B
block	I
circulant	I
matrix	I
corresponds	O
to	O
convolution	O
in	O
addition	O
to	O
these	O
constraints	O
that	O
several	O
elements	O
be	O
equal	O
to	O
each	O
other	O
convolution	O
usually	O
corresponds	O
to	O
a	O
very	O
sparse	O
matrix	O
matrix	O
whose	O
entries	O
are	O
mostly	O
equal	O
to	O
zero	O
this	O
is	O
because	O
the	O
kernel	O
is	O
usually	O
much	O
smaller	O
than	O
the	O
input	O
image	O
any	O
neural	B
network	I
algorithm	O
that	O
works	O
with	O
matrix	O
multiplication	O
and	O
does	O
not	O
depend	O
on	O
specific	O
properties	O
of	O
the	O
matrix	O
structure	O
should	O
work	O
with	O
convolution	O
without	O
requiring	O
any	O
further	O
changes	O
to	O
the	O
neural	B
network	I
typical	O
convolutional	O
neural	O
networks	O
do	O
make	O
use	O
of	O
further	O
specializations	O
in	O
order	O
to	O
deal	O
with	O
large	O
inputs	O
efficiently	O
but	O
these	O
are	O
not	O
strictly	O
necessary	O
from	O
a	O
theoretical	O
perspective	O
chapter	O
convolutional	O
networks	O
input	O
a	O
e	O
i	O
b	O
f	O
j	O
c	O
g	O
k	O
d	O
h	O
l	O
output	O
kernel	O
w	O
y	O
x	O
z	O
aw	O
bx	O
aw	O
bx	O
ey	O
f	O
z	O
ey	O
f	O
z	O
bw	O
cx	O
bw	O
cx	O
f	O
y	O
gz	O
f	O
y	O
gz	O
cw	O
dx	O
cw	O
dx	O
gy	O
hz	O
gy	O
hz	O
ew	O
f	O
x	O
ew	O
f	O
x	O
iy	O
jz	O
iy	O
jz	O
f	O
w	O
gx	O
f	O
w	O
gx	O
jy	O
kz	O
jy	O
kz	O
gw	O
hx	O
gw	O
hx	O
ky	O
lz	O
ky	O
lz	O
figure	O
an	O
example	B
of	O
convolution	O
without	O
kernel-flipping	O
in	O
this	O
case	O
we	O
restrict	O
the	O
output	O
to	O
only	O
positions	O
where	O
the	O
kernel	O
lies	O
entirely	O
within	O
the	O
image	O
called	O
valid	O
convolution	O
in	O
some	O
contexts	O
we	O
draw	O
boxes	O
with	O
arrows	O
to	O
indicate	O
how	O
the	O
upper-left	O
element	O
of	O
the	O
output	O
tensor	O
is	O
formed	O
by	O
applying	O
the	O
kernel	O
to	O
the	O
corresponding	O
upper-left	O
region	O
of	O
the	O
input	O
tensor	O
chapter	O
convolutional	O
networks	O
motivation	O
convolution	O
leverages	O
three	O
important	O
ideas	O
that	O
can	O
help	O
improve	O
a	O
machine	B
learning	I
system	O
sparse	O
interactions	O
parameter	O
sharing	O
and	O
equivariant	O
representations	O
moreover	O
convolution	O
provides	O
a	O
means	O
for	O
working	O
with	O
inputs	O
of	O
variable	O
size	O
we	O
now	O
describe	O
each	O
of	O
these	O
ideas	O
in	O
turn	O
traditional	O
neural	B
network	I
layers	O
use	O
matrix	O
multiplication	O
by	O
a	O
matrix	O
of	O
parameters	O
with	O
a	O
separate	O
parameter	O
describing	O
the	O
interaction	O
between	O
each	O
input	O
unit	O
and	O
each	O
output	O
unit	O
this	O
means	O
every	O
output	O
unit	O
interacts	O
with	O
every	O
input	O
unit	O
convolutional	O
networks	O
however	O
typically	O
have	O
sparse	O
interactions	O
referred	O
to	O
as	O
sparse	O
connectivity	O
or	O
sparse	O
weights	B
this	O
is	O
accomplished	O
by	O
making	O
the	O
kernel	O
smaller	O
than	O
the	O
input	O
for	O
example	B
when	O
processing	O
an	O
image	O
the	O
input	O
image	O
might	O
have	O
thousands	O
or	O
millions	O
of	O
pixels	O
but	O
we	O
can	O
detect	O
small	O
meaningful	O
features	O
such	O
as	O
edges	O
with	O
kernels	O
that	O
occupy	O
only	O
tens	O
or	O
hundreds	O
of	O
pixels	O
this	O
means	O
that	O
we	O
need	O
to	O
store	O
fewer	O
parameters	O
which	O
both	O
reduces	O
the	O
memory	O
requirements	O
of	O
the	O
model	O
and	O
improves	O
its	O
statistical	O
efficiency	O
it	O
also	O
means	O
that	O
computing	O
the	O
output	O
requires	O
fewer	O
operations	O
these	O
improvements	O
in	O
efficiency	O
are	O
usually	O
quite	O
large	O
if	O
there	O
are	O
m	O
inputs	O
and	O
n	O
outputs	O
then	O
matrix	O
multiplication	O
requires	O
m	O
n	O
parameters	O
and	O
the	O
algorithms	O
used	O
in	O
practice	O
have	O
om	O
n	O
runtime	O
example	B
if	O
we	O
limit	O
the	O
number	O
of	O
connections	O
each	O
output	O
may	O
have	O
to	O
k	O
then	O
the	O
sparsely	O
connected	O
approach	O
requires	O
only	O
k	O
runtime	O
for	O
many	O
practical	O
applications	O
it	O
is	O
possible	O
to	O
obtain	O
good	O
performance	O
on	O
the	O
machine	B
learning	I
task	O
while	O
keeping	O
k	O
several	O
orders	O
of	O
magnitude	O
smaller	O
than	O
m	O
for	O
graphical	O
demonstrations	O
of	O
sparse	O
connectivity	O
see	O
figure	O
in	O
a	O
deep	O
convolutional	B
network	I
units	O
in	O
the	O
deeper	O
layers	O
may	O
indirectly	O
interact	O
with	O
a	O
larger	O
portion	O
of	O
the	O
input	O
as	O
shown	O
in	O
figure	O
this	O
allows	O
the	O
network	O
to	O
efficiently	O
describe	O
complicated	O
interactions	O
between	O
many	O
variables	O
by	O
constructing	O
such	O
interactions	O
from	O
simple	O
building	O
blocks	O
that	O
each	O
describe	O
only	O
sparse	O
interactions	O
parameters	O
and	O
ok	O
and	O
figure	O
n	O
n	O
parameter	O
sharing	O
refers	O
to	O
using	O
the	O
same	O
parameter	O
for	O
more	O
than	O
one	O
function	O
in	O
a	O
model	O
in	O
a	O
traditional	O
neural	O
net	O
each	O
element	O
of	O
the	O
weight	O
matrix	O
is	O
used	O
exactly	O
once	O
when	O
computing	O
the	O
output	O
of	O
a	O
layer	O
it	O
is	O
multiplied	O
by	O
one	O
element	O
of	O
the	O
input	O
and	O
then	O
never	O
revisited	O
as	O
a	O
synonym	O
for	O
parameter	O
sharing	O
one	O
can	O
say	O
that	O
a	O
network	O
has	O
tied	O
weights	B
because	O
the	O
value	O
of	O
the	O
weight	O
applied	O
to	O
one	O
input	O
is	O
tied	O
to	O
the	O
value	O
of	O
a	O
weight	O
applied	O
elsewhere	O
in	O
a	O
convolutional	O
neural	O
net	O
each	O
member	O
of	O
the	O
kernel	O
is	O
used	O
at	O
every	O
position	O
of	O
the	O
input	O
perhaps	O
some	O
of	O
the	O
boundary	O
pixels	O
depending	O
on	O
the	O
design	O
decisions	O
regarding	O
the	O
boundary	O
the	O
parameter	O
sharing	O
used	O
by	O
the	O
convolution	O
operation	B
means	O
that	O
rather	O
than	O
learning	O
a	O
separate	O
set	O
of	O
parameters	O
chapter	O
convolutional	O
networks	O
figure	O
sparse	O
connectivity	O
viewed	O
from	O
below	O
we	O
highlight	O
one	O
input	O
unit	O
and	O
also	O
highlight	O
the	O
output	O
units	O
in	O
s	O
that	O
are	O
affected	O
by	O
this	O
unit	O
s	O
is	O
formed	O
by	O
convolution	O
with	O
a	O
kernel	O
of	O
width	O
only	O
three	O
outputs	O
are	O
affected	O
by	O
x	O
is	O
formed	O
by	O
matrix	O
multiplication	O
connectivity	O
is	O
no	O
longer	O
sparse	O
so	O
all	O
of	O
the	O
outputs	O
are	O
affected	O
by	O
s	O
chapter	O
convolutional	O
networks	O
figure	O
sparse	O
connectivity	O
viewed	O
from	O
above	O
we	O
highlight	O
one	O
output	O
unit	O
and	O
also	O
highlight	O
the	O
input	O
units	O
in	O
x	O
that	O
affect	O
this	O
unit	O
these	O
units	O
are	O
known	O
as	O
the	O
receptive	B
field	I
of	O
s	O
is	O
formed	O
by	O
convolution	O
with	O
a	O
kernel	O
of	O
width	O
only	O
three	O
inputs	O
affect	O
s	O
is	O
formed	O
by	O
matrix	O
multiplication	O
connectivity	O
is	O
no	O
longer	O
sparse	O
so	O
all	O
of	O
the	O
inputs	O
affect	O
when	O
s	O
figure	O
the	O
receptive	B
field	I
of	O
the	O
units	O
in	O
the	O
deeper	O
layers	O
of	O
a	O
convolutional	B
network	I
is	O
larger	O
than	O
the	O
receptive	B
field	I
of	O
the	O
units	O
in	O
the	O
shallow	O
layers	O
this	O
effect	O
increases	O
if	O
the	O
network	O
includes	O
architectural	O
features	O
like	O
strided	O
convolution	O
or	O
pooling	O
direct	O
connections	O
in	O
a	O
convolutional	O
net	O
are	O
very	O
sparse	O
units	O
in	O
the	O
deeper	O
layers	O
can	O
be	O
indirectly	O
connected	O
to	O
all	O
or	O
most	O
of	O
the	O
input	O
image	O
this	O
means	O
that	O
even	O
though	O
chapter	O
convolutional	O
networks	O
figure	O
parameter	O
sharing	O
black	O
arrows	O
indicate	O
the	O
connections	O
that	O
use	O
a	O
particular	O
parameter	O
in	O
two	O
different	O
models	O
black	O
arrows	O
indicate	O
uses	O
of	O
the	O
central	O
element	O
of	O
a	O
kernel	O
in	O
a	O
convolutional	O
model	O
due	O
to	O
parameter	O
sharing	O
this	O
single	O
parameter	O
is	O
used	O
at	O
all	O
input	O
locations	O
the	O
single	O
black	O
arrow	O
indicates	O
the	O
use	O
of	O
the	O
central	O
element	O
of	O
the	O
weight	O
matrix	O
in	O
a	O
fully	O
connected	O
model	O
this	O
model	O
has	O
no	O
parameter	O
sharing	O
so	O
the	O
parameter	O
is	O
used	O
only	O
once	O
n	O
for	O
every	O
location	O
we	O
learn	O
only	O
one	O
set	O
this	O
does	O
not	O
affect	O
the	O
runtime	O
of	O
forward	B
propagation	I
it	O
is	O
still	O
ok	O
but	O
it	O
does	O
further	O
reduce	O
the	O
storage	O
requirements	O
of	O
the	O
model	O
to	O
k	O
parameters	O
recall	B
that	O
k	O
is	O
usually	O
several	O
orders	O
of	O
magnitude	O
less	O
than	O
m	O
since	O
m	O
and	O
n	O
are	O
usually	O
roughly	O
the	O
same	O
size	O
k	O
is	O
practically	O
insignificant	O
compared	O
to	O
m	O
n	O
convolution	O
is	O
thus	O
dramatically	O
more	O
efficient	O
than	O
dense	O
matrix	O
multiplication	O
in	O
terms	O
of	O
the	O
memory	O
requirements	O
and	O
statistical	O
efficiency	O
for	O
a	O
graphical	O
depiction	O
of	O
how	O
parameter	O
sharing	O
works	O
see	O
figure	O
as	O
an	O
example	B
of	O
both	O
of	O
these	O
first	O
two	O
principles	O
in	O
action	O
figure	O
shows	O
how	O
sparse	O
connectivity	O
and	O
parameter	O
sharing	O
can	O
dramatically	O
improve	O
the	O
efficiency	O
of	O
a	O
linear	O
function	O
for	O
detecting	O
edges	O
in	O
an	O
image	O
in	O
the	O
case	O
of	O
convolution	O
the	O
particular	O
form	O
of	O
parameter	O
sharing	O
causes	O
the	O
layer	O
to	O
have	O
a	O
property	O
called	O
equivariance	B
to	O
translation	O
to	O
say	O
a	O
function	O
is	O
equivariant	O
means	O
that	O
if	O
the	O
input	O
changes	O
the	O
output	O
changes	O
in	O
the	O
same	O
way	O
specifically	O
a	O
function	O
f	O
is	O
equivariant	O
to	O
a	O
function	O
g	O
if	O
fgx	O
gf	O
in	O
the	O
case	O
of	O
convolution	O
if	O
we	O
let	O
g	O
be	O
any	O
function	O
that	O
translates	O
the	O
input	O
i	O
e	O
shifts	O
it	O
then	O
the	O
convolution	O
function	O
is	O
equivariant	O
to	O
g	O
for	O
example	B
let	O
i	O
be	O
a	O
function	O
giving	O
image	O
brightness	O
at	O
integer	O
coordinates	O
let	O
g	O
be	O
a	O
function	O
chapter	O
convolutional	O
networks	O
y	O
ix	O
gi	O
is	O
mapping	O
one	O
image	O
function	O
to	O
another	O
image	O
function	O
such	O
that	O
i	O
the	O
image	O
function	O
with	O
i	O
y	O
this	O
shifts	O
every	O
pixel	O
of	O
i	O
one	O
unit	O
to	O
the	O
right	O
if	O
we	O
apply	O
this	O
transformation	O
to	O
i	O
then	O
apply	O
convolution	O
the	O
result	O
will	O
be	O
the	O
same	O
as	O
if	O
we	O
applied	O
convolution	O
to	O
i	O
then	O
applied	O
the	O
transformation	O
g	O
to	O
the	O
output	O
when	O
processing	O
time	O
series	O
data	O
this	O
means	O
that	O
convolution	O
produces	O
a	O
sort	O
of	O
timeline	O
that	O
shows	O
when	O
different	O
features	O
appear	O
in	O
the	O
input	O
if	O
we	O
move	O
an	O
event	O
later	O
in	O
time	O
in	O
the	O
input	O
the	O
exact	O
same	O
representation	O
of	O
it	O
will	O
appear	O
in	O
the	O
output	O
just	O
later	O
in	O
time	O
similarly	O
with	O
images	O
convolution	O
creates	O
a	O
map	O
of	O
where	O
certain	O
features	O
appear	O
in	O
the	O
input	O
if	O
we	O
move	O
the	O
object	O
in	O
the	O
input	O
its	O
representation	O
will	O
move	O
the	O
same	O
amount	O
in	O
the	O
output	O
this	O
is	O
useful	O
for	O
when	O
we	O
know	O
that	O
some	O
function	O
of	O
a	O
small	O
number	O
of	O
neighboring	O
pixels	O
is	O
useful	O
when	O
applied	O
to	O
multiple	O
input	O
locations	O
for	O
example	B
when	O
processing	O
images	O
it	O
is	O
useful	O
to	O
detect	O
edges	O
in	O
the	O
first	O
layer	O
of	O
a	O
convolutional	B
network	I
the	O
same	O
edges	O
appear	O
more	O
or	O
less	O
everywhere	O
in	O
the	O
image	O
so	O
it	O
is	O
practical	O
to	O
share	O
parameters	O
across	O
the	O
entire	O
image	O
in	O
some	O
cases	O
we	O
may	O
not	O
wish	O
to	O
share	O
parameters	O
across	O
the	O
entire	O
image	O
for	O
example	B
if	O
we	O
are	O
processing	O
images	O
that	O
are	O
cropped	O
to	O
be	O
centered	O
on	O
an	O
individual	O
s	O
face	O
we	O
probably	O
want	O
to	O
extract	O
different	O
features	O
at	O
different	O
locations	O
the	O
part	O
of	O
the	O
network	O
processing	O
the	O
top	O
of	O
the	O
face	O
needs	O
to	O
look	O
for	O
eyebrows	O
while	O
the	O
part	O
of	O
the	O
network	O
processing	O
the	O
bottom	O
of	O
the	O
face	O
needs	O
to	O
look	O
for	O
a	O
chin	O
convolution	O
is	O
not	O
naturally	O
equivariant	O
to	O
some	O
other	O
transformations	O
such	O
as	O
changes	O
in	O
the	O
scale	O
or	O
rotation	O
of	O
an	O
image	O
other	O
mechanisms	O
are	O
necessary	O
for	O
handling	O
these	O
kinds	O
of	O
transformations	O
finally	O
some	O
kinds	O
of	O
data	O
cannot	O
be	O
processed	O
by	O
neural	O
networks	O
defined	O
by	O
matrix	O
multiplication	O
with	O
a	O
fixed-shape	O
matrix	O
convolution	O
enables	O
processing	O
of	O
some	O
of	O
these	O
kinds	O
of	O
data	O
we	O
discuss	O
this	O
further	O
in	O
section	O
pooling	O
a	O
typical	O
layer	O
of	O
a	O
convolutional	B
network	I
consists	O
of	O
three	O
stages	O
figure	O
in	O
the	O
first	O
stage	O
the	O
layer	O
performs	O
several	O
convolutions	O
in	O
parallel	O
to	O
produce	O
a	O
set	O
of	O
linear	O
activations	O
in	O
the	O
second	O
stage	O
each	O
linear	O
activation	O
is	O
run	O
through	O
a	O
nonlinear	O
activation	B
function	I
such	O
as	O
the	O
rectified	O
linear	O
activation	B
function	I
this	O
stage	O
is	O
sometimes	O
called	O
the	O
detector	O
stage	O
in	O
the	O
third	O
stage	O
we	O
use	O
a	O
pooling	O
function	O
to	O
modify	O
the	O
output	O
of	O
the	O
layer	O
further	O
a	O
pooling	O
function	O
replaces	O
the	O
output	O
of	O
the	O
net	O
at	O
a	O
certain	O
location	O
with	O
a	O
summary	O
statistic	B
of	O
the	O
nearby	O
outputs	O
for	O
example	B
the	O
max	B
pooling	I
chapter	O
convolutional	O
networks	O
figure	O
efficiency	O
of	O
edge	O
detection	O
the	O
image	O
on	O
the	O
right	O
was	O
formed	O
by	O
taking	O
each	O
pixel	O
in	O
the	O
original	O
image	O
and	O
subtracting	O
the	O
value	O
of	O
its	O
neighboring	O
pixel	O
on	O
the	O
left	O
this	O
shows	O
the	O
strength	O
of	O
all	O
of	O
the	O
vertically	O
oriented	O
edges	O
in	O
the	O
input	O
image	O
which	O
can	O
be	O
a	O
useful	O
operation	B
for	O
object	B
detection	I
both	O
images	O
are	O
pixels	O
tall	O
the	O
input	O
image	O
is	O
pixels	O
wide	O
while	O
the	O
output	O
image	O
is	O
pixels	O
wide	O
this	O
transformation	O
can	O
be	O
described	O
by	O
a	O
convolution	O
kernel	O
containing	O
two	O
elements	O
and	O
requires	O
floating	O
point	O
operations	O
multiplications	O
and	O
one	O
addition	O
per	O
output	O
pixel	O
to	O
compute	O
using	O
convolution	O
to	O
describe	O
the	O
same	O
transformation	O
with	O
a	O
matrix	O
multiplication	O
would	O
take	O
or	O
over	O
eight	O
billion	O
entries	O
in	O
the	O
matrix	O
making	O
convolution	O
four	O
billion	O
times	O
more	O
efficient	O
for	O
representing	O
this	O
transformation	O
the	O
straightforward	O
matrix	O
multiplication	O
algorithm	O
performs	O
over	O
sixteen	O
billion	O
floating	O
point	O
operations	O
making	O
convolution	O
roughly	O
times	O
more	O
efficient	O
computationally	O
of	O
course	O
most	O
of	O
the	O
entries	O
of	O
the	O
matrix	O
would	O
be	O
zero	O
if	O
we	O
stored	O
only	O
the	O
nonzero	O
entries	O
of	O
the	O
matrix	O
then	O
both	O
matrix	O
multiplication	O
and	O
convolution	O
would	O
require	O
the	O
same	O
number	O
of	O
floating	O
point	O
operations	O
to	O
compute	O
the	O
matrix	O
would	O
still	O
need	O
to	O
contain	O
entries	O
convolution	O
is	O
an	O
extremely	O
efficient	O
way	O
of	O
describing	O
transformations	O
that	O
apply	O
the	O
same	O
linear	O
transformation	O
of	O
a	O
small	O
local	O
region	O
across	O
the	O
entire	O
input	O
credit	O
paula	O
goodfellow	O
chapter	O
convolutional	O
networks	O
complex	O
layer	O
terminology	O
simple	O
layer	O
terminology	O
next	O
layer	O
next	O
layer	O
convolutional	O
layer	O
pooling	O
stage	O
pooling	O
layer	O
detector	O
stage	O
nonlinearity	O
e	O
g	O
rectified	O
linear	O
convolution	O
stage	O
a	O
ne	O
transform	O
ffi	O
detector	B
layer	I
nonlinearity	O
e	O
g	O
rectified	O
linear	O
convolution	O
layer	O
a	O
ne	O
transform	O
ffi	O
input	O
to	O
layer	O
input	O
to	O
layers	O
figure	O
the	O
components	O
of	O
a	O
typical	O
convolutional	O
neural	B
network	I
layer	O
there	O
are	O
two	O
commonly	O
used	O
sets	O
of	O
terminology	O
for	O
describing	O
these	O
layers	O
this	O
terminology	O
the	O
convolutional	O
net	O
is	O
viewed	O
as	O
a	O
small	O
number	O
of	O
relatively	O
complex	O
layers	O
with	O
each	O
layer	O
having	O
many	O
stages	O
in	O
this	O
terminology	O
there	O
is	O
a	O
one-to-one	O
mapping	O
between	O
kernel	O
tensors	O
and	O
network	O
layers	O
in	O
this	O
book	O
we	O
generally	O
use	O
this	O
terminology	O
this	O
terminology	O
the	O
convolutional	O
net	O
is	O
viewed	O
as	O
a	O
larger	O
number	O
of	O
simple	O
layers	O
every	O
step	O
of	O
processing	O
is	O
regarded	O
as	O
a	O
layer	O
in	O
its	O
own	O
right	O
this	O
means	O
that	O
not	O
every	O
layer	O
has	O
parameters	O
chapter	O
convolutional	O
networks	O
operation	B
reports	O
the	O
maximum	O
output	O
within	O
a	O
rectangular	O
and	O
chellappa	O
neighborhood	O
other	O
popular	O
pooling	O
functions	O
include	O
the	O
average	O
of	O
a	O
rectangular	O
neighborhood	O
the	O
norm	O
of	O
a	O
rectangular	O
neighborhood	O
or	O
a	O
weighted	O
average	O
based	O
on	O
the	O
distance	O
from	O
the	O
central	O
pixel	O
for	O
an	O
example	B
of	O
how	O
this	O
works	O
in	O
all	O
cases	O
pooling	O
helps	O
to	O
make	O
the	O
representation	O
become	O
approximately	O
invariant	O
to	O
small	O
translations	O
of	O
the	O
input	O
invariance	B
to	O
translation	O
means	O
that	O
if	O
we	O
translate	O
the	O
input	O
by	O
a	O
small	O
amount	O
the	O
values	O
of	O
most	O
of	O
the	O
pooled	O
outputs	O
do	O
not	O
change	O
see	O
figure	O
invariance	B
to	O
local	O
translation	O
can	O
be	O
a	O
very	O
useful	O
property	O
if	O
we	O
care	O
more	O
about	O
whether	O
some	O
feature	B
is	O
present	O
than	O
exactly	O
where	O
it	O
is	O
for	O
example	B
when	O
determining	O
whether	O
an	O
image	O
contains	O
a	O
face	O
we	O
need	O
not	O
know	O
the	O
location	O
of	O
the	O
eyes	O
with	O
pixel-perfect	O
accuracy	B
we	O
just	O
need	O
to	O
know	O
that	O
there	O
is	O
an	O
eye	O
on	O
the	O
left	O
side	O
of	O
the	O
face	O
and	O
an	O
eye	O
on	O
the	O
right	O
side	O
of	O
the	O
face	O
in	O
other	O
contexts	O
it	O
is	O
more	O
important	O
to	O
preserve	O
the	O
location	O
of	O
a	O
feature	B
for	O
example	B
if	O
we	O
want	O
to	O
find	O
a	O
corner	O
defined	O
by	O
two	O
edges	O
meeting	O
at	O
a	O
specific	O
orientation	O
we	O
need	O
to	O
preserve	O
the	O
location	O
of	O
the	O
edges	O
well	O
enough	O
to	O
test	O
whether	O
they	O
meet	O
the	O
use	O
of	O
pooling	O
can	O
be	O
viewed	O
as	O
adding	O
an	O
infinitely	O
strong	O
prior	O
that	O
the	O
function	O
the	O
layer	O
learns	O
must	O
be	O
invariant	O
to	O
small	O
translations	O
when	O
this	O
assumption	O
is	O
correct	O
it	O
can	O
greatly	O
improve	O
the	O
statistical	O
efficiency	O
of	O
the	O
network	O
pooling	O
over	O
spatial	O
regions	O
produces	O
invariance	B
to	O
translation	O
but	O
if	O
we	O
pool	O
over	O
the	O
outputs	O
of	O
separately	O
parametrized	O
convolutions	O
the	O
features	O
can	O
learn	O
which	O
transformations	O
to	O
become	O
invariant	O
to	O
figure	O
because	O
pooling	O
summarizes	O
the	O
responses	O
over	O
a	O
whole	O
neighborhood	O
it	O
is	O
possible	O
to	O
use	O
fewer	O
pooling	O
units	O
than	O
detector	O
units	O
by	O
reporting	O
summary	O
statistics	O
for	O
pooling	O
regions	O
spaced	O
k	O
pixels	O
apart	O
rather	O
than	O
pixel	O
apart	O
see	O
figure	O
for	O
an	O
example	B
this	O
improves	O
the	O
computational	O
efficiency	O
of	O
the	O
network	O
because	O
the	O
next	O
layer	O
has	O
roughly	O
k	O
times	O
fewer	O
inputs	O
to	O
process	O
when	O
the	O
number	O
of	O
parameters	O
in	O
the	O
next	O
layer	O
is	O
a	O
function	O
of	O
its	O
input	O
size	O
as	O
when	O
the	O
next	O
layer	O
is	O
fully	O
connected	O
and	O
based	O
on	O
matrix	O
multiplication	O
this	O
reduction	O
in	O
the	O
input	O
size	O
can	O
also	O
result	O
in	O
improved	O
statistical	O
efficiency	O
and	O
reduced	O
memory	O
requirements	O
for	O
storing	O
the	O
parameters	O
for	O
many	O
tasks	O
pooling	O
is	O
essential	O
for	O
handling	O
inputs	O
of	O
varying	O
size	O
for	O
example	B
if	O
we	O
want	O
to	O
classify	O
images	O
of	O
variable	O
size	O
the	O
input	O
to	O
the	O
classification	B
layer	O
must	O
have	O
a	O
fixed	O
size	O
this	O
is	O
usually	O
accomplished	O
by	O
varying	O
the	O
size	O
of	O
an	O
offset	O
between	O
pooling	O
regions	O
so	O
that	O
the	O
classification	B
layer	O
always	O
receives	O
the	O
same	O
number	O
of	O
summary	O
statistics	O
regardless	O
of	O
the	O
input	O
size	O
for	O
example	B
the	O
final	O
pooling	O
layer	O
of	O
the	O
network	O
may	O
be	O
defined	O
to	O
output	O
four	O
sets	O
of	O
summary	O
statistics	O
one	O
for	O
each	O
quadrant	O
of	O
an	O
image	O
regardless	O
of	O
the	O
image	O
size	O
chapter	O
convolutional	O
networks	O
pooling	O
stage	O
detector	O
stage	O
pooling	O
stage	O
detector	O
stage	O
figure	O
max	B
pooling	I
introduces	O
invariance	B
view	O
of	O
the	O
middle	O
of	O
the	O
output	O
of	O
a	O
convolutional	O
layer	O
the	O
bottom	O
row	O
shows	O
outputs	O
of	O
the	O
nonlinearity	O
the	O
top	O
row	O
shows	O
the	O
outputs	O
of	O
max	B
pooling	I
with	O
a	O
stride	O
of	O
one	O
pixel	O
between	O
pooling	O
regions	O
and	O
a	O
pooling	O
region	O
width	O
of	O
three	O
pixels	O
a	O
view	O
of	O
the	O
same	O
network	O
after	O
the	O
input	O
has	O
been	O
shifted	O
to	O
the	O
right	O
by	O
one	O
pixel	O
every	O
value	O
in	O
the	O
bottom	O
row	O
has	O
changed	O
but	O
only	O
half	O
of	O
the	O
values	O
in	O
the	O
top	O
row	O
have	O
changed	O
because	O
the	O
max	B
pooling	I
units	O
are	O
only	O
sensitive	O
to	O
the	O
maximum	O
value	O
in	O
the	O
neighborhood	O
not	O
its	O
exact	O
location	O
chapter	O
convolutional	O
networks	O
large	O
response	O
in	O
pooling	O
unit	O
large	O
response	O
in	O
detector	O
unit	O
large	O
response	O
in	O
pooling	O
unit	O
large	O
response	O
in	O
detector	O
unit	O
figure	O
example	B
of	O
learned	O
invariances	O
a	O
pooling	O
unit	O
that	O
pools	O
over	O
multiple	O
features	O
that	O
are	O
learned	O
with	O
separate	O
parameters	O
can	O
learn	O
to	O
be	O
invariant	O
to	O
transformations	O
of	O
the	O
input	O
here	O
we	O
show	O
how	O
a	O
set	O
of	O
three	O
learned	O
filters	O
and	O
a	O
max	B
pooling	I
unit	O
can	O
learn	O
to	O
become	O
invariant	O
to	O
rotation	O
all	O
three	O
filters	O
are	O
intended	O
to	O
detect	O
a	O
hand-written	O
each	O
filter	O
attempts	O
to	O
match	O
a	O
slightly	O
different	O
orientation	O
of	O
the	O
when	O
a	O
appears	O
in	O
the	O
input	O
the	O
corresponding	O
filter	O
will	O
match	O
it	O
and	O
cause	O
a	O
large	O
activation	O
in	O
a	O
detector	O
unit	O
the	O
max	B
pooling	I
unit	O
then	O
has	O
a	O
large	O
activation	O
regardless	O
of	O
which	O
detector	O
unit	O
was	O
activated	O
we	O
show	O
here	O
how	O
the	O
network	O
processes	O
two	O
different	O
inputs	O
resulting	O
in	O
two	O
different	O
detector	O
units	O
being	O
activated	O
the	O
effect	O
on	O
the	O
pooling	O
unit	O
is	O
roughly	O
the	O
same	O
either	O
way	O
this	O
principle	O
is	O
leveraged	O
by	O
maxout	O
networks	O
et	O
al	O
and	O
other	O
convolutional	O
networks	O
max	B
pooling	I
over	O
spatial	O
positions	O
is	O
naturally	O
invariant	O
to	O
translation	O
this	O
multi-channel	O
approach	O
is	O
only	O
necessary	O
for	O
learning	O
other	O
transformations	O
figure	O
pooling	O
with	O
downsampling	O
here	O
we	O
use	O
max-pooling	O
with	O
a	O
pool	O
width	O
of	O
three	O
and	O
a	O
stride	O
between	O
pools	O
of	O
two	O
this	O
reduces	O
the	O
representation	O
size	O
by	O
a	O
factor	O
of	O
two	O
which	O
reduces	O
the	O
computational	O
and	O
statistical	O
burden	O
on	O
the	O
next	O
layer	O
note	O
that	O
the	O
rightmost	O
pooling	O
region	O
has	O
a	O
smaller	O
size	O
but	O
must	O
be	O
included	O
if	O
we	O
do	O
not	O
want	O
to	O
ignore	O
some	O
of	O
the	O
detector	O
units	O
chapter	O
convolutional	O
networks	O
some	O
theoretical	O
work	O
gives	O
guidance	O
as	O
to	O
which	O
kinds	O
of	O
pooling	O
one	O
should	O
use	O
in	O
various	O
situations	O
it	O
is	O
also	O
possible	O
to	O
dynamically	O
pool	O
features	O
together	O
for	O
example	B
by	O
running	O
a	O
clustering	O
algorithm	O
on	O
the	O
locations	O
of	O
interesting	O
features	O
this	O
approach	O
yields	O
a	O
different	O
set	O
of	O
pooling	O
regions	O
for	O
each	O
image	O
another	O
approach	O
is	O
to	O
learn	O
a	O
single	O
pooling	O
structure	O
that	O
is	O
then	O
applied	O
to	O
all	O
images	O
boureau	O
et	O
al	O
boureau	O
et	O
al	O
jia	O
et	O
al	O
pooling	O
can	O
complicate	O
some	O
kinds	O
of	O
neural	B
network	I
architectures	O
that	O
use	O
top-down	O
information	O
such	O
as	O
boltzmann	O
machines	O
and	O
autoencoders	O
these	O
issues	O
will	O
be	O
discussed	O
further	O
when	O
we	O
present	O
these	O
types	O
of	O
networks	O
in	O
part	O
iii	O
the	O
pooling	O
in	O
convolutional	O
boltzmann	O
machines	O
is	O
presented	O
in	O
section	O
inverse-like	O
operations	O
on	O
pooling	O
units	O
needed	O
in	O
some	O
differentiable	O
networks	O
will	O
be	O
covered	O
in	O
section	O
some	O
examples	O
of	O
complete	O
convolutional	B
network	I
architectures	O
for	O
classification	B
using	O
convolution	O
and	O
pooling	O
are	O
shown	O
in	O
figure	O
convolution	O
and	O
pooling	O
as	O
an	O
infinitely	O
strong	O
prior	O
recall	B
the	O
concept	O
of	O
a	O
prior	B
probability	B
distribution	I
from	O
section	O
this	O
is	O
a	O
probability	B
distribution	I
over	O
the	O
parameters	O
of	O
a	O
model	O
that	O
encodes	O
our	O
beliefs	O
about	O
what	O
models	O
are	O
reasonable	O
before	O
we	O
have	O
seen	O
any	O
data	O
priors	O
can	O
be	O
considered	O
weak	O
or	O
strong	O
depending	O
on	O
how	O
concentrated	O
the	O
probability	O
density	O
in	O
the	O
prior	O
is	O
a	O
weak	O
prior	O
is	O
a	O
prior	O
distribution	O
with	O
high	O
entropy	O
such	O
as	O
a	O
gaussian	O
distribution	O
with	O
high	O
variance	O
such	O
a	O
prior	O
allows	O
the	O
data	O
to	O
move	O
the	O
parameters	O
more	O
or	O
less	O
freely	O
a	O
strong	O
prior	O
has	O
very	O
low	O
entropy	O
such	O
as	O
a	O
gaussian	O
distribution	O
with	O
low	O
variance	O
such	O
a	O
prior	O
plays	O
a	O
more	O
active	O
role	O
in	O
determining	O
where	O
the	O
parameters	O
end	O
up	O
an	O
infinitely	O
strong	O
prior	O
places	O
zero	O
probability	O
on	O
some	O
parameters	O
and	O
says	O
that	O
these	O
parameter	O
values	O
are	O
completely	O
forbidden	O
regardless	O
of	O
how	O
much	O
support	O
the	O
data	O
gives	O
to	O
those	O
values	O
we	O
can	O
imagine	O
a	O
convolutional	O
net	O
as	O
being	O
similar	O
to	O
a	O
fully	O
connected	O
net	O
but	O
with	O
an	O
infinitely	O
strong	O
prior	O
over	O
its	O
weights	B
this	O
infinitely	O
strong	O
prior	O
says	O
that	O
the	O
weights	B
for	O
one	O
hidden	O
unit	O
must	O
be	O
identical	O
to	O
the	O
weights	B
of	O
its	O
neighbor	O
but	O
shifted	O
in	O
space	O
the	O
prior	O
also	O
says	O
that	O
the	O
weights	B
must	O
be	O
zero	O
except	O
for	O
in	O
the	O
small	O
spatially	O
contiguous	O
receptive	B
field	I
assigned	O
to	O
that	O
hidden	O
unit	O
overall	O
we	O
can	O
think	O
of	O
the	O
use	O
of	O
convolution	O
as	O
introducing	O
an	O
infinitely	O
strong	O
prior	B
probability	B
distribution	I
over	O
the	O
parameters	O
of	O
a	O
layer	O
this	O
prior	O
chapter	O
convolutional	O
networks	O
output	O
of	O
softmax	O
output	O
of	O
softmax	O
output	O
of	O
softmax	O
class	O
probabilities	O
class	O
probabilities	O
class	O
probabilities	O
output	O
of	O
matrix	O
multiply	O
units	O
output	O
of	O
matrix	O
multiply	O
units	O
output	O
of	O
average	O
pooling	O
output	O
of	O
reshape	O
to	O
output	O
of	O
reshape	O
to	O
vector	O
units	O
vector	O
units	O
output	O
of	O
convolution	O
output	O
of	O
pooling	O
with	O
stride	O
output	O
of	O
convolution	O
relu	O
output	O
of	O
pooling	O
to	O
grid	O
output	O
of	O
convolution	O
relu	O
output	O
of	O
pooling	O
with	O
stride	O
output	O
of	O
convolution	O
relu	O
output	O
of	O
pooling	O
output	O
of	O
pooling	O
output	O
of	O
pooling	O
with	O
stride	O
output	O
of	O
convolution	O
with	O
stride	O
output	O
of	O
convolution	O
with	O
stride	O
output	O
of	O
convolution	O
relu	O
relu	O
relu	O
input	O
image	O
input	O
image	O
input	O
image	O
figure	O
examples	O
of	O
architectures	O
for	O
classification	B
with	O
convolutional	O
networks	O
the	O
specific	O
strides	O
and	O
depths	O
used	O
in	O
this	O
figure	O
are	O
not	O
advisable	O
for	O
real	O
use	O
they	O
are	O
designed	O
to	O
be	O
very	O
shallow	O
in	O
order	O
to	O
fit	O
onto	O
the	O
page	O
real	O
convolutional	O
networks	O
also	O
often	O
involve	O
significant	O
amounts	O
of	O
branching	O
unlike	O
the	O
chain	O
structures	O
used	O
here	O
for	O
simplicity	O
convolutional	B
network	I
that	O
processes	O
a	O
fixed	O
image	O
size	O
after	O
alternating	O
between	O
convolution	O
and	O
pooling	O
for	O
a	O
few	O
layers	O
the	O
tensor	O
for	O
the	O
convolutional	O
feature	B
map	O
is	O
reshaped	O
to	O
flatten	O
out	O
the	O
spatial	O
dimensions	O
the	O
rest	O
of	O
the	O
network	O
is	O
an	O
ordinary	O
feedforward	O
network	O
classifier	O
as	O
described	O
in	O
chapter	O
convolutional	B
network	I
that	O
processes	O
a	O
variable-sized	O
image	O
but	O
still	O
maintains	O
a	O
fully	O
connected	O
section	O
this	O
network	O
uses	O
a	O
pooling	O
operation	B
with	O
variably-sized	O
pools	O
but	O
a	O
fixed	O
number	O
of	O
pools	O
in	O
order	O
to	O
provide	O
a	O
fixed-size	O
vector	O
of	O
units	O
to	O
the	O
fully	O
connected	O
portion	O
of	O
the	O
network	O
a	O
convolutional	B
network	I
that	O
does	O
not	O
have	O
any	O
fully	O
connected	O
weight	O
layer	O
instead	O
the	O
last	O
convolutional	O
layer	O
outputs	O
one	O
feature	B
map	O
per	O
class	O
the	O
model	O
presumably	O
learns	O
a	O
map	O
of	O
how	O
likely	O
each	O
class	O
is	O
to	O
occur	O
at	O
each	O
spatial	O
location	O
averaging	O
a	O
feature	B
map	O
down	O
to	O
a	O
single	O
value	O
provides	O
the	O
argument	O
to	O
the	O
softmax	O
classifier	O
at	O
the	O
top	O
chapter	O
convolutional	O
networks	O
says	O
that	O
the	O
function	O
the	O
layer	O
should	O
learn	O
contains	O
only	O
local	O
interactions	O
and	O
is	O
equivariant	O
to	O
translation	O
likewise	O
the	O
use	O
of	O
pooling	O
is	O
an	O
infinitely	O
strong	O
prior	O
that	O
each	O
unit	O
should	O
be	O
invariant	O
to	O
small	O
translations	O
of	O
course	O
implementing	O
a	O
convolutional	O
net	O
as	O
a	O
fully	O
connected	O
net	O
with	O
an	O
infinitely	O
strong	O
prior	O
would	O
be	O
extremely	O
computationally	O
wasteful	O
but	O
thinking	O
of	O
a	O
convolutional	O
net	O
as	O
a	O
fully	O
connected	O
net	O
with	O
an	O
infinitely	O
strong	O
prior	O
can	O
give	O
us	O
some	O
insights	O
into	O
how	O
convolutional	O
nets	O
work	O
one	O
key	O
insight	O
is	O
that	O
convolution	O
and	O
pooling	O
can	O
cause	O
underfitting	O
like	O
any	O
prior	O
convolution	O
and	O
pooling	O
are	O
only	O
useful	O
when	O
the	O
assumptions	O
made	O
by	O
the	O
prior	O
are	O
reasonably	O
accurate	O
if	O
a	O
task	O
relies	O
on	O
preserving	O
precise	O
spatial	O
information	O
then	O
using	O
pooling	O
on	O
all	O
features	O
can	O
increase	O
the	O
training	B
error	I
some	O
convolutional	B
network	I
architectures	O
are	O
designed	O
to	O
use	O
pooling	O
on	O
some	O
channels	O
but	O
not	O
on	O
other	O
channels	O
in	O
order	O
to	O
get	O
both	O
highly	O
invariant	O
features	O
and	O
features	O
that	O
will	O
not	O
underfit	O
when	O
the	O
translation	O
invariance	B
prior	O
is	O
incorrect	O
when	O
a	O
task	O
involves	O
incorporating	O
information	O
from	O
very	O
distant	O
locations	O
in	O
the	O
input	O
then	O
the	O
prior	O
imposed	O
by	O
convolution	O
may	O
be	O
inappropriate	O
szegedy	O
et	O
al	O
another	O
key	O
insight	O
from	O
this	O
view	O
is	O
that	O
we	O
should	O
only	O
compare	O
convolutional	O
models	O
to	O
other	O
convolutional	O
models	O
in	O
benchmarks	O
of	O
statistical	O
learning	O
performance	O
models	O
that	O
do	O
not	O
use	O
convolution	O
would	O
be	O
able	O
to	O
learn	O
even	O
if	O
we	O
permuted	O
all	O
of	O
the	O
pixels	O
in	O
the	O
image	O
for	O
many	O
image	O
datasets	O
there	O
are	O
separate	O
benchmarks	O
for	O
models	O
that	O
are	O
permutation	O
invariant	O
and	O
must	O
discover	O
the	O
concept	O
of	O
topology	O
via	O
learning	O
and	O
models	O
that	O
have	O
the	O
knowledge	O
of	O
spatial	O
relationships	O
hard-coded	O
into	O
them	O
by	O
their	O
designer	O
variants	O
of	O
the	O
basic	O
convolution	O
function	O
when	O
discussing	O
convolution	O
in	O
the	O
context	O
of	O
neural	O
networks	O
we	O
usually	O
do	O
not	O
refer	O
exactly	O
to	O
the	O
standard	O
discrete	O
convolution	O
operation	B
as	O
it	O
is	O
usually	O
understood	O
in	O
the	O
mathematical	O
literature	O
the	O
functions	O
used	O
in	O
practice	O
differ	O
slightly	O
here	O
we	O
describe	O
these	O
differences	O
in	O
detail	O
and	O
highlight	O
some	O
useful	O
properties	O
of	O
the	O
functions	O
used	O
in	O
neural	O
networks	O
first	O
when	O
we	O
refer	O
to	O
convolution	O
in	O
the	O
context	O
of	O
neural	O
networks	O
we	O
usually	O
actually	O
mean	O
an	O
operation	B
that	O
consists	O
of	O
many	O
applications	O
of	O
convolution	O
in	O
parallel	O
this	O
is	O
because	O
convolution	O
with	O
a	O
single	O
kernel	O
can	O
only	O
extract	O
one	O
kind	O
of	O
feature	B
albeit	O
at	O
many	O
spatial	O
locations	O
usually	O
we	O
want	O
each	O
layer	O
of	O
our	O
network	O
to	O
extract	O
many	O
kinds	O
of	O
features	O
at	O
many	O
locations	O
chapter	O
convolutional	O
networks	O
additionally	O
the	O
input	O
is	O
usually	O
not	O
just	O
a	O
grid	O
of	O
real	O
values	O
rather	O
it	O
is	O
a	O
grid	O
of	O
vector-valued	O
observations	O
for	O
example	B
a	O
color	O
image	O
has	O
a	O
red	O
green	O
and	O
blue	O
intensity	O
at	O
each	O
pixel	O
in	O
a	O
multilayer	O
convolutional	B
network	I
the	O
input	O
to	O
the	O
second	O
layer	O
is	O
the	O
output	O
of	O
the	O
first	O
layer	O
which	O
usually	O
has	O
the	O
output	O
of	O
many	O
different	O
convolutions	O
at	O
each	O
position	O
when	O
working	O
with	O
images	O
we	O
usually	O
think	O
of	O
the	O
input	O
and	O
output	O
of	O
the	O
convolution	O
as	O
being	O
tensors	O
with	O
one	O
index	O
into	O
the	O
different	O
channels	O
and	O
two	O
indices	O
into	O
the	O
spatial	O
coordinates	O
of	O
each	O
channel	O
software	O
implementations	O
usually	O
work	O
in	O
batch	O
mode	O
so	O
they	O
will	O
actually	O
use	O
tensors	O
with	O
the	O
fourth	O
axis	O
indexing	O
different	O
examples	O
in	O
the	O
batch	O
but	O
we	O
will	O
omit	O
the	O
batch	O
axis	O
in	O
our	O
description	O
here	O
for	O
simplicity	O
because	O
convolutional	O
networks	O
usually	O
use	O
multi-channel	O
convolution	O
the	O
linear	O
operations	O
they	O
are	O
based	O
on	O
are	O
not	O
guaranteed	O
to	O
be	O
commutative	O
even	O
if	O
kernel-flipping	O
is	O
used	O
these	O
multi-channel	O
operations	O
are	O
only	O
commutative	O
if	O
each	O
operation	B
has	O
the	O
same	O
number	O
of	O
output	O
channels	O
as	O
input	O
channels	O
assume	O
we	O
have	O
a	O
kernel	O
tensor	O
k	O
with	O
element	O
kijkl	O
giving	O
the	O
connection	O
strength	O
between	O
a	O
unit	O
in	O
channel	O
i	O
of	O
the	O
output	O
and	O
a	O
unit	O
in	O
channel	O
j	O
of	O
the	O
input	O
with	O
an	O
offset	O
of	O
k	O
rows	O
and	O
l	O
columns	O
between	O
the	O
output	O
unit	O
and	O
the	O
input	O
unit	O
assume	O
our	O
input	O
consists	O
of	O
observed	O
data	O
v	O
with	O
element	O
vijk	O
giving	O
the	O
value	O
of	O
the	O
input	O
unit	O
within	O
channel	O
i	O
at	O
row	O
j	O
and	O
column	O
k	O
assume	O
our	O
output	O
consists	O
of	O
z	O
with	O
the	O
same	O
format	O
as	O
v	O
if	O
z	O
is	O
produced	O
by	O
convolving	O
k	O
across	O
without	O
flipping	O
then	O
v	O
k	O
zijk	O
lmn	O
vlj	O
m	O
n	O
where	O
the	O
summation	O
over	O
l	O
m	O
and	O
n	O
is	O
over	O
all	O
values	O
for	O
which	O
the	O
tensor	O
indexing	O
operations	O
inside	O
the	O
summation	O
is	O
valid	O
in	O
linear	O
algebra	O
notation	O
we	O
index	O
into	O
arrays	O
using	O
a	O
in	O
the	O
above	O
formula	O
programming	O
languages	O
such	O
as	O
c	O
and	O
python	O
index	O
starting	O
from	O
rendering	O
the	O
above	O
expression	O
even	O
simpler	O
for	O
the	O
first	O
entry	O
this	O
necessitates	O
the	O
we	O
may	O
want	O
to	O
skip	O
over	O
some	O
positions	O
of	O
the	O
kernel	O
in	O
order	O
to	O
reduce	O
the	O
computational	O
cost	O
the	O
expense	O
of	O
not	O
extracting	O
our	O
features	O
as	O
finely	O
we	O
can	O
think	O
of	O
this	O
as	O
downsampling	O
the	O
output	O
of	O
the	O
full	O
convolution	O
function	O
if	O
we	O
want	O
to	O
sample	O
only	O
every	O
s	O
pixels	O
in	O
each	O
direction	O
in	O
the	O
output	O
then	O
we	O
can	O
define	O
a	O
downsampled	O
convolution	O
function	O
such	O
that	O
c	O
zijk	O
c	O
k	O
v	O
s	O
ijk	O
s	O
m	O
k	O
kilmn	O
s	O
n	O
vl	O
j	O
lmn	O
we	O
refer	O
to	O
s	O
as	O
the	O
stride	O
of	O
this	O
downsampled	O
convolution	O
it	O
is	O
also	O
possible	O
chapter	O
convolutional	O
networks	O
to	O
define	O
a	O
separate	O
stride	O
for	O
each	O
direction	O
of	O
motion	O
see	O
figure	O
illustration	O
for	O
an	O
one	O
essential	O
feature	B
of	O
any	O
convolutional	B
network	I
implementation	O
is	O
the	O
ability	O
to	O
implicitly	O
zero-pad	O
the	O
input	O
v	O
in	O
order	O
to	O
make	O
it	O
wider	O
without	O
this	O
feature	B
the	O
width	O
of	O
the	O
representation	O
shrinks	O
by	O
one	O
pixel	O
less	O
than	O
the	O
kernel	O
width	O
at	O
each	O
layer	O
zero	O
padding	O
the	O
input	O
allows	O
us	O
to	O
control	O
the	O
kernel	O
width	O
and	O
the	O
size	O
of	O
the	O
output	O
independently	O
without	O
zero	O
padding	O
we	O
are	O
forced	O
to	O
choose	O
between	O
shrinking	O
the	O
spatial	O
extent	O
of	O
the	O
network	O
rapidly	O
and	O
using	O
small	O
kernels	O
both	O
scenarios	O
that	O
significantly	O
limit	O
the	O
expressive	O
power	O
of	O
the	O
network	O
see	O
figure	O
for	O
an	O
example	B
three	O
special	O
cases	O
of	O
the	O
zero-padding	O
setting	O
are	O
worth	O
mentioning	O
one	O
is	O
the	O
extreme	O
case	O
in	O
which	O
no	O
zero-padding	O
is	O
used	O
whatsoever	O
and	O
the	O
convolution	O
kernel	O
is	O
only	O
allowed	O
to	O
visit	O
positions	O
where	O
the	O
entire	O
kernel	O
is	O
contained	O
entirely	O
within	O
the	O
image	O
in	O
matlab	O
terminology	O
this	O
is	O
called	O
valid	O
convolution	O
in	O
this	O
case	O
all	O
pixels	O
in	O
the	O
output	O
are	O
a	O
function	O
of	O
the	O
same	O
number	O
of	O
pixels	O
in	O
the	O
input	O
so	O
the	O
behavior	O
of	O
an	O
output	O
pixel	O
is	O
somewhat	O
more	O
regular	O
however	O
the	O
size	O
of	O
the	O
output	O
shrinks	O
at	O
each	O
layer	O
if	O
the	O
input	O
image	O
has	O
width	O
m	O
and	O
the	O
kernel	O
has	O
width	O
k	O
the	O
output	O
will	O
be	O
of	O
width	O
m	O
k	O
the	O
rate	O
of	O
this	O
shrinkage	O
can	O
be	O
dramatic	O
if	O
the	O
kernels	O
used	O
are	O
large	O
since	O
the	O
shrinkage	O
is	O
greater	O
than	O
it	O
limits	O
the	O
number	O
of	O
convolutional	O
layers	O
that	O
can	O
be	O
included	O
in	O
the	O
network	O
as	O
layers	O
are	O
added	O
the	O
spatial	O
dimension	O
of	O
the	O
network	O
will	O
eventually	O
drop	O
to	O
at	O
which	O
point	O
additional	O
layers	O
cannot	O
meaningfully	O
be	O
considered	O
convolutional	O
another	O
special	O
case	O
of	O
the	O
zero-padding	O
setting	O
is	O
when	O
just	O
enough	O
zero-padding	O
is	O
added	O
to	O
keep	O
the	O
size	O
of	O
the	O
output	O
equal	O
to	O
the	O
size	O
of	O
the	O
input	O
matlab	O
calls	O
this	O
same	O
convolution	O
in	O
this	O
case	O
the	O
network	O
can	O
contain	O
as	O
many	O
convolutional	O
layers	O
as	O
the	O
available	O
hardware	O
can	O
support	O
since	O
the	O
operation	B
of	O
convolution	O
does	O
not	O
modify	O
the	O
architectural	O
possibilities	O
available	O
to	O
the	O
next	O
layer	O
however	O
the	O
input	O
pixels	O
near	O
the	O
border	O
influence	O
fewer	O
output	O
pixels	O
than	O
the	O
input	O
pixels	O
near	O
the	O
center	O
this	O
can	O
make	O
the	O
border	O
pixels	O
somewhat	O
underrepresented	O
in	O
the	O
model	O
this	O
motivates	O
the	O
other	O
extreme	O
case	O
which	O
matlab	O
refers	O
to	O
as	O
full	O
convolution	O
in	O
which	O
enough	O
zeroes	O
are	O
added	O
for	O
every	O
pixel	O
to	O
be	O
visited	O
k	O
times	O
in	O
each	O
direction	O
resulting	O
in	O
an	O
output	O
image	O
of	O
width	O
m	O
k	O
in	O
this	O
case	O
the	O
output	O
pixels	O
near	O
the	O
border	O
are	O
a	O
function	O
of	O
fewer	O
pixels	O
than	O
the	O
output	O
pixels	O
near	O
the	O
center	O
this	O
can	O
make	O
it	O
difficult	O
to	O
learn	O
a	O
single	O
kernel	O
that	O
performs	O
well	O
at	O
all	O
positions	O
in	O
the	O
convolutional	O
feature	B
map	O
usually	O
the	O
optimal	O
amount	O
of	O
zero	O
padding	O
terms	O
of	O
test	B
set	I
classification	B
accuracy	B
lies	O
somewhere	O
between	O
valid	O
and	O
same	O
convolution	O
chapter	O
convolutional	O
networks	O
strided	O
convolution	O
downsampling	O
convolution	O
figure	O
convolution	O
with	O
a	O
stride	O
in	O
this	O
example	B
we	O
use	O
a	O
stride	O
of	O
two	O
with	O
a	O
stride	O
length	O
of	O
two	O
implemented	O
in	O
a	O
single	O
operation	B
with	O
a	O
stride	O
greater	O
than	O
one	O
pixel	O
is	O
mathematically	O
equivalent	O
to	O
convolution	O
with	O
unit	O
stride	O
followed	O
by	O
downsampling	O
obviously	O
the	O
two-step	O
approach	O
involving	O
downsampling	O
is	O
computationally	O
wasteful	O
because	O
it	O
computes	O
many	O
values	O
that	O
are	O
then	O
discarded	O
chapter	O
convolutional	O
networks	O
figure	O
the	O
effect	O
of	O
zero	O
padding	O
on	O
network	O
size	O
consider	O
a	O
convolutional	B
network	I
with	O
a	O
kernel	O
of	O
width	O
six	O
at	O
every	O
layer	O
in	O
this	O
example	B
we	O
do	O
not	O
use	O
any	O
pooling	O
so	O
only	O
the	O
convolution	O
operation	B
itself	O
shrinks	O
the	O
network	O
size	O
this	O
convolutional	B
network	I
we	O
do	O
not	O
use	O
any	O
implicit	O
zero	O
padding	O
this	O
causes	O
the	O
representation	O
to	O
shrink	O
by	O
five	O
pixels	O
at	O
each	O
layer	O
starting	O
from	O
an	O
input	O
of	O
sixteen	O
pixels	O
we	O
are	O
only	O
able	O
to	O
have	O
three	O
convolutional	O
layers	O
and	O
the	O
last	O
layer	O
does	O
not	O
ever	O
move	O
the	O
kernel	O
so	O
arguably	O
only	O
two	O
of	O
the	O
layers	O
are	O
truly	O
convolutional	O
the	O
rate	O
of	O
shrinking	O
can	O
be	O
mitigated	O
by	O
using	O
smaller	O
kernels	O
but	O
smaller	O
kernels	O
are	O
less	O
expressive	O
and	O
some	O
shrinking	O
is	O
inevitable	O
in	O
this	O
kind	O
of	O
architecture	O
by	O
adding	O
five	O
implicit	O
zeroes	O
to	O
each	O
layer	O
we	O
prevent	O
the	O
representation	O
from	O
shrinking	O
with	O
depth	O
this	O
allows	O
us	O
to	O
make	O
an	O
arbitrarily	O
deep	O
convolutional	B
network	I
chapter	O
convolutional	O
networks	O
lecun	O
in	O
some	O
cases	O
we	O
do	O
not	O
actually	O
want	O
to	O
use	O
convolution	O
but	O
rather	O
locally	O
connected	O
layers	O
in	O
this	O
case	O
the	O
adjacency	O
matrix	O
in	O
the	O
graph	O
of	O
our	O
mlp	O
is	O
the	O
same	O
but	O
every	O
connection	O
has	O
its	O
own	O
weight	O
specified	O
by	O
a	O
tensor	O
w	O
the	O
indices	O
into	O
w	O
are	O
respectively	O
i	O
the	O
output	O
channel	O
j	O
the	O
output	O
row	O
k	O
the	O
output	O
column	O
l	O
the	O
input	O
channel	O
m	O
the	O
row	O
offset	O
within	O
the	O
input	O
and	O
n	O
the	O
column	O
offset	O
within	O
the	O
input	O
the	O
linear	O
part	O
of	O
a	O
locally	O
connected	O
layer	O
is	O
then	O
given	O
by	O
zijk	O
m	O
n	O
lmn	O
this	O
is	O
sometimes	O
also	O
called	O
unshared	O
convolution	O
because	O
it	O
is	O
a	O
similar	O
operation	B
to	O
discrete	O
convolution	O
with	O
a	O
small	O
kernel	O
but	O
without	O
sharing	O
parameters	O
across	O
locations	O
figure	O
compares	O
local	O
connections	O
convolution	O
and	O
full	O
connections	O
locally	O
connected	O
layers	O
are	O
useful	O
when	O
we	O
know	O
that	O
each	O
feature	B
should	O
be	O
a	O
function	O
of	O
a	O
small	O
part	O
of	O
space	O
but	O
there	O
is	O
no	O
reason	O
to	O
think	O
that	O
the	O
same	O
feature	B
should	O
occur	O
across	O
all	O
of	O
space	O
for	O
example	B
if	O
we	O
want	O
to	O
tell	O
if	O
an	O
image	O
is	O
a	O
picture	O
of	O
a	O
face	O
we	O
only	O
need	O
to	O
look	O
for	O
the	O
mouth	O
in	O
the	O
bottom	O
half	O
of	O
the	O
image	O
it	O
can	O
also	O
be	O
useful	O
to	O
make	O
versions	O
of	O
convolution	O
or	O
locally	O
connected	O
layers	O
in	O
which	O
the	O
connectivity	O
is	O
further	O
restricted	O
for	O
example	B
to	O
constrain	O
each	O
output	O
channel	O
i	O
to	O
be	O
a	O
function	O
of	O
only	O
a	O
subset	O
of	O
the	O
input	O
channels	O
l	O
a	O
common	O
way	O
to	O
do	O
this	O
is	O
to	O
make	O
the	O
first	O
m	O
output	O
channels	O
connect	O
to	O
only	O
the	O
first	O
n	O
input	O
channels	O
the	O
second	O
m	O
output	O
channels	O
connect	O
to	O
only	O
the	O
second	O
n	O
input	O
channels	O
and	O
so	O
on	O
see	O
figure	O
for	O
an	O
example	B
modeling	O
interactions	O
between	O
few	O
channels	O
allows	O
the	O
network	O
to	O
have	O
fewer	O
parameters	O
in	O
order	O
to	O
reduce	O
memory	O
consumption	O
and	O
increase	O
statistical	O
efficiency	O
and	O
also	O
reduces	O
the	O
amount	O
of	O
computation	O
needed	O
to	O
perform	O
forward	O
and	O
back-propagation	B
it	O
accomplishes	O
these	O
goals	O
without	O
reducing	O
the	O
number	O
of	O
hidden	O
units	O
tiled	B
convolution	I
gregor	O
and	O
lecun	O
le	O
et	O
al	O
offers	O
a	O
compromise	O
between	O
a	O
convolutional	O
layer	O
and	O
a	O
locally	O
connected	O
layer	O
rather	O
than	O
learning	O
a	O
separate	O
set	O
of	O
weights	B
at	O
spatial	O
location	O
we	O
learn	O
a	O
set	O
of	O
kernels	O
that	O
we	O
rotate	O
through	O
as	O
we	O
move	O
through	O
space	O
this	O
means	O
that	O
immediately	O
neighboring	O
locations	O
will	O
have	O
different	O
filters	O
like	O
in	O
a	O
locally	O
connected	O
layer	O
but	O
the	O
memory	O
requirements	O
for	O
storing	O
the	O
parameters	O
will	O
increase	O
only	O
by	O
a	O
factor	O
of	O
the	O
size	O
of	O
this	O
set	O
of	O
kernels	O
rather	O
than	O
the	O
size	O
of	O
the	O
entire	O
output	O
feature	B
map	O
see	O
figure	O
for	O
a	O
comparison	O
of	O
locally	O
connected	O
layers	O
tiled	B
convolution	I
and	O
standard	O
convolution	O
every	O
chapter	O
convolutional	O
networks	O
a	O
b	O
c	O
d	O
e	O
f	O
g	O
h	O
i	O
a	O
b	O
a	O
b	O
a	O
b	O
a	O
b	O
a	O
figure	O
comparison	O
of	O
local	O
connections	O
convolution	O
and	O
full	O
connections	O
locally	O
connected	O
layer	O
with	O
a	O
patch	O
size	O
of	O
two	O
pixels	O
each	O
edge	O
is	O
labeled	O
with	O
a	O
unique	O
letter	O
to	O
show	O
that	O
each	O
edge	O
is	O
associated	O
with	O
its	O
own	O
weight	O
parameter	O
convolutional	O
layer	O
with	O
a	O
kernel	O
width	O
of	O
two	O
pixels	O
this	O
model	O
has	O
exactly	O
the	O
same	O
connectivity	O
as	O
the	O
locally	O
connected	O
layer	O
the	O
difference	O
lies	O
not	O
in	O
which	O
units	O
interact	O
with	O
each	O
other	O
but	O
in	O
how	O
the	O
parameters	O
are	O
shared	O
the	O
locally	O
connected	O
layer	O
has	O
no	O
parameter	O
sharing	O
the	O
convolutional	O
layer	O
uses	O
the	O
same	O
two	O
weights	B
repeatedly	O
across	O
the	O
entire	O
input	O
as	O
indicated	O
by	O
the	O
repetition	O
of	O
the	O
letters	O
labeling	O
each	O
edge	O
fully	O
connected	O
layer	O
resembles	O
a	O
locally	O
connected	O
layer	O
in	O
the	O
sense	O
that	O
each	O
edge	O
has	O
its	O
own	O
parameter	O
are	O
too	O
many	O
to	O
label	O
explicitly	O
with	O
letters	O
in	O
this	O
diagram	O
however	O
it	O
does	O
not	O
have	O
the	O
restricted	O
connectivity	O
of	O
the	O
locally	O
connected	O
layer	O
chapter	O
convolutional	O
networks	O
output	O
tensor	O
input	O
tensor	O
s	O
e	O
t	O
a	O
n	O
i	O
d	O
r	O
o	O
o	O
c	O
l	O
e	O
n	O
n	O
a	O
h	O
c	O
spatial	O
coordinates	O
figure	O
a	O
convolutional	B
network	I
with	O
the	O
first	O
two	O
output	O
channels	O
connected	O
to	O
only	O
the	O
first	O
two	O
input	O
channels	O
and	O
the	O
second	O
two	O
output	O
channels	O
connected	O
to	O
only	O
the	O
second	O
two	O
input	O
channels	O
chapter	O
convolutional	O
networks	O
a	O
b	O
c	O
d	O
e	O
f	O
g	O
h	O
i	O
a	O
b	O
c	O
d	O
a	O
b	O
c	O
d	O
a	O
a	O
b	O
a	O
b	O
a	O
b	O
a	O
b	O
a	O
figure	O
a	O
comparison	O
of	O
locally	O
connected	O
layers	O
tiled	B
convolution	I
and	O
standard	O
convolution	O
all	O
three	O
have	O
the	O
same	O
sets	O
of	O
connections	O
between	O
units	O
when	O
the	O
same	O
size	O
of	O
kernel	O
is	O
used	O
this	O
diagram	O
illustrates	O
the	O
use	O
of	O
a	O
kernel	O
that	O
is	O
two	O
pixels	O
wide	O
the	O
differences	O
between	O
the	O
methods	O
lies	O
in	O
how	O
they	O
share	O
parameters	O
locally	O
connected	O
layer	O
has	O
no	O
sharing	O
at	O
all	O
we	O
indicate	O
that	O
each	O
connection	O
has	O
its	O
own	O
weight	O
by	O
labeling	O
each	O
connection	O
with	O
a	O
unique	O
letter	O
tiled	B
convolution	I
has	O
a	O
set	O
of	O
t	O
different	O
kernels	O
here	O
we	O
illustrate	O
the	O
case	O
of	O
t	O
one	O
of	O
these	O
kernels	O
has	O
edges	O
labeled	O
a	O
and	O
b	O
while	O
the	O
other	O
has	O
edges	O
labeled	O
c	O
and	O
d	O
each	O
time	O
we	O
move	O
one	O
pixel	O
to	O
the	O
right	O
in	O
the	O
output	O
we	O
move	O
on	O
to	O
using	O
a	O
different	O
kernel	O
this	O
means	O
that	O
like	O
the	O
locally	O
connected	O
layer	O
neighboring	O
units	O
in	O
the	O
output	O
have	O
different	O
parameters	O
unlike	O
the	O
locally	O
connected	O
layer	O
after	O
we	O
have	O
gone	O
through	O
all	O
t	O
available	O
kernels	O
we	O
cycle	O
back	O
to	O
the	O
first	O
kernel	O
if	O
two	O
output	O
units	O
are	O
separated	O
by	O
a	O
multiple	O
of	O
t	O
steps	O
then	O
they	O
share	O
parameters	O
traditional	O
convolution	O
is	O
equivalent	O
to	O
tiled	B
convolution	I
with	O
t	O
there	O
is	O
only	O
one	O
kernel	O
and	O
it	O
is	O
applied	O
everywhere	O
as	O
indicated	O
in	O
the	O
diagram	O
by	O
using	O
the	O
kernel	O
with	O
weights	B
labeled	O
a	O
and	O
b	O
everywhere	O
chapter	O
convolutional	O
networks	O
to	O
define	O
tiled	B
convolution	I
algebraically	O
let	O
k	O
be	O
a	O
tensor	O
where	O
two	O
of	O
the	O
dimensions	O
correspond	O
to	O
different	O
locations	O
in	O
the	O
output	O
map	O
rather	O
than	O
having	O
a	O
separate	O
index	O
for	O
each	O
location	O
in	O
the	O
output	O
map	O
output	O
locations	O
cycle	O
through	O
a	O
set	O
of	O
t	O
different	O
choices	O
of	O
kernel	O
stack	O
in	O
each	O
direction	O
if	O
t	O
is	O
equal	O
to	O
the	O
output	O
width	O
this	O
is	O
the	O
same	O
as	O
a	O
locally	O
connected	O
layer	O
zijk	O
lmn	O
vlj	O
m	O
n	O
t	O
t	O
is	O
the	O
modulo	O
operation	B
with	O
where	O
it	O
is	O
straightforward	O
to	O
generalize	O
this	O
equation	O
to	O
use	O
a	O
different	O
tiling	O
range	O
for	O
each	O
dimension	O
t	O
etc	O
tt	O
both	O
locally	O
connected	O
layers	O
and	O
tiled	O
convolutional	O
layers	O
have	O
an	O
interesting	O
interaction	O
with	O
max-pooling	O
the	O
detector	O
units	O
of	O
these	O
layers	O
are	O
driven	O
by	O
different	O
filters	O
if	O
these	O
filters	O
learn	O
to	O
detect	O
different	O
transformed	O
versions	O
of	O
the	O
same	O
underlying	O
features	O
then	O
the	O
max-pooled	O
units	O
become	O
invariant	O
to	O
the	O
learned	O
transformation	O
figure	O
convolutional	O
layers	O
are	O
hard-coded	O
to	O
be	O
invariant	O
specifically	O
to	O
translation	O
other	O
operations	O
besides	O
convolution	O
are	O
usually	O
necessary	O
to	O
implement	O
a	O
convolutional	B
network	I
to	O
perform	O
learning	O
one	O
must	O
be	O
able	O
to	O
compute	O
the	O
gradient	B
with	O
respect	O
to	O
the	O
kernel	O
given	O
the	O
gradient	B
with	O
respect	O
to	O
the	O
outputs	O
in	O
some	O
simple	O
cases	O
this	O
operation	B
can	O
be	O
performed	O
using	O
the	O
convolution	O
operation	B
but	O
many	O
cases	O
of	O
interest	O
including	O
the	O
case	O
of	O
stride	O
greater	O
than	O
do	O
not	O
have	O
this	O
property	O
recall	B
that	O
convolution	O
is	O
a	O
linear	O
operation	B
and	O
can	O
thus	O
be	O
described	O
as	O
a	O
matrix	O
multiplication	O
we	O
first	O
reshape	O
the	O
input	O
tensor	O
into	O
a	O
flat	O
vector	O
the	O
matrix	O
involved	O
is	O
a	O
function	O
of	O
the	O
convolution	O
kernel	O
the	O
matrix	O
is	O
sparse	O
and	O
each	O
element	O
of	O
the	O
kernel	O
is	O
copied	O
to	O
several	O
elements	O
of	O
the	O
matrix	O
this	O
view	O
helps	O
us	O
to	O
derive	O
some	O
of	O
the	O
other	O
operations	O
needed	O
to	O
implement	O
a	O
convolutional	B
network	I
multiplication	O
by	O
the	O
transpose	O
of	O
the	O
matrix	O
defined	O
by	O
convolution	O
is	O
one	O
such	O
operation	B
this	O
is	O
the	O
operation	B
needed	O
to	O
back-propagate	O
error	O
derivatives	O
through	O
a	O
convolutional	O
layer	O
so	O
it	O
is	O
needed	O
to	O
train	O
convolutional	O
networks	O
that	O
have	O
more	O
than	O
one	O
hidden	B
layer	I
this	O
same	O
operation	B
is	O
also	O
needed	O
if	O
we	O
wish	O
to	O
reconstruct	O
the	O
visible	O
units	O
from	O
the	O
hidden	O
units	O
reconstructing	O
the	O
visible	O
units	O
is	O
an	O
operation	B
commonly	O
used	O
in	O
the	O
models	O
described	O
in	O
part	O
of	O
this	O
book	O
such	O
as	O
autoencoders	O
rbms	O
and	O
sparse	O
coding	O
transpose	O
convolution	O
is	O
necessary	O
to	O
construct	O
convolutional	O
versions	O
of	O
those	O
models	O
like	O
the	O
kernel	O
gradient	B
operation	B
this	O
input	O
gradient	B
operation	B
can	O
be	O
simard	O
et	O
al	O
iii	O
chapter	O
convolutional	O
networks	O
implemented	O
using	O
a	O
convolution	O
in	O
some	O
cases	O
but	O
in	O
the	O
general	O
case	O
requires	O
a	O
third	O
operation	B
to	O
be	O
implemented	O
care	O
must	O
be	O
taken	O
to	O
coordinate	O
this	O
transpose	O
operation	B
with	O
the	O
forward	B
propagation	I
the	O
size	O
of	O
the	O
output	O
that	O
the	O
transpose	O
operation	B
should	O
return	O
depends	O
on	O
the	O
zero	O
padding	O
policy	B
and	O
stride	O
of	O
the	O
forward	B
propagation	I
operation	B
as	O
well	O
as	O
the	O
size	O
of	O
the	O
forward	B
propagation	I
s	O
output	O
map	O
in	O
some	O
cases	O
multiple	O
sizes	O
of	O
input	O
to	O
forward	B
propagation	I
can	O
result	O
in	O
the	O
same	O
size	O
of	O
output	O
map	O
so	O
the	O
transpose	O
operation	B
must	O
be	O
explicitly	O
told	O
what	O
the	O
size	O
of	O
the	O
original	O
input	O
was	O
these	O
three	O
operations	O
convolution	O
backprop	O
from	O
output	O
to	O
weights	B
and	O
backprop	O
from	O
output	O
to	O
inputs	O
are	O
sufficient	O
to	O
compute	O
all	O
of	O
the	O
gradients	O
needed	O
to	O
train	O
any	O
depth	O
of	O
feedforward	O
convolutional	B
network	I
as	O
well	O
as	O
to	O
train	O
convolutional	O
networks	O
with	O
reconstruction	O
functions	O
based	O
on	O
the	O
transpose	O
of	O
convolution	O
see	O
for	O
a	O
full	O
derivation	O
of	O
the	O
equations	O
in	O
the	O
fully	O
general	O
multi-dimensional	O
multi-example	O
case	O
to	O
give	O
a	O
sense	O
of	O
how	O
these	O
equations	O
work	O
we	O
present	O
the	O
two	O
dimensional	O
single	O
example	B
version	O
here	O
goodfellow	O
suppose	O
we	O
want	O
to	O
train	O
a	O
convolutional	B
network	I
that	O
incorporates	O
strided	O
convolution	O
of	O
kernel	O
stack	O
k	O
applied	O
to	O
multi-channel	O
image	O
v	O
with	O
stride	O
s	O
as	O
s	O
as	O
in	O
equation	O
defined	O
by	O
ck	O
v	O
suppose	O
we	O
want	O
to	O
minimize	O
some	O
loss	O
during	O
forward	B
propagation	I
we	O
will	O
need	O
to	O
use	O
c	O
itself	O
to	O
function	O
j	O
k	O
output	O
z	O
which	O
is	O
then	O
propagated	O
through	O
the	O
rest	O
of	O
the	O
network	O
and	O
used	O
to	O
compute	O
the	O
cost	O
function	O
j	O
during	O
back-propagation	B
we	O
will	O
receive	O
a	O
tensor	O
g	O
such	O
that	O
gijk	O
k	O
j	O
zijk	O
to	O
train	O
the	O
network	O
we	O
need	O
to	O
compute	O
the	O
derivatives	O
with	O
respect	O
to	O
the	O
weights	B
in	O
the	O
kernel	O
to	O
do	O
so	O
we	O
can	O
use	O
a	O
function	O
g	O
v	O
s	O
kijkl	O
j	O
k	O
mn	O
gimnvj	O
m	O
s	O
k	O
n	O
s	O
l	O
if	O
this	O
layer	O
is	O
not	O
the	O
bottom	O
layer	O
of	O
the	O
network	O
we	O
will	O
need	O
to	O
compute	O
the	O
gradient	B
with	O
respect	O
to	O
v	O
in	O
order	O
to	O
back-propagate	O
the	O
error	O
farther	O
down	O
to	O
do	O
so	O
we	O
can	O
use	O
a	O
function	O
vijk	O
h	O
g	O
ijk	O
s	O
j	O
k	O
kqimpgqln	O
lm	O
s	O
t	O
s	O
m	O
j	O
l	O
np	O
s	O
t	O
n	O
s	O
p	O
k	O
q	O
autoencoder	O
networks	O
described	O
in	O
chapter	O
are	O
feedforward	O
networks	O
trained	O
to	O
copy	O
their	O
input	O
to	O
their	O
output	O
a	O
simple	O
example	B
is	O
the	O
pca	O
algorithm	O
chapter	O
convolutional	O
networks	O
w	O
x	O
that	O
copies	O
its	O
input	O
x	O
to	O
an	O
approximate	O
reconstruction	O
r	O
using	O
the	O
function	O
w	O
it	O
is	O
common	O
for	O
more	O
general	O
autoencoders	O
to	O
use	O
multiplication	O
by	O
the	O
transpose	O
of	O
the	O
weight	O
matrix	O
just	O
as	O
pca	O
does	O
to	O
make	O
such	O
models	O
convolutional	O
we	O
can	O
use	O
the	O
function	O
h	O
to	O
perform	O
the	O
transpose	O
of	O
the	O
convolution	O
operation	B
suppose	O
we	O
have	O
hidden	O
units	O
h	O
in	O
the	O
same	O
format	O
as	O
z	O
and	O
we	O
define	O
a	O
reconstruction	O
k	O
h	O
s	O
r	O
in	O
order	O
to	O
train	O
the	O
autoencoder	O
we	O
will	O
receive	O
the	O
gradient	B
with	O
respect	O
to	O
r	O
as	O
a	O
tensor	O
e	O
to	O
train	O
the	O
decoder	B
we	O
need	O
to	O
obtain	O
the	O
gradient	B
with	O
respect	O
to	O
k	O
this	O
is	O
given	O
by	O
gh	O
e	O
s	O
to	O
train	O
the	O
encoder	B
we	O
need	O
to	O
obtain	O
the	O
gradient	B
with	O
respect	O
to	O
h	O
this	O
is	O
given	O
by	O
ck	O
e	O
s	O
it	O
is	O
also	O
possible	O
to	O
differentiate	O
through	O
g	O
using	O
c	O
and	O
h	O
but	O
these	O
operations	O
are	O
not	O
needed	O
for	O
the	O
back-propagation	B
algorithm	O
on	O
any	O
standard	O
network	O
architectures	O
generally	O
we	O
do	O
not	O
use	O
only	O
a	O
linear	O
operation	B
in	O
order	O
to	O
transform	O
from	O
the	O
inputs	O
to	O
the	O
outputs	O
in	O
a	O
convolutional	O
layer	O
we	O
generally	O
also	O
add	O
some	O
bias	O
term	O
to	O
each	O
output	O
before	O
applying	O
the	O
nonlinearity	O
this	O
raises	O
the	O
question	O
of	O
how	O
to	O
share	O
parameters	O
among	O
the	O
biases	O
for	O
locally	O
connected	O
layers	O
it	O
is	O
natural	O
to	O
give	O
each	O
unit	O
its	O
own	O
bias	O
and	O
for	O
tiled	B
convolution	I
it	O
is	O
natural	O
to	O
share	O
the	O
biases	O
with	O
the	O
same	O
tiling	O
pattern	O
as	O
the	O
kernels	O
for	O
convolutional	O
layers	O
it	O
is	O
typical	O
to	O
have	O
one	O
bias	O
per	O
channel	O
of	O
the	O
output	O
and	O
share	O
it	O
across	O
all	O
locations	O
within	O
each	O
convolution	O
map	O
however	O
if	O
the	O
input	O
is	O
of	O
known	O
fixed	O
size	O
it	O
is	O
also	O
possible	O
to	O
learn	O
a	O
separate	O
bias	O
at	O
each	O
location	O
of	O
the	O
output	O
map	O
separating	O
the	O
biases	O
may	O
slightly	O
reduce	O
the	O
statistical	O
efficiency	O
of	O
the	O
model	O
but	O
also	O
allows	O
the	O
model	O
to	O
correct	O
for	O
differences	O
in	O
the	O
image	O
statistics	O
at	O
different	O
locations	O
for	O
example	B
when	O
using	O
implicit	O
zero	O
padding	O
detector	O
units	O
at	O
the	O
edge	O
of	O
the	O
image	O
receive	O
less	O
total	O
input	O
and	O
may	O
need	O
larger	O
biases	O
structured	O
outputs	O
convolutional	O
networks	O
can	O
be	O
used	O
to	O
output	O
a	O
high-dimensional	O
structured	O
object	O
rather	O
than	O
just	O
predicting	O
a	O
class	O
label	O
for	O
a	O
classification	B
task	O
or	O
a	O
real	O
value	O
for	O
a	O
regression	B
task	O
typically	O
this	O
object	O
is	O
just	O
a	O
tensor	O
emitted	O
by	O
a	O
standard	O
convolutional	O
layer	O
for	O
example	B
the	O
model	O
might	O
emit	O
a	O
tensor	O
s	O
where	O
sijk	O
is	O
the	O
probability	O
that	O
pixel	O
k	O
of	O
the	O
input	O
to	O
the	O
network	O
belongs	O
to	O
class	O
i	O
this	O
allows	O
the	O
model	O
to	O
label	O
every	O
pixel	O
in	O
an	O
image	O
and	O
draw	O
precise	O
masks	O
that	O
follow	O
the	O
outlines	O
of	O
individual	O
objects	O
one	O
issue	O
that	O
often	O
comes	O
up	O
is	O
that	O
the	O
output	O
plane	O
can	O
be	O
smaller	O
than	O
the	O
chapter	O
convolutional	O
networks	O
y	O
y	O
y	O
y	O
y	O
y	O
v	O
w	O
v	O
w	O
v	O
u	O
u	O
u	O
xx	O
x	O
figure	O
an	O
example	B
of	O
a	O
recurrent	O
convolutional	B
network	I
for	O
pixel	O
labeling	O
the	O
input	O
is	O
an	O
image	O
tensor	O
with	O
axes	O
corresponding	O
to	O
image	O
rows	O
image	O
columns	O
and	O
channels	O
green	O
blue	O
the	O
goal	O
is	O
to	O
output	O
a	O
tensor	O
of	O
labels	O
y	O
with	O
a	O
probability	B
distribution	I
over	O
labels	O
for	O
each	O
pixel	O
this	O
tensor	O
has	O
axes	O
corresponding	O
to	O
image	O
rows	O
image	O
columns	O
and	O
the	O
different	O
classes	O
rather	O
than	O
outputting	O
y	O
in	O
a	O
single	O
shot	O
the	O
recurrent	B
network	I
iteratively	O
refines	O
its	O
estimate	O
y	O
by	O
using	O
a	O
previous	O
estimate	O
of	O
y	O
as	O
input	O
for	O
creating	O
a	O
new	O
estimate	O
the	O
same	O
parameters	O
are	O
used	O
for	O
each	O
updated	O
estimate	O
and	O
the	O
estimate	O
can	O
be	O
refined	O
as	O
many	O
times	O
as	O
we	O
wish	O
the	O
tensor	O
of	O
convolution	O
kernels	O
u	O
is	O
used	O
on	O
each	O
step	O
to	O
compute	O
the	O
hidden	O
representation	O
given	O
the	O
input	O
image	O
the	O
kernel	O
tensor	O
v	O
is	O
used	O
to	O
produce	O
an	O
estimate	O
of	O
the	O
labels	O
given	O
the	O
hidden	O
values	O
on	O
all	O
but	O
the	O
first	O
step	O
the	O
kernels	O
w	O
are	O
convolved	O
over	O
y	O
to	O
provide	O
input	O
to	O
the	O
hidden	B
layer	I
on	O
the	O
first	O
time	O
step	O
this	O
term	O
is	O
replaced	O
by	O
zero	O
because	O
the	O
same	O
parameters	O
are	O
used	O
on	O
each	O
step	O
this	O
is	O
an	O
example	B
of	O
a	O
recurrent	B
network	I
as	O
described	O
in	O
chapter	O
input	O
plane	O
as	O
shown	O
in	O
figure	O
in	O
the	O
kinds	O
of	O
architectures	O
typically	O
used	O
for	O
classification	B
of	O
a	O
single	O
object	O
in	O
an	O
image	O
the	O
greatest	O
reduction	O
in	O
the	O
spatial	O
dimensions	O
of	O
the	O
network	O
comes	O
from	O
using	O
pooling	O
layers	O
with	O
large	O
stride	O
in	O
order	O
to	O
produce	O
an	O
output	O
map	O
of	O
similar	O
size	O
as	O
the	O
input	O
one	O
can	O
avoid	O
pooling	O
another	O
strategy	O
is	O
to	O
simply	O
emit	O
a	O
lower-resolution	O
altogether	O
grid	O
of	O
labels	O
finally	O
in	O
principle	O
one	O
could	O
use	O
a	O
pooling	O
operator	O
with	O
unit	O
stride	O
pinheiro	O
and	O
collobert	O
jain	O
et	O
al	O
one	O
strategy	O
for	O
pixel-wise	O
labeling	O
of	O
images	O
is	O
to	O
produce	O
an	O
initial	O
guess	O
of	O
the	O
image	O
labels	O
then	O
refine	O
this	O
initial	O
guess	O
using	O
the	O
interactions	O
between	O
neighboring	O
pixels	O
repeating	O
this	O
refinement	O
step	O
several	O
times	O
corresponds	O
to	O
using	O
the	O
same	O
convolutions	O
at	O
each	O
stage	O
sharing	O
weights	B
between	O
the	O
last	O
layers	O
of	O
the	O
deep	O
net	O
this	O
makes	O
the	O
sequence	O
of	O
computations	O
performed	O
by	O
the	O
successive	O
convolutional	O
layers	O
with	O
weights	B
shared	O
across	O
layers	O
a	O
particular	O
kind	O
of	O
recurrent	B
network	I
shows	O
the	O
architecture	O
of	O
such	O
a	O
recurrent	O
convolutional	B
network	I
pinheiro	O
and	O
collobert	O
jain	O
et	O
al	O
figure	O
chapter	O
convolutional	O
networks	O
briggman	O
et	O
al	O
turaga	O
once	O
a	O
prediction	O
for	O
each	O
pixel	O
is	O
made	O
various	O
methods	O
can	O
be	O
used	O
to	O
further	O
process	O
these	O
predictions	O
in	O
order	O
to	O
obtain	O
a	O
segmentation	O
of	O
the	O
image	O
into	O
regions	O
the	O
general	O
idea	O
is	O
to	O
assume	O
that	O
large	O
groups	O
of	O
contiguous	O
pixels	O
tend	O
to	O
be	O
associated	O
with	O
the	O
same	O
label	O
graphical	O
models	O
can	O
describe	O
the	O
probabilistic	O
relationships	O
between	O
neighboring	O
pixels	O
alternatively	O
the	O
convolutional	B
network	I
can	O
be	O
trained	O
to	O
maximize	O
an	O
approximation	O
of	O
the	O
graphical	O
model	O
training	O
objective	O
ning	O
et	O
al	O
thompson	O
et	O
al	O
farabet	O
et	O
al	O
et	O
al	O
data	O
types	O
the	O
data	O
used	O
with	O
a	O
convolutional	B
network	I
usually	O
consists	O
of	O
several	O
channels	O
each	O
channel	O
being	O
the	O
observation	O
of	O
a	O
different	O
quantity	O
at	O
some	O
point	O
in	O
space	O
or	O
time	O
see	O
table	O
for	O
examples	O
of	O
data	O
types	O
with	O
different	O
dimensionalities	O
and	O
number	O
of	O
channels	O
for	O
an	O
example	B
of	O
convolutional	O
networks	O
applied	O
to	O
video	O
see	O
chen	O
et	O
al	O
so	O
far	O
we	O
have	O
discussed	O
only	O
the	O
case	O
where	O
every	O
example	B
in	O
the	O
train	O
and	O
test	O
data	O
has	O
the	O
same	O
spatial	O
dimensions	O
one	O
advantage	O
to	O
convolutional	O
networks	O
is	O
that	O
they	O
can	O
also	O
process	O
inputs	O
with	O
varying	O
spatial	O
extents	O
these	O
kinds	O
of	O
input	O
simply	O
cannot	O
be	O
represented	O
by	O
traditional	O
matrix	O
multiplication-based	O
neural	O
networks	O
this	O
provides	O
a	O
compelling	O
reason	O
to	O
use	O
convolutional	O
networks	O
even	O
when	O
computational	O
cost	O
and	O
overfitting	O
are	O
not	O
significant	O
issues	O
for	O
example	B
consider	O
a	O
collection	O
of	O
images	O
where	O
each	O
image	O
has	O
a	O
different	O
width	O
and	O
height	O
it	O
is	O
unclear	O
how	O
to	O
model	O
such	O
inputs	O
with	O
a	O
weight	O
matrix	O
of	O
fixed	O
size	O
convolution	O
is	O
straightforward	O
to	O
apply	O
the	O
kernel	O
is	O
simply	O
applied	O
a	O
different	O
number	O
of	O
times	O
depending	O
on	O
the	O
size	O
of	O
the	O
input	O
and	O
the	O
output	O
of	O
the	O
convolution	O
operation	B
scales	O
accordingly	O
convolution	O
may	O
be	O
viewed	O
as	O
matrix	O
multiplication	O
the	O
same	O
convolution	O
kernel	O
induces	O
a	O
different	O
size	O
of	O
doubly	B
block	I
circulant	I
matrix	I
for	O
each	O
size	O
of	O
input	O
sometimes	O
the	O
output	O
of	O
the	O
network	O
is	O
allowed	O
to	O
have	O
variable	O
size	O
as	O
well	O
as	O
the	O
input	O
for	O
example	B
if	O
we	O
want	O
to	O
assign	O
a	O
class	O
label	O
to	O
each	O
pixel	O
of	O
the	O
input	O
in	O
this	O
case	O
no	O
further	O
design	O
work	O
is	O
necessary	O
in	O
other	O
cases	O
the	O
network	O
must	O
produce	O
some	O
fixed-size	O
output	O
for	O
example	B
if	O
we	O
want	O
to	O
assign	O
a	O
single	O
class	O
label	O
to	O
the	O
entire	O
image	O
in	O
this	O
case	O
we	O
must	O
make	O
some	O
additional	O
design	O
steps	O
like	O
inserting	O
a	O
pooling	O
layer	O
whose	O
pooling	O
regions	O
scale	O
in	O
size	O
proportional	O
to	O
the	O
size	O
of	O
the	O
input	O
in	O
order	O
to	O
maintain	O
a	O
fixed	O
number	O
of	O
pooled	O
outputs	O
some	O
examples	O
of	O
this	O
kind	O
of	O
strategy	O
are	O
shown	O
in	O
figure	O
chapter	O
convolutional	O
networks	O
single	O
channel	O
audio	O
waveform	O
the	O
axis	O
we	O
convolve	O
over	O
corresponds	O
to	O
time	O
we	O
discretize	O
time	O
and	O
measure	O
the	O
amplitude	O
of	O
the	O
waveform	O
once	O
per	O
time	O
step	O
audio	O
data	O
that	O
has	O
been	O
preprocessed	O
with	O
a	O
fourier	O
transform	O
we	O
can	O
transform	O
the	O
audio	O
waveform	O
into	O
a	O
tensor	O
with	O
different	O
rows	O
corresponding	O
to	O
different	O
frequencies	O
and	O
different	O
columns	O
corresponding	O
to	O
different	O
points	O
in	O
time	O
using	O
convolution	O
in	O
the	O
time	O
makes	O
the	O
model	O
equivariant	O
to	O
shifts	O
in	O
time	O
using	O
convolution	O
across	O
the	O
frequency	O
axis	O
makes	O
the	O
model	O
equivariant	O
to	O
frequency	O
so	O
that	O
the	O
same	O
melody	O
played	O
in	O
a	O
different	O
octave	O
produces	O
the	O
same	O
representation	O
but	O
at	O
a	O
different	O
height	O
in	O
the	O
network	O
s	O
output	O
volumetric	O
data	O
a	O
common	O
source	O
of	O
this	O
kind	O
of	O
data	O
is	O
medical	O
imaging	O
technology	O
such	O
as	O
ct	O
scans	O
multi-channel	O
skeleton	O
animation	O
data	O
animations	O
of	O
computer-rendered	O
characters	O
are	O
generated	O
by	O
altering	O
the	O
pose	O
of	O
a	O
skeleton	O
over	O
time	O
at	O
each	O
point	O
in	O
time	O
the	O
pose	O
of	O
the	O
character	O
is	O
described	O
by	O
a	O
specification	O
of	O
the	O
angles	O
of	O
each	O
of	O
the	O
joints	O
in	O
the	O
character	O
s	O
skeleton	O
each	O
channel	O
in	O
the	O
data	O
we	O
feed	O
to	O
the	O
convolutional	O
model	O
represents	O
the	O
angle	O
about	O
one	O
axis	O
of	O
one	O
joint	O
color	O
image	O
data	O
one	O
channel	O
contains	O
the	O
red	O
pixels	O
one	O
the	O
green	O
pixels	O
and	O
one	O
the	O
blue	O
pixels	O
the	O
convolution	O
kernel	O
moves	O
over	O
both	O
the	O
horizontal	O
and	O
vertical	O
axes	O
of	O
the	O
image	O
conferring	O
translation	O
equivariance	B
in	O
both	O
directions	O
color	O
video	O
data	O
one	O
axis	O
corresponds	O
to	O
time	O
one	O
to	O
the	O
height	O
of	O
the	O
video	O
frame	O
and	O
one	O
to	O
the	O
width	O
of	O
the	O
video	O
frame	O
table	O
examples	O
of	O
different	O
formats	O
of	O
data	O
that	O
can	O
be	O
used	O
with	O
convolutional	O
networks	O
chapter	O
convolutional	O
networks	O
note	O
that	O
the	O
use	O
of	O
convolution	O
for	O
processing	O
variable	O
sized	O
inputs	O
only	O
makes	O
sense	O
for	O
inputs	O
that	O
have	O
variable	O
size	O
because	O
they	O
contain	O
varying	O
amounts	O
of	O
observation	O
of	O
the	O
same	O
kind	O
of	O
thing	O
different	O
lengths	O
of	O
recordings	O
over	O
time	O
different	O
widths	O
of	O
observations	O
over	O
space	O
etc	O
convolution	O
does	O
not	O
make	O
sense	O
if	O
the	O
input	O
has	O
variable	O
size	O
because	O
it	O
can	O
optionally	O
include	O
different	O
kinds	O
of	O
observations	O
for	O
example	B
if	O
we	O
are	O
processing	O
college	O
applications	O
and	O
our	O
features	O
consist	O
of	O
both	O
grades	O
and	O
standardized	O
test	O
scores	O
but	O
not	O
every	O
applicant	O
took	O
the	O
standardized	O
test	O
then	O
it	O
does	O
not	O
make	O
sense	O
to	O
convolve	O
the	O
same	O
weights	B
over	O
both	O
the	O
features	O
corresponding	O
to	O
the	O
grades	O
and	O
the	O
features	O
corresponding	O
to	O
the	O
test	O
scores	O
efficient	O
convolution	O
algorithms	O
modern	O
convolutional	B
network	I
applications	O
often	O
involve	O
networks	O
containing	O
more	O
than	O
one	O
million	O
units	O
powerful	O
implementations	O
exploiting	O
parallel	O
computation	O
resources	O
as	O
discussed	O
in	O
section	O
are	O
essential	O
however	O
in	O
many	O
cases	O
it	O
is	O
also	O
possible	O
to	O
speed	O
up	O
convolution	O
by	O
selecting	O
an	O
appropriate	O
convolution	O
algorithm	O
convolution	O
is	O
equivalent	O
to	O
converting	O
both	O
the	O
input	O
and	O
the	O
kernel	O
to	O
the	O
frequency	O
domain	O
using	O
a	O
fourier	O
transform	O
performing	O
point-wise	O
multiplication	O
of	O
the	O
two	O
signals	O
and	O
converting	O
back	O
to	O
the	O
time	O
domain	O
using	O
an	O
inverse	O
fourier	O
transform	O
for	O
some	O
problem	O
sizes	O
this	O
can	O
be	O
faster	O
than	O
the	O
naive	O
implementation	O
of	O
discrete	O
convolution	O
when	O
a	O
d-dimensional	O
kernel	O
can	O
be	O
expressed	O
as	O
the	O
outer	O
product	O
of	O
d	O
vectors	O
one	O
vector	O
per	O
dimension	O
the	O
kernel	O
is	O
called	O
separable	O
when	O
the	O
kernel	O
is	O
separable	O
naive	O
convolution	O
is	O
inefficient	O
it	O
is	O
equivalent	O
to	O
compose	O
d	O
one-dimensional	O
convolutions	O
with	O
each	O
of	O
these	O
vectors	O
the	O
composed	O
approach	O
is	O
significantly	O
faster	O
than	O
performing	O
one	O
d-dimensional	O
convolution	O
with	O
their	O
outer	O
product	O
the	O
kernel	O
also	O
takes	O
fewer	O
parameters	O
to	O
represent	O
as	O
vectors	O
if	O
the	O
kernel	O
is	O
w	O
elements	O
wide	O
in	O
each	O
dimension	O
then	O
naive	O
multidimensional	O
convolution	O
requires	O
o	O
runtime	O
and	O
parameter	O
storage	O
space	O
while	O
separable	B
convolution	I
requires	O
ow	O
d	O
runtime	O
and	O
parameter	O
storage	O
space	O
of	O
course	O
not	O
every	O
convolution	O
can	O
be	O
represented	O
in	O
this	O
way	O
devising	O
faster	O
ways	O
of	O
performing	O
convolution	O
or	O
approximate	O
convolution	O
without	O
harming	O
the	O
accuracy	B
of	O
the	O
model	O
is	O
an	O
active	O
area	O
of	O
research	O
even	O
techniques	O
that	O
improve	O
the	O
efficiency	O
of	O
only	O
forward	B
propagation	I
are	O
useful	O
because	O
in	O
the	O
commercial	O
setting	O
it	O
is	O
typical	O
to	O
devote	O
more	O
resources	O
to	O
deployment	O
of	O
a	O
network	O
than	O
to	O
its	O
training	O
chapter	O
convolutional	O
networks	O
random	O
or	O
unsupervised	O
features	O
typically	O
the	O
most	O
expensive	O
part	O
of	O
convolutional	B
network	I
training	O
is	O
learning	O
the	O
features	O
the	O
output	O
layer	O
is	O
usually	O
relatively	O
inexpensive	O
due	O
to	O
the	O
small	O
number	O
of	O
features	O
provided	O
as	O
input	O
to	O
this	O
layer	O
after	O
passing	O
through	O
several	O
layers	O
of	O
pooling	O
when	O
performing	O
supervised	O
training	O
with	O
gradient	B
descent	O
every	O
gradient	B
step	O
requires	O
a	O
complete	O
run	O
of	O
forward	B
propagation	I
and	O
backward	O
propagation	O
through	O
the	O
entire	O
network	O
one	O
way	O
to	O
reduce	O
the	O
cost	O
of	O
convolutional	B
network	I
training	O
is	O
to	O
use	O
features	O
that	O
are	O
not	O
trained	O
in	O
a	O
supervised	O
fashion	O
coates	O
et	O
al	O
there	O
are	O
three	O
basic	O
strategies	O
for	O
obtaining	O
convolution	O
kernels	O
without	O
supervised	O
training	O
one	O
is	O
to	O
simply	O
initialize	O
them	O
randomly	O
another	O
is	O
to	O
design	O
them	O
by	O
hand	O
for	O
example	B
by	O
setting	O
each	O
kernel	O
to	O
detect	O
edges	O
at	O
a	O
certain	O
orientation	O
or	O
scale	O
finally	O
one	O
can	O
learn	O
the	O
kernels	O
with	O
an	O
unsupervised	O
k-means	O
clustering	O
to	O
small	O
criterion	O
for	O
example	B
image	O
patches	O
then	O
use	O
each	O
learned	O
centroid	O
as	O
a	O
convolution	O
kernel	O
part	O
iii	O
describes	O
many	O
more	O
unsupervised	O
learning	O
approaches	O
learning	O
the	O
features	O
with	O
an	O
unsupervised	O
criterion	O
allows	O
them	O
to	O
be	O
determined	O
separately	O
from	O
the	O
classifier	O
layer	O
at	O
the	O
top	O
of	O
the	O
architecture	O
one	O
can	O
then	O
extract	O
the	O
features	O
for	O
the	O
entire	O
training	O
set	O
just	O
once	O
essentially	O
constructing	O
a	O
new	O
training	O
set	O
for	O
the	O
last	O
layer	O
learning	O
the	O
last	O
layer	O
is	O
then	O
typically	O
a	O
convex	B
optimization	I
problem	O
assuming	O
the	O
last	O
layer	O
is	O
something	O
like	O
logistic	O
regression	B
or	O
an	O
svm	O
apply	O
et	O
al	O
et	O
al	O
pinto	O
cox	O
and	O
pinto	O
random	O
filters	O
often	O
work	O
surprisingly	O
well	O
in	O
convolutional	O
networks	O
et	O
al	O
et	O
al	O
saxe	O
showed	O
that	O
layers	O
consisting	O
of	O
convolution	O
following	O
by	O
pooling	O
naturally	O
become	O
frequency	O
selective	O
and	O
translation	O
invariant	O
when	O
assigned	O
random	O
weights	B
they	O
argue	O
that	O
this	O
provides	O
an	O
inexpensive	O
way	O
to	O
choose	O
the	O
architecture	O
of	O
a	O
convolutional	B
network	I
first	O
evaluate	O
the	O
performance	O
of	O
several	O
convolutional	B
network	I
architectures	O
by	O
training	O
only	O
the	O
last	O
layer	O
then	O
take	O
the	O
best	O
of	O
these	O
architectures	O
and	O
train	O
the	O
entire	O
architecture	O
using	O
a	O
more	O
expensive	O
approach	O
saxe	O
an	O
intermediate	O
approach	O
is	O
to	O
learn	O
the	O
features	O
but	O
using	O
methods	O
that	O
do	O
not	O
require	O
full	O
forward	O
and	O
back-propagation	B
at	O
every	O
gradient	B
step	O
as	O
with	O
multilayer	O
perceptrons	O
we	O
use	O
greedy	O
layer-wise	O
pretraining	O
to	O
train	O
the	O
first	O
layer	O
in	O
isolation	O
then	O
extract	O
all	O
features	O
from	O
the	O
first	O
layer	O
only	O
once	O
then	O
train	O
the	O
second	O
layer	O
in	O
isolation	O
given	O
those	O
features	O
and	O
so	O
on	O
chapter	O
has	O
described	O
how	O
to	O
perform	O
supervised	O
greedy	O
layer-wise	O
pretraining	O
and	O
part	O
extends	O
this	O
to	O
greedy	O
layer-wise	O
pretraining	O
using	O
an	O
unsupervised	O
criterion	O
at	O
each	O
layer	O
the	O
canonical	O
example	B
of	O
greedy	O
layer-wise	O
pretraining	O
of	O
a	O
convolutional	O
model	O
is	O
the	O
convolutional	O
deep	O
belief	O
network	O
convolutional	O
networks	O
offer	O
lee	O
et	O
al	O
iii	O
chapter	O
convolutional	O
networks	O
do	O
with	O
coates	O
et	O
al	O
us	O
the	O
opportunity	O
to	O
take	O
the	O
pretraining	O
strategy	O
one	O
step	O
further	O
than	O
is	O
possible	O
with	O
multilayer	O
perceptrons	O
instead	O
of	O
training	O
an	O
entire	O
convolutional	O
layer	O
at	O
a	O
k-means	O
time	O
we	O
can	O
train	O
a	O
model	O
of	O
a	O
small	O
patch	O
as	O
we	O
can	O
then	O
use	O
the	O
parameters	O
from	O
this	O
patch-based	O
model	O
to	O
define	O
the	O
kernels	O
of	O
a	O
convolutional	O
layer	O
this	O
means	O
that	O
it	O
is	O
possible	O
to	O
use	O
unsupervised	O
learning	O
to	O
train	O
a	O
convolutional	B
network	I
without	O
ever	O
using	O
convolution	O
during	O
the	O
training	O
process	O
using	O
this	O
approach	O
we	O
can	O
train	O
very	O
large	O
models	O
and	O
incur	O
a	O
high	O
ranzato	O
et	O
al	O
jarrett	O
et	O
al	O
computational	O
cost	O
only	O
at	O
inference	O
time	O
kavukcuoglu	O
this	O
approach	O
was	O
popular	O
from	O
roughly	O
when	O
labeled	O
datasets	O
were	O
small	O
and	O
computational	O
power	O
was	O
more	O
limited	O
today	O
most	O
convolutional	O
networks	O
are	O
trained	O
in	O
a	O
purely	O
supervised	O
fashion	O
using	O
full	O
forward	O
and	O
back-propagation	B
through	O
the	O
entire	O
network	O
on	O
each	O
training	O
iteration	O
coates	O
et	O
al	O
et	O
al	O
as	O
with	O
other	O
approaches	O
to	O
unsupervised	B
pretraining	I
it	O
remains	O
difficult	O
to	O
tease	O
apart	O
the	O
cause	O
of	O
some	O
of	O
the	O
benefits	O
seen	O
with	O
this	O
approach	O
unsupervised	B
pretraining	I
may	O
offer	O
some	O
regularization	O
relative	O
to	O
supervised	O
training	O
or	O
it	O
may	O
simply	O
allow	O
us	O
to	O
train	O
much	O
larger	O
architectures	O
due	O
to	O
the	O
reduced	O
computational	O
cost	O
of	O
the	O
learning	O
rule	O
the	O
neuroscientific	O
basis	O
for	O
convolutional	O
net	O
works	O
convolutional	O
networks	O
are	O
perhaps	O
the	O
greatest	O
success	O
story	O
of	O
biologically	O
inspired	O
artificial	B
intelligence	I
though	O
convolutional	O
networks	O
have	O
been	O
guided	O
by	O
many	O
other	O
fields	O
some	O
of	O
the	O
key	O
design	O
principles	O
of	O
neural	O
networks	O
were	O
drawn	O
from	O
neuroscience	B
the	O
history	O
of	O
convolutional	O
networks	O
begins	O
with	O
neuroscientific	O
experiments	O
long	O
before	O
the	O
relevant	O
computational	O
models	O
were	O
developed	O
neurophysiologists	O
david	O
hubel	O
and	O
torsten	O
wiesel	O
collaborated	O
for	O
several	O
years	O
to	O
determine	O
many	O
of	O
the	O
most	O
basic	O
facts	O
about	O
how	O
the	O
mammalian	O
vision	O
system	O
works	O
and	O
wiesel	O
their	O
accomplishments	O
were	O
eventually	O
recognized	O
with	O
a	O
nobel	O
prize	O
their	O
findings	O
that	O
have	O
had	O
the	O
greatest	O
influence	O
on	O
contemporary	O
deep	O
learning	O
models	O
were	O
based	O
on	O
recording	O
the	O
activity	O
of	O
individual	O
neurons	O
in	O
cats	O
they	O
observed	O
how	O
neurons	O
in	O
the	O
cat	O
s	O
brain	O
responded	O
to	O
images	O
projected	O
in	O
precise	O
locations	O
on	O
a	O
screen	O
in	O
front	O
of	O
the	O
cat	O
their	O
great	O
discovery	O
was	O
that	O
neurons	O
in	O
the	O
early	O
visual	O
system	O
responded	O
most	O
strongly	O
to	O
very	O
specific	O
patterns	O
of	O
light	O
such	O
as	O
precisely	O
oriented	O
bars	O
but	O
responded	O
hardly	O
at	O
all	O
to	O
other	O
patterns	O
chapter	O
convolutional	O
networks	O
their	O
work	O
helped	O
to	O
characterize	O
many	O
aspects	O
of	O
brain	O
function	O
that	O
are	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
from	O
the	O
point	O
of	O
view	O
of	O
deep	O
learning	O
we	O
can	O
focus	O
on	O
a	O
simplified	O
cartoon	O
view	O
of	O
brain	O
function	O
in	O
this	O
simplified	O
view	O
we	O
focus	O
on	O
a	O
part	O
of	O
the	O
brain	O
called	O
also	O
known	O
as	O
the	O
primary	B
visual	I
cortex	I
is	O
the	O
first	O
area	O
of	O
the	O
brain	O
that	O
begins	O
to	O
perform	O
significantly	O
advanced	O
processing	O
of	O
visual	O
input	O
in	O
this	O
cartoon	O
view	O
images	O
are	O
formed	O
by	O
light	O
arriving	O
in	O
the	O
eye	O
and	O
stimulating	O
the	O
retina	O
the	O
light-sensitive	O
tissue	O
in	O
the	O
back	O
of	O
the	O
eye	O
the	O
neurons	O
in	O
the	O
retina	O
perform	O
some	O
simple	O
preprocessing	B
of	O
the	O
image	O
but	O
do	O
not	O
substantially	O
alter	O
the	O
way	O
it	O
is	O
represented	O
the	O
image	O
then	O
passes	O
through	O
the	O
optic	O
nerve	O
and	O
a	O
brain	O
region	O
called	O
the	O
lateral	O
geniculate	O
nucleus	O
the	O
main	O
role	O
as	O
far	O
as	O
we	O
are	O
concerned	O
here	O
of	O
both	O
of	O
these	O
anatomical	O
regions	O
is	O
primarily	O
just	O
to	O
carry	O
the	O
signal	O
from	O
the	O
eye	O
to	O
which	O
is	O
located	O
at	O
the	O
back	O
of	O
the	O
head	O
a	O
convolutional	B
network	I
layer	O
is	O
designed	O
to	O
capture	O
three	O
properties	O
of	O
is	O
arranged	O
in	O
a	O
spatial	O
map	O
it	O
actually	O
has	O
a	O
two-dimensional	O
structure	O
mirroring	O
the	O
structure	O
of	O
the	O
image	O
in	O
the	O
retina	O
for	O
example	B
light	O
arriving	O
at	O
the	O
lower	O
half	O
of	O
the	O
retina	O
affects	O
only	O
the	O
corresponding	O
half	O
of	O
convolutional	O
networks	O
capture	O
this	O
property	O
by	O
having	O
their	O
features	O
defined	O
in	O
terms	O
of	O
two	O
dimensional	O
maps	O
contains	O
many	O
simple	O
cells	O
a	O
simple	B
cell	I
s	O
activity	O
can	O
to	O
some	O
extent	O
be	O
characterized	O
by	O
a	O
linear	O
function	O
of	O
the	O
image	O
in	O
a	O
small	O
spatially	O
localized	O
receptive	B
field	I
the	O
detector	O
units	O
of	O
a	O
convolutional	B
network	I
are	O
designed	O
to	O
emulate	O
these	O
properties	O
of	O
simple	O
cells	O
also	O
contains	O
many	O
complex	O
cells	O
these	O
cells	O
respond	O
to	O
features	O
that	O
are	O
similar	O
to	O
those	O
detected	O
by	O
simple	O
cells	O
but	O
complex	O
cells	O
are	O
invariant	O
to	O
small	O
shifts	O
in	O
the	O
position	O
of	O
the	O
feature	B
this	O
inspires	O
the	O
pooling	O
units	O
of	O
convolutional	O
networks	O
complex	O
cells	O
are	O
also	O
invariant	O
to	O
some	O
changes	O
in	O
lighting	O
that	O
cannot	O
be	O
captured	O
simply	O
by	O
pooling	O
over	O
spatial	O
locations	O
these	O
invariances	O
have	O
inspired	O
some	O
of	O
the	O
cross-channel	O
pooling	O
strategies	O
in	O
convolutional	O
networks	O
such	O
as	O
maxout	O
units	O
goodfellow	O
et	O
al	O
though	O
we	O
know	O
the	O
most	O
about	O
it	O
is	O
generally	O
believed	O
that	O
the	O
same	O
basic	O
principles	O
apply	O
to	O
other	O
areas	O
of	O
the	O
visual	O
system	O
in	O
our	O
cartoon	O
view	O
of	O
the	O
visual	O
system	O
the	O
basic	O
strategy	O
of	O
detection	O
followed	O
by	O
pooling	O
is	O
repeatedly	O
applied	O
as	O
we	O
move	O
deeper	O
into	O
the	O
brain	O
as	O
we	O
pass	O
through	O
multiple	O
anatomical	O
layers	O
of	O
the	O
brain	O
we	O
eventually	O
find	O
cells	O
that	O
respond	O
to	O
some	O
specific	O
concept	O
and	O
are	O
invariant	O
to	O
many	O
transformations	O
of	O
the	O
input	O
these	O
cells	O
have	O
been	O
chapter	O
convolutional	O
networks	O
nicknamed	O
grandmother	O
cells	O
the	O
idea	O
is	O
that	O
a	O
person	O
could	O
have	O
a	O
neuron	O
that	O
activates	O
when	O
seeing	O
an	O
image	O
of	O
their	O
grandmother	O
regardless	O
of	O
whether	O
she	O
appears	O
in	O
the	O
left	O
or	O
right	O
side	O
of	O
the	O
image	O
whether	O
the	O
image	O
is	O
a	O
close-up	O
of	O
her	O
face	O
or	O
zoomed	O
out	O
shot	O
of	O
her	O
entire	O
body	O
whether	O
she	O
is	O
brightly	O
lit	O
or	O
in	O
shadow	O
etc	O
these	O
grandmother	O
cells	O
have	O
been	O
shown	O
to	O
actually	O
exist	O
in	O
the	O
human	O
brain	O
researchers	O
in	O
a	O
region	O
called	O
the	O
medial	O
temporal	O
lobe	O
tested	O
whether	O
individual	O
neurons	O
would	O
respond	O
to	O
photos	O
of	O
famous	O
individuals	O
they	O
found	O
what	O
has	O
come	O
to	O
be	O
called	O
the	O
halle	O
berry	O
neuron	O
an	O
individual	O
neuron	O
that	O
is	O
activated	O
by	O
the	O
concept	O
of	O
halle	O
berry	O
this	O
neuron	O
fires	O
when	O
a	O
person	O
sees	O
a	O
photo	O
of	O
halle	O
berry	O
a	O
drawing	O
of	O
halle	O
berry	O
or	O
even	O
text	O
containing	O
the	O
words	O
halle	O
berry	O
of	O
course	O
this	O
has	O
nothing	O
to	O
do	O
with	O
halle	O
berry	O
herself	O
other	O
neurons	O
responded	O
to	O
the	O
presence	O
of	O
bill	O
clinton	O
jennifer	O
aniston	O
etc	O
quiroga	O
et	O
al	O
these	O
medial	O
temporal	O
lobe	O
neurons	O
are	O
somewhat	O
more	O
general	O
than	O
modern	O
convolutional	O
networks	O
which	O
would	O
not	O
automatically	O
generalize	O
to	O
identifying	O
a	O
person	O
or	O
object	O
when	O
reading	O
its	O
name	O
the	O
closest	O
analog	O
to	O
a	O
convolutional	B
network	I
s	O
last	O
layer	O
of	O
features	O
is	O
a	O
brain	O
area	O
called	O
the	O
inferotemporal	O
cortex	O
when	O
viewing	O
an	O
object	O
information	O
flows	O
from	O
the	O
retina	O
through	O
the	O
lgn	O
to	O
then	O
onward	O
to	O
then	O
then	O
it	O
this	O
happens	O
within	O
the	O
first	O
of	O
glimpsing	O
an	O
object	O
if	O
a	O
person	O
is	O
allowed	O
to	O
continue	O
looking	O
at	O
the	O
object	O
for	O
more	O
time	O
then	O
information	O
will	O
begin	O
to	O
flow	O
backwards	O
as	O
the	O
brain	O
uses	O
top-down	O
feedback	O
to	O
update	O
the	O
activations	O
in	O
the	O
lower	O
level	O
brain	O
areas	O
however	O
if	O
we	O
interrupt	O
the	O
person	O
s	O
gaze	O
and	O
observe	O
only	O
the	O
firing	O
rates	O
that	O
result	O
from	O
the	O
first	O
of	O
mostly	O
feedforward	O
activation	O
then	O
it	O
proves	O
to	O
be	O
very	O
similar	O
to	O
a	O
convolutional	B
network	I
convolutional	O
networks	O
can	O
predict	O
it	O
firing	O
rates	O
and	O
also	O
perform	O
very	O
similarly	O
to	O
limited	O
humans	O
on	O
object	B
recognition	I
tasks	O
dicarlo	O
that	O
being	O
said	O
there	O
are	O
many	O
differences	O
between	O
convolutional	O
networks	O
and	O
the	O
mammalian	O
vision	O
system	O
some	O
of	O
these	O
differences	O
are	O
well	O
known	O
to	O
computational	O
neuroscientists	O
but	O
outside	O
the	O
scope	O
of	O
this	O
book	O
some	O
of	O
these	O
differences	O
are	O
not	O
yet	O
known	O
because	O
many	O
basic	O
questions	O
about	O
how	O
the	O
mammalian	O
vision	O
system	O
works	O
remain	O
unanswered	O
as	O
a	O
brief	O
list	O
the	O
human	O
eye	O
is	O
mostly	O
very	O
low	O
resolution	O
except	O
for	O
a	O
tiny	O
patch	O
called	O
the	O
fovea	B
the	O
fovea	B
only	O
observes	O
an	O
area	O
about	O
the	O
size	O
of	O
a	O
thumbnail	O
held	O
at	O
arms	O
length	O
though	O
we	O
feel	O
as	O
if	O
we	O
can	O
see	O
an	O
entire	O
scene	O
in	O
high	O
resolution	O
this	O
is	O
an	O
illusion	O
created	O
by	O
the	O
subconscious	O
part	O
of	O
our	O
brain	O
as	O
it	O
stitches	O
together	O
several	O
glimpses	O
of	O
small	O
areas	O
most	O
convolutional	O
networks	O
actually	O
receive	O
large	O
full	O
resolution	O
photographs	O
as	O
input	O
the	O
human	O
brain	O
makes	O
chapter	O
convolutional	O
networks	O
several	O
eye	O
movements	O
called	O
saccades	O
to	O
glimpse	O
the	O
most	O
visually	O
salient	O
or	O
task-relevant	O
parts	O
of	O
a	O
scene	O
incorporating	O
similar	O
attention	O
mechanisms	O
into	O
deep	O
learning	O
models	O
is	O
an	O
active	O
research	O
direction	O
in	O
the	O
context	O
of	O
deep	O
learning	O
attention	O
mechanisms	O
have	O
been	O
most	O
successful	O
for	O
natural	B
language	I
processing	I
as	O
described	O
in	O
section	O
several	O
visual	O
models	O
with	O
foveation	O
mechanisms	O
have	O
been	O
developed	O
but	O
so	O
far	O
have	O
not	O
become	O
the	O
dominant	O
approach	O
and	O
hinton	O
denil	O
et	O
al	O
the	O
human	O
visual	O
system	O
is	O
integrated	O
with	O
many	O
other	O
senses	O
such	O
as	O
hearing	O
and	O
factors	O
like	O
our	O
moods	O
and	O
thoughts	O
convolutional	O
networks	O
so	O
far	O
are	O
purely	O
visual	O
the	O
human	O
visual	O
system	O
does	O
much	O
more	O
than	O
just	O
recognize	O
objects	O
it	O
is	O
able	O
to	O
understand	O
entire	O
scenes	O
including	O
many	O
objects	O
and	O
relationships	O
between	O
objects	O
and	O
processes	O
rich	O
geometric	O
information	O
needed	O
for	O
our	O
bodies	O
to	O
interface	O
with	O
the	O
world	O
convolutional	O
networks	O
have	O
been	O
applied	O
to	O
some	O
of	O
these	O
problems	O
but	O
these	O
applications	O
are	O
in	O
their	O
infancy	O
even	O
simple	O
brain	O
areas	O
like	O
are	O
heavily	O
impacted	O
by	O
feedback	O
from	O
higher	O
levels	O
feedback	O
has	O
been	O
explored	O
extensively	O
in	O
neural	B
network	I
models	O
but	O
has	O
not	O
yet	O
been	O
shown	O
to	O
offer	O
a	O
compelling	O
improvement	O
while	O
feedforward	O
it	O
firing	O
rates	O
capture	O
much	O
of	O
the	O
same	O
information	O
as	O
convolutional	B
network	I
features	O
it	O
is	O
not	O
clear	O
how	O
similar	O
the	O
intermediate	O
computations	O
are	O
the	O
brain	O
probably	O
uses	O
very	O
different	O
activation	O
and	O
pooling	O
functions	O
an	O
individual	O
neuron	O
s	O
activation	O
probably	O
is	O
not	O
wellcharacterized	O
by	O
a	O
single	O
linear	O
filter	O
response	O
a	O
recent	O
model	O
of	O
involves	O
multiple	O
quadratic	O
filters	O
for	O
each	O
neuron	O
indeed	O
our	O
cartoon	O
picture	O
of	O
simple	O
cells	O
and	O
complex	O
cells	O
might	O
create	O
a	O
nonexistent	O
distinction	O
simple	O
cells	O
and	O
complex	O
cells	O
might	O
both	O
be	O
the	O
same	O
kind	O
of	O
cell	O
but	O
with	O
their	O
parameters	O
enabling	O
a	O
continuum	O
of	O
behaviors	O
ranging	O
from	O
what	O
we	O
call	O
simple	O
to	O
what	O
we	O
call	O
complex	O
rust	O
et	O
al	O
it	O
is	O
also	O
worth	O
mentioning	O
that	O
neuroscience	B
has	O
told	O
us	O
relatively	O
little	O
about	O
how	O
to	O
train	O
convolutional	O
networks	O
model	O
structures	O
with	O
parameter	O
sharing	O
across	O
multiple	O
spatial	O
locations	O
date	O
back	O
to	O
early	O
connectionist	O
models	O
of	O
vision	O
but	O
these	O
models	O
did	O
not	O
use	O
the	O
modern	O
back-propagation	B
algorithm	O
and	O
gradient	B
descent	O
for	O
example	B
the	O
neocognitron	O
incorporated	O
most	O
of	O
the	O
model	O
architecture	O
design	O
elements	O
of	O
the	O
modern	O
convolutional	B
network	I
but	O
relied	O
on	O
a	O
layer-wise	O
unsupervised	O
clustering	O
algorithm	O
marr	O
and	O
poggio	O
chapter	O
convolutional	O
networks	O
lang	O
and	O
hinton	O
introduced	O
the	O
use	O
of	O
back-propagation	B
to	O
train	O
time-delay	O
neural	O
networks	O
to	O
use	O
contemporary	O
terminology	O
tdnns	O
are	O
one-dimensional	O
convolutional	O
networks	O
applied	O
to	O
time	O
series	O
backpropagation	O
applied	O
to	O
these	O
models	O
was	O
not	O
inspired	O
by	O
any	O
neuroscientific	O
observation	O
and	O
is	O
considered	O
by	O
some	O
to	O
be	O
biologically	O
implausible	O
following	O
the	O
success	O
of	O
back-propagation-based	O
training	O
of	O
tdnns	O
developed	O
the	O
modern	O
convolutional	B
network	I
by	O
applying	O
the	O
same	O
training	O
algorithm	O
to	O
convolution	O
applied	O
to	O
images	O
lecun	O
et	O
al	O
so	O
far	O
we	O
have	O
described	O
how	O
simple	O
cells	O
are	O
roughly	O
linear	O
and	O
selective	O
for	O
certain	O
features	O
complex	O
cells	O
are	O
more	O
nonlinear	O
and	O
become	O
invariant	O
to	O
some	O
transformations	O
of	O
these	O
simple	B
cell	I
features	O
and	O
stacks	O
of	O
layers	O
that	O
alternate	O
between	O
selectivity	O
and	O
invariance	B
can	O
yield	O
grandmother	O
cells	O
for	O
very	O
specific	O
phenomena	O
we	O
have	O
not	O
yet	O
described	O
precisely	O
what	O
these	O
individual	O
cells	O
detect	O
in	O
a	O
deep	O
nonlinear	O
network	O
it	O
can	O
be	O
difficult	O
to	O
understand	O
the	O
function	O
of	O
individual	O
cells	O
simple	O
cells	O
in	O
the	O
first	O
layer	O
are	O
easier	O
to	O
analyze	O
because	O
their	O
responses	O
are	O
driven	O
by	O
a	O
linear	O
function	O
in	O
an	O
artificial	O
neural	B
network	I
we	O
can	O
just	O
display	O
an	O
image	O
of	O
the	O
convolution	O
kernel	O
to	O
see	O
what	O
the	O
corresponding	O
channel	O
of	O
a	O
convolutional	O
layer	O
responds	O
to	O
in	O
a	O
biological	O
neural	B
network	I
we	O
do	O
not	O
have	O
access	O
to	O
the	O
weights	B
themselves	O
instead	O
we	O
put	O
an	O
electrode	O
in	O
the	O
neuron	O
itself	O
display	O
several	O
samples	O
of	O
white	O
noise	O
images	O
in	O
front	O
of	O
the	O
animal	O
s	O
retina	O
and	O
record	O
how	O
each	O
of	O
these	O
samples	O
causes	O
the	O
neuron	O
to	O
activate	O
we	O
can	O
then	O
fit	O
a	O
linear	O
model	O
to	O
these	O
responses	O
in	O
order	O
to	O
obtain	O
an	O
approximation	O
of	O
the	O
neuron	O
s	O
weights	B
this	O
approach	O
is	O
known	O
as	O
reverse	O
correlation	B
and	O
shapley	O
reverse	O
correlation	B
shows	O
us	O
that	O
most	O
cells	O
have	O
weights	B
that	O
are	O
described	O
by	O
gabor	O
functions	O
the	O
gabor	B
function	I
describes	O
the	O
weight	O
at	O
a	O
point	O
in	O
the	O
image	O
we	O
can	O
think	O
of	O
an	O
image	O
as	O
being	O
a	O
function	O
of	O
coordinates	O
ix	O
y	O
likewise	O
we	O
can	O
think	O
of	O
a	O
simple	B
cell	I
as	O
sampling	O
the	O
image	O
at	O
a	O
set	O
of	O
locations	O
defined	O
by	O
a	O
set	O
of	O
x	O
coordinates	O
x	O
and	O
a	O
set	O
of	O
y	O
coordinates	O
y	O
and	O
applying	O
weights	B
that	O
are	O
also	O
a	O
function	O
of	O
the	O
location	O
wx	O
y	O
from	O
this	O
point	O
of	O
view	O
the	O
response	O
of	O
a	O
simple	B
cell	I
to	O
an	O
image	O
is	O
given	O
by	O
s	O
i	O
x	O
x	O
y	O
y	O
w	O
x	O
y	O
i	O
x	O
y	O
specifically	O
w	O
x	O
y	O
takes	O
the	O
form	O
of	O
a	O
gabor	B
function	I
w	O
x	O
y	O
exp	O
x	O
y	O
f	O
y	O
x	O
where	O
xx	O
y	O
y	O
cosfx	O
cos	O
x	O
y	O
sin	O
y	O
chapter	O
convolutional	O
networks	O
and	O
x	O
y	O
x	O
sin	O
y	O
y	O
cos	O
here	O
x	O
y	O
f	O
and	O
are	O
parameters	O
that	O
control	O
the	O
properties	O
shows	O
some	O
examples	O
of	O
gabor	O
functions	O
with	O
of	O
the	O
gabor	B
function	I
figure	O
different	O
settings	O
of	O
these	O
parameters	O
the	O
parameters	O
and	O
define	O
a	O
coordinate	O
system	O
we	O
translate	O
and	O
rotate	O
x	O
and	O
y	O
to	O
form	O
x	O
specifically	O
the	O
simple	B
cell	I
will	O
respond	O
to	O
image	O
features	O
centered	O
at	O
the	O
point	O
y	O
and	O
it	O
will	O
respond	O
to	O
changes	O
in	O
brightness	O
as	O
we	O
move	O
along	O
a	O
line	O
rotated	O
radians	O
from	O
the	O
horizontal	O
and	O
y	O
viewed	O
as	O
a	O
function	O
of	O
x	O
and	O
y	O
brightness	O
as	O
we	O
move	O
along	O
the	O
x	O
gaussian	O
function	O
and	O
the	O
other	O
is	O
a	O
cosine	O
function	O
the	O
function	O
w	O
then	O
responds	O
to	O
changes	O
in	O
axis	O
it	O
has	O
two	O
important	O
factors	O
one	O
is	O
a	O
the	O
gaussian	O
factor	O
exp	O
can	O
be	O
seen	O
as	O
a	O
gating	O
term	O
that	O
ensures	O
the	O
simple	B
cell	I
will	O
only	O
respond	O
to	O
values	O
near	O
where	O
x	O
are	O
both	O
zero	O
in	O
other	O
words	O
near	O
the	O
center	O
of	O
the	O
cell	O
s	O
receptive	B
field	I
the	O
scaling	O
factor	O
adjusts	O
the	O
total	O
magnitude	O
of	O
the	O
simple	B
cell	I
s	O
response	O
while	O
x	O
and	O
y	O
control	O
how	O
quickly	O
its	O
receptive	B
field	I
falls	O
off	O
and	O
y	O
yy	O
xx	O
the	O
cosine	O
factor	O
cosfx	O
brightness	O
along	O
the	O
x	O
and	O
controls	O
its	O
phase	O
offset	O
controls	O
how	O
the	O
simple	B
cell	I
responds	O
to	O
changing	O
axis	O
the	O
parameter	O
f	O
controls	O
the	O
frequency	O
of	O
the	O
cosine	O
altogether	O
this	O
cartoon	O
view	O
of	O
simple	O
cells	O
means	O
that	O
a	O
simple	B
cell	I
responds	O
to	O
a	O
specific	O
spatial	O
frequency	O
of	O
brightness	O
in	O
a	O
specific	O
direction	O
at	O
a	O
specific	O
location	O
simple	O
cells	O
are	O
most	O
excited	O
when	O
the	O
wave	O
of	O
brightness	O
in	O
the	O
image	O
has	O
the	O
same	O
phase	O
as	O
the	O
weights	B
this	O
occurs	O
when	O
the	O
image	O
is	O
bright	O
where	O
the	O
weights	B
are	O
positive	O
and	O
dark	O
where	O
the	O
weights	B
are	O
negative	O
simple	O
cells	O
are	O
most	O
inhibited	O
when	O
the	O
wave	O
of	O
brightness	O
is	O
fully	O
out	O
of	O
phase	O
with	O
the	O
weights	B
when	O
the	O
image	O
is	O
dark	O
where	O
the	O
weights	B
are	O
positive	O
and	O
bright	O
where	O
the	O
weights	B
are	O
negative	O
the	O
cartoon	O
view	O
of	O
a	O
complex	B
cell	I
is	O
that	O
it	O
computes	O
the	O
norm	O
of	O
the	O
an	O
vector	O
containing	O
two	O
simple	O
cells	O
responses	O
c	O
i	O
important	O
special	O
case	O
occurs	O
when	O
has	O
all	O
of	O
the	O
same	O
parameters	O
as	O
except	O
for	O
and	O
is	O
set	O
such	O
that	O
is	O
one	O
quarter	O
cycle	O
out	O
of	O
phase	O
with	O
in	O
this	O
case	O
and	O
form	O
a	O
quadrature	B
pair	I
a	O
complex	B
cell	I
defined	O
in	O
this	O
way	O
contains	O
responds	O
when	O
the	O
gaussian	O
reweighted	O
image	O
ix	O
y	O
exp	O
x	O
x	O
a	O
high	O
amplitude	O
sinusoidal	O
wave	O
with	O
frequency	O
f	O
in	O
direction	O
near	O
regardless	O
of	O
the	O
phase	O
offset	O
of	O
this	O
wave	O
in	O
other	O
words	O
the	O
complex	B
cell	I
is	O
invariant	O
to	O
small	O
translations	O
of	O
the	O
image	O
in	O
direction	O
or	O
to	O
negating	O
the	O
image	O
yy	O
chapter	O
convolutional	O
networks	O
figure	O
gabor	O
functions	O
with	O
a	O
variety	O
of	O
parameter	O
settings	O
white	O
indicates	O
large	O
positive	O
weight	O
black	O
indicates	O
large	O
negative	O
weight	O
and	O
the	O
background	O
gray	O
corresponds	O
to	O
zero	O
weight	O
functions	O
with	O
different	O
values	O
of	O
the	O
parameters	O
that	O
control	O
the	O
coordinate	O
system	O
x	O
and	O
each	O
gabor	B
function	I
in	O
this	O
grid	O
is	O
assigned	O
a	O
value	O
of	O
and	O
y	O
proportional	O
to	O
its	O
position	O
in	O
its	O
grid	O
and	O
is	O
chosen	O
so	O
that	O
each	O
gabor	O
filter	O
is	O
sensitive	O
to	O
the	O
direction	O
radiating	O
out	O
from	O
the	O
center	O
of	O
the	O
grid	O
for	O
the	O
other	O
two	O
plots	O
y	O
and	O
are	O
fixed	O
to	O
zero	O
gabor	O
functions	O
with	O
different	O
gaussian	O
scale	O
parameters	O
x	O
and	O
y	O
gabor	O
functions	O
are	O
arranged	O
in	O
increasing	O
width	O
x	O
as	O
we	O
move	O
left	O
to	O
right	O
through	O
the	O
grid	O
and	O
increasing	O
height	O
y	O
as	O
we	O
move	O
top	O
to	O
bottom	O
for	O
the	O
other	O
two	O
plots	O
the	O
values	O
are	O
fixed	O
to	O
f	O
and	O
as	O
we	O
move	O
top	O
to	O
bottom	O
f	O
increases	O
and	O
as	O
we	O
move	O
left	O
to	O
right	O
increases	O
for	O
the	O
other	O
two	O
plots	O
gabor	O
functions	O
with	O
different	O
sinusoid	O
parameters	O
the	O
image	O
width	O
the	O
image	O
width	O
is	O
fixed	O
to	O
and	O
is	O
fixed	O
to	O
f	O
black	O
with	O
white	O
and	O
vice	O
versa	O
olshausen	O
and	O
field	O
some	O
of	O
the	O
most	O
striking	O
correspondences	O
between	O
neuroscience	B
and	O
machine	B
learning	I
come	O
from	O
visually	O
comparing	O
the	O
features	O
learned	O
by	O
machine	B
learning	I
models	O
with	O
those	O
employed	O
by	O
showed	O
that	O
a	O
simple	O
unsupervised	O
learning	O
algorithm	O
sparse	O
coding	O
learns	O
features	O
with	O
receptive	O
fields	O
similar	O
to	O
those	O
of	O
simple	O
cells	O
since	O
then	O
we	O
have	O
found	O
that	O
an	O
extremely	O
wide	O
variety	O
of	O
statistical	O
learning	O
algorithms	O
learn	O
features	O
with	O
gabor-like	O
functions	O
when	O
applied	O
to	O
natural	O
images	O
this	O
includes	O
most	O
deep	O
learning	O
algorithms	O
which	O
learn	O
these	O
features	O
in	O
their	O
first	O
layer	O
figure	O
shows	O
some	O
examples	O
because	O
so	O
many	O
different	O
learning	O
algorithms	O
learn	O
edge	O
detectors	O
it	O
is	O
difficult	O
to	O
conclude	O
that	O
any	O
specific	O
learning	O
algorithm	O
is	O
the	O
right	O
model	O
of	O
the	O
brain	O
just	O
based	O
on	O
the	O
features	O
that	O
it	O
learns	O
it	O
can	O
certainly	O
be	O
a	O
bad	O
sign	O
if	O
an	O
algorithm	O
does	O
learn	O
some	O
sort	O
of	O
edge	O
detector	O
when	O
applied	O
to	O
natural	O
images	O
these	O
features	O
are	O
an	O
important	O
part	O
of	O
the	O
statistical	O
structure	O
of	O
natural	O
images	O
and	O
can	O
be	O
recovered	O
by	O
many	O
different	O
approaches	O
to	O
statistical	O
modeling	O
see	O
hyv	O
rinen	O
for	O
a	O
review	O
of	O
the	O
field	O
of	O
natural	B
image	I
statistics	O
et	O
al	O
not	O
chapter	O
convolutional	O
networks	O
figure	O
many	O
machine	B
learning	I
algorithms	O
learn	O
features	O
that	O
detect	O
edges	O
or	O
specific	O
colors	O
of	O
edges	O
when	O
applied	O
to	O
natural	O
images	O
these	O
feature	B
detectors	O
are	O
reminiscent	O
of	O
the	O
gabor	O
functions	O
known	O
to	O
be	O
present	O
in	O
primary	B
visual	I
cortex	I
learned	O
by	O
an	O
unsupervised	O
learning	O
algorithm	O
and	O
slab	O
sparse	O
coding	O
applied	O
to	O
small	O
image	O
patches	O
kernels	O
learned	O
by	O
the	O
first	O
layer	O
of	O
a	O
fully	O
supervised	O
convolutional	O
maxout	O
network	O
neighboring	O
pairs	O
of	O
filters	O
drive	O
the	O
same	O
maxout	O
unit	O
convolutional	O
networks	O
and	O
the	O
history	O
of	O
deep	O
learning	O
convolutional	O
networks	O
have	O
played	O
an	O
important	O
role	O
in	O
the	O
history	O
of	O
deep	O
learning	O
they	O
are	O
a	O
key	O
example	B
of	O
a	O
successful	O
application	O
of	O
insights	O
obtained	O
by	O
studying	O
the	O
brain	O
to	O
machine	B
learning	I
applications	O
they	O
were	O
also	O
some	O
of	O
the	O
first	O
deep	O
models	O
to	O
perform	O
well	O
long	O
before	O
arbitrary	O
deep	O
models	O
were	O
considered	O
viable	O
convolutional	O
networks	O
were	O
also	O
some	O
of	O
the	O
first	O
neural	O
networks	O
to	O
solve	O
important	O
commercial	O
applications	O
and	O
remain	O
at	O
the	O
forefront	O
of	O
commercial	O
applications	O
of	O
deep	O
learning	O
today	O
for	O
example	B
in	O
the	O
the	O
neural	B
network	I
research	O
group	O
at	O
att	O
developed	O
a	O
convolutional	B
network	I
for	O
reading	O
checks	O
by	O
the	O
end	O
of	O
the	O
this	O
system	O
deployed	O
by	O
nec	O
was	O
reading	O
over	O
of	O
all	O
the	O
checks	O
in	O
the	O
us	O
later	O
several	O
ocr	O
and	O
handwriting	O
recognition	O
systems	O
based	O
on	O
convolutional	O
nets	O
were	O
deployed	O
by	O
for	O
more	O
details	O
on	O
such	O
applications	O
microsoft	O
and	O
more	O
modern	O
applications	O
of	O
convolutional	O
networks	O
see	O
lecun	O
et	O
al	O
for	O
a	O
more	O
in-depth	O
history	O
of	O
convolutional	O
networks	O
up	O
to	O
lecun	O
et	O
al	O
see	O
chapter	O
simard	O
et	O
al	O
convolutional	O
networks	O
were	O
also	O
used	O
to	O
win	O
many	O
contests	O
the	O
current	O
intensity	O
of	O
commercial	O
interest	O
in	O
deep	O
learning	O
began	O
when	O
krizhevsky	O
et	O
al	O
won	O
the	O
imagenet	O
object	B
recognition	I
challenge	B
but	O
convolutional	O
networks	O
chapter	O
convolutional	O
networks	O
had	O
been	O
used	O
to	O
win	O
other	O
machine	B
learning	I
and	O
computer	B
vision	I
contests	O
with	O
less	O
impact	O
for	O
years	O
earlier	O
convolutional	O
nets	O
were	O
some	O
of	O
the	O
first	O
working	O
deep	O
networks	O
trained	O
with	O
back-propagation	B
it	O
is	O
not	O
entirely	O
clear	O
why	O
convolutional	O
networks	O
succeeded	O
when	O
general	O
back-propagation	B
networks	O
were	O
considered	O
to	O
have	O
failed	O
it	O
may	O
simply	O
be	O
that	O
convolutional	O
networks	O
were	O
more	O
computationally	O
efficient	O
than	O
fully	O
connected	O
networks	O
so	O
it	O
was	O
easier	O
to	O
run	O
multiple	O
experiments	O
with	O
them	O
and	O
tune	O
their	O
implementation	O
and	O
hyperparameters	O
larger	O
networks	O
also	O
seem	O
to	O
be	O
easier	O
to	O
train	O
with	O
modern	O
hardware	O
large	O
fully	O
connected	O
networks	O
appear	O
to	O
perform	O
reasonably	O
on	O
many	O
tasks	O
even	O
when	O
using	O
datasets	O
that	O
were	O
available	O
and	O
activation	O
functions	O
that	O
were	O
popular	O
during	O
the	O
times	O
when	O
fully	O
connected	O
networks	O
were	O
believed	O
not	O
to	O
work	O
well	O
it	O
may	O
be	O
that	O
the	O
primary	O
barriers	O
to	O
the	O
success	O
of	O
neural	O
networks	O
were	O
psychological	O
did	O
not	O
expect	O
neural	O
networks	O
to	O
work	O
so	O
they	O
did	O
not	O
make	O
a	O
serious	O
effort	O
to	O
use	O
neural	O
networks	O
whatever	O
the	O
case	O
it	O
is	O
fortunate	O
that	O
convolutional	O
networks	O
performed	O
well	O
decades	O
ago	O
in	O
many	O
ways	O
they	O
carried	O
the	O
torch	O
for	O
the	O
rest	O
of	O
deep	O
learning	O
and	O
paved	O
the	O
way	O
to	O
the	O
acceptance	O
of	O
neural	O
networks	O
in	O
general	O
convolutional	O
networks	O
provide	O
a	O
way	O
to	O
specialize	O
neural	O
networks	O
to	O
work	O
with	O
data	O
that	O
has	O
a	O
clear	O
grid-structured	O
topology	O
and	O
to	O
scale	O
such	O
models	O
to	O
very	O
large	O
size	O
this	O
approach	O
has	O
been	O
the	O
most	O
successful	O
on	O
a	O
two-dimensional	O
image	O
topology	O
to	O
process	O
one-dimensional	O
sequential	O
data	O
we	O
turn	O
next	O
to	O
another	O
powerful	O
specialization	O
of	O
the	O
neural	O
networks	O
framework	O
recurrent	O
neural	O
networks	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
rumelhart	O
et	O
al	O
recurrent	O
neural	O
networks	O
or	O
rnns	O
are	O
a	O
family	O
of	O
neural	O
networks	O
for	O
processing	O
sequential	O
data	O
much	O
as	O
a	O
convolutional	B
network	I
is	O
a	O
neural	B
network	I
that	O
is	O
specialized	O
for	O
processing	O
a	O
grid	O
of	O
values	O
x	O
such	O
as	O
an	O
image	O
a	O
recurrent	B
neural	B
network	I
is	O
a	O
neural	B
network	I
that	O
is	O
specialized	O
for	O
processing	O
a	O
sequence	O
of	O
values	O
x	O
just	O
as	O
convolutional	O
networks	O
can	O
readily	O
scale	O
to	O
images	O
with	O
large	O
width	O
and	O
height	O
and	O
some	O
convolutional	O
networks	O
can	O
process	O
images	O
of	O
variable	O
size	O
recurrent	O
networks	O
can	O
scale	O
to	O
much	O
longer	O
sequences	O
than	O
would	O
be	O
practical	O
for	O
networks	O
without	O
sequence-based	O
specialization	O
most	O
recurrent	O
networks	O
can	O
also	O
process	O
sequences	O
of	O
variable	O
length	O
to	O
go	O
from	O
multi-layer	O
networks	O
to	O
recurrent	O
networks	O
we	O
need	O
to	O
take	O
advantage	O
of	O
one	O
of	O
the	O
early	O
ideas	O
found	O
in	O
machine	B
learning	I
and	O
statistical	O
models	O
of	O
the	O
sharing	O
parameters	O
across	O
different	O
parts	O
of	O
a	O
model	O
parameter	O
sharing	O
makes	O
it	O
possible	O
to	O
extend	O
and	O
apply	O
the	O
model	O
to	O
examples	O
of	O
different	O
forms	O
lengths	O
here	O
and	O
generalize	O
across	O
them	O
if	O
we	O
had	O
separate	O
parameters	O
for	O
each	O
value	O
of	O
the	O
time	O
index	O
we	O
could	O
not	O
generalize	O
to	O
sequence	O
lengths	O
not	O
seen	O
during	O
training	O
nor	O
share	O
statistical	O
strength	O
across	O
different	O
sequence	O
lengths	O
and	O
across	O
different	O
positions	O
in	O
time	O
such	O
sharing	O
is	O
particularly	O
important	O
when	O
a	O
specific	O
piece	O
of	O
information	O
can	O
occur	O
at	O
multiple	O
positions	O
within	O
the	O
sequence	O
for	O
example	B
consider	O
the	O
two	O
sentences	O
i	O
went	O
to	O
nepal	O
in	O
and	O
in	O
i	O
went	O
to	O
nepal	O
if	O
we	O
ask	O
a	O
machine	B
learning	I
model	O
to	O
read	O
each	O
sentence	O
and	O
extract	O
the	O
year	O
in	O
which	O
the	O
narrator	O
went	O
to	O
nepal	O
we	O
would	O
like	O
it	O
to	O
recognize	O
the	O
year	O
as	O
the	O
relevant	O
piece	O
of	O
information	O
whether	O
it	O
appears	O
in	O
the	O
sixth	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
word	O
or	O
the	O
second	O
word	O
of	O
the	O
sentence	O
suppose	O
that	O
we	O
trained	O
a	O
feedforward	O
network	O
that	O
processes	O
sentences	O
of	O
fixed	O
length	O
a	O
traditional	O
fully	O
connected	O
feedforward	O
network	O
would	O
have	O
separate	O
parameters	O
for	O
each	O
input	O
feature	B
so	O
it	O
would	O
need	O
to	O
learn	O
all	O
of	O
the	O
rules	O
of	O
the	O
language	O
separately	O
at	O
each	O
position	O
in	O
the	O
sentence	O
by	O
comparison	O
a	O
recurrent	B
neural	B
network	I
shares	O
the	O
same	O
weights	B
across	O
several	O
time	O
steps	O
et	O
al	O
et	O
al	O
lang	O
a	O
related	O
idea	O
is	O
the	O
use	O
of	O
convolution	O
across	O
a	O
temporal	O
sequence	O
this	O
convolutional	O
approach	O
is	O
the	O
basis	O
for	O
time-delay	O
neural	O
networks	O
and	O
hinton	O
waibel	O
the	O
convolution	O
operation	B
allows	O
a	O
network	O
to	O
share	O
parameters	O
across	O
time	O
but	O
is	O
shallow	O
the	O
output	O
of	O
convolution	O
is	O
a	O
sequence	O
where	O
each	O
member	O
of	O
the	O
output	O
is	O
a	O
function	O
of	O
a	O
small	O
number	O
of	O
neighboring	O
members	O
of	O
the	O
input	O
the	O
idea	O
of	O
parameter	O
sharing	O
manifests	O
in	O
the	O
application	O
of	O
the	O
same	O
convolution	O
kernel	O
at	O
each	O
time	O
step	O
recurrent	O
networks	O
share	O
parameters	O
in	O
a	O
different	O
way	O
each	O
member	O
of	O
the	O
output	O
is	O
a	O
function	O
of	O
the	O
previous	O
members	O
of	O
the	O
output	O
each	O
member	O
of	O
the	O
output	O
is	O
produced	O
using	O
the	O
same	O
update	O
rule	O
applied	O
to	O
the	O
previous	O
outputs	O
this	O
recurrent	O
formulation	O
results	O
in	O
the	O
sharing	O
of	O
parameters	O
through	O
a	O
very	O
deep	O
computational	B
graph	I
for	O
the	O
simplicity	O
of	O
exposition	O
we	O
refer	O
to	O
rnns	O
as	O
operating	O
on	O
a	O
sequence	O
that	O
contains	O
vectors	O
x	O
with	O
the	O
time	O
step	O
index	O
t	O
ranging	O
from	O
in	O
practice	O
recurrent	O
networks	O
usually	O
operate	O
on	O
minibatches	O
of	O
such	O
sequences	O
with	O
a	O
different	O
sequence	O
length	O
for	O
each	O
member	O
of	O
the	O
minibatch	B
we	O
have	O
omitted	O
the	O
minibatch	B
indices	O
to	O
simplify	O
notation	O
moreover	O
the	O
time	O
step	O
index	O
need	O
not	O
literally	O
refer	O
to	O
the	O
passage	O
of	O
time	O
in	O
the	O
real	O
world	O
sometimes	O
it	O
refers	O
only	O
to	O
the	O
position	O
in	O
the	O
sequence	O
rnns	O
may	O
also	O
be	O
applied	O
in	O
two	O
dimensions	O
across	O
spatial	O
data	O
such	O
as	O
images	O
and	O
even	O
when	O
applied	O
to	O
data	O
involving	O
time	O
the	O
network	O
may	O
have	O
connections	O
that	O
go	O
backwards	O
in	O
time	O
provided	O
that	O
the	O
entire	O
sequence	O
is	O
observed	O
before	O
it	O
is	O
provided	O
to	O
the	O
network	O
this	O
chapter	O
extends	O
the	O
idea	O
of	O
a	O
computational	B
graph	I
to	O
include	O
cycles	O
these	O
cycles	O
represent	O
the	O
influence	O
of	O
the	O
present	O
value	O
of	O
a	O
variable	O
on	O
its	O
own	O
value	O
at	O
a	O
future	O
time	O
step	O
such	O
computational	O
graphs	O
allow	O
us	O
to	O
define	O
recurrent	O
neural	O
networks	O
we	O
then	O
describe	O
many	O
different	O
ways	O
to	O
construct	O
train	O
and	O
use	O
recurrent	O
neural	O
networks	O
for	O
more	O
information	O
on	O
recurrent	O
neural	O
networks	O
than	O
is	O
available	O
in	O
this	O
chapter	O
we	O
refer	O
the	O
reader	O
to	O
the	O
textbook	O
of	O
graves	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
unfolding	O
computational	O
graphs	O
a	O
computational	B
graph	I
is	O
a	O
way	O
to	O
formalize	O
the	O
structure	O
of	O
a	O
set	O
of	O
computations	O
such	O
as	O
those	O
involved	O
in	O
mapping	O
inputs	O
and	O
parameters	O
to	O
outputs	O
and	O
loss	O
please	O
refer	O
to	O
section	O
for	O
a	O
general	O
introduction	O
in	O
this	O
section	O
we	O
explain	O
the	O
idea	O
of	O
unfolding	O
a	O
recursive	O
or	O
recurrent	O
computation	O
into	O
a	O
computational	B
graph	I
that	O
has	O
a	O
repetitive	O
structure	O
typically	O
corresponding	O
to	O
a	O
chain	O
of	O
events	O
unfolding	O
this	O
graph	O
results	O
in	O
the	O
sharing	O
of	O
parameters	O
across	O
a	O
deep	O
network	O
structure	O
for	O
example	B
consider	O
the	O
classical	O
form	O
of	O
a	O
dynamical	O
system	O
s	O
s	O
t	O
where	O
s	O
is	O
called	O
the	O
state	O
of	O
the	O
system	O
equation	O
is	O
recurrent	O
because	O
the	O
definition	O
of	O
s	O
at	O
time	O
t	O
refers	O
back	O
to	O
the	O
same	O
definition	O
at	O
time	O
t	O
for	O
a	O
finite	O
number	O
of	O
time	O
steps	O
the	O
graph	O
can	O
be	O
unfolded	O
by	O
applying	O
time	O
times	O
for	O
example	B
if	O
we	O
unfold	O
equation	O
for	O
the	O
definition	O
steps	O
we	O
obtain	O
f	O
f	O
unfolding	O
the	O
equation	O
by	O
repeatedly	O
applying	O
the	O
definition	O
in	O
this	O
way	O
has	O
yielded	O
an	O
expression	O
that	O
does	O
not	O
involve	O
recurrence	O
such	O
an	O
expression	O
can	O
now	O
be	O
represented	O
by	O
a	O
traditional	O
directed	O
acyclic	O
computational	B
graph	I
the	O
unfolded	O
computational	B
graph	I
of	O
equation	O
is	O
illustrated	O
in	O
figure	O
and	O
equation	O
s	O
ff	O
st	O
st	O
ff	O
s	O
ff	O
s	O
ts	O
t	O
ff	O
s	O
figure	O
the	O
classical	B
dynamical	I
system	I
described	O
by	O
equation	O
illustrated	O
as	O
an	O
unfolded	O
computational	B
graph	I
each	O
node	O
represents	O
the	O
state	O
at	O
some	O
time	O
t	O
and	O
the	O
function	O
f	O
maps	O
the	O
state	O
at	O
t	O
to	O
the	O
state	O
at	O
t	O
the	O
same	O
parameters	O
same	O
value	O
of	O
are	O
used	O
for	O
all	O
time	O
steps	O
used	O
to	O
parametrize	O
f	O
as	O
another	O
example	B
let	O
us	O
consider	O
a	O
dynamical	O
system	O
driven	O
by	O
an	O
external	O
signal	O
x	O
t	O
s	O
s	O
x	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
where	O
we	O
see	O
that	O
the	O
state	O
now	O
contains	O
information	O
about	O
the	O
whole	O
past	O
sequence	O
recurrent	O
neural	O
networks	O
can	O
be	O
built	O
in	O
many	O
different	O
ways	O
much	O
as	O
almost	O
any	O
function	O
can	O
be	O
considered	O
a	O
feedforward	B
neural	B
network	I
essentially	O
any	O
function	O
involving	O
recurrence	O
can	O
be	O
considered	O
a	O
recurrent	B
neural	B
network	I
many	O
recurrent	O
neural	O
networks	O
use	O
equation	O
or	O
a	O
similar	O
equation	O
to	O
define	O
the	O
values	O
of	O
their	O
hidden	O
units	O
to	O
indicate	O
that	O
the	O
state	O
is	O
the	O
hidden	O
h	O
to	O
represent	O
units	O
of	O
the	O
network	O
we	O
now	O
rewrite	O
equation	O
the	O
state	O
using	O
the	O
variable	O
t	O
h	O
h	O
x	O
illustrated	O
in	O
figure	O
as	O
output	O
layers	O
that	O
read	O
information	O
out	O
of	O
the	O
state	O
typical	O
rnns	O
will	O
add	O
extra	O
architectural	O
features	O
such	O
h	O
to	O
make	O
predictions	O
t	O
x	O
when	O
the	O
recurrent	B
network	I
is	O
trained	O
to	O
perform	O
a	O
task	O
that	O
requires	O
predicting	O
the	O
future	O
from	O
the	O
past	O
the	O
network	O
typically	O
learns	O
to	O
use	O
h	O
as	O
a	O
kind	O
of	O
lossy	O
summary	O
of	O
the	O
task-relevant	O
aspects	O
of	O
the	O
past	O
sequence	O
of	O
inputs	O
up	O
to	O
t	O
this	O
summary	O
is	O
in	O
general	O
necessarily	O
lossy	O
since	O
it	O
maps	O
an	O
arbitrary	O
length	O
sequence	O
t	O
x	O
to	O
a	O
fixed	O
length	O
vector	O
h	O
depending	O
on	O
the	O
training	O
criterion	O
this	O
summary	O
might	O
selectively	O
keep	O
some	O
aspects	O
of	O
the	O
past	O
sequence	O
with	O
more	O
precision	B
than	O
other	O
aspects	O
for	O
example	B
if	O
the	O
rnn	O
is	O
used	O
in	O
statistical	O
language	O
modeling	O
typically	O
to	O
predict	O
the	O
next	O
word	O
given	O
previous	O
words	O
it	O
may	O
not	O
be	O
necessary	O
to	O
store	O
all	O
of	O
the	O
information	O
in	O
the	O
input	O
sequence	O
up	O
to	O
time	O
t	O
but	O
rather	O
only	O
enough	O
information	O
to	O
predict	O
the	O
rest	O
of	O
the	O
sentence	O
the	O
most	O
demanding	O
situation	O
is	O
when	O
we	O
ask	O
h	O
to	O
be	O
rich	O
enough	O
to	O
allow	O
one	O
to	O
approximately	O
recover	O
the	O
input	O
sequence	O
as	O
in	O
autoencoder	O
frameworks	O
h	O
ff	O
unfold	O
hh	O
xx	O
ht	O
ht	O
h	O
h	O
th	O
t	O
h	O
ff	O
ff	O
ff	O
f	O
xt	O
xt	O
x	O
t	O
x	O
tx	O
figure	O
a	O
recurrent	B
network	I
with	O
no	O
outputs	O
this	O
recurrent	B
network	I
just	O
processes	O
information	O
from	O
the	O
input	O
x	O
by	O
incorporating	O
it	O
into	O
the	O
state	O
h	O
that	O
is	O
passed	O
forward	O
through	O
time	O
diagram	O
the	O
black	O
square	O
indicates	O
a	O
delay	O
of	O
a	O
single	O
time	O
step	O
the	O
same	O
network	O
seen	O
as	O
an	O
unfolded	O
computational	B
graph	I
where	O
each	O
node	O
is	O
now	O
associated	O
with	O
one	O
particular	O
time	O
instance	O
equation	O
can	O
be	O
drawn	O
in	O
two	O
different	O
ways	O
one	O
way	O
to	O
draw	O
the	O
rnn	O
is	O
with	O
a	O
diagram	O
containing	O
one	O
node	O
for	O
every	O
component	O
that	O
might	O
exist	O
in	O
a	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
physical	O
implementation	O
of	O
the	O
model	O
such	O
as	O
a	O
biological	O
neural	B
network	I
in	O
this	O
view	O
the	O
network	O
defines	O
a	O
circuit	O
that	O
operates	O
in	O
real	O
time	O
with	O
physical	O
parts	O
whose	O
current	O
state	O
can	O
influence	O
their	O
future	O
state	O
as	O
in	O
the	O
left	O
of	O
figure	O
throughout	O
this	O
chapter	O
we	O
use	O
a	O
black	O
square	O
in	O
a	O
circuit	O
diagram	O
to	O
indicate	O
that	O
an	O
interaction	O
takes	O
place	O
with	O
a	O
delay	O
of	O
a	O
single	O
time	O
step	O
from	O
the	O
state	O
at	O
time	O
t	O
to	O
the	O
state	O
at	O
time	O
t	O
the	O
other	O
way	O
to	O
draw	O
the	O
rnn	O
is	O
as	O
an	O
unfolded	O
computational	B
graph	I
in	O
which	O
each	O
component	O
is	O
represented	O
by	O
many	O
different	O
variables	O
with	O
one	O
variable	O
per	O
time	O
step	O
representing	O
the	O
state	O
of	O
the	O
component	O
at	O
that	O
point	O
in	O
time	O
each	O
variable	O
for	O
each	O
time	O
step	O
is	O
drawn	O
as	O
a	O
separate	O
node	O
of	O
the	O
computational	B
graph	I
as	O
in	O
the	O
right	O
of	O
figure	O
what	O
we	O
call	O
unfolding	O
is	O
the	O
operation	B
that	O
maps	O
a	O
circuit	O
as	O
in	O
the	O
left	O
side	O
of	O
the	O
figure	O
to	O
a	O
computational	B
graph	I
with	O
repeated	O
pieces	O
as	O
in	O
the	O
right	O
side	O
the	O
unfolded	O
graph	O
now	O
has	O
a	O
size	O
that	O
depends	O
on	O
the	O
sequence	O
length	O
we	O
can	O
represent	O
the	O
unfolded	O
recurrence	O
after	O
t	O
steps	O
with	O
a	O
function	O
g	O
h	O
x	O
t	O
t	O
x	O
t	O
h	O
x	O
x	O
the	O
function	O
g	O
takes	O
the	O
whole	O
past	O
sequence	O
x	O
t	O
as	O
input	O
and	O
produces	O
the	O
current	O
state	O
but	O
the	O
unfolded	O
recurrent	O
structure	O
allows	O
us	O
to	O
factorize	O
g	O
into	O
repeated	O
application	O
of	O
a	O
function	O
f	O
the	O
unfolding	O
process	O
thus	O
introduces	O
two	O
major	O
advantages	O
t	O
x	O
regardless	O
of	O
the	O
sequence	O
length	O
the	O
learned	O
model	O
always	O
has	O
the	O
same	O
input	O
size	O
because	O
it	O
is	O
specified	O
in	O
terms	O
of	O
transition	O
from	O
one	O
state	O
to	O
another	O
state	O
rather	O
than	O
specified	O
in	O
terms	O
of	O
a	O
variable-length	O
history	O
of	O
states	O
it	O
is	O
possible	O
to	O
use	O
the	O
same	O
transition	O
function	O
f	O
with	O
the	O
same	O
parameters	O
at	O
every	O
time	O
step	O
these	O
two	O
factors	O
make	O
it	O
possible	O
to	O
learn	O
a	O
single	O
model	O
f	O
that	O
operates	O
on	O
all	O
time	O
steps	O
and	O
all	O
sequence	O
lengths	O
rather	O
than	O
needing	O
to	O
learn	O
a	O
separate	O
model	O
g	O
for	O
all	O
possible	O
time	O
steps	O
learning	O
a	O
single	O
shared	O
model	O
allows	O
generalization	B
to	O
sequence	O
lengths	O
that	O
did	O
not	O
appear	O
in	O
the	O
training	O
set	O
and	O
allows	O
the	O
model	O
to	O
be	O
estimated	O
with	O
far	O
fewer	O
training	O
examples	O
than	O
would	O
be	O
required	O
without	O
parameter	O
sharing	O
both	O
the	O
recurrent	O
graph	O
and	O
the	O
unrolled	O
graph	O
have	O
their	O
uses	O
the	O
recurrent	O
graph	O
is	O
succinct	O
the	O
unfolded	O
graph	O
provides	O
an	O
explicit	O
description	O
of	O
which	O
computations	O
to	O
perform	O
the	O
unfolded	O
graph	O
also	O
helps	O
to	O
illustrate	O
the	O
idea	O
of	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
information	O
flow	O
forward	O
in	O
time	O
outputs	O
and	O
losses	O
and	O
backward	O
in	O
time	O
gradients	O
by	O
explicitly	O
showing	O
the	O
path	O
along	O
which	O
this	O
information	O
flows	O
recurrent	O
neural	O
networks	O
armed	O
with	O
the	O
graph	O
unrolling	O
and	O
parameter	O
sharing	O
ideas	O
of	O
section	O
can	O
design	O
a	O
wide	O
variety	O
of	O
recurrent	O
neural	O
networks	O
we	O
yy	O
ll	O
oo	O
vv	O
hh	O
uu	O
xx	O
unfold	O
ww	O
ww	O
h	O
yt	O
yt	O
lt	O
lt	O
ot	O
ot	O
vv	O
ht	O
ht	O
y	O
y	O
ty	O
t	O
l	O
l	O
tl	O
t	O
o	O
t	O
o	O
to	O
ww	O
vv	O
ww	O
vv	O
ww	O
h	O
h	O
th	O
t	O
h	O
uu	O
uu	O
uu	O
xt	O
xt	O
x	O
x	O
tx	O
t	O
figure	O
the	O
computational	B
graph	I
to	O
compute	O
the	O
training	O
loss	O
of	O
a	O
recurrent	B
network	I
that	O
maps	O
an	O
input	O
sequence	O
of	O
x	O
values	O
to	O
a	O
corresponding	O
sequence	O
of	O
output	O
o	O
values	O
a	O
loss	O
l	O
measures	O
how	O
far	O
each	O
o	O
is	O
from	O
the	O
corresponding	O
training	O
target	O
y	O
when	O
using	O
softmax	O
outputs	O
we	O
assume	O
o	O
is	O
the	O
unnormalized	O
log	O
probabilities	O
the	O
loss	O
l	O
internally	O
computes	O
y	O
softmaxo	O
and	O
compares	O
this	O
to	O
the	O
target	O
y	O
the	O
rnn	O
has	O
input	O
to	O
hidden	O
connections	O
parametrized	O
by	O
a	O
weight	O
matrix	O
u	O
hidden-to-hidden	O
recurrent	O
connections	O
parametrized	O
by	O
a	O
weight	O
matrix	O
w	O
and	O
hidden-to-output	O
connections	O
parametrized	O
by	O
a	O
weight	O
matrix	O
v	O
equation	O
rnn	O
and	O
its	O
loss	O
drawn	O
with	O
recurrent	O
connections	O
same	O
seen	O
as	O
an	O
timeunfolded	O
computational	B
graph	I
where	O
each	O
node	O
is	O
now	O
associated	O
with	O
one	O
particular	O
time	O
instance	O
defines	O
forward	B
propagation	I
in	O
this	O
model	O
some	O
examples	O
of	O
important	O
design	O
patterns	O
for	O
recurrent	O
neural	O
networks	O
include	O
the	O
following	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
recurrent	O
networks	O
that	O
produce	O
an	O
output	O
at	O
each	O
time	O
step	O
and	O
have	O
recurrent	O
connections	O
between	O
hidden	O
units	O
illustrated	O
in	O
figure	O
recurrent	O
networks	O
that	O
produce	O
an	O
output	O
at	O
each	O
time	O
step	O
and	O
have	O
recurrent	O
connections	O
only	O
from	O
the	O
output	O
at	O
one	O
time	O
step	O
to	O
the	O
hidden	O
units	O
at	O
the	O
next	O
time	O
step	O
illustrated	O
in	O
figure	O
recurrent	O
networks	O
with	O
recurrent	O
connections	O
between	O
hidden	O
units	O
that	O
read	O
an	O
entire	O
sequence	O
and	O
then	O
produce	O
a	O
single	O
output	O
illustrated	O
in	O
figure	O
figure	O
most	O
of	O
the	O
chapter	O
is	O
a	O
reasonably	O
representative	O
example	B
that	O
we	O
return	O
to	O
throughout	O
and	O
equation	O
the	O
recurrent	B
neural	B
network	I
of	O
figure	O
is	O
universal	O
in	O
the	O
sense	O
that	O
any	O
function	O
computable	O
by	O
a	O
turing	O
machine	O
can	O
be	O
computed	O
by	O
such	O
a	O
recurrent	B
network	I
of	O
a	O
finite	O
size	O
the	O
output	O
can	O
be	O
read	O
from	O
the	O
rnn	O
after	O
a	O
number	O
of	O
time	O
steps	O
that	O
is	O
asymptotically	O
linear	O
in	O
the	O
number	O
of	O
time	O
steps	O
used	O
by	O
the	O
turing	O
machine	O
and	O
asymptotically	O
linear	O
in	O
the	O
length	O
of	O
the	O
input	O
and	O
sontag	O
siegelmann	O
siegelmann	O
and	O
sontag	O
hyotyniemi	O
the	O
functions	O
computable	O
by	O
a	O
turing	O
machine	O
are	O
discrete	O
so	O
these	O
results	O
regard	O
exact	O
implementation	O
of	O
the	O
function	O
not	O
approximations	O
the	O
rnn	O
when	O
used	O
as	O
a	O
turing	O
machine	O
takes	O
a	O
binary	O
sequence	O
as	O
input	O
and	O
its	O
outputs	O
must	O
be	O
discretized	O
to	O
provide	O
a	O
binary	O
output	O
it	O
is	O
possible	O
to	O
compute	O
all	O
functions	O
in	O
this	O
setting	O
using	O
a	O
single	O
specific	O
rnn	O
of	O
finite	O
size	O
and	O
sontag	O
use	O
units	O
the	O
input	O
of	O
the	O
turing	O
machine	O
is	O
a	O
specification	O
of	O
the	O
function	O
to	O
be	O
computed	O
so	O
the	O
same	O
network	O
that	O
simulates	O
this	O
turing	O
machine	O
is	O
sufficient	O
for	O
all	O
problems	O
the	O
theoretical	O
rnn	O
used	O
for	O
the	O
proof	O
can	O
simulate	O
an	O
unbounded	O
stack	O
by	O
representing	O
its	O
activations	O
and	O
weights	B
with	O
rational	O
numbers	O
of	O
unbounded	O
precision	B
we	O
now	O
develop	O
the	O
forward	B
propagation	I
equations	O
for	O
the	O
rnn	O
depicted	O
in	O
figure	O
the	O
figure	O
does	O
not	O
specify	O
the	O
choice	O
of	O
activation	B
function	I
for	O
the	O
hidden	O
units	O
here	O
we	O
assume	O
the	O
hyperbolic	O
tangent	O
activation	B
function	I
also	O
the	O
figure	O
does	O
not	O
specify	O
exactly	O
what	O
form	O
the	O
output	O
and	O
loss	O
function	O
take	O
here	O
we	O
assume	O
that	O
the	O
output	O
is	O
discrete	O
as	O
if	O
the	O
rnn	O
is	O
used	O
to	O
predict	O
words	O
or	O
characters	O
a	O
natural	O
way	O
to	O
represent	O
discrete	O
variables	O
is	O
to	O
regard	O
the	O
output	O
o	O
as	O
giving	O
the	O
unnormalized	O
log	O
probabilities	O
of	O
each	O
possible	O
value	O
of	O
the	O
discrete	O
variable	O
we	O
can	O
then	O
apply	O
the	O
softmax	O
operation	B
as	O
a	O
post-processing	O
step	O
to	O
obtain	O
a	O
vector	O
y	O
of	O
normalized	O
probabilities	O
over	O
the	O
output	O
forward	B
propagation	I
begins	O
with	O
a	O
specification	O
of	O
the	O
initial	O
state	O
then	O
for	O
each	O
time	O
step	O
from	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
yy	O
ll	O
oo	O
hh	O
v	O
u	O
xx	O
o	O
w	O
unfold	O
y	O
y	O
lt	O
lt	O
ot	O
ot	O
y	O
y	O
ty	O
t	O
l	O
t	O
l	O
tl	O
o	O
t	O
o	O
to	O
w	O
w	O
w	O
w	O
v	O
v	O
v	O
ht	O
ht	O
u	O
xt	O
xt	O
h	O
t	O
h	O
th	O
h	O
u	O
u	O
x	O
t	O
x	O
tx	O
figure	O
an	O
rnn	O
whose	O
only	O
recurrence	O
is	O
the	O
feedback	O
connection	O
from	O
the	O
output	O
to	O
the	O
hidden	B
layer	I
at	O
each	O
time	O
step	O
t	O
the	O
input	O
is	O
x	O
t	O
the	O
hidden	B
layer	I
activations	O
are	O
h	O
the	O
outputs	O
are	O
o	O
the	O
targets	O
are	O
y	O
and	O
the	O
loss	O
is	O
l	O
diagram	O
computational	B
graph	I
such	O
an	O
rnn	O
is	O
less	O
powerful	O
express	O
a	O
smaller	O
set	O
of	O
functions	O
than	O
those	O
in	O
the	O
family	O
represented	O
by	O
figure	O
the	O
rnn	O
in	O
figure	O
can	O
choose	O
to	O
put	O
any	O
information	O
it	O
wants	O
about	O
the	O
past	O
into	O
its	O
hidden	O
representation	O
h	O
and	O
transmit	O
h	O
to	O
the	O
future	O
the	O
rnn	O
in	O
this	O
figure	O
is	O
trained	O
to	O
put	O
a	O
specific	O
output	O
value	O
into	O
o	O
and	O
o	O
is	O
the	O
only	O
information	O
it	O
is	O
allowed	O
to	O
send	O
to	O
the	O
future	O
there	O
are	O
no	O
direct	O
connections	O
from	O
h	O
going	O
forward	O
the	O
previous	O
h	O
is	O
connected	O
to	O
the	O
present	O
only	O
indirectly	O
via	O
the	O
predictions	O
it	O
was	O
used	O
to	O
produce	O
unless	O
o	O
is	O
very	O
high-dimensional	O
and	O
rich	O
it	O
will	O
usually	O
lack	O
important	O
information	O
from	O
the	O
past	O
this	O
makes	O
the	O
rnn	O
in	O
this	O
figure	O
less	O
powerful	O
but	O
it	O
may	O
be	O
easier	O
to	O
train	O
because	O
each	O
time	O
step	O
can	O
be	O
trained	O
in	O
isolation	O
from	O
the	O
others	O
allowing	O
greater	O
parallelization	O
during	O
training	O
as	O
described	O
in	O
section	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
t	O
to	O
t	O
we	O
apply	O
the	O
following	O
update	O
equations	O
a	O
t	O
w	O
h	O
h	O
tanha	O
o	O
v	O
h	O
y	O
softmaxo	O
u	O
x	O
where	O
the	O
parameters	O
are	O
the	O
bias	O
vectors	O
b	O
and	O
c	O
along	O
with	O
the	O
weight	O
matrices	O
u	O
v	O
and	O
w	O
respectively	O
for	O
input-to-hidden	O
hidden-to-output	O
and	O
hidden-tohidden	O
connections	O
this	O
is	O
an	O
example	B
of	O
a	O
recurrent	B
network	I
that	O
maps	O
an	O
input	O
sequence	O
to	O
an	O
output	O
sequence	O
of	O
the	O
same	O
length	O
the	O
total	O
loss	O
for	O
a	O
values	O
would	O
then	O
be	O
just	O
given	O
sequence	O
of	O
the	O
sum	O
of	O
the	O
losses	O
over	O
all	O
the	O
time	O
steps	O
for	O
example	B
if	O
l	O
is	O
the	O
negative	O
log-likelihood	O
of	O
y	O
given	O
x	O
then	O
values	O
paired	O
with	O
a	O
sequence	O
of	O
x	O
y	O
l	O
x	O
y	O
x	O
y	O
log	O
pmodel	O
l	O
t	O
t	O
y	O
x	O
is	O
given	O
by	O
reading	O
the	O
entry	O
for	O
y	O
where	O
pmodel	O
from	O
the	O
model	O
s	O
output	O
vector	O
y	O
computing	O
the	O
gradient	B
of	O
this	O
loss	O
function	O
with	O
respect	O
to	O
the	O
parameters	O
is	O
an	O
expensive	O
operation	B
the	O
gradient	B
computation	O
involves	O
performing	O
a	O
forward	B
propagation	I
pass	O
moving	O
left	O
to	O
right	O
through	O
our	O
illustration	O
of	O
the	O
unrolled	O
graph	O
in	O
figure	O
followed	O
by	O
a	O
backward	O
propagation	O
pass	O
moving	O
right	O
to	O
left	O
through	O
the	O
graph	O
the	O
runtime	O
is	O
o	O
and	O
cannot	O
be	O
reduced	O
by	O
parallelization	O
because	O
the	O
forward	B
propagation	I
graph	O
is	O
inherently	O
sequential	O
each	O
time	O
step	O
may	O
only	O
be	O
computed	O
after	O
the	O
previous	O
one	O
states	O
computed	O
in	O
the	O
forward	O
pass	O
must	O
be	O
stored	O
until	O
they	O
are	O
reused	O
during	O
the	O
backward	O
pass	O
so	O
the	O
memory	O
cost	O
is	O
also	O
o	O
the	O
back-propagation	B
algorithm	O
applied	O
to	O
the	O
unrolled	O
graph	O
with	O
o	O
cost	O
is	O
called	O
back-propagation	B
through	I
time	I
or	O
bptt	O
and	O
is	O
discussed	O
further	O
in	O
section	O
the	O
network	O
with	O
recurrence	O
between	O
hidden	O
units	O
is	O
thus	O
very	O
powerful	O
but	O
also	O
expensive	O
to	O
train	O
is	O
there	O
an	O
alternative	O
teacher	O
forcing	O
and	O
networks	O
with	O
output	O
recurrence	O
the	O
network	O
with	O
recurrent	O
connections	O
only	O
from	O
the	O
output	O
at	O
one	O
time	O
step	O
to	O
is	O
strictly	O
less	O
powerful	O
the	O
hidden	O
units	O
at	O
the	O
next	O
time	O
step	O
in	O
figure	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
because	O
it	O
lacks	O
hidden-to-hidden	O
recurrent	O
connections	O
for	O
example	B
it	O
cannot	O
simulate	O
a	O
universal	O
turing	O
machine	O
because	O
this	O
network	O
lacks	O
hidden-to-hidden	O
recurrence	O
it	O
requires	O
that	O
the	O
output	O
units	O
capture	O
all	O
of	O
the	O
information	O
about	O
the	O
past	O
that	O
the	O
network	O
will	O
use	O
to	O
predict	O
the	O
future	O
because	O
the	O
output	O
units	O
are	O
explicitly	O
trained	O
to	O
match	O
the	O
training	O
set	O
targets	O
they	O
are	O
unlikely	O
to	O
capture	O
the	O
necessary	O
information	O
about	O
the	O
past	O
history	O
of	O
the	O
input	O
unless	O
the	O
user	O
knows	O
how	O
to	O
describe	O
the	O
full	O
state	O
of	O
the	O
system	O
and	O
provides	O
it	O
as	O
part	O
of	O
the	O
training	O
set	O
targets	O
the	O
advantage	O
of	O
eliminating	O
hidden-to-hidden	O
recurrence	O
is	O
that	O
for	O
any	O
loss	O
function	O
based	O
on	O
comparing	O
the	O
prediction	O
at	O
time	O
t	O
to	O
the	O
training	O
target	O
at	O
time	O
t	O
all	O
the	O
time	O
steps	O
are	O
decoupled	O
training	O
can	O
thus	O
be	O
parallelized	O
with	O
the	O
gradient	B
for	O
each	O
step	O
t	O
computed	O
in	O
isolation	O
there	O
is	O
no	O
need	O
to	O
compute	O
the	O
output	O
for	O
the	O
previous	O
time	O
step	O
first	O
because	O
the	O
training	O
set	O
provides	O
the	O
ideal	O
value	O
of	O
that	O
output	O
l	O
l	O
y	O
y	O
o	O
o	O
v	O
h	O
h	O
h	O
ht	O
ht	O
w	O
w	O
w	O
w	O
u	O
u	O
u	O
u	O
xt	O
xt	O
x	O
x	O
x	O
x	O
figure	O
time-unfolded	O
recurrent	B
neural	B
network	I
with	O
a	O
single	O
output	O
at	O
the	O
end	O
of	O
the	O
sequence	O
such	O
a	O
network	O
can	O
be	O
used	O
to	O
summarize	O
a	O
sequence	O
and	O
produce	O
a	O
fixed-size	O
representation	O
used	O
as	O
input	O
for	O
further	O
processing	O
there	O
might	O
be	O
a	O
target	O
right	O
at	O
the	O
end	O
depicted	O
here	O
or	O
the	O
gradient	B
on	O
the	O
output	O
o	O
can	O
be	O
obtained	O
by	O
back-propagating	O
from	O
further	O
downstream	O
modules	O
models	O
that	O
have	O
recurrent	O
connections	O
from	O
their	O
outputs	O
leading	O
back	O
into	O
the	O
model	O
may	O
be	O
trained	O
with	O
teacher	O
forcing	O
teacher	O
forcing	O
is	O
a	O
procedure	O
that	O
emerges	O
from	O
the	O
maximum	B
likelihood	I
criterion	O
in	O
which	O
during	O
training	O
the	O
model	O
receives	O
the	O
ground	O
truth	O
output	O
y	O
as	O
input	O
at	O
time	O
t	O
we	O
can	O
see	O
this	O
by	O
examining	O
a	O
sequence	O
with	O
two	O
time	O
steps	O
the	O
conditional	O
maximum	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
y	O
y	O
lt	O
lt	O
ot	O
ot	O
v	O
ht	O
ht	O
u	O
xt	O
xt	O
w	O
y	O
l	O
o	O
v	O
h	O
u	O
x	O
ot	O
ot	O
w	O
v	O
ht	O
ht	O
u	O
xt	O
xt	O
o	O
v	O
h	O
u	O
x	O
train	O
time	O
test	O
time	O
figure	O
illustration	O
of	O
teacher	O
forcing	O
teacher	O
forcing	O
is	O
a	O
training	O
technique	O
that	O
is	O
applicable	O
to	O
rnns	O
that	O
have	O
connections	O
from	O
their	O
output	O
to	O
their	O
hidden	O
states	O
at	O
the	O
next	O
time	O
step	O
train	O
time	O
we	O
feed	O
the	O
correct	O
output	O
y	O
drawn	O
from	O
the	O
train	O
set	O
as	O
input	O
to	O
h	O
when	O
the	O
model	O
is	O
deployed	O
the	O
true	O
output	O
is	O
generally	O
not	O
known	O
in	O
this	O
case	O
we	O
approximate	O
the	O
correct	O
output	O
y	O
with	O
the	O
model	O
s	O
output	O
o	O
and	O
feed	O
the	O
output	O
back	O
into	O
the	O
model	O
t	O
likelihood	O
criterion	O
is	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
log	O
p	O
y	O
log	O
p	O
y	O
log	O
p	O
y	O
in	O
this	O
example	B
we	O
see	O
that	O
at	O
time	O
t	O
the	O
model	O
is	O
trained	O
to	O
maximize	O
the	O
conditional	B
probability	I
of	O
given	O
both	O
the	O
x	O
sequence	O
so	O
far	O
and	O
the	O
previous	O
y	O
value	O
from	O
the	O
training	O
set	O
maximum	B
likelihood	I
thus	O
specifies	O
that	O
during	O
training	O
rather	O
than	O
feeding	O
the	O
model	O
s	O
own	O
output	O
back	O
into	O
itself	O
these	O
connections	O
should	O
be	O
fed	O
with	O
the	O
target	O
values	O
specifying	O
what	O
the	O
correct	O
output	O
should	O
be	O
this	O
is	O
illustrated	O
in	O
figure	O
we	O
originally	O
motivated	O
teacher	O
forcing	O
as	O
allowing	O
us	O
to	O
avoid	O
back-propagation	B
through	I
time	I
in	O
models	O
that	O
lack	O
hidden-to-hidden	O
connections	O
teacher	O
forcing	O
may	O
still	O
be	O
applied	O
to	O
models	O
that	O
have	O
hidden-to-hidden	O
connections	O
so	O
long	O
as	O
they	O
have	O
connections	O
from	O
the	O
output	O
at	O
one	O
time	O
step	O
to	O
values	O
computed	O
in	O
the	O
next	O
time	O
step	O
however	O
as	O
soon	O
as	O
the	O
hidden	O
units	O
become	O
a	O
function	O
of	O
earlier	O
time	O
steps	O
the	O
bptt	O
algorithm	O
is	O
necessary	O
some	O
models	O
may	O
thus	O
be	O
trained	O
with	O
both	O
teacher	O
forcing	O
and	O
bptt	O
the	O
disadvantage	O
of	O
strict	O
teacher	O
forcing	O
arises	O
if	O
the	O
network	O
is	O
going	O
to	O
be	O
later	O
used	O
in	O
an	O
open-loop	O
mode	O
with	O
the	O
network	O
outputs	O
samples	O
from	O
the	O
output	O
distribution	O
fed	O
back	O
as	O
input	O
in	O
this	O
case	O
the	O
kind	O
of	O
inputs	O
that	O
the	O
network	O
sees	O
during	O
training	O
could	O
be	O
quite	O
different	O
from	O
the	O
kind	O
of	O
inputs	O
that	O
it	O
will	O
see	O
at	O
test	O
time	O
one	O
way	O
to	O
mitigate	O
this	O
problem	O
is	O
to	O
train	O
with	O
both	O
teacher-forced	O
inputs	O
and	O
with	O
free-running	O
inputs	O
for	O
example	B
by	O
predicting	O
the	O
correct	O
target	O
a	O
number	O
of	O
steps	O
in	O
the	O
future	O
through	O
the	O
unfolded	O
recurrent	O
output-to-input	O
paths	O
in	O
this	O
way	O
the	O
network	O
can	O
learn	O
to	O
take	O
into	O
account	O
input	O
conditions	O
as	O
those	O
it	O
generates	O
itself	O
in	O
the	O
free-running	O
mode	O
not	O
seen	O
during	O
training	O
and	O
how	O
to	O
map	O
the	O
state	O
back	O
towards	O
one	O
that	O
will	O
make	O
the	O
network	O
generate	O
proper	O
outputs	O
after	O
a	O
few	O
steps	O
another	O
approach	O
et	O
al	O
to	O
mitigate	O
the	O
gap	O
between	O
the	O
inputs	O
seen	O
at	O
train	O
time	O
and	O
the	O
inputs	O
seen	O
at	O
test	O
time	O
randomly	O
chooses	O
to	O
use	O
generated	O
values	O
or	O
actual	O
data	O
values	O
as	O
input	O
this	O
approach	O
exploits	O
a	O
curriculum	B
learning	I
strategy	O
to	O
gradually	O
use	O
more	O
of	O
the	O
generated	O
values	O
as	O
input	O
computing	O
the	O
gradient	B
in	O
a	O
recurrent	B
neural	B
network	I
computing	O
the	O
gradient	B
through	O
a	O
recurrent	B
neural	B
network	I
is	O
straightforward	O
one	O
simply	O
applies	O
the	O
generalized	O
back-propagation	B
algorithm	O
of	O
section	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
to	O
the	O
unrolled	O
computational	B
graph	I
no	O
specialized	O
algorithms	O
are	O
necessary	O
gradients	O
obtained	O
by	O
back-propagation	B
may	O
then	O
be	O
used	O
with	O
any	O
general-purpose	O
gradient-based	O
techniques	O
to	O
train	O
an	O
rnn	O
and	O
equation	O
to	O
gain	O
some	O
intuition	O
for	O
how	O
the	O
bptt	O
algorithm	O
behaves	O
we	O
provide	O
an	O
example	B
of	O
how	O
to	O
compute	O
gradients	O
by	O
bptt	O
for	O
the	O
rnn	O
equations	O
above	O
the	O
nodes	O
of	O
our	O
computational	B
graph	I
include	O
the	O
parameters	O
u	O
v	O
w	O
b	O
and	O
c	O
as	O
well	O
as	O
the	O
sequence	O
of	O
nodes	O
indexed	O
by	O
t	O
for	O
x	O
h	O
o	O
and	O
l	O
for	O
each	O
node	O
n	O
we	O
need	O
to	O
compute	O
the	O
gradient	B
l	O
recursively	O
based	O
on	O
the	O
gradient	B
computed	O
at	O
nodes	O
that	O
follow	O
it	O
in	O
the	O
graph	O
we	O
start	O
the	O
recursion	O
with	O
the	O
nodes	O
immediately	O
preceding	O
the	O
final	O
loss	O
n	O
l	O
l	O
in	O
this	O
derivation	O
we	O
assume	O
that	O
the	O
outputs	O
o	O
are	O
used	O
as	O
the	O
argument	O
to	O
the	O
softmax	O
function	O
to	O
obtain	O
the	O
vector	O
y	O
of	O
probabilities	O
over	O
the	O
output	O
we	O
also	O
assume	O
that	O
the	O
loss	O
is	O
the	O
negative	O
log-likelihood	O
of	O
the	O
true	O
target	O
y	O
given	O
the	O
o	O
l	O
on	O
the	O
outputs	O
at	O
time	O
step	O
t	O
for	O
all	O
i	O
t	O
is	O
as	O
input	O
so	O
far	O
the	O
gradient	B
follows	O
o	O
l	O
i	O
l	O
o	O
i	O
l	O
l	O
l	O
o	O
i	O
y	O
i	O
we	O
work	O
our	O
way	O
backwards	O
starting	O
from	O
the	O
end	O
of	O
the	O
sequence	O
at	O
the	O
final	O
time	O
step	O
h	O
only	O
has	O
o	O
as	O
a	O
descendent	O
so	O
its	O
gradient	B
is	O
simple	O
h	O
l	O
v	O
o	O
l	O
we	O
can	O
then	O
iterate	O
backwards	O
in	O
time	O
to	O
back-propagate	O
gradients	O
through	O
time	O
down	O
to	O
t	O
noting	O
that	O
h	O
t	O
has	O
as	O
descendents	O
both	O
from	O
t	O
o	O
and	O
h	O
its	O
gradient	B
is	O
thus	O
given	O
by	O
t	O
h	O
l	O
t	O
h	O
h	O
w	O
o	O
h	O
h	O
t	O
l	O
t	O
l	O
diag	O
h	O
t	O
h	O
v	O
o	O
l	O
o	O
l	O
where	O
diag	O
t	O
hidden	O
unit	O
at	O
time	O
i	O
i	O
h	O
t	O
indicates	O
the	O
diagonal	B
matrix	I
containing	O
the	O
elements	O
this	O
is	O
the	O
jacobian	O
of	O
the	O
hyperbolic	O
tangent	O
associated	O
with	O
the	O
t	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
once	O
the	O
gradients	O
on	O
the	O
internal	O
nodes	O
of	O
the	O
computational	B
graph	I
are	O
obtained	O
we	O
can	O
obtain	O
the	O
gradients	O
on	O
the	O
parameter	O
nodes	O
because	O
the	O
parameters	O
are	O
shared	O
across	O
many	O
time	O
steps	O
we	O
must	O
take	O
some	O
care	O
when	O
denoting	O
calculus	O
operations	O
involving	O
these	O
variables	O
the	O
equations	O
we	O
wish	O
to	O
that	O
computes	O
the	O
contribution	O
implement	O
use	O
the	O
bprop	O
method	O
of	O
section	O
w	O
f	O
of	O
a	O
single	O
edge	O
in	O
the	O
computational	B
graph	I
to	O
the	O
gradient	B
however	O
the	O
operator	O
used	O
in	O
calculus	O
takes	O
into	O
account	O
the	O
contribution	O
of	O
w	O
to	O
the	O
value	O
of	O
f	O
due	O
to	O
edges	O
in	O
the	O
computational	B
graph	I
to	O
resolve	O
this	O
ambiguity	O
we	O
introduce	O
dummy	O
variables	O
w	O
that	O
are	O
defined	O
to	O
be	O
copies	O
of	O
w	O
but	O
with	O
each	O
w	O
used	O
only	O
at	O
time	O
step	O
t	O
we	O
may	O
then	O
use	O
w	O
to	O
denote	O
the	O
contribution	O
of	O
the	O
weights	B
at	O
time	O
step	O
to	O
the	O
gradient	B
all	O
t	O
using	O
this	O
notation	O
the	O
gradient	B
on	O
the	O
remaining	O
parameters	O
is	O
given	O
by	O
t	O
t	O
i	O
i	O
diag	O
o	O
c	O
h	O
b	O
t	O
t	O
t	O
t	O
t	O
o	O
l	O
h	O
l	O
l	O
o	O
i	O
l	O
h	O
i	O
l	O
h	O
i	O
i	O
v	O
o	O
i	O
w	O
h	O
i	O
u	O
h	O
h	O
h	O
i	O
diag	O
t	O
t	O
cl	O
bl	O
v	O
l	O
wl	O
ul	O
t	O
h	O
l	O
h	O
h	O
l	O
x	O
o	O
l	O
h	O
h	O
l	O
diag	O
o	O
l	O
h	O
t	O
we	O
do	O
not	O
need	O
to	O
compute	O
the	O
gradient	B
with	O
respect	O
to	O
x	O
for	O
training	O
because	O
it	O
does	O
not	O
have	O
any	O
parameters	O
as	O
ancestors	O
in	O
the	O
computational	B
graph	I
defining	O
the	O
loss	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
recurrent	O
networks	O
as	O
directed	O
graphical	O
models	O
in	O
the	O
example	B
recurrent	B
network	I
we	O
have	O
developed	O
so	O
far	O
the	O
losses	O
l	O
were	O
cross-entropies	O
between	O
training	O
targets	O
y	O
and	O
outputs	O
o	O
as	O
with	O
a	O
feedforward	O
network	O
it	O
is	O
in	O
principle	O
possible	O
to	O
use	O
almost	O
any	O
loss	O
with	O
a	O
recurrent	B
network	I
the	O
loss	O
should	O
be	O
chosen	O
based	O
on	O
the	O
task	O
as	O
with	O
a	O
feedforward	O
network	O
we	O
usually	O
wish	O
to	O
interpret	O
the	O
output	O
of	O
the	O
rnn	O
as	O
a	O
probability	B
distribution	I
and	O
we	O
usually	O
use	O
the	O
cross-entropy	B
associated	O
with	O
that	O
distribution	O
to	O
define	O
the	O
loss	O
mean	B
squared	I
error	I
is	O
the	O
cross-entropy	B
loss	O
associated	O
with	O
an	O
output	O
distribution	O
that	O
is	O
a	O
unit	O
gaussian	O
for	O
example	B
just	O
as	O
with	O
a	O
feedforward	O
network	O
when	O
we	O
use	O
a	O
predictive	O
log-likelihood	O
training	O
objective	O
such	O
as	O
equation	O
we	O
train	O
the	O
rnn	O
to	O
estimate	O
the	O
conditional	O
distribution	O
of	O
the	O
next	O
sequence	O
element	O
y	O
given	O
the	O
past	O
inputs	O
this	O
may	O
mean	O
that	O
we	O
maximize	O
the	O
log-likelihood	O
log	O
y	O
x	O
or	O
if	O
the	O
model	O
includes	O
connections	O
from	O
the	O
output	O
at	O
one	O
time	O
step	O
to	O
the	O
next	O
time	O
step	O
t	O
x	O
y	O
log	O
y	O
in	O
the	O
past	O
to	O
the	O
current	O
y	O
decomposing	O
the	O
joint	B
probability	I
over	O
the	O
sequence	O
of	O
y	O
values	O
as	O
a	O
series	O
of	O
one-step	O
probabilistic	O
predictions	O
is	O
one	O
way	O
to	O
capture	O
the	O
full	O
joint	O
distribution	O
across	O
the	O
whole	O
sequence	O
when	O
we	O
do	O
not	O
feed	O
past	O
y	O
values	O
as	O
inputs	O
that	O
condition	O
the	O
next	O
step	O
prediction	O
the	O
directed	O
graphical	O
model	O
contains	O
no	O
edges	O
from	O
any	O
y	O
in	O
this	O
case	O
the	O
outputs	O
y	O
are	O
conditionally	O
independent	O
given	O
the	O
sequence	O
of	O
x	O
values	O
when	O
we	O
do	O
feed	O
the	O
actual	O
y	O
values	O
their	O
prediction	O
but	O
the	O
actual	O
observed	O
or	O
generated	O
values	O
back	O
into	O
the	O
network	O
the	O
directed	O
graphical	O
model	O
contains	O
edges	O
from	O
all	O
y	O
values	O
in	O
the	O
past	O
to	O
the	O
current	O
y	O
value	O
y	O
as	O
a	O
simple	O
example	B
let	O
us	O
consider	O
the	O
case	O
where	O
the	O
rnn	O
models	O
only	O
a	O
sequence	O
of	O
scalar	O
random	O
variables	O
y	O
with	O
no	O
additional	O
inputs	O
x	O
the	O
input	O
at	O
time	O
step	O
t	O
is	O
simply	O
the	O
output	O
at	O
time	O
step	O
t	O
the	O
rnn	O
then	O
defines	O
a	O
directed	O
graphical	O
model	O
over	O
the	O
y	O
variables	O
we	O
parametrize	O
the	O
joint	O
distribution	O
of	O
these	O
observations	O
using	O
the	O
chain	O
rule	O
for	O
conditional	O
probabilities	O
p	O
y	O
p	O
y	O
p	O
t	O
y	O
t	O
y	O
where	O
the	O
right-hand	O
side	O
of	O
the	O
bar	O
is	O
empty	O
for	O
t	O
of	O
course	O
hence	O
the	O
according	O
to	O
such	O
a	O
model	O
negative	O
log-likelihood	O
of	O
a	O
set	O
of	O
values	O
y	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
y	O
y	O
figure	O
fully	O
connected	O
graphical	O
model	O
for	O
a	O
sequence	O
y	O
y	O
every	O
past	O
observation	O
y	O
may	O
influence	O
the	O
conditional	O
distribution	O
of	O
some	O
y	O
t	O
i	O
given	O
the	O
previous	O
values	O
parametrizing	O
the	O
graphical	O
model	O
directly	O
according	O
to	O
this	O
graph	O
in	O
equation	O
might	O
be	O
very	O
inefficient	O
with	O
an	O
ever	O
growing	O
number	O
of	O
inputs	O
and	O
parameters	O
for	O
each	O
element	O
of	O
the	O
sequence	O
rnns	O
obtain	O
the	O
same	O
full	O
connectivity	O
but	O
efficient	O
parametrization	O
as	O
illustrated	O
in	O
figure	O
is	O
where	O
l	O
l	O
t	O
l	O
log	O
p	O
y	O
y	O
t	O
y	O
t	O
y	O
y	O
h	O
y	O
y	O
y	O
figure	O
introducing	O
the	O
state	O
variable	O
in	O
the	O
graphical	O
model	O
of	O
the	O
rnn	O
even	O
though	O
it	O
is	O
a	O
deterministic	O
function	O
of	O
its	O
inputs	O
helps	O
to	O
see	O
how	O
we	O
can	O
obtain	O
a	O
very	O
efficient	O
parametrization	O
based	O
on	O
equation	O
h	O
and	O
y	O
involves	O
the	O
same	O
structure	O
same	O
number	O
of	O
inputs	O
for	O
each	O
node	O
and	O
can	O
share	O
the	O
same	O
parameters	O
with	O
the	O
other	O
stages	O
every	O
stage	O
in	O
the	O
sequence	O
the	O
edges	O
in	O
a	O
graphical	O
model	O
indicate	O
which	O
variables	O
depend	O
directly	O
on	O
other	O
variables	O
many	O
graphical	O
models	O
aim	O
to	O
achieve	O
statistical	O
and	O
computational	O
efficiency	O
by	O
omitting	O
edges	O
that	O
do	O
not	O
correspond	O
to	O
strong	O
interactions	O
for	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
y	O
t	O
k	O
example	B
it	O
is	O
common	O
to	O
make	O
the	O
markov	O
assumption	O
that	O
the	O
graphical	O
model	O
to	O
y	O
rather	O
than	O
containing	O
should	O
only	O
contain	O
edges	O
from	O
edges	O
from	O
the	O
entire	O
past	O
history	O
however	O
in	O
some	O
cases	O
we	O
believe	O
that	O
all	O
past	O
inputs	O
should	O
have	O
an	O
influence	O
on	O
the	O
next	O
element	O
of	O
the	O
sequence	O
rnns	O
are	O
useful	O
when	O
we	O
believe	O
that	O
the	O
distribution	O
over	O
y	O
may	O
depend	O
on	O
a	O
value	O
of	O
y	O
from	O
the	O
distant	O
past	O
in	O
a	O
way	O
that	O
is	O
not	O
captured	O
by	O
the	O
effect	O
of	O
y	O
on	O
y	O
t	O
y	O
t	O
one	O
way	O
to	O
interpret	O
an	O
rnn	O
as	O
a	O
graphical	O
model	O
is	O
to	O
view	O
the	O
rnn	O
as	O
defining	O
a	O
graphical	O
model	O
whose	O
structure	O
is	O
the	O
complete	O
graph	O
able	O
to	O
represent	O
direct	O
dependencies	O
between	O
any	O
pair	O
of	O
y	O
values	O
the	O
graphical	O
model	O
over	O
the	O
y	O
values	O
with	O
the	O
complete	O
graph	O
structure	O
is	O
shown	O
in	O
figure	O
the	O
complete	O
graph	O
interpretation	O
of	O
the	O
rnn	O
is	O
based	O
on	O
ignoring	O
the	O
hidden	O
units	O
h	O
by	O
marginalizing	O
them	O
out	O
of	O
the	O
model	O
it	O
is	O
more	O
interesting	O
to	O
consider	O
the	O
graphical	O
model	O
structure	O
of	O
rnns	O
that	O
results	O
from	O
regarding	O
the	O
hidden	O
units	O
h	O
as	O
random	O
including	O
the	O
hidden	O
units	O
in	O
the	O
graphical	O
model	O
reveals	O
that	O
the	O
rnn	O
provides	O
a	O
very	O
efficient	O
parametrization	O
of	O
the	O
joint	O
distribution	O
over	O
the	O
observations	O
suppose	O
that	O
we	O
represented	O
an	O
arbitrary	O
joint	O
distribution	O
over	O
discrete	O
values	O
with	O
a	O
tabular	O
representation	O
an	O
array	O
containing	O
a	O
separate	O
entry	O
for	O
each	O
possible	O
assignment	O
of	O
values	O
with	O
the	O
value	O
of	O
that	O
entry	O
giving	O
the	O
probability	O
of	O
that	O
assignment	O
occurring	O
if	O
y	O
can	O
take	O
on	O
k	O
different	O
values	O
the	O
tabular	O
representation	O
would	O
have	O
ok	O
parameters	O
by	O
comparison	O
due	O
to	O
parameter	O
sharing	O
the	O
number	O
of	O
parameters	O
in	O
the	O
rnn	O
is	O
as	O
a	O
function	O
of	O
sequence	O
length	O
the	O
number	O
of	O
parameters	O
in	O
the	O
rnn	O
may	O
be	O
adjusted	O
to	O
control	O
model	O
capacity	O
but	O
is	O
not	O
forced	O
to	O
scale	O
with	O
sequence	O
length	O
equation	O
shows	O
that	O
the	O
rnn	O
parametrizes	O
long-term	O
relationships	O
between	O
variables	O
efficiently	O
using	O
recurrent	O
applications	O
of	O
the	O
same	O
function	O
f	O
and	O
same	O
parameters	O
at	O
each	O
time	O
step	O
figure	O
illustrates	O
the	O
graphical	O
model	O
interpretation	O
incorporating	O
the	O
h	O
nodes	O
in	O
the	O
graphical	O
model	O
decouples	O
the	O
past	O
and	O
the	O
future	O
acting	O
as	O
an	O
intermediate	O
quantity	O
between	O
them	O
a	O
variable	O
y	O
in	O
the	O
distant	O
past	O
may	O
influence	O
a	O
variable	O
y	O
via	O
its	O
effect	O
on	O
h	O
the	O
structure	O
of	O
this	O
graph	O
shows	O
that	O
the	O
model	O
can	O
be	O
efficiently	O
parametrized	O
by	O
using	O
the	O
same	O
conditional	B
probability	I
distributions	O
at	O
each	O
time	O
step	O
and	O
that	O
when	O
the	O
variables	O
are	O
all	O
observed	O
the	O
probability	O
of	O
the	O
joint	O
assignment	O
of	O
all	O
variables	O
can	O
be	O
evaluated	O
efficiently	O
even	O
with	O
the	O
efficient	O
parametrization	O
of	O
the	O
graphical	O
model	O
some	O
operations	O
remain	O
computationally	O
challenging	O
for	O
example	B
it	O
is	O
difficult	O
to	O
predict	O
missing	O
conditional	O
distribution	O
over	O
these	O
variables	O
given	O
their	O
parents	O
is	O
deterministic	O
this	O
is	O
perfectly	O
legitimate	O
though	O
it	O
is	O
somewhat	O
rare	O
to	O
design	O
a	O
graphical	O
model	O
with	O
such	O
deterministic	O
hidden	O
units	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
values	O
in	O
the	O
middle	O
of	O
the	O
sequence	O
the	O
price	O
recurrent	O
networks	O
pay	O
for	O
their	O
reduced	O
number	O
of	O
parameters	O
is	O
that	O
optimizing	O
the	O
parameters	O
may	O
be	O
difficult	O
the	O
parameter	O
sharing	O
used	O
in	O
recurrent	O
networks	O
relies	O
on	O
the	O
assumption	O
that	O
the	O
same	O
parameters	O
can	O
be	O
used	O
for	O
different	O
time	O
steps	O
equivalently	O
the	O
assumption	O
is	O
that	O
the	O
conditional	B
probability	B
distribution	I
over	O
the	O
variables	O
at	O
time	O
t	O
given	O
the	O
variables	O
at	O
time	O
t	O
is	O
stationary	O
meaning	O
that	O
the	O
relationship	O
between	O
the	O
previous	O
time	O
step	O
and	O
the	O
next	O
time	O
step	O
does	O
not	O
depend	O
on	O
t	O
in	O
principle	O
it	O
would	O
be	O
possible	O
to	O
use	O
t	O
as	O
an	O
extra	O
input	O
at	O
each	O
time	O
step	O
and	O
let	O
the	O
learner	O
discover	O
any	O
time-dependence	O
while	O
sharing	O
as	O
much	O
as	O
it	O
can	O
between	O
different	O
time	O
steps	O
this	O
would	O
already	O
be	O
much	O
better	O
than	O
using	O
a	O
different	O
conditional	B
probability	B
distribution	I
for	O
each	O
t	O
but	O
the	O
network	O
would	O
then	O
have	O
to	O
extrapolate	O
when	O
faced	O
with	O
new	O
values	O
of	O
to	O
complete	O
our	O
view	O
of	O
an	O
rnn	O
as	O
a	O
graphical	O
model	O
we	O
must	O
describe	O
how	O
to	O
draw	O
samples	O
from	O
the	O
model	O
the	O
main	O
operation	B
that	O
we	O
need	O
to	O
perform	O
is	O
simply	O
to	O
sample	O
from	O
the	O
conditional	O
distribution	O
at	O
each	O
time	O
step	O
however	O
there	O
is	O
one	O
additional	O
complication	O
the	O
rnn	O
must	O
have	O
some	O
mechanism	O
for	O
determining	O
the	O
length	O
of	O
the	O
sequence	O
this	O
can	O
be	O
achieved	O
in	O
various	O
ways	O
in	O
the	O
case	O
when	O
the	O
output	O
is	O
a	O
symbol	O
taken	O
from	O
a	O
vocabulary	O
one	O
can	O
add	O
a	O
special	O
symbol	O
corresponding	O
to	O
the	O
end	O
of	O
a	O
sequence	O
when	O
that	O
symbol	O
is	O
generated	O
the	O
sampling	O
process	O
stops	O
in	O
the	O
training	O
set	O
we	O
insert	O
this	O
symbol	O
as	O
an	O
extra	O
member	O
of	O
the	O
sequence	O
immediately	O
after	O
x	O
in	O
each	O
training	O
example	B
another	O
option	O
is	O
to	O
introduce	O
an	O
extra	O
bernoulli	O
output	O
to	O
the	O
model	O
that	O
represents	O
the	O
decision	O
to	O
either	O
continue	O
generation	O
or	O
halt	O
generation	O
at	O
each	O
time	O
step	O
this	O
approach	O
is	O
more	O
general	O
than	O
the	O
approach	O
of	O
adding	O
an	O
extra	O
symbol	O
to	O
the	O
vocabulary	O
because	O
it	O
may	O
be	O
applied	O
to	O
any	O
rnn	O
rather	O
than	O
only	O
rnns	O
that	O
output	O
a	O
sequence	O
of	O
symbols	O
for	O
example	B
it	O
may	O
be	O
applied	O
to	O
an	O
rnn	O
that	O
emits	O
a	O
sequence	O
of	O
real	O
numbers	O
the	O
new	O
output	O
unit	O
is	O
usually	O
a	O
sigmoid	O
unit	O
trained	O
with	O
the	O
cross-entropy	B
loss	O
in	O
this	O
approach	O
the	O
sigmoid	O
is	O
trained	O
to	O
maximize	O
the	O
log-probability	O
of	O
the	O
correct	O
prediction	O
as	O
to	O
whether	O
the	O
sequence	O
ends	O
or	O
continues	O
at	O
each	O
time	O
step	O
another	O
way	O
to	O
determine	O
the	O
sequence	O
length	O
is	O
to	O
add	O
an	O
extra	O
output	O
to	O
the	O
model	O
that	O
predicts	O
the	O
integer	O
itself	O
the	O
model	O
can	O
sample	O
a	O
value	O
of	O
and	O
then	O
sample	O
steps	O
worth	O
of	O
data	O
this	O
approach	O
requires	O
adding	O
an	O
extra	O
input	O
to	O
the	O
recurrent	O
update	O
at	O
each	O
time	O
step	O
so	O
that	O
the	O
recurrent	O
update	O
is	O
aware	O
of	O
whether	O
it	O
is	O
near	O
the	O
end	O
of	O
the	O
generated	O
sequence	O
this	O
extra	O
input	O
can	O
either	O
consist	O
of	O
the	O
value	O
of	O
or	O
can	O
consist	O
of	O
the	O
number	O
of	O
remaining	O
t	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
time	O
steps	O
without	O
this	O
extra	O
input	O
the	O
rnn	O
might	O
generate	O
sequences	O
that	O
end	O
abruptly	O
such	O
as	O
a	O
sentence	O
that	O
ends	O
before	O
it	O
is	O
complete	O
this	O
approach	O
is	O
based	O
on	O
the	O
decomposition	O
p	O
x	O
p	O
p	O
x	O
the	O
strategy	O
of	O
predicting	O
directly	O
is	O
used	O
for	O
example	B
by	O
goodfellow	O
et	O
al	O
modeling	O
sequences	O
conditioned	O
on	O
context	O
with	O
rnns	O
in	O
the	O
previous	O
section	O
we	O
described	O
how	O
an	O
rnn	O
could	O
correspond	O
to	O
a	O
directed	O
graphical	O
model	O
over	O
a	O
sequence	O
of	O
random	O
variables	O
y	O
with	O
no	O
inputs	O
x	O
of	O
course	O
our	O
development	O
of	O
rnns	O
as	O
in	O
equation	O
included	O
a	O
sequence	O
of	O
inputs	O
x	O
in	O
general	O
rnns	O
allow	O
the	O
extension	O
of	O
the	O
graphical	O
model	O
view	O
to	O
represent	O
not	O
only	O
a	O
joint	O
distribution	O
over	O
the	O
y	O
variables	O
but	O
also	O
a	O
conditional	O
distribution	O
over	O
y	O
given	O
x	O
as	O
discussed	O
in	O
the	O
context	O
of	O
p	O
feedforward	O
networks	O
in	O
section	O
can	O
be	O
reinterpreted	O
as	O
a	O
model	O
representing	O
a	O
conditional	O
distribution	O
p	O
with	O
we	O
can	O
extend	O
such	O
a	O
model	O
to	O
represent	O
a	O
distribution	O
p	O
y	O
x	O
by	O
using	O
the	O
same	O
py	O
as	O
before	O
but	O
making	O
a	O
function	O
of	O
x	O
in	O
the	O
case	O
of	O
an	O
rnn	O
this	O
can	O
be	O
achieved	O
in	O
different	O
ways	O
we	O
review	O
here	O
the	O
most	O
common	O
and	O
obvious	O
choices	O
any	O
model	O
representing	O
a	O
variable	O
previously	O
we	O
have	O
discussed	O
rnns	O
that	O
take	O
a	O
sequence	O
of	O
vectors	O
x	O
for	O
t	O
as	O
input	O
another	O
option	O
is	O
to	O
take	O
only	O
a	O
single	O
vector	O
x	O
as	O
input	O
when	O
x	O
is	O
a	O
fixed-size	O
vector	O
we	O
can	O
simply	O
make	O
it	O
an	O
extra	O
input	O
of	O
the	O
rnn	O
that	O
generates	O
the	O
y	O
sequence	O
some	O
common	O
ways	O
of	O
providing	O
an	O
extra	O
input	O
to	O
an	O
rnn	O
are	O
as	O
an	O
extra	O
input	O
at	O
each	O
time	O
step	O
or	O
as	O
the	O
initial	O
state	O
h	O
or	O
both	O
the	O
interaction	O
the	O
first	O
and	O
most	O
common	O
approach	O
is	O
illustrated	O
in	O
figure	O
between	O
the	O
input	O
x	O
and	O
each	O
hidden	O
unit	B
vector	I
h	O
is	O
parametrized	O
by	O
a	O
newly	O
introduced	O
weight	O
matrix	O
r	O
that	O
was	O
absent	O
from	O
the	O
model	O
of	O
only	O
the	O
sequence	O
r	O
is	O
added	O
as	O
additional	O
input	O
to	O
the	O
hidden	O
of	O
y	O
values	O
the	O
same	O
product	O
x	O
units	O
at	O
every	O
time	O
step	O
we	O
can	O
think	O
of	O
the	O
choice	O
of	O
x	O
as	O
determining	O
the	O
value	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
r	O
that	O
is	O
effectively	O
a	O
new	O
bias	B
parameter	I
used	O
for	O
each	O
of	O
the	O
hidden	O
units	O
of	O
x	O
the	O
weights	B
remain	O
independent	O
of	O
the	O
input	O
we	O
can	O
think	O
of	O
this	O
model	O
as	O
taking	O
the	O
parameters	O
of	O
the	O
non-conditional	O
model	O
and	O
turning	O
them	O
into	O
where	O
the	O
bias	O
parameters	O
within	O
are	O
now	O
a	O
function	O
of	O
the	O
input	O
y	O
y	O
lt	O
lt	O
ot	O
ot	O
y	O
t	O
y	O
ty	O
y	O
u	O
l	O
u	O
l	O
tl	O
t	O
o	O
t	O
o	O
to	O
v	O
v	O
v	O
ht	O
ht	O
w	O
w	O
h	O
w	O
h	O
th	O
t	O
h	O
u	O
w	O
s	O
r	O
r	O
r	O
r	O
r	O
xx	O
figure	O
an	O
rnn	O
that	O
maps	O
a	O
fixed-length	O
vector	O
x	O
into	O
a	O
distribution	O
over	O
sequences	O
y	O
this	O
rnn	O
is	O
appropriate	O
for	O
tasks	O
such	O
as	O
image	O
captioning	O
where	O
a	O
single	O
image	O
is	O
used	O
as	O
input	O
to	O
a	O
model	O
that	O
then	O
produces	O
a	O
sequence	O
of	O
words	O
describing	O
the	O
image	O
each	O
element	O
y	O
of	O
the	O
observed	O
output	O
sequence	O
serves	O
both	O
as	O
input	O
the	O
current	O
time	O
step	O
and	O
during	O
training	O
as	O
target	O
the	O
previous	O
time	O
step	O
rather	O
than	O
receiving	O
only	O
a	O
single	O
vector	O
x	O
as	O
input	O
the	O
rnn	O
may	O
receive	O
correx	O
x	O
that	O
makes	O
a	O
a	O
sequence	O
of	O
vectors	O
x	O
as	O
input	O
the	O
rnn	O
described	O
in	O
equation	O
sponds	O
to	O
a	O
conditional	O
distribution	O
p	O
y	O
conditional	O
independence	O
assumption	O
that	O
this	O
distribution	O
factorizes	O
as	O
p	O
t	O
x	O
to	O
remove	O
the	O
conditional	O
independence	O
assumption	O
we	O
can	O
add	O
connections	O
from	O
the	O
output	O
at	O
time	O
t	O
to	O
the	O
hidden	O
unit	O
at	O
time	O
t	O
as	O
shown	O
in	O
figure	O
the	O
model	O
can	O
then	O
represent	O
arbitrary	O
probability	O
distributions	O
over	O
the	O
y	O
sequence	O
this	O
kind	O
of	O
model	O
representing	O
a	O
distribution	O
over	O
a	O
sequence	O
given	O
another	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
yt	O
yt	O
lt	O
lt	O
ot	O
ot	O
v	O
w	O
h	O
ht	O
ht	O
u	O
xt	O
xt	O
y	O
y	O
ty	O
t	O
l	O
t	O
l	O
tl	O
r	O
r	O
r	O
w	O
o	O
v	O
h	O
u	O
x	O
t	O
o	O
to	O
v	O
w	O
w	O
t	O
h	O
th	O
h	O
u	O
x	O
tx	O
t	O
figure	O
a	O
conditional	O
recurrent	B
neural	B
network	I
mapping	O
a	O
variable-length	O
sequence	O
of	O
x	O
values	O
into	O
a	O
distribution	O
over	O
sequences	O
of	O
y	O
values	O
of	O
the	O
same	O
length	O
compared	O
to	O
figure	O
this	O
rnn	O
contains	O
connections	O
from	O
the	O
previous	O
output	O
to	O
the	O
current	O
state	O
these	O
connections	O
allow	O
this	O
rnn	O
to	O
model	O
an	O
arbitrary	O
distribution	O
over	O
sequences	O
of	O
y	O
given	O
sequences	O
of	O
x	O
of	O
the	O
same	O
length	O
the	O
rnn	O
of	O
figure	O
is	O
only	O
able	O
to	O
represent	O
distributions	O
in	O
which	O
the	O
y	O
values	O
are	O
conditionally	O
independent	O
from	O
each	O
other	O
given	O
the	O
values	O
x	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
sequence	O
still	O
has	O
one	O
restriction	O
which	O
is	O
that	O
the	O
length	O
of	O
both	O
sequences	O
must	O
be	O
the	O
same	O
we	O
describe	O
how	O
to	O
remove	O
this	O
restriction	O
in	O
section	O
yt	O
yt	O
lt	O
lt	O
ot	O
ot	O
g	O
g	O
ht	O
ht	O
xt	O
xt	O
y	O
y	O
ty	O
t	O
l	O
l	O
tl	O
t	O
o	O
t	O
o	O
to	O
g	O
g	O
tg	O
t	O
h	O
h	O
th	O
t	O
x	O
x	O
tx	O
t	O
figure	O
computation	O
of	O
a	O
typical	O
bidirectional	O
recurrent	B
neural	B
network	I
meant	O
to	O
learn	O
to	O
map	O
input	O
sequences	O
x	O
to	O
target	O
sequences	O
y	O
with	O
loss	O
l	O
at	O
each	O
step	O
t	O
the	O
h	O
recurrence	O
propagates	O
information	O
forward	O
in	O
time	O
the	O
right	O
while	O
the	O
g	O
recurrence	O
propagates	O
information	O
backward	O
in	O
time	O
the	O
left	O
thus	O
at	O
each	O
point	O
t	O
the	O
output	O
units	O
o	O
can	O
benefit	O
from	O
a	O
relevant	O
summary	O
of	O
the	O
past	O
in	O
its	O
h	O
input	O
and	O
from	O
a	O
relevant	O
summary	O
of	O
the	O
future	O
in	O
its	O
g	O
input	O
bidirectional	O
rnns	O
all	O
of	O
the	O
recurrent	O
networks	O
we	O
have	O
considered	O
up	O
to	O
now	O
have	O
a	O
causal	O
structure	O
meaning	O
that	O
the	O
state	O
at	O
time	O
t	O
only	O
captures	O
information	O
from	O
the	O
past	O
x	O
and	O
the	O
present	O
input	O
x	O
some	O
of	O
the	O
models	O
we	O
have	O
discussed	O
t	O
also	O
allow	O
information	O
from	O
past	O
y	O
values	O
to	O
affect	O
the	O
current	O
state	O
when	O
the	O
y	O
values	O
are	O
available	O
however	O
in	O
many	O
applications	O
we	O
want	O
to	O
output	O
a	O
prediction	O
of	O
y	O
which	O
may	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
depend	O
on	O
the	O
whole	O
input	O
sequence	O
for	O
example	B
in	O
speech	O
recognition	O
the	O
correct	O
interpretation	O
of	O
the	O
current	O
sound	O
as	O
a	O
phoneme	O
may	O
depend	O
on	O
the	O
next	O
few	O
phonemes	O
because	O
of	O
co-articulation	O
and	O
potentially	O
may	O
even	O
depend	O
on	O
the	O
next	O
few	O
words	O
because	O
of	O
the	O
linguistic	O
dependencies	O
between	O
nearby	O
words	O
if	O
there	O
are	O
two	O
interpretations	O
of	O
the	O
current	O
word	O
that	O
are	O
both	O
acoustically	O
plausible	O
we	O
may	O
have	O
to	O
look	O
far	O
into	O
the	O
future	O
the	O
past	O
to	O
disambiguate	O
them	O
this	O
is	O
also	O
true	O
of	O
handwriting	O
recognition	O
and	O
many	O
other	O
sequence-to-sequence	O
learning	O
tasks	O
described	O
in	O
the	O
next	O
section	O
bidirectional	O
recurrent	O
neural	O
networks	O
bidirectional	O
rnns	O
were	O
invented	O
they	O
have	O
been	O
extremely	O
suc	O
in	O
applications	O
where	O
that	O
need	O
arises	O
such	O
as	O
handwriting	O
speech	O
recogniet	O
al	O
baldi	O
to	O
address	O
that	O
need	O
and	O
paliwal	O
cessful	O
recognition	O
tion	B
and	O
schmidhuber	O
graves	O
et	O
al	O
graves	O
and	O
schmidhuber	O
and	O
bioinformatics	O
et	O
al	O
as	O
the	O
name	O
suggests	O
bidirectional	O
rnns	O
combine	O
an	O
rnn	O
that	O
moves	O
forward	O
through	O
time	O
beginning	O
from	O
the	O
start	O
of	O
the	O
sequence	O
with	O
another	O
rnn	O
that	O
moves	O
backward	O
through	O
time	O
beginning	O
from	O
the	O
end	O
of	O
the	O
sequence	O
figure	O
illustrates	O
the	O
typical	O
bidirectional	O
rnn	O
with	O
h	O
standing	O
for	O
the	O
state	O
of	O
the	O
sub-rnn	O
that	O
moves	O
forward	O
through	O
time	O
and	O
g	O
standing	O
for	O
the	O
state	O
of	O
the	O
sub-rnn	O
that	O
moves	O
backward	O
through	O
time	O
this	O
allows	O
the	O
output	O
units	O
o	O
to	O
compute	O
a	O
representation	O
that	O
depends	O
on	O
both	O
the	O
past	O
and	O
the	O
future	O
but	O
is	O
most	O
sensitive	O
to	O
the	O
input	O
values	O
around	O
time	O
t	O
without	O
having	O
to	O
specify	O
a	O
fixed-size	O
window	O
around	O
t	O
one	O
would	O
have	O
to	O
do	O
with	O
a	O
feedforward	O
network	O
a	O
convolutional	B
network	I
or	O
a	O
regular	O
rnn	O
with	O
a	O
fixed-size	O
look-ahead	O
buffer	O
four	O
this	O
idea	O
can	O
be	O
naturally	O
extended	O
to	O
input	O
such	O
as	O
images	O
by	O
having	O
rnns	O
each	O
one	O
going	O
in	O
one	O
of	O
the	O
four	O
directions	O
up	O
down	O
left	O
right	O
at	O
each	O
point	O
j	O
of	O
a	O
grid	O
an	O
output	O
oij	O
could	O
then	O
compute	O
a	O
representation	O
that	O
would	O
capture	O
mostly	O
local	O
information	O
but	O
could	O
also	O
depend	O
on	O
long-range	O
inputs	O
if	O
the	O
rnn	O
is	O
able	O
to	O
learn	O
to	O
carry	O
that	O
information	O
compared	O
to	O
a	O
convolutional	B
network	I
rnns	O
applied	O
to	O
images	O
are	O
typically	O
more	O
expensive	O
but	O
allow	O
for	O
long-range	O
lateral	O
interactions	O
between	O
features	O
in	O
the	O
same	O
feature	B
map	O
indeed	O
the	O
forward	B
propagation	I
equations	O
for	O
such	O
rnns	O
may	O
be	O
written	O
in	O
a	O
form	O
that	O
shows	O
they	O
use	O
a	O
convolution	O
that	O
computes	O
the	O
bottom-up	O
input	O
to	O
each	O
layer	O
prior	O
to	O
the	O
recurrent	O
propagation	O
across	O
the	O
feature	B
map	O
that	O
incorporates	O
the	O
lateral	O
interactions	O
visin	O
et	O
al	O
kalchbrenner	O
et	O
al	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
encoder-decoder	O
sequence-to-sequence	O
architec	O
tures	O
we	O
have	O
seen	O
in	O
figure	O
vector	O
we	O
have	O
seen	O
in	O
figure	O
sequence	O
we	O
have	O
seen	O
in	O
figures	O
map	O
an	O
input	O
sequence	O
to	O
an	O
output	O
sequence	O
of	O
the	O
same	O
length	O
how	O
an	O
rnn	O
can	O
map	O
an	O
input	O
sequence	O
to	O
a	O
fixed-size	O
how	O
an	O
rnn	O
can	O
map	O
a	O
fixed-size	O
vector	O
to	O
a	O
how	O
an	O
rnn	O
can	O
and	O
encoder	B
x	O
xn	O
x	O
xn	O
x	O
cc	O
decoder	B
y	O
y	O
y	O
y	O
y	O
y	O
y	O
figure	O
example	B
of	O
an	O
encoder-decoder	O
or	O
sequence-to-sequence	O
rnn	O
architecture	O
for	O
learning	O
to	O
generate	O
an	O
output	O
sequence	O
yn	O
y	O
given	O
an	O
input	O
sequence	O
x	O
xnx	O
it	O
is	O
composed	O
of	O
an	O
encoder	B
rnn	O
that	O
reads	O
the	O
input	O
sequence	O
and	O
a	O
decoder	B
rnn	O
that	O
generates	O
the	O
output	O
sequence	O
computes	O
the	O
probability	O
of	O
a	O
given	O
output	O
sequence	O
the	O
final	O
hidden	O
state	O
of	O
the	O
encoder	B
rnn	O
is	O
used	O
to	O
compute	O
a	O
generally	O
fixed-size	O
context	O
variable	O
c	O
which	O
represents	O
a	O
semantic	O
summary	O
of	O
the	O
input	O
sequence	O
and	O
is	O
given	O
as	O
input	O
to	O
the	O
decoder	B
rnn	O
here	O
we	O
discuss	O
how	O
an	O
rnn	O
can	O
be	O
trained	O
to	O
map	O
an	O
input	O
sequence	O
to	O
an	O
output	O
sequence	O
which	O
is	O
not	O
necessarily	O
of	O
the	O
same	O
length	O
this	O
comes	O
up	O
in	O
many	O
applications	O
such	O
as	O
speech	O
recognition	O
machine	B
translation	I
or	O
question	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
answering	O
where	O
the	O
input	O
and	O
output	O
sequences	O
in	O
the	O
training	O
set	O
are	O
generally	O
not	O
of	O
the	O
same	O
length	O
their	O
lengths	O
might	O
be	O
related	O
we	O
often	O
call	O
the	O
input	O
to	O
the	O
rnn	O
the	O
context	O
we	O
want	O
to	O
produce	O
a	O
representation	O
of	O
this	O
context	O
c	O
the	O
context	O
c	O
might	O
be	O
a	O
vector	O
or	O
sequence	O
of	O
vectors	O
that	O
summarize	O
the	O
input	O
sequence	O
x	O
x	O
xnx	O
et	O
al	O
cho	O
et	O
al	O
the	O
simplest	O
rnn	O
architecture	O
for	O
mapping	O
a	O
variable-length	O
sequence	O
to	O
and	O
another	O
variable-length	O
sequence	O
was	O
first	O
proposed	O
by	O
shortly	O
after	O
by	O
sutskever	O
who	O
independently	O
developed	O
that	O
architecture	O
and	O
were	O
the	O
first	O
to	O
obtain	O
state-of-the-art	O
translation	O
using	O
this	O
approach	O
the	O
former	O
system	O
is	O
based	O
on	O
scoring	O
proposals	O
generated	O
by	O
another	O
machine	B
translation	I
system	O
while	O
the	O
latter	O
uses	O
a	O
standalone	O
recurrent	B
network	I
to	O
generate	O
the	O
translations	O
these	O
authors	O
respectively	O
called	O
this	O
architecture	O
illustrated	O
in	O
figure	O
the	O
encoder-decoder	O
or	O
sequence-to-sequence	O
architecture	O
the	O
idea	O
is	O
very	O
simple	O
an	O
encoder	B
or	O
reader	O
or	O
input	O
rnn	O
processes	O
the	O
input	O
sequence	O
the	O
encoder	B
emits	O
the	O
context	O
c	O
usually	O
as	O
a	O
simple	O
function	O
of	O
its	O
final	O
hidden	O
state	O
a	O
decoder	B
or	O
writer	O
or	O
output	O
rnn	O
is	O
conditioned	O
on	O
that	O
fixed-length	O
vector	O
like	O
in	O
figure	O
to	O
generate	O
the	O
output	O
sequence	O
y	O
y	O
the	O
innovation	O
of	O
this	O
kind	O
of	O
architecture	O
over	O
those	O
presented	O
in	O
earlier	O
sections	O
of	O
this	O
chapter	O
is	O
that	O
the	O
lengths	O
n	O
x	O
and	O
ny	O
can	O
vary	O
from	O
each	O
other	O
while	O
previous	O
architectures	O
constrained	O
nx	O
ny	O
in	O
a	O
sequence-to-sequence	O
architecture	O
the	O
two	O
rnns	O
are	O
trained	O
jointly	O
to	O
maximize	O
the	O
average	O
of	O
log	O
p	O
y	O
xnx	O
over	O
all	O
the	O
pairs	O
of	O
x	O
and	O
y	O
sequences	O
in	O
the	O
training	O
set	O
the	O
last	O
state	O
hnx	O
of	O
the	O
encoder	B
rnn	O
is	O
typically	O
used	O
as	O
a	O
representation	O
c	O
of	O
the	O
input	O
sequence	O
that	O
is	O
provided	O
as	O
input	O
to	O
the	O
decoder	B
rnn	O
if	O
the	O
context	O
c	O
is	O
a	O
vector	O
then	O
the	O
decoder	B
rnn	O
is	O
simply	O
a	O
vector-tosequence	O
rnn	O
as	O
described	O
in	O
section	O
as	O
we	O
have	O
seen	O
there	O
are	O
at	O
least	O
two	O
ways	O
for	O
a	O
vector-to-sequence	O
rnn	O
to	O
receive	O
input	O
the	O
input	O
can	O
be	O
provided	O
as	O
the	O
initial	O
state	O
of	O
the	O
rnn	O
or	O
the	O
input	O
can	O
be	O
connected	O
to	O
the	O
hidden	O
units	O
at	O
each	O
time	O
step	O
these	O
two	O
ways	O
can	O
also	O
be	O
combined	O
there	O
is	O
no	O
constraint	O
that	O
the	O
encoder	B
must	O
have	O
the	O
same	O
size	O
of	O
hidden	B
layer	I
as	O
the	O
decoder	B
one	O
clear	O
limitation	O
of	O
this	O
architecture	O
is	O
when	O
the	O
context	O
c	O
output	O
by	O
the	O
encoder	B
rnn	O
has	O
a	O
dimension	O
that	O
is	O
too	O
small	O
to	O
properly	O
summarize	O
a	O
long	O
sequence	O
this	O
phenomenon	O
was	O
observed	O
by	O
in	O
the	O
context	O
of	O
machine	B
translation	I
they	O
proposed	O
to	O
make	O
c	O
a	O
variable-length	O
sequence	O
rather	O
than	O
a	O
fixed-size	O
vector	O
additionally	O
they	O
introduced	O
an	O
attention	O
mechanism	O
that	O
learns	O
to	O
associate	O
elements	O
of	O
the	O
sequence	O
c	O
to	O
elements	O
of	O
the	O
output	O
bahdanau	O
et	O
al	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
sequence	O
see	O
section	O
for	O
more	O
details	O
deep	O
recurrent	O
networks	O
the	O
computation	O
in	O
most	O
rnns	O
can	O
be	O
decomposed	O
into	O
three	O
blocks	O
of	O
parameters	O
and	O
associated	O
transformations	O
from	O
the	O
input	O
to	O
the	O
hidden	O
state	O
from	O
the	O
previous	O
hidden	O
state	O
to	O
the	O
next	O
hidden	O
state	O
and	O
from	O
the	O
hidden	O
state	O
to	O
the	O
output	O
with	O
the	O
rnn	O
architecture	O
of	O
figure	O
each	O
of	O
these	O
three	O
blocks	O
is	O
associated	O
with	O
a	O
single	O
weight	O
matrix	O
in	O
other	O
words	O
when	O
the	O
network	O
is	O
unfolded	O
each	O
of	O
these	O
corresponds	O
to	O
a	O
shallow	O
transformation	O
by	O
a	O
shallow	O
transformation	O
we	O
mean	O
a	O
transformation	O
that	O
would	O
be	O
represented	O
by	O
a	O
single	O
layer	O
within	O
a	O
deep	O
mlp	O
typically	O
this	O
is	O
a	O
transformation	O
represented	O
by	O
a	O
learned	O
affine	B
transformation	O
followed	O
by	O
a	O
fixed	O
nonlinearity	O
would	O
it	O
be	O
advantageous	O
to	O
introduce	O
depth	O
in	O
each	O
of	O
these	O
operations	O
experimental	O
evidence	O
strongly	O
suggests	O
so	O
the	O
experimental	O
evidence	O
is	O
in	O
agreement	O
with	O
the	O
idea	O
that	O
we	O
need	O
enough	O
depth	O
in	O
order	O
to	O
perform	O
the	O
required	O
mappings	O
see	O
also	O
schmidhuber	O
el	O
hihi	O
and	O
bengio	O
for	O
earlier	O
work	O
on	O
deep	O
rnns	O
pascanu	O
jaeger	O
et	O
al	O
et	O
al	O
or	O
et	O
al	O
graves	O
et	O
al	O
were	O
the	O
first	O
to	O
show	O
a	O
significant	O
benefit	O
of	O
decomposing	O
we	O
can	O
think	O
the	O
state	O
of	O
an	O
rnn	O
into	O
multiple	O
layers	O
as	O
in	O
figure	O
of	O
the	O
lower	O
layers	O
in	O
the	O
hierarchy	O
depicted	O
in	O
figure	O
a	O
as	O
playing	O
a	O
role	O
in	O
transforming	O
the	O
raw	O
input	O
into	O
a	O
representation	O
that	O
is	O
more	O
appropriate	O
at	O
the	O
higher	O
levels	O
of	O
the	O
hidden	O
state	O
pascanu	O
go	O
a	O
step	O
further	O
and	O
propose	O
to	O
have	O
a	O
separate	O
mlp	O
deep	O
for	O
each	O
of	O
the	O
three	O
blocks	O
enumerated	O
above	O
as	O
illustrated	O
in	O
figure	O
b	O
considerations	O
of	O
representational	B
capacity	I
suggest	O
to	O
allocate	O
enough	O
capacity	O
in	O
each	O
of	O
these	O
three	O
steps	O
but	O
doing	O
so	O
by	O
adding	O
depth	O
may	O
hurt	O
learning	O
by	O
making	O
optimization	O
difficult	O
in	O
general	O
it	O
is	O
easier	O
to	O
optimize	O
shallower	O
architectures	O
and	O
adding	O
the	O
extra	O
depth	O
of	O
t	O
to	O
a	O
variable	O
figure	O
in	O
time	O
step	O
t	O
become	O
longer	O
for	O
example	B
if	O
an	O
mlp	O
with	O
a	O
single	O
hidden	B
layer	I
is	O
used	O
for	O
the	O
state-to-state	O
transition	O
we	O
have	O
doubled	O
the	O
length	O
of	O
the	O
shortest	O
path	O
between	O
variables	O
in	O
any	O
two	O
different	O
time	O
steps	O
compared	O
with	O
the	O
this	O
ordinary	O
rnn	O
of	O
figure	O
b	O
makes	O
the	O
shortest	O
path	O
from	O
a	O
variable	O
in	O
time	O
step	O
however	O
as	O
argued	O
by	O
pascanu	O
et	O
al	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
y	O
h	O
x	O
y	O
h	O
x	O
y	O
z	O
h	O
x	O
figure	O
a	O
recurrent	B
neural	B
network	I
can	O
be	O
made	O
deep	O
in	O
many	O
ways	O
et	O
al	O
the	O
hidden	O
recurrent	O
state	O
can	O
be	O
broken	O
down	O
into	O
groups	O
organized	O
hierarchically	O
deeper	O
computation	O
an	O
mlp	O
can	O
be	O
introduced	O
in	O
the	O
input-tohidden	O
hidden-to-hidden	O
and	O
hidden-to-output	O
parts	O
this	O
may	O
lengthen	O
the	O
shortest	O
path	O
linking	O
different	O
time	O
steps	O
the	O
path-lengthening	O
effect	O
can	O
be	O
mitigated	O
by	O
introducing	O
skip	O
connections	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
can	O
be	O
mitigated	O
by	O
introducing	O
skip	O
connections	O
in	O
the	O
hidden-to-hidden	O
path	O
as	O
illustrated	O
in	O
figure	O
c	O
recursive	O
neural	O
networks	O
ll	O
oo	O
yy	O
u	O
w	O
u	O
w	O
u	O
w	O
v	O
v	O
v	O
v	O
figure	O
a	O
recursive	O
network	O
has	O
a	O
computational	B
graph	I
that	O
generalizes	O
that	O
of	O
the	O
recurrent	B
network	I
from	O
a	O
chain	O
to	O
a	O
tree	O
a	O
variable-size	O
sequence	O
x	O
x	O
can	O
be	O
mapped	O
to	O
a	O
fixed-size	O
representation	O
output	O
o	O
with	O
a	O
fixed	O
set	O
of	O
parameters	O
weight	O
matrices	O
u	O
v	O
w	O
the	O
figure	O
illustrates	O
a	O
supervised	B
learning	I
case	O
in	O
which	O
some	O
target	O
is	O
provided	O
which	O
is	O
associated	O
with	O
the	O
whole	O
sequence	O
y	O
recursive	O
neural	O
represent	O
yet	O
another	O
generalization	B
of	O
recurrent	O
networks	O
with	O
a	O
different	O
kind	O
of	O
computational	B
graph	I
which	O
is	O
structured	O
as	O
a	O
deep	O
tree	O
rather	O
than	O
the	O
chain-like	O
structure	O
of	O
rnns	O
the	O
typical	O
computational	O
recursive	O
neural	O
graph	O
for	O
a	O
recursive	O
network	O
is	O
illustrated	O
in	O
figure	O
suggest	O
to	O
not	O
abbreviate	O
recursive	O
neural	B
network	I
as	O
rnn	O
to	O
avoid	O
confusion	O
with	O
recurrent	B
neural	B
network	I
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
networks	O
were	O
introduced	O
by	O
pollack	O
reason	O
was	O
described	O
by	O
applied	O
to	O
processing	O
data	O
structures	O
as	O
input	O
to	O
neural	O
nets	O
computer	B
vision	I
and	O
their	O
potential	O
use	O
for	O
learning	O
to	O
recursive	O
networks	O
have	O
been	O
successfully	O
bottou	O
as	O
well	O
as	O
in	O
in	O
natural	B
language	I
processing	I
socher	O
et	O
al	O
c	O
socher	O
et	O
al	O
et	O
al	O
one	O
clear	O
advantage	O
of	O
recursive	O
nets	O
over	O
recurrent	O
nets	O
is	O
that	O
for	O
a	O
sequence	O
of	O
the	O
same	O
length	O
the	O
depth	O
as	O
the	O
number	O
of	O
compositions	O
of	O
nonlinear	O
operations	O
can	O
be	O
drastically	O
reduced	O
from	O
to	O
olog	O
which	O
might	O
help	O
deal	O
with	O
long-term	O
dependencies	O
an	O
open	O
question	O
is	O
how	O
to	O
best	O
structure	O
the	O
tree	O
one	O
option	O
is	O
to	O
have	O
a	O
tree	O
structure	O
which	O
does	O
not	O
depend	O
on	O
the	O
data	O
such	O
as	O
a	O
balanced	O
binary	O
tree	O
in	O
some	O
application	O
domains	O
external	O
methods	O
can	O
suggest	O
the	O
appropriate	O
tree	O
structure	O
for	O
example	B
when	O
processing	O
natural	O
language	O
sentences	O
the	O
tree	O
structure	O
for	O
the	O
recursive	O
network	O
can	O
be	O
fixed	O
to	O
the	O
structure	O
of	O
the	O
parse	O
tree	O
of	O
the	O
sentence	O
provided	O
by	O
a	O
natural	O
language	O
parser	O
ideally	O
one	O
would	O
like	O
the	O
learner	O
itself	O
to	O
discover	O
and	O
infer	O
the	O
tree	O
structure	O
that	O
is	O
appropriate	O
for	O
any	O
given	O
input	O
as	O
suggested	O
by	O
socher	O
et	O
al	O
bottou	O
and	O
et	O
al	O
frasconi	O
many	O
variants	O
of	O
the	O
recursive	O
net	O
idea	O
are	O
possible	O
for	O
example	B
frasconi	O
associate	O
the	O
data	O
with	O
a	O
tree	O
structure	O
et	O
al	O
and	O
associate	O
the	O
inputs	O
and	O
targets	O
with	O
individual	O
nodes	O
of	O
the	O
tree	O
the	O
computation	O
performed	O
by	O
each	O
node	O
does	O
not	O
have	O
to	O
be	O
the	O
traditional	O
artificial	O
neuron	O
computation	O
transformation	O
of	O
all	O
inputs	O
followed	O
by	O
a	O
monotone	O
nonlinearity	O
for	O
example	B
propose	O
using	O
tensor	O
operations	O
and	O
bilinear	O
forms	O
which	O
have	O
previously	O
been	O
found	O
useful	O
to	O
model	O
relationships	O
between	O
concepts	O
when	O
the	O
concepts	O
are	O
represented	O
by	O
continuous	O
vectors	O
socher	O
et	O
al	O
bordes	O
et	O
al	O
et	O
al	O
the	O
challenge	B
of	O
long-term	O
dependencies	O
the	O
mathematical	O
challenge	B
of	O
learning	O
long-term	O
dependencies	O
in	O
recurrent	O
networks	O
was	O
introduced	O
in	O
section	O
the	O
basic	O
problem	O
is	O
that	O
gradients	O
propagated	O
over	O
many	O
stages	O
tend	O
to	O
either	O
vanish	O
of	O
the	O
time	O
or	O
explode	O
but	O
with	O
much	O
damage	O
to	O
the	O
optimization	O
even	O
if	O
we	O
assume	O
that	O
the	O
parameters	O
are	O
such	O
that	O
the	O
recurrent	B
network	I
is	O
stable	O
store	O
memories	O
with	O
gradients	O
not	O
exploding	O
the	O
difficulty	O
with	O
long-term	O
dependencies	O
arises	O
from	O
the	O
exponentially	O
smaller	O
weights	B
given	O
to	O
long-term	O
interactions	O
the	O
multiplication	O
of	O
many	O
jacobians	O
compared	O
to	O
short-term	O
ones	O
many	O
other	O
et	O
al	O
sources	O
provide	O
a	O
deeper	O
treatment	O
hochreiter	O
doya	O
bengio	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
t	O
u	O
p	O
t	O
u	O
o	O
f	O
o	O
n	O
o	O
i	O
t	O
c	O
e	O
j	O
o	O
r	O
p	O
input	O
coordinate	O
figure	O
when	O
composing	O
many	O
nonlinear	O
functions	O
the	O
linear-tanh	O
layer	O
shown	O
here	O
the	O
result	O
is	O
highly	O
nonlinear	O
typically	O
with	O
most	O
of	O
the	O
values	O
associated	O
with	O
a	O
tiny	O
derivative	B
some	O
values	O
with	O
a	O
large	O
derivative	B
and	O
many	O
alternations	O
between	O
increasing	O
and	O
decreasing	O
in	O
this	O
plot	O
we	O
plot	O
a	O
linear	O
projection	O
of	O
a	O
hidden	O
state	O
down	O
to	O
a	O
single	O
dimension	O
plotted	O
on	O
the	O
y-axis	O
the	O
x-axis	O
is	O
the	O
coordinate	O
of	O
the	O
initial	O
state	O
along	O
a	O
random	O
direction	O
in	O
the	O
space	O
we	O
can	O
thus	O
view	O
this	O
plot	O
as	O
a	O
linear	O
cross-section	O
of	O
a	O
high-dimensional	O
function	O
the	O
plots	O
show	O
the	O
function	O
after	O
each	O
time	O
step	O
or	O
equivalently	O
after	O
each	O
number	O
of	O
times	O
the	O
transition	O
function	O
has	O
been	O
composed	O
pascanu	O
detail	O
the	O
remaining	O
sections	O
describe	O
approaches	O
to	O
overcoming	O
the	O
problem	O
in	O
this	O
section	O
we	O
describe	O
the	O
problem	O
in	O
more	O
et	O
al	O
recurrent	O
networks	O
involve	O
the	O
composition	O
of	O
the	O
same	O
function	O
multiple	O
times	O
once	O
per	O
time	O
step	O
these	O
compositions	O
can	O
result	O
in	O
extremely	O
nonlinear	O
behavior	O
as	O
illustrated	O
in	O
figure	O
in	O
particular	O
the	O
function	O
composition	O
employed	O
by	O
recurrent	O
neural	O
networks	O
somewhat	O
resembles	O
matrix	O
multiplication	O
we	O
can	O
think	O
of	O
the	O
recurrence	O
relation	O
as	O
a	O
very	O
simple	O
recurrent	B
neural	B
network	I
lacking	O
a	O
nonlinear	O
activation	B
function	I
and	O
lacking	O
inputs	O
x	O
as	O
described	O
in	O
section	O
this	O
recurrence	O
relation	O
essentially	O
describes	O
the	O
power	O
method	O
it	O
may	O
be	O
simplified	O
to	O
h	O
w	O
t	O
h	O
h	O
w	O
t	O
and	O
if	O
w	O
admits	O
an	O
eigendecomposition	B
of	O
the	O
form	O
w	O
q	O
q	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
with	O
orthogonal	O
q	O
the	O
recurrence	O
may	O
be	O
simplified	O
further	O
to	O
h	O
q	O
the	O
eigenvalues	O
are	O
raised	O
to	O
the	O
power	O
of	O
t	O
causing	O
eigenvalues	O
with	O
magnitude	O
less	O
than	O
one	O
to	O
decay	O
to	O
zero	O
and	O
eigenvalues	O
with	O
magnitude	O
greater	O
than	O
one	O
to	O
explode	O
any	O
component	O
of	O
that	O
is	O
not	O
aligned	O
with	O
the	O
largest	O
eigenvector	B
will	O
eventually	O
be	O
discarded	O
this	O
problem	O
is	O
particular	O
to	O
recurrent	O
networks	O
in	O
the	O
scalar	O
case	O
imagine	O
multiplying	O
a	O
weight	O
w	O
by	O
itself	O
many	O
times	O
the	O
product	O
wt	O
will	O
either	O
vanish	O
or	O
explode	O
depending	O
on	O
the	O
magnitude	O
of	O
w	O
however	O
if	O
we	O
make	O
a	O
non-recurrent	O
network	O
that	O
has	O
a	O
different	O
weight	O
w	O
at	O
each	O
time	O
step	O
the	O
situation	O
is	O
different	O
t	O
w	O
suppose	O
if	O
the	O
initial	O
state	O
is	O
given	O
by	O
then	O
the	O
state	O
at	O
time	O
that	O
the	O
w	O
values	O
are	O
generated	O
randomly	O
independently	O
from	O
one	O
another	O
with	O
zero	O
mean	O
and	O
variance	O
v	O
the	O
variance	O
of	O
the	O
product	O
is	O
ov	O
n	O
to	O
obtain	O
some	O
desired	O
variance	O
v	O
very	O
deep	O
feedforward	O
networks	O
with	O
carefully	O
chosen	O
scaling	O
can	O
thus	O
avoid	O
the	O
vanishing	O
and	O
exploding	O
gradient	B
problem	O
as	O
argued	O
by	O
we	O
may	O
choose	O
the	O
individual	O
weights	B
with	O
variance	O
v	O
n	O
sussillo	O
t	O
is	O
given	O
by	O
v	O
the	O
vanishing	O
and	O
exploding	O
gradient	B
problem	O
for	O
rnns	O
was	O
independently	O
discovered	O
by	O
separate	O
researchers	O
hochreiter	O
bengio	O
et	O
al	O
one	O
may	O
hope	O
that	O
the	O
problem	O
can	O
be	O
avoided	O
simply	O
by	O
staying	O
in	O
a	O
region	O
of	O
parameter	O
space	O
where	O
the	O
gradients	O
do	O
not	O
vanish	O
or	O
explode	O
unfortunately	O
in	O
order	O
to	O
store	O
memories	O
in	O
a	O
way	O
that	O
is	O
robust	O
to	O
small	O
perturbations	O
the	O
rnn	O
must	O
enter	O
a	O
region	O
of	O
parameter	O
space	O
where	O
gradients	O
vanish	O
bengio	O
et	O
al	O
specifically	O
whenever	O
the	O
model	O
is	O
able	O
to	O
represent	O
long	O
term	O
dependencies	O
the	O
gradient	B
of	O
a	O
long	O
term	O
interaction	O
has	O
exponentially	O
smaller	O
magnitude	O
than	O
the	O
gradient	B
of	O
a	O
short	O
term	O
interaction	O
it	O
does	O
not	O
mean	O
that	O
it	O
is	O
impossible	O
to	O
learn	O
but	O
that	O
it	O
might	O
take	O
a	O
very	O
long	O
time	O
to	O
learn	O
long-term	O
dependencies	O
because	O
the	O
signal	O
about	O
these	O
dependencies	O
will	O
tend	O
to	O
be	O
hidden	O
by	O
the	O
smallest	O
fluctuations	O
arising	O
from	O
short-term	O
dependencies	O
in	O
practice	O
the	O
experiments	O
in	O
show	O
that	O
as	O
we	O
increase	O
the	O
span	O
of	O
the	O
dependencies	O
that	O
need	O
to	O
be	O
captured	O
gradient-based	O
optimization	O
becomes	O
increasingly	O
difficult	O
with	O
the	O
probability	O
of	O
successful	O
training	O
of	O
a	O
traditional	O
rnn	O
via	O
sgd	O
rapidly	O
reaching	O
for	O
sequences	O
of	O
only	O
length	O
or	O
bengio	O
et	O
al	O
for	O
a	O
deeper	O
treatment	O
of	O
recurrent	O
networks	O
as	O
dynamical	O
systems	O
see	O
doya	O
with	O
a	O
review	O
bengio	O
et	O
al	O
in	O
pascanu	O
the	O
remaining	O
sections	O
of	O
this	O
chapter	O
discuss	O
various	O
approaches	O
that	O
have	O
been	O
proposed	O
to	O
reduce	O
the	O
difficulty	O
of	O
learning	O
longterm	O
dependencies	O
some	O
cases	O
allowing	O
an	O
rnn	O
to	O
learn	O
dependencies	O
across	O
siegelmann	O
and	O
sontag	O
et	O
al	O
and	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
hundreds	O
of	O
steps	O
but	O
the	O
problem	O
of	O
learning	O
long-term	O
dependencies	O
remains	O
one	O
of	O
the	O
main	O
challenges	O
in	O
deep	O
learning	O
echo	O
state	O
networks	O
the	O
recurrent	O
weights	B
mapping	O
from	O
h	O
t	O
to	O
h	O
and	O
the	O
input	O
weights	B
mapping	O
from	O
x	O
to	O
h	O
are	O
some	O
of	O
the	O
most	O
difficult	O
parameters	O
to	O
learn	O
in	O
a	O
recurrent	B
network	I
one	O
proposed	O
jaeger	O
maass	O
et	O
al	O
jaeger	O
and	O
haas	O
jaeger	O
approach	O
to	O
avoiding	O
this	O
difficulty	O
is	O
to	O
set	O
the	O
recurrent	O
weights	B
such	O
that	O
the	O
recurrent	O
hidden	O
units	O
do	O
a	O
good	O
job	O
of	O
capturing	O
the	O
history	O
of	O
past	O
inputs	O
and	O
learn	O
only	O
the	O
output	O
weights	B
this	O
is	O
the	O
idea	O
that	O
was	O
independently	O
proposed	O
for	O
echo	O
state	O
networks	O
or	O
esns	O
jaeger	O
and	O
haas	O
jaeger	O
and	O
liquid	O
state	O
machines	O
the	O
latter	O
is	O
similar	O
except	O
that	O
it	O
uses	O
spiking	O
neurons	O
binary	O
outputs	O
instead	O
of	O
the	O
continuous-valued	O
hidden	O
units	O
used	O
for	O
esns	O
both	O
esns	O
and	O
liquid	O
state	O
machines	O
are	O
termed	O
reservoir	O
computing	O
evi	O
ius	O
and	O
jaeger	O
to	O
denote	O
the	O
fact	O
that	O
the	O
hidden	O
units	O
form	O
of	O
reservoir	O
of	O
temporal	O
features	O
which	O
may	O
capture	O
different	O
aspects	O
of	O
the	O
history	O
of	O
inputs	O
maass	O
et	O
al	O
one	O
way	O
to	O
think	O
about	O
these	O
reservoir	O
computing	O
recurrent	O
networks	O
is	O
that	O
they	O
are	O
similar	O
to	O
kernel	O
machines	O
they	O
map	O
an	O
arbitrary	O
length	O
sequence	O
history	O
of	O
inputs	O
up	O
to	O
time	O
t	O
into	O
a	O
fixed-length	O
vector	O
recurrent	O
state	O
h	O
on	O
which	O
a	O
linear	O
predictor	O
a	O
linear	O
regression	B
can	O
be	O
applied	O
to	O
solve	O
the	O
problem	O
of	O
interest	O
the	O
training	O
criterion	O
may	O
then	O
be	O
easily	O
designed	O
to	O
be	O
convex	O
as	O
a	O
function	O
of	O
the	O
output	O
weights	B
for	O
example	B
if	O
the	O
output	O
consists	O
of	O
linear	O
regression	B
from	O
the	O
hidden	O
units	O
to	O
the	O
output	O
targets	O
and	O
the	O
training	O
criterion	O
is	O
mean	B
squared	I
error	I
then	O
it	O
is	O
convex	O
and	O
may	O
be	O
solved	O
reliably	O
with	O
simple	O
learning	O
algorithms	O
jaeger	O
the	O
important	O
question	O
is	O
therefore	O
how	O
do	O
we	O
set	O
the	O
input	O
and	O
recurrent	O
weights	B
so	O
that	O
a	O
rich	O
set	O
of	O
histories	O
can	O
be	O
represented	O
in	O
the	O
recurrent	B
neural	B
network	I
state	O
the	O
answer	O
proposed	O
in	O
the	O
reservoir	O
computing	O
literature	O
is	O
to	O
view	O
the	O
recurrent	O
net	O
as	O
a	O
dynamical	O
system	O
and	O
set	O
the	O
input	O
and	O
recurrent	O
weights	B
such	O
that	O
the	O
dynamical	O
system	O
is	O
near	O
the	O
edge	O
of	O
stability	O
the	O
original	O
idea	O
was	O
to	O
make	O
the	O
eigenvalues	O
of	O
the	O
jacobian	O
of	O
the	O
state-to	O
an	O
important	O
state	O
transition	O
function	O
be	O
close	O
to	O
as	O
explained	O
in	O
section	O
characteristic	O
of	O
a	O
recurrent	B
network	I
is	O
the	O
eigenvalue	B
spectrum	O
of	O
the	O
jacobians	O
j	O
s	O
of	O
particular	O
importance	O
is	O
the	O
spectral	B
radius	I
of	O
j	O
defined	O
to	O
t	O
s	O
be	O
the	O
maximum	O
of	O
the	O
absolute	O
values	O
of	O
its	O
eigenvalues	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
to	O
understand	O
the	O
effect	O
of	O
the	O
spectral	B
radius	I
consider	O
the	O
simple	O
case	O
of	O
back-propagation	B
with	O
a	O
jacobian	O
matrix	O
j	O
that	O
does	O
not	O
change	O
with	O
t	O
this	O
case	O
happens	O
for	O
example	B
when	O
the	O
network	O
is	O
purely	O
linear	O
suppose	O
that	O
j	O
has	O
an	O
eigenvector	B
v	O
with	O
corresponding	O
eigenvalue	B
consider	O
what	O
happens	O
as	O
we	O
propagate	O
a	O
gradient	B
vector	O
backwards	O
through	O
time	O
if	O
we	O
begin	O
with	O
a	O
gradient	B
vector	O
g	O
then	O
after	O
one	O
step	O
of	O
back-propagation	B
we	O
will	O
have	O
j	O
g	O
and	O
after	O
n	O
steps	O
we	O
will	O
have	O
j	O
n	O
g	O
now	O
consider	O
what	O
happens	O
if	O
we	O
instead	O
back-propagate	O
a	O
perturbed	O
version	O
of	O
g	O
if	O
we	O
begin	O
with	O
g	O
v	O
then	O
after	O
one	O
step	O
we	O
will	O
have	O
jg	O
v	O
after	O
n	O
steps	O
we	O
will	O
have	O
j	O
ng	O
v	O
from	O
this	O
we	O
can	O
see	O
that	O
back-propagation	B
starting	O
from	O
g	O
and	O
back-propagation	B
starting	O
from	O
g	O
v	O
diverge	O
by	O
j	O
n	O
v	O
after	O
n	O
steps	O
of	O
back-propagation	B
if	O
v	O
is	O
chosen	O
to	O
be	O
a	O
unit	O
eigenvector	B
of	O
j	O
with	O
eigenvalue	B
then	O
multiplication	O
by	O
the	O
jacobian	O
simply	O
scales	O
the	O
difference	O
at	O
each	O
step	O
the	O
two	O
executions	O
of	O
back-propagation	B
are	O
n	O
when	O
v	O
corresponds	O
to	O
the	O
largest	O
value	O
of	O
separated	O
by	O
a	O
distance	O
of	O
this	O
perturbation	O
achieves	O
the	O
widest	O
possible	O
separation	O
of	O
an	O
initial	O
perturbation	O
of	O
size	O
n	O
grows	O
exponentially	O
large	O
when	O
the	O
deviation	O
size	O
when	O
the	O
deviation	O
size	O
becomes	O
exponentially	O
small	O
of	O
course	O
this	O
example	B
assumed	O
that	O
the	O
jacobian	O
was	O
the	O
same	O
at	O
every	O
time	O
step	O
corresponding	O
to	O
a	O
recurrent	B
network	I
with	O
no	O
nonlinearity	O
when	O
a	O
nonlinearity	O
is	O
present	O
the	O
derivative	B
of	O
the	O
nonlinearity	O
will	O
approach	O
zero	O
on	O
many	O
time	O
steps	O
and	O
help	O
to	O
prevent	O
the	O
explosion	O
resulting	O
from	O
a	O
large	O
spectral	B
radius	I
indeed	O
the	O
most	O
recent	O
work	O
on	O
echo	O
state	O
networks	O
advocates	O
using	O
a	O
spectral	B
radius	I
much	O
larger	O
than	O
unity	O
yildiz	O
et	O
al	O
jaeger	O
everything	O
we	O
have	O
said	O
about	O
back-propagation	B
via	O
repeated	O
matrix	O
multiplication	O
applies	O
equally	O
to	O
forward	B
propagation	I
in	O
a	O
network	O
with	O
no	O
nonlinearity	O
where	O
the	O
state	O
h	O
w	O
t	O
h	O
when	O
a	O
linear	O
map	O
w	O
always	O
shrinks	O
h	O
as	O
measured	O
by	O
the	O
norm	O
then	O
we	O
say	O
that	O
the	O
map	O
is	O
contractive	O
when	O
the	O
spectral	B
radius	I
is	O
less	O
than	O
one	O
the	O
mapping	O
from	O
h	O
to	O
h	O
is	O
contractive	O
so	O
a	O
small	O
change	O
becomes	O
smaller	O
after	O
each	O
time	O
step	O
this	O
necessarily	O
makes	O
the	O
network	O
forget	O
information	O
about	O
the	O
past	O
when	O
we	O
use	O
a	O
finite	O
level	O
of	O
precision	B
as	O
bit	O
integers	O
to	O
store	O
the	O
state	O
vector	O
t	O
the	O
jacobian	O
matrix	O
tells	O
us	O
how	O
a	O
small	O
change	O
of	O
h	O
propagates	O
one	O
step	O
forward	O
or	O
equivalently	O
how	O
the	O
gradient	B
on	O
h	O
propagates	O
one	O
step	O
backward	O
during	O
back-propagation	B
note	O
that	O
neither	O
w	O
nor	O
j	O
need	O
to	O
be	O
symmetric	O
they	O
are	O
square	O
and	O
real	O
so	O
they	O
can	O
have	O
complex-valued	O
eigenvalues	O
and	O
eigenvectors	O
with	O
imaginary	O
components	O
corresponding	O
to	O
potentially	O
oscillatory	O
t	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
behavior	O
the	O
same	O
jacobian	O
was	O
applied	O
iteratively	O
even	O
though	O
h	O
or	O
a	O
small	O
variation	O
of	O
h	O
of	O
interest	O
in	O
back-propagation	B
are	O
real-valued	O
they	O
can	O
be	O
expressed	O
in	O
such	O
a	O
complex-valued	O
basis	O
what	O
matters	O
is	O
what	O
happens	O
to	O
the	O
magnitude	O
absolute	O
value	O
of	O
these	O
possibly	O
complex-valued	O
basis	O
coefficients	O
when	O
we	O
multiply	O
the	O
matrix	O
by	O
the	O
vector	O
an	O
eigenvalue	B
with	O
magnitude	O
greater	O
than	O
one	O
corresponds	O
to	O
magnification	O
growth	O
if	O
applied	O
iteratively	O
or	O
shrinking	O
decay	O
if	O
applied	O
iteratively	O
with	O
a	O
nonlinear	O
map	O
the	O
jacobian	O
is	O
free	O
to	O
change	O
at	O
each	O
step	O
the	O
dynamics	O
therefore	O
become	O
more	O
complicated	O
however	O
it	O
remains	O
true	O
that	O
a	O
small	O
initial	O
variation	O
can	O
turn	O
into	O
a	O
large	O
variation	O
after	O
several	O
steps	O
one	O
difference	O
between	O
the	O
purely	O
linear	O
case	O
and	O
the	O
nonlinear	O
case	O
is	O
that	O
the	O
use	O
of	O
a	O
squashing	O
nonlinearity	O
such	O
as	O
tanh	O
can	O
cause	O
the	O
recurrent	O
dynamics	O
to	O
become	O
bounded	O
note	O
that	O
it	O
is	O
possible	O
for	O
back-propagation	B
to	O
retain	O
unbounded	O
dynamics	O
even	O
when	O
forward	B
propagation	I
has	O
bounded	O
dynamics	O
for	O
example	B
when	O
a	O
sequence	O
of	O
tanh	O
units	O
are	O
all	O
in	O
the	O
middle	O
of	O
their	O
linear	O
regime	O
and	O
are	O
connected	O
by	O
weight	O
matrices	O
with	O
spectral	B
radius	I
greater	O
than	O
however	O
it	O
is	O
rare	O
for	O
all	O
of	O
the	O
units	O
to	O
simultaneously	O
lie	O
at	O
their	O
linear	O
activation	O
point	O
tanh	O
the	O
strategy	O
of	O
echo	O
state	O
networks	O
is	O
simply	O
to	O
fix	O
the	O
weights	B
to	O
have	O
some	O
where	O
information	O
is	O
carried	O
forward	O
through	O
time	O
but	O
spectral	B
radius	I
such	O
as	O
does	O
not	O
explode	O
due	O
to	O
the	O
stabilizing	O
effect	O
of	O
saturating	O
nonlinearities	O
like	O
tanh	O
more	O
recently	O
it	O
has	O
been	O
shown	O
that	O
the	O
techniques	O
used	O
to	O
set	O
the	O
weights	B
the	O
weights	B
in	O
a	O
fully	O
trainable	O
recurrent	O
netin	O
esns	O
could	O
be	O
used	O
to	O
work	O
the	O
hidden-to-hidden	O
recurrent	O
weights	B
trained	O
using	O
back-propagation	B
through	I
time	I
helping	O
to	O
learn	O
long-term	O
dependencies	O
sutskever	O
et	O
al	O
in	O
this	O
setting	O
an	O
initial	O
spectral	B
radius	I
of	O
performs	O
well	O
combined	O
with	O
the	O
sparse	O
initialization	B
scheme	O
described	O
in	O
section	O
initialize	O
leaky	B
units	I
and	O
other	O
strategies	O
for	O
multiple	O
time	O
scales	O
one	O
way	O
to	O
deal	O
with	O
long-term	O
dependencies	O
is	O
to	O
design	O
a	O
model	O
that	O
operates	O
at	O
multiple	O
time	O
scales	O
so	O
that	O
some	O
parts	O
of	O
the	O
model	O
operate	O
at	O
fine-grained	O
time	O
scales	O
and	O
can	O
handle	O
small	O
details	O
while	O
other	O
parts	O
operate	O
at	O
coarse	O
time	O
scales	O
and	O
transfer	O
information	O
from	O
the	O
distant	O
past	O
to	O
the	O
present	O
more	O
efficiently	O
various	O
strategies	O
for	O
building	O
both	O
fine	O
and	O
coarse	O
time	O
scales	O
are	O
possible	O
these	O
include	O
the	O
addition	O
of	O
skip	O
connections	O
across	O
time	O
leaky	B
units	I
that	O
integrate	O
signals	O
with	O
different	O
time	O
constants	O
and	O
the	O
removal	O
of	O
some	O
of	O
the	O
connections	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
used	O
to	O
model	O
fine-grained	O
time	O
scales	O
adding	O
skip	O
connections	O
through	O
time	O
one	O
way	O
to	O
obtain	O
coarse	O
time	O
scales	O
is	O
to	O
add	O
direct	O
connections	O
from	O
variables	O
in	O
the	O
distant	O
past	O
to	O
variables	O
in	O
the	O
present	O
the	O
idea	O
of	O
using	O
such	O
skip	O
connections	O
dates	O
back	O
to	O
and	O
follows	O
from	O
the	O
idea	O
of	O
incorporating	O
delays	O
in	O
feedforward	O
neural	O
networks	O
in	O
an	O
ordinary	O
recurrent	B
network	I
a	O
recurrent	O
connection	O
goes	O
from	O
a	O
unit	O
at	O
time	O
t	O
to	O
a	O
unit	O
at	O
time	O
t	O
it	O
is	O
possible	O
to	O
construct	O
recurrent	O
networks	O
with	O
longer	O
delays	O
lang	O
and	O
hinton	O
lin	O
et	O
al	O
bengio	O
as	O
we	O
have	O
seen	O
in	O
section	O
gradients	O
may	O
vanish	O
or	O
explode	O
exponentially	O
with	O
respect	O
to	O
the	O
number	O
of	O
time	O
steps	O
introduced	O
recurrent	O
connections	O
with	O
a	O
time-delay	O
of	O
d	O
to	O
mitigate	O
this	O
problem	O
gradients	O
now	O
diminish	O
exponentially	O
as	O
a	O
function	O
of	O
rather	O
than	O
since	O
there	O
are	O
both	O
d	O
delayed	O
and	O
single	O
step	O
connections	O
gradients	O
may	O
still	O
explode	O
exponentially	O
in	O
this	O
allows	O
the	O
learning	O
algorithm	O
to	O
capture	O
longer	O
dependencies	O
although	O
not	O
all	O
long-term	O
dependencies	O
may	O
be	O
represented	O
well	O
in	O
this	O
way	O
lin	O
et	O
al	O
leaky	B
units	I
and	O
a	O
spectrum	O
of	O
different	O
time	O
scales	O
another	O
way	O
to	O
obtain	O
paths	O
on	O
which	O
the	O
product	O
of	O
derivatives	O
is	O
close	O
to	O
one	O
is	O
to	O
have	O
units	O
with	O
linear	O
self-connections	O
and	O
a	O
weight	O
near	O
one	O
on	O
these	O
connections	O
when	O
we	O
accumulate	O
a	O
running	O
average	O
of	O
some	O
value	O
v	O
by	O
applying	O
the	O
t	O
the	O
parameter	O
is	O
an	O
example	B
of	O
a	O
linear	O
selfupdate	O
connection	O
from	O
t	O
to	O
when	O
is	O
near	O
one	O
the	O
running	O
average	O
remembers	O
information	O
about	O
the	O
past	O
for	O
a	O
long	O
time	O
and	O
when	O
is	O
near	O
zero	O
information	O
about	O
the	O
past	O
is	O
rapidly	O
discarded	O
hidden	O
units	O
with	O
linear	O
self-connections	O
can	O
behave	O
similarly	O
to	O
such	O
running	O
averages	O
such	O
hidden	O
units	O
are	O
called	O
leaky	B
units	I
skip	O
connections	O
through	O
d	O
time	O
steps	O
are	O
a	O
way	O
of	O
ensuring	O
that	O
a	O
unit	O
can	O
always	O
learn	O
to	O
be	O
influenced	O
by	O
a	O
value	O
from	O
d	O
time	O
steps	O
earlier	O
the	O
use	O
of	O
a	O
linear	O
self-connection	O
with	O
a	O
weight	O
near	O
one	O
is	O
a	O
different	O
way	O
of	O
ensuring	O
that	O
the	O
unit	O
can	O
access	O
values	O
from	O
the	O
past	O
the	O
linear	O
self-connection	O
approach	O
allows	O
this	O
effect	O
to	O
be	O
adapted	O
more	O
smoothly	O
and	O
flexibly	O
by	O
adjusting	O
the	O
real-valued	O
rather	O
than	O
by	O
adjusting	O
the	O
integer-valued	O
skip	O
length	O
these	O
ideas	O
were	O
proposed	O
by	O
el	O
hihi	O
and	O
bengio	O
leaky	B
units	I
were	O
also	O
found	O
to	O
be	O
useful	O
in	O
the	O
context	O
of	O
echo	O
state	O
networks	O
jaeger	O
et	O
al	O
mozer	O
and	O
by	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
there	O
are	O
two	O
basic	O
strategies	O
for	O
setting	O
the	O
time	O
constants	O
used	O
by	O
leaky	B
units	I
one	O
strategy	O
is	O
to	O
manually	O
fix	O
them	O
to	O
values	O
that	O
remain	O
constant	O
for	O
example	B
by	O
sampling	O
their	O
values	O
from	O
some	O
distribution	O
once	O
at	O
initialization	B
time	O
another	O
strategy	O
is	O
to	O
make	O
the	O
time	O
constants	O
free	O
parameters	O
and	O
learn	O
them	O
having	O
such	O
leaky	B
units	I
at	O
different	O
time	O
scales	O
appears	O
to	O
help	O
with	O
long-term	O
dependencies	O
mozer	O
pascanu	O
et	O
al	O
removing	O
connections	O
another	O
approach	O
to	O
handle	O
long-term	O
dependencies	O
is	O
the	O
idea	O
of	O
organizing	O
the	O
state	O
of	O
the	O
rnn	O
at	O
multiple	O
time-scales	O
with	O
information	O
flowing	O
more	O
easily	O
through	O
long	O
distances	O
at	O
the	O
slower	O
time	O
scales	O
el	O
hihi	O
and	O
bengio	O
this	O
idea	O
differs	O
from	O
the	O
skip	O
connections	O
through	O
time	O
discussed	O
earlier	O
because	O
it	O
involves	O
actively	O
removing	O
length-one	O
connections	O
and	O
replacing	O
them	O
with	O
longer	O
connections	O
units	O
modified	O
in	O
such	O
a	O
way	O
are	O
forced	O
to	O
operate	O
on	O
a	O
long	O
time	O
scale	O
skip	O
connections	O
through	O
time	O
edges	O
units	O
receiving	O
such	O
new	O
connections	O
may	O
learn	O
to	O
operate	O
on	O
a	O
long	O
time	O
scale	O
but	O
may	O
also	O
choose	O
to	O
focus	O
on	O
their	O
other	O
short-term	O
connections	O
add	O
there	O
are	O
different	O
ways	O
in	O
which	O
a	O
group	O
of	O
recurrent	O
units	O
can	O
be	O
forced	O
to	O
operate	O
at	O
different	O
time	O
scales	O
one	O
option	O
is	O
to	O
make	O
the	O
recurrent	O
units	O
leaky	O
but	O
to	O
have	O
different	O
groups	O
of	O
units	O
associated	O
with	O
different	O
fixed	O
time	O
scales	O
this	O
was	O
the	O
proposal	O
in	O
pascanu	O
et	O
al	O
another	O
option	O
is	O
to	O
have	O
explicit	O
and	O
discrete	O
updates	O
taking	O
place	O
at	O
different	O
times	O
with	O
a	O
different	O
frequency	O
for	O
different	O
groups	O
of	O
units	O
this	O
is	O
the	O
approach	O
of	O
el	O
hihi	O
and	O
bengio	O
it	O
worked	O
well	O
on	O
a	O
number	O
of	O
benchmark	O
datasets	O
and	O
has	O
been	O
successfully	O
used	O
in	O
mozer	O
koutnik	O
et	O
al	O
and	O
the	O
long	O
short-term	O
memory	O
and	O
other	O
gated	O
rnns	O
as	O
of	O
this	O
writing	O
the	O
most	O
effective	O
sequence	O
models	O
used	O
in	O
practical	O
applications	O
are	O
called	O
gated	O
rnns	O
these	O
include	O
the	O
long	O
short-term	O
memory	O
and	O
networks	O
based	O
on	O
the	O
gated	B
recurrent	I
unit	I
like	O
leaky	B
units	I
gated	O
rnns	O
are	O
based	O
on	O
the	O
idea	O
of	O
creating	O
paths	O
through	O
time	O
that	O
have	O
derivatives	O
that	O
neither	O
vanish	O
nor	O
explode	O
leaky	B
units	I
did	O
this	O
with	O
connection	O
weights	B
that	O
were	O
either	O
manually	O
chosen	O
constants	O
or	O
were	O
parameters	O
gated	O
rnns	O
generalize	O
this	O
to	O
connection	O
weights	B
that	O
may	O
change	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
at	O
each	O
time	O
step	O
output	O
self-loop	O
state	O
input	O
input	O
gate	O
forget	B
gate	I
output	O
gate	O
figure	O
block	O
diagram	O
of	O
the	O
lstm	O
recurrent	B
network	I
cell	O
cells	O
are	O
connected	O
recurrently	O
to	O
each	O
other	O
replacing	O
the	O
usual	O
hidden	O
units	O
of	O
ordinary	O
recurrent	O
networks	O
an	O
input	O
feature	B
is	O
computed	O
with	O
a	O
regular	O
artificial	O
neuron	O
unit	O
its	O
value	O
can	O
be	O
accumulated	O
into	O
the	O
state	O
if	O
the	O
sigmoidal	O
input	O
gate	O
allows	O
it	O
the	O
state	O
unit	O
has	O
a	O
linear	O
self-loop	O
whose	O
weight	O
is	O
controlled	O
by	O
the	O
forget	B
gate	I
the	O
output	O
of	O
the	O
cell	O
can	O
be	O
shut	O
off	O
by	O
the	O
output	O
gate	O
all	O
the	O
gating	O
units	O
have	O
a	O
sigmoid	O
nonlinearity	O
while	O
the	O
input	O
unit	O
can	O
have	O
any	O
squashing	O
nonlinearity	O
the	O
state	O
unit	O
can	O
also	O
be	O
used	O
as	O
an	O
extra	O
input	O
to	O
the	O
gating	O
units	O
the	O
black	O
square	O
indicates	O
a	O
delay	O
of	O
a	O
single	O
time	O
step	O
leaky	B
units	I
allow	O
the	O
network	O
to	O
accumulate	O
information	O
as	O
evidence	O
for	O
a	O
particular	O
feature	B
or	O
category	O
over	O
a	O
long	O
duration	O
however	O
once	O
that	O
information	O
has	O
been	O
used	O
it	O
might	O
be	O
useful	O
for	O
the	O
neural	B
network	I
to	O
forget	O
the	O
old	O
state	O
for	O
example	B
if	O
a	O
sequence	O
is	O
made	O
of	O
sub-sequences	O
and	O
we	O
want	O
a	O
leaky	O
unit	O
to	O
accumulate	O
evidence	O
inside	O
each	O
sub-subsequence	O
we	O
need	O
a	O
mechanism	O
to	O
forget	O
the	O
old	O
state	O
by	O
setting	O
it	O
to	O
zero	O
instead	O
of	O
manually	O
deciding	O
when	O
to	O
clear	O
the	O
state	O
we	O
want	O
the	O
neural	B
network	I
to	O
learn	O
to	O
decide	O
when	O
to	O
do	O
it	O
this	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
is	O
what	O
gated	O
rnns	O
do	O
lstm	O
gers	O
et	O
al	O
the	O
clever	O
idea	O
of	O
introducing	O
self-loops	O
to	O
produce	O
paths	O
where	O
the	O
gradient	B
can	O
flow	O
for	O
long	O
durations	O
is	O
a	O
core	O
contribution	O
of	O
the	O
initial	O
long	O
short-term	O
memory	O
model	O
and	O
schmidhuber	O
a	O
crucial	O
addition	O
has	O
been	O
to	O
make	O
the	O
weight	O
on	O
this	O
self-loop	O
conditioned	O
on	O
the	O
context	O
rather	O
than	O
fixed	O
by	O
making	O
the	O
weight	O
of	O
this	O
self-loop	O
gated	O
by	O
another	O
hidden	O
unit	O
the	O
time	O
scale	O
of	O
integration	O
can	O
be	O
changed	O
dynamically	O
in	O
this	O
case	O
we	O
mean	O
that	O
even	O
for	O
an	O
lstm	O
with	O
fixed	O
parameters	O
the	O
time	O
scale	O
of	O
integration	O
can	O
change	O
based	O
on	O
the	O
input	O
sequence	O
because	O
the	O
time	O
constants	O
are	O
output	O
by	O
the	O
model	O
itself	O
the	O
lstm	O
has	O
been	O
found	O
extremely	O
successful	O
in	O
many	O
applications	O
such	O
as	O
unconstrained	O
handwriting	O
recognition	O
et	O
al	O
graves	O
and	O
jaitly	O
handwriting	O
generation	O
image	O
captioning	O
and	O
parsing	O
machine	B
translation	I
kiros	O
et	O
al	O
vinyals	O
speech	O
recognition	O
et	O
al	O
xu	O
graves	O
et	O
al	O
et	O
al	O
et	O
al	O
et	O
al	O
et	O
al	O
pascanu	O
the	O
lstm	O
block	O
diagram	O
is	O
illustrated	O
in	O
figure	O
the	O
corresponding	O
forward	B
propagation	I
equations	O
are	O
given	O
below	O
in	O
the	O
case	O
of	O
a	O
shallow	O
recurrent	B
network	I
architecture	O
deeper	O
architectures	O
have	O
also	O
been	O
successfully	O
used	O
et	O
al	O
instead	O
of	O
a	O
unit	O
that	O
simply	O
applies	O
an	O
elementwise	O
nonlinearity	O
to	O
the	O
affine	B
transformation	O
of	O
inputs	O
and	O
recurrent	O
units	O
lstm	O
recurrent	O
networks	O
have	O
lstm	O
cells	O
that	O
have	O
an	O
internal	O
recurrence	O
self-loop	O
in	O
addition	O
to	O
the	O
outer	O
recurrence	O
of	O
the	O
rnn	O
each	O
cell	O
has	O
the	O
same	O
inputs	O
and	O
outputs	O
as	O
an	O
ordinary	O
recurrent	B
network	I
but	O
has	O
more	O
parameters	O
and	O
a	O
system	O
of	O
gating	O
units	O
that	O
controls	O
the	O
flow	O
of	O
information	O
the	O
most	O
important	O
component	O
is	O
the	O
state	O
unit	O
s	O
that	O
has	O
a	O
linear	O
self-loop	O
similar	O
to	O
the	O
leaky	B
units	I
described	O
in	O
the	O
previous	O
section	O
however	O
here	O
the	O
self-loop	O
weight	O
the	O
associated	O
time	O
constant	O
is	O
controlled	O
by	O
a	O
forget	B
gate	I
unit	O
f	O
time	O
step	O
t	O
and	O
cell	O
that	O
sets	O
this	O
weight	O
to	O
a	O
value	O
between	O
and	O
via	O
a	O
sigmoid	O
unit	O
i	O
i	O
i	O
f	O
i	O
bf	O
i	O
ij	O
x	O
u	O
f	O
j	O
j	O
j	O
t	O
j	O
wf	O
ij	O
h	O
is	O
the	O
current	O
input	O
vector	O
and	O
h	O
where	O
x	O
is	O
the	O
current	O
hidden	B
layer	I
vector	O
containing	O
the	O
outputs	O
of	O
all	O
the	O
lstm	O
cells	O
and	O
bf	O
w	O
f	O
are	O
respectively	O
biases	O
input	O
weights	B
and	O
recurrent	O
weights	B
for	O
the	O
forget	O
gates	O
the	O
lstm	O
cell	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
internal	O
state	O
is	O
thus	O
updated	O
as	O
follows	O
but	O
with	O
a	O
conditional	O
self-loop	O
weight	O
f	O
i	O
t	O
i	O
f	O
s	O
i	O
s	O
i	O
g	O
i	O
b	O
i	O
uijx	O
j	O
j	O
j	O
t	O
wijh	O
j	O
where	O
b	O
u	O
and	O
w	O
respectively	O
denote	O
the	O
biases	O
input	O
weights	B
and	O
recurrent	O
weights	B
into	O
the	O
lstm	O
cell	O
the	O
external	O
input	O
gate	O
unit	O
g	O
is	O
computed	O
similarly	O
to	O
the	O
forget	B
gate	I
a	O
sigmoid	O
unit	O
to	O
obtain	O
a	O
gating	O
value	O
between	O
and	O
but	O
with	O
its	O
own	O
parameters	O
i	O
g	O
i	O
bg	O
i	O
ijx	O
u	O
g	O
j	O
t	O
j	O
w	O
g	O
ijh	O
j	O
the	O
output	O
h	O
which	O
also	O
uses	O
a	O
sigmoid	O
unit	O
for	O
gating	O
i	O
of	O
the	O
lstm	O
cell	O
can	O
also	O
be	O
shut	O
off	O
via	O
the	O
output	O
gate	O
q	O
j	O
h	O
i	O
tanh	O
s	O
i	O
q	O
i	O
q	O
i	O
bo	O
i	O
ijx	O
u	O
o	O
j	O
j	O
j	O
t	O
j	O
w	O
o	O
ij	O
h	O
i	O
which	O
has	O
parameters	O
bo	O
u	O
o	O
w	O
o	O
for	O
its	O
biases	O
input	O
weights	B
and	O
recurrent	O
weights	B
respectively	O
among	O
the	O
variants	O
one	O
can	O
choose	O
to	O
use	O
the	O
cell	O
state	O
s	O
as	O
an	O
extra	O
input	O
its	O
weight	O
into	O
the	O
three	O
gates	O
of	O
the	O
i-th	O
unit	O
as	O
shown	O
in	O
figure	O
this	O
would	O
require	O
three	O
additional	O
parameters	O
i	O
lstm	O
networks	O
have	O
been	O
shown	O
to	O
learn	O
long-term	O
dependencies	O
more	O
easily	O
than	O
the	O
simple	O
recurrent	O
architectures	O
first	O
on	O
artificial	O
data	O
sets	O
designed	O
for	O
testing	O
the	O
ability	O
to	O
learn	O
long-term	O
dependencies	O
bengio	O
et	O
al	O
hochreiter	O
then	O
on	O
challenging	O
sequence	O
and	O
schmidhuber	O
hochreiter	O
processing	O
tasks	O
where	O
state-of-the-art	O
performance	O
was	O
obtained	O
graves	O
variants	O
and	O
alternatives	O
to	O
the	O
lstm	O
have	O
been	O
studied	O
and	O
used	O
and	O
are	O
discussed	O
next	O
sutskever	O
et	O
al	O
et	O
al	O
et	O
al	O
other	O
gated	O
rnns	O
which	O
pieces	O
of	O
the	O
lstm	O
architecture	O
are	O
actually	O
necessary	O
what	O
other	O
successful	O
architectures	O
could	O
be	O
designed	O
that	O
allow	O
the	O
network	O
to	O
dynamically	O
control	O
the	O
time	O
scale	O
and	O
forgetting	O
behavior	O
of	O
different	O
units	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
et	O
al	O
some	O
answers	O
to	O
these	O
questions	O
are	O
given	O
with	O
the	O
recent	O
work	O
on	O
gated	O
rnns	O
cho	O
et	O
al	O
whose	O
units	O
are	O
also	O
known	O
as	O
gated	O
recurrent	O
units	O
or	O
grus	O
chung	O
the	O
main	O
et	O
al	O
difference	O
with	O
the	O
lstm	O
is	O
that	O
a	O
single	O
gating	O
unit	O
simultaneously	O
controls	O
the	O
forgetting	O
factor	O
and	O
the	O
decision	O
to	O
update	O
the	O
state	O
unit	O
the	O
update	O
equations	O
are	O
the	O
following	O
jozefowicz	O
chrupala	O
et	O
al	O
t	O
h	O
i	O
u	O
i	O
t	O
h	O
i	O
t	O
u	O
i	O
t	O
uijx	O
j	O
t	O
wijr	O
j	O
t	O
h	O
j	O
where	O
u	O
stands	O
for	O
update	O
gate	O
and	O
r	O
for	O
reset	O
gate	O
their	O
value	O
is	O
defined	O
as	O
usual	O
bu	O
i	O
ijx	O
uu	O
j	O
w	O
u	O
ij	O
h	O
j	O
u	O
i	O
and	O
j	O
bi	O
j	O
j	O
j	O
r	O
i	O
b	O
r	O
i	O
ij	O
x	O
u	O
r	O
j	O
j	O
j	O
w	O
r	O
ijh	O
j	O
the	O
reset	O
and	O
updates	O
gates	O
can	O
individually	O
ignore	O
parts	O
of	O
the	O
state	O
vector	O
the	O
update	O
gates	O
act	O
like	O
conditional	O
leaky	O
integrators	O
that	O
can	O
linearly	O
gate	O
any	O
dimension	O
thus	O
choosing	O
to	O
copy	O
it	O
one	O
extreme	O
of	O
the	O
sigmoid	O
or	O
completely	O
ignore	O
it	O
the	O
other	O
extreme	O
by	O
replacing	O
it	O
by	O
the	O
new	O
target	O
state	O
value	O
which	O
the	O
leaky	O
integrator	O
wants	O
to	O
converge	O
the	O
reset	O
gates	O
control	O
which	O
parts	O
of	O
the	O
state	O
get	O
used	O
to	O
compute	O
the	O
next	O
target	O
state	O
introducing	O
an	O
additional	O
nonlinear	O
effect	O
in	O
the	O
relationship	O
between	O
past	O
state	O
and	O
future	O
state	O
many	O
more	O
variants	O
around	O
this	O
theme	O
can	O
be	O
designed	O
for	O
example	B
the	O
reset	O
gate	O
forget	B
gate	I
output	O
could	O
be	O
shared	O
across	O
multiple	O
hidden	O
units	O
alternately	O
the	O
product	O
of	O
a	O
global	O
gate	O
a	O
whole	O
group	O
of	O
units	O
such	O
as	O
an	O
entire	O
layer	O
and	O
a	O
local	O
gate	O
unit	O
could	O
be	O
used	O
to	O
combine	O
global	O
control	O
and	O
local	O
control	O
however	O
several	O
investigations	O
over	O
architectural	O
variations	O
of	O
the	O
lstm	O
and	O
gru	O
found	O
no	O
variant	O
that	O
would	O
clearly	O
beat	O
both	O
of	O
these	O
greff	O
across	O
a	O
wide	O
range	O
of	O
tasks	O
found	O
that	O
a	O
crucial	O
ingredient	O
is	O
the	O
forget	B
gate	I
while	O
et	O
al	O
jozefowicz	O
et	O
al	O
found	O
that	O
adding	O
a	O
bias	O
of	O
to	O
the	O
lstm	O
forget	B
gate	I
a	O
practice	O
advocated	O
by	O
gers	O
et	O
al	O
makes	O
the	O
lstm	O
as	O
strong	O
as	O
the	O
best	O
of	O
the	O
explored	O
architectural	O
variants	O
greff	O
et	O
al	O
jozefowicz	O
et	O
al	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
optimization	O
for	O
long-term	O
dependencies	O
section	O
problems	O
that	O
occur	O
when	O
optimizing	O
rnns	O
over	O
many	O
time	O
steps	O
have	O
described	O
the	O
vanishing	O
and	O
exploding	O
gradient	B
and	O
section	O
an	O
interesting	O
idea	O
proposed	O
by	O
martens	O
and	O
sutskever	O
is	O
that	O
second	O
derivatives	O
may	O
vanish	O
at	O
the	O
same	O
time	O
that	O
first	O
derivatives	O
vanish	O
second-order	O
optimization	O
algorithms	O
may	O
roughly	O
be	O
understood	O
as	O
dividing	O
the	O
first	O
derivative	B
by	O
the	O
second	B
derivative	B
higher	O
dimension	O
multiplying	O
the	O
gradient	B
by	O
the	O
inverse	O
hessian	B
if	O
the	O
second	B
derivative	B
shrinks	O
at	O
a	O
similar	O
rate	O
to	O
the	O
first	O
derivative	B
then	O
the	O
ratio	O
of	O
first	O
and	O
second	O
derivatives	O
may	O
remain	O
relatively	O
constant	O
unfortunately	O
second-order	O
methods	O
have	O
many	O
drawbacks	O
including	O
high	O
computational	O
cost	O
the	O
need	O
for	O
a	O
large	O
minibatch	B
and	O
a	O
tendency	O
to	O
be	O
attracted	O
to	O
saddle	B
points	I
martens	O
and	O
sutskever	O
found	O
promising	O
results	O
using	O
second-order	O
methods	O
later	O
sutskever	O
found	O
that	O
simpler	O
et	O
al	O
methods	O
such	O
as	O
nesterov	B
momentum	I
with	O
careful	O
initialization	B
could	O
achieve	O
similar	O
results	O
see	O
sutskever	O
for	O
more	O
detail	O
both	O
of	O
these	O
approaches	O
have	O
largely	O
been	O
replaced	O
by	O
simply	O
using	O
sgd	O
without	O
momentum	O
applied	O
to	O
lstms	O
this	O
is	O
part	O
of	O
a	O
continuing	O
theme	O
in	O
machine	B
learning	I
that	O
it	O
is	O
often	O
much	O
easier	O
to	O
design	O
a	O
model	O
that	O
is	O
easy	O
to	O
optimize	O
than	O
it	O
is	O
to	O
design	O
a	O
more	O
powerful	O
optimization	O
algorithm	O
clipping	O
gradients	O
as	O
discussed	O
in	O
section	O
strongly	O
nonlinear	O
functions	O
such	O
as	O
those	O
computed	O
by	O
a	O
recurrent	O
net	O
over	O
many	O
time	O
steps	O
tend	O
to	O
have	O
derivatives	O
that	O
can	O
be	O
either	O
very	O
large	O
or	O
very	O
small	O
in	O
magnitude	O
this	O
is	O
illustrated	O
in	O
figure	O
and	O
figure	O
in	O
which	O
we	O
see	O
that	O
the	O
objective	B
function	I
a	O
function	O
of	O
the	O
parameters	O
has	O
a	O
landscape	O
in	O
which	O
one	O
finds	O
cliffs	O
wide	O
and	O
rather	O
flat	O
regions	O
separated	O
by	O
tiny	O
regions	O
where	O
the	O
objective	B
function	I
changes	O
quickly	O
forming	O
a	O
kind	O
of	O
cliff	O
the	O
difficulty	O
that	O
arises	O
is	O
that	O
when	O
the	O
parameter	O
gradient	B
is	O
very	O
large	O
a	O
gradient	B
descent	O
parameter	O
update	O
could	O
throw	O
the	O
parameters	O
very	O
far	O
into	O
a	O
region	O
where	O
the	O
objective	B
function	I
is	O
larger	O
undoing	O
much	O
of	O
the	O
work	O
that	O
had	O
been	O
done	O
to	O
reach	O
the	O
current	O
solution	O
the	O
gradient	B
tells	O
us	O
the	O
direction	O
that	O
corresponds	O
to	O
the	O
steepest	O
descent	O
within	O
an	O
infinitesimal	O
region	O
surrounding	O
the	O
current	O
parameters	O
outside	O
of	O
this	O
infinitesimal	O
region	O
the	O
cost	O
function	O
may	O
begin	O
to	O
curve	O
back	O
upwards	O
the	O
update	O
must	O
be	O
chosen	O
to	O
be	O
small	O
enough	O
to	O
avoid	O
traversing	O
too	O
much	O
upward	O
curvature	O
we	O
typically	O
use	O
learning	O
rates	O
that	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
decay	O
slowly	O
enough	O
that	O
consecutive	O
steps	O
have	O
approximately	O
the	O
same	O
learning	B
rate	I
a	O
step	O
size	O
that	O
is	O
appropriate	O
for	O
a	O
relatively	O
linear	O
part	O
of	O
the	O
landscape	O
is	O
often	O
inappropriate	O
and	O
causes	O
uphill	O
motion	O
if	O
we	O
enter	O
a	O
more	O
curved	O
part	O
of	O
the	O
landscape	O
on	O
the	O
next	O
step	O
figure	O
example	B
of	O
the	O
effect	O
of	O
gradient	B
clipping	O
in	O
a	O
recurrent	B
network	I
with	O
two	O
parameters	O
w	O
and	O
b	O
gradient	B
clipping	O
can	O
make	O
gradient	B
descent	O
perform	O
more	O
reasonably	O
in	O
the	O
vicinity	O
of	O
extremely	O
steep	O
cliffs	O
these	O
steep	O
cliffs	O
commonly	O
occur	O
in	O
recurrent	O
networks	O
near	O
where	O
a	O
recurrent	B
network	I
behaves	O
approximately	O
linearly	O
the	O
cliff	O
is	O
exponentially	O
steep	O
in	O
the	O
number	O
of	O
time	O
steps	O
because	O
the	O
weight	O
matrix	O
is	O
multiplied	O
by	O
itself	O
once	O
for	O
each	O
time	O
step	O
descent	O
without	O
gradient	B
clipping	O
overshoots	O
the	O
bottom	O
of	O
this	O
small	O
ravine	O
then	O
receives	O
a	O
very	O
large	O
gradient	B
from	O
the	O
cliff	O
face	O
the	O
large	O
gradient	B
catastrophically	O
propels	O
the	O
parameters	O
outside	O
the	O
axes	O
of	O
the	O
plot	O
gradient	B
descent	O
with	O
gradient	B
clipping	O
has	O
a	O
more	O
moderate	O
reaction	O
to	O
the	O
cliff	O
while	O
it	O
does	O
ascend	O
the	O
cliff	O
face	O
the	O
step	O
size	O
is	O
restricted	O
so	O
that	O
it	O
cannot	O
be	O
propelled	O
away	O
from	O
steep	O
region	O
near	O
the	O
solution	O
figure	O
adapted	O
with	O
permission	O
from	O
pascanu	O
et	O
al	O
a	O
simple	O
type	O
of	O
solution	O
has	O
been	O
in	O
use	O
by	O
practitioners	O
for	O
many	O
years	O
clipping	O
the	O
gradient	B
there	O
are	O
different	O
instances	O
of	O
this	O
idea	O
pascanu	O
one	O
option	O
is	O
to	O
clip	O
the	O
parameter	O
gradient	B
from	O
a	O
minibatch	B
just	O
before	O
the	O
parameter	O
update	O
another	O
is	O
to	O
clip	O
element-wise	O
the	O
norm	O
just	O
before	O
the	O
parameter	O
update	O
et	O
al	O
g	O
of	O
the	O
gradient	B
g	O
et	O
al	O
gv	O
g	O
g	O
g	O
v	O
if	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
where	O
v	O
is	O
the	O
norm	O
threshold	O
and	O
g	O
is	O
used	O
to	O
update	O
parameters	O
because	O
the	O
gradient	B
of	O
all	O
the	O
parameters	O
different	O
groups	O
of	O
parameters	O
such	O
as	O
weights	B
and	O
biases	O
is	O
renormalized	O
jointly	O
with	O
a	O
single	O
scaling	O
factor	O
the	O
latter	O
method	O
has	O
the	O
advantage	O
that	O
it	O
guarantees	O
that	O
each	O
step	O
is	O
still	O
in	O
the	O
gradient	B
direction	O
but	O
experiments	O
suggest	O
that	O
both	O
forms	O
work	O
similarly	O
although	O
the	O
parameter	O
update	O
has	O
the	O
same	O
direction	O
as	O
the	O
true	O
gradient	B
with	O
gradient	B
norm	O
clipping	O
the	O
parameter	O
update	O
vector	O
norm	O
is	O
now	O
bounded	O
this	O
bounded	O
gradient	B
avoids	O
performing	O
a	O
detrimental	O
step	O
when	O
the	O
gradient	B
explodes	O
in	O
fact	O
even	O
simply	O
taking	O
a	O
random	O
step	O
when	O
the	O
gradient	B
magnitude	O
is	O
above	O
a	O
threshold	O
tends	O
to	O
work	O
almost	O
as	O
well	O
if	O
the	O
explosion	O
is	O
so	O
severe	O
that	O
the	O
gradient	B
is	O
numerically	O
inf	O
or	O
nan	O
infinite	O
or	O
not-a-number	O
then	O
a	O
random	O
step	O
of	O
size	O
v	O
can	O
be	O
taken	O
and	O
will	O
typically	O
move	O
away	O
from	O
the	O
numerically	O
unstable	O
configuration	O
clipping	O
the	O
gradient	B
norm	O
per-minibatch	O
will	O
not	O
change	O
the	O
direction	O
of	O
the	O
gradient	B
for	O
an	O
individual	O
minibatch	B
however	O
taking	O
the	O
average	O
of	O
the	O
norm-clipped	O
gradient	B
from	O
many	O
minibatches	O
is	O
not	O
equivalent	O
to	O
clipping	O
the	O
norm	O
of	O
the	O
true	O
gradient	B
gradient	B
formed	O
from	O
using	O
all	O
examples	O
examples	O
that	O
have	O
large	O
gradient	B
norm	O
as	O
well	O
as	O
examples	O
that	O
appear	O
in	O
the	O
same	O
minibatch	B
as	O
such	O
examples	O
will	O
have	O
their	O
contribution	O
to	O
the	O
final	O
direction	O
diminished	O
this	O
stands	O
in	O
contrast	B
to	O
traditional	O
minibatch	B
gradient	B
descent	O
where	O
the	O
true	O
gradient	B
direction	O
is	O
equal	O
to	O
the	O
average	O
over	O
all	O
minibatch	B
gradients	O
put	O
another	O
way	O
traditional	O
stochastic	O
gradient	B
descent	O
uses	O
an	O
unbiased	B
estimate	O
of	O
the	O
gradient	B
while	O
gradient	B
descent	O
with	O
norm	O
clipping	O
introduces	O
a	O
heuristic	O
bias	O
that	O
we	O
know	O
empirically	O
to	O
be	O
useful	O
with	O
elementwise	O
clipping	O
the	O
direction	O
of	O
the	O
update	O
is	O
not	O
aligned	O
with	O
the	O
true	O
gradient	B
or	O
the	O
minibatch	B
gradient	B
but	O
it	O
is	O
still	O
a	O
descent	O
direction	O
it	O
has	O
also	O
been	O
proposed	O
to	O
clip	O
the	O
back-propagated	O
gradient	B
respect	O
to	O
hidden	O
units	O
but	O
no	O
comparison	O
has	O
been	O
published	O
between	O
these	O
variants	O
we	O
conjecture	O
that	O
all	O
these	O
methods	O
behave	O
similarly	O
regularizing	O
to	O
encourage	O
information	O
flow	O
gradient	B
clipping	O
helps	O
to	O
deal	O
with	O
exploding	O
gradients	O
but	O
it	O
does	O
not	O
help	O
with	O
vanishing	O
gradients	O
to	O
address	O
vanishing	O
gradients	O
and	O
better	O
capture	O
long-term	O
dependencies	O
we	O
discussed	O
the	O
idea	O
of	O
creating	O
paths	O
in	O
the	O
computational	B
graph	I
of	O
the	O
unfolded	O
recurrent	O
architecture	O
along	O
which	O
the	O
product	O
of	O
gradients	O
associated	O
with	O
arcs	O
is	O
near	O
one	O
approach	O
to	O
achieve	O
this	O
is	O
with	O
lstms	O
and	O
other	O
selfloops	O
and	O
gating	O
mechanisms	O
described	O
above	O
in	O
section	O
another	O
idea	O
is	O
to	O
regularize	O
or	O
constrain	O
the	O
parameters	O
so	O
as	O
to	O
encourage	O
information	O
flow	O
h	O
l	O
being	O
back-propagated	O
to	O
in	O
particular	O
we	O
would	O
like	O
the	O
gradient	B
vector	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
maintain	O
its	O
magnitude	O
even	O
if	O
the	O
loss	O
function	O
only	O
penalizes	O
the	O
output	O
at	O
the	O
end	O
of	O
the	O
sequence	O
formally	O
we	O
want	O
to	O
be	O
as	O
large	O
as	O
h	O
h	O
t	O
h	O
l	O
h	O
l	O
et	O
al	O
with	O
this	O
objective	O
pascanu	O
propose	O
the	O
following	O
regularizer	B
h	O
l	O
h	O
h	O
t	O
h	O
l	O
t	O
computing	O
the	O
gradient	B
of	O
this	O
regularizer	B
may	O
appear	O
difficult	O
but	O
pascanu	O
propose	O
an	O
approximation	O
in	O
which	O
we	O
consider	O
the	O
back-propagated	O
et	O
al	O
h	O
l	O
as	O
if	O
they	O
were	O
constants	O
the	O
purpose	O
of	O
this	O
regularizer	B
so	O
vectors	O
that	O
there	O
is	O
no	O
need	O
to	O
back-propagate	O
through	O
them	O
the	O
experiments	O
with	O
this	O
regularizer	B
suggest	O
that	O
if	O
combined	O
with	O
the	O
norm	O
clipping	O
heuristic	O
handles	O
gradient	B
explosion	O
the	O
regularizer	B
can	O
considerably	O
increase	O
the	O
span	O
of	O
the	O
dependencies	O
that	O
an	O
rnn	O
can	O
learn	O
because	O
it	O
keeps	O
the	O
rnn	O
dynamics	O
on	O
the	O
edge	O
of	O
explosive	O
gradients	O
the	O
gradient	B
clipping	O
is	O
particularly	O
important	O
without	O
gradient	B
clipping	O
gradient	B
explosion	O
prevents	O
learning	O
from	O
succeeding	O
a	O
key	O
weakness	O
of	O
this	O
approach	O
is	O
that	O
it	O
is	O
not	O
as	O
effective	O
as	O
the	O
lstm	O
for	O
tasks	O
where	O
data	O
is	O
abundant	O
such	O
as	O
language	O
modeling	O
explicit	O
memory	O
intelligence	O
requires	O
knowledge	O
and	O
acquiring	O
knowledge	O
can	O
be	O
done	O
via	O
learning	O
which	O
has	O
motivated	O
the	O
development	O
of	O
large-scale	O
deep	O
architectures	O
however	O
there	O
are	O
different	O
kinds	O
of	O
knowledge	O
some	O
knowledge	O
can	O
be	O
implicit	O
subconscious	O
and	O
difficult	O
to	O
verbalize	O
such	O
as	O
how	O
to	O
walk	O
or	O
how	O
a	O
dog	O
looks	O
different	O
from	O
a	O
cat	O
other	O
knowledge	O
can	O
be	O
explicit	O
declarative	O
and	O
relatively	O
straightforward	O
to	O
put	O
into	O
words	O
every	O
day	O
commonsense	O
knowledge	O
like	O
a	O
cat	O
is	O
a	O
kind	O
of	O
animal	O
or	O
very	O
specific	O
facts	O
that	O
you	O
need	O
to	O
know	O
to	O
accomplish	O
your	O
current	O
goals	O
like	O
the	O
meeting	O
with	O
the	O
sales	O
team	O
is	O
at	O
pm	O
in	O
room	O
neural	O
networks	O
excel	O
at	O
storing	O
implicit	O
knowledge	O
however	O
they	O
struggle	O
to	O
memorize	O
facts	O
stochastic	O
gradient	B
descent	O
requires	O
many	O
presentations	O
of	O
the	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
memory	O
cells	O
writing	O
mechanism	O
reading	O
mechanism	O
task	O
network	O
controlling	O
the	O
memory	O
figure	O
a	O
schematic	O
of	O
an	O
example	B
of	O
a	O
network	O
with	O
an	O
explicit	O
memory	O
capturing	O
some	O
of	O
the	O
key	O
design	O
elements	O
of	O
the	O
neural	B
turing	I
machine	I
in	O
this	O
diagram	O
we	O
distinguish	O
the	O
representation	O
part	O
of	O
the	O
model	O
task	O
network	O
here	O
a	O
recurrent	O
net	O
in	O
the	O
bottom	O
from	O
the	O
memory	O
part	O
of	O
the	O
model	O
set	O
of	O
cells	O
which	O
can	O
store	O
facts	O
the	O
task	O
network	O
learns	O
to	O
control	O
the	O
memory	O
deciding	O
where	O
to	O
read	O
from	O
and	O
where	O
to	O
write	O
to	O
within	O
the	O
memory	O
the	O
reading	O
and	O
writing	O
mechanisms	O
indicated	O
by	O
bold	O
arrows	O
pointing	O
at	O
the	O
reading	O
and	O
writing	O
addresses	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
et	O
al	O
same	O
input	O
before	O
it	O
can	O
be	O
stored	O
in	O
a	O
neural	B
network	I
parameters	O
and	O
even	O
then	O
that	O
input	O
will	O
not	O
be	O
stored	O
especially	O
precisely	O
graves	O
hypothesized	O
that	O
this	O
is	O
because	O
neural	O
networks	O
lack	O
the	O
equivalent	O
of	O
the	O
working	O
memory	O
system	O
that	O
allows	O
human	O
beings	O
to	O
explicitly	O
hold	O
and	O
manipulate	O
pieces	O
of	O
information	O
that	O
are	O
relevant	O
to	O
achieving	O
some	O
goal	O
such	O
explicit	O
memory	O
components	O
would	O
allow	O
our	O
systems	O
not	O
only	O
to	O
rapidly	O
and	O
intentionally	O
store	O
and	O
retrieve	O
specific	O
facts	O
but	O
also	O
to	O
sequentially	O
reason	O
with	O
them	O
the	O
need	O
for	O
neural	O
networks	O
that	O
can	O
process	O
information	O
in	O
a	O
sequence	O
of	O
steps	O
changing	O
the	O
way	O
the	O
input	O
is	O
fed	O
into	O
the	O
network	O
at	O
each	O
step	O
has	O
long	O
been	O
recognized	O
as	O
important	O
for	O
the	O
ability	O
to	O
reason	O
rather	O
than	O
to	O
make	O
automatic	O
intuitive	O
responses	O
to	O
the	O
input	O
hinton	O
et	O
al	O
et	O
al	O
to	O
resolve	O
this	O
difficulty	O
weston	O
introduced	O
memory	O
networks	O
that	O
include	O
a	O
set	O
of	O
memory	O
cells	O
that	O
can	O
be	O
accessed	O
via	O
an	O
addressing	O
mechanism	O
memory	O
networks	O
originally	O
required	O
a	O
supervision	O
signal	O
instructing	O
them	O
how	O
to	O
use	O
their	O
memory	O
cells	O
graves	O
introduced	O
the	O
neural	B
turing	I
machine	I
which	O
is	O
able	O
to	O
learn	O
to	O
read	O
from	O
and	O
write	O
arbitrary	O
content	O
to	O
memory	O
cells	O
without	O
explicit	O
supervision	O
about	O
which	O
actions	O
to	O
undertake	O
and	O
allowed	O
end-to-end	O
training	O
without	O
this	O
supervision	O
signal	O
via	O
the	O
use	O
of	O
a	O
content-based	O
soft	O
attention	O
mechanism	O
and	O
section	O
this	O
soft	O
addressing	O
mechanism	O
has	O
become	O
standard	O
with	O
other	O
related	O
architectures	O
emulating	O
algorithmic	O
mechanisms	O
in	O
a	O
way	O
that	O
still	O
allows	O
gradient-based	O
optimization	O
sukhbaatar	O
et	O
al	O
joulin	O
and	O
mikolov	O
kumar	O
grefenstette	O
bahdanau	O
et	O
al	O
vinyals	O
et	O
al	O
et	O
al	O
et	O
al	O
each	O
memory	O
cell	O
can	O
be	O
thought	O
of	O
as	O
an	O
extension	O
of	O
the	O
memory	O
cells	O
in	O
lstms	O
and	O
grus	O
the	O
difference	O
is	O
that	O
the	O
network	O
outputs	O
an	O
internal	O
state	O
that	O
chooses	O
which	O
cell	O
to	O
read	O
from	O
or	O
write	O
to	O
just	O
as	O
memory	O
accesses	O
in	O
a	O
digital	O
computer	O
read	O
from	O
or	O
write	O
to	O
a	O
specific	O
address	O
it	O
is	O
difficult	O
to	O
optimize	O
functions	O
that	O
produce	O
exact	O
integer	O
addresses	O
to	O
alleviate	O
this	O
problem	O
ntms	O
actually	O
read	O
to	O
or	O
write	O
from	O
many	O
memory	O
cells	O
simultaneously	O
to	O
read	O
they	O
take	O
a	O
weighted	O
average	O
of	O
many	O
cells	O
to	O
write	O
they	O
modify	O
multiple	O
cells	O
by	O
different	O
amounts	O
the	O
coefficients	O
for	O
these	O
operations	O
are	O
chosen	O
to	O
be	O
focused	O
on	O
a	O
small	O
number	O
of	O
cells	O
for	O
example	B
by	O
producing	O
them	O
via	O
a	O
softmax	O
function	O
using	O
these	O
weights	B
with	O
non-zero	O
derivatives	O
allows	O
the	O
functions	O
controlling	O
access	O
to	O
the	O
memory	O
to	O
be	O
optimized	O
using	O
gradient	B
descent	O
the	O
gradient	B
on	O
these	O
coefficients	O
indicates	O
whether	O
each	O
of	O
them	O
should	O
be	O
increased	O
or	O
decreased	O
but	O
the	O
gradient	B
will	O
typically	O
be	O
large	O
only	O
for	O
those	O
memory	O
addresses	O
receiving	O
a	O
large	O
coefficient	O
these	O
memory	O
cells	O
are	O
typically	O
augmented	O
to	O
contain	O
a	O
vector	O
rather	O
than	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
the	O
single	O
scalar	O
stored	O
by	O
an	O
lstm	O
or	O
gru	O
memory	O
cell	O
there	O
are	O
two	O
reasons	O
to	O
increase	O
the	O
size	O
of	O
the	O
memory	O
cell	O
one	O
reason	O
is	O
that	O
we	O
have	O
increased	O
the	O
cost	O
of	O
accessing	O
a	O
memory	O
cell	O
we	O
pay	O
the	O
computational	O
cost	O
of	O
producing	O
a	O
coefficient	O
for	O
many	O
cells	O
but	O
we	O
expect	O
these	O
coefficients	O
to	O
cluster	O
around	O
a	O
small	O
number	O
of	O
cells	O
by	O
reading	O
a	O
vector	O
value	O
rather	O
than	O
a	O
scalar	O
value	O
we	O
can	O
offset	O
some	O
of	O
this	O
cost	O
another	O
reason	O
to	O
use	O
vector-valued	O
memory	O
cells	O
is	O
that	O
they	O
allow	O
for	O
content-based	B
addressing	I
where	O
the	O
weight	O
used	O
to	O
read	O
to	O
or	O
write	O
from	O
a	O
cell	O
is	O
a	O
function	O
of	O
that	O
cell	O
vector-valued	O
cells	O
allow	O
us	O
to	O
retrieve	O
a	O
complete	O
vector-valued	O
memory	O
if	O
we	O
are	O
able	O
to	O
produce	O
a	O
pattern	O
that	O
matches	O
some	O
but	O
not	O
all	O
of	O
its	O
elements	O
this	O
is	O
analogous	O
to	O
the	O
way	O
that	O
people	O
can	O
recall	B
the	O
lyrics	O
of	O
a	O
song	O
based	O
on	O
a	O
few	O
words	O
we	O
can	O
think	O
of	O
a	O
content-based	O
read	O
instruction	O
as	O
saying	O
retrieve	O
the	O
lyrics	O
of	O
the	O
song	O
that	O
has	O
the	O
chorus	O
we	O
all	O
live	O
in	O
a	O
yellow	O
submarine	O
content-based	B
addressing	I
is	O
more	O
useful	O
when	O
we	O
make	O
the	O
objects	O
to	O
be	O
retrieved	O
large	O
if	O
every	O
letter	O
of	O
the	O
song	O
was	O
stored	O
in	O
a	O
separate	O
memory	O
cell	O
we	O
would	O
not	O
be	O
able	O
to	O
find	O
them	O
this	O
way	O
by	O
comparison	O
location-based	O
addressing	O
is	O
not	O
allowed	O
to	O
refer	O
to	O
the	O
content	O
of	O
the	O
memory	O
we	O
can	O
think	O
of	O
a	O
location-based	O
read	O
instruction	O
as	O
saying	O
retrieve	O
the	O
lyrics	O
of	O
the	O
song	O
in	O
slot	O
location-based	O
addressing	O
can	O
often	O
be	O
a	O
perfectly	O
sensible	O
mechanism	O
even	O
when	O
the	O
memory	O
cells	O
are	O
small	O
if	O
the	O
content	O
of	O
a	O
memory	O
cell	O
is	O
copied	O
forgotten	O
at	O
most	O
time	O
steps	O
then	O
the	O
information	O
it	O
contains	O
can	O
be	O
propagated	O
forward	O
in	O
time	O
and	O
the	O
gradients	O
propagated	O
backward	O
in	O
time	O
without	O
either	O
vanishing	O
or	O
exploding	O
the	O
explicit	O
memory	O
approach	O
is	O
illustrated	O
in	O
figure	O
where	O
we	O
see	O
that	O
a	O
task	O
neural	B
network	I
is	O
coupled	O
with	O
a	O
memory	O
although	O
that	O
task	O
neural	B
network	I
could	O
be	O
feedforward	O
or	O
recurrent	O
the	O
overall	O
system	O
is	O
a	O
recurrent	B
network	I
the	O
task	O
network	O
can	O
choose	O
to	O
read	O
from	O
or	O
write	O
to	O
specific	O
memory	O
addresses	O
explicit	O
memory	O
seems	O
to	O
allow	O
models	O
to	O
learn	O
tasks	O
that	O
ordinary	O
rnns	O
or	O
lstm	O
rnns	O
cannot	O
learn	O
one	O
reason	O
for	O
this	O
advantage	O
may	O
be	O
because	O
information	O
and	O
gradients	O
can	O
be	O
propagated	O
in	O
time	O
or	O
backwards	O
in	O
time	O
respectively	O
for	O
very	O
long	O
durations	O
as	O
an	O
alternative	O
to	O
back-propagation	B
through	O
weighted	O
averages	O
of	O
memory	O
cells	O
we	O
can	O
interpret	O
the	O
memory	O
addressing	O
coefficients	O
as	O
probabilities	O
and	O
stochastically	O
read	O
just	O
one	O
cell	O
and	O
sutskever	O
optimizing	O
models	O
that	O
make	O
discrete	O
decisions	O
requires	O
specialized	O
optimization	O
algorithms	O
described	O
in	O
section	O
so	O
far	O
training	O
these	O
stochastic	O
architectures	O
that	O
make	O
discrete	O
decisions	O
remains	O
harder	O
than	O
training	O
deterministic	O
algorithms	O
that	O
make	O
soft	O
decisions	O
whether	O
it	O
is	O
soft	O
back-propagation	B
or	O
stochastic	O
and	O
hard	O
the	O
chapter	O
sequence	O
modeling	O
recurrent	O
and	O
recursive	O
nets	O
mechanism	O
for	O
choosing	O
an	O
address	O
is	O
in	O
its	O
form	O
identical	O
to	O
the	O
attention	O
mechanism	O
which	O
had	O
been	O
previously	O
introduced	O
in	O
the	O
context	O
of	O
machine	B
translation	I
the	O
idea	O
of	O
attention	O
mechanisms	O
for	O
neural	O
networks	O
was	O
introduced	O
even	O
earlier	O
in	O
the	O
context	O
of	O
handwriting	O
generation	O
with	O
an	O
attention	O
mechanism	O
that	O
was	O
constrained	O
to	O
move	O
only	O
forward	O
in	O
time	O
through	O
the	O
sequence	O
in	O
the	O
case	O
of	O
machine	B
translation	I
and	O
memory	O
networks	O
at	O
each	O
step	O
the	O
focus	O
of	O
attention	O
can	O
move	O
to	O
a	O
completely	O
different	O
place	O
compared	O
to	O
the	O
previous	O
step	O
and	O
discussed	O
in	O
section	O
bahdanau	O
et	O
al	O
recurrent	O
neural	O
networks	O
provide	O
a	O
way	O
to	O
extend	O
deep	O
learning	O
to	O
sequential	O
data	O
they	O
are	O
the	O
last	O
major	O
tool	O
in	O
our	O
deep	O
learning	O
toolbox	O
our	O
discussion	O
now	O
moves	O
to	O
how	O
to	O
choose	O
and	O
use	O
these	O
tools	O
and	O
how	O
to	O
apply	O
them	O
to	O
real-world	O
tasks	O
chapter	O
practical	O
methodology	O
successfully	O
applying	O
deep	O
learning	O
techniques	O
requires	O
more	O
than	O
just	O
a	O
good	O
knowledge	O
of	O
what	O
algorithms	O
exist	O
and	O
the	O
principles	O
that	O
explain	O
how	O
they	O
work	O
a	O
good	O
machine	B
learning	I
practitioner	O
also	O
needs	O
to	O
know	O
how	O
to	O
choose	O
an	O
algorithm	O
for	O
a	O
particular	O
application	O
and	O
how	O
to	O
monitor	O
and	O
respond	O
to	O
feedback	O
obtained	O
from	O
experiments	O
in	O
order	O
to	O
improve	O
a	O
machine	B
learning	I
system	O
during	O
day	O
to	O
day	O
development	O
of	O
machine	B
learning	I
systems	O
practitioners	O
need	O
to	O
decide	O
whether	O
to	O
gather	O
more	O
data	O
increase	O
or	O
decrease	O
model	O
capacity	O
add	O
or	O
remove	O
regularizing	O
features	O
improve	O
the	O
optimization	O
of	O
a	O
model	O
improve	O
approximate	B
inference	I
in	O
a	O
model	O
or	O
debug	O
the	O
software	O
implementation	O
of	O
the	O
model	O
all	O
of	O
these	O
operations	O
are	O
at	O
the	O
very	O
least	O
time-consuming	O
to	O
try	O
out	O
so	O
it	O
is	O
important	O
to	O
be	O
able	O
to	O
determine	O
the	O
right	O
course	O
of	O
action	O
rather	O
than	O
blindly	O
guessing	O
most	O
of	O
this	O
book	O
is	O
about	O
different	O
machine	B
learning	I
models	O
training	O
algorithms	O
and	O
objective	O
functions	O
this	O
may	O
give	O
the	O
impression	O
that	O
the	O
most	O
important	O
ingredient	O
to	O
being	O
a	O
machine	B
learning	I
expert	O
is	O
knowing	O
a	O
wide	O
variety	O
of	O
machine	B
learning	I
techniques	O
and	O
being	O
good	O
at	O
different	O
kinds	O
of	O
math	O
in	O
practice	O
one	O
can	O
usually	O
do	O
much	O
better	O
with	O
a	O
correct	O
application	O
of	O
a	O
commonplace	O
algorithm	O
than	O
by	O
sloppily	O
applying	O
an	O
obscure	O
algorithm	O
correct	O
application	O
of	O
an	O
algorithm	O
depends	O
on	O
mastering	O
some	O
fairly	O
simple	O
methodology	O
many	O
of	O
the	O
recommendations	O
in	O
this	O
chapter	O
are	O
adapted	O
from	O
ng	O
we	O
recommend	O
the	O
following	O
practical	O
design	O
process	O
determine	O
your	O
goals	O
what	O
error	O
metric	O
to	O
use	O
and	O
your	O
target	O
value	O
for	O
this	O
error	O
metric	O
these	O
goals	O
and	O
error	O
metrics	O
should	O
be	O
driven	O
by	O
the	O
problem	O
that	O
the	O
application	O
is	O
intended	O
to	O
solve	O
establish	O
a	O
working	O
end-to-end	O
pipeline	O
as	O
soon	O
as	O
possible	O
including	O
the	O
chapter	O
practical	O
methodology	O
estimation	O
of	O
the	O
appropriate	O
performance	O
metrics	O
instrument	O
the	O
system	O
well	O
to	O
determine	O
bottlenecks	O
in	O
performance	O
diagnose	O
which	O
components	O
are	O
performing	O
worse	O
than	O
expected	O
and	O
whether	O
it	O
is	O
due	O
to	O
overfitting	O
underfitting	O
or	O
a	O
defect	O
in	O
the	O
data	O
or	O
software	O
repeatedly	O
make	O
incremental	O
changes	O
such	O
as	O
gathering	O
new	O
data	O
adjusting	O
hyperparameters	O
or	O
changing	O
algorithms	O
based	O
on	O
specific	O
findings	O
from	O
your	O
instrumentation	O
goodfellow	O
et	O
al	O
as	O
a	O
running	O
example	B
we	O
will	O
use	O
street	O
view	O
address	O
number	O
transcription	B
system	O
the	O
purpose	O
of	O
this	O
application	O
is	O
to	O
add	O
buildings	O
to	O
google	O
maps	O
street	O
view	O
cars	O
photograph	O
the	O
buildings	O
and	O
record	O
the	O
gps	O
coordinates	O
associated	O
with	O
each	O
photograph	O
a	O
convolutional	B
network	I
recognizes	O
the	O
address	O
number	O
in	O
each	O
photograph	O
allowing	O
the	O
google	O
maps	O
database	O
to	O
add	O
that	O
address	O
in	O
the	O
correct	O
location	O
the	O
story	O
of	O
how	O
this	O
commercial	O
application	O
was	O
developed	O
gives	O
an	O
example	B
of	O
how	O
to	O
follow	O
the	O
design	O
methodology	O
we	O
advocate	O
we	O
now	O
describe	O
each	O
of	O
the	O
steps	O
in	O
this	O
process	O
performance	O
metrics	O
determining	O
your	O
goals	O
in	O
terms	O
of	O
which	O
error	O
metric	O
to	O
use	O
is	O
a	O
necessary	O
first	O
step	O
because	O
your	O
error	O
metric	O
will	O
guide	O
all	O
of	O
your	O
future	O
actions	O
you	O
should	O
also	O
have	O
an	O
idea	O
of	O
what	O
level	O
of	O
performance	O
you	O
desire	O
keep	O
in	O
mind	O
that	O
for	O
most	O
applications	O
it	O
is	O
impossible	O
to	O
achieve	O
absolute	O
zero	O
error	O
the	O
bayes	B
error	I
defines	O
the	O
minimum	O
error	O
rate	O
that	O
you	O
can	O
hope	O
to	O
achieve	O
even	O
if	O
you	O
have	O
infinite	O
training	O
data	O
and	O
can	O
recover	O
the	O
true	O
probability	B
distribution	I
this	O
is	O
because	O
your	O
input	O
features	O
may	O
not	O
contain	O
complete	O
information	O
about	O
the	O
output	O
variable	O
or	O
because	O
the	O
system	O
might	O
be	O
intrinsically	O
stochastic	O
you	O
will	O
also	O
be	O
limited	O
by	O
having	O
a	O
finite	O
amount	O
of	O
training	O
data	O
the	O
amount	O
of	O
training	O
data	O
can	O
be	O
limited	O
for	O
a	O
variety	O
of	O
reasons	O
when	O
your	O
goal	O
is	O
to	O
build	O
the	O
best	O
possible	O
real-world	O
product	O
or	O
service	O
you	O
can	O
typically	O
collect	O
more	O
data	O
but	O
must	O
determine	O
the	O
value	O
of	O
reducing	O
error	O
further	O
and	O
weigh	O
this	O
against	O
the	O
cost	O
of	O
collecting	O
more	O
data	O
data	O
collection	O
can	O
require	O
time	O
money	O
or	O
human	O
suffering	O
example	B
if	O
your	O
data	O
collection	O
process	O
involves	O
performing	O
invasive	O
medical	O
tests	O
when	O
your	O
goal	O
is	O
to	O
answer	O
a	O
scientific	O
question	O
about	O
which	O
algorithm	O
performs	O
better	O
on	O
a	O
fixed	O
benchmark	O
the	O
benchmark	O
chapter	O
practical	O
methodology	O
specification	O
usually	O
determines	O
the	O
training	O
set	O
and	O
you	O
are	O
not	O
allowed	O
to	O
collect	O
more	O
data	O
how	O
can	O
one	O
determine	O
a	O
reasonable	O
level	O
of	O
performance	O
to	O
expect	O
typically	O
in	O
the	O
academic	O
setting	O
we	O
have	O
some	O
estimate	O
of	O
the	O
error	O
rate	O
that	O
is	O
attainable	O
based	O
on	O
previously	O
published	O
benchmark	O
results	O
in	O
the	O
real-word	O
setting	O
we	O
have	O
some	O
idea	O
of	O
the	O
error	O
rate	O
that	O
is	O
necessary	O
for	O
an	O
application	O
to	O
be	O
safe	O
cost-effective	O
or	O
appealing	O
to	O
consumers	O
once	O
you	O
have	O
determined	O
your	O
realistic	O
desired	O
error	O
rate	O
your	O
design	O
decisions	O
will	O
be	O
guided	O
by	O
reaching	O
this	O
error	O
rate	O
another	O
important	O
consideration	O
besides	O
the	O
target	O
value	O
of	O
the	O
performance	O
metric	O
is	O
the	O
choice	O
of	O
which	O
metric	O
to	O
use	O
several	O
different	O
performance	O
metrics	O
may	O
be	O
used	O
to	O
measure	O
the	O
effectiveness	O
of	O
a	O
complete	O
application	O
that	O
includes	O
machine	B
learning	I
components	O
these	O
performance	O
metrics	O
are	O
usually	O
different	O
from	O
the	O
cost	O
function	O
used	O
to	O
train	O
the	O
model	O
as	O
described	O
in	O
section	O
it	O
is	O
common	O
to	O
measure	O
the	O
accuracy	B
or	O
equivalently	O
the	O
error	O
rate	O
of	O
a	O
system	O
however	O
many	O
applications	O
require	O
more	O
advanced	O
metrics	O
sometimes	O
it	O
is	O
much	O
more	O
costly	O
to	O
make	O
one	O
kind	O
of	O
a	O
mistake	O
than	O
another	O
for	O
example	B
an	O
e-mail	O
spam	B
detection	I
system	O
can	O
make	O
two	O
kinds	O
of	O
mistakes	O
incorrectly	O
classifying	O
a	O
legitimate	O
message	O
as	O
spam	O
and	O
incorrectly	O
allowing	O
a	O
spam	O
message	O
to	O
appear	O
in	O
the	O
inbox	O
it	O
is	O
much	O
worse	O
to	O
block	O
a	O
legitimate	O
message	O
than	O
to	O
allow	O
a	O
questionable	O
message	O
to	O
pass	O
through	O
rather	O
than	O
measuring	O
the	O
error	O
rate	O
of	O
a	O
spam	O
classifier	O
we	O
may	O
wish	O
to	O
measure	O
some	O
form	O
of	O
total	O
cost	O
where	O
the	O
cost	O
of	O
blocking	O
legitimate	O
messages	O
is	O
higher	O
than	O
the	O
cost	O
of	O
allowing	O
spam	O
messages	O
sometimes	O
we	O
wish	O
to	O
train	O
a	O
binary	O
classifier	O
that	O
is	O
intended	O
to	O
detect	O
some	O
rare	O
event	O
for	O
example	B
we	O
might	O
design	O
a	O
medical	O
test	O
for	O
a	O
rare	O
disease	O
suppose	O
that	O
only	O
one	O
in	O
every	O
million	O
people	O
has	O
this	O
disease	O
we	O
can	O
easily	O
achieve	O
accuracy	B
on	O
the	O
detection	O
task	O
by	O
simply	O
hard-coding	O
the	O
classifier	O
to	O
always	O
report	O
that	O
the	O
disease	O
is	O
absent	O
clearly	O
accuracy	B
is	O
a	O
poor	O
way	O
to	O
characterize	O
the	O
performance	O
of	O
such	O
a	O
system	O
one	O
way	O
to	O
solve	O
this	O
problem	O
is	O
to	O
instead	O
measure	O
precision	B
and	O
recall	B
precision	B
is	O
the	O
fraction	O
of	O
detections	O
reported	O
by	O
the	O
model	O
that	O
were	O
correct	O
while	O
recall	B
is	O
the	O
fraction	O
of	O
true	O
events	O
that	O
were	O
detected	O
a	O
detector	O
that	O
says	O
no	O
one	O
has	O
the	O
disease	O
would	O
achieve	O
perfect	O
precision	B
but	O
zero	O
recall	B
a	O
detector	O
that	O
says	O
everyone	O
has	O
the	O
disease	O
would	O
achieve	O
perfect	O
recall	B
but	O
precision	B
equal	O
to	O
the	O
percentage	O
of	O
people	O
who	O
have	O
the	O
disease	O
in	O
our	O
example	B
of	O
a	O
disease	O
that	O
only	O
one	O
people	O
in	O
a	O
million	O
have	O
when	O
using	O
precision	B
and	O
recall	B
it	O
is	O
common	O
to	O
plot	O
a	O
pr	O
curve	O
with	O
precision	B
on	O
the	O
y-axis	O
and	O
recall	B
on	O
the	O
x-axis	O
the	O
classifier	O
generates	O
a	O
score	O
that	O
is	O
higher	O
if	O
the	O
event	O
to	O
be	O
detected	O
occurred	O
for	O
example	B
a	O
feedforward	O
chapter	O
practical	O
methodology	O
x	O
estimating	O
the	O
network	O
designed	O
to	O
detect	O
a	O
disease	O
outputs	O
y	O
p	O
probability	O
that	O
a	O
person	O
whose	O
medical	O
results	O
are	O
described	O
by	O
features	O
x	O
has	O
the	O
disease	O
we	O
choose	O
to	O
report	O
a	O
detection	O
whenever	O
this	O
score	O
exceeds	O
some	O
threshold	O
by	O
varying	O
the	O
threshold	O
we	O
can	O
trade	O
precision	B
for	O
recall	B
in	O
many	O
cases	O
we	O
wish	O
to	O
summarize	O
the	O
performance	O
of	O
the	O
classifier	O
with	O
a	O
single	O
number	O
rather	O
than	O
a	O
curve	O
to	O
do	O
so	O
we	O
can	O
convert	O
precision	B
p	O
and	O
recall	B
r	O
into	O
an	O
f-score	B
given	O
by	O
f	O
r	O
p	O
another	O
option	O
is	O
to	O
report	O
the	O
total	O
area	O
lying	O
beneath	O
the	O
pr	O
curve	O
in	O
some	O
applications	O
it	O
is	O
possible	O
for	O
the	O
machine	B
learning	I
system	O
to	O
refuse	O
to	O
make	O
a	O
decision	O
this	O
is	O
useful	O
when	O
the	O
machine	B
learning	I
algorithm	O
can	O
estimate	O
how	O
confident	O
it	O
should	O
be	O
about	O
a	O
decision	O
especially	O
if	O
a	O
wrong	O
decision	O
can	O
be	O
harmful	O
and	O
if	O
a	O
human	O
operator	O
is	O
able	O
to	O
occasionally	O
take	O
over	O
the	O
street	O
view	O
transcription	B
system	O
provides	O
an	O
example	B
of	O
this	O
situation	O
the	O
task	O
is	O
to	O
transcribe	O
the	O
address	O
number	O
from	O
a	O
photograph	O
in	O
order	O
to	O
associate	O
the	O
location	O
where	O
the	O
photo	O
was	O
taken	O
with	O
the	O
correct	O
address	O
in	O
a	O
map	O
because	O
the	O
value	O
of	O
the	O
map	O
degrades	O
considerably	O
if	O
the	O
map	O
is	O
inaccurate	O
it	O
is	O
important	O
to	O
add	O
an	O
address	O
only	O
if	O
the	O
transcription	B
is	O
correct	O
if	O
the	O
machine	B
learning	I
system	O
thinks	O
that	O
it	O
is	O
less	O
likely	O
than	O
a	O
human	O
being	O
to	O
obtain	O
the	O
correct	O
transcription	B
then	O
the	O
best	O
course	O
of	O
action	O
is	O
to	O
allow	O
a	O
human	O
to	O
transcribe	O
the	O
photo	O
instead	O
of	O
course	O
the	O
machine	B
learning	I
system	O
is	O
only	O
useful	O
if	O
it	O
is	O
able	O
to	O
dramatically	O
reduce	O
the	O
amount	O
of	O
photos	O
that	O
the	O
human	O
operators	O
must	O
process	O
a	O
natural	O
performance	O
metric	O
to	O
use	O
in	O
this	O
situation	O
is	O
coverage	B
coverage	B
is	O
the	O
fraction	O
of	O
examples	O
for	O
which	O
the	O
machine	B
learning	I
system	O
is	O
able	O
to	O
produce	O
a	O
response	O
it	O
is	O
possible	O
to	O
trade	O
coverage	B
for	O
accuracy	B
one	O
can	O
always	O
obtain	O
accuracy	B
by	O
refusing	O
to	O
process	O
any	O
example	B
but	O
this	O
reduces	O
the	O
coverage	B
to	O
for	O
the	O
street	O
view	O
task	O
the	O
goal	O
for	O
the	O
project	O
was	O
to	O
reach	O
human-level	O
transcription	B
accuracy	B
while	O
maintaining	O
coverage	B
human-level	O
performance	O
on	O
this	O
task	O
is	O
accuracy	B
many	O
other	O
metrics	O
are	O
possible	O
we	O
can	O
for	O
example	B
measure	O
click-through	O
rates	O
collect	O
user	O
satisfaction	O
surveys	O
and	O
so	O
on	O
many	O
specialized	O
application	O
areas	O
have	O
application-specific	O
criteria	O
as	O
well	O
what	O
is	O
important	O
is	O
to	O
determine	O
which	O
performance	O
metric	O
to	O
improve	O
ahead	O
of	O
time	O
then	O
concentrate	O
on	O
improving	O
this	O
metric	O
without	O
clearly	O
defined	O
goals	O
it	O
can	O
be	O
difficult	O
to	O
tell	O
whether	O
changes	O
to	O
a	O
machine	B
learning	I
system	O
make	O
progress	O
or	O
not	O
chapter	O
practical	O
methodology	O
default	O
baseline	O
models	O
after	O
choosing	O
performance	O
metrics	O
and	O
goals	O
the	O
next	O
step	O
in	O
any	O
practical	O
application	O
is	O
to	O
establish	O
a	O
reasonable	O
end-to-end	O
system	O
as	O
soon	O
as	O
possible	O
in	O
this	O
section	O
we	O
provide	O
recommendations	O
for	O
which	O
algorithms	O
to	O
use	O
as	O
the	O
first	O
baseline	O
approach	O
in	O
various	O
situations	O
keep	O
in	O
mind	O
that	O
deep	O
learning	O
research	O
progresses	O
quickly	O
so	O
better	O
default	O
algorithms	O
are	O
likely	O
to	O
become	O
available	O
soon	O
after	O
this	O
writing	O
depending	O
on	O
the	O
complexity	O
of	O
your	O
problem	O
you	O
may	O
even	O
want	O
to	O
begin	O
without	O
using	O
deep	O
learning	O
if	O
your	O
problem	O
has	O
a	O
chance	O
of	O
being	O
solved	O
by	O
just	O
choosing	O
a	O
few	O
linear	O
weights	B
correctly	O
you	O
may	O
want	O
to	O
begin	O
with	O
a	O
simple	O
statistical	O
model	O
like	O
logistic	O
regression	B
if	O
you	O
know	O
that	O
your	O
problem	O
falls	O
into	O
an	O
ai-complete	O
category	O
like	O
object	B
recognition	I
speech	O
recognition	O
machine	B
translation	I
and	O
so	O
on	O
then	O
you	O
are	O
likely	O
to	O
do	O
well	O
by	O
beginning	O
with	O
an	O
appropriate	O
deep	O
learning	O
model	O
first	O
choose	O
the	O
general	O
category	O
of	O
model	O
based	O
on	O
the	O
structure	O
of	O
your	O
data	O
if	O
you	O
want	O
to	O
perform	O
supervised	B
learning	I
with	O
fixed-size	O
vectors	O
as	O
input	O
use	O
a	O
feedforward	O
network	O
with	O
fully	O
connected	O
layers	O
if	O
the	O
input	O
has	O
known	O
topological	O
structure	O
example	B
if	O
the	O
input	O
is	O
an	O
image	O
use	O
a	O
convolutional	B
network	I
in	O
these	O
cases	O
you	O
should	O
begin	O
by	O
using	O
some	O
kind	O
of	O
piecewise	O
linear	O
unit	O
or	O
their	O
generalizations	O
like	O
leaky	O
relus	O
prelus	O
and	O
maxout	O
if	O
your	O
input	O
or	O
output	O
is	O
a	O
sequence	O
use	O
a	O
gated	O
recurrent	O
net	O
or	O
gru	O
a	O
reasonable	O
choice	O
of	O
optimization	O
algorithm	O
is	O
sgd	O
with	O
momentum	O
with	O
a	O
decaying	O
learning	B
rate	I
decay	O
schemes	O
that	O
perform	O
better	O
or	O
worse	O
on	O
different	O
problems	O
include	O
decaying	O
linearly	O
until	O
reaching	O
a	O
fixed	O
minimum	O
learning	B
rate	I
decaying	O
exponentially	O
or	O
decreasing	O
the	O
learning	B
rate	I
by	O
a	O
factor	O
of	O
each	O
time	O
validation	O
error	O
plateaus	O
another	O
very	O
reasonable	O
alternative	O
is	O
adam	O
batch	O
normalization	O
can	O
have	O
a	O
dramatic	O
effect	O
on	O
optimization	O
performance	O
especially	O
for	O
convolutional	O
networks	O
and	O
networks	O
with	O
sigmoidal	O
nonlinearities	O
while	O
it	O
is	O
reasonable	O
to	O
omit	O
batch	O
normalization	O
from	O
the	O
very	O
first	O
baseline	O
it	O
should	O
be	O
introduced	O
quickly	O
if	O
optimization	O
appears	O
to	O
be	O
problematic	O
unless	O
your	O
training	O
set	O
contains	O
tens	O
of	O
millions	O
of	O
examples	O
or	O
more	O
you	O
should	O
include	O
some	O
mild	O
forms	O
of	O
regularization	O
from	O
the	O
start	O
early	O
stopping	O
should	O
be	O
used	O
almost	O
universally	O
dropout	O
is	O
an	O
excellent	O
regularizer	B
that	O
is	O
easy	O
to	O
implement	O
and	O
compatible	O
with	O
many	O
models	O
and	O
training	O
algorithms	O
batch	O
normalization	O
also	O
sometimes	O
reduces	O
generalization	B
error	O
and	O
allows	O
dropout	O
to	O
be	O
omitted	O
due	O
to	O
the	O
noise	O
in	O
the	O
estimate	O
of	O
the	O
statistics	O
used	O
to	O
normalize	O
each	O
variable	O
chapter	O
practical	O
methodology	O
if	O
your	O
task	O
is	O
similar	O
to	O
another	O
task	O
that	O
has	O
been	O
studied	O
extensively	O
you	O
will	O
probably	O
do	O
well	O
by	O
first	O
copying	O
the	O
model	O
and	O
algorithm	O
that	O
is	O
already	O
known	O
to	O
perform	O
best	O
on	O
the	O
previously	O
studied	O
task	O
you	O
may	O
even	O
want	O
to	O
copy	O
a	O
trained	O
model	O
from	O
that	O
task	O
for	O
example	B
it	O
is	O
common	O
to	O
use	O
the	O
features	O
from	O
a	O
convolutional	B
network	I
trained	O
on	O
imagenet	O
to	O
solve	O
other	O
computer	B
vision	I
tasks	O
girshick	O
et	O
al	O
iii	O
a	O
common	O
question	O
is	O
whether	O
to	O
begin	O
by	O
using	O
unsupervised	O
learning	O
described	O
further	O
in	O
part	O
this	O
is	O
somewhat	O
domain	O
specific	O
some	O
domains	O
such	O
as	O
natural	B
language	I
processing	I
are	O
known	O
to	O
benefit	O
tremendously	O
from	O
unsupervised	O
learning	O
techniques	O
such	O
as	O
learning	O
unsupervised	O
word	O
embeddings	O
in	O
other	O
domains	O
such	O
as	O
computer	B
vision	I
current	O
unsupervised	O
learning	O
techniques	O
do	O
not	O
bring	O
a	O
benefit	O
except	O
in	O
the	O
semi-supervised	O
setting	O
when	O
the	O
number	O
of	O
labeled	O
examples	O
is	O
very	O
small	O
if	O
your	O
application	O
is	O
in	O
a	O
context	O
where	O
unsupervised	O
learning	O
is	O
known	O
to	O
be	O
important	O
then	O
include	O
it	O
in	O
your	O
first	O
end-to-end	O
baseline	O
otherwise	O
only	O
use	O
unsupervised	O
learning	O
in	O
your	O
first	O
attempt	O
if	O
the	O
task	O
you	O
want	O
to	O
solve	O
is	O
unsupervised	O
you	O
can	O
always	O
try	O
adding	O
unsupervised	O
learning	O
later	O
if	O
you	O
observe	O
that	O
your	O
initial	O
baseline	O
overfits	O
kingma	O
et	O
al	O
rasmus	O
et	O
al	O
determining	O
whether	O
to	O
gather	O
more	O
data	O
after	O
the	O
first	O
end-to-end	O
system	O
is	O
established	O
it	O
is	O
time	O
to	O
measure	O
the	O
performance	O
of	O
the	O
algorithm	O
and	O
determine	O
how	O
to	O
improve	O
it	O
many	O
machine	B
learning	I
novices	O
are	O
tempted	O
to	O
make	O
improvements	O
by	O
trying	O
out	O
many	O
different	O
algorithms	O
however	O
it	O
is	O
often	O
much	O
better	O
to	O
gather	O
more	O
data	O
than	O
to	O
improve	O
the	O
learning	O
algorithm	O
how	O
does	O
one	O
decide	O
whether	O
to	O
gather	O
more	O
data	O
first	O
determine	O
whether	O
the	O
performance	O
on	O
the	O
training	O
set	O
is	O
acceptable	O
if	O
performance	O
on	O
the	O
training	O
set	O
is	O
poor	O
the	O
learning	O
algorithm	O
is	O
not	O
using	O
the	O
training	O
data	O
that	O
is	O
already	O
available	O
so	O
there	O
is	O
no	O
reason	O
to	O
gather	O
more	O
data	O
instead	O
try	O
increasing	O
the	O
size	O
of	O
the	O
model	O
by	O
adding	O
more	O
layers	O
or	O
adding	O
more	O
hidden	O
units	O
to	O
each	O
layer	O
also	O
try	O
improving	O
the	O
learning	O
algorithm	O
for	O
example	B
by	O
tuning	O
the	O
learning	B
rate	I
hyperparameter	O
if	O
large	O
models	O
and	O
carefully	O
tuned	O
optimization	O
algorithms	O
do	O
not	O
work	O
well	O
then	O
the	O
problem	O
might	O
be	O
the	O
of	O
the	O
training	O
data	O
the	O
data	O
may	O
be	O
too	O
noisy	O
or	O
may	O
not	O
include	O
the	O
right	O
inputs	O
needed	O
to	O
predict	O
the	O
desired	O
outputs	O
this	O
suggests	O
starting	O
over	O
collecting	O
cleaner	O
data	O
or	O
collecting	O
a	O
richer	O
set	O
of	O
features	O
quality	O
if	O
the	O
performance	O
on	O
the	O
training	O
set	O
is	O
acceptable	O
then	O
measure	O
the	O
per	O
chapter	O
practical	O
methodology	O
if	O
the	O
performance	O
on	O
the	O
test	B
set	I
is	O
also	O
acceptable	O
formance	O
on	O
a	O
test	B
set	I
then	O
there	O
is	O
nothing	O
left	O
to	O
be	O
done	O
if	O
test	B
set	I
performance	O
is	O
much	O
worse	O
than	O
training	O
set	O
performance	O
then	O
gathering	O
more	O
data	O
is	O
one	O
of	O
the	O
most	O
effective	O
solutions	O
the	O
key	O
considerations	O
are	O
the	O
cost	O
and	O
feasibility	O
of	O
gathering	O
more	O
data	O
the	O
cost	O
and	O
feasibility	O
of	O
reducing	O
the	O
test	O
error	O
by	O
other	O
means	O
and	O
the	O
amount	O
of	O
data	O
that	O
is	O
expected	O
to	O
be	O
necessary	O
to	O
improve	O
test	B
set	I
performance	O
significantly	O
at	O
large	O
internet	O
companies	O
with	O
millions	O
or	O
billions	O
of	O
users	O
it	O
is	O
feasible	O
to	O
gather	O
large	O
datasets	O
and	O
the	O
expense	O
of	O
doing	O
so	O
can	O
be	O
considerably	O
less	O
than	O
the	O
other	O
alternatives	O
so	O
the	O
answer	O
is	O
almost	O
always	O
to	O
gather	O
more	O
training	O
data	O
for	O
example	B
the	O
development	O
of	O
large	O
labeled	O
datasets	O
was	O
one	O
of	O
the	O
most	O
important	O
factors	O
in	O
solving	O
object	B
recognition	I
in	O
other	O
contexts	O
such	O
as	O
medical	O
applications	O
it	O
may	O
be	O
costly	O
or	O
infeasible	O
to	O
gather	O
more	O
data	O
a	O
simple	O
alternative	O
to	O
gathering	O
more	O
data	O
is	O
to	O
reduce	O
the	O
size	O
of	O
the	O
model	O
or	O
improve	O
regularization	O
by	O
adjusting	O
hyperparameters	O
such	O
as	O
weight	O
decay	O
coefficients	O
or	O
by	O
adding	O
regularization	O
strategies	O
such	O
as	O
dropout	O
if	O
you	O
find	O
that	O
the	O
gap	O
between	O
train	O
and	O
test	O
performance	O
is	O
still	O
unacceptable	O
even	O
after	O
tuning	O
the	O
regularization	O
hyperparameters	O
then	O
gathering	O
more	O
data	O
is	O
advisable	O
when	O
deciding	O
whether	O
to	O
gather	O
more	O
data	O
it	O
is	O
also	O
necessary	O
to	O
decide	O
how	O
much	O
to	O
gather	O
it	O
is	O
helpful	O
to	O
plot	O
curves	O
showing	O
the	O
relationship	O
between	O
training	O
set	O
size	O
and	O
generalization	B
error	O
like	O
in	O
figure	O
by	O
extrapolating	O
such	O
curves	O
one	O
can	O
predict	O
how	O
much	O
additional	O
training	O
data	O
would	O
be	O
needed	O
to	O
achieve	O
a	O
certain	O
level	O
of	O
performance	O
usually	O
adding	O
a	O
small	O
fraction	O
of	O
the	O
total	O
number	O
of	O
examples	O
will	O
not	O
have	O
a	O
noticeable	O
impact	O
on	O
generalization	B
error	O
it	O
is	O
therefore	O
recommended	O
to	O
experiment	O
with	O
training	O
set	O
sizes	O
on	O
a	O
logarithmic	O
scale	O
for	O
example	B
doubling	O
the	O
number	O
of	O
examples	O
between	O
consecutive	O
experiments	O
if	O
gathering	O
much	O
more	O
data	O
is	O
not	O
feasible	O
the	O
only	O
other	O
way	O
to	O
improve	O
generalization	B
error	O
is	O
to	O
improve	O
the	O
learning	O
algorithm	O
itself	O
this	O
becomes	O
the	O
domain	O
of	O
research	O
and	O
not	O
the	O
domain	O
of	O
advice	O
for	O
applied	O
practitioners	O
selecting	O
hyperparameters	O
most	O
deep	O
learning	O
algorithms	O
come	O
with	O
many	O
hyperparameters	O
that	O
control	O
many	O
aspects	O
of	O
the	O
algorithm	O
s	O
behavior	O
some	O
of	O
these	O
hyperparameters	O
affect	O
the	O
time	O
and	O
memory	O
cost	O
of	O
running	O
the	O
algorithm	O
some	O
of	O
these	O
hyperparameters	O
affect	O
the	O
quality	O
of	O
the	O
model	O
recovered	O
by	O
the	O
training	O
process	O
and	O
its	O
ability	O
to	O
infer	O
correct	O
results	O
when	O
deployed	O
on	O
new	O
inputs	O
there	O
are	O
two	O
basic	O
approaches	O
to	O
choosing	O
these	O
hyperparameters	O
choosing	O
them	O
manually	O
and	O
choosing	O
them	O
automatically	O
choosing	O
the	O
hyperparameters	O
chapter	O
practical	O
methodology	O
manually	O
requires	O
understanding	O
what	O
the	O
hyperparameters	O
do	O
and	O
how	O
machine	B
learning	I
models	O
achieve	O
good	O
generalization	B
automatic	O
hyperparameter	O
selection	O
algorithms	O
greatly	O
reduce	O
the	O
need	O
to	O
understand	O
these	O
ideas	O
but	O
they	O
are	O
often	O
much	O
more	O
computationally	O
costly	O
manual	O
hyperparameter	O
tuning	O
to	O
set	O
hyperparameters	O
manually	O
one	O
must	O
understand	O
the	O
relationship	O
between	O
hyperparameters	O
training	B
error	I
generalization	B
error	O
and	O
computational	O
resources	O
and	O
runtime	O
this	O
means	O
establishing	O
a	O
solid	O
foundation	O
on	O
the	O
fundamental	O
ideas	O
concerning	O
the	O
effective	B
capacity	I
of	O
a	O
learning	O
algorithm	O
from	O
chapter	O
the	O
goal	O
of	O
manual	O
hyperparameter	O
search	O
is	O
usually	O
to	O
find	O
the	O
lowest	O
generalization	B
error	O
subject	O
to	O
some	O
runtime	O
and	O
memory	O
budget	O
we	O
do	O
not	O
discuss	O
how	O
to	O
determine	O
the	O
runtime	O
and	O
memory	O
impact	O
of	O
various	O
hyperparameters	O
here	O
because	O
this	O
is	O
highly	O
platform-dependent	O
the	O
primary	O
goal	O
of	O
manual	O
hyperparameter	O
search	O
is	O
to	O
adjust	O
the	O
effective	B
capacity	I
of	O
the	O
model	O
to	O
match	O
the	O
complexity	O
of	O
the	O
task	O
effective	B
capacity	I
is	O
constrained	O
by	O
three	O
factors	O
the	O
representational	B
capacity	I
of	O
the	O
model	O
the	O
ability	O
of	O
the	O
learning	O
algorithm	O
to	O
successfully	O
minimize	O
the	O
cost	O
function	O
used	O
to	O
train	O
the	O
model	O
and	O
the	O
degree	O
to	O
which	O
the	O
cost	O
function	O
and	O
training	O
procedure	O
regularize	O
the	O
model	O
a	O
model	O
with	O
more	O
layers	O
and	O
more	O
hidden	O
units	O
per	O
layer	O
has	O
higher	O
representational	B
capacity	I
it	O
is	O
capable	O
of	O
representing	O
more	O
complicated	O
functions	O
it	O
can	O
not	O
necessarily	O
actually	O
learn	O
all	O
of	O
these	O
functions	O
though	O
if	O
the	O
training	O
algorithm	O
cannot	O
discover	O
that	O
certain	O
functions	O
do	O
a	O
good	O
job	O
of	O
minimizing	O
the	O
training	O
cost	O
or	O
if	O
regularization	O
terms	O
such	O
as	O
weight	O
decay	O
forbid	O
some	O
of	O
these	O
functions	O
the	O
generalization	B
error	O
typically	O
follows	O
a	O
u-shaped	O
curve	O
when	O
plotted	O
as	O
a	O
function	O
of	O
one	O
of	O
the	O
hyperparameters	O
as	O
in	O
figure	O
at	O
one	O
extreme	O
the	O
hyperparameter	O
value	O
corresponds	O
to	O
low	O
capacity	O
and	O
generalization	B
error	O
is	O
high	O
because	O
training	B
error	I
is	O
high	O
this	O
is	O
the	O
underfitting	O
regime	O
at	O
the	O
other	O
extreme	O
the	O
hyperparameter	O
value	O
corresponds	O
to	O
high	O
capacity	O
and	O
the	O
generalization	B
error	O
is	O
high	O
because	O
the	O
gap	O
between	O
training	O
and	O
test	O
error	O
is	O
high	O
somewhere	O
in	O
the	O
middle	O
lies	O
the	O
optimal	O
model	O
capacity	O
which	O
achieves	O
the	O
lowest	O
possible	O
generalization	B
error	O
by	O
adding	O
a	O
medium	O
generalization	B
gap	O
to	O
a	O
medium	O
amount	O
of	O
training	B
error	I
for	O
some	O
hyperparameters	O
overfitting	O
occurs	O
when	O
the	O
value	O
of	O
the	O
hyperparameter	O
is	O
large	O
the	O
number	O
of	O
hidden	O
units	O
in	O
a	O
layer	O
is	O
one	O
such	O
example	B
chapter	O
practical	O
methodology	O
because	O
increasing	O
the	O
number	O
of	O
hidden	O
units	O
increases	O
the	O
capacity	O
of	O
the	O
model	O
for	O
some	O
hyperparameters	O
overfitting	O
occurs	O
when	O
the	O
value	O
of	O
the	O
hyperparameter	O
is	O
small	O
for	O
example	B
the	O
smallest	O
allowable	O
weight	O
decay	O
coefficient	O
of	O
zero	O
corresponds	O
to	O
the	O
greatest	O
effective	B
capacity	I
of	O
the	O
learning	O
algorithm	O
not	O
every	O
hyperparameter	O
will	O
be	O
able	O
to	O
explore	O
the	O
entire	O
u-shaped	O
curve	O
many	O
hyperparameters	O
are	O
discrete	O
such	O
as	O
the	O
number	O
of	O
units	O
in	O
a	O
layer	O
or	O
the	O
number	O
of	O
linear	O
pieces	O
in	O
a	O
maxout	O
unit	O
so	O
it	O
is	O
only	O
possible	O
to	O
visit	O
a	O
few	O
points	O
along	O
the	O
curve	O
some	O
hyperparameters	O
are	O
binary	O
usually	O
these	O
hyperparameters	O
are	O
switches	O
that	O
specify	O
whether	O
or	O
not	O
to	O
use	O
some	O
optional	O
component	O
of	O
the	O
learning	O
algorithm	O
such	O
as	O
a	O
preprocessing	B
step	O
that	O
normalizes	O
the	O
input	O
features	O
by	O
subtracting	O
their	O
mean	O
and	O
dividing	O
by	O
their	O
standard	B
deviation	I
these	O
hyperparameters	O
can	O
only	O
explore	O
two	O
points	O
on	O
the	O
curve	O
other	O
hyperparameters	O
have	O
some	O
minimum	O
or	O
maximum	O
value	O
that	O
prevents	O
them	O
from	O
exploring	O
some	O
part	O
of	O
the	O
curve	O
for	O
example	B
the	O
minimum	O
weight	O
decay	O
coefficient	O
is	O
zero	O
this	O
means	O
that	O
if	O
the	O
model	O
is	O
underfitting	O
when	O
weight	O
decay	O
is	O
zero	O
we	O
can	O
not	O
enter	O
the	O
overfitting	O
region	O
by	O
modifying	O
the	O
weight	O
decay	O
coefficient	O
in	O
other	O
words	O
some	O
hyperparameters	O
can	O
only	O
subtract	O
capacity	O
if	O
you	O
the	O
learning	B
rate	I
is	O
perhaps	O
the	O
most	O
important	O
hyperparameter	O
it	O
conhave	O
time	O
to	O
tune	O
only	O
one	O
hyperparameter	O
tune	O
the	O
learning	B
rate	I
trols	O
the	O
effective	B
capacity	I
of	O
the	O
model	O
in	O
a	O
more	O
complicated	O
way	O
than	O
other	O
hyperparameters	O
the	O
effective	B
capacity	I
of	O
the	O
model	O
is	O
highest	O
when	O
the	O
learning	B
rate	I
is	O
correct	O
for	O
the	O
optimization	O
problem	O
not	O
when	O
the	O
learning	B
rate	I
is	O
especially	O
large	O
or	O
especially	O
small	O
the	O
learning	B
rate	I
has	O
a	O
u-shaped	O
curve	O
for	O
training	B
error	I
illustrated	O
in	O
figure	O
when	O
the	O
learning	B
rate	I
is	O
too	O
large	O
gradient	B
descent	O
can	O
inadvertently	O
increase	O
rather	O
than	O
decrease	O
the	O
training	B
error	I
in	O
the	O
idealized	O
quadratic	O
case	O
this	O
occurs	O
if	O
the	O
learning	B
rate	I
is	O
at	O
least	O
twice	O
as	O
large	O
as	O
its	O
optimal	O
value	O
when	O
the	O
learning	B
rate	I
is	O
too	O
small	O
training	O
is	O
not	O
only	O
slower	O
but	O
may	O
become	O
permanently	O
stuck	O
with	O
a	O
high	O
training	B
error	I
this	O
effect	O
is	O
poorly	O
understood	O
would	O
not	O
happen	O
for	O
a	O
convex	O
loss	O
function	O
lecun	O
et	O
al	O
tuning	O
the	O
parameters	O
other	O
than	O
the	O
learning	B
rate	I
requires	O
monitoring	O
both	O
training	O
and	O
test	O
error	O
to	O
diagnose	O
whether	O
your	O
model	O
is	O
overfitting	O
or	O
underfitting	O
then	O
adjusting	O
its	O
capacity	O
appropriately	O
if	O
your	O
error	O
on	O
the	O
training	O
set	O
is	O
higher	O
than	O
your	O
target	O
error	O
rate	O
you	O
have	O
no	O
choice	O
but	O
to	O
increase	O
capacity	O
if	O
you	O
are	O
not	O
using	O
regularization	O
and	O
you	O
are	O
confident	O
that	O
your	O
optimization	O
algorithm	O
is	O
performing	O
correctly	O
then	O
you	O
must	O
add	O
more	O
layers	O
to	O
your	O
network	O
or	O
add	O
more	O
hidden	O
units	O
unfortunately	O
this	O
increases	O
the	O
computational	O
costs	O
associated	O
with	O
the	O
model	O
if	O
your	O
error	O
on	O
the	O
test	B
set	I
is	O
higher	O
than	O
than	O
your	O
target	O
error	O
rate	O
you	O
can	O
chapter	O
practical	O
methodology	O
r	O
o	O
r	O
r	O
e	O
i	O
g	O
n	O
n	O
i	O
a	O
r	O
t	O
learning	B
rate	I
scale	O
figure	O
typical	O
relationship	O
between	O
the	O
learning	B
rate	I
and	O
the	O
training	B
error	I
notice	O
the	O
sharp	O
rise	O
in	O
error	O
when	O
the	O
learning	O
is	O
above	O
an	O
optimal	O
value	O
this	O
is	O
for	O
a	O
fixed	O
training	O
time	O
as	O
a	O
smaller	O
learning	B
rate	I
may	O
sometimes	O
only	O
slow	O
down	O
training	O
by	O
a	O
factor	O
proportional	O
to	O
the	O
learning	B
rate	I
reduction	O
generalization	B
error	O
can	O
follow	O
this	O
curve	O
or	O
be	O
complicated	O
by	O
regularization	O
effects	O
arising	O
out	O
of	O
having	O
a	O
too	O
large	O
or	O
too	O
small	O
learning	O
rates	O
since	O
poor	O
optimization	O
can	O
to	O
some	O
degree	O
reduce	O
or	O
prevent	O
overfitting	O
and	O
even	O
points	O
with	O
equivalent	O
training	B
error	I
can	O
have	O
different	O
generalization	B
error	O
now	O
take	O
two	O
kinds	O
of	O
actions	O
the	O
test	O
error	O
is	O
the	O
sum	O
of	O
the	O
training	B
error	I
and	O
the	O
gap	O
between	O
training	O
and	O
test	O
error	O
the	O
optimal	O
test	O
error	O
is	O
found	O
by	O
trading	O
off	O
these	O
quantities	O
neural	O
networks	O
typically	O
perform	O
best	O
when	O
the	O
training	B
error	I
is	O
very	O
low	O
thus	O
when	O
capacity	O
is	O
high	O
and	O
the	O
test	O
error	O
is	O
primarily	O
driven	O
by	O
the	O
gap	O
between	O
train	O
and	O
test	O
error	O
your	O
goal	O
is	O
to	O
reduce	O
this	O
gap	O
without	O
increasing	O
training	B
error	I
faster	O
than	O
the	O
gap	O
decreases	O
to	O
reduce	O
the	O
gap	O
change	O
regularization	O
hyperparameters	O
to	O
reduce	O
effective	O
model	O
capacity	O
such	O
as	O
by	O
adding	O
dropout	O
or	O
weight	O
decay	O
usually	O
the	O
best	O
performance	O
comes	O
from	O
a	O
large	O
model	O
that	O
is	O
regularized	O
well	O
for	O
example	B
by	O
using	O
dropout	O
most	O
hyperparameters	O
can	O
be	O
set	O
by	O
reasoning	O
about	O
whether	O
they	O
increase	O
or	O
decrease	O
model	O
capacity	O
some	O
examples	O
are	O
included	O
in	O
table	O
while	O
manually	O
tuning	O
hyperparameters	O
do	O
not	O
lose	O
sight	O
of	O
your	O
end	O
goal	O
good	O
performance	O
on	O
the	O
test	B
set	I
adding	O
regularization	O
is	O
only	O
one	O
way	O
to	O
achieve	O
this	O
goal	O
as	O
long	O
as	O
you	O
have	O
low	O
training	B
error	I
you	O
can	O
always	O
reduce	O
generalization	B
error	O
by	O
collecting	O
more	O
training	O
data	O
the	O
brute	O
force	O
way	O
to	O
practically	O
guarantee	O
success	O
is	O
to	O
continually	O
increase	O
model	O
capacity	O
and	O
training	O
set	O
size	O
until	O
the	O
task	O
is	O
solved	O
this	O
approach	O
does	O
of	O
course	O
increase	O
the	O
computational	O
cost	O
of	O
training	O
and	O
inference	O
so	O
it	O
is	O
only	O
feasible	O
given	O
appropriate	O
resources	O
in	O
chapter	O
practical	O
methodology	O
reason	O
caveats	O
hyperparameter	O
number	O
of	O
hidden	O
units	O
increases	O
capacity	O
when	O
increased	O
learning	B
rate	I
tuned	O
optimally	O
convolution	O
kernel	O
width	O
increased	O
increasing	O
the	O
number	O
of	O
hidden	O
units	O
increases	O
the	O
representational	B
capacity	I
of	O
the	O
model	O
an	O
improper	O
learning	B
rate	I
whether	O
too	O
high	O
or	O
too	O
low	O
results	O
in	O
a	O
model	O
with	O
low	O
effective	B
capacity	I
due	O
to	O
optimization	O
failure	O
increasing	O
the	O
kernel	O
width	O
increases	O
the	O
number	O
of	O
parameters	O
in	O
the	O
model	O
increasing	O
the	O
number	O
of	O
hidden	O
units	O
increases	O
both	O
the	O
time	O
and	O
memory	O
cost	O
of	O
essentially	O
every	O
operation	B
on	O
the	O
model	O
a	O
wider	O
kernel	O
results	O
in	O
a	O
narrower	O
output	O
dimension	O
reducing	O
model	O
capacity	O
unless	O
you	O
use	O
implicit	O
zero	O
padding	O
to	O
reduce	O
this	O
effect	O
wider	O
kernels	O
require	O
more	O
memory	O
for	O
parameter	O
storage	O
and	O
increase	O
runtime	O
but	O
a	O
narrower	O
output	O
reduces	O
memory	O
cost	O
increased	O
time	O
and	O
memory	O
cost	O
of	O
most	O
operations	O
implicit	O
padding	O
zero	O
weight	O
decay	O
coefficient	O
dropout	O
rate	O
increased	O
adding	O
implicit	O
zeros	O
before	O
convolution	O
keeps	O
the	O
representation	O
size	O
large	O
decreased	O
decreasing	O
the	O
weight	O
decay	O
coefficient	O
frees	O
the	O
model	O
parameters	O
to	O
become	O
larger	O
decreased	O
dropping	O
units	O
less	O
often	O
gives	O
the	O
units	O
more	O
opportunities	O
to	O
conspire	O
with	O
each	O
other	O
to	O
fit	O
the	O
training	O
set	O
table	O
the	O
effect	O
of	O
various	O
hyperparameters	O
on	O
model	O
capacity	O
chapter	O
practical	O
methodology	O
principle	O
this	O
approach	O
could	O
fail	O
due	O
to	O
optimization	O
difficulties	O
but	O
for	O
many	O
problems	O
optimization	O
does	O
not	O
seem	O
to	O
be	O
a	O
significant	O
barrier	O
provided	O
that	O
the	O
model	O
is	O
chosen	O
appropriately	O
automatic	O
hyperparameter	B
optimization	I
algorithms	O
the	O
ideal	O
learning	O
algorithm	O
just	O
takes	O
a	O
dataset	B
and	O
outputs	O
a	O
function	O
without	O
requiring	O
hand-tuning	O
of	O
hyperparameters	O
the	O
popularity	O
of	O
several	O
learning	O
algorithms	O
such	O
as	O
logistic	O
regression	B
and	O
svms	O
stems	O
in	O
part	O
from	O
their	O
ability	O
to	O
perform	O
well	O
with	O
only	O
one	O
or	O
two	O
tuned	O
hyperparameters	O
neural	O
networks	O
can	O
sometimes	O
perform	O
well	O
with	O
only	O
a	O
small	O
number	O
of	O
tuned	O
hyperparameters	O
but	O
often	O
benefit	O
significantly	O
from	O
tuning	O
of	O
forty	O
or	O
more	O
hyperparameters	O
manual	O
hyperparameter	O
tuning	O
can	O
work	O
very	O
well	O
when	O
the	O
user	O
has	O
a	O
good	O
starting	O
point	O
such	O
as	O
one	O
determined	O
by	O
others	O
having	O
worked	O
on	O
the	O
same	O
type	O
of	O
application	O
and	O
architecture	O
or	O
when	O
the	O
user	O
has	O
months	O
or	O
years	O
of	O
experience	O
in	O
exploring	O
hyperparameter	O
values	O
for	O
neural	O
networks	O
applied	O
to	O
similar	O
tasks	O
however	O
for	O
many	O
applications	O
these	O
starting	O
points	O
are	O
not	O
available	O
in	O
these	O
cases	O
automated	O
algorithms	O
can	O
find	O
useful	O
values	O
of	O
the	O
hyperparameters	O
if	O
we	O
think	O
about	O
the	O
way	O
in	O
which	O
the	O
user	O
of	O
a	O
learning	O
algorithm	O
searches	O
for	O
good	O
values	O
of	O
the	O
hyperparameters	O
we	O
realize	O
that	O
an	O
optimization	O
is	O
taking	O
place	O
we	O
are	O
trying	O
to	O
find	O
a	O
value	O
of	O
the	O
hyperparameters	O
that	O
optimizes	O
an	O
objective	B
function	I
such	O
as	O
validation	O
error	O
sometimes	O
under	O
constraints	O
as	O
a	O
budget	O
for	O
training	O
time	O
memory	O
or	O
recognition	O
time	O
it	O
is	O
therefore	O
possible	O
in	O
principle	O
to	O
develop	O
hyperparameter	B
optimization	I
algorithms	O
that	O
wrap	O
a	O
learning	O
algorithm	O
and	O
choose	O
its	O
hyperparameters	O
thus	O
hiding	O
the	O
hyperparameters	O
of	O
the	O
learning	O
algorithm	O
from	O
the	O
user	O
unfortunately	O
hyperparameter	B
optimization	I
algorithms	O
often	O
have	O
their	O
own	O
hyperparameters	O
such	O
as	O
the	O
range	O
of	O
values	O
that	O
should	O
be	O
explored	O
for	O
each	O
of	O
the	O
learning	O
algorithm	O
s	O
hyperparameters	O
however	O
these	O
secondary	O
hyperparameters	O
are	O
usually	O
easier	O
to	O
choose	O
in	O
the	O
sense	O
that	O
acceptable	O
performance	O
may	O
be	O
achieved	O
on	O
a	O
wide	O
range	O
of	O
tasks	O
using	O
the	O
same	O
secondary	O
hyperparameters	O
for	O
all	O
tasks	O
grid	B
search	I
when	O
there	O
are	O
three	O
or	O
fewer	O
hyperparameters	O
the	O
common	O
practice	O
is	O
to	O
perform	O
grid	B
search	I
for	O
each	O
hyperparameter	O
the	O
user	O
selects	O
a	O
small	O
finite	O
set	O
of	O
values	O
to	O
explore	O
the	O
grid	B
search	I
algorithm	O
then	O
trains	O
a	O
model	O
for	O
every	O
joint	O
specification	O
of	O
hyperparameter	O
values	O
in	O
the	O
cartesian	O
product	O
of	O
the	O
set	O
of	O
values	O
for	O
each	O
individual	O
hyperparameter	O
the	O
experiment	O
that	O
yields	O
the	O
best	O
validation	O
chapter	O
practical	O
methodology	O
grid	O
random	O
figure	O
comparison	O
of	O
grid	B
search	I
and	O
random	B
search	I
for	O
illustration	O
purposes	O
we	O
display	O
two	O
hyperparameters	O
but	O
we	O
are	O
typically	O
interested	O
in	O
having	O
many	O
more	O
perform	O
grid	B
search	I
we	O
provide	O
a	O
set	O
of	O
values	O
for	O
each	O
hyperparameter	O
the	O
search	O
algorithm	O
runs	O
training	O
for	O
every	O
joint	O
hyperparameter	O
setting	O
in	O
the	O
cross	O
product	O
of	O
these	O
sets	O
to	O
perform	O
random	B
search	I
we	O
provide	O
a	O
probability	B
distribution	I
over	O
joint	O
hyperparameter	O
configurations	O
usually	O
most	O
of	O
these	O
hyperparameters	O
are	O
independent	O
from	O
each	O
other	O
common	O
choices	O
for	O
the	O
distribution	O
over	O
a	O
single	O
hyperparameter	O
include	O
uniform	O
and	O
log-uniform	O
sample	O
from	O
a	O
log-uniform	O
distribution	O
take	O
the	O
exp	O
of	O
a	O
sample	O
from	O
a	O
uniform	B
distribution	I
the	O
search	O
algorithm	O
then	O
randomly	O
samples	O
joint	O
hyperparameter	O
configurations	O
and	O
runs	O
training	O
with	O
each	O
of	O
them	O
both	O
grid	B
search	I
and	O
random	B
search	I
evaluate	O
the	O
validation	O
set	O
error	O
and	O
return	O
the	O
best	O
configuration	O
the	O
figure	O
illustrates	O
the	O
typical	O
case	O
where	O
only	O
some	O
hyperparameters	O
have	O
a	O
significant	O
influence	O
on	O
the	O
result	O
in	O
this	O
illustration	O
only	O
the	O
hyperparameter	O
on	O
the	O
horizontal	O
axis	O
has	O
a	O
significant	O
effect	O
grid	B
search	I
wastes	O
an	O
amount	O
of	O
computation	O
that	O
is	O
exponential	O
in	O
the	O
number	O
of	O
non-influential	O
hyperparameters	O
while	O
random	B
search	I
tests	O
a	O
unique	O
value	O
of	O
every	O
influential	O
hyperparameter	O
on	O
nearly	O
every	O
trial	O
figure	O
reproduced	O
with	O
permission	O
from	O
bergstra	O
and	O
bengio	O
chapter	O
practical	O
methodology	O
set	O
error	O
is	O
then	O
chosen	O
as	O
having	O
found	O
the	O
best	O
hyperparameters	O
see	O
the	O
left	O
of	O
figure	O
for	O
an	O
illustration	O
of	O
a	O
grid	O
of	O
hyperparameter	O
values	O
how	O
should	O
the	O
lists	O
of	O
values	O
to	O
search	O
over	O
be	O
chosen	O
in	O
the	O
case	O
of	O
numerical	O
hyperparameters	O
the	O
smallest	O
and	O
largest	O
element	O
of	O
each	O
list	O
is	O
chosen	O
conservatively	O
based	O
on	O
prior	O
experience	O
with	O
similar	O
experiments	O
to	O
make	O
sure	O
that	O
the	O
optimal	O
value	O
is	O
very	O
likely	O
to	O
be	O
in	O
the	O
selected	O
range	O
typically	O
a	O
grid	B
search	I
involves	O
picking	O
values	O
approximately	O
on	O
a	O
logarithmic	O
scale	O
e	O
g	O
a	O
learning	B
rate	I
taken	O
within	O
the	O
set	O
or	O
a	O
number	O
of	O
hidden	O
units	O
taken	O
with	O
the	O
set	O
grid	B
search	I
usually	O
performs	O
best	O
when	O
it	O
is	O
performed	O
repeatedly	O
for	O
example	B
suppose	O
that	O
we	O
ran	O
a	O
grid	B
search	I
over	O
a	O
hyperparameter	O
using	O
values	O
of	O
if	O
the	O
best	O
value	O
found	O
is	O
lies	O
and	O
we	O
should	O
shift	O
the	O
grid	O
and	O
run	O
another	O
search	O
with	O
in	O
for	O
example	B
then	O
we	O
may	O
wish	O
to	O
refine	O
our	O
then	O
we	O
underestimated	O
the	O
range	O
in	O
which	O
the	O
best	O
if	O
we	O
find	O
that	O
the	O
best	O
value	O
of	O
is	O
estimate	O
by	O
zooming	O
in	O
and	O
running	O
a	O
grid	B
search	I
over	O
the	O
obvious	O
problem	O
with	O
grid	B
search	I
is	O
that	O
its	O
computational	O
cost	O
grows	O
exponentially	O
with	O
the	O
number	O
of	O
hyperparameters	O
if	O
there	O
are	O
m	O
hyperparameters	O
each	O
taking	O
at	O
most	O
n	O
values	O
then	O
the	O
number	O
of	O
training	O
and	O
evaluation	O
trials	O
required	O
grows	O
as	O
onm	O
the	O
trials	O
may	O
be	O
run	O
in	O
parallel	O
and	O
exploit	O
loose	O
parallelism	O
almost	O
no	O
need	O
for	O
communication	O
between	O
different	O
machines	O
carrying	O
out	O
the	O
search	O
unfortunately	O
due	O
to	O
the	O
exponential	O
cost	O
of	O
grid	B
search	I
even	O
parallelization	O
may	O
not	O
provide	O
a	O
satisfactory	O
size	O
of	O
search	O
random	B
search	I
fortunately	O
there	O
is	O
an	O
alternative	O
to	O
grid	B
search	I
that	O
is	O
as	O
simple	O
to	O
program	O
more	O
convenient	O
to	O
use	O
and	O
converges	O
much	O
faster	O
to	O
good	O
values	O
of	O
the	O
hyperparameters	O
random	B
search	I
bergstra	O
and	O
bengio	O
a	O
random	B
search	I
proceeds	O
as	O
follows	O
first	O
we	O
define	O
a	O
marginal	O
distribution	O
for	O
each	O
hyperparameter	O
e	O
g	O
a	O
bernoulli	O
or	O
multinoulli	O
for	O
binary	O
or	O
discrete	O
hyperparameters	O
or	O
a	O
uniform	B
distribution	I
on	O
a	O
log-scale	O
for	O
positive	O
real-valued	O
hyperparameters	O
for	O
example	B
log	O
learning	B
rate	I
u	O
learning	B
rate	I
learning	B
rate	I
where	O
ua	O
b	O
indicates	O
a	O
sample	O
of	O
the	O
uniform	B
distribution	I
in	O
the	O
interval	O
b	O
may	O
be	O
sampled	O
from	O
similarly	O
the	O
log	O
number	O
of	O
hidden	O
units	O
chapter	O
practical	O
methodology	O
unlike	O
in	O
the	O
case	O
of	O
a	O
grid	B
search	I
one	O
should	O
not	O
discretize	O
or	O
bin	O
the	O
values	O
of	O
the	O
hyperparameters	O
this	O
allows	O
one	O
to	O
explore	O
a	O
larger	O
set	O
of	O
values	O
and	O
does	O
not	O
incur	O
additional	O
computational	O
cost	O
in	O
fact	O
as	O
illustrated	O
in	O
figure	O
a	O
random	B
search	I
can	O
be	O
exponentially	O
more	O
efficient	O
than	O
a	O
grid	B
search	I
when	O
there	O
are	O
several	O
hyperparameters	O
that	O
do	O
not	O
strongly	O
affect	O
the	O
performance	O
measure	O
this	O
is	O
studied	O
at	O
length	O
in	O
who	O
found	O
that	O
random	B
search	I
reduces	O
the	O
validation	O
set	O
error	O
much	O
faster	O
than	O
grid	B
search	I
in	O
terms	O
of	O
the	O
number	O
of	O
trials	O
run	O
by	O
each	O
method	O
bergstra	O
and	O
bengio	O
as	O
with	O
grid	B
search	I
one	O
may	O
often	O
want	O
to	O
run	O
repeated	O
versions	O
of	O
random	B
search	I
to	O
refine	O
the	O
search	O
based	O
on	O
the	O
results	O
of	O
the	O
first	O
run	O
the	O
main	O
reason	O
why	O
random	B
search	I
finds	O
good	O
solutions	O
faster	O
than	O
grid	B
search	I
is	O
that	O
there	O
are	O
no	O
wasted	O
experimental	O
runs	O
unlike	O
in	O
the	O
case	O
of	O
grid	B
search	I
when	O
two	O
values	O
of	O
a	O
hyperparameter	O
values	O
of	O
the	O
other	O
hyperparameters	O
would	O
give	O
the	O
same	O
result	O
in	O
the	O
case	O
of	O
grid	B
search	I
the	O
other	O
hyperparameters	O
would	O
have	O
the	O
same	O
values	O
for	O
these	O
two	O
runs	O
whereas	O
with	O
random	B
search	I
they	O
would	O
usually	O
have	O
different	O
values	O
hence	O
if	O
the	O
change	O
between	O
these	O
two	O
values	O
does	O
not	O
marginally	O
make	O
much	O
difference	O
in	O
terms	O
of	O
validation	O
set	O
error	O
grid	B
search	I
will	O
unnecessarily	O
repeat	O
two	O
equivalent	O
experiments	O
while	O
random	B
search	I
will	O
still	O
give	O
two	O
independent	O
explorations	O
of	O
the	O
other	O
hyperparameters	O
model-based	O
hyperparameter	B
optimization	I
the	O
search	O
for	O
good	O
hyperparameters	O
can	O
be	O
cast	O
as	O
an	O
optimization	O
problem	O
the	O
decision	O
variables	O
are	O
the	O
hyperparameters	O
the	O
cost	O
to	O
be	O
optimized	O
is	O
the	O
validation	O
set	O
error	O
that	O
results	O
from	O
training	O
using	O
these	O
hyperparameters	O
in	O
simplified	O
settings	O
where	O
it	O
is	O
feasible	O
to	O
compute	O
the	O
gradient	B
of	O
some	O
differentiable	O
error	O
measure	O
on	O
the	O
validation	O
set	O
with	O
respect	O
to	O
the	O
hyperparameters	O
we	O
can	O
simply	O
follow	O
this	O
gradient	B
bengio	O
et	O
al	O
bengio	O
maclaurin	O
et	O
al	O
unfortunately	O
in	O
most	O
practical	O
settings	O
this	O
gradient	B
is	O
unavailable	O
either	O
due	O
to	O
its	O
high	O
computation	O
and	O
memory	O
cost	O
or	O
due	O
to	O
hyperparameters	O
having	O
intrinsically	O
non-differentiable	O
interactions	O
with	O
the	O
validation	O
set	O
error	O
as	O
in	O
the	O
case	O
of	O
discrete-valued	O
hyperparameters	O
to	O
compensate	O
for	O
this	O
lack	O
of	O
a	O
gradient	B
we	O
can	O
build	O
a	O
model	O
of	O
the	O
validation	O
set	O
error	O
then	O
propose	O
new	O
hyperparameter	O
guesses	O
by	O
performing	O
optimization	O
within	O
this	O
model	O
most	O
model-based	O
algorithms	O
for	O
hyperparameter	O
search	O
use	O
a	O
bayesian	O
regression	B
model	O
to	O
estimate	O
both	O
the	O
expected	O
value	O
of	O
the	O
validation	O
set	O
error	O
for	O
each	O
hyperparameter	O
and	O
the	O
uncertainty	O
around	O
this	O
expectation	B
optimization	O
thus	O
involves	O
a	O
tradeoff	O
between	O
exploration	B
hyperparameters	O
chapter	O
practical	O
methodology	O
for	O
which	O
there	O
is	O
high	O
uncertainty	O
which	O
may	O
lead	O
to	O
a	O
large	O
improvement	O
but	O
may	O
also	O
perform	O
poorly	O
and	O
exploitation	B
hyperparameters	O
which	O
the	O
model	O
is	O
confident	O
will	O
perform	O
as	O
well	O
as	O
any	O
hyperparameters	O
it	O
has	O
seen	O
so	O
far	O
usually	O
hyperparameters	O
that	O
are	O
very	O
similar	O
to	O
ones	O
it	O
has	O
seen	O
before	O
contemporary	O
approaches	O
to	O
hyperparameter	B
optimization	I
include	O
spearmint	B
tpe	O
bergstra	O
et	O
al	O
snoek	O
et	O
al	O
and	O
smac	O
hutter	O
et	O
al	O
currently	O
we	O
cannot	O
unambiguously	O
recommend	O
bayesian	B
hyperparameter	B
optimization	I
as	O
an	O
established	O
tool	O
for	O
achieving	O
better	O
deep	O
learning	O
results	O
or	O
for	O
obtaining	O
those	O
results	O
with	O
less	O
effort	O
bayesian	B
hyperparameter	B
optimization	I
sometimes	O
performs	O
comparably	O
to	O
human	O
experts	O
sometimes	O
better	O
but	O
fails	O
catastrophically	O
on	O
other	O
problems	O
it	O
may	O
be	O
worth	O
trying	O
to	O
see	O
if	O
it	O
works	O
on	O
a	O
particular	O
problem	O
but	O
is	O
not	O
yet	O
sufficiently	O
mature	O
or	O
reliable	O
that	O
being	O
said	O
hyperparameter	B
optimization	I
is	O
an	O
important	O
field	O
of	O
research	O
that	O
while	O
often	O
driven	O
primarily	O
by	O
the	O
needs	O
of	O
deep	O
learning	O
holds	O
the	O
potential	O
to	O
benefit	O
not	O
only	O
the	O
entire	O
field	O
of	O
machine	B
learning	I
but	O
the	O
discipline	O
of	O
engineering	O
in	O
general	O
one	O
drawback	O
common	O
to	O
most	O
hyperparameter	B
optimization	I
algorithms	O
with	O
more	O
sophistication	O
than	O
random	B
search	I
is	O
that	O
they	O
require	O
for	O
a	O
training	O
experiment	O
to	O
run	O
to	O
completion	O
before	O
they	O
are	O
able	O
to	O
extract	O
any	O
information	O
from	O
the	O
experiment	O
this	O
is	O
much	O
less	O
efficient	O
in	O
the	O
sense	O
of	O
how	O
much	O
information	O
can	O
be	O
gleaned	O
early	O
in	O
an	O
experiment	O
than	O
manual	O
search	O
by	O
a	O
human	O
practitioner	O
since	O
one	O
can	O
usually	O
tell	O
early	O
on	O
if	O
some	O
set	O
of	O
hyperparameters	O
is	O
completely	O
pathological	O
have	O
introduced	O
an	O
early	O
version	O
of	O
an	O
algorithm	O
that	O
maintains	O
a	O
set	O
of	O
multiple	O
experiments	O
at	O
various	O
time	O
points	O
the	O
hyperparameter	B
optimization	I
algorithm	O
can	O
choose	O
to	O
begin	O
a	O
new	O
experiment	O
to	O
freeze	O
a	O
running	O
experiment	O
that	O
is	O
not	O
promising	O
or	O
to	O
thaw	O
and	O
resume	O
an	O
experiment	O
that	O
was	O
earlier	O
frozen	O
but	O
now	O
appears	O
promising	O
given	O
more	O
information	O
swersky	O
et	O
al	O
debugging	O
strategies	O
when	O
a	O
machine	B
learning	I
system	O
performs	O
poorly	O
it	O
is	O
usually	O
difficult	O
to	O
tell	O
whether	O
the	O
poor	O
performance	O
is	O
intrinsic	O
to	O
the	O
algorithm	O
itself	O
or	O
whether	O
there	O
is	O
a	O
bug	O
in	O
the	O
implementation	O
of	O
the	O
algorithm	O
machine	B
learning	I
systems	O
are	O
difficult	O
to	O
debug	O
for	O
a	O
variety	O
of	O
reasons	O
in	O
most	O
cases	O
we	O
do	O
not	O
know	O
a	O
priori	O
what	O
the	O
intended	O
behavior	O
of	O
the	O
algorithm	O
is	O
in	O
fact	O
the	O
entire	O
point	O
of	O
using	O
machine	B
learning	I
is	O
that	O
it	O
will	O
discover	O
useful	O
behavior	O
that	O
we	O
were	O
not	O
able	O
to	O
specify	O
ourselves	O
if	O
we	O
train	O
a	O
chapter	O
practical	O
methodology	O
classification	B
task	O
and	O
it	O
achieves	O
test	O
error	O
we	O
have	O
neural	B
network	I
on	O
a	O
no	O
straightforward	O
way	O
of	O
knowing	O
if	O
this	O
is	O
the	O
expected	O
behavior	O
or	O
sub-optimal	O
behavior	O
new	O
a	O
further	O
difficulty	O
is	O
that	O
most	O
machine	B
learning	I
models	O
have	O
multiple	O
parts	O
that	O
are	O
each	O
adaptive	O
if	O
one	O
part	O
is	O
broken	O
the	O
other	O
parts	O
can	O
adapt	O
and	O
still	O
achieve	O
roughly	O
acceptable	O
performance	O
for	O
example	B
suppose	O
that	O
we	O
are	O
training	O
a	O
neural	O
net	O
with	O
several	O
layers	O
parametrized	O
by	O
weights	B
w	O
and	O
biases	O
b	O
suppose	O
further	O
that	O
we	O
have	O
manually	O
implemented	O
the	O
gradient	B
descent	O
rule	O
for	O
each	O
parameter	O
separately	O
and	O
we	O
made	O
an	O
error	O
in	O
the	O
update	O
for	O
the	O
biases	O
b	O
b	O
where	O
is	O
the	O
learning	B
rate	I
this	O
erroneous	O
update	O
does	O
not	O
use	O
the	O
gradient	B
at	O
all	O
it	O
causes	O
the	O
biases	O
to	O
constantly	O
become	O
negative	O
throughout	O
learning	O
which	O
is	O
clearly	O
not	O
a	O
correct	O
implementation	O
of	O
any	O
reasonable	O
learning	O
algorithm	O
the	O
bug	O
may	O
not	O
be	O
apparent	O
just	O
from	O
examining	O
the	O
output	O
of	O
the	O
model	O
though	O
depending	O
on	O
the	O
distribution	O
of	O
the	O
input	O
the	O
weights	B
may	O
be	O
able	O
to	O
adapt	O
to	O
compensate	O
for	O
the	O
negative	O
biases	O
most	O
debugging	O
strategies	O
for	O
neural	O
nets	O
are	O
designed	O
to	O
get	O
around	O
one	O
or	O
both	O
of	O
these	O
two	O
difficulties	O
either	O
we	O
design	O
a	O
case	O
that	O
is	O
so	O
simple	O
that	O
the	O
correct	O
behavior	O
actually	O
can	O
be	O
predicted	O
or	O
we	O
design	O
a	O
test	O
that	O
exercises	O
one	O
part	O
of	O
the	O
neural	O
net	O
implementation	O
in	O
isolation	O
some	O
important	O
debugging	O
tests	O
include	O
visualize	O
the	O
model	O
in	O
action	O
when	O
training	O
a	O
model	O
to	O
detect	O
objects	O
in	O
images	O
view	O
some	O
images	O
with	O
the	O
detections	O
proposed	O
by	O
the	O
model	O
displayed	O
superimposed	O
on	O
the	O
image	O
when	O
training	O
a	O
generative	O
model	O
of	O
speech	O
listen	O
to	O
some	O
of	O
the	O
speech	O
samples	O
it	O
produces	O
this	O
may	O
seem	O
obvious	O
but	O
it	O
is	O
easy	O
to	O
fall	O
into	O
the	O
practice	O
of	O
only	O
looking	O
at	O
quantitative	O
performance	O
measurements	O
like	O
accuracy	B
or	O
log-likelihood	O
directly	O
observing	O
the	O
machine	B
learning	I
model	O
performing	O
its	O
task	O
will	O
help	O
to	O
determine	O
whether	O
the	O
quantitative	O
performance	O
numbers	O
it	O
achieves	O
seem	O
reasonable	O
evaluation	O
bugs	O
can	O
be	O
some	O
of	O
the	O
most	O
devastating	O
bugs	O
because	O
they	O
can	O
mislead	O
you	O
into	O
believing	O
your	O
system	O
is	O
performing	O
well	O
when	O
it	O
is	O
not	O
visualize	O
the	O
worst	O
mistakes	O
most	O
models	O
are	O
able	O
to	O
output	O
some	O
sort	O
of	O
confidence	O
measure	O
for	O
the	O
task	O
they	O
perform	O
for	O
example	B
classifiers	O
based	O
on	O
a	O
softmax	O
output	O
layer	O
assign	O
a	O
probability	O
to	O
each	O
class	O
the	O
probability	O
assigned	O
to	O
the	O
most	O
likely	O
class	O
thus	O
gives	O
an	O
estimate	O
of	O
the	O
confidence	O
the	O
model	O
has	O
in	O
its	O
classification	B
decision	O
typically	O
maximum	B
likelihood	I
training	O
results	O
in	O
these	O
values	O
being	O
overestimates	O
rather	O
than	O
accurate	O
probabilities	O
of	O
correct	O
prediction	O
chapter	O
practical	O
methodology	O
but	O
they	O
are	O
somewhat	O
useful	O
in	O
the	O
sense	O
that	O
examples	O
that	O
are	O
actually	O
less	O
likely	O
to	O
be	O
correctly	O
labeled	O
receive	O
smaller	O
probabilities	O
under	O
the	O
model	O
by	O
viewing	O
the	O
training	O
set	O
examples	O
that	O
are	O
the	O
hardest	O
to	O
model	O
correctly	O
one	O
can	O
often	O
discover	O
problems	O
with	O
the	O
way	O
the	O
data	O
has	O
been	O
preprocessed	O
or	O
labeled	O
for	O
example	B
the	O
street	O
view	O
transcription	B
system	O
originally	O
had	O
a	O
problem	O
where	O
the	O
address	O
number	O
detection	O
system	O
would	O
crop	O
the	O
image	O
too	O
tightly	O
and	O
omit	O
some	O
of	O
the	O
digits	O
the	O
transcription	B
network	O
then	O
assigned	O
very	O
low	O
probability	O
to	O
the	O
correct	O
answer	O
on	O
these	O
images	O
sorting	O
the	O
images	O
to	O
identify	O
the	O
most	O
confident	O
mistakes	O
showed	O
that	O
there	O
was	O
a	O
systematic	O
problem	O
with	O
the	O
cropping	O
modifying	O
the	O
detection	O
system	O
to	O
crop	O
much	O
wider	O
images	O
resulted	O
in	O
much	O
better	O
performance	O
of	O
the	O
overall	O
system	O
even	O
though	O
the	O
transcription	B
network	O
needed	O
to	O
be	O
able	O
to	O
process	O
greater	O
variation	O
in	O
the	O
position	O
and	O
scale	O
of	O
the	O
address	O
numbers	O
reasoning	O
about	O
software	O
using	O
train	O
and	O
test	O
error	O
it	O
is	O
often	O
difficult	O
to	O
determine	O
whether	O
the	O
underlying	O
software	O
is	O
correctly	O
implemented	O
some	O
clues	O
can	O
be	O
obtained	O
from	O
the	O
train	O
and	O
test	O
error	O
if	O
training	B
error	I
is	O
low	O
but	O
test	O
error	O
is	O
high	O
then	O
it	O
is	O
likely	O
that	O
that	O
the	O
training	O
procedure	O
works	O
correctly	O
and	O
the	O
model	O
is	O
overfitting	O
for	O
fundamental	O
algorithmic	O
reasons	O
an	O
alternative	O
possibility	O
is	O
that	O
the	O
test	O
error	O
is	O
measured	O
incorrectly	O
due	O
to	O
a	O
problem	O
with	O
saving	O
the	O
model	O
after	O
training	O
then	O
reloading	O
it	O
for	O
test	B
set	I
evaluation	O
or	O
if	O
the	O
test	O
data	O
was	O
prepared	O
differently	O
from	O
the	O
training	O
data	O
if	O
both	O
train	O
and	O
test	O
error	O
are	O
high	O
then	O
it	O
is	O
difficult	O
to	O
determine	O
whether	O
there	O
is	O
a	O
software	O
defect	O
or	O
whether	O
the	O
model	O
is	O
underfitting	O
due	O
to	O
fundamental	O
algorithmic	O
reasons	O
this	O
scenario	O
requires	O
further	O
tests	O
described	O
next	O
fit	O
a	O
tiny	O
dataset	B
if	O
you	O
have	O
high	O
error	O
on	O
the	O
training	O
set	O
determine	O
whether	O
it	O
is	O
due	O
to	O
genuine	O
underfitting	O
or	O
due	O
to	O
a	O
software	O
defect	O
usually	O
even	O
small	O
models	O
can	O
be	O
guaranteed	O
to	O
be	O
able	O
fit	O
a	O
sufficiently	O
small	O
dataset	B
for	O
example	B
a	O
classification	B
dataset	B
with	O
only	O
one	O
example	B
can	O
be	O
fit	O
just	O
by	O
setting	O
the	O
biases	O
of	O
the	O
output	O
layer	O
correctly	O
usually	O
if	O
you	O
cannot	O
train	O
a	O
classifier	O
to	O
correctly	O
label	O
a	O
single	O
example	B
an	O
autoencoder	O
to	O
successfully	O
reproduce	O
a	O
single	O
example	B
with	O
high	O
fidelity	O
or	O
a	O
generative	O
model	O
to	O
consistently	O
emit	O
samples	O
resembling	O
a	O
single	O
example	B
there	O
is	O
a	O
software	O
defect	O
preventing	O
successful	O
optimization	O
on	O
the	O
training	O
set	O
this	O
test	O
can	O
be	O
extended	O
to	O
a	O
small	O
dataset	B
with	O
few	O
examples	O
compare	O
back-propagated	O
derivatives	O
to	O
numerical	O
derivatives	O
if	O
you	O
are	O
using	O
a	O
software	O
framework	O
that	O
requires	O
you	O
to	O
implement	O
your	O
own	O
gradient	B
computations	O
or	O
if	O
you	O
are	O
adding	O
a	O
new	O
operation	B
to	O
a	O
differentiation	O
library	O
and	O
must	O
define	O
its	O
bprop	O
method	O
then	O
a	O
common	O
source	O
of	O
error	O
is	O
implementing	O
this	O
gradient	B
expression	O
incorrectly	O
one	O
way	O
to	O
verify	O
that	O
these	O
derivatives	O
are	O
correct	O
chapter	O
practical	O
methodology	O
is	O
to	O
compare	O
the	O
derivatives	O
computed	O
by	O
your	O
implementation	O
of	O
automatic	O
differentiation	O
to	O
the	O
derivatives	O
computed	O
by	O
a	O
finite	B
differences	I
because	O
f	O
lim	O
x	O
f	O
x	O
f	O
x	O
we	O
can	O
approximate	O
the	O
derivative	B
by	O
using	O
a	O
small	O
finite	O
f	O
x	O
f	O
x	O
f	O
x	O
we	O
can	O
improve	O
the	O
accuracy	B
of	O
the	O
approximation	O
by	O
using	O
the	O
centered	O
difference	O
f	O
x	O
f	O
x	O
f	O
x	O
the	O
perturbation	O
size	O
must	O
chosen	O
to	O
be	O
large	O
enough	O
to	O
ensure	O
that	O
the	O
perturbation	O
is	O
not	O
rounded	O
down	O
too	O
much	O
by	O
finite-precision	O
numerical	O
computations	O
m	O
r	O
usually	O
we	O
will	O
want	O
to	O
test	O
the	O
gradient	B
or	O
jacobian	O
of	O
a	O
vector-valued	O
function	O
n	O
unfortunately	O
finite	O
differencing	O
only	O
allows	O
us	O
to	O
take	O
a	O
single	O
g	O
r	O
derivative	B
at	O
a	O
time	O
we	O
can	O
either	O
run	O
finite	O
differencing	O
mn	O
times	O
to	O
evaluate	O
all	O
of	O
the	O
partial	O
derivatives	O
of	O
g	O
or	O
we	O
can	O
apply	O
the	O
test	O
to	O
a	O
new	O
function	O
that	O
uses	O
random	O
projections	O
at	O
both	O
the	O
input	O
and	O
output	O
of	O
g	O
for	O
example	B
we	O
can	O
apply	O
our	O
test	O
of	O
the	O
implementation	O
of	O
the	O
derivatives	O
to	O
fx	O
where	O
f	O
ut	O
gvx	O
where	O
u	O
and	O
v	O
are	O
randomly	O
chosen	O
vectors	O
computing	O
f	O
correctly	O
requires	O
being	O
able	O
to	O
back-propagate	O
through	O
g	O
correctly	O
yet	O
is	O
efficient	O
to	O
do	O
with	O
finite	B
differences	I
because	O
f	O
has	O
only	O
a	O
single	O
input	O
and	O
a	O
single	O
output	O
it	O
is	O
usually	O
a	O
good	O
idea	O
to	O
repeat	O
this	O
test	O
for	O
more	O
than	O
one	O
value	O
of	O
u	O
and	O
v	O
to	O
reduce	O
the	O
chance	O
that	O
the	O
test	O
overlooks	O
mistakes	O
that	O
are	O
orthogonal	O
to	O
the	O
random	O
projection	O
if	O
one	O
has	O
access	O
to	O
numerical	O
computation	O
on	O
complex	O
numbers	O
then	O
there	O
is	O
a	O
very	O
efficient	O
way	O
to	O
numerically	O
estimate	O
the	O
gradient	B
by	O
using	O
complex	O
numbers	O
as	O
input	O
to	O
the	O
function	O
and	O
trapp	O
the	O
method	O
is	O
based	O
on	O
the	O
observation	O
that	O
f	O
x	O
f	O
x	O
i	O
i	O
f	O
x	O
o	O
real	O
f	O
x	O
f	O
x	O
i	O
o	O
f	O
x	O
o	O
imag	O
f	O
x	O
i	O
where	O
i	O
unlike	O
in	O
the	O
real-valued	O
case	O
above	O
there	O
is	O
no	O
cancellation	O
effect	O
due	O
to	O
taking	O
the	O
difference	O
between	O
the	O
value	O
of	O
f	O
at	O
different	O
points	O
this	O
allows	O
which	O
make	O
the	O
o	O
error	O
insignificant	O
the	O
use	O
of	O
tiny	O
values	O
of	O
like	O
for	O
all	O
practical	O
purposes	O
chapter	O
practical	O
methodology	O
monitor	O
histograms	O
of	O
activations	O
and	O
gradient	B
it	O
is	O
often	O
useful	O
to	O
visualize	O
statistics	O
of	O
neural	B
network	I
activations	O
and	O
gradients	O
collected	O
over	O
a	O
large	O
amount	O
of	O
training	O
iterations	O
one	O
epoch	B
the	O
pre-activation	O
value	O
of	O
hidden	O
units	O
can	O
tell	O
us	O
if	O
the	O
units	O
saturate	O
or	O
how	O
often	O
they	O
do	O
for	O
example	B
for	O
rectifiers	O
how	O
often	O
are	O
they	O
off	O
are	O
there	O
units	O
that	O
are	O
always	O
off	O
for	O
tanh	O
units	O
the	O
average	O
of	O
the	O
absolute	O
value	O
of	O
the	O
pre-activations	O
tells	O
us	O
how	O
saturated	O
the	O
unit	O
is	O
in	O
a	O
deep	O
network	O
where	O
the	O
propagated	O
gradients	O
quickly	O
grow	O
or	O
quickly	O
vanish	O
optimization	O
may	O
be	O
hampered	O
finally	O
it	O
is	O
useful	O
to	O
compare	O
the	O
magnitude	O
of	O
parameter	O
gradients	O
to	O
the	O
magnitude	O
of	O
the	O
parameters	O
themselves	O
as	O
suggested	O
by	O
we	O
would	O
like	O
the	O
magnitude	O
of	O
parameter	O
updates	O
over	O
a	O
minibatch	B
to	O
represent	O
something	O
like	O
of	O
the	O
magnitude	O
of	O
the	O
parameter	O
not	O
or	O
would	O
make	O
the	O
parameters	O
move	O
too	O
slowly	O
it	O
may	O
be	O
that	O
some	O
groups	O
of	O
parameters	O
are	O
moving	O
at	O
a	O
good	O
pace	O
while	O
others	O
are	O
stalled	O
when	O
the	O
data	O
is	O
sparse	O
in	O
natural	O
language	O
some	O
parameters	O
may	O
be	O
very	O
rarely	O
updated	O
and	O
this	O
should	O
be	O
kept	O
in	O
mind	O
when	O
monitoring	O
their	O
evolution	O
bottou	O
iii	O
finally	O
many	O
deep	O
learning	O
algorithms	O
provide	O
some	O
sort	O
of	O
guarantee	O
about	O
the	O
results	O
produced	O
at	O
each	O
step	O
for	O
example	B
in	O
part	O
we	O
will	O
see	O
some	O
approximate	B
inference	I
algorithms	O
that	O
work	O
by	O
using	O
algebraic	O
solutions	O
to	O
optimization	O
problems	O
typically	O
these	O
can	O
be	O
debugged	O
by	O
testing	O
each	O
of	O
their	O
guarantees	O
some	O
guarantees	O
that	O
some	O
optimization	O
algorithms	O
offer	O
include	O
that	O
the	O
objective	B
function	I
will	O
never	O
increase	O
after	O
one	O
step	O
of	O
the	O
algorithm	O
that	O
the	O
gradient	B
with	O
respect	O
to	O
some	O
subset	O
of	O
variables	O
will	O
be	O
zero	O
after	O
each	O
step	O
of	O
the	O
algorithm	O
and	O
that	O
the	O
gradient	B
with	O
respect	O
to	O
all	O
variables	O
will	O
be	O
zero	O
at	O
convergence	O
usually	O
due	O
to	O
rounding	O
error	O
these	O
conditions	O
will	O
not	O
hold	O
exactly	O
in	O
a	O
digital	O
computer	O
so	O
the	O
debugging	O
test	O
should	O
include	O
some	O
tolerance	O
parameter	O
example	B
multi-digit	O
number	O
recognition	O
to	O
provide	O
an	O
end-to-end	O
description	O
of	O
how	O
to	O
apply	O
our	O
design	O
methodology	O
in	O
practice	O
we	O
present	O
a	O
brief	O
account	O
of	O
the	O
street	O
view	O
transcription	B
system	O
from	O
the	O
point	O
of	O
view	O
of	O
designing	O
the	O
deep	O
learning	O
components	O
obviously	O
many	O
other	O
components	O
of	O
the	O
complete	O
system	O
such	O
as	O
the	O
street	O
view	O
cars	O
the	O
database	O
infrastructure	O
and	O
so	O
on	O
were	O
of	O
paramount	O
importance	O
from	O
the	O
point	O
of	O
view	O
of	O
the	O
machine	B
learning	I
task	O
the	O
process	O
began	O
with	O
data	O
collection	O
the	O
cars	O
collected	O
the	O
raw	O
data	O
and	O
human	O
operators	O
provided	O
labels	O
the	O
transcription	B
task	O
was	O
preceded	O
by	O
a	O
significant	O
amount	O
of	O
dataset	B
curation	O
including	O
using	O
other	O
machine	B
learning	I
techniques	O
to	O
detect	O
the	O
house	O
chapter	O
practical	O
methodology	O
numbers	O
prior	O
to	O
transcribing	O
them	O
the	O
transcription	B
project	O
began	O
with	O
a	O
choice	O
of	O
performance	O
metrics	O
and	O
desired	O
values	O
for	O
these	O
metrics	O
an	O
important	O
general	O
principle	O
is	O
to	O
tailor	O
the	O
choice	O
of	O
metric	O
to	O
the	O
business	O
goals	O
for	O
the	O
project	O
because	O
maps	O
are	O
only	O
useful	O
if	O
they	O
have	O
high	O
accuracy	B
it	O
was	O
important	O
to	O
set	O
a	O
high	O
accuracy	B
requirement	O
for	O
this	O
project	O
specifically	O
the	O
goal	O
was	O
to	O
obtain	O
human-level	O
accuracy	B
this	O
level	O
of	O
accuracy	B
may	O
not	O
always	O
be	O
feasible	O
to	O
obtain	O
in	O
order	O
to	O
reach	O
this	O
level	O
of	O
accuracy	B
the	O
street	O
view	O
transcription	B
system	O
sacrifices	O
coverage	B
coverage	B
thus	O
became	O
the	O
main	O
performance	O
metric	O
optimized	O
during	O
the	O
project	O
with	O
accuracy	B
held	O
at	O
as	O
the	O
convolutional	B
network	I
improved	O
it	O
became	O
possible	O
to	O
reduce	O
the	O
confidence	O
threshold	O
below	O
which	O
the	O
network	O
refuses	O
to	O
transcribe	O
the	O
input	O
eventually	O
exceeding	O
the	O
goal	O
of	O
coverage	B
after	O
choosing	O
quantitative	O
goals	O
the	O
next	O
step	O
in	O
our	O
recommended	O
methodology	O
is	O
to	O
rapidly	O
establish	O
a	O
sensible	O
baseline	O
system	O
for	O
vision	O
tasks	O
this	O
means	O
a	O
convolutional	B
network	I
with	O
rectified	O
linear	O
units	O
the	O
transcription	B
project	O
began	O
with	O
such	O
a	O
model	O
at	O
the	O
time	O
it	O
was	O
not	O
common	O
for	O
a	O
convolutional	B
network	I
to	O
output	O
a	O
sequence	O
of	O
predictions	O
in	O
order	O
to	O
begin	O
with	O
the	O
simplest	O
possible	O
baseline	O
the	O
first	O
implementation	O
of	O
the	O
output	O
layer	O
of	O
the	O
model	O
consisted	O
of	O
n	O
different	O
softmax	O
units	O
to	O
predict	O
a	O
sequence	O
of	O
n	O
characters	O
these	O
softmax	O
units	O
were	O
trained	O
exactly	O
the	O
same	O
as	O
if	O
the	O
task	O
were	O
classification	B
with	O
each	O
softmax	O
unit	O
trained	O
independently	O
our	O
recommended	O
methodology	O
is	O
to	O
iteratively	O
refine	O
the	O
baseline	O
and	O
test	O
whether	O
each	O
change	O
makes	O
an	O
improvement	O
the	O
first	O
change	O
to	O
the	O
street	O
view	O
transcription	B
system	O
was	O
motivated	O
by	O
a	O
theoretical	O
understanding	O
of	O
the	O
coverage	B
metric	O
and	O
the	O
structure	O
of	O
the	O
data	O
specifically	O
the	O
network	O
refuses	O
to	O
classify	O
an	O
input	O
x	O
whenever	O
the	O
probability	O
of	O
the	O
output	O
sequence	O
py	O
x	O
t	O
for	O
some	O
threshold	O
t	O
initially	O
the	O
definition	O
of	O
py	O
x	O
was	O
ad-hoc	O
based	O
on	O
simply	O
multiplying	O
all	O
of	O
the	O
softmax	O
outputs	O
together	O
this	O
motivated	O
the	O
development	O
of	O
a	O
specialized	O
output	O
layer	O
and	O
cost	O
function	O
that	O
actually	O
computed	O
a	O
principled	O
log-likelihood	O
this	O
approach	O
allowed	O
the	O
example	B
rejection	O
mechanism	O
to	O
function	O
much	O
more	O
effectively	O
at	O
this	O
point	O
coverage	B
was	O
still	O
below	O
yet	O
there	O
were	O
no	O
obvious	O
theoretical	O
problems	O
with	O
the	O
approach	O
our	O
methodology	O
therefore	O
suggests	O
to	O
instrument	O
the	O
train	O
and	O
test	B
set	I
performance	O
in	O
order	O
to	O
determine	O
whether	O
the	O
problem	O
is	O
underfitting	O
or	O
overfitting	O
in	O
this	O
case	O
train	O
and	O
test	B
set	I
error	O
were	O
nearly	O
identical	O
indeed	O
the	O
main	O
reason	O
this	O
project	O
proceeded	O
so	O
smoothly	O
was	O
the	O
availability	O
of	O
a	O
dataset	B
with	O
tens	O
of	O
millions	O
of	O
labeled	O
examples	O
because	O
train	O
and	O
test	B
set	I
error	O
were	O
so	O
similar	O
this	O
suggested	O
that	O
the	O
problem	O
was	O
either	O
due	O
chapter	O
practical	O
methodology	O
to	O
underfitting	O
or	O
due	O
to	O
a	O
problem	O
with	O
the	O
training	O
data	O
one	O
of	O
the	O
debugging	O
strategies	O
we	O
recommend	O
is	O
to	O
visualize	O
the	O
model	O
s	O
worst	O
errors	O
in	O
this	O
case	O
that	O
meant	O
visualizing	O
the	O
incorrect	O
training	O
set	O
transcriptions	O
that	O
the	O
model	O
gave	O
the	O
highest	O
confidence	O
these	O
proved	O
to	O
mostly	O
consist	O
of	O
examples	O
where	O
the	O
input	O
image	O
had	O
been	O
cropped	O
too	O
tightly	O
with	O
some	O
of	O
the	O
digits	O
of	O
the	O
address	O
being	O
removed	O
by	O
the	O
cropping	O
operation	B
for	O
example	B
a	O
photo	O
of	O
an	O
address	O
might	O
be	O
cropped	O
too	O
tightly	O
with	O
only	O
the	O
remaining	O
visible	O
this	O
problem	O
could	O
have	O
been	O
resolved	O
by	O
spending	O
weeks	O
improving	O
the	O
accuracy	B
of	O
the	O
address	O
number	O
detection	O
system	O
responsible	O
for	O
determining	O
the	O
cropping	O
regions	O
instead	O
the	O
team	O
took	O
a	O
much	O
more	O
practical	O
decision	O
to	O
simply	O
expand	O
the	O
width	O
of	O
the	O
crop	O
region	O
to	O
be	O
systematically	O
wider	O
than	O
the	O
address	O
number	O
detection	O
system	O
predicted	O
this	O
single	O
change	O
added	O
ten	O
percentage	O
points	O
to	O
the	O
transcription	B
system	O
s	O
coverage	B
finally	O
the	O
last	O
few	O
percentage	O
points	O
of	O
performance	O
came	O
from	O
adjusting	O
hyperparameters	O
this	O
mostly	O
consisted	O
of	O
making	O
the	O
model	O
larger	O
while	O
maintaining	O
some	O
restrictions	O
on	O
its	O
computational	O
cost	O
because	O
train	O
and	O
test	O
error	O
remained	O
roughly	O
equal	O
it	O
was	O
always	O
clear	O
that	O
any	O
performance	O
deficits	O
were	O
due	O
to	O
underfitting	O
as	O
well	O
as	O
due	O
to	O
a	O
few	O
remaining	O
problems	O
with	O
the	O
dataset	B
itself	O
overall	O
the	O
transcription	B
project	O
was	O
a	O
great	O
success	O
and	O
allowed	O
hundreds	O
of	O
millions	O
of	O
addresses	O
to	O
be	O
transcribed	O
both	O
faster	O
and	O
at	O
lower	O
cost	O
than	O
would	O
have	O
been	O
possible	O
via	O
human	O
effort	O
we	O
hope	O
that	O
the	O
design	O
principles	O
described	O
in	O
this	O
chapter	O
will	O
lead	O
to	O
many	O
other	O
similar	O
successes	O
chapter	O
applications	O
in	O
this	O
chapter	O
we	O
describe	O
how	O
to	O
use	O
deep	O
learning	O
to	O
solve	O
applications	O
in	O
computer	B
vision	I
speech	O
recognition	O
natural	B
language	I
processing	I
and	O
other	O
application	O
areas	O
of	O
commercial	O
interest	O
we	O
begin	O
by	O
discussing	O
the	O
large	O
scale	O
neural	B
network	I
implementations	O
required	O
for	O
most	O
serious	O
ai	O
applications	O
next	O
we	O
review	O
several	O
specific	O
application	O
areas	O
that	O
deep	O
learning	O
has	O
been	O
used	O
to	O
solve	O
while	O
one	O
goal	O
of	O
deep	O
learning	O
is	O
to	O
design	O
algorithms	O
that	O
are	O
capable	O
of	O
solving	O
a	O
broad	O
variety	O
of	O
tasks	O
so	O
far	O
some	O
degree	O
of	O
specialization	O
is	O
needed	O
for	O
example	B
vision	O
tasks	O
require	O
processing	O
a	O
large	O
number	O
of	O
input	O
features	O
per	O
example	B
language	O
tasks	O
require	O
modeling	O
a	O
large	O
number	O
of	O
possible	O
values	O
in	O
the	O
vocabulary	O
per	O
input	O
feature	B
large-scale	O
deep	O
learning	O
deep	O
learning	O
is	O
based	O
on	O
the	O
philosophy	O
of	O
connectionism	B
while	O
an	O
individual	O
biological	O
neuron	O
or	O
an	O
individual	O
feature	B
in	O
a	O
machine	B
learning	I
model	O
is	O
not	O
intelligent	O
a	O
large	O
population	O
of	O
these	O
neurons	O
or	O
features	O
acting	O
together	O
can	O
exhibit	O
intelligent	O
behavior	O
it	O
truly	O
is	O
important	O
to	O
emphasize	O
the	O
fact	O
that	O
the	O
number	O
of	O
neurons	O
must	O
be	O
large	O
one	O
of	O
the	O
key	O
factors	O
responsible	O
for	O
the	O
improvement	O
in	O
neural	B
network	I
s	O
accuracy	B
and	O
the	O
improvement	O
of	O
the	O
complexity	O
of	O
tasks	O
they	O
can	O
solve	O
between	O
the	O
and	O
today	O
is	O
the	O
dramatic	O
increase	O
in	O
the	O
size	O
of	O
the	O
networks	O
we	O
use	O
as	O
we	O
saw	O
in	O
section	O
network	O
sizes	O
have	O
grown	O
exponentially	O
for	O
the	O
past	O
three	O
decades	O
yet	O
artificial	O
neural	O
networks	O
are	O
only	O
as	O
large	O
as	O
the	O
nervous	O
systems	O
of	O
insects	O
because	O
the	O
size	O
of	O
neural	O
networks	O
is	O
of	O
paramount	O
importance	O
deep	O
learning	O
chapter	O
applications	O
requires	O
high	O
performance	O
hardware	O
and	O
software	O
infrastructure	O
fast	O
cpu	O
implementations	O
traditionally	O
neural	O
networks	O
were	O
trained	O
using	O
the	O
cpu	O
of	O
a	O
single	O
machine	O
today	O
this	O
approach	O
is	O
generally	O
considered	O
insufficient	O
we	O
now	O
mostly	O
use	O
gpu	O
computing	O
or	O
the	O
cpus	O
of	O
many	O
machines	O
networked	O
together	O
before	O
moving	O
to	O
these	O
expensive	O
setups	O
researchers	O
worked	O
hard	O
to	O
demonstrate	O
that	O
cpus	O
could	O
not	O
manage	O
the	O
high	O
computational	O
workload	O
required	O
by	O
neural	O
networks	O
a	O
description	O
of	O
how	O
to	O
implement	O
efficient	O
numerical	O
cpu	O
code	O
is	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
but	O
we	O
emphasize	O
here	O
that	O
careful	O
implementation	O
for	O
specific	O
cpu	O
families	O
can	O
yield	O
large	O
improvements	O
for	O
example	B
in	O
the	O
best	O
cpus	O
available	O
could	O
run	O
neural	B
network	I
workloads	O
faster	O
when	O
using	O
fixed-point	O
arithmetic	O
rather	O
than	O
floating-point	O
arithmetic	O
by	O
creating	O
a	O
carefully	O
tuned	O
fixedpoint	O
implementation	O
vanhoucke	O
obtained	O
a	O
threefold	O
speedup	O
over	O
a	O
strong	O
floating-point	O
system	O
each	O
new	O
model	O
of	O
cpu	O
has	O
different	O
performance	O
characteristics	O
so	O
sometimes	O
floating-point	O
implementations	O
can	O
be	O
faster	O
too	O
the	O
important	O
principle	O
is	O
that	O
careful	O
specialization	O
of	O
numerical	O
computation	O
routines	O
can	O
yield	O
a	O
large	O
payoff	O
other	O
strategies	O
besides	O
choosing	O
whether	O
to	O
use	O
fixed	O
or	O
floating	O
point	O
include	O
optimizing	O
data	O
structures	O
to	O
avoid	O
cache	O
misses	O
and	O
using	O
vector	O
instructions	O
many	O
machine	B
learning	I
researchers	O
neglect	O
these	O
implementation	O
details	O
but	O
when	O
the	O
performance	O
of	O
an	O
implementation	O
restricts	O
the	O
size	O
of	O
the	O
model	O
the	O
accuracy	B
of	O
the	O
model	O
suffers	O
et	O
al	O
gpu	O
implementations	O
most	O
modern	O
neural	B
network	I
implementations	O
are	O
based	O
on	O
graphics	O
processing	O
units	O
graphics	O
processing	O
units	O
are	O
specialized	O
hardware	O
components	O
that	O
were	O
originally	O
developed	O
for	O
graphics	O
applications	O
the	O
consumer	O
market	O
for	O
video	O
gaming	O
systems	O
spurred	O
development	O
of	O
graphics	O
processing	O
hardware	O
the	O
performance	O
characteristics	O
needed	O
for	O
good	O
video	O
gaming	O
systems	O
turn	O
out	O
to	O
be	O
beneficial	O
for	O
neural	O
networks	O
as	O
well	O
video	O
game	O
rendering	O
requires	O
performing	O
many	O
operations	O
in	O
parallel	O
quickly	O
models	O
of	O
characters	O
and	O
environments	O
are	O
specified	O
in	O
terms	O
of	O
lists	O
of	O
coordinates	O
of	O
vertices	O
graphics	O
cards	O
must	O
perform	O
matrix	O
multiplication	O
and	O
division	O
on	O
many	O
vertices	O
in	O
parallel	O
to	O
convert	O
these	O
coordinates	O
into	O
on-screen	O
coordinates	O
the	O
graphics	O
card	O
must	O
then	O
perform	O
many	O
computations	O
at	O
each	O
pixel	O
in	O
parallel	O
to	O
determine	O
the	O
color	O
of	O
each	O
pixel	O
in	O
both	O
cases	O
the	O
chapter	O
applications	O
computations	O
are	O
fairly	O
simple	O
and	O
do	O
not	O
involve	O
much	O
branching	O
compared	O
to	O
the	O
computational	O
workload	O
that	O
a	O
cpu	O
usually	O
encounters	O
for	O
example	B
each	O
vertex	O
in	O
the	O
same	O
rigid	O
object	O
will	O
be	O
multiplied	O
by	O
the	O
same	O
matrix	O
there	O
is	O
no	O
need	O
to	O
evaluate	O
an	O
if	O
statement	O
per-vertex	O
to	O
determine	O
which	O
matrix	O
to	O
multiply	O
by	O
the	O
computations	O
are	O
also	O
entirely	O
independent	O
of	O
each	O
other	O
and	O
thus	O
may	O
be	O
parallelized	O
easily	O
the	O
computations	O
also	O
involve	O
processing	O
massive	O
buffers	O
of	O
memory	O
containing	O
bitmaps	O
describing	O
the	O
texture	O
pattern	O
of	O
each	O
object	O
to	O
be	O
rendered	O
together	O
this	O
results	O
in	O
graphics	O
cards	O
having	O
been	O
designed	O
to	O
have	O
a	O
high	O
degree	O
of	O
parallelism	O
and	O
high	O
memory	O
bandwidth	O
at	O
the	O
cost	O
of	O
having	O
a	O
lower	O
clock	O
speed	O
and	O
less	O
branching	O
capability	O
relative	O
to	O
traditional	O
cpus	O
neural	B
network	I
algorithms	O
require	O
the	O
same	O
performance	O
characteristics	O
as	O
the	O
real-time	O
graphics	O
algorithms	O
described	O
above	O
neural	O
networks	O
usually	O
involve	O
large	O
and	O
numerous	O
buffers	O
of	O
parameters	O
activation	O
values	O
and	O
gradient	B
values	O
each	O
of	O
which	O
must	O
be	O
completely	O
updated	O
during	O
every	O
step	O
of	O
training	O
these	O
buffers	O
are	O
large	O
enough	O
to	O
fall	O
outside	O
the	O
cache	O
of	O
a	O
traditional	O
desktop	O
computer	O
so	O
the	O
memory	O
bandwidth	O
of	O
the	O
system	O
often	O
becomes	O
the	O
rate	O
limiting	O
factor	O
gpus	O
offer	O
a	O
compelling	O
advantage	O
over	O
cpus	O
due	O
to	O
their	O
high	O
memory	O
bandwidth	O
neural	B
network	I
training	O
algorithms	O
typically	O
do	O
not	O
involve	O
much	O
branching	O
or	O
sophisticated	O
control	O
so	O
they	O
are	O
appropriate	O
for	O
gpu	O
hardware	O
since	O
neural	O
networks	O
can	O
be	O
divided	O
into	O
multiple	O
individual	O
neurons	O
that	O
can	O
be	O
processed	O
independently	O
from	O
the	O
other	O
neurons	O
in	O
the	O
same	O
layer	O
neural	O
networks	O
easily	O
benefit	O
from	O
the	O
parallelism	O
of	O
gpu	O
computing	O
gpu	O
hardware	O
was	O
originally	O
so	O
specialized	O
that	O
it	O
could	O
only	O
be	O
used	O
for	O
graphics	O
tasks	O
over	O
time	O
gpu	O
hardware	O
became	O
more	O
flexible	O
allowing	O
custom	O
subroutines	O
to	O
be	O
used	O
to	O
transform	O
the	O
coordinates	O
of	O
vertices	O
or	O
assign	O
colors	O
to	O
pixels	O
in	O
principle	O
there	O
was	O
no	O
requirement	O
that	O
these	O
pixel	O
values	O
actually	O
be	O
based	O
on	O
a	O
rendering	O
task	O
these	O
gpus	O
could	O
be	O
used	O
for	O
scientific	O
computing	O
by	O
writing	O
the	O
output	O
of	O
a	O
computation	O
to	O
a	O
buffer	O
of	O
pixel	O
values	O
steinkrau	O
et	O
al	O
implemented	O
a	O
two-layer	O
fully	O
connected	O
neural	B
network	I
on	O
a	O
gpu	O
and	O
reported	O
a	O
threefold	O
speedup	O
over	O
their	O
cpu-based	O
baseline	O
shortly	O
thereafter	O
chellapilla	O
demonstrated	O
that	O
the	O
same	O
technique	O
could	O
be	O
used	O
to	O
accelerate	O
supervised	O
convolutional	O
networks	O
et	O
al	O
the	O
popularity	O
of	O
graphics	O
cards	O
for	O
neural	B
network	I
training	O
exploded	O
after	O
the	O
advent	O
of	O
general	O
purpose	O
gpus	O
these	O
gp-gpus	O
could	O
execute	O
arbitrary	O
code	O
not	O
just	O
rendering	O
subroutines	O
nvidia	O
s	O
cuda	O
programming	O
language	O
provided	O
a	O
way	O
to	O
write	O
this	O
arbitrary	O
code	O
in	O
a	O
c-like	O
language	O
with	O
their	O
relatively	O
convenient	O
programming	O
model	O
massive	O
parallelism	O
and	O
high	O
memory	O
chapter	O
applications	O
bandwidth	O
gp-gpus	O
now	O
offer	O
an	O
ideal	O
platform	O
for	O
neural	B
network	I
programming	O
this	O
platform	O
was	O
rapidly	O
adopted	O
by	O
deep	O
learning	O
researchers	O
soon	O
after	O
it	O
became	O
available	O
raina	O
et	O
al	O
ciresan	O
et	O
al	O
writing	O
efficient	O
code	O
for	O
gp-gpus	O
remains	O
a	O
difficult	O
task	O
best	O
left	O
to	O
specialists	O
the	O
techniques	O
required	O
to	O
obtain	O
good	O
performance	O
on	O
gpu	O
are	O
very	O
different	O
from	O
those	O
used	O
on	O
cpu	O
for	O
example	B
good	O
cpu-based	O
code	O
is	O
usually	O
designed	O
to	O
read	O
information	O
from	O
the	O
cache	O
as	O
much	O
as	O
possible	O
on	O
gpu	O
most	O
writable	O
memory	O
locations	O
are	O
not	O
cached	O
so	O
it	O
can	O
actually	O
be	O
faster	O
to	O
compute	O
the	O
same	O
value	O
twice	O
rather	O
than	O
compute	O
it	O
once	O
and	O
read	O
it	O
back	O
from	O
memory	O
gpu	O
code	O
is	O
also	O
inherently	O
multi-threaded	O
and	O
the	O
different	O
threads	O
must	O
be	O
coordinated	O
with	O
each	O
other	O
carefully	O
for	O
example	B
memory	O
operations	O
are	O
faster	O
if	O
they	O
can	O
be	O
coalesced	O
coalesced	O
reads	O
or	O
writes	O
occur	O
when	O
several	O
threads	O
can	O
each	O
read	O
or	O
write	O
a	O
value	O
that	O
they	O
need	O
simultaneously	O
as	O
part	O
of	O
a	O
single	O
memory	O
transaction	O
different	O
models	O
of	O
gpus	O
are	O
able	O
to	O
coalesce	O
different	O
kinds	O
of	O
read	O
or	O
write	O
patterns	O
typically	O
memory	O
operations	O
are	O
easier	O
to	O
coalesce	O
if	O
among	O
n	O
threads	O
thread	O
i	O
accesses	O
byte	O
i	O
j	O
of	O
memory	O
and	O
j	O
is	O
a	O
multiple	O
of	O
some	O
power	O
of	O
the	O
exact	O
specifications	O
differ	O
between	O
models	O
of	O
gpu	O
another	O
common	O
consideration	O
for	O
gpus	O
is	O
making	O
sure	O
that	O
each	O
thread	O
in	O
a	O
group	O
executes	O
the	O
same	O
instruction	O
simultaneously	O
this	O
means	O
that	O
branching	O
can	O
be	O
difficult	O
on	O
gpu	O
threads	O
are	O
divided	O
into	O
small	O
groups	O
called	O
warps	O
each	O
thread	O
in	O
a	O
warp	O
executes	O
the	O
same	O
instruction	O
during	O
each	O
cycle	O
so	O
if	O
different	O
threads	O
within	O
the	O
same	O
warp	O
need	O
to	O
execute	O
different	O
code	O
paths	O
these	O
different	O
code	O
paths	O
must	O
be	O
traversed	O
sequentially	O
rather	O
than	O
in	O
parallel	O
due	O
to	O
the	O
difficulty	O
of	O
writing	O
high	O
performance	O
gpu	O
code	O
researchers	O
should	O
structure	O
their	O
workflow	O
to	O
avoid	O
needing	O
to	O
write	O
new	O
gpu	O
code	O
in	O
order	O
to	O
test	O
new	O
models	O
or	O
algorithms	O
typically	O
one	O
can	O
do	O
this	O
by	O
building	O
a	O
software	O
library	O
of	O
high	O
performance	O
operations	O
like	O
convolution	O
and	O
matrix	O
multiplication	O
then	O
specifying	O
models	O
in	O
terms	O
of	O
calls	O
to	O
this	O
library	O
of	O
operations	O
for	O
example	B
the	O
machine	B
learning	I
library	O
specifies	O
all	O
of	O
its	O
machine	B
learning	I
algorithms	O
in	O
terms	O
of	O
calls	O
to	O
theano	O
bergstra	O
et	O
al	O
bastien	O
which	O
provide	O
these	O
high-performance	O
operations	O
this	O
factored	O
approach	O
can	O
also	O
ease	O
support	O
for	O
multiple	O
kinds	O
of	O
hardware	O
for	O
example	B
the	O
same	O
theano	O
program	O
can	O
run	O
on	O
either	O
cpu	O
or	O
gpu	O
without	O
needing	O
to	O
change	O
any	O
of	O
the	O
calls	O
to	O
theano	O
itself	O
other	O
libraries	O
like	O
tensorflow	O
collobert	O
et	O
al	O
provide	O
similar	O
features	O
and	O
cuda-convnet	O
abadi	O
et	O
al	O
and	O
torch	O
krizhevsky	O
et	O
al	O
et	O
al	O
chapter	O
applications	O
large-scale	O
distributed	O
implementations	O
in	O
many	O
cases	O
the	O
computational	O
resources	O
available	O
on	O
a	O
single	O
machine	O
are	O
insufficient	O
we	O
therefore	O
want	O
to	O
distribute	O
the	O
workload	O
of	O
training	O
and	O
inference	O
across	O
many	O
machines	O
distributing	O
inference	O
is	O
simple	O
because	O
each	O
input	O
example	B
we	O
want	O
to	O
process	O
can	O
be	O
run	O
by	O
a	O
separate	O
machine	O
this	O
is	O
known	O
as	O
data	B
parallelism	I
it	O
is	O
also	O
possible	O
to	O
get	O
model	B
parallelism	I
where	O
multiple	O
machines	O
work	O
together	O
on	O
a	O
single	O
datapoint	O
with	O
each	O
machine	O
running	O
a	O
different	O
part	O
of	O
the	O
model	O
this	O
is	O
feasible	O
for	O
both	O
inference	O
and	O
training	O
data	B
parallelism	I
during	O
training	O
is	O
somewhat	O
harder	O
we	O
can	O
increase	O
the	O
size	O
of	O
the	O
minibatch	B
used	O
for	O
a	O
single	O
sgd	O
step	O
but	O
usually	O
we	O
get	O
less	O
than	O
linear	O
returns	O
in	O
terms	O
of	O
optimization	O
performance	O
it	O
would	O
be	O
better	O
to	O
allow	O
multiple	O
machines	O
to	O
compute	O
multiple	O
gradient	B
descent	O
steps	O
in	O
parallel	O
unfortunately	O
the	O
standard	O
definition	O
of	O
gradient	B
descent	O
is	O
as	O
a	O
completely	O
sequential	O
algorithm	O
the	O
gradient	B
at	O
step	O
is	O
a	O
function	O
of	O
the	O
parameters	O
produced	O
by	O
step	O
t	O
t	O
et	O
al	O
recht	O
this	O
can	O
be	O
solved	O
using	O
asynchronous	O
stochastic	O
gradient	B
descent	O
et	O
al	O
in	O
this	O
approach	O
several	O
processor	O
cores	O
share	O
the	O
memory	O
representing	O
the	O
parameters	O
each	O
core	O
reads	O
parameters	O
without	O
a	O
lock	O
then	O
computes	O
a	O
gradient	B
then	O
increments	O
the	O
parameters	O
without	O
a	O
lock	O
this	O
reduces	O
the	O
average	O
amount	O
of	O
improvement	O
that	O
each	O
gradient	B
descent	O
step	O
yields	O
because	O
some	O
of	O
the	O
cores	O
overwrite	O
each	O
other	O
s	O
progress	O
but	O
the	O
increased	O
rate	O
of	O
production	O
of	O
steps	O
causes	O
the	O
learning	O
process	O
to	O
be	O
faster	O
overall	O
dean	O
et	O
al	O
pioneered	O
the	O
multi-machine	O
implementation	O
of	O
this	O
lock-free	O
approach	O
to	O
gradient	B
descent	O
where	O
the	O
parameters	O
are	O
managed	O
by	O
a	O
parameter	O
server	O
rather	O
than	O
stored	O
in	O
shared	O
memory	O
distributed	O
asynchronous	O
gradient	B
descent	O
remains	O
the	O
primary	O
strategy	O
for	O
training	O
large	O
deep	O
networks	O
and	O
is	O
used	O
by	O
most	O
major	O
deep	O
learning	O
groups	O
in	O
industry	O
chilimbi	O
et	O
al	O
wu	O
et	O
al	O
academic	O
deep	O
learning	O
researchers	O
typically	O
cannot	O
afford	O
the	O
same	O
scale	O
of	O
distributed	O
learning	O
systems	O
but	O
some	O
research	O
has	O
focused	O
on	O
how	O
to	O
build	O
distributed	O
networks	O
with	O
relatively	O
low-cost	O
hardware	O
available	O
in	O
the	O
university	O
setting	O
coates	O
et	O
al	O
model	B
compression	I
in	O
many	O
commercial	O
applications	O
it	O
is	O
much	O
more	O
important	O
that	O
the	O
time	O
and	O
memory	O
cost	O
of	O
running	O
inference	O
in	O
a	O
machine	B
learning	I
model	O
be	O
low	O
than	O
that	O
the	O
time	O
and	O
memory	O
cost	O
of	O
training	O
be	O
low	O
for	O
applications	O
that	O
do	O
not	O
require	O
chapter	O
applications	O
personalization	O
it	O
is	O
possible	O
to	O
train	O
a	O
model	O
once	O
then	O
deploy	O
it	O
to	O
be	O
used	O
by	O
billions	O
of	O
users	O
in	O
many	O
cases	O
the	O
end	O
user	O
is	O
more	O
resource-constrained	O
than	O
the	O
developer	O
for	O
example	B
one	O
might	O
train	O
a	O
speech	O
recognition	O
network	O
with	O
a	O
powerful	O
computer	O
cluster	O
then	O
deploy	O
it	O
on	O
mobile	O
phones	O
et	O
al	O
a	O
key	O
strategy	O
for	O
reducing	O
the	O
cost	O
of	O
inference	O
is	O
model	B
compression	I
a	O
the	O
basic	O
idea	O
of	O
model	B
compression	I
is	O
to	O
replace	O
the	O
original	O
expensive	O
model	O
with	O
a	O
smaller	O
model	O
that	O
requires	O
less	O
memory	O
and	O
runtime	O
to	O
store	O
and	O
evaluate	O
model	B
compression	I
is	O
applicable	O
when	O
the	O
size	O
of	O
the	O
original	O
model	O
is	O
driven	O
primarily	O
by	O
a	O
need	O
to	O
prevent	O
overfitting	O
in	O
most	O
cases	O
the	O
model	O
with	O
the	O
lowest	O
generalization	B
error	O
is	O
an	O
ensemble	O
of	O
several	O
independently	O
trained	O
models	O
evaluating	O
all	O
n	O
ensemble	O
members	O
is	O
expensive	O
sometimes	O
even	O
a	O
single	O
model	O
generalizes	O
better	O
if	O
it	O
is	O
large	O
example	B
if	O
it	O
is	O
regularized	O
with	O
dropout	O
these	O
large	O
models	O
learn	O
some	O
function	O
fx	O
but	O
do	O
so	O
using	O
many	O
more	O
parameters	O
than	O
are	O
necessary	O
for	O
the	O
task	O
their	O
size	O
is	O
necessary	O
only	O
due	O
to	O
the	O
limited	O
number	O
of	O
training	O
examples	O
as	O
soon	O
as	O
we	O
have	O
fit	O
this	O
function	O
f	O
we	O
can	O
generate	O
a	O
training	O
set	O
containing	O
infinitely	O
many	O
examples	O
simply	O
by	O
applying	O
f	O
to	O
randomly	O
sampled	O
points	O
x	O
we	O
then	O
train	O
the	O
new	O
smaller	O
model	O
to	O
match	O
f	O
on	O
these	O
points	O
in	O
order	O
to	O
most	O
efficiently	O
use	O
the	O
capacity	O
of	O
the	O
new	O
small	O
model	O
it	O
is	O
best	O
to	O
sample	O
the	O
new	O
x	O
points	O
from	O
a	O
distribution	O
resembling	O
the	O
actual	O
test	O
inputs	O
that	O
will	O
be	O
supplied	O
to	O
the	O
model	O
later	O
this	O
can	O
be	O
done	O
by	O
corrupting	O
training	O
examples	O
or	O
by	O
drawing	O
points	O
from	O
a	O
generative	O
model	O
trained	O
on	O
the	O
original	O
training	O
set	O
alternatively	O
one	O
can	O
train	O
the	O
smaller	O
model	O
only	O
on	O
the	O
original	O
training	O
points	O
but	O
train	O
it	O
to	O
copy	O
other	O
features	O
of	O
the	O
model	O
such	O
as	O
its	O
posterior	O
distribution	O
over	O
the	O
incorrect	O
classes	O
et	O
al	O
dynamic	B
structure	I
one	O
strategy	O
for	O
accelerating	O
data	O
processing	O
systems	O
in	O
general	O
is	O
to	O
build	O
systems	O
that	O
have	O
dynamic	B
structure	I
in	O
the	O
graph	O
describing	O
the	O
computation	O
needed	O
to	O
process	O
an	O
input	O
data	O
processing	O
systems	O
can	O
dynamically	O
determine	O
which	O
subset	O
of	O
many	O
neural	O
networks	O
should	O
be	O
run	O
on	O
a	O
given	O
input	O
individual	O
neural	O
networks	O
can	O
also	O
exhibit	O
dynamic	B
structure	I
internally	O
by	O
determining	O
which	O
subset	O
of	O
features	O
units	O
to	O
compute	O
given	O
information	O
from	O
the	O
input	O
this	O
form	O
of	O
dynamic	B
structure	I
inside	O
neural	O
networks	O
is	O
sometimes	O
called	O
conditional	O
computation	O
since	O
many	O
components	O
of	O
the	O
architecture	O
may	O
be	O
relevant	O
only	O
for	O
a	O
small	O
amount	O
of	O
possible	O
inputs	O
the	O
bengio	O
bengio	O
et	O
al	O
chapter	O
applications	O
system	O
can	O
run	O
faster	O
by	O
computing	O
these	O
features	O
only	O
when	O
they	O
are	O
needed	O
dynamic	B
structure	I
of	O
computations	O
is	O
a	O
basic	O
computer	O
science	O
principle	O
applied	O
generally	O
throughout	O
the	O
software	O
engineering	O
discipline	O
the	O
simplest	O
versions	O
of	O
dynamic	B
structure	I
applied	O
to	O
neural	O
networks	O
are	O
based	O
on	O
determining	O
which	O
subset	O
of	O
some	O
group	O
of	O
neural	O
networks	O
other	O
machine	B
learning	I
models	O
should	O
be	O
applied	O
to	O
a	O
particular	O
input	O
a	O
venerable	O
strategy	O
for	O
accelerating	O
inference	O
in	O
a	O
classifier	O
is	O
to	O
use	O
a	O
cascade	O
of	O
classifiers	O
the	O
cascade	O
strategy	O
may	O
be	O
applied	O
when	O
the	O
goal	O
is	O
to	O
detect	O
the	O
presence	O
of	O
a	O
rare	O
object	O
event	O
to	O
know	O
for	O
sure	O
that	O
the	O
object	O
is	O
present	O
we	O
must	O
use	O
a	O
sophisticated	O
classifier	O
with	O
high	O
capacity	O
that	O
is	O
expensive	O
to	O
run	O
however	O
because	O
the	O
object	O
is	O
rare	O
we	O
can	O
usually	O
use	O
much	O
less	O
computation	O
to	O
reject	O
inputs	O
as	O
not	O
containing	O
the	O
object	O
in	O
these	O
situations	O
we	O
can	O
train	O
a	O
sequence	O
of	O
classifiers	O
the	O
first	O
classifiers	O
in	O
the	O
sequence	O
have	O
low	O
capacity	O
and	O
are	O
trained	O
to	O
have	O
high	O
recall	B
in	O
other	O
words	O
they	O
are	O
trained	O
to	O
make	O
sure	O
we	O
do	O
not	O
wrongly	O
reject	O
an	O
input	O
when	O
the	O
object	O
is	O
present	O
the	O
final	O
classifier	O
is	O
trained	O
to	O
have	O
high	O
precision	B
at	O
test	O
time	O
we	O
run	O
inference	O
by	O
running	O
the	O
classifiers	O
in	O
a	O
sequence	O
abandoning	O
any	O
example	B
as	O
soon	O
as	O
any	O
one	O
element	O
in	O
the	O
cascade	O
rejects	O
it	O
overall	O
this	O
allows	O
us	O
to	O
verify	O
the	O
presence	O
of	O
objects	O
with	O
high	O
confidence	O
using	O
a	O
high	O
capacity	O
model	O
but	O
does	O
not	O
force	O
us	O
to	O
pay	O
the	O
cost	O
of	O
full	O
inference	O
for	O
every	O
example	B
there	O
are	O
two	O
different	O
ways	O
that	O
the	O
cascade	O
can	O
achieve	O
high	O
capacity	O
one	O
way	O
is	O
to	O
make	O
the	O
later	O
members	O
of	O
the	O
cascade	O
individually	O
have	O
high	O
capacity	O
in	O
this	O
case	O
the	O
system	O
as	O
a	O
whole	O
obviously	O
has	O
high	O
capacity	O
because	O
some	O
of	O
its	O
individual	O
members	O
do	O
it	O
is	O
also	O
possible	O
to	O
make	O
a	O
cascade	O
in	O
which	O
every	O
individual	O
model	O
has	O
low	O
capacity	O
but	O
the	O
system	O
as	O
a	O
whole	O
has	O
high	O
capacity	O
due	O
to	O
the	O
combination	O
of	O
many	O
small	O
models	O
viola	O
and	O
jones	O
used	O
a	O
cascade	O
of	O
boosted	O
decision	O
trees	O
to	O
implement	O
a	O
fast	O
and	O
robust	O
face	O
detector	O
suitable	O
for	O
use	O
in	O
handheld	O
digital	O
cameras	O
their	O
classifier	O
localizes	O
a	O
face	O
using	O
essentially	O
a	O
sliding	O
window	O
approach	O
in	O
which	O
many	O
windows	O
are	O
examined	O
and	O
rejected	O
if	O
they	O
do	O
not	O
contain	O
faces	O
another	O
version	O
of	O
cascades	O
uses	O
the	O
earlier	O
models	O
to	O
implement	O
a	O
sort	O
of	O
hard	O
attention	O
mechanism	O
the	O
early	O
members	O
of	O
the	O
cascade	O
localize	O
an	O
object	O
and	O
later	O
members	O
of	O
the	O
cascade	O
perform	O
further	O
processing	O
given	O
the	O
location	O
of	O
the	O
object	O
for	O
example	B
google	O
transcribes	O
address	O
numbers	O
from	O
street	O
view	O
imagery	O
using	O
a	O
two-step	O
cascade	O
that	O
first	O
locates	O
the	O
address	O
number	O
with	O
one	O
machine	B
learning	I
model	O
and	O
then	O
transcribes	O
it	O
with	O
another	O
et	O
al	O
decision	O
trees	O
themselves	O
are	O
an	O
example	B
of	O
dynamic	B
structure	I
because	O
each	O
node	O
in	O
the	O
tree	O
determines	O
which	O
of	O
its	O
subtrees	O
should	O
be	O
evaluated	O
for	O
each	O
input	O
a	O
simple	O
way	O
to	O
accomplish	O
the	O
union	O
of	O
deep	O
learning	O
and	O
dynamic	B
structure	I
chapter	O
applications	O
is	O
to	O
train	O
a	O
decision	O
tree	O
in	O
which	O
each	O
node	O
uses	O
a	O
neural	B
network	I
to	O
make	O
the	O
splitting	O
decision	O
though	O
this	O
has	O
typically	O
not	O
been	O
done	O
with	O
the	O
primary	O
goal	O
of	O
accelerating	O
inference	O
computations	O
guo	O
and	O
gelfand	O
et	O
al	O
in	O
the	O
same	O
spirit	O
one	O
can	O
use	O
a	O
neural	B
network	I
called	O
the	O
gater	O
to	O
select	O
which	O
one	O
out	O
of	O
several	O
expert	O
networks	O
will	O
be	O
used	O
to	O
compute	O
the	O
output	O
given	O
the	O
current	O
input	O
the	O
first	O
version	O
of	O
this	O
idea	O
is	O
called	O
the	O
mixture	O
of	O
experts	O
jacobs	O
in	O
which	O
the	O
gater	O
outputs	O
a	O
set	O
of	O
probabilities	O
or	O
weights	B
via	O
a	O
softmax	O
nonlinearity	O
one	O
per	O
expert	O
and	O
the	O
final	O
output	O
is	O
obtained	O
by	O
the	O
weighted	O
combination	O
of	O
the	O
output	O
of	O
the	O
experts	O
in	O
that	O
case	O
the	O
use	O
of	O
the	O
gater	O
does	O
not	O
offer	O
a	O
reduction	O
in	O
computational	O
cost	O
but	O
if	O
a	O
single	O
expert	O
is	O
chosen	O
by	O
the	O
gater	O
for	O
each	O
example	B
we	O
obtain	O
the	O
hard	O
mixture	O
of	O
experts	O
which	O
can	O
considerably	O
accelerate	O
training	O
and	O
inference	O
time	O
this	O
strategy	O
works	O
well	O
when	O
the	O
number	O
of	O
gating	O
decisions	O
is	O
small	O
because	O
it	O
is	O
not	O
combinatorial	O
but	O
when	O
we	O
want	O
to	O
select	O
different	O
subsets	O
of	O
units	O
or	O
parameters	O
it	O
is	O
not	O
possible	O
to	O
use	O
a	O
soft	O
switch	O
because	O
it	O
requires	O
enumerating	O
computing	O
outputs	O
for	O
all	O
the	O
gater	O
configurations	O
to	O
deal	O
with	O
this	O
problem	O
several	O
approaches	O
have	O
been	O
explored	O
to	O
train	O
combinatorial	O
gaters	O
experiment	O
with	O
several	O
estimators	O
of	O
the	O
gradient	B
on	O
the	O
gating	O
probabilities	O
while	O
bacon	O
et	O
al	O
use	O
reinforcement	O
learning	O
techniques	O
gradient	B
to	O
learn	O
a	O
form	O
of	O
conditional	O
dropout	O
on	O
blocks	O
of	O
hidden	O
units	O
and	O
get	O
an	O
actual	O
reduction	O
in	O
computational	O
cost	O
without	O
impacting	O
negatively	O
on	O
the	O
quality	O
of	O
the	O
approximation	O
collobert	O
et	O
al	O
bengio	O
et	O
al	O
bengio	O
et	O
al	O
and	O
another	O
kind	O
of	O
dynamic	B
structure	I
is	O
a	O
switch	O
where	O
a	O
hidden	O
unit	O
can	O
receive	O
input	O
from	O
different	O
units	O
depending	O
on	O
the	O
context	O
this	O
dynamic	O
routing	O
approach	O
can	O
be	O
interpreted	O
as	O
an	O
attention	O
mechanism	O
olshausen	O
et	O
al	O
so	O
far	O
the	O
use	O
of	O
a	O
hard	O
switch	O
has	O
not	O
proven	O
effective	O
on	O
large-scale	O
applications	O
contemporary	O
approaches	O
instead	O
use	O
a	O
weighted	O
average	O
over	O
many	O
possible	O
inputs	O
and	O
thus	O
do	O
not	O
achieve	O
all	O
of	O
the	O
possible	O
computational	O
benefits	O
of	O
dynamic	B
structure	I
contemporary	O
attention	O
mechanisms	O
are	O
described	O
in	O
section	O
one	O
major	O
obstacle	O
to	O
using	O
dynamically	O
structured	O
systems	O
is	O
the	O
decreased	O
degree	O
of	O
parallelism	O
that	O
results	O
from	O
the	O
system	O
following	O
different	O
code	O
branches	O
for	O
different	O
inputs	O
this	O
means	O
that	O
few	O
operations	O
in	O
the	O
network	O
can	O
be	O
described	O
as	O
matrix	O
multiplication	O
or	O
batch	O
convolution	O
on	O
a	O
minibatch	B
of	O
examples	O
we	O
can	O
write	O
more	O
specialized	O
sub-routines	O
that	O
convolve	O
each	O
example	B
with	O
different	O
kernels	O
or	O
multiply	O
each	O
row	O
of	O
a	O
design	B
matrix	I
by	O
a	O
different	O
set	O
of	O
columns	O
of	O
weights	B
unfortunately	O
these	O
more	O
specialized	O
subroutines	O
are	O
difficult	O
to	O
implement	O
efficiently	O
cpu	O
implementations	O
will	O
be	O
slow	O
due	O
to	O
the	O
lack	O
of	O
cache	O
chapter	O
applications	O
coherence	O
and	O
gpu	O
implementations	O
will	O
be	O
slow	O
due	O
to	O
the	O
lack	O
of	O
coalesced	O
memory	O
transactions	O
and	O
the	O
need	O
to	O
serialize	O
warps	O
when	O
members	O
of	O
a	O
warp	O
take	O
different	O
branches	O
in	O
some	O
cases	O
these	O
issues	O
can	O
be	O
mitigated	O
by	O
partitioning	O
the	O
examples	O
into	O
groups	O
that	O
all	O
take	O
the	O
same	O
branch	O
and	O
processing	O
these	O
groups	O
of	O
examples	O
simultaneously	O
this	O
can	O
be	O
an	O
acceptable	O
strategy	O
for	O
minimizing	O
the	O
time	O
required	O
to	O
process	O
a	O
fixed	O
amount	O
of	O
examples	O
in	O
an	O
o	O
ine	O
setting	O
in	O
a	O
real-time	O
setting	O
where	O
examples	O
must	O
be	O
processed	O
continuously	O
partitioning	O
the	O
workload	O
can	O
result	O
in	O
load-balancing	O
issues	O
for	O
example	B
if	O
we	O
assign	O
one	O
machine	O
to	O
process	O
the	O
first	O
step	O
in	O
a	O
cascade	O
and	O
another	O
machine	O
to	O
process	O
the	O
last	O
step	O
in	O
a	O
cascade	O
then	O
the	O
first	O
will	O
tend	O
to	O
be	O
overloaded	O
and	O
the	O
last	O
will	O
tend	O
to	O
be	O
underloaded	O
similar	O
issues	O
arise	O
if	O
each	O
machine	O
is	O
assigned	O
to	O
implement	O
different	O
nodes	O
of	O
a	O
neural	O
decision	O
tree	O
specialized	O
hardware	O
implementations	O
of	O
deep	O
networks	O
since	O
the	O
early	O
days	O
of	O
neural	O
networks	O
research	O
hardware	O
designers	O
have	O
worked	O
on	O
specialized	O
hardware	O
implementations	O
that	O
could	O
speed	O
up	O
training	O
andor	O
inference	O
of	O
neural	B
network	I
algorithms	O
see	O
early	O
and	O
more	O
recent	O
reviews	O
of	O
specialized	O
hardware	O
for	O
deep	O
networks	O
lindsey	O
and	O
lindblad	O
beiu	O
et	O
al	O
misra	O
and	O
saha	O
et	O
al	O
et	O
al	O
chen	O
pham	O
different	O
forms	O
of	O
specialized	O
hardware	O
and	O
jackel	O
mead	O
and	O
ismail	O
kim	O
have	O
been	O
developed	O
over	O
the	O
last	O
decades	O
either	O
with	O
asics	O
integrated	O
circuit	O
either	O
with	O
digital	O
on	O
binary	O
representations	O
of	O
numbers	O
analog	O
and	O
jackel	O
mead	O
and	O
ismail	O
on	O
physical	O
implementations	O
of	O
continuous	O
values	O
as	O
voltages	O
or	O
currents	O
or	O
hybrid	O
implementations	O
digital	O
and	O
analog	O
components	O
in	O
recent	O
years	O
more	O
flexible	O
fpga	O
programmable	O
gated	O
array	O
implementations	O
the	O
particulars	O
of	O
the	O
circuit	O
can	O
be	O
written	O
on	O
the	O
chip	O
after	O
it	O
has	O
been	O
built	O
have	O
been	O
developed	O
b	O
et	O
al	O
though	O
software	O
implementations	O
on	O
general-purpose	O
processing	O
units	O
and	O
gpus	O
typically	O
use	O
or	O
bits	O
of	O
precision	B
to	O
represent	O
floating	O
point	O
numbers	O
it	O
has	O
long	O
been	O
known	O
that	O
it	O
was	O
possible	O
to	O
use	O
less	O
precision	B
at	O
least	O
at	O
inference	O
time	O
and	O
baker	O
holi	O
and	O
hwang	O
presley	O
and	O
haggard	O
simard	O
and	O
graf	O
wawrzynek	O
et	O
al	O
this	O
has	O
become	O
a	O
more	O
pressing	O
issue	O
in	O
recent	O
years	O
as	O
deep	O
learning	O
has	O
gained	O
in	O
popularity	O
in	O
industrial	O
products	O
and	O
as	O
the	O
great	O
impact	O
of	O
faster	O
hardware	O
was	O
demonstrated	O
with	O
gpus	O
another	O
factor	O
that	O
motivates	O
current	O
research	O
on	O
specialized	O
hardware	O
for	O
deep	O
networks	O
is	O
that	O
the	O
rate	O
of	O
progress	O
of	O
a	O
single	O
cpu	O
or	O
gpu	O
core	O
has	O
slowed	O
down	O
and	O
most	O
recent	O
improvements	O
in	O
savich	O
et	O
al	O
chapter	O
applications	O
computing	O
speed	O
have	O
come	O
from	O
parallelization	O
across	O
cores	O
in	O
cpus	O
or	O
gpus	O
this	O
is	O
very	O
different	O
from	O
the	O
situation	O
of	O
the	O
previous	O
neural	B
network	I
era	O
where	O
the	O
hardware	O
implementations	O
of	O
neural	O
networks	O
might	O
take	O
two	O
years	O
from	O
inception	O
to	O
availability	O
of	O
a	O
chip	O
could	O
not	O
keep	O
up	O
with	O
the	O
rapid	O
progress	O
and	O
low	O
prices	O
of	O
general-purpose	O
cpus	O
building	O
specialized	O
hardware	O
is	O
thus	O
a	O
way	O
to	O
push	O
the	O
envelope	O
further	O
at	O
a	O
time	O
when	O
new	O
hardware	O
designs	O
are	O
being	O
developed	O
for	O
low-power	O
devices	O
such	O
as	O
phones	O
aiming	O
for	O
general-public	O
applications	O
of	O
deep	O
learning	O
with	O
speech	O
computer	B
vision	I
or	O
natural	O
language	O
et	O
al	O
gupta	O
et	O
al	O
et	O
al	O
courbariaux	O
recent	O
work	O
on	O
low-precision	O
implementations	O
of	O
backprop-based	O
neural	O
nets	O
suggests	O
that	O
between	O
and	O
bits	O
of	O
precision	B
can	O
suffice	O
for	O
using	O
or	O
training	O
deep	O
neural	O
networks	O
with	O
back-propagation	B
what	O
is	O
clear	O
is	O
that	O
more	O
precision	B
is	O
required	O
during	O
training	O
than	O
at	O
inference	O
time	O
and	O
that	O
some	O
forms	O
of	O
dynamic	O
fixed	O
point	O
representation	O
of	O
numbers	O
can	O
be	O
used	O
to	O
reduce	O
how	O
many	O
bits	O
are	O
required	O
per	O
number	O
traditional	O
fixed	O
point	O
numbers	O
are	O
restricted	O
to	O
a	O
fixed	O
range	O
corresponds	O
to	O
a	O
given	O
exponent	O
in	O
a	O
floating	O
point	O
representation	O
dynamic	O
fixed	O
point	O
representations	O
share	O
that	O
range	O
among	O
a	O
set	O
of	O
numbers	O
as	O
all	O
the	O
weights	B
in	O
one	O
layer	O
using	O
fixed	O
point	O
rather	O
than	O
floating	O
point	O
representations	O
and	O
using	O
less	O
bits	O
per	O
number	O
reduces	O
the	O
hardware	O
surface	O
area	O
power	O
requirements	O
and	O
computing	O
time	O
needed	O
for	O
performing	O
multiplications	O
and	O
multiplications	O
are	O
the	O
most	O
demanding	O
of	O
the	O
operations	O
needed	O
to	O
use	O
or	O
train	O
a	O
modern	O
deep	O
network	O
with	O
backprop	O
computer	B
vision	I
computer	B
vision	I
has	O
traditionally	O
been	O
one	O
of	O
the	O
most	O
active	O
research	O
areas	O
for	O
deep	O
learning	O
applications	O
because	O
vision	O
is	O
a	O
task	O
that	O
is	O
effortless	O
for	O
humans	O
and	O
many	O
animals	O
but	O
challenging	O
for	O
computers	O
many	O
of	O
the	O
most	O
popular	O
standard	O
benchmark	O
tasks	O
for	O
deep	O
learning	O
algorithms	O
are	O
forms	O
of	O
object	B
recognition	I
or	O
optical	O
character	O
recognition	O
ballard	O
et	O
al	O
computer	B
vision	I
is	O
a	O
very	O
broad	O
field	O
encompassing	O
a	O
wide	O
variety	O
of	O
ways	O
of	O
processing	O
images	O
and	O
an	O
amazing	O
diversity	O
of	O
applications	O
applications	O
of	O
computer	B
vision	I
range	O
from	O
reproducing	O
human	O
visual	O
abilities	O
such	O
as	O
recognizing	O
faces	O
to	O
creating	O
entirely	O
new	O
categories	O
of	O
visual	O
abilities	O
as	O
an	O
example	B
of	O
the	O
latter	O
category	O
one	O
recent	O
computer	B
vision	I
application	O
is	O
to	O
recognize	O
sound	O
waves	O
from	O
the	O
vibrations	O
they	O
induce	O
in	O
objects	O
visible	O
in	O
a	O
video	O
davis	O
et	O
al	O
most	O
deep	O
learning	O
research	O
on	O
computer	B
vision	I
has	O
not	O
focused	O
on	O
such	O
chapter	O
applications	O
exotic	O
applications	O
that	O
expand	O
the	O
realm	O
of	O
what	O
is	O
possible	O
with	O
imagery	O
but	O
rather	O
a	O
small	O
core	O
of	O
ai	O
goals	O
aimed	O
at	O
replicating	O
human	O
abilities	O
most	O
deep	O
learning	O
for	O
computer	B
vision	I
is	O
used	O
for	O
object	B
recognition	I
or	O
detection	O
of	O
some	O
form	O
whether	O
this	O
means	O
reporting	O
which	O
object	O
is	O
present	O
in	O
an	O
image	O
annotating	O
an	O
image	O
with	O
bounding	O
boxes	O
around	O
each	O
object	O
transcribing	O
a	O
sequence	O
of	O
symbols	O
from	O
an	O
image	O
or	O
labeling	O
each	O
pixel	O
in	O
an	O
image	O
with	O
the	O
identity	O
of	O
the	O
object	O
it	O
belongs	O
to	O
because	O
generative	O
modeling	O
has	O
been	O
a	O
guiding	O
principle	O
of	O
deep	O
learning	O
research	O
there	O
is	O
also	O
a	O
large	O
body	O
of	O
work	O
on	O
image	O
synthesis	O
using	O
deep	O
models	O
while	O
image	O
synthesis	O
is	O
usually	O
not	O
considered	O
a	O
computer	B
vision	I
endeavor	O
models	O
capable	O
of	O
image	O
synthesis	O
are	O
usually	O
useful	O
for	O
image	O
restoration	O
a	O
computer	B
vision	I
task	O
involving	O
repairing	O
defects	O
in	O
images	O
or	O
removing	O
objects	O
from	O
images	O
ex	O
nihilo	O
preprocessing	B
many	O
application	O
areas	O
require	O
sophisticated	O
preprocessing	B
because	O
the	O
original	O
input	O
comes	O
in	O
a	O
form	O
that	O
is	O
difficult	O
for	O
many	O
deep	O
learning	O
architectures	O
to	O
represent	O
computer	B
vision	I
usually	O
requires	O
relatively	O
little	O
of	O
this	O
kind	O
of	O
preprocessing	B
the	O
images	O
should	O
be	O
standardized	O
so	O
that	O
their	O
pixels	O
all	O
lie	O
in	O
the	O
same	O
reasonable	O
range	O
like	O
or	O
mixing	O
images	O
that	O
lie	O
in	O
with	O
images	O
that	O
lie	O
in	O
will	O
usually	O
result	O
in	O
failure	O
formatting	O
images	O
to	O
have	O
the	O
same	O
scale	O
is	O
the	O
only	O
kind	O
of	O
preprocessing	B
that	O
is	O
strictly	O
necessary	O
many	O
computer	B
vision	I
architectures	O
require	O
images	O
of	O
a	O
standard	O
size	O
so	O
images	O
must	O
be	O
cropped	O
or	O
scaled	O
to	O
fit	O
that	O
size	O
even	O
this	O
rescaling	O
is	O
not	O
always	O
strictly	O
necessary	O
some	O
convolutional	O
models	O
accept	O
variably-sized	O
inputs	O
and	O
dynamically	O
adjust	O
the	O
size	O
of	O
their	O
pooling	O
regions	O
to	O
keep	O
the	O
output	O
size	O
constant	O
et	O
al	O
other	O
convolutional	O
models	O
have	O
variable-sized	O
output	O
that	O
automatically	O
scales	O
in	O
size	O
with	O
the	O
input	O
such	O
as	O
models	O
that	O
denoise	O
or	O
label	O
each	O
pixel	O
in	O
an	O
image	O
hadsell	O
et	O
al	O
dataset	B
augmentation	O
may	O
be	O
seen	O
as	O
a	O
way	O
of	O
preprocessing	B
the	O
training	O
set	O
only	O
dataset	B
augmentation	O
is	O
an	O
excellent	O
way	O
to	O
reduce	O
the	O
generalization	B
error	O
of	O
most	O
computer	B
vision	I
models	O
a	O
related	O
idea	O
applicable	O
at	O
test	O
time	O
is	O
to	O
show	O
the	O
model	O
many	O
different	O
versions	O
of	O
the	O
same	O
input	O
example	B
the	O
same	O
image	O
cropped	O
at	O
slightly	O
different	O
locations	O
and	O
have	O
the	O
different	O
instantiations	O
of	O
the	O
model	O
vote	O
to	O
determine	O
the	O
output	O
this	O
latter	O
idea	O
can	O
be	O
interpreted	O
as	O
an	O
ensemble	O
approach	O
and	O
helps	O
to	O
reduce	O
generalization	B
error	O
other	O
kinds	O
of	O
preprocessing	B
are	O
applied	O
to	O
both	O
the	O
train	O
and	O
the	O
test	B
set	I
with	O
the	O
goal	O
of	O
putting	O
each	O
example	B
into	O
a	O
more	O
canonical	O
form	O
in	O
order	O
to	O
reduce	O
the	O
amount	O
of	O
variation	O
that	O
the	O
model	O
needs	O
to	O
account	O
for	O
reducing	O
the	O
amount	O
of	O
chapter	O
applications	O
variation	O
in	O
the	O
data	O
can	O
both	O
reduce	O
generalization	B
error	O
and	O
reduce	O
the	O
size	O
of	O
the	O
model	O
needed	O
to	O
fit	O
the	O
training	O
set	O
simpler	O
tasks	O
may	O
be	O
solved	O
by	O
smaller	O
models	O
and	O
simpler	O
solutions	O
are	O
more	O
likely	O
to	O
generalize	O
well	O
preprocessing	B
of	O
this	O
kind	O
is	O
usually	O
designed	O
to	O
remove	O
some	O
kind	O
of	O
variability	O
in	O
the	O
input	O
data	O
that	O
is	O
easy	O
for	O
a	O
human	O
designer	O
to	O
describe	O
and	O
that	O
the	O
human	O
designer	O
is	O
confident	O
has	O
no	O
relevance	O
to	O
the	O
task	O
when	O
training	O
with	O
large	O
datasets	O
and	O
large	O
models	O
this	O
kind	O
of	O
preprocessing	B
is	O
often	O
unnecessary	O
and	O
it	O
is	O
best	O
to	O
just	O
let	O
the	O
model	O
learn	O
which	O
kinds	O
of	O
variability	O
it	O
should	O
become	O
invariant	O
to	O
for	O
example	B
the	O
alexnet	O
system	O
for	O
classifying	O
imagenet	O
only	O
has	O
one	O
preprocessing	B
step	O
subtracting	O
the	O
mean	O
across	O
training	O
examples	O
of	O
each	O
pixel	O
et	O
al	O
contrast	B
normalization	O
one	O
of	O
the	O
most	O
obvious	O
sources	O
of	O
variation	O
that	O
can	O
be	O
safely	O
removed	O
for	O
many	O
tasks	O
is	O
the	O
amount	O
of	O
contrast	B
in	O
the	O
image	O
contrast	B
simply	O
refers	O
to	O
the	O
magnitude	O
of	O
the	O
difference	O
between	O
the	O
bright	O
and	O
the	O
dark	O
pixels	O
in	O
an	O
image	O
there	O
are	O
many	O
ways	O
of	O
quantifying	O
the	O
contrast	B
of	O
an	O
image	O
in	O
the	O
context	O
of	O
deep	O
learning	O
contrast	B
usually	O
refers	O
to	O
the	O
standard	B
deviation	I
of	O
the	O
pixels	O
in	O
an	O
image	O
or	O
region	O
of	O
an	O
image	O
suppose	O
we	O
have	O
an	O
image	O
represented	O
by	O
a	O
tensor	O
with	O
being	O
the	O
red	O
intensity	O
at	O
row	O
i	O
and	O
column	O
j	O
giving	O
x	O
the	O
green	O
intensity	O
and	O
giving	O
the	O
blue	O
intensity	O
then	O
the	O
contrast	B
of	O
the	O
entire	O
image	O
is	O
given	O
by	O
r	O
c	O
r	O
x	O
xijk	O
where	O
x	O
is	O
the	O
mean	O
intensity	O
of	O
the	O
entire	O
image	O
r	O
c	O
x	O
r	O
c	O
xijk	O
global	B
contrast	B
normalization	I
aims	O
to	O
prevent	O
images	O
from	O
having	O
varying	O
amounts	O
of	O
contrast	B
by	O
subtracting	O
the	O
mean	O
from	O
each	O
image	O
then	O
rescaling	O
it	O
so	O
that	O
the	O
standard	B
deviation	I
across	O
its	O
pixels	O
is	O
equal	O
to	O
some	O
constant	O
s	O
this	O
approach	O
is	O
complicated	O
by	O
the	O
fact	O
that	O
no	O
scaling	O
factor	O
can	O
change	O
the	O
contrast	B
of	O
a	O
zero-contrast	O
image	O
whose	O
pixels	O
all	O
have	O
equal	O
intensity	O
images	O
with	O
very	O
low	O
but	O
non-zero	O
contrast	B
often	O
have	O
little	O
information	O
content	O
dividing	O
by	O
the	O
true	O
standard	B
deviation	I
usually	O
accomplishes	O
nothing	O
chapter	O
applications	O
more	O
than	O
amplifying	O
sensor	O
noise	O
or	O
compression	O
artifacts	O
in	O
such	O
cases	O
this	O
motivates	O
introducing	O
a	O
small	O
positive	O
regularization	O
parameter	O
to	O
bias	O
the	O
estimate	O
of	O
the	O
standard	B
deviation	I
alternately	O
one	O
can	O
constrain	O
the	O
denominator	O
to	O
be	O
at	O
least	O
given	O
an	O
input	O
image	O
x	O
gcn	O
produces	O
an	O
output	O
image	O
x	O
defined	O
such	O
that	O
x	O
xijk	O
ijk	O
s	O
x	O
max	O
r	O
c	O
xijk	O
x	O
datasets	O
consisting	O
of	O
large	O
images	O
cropped	O
to	O
interesting	O
objects	O
are	O
unlikely	O
to	O
contain	O
any	O
images	O
with	O
nearly	O
constant	O
intensity	O
in	O
these	O
cases	O
it	O
is	O
safe	O
to	O
practically	O
ignore	O
the	O
small	O
denominator	O
problem	O
by	O
setting	O
and	O
avoid	O
division	O
by	O
in	O
extremely	O
rare	O
cases	O
by	O
setting	O
to	O
an	O
extremely	O
low	O
value	O
like	O
on	O
the	O
dataset	B
small	O
images	O
cropped	O
randomly	O
are	O
more	O
likely	O
to	O
have	O
nearly	O
constant	O
intensity	O
making	O
aggressive	O
regularization	O
more	O
useful	O
used	O
and	O
on	O
small	O
randomly	O
selected	O
patches	O
drawn	O
from	O
this	O
is	O
the	O
approach	O
used	O
by	O
goodfellow	O
et	O
al	O
coates	O
et	O
al	O
the	O
scale	O
parameter	O
s	O
can	O
usually	O
be	O
set	O
to	O
as	O
done	O
by	O
or	O
chosen	O
to	O
make	O
each	O
individual	O
pixel	O
have	O
standard	B
deviation	I
across	O
examples	O
close	O
to	O
as	O
done	O
by	O
goodfellow	O
et	O
al	O
coates	O
et	O
al	O
is	O
just	O
a	O
rescaling	O
of	O
the	O
the	O
standard	B
deviation	I
in	O
equation	O
norm	O
of	O
the	O
image	O
the	O
mean	O
of	O
the	O
image	O
has	O
already	O
been	O
removed	O
it	O
is	O
preferable	O
to	O
define	O
gcn	O
in	O
terms	O
of	O
standard	B
deviation	I
rather	O
than	O
norm	O
because	O
the	O
standard	B
deviation	I
includes	O
division	O
by	O
the	O
number	O
of	O
pixels	O
so	O
gcn	O
based	O
on	O
standard	B
deviation	I
allows	O
the	O
same	O
s	O
to	O
be	O
used	O
regardless	O
of	O
image	O
size	O
however	O
the	O
observation	O
that	O
the	O
norm	O
is	O
proportional	O
to	O
the	O
standard	B
deviation	I
can	O
help	O
build	O
a	O
useful	O
intuition	O
one	O
can	O
understand	O
gcn	O
as	O
mapping	O
examples	O
to	O
a	O
spherical	O
shell	O
see	O
figure	O
for	O
an	O
illustration	O
this	O
can	O
be	O
a	O
useful	O
property	O
because	O
neural	O
networks	O
are	O
often	O
better	O
at	O
responding	O
to	O
directions	O
in	O
space	O
rather	O
than	O
exact	O
locations	O
responding	O
to	O
multiple	O
distances	O
in	O
the	O
same	O
direction	O
requires	O
hidden	O
units	O
with	O
collinear	O
weight	O
vectors	O
but	O
different	O
biases	O
such	O
coordination	O
can	O
be	O
difficult	O
for	O
the	O
learning	O
algorithm	O
to	O
discover	O
additionally	O
many	O
shallow	O
graphical	O
models	O
have	O
problems	O
with	O
representing	O
multiple	O
separated	O
modes	O
along	O
the	O
same	O
line	O
gcn	O
avoids	O
these	O
problems	O
by	O
reducing	O
each	O
example	B
to	O
a	O
direction	O
rather	O
than	O
a	O
direction	O
and	O
a	O
distance	O
counterintuitively	O
there	O
is	O
a	O
preprocessing	B
operation	B
known	O
as	O
sphering	O
and	O
it	O
is	O
not	O
the	O
same	O
operation	B
as	O
gcn	O
sphering	O
does	O
not	O
refer	O
to	O
making	O
the	O
data	O
lie	O
on	O
a	O
spherical	O
shell	O
but	O
rather	O
to	O
rescaling	O
the	O
principal	O
components	O
to	O
have	O
chapter	O
applications	O
raw	O
input	O
gcn	O
gcn	O
x	O
x	O
figure	O
gcn	O
maps	O
examples	O
onto	O
a	O
sphere	O
input	O
data	O
may	O
have	O
any	O
norm	O
with	O
maps	O
all	O
non-zero	O
examples	O
perfectly	O
onto	O
a	O
sphere	O
here	O
we	O
use	O
s	O
and	O
because	O
we	O
use	O
gcn	O
based	O
on	O
normalizing	O
the	O
standard	B
deviation	I
rather	O
than	O
the	O
norm	O
the	O
resulting	O
sphere	O
is	O
not	O
the	O
unit	O
sphere	O
gcn	O
with	O
draws	O
examples	O
toward	O
the	O
sphere	O
but	O
does	O
not	O
completely	O
discard	O
the	O
variation	O
in	O
their	O
norm	O
we	O
leave	O
and	O
the	O
same	O
as	O
before	O
s	O
equal	O
variance	O
so	O
that	O
the	O
multivariate	O
normal	O
distribution	O
used	O
by	O
pca	O
has	O
spherical	O
contours	O
sphering	O
is	O
more	O
commonly	O
known	O
as	O
whitening	B
global	B
contrast	B
normalization	I
will	O
often	O
fail	O
to	O
highlight	O
image	O
features	O
we	O
would	O
like	O
to	O
stand	O
out	O
such	O
as	O
edges	O
and	O
corners	O
if	O
we	O
have	O
a	O
scene	O
with	O
a	O
large	O
dark	O
area	O
and	O
a	O
large	O
bright	O
area	O
as	O
a	O
city	O
square	O
with	O
half	O
the	O
image	O
in	O
the	O
shadow	O
of	O
a	O
building	O
then	O
global	B
contrast	B
normalization	I
will	O
ensure	O
there	O
is	O
a	O
large	O
difference	O
between	O
the	O
brightness	O
of	O
the	O
dark	O
area	O
and	O
the	O
brightness	O
of	O
the	O
light	O
area	O
it	O
will	O
not	O
however	O
ensure	O
that	O
edges	O
within	O
the	O
dark	O
region	O
stand	O
out	O
this	O
motivates	O
local	B
contrast	B
normalization	I
local	B
contrast	B
normalization	I
ensures	O
that	O
the	O
contrast	B
is	O
normalized	O
across	O
each	O
small	O
window	O
rather	O
than	O
over	O
the	O
image	O
as	O
a	O
whole	O
see	O
figure	O
for	O
a	O
comparison	O
of	O
global	O
and	O
local	B
contrast	B
normalization	I
various	O
definitions	O
of	O
local	B
contrast	B
normalization	I
are	O
possible	O
in	O
all	O
cases	O
one	O
modifies	O
each	O
pixel	O
by	O
subtracting	O
a	O
mean	O
of	O
nearby	O
pixels	O
and	O
dividing	O
by	O
a	O
standard	B
deviation	I
of	O
nearby	O
pixels	O
in	O
some	O
cases	O
this	O
is	O
literally	O
the	O
mean	O
and	O
standard	B
deviation	I
of	O
all	O
pixels	O
in	O
a	O
rectangular	O
window	O
centered	O
on	O
the	O
pixel	O
to	O
be	O
modified	O
in	O
other	O
cases	O
this	O
is	O
a	O
weighted	O
mean	O
and	O
weighted	O
standard	B
deviation	I
using	O
gaussian	O
weights	B
centered	O
on	O
the	O
pixel	O
to	O
be	O
modified	O
in	O
the	O
case	O
of	O
color	B
images	I
some	O
strategies	O
process	O
different	O
color	O
pinto	O
et	O
al	O
chapter	O
applications	O
input	O
image	O
gcn	O
lcn	O
figure	O
a	O
comparison	O
of	O
global	O
and	O
local	B
contrast	B
normalization	I
visually	O
the	O
effects	O
of	O
global	B
contrast	B
normalization	I
are	O
subtle	O
it	O
places	O
all	O
images	O
on	O
roughly	O
the	O
same	O
scale	O
which	O
reduces	O
the	O
burden	O
on	O
the	O
learning	O
algorithm	O
to	O
handle	O
multiple	O
scales	O
local	B
contrast	B
normalization	I
modifies	O
the	O
image	O
much	O
more	O
discarding	O
all	O
regions	O
of	O
constant	O
intensity	O
this	O
allows	O
the	O
model	O
to	O
focus	O
on	O
just	O
the	O
edges	O
regions	O
of	O
fine	O
texture	O
such	O
as	O
the	O
houses	O
in	O
the	O
second	O
row	O
may	O
lose	O
some	O
detail	O
due	O
to	O
the	O
bandwidth	O
of	O
the	O
normalization	O
kernel	O
being	O
too	O
high	O
channels	O
separately	O
while	O
others	O
combine	O
information	O
from	O
different	O
channels	O
to	O
normalize	O
each	O
pixel	O
sermanet	O
et	O
al	O
local	B
contrast	B
normalization	I
can	O
usually	O
be	O
implemented	O
efficiently	O
by	O
using	O
separable	B
convolution	I
section	O
to	O
compute	O
feature	B
maps	O
of	O
local	O
means	O
and	O
local	O
standard	O
deviations	O
then	O
using	O
element-wise	O
subtraction	O
and	O
element-wise	O
division	O
on	O
different	O
feature	B
maps	O
local	B
contrast	B
normalization	I
is	O
a	O
differentiable	O
operation	B
and	O
can	O
also	O
be	O
used	O
as	O
a	O
nonlinearity	O
applied	O
to	O
the	O
hidden	O
layers	O
of	O
a	O
network	O
as	O
well	O
as	O
a	O
preprocessing	B
operation	B
applied	O
to	O
the	O
input	O
as	O
with	O
global	B
contrast	B
normalization	I
we	O
typically	O
need	O
to	O
regularize	O
local	B
contrast	B
normalization	I
to	O
avoid	O
division	O
by	O
zero	O
in	O
fact	O
because	O
local	B
contrast	B
normalization	I
typically	O
acts	O
on	O
smaller	O
windows	O
it	O
is	O
even	O
more	O
important	O
to	O
regularize	O
smaller	O
windows	O
are	O
more	O
likely	O
to	O
contain	O
values	O
that	O
are	O
all	O
nearly	O
the	O
same	O
as	O
each	O
other	O
and	O
thus	O
more	O
likely	O
to	O
have	O
zero	O
standard	B
deviation	I
chapter	O
applications	O
dataset	B
augmentation	O
as	O
described	O
in	O
section	O
it	O
is	O
easy	O
to	O
improve	O
the	O
generalization	B
of	O
a	O
classifier	O
by	O
increasing	O
the	O
size	O
of	O
the	O
training	O
set	O
by	O
adding	O
extra	O
copies	O
of	O
the	O
training	O
examples	O
that	O
have	O
been	O
modified	O
with	O
transformations	O
that	O
do	O
not	O
change	O
the	O
class	O
object	B
recognition	I
is	O
a	O
classification	B
task	O
that	O
is	O
especially	O
amenable	O
to	O
this	O
form	O
of	O
dataset	B
augmentation	O
because	O
the	O
class	O
is	O
invariant	O
to	O
so	O
many	O
transformations	O
and	O
the	O
input	O
can	O
be	O
easily	O
transformed	O
with	O
many	O
geometric	O
operations	O
as	O
described	O
before	O
classifiers	O
can	O
benefit	O
from	O
random	O
translations	O
rotations	O
and	O
in	O
some	O
cases	O
flips	O
of	O
the	O
input	O
to	O
augment	O
the	O
dataset	B
in	O
specialized	O
computer	B
vision	I
applications	O
more	O
advanced	O
transformations	O
are	O
commonly	O
used	O
for	O
dataset	B
augmentation	O
these	O
schemes	O
include	O
random	O
perturbation	O
of	O
the	O
colors	O
in	O
an	O
image	O
and	O
nonlinear	O
geometric	O
distortions	O
of	O
the	O
input	O
krizhevsky	O
et	O
al	O
lecun	O
et	O
al	O
speech	O
recognition	O
the	O
task	O
of	O
speech	O
recognition	O
is	O
to	O
map	O
an	O
acoustic	O
signal	O
containing	O
a	O
spoken	O
natural	O
language	O
utterance	O
into	O
the	O
corresponding	O
sequence	O
of	O
words	O
intended	O
by	O
the	O
speaker	O
let	O
x	O
x	O
denote	O
the	O
sequence	O
of	O
acoustic	O
input	O
vectors	O
produced	O
by	O
splitting	O
the	O
audio	O
into	O
frames	O
most	O
speech	O
recognition	O
systems	O
preprocess	O
the	O
input	O
using	O
specialized	O
hand-designed	O
features	O
but	O
some	O
deep	O
learning	O
systems	O
learn	O
features	O
from	O
raw	O
input	O
let	O
y	O
yn	O
denote	O
the	O
target	O
output	O
sequence	O
a	O
sequence	O
of	O
words	O
or	O
characters	O
the	O
automatic	B
speech	I
recognition	I
task	O
consists	O
of	O
creating	O
a	O
function	O
f	O
asr	O
that	O
computes	O
the	O
most	O
probable	O
linguistic	O
sequence	O
given	O
the	O
acoustic	O
sequence	O
jaitly	O
and	O
hinton	O
x	O
y	O
asr	O
f	O
x	O
arg	O
max	O
p	O
y	O
y	O
x	O
x	O
where	O
p	O
y	O
is	O
the	O
true	O
conditional	O
distribution	O
relating	O
the	O
inputs	O
x	O
to	O
the	O
targets	O
since	O
the	O
and	O
until	O
about	O
state-of-the	O
art	O
speech	O
recognition	O
systems	O
primarily	O
combined	O
hidden	O
markov	O
models	O
and	O
gaussian	O
mixture	O
models	O
gmms	O
modeled	O
the	O
association	O
between	O
acoustic	O
features	O
and	O
phonemes	O
while	O
hmms	O
modeled	O
the	O
sequence	O
of	O
phonemes	O
the	O
gmm-hmm	O
model	O
family	O
treats	O
acoustic	O
waveforms	O
as	O
being	O
generated	O
by	O
the	O
following	O
process	O
first	O
an	O
hmm	O
generates	O
a	O
sequence	O
of	O
phonemes	O
and	O
discrete	O
sub-phonemic	O
states	O
as	O
the	O
beginning	O
middle	O
and	O
end	O
of	O
each	O
bahl	O
et	O
al	O
chapter	O
applications	O
et	O
al	O
et	O
al	O
et	O
al	O
konig	O
phoneme	O
then	O
a	O
gmm	O
transforms	O
each	O
discrete	O
symbol	O
into	O
a	O
brief	O
segment	O
of	O
audio	O
waveform	O
although	O
gmm-hmm	O
systems	O
dominated	O
asr	O
until	O
recently	O
speech	O
recognition	O
was	O
actually	O
one	O
of	O
the	O
first	O
areas	O
where	O
neural	O
networks	O
were	O
applied	O
and	O
numerous	O
asr	O
systems	O
from	O
the	O
late	O
and	O
early	O
used	O
robinson	O
and	O
neural	O
nets	O
and	O
wellekens	O
waibel	O
fallside	O
bengio	O
at	O
the	O
time	O
the	O
performance	O
of	O
asr	O
based	O
on	O
neural	O
nets	O
approximately	O
matched	O
the	O
performance	O
of	O
gmm-hmm	O
systems	O
for	O
example	B
robinson	O
and	O
fallside	O
achieved	O
phoneme	O
error	O
rate	O
on	O
the	O
timit	O
corpus	O
phonemes	O
to	O
discriminate	O
between	O
which	O
was	O
better	O
than	O
or	O
comparable	O
to	O
hmm-based	O
systems	O
since	O
then	O
timit	O
has	O
been	O
a	O
benchmark	O
for	O
phoneme	O
recognition	O
playing	O
a	O
role	O
similar	O
to	O
the	O
role	O
mnist	O
plays	O
for	O
object	B
recognition	I
however	O
because	O
of	O
the	O
complex	O
engineering	O
involved	O
in	O
software	O
systems	O
for	O
speech	O
recognition	O
and	O
the	O
effort	O
that	O
had	O
been	O
invested	O
in	O
building	O
these	O
systems	O
on	O
the	O
basis	O
of	O
gmm-hmms	O
the	O
industry	O
did	O
not	O
see	O
a	O
compelling	O
argument	O
for	O
switching	O
to	O
neural	O
networks	O
as	O
a	O
consequence	O
until	O
the	O
late	O
both	O
academic	O
and	O
industrial	O
research	O
in	O
using	O
neural	O
nets	O
for	O
speech	O
recognition	O
mostly	O
focused	O
on	O
using	O
neural	O
nets	O
to	O
learn	O
extra	O
features	O
for	O
gmm-hmm	O
systems	O
garofolo	O
et	O
al	O
later	O
with	O
much	O
larger	O
and	O
deeper	O
models	O
and	O
much	O
larger	O
datasets	O
recognition	O
accuracy	B
was	O
dramatically	O
improved	O
by	O
using	O
neural	O
networks	O
to	O
replace	O
gmms	O
for	O
the	O
task	O
of	O
associating	O
acoustic	O
features	O
to	O
phonemes	O
sub-phonemic	O
states	O
starting	O
in	O
speech	O
researchers	O
applied	O
a	O
form	O
of	O
deep	O
learning	O
based	O
on	O
unsupervised	O
learning	O
to	O
speech	O
recognition	O
this	O
approach	O
to	O
deep	O
learning	O
was	O
based	O
on	O
training	O
undirected	O
probabilistic	O
models	O
called	O
restricted	O
boltzmann	O
machines	O
to	O
model	O
the	O
input	O
data	O
rbms	O
will	O
be	O
described	O
in	O
part	O
iii	O
to	O
solve	O
speech	O
recognition	O
tasks	O
unsupervised	B
pretraining	I
was	O
used	O
to	O
build	O
deep	O
feedforward	O
networks	O
whose	O
layers	O
were	O
each	O
initialized	O
by	O
training	O
an	O
rbm	O
these	O
networks	O
take	O
spectral	O
acoustic	O
representations	O
in	O
a	O
fixed-size	O
input	O
window	O
a	O
center	O
frame	O
and	O
predict	O
the	O
conditional	O
probabilities	O
of	O
hmm	O
states	O
for	O
that	O
center	O
frame	O
training	O
such	O
deep	O
networks	O
helped	O
to	O
significantly	O
improve	O
bringing	O
down	O
the	O
the	O
recognition	O
rate	O
on	O
timit	O
phoneme	O
error	O
rate	O
from	O
about	O
to	O
see	O
for	O
an	O
analysis	O
of	O
reasons	O
for	O
the	O
success	O
of	O
these	O
models	O
extensions	O
to	O
the	O
basic	O
phone	O
recognition	O
pipeline	O
included	O
the	O
addition	O
of	O
speaker-adaptive	O
features	O
et	O
al	O
that	O
further	O
reduced	O
the	O
error	O
rate	O
this	O
was	O
quickly	O
followed	O
up	O
by	O
work	O
to	O
expand	O
the	O
architecture	O
from	O
phoneme	O
recognition	O
is	O
what	O
timit	O
is	O
focused	O
on	O
to	O
large-vocabulary	O
speech	O
recognition	O
which	O
involves	O
not	O
just	O
recognizing	O
phonemes	O
but	O
also	O
recognizing	O
sequences	O
of	O
words	O
from	O
a	O
large	O
vocabulary	O
deep	O
networks	O
for	O
speech	O
recognition	O
eventually	O
mohamed	O
et	O
al	O
mohamed	O
et	O
al	O
dahl	O
et	O
al	O
chapter	O
applications	O
shifted	O
from	O
being	O
based	O
on	O
pretraining	O
and	O
boltzmann	O
machines	O
to	O
being	O
based	O
on	O
techniques	O
such	O
as	O
rectified	O
linear	O
units	O
and	O
dropout	O
zeiler	O
et	O
al	O
dahl	O
et	O
al	O
by	O
that	O
time	O
several	O
of	O
the	O
major	O
speech	O
groups	O
in	O
industry	O
had	O
started	O
exploring	O
deep	O
learning	O
in	O
collaboration	O
with	O
academic	O
researchers	O
hinton	O
et	O
al	O
describe	O
the	O
breakthroughs	O
achieved	O
by	O
these	O
collaborators	O
which	O
are	O
now	O
deployed	O
in	O
products	O
such	O
as	O
mobile	O
phones	O
later	O
as	O
these	O
groups	O
explored	O
larger	O
and	O
larger	O
labeled	O
datasets	O
and	O
incorporated	O
some	O
of	O
the	O
methods	O
for	O
initializing	O
training	O
and	O
setting	O
up	O
the	O
architecture	O
of	O
deep	O
nets	O
they	O
realized	O
that	O
the	O
unsupervised	B
pretraining	I
phase	O
was	O
either	O
unnecessary	O
or	O
did	O
not	O
bring	O
any	O
significant	O
improvement	O
these	O
breakthroughs	O
in	O
recognition	O
performance	O
for	O
word	O
error	O
rate	O
in	O
speech	O
recognition	O
were	O
unprecedented	O
improvement	O
and	O
were	O
following	O
a	O
long	O
period	O
of	O
about	O
ten	O
years	O
during	O
which	O
error	O
rates	O
did	O
not	O
improve	O
much	O
with	O
the	O
traditional	O
gmm-hmm	O
technology	O
in	O
spite	O
of	O
the	O
continuously	O
growing	O
size	O
of	O
training	O
sets	O
figure	O
of	O
deng	O
and	O
yu	O
this	O
created	O
a	O
rapid	O
shift	O
in	O
the	O
speech	O
recognition	O
community	O
towards	O
deep	O
learning	O
in	O
a	O
matter	O
of	O
roughly	O
two	O
years	O
most	O
of	O
the	O
industrial	O
products	O
for	O
speech	O
recognition	O
incorporated	O
deep	O
neural	O
networks	O
and	O
this	O
success	O
spurred	O
a	O
new	O
wave	O
of	O
research	O
into	O
deep	O
learning	O
algorithms	O
and	O
architectures	O
for	O
asr	O
which	O
is	O
still	O
ongoing	O
today	O
one	O
of	O
these	O
innovations	O
was	O
the	O
use	O
of	O
convolutional	O
networks	O
sainath	O
et	O
al	O
that	O
replicate	O
weights	B
across	O
time	O
and	O
frequency	O
improving	O
over	O
the	O
earlier	O
time-delay	O
neural	O
networks	O
that	O
replicated	O
weights	B
only	O
across	O
time	O
the	O
new	O
two-dimensional	O
convolutional	O
models	O
regard	O
the	O
input	O
spectrogram	O
not	O
as	O
one	O
long	O
vector	O
but	O
as	O
an	O
image	O
with	O
one	O
axis	O
corresponding	O
to	O
time	O
and	O
the	O
other	O
to	O
frequency	O
of	O
spectral	O
components	O
another	O
important	O
push	O
still	O
ongoing	O
has	O
been	O
towards	O
end-to-end	O
deep	O
learning	O
speech	O
recognition	O
systems	O
that	O
completely	O
remove	O
the	O
hmm	O
the	O
first	O
major	O
breakthrough	O
in	O
this	O
direction	O
came	O
from	O
graves	O
who	O
trained	O
using	O
map	O
inference	O
over	O
the	O
frame-toa	O
deep	O
lstm	O
rnn	O
section	O
phoneme	O
alignment	O
as	O
in	O
graves	O
has	O
state	O
variables	O
et	O
al	O
graves	O
from	O
several	O
layers	O
at	O
each	O
time	O
step	O
giving	O
the	O
unfolded	O
graph	O
two	O
kinds	O
of	O
depth	O
ordinary	O
depth	O
due	O
to	O
a	O
stack	O
of	O
layers	O
and	O
depth	O
due	O
to	O
time	O
unfolding	O
this	O
work	O
brought	O
the	O
phoneme	O
error	O
rate	O
on	O
timit	O
to	O
a	O
record	O
low	O
of	O
see	O
pascanu	O
for	O
other	O
variants	O
of	O
deep	O
rnns	O
applied	O
in	O
other	O
settings	O
lecun	O
et	O
al	O
a	O
deep	O
rnn	O
and	O
in	O
the	O
ctc	O
framework	O
et	O
al	O
et	O
al	O
graves	O
et	O
al	O
and	O
et	O
al	O
chung	O
another	O
contemporary	O
step	O
toward	O
end-to-end	O
deep	O
learning	O
asr	O
is	O
to	O
let	O
the	O
system	O
learn	O
how	O
to	O
align	O
the	O
acoustic-level	O
information	O
with	O
the	O
phonetic-level	O
chapter	O
applications	O
information	O
chorowski	O
et	O
al	O
lu	O
et	O
al	O
natural	B
language	I
processing	I
natural	B
language	I
processing	I
is	O
the	O
use	O
of	O
human	O
languages	O
such	O
as	O
english	O
or	O
french	O
by	O
a	O
computer	O
computer	O
programs	O
typically	O
read	O
and	O
emit	O
specialized	O
languages	O
designed	O
to	O
allow	O
efficient	O
and	O
unambiguous	O
parsing	O
by	O
simple	O
programs	O
more	O
naturally	O
occurring	O
languages	O
are	O
often	O
ambiguous	O
and	O
defy	O
formal	O
description	O
natural	B
language	I
processing	I
includes	O
applications	O
such	O
as	O
machine	B
translation	I
in	O
which	O
the	O
learner	O
must	O
read	O
a	O
sentence	O
in	O
one	O
human	O
language	O
and	O
emit	O
an	O
equivalent	O
sentence	O
in	O
another	O
human	O
language	O
many	O
nlp	O
applications	O
are	O
based	O
on	O
language	O
models	O
that	O
define	O
a	O
probability	B
distribution	I
over	O
sequences	O
of	O
words	O
characters	O
or	O
bytes	O
in	O
a	O
natural	O
language	O
as	O
with	O
the	O
other	O
applications	O
discussed	O
in	O
this	O
chapter	O
very	O
generic	O
neural	B
network	I
techniques	O
can	O
be	O
successfully	O
applied	O
to	O
natural	B
language	I
processing	I
however	O
to	O
achieve	O
excellent	O
performance	O
and	O
to	O
scale	O
well	O
to	O
large	O
applications	O
some	O
domain-specific	O
strategies	O
become	O
important	O
to	O
build	O
an	O
efficient	O
model	O
of	O
natural	O
language	O
we	O
must	O
usually	O
use	O
techniques	O
that	O
are	O
specialized	O
for	O
processing	O
sequential	O
data	O
in	O
many	O
cases	O
we	O
choose	O
to	O
regard	O
natural	O
language	O
as	O
a	O
sequence	O
of	O
words	O
rather	O
than	O
a	O
sequence	O
of	O
individual	O
characters	O
or	O
bytes	O
because	O
the	O
total	O
number	O
of	O
possible	O
words	O
is	O
so	O
large	O
word-based	O
language	O
models	O
must	O
operate	O
on	O
an	O
extremely	O
high-dimensional	O
and	O
sparse	O
discrete	O
space	O
several	O
strategies	O
have	O
been	O
developed	O
to	O
make	O
models	O
of	O
such	O
a	O
space	O
efficient	O
both	O
in	O
a	O
computational	O
and	O
in	O
a	O
statistical	O
sense	O
n	O
a	O
language	O
model	O
defines	O
a	O
probability	B
distribution	I
over	O
sequences	O
of	O
tokens	O
in	O
a	O
natural	O
language	O
depending	O
on	O
how	O
the	O
model	O
is	O
designed	O
a	O
token	O
may	O
be	O
a	O
word	O
a	O
character	O
or	O
even	O
a	O
byte	O
tokens	O
are	O
always	O
discrete	O
entities	O
the	O
earliest	O
successful	O
language	O
models	O
were	O
based	O
on	O
models	O
of	O
fixed-length	O
sequences	O
of	O
tokens	O
called	O
an	O
is	O
a	O
sequence	O
of	O
tokens	O
n	O
n	O
n	O
models	O
based	O
on	O
n-grams	O
define	O
the	O
conditional	B
probability	I
of	O
the	O
n-th	O
token	O
tokens	O
the	O
model	O
uses	O
products	O
of	O
these	O
conditional	O
given	O
the	O
preceding	O
n	O
distributions	O
to	O
define	O
the	O
probability	B
distribution	I
over	O
longer	O
sequences	O
p	O
x	O
x	O
xn	O
p	O
x	O
t	O
xt	O
n	O
xt	O
t	O
n	O
chapter	O
applications	O
this	O
decomposition	O
is	O
justified	O
by	O
the	O
chain	B
rule	I
of	I
probability	I
the	O
probability	B
distribution	I
over	O
the	O
initial	O
sequence	O
p	O
xn	O
may	O
be	O
modeled	O
by	O
a	O
different	O
model	O
with	O
a	O
smaller	O
value	O
of	O
training	O
n-gram	B
models	O
is	O
straightforward	O
because	O
the	O
maximum	B
likelihood	I
estimate	O
can	O
be	O
computed	O
simply	O
by	O
counting	O
how	O
many	O
times	O
each	O
possible	O
n	O
gram	O
occurs	O
in	O
the	O
training	O
set	O
models	O
based	O
on	O
n-grams	O
have	O
been	O
the	O
core	O
building	O
block	O
of	O
statistical	O
language	O
modeling	O
for	O
many	O
decades	O
and	O
mercer	O
katz	O
chen	O
and	O
goodman	O
for	O
small	O
values	O
of	O
n	O
models	O
have	O
particular	O
names	O
unigram	B
for	O
bigram	B
for	O
and	O
trigram	B
for	O
these	O
names	O
derive	O
from	O
the	O
latin	O
prefixes	O
for	O
the	O
corresponding	O
numbers	O
and	O
the	O
greek	O
suffix	O
denoting	O
something	O
that	O
is	O
written	O
usually	O
we	O
train	O
both	O
an	O
n-gram	B
model	O
and	O
an	O
n	O
this	O
makes	O
it	O
easy	O
to	O
compute	O
gram	O
model	O
simultaneously	O
p	O
x	O
t	O
xt	O
n	O
xt	O
pnxt	O
n	O
n	O
pn	O
xt	O
xt	O
simply	O
by	O
looking	O
up	O
two	O
stored	O
probabilities	O
for	O
this	O
to	O
exactly	O
reproduce	O
inference	O
in	O
pn	O
we	O
must	O
omit	O
the	O
final	O
character	O
from	O
each	O
sequence	O
when	O
we	O
train	O
p	O
n	O
as	O
an	O
example	B
we	O
demonstrate	O
how	O
a	O
trigram	B
model	O
computes	O
the	O
probability	O
of	O
the	O
sentence	O
the	O
dog	O
ran	O
away	O
the	O
first	O
words	O
of	O
the	O
sentence	O
cannot	O
be	O
handled	O
by	O
the	O
default	O
formula	O
based	O
on	O
conditional	B
probability	I
because	O
there	O
is	O
no	O
context	O
at	O
the	O
beginning	O
of	O
the	O
sentence	O
instead	O
we	O
must	O
use	O
the	O
marginal	B
probability	I
over	O
words	O
at	O
the	O
start	O
of	O
the	O
sentence	O
we	O
thus	O
evaluate	O
dog	O
ran	O
finally	O
the	O
last	O
word	O
may	O
be	O
predicted	O
using	O
the	O
typical	O
case	O
of	O
using	O
the	O
conditional	O
distribution	O
paway	O
dog	O
ran	O
we	O
obtain	O
putting	O
this	O
together	O
with	O
equation	O
p	O
p	O
the	O
dog	O
ran	O
away	O
the	O
dog	O
ran	O
dog	O
ran	O
away	O
dog	O
ran	O
a	O
fundamental	O
limitation	O
of	O
maximum	B
likelihood	I
for	O
n-gram	B
models	O
is	O
that	O
pn	O
as	O
estimated	O
from	O
training	O
set	O
counts	O
is	O
very	O
likely	O
to	O
be	O
zero	O
in	O
many	O
cases	O
even	O
though	O
the	O
tuple	O
t	O
n	O
xt	O
may	O
appear	O
in	O
the	O
test	B
set	I
this	O
can	O
cause	O
two	O
different	O
kinds	O
of	O
catastrophic	O
outcomes	O
when	O
pn	O
is	O
zero	O
the	O
ratio	O
is	O
undefined	O
so	O
the	O
model	O
does	O
not	O
even	O
produce	O
a	O
sensible	O
output	O
when	O
pn	O
is	O
non-zero	O
but	O
pn	O
is	O
zero	O
the	O
test	O
log-likelihood	O
is	O
to	O
avoid	O
such	O
catastrophic	O
outcomes	O
most	O
n-gram	B
models	O
employ	O
some	O
form	O
of	O
smoothing	O
smoothing	O
techniques	O
chapter	O
applications	O
chen	O
and	O
goodman	O
shift	O
probability	O
mass	O
from	O
the	O
observed	O
tuples	O
to	O
unobserved	O
ones	O
that	O
are	O
similar	O
see	O
for	O
a	O
review	O
and	O
empirical	O
comparisons	O
one	O
basic	O
technique	O
consists	O
of	O
adding	O
non-zero	O
probability	O
mass	O
to	O
all	O
of	O
the	O
possible	O
next	O
symbol	O
values	O
this	O
method	O
can	O
be	O
justified	O
as	O
bayesian	O
inference	O
with	O
a	O
uniform	O
or	O
dirichlet	O
prior	O
over	O
the	O
count	O
parameters	O
another	O
very	O
popular	O
idea	O
is	O
to	O
form	O
a	O
mixture	O
model	O
containing	O
higher-order	O
and	O
lower-order	O
n-gram	B
models	O
with	O
the	O
higher-order	O
models	O
providing	O
more	O
capacity	O
and	O
the	O
lower-order	O
models	O
being	O
more	O
likely	O
to	O
avoid	O
counts	O
of	O
zero	O
back-off	O
methods	O
look-up	O
the	O
lower-order	O
n-grams	O
if	O
the	O
frequency	O
of	O
the	O
context	O
xt	O
x	O
t	O
n	O
is	O
too	O
small	O
to	O
use	O
the	O
higher-order	O
model	O
more	O
formally	O
they	O
estimate	O
the	O
distribution	O
over	O
xt	O
by	O
using	O
contexts	O
xt	O
n	O
k	O
for	O
increasing	O
k	O
until	O
a	O
sufficiently	O
reliable	O
estimate	O
is	O
xt	O
found	O
v	O
n	O
possible	O
n-grams	O
and	O
classical	O
n-gram	B
models	O
are	O
particularly	O
vulnerable	O
to	O
the	O
curse	B
of	I
dimensionality	I
there	O
are	O
v	O
is	O
often	O
very	O
large	O
even	O
with	O
a	O
massive	O
training	O
set	O
and	O
modest	O
n	O
most	O
n-grams	O
will	O
not	O
occur	O
in	O
the	O
training	O
set	O
one	O
way	O
to	O
view	O
a	O
classical	O
n-gram	B
model	O
is	O
that	O
it	O
is	O
performing	O
nearest-neighbor	O
lookup	O
in	O
other	O
words	O
it	O
can	O
be	O
viewed	O
as	O
a	O
local	O
non-parametric	O
predictor	O
similar	O
to	O
k-nearest	O
neighbors	O
the	O
statistical	O
problems	O
facing	O
these	O
extremely	O
local	O
predictors	O
are	O
described	O
in	O
section	O
the	O
problem	O
for	O
a	O
language	O
model	O
is	O
even	O
more	O
severe	O
than	O
usual	O
because	O
any	O
two	O
different	O
words	O
have	O
the	O
same	O
distance	O
from	O
each	O
other	O
in	O
one-hot	O
vector	O
space	O
it	O
is	O
thus	O
difficult	O
to	O
leverage	O
much	O
information	O
from	O
any	O
neighbors	O
only	O
training	O
examples	O
that	O
repeat	O
literally	O
the	O
same	O
context	O
are	O
useful	O
for	O
local	O
generalization	B
to	O
overcome	O
these	O
problems	O
a	O
language	O
model	O
must	O
be	O
able	O
to	O
share	O
knowledge	O
between	O
one	O
word	O
and	O
other	O
semantically	O
similar	O
words	O
et	O
al	O
et	O
al	O
ney	O
and	O
kneser	O
niesler	O
to	O
improve	O
the	O
statistical	O
efficiency	O
of	O
n-gram	B
models	O
class-based	B
language	I
models	I
introduce	O
the	O
notion	O
of	O
word	O
categories	O
and	O
then	O
share	O
statistical	O
strength	O
between	O
words	O
that	O
are	O
in	O
the	O
same	O
category	O
the	O
idea	O
is	O
to	O
use	O
a	O
clustering	O
algorithm	O
to	O
partition	O
the	O
set	O
of	O
words	O
into	O
clusters	O
or	O
classes	O
based	O
on	O
their	O
co-occurrence	O
frequencies	O
with	O
other	O
words	O
the	O
model	O
can	O
then	O
use	O
word	O
class	O
ids	O
rather	O
than	O
individual	O
word	O
ids	O
to	O
represent	O
the	O
context	O
on	O
the	O
right	O
side	O
of	O
the	O
conditioning	O
bar	O
composite	O
models	O
combining	O
word-based	O
and	O
class-based	O
models	O
via	O
mixing	O
or	O
back-off	O
are	O
also	O
possible	O
although	O
word	O
classes	O
provide	O
a	O
way	O
to	O
generalize	O
between	O
sequences	O
in	O
which	O
some	O
word	O
is	O
replaced	O
by	O
another	O
of	O
the	O
same	O
class	O
much	O
information	O
is	O
lost	O
in	O
this	O
representation	O
chapter	O
applications	O
neural	O
language	O
models	O
neural	O
language	O
models	O
or	O
nlms	O
are	O
a	O
class	O
of	O
language	O
model	O
designed	O
to	O
overcome	O
the	O
curse	B
of	I
dimensionality	I
problem	O
for	O
modeling	O
natural	O
language	O
sequences	O
by	O
using	O
a	O
distributed	O
representation	O
of	O
words	O
bengio	O
et	O
al	O
unlike	O
class-based	O
n-gram	B
models	O
neural	O
language	O
models	O
are	O
able	O
to	O
recognize	O
that	O
two	O
words	O
are	O
similar	O
without	O
losing	O
the	O
ability	O
to	O
encode	O
each	O
word	O
as	O
distinct	O
from	O
the	O
other	O
neural	O
language	O
models	O
share	O
statistical	O
strength	O
between	O
one	O
word	O
its	O
context	O
and	O
other	O
similar	O
words	O
and	O
contexts	O
the	O
distributed	O
representation	O
the	O
model	O
learns	O
for	O
each	O
word	O
enables	O
this	O
sharing	O
by	O
allowing	O
the	O
model	O
to	O
treat	O
words	O
that	O
have	O
features	O
in	O
common	O
similarly	O
for	O
example	B
if	O
the	O
word	O
dog	O
and	O
the	O
word	O
cat	O
map	O
to	O
representations	O
that	O
share	O
many	O
attributes	O
then	O
sentences	O
that	O
contain	O
the	O
word	O
cat	O
can	O
inform	O
the	O
predictions	O
that	O
will	O
be	O
made	O
by	O
the	O
model	O
for	O
sentences	O
that	O
contain	O
the	O
word	O
dog	O
and	O
vice-versa	O
because	O
there	O
are	O
many	O
such	O
attributes	O
there	O
are	O
many	O
ways	O
in	O
which	O
generalization	B
can	O
happen	O
transferring	O
information	O
from	O
each	O
training	O
sentence	O
to	O
an	O
exponentially	O
large	O
number	O
of	O
semantically	O
related	O
sentences	O
the	O
curse	B
of	I
dimensionality	I
requires	O
the	O
model	O
to	O
generalize	O
to	O
a	O
number	O
of	O
sentences	O
that	O
is	O
exponential	O
in	O
the	O
sentence	O
length	O
the	O
model	O
counters	O
this	O
curse	O
by	O
relating	O
each	O
training	O
sentence	O
to	O
an	O
exponential	O
number	O
of	O
similar	O
sentences	O
we	O
sometimes	O
call	O
these	O
word	O
representations	O
word	O
embeddings	O
in	O
this	O
interpretation	O
we	O
view	O
the	O
raw	O
symbols	O
as	O
points	O
in	O
a	O
space	O
of	O
dimension	O
equal	O
to	O
the	O
vocabulary	O
size	O
the	O
word	O
representations	O
embed	O
those	O
points	O
in	O
a	O
feature	B
space	O
of	O
lower	O
dimension	O
in	O
the	O
original	O
space	O
every	O
word	O
is	O
represented	O
by	O
from	O
each	O
a	O
one-hot	O
vector	O
so	O
every	O
pair	O
of	O
words	O
is	O
at	O
euclidean	O
distance	O
other	O
in	O
the	O
embedding	B
space	O
words	O
that	O
frequently	O
appear	O
in	O
similar	O
contexts	O
any	O
pair	O
of	O
words	O
sharing	O
some	O
features	O
learned	O
by	O
the	O
model	O
are	O
close	O
to	O
each	O
other	O
this	O
often	O
results	O
in	O
words	O
with	O
similar	O
meanings	O
being	O
neighbors	O
figure	O
zooms	O
in	O
on	O
specific	O
areas	O
of	O
a	O
learned	O
word	B
embedding	B
space	O
to	O
show	O
how	O
semantically	O
similar	O
words	O
map	O
to	O
representations	O
that	O
are	O
close	O
to	O
each	O
other	O
neural	O
networks	O
in	O
other	O
domains	O
also	O
define	O
embeddings	O
for	O
example	B
a	O
hidden	B
layer	I
of	O
a	O
convolutional	B
network	I
provides	O
an	O
image	O
embedding	B
usually	O
nlp	O
practitioners	O
are	O
much	O
more	O
interested	O
in	O
this	O
idea	O
of	O
embeddings	O
because	O
natural	O
language	O
does	O
not	O
originally	O
lie	O
in	O
a	O
real-valued	O
vector	O
space	O
the	O
hidden	B
layer	I
has	O
provided	O
a	O
more	O
qualitatively	O
dramatic	O
change	O
in	O
the	O
way	O
the	O
data	O
is	O
represented	O
the	O
basic	O
idea	O
of	O
using	O
distributed	O
representations	O
to	O
improve	O
models	O
for	O
natural	B
language	I
processing	I
is	O
not	O
restricted	O
to	O
neural	O
networks	O
it	O
may	O
also	O
be	O
used	O
with	O
graphical	O
models	O
that	O
have	O
distributed	O
representations	O
in	O
the	O
form	O
of	O
chapter	O
applications	O
multiple	O
latent	O
variables	O
and	O
hinton	O
france	O
china	O
russian	O
french	O
english	O
germany	O
ontario	O
iraq	O
japan	O
europe	O
eu	O
unionafrican	O
africa	O
assembly	O
european	O
british	O
canada	O
canadian	O
north	O
south	O
figure	O
two-dimensional	O
visualizations	O
of	O
word	O
embeddings	O
obtained	O
from	O
a	O
neural	O
machine	B
translation	I
model	O
zooming	O
in	O
on	O
specific	O
areas	O
where	O
semantically	O
related	O
words	O
have	O
embedding	B
vectors	O
that	O
are	O
close	O
to	O
each	O
other	O
countries	O
appear	O
on	O
the	O
left	O
and	O
numbers	O
on	O
the	O
right	O
keep	O
in	O
mind	O
that	O
these	O
embeddings	O
are	O
for	O
the	O
purpose	O
of	O
visualization	O
in	O
real	O
applications	O
embeddings	O
typically	O
have	O
higher	O
dimensionality	O
and	O
can	O
simultaneously	O
capture	O
many	O
kinds	O
of	O
similarity	O
between	O
words	O
bahdanau	O
et	O
al	O
high-dimensional	O
outputs	O
in	O
many	O
natural	O
language	O
applications	O
we	O
often	O
want	O
our	O
models	O
to	O
produce	O
words	O
than	O
characters	O
as	O
the	O
fundamental	O
unit	O
of	O
the	O
output	O
for	O
large	O
vocabularies	O
it	O
can	O
be	O
very	O
computationally	O
expensive	O
to	O
represent	O
an	O
output	O
distribution	O
over	O
the	O
choice	O
of	O
a	O
word	O
because	O
the	O
vocabulary	O
size	O
is	O
large	O
in	O
many	O
applications	O
v	O
contains	O
hundreds	O
of	O
thousands	O
of	O
words	O
the	O
naive	O
approach	O
to	O
representing	O
such	O
a	O
distribution	O
is	O
to	O
apply	O
an	O
affine	B
transformation	O
from	O
a	O
hidden	O
representation	O
to	O
the	O
output	O
space	O
then	O
apply	O
the	O
softmax	O
function	O
suppose	O
we	O
have	O
a	O
vocabulary	O
v	O
with	O
size	O
v	O
the	O
weight	O
matrix	O
describing	O
the	O
linear	O
component	O
of	O
this	O
affine	B
transformation	O
is	O
very	O
large	O
because	O
its	O
output	O
dimension	O
is	O
v	O
this	O
imposes	O
a	O
high	O
memory	O
cost	O
to	O
represent	O
the	O
matrix	O
and	O
a	O
high	O
computational	O
cost	O
to	O
multiply	O
by	O
it	O
because	O
the	O
softmax	O
is	O
normalized	O
across	O
all	O
v	O
outputs	O
it	O
is	O
necessary	O
to	O
perform	O
the	O
full	O
matrix	O
multiplication	O
at	O
training	O
time	O
as	O
well	O
as	O
test	O
time	O
we	O
cannot	O
calculate	O
only	O
the	O
dot	O
product	O
with	O
the	O
weight	O
vector	O
for	O
the	O
correct	O
output	O
the	O
high	O
computational	O
costs	O
of	O
the	O
output	O
layer	O
thus	O
arise	O
both	O
at	O
training	O
time	O
compute	O
the	O
likelihood	O
and	O
its	O
gradient	B
and	O
at	O
test	O
time	O
compute	O
probabilities	O
for	O
all	O
or	O
selected	O
words	O
for	O
specialized	O
chapter	O
applications	O
but	O
loss	O
functions	O
the	O
gradient	B
can	O
be	O
computed	O
efficiently	O
the	O
standard	O
cross-entropy	B
loss	O
applied	O
to	O
a	O
traditional	O
softmax	O
output	O
layer	O
poses	O
many	O
difficulties	O
vincent	O
et	O
al	O
suppose	O
that	O
h	O
is	O
the	O
top	O
hidden	B
layer	I
used	O
to	O
predict	O
the	O
output	O
probabilities	O
y	O
if	O
we	O
parametrize	O
the	O
transformation	O
from	O
h	O
to	O
y	O
with	O
learned	O
weights	B
w	O
and	O
learned	O
biases	O
b	O
then	O
the	O
affine-softmax	O
output	O
layer	O
performs	O
the	O
following	O
computations	O
ai	O
bi	O
wijhj	O
i	O
v	O
yi	O
j	O
eai	O
ea	O
i	O
v	O
i	O
v	O
n	O
h	O
with	O
nh	O
in	O
the	O
v	O
in	O
the	O
hundreds	O
of	O
thousands	O
this	O
operation	B
dominates	O
the	O
if	O
h	O
contains	O
nh	O
elements	O
then	O
the	O
above	O
operation	B
is	O
o	O
thousands	O
and	O
computation	O
of	O
most	O
neural	O
language	O
models	O
use	O
of	O
a	O
short	O
list	O
bengio	O
et	O
al	O
the	O
first	O
neural	O
language	O
models	O
dealt	O
with	O
the	O
high	O
cost	O
of	O
using	O
a	O
softmax	O
over	O
a	O
large	O
number	O
of	O
output	O
words	O
by	O
limiting	O
the	O
vocabulary	O
size	O
to	O
or	O
words	O
schwenk	O
and	O
gauvain	O
schwenk	O
and	O
built	O
upon	O
this	O
approach	O
by	O
splitting	O
the	O
vocabulary	O
v	O
into	O
a	O
shortlist	B
l	O
of	O
most	O
frequent	O
words	O
by	O
the	O
neural	O
net	O
and	O
a	O
tail	O
t	O
v	O
l	O
of	O
more	O
rare	O
words	O
by	O
an	O
n-gram	B
model	O
to	O
be	O
able	O
to	O
combine	O
the	O
two	O
predictions	O
the	O
neural	O
net	O
also	O
has	O
to	O
predict	O
the	O
probability	O
that	O
a	O
word	O
appearing	O
after	O
context	O
c	O
belongs	O
to	O
the	O
tail	O
list	O
this	O
may	O
be	O
achieved	O
by	O
adding	O
an	O
extra	O
sigmoid	O
output	O
unit	O
to	O
provide	O
an	O
estimate	O
of	O
p	O
the	O
extra	O
output	O
can	O
then	O
be	O
used	O
to	O
achieve	O
an	O
estimate	O
of	O
the	O
probability	B
distribution	I
over	O
all	O
words	O
in	O
as	O
follows	O
c	O
t	O
v	O
i	O
c	O
p	O
y	O
i	O
c	O
i	O
i	O
c	O
i	O
l	O
p	O
y	O
p	O
y	O
t	O
t	O
p	O
i	O
p	O
i	O
t	O
t	O
c	O
c	O
l	O
is	O
provided	O
by	O
the	O
neural	O
language	O
model	O
and	O
p	O
i	O
where	O
p	O
i	O
c	O
i	O
t	O
is	O
provided	O
by	O
the	O
n-gram	B
model	O
with	O
slight	O
modification	O
this	O
approach	O
c	O
i	O
can	O
also	O
work	O
using	O
an	O
extra	O
output	O
value	O
in	O
the	O
neural	O
language	O
model	O
s	O
softmax	O
layer	O
rather	O
than	O
a	O
separate	O
sigmoid	O
unit	O
an	O
obvious	O
disadvantage	O
of	O
the	O
short	O
list	O
approach	O
is	O
that	O
the	O
potential	O
generalization	B
advantage	O
of	O
the	O
neural	O
language	O
models	O
is	O
limited	O
to	O
the	O
most	O
frequent	O
chapter	O
applications	O
words	O
where	O
arguably	O
it	O
is	O
the	O
least	O
useful	O
this	O
disadvantage	O
has	O
stimulated	O
the	O
exploration	B
of	O
alternative	O
methods	O
to	O
deal	O
with	O
high-dimensional	O
outputs	O
described	O
below	O
hierarchical	O
softmax	O
goodman	O
to	O
reducing	O
the	O
computational	O
burden	O
a	O
classical	O
approach	O
of	O
high-dimensional	O
output	O
layers	O
over	O
large	O
vocabulary	O
sets	O
v	O
is	O
to	O
decompose	O
probabilities	O
hierarchically	O
instead	O
of	O
necessitating	O
a	O
number	O
of	O
computations	O
v	O
also	O
proportional	O
to	O
the	O
number	O
of	O
hidden	O
units	O
nh	O
proportional	O
to	O
the	O
morin	O
and	O
bengio	O
introduced	O
this	O
factorized	O
approach	O
to	O
the	O
context	O
of	O
neural	O
language	O
models	O
v	O
factor	O
can	O
be	O
reduced	O
to	O
as	O
low	O
as	O
log	O
bengio	O
v	O
and	O
one	O
can	O
think	O
of	O
this	O
hierarchy	O
as	O
building	O
categories	O
of	O
words	O
then	O
categories	O
of	O
categories	O
of	O
words	O
then	O
categories	O
of	O
categories	O
of	O
categories	O
of	O
words	O
etc	O
these	O
nested	O
categories	O
form	O
a	O
tree	O
with	O
words	O
at	O
the	O
leaves	O
in	O
a	O
balanced	O
tree	O
the	O
tree	O
has	O
depth	O
olog	O
v	O
the	O
probability	O
of	O
a	O
choosing	O
a	O
word	O
is	O
given	O
by	O
the	O
product	O
of	O
the	O
probabilities	O
of	O
choosing	O
the	O
branch	O
leading	O
to	O
that	O
word	O
at	O
every	O
node	O
on	O
a	O
path	O
from	O
the	O
root	O
of	O
the	O
tree	O
to	O
the	O
leaf	O
containing	O
the	O
word	O
figure	O
also	O
describe	O
how	O
to	O
use	O
multiple	O
paths	O
to	O
identify	O
a	O
single	O
word	O
in	O
order	O
to	O
better	O
model	O
words	O
that	O
have	O
multiple	O
meanings	O
computing	O
the	O
probability	O
of	O
a	O
word	O
then	O
involves	O
summation	O
over	O
all	O
of	O
the	O
paths	O
that	O
lead	O
to	O
that	O
word	O
illustrates	O
a	O
simple	O
example	B
mnih	O
and	O
hinton	O
to	O
predict	O
the	O
conditional	O
probabilities	O
required	O
at	O
each	O
node	O
of	O
the	O
tree	O
we	O
typically	O
use	O
a	O
logistic	O
regression	B
model	O
at	O
each	O
node	O
of	O
the	O
tree	O
and	O
provide	O
the	O
same	O
context	O
c	O
as	O
input	O
to	O
all	O
of	O
these	O
models	O
because	O
the	O
correct	O
output	O
is	O
encoded	O
in	O
the	O
training	O
set	O
we	O
can	O
use	O
supervised	B
learning	I
to	O
train	O
the	O
logistic	O
regression	B
models	O
this	O
is	O
typically	O
done	O
using	O
a	O
standard	O
cross-entropy	B
loss	O
corresponding	O
to	O
maximizing	O
the	O
log-likelihood	O
of	O
the	O
correct	O
sequence	O
of	O
decisions	O
because	O
the	O
output	O
log-likelihood	O
can	O
be	O
computed	O
efficiently	O
low	O
as	O
log	O
v	O
rather	O
than	O
v	O
its	O
gradients	O
may	O
also	O
be	O
computed	O
efficiently	O
this	O
includes	O
not	O
only	O
the	O
gradient	B
with	O
respect	O
to	O
the	O
output	O
parameters	O
but	O
also	O
the	O
gradients	O
with	O
respect	O
to	O
the	O
hidden	B
layer	I
activations	O
it	O
is	O
possible	O
but	O
usually	O
not	O
practical	O
to	O
optimize	O
the	O
tree	O
structure	O
to	O
minimize	O
the	O
expected	O
number	O
of	O
computations	O
tools	O
from	O
information	O
theory	O
specify	O
how	O
to	O
choose	O
the	O
optimal	O
binary	O
code	O
given	O
the	O
relative	O
frequencies	O
of	O
the	O
words	O
to	O
do	O
so	O
we	O
could	O
structure	O
the	O
tree	O
so	O
that	O
the	O
number	O
of	O
bits	O
associated	O
with	O
a	O
word	O
is	O
approximately	O
equal	O
to	O
the	O
logarithm	O
of	O
the	O
frequency	O
of	O
that	O
word	O
however	O
in	O
chapter	O
applications	O
and	O
which	O
respectively	O
contain	O
the	O
sets	O
of	O
words	O
figure	O
illustration	O
of	O
a	O
simple	O
hierarchy	O
of	O
word	O
categories	O
with	O
words	O
organized	O
into	O
a	O
three	O
level	O
hierarchy	O
the	O
leaves	O
of	O
the	O
tree	O
represent	O
actual	O
specific	O
words	O
internal	O
nodes	O
represent	O
groups	O
of	O
words	O
any	O
node	O
can	O
be	O
indexed	O
by	O
the	O
sequence	O
of	O
binary	O
decisions	O
to	O
reach	O
the	O
node	O
from	O
the	O
root	O
super-class	O
contains	O
the	O
classes	O
w	O
and	O
which	O
and	O
similarly	O
super-class	O
respectively	O
contain	O
the	O
words	O
w	O
and	O
w	O
if	O
the	O
tree	O
is	O
sufficiently	O
balanced	O
the	O
maximum	O
depth	O
of	O
binary	O
decisions	O
is	O
on	O
the	O
order	O
of	O
the	O
logarithm	O
of	O
the	O
number	O
of	O
words	O
v	O
words	O
can	O
be	O
obtained	O
by	O
doing	O
v	O
operations	O
for	O
each	O
of	O
the	O
nodes	O
on	O
the	O
path	O
from	O
the	O
root	O
in	O
this	O
example	B
olog	O
computing	O
the	O
probability	O
of	O
a	O
word	O
y	O
can	O
be	O
done	O
by	O
multiplying	O
three	O
probabilities	O
associated	O
with	O
the	O
binary	O
decisions	O
to	O
move	O
left	O
or	O
right	O
at	O
each	O
node	O
on	O
the	O
path	O
from	O
the	O
root	O
to	O
a	O
node	O
y	O
let	O
biy	O
be	O
the	O
i-th	O
binary	O
decision	O
when	O
traversing	O
the	O
tree	O
towards	O
the	O
value	O
y	O
the	O
probability	O
of	O
sampling	O
an	O
output	O
y	O
decomposes	O
into	O
a	O
product	O
of	O
conditional	O
probabilities	O
using	O
the	O
chain	O
rule	O
for	O
conditional	O
probabilities	O
with	O
each	O
node	O
indexed	O
by	O
the	O
prefix	O
of	O
these	O
bits	O
for	O
example	B
node	O
corresponds	O
to	O
the	O
prefix	O
and	O
the	O
probability	O
of	O
w	O
can	O
be	O
decomposed	O
as	O
follows	O
v	O
the	O
choice	O
of	O
one	O
out	O
of	O
contains	O
the	O
classes	O
and	O
p	O
y	O
w	O
b	O
chapter	O
applications	O
practice	O
the	O
computational	O
savings	O
are	O
typically	O
not	O
worth	O
the	O
effort	O
because	O
the	O
computation	O
of	O
the	O
output	O
probabilities	O
is	O
only	O
one	O
part	O
of	O
the	O
total	O
computation	O
in	O
the	O
neural	O
language	O
model	O
for	O
example	B
suppose	O
there	O
are	O
l	O
fully	O
connected	O
hidden	O
layers	O
of	O
width	O
nh	O
let	O
nb	O
be	O
the	O
weighted	O
average	O
of	O
the	O
number	O
of	O
bits	O
required	O
to	O
identify	O
a	O
word	O
with	O
the	O
weighting	O
given	O
by	O
the	O
frequency	O
of	O
these	O
words	O
in	O
this	O
example	B
the	O
number	O
of	O
operations	O
needed	O
to	O
compute	O
the	O
hidden	O
activations	O
grows	O
as	O
as	O
h	O
while	O
the	O
output	O
computations	O
grow	O
as	O
onhnb	O
as	O
long	O
as	O
nb	O
lnh	O
we	O
can	O
reduce	O
computation	O
more	O
by	O
shrinking	O
nh	O
than	O
by	O
shrinking	O
nb	O
indeed	O
nb	O
is	O
often	O
small	O
because	O
the	O
size	O
of	O
the	O
vocabulary	O
rarely	O
exceeds	O
a	O
million	O
words	O
and	O
but	O
nh	O
is	O
often	O
much	O
larger	O
around	O
or	O
more	O
rather	O
than	O
carefully	O
optimizing	O
a	O
tree	O
with	O
a	O
branching	O
factor	O
of	O
one	O
can	O
instead	O
define	O
a	O
tree	O
with	O
depth	O
two	O
and	O
a	O
branching	O
factor	O
of	O
v	O
such	O
a	O
tree	O
corresponds	O
to	O
simply	O
defining	O
a	O
set	O
of	O
mutually	O
exclusive	O
word	O
classes	O
the	O
simple	O
approach	O
based	O
on	O
a	O
tree	O
of	O
depth	O
two	O
captures	O
most	O
of	O
the	O
computational	O
benefit	O
of	O
the	O
hierarchical	O
strategy	O
it	O
is	O
possible	O
to	O
reduce	O
nb	O
to	O
about	O
morin	O
and	O
bengio	O
one	O
question	O
that	O
remains	O
somewhat	O
open	O
is	O
how	O
to	O
best	O
define	O
these	O
word	O
classes	O
or	O
how	O
to	O
define	O
the	O
word	O
hierarchy	O
in	O
general	O
early	O
work	O
used	O
existing	O
hierarchies	O
but	O
the	O
hierarchy	O
can	O
also	O
be	O
learned	O
ideally	O
jointly	O
with	O
the	O
neural	O
language	O
model	O
learning	O
the	O
hierarchy	O
is	O
difficult	O
an	O
exact	O
optimization	O
of	O
the	O
log-likelihood	O
appears	O
intractable	O
because	O
the	O
choice	O
of	O
a	O
word	O
hierarchy	O
is	O
a	O
discrete	O
one	O
not	O
amenable	O
to	O
gradient-based	O
optimization	O
however	O
one	O
could	O
use	O
discrete	O
optimization	O
to	O
approximately	O
optimize	O
the	O
partition	O
of	O
words	O
into	O
word	O
classes	O
an	O
important	O
advantage	O
of	O
the	O
hierarchical	O
softmax	O
is	O
that	O
it	O
brings	O
computational	O
benefits	O
both	O
at	O
training	O
time	O
and	O
at	O
test	O
time	O
if	O
at	O
test	O
time	O
we	O
want	O
to	O
compute	O
the	O
probability	O
of	O
specific	O
words	O
v	O
words	O
will	O
remain	O
expensive	O
even	O
with	O
the	O
hierarchical	O
softmax	O
another	O
important	O
operation	B
is	O
selecting	O
the	O
most	O
likely	O
word	O
in	O
a	O
given	O
context	O
unfortunately	O
the	O
tree	O
structure	O
does	O
not	O
provide	O
an	O
efficient	O
and	O
exact	O
solution	O
to	O
this	O
problem	O
of	O
course	O
computing	O
the	O
probability	O
of	O
all	O
a	O
disadvantage	O
is	O
that	O
in	O
practice	O
the	O
hierarchical	O
softmax	O
tends	O
to	O
give	O
worse	O
test	O
results	O
than	O
sampling-based	O
methods	O
we	O
will	O
describe	O
next	O
this	O
may	O
be	O
due	O
to	O
a	O
poor	O
choice	O
of	O
word	O
classes	O
importance	O
sampling	O
one	O
way	O
to	O
speed	O
up	O
the	O
training	O
of	O
neural	O
language	O
models	O
is	O
to	O
avoid	O
explicitly	O
computing	O
the	O
contribution	O
of	O
the	O
gradient	B
from	O
all	O
of	O
the	O
words	O
that	O
do	O
not	O
appear	O
chapter	O
applications	O
in	O
the	O
next	O
position	O
every	O
incorrect	O
word	O
should	O
have	O
low	O
probability	O
under	O
the	O
model	O
it	O
can	O
be	O
computationally	O
costly	O
to	O
enumerate	O
all	O
of	O
these	O
words	O
instead	O
it	O
is	O
possible	O
to	O
sample	O
only	O
a	O
subset	O
of	O
the	O
words	O
using	O
the	O
notation	O
introduced	O
in	O
equation	O
the	O
gradient	B
can	O
be	O
written	O
as	O
follows	O
p	O
y	O
c	O
log	O
log	O
y	O
ay	O
i	O
log	O
softmaxy	O
eay	O
i	O
eai	O
log	O
i	O
ea	O
i	O
i	O
c	O
p	O
y	O
ai	O
where	O
a	O
is	O
the	O
vector	O
of	O
pre-softmax	O
activations	O
scores	O
with	O
one	O
element	O
per	O
word	O
the	O
first	O
term	O
is	O
the	O
positive	O
phase	O
term	O
ay	O
up	O
while	O
the	O
second	O
term	O
is	O
the	O
negative	O
phase	O
term	O
ai	O
down	O
for	O
all	O
i	O
with	O
weight	O
p	O
c	O
since	O
the	O
negative	O
phase	O
term	O
is	O
an	O
expectation	B
we	O
can	O
estimate	O
it	O
with	O
a	O
monte	O
carlo	O
sample	O
however	O
that	O
would	O
require	O
sampling	O
from	O
the	O
model	O
itself	O
sampling	O
from	O
the	O
model	O
requires	O
computing	O
p	O
c	O
for	O
all	O
i	O
in	O
the	O
vocabulary	O
which	O
is	O
precisely	O
what	O
we	O
are	O
trying	O
to	O
avoid	O
instead	O
of	O
sampling	O
from	O
the	O
model	O
one	O
can	O
sample	O
from	O
another	O
distribution	O
called	O
the	O
proposal	O
distribution	O
q	O
and	O
use	O
appropriate	O
weights	B
to	O
correct	O
for	O
the	O
bias	O
introduced	O
by	O
sampling	O
from	O
the	O
wrong	O
distribution	O
and	O
s	O
n	O
cal	O
bengio	O
and	O
s	O
n	O
cal	O
this	O
is	O
an	O
application	O
of	O
a	O
more	O
general	O
technique	O
called	O
importance	O
sampling	O
which	O
will	O
be	O
described	O
in	O
more	O
detail	O
unfortunately	O
even	O
exact	O
importance	O
sampling	O
is	O
not	O
efficient	O
in	O
section	O
because	O
it	O
requires	O
computing	O
weights	B
piqi	O
where	O
pi	O
p	O
c	O
which	O
can	O
only	O
be	O
computed	O
if	O
all	O
the	O
scores	O
ai	O
are	O
computed	O
the	O
solution	O
adopted	O
for	O
this	O
application	O
is	O
called	O
biased	B
importance	I
sampling	I
where	O
the	O
importance	O
weights	B
are	O
normalized	O
to	O
sum	O
to	O
when	O
negative	O
word	O
ni	O
is	O
sampled	O
the	O
associated	O
gradient	B
is	O
weighted	O
by	O
wi	O
pni	O
i	O
n	O
pnj	O
these	O
weights	B
are	O
used	O
to	O
give	O
the	O
appropriate	O
importance	O
to	O
the	O
m	O
negative	O
samples	O
from	O
q	O
used	O
to	O
form	O
the	O
estimated	O
negative	O
phase	O
contribution	O
to	O
the	O
chapter	O
applications	O
gradient	B
v	O
p	O
i	O
c	O
m	O
a	O
i	O
m	O
wi	O
ani	O
a	O
unigram	B
or	O
a	O
bigram	B
distribution	O
works	O
well	O
as	O
the	O
proposal	O
distribution	O
q	O
it	O
is	O
easy	O
to	O
estimate	O
the	O
parameters	O
of	O
such	O
a	O
distribution	O
from	O
data	O
after	O
estimating	O
the	O
parameters	O
it	O
is	O
also	O
possible	O
to	O
sample	O
from	O
such	O
a	O
distribution	O
very	O
efficiently	O
importance	O
sampling	O
is	O
not	O
only	O
useful	O
for	O
speeding	O
up	O
models	O
with	O
large	O
softmax	O
outputs	O
more	O
generally	O
it	O
is	O
useful	O
for	O
accelerating	O
training	O
with	O
large	O
n	O
sparse	O
output	O
layers	O
where	O
the	O
output	O
is	O
a	O
sparse	O
vector	O
rather	O
than	O
a	O
an	O
example	B
is	O
a	O
bag	B
of	I
words	I
a	O
bag	B
of	I
words	I
is	O
a	O
sparse	O
vector	O
v	O
where	O
vi	O
indicates	O
the	O
presence	O
or	O
absence	O
of	O
word	O
i	O
from	O
the	O
vocabulary	O
in	O
the	O
document	O
alternately	O
vi	O
can	O
indicate	O
the	O
number	O
of	O
times	O
that	O
word	O
i	O
appears	O
machine	B
learning	I
models	O
that	O
emit	O
such	O
sparse	O
vectors	O
can	O
be	O
expensive	O
to	O
train	O
for	O
a	O
variety	O
of	O
reasons	O
early	O
in	O
learning	O
the	O
model	O
may	O
not	O
actually	O
choose	O
to	O
make	O
the	O
output	O
truly	O
sparse	O
moreover	O
the	O
loss	O
function	O
we	O
use	O
for	O
training	O
might	O
most	O
naturally	O
be	O
described	O
in	O
terms	O
of	O
comparing	O
every	O
element	O
of	O
the	O
output	O
to	O
every	O
element	O
of	O
the	O
target	O
this	O
means	O
that	O
it	O
is	O
not	O
always	O
clear	O
that	O
there	O
is	O
a	O
computational	O
benefit	O
to	O
using	O
sparse	O
outputs	O
because	O
the	O
model	O
may	O
choose	O
to	O
make	O
the	O
majority	O
of	O
the	O
output	O
non-zero	O
and	O
all	O
of	O
these	O
non-zero	O
values	O
need	O
to	O
be	O
compared	O
to	O
the	O
corresponding	O
training	O
target	O
even	O
if	O
the	O
training	O
target	O
is	O
zero	O
dauphin	O
demonstrated	O
that	O
such	O
models	O
can	O
be	O
accelerated	O
using	O
importance	O
sampling	O
the	O
efficient	O
algorithm	O
minimizes	O
the	O
loss	O
reconstruction	O
for	O
the	O
positive	O
words	O
that	O
are	O
non-zero	O
in	O
the	O
target	O
and	O
an	O
equal	O
number	O
of	O
negative	O
words	O
the	O
negative	O
words	O
are	O
chosen	O
randomly	O
using	O
a	O
heuristic	O
to	O
sample	O
words	O
that	O
are	O
more	O
likely	O
to	O
be	O
mistaken	O
the	O
bias	O
introduced	O
by	O
this	O
heuristic	O
oversampling	O
can	O
then	O
be	O
corrected	O
using	O
importance	O
weights	B
et	O
al	O
in	O
all	O
of	O
these	O
cases	O
the	O
computational	O
complexity	O
of	O
gradient	B
estimation	O
for	O
the	O
output	O
layer	O
is	O
reduced	O
to	O
be	O
proportional	O
to	O
the	O
number	O
of	O
negative	O
samples	O
rather	O
than	O
proportional	O
to	O
the	O
size	O
of	O
the	O
output	O
vector	O
noise-contrastive	B
estimation	I
and	O
ranking	O
loss	O
other	O
approaches	O
based	O
on	O
sampling	O
have	O
been	O
proposed	O
to	O
reduce	O
the	O
computational	O
cost	O
of	O
training	O
neural	O
language	O
models	O
with	O
large	O
vocabularies	O
an	O
early	O
example	B
is	O
the	O
ranking	O
loss	O
proposed	O
by	O
collobert	O
and	O
weston	O
which	O
views	O
the	O
output	O
of	O
the	O
neural	O
language	O
model	O
for	O
each	O
word	O
as	O
a	O
score	O
and	O
tries	O
to	O
make	O
the	O
score	O
of	O
the	O
correct	O
word	O
ay	O
be	O
ranked	O
high	O
in	O
comparison	O
to	O
the	O
other	O
chapter	O
applications	O
scores	O
ai	O
the	O
ranking	O
loss	O
proposed	O
then	O
is	O
l	O
ay	O
ai	O
i	O
the	O
gradient	B
is	O
zero	O
for	O
the	O
i-th	O
term	O
if	O
the	O
score	O
of	O
the	O
observed	O
word	O
a	O
y	O
is	O
greater	O
than	O
the	O
score	O
of	O
the	O
negative	O
word	O
ai	O
by	O
a	O
margin	O
of	O
one	O
issue	O
with	O
this	O
criterion	O
is	O
that	O
it	O
does	O
not	O
provide	O
estimated	O
conditional	O
probabilities	O
which	O
are	O
useful	O
in	O
some	O
applications	O
including	O
speech	O
recognition	O
and	O
text	O
generation	O
conditional	O
text	O
generation	O
tasks	O
such	O
as	O
translation	O
a	O
more	O
recently	O
used	O
training	O
objective	O
for	O
neural	O
language	O
model	O
is	O
noisecontrastive	O
estimation	O
which	O
is	O
introduced	O
in	O
section	O
this	O
approach	O
has	O
been	O
successfully	O
applied	O
to	O
neural	O
language	O
models	O
and	O
teh	O
mnih	O
and	O
kavukcuoglu	O
combining	O
neural	O
language	O
models	O
with	O
n	O
a	O
major	O
advantage	O
of	O
n-gram	B
models	O
over	O
neural	O
networks	O
is	O
that	O
n-gram	B
models	O
achieve	O
high	O
model	O
capacity	O
storing	O
the	O
frequencies	O
of	O
very	O
many	O
tuples	O
while	O
requiring	O
very	O
little	O
computation	O
to	O
process	O
an	O
example	B
looking	O
up	O
only	O
a	O
few	O
tuples	O
that	O
match	O
the	O
current	O
context	O
if	O
we	O
use	O
hash	O
tables	O
or	O
trees	O
to	O
access	O
the	O
counts	O
the	O
computation	O
used	O
for	O
n-grams	O
is	O
almost	O
independent	O
of	O
capacity	O
in	O
comparison	O
doubling	O
a	O
neural	B
network	I
s	O
number	O
of	O
parameters	O
typically	O
also	O
roughly	O
doubles	O
its	O
computation	O
time	O
exceptions	O
include	O
models	O
that	O
avoid	O
using	O
all	O
parameters	O
on	O
each	O
pass	O
embedding	B
layers	O
index	O
only	O
a	O
single	O
embedding	B
in	O
each	O
pass	O
so	O
we	O
can	O
increase	O
the	O
vocabulary	O
size	O
without	O
increasing	O
the	O
computation	O
time	O
per	O
example	B
some	O
other	O
models	O
such	O
as	O
tiled	O
convolutional	O
networks	O
can	O
add	O
parameters	O
while	O
reducing	O
the	O
degree	O
of	O
parameter	O
sharing	O
in	O
order	O
to	O
maintain	O
the	O
same	O
amount	O
of	O
computation	O
however	O
typical	O
neural	B
network	I
layers	O
based	O
on	O
matrix	O
multiplication	O
use	O
an	O
amount	O
of	O
computation	O
proportional	O
to	O
the	O
number	O
of	O
parameters	O
one	O
easy	O
way	O
to	O
add	O
capacity	O
is	O
thus	O
to	O
combine	O
both	O
approaches	O
in	O
an	O
ensemble	O
consisting	O
of	O
a	O
neural	O
language	O
model	O
and	O
an	O
n-gram	B
language	O
model	O
et	O
al	O
as	O
with	O
any	O
ensemble	O
this	O
technique	O
can	O
reduce	O
test	O
error	O
if	O
the	O
ensemble	O
members	O
make	O
independent	O
mistakes	O
the	O
field	O
of	O
ensemble	O
learning	O
provides	O
many	O
ways	O
of	O
combining	O
the	O
ensemble	O
members	O
predictions	O
including	O
uniform	O
weighting	O
and	O
weights	B
chosen	O
on	O
a	O
validation	O
set	O
mikolov	O
extended	O
the	O
ensemble	O
to	O
include	O
not	O
just	O
two	O
models	O
but	O
a	O
large	O
array	O
of	O
models	O
it	O
is	O
also	O
possible	O
to	O
pair	O
a	O
neural	B
network	I
with	O
a	O
maximum	O
entropy	O
model	O
and	O
this	O
approach	O
can	O
be	O
viewed	O
as	O
training	O
train	O
both	O
jointly	O
et	O
al	O
et	O
al	O
chapter	O
applications	O
a	O
neural	B
network	I
with	O
an	O
extra	O
set	O
of	O
inputs	O
that	O
are	O
connected	O
directly	O
to	O
the	O
output	O
and	O
not	O
connected	O
to	O
any	O
other	O
part	O
of	O
the	O
model	O
the	O
extra	O
inputs	O
are	O
indicators	O
for	O
the	O
presence	O
of	O
particular	O
n-grams	O
in	O
the	O
input	O
context	O
so	O
these	O
variables	O
are	O
very	O
high-dimensional	O
and	O
very	O
sparse	O
the	O
increase	O
in	O
model	O
capacity	O
sv	O
n	O
parameters	O
but	O
is	O
huge	O
the	O
new	O
portion	O
of	O
the	O
architecture	O
contains	O
up	O
to	O
the	O
amount	O
of	O
added	O
computation	O
needed	O
to	O
process	O
an	O
input	O
is	O
minimal	O
because	O
the	O
extra	O
inputs	O
are	O
very	O
sparse	O
neural	O
machine	B
translation	I
machine	B
translation	I
is	O
the	O
task	O
of	O
reading	O
a	O
sentence	O
in	O
one	O
natural	O
language	O
and	O
emitting	O
a	O
sentence	O
with	O
the	O
equivalent	O
meaning	O
in	O
another	O
language	O
machine	B
translation	I
systems	O
often	O
involve	O
many	O
components	O
at	O
a	O
high	O
level	O
there	O
is	O
often	O
one	O
component	O
that	O
proposes	O
many	O
candidate	O
translations	O
many	O
of	O
these	O
translations	O
will	O
not	O
be	O
grammatical	O
due	O
to	O
differences	O
between	O
the	O
languages	O
for	O
example	B
many	O
languages	O
put	O
adjectives	O
after	O
nouns	O
so	O
when	O
translated	O
to	O
english	O
directly	O
they	O
yield	O
phrases	O
such	O
as	O
apple	O
red	O
the	O
proposal	O
mechanism	O
suggests	O
many	O
variants	O
of	O
the	O
suggested	O
translation	O
ideally	O
including	O
red	O
apple	O
a	O
second	O
component	O
of	O
the	O
translation	O
system	O
a	O
language	O
model	O
evaluates	O
the	O
proposed	O
translations	O
and	O
can	O
score	O
red	O
apple	O
as	O
better	O
than	O
apple	O
red	O
schwenk	O
the	O
earliest	O
use	O
of	O
neural	O
networks	O
for	O
machine	B
translation	I
was	O
to	O
upgrade	O
the	O
language	O
model	O
of	O
a	O
translation	O
system	O
by	O
using	O
a	O
neural	O
language	O
model	O
et	O
al	O
previously	O
most	O
machine	B
translation	I
systems	O
had	O
used	O
an	O
n-gram	B
model	O
for	O
this	O
component	O
the	O
n-gram	B
based	O
models	O
used	O
for	O
machine	B
translation	I
include	O
not	O
just	O
traditional	O
back-off	O
n-gram	B
models	O
and	O
mercer	O
katz	O
chen	O
and	O
goodman	O
but	O
also	O
maximum	O
entropy	O
language	O
models	O
in	O
which	O
an	O
affine-softmax	O
layer	O
predicts	O
the	O
next	O
word	O
given	O
the	O
presence	O
of	O
frequent	O
berger	O
et	O
al	O
in	O
the	O
context	O
n	O
traditional	O
language	O
models	O
simply	O
report	O
the	O
probability	O
of	O
a	O
natural	O
language	O
sentence	O
because	O
machine	B
translation	I
involves	O
producing	O
an	O
output	O
sentence	O
given	O
an	O
input	O
sentence	O
it	O
makes	O
sense	O
to	O
extend	O
the	O
natural	O
language	O
model	O
to	O
be	O
conditional	O
as	O
described	O
in	O
section	O
it	O
is	O
straightforward	O
to	O
extend	O
a	O
model	O
that	O
defines	O
a	O
marginal	O
distribution	O
over	O
some	O
variable	O
to	O
define	O
a	O
conditional	O
distribution	O
over	O
that	O
variable	O
given	O
a	O
context	O
c	O
where	O
c	O
might	O
be	O
a	O
single	O
variable	O
or	O
a	O
list	O
of	O
variables	O
beat	O
the	O
state-of-the-art	O
in	O
some	O
statistical	O
machine	B
translation	I
benchmarks	O
by	O
using	O
an	O
mlp	O
to	O
score	O
a	O
phrase	O
tk	O
in	O
the	O
target	O
language	O
given	O
a	O
phrase	O
s	O
n	O
in	O
the	O
source	O
language	O
the	O
mlp	O
estimates	O
p	O
tk	O
sn	O
the	O
estimate	O
formed	O
by	O
this	O
mlp	O
replaces	O
the	O
estimate	O
provided	O
by	O
conditional	O
devlin	O
et	O
al	O
models	O
n	O
chapter	O
applications	O
output	O
object	O
sentence	O
decoder	B
intermediate	O
semantic	O
representation	O
encoder	B
source	O
object	O
sentence	O
or	O
image	O
figure	O
the	O
encoder-decoder	O
architecture	O
to	O
map	O
back	O
and	O
forth	O
between	O
a	O
surface	O
representation	O
as	O
a	O
sequence	O
of	O
words	O
or	O
an	O
image	O
and	O
a	O
semantic	O
representation	O
by	O
using	O
the	O
output	O
of	O
an	O
encoder	B
of	O
data	O
from	O
one	O
modality	O
as	O
the	O
encoder	B
mapping	O
from	O
french	O
sentences	O
to	O
hidden	O
representations	O
capturing	O
the	O
meaning	O
of	O
sentences	O
as	O
the	O
input	O
to	O
a	O
decoder	B
for	O
another	O
modality	O
as	O
the	O
decoder	B
mapping	O
from	O
hidden	O
representations	O
capturing	O
the	O
meaning	O
of	O
sentences	O
to	O
english	O
we	O
can	O
train	O
systems	O
that	O
translate	O
from	O
one	O
modality	O
to	O
another	O
this	O
idea	O
has	O
been	O
applied	O
successfully	O
not	O
just	O
to	O
machine	B
translation	I
but	O
also	O
to	O
caption	O
generation	O
from	O
images	O
a	O
drawback	O
of	O
the	O
mlp-based	O
approach	O
is	O
that	O
it	O
requires	O
the	O
sequences	O
to	O
be	O
preprocessed	O
to	O
be	O
of	O
fixed	O
length	O
to	O
make	O
the	O
translation	O
more	O
flexible	O
we	O
would	O
like	O
to	O
use	O
a	O
model	O
that	O
can	O
accommodate	O
variable	O
length	O
inputs	O
and	O
variable	O
length	O
outputs	O
an	O
rnn	O
provides	O
this	O
ability	O
section	O
describes	O
several	O
ways	O
of	O
constructing	O
an	O
rnn	O
that	O
represents	O
a	O
conditional	O
distribution	O
over	O
a	O
sequence	O
given	O
some	O
input	O
and	O
section	O
describes	O
how	O
to	O
accomplish	O
this	O
conditioning	O
when	O
the	O
input	O
is	O
a	O
sequence	O
in	O
all	O
cases	O
one	O
model	O
first	O
reads	O
the	O
input	O
sequence	O
and	O
emits	O
a	O
data	O
structure	O
that	O
summarizes	O
the	O
input	O
sequence	O
we	O
call	O
this	O
summary	O
the	O
context	O
c	O
the	O
context	O
c	O
may	O
be	O
a	O
list	O
of	O
vectors	O
or	O
it	O
may	O
be	O
a	O
vector	O
or	O
tensor	O
the	O
model	O
that	O
reads	O
the	O
input	O
to	O
produce	O
c	O
may	O
be	O
an	O
rnn	O
cho	O
et	O
al	O
sutskever	O
or	O
a	O
convolutional	B
network	I
and	O
blunsom	O
a	O
second	O
model	O
usually	O
an	O
rnn	O
then	O
reads	O
the	O
context	O
c	O
and	O
generates	O
a	O
sentence	O
in	O
the	O
target	O
language	O
this	O
general	O
idea	O
of	O
an	O
encoder-decoder	O
framework	O
for	O
machine	B
translation	I
is	O
illustrated	O
in	O
figure	O
jean	O
et	O
al	O
et	O
al	O
in	O
order	O
to	O
generate	O
an	O
entire	O
sentence	O
conditioned	O
on	O
the	O
source	O
sentence	O
the	O
model	O
must	O
have	O
a	O
way	O
to	O
represent	O
the	O
entire	O
source	O
sentence	O
earlier	O
models	O
were	O
only	O
able	O
to	O
represent	O
individual	O
words	O
or	O
phrases	O
from	O
a	O
representation	O
chapter	O
applications	O
learning	O
point	O
of	O
view	O
it	O
can	O
be	O
useful	O
to	O
learn	O
a	O
representation	O
in	O
which	O
sentences	O
that	O
have	O
the	O
same	O
meaning	O
have	O
similar	O
representations	O
regardless	O
of	O
whether	O
they	O
were	O
written	O
in	O
the	O
source	O
language	O
or	O
the	O
target	O
language	O
this	O
strategy	O
was	O
explored	O
first	O
using	O
a	O
combination	O
of	O
convolutions	O
and	O
rnns	O
and	O
later	O
work	O
introduced	O
the	O
use	O
of	O
an	O
rnn	O
for	O
scoring	O
proposed	O
blunsom	O
translations	O
sutskever	O
et	O
al	O
and	O
for	O
generating	O
translated	O
sentences	O
scaled	O
these	O
models	O
to	O
larger	O
vocabularies	O
cho	O
et	O
al	O
jean	O
et	O
al	O
using	O
an	O
attention	O
mechanism	O
and	O
aligning	O
pieces	O
of	O
data	O
cc	O
t	O
t	O
h	O
t	O
h	O
th	O
ht	O
ht	O
bahdanau	O
et	O
al	O
figure	O
a	O
modern	O
attention	O
mechanism	O
as	O
introduced	O
by	O
is	O
essentially	O
a	O
weighted	O
average	O
a	O
context	O
vector	O
c	O
is	O
formed	O
by	O
taking	O
a	O
weighted	O
average	O
of	O
feature	B
vectors	O
h	O
with	O
weights	B
in	O
some	O
applications	O
the	O
feature	B
vectors	O
h	O
are	O
hidden	O
units	O
of	O
a	O
neural	B
network	I
but	O
they	O
may	O
also	O
be	O
raw	O
input	O
to	O
the	O
model	O
the	O
weights	B
are	O
produced	O
by	O
the	O
model	O
itself	O
they	O
are	O
usually	O
values	O
in	O
the	O
interval	O
and	O
are	O
intended	O
to	O
concentrate	O
around	O
just	O
one	O
h	O
so	O
that	O
the	O
weighted	O
average	O
approximates	O
reading	O
that	O
one	O
specific	O
time	O
step	O
precisely	O
the	O
weights	B
are	O
usually	O
produced	O
by	O
applying	O
a	O
softmax	O
function	O
to	O
relevance	O
scores	O
emitted	O
by	O
another	O
portion	O
of	O
the	O
model	O
the	O
attention	O
mechanism	O
is	O
more	O
expensive	O
computationally	O
than	O
directly	O
indexing	O
the	O
desired	O
h	O
but	O
direct	O
indexing	O
cannot	O
be	O
trained	O
with	O
gradient	B
descent	O
the	O
attention	O
mechanism	O
based	O
on	O
weighted	O
averages	O
is	O
a	O
smooth	O
differentiable	O
approximation	O
that	O
can	O
be	O
trained	O
with	O
existing	O
optimization	O
algorithms	O
using	O
a	O
fixed-size	O
representation	O
to	O
capture	O
all	O
the	O
semantic	O
details	O
of	O
a	O
very	O
long	O
sentence	O
of	O
say	O
words	O
is	O
very	O
difficult	O
it	O
can	O
be	O
achieved	O
by	O
training	O
a	O
sufficiently	O
large	O
rnn	O
well	O
enough	O
and	O
for	O
long	O
enough	O
as	O
demonstrated	O
by	O
cho	O
et	O
al	O
however	O
a	O
more	O
efficient	O
approach	O
is	O
to	O
read	O
the	O
whole	O
sentence	O
or	O
paragraph	O
get	O
the	O
context	O
and	O
the	O
gist	O
of	O
what	O
sutskever	O
et	O
al	O
and	O
chapter	O
applications	O
is	O
being	O
expressed	O
then	O
produce	O
the	O
translated	O
words	O
one	O
at	O
a	O
time	O
each	O
time	O
focusing	O
on	O
a	O
different	O
part	O
of	O
the	O
input	O
sentence	O
in	O
order	O
to	O
gather	O
the	O
semantic	O
details	O
that	O
are	O
required	O
to	O
produce	O
the	O
next	O
output	O
word	O
that	O
is	O
exactly	O
the	O
idea	O
that	O
first	O
introduced	O
the	O
attention	O
mechanism	O
used	O
to	O
focus	O
on	O
specific	O
parts	O
of	O
the	O
input	O
sequence	O
at	O
each	O
time	O
step	O
is	O
illustrated	O
in	O
figure	O
bahdanau	O
et	O
al	O
we	O
can	O
think	O
of	O
an	O
attention-based	O
system	O
as	O
having	O
three	O
components	O
a	O
process	O
that	O
reads	O
raw	O
data	O
as	O
source	O
words	O
in	O
a	O
source	O
sentence	O
and	O
converts	O
them	O
into	O
distributed	O
representations	O
with	O
one	O
feature	B
vector	O
associated	O
with	O
each	O
word	O
position	O
a	O
list	O
of	O
feature	B
vectors	O
storing	O
the	O
output	O
of	O
the	O
reader	O
this	O
can	O
be	O
containing	O
a	O
sequence	O
of	O
facts	O
which	O
can	O
be	O
understood	O
as	O
a	O
retrieved	O
later	O
not	O
necessarily	O
in	O
the	O
same	O
order	O
without	O
having	O
to	O
visit	O
all	O
of	O
them	O
memory	O
a	O
process	O
that	O
the	O
content	O
of	O
the	O
memory	O
to	O
sequentially	O
perform	O
a	O
task	O
at	O
each	O
time	O
step	O
having	O
the	O
ability	O
put	O
attention	O
on	O
the	O
content	O
of	O
one	O
memory	O
element	O
a	O
few	O
with	O
a	O
different	O
weight	O
exploits	O
the	O
third	O
component	O
generates	O
the	O
translated	O
sentence	O
when	O
words	O
in	O
a	O
sentence	O
written	O
in	O
one	O
language	O
are	O
aligned	O
with	O
corresponding	O
words	O
in	O
a	O
translated	O
sentence	O
in	O
another	O
language	O
it	O
becomes	O
possible	O
to	O
relate	O
the	O
corresponding	O
word	O
embeddings	O
earlier	O
work	O
showed	O
that	O
one	O
could	O
learn	O
a	O
kind	O
of	O
translation	O
matrix	O
relating	O
the	O
word	O
embeddings	O
in	O
one	O
language	O
with	O
the	O
word	O
embeddings	O
in	O
another	O
isk	O
yielding	O
lower	O
alignment	O
error	O
rates	O
than	O
traditional	O
approaches	O
based	O
on	O
the	O
frequency	O
counts	O
in	O
the	O
phrase	O
table	O
there	O
is	O
even	O
earlier	O
work	O
on	O
learning	O
cross-lingual	O
word	O
vectors	O
et	O
al	O
many	O
extensions	O
to	O
this	O
approach	O
are	O
possible	O
for	O
example	B
more	O
efficient	O
cross-lingual	O
alignment	O
allows	O
training	O
on	O
larger	O
datasets	O
gouws	O
et	O
al	O
et	O
al	O
historical	O
perspective	O
the	O
idea	O
of	O
distributed	O
representations	O
for	O
symbols	O
was	O
introduced	O
by	O
rumelhart	O
et	O
al	O
in	O
one	O
of	O
the	O
first	O
explorations	O
of	O
back-propagation	B
with	O
symbols	O
corresponding	O
to	O
the	O
identity	O
of	O
family	O
members	O
and	O
the	O
neural	B
network	I
capturing	O
the	O
relationships	O
between	O
family	O
members	O
with	O
training	O
examples	O
forming	O
triplets	O
such	O
as	O
mother	O
victoria	O
the	O
first	O
layer	O
of	O
the	O
neural	B
network	I
learned	O
a	O
representation	O
of	O
each	O
family	O
member	O
for	O
example	B
the	O
features	O
for	O
colin	O
chapter	O
applications	O
might	O
represent	O
which	O
family	O
tree	O
colin	O
was	O
in	O
what	O
branch	O
of	O
that	O
tree	O
he	O
was	O
in	O
what	O
generation	O
he	O
was	O
from	O
etc	O
one	O
can	O
think	O
of	O
the	O
neural	B
network	I
as	O
computing	O
learned	O
rules	O
relating	O
these	O
attributes	O
together	O
in	O
order	O
to	O
obtain	O
the	O
desired	O
predictions	O
the	O
model	O
can	O
then	O
make	O
predictions	O
such	O
as	O
inferring	O
who	O
is	O
the	O
mother	O
of	O
colin	O
the	O
idea	O
of	O
forming	O
an	O
embedding	B
for	O
a	O
symbol	O
was	O
extended	O
to	O
the	O
idea	O
of	O
an	O
these	O
embeddings	O
were	O
learned	O
embedding	B
for	O
a	O
word	O
by	O
deerwester	O
using	O
the	O
svd	O
later	O
embeddings	O
would	O
be	O
learned	O
by	O
neural	O
networks	O
et	O
al	O
the	O
history	O
of	O
natural	B
language	I
processing	I
is	O
marked	O
by	O
transitions	O
in	O
the	O
popularity	O
of	O
different	O
ways	O
of	O
representing	O
the	O
input	O
to	O
the	O
model	O
following	O
this	O
early	O
work	O
on	O
symbols	O
or	O
words	O
some	O
of	O
the	O
earliest	O
applications	O
of	O
neural	O
networks	O
to	O
nlp	O
represented	O
the	O
input	O
as	O
a	O
sequence	O
of	O
characters	O
miikkulainen	O
and	O
dyer	O
schmidhuber	O
bengio	O
et	O
al	O
returned	O
the	O
focus	O
to	O
modeling	O
words	O
and	O
introduced	O
neural	O
language	O
models	O
which	O
produce	O
interpretable	O
word	O
embeddings	O
these	O
neural	O
models	O
have	O
scaled	O
up	O
from	O
defining	O
representations	O
of	O
a	O
small	O
set	O
of	O
symbols	O
in	O
the	O
to	O
millions	O
of	O
words	O
proper	O
nouns	O
and	O
misspellings	O
in	O
modern	O
applications	O
this	O
computational	O
scaling	O
effort	O
led	O
to	O
the	O
invention	O
of	O
the	O
techniques	O
described	O
above	O
in	O
section	O
initially	O
the	O
use	O
of	O
words	O
as	O
the	O
fundamental	O
units	O
of	O
language	O
models	O
yielded	O
improved	O
language	O
modeling	O
performance	O
to	O
this	O
day	O
new	O
techniques	O
continually	O
push	O
both	O
character-based	O
models	O
et	O
al	O
and	O
word-based	O
models	O
forward	O
with	O
recent	O
work	O
even	O
modeling	O
individual	O
bytes	O
of	O
unicode	O
characters	O
bengio	O
et	O
al	O
gillick	O
et	O
al	O
the	O
ideas	O
behind	O
neural	O
language	O
models	O
have	O
been	O
extended	O
into	O
several	O
henderson	O
natural	B
language	I
processing	I
applications	O
such	O
as	O
parsing	O
collobert	O
part-of-speech	O
tagging	O
semantic	O
role	O
labeling	O
chunking	O
etc	O
sometimes	O
using	O
a	O
single	O
multi-task	O
learning	O
architecture	O
and	O
weston	O
collobert	O
in	O
which	O
the	O
word	O
embeddings	O
are	O
shared	O
across	O
tasks	O
et	O
al	O
two-dimensional	O
visualizations	O
of	O
embeddings	O
became	O
a	O
popular	O
tool	O
for	O
analyzing	O
language	O
models	O
following	O
the	O
development	O
of	O
the	O
t-sne	O
dimensionality	O
reduction	O
algorithm	O
der	O
maaten	O
and	O
hinton	O
and	O
its	O
high-profile	O
application	O
to	O
visualization	O
word	O
embeddings	O
by	O
joseph	O
turian	O
in	O
chapter	O
applications	O
other	O
applications	O
in	O
this	O
section	O
we	O
cover	O
a	O
few	O
other	O
types	O
of	O
applications	O
of	O
deep	O
learning	O
that	O
are	O
different	O
from	O
the	O
standard	O
object	B
recognition	I
speech	O
recognition	O
and	O
natural	B
language	I
processing	I
tasks	O
discussed	O
above	O
part	O
of	O
this	O
book	O
will	O
expand	O
that	O
scope	O
even	O
further	O
to	O
tasks	O
that	O
remain	O
primarily	O
research	O
areas	O
iii	O
recommender	B
systems	I
one	O
of	O
the	O
major	O
families	O
of	O
applications	O
of	O
machine	B
learning	I
in	O
the	O
information	O
technology	O
sector	O
is	O
the	O
ability	O
to	O
make	O
recommendations	O
of	O
items	O
to	O
potential	O
users	O
or	O
customers	O
two	O
major	O
types	O
of	O
applications	O
can	O
be	O
distinguished	O
online	O
advertising	O
and	O
item	O
recommendations	O
these	O
recommendations	O
are	O
still	O
for	O
the	O
purpose	O
of	O
selling	O
a	O
product	O
both	O
rely	O
on	O
predicting	O
the	O
association	O
between	O
a	O
user	O
and	O
an	O
item	O
either	O
to	O
predict	O
the	O
probability	O
of	O
some	O
action	O
user	O
buying	O
the	O
product	O
or	O
some	O
proxy	O
for	O
this	O
action	O
or	O
the	O
expected	O
gain	O
may	O
depend	O
on	O
the	O
value	O
of	O
the	O
product	O
if	O
an	O
ad	O
is	O
shown	O
or	O
a	O
recommendation	O
is	O
made	O
regarding	O
that	O
product	O
to	O
that	O
user	O
the	O
internet	O
is	O
currently	O
financed	O
in	O
great	O
part	O
by	O
various	O
forms	O
of	O
online	O
advertising	O
there	O
are	O
major	O
parts	O
of	O
the	O
economy	O
that	O
rely	O
on	O
online	O
shopping	O
companies	O
including	O
amazon	O
and	O
ebay	O
use	O
machine	B
learning	I
including	O
deep	O
learning	O
for	O
their	O
product	O
recommendations	O
sometimes	O
the	O
items	O
are	O
not	O
products	O
that	O
are	O
actually	O
for	O
sale	O
examples	O
include	O
selecting	O
posts	O
to	O
display	O
on	O
social	O
network	O
news	O
feeds	O
recommending	O
movies	O
to	O
watch	O
recommending	O
jokes	O
recommending	O
advice	O
from	O
experts	O
matching	O
players	O
for	O
video	O
games	O
or	O
matching	O
people	O
in	O
dating	O
services	O
often	O
this	O
association	O
problem	O
is	O
handled	O
like	O
a	O
supervised	B
learning	I
problem	O
given	O
some	O
information	O
about	O
the	O
item	O
and	O
about	O
the	O
user	O
predict	O
the	O
proxy	O
of	O
interest	O
clicks	O
on	O
ad	O
user	O
enters	O
a	O
rating	O
user	O
clicks	O
on	O
a	O
like	O
button	O
user	O
buys	O
product	O
user	O
spends	O
some	O
amount	O
of	O
money	O
on	O
the	O
product	O
user	O
spends	O
time	O
visiting	O
a	O
page	O
for	O
the	O
product	O
etc	O
this	O
often	O
ends	O
up	O
being	O
either	O
a	O
regression	B
problem	O
some	O
conditional	O
expected	O
value	O
or	O
a	O
probabilistic	O
classification	B
problem	O
the	O
conditional	B
probability	I
of	O
some	O
discrete	O
event	O
the	O
early	O
work	O
on	O
recommender	B
systems	I
relied	O
on	O
minimal	O
information	O
as	O
inputs	O
for	O
these	O
predictions	O
the	O
user	O
id	O
and	O
the	O
item	O
id	O
in	O
this	O
context	O
the	O
only	O
way	O
to	O
generalize	O
is	O
to	O
rely	O
on	O
the	O
similarity	O
between	O
the	O
patterns	O
of	O
values	O
of	O
the	O
target	O
variable	O
for	O
different	O
users	O
or	O
for	O
different	O
items	O
suppose	O
that	O
user	O
and	O
user	O
both	O
like	O
items	O
a	O
b	O
and	O
c	O
from	O
this	O
we	O
may	O
infer	O
that	O
user	O
and	O
chapter	O
applications	O
user	O
have	O
similar	O
tastes	O
if	O
user	O
likes	O
item	O
d	O
then	O
this	O
should	O
be	O
a	O
strong	O
cue	O
that	O
user	O
will	O
also	O
like	O
d	O
algorithms	O
based	O
on	O
this	O
principle	O
come	O
under	O
the	O
name	O
of	O
collaborative	B
filtering	I
both	O
non-parametric	O
approaches	O
as	O
nearest-neighbor	O
methods	O
based	O
on	O
the	O
estimated	O
similarity	O
between	O
patterns	O
of	O
preferences	O
and	O
parametric	O
methods	O
are	O
possible	O
parametric	O
methods	O
often	O
rely	O
on	O
learning	O
a	O
distributed	O
representation	O
called	O
an	O
embedding	B
for	O
each	O
user	O
and	O
for	O
each	O
item	O
bilinear	O
prediction	O
of	O
the	O
target	O
variable	O
as	O
a	O
rating	O
is	O
a	O
simple	O
parametric	O
method	O
that	O
is	O
highly	O
successful	O
and	O
often	O
found	O
as	O
a	O
component	O
of	O
state-of-the-art	O
systems	O
the	O
prediction	O
is	O
obtained	O
by	O
the	O
dot	O
product	O
between	O
the	O
user	O
embedding	B
and	O
the	O
item	O
embedding	B
corrected	O
by	O
constants	O
that	O
depend	O
only	O
on	O
either	O
the	O
user	O
id	O
or	O
the	O
item	O
id	O
let	O
r	O
be	O
the	O
matrix	O
containing	O
our	O
predictions	O
a	O
a	O
matrix	O
with	O
user	O
embeddings	O
in	O
its	O
rows	O
and	O
b	O
a	O
matrix	O
with	O
item	O
embeddings	O
in	O
its	O
columns	O
let	O
b	O
and	O
c	O
be	O
vectors	O
that	O
contain	O
respectively	O
a	O
kind	O
of	O
bias	O
for	O
each	O
user	O
how	O
grumpy	O
or	O
positive	O
that	O
user	O
is	O
in	O
general	O
and	O
for	O
each	O
item	O
its	O
general	O
popularity	O
the	O
bilinear	O
prediction	O
is	O
thus	O
obtained	O
as	O
follows	O
rui	O
bu	O
ci	O
a	O
ujbji	O
j	O
typically	O
one	O
wants	O
to	O
minimize	O
the	O
squared	O
error	O
between	O
predicted	O
ratings	O
rui	O
and	O
actual	O
ratings	O
rui	O
user	O
embeddings	O
and	O
item	O
embeddings	O
can	O
then	O
be	O
conveniently	O
visualized	O
when	O
they	O
are	O
first	O
reduced	O
to	O
a	O
low	O
dimension	O
or	O
three	O
or	O
they	O
can	O
be	O
used	O
to	O
compare	O
users	O
or	O
items	O
against	O
each	O
other	O
just	O
like	O
word	O
embeddings	O
one	O
way	O
to	O
obtain	O
these	O
embeddings	O
is	O
by	O
performing	O
a	O
singular	B
value	I
decomposition	O
of	O
the	O
matrix	O
r	O
of	O
actual	O
targets	O
as	O
ratings	O
this	O
corresponds	O
to	O
factorizing	O
r	O
u	O
dv	O
a	O
normalized	O
variant	O
into	O
the	O
product	O
of	O
two	O
factors	O
the	O
lower	O
rank	O
matrices	O
a	O
u	O
d	O
and	O
b	O
v	O
one	O
problem	O
with	O
the	O
svd	O
is	O
that	O
it	O
treats	O
the	O
missing	O
entries	O
in	O
an	O
arbitrary	O
way	O
as	O
if	O
they	O
corresponded	O
to	O
a	O
target	O
value	O
of	O
instead	O
we	O
would	O
like	O
to	O
avoid	O
paying	O
any	O
cost	O
for	O
the	O
predictions	O
made	O
on	O
missing	O
entries	O
fortunately	O
the	O
sum	O
of	O
squared	O
errors	O
on	O
the	O
observed	O
ratings	O
can	O
also	O
be	O
easily	O
minimized	O
by	O
gradientbased	O
optimization	O
the	O
svd	O
and	O
the	O
bilinear	O
prediction	O
of	O
equation	O
both	O
performed	O
very	O
well	O
in	O
the	O
competition	O
for	O
the	O
netflix	O
prize	O
bennett	O
and	O
lanning	O
aiming	O
at	O
predicting	O
ratings	O
for	O
films	O
based	O
only	O
on	O
previous	O
ratings	O
by	O
a	O
large	O
set	O
of	O
anonymous	O
users	O
many	O
machine	B
learning	I
experts	O
participated	O
in	O
this	O
competition	O
which	O
took	O
place	O
between	O
and	O
it	O
raised	O
the	O
level	O
of	O
research	O
in	O
recommender	B
systems	I
using	O
advanced	O
machine	B
learning	I
and	O
yielded	O
improvements	O
in	O
recommender	B
systems	I
even	O
though	O
it	O
did	O
not	O
win	O
by	O
itself	O
the	O
simple	O
bilinear	O
prediction	O
or	O
svd	O
was	O
a	O
component	O
of	O
the	O
ensemble	O
models	O
chapter	O
applications	O
presented	O
by	O
most	O
of	O
the	O
competitors	O
including	O
the	O
winners	O
koren	O
t	O
scher	O
et	O
al	O
beyond	O
these	O
bilinear	O
models	O
with	O
distributed	O
representations	O
one	O
of	O
the	O
first	O
uses	O
of	O
neural	O
networks	O
for	O
collaborative	B
filtering	I
is	O
based	O
on	O
the	O
rbm	O
undirected	O
rbms	O
were	O
an	O
important	O
element	O
probabilistic	O
model	O
of	O
the	O
ensemble	O
of	O
methods	O
that	O
won	O
the	O
netflix	O
competition	O
scher	O
more	O
advanced	O
variants	O
on	O
the	O
idea	O
of	O
factorizing	O
the	O
ratings	O
matrix	O
koren	O
have	O
also	O
been	O
explored	O
in	O
the	O
neural	O
networks	O
community	O
and	O
mnih	O
et	O
al	O
et	O
al	O
however	O
there	O
is	O
a	O
basic	O
limitation	O
of	O
collaborative	B
filtering	I
systems	O
when	O
a	O
new	O
item	O
or	O
a	O
new	O
user	O
is	O
introduced	O
its	O
lack	O
of	O
rating	O
history	O
means	O
that	O
there	O
is	O
no	O
way	O
to	O
evaluate	O
its	O
similarity	O
with	O
other	O
items	O
or	O
users	O
or	O
the	O
degree	O
of	O
association	O
between	O
say	O
that	O
new	O
user	O
and	O
existing	O
items	O
this	O
is	O
called	O
the	O
problem	O
of	O
cold-start	O
recommendations	O
a	O
general	O
way	O
of	O
solving	O
the	O
cold-start	O
recommendation	O
problem	O
is	O
to	O
introduce	O
extra	O
information	O
about	O
the	O
individual	O
users	O
and	O
items	O
for	O
example	B
this	O
extra	O
information	O
could	O
be	O
user	O
profile	O
information	O
or	O
features	O
of	O
each	O
item	O
systems	O
that	O
use	O
such	O
information	O
are	O
called	O
content-based	B
recommender	B
systems	I
the	O
mapping	O
from	O
a	O
rich	O
set	O
of	O
user	O
features	O
or	O
item	O
features	O
to	O
an	O
embedding	B
can	O
be	O
learned	O
through	O
a	O
deep	O
learning	O
architecture	O
huang	O
et	O
al	O
elkahky	O
et	O
al	O
specialized	O
deep	O
learning	O
architectures	O
such	O
as	O
convolutional	O
networks	O
have	O
also	O
been	O
applied	O
to	O
learn	O
to	O
extract	O
features	O
from	O
rich	O
content	O
such	O
as	O
from	O
musical	O
audio	O
tracks	O
for	O
music	O
recommendation	O
den	O
o	O
rd	O
in	O
that	O
work	O
the	O
convolutional	O
net	O
takes	O
acoustic	O
features	O
as	O
input	O
and	O
computes	O
an	O
embedding	B
for	O
the	O
associated	O
song	O
the	O
dot	O
product	O
between	O
this	O
song	O
embedding	B
and	O
the	O
embedding	B
for	O
a	O
user	O
is	O
then	O
used	O
to	O
predict	O
whether	O
a	O
user	O
will	O
listen	O
to	O
the	O
song	O
et	O
al	O
exploration	B
versus	O
exploitation	B
langford	O
and	O
zhang	O
lu	O
et	O
al	O
when	O
making	O
recommendations	O
to	O
users	O
an	O
issue	O
arises	O
that	O
goes	O
beyond	O
ordinary	O
supervised	B
learning	I
and	O
into	O
the	O
realm	O
of	O
reinforcement	O
learning	O
many	O
recommendation	O
problems	O
are	O
most	O
accurately	O
described	O
theoretically	O
as	O
contextual	B
bandits	I
the	O
issue	O
is	O
that	O
when	O
we	O
use	O
the	O
recommendation	O
system	O
to	O
collect	O
data	O
we	O
get	O
a	O
biased	O
and	O
incomplete	O
view	O
of	O
the	O
preferences	O
of	O
users	O
we	O
only	O
see	O
the	O
responses	O
of	O
users	O
to	O
the	O
items	O
they	O
were	O
recommended	O
and	O
not	O
to	O
the	O
other	O
items	O
in	O
addition	O
in	O
some	O
cases	O
we	O
may	O
not	O
get	O
any	O
information	O
on	O
users	O
for	O
whom	O
no	O
recommendation	O
has	O
been	O
made	O
example	B
with	O
ad	O
auctions	O
it	O
may	O
be	O
that	O
the	O
price	O
proposed	O
for	O
an	O
chapter	O
applications	O
ad	O
was	O
below	O
a	O
minimum	O
price	O
threshold	O
or	O
does	O
not	O
win	O
the	O
auction	O
so	O
the	O
ad	O
is	O
not	O
shown	O
at	O
all	O
more	O
importantly	O
we	O
get	O
no	O
information	O
about	O
what	O
outcome	O
would	O
have	O
resulted	O
from	O
recommending	O
any	O
of	O
the	O
other	O
items	O
this	O
would	O
be	O
like	O
training	O
a	O
classifier	O
by	O
picking	O
one	O
class	O
y	O
for	O
each	O
training	O
example	B
x	O
the	O
class	O
with	O
the	O
highest	O
probability	O
according	O
to	O
the	O
model	O
and	O
then	O
only	O
getting	O
as	O
feedback	O
whether	O
this	O
was	O
the	O
correct	O
class	O
or	O
not	O
clearly	O
each	O
example	B
conveys	O
less	O
information	O
than	O
in	O
the	O
supervised	O
case	O
where	O
the	O
true	O
label	O
y	O
is	O
directly	O
accessible	O
so	O
more	O
examples	O
are	O
necessary	O
worse	O
if	O
we	O
are	O
not	O
careful	O
we	O
could	O
end	O
up	O
with	O
a	O
system	O
that	O
continues	O
picking	O
the	O
wrong	O
decisions	O
even	O
as	O
more	O
and	O
more	O
data	O
is	O
collected	O
because	O
the	O
correct	O
decision	O
initially	O
had	O
a	O
very	O
low	O
probability	O
until	O
the	O
learner	O
picks	O
that	O
correct	O
decision	O
it	O
does	O
not	O
learn	O
about	O
the	O
correct	O
decision	O
this	O
is	O
similar	O
to	O
the	O
situation	O
in	O
reinforcement	O
learning	O
where	O
only	O
the	O
reward	O
for	O
the	O
selected	O
action	O
is	O
observed	O
in	O
general	O
reinforcement	O
learning	O
can	O
involve	O
a	O
sequence	O
of	O
many	O
actions	O
and	O
many	O
rewards	O
the	O
bandits	O
scenario	O
is	O
a	O
special	O
case	O
of	O
reinforcement	O
learning	O
in	O
which	O
the	O
learner	O
takes	O
only	O
a	O
single	O
action	O
and	O
receives	O
a	O
single	O
reward	O
the	O
bandit	O
problem	O
is	O
easier	O
in	O
the	O
sense	O
that	O
the	O
learner	O
knows	O
which	O
reward	O
is	O
associated	O
with	O
which	O
action	O
in	O
the	O
general	O
reinforcement	O
learning	O
scenario	O
a	O
high	O
reward	O
or	O
a	O
low	O
reward	O
might	O
have	O
been	O
caused	O
by	O
a	O
recent	O
action	O
or	O
by	O
an	O
action	O
in	O
the	O
distant	O
past	O
the	O
term	O
contextual	B
bandits	I
refers	O
to	O
the	O
case	O
where	O
the	O
action	O
is	O
taken	O
in	O
the	O
context	O
of	O
some	O
input	O
variable	O
that	O
can	O
inform	O
the	O
decision	O
for	O
example	B
we	O
at	O
least	O
know	O
the	O
user	O
identity	O
and	O
we	O
want	O
to	O
pick	O
an	O
item	O
the	O
mapping	O
from	O
context	O
to	O
action	O
is	O
also	O
called	O
a	O
policy	B
the	O
feedback	O
loop	B
between	O
the	O
learner	O
and	O
the	O
data	O
distribution	O
now	O
depends	O
on	O
the	O
actions	O
of	O
the	O
learner	O
is	O
a	O
central	O
research	O
issue	O
in	O
the	O
reinforcement	O
learning	O
and	O
bandits	O
literature	O
reinforcement	O
learning	O
requires	O
choosing	O
a	O
tradeoff	O
between	O
exploration	B
and	O
exploitation	B
exploitation	B
refers	O
to	O
taking	O
actions	O
that	O
come	O
from	O
the	O
current	O
best	O
version	O
of	O
the	O
learned	O
policy	B
actions	O
that	O
we	O
know	O
will	O
achieve	O
a	O
high	O
reward	O
exploration	B
refers	O
to	O
taking	O
actions	O
specifically	O
in	O
order	O
to	O
obtain	O
more	O
training	O
data	O
if	O
we	O
know	O
that	O
given	O
context	O
x	O
action	O
a	O
gives	O
us	O
a	O
reward	O
of	O
we	O
do	O
not	O
know	O
whether	O
that	O
is	O
the	O
best	O
possible	O
reward	O
we	O
may	O
want	O
to	O
exploit	O
our	O
current	O
policy	B
and	O
continue	O
taking	O
action	O
a	O
in	O
order	O
to	O
be	O
relatively	O
sure	O
of	O
obtaining	O
a	O
reward	O
of	O
however	O
we	O
may	O
also	O
want	O
to	O
explore	O
by	O
trying	O
action	O
a	O
we	O
do	O
not	O
know	O
what	O
will	O
happen	O
if	O
we	O
try	O
action	O
a	O
but	O
we	O
either	O
way	O
we	O
at	O
least	O
gain	O
some	O
knowledge	O
run	O
the	O
risk	B
of	O
getting	O
a	O
reward	O
of	O
we	O
hope	O
to	O
get	O
a	O
reward	O
of	O
exploration	B
can	O
be	O
implemented	O
in	O
many	O
ways	O
ranging	O
from	O
occasionally	O
taking	O
random	O
actions	O
intended	O
to	O
cover	O
the	O
entire	O
space	O
of	O
possible	O
actions	O
to	O
model-based	O
approaches	O
that	O
compute	O
a	O
choice	O
of	O
action	O
based	O
on	O
its	O
expected	O
reward	O
and	O
the	O
model	O
s	O
amount	O
of	O
uncertainty	O
about	O
that	O
reward	O
chapter	O
applications	O
many	O
factors	O
determine	O
the	O
extent	O
to	O
which	O
we	O
prefer	O
exploration	B
or	O
exploitation	B
one	O
of	O
the	O
most	O
prominent	O
factors	O
is	O
the	O
time	O
scale	O
we	O
are	O
interested	O
in	O
if	O
the	O
agent	O
has	O
only	O
a	O
short	O
amount	O
of	O
time	O
to	O
accrue	O
reward	O
then	O
we	O
prefer	O
more	O
exploitation	B
if	O
the	O
agent	O
has	O
a	O
long	O
time	O
to	O
accrue	O
reward	O
then	O
we	O
begin	O
with	O
more	O
exploration	B
so	O
that	O
future	O
actions	O
can	O
be	O
planned	O
more	O
effectively	O
with	O
more	O
knowledge	O
as	O
time	O
progresses	O
and	O
our	O
learned	O
policy	B
improves	O
we	O
move	O
toward	O
more	O
exploitation	B
supervised	B
learning	I
has	O
no	O
tradeoff	O
between	O
exploration	B
and	O
exploitation	B
because	O
the	O
supervision	O
signal	O
always	O
specifies	O
which	O
output	O
is	O
correct	O
for	O
each	O
input	O
there	O
is	O
no	O
need	O
to	O
try	O
out	O
different	O
outputs	O
to	O
determine	O
if	O
one	O
is	O
better	O
than	O
the	O
model	O
s	O
current	O
output	O
we	O
always	O
know	O
that	O
the	O
label	O
is	O
the	O
best	O
output	O
another	O
difficulty	O
arising	O
in	O
the	O
context	O
of	O
reinforcement	O
learning	O
besides	O
the	O
exploration-exploitation	O
trade-off	O
is	O
the	O
difficulty	O
of	O
evaluating	O
and	O
comparing	O
different	O
policies	O
reinforcement	O
learning	O
involves	O
interaction	O
between	O
the	O
learner	O
and	O
the	O
environment	O
this	O
feedback	O
loop	B
means	O
that	O
it	O
is	O
not	O
straightforward	O
to	O
evaluate	O
the	O
learner	O
s	O
performance	O
using	O
a	O
fixed	O
set	O
of	O
test	B
set	I
input	O
values	O
the	O
policy	B
itself	O
determines	O
which	O
inputs	O
will	O
be	O
seen	O
present	O
techniques	O
for	O
evaluating	O
contextual	B
bandits	I
dudik	O
et	O
al	O
knowledge	O
representation	O
reasoning	O
and	O
question	O
an	O
swering	O
rumelhart	O
et	O
al	O
deep	O
learning	O
approaches	O
have	O
been	O
very	O
successful	O
in	O
language	O
modeling	O
machine	B
translation	I
and	O
natural	B
language	I
processing	I
due	O
to	O
the	O
use	O
of	O
embeddings	O
for	O
symbols	O
et	O
al	O
these	O
embeddings	O
represent	O
semantic	O
knowledge	O
about	O
individual	O
words	O
and	O
concepts	O
a	O
research	O
frontier	O
is	O
to	O
develop	O
embeddings	O
for	O
phrases	O
and	O
for	O
relations	B
between	O
words	O
and	O
facts	O
search	O
engines	O
already	O
use	O
machine	B
learning	I
for	O
this	O
purpose	O
but	O
much	O
more	O
remains	O
to	O
be	O
done	O
to	O
improve	O
these	O
more	O
advanced	O
representations	O
and	O
words	O
deerwester	O
et	O
al	O
bengio	O
knowledge	O
relations	B
and	O
question	O
answering	O
one	O
interesting	O
research	O
direction	O
is	O
determining	O
how	O
distributed	O
representations	O
can	O
be	O
trained	O
to	O
capture	O
the	O
relations	B
between	O
two	O
entities	O
these	O
relations	B
allow	O
us	O
to	O
formalize	O
facts	O
about	O
objects	O
and	O
how	O
objects	O
interact	O
with	O
each	O
other	O
in	O
mathematics	O
a	O
binary	B
relation	I
is	O
a	O
set	O
of	O
ordered	O
pairs	O
of	O
objects	O
pairs	O
that	O
are	O
in	O
the	O
set	O
are	O
said	O
to	O
have	O
the	O
relation	O
while	O
those	O
who	O
are	O
not	O
in	O
the	O
set	O
chapter	O
applications	O
by	O
defining	O
the	O
set	O
of	O
ordered	O
pairs	O
s	O
do	O
not	O
for	O
example	B
we	O
can	O
define	O
the	O
relation	O
is	O
less	O
than	O
on	O
the	O
set	O
of	O
entities	O
once	O
this	O
relation	O
is	O
defined	O
we	O
can	O
use	O
it	O
like	O
a	O
verb	O
because	O
s	O
we	O
say	O
that	O
is	O
less	O
than	O
because	O
s	O
we	O
can	O
not	O
say	O
that	O
is	O
less	O
than	O
of	O
course	O
the	O
entities	O
that	O
are	O
related	O
to	O
one	O
another	O
need	O
not	O
be	O
numbers	O
we	O
could	O
define	O
a	O
relation	O
containing	O
tuples	O
like	O
is	O
a	O
type	O
of	O
dog	O
mammal	O
in	O
the	O
context	O
of	O
ai	O
we	O
think	O
of	O
a	O
relation	O
as	O
a	O
sentence	O
in	O
a	O
syntactically	O
simple	O
and	O
highly	O
structured	O
language	O
the	O
relation	O
plays	O
the	O
role	O
of	O
a	O
verb	O
while	O
two	O
arguments	O
to	O
the	O
relation	O
play	O
the	O
role	O
of	O
its	O
subject	O
and	O
object	O
these	O
sentences	O
take	O
the	O
form	O
of	O
a	O
triplet	O
of	O
tokens	O
verb	O
object	O
with	O
values	O
relationj	O
entity	O
k	O
we	O
can	O
also	O
define	O
an	O
attribute	O
a	O
concept	O
analogous	O
to	O
a	O
relation	O
but	O
taking	O
only	O
one	O
argument	O
attribute	O
j	O
for	O
example	B
we	O
could	O
define	O
the	O
has	O
fur	O
attribute	O
and	O
apply	O
it	O
to	O
entities	O
like	O
dog	O
many	O
applications	O
require	O
representing	O
relations	B
and	O
reasoning	O
about	O
them	O
how	O
should	O
we	O
best	O
do	O
this	O
within	O
the	O
context	O
of	O
neural	O
networks	O
machine	B
learning	I
models	O
of	O
course	O
require	O
training	O
data	O
we	O
can	O
infer	O
relations	B
between	O
entities	O
from	O
training	O
datasets	O
consisting	O
of	O
unstructured	O
natural	O
language	O
there	O
are	O
also	O
structured	O
databases	O
that	O
identify	O
relations	B
explicitly	O
a	O
common	O
structure	O
for	O
these	O
databases	O
is	O
the	O
relational	B
database	I
which	O
stores	O
this	O
same	O
kind	O
of	O
information	O
albeit	O
not	O
formatted	O
as	O
three	O
token	O
sentences	O
when	O
a	O
database	O
is	O
intended	O
to	O
convey	O
commonsense	O
knowledge	O
about	O
everyday	O
life	O
or	O
expert	O
knowledge	O
about	O
an	O
application	O
area	O
to	O
an	O
artificial	B
intelligence	I
system	O
we	O
call	O
the	O
database	O
a	O
knowledge	O
base	O
knowledge	O
bases	O
range	O
from	O
general	O
ones	O
like	O
freebase	B
opencyc	O
wordnet	B
or	O
wikibase	B
etc	O
to	O
more	O
specialized	O
knowledge	O
bases	O
like	O
representations	O
for	O
entities	O
and	O
relations	B
can	O
be	O
learned	O
by	O
considering	O
each	O
triplet	O
in	O
a	O
knowledge	O
base	O
as	O
a	O
training	O
example	B
and	O
maximizing	O
a	O
training	O
objective	O
that	O
captures	O
their	O
joint	O
distribution	O
et	O
al	O
available	O
from	O
these	O
web	O
sites	O
freebase	B
com	O
cyc	B
comopencyc	O
wordnet	B
princeton	O
edu	O
wikiba	O
se	O
chapter	O
applications	O
in	O
addition	O
to	O
training	O
data	O
we	O
also	O
need	O
to	O
define	O
a	O
model	O
family	O
to	O
train	O
a	O
common	O
approach	O
is	O
to	O
extend	O
neural	O
language	O
models	O
to	O
model	O
entities	O
and	O
relations	B
neural	O
language	O
models	O
learn	O
a	O
vector	O
that	O
provides	O
a	O
distributed	O
representation	O
of	O
each	O
word	O
they	O
also	O
learn	O
about	O
interactions	O
between	O
words	O
such	O
as	O
which	O
word	O
is	O
likely	O
to	O
come	O
after	O
a	O
sequence	O
of	O
words	O
by	O
learning	O
functions	O
of	O
these	O
vectors	O
we	O
can	O
extend	O
this	O
approach	O
to	O
entities	O
and	O
relations	B
by	O
learning	O
an	O
embedding	B
vector	O
for	O
each	O
relation	O
in	O
fact	O
the	O
parallel	O
between	O
modeling	O
language	O
and	O
modeling	O
knowledge	O
encoded	O
as	O
relations	B
is	O
so	O
close	O
that	O
researchers	O
and	O
have	O
trained	O
representations	O
of	O
such	O
entities	O
by	O
using	O
both	O
natural	O
language	O
sentences	O
or	O
combining	O
data	O
from	O
multiple	O
relational	O
databases	O
many	O
possibilities	O
exist	O
for	O
the	O
particular	O
parametrization	O
associated	O
with	O
such	O
a	O
model	O
early	O
work	O
on	O
learning	O
about	O
relations	B
between	O
entities	O
paccanaro	O
and	O
hinton	O
posited	O
highly	O
constrained	O
parametric	O
forms	O
linear	O
relational	O
embeddings	O
often	O
using	O
a	O
different	O
form	O
of	O
representation	O
for	O
the	O
relation	O
than	O
for	O
the	O
entities	O
for	O
example	B
paccanaro	O
and	O
hinton	O
used	O
vectors	O
for	O
entities	O
and	O
matrices	O
for	O
relations	B
with	O
the	O
idea	O
that	O
a	O
relation	O
acts	O
like	O
an	O
operator	O
on	O
entities	O
alternatively	O
relations	B
can	O
be	O
considered	O
as	O
any	O
other	O
entity	O
et	O
al	O
allowing	O
us	O
to	O
make	O
statements	O
about	O
relations	B
but	O
more	O
flexibility	O
is	O
put	O
in	O
the	O
machinery	O
that	O
combines	O
them	O
in	O
order	O
to	O
model	O
their	O
joint	O
distribution	O
knowledge	O
bases	O
bordes	O
et	O
al	O
wang	O
bordes	O
et	O
al	O
bordes	O
et	O
al	O
et	O
al	O
and	O
a	O
practical	O
short-term	O
application	O
of	O
such	O
models	O
is	O
link	B
prediction	I
predicting	O
missing	O
arcs	O
in	O
the	O
knowledge	O
graph	O
this	O
is	O
a	O
form	O
of	O
generalization	B
to	O
new	O
facts	O
based	O
on	O
old	O
facts	O
most	O
of	O
the	O
knowledge	O
bases	O
that	O
currently	O
exist	O
have	O
been	O
constructed	O
through	O
manual	O
labor	O
which	O
tends	O
to	O
leave	O
many	O
and	O
probably	O
the	O
majority	O
of	O
true	O
relations	B
absent	O
from	O
the	O
knowledge	O
base	O
see	O
wang	O
et	O
al	O
lin	O
et	O
al	O
for	O
examples	O
of	O
such	O
an	O
application	O
garcia-duran	O
et	O
al	O
and	O
evaluating	O
the	O
performance	O
of	O
a	O
model	O
on	O
a	O
link	B
prediction	I
task	O
is	O
difficult	O
because	O
we	O
have	O
only	O
a	O
dataset	B
of	O
positive	O
examples	O
that	O
are	O
known	O
to	O
be	O
true	O
if	O
the	O
model	O
proposes	O
a	O
fact	O
that	O
is	O
not	O
in	O
the	O
dataset	B
we	O
are	O
unsure	O
whether	O
the	O
model	O
has	O
made	O
a	O
mistake	O
or	O
discovered	O
a	O
new	O
previously	O
unknown	O
fact	O
the	O
metrics	O
are	O
thus	O
somewhat	O
imprecise	O
and	O
are	O
based	O
on	O
testing	O
how	O
the	O
model	O
ranks	O
a	O
held-out	O
of	O
set	O
of	O
known	O
true	O
positive	O
facts	O
compared	O
to	O
other	O
facts	O
that	O
are	O
less	O
likely	O
to	O
be	O
true	O
a	O
common	O
way	O
to	O
construct	O
interesting	O
examples	O
that	O
are	O
probably	O
negative	O
that	O
are	O
probably	O
false	O
is	O
to	O
begin	O
with	O
a	O
true	O
fact	O
and	O
create	O
corrupted	O
versions	O
of	O
that	O
fact	O
for	O
example	B
by	O
replacing	O
one	O
entity	O
in	O
the	O
relation	O
with	O
a	O
different	O
entity	O
selected	O
at	O
random	O
the	O
popular	O
precision	B
at	O
metric	O
counts	O
how	O
many	O
times	O
the	O
model	O
ranks	O
a	O
correct	O
fact	O
among	O
the	O
top	O
of	O
all	O
corrupted	O
versions	O
of	O
that	O
fact	O
chapter	O
applications	O
another	O
application	O
of	O
knowledge	O
bases	O
and	O
distributed	O
representations	O
for	O
them	O
is	O
word-sense	B
disambiguation	I
and	O
velardi	O
bordes	O
et	O
al	O
which	O
is	O
the	O
task	O
of	O
deciding	O
which	O
of	O
the	O
senses	O
of	O
a	O
word	O
is	O
the	O
appropriate	O
one	O
in	O
some	O
context	O
eventually	O
knowledge	O
of	O
relations	B
combined	O
with	O
a	O
reasoning	O
process	O
and	O
understanding	O
of	O
natural	O
language	O
could	O
allow	O
us	O
to	O
build	O
a	O
general	O
question	O
answering	O
system	O
a	O
general	O
question	O
answering	O
system	O
must	O
be	O
able	O
to	O
process	O
input	O
information	O
and	O
remember	O
important	O
facts	O
organized	O
in	O
a	O
way	O
that	O
enables	O
it	O
to	O
retrieve	O
and	O
reason	O
about	O
them	O
later	O
this	O
remains	O
a	O
difficult	O
open	O
problem	O
which	O
can	O
only	O
be	O
solved	O
in	O
restricted	O
toy	O
environments	O
currently	O
the	O
best	O
approach	O
to	O
remembering	O
and	O
retrieving	O
specific	O
declarative	O
facts	O
is	O
to	O
use	O
an	O
memory	O
networks	O
were	O
explicit	O
memory	O
mechanism	O
as	O
described	O
in	O
section	O
first	O
proposed	O
to	O
solve	O
a	O
toy	O
question	O
answering	O
task	O
kumar	O
et	O
al	O
have	O
proposed	O
an	O
extension	O
that	O
uses	O
gru	O
recurrent	O
nets	O
to	O
read	O
the	O
input	O
into	O
the	O
memory	O
and	O
to	O
produce	O
the	O
answer	O
given	O
the	O
contents	O
of	O
the	O
memory	O
et	O
al	O
deep	O
learning	O
has	O
been	O
applied	O
to	O
many	O
other	O
applications	O
besides	O
the	O
ones	O
described	O
here	O
and	O
will	O
surely	O
be	O
applied	O
to	O
even	O
more	O
after	O
this	O
writing	O
it	O
would	O
be	O
impossible	O
to	O
describe	O
anything	O
remotely	O
resembling	O
a	O
comprehensive	O
coverage	B
of	O
such	O
a	O
topic	O
this	O
survey	O
provides	O
a	O
representative	O
sample	O
of	O
what	O
is	O
possible	O
as	O
of	O
this	O
writing	O
ii	O
this	O
concludes	O
part	O
which	O
has	O
described	O
modern	O
practices	O
involving	O
deep	O
networks	O
comprising	O
all	O
of	O
the	O
most	O
successful	O
methods	O
generally	O
speaking	O
these	O
methods	O
involve	O
using	O
the	O
gradient	B
of	O
a	O
cost	O
function	O
to	O
find	O
the	O
parameters	O
of	O
a	O
model	O
that	O
approximates	O
some	O
desired	O
function	O
with	O
enough	O
training	O
data	O
this	O
approach	O
is	O
extremely	O
powerful	O
we	O
now	O
turn	O
to	O
part	O
in	O
which	O
we	O
step	O
into	O
the	O
territory	O
of	O
research	O
methods	O
that	O
are	O
designed	O
to	O
work	O
with	O
less	O
training	O
data	O
or	O
to	O
perform	O
a	O
greater	O
variety	O
of	O
tasks	O
where	O
the	O
challenges	O
are	O
more	O
difficult	O
and	O
not	O
as	O
close	O
to	O
being	O
solved	O
as	O
the	O
situations	O
we	O
have	O
described	O
so	O
far	O
iii	O
part	O
iii	O
deep	O
learning	O
research	O
this	O
part	O
of	O
the	O
book	O
describes	O
the	O
more	O
ambitious	O
and	O
advanced	O
approaches	O
to	O
deep	O
learning	O
currently	O
pursued	O
by	O
the	O
research	O
community	O
in	O
the	O
previous	O
parts	O
of	O
the	O
book	O
we	O
have	O
shown	O
how	O
to	O
solve	O
supervised	B
learning	I
problems	O
how	O
to	O
learn	O
to	O
map	O
one	O
vector	O
to	O
another	O
given	O
enough	O
examples	O
of	O
the	O
mapping	O
not	O
all	O
problems	O
we	O
might	O
want	O
to	O
solve	O
fall	O
into	O
this	O
category	O
we	O
may	O
wish	O
to	O
generate	O
new	O
examples	O
or	O
determine	O
how	O
likely	O
some	O
point	O
is	O
or	O
handle	O
missing	O
values	O
and	O
take	O
advantage	O
of	O
a	O
large	O
set	O
of	O
unlabeled	O
examples	O
or	O
examples	O
from	O
related	O
tasks	O
a	O
shortcoming	O
of	O
the	O
current	O
state	O
of	O
the	O
art	O
for	O
industrial	O
applications	O
is	O
that	O
our	O
learning	O
algorithms	O
require	O
large	O
amounts	O
of	O
supervised	O
data	O
to	O
achieve	O
good	O
accuracy	B
in	O
this	O
part	O
of	O
the	O
book	O
we	O
discuss	O
some	O
of	O
the	O
speculative	O
approaches	O
to	O
reducing	O
the	O
amount	O
of	O
labeled	O
data	O
necessary	O
for	O
existing	O
models	O
to	O
work	O
well	O
and	O
be	O
applicable	O
across	O
a	O
broader	O
range	O
of	O
tasks	O
accomplishing	O
these	O
goals	O
usually	O
requires	O
some	O
form	O
of	O
unsupervised	O
or	O
semi-supervised	B
learning	I
many	O
deep	O
learning	O
algorithms	O
have	O
been	O
designed	O
to	O
tackle	O
unsupervised	O
learning	O
problems	O
but	O
none	O
have	O
truly	O
solved	O
the	O
problem	O
in	O
the	O
same	O
way	O
that	O
deep	O
learning	O
has	O
largely	O
solved	O
the	O
supervised	B
learning	I
problem	O
for	O
a	O
wide	O
variety	O
of	O
tasks	O
in	O
this	O
part	O
of	O
the	O
book	O
we	O
describe	O
the	O
existing	O
approaches	O
to	O
unsupervised	O
learning	O
and	O
some	O
of	O
the	O
popular	O
thought	O
about	O
how	O
we	O
can	O
make	O
progress	O
in	O
this	O
field	O
a	O
central	O
cause	O
of	O
the	O
difficulties	O
with	O
unsupervised	O
learning	O
is	O
the	O
high	O
dimensionality	O
of	O
the	O
random	O
variables	O
being	O
modeled	O
this	O
brings	O
two	O
distinct	O
challenges	O
a	O
statistical	O
challenge	B
and	O
a	O
computational	O
challenge	B
the	O
statistical	O
challenge	B
regards	O
generalization	B
the	O
number	O
of	O
configurations	O
we	O
may	O
want	O
to	O
distinguish	O
can	O
grow	O
exponentially	O
with	O
the	O
number	O
of	O
dimensions	O
of	O
interest	O
and	O
this	O
quickly	O
becomes	O
much	O
larger	O
than	O
the	O
number	O
of	O
examples	O
one	O
can	O
possibly	O
have	O
use	O
with	O
bounded	O
computational	O
resources	O
the	O
computational	O
challenge	B
associated	O
with	O
high-dimensional	O
distributions	O
arises	O
because	O
many	O
algorithms	O
for	O
learning	O
or	O
using	O
a	O
trained	O
model	O
those	O
based	O
on	O
estimating	O
an	O
explicit	O
probability	O
function	O
involve	O
intractable	O
computations	O
that	O
grow	O
exponentially	O
with	O
the	O
number	O
of	O
dimensions	O
with	O
probabilistic	O
models	O
this	O
computational	O
challenge	B
arises	O
from	O
the	O
need	O
to	O
perform	O
intractable	O
inference	O
or	O
simply	O
from	O
the	O
need	O
to	O
normalize	O
the	O
distribution	O
intractable	O
inference	O
inference	O
is	O
discussed	O
mostly	O
in	O
chapter	O
it	O
regards	O
the	O
question	O
of	O
guessing	O
the	O
probable	O
values	O
of	O
some	O
variables	O
a	O
given	O
other	O
variables	O
b	O
with	O
respect	O
to	O
a	O
model	O
that	O
captures	O
the	O
joint	O
distribution	O
over	O
a	O
b	O
and	O
c	O
in	O
order	O
to	O
even	O
compute	O
such	O
conditional	O
probabilities	O
one	O
needs	O
to	O
sum	O
over	O
the	O
values	O
of	O
the	O
variables	O
c	O
as	O
well	O
as	O
compute	O
a	O
normalization	O
constant	O
which	O
sums	O
over	O
the	O
values	O
of	O
a	O
and	O
c	O
intractable	O
normalization	O
constants	O
partition	O
function	O
the	O
partition	O
function	O
is	O
discussed	O
mostly	O
in	O
chapter	O
normalizing	O
constants	O
of	O
probability	O
functions	O
come	O
up	O
in	O
inference	O
as	O
well	O
as	O
in	O
learning	O
many	O
probabilistic	O
models	O
involve	O
such	O
a	O
normalizing	O
constant	O
unfortunately	O
learning	O
such	O
a	O
model	O
often	O
requires	O
computing	O
the	O
gradient	B
of	O
the	O
logarithm	O
of	O
the	O
partition	O
function	O
with	O
respect	O
to	O
the	O
model	O
parameters	O
that	O
computation	O
is	O
generally	O
as	O
intractable	O
as	O
computing	O
the	O
partition	O
function	O
itself	O
monte	O
carlo	O
markov	B
chain	I
methods	O
are	O
often	O
used	O
to	O
deal	O
with	O
the	O
partition	O
function	O
it	O
or	O
its	O
gradient	B
unfortunately	O
mcmc	O
methods	O
suffer	O
when	O
the	O
modes	O
of	O
the	O
model	O
distribution	O
are	O
numerous	O
and	O
well-separated	O
especially	O
in	O
high-dimensional	O
spaces	O
one	O
way	O
to	O
confront	O
these	O
intractable	O
computations	O
is	O
to	O
approximate	O
them	O
and	O
many	O
approaches	O
have	O
been	O
proposed	O
as	O
discussed	O
in	O
this	O
third	O
part	O
of	O
the	O
book	O
another	O
interesting	O
way	O
also	O
discussed	O
here	O
would	O
be	O
to	O
avoid	O
these	O
intractable	O
computations	O
altogether	O
by	O
design	O
and	O
methods	O
that	O
do	O
not	O
require	O
such	O
computations	O
are	O
thus	O
very	O
appealing	O
several	O
generative	O
models	O
have	O
been	O
proposed	O
in	O
recent	O
years	O
with	O
that	O
motivation	O
a	O
wide	O
variety	O
of	O
contemporary	O
approaches	O
to	O
generative	O
modeling	O
are	O
discussed	O
in	O
chapter	O
iii	O
part	O
is	O
the	O
most	O
important	O
for	O
a	O
researcher	O
someone	O
who	O
wants	O
to	O
understand	O
the	O
breadth	O
of	O
perspectives	O
that	O
have	O
been	O
brought	O
to	O
the	O
field	O
of	O
deep	O
learning	O
and	O
push	O
the	O
field	O
forward	O
towards	O
true	O
artificial	B
intelligence	I
chapter	O
linear	B
factor	I
models	I
many	O
of	O
the	O
research	O
frontiers	O
in	O
deep	O
learning	O
involve	O
building	O
a	O
probabilistic	O
model	O
of	O
the	O
input	O
pmodelx	O
such	O
a	O
model	O
can	O
in	O
principle	O
use	O
probabilistic	O
inference	O
to	O
predict	O
any	O
of	O
the	O
variables	O
in	O
its	O
environment	O
given	O
any	O
of	O
the	O
other	O
variables	O
many	O
of	O
these	O
models	O
also	O
have	O
latent	O
variables	O
h	O
with	O
pmodel	O
x	O
h	O
these	O
latent	O
variables	O
provide	O
another	O
means	O
of	O
representing	O
the	O
data	O
distributed	O
representations	O
based	O
on	O
latent	O
variables	O
can	O
obtain	O
all	O
of	O
the	O
advantages	O
of	O
representation	B
learning	I
that	O
we	O
have	O
seen	O
with	O
deep	O
feedforward	O
and	O
recurrent	O
networks	O
ehpmodel	O
x	O
in	O
this	O
chapter	O
we	O
describe	O
some	O
of	O
the	O
simplest	O
probabilistic	O
models	O
with	O
latent	O
variables	O
linear	B
factor	I
models	I
these	O
models	O
are	O
sometimes	O
used	O
as	O
building	O
ghahramani	O
and	O
hinton	O
blocks	O
of	O
mixture	O
models	O
they	O
roweis	O
also	O
show	O
many	O
of	O
the	O
basic	O
approaches	O
necessary	O
to	O
build	O
generative	O
models	O
that	O
the	O
more	O
advanced	O
deep	O
models	O
will	O
extend	O
further	O
or	O
larger	O
deep	O
probabilistic	O
models	O
et	O
al	O
et	O
al	O
et	O
al	O
tang	O
a	O
linear	O
factor	O
model	O
is	O
defined	O
by	O
the	O
use	O
of	O
a	O
stochastic	O
linear	O
decoder	B
function	O
that	O
generates	O
x	O
by	O
adding	O
noise	O
to	O
a	O
linear	O
transformation	O
of	O
h	O
these	O
models	O
are	O
interesting	O
because	O
they	O
allow	O
us	O
to	O
discover	O
explanatory	O
factors	O
that	O
have	O
a	O
simple	O
joint	O
distribution	O
the	O
simplicity	O
of	O
using	O
a	O
linear	O
decoder	B
made	O
these	O
models	O
some	O
of	O
the	O
first	O
latent	B
variable	I
models	O
to	O
be	O
extensively	O
studied	O
a	O
linear	O
factor	O
model	O
describes	O
the	O
data	O
generation	O
process	O
as	O
follows	O
first	O
we	O
sample	O
the	O
explanatory	O
factors	O
h	O
h	O
from	O
a	O
distribution	O
p	O
where	O
ph	O
is	O
a	O
factorial	O
distribution	O
with	O
ph	O
i	O
phi	O
so	O
that	O
it	O
is	O
easy	O
to	O
chapter	O
linear	B
factor	I
models	I
sample	O
from	O
next	O
we	O
sample	O
the	O
real-valued	O
observable	O
variables	O
given	O
the	O
factors	O
x	O
w	O
h	O
b	O
noise	O
where	O
the	O
noise	O
is	O
typically	O
gaussian	O
and	O
diagonal	O
across	O
dimensions	O
this	O
is	O
illustrated	O
in	O
figure	O
x	O
x	O
w	O
w	O
h	O
h	O
n	O
ois	O
e	O
n	O
ois	O
e	O
figure	O
the	O
directed	O
graphical	O
model	O
describing	O
the	O
linear	O
factor	O
model	O
family	O
in	O
which	O
we	O
assume	O
that	O
an	O
observed	O
data	O
vector	O
x	O
is	O
obtained	O
by	O
a	O
linear	B
combination	I
of	O
independent	O
latent	O
factors	O
h	O
plus	O
some	O
noise	O
different	O
models	O
such	O
as	O
probabilistic	O
pca	O
factor	B
analysis	I
or	O
ica	O
make	O
different	O
choices	O
about	O
the	O
form	O
of	O
the	O
noise	O
and	O
of	O
the	O
prior	O
p	O
probabilistic	O
pca	O
and	O
factor	B
analysis	I
probabilistic	O
pca	O
components	O
analysis	O
factor	B
analysis	I
and	O
other	O
linear	B
factor	I
models	I
are	O
special	O
cases	O
of	O
the	O
above	O
equations	O
and	O
only	O
differ	O
in	O
the	O
choices	O
made	O
for	O
the	O
noise	O
distribution	O
and	O
the	O
model	O
s	O
prior	O
over	O
latent	O
variables	O
before	O
observing	O
and	O
x	O
h	O
bartholomew	O
basilevsky	O
the	O
latent	B
variable	I
in	O
factor	B
analysis	I
prior	O
is	O
just	O
the	O
unit	O
variance	O
gaussian	O
n	O
h	O
i	O
while	O
the	O
observed	O
variables	O
xi	O
are	O
assumed	O
to	O
be	O
conditionally	O
independent	O
given	O
h	O
specifically	O
the	O
noise	O
is	O
assumed	O
to	O
be	O
drawn	O
from	O
a	O
diagonal	O
covariance	O
gaussian	O
distribution	O
with	O
covariance	B
matrix	I
diag	O
with	O
a	O
vector	O
of	O
per-variable	O
variances	O
n	O
the	O
role	O
of	O
the	O
latent	O
variables	O
is	O
thus	O
to	O
capture	O
the	O
dependencies	O
between	O
the	O
different	O
observed	O
variables	O
xi	O
indeed	O
it	O
can	O
easily	O
be	O
shown	O
that	O
x	O
is	O
just	O
a	O
multivariate	O
normal	O
random	B
variable	I
with	O
n	O
x	O
b	O
w	O
w	O
chapter	O
linear	B
factor	I
models	I
in	O
order	O
to	O
cast	O
pca	O
in	O
a	O
probabilistic	O
framework	O
we	O
can	O
make	O
a	O
slight	O
modification	O
to	O
the	O
factor	B
analysis	I
model	O
making	O
the	O
conditional	O
variances	O
i	O
i	O
where	O
equal	O
to	O
each	O
other	O
in	O
that	O
case	O
the	O
covariance	O
of	O
x	O
is	O
just	O
w	O
w	O
is	O
now	O
a	O
scalar	O
this	O
yields	O
the	O
conditional	O
distribution	O
x	O
or	O
equivalently	O
n	O
b	O
w	O
w	O
x	O
w	O
h	O
z	O
n	O
where	O
z	O
iterative	O
em	O
algorithm	O
for	O
estimating	O
the	O
parameters	O
tipping	O
and	O
bishop	O
i	O
is	O
gaussian	O
noise	O
andw	O
then	O
show	O
an	O
this	O
probabilistic	O
pca	O
model	O
takes	O
advantage	O
of	O
the	O
observation	O
that	O
most	O
variations	O
in	O
the	O
data	O
can	O
be	O
captured	O
by	O
the	O
latent	O
variables	O
h	O
up	O
to	O
some	O
small	O
residual	O
reconstruction	O
error	O
as	O
shown	O
by	O
in	O
that	O
case	O
the	O
conditional	O
expected	O
probabilistic	O
pca	O
becomes	O
pca	O
as	O
value	O
of	O
h	O
given	O
x	O
becomes	O
an	O
orthogonal	O
projection	O
of	O
x	O
onto	O
the	O
space	O
spanned	O
by	O
the	O
tipping	O
and	O
bishop	O
like	O
in	O
pca	O
columns	O
of	O
w	O
d	O
b	O
as	O
the	O
density	O
model	O
defined	O
by	O
probabilistic	O
pca	O
becomes	O
very	O
sharp	O
around	O
these	O
d	O
dimensions	O
spanned	O
by	O
the	O
columns	O
of	O
w	O
this	O
can	O
make	O
the	O
model	O
assign	O
very	O
low	O
likelihood	O
to	O
the	O
data	O
if	O
the	O
data	O
does	O
not	O
actually	O
cluster	O
near	O
a	O
hyperplane	O
independent	B
component	I
analysis	I
independent	B
component	I
analysis	I
is	O
among	O
the	O
oldest	O
representation	B
learning	I
herault	O
and	O
ans	O
jutten	O
and	O
herault	O
comon	O
algorithms	O
hyv	O
rinen	O
hyv	O
rinen	O
it	O
is	O
an	O
approach	O
to	O
modeling	O
linear	O
factors	O
that	O
seeks	O
to	O
separate	O
an	O
observed	O
signal	O
into	O
many	O
underlying	O
signals	O
that	O
are	O
scaled	O
and	O
added	O
together	O
to	O
form	O
the	O
observed	O
data	O
these	O
signals	O
are	O
intended	O
to	O
be	O
fully	O
independent	O
rather	O
than	O
merely	O
decorrelated	O
from	O
each	O
hinton	O
teh	O
et	O
al	O
et	O
al	O
et	O
al	O
many	O
different	O
specific	O
methodologies	O
are	O
referred	O
to	O
as	O
ica	O
the	O
variant	O
that	O
is	O
most	O
similar	O
to	O
the	O
other	O
generative	O
models	O
we	O
have	O
described	O
here	O
is	O
a	O
variant	O
that	O
trains	O
a	O
fully	O
parametric	O
generative	O
model	O
the	O
prior	O
distribution	O
over	O
the	O
underlying	O
factors	O
ph	O
must	O
be	O
fixed	O
ahead	O
of	O
time	O
by	O
the	O
user	O
the	O
model	O
then	O
deterministically	O
generates	O
x	O
w	O
h	O
we	O
can	O
perform	O
a	O
pham	O
et	O
al	O
section	O
dent	O
variables	O
for	O
a	O
discussion	O
of	O
the	O
difference	O
between	O
uncorrelated	O
variables	O
and	O
indepen	O
chapter	O
linear	B
factor	I
models	I
nonlinear	O
change	O
of	O
variables	O
equation	O
the	O
model	O
then	O
proceeds	O
as	O
usual	O
using	O
maximum	B
likelihood	I
to	O
determine	O
px	O
learning	O
the	O
motivation	O
for	O
this	O
approach	O
is	O
that	O
by	O
choosing	O
ph	O
to	O
be	O
independent	O
we	O
can	O
recover	O
underlying	O
factors	O
that	O
are	O
as	O
close	O
as	O
possible	O
to	O
independent	O
this	O
is	O
commonly	O
used	O
not	O
to	O
capture	O
high-level	O
abstract	O
causal	O
factors	O
but	O
to	O
recover	O
low-level	O
signals	O
that	O
have	O
been	O
mixed	O
together	O
in	O
this	O
setting	O
each	O
training	O
example	B
is	O
one	O
moment	O
in	O
time	O
each	O
xi	O
is	O
one	O
sensor	O
s	O
observation	O
of	O
the	O
mixed	O
signals	O
and	O
each	O
hi	O
is	O
one	O
estimate	O
of	O
one	O
of	O
the	O
original	O
signals	O
for	O
example	B
we	O
might	O
have	O
n	O
people	O
speaking	O
simultaneously	O
if	O
we	O
have	O
n	O
different	O
microphones	O
placed	O
in	O
different	O
locations	O
ica	O
can	O
detect	O
the	O
changes	O
in	O
the	O
volume	O
between	O
each	O
speaker	O
as	O
heard	O
by	O
each	O
microphone	O
and	O
separate	O
the	O
signals	O
so	O
that	O
each	O
h	O
i	O
contains	O
only	O
one	O
person	O
speaking	O
clearly	O
this	O
is	O
commonly	O
used	O
in	O
neuroscience	B
for	O
electroencephalography	O
a	O
technology	O
for	O
recording	O
electrical	O
signals	O
originating	O
in	O
the	O
brain	O
many	O
electrode	O
sensors	O
placed	O
on	O
the	O
subject	O
s	O
head	O
are	O
used	O
to	O
measure	O
many	O
electrical	O
signals	O
coming	O
from	O
the	O
body	O
the	O
experimenter	O
is	O
typically	O
only	O
interested	O
in	O
signals	O
from	O
the	O
brain	O
but	O
signals	O
from	O
the	O
subject	O
s	O
heart	O
and	O
eyes	O
are	O
strong	O
enough	O
to	O
confound	O
measurements	O
taken	O
at	O
the	O
subject	O
s	O
scalp	O
the	O
signals	O
arrive	O
at	O
the	O
electrodes	O
mixed	O
together	O
so	O
ica	O
is	O
necessary	O
to	O
separate	O
the	O
electrical	O
signature	O
of	O
the	O
heart	O
from	O
the	O
signals	O
originating	O
in	O
the	O
brain	O
and	O
to	O
separate	O
signals	O
in	O
different	O
brain	O
regions	O
from	O
each	O
other	O
as	O
mentioned	O
before	O
many	O
variants	O
of	O
ica	O
are	O
possible	O
some	O
add	O
some	O
noise	O
in	O
the	O
generation	O
of	O
x	O
rather	O
than	O
using	O
a	O
deterministic	O
decoder	B
most	O
do	O
not	O
use	O
the	O
maximum	B
likelihood	I
criterion	O
but	O
instead	O
aim	O
to	O
make	O
the	O
elements	O
of	O
independent	O
from	O
each	O
other	O
many	O
criteria	O
that	O
accomplish	O
this	O
goal	O
h	O
w	O
w	O
which	O
can	O
be	O
are	O
possible	O
equation	O
an	O
expensive	O
and	O
numerically	O
unstable	O
operation	B
some	O
variants	O
of	O
ica	O
avoid	O
this	O
problematic	O
operation	B
by	O
constraining	O
requires	O
taking	O
the	O
determinant	O
of	O
to	O
be	O
orthogonal	O
w	O
all	O
variants	O
of	O
ica	O
require	O
that	O
ph	O
be	O
non-gaussian	O
this	O
is	O
because	O
if	O
ph	O
is	O
an	O
independent	O
prior	O
with	O
gaussian	O
components	O
then	O
w	O
is	O
not	O
identifiable	O
we	O
can	O
obtain	O
the	O
same	O
distribution	O
over	O
px	O
for	O
many	O
values	O
of	O
w	O
this	O
is	O
very	O
different	O
from	O
other	O
linear	B
factor	I
models	I
like	O
probabilistic	O
pca	O
and	O
factor	B
analysis	I
that	O
often	O
require	O
ph	O
to	O
be	O
gaussian	O
in	O
order	O
to	O
make	O
many	O
operations	O
on	O
the	O
model	O
have	O
closed	O
form	O
solutions	O
in	O
the	O
maximum	B
likelihood	I
approach	O
where	O
the	O
user	O
explicitly	O
specifies	O
the	O
distribution	O
a	O
typical	O
choice	O
is	O
to	O
use	O
phi	O
d	O
dhi	O
typical	O
choices	O
of	O
these	O
non-gaussian	O
distributions	O
have	O
larger	O
peaks	O
near	O
than	O
does	O
the	O
gaussian	O
distribution	O
so	O
we	O
can	O
also	O
see	O
most	O
implementations	O
of	O
ica	O
as	O
learning	O
sparse	O
features	O
chapter	O
linear	B
factor	I
models	I
many	O
variants	O
of	O
ica	O
are	O
not	O
generative	O
models	O
in	O
the	O
sense	O
that	O
we	O
use	O
the	O
phrase	O
in	O
this	O
book	O
a	O
generative	O
model	O
either	O
represents	O
px	O
or	O
can	O
draw	O
samples	O
from	O
it	O
many	O
variants	O
of	O
ica	O
only	O
know	O
how	O
to	O
transform	O
between	O
x	O
and	O
h	O
but	O
do	O
not	O
have	O
any	O
way	O
of	O
representing	O
ph	O
and	O
thus	O
do	O
not	O
impose	O
a	O
distribution	O
over	O
px	O
for	O
example	B
many	O
ica	O
variants	O
aim	O
to	O
increase	O
the	O
sample	O
kurtosis	O
of	O
because	O
high	O
kurtosis	O
indicates	O
that	O
ph	O
is	O
non-gaussian	O
but	O
this	O
is	O
h	O
w	O
accomplished	O
without	O
explicitly	O
representing	O
ph	O
this	O
is	O
because	O
ica	O
is	O
more	O
often	O
used	O
as	O
an	O
analysis	O
tool	O
for	O
separating	O
signals	O
rather	O
than	O
for	O
generating	O
data	O
or	O
estimating	O
its	O
density	O
and	O
roberts	O
and	O
everson	O
just	O
as	O
pca	O
can	O
be	O
generalized	O
to	O
the	O
nonlinear	O
autoencoders	O
described	O
in	O
chapter	O
ica	O
can	O
be	O
generalized	O
to	O
a	O
nonlinear	O
generative	O
model	O
in	O
which	O
we	O
use	O
a	O
nonlinear	O
function	O
f	O
to	O
generate	O
the	O
observed	O
data	O
see	O
hyv	O
rinen	O
and	O
pajunen	O
for	O
the	O
initial	O
work	O
on	O
nonlinear	O
ica	O
and	O
its	O
successful	O
use	O
with	O
ensemble	O
learning	O
by	O
lappalainen	O
et	O
al	O
another	O
nonlinear	O
extension	O
of	O
ica	O
is	O
the	O
approach	O
of	O
nonlinear	O
independent	O
components	O
estimation	O
or	O
nice	O
which	O
stacks	O
a	O
series	O
of	O
invertible	O
transformations	O
stages	O
that	O
have	O
the	O
property	O
that	O
the	O
determinant	O
of	O
the	O
jacobian	O
of	O
each	O
transformation	O
can	O
be	O
computed	O
efficiently	O
this	O
makes	O
it	O
possible	O
to	O
compute	O
the	O
likelihood	O
exactly	O
and	O
like	O
ica	O
attempts	O
to	O
transform	O
the	O
data	O
into	O
a	O
space	O
where	O
it	O
has	O
a	O
factorized	O
marginal	O
distribution	O
but	O
is	O
more	O
likely	O
to	O
succeed	O
thanks	O
to	O
the	O
nonlinear	O
encoder	B
because	O
the	O
encoder	B
is	O
associated	O
with	O
a	O
decoder	B
that	O
is	O
its	O
perfect	O
inverse	O
it	O
is	O
straightforward	O
to	O
generate	O
samples	O
from	O
the	O
model	O
first	O
sampling	O
from	O
ph	O
and	O
then	O
applying	O
the	O
decoder	B
dinh	O
et	O
al	O
et	O
al	O
another	O
generalization	B
of	O
ica	O
is	O
to	O
learn	O
groups	O
of	O
features	O
with	O
statistical	O
dependence	O
allowed	O
within	O
a	O
group	O
but	O
discouraged	O
between	O
groups	O
rinen	O
and	O
hoyer	O
hyv	O
rinen	O
when	O
the	O
groups	O
of	O
related	O
units	O
are	O
chosen	O
to	O
be	O
non-overlapping	O
this	O
is	O
called	O
independent	B
subspace	I
analysis	I
it	O
is	O
also	O
possible	O
to	O
assign	O
spatial	O
coordinates	O
to	O
each	O
hidden	O
unit	O
and	O
form	O
overlapping	O
groups	O
of	O
spatially	O
neighboring	O
units	O
this	O
encourages	O
nearby	O
units	O
to	O
learn	O
similar	O
features	O
when	O
applied	O
to	O
natural	O
images	O
this	O
topographic	B
ica	I
approach	O
learns	O
gabor	O
filters	O
such	O
that	O
neighboring	O
features	O
have	O
similar	O
orientation	O
location	O
or	O
frequency	O
many	O
different	O
phase	O
offsets	O
of	O
similar	O
gabor	O
functions	O
occur	O
within	O
each	O
region	O
so	O
that	O
pooling	O
over	O
small	O
regions	O
yields	O
translation	O
invariance	B
slow	B
feature	B
analysis	I
slow	B
feature	B
analysis	I
is	O
a	O
linear	O
factor	O
model	O
that	O
uses	O
information	O
from	O
chapter	O
linear	B
factor	I
models	I
time	O
signals	O
to	O
learn	O
invariant	O
features	O
wiskott	O
and	O
sejnowski	O
slow	B
feature	B
analysis	I
is	O
motivated	O
by	O
a	O
general	O
principle	O
called	O
the	O
slowness	O
principle	O
the	O
idea	O
is	O
that	O
the	O
important	O
characteristics	O
of	O
scenes	O
change	O
very	O
slowly	O
compared	O
to	O
the	O
individual	O
measurements	O
that	O
make	O
up	O
a	O
description	O
of	O
a	O
scene	O
for	O
example	B
in	O
computer	B
vision	I
individual	O
pixel	O
values	O
can	O
change	O
very	O
rapidly	O
if	O
a	O
zebra	O
moves	O
from	O
left	O
to	O
right	O
across	O
the	O
image	O
an	O
individual	O
pixel	O
will	O
rapidly	O
change	O
from	O
black	O
to	O
white	O
and	O
back	O
again	O
as	O
the	O
zebra	O
s	O
stripes	O
pass	O
over	O
the	O
pixel	O
by	O
comparison	O
the	O
feature	B
indicating	O
whether	O
a	O
zebra	O
is	O
in	O
the	O
image	O
will	O
not	O
change	O
at	O
all	O
and	O
the	O
feature	B
describing	O
the	O
zebra	O
s	O
position	O
will	O
change	O
slowly	O
we	O
therefore	O
may	O
wish	O
to	O
regularize	O
our	O
model	O
to	O
learn	O
features	O
that	O
change	O
slowly	O
over	O
time	O
the	O
slowness	O
principle	O
predates	O
slow	B
feature	B
analysis	I
and	O
has	O
been	O
applied	O
hinton	O
f	O
ldi	O
k	O
mobahi	O
et	O
al	O
to	O
a	O
wide	O
variety	O
of	O
models	O
bergstra	O
and	O
bengio	O
in	O
general	O
we	O
can	O
apply	O
the	O
slowness	O
principle	O
to	O
any	O
differentiable	O
model	O
trained	O
with	O
gradient	B
descent	O
the	O
slowness	O
principle	O
may	O
be	O
introduced	O
by	O
adding	O
a	O
term	O
to	O
the	O
cost	O
function	O
of	O
the	O
form	O
l	O
f	O
t	O
f	O
x	O
t	O
where	O
is	O
a	O
hyperparameter	O
determining	O
the	O
strength	O
of	O
the	O
slowness	O
regularization	O
term	O
t	O
is	O
the	O
index	O
into	O
a	O
time	O
sequence	O
of	O
examples	O
f	O
is	O
the	O
feature	B
extractor	O
to	O
be	O
regularized	O
and	O
l	O
is	O
a	O
loss	O
function	O
measuring	O
the	O
distance	O
between	O
fx	O
and	O
f	O
is	O
the	O
mean	O
squared	O
difference	O
a	O
common	O
choice	O
for	O
l	O
t	O
slow	B
feature	B
analysis	I
is	O
a	O
particularly	O
efficient	O
application	O
of	O
the	O
slowness	O
principle	O
it	O
is	O
efficient	O
because	O
it	O
is	O
applied	O
to	O
a	O
linear	O
feature	B
extractor	O
and	O
can	O
thus	O
be	O
trained	O
in	O
closed	O
form	O
like	O
some	O
variants	O
of	O
ica	O
sfa	O
is	O
not	O
quite	O
a	O
generative	O
model	O
per	O
se	O
in	O
the	O
sense	O
that	O
it	O
defines	O
a	O
linear	O
map	O
between	O
input	O
space	O
and	O
feature	B
space	O
but	O
does	O
not	O
define	O
a	O
prior	O
over	O
feature	B
space	O
and	O
thus	O
does	O
not	O
impose	O
a	O
distribution	O
on	O
input	O
space	O
p	O
the	O
sfa	O
algorithm	O
and	O
sejnowski	O
consists	O
of	O
defining	O
f	O
to	O
be	O
a	O
linear	O
transformation	O
and	O
solving	O
the	O
optimization	O
problem	O
et	O
x	O
t	O
min	O
f	O
subject	O
to	O
the	O
constraints	O
and	O
etf	O
et	O
x	O
i	O
chapter	O
linear	B
factor	I
models	I
the	O
constraint	O
that	O
the	O
learned	O
feature	B
have	O
zero	O
mean	O
is	O
necessary	O
to	O
make	O
the	O
problem	O
have	O
a	O
unique	O
solution	O
otherwise	O
we	O
could	O
add	O
a	O
constant	O
to	O
all	O
feature	B
values	O
and	O
obtain	O
a	O
different	O
solution	O
with	O
equal	O
value	O
of	O
the	O
slowness	O
objective	O
the	O
constraint	O
that	O
the	O
features	O
have	O
unit	O
variance	O
is	O
necessary	O
to	O
prevent	O
the	O
pathological	O
solution	O
where	O
all	O
features	O
collapse	O
to	O
like	O
pca	O
the	O
sfa	O
features	O
are	O
ordered	O
with	O
the	O
first	O
feature	B
being	O
the	O
slowest	O
to	O
learn	O
multiple	O
features	O
we	O
must	O
also	O
add	O
the	O
constraint	O
i	O
j	O
et	O
x	O
if	O
this	O
specifies	O
that	O
the	O
learned	O
features	O
must	O
be	O
linearly	O
decorrelated	O
from	O
each	O
other	O
without	O
this	O
constraint	O
all	O
of	O
the	O
learned	O
features	O
would	O
simply	O
capture	O
the	O
one	O
slowest	O
signal	O
one	O
could	O
imagine	O
using	O
other	O
mechanisms	O
such	O
as	O
minimizing	O
reconstruction	O
error	O
to	O
force	O
the	O
features	O
to	O
diversify	O
but	O
this	O
decorrelation	O
mechanism	O
admits	O
a	O
simple	O
solution	O
due	O
to	O
the	O
linearity	O
of	O
sfa	O
features	O
the	O
sfa	O
problem	O
may	O
be	O
solved	O
in	O
closed	O
form	O
by	O
a	O
linear	O
algebra	O
package	O
sfa	O
is	O
typically	O
used	O
to	O
learn	O
nonlinear	O
features	O
by	O
applying	O
a	O
nonlinear	O
basis	O
expansion	O
to	O
x	O
before	O
running	O
sfa	O
for	O
example	B
it	O
is	O
common	O
to	O
replace	O
x	O
by	O
the	O
quadratic	O
basis	O
expansion	O
a	O
vector	O
containing	O
elements	O
x	O
ixj	O
for	O
all	O
i	O
and	O
j	O
linear	O
sfa	O
modules	O
may	O
then	O
be	O
composed	O
to	O
learn	O
deep	O
nonlinear	O
slow	O
feature	B
extractors	O
by	O
repeatedly	O
learning	O
a	O
linear	O
sfa	O
feature	B
extractor	O
applying	O
a	O
nonlinear	O
basis	O
expansion	O
to	O
its	O
output	O
and	O
then	O
learning	O
another	O
linear	O
sfa	O
feature	B
extractor	O
on	O
top	O
of	O
that	O
expansion	O
when	O
trained	O
on	O
small	O
spatial	O
patches	O
of	O
videos	O
of	O
natural	O
scenes	O
sfa	O
with	O
quadratic	O
basis	O
expansions	O
learns	O
features	O
that	O
share	O
many	O
characteristics	O
with	O
those	O
of	O
complex	O
cells	O
in	O
cortex	O
and	O
wiskott	O
when	O
trained	O
on	O
videos	O
of	O
random	O
motion	O
within	O
computer	O
rendered	O
environments	O
deep	O
sfa	O
learns	O
features	O
that	O
share	O
many	O
characteristics	O
with	O
the	O
features	O
represented	O
by	O
neurons	O
in	O
rat	O
brains	O
that	O
are	O
used	O
for	O
navigation	O
sfa	O
thus	O
seems	O
to	O
be	O
a	O
reasonably	O
biologically	O
plausible	O
model	O
et	O
al	O
a	O
major	O
advantage	O
of	O
sfa	O
is	O
that	O
it	O
is	O
possibly	O
to	O
theoretically	O
predict	O
which	O
features	O
sfa	O
will	O
learn	O
even	O
in	O
the	O
deep	O
nonlinear	O
setting	O
to	O
make	O
such	O
theoretical	O
predictions	O
one	O
must	O
know	O
about	O
the	O
dynamics	O
of	O
the	O
environment	O
in	O
terms	O
of	O
configuration	O
space	O
in	O
the	O
case	O
of	O
random	O
motion	O
in	O
the	O
rendered	O
environment	O
the	O
theoretical	O
analysis	O
proceeds	O
from	O
knowledge	O
of	O
the	O
probability	B
distribution	I
over	O
position	O
and	O
velocity	O
of	O
the	O
camera	O
given	O
the	O
knowledge	O
of	O
how	O
the	O
underlying	O
factors	O
actually	O
change	O
it	O
is	O
possible	O
to	O
analytically	O
solve	O
for	O
the	O
optimal	O
functions	O
expressing	O
these	O
factors	O
in	O
practice	O
experiments	O
with	O
deep	O
sfa	O
applied	O
to	O
simulated	O
data	O
seem	O
to	O
recover	O
the	O
theoretically	O
predicted	O
functions	O
chapter	O
linear	B
factor	I
models	I
this	O
is	O
in	O
comparison	O
to	O
other	O
learning	O
algorithms	O
where	O
the	O
cost	O
function	O
depends	O
highly	O
on	O
specific	O
pixel	O
values	O
making	O
it	O
much	O
more	O
difficult	O
to	O
determine	O
what	O
features	O
the	O
model	O
will	O
learn	O
et	O
al	O
deep	O
sfa	O
has	O
also	O
been	O
used	O
to	O
learn	O
features	O
for	O
object	B
recognition	I
and	O
pose	O
estimation	O
so	O
far	O
the	O
slowness	O
principle	O
has	O
not	O
become	O
the	O
basis	O
for	O
any	O
state	O
of	O
the	O
art	O
applications	O
it	O
is	O
unclear	O
what	O
factor	O
has	O
limited	O
its	O
performance	O
we	O
speculate	O
that	O
perhaps	O
the	O
slowness	O
prior	O
is	O
too	O
strong	O
and	O
that	O
rather	O
than	O
imposing	O
a	O
prior	O
that	O
features	O
should	O
be	O
approximately	O
constant	O
it	O
would	O
be	O
better	O
to	O
impose	O
a	O
prior	O
that	O
features	O
should	O
be	O
easy	O
to	O
predict	O
from	O
one	O
time	O
step	O
to	O
the	O
next	O
the	O
position	O
of	O
an	O
object	O
is	O
a	O
useful	O
feature	B
regardless	O
of	O
whether	O
the	O
object	O
s	O
velocity	O
is	O
high	O
or	O
low	O
but	O
the	O
slowness	O
principle	O
encourages	O
the	O
model	O
to	O
ignore	O
the	O
position	O
of	O
objects	O
that	O
have	O
high	O
velocity	O
sparse	O
coding	O
olshausen	O
and	O
field	O
sparse	O
coding	O
is	O
a	O
linear	O
factor	O
model	O
that	O
has	O
been	O
heavily	O
studied	O
as	O
an	O
unsupervised	O
feature	B
learning	O
and	O
feature	B
extraction	O
mechanism	O
strictly	O
speaking	O
the	O
term	O
sparse	O
coding	O
refers	O
to	O
the	O
process	O
of	O
inferring	O
the	O
value	O
of	O
h	O
in	O
this	O
model	O
while	O
sparse	O
modeling	O
refers	O
to	O
the	O
process	O
of	O
designing	O
and	O
learning	O
the	O
model	O
but	O
the	O
term	O
sparse	O
coding	O
is	O
often	O
used	O
to	O
refer	O
to	O
both	O
like	O
most	O
other	O
linear	B
factor	I
models	I
it	O
uses	O
a	O
linear	O
decoder	B
plus	O
noise	O
to	O
obtain	O
reconstructions	O
of	O
x	O
as	O
specified	O
in	O
equation	O
more	O
specifically	O
sparse	O
coding	O
models	O
typically	O
assume	O
that	O
the	O
linear	O
factors	O
have	O
gaussian	O
noise	O
with	O
isotropic	B
precision	B
n	O
p	O
x	O
h	O
x	O
w	O
h	O
b	O
i	O
the	O
distribution	O
ph	O
is	O
chosen	O
to	O
be	O
one	O
with	O
sharp	O
peaks	O
near	O
and	O
field	O
common	O
choices	O
include	O
factorized	O
laplace	O
cauchy	O
or	O
factorized	O
student-t	O
distributions	O
for	O
example	B
the	O
laplace	O
prior	O
parametrized	O
in	O
terms	O
of	O
the	O
sparsity	O
penalty	O
coefficient	O
is	O
given	O
by	O
p	O
h	O
i	O
laplacehi	O
and	O
the	O
student-	O
prior	O
by	O
t	O
p	O
h	O
i	O
i	O
e	O
h	O
i	O
chapter	O
linear	B
factor	I
models	I
training	O
sparse	O
coding	O
with	O
maximum	B
likelihood	I
is	O
intractable	O
instead	O
the	O
training	O
alternates	O
between	O
encoding	O
the	O
data	O
and	O
training	O
the	O
decoder	B
to	O
better	O
reconstruct	O
the	O
data	O
given	O
the	O
encoding	O
this	O
approach	O
will	O
be	O
justified	O
further	O
as	O
a	O
principled	O
approximation	O
to	O
maximum	B
likelihood	I
later	O
in	O
section	O
for	O
models	O
such	O
as	O
pca	O
we	O
have	O
seen	O
the	O
use	O
of	O
a	O
parametric	O
encoder	B
function	O
that	O
predicts	O
h	O
and	O
consists	O
only	O
of	O
multiplication	O
by	O
a	O
weight	O
matrix	O
the	O
encoder	B
that	O
we	O
use	O
with	O
sparse	O
coding	O
is	O
not	O
a	O
parametric	O
encoder	B
instead	O
the	O
encoder	B
is	O
an	O
optimization	O
algorithm	O
that	O
solves	O
an	O
optimization	O
problem	O
in	O
which	O
we	O
seek	O
the	O
single	O
most	O
likely	O
code	O
value	O
when	O
combined	O
with	O
equation	O
optimization	O
problem	O
and	O
equation	O
this	O
yields	O
the	O
following	O
h	O
arg	O
max	O
f	O
x	O
h	O
h	O
x	O
p	O
arg	O
max	O
h	O
p	O
h	O
x	O
arg	O
max	O
h	O
arg	O
min	O
h	O
log	O
p	O
h	O
x	O
x	O
w	O
h	O
h	O
where	O
we	O
have	O
dropped	O
terms	O
not	O
depending	O
on	O
h	O
and	O
divided	O
by	O
positive	O
scaling	O
factors	O
to	O
simplify	O
the	O
equation	O
h	O
due	O
to	O
the	O
imposition	O
of	O
an	O
norm	O
on	O
h	O
this	O
procedure	O
will	O
yield	O
a	O
sparse	O
section	O
to	O
train	O
the	O
model	O
rather	O
than	O
just	O
perform	O
inference	O
we	O
alternate	O
between	O
minimization	O
with	O
respect	O
to	O
h	O
and	O
minimization	O
with	O
respect	O
to	O
w	O
in	O
this	O
presentation	O
we	O
treat	O
as	O
a	O
hyperparameter	O
typically	O
it	O
is	O
set	O
to	O
because	O
its	O
role	O
in	O
this	O
optimization	O
problem	O
is	O
shared	O
with	O
and	O
there	O
is	O
no	O
need	O
for	O
both	O
hyperparameters	O
in	O
principle	O
we	O
could	O
also	O
treat	O
as	O
a	O
parameter	O
of	O
the	O
model	O
and	O
learn	O
it	O
our	O
presentation	O
here	O
has	O
discarded	O
some	O
terms	O
that	O
do	O
not	O
depend	O
on	O
h	O
but	O
do	O
depend	O
on	O
to	O
learn	O
these	O
terms	O
must	O
be	O
included	O
or	O
will	O
collapse	O
to	O
not	O
all	O
approaches	O
to	O
sparse	O
coding	O
explicitly	O
build	O
a	O
ph	O
and	O
a	O
px	O
h	O
often	O
we	O
are	O
just	O
interested	O
in	O
learning	O
a	O
dictionary	O
of	O
features	O
with	O
activation	O
values	O
that	O
will	O
often	O
be	O
zero	O
when	O
extracted	O
using	O
this	O
inference	O
procedure	O
if	O
we	O
sample	O
h	O
from	O
a	O
laplace	O
prior	O
it	O
is	O
in	O
fact	O
a	O
zero	O
probability	O
event	O
for	O
an	O
element	O
of	O
h	O
to	O
actually	O
be	O
zero	O
the	O
generative	O
model	O
itself	O
is	O
not	O
especially	O
describe	O
approximate	O
sparse	O
only	O
the	O
feature	B
extractor	O
is	O
goodfellow	O
et	O
al	O
chapter	O
linear	B
factor	I
models	I
inference	O
in	O
a	O
different	O
model	O
family	O
the	O
spike	O
and	O
slab	O
sparse	O
coding	O
model	O
for	O
which	O
samples	O
from	O
the	O
prior	O
usually	O
contain	O
true	O
zeros	O
the	O
sparse	O
coding	O
approach	O
combined	O
with	O
the	O
use	O
of	O
the	O
non-parametric	O
encoder	B
can	O
in	O
principle	O
minimize	O
the	O
combination	O
of	O
reconstruction	O
error	O
and	O
log-prior	O
better	O
than	O
any	O
specific	O
parametric	O
encoder	B
another	O
advantage	O
is	O
that	O
there	O
is	O
no	O
generalization	B
error	O
to	O
the	O
encoder	B
a	O
parametric	O
encoder	B
must	O
learn	O
how	O
to	O
map	O
x	O
to	O
h	O
in	O
a	O
way	O
that	O
generalizes	O
for	O
unusual	O
x	O
that	O
do	O
not	O
resemble	O
the	O
training	O
data	O
a	O
learned	O
parametric	O
encoder	B
may	O
fail	O
to	O
find	O
an	O
h	O
that	O
results	O
in	O
accurate	O
reconstruction	O
or	O
a	O
sparse	O
code	O
for	O
the	O
vast	O
majority	O
of	O
formulations	O
of	O
sparse	O
coding	O
models	O
where	O
the	O
inference	O
problem	O
is	O
convex	O
the	O
optimization	O
procedure	O
will	O
always	O
find	O
the	O
optimal	O
code	O
degenerate	O
cases	O
such	O
as	O
replicated	O
weight	O
vectors	O
occur	O
obviously	O
the	O
sparsity	O
and	O
reconstruction	O
costs	O
can	O
still	O
rise	O
on	O
unfamiliar	O
points	O
but	O
this	O
is	O
due	O
to	O
generalization	B
error	O
in	O
the	O
decoder	B
weights	B
rather	O
than	O
generalization	B
error	O
in	O
the	O
encoder	B
the	O
lack	O
of	O
generalization	B
error	O
in	O
sparse	O
coding	O
s	O
optimization-based	O
encoding	O
process	O
may	O
result	O
in	O
better	O
generalization	B
when	O
sparse	O
coding	O
is	O
used	O
as	O
a	O
feature	B
extractor	O
for	O
a	O
classifier	O
than	O
when	O
a	O
parametric	O
function	O
is	O
used	O
to	O
predict	O
the	O
code	O
coates	O
and	O
ng	O
demonstrated	O
that	O
sparse	O
coding	O
features	O
generalize	O
better	O
for	O
object	B
recognition	I
tasks	O
than	O
the	O
features	O
of	O
a	O
related	O
model	O
based	O
on	O
a	O
parametric	O
encoder	B
the	O
linear-sigmoid	O
autoencoder	O
inspired	O
by	O
their	O
work	O
goodfellow	O
et	O
al	O
showed	O
that	O
a	O
variant	O
of	O
sparse	O
coding	O
generalizes	O
better	O
than	O
other	O
feature	B
extractors	O
in	O
the	O
regime	O
where	O
extremely	O
few	O
labels	O
are	O
available	O
or	O
fewer	O
labels	O
per	O
class	O
the	O
primary	O
disadvantage	O
of	O
the	O
non-parametric	O
encoder	B
is	O
that	O
it	O
requires	O
greater	O
time	O
to	O
compute	O
h	O
given	O
x	O
because	O
the	O
non-parametric	O
approach	O
requires	O
running	O
an	O
iterative	O
algorithm	O
the	O
parametric	O
autoencoder	O
approach	O
developed	O
in	O
chapter	O
uses	O
only	O
a	O
fixed	O
number	O
of	O
layers	O
often	O
only	O
one	O
another	O
disadvantage	O
is	O
that	O
it	O
is	O
not	O
straight-forward	O
to	O
back-propagate	O
through	O
the	O
non-parametric	O
encoder	B
which	O
makes	O
it	O
difficult	O
to	O
pretrain	O
a	O
sparse	O
coding	O
model	O
with	O
an	O
unsupervised	O
criterion	O
and	O
then	O
fine-tune	O
it	O
using	O
a	O
supervised	O
criterion	O
modified	O
versions	O
of	O
sparse	O
coding	O
that	O
permit	O
approximate	O
derivatives	O
do	O
exist	O
but	O
are	O
not	O
widely	O
used	O
bagnell	O
and	O
bradley	O
sparse	O
coding	O
like	O
other	O
linear	B
factor	I
models	I
often	O
produces	O
poor	O
samples	O
as	O
shown	O
in	O
figure	O
this	O
happens	O
even	O
when	O
the	O
model	O
is	O
able	O
to	O
reconstruct	O
the	O
data	O
well	O
and	O
provide	O
useful	O
features	O
for	O
a	O
classifier	O
the	O
reason	O
is	O
that	O
each	O
individual	O
feature	B
may	O
be	O
learned	O
well	O
but	O
the	O
factorial	O
prior	O
on	O
the	O
hidden	O
code	O
results	O
in	O
the	O
model	O
including	O
random	O
subsets	O
of	O
all	O
of	O
the	O
features	O
in	O
each	O
generated	O
sample	O
this	O
motivates	O
the	O
development	O
of	O
deeper	O
models	O
that	O
can	O
impose	O
a	O
non	O
chapter	O
linear	B
factor	I
models	I
figure	O
example	B
samples	O
and	O
weights	B
from	O
a	O
spike	O
and	O
slab	O
sparse	O
coding	O
model	O
trained	O
on	O
the	O
mnist	O
dataset	B
samples	O
from	O
the	O
model	O
do	O
not	O
resemble	O
the	O
training	O
examples	O
at	O
first	O
glance	O
one	O
might	O
assume	O
the	O
model	O
is	O
poorly	O
fit	O
the	O
weight	O
vectors	O
of	O
the	O
model	O
have	O
learned	O
to	O
represent	O
penstrokes	O
and	O
sometimes	O
complete	O
digits	O
the	O
model	O
has	O
thus	O
learned	O
useful	O
features	O
the	O
problem	O
is	O
that	O
the	O
factorial	O
prior	O
over	O
features	O
results	O
in	O
random	O
subsets	O
of	O
features	O
being	O
combined	O
few	O
such	O
subsets	O
are	O
appropriate	O
to	O
form	O
a	O
recognizable	O
mnist	O
digit	O
this	O
motivates	O
the	O
development	O
of	O
generative	O
models	O
that	O
have	O
more	O
powerful	O
distributions	O
over	O
their	O
latent	O
codes	O
figure	O
reproduced	O
with	O
permission	O
from	O
goodfellow	O
et	O
al	O
factorial	O
distribution	O
on	O
the	O
deepest	O
code	O
layer	O
as	O
well	O
as	O
the	O
development	O
of	O
more	O
sophisticated	O
shallow	O
models	O
manifold	B
interpretation	O
of	O
pca	O
hinton	O
et	O
al	O
linear	B
factor	I
models	I
including	O
pca	O
and	O
factor	B
analysis	I
can	O
be	O
interpreted	O
as	O
learning	O
a	O
manifold	B
we	O
can	O
view	O
probabilistic	O
pca	O
as	O
defining	O
a	O
thin	O
pancake-shaped	O
region	O
of	O
high	O
probability	O
a	O
gaussian	O
distribution	O
that	O
is	O
very	O
narrow	O
along	O
some	O
axes	O
just	O
as	O
a	O
pancake	O
is	O
very	O
flat	O
along	O
its	O
vertical	O
axis	O
but	O
is	O
elongated	O
along	O
other	O
axes	O
just	O
as	O
a	O
pancake	O
is	O
wide	O
along	O
its	O
horizontal	O
axes	O
this	O
is	O
illustrated	O
in	O
figure	O
pca	O
can	O
be	O
interpreted	O
as	O
aligning	O
this	O
pancake	O
with	O
a	O
linear	O
manifold	B
in	O
a	O
higher-dimensional	O
space	O
this	O
interpretation	O
applies	O
not	O
just	O
to	O
traditional	O
pca	O
but	O
also	O
to	O
any	O
linear	O
autoencoder	O
that	O
learns	O
matrices	O
w	O
and	O
v	O
with	O
the	O
goal	O
of	O
making	O
the	O
reconstruction	O
of	O
x	O
lie	O
as	O
close	O
to	O
x	O
as	O
possible	O
let	O
the	O
encoder	B
be	O
h	O
x	O
w	O
x	O
chapter	O
linear	B
factor	I
models	I
the	O
encoder	B
computes	O
a	O
low-dimensional	O
representation	O
of	O
h	O
with	O
the	O
autoencoder	O
view	O
we	O
have	O
a	O
decoder	B
computing	O
the	O
reconstruction	O
x	O
h	O
b	O
v	O
h	O
figure	O
flat	O
gaussian	O
capturing	O
probability	O
concentration	O
near	O
a	O
low-dimensional	O
manifold	B
the	O
figure	O
shows	O
the	O
upper	O
half	O
of	O
the	O
pancake	O
above	O
the	O
manifold	B
plane	O
which	O
goes	O
through	O
its	O
middle	O
the	O
variance	O
in	O
the	O
direction	O
orthogonal	O
to	O
the	O
manifold	B
is	O
very	O
small	O
pointing	O
out	O
of	O
plane	O
and	O
can	O
be	O
considered	O
like	O
noise	O
while	O
the	O
other	O
variances	O
are	O
large	O
in	O
the	O
plane	O
and	O
correspond	O
to	O
signal	O
and	O
a	O
coordinate	O
system	O
for	O
the	O
reduced-dimension	O
data	O
the	O
choices	O
of	O
linear	O
encoder	B
and	O
decoder	B
that	O
minimize	O
reconstruction	O
error	O
x	O
x	O
e	O
correspond	O
to	O
v	O
w	O
b	O
ex	O
and	O
the	O
columns	O
of	O
w	O
form	O
an	O
orthonormal	O
basis	O
which	O
spans	O
the	O
same	O
subspace	O
as	O
the	O
principal	O
eigenvectors	O
of	O
the	O
covariance	B
matrix	I
x	O
x	O
c	O
in	O
the	O
case	O
of	O
pca	O
the	O
columns	O
of	O
w	O
are	O
these	O
eigenvectors	O
ordered	O
by	O
the	O
magnitude	O
of	O
the	O
corresponding	O
eigenvalues	O
are	O
all	O
real	O
and	O
non-negative	O
one	O
can	O
also	O
show	O
that	O
eigenvalue	B
i	O
of	O
c	O
corresponds	O
to	O
the	O
variance	O
of	O
x	O
d	O
with	O
d	O
d	O
then	O
the	O
in	O
the	O
direction	O
of	O
eigenvector	B
v	O
if	O
x	O
d	O
and	O
h	O
r	O
r	O
chapter	O
linear	B
factor	I
models	I
optimal	O
reconstruction	O
error	O
x	O
min	O
b	O
v	O
x	O
and	O
d	O
w	O
as	O
above	O
is	O
i	O
i	O
d	O
hence	O
if	O
the	O
covariance	O
has	O
rank	O
d	O
the	O
eigenvalues	O
to	O
d	O
are	O
and	O
reconstruction	O
error	O
is	O
furthermore	O
one	O
can	O
also	O
show	O
that	O
the	O
above	O
solution	O
can	O
be	O
obtained	O
by	O
maximizing	O
the	O
variances	O
of	O
the	O
elements	O
of	O
h	O
under	O
orthogonal	O
w	O
instead	O
of	O
minimizing	O
reconstruction	O
error	O
linear	B
factor	I
models	I
are	O
some	O
of	O
the	O
simplest	O
generative	O
models	O
and	O
some	O
of	O
the	O
simplest	O
models	O
that	O
learn	O
a	O
representation	O
of	O
data	O
much	O
as	O
linear	O
classifiers	O
and	O
linear	O
regression	B
models	O
may	O
be	O
extended	O
to	O
deep	O
feedforward	O
networks	O
these	O
linear	B
factor	I
models	I
may	O
be	O
extended	O
to	O
autoencoder	O
networks	O
and	O
deep	O
probabilistic	O
models	O
that	O
perform	O
the	O
same	O
tasks	O
but	O
with	O
a	O
much	O
more	O
powerful	O
and	O
flexible	O
model	O
family	O
chapter	O
autoencoders	O
an	O
autoencoder	O
is	O
a	O
neural	B
network	I
that	O
is	O
trained	O
to	O
attempt	O
to	O
copy	O
its	O
input	O
to	O
its	O
output	O
internally	O
it	O
has	O
a	O
hidden	B
layer	I
h	O
that	O
describes	O
a	O
code	O
used	O
to	O
represent	O
the	O
input	O
the	O
network	O
may	O
be	O
viewed	O
as	O
consisting	O
of	O
two	O
parts	O
an	O
encoder	B
function	O
h	O
f	O
and	O
a	O
decoder	B
that	O
produces	O
a	O
reconstruction	O
r	O
gh	O
this	O
architecture	O
is	O
presented	O
in	O
figure	O
if	O
an	O
autoencoder	O
succeeds	O
in	O
simply	O
learning	O
to	O
set	O
gf	O
x	O
everywhere	O
then	O
it	O
is	O
not	O
especially	O
useful	O
instead	O
autoencoders	O
are	O
designed	O
to	O
be	O
unable	O
to	O
learn	O
to	O
copy	O
perfectly	O
usually	O
they	O
are	O
restricted	O
in	O
ways	O
that	O
allow	O
them	O
to	O
copy	O
only	O
approximately	O
and	O
to	O
copy	O
only	O
input	O
that	O
resembles	O
the	O
training	O
data	O
because	O
the	O
model	O
is	O
forced	O
to	O
prioritize	O
which	O
aspects	O
of	O
the	O
input	O
should	O
be	O
copied	O
it	O
often	O
learns	O
useful	O
properties	O
of	O
the	O
data	O
modern	O
autoencoders	O
have	O
generalized	O
the	O
idea	O
of	O
an	O
encoder	B
and	O
a	O
de	O
and	O
coder	O
beyond	O
deterministic	O
functions	O
to	O
stochastic	O
mappings	O
pencoderh	O
x	O
pdecoder	O
x	O
h	O
the	O
idea	O
of	O
autoencoders	O
has	O
been	O
part	O
of	O
the	O
historical	O
landscape	O
of	O
neural	O
networks	O
for	O
decades	O
lecun	O
bourlard	O
and	O
kamp	O
hinton	O
and	O
zemel	O
traditionally	O
autoencoders	O
were	O
used	O
for	O
dimensionality	O
reduction	O
or	O
feature	B
learning	O
recently	O
theoretical	O
connections	O
between	O
autoencoders	O
and	O
latent	B
variable	I
models	O
have	O
brought	O
autoencoders	O
to	O
the	O
forefront	O
of	O
generative	O
modeling	O
as	O
we	O
will	O
see	O
in	O
chapter	O
autoencoders	O
may	O
be	O
thought	O
of	O
as	O
being	O
a	O
special	O
case	O
of	O
feedforward	O
networks	O
and	O
may	O
be	O
trained	O
with	O
all	O
of	O
the	O
same	O
techniques	O
typically	O
minibatch	B
gradient	B
descent	O
following	O
gradients	O
computed	O
by	O
back-propagation	B
unlike	O
general	O
feedforward	O
networks	O
autoencoders	O
may	O
also	O
be	O
trained	O
using	O
recirculation	O
and	O
mcclelland	O
a	O
learning	O
algorithm	O
based	O
on	O
comparing	O
the	O
activations	O
of	O
the	O
network	O
on	O
the	O
original	O
input	O
chapter	O
autoencoders	O
to	O
the	O
activations	O
on	O
the	O
reconstructed	O
input	O
recirculation	O
is	O
regarded	O
as	O
more	O
biologically	O
plausible	O
than	O
back-propagation	B
but	O
is	O
rarely	O
used	O
for	O
machine	B
learning	I
applications	O
hh	O
g	O
rr	O
f	O
xx	O
figure	O
the	O
general	O
structure	O
of	O
an	O
autoencoder	O
mapping	O
an	O
input	O
to	O
an	O
output	O
reconstruction	O
r	O
through	O
an	O
internal	O
representation	O
or	O
code	O
h	O
the	O
autoencoder	O
has	O
two	O
components	O
the	O
encoder	B
f	O
x	O
to	O
h	O
and	O
the	O
decoder	B
g	O
h	O
to	O
r	O
x	O
undercomplete	O
autoencoders	O
copying	O
the	O
input	O
to	O
the	O
output	O
may	O
sound	O
useless	O
but	O
we	O
are	O
typically	O
not	O
interested	O
in	O
the	O
output	O
of	O
the	O
decoder	B
instead	O
we	O
hope	O
that	O
training	O
the	O
autoencoder	O
to	O
perform	O
the	O
input	O
copying	O
task	O
will	O
result	O
in	O
h	O
taking	O
on	O
useful	O
properties	O
one	O
way	O
to	O
obtain	O
useful	O
features	O
from	O
the	O
autoencoder	O
is	O
to	O
constrain	O
h	O
to	O
have	O
smaller	O
dimension	O
than	O
x	O
an	O
autoencoder	O
whose	O
code	O
dimension	O
is	O
less	O
than	O
the	O
input	O
dimension	O
is	O
called	O
undercomplete	O
learning	O
an	O
undercomplete	O
representation	O
forces	O
the	O
autoencoder	O
to	O
capture	O
the	O
most	O
salient	O
features	O
of	O
the	O
training	O
data	O
the	O
learning	O
process	O
is	O
described	O
simply	O
as	O
minimizing	O
a	O
loss	O
function	O
l	O
g	O
f	O
where	O
l	O
is	O
a	O
loss	O
function	O
penalizing	O
gf	O
for	O
being	O
dissimilar	O
from	O
x	O
such	O
as	O
the	O
mean	B
squared	I
error	I
when	O
the	O
decoder	B
is	O
linear	O
and	O
l	O
is	O
the	O
mean	B
squared	I
error	I
an	O
undercomplete	O
autoencoder	O
learns	O
to	O
span	O
the	O
same	O
subspace	O
as	O
pca	O
in	O
this	O
case	O
an	O
autoencoder	O
trained	O
to	O
perform	O
the	O
copying	O
task	O
has	O
learned	O
the	O
principal	O
subspace	O
of	O
the	O
training	O
data	O
as	O
a	O
side-effect	O
autoencoders	O
with	O
nonlinear	O
encoder	B
functions	O
f	O
and	O
nonlinear	O
decoder	B
functions	O
g	O
can	O
thus	O
learn	O
a	O
more	O
powerful	O
nonlinear	O
generalization	B
of	O
pca	O
unfortu	O
chapter	O
autoencoders	O
nately	O
if	O
the	O
encoder	B
and	O
decoder	B
are	O
allowed	O
too	O
much	O
capacity	O
the	O
autoencoder	O
can	O
learn	O
to	O
perform	O
the	O
copying	O
task	O
without	O
extracting	O
useful	O
information	O
about	O
the	O
distribution	O
of	O
the	O
data	O
theoretically	O
one	O
could	O
imagine	O
that	O
an	O
autoencoder	O
with	O
a	O
one-dimensional	O
code	O
but	O
a	O
very	O
powerful	O
nonlinear	O
encoder	B
could	O
learn	O
to	O
represent	O
each	O
training	O
example	B
x	O
with	O
the	O
code	O
i	O
the	O
decoder	B
could	O
learn	O
to	O
map	O
these	O
integer	O
indices	O
back	O
to	O
the	O
values	O
of	O
specific	O
training	O
examples	O
this	O
specific	O
scenario	O
does	O
not	O
occur	O
in	O
practice	O
but	O
it	O
illustrates	O
clearly	O
that	O
an	O
autoencoder	O
trained	O
to	O
perform	O
the	O
copying	O
task	O
can	O
fail	O
to	O
learn	O
anything	O
useful	O
about	O
the	O
dataset	B
if	O
the	O
capacity	O
of	O
the	O
autoencoder	O
is	O
allowed	O
to	O
become	O
too	O
great	O
regularized	O
autoencoders	O
undercomplete	O
autoencoders	O
with	O
code	O
dimension	O
less	O
than	O
the	O
input	O
dimension	O
can	O
learn	O
the	O
most	O
salient	O
features	O
of	O
the	O
data	O
distribution	O
we	O
have	O
seen	O
that	O
these	O
autoencoders	O
fail	O
to	O
learn	O
anything	O
useful	O
if	O
the	O
encoder	B
and	O
decoder	B
are	O
given	O
too	O
much	O
capacity	O
a	O
similar	O
problem	O
occurs	O
if	O
the	O
hidden	O
code	O
is	O
allowed	O
to	O
have	O
dimension	O
equal	O
to	O
the	O
input	O
and	O
in	O
the	O
overcomplete	O
case	O
in	O
which	O
the	O
hidden	O
code	O
has	O
dimension	O
greater	O
than	O
the	O
input	O
in	O
these	O
cases	O
even	O
a	O
linear	O
encoder	B
and	O
linear	O
decoder	B
can	O
learn	O
to	O
copy	O
the	O
input	O
to	O
the	O
output	O
without	O
learning	O
anything	O
useful	O
about	O
the	O
data	O
distribution	O
ideally	O
one	O
could	O
train	O
any	O
architecture	O
of	O
autoencoder	O
successfully	O
choosing	O
the	O
code	O
dimension	O
and	O
the	O
capacity	O
of	O
the	O
encoder	B
and	O
decoder	B
based	O
on	O
the	O
complexity	O
of	O
distribution	O
to	O
be	O
modeled	O
regularized	O
autoencoders	O
provide	O
the	O
ability	O
to	O
do	O
so	O
rather	O
than	O
limiting	O
the	O
model	O
capacity	O
by	O
keeping	O
the	O
encoder	B
and	O
decoder	B
shallow	O
and	O
the	O
code	O
size	O
small	O
regularized	O
autoencoders	O
use	O
a	O
loss	O
function	O
that	O
encourages	O
the	O
model	O
to	O
have	O
other	O
properties	O
besides	O
the	O
ability	O
to	O
copy	O
its	O
input	O
to	O
its	O
output	O
these	O
other	O
properties	O
include	O
sparsity	O
of	O
the	O
representation	O
smallness	O
of	O
the	O
derivative	B
of	O
the	O
representation	O
and	O
robustness	O
to	O
noise	O
or	O
to	O
missing	B
inputs	I
a	O
regularized	O
autoencoder	O
can	O
be	O
nonlinear	O
and	O
overcomplete	O
but	O
still	O
learn	O
something	O
useful	O
about	O
the	O
data	O
distribution	O
even	O
if	O
the	O
model	O
capacity	O
is	O
great	O
enough	O
to	O
learn	O
a	O
trivial	O
identity	O
function	O
in	O
addition	O
to	O
the	O
methods	O
described	O
here	O
which	O
are	O
most	O
naturally	O
interpreted	O
as	O
regularized	O
autoencoders	O
nearly	O
any	O
generative	O
model	O
with	O
latent	O
variables	O
and	O
equipped	O
with	O
an	O
inference	O
procedure	O
computing	O
latent	O
representations	O
given	O
input	O
may	O
be	O
viewed	O
as	O
a	O
particular	O
form	O
of	O
autoencoder	O
two	O
generative	O
modeling	O
approaches	O
that	O
emphasize	O
this	O
connection	O
with	O
autoencoders	O
are	O
the	O
such	O
as	O
the	O
variational	O
descendants	O
of	O
the	O
helmholtz	O
machine	O
hinton	O
et	O
al	O
chapter	O
autoencoders	O
and	O
the	O
generative	O
stochastic	O
networks	O
autoencoder	O
these	O
models	O
naturally	O
learn	O
high-capacity	O
overcomplete	O
encodings	O
of	O
the	O
input	O
and	O
do	O
not	O
require	O
regularization	O
for	O
these	O
encodings	O
to	O
be	O
useful	O
their	O
encodings	O
are	O
naturally	O
useful	O
because	O
the	O
models	O
were	O
trained	O
to	O
approximately	O
maximize	O
the	O
probability	O
of	O
the	O
training	O
data	O
rather	O
than	O
to	O
copy	O
the	O
input	O
to	O
the	O
output	O
sparse	O
autoencoders	O
a	O
sparse	O
autoencoder	O
is	O
simply	O
an	O
autoencoder	O
whose	O
training	O
criterion	O
involves	O
a	O
sparsity	O
penalty	O
on	O
the	O
code	O
layer	O
h	O
in	O
addition	O
to	O
the	O
reconstruction	O
error	O
l	O
g	O
f	O
h	O
x	O
where	O
gh	O
is	O
the	O
decoder	B
output	O
and	O
typically	O
we	O
have	O
h	O
f	O
the	O
encoder	B
output	O
sparse	O
autoencoders	O
are	O
typically	O
used	O
to	O
learn	O
features	O
for	O
another	O
task	O
such	O
as	O
classification	B
an	O
autoencoder	O
that	O
has	O
been	O
regularized	O
to	O
be	O
sparse	O
must	O
respond	O
to	O
unique	O
statistical	O
features	O
of	O
the	O
dataset	B
it	O
has	O
been	O
trained	O
on	O
rather	O
than	O
simply	O
acting	O
as	O
an	O
identity	O
function	O
in	O
this	O
way	O
training	O
to	O
perform	O
the	O
copying	O
task	O
with	O
a	O
sparsity	O
penalty	O
can	O
yield	O
a	O
model	O
that	O
has	O
learned	O
useful	O
features	O
as	O
a	O
byproduct	O
we	O
can	O
think	O
of	O
the	O
penalty	O
simply	O
as	O
a	O
regularizer	B
term	O
added	O
to	O
a	O
feedforward	O
network	O
whose	O
primary	O
task	O
is	O
to	O
copy	O
the	O
input	O
to	O
the	O
output	O
learning	O
objective	O
and	O
possibly	O
also	O
perform	O
some	O
supervised	O
task	O
a	O
supervised	B
learning	I
objective	O
that	O
depends	O
on	O
these	O
sparse	O
features	O
unlike	O
other	O
regularizers	O
such	O
as	O
weight	O
decay	O
there	O
is	O
not	O
a	O
straightforward	O
bayesian	O
interpretation	O
to	O
this	O
regularizer	B
as	O
described	O
in	O
section	O
training	O
with	O
weight	O
decay	O
and	O
other	O
regularization	O
penalties	O
can	O
be	O
interpreted	O
as	O
a	O
map	O
approximation	O
to	O
bayesian	O
inference	O
with	O
the	O
added	O
regularizing	O
penalty	O
corresponding	O
to	O
a	O
prior	B
probability	B
distribution	I
over	O
the	O
model	O
parameters	O
in	O
this	O
view	O
regularized	O
maximum	B
likelihood	I
corresponds	O
to	O
maximizing	O
p	O
x	O
which	O
is	O
equivalent	O
to	O
maximizing	O
log	O
px	O
term	O
is	O
the	O
usual	O
data	O
log-likelihood	O
term	O
and	O
the	O
log	O
p	O
term	O
the	O
log-prior	O
over	O
parameters	O
incorporates	O
the	O
preference	O
over	O
particular	O
values	O
of	O
this	O
view	O
was	O
described	O
in	O
section	O
regularized	O
autoencoders	O
defy	O
such	O
an	O
interpretation	O
because	O
the	O
regularizer	B
depends	O
on	O
the	O
data	O
and	O
is	O
therefore	O
by	O
definition	O
not	O
a	O
prior	O
in	O
the	O
formal	O
sense	O
of	O
the	O
word	O
we	O
can	O
still	O
think	O
of	O
these	O
regularization	O
terms	O
as	O
implicitly	O
expressing	O
a	O
preference	O
over	O
functions	O
log	O
p	O
the	O
log	O
px	O
rather	O
than	O
thinking	O
of	O
the	O
sparsity	O
penalty	O
as	O
a	O
regularizer	B
for	O
the	O
copying	O
task	O
we	O
can	O
think	O
of	O
the	O
entire	O
sparse	O
autoencoder	O
framework	O
as	O
approximating	O
chapter	O
autoencoders	O
maximum	B
likelihood	I
training	O
of	O
a	O
generative	O
model	O
that	O
has	O
latent	O
variables	O
suppose	O
we	O
have	O
a	O
model	O
with	O
visible	O
variables	O
x	O
and	O
latent	O
variables	O
h	O
with	O
an	O
explicit	O
joint	O
distribution	O
pmodelx	O
h	O
we	O
refer	O
to	O
pmodelh	O
as	O
the	O
model	O
s	O
prior	O
distribution	O
over	O
the	O
latent	O
variables	O
representing	O
the	O
model	O
s	O
beliefs	O
prior	O
to	O
seeing	O
x	O
this	O
is	O
different	O
from	O
the	O
way	O
we	O
have	O
previously	O
used	O
the	O
word	O
prior	O
to	O
refer	O
to	O
the	O
distribution	O
p	O
encoding	O
our	O
beliefs	O
about	O
the	O
model	O
s	O
parameters	O
before	O
we	O
have	O
seen	O
the	O
training	O
data	O
the	O
log-likelihood	O
can	O
be	O
decomposed	O
as	O
pmodelhpmodelx	O
h	O
log	O
pmodel	O
log	O
x	O
pmodel	O
x	O
h	O
we	O
can	O
think	O
of	O
the	O
autoencoder	O
as	O
approximating	O
this	O
sum	O
with	O
a	O
point	O
estimate	O
for	O
just	O
one	O
highly	O
likely	O
value	O
for	O
h	O
this	O
is	O
similar	O
to	O
the	O
sparse	O
coding	O
generative	O
h	O
being	O
the	O
output	O
of	O
the	O
parametric	O
encoder	B
rather	O
model	O
than	O
the	O
result	O
of	O
an	O
optimization	O
that	O
infers	O
the	O
most	O
likely	O
h	O
from	O
this	O
point	O
of	O
view	O
with	O
this	O
chosen	O
we	O
are	O
maximizing	O
but	O
with	O
h	O
log	O
pmodel	O
h	O
x	O
log	O
pmodel	O
log	O
h	O
pmodel	O
x	O
h	O
the	O
log	O
pmodel	O
term	O
can	O
be	O
sparsity-inducing	O
for	O
example	B
the	O
laplace	O
prior	O
pmodelhi	O
hi	O
e	O
corresponds	O
to	O
an	O
absolute	O
value	O
sparsity	O
penalty	O
expressing	O
the	O
log-prior	O
as	O
an	O
absolute	O
value	O
penalty	O
we	O
obtain	O
hi	O
h	O
h	O
log	O
pmodel	O
i	O
i	O
i	O
log	O
const	O
h	O
where	O
the	O
constant	O
term	O
depends	O
only	O
on	O
and	O
not	O
h	O
we	O
typically	O
treat	O
as	O
a	O
hyperparameter	O
and	O
discard	O
the	O
constant	O
term	O
since	O
it	O
does	O
not	O
affect	O
the	O
parameter	O
learning	O
other	O
priors	O
such	O
as	O
the	O
student-t	O
prior	O
can	O
also	O
induce	O
sparsity	O
from	O
this	O
point	O
of	O
view	O
of	O
sparsity	O
as	O
resulting	O
from	O
the	O
effect	O
of	O
pmodelh	O
on	O
approximate	O
maximum	B
likelihood	I
learning	O
the	O
sparsity	O
penalty	O
is	O
not	O
a	O
regularization	O
term	O
at	O
all	O
it	O
is	O
just	O
a	O
consequence	O
of	O
the	O
model	O
s	O
distribution	O
over	O
its	O
latent	O
variables	O
this	O
view	O
provides	O
a	O
different	O
motivation	O
for	O
training	O
an	O
autoencoder	O
it	O
is	O
a	O
way	O
of	O
approximately	O
training	O
a	O
generative	O
model	O
it	O
also	O
provides	O
a	O
different	O
reason	O
for	O
chapter	O
autoencoders	O
why	O
the	O
features	O
learned	O
by	O
the	O
autoencoder	O
are	O
useful	O
they	O
describe	O
the	O
latent	O
variables	O
that	O
explain	O
the	O
input	O
ranzato	O
et	O
al	O
early	O
work	O
on	O
sparse	O
autoencoders	O
explored	O
various	O
forms	O
of	O
sparsity	O
and	O
proposed	O
a	O
connection	O
between	O
the	O
sparsity	O
penalty	O
and	O
the	O
log	O
z	O
term	O
that	O
arises	O
when	O
applying	O
maximum	B
likelihood	I
to	O
an	O
undirected	O
probabilistic	O
model	O
px	O
px	O
the	O
idea	O
is	O
that	O
minimizing	O
log	O
z	O
prevents	O
a	O
z	O
probabilistic	O
model	O
from	O
having	O
high	O
probability	O
everywhere	O
and	O
imposing	O
sparsity	O
on	O
an	O
autoencoder	O
prevents	O
the	O
autoencoder	O
from	O
having	O
low	O
reconstruction	O
error	O
everywhere	O
in	O
this	O
case	O
the	O
connection	O
is	O
on	O
the	O
level	O
of	O
an	O
intuitive	O
understanding	O
of	O
a	O
general	O
mechanism	O
rather	O
than	O
a	O
mathematical	O
correspondence	O
the	O
interpretation	O
of	O
the	O
sparsity	O
penalty	O
as	O
corresponding	O
to	O
log	O
pmodelh	O
in	O
a	O
directed	O
model	O
pmodel	O
pmodel	O
is	O
more	O
mathematically	O
straightforward	O
x	O
h	O
one	O
way	O
to	O
achieve	O
actual	O
zeros	O
in	O
h	O
for	O
sparse	O
denoising	O
autoencoders	O
was	O
introduced	O
in	O
the	O
idea	O
is	O
to	O
use	O
rectified	O
linear	O
units	O
to	O
produce	O
the	O
code	O
layer	O
with	O
a	O
prior	O
that	O
actually	O
pushes	O
the	O
representations	O
to	O
zero	O
the	O
absolute	O
value	O
penalty	O
one	O
can	O
thus	O
indirectly	O
control	O
the	O
average	O
number	O
of	O
zeros	O
in	O
the	O
representation	O
glorot	O
et	O
al	O
denoising	O
autoencoders	O
rather	O
than	O
adding	O
a	O
penalty	O
to	O
the	O
cost	O
function	O
we	O
can	O
obtain	O
an	O
autoencoder	O
that	O
learns	O
something	O
useful	O
by	O
changing	O
the	O
reconstruction	O
error	O
term	O
of	O
the	O
cost	O
function	O
traditionally	O
autoencoders	O
minimize	O
some	O
function	O
l	O
g	O
f	O
where	O
l	O
is	O
a	O
loss	O
function	O
penalizing	O
gf	O
for	O
being	O
dissimilar	O
from	O
x	O
such	O
as	O
the	O
norm	O
of	O
their	O
difference	O
this	O
encourages	O
g	O
to	O
learn	O
to	O
be	O
merely	O
an	O
identity	O
function	O
if	O
they	O
have	O
the	O
capacity	O
to	O
do	O
so	O
f	O
a	O
denoising	O
autoencoder	O
or	O
dae	O
instead	O
minimizes	O
l	O
g	O
f	O
x	O
where	O
x	O
is	O
a	O
copy	O
of	O
x	O
that	O
has	O
been	O
corrupted	O
by	O
some	O
form	O
of	O
noise	O
denoising	O
autoencoders	O
must	O
therefore	O
undo	O
this	O
corruption	O
rather	O
than	O
simply	O
copying	O
their	O
input	O
denoising	O
training	O
forces	O
f	O
and	O
g	O
to	O
implicitly	O
learn	O
the	O
structure	O
of	O
pdata	O
denoising	O
alain	O
and	O
bengio	O
bengio	O
et	O
al	O
as	O
shown	O
by	O
and	O
chapter	O
autoencoders	O
autoencoders	O
thus	O
provide	O
yet	O
another	O
example	B
of	O
how	O
useful	O
properties	O
can	O
emerge	O
as	O
a	O
byproduct	O
of	O
minimizing	O
reconstruction	O
error	O
they	O
are	O
also	O
an	O
example	B
of	O
how	O
overcomplete	O
high-capacity	O
models	O
may	O
be	O
used	O
as	O
autoencoders	O
so	O
long	O
as	O
care	O
is	O
taken	O
to	O
prevent	O
them	O
from	O
learning	O
the	O
identity	O
function	O
denoising	O
autoencoders	O
are	O
presented	O
in	O
more	O
detail	O
in	O
section	O
regularizing	O
by	O
penalizing	O
derivatives	O
another	O
strategy	O
for	O
regularizing	O
an	O
autoencoder	O
is	O
to	O
use	O
a	O
penalty	O
autoencoders	O
l	O
g	O
f	O
x	O
h	O
x	O
but	O
with	O
a	O
different	O
form	O
of	O
h	O
x	O
xhi	O
i	O
as	O
in	O
sparse	O
this	O
forces	O
the	O
model	O
to	O
learn	O
a	O
function	O
that	O
does	O
not	O
change	O
much	O
when	O
x	O
changes	O
slightly	O
because	O
this	O
penalty	O
is	O
applied	O
only	O
at	O
training	O
examples	O
it	O
forces	O
the	O
autoencoder	O
to	O
learn	O
features	O
that	O
capture	O
information	O
about	O
the	O
training	O
distribution	O
an	O
autoencoder	O
regularized	O
in	O
this	O
way	O
is	O
called	O
a	O
contractive	B
autoencoder	I
or	O
cae	O
this	O
approach	O
has	O
theoretical	O
connections	O
to	O
denoising	O
autoencoders	O
manifold	B
learning	I
and	O
probabilistic	O
modeling	O
the	O
cae	O
is	O
described	O
in	O
more	O
detail	O
in	O
section	O
representational	O
power	O
layer	O
size	O
and	O
depth	O
autoencoders	O
are	O
often	O
trained	O
with	O
only	O
a	O
single	O
layer	O
encoder	B
and	O
a	O
single	O
layer	O
decoder	B
however	O
this	O
is	O
not	O
a	O
requirement	O
in	O
fact	O
using	O
deep	O
encoders	O
and	O
decoders	O
offers	O
many	O
advantages	O
recall	B
from	O
section	O
that	O
there	O
are	O
many	O
advantages	O
to	O
depth	O
in	O
a	O
feedforward	O
network	O
because	O
autoencoders	O
are	O
feedforward	O
networks	O
these	O
advantages	O
also	O
apply	O
to	O
autoencoders	O
moreover	O
the	O
encoder	B
is	O
itself	O
a	O
feedforward	O
network	O
as	O
is	O
the	O
decoder	B
so	O
each	O
of	O
these	O
components	O
of	O
the	O
autoencoder	O
can	O
individually	O
benefit	O
from	O
depth	O
one	O
major	O
advantage	O
of	O
non-trivial	O
depth	O
is	O
that	O
the	O
universal	B
approximator	I
theorem	O
guarantees	O
that	O
a	O
feedforward	B
neural	B
network	I
with	O
at	O
least	O
one	O
hidden	B
layer	I
can	O
represent	O
an	O
approximation	O
of	O
any	O
function	O
a	O
broad	O
class	O
to	O
an	O
chapter	O
autoencoders	O
arbitrary	O
degree	O
of	O
accuracy	B
provided	O
that	O
it	O
has	O
enough	O
hidden	O
units	O
this	O
means	O
that	O
an	O
autoencoder	O
with	O
a	O
single	O
hidden	B
layer	I
is	O
able	O
to	O
represent	O
the	O
identity	O
function	O
along	O
the	O
domain	O
of	O
the	O
data	O
arbitrarily	O
well	O
however	O
the	O
mapping	O
from	O
input	O
to	O
code	O
is	O
shallow	O
this	O
means	O
that	O
we	O
are	O
not	O
able	O
to	O
enforce	O
arbitrary	O
constraints	O
such	O
as	O
that	O
the	O
code	O
should	O
be	O
sparse	O
a	O
deep	O
autoencoder	O
with	O
at	O
least	O
one	O
additional	O
hidden	B
layer	I
inside	O
the	O
encoder	B
itself	O
can	O
approximate	O
any	O
mapping	O
from	O
input	O
to	O
code	O
arbitrarily	O
well	O
given	O
enough	O
hidden	O
units	O
depth	O
can	O
exponentially	O
reduce	O
the	O
computational	O
cost	O
of	O
representing	O
some	O
functions	O
depth	O
can	O
also	O
exponentially	O
decrease	O
the	O
amount	O
of	O
training	O
data	O
needed	O
to	O
learn	O
some	O
functions	O
see	O
section	O
for	O
a	O
review	O
of	O
the	O
advantages	O
of	O
depth	O
in	O
feedforward	O
networks	O
experimentally	O
deep	O
autoencoders	O
yield	O
much	O
better	O
compression	O
than	O
corre	O
sponding	O
shallow	O
or	O
linear	O
autoencoders	O
and	O
salakhutdinov	O
a	O
common	O
strategy	O
for	O
training	O
a	O
deep	O
autoencoder	O
is	O
to	O
greedily	O
pretrain	O
the	O
deep	O
architecture	O
by	O
training	O
a	O
stack	O
of	O
shallow	O
autoencoders	O
so	O
we	O
often	O
encounter	O
shallow	O
autoencoders	O
even	O
when	O
the	O
ultimate	O
goal	O
is	O
to	O
train	O
a	O
deep	O
autoencoder	O
stochastic	O
encoders	O
and	O
decoders	O
autoencoders	O
are	O
just	O
feedforward	O
networks	O
the	O
same	O
loss	O
functions	O
and	O
output	O
unit	O
types	O
that	O
can	O
be	O
used	O
for	O
traditional	O
feedforward	O
networks	O
are	O
also	O
used	O
for	O
autoencoders	O
as	O
described	O
in	O
section	O
a	O
general	O
strategy	O
for	O
designing	O
the	O
output	O
units	O
and	O
the	O
loss	O
function	O
of	O
a	O
feedforward	O
network	O
is	O
to	O
define	O
an	O
output	O
distribution	O
py	O
x	O
in	O
that	O
setting	O
y	O
was	O
a	O
vector	O
of	O
targets	O
such	O
as	O
class	O
labels	O
and	O
minimize	O
the	O
negative	O
log-likelihood	O
log	O
py	O
x	O
in	O
the	O
case	O
of	O
an	O
autoencoder	O
x	O
is	O
now	O
the	O
target	O
as	O
well	O
as	O
the	O
input	O
however	O
we	O
can	O
still	O
apply	O
the	O
same	O
machinery	O
as	O
before	O
given	O
a	O
hidden	O
code	O
h	O
we	O
may	O
think	O
of	O
the	O
decoder	B
as	O
providing	O
a	O
conditional	O
distribution	O
p	O
decoderx	O
h	O
we	O
may	O
then	O
train	O
the	O
autoencoder	O
by	O
minimizing	O
the	O
exact	O
form	O
of	O
this	O
loss	O
function	O
will	O
change	O
depending	O
on	O
the	O
form	O
of	O
pdecoder	O
as	O
with	O
traditional	O
feedforward	O
networks	O
we	O
usually	O
use	O
linear	O
output	O
units	O
to	O
parametrize	O
the	O
mean	O
of	O
a	O
gaussian	O
distribution	O
if	O
x	O
is	O
real-valued	O
in	O
that	O
case	O
the	O
negative	O
log-likelihood	O
yields	O
a	O
mean	B
squared	I
error	I
criterion	O
similarly	O
binary	O
x	O
values	O
correspond	O
to	O
a	O
bernoulli	B
distribution	I
whose	O
parameters	O
are	O
given	O
by	O
a	O
sigmoid	O
output	O
unit	O
discrete	O
x	O
values	O
correspond	O
to	O
a	O
softmax	O
distribution	O
and	O
so	O
on	O
log	O
pdecoder	O
x	O
h	O
chapter	O
autoencoders	O
typically	O
the	O
output	O
variables	O
are	O
treated	O
as	O
being	O
conditionally	O
independent	O
given	O
h	O
so	O
that	O
this	O
probability	B
distribution	I
is	O
inexpensive	O
to	O
evaluate	O
but	O
some	O
techniques	O
such	O
as	O
mixture	O
density	O
outputs	O
allow	O
tractable	O
modeling	O
of	O
outputs	O
with	O
correlations	O
hh	O
pencoder	O
h	O
x	O
pdecoder	O
x	O
h	O
xx	O
rr	O
figure	O
the	O
structure	O
of	O
a	O
stochastic	O
autoencoder	O
in	O
which	O
both	O
the	O
encoder	B
and	O
the	O
decoder	B
are	O
not	O
simple	O
functions	O
but	O
instead	O
involve	O
some	O
noise	O
injection	O
meaning	O
that	O
their	O
output	O
can	O
be	O
seen	O
as	O
sampled	O
from	O
a	O
distribution	O
pencoderh	O
x	O
for	O
the	O
encoder	B
and	O
pdecoder	O
for	O
the	O
decoder	B
x	O
h	O
to	O
make	O
a	O
more	O
radical	O
departure	O
from	O
the	O
feedforward	O
networks	O
we	O
have	O
seen	O
previously	O
we	O
can	O
also	O
generalize	O
the	O
notion	O
of	O
an	O
encoding	O
function	O
f	O
to	O
an	O
encoding	O
distribution	O
pencoder	O
any	O
latent	B
variable	I
model	O
pmodel	O
as	O
illustrated	O
in	O
figure	O
h	O
x	O
defines	O
a	O
stochastic	O
encoder	B
x	O
pencoder	O
h	O
x	O
pmodel	O
h	O
x	O
and	O
a	O
stochastic	O
decoder	B
pdecoder	O
x	O
h	O
pmodel	O
x	O
h	O
in	O
general	O
the	O
encoder	B
and	O
decoder	B
distributions	O
are	O
not	O
necessarily	O
conditional	O
distributions	O
compatible	O
with	O
a	O
unique	O
joint	O
distribution	O
pmodelx	O
h	O
alain	O
et	O
al	O
showed	O
that	O
training	O
the	O
encoder	B
and	O
decoder	B
as	O
a	O
denoising	O
autoencoder	O
will	O
tend	O
to	O
make	O
them	O
compatible	O
asymptotically	O
enough	O
capacity	O
and	O
examples	O
denoising	O
autoencoders	O
the	O
denoising	O
autoencoder	O
is	O
an	O
autoencoder	O
that	O
receives	O
a	O
corrupted	O
data	O
point	O
as	O
input	O
and	O
is	O
trained	O
to	O
predict	O
the	O
original	O
uncorrupted	O
data	O
point	O
as	O
its	O
output	O
the	O
dae	O
training	O
procedure	O
is	O
illustrated	O
in	O
figure	O
we	O
introduce	O
a	O
which	O
represents	O
a	O
conditional	O
distribution	O
over	O
corruption	O
process	O
c	O
x	O
x	O
chapter	O
autoencoders	O
hh	O
g	O
ll	O
f	O
x	O
x	O
xx	O
c	O
x	O
x	O
figure	O
the	O
computational	B
graph	I
of	O
the	O
cost	O
function	O
for	O
a	O
denoising	O
autoencoder	O
which	O
is	O
trained	O
to	O
reconstruct	O
the	O
clean	O
data	O
point	O
x	O
from	O
its	O
corrupted	O
version	O
x	O
this	O
is	O
accomplished	O
by	O
minimizing	O
the	O
loss	O
l	O
f	O
x	O
where	O
x	O
is	O
a	O
corrupted	O
version	O
of	O
the	O
data	O
example	B
x	O
obtained	O
through	O
a	O
given	O
corruption	O
process	O
c	O
x	O
x	O
typically	O
the	O
distribution	O
pdecoder	O
is	O
a	O
factorial	O
distribution	O
whose	O
mean	O
parameters	O
are	O
emitted	O
by	O
a	O
feedforward	O
network	O
log	O
pdecoderx	O
h	O
corrupted	O
samples	O
x	O
given	O
a	O
data	O
sample	O
x	O
the	O
autoencoder	O
then	O
learns	O
a	O
x	O
estimated	O
from	O
training	O
pairs	O
reconstruction	O
distribution	O
preconstruct	O
x	O
as	O
follows	O
sample	O
a	O
training	O
example	B
x	O
from	O
the	O
training	O
data	O
sample	O
a	O
corrupted	O
version	O
x	O
from	O
c	O
x	O
x	O
use	O
x	O
as	O
a	O
training	O
example	B
for	O
estimating	O
the	O
autoencoder	O
reconstruction	O
with	O
h	O
the	O
output	O
of	O
encoder	B
distribution	O
preconstructx	O
f	O
x	O
and	O
pdecoder	O
typically	O
defined	O
by	O
a	O
decoder	B
x	O
pdecoderx	O
h	O
g	O
typically	O
we	O
can	O
simply	O
perform	O
gradient-based	O
approximate	O
minimization	O
log	O
pdecoderx	O
h	O
as	O
minibatch	B
gradient	B
descent	O
on	O
the	O
negative	O
log-likelihood	O
so	O
long	O
as	O
the	O
encoder	B
is	O
deterministic	O
the	O
denoising	O
autoencoder	O
is	O
a	O
feedforward	O
network	O
and	O
may	O
be	O
trained	O
with	O
exactly	O
the	O
same	O
techniques	O
as	O
any	O
other	O
feedforward	O
network	O
we	O
can	O
therefore	O
view	O
the	O
dae	O
as	O
performing	O
stochastic	O
gradient	B
descent	O
on	O
the	O
following	O
expectation	B
x	O
log	O
pdecoder	O
pdata	O
e	O
x	O
c	O
x	O
ex	O
x	O
h	O
f	O
x	O
where	O
pdata	O
is	O
the	O
training	O
distribution	O
chapter	O
autoencoders	O
x	O
g	O
f	O
x	O
x	O
c	O
x	O
x	O
x	O
figure	O
a	O
denoising	O
autoencoder	O
is	O
trained	O
to	O
map	O
a	O
corrupted	O
data	O
point	O
x	O
back	O
to	O
the	O
original	O
data	O
point	O
x	O
we	O
illustrate	O
training	O
examples	O
x	O
as	O
red	O
crosses	O
lying	O
near	O
a	O
low-dimensional	O
manifold	B
illustrated	O
with	O
the	O
bold	O
black	O
line	O
we	O
illustrate	O
the	O
corruption	O
process	O
c	O
x	O
x	O
with	O
a	O
gray	O
circle	O
of	O
equiprobable	O
corruptions	O
a	O
gray	O
arrow	O
demonstrates	O
how	O
one	O
training	O
example	B
is	O
transformed	O
into	O
one	O
sample	O
from	O
this	O
corruption	O
process	O
when	O
the	O
denoising	O
autoencoder	O
is	O
trained	O
to	O
minimize	O
the	O
average	O
of	O
squared	O
errors	O
x	O
the	O
reconstruction	O
g	O
x	O
estimates	O
e	O
x	O
x	O
the	O
vector	O
gf	O
x	O
x	O
points	O
approximately	O
towards	O
the	O
nearest	O
point	O
on	O
the	O
manifold	B
since	O
gf	O
x	O
gf	O
x	O
estimates	O
the	O
center	O
of	O
mass	O
of	O
the	O
clean	O
points	O
x	O
which	O
could	O
have	O
given	O
rise	O
to	O
x	O
the	O
autoencoder	O
thus	O
learns	O
a	O
vector	O
field	O
gf	O
x	O
indicated	O
by	O
the	O
green	O
arrows	O
this	O
vector	O
field	O
estimates	O
the	O
score	O
xlog	O
pdata	O
up	O
to	O
a	O
multiplicative	O
factor	O
that	O
is	O
the	O
average	O
root	O
mean	O
square	O
reconstruction	O
error	O
pdata	O
x	O
c	O
x	O
x	O
x	O
chapter	O
autoencoders	O
estimating	O
the	O
score	O
hyv	O
rinen	O
score	O
matching	O
is	O
an	O
alternative	O
to	O
maximum	B
likelihood	I
it	O
provides	O
a	O
consistent	O
estimator	O
of	O
probability	O
distributions	O
based	O
on	O
encouraging	O
the	O
model	O
to	O
have	O
the	O
same	O
score	O
as	O
the	O
data	O
distribution	O
at	O
every	O
training	O
point	O
x	O
in	O
this	O
context	O
the	O
score	O
is	O
a	O
particular	O
gradient	B
field	O
x	O
log	O
p	O
x	O
score	O
matching	O
is	O
discussed	O
further	O
in	O
section	O
for	O
the	O
present	O
discussion	O
regarding	O
autoencoders	O
it	O
is	O
sufficient	O
to	O
understand	O
that	O
learning	O
the	O
gradient	B
field	O
of	O
log	O
pdata	O
is	O
one	O
way	O
to	O
learn	O
the	O
structure	O
of	O
pdata	O
itself	O
a	O
very	O
important	O
property	O
of	O
daes	O
is	O
that	O
their	O
training	O
criterion	O
makes	O
the	O
autoencoder	O
learn	O
a	O
vector	O
field	O
x	O
that	O
estimates	O
the	O
score	O
of	O
the	O
data	O
distribution	O
this	O
is	O
illustrated	O
conditionally	O
gaussian	O
p	O
x	O
h	O
in	O
figure	O
vincent	O
denoising	O
training	O
of	O
a	O
specific	O
kind	O
of	O
autoencoder	O
hidden	O
units	O
linear	O
reconstruction	O
units	O
using	O
gaussian	O
noise	O
and	O
mean	B
squared	I
error	I
as	O
the	O
reconstruction	O
cost	O
is	O
equivalent	O
to	O
training	O
a	O
specific	O
kind	O
of	O
undirected	O
probabilistic	O
model	O
called	O
an	O
rbm	O
with	O
gaussian	O
visible	O
units	O
this	O
kind	O
of	O
model	O
will	O
be	O
described	O
in	O
detail	O
in	O
section	O
for	O
the	O
present	O
discussion	O
it	O
suffices	O
to	O
know	O
that	O
it	O
is	O
a	O
model	O
that	O
provides	O
an	O
explicit	O
pmodelx	O
when	O
the	O
rbm	O
is	O
trained	O
using	O
denoising	B
score	I
matching	I
kingma	O
and	O
lecun	O
its	O
learning	O
algorithm	O
is	O
equivalent	O
to	O
denoising	O
training	O
in	O
the	O
corresponding	O
autoencoder	O
with	O
a	O
fixed	O
noise	O
level	O
regularized	O
score	O
matching	O
is	O
not	O
a	O
consistent	O
estimator	O
it	O
instead	O
recovers	O
a	O
blurred	O
version	O
of	O
the	O
distribution	O
however	O
if	O
the	O
noise	O
level	O
is	O
chosen	O
to	O
approach	O
when	O
the	O
number	O
of	O
examples	O
approaches	O
infinity	O
then	O
consistency	O
is	O
recovered	O
denoising	B
score	I
matching	I
is	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
other	O
connections	O
between	O
autoencoders	O
and	O
rbms	O
exist	O
score	O
matching	O
applied	O
to	O
rbms	O
yields	O
a	O
cost	O
function	O
that	O
is	O
identical	O
to	O
reconstruction	O
error	O
combined	O
with	O
a	O
regularization	O
term	O
similar	O
to	O
the	O
contractive	O
penalty	O
of	O
the	O
cae	O
showed	O
that	O
an	O
autoencoder	O
gradient	B
provides	O
an	O
approximation	O
to	O
contrastive	O
divergence	O
training	O
of	O
rbms	O
bengio	O
and	O
delalleau	O
et	O
al	O
for	O
continuous-valued	O
x	O
the	O
denoising	O
criterion	O
with	O
gaussian	O
corruption	O
and	O
reconstruction	O
distribution	O
yields	O
an	O
estimator	O
of	O
the	O
score	O
that	O
is	O
applicable	O
to	O
general	O
encoder	B
and	O
decoder	B
parametrizations	O
this	O
means	O
a	O
generic	O
encoder-decoder	O
architecture	O
may	O
be	O
made	O
to	O
estimate	O
the	O
score	O
alain	O
and	O
bengio	O
chapter	O
autoencoders	O
by	O
training	O
with	O
the	O
squared	O
error	O
criterion	O
g	O
f	O
x	O
n	O
c	O
x	O
x	O
x	O
and	O
corruption	O
x	O
x	O
x	O
i	O
with	O
noise	O
variance	O
see	O
figure	O
for	O
an	O
illustration	O
of	O
how	O
this	O
works	O
figure	O
vector	O
field	O
learned	O
by	O
a	O
denoising	O
autoencoder	O
around	O
a	O
curved	O
manifold	B
near	O
which	O
the	O
data	O
concentrates	O
in	O
a	O
space	O
each	O
arrow	O
is	O
proportional	O
to	O
the	O
reconstruction	O
minus	O
input	O
vector	O
of	O
the	O
autoencoder	O
and	O
points	O
towards	O
higher	O
probability	O
according	O
to	O
the	O
implicitly	O
estimated	O
probability	B
distribution	I
the	O
vector	O
field	O
has	O
zeros	O
at	O
both	O
maxima	O
of	O
the	O
estimated	O
density	O
function	O
the	O
data	O
manifolds	O
and	O
at	O
minima	O
of	O
that	O
density	O
function	O
for	O
example	B
the	O
spiral	O
arm	O
forms	O
a	O
one-dimensional	O
manifold	B
of	O
local	O
maxima	O
that	O
are	O
connected	O
to	O
each	O
other	O
local	O
minima	O
appear	O
near	O
the	O
middle	O
of	O
the	O
gap	O
between	O
two	O
arms	O
when	O
the	O
norm	O
of	O
reconstruction	O
error	O
by	O
the	O
length	O
of	O
the	O
arrows	O
is	O
large	O
it	O
means	O
that	O
probability	O
can	O
be	O
significantly	O
increased	O
by	O
moving	O
in	O
the	O
direction	O
of	O
the	O
arrow	O
and	O
that	O
is	O
mostly	O
the	O
case	O
in	O
places	O
of	O
low	O
probability	O
the	O
autoencoder	O
maps	O
these	O
low	O
probability	O
points	O
to	O
higher	O
probability	O
reconstructions	O
where	O
probability	O
is	O
maximal	O
the	O
arrows	O
shrink	O
because	O
the	O
reconstruction	O
becomes	O
more	O
accurate	O
figure	O
reproduced	O
with	O
permission	O
from	O
alain	O
and	O
bengio	O
in	O
general	O
there	O
is	O
no	O
guarantee	O
that	O
the	O
reconstruction	O
gf	O
minus	O
the	O
input	O
x	O
corresponds	O
to	O
the	O
gradient	B
of	O
any	O
function	O
let	O
alone	O
to	O
the	O
score	O
that	O
is	O
chapter	O
autoencoders	O
vincent	O
why	O
the	O
early	O
results	O
where	O
g	O
vincent	O
generalized	O
the	O
results	O
of	O
kamyshanska	O
and	O
memisevic	O
identifying	O
a	O
family	O
of	O
shallow	O
autoencoders	O
such	O
that	O
gf	O
a	O
score	O
for	O
all	O
members	O
of	O
the	O
family	O
are	O
specialized	O
to	O
particular	O
parametrizations	O
x	O
may	O
be	O
obtained	O
by	O
taking	O
the	O
derivative	B
of	O
another	O
function	O
by	O
x	O
corresponds	O
to	O
so	O
far	O
we	O
have	O
described	O
only	O
how	O
the	O
denoising	O
autoencoder	O
learns	O
to	O
represent	O
a	O
probability	B
distribution	I
more	O
generally	O
one	O
may	O
want	O
to	O
use	O
the	O
autoencoder	O
as	O
a	O
generative	O
model	O
and	O
draw	O
samples	O
from	O
this	O
distribution	O
this	O
will	O
be	O
described	O
later	O
in	O
section	O
historical	O
perspective	O
gallinari	O
et	O
al	O
behnke	O
lecun	O
the	O
idea	O
of	O
using	O
mlps	O
for	O
denoising	O
dates	O
back	O
to	O
the	O
work	O
of	O
and	O
also	O
used	O
recurrent	O
networks	O
to	O
denoise	O
images	O
denoising	O
autoencoders	O
are	O
in	O
some	O
sense	O
just	O
mlps	O
trained	O
to	O
denoise	O
however	O
the	O
name	O
denoising	O
autoencoder	O
refers	O
to	O
a	O
model	O
that	O
is	O
intended	O
not	O
merely	O
to	O
learn	O
to	O
denoise	O
its	O
input	O
but	O
to	O
learn	O
a	O
good	O
internal	O
representation	O
as	O
a	O
side	O
effect	O
of	O
learning	O
to	O
denoise	O
this	O
idea	O
came	O
much	O
later	O
et	O
al	O
the	O
learned	O
representation	O
may	O
then	O
be	O
used	O
to	O
pretrain	O
a	O
deeper	O
unsupervised	O
network	O
or	O
a	O
supervised	O
network	O
like	O
sparse	O
autoencoders	O
sparse	O
coding	O
contractive	O
autoencoders	O
and	O
other	O
regularized	O
autoencoders	O
the	O
motivation	O
for	O
daes	O
was	O
to	O
allow	O
the	O
learning	O
of	O
a	O
very	O
high-capacity	O
encoder	B
while	O
preventing	O
the	O
encoder	B
and	O
decoder	B
from	O
learning	O
a	O
useless	O
identity	O
function	O
prior	O
to	O
the	O
introduction	O
of	O
the	O
modern	O
dae	O
inayoshi	O
and	O
kurita	O
explored	O
some	O
of	O
the	O
same	O
goals	O
with	O
some	O
of	O
the	O
same	O
methods	O
their	O
approach	O
minimizes	O
reconstruction	O
error	O
in	O
addition	O
to	O
a	O
supervised	O
objective	O
while	O
injecting	O
noise	O
in	O
the	O
hidden	B
layer	I
of	O
a	O
supervised	O
mlp	O
with	O
the	O
objective	O
to	O
improve	O
generalization	B
by	O
introducing	O
the	O
reconstruction	O
error	O
and	O
the	O
injected	O
noise	O
however	O
their	O
method	O
was	O
based	O
on	O
a	O
linear	O
encoder	B
and	O
could	O
not	O
learn	O
function	O
families	O
as	O
powerful	O
as	O
can	O
the	O
modern	O
dae	O
learning	O
manifolds	O
with	O
autoencoders	O
like	O
many	O
other	O
machine	B
learning	I
algorithms	O
autoencoders	O
exploit	O
the	O
idea	O
that	O
data	O
concentrates	O
around	O
a	O
low-dimensional	O
manifold	B
or	O
a	O
small	O
set	O
of	O
such	O
manifolds	O
as	O
described	O
in	O
section	O
some	O
machine	B
learning	I
algorithms	O
exploit	O
this	O
idea	O
only	O
insofar	O
as	O
that	O
they	O
learn	O
a	O
function	O
that	O
behaves	O
correctly	O
on	O
the	O
manifold	B
but	O
may	O
have	O
unusual	O
behavior	O
if	O
given	O
an	O
input	O
that	O
is	O
off	O
the	O
manifold	B
chapter	O
autoencoders	O
autoencoders	O
take	O
this	O
idea	O
further	O
and	O
aim	O
to	O
learn	O
the	O
structure	O
of	O
the	O
manifold	B
to	O
understand	O
how	O
autoencoders	O
do	O
this	O
we	O
must	O
present	O
some	O
important	O
characteristics	O
of	O
manifolds	O
an	O
important	O
characterization	O
of	O
a	O
manifold	B
is	O
the	O
set	O
of	O
its	O
tangent	O
planes	O
at	O
a	O
point	O
x	O
on	O
a	O
d-dimensional	O
manifold	B
the	O
tangent	B
plane	I
is	O
given	O
by	O
d	O
basis	O
vectors	O
that	O
span	O
the	O
local	O
directions	O
of	O
variation	O
allowed	O
on	O
the	O
manifold	B
as	O
x	O
illustrated	O
in	O
figure	O
infinitesimally	O
while	O
staying	O
on	O
the	O
manifold	B
these	O
local	O
directions	O
specify	O
how	O
one	O
can	O
change	O
all	O
autoencoder	O
training	O
procedures	O
involve	O
a	O
compromise	O
between	O
two	O
forces	O
learning	O
a	O
representation	O
h	O
of	O
a	O
training	O
example	B
x	O
such	O
that	O
x	O
can	O
be	O
approximately	O
recovered	O
from	O
h	O
through	O
a	O
decoder	B
the	O
fact	O
that	O
x	O
is	O
drawn	O
from	O
the	O
training	O
data	O
is	O
crucial	O
because	O
it	O
means	O
the	O
autoencoder	O
need	O
not	O
successfully	O
reconstruct	O
inputs	O
that	O
are	O
not	O
probable	O
under	O
the	O
data	O
generating	O
distribution	O
satisfying	O
the	O
constraint	O
or	O
regularization	O
penalty	O
this	O
can	O
be	O
an	O
architectural	O
constraint	O
that	O
limits	O
the	O
capacity	O
of	O
the	O
autoencoder	O
or	O
it	O
can	O
be	O
a	O
regularization	O
term	O
added	O
to	O
the	O
reconstruction	O
cost	O
these	O
techniques	O
generally	O
prefer	O
solutions	O
that	O
are	O
less	O
sensitive	O
to	O
the	O
input	O
clearly	O
neither	O
force	O
alone	O
would	O
be	O
useful	O
copying	O
the	O
input	O
to	O
the	O
output	O
is	O
not	O
useful	O
on	O
its	O
own	O
nor	O
is	O
ignoring	O
the	O
input	O
instead	O
the	O
two	O
forces	O
together	O
are	O
useful	O
because	O
they	O
force	O
the	O
hidden	O
representation	O
to	O
capture	O
information	O
about	O
the	O
structure	O
of	O
the	O
data	O
generating	O
distribution	O
the	O
important	O
principle	O
is	O
that	O
the	O
autoencoder	O
can	O
afford	O
to	O
represent	O
only	O
the	O
variations	O
that	O
are	O
needed	O
to	O
reconstruct	O
training	O
examples	O
if	O
the	O
data	O
generating	O
distribution	O
concentrates	O
near	O
a	O
low-dimensional	O
manifold	B
this	O
yields	O
representations	O
that	O
implicitly	O
capture	O
a	O
local	O
coordinate	O
system	O
for	O
this	O
manifold	B
only	O
the	O
variations	O
tangent	O
to	O
the	O
manifold	B
around	O
x	O
need	O
to	O
correspond	O
to	O
changes	O
in	O
h	O
fx	O
hence	O
the	O
encoder	B
learns	O
a	O
mapping	O
from	O
the	O
input	O
space	O
x	O
to	O
a	O
representation	O
space	O
a	O
mapping	O
that	O
is	O
only	O
sensitive	O
to	O
changes	O
along	O
the	O
manifold	B
directions	O
but	O
that	O
is	O
insensitive	O
to	O
changes	O
orthogonal	O
to	O
the	O
manifold	B
a	O
one-dimensional	O
example	B
is	O
illustrated	O
in	O
figure	O
showing	O
that	O
by	O
making	O
the	O
reconstruction	O
function	O
insensitive	O
to	O
perturbations	O
of	O
the	O
input	O
around	O
the	O
data	O
points	O
we	O
cause	O
the	O
autoencoder	O
to	O
recover	O
the	O
manifold	B
structure	O
to	O
understand	O
why	O
autoencoders	O
are	O
useful	O
for	O
manifold	B
learning	I
it	O
is	O
instructive	O
to	O
compare	O
them	O
to	O
other	O
approaches	O
what	O
is	O
most	O
commonly	O
learned	O
to	O
characterize	O
a	O
manifold	B
is	O
a	O
representation	O
of	O
the	O
data	O
points	O
on	O
near	O
chapter	O
autoencoders	O
figure	O
an	O
illustration	O
of	O
the	O
concept	O
of	O
a	O
tangent	O
hyperplane	O
here	O
we	O
create	O
a	O
one-dimensional	O
manifold	B
in	O
space	O
we	O
take	O
an	O
mnist	O
image	O
with	O
pixels	O
and	O
transform	O
it	O
by	O
translating	O
it	O
vertically	O
the	O
amount	O
of	O
vertical	O
translation	O
defines	O
a	O
coordinate	O
along	O
a	O
one-dimensional	O
manifold	B
that	O
traces	O
out	O
a	O
curved	O
path	O
through	O
image	O
space	O
this	O
plot	O
shows	O
a	O
few	O
points	O
along	O
this	O
manifold	B
for	O
visualization	O
we	O
have	O
projected	O
the	O
manifold	B
into	O
two	O
dimensional	O
space	O
using	O
pca	O
an	O
n-dimensional	O
manifold	B
has	O
an	O
n-dimensional	O
tangent	B
plane	I
at	O
every	O
point	O
this	O
tangent	B
plane	I
touches	O
the	O
manifold	B
exactly	O
at	O
that	O
point	O
and	O
is	O
oriented	O
parallel	O
to	O
the	O
surface	O
at	O
that	O
point	O
it	O
defines	O
the	O
space	O
of	O
directions	O
in	O
which	O
it	O
is	O
possible	O
to	O
move	O
while	O
remaining	O
on	O
the	O
manifold	B
this	O
one-dimensional	O
manifold	B
has	O
a	O
single	O
tangent	O
line	O
we	O
indicate	O
an	O
example	B
tangent	O
line	O
at	O
one	O
point	O
with	O
an	O
image	O
showing	O
how	O
this	O
tangent	O
direction	O
appears	O
in	O
image	O
space	O
gray	O
pixels	O
indicate	O
pixels	O
that	O
do	O
not	O
change	O
as	O
we	O
move	O
along	O
the	O
tangent	O
line	O
white	O
pixels	O
indicate	O
pixels	O
that	O
brighten	O
and	O
black	O
pixels	O
indicate	O
pixels	O
that	O
darken	O
chapter	O
autoencoders	O
x	O
r	O
identity	O
optimal	O
reconstruction	O
x	O
x	O
figure	O
if	O
the	O
autoencoder	O
learns	O
a	O
reconstruction	O
function	O
that	O
is	O
invariant	O
to	O
small	O
perturbations	O
near	O
the	O
data	O
points	O
it	O
captures	O
the	O
manifold	B
structure	O
of	O
the	O
data	O
here	O
the	O
manifold	B
structure	O
is	O
a	O
collection	O
of	O
manifolds	O
the	O
dashed	O
diagonal	O
line	O
indicates	O
the	O
identity	O
function	O
target	O
for	O
reconstruction	O
the	O
optimal	O
reconstruction	O
function	O
crosses	O
the	O
identity	O
function	O
wherever	O
there	O
is	O
a	O
data	O
point	O
the	O
horizontal	O
arrows	O
at	O
the	O
bottom	O
of	O
the	O
plot	O
indicate	O
the	O
r	O
x	O
reconstruction	O
direction	O
vector	O
at	O
the	O
base	O
of	O
the	O
arrow	O
in	O
input	O
space	O
always	O
pointing	O
towards	O
the	O
nearest	O
manifold	B
single	O
datapoint	O
in	O
the	O
case	O
the	O
denoising	O
autoencoder	O
explicitly	O
tries	O
to	O
make	O
the	O
derivative	B
of	O
the	O
reconstruction	O
function	O
rx	O
small	O
around	O
the	O
data	O
points	O
the	O
contractive	B
autoencoder	I
does	O
the	O
same	O
for	O
the	O
encoder	B
although	O
the	O
derivative	B
of	O
rx	O
is	O
asked	O
to	O
be	O
small	O
around	O
the	O
data	O
points	O
it	O
can	O
be	O
large	O
between	O
the	O
data	O
points	O
the	O
space	O
between	O
the	O
data	O
points	O
corresponds	O
to	O
the	O
region	O
between	O
the	O
manifolds	O
where	O
the	O
reconstruction	O
function	O
must	O
have	O
a	O
large	O
derivative	B
in	O
order	O
to	O
map	O
corrupted	O
points	O
back	O
onto	O
the	O
manifold	B
the	O
manifold	B
such	O
a	O
representation	O
for	O
a	O
particular	O
example	B
is	O
also	O
called	O
its	O
embedding	B
it	O
is	O
typically	O
given	O
by	O
a	O
low-dimensional	O
vector	O
with	O
less	O
dimensions	O
than	O
the	O
ambient	O
space	O
of	O
which	O
the	O
manifold	B
is	O
a	O
low-dimensional	O
subset	O
some	O
algorithms	O
manifold	B
learning	I
algorithms	O
discussed	O
below	O
directly	O
learn	O
an	O
embedding	B
for	O
each	O
training	O
example	B
while	O
others	O
learn	O
a	O
more	O
general	O
mapping	O
sometimes	O
called	O
an	O
encoder	B
or	O
representation	O
function	O
that	O
maps	O
any	O
point	O
in	O
the	O
ambient	O
space	O
input	O
space	O
to	O
its	O
embedding	B
manifold	B
learning	I
has	O
mostly	O
focused	O
on	O
unsupervised	O
learning	O
procedures	O
that	O
attempt	O
to	O
capture	O
these	O
manifolds	O
most	O
of	O
the	O
initial	O
machine	B
learning	I
research	O
on	O
learning	O
nonlinear	O
manifolds	O
has	O
focused	O
on	O
non-parametric	O
methods	O
based	O
on	O
the	O
nearest-neighbor	O
graph	O
this	O
graph	O
has	O
one	O
node	O
per	O
training	O
example	B
and	O
edges	O
connecting	O
near	O
neighbors	O
to	O
each	O
other	O
these	O
methods	O
lkopf	O
brand	O
belkin	O
et	O
al	O
roweis	O
and	O
saul	O
tenenbaum	O
et	O
al	O
chapter	O
autoencoders	O
figure	O
non-parametric	O
manifold	B
learning	I
procedures	O
build	O
a	O
nearest	O
neighbor	O
graph	O
in	O
which	O
nodes	O
represent	O
training	O
examples	O
a	O
directed	O
edges	O
indicate	O
nearest	O
neighbor	O
relationships	O
various	O
procedures	O
can	O
thus	O
obtain	O
the	O
tangent	B
plane	I
associated	O
with	O
a	O
neighborhood	O
of	O
the	O
graph	O
as	O
well	O
as	O
a	O
coordinate	O
system	O
that	O
associates	O
each	O
training	O
example	B
with	O
a	O
real-valued	O
vector	O
position	O
or	O
embedding	B
it	O
is	O
possible	O
to	O
generalize	O
such	O
a	O
representation	O
to	O
new	O
examples	O
by	O
a	O
form	O
of	O
interpolation	O
so	O
long	O
as	O
the	O
number	O
of	O
examples	O
is	O
large	O
enough	O
to	O
cover	O
the	O
curvature	O
and	O
twists	O
of	O
the	O
manifold	B
these	O
approaches	O
work	O
well	O
images	O
from	O
the	O
qmul	O
multiview	O
face	O
dataset	B
gong	O
et	O
al	O
and	O
niyogi	O
donoho	O
and	O
grimes	O
weinberger	O
and	O
saul	O
hinton	O
and	O
roweis	O
van	O
der	O
maaten	O
and	O
hinton	O
associate	O
each	O
of	O
nodes	O
with	O
a	O
tangent	B
plane	I
that	O
spans	O
the	O
directions	O
of	O
variations	O
associated	O
with	O
the	O
difference	O
vectors	O
between	O
the	O
example	B
and	O
its	O
neighbors	O
as	O
illustrated	O
in	O
figure	O
a	O
global	O
coordinate	O
system	O
can	O
then	O
be	O
obtained	O
through	O
an	O
optimization	O
or	O
solving	O
a	O
linear	O
system	O
figure	O
illustrates	O
how	O
a	O
manifold	B
can	O
be	O
tiled	O
by	O
a	O
large	O
number	O
of	O
locally	O
linear	O
gaussian-like	O
patches	O
pancakes	O
because	O
the	O
gaussians	O
are	O
flat	O
in	O
the	O
tangent	O
directions	O
however	O
there	O
is	O
a	O
fundamental	O
difficulty	O
with	O
such	O
local	O
non-parametric	O
approaches	O
to	O
manifold	B
learning	I
raised	O
in	O
if	O
the	O
manifolds	O
are	O
not	O
very	O
smooth	O
have	O
many	O
peaks	O
and	O
troughs	O
and	O
twists	O
one	O
may	O
need	O
a	O
very	O
large	O
number	O
of	O
training	O
examples	O
to	O
cover	O
each	O
one	O
of	O
bengio	O
and	O
monperrus	O
chapter	O
autoencoders	O
figure	O
if	O
the	O
tangent	O
planes	O
figure	O
at	O
each	O
location	O
are	O
known	O
then	O
they	O
can	O
be	O
tiled	O
to	O
form	O
a	O
global	O
coordinate	O
system	O
or	O
a	O
density	O
function	O
each	O
local	O
patch	O
can	O
be	O
thought	O
of	O
as	O
a	O
local	O
euclidean	O
coordinate	O
system	O
or	O
as	O
a	O
locally	O
flat	O
gaussian	O
or	O
pancake	O
with	O
a	O
very	O
small	O
variance	O
in	O
the	O
directions	O
orthogonal	O
to	O
the	O
pancake	O
and	O
a	O
very	O
large	O
variance	O
in	O
the	O
directions	O
defining	O
the	O
coordinate	O
system	O
on	O
the	O
pancake	O
a	O
mixture	O
of	O
these	O
gaussians	O
provides	O
an	O
estimated	O
density	O
function	O
as	O
in	O
the	O
manifold	B
parzen	O
window	O
algorithm	O
or	O
its	O
non-local	O
neural-net	O
based	O
variant	O
bengio	O
et	O
al	O
vincent	O
and	O
bengio	O
these	O
variations	O
with	O
no	O
chance	O
to	O
generalize	O
to	O
unseen	O
variations	O
indeed	O
these	O
methods	O
can	O
only	O
generalize	O
the	O
shape	O
of	O
the	O
manifold	B
by	O
interpolating	O
between	O
neighboring	O
examples	O
unfortunately	O
the	O
manifolds	O
involved	O
in	O
ai	O
problems	O
can	O
have	O
very	O
complicated	O
structure	O
that	O
can	O
be	O
difficult	O
to	O
capture	O
from	O
only	O
local	O
interpolation	O
consider	O
for	O
example	B
the	O
manifold	B
resulting	O
from	O
translation	O
shown	O
in	O
figure	O
xi	O
as	O
the	O
image	O
is	O
translated	O
we	O
will	O
observe	O
that	O
one	O
coordinate	O
encounters	O
a	O
peak	O
or	O
a	O
trough	O
in	O
its	O
value	O
once	O
for	O
every	O
peak	O
or	O
trough	O
in	O
brightness	O
in	O
the	O
image	O
in	O
other	O
words	O
the	O
complexity	O
of	O
the	O
patterns	O
of	O
brightness	O
in	O
an	O
underlying	O
image	O
template	O
drives	O
the	O
complexity	O
of	O
the	O
manifolds	O
that	O
are	O
generated	O
by	O
performing	O
simple	O
image	O
transformations	O
this	O
motivates	O
the	O
use	O
of	O
distributed	O
representations	O
and	O
deep	O
learning	O
for	O
capturing	O
manifold	B
structure	O
if	O
we	O
watch	O
just	O
one	O
coordinate	O
within	O
the	O
input	O
vector	O
chapter	O
autoencoders	O
contractive	O
autoencoders	O
the	O
contractive	B
autoencoder	I
introduces	O
an	O
explicit	O
regularizer	B
on	O
the	O
code	O
h	O
fx	O
encouraging	O
the	O
derivatives	O
of	O
f	O
to	O
be	O
as	O
small	O
as	O
possible	O
rifai	O
et	O
al	O
b	O
h	O
f	O
x	O
f	O
the	O
penalty	O
is	O
the	O
squared	O
frobenius	B
norm	I
of	O
squared	O
elements	O
of	O
the	O
jacobian	O
matrix	O
of	O
partial	O
derivatives	O
associated	O
with	O
the	O
encoder	B
function	O
alain	O
and	O
bengio	O
there	O
is	O
a	O
connection	O
between	O
the	O
denoising	O
autoencoder	O
and	O
the	O
contractive	B
autoencoder	I
showed	O
that	O
in	O
the	O
limit	O
of	O
small	O
gaussian	O
input	O
noise	O
the	O
denoising	O
reconstruction	O
error	O
is	O
equivalent	O
to	O
a	O
contractive	O
penalty	O
on	O
the	O
reconstruction	O
function	O
that	O
maps	O
x	O
to	O
r	O
g	O
fx	O
in	O
other	O
words	O
denoising	O
autoencoders	O
make	O
the	O
reconstruction	O
function	O
resist	O
small	O
but	O
finite-sized	O
perturbations	O
of	O
the	O
input	O
while	O
contractive	O
autoencoders	O
make	O
the	O
feature	B
extraction	O
function	O
resist	O
infinitesimal	O
perturbations	O
of	O
the	O
input	O
when	O
using	O
the	O
jacobian-based	O
contractive	O
penalty	O
to	O
pretrain	O
features	O
fx	O
for	O
use	O
with	O
a	O
classifier	O
the	O
best	O
classification	B
accuracy	B
usually	O
results	O
from	O
applying	O
the	O
contractive	O
penalty	O
to	O
f	O
rather	O
than	O
to	O
gf	O
a	O
contractive	O
penalty	O
on	O
f	O
also	O
has	O
close	O
connections	O
to	O
score	O
matching	O
as	O
discussed	O
in	O
section	O
the	O
name	O
contractive	O
arises	O
from	O
the	O
way	O
that	O
the	O
cae	O
warps	O
space	O
specifically	O
because	O
the	O
cae	O
is	O
trained	O
to	O
resist	O
perturbations	O
of	O
its	O
input	O
it	O
is	O
encouraged	O
to	O
map	O
a	O
neighborhood	O
of	O
input	O
points	O
to	O
a	O
smaller	O
neighborhood	O
of	O
output	O
points	O
we	O
can	O
think	O
of	O
this	O
as	O
contracting	O
the	O
input	O
neighborhood	O
to	O
a	O
smaller	O
output	O
neighborhood	O
to	O
clarify	O
the	O
cae	O
is	O
contractive	O
only	O
locally	O
all	O
perturbations	O
of	O
a	O
training	O
point	O
x	O
are	O
mapped	O
near	O
to	O
f	O
x	O
globally	O
two	O
different	O
points	O
x	O
and	O
x	O
may	O
be	O
mapped	O
to	O
fx	O
and	O
fx	O
points	O
that	O
are	O
farther	O
apart	O
than	O
the	O
original	O
points	O
it	O
is	O
plausible	O
that	O
f	O
be	O
expanding	O
in-between	O
or	O
far	O
from	O
the	O
data	O
manifolds	O
for	O
example	B
what	O
happens	O
in	O
the	O
toy	O
example	B
of	O
figure	O
penalty	O
is	O
applied	O
to	O
sigmoidal	O
units	O
one	O
easy	O
way	O
to	O
shrink	O
the	O
jacobian	O
is	O
to	O
make	O
the	O
sigmoid	O
units	O
saturate	O
to	O
this	O
encourages	O
the	O
cae	O
to	O
encode	O
input	O
points	O
with	O
extreme	O
values	O
of	O
the	O
sigmoid	O
that	O
may	O
be	O
interpreted	O
as	O
a	O
binary	O
code	O
it	O
also	O
ensures	O
that	O
the	O
cae	O
will	O
spread	O
its	O
code	O
values	O
throughout	O
most	O
of	O
the	O
hypercube	O
that	O
its	O
sigmoidal	O
hidden	O
units	O
can	O
span	O
when	O
the	O
or	O
we	O
can	O
think	O
of	O
the	O
jacobian	O
matrix	O
j	O
at	O
a	O
point	O
x	O
as	O
approximating	O
the	O
nonlinear	O
encoder	B
f	O
as	O
being	O
a	O
linear	O
operator	O
this	O
allows	O
us	O
to	O
use	O
the	O
word	O
contractive	O
more	O
formally	O
in	O
the	O
theory	O
of	O
linear	O
operators	O
a	O
linear	O
operator	O
chapter	O
autoencoders	O
is	O
said	O
to	O
be	O
contractive	O
if	O
the	O
norm	O
of	O
j	O
x	O
remains	O
less	O
than	O
or	O
equal	O
to	O
for	O
all	O
unit-norm	O
x	O
in	O
other	O
words	O
j	O
is	O
contractive	O
if	O
it	O
shrinks	O
the	O
unit	O
sphere	O
we	O
can	O
think	O
of	O
the	O
cae	O
as	O
penalizing	O
the	O
frobenius	B
norm	I
of	O
the	O
local	O
linear	O
approximation	O
of	O
f	O
at	O
every	O
training	O
point	O
x	O
in	O
order	O
to	O
encourage	O
each	O
of	O
these	O
local	O
linear	O
operator	O
to	O
become	O
a	O
contraction	O
as	O
described	O
in	O
section	O
regularized	O
autoencoders	O
learn	O
manifolds	O
by	O
in	O
the	O
case	O
of	O
the	O
cae	O
these	O
two	O
forces	O
are	O
balancing	O
two	O
opposing	O
forces	O
reconstruction	O
error	O
and	O
the	O
contractive	O
penalty	O
reconstruction	O
error	O
alone	O
would	O
encourage	O
the	O
cae	O
to	O
learn	O
an	O
identity	O
function	O
the	O
contractive	O
penalty	O
alone	O
would	O
encourage	O
the	O
cae	O
to	O
learn	O
features	O
that	O
are	O
constant	O
with	O
respect	O
to	O
x	O
the	O
compromise	O
between	O
these	O
two	O
forces	O
yields	O
an	O
autoencoder	O
whose	O
derivatives	O
f	O
are	O
mostly	O
tiny	O
only	O
a	O
small	O
number	O
of	O
hidden	O
units	O
corresponding	O
to	O
a	O
small	O
number	O
of	O
directions	O
in	O
the	O
input	O
may	O
have	O
significant	O
derivatives	O
x	O
rifai	O
et	O
al	O
the	O
goal	O
of	O
the	O
cae	O
is	O
to	O
learn	O
the	O
manifold	B
structure	O
of	O
the	O
data	O
directions	O
x	O
with	O
large	O
j	O
x	O
rapidly	O
change	O
h	O
so	O
these	O
are	O
likely	O
to	O
be	O
directions	O
which	O
approximate	O
the	O
tangent	O
planes	O
of	O
the	O
manifold	B
experiments	O
by	O
rifai	O
et	O
al	O
and	O
show	O
that	O
training	O
the	O
cae	O
results	O
in	O
most	O
singular	O
values	O
of	O
j	O
dropping	O
below	O
in	O
magnitude	O
and	O
therefore	O
becoming	O
contractive	O
however	O
some	O
singular	O
values	O
remain	O
above	O
because	O
the	O
reconstruction	O
error	O
penalty	O
encourages	O
the	O
cae	O
to	O
encode	O
the	O
directions	O
with	O
the	O
most	O
local	O
variance	O
the	O
directions	O
corresponding	O
to	O
the	O
largest	O
singular	O
values	O
are	O
interpreted	O
as	O
the	O
tangent	O
directions	O
that	O
the	O
contractive	B
autoencoder	I
has	O
learned	O
ideally	O
these	O
tangent	O
directions	O
should	O
correspond	O
to	O
real	O
variations	O
in	O
the	O
data	O
for	O
example	B
a	O
cae	O
applied	O
to	O
images	O
should	O
learn	O
tangent	O
vectors	O
that	O
show	O
how	O
the	O
image	O
changes	O
as	O
objects	O
in	O
the	O
image	O
gradually	O
change	O
pose	O
as	O
shown	O
in	O
figure	O
visualizations	O
of	O
the	O
experimentally	O
obtained	O
singular	O
vectors	O
do	O
seem	O
to	O
correspond	O
to	O
meaningful	O
transformations	O
of	O
the	O
input	O
image	O
as	O
shown	O
in	O
figure	O
et	O
al	O
one	O
practical	O
issue	O
with	O
the	O
cae	O
regularization	O
criterion	O
is	O
that	O
although	O
it	O
is	O
cheap	O
to	O
compute	O
in	O
the	O
case	O
of	O
a	O
single	O
hidden	B
layer	I
autoencoder	O
it	O
becomes	O
much	O
more	O
expensive	O
in	O
the	O
case	O
of	O
deeper	O
autoencoders	O
the	O
strategy	O
followed	O
by	O
rifai	O
is	O
to	O
separately	O
train	O
a	O
series	O
of	O
single-layer	O
autoencoders	O
each	O
trained	O
to	O
reconstruct	O
the	O
previous	O
autoencoder	O
s	O
hidden	B
layer	I
the	O
composition	O
of	O
these	O
autoencoders	O
then	O
forms	O
a	O
deep	O
autoencoder	O
because	O
each	O
layer	O
was	O
separately	O
trained	O
to	O
be	O
locally	O
contractive	O
the	O
deep	O
autoencoder	O
is	O
contractive	O
as	O
well	O
the	O
result	O
is	O
not	O
the	O
same	O
as	O
what	O
would	O
be	O
obtained	O
by	O
jointly	O
training	O
the	O
entire	O
architecture	O
with	O
a	O
penalty	O
on	O
the	O
jacobian	O
of	O
the	O
deep	O
model	O
but	O
it	O
captures	O
many	O
of	O
the	O
desirable	O
qualitative	O
characteristics	O
another	O
practical	O
issue	O
is	O
that	O
the	O
contraction	O
penalty	O
can	O
obtain	O
useless	O
results	O
chapter	O
autoencoders	O
input	O
point	O
tangent	O
vectors	O
local	O
pca	O
sharing	O
across	O
regions	O
contractive	B
autoencoder	I
figure	O
illustration	O
of	O
tangent	O
vectors	O
of	O
the	O
manifold	B
estimated	O
by	O
local	O
pca	O
and	O
by	O
a	O
contractive	B
autoencoder	I
the	O
location	O
on	O
the	O
manifold	B
is	O
defined	O
by	O
the	O
input	O
image	O
of	O
a	O
dog	O
drawn	O
from	O
the	O
dataset	B
the	O
tangent	O
vectors	O
are	O
estimated	O
by	O
the	O
leading	O
singular	O
vectors	O
of	O
the	O
jacobian	O
matrix	O
h	O
of	O
the	O
input-to-code	O
mapping	O
x	O
although	O
both	O
local	O
pca	O
and	O
the	O
cae	O
can	O
capture	O
local	O
tangents	O
the	O
cae	O
is	O
able	O
to	O
form	O
more	O
accurate	O
estimates	O
from	O
limited	O
training	O
data	O
because	O
it	O
exploits	O
parameter	O
sharing	O
across	O
different	O
locations	O
that	O
share	O
a	O
subset	O
of	O
active	O
hidden	O
units	O
the	O
cae	O
tangent	O
directions	O
typically	O
correspond	O
to	O
moving	O
or	O
changing	O
parts	O
of	O
the	O
object	O
as	O
the	O
head	O
or	O
legs	O
images	O
reproduced	O
with	O
permission	O
from	O
rifai	O
et	O
al	O
if	O
we	O
do	O
not	O
impose	O
some	O
sort	O
of	O
scale	O
on	O
the	O
decoder	B
for	O
example	B
the	O
encoder	B
could	O
consist	O
of	O
multiplying	O
the	O
input	O
by	O
a	O
small	O
constant	O
and	O
the	O
decoder	B
could	O
consist	O
of	O
dividing	O
the	O
code	O
by	O
as	O
approaches	O
the	O
encoder	B
drives	O
the	O
contractive	O
penalty	O
to	O
approach	O
without	O
having	O
learned	O
anything	O
about	O
the	O
distribution	O
meanwhile	O
the	O
decoder	B
maintains	O
perfect	O
reconstruction	O
in	O
rifai	O
et	O
al	O
f	O
and	O
g	O
both	O
f	O
and	O
g	O
are	O
standard	O
neural	B
network	I
layers	O
consisting	O
of	O
an	O
affine	B
transformation	O
followed	O
by	O
an	O
element-wise	O
nonlinearity	O
so	O
it	O
is	O
straightforward	O
to	O
set	O
the	O
weight	O
matrix	O
of	O
g	O
to	O
be	O
the	O
transpose	O
of	O
the	O
weight	O
matrix	O
of	O
this	O
is	O
prevented	O
by	O
tying	O
the	O
weights	B
of	O
predictive	B
sparse	I
decomposition	I
predictive	B
sparse	I
decomposition	I
is	O
a	O
model	O
that	O
is	O
a	O
hybrid	O
of	O
sparse	O
coding	O
and	O
parametric	O
autoencoders	O
a	O
parametric	O
encoder	B
is	O
trained	O
to	O
predict	O
the	O
output	O
of	O
iterative	O
inference	O
psd	O
has	O
been	O
applied	O
to	O
unsupervised	O
feature	B
learning	O
for	O
object	B
recognition	I
in	O
images	O
and	O
video	O
as	O
well	O
f	O
and	O
a	O
as	O
for	O
audio	O
decoder	B
gh	O
that	O
are	O
both	O
parametric	O
during	O
training	O
h	O
is	O
controlled	O
by	O
the	O
et	O
al	O
henaff	O
et	O
al	O
the	O
model	O
consists	O
of	O
an	O
encoder	B
jarrett	O
farabet	O
et	O
al	O
et	O
al	O
et	O
al	O
chapter	O
autoencoders	O
optimization	O
algorithm	O
training	O
proceeds	O
by	O
minimizing	O
x	O
x	O
g	O
h	O
h	O
f	O
like	O
in	O
sparse	O
coding	O
the	O
training	O
algorithm	O
alternates	O
between	O
minimization	O
with	O
respect	O
to	O
h	O
and	O
minimization	O
with	O
respect	O
to	O
the	O
model	O
parameters	O
minimization	O
with	O
respect	O
to	O
h	O
is	O
fast	O
because	O
fx	O
provides	O
a	O
good	O
initial	O
value	O
of	O
h	O
and	O
the	O
cost	O
function	O
constrains	O
h	O
to	O
remain	O
near	O
f	O
anyway	O
simple	O
gradient	B
descent	O
can	O
obtain	O
reasonable	O
values	O
of	O
in	O
as	O
few	O
as	O
ten	O
steps	O
h	O
the	O
training	O
procedure	O
used	O
by	O
psd	O
is	O
different	O
from	O
first	O
training	O
a	O
sparse	O
coding	O
model	O
and	O
then	O
training	O
fx	O
to	O
predict	O
the	O
values	O
of	O
the	O
sparse	O
coding	O
features	O
the	O
psd	O
training	O
procedure	O
regularizes	O
the	O
decoder	B
to	O
use	O
parameters	O
for	O
which	O
can	O
infer	O
good	O
code	O
values	O
f	O
this	O
topic	O
is	O
developed	O
further	O
the	O
tools	O
presented	O
in	O
chapter	O
predictive	O
sparse	O
coding	O
is	O
an	O
example	B
of	O
learned	O
approximate	B
inference	I
in	O
section	O
make	O
it	O
clear	O
that	O
psd	O
can	O
be	O
interpreted	O
as	O
training	O
a	O
directed	O
sparse	O
coding	O
probabilistic	O
model	O
by	O
maximizing	O
a	O
lower	O
bound	B
on	O
the	O
log-likelihood	O
of	O
the	O
model	O
in	O
practical	O
applications	O
of	O
psd	O
the	O
iterative	O
optimization	O
is	O
only	O
used	O
during	O
training	O
the	O
parametric	O
encoder	B
f	O
is	O
used	O
to	O
compute	O
the	O
learned	O
features	O
when	O
the	O
model	O
is	O
deployed	O
evaluating	O
f	O
is	O
computationally	O
inexpensive	O
compared	O
to	O
inferring	O
h	O
via	O
gradient	B
descent	O
because	O
f	O
is	O
a	O
differentiable	O
parametric	O
function	O
psd	O
models	O
may	O
be	O
stacked	O
and	O
used	O
to	O
initialize	O
a	O
deep	O
network	O
to	O
be	O
trained	O
with	O
another	O
criterion	O
applications	O
of	O
autoencoders	O
autoencoders	O
have	O
been	O
successfully	O
applied	O
to	O
dimensionality	O
reduction	O
and	O
information	B
retrieval	I
tasks	O
dimensionality	O
reduction	O
was	O
one	O
of	O
the	O
first	O
applications	O
of	O
representation	B
learning	I
and	O
deep	O
learning	O
it	O
was	O
one	O
of	O
the	O
early	O
motivations	O
for	O
studying	O
autoencoders	O
for	O
example	B
hinton	O
and	O
salakhutdinov	O
trained	O
a	O
stack	O
of	O
rbms	O
and	O
then	O
used	O
their	O
weights	B
to	O
initialize	O
a	O
deep	O
autoencoder	O
with	O
gradually	O
smaller	O
hidden	O
layers	O
culminating	O
in	O
a	O
bottleneck	O
of	O
units	O
the	O
resulting	O
code	O
yielded	O
less	O
reconstruction	O
error	O
than	O
pca	O
into	O
dimensions	O
and	O
the	O
learned	O
representation	O
was	O
qualitatively	O
easier	O
to	O
interpret	O
and	O
relate	O
to	O
the	O
underlying	O
categories	O
with	O
these	O
categories	O
manifesting	O
as	O
well-separated	O
clusters	O
lower-dimensional	O
representations	O
can	O
improve	O
performance	O
on	O
many	O
tasks	O
such	O
as	O
classification	B
models	O
of	O
smaller	O
spaces	O
consume	O
less	O
memory	O
and	O
runtime	O
chapter	O
autoencoders	O
many	O
forms	O
of	O
dimensionality	O
reduction	O
place	O
semantically	O
related	O
examples	O
near	O
each	O
other	O
as	O
observed	O
by	O
salakhutdinov	O
and	O
hinton	O
et	O
al	O
the	O
hints	O
provided	O
by	O
the	O
mapping	O
to	O
the	O
lower-dimensional	O
space	O
aid	O
generalization	B
torralba	O
and	O
one	O
task	O
that	O
benefits	O
even	O
more	O
than	O
usual	O
from	O
dimensionality	O
reduction	O
is	O
information	B
retrieval	I
the	O
task	O
of	O
finding	O
entries	O
in	O
a	O
database	O
that	O
resemble	O
a	O
query	O
entry	O
this	O
task	O
derives	O
the	O
usual	O
benefits	O
from	O
dimensionality	O
reduction	O
that	O
other	O
tasks	O
do	O
but	O
also	O
derives	O
the	O
additional	O
benefit	O
that	O
search	O
can	O
become	O
extremely	O
efficient	O
in	O
certain	O
kinds	O
of	O
low	O
dimensional	O
spaces	O
specifically	O
if	O
we	O
train	O
the	O
dimensionality	O
reduction	O
algorithm	O
to	O
produce	O
a	O
code	O
that	O
is	O
lowdimensional	O
and	O
then	O
we	O
can	O
store	O
all	O
database	O
entries	O
in	O
a	O
hash	O
table	O
mapping	O
binary	O
code	O
vectors	O
to	O
entries	O
this	O
hash	O
table	O
allows	O
us	O
to	O
perform	O
information	B
retrieval	I
by	O
returning	O
all	O
database	O
entries	O
that	O
have	O
the	O
same	O
binary	O
code	O
as	O
the	O
query	O
we	O
can	O
also	O
search	O
over	O
slightly	O
less	O
similar	O
entries	O
very	O
efficiently	O
just	O
by	O
flipping	O
individual	O
bits	O
from	O
the	O
encoding	O
of	O
the	O
query	O
this	O
approach	O
to	O
information	B
retrieval	I
via	O
dimensionality	O
reduction	O
and	O
binarization	O
is	O
called	O
semantic	B
hashing	I
and	O
hinton	O
and	O
has	O
been	O
applied	O
to	O
both	O
textual	O
input	O
and	O
hinton	O
and	O
images	O
krizhevsky	O
and	O
hinton	O
weiss	O
binary	O
et	O
al	O
et	O
al	O
to	O
produce	O
binary	O
codes	O
for	O
semantic	B
hashing	I
one	O
typically	O
uses	O
an	O
encoding	O
function	O
with	O
sigmoids	O
on	O
the	O
final	O
layer	O
the	O
sigmoid	O
units	O
must	O
be	O
trained	O
to	O
be	O
saturated	O
to	O
nearly	O
or	O
nearly	O
for	O
all	O
input	O
values	O
one	O
trick	B
that	O
can	O
accomplish	O
this	O
is	O
simply	O
to	O
inject	O
additive	O
noise	O
just	O
before	O
the	O
sigmoid	O
nonlinearity	O
during	O
training	O
the	O
magnitude	O
of	O
the	O
noise	O
should	O
increase	O
over	O
time	O
to	O
fight	O
that	O
noise	O
and	O
preserve	O
as	O
much	O
information	O
as	O
possible	O
the	O
network	O
must	O
increase	O
the	O
magnitude	O
of	O
the	O
inputs	O
to	O
the	O
sigmoid	O
function	O
until	O
saturation	O
occurs	O
the	O
idea	O
of	O
learning	O
a	O
hashing	O
function	O
has	O
been	O
further	O
explored	O
in	O
several	O
directions	O
including	O
the	O
idea	O
of	O
training	O
the	O
representations	O
so	O
as	O
to	O
optimize	O
a	O
loss	O
more	O
directly	O
linked	O
to	O
the	O
task	O
of	O
finding	O
nearby	O
examples	O
in	O
the	O
hash	O
table	O
norouzi	O
and	O
fleet	O
chapter	O
representation	B
learning	I
in	O
this	O
chapter	O
we	O
first	O
discuss	O
what	O
it	O
means	O
to	O
learn	O
representations	O
and	O
how	O
the	O
notion	O
of	O
representation	O
can	O
be	O
useful	O
to	O
design	O
deep	O
architectures	O
we	O
discuss	O
how	O
learning	O
algorithms	O
share	O
statistical	O
strength	O
across	O
different	O
tasks	O
including	O
using	O
information	O
from	O
unsupervised	O
tasks	O
to	O
perform	O
supervised	O
tasks	O
shared	O
representations	O
are	O
useful	O
to	O
handle	O
multiple	O
modalities	O
or	O
domains	O
or	O
to	O
transfer	O
learned	O
knowledge	O
to	O
tasks	O
for	O
which	O
few	O
or	O
no	O
examples	O
are	O
given	O
but	O
a	O
task	O
representation	O
exists	O
finally	O
we	O
step	O
back	O
and	O
argue	O
about	O
the	O
reasons	O
for	O
the	O
success	O
of	O
representation	B
learning	I
starting	O
with	O
the	O
theoretical	O
advantages	O
of	O
distributed	O
representations	O
and	O
deep	O
representations	O
and	O
ending	O
with	O
the	O
more	O
general	O
idea	O
of	O
underlying	O
assumptions	O
about	O
the	O
data	B
generating	I
process	I
in	O
particular	O
about	O
underlying	O
causes	O
of	O
the	O
observed	O
data	O
et	O
al	O
many	O
information	O
processing	O
tasks	O
can	O
be	O
very	O
easy	O
or	O
very	O
difficult	O
depending	O
on	O
how	O
the	O
information	O
is	O
represented	O
this	O
is	O
a	O
general	O
principle	O
applicable	O
to	O
daily	O
life	O
computer	O
science	O
in	O
general	O
and	O
to	O
machine	B
learning	I
for	O
example	B
it	O
is	O
straightforward	O
for	O
a	O
person	O
to	O
divide	O
by	O
using	O
long	O
division	O
the	O
task	O
becomes	O
considerably	O
less	O
straightforward	O
if	O
it	O
is	O
instead	O
posed	O
using	O
the	O
roman	O
numeral	O
representation	O
of	O
the	O
numbers	O
most	O
modern	O
people	O
asked	O
to	O
divide	O
ccx	O
by	O
vi	O
would	O
begin	O
by	O
converting	O
the	O
numbers	O
to	O
the	O
arabic	O
numeral	O
representation	O
permitting	O
long	O
division	O
procedures	O
that	O
make	O
use	O
of	O
the	O
place	O
value	O
system	O
more	O
concretely	O
we	O
can	O
quantify	O
the	O
asymptotic	O
runtime	O
of	O
various	O
operations	O
using	O
appropriate	O
or	O
inappropriate	O
representations	O
for	O
example	B
inserting	O
a	O
number	O
into	O
the	O
correct	O
position	O
in	O
a	O
sorted	O
list	O
of	O
numbers	O
is	O
an	O
on	O
operation	B
if	O
the	O
list	O
is	O
represented	O
as	O
a	O
linked	O
list	O
but	O
only	O
olog	O
n	O
if	O
the	O
list	O
is	O
represented	O
as	O
a	O
red-black	O
tree	O
in	O
the	O
context	O
of	O
machine	B
learning	I
what	O
makes	O
one	O
representation	O
better	O
than	O
chapter	O
representation	B
learning	I
another	O
generally	O
speaking	O
a	O
good	O
representation	O
is	O
one	O
that	O
makes	O
a	O
subsequent	O
learning	O
task	O
easier	O
the	O
choice	O
of	O
representation	O
will	O
usually	O
depend	O
on	O
the	O
choice	O
of	O
the	O
subsequent	O
learning	O
task	O
we	O
can	O
think	O
of	O
feedforward	O
networks	O
trained	O
by	O
supervised	B
learning	I
as	O
performing	O
a	O
kind	O
of	O
representation	B
learning	I
specifically	O
the	O
last	O
layer	O
of	O
the	O
network	O
is	O
typically	O
a	O
linear	O
classifier	O
such	O
as	O
a	O
softmax	O
regression	B
classifier	O
the	O
rest	O
of	O
the	O
network	O
learns	O
to	O
provide	O
a	O
representation	O
to	O
this	O
classifier	O
training	O
with	O
a	O
supervised	O
criterion	O
naturally	O
leads	O
to	O
the	O
representation	O
at	O
every	O
hidden	B
layer	I
more	O
so	O
near	O
the	O
top	O
hidden	B
layer	I
taking	O
on	O
properties	O
that	O
make	O
the	O
classification	B
task	O
easier	O
for	O
example	B
classes	O
that	O
were	O
not	O
linearly	O
separable	O
in	O
the	O
input	O
features	O
may	O
become	O
linearly	O
separable	O
in	O
the	O
last	O
hidden	B
layer	I
in	O
principle	O
the	O
last	O
layer	O
could	O
be	O
another	O
kind	O
of	O
model	O
such	O
as	O
a	O
nearest	O
neighbor	O
classifier	O
and	O
hinton	O
the	O
features	O
in	O
the	O
penultimate	O
layer	O
should	O
learn	O
different	O
properties	O
depending	O
on	O
the	O
type	O
of	O
the	O
last	O
layer	O
supervised	O
training	O
of	O
feedforward	O
networks	O
does	O
not	O
involve	O
explicitly	O
imposing	O
any	O
condition	O
on	O
the	O
learned	O
intermediate	O
features	O
other	O
kinds	O
of	O
representation	B
learning	I
algorithms	O
are	O
often	O
explicitly	O
designed	O
to	O
shape	O
the	O
representation	O
in	O
some	O
particular	O
way	O
for	O
example	B
suppose	O
we	O
want	O
to	O
learn	O
a	O
representation	O
that	O
makes	O
density	B
estimation	I
easier	O
distributions	O
with	O
more	O
independences	O
are	O
easier	O
to	O
model	O
so	O
we	O
could	O
design	O
an	O
objective	B
function	I
that	O
encourages	O
the	O
elements	O
of	O
the	O
representation	O
vector	O
h	O
to	O
be	O
independent	O
just	O
like	O
supervised	O
networks	O
unsupervised	O
deep	O
learning	O
algorithms	O
have	O
a	O
main	O
training	O
objective	O
but	O
also	O
learn	O
a	O
representation	O
as	O
a	O
side	O
effect	O
regardless	O
of	O
how	O
a	O
representation	O
was	O
obtained	O
it	O
can	O
be	O
used	O
for	O
another	O
task	O
alternatively	O
multiple	O
tasks	O
supervised	O
some	O
unsupervised	O
can	O
be	O
learned	O
together	O
with	O
some	O
shared	O
internal	O
representation	O
most	O
representation	B
learning	I
problems	O
face	O
a	O
tradeoff	O
between	O
preserving	O
as	O
much	O
information	O
about	O
the	O
input	O
as	O
possible	O
and	O
attaining	O
nice	O
properties	O
as	O
independence	O
representation	B
learning	I
is	O
particularly	O
interesting	O
because	O
it	O
provides	O
one	O
way	O
to	O
perform	O
unsupervised	O
and	O
semi-supervised	B
learning	I
we	O
often	O
have	O
very	O
large	O
amounts	O
of	O
unlabeled	O
training	O
data	O
and	O
relatively	O
little	O
labeled	O
training	O
data	O
training	O
with	O
supervised	B
learning	I
techniques	O
on	O
the	O
labeled	O
subset	O
often	O
results	O
in	O
severe	O
overfitting	O
semi-supervised	B
learning	I
offers	O
the	O
chance	O
to	O
resolve	O
this	O
overfitting	O
problem	O
by	O
also	O
learning	O
from	O
the	O
unlabeled	O
data	O
specifically	O
we	O
can	O
learn	O
good	O
representations	O
for	O
the	O
unlabeled	O
data	O
and	O
then	O
use	O
these	O
representations	O
to	O
solve	O
the	O
supervised	B
learning	I
task	O
humans	O
and	O
animals	O
are	O
able	O
to	O
learn	O
from	O
very	O
few	O
labeled	O
examples	O
we	O
do	O
chapter	O
representation	B
learning	I
not	O
yet	O
know	O
how	O
this	O
is	O
possible	O
many	O
factors	O
could	O
explain	O
improved	O
human	O
performance	O
for	O
example	B
the	O
brain	O
may	O
use	O
very	O
large	O
ensembles	O
of	O
classifiers	O
or	O
bayesian	O
inference	O
techniques	O
one	O
popular	O
hypothesis	O
is	O
that	O
the	O
brain	O
is	O
able	O
to	O
leverage	O
unsupervised	O
or	O
semi-supervised	B
learning	I
there	O
are	O
many	O
ways	O
to	O
leverage	O
unlabeled	O
data	O
in	O
this	O
chapter	O
we	O
focus	O
on	O
the	O
hypothesis	O
that	O
the	O
unlabeled	O
data	O
can	O
be	O
used	O
to	O
learn	O
a	O
good	O
representation	O
greedy	O
layer-wise	O
unsupervised	B
pretraining	I
unsupervised	O
learning	O
played	O
a	O
key	O
historical	O
role	O
in	O
the	O
revival	O
of	O
deep	O
neural	O
networks	O
enabling	O
researchers	O
for	O
the	O
first	O
time	O
to	O
train	O
a	O
deep	O
supervised	O
network	O
without	O
requiring	O
architectural	O
specializations	O
like	O
convolution	O
or	O
recurrence	O
we	O
call	O
this	O
procedure	O
unsupervised	B
pretraining	I
or	O
more	O
precisely	O
greedy	O
layerwise	O
unsupervised	B
pretraining	I
this	O
procedure	O
is	O
a	O
canonical	O
example	B
of	O
how	O
a	O
representation	O
learned	O
for	O
one	O
task	O
learning	O
trying	O
to	O
capture	O
the	O
shape	O
of	O
the	O
input	O
distribution	O
can	O
sometimes	O
be	O
useful	O
for	O
another	O
task	O
learning	O
with	O
the	O
same	O
input	O
domain	O
greedy	O
layer-wise	O
unsupervised	B
pretraining	I
relies	O
on	O
a	O
single-layer	O
representation	B
learning	I
algorithm	O
such	O
as	O
an	O
rbm	O
a	O
single-layer	O
autoencoder	O
a	O
sparse	O
coding	O
model	O
or	O
another	O
model	O
that	O
learns	O
latent	O
representations	O
each	O
layer	O
is	O
pretrained	O
using	O
unsupervised	O
learning	O
taking	O
the	O
output	O
of	O
the	O
previous	O
layer	O
and	O
producing	O
as	O
output	O
a	O
new	O
representation	O
of	O
the	O
data	O
whose	O
distribution	O
its	O
relation	O
to	O
other	O
variables	O
such	O
as	O
categories	O
to	O
predict	O
is	O
hopefully	O
simpler	O
see	O
algorithm	O
for	O
a	O
formal	O
description	O
greedy	O
layer-wise	O
training	O
procedures	O
based	O
on	O
unsupervised	O
criteria	O
have	O
long	O
been	O
used	O
to	O
sidestep	O
the	O
difficulty	O
of	O
jointly	O
training	O
the	O
layers	O
of	O
a	O
deep	O
neural	O
net	O
for	O
a	O
supervised	O
task	O
this	O
approach	O
dates	O
back	O
at	O
least	O
as	O
far	O
as	O
the	O
neocognitron	O
the	O
deep	O
learning	O
renaissance	O
of	O
began	O
with	O
the	O
discovery	O
that	O
this	O
greedy	O
learning	O
procedure	O
could	O
be	O
used	O
to	O
find	O
a	O
good	O
initialization	B
for	O
a	O
joint	O
learning	O
procedure	O
over	O
all	O
the	O
layers	O
and	O
that	O
this	O
approach	O
could	O
be	O
used	O
to	O
successfully	O
train	O
even	O
fully	O
connected	O
architectures	O
hinton	O
and	O
salakhutdinov	O
hinton	O
bengio	O
et	O
al	O
prior	O
to	O
this	O
discovery	O
only	O
convolutional	O
deep	O
networks	O
or	O
networks	O
whose	O
depth	O
resulted	O
from	O
recurrence	O
were	O
regarded	O
as	O
feasible	O
to	O
train	O
today	O
we	O
now	O
know	O
that	O
greedy	O
layer-wise	O
pretraining	O
is	O
not	O
required	O
to	O
train	O
fully	O
connected	O
deep	O
architectures	O
but	O
the	O
unsupervised	B
pretraining	I
approach	O
was	O
the	O
first	O
method	O
to	O
succeed	O
et	O
al	O
ranzato	O
et	O
al	O
greedy	O
layer-wise	O
pretraining	O
is	O
called	O
greedy	O
because	O
it	O
is	O
a	O
greedy	O
algo	O
chapter	O
representation	B
learning	I
rithm	O
meaning	O
that	O
it	O
optimizes	O
each	O
piece	O
of	O
the	O
solution	O
independently	O
one	O
piece	O
at	O
a	O
time	O
rather	O
than	O
jointly	O
optimizing	O
all	O
pieces	O
it	O
is	O
called	O
layer-wise	O
because	O
these	O
independent	O
pieces	O
are	O
the	O
layers	O
of	O
the	O
network	O
specifically	O
greedy	O
layer-wise	O
pretraining	O
proceeds	O
one	O
layer	O
at	O
a	O
time	O
training	O
the	O
k-th	O
layer	O
while	O
keeping	O
the	O
previous	O
ones	O
fixed	O
in	O
particular	O
the	O
lower	O
layers	O
are	O
trained	O
first	O
are	O
not	O
adapted	O
after	O
the	O
upper	O
layers	O
are	O
introduced	O
it	O
is	O
called	O
unsupervised	O
because	O
each	O
layer	O
is	O
trained	O
with	O
an	O
unsupervised	O
representation	B
learning	I
algorithm	O
however	O
it	O
is	O
also	O
called	O
pretraining	O
because	O
it	O
is	O
supposed	O
to	O
be	O
only	O
a	O
first	O
step	O
before	O
a	O
joint	O
training	O
algorithm	O
is	O
applied	O
to	O
fine-tune	O
all	O
the	O
layers	O
together	O
in	O
the	O
context	O
of	O
a	O
supervised	B
learning	I
task	O
it	O
can	O
be	O
viewed	O
as	O
a	O
regularizer	B
some	O
experiments	O
pretraining	O
decreases	O
test	O
error	O
without	O
decreasing	O
training	B
error	I
and	O
a	O
form	O
of	O
parameter	O
initialization	B
it	O
is	O
common	O
to	O
use	O
the	O
word	O
pretraining	O
to	O
refer	O
not	O
only	O
to	O
the	O
pretraining	O
stage	O
itself	O
but	O
to	O
the	O
entire	O
two	O
phase	O
protocol	O
that	O
combines	O
the	O
pretraining	O
phase	O
and	O
a	O
supervised	B
learning	I
phase	O
the	O
supervised	B
learning	I
phase	O
may	O
involve	O
training	O
a	O
simple	O
classifier	O
on	O
top	O
of	O
the	O
features	O
learned	O
in	O
the	O
pretraining	O
phase	O
or	O
it	O
may	O
involve	O
supervised	O
fine-tuning	B
of	O
the	O
entire	O
network	O
learned	O
in	O
the	O
pretraining	O
phase	O
no	O
matter	O
what	O
kind	O
of	O
unsupervised	O
learning	O
algorithm	O
or	O
what	O
model	O
type	O
is	O
employed	O
in	O
the	O
vast	O
majority	O
of	O
cases	O
the	O
overall	O
training	O
scheme	O
is	O
nearly	O
the	O
same	O
while	O
the	O
choice	O
of	O
unsupervised	O
learning	O
algorithm	O
will	O
obviously	O
impact	O
the	O
details	O
most	O
applications	O
of	O
unsupervised	B
pretraining	I
follow	O
this	O
basic	O
protocol	O
greedy	O
layer-wise	O
unsupervised	B
pretraining	I
can	O
also	O
be	O
used	O
as	O
initialization	B
for	O
other	O
unsupervised	O
learning	O
algorithms	O
such	O
as	O
deep	O
autoencoders	O
and	O
probabilistic	O
models	O
with	O
many	O
layers	O
of	O
latent	O
and	O
salakhutdinov	O
variables	O
such	O
models	O
include	O
deep	O
belief	O
networks	O
and	O
deep	O
boltzmann	O
machines	O
and	O
hinton	O
these	O
deep	O
generative	O
models	O
will	O
be	O
described	O
in	O
chapter	O
hinton	O
et	O
al	O
as	O
discussed	O
in	O
section	O
it	O
is	O
also	O
possible	O
to	O
have	O
greedy	O
layer-wise	O
supervised	O
pretraining	O
this	O
builds	O
on	O
the	O
premise	O
that	O
training	O
a	O
shallow	O
network	O
is	O
easier	O
than	O
training	O
a	O
deep	O
one	O
which	O
seems	O
to	O
have	O
been	O
validated	O
in	O
several	O
contexts	O
erhan	O
et	O
al	O
when	O
and	O
why	O
does	O
unsupervised	B
pretraining	I
work	O
on	O
many	O
tasks	O
greedy	O
layer-wise	O
unsupervised	B
pretraining	I
can	O
yield	O
substantial	O
improvements	O
in	O
test	O
error	O
for	O
classification	B
tasks	O
this	O
observation	O
was	O
responsible	O
for	O
the	O
renewed	O
interested	O
in	O
deep	O
neural	O
networks	O
starting	O
in	O
et	O
al	O
chapter	O
representation	B
learning	I
l	O
algorithm	O
greedy	O
layer-wise	O
unsupervised	B
pretraining	I
protocol	O
given	O
the	O
following	O
unsupervised	O
feature	B
learning	O
algorithm	O
which	O
takes	O
a	O
training	O
set	O
of	O
examples	O
and	O
returns	O
an	O
encoder	B
or	O
feature	B
function	O
f	O
the	O
raw	O
input	O
data	O
is	O
x	O
with	O
one	O
row	O
per	O
example	B
and	O
f	O
is	O
the	O
output	O
of	O
the	O
first	O
t	O
stage	O
encoder	B
on	O
x	O
in	O
the	O
case	O
where	O
fine-tuning	B
is	O
performed	O
we	O
use	O
a	O
learner	O
which	O
takes	O
an	O
initial	O
function	O
f	O
input	O
examples	O
x	O
in	O
the	O
supervised	O
fine-tuning	B
case	O
associated	O
targets	O
y	O
and	O
returns	O
a	O
tuned	O
function	O
the	O
number	O
of	O
stages	O
is	O
identity	O
function	O
f	O
x	O
x	O
for	O
do	O
m	O
l	O
x	O
k	O
f	O
f	O
f	O
x	O
f	O
x	O
f	O
end	O
for	O
t	O
if	O
fine-tuning	B
then	O
f	O
x	O
y	O
f	O
end	O
if	O
return	O
f	O
et	O
al	O
et	O
al	O
ranzato	O
ma	O
et	O
al	O
bengio	O
on	O
many	O
other	O
tasks	O
however	O
unsupervised	B
pretraining	I
either	O
does	O
not	O
confer	O
a	O
benefit	O
or	O
even	O
causes	O
noticeable	O
harm	O
studied	O
the	O
effect	O
of	O
pretraining	O
on	O
machine	B
learning	I
models	O
for	O
chemical	O
activity	O
prediction	O
and	O
found	O
that	O
on	O
average	O
pretraining	O
was	O
slightly	O
harmful	O
but	O
for	O
many	O
tasks	O
was	O
significantly	O
helpful	O
because	O
unsupervised	B
pretraining	I
is	O
sometimes	O
helpful	O
but	O
often	O
harmful	O
it	O
is	O
important	O
to	O
understand	O
when	O
and	O
why	O
it	O
works	O
in	O
order	O
to	O
determine	O
whether	O
it	O
is	O
applicable	O
to	O
a	O
particular	O
task	O
at	O
the	O
outset	O
it	O
is	O
important	O
to	O
clarify	O
that	O
most	O
of	O
this	O
discussion	O
is	O
restricted	O
to	O
greedy	O
unsupervised	B
pretraining	I
in	O
particular	O
there	O
are	O
other	O
completely	O
different	O
paradigms	O
for	O
performing	O
semi-supervised	B
learning	I
with	O
neural	O
networks	O
such	O
as	O
virtual	O
adversarial	O
training	O
described	O
in	O
section	O
it	O
is	O
also	O
possible	O
to	O
train	O
an	O
autoencoder	O
or	O
generative	O
model	O
at	O
the	O
same	O
time	O
as	O
the	O
supervised	O
model	O
examples	O
of	O
this	O
single-stage	O
approach	O
include	O
the	O
discriminative	B
rbm	I
and	O
bengio	O
in	O
which	O
the	O
total	O
objective	O
is	O
an	O
explicit	O
sum	O
of	O
the	O
two	O
terms	O
using	O
the	O
labels	O
and	O
one	O
only	O
using	O
the	O
input	O
and	O
the	O
ladder	O
network	O
rasmus	O
et	O
al	O
unsupervised	B
pretraining	I
combines	O
two	O
different	O
ideas	O
first	O
it	O
makes	O
use	O
of	O
chapter	O
representation	B
learning	I
the	O
idea	O
that	O
the	O
choice	O
of	O
initial	O
parameters	O
for	O
a	O
deep	O
neural	B
network	I
can	O
have	O
a	O
significant	O
regularizing	O
effect	O
on	O
the	O
model	O
to	O
a	O
lesser	O
extent	O
that	O
it	O
can	O
improve	O
optimization	O
second	O
it	O
makes	O
use	O
of	O
the	O
more	O
general	O
idea	O
that	O
learning	O
about	O
the	O
input	O
distribution	O
can	O
help	O
to	O
learn	O
about	O
the	O
mapping	O
from	O
inputs	O
to	O
outputs	O
both	O
of	O
these	O
ideas	O
involve	O
many	O
complicated	O
interactions	O
between	O
several	O
parts	O
of	O
the	O
machine	B
learning	I
algorithm	O
that	O
are	O
not	O
entirely	O
understood	O
the	O
first	O
idea	O
that	O
the	O
choice	O
of	O
initial	O
parameters	O
for	O
a	O
deep	O
neural	B
network	I
can	O
have	O
a	O
strong	O
regularizing	O
effect	O
on	O
its	O
performance	O
is	O
the	O
least	O
well	O
understood	O
at	O
the	O
time	O
that	O
pretraining	O
became	O
popular	O
it	O
was	O
understood	O
as	O
initializing	O
the	O
model	O
in	O
a	O
location	O
that	O
would	O
cause	O
it	O
to	O
approach	O
one	O
local	O
minimum	O
rather	O
than	O
another	O
today	O
local	O
minima	O
are	O
no	O
longer	O
considered	O
to	O
be	O
a	O
serious	O
problem	O
for	O
neural	B
network	I
optimization	O
we	O
now	O
know	O
that	O
our	O
standard	O
neural	B
network	I
training	O
procedures	O
usually	O
do	O
not	O
arrive	O
at	O
a	O
critical	O
point	O
of	O
any	O
kind	O
it	O
remains	O
possible	O
that	O
pretraining	O
initializes	O
the	O
model	O
in	O
a	O
location	O
that	O
would	O
otherwise	O
be	O
inaccessible	O
for	O
example	B
a	O
region	O
that	O
is	O
surrounded	O
by	O
areas	O
where	O
the	O
cost	O
function	O
varies	O
so	O
much	O
from	O
one	O
example	B
to	O
another	O
that	O
minibatches	O
give	O
only	O
a	O
very	O
noisy	O
estimate	O
of	O
the	O
gradient	B
or	O
a	O
region	O
surrounded	O
by	O
areas	O
where	O
the	O
hessian	B
matrix	O
is	O
so	O
poorly	O
conditioned	O
that	O
gradient	B
descent	O
methods	O
must	O
use	O
very	O
small	O
steps	O
however	O
our	O
ability	O
to	O
characterize	O
exactly	O
what	O
aspects	O
of	O
the	O
pretrained	O
parameters	O
are	O
retained	O
during	O
the	O
supervised	O
training	O
stage	O
is	O
limited	O
this	O
is	O
one	O
reason	O
that	O
modern	O
approaches	O
typically	O
use	O
simultaneous	O
unsupervised	O
learning	O
and	O
supervised	B
learning	I
rather	O
than	O
two	O
sequential	O
stages	O
one	O
may	O
also	O
avoid	O
struggling	O
with	O
these	O
complicated	O
ideas	O
about	O
how	O
optimization	O
in	O
the	O
supervised	B
learning	I
stage	O
preserves	O
information	O
from	O
the	O
unsupervised	O
learning	O
stage	O
by	O
simply	O
freezing	O
the	O
parameters	O
for	O
the	O
feature	B
extractors	O
and	O
using	O
supervised	B
learning	I
only	O
to	O
add	O
a	O
classifier	O
on	O
top	O
of	O
the	O
learned	O
features	O
the	O
other	O
idea	O
that	O
a	O
learning	O
algorithm	O
can	O
use	O
information	O
learned	O
in	O
the	O
unsupervised	O
phase	O
to	O
perform	O
better	O
in	O
the	O
supervised	B
learning	I
stage	O
is	O
better	O
understood	O
the	O
basic	O
idea	O
is	O
that	O
some	O
features	O
that	O
are	O
useful	O
for	O
the	O
unsupervised	O
task	O
may	O
also	O
be	O
useful	O
for	O
the	O
supervised	B
learning	I
task	O
for	O
example	B
if	O
we	O
train	O
a	O
generative	O
model	O
of	O
images	O
of	O
cars	O
and	O
motorcycles	O
it	O
will	O
need	O
to	O
know	O
about	O
wheels	O
and	O
about	O
how	O
many	O
wheels	O
should	O
be	O
in	O
an	O
image	O
if	O
we	O
are	O
fortunate	O
the	O
representation	O
of	O
the	O
wheels	O
will	O
take	O
on	O
a	O
form	O
that	O
is	O
easy	O
for	O
the	O
supervised	O
learner	O
to	O
access	O
this	O
is	O
not	O
yet	O
understood	O
at	O
a	O
mathematical	O
theoretical	O
level	O
so	O
it	O
is	O
not	O
always	O
possible	O
to	O
predict	O
which	O
tasks	O
will	O
benefit	O
from	O
unsupervised	O
learning	O
in	O
this	O
way	O
many	O
aspects	O
of	O
this	O
approach	O
are	O
highly	O
dependent	O
on	O
the	O
specific	O
models	O
used	O
for	O
example	B
if	O
we	O
wish	O
to	O
add	O
a	O
linear	O
classifier	O
on	O
chapter	O
representation	B
learning	I
top	O
of	O
pretrained	O
features	O
the	O
features	O
must	O
make	O
the	O
underlying	O
classes	O
linearly	O
separable	O
these	O
properties	O
often	O
occur	O
naturally	O
but	O
do	O
not	O
always	O
do	O
so	O
this	O
is	O
another	O
reason	O
that	O
simultaneous	O
supervised	O
and	O
unsupervised	O
learning	O
can	O
be	O
preferable	O
the	O
constraints	O
imposed	O
by	O
the	O
output	O
layer	O
are	O
naturally	O
included	O
from	O
the	O
start	O
from	O
the	O
point	O
of	O
view	O
of	O
unsupervised	B
pretraining	I
as	O
learning	O
a	O
representation	O
we	O
can	O
expect	O
unsupervised	B
pretraining	I
to	O
be	O
more	O
effective	O
when	O
the	O
initial	O
representation	O
is	O
poor	O
one	O
key	O
example	B
of	O
this	O
is	O
the	O
use	O
of	O
word	O
embeddings	O
words	O
represented	O
by	O
one-hot	O
vectors	O
are	O
not	O
very	O
informative	O
because	O
every	O
two	O
distinct	O
one-hot	O
vectors	O
are	O
the	O
same	O
distance	O
from	O
each	O
other	O
distance	O
of	O
learned	O
word	O
embeddings	O
naturally	O
encode	O
similarity	O
between	O
words	O
by	O
their	O
distance	O
from	O
each	O
other	O
because	O
of	O
this	O
unsupervised	B
pretraining	I
is	O
especially	O
useful	O
when	O
processing	O
words	O
it	O
is	O
less	O
useful	O
when	O
processing	O
images	O
perhaps	O
because	O
images	O
already	O
lie	O
in	O
a	O
rich	O
vector	O
space	O
where	O
distances	O
provide	O
a	O
low	O
quality	O
similarity	O
metric	O
from	O
the	O
point	O
of	O
view	O
of	O
unsupervised	B
pretraining	I
as	O
a	O
regularizer	B
we	O
can	O
expect	O
unsupervised	B
pretraining	I
to	O
be	O
most	O
helpful	O
when	O
the	O
number	O
of	O
labeled	O
examples	O
is	O
very	O
small	O
because	O
the	O
source	O
of	O
information	O
added	O
by	O
unsupervised	B
pretraining	I
is	O
the	O
unlabeled	O
data	O
we	O
may	O
also	O
expect	O
unsupervised	B
pretraining	I
to	O
perform	O
best	O
when	O
the	O
number	O
of	O
unlabeled	O
examples	O
is	O
very	O
large	O
the	O
advantage	O
of	O
semi-supervised	B
learning	I
via	O
unsupervised	B
pretraining	I
with	O
many	O
unlabeled	O
examples	O
and	O
few	O
labeled	O
examples	O
was	O
made	O
particularly	O
clear	O
in	O
with	O
unsupervised	B
pretraining	I
winning	O
two	O
international	O
transfer	B
learning	I
competitions	O
in	O
settings	O
where	O
the	O
number	O
of	O
labeled	O
examples	O
in	O
the	O
target	O
task	O
was	O
small	O
a	O
handful	O
to	O
dozens	O
of	O
examples	O
per	O
class	O
these	O
effects	O
were	O
also	O
documented	O
in	O
carefully	O
controlled	O
experiments	O
by	O
paine	O
mesnil	O
et	O
al	O
goodfellow	O
et	O
al	O
et	O
al	O
other	O
factors	O
are	O
likely	O
to	O
be	O
involved	O
for	O
example	B
unsupervised	B
pretraining	I
is	O
likely	O
to	O
be	O
most	O
useful	O
when	O
the	O
function	O
to	O
be	O
learned	O
is	O
extremely	O
complicated	O
unsupervised	O
learning	O
differs	O
from	O
regularizers	O
like	O
weight	O
decay	O
because	O
it	O
does	O
not	O
bias	O
the	O
learner	O
toward	O
discovering	O
a	O
simple	O
function	O
but	O
rather	O
toward	O
discovering	O
feature	B
functions	O
that	O
are	O
useful	O
for	O
the	O
unsupervised	O
learning	O
task	O
if	O
the	O
true	O
underlying	O
functions	O
are	O
complicated	O
and	O
shaped	O
by	O
regularities	O
of	O
the	O
input	O
distribution	O
unsupervised	O
learning	O
can	O
be	O
a	O
more	O
appropriate	O
regularizer	B
these	O
caveats	O
aside	O
we	O
now	O
analyze	O
some	O
success	O
cases	O
where	O
unsupervised	B
pretraining	I
is	O
known	O
to	O
cause	O
an	O
improvement	O
and	O
explain	O
what	O
is	O
known	O
about	O
why	O
this	O
improvement	O
occurs	O
unsupervised	B
pretraining	I
has	O
usually	O
been	O
used	O
to	O
improve	O
classifiers	O
and	O
is	O
usually	O
most	O
interesting	O
from	O
the	O
point	O
of	O
view	O
of	O
chapter	O
representation	B
learning	I
erhan	O
et	O
al	O
erhan	O
et	O
al	O
figure	O
visualization	O
via	O
nonlinear	O
projection	O
of	O
the	O
learning	O
trajectories	O
of	O
different	O
neural	O
networks	O
in	O
function	O
space	O
parameter	O
space	O
to	O
avoid	O
the	O
issue	O
of	O
many-to-one	O
mappings	O
from	O
parameter	O
vectors	O
to	O
functions	O
with	O
different	O
random	O
initializations	O
and	O
with	O
or	O
without	O
unsupervised	B
pretraining	I
each	O
point	O
corresponds	O
to	O
a	O
different	O
neural	B
network	I
at	O
a	O
particular	O
time	O
during	O
its	O
training	O
process	O
this	O
figure	O
is	O
adapted	O
a	O
coordinate	O
in	O
function	O
space	O
is	O
an	O
infinitewith	O
permission	O
from	O
dimensional	O
vector	O
associating	O
every	O
input	O
x	O
with	O
an	O
output	O
y	O
made	O
a	O
linear	O
projection	O
to	O
high-dimensional	O
space	O
by	O
concatenating	O
the	O
y	O
for	O
many	O
specific	O
x	O
points	O
they	O
then	O
made	O
a	O
further	O
nonlinear	O
projection	O
to	O
by	O
isomap	O
et	O
al	O
color	O
indicates	O
time	O
all	O
networks	O
are	O
initialized	O
near	O
the	O
center	O
of	O
the	O
plot	O
to	O
the	O
region	O
of	O
functions	O
that	O
produce	O
approximately	O
uniform	O
distributions	O
over	O
the	O
class	O
y	O
for	O
most	O
inputs	O
over	O
time	O
learning	O
moves	O
the	O
function	O
outward	O
to	O
points	O
that	O
make	O
strong	O
predictions	O
training	O
consistently	O
terminates	O
in	O
one	O
region	O
when	O
using	O
pretraining	O
and	O
in	O
another	O
non-overlapping	O
region	O
when	O
not	O
using	O
pretraining	O
isomap	O
tries	O
to	O
preserve	O
global	O
relative	O
distances	O
hence	O
volumes	O
so	O
the	O
small	O
region	O
corresponding	O
to	O
pretrained	O
models	O
may	O
indicate	O
that	O
the	O
pretraining-based	O
estimator	O
has	O
reduced	O
variance	O
chapter	O
representation	B
learning	I
reducing	O
test	B
set	I
error	O
however	O
unsupervised	B
pretraining	I
can	O
help	O
tasks	O
other	O
than	O
classification	B
and	O
can	O
act	O
to	O
improve	O
optimization	O
rather	O
than	O
being	O
merely	O
a	O
regularizer	B
for	O
example	B
it	O
can	O
improve	O
both	O
train	O
and	O
test	O
reconstruction	O
error	O
for	O
deep	O
autoencoders	O
and	O
salakhutdinov	O
erhan	O
et	O
al	O
performed	O
many	O
experiments	O
to	O
explain	O
several	O
successes	O
of	O
unsupervised	B
pretraining	I
both	O
improvements	O
to	O
training	B
error	I
and	O
improvements	O
to	O
test	O
error	O
may	O
be	O
explained	O
in	O
terms	O
of	O
unsupervised	B
pretraining	I
taking	O
the	O
parameters	O
into	O
a	O
region	O
that	O
would	O
otherwise	O
be	O
inaccessible	O
neural	B
network	I
training	O
is	O
non-deterministic	O
and	O
converges	O
to	O
a	O
different	O
function	O
every	O
time	O
it	O
is	O
run	O
training	O
may	O
halt	O
at	O
a	O
point	O
where	O
the	O
gradient	B
becomes	O
small	O
a	O
point	O
where	O
early	O
stopping	O
ends	O
training	O
to	O
prevent	O
overfitting	O
or	O
at	O
a	O
point	O
where	O
the	O
gradient	B
is	O
large	O
but	O
it	O
is	O
difficult	O
to	O
find	O
a	O
downhill	O
step	O
due	O
to	O
problems	O
such	O
as	O
stochasticity	O
or	O
poor	O
conditioning	O
of	O
the	O
hessian	B
neural	O
networks	O
that	O
receive	O
unsupervised	B
pretraining	I
consistently	O
halt	O
in	O
the	O
same	O
region	O
of	O
function	O
space	O
while	O
neural	O
networks	O
without	O
pretraining	O
consistently	O
halt	O
in	O
another	O
region	O
see	O
figure	O
for	O
a	O
visualization	O
of	O
this	O
phenomenon	O
the	O
region	O
where	O
pretrained	O
networks	O
arrive	O
is	O
smaller	O
suggesting	O
that	O
pretraining	O
reduces	O
the	O
variance	O
of	O
the	O
estimation	O
process	O
which	O
can	O
in	O
turn	O
reduce	O
the	O
risk	B
of	O
severe	O
over-fitting	O
in	O
other	O
words	O
unsupervised	B
pretraining	I
initializes	O
neural	B
network	I
parameters	O
into	O
a	O
region	O
that	O
they	O
do	O
not	O
escape	O
and	O
the	O
results	O
following	O
this	O
initialization	B
are	O
more	O
consistent	O
and	O
less	O
likely	O
to	O
be	O
very	O
bad	O
than	O
without	O
this	O
initialization	B
erhan	O
et	O
al	O
also	O
provide	O
some	O
answers	O
as	O
to	O
pretraining	O
works	O
best	O
the	O
mean	O
and	O
variance	O
of	O
the	O
test	O
error	O
were	O
most	O
reduced	O
by	O
pretraining	O
for	O
deeper	O
networks	O
keep	O
in	O
mind	O
that	O
these	O
experiments	O
were	O
performed	O
before	O
the	O
invention	O
and	O
popularization	O
of	O
modern	O
techniques	O
for	O
training	O
very	O
deep	O
networks	O
linear	O
units	O
dropout	O
and	O
batch	O
normalization	O
so	O
less	O
is	O
known	O
about	O
the	O
effect	O
of	O
unsupervised	B
pretraining	I
in	O
conjunction	O
with	O
contemporary	O
approaches	O
when	O
an	O
important	O
question	O
is	O
how	O
unsupervised	B
pretraining	I
can	O
act	O
as	O
a	O
regularizer	B
one	O
hypothesis	O
is	O
that	O
pretraining	O
encourages	O
the	O
learning	O
algorithm	O
to	O
discover	O
features	O
that	O
relate	O
to	O
the	O
underlying	O
causes	O
that	O
generate	O
the	O
observed	O
data	O
this	O
is	O
an	O
important	O
idea	O
motivating	O
many	O
other	O
algorithms	O
besides	O
unsupervised	B
pretraining	I
and	O
is	O
described	O
further	O
in	O
section	O
compared	O
to	O
other	O
forms	O
of	O
unsupervised	O
learning	O
unsupervised	B
pretraining	I
has	O
the	O
disadvantage	O
that	O
it	O
operates	O
with	O
two	O
separate	O
training	O
phases	O
many	O
regularization	O
strategies	O
have	O
the	O
advantage	O
of	O
allowing	O
the	O
user	O
to	O
control	O
the	O
strength	O
of	O
the	O
regularization	O
by	O
adjusting	O
the	O
value	O
of	O
a	O
single	O
hyperparameter	O
unsupervised	B
pretraining	I
does	O
not	O
offer	O
a	O
clear	O
way	O
to	O
adjust	O
the	O
the	O
strength	O
of	O
the	O
regularization	O
arising	O
from	O
the	O
unsupervised	O
stage	O
instead	O
there	O
are	O
chapter	O
representation	B
learning	I
very	O
many	O
hyperparameters	O
whose	O
effect	O
may	O
be	O
measured	O
after	O
the	O
fact	O
but	O
is	O
often	O
difficult	O
to	O
predict	O
ahead	O
of	O
time	O
when	O
we	O
perform	O
unsupervised	O
and	O
supervised	B
learning	I
simultaneously	O
instead	O
of	O
using	O
the	O
pretraining	O
strategy	O
there	O
is	O
a	O
single	O
hyperparameter	O
usually	O
a	O
coefficient	O
attached	O
to	O
the	O
unsupervised	O
cost	O
that	O
determines	O
how	O
strongly	O
the	O
unsupervised	O
objective	O
will	O
regularize	O
the	O
supervised	O
model	O
one	O
can	O
always	O
predictably	O
obtain	O
less	O
regularization	O
by	O
decreasing	O
this	O
coefficient	O
in	O
the	O
case	O
of	O
unsupervised	B
pretraining	I
there	O
is	O
not	O
a	O
way	O
of	O
flexibly	O
adapting	O
the	O
strength	O
of	O
the	O
regularization	O
either	O
the	O
supervised	O
model	O
is	O
initialized	O
to	O
pretrained	O
parameters	O
or	O
it	O
is	O
not	O
another	O
disadvantage	O
of	O
having	O
two	O
separate	O
training	O
phases	O
is	O
that	O
each	O
phase	O
has	O
its	O
own	O
hyperparameters	O
the	O
performance	O
of	O
the	O
second	O
phase	O
usually	O
cannot	O
be	O
predicted	O
during	O
the	O
first	O
phase	O
so	O
there	O
is	O
a	O
long	O
delay	O
between	O
proposing	O
hyperparameters	O
for	O
the	O
first	O
phase	O
and	O
being	O
able	O
to	O
update	O
them	O
using	O
feedback	O
from	O
the	O
second	O
phase	O
the	O
most	O
principled	O
approach	O
is	O
to	O
use	O
validation	O
set	O
error	O
in	O
the	O
supervised	O
phase	O
in	O
order	O
to	O
select	O
the	O
hyperparameters	O
of	O
the	O
pretraining	O
phase	O
as	O
discussed	O
in	O
in	O
practice	O
some	O
hyperparameters	O
like	O
the	O
number	O
of	O
pretraining	O
iterations	O
are	O
more	O
conveniently	O
set	O
during	O
the	O
pretraining	O
phase	O
using	O
early	O
stopping	O
on	O
the	O
unsupervised	O
objective	O
which	O
is	O
not	O
ideal	O
but	O
computationally	O
much	O
cheaper	O
than	O
using	O
the	O
supervised	O
objective	O
larochelle	O
et	O
al	O
today	O
unsupervised	B
pretraining	I
has	O
been	O
largely	O
abandoned	O
except	O
in	O
the	O
field	O
of	O
natural	B
language	I
processing	I
where	O
the	O
natural	O
representation	O
of	O
words	O
as	O
one-hot	O
vectors	O
conveys	O
no	O
similarity	O
information	O
and	O
where	O
very	O
large	O
unlabeled	O
sets	O
are	O
available	O
in	O
that	O
case	O
the	O
advantage	O
of	O
pretraining	O
is	O
that	O
one	O
can	O
pretrain	O
once	O
on	O
a	O
huge	O
unlabeled	O
set	O
example	B
with	O
a	O
corpus	O
containing	O
billions	O
of	O
words	O
learn	O
a	O
good	O
representation	O
of	O
words	O
but	O
also	O
of	O
sentences	O
and	O
then	O
use	O
this	O
representation	O
or	O
fine-tune	O
it	O
for	O
a	O
supervised	O
task	O
for	O
which	O
the	O
training	O
set	O
contains	O
substantially	O
fewer	O
examples	O
this	O
approach	O
was	O
pioneered	O
by	O
by	O
collobert	O
and	O
weston	O
turian	O
et	O
al	O
and	O
remains	O
in	O
common	O
use	O
today	O
collobert	O
and	O
et	O
al	O
deep	O
learning	O
techniques	O
based	O
on	O
supervised	B
learning	I
regularized	O
with	O
dropout	O
or	O
batch	O
normalization	O
are	O
able	O
to	O
achieve	O
human-level	O
performance	O
on	O
very	O
many	O
tasks	O
but	O
only	O
with	O
extremely	O
large	O
labeled	O
datasets	O
these	O
same	O
techniques	O
outperform	O
unsupervised	B
pretraining	I
on	O
medium-sized	O
datasets	O
such	O
as	O
and	O
mnist	O
which	O
have	O
roughly	O
labeled	O
examples	O
per	O
class	O
on	O
extremely	O
small	O
datasets	O
such	O
as	O
the	O
alternative	O
splicing	O
dataset	B
bayesian	O
methods	O
outperform	O
methods	O
based	O
on	O
unsupervised	B
pretraining	I
for	O
these	O
reasons	O
the	O
popularity	O
of	O
unsupervised	B
pretraining	I
has	O
declined	O
nevertheless	O
unsupervised	B
pretraining	I
remains	O
an	O
important	O
milestone	O
in	O
the	O
history	O
of	O
deep	O
learning	O
research	O
chapter	O
representation	B
learning	I
and	O
continues	O
to	O
influence	O
contemporary	O
approaches	O
the	O
idea	O
of	O
pretraining	O
has	O
been	O
generalized	O
to	O
supervised	O
pretraining	O
discussed	O
in	O
section	O
as	O
a	O
very	O
common	O
approach	O
for	O
transfer	B
learning	I
supervised	O
pretraining	O
for	O
transfer	B
learning	I
is	O
popular	O
for	O
use	O
with	O
convolutional	O
networks	O
pretrained	O
on	O
the	O
imagenet	O
dataset	B
practitioners	O
publish	O
the	O
parameters	O
of	O
these	O
trained	O
networks	O
for	O
this	O
purpose	O
just	O
like	O
pretrained	O
word	O
vectors	O
are	O
published	O
for	O
natural	O
language	O
tasks	O
collobert	O
et	O
al	O
mikolov	O
oquab	O
et	O
al	O
yosinski	O
et	O
al	O
et	O
al	O
transfer	B
learning	I
and	O
domain	B
adaptation	I
transfer	B
learning	I
and	O
domain	B
adaptation	I
refer	O
to	O
the	O
situation	O
where	O
what	O
has	O
been	O
learned	O
in	O
one	O
setting	O
distribution	O
is	O
exploited	O
to	O
improve	O
generalization	B
in	O
another	O
setting	O
distribution	O
p	O
this	O
generalizes	O
the	O
idea	O
presented	O
in	O
the	O
previous	O
section	O
where	O
we	O
transferred	O
representations	O
between	O
an	O
unsupervised	O
learning	O
task	O
and	O
a	O
supervised	B
learning	I
task	O
in	O
transfer	B
learning	I
the	O
learner	O
must	O
perform	O
two	O
or	O
more	O
different	O
tasks	O
but	O
we	O
assume	O
that	O
many	O
of	O
the	O
factors	O
that	O
explain	O
the	O
variations	O
in	O
are	O
relevant	O
to	O
the	O
variations	O
that	O
need	O
to	O
be	O
captured	O
for	O
learning	O
this	O
is	O
typically	O
understood	O
in	O
a	O
supervised	B
learning	I
context	O
where	O
the	O
input	O
is	O
the	O
same	O
but	O
the	O
target	O
may	O
be	O
of	O
a	O
different	O
nature	O
for	O
example	B
we	O
may	O
learn	O
about	O
one	O
set	O
of	O
visual	O
categories	O
such	O
as	O
cats	O
and	O
dogs	O
in	O
the	O
first	O
setting	O
then	O
learn	O
about	O
a	O
different	O
set	O
of	O
visual	O
categories	O
such	O
as	O
ants	O
and	O
wasps	O
in	O
the	O
second	O
setting	O
if	O
there	O
is	O
significantly	O
more	O
data	O
in	O
the	O
first	O
setting	O
from	O
p	O
then	O
that	O
may	O
help	O
to	O
learn	O
representations	O
that	O
are	O
useful	O
to	O
quickly	O
generalize	O
from	O
only	O
very	O
few	O
examples	O
drawn	O
from	O
many	O
visual	O
categories	O
share	O
low-level	O
notions	O
of	O
edges	O
and	O
visual	O
shapes	O
the	O
effects	O
of	O
geometric	O
changes	O
changes	O
in	O
lighting	O
etc	O
in	O
general	O
transfer	B
learning	I
multi-task	O
learning	O
and	O
domain	B
adaptation	I
can	O
be	O
achieved	O
via	O
representation	B
learning	I
when	O
there	O
exist	O
features	O
that	O
are	O
useful	O
for	O
the	O
different	O
settings	O
or	O
tasks	O
corresponding	O
to	O
underlying	O
factors	O
that	O
appear	O
in	O
more	O
than	O
one	O
setting	O
this	O
is	O
illustrated	O
in	O
figure	O
with	O
shared	O
lower	O
layers	O
and	O
task-dependent	O
upper	O
layers	O
however	O
sometimes	O
what	O
is	O
shared	O
among	O
the	O
different	O
tasks	O
is	O
not	O
the	O
semantics	O
of	O
the	O
input	O
but	O
the	O
semantics	O
of	O
the	O
output	O
for	O
example	B
a	O
speech	O
recognition	O
system	O
needs	O
to	O
produce	O
valid	O
sentences	O
at	O
the	O
output	O
layer	O
but	O
the	O
earlier	O
layers	O
near	O
the	O
input	O
may	O
need	O
to	O
recognize	O
very	O
different	O
versions	O
of	O
the	O
same	O
phonemes	O
or	O
sub-phonemic	O
vocalizations	O
depending	O
on	O
which	O
person	O
is	O
speaking	O
in	O
cases	O
like	O
these	O
it	O
makes	O
more	O
sense	O
to	O
share	O
the	O
upper	O
layers	O
the	O
output	O
of	O
the	O
neural	B
network	I
and	O
have	O
a	O
task-specific	O
preprocessing	B
as	O
chapter	O
representation	B
learning	I
illustrated	O
in	O
figure	O
yy	O
hshared	O
hshared	O
selection	O
switch	O
y	O
has	O
the	O
same	O
semantics	O
for	O
all	O
tasks	O
while	O
the	O
input	O
variable	O
figure	O
example	B
architecture	O
for	O
multi-task	O
or	O
transfer	B
learning	I
when	O
the	O
output	O
variable	O
has	O
a	O
different	O
meaning	O
possibly	O
even	O
a	O
different	O
dimension	O
for	O
each	O
task	O
for	O
example	B
each	O
user	O
called	O
and	O
for	O
three	O
tasks	O
the	O
lower	O
levels	O
to	O
the	O
selection	O
switch	O
are	O
task-specific	O
while	O
the	O
upper	O
levels	O
are	O
shared	O
the	O
lower	O
levels	O
learn	O
to	O
translate	O
their	O
task-specific	O
input	O
into	O
a	O
generic	O
set	O
of	O
features	O
x	O
in	O
the	O
related	O
case	O
of	O
domain	B
adaptation	I
the	O
task	O
the	O
optimal	O
input-tooutput	O
mapping	O
remains	O
the	O
same	O
between	O
each	O
setting	O
but	O
the	O
input	O
distribution	O
is	O
slightly	O
different	O
for	O
example	B
consider	O
the	O
task	O
of	O
sentiment	O
analysis	O
which	O
consists	O
of	O
determining	O
whether	O
a	O
comment	O
expresses	O
positive	O
or	O
negative	O
sentiment	O
comments	O
posted	O
on	O
the	O
web	O
come	O
from	O
many	O
categories	O
a	O
domain	B
adaptation	I
scenario	O
can	O
arise	O
when	O
a	O
sentiment	O
predictor	O
trained	O
on	O
customer	O
reviews	O
of	O
media	O
content	O
such	O
as	O
books	O
videos	O
and	O
music	O
is	O
later	O
used	O
to	O
analyze	O
comments	O
about	O
consumer	O
electronics	O
such	O
as	O
televisions	O
or	O
smartphones	O
one	O
can	O
imagine	O
that	O
there	O
is	O
an	O
underlying	O
function	O
that	O
tells	O
whether	O
any	O
statement	O
is	O
positive	O
neutral	O
or	O
negative	O
but	O
of	O
course	O
the	O
vocabulary	O
and	O
style	O
may	O
vary	O
from	O
one	O
domain	O
to	O
another	O
making	O
it	O
more	O
difficult	O
to	O
generalize	O
across	O
domains	O
simple	O
unsupervised	B
pretraining	I
denoising	O
autoencoders	O
has	O
been	O
found	O
to	O
be	O
very	O
successful	O
for	O
sentiment	O
analysis	O
with	O
domain	B
adaptation	I
glorot	O
et	O
al	O
a	O
related	O
problem	O
is	O
that	O
of	O
concept	B
drift	I
which	O
we	O
can	O
view	O
as	O
a	O
form	O
of	O
transfer	B
learning	I
due	O
to	O
gradual	O
changes	O
in	O
the	O
data	O
distribution	O
over	O
time	O
both	O
concept	B
drift	I
and	O
transfer	B
learning	I
can	O
be	O
viewed	O
as	O
particular	O
forms	O
of	O
chapter	O
representation	B
learning	I
multi-task	O
learning	O
while	O
the	O
phrase	O
multi-task	O
learning	O
typically	O
refers	O
to	O
supervised	B
learning	I
tasks	O
the	O
more	O
general	O
notion	O
of	O
transfer	B
learning	I
is	O
applicable	O
to	O
unsupervised	O
learning	O
and	O
reinforcement	O
learning	O
as	O
well	O
in	O
all	O
of	O
these	O
cases	O
the	O
objective	O
is	O
to	O
take	O
advantage	O
of	O
data	O
from	O
the	O
first	O
setting	O
to	O
extract	O
information	O
that	O
may	O
be	O
useful	O
when	O
learning	O
or	O
even	O
when	O
directly	O
making	O
predictions	O
in	O
the	O
second	O
setting	O
the	O
core	O
idea	O
of	O
representation	B
learning	I
is	O
that	O
the	O
same	O
representation	O
may	O
be	O
useful	O
in	O
both	O
settings	O
using	O
the	O
same	O
representation	O
in	O
both	O
settings	O
allows	O
the	O
representation	O
to	O
benefit	O
from	O
the	O
training	O
data	O
that	O
is	O
available	O
for	O
both	O
tasks	O
as	O
mentioned	O
before	O
unsupervised	O
deep	O
learning	O
for	O
transfer	B
learning	I
has	O
found	O
mesnil	O
et	O
al	O
goodfellow	O
success	O
in	O
some	O
machine	B
learning	I
competitions	O
et	O
al	O
in	O
the	O
first	O
of	O
these	O
competitions	O
the	O
experimental	O
setup	O
is	O
the	O
following	O
each	O
participant	O
is	O
first	O
given	O
a	O
dataset	B
from	O
the	O
first	O
setting	O
distribution	O
illustrating	O
examples	O
of	O
some	O
set	O
of	O
categories	O
the	O
participants	O
must	O
use	O
this	O
to	O
learn	O
a	O
good	O
feature	B
space	O
the	O
raw	O
input	O
to	O
some	O
representation	O
such	O
that	O
when	O
we	O
apply	O
this	O
learned	O
transformation	O
to	O
inputs	O
from	O
the	O
transfer	O
setting	O
a	O
linear	O
classifier	O
can	O
be	O
trained	O
and	O
generalize	O
well	O
from	O
very	O
few	O
labeled	O
examples	O
one	O
of	O
the	O
most	O
striking	O
results	O
found	O
in	O
this	O
competition	O
is	O
that	O
as	O
an	O
architecture	O
makes	O
use	O
of	O
deeper	O
and	O
deeper	O
representations	O
in	O
a	O
purely	O
unsupervised	O
way	O
from	O
data	O
collected	O
in	O
the	O
first	O
setting	O
p	O
the	O
learning	O
curve	O
on	O
the	O
new	O
categories	O
of	O
the	O
second	O
setting	O
p	O
becomes	O
much	O
better	O
for	O
deep	O
representations	O
fewer	O
labeled	O
examples	O
of	O
the	O
transfer	O
tasks	O
are	O
necessary	O
to	O
achieve	O
the	O
apparently	O
asymptotic	O
generalization	B
performance	O
two	O
extreme	O
forms	O
of	O
transfer	B
learning	I
are	O
one-shot	B
learning	I
and	O
zero-shot	B
learning	I
sometimes	O
also	O
called	O
zero-data	O
learning	O
only	O
one	O
labeled	O
example	B
of	O
the	O
transfer	O
task	O
is	O
given	O
for	O
one-shot	B
learning	I
while	O
no	O
labeled	O
examples	O
are	O
given	O
at	O
all	O
for	O
the	O
zero-shot	B
learning	I
task	O
et	O
al	O
one-shot	B
learning	I
is	O
possible	O
because	O
the	O
representation	O
learns	O
to	O
cleanly	O
separate	O
the	O
underlying	O
classes	O
during	O
the	O
first	O
stage	O
during	O
the	O
transfer	B
learning	I
stage	O
only	O
one	O
labeled	O
example	B
is	O
needed	O
to	O
infer	O
the	O
label	O
of	O
many	O
possible	O
test	O
examples	O
that	O
all	O
cluster	O
around	O
the	O
same	O
point	O
in	O
representation	O
space	O
this	O
works	O
to	O
the	O
extent	O
that	O
the	O
factors	B
of	I
variation	I
corresponding	O
to	O
these	O
invariances	O
have	O
been	O
cleanly	O
separated	O
from	O
the	O
other	O
factors	O
in	O
the	O
learned	O
representation	O
space	O
and	O
we	O
have	O
somehow	O
learned	O
which	O
factors	O
do	O
and	O
do	O
not	O
matter	O
when	O
discriminating	O
objects	O
of	O
certain	O
categories	O
as	O
an	O
example	B
of	O
a	O
zero-shot	B
learning	I
setting	O
consider	O
the	O
problem	O
of	O
having	O
a	O
learner	O
read	O
a	O
large	O
collection	O
of	O
text	O
and	O
then	O
solve	O
object	B
recognition	I
problems	O
chapter	O
representation	B
learning	I
it	O
may	O
be	O
possible	O
to	O
recognize	O
a	O
specific	O
object	O
class	O
even	O
without	O
having	O
seen	O
an	O
image	O
of	O
that	O
object	O
if	O
the	O
text	O
describes	O
the	O
object	O
well	O
enough	O
for	O
example	B
having	O
read	O
that	O
a	O
cat	O
has	O
four	O
legs	O
and	O
pointy	O
ears	O
the	O
learner	O
might	O
be	O
able	O
to	O
guess	O
that	O
an	O
image	O
is	O
a	O
cat	O
without	O
having	O
seen	O
a	O
cat	O
before	O
et	O
al	O
et	O
al	O
socher	O
and	O
zero-shot	B
learning	I
zero-data	O
learning	O
palatucci	O
et	O
al	O
are	O
only	O
possible	O
because	O
additional	O
information	O
has	O
been	O
exploited	O
during	O
training	O
we	O
can	O
think	O
of	O
the	O
zero-data	O
learning	O
scenario	O
as	O
including	O
three	O
random	O
variables	O
the	O
traditional	O
inputs	O
x	O
the	O
traditional	O
outputs	O
or	O
targets	O
y	O
and	O
an	O
additional	O
random	B
variable	I
describing	O
the	O
task	O
t	O
the	O
model	O
is	O
trained	O
to	O
estimate	O
the	O
conditional	O
distribution	O
py	O
x	O
t	O
where	O
t	O
is	O
a	O
description	O
of	O
the	O
task	O
we	O
wish	O
the	O
model	O
to	O
perform	O
in	O
our	O
example	B
of	O
recognizing	O
cats	O
after	O
having	O
read	O
about	O
cats	O
the	O
output	O
is	O
a	O
binary	O
variable	O
y	O
with	O
y	O
indicating	O
yes	O
and	O
y	O
indicating	O
no	O
the	O
task	O
variable	O
t	O
then	O
represents	O
questions	O
to	O
be	O
answered	O
such	O
as	O
is	O
there	O
a	O
cat	O
in	O
this	O
image	O
if	O
we	O
have	O
a	O
training	O
set	O
containing	O
unsupervised	O
examples	O
of	O
objects	O
that	O
live	O
in	O
the	O
same	O
space	O
as	O
t	O
we	O
may	O
be	O
able	O
to	O
infer	O
the	O
meaning	O
of	O
unseen	O
instances	O
of	O
t	O
in	O
our	O
example	B
of	O
recognizing	O
cats	O
without	O
having	O
seen	O
an	O
image	O
of	O
the	O
cat	O
it	O
is	O
important	O
that	O
we	O
have	O
had	O
unlabeled	O
text	O
data	O
containing	O
sentences	O
such	O
as	O
cats	O
have	O
four	O
legs	O
or	O
cats	O
have	O
pointy	O
ears	O
zero-shot	B
learning	I
requires	O
t	O
to	O
be	O
represented	O
in	O
a	O
way	O
that	O
allows	O
some	O
sort	O
of	O
generalization	B
for	O
example	B
t	O
cannot	O
be	O
just	O
a	O
one-hot	O
code	O
indicating	O
an	O
object	O
category	O
provide	O
instead	O
a	O
distributed	O
representation	O
of	O
object	O
categories	O
by	O
using	O
a	O
learned	O
word	B
embedding	B
for	O
the	O
word	O
associated	O
with	O
each	O
category	O
socher	O
et	O
al	O
et	O
al	O
et	O
al	O
et	O
al	O
gouws	O
a	O
similar	O
phenomenon	O
happens	O
in	O
machine	B
translation	I
mikolov	O
we	O
have	O
words	O
in	O
one	O
language	O
and	O
the	O
relationships	O
between	O
words	O
can	O
be	O
learned	O
from	O
unilingual	O
corpora	O
on	O
the	O
other	O
hand	O
we	O
have	O
translated	O
sentences	O
which	O
relate	O
words	O
in	O
one	O
language	O
with	O
words	O
in	O
the	O
other	O
even	O
though	O
we	O
may	O
not	O
have	O
labeled	O
examples	O
translating	O
word	O
a	O
in	O
language	O
x	O
to	O
word	O
b	O
in	O
language	O
y	O
we	O
can	O
generalize	O
and	O
guess	O
a	O
translation	O
for	O
word	O
a	O
because	O
we	O
have	O
learned	O
a	O
distributed	O
representation	O
for	O
words	O
in	O
language	O
x	O
a	O
distributed	O
representation	O
for	O
words	O
in	O
language	O
y	O
and	O
created	O
a	O
link	O
two-way	O
relating	O
the	O
two	O
spaces	O
via	O
training	O
examples	O
consisting	O
of	O
matched	O
pairs	O
of	O
sentences	O
in	O
both	O
languages	O
this	O
transfer	O
will	O
be	O
most	O
successful	O
if	O
all	O
three	O
ingredients	O
two	O
representations	O
and	O
the	O
relations	B
between	O
them	O
are	O
learned	O
jointly	O
zero-shot	B
learning	I
is	O
a	O
particular	O
form	O
of	O
transfer	B
learning	I
the	O
same	O
principle	O
explains	O
how	O
one	O
can	O
perform	O
multi-modal	B
learning	I
capturing	O
a	O
representation	O
chapter	O
representation	B
learning	I
hx	O
fx	O
hy	O
fy	O
fy	O
space	O
x	O
fx	O
xtest	O
space	O
y	O
y	O
test	O
pairs	O
in	O
the	O
training	O
set	O
x	O
y	O
fx	O
encoder	B
function	O
for	O
x	O
fy	O
encoder	B
function	O
for	O
y	O
relationship	O
between	O
embedded	O
points	O
within	O
one	O
of	O
the	O
domains	O
maps	O
between	O
representation	O
spaces	O
figure	O
transfer	B
learning	I
between	O
two	O
domains	O
x	O
and	O
y	O
enables	O
zero-shot	B
learning	I
labeled	O
or	O
unlabeled	O
examples	O
of	O
x	O
allow	O
one	O
to	O
learn	O
a	O
representation	O
function	O
fx	O
and	O
similarly	O
with	O
examples	O
of	O
y	O
to	O
learn	O
f	O
y	O
each	O
application	O
of	O
the	O
fx	O
and	O
fy	O
functions	O
appears	O
as	O
an	O
upward	O
arrow	O
with	O
the	O
style	O
of	O
the	O
arrows	O
indicating	O
which	O
function	O
is	O
applied	O
distance	O
in	O
hx	O
space	O
provides	O
a	O
similarity	O
metric	O
between	O
any	O
pair	O
of	O
points	O
in	O
x	O
space	O
that	O
may	O
be	O
more	O
meaningful	O
than	O
distance	O
in	O
x	O
space	O
likewise	O
distance	O
in	O
hy	O
space	O
provides	O
a	O
similarity	O
metric	O
between	O
any	O
pair	O
of	O
points	O
in	O
y	O
space	O
both	O
of	O
these	O
similarity	O
functions	O
are	O
indicated	O
with	O
dotted	O
bidirectional	O
arrows	O
labeled	O
examples	O
horizontal	O
lines	O
are	O
pairs	O
y	O
which	O
allow	O
one	O
to	O
learn	O
a	O
one-way	O
or	O
two-way	O
map	O
bidirectional	O
arrow	O
between	O
the	O
representations	O
fxx	O
and	O
the	O
representations	O
fy	O
and	O
anchor	O
these	O
representations	O
to	O
each	O
other	O
zero-data	O
learning	O
is	O
then	O
enabled	O
as	O
follows	O
one	O
can	O
associate	O
an	O
image	O
xtest	O
to	O
a	O
word	O
y	O
test	O
even	O
if	O
no	O
image	O
of	O
that	O
word	O
was	O
ever	O
presented	O
simply	O
because	O
word-representations	O
f	O
yytest	O
and	O
image-representations	O
fx	O
can	O
be	O
related	O
to	O
each	O
other	O
via	O
the	O
maps	O
between	O
representation	O
spaces	O
it	O
works	O
because	O
although	O
that	O
image	O
and	O
that	O
word	O
were	O
never	O
paired	O
their	O
respective	O
feature	B
vectors	O
fxxtest	O
and	O
fy	O
ytest	O
have	O
been	O
related	O
to	O
each	O
other	O
figure	O
inspired	O
from	O
suggestion	O
by	O
hrant	O
khachatrian	O
chapter	O
representation	B
learning	I
in	O
one	O
modality	O
a	O
representation	O
in	O
the	O
other	O
and	O
the	O
relationship	O
general	O
a	O
joint	O
distribution	O
between	O
pairs	O
y	O
consisting	O
of	O
one	O
observation	O
x	O
in	O
one	O
modality	O
and	O
another	O
observation	O
y	O
in	O
the	O
other	O
modality	O
and	O
salakhutdinov	O
by	O
learning	O
all	O
three	O
sets	O
of	O
parameters	O
x	O
to	O
its	O
representation	O
from	O
y	O
to	O
its	O
representation	O
and	O
the	O
relationship	O
between	O
the	O
two	O
representations	O
concepts	O
in	O
one	O
representation	O
are	O
anchored	O
in	O
the	O
other	O
and	O
vice-versa	O
allowing	O
one	O
to	O
meaningfully	O
generalize	O
to	O
new	O
pairs	O
the	O
procedure	O
is	O
illustrated	O
in	O
figure	O
semi-supervised	O
disentangling	O
of	O
causal	O
factors	O
an	O
important	O
question	O
about	O
representation	B
learning	I
is	O
what	O
makes	O
one	O
representation	O
better	O
than	O
another	O
one	O
hypothesis	O
is	O
that	O
an	O
ideal	O
representation	O
is	O
one	O
in	O
which	O
the	O
features	O
within	O
the	O
representation	O
correspond	O
to	O
the	O
underlying	O
causes	O
of	O
the	O
observed	O
data	O
with	O
separate	O
features	O
or	O
directions	O
in	O
feature	B
space	O
corresponding	O
to	O
different	O
causes	O
so	O
that	O
the	O
representation	O
disentangles	O
the	O
causes	O
from	O
one	O
another	O
this	O
hypothesis	O
motivates	O
approaches	O
in	O
which	O
we	O
first	O
seek	O
a	O
good	O
representation	O
for	O
px	O
such	O
a	O
representation	O
may	O
also	O
be	O
a	O
good	O
representation	O
for	O
computing	O
py	O
x	O
if	O
y	O
is	O
among	O
the	O
most	O
salient	O
causes	O
of	O
x	O
this	O
idea	O
has	O
guided	O
a	O
large	O
amount	O
of	O
deep	O
learning	O
research	O
since	O
at	O
least	O
the	O
and	O
hinton	O
hinton	O
and	O
sejnowski	O
in	O
more	O
detail	O
for	O
other	O
arguments	O
about	O
when	O
semi-supervised	B
learning	I
can	O
outperform	O
pure	O
supervised	B
learning	I
we	O
refer	O
the	O
reader	O
to	O
section	O
of	O
chapelle	O
et	O
al	O
in	O
other	O
approaches	O
to	O
representation	B
learning	I
we	O
have	O
often	O
been	O
concerned	O
with	O
a	O
representation	O
that	O
is	O
easy	O
to	O
model	O
for	O
example	B
one	O
whose	O
entries	O
are	O
sparse	O
or	O
independent	O
from	O
each	O
other	O
a	O
representation	O
that	O
cleanly	O
separates	O
the	O
underlying	O
causal	O
factors	O
may	O
not	O
necessarily	O
be	O
one	O
that	O
is	O
easy	O
to	O
model	O
however	O
a	O
further	O
part	O
of	O
the	O
hypothesis	O
motivating	O
semi-supervised	B
learning	I
via	O
unsupervised	O
representation	B
learning	I
is	O
that	O
for	O
many	O
ai	O
tasks	O
these	O
two	O
properties	O
coincide	O
once	O
we	O
are	O
able	O
to	O
obtain	O
the	O
underlying	O
explanations	O
for	O
what	O
we	O
observe	O
it	O
generally	O
becomes	O
easy	O
to	O
isolate	O
individual	O
attributes	O
from	O
the	O
others	O
specifically	O
if	O
a	O
representation	O
h	O
represents	O
many	O
of	O
the	O
underlying	O
causes	O
of	O
the	O
observed	O
x	O
and	O
the	O
outputs	O
y	O
are	O
among	O
the	O
most	O
salient	O
causes	O
then	O
it	O
is	O
easy	O
to	O
predict	O
from	O
h	O
y	O
first	O
let	O
us	O
see	O
how	O
semi-supervised	B
learning	I
can	O
fail	O
because	O
unsupervised	O
consider	O
for	O
example	B
the	O
case	O
x	O
clearly	O
y	O
x	O
learning	O
of	O
px	O
is	O
of	O
no	O
help	O
to	O
learn	O
py	O
x	O
where	O
px	O
is	O
uniformly	O
distributed	O
and	O
we	O
want	O
to	O
learn	O
f	O
ey	O
observing	O
a	O
training	O
set	O
of	O
values	O
alone	O
gives	O
us	O
no	O
information	O
about	O
p	O
x	O
chapter	O
representation	B
learning	I
x	O
p	O
x	O
figure	O
example	B
of	O
a	O
density	O
over	O
x	O
that	O
is	O
a	O
mixture	O
over	O
three	O
components	O
the	O
component	O
identity	O
is	O
an	O
underlying	O
explanatory	O
factor	O
y	O
because	O
the	O
mixture	O
components	O
natural	O
object	O
classes	O
in	O
image	O
data	O
are	O
statistically	O
salient	O
just	O
modeling	O
p	O
x	O
in	O
an	O
unsupervised	O
way	O
with	O
no	O
labeled	O
example	B
already	O
reveals	O
the	O
factor	O
y	O
next	O
let	O
us	O
see	O
a	O
simple	O
example	B
of	O
how	O
semi-supervised	B
learning	I
can	O
succeed	O
consider	O
the	O
situation	O
where	O
x	O
arises	O
from	O
a	O
mixture	O
with	O
one	O
mixture	O
component	O
per	O
value	O
of	O
y	O
as	O
illustrated	O
in	O
figure	O
if	O
the	O
mixture	O
components	O
are	O
wellseparated	O
then	O
modeling	O
px	O
reveals	O
precisely	O
where	O
each	O
component	O
is	O
and	O
a	O
single	O
labeled	O
example	B
of	O
each	O
class	O
will	O
then	O
be	O
enough	O
to	O
perfectly	O
learn	O
py	O
x	O
but	O
more	O
generally	O
what	O
could	O
make	O
be	O
tied	O
together	O
y	O
x	O
p	O
and	O
p	O
x	O
if	O
y	O
is	O
closely	O
associated	O
with	O
one	O
of	O
the	O
causal	O
factors	O
of	O
x	O
then	O
px	O
and	O
py	O
will	O
be	O
strongly	O
tied	O
and	O
unsupervised	O
representation	B
learning	I
that	O
tries	O
to	O
disentangle	O
the	O
underlying	O
factors	B
of	I
variation	I
is	O
likely	O
to	O
be	O
useful	O
as	O
a	O
semi-supervised	B
learning	I
strategy	O
consider	O
the	O
assumption	O
that	O
y	O
is	O
one	O
of	O
the	O
causal	O
factors	O
of	O
x	O
and	O
let	O
h	O
represent	O
all	O
those	O
factors	O
the	O
true	O
generative	O
process	O
can	O
be	O
conceived	O
as	O
structured	O
according	O
to	O
this	O
directed	O
graphical	O
model	O
with	O
x	O
as	O
the	O
parent	O
of	O
h	O
as	O
a	O
consequence	O
the	O
data	O
has	O
marginal	B
probability	I
p	O
x	O
p	O
p	O
x	O
h	O
p	O
x	O
x	O
h	O
ehp	O
from	O
this	O
straightforward	O
observation	O
we	O
conclude	O
that	O
the	O
best	O
possible	O
model	O
of	O
x	O
a	O
generalization	B
point	O
of	O
view	O
is	O
the	O
one	O
that	O
uncovers	O
the	O
above	O
true	O
chapter	O
representation	B
learning	I
structure	O
with	O
h	O
as	O
a	O
latent	B
variable	I
that	O
explains	O
the	O
observed	O
variations	O
in	O
x	O
the	O
ideal	O
representation	B
learning	I
discussed	O
above	O
should	O
thus	O
recover	O
these	O
latent	O
factors	O
if	O
y	O
is	O
one	O
of	O
these	O
closely	O
related	O
to	O
one	O
of	O
them	O
then	O
it	O
will	O
be	O
very	O
easy	O
to	O
learn	O
to	O
predict	O
y	O
from	O
such	O
a	O
representation	O
we	O
also	O
see	O
that	O
the	O
conditional	O
distribution	O
of	O
y	O
given	O
x	O
is	O
tied	O
by	O
bayes	O
rule	O
to	O
the	O
components	O
in	O
the	O
above	O
equation	O
p	O
y	O
x	O
p	O
x	O
y	O
p	O
p	O
thus	O
the	O
marginal	O
px	O
is	O
intimately	O
tied	O
to	O
the	O
conditional	O
py	O
x	O
and	O
knowledge	O
of	O
the	O
structure	O
of	O
the	O
former	O
should	O
be	O
helpful	O
to	O
learn	O
the	O
latter	O
therefore	O
in	O
situations	O
respecting	O
these	O
assumptions	O
semi-supervised	B
learning	I
should	O
improve	O
performance	O
an	O
important	O
research	O
problem	O
regards	O
the	O
fact	O
that	O
most	O
observations	O
are	O
formed	O
by	O
an	O
extremely	O
large	O
number	O
of	O
underlying	O
causes	O
suppose	O
y	O
hi	O
but	O
the	O
unsupervised	O
learner	O
does	O
not	O
know	O
which	O
hi	O
the	O
brute	O
force	O
solution	O
is	O
for	O
an	O
unsupervised	O
learner	O
to	O
learn	O
a	O
representation	O
that	O
captures	O
the	O
reasonably	O
salient	O
generative	O
factors	O
hj	O
and	O
disentangles	O
them	O
from	O
each	O
other	O
thus	O
making	O
it	O
easy	O
to	O
predict	O
from	O
regardless	O
of	O
which	O
h	O
i	O
is	O
associated	O
with	O
all	O
h	O
y	O
in	O
practice	O
the	O
brute	O
force	O
solution	O
is	O
not	O
feasible	O
because	O
it	O
is	O
not	O
possible	O
to	O
capture	O
all	O
or	O
most	O
of	O
the	O
factors	B
of	I
variation	I
that	O
influence	O
an	O
observation	O
for	O
example	B
in	O
a	O
visual	O
scene	O
should	O
the	O
representation	O
always	O
encode	O
all	O
of	O
the	O
smallest	O
objects	O
in	O
the	O
background	O
it	O
is	O
a	O
well-documented	O
psychological	O
phenomenon	O
that	O
human	O
beings	O
fail	O
to	O
perceive	O
changes	O
in	O
their	O
environment	O
that	O
are	O
not	O
immediately	O
relevant	O
to	O
the	O
task	O
they	O
are	O
performing	O
see	O
e	O
g	O
simons	O
and	O
levin	O
an	O
important	O
research	O
frontier	O
in	O
semi-supervised	B
learning	I
is	O
determining	O
what	O
to	O
encode	O
in	O
each	O
situation	O
currently	O
two	O
of	O
the	O
main	O
strategies	O
for	O
dealing	O
with	O
a	O
large	O
number	O
of	O
underlying	O
causes	O
are	O
to	O
use	O
a	O
supervised	B
learning	I
signal	O
at	O
the	O
same	O
time	O
as	O
the	O
unsupervised	O
learning	O
signal	O
so	O
that	O
the	O
model	O
will	O
choose	O
to	O
capture	O
the	O
most	O
relevant	O
factors	B
of	I
variation	I
or	O
to	O
use	O
much	O
larger	O
representations	O
if	O
using	O
purely	O
unsupervised	O
learning	O
an	O
emerging	O
strategy	O
for	O
unsupervised	O
learning	O
is	O
to	O
modify	O
the	O
definition	O
of	O
which	O
underlying	O
causes	O
are	O
most	O
salient	O
historically	O
autoencoders	O
and	O
generative	O
models	O
have	O
been	O
trained	O
to	O
optimize	O
a	O
fixed	O
criterion	O
often	O
similar	O
to	O
mean	B
squared	I
error	I
these	O
fixed	O
criteria	O
determine	O
which	O
causes	O
are	O
considered	O
salient	O
for	O
example	B
mean	B
squared	I
error	I
applied	O
to	O
the	O
pixels	O
of	O
an	O
image	O
implicitly	O
specifies	O
that	O
an	O
underlying	O
cause	O
is	O
only	O
salient	O
if	O
it	O
significantly	O
changes	O
the	O
brightness	O
of	O
a	O
large	O
number	O
of	O
pixels	O
this	O
can	O
be	O
problematic	O
if	O
the	O
task	O
we	O
wish	O
to	O
solve	O
involves	O
interacting	O
with	O
small	O
objects	O
see	O
figure	O
for	O
an	O
example	B
chapter	O
representation	B
learning	I
input	O
reconstruction	O
figure	O
an	O
autoencoder	O
trained	O
with	O
mean	B
squared	I
error	I
for	O
a	O
robotics	O
task	O
has	O
failed	O
to	O
reconstruct	O
a	O
ping	O
pong	O
ball	O
the	O
existence	O
of	O
the	O
ping	O
pong	O
ball	O
and	O
all	O
of	O
its	O
spatial	O
coordinates	O
are	O
important	O
underlying	O
causal	O
factors	O
that	O
generate	O
the	O
image	O
and	O
are	O
relevant	O
to	O
the	O
robotics	O
task	O
unfortunately	O
the	O
autoencoder	O
has	O
limited	O
capacity	O
and	O
the	O
training	O
with	O
mean	B
squared	I
error	I
did	O
not	O
identify	O
the	O
ping	O
pong	O
ball	O
as	O
being	O
salient	O
enough	O
to	O
encode	O
images	O
graciously	O
provided	O
by	O
chelsea	O
finn	O
of	O
a	O
robotics	O
task	O
in	O
which	O
an	O
autoencoder	O
has	O
failed	O
to	O
learn	O
to	O
encode	O
a	O
small	O
ping	O
pong	O
ball	O
this	O
same	O
robot	O
is	O
capable	O
of	O
successfully	O
interacting	O
with	O
larger	O
objects	O
such	O
as	O
baseballs	O
which	O
are	O
more	O
salient	O
according	O
to	O
mean	B
squared	I
error	I
other	O
definitions	O
of	O
salience	O
are	O
possible	O
for	O
example	B
if	O
a	O
group	O
of	O
pixels	O
follow	O
a	O
highly	O
recognizable	O
pattern	O
even	O
if	O
that	O
pattern	O
does	O
not	O
involve	O
extreme	O
brightness	O
or	O
darkness	O
then	O
that	O
pattern	O
could	O
be	O
considered	O
extremely	O
salient	O
one	O
way	O
to	O
implement	O
such	O
a	O
definition	O
of	O
salience	O
is	O
to	O
use	O
a	O
recently	O
developed	O
approach	O
called	O
generative	O
adversarial	O
networks	O
goodfellow	O
et	O
al	O
in	O
this	O
approach	O
a	O
generative	O
model	O
is	O
trained	O
to	O
fool	O
a	O
feedforward	O
classifier	O
the	O
feedforward	O
classifier	O
attempts	O
to	O
recognize	O
all	O
samples	O
from	O
the	O
generative	O
model	O
as	O
being	O
fake	O
and	O
all	O
samples	O
from	O
the	O
training	O
set	O
as	O
being	O
real	O
in	O
this	O
framework	O
any	O
structured	O
pattern	O
that	O
the	O
feedforward	O
network	O
can	O
recognize	O
is	O
highly	O
salient	O
the	O
generative	O
adversarial	O
network	O
will	O
be	O
described	O
in	O
more	O
detail	O
for	O
the	O
purposes	O
of	O
the	O
present	O
discussion	O
it	O
is	O
sufficient	O
to	O
in	O
section	O
understand	O
that	O
they	O
learn	O
how	O
to	O
determine	O
what	O
is	O
salient	O
lotter	O
et	O
al	O
showed	O
that	O
models	O
trained	O
to	O
generate	O
images	O
of	O
human	O
heads	O
will	O
often	O
neglect	O
to	O
generate	O
the	O
ears	O
when	O
trained	O
with	O
mean	B
squared	I
error	I
but	O
will	O
successfully	O
generate	O
the	O
ears	O
when	O
trained	O
with	O
the	O
adversarial	O
framework	O
because	O
the	O
ears	O
are	O
not	O
extremely	O
bright	O
or	O
dark	O
compared	O
to	O
the	O
surrounding	O
skin	O
they	O
are	O
not	O
especially	O
salient	O
according	O
to	O
mean	B
squared	I
error	I
loss	O
but	O
their	O
highly	O
chapter	O
representation	B
learning	I
ground	O
truth	O
mse	O
adversarial	O
figure	O
predictive	O
generative	O
networks	O
provide	O
an	O
example	B
of	O
the	O
importance	O
of	O
learning	O
which	O
features	O
are	O
salient	O
in	O
this	O
example	B
the	O
predictive	O
generative	O
network	O
has	O
been	O
trained	O
to	O
predict	O
the	O
appearance	O
of	O
a	O
model	O
of	O
a	O
human	O
head	O
at	O
a	O
specific	O
viewing	O
angle	O
truth	O
this	O
is	O
the	O
correct	O
image	O
that	O
the	O
network	O
should	O
emit	O
image	O
produced	O
by	O
a	O
predictive	O
generative	O
network	O
trained	O
with	O
mean	B
squared	I
error	I
alone	O
because	O
the	O
ears	O
do	O
not	O
cause	O
an	O
extreme	O
difference	O
in	O
brightness	O
compared	O
to	O
the	O
neighboring	O
skin	O
they	O
were	O
not	O
sufficiently	O
salient	O
for	O
the	O
model	O
to	O
learn	O
to	O
represent	O
them	O
produced	O
by	O
a	O
model	O
trained	O
with	O
a	O
combination	O
of	O
mean	B
squared	I
error	I
and	O
adversarial	O
loss	O
using	O
this	O
learned	O
cost	O
function	O
the	O
ears	O
are	O
salient	O
because	O
they	O
follow	O
a	O
predictable	O
pattern	O
learning	O
which	O
underlying	O
causes	O
are	O
important	O
and	O
relevant	O
enough	O
to	O
model	O
is	O
an	O
important	O
active	O
area	O
of	O
research	O
figures	O
graciously	O
provided	O
by	O
lotter	O
et	O
al	O
recognizable	O
shape	O
and	O
consistent	O
position	O
means	O
that	O
a	O
feedforward	O
network	O
can	O
easily	O
learn	O
to	O
detect	O
them	O
making	O
them	O
highly	O
salient	O
under	O
the	O
generative	O
adversarial	O
framework	O
see	O
figure	O
for	O
example	B
images	O
generative	O
adversarial	O
networks	O
are	O
only	O
one	O
step	O
toward	O
determining	O
which	O
factors	O
should	O
be	O
represented	O
we	O
expect	O
that	O
future	O
research	O
will	O
discover	O
better	O
ways	O
of	O
determining	O
which	O
factors	O
to	O
represent	O
and	O
develop	O
mechanisms	O
for	O
representing	O
different	O
factors	O
depending	O
on	O
the	O
task	O
is	O
that	O
if	O
the	O
true	O
generative	O
process	O
has	O
a	O
benefit	O
of	O
learning	O
the	O
underlying	O
causal	O
factors	O
as	O
pointed	O
out	O
by	O
sch	O
lkopf	O
et	O
al	O
x	O
as	O
an	O
effect	O
and	O
y	O
as	O
a	O
cause	O
then	O
modeling	O
px	O
y	O
is	O
robust	O
to	O
changes	O
in	O
py	O
if	O
the	O
cause-effect	O
relationship	O
was	O
reversed	O
this	O
would	O
not	O
be	O
true	O
since	O
by	O
bayes	O
rule	O
p	O
x	O
y	O
would	O
be	O
sensitive	O
to	O
changes	O
in	O
py	O
very	O
often	O
when	O
we	O
consider	O
changes	O
in	O
distribution	O
due	O
to	O
different	O
domains	O
temporal	O
non-stationarity	O
or	O
changes	O
in	O
the	O
nature	O
of	O
the	O
task	O
the	O
causal	O
mechanisms	O
remain	O
invariant	O
laws	O
of	O
the	O
universe	O
are	O
constant	O
while	O
the	O
marginal	O
distribution	O
over	O
the	O
underlying	O
causes	O
can	O
change	O
hence	O
better	O
generalization	B
and	O
robustness	O
to	O
all	O
kinds	O
of	O
changes	O
can	O
chapter	O
representation	B
learning	I
be	O
expected	O
via	O
learning	O
a	O
generative	O
model	O
that	O
attempts	O
to	O
recover	O
the	O
causal	O
factors	O
x	O
h	O
p	O
h	O
and	O
distributed	O
representation	O
distributed	O
representations	O
of	O
concepts	O
representations	O
composed	O
of	O
many	O
elements	O
that	O
can	O
be	O
set	O
separately	O
from	O
each	O
other	O
are	O
one	O
of	O
the	O
most	O
important	O
tools	O
for	O
representation	B
learning	I
distributed	O
representations	O
are	O
powerful	O
because	O
they	O
can	O
use	O
n	O
features	O
with	O
k	O
values	O
to	O
describe	O
k	O
n	O
different	O
concepts	O
as	O
we	O
have	O
seen	O
throughout	O
this	O
book	O
both	O
neural	O
networks	O
with	O
multiple	O
hidden	O
units	O
and	O
probabilistic	O
models	O
with	O
multiple	O
latent	O
variables	O
make	O
use	O
of	O
the	O
strategy	O
of	O
distributed	O
representation	O
we	O
now	O
introduce	O
an	O
additional	O
observation	O
many	O
deep	O
learning	O
algorithms	O
are	O
motivated	O
by	O
the	O
assumption	O
that	O
the	O
hidden	O
units	O
can	O
learn	O
to	O
represent	O
the	O
underlying	O
causal	O
factors	O
that	O
explain	O
the	O
data	O
as	O
discussed	O
in	O
section	O
distributed	O
representations	O
are	O
natural	O
for	O
this	O
approach	O
because	O
each	O
direction	O
in	O
representation	O
space	O
can	O
correspond	O
to	O
the	O
value	O
of	O
a	O
different	O
underlying	O
configuration	O
variable	O
an	O
example	B
of	O
a	O
distributed	O
representation	O
is	O
a	O
vector	O
of	O
n	O
binary	O
features	O
which	O
can	O
take	O
n	O
configurations	O
each	O
potentially	O
corresponding	O
to	O
a	O
different	O
region	O
in	O
input	O
space	O
as	O
illustrated	O
in	O
figure	O
this	O
can	O
be	O
compared	O
with	O
a	O
symbolic	O
representation	O
where	O
the	O
input	O
is	O
associated	O
with	O
a	O
single	O
symbol	O
or	O
category	O
if	O
there	O
are	O
n	O
symbols	O
in	O
the	O
dictionary	O
one	O
can	O
imagine	O
n	O
feature	B
detectors	O
each	O
corresponding	O
to	O
the	O
detection	O
of	O
the	O
presence	O
of	O
the	O
associated	O
category	O
in	O
that	O
case	O
only	O
n	O
different	O
configurations	O
of	O
the	O
representation	O
space	O
are	O
possible	O
carving	O
n	O
different	O
regions	O
in	O
input	O
space	O
as	O
illustrated	O
in	O
figure	O
such	O
a	O
symbolic	O
representation	O
is	O
also	O
called	O
a	O
one-hot	O
representation	O
since	O
it	O
can	O
be	O
captured	O
by	O
a	O
binary	O
vector	O
with	O
n	O
bits	O
that	O
are	O
mutually	O
exclusive	O
one	O
of	O
them	O
can	O
be	O
active	O
a	O
symbolic	O
representation	O
is	O
a	O
specific	O
example	B
of	O
the	O
broader	O
class	O
of	O
non-distributed	O
representations	O
which	O
are	O
representations	O
that	O
may	O
contain	O
many	O
entries	O
but	O
without	O
significant	O
meaningful	O
separate	O
control	O
over	O
each	O
entry	O
examples	O
of	O
learning	O
algorithms	O
based	O
on	O
non-distributed	O
representations	O
include	O
clustering	O
methods	O
including	O
the	O
k-means	O
algorithm	O
each	O
input	O
point	O
is	O
assigned	O
to	O
exactly	O
one	O
cluster	O
k-nearest	O
neighbors	O
algorithms	O
one	O
or	O
a	O
few	O
templates	O
or	O
prototype	O
examples	O
are	O
associated	O
with	O
a	O
given	O
input	O
in	O
the	O
case	O
of	O
k	O
there	O
are	O
multiple	O
chapter	O
representation	B
learning	I
h	O
h	O
h	O
h	O
h	O
h	O
h	O
i	O
h	O
into	O
two	O
half-planes	O
let	O
h	O
corresponds	O
to	O
the	O
region	O
h	O
figure	O
illustration	O
of	O
how	O
a	O
learning	O
algorithm	O
based	O
on	O
a	O
distributed	O
representation	O
breaks	O
up	O
the	O
input	O
space	O
into	O
regions	O
in	O
this	O
example	B
there	O
are	O
three	O
binary	O
features	O
and	O
each	O
feature	B
is	O
defined	O
by	O
thresholding	O
the	O
output	O
of	O
a	O
learned	O
linear	O
transformation	O
each	O
feature	B
divides	O
r	O
i	O
be	O
the	O
set	O
of	O
input	O
be	O
the	O
set	O
of	O
input	O
points	O
for	O
which	O
hi	O
in	O
this	O
points	O
for	O
which	O
hi	O
and	O
h	O
illustration	O
each	O
line	O
represents	O
the	O
decision	O
boundary	O
for	O
one	O
hi	O
with	O
the	O
corresponding	O
arrow	O
pointing	O
to	O
the	O
h	O
i	O
side	O
of	O
the	O
boundary	O
the	O
representation	O
as	O
a	O
whole	O
takes	O
on	O
a	O
unique	O
value	O
at	O
each	O
possible	O
intersection	O
of	O
these	O
half-planes	O
for	O
example	B
the	O
representation	O
value	O
compare	O
this	O
to	O
the	O
h	O
non-distributed	O
representations	O
in	O
figure	O
d	O
input	O
dimensions	O
in	O
the	O
general	O
case	O
of	O
a	O
distributed	O
representation	O
divides	O
r	O
d	O
by	O
intersecting	O
half-spaces	O
rather	O
than	O
half-planes	O
the	O
distributed	O
representation	O
with	O
n	O
features	O
assigns	O
unique	O
codes	O
to	O
ond	O
different	O
regions	O
while	O
the	O
nearest	O
neighbor	O
algorithm	O
with	O
n	O
examples	O
assigns	O
unique	O
codes	O
to	O
only	O
n	O
regions	O
the	O
distributed	O
representation	O
is	O
thus	O
able	O
to	O
distinguish	O
exponentially	O
many	O
more	O
regions	O
than	O
the	O
non-distributed	O
one	O
keep	O
in	O
mind	O
that	O
not	O
all	O
h	O
values	O
are	O
feasible	O
is	O
no	O
h	O
in	O
this	O
example	B
and	O
that	O
a	O
linear	O
classifier	O
on	O
top	O
of	O
the	O
distributed	O
representation	O
is	O
not	O
able	O
to	O
assign	O
different	O
class	O
identities	O
to	O
every	O
neighboring	O
region	O
even	O
a	O
deep	O
linear-threshold	O
network	O
has	O
a	O
vc	O
dimension	O
of	O
only	O
ow	O
wlog	O
where	O
w	O
is	O
the	O
number	O
of	O
weights	B
the	O
combination	O
of	O
a	O
powerful	O
representation	O
layer	O
and	O
a	O
weak	O
classifier	O
layer	O
can	O
be	O
a	O
strong	O
regularizer	B
a	O
classifier	O
trying	O
to	O
learn	O
the	O
concept	O
of	O
person	O
versus	O
not	O
a	O
person	O
does	O
not	O
need	O
to	O
assign	O
a	O
different	O
class	O
to	O
an	O
input	O
represented	O
as	O
woman	O
with	O
glasses	O
than	O
it	O
assigns	O
to	O
an	O
input	O
represented	O
as	O
man	O
without	O
glasses	O
this	O
capacity	O
constraint	O
encourages	O
each	O
classifier	O
to	O
focus	O
on	O
few	O
hi	O
and	O
encourages	O
to	O
learn	O
to	O
represent	O
the	O
classes	O
in	O
a	O
linearly	O
separable	O
way	O
sontag	O
h	O
chapter	O
representation	B
learning	I
values	O
describing	O
each	O
input	O
but	O
they	O
can	O
not	O
be	O
controlled	O
separately	O
from	O
each	O
other	O
so	O
this	O
does	O
not	O
qualify	O
as	O
a	O
true	O
distributed	O
representation	O
decision	O
trees	O
only	O
one	O
leaf	O
the	O
nodes	O
on	O
the	O
path	O
from	O
root	O
to	O
leaf	O
is	O
activated	O
when	O
an	O
input	O
is	O
given	O
gaussian	O
mixtures	O
and	O
mixtures	O
of	O
experts	O
the	O
templates	O
centers	O
or	O
experts	O
are	O
now	O
associated	O
with	O
a	O
degree	O
of	O
activation	O
as	O
with	O
the	O
k-nearest	O
neighbors	O
algorithm	O
each	O
input	O
is	O
represented	O
with	O
multiple	O
values	O
but	O
those	O
values	O
cannot	O
readily	O
be	O
controlled	O
separately	O
from	O
each	O
other	O
kernel	O
machines	O
with	O
a	O
gaussian	B
kernel	I
other	O
similarly	O
local	O
kernel	O
although	O
the	O
degree	O
of	O
activation	O
of	O
each	O
support	O
vector	O
or	O
template	O
example	B
is	O
now	O
continuous-valued	O
the	O
same	O
issue	O
arises	O
as	O
with	O
gaussian	O
mixtures	O
language	O
or	O
translation	O
models	O
based	O
on	O
n-grams	O
the	O
set	O
of	O
contexts	O
of	O
symbols	O
is	O
partitioned	O
according	O
to	O
a	O
tree	O
structure	O
of	O
suffixes	O
a	O
leaf	O
may	O
correspond	O
to	O
the	O
last	O
two	O
words	O
being	O
and	O
for	O
example	B
separate	O
parameters	O
are	O
estimated	O
for	O
each	O
leaf	O
of	O
the	O
tree	O
some	O
sharing	O
being	O
possible	O
for	O
some	O
of	O
these	O
non-distributed	O
algorithms	O
the	O
output	O
is	O
not	O
constant	O
by	O
parts	O
but	O
instead	O
interpolates	O
between	O
neighboring	O
regions	O
the	O
relationship	O
between	O
the	O
number	O
of	O
parameters	O
examples	O
and	O
the	O
number	O
of	O
regions	O
they	O
can	O
define	O
remains	O
linear	O
an	O
important	O
related	O
concept	O
that	O
distinguishes	O
a	O
distributed	O
representation	O
from	O
a	O
symbolic	O
one	O
is	O
that	O
generalization	B
arises	O
due	O
to	O
shared	O
attributes	O
between	O
different	O
concepts	O
as	O
pure	O
symbols	O
cat	O
and	O
dog	O
are	O
as	O
far	O
from	O
each	O
other	O
as	O
any	O
other	O
two	O
symbols	O
however	O
if	O
one	O
associates	O
them	O
with	O
a	O
meaningful	O
distributed	O
representation	O
then	O
many	O
of	O
the	O
things	O
that	O
can	O
be	O
said	O
about	O
cats	O
can	O
generalize	O
to	O
dogs	O
and	O
vice-versa	O
for	O
example	B
our	O
distributed	O
representation	O
may	O
contain	O
entries	O
such	O
as	O
has	O
fur	O
or	O
number	O
of	O
legs	O
that	O
have	O
the	O
same	O
value	O
for	O
the	O
embedding	B
of	O
both	O
cat	O
and	O
dog	O
neural	O
language	O
models	O
that	O
operate	O
on	O
distributed	O
representations	O
of	O
words	O
generalize	O
much	O
better	O
than	O
other	O
models	O
that	O
operate	O
directly	O
on	O
one-hot	O
representations	O
of	O
words	O
as	O
discussed	O
in	O
section	O
similarity	O
space	O
in	O
which	O
semantically	O
close	O
concepts	O
inputs	O
are	O
close	O
in	O
distance	O
a	O
property	O
that	O
is	O
absent	O
from	O
purely	O
symbolic	O
representations	O
distributed	O
representations	O
induce	O
a	O
rich	O
when	O
and	O
why	O
can	O
there	O
be	O
a	O
statistical	O
advantage	O
from	O
using	O
a	O
distributed	O
representation	O
as	O
part	O
of	O
a	O
learning	O
algorithm	O
distributed	O
representations	O
can	O
chapter	O
representation	B
learning	I
figure	O
illustration	O
of	O
how	O
the	O
nearest	O
neighbor	O
algorithm	O
breaks	O
up	O
the	O
input	O
space	O
into	O
different	O
regions	O
the	O
nearest	O
neighbor	O
algorithm	O
provides	O
an	O
example	B
of	O
a	O
learning	O
algorithm	O
based	O
on	O
a	O
non-distributed	O
representation	O
different	O
non-distributed	O
algorithms	O
may	O
have	O
different	O
geometry	O
but	O
they	O
typically	O
break	O
the	O
input	O
space	O
into	O
regions	O
with	O
a	O
separate	O
set	O
of	O
parameters	O
for	O
each	O
region	O
the	O
advantage	O
of	O
a	O
non-distributed	O
approach	O
is	O
that	O
given	O
enough	O
parameters	O
it	O
can	O
fit	O
the	O
training	O
set	O
without	O
solving	O
a	O
difficult	O
optimization	O
algorithm	O
because	O
it	O
is	O
straightforward	O
to	O
choose	O
a	O
different	O
output	O
independently	O
for	O
each	O
region	O
the	O
disadvantage	O
is	O
that	O
such	O
non-distributed	O
models	O
generalize	O
only	O
locally	O
via	O
the	O
smoothness	O
prior	O
making	O
it	O
difficult	O
to	O
learn	O
a	O
complicated	O
function	O
with	O
more	O
peaks	O
and	O
troughs	O
than	O
the	O
available	O
number	O
of	O
examples	O
contrast	B
this	O
with	O
a	O
distributed	O
representation	O
figure	O
chapter	O
representation	B
learning	I
v	O
have	O
a	O
statistical	O
advantage	O
when	O
an	O
apparently	O
complicated	O
structure	O
can	O
be	O
compactly	O
represented	O
using	O
a	O
small	O
number	O
of	O
parameters	O
some	O
traditional	O
nondistributed	O
learning	O
algorithms	O
generalize	O
only	O
due	O
to	O
the	O
smoothness	O
assumption	O
then	O
the	O
target	O
function	O
f	O
to	O
be	O
learned	O
has	O
the	O
which	O
states	O
that	O
if	O
u	O
property	O
that	O
fu	O
fv	O
in	O
general	O
there	O
are	O
many	O
ways	O
of	O
formalizing	O
such	O
an	O
assumption	O
but	O
the	O
end	O
result	O
is	O
that	O
if	O
we	O
have	O
an	O
example	B
y	O
for	O
which	O
we	O
y	O
then	O
we	O
choose	O
an	O
estimator	O
f	O
that	O
approximately	O
satisfies	O
know	O
that	O
f	O
these	O
constraints	O
while	O
changing	O
as	O
little	O
as	O
possible	O
when	O
we	O
move	O
to	O
a	O
nearby	O
input	O
x	O
this	O
assumption	O
is	O
clearly	O
very	O
useful	O
but	O
it	O
suffers	O
from	O
the	O
curse	B
of	I
dimensionality	I
in	O
order	O
to	O
learn	O
a	O
target	O
function	O
that	O
increases	O
and	O
decreases	O
many	O
times	O
in	O
many	O
different	O
we	O
may	O
need	O
a	O
number	O
of	O
examples	O
that	O
is	O
at	O
least	O
as	O
large	O
as	O
the	O
number	O
of	O
distinguishable	O
regions	O
one	O
can	O
think	O
of	O
each	O
of	O
these	O
regions	O
as	O
a	O
category	O
or	O
symbol	O
by	O
having	O
a	O
separate	O
degree	O
of	O
freedom	O
for	O
each	O
symbol	O
region	O
we	O
can	O
learn	O
an	O
arbitrary	O
decoder	B
mapping	O
from	O
symbol	O
to	O
value	O
however	O
this	O
does	O
not	O
allow	O
us	O
to	O
generalize	O
to	O
new	O
symbols	O
for	O
new	O
regions	O
if	O
we	O
are	O
lucky	O
there	O
may	O
be	O
some	O
regularity	O
in	O
the	O
target	O
function	O
besides	O
being	O
smooth	O
for	O
example	B
a	O
convolutional	B
network	I
with	O
max-pooling	O
can	O
recognize	O
an	O
object	O
regardless	O
of	O
its	O
location	O
in	O
the	O
image	O
even	O
though	O
spatial	O
translation	O
of	O
the	O
object	O
may	O
not	O
correspond	O
to	O
smooth	O
transformations	O
in	O
the	O
input	O
space	O
let	O
us	O
examine	O
a	O
special	O
case	O
of	O
a	O
distributed	O
representation	B
learning	I
algorithm	O
that	O
extracts	O
binary	O
features	O
by	O
thresholding	O
linear	O
functions	O
of	O
the	O
input	O
each	O
d	O
into	O
a	O
pair	O
of	O
half-spaces	O
as	O
binary	O
feature	B
in	O
this	O
representation	O
divides	O
r	O
n	O
illustrated	O
in	O
figure	O
of	O
the	O
corresponding	O
half-spaces	O
determines	O
how	O
many	O
regions	O
this	O
distributed	O
representation	O
learner	O
can	O
distinguish	O
how	O
many	O
regions	O
are	O
generated	O
by	O
an	O
d	O
by	O
applying	O
a	O
general	O
result	O
concerning	O
the	O
arrangement	O
of	O
n	O
hyperplanes	O
in	O
r	O
intersection	O
of	O
hyperplanes	O
that	O
the	O
number	O
of	O
regions	O
this	O
binary	O
feature	B
representation	O
can	O
distinguish	O
is	O
the	O
exponentially	O
large	O
number	O
of	O
intersections	O
of	O
one	O
can	O
show	O
zaslavsky	O
pascanu	O
et	O
al	O
d	O
n	O
j	O
nd	O
therefore	O
we	O
see	O
a	O
growth	O
that	O
is	O
exponential	O
in	O
the	O
input	O
size	O
and	O
polynomial	O
in	O
the	O
number	O
of	O
hidden	O
units	O
potentially	O
we	O
may	O
want	O
to	O
learn	O
a	O
function	O
whose	O
behavior	O
is	O
distinct	O
in	O
exponentially	O
many	O
regions	O
in	O
a	O
d-dimensional	O
space	O
with	O
at	O
least	O
different	O
values	O
to	O
distinguish	O
per	O
dimension	O
we	O
might	O
want	O
different	O
regions	O
requiring	O
d	O
training	O
examples	O
to	O
differ	O
in	O
f	O
chapter	O
representation	B
learning	I
this	O
provides	O
a	O
geometric	O
argument	O
to	O
explain	O
the	O
generalization	B
power	O
of	O
distributed	O
representation	O
with	O
ond	O
parameters	O
n	O
linear-threshold	O
features	O
d	O
we	O
can	O
distinctly	O
represent	O
ond	O
regions	O
in	O
input	O
space	O
if	O
instead	O
we	O
made	O
in	O
r	O
no	O
assumption	O
at	O
all	O
about	O
the	O
data	O
and	O
used	O
a	O
representation	O
with	O
one	O
unique	O
symbol	O
for	O
each	O
region	O
and	O
separate	O
parameters	O
for	O
each	O
symbol	O
to	O
recognize	O
its	O
d	O
then	O
specifying	O
ond	O
regions	O
would	O
require	O
ond	O
corresponding	O
portion	O
of	O
r	O
examples	O
more	O
generally	O
the	O
argument	O
in	O
favor	O
of	O
the	O
distributed	O
representation	O
could	O
be	O
extended	O
to	O
the	O
case	O
where	O
instead	O
of	O
using	O
linear	O
threshold	O
units	O
we	O
use	O
nonlinear	O
possibly	O
continuous	O
feature	B
extractors	O
for	O
each	O
of	O
the	O
attributes	O
in	O
the	O
distributed	O
representation	O
the	O
argument	O
in	O
this	O
case	O
is	O
that	O
if	O
a	O
parametric	O
transformation	O
with	O
k	O
parameters	O
can	O
learn	O
about	O
r	O
regions	O
in	O
input	O
space	O
with	O
k	O
and	O
if	O
obtaining	O
such	O
a	O
representation	O
was	O
useful	O
to	O
the	O
task	O
of	O
interest	O
then	O
we	O
could	O
potentially	O
generalize	O
much	O
better	O
in	O
this	O
way	O
than	O
in	O
a	O
non-distributed	O
setting	O
where	O
we	O
would	O
need	O
or	O
examples	O
to	O
obtain	O
the	O
same	O
features	O
and	O
associated	O
partitioning	O
of	O
the	O
input	O
space	O
into	O
r	O
regions	O
using	O
fewer	O
parameters	O
to	O
represent	O
the	O
model	O
means	O
that	O
we	O
have	O
fewer	O
parameters	O
to	O
fit	O
and	O
thus	O
require	O
far	O
fewer	O
training	O
examples	O
to	O
generalize	O
well	O
r	O
wlog	O
a	O
further	O
part	O
of	O
the	O
argument	O
for	O
why	O
models	O
based	O
on	O
distributed	O
representations	O
generalize	O
well	O
is	O
that	O
their	O
capacity	O
remains	O
limited	O
despite	O
being	O
able	O
to	O
distinctly	O
encode	O
so	O
many	O
different	O
regions	O
for	O
example	B
the	O
vc	O
dimension	O
of	O
a	O
neural	B
network	I
of	O
linear	O
threshold	O
units	O
is	O
only	O
ow	O
where	O
w	O
is	O
the	O
number	O
of	O
weights	B
this	O
limitation	O
arises	O
because	O
while	O
we	O
can	O
assign	O
very	O
many	O
unique	O
codes	O
to	O
representation	O
space	O
we	O
cannot	O
use	O
absolutely	O
all	O
of	O
the	O
code	O
space	O
nor	O
can	O
we	O
learn	O
arbitrary	O
functions	O
mapping	O
from	O
the	O
representation	O
space	O
h	O
to	O
the	O
output	O
y	O
using	O
a	O
linear	O
classifier	O
the	O
use	O
of	O
a	O
distributed	O
representation	O
combined	O
with	O
a	O
linear	O
classifier	O
thus	O
expresses	O
a	O
prior	O
belief	O
that	O
the	O
classes	O
to	O
be	O
recognized	O
are	O
linearly	O
separable	O
as	O
a	O
function	O
of	O
the	O
underlying	O
causal	O
factors	O
captured	O
by	O
h	O
we	O
will	O
typically	O
want	O
to	O
learn	O
categories	O
such	O
as	O
the	O
set	O
of	O
all	O
images	O
of	O
all	O
green	O
objects	O
or	O
the	O
set	O
of	O
all	O
images	O
of	O
cars	O
but	O
not	O
categories	O
that	O
require	O
nonlinear	O
xor	O
logic	O
for	O
example	B
we	O
typically	O
do	O
not	O
want	O
to	O
partition	O
the	O
data	O
into	O
the	O
set	O
of	O
all	O
red	O
cars	O
and	O
green	O
trucks	O
as	O
one	O
class	O
and	O
the	O
set	O
of	O
all	O
green	O
cars	O
and	O
red	O
trucks	O
as	O
another	O
class	O
zhou	O
et	O
al	O
the	O
ideas	O
discussed	O
so	O
far	O
have	O
been	O
abstract	O
but	O
they	O
may	O
be	O
experimentally	O
validated	O
find	O
that	O
hidden	O
units	O
in	O
a	O
deep	O
convolutional	B
network	I
trained	O
on	O
the	O
imagenet	O
and	O
places	O
benchmark	O
datasets	O
learn	O
features	O
that	O
are	O
very	O
often	O
interpretable	O
corresponding	O
to	O
a	O
label	O
that	O
humans	O
would	O
naturally	O
assign	O
in	O
practice	O
it	O
is	O
certainly	O
not	O
always	O
the	O
case	O
that	O
hidden	O
units	O
learn	O
something	O
that	O
has	O
a	O
simple	O
linguistic	O
name	O
but	O
it	O
is	O
interesting	O
to	O
see	O
this	O
emerge	O
near	O
the	O
top	O
levels	O
of	O
the	O
best	O
computer	B
vision	I
deep	O
networks	O
what	O
such	O
features	O
have	O
in	O
chapter	O
representation	B
learning	I
figure	O
a	O
generative	O
model	O
has	O
learned	O
a	O
distributed	O
representation	O
that	O
disentangles	O
the	O
concept	O
of	O
gender	O
from	O
the	O
concept	O
of	O
wearing	O
glasses	O
if	O
we	O
begin	O
with	O
the	O
representation	O
of	O
the	O
concept	O
of	O
a	O
man	O
with	O
glasses	O
then	O
subtract	O
the	O
vector	O
representing	O
the	O
concept	O
of	O
a	O
man	O
without	O
glasses	O
and	O
finally	O
add	O
the	O
vector	O
representing	O
the	O
concept	O
of	O
a	O
woman	O
without	O
glasses	O
we	O
obtain	O
the	O
vector	O
representing	O
the	O
concept	O
of	O
a	O
woman	O
with	O
glasses	O
the	O
generative	O
model	O
correctly	O
decodes	O
all	O
of	O
these	O
representation	O
vectors	O
to	O
images	O
that	O
may	O
be	O
recognized	O
as	O
belonging	O
to	O
the	O
correct	O
class	O
images	O
reproduced	O
with	O
permission	O
from	O
radford	O
et	O
al	O
radford	O
et	O
al	O
common	O
is	O
that	O
one	O
could	O
imagine	O
learning	O
about	O
each	O
of	O
them	O
without	O
having	O
to	O
see	O
all	O
the	O
configurations	O
of	O
all	O
the	O
others	O
demonstrated	O
that	O
a	O
generative	O
model	O
can	O
learn	O
a	O
representation	O
of	O
images	O
of	O
faces	O
with	O
separate	O
directions	O
in	O
representation	O
space	O
capturing	O
different	O
underlying	O
factors	B
of	I
variation	I
figure	O
demonstrates	O
that	O
one	O
direction	O
in	O
representation	O
space	O
corresponds	O
to	O
whether	O
the	O
person	O
is	O
male	O
or	O
female	O
while	O
another	O
corresponds	O
to	O
whether	O
the	O
person	O
is	O
wearing	O
glasses	O
these	O
features	O
were	O
discovered	O
automatically	O
not	O
fixed	O
a	O
priori	O
there	O
is	O
no	O
need	O
to	O
have	O
labels	O
for	O
the	O
hidden	O
unit	O
classifiers	O
gradient	B
descent	O
on	O
an	O
objective	B
function	I
of	O
interest	O
naturally	O
learns	O
semantically	O
interesting	O
features	O
so	O
long	O
as	O
the	O
task	O
requires	O
such	O
features	O
we	O
can	O
learn	O
about	O
the	O
distinction	O
between	O
male	O
and	O
female	O
or	O
about	O
the	O
presence	O
or	O
absence	O
of	O
glasses	O
without	O
having	O
to	O
characterize	O
all	O
of	O
the	O
configurations	O
of	O
the	O
n	O
other	O
features	O
by	O
examples	O
covering	O
all	O
of	O
these	O
combinations	O
of	O
values	O
this	O
form	O
of	O
statistical	O
separability	O
is	O
what	O
allows	O
one	O
to	O
generalize	O
to	O
new	O
configurations	O
of	O
a	O
person	O
s	O
features	O
that	O
have	O
never	O
been	O
seen	O
during	O
training	O
chapter	O
representation	B
learning	I
exponential	O
gains	O
from	O
depth	O
we	O
have	O
seen	O
in	O
section	O
that	O
multilayer	O
perceptrons	O
are	O
universal	O
approximators	O
and	O
that	O
some	O
functions	O
can	O
be	O
represented	O
by	O
exponentially	O
smaller	O
deep	O
networks	O
compared	O
to	O
shallow	O
networks	O
this	O
decrease	O
in	O
model	O
size	O
leads	O
to	O
improved	O
statistical	O
efficiency	O
in	O
this	O
section	O
we	O
describe	O
how	O
similar	O
results	O
apply	O
more	O
generally	O
to	O
other	O
kinds	O
of	O
models	O
with	O
distributed	O
hidden	O
representations	O
in	O
section	O
we	O
saw	O
an	O
example	B
of	O
a	O
generative	O
model	O
that	O
learned	O
about	O
the	O
explanatory	O
factors	O
underlying	O
images	O
of	O
faces	O
including	O
the	O
person	O
s	O
gender	O
and	O
whether	O
they	O
are	O
wearing	O
glasses	O
the	O
generative	O
model	O
that	O
accomplished	O
this	O
task	O
was	O
based	O
on	O
a	O
deep	O
neural	B
network	I
it	O
would	O
not	O
be	O
reasonable	O
to	O
expect	O
a	O
shallow	O
network	O
such	O
as	O
a	O
linear	O
network	O
to	O
learn	O
the	O
complicated	O
relationship	O
between	O
these	O
abstract	O
explanatory	O
factors	O
and	O
the	O
pixels	O
in	O
the	O
image	O
in	O
this	O
and	O
other	O
ai	O
tasks	O
the	O
factors	O
that	O
can	O
be	O
chosen	O
almost	O
independently	O
from	O
each	O
other	O
yet	O
still	O
correspond	O
to	O
meaningful	O
inputs	O
are	O
more	O
likely	O
to	O
be	O
very	O
high-level	O
and	O
related	O
in	O
highly	O
nonlinear	O
ways	O
to	O
the	O
input	O
we	O
argue	O
that	O
this	O
demands	O
deep	O
distributed	O
representations	O
where	O
the	O
higher	O
level	O
features	O
as	O
functions	O
of	O
the	O
input	O
or	O
factors	O
as	O
generative	O
causes	O
are	O
obtained	O
through	O
the	O
composition	O
of	O
many	O
nonlinearities	O
it	O
has	O
been	O
proven	O
in	O
many	O
different	O
settings	O
that	O
organizing	O
computation	O
through	O
the	O
composition	O
of	O
many	O
nonlinearities	O
and	O
a	O
hierarchy	O
of	O
reused	O
features	O
can	O
give	O
an	O
exponential	O
boost	O
to	O
statistical	O
efficiency	O
on	O
top	O
of	O
the	O
exponential	O
boost	O
given	O
by	O
using	O
a	O
distributed	O
representation	O
many	O
kinds	O
of	O
networks	O
with	O
saturating	O
nonlinearities	O
boolean	O
gates	O
sumproducts	O
or	O
rbf	B
units	O
with	O
a	O
single	O
hidden	B
layer	I
can	O
be	O
shown	O
to	O
be	O
universal	O
approximators	O
a	O
model	O
family	O
that	O
is	O
a	O
universal	B
approximator	I
can	O
approximate	O
a	O
large	O
class	O
of	O
functions	O
all	O
continuous	O
functions	O
up	O
to	O
any	O
non-zero	O
tolerance	O
level	O
given	O
enough	O
hidden	O
units	O
however	O
the	O
required	O
number	O
of	O
hidden	O
units	O
may	O
be	O
very	O
large	O
theoretical	O
results	O
concerning	O
the	O
expressive	O
power	O
of	O
deep	O
architectures	O
state	O
that	O
there	O
are	O
families	O
of	O
functions	O
that	O
can	O
be	O
represented	O
efficiently	O
by	O
an	O
architecture	O
of	O
depth	O
k	O
but	O
would	O
require	O
an	O
exponential	O
number	O
of	O
hidden	O
units	O
respect	O
to	O
the	O
input	O
size	O
with	O
insufficient	O
depth	O
or	O
depth	O
k	O
in	O
section	O
we	O
saw	O
that	O
deterministic	O
feedforward	O
networks	O
are	O
universal	O
approximators	O
of	O
functions	O
many	O
structured	O
probabilistic	O
models	O
with	O
a	O
single	O
hidden	B
layer	I
of	O
latent	O
variables	O
including	O
restricted	O
boltzmann	O
machines	O
and	O
deep	O
belief	O
networks	O
are	O
universal	O
approximators	O
of	O
probability	O
distributions	O
roux	O
and	O
bengio	O
mont	O
far	O
and	O
ay	O
mont	O
far	O
krause	O
et	O
al	O
chapter	O
representation	B
learning	I
in	O
section	O
we	O
saw	O
that	O
a	O
sufficiently	O
deep	O
feedforward	O
network	O
can	O
have	O
an	O
exponential	O
advantage	O
over	O
a	O
network	O
that	O
is	O
too	O
shallow	O
such	O
results	O
can	O
also	O
be	O
obtained	O
for	O
other	O
models	O
such	O
as	O
probabilistic	O
models	O
one	O
such	O
probabilistic	O
model	O
is	O
the	O
sum-product	B
network	I
or	O
spn	O
and	O
domingos	O
these	O
models	O
use	O
polynomial	O
circuits	O
to	O
compute	O
the	O
probability	B
distribution	I
over	O
a	O
set	O
of	O
random	O
variables	O
showed	O
that	O
there	O
exist	O
probability	O
distributions	O
for	O
which	O
a	O
minimum	O
depth	O
of	O
spn	O
is	O
required	O
to	O
avoid	O
needing	O
an	O
exponentially	O
large	O
model	O
later	O
martens	O
and	O
medabalimi	O
showed	O
that	O
there	O
are	O
significant	O
differences	O
between	O
every	O
two	O
finite	O
depths	O
of	O
spn	O
and	O
that	O
some	O
of	O
the	O
constraints	O
used	O
to	O
make	O
spns	O
tractable	O
may	O
limit	O
their	O
representational	O
power	O
delalleau	O
and	O
bengio	O
another	O
interesting	O
development	O
is	O
a	O
set	O
of	O
theoretical	O
results	O
for	O
the	O
expressive	O
power	O
of	O
families	O
of	O
deep	O
circuits	O
related	O
to	O
convolutional	O
nets	O
highlighting	O
an	O
exponential	O
advantage	O
for	O
the	O
deep	O
circuit	O
even	O
when	O
the	O
shallow	O
circuit	O
is	O
allowed	O
to	O
only	O
approximate	O
the	O
function	O
computed	O
by	O
the	O
deep	O
circuit	O
cohen	O
et	O
al	O
by	O
comparison	O
previous	O
theoretical	O
work	O
made	O
claims	O
regarding	O
only	O
the	O
case	O
where	O
the	O
shallow	O
circuit	O
must	O
exactly	O
replicate	O
particular	O
functions	O
providing	O
clues	O
to	O
discover	O
underlying	O
causes	O
to	O
close	O
this	O
chapter	O
we	O
come	O
back	O
to	O
one	O
of	O
our	O
original	O
questions	O
what	O
makes	O
one	O
representation	O
better	O
than	O
another	O
one	O
answer	O
first	O
introduced	O
in	O
section	O
is	O
that	O
an	O
ideal	O
representation	O
is	O
one	O
that	O
disentangles	O
the	O
underlying	O
causal	O
factors	B
of	I
variation	I
that	O
generated	O
the	O
data	O
especially	O
those	O
factors	O
that	O
are	O
relevant	O
to	O
our	O
applications	O
most	O
strategies	O
for	O
representation	B
learning	I
are	O
based	O
on	O
introducing	O
clues	O
that	O
help	O
the	O
learning	O
to	O
find	O
these	O
underlying	O
factors	O
of	O
variations	O
the	O
clues	O
can	O
help	O
the	O
learner	O
separate	O
these	O
observed	O
factors	O
from	O
the	O
others	O
supervised	B
learning	I
provides	O
a	O
very	O
strong	O
clue	O
a	O
label	O
y	O
presented	O
with	O
each	O
x	O
that	O
usually	O
specifies	O
the	O
value	O
of	O
at	O
least	O
one	O
of	O
the	O
factors	B
of	I
variation	I
directly	O
more	O
generally	O
to	O
make	O
use	O
of	O
abundant	O
unlabeled	O
data	O
representation	B
learning	I
makes	O
use	O
of	O
other	O
less	O
direct	O
hints	O
about	O
the	O
underlying	O
factors	O
these	O
hints	O
take	O
the	O
form	O
of	O
implicit	O
prior	O
beliefs	O
that	O
we	O
the	O
designers	O
of	O
the	O
learning	O
algorithm	O
impose	O
in	O
order	O
to	O
guide	O
the	O
learner	O
results	O
such	O
as	O
the	O
no	B
free	I
lunch	I
theorem	I
show	O
that	O
regularization	O
strategies	O
are	O
necessary	O
to	O
obtain	O
good	O
generalization	B
while	O
it	O
is	O
impossible	O
to	O
find	O
a	O
universally	O
superior	O
regularization	O
strategy	O
one	O
goal	O
of	O
deep	O
learning	O
is	O
to	O
find	O
a	O
set	O
of	O
fairly	O
generic	O
regularization	O
strategies	O
that	O
are	O
applicable	O
to	O
a	O
wide	O
variety	O
of	O
ai	O
tasks	O
similar	O
to	O
the	O
tasks	O
that	O
people	O
and	O
animals	O
are	O
able	O
to	O
solve	O
chapter	O
representation	B
learning	I
we	O
provide	O
here	O
a	O
list	O
of	O
these	O
generic	O
regularization	O
strategies	O
the	O
list	O
is	O
clearly	O
not	O
exhaustive	O
but	O
gives	O
some	O
concrete	O
examples	O
of	O
ways	O
that	O
learning	O
algorithms	O
can	O
be	O
encouraged	O
to	O
discover	O
features	O
that	O
correspond	O
to	O
underlying	O
factors	O
this	O
list	O
was	O
introduced	O
in	O
section	O
of	O
and	O
has	O
been	O
partially	O
expanded	O
here	O
bengio	O
et	O
al	O
smoothness	O
this	O
is	O
the	O
assumption	O
that	O
fx	O
d	O
f	O
for	O
unit	O
d	O
and	O
small	O
this	O
assumption	O
allows	O
the	O
learner	O
to	O
generalize	O
from	O
training	O
examples	O
to	O
nearby	O
points	O
in	O
input	O
space	O
many	O
machine	B
learning	I
algorithms	O
leverage	O
this	O
idea	O
but	O
it	O
is	O
insufficient	O
to	O
overcome	O
the	O
curse	B
of	I
dimensionality	I
linearity	O
many	O
learning	O
algorithms	O
assume	O
that	O
relationships	O
between	O
some	O
variables	O
are	O
linear	O
this	O
allows	O
the	O
algorithm	O
to	O
make	O
predictions	O
even	O
very	O
far	O
from	O
the	O
observed	O
data	O
but	O
can	O
sometimes	O
lead	O
to	O
overly	O
extreme	O
predictions	O
most	O
simple	O
machine	B
learning	I
algorithms	O
that	O
do	O
not	O
make	O
the	O
smoothness	O
assumption	O
instead	O
make	O
the	O
linearity	O
assumption	O
these	O
are	O
in	O
fact	O
different	O
assumptions	O
linear	O
functions	O
with	O
large	O
weights	B
applied	O
to	O
high-dimensional	O
spaces	O
may	O
not	O
be	O
very	O
smooth	O
see	O
goodfellow	O
et	O
al	O
for	O
a	O
further	O
discussion	O
of	O
the	O
limitations	O
of	O
the	O
linearity	O
assumption	O
multiple	O
explanatory	O
factors	O
many	O
representation	B
learning	I
algorithms	O
are	O
motivated	O
by	O
the	O
assumption	O
that	O
the	O
data	O
is	O
generated	O
by	O
multiple	O
underlying	O
explanatory	O
factors	O
and	O
that	O
most	O
tasks	O
can	O
be	O
solved	O
easily	O
given	O
the	O
state	O
of	O
each	O
of	O
these	O
factors	O
section	O
describes	O
how	O
this	O
view	O
motivates	O
semi	O
supervised	B
learning	I
via	O
representation	B
learning	I
learning	O
the	O
structure	O
of	O
px	O
requires	O
learning	O
some	O
of	O
the	O
same	O
features	O
that	O
are	O
useful	O
for	O
modeling	O
py	O
x	O
because	O
both	O
refer	O
to	O
the	O
same	O
underlying	O
explanatory	O
factors	O
section	O
describes	O
how	O
this	O
view	O
motivates	O
the	O
use	O
of	O
distributed	O
representations	O
with	O
separate	O
directions	O
in	O
representation	O
space	O
corresponding	O
to	O
separate	O
factors	B
of	I
variation	I
causal	O
factors	O
the	O
model	O
is	O
constructed	O
in	O
such	O
a	O
way	O
that	O
it	O
treats	O
the	O
factors	B
of	I
variation	I
described	O
by	O
the	O
learned	O
representation	O
h	O
as	O
the	O
causes	O
of	O
the	O
observed	O
data	O
x	O
and	O
not	O
vice-versa	O
as	O
discussed	O
in	O
section	O
this	O
is	O
advantageous	O
for	O
semi-supervised	B
learning	I
and	O
makes	O
the	O
learned	O
model	O
more	O
robust	O
when	O
the	O
distribution	O
over	O
the	O
underlying	O
causes	O
changes	O
or	O
when	O
we	O
use	O
the	O
model	O
for	O
a	O
new	O
task	O
or	O
a	O
hierarchical	O
organization	O
of	O
explanatory	O
factors	O
depth	O
high-level	O
abstract	O
concepts	O
can	O
be	O
defined	O
in	O
terms	O
of	O
simple	O
concepts	O
forming	O
a	O
hierarchy	O
from	O
another	O
point	O
of	O
view	O
the	O
use	O
of	O
a	O
deep	O
architecture	O
chapter	O
representation	B
learning	I
expresses	O
our	O
belief	O
that	O
the	O
task	O
should	O
be	O
accomplished	O
via	O
a	O
multi-step	O
program	O
with	O
each	O
step	O
referring	O
back	O
to	O
the	O
output	O
of	O
the	O
processing	O
accomplished	O
via	O
previous	O
steps	O
shared	O
factors	O
across	O
tasks	O
in	O
the	O
context	O
where	O
we	O
have	O
many	O
tasks	O
corresponding	O
to	O
different	O
yi	O
variables	O
sharing	O
the	O
same	O
input	O
x	O
or	O
where	O
each	O
task	O
is	O
associated	O
with	O
a	O
subset	O
or	O
a	O
function	O
f	O
of	O
a	O
global	O
input	O
x	O
the	O
assumption	O
is	O
that	O
each	O
y	O
i	O
is	O
associated	O
with	O
a	O
different	O
subset	O
from	O
a	O
common	O
pool	O
of	O
relevant	O
factors	O
h	O
because	O
these	O
subsets	O
overlap	O
learning	O
all	O
the	O
p	O
i	O
allows	O
sharing	O
of	O
statistical	O
strength	O
between	O
the	O
tasks	O
x	O
via	O
a	O
shared	O
intermediate	O
representation	O
p	O
x	O
manifolds	O
probability	O
mass	O
concentrates	O
and	O
the	O
regions	O
in	O
which	O
it	O
concentrates	O
are	O
locally	O
connected	O
and	O
occupy	O
a	O
tiny	O
volume	O
in	O
the	O
continuous	O
case	O
these	O
regions	O
can	O
be	O
approximated	O
by	O
low-dimensional	O
manifolds	O
with	O
a	O
much	O
smaller	O
dimensionality	O
than	O
the	O
original	O
space	O
where	O
the	O
data	O
lives	O
many	O
machine	B
learning	I
algorithms	O
behave	O
sensibly	O
only	O
on	O
this	O
manifold	B
some	O
machine	B
learning	I
algorithms	O
especially	O
goodfellow	O
et	O
al	O
autoencoders	O
attempt	O
to	O
explicitly	O
learn	O
the	O
structure	O
of	O
the	O
manifold	B
natural	O
clustering	O
many	O
machine	B
learning	I
algorithms	O
assume	O
that	O
each	O
connected	O
manifold	B
in	O
the	O
input	O
space	O
may	O
be	O
assigned	O
to	O
a	O
single	O
class	O
the	O
data	O
may	O
lie	O
on	O
many	O
disconnected	O
manifolds	O
but	O
the	O
class	O
remains	O
constant	O
within	O
each	O
one	O
of	O
these	O
this	O
assumption	O
motivates	O
a	O
variety	O
of	O
learning	O
algorithms	O
including	O
tangent	O
propagation	O
double	B
backprop	I
the	O
manifold	B
tangent	I
classifier	I
and	O
adversarial	O
training	O
temporal	O
and	O
spatial	O
coherence	O
slow	B
feature	B
analysis	I
and	O
related	O
algorithms	O
make	O
the	O
assumption	O
that	O
the	O
most	O
important	O
explanatory	O
factors	O
change	O
slowly	O
over	O
time	O
or	O
at	O
least	O
that	O
it	O
is	O
easier	O
to	O
predict	O
the	O
true	O
underlying	O
explanatory	O
factors	O
than	O
to	O
predict	O
raw	O
observations	O
such	O
as	O
pixel	O
values	O
see	O
section	O
for	O
further	O
description	O
of	O
this	O
approach	O
sparsity	O
most	O
features	O
should	O
presumably	O
not	O
be	O
relevant	O
to	O
describing	O
most	O
inputs	O
there	O
is	O
no	O
need	O
to	O
use	O
a	O
feature	B
that	O
detects	O
elephant	O
trunks	O
when	O
representing	O
an	O
image	O
of	O
a	O
cat	O
it	O
is	O
therefore	O
reasonable	O
to	O
impose	O
a	O
prior	O
that	O
any	O
feature	B
that	O
can	O
be	O
interpreted	O
as	O
present	O
or	O
absent	O
should	O
be	O
absent	O
most	O
of	O
the	O
time	O
simplicity	O
of	O
factor	O
dependencies	O
in	O
good	O
high-level	O
representations	O
the	O
factors	O
are	O
related	O
to	O
each	O
other	O
through	O
simple	O
dependencies	O
the	O
simplest	O
chapter	O
representation	B
learning	I
possible	O
is	O
marginal	O
independence	O
p	O
i	O
p	O
but	O
linear	O
dependencies	O
or	O
those	O
captured	O
by	O
a	O
shallow	O
autoencoder	O
are	O
also	O
reasonable	O
assumptions	O
this	O
can	O
be	O
seen	O
in	O
many	O
laws	O
of	O
physics	O
and	O
is	O
assumed	O
when	O
plugging	O
a	O
linear	O
predictor	O
or	O
a	O
factorized	O
prior	O
on	O
top	O
of	O
a	O
learned	O
representation	O
the	O
concept	O
of	O
representation	B
learning	I
ties	O
together	O
all	O
of	O
the	O
many	O
forms	O
of	O
deep	O
learning	O
feedforward	O
and	O
recurrent	O
networks	O
autoencoders	O
and	O
deep	O
probabilistic	O
models	O
all	O
learn	O
and	O
exploit	O
representations	O
learning	O
the	O
best	O
possible	O
representation	O
remains	O
an	O
exciting	O
avenue	O
of	O
research	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
deep	O
learning	O
draws	O
upon	O
many	O
modeling	O
formalisms	O
that	O
researchers	O
can	O
use	O
to	O
guide	O
their	O
design	O
efforts	O
and	O
describe	O
their	O
algorithms	O
one	O
of	O
these	O
formalisms	O
is	O
the	O
idea	O
of	O
structured	O
probabilistic	O
models	O
we	O
have	O
already	O
discussed	O
structured	O
probabilistic	O
models	O
briefly	O
in	O
section	O
that	O
brief	O
presentation	O
was	O
sufficient	O
to	O
understand	O
how	O
to	O
use	O
structured	O
probabilistic	O
models	O
as	O
a	O
language	O
to	O
describe	O
some	O
of	O
the	O
algorithms	O
in	O
part	O
structured	O
probabilistic	O
models	O
are	O
a	O
key	O
ingredient	O
of	O
many	O
of	O
the	O
most	O
important	O
research	O
topics	O
in	O
deep	O
learning	O
in	O
order	O
to	O
prepare	O
to	O
discuss	O
these	O
research	O
ideas	O
this	O
chapter	O
describes	O
structured	O
probabilistic	O
models	O
in	O
much	O
greater	O
detail	O
this	O
chapter	O
is	O
intended	O
to	O
be	O
self-contained	O
the	O
reader	O
does	O
not	O
need	O
to	O
review	O
the	O
earlier	O
introduction	O
before	O
continuing	O
with	O
this	O
chapter	O
now	O
in	O
part	O
ii	O
iii	O
a	O
structured	O
probabilistic	O
model	O
is	O
a	O
way	O
of	O
describing	O
a	O
probability	B
distribution	I
using	O
a	O
graph	O
to	O
describe	O
which	O
random	O
variables	O
in	O
the	O
probability	B
distribution	I
interact	O
with	O
each	O
other	O
directly	O
here	O
we	O
use	O
graph	O
in	O
the	O
graph	O
theory	O
sense	O
a	O
set	O
of	O
vertices	O
connected	O
to	O
one	O
another	O
by	O
a	O
set	O
of	O
edges	O
because	O
the	O
structure	O
of	O
the	O
model	O
is	O
defined	O
by	O
a	O
graph	O
these	O
models	O
are	O
often	O
also	O
referred	O
to	O
as	O
graphical	O
models	O
the	O
graphical	O
models	O
research	O
community	O
is	O
large	O
and	O
has	O
developed	O
many	O
different	O
models	O
training	O
algorithms	O
and	O
inference	O
algorithms	O
in	O
this	O
chapter	O
we	O
provide	O
basic	O
background	O
on	O
some	O
of	O
the	O
most	O
central	O
ideas	O
of	O
graphical	O
models	O
with	O
an	O
emphasis	O
on	O
the	O
concepts	O
that	O
have	O
proven	O
most	O
useful	O
to	O
the	O
deep	O
learning	O
research	O
community	O
if	O
you	O
already	O
have	O
a	O
strong	O
background	O
in	O
graphical	O
models	O
you	O
may	O
wish	O
to	O
skip	O
most	O
of	O
this	O
chapter	O
however	O
even	O
a	O
graphical	O
model	O
expert	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
in	O
which	O
we	O
may	O
benefit	O
from	O
reading	O
the	O
final	O
section	O
of	O
this	O
chapter	O
section	O
highlight	O
some	O
of	O
the	O
unique	O
ways	O
that	O
graphical	O
models	O
are	O
used	O
for	O
deep	O
learning	O
algorithms	O
deep	O
learning	O
practitioners	O
tend	O
to	O
use	O
very	O
different	O
model	O
structures	O
learning	O
algorithms	O
and	O
inference	O
procedures	O
than	O
are	O
commonly	O
used	O
by	O
the	O
rest	O
of	O
the	O
graphical	O
models	O
research	O
community	O
in	O
this	O
chapter	O
we	O
identify	O
these	O
differences	O
in	O
preferences	O
and	O
explain	O
the	O
reasons	O
for	O
them	O
in	O
this	O
chapter	O
we	O
first	O
describe	O
the	O
challenges	O
of	O
building	O
large-scale	O
probabilistic	O
models	O
next	O
we	O
describe	O
how	O
to	O
use	O
a	O
graph	O
to	O
describe	O
the	O
structure	O
of	O
a	O
probability	B
distribution	I
while	O
this	O
approach	O
allows	O
us	O
to	O
overcome	O
many	O
challenges	O
it	O
is	O
not	O
without	O
its	O
own	O
complications	O
one	O
of	O
the	O
major	O
difficulties	O
in	O
graphical	O
modeling	O
is	O
understanding	O
which	O
variables	O
need	O
to	O
be	O
able	O
to	O
interact	O
directly	O
i	O
e	O
which	O
graph	O
structures	O
are	O
most	O
suitable	O
for	O
a	O
given	O
problem	O
we	O
outline	O
two	O
approaches	O
to	O
resolving	O
this	O
difficulty	O
by	O
learning	O
about	O
the	O
dependencies	O
in	O
section	O
finally	O
we	O
close	O
with	O
a	O
discussion	O
of	O
the	O
unique	O
emphasis	O
that	O
deep	O
learning	O
practitioners	O
place	O
on	O
specific	O
approaches	O
to	O
graphical	O
modeling	O
in	O
section	O
the	O
challenge	B
of	O
unstructured	O
modeling	O
the	O
goal	O
of	O
deep	O
learning	O
is	O
to	O
scale	O
machine	B
learning	I
to	O
the	O
kinds	O
of	O
challenges	O
needed	O
to	O
solve	O
artificial	B
intelligence	I
this	O
means	O
being	O
able	O
to	O
understand	O
highdimensional	O
data	O
with	O
rich	O
structure	O
for	O
example	B
we	O
would	O
like	O
ai	O
algorithms	O
to	O
be	O
able	O
to	O
understand	O
natural	O
audio	O
waveforms	O
representing	O
speech	O
and	O
documents	O
containing	O
multiple	O
words	O
and	O
punctuation	O
characters	O
classification	B
algorithms	O
can	O
take	O
an	O
input	O
from	O
such	O
a	O
rich	O
high-dimensional	O
distribution	O
and	O
summarize	O
it	O
with	O
a	O
categorical	O
label	O
what	O
object	O
is	O
in	O
a	O
photo	O
what	O
word	O
is	O
spoken	O
in	O
a	O
recording	O
what	O
topic	O
a	O
document	O
is	O
about	O
the	O
process	O
of	O
classification	B
discards	O
most	O
of	O
the	O
information	O
in	O
the	O
input	O
and	O
produces	O
a	O
single	O
output	O
a	O
probability	B
distribution	I
over	O
values	O
of	O
that	O
single	O
output	O
the	O
classifier	O
is	O
also	O
often	O
able	O
to	O
ignore	O
many	O
parts	O
of	O
the	O
input	O
for	O
example	B
when	O
recognizing	O
an	O
object	O
in	O
a	O
photo	O
it	O
is	O
usually	O
possible	O
to	O
ignore	O
the	O
background	O
of	O
the	O
photo	O
it	O
is	O
possible	O
to	O
ask	O
probabilistic	O
models	O
to	O
do	O
many	O
other	O
tasks	O
these	O
tasks	O
are	O
often	O
more	O
expensive	O
than	O
classification	B
some	O
of	O
them	O
require	O
producing	O
multiple	O
output	O
values	O
most	O
require	O
a	O
complete	O
understanding	O
of	O
the	O
entire	O
structure	O
of	O
a	O
natural	B
image	I
is	O
an	O
image	O
that	O
might	O
be	O
captured	O
by	O
a	O
camera	O
in	O
a	O
reasonably	O
ordinary	O
environment	O
as	O
opposed	O
to	O
a	O
synthetically	O
rendered	O
image	O
a	O
screenshot	O
of	O
a	O
web	O
page	O
etc	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
the	O
input	O
with	O
no	O
option	O
to	O
ignore	O
sections	O
of	O
it	O
these	O
tasks	O
include	O
the	O
following	O
density	B
estimation	I
given	O
an	O
input	O
x	O
the	O
machine	B
learning	I
system	O
returns	O
an	O
estimate	O
of	O
the	O
true	O
density	O
px	O
under	O
the	O
data	O
generating	O
distribution	O
this	O
requires	O
only	O
a	O
single	O
output	O
but	O
it	O
does	O
require	O
a	O
complete	O
understanding	O
of	O
the	O
entire	O
input	O
if	O
even	O
one	O
element	O
of	O
the	O
vector	O
is	O
unusual	O
the	O
system	O
must	O
assign	O
it	O
a	O
low	O
probability	O
denoising	O
given	O
a	O
damaged	O
or	O
incorrectly	O
observed	O
input	O
x	O
the	O
machine	B
learning	I
system	O
returns	O
an	O
estimate	O
of	O
the	O
original	O
or	O
correct	O
x	O
for	O
example	B
the	O
machine	B
learning	I
system	O
might	O
be	O
asked	O
to	O
remove	O
dust	O
or	O
scratches	O
from	O
an	O
old	O
photograph	O
this	O
requires	O
multiple	O
outputs	O
element	O
of	O
the	O
estimated	O
clean	O
example	B
x	O
and	O
an	O
understanding	O
of	O
the	O
entire	O
input	O
even	O
one	O
damaged	O
area	O
will	O
still	O
reveal	O
the	O
final	O
estimate	O
as	O
being	O
damaged	O
missing	O
value	O
imputation	O
given	O
the	O
observations	O
of	O
some	O
elements	O
of	O
x	O
the	O
model	O
is	O
asked	O
to	O
return	O
estimates	O
of	O
or	O
a	O
probability	B
distribution	I
over	O
some	O
or	O
all	O
of	O
the	O
unobserved	O
elements	O
of	O
x	O
this	O
requires	O
multiple	O
outputs	O
because	O
the	O
model	O
could	O
be	O
asked	O
to	O
restore	O
any	O
of	O
the	O
elements	O
of	O
x	O
it	O
must	O
understand	O
the	O
entire	O
input	O
sampling	O
the	O
model	O
generates	O
new	O
samples	O
from	O
the	O
distribution	O
px	O
applications	O
include	O
speech	O
synthesis	O
i	O
e	O
producing	O
new	O
waveforms	O
that	O
sound	O
like	O
natural	O
human	O
speech	O
this	O
requires	O
multiple	O
output	O
values	O
and	O
a	O
good	O
model	O
of	O
the	O
entire	O
input	O
if	O
the	O
samples	O
have	O
even	O
one	O
element	O
drawn	O
from	O
the	O
wrong	O
distribution	O
then	O
the	O
sampling	O
process	O
is	O
wrong	O
for	O
an	O
example	B
of	O
a	O
sampling	O
task	O
using	O
small	O
natural	O
images	O
see	O
figure	O
modeling	O
a	O
rich	O
distribution	O
over	O
thousands	O
or	O
millions	O
of	O
random	O
variables	O
is	O
a	O
challenging	O
task	O
both	O
computationally	O
and	O
statistically	O
suppose	O
we	O
only	O
wanted	O
to	O
model	O
binary	O
variables	O
this	O
is	O
the	O
simplest	O
possible	O
case	O
and	O
yet	O
already	O
it	O
seems	O
overwhelming	O
for	O
a	O
small	O
possible	O
binary	O
images	O
of	O
this	O
form	O
this	O
number	O
is	O
over	O
times	O
larger	O
than	O
the	O
estimated	O
number	O
of	O
atoms	O
in	O
the	O
universe	O
pixel	O
color	O
image	O
there	O
are	O
in	O
general	O
if	O
we	O
wish	O
to	O
model	O
a	O
distribution	O
over	O
a	O
random	O
vector	O
x	O
containing	O
n	O
discrete	O
variables	O
capable	O
of	O
taking	O
on	O
k	O
values	O
each	O
then	O
the	O
naive	O
approach	O
of	O
representing	O
p	O
by	O
storing	O
a	O
lookup	O
table	O
with	O
one	O
probability	O
value	O
per	O
possible	O
outcome	O
requires	O
kn	O
parameters	O
this	O
is	O
not	O
feasible	O
for	O
several	O
reasons	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
pixel	O
color	O
figure	O
probabilistic	O
modeling	O
of	O
natural	O
images	O
images	O
from	O
the	O
dataset	B
samples	O
drawn	O
from	O
a	O
structured	O
probabilistic	O
model	O
trained	O
on	O
this	O
dataset	B
each	O
sample	O
appears	O
at	O
the	O
same	O
position	O
in	O
the	O
grid	O
as	O
the	O
training	O
example	B
that	O
is	O
closest	O
to	O
it	O
in	O
euclidean	O
space	O
this	O
comparison	O
allows	O
us	O
to	O
see	O
that	O
the	O
model	O
is	O
truly	O
synthesizing	O
new	O
images	O
rather	O
than	O
memorizing	O
the	O
training	O
data	O
contrast	B
of	O
both	O
sets	O
of	O
images	O
has	O
been	O
adjusted	O
for	O
display	O
figure	O
reproduced	O
with	O
permission	O
from	O
krizhevsky	O
and	O
hinton	O
courville	O
et	O
al	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
memory	O
the	O
cost	O
of	O
storing	O
the	O
representation	O
for	O
all	O
but	O
very	O
small	O
values	O
of	O
n	O
and	O
k	O
representing	O
the	O
distribution	O
as	O
a	O
table	O
will	O
require	O
too	O
many	O
values	O
to	O
store	O
statistical	O
efficiency	O
as	O
the	O
number	O
of	O
parameters	O
in	O
a	O
model	O
increases	O
so	O
does	O
the	O
amount	O
of	O
training	O
data	O
needed	O
to	O
choose	O
the	O
values	O
of	O
those	O
parameters	O
using	O
a	O
statistical	O
estimator	O
because	O
the	O
table-based	O
model	O
has	O
an	O
astronomical	O
number	O
of	O
parameters	O
it	O
will	O
require	O
an	O
astronomically	O
large	O
training	O
set	O
to	O
fit	O
accurately	O
any	O
such	O
model	O
will	O
overfit	O
the	O
training	O
set	O
very	O
badly	O
unless	O
additional	O
assumptions	O
are	O
made	O
linking	O
the	O
different	O
entries	O
in	O
the	O
table	O
example	B
like	O
in	O
back-off	O
or	O
smoothed	O
n-gram	B
models	O
section	O
runtime	O
the	O
cost	O
of	O
inference	O
suppose	O
we	O
want	O
to	O
perform	O
an	O
inference	O
task	O
where	O
we	O
use	O
our	O
model	O
of	O
the	O
joint	O
distribution	O
p	O
to	O
compute	O
some	O
other	O
distribution	O
such	O
as	O
the	O
marginal	O
distribution	O
p	O
or	O
the	O
conditional	O
computing	O
these	O
distributions	O
will	O
require	O
summing	O
distribution	O
p	O
across	O
the	O
entire	O
table	O
so	O
the	O
runtime	O
of	O
these	O
operations	O
is	O
as	O
high	O
as	O
the	O
intractable	O
memory	O
cost	O
of	O
storing	O
the	O
model	O
runtime	O
the	O
cost	O
of	O
sampling	O
likewise	O
suppose	O
we	O
want	O
to	O
draw	O
a	O
sample	O
u	O
from	O
the	O
model	O
the	O
naive	O
way	O
to	O
do	O
this	O
is	O
to	O
sample	O
some	O
value	O
u	O
then	O
iterate	O
through	O
the	O
table	O
adding	O
up	O
the	O
probability	O
values	O
until	O
they	O
exceed	O
u	O
and	O
return	O
the	O
outcome	O
corresponding	O
to	O
that	O
position	O
in	O
the	O
table	O
this	O
requires	O
reading	O
through	O
the	O
whole	O
table	O
in	O
the	O
worst	O
case	O
so	O
it	O
has	O
the	O
same	O
exponential	O
cost	O
as	O
the	O
other	O
operations	O
the	O
problem	O
with	O
the	O
table-based	O
approach	O
is	O
that	O
we	O
are	O
explicitly	O
modeling	O
every	O
possible	O
kind	O
of	O
interaction	O
between	O
every	O
possible	O
subset	O
of	O
variables	O
the	O
probability	O
distributions	O
we	O
encounter	O
in	O
real	O
tasks	O
are	O
much	O
simpler	O
than	O
this	O
usually	O
most	O
variables	O
influence	O
each	O
other	O
only	O
indirectly	O
for	O
example	B
consider	O
modeling	O
the	O
finishing	O
times	O
of	O
a	O
team	O
in	O
a	O
relay	O
race	O
suppose	O
the	O
team	O
consists	O
of	O
three	O
runners	O
alice	O
bob	O
and	O
carol	O
at	O
the	O
start	O
of	O
the	O
race	O
alice	O
carries	O
a	O
baton	O
and	O
begins	O
running	O
around	O
a	O
track	O
after	O
completing	O
her	O
lap	O
around	O
the	O
track	O
she	O
hands	O
the	O
baton	O
to	O
bob	O
bob	O
then	O
runs	O
his	O
own	O
lap	O
and	O
hands	O
the	O
baton	O
to	O
carol	O
who	O
runs	O
the	O
final	O
lap	O
we	O
can	O
model	O
each	O
of	O
their	O
finishing	O
times	O
as	O
a	O
continuous	O
random	B
variable	I
alice	O
s	O
finishing	O
time	O
does	O
not	O
depend	O
on	O
anyone	O
else	O
s	O
since	O
she	O
goes	O
first	O
bob	O
s	O
finishing	O
time	O
depends	O
on	O
alice	O
s	O
because	O
bob	O
does	O
not	O
have	O
the	O
opportunity	O
to	O
start	O
his	O
lap	O
until	O
alice	O
has	O
completed	O
hers	O
if	O
alice	O
finishes	O
faster	O
bob	O
will	O
finish	O
faster	O
all	O
else	O
being	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
equal	O
finally	O
carol	O
s	O
finishing	O
time	O
depends	O
on	O
both	O
her	O
teammates	O
if	O
alice	O
is	O
slow	O
bob	O
will	O
probably	O
finish	O
late	O
too	O
as	O
a	O
consequence	O
carol	O
will	O
have	O
quite	O
a	O
late	O
starting	O
time	O
and	O
thus	O
is	O
likely	O
to	O
have	O
a	O
late	O
finishing	O
time	O
as	O
well	O
however	O
carol	O
s	O
finishing	O
time	O
depends	O
only	O
indirectly	O
on	O
alice	O
s	O
finishing	O
time	O
via	O
bob	O
s	O
if	O
we	O
already	O
know	O
bob	O
s	O
finishing	O
time	O
we	O
will	O
not	O
be	O
able	O
to	O
estimate	O
carol	O
s	O
finishing	O
time	O
better	O
by	O
finding	O
out	O
what	O
alice	O
s	O
finishing	O
time	O
was	O
this	O
means	O
we	O
can	O
model	O
the	O
relay	O
race	O
using	O
only	O
two	O
interactions	O
alice	O
s	O
effect	O
on	O
bob	O
and	O
bob	O
s	O
effect	O
on	O
carol	O
we	O
can	O
omit	O
the	O
third	O
indirect	O
interaction	O
between	O
alice	O
and	O
carol	O
from	O
our	O
model	O
structured	O
probabilistic	O
models	O
provide	O
a	O
formal	O
framework	O
for	O
modeling	O
only	O
direct	O
interactions	O
between	O
random	O
variables	O
this	O
allows	O
the	O
models	O
to	O
have	O
significantly	O
fewer	O
parameters	O
and	O
therefore	O
be	O
estimated	O
reliably	O
from	O
less	O
data	O
these	O
smaller	O
models	O
also	O
have	O
dramatically	O
reduced	O
computational	O
cost	O
in	O
terms	O
of	O
storing	O
the	O
model	O
performing	O
inference	O
in	O
the	O
model	O
and	O
drawing	O
samples	O
from	O
the	O
model	O
using	O
graphs	O
to	O
describe	O
model	O
structure	O
structured	O
probabilistic	O
models	O
use	O
graphs	O
the	O
graph	O
theory	O
sense	O
of	O
nodes	O
or	O
vertices	O
connected	O
by	O
edges	O
to	O
represent	O
interactions	O
between	O
random	O
variables	O
each	O
node	O
represents	O
a	O
random	B
variable	I
each	O
edge	O
represents	O
a	O
direct	O
interaction	O
these	O
direct	O
interactions	O
imply	O
other	O
indirect	O
interactions	O
but	O
only	O
the	O
direct	O
interactions	O
need	O
to	O
be	O
explicitly	O
modeled	O
there	O
is	O
more	O
than	O
one	O
way	O
to	O
describe	O
the	O
interactions	O
in	O
a	O
probability	B
distribution	I
using	O
a	O
graph	O
in	O
the	O
following	O
sections	O
we	O
describe	O
some	O
of	O
the	O
most	O
popular	O
and	O
useful	O
approaches	O
graphical	O
models	O
can	O
be	O
largely	O
divided	O
into	O
two	O
categories	O
models	O
based	O
on	O
directed	O
acyclic	O
graphs	O
and	O
models	O
based	O
on	O
undirected	O
graphs	O
directed	O
models	O
one	O
kind	O
of	O
structured	O
probabilistic	O
model	O
is	O
the	O
directed	O
graphical	O
model	O
otherwise	O
known	O
as	O
the	O
belief	O
network	O
bayesian	O
network	O
or	O
directed	O
graphical	O
models	O
are	O
called	O
directed	O
because	O
their	O
edges	O
are	O
directed	O
judea	O
pearl	O
suggested	O
using	O
the	O
term	O
bayesian	O
network	O
when	O
one	O
wishes	O
to	O
emphasize	O
the	O
judgmental	O
nature	O
of	O
the	O
values	O
computed	O
by	O
the	O
network	O
i	O
e	O
to	O
highlight	O
that	O
they	O
usually	O
represent	O
degrees	O
of	O
belief	O
rather	O
than	O
frequencies	O
of	O
events	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
alice	O
bob	O
carol	O
figure	O
a	O
directed	O
graphical	O
model	O
depicting	O
the	O
relay	O
race	O
example	B
alice	O
s	O
finishing	O
time	O
influences	O
bob	O
s	O
finishing	O
time	O
because	O
bob	O
does	O
not	O
get	O
to	O
start	O
running	O
until	O
alice	O
finishes	O
likewise	O
carol	O
only	O
gets	O
to	O
start	O
running	O
after	O
bob	O
finishes	O
so	O
bob	O
s	O
finishing	O
time	O
directly	O
influences	O
carol	O
s	O
finishing	O
time	O
that	O
is	O
they	O
point	O
from	O
one	O
vertex	O
to	O
another	O
this	O
direction	O
is	O
represented	O
in	O
the	O
drawing	O
with	O
an	O
arrow	O
the	O
direction	O
of	O
the	O
arrow	O
indicates	O
which	O
variable	O
s	O
probability	B
distribution	I
is	O
defined	O
in	O
terms	O
of	O
the	O
other	O
s	O
drawing	O
an	O
arrow	O
from	O
a	O
to	O
b	O
means	O
that	O
we	O
define	O
the	O
probability	B
distribution	I
over	O
b	O
via	O
a	O
conditional	O
distribution	O
with	O
a	O
as	O
one	O
of	O
the	O
variables	O
on	O
the	O
right	O
side	O
of	O
the	O
conditioning	O
bar	O
in	O
other	O
words	O
the	O
distribution	O
over	O
b	O
depends	O
on	O
the	O
value	O
of	O
a	O
continuing	O
with	O
the	O
relay	O
race	O
example	B
from	O
section	O
suppose	O
we	O
name	O
alice	O
s	O
finishing	O
time	O
bob	O
s	O
finishing	O
time	O
and	O
carol	O
s	O
finishing	O
time	O
as	O
we	O
saw	O
earlier	O
our	O
estimate	O
of	O
t	O
depends	O
on	O
our	O
estimate	O
of	O
depends	O
directly	O
on	O
but	O
only	O
indirectly	O
on	O
we	O
can	O
draw	O
this	O
relationship	O
in	O
a	O
directed	O
graphical	O
model	O
illustrated	O
in	O
figure	O
g	O
formally	O
a	O
directed	O
graphical	O
model	O
defined	O
on	O
variables	O
x	O
is	O
defined	O
by	O
a	O
whose	O
vertices	O
are	O
the	O
random	O
variables	O
in	O
the	O
model	O
p	O
ag	O
where	O
the	O
probability	B
distribution	I
over	O
x	O
is	O
given	O
directed	O
acyclic	O
graph	O
and	O
a	O
set	O
of	O
local	O
conditional	B
probability	I
distributions	O
pxi	O
p	O
agxi	O
gives	O
the	O
parents	O
of	O
xi	O
in	O
by	O
g	O
p	O
x	O
i	O
pxi	O
p	O
agxi	O
in	O
our	O
relay	O
race	O
example	B
this	O
means	O
that	O
using	O
the	O
graph	O
drawn	O
in	O
figure	O
this	O
is	O
our	O
first	O
time	O
seeing	O
a	O
structured	O
probabilistic	O
model	O
in	O
action	O
we	O
can	O
examine	O
the	O
cost	O
of	O
using	O
it	O
in	O
order	O
to	O
observe	O
how	O
structured	O
modeling	O
has	O
many	O
advantages	O
relative	O
to	O
unstructured	O
modeling	O
suppose	O
we	O
represented	O
time	O
by	O
discretizing	O
time	O
ranging	O
from	O
minute	O
to	O
minute	O
into	O
second	O
chunks	O
this	O
would	O
make	O
and	O
each	O
be	O
a	O
discrete	O
variable	O
with	O
possible	O
values	O
if	O
we	O
attempted	O
to	O
represent	O
p	O
with	O
a	O
table	O
it	O
would	O
need	O
to	O
store	O
values	O
values	O
of	O
values	O
of	O
minus	O
since	O
the	O
probability	O
of	O
one	O
of	O
the	O
configurations	O
is	O
made	O
values	O
of	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
redundant	O
by	O
the	O
constraint	O
that	O
the	O
sum	O
of	O
the	O
probabilities	O
be	O
if	O
instead	O
we	O
only	O
make	O
a	O
table	O
for	O
each	O
of	O
the	O
conditional	B
probability	I
distributions	O
then	O
the	O
distribution	O
over	O
requires	O
values	O
the	O
table	O
defining	O
given	O
requires	O
values	O
and	O
so	O
does	O
the	O
table	O
defining	O
given	O
this	O
comes	O
to	O
a	O
total	O
of	O
values	O
this	O
means	O
that	O
using	O
the	O
directed	O
graphical	O
model	O
reduced	O
our	O
number	O
of	O
parameters	O
by	O
a	O
factor	O
of	O
more	O
than	O
in	O
general	O
to	O
model	O
n	O
discrete	O
variables	O
each	O
having	O
k	O
values	O
the	O
cost	O
of	O
the	O
single	O
table	O
approach	O
scales	O
like	O
ok	O
n	O
as	O
we	O
have	O
observed	O
before	O
now	O
suppose	O
we	O
build	O
a	O
directed	O
graphical	O
model	O
over	O
these	O
variables	O
if	O
m	O
is	O
the	O
maximum	O
number	O
of	O
variables	O
appearing	O
either	O
side	O
of	O
the	O
conditioning	O
bar	O
in	O
a	O
single	O
conditional	B
probability	B
distribution	I
then	O
the	O
cost	O
of	O
the	O
tables	O
for	O
the	O
directed	O
model	O
scales	O
like	O
o	O
km	O
as	O
long	O
as	O
we	O
can	O
design	O
a	O
model	O
such	O
that	O
m	O
n	O
we	O
get	O
very	O
dramatic	O
savings	O
in	O
other	O
words	O
so	O
long	O
as	O
each	O
variable	O
has	O
few	O
parents	O
in	O
the	O
graph	O
the	O
distribution	O
can	O
be	O
represented	O
with	O
very	O
few	O
parameters	O
some	O
restrictions	O
on	O
the	O
graph	O
structure	O
such	O
as	O
requiring	O
it	O
to	O
be	O
a	O
tree	O
can	O
also	O
guarantee	O
that	O
operations	O
like	O
computing	O
marginal	O
or	O
conditional	O
distributions	O
over	O
subsets	O
of	O
variables	O
are	O
efficient	O
it	O
is	O
important	O
to	O
realize	O
what	O
kinds	O
of	O
information	O
can	O
and	O
cannot	O
be	O
encoded	O
in	O
the	O
graph	O
the	O
graph	O
encodes	O
only	O
simplifying	O
assumptions	O
about	O
which	O
variables	O
are	O
conditionally	O
independent	O
from	O
each	O
other	O
it	O
is	O
also	O
possible	O
to	O
make	O
other	O
kinds	O
of	O
simplifying	O
assumptions	O
for	O
example	B
suppose	O
we	O
assume	O
bob	O
always	O
runs	O
the	O
same	O
regardless	O
of	O
how	O
alice	O
performed	O
reality	O
alice	O
s	O
performance	O
probably	O
influences	O
bob	O
s	O
performance	O
depending	O
on	O
bob	O
s	O
personality	O
if	O
alice	O
runs	O
especially	O
fast	O
in	O
a	O
given	O
race	O
this	O
might	O
encourage	O
bob	O
to	O
push	O
hard	O
and	O
match	O
her	O
exceptional	O
performance	O
or	O
it	O
might	O
make	O
him	O
overconfident	O
and	O
lazy	O
then	O
the	O
only	O
effect	O
alice	O
has	O
on	O
bob	O
s	O
finishing	O
time	O
is	O
that	O
we	O
must	O
add	O
alice	O
s	O
finishing	O
time	O
to	O
the	O
total	O
amount	O
of	O
time	O
we	O
think	O
bob	O
needs	O
to	O
run	O
this	O
observation	O
allows	O
us	O
to	O
define	O
a	O
model	O
with	O
ok	O
parameters	O
instead	O
of	O
ok	O
however	O
note	O
that	O
and	O
are	O
still	O
directly	O
dependent	O
with	O
this	O
assumption	O
because	O
represents	O
the	O
absolute	O
time	O
at	O
which	O
bob	O
finishes	O
not	O
the	O
total	O
time	O
he	O
himself	O
spends	O
running	O
this	O
means	O
our	O
graph	O
must	O
still	O
contain	O
an	O
arrow	O
from	O
to	O
the	O
assumption	O
that	O
bob	O
s	O
personal	O
running	O
time	O
is	O
independent	O
from	O
all	O
other	O
factors	O
cannot	O
be	O
encoded	O
in	O
a	O
graph	O
over	O
and	O
instead	O
we	O
encode	O
this	O
information	O
in	O
the	O
definition	O
of	O
the	O
conditional	O
distribution	O
itself	O
the	O
conditional	O
distribution	O
is	O
no	O
longer	O
a	O
k	O
element	O
table	O
indexed	O
by	O
and	O
but	O
is	O
now	O
a	O
slightly	O
more	O
complicated	O
formula	O
using	O
only	O
k	O
parameters	O
the	O
directed	O
graphical	O
model	O
syntax	O
does	O
not	O
place	O
any	O
constraint	O
on	O
how	O
we	O
define	O
k	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
our	O
conditional	O
distributions	O
it	O
only	O
defines	O
which	O
variables	O
they	O
are	O
allowed	O
to	O
take	O
in	O
as	O
arguments	O
undirected	O
models	O
directed	O
graphical	O
models	O
give	O
us	O
one	O
language	O
for	O
describing	O
structured	O
probabilistic	O
models	O
another	O
popular	O
language	O
is	O
that	O
of	O
undirected	O
models	O
otherwise	O
known	O
as	O
markov	O
random	O
fields	O
or	O
markov	O
networks	O
as	O
their	O
name	O
implies	O
undirected	O
models	O
use	O
graphs	O
whose	O
edges	O
are	O
undirected	O
directed	O
models	O
are	O
most	O
naturally	O
applicable	O
to	O
situations	O
where	O
there	O
is	O
a	O
clear	O
reason	O
to	O
draw	O
each	O
arrow	O
in	O
one	O
particular	O
direction	O
often	O
these	O
are	O
situations	O
where	O
we	O
understand	O
the	O
causality	O
and	O
the	O
causality	O
only	O
flows	O
in	O
one	O
direction	O
one	O
such	O
situation	O
is	O
the	O
relay	O
race	O
example	B
earlier	O
runners	O
affect	O
the	O
finishing	O
times	O
of	O
later	O
runners	O
later	O
runners	O
do	O
not	O
affect	O
the	O
finishing	O
times	O
of	O
earlier	O
runners	O
not	O
all	O
situations	O
we	O
might	O
want	O
to	O
model	O
have	O
such	O
a	O
clear	O
direction	O
to	O
their	O
interactions	O
when	O
the	O
interactions	O
seem	O
to	O
have	O
no	O
intrinsic	O
direction	O
or	O
to	O
operate	O
in	O
both	O
directions	O
it	O
may	O
be	O
more	O
appropriate	O
to	O
use	O
an	O
undirected	B
model	I
as	O
an	O
example	B
of	O
such	O
a	O
situation	O
suppose	O
we	O
want	O
to	O
model	O
a	O
distribution	O
over	O
three	O
binary	O
variables	O
whether	O
or	O
not	O
you	O
are	O
sick	O
whether	O
or	O
not	O
your	O
coworker	O
is	O
sick	O
and	O
whether	O
or	O
not	O
your	O
roommate	O
is	O
sick	O
as	O
in	O
the	O
relay	O
race	O
example	B
we	O
can	O
make	O
simplifying	O
assumptions	O
about	O
the	O
kinds	O
of	O
interactions	O
that	O
take	O
place	O
assuming	O
that	O
your	O
coworker	O
and	O
your	O
roommate	O
do	O
not	O
know	O
each	O
other	O
it	O
is	O
very	O
unlikely	O
that	O
one	O
of	O
them	O
will	O
give	O
the	O
other	O
an	O
infection	O
such	O
as	O
a	O
cold	O
directly	O
this	O
event	O
can	O
be	O
seen	O
as	O
so	O
rare	O
that	O
it	O
is	O
acceptable	O
not	O
to	O
model	O
it	O
however	O
it	O
is	O
reasonably	O
likely	O
that	O
either	O
of	O
them	O
could	O
give	O
you	O
a	O
cold	O
and	O
that	O
you	O
could	O
pass	O
it	O
on	O
to	O
the	O
other	O
we	O
can	O
model	O
the	O
indirect	O
transmission	O
of	O
a	O
cold	O
from	O
your	O
coworker	O
to	O
your	O
roommate	O
by	O
modeling	O
the	O
transmission	O
of	O
the	O
cold	O
from	O
your	O
coworker	O
to	O
you	O
and	O
the	O
transmission	O
of	O
the	O
cold	O
from	O
you	O
to	O
your	O
roommate	O
in	O
this	O
case	O
it	O
is	O
just	O
as	O
easy	O
for	O
you	O
to	O
cause	O
your	O
roommate	O
to	O
get	O
sick	O
as	O
it	O
is	O
for	O
your	O
roommate	O
to	O
make	O
you	O
sick	O
so	O
there	O
is	O
not	O
a	O
clean	O
uni-directional	O
narrative	O
on	O
which	O
to	O
base	O
the	O
model	O
this	O
motivates	O
using	O
an	O
undirected	B
model	I
as	O
with	O
directed	O
models	O
if	O
two	O
nodes	O
in	O
an	O
undirected	B
model	I
are	O
connected	O
by	O
an	O
edge	O
then	O
the	O
random	O
variables	O
corresponding	O
to	O
those	O
nodes	O
interact	O
with	O
each	O
other	O
directly	O
unlike	O
directed	O
models	O
the	O
edge	O
in	O
an	O
undirected	B
model	I
has	O
no	O
arrow	O
and	O
is	O
not	O
associated	O
with	O
a	O
conditional	B
probability	B
distribution	I
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
hrhr	O
hyhy	O
hchc	O
figure	O
an	O
undirected	O
graph	O
representing	O
how	O
your	O
roommate	O
s	O
health	O
hr	O
your	O
health	O
hy	O
and	O
your	O
work	O
colleague	O
s	O
health	O
hc	O
affect	O
each	O
other	O
you	O
and	O
your	O
roommate	O
might	O
infect	O
each	O
other	O
with	O
a	O
cold	O
and	O
you	O
and	O
your	O
work	O
colleague	O
might	O
do	O
the	O
same	O
but	O
assuming	O
that	O
your	O
roommate	O
and	O
your	O
colleague	O
do	O
not	O
know	O
each	O
other	O
they	O
can	O
only	O
infect	O
each	O
other	O
indirectly	O
via	O
you	O
we	O
denote	O
the	O
random	B
variable	I
representing	O
your	O
health	O
as	O
hy	O
the	O
random	B
variable	I
representing	O
your	O
roommate	O
s	O
health	O
as	O
hr	O
and	O
the	O
random	B
variable	I
representing	O
your	O
colleague	O
s	O
health	O
as	O
hc	O
see	O
figure	O
for	O
a	O
drawing	O
of	O
the	O
graph	O
representing	O
this	O
scenario	O
g	O
c	O
formally	O
an	O
undirected	O
graphical	O
model	O
is	O
a	O
structured	O
probabilistic	O
model	O
in	O
the	O
a	O
factor	O
defined	O
on	O
an	O
undirected	O
graph	O
called	O
a	O
clique	O
potential	O
measures	O
the	O
affinity	O
of	O
the	O
variables	O
in	O
that	O
clique	O
for	O
being	O
in	O
each	O
of	O
their	O
possible	O
joint	O
states	O
the	O
factors	O
are	O
constrained	O
to	O
be	O
non-negative	O
together	O
they	O
define	O
an	O
unnormalized	B
probability	B
distribution	I
for	O
each	O
clique	O
c	O
c	O
c	O
g	O
p	O
x	O
the	O
unnormalized	B
probability	B
distribution	I
is	O
efficient	O
to	O
work	O
with	O
so	O
long	O
as	O
all	O
the	O
cliques	O
are	O
small	O
it	O
encodes	O
the	O
idea	O
that	O
states	O
with	O
higher	O
affinity	O
are	O
more	O
likely	O
however	O
unlike	O
in	O
a	O
bayesian	O
network	O
there	O
is	O
little	O
structure	O
to	O
the	O
definition	O
of	O
the	O
cliques	O
so	O
there	O
is	O
nothing	O
to	O
guarantee	O
that	O
multiplying	O
them	O
together	O
will	O
yield	O
a	O
valid	O
probability	B
distribution	I
see	O
figure	O
for	O
an	O
example	B
of	O
reading	O
factorization	O
information	O
from	O
an	O
undirected	O
graph	O
our	O
example	B
of	O
the	O
cold	O
spreading	O
between	O
you	O
your	O
roommate	O
and	O
your	O
colleague	O
contains	O
two	O
cliques	O
one	O
clique	O
contains	O
h	O
y	O
and	O
hc	O
the	O
factor	O
for	O
this	O
clique	O
can	O
be	O
defined	O
by	O
a	O
table	O
and	O
might	O
have	O
values	O
resembling	O
these	O
hy	O
hy	O
hc	O
hc	O
clique	O
of	O
the	O
graph	O
is	O
a	O
subset	O
of	O
nodes	O
that	O
are	O
all	O
connected	O
to	O
each	O
other	O
by	O
an	O
edge	O
of	O
the	O
graph	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
a	O
state	O
of	O
indicates	O
good	O
health	O
while	O
a	O
state	O
of	O
indicates	O
poor	O
health	O
been	O
infected	O
with	O
a	O
cold	O
both	O
of	O
you	O
are	O
usually	O
healthy	O
so	O
the	O
corresponding	O
state	O
has	O
the	O
highest	O
affinity	O
the	O
state	O
where	O
only	O
one	O
of	O
you	O
is	O
sick	O
has	O
the	O
lowest	O
affinity	O
because	O
this	O
is	O
a	O
rare	O
state	O
the	O
state	O
where	O
both	O
of	O
you	O
are	O
sick	O
one	O
of	O
you	O
has	O
infected	O
the	O
other	O
is	O
a	O
higher	O
affinity	O
state	O
though	O
still	O
not	O
as	O
common	O
as	O
the	O
state	O
where	O
both	O
are	O
healthy	O
to	O
complete	O
the	O
model	O
we	O
would	O
need	O
to	O
also	O
define	O
a	O
similar	O
factor	O
for	O
the	O
clique	O
containing	O
hy	O
and	O
hr	O
the	O
partition	O
function	O
while	O
the	O
unnormalized	B
probability	B
distribution	I
is	O
guaranteed	O
to	O
be	O
non-negative	O
everywhere	O
it	O
is	O
not	O
guaranteed	O
to	O
sum	O
or	O
integrate	O
to	O
to	O
obtain	O
a	O
valid	O
probability	B
distribution	I
we	O
must	O
use	O
the	O
corresponding	O
normalized	O
probability	O
p	O
p	O
z	O
where	O
z	O
is	O
the	O
value	O
that	O
results	O
in	O
the	O
probability	B
distribution	I
summing	O
or	O
integrating	O
to	O
z	O
p	O
d	O
x	O
you	O
can	O
think	O
of	O
z	O
as	O
a	O
constant	O
when	O
the	O
functions	O
are	O
held	O
constant	O
note	O
that	O
if	O
the	O
functions	O
have	O
parameters	O
then	O
z	O
is	O
a	O
function	O
of	O
those	O
parameters	O
it	O
is	O
common	O
in	O
the	O
literature	O
to	O
write	O
z	O
with	O
its	O
arguments	O
omitted	O
to	O
save	O
space	O
the	O
normalizing	O
constant	O
z	O
is	O
known	O
as	O
the	O
partition	O
function	O
a	O
term	O
borrowed	O
from	O
statistical	O
physics	O
since	O
z	O
is	O
an	O
integral	O
or	O
sum	O
over	O
all	O
possible	O
joint	O
assignments	O
of	O
the	O
state	O
x	O
it	O
is	O
often	O
intractable	O
to	O
compute	O
in	O
order	O
to	O
be	O
able	O
to	O
obtain	O
the	O
normalized	O
probability	B
distribution	I
of	O
an	O
undirected	B
model	I
the	O
model	O
structure	O
and	O
the	O
definitions	O
of	O
the	O
functions	O
must	O
be	O
conducive	O
to	O
computing	O
z	O
efficiently	O
in	O
the	O
context	O
of	O
deep	O
learning	O
z	O
is	O
usually	O
intractable	O
due	O
to	O
the	O
intractability	O
of	O
computing	O
z	O
exactly	O
we	O
must	O
resort	O
to	O
approximations	O
such	O
approximate	O
algorithms	O
are	O
the	O
topic	O
of	O
chapter	O
one	O
important	O
consideration	O
to	O
keep	O
in	O
mind	O
when	O
designing	O
undirected	O
models	O
is	O
that	O
it	O
is	O
possible	O
to	O
specify	O
the	O
factors	O
in	O
such	O
a	O
way	O
that	O
z	O
does	O
not	O
exist	O
this	O
happens	O
if	O
some	O
of	O
the	O
variables	O
in	O
the	O
model	O
are	O
continuous	O
and	O
the	O
integral	O
distribution	O
defined	O
by	O
normalizing	O
a	O
product	O
of	O
clique	O
potentials	O
is	O
also	O
called	O
a	O
gibbs	B
distribution	I
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
of	O
p	O
over	O
their	O
domain	O
diverges	O
for	O
example	B
suppose	O
we	O
want	O
to	O
model	O
a	O
single	O
scalar	O
variable	O
x	O
with	O
a	O
single	O
clique	O
potential	O
in	O
this	O
case	O
x	O
x	O
z	O
r	O
since	O
this	O
integral	O
diverges	O
there	O
is	O
no	O
probability	B
distribution	I
corresponding	O
to	O
this	O
choice	O
of	O
sometimes	O
the	O
choice	O
of	O
some	O
parameter	O
of	O
the	O
functions	O
determines	O
whether	O
the	O
probability	B
distribution	I
is	O
defined	O
for	O
example	B
for	O
exp	O
the	O
parameter	O
determines	O
whether	O
z	O
exists	O
positive	O
results	O
in	O
a	O
gaussian	O
distribution	O
over	O
x	O
but	O
all	O
other	O
values	O
of	O
make	O
impossible	O
to	O
normalize	O
one	O
key	O
difference	O
between	O
directed	O
modeling	O
and	O
undirected	O
modeling	O
is	O
that	O
directed	O
models	O
are	O
defined	O
directly	O
in	O
terms	O
of	O
probability	O
distributions	O
from	O
the	O
start	O
while	O
undirected	O
models	O
are	O
defined	O
more	O
loosely	O
by	O
functions	O
that	O
are	O
then	O
converted	O
into	O
probability	O
distributions	O
this	O
changes	O
the	O
intuitions	O
one	O
must	O
develop	O
in	O
order	O
to	O
work	O
with	O
these	O
models	O
one	O
key	O
idea	O
to	O
keep	O
in	O
mind	O
while	O
working	O
with	O
undirected	O
models	O
is	O
that	O
the	O
domain	O
of	O
each	O
of	O
the	O
variables	O
has	O
dramatic	O
effect	O
on	O
the	O
kind	O
of	O
probability	B
distribution	I
that	O
a	O
given	O
set	O
of	O
functions	O
corresponds	O
to	O
for	O
example	B
consider	O
an	O
n-dimensional	O
vector-valued	O
random	B
variable	I
x	O
and	O
an	O
undirected	B
model	I
parametrized	O
by	O
a	O
vector	O
of	O
biases	O
b	O
suppose	O
we	O
have	O
one	O
clique	O
for	O
each	O
element	O
of	O
x	O
expbixi	O
what	O
kind	O
of	O
probability	B
distribution	I
does	O
this	O
result	O
in	O
the	O
answer	O
is	O
that	O
we	O
do	O
not	O
have	O
enough	O
information	O
because	O
we	O
have	O
not	O
yet	O
specified	O
the	O
domain	O
of	O
x	O
n	O
then	O
the	O
integral	O
defining	O
z	O
diverges	O
and	O
no	O
probability	B
distribution	I
if	O
x	O
n	O
then	O
px	O
factorizes	O
into	O
n	O
independent	O
distributions	O
with	O
exists	O
if	O
x	O
px	O
i	O
sigmoid	O
if	O
the	O
domain	O
of	O
x	O
is	O
the	O
set	O
of	O
elementary	O
basis	O
vectors	O
then	O
px	O
softmaxb	O
so	O
a	O
large	O
value	O
of	O
bi	O
actually	O
reduces	O
px	O
j	O
for	O
j	O
i	O
often	O
it	O
is	O
possible	O
to	O
leverage	O
the	O
effect	O
of	O
a	O
carefully	O
chosen	O
domain	O
of	O
a	O
variable	O
in	O
order	O
to	O
obtain	O
complicated	O
behavior	O
from	O
a	O
relatively	O
simple	O
set	O
of	O
functions	O
we	O
will	O
explore	O
a	O
practical	O
application	O
of	O
this	O
idea	O
later	O
in	O
section	O
r	O
energy-based	O
models	O
many	O
interesting	O
theoretical	O
results	O
about	O
undirected	O
models	O
depend	O
on	O
the	O
asx	O
px	O
a	O
convenient	O
way	O
to	O
enforce	O
this	O
condition	O
is	O
to	O
use	O
sumption	O
that	O
an	O
energy-based	O
model	O
where	O
e	O
exp	O
x	O
p	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
a	O
d	O
b	O
e	O
c	O
f	O
a	O
b	O
b	O
figure	O
z	O
tions	O
this	O
b	O
c	O
c	O
graph	O
implies	O
b	O
e	O
e	O
that	O
pa	O
b	O
c	O
d	O
e	O
f	O
can	O
be	O
written	O
as	O
e	O
f	O
f	O
for	O
an	O
appropriate	O
choice	O
of	O
the	O
func	O
a	O
d	O
d	O
and	O
ex	O
is	O
known	O
as	O
the	O
energy	B
function	I
because	O
expz	O
is	O
positive	O
for	O
all	O
z	O
this	O
guarantees	O
that	O
no	O
energy	B
function	I
will	O
result	O
in	O
a	O
probability	O
of	O
zero	O
for	O
any	O
state	O
x	O
being	O
completely	O
free	O
to	O
choose	O
the	O
energy	B
function	I
makes	O
learning	O
simpler	O
if	O
we	O
learned	O
the	O
clique	O
potentials	O
directly	O
we	O
would	O
need	O
to	O
use	O
constrained	O
optimization	O
to	O
arbitrarily	O
impose	O
some	O
specific	O
minimal	O
probability	O
value	O
by	O
learning	O
the	O
energy	B
function	I
we	O
can	O
use	O
unconstrained	O
the	O
probabilities	O
in	O
an	O
energy-based	O
model	O
can	O
approach	O
arbitrarily	O
close	O
to	O
zero	O
but	O
never	O
reach	O
it	O
et	O
al	O
et	O
al	O
ackley	O
is	O
an	O
example	B
of	O
a	O
any	O
distribution	O
of	O
the	O
form	O
given	O
by	O
equation	O
boltzmann	B
distribution	I
for	O
this	O
reason	O
many	O
energy-based	O
models	O
are	O
called	O
boltzmann	O
machines	O
et	O
al	O
hinton	O
and	O
sejnowski	O
there	O
is	O
no	O
accepted	O
guideline	O
for	O
when	O
to	O
call	O
a	O
model	O
an	O
energy-based	O
model	O
and	O
when	O
to	O
call	O
it	O
a	O
boltzmann	O
machine	O
the	O
term	O
boltzmann	O
machine	O
was	O
first	O
introduced	O
to	O
describe	O
a	O
model	O
with	O
exclusively	O
binary	O
variables	O
but	O
today	O
many	O
models	O
such	O
as	O
the	O
mean-covariance	O
restricted	O
boltzmann	O
machine	O
incorporate	O
real-valued	O
variables	O
as	O
well	O
while	O
boltzmann	O
machines	O
were	O
originally	O
defined	O
to	O
encompass	O
both	O
models	O
with	O
and	O
without	O
latent	O
variables	O
the	O
term	O
boltzmann	O
machine	O
is	O
today	O
most	O
often	O
used	O
to	O
designate	O
models	O
with	O
latent	O
variables	O
while	O
boltzmann	O
machines	O
without	O
latent	O
variables	O
are	O
more	O
often	O
called	O
markov	O
random	O
fields	O
or	O
log-linear	O
models	O
hinton	O
cliques	O
in	O
an	O
undirected	O
graph	O
correspond	O
to	O
factors	O
of	O
the	O
unnormalized	O
probability	O
function	O
because	O
expa	O
expb	O
exp	O
a	O
b	O
this	O
means	O
that	O
different	O
cliques	O
in	O
the	O
undirected	O
graph	O
correspond	O
to	O
the	O
different	O
terms	O
of	O
the	O
energy	B
function	I
in	O
other	O
words	O
an	O
energy-based	O
model	O
is	O
just	O
a	O
special	O
kind	O
of	O
markov	O
network	O
the	O
exponentiation	O
makes	O
each	O
term	O
in	O
the	O
energy	B
function	I
correspond	O
to	O
a	O
factor	O
for	O
a	O
different	O
clique	O
see	O
figure	O
for	O
an	O
example	B
of	O
how	O
to	O
read	O
the	O
some	O
models	O
we	O
may	O
still	O
need	O
to	O
use	O
constrained	O
optimization	O
to	O
make	O
sure	O
z	O
exists	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
a	O
d	O
b	O
e	O
c	O
f	O
figure	O
this	O
graph	O
implies	O
that	O
ea	O
b	O
c	O
d	O
e	O
f	O
b	O
c	O
c	O
e	O
e	O
energy	O
functions	O
note	O
that	O
we	O
can	O
obtain	O
the	O
functions	O
in	O
figure	O
to	O
the	O
exponential	O
of	O
the	O
corresponding	O
negative	O
energy	O
e	O
g	O
a	O
b	O
b	O
e	O
f	O
f	O
for	O
an	O
appropriate	O
choice	O
of	O
the	O
per-clique	O
by	O
setting	O
each	O
a	O
b	O
b	O
exp	O
e	O
a	O
b	O
can	O
be	O
written	O
as	O
e	O
a	O
d	O
d	O
e	O
b	O
e	O
e	O
e	O
form	O
of	O
the	O
energy	B
function	I
from	O
an	O
undirected	O
graph	O
structure	O
one	O
can	O
view	O
an	O
energy-based	O
model	O
with	O
multiple	O
terms	O
in	O
its	O
energy	B
function	I
as	O
being	O
a	O
product	B
of	I
experts	I
each	O
term	O
in	O
the	O
energy	B
function	I
corresponds	O
to	O
another	O
factor	O
in	O
the	O
probability	B
distribution	I
each	O
term	O
of	O
the	O
energy	B
function	I
can	O
be	O
thought	O
of	O
as	O
an	O
expert	O
that	O
determines	O
whether	O
a	O
particular	O
soft	O
constraint	O
is	O
satisfied	O
each	O
expert	O
may	O
enforce	O
only	O
one	O
constraint	O
that	O
concerns	O
only	O
a	O
low-dimensional	O
projection	O
of	O
the	O
random	O
variables	O
but	O
when	O
combined	O
by	O
multiplication	O
of	O
probabilities	O
the	O
experts	O
together	O
enforce	O
a	O
complicated	O
highdimensional	O
constraint	O
this	O
sign	O
in	O
equation	O
one	O
part	O
of	O
the	O
definition	O
of	O
an	O
energy-based	O
model	O
serves	O
no	O
functional	O
purpose	O
from	O
a	O
machine	B
learning	I
point	O
of	O
view	O
the	O
sign	O
could	O
be	O
incorporated	O
into	O
the	O
definition	O
of	O
e	O
for	O
many	O
choices	O
of	O
the	O
function	O
e	O
the	O
learning	O
algorithm	O
is	O
free	O
to	O
determine	O
the	O
sign	O
of	O
the	O
energy	O
anyway	O
the	O
sign	O
is	O
present	O
primarily	O
to	O
preserve	O
compatibility	O
between	O
the	O
machine	B
learning	I
literature	O
and	O
the	O
physics	O
literature	O
many	O
advances	O
in	O
probabilistic	O
modeling	O
were	O
originally	O
developed	O
by	O
statistical	O
physicists	O
for	O
whom	O
e	O
refers	O
to	O
actual	O
physical	O
energy	O
and	O
does	O
not	O
have	O
arbitrary	O
sign	O
terminology	O
such	O
as	O
energy	O
and	O
partition	O
function	O
remains	O
associated	O
with	O
these	O
techniques	O
even	O
though	O
their	O
mathematical	O
applicability	O
is	O
broader	O
than	O
the	O
physics	O
context	O
in	O
which	O
they	O
were	O
developed	O
some	O
machine	B
learning	I
researchers	O
who	O
referred	O
to	O
negative	O
energy	O
as	O
harmony	O
have	O
chosen	O
to	O
emit	O
the	O
negation	O
but	O
this	O
is	O
not	O
the	O
standard	O
convention	O
smolensky	O
many	O
algorithms	O
that	O
operate	O
on	O
probabilistic	O
models	O
do	O
not	O
need	O
to	O
compute	O
pmodel	O
but	O
only	O
log	O
pmodelx	O
for	O
energy-based	O
models	O
with	O
latent	O
variables	O
h	O
these	O
algorithms	O
are	O
sometimes	O
phrased	O
in	O
terms	O
of	O
the	O
negative	O
of	O
this	O
quantity	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
a	O
s	O
b	O
a	O
s	O
b	O
figure	O
the	O
path	O
between	O
random	B
variable	I
a	O
and	O
random	B
variable	I
b	O
through	O
s	O
is	O
active	O
because	O
s	O
is	O
not	O
observed	O
this	O
means	O
that	O
a	O
and	O
b	O
are	O
not	O
separated	O
here	O
s	O
is	O
shaded	O
in	O
to	O
indicate	O
that	O
it	O
is	O
observed	O
because	O
the	O
only	O
path	O
between	O
a	O
and	O
b	O
is	O
through	O
s	O
and	O
that	O
path	O
is	O
inactive	O
we	O
can	O
conclude	O
that	O
a	O
and	O
b	O
are	O
separated	O
given	O
s	O
called	O
the	O
free	O
energy	O
f	O
x	O
log	O
h	O
e	O
x	O
h	O
exp	O
in	O
this	O
book	O
we	O
usually	O
prefer	O
the	O
more	O
general	O
log	O
pmodel	O
formulation	O
separation	O
and	O
d-separation	B
the	O
edges	O
in	O
a	O
graphical	O
model	O
tell	O
us	O
which	O
variables	O
directly	O
interact	O
we	O
often	O
need	O
to	O
know	O
which	O
variables	O
indirectly	O
interact	O
some	O
of	O
these	O
indirect	O
interactions	O
can	O
be	O
enabled	O
or	O
disabled	O
by	O
observing	O
other	O
variables	O
more	O
formally	O
we	O
would	O
like	O
to	O
know	O
which	O
subsets	O
of	O
variables	O
are	O
conditionally	O
independent	O
from	O
each	O
other	O
given	O
the	O
values	O
of	O
other	O
subsets	O
of	O
variables	O
identifying	O
the	O
conditional	O
independences	O
in	O
a	O
graph	O
is	O
very	O
simple	O
in	O
the	O
case	O
of	O
undirected	O
models	O
in	O
this	O
case	O
conditional	O
independence	O
implied	O
by	O
the	O
graph	O
is	O
called	O
separation	O
we	O
say	O
that	O
a	O
set	O
of	O
variables	O
a	O
is	O
separated	O
from	O
another	O
set	O
of	O
variables	O
b	O
given	O
a	O
third	O
set	O
of	O
variables	O
s	O
if	O
the	O
graph	O
structure	O
implies	O
that	O
a	O
is	O
independent	O
from	O
b	O
given	O
s	O
if	O
two	O
variables	O
a	O
and	O
b	O
are	O
connected	O
by	O
a	O
path	O
involving	O
only	O
unobserved	O
variables	O
then	O
those	O
variables	O
are	O
not	O
separated	O
if	O
no	O
path	O
exists	O
between	O
them	O
or	O
all	O
paths	O
contain	O
an	O
observed	O
variable	O
then	O
they	O
are	O
separated	O
we	O
refer	O
to	O
paths	O
involving	O
only	O
unobserved	O
variables	O
as	O
active	O
and	O
paths	O
including	O
an	O
observed	O
variable	O
as	O
inactive	O
when	O
we	O
draw	O
a	O
graph	O
we	O
can	O
indicate	O
observed	O
variables	O
by	O
shading	O
them	O
in	O
for	O
a	O
depiction	O
of	O
how	O
active	O
and	O
inactive	O
paths	O
in	O
an	O
undirected	O
for	O
an	O
example	B
of	O
reading	O
see	O
figure	O
model	O
look	O
when	O
drawn	O
in	O
this	O
way	O
see	O
figure	O
separation	O
from	O
an	O
undirected	O
graph	O
similar	O
concepts	O
apply	O
to	O
directed	O
models	O
except	O
that	O
in	O
the	O
context	O
of	O
directed	O
models	O
these	O
concepts	O
are	O
referred	O
to	O
as	O
d-separation	B
the	O
d	O
stands	O
for	O
dependence	O
d-separation	B
for	O
directed	O
graphs	O
is	O
defined	O
the	O
same	O
as	O
separation	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
a	O
d	O
b	O
c	O
figure	O
an	O
example	B
of	O
reading	O
separation	O
properties	O
from	O
an	O
undirected	O
graph	O
here	O
b	O
is	O
shaded	O
to	O
indicate	O
that	O
it	O
is	O
observed	O
because	O
observing	O
b	O
blocks	O
the	O
only	O
path	O
from	O
a	O
to	O
c	O
we	O
say	O
that	O
a	O
and	O
c	O
are	O
separated	O
from	O
each	O
other	O
given	O
b	O
the	O
observation	O
of	O
b	O
also	O
blocks	O
one	O
path	O
between	O
a	O
and	O
d	O
but	O
there	O
is	O
a	O
second	O
active	O
path	O
between	O
them	O
therefore	O
a	O
and	O
d	O
are	O
not	O
separated	O
given	O
b	O
for	O
undirected	O
graphs	O
we	O
say	O
that	O
a	O
set	O
of	O
variables	O
a	O
is	O
d-separated	O
from	O
another	O
set	O
of	O
variables	O
b	O
given	O
a	O
third	O
set	O
of	O
variables	O
s	O
if	O
the	O
graph	O
structure	O
implies	O
that	O
is	O
independent	O
from	O
given	O
s	O
a	O
b	O
as	O
with	O
undirected	O
models	O
we	O
can	O
examine	O
the	O
independences	O
implied	O
by	O
the	O
graph	O
by	O
looking	O
at	O
what	O
active	O
paths	O
exist	O
in	O
the	O
graph	O
as	O
before	O
two	O
variables	O
are	O
dependent	O
if	O
there	O
is	O
an	O
active	O
path	O
between	O
them	O
and	O
d-separated	O
if	O
no	O
such	O
path	O
exists	O
in	O
directed	O
nets	O
determining	O
whether	O
a	O
path	O
is	O
active	O
is	O
somewhat	O
more	O
complicated	O
see	O
figure	O
for	O
a	O
guide	O
to	O
identifying	O
active	O
paths	O
in	O
a	O
directed	O
model	O
see	O
figure	O
for	O
an	O
example	B
of	O
reading	O
some	O
properties	O
from	O
a	O
graph	O
it	O
is	O
important	O
to	O
remember	O
that	O
separation	O
and	O
d-separation	B
tell	O
us	O
only	O
about	O
those	O
conditional	O
independences	O
that	O
are	O
implied	O
by	O
the	O
graph	O
there	O
is	O
no	O
requirement	O
that	O
the	O
graph	O
imply	O
all	O
independences	O
that	O
are	O
present	O
in	O
particular	O
it	O
is	O
always	O
legitimate	O
to	O
use	O
the	O
complete	O
graph	O
graph	O
with	O
all	O
possible	O
edges	O
to	O
represent	O
any	O
distribution	O
in	O
fact	O
some	O
distributions	O
contain	O
independences	O
that	O
are	O
not	O
possible	O
to	O
represent	O
with	O
existing	O
graphical	O
notation	O
contextspecific	O
independences	O
are	O
independences	O
that	O
are	O
present	O
dependent	O
on	O
the	O
value	O
of	O
some	O
variables	O
in	O
the	O
network	O
for	O
example	B
consider	O
a	O
model	O
of	O
three	O
binary	O
variables	O
a	O
b	O
and	O
c	O
suppose	O
that	O
when	O
a	O
is	O
b	O
and	O
c	O
are	O
independent	O
but	O
when	O
a	O
is	O
b	O
is	O
deterministically	O
equal	O
to	O
c	O
encoding	O
the	O
behavior	O
when	O
a	O
requires	O
an	O
edge	O
connecting	O
b	O
and	O
c	O
the	O
graph	O
then	O
fails	O
to	O
indicate	O
that	O
b	O
and	O
c	O
are	O
independent	O
when	O
a	O
in	O
general	O
a	O
graph	O
will	O
never	O
imply	O
that	O
an	O
independence	O
exists	O
when	O
it	O
does	O
not	O
however	O
a	O
graph	O
may	O
fail	O
to	O
encode	O
an	O
independence	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
a	O
a	O
b	O
b	O
s	O
s	O
a	O
b	O
a	O
a	O
s	O
b	O
b	O
s	O
s	O
c	O
any	O
path	O
with	O
arrows	O
proceeding	O
directly	O
from	O
figure	O
all	O
of	O
the	O
kinds	O
of	O
active	O
paths	O
of	O
length	O
two	O
that	O
can	O
exist	O
between	O
random	O
variables	O
a	O
and	O
b	O
a	O
to	O
b	O
or	O
vice	O
versa	O
this	O
kind	O
of	O
path	O
becomes	O
blocked	O
if	O
s	O
is	O
observed	O
we	O
have	O
already	O
seen	O
this	O
kind	O
of	O
path	O
in	O
the	O
relay	O
race	O
example	B
and	O
b	O
are	O
connected	O
by	O
a	O
common	O
cause	O
s	O
for	O
example	B
suppose	O
s	O
is	O
a	O
variable	O
indicating	O
whether	O
or	O
not	O
there	O
is	O
a	O
hurricane	O
and	O
a	O
and	O
b	O
measure	O
the	O
wind	O
speed	O
at	O
two	O
different	O
nearby	O
weather	O
monitoring	O
outposts	O
if	O
we	O
observe	O
very	O
high	O
winds	O
at	O
station	O
a	O
we	O
might	O
expect	O
to	O
also	O
see	O
high	O
winds	O
at	O
b	O
this	O
kind	O
of	O
path	O
can	O
be	O
blocked	O
by	O
observing	O
s	O
if	O
we	O
already	O
know	O
there	O
is	O
a	O
hurricane	O
we	O
expect	O
to	O
see	O
high	O
winds	O
at	O
b	O
regardless	O
of	O
what	O
is	O
observed	O
at	O
a	O
a	O
lower	O
than	O
expected	O
wind	O
at	O
a	O
a	O
hurricane	O
would	O
not	O
change	O
our	O
expectation	B
of	O
winds	O
at	O
b	O
there	O
is	O
a	O
hurricane	O
however	O
if	O
s	O
is	O
not	O
observed	O
then	O
a	O
and	O
b	O
are	O
dependent	O
i	O
e	O
the	O
path	O
is	O
active	O
and	O
b	O
are	O
both	O
parents	O
of	O
s	O
this	O
is	O
called	O
a	O
v-structure	O
or	O
the	O
collider	O
case	O
the	O
v-structure	O
causes	O
a	O
and	O
b	O
to	O
be	O
related	O
by	O
the	O
explaining	O
away	O
effect	O
in	O
this	O
case	O
the	O
path	O
is	O
actually	O
active	O
when	O
s	O
is	O
observed	O
for	O
example	B
suppose	O
s	O
is	O
a	O
variable	O
indicating	O
that	O
your	O
colleague	O
is	O
not	O
at	O
work	O
the	O
variable	O
a	O
represents	O
her	O
being	O
sick	O
while	O
b	O
represents	O
her	O
being	O
on	O
vacation	O
if	O
you	O
observe	O
that	O
she	O
is	O
not	O
at	O
work	O
you	O
can	O
presume	O
she	O
is	O
probably	O
sick	O
or	O
on	O
vacation	O
but	O
it	O
is	O
not	O
especially	O
likely	O
that	O
both	O
have	O
happened	O
at	O
the	O
same	O
time	O
if	O
you	O
find	O
out	O
that	O
she	O
is	O
on	O
vacation	O
her	O
absence	O
you	O
can	O
infer	O
that	O
she	O
is	O
probably	O
not	O
also	O
this	O
fact	O
is	O
sufficient	O
to	O
sick	O
s	O
is	O
observed	O
for	O
example	B
suppose	O
that	O
c	O
is	O
a	O
variable	O
representing	O
whether	O
you	O
have	O
received	O
a	O
report	O
from	O
your	O
colleague	O
if	O
you	O
notice	O
that	O
you	O
have	O
not	O
received	O
the	O
report	O
this	O
increases	O
your	O
estimate	O
of	O
the	O
probability	O
that	O
she	O
is	O
not	O
at	O
work	O
today	O
which	O
in	O
turn	O
makes	O
it	O
more	O
likely	O
that	O
she	O
is	O
either	O
sick	O
or	O
on	O
vacation	O
the	O
only	O
way	O
to	O
block	O
a	O
path	O
through	O
a	O
v-structure	O
is	O
to	O
observe	O
none	O
of	O
the	O
descendants	O
of	O
the	O
shared	O
child	O
the	O
explaining	O
away	O
effect	O
happens	O
even	O
if	O
any	O
descendant	O
of	O
explain	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
a	O
d	O
c	O
b	O
e	O
figure	O
from	O
this	O
graph	O
we	O
can	O
read	O
out	O
several	O
d-separation	B
properties	O
examples	O
include	O
a	O
and	O
b	O
are	O
d-separated	O
given	O
the	O
empty	O
set	O
we	O
can	O
also	O
see	O
that	O
some	O
variables	O
are	O
no	O
longer	O
d-separated	O
when	O
we	O
observe	O
some	O
variables	O
a	O
and	O
e	O
are	O
d-separated	O
given	O
c	O
d	O
and	O
e	O
are	O
d-separated	O
given	O
c	O
a	O
and	O
b	O
are	O
not	O
d-separated	O
given	O
c	O
a	O
and	O
b	O
are	O
not	O
d-separated	O
given	O
d	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
converting	O
between	O
undirected	O
and	O
directed	O
graphs	O
we	O
often	O
refer	O
to	O
a	O
specific	O
machine	B
learning	I
model	O
as	O
being	O
undirected	O
or	O
directed	O
for	O
example	B
we	O
typically	O
refer	O
to	O
rbms	O
as	O
undirected	O
and	O
sparse	O
coding	O
as	O
directed	O
this	O
choice	O
of	O
wording	O
can	O
be	O
somewhat	O
misleading	O
because	O
no	O
probabilistic	O
model	O
is	O
inherently	O
directed	O
or	O
undirected	O
instead	O
some	O
models	O
are	O
most	O
easily	O
described	O
using	O
a	O
directed	O
graph	O
or	O
most	O
easily	O
described	O
using	O
an	O
undirected	O
graph	O
directed	O
models	O
and	O
undirected	O
models	O
both	O
have	O
their	O
advantages	O
and	O
disadvantages	O
neither	O
approach	O
is	O
clearly	O
superior	O
and	O
universally	O
preferred	O
instead	O
we	O
should	O
choose	O
which	O
language	O
to	O
use	O
for	O
each	O
task	O
this	O
choice	O
will	O
partially	O
depend	O
on	O
which	O
probability	B
distribution	I
we	O
wish	O
to	O
describe	O
we	O
may	O
choose	O
to	O
use	O
either	O
directed	O
modeling	O
or	O
undirected	O
modeling	O
based	O
on	O
which	O
approach	O
can	O
capture	O
the	O
most	O
independences	O
in	O
the	O
probability	B
distribution	I
or	O
which	O
approach	O
uses	O
the	O
fewest	O
edges	O
to	O
describe	O
the	O
distribution	O
there	O
are	O
other	O
factors	O
that	O
can	O
affect	O
the	O
decision	O
of	O
which	O
language	O
to	O
use	O
even	O
while	O
working	O
with	O
a	O
single	O
probability	B
distribution	I
we	O
may	O
sometimes	O
switch	O
between	O
different	O
modeling	O
languages	O
sometimes	O
a	O
different	O
language	O
becomes	O
more	O
appropriate	O
if	O
we	O
observe	O
a	O
certain	O
subset	O
of	O
variables	O
or	O
if	O
we	O
wish	O
to	O
perform	O
a	O
different	O
computational	O
task	O
for	O
example	B
the	O
directed	O
model	O
description	O
often	O
provides	O
a	O
straightforward	O
approach	O
to	O
efficiently	O
draw	O
samples	O
from	O
the	O
model	O
in	O
section	O
while	O
the	O
undirected	B
model	I
formulation	O
is	O
often	O
useful	O
for	O
deriving	O
approximate	B
inference	I
procedures	O
we	O
will	O
see	O
in	O
chapter	O
where	O
the	O
role	O
of	O
undirected	O
models	O
is	O
highlighted	O
in	O
equation	O
every	O
probability	B
distribution	I
can	O
be	O
represented	O
by	O
either	O
a	O
directed	O
model	O
or	O
by	O
an	O
undirected	B
model	I
in	O
the	O
worst	O
case	O
one	O
can	O
always	O
represent	O
any	O
distribution	O
by	O
using	O
a	O
complete	O
graph	O
in	O
the	O
case	O
of	O
a	O
directed	O
model	O
the	O
complete	O
graph	O
is	O
any	O
directed	O
acyclic	O
graph	O
where	O
we	O
impose	O
some	O
ordering	O
on	O
the	O
random	O
variables	O
and	O
each	O
variable	O
has	O
all	O
other	O
variables	O
that	O
precede	O
it	O
in	O
the	O
ordering	O
as	O
its	O
ancestors	O
in	O
the	O
graph	O
for	O
an	O
undirected	B
model	I
the	O
complete	O
graph	O
is	O
simply	O
a	O
graph	O
containing	O
a	O
single	O
clique	O
encompassing	O
all	O
of	O
the	O
variables	O
see	O
figure	O
for	O
an	O
example	B
of	O
course	O
the	O
utility	O
of	O
a	O
graphical	O
model	O
is	O
that	O
the	O
graph	O
implies	O
that	O
some	O
variables	O
do	O
not	O
interact	O
directly	O
the	O
complete	O
graph	O
is	O
not	O
very	O
useful	O
because	O
it	O
does	O
not	O
imply	O
any	O
independences	O
when	O
we	O
represent	O
a	O
probability	B
distribution	I
with	O
a	O
graph	O
we	O
want	O
to	O
choose	O
a	O
graph	O
that	O
implies	O
as	O
many	O
independences	O
as	O
possible	O
without	O
implying	O
any	O
independences	O
that	O
do	O
not	O
actually	O
exist	O
from	O
this	O
point	O
of	O
view	O
some	O
distributions	O
can	O
be	O
represented	O
more	O
efficiently	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
figure	O
examples	O
of	O
complete	O
graphs	O
which	O
can	O
describe	O
any	O
probability	B
distribution	I
here	O
we	O
show	O
examples	O
with	O
four	O
random	O
variables	O
complete	O
undirected	O
graph	O
in	O
the	O
undirected	O
case	O
the	O
complete	O
graph	O
is	O
unique	O
a	O
complete	O
directed	O
graph	O
in	O
the	O
directed	O
case	O
there	O
is	O
not	O
a	O
unique	O
complete	O
graph	O
we	O
choose	O
an	O
ordering	O
of	O
the	O
variables	O
and	O
draw	O
an	O
arc	O
from	O
each	O
variable	O
to	O
every	O
variable	O
that	O
comes	O
after	O
it	O
in	O
the	O
ordering	O
there	O
are	O
thus	O
a	O
factorial	O
number	O
of	O
complete	O
graphs	O
for	O
every	O
set	O
of	O
random	O
variables	O
in	O
this	O
example	B
we	O
order	O
the	O
variables	O
from	O
left	O
to	O
right	O
top	O
to	O
bottom	O
using	O
directed	O
models	O
while	O
other	O
distributions	O
can	O
be	O
represented	O
more	O
efficiently	O
using	O
undirected	O
models	O
in	O
other	O
words	O
directed	O
models	O
can	O
encode	O
some	O
independences	O
that	O
undirected	O
models	O
cannot	O
encode	O
and	O
vice	O
versa	O
directed	O
models	O
are	O
able	O
to	O
use	O
one	O
specific	O
kind	O
of	O
substructure	O
that	O
undirected	O
models	O
cannot	O
represent	O
perfectly	O
this	O
substructure	O
is	O
called	O
an	O
immorality	B
the	O
structure	O
occurs	O
when	O
two	O
random	O
variables	O
a	O
and	O
b	O
are	O
both	O
parents	O
of	O
a	O
third	O
random	B
variable	I
c	O
and	O
there	O
is	O
no	O
edge	O
directly	O
connecting	O
a	O
and	O
b	O
in	O
either	O
direction	O
name	O
immorality	B
may	O
seem	O
strange	O
it	O
was	O
coined	O
in	O
the	O
graphical	O
u	O
models	O
literature	O
as	O
a	O
joke	O
about	O
unmarried	O
parents	O
to	O
convert	O
a	O
directed	O
model	O
with	O
graph	O
for	O
u	O
every	O
pair	O
of	O
variables	O
x	O
and	O
y	O
we	O
add	O
an	O
undirected	O
edge	O
connecting	O
x	O
and	O
y	O
to	O
or	O
if	O
x	O
is	O
known	O
as	O
a	O
for	O
examples	O
of	O
converting	O
directed	O
models	O
to	O
into	O
an	O
undirected	B
model	I
we	O
need	O
to	O
create	O
a	O
new	O
graph	O
d	O
if	O
there	O
is	O
a	O
directed	O
edge	O
either	O
direction	O
connecting	O
x	O
and	O
y	O
in	O
of	O
a	O
third	O
variable	O
z	O
the	O
resulting	O
and	O
y	O
are	O
both	O
parents	O
in	O
moralized	B
graph	I
see	O
figure	O
undirected	O
models	O
via	O
moralization	O
d	O
d	O
u	O
d	O
likewise	O
undirected	O
models	O
can	O
include	O
substructures	O
that	O
no	O
directed	O
model	O
cannot	O
capture	O
all	O
of	O
the	O
can	O
represent	O
perfectly	O
specifically	O
a	O
directed	O
graph	O
conditional	O
independences	O
implied	O
by	O
an	O
undirected	O
graph	O
contains	O
a	O
loop	B
of	O
length	O
greater	O
than	O
three	O
unless	O
that	O
loop	B
also	O
contains	O
a	O
chord	B
a	O
loop	B
is	O
a	O
sequence	O
of	O
variables	O
connected	O
by	O
undirected	O
edges	O
with	O
the	O
last	O
variable	O
in	O
the	O
sequence	O
connected	O
back	O
to	O
the	O
first	O
variable	O
in	O
the	O
sequence	O
a	O
chord	B
is	O
a	O
connection	O
between	O
any	O
two	O
non-consecutive	O
variables	O
in	O
the	O
sequence	O
defining	O
a	O
loop	B
if	O
has	O
loops	O
of	O
length	O
four	O
or	O
greater	O
and	O
does	O
not	O
have	O
chords	O
for	O
these	O
loops	O
we	O
must	O
add	O
the	O
chords	O
before	O
we	O
can	O
convert	O
it	O
to	O
a	O
directed	O
model	O
adding	O
u	O
u	O
u	O
if	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
a	O
b	O
c	O
a	O
b	O
c	O
a	O
b	O
c	O
a	O
b	O
c	O
figure	O
examples	O
of	O
converting	O
directed	O
models	O
row	O
to	O
undirected	O
models	O
row	O
by	O
constructing	O
moralized	O
graphs	O
simple	O
chain	O
can	O
be	O
converted	O
to	O
a	O
moralized	B
graph	I
merely	O
by	O
replacing	O
its	O
directed	O
edges	O
with	O
undirected	O
edges	O
the	O
resulting	O
undirected	B
model	I
implies	O
exactly	O
the	O
same	O
set	O
of	O
independences	O
and	O
conditional	O
independences	O
this	O
graph	O
is	O
the	O
simplest	O
directed	O
model	O
that	O
cannot	O
be	O
converted	O
to	O
an	O
undirected	B
model	I
without	O
losing	O
some	O
independences	O
this	O
graph	O
consists	O
entirely	O
of	O
a	O
single	O
immorality	B
because	O
a	O
and	O
b	O
are	O
parents	O
of	O
c	O
they	O
are	O
connected	O
by	O
an	O
active	O
path	O
when	O
c	O
is	O
observed	O
to	O
capture	O
this	O
dependence	O
the	O
undirected	B
model	I
must	O
include	O
a	O
clique	O
encompassing	O
all	O
three	O
variables	O
this	O
clique	O
fails	O
to	O
encode	O
the	O
fact	O
that	O
a	O
b	O
general	O
moralization	O
may	O
add	O
many	O
edges	O
to	O
the	O
graph	O
thus	O
losing	O
many	O
implied	O
independences	O
for	O
example	B
this	O
sparse	O
coding	O
graph	O
requires	O
adding	O
moralizing	O
edges	O
between	O
every	O
pair	O
of	O
hidden	O
units	O
thus	O
introducing	O
a	O
quadratic	O
number	O
of	O
new	O
direct	O
dependences	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
a	O
d	O
b	O
c	O
a	O
d	O
b	O
c	O
a	O
d	O
b	O
c	O
b	O
d	O
figure	O
converting	O
an	O
undirected	B
model	I
to	O
a	O
directed	O
model	O
undirected	B
model	I
cannot	O
be	O
converted	O
directed	O
to	O
a	O
directed	O
model	O
because	O
it	O
has	O
a	O
loop	B
of	O
length	O
four	O
with	O
no	O
chords	O
specifically	O
the	O
undirected	B
model	I
encodes	O
two	O
different	O
independences	O
that	O
no	O
directed	O
model	O
can	O
capture	O
simultaneously	O
a	O
c	O
to	O
convert	O
the	O
undirected	B
model	I
to	O
a	O
directed	O
model	O
we	O
must	O
triangulate	O
the	O
graph	O
by	O
ensuring	O
that	O
all	O
loops	O
of	O
greater	O
than	O
length	O
three	O
have	O
a	O
chord	B
to	O
do	O
so	O
we	O
can	O
either	O
add	O
an	O
edge	O
connecting	O
a	O
and	O
c	O
or	O
we	O
can	O
add	O
an	O
edge	O
connecting	O
b	O
and	O
d	O
in	O
this	O
example	B
we	O
choose	O
to	O
add	O
the	O
edge	O
connecting	O
a	O
and	O
c	O
to	O
finish	O
the	O
conversion	O
process	O
we	O
must	O
assign	O
a	O
direction	O
to	O
each	O
edge	O
when	O
doing	O
so	O
we	O
must	O
not	O
create	O
any	O
directed	O
cycles	O
one	O
way	O
to	O
avoid	O
directed	O
cycles	O
is	O
to	O
impose	O
an	O
ordering	O
over	O
the	O
nodes	O
and	O
always	O
point	O
each	O
edge	O
from	O
the	O
node	O
that	O
comes	O
earlier	O
in	O
the	O
ordering	O
to	O
the	O
node	O
that	O
comes	O
later	O
in	O
the	O
ordering	O
in	O
this	O
example	B
we	O
use	O
the	O
variable	O
names	O
to	O
impose	O
alphabetical	O
order	O
a	O
c	O
and	O
b	O
d	O
u	O
u	O
these	O
chords	O
discards	O
some	O
of	O
the	O
independence	O
information	O
that	O
was	O
encoded	O
in	O
the	O
graph	O
formed	O
by	O
adding	O
chords	O
to	O
is	O
known	O
as	O
a	O
chordal	O
or	O
triangulated	O
graph	O
because	O
all	O
the	O
loops	O
can	O
now	O
be	O
described	O
in	O
terms	O
of	O
smaller	O
triangular	O
loops	O
to	O
build	O
a	O
directed	O
graph	O
from	O
the	O
chordal	B
graph	I
we	O
need	O
to	O
also	O
assign	O
d	O
directions	O
to	O
the	O
edges	O
when	O
doing	O
so	O
we	O
must	O
not	O
create	O
a	O
directed	O
cycle	O
in	O
or	O
the	O
result	O
does	O
not	O
define	O
a	O
valid	O
directed	O
probabilistic	O
model	O
one	O
way	O
to	O
assign	O
directions	O
to	O
the	O
edges	O
in	O
is	O
to	O
impose	O
an	O
ordering	O
on	O
the	O
random	O
variables	O
then	O
point	O
each	O
edge	O
from	O
the	O
node	O
that	O
comes	O
earlier	O
in	O
the	O
ordering	O
to	O
the	O
node	O
that	O
comes	O
later	O
in	O
the	O
ordering	O
see	O
figure	O
for	O
a	O
demonstration	O
d	O
d	O
factor	O
graphs	O
factor	O
graphs	O
are	O
another	O
way	O
of	O
drawing	O
undirected	O
models	O
that	O
resolve	O
an	O
ambiguity	O
in	O
the	O
graphical	O
representation	O
of	O
standard	O
undirected	B
model	I
syntax	O
in	O
an	O
undirected	B
model	I
the	O
scope	O
of	O
every	O
function	O
must	O
be	O
a	O
of	O
some	O
clique	O
in	O
the	O
graph	O
ambiguity	O
arises	O
because	O
it	O
is	O
not	O
clear	O
if	O
each	O
clique	O
actually	O
has	O
a	O
corresponding	O
factor	O
whose	O
scope	O
encompasses	O
the	O
entire	O
clique	O
for	O
example	B
a	O
clique	O
containing	O
three	O
nodes	O
may	O
correspond	O
to	O
a	O
factor	O
over	O
all	O
three	O
nodes	O
or	O
may	O
correspond	O
to	O
three	O
factors	O
that	O
each	O
contain	O
only	O
a	O
pair	O
of	O
the	O
nodes	O
subset	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
factor	O
graphs	O
resolve	O
this	O
ambiguity	O
by	O
explicitly	O
representing	O
the	O
scope	O
of	O
each	O
function	O
specifically	O
a	O
factor	B
graph	I
is	O
a	O
graphical	O
representation	O
of	O
an	O
undirected	B
model	I
that	O
consists	O
of	O
a	O
bipartite	O
undirected	O
graph	O
some	O
of	O
the	O
nodes	O
are	O
drawn	O
as	O
circles	O
these	O
nodes	O
correspond	O
to	O
random	O
variables	O
as	O
in	O
a	O
standard	O
undirected	B
model	I
the	O
rest	O
of	O
the	O
nodes	O
are	O
drawn	O
as	O
squares	O
these	O
nodes	O
correspond	O
to	O
the	O
factors	O
of	O
the	O
unnormalized	B
probability	B
distribution	I
variables	O
and	O
factors	O
may	O
be	O
connected	O
with	O
undirected	O
edges	O
a	O
variable	O
and	O
a	O
factor	O
are	O
connected	O
in	O
the	O
graph	O
if	O
and	O
only	O
if	O
the	O
variable	O
is	O
one	O
of	O
the	O
arguments	O
to	O
the	O
factor	O
in	O
the	O
unnormalized	B
probability	B
distribution	I
no	O
factor	O
may	O
be	O
connected	O
to	O
another	O
factor	O
in	O
the	O
graph	O
nor	O
can	O
a	O
variable	O
be	O
connected	O
to	O
a	O
variable	O
see	O
figure	O
for	O
an	O
example	B
of	O
how	O
factor	O
graphs	O
can	O
resolve	O
ambiguity	O
in	O
the	O
interpretation	O
of	O
undirected	O
networks	O
a	O
b	O
a	O
c	O
b	O
c	O
a	O
b	O
c	O
figure	O
an	O
example	B
of	O
how	O
a	O
factor	B
graph	I
can	O
resolve	O
ambiguity	O
in	O
the	O
interpretation	O
of	O
undirected	O
networks	O
undirected	O
network	O
with	O
a	O
clique	O
involving	O
three	O
variables	O
a	O
b	O
and	O
c	O
a	O
factor	B
graph	I
corresponding	O
to	O
the	O
same	O
undirected	B
model	I
this	O
factor	B
graph	I
has	O
one	O
factor	O
over	O
all	O
three	O
variables	O
another	O
valid	O
factor	B
graph	I
for	O
the	O
same	O
undirected	B
model	I
this	O
factor	B
graph	I
has	O
three	O
factors	O
each	O
over	O
only	O
two	O
variables	O
representation	O
inference	O
and	O
learning	O
are	O
all	O
asymptotically	O
cheaper	O
in	O
this	O
factor	B
graph	I
than	O
in	O
the	O
factor	B
graph	I
depicted	O
in	O
the	O
center	O
even	O
though	O
both	O
require	O
the	O
same	O
undirected	O
graph	O
to	O
represent	O
sampling	O
from	O
graphical	O
models	O
graphical	O
models	O
also	O
facilitate	O
the	O
task	O
of	O
drawing	O
samples	O
from	O
a	O
model	O
one	O
advantage	O
of	O
directed	O
graphical	O
models	O
is	O
that	O
a	O
simple	O
and	O
efficient	O
procedure	O
called	O
ancestral	O
sampling	O
can	O
produce	O
a	O
sample	O
from	O
the	O
joint	O
distribution	O
represented	O
by	O
the	O
model	O
the	O
basic	O
idea	O
is	O
to	O
sort	O
the	O
variables	O
xi	O
in	O
the	O
graph	O
into	O
a	O
topological	O
ordering	O
so	O
that	O
for	O
all	O
i	O
and	O
j	O
j	O
is	O
greater	O
than	O
i	O
if	O
xi	O
is	O
a	O
parent	O
of	O
xj	O
the	O
variables	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
p	O
and	O
so	O
on	O
until	O
finally	O
we	O
sample	O
p	O
p	O
can	O
then	O
be	O
sampled	O
in	O
this	O
order	O
in	O
other	O
words	O
we	O
first	O
sample	O
p	O
agxn	O
then	O
sample	O
p	O
p	O
agxi	O
is	O
easy	O
to	O
sample	O
from	O
so	O
long	O
as	O
each	O
conditional	O
distribution	O
pxi	O
then	O
the	O
whole	O
model	O
is	O
easy	O
to	O
sample	O
from	O
the	O
topological	O
sorting	O
operation	B
guarantees	O
that	O
we	O
can	O
read	O
the	O
conditional	O
distributions	O
in	O
equation	O
and	O
sample	O
from	O
them	O
in	O
order	O
without	O
the	O
topological	O
sorting	O
we	O
might	O
attempt	O
to	O
sample	O
a	O
variable	O
before	O
its	O
parents	O
are	O
available	O
for	O
some	O
graphs	O
more	O
than	O
one	O
topological	O
ordering	O
is	O
possible	O
ancestral	O
sampling	O
may	O
be	O
used	O
with	O
any	O
of	O
these	O
topological	O
orderings	O
ancestral	O
sampling	O
is	O
generally	O
very	O
fast	O
sampling	O
from	O
each	O
condi	O
tional	O
is	O
easy	O
and	O
convenient	O
one	O
drawback	O
to	O
ancestral	O
sampling	O
is	O
that	O
it	O
only	O
applies	O
to	O
directed	O
graphical	O
models	O
another	O
drawback	O
is	O
that	O
it	O
does	O
not	O
support	O
every	O
conditional	O
sampling	O
operation	B
when	O
we	O
wish	O
to	O
sample	O
from	O
a	O
subset	O
of	O
the	O
variables	O
in	O
a	O
directed	O
graphical	O
model	O
given	O
some	O
other	O
variables	O
we	O
often	O
require	O
that	O
all	O
the	O
conditioning	O
variables	O
come	O
earlier	O
than	O
the	O
variables	O
to	O
be	O
sampled	O
in	O
the	O
ordered	O
graph	O
in	O
this	O
case	O
we	O
can	O
sample	O
from	O
the	O
local	O
conditional	B
probability	I
distributions	O
specified	O
by	O
the	O
model	O
distribution	O
otherwise	O
the	O
conditional	O
distributions	O
we	O
need	O
to	O
sample	O
from	O
are	O
the	O
posterior	O
distributions	O
given	O
the	O
observed	O
variables	O
these	O
posterior	O
distributions	O
are	O
usually	O
not	O
explicitly	O
specified	O
and	O
parametrized	O
in	O
the	O
model	O
inferring	O
these	O
posterior	O
distributions	O
can	O
be	O
costly	O
in	O
models	O
where	O
this	O
is	O
the	O
case	O
ancestral	O
sampling	O
is	O
no	O
longer	O
efficient	O
unfortunately	O
ancestral	O
sampling	O
is	O
applicable	O
only	O
to	O
directed	O
models	O
we	O
can	O
sample	O
from	O
undirected	O
models	O
by	O
converting	O
them	O
to	O
directed	O
models	O
but	O
this	O
often	O
requires	O
solving	O
intractable	O
inference	O
problems	O
determine	O
the	O
marginal	O
distribution	O
over	O
the	O
root	O
nodes	O
of	O
the	O
new	O
directed	O
graph	O
or	O
requires	O
introducing	O
so	O
many	O
edges	O
that	O
the	O
resulting	O
directed	O
model	O
becomes	O
intractable	O
sampling	O
from	O
an	O
undirected	B
model	I
without	O
first	O
converting	O
it	O
to	O
a	O
directed	O
model	O
seems	O
to	O
require	O
resolving	O
cyclical	O
dependencies	O
every	O
variable	O
interacts	O
with	O
every	O
other	O
variable	O
so	O
there	O
is	O
no	O
clear	O
beginning	O
point	O
for	O
the	O
sampling	O
process	O
unfortunately	O
drawing	O
samples	O
from	O
an	O
undirected	O
graphical	O
model	O
is	O
an	O
expensive	O
multi-pass	O
process	O
the	O
conceptually	O
simplest	O
approach	O
is	O
gibbs	O
sampling	O
suppose	O
we	O
have	O
a	O
graphical	O
model	O
over	O
an	O
n-dimensional	O
vector	O
of	O
random	O
variables	O
x	O
we	O
iteratively	O
visit	O
each	O
variable	O
xi	O
and	O
draw	O
a	O
sample	O
conditioned	O
on	O
all	O
of	O
the	O
other	O
variables	O
from	O
pxi	O
i	O
due	O
to	O
the	O
separation	O
properties	O
of	O
the	O
graphical	O
model	O
we	O
can	O
equivalently	O
condition	O
on	O
only	O
the	O
neighbors	O
of	O
xi	O
unfortunately	O
after	O
we	O
have	O
made	O
one	O
pass	O
through	O
the	O
graphical	O
model	O
and	O
sampled	O
all	O
n	O
variables	O
we	O
still	O
do	O
not	O
have	O
a	O
fair	O
sample	O
from	O
px	O
instead	O
we	O
must	O
repeat	O
the	O
x	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
process	O
and	O
resample	O
all	O
n	O
variables	O
using	O
the	O
updated	O
values	O
of	O
their	O
neighbors	O
asymptotically	O
after	O
many	O
repetitions	O
this	O
process	O
converges	O
to	O
sampling	O
from	O
the	O
correct	O
distribution	O
it	O
can	O
be	O
difficult	O
to	O
determine	O
when	O
the	O
samples	O
have	O
reached	O
a	O
sufficiently	O
accurate	O
approximation	O
of	O
the	O
desired	O
distribution	O
sampling	O
techniques	O
for	O
undirected	O
models	O
are	O
an	O
advanced	O
topic	O
covered	O
in	O
more	O
detail	O
in	O
chapter	O
advantages	O
of	O
structured	O
modeling	O
the	O
primary	O
advantage	O
of	O
using	O
structured	O
probabilistic	O
models	O
is	O
that	O
they	O
allow	O
us	O
to	O
dramatically	O
reduce	O
the	O
cost	O
of	O
representing	O
probability	O
distributions	O
as	O
well	O
as	O
learning	O
and	O
inference	O
sampling	O
is	O
also	O
accelerated	O
in	O
the	O
case	O
of	O
directed	O
models	O
while	O
the	O
situation	O
can	O
be	O
complicated	O
with	O
undirected	O
models	O
the	O
primary	O
mechanism	O
that	O
allows	O
all	O
of	O
these	O
operations	O
to	O
use	O
less	O
runtime	O
and	O
memory	O
is	O
choosing	O
to	O
not	O
model	O
certain	O
interactions	O
graphical	O
models	O
convey	O
information	O
by	O
leaving	O
edges	O
out	O
anywhere	O
there	O
is	O
not	O
an	O
edge	O
the	O
model	O
specifies	O
the	O
assumption	O
that	O
we	O
do	O
not	O
need	O
to	O
model	O
a	O
direct	O
interaction	O
a	O
less	O
quantifiable	O
benefit	O
of	O
using	O
structured	O
probabilistic	O
models	O
is	O
that	O
they	O
allow	O
us	O
to	O
explicitly	O
separate	O
representation	O
of	O
knowledge	O
from	O
learning	O
of	O
knowledge	O
or	O
inference	O
given	O
existing	O
knowledge	O
this	O
makes	O
our	O
models	O
easier	O
to	O
develop	O
and	O
debug	O
we	O
can	O
design	O
analyze	O
and	O
evaluate	O
learning	O
algorithms	O
and	O
inference	O
algorithms	O
that	O
are	O
applicable	O
to	O
broad	O
classes	O
of	O
graphs	O
independently	O
we	O
can	O
design	O
models	O
that	O
capture	O
the	O
relationships	O
we	O
believe	O
are	O
important	O
in	O
our	O
data	O
we	O
can	O
then	O
combine	O
these	O
different	O
algorithms	O
and	O
structures	O
and	O
obtain	O
a	O
cartesian	O
product	O
of	O
different	O
possibilities	O
it	O
would	O
be	O
much	O
more	O
difficult	O
to	O
design	O
end-to-end	O
algorithms	O
for	O
every	O
possible	O
situation	O
learning	O
about	O
dependencies	O
a	O
good	O
generative	O
model	O
needs	O
to	O
accurately	O
capture	O
the	O
distribution	O
over	O
the	O
observed	O
or	O
visible	O
variables	O
v	O
often	O
the	O
different	O
elements	O
of	O
v	O
are	O
highly	O
dependent	O
on	O
each	O
other	O
in	O
the	O
context	O
of	O
deep	O
learning	O
the	O
approach	O
most	O
commonly	O
used	O
to	O
model	O
these	O
dependencies	O
is	O
to	O
introduce	O
several	O
latent	O
or	O
hidden	O
variables	O
h	O
the	O
model	O
can	O
then	O
capture	O
dependencies	O
between	O
any	O
pair	O
of	O
variables	O
v	O
i	O
and	O
vj	O
indirectly	O
via	O
direct	O
dependencies	O
between	O
vi	O
and	O
h	O
and	O
direct	O
dependencies	O
between	O
and	O
v	O
h	O
j	O
a	O
good	O
model	O
of	O
v	O
which	O
did	O
not	O
contain	O
any	O
latent	O
variables	O
would	O
need	O
to	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
have	O
very	O
large	O
numbers	O
of	O
parents	O
per	O
node	O
in	O
a	O
bayesian	O
network	O
or	O
very	O
large	O
cliques	O
in	O
a	O
markov	O
network	O
just	O
representing	O
these	O
higher	O
order	O
interactions	O
is	O
costly	O
both	O
in	O
a	O
computational	O
sense	O
because	O
the	O
number	O
of	O
parameters	O
that	O
must	O
be	O
stored	O
in	O
memory	O
scales	O
exponentially	O
with	O
the	O
number	O
of	O
members	O
in	O
a	O
clique	O
but	O
also	O
in	O
a	O
statistical	O
sense	O
because	O
this	O
exponential	O
number	O
of	O
parameters	O
requires	O
a	O
wealth	O
of	O
data	O
to	O
estimate	O
accurately	O
when	O
the	O
model	O
is	O
intended	O
to	O
capture	O
dependencies	O
between	O
visible	O
variables	O
with	O
direct	O
connections	O
it	O
is	O
usually	O
infeasible	O
to	O
connect	O
all	O
variables	O
so	O
the	O
graph	O
must	O
be	O
designed	O
to	O
connect	O
those	O
variables	O
that	O
are	O
tightly	O
coupled	O
and	O
omit	O
edges	O
between	O
other	O
variables	O
an	O
entire	O
field	O
of	O
machine	B
learning	I
called	O
structure	B
learning	I
is	O
devoted	O
to	O
this	O
problem	O
for	O
a	O
good	O
reference	O
on	O
structure	B
learning	I
see	O
and	O
friedman	O
most	O
structure	B
learning	I
techniques	O
are	O
a	O
form	O
of	O
greedy	O
search	O
a	O
structure	O
is	O
proposed	O
a	O
model	O
with	O
that	O
structure	O
is	O
trained	O
then	O
given	O
a	O
score	O
the	O
score	O
rewards	O
high	O
training	O
set	O
accuracy	B
and	O
penalizes	O
model	O
complexity	O
candidate	O
structures	O
with	O
a	O
small	O
number	O
of	O
edges	O
added	O
or	O
removed	O
are	O
then	O
proposed	O
as	O
the	O
next	O
step	O
of	O
the	O
search	O
the	O
search	O
proceeds	O
to	O
a	O
new	O
structure	O
that	O
is	O
expected	O
to	O
increase	O
the	O
score	O
using	O
latent	O
variables	O
instead	O
of	O
adaptive	O
structure	O
avoids	O
the	O
need	O
to	O
perform	O
discrete	O
searches	O
and	O
multiple	O
rounds	O
of	O
training	O
a	O
fixed	O
structure	O
over	O
visible	O
and	O
hidden	O
variables	O
can	O
use	O
direct	O
interactions	O
between	O
visible	O
and	O
hidden	O
units	O
to	O
impose	O
indirect	O
interactions	O
between	O
visible	O
units	O
using	O
simple	O
parameter	O
learning	O
techniques	O
we	O
can	O
learn	O
a	O
model	O
with	O
a	O
fixed	O
structure	O
that	O
imputes	O
the	O
right	O
structure	O
on	O
the	O
marginal	O
p	O
latent	O
variables	O
have	O
advantages	O
beyond	O
their	O
role	O
in	O
efficiently	O
capturing	O
pv	O
the	O
new	O
variables	O
h	O
also	O
provide	O
an	O
alternative	O
representation	O
for	O
v	O
for	O
example	B
as	O
discussed	O
in	O
section	O
the	O
mixture	O
of	O
gaussians	O
model	O
learns	O
a	O
latent	B
variable	I
that	O
corresponds	O
to	O
which	O
category	O
of	O
examples	O
the	O
input	O
was	O
drawn	O
from	O
this	O
means	O
that	O
the	O
latent	B
variable	I
in	O
a	O
mixture	O
of	O
gaussians	O
model	O
can	O
be	O
used	O
to	O
do	O
classification	B
in	O
chapter	O
we	O
saw	O
how	O
simple	O
probabilistic	O
models	O
like	O
sparse	O
coding	O
learn	O
latent	O
variables	O
that	O
can	O
be	O
used	O
as	O
input	O
features	O
for	O
a	O
classifier	O
or	O
as	O
coordinates	O
along	O
a	O
manifold	B
other	O
models	O
can	O
be	O
used	O
in	O
this	O
same	O
way	O
but	O
deeper	O
models	O
and	O
models	O
with	O
different	O
kinds	O
of	O
interactions	O
can	O
create	O
even	O
richer	O
descriptions	O
of	O
the	O
input	O
many	O
approaches	O
accomplish	O
feature	B
learning	O
by	O
learning	O
latent	O
variables	O
often	O
given	O
some	O
model	O
of	O
v	O
and	O
h	O
experimental	O
observations	O
show	O
that	O
eh	O
v	O
or	O
argmaxhph	O
v	O
is	O
a	O
good	O
feature	B
mapping	O
for	O
v	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
inference	O
and	O
approximate	B
inference	I
one	O
of	O
the	O
main	O
ways	O
we	O
can	O
use	O
a	O
probabilistic	O
model	O
is	O
to	O
ask	O
questions	O
about	O
how	O
variables	O
are	O
related	O
to	O
each	O
other	O
given	O
a	O
set	O
of	O
medical	O
tests	O
we	O
can	O
ask	O
what	O
disease	O
a	O
patient	O
might	O
have	O
in	O
a	O
latent	B
variable	I
model	O
we	O
might	O
want	O
to	O
extract	O
features	O
eh	O
v	O
describing	O
the	O
observed	O
variables	O
v	O
sometimes	O
we	O
need	O
to	O
solve	O
such	O
problems	O
in	O
order	O
to	O
perform	O
other	O
tasks	O
we	O
often	O
train	O
our	O
models	O
using	O
the	O
principle	O
of	O
maximum	B
likelihood	I
because	O
p	O
h	O
v	O
log	O
log	O
p	O
v	O
v	O
h	O
p	O
h	O
v	O
eh	O
p	O
we	O
often	O
want	O
to	O
compute	O
ph	O
v	O
in	O
order	O
to	O
implement	O
a	O
learning	O
rule	O
all	O
of	O
these	O
are	O
examples	O
of	O
inference	O
problems	O
in	O
which	O
we	O
must	O
predict	O
the	O
value	O
of	O
some	O
variables	O
given	O
other	O
variables	O
or	O
predict	O
the	O
probability	B
distribution	I
over	O
some	O
variables	O
given	O
the	O
value	O
of	O
other	O
variables	O
unfortunately	O
for	O
most	O
interesting	O
deep	O
models	O
these	O
inference	O
problems	O
are	O
intractable	O
even	O
when	O
we	O
use	O
a	O
structured	O
graphical	O
model	O
to	O
simplify	O
them	O
the	O
graph	O
structure	O
allows	O
us	O
to	O
represent	O
complicated	O
high-dimensional	O
distributions	O
with	O
a	O
reasonable	O
number	O
of	O
parameters	O
but	O
the	O
graphs	O
used	O
for	O
deep	O
learning	O
are	O
usually	O
not	O
restrictive	O
enough	O
to	O
also	O
allow	O
efficient	O
inference	O
it	O
is	O
straightforward	O
to	O
see	O
that	O
computing	O
the	O
marginal	B
probability	I
of	O
a	O
general	O
graphical	O
model	O
is	O
hard	O
the	O
complexity	O
class	O
is	O
a	O
generalization	B
of	O
the	O
complexity	O
class	O
np	O
problems	O
in	O
np	O
require	O
determining	O
only	O
whether	O
a	O
problem	O
has	O
a	O
solution	O
and	O
finding	O
a	O
solution	O
if	O
one	O
exists	O
problems	O
in	O
require	O
counting	O
the	O
number	O
of	O
solutions	O
to	O
construct	O
a	O
worst-case	O
graphical	O
model	O
imagine	O
that	O
we	O
define	O
a	O
graphical	O
model	O
over	O
the	O
binary	O
variables	O
in	O
a	O
problem	O
we	O
can	O
impose	O
a	O
uniform	B
distribution	I
over	O
these	O
variables	O
we	O
can	O
then	O
add	O
one	O
binary	O
latent	B
variable	I
per	O
clause	O
that	O
indicates	O
whether	O
each	O
clause	O
is	O
satisfied	O
we	O
can	O
then	O
add	O
another	O
latent	B
variable	I
indicating	O
whether	O
all	O
of	O
the	O
clauses	O
are	O
satisfied	O
this	O
can	O
be	O
done	O
without	O
making	O
a	O
large	O
clique	O
by	O
building	O
a	O
reduction	O
tree	O
of	O
latent	O
variables	O
with	O
each	O
node	O
in	O
the	O
tree	O
reporting	O
whether	O
two	O
other	O
variables	O
are	O
satisfied	O
the	O
leaves	O
of	O
this	O
tree	O
are	O
the	O
variables	O
for	O
each	O
clause	O
the	O
root	O
of	O
the	O
tree	O
reports	O
whether	O
the	O
entire	O
problem	O
is	O
satisfied	O
due	O
to	O
the	O
uniform	B
distribution	I
over	O
the	O
literals	O
the	O
marginal	O
distribution	O
over	O
the	O
root	O
of	O
the	O
reduction	O
tree	O
specifies	O
what	O
fraction	O
of	O
assignments	O
satisfy	O
the	O
problem	O
while	O
this	O
is	O
a	O
contrived	O
worst-case	O
example	B
np	O
hard	O
graphs	O
commonly	O
arise	O
in	O
practical	O
real-world	O
scenarios	O
this	O
motivates	O
the	O
use	O
of	O
approximate	B
inference	I
in	O
the	O
context	O
of	O
deep	O
learning	O
this	O
usually	O
refers	O
to	O
variational	O
inference	O
in	O
which	O
we	O
approximate	O
the	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
v	O
by	O
seeking	O
an	O
approximate	O
distribution	O
q	O
v	O
true	O
distribution	O
ph	O
that	O
is	O
as	O
close	O
to	O
the	O
true	O
one	O
as	O
possible	O
this	O
and	O
other	O
techniques	O
are	O
described	O
in	O
depth	O
in	O
chapter	O
the	O
deep	O
learning	O
approach	O
to	O
structured	O
prob	O
abilistic	O
models	O
deep	O
learning	O
practitioners	O
generally	O
use	O
the	O
same	O
basic	O
computational	O
tools	O
as	O
other	O
machine	B
learning	I
practitioners	O
who	O
work	O
with	O
structured	O
probabilistic	O
models	O
however	O
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
usually	O
make	O
different	O
design	O
decisions	O
about	O
how	O
to	O
combine	O
these	O
tools	O
resulting	O
in	O
overall	O
algorithms	O
and	O
models	O
that	O
have	O
a	O
very	O
different	O
flavor	O
from	O
more	O
traditional	O
graphical	O
models	O
deep	O
learning	O
does	O
not	O
always	O
involve	O
especially	O
deep	O
graphical	O
models	O
in	O
the	O
context	O
of	O
graphical	O
models	O
we	O
can	O
define	O
the	O
depth	O
of	O
a	O
model	O
in	O
terms	O
of	O
the	O
graphical	O
model	O
graph	O
rather	O
than	O
the	O
computational	B
graph	I
we	O
can	O
think	O
of	O
a	O
latent	B
variable	I
hi	O
as	O
being	O
at	O
depth	O
j	O
if	O
the	O
shortest	O
path	O
from	O
h	O
i	O
to	O
an	O
observed	O
variable	O
is	O
j	O
steps	O
we	O
usually	O
describe	O
the	O
depth	O
of	O
the	O
model	O
as	O
being	O
the	O
greatest	O
depth	O
of	O
any	O
such	O
hi	O
this	O
kind	O
of	O
depth	O
is	O
different	O
from	O
the	O
depth	O
induced	O
by	O
the	O
computational	B
graph	I
many	O
generative	O
models	O
used	O
for	O
deep	O
learning	O
have	O
no	O
latent	O
variables	O
or	O
only	O
one	O
layer	O
of	O
latent	O
variables	O
but	O
use	O
deep	O
computational	O
graphs	O
to	O
define	O
the	O
conditional	O
distributions	O
within	O
a	O
model	O
deep	O
learning	O
essentially	O
always	O
makes	O
use	O
of	O
the	O
idea	O
of	O
distributed	O
representations	O
even	O
shallow	O
models	O
used	O
for	O
deep	O
learning	O
purposes	O
as	O
pretraining	O
shallow	O
models	O
that	O
will	O
later	O
be	O
composed	O
to	O
form	O
deep	O
ones	O
nearly	O
always	O
have	O
a	O
single	O
large	O
layer	O
of	O
latent	O
variables	O
deep	O
learning	O
models	O
typically	O
have	O
more	O
latent	O
variables	O
than	O
observed	O
variables	O
complicated	O
nonlinear	O
interactions	O
between	O
variables	O
are	O
accomplished	O
via	O
indirect	O
connections	O
that	O
flow	O
through	O
multiple	O
latent	O
variables	O
by	O
contrast	B
traditional	O
graphical	O
models	O
usually	O
contain	O
mostly	O
variables	O
that	O
are	O
at	O
least	O
occasionally	O
observed	O
even	O
if	O
many	O
of	O
the	O
variables	O
are	O
missing	O
at	O
random	O
from	O
some	O
training	O
examples	O
traditional	O
models	O
mostly	O
use	O
higher-order	O
terms	O
and	O
structure	B
learning	I
to	O
capture	O
complicated	O
nonlinear	O
interactions	O
between	O
variables	O
if	O
there	O
are	O
latent	O
variables	O
they	O
are	O
usually	O
few	O
in	O
number	O
the	O
way	O
that	O
latent	O
variables	O
are	O
designed	O
also	O
differs	O
in	O
deep	O
learning	O
the	O
deep	O
learning	O
practitioner	O
typically	O
does	O
not	O
intend	O
for	O
the	O
latent	O
variables	O
to	O
take	O
on	O
any	O
specific	O
semantics	O
ahead	O
of	O
time	O
the	O
training	O
algorithm	O
is	O
free	O
to	O
invent	O
the	O
concepts	O
it	O
needs	O
to	O
model	O
a	O
particular	O
dataset	B
the	O
latent	O
variables	O
are	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
usually	O
not	O
very	O
easy	O
for	O
a	O
human	O
to	O
interpret	O
after	O
the	O
fact	O
though	O
visualization	O
techniques	O
may	O
allow	O
some	O
rough	O
characterization	O
of	O
what	O
they	O
represent	O
when	O
latent	O
variables	O
are	O
used	O
in	O
the	O
context	O
of	O
traditional	O
graphical	O
models	O
they	O
are	O
often	O
designed	O
with	O
some	O
specific	O
semantics	O
in	O
mind	O
the	O
topic	O
of	O
a	O
document	O
the	O
intelligence	O
of	O
a	O
student	O
the	O
disease	O
causing	O
a	O
patient	O
s	O
symptoms	O
etc	O
these	O
models	O
are	O
often	O
much	O
more	O
interpretable	O
by	O
human	O
practitioners	O
and	O
often	O
have	O
more	O
theoretical	O
guarantees	O
yet	O
are	O
less	O
able	O
to	O
scale	O
to	O
complex	O
problems	O
and	O
are	O
not	O
reusable	O
in	O
as	O
many	O
different	O
contexts	O
as	O
deep	O
models	O
another	O
obvious	O
difference	O
is	O
the	O
kind	O
of	O
connectivity	O
typically	O
used	O
in	O
the	O
deep	O
learning	O
approach	O
deep	O
graphical	O
models	O
typically	O
have	O
large	O
groups	O
of	O
units	O
that	O
are	O
all	O
connected	O
to	O
other	O
groups	O
of	O
units	O
so	O
that	O
the	O
interactions	O
between	O
two	O
groups	O
may	O
be	O
described	O
by	O
a	O
single	O
matrix	O
traditional	O
graphical	O
models	O
have	O
very	O
few	O
connections	O
and	O
the	O
choice	O
of	O
connections	O
for	O
each	O
variable	O
may	O
be	O
individually	O
designed	O
the	O
design	O
of	O
the	O
model	O
structure	O
is	O
tightly	O
linked	O
with	O
the	O
choice	O
of	O
inference	O
algorithm	O
traditional	O
approaches	O
to	O
graphical	O
models	O
typically	O
aim	O
to	O
maintain	O
the	O
tractability	O
of	O
exact	O
inference	O
when	O
this	O
constraint	O
is	O
too	O
limiting	O
a	O
popular	O
approximate	B
inference	I
algorithm	O
is	O
an	O
algorithm	O
called	O
loopy	B
belief	I
propagation	I
both	O
of	O
these	O
approaches	O
often	O
work	O
well	O
with	O
very	O
sparsely	O
connected	O
graphs	O
by	O
comparison	O
models	O
used	O
in	O
deep	O
learning	O
tend	O
to	O
connect	O
each	O
visible	O
unit	O
vi	O
to	O
very	O
many	O
hidden	O
units	O
hj	O
so	O
that	O
h	O
can	O
provide	O
a	O
distributed	O
representation	O
of	O
vi	O
probably	O
several	O
other	O
observed	O
variables	O
too	O
distributed	O
representations	O
have	O
many	O
advantages	O
but	O
from	O
the	O
point	O
of	O
view	O
of	O
graphical	O
models	O
and	O
computational	O
complexity	O
distributed	O
representations	O
have	O
the	O
disadvantage	O
of	O
usually	O
yielding	O
graphs	O
that	O
are	O
not	O
sparse	O
enough	O
for	O
the	O
traditional	O
techniques	O
of	O
exact	O
inference	O
and	O
loopy	B
belief	I
propagation	I
to	O
be	O
relevant	O
as	O
a	O
consequence	O
one	O
of	O
the	O
most	O
striking	O
differences	O
between	O
the	O
larger	O
graphical	O
models	O
community	O
and	O
the	O
deep	O
graphical	O
models	O
community	O
is	O
that	O
loopy	B
belief	I
propagation	I
is	O
almost	O
never	O
used	O
for	O
deep	O
learning	O
most	O
deep	O
models	O
are	O
instead	O
designed	O
to	O
make	O
gibbs	O
sampling	O
or	O
variational	O
inference	O
algorithms	O
efficient	O
another	O
consideration	O
is	O
that	O
deep	O
learning	O
models	O
contain	O
a	O
very	O
large	O
number	O
of	O
latent	O
variables	O
making	O
efficient	O
numerical	O
code	O
essential	O
this	O
provides	O
an	O
additional	O
motivation	O
besides	O
the	O
choice	O
of	O
high-level	O
inference	O
algorithm	O
for	O
grouping	O
the	O
units	O
into	O
layers	O
with	O
a	O
matrix	O
describing	O
the	O
interaction	O
between	O
two	O
layers	O
this	O
allows	O
the	O
individual	O
steps	O
of	O
the	O
algorithm	O
to	O
be	O
implemented	O
with	O
efficient	O
matrix	B
product	I
operations	O
or	O
sparsely	O
connected	O
generalizations	O
like	O
block	O
diagonal	B
matrix	I
products	O
or	O
convolutions	O
finally	O
the	O
deep	O
learning	O
approach	O
to	O
graphical	O
modeling	O
is	O
characterized	O
by	O
a	O
marked	O
tolerance	O
of	O
the	O
unknown	O
rather	O
than	O
simplifying	O
the	O
model	O
until	O
all	O
quantities	O
we	O
might	O
want	O
can	O
be	O
computed	O
exactly	O
we	O
increase	O
the	O
power	O
of	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
the	O
model	O
until	O
it	O
is	O
just	O
barely	O
possible	O
to	O
train	O
or	O
use	O
we	O
often	O
use	O
models	O
whose	O
marginal	O
distributions	O
cannot	O
be	O
computed	O
and	O
are	O
satisfied	O
simply	O
to	O
draw	O
approximate	O
samples	O
from	O
these	O
models	O
we	O
often	O
train	O
models	O
with	O
an	O
intractable	O
objective	B
function	I
that	O
we	O
cannot	O
even	O
approximate	O
in	O
a	O
reasonable	O
amount	O
of	O
time	O
but	O
we	O
are	O
still	O
able	O
to	O
approximately	O
train	O
the	O
model	O
if	O
we	O
can	O
efficiently	O
obtain	O
an	O
estimate	O
of	O
the	O
gradient	B
of	O
such	O
a	O
function	O
the	O
deep	O
learning	O
approach	O
is	O
often	O
to	O
figure	O
out	O
what	O
the	O
minimum	O
amount	O
of	O
information	O
we	O
absolutely	O
need	O
is	O
and	O
then	O
to	O
figure	O
out	O
how	O
to	O
get	O
a	O
reasonable	O
approximation	O
of	O
that	O
information	O
as	O
quickly	O
as	O
possible	O
example	B
the	O
restricted	O
boltzmann	O
machine	O
or	O
smolensky	O
the	O
restricted	O
boltzmann	O
machine	O
harmonium	O
is	O
the	O
quintessential	O
example	B
of	O
how	O
graphical	O
models	O
are	O
used	O
for	O
deep	O
learning	O
the	O
rbm	O
is	O
not	O
itself	O
a	O
deep	O
model	O
instead	O
it	O
has	O
a	O
single	O
layer	O
of	O
latent	O
variables	O
that	O
may	O
be	O
used	O
to	O
learn	O
a	O
representation	O
for	O
the	O
input	O
in	O
chapter	O
we	O
will	O
see	O
how	O
rbms	O
can	O
be	O
used	O
to	O
build	O
many	O
deeper	O
models	O
here	O
we	O
show	O
how	O
the	O
rbm	O
exemplifies	O
many	O
of	O
the	O
practices	O
used	O
in	O
a	O
wide	O
variety	O
of	O
deep	O
graphical	O
models	O
its	O
units	O
are	O
organized	O
into	O
large	O
groups	O
called	O
layers	O
the	O
connectivity	O
between	O
layers	O
is	O
described	O
by	O
a	O
matrix	O
the	O
connectivity	O
is	O
relatively	O
dense	O
the	O
model	O
is	O
designed	O
to	O
allow	O
efficient	O
gibbs	O
sampling	O
and	O
the	O
emphasis	O
of	O
the	O
model	O
design	O
is	O
on	O
freeing	O
the	O
training	O
algorithm	O
to	O
learn	O
latent	O
variables	O
whose	O
semantics	O
were	O
not	O
specified	O
by	O
the	O
designer	O
later	O
in	O
section	O
we	O
will	O
revisit	O
the	O
rbm	O
in	O
more	O
detail	O
the	O
canonical	O
rbm	O
is	O
an	O
energy-based	O
model	O
with	O
binary	O
visible	O
and	O
hidden	O
units	O
its	O
energy	B
function	I
is	O
e	O
h	O
b	O
c	O
h	O
v	O
v	O
w	O
h	O
where	O
b	O
c	O
and	O
w	O
are	O
unconstrained	O
real-valued	O
learnable	O
parameters	O
we	O
can	O
see	O
that	O
the	O
model	O
is	O
divided	O
into	O
two	O
groups	O
of	O
units	O
v	O
and	O
h	O
and	O
the	O
interaction	O
between	O
them	O
is	O
described	O
by	O
a	O
matrix	O
w	O
the	O
model	O
is	O
depicted	O
graphically	O
in	O
figure	O
as	O
this	O
figure	O
makes	O
clear	O
an	O
important	O
aspect	O
of	O
this	O
model	O
is	O
that	O
there	O
are	O
no	O
direct	O
interactions	O
between	O
any	O
two	O
visible	O
units	O
or	O
between	O
any	O
two	O
hidden	O
units	O
the	O
restricted	O
a	O
general	O
boltzmann	O
machine	O
may	O
have	O
arbitrary	O
connections	O
the	O
restrictions	O
on	O
the	O
rbm	O
structure	O
yield	O
the	O
nice	O
properties	O
p	O
h	O
v	O
iphi	O
v	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
figure	O
an	O
rbm	O
drawn	O
as	O
a	O
markov	O
network	O
and	O
p	O
v	O
h	O
ipv	O
i	O
h	O
the	O
individual	O
conditionals	O
are	O
simple	O
to	O
compute	O
as	O
well	O
for	O
the	O
binary	O
rbm	O
we	O
obtain	O
p	O
p	O
v	O
v	O
v	O
v	O
wi	O
bi	O
wi	O
bi	O
together	O
these	O
properties	O
allow	O
for	O
efficient	O
block	B
gibbs	I
sampling	I
which	O
alternates	O
between	O
sampling	O
all	O
of	O
h	O
simultaneously	O
and	O
sampling	O
all	O
of	O
v	O
simultaneously	O
samples	O
generated	O
by	O
gibbs	O
sampling	O
from	O
an	O
rbm	O
model	O
are	O
shown	O
in	O
figure	O
since	O
the	O
energy	B
function	I
itself	O
is	O
just	O
a	O
linear	O
function	O
of	O
the	O
parameters	O
it	O
is	O
easy	O
to	O
take	O
its	O
derivatives	O
for	O
example	B
vihj	O
e	O
h	O
wij	O
these	O
two	O
properties	O
efficient	O
gibbs	O
sampling	O
and	O
efficient	O
derivatives	O
make	O
we	O
will	O
see	O
that	O
undirected	O
models	O
may	O
be	O
training	O
convenient	O
in	O
chapter	O
trained	O
by	O
computing	O
such	O
derivatives	O
applied	O
to	O
samples	O
from	O
the	O
model	O
v	O
h	O
as	O
a	O
set	O
of	O
features	O
to	O
describe	O
training	O
the	O
model	O
induces	O
a	O
representation	O
h	O
of	O
the	O
data	O
v	O
we	O
can	O
often	O
use	O
eh	O
p	O
overall	O
the	O
rbm	O
demonstrates	O
the	O
typical	O
deep	O
learning	O
approach	O
to	O
graphical	O
models	O
representation	B
learning	I
accomplished	O
via	O
layers	O
of	O
latent	O
variables	O
combined	O
with	O
efficient	O
interactions	O
between	O
layers	O
parametrized	O
by	O
matrices	O
the	O
language	O
of	O
graphical	O
models	O
provides	O
an	O
elegant	O
flexible	O
and	O
clear	O
language	O
for	O
describing	O
probabilistic	O
models	O
in	O
the	O
chapters	O
ahead	O
we	O
use	O
this	O
language	O
among	O
other	O
perspectives	O
to	O
describe	O
a	O
wide	O
variety	O
of	O
deep	O
probabilistic	O
models	O
chapter	O
structured	O
probabilistic	O
models	O
for	O
deep	O
learning	O
lisa	O
figure	O
samples	O
from	O
a	O
trained	O
rbm	O
and	O
its	O
weights	B
image	O
reproduced	O
with	O
permission	O
from	O
from	O
a	O
model	O
trained	O
on	O
mnist	O
drawn	O
using	O
gibbs	O
sampling	O
each	O
column	O
is	O
a	O
separate	O
gibbs	O
sampling	O
process	O
each	O
row	O
represents	O
the	O
output	O
of	O
another	O
steps	O
of	O
gibbs	O
sampling	O
successive	O
samples	O
are	O
highly	O
correlated	O
with	O
one	O
another	O
the	O
corresponding	O
weight	O
vectors	O
compare	O
this	O
to	O
the	O
samples	O
and	O
weights	B
of	O
a	O
linear	O
factor	O
model	O
shown	O
in	O
figure	O
the	O
samples	O
here	O
are	O
much	O
better	O
because	O
the	O
rbm	O
prior	O
ph	O
is	O
not	O
constrained	O
to	O
be	O
factorial	O
the	O
rbm	O
can	O
learn	O
which	O
features	O
should	O
appear	O
together	O
when	O
sampling	O
on	O
the	O
other	O
hand	O
the	O
rbm	O
posterior	O
is	O
not	O
so	O
the	O
sparse	O
coding	O
model	O
may	O
be	O
better	O
for	O
feature	B
extraction	O
other	O
models	O
are	O
able	O
to	O
have	O
both	O
a	O
non-factorial	O
is	O
factorial	O
while	O
the	O
sparse	O
coding	O
posterior	O
and	O
a	O
non-factorial	O
h	O
v	O
h	O
v	O
h	O
v	O
p	O
p	O
p	O
p	O
chapter	O
monte	O
carlo	O
methods	O
randomized	O
algorithms	O
fall	O
into	O
two	O
rough	O
categories	O
las	O
vegas	O
algorithms	O
and	O
monte	O
carlo	O
algorithms	O
las	O
vegas	O
algorithms	O
always	O
return	O
precisely	O
the	O
correct	O
answer	O
report	O
that	O
they	O
failed	O
these	O
algorithms	O
consume	O
a	O
random	O
amount	O
of	O
resources	O
usually	O
memory	O
or	O
time	O
in	O
contrast	B
monte	O
carlo	O
algorithms	O
return	O
answers	O
with	O
a	O
random	O
amount	O
of	O
error	O
the	O
amount	O
of	O
error	O
can	O
typically	O
be	O
reduced	O
by	O
expending	O
more	O
resources	O
running	O
time	O
and	O
memory	O
for	O
any	O
fixed	O
computational	O
budget	O
a	O
monte	O
carlo	O
algorithm	O
can	O
provide	O
an	O
approximate	O
answer	O
many	O
problems	O
in	O
machine	B
learning	I
are	O
so	O
difficult	O
that	O
we	O
can	O
never	O
expect	O
to	O
obtain	O
precise	O
answers	O
to	O
them	O
this	O
excludes	O
precise	O
deterministic	O
algorithms	O
and	O
las	O
vegas	O
algorithms	O
instead	O
we	O
must	O
use	O
deterministic	O
approximate	O
algorithms	O
or	O
monte	O
carlo	O
approximations	O
both	O
approaches	O
are	O
ubiquitous	O
in	O
machine	B
learning	I
in	O
this	O
chapter	O
we	O
focus	O
on	O
monte	O
carlo	O
methods	O
sampling	O
and	O
monte	O
carlo	O
methods	O
many	O
important	O
technologies	O
used	O
to	O
accomplish	O
machine	B
learning	I
goals	O
are	O
based	O
on	O
drawing	O
samples	O
from	O
some	O
probability	B
distribution	I
and	O
using	O
these	O
samples	O
to	O
form	O
a	O
monte	O
carlo	O
estimate	O
of	O
some	O
desired	O
quantity	O
why	O
sampling	O
there	O
are	O
many	O
reasons	O
that	O
we	O
may	O
wish	O
to	O
draw	O
samples	O
from	O
a	O
probability	B
distribution	I
sampling	O
provides	O
a	O
flexible	O
way	O
to	O
approximate	O
many	O
sums	O
and	O
chapter	O
monte	O
carlo	O
methods	O
integrals	O
at	O
reduced	O
cost	O
sometimes	O
we	O
use	O
this	O
to	O
provide	O
a	O
significant	O
speedup	O
to	O
a	O
costly	O
but	O
tractable	O
sum	O
as	O
in	O
the	O
case	O
when	O
we	O
subsample	O
the	O
full	O
training	O
cost	O
with	O
minibatches	O
in	O
other	O
cases	O
our	O
learning	O
algorithm	O
requires	O
us	O
to	O
approximate	O
an	O
intractable	O
sum	O
or	O
integral	O
such	O
as	O
the	O
gradient	B
of	O
the	O
log	O
partition	O
function	O
of	O
an	O
undirected	B
model	I
in	O
many	O
other	O
cases	O
sampling	O
is	O
actually	O
our	O
goal	O
in	O
the	O
sense	O
that	O
we	O
want	O
to	O
train	O
a	O
model	O
that	O
can	O
sample	O
from	O
the	O
training	O
distribution	O
basics	O
of	O
monte	O
carlo	O
sampling	O
when	O
a	O
sum	O
or	O
an	O
integral	O
cannot	O
be	O
computed	O
exactly	O
example	B
the	O
sum	O
has	O
an	O
exponential	O
number	O
of	O
terms	O
and	O
no	O
exact	O
simplification	O
is	O
known	O
it	O
is	O
often	O
possible	O
to	O
approximate	O
it	O
using	O
monte	O
carlo	O
sampling	O
the	O
idea	O
is	O
to	O
view	O
the	O
sum	O
or	O
integral	O
as	O
if	O
it	O
was	O
an	O
expectation	B
under	O
some	O
distribution	O
and	O
to	O
approximate	O
the	O
expectation	B
by	O
a	O
corresponding	O
average	O
let	O
s	O
p	O
x	O
f	O
e	O
p	O
f	O
x	O
or	O
s	O
p	O
x	O
d	O
f	O
e	O
p	O
f	O
x	O
x	O
be	O
the	O
sum	O
or	O
integral	O
to	O
estimate	O
rewritten	O
as	O
an	O
expectation	B
with	O
the	O
constraint	O
that	O
p	O
is	O
a	O
probability	B
distribution	I
the	O
sum	O
or	O
a	O
probability	O
density	O
the	O
integral	O
over	O
random	B
variable	I
we	O
can	O
approximate	O
s	O
by	O
drawing	O
n	O
samples	O
x	O
from	O
p	O
and	O
then	O
forming	O
the	O
empirical	O
average	O
n	O
n	O
f	O
sn	O
this	O
approximation	O
is	O
justified	O
by	O
a	O
few	O
different	O
properties	O
the	O
first	O
trivial	O
observation	O
is	O
that	O
the	O
estimator	O
s	O
is	O
unbiased	B
since	O
e	O
sn	O
n	O
n	O
e	O
x	O
n	O
n	O
s	O
s	O
but	O
in	O
addition	O
the	O
law	O
of	O
large	O
numbers	O
states	O
that	O
if	O
the	O
samples	O
x	O
are	O
i	O
i	O
d	O
then	O
the	O
average	O
converges	O
almost	O
surely	O
to	O
the	O
expected	O
value	O
sn	O
s	O
lim	O
n	O
chapter	O
monte	O
carlo	O
methods	O
provided	O
that	O
the	O
variance	O
of	O
the	O
individual	O
terms	O
varf	O
is	O
bounded	O
to	O
see	O
this	O
more	O
clearly	O
consider	O
the	O
variance	O
of	O
sn	O
as	O
n	O
increases	O
the	O
variance	O
var	O
sn	O
decreases	O
and	O
converges	O
to	O
so	O
long	O
as	O
var	O
x	O
var	O
sn	O
n	O
var	O
f	O
x	O
var	O
f	O
x	O
n	O
this	O
convenient	O
result	O
also	O
tells	O
us	O
how	O
to	O
estimate	O
the	O
uncertainty	O
in	O
a	O
monte	O
carlo	O
average	O
or	O
equivalently	O
the	O
amount	O
of	O
expected	O
error	O
of	O
the	O
monte	O
carlo	O
approximation	O
we	O
compute	O
both	O
the	O
empirical	O
average	O
of	O
the	O
f	O
and	O
their	O
empirical	O
and	O
then	O
divide	O
the	O
estimated	O
variance	O
by	O
the	O
number	O
of	O
samples	O
n	O
to	O
obtain	O
an	O
estimator	O
of	O
var	O
s	O
n	O
the	O
central	B
limit	I
theorem	I
tells	O
us	O
that	O
the	O
distribution	O
of	O
the	O
average	O
sn	O
converges	O
to	O
a	O
normal	O
distribution	O
with	O
mean	O
s	O
and	O
variance	O
var	O
f	O
x	O
this	O
allows	O
us	O
to	O
estimate	O
confidence	O
intervals	O
n	O
around	O
the	O
estimate	O
sn	O
using	O
the	O
cumulative	O
distribution	O
of	O
the	O
normal	O
density	O
however	O
all	O
this	O
relies	O
on	O
our	O
ability	O
to	O
easily	O
sample	O
from	O
the	O
base	O
distribution	O
px	O
but	O
doing	O
so	O
is	O
not	O
always	O
possible	O
when	O
it	O
is	O
not	O
feasible	O
to	O
sample	O
from	O
p	O
an	O
alternative	O
is	O
to	O
use	O
importance	O
sampling	O
presented	O
in	O
section	O
a	O
more	O
general	O
approach	O
is	O
to	O
form	O
a	O
sequence	O
of	O
estimators	O
that	O
converge	O
towards	O
the	O
distribution	O
of	O
interest	O
that	O
is	O
the	O
approach	O
of	O
monte	O
carlo	O
markov	O
chains	O
importance	O
sampling	O
an	O
important	O
step	O
in	O
the	O
decomposition	O
of	O
the	O
integrand	O
summand	O
used	O
by	O
the	O
monte	O
carlo	O
method	O
in	O
equation	O
is	O
deciding	O
which	O
part	O
of	O
the	O
integrand	O
should	O
play	O
the	O
role	O
the	O
probability	O
px	O
and	O
which	O
part	O
of	O
the	O
integrand	O
should	O
play	O
the	O
role	O
of	O
the	O
quantity	O
fx	O
whose	O
expected	O
value	O
that	O
probability	B
distribution	I
is	O
to	O
be	O
estimated	O
there	O
is	O
no	O
unique	O
decomposition	O
because	O
pxfx	O
can	O
always	O
be	O
rewritten	O
as	O
p	O
q	O
x	O
f	O
p	O
f	O
q	O
where	O
we	O
now	O
sample	O
from	O
q	O
and	O
average	O
pf	O
in	O
many	O
cases	O
we	O
wish	O
to	O
compute	O
q	O
an	O
expectation	B
for	O
a	O
given	O
p	O
and	O
an	O
f	O
and	O
the	O
fact	O
that	O
the	O
problem	O
is	O
specified	O
unbiased	B
estimator	O
of	O
the	O
variance	O
is	O
often	O
preferred	O
in	O
which	O
the	O
sum	O
of	O
squared	O
differences	O
is	O
divided	O
by	O
n	O
instead	O
of	O
n	O
chapter	O
monte	O
carlo	O
methods	O
from	O
the	O
start	O
as	O
an	O
expectation	B
suggests	O
that	O
this	O
p	O
and	O
f	O
would	O
be	O
a	O
natural	O
choice	O
of	O
decomposition	O
however	O
the	O
original	O
specification	O
of	O
the	O
problem	O
may	O
not	O
be	O
the	O
the	O
optimal	O
choice	O
in	O
terms	O
of	O
the	O
number	O
of	O
samples	O
required	O
to	O
obtain	O
a	O
given	O
level	O
of	O
accuracy	B
fortunately	O
the	O
form	O
of	O
the	O
optimal	O
choice	O
q	O
can	O
be	O
derived	O
easily	O
the	O
optimal	O
q	O
corresponds	O
to	O
what	O
is	O
called	O
optimal	O
importance	O
sampling	O
because	O
of	O
the	O
identity	O
shown	O
in	O
equation	O
any	O
monte	O
carlo	O
estimator	O
n	O
n	O
sp	O
f	O
p	O
i	O
x	O
can	O
be	O
transformed	O
into	O
an	O
importance	O
sampling	O
estimator	O
sq	O
n	O
n	O
px	O
x	O
q	O
i	O
x	O
qx	O
we	O
see	O
readily	O
that	O
the	O
expected	O
value	O
of	O
the	O
estimator	O
does	O
not	O
depend	O
on	O
eq	O
sq	O
eq	O
sp	O
s	O
however	O
the	O
variance	O
of	O
an	O
importance	O
sampling	O
estimator	O
can	O
be	O
greatly	O
sensitive	O
to	O
the	O
choice	O
of	O
the	O
variance	O
is	O
given	O
by	O
q	O
var	O
sq	O
var	O
p	O
f	O
q	O
the	O
minimum	O
variance	O
occurs	O
when	O
isq	O
q	O
p	O
f	O
z	O
where	O
z	O
is	O
the	O
normalization	O
constant	O
chosen	O
so	O
that	O
q	O
sums	O
or	O
integrates	O
to	O
as	O
appropriate	O
better	O
importance	O
sampling	O
distributions	O
put	O
more	O
weight	O
where	O
the	O
integrand	O
is	O
larger	O
in	O
fact	O
when	O
fx	O
does	O
not	O
change	O
sign	O
var	O
sq	O
when	O
the	O
optimal	O
distribution	O
is	O
used	O
meaning	O
that	O
of	O
course	O
this	O
is	O
only	O
because	O
the	O
computation	O
of	O
q	O
has	O
essentially	O
solved	O
the	O
original	O
problem	O
so	O
it	O
is	O
usually	O
not	O
practical	O
to	O
use	O
this	O
approach	O
of	O
drawing	O
a	O
single	O
sample	O
from	O
the	O
optimal	O
distribution	O
a	O
single	O
sample	O
is	O
sufficient	O
any	O
choice	O
of	O
sampling	O
distribution	O
q	O
is	O
valid	O
the	O
sense	O
of	O
yielding	O
the	O
is	O
the	O
optimal	O
one	O
the	O
sense	O
of	O
yielding	O
minimum	O
is	O
usually	O
infeasible	O
but	O
other	O
choices	O
of	O
q	O
can	O
be	O
correct	O
expected	O
value	O
and	O
q	O
variance	O
sampling	O
from	O
q	O
feasible	O
while	O
still	O
reducing	O
the	O
variance	O
somewhat	O
chapter	O
monte	O
carlo	O
methods	O
another	O
approach	O
is	O
to	O
use	O
biased	B
importance	I
sampling	I
which	O
has	O
the	O
advantage	O
of	O
not	O
requiring	O
normalized	O
p	O
or	O
q	O
in	O
the	O
case	O
of	O
discrete	O
variables	O
the	O
biased	B
importance	I
sampling	I
estimator	O
is	O
given	O
by	O
n	O
n	O
n	O
sbis	O
f	O
px	O
qx	O
f	O
px	O
qx	O
n	O
px	O
qx	O
n	O
px	O
qx	O
n	O
px	O
qx	O
px	O
qx	O
f	O
where	O
p	O
and	O
q	O
are	O
the	O
unnormalized	O
forms	O
of	O
p	O
and	O
q	O
and	O
the	O
x	O
are	O
the	O
samples	O
s	O
except	O
asymptotically	O
when	O
from	O
q	O
this	O
estimator	O
is	O
biased	O
because	O
e	O
s	O
bis	O
converges	O
to	O
hence	O
this	O
estimator	O
n	O
is	O
called	O
asymptotically	B
unbiased	B
and	O
the	O
denominator	O
of	O
equation	O
q	O
for	O
which	O
p	O
f	O
q	O
we	O
see	O
that	O
if	O
there	O
are	O
samples	O
of	O
although	O
a	O
good	O
choice	O
of	O
q	O
can	O
greatly	O
improve	O
the	O
efficiency	O
of	O
monte	O
carlo	O
estimation	O
a	O
poor	O
choice	O
of	O
q	O
can	O
make	O
the	O
efficiency	O
much	O
worse	O
going	O
back	O
to	O
equation	O
is	O
large	O
then	O
the	O
variance	O
of	O
the	O
estimator	O
can	O
get	O
very	O
large	O
this	O
may	O
happen	O
when	O
qx	O
is	O
tiny	O
while	O
neither	O
px	O
nor	O
f	O
are	O
small	O
enough	O
to	O
cancel	O
it	O
the	O
q	O
distribution	O
is	O
usually	O
chosen	O
to	O
be	O
a	O
very	O
simple	O
distribution	O
so	O
that	O
it	O
is	O
easy	O
to	O
sample	O
from	O
when	O
x	O
is	O
high-dimensional	O
this	O
simplicity	O
in	O
q	O
causes	O
it	O
to	O
match	O
p	O
or	O
p	O
f	O
importance	O
sampling	O
collects	O
useless	O
samples	O
tiny	O
numbers	O
or	O
zeros	O
on	O
the	O
other	O
hand	O
when	O
which	O
will	O
happen	O
more	O
rarely	O
the	O
ratio	O
can	O
be	O
huge	O
qx	O
because	O
these	O
latter	O
events	O
are	O
rare	O
they	O
may	O
not	O
show	O
up	O
in	O
a	O
typical	O
sample	O
yielding	O
typical	O
underestimation	O
of	O
s	O
compensated	O
rarely	O
by	O
gross	O
overestimation	O
such	O
very	O
large	O
or	O
very	O
small	O
numbers	O
are	O
typical	O
when	O
x	O
is	O
high	O
dimensional	O
because	O
in	O
high	O
dimension	O
the	O
dynamic	O
range	O
of	O
joint	O
probabilities	O
can	O
be	O
very	O
large	O
poorly	O
when	O
qx	O
fx	O
f	O
px	O
px	O
in	O
spite	O
of	O
this	O
danger	O
importance	O
sampling	O
and	O
its	O
variants	O
have	O
been	O
found	O
very	O
useful	O
in	O
many	O
machine	B
learning	I
algorithms	O
including	O
deep	O
learning	O
algorithms	O
for	O
example	B
see	O
the	O
use	O
of	O
importance	O
sampling	O
to	O
accelerate	O
training	O
in	O
neural	O
language	O
models	O
with	O
a	O
large	O
vocabulary	O
or	O
other	O
neural	O
nets	O
with	O
a	O
large	O
number	O
of	O
outputs	O
see	O
also	O
how	O
importance	O
sampling	O
has	O
been	O
used	O
to	O
estimate	O
a	O
partition	O
function	O
normalization	O
constant	O
of	O
a	O
probability	O
chapter	O
monte	O
carlo	O
methods	O
and	O
to	O
estimate	O
the	O
log-likelihood	O
in	O
deep	O
directed	O
distribution	O
in	O
section	O
models	O
such	O
as	O
the	O
variational	O
autoencoder	O
in	O
section	O
importance	O
sampling	O
may	O
also	O
be	O
used	O
to	O
improve	O
the	O
estimate	O
of	O
the	O
gradient	B
of	O
the	O
cost	O
function	O
used	O
to	O
train	O
model	O
parameters	O
with	O
stochastic	O
gradient	B
descent	O
particularly	O
for	O
models	O
such	O
as	O
classifiers	O
where	O
most	O
of	O
the	O
total	O
value	O
of	O
the	O
cost	O
function	O
comes	O
from	O
a	O
small	O
number	O
of	O
misclassified	O
examples	O
sampling	O
more	O
difficult	O
examples	O
more	O
frequently	O
can	O
reduce	O
the	O
variance	O
of	O
the	O
gradient	B
in	O
such	O
cases	O
hinton	O
markov	B
chain	I
monte	I
carlo	I
methods	O
in	O
many	O
cases	O
we	O
wish	O
to	O
use	O
a	O
monte	O
carlo	O
technique	O
but	O
there	O
is	O
no	O
tractable	O
method	O
for	O
drawing	O
exact	O
samples	O
from	O
the	O
distribution	O
pmodelx	O
or	O
from	O
a	O
good	O
variance	O
importance	O
sampling	O
distribution	O
q	O
in	O
the	O
context	O
of	O
deep	O
learning	O
this	O
most	O
often	O
happens	O
when	O
pmodelx	O
is	O
represented	O
by	O
an	O
undirected	B
model	I
in	O
these	O
cases	O
we	O
introduce	O
a	O
mathematical	O
tool	O
called	O
a	O
markov	B
chain	I
to	O
approximately	O
sample	O
from	O
pmodel	O
the	O
family	O
of	O
algorithms	O
that	O
use	O
markov	O
chains	O
to	O
perform	O
monte	O
carlo	O
estimates	O
is	O
called	O
markov	B
chain	I
monte	I
carlo	I
methods	O
markov	B
chain	I
monte	I
carlo	I
methods	O
for	O
machine	B
learning	I
are	O
described	O
at	O
greater	O
length	O
in	O
koller	O
and	O
friedman	O
the	O
most	O
standard	O
generic	O
guarantees	O
for	O
mcmc	O
techniques	O
are	O
only	O
applicable	O
when	O
the	O
model	O
does	O
not	O
assign	O
zero	O
probability	O
to	O
any	O
state	O
therefore	O
it	O
is	O
most	O
convenient	O
to	O
present	O
these	O
techniques	O
as	O
sampling	O
from	O
an	O
energy-based	O
model	O
px	O
in	O
the	O
ebm	O
formulation	O
every	O
state	O
is	O
guaranteed	O
to	O
have	O
non-zero	O
probability	O
mcmc	O
methods	O
are	O
in	O
fact	O
more	O
broadly	O
applicable	O
and	O
can	O
be	O
used	O
with	O
many	O
probability	O
distributions	O
that	O
contain	O
zero	O
probability	O
states	O
however	O
the	O
theoretical	O
guarantees	O
concerning	O
the	O
behavior	O
of	O
mcmc	O
methods	O
must	O
be	O
proven	O
on	O
a	O
case-by-case	O
basis	O
for	O
different	O
families	O
of	O
such	O
distributions	O
in	O
the	O
context	O
of	O
deep	O
learning	O
it	O
is	O
most	O
common	O
to	O
rely	O
on	O
the	O
most	O
general	O
theoretical	O
guarantees	O
that	O
naturally	O
apply	O
to	O
all	O
energy-based	O
models	O
exp	O
e	O
as	O
described	O
in	O
section	O
to	O
understand	O
why	O
drawing	O
samples	O
from	O
an	O
energy-based	O
model	O
is	O
difficult	O
a	O
b	O
in	O
order	O
consider	O
an	O
ebm	O
over	O
just	O
two	O
variables	O
defining	O
a	O
distribution	O
to	O
sample	O
a	O
we	O
must	O
draw	O
a	O
from	O
pa	O
b	O
and	O
in	O
order	O
to	O
sample	O
b	O
we	O
must	O
draw	O
it	O
from	O
pb	O
it	O
seems	O
to	O
be	O
an	O
intractable	O
chicken-and-egg	O
problem	O
directed	O
models	O
avoid	O
this	O
because	O
their	O
graph	O
is	O
directed	O
and	O
acyclic	O
to	O
perform	O
ancestral	O
sampling	O
one	O
simply	O
samples	O
each	O
of	O
the	O
variables	O
in	O
topological	O
order	O
conditioning	O
on	O
each	O
variable	O
s	O
parents	O
which	O
are	O
guaranteed	O
to	O
have	O
already	O
been	O
sampled	O
ancestral	O
sampling	O
defines	O
an	O
efficient	O
single-pass	O
method	O
p	O
a	O
chapter	O
monte	O
carlo	O
methods	O
of	O
obtaining	O
a	O
sample	O
in	O
an	O
ebm	O
we	O
can	O
avoid	O
this	O
chicken	O
and	O
egg	O
problem	O
by	O
sampling	O
using	O
a	O
markov	B
chain	I
the	O
core	O
idea	O
of	O
a	O
markov	B
chain	I
is	O
to	O
have	O
a	O
state	O
x	O
that	O
begins	O
as	O
an	O
arbitrary	O
value	O
over	O
time	O
we	O
randomly	O
update	O
x	O
repeatedly	O
eventually	O
x	O
becomes	O
nearly	O
a	O
fair	O
sample	O
from	O
px	O
formally	O
a	O
markov	B
chain	I
is	O
defined	O
by	O
a	O
random	O
state	O
x	O
and	O
a	O
transition	O
distribution	O
tx	O
x	O
specifying	O
the	O
probability	O
that	O
a	O
random	O
update	O
will	O
go	O
to	O
state	O
x	O
if	O
it	O
starts	O
in	O
state	O
x	O
running	O
the	O
markov	B
chain	I
means	O
repeatedly	O
updating	O
the	O
state	O
x	O
to	O
a	O
value	O
x	O
sampled	O
from	O
t	O
x	O
to	O
gain	O
some	O
theoretical	O
understanding	O
of	O
how	O
mcmc	O
methods	O
work	O
it	O
is	O
useful	O
to	O
reparametrize	O
the	O
problem	O
first	O
we	O
restrict	O
our	O
attention	O
to	O
the	O
case	O
where	O
the	O
random	B
variable	I
x	O
has	O
countably	O
many	O
states	O
we	O
can	O
then	O
represent	O
the	O
state	O
as	O
just	O
a	O
positive	O
integer	O
x	O
different	O
integer	O
values	O
of	O
x	O
map	O
back	O
to	O
different	O
states	O
in	O
the	O
original	O
problem	O
x	O
consider	O
what	O
happens	O
when	O
we	O
run	O
infinitely	O
many	O
markov	O
chains	O
in	O
parallel	O
all	O
of	O
the	O
states	O
of	O
the	O
different	O
markov	O
chains	O
are	O
drawn	O
from	O
some	O
distribution	O
q	O
where	O
t	O
indicates	O
the	O
number	O
of	O
time	O
steps	O
that	O
have	O
elapsed	O
at	O
the	O
beginning	O
is	O
some	O
distribution	O
that	O
we	O
used	O
to	O
arbitrarily	O
initialize	O
x	O
for	O
each	O
markov	B
chain	I
later	O
q	O
is	O
influenced	O
by	O
all	O
of	O
the	O
markov	B
chain	I
steps	O
that	O
have	O
run	O
so	O
far	O
our	O
goal	O
is	O
for	O
q	O
to	O
converge	O
to	O
p	O
x	O
because	O
we	O
have	O
reparametrized	O
the	O
problem	O
in	O
terms	O
of	O
positive	O
integer	O
x	O
we	O
can	O
describe	O
the	O
probability	B
distribution	I
q	O
using	O
a	O
vector	O
v	O
with	O
q	O
x	O
i	O
i	O
v	O
new	O
state	O
x	O
consider	O
what	O
happens	O
when	O
we	O
update	O
a	O
single	O
markov	B
chain	I
s	O
state	O
x	O
to	O
a	O
the	O
probability	O
of	O
a	O
single	O
state	O
landing	O
in	O
state	O
x	O
is	O
given	O
by	O
t	O
q	O
x	O
q	O
t	O
x	O
x	O
using	O
our	O
integer	O
parametrization	O
we	O
can	O
represent	O
the	O
effect	O
of	O
the	O
transition	O
operator	O
t	O
using	O
a	O
matrix	O
a	O
we	O
define	O
aij	O
x	O
a	O
i	O
so	O
that	O
x	O
j	O
rather	O
than	O
writing	O
it	O
in	O
using	O
this	O
definition	O
we	O
can	O
now	O
rewrite	O
equation	O
terms	O
of	O
q	O
and	O
t	O
to	O
understand	O
how	O
a	O
single	O
state	O
is	O
updated	O
we	O
may	O
now	O
use	O
v	O
and	O
a	O
to	O
describe	O
how	O
the	O
entire	O
distribution	O
over	O
all	O
the	O
different	O
markov	O
chains	O
in	O
parallel	O
shifts	O
as	O
we	O
apply	O
an	O
update	O
t	O
v	O
av	O
chapter	O
monte	O
carlo	O
methods	O
applying	O
the	O
markov	B
chain	I
update	O
repeatedly	O
corresponds	O
to	O
multiplying	O
by	O
the	O
matrix	O
a	O
repeatedly	O
in	O
other	O
words	O
we	O
can	O
think	O
of	O
the	O
process	O
as	O
exponentiating	O
the	O
matrix	O
v	O
atv	O
the	O
matrix	O
a	O
has	O
special	O
structure	O
because	O
each	O
of	O
its	O
columns	O
represents	O
a	O
probability	B
distribution	I
such	O
matrices	O
are	O
called	O
stochastic	O
matrices	O
if	O
there	O
is	O
a	O
non-zero	O
probability	O
of	O
transitioning	O
from	O
any	O
state	O
x	O
to	O
any	O
other	O
state	O
x	O
for	O
some	O
power	O
t	O
then	O
the	O
perron-frobenius	O
theorem	O
perron	O
frobenius	O
guarantees	O
that	O
the	O
largest	O
eigenvalue	B
is	O
real	O
and	O
equal	O
to	O
over	O
time	O
we	O
can	O
see	O
that	O
all	O
of	O
the	O
eigenvalues	O
are	O
exponentiated	O
v	O
v	O
diag	O
v	O
t	O
v	O
diag	O
tv	O
this	O
process	O
causes	O
all	O
of	O
the	O
eigenvalues	O
that	O
are	O
not	O
equal	O
to	O
to	O
decay	O
to	O
zero	O
under	O
some	O
additional	O
mild	O
conditions	O
a	O
is	O
guaranteed	O
to	O
have	O
only	O
one	O
eigenvector	B
stationary	O
distribution	O
with	O
eigenvalue	B
sometimes	O
also	O
called	O
the	O
at	O
convergence	O
the	O
process	O
thus	O
converges	O
to	O
a	O
equilibrium	O
distribution	O
v	O
av	O
v	O
and	O
this	O
same	O
condition	O
holds	O
for	O
every	O
additional	O
step	O
this	O
is	O
an	O
eigenvector	B
equation	O
to	O
be	O
a	O
stationary	O
point	O
v	O
must	O
be	O
an	O
eigenvector	B
with	O
corresponding	O
eigenvalue	B
this	O
condition	O
guarantees	O
that	O
once	O
we	O
have	O
reached	O
the	O
stationary	O
distribution	O
repeated	O
applications	O
of	O
the	O
transition	O
sampling	O
procedure	O
do	O
not	O
change	O
the	O
over	O
the	O
states	O
of	O
all	O
the	O
various	O
markov	O
chains	O
transition	O
operator	O
does	O
change	O
each	O
individual	O
state	O
of	O
course	O
distribution	O
if	O
we	O
have	O
chosen	O
t	O
correctly	O
then	O
the	O
stationary	O
distribution	O
q	O
will	O
be	O
equal	O
to	O
the	O
distribution	O
p	O
we	O
wish	O
to	O
sample	O
from	O
we	O
will	O
describe	O
how	O
to	O
choose	O
t	O
shortly	O
in	O
section	O
most	O
properties	O
of	O
markov	O
chains	O
with	O
countable	O
states	O
can	O
be	O
generalized	O
to	O
continuous	O
variables	O
in	O
this	O
situation	O
some	O
authors	O
call	O
the	O
markov	B
chain	I
a	O
harris	O
chain	O
but	O
we	O
use	O
the	O
term	O
markov	B
chain	I
to	O
describe	O
both	O
conditions	O
in	O
general	O
a	O
markov	B
chain	I
with	O
transition	O
operator	O
t	O
will	O
converge	O
under	O
mild	O
conditions	O
to	O
a	O
fixed	O
point	O
described	O
by	O
the	O
equation	O
q	O
qt	O
ex	O
x	O
x	O
is	O
discrete	O
which	O
in	O
the	O
discrete	O
case	O
is	O
just	O
rewriting	O
equation	O
the	O
expectation	B
corresponds	O
to	O
a	O
sum	O
and	O
when	O
x	O
is	O
continuous	O
the	O
expectation	B
corresponds	O
to	O
an	O
integral	O
when	O
chapter	O
monte	O
carlo	O
methods	O
regardless	O
of	O
whether	O
the	O
state	O
is	O
continuous	O
or	O
discrete	O
all	O
markov	B
chain	I
methods	O
consist	O
of	O
repeatedly	O
applying	O
stochastic	O
updates	O
until	O
eventually	O
the	O
state	O
begins	O
to	O
yield	O
samples	O
from	O
the	O
equilibrium	O
distribution	O
running	O
the	O
markov	B
chain	I
until	O
it	O
reaches	O
its	O
equilibrium	O
distribution	O
is	O
called	O
burning	O
in	O
the	O
markov	B
chain	I
after	O
the	O
chain	O
has	O
reached	O
equilibrium	O
a	O
sequence	O
of	O
infinitely	O
many	O
samples	O
may	O
be	O
drawn	O
from	O
from	O
the	O
equilibrium	O
distribution	O
they	O
are	O
identically	O
distributed	O
but	O
any	O
two	O
successive	O
samples	O
will	O
be	O
highly	O
correlated	O
with	O
each	O
other	O
a	O
finite	O
sequence	O
of	O
samples	O
may	O
thus	O
not	O
be	O
very	O
representative	O
of	O
the	O
equilibrium	O
distribution	O
one	O
way	O
to	O
mitigate	O
this	O
problem	O
is	O
to	O
return	O
only	O
every	O
n	O
successive	O
samples	O
so	O
that	O
our	O
estimate	O
of	O
the	O
statistics	O
of	O
the	O
equilibrium	O
distribution	O
is	O
not	O
as	O
biased	O
by	O
the	O
correlation	B
between	O
an	O
mcmc	O
sample	O
and	O
the	O
next	O
several	O
samples	O
markov	O
chains	O
are	O
thus	O
expensive	O
to	O
use	O
because	O
of	O
the	O
time	O
required	O
to	O
burn	O
in	O
to	O
the	O
equilibrium	O
distribution	O
and	O
the	O
time	O
required	O
to	O
transition	O
from	O
one	O
sample	O
to	O
another	O
reasonably	O
decorrelated	O
sample	O
after	O
reaching	O
equilibrium	O
if	O
one	O
desires	O
truly	O
independent	O
samples	O
one	O
can	O
run	O
multiple	O
markov	O
chains	O
in	O
parallel	O
this	O
approach	O
uses	O
extra	O
parallel	O
computation	O
to	O
eliminate	O
latency	O
the	O
strategy	O
of	O
using	O
only	O
a	O
single	O
markov	B
chain	I
to	O
generate	O
all	O
samples	O
and	O
the	O
strategy	O
of	O
using	O
one	O
markov	B
chain	I
for	O
each	O
desired	O
sample	O
are	O
two	O
extremes	O
deep	O
learning	O
practitioners	O
usually	O
use	O
a	O
number	O
of	O
chains	O
that	O
is	O
similar	O
to	O
the	O
number	O
of	O
examples	O
in	O
a	O
minibatch	B
and	O
then	O
draw	O
as	O
many	O
samples	O
as	O
are	O
needed	O
from	O
this	O
fixed	O
set	O
of	O
markov	O
chains	O
a	O
commonly	O
used	O
number	O
of	O
markov	O
chains	O
is	O
another	O
difficulty	O
is	O
that	O
we	O
do	O
not	O
know	O
in	O
advance	O
how	O
many	O
steps	O
the	O
markov	B
chain	I
must	O
run	O
before	O
reaching	O
its	O
equilibrium	O
distribution	O
this	O
length	O
of	O
time	O
is	O
called	O
the	O
mixing	O
time	O
it	O
is	O
also	O
very	O
difficult	O
to	O
test	O
whether	O
a	O
markov	B
chain	I
has	O
reached	O
equilibrium	O
we	O
do	O
not	O
have	O
a	O
precise	O
enough	O
theory	O
for	O
guiding	O
us	O
in	O
answering	O
this	O
question	O
theory	O
tells	O
us	O
that	O
the	O
chain	O
will	O
converge	O
but	O
not	O
much	O
more	O
if	O
we	O
analyze	O
the	O
markov	B
chain	I
from	O
the	O
point	O
of	O
view	O
of	O
a	O
matrix	O
a	O
acting	O
on	O
a	O
vector	O
of	O
probabilities	O
v	O
then	O
we	O
know	O
that	O
the	O
chain	O
mixes	O
when	O
at	O
has	O
effectively	O
lost	O
all	O
of	O
the	O
eigenvalues	O
from	O
a	O
besides	O
the	O
unique	O
eigenvalue	B
of	O
this	O
means	O
that	O
the	O
magnitude	O
of	O
the	O
second	O
largest	O
eigenvalue	B
will	O
determine	O
the	O
mixing	O
time	O
however	O
in	O
practice	O
we	O
cannot	O
actually	O
represent	O
our	O
markov	B
chain	I
in	O
terms	O
of	O
a	O
matrix	O
the	O
number	O
of	O
states	O
that	O
our	O
probabilistic	O
model	O
can	O
visit	O
is	O
exponentially	O
large	O
in	O
the	O
number	O
of	O
variables	O
so	O
it	O
is	O
infeasible	O
to	O
represent	O
v	O
a	O
or	O
the	O
eigenvalues	O
of	O
a	O
due	O
to	O
these	O
and	O
other	O
obstacles	O
we	O
usually	O
do	O
not	O
know	O
whether	O
a	O
markov	B
chain	I
has	O
mixed	O
instead	O
we	O
simply	O
run	O
the	O
markov	B
chain	I
for	O
an	O
amount	O
of	O
time	O
that	O
we	O
roughly	O
estimate	O
to	O
be	O
sufficient	O
and	O
use	O
heuristic	O
methods	O
to	O
determine	O
whether	O
the	O
chain	O
has	O
mixed	O
these	O
heuristic	O
methods	O
include	O
manually	O
inspecting	O
samples	O
or	O
measuring	O
correlations	O
between	O
chapter	O
monte	O
carlo	O
methods	O
successive	O
samples	O
gibbs	O
sampling	O
x	O
t	O
so	O
far	O
we	O
have	O
described	O
how	O
to	O
draw	O
samples	O
from	O
a	O
distribution	O
qx	O
by	O
repeatedly	O
updating	O
x	O
x	O
however	O
we	O
have	O
not	O
described	O
how	O
to	O
ensure	O
that	O
qx	O
is	O
a	O
useful	O
distribution	O
two	O
basic	O
approaches	O
are	O
considered	O
in	O
this	O
book	O
the	O
first	O
one	O
is	O
to	O
derive	O
t	O
from	O
a	O
given	O
learned	O
pmodel	O
described	O
below	O
with	O
the	O
case	O
of	O
sampling	O
from	O
ebms	O
the	O
second	O
one	O
is	O
to	O
directly	O
parametrize	O
t	O
and	O
learn	O
it	O
so	O
that	O
its	O
stationary	O
distribution	O
implicitly	O
defines	O
the	O
pmodel	O
of	O
interest	O
examples	O
of	O
this	O
second	O
approach	O
are	O
discussed	O
in	O
sections	O
and	O
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
commonly	O
use	O
markov	O
chains	O
to	O
draw	O
samples	O
from	O
an	O
energy-based	O
model	O
defining	O
a	O
distribution	O
pmodelx	O
in	O
this	O
case	O
we	O
want	O
the	O
qx	O
for	O
the	O
markov	B
chain	I
to	O
be	O
pmodelx	O
to	O
obtain	O
the	O
desired	O
q	O
we	O
must	O
choose	O
an	O
appropriate	O
t	O
x	O
g	O
a	O
conceptually	O
simple	O
and	O
effective	O
approach	O
to	O
building	O
a	O
markov	B
chain	I
that	O
samples	O
from	O
pmodelx	O
is	O
to	O
use	O
gibbs	O
sampling	O
in	O
which	O
sampling	O
from	O
x	O
is	O
accomplished	O
by	O
selecting	O
one	O
variable	O
xi	O
and	O
sampling	O
it	O
from	O
pmodel	O
t	O
conditioned	O
on	O
its	O
neighbors	O
in	O
the	O
undirected	O
graph	O
defining	O
the	O
structure	O
of	O
the	O
energy-based	O
model	O
it	O
is	O
also	O
possible	O
to	O
sample	O
several	O
variables	O
at	O
the	O
same	O
time	O
so	O
long	O
as	O
they	O
are	O
conditionally	O
independent	O
given	O
all	O
of	O
their	O
neighbors	O
as	O
shown	O
in	O
the	O
rbm	O
example	B
in	O
section	O
all	O
of	O
the	O
hidden	O
units	O
of	O
an	O
rbm	O
may	O
be	O
sampled	O
simultaneously	O
because	O
they	O
are	O
conditionally	O
independent	O
from	O
each	O
other	O
given	O
all	O
of	O
the	O
visible	O
units	O
likewise	O
all	O
of	O
the	O
visible	O
units	O
may	O
be	O
sampled	O
simultaneously	O
because	O
they	O
are	O
conditionally	O
independent	O
from	O
each	O
other	O
given	O
all	O
of	O
the	O
hidden	O
units	O
gibbs	O
sampling	O
approaches	O
that	O
update	O
many	O
variables	O
simultaneously	O
in	O
this	O
way	O
are	O
called	O
block	B
gibbs	I
sampling	I
alternate	O
approaches	O
to	O
designing	O
markov	O
chains	O
to	O
sample	O
from	O
pmodel	O
are	O
possible	O
for	O
example	B
the	O
metropolis-hastings	O
algorithm	O
is	O
widely	O
used	O
in	O
other	O
disciplines	O
in	O
the	O
context	O
of	O
the	O
deep	O
learning	O
approach	O
to	O
undirected	O
modeling	O
it	O
is	O
rare	O
to	O
use	O
any	O
approach	O
other	O
than	O
gibbs	O
sampling	O
improved	O
sampling	O
techniques	O
are	O
one	O
possible	O
research	O
frontier	O
the	O
challenge	B
of	O
mixing	O
between	O
separated	O
modes	O
the	O
primary	O
difficulty	O
involved	O
with	O
mcmc	O
methods	O
is	O
that	O
they	O
have	O
a	O
tendency	O
to	O
mix	O
poorly	O
ideally	O
successive	O
samples	O
from	O
a	O
markov	B
chain	I
designed	O
to	O
sample	O
chapter	O
monte	O
carlo	O
methods	O
from	O
px	O
would	O
be	O
completely	O
independent	O
from	O
each	O
other	O
and	O
would	O
visit	O
many	O
different	O
regions	O
in	O
x	O
space	O
proportional	O
to	O
their	O
probability	O
instead	O
especially	O
in	O
high	O
dimensional	O
cases	O
mcmc	O
samples	O
become	O
very	O
correlated	O
we	O
refer	O
to	O
such	O
behavior	O
as	O
slow	O
mixing	O
or	O
even	O
failure	O
to	O
mix	O
mcmc	O
methods	O
with	O
slow	O
mixing	O
can	O
be	O
seen	O
as	O
inadvertently	O
performing	O
something	O
resembling	O
noisy	O
gradient	B
descent	O
on	O
the	O
energy	B
function	I
or	O
equivalently	O
noisy	O
hill	B
climbing	I
on	O
the	O
probability	O
with	O
respect	O
to	O
the	O
state	O
of	O
the	O
chain	O
random	O
variables	O
being	O
sampled	O
the	O
chain	O
tends	O
to	O
take	O
small	O
steps	O
the	O
space	O
of	O
the	O
state	O
of	O
the	O
markov	B
chain	I
from	O
a	O
configuration	O
x	O
t	O
to	O
a	O
configuration	O
x	O
with	O
the	O
energy	O
ex	O
generally	O
lower	O
or	O
approximately	O
equal	O
to	O
the	O
energy	O
ex	O
t	O
with	O
a	O
preference	O
for	O
moves	O
that	O
yield	O
lower	O
energy	O
configurations	O
when	O
starting	O
from	O
a	O
rather	O
improbable	O
configuration	O
energy	O
than	O
the	O
typical	O
ones	O
from	O
px	O
the	O
chain	O
tends	O
to	O
gradually	O
reduce	O
the	O
energy	O
of	O
the	O
state	O
and	O
only	O
occasionally	O
move	O
to	O
another	O
mode	O
once	O
the	O
chain	O
has	O
found	O
a	O
region	O
of	O
low	O
energy	O
example	B
if	O
the	O
variables	O
are	O
pixels	O
in	O
an	O
image	O
a	O
region	O
of	O
low	O
energy	O
might	O
be	O
a	O
connected	O
manifold	B
of	O
images	O
of	O
the	O
same	O
object	O
which	O
we	O
call	O
a	O
mode	O
the	O
chain	O
will	O
tend	O
to	O
walk	O
around	O
that	O
mode	O
a	O
kind	O
of	O
random	O
walk	O
once	O
in	O
a	O
while	O
it	O
will	O
step	O
out	O
of	O
that	O
mode	O
and	O
generally	O
return	O
to	O
it	O
or	O
it	O
finds	O
an	O
escape	O
route	O
move	O
towards	O
another	O
mode	O
the	O
problem	O
is	O
that	O
successful	O
escape	O
routes	O
are	O
rare	O
for	O
many	O
interesting	O
distributions	O
so	O
the	O
markov	B
chain	I
will	O
continue	O
to	O
sample	O
the	O
same	O
mode	O
longer	O
than	O
it	O
should	O
this	O
is	O
very	O
clear	O
when	O
we	O
consider	O
the	O
gibbs	O
sampling	O
algorithm	O
in	O
this	O
context	O
consider	O
the	O
probability	O
of	O
going	O
from	O
one	O
mode	O
to	O
a	O
nearby	O
mode	O
within	O
a	O
given	O
number	O
of	O
steps	O
what	O
will	O
determine	O
that	O
probability	O
is	O
the	O
shape	O
of	O
the	O
energy	O
barrier	O
between	O
these	O
modes	O
transitions	O
between	O
two	O
modes	O
that	O
are	O
separated	O
by	O
a	O
high	O
energy	O
barrier	O
region	O
of	O
low	O
probability	O
are	O
exponentially	O
less	O
likely	O
terms	O
of	O
the	O
height	O
of	O
the	O
energy	O
barrier	O
this	O
is	O
illustrated	O
in	O
figure	O
the	O
problem	O
arises	O
when	O
there	O
are	O
multiple	O
modes	O
with	O
high	O
probability	O
that	O
are	O
separated	O
by	O
regions	O
of	O
low	O
probability	O
especially	O
when	O
each	O
gibbs	O
sampling	O
step	O
must	O
update	O
only	O
a	O
small	O
subset	O
of	O
variables	O
whose	O
values	O
are	O
largely	O
determined	O
by	O
the	O
other	O
variables	O
as	O
a	O
simple	O
example	B
consider	O
an	O
energy-based	O
model	O
over	O
two	O
variables	O
a	O
and	O
wab	O
b	O
which	O
are	O
both	O
binary	O
with	O
a	O
sign	O
taking	O
on	O
values	O
for	O
some	O
large	O
positive	O
number	O
w	O
then	O
the	O
model	O
expresses	O
a	O
strong	O
belief	O
that	O
a	O
and	O
b	O
have	O
the	O
same	O
sign	O
consider	O
updating	O
b	O
using	O
a	O
gibbs	O
sampling	O
step	O
with	O
a	O
a	O
the	O
conditional	O
distribution	O
over	O
b	O
is	O
given	O
by	O
pb	O
if	O
w	O
is	O
large	O
the	O
sigmoid	O
saturates	O
and	O
the	O
probability	O
of	O
also	O
assigning	O
b	O
to	O
be	O
is	O
close	O
to	O
likewise	O
if	O
a	O
is	O
close	O
to	O
according	O
to	O
pmodela	O
b	O
both	O
signs	O
of	O
both	O
variables	O
are	O
equally	O
likely	O
the	O
probability	O
of	O
assigning	O
b	O
to	O
be	O
and	O
if	O
e	O
b	O
chapter	O
monte	O
carlo	O
methods	O
figure	O
paths	O
followed	O
by	O
gibbs	O
sampling	O
for	O
three	O
distributions	O
with	O
the	O
markov	B
chain	I
initialized	O
at	O
the	O
mode	O
in	O
both	O
cases	O
multivariate	O
normal	O
distribution	O
with	O
two	O
independent	O
variables	O
gibbs	O
sampling	O
mixes	O
well	O
because	O
the	O
variables	O
are	O
independent	O
a	O
multivariate	O
normal	O
distribution	O
with	O
highly	O
correlated	O
variables	O
the	O
correlation	B
between	O
variables	O
makes	O
it	O
difficult	O
for	O
the	O
markov	B
chain	I
to	O
mix	O
because	O
the	O
update	O
for	O
each	O
variable	O
must	O
be	O
conditioned	O
on	O
the	O
other	O
variable	O
the	O
correlation	B
reduces	O
the	O
rate	O
at	O
which	O
the	O
markov	B
chain	I
can	O
move	O
away	O
from	O
the	O
starting	O
point	O
mixture	O
of	O
gaussians	O
with	O
widely	O
separated	O
modes	O
that	O
are	O
not	O
axis-aligned	O
gibbs	O
sampling	O
mixes	O
very	O
slowly	O
because	O
it	O
is	O
difficult	O
to	O
change	O
modes	O
while	O
altering	O
only	O
one	O
variable	O
at	O
a	O
time	O
according	O
to	O
pmodela	O
b	O
that	O
gibbs	O
sampling	O
will	O
only	O
very	O
rarely	O
flip	O
the	O
signs	O
of	O
these	O
variables	O
both	O
variables	O
should	O
have	O
the	O
same	O
sign	O
this	O
means	O
in	O
more	O
practical	O
scenarios	O
the	O
challenge	B
is	O
even	O
greater	O
because	O
we	O
care	O
not	O
only	O
about	O
making	O
transitions	O
between	O
two	O
modes	O
but	O
more	O
generally	O
between	O
all	O
the	O
many	O
modes	O
that	O
a	O
real	O
model	O
might	O
contain	O
if	O
several	O
such	O
transitions	O
are	O
difficult	O
because	O
of	O
the	O
difficulty	O
of	O
mixing	O
between	O
modes	O
then	O
it	O
becomes	O
very	O
expensive	O
to	O
obtain	O
a	O
reliable	O
set	O
of	O
samples	O
covering	O
most	O
of	O
the	O
modes	O
and	O
convergence	O
of	O
the	O
chain	O
to	O
its	O
stationary	O
distribution	O
is	O
very	O
slow	O
sometimes	O
this	O
problem	O
can	O
be	O
resolved	O
by	O
finding	O
groups	O
of	O
highly	O
dependent	O
units	O
and	O
updating	O
all	O
of	O
them	O
simultaneously	O
in	O
a	O
block	O
unfortunately	O
when	O
the	O
dependencies	O
are	O
complicated	O
it	O
can	O
be	O
computationally	O
intractable	O
to	O
draw	O
a	O
sample	O
from	O
the	O
group	O
after	O
all	O
the	O
problem	O
that	O
the	O
markov	B
chain	I
was	O
originally	O
introduced	O
to	O
solve	O
is	O
this	O
problem	O
of	O
sampling	O
from	O
a	O
large	O
group	O
of	O
variables	O
in	O
the	O
context	O
of	O
models	O
with	O
latent	O
variables	O
which	O
define	O
a	O
joint	O
distribution	O
we	O
often	O
draw	O
samples	O
of	O
x	O
by	O
alternating	O
between	O
sampling	O
from	O
and	O
sampling	O
from	O
p	O
modelh	O
x	O
from	O
the	O
point	O
of	O
view	O
of	O
mixing	O
pmodelx	O
h	O
pmodelx	O
h	O
chapter	O
monte	O
carlo	O
methods	O
figure	O
an	O
illustration	O
of	O
the	O
slow	O
mixing	O
problem	O
in	O
deep	O
probabilistic	O
models	O
each	O
panel	O
should	O
be	O
read	O
left	O
to	O
right	O
top	O
to	O
bottom	O
samples	O
from	O
gibbs	O
sampling	O
applied	O
to	O
a	O
deep	O
boltzmann	O
machine	O
trained	O
on	O
the	O
mnist	O
dataset	B
consecutive	O
samples	O
are	O
similar	O
to	O
each	O
other	O
because	O
the	O
gibbs	O
sampling	O
is	O
performed	O
in	O
a	O
deep	O
graphical	O
model	O
this	O
similarity	O
is	O
based	O
more	O
on	O
semantic	O
rather	O
than	O
raw	O
visual	O
features	O
but	O
it	O
is	O
still	O
difficult	O
for	O
the	O
gibbs	O
chain	O
to	O
transition	O
from	O
one	O
mode	O
of	O
the	O
distribution	O
to	O
another	O
for	O
example	B
by	O
changing	O
the	O
digit	O
identity	O
consecutive	O
ancestral	O
samples	O
from	O
a	O
generative	O
adversarial	O
network	O
because	O
ancestral	O
sampling	O
generates	O
each	O
sample	O
independently	O
from	O
the	O
others	O
there	O
is	O
no	O
mixing	O
problem	O
rapidly	O
we	O
would	O
like	O
pmodelh	O
x	O
to	O
have	O
very	O
high	O
entropy	O
however	O
from	O
the	O
point	O
of	O
view	O
of	O
learning	O
a	O
useful	O
representation	O
of	O
h	O
we	O
would	O
like	O
h	O
to	O
encode	O
enough	O
information	O
about	O
x	O
to	O
reconstruct	O
it	O
well	O
which	O
implies	O
that	O
h	O
and	O
x	O
should	O
have	O
very	O
high	O
mutual	O
information	O
these	O
two	O
goals	O
are	O
at	O
odds	O
with	O
each	O
other	O
we	O
often	O
learn	O
generative	O
models	O
that	O
very	O
precisely	O
encode	O
x	O
into	O
h	O
but	O
are	O
not	O
able	O
to	O
mix	O
very	O
well	O
this	O
situation	O
arises	O
frequently	O
with	O
boltzmann	O
machines	O
the	O
sharper	O
the	O
distribution	O
a	O
boltzmann	O
machine	O
learns	O
the	O
harder	O
it	O
is	O
for	O
a	O
markov	B
chain	I
sampling	O
from	O
the	O
model	O
distribution	O
to	O
mix	O
well	O
this	O
problem	O
is	O
illustrated	O
in	O
figure	O
all	O
this	O
could	O
make	O
mcmc	O
methods	O
less	O
useful	O
when	O
the	O
distribution	O
of	O
interest	O
has	O
a	O
manifold	B
structure	O
with	O
a	O
separate	O
manifold	B
for	O
each	O
class	O
the	O
distribution	O
is	O
concentrated	O
around	O
many	O
modes	O
and	O
these	O
modes	O
are	O
separated	O
by	O
vast	O
regions	O
of	O
high	O
energy	O
this	O
type	O
of	O
distribution	O
is	O
what	O
we	O
expect	O
in	O
many	O
classification	B
problems	O
and	O
would	O
make	O
mcmc	O
methods	O
converge	O
very	O
slowly	O
because	O
of	O
poor	O
mixing	O
between	O
modes	O
chapter	O
monte	O
carlo	O
methods	O
tempering	B
to	O
mix	O
between	O
modes	O
when	O
a	O
distribution	O
has	O
sharp	O
peaks	O
of	O
high	O
probability	O
surrounded	O
by	O
regions	O
of	O
low	O
probability	O
it	O
is	O
difficult	O
to	O
mix	O
between	O
the	O
different	O
modes	O
of	O
the	O
distribution	O
several	O
techniques	O
for	O
faster	O
mixing	O
are	O
based	O
on	O
constructing	O
alternative	O
versions	O
of	O
the	O
target	O
distribution	O
in	O
which	O
the	O
peaks	O
are	O
not	O
as	O
high	O
and	O
the	O
surrounding	O
valleys	O
are	O
not	O
as	O
low	O
energy-based	O
models	O
provide	O
a	O
particularly	O
simple	O
way	O
to	O
do	O
so	O
so	O
far	O
we	O
have	O
described	O
an	O
energy-based	O
model	O
as	O
defining	O
a	O
probability	B
distribution	I
x	O
e	O
exp	O
p	O
energy-based	O
models	O
may	O
be	O
augmented	O
with	O
an	O
extra	O
parameter	O
controlling	O
how	O
sharply	O
peaked	O
the	O
distribution	O
is	O
p	O
x	O
exp	O
e	O
x	O
the	O
parameter	O
is	O
often	O
described	O
as	O
being	O
the	O
reciprocal	O
of	O
the	O
temperature	O
reflecting	O
the	O
origin	O
of	O
energy-based	O
models	O
in	O
statistical	O
physics	O
when	O
the	O
temperature	O
falls	O
to	O
zero	O
and	O
rises	O
to	O
infinity	O
the	O
energy-based	O
model	O
becomes	O
deterministic	O
when	O
the	O
temperature	O
rises	O
to	O
infinity	O
and	O
falls	O
to	O
zero	O
the	O
distribution	O
discrete	O
becomes	O
uniform	O
x	O
typically	O
a	O
model	O
is	O
trained	O
to	O
be	O
evaluated	O
at	O
however	O
we	O
can	O
make	O
use	O
of	O
other	O
temperatures	O
particularly	O
those	O
where	O
tempering	B
is	O
a	O
general	O
strategy	O
of	O
mixing	O
between	O
modes	O
of	O
p	O
rapidly	O
by	O
drawing	O
samples	O
with	O
iba	O
neal	O
markov	O
chains	O
based	O
on	O
tempered	O
transitions	O
temporarily	O
sample	O
from	O
higher-temperature	O
distributions	O
in	O
order	O
to	O
mix	O
to	O
different	O
modes	O
then	O
resume	O
sampling	O
from	O
the	O
unit	O
temperature	O
distribution	O
these	O
techniques	O
have	O
been	O
applied	O
to	O
models	O
such	O
as	O
rbms	O
another	O
approach	O
is	O
to	O
use	O
parallel	O
tempering	B
in	O
which	O
the	O
markov	B
chain	I
simulates	O
many	O
different	O
states	O
in	O
parallel	O
at	O
different	O
temperatures	O
the	O
highest	O
temperature	O
states	O
mix	O
slowly	O
while	O
the	O
lowest	O
temperature	O
states	O
at	O
temperature	O
provide	O
accurate	O
samples	O
from	O
the	O
model	O
the	O
transition	O
operator	O
includes	O
stochastically	O
swapping	O
states	O
between	O
two	O
different	O
temperature	O
levels	O
so	O
that	O
a	O
sufficiently	O
high-probability	O
sample	O
from	O
a	O
high-temperature	O
slot	O
can	O
jump	O
into	O
a	O
lower	O
temperature	O
slot	O
this	O
approach	O
has	O
also	O
been	O
applied	O
to	O
rbms	O
et	O
al	O
although	O
tempering	B
is	O
a	O
promising	O
approach	O
at	O
this	O
point	O
it	O
has	O
not	O
allowed	O
researchers	O
to	O
make	O
a	O
strong	O
advance	O
in	O
solving	O
the	O
challenge	B
of	O
sampling	O
from	O
complex	O
ebms	O
one	O
possible	O
reason	O
is	O
that	O
there	O
are	O
critical	O
temperatures	O
around	O
which	O
the	O
temperature	O
transition	O
must	O
be	O
very	O
slow	O
the	O
temperature	O
is	O
gradually	O
reduced	O
in	O
order	O
for	O
tempering	B
to	O
be	O
effective	O
cho	O
et	O
al	O
chapter	O
monte	O
carlo	O
methods	O
depth	O
may	O
help	O
mixing	O
x	O
h	O
into	O
encodes	O
x	O
too	O
well	O
then	O
sampling	O
from	O
px	O
h	O
we	O
have	O
seen	O
that	O
if	O
when	O
drawing	O
samples	O
from	O
a	O
latent	B
variable	I
model	O
ph	O
x	O
ph	O
x	O
will	O
not	O
change	O
x	O
very	O
much	O
and	O
mixing	O
will	O
be	O
poor	O
one	O
way	O
to	O
resolve	O
this	O
problem	O
is	O
to	O
make	O
h	O
be	O
a	O
deep	O
representation	O
that	O
encodes	O
in	O
such	O
a	O
way	O
that	O
a	O
markov	B
chain	I
in	O
the	O
space	O
of	O
h	O
can	O
mix	O
more	O
easily	O
many	O
representation	B
learning	I
algorithms	O
such	O
as	O
autoencoders	O
and	O
rbms	O
tend	O
to	O
yield	O
a	O
marginal	O
distribution	O
over	O
h	O
that	O
is	O
more	O
uniform	O
and	O
more	O
unimodal	O
than	O
the	O
original	O
data	O
distribution	O
over	O
x	O
it	O
can	O
be	O
argued	O
that	O
this	O
arises	O
from	O
trying	O
to	O
minimize	O
reconstruction	O
error	O
while	O
using	O
all	O
of	O
the	O
available	O
representation	O
space	O
because	O
minimizing	O
reconstruction	O
error	O
over	O
the	O
training	O
examples	O
will	O
be	O
better	O
achieved	O
when	O
different	O
training	O
examples	O
are	O
easily	O
distinguishable	O
from	O
each	O
other	O
in	O
h-space	O
and	O
thus	O
well	O
separated	O
bengio	O
observed	O
that	O
deeper	O
stacks	O
of	O
regularized	O
autoencoders	O
or	O
rbms	O
yield	O
marginal	O
distributions	O
in	O
the	O
top-level	O
h-space	O
that	O
appeared	O
more	O
spread	O
out	O
and	O
more	O
uniform	O
with	O
less	O
of	O
a	O
gap	O
between	O
the	O
regions	O
corresponding	O
to	O
different	O
modes	O
in	O
the	O
experiments	O
training	O
an	O
rbm	O
in	O
that	O
higher-level	O
space	O
allowed	O
gibbs	O
sampling	O
to	O
mix	O
faster	O
between	O
modes	O
it	O
remains	O
however	O
unclear	O
how	O
to	O
exploit	O
this	O
observation	O
to	O
help	O
better	O
train	O
and	O
sample	O
from	O
deep	O
generative	O
models	O
et	O
al	O
despite	O
the	O
difficulty	O
of	O
mixing	O
monte	O
carlo	O
techniques	O
are	O
useful	O
and	O
are	O
often	O
the	O
best	O
tool	O
available	O
indeed	O
they	O
are	O
the	O
primary	O
tool	O
used	O
to	O
confront	O
the	O
intractable	O
partition	O
function	O
of	O
undirected	O
models	O
discussed	O
next	O
chapter	O
confronting	O
the	O
partition	O
function	O
in	O
section	O
we	O
saw	O
that	O
many	O
probabilistic	O
models	O
known	O
as	O
undirected	O
graphical	O
models	O
are	O
defined	O
by	O
an	O
unnormalized	B
probability	B
distribution	I
px	O
we	O
must	O
normalize	O
p	O
by	O
dividing	O
by	O
a	O
partition	O
function	O
z	O
in	O
order	O
to	O
obtain	O
a	O
valid	O
probability	B
distribution	I
p	O
x	O
p	O
the	O
partition	O
function	O
is	O
an	O
integral	O
continuous	O
variables	O
or	O
sum	O
discrete	O
variables	O
over	O
the	O
unnormalized	O
probability	O
of	O
all	O
states	O
z	O
p	O
x	O
d	O
or	O
p	O
x	O
this	O
operation	B
is	O
intractable	O
for	O
many	O
interesting	O
models	O
as	O
we	O
will	O
see	O
in	O
chapter	O
several	O
deep	O
learning	O
models	O
are	O
designed	O
to	O
have	O
a	O
tractable	O
normalizing	O
constant	O
or	O
are	O
designed	O
to	O
be	O
used	O
in	O
ways	O
that	O
do	O
not	O
involve	O
computing	O
px	O
at	O
all	O
however	O
other	O
models	O
directly	O
confront	O
the	O
challenge	B
of	O
intractable	O
partition	O
functions	O
in	O
this	O
chapter	O
we	O
describe	O
techniques	O
used	O
for	O
training	O
and	O
evaluating	O
models	O
that	O
have	O
intractable	O
partition	O
functions	O
chapter	O
confronting	O
the	O
partition	O
function	O
the	O
log-likelihood	O
gradient	B
what	O
makes	O
learning	O
undirected	O
models	O
by	O
maximum	B
likelihood	I
particularly	O
difficult	O
is	O
that	O
the	O
partition	O
function	O
depends	O
on	O
the	O
parameters	O
the	O
gradient	B
of	O
the	O
log-likelihood	O
with	O
respect	O
to	O
the	O
parameters	O
has	O
a	O
term	O
corresponding	O
to	O
the	O
gradient	B
of	O
the	O
partition	O
function	O
log	O
p	O
log	O
p	O
x	O
log	O
this	O
is	O
a	O
well-known	O
decomposition	O
into	O
the	O
positive	O
phase	O
and	O
negative	O
phase	O
of	O
learning	O
for	O
most	O
undirected	O
models	O
of	O
interest	O
the	O
negative	O
phase	O
is	O
difficult	O
models	O
with	O
no	O
latent	O
variables	O
or	O
with	O
few	O
interactions	O
between	O
latent	O
variables	O
typically	O
have	O
a	O
tractable	O
positive	O
phase	O
the	O
quintessential	O
example	B
of	O
a	O
model	O
with	O
a	O
straightforward	O
positive	O
phase	O
and	O
difficult	O
negative	O
phase	O
is	O
the	O
rbm	O
which	O
has	O
hidden	O
units	O
that	O
are	O
conditionally	O
independent	O
from	O
each	O
other	O
given	O
the	O
visible	O
units	O
the	O
case	O
where	O
the	O
positive	O
phase	O
is	O
difficult	O
with	O
complicated	O
interactions	O
between	O
latent	O
variables	O
is	O
primarily	O
covered	O
in	O
chapter	O
this	O
chapter	O
focuses	O
on	O
the	O
difficulties	O
of	O
the	O
negative	O
phase	O
let	O
us	O
look	O
more	O
closely	O
at	O
the	O
gradient	B
of	O
log	O
z	O
log	O
z	O
z	O
z	O
p	O
x	O
z	O
p	O
z	O
x	O
for	O
models	O
that	O
guarantee	O
px	O
for	O
all	O
x	O
we	O
can	O
substitute	O
exp	O
p	O
for	O
p	O
exp	O
p	O
z	O
log	O
p	O
exp	O
p	O
x	O
x	O
x	O
x	O
z	O
p	O
z	O
p	O
log	O
p	O
log	O
p	O
chapter	O
confronting	O
the	O
partition	O
function	O
ex	O
p	O
x	O
log	O
p	O
p	O
p	O
this	O
derivation	O
made	O
use	O
of	O
summation	O
over	O
discrete	O
x	O
but	O
a	O
similar	O
result	O
applies	O
using	O
integration	O
over	O
continuous	O
x	O
in	O
the	O
continuous	O
version	O
of	O
the	O
derivation	O
we	O
use	O
leibniz	O
s	O
rule	O
for	O
differentiation	O
under	O
the	O
integral	O
sign	O
to	O
obtain	O
the	O
identity	O
x	O
d	O
d	O
x	O
this	O
identity	O
is	O
applicable	O
only	O
under	O
certain	O
regularity	O
conditions	O
on	O
p	O
and	O
px	O
in	O
measure	O
theoretic	O
terms	O
the	O
conditions	O
are	O
the	O
unnormalized	O
distribution	O
p	O
must	O
be	O
a	O
lebesgue-integrable	O
function	O
of	O
x	O
for	O
every	O
value	O
of	O
the	O
gradient	B
px	O
must	O
exist	O
for	O
all	O
and	O
almost	O
all	O
x	O
there	O
must	O
exist	O
an	O
integrable	O
rx	O
for	O
all	O
function	O
rx	O
that	O
bounds	O
and	O
almost	O
all	O
x	O
fortunately	O
most	O
machine	B
learning	I
models	O
of	O
interest	O
have	O
these	O
properties	O
px	O
in	O
the	O
sense	O
that	O
maxi	O
px	O
i	O
this	O
identity	O
log	O
z	O
ex	O
p	O
x	O
log	O
p	O
is	O
the	O
basis	O
for	O
a	O
variety	O
of	O
monte	O
carlo	O
methods	O
for	O
approximately	O
maximizing	O
the	O
likelihood	O
of	O
models	O
with	O
intractable	O
partition	O
functions	O
the	O
monte	O
carlo	O
approach	O
to	O
learning	O
undirected	O
models	O
provides	O
an	O
intuitive	O
framework	O
in	O
which	O
we	O
can	O
think	O
of	O
both	O
the	O
positive	O
phase	O
and	O
the	O
negative	O
phase	O
in	O
the	O
positive	O
phase	O
we	O
increase	O
log	O
px	O
for	O
x	O
drawn	O
from	O
the	O
data	O
in	O
the	O
negative	O
phase	O
we	O
decrease	O
the	O
partition	O
function	O
by	O
decreasing	O
log	O
px	O
drawn	O
from	O
the	O
model	O
distribution	O
in	O
the	O
deep	O
learning	O
literature	O
it	O
is	O
common	O
to	O
parametrize	O
log	O
p	O
in	O
terms	O
of	O
an	O
energy	B
function	I
in	O
this	O
case	O
we	O
can	O
interpret	O
the	O
positive	O
phase	O
as	O
pushing	O
down	O
on	O
the	O
energy	O
of	O
training	O
examples	O
and	O
the	O
negative	O
phase	O
as	O
pushing	O
up	O
on	O
the	O
energy	O
of	O
samples	O
drawn	O
from	O
the	O
model	O
as	O
illustrated	O
in	O
figure	O
stochastic	O
maximum	B
likelihood	I
and	O
contrastive	O
divergence	O
the	O
naive	O
way	O
of	O
implementing	O
equation	O
is	O
to	O
compute	O
it	O
by	O
burning	O
in	O
a	O
set	O
of	O
markov	O
chains	O
from	O
a	O
random	O
initialization	B
every	O
time	O
the	O
gradient	B
is	O
needed	O
when	O
learning	O
is	O
performed	O
using	O
stochastic	O
gradient	B
descent	O
this	O
means	O
the	O
chains	O
must	O
be	O
burned	O
in	O
once	O
per	O
gradient	B
step	O
this	O
approach	O
leads	O
to	O
the	O
chapter	O
confronting	O
the	O
partition	O
function	O
the	O
high	O
cost	O
of	O
burning	O
in	O
the	O
training	O
procedure	O
presented	O
in	O
algorithm	O
markov	O
chains	O
in	O
the	O
inner	O
loop	B
makes	O
this	O
procedure	O
computationally	O
infeasible	O
but	O
this	O
procedure	O
is	O
the	O
starting	O
point	O
that	O
other	O
more	O
practical	O
algorithms	O
aim	O
to	O
approximate	O
algorithm	O
a	O
naive	O
mcmc	O
algorithm	O
for	O
maximizing	O
the	O
log-likelihood	O
with	O
an	O
intractable	O
partition	O
function	O
using	O
gradient	B
ascent	O
set	O
the	O
step	O
size	O
to	O
a	O
small	O
positive	O
number	O
set	O
k	O
the	O
number	O
of	O
gibbs	O
steps	O
high	O
enough	O
to	O
allow	O
burn	O
in	O
perhaps	O
to	O
train	O
an	O
rbm	O
on	O
a	O
small	O
image	O
patch	O
while	O
not	O
converged	O
do	O
x	O
sample	O
a	O
minibatch	B
of	O
log	O
px	O
g	O
initialize	O
a	O
set	O
of	O
m	O
samples	O
to	O
random	O
values	O
from	O
a	O
uniform	O
or	O
normal	O
distribution	O
or	O
possibly	O
a	O
distribution	O
with	O
marginals	O
matched	O
to	O
the	O
model	O
s	O
marginals	O
for	O
from	O
the	O
training	O
set	O
x	O
examples	O
m	O
m	O
m	O
i	O
for	O
to	O
k	O
to	O
j	O
x	O
do	O
m	O
do	O
gibbs	O
update	O
x	O
end	O
for	O
end	O
for	O
g	O
m	O
g	O
m	O
log	O
p	O
x	O
end	O
while	O
we	O
can	O
view	O
the	O
mcmc	O
approach	O
to	O
maximum	B
likelihood	I
as	O
trying	O
to	O
achieve	O
balance	O
between	O
two	O
forces	O
one	O
pushing	O
up	O
on	O
the	O
model	O
distribution	O
where	O
the	O
data	O
occurs	O
and	O
another	O
pushing	O
down	O
on	O
the	O
model	O
distribution	O
where	O
the	O
model	O
samples	O
occur	O
figure	O
illustrates	O
this	O
process	O
the	O
two	O
forces	O
correspond	O
to	O
maximizing	O
log	O
p	O
and	O
minimizing	O
log	O
z	O
several	O
approximations	O
to	O
the	O
negative	O
phase	O
are	O
possible	O
each	O
of	O
these	O
approximations	O
can	O
be	O
understood	O
as	O
making	O
the	O
negative	O
phase	O
computationally	O
cheaper	O
but	O
also	O
making	O
it	O
push	O
down	O
in	O
the	O
wrong	O
locations	O
because	O
the	O
negative	O
phase	O
involves	O
drawing	O
samples	O
from	O
the	O
model	O
s	O
distribution	O
we	O
can	O
think	O
of	O
it	O
as	O
finding	O
points	O
that	O
the	O
model	O
believes	O
in	O
strongly	O
because	O
the	O
negative	O
phase	O
acts	O
to	O
reduce	O
the	O
probability	O
of	O
those	O
points	O
they	O
are	O
generally	O
considered	O
to	O
represent	O
the	O
model	O
s	O
incorrect	O
beliefs	O
about	O
the	O
world	O
they	O
are	O
frequently	O
referred	O
to	O
in	O
the	O
literature	O
as	O
hallucinations	O
or	O
fantasy	O
particles	O
in	O
fact	O
the	O
negative	O
phase	O
has	O
been	O
proposed	O
as	O
a	O
possible	O
explanation	O
chapter	O
confronting	O
the	O
partition	O
function	O
the	O
positive	O
phase	O
the	O
negative	O
phase	O
pmodel	O
pdata	O
pmodel	O
pdata	O
x	O
p	O
x	O
p	O
x	O
x	O
figure	O
the	O
view	O
of	O
algorithm	O
as	O
having	O
a	O
positive	O
phase	O
and	O
negative	O
phase	O
the	O
positive	O
phase	O
we	O
sample	O
points	O
from	O
the	O
data	O
distribution	O
and	O
push	O
up	O
on	O
their	O
unnormalized	O
probability	O
this	O
means	O
points	O
that	O
are	O
likely	O
in	O
the	O
data	O
get	O
pushed	O
up	O
on	O
more	O
the	O
negative	O
phase	O
we	O
sample	O
points	O
from	O
the	O
model	O
distribution	O
and	O
push	O
down	O
on	O
their	O
unnormalized	O
probability	O
this	O
counteracts	O
the	O
positive	O
phase	O
s	O
tendency	O
to	O
just	O
add	O
a	O
large	O
constant	O
to	O
the	O
unnormalized	O
probability	O
everywhere	O
when	O
the	O
data	O
distribution	O
and	O
the	O
model	O
distribution	O
are	O
equal	O
the	O
positive	O
phase	O
has	O
the	O
same	O
chance	O
to	O
push	O
up	O
at	O
a	O
point	O
as	O
the	O
negative	O
phase	O
has	O
to	O
push	O
down	O
when	O
this	O
occurs	O
there	O
is	O
no	O
longer	O
any	O
gradient	B
expectation	B
and	O
training	O
must	O
terminate	O
the	O
idea	O
for	O
dreaming	O
in	O
humans	O
and	O
other	O
animals	O
and	O
mitchison	O
being	O
that	O
the	O
brain	O
maintains	O
a	O
probabilistic	O
model	O
of	O
the	O
world	O
and	O
follows	O
the	O
gradient	B
of	O
log	O
p	O
while	O
experiencing	O
real	O
events	O
while	O
awake	O
and	O
follows	O
the	O
negative	O
gradient	B
of	O
log	O
p	O
to	O
minimize	O
log	O
z	O
while	O
sleeping	O
and	O
experiencing	O
events	O
sampled	O
from	O
the	O
current	O
model	O
this	O
view	O
explains	O
much	O
of	O
the	O
language	O
used	O
to	O
describe	O
algorithms	O
with	O
a	O
positive	O
and	O
negative	O
phase	O
but	O
it	O
has	O
not	O
been	O
proven	O
to	O
be	O
correct	O
with	O
neuroscientific	O
experiments	O
in	O
machine	B
learning	I
models	O
it	O
is	O
usually	O
necessary	O
to	O
use	O
the	O
positive	O
and	O
negative	O
phase	O
simultaneously	O
rather	O
than	O
in	O
separate	O
time	O
periods	O
of	O
wakefulness	O
and	O
rem	O
sleep	O
as	O
we	O
will	O
see	O
in	O
section	O
other	O
machine	B
learning	I
algorithms	O
draw	O
samples	O
from	O
the	O
model	O
distribution	O
for	O
other	O
purposes	O
and	O
such	O
algorithms	O
could	O
also	O
provide	O
an	O
account	O
for	O
the	O
function	O
of	O
dream	O
sleep	O
given	O
this	O
understanding	O
of	O
the	O
role	O
of	O
the	O
positive	O
and	O
negative	O
phase	O
of	O
learning	O
we	O
can	O
attempt	O
to	O
design	O
a	O
less	O
expensive	O
alternative	O
to	O
algorithm	O
the	O
main	O
cost	O
of	O
the	O
naive	O
mcmc	O
algorithm	O
is	O
the	O
cost	O
of	O
burning	O
in	O
the	O
markov	O
chains	O
from	O
a	O
random	O
initialization	B
at	O
each	O
step	O
a	O
natural	O
solution	O
is	O
to	O
initialize	O
the	O
markov	O
chains	O
from	O
a	O
distribution	O
that	O
is	O
very	O
close	O
to	O
the	O
model	O
distribution	O
chapter	O
confronting	O
the	O
partition	O
function	O
so	O
that	O
the	O
burn	O
in	O
operation	B
does	O
not	O
take	O
as	O
many	O
steps	O
this	O
approach	O
is	O
presented	O
as	O
algorithm	O
the	O
contrastive	O
divergence	O
or	O
cd-k	O
to	O
indicate	O
cd	O
with	O
k	O
gibbs	O
steps	O
algorithm	O
initializes	O
the	O
markov	B
chain	I
at	O
each	O
step	O
with	O
samples	O
from	O
the	O
data	O
distribution	O
obtaining	O
samples	O
from	O
the	O
data	O
distribution	O
is	O
free	O
because	O
they	O
are	O
already	O
available	O
in	O
the	O
data	O
set	O
initially	O
the	O
data	O
distribution	O
is	O
not	O
close	O
to	O
the	O
model	O
distribution	O
so	O
the	O
negative	O
phase	O
is	O
not	O
very	O
accurate	O
fortunately	O
the	O
positive	O
phase	O
can	O
still	O
accurately	O
increase	O
the	O
model	O
s	O
probability	O
of	O
the	O
data	O
after	O
the	O
positive	O
phase	O
has	O
had	O
some	O
time	O
to	O
act	O
the	O
model	O
distribution	O
is	O
closer	O
to	O
the	O
data	O
distribution	O
and	O
the	O
negative	O
phase	O
starts	O
to	O
become	O
accurate	O
algorithm	O
the	O
contrastive	O
divergence	O
algorithm	O
using	O
gradient	B
ascent	O
as	O
the	O
optimization	O
procedure	O
set	O
the	O
step	O
size	O
to	O
a	O
small	O
positive	O
number	O
set	O
k	O
the	O
number	O
of	O
gibbs	O
steps	O
high	O
enough	O
to	O
allow	O
a	O
markov	B
chain	I
sampling	O
from	O
px	O
to	O
mix	O
when	O
initialized	O
from	O
pdata	O
perhaps	O
to	O
train	O
an	O
rbm	O
on	O
a	O
small	O
image	O
patch	O
while	O
not	O
converged	O
do	O
sample	O
a	O
minibatch	B
of	O
g	O
for	O
log	O
px	O
do	O
x	O
from	O
the	O
training	O
set	O
examples	O
m	O
m	O
m	O
to	O
m	O
x	O
i	O
x	O
do	O
m	O
do	O
gibbs	O
update	O
x	O
end	O
for	O
for	O
i	O
for	O
to	O
k	O
to	O
j	O
x	O
end	O
for	O
end	O
for	O
g	O
m	O
g	O
m	O
log	O
p	O
x	O
end	O
while	O
of	O
course	O
cd	O
is	O
still	O
an	O
approximation	O
to	O
the	O
correct	O
negative	O
phase	O
the	O
main	O
way	O
that	O
cd	O
qualitatively	O
fails	O
to	O
implement	O
the	O
correct	O
negative	O
phase	O
is	O
that	O
it	O
fails	O
to	O
suppress	O
regions	O
of	O
high	O
probability	O
that	O
are	O
far	O
from	O
actual	O
training	O
examples	O
these	O
regions	O
that	O
have	O
high	O
probability	O
under	O
the	O
model	O
but	O
low	O
probability	O
under	O
the	O
data	O
generating	O
distribution	O
are	O
called	O
spurious	O
modes	O
figure	O
illustrates	O
why	O
this	O
happens	O
essentially	O
it	O
is	O
because	O
modes	O
in	O
the	O
model	O
distribution	O
that	O
are	O
far	O
from	O
the	O
data	O
distribution	O
will	O
not	O
be	O
visited	O
by	O
chapter	O
confronting	O
the	O
partition	O
function	O
pmodel	O
pdata	O
x	O
p	O
x	O
figure	O
an	O
illustration	O
of	O
how	O
the	O
negative	O
phase	O
of	O
contrastive	O
divergence	O
can	O
fail	O
to	O
suppress	O
spurious	O
modes	O
a	O
spurious	O
mode	O
is	O
a	O
mode	O
that	O
is	O
present	O
in	O
the	O
model	O
distribution	O
but	O
absent	O
in	O
the	O
data	O
distribution	O
because	O
contrastive	O
divergence	O
initializes	O
its	O
markov	O
chains	O
from	O
data	O
points	O
and	O
runs	O
the	O
markov	B
chain	I
for	O
only	O
a	O
few	O
steps	O
it	O
is	O
unlikely	O
to	O
visit	O
modes	O
in	O
the	O
model	O
that	O
are	O
far	O
from	O
the	O
data	O
points	O
this	O
means	O
that	O
when	O
sampling	O
from	O
the	O
model	O
we	O
will	O
sometimes	O
get	O
samples	O
that	O
do	O
not	O
resemble	O
the	O
data	O
it	O
also	O
means	O
that	O
due	O
to	O
wasting	O
some	O
of	O
its	O
probability	O
mass	O
on	O
these	O
modes	O
the	O
model	O
will	O
struggle	O
to	O
place	O
high	O
probability	O
mass	O
on	O
the	O
correct	O
modes	O
for	O
the	O
purpose	O
of	O
visualization	O
this	O
figure	O
uses	O
a	O
somewhat	O
simplified	O
concept	O
of	O
distance	O
the	O
spurious	O
mode	O
is	O
far	O
from	O
the	O
correct	O
mode	O
along	O
the	O
number	O
line	O
in	O
r	O
this	O
corresponds	O
to	O
a	O
markov	B
chain	I
based	O
on	O
making	O
local	O
moves	O
with	O
a	O
single	O
x	O
variable	O
in	O
r	O
for	O
most	O
deep	O
probabilistic	O
models	O
the	O
markov	O
chains	O
are	O
based	O
on	O
gibbs	O
sampling	O
and	O
can	O
make	O
non-local	O
moves	O
of	O
individual	O
variables	O
but	O
cannot	O
move	O
all	O
of	O
the	O
variables	O
simultaneously	O
for	O
these	O
problems	O
it	O
is	O
usually	O
better	O
to	O
consider	O
the	O
edit	O
distance	O
between	O
modes	O
rather	O
than	O
the	O
euclidean	O
distance	O
however	O
edit	O
distance	O
in	O
a	O
high	O
dimensional	O
space	O
is	O
difficult	O
to	O
depict	O
in	O
a	O
plot	O
markov	O
chains	O
initialized	O
at	O
training	O
points	O
unless	O
k	O
is	O
very	O
large	O
carreira-perpi	O
an	O
and	O
hinton	O
showed	O
experimentally	O
that	O
the	O
cd	O
estimator	O
is	O
biased	O
for	O
rbms	O
and	O
fully	O
visible	O
boltzmann	O
machines	O
in	O
that	O
it	O
converges	O
to	O
different	O
points	O
than	O
the	O
maximum	B
likelihood	I
estimator	O
they	O
argue	O
that	O
because	O
the	O
bias	O
is	O
small	O
cd	O
could	O
be	O
used	O
as	O
an	O
inexpensive	O
way	O
to	O
initialize	O
a	O
model	O
that	O
could	O
later	O
be	O
fine-tuned	O
via	O
more	O
expensive	O
mcmc	O
methods	O
bengio	O
and	O
delalleau	O
showed	O
that	O
cd	O
can	O
be	O
interpreted	O
as	O
discarding	O
the	O
smallest	O
terms	O
of	O
the	O
correct	O
mcmc	O
update	O
gradient	B
which	O
explains	O
the	O
bias	O
cd	O
is	O
useful	O
for	O
training	O
shallow	O
models	O
like	O
rbms	O
these	O
can	O
in	O
turn	O
be	O
stacked	O
to	O
initialize	O
deeper	O
models	O
like	O
dbns	O
or	O
dbms	O
however	O
cd	O
does	O
not	O
provide	O
much	O
help	O
for	O
training	O
deeper	O
models	O
directly	O
this	O
is	O
because	O
it	O
is	O
difficult	O
chapter	O
confronting	O
the	O
partition	O
function	O
to	O
obtain	O
samples	O
of	O
the	O
hidden	O
units	O
given	O
samples	O
of	O
the	O
visible	O
units	O
since	O
the	O
hidden	O
units	O
are	O
not	O
included	O
in	O
the	O
data	O
initializing	O
from	O
training	O
points	O
cannot	O
solve	O
the	O
problem	O
even	O
if	O
we	O
initialize	O
the	O
visible	O
units	O
from	O
the	O
data	O
we	O
will	O
still	O
need	O
to	O
burn	O
in	O
a	O
markov	B
chain	I
sampling	O
from	O
the	O
distribution	O
over	O
the	O
hidden	O
units	O
conditioned	O
on	O
those	O
visible	O
samples	O
the	O
cd	O
algorithm	O
can	O
be	O
thought	O
of	O
as	O
penalizing	O
the	O
model	O
for	O
having	O
a	O
markov	B
chain	I
that	O
changes	O
the	O
input	O
rapidly	O
when	O
the	O
input	O
comes	O
from	O
the	O
data	O
this	O
means	O
training	O
with	O
cd	O
somewhat	O
resembles	O
autoencoder	O
training	O
even	O
though	O
cd	O
is	O
more	O
biased	O
than	O
some	O
of	O
the	O
other	O
training	O
methods	O
it	O
can	O
be	O
useful	O
for	O
pretraining	O
shallow	O
models	O
that	O
will	O
later	O
be	O
stacked	O
this	O
is	O
because	O
the	O
earliest	O
models	O
in	O
the	O
stack	O
are	O
encouraged	O
to	O
copy	O
more	O
information	O
up	O
to	O
their	O
latent	O
variables	O
thereby	O
making	O
it	O
available	O
to	O
the	O
later	O
models	O
this	O
should	O
be	O
thought	O
of	O
more	O
of	O
as	O
an	O
often-exploitable	O
side	O
effect	O
of	O
cd	O
training	O
rather	O
than	O
a	O
principled	O
design	O
advantage	O
sutskever	O
and	O
tieleman	O
showed	O
that	O
the	O
cd	O
update	O
direction	O
is	O
not	O
the	O
gradient	B
of	O
any	O
function	O
this	O
allows	O
for	O
situations	O
where	O
cd	O
could	O
cycle	O
forever	O
but	O
in	O
practice	O
this	O
is	O
not	O
a	O
serious	O
problem	O
a	O
different	O
strategy	O
that	O
resolves	O
many	O
of	O
the	O
problems	O
with	O
cd	O
is	O
to	O
initialize	O
the	O
markov	O
chains	O
at	O
each	O
gradient	B
step	O
with	O
their	O
states	O
from	O
the	O
previous	O
gradient	B
step	O
this	O
approach	O
was	O
first	O
discovered	O
under	O
the	O
name	O
stochastic	O
maximum	B
likelihood	I
in	O
the	O
applied	O
mathematics	O
and	O
statistics	O
community	O
and	O
later	O
independently	O
rediscovered	O
under	O
the	O
name	O
persistent	O
contrastive	O
divergence	O
or	O
pcd-k	O
to	O
indicate	O
the	O
use	O
of	O
k	O
gibbs	O
steps	O
per	O
update	O
in	O
the	O
deep	O
learning	O
community	O
the	O
basic	O
idea	O
of	O
this	O
approach	O
is	O
that	O
so	O
long	O
as	O
the	O
steps	O
taken	O
by	O
the	O
stochastic	O
gradient	B
algorithm	O
are	O
small	O
then	O
the	O
model	O
from	O
the	O
previous	O
step	O
will	O
be	O
similar	O
to	O
the	O
model	O
from	O
the	O
current	O
step	O
it	O
follows	O
that	O
the	O
samples	O
from	O
the	O
previous	O
model	O
s	O
distribution	O
will	O
be	O
very	O
close	O
to	O
being	O
fair	O
samples	O
from	O
the	O
current	O
model	O
s	O
distribution	O
so	O
a	O
markov	B
chain	I
initialized	O
with	O
these	O
samples	O
will	O
not	O
require	O
much	O
time	O
to	O
mix	O
see	O
algorithm	O
tieleman	O
because	O
each	O
markov	B
chain	I
is	O
continually	O
updated	O
throughout	O
the	O
learning	O
process	O
rather	O
than	O
restarted	O
at	O
each	O
gradient	B
step	O
the	O
chains	O
are	O
free	O
to	O
wander	O
far	O
enough	O
to	O
find	O
all	O
of	O
the	O
model	O
s	O
modes	O
sml	O
is	O
thus	O
considerably	O
more	O
resistant	O
to	O
forming	O
models	O
with	O
spurious	O
modes	O
than	O
cd	O
is	O
moreover	O
because	O
it	O
is	O
possible	O
to	O
store	O
the	O
state	O
of	O
all	O
of	O
the	O
sampled	O
variables	O
whether	O
visible	O
or	O
latent	O
sml	O
provides	O
an	O
initialization	B
point	O
for	O
both	O
the	O
hidden	O
and	O
visible	O
units	O
cd	O
is	O
only	O
able	O
to	O
provide	O
an	O
initialization	B
for	O
the	O
visible	O
units	O
and	O
therefore	O
requires	O
burn-in	B
for	O
deep	O
models	O
sml	O
is	O
able	O
to	O
train	O
deep	O
models	O
efficiently	O
chapter	O
confronting	O
the	O
partition	O
function	O
et	O
al	O
compared	O
sml	O
to	O
many	O
of	O
the	O
other	O
criteria	O
presented	O
in	O
marlin	O
this	O
chapter	O
they	O
found	O
that	O
sml	O
results	O
in	O
the	O
best	O
test	B
set	I
log-likelihood	O
for	O
an	O
rbm	O
and	O
that	O
if	O
the	O
rbm	O
s	O
hidden	O
units	O
are	O
used	O
as	O
features	O
for	O
an	O
svm	O
classifier	O
sml	O
results	O
in	O
the	O
best	O
classification	B
accuracy	B
sml	O
is	O
vulnerable	O
to	O
becoming	O
inaccurate	O
if	O
the	O
stochastic	O
gradient	B
algorithm	O
can	O
move	O
the	O
model	O
faster	O
than	O
the	O
markov	B
chain	I
can	O
mix	O
between	O
steps	O
this	O
can	O
happen	O
if	O
k	O
is	O
too	O
small	O
or	O
is	O
too	O
large	O
the	O
permissible	O
range	O
of	O
values	O
is	O
unfortunately	O
highly	O
problem-dependent	O
there	O
is	O
no	O
known	O
way	O
to	O
test	O
formally	O
whether	O
the	O
chain	O
is	O
successfully	O
mixing	O
between	O
steps	O
subjectively	O
if	O
the	O
learning	B
rate	I
is	O
too	O
high	O
for	O
the	O
number	O
of	O
gibbs	O
steps	O
the	O
human	O
operator	O
will	O
be	O
able	O
to	O
observe	O
that	O
there	O
is	O
much	O
more	O
variance	O
in	O
the	O
negative	O
phase	O
samples	O
across	O
gradient	B
steps	O
rather	O
than	O
across	O
different	O
markov	O
chains	O
for	O
example	B
a	O
model	O
trained	O
on	O
mnist	O
might	O
sample	O
exclusively	O
on	O
one	O
step	O
the	O
learning	O
process	O
will	O
then	O
push	O
down	O
strongly	O
on	O
the	O
mode	O
corresponding	O
to	O
and	O
the	O
model	O
might	O
sample	O
exclusively	O
on	O
the	O
next	O
step	O
algorithm	O
the	O
stochastic	O
maximum	B
likelihood	I
persistent	O
contrastive	O
divergence	O
algorithm	O
using	O
gradient	B
ascent	O
as	O
the	O
optimization	O
procedure	O
set	O
the	O
step	O
size	O
to	O
a	O
small	O
positive	O
number	O
set	O
k	O
the	O
number	O
of	O
gibbs	O
steps	O
high	O
enough	O
to	O
allow	O
a	O
markov	B
chain	I
sampling	O
from	O
px	O
g	O
to	O
burn	O
in	O
starting	O
from	O
samples	O
from	O
px	O
perhaps	O
for	O
rbm	O
on	O
a	O
small	O
image	O
patch	O
or	O
for	O
a	O
more	O
complicated	O
model	O
like	O
a	O
dbm	O
initialize	O
a	O
set	O
of	O
m	O
samples	O
to	O
random	O
values	O
from	O
a	O
uniform	O
or	O
normal	O
distribution	O
or	O
possibly	O
a	O
distribution	O
with	O
marginals	O
matched	O
to	O
the	O
model	O
s	O
marginals	O
while	O
not	O
converged	O
do	O
sample	O
a	O
minibatch	B
of	O
g	O
for	O
x	O
from	O
the	O
training	O
set	O
x	O
examples	O
m	O
log	O
px	O
do	O
m	O
do	O
gibbs	O
update	O
x	O
m	O
log	O
p	O
x	O
i	O
for	O
m	O
m	O
to	O
k	O
to	O
j	O
x	O
end	O
for	O
end	O
for	O
g	O
m	O
g	O
end	O
while	O
care	O
must	O
be	O
taken	O
when	O
evaluating	O
the	O
samples	O
from	O
a	O
model	O
trained	O
with	O
sml	O
it	O
is	O
necessary	O
to	O
draw	O
the	O
samples	O
starting	O
from	O
a	O
fresh	O
markov	B
chain	I
chapter	O
confronting	O
the	O
partition	O
function	O
initialized	O
from	O
a	O
random	O
starting	O
point	O
after	O
the	O
model	O
is	O
done	O
training	O
the	O
samples	O
present	O
in	O
the	O
persistent	O
negative	O
chains	O
used	O
for	O
training	O
have	O
been	O
influenced	O
by	O
several	O
recent	O
versions	O
of	O
the	O
model	O
and	O
thus	O
can	O
make	O
the	O
model	O
appear	O
to	O
have	O
greater	O
capacity	O
than	O
it	O
actually	O
does	O
berglund	O
and	O
raiko	O
performed	O
experiments	O
to	O
examine	O
the	O
bias	O
and	O
variance	O
in	O
the	O
estimate	O
of	O
the	O
gradient	B
provided	O
by	O
cd	O
and	O
sml	O
cd	O
proves	O
to	O
have	O
lower	O
variance	O
than	O
the	O
estimator	O
based	O
on	O
exact	O
sampling	O
sml	O
has	O
higher	O
variance	O
the	O
cause	O
of	O
cd	O
s	O
low	O
variance	O
is	O
its	O
use	O
of	O
the	O
same	O
training	O
points	O
in	O
both	O
the	O
positive	O
and	O
negative	O
phase	O
if	O
the	O
negative	O
phase	O
is	O
initialized	O
from	O
different	O
training	O
points	O
the	O
variance	O
rises	O
above	O
that	O
of	O
the	O
estimator	O
based	O
on	O
exact	O
sampling	O
all	O
of	O
these	O
methods	O
based	O
on	O
using	O
mcmc	O
to	O
draw	O
samples	O
from	O
the	O
model	O
can	O
in	O
principle	O
be	O
used	O
with	O
almost	O
any	O
variant	O
of	O
mcmc	O
this	O
means	O
that	O
techniques	O
such	O
as	O
sml	O
can	O
be	O
improved	O
by	O
using	O
any	O
of	O
the	O
enhanced	O
mcmc	O
techniques	O
described	O
in	O
chapter	O
desjardins	O
et	O
al	O
cho	O
such	O
as	O
parallel	O
tempering	B
et	O
al	O
one	O
approach	O
to	O
accelerating	O
mixing	O
during	O
learning	O
relies	O
not	O
on	O
changing	O
the	O
monte	O
carlo	O
sampling	O
technology	O
but	O
rather	O
on	O
changing	O
the	O
parametrization	O
of	O
the	O
model	O
and	O
the	O
cost	O
function	O
fast	O
pcd	O
or	O
fpcd	B
tieleman	O
and	O
hinton	O
involves	O
replacing	O
the	O
parameters	O
of	O
a	O
traditional	O
model	O
with	O
an	O
expression	O
slow	O
fast	O
there	O
are	O
now	O
twice	O
as	O
many	O
parameters	O
as	O
before	O
and	O
they	O
are	O
added	O
together	O
element-wise	O
to	O
provide	O
the	O
parameters	O
used	O
by	O
the	O
original	O
model	O
definition	O
the	O
fast	O
copy	O
of	O
the	O
parameters	O
is	O
trained	O
with	O
a	O
much	O
larger	O
learning	B
rate	I
allowing	O
it	O
to	O
adapt	O
rapidly	O
in	O
response	O
to	O
the	O
negative	O
phase	O
of	O
learning	O
and	O
push	O
the	O
markov	B
chain	I
to	O
new	O
territory	O
this	O
forces	O
the	O
markov	B
chain	I
to	O
mix	O
rapidly	O
though	O
this	O
effect	O
only	O
occurs	O
during	O
learning	O
while	O
the	O
fast	O
weights	B
are	O
free	O
to	O
change	O
typically	O
one	O
also	O
applies	O
significant	O
weight	O
decay	O
to	O
the	O
fast	O
weights	B
encouraging	O
them	O
to	O
converge	O
to	O
small	O
values	O
after	O
only	O
transiently	O
taking	O
on	O
large	O
values	O
long	O
enough	O
to	O
encourage	O
the	O
markov	B
chain	I
to	O
change	O
modes	O
one	O
key	O
benefit	O
to	O
the	O
mcmc-based	O
methods	O
described	O
in	O
this	O
section	O
is	O
that	O
they	O
provide	O
an	O
estimate	O
of	O
the	O
gradient	B
of	O
log	O
z	O
and	O
thus	O
we	O
can	O
essentially	O
decompose	O
the	O
problem	O
into	O
the	O
log	O
p	O
contribution	O
and	O
the	O
log	O
z	O
contribution	O
we	O
can	O
then	O
use	O
any	O
other	O
method	O
to	O
tackle	O
log	O
px	O
and	O
just	O
add	O
our	O
negative	O
phase	O
gradient	B
onto	O
the	O
other	O
method	O
s	O
gradient	B
in	O
particular	O
this	O
means	O
that	O
our	O
positive	O
phase	O
can	O
make	O
use	O
of	O
methods	O
that	O
provide	O
only	O
a	O
lower	O
bound	B
on	O
p	O
most	O
of	O
the	O
other	O
methods	O
of	O
dealing	O
with	O
log	O
z	O
presented	O
in	O
this	O
chapter	O
are	O
chapter	O
confronting	O
the	O
partition	O
function	O
incompatible	O
with	O
bound-based	O
positive	O
phase	O
methods	O
pseudolikelihood	B
monte	O
carlo	O
approximations	O
to	O
the	O
partition	O
function	O
and	O
its	O
gradient	B
directly	O
confront	O
the	O
partition	O
function	O
other	O
approaches	O
sidestep	O
the	O
issue	O
by	O
training	O
the	O
model	O
without	O
computing	O
the	O
partition	O
function	O
most	O
of	O
these	O
approaches	O
are	O
based	O
on	O
the	O
observation	O
that	O
it	O
is	O
easy	O
to	O
compute	O
ratios	O
of	O
probabilities	O
in	O
an	O
undirected	O
probabilistic	O
model	O
this	O
is	O
because	O
the	O
partition	O
function	O
appears	O
in	O
both	O
the	O
numerator	O
and	O
the	O
denominator	O
of	O
the	O
ratio	O
and	O
cancels	O
out	O
p	O
p	O
p	O
p	O
z	O
z	O
p	O
p	O
the	O
pseudolikelihood	B
is	O
based	O
on	O
the	O
observation	O
that	O
conditional	O
probabilities	O
take	O
this	O
ratio-based	O
form	O
and	O
thus	O
can	O
be	O
computed	O
without	O
knowledge	O
of	O
the	O
partition	O
function	O
suppose	O
that	O
we	O
partition	O
x	O
into	O
a	O
b	O
and	O
c	O
where	O
a	O
contains	O
the	O
variables	O
we	O
want	O
to	O
find	O
the	O
conditional	O
distribution	O
over	O
b	O
contains	O
the	O
variables	O
we	O
want	O
to	O
condition	O
on	O
and	O
c	O
contains	O
the	O
variables	O
that	O
are	O
not	O
part	O
of	O
our	O
query	O
a	O
b	O
p	O
p	O
b	O
p	O
p	O
b	O
a	O
c	O
p	O
b	O
c	O
p	O
b	O
a	O
c	O
p	O
b	O
c	O
this	O
quantity	O
requires	O
marginalizing	O
out	O
a	O
which	O
can	O
be	O
a	O
very	O
efficient	O
operation	B
provided	O
that	O
a	O
and	O
c	O
do	O
not	O
contain	O
very	O
many	O
variables	O
in	O
the	O
extreme	O
case	O
a	O
can	O
be	O
a	O
single	O
variable	O
and	O
c	O
can	O
be	O
empty	O
making	O
this	O
operation	B
require	O
only	O
as	O
many	O
evaluations	O
of	O
p	O
as	O
there	O
are	O
values	O
of	O
a	O
single	O
random	B
variable	I
unfortunately	O
in	O
order	O
to	O
compute	O
the	O
log-likelihood	O
we	O
need	O
to	O
marginalize	O
out	O
large	O
sets	O
of	O
variables	O
if	O
there	O
are	O
n	O
variables	O
total	O
we	O
must	O
marginalize	O
a	O
set	O
of	O
size	O
by	O
the	O
chain	B
rule	I
of	I
probability	I
n	O
p	O
xn	O
log	O
log	O
p	O
x	O
p	O
log	O
in	O
this	O
case	O
we	O
have	O
made	O
a	O
maximally	O
small	O
but	O
c	O
can	O
be	O
as	O
large	O
as	O
what	O
if	O
we	O
simply	O
move	O
c	O
into	O
b	O
to	O
reduce	O
the	O
computational	O
cost	O
this	O
yields	O
the	O
pseudolikelihood	B
objective	B
function	I
based	O
on	O
predicting	O
the	O
value	O
of	O
feature	B
xi	O
given	O
all	O
of	O
the	O
other	O
features	O
x	O
i	O
besag	O
x	O
i	O
log	O
xi	O
n	O
chapter	O
confronting	O
the	O
partition	O
function	O
if	O
each	O
random	B
variable	I
has	O
k	O
different	O
values	O
this	O
requires	O
only	O
k	O
n	O
evaluations	O
of	O
p	O
to	O
compute	O
as	O
opposed	O
to	O
the	O
kn	O
evaluations	O
needed	O
to	O
compute	O
the	O
partition	O
function	O
this	O
may	O
look	O
like	O
an	O
unprincipled	O
hack	O
but	O
it	O
can	O
be	O
proven	O
that	O
estimation	O
by	O
maximizing	O
the	O
pseudolikelihood	B
is	O
asymptotically	O
consistent	O
mase	O
of	O
course	O
in	O
the	O
case	O
of	O
datasets	O
that	O
do	O
not	O
approach	O
the	O
large	O
sample	O
limit	O
pseudolikelihood	B
may	O
display	O
different	O
behavior	O
from	O
the	O
maximum	B
likelihood	I
estimator	O
it	O
is	O
possible	O
to	O
trade	O
computational	O
complexity	O
for	O
deviation	O
from	O
maximum	B
likelihood	I
behavior	O
by	O
using	O
the	O
generalized	O
pseudolikelihood	B
estimator	O
the	O
generalized	O
pseudolikelihood	B
estimator	O
uses	O
m	O
different	O
sets	O
and	O
ogata	O
i	O
m	O
of	O
indices	O
of	O
variables	O
that	O
appear	O
together	O
on	O
the	O
left	O
side	O
of	O
the	O
s	O
n	O
the	O
generalized	O
conditioning	O
bar	O
in	O
the	O
extreme	O
case	O
of	O
m	O
and	O
s	O
pseudolikelihood	B
recovers	O
the	O
log-likelihood	O
in	O
the	O
extreme	O
case	O
of	O
m	O
n	O
and	O
i	O
the	O
generalized	O
pseudolikelihood	B
recovers	O
the	O
pseudolikelihood	B
the	O
s	O
generalized	O
pseudolikelihood	B
objective	B
function	I
is	O
given	O
by	O
m	O
log	O
x	O
s	O
x	O
s	O
the	O
performance	O
of	O
pseudolikelihood-based	O
approaches	O
depends	O
largely	O
on	O
how	O
the	O
model	O
will	O
be	O
used	O
pseudolikelihood	B
tends	O
to	O
perform	O
poorly	O
on	O
tasks	O
that	O
require	O
a	O
good	O
model	O
of	O
the	O
full	O
joint	O
px	O
such	O
as	O
density	B
estimation	I
and	O
sampling	O
however	O
it	O
can	O
perform	O
better	O
than	O
maximum	B
likelihood	I
for	O
tasks	O
that	O
require	O
only	O
the	O
conditional	O
distributions	O
used	O
during	O
training	O
such	O
as	O
filling	O
in	O
small	O
amounts	O
of	O
missing	O
values	O
generalized	O
pseudolikelihood	B
techniques	O
are	O
especially	O
powerful	O
if	O
the	O
data	O
has	O
regular	O
structure	O
that	O
allows	O
the	O
s	O
index	O
sets	O
to	O
be	O
designed	O
to	O
capture	O
the	O
most	O
important	O
correlations	O
while	O
leaving	O
out	O
groups	O
of	O
variables	O
that	O
only	O
have	O
negligible	O
correlation	B
for	O
example	B
in	O
natural	O
images	O
pixels	O
that	O
are	O
widely	O
separated	O
in	O
space	O
also	O
have	O
weak	O
correlation	B
so	O
the	O
generalized	O
pseudolikelihood	B
can	O
be	O
applied	O
with	O
each	O
set	O
being	O
a	O
small	O
spatially	O
localized	O
window	O
s	O
one	O
weakness	O
of	O
the	O
pseudolikelihood	B
estimator	O
is	O
that	O
it	O
cannot	O
be	O
used	O
with	O
other	O
approximations	O
that	O
provide	O
only	O
a	O
lower	O
bound	B
on	O
px	O
such	O
as	O
variational	O
p	O
appears	O
in	O
the	O
inference	O
which	O
will	O
be	O
covered	O
in	O
chapter	O
denominator	O
a	O
lower	O
bound	B
on	O
the	O
denominator	O
provides	O
only	O
an	O
upper	O
bound	B
on	O
the	O
expression	O
as	O
a	O
whole	O
and	O
there	O
is	O
no	O
benefit	O
to	O
maximizing	O
an	O
upper	O
bound	B
this	O
makes	O
it	O
difficult	O
to	O
apply	O
pseudolikelihood	B
approaches	O
to	O
deep	O
models	O
such	O
as	O
deep	O
boltzmann	O
machines	O
since	O
variational	O
methods	O
are	O
one	O
of	O
the	O
dominant	O
approaches	O
to	O
approximately	O
marginalizing	O
out	O
the	O
many	O
layers	O
of	O
hidden	O
variables	O
this	O
is	O
because	O
chapter	O
confronting	O
the	O
partition	O
function	O
that	O
interact	O
with	O
each	O
other	O
however	O
pseudolikelihood	B
is	O
still	O
useful	O
for	O
deep	O
learning	O
because	O
it	O
can	O
be	O
used	O
to	O
train	O
single	O
layer	O
models	O
or	O
deep	O
models	O
using	O
approximate	B
inference	I
methods	O
that	O
are	O
not	O
based	O
on	O
lower	O
bounds	O
pseudolikelihood	B
has	O
a	O
much	O
greater	O
cost	O
per	O
gradient	B
step	O
than	O
sml	O
due	O
to	O
its	O
explicit	O
computation	O
of	O
all	O
of	O
the	O
conditionals	O
however	O
generalized	O
pseudolikelihood	B
and	O
similar	O
criteria	O
can	O
still	O
perform	O
well	O
if	O
only	O
one	O
randomly	O
selected	O
conditional	O
is	O
computed	O
per	O
example	B
thereby	O
bringing	O
the	O
computational	O
cost	O
down	O
to	O
match	O
that	O
of	O
sml	O
et	O
al	O
though	O
the	O
pseudolikelihood	B
estimator	O
does	O
not	O
explicitly	O
minimize	O
log	O
z	O
it	O
can	O
still	O
be	O
thought	O
of	O
as	O
having	O
something	O
resembling	O
a	O
negative	O
phase	O
the	O
denominators	O
of	O
each	O
conditional	O
distribution	O
result	O
in	O
the	O
learning	O
algorithm	O
suppressing	O
the	O
probability	O
of	O
all	O
states	O
that	O
have	O
only	O
one	O
variable	O
differing	O
from	O
a	O
training	O
example	B
see	O
marlin	O
and	O
de	O
freitas	O
for	O
a	O
theoretical	O
analysis	O
of	O
the	O
asymptotic	O
efficiency	O
of	O
pseudolikelihood	B
score	O
matching	O
and	O
ratio	B
matching	I
hyv	O
rinen	O
score	O
matching	O
provides	O
another	O
consistent	O
means	O
of	O
training	O
a	O
model	O
without	O
estimating	O
z	O
or	O
its	O
derivatives	O
the	O
name	O
score	O
matching	O
comes	O
from	O
terminology	O
in	O
which	O
the	O
derivatives	O
of	O
a	O
log	O
density	O
with	O
respect	O
to	O
its	O
x	O
log	O
px	O
are	O
called	O
its	O
score	O
the	O
strategy	O
used	O
by	O
score	O
matching	O
argument	O
is	O
to	O
minimize	O
the	O
expected	O
squared	O
difference	O
between	O
the	O
derivatives	O
of	O
the	O
model	O
s	O
log	O
density	O
with	O
respect	O
to	O
the	O
input	O
and	O
the	O
derivatives	O
of	O
the	O
data	O
s	O
log	O
density	O
with	O
respect	O
to	O
the	O
input	O
l	O
j	O
x	O
log	O
pmodel	O
l	O
x	O
log	O
pdata	O
min	O
j	O
this	O
objective	B
function	I
avoids	O
the	O
difficulties	O
associated	O
with	O
differentiating	O
the	O
partition	O
function	O
z	O
because	O
z	O
is	O
not	O
a	O
function	O
of	O
x	O
and	O
therefore	O
xz	O
initially	O
score	O
matching	O
appears	O
to	O
have	O
a	O
new	O
difficulty	O
computing	O
the	O
score	O
of	O
the	O
data	O
distribution	O
requires	O
knowledge	O
of	O
the	O
true	O
distribution	O
generating	O
the	O
training	O
data	O
pdata	O
fortunately	O
minimizing	O
the	O
expected	O
value	O
of	O
is	O
l	O
chapter	O
confronting	O
the	O
partition	O
function	O
log	O
pmodel	O
equivalent	O
to	O
minimizing	O
the	O
expected	O
value	O
of	O
l	O
n	O
j	O
log	O
pmodel	O
x	O
xj	O
where	O
n	O
is	O
the	O
dimensionality	O
of	O
x	O
because	O
score	O
matching	O
requires	O
taking	O
derivatives	O
with	O
respect	O
to	O
x	O
it	O
is	O
not	O
applicable	O
to	O
models	O
of	O
discrete	O
data	O
however	O
the	O
latent	O
variables	O
in	O
the	O
model	O
may	O
be	O
discrete	O
like	O
the	O
pseudolikelihood	B
score	O
matching	O
only	O
works	O
when	O
we	O
are	O
able	O
to	O
evaluate	O
log	O
px	O
and	O
its	O
derivatives	O
directly	O
it	O
is	O
not	O
compatible	O
with	O
methods	O
that	O
only	O
provide	O
a	O
lower	O
bound	B
on	O
log	O
px	O
because	O
score	O
matching	O
requires	O
the	O
derivatives	O
and	O
second	O
derivatives	O
of	O
log	O
px	O
and	O
a	O
lower	O
bound	B
conveys	O
no	O
information	O
about	O
its	O
derivatives	O
this	O
means	O
that	O
score	O
matching	O
cannot	O
be	O
applied	O
to	O
estimating	O
models	O
with	O
complicated	O
interactions	O
between	O
the	O
hidden	O
units	O
such	O
as	O
sparse	O
coding	O
models	O
or	O
deep	O
boltzmann	O
machines	O
while	O
score	O
matching	O
can	O
be	O
used	O
to	O
pretrain	O
the	O
first	O
hidden	B
layer	I
of	O
a	O
larger	O
model	O
it	O
has	O
not	O
been	O
applied	O
as	O
a	O
pretraining	O
strategy	O
for	O
the	O
deeper	O
layers	O
of	O
a	O
larger	O
model	O
this	O
is	O
probably	O
because	O
the	O
hidden	O
layers	O
of	O
such	O
models	O
usually	O
contain	O
some	O
discrete	O
variables	O
while	O
score	O
matching	O
does	O
not	O
explicitly	O
have	O
a	O
negative	O
phase	O
it	O
can	O
be	O
viewed	O
as	O
a	O
version	O
of	O
contrastive	O
divergence	O
using	O
a	O
specific	O
kind	O
of	O
markov	B
chain	I
the	O
markov	B
chain	I
in	O
this	O
case	O
is	O
not	O
gibbs	O
sampling	O
but	O
hyv	O
rinen	O
rather	O
a	O
different	O
approach	O
that	O
makes	O
local	O
moves	O
guided	O
by	O
the	O
gradient	B
score	O
matching	O
is	O
equivalent	O
to	O
cd	O
with	O
this	O
type	O
of	O
markov	B
chain	I
when	O
the	O
size	O
of	O
the	O
local	O
moves	O
approaches	O
zero	O
lyu	O
generalized	O
score	O
matching	O
to	O
the	O
discrete	O
case	O
made	O
an	O
error	O
marlin	O
et	O
al	O
marlin	O
et	O
al	O
generalized	O
score	O
matching	O
does	O
not	O
work	O
in	O
high	O
in	O
their	O
derivation	O
that	O
was	O
corrected	O
by	O
dimensional	O
discrete	O
spaces	O
where	O
the	O
observed	O
probability	O
of	O
many	O
events	O
is	O
found	O
that	O
a	O
more	O
successful	O
approach	O
to	O
extending	O
the	O
basic	O
ideas	O
of	O
score	O
matching	O
to	O
discrete	O
data	O
is	O
ratio	B
matching	I
ratio	B
matching	I
applies	O
specifically	O
to	O
binary	O
data	O
ratio	B
matching	I
consists	O
of	O
minimizing	O
the	O
average	O
over	O
examples	O
of	O
the	O
following	O
objective	B
function	I
hyv	O
rinen	O
l	O
x	O
n	O
pmodel	O
pmodel	O
f	O
x	O
chapter	O
confronting	O
the	O
partition	O
function	O
f	O
x	O
j	O
returns	O
with	O
the	O
bit	O
at	O
position	O
flipped	O
ratio	B
matching	I
avoids	O
where	O
the	O
partition	O
function	O
using	O
the	O
same	O
trick	B
as	O
the	O
pseudolikelihood	B
estimator	O
in	O
a	O
ratio	O
of	O
two	O
probabilities	O
the	O
partition	O
function	O
cancels	O
out	O
marlin	O
et	O
al	O
found	O
that	O
ratio	B
matching	I
outperforms	O
sml	O
pseudolikelihood	B
and	O
gsm	O
in	O
terms	O
of	O
the	O
ability	O
of	O
models	O
trained	O
with	O
ratio	B
matching	I
to	O
denoise	O
test	B
set	I
images	O
j	O
like	O
the	O
pseudolikelihood	B
estimator	O
ratio	B
matching	I
requires	O
n	O
evaluations	O
of	O
p	O
per	O
data	O
point	O
making	O
its	O
computational	O
cost	O
per	O
update	O
roughly	O
n	O
times	O
higher	O
than	O
that	O
of	O
sml	O
as	O
with	O
the	O
pseudolikelihood	B
estimator	O
ratio	B
matching	I
can	O
be	O
thought	O
of	O
as	O
pushing	O
down	O
on	O
all	O
fantasy	O
states	O
that	O
have	O
only	O
one	O
variable	O
different	O
from	O
a	O
training	O
example	B
since	O
ratio	B
matching	I
applies	O
specifically	O
to	O
binary	O
data	O
this	O
means	O
that	O
it	O
acts	O
on	O
all	O
fantasy	O
states	O
within	O
hamming	O
distance	O
of	O
the	O
data	O
ratio	B
matching	I
can	O
also	O
be	O
useful	O
as	O
the	O
basis	O
for	O
dealing	O
with	O
high-dimensional	O
sparse	O
data	O
such	O
as	O
word	O
count	O
vectors	O
this	O
kind	O
of	O
data	O
poses	O
a	O
challenge	B
for	O
mcmc-based	O
methods	O
because	O
the	O
data	O
is	O
extremely	O
expensive	O
to	O
represent	O
in	O
dense	O
format	O
yet	O
the	O
mcmc	O
sampler	O
does	O
not	O
yield	O
sparse	O
values	O
until	O
the	O
model	O
has	O
learned	O
to	O
represent	O
the	O
sparsity	O
in	O
the	O
data	O
distribution	O
dauphin	O
and	O
bengio	O
overcame	O
this	O
issue	O
by	O
designing	O
an	O
unbiased	B
stochastic	O
approximation	O
to	O
ratio	B
matching	I
the	O
approximation	O
evaluates	O
only	O
a	O
randomly	O
selected	O
subset	O
of	O
the	O
terms	O
of	O
the	O
objective	O
and	O
does	O
not	O
require	O
the	O
model	O
to	O
generate	O
complete	O
fantasy	O
samples	O
see	O
marlin	O
and	O
de	O
freitas	O
for	O
a	O
theoretical	O
analysis	O
of	O
the	O
asymptotic	O
efficiency	O
of	O
ratio	B
matching	I
denoising	B
score	I
matching	I
in	O
some	O
cases	O
we	O
may	O
wish	O
to	O
regularize	O
score	O
matching	O
by	O
fitting	O
a	O
distribution	O
y	O
q	O
x	O
y	O
rather	O
than	O
the	O
true	O
pdata	O
the	O
distribution	O
qx	O
y	O
one	O
that	O
forms	O
by	O
adding	O
a	O
small	O
amount	O
of	O
noise	O
to	O
psmoothed	O
p	O
data	O
x	O
y	O
dy	O
is	O
a	O
corruption	O
process	O
usually	O
denoising	B
score	I
matching	I
is	O
especially	O
useful	O
because	O
in	O
practice	O
we	O
usually	O
do	O
not	O
have	O
access	O
to	O
the	O
true	O
pdata	O
but	O
rather	O
only	O
an	O
empirical	B
distribution	I
defined	O
by	O
samples	O
from	O
it	O
any	O
consistent	O
estimator	O
will	O
given	O
enough	O
capacity	O
make	O
pmodel	O
into	O
a	O
set	O
of	O
dirac	O
distributions	O
centered	O
on	O
the	O
training	O
points	O
smoothing	O
by	O
q	O
helps	O
to	O
reduce	O
this	O
problem	O
at	O
the	O
loss	O
of	O
the	O
asymptotic	O
consistency	O
property	O
chapter	O
confronting	O
the	O
partition	O
function	O
introduced	O
a	O
procedure	O
for	O
described	O
in	O
section	O
performing	O
regularized	O
score	O
matching	O
with	O
the	O
smoothing	O
distribution	O
q	O
being	O
normally	O
distributed	O
noise	O
kingma	O
and	O
lecun	O
recall	B
from	O
section	O
that	O
several	O
autoencoder	O
training	O
algorithms	O
are	O
equivalent	O
to	O
score	O
matching	O
or	O
denoising	B
score	I
matching	I
these	O
autoencoder	O
training	O
algorithms	O
are	O
therefore	O
a	O
way	O
of	O
overcoming	O
the	O
partition	O
function	O
problem	O
noise-contrastive	B
estimation	I
most	O
techniques	O
for	O
estimating	O
models	O
with	O
intractable	O
partition	O
functions	O
do	O
not	O
provide	O
an	O
estimate	O
of	O
the	O
partition	O
function	O
sml	O
and	O
cd	O
estimate	O
only	O
the	O
gradient	B
of	O
the	O
log	O
partition	O
function	O
rather	O
than	O
the	O
partition	O
function	O
itself	O
score	O
matching	O
and	O
pseudolikelihood	B
avoid	O
computing	O
quantities	O
related	O
to	O
the	O
partition	O
function	O
altogether	O
noise-contrastive	B
estimation	I
and	O
hyvarinen	O
takes	O
a	O
different	O
strategy	O
in	O
this	O
approach	O
the	O
probability	B
distribution	I
estimated	O
by	O
the	O
model	O
is	O
represented	O
explicitly	O
as	O
log	O
pmodel	O
log	O
x	O
pmodel	O
x	O
c	O
log	O
z	O
rather	O
than	O
where	O
c	O
is	O
explicitly	O
introduced	O
as	O
an	O
approximation	O
of	O
estimating	O
only	O
the	O
noise	O
contrastive	O
estimation	O
procedure	O
treats	O
c	O
as	O
just	O
another	O
parameter	O
and	O
estimates	O
and	O
c	O
simultaneously	O
using	O
the	O
same	O
algorithm	O
for	O
both	O
the	O
resulting	O
log	O
p	O
modelx	O
thus	O
may	O
not	O
correspond	O
exactly	O
to	O
a	O
valid	O
probability	B
distribution	I
but	O
will	O
become	O
closer	O
and	O
closer	O
to	O
being	O
valid	O
as	O
the	O
estimate	O
of	O
improves	O
c	O
such	O
an	O
approach	O
would	O
not	O
be	O
possible	O
using	O
maximum	B
likelihood	I
as	O
the	O
criterion	O
for	O
the	O
estimator	O
the	O
maximum	B
likelihood	I
criterion	O
would	O
choose	O
to	O
set	O
to	O
create	O
a	O
valid	O
probability	B
distribution	I
c	O
arbitrarily	O
high	O
rather	O
than	O
setting	O
c	O
nce	O
works	O
by	O
reducing	O
the	O
unsupervised	O
learning	O
problem	O
of	O
estimating	O
px	O
to	O
that	O
of	O
learning	O
a	O
probabilistic	O
binary	O
classifier	O
in	O
which	O
one	O
of	O
the	O
categories	O
corresponds	O
to	O
the	O
data	O
generated	O
by	O
the	O
model	O
this	O
supervised	B
learning	I
problem	O
is	O
constructed	O
in	O
such	O
a	O
way	O
that	O
maximum	B
likelihood	I
estimation	O
in	O
this	O
supervised	O
is	O
also	O
applicable	O
to	O
problems	O
with	O
a	O
tractable	O
partition	O
function	O
where	O
there	O
is	O
no	O
need	O
to	O
introduce	O
the	O
extra	O
parameter	O
c	O
however	O
it	O
has	O
generated	O
the	O
most	O
interest	O
as	O
a	O
means	O
of	O
estimating	O
models	O
with	O
difficult	O
partition	O
functions	O
chapter	O
confronting	O
the	O
partition	O
function	O
learning	O
problem	O
defines	O
an	O
asymptotically	O
consistent	O
estimator	O
of	O
the	O
original	O
problem	O
specifically	O
we	O
introduce	O
a	O
second	O
distribution	O
the	O
noise	O
distribution	O
pnoisex	O
the	O
noise	O
distribution	O
should	O
be	O
tractable	O
to	O
evaluate	O
and	O
to	O
sample	O
from	O
we	O
can	O
now	O
construct	O
a	O
model	O
over	O
both	O
x	O
and	O
a	O
new	O
binary	O
class	O
variable	O
y	O
in	O
the	O
new	O
joint	O
model	O
we	O
specify	O
that	O
pjoint	O
y	O
pjoint	O
x	O
y	O
pmodel	O
and	O
pjoint	O
x	O
y	O
pnoise	O
in	O
other	O
words	O
y	O
is	O
a	O
switch	O
variable	O
that	O
determines	O
whether	O
we	O
will	O
generate	O
x	O
from	O
the	O
model	O
or	O
from	O
the	O
noise	O
distribution	O
we	O
can	O
construct	O
a	O
similar	O
joint	O
model	O
of	O
training	O
data	O
in	O
this	O
case	O
the	O
switch	O
variable	O
determines	O
whether	O
we	O
draw	O
x	O
from	O
the	O
data	O
or	O
from	O
the	O
noise	O
distribution	O
formally	O
ptrainy	O
y	O
p	O
data	O
x	O
and	O
ptrain	O
x	O
ptrainx	O
pnoise	O
y	O
we	O
can	O
now	O
just	O
use	O
standard	O
maximum	B
likelihood	I
learning	O
on	O
the	O
supervised	B
learning	I
problem	O
of	O
fitting	O
pjoint	O
to	O
ptrain	O
py	O
c	O
arg	O
max	O
ex	O
log	O
pjoint	O
y	O
train	O
x	O
the	O
distribution	O
pjoint	O
is	O
essentially	O
a	O
logistic	O
regression	B
model	O
applied	O
to	O
the	O
difference	O
in	O
log	O
probabilities	O
of	O
the	O
model	O
and	O
the	O
noise	O
distribution	O
pjoint	O
y	O
x	O
pmodel	O
p	O
model	O
p	O
noise	O
pnoise	O
pmodel	O
exp	O
log	O
log	O
pnoise	O
pmodel	O
pnoise	O
pmodel	O
pmodel	O
x	O
log	O
p	O
noise	O
chapter	O
confronting	O
the	O
partition	O
function	O
nce	O
is	O
thus	O
simple	O
to	O
apply	O
so	O
long	O
as	O
log	O
p	O
model	O
is	O
easy	O
to	O
back-propagate	O
through	O
and	O
as	O
specified	O
above	O
pnoise	O
is	O
easy	O
to	O
evaluate	O
order	O
to	O
evaluate	O
pjoint	O
and	O
sample	O
from	O
order	O
to	O
generate	O
the	O
training	O
data	O
nce	O
is	O
most	O
successful	O
when	O
applied	O
to	O
problems	O
with	O
few	O
random	O
variables	O
but	O
can	O
work	O
well	O
even	O
if	O
those	O
random	O
variables	O
can	O
take	O
on	O
a	O
high	O
number	O
of	O
values	O
for	O
example	B
it	O
has	O
been	O
successfully	O
applied	O
to	O
modeling	O
the	O
conditional	O
distribution	O
over	O
a	O
word	O
given	O
the	O
context	O
of	O
the	O
word	O
and	O
kavukcuoglu	O
though	O
the	O
word	O
may	O
be	O
drawn	O
from	O
a	O
large	O
vocabulary	O
there	O
is	O
only	O
one	O
word	O
when	O
nce	O
is	O
applied	O
to	O
problems	O
with	O
many	O
random	O
variables	O
it	O
becomes	O
less	O
efficient	O
the	O
logistic	O
regression	B
classifier	O
can	O
reject	O
a	O
noise	O
sample	O
by	O
identifying	O
any	O
one	O
variable	O
whose	O
value	O
is	O
unlikely	O
this	O
means	O
that	O
learning	O
slows	O
down	O
greatly	O
after	O
pmodel	O
has	O
learned	O
the	O
basic	O
marginal	O
statistics	O
imagine	O
learning	O
a	O
model	O
of	O
images	O
of	O
faces	O
using	O
unstructured	O
gaussian	O
noise	O
as	O
pnoise	O
if	O
pmodel	O
learns	O
about	O
eyes	O
it	O
can	O
reject	O
almost	O
all	O
unstructured	O
noise	O
samples	O
without	O
having	O
learned	O
anything	O
about	O
other	O
facial	O
features	O
such	O
as	O
mouths	O
the	O
constraint	O
that	O
pnoise	O
must	O
be	O
easy	O
to	O
evaluate	O
and	O
easy	O
to	O
sample	O
from	O
can	O
be	O
overly	O
restrictive	O
when	O
pnoise	O
is	O
simple	O
most	O
samples	O
are	O
likely	O
to	O
be	O
too	O
obviously	O
distinct	O
from	O
the	O
data	O
to	O
force	O
pmodel	O
to	O
improve	O
noticeably	O
like	O
score	O
matching	O
and	O
pseudolikelihood	B
nce	O
does	O
not	O
work	O
if	O
only	O
a	O
lower	O
bound	B
on	O
p	O
is	O
available	O
such	O
a	O
lower	O
bound	B
could	O
be	O
used	O
to	O
construct	O
a	O
lower	O
x	O
but	O
it	O
can	O
only	O
be	O
used	O
to	O
construct	O
an	O
upper	O
bound	B
on	O
bound	B
on	O
pjointy	O
x	O
which	O
appears	O
in	O
half	O
the	O
terms	O
of	O
the	O
nce	O
objective	O
likewise	O
pjointy	O
a	O
lower	O
bound	B
on	O
p	O
noise	O
is	O
not	O
useful	O
because	O
it	O
provides	O
only	O
an	O
upper	O
bound	B
on	O
pjoint	O
x	O
y	O
goodfellow	O
when	O
the	O
model	O
distribution	O
is	O
copied	O
to	O
define	O
a	O
new	O
noise	O
distribution	O
before	O
each	O
gradient	B
step	O
nce	O
defines	O
a	O
procedure	O
called	O
self-contrastive	O
estimation	O
whose	O
expected	O
gradient	B
is	O
equivalent	O
to	O
the	O
expected	O
gradient	B
of	O
maximum	B
likelihood	I
the	O
special	O
case	O
of	O
nce	O
where	O
the	O
noise	O
samples	O
are	O
those	O
generated	O
by	O
the	O
model	O
suggests	O
that	O
maximum	B
likelihood	I
can	O
be	O
interpreted	O
as	O
a	O
procedure	O
that	O
forces	O
a	O
model	O
to	O
constantly	O
learn	O
to	O
distinguish	O
reality	O
from	O
its	O
own	O
evolving	O
beliefs	O
while	O
noise	O
contrastive	O
estimation	O
achieves	O
some	O
reduced	O
computational	O
cost	O
by	O
only	O
forcing	O
the	O
model	O
to	O
distinguish	O
reality	O
from	O
a	O
fixed	O
baseline	O
noise	O
model	O
using	O
the	O
supervised	O
task	O
of	O
classifying	O
between	O
training	O
samples	O
and	O
generated	O
samples	O
the	O
model	O
energy	B
function	I
used	O
in	O
defining	O
the	O
classifier	O
to	O
provide	O
a	O
gradient	B
on	O
the	O
model	O
was	O
introduced	O
earlier	O
in	O
various	O
forms	O
et	O
al	O
bengio	O
chapter	O
confronting	O
the	O
partition	O
function	O
noise	O
contrastive	O
estimation	O
is	O
based	O
on	O
the	O
idea	O
that	O
a	O
good	O
generative	O
model	O
should	O
be	O
able	O
to	O
distinguish	O
data	O
from	O
noise	O
a	O
closely	O
related	O
idea	O
is	O
that	O
a	O
good	O
generative	O
model	O
should	O
be	O
able	O
to	O
generate	O
samples	O
that	O
no	O
classifier	O
can	O
distinguish	O
from	O
data	O
this	O
idea	O
yields	O
generative	O
adversarial	O
networks	O
estimating	O
the	O
partition	O
function	O
while	O
much	O
of	O
this	O
chapter	O
is	O
dedicated	O
to	O
describing	O
methods	O
that	O
avoid	O
needing	O
to	O
compute	O
the	O
intractable	O
partition	O
function	O
z	O
associated	O
with	O
an	O
undirected	O
graphical	O
model	O
in	O
this	O
section	O
we	O
discuss	O
several	O
methods	O
for	O
directly	O
estimating	O
the	O
partition	O
function	O
estimating	O
the	O
partition	O
function	O
can	O
be	O
important	O
because	O
we	O
require	O
it	O
if	O
we	O
wish	O
to	O
compute	O
the	O
normalized	O
likelihood	O
of	O
data	O
this	O
is	O
often	O
important	O
in	O
evaluating	O
the	O
model	O
monitoring	O
training	O
performance	O
and	O
comparing	O
models	O
to	O
each	O
other	O
m	O
for	O
example	B
imagine	O
we	O
have	O
two	O
models	O
model	O
a	O
defining	O
a	O
probability	B
distribution	I
pax	O
a	O
b	O
defining	O
a	O
probability	O
za	O
distribution	O
pbx	O
b	O
pbx	O
b	O
a	O
common	O
way	O
to	O
compare	O
the	O
models	O
zb	O
is	O
to	O
evaluate	O
and	O
compare	O
the	O
likelihood	O
that	O
both	O
models	O
assign	O
to	O
an	O
i	O
i	O
d	O
test	O
dataset	B
suppose	O
the	O
test	B
set	I
consists	O
of	O
m	O
examples	O
if	O
x	O
pax	O
a	O
and	O
model	O
m	O
i	O
pax	O
a	O
i	O
pbx	O
b	O
or	O
equivalently	O
if	O
a	O
is	O
a	O
better	O
model	O
than	O
then	O
we	O
say	O
that	O
b	O
at	O
least	O
it	O
is	O
a	O
better	O
model	O
of	O
the	O
test	B
set	I
in	O
the	O
sense	O
that	O
it	O
has	O
a	O
better	O
test	O
log-likelihood	O
unfortunately	O
testing	O
whether	O
this	O
condition	O
holds	O
requires	O
knowledge	O
of	O
the	O
partition	O
function	O
unfortunately	O
equation	O
seems	O
to	O
require	O
evaluating	O
the	O
log	O
probability	O
that	O
the	O
model	O
assigns	O
to	O
each	O
point	O
which	O
in	O
turn	O
requires	O
evaluating	O
the	O
partition	O
function	O
we	O
can	O
simplify	O
the	O
situation	O
slightly	O
by	O
re-arranging	O
equation	O
into	O
a	O
form	O
where	O
we	O
need	O
to	O
know	O
only	O
the	O
ratio	O
of	O
the	O
two	O
model	O
s	O
partition	O
functions	O
log	O
pax	O
a	O
log	O
pbx	O
b	O
i	O
i	O
i	O
log	O
pax	O
a	O
pbx	O
b	O
m	O
log	O
z	O
a	O
z	O
b	O
log	O
pa	O
a	O
i	O
m	O
log	O
pb	O
b	O
m	O
i	O
chapter	O
confronting	O
the	O
partition	O
function	O
m	O
m	O
a	O
is	O
a	O
better	O
model	O
than	O
b	O
without	O
knowing	O
we	O
can	O
thus	O
determine	O
whether	O
the	O
partition	O
function	O
of	O
either	O
model	O
but	O
only	O
their	O
ratio	O
as	O
we	O
will	O
see	O
shortly	O
we	O
can	O
estimate	O
this	O
ratio	O
using	O
importance	O
sampling	O
provided	O
that	O
the	O
two	O
models	O
are	O
similar	O
m	O
if	O
however	O
we	O
wanted	O
to	O
compute	O
the	O
actual	O
probability	O
of	O
the	O
test	O
data	O
under	O
b	O
we	O
would	O
need	O
to	O
compute	O
the	O
actual	O
value	O
of	O
the	O
partition	O
either	O
functions	O
that	O
said	O
if	O
we	O
knew	O
the	O
ratio	O
of	O
two	O
partition	O
functions	O
r	O
z	O
b	O
z	O
a	O
and	O
we	O
knew	O
the	O
actual	O
value	O
of	O
just	O
one	O
of	O
the	O
two	O
say	O
z	O
a	O
we	O
could	O
compute	O
the	O
value	O
of	O
the	O
other	O
a	O
or	O
m	O
z	O
b	O
a	O
z	O
b	O
z	O
a	O
z	O
a	O
a	O
simple	O
way	O
to	O
estimate	O
the	O
partition	O
function	O
is	O
to	O
use	O
a	O
monte	O
carlo	O
method	O
such	O
as	O
simple	O
importance	O
sampling	O
we	O
present	O
the	O
approach	O
in	O
terms	O
of	O
continuous	O
variables	O
using	O
integrals	O
but	O
it	O
can	O
be	O
readily	O
applied	O
to	O
discrete	O
variables	O
by	O
replacing	O
the	O
integrals	O
with	O
summation	O
we	O
use	O
a	O
proposal	O
distribution	O
which	O
supports	O
tractable	O
sampling	O
and	O
tractable	O
evaluation	O
of	O
both	O
the	O
partition	O
function	O
and	O
the	O
unnormalized	O
distribution	O
p	O
dx	O
dx	O
k	O
k	O
dx	O
x	O
s	O
t	O
in	O
the	O
last	O
line	O
we	O
make	O
a	O
monte	O
carlo	O
estimator	O
of	O
the	O
integral	O
using	O
samples	O
drawn	O
from	O
and	O
then	O
weight	O
each	O
sample	O
with	O
the	O
ratio	O
of	O
the	O
unnormalized	O
and	O
the	O
proposal	O
we	O
see	O
also	O
that	O
this	O
approach	O
allows	O
us	O
to	O
estimate	O
the	O
ratio	O
between	O
the	O
partition	O
functions	O
as	O
k	O
k	O
x	O
s	O
t	O
p	O
this	O
value	O
can	O
then	O
be	O
used	O
directly	O
to	O
compare	O
two	O
models	O
as	O
described	O
in	O
equation	O
chapter	O
confronting	O
the	O
partition	O
function	O
if	O
the	O
distribution	O
is	O
close	O
to	O
equation	O
can	O
be	O
an	O
effective	O
way	O
of	O
estimating	O
the	O
partition	O
function	O
unfortunately	O
most	O
of	O
the	O
time	O
is	O
both	O
complicated	O
multimodal	O
and	O
defined	O
over	O
a	O
high	O
dimensional	O
space	O
it	O
is	O
difficult	O
to	O
find	O
a	O
tractable	O
that	O
is	O
simple	O
enough	O
to	O
evaluate	O
while	O
still	O
being	O
close	O
enough	O
to	O
to	O
result	O
in	O
a	O
high	O
quality	O
approximation	O
if	O
and	O
are	O
not	O
close	O
most	O
samples	O
from	O
will	O
have	O
low	O
probability	O
under	O
and	O
therefore	O
make	O
negligible	O
contribution	O
to	O
the	O
sum	O
in	O
equation	O
having	O
few	O
samples	O
with	O
significant	O
weights	B
in	O
this	O
sum	O
will	O
result	O
in	O
an	O
estimator	O
that	O
is	O
of	O
poor	O
quality	O
due	O
to	O
high	O
variance	O
this	O
can	O
be	O
understood	O
quantitatively	O
through	O
an	O
estimate	O
of	O
the	O
variance	O
of	O
our	O
estimate	O
var	O
k	O
this	O
quantity	O
is	O
largest	O
when	O
there	O
is	O
significant	O
deviation	O
in	O
the	O
values	O
of	O
the	O
importance	O
weights	B
we	O
now	O
turn	O
to	O
two	O
related	O
strategies	O
developed	O
to	O
cope	O
with	O
the	O
challenging	O
task	O
of	O
estimating	O
partition	O
functions	O
for	O
complex	O
distributions	O
over	O
highdimensional	O
spaces	O
annealed	O
importance	O
sampling	O
and	O
bridge	O
sampling	O
both	O
start	O
with	O
the	O
simple	O
importance	O
sampling	O
strategy	O
introduced	O
above	O
and	O
both	O
attempt	O
to	O
overcome	O
the	O
problem	O
of	O
the	O
proposal	O
being	O
too	O
far	O
from	O
p	O
by	O
introducing	O
intermediate	O
distributions	O
that	O
attempt	O
to	O
and	O
bridge	O
the	O
gap	O
between	O
annealed	O
importance	O
sampling	O
in	O
situations	O
where	O
d	O
is	O
large	O
where	O
there	O
is	O
little	O
overlap	O
between	O
and	O
a	O
strategy	O
called	O
annealed	O
importance	O
sampling	O
attempts	O
to	O
bridge	O
the	O
gap	O
by	O
introducing	O
intermediate	O
distributions	O
jarzynski	O
neal	O
consider	O
a	O
sequence	O
of	O
distributions	O
p	O
n	O
n	O
so	O
that	O
the	O
first	O
and	O
last	O
distributions	O
in	O
the	O
sequence	O
are	O
and	O
respectively	O
with	O
p	O
n	O
this	O
approach	O
allows	O
us	O
to	O
estimate	O
the	O
partition	O
function	O
of	O
a	O
multimodal	O
distribution	O
defined	O
over	O
a	O
high-dimensional	O
space	O
as	O
the	O
distribution	O
defined	O
by	O
a	O
trained	O
rbm	O
we	O
begin	O
with	O
a	O
simpler	O
model	O
with	O
a	O
known	O
partition	O
function	O
as	O
an	O
rbm	O
with	O
zeroes	O
for	O
weights	B
and	O
estimate	O
the	O
ratio	O
between	O
the	O
two	O
model	O
s	O
partition	O
functions	O
the	O
estimate	O
of	O
this	O
ratio	O
is	O
based	O
on	O
the	O
estimate	O
of	O
the	O
ratios	O
of	O
a	O
sequence	O
of	O
many	O
similar	O
distributions	O
such	O
as	O
the	O
sequence	O
of	O
rbms	O
with	O
weights	B
interpolating	O
between	O
zero	O
and	O
the	O
learned	O
weights	B
chapter	O
confronting	O
the	O
partition	O
function	O
we	O
can	O
now	O
write	O
the	O
ratio	O
as	O
z	O
n	O
z	O
n	O
z	O
n	O
z	O
n	O
z	O
n	O
z	O
z	O
n	O
z	O
z	O
z	O
z	O
z	O
z	O
j	O
are	O
sufficiently	O
n	O
provided	O
the	O
distributions	O
p	O
j	O
j	O
close	O
we	O
can	O
reliably	O
estimate	O
each	O
of	O
the	O
factors	O
z	O
z	O
j	O
sampling	O
and	O
then	O
use	O
these	O
to	O
obtain	O
an	O
estimate	O
of	O
and	O
p	O
j	O
for	O
all	O
using	O
simple	O
importance	O
p	O
n	O
where	O
do	O
these	O
intermediate	O
distributions	O
come	O
from	O
just	O
as	O
the	O
original	O
proposal	O
distribution	O
is	O
a	O
design	O
choice	O
so	O
is	O
the	O
sequence	O
of	O
distributions	O
p	O
that	O
is	O
it	O
can	O
be	O
specifically	O
constructed	O
to	O
suit	O
the	O
problem	O
domain	O
one	O
general-purpose	O
and	O
popular	O
choice	O
for	O
the	O
intermediate	O
distributions	O
is	O
to	O
use	O
the	O
weighted	O
geometric	O
average	O
of	O
the	O
target	O
distribution	O
and	O
the	O
starting	O
proposal	O
distribution	O
which	O
the	O
partition	O
function	O
is	O
known	O
j	O
p	O
j	O
p	O
j	O
in	O
order	O
to	O
sample	O
from	O
these	O
intermediate	O
distributions	O
we	O
define	O
a	O
series	O
of	O
x	O
that	O
define	O
the	O
conditional	B
probability	I
given	O
we	O
are	O
currently	O
at	O
x	O
the	O
transition	O
markov	B
chain	I
transition	O
functions	O
t	O
j	O
distribution	O
of	O
transitioning	O
to	O
x	O
operator	O
t	O
j	O
x	O
is	O
defined	O
to	O
leave	O
p	O
j	O
p	O
j	O
p	O
j	O
invariant	O
x	O
dx	O
j	O
these	O
transitions	O
may	O
be	O
constructed	O
as	O
any	O
markov	B
chain	I
monte	I
carlo	I
method	O
metropolis-hastings	O
gibbs	O
including	O
methods	O
involving	O
multiple	O
passes	O
through	O
all	O
of	O
the	O
random	O
variables	O
or	O
other	O
kinds	O
of	O
iterations	O
the	O
ais	O
sampling	O
strategy	O
is	O
then	O
to	O
generate	O
samples	O
from	O
and	O
then	O
use	O
the	O
transition	O
operators	O
to	O
sequentially	O
generate	O
samples	O
from	O
the	O
intermediate	O
distributions	O
until	O
we	O
arrive	O
at	O
samples	O
from	O
the	O
target	O
distribution	O
for	O
k	O
k	O
sample	O
x	O
chapter	O
confronting	O
the	O
partition	O
function	O
sample	O
x	O
sample	O
x	O
n	O
sample	O
x	O
n	O
t	O
x	O
t	O
n	O
t	O
n	O
n	O
n	O
x	O
n	O
x	O
n	O
end	O
for	O
sample	O
k	O
we	O
can	O
derive	O
the	O
importance	O
weight	O
by	O
chaining	O
together	O
the	O
importance	O
weights	B
for	O
the	O
jumps	O
between	O
the	O
intermediate	O
distributions	O
given	O
in	O
equation	O
w	O
p	O
p	O
p	O
p	O
n	O
n	O
to	O
avoid	O
numerical	O
issues	O
such	O
as	O
overflow	O
it	O
is	O
probably	O
best	O
to	O
compute	O
log	O
w	O
by	O
adding	O
and	O
subtracting	O
log	O
probabilities	O
rather	O
than	O
computing	O
w	O
by	O
multiplying	O
and	O
dividing	O
probabilities	O
with	O
the	O
sampling	O
procedure	O
thus	O
defined	O
and	O
the	O
importance	O
weights	B
given	O
in	O
equation	O
the	O
estimate	O
of	O
the	O
ratio	O
of	O
partition	O
functions	O
is	O
given	O
by	O
k	O
k	O
w	O
in	O
order	O
to	O
verify	O
that	O
this	O
procedure	O
defines	O
a	O
valid	O
importance	O
sampling	O
scheme	O
we	O
can	O
show	O
that	O
the	O
ais	O
procedure	O
corresponds	O
to	O
simple	O
importance	O
sampling	O
on	O
an	O
extended	O
state	O
space	O
with	O
points	O
sampled	O
over	O
the	O
product	O
space	O
to	O
do	O
this	O
we	O
define	O
the	O
distribution	O
over	O
the	O
extended	O
space	O
as	O
x	O
n	O
neal	O
px	O
x	O
n	O
n	O
p	O
t	O
n	O
x	O
t	O
n	O
n	O
x	O
n	O
t	O
x	O
where	O
ta	O
is	O
the	O
reverse	O
of	O
the	O
transition	O
operator	O
defined	O
by	O
t	O
a	O
an	O
application	O
of	O
bayes	O
rule	O
tax	O
x	O
pax	O
pa	O
t	O
ax	O
x	O
pa	O
pa	O
tax	O
x	O
plugging	O
the	O
above	O
into	O
the	O
expression	O
for	O
the	O
joint	O
distribution	O
on	O
the	O
extended	O
state	O
space	O
given	O
in	O
equation	O
we	O
get	O
px	O
x	O
n	O
x	O
chapter	O
confronting	O
the	O
partition	O
function	O
p	O
n	O
n	O
p	O
n	O
t	O
n	O
x	O
n	O
p	O
i	O
p	O
i	O
i	O
t	O
i	O
x	O
i	O
n	O
n	O
p	O
n	O
t	O
n	O
x	O
n	O
p	O
p	O
p	O
i	O
t	O
i	O
x	O
i	O
we	O
now	O
have	O
means	O
of	O
generating	O
samples	O
from	O
the	O
joint	O
proposal	O
distribution	O
q	O
over	O
the	O
extended	O
sample	O
via	O
a	O
sampling	O
scheme	O
given	O
above	O
with	O
the	O
joint	O
distribution	O
given	O
by	O
qx	O
x	O
n	O
x	O
p	O
x	O
t	O
n	O
x	O
n	O
we	O
have	O
a	O
joint	O
distribution	O
on	O
the	O
extended	O
space	O
given	O
by	O
equation	O
qx	O
which	O
we	O
will	O
draw	O
samples	O
it	O
remains	O
to	O
determine	O
the	O
importance	O
weights	B
taking	O
as	O
the	O
proposal	O
distribution	O
on	O
the	O
extended	O
state	O
space	O
from	O
x	O
n	O
w	O
px	O
qx	O
x	O
n	O
x	O
n	O
x	O
p	O
n	O
n	O
p	O
p	O
these	O
weights	B
are	O
the	O
same	O
as	O
proposed	O
for	O
ais	O
thus	O
we	O
can	O
interpret	O
ais	O
as	O
simple	O
importance	O
sampling	O
applied	O
to	O
an	O
extended	O
state	O
and	O
its	O
validity	O
follows	O
immediately	O
from	O
the	O
validity	O
of	O
importance	O
sampling	O
neal	O
annealed	O
importance	O
sampling	O
was	O
first	O
discovered	O
by	O
jarzynski	O
it	O
is	O
currently	O
the	O
most	O
common	O
and	O
then	O
again	O
independently	O
by	O
way	O
of	O
estimating	O
the	O
partition	O
function	O
for	O
undirected	O
probabilistic	O
models	O
the	O
reasons	O
for	O
this	O
may	O
have	O
more	O
to	O
do	O
with	O
the	O
publication	O
of	O
an	O
influential	O
paper	O
and	O
murray	O
describing	O
its	O
application	O
to	O
estimating	O
the	O
partition	O
function	O
of	O
restricted	O
boltzmann	O
machines	O
and	O
deep	O
belief	O
networks	O
than	O
with	O
any	O
inherent	O
advantage	O
the	O
method	O
has	O
over	O
the	O
other	O
method	O
described	O
below	O
a	O
discussion	O
of	O
the	O
properties	O
of	O
the	O
ais	O
estimator	O
its	O
variance	O
and	O
efficiency	O
can	O
be	O
found	O
in	O
neal	O
bridge	O
sampling	O
is	O
another	O
method	O
that	O
like	O
ais	O
addresses	O
the	O
bridge	O
sampling	O
shortcomings	O
of	O
importance	O
sampling	O
rather	O
than	O
chaining	O
together	O
a	O
series	O
of	O
bennett	O
chapter	O
confronting	O
the	O
partition	O
function	O
intermediate	O
distributions	O
bridge	O
sampling	O
relies	O
on	O
a	O
single	O
distribution	O
p	O
known	O
as	O
the	O
bridge	O
to	O
interpolate	O
between	O
a	O
distribution	O
with	O
known	O
partition	O
function	O
and	O
a	O
distribution	O
for	O
which	O
we	O
are	O
trying	O
to	O
estimate	O
the	O
partition	O
function	O
bridge	O
sampling	O
estimates	O
the	O
ratio	O
as	O
the	O
ratio	O
of	O
the	O
expected	O
impor	O
tance	O
weights	B
between	O
and	O
p	O
and	O
between	O
and	O
p	O
p	O
p	O
k	O
z	O
z	O
k	O
if	O
the	O
bridge	O
distribution	O
p	O
is	O
chosen	O
carefully	O
to	O
have	O
a	O
large	O
overlap	O
of	O
support	O
with	O
both	O
and	O
then	O
bridge	O
sampling	O
can	O
allow	O
the	O
distance	O
between	O
two	O
distributions	O
more	O
formally	O
p	O
to	O
be	O
much	O
larger	O
than	O
with	O
standard	O
importance	O
sampling	O
it	O
can	O
be	O
shown	O
that	O
the	O
optimal	O
bridging	O
distribution	O
is	O
given	O
by	O
p	O
x	O
where	O
r	O
at	O
first	O
this	O
appears	O
to	O
be	O
an	O
unworkable	O
solution	O
r	O
x	O
as	O
it	O
would	O
seem	O
to	O
require	O
the	O
very	O
quantity	O
we	O
are	O
trying	O
to	O
estimate	O
however	O
it	O
is	O
possible	O
to	O
start	O
with	O
a	O
coarse	O
estimate	O
of	O
r	O
and	O
use	O
the	O
resulting	O
bridge	O
distribution	O
to	O
refine	O
our	O
estimate	O
iteratively	O
that	O
is	O
we	O
iteratively	O
re-estimate	O
the	O
ratio	O
and	O
use	O
each	O
iteration	O
to	O
update	O
the	O
value	O
of	O
neal	O
linked	O
importance	O
sampling	O
both	O
ais	O
and	O
bridge	O
sampling	O
have	O
their	O
advantages	O
if	O
dkl	O
is	O
not	O
too	O
large	O
and	O
are	O
sufficiently	O
close	O
bridge	O
sampling	O
can	O
be	O
a	O
more	O
effective	O
means	O
of	O
estimating	O
the	O
ratio	O
of	O
partition	O
functions	O
than	O
ais	O
if	O
however	O
the	O
two	O
distributions	O
are	O
too	O
far	O
apart	O
for	O
a	O
single	O
distribution	O
p	O
to	O
bridge	O
the	O
gap	O
then	O
one	O
can	O
at	O
least	O
use	O
ais	O
with	O
potentially	O
many	O
intermediate	O
distributions	O
to	O
span	O
the	O
distance	O
between	O
and	O
neal	O
showed	O
how	O
his	O
linked	O
importance	O
sampling	O
method	O
leveraged	O
the	O
power	O
of	O
the	O
bridge	O
sampling	O
strategy	O
to	O
bridge	O
the	O
intermediate	O
distributions	O
used	O
in	O
ais	O
to	O
significantly	O
improve	O
the	O
overall	O
partition	O
function	O
estimates	O
estimating	O
the	O
partition	O
function	O
while	O
training	O
while	O
ais	O
has	O
become	O
accepted	O
as	O
the	O
standard	O
method	O
for	O
estimating	O
the	O
partition	O
function	O
for	O
many	O
undirected	O
models	O
it	O
is	O
sufficiently	O
computationally	O
intensive	O
that	O
it	O
remains	O
infeasible	O
to	O
use	O
during	O
training	O
however	O
alternative	O
strategies	O
that	O
have	O
been	O
explored	O
to	O
maintain	O
an	O
estimate	O
of	O
the	O
partition	O
function	O
throughout	O
training	O
using	O
a	O
combination	O
of	O
bridge	O
sampling	O
short-chain	O
ais	O
and	O
parallel	O
tempering	B
devised	O
a	O
scheme	O
to	O
track	O
the	O
partition	O
function	O
of	O
an	O
et	O
al	O
desjardins	O
chapter	O
confronting	O
the	O
partition	O
function	O
rbm	O
throughout	O
the	O
training	O
process	O
the	O
strategy	O
is	O
based	O
on	O
the	O
maintenance	O
of	O
independent	O
estimates	O
of	O
the	O
partition	O
functions	O
of	O
the	O
rbm	O
at	O
every	O
temperature	O
operating	O
in	O
the	O
parallel	O
tempering	B
scheme	O
the	O
authors	O
combined	O
bridge	O
sampling	O
estimates	O
of	O
the	O
ratios	O
of	O
partition	O
functions	O
of	O
neighboring	O
chains	O
from	O
parallel	O
tempering	B
with	O
ais	O
estimates	O
across	O
time	O
to	O
come	O
up	O
with	O
a	O
low	O
variance	O
estimate	O
of	O
the	O
partition	O
functions	O
at	O
every	O
iteration	O
of	O
learning	O
the	O
tools	O
described	O
in	O
this	O
chapter	O
provide	O
many	O
different	O
ways	O
of	O
overcoming	O
the	O
problem	O
of	O
intractable	O
partition	O
functions	O
but	O
there	O
can	O
be	O
several	O
other	O
difficulties	O
involved	O
in	O
training	O
and	O
using	O
generative	O
models	O
foremost	O
among	O
these	O
is	O
the	O
problem	O
of	O
intractable	O
inference	O
which	O
we	O
confront	O
next	O
chapter	O
approximate	B
inference	I
many	O
probabilistic	O
models	O
are	O
difficult	O
to	O
train	O
because	O
it	O
is	O
difficult	O
to	O
perform	O
inference	O
in	O
them	O
in	O
the	O
context	O
of	O
deep	O
learning	O
we	O
usually	O
have	O
a	O
set	O
of	O
visible	O
variables	O
v	O
and	O
a	O
set	O
of	O
latent	O
variables	O
h	O
the	O
challenge	B
of	O
inference	O
usually	O
refers	O
to	O
the	O
difficult	O
problem	O
of	O
computing	O
ph	O
v	O
or	O
taking	O
expectations	O
with	O
respect	O
to	O
it	O
such	O
operations	O
are	O
often	O
necessary	O
for	O
tasks	O
like	O
maximum	B
likelihood	I
learning	O
many	O
simple	O
graphical	O
models	O
with	O
only	O
one	O
hidden	B
layer	I
such	O
as	O
restricted	O
boltzmann	O
machines	O
and	O
probabilistic	O
pca	O
are	O
defined	O
in	O
a	O
way	O
that	O
makes	O
inference	O
operations	O
like	O
computing	O
ph	O
v	O
or	O
taking	O
expectations	O
with	O
respect	O
to	O
it	O
simple	O
unfortunately	O
most	O
graphical	O
models	O
with	O
multiple	O
layers	O
of	O
hidden	O
variables	O
have	O
intractable	O
posterior	O
distributions	O
exact	O
inference	O
requires	O
an	O
exponential	O
amount	O
of	O
time	O
in	O
these	O
models	O
even	O
some	O
models	O
with	O
only	O
a	O
single	O
layer	O
such	O
as	O
sparse	O
coding	O
have	O
this	O
problem	O
in	O
this	O
chapter	O
we	O
introduce	O
several	O
of	O
the	O
techniques	O
for	O
confronting	O
these	O
we	O
will	O
describe	O
how	O
to	O
use	O
intractable	O
inference	O
problems	O
later	O
in	O
chapter	O
these	O
techniques	O
to	O
train	O
probabilistic	O
models	O
that	O
would	O
otherwise	O
be	O
intractable	O
such	O
as	O
deep	O
belief	O
networks	O
and	O
deep	O
boltzmann	O
machines	O
intractable	O
inference	O
problems	O
in	O
deep	O
learning	O
usually	O
arise	O
from	O
interactions	O
between	O
latent	O
variables	O
in	O
a	O
structured	O
graphical	O
model	O
see	O
figure	O
for	O
some	O
examples	O
these	O
interactions	O
may	O
be	O
due	O
to	O
direct	O
interactions	O
in	O
undirected	O
models	O
or	O
explaining	O
away	O
interactions	O
between	O
mutual	O
ancestors	O
of	O
the	O
same	O
visible	O
unit	O
in	O
directed	O
models	O
chapter	O
approximate	B
inference	I
osindero	O
and	O
hinton	O
figure	O
intractable	O
inference	O
problems	O
in	O
deep	O
learning	O
are	O
usually	O
the	O
result	O
of	O
interactions	O
between	O
latent	O
variables	O
in	O
a	O
structured	O
graphical	O
model	O
these	O
can	O
be	O
due	O
to	O
edges	O
directly	O
connecting	O
one	O
latent	B
variable	I
to	O
another	O
or	O
due	O
to	O
longer	O
paths	O
that	O
are	O
activated	O
when	O
the	O
child	O
of	O
a	O
v-structure	O
is	O
observed	O
semi-restricted	O
boltzmann	O
machine	O
with	O
connections	O
between	O
hidden	O
units	O
these	O
direct	O
connections	O
between	O
latent	O
variables	O
make	O
the	O
posterior	O
distribution	O
intractable	O
due	O
to	O
large	O
cliques	O
of	O
latent	O
variables	O
a	O
deep	O
boltzmann	O
machine	O
organized	O
into	O
layers	O
of	O
variables	O
without	O
intra-layer	O
connections	O
still	O
has	O
an	O
intractable	O
posterior	O
distribution	O
due	O
to	O
the	O
connections	O
between	O
layers	O
this	O
directed	O
model	O
has	O
interactions	O
between	O
latent	O
variables	O
when	O
the	O
visible	O
variables	O
are	O
observed	O
because	O
every	O
two	O
latent	O
variables	O
are	O
co-parents	O
some	O
probabilistic	O
models	O
are	O
able	O
to	O
provide	O
tractable	O
inference	O
over	O
the	O
latent	O
variables	O
despite	O
having	O
one	O
of	O
the	O
graph	O
structures	O
depicted	O
above	O
this	O
is	O
possible	O
if	O
the	O
conditional	B
probability	I
distributions	O
are	O
chosen	O
to	O
introduce	O
additional	O
independences	O
beyond	O
those	O
described	O
by	O
the	O
graph	O
for	O
example	B
probabilistic	O
pca	O
has	O
the	O
graph	O
structure	O
shown	O
in	O
the	O
right	O
yet	O
still	O
has	O
simple	O
inference	O
due	O
to	O
special	O
properties	O
of	O
the	O
specific	O
conditional	O
distributions	O
it	O
uses	O
conditionals	O
with	O
mutually	O
orthogonal	O
basis	O
vectors	O
chapter	O
approximate	B
inference	I
inference	O
as	O
optimization	O
many	O
approaches	O
to	O
confronting	O
the	O
problem	O
of	O
difficult	O
inference	O
make	O
use	O
of	O
the	O
observation	O
that	O
exact	O
inference	O
can	O
be	O
described	O
as	O
an	O
optimization	O
problem	O
approximate	B
inference	I
algorithms	O
may	O
then	O
be	O
derived	O
by	O
approximating	O
the	O
underlying	O
optimization	O
problem	O
to	O
construct	O
the	O
optimization	O
problem	O
assume	O
we	O
have	O
a	O
probabilistic	O
model	O
consisting	O
of	O
observed	O
variables	O
v	O
and	O
latent	O
variables	O
h	O
we	O
would	O
like	O
to	O
compute	O
the	O
log	O
probability	O
of	O
the	O
observed	O
data	O
log	O
pv	O
sometimes	O
it	O
is	O
too	O
difficult	O
to	O
compute	O
log	O
pv	O
if	O
it	O
is	O
costly	O
to	O
marginalize	O
out	O
h	O
instead	O
we	O
can	O
compute	O
q	O
on	O
log	O
pv	O
this	O
bound	B
is	O
called	O
the	O
evidence	O
lower	O
a	O
lower	O
bound	B
bound	B
another	O
commonly	O
used	O
name	O
for	O
this	O
lower	O
bound	B
is	O
the	O
negative	O
variational	O
free	O
energy	O
specifically	O
the	O
evidence	O
lower	O
bound	B
is	O
defined	O
to	O
be	O
l	O
l	O
v	O
q	O
log	O
p	O
v	O
dkl	O
q	O
h	O
v	O
p	O
h	O
v	O
where	O
q	O
is	O
an	O
arbitrary	O
probability	B
distribution	I
over	O
l	O
h	O
because	O
the	O
difference	O
between	O
log	O
pv	O
and	O
q	O
is	O
given	O
by	O
the	O
kl	O
l	O
divergence	O
and	O
because	O
the	O
kl	O
divergence	O
is	O
always	O
non-negative	O
we	O
can	O
see	O
that	O
always	O
has	O
at	O
most	O
the	O
same	O
value	O
as	O
the	O
desired	O
log	O
probability	O
the	O
two	O
are	O
q	O
is	O
the	O
same	O
distribution	O
as	O
p	O
h	O
v	O
equal	O
if	O
and	O
only	O
if	O
l	O
surprisingly	O
simple	O
algebra	O
shows	O
that	O
we	O
can	O
rearrange	O
can	O
be	O
considerably	O
easier	O
to	O
compute	O
for	O
some	O
distributions	O
q	O
into	O
a	O
much	O
more	O
convenient	O
form	O
l	O
l	O
v	O
q	O
log	O
p	O
v	O
log	O
p	O
v	O
log	O
p	O
v	O
dkl	O
q	O
log	O
eh	O
q	O
log	O
eh	O
q	O
h	O
v	O
q	O
p	O
q	O
p	O
p	O
h	O
v	O
h	O
v	O
h	O
v	O
h	O
v	O
v	O
p	O
q	O
h	O
v	O
log	O
p	O
h	O
v	O
log	O
p	O
v	O
q	O
eh	O
q	O
h	O
v	O
q	O
eh	O
p	O
h	O
v	O
log	O
p	O
v	O
log	O
this	O
yields	O
the	O
more	O
canonical	O
definition	O
of	O
the	O
evidence	O
lower	O
bound	B
l	O
for	O
an	O
appropriate	O
choice	O
of	O
q	O
is	O
tractable	O
to	O
compute	O
for	O
any	O
choice	O
that	O
are	O
better	O
of	O
q	O
provides	O
a	O
lower	O
bound	B
on	O
the	O
likelihood	O
for	O
qh	O
v	O
p	O
h	O
v	O
h	O
q	O
l	O
v	O
q	O
q	O
eh	O
l	O
chapter	O
approximate	B
inference	I
approximations	O
of	O
ph	O
v	O
l	O
closer	O
to	O
log	O
pv	O
when	O
q	O
v	O
v	O
l	O
log	O
p	O
v	O
l	O
q	O
l	O
the	O
lower	O
bound	B
p	O
v	O
will	O
be	O
tighter	O
in	O
other	O
words	O
the	O
approximation	O
is	O
perfect	O
and	O
exact	O
inference	O
maximizes	O
we	O
can	O
thus	O
think	O
of	O
inference	O
as	O
the	O
procedure	O
for	O
finding	O
the	O
q	O
that	O
maximizes	O
perfectly	O
by	O
searching	O
over	O
a	O
family	O
of	O
functions	O
q	O
that	O
includes	O
ph	O
v	O
throughout	O
this	O
chapter	O
we	O
will	O
show	O
how	O
to	O
derive	O
different	O
forms	O
of	O
approximate	B
inference	I
by	O
using	O
approximate	O
optimization	O
to	O
find	O
q	O
we	O
can	O
make	O
the	O
optimization	O
procedure	O
less	O
expensive	O
but	O
approximate	O
by	O
restricting	O
the	O
family	O
of	O
distributions	O
q	O
the	O
optimization	O
is	O
allowed	O
to	O
search	O
over	O
or	O
by	O
using	O
an	O
imperfect	O
optimization	O
procedure	O
that	O
may	O
not	O
completely	O
maximize	O
but	O
merely	O
increase	O
it	O
by	O
a	O
significant	O
amount	O
l	O
no	O
matter	O
what	O
choice	O
of	O
q	O
we	O
use	O
is	O
a	O
lower	O
bound	B
we	O
can	O
get	O
tighter	O
or	O
looser	O
bounds	O
that	O
are	O
cheaper	O
or	O
more	O
expensive	O
to	O
compute	O
depending	O
on	O
how	O
we	O
choose	O
to	O
approach	O
this	O
optimization	O
problem	O
we	O
can	O
obtain	O
a	O
poorly	O
matched	O
q	O
but	O
reduce	O
the	O
computational	O
cost	O
by	O
using	O
an	O
imperfect	O
optimization	O
procedure	O
or	O
by	O
using	O
a	O
perfect	O
optimization	O
procedure	O
over	O
a	O
restricted	O
family	O
of	O
q	O
distributions	O
l	O
expectation	B
maximization	I
the	O
first	O
algorithm	O
we	O
introduce	O
based	O
on	O
maximizing	O
a	O
lower	O
bound	B
is	O
the	O
expectation	B
maximization	I
algorithm	O
a	O
popular	O
training	O
algorithm	O
for	O
models	O
with	O
latent	O
variables	O
we	O
describe	O
here	O
a	O
view	O
on	O
the	O
em	O
algorithm	O
developed	O
by	O
unlike	O
most	O
of	O
the	O
other	O
algorithms	O
we	O
describe	O
in	O
this	O
chapter	O
em	O
is	O
not	O
an	O
approach	O
to	O
approximate	B
inference	I
but	O
rather	O
an	O
approach	O
to	O
learning	O
with	O
an	O
approximate	O
posterior	O
neal	O
and	O
hinton	O
l	O
the	O
em	O
algorithm	O
consists	O
of	O
alternating	O
between	O
two	O
steps	O
until	O
convergence	O
the	O
e-step	B
step	O
let	O
denote	O
the	O
value	O
of	O
the	O
parameters	O
at	O
the	O
beginning	O
of	O
the	O
step	O
set	O
qh	O
v	O
for	O
all	O
indices	O
i	O
of	O
the	O
training	O
examples	O
v	O
we	O
want	O
to	O
train	O
on	O
batch	O
and	O
minibatch	B
variants	O
are	O
valid	O
by	O
this	O
we	O
mean	O
q	O
is	O
defined	O
in	O
terms	O
of	O
the	O
current	O
parameter	O
value	O
of	O
if	O
we	O
vary	O
then	O
ph	O
v	O
will	O
change	O
but	O
q	O
will	O
remain	O
equal	O
to	O
p	O
h	O
v	O
v	O
ph	O
h	O
v	O
the	O
m-step	B
step	O
completely	O
or	O
partially	O
maximize	O
l	O
i	O
q	O
chapter	O
approximate	B
inference	I
with	O
respect	O
to	O
using	O
your	O
optimization	O
algorithm	O
of	O
choice	O
l	O
step	O
we	O
maximize	O
respect	O
to	O
this	O
can	O
be	O
viewed	O
as	O
a	O
coordinate	O
ascent	O
algorithm	O
to	O
maximize	O
with	O
respect	O
to	O
q	O
and	O
on	O
the	O
other	O
we	O
maximize	O
l	O
on	O
one	O
with	O
l	O
stochastic	O
gradient	B
ascent	O
on	O
latent	B
variable	I
models	O
can	O
be	O
seen	O
as	O
a	O
special	O
case	O
of	O
the	O
em	O
algorithm	O
where	O
the	O
m	O
step	O
consists	O
of	O
taking	O
a	O
single	O
gradient	B
step	O
other	O
variants	O
of	O
the	O
em	O
algorithm	O
can	O
make	O
much	O
larger	O
steps	O
for	O
some	O
model	O
families	O
the	O
m	O
step	O
can	O
even	O
be	O
performed	O
analytically	O
jumping	O
all	O
the	O
way	O
to	O
the	O
optimal	O
solution	O
for	O
given	O
the	O
current	O
q	O
even	O
though	O
the	O
e-step	B
involves	O
exact	O
inference	O
we	O
can	O
think	O
of	O
the	O
em	O
algorithm	O
as	O
using	O
approximate	B
inference	I
in	O
some	O
sense	O
specifically	O
the	O
m-step	B
assumes	O
that	O
the	O
same	O
value	O
of	O
q	O
can	O
be	O
used	O
for	O
all	O
values	O
of	O
this	O
will	O
introduce	O
and	O
the	O
true	O
log	O
pv	O
as	O
the	O
m-step	B
moves	O
further	O
and	O
further	O
a	O
gap	O
between	O
away	O
from	O
the	O
value	O
used	O
in	O
the	O
e-step	B
fortunately	O
the	O
e-step	B
reduces	O
the	O
gap	O
to	O
zero	O
again	O
as	O
we	O
enter	O
the	O
loop	B
for	O
the	O
next	O
time	O
l	O
the	O
em	O
algorithm	O
contains	O
a	O
few	O
different	O
insights	O
first	O
there	O
is	O
the	O
basic	O
structure	O
of	O
the	O
learning	O
process	O
in	O
which	O
we	O
update	O
the	O
model	O
parameters	O
to	O
improve	O
the	O
likelihood	O
of	O
a	O
completed	O
dataset	B
where	O
all	O
missing	O
variables	O
have	O
their	O
values	O
provided	O
by	O
an	O
estimate	O
of	O
the	O
posterior	O
distribution	O
this	O
particular	O
insight	O
is	O
not	O
unique	O
to	O
the	O
em	O
algorithm	O
for	O
example	B
using	O
gradient	B
descent	O
to	O
maximize	O
the	O
log-likelihood	O
also	O
has	O
this	O
same	O
property	O
the	O
log-likelihood	O
gradient	B
computations	O
require	O
taking	O
expectations	O
with	O
respect	O
to	O
the	O
posterior	O
distribution	O
over	O
the	O
hidden	O
units	O
another	O
key	O
insight	O
in	O
the	O
em	O
algorithm	O
is	O
that	O
we	O
can	O
continue	O
to	O
use	O
one	O
value	O
of	O
q	O
even	O
after	O
we	O
have	O
moved	O
to	O
a	O
different	O
value	O
of	O
this	O
particular	O
insight	O
is	O
used	O
throughout	O
classical	O
machine	B
learning	I
to	O
derive	O
large	O
m-step	B
updates	O
in	O
the	O
context	O
of	O
deep	O
learning	O
most	O
models	O
are	O
too	O
complex	O
to	O
admit	O
a	O
tractable	O
solution	O
for	O
an	O
optimal	O
large	O
m-step	B
update	O
so	O
this	O
second	O
insight	O
which	O
is	O
more	O
unique	O
to	O
the	O
em	O
algorithm	O
is	O
rarely	O
used	O
map	O
inference	O
and	O
sparse	O
coding	O
we	O
usually	O
use	O
the	O
term	O
inference	O
to	O
refer	O
to	O
computing	O
the	O
probability	B
distribution	I
over	O
one	O
set	O
of	O
variables	O
given	O
another	O
when	O
training	O
probabilistic	O
models	O
with	O
latent	O
variables	O
we	O
are	O
usually	O
interested	O
in	O
computing	O
ph	O
v	O
an	O
alternative	O
form	O
of	O
inference	O
is	O
to	O
compute	O
the	O
single	O
most	O
likely	O
value	O
of	O
the	O
missing	O
variables	O
rather	O
than	O
to	O
infer	O
the	O
entire	O
distribution	O
over	O
their	O
possible	O
values	O
in	O
the	O
context	O
chapter	O
approximate	B
inference	I
of	O
latent	B
variable	I
models	O
this	O
means	O
computing	O
h	O
v	O
p	O
arg	O
max	O
h	O
h	O
this	O
is	O
known	O
as	O
maximum	O
a	O
posteriori	O
inference	O
abbreviated	O
map	O
inference	O
map	O
inference	O
is	O
usually	O
not	O
thought	O
of	O
as	O
approximate	B
inference	I
it	O
does	O
l	O
compute	O
the	O
exact	O
most	O
likely	O
value	O
of	O
h	O
however	O
if	O
we	O
wish	O
to	O
develop	O
a	O
q	O
then	O
it	O
is	O
helpful	O
to	O
think	O
of	O
map	O
h	O
learning	O
process	O
based	O
on	O
maximizing	O
inference	O
as	O
a	O
procedure	O
that	O
provides	O
a	O
value	O
of	O
q	O
in	O
this	O
sense	O
we	O
can	O
think	O
of	O
map	O
inference	O
as	O
approximate	B
inference	I
because	O
it	O
does	O
not	O
provide	O
the	O
optimal	O
q	O
recall	B
from	O
section	O
l	O
v	O
that	O
exact	O
inference	O
consists	O
of	O
maximizing	O
q	O
q	O
eh	O
p	O
h	O
v	O
h	O
q	O
with	O
respect	O
to	O
q	O
over	O
an	O
unrestricted	O
family	O
of	O
probability	O
distributions	O
using	O
an	O
exact	O
optimization	O
algorithm	O
we	O
can	O
derive	O
map	O
inference	O
as	O
a	O
form	O
of	O
approximate	B
inference	I
by	O
restricting	O
the	O
family	O
of	O
distributions	O
q	O
may	O
be	O
drawn	O
from	O
specifically	O
we	O
require	O
to	O
take	O
on	O
a	O
dirac	O
distribution	O
q	O
h	O
v	O
q	O
h	O
l	O
that	O
this	O
means	O
that	O
we	O
can	O
now	O
control	O
q	O
entirely	O
via	O
dropping	O
terms	O
of	O
do	O
not	O
vary	O
with	O
we	O
are	O
left	O
with	O
the	O
optimization	O
problem	O
arg	O
max	O
log	O
p	O
h	O
v	O
which	O
is	O
equivalent	O
to	O
the	O
map	O
inference	O
problem	O
h	O
arg	O
max	O
h	O
h	O
v	O
p	O
we	O
can	O
thus	O
justify	O
a	O
learning	O
procedure	O
similar	O
to	O
em	O
in	O
which	O
we	O
alternate	O
and	O
then	O
update	O
to	O
increase	O
between	O
performing	O
map	O
inference	O
to	O
infer	O
h	O
l	O
log	O
ph	O
v	O
as	O
with	O
em	O
this	O
is	O
a	O
form	O
of	O
coordinate	O
ascent	O
on	O
where	O
we	O
with	O
respect	O
to	O
q	O
and	O
using	O
alternate	O
between	O
using	O
inference	O
to	O
optimize	O
l	O
with	O
respect	O
to	O
the	O
procedure	O
as	O
a	O
whole	O
can	O
parameter	O
updates	O
to	O
optimize	O
is	O
a	O
lower	O
bound	B
on	O
log	O
pv	O
in	O
the	O
case	O
of	O
map	O
be	O
justified	O
by	O
the	O
fact	O
that	O
inference	O
this	O
justification	O
is	O
rather	O
vacuous	O
because	O
the	O
bound	B
is	O
infinitely	O
loose	O
due	O
to	O
the	O
dirac	O
distribution	O
s	O
differential	O
entropy	O
of	O
negative	O
infinity	O
however	O
adding	O
noise	O
to	O
would	O
make	O
the	O
bound	B
meaningful	O
again	O
l	O
l	O
chapter	O
approximate	B
inference	I
map	O
inference	O
is	O
commonly	O
used	O
in	O
deep	O
learning	O
as	O
both	O
a	O
feature	B
extractor	O
and	O
a	O
learning	O
mechanism	O
it	O
is	O
primarily	O
used	O
for	O
sparse	O
coding	O
models	O
recall	B
from	O
section	O
that	O
sparse	O
coding	O
is	O
a	O
linear	O
factor	O
model	O
that	O
imposes	O
a	O
sparsity-inducing	O
prior	O
on	O
its	O
hidden	O
units	O
a	O
common	O
choice	O
is	O
a	O
factorial	O
laplace	O
prior	O
with	O
p	O
h	O
i	O
hi	O
e	O
the	O
visible	O
units	O
are	O
then	O
generated	O
by	O
performing	O
a	O
linear	O
transformation	O
and	O
adding	O
noise	O
n	O
p	O
x	O
h	O
v	O
w	O
h	O
b	O
computing	O
or	O
even	O
representing	O
ph	O
v	O
is	O
difficult	O
every	O
pair	O
of	O
variables	O
hi	O
and	O
hj	O
are	O
both	O
parents	O
of	O
v	O
this	O
means	O
that	O
when	O
v	O
is	O
observed	O
the	O
graphical	O
model	O
contains	O
an	O
active	O
path	O
connecting	O
hi	O
and	O
hj	O
all	O
of	O
the	O
hidden	O
units	O
thus	O
participate	O
in	O
one	O
massive	O
clique	O
in	O
ph	O
v	O
if	O
the	O
model	O
were	O
gaussian	O
then	O
these	O
interactions	O
could	O
be	O
modeled	O
efficiently	O
via	O
the	O
covariance	B
matrix	I
but	O
the	O
sparse	O
prior	O
makes	O
these	O
interactions	O
non-gaussian	O
is	O
intractable	O
so	O
is	O
the	O
computation	O
of	O
the	O
log-likelihood	O
and	O
its	O
gradient	B
we	O
thus	O
cannot	O
use	O
exact	O
maximum	B
likelihood	I
learning	O
instead	O
we	O
use	O
map	O
inference	O
and	O
learn	O
the	O
parameters	O
by	O
maximizing	O
the	O
elbo	O
defined	O
by	O
the	O
dirac	O
distribution	O
around	O
the	O
map	O
estimate	O
of	O
because	O
ph	O
v	O
if	O
we	O
concatenate	O
all	O
of	O
the	O
h	O
vectors	O
in	O
the	O
training	O
set	O
into	O
a	O
matrix	O
h	O
and	O
then	O
the	O
sparse	O
coding	O
learning	O
vectors	O
into	O
a	O
matrix	O
v	O
concatenate	O
all	O
of	O
the	O
process	O
consists	O
of	O
minimizing	O
v	O
j	O
w	O
hij	O
ij	O
ij	O
v	O
hw	O
ij	O
most	O
applications	O
of	O
sparse	O
coding	O
also	O
involve	O
weight	O
decay	O
or	O
a	O
constraint	O
on	O
the	O
norms	O
of	O
the	O
columns	O
of	O
w	O
in	O
order	O
to	O
prevent	O
the	O
pathological	O
solution	O
with	O
extremely	O
small	O
and	O
large	O
w	O
h	O
we	O
can	O
minimize	O
j	O
by	O
alternating	O
between	O
minimization	O
with	O
respect	O
to	O
h	O
and	O
minimization	O
with	O
respect	O
to	O
w	O
both	O
sub-problems	O
are	O
convex	O
in	O
fact	O
the	O
minimization	O
with	O
respect	O
to	O
w	O
is	O
just	O
a	O
linear	O
regression	B
problem	O
however	O
minimization	O
of	O
j	O
with	O
respect	O
to	O
both	O
arguments	O
is	O
usually	O
not	O
a	O
convex	O
problem	O
minimization	O
with	O
respect	O
to	O
h	O
requires	O
specialized	O
algorithms	O
such	O
as	O
the	O
feature-sign	O
search	O
algorithm	O
lee	O
et	O
al	O
chapter	O
approximate	B
inference	I
variational	O
inference	O
and	O
learning	O
l	O
l	O
q	O
is	O
a	O
lower	O
bound	B
on	O
we	O
have	O
seen	O
how	O
the	O
evidence	O
lower	O
bound	B
l	O
with	O
respect	O
to	O
q	O
and	O
log	O
pv	O
how	O
inference	O
can	O
be	O
viewed	O
as	O
maximizing	O
with	O
respect	O
to	O
we	O
have	O
seen	O
how	O
learning	O
can	O
be	O
viewed	O
as	O
maximizing	O
that	O
the	O
em	O
algorithm	O
allows	O
us	O
to	O
make	O
large	O
learning	O
steps	O
with	O
a	O
fixed	O
q	O
and	O
that	O
learning	O
algorithms	O
based	O
on	O
map	O
inference	O
allow	O
us	O
to	O
learn	O
using	O
a	O
point	O
estimate	O
of	O
ph	O
v	O
rather	O
than	O
inferring	O
the	O
entire	O
distribution	O
now	O
we	O
develop	O
the	O
more	O
general	O
approach	O
to	O
variational	O
learning	O
the	O
core	O
idea	O
behind	O
variational	O
learning	O
is	O
that	O
we	O
can	O
maximize	O
over	O
a	O
restricted	O
family	O
of	O
distributions	O
q	O
this	O
family	O
should	O
be	O
chosen	O
so	O
that	O
it	O
is	O
easy	O
to	O
compute	O
eq	O
log	O
ph	O
v	O
a	O
typical	O
way	O
to	O
do	O
this	O
is	O
to	O
introduce	O
assumptions	O
about	O
how	O
factorizes	O
q	O
l	O
a	O
common	O
approach	O
to	O
variational	O
learning	O
is	O
to	O
impose	O
the	O
restriction	O
that	O
q	O
is	O
a	O
factorial	O
distribution	O
h	O
v	O
q	O
v	O
q	O
h	O
i	O
i	O
this	O
is	O
called	O
the	O
mean	O
field	O
approach	O
more	O
generally	O
we	O
can	O
impose	O
any	O
graphical	O
model	O
structure	O
we	O
choose	O
on	O
q	O
to	O
flexibly	O
determine	O
how	O
many	O
interactions	O
we	O
want	O
our	O
approximation	O
to	O
capture	O
this	O
fully	O
general	O
graphical	O
model	O
approach	O
is	O
called	O
structured	O
variational	O
inference	O
saul	O
and	O
jordan	O
the	O
beauty	O
of	O
the	O
variational	O
approach	O
is	O
that	O
we	O
do	O
not	O
need	O
to	O
specify	O
a	O
specific	O
parametric	O
form	O
for	O
q	O
we	O
specify	O
how	O
it	O
should	O
factorize	O
but	O
then	O
the	O
optimization	O
problem	O
determines	O
the	O
optimal	O
probability	B
distribution	I
within	O
those	O
factorization	O
constraints	O
for	O
discrete	O
latent	O
variables	O
this	O
just	O
means	O
that	O
we	O
use	O
traditional	O
optimization	O
techniques	O
to	O
optimize	O
a	O
finite	O
number	O
of	O
variables	O
describing	O
the	O
q	O
distribution	O
for	O
continuous	O
latent	O
variables	O
this	O
means	O
that	O
we	O
use	O
a	O
branch	O
of	O
mathematics	O
called	O
calculus	B
of	I
variations	I
to	O
perform	O
optimization	O
over	O
a	O
space	O
of	O
functions	O
and	O
actually	O
determine	O
which	O
function	O
should	O
be	O
used	O
to	O
represent	O
q	O
calculus	B
of	I
variations	I
is	O
the	O
origin	O
of	O
the	O
names	O
variational	O
learning	O
and	O
variational	O
inference	O
though	O
these	O
names	O
apply	O
even	O
when	O
the	O
latent	O
variables	O
are	O
discrete	O
and	O
calculus	B
of	I
variations	I
is	O
not	O
needed	O
in	O
the	O
case	O
of	O
continuous	O
latent	O
variables	O
calculus	B
of	I
variations	I
is	O
a	O
powerful	O
technique	O
that	O
removes	O
much	O
of	O
the	O
responsibility	O
from	O
the	O
human	O
designer	O
of	O
the	O
model	O
who	O
now	O
must	O
specify	O
only	O
how	O
q	O
factorizes	O
rather	O
than	O
needing	O
to	O
guess	O
how	O
to	O
design	O
a	O
specific	O
that	O
can	O
accurately	O
approximate	O
the	O
posterior	O
l	O
we	O
ph	O
v	O
with	O
respect	O
to	O
q	O
as	O
minimizing	O
dklqh	O
v	O
ph	O
v	O
dkl	O
v	O
q	O
is	O
defined	O
to	O
be	O
log	O
pv	O
can	O
think	O
of	O
maximizing	O
because	O
l	O
q	O
chapter	O
approximate	B
inference	I
pmodel	O
as	O
illustrated	O
in	O
figure	O
in	O
this	O
sense	O
we	O
are	O
fitting	O
q	O
to	O
p	O
however	O
we	O
are	O
doing	O
so	O
with	O
the	O
opposite	O
direction	O
of	O
the	O
kl	O
divergence	O
than	O
we	O
are	O
used	O
to	O
using	O
for	O
fitting	O
an	O
approximation	O
when	O
we	O
use	O
maximum	B
likelihood	I
learning	O
to	O
fit	O
a	O
model	O
to	O
data	O
we	O
minimize	O
d	O
klpdata	O
this	O
means	O
that	O
maximum	B
likelihood	I
encourages	O
the	O
model	O
to	O
have	O
high	O
probability	O
everywhere	O
that	O
the	O
data	O
has	O
high	O
probability	O
while	O
our	O
optimization-based	O
inference	O
procedure	O
encourages	O
q	O
to	O
have	O
low	O
probability	O
everywhere	O
the	O
true	O
posterior	O
has	O
low	O
probability	O
both	O
directions	O
of	O
the	O
kl	O
divergence	O
can	O
have	O
desirable	O
and	O
undesirable	O
properties	O
the	O
choice	O
of	O
which	O
to	O
use	O
depends	O
on	O
which	O
properties	O
are	O
the	O
highest	O
priority	O
for	O
each	O
application	O
in	O
the	O
case	O
of	O
the	O
inference	O
optimization	O
problem	O
we	O
choose	O
to	O
use	O
dklqh	O
v	O
ph	O
v	O
for	O
computational	O
reasons	O
specifically	O
computing	O
d	O
klqh	O
v	O
ph	O
v	O
involves	O
evaluating	O
expectations	O
with	O
respect	O
to	O
q	O
so	O
by	O
designing	O
q	O
to	O
be	O
simple	O
we	O
can	O
simplify	O
the	O
required	O
expectations	O
the	O
opposite	O
direction	O
of	O
the	O
kl	O
divergence	O
would	O
require	O
computing	O
expectations	O
with	O
respect	O
to	O
the	O
true	O
posterior	O
because	O
the	O
form	O
of	O
the	O
true	O
posterior	O
is	O
determined	O
by	O
the	O
choice	O
of	O
model	O
we	O
cannot	O
design	O
a	O
reduced-cost	O
approach	O
to	O
computing	O
d	O
kl	O
q	O
h	O
v	O
p	O
h	O
v	O
exactly	O
discrete	O
latent	O
variables	O
variational	O
inference	O
with	O
discrete	O
latent	O
variables	O
is	O
relatively	O
straightforward	O
we	O
define	O
a	O
distribution	O
q	O
typically	O
one	O
where	O
each	O
factor	O
of	O
q	O
is	O
just	O
defined	O
by	O
a	O
lookup	O
table	O
over	O
discrete	O
states	O
in	O
the	O
simplest	O
case	O
h	O
is	O
binary	O
and	O
we	O
make	O
the	O
mean	O
field	O
assumption	O
that	O
hi	O
in	O
this	O
case	O
we	O
can	O
parametrize	O
q	O
with	O
a	O
vector	O
h	O
whose	O
entries	O
are	O
probabilities	O
then	O
q	O
h	O
i	O
factorizes	O
over	O
each	O
individual	O
hi	O
v	O
q	O
after	O
determining	O
how	O
to	O
represent	O
q	O
we	O
simply	O
optimize	O
its	O
parameters	O
in	O
the	O
case	O
of	O
discrete	O
latent	O
variables	O
this	O
is	O
just	O
a	O
standard	O
optimization	O
problem	O
in	O
principle	O
the	O
selection	O
of	O
q	O
could	O
be	O
done	O
with	O
any	O
optimization	O
algorithm	O
such	O
as	O
gradient	B
descent	O
because	O
this	O
optimization	O
must	O
occur	O
in	O
the	O
inner	O
loop	B
of	O
a	O
learning	O
algorithm	O
it	O
must	O
be	O
very	O
fast	O
to	O
achieve	O
this	O
speed	O
we	O
typically	O
use	O
special	O
optimization	O
algorithms	O
that	O
are	O
designed	O
to	O
solve	O
comparatively	O
small	O
and	O
simple	O
problems	O
in	O
very	O
few	O
iterations	O
a	O
popular	O
choice	O
is	O
to	O
iterate	O
fixed	O
point	O
equations	O
in	O
other	O
words	O
to	O
solve	O
l	O
hi	O
for	O
hi	O
we	O
repeatedly	O
update	O
different	O
elements	O
of	O
h	O
until	O
we	O
satisfy	O
a	O
convergence	O
chapter	O
approximate	B
inference	I
criterion	O
to	O
make	O
this	O
more	O
concrete	O
we	O
show	O
how	O
to	O
apply	O
variational	O
inference	O
to	O
the	O
binary	O
sparse	O
coding	O
model	O
present	O
here	O
the	O
model	O
developed	O
by	O
henniges	O
et	O
al	O
but	O
demonstrate	O
traditional	O
generic	O
mean	O
field	O
applied	O
to	O
the	O
model	O
while	O
they	O
introduce	O
a	O
specialized	O
algorithm	O
this	O
derivation	O
goes	O
into	O
considerable	O
mathematical	O
detail	O
and	O
is	O
intended	O
for	O
the	O
reader	O
who	O
wishes	O
to	O
fully	O
resolve	O
any	O
ambiguity	O
in	O
the	O
high-level	O
conceptual	O
description	O
of	O
variational	O
inference	O
and	O
learning	O
we	O
have	O
presented	O
so	O
far	O
readers	O
who	O
do	O
not	O
plan	O
to	O
derive	O
or	O
implement	O
variational	O
learning	O
algorithms	O
may	O
safely	O
skip	O
to	O
the	O
next	O
section	O
without	O
missing	O
any	O
new	O
high-level	O
concepts	O
readers	O
who	O
proceed	O
with	O
the	O
binary	O
sparse	O
coding	O
example	B
are	O
encouraged	O
to	O
review	O
the	O
list	O
of	O
useful	O
properties	O
of	O
functions	O
that	O
commonly	O
arise	O
in	O
probabilistic	O
models	O
in	O
section	O
we	O
use	O
these	O
properties	O
liberally	O
throughout	O
the	O
following	O
derivations	O
without	O
highlighting	O
exactly	O
where	O
we	O
use	O
each	O
one	O
in	O
the	O
binary	O
sparse	O
coding	O
model	O
the	O
input	O
v	O
n	O
is	O
generated	O
from	O
the	O
model	O
by	O
adding	O
gaussian	O
noise	O
to	O
the	O
sum	O
of	O
m	O
different	O
components	O
which	O
can	O
each	O
be	O
present	O
or	O
absent	O
each	O
component	O
is	O
switched	O
on	O
or	O
off	O
by	O
the	O
corresponding	O
hidden	O
unit	O
in	O
h	O
m	O
r	O
p	O
h	O
i	O
bi	O
n	O
p	O
v	O
h	O
v	O
w	O
h	O
where	O
b	O
is	O
a	O
learnable	O
set	O
of	O
biases	O
w	O
is	O
a	O
learnable	O
weight	O
matrix	O
and	O
is	O
a	O
learnable	O
diagonal	O
precision	B
matrix	O
training	O
this	O
model	O
with	O
maximum	B
likelihood	I
requires	O
taking	O
the	O
derivative	B
with	O
respect	O
to	O
the	O
parameters	O
consider	O
the	O
derivative	B
with	O
respect	O
to	O
one	O
of	O
the	O
biases	O
log	O
v	O
bi	O
b	O
i	O
p	O
p	O
b	O
i	O
p	O
v	O
h	O
p	O
b	O
i	O
h	O
p	O
p	O
v	O
h	O
p	O
h	O
p	O
v	O
h	O
p	O
h	O
v	O
p	O
p	O
b	O
i	O
p	O
bi	O
p	O
h	O
ph	O
v	O
b	O
i	O
log	O
p	O
h	O
chapter	O
approximate	B
inference	I
figure	O
the	O
graph	O
structure	O
of	O
a	O
binary	O
sparse	O
coding	O
model	O
with	O
four	O
hidden	O
units	O
graph	O
structure	O
of	O
ph	O
v	O
note	O
that	O
the	O
edges	O
are	O
directed	O
and	O
that	O
every	O
two	O
hidden	O
units	O
are	O
co-parents	O
of	O
every	O
visible	O
unit	O
ph	O
v	O
in	O
order	O
to	O
account	O
for	O
the	O
active	O
paths	O
between	O
co-parents	O
the	O
posterior	O
distribution	O
needs	O
an	O
edge	O
between	O
all	O
of	O
the	O
hidden	O
units	O
the	O
graph	O
structure	O
of	O
learning	O
instead	O
we	O
can	O
make	O
a	O
mean	O
field	O
approximation	O
is	O
a	O
complicated	O
distribution	O
see	O
figure	O
this	O
requires	O
computing	O
expectations	O
with	O
respect	O
to	O
ph	O
v	O
unfortunately	O
ph	O
v	O
for	O
the	O
graph	O
structure	O
of	O
ph	O
v	O
and	O
ph	O
v	O
the	O
posterior	O
distribution	O
corresponds	O
to	O
the	O
complete	O
graph	O
over	O
the	O
hidden	O
units	O
so	O
variable	O
elimination	O
algorithms	O
do	O
not	O
help	O
us	O
to	O
compute	O
the	O
required	O
expectations	O
any	O
faster	O
than	O
brute	O
force	O
we	O
can	O
resolve	O
this	O
difficulty	O
by	O
using	O
variational	O
inference	O
and	O
variational	O
h	O
v	O
q	O
v	O
q	O
h	O
i	O
i	O
the	O
latent	O
variables	O
of	O
the	O
binary	O
sparse	O
coding	O
model	O
are	O
binary	O
so	O
to	O
represent	O
a	O
factorial	O
q	O
we	O
simply	O
need	O
to	O
model	O
m	O
bernoulli	O
distributions	O
qhi	O
v	O
a	O
natural	O
way	O
to	O
represent	O
the	O
means	O
of	O
the	O
bernoulli	O
distributions	O
is	O
with	O
a	O
vector	O
h	O
of	O
v	O
hi	O
we	O
impose	O
a	O
restriction	O
that	O
h	O
i	O
is	O
never	O
probabilities	O
with	O
qhi	O
equal	O
to	O
or	O
to	O
in	O
order	O
to	O
avoid	O
errors	O
when	O
computing	O
for	O
example	B
log	O
hi	O
hi	O
we	O
will	O
see	O
that	O
the	O
variational	O
inference	O
equations	O
never	O
assign	O
or	O
to	O
chapter	O
approximate	B
inference	I
or	O
analytically	O
however	O
in	O
a	O
software	O
implementation	O
machine	O
rounding	O
error	O
could	O
result	O
in	O
values	O
in	O
software	O
we	O
may	O
wish	O
to	O
implement	O
binary	O
sparse	O
coding	O
using	O
an	O
unrestricted	O
vector	O
of	O
variational	O
parameters	O
z	O
and	O
obtain	O
h	O
via	O
the	O
relation	O
h	O
we	O
can	O
thus	O
safely	O
compute	O
log	O
hi	O
on	O
a	O
computer	O
by	O
using	O
the	O
identity	O
log	O
zi	O
zi	O
relating	O
the	O
sigmoid	O
and	O
the	O
softplus	O
to	O
begin	O
our	O
derivation	O
of	O
variational	O
learning	O
in	O
the	O
binary	O
sparse	O
coding	O
model	O
we	O
show	O
that	O
the	O
use	O
of	O
this	O
mean	O
field	O
approximation	O
makes	O
learning	O
tractable	O
q	O
the	O
evidence	O
lower	O
bound	B
is	O
given	O
by	O
l	O
v	O
qlog	O
qlog	O
log	O
h	O
q	O
p	O
v	O
h	O
p	O
h	O
v	O
log	O
p	O
h	O
m	O
q	O
h	O
v	O
h	O
v	O
log	O
hi	O
hilog	O
bi	O
log	O
eh	O
q	O
log	O
i	O
q	O
m	O
m	O
m	O
n	O
n	O
n	O
log	O
vi	O
log	O
hi	O
hilog	O
hi	O
b	O
i	O
i	O
exp	O
hilog	O
b	O
i	O
hi	O
hi	O
hilog	O
bi	O
log	O
hi	O
log	O
i	O
i	O
i	O
h	O
w	O
ij	O
hj	O
wijwik	O
hj	O
hk	O
j	O
k	O
j	O
while	O
these	O
equations	O
are	O
somewhat	O
unappealing	O
aesthetically	O
they	O
show	O
that	O
can	O
be	O
expressed	O
in	O
a	O
small	O
number	O
of	O
simple	O
arithmetic	O
operations	O
the	O
evidence	O
lower	O
bound	B
as	O
a	O
replacement	O
for	O
the	O
intractable	O
log-likelihood	O
is	O
therefore	O
tractable	O
we	O
can	O
use	O
l	O
l	O
l	O
in	O
principle	O
we	O
could	O
simply	O
run	O
gradient	B
ascent	O
on	O
both	O
v	O
and	O
h	O
and	O
this	O
would	O
make	O
a	O
perfectly	O
acceptable	O
combined	O
inference	O
and	O
training	O
algorithm	O
usually	O
however	O
we	O
do	O
not	O
do	O
this	O
for	O
two	O
reasons	O
first	O
this	O
would	O
require	O
storing	O
h	O
for	O
each	O
v	O
we	O
typically	O
prefer	O
algorithms	O
that	O
do	O
not	O
require	O
perexample	O
memory	O
it	O
is	O
difficult	O
to	O
scale	O
learning	O
algorithms	O
to	O
billions	O
of	O
examples	O
if	O
we	O
must	O
remember	O
a	O
dynamically	O
updated	O
vector	O
associated	O
with	O
each	O
example	B
chapter	O
approximate	B
inference	I
second	O
we	O
would	O
like	O
to	O
be	O
able	O
to	O
extract	O
the	O
features	O
h	O
very	O
quickly	O
in	O
order	O
to	O
recognize	O
the	O
content	O
of	O
v	O
in	O
a	O
realistic	O
deployed	O
setting	O
we	O
would	O
need	O
to	O
be	O
able	O
to	O
compute	O
h	O
in	O
real	O
time	O
for	O
both	O
these	O
reasons	O
we	O
typically	O
do	O
not	O
use	O
gradient	B
descent	O
to	O
compute	O
the	O
mean	O
field	O
parameters	O
h	O
instead	O
we	O
rapidly	O
estimate	O
them	O
with	O
fixed	O
point	O
equations	O
the	O
idea	O
behind	O
fixed	O
point	O
equations	O
is	O
that	O
we	O
are	O
seeking	O
a	O
local	O
maximum	O
with	O
respect	O
to	O
h	O
where	O
h	O
we	O
cannot	O
efficiently	O
solve	O
this	O
equation	O
with	O
respect	O
to	O
all	O
of	O
h	O
simultaneously	O
however	O
we	O
can	O
solve	O
for	O
a	O
single	O
variable	O
h	O
l	O
h	O
l	O
hi	O
we	O
can	O
then	O
iteratively	O
apply	O
the	O
solution	O
to	O
the	O
equation	O
for	O
i	O
m	O
and	O
repeat	O
the	O
cycle	O
until	O
we	O
satisfy	O
a	O
converge	O
criterion	O
common	O
convergence	O
criteria	O
include	O
stopping	O
when	O
a	O
full	O
cycle	O
of	O
updates	O
does	O
not	O
improve	O
by	O
more	O
than	O
some	O
tolerance	O
amount	O
or	O
when	O
the	O
cycle	O
does	O
not	O
change	O
h	O
by	O
more	O
than	O
some	O
amount	O
l	O
iterating	O
mean	O
field	O
fixed	O
point	O
equations	O
is	O
a	O
general	O
technique	O
that	O
can	O
provide	O
fast	O
variational	O
inference	O
in	O
a	O
broad	O
variety	O
of	O
models	O
to	O
make	O
this	O
more	O
concrete	O
we	O
show	O
how	O
to	O
derive	O
the	O
updates	O
for	O
the	O
binary	O
sparse	O
coding	O
model	O
in	O
particular	O
first	O
we	O
must	O
write	O
an	O
expression	O
for	O
the	O
derivatives	O
with	O
respect	O
to	O
hi	O
to	O
do	O
so	O
we	O
substitute	O
equation	O
into	O
the	O
left	O
side	O
of	O
equation	O
hj	O
bj	O
log	O
h	O
j	O
hj	O
bj	O
hi	O
hi	O
h	O
m	O
l	O
n	O
log	O
log	O
bi	O
log	O
j	O
j	O
v	O
j	O
hi	O
w	O
ji	O
n	O
j	O
vjwji	O
hj	O
h	O
k	O
jwj	O
bi	O
log	O
h	O
i	O
w	O
jk	O
hk	O
wjkwjl	O
hk	O
hl	O
l	O
k	O
wjkwji	O
hk	O
k	O
i	O
chapter	O
approximate	B
inference	I
log	O
hi	O
hi	O
v	O
wi	O
w	O
wi	O
wi	O
w	O
hj	O
j	O
i	O
to	O
apply	O
the	O
fixed	O
point	O
update	O
inference	O
rule	O
we	O
solve	O
for	O
the	O
hi	O
that	O
sets	O
equation	O
to	O
hi	O
bi	O
v	O
wi	O
wi	O
w	O
wi	O
w	O
hj	O
j	O
i	O
at	O
this	O
point	O
we	O
can	O
see	O
that	O
there	O
is	O
a	O
close	O
connection	O
between	O
recurrent	O
neural	O
networks	O
and	O
inference	O
in	O
graphical	O
models	O
specifically	O
the	O
mean	O
field	O
fixed	O
point	O
equations	O
defined	O
a	O
recurrent	B
neural	B
network	I
the	O
task	O
of	O
this	O
network	O
is	O
to	O
perform	O
inference	O
we	O
have	O
described	O
how	O
to	O
derive	O
this	O
network	O
from	O
a	O
model	O
description	O
but	O
it	O
is	O
also	O
possible	O
to	O
train	O
the	O
inference	O
network	O
directly	O
several	O
ideas	O
based	O
on	O
this	O
theme	O
are	O
described	O
in	O
chapter	O
in	O
the	O
case	O
of	O
binary	O
sparse	O
coding	O
we	O
can	O
see	O
that	O
the	O
recurrent	B
network	I
connection	O
specified	O
by	O
equation	O
consists	O
of	O
repeatedly	O
updating	O
the	O
hidden	O
units	O
based	O
on	O
the	O
changing	O
values	O
of	O
the	O
neighboring	O
hidden	O
units	O
the	O
input	O
always	O
sends	O
a	O
fixed	O
message	O
of	O
v	O
w	O
to	O
the	O
hidden	O
units	O
but	O
the	O
hidden	O
units	O
constantly	O
update	O
the	O
message	O
they	O
send	O
to	O
each	O
other	O
specifically	O
two	O
units	O
hi	O
and	O
hj	O
inhibit	O
each	O
other	O
when	O
their	O
weight	O
vectors	O
are	O
aligned	O
this	O
is	O
a	O
form	O
of	O
competition	O
between	O
two	O
hidden	O
units	O
that	O
both	O
explain	O
the	O
input	O
only	O
the	O
one	O
that	O
explains	O
the	O
input	O
best	O
will	O
be	O
allowed	O
to	O
remain	O
active	O
this	O
competition	O
is	O
the	O
mean	O
field	O
approximation	O
s	O
attempt	O
to	O
capture	O
the	O
explaining	O
away	O
interactions	O
in	O
the	O
binary	O
sparse	O
coding	O
posterior	O
the	O
explaining	O
away	O
effect	O
actually	O
should	O
cause	O
a	O
multi-modal	O
posterior	O
so	O
that	O
if	O
we	O
draw	O
samples	O
from	O
the	O
posterior	O
some	O
samples	O
will	O
have	O
one	O
unit	O
active	O
other	O
samples	O
will	O
have	O
the	O
other	O
unit	O
active	O
but	O
very	O
few	O
samples	O
have	O
both	O
active	O
unfortunately	O
explaining	O
away	O
interactions	O
cannot	O
be	O
modeled	O
by	O
the	O
factorial	O
q	O
used	O
for	O
mean	O
field	O
so	O
the	O
mean	O
field	O
approximation	O
is	O
forced	O
to	O
choose	O
one	O
mode	O
to	O
model	O
this	O
is	O
an	O
instance	O
of	O
the	O
behavior	O
illustrated	O
in	O
figure	O
we	O
can	O
rewrite	O
equation	O
into	O
an	O
equivalent	O
form	O
that	O
reveals	O
some	O
further	O
insights	O
hi	O
bi	O
v	O
j	O
i	O
wj	O
hj	O
wi	O
wi	O
w	O
hj	O
in	O
this	O
reformulation	O
we	O
see	O
the	O
input	O
at	O
each	O
step	O
as	O
consisting	O
of	O
v	O
rather	O
than	O
v	O
we	O
can	O
thus	O
think	O
of	O
unit	O
i	O
as	O
attempting	O
to	O
encode	O
the	O
residual	O
wj	O
i	O
j	O
chapter	O
approximate	B
inference	I
error	O
in	O
v	O
given	O
the	O
code	O
of	O
the	O
other	O
units	O
we	O
can	O
thus	O
think	O
of	O
sparse	O
coding	O
as	O
an	O
iterative	O
autoencoder	O
that	O
repeatedly	O
encodes	O
and	O
decodes	O
its	O
input	O
attempting	O
to	O
fix	O
mistakes	O
in	O
the	O
reconstruction	O
after	O
each	O
iteration	O
in	O
this	O
example	B
we	O
have	O
derived	O
an	O
update	O
rule	O
that	O
updates	O
a	O
single	O
unit	O
at	O
a	O
time	O
it	O
would	O
be	O
advantageous	O
to	O
be	O
able	O
to	O
update	O
more	O
units	O
simultaneously	O
some	O
graphical	O
models	O
such	O
as	O
deep	O
boltzmann	O
machines	O
are	O
structured	O
in	O
such	O
a	O
way	O
that	O
we	O
can	O
solve	O
for	O
many	O
entries	O
of	O
h	O
simultaneously	O
unfortunately	O
binary	O
sparse	O
coding	O
does	O
not	O
admit	O
such	O
block	O
updates	O
instead	O
we	O
can	O
use	O
a	O
heuristic	O
technique	O
called	O
damping	O
to	O
perform	O
block	O
updates	O
in	O
the	O
damping	O
approach	O
we	O
solve	O
for	O
the	O
individually	O
optimal	O
values	O
of	O
every	O
element	O
of	O
h	O
then	O
move	O
all	O
of	O
the	O
values	O
in	O
a	O
small	O
step	O
in	O
that	O
direction	O
this	O
approach	O
is	O
no	O
longer	O
guaranteed	O
at	O
each	O
step	O
but	O
works	O
well	O
in	O
practice	O
for	O
many	O
models	O
see	O
koller	O
to	O
increase	O
and	O
friedman	O
for	O
more	O
information	O
about	O
choosing	O
the	O
degree	O
of	O
synchrony	O
and	O
damping	O
strategies	O
in	O
message	O
passing	O
algorithms	O
l	O
calculus	B
of	I
variations	I
before	O
continuing	O
with	O
our	O
presentation	O
of	O
variational	O
learning	O
we	O
must	O
briefly	O
introduce	O
an	O
important	O
set	O
of	O
mathematical	O
tools	O
used	O
in	O
variational	O
learning	O
calculus	B
of	I
variations	I
many	O
machine	B
learning	I
techniques	O
are	O
based	O
on	O
minimizing	O
a	O
function	O
j	O
by	O
n	O
for	O
which	O
it	O
takes	O
on	O
its	O
minimal	O
value	O
this	O
can	O
finding	O
the	O
input	O
vector	O
be	O
accomplished	O
with	O
multivariate	O
calculus	O
and	O
linear	O
algebra	O
by	O
solving	O
for	O
the	O
j	O
in	O
some	O
cases	O
we	O
actually	O
want	O
to	O
solve	O
for	O
a	O
critical	O
points	O
where	O
function	O
fx	O
such	O
as	O
when	O
we	O
want	O
to	O
find	O
the	O
probability	B
density	I
function	I
over	O
some	O
random	B
variable	I
this	O
is	O
what	O
calculus	B
of	I
variations	I
enables	O
us	O
to	O
do	O
r	O
a	O
function	O
of	O
a	O
function	O
f	O
is	O
known	O
as	O
a	O
functional	O
j	O
much	O
as	O
we	O
can	O
take	O
partial	O
derivatives	O
of	O
a	O
function	O
with	O
respect	O
to	O
elements	O
of	O
its	O
vectorvalued	O
argument	O
we	O
can	O
take	O
functional	B
derivatives	I
also	O
known	O
as	O
variational	O
derivatives	O
of	O
a	O
functional	O
j	O
f	O
with	O
respect	O
to	O
individual	O
values	O
of	O
the	O
function	O
f	O
at	O
any	O
specific	O
value	O
of	O
x	O
the	O
functional	O
derivative	B
of	O
the	O
functional	O
j	O
with	O
respect	O
to	O
the	O
value	O
of	O
the	O
function	O
is	O
denoted	O
at	O
point	O
j	O
x	O
f	O
f	O
x	O
a	O
complete	O
formal	O
development	O
of	O
functional	B
derivatives	I
is	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
for	O
our	O
purposes	O
it	O
is	O
sufficient	O
to	O
state	O
that	O
for	O
differentiable	O
functions	O
f	O
x	O
with	O
continuous	O
derivatives	O
that	O
and	O
differentiable	O
functions	O
g	O
y	O
f	O
g	O
f	O
x	O
x	O
d	O
y	O
g	O
f	O
x	O
chapter	O
approximate	B
inference	I
to	O
gain	O
some	O
intuition	O
for	O
this	O
identity	O
one	O
can	O
think	O
of	O
fx	O
as	O
being	O
a	O
vector	O
with	O
uncountably	O
many	O
elements	O
indexed	O
by	O
a	O
real	O
vector	O
x	O
in	O
this	O
incomplete	O
view	O
the	O
identity	O
providing	O
the	O
functional	B
derivatives	I
is	O
the	O
same	O
as	O
we	O
would	O
obtain	O
for	O
a	O
vector	O
n	O
indexed	O
by	O
positive	O
integers	O
r	O
i	O
j	O
g	O
j	O
j	O
i	O
g	O
i	O
i	O
many	O
results	O
in	O
other	O
machine	B
learning	I
publications	O
are	O
presented	O
using	O
the	O
more	O
general	O
euler-lagrange	B
equation	I
which	O
allows	O
g	O
to	O
depend	O
on	O
the	O
derivatives	O
of	O
f	O
as	O
well	O
as	O
the	O
value	O
of	O
f	O
but	O
we	O
do	O
not	O
need	O
this	O
fully	O
general	O
form	O
for	O
the	O
results	O
presented	O
in	O
this	O
book	O
to	O
optimize	O
a	O
function	O
with	O
respect	O
to	O
a	O
vector	O
we	O
take	O
the	O
gradient	B
of	O
the	O
function	O
with	O
respect	O
to	O
the	O
vector	O
and	O
solve	O
for	O
the	O
point	O
where	O
every	O
element	O
of	O
the	O
gradient	B
is	O
equal	O
to	O
zero	O
likewise	O
we	O
can	O
optimize	O
a	O
functional	O
by	O
solving	O
for	O
the	O
function	O
where	O
the	O
functional	O
derivative	B
at	O
every	O
point	O
is	O
equal	O
to	O
zero	O
as	O
an	O
example	B
of	O
how	O
this	O
process	O
works	O
consider	O
the	O
problem	O
of	O
finding	O
the	O
r	O
that	O
has	O
maximal	O
differential	O
entropy	O
probability	B
distribution	I
function	O
over	O
x	O
recall	B
that	O
the	O
entropy	O
of	O
a	O
probability	B
distribution	I
is	O
defined	O
as	O
p	O
x	O
h	O
p	O
ex	O
log	O
x	O
for	O
continuous	O
values	O
the	O
expectation	B
is	O
an	O
integral	O
h	O
p	O
p	O
x	O
log	O
p	O
x	O
dx	O
we	O
cannot	O
simply	O
maximize	O
hp	O
with	O
respect	O
to	O
the	O
function	O
px	O
because	O
the	O
result	O
might	O
not	O
be	O
a	O
probability	B
distribution	I
instead	O
we	O
need	O
to	O
use	O
lagrange	O
multipliers	O
to	O
add	O
a	O
constraint	O
that	O
px	O
integrates	O
to	O
also	O
the	O
entropy	O
increases	O
without	O
bound	B
as	O
the	O
variance	O
increases	O
this	O
makes	O
the	O
question	O
of	O
which	O
distribution	O
has	O
the	O
greatest	O
entropy	O
uninteresting	O
instead	O
we	O
ask	O
which	O
distribution	O
has	O
maximal	O
entropy	O
for	O
fixed	O
variance	O
finally	O
the	O
problem	O
is	O
underdetermined	O
because	O
the	O
distribution	O
can	O
be	O
shifted	O
arbitrarily	O
without	O
changing	O
the	O
entropy	O
to	O
impose	O
a	O
unique	O
solution	O
we	O
add	O
a	O
constraint	O
that	O
the	O
mean	O
of	O
the	O
distribution	O
be	O
the	O
lagrangian	O
functional	O
for	O
this	O
optimization	O
problem	O
is	O
l	O
p	O
p	O
p	O
x	O
dx	O
e	O
x	O
x	O
e	O
chapter	O
approximate	B
inference	I
x	O
p	O
x	O
x	O
x	O
x	O
p	O
x	O
log	O
p	O
x	O
dx	O
to	O
minimize	O
the	O
lagrangian	O
with	O
respect	O
to	O
p	O
we	O
set	O
the	O
functional	B
derivatives	I
equal	O
to	O
x	O
l	O
p	O
x	O
x	O
x	O
log	O
p	O
x	O
this	O
condition	O
now	O
tells	O
us	O
the	O
functional	O
form	O
of	O
px	O
by	O
algebraically	O
re-arranging	O
the	O
equation	O
we	O
obtain	O
p	O
x	O
exp	O
x	O
we	O
never	O
assumed	O
directly	O
that	O
p	O
x	O
would	O
take	O
this	O
functional	O
form	O
we	O
obtained	O
the	O
expression	O
itself	O
by	O
analytically	O
minimizing	O
a	O
functional	O
to	O
finish	O
the	O
minimization	O
problem	O
we	O
must	O
choose	O
the	O
values	O
to	O
ensure	O
that	O
all	O
of	O
our	O
constraints	O
are	O
satisfied	O
we	O
are	O
free	O
to	O
choose	O
any	O
values	O
because	O
the	O
gradient	B
of	O
the	O
lagrangian	O
with	O
respect	O
to	O
the	O
variables	O
is	O
zero	O
so	O
long	O
as	O
the	O
constraints	O
are	O
satisfied	O
to	O
satisfy	O
all	O
of	O
the	O
constraints	O
we	O
may	O
set	O
and	O
to	O
obtain	O
log	O
n	O
p	O
x	O
x	O
this	O
is	O
one	O
reason	O
for	O
using	O
the	O
normal	O
distribution	O
when	O
we	O
do	O
not	O
know	O
the	O
true	O
distribution	O
because	O
the	O
normal	O
distribution	O
has	O
the	O
maximum	O
entropy	O
we	O
impose	O
the	O
least	O
possible	O
amount	O
of	O
structure	O
by	O
making	O
this	O
assumption	O
while	O
examining	O
the	O
critical	O
points	O
of	O
the	O
lagrangian	O
functional	O
for	O
the	O
entropy	O
we	O
found	O
only	O
one	O
critical	O
point	O
corresponding	O
to	O
maximizing	O
the	O
entropy	O
for	O
fixed	O
variance	O
what	O
about	O
the	O
probability	B
distribution	I
function	O
that	O
minimizes	O
the	O
entropy	O
why	O
did	O
we	O
not	O
find	O
a	O
second	O
critical	O
point	O
corresponding	O
to	O
the	O
minimum	O
the	O
reason	O
is	O
that	O
there	O
is	O
no	O
specific	O
function	O
that	O
achieves	O
minimal	O
entropy	O
as	O
functions	O
place	O
more	O
probability	O
density	O
on	O
the	O
two	O
points	O
x	O
and	O
x	O
and	O
place	O
less	O
probability	O
density	O
on	O
all	O
other	O
values	O
of	O
x	O
they	O
lose	O
entropy	O
while	O
maintaining	O
the	O
desired	O
variance	O
however	O
any	O
function	O
placing	O
exactly	O
zero	O
mass	O
on	O
all	O
but	O
two	O
points	O
does	O
not	O
integrate	O
to	O
one	O
and	O
is	O
not	O
a	O
valid	O
probability	B
distribution	I
there	O
thus	O
is	O
no	O
single	O
minimal	O
entropy	O
probability	B
distribution	I
function	O
much	O
as	O
there	O
is	O
no	O
single	O
minimal	O
positive	O
real	O
number	O
instead	O
we	O
can	O
say	O
that	O
there	O
is	O
a	O
sequence	O
of	O
probability	O
distributions	O
converging	O
toward	O
putting	O
mass	O
only	O
on	O
these	O
two	O
points	O
this	O
degenerate	O
scenario	O
may	O
be	O
chapter	O
approximate	B
inference	I
described	O
as	O
a	O
mixture	O
of	O
dirac	O
distributions	O
because	O
dirac	O
distributions	O
are	O
not	O
described	O
by	O
a	O
single	O
probability	B
distribution	I
function	O
no	O
dirac	O
or	O
mixture	O
of	O
dirac	O
distribution	O
corresponds	O
to	O
a	O
single	O
specific	O
point	O
in	O
function	O
space	O
these	O
distributions	O
are	O
thus	O
invisible	O
to	O
our	O
method	O
of	O
solving	O
for	O
a	O
specific	O
point	O
where	O
the	O
functional	B
derivatives	I
are	O
zero	O
this	O
is	O
a	O
limitation	O
of	O
the	O
method	O
distributions	O
such	O
as	O
the	O
dirac	O
must	O
be	O
found	O
by	O
other	O
methods	O
such	O
as	O
guessing	O
the	O
solution	O
and	O
then	O
proving	O
that	O
it	O
is	O
correct	O
continuous	O
latent	O
variables	O
when	O
our	O
graphical	O
model	O
contains	O
continuous	O
latent	O
variables	O
we	O
may	O
still	O
perform	O
variational	O
inference	O
and	O
learning	O
by	O
maximizing	O
however	O
we	O
must	O
now	O
use	O
calculus	B
of	I
variations	I
when	O
maximizing	O
with	O
respect	O
to	O
h	O
v	O
l	O
q	O
in	O
most	O
cases	O
practitioners	O
need	O
not	O
solve	O
any	O
calculus	B
of	I
variations	I
problems	O
themselves	O
instead	O
there	O
is	O
a	O
general	O
equation	O
for	O
the	O
mean	O
field	O
fixed	O
point	O
updates	O
if	O
we	O
make	O
the	O
mean	O
field	O
approximation	O
h	O
v	O
q	O
q	O
h	O
i	O
v	O
i	O
l	O
v	O
for	O
all	O
j	O
and	O
fix	O
qhj	O
normalizing	O
the	O
unnormalized	O
distribution	O
qh	O
v	O
exp	O
q	O
h	O
i	O
eh	O
i	O
i	O
i	O
then	O
the	O
optimal	O
qh	O
i	O
v	O
log	O
p	O
h	O
v	O
may	O
be	O
obtained	O
by	O
so	O
long	O
as	O
p	O
does	O
not	O
assign	O
probability	O
to	O
any	O
joint	O
configuration	O
of	O
variables	O
carrying	O
out	O
the	O
expectation	B
inside	O
the	O
equation	O
will	O
yield	O
the	O
correct	O
functional	O
form	O
of	O
qhi	O
v	O
it	O
is	O
only	O
necessary	O
to	O
derive	O
functional	O
forms	O
of	O
q	O
directly	O
using	O
calculus	B
of	I
variations	I
if	O
one	O
wishes	O
to	O
develop	O
a	O
new	O
form	O
of	O
variational	O
learning	O
equation	O
yields	O
the	O
mean	O
field	O
approximation	O
for	O
any	O
probabilistic	O
model	O
equation	O
is	O
a	O
fixed	O
point	O
equation	O
designed	O
to	O
be	O
iteratively	O
applied	O
for	O
each	O
value	O
of	O
i	O
repeatedly	O
until	O
convergence	O
however	O
it	O
also	O
tells	O
us	O
more	O
than	O
that	O
it	O
tells	O
us	O
the	O
functional	O
form	O
that	O
the	O
optimal	O
solution	O
will	O
take	O
whether	O
we	O
arrive	O
there	O
by	O
fixed	O
point	O
equations	O
or	O
not	O
this	O
means	O
we	O
can	O
take	O
the	O
functional	O
form	O
from	O
that	O
equation	O
but	O
regard	O
some	O
of	O
the	O
values	O
that	O
appear	O
in	O
it	O
as	O
parameters	O
that	O
we	O
can	O
optimize	O
with	O
any	O
optimization	O
algorithm	O
we	O
like	O
as	O
an	O
example	B
consider	O
a	O
very	O
simple	O
probabilistic	O
model	O
with	O
latent	O
variables	O
i	O
and	O
h	O
h	O
we	O
could	O
actually	O
simplify	O
this	O
model	O
by	O
integrating	O
pv	O
out	O
h	O
the	O
result	O
is	O
just	O
a	O
gaussian	O
distribution	O
over	O
v	O
the	O
model	O
itself	O
is	O
not	O
and	O
just	O
one	O
visible	O
variable	O
v	O
suppose	O
that	O
ph	O
r	O
h	O
n	O
n	O
chapter	O
approximate	B
inference	I
interesting	O
we	O
have	O
constructed	O
it	O
only	O
to	O
provide	O
a	O
simple	O
demonstration	O
of	O
how	O
calculus	B
of	I
variations	I
may	O
be	O
applied	O
to	O
probabilistic	O
modeling	O
the	O
true	O
posterior	O
is	O
given	O
up	O
to	O
a	O
normalizing	O
constant	O
by	O
p	O
h	O
v	O
p	O
v	O
p	O
v	O
h	O
exp	O
h	O
exp	O
v	O
due	O
to	O
the	O
presence	O
of	O
the	O
terms	O
multiplying	O
and	O
together	O
we	O
can	O
see	O
that	O
the	O
true	O
posterior	O
does	O
not	O
factorize	O
over	O
and	O
applying	O
equation	O
we	O
find	O
that	O
v	O
log	O
p	O
h	O
v	O
v	O
q	O
h	O
exp	O
exp	O
from	O
this	O
we	O
can	O
see	O
that	O
there	O
are	O
effectively	O
only	O
two	O
values	O
we	O
need	O
to	O
obtain	O
from	O
qh	O
we	O
obtain	O
qh	O
v	O
and	O
writing	O
these	O
as	O
qh	O
v	O
eh	O
and	O
q	O
h	O
v	O
exp	O
h	O
h	O
w	O
n	O
from	O
this	O
we	O
can	O
see	O
that	O
q	O
has	O
the	O
functional	O
form	O
of	O
a	O
gaussian	O
we	O
can	O
where	O
and	O
diagonal	O
are	O
variational	O
thus	O
conclude	O
q	O
v	O
parameters	O
that	O
we	O
can	O
optimize	O
using	O
any	O
technique	O
we	O
choose	O
it	O
is	O
important	O
to	O
recall	B
that	O
we	O
did	O
not	O
ever	O
assume	O
that	O
q	O
would	O
be	O
gaussian	O
its	O
gaussian	O
form	O
was	O
derived	O
automatically	O
by	O
using	O
calculus	B
of	I
variations	I
to	O
maximize	O
q	O
with	O
chapter	O
approximate	B
inference	I
l	O
respect	O
to	O
functional	O
form	O
of	O
using	O
the	O
same	O
approach	O
on	O
a	O
different	O
model	O
could	O
yield	O
a	O
different	O
this	O
was	O
of	O
course	O
just	O
a	O
small	O
case	O
constructed	O
for	O
demonstration	O
purposes	O
for	O
examples	O
of	O
real	O
applications	O
of	O
variational	O
learning	O
with	O
continuous	O
variables	O
in	O
the	O
context	O
of	O
deep	O
learning	O
see	O
goodfellow	O
et	O
al	O
interactions	O
between	O
learning	O
and	O
inference	O
using	O
approximate	B
inference	I
as	O
part	O
of	O
a	O
learning	O
algorithm	O
affects	O
the	O
learning	O
process	O
and	O
this	O
in	O
turn	O
affects	O
the	O
accuracy	B
of	O
the	O
inference	O
algorithm	O
specifically	O
the	O
training	O
algorithm	O
tends	O
to	O
adapt	O
the	O
model	O
in	O
a	O
way	O
that	O
makes	O
the	O
approximating	O
assumptions	O
underlying	O
the	O
approximate	B
inference	I
algorithm	O
become	O
more	O
true	O
when	O
training	O
the	O
parameters	O
variational	O
learning	O
increases	O
q	O
log	O
eh	O
for	O
a	O
specific	O
v	O
this	O
increases	O
ph	O
v	O
under	O
qh	O
v	O
and	O
decreases	O
ph	O
v	O
under	O
h	O
v	O
q	O
p	O
v	O
h	O
for	O
values	O
of	O
h	O
that	O
have	O
high	O
probability	O
for	O
values	O
of	O
h	O
that	O
have	O
low	O
probability	O
this	O
behavior	O
causes	O
our	O
approximating	O
assumptions	O
to	O
become	O
self-fulfilling	O
prophecies	O
if	O
we	O
train	O
the	O
model	O
with	O
a	O
unimodal	O
approximate	O
posterior	O
we	O
will	O
obtain	O
a	O
model	O
with	O
a	O
true	O
posterior	O
that	O
is	O
far	O
closer	O
to	O
unimodal	O
than	O
we	O
would	O
have	O
obtained	O
by	O
training	O
the	O
model	O
with	O
exact	O
inference	O
l	O
computing	O
the	O
true	O
amount	O
of	O
harm	O
imposed	O
on	O
a	O
model	O
by	O
a	O
variational	O
approximation	O
is	O
thus	O
very	O
difficult	O
there	O
exist	O
several	O
methods	O
for	O
estimating	O
log	O
pv	O
we	O
often	O
estimate	O
log	O
pv	O
after	O
training	O
the	O
model	O
and	O
find	O
that	O
q	O
is	O
small	O
from	O
this	O
we	O
can	O
conclude	O
that	O
our	O
variational	O
the	O
gap	O
with	O
approximation	O
is	O
accurate	O
for	O
the	O
specific	O
value	O
of	O
that	O
we	O
obtained	O
from	O
the	O
learning	O
process	O
we	O
should	O
not	O
conclude	O
that	O
our	O
variational	O
approximation	O
is	O
accurate	O
in	O
general	O
or	O
that	O
the	O
variational	O
approximation	O
did	O
little	O
harm	O
to	O
the	O
learning	O
process	O
to	O
measure	O
the	O
true	O
amount	O
of	O
harm	O
induced	O
by	O
the	O
variational	O
l	O
max	O
log	O
p	O
v	O
it	O
is	O
possible	O
for	O
approximation	O
we	O
would	O
need	O
to	O
know	O
l	O
log	O
pv	O
q	O
to	O
hold	O
simultaneously	O
if	O
maxq	O
because	O
induces	O
too	O
complicated	O
of	O
a	O
posterior	O
distribution	O
for	O
our	O
q	O
family	O
to	O
capture	O
then	O
the	O
learning	O
process	O
will	O
never	O
approach	O
such	O
a	O
problem	O
is	O
very	O
difficult	O
to	O
detect	O
because	O
we	O
can	O
only	O
know	O
for	O
sure	O
that	O
it	O
happened	O
if	O
we	O
have	O
a	O
superior	O
learning	O
algorithm	O
that	O
can	O
find	O
for	O
comparison	O
log	O
pv	O
and	O
log	O
p	O
q	O
log	O
pv	O
chapter	O
approximate	B
inference	I
learned	O
approximate	B
inference	I
l	O
we	O
have	O
seen	O
that	O
inference	O
can	O
be	O
thought	O
of	O
as	O
an	O
optimization	O
procedure	O
that	O
increases	O
the	O
value	O
of	O
a	O
function	O
explicitly	O
performing	O
optimization	O
via	O
iterative	O
procedures	O
such	O
as	O
fixed	O
point	O
equations	O
or	O
gradient-based	O
optimization	O
is	O
often	O
very	O
expensive	O
and	O
time-consuming	O
many	O
approaches	O
to	O
inference	O
avoid	O
this	O
expense	O
by	O
learning	O
to	O
perform	O
approximate	B
inference	I
specifically	O
we	O
can	O
l	O
think	O
of	O
the	O
optimization	O
process	O
as	O
a	O
function	O
f	O
that	O
maps	O
an	O
input	O
v	O
to	O
an	O
approximate	O
distribution	O
q	O
q	O
once	O
we	O
think	O
of	O
the	O
multi-step	O
iterative	O
optimization	O
process	O
as	O
just	O
being	O
a	O
function	O
we	O
can	O
approximate	O
it	O
with	O
a	O
neural	B
network	I
that	O
implements	O
an	O
approximation	O
f	O
arg	O
maxq	O
wake-sleep	O
et	O
al	O
frey	O
one	O
of	O
the	O
main	O
difficulties	O
with	O
training	O
a	O
model	O
to	O
infer	O
h	O
from	O
v	O
is	O
that	O
we	O
do	O
not	O
have	O
a	O
supervised	O
training	O
set	O
with	O
which	O
to	O
train	O
the	O
model	O
given	O
a	O
v	O
we	O
do	O
not	O
know	O
the	O
appropriate	O
h	O
the	O
mapping	O
from	O
v	O
to	O
h	O
depends	O
on	O
the	O
choice	O
of	O
model	O
family	O
and	O
evolves	O
throughout	O
the	O
learning	O
process	O
as	O
changes	O
the	O
wake-sleep	O
algorithm	O
resolves	O
this	O
problem	O
by	O
drawing	O
samples	O
of	O
both	O
h	O
and	O
v	O
from	O
the	O
model	O
distribution	O
for	O
example	B
in	O
a	O
directed	O
model	O
this	O
can	O
be	O
done	O
cheaply	O
by	O
performing	O
ancestral	O
sampling	O
beginning	O
at	O
h	O
and	O
ending	O
at	O
v	O
the	O
inference	O
network	O
can	O
then	O
be	O
trained	O
to	O
perform	O
the	O
reverse	O
mapping	O
predicting	O
which	O
h	O
caused	O
the	O
present	O
v	O
the	O
main	O
drawback	O
to	O
this	O
approach	O
is	O
that	O
we	O
will	O
only	O
be	O
able	O
to	O
train	O
the	O
inference	O
network	O
on	O
values	O
of	O
v	O
that	O
have	O
high	O
probability	O
under	O
the	O
model	O
early	O
in	O
learning	O
the	O
model	O
distribution	O
will	O
not	O
resemble	O
the	O
data	O
distribution	O
so	O
the	O
inference	O
network	O
will	O
not	O
have	O
an	O
opportunity	O
to	O
learn	O
on	O
samples	O
that	O
resemble	O
data	O
et	O
al	O
in	O
section	O
we	O
saw	O
that	O
one	O
possible	O
explanation	O
for	O
the	O
role	O
of	O
dream	O
sleep	O
in	O
human	O
beings	O
and	O
animals	O
is	O
that	O
dreams	O
could	O
provide	O
the	O
negative	O
phase	O
samples	O
that	O
monte	O
carlo	O
training	O
algorithms	O
use	O
to	O
approximate	O
the	O
negative	O
gradient	B
of	O
the	O
log	O
partition	O
function	O
of	O
undirected	O
models	O
another	O
possible	O
explanation	O
for	O
biological	O
dreaming	O
is	O
that	O
it	O
is	O
providing	O
samples	O
from	O
ph	O
v	O
which	O
can	O
be	O
used	O
to	O
train	O
an	O
inference	O
network	O
to	O
predict	O
h	O
given	O
v	O
in	O
some	O
senses	O
this	O
explanation	O
is	O
more	O
satisfying	O
than	O
the	O
partition	O
function	O
explanation	O
monte	O
carlo	O
algorithms	O
generally	O
do	O
not	O
perform	O
well	O
if	O
they	O
are	O
run	O
using	O
only	O
the	O
positive	O
phase	O
of	O
the	O
gradient	B
for	O
several	O
steps	O
then	O
with	O
only	O
the	O
negative	O
phase	O
of	O
the	O
gradient	B
for	O
several	O
steps	O
human	O
beings	O
and	O
animals	O
are	O
usually	O
awake	O
for	O
several	O
consecutive	O
hours	O
then	O
asleep	O
for	O
several	O
consecutive	O
hours	O
it	O
is	O
chapter	O
approximate	B
inference	I
l	O
not	O
readily	O
apparent	O
how	O
this	O
schedule	O
could	O
support	O
monte	O
carlo	O
training	O
of	O
an	O
undirected	B
model	I
learning	O
algorithms	O
based	O
on	O
maximizing	O
can	O
be	O
run	O
with	O
prolonged	O
periods	O
of	O
improving	O
q	O
and	O
prolonged	O
periods	O
of	O
improving	O
however	O
if	O
the	O
role	O
of	O
biological	O
dreaming	O
is	O
to	O
train	O
networks	O
for	O
predicting	O
q	O
then	O
this	O
explains	O
how	O
animals	O
are	O
able	O
to	O
remain	O
awake	O
for	O
several	O
hours	O
longer	O
they	O
are	O
awake	O
the	O
greater	O
the	O
gap	O
between	O
will	O
remain	O
a	O
lower	O
bound	B
and	O
to	O
remain	O
asleep	O
for	O
several	O
hours	O
generative	O
model	O
itself	O
is	O
not	O
modified	O
during	O
sleep	O
without	O
damaging	O
their	O
internal	O
models	O
of	O
course	O
these	O
ideas	O
are	O
purely	O
speculative	O
and	O
there	O
is	O
no	O
hard	O
evidence	O
to	O
suggest	O
that	O
dreaming	O
accomplishes	O
either	O
of	O
these	O
goals	O
dreaming	O
may	O
also	O
serve	O
reinforcement	O
learning	O
rather	O
than	O
probabilistic	O
modeling	O
by	O
sampling	O
synthetic	O
experiences	O
from	O
the	O
animal	O
s	O
transition	O
model	O
on	O
which	O
to	O
train	O
the	O
animal	O
s	O
policy	B
or	O
sleep	O
may	O
serve	O
some	O
other	O
purpose	O
not	O
yet	O
anticipated	O
by	O
the	O
machine	B
learning	I
community	O
and	O
log	O
pv	O
but	O
l	O
l	O
other	O
forms	O
of	O
learned	O
inference	O
this	O
strategy	O
of	O
learned	O
approximate	B
inference	I
has	O
also	O
been	O
applied	O
to	O
other	O
models	O
salakhutdinov	O
and	O
larochelle	O
showed	O
that	O
a	O
single	O
pass	O
in	O
a	O
learned	O
inference	O
network	O
could	O
yield	O
faster	O
inference	O
than	O
iterating	O
the	O
mean	O
field	O
fixed	O
point	O
equations	O
in	O
a	O
dbm	O
the	O
training	O
procedure	O
is	O
based	O
on	O
running	O
the	O
inference	O
network	O
then	O
applying	O
one	O
step	O
of	O
mean	O
field	O
to	O
improve	O
its	O
estimates	O
and	O
training	O
the	O
inference	O
network	O
to	O
output	O
this	O
refined	O
estimate	O
instead	O
of	O
its	O
original	O
estimate	O
we	O
have	O
already	O
seen	O
in	O
section	O
that	O
the	O
predictive	B
sparse	I
decomposition	I
model	O
trains	O
a	O
shallow	O
encoder	B
network	O
to	O
predict	O
a	O
sparse	O
code	O
for	O
the	O
input	O
this	O
can	O
be	O
seen	O
as	O
a	O
hybrid	O
between	O
an	O
autoencoder	O
and	O
sparse	O
coding	O
it	O
is	O
possible	O
to	O
devise	O
probabilistic	O
semantics	O
for	O
the	O
model	O
under	O
which	O
the	O
encoder	B
may	O
be	O
viewed	O
as	O
performing	O
learned	O
approximate	O
map	O
inference	O
due	O
to	O
its	O
shallow	O
encoder	B
psd	O
is	O
not	O
able	O
to	O
implement	O
the	O
kind	O
of	O
competition	O
between	O
units	O
that	O
we	O
have	O
seen	O
in	O
mean	O
field	O
inference	O
however	O
that	O
problem	O
can	O
be	O
remedied	O
by	O
training	O
a	O
deep	O
encoder	B
to	O
perform	O
learned	O
approximate	B
inference	I
as	O
in	O
the	O
ista	O
technique	O
gregor	O
and	O
lecun	O
learned	O
approximate	B
inference	I
has	O
recently	O
become	O
one	O
of	O
the	O
dominant	O
approaches	O
to	O
generative	O
modeling	O
in	O
the	O
form	O
of	O
the	O
variational	O
autoencoder	O
kingma	O
rezende	O
et	O
al	O
in	O
this	O
elegant	O
approach	O
there	O
is	O
no	O
need	O
to	O
construct	O
explicit	O
targets	O
for	O
the	O
inference	O
network	O
instead	O
the	O
inference	O
network	O
l	O
and	O
then	O
the	O
parameters	O
of	O
the	O
inference	O
network	O
are	O
is	O
simply	O
used	O
to	O
define	O
adapted	O
to	O
increase	O
this	O
model	O
is	O
described	O
in	O
depth	O
later	O
in	O
section	O
l	O
chapter	O
approximate	B
inference	I
using	O
approximate	B
inference	I
it	O
is	O
possible	O
to	O
train	O
and	O
use	O
a	O
wide	O
variety	O
of	O
models	O
many	O
of	O
these	O
models	O
are	O
described	O
in	O
the	O
next	O
chapter	O
chapter	O
deep	O
generative	O
models	O
in	O
this	O
chapter	O
we	O
present	O
several	O
of	O
the	O
specific	O
kinds	O
of	O
generative	O
models	O
that	O
can	O
be	O
built	O
and	O
trained	O
using	O
the	O
techniques	O
presented	O
in	O
chapters	O
all	O
of	O
these	O
models	O
represent	O
probability	O
distributions	O
over	O
multiple	O
variables	O
in	O
some	O
way	O
some	O
allow	O
the	O
probability	B
distribution	I
function	O
to	O
be	O
evaluated	O
explicitly	O
others	O
do	O
not	O
allow	O
the	O
evaluation	O
of	O
the	O
probability	B
distribution	I
function	O
but	O
support	O
operations	O
that	O
implicitly	O
require	O
knowledge	O
of	O
it	O
such	O
as	O
drawing	O
samples	O
from	O
the	O
distribution	O
some	O
of	O
these	O
models	O
are	O
structured	O
probabilistic	O
models	O
described	O
in	O
terms	O
of	O
graphs	O
and	O
factors	O
using	O
the	O
language	O
of	O
graphical	O
models	O
presented	O
in	O
chapter	O
others	O
can	O
not	O
easily	O
be	O
described	O
in	O
terms	O
of	O
factors	O
but	O
represent	O
probability	O
distributions	O
nonetheless	O
boltzmann	O
machines	O
ackley	O
et	O
al	O
hinton	O
boltzmann	O
machines	O
were	O
originally	O
introduced	O
as	O
a	O
general	O
connectionist	O
approach	O
to	O
learning	O
arbitrary	O
probability	O
distributions	O
over	O
binary	O
vectors	O
et	O
al	O
hinton	O
and	O
sejnowski	O
variants	O
of	O
the	O
boltzmann	O
machine	O
that	O
include	O
other	O
kinds	O
of	O
variables	O
have	O
long	O
ago	O
surpassed	O
the	O
popularity	O
of	O
the	O
original	O
in	O
this	O
section	O
we	O
briefly	O
introduce	O
the	O
binary	O
boltzmann	O
machine	O
and	O
discuss	O
the	O
issues	O
that	O
come	O
up	O
when	O
trying	O
to	O
train	O
and	O
perform	O
inference	O
in	O
the	O
model	O
we	O
define	O
the	O
boltzmann	O
machine	O
over	O
a	O
d-dimensional	O
binary	O
random	O
vector	O
d	O
the	O
boltzmann	O
machine	O
is	O
an	O
energy-based	O
model	O
et	O
al	O
x	O
chapter	O
deep	O
generative	O
models	O
meaning	O
we	O
define	O
the	O
joint	B
probability	B
distribution	I
using	O
an	O
energy	B
function	I
e	O
x	O
exp	O
z	O
p	O
x	O
where	O
ex	O
is	O
the	O
energy	B
function	I
and	O
z	O
is	O
the	O
partition	O
function	O
that	O
ensures	O
that	O
the	O
energy	B
function	I
of	O
the	O
boltzmann	O
machine	O
is	O
given	O
by	O
p	O
x	O
x	O
e	O
x	O
u	O
x	O
b	O
x	O
where	O
u	O
is	O
the	O
weight	O
matrix	O
of	O
model	O
parameters	O
and	O
b	O
is	O
the	O
vector	O
of	O
bias	O
parameters	O
in	O
the	O
general	O
setting	O
of	O
the	O
boltzmann	O
machine	O
we	O
are	O
given	O
a	O
set	O
of	O
training	O
examples	O
each	O
of	O
which	O
are	O
n-dimensional	O
equation	O
describes	O
the	O
joint	B
probability	B
distribution	I
over	O
the	O
observed	O
variables	O
while	O
this	O
scenario	O
is	O
certainly	O
viable	O
it	O
does	O
limit	O
the	O
kinds	O
of	O
interactions	O
between	O
the	O
observed	O
variables	O
to	O
those	O
described	O
by	O
the	O
weight	O
matrix	O
specifically	O
it	O
means	O
that	O
the	O
probability	O
of	O
one	O
unit	O
being	O
on	O
is	O
given	O
by	O
a	O
linear	O
model	O
regression	B
from	O
the	O
values	O
of	O
the	O
other	O
units	O
the	O
boltzmann	O
machine	O
becomes	O
more	O
powerful	O
when	O
not	O
all	O
the	O
variables	O
are	O
observed	O
in	O
this	O
case	O
the	O
latent	O
variables	O
can	O
act	O
similarly	O
to	O
hidden	O
units	O
in	O
a	O
multi-layer	O
perceptron	O
and	O
model	O
higher-order	O
interactions	O
among	O
the	O
visible	O
units	O
just	O
as	O
the	O
addition	O
of	O
hidden	O
units	O
to	O
convert	O
logistic	O
regression	B
into	O
an	O
mlp	O
results	O
in	O
the	O
mlp	O
being	O
a	O
universal	B
approximator	I
of	O
functions	O
a	O
boltzmann	O
machine	O
with	O
hidden	O
units	O
is	O
no	O
longer	O
limited	O
to	O
modeling	O
linear	O
relationships	O
between	O
variables	O
instead	O
the	O
boltzmann	O
machine	O
becomes	O
a	O
universal	B
approximator	I
of	O
probability	O
mass	O
functions	O
over	O
discrete	O
variables	O
le	O
roux	O
and	O
bengio	O
formally	O
we	O
decompose	O
the	O
units	O
x	O
into	O
two	O
subsets	O
the	O
visible	O
units	O
v	O
and	O
the	O
latent	O
hidden	O
units	O
h	O
v	O
e	O
h	O
rv	O
the	O
energy	B
function	I
becomes	O
v	O
w	O
h	O
h	O
sh	O
b	O
c	O
v	O
h	O
boltzmann	O
machine	B
learning	I
learning	O
algorithms	O
for	O
boltzmann	O
machines	O
are	O
usually	O
based	O
on	O
maximum	B
likelihood	I
all	O
boltzmann	O
machines	O
have	O
an	O
intractable	O
partition	O
function	O
so	O
the	O
maximum	B
likelihood	I
gradient	B
must	O
be	O
approximated	O
using	O
the	O
techniques	O
described	O
in	O
chapter	O
one	O
interesting	O
property	O
of	O
boltzmann	O
machines	O
when	O
trained	O
with	O
learning	O
rules	O
based	O
on	O
maximum	B
likelihood	I
is	O
that	O
the	O
update	O
for	O
a	O
particular	O
weight	O
connecting	O
two	O
units	O
depends	O
only	O
the	O
statistics	O
of	O
those	O
two	O
units	O
collected	O
under	O
different	O
distributions	O
pmodelv	O
and	O
pdatavpmodelh	O
v	O
the	O
rest	O
of	O
the	O
chapter	O
deep	O
generative	O
models	O
network	O
participates	O
in	O
shaping	O
those	O
statistics	O
but	O
the	O
weight	O
can	O
be	O
updated	O
without	O
knowing	O
anything	O
about	O
the	O
rest	O
of	O
the	O
network	O
or	O
how	O
those	O
statistics	O
were	O
produced	O
this	O
means	O
that	O
the	O
learning	O
rule	O
is	O
local	O
which	O
makes	O
boltzmann	O
machine	B
learning	I
somewhat	O
biologically	O
plausible	O
it	O
is	O
conceivable	O
that	O
if	O
each	O
neuron	O
were	O
a	O
random	B
variable	I
in	O
a	O
boltzmann	O
machine	O
then	O
the	O
axons	O
and	O
dendrites	O
connecting	O
two	O
random	O
variables	O
could	O
learn	O
only	O
by	O
observing	O
the	O
firing	O
pattern	O
of	O
the	O
cells	O
that	O
they	O
actually	O
physically	O
touch	O
in	O
particular	O
in	O
the	O
positive	O
phase	O
two	O
units	O
that	O
frequently	O
activate	O
together	O
have	O
their	O
connection	O
strengthened	O
this	O
is	O
an	O
example	B
of	O
a	O
hebbian	O
learning	O
rule	O
often	O
summarized	O
with	O
the	O
mnemonic	O
fire	O
together	O
wire	O
together	O
hebbian	O
learning	O
rules	O
are	O
among	O
the	O
oldest	O
hypothesized	O
explanations	O
for	O
learning	O
in	O
biological	O
systems	O
and	O
remain	O
relevant	O
today	O
giudice	O
et	O
al	O
hebb	O
other	O
learning	O
algorithms	O
that	O
use	O
more	O
information	O
than	O
local	O
statistics	O
seem	O
to	O
require	O
us	O
to	O
hypothesize	O
the	O
existence	O
of	O
more	O
machinery	O
than	O
this	O
for	O
example	B
for	O
the	O
brain	O
to	O
implement	O
back-propagation	B
in	O
a	O
multilayer	B
perceptron	I
it	O
seems	O
necessary	O
for	O
the	O
brain	O
to	O
maintain	O
a	O
secondary	O
communication	O
network	O
for	O
transmitting	O
gradient	B
information	O
backwards	O
through	O
the	O
network	O
proposals	O
for	O
biologically	O
plausible	O
implementations	O
approximations	O
of	O
back-propagation	B
have	O
been	O
made	O
but	O
remain	O
to	O
be	O
validated	O
and	O
bengio	O
links	O
back-propagation	B
of	O
gradients	O
to	O
inference	O
in	O
energy-based	O
models	O
similar	O
to	O
the	O
boltzmann	O
machine	O
with	O
continuous	O
latent	O
variables	O
hinton	O
bengio	O
the	O
negative	O
phase	O
of	O
boltzmann	O
machine	B
learning	I
is	O
somewhat	O
harder	O
to	O
explain	O
from	O
a	O
biological	O
point	O
of	O
view	O
as	O
argued	O
in	O
section	O
dream	O
sleep	O
may	O
be	O
a	O
form	O
of	O
negative	O
phase	O
sampling	O
this	O
idea	O
is	O
more	O
speculative	O
though	O
restricted	O
boltzmann	O
machines	O
smolensky	O
restricted	O
boltzmann	O
invented	O
under	O
the	O
name	O
harmonium	O
machines	O
are	O
some	O
of	O
the	O
most	O
common	O
building	O
blocks	O
of	O
deep	O
probabilistic	O
models	O
we	O
have	O
briefly	O
described	O
rbms	O
previously	O
in	O
section	O
here	O
we	O
review	O
the	O
previous	O
information	O
and	O
go	O
into	O
more	O
detail	O
rbms	O
are	O
undirected	O
probabilistic	O
graphical	O
models	O
containing	O
a	O
layer	O
of	O
observable	O
variables	O
and	O
a	O
single	O
layer	O
of	O
latent	O
variables	O
rbms	O
may	O
be	O
stacked	O
on	O
top	O
of	O
the	O
other	O
to	O
form	O
deeper	O
models	O
see	O
figure	O
a	O
shows	O
the	O
graph	O
structure	O
of	O
the	O
rbm	O
itself	O
it	O
is	O
a	O
bipartite	O
graph	O
with	O
no	O
connections	O
permitted	O
between	O
any	O
variables	O
in	O
the	O
observed	O
layer	O
or	O
between	O
any	O
units	O
in	O
the	O
latent	O
layer	O
for	O
some	O
examples	O
in	O
particular	O
figure	O
chapter	O
deep	O
generative	O
models	O
figure	O
examples	O
of	O
models	O
that	O
may	O
be	O
built	O
with	O
restricted	O
boltzmann	O
machines	O
restricted	O
boltzmann	O
machine	O
itself	O
is	O
an	O
undirected	O
graphical	O
model	O
based	O
on	O
a	O
bipartite	O
graph	O
with	O
visible	O
units	O
in	O
one	O
part	O
of	O
the	O
graph	O
and	O
hidden	O
units	O
in	O
the	O
other	O
part	O
there	O
are	O
no	O
connections	O
among	O
the	O
visible	O
units	O
nor	O
any	O
connections	O
among	O
the	O
hidden	O
units	O
typically	O
every	O
visible	O
unit	O
is	O
connected	O
to	O
every	O
hidden	O
unit	O
but	O
it	O
is	O
possible	O
to	O
construct	O
sparsely	O
connected	O
rbms	O
such	O
as	O
convolutional	O
rbms	O
ab	O
deep	O
belief	O
network	O
is	O
a	O
hybrid	O
graphical	O
model	O
involving	O
both	O
directed	O
and	O
undirected	O
connections	O
like	O
an	O
rbm	O
it	O
has	O
no	O
intralayer	O
connections	O
however	O
a	O
dbn	O
has	O
multiple	O
hidden	O
layers	O
and	O
thus	O
there	O
are	O
connections	O
between	O
hidden	O
units	O
that	O
are	O
in	O
separate	O
layers	O
all	O
of	O
the	O
local	O
conditional	B
probability	I
distributions	O
needed	O
by	O
the	O
deep	O
belief	O
network	O
are	O
copied	O
directly	O
from	O
the	O
local	O
conditional	B
probability	I
distributions	O
of	O
its	O
constituent	O
rbms	O
alternatively	O
we	O
could	O
also	O
represent	O
the	O
deep	O
belief	O
network	O
with	O
a	O
completely	O
undirected	O
graph	O
but	O
it	O
would	O
need	O
intralayer	O
connections	O
to	O
capture	O
the	O
dependencies	O
between	O
parents	O
a	O
deep	O
boltzmann	O
machine	O
is	O
an	O
undirected	O
graphical	O
model	O
with	O
several	O
layers	O
of	O
latent	O
variables	O
like	O
rbms	O
and	O
dbns	O
dbms	O
lack	O
intralayer	O
connections	O
dbms	O
are	O
less	O
closely	O
tied	O
to	O
rbms	O
than	O
dbns	O
are	O
when	O
initializing	O
a	O
dbm	O
from	O
a	O
stack	O
of	O
rbms	O
it	O
is	O
necessary	O
to	O
modify	O
the	O
rbm	O
parameters	O
slightly	O
some	O
kinds	O
of	O
dbms	O
may	O
be	O
trained	O
without	O
first	O
training	O
a	O
set	O
of	O
rbms	O
chapter	O
deep	O
generative	O
models	O
we	O
begin	O
with	O
the	O
binary	O
version	O
of	O
the	O
restricted	O
boltzmann	O
machine	O
but	O
as	O
we	O
see	O
later	O
there	O
are	O
extensions	O
to	O
other	O
types	O
of	O
visible	O
and	O
hidden	O
units	O
more	O
formally	O
let	O
the	O
observed	O
layer	O
consist	O
of	O
a	O
set	O
of	O
n	O
v	O
binary	O
random	O
variables	O
which	O
we	O
refer	O
to	O
collectively	O
with	O
the	O
vector	O
v	O
we	O
refer	O
to	O
the	O
latent	O
or	O
hidden	B
layer	I
of	O
nh	O
binary	O
random	O
variables	O
as	O
like	O
the	O
general	O
boltzmann	O
machine	O
the	O
restricted	O
boltzmann	O
machine	O
is	O
an	O
energy-based	O
model	O
with	O
the	O
joint	B
probability	B
distribution	I
specified	O
by	O
its	O
energy	B
function	I
p	O
v	O
v	O
h	O
e	O
v	O
h	O
exp	O
z	O
the	O
energy	B
function	I
for	O
an	O
rbm	O
is	O
given	O
by	O
c	O
b	O
e	O
h	O
v	O
h	O
v	O
w	O
h	O
and	O
z	O
is	O
the	O
normalizing	O
constant	O
known	O
as	O
the	O
partition	O
function	O
e	O
v	O
h	O
z	O
exp	O
v	O
h	O
it	O
is	O
apparent	O
from	O
the	O
definition	O
of	O
the	O
partition	O
function	O
z	O
that	O
the	O
naive	O
method	O
of	O
computing	O
z	O
summing	O
over	O
all	O
states	O
could	O
be	O
computationally	O
intractable	O
unless	O
a	O
cleverly	O
designed	O
algorithm	O
could	O
exploit	O
regularities	O
in	O
the	O
probability	B
distribution	I
to	O
compute	O
z	O
faster	O
in	O
the	O
case	O
of	O
restricted	O
boltzmann	O
z	O
machines	O
is	O
intractable	O
the	O
intractable	O
partition	O
function	O
z	O
implies	O
that	O
the	O
normalized	O
joint	B
probability	B
distribution	I
formally	O
proved	O
that	O
the	O
partition	O
function	O
is	O
also	O
intractable	O
to	O
evaluate	O
long	O
and	O
servedio	O
p	O
conditional	O
distributions	O
though	O
p	O
is	O
intractable	O
the	O
bipartite	O
graph	O
structure	O
of	O
the	O
rbm	O
has	O
the	O
very	O
special	O
property	O
that	O
its	O
conditional	O
distributions	O
ph	O
v	O
are	O
factorial	O
and	O
relatively	O
simple	O
to	O
compute	O
and	O
to	O
sample	O
from	O
and	O
p	O
h	O
deriving	O
the	O
conditional	O
distributions	O
from	O
the	O
joint	O
distribution	O
is	O
straightfor	O
h	O
v	O
w	O
h	O
ward	O
h	O
v	O
p	O
p	O
v	O
p	O
p	O
z	O
exp	O
z	O
v	O
b	O
c	O
exp	O
c	O
h	O
v	O
w	O
h	O
chapter	O
deep	O
generative	O
models	O
nh	O
exp	O
z	O
z	O
nh	O
exp	O
wj	O
hj	O
nh	O
v	O
cjhj	O
c	O
jhj	O
v	O
wj	O
hj	O
since	O
we	O
are	O
conditioning	O
on	O
the	O
visible	O
units	O
v	O
we	O
can	O
treat	O
these	O
as	O
constant	O
with	O
respect	O
to	O
the	O
distribution	O
p	O
v	O
the	O
factorial	O
nature	O
of	O
the	O
conditional	O
p	O
v	O
follows	O
immediately	O
from	O
our	O
ability	O
to	O
write	O
the	O
joint	B
probability	I
over	O
the	O
vector	O
h	O
as	O
the	O
product	O
of	O
distributions	O
over	O
the	O
individual	O
elements	O
h	O
j	O
it	O
is	O
now	O
a	O
simple	O
matter	O
of	O
normalizing	O
the	O
distributions	O
over	O
the	O
individual	O
binary	O
hj	O
p	O
h	O
j	O
v	O
v	O
p	O
h	O
j	O
p	O
h	O
j	O
p	O
h	O
j	O
v	O
exp	O
wj	O
cj	O
v	O
cj	O
v	O
exp	O
exp	O
wj	O
cj	O
v	O
wj	O
v	O
nh	O
we	O
can	O
now	O
express	O
the	O
full	O
conditional	O
over	O
the	O
hidden	B
layer	I
as	O
the	O
factorial	O
distribution	O
h	O
v	O
p	O
h	O
c	O
w	O
v	O
j	O
a	O
similar	O
derivation	O
will	O
show	O
that	O
the	O
other	O
condition	O
of	O
interest	O
to	O
us	O
p	O
h	O
is	O
also	O
a	O
factorial	O
distribution	O
v	O
h	O
p	O
v	O
nv	O
b	O
w	O
h	O
i	O
training	O
restricted	O
boltzmann	O
machines	O
because	O
the	O
rbm	O
admits	O
efficient	O
evaluation	O
and	O
differentiation	O
of	O
p	O
and	O
efficient	O
mcmc	O
sampling	O
in	O
the	O
form	O
of	O
block	B
gibbs	I
sampling	I
it	O
can	O
readily	O
be	O
trained	O
with	O
any	O
of	O
the	O
techniques	O
described	O
in	O
chapter	O
for	O
training	O
models	O
that	O
have	O
intractable	O
partition	O
functions	O
this	O
includes	O
cd	O
sml	O
ratio	B
matching	I
and	O
so	O
on	O
compared	O
to	O
other	O
undirected	O
models	O
used	O
in	O
deep	O
learning	O
v	O
the	O
rbm	O
is	O
relatively	O
straightforward	O
to	O
train	O
because	O
we	O
can	O
compute	O
ph	O
chapter	O
deep	O
generative	O
models	O
exactly	O
in	O
closed	O
form	O
some	O
other	O
deep	O
models	O
such	O
as	O
the	O
deep	O
boltzmann	O
machine	O
combine	O
both	O
the	O
difficulty	O
of	O
an	O
intractable	O
partition	O
function	O
and	O
the	O
difficulty	O
of	O
intractable	O
inference	O
deep	O
belief	O
networks	O
et	O
al	O
deep	O
belief	O
networks	O
were	O
one	O
of	O
the	O
first	O
non-convolutional	O
models	O
to	O
successfully	O
admit	O
training	O
of	O
deep	O
architectures	O
hinton	O
the	O
introduction	O
of	O
deep	O
belief	O
networks	O
in	O
began	O
the	O
current	O
deep	O
learning	O
renaissance	O
prior	O
to	O
the	O
introduction	O
of	O
deep	O
belief	O
networks	O
deep	O
models	O
were	O
considered	O
too	O
difficult	O
to	O
optimize	O
kernel	O
machines	O
with	O
convex	O
objective	O
functions	O
dominated	O
the	O
research	O
landscape	O
deep	O
belief	O
networks	O
demonstrated	O
that	O
deep	O
architectures	O
can	O
be	O
successful	O
by	O
outperforming	O
kernelized	O
support	O
vector	O
machines	O
on	O
the	O
mnist	O
dataset	B
today	O
deep	O
belief	O
networks	O
have	O
mostly	O
fallen	O
out	O
of	O
favor	O
and	O
are	O
rarely	O
used	O
even	O
compared	O
to	O
other	O
unsupervised	O
or	O
generative	O
learning	O
algorithms	O
but	O
they	O
are	O
still	O
deservedly	O
recognized	O
for	O
their	O
important	O
role	O
in	O
deep	O
learning	O
history	O
hinton	O
et	O
al	O
deep	O
belief	O
networks	O
are	O
generative	O
models	O
with	O
several	O
layers	O
of	O
latent	O
variables	O
the	O
latent	O
variables	O
are	O
typically	O
binary	O
while	O
the	O
visible	O
units	O
may	O
be	O
binary	O
or	O
real	O
there	O
are	O
no	O
intralayer	O
connections	O
usually	O
every	O
unit	O
in	O
each	O
layer	O
is	O
connected	O
to	O
every	O
unit	O
in	O
each	O
neighboring	O
layer	O
though	O
it	O
is	O
possible	O
to	O
construct	O
more	O
sparsely	O
connected	O
dbns	O
the	O
connections	O
between	O
the	O
top	O
two	O
layers	O
are	O
undirected	O
the	O
connections	O
between	O
all	O
other	O
layers	O
are	O
directed	O
with	O
the	O
arrows	O
pointed	O
toward	O
the	O
layer	O
that	O
is	O
closest	O
to	O
the	O
data	O
see	O
figure	O
b	O
for	O
an	O
example	B
a	O
dbn	O
with	O
l	O
hidden	O
layers	O
contains	O
l	O
weight	O
matrices	O
w	O
w	O
it	O
also	O
contains	O
l	O
bias	O
vectors	O
b	O
with	O
providing	O
the	O
biases	O
for	O
the	O
visible	B
layer	I
the	O
probability	B
distribution	I
represented	O
by	O
the	O
dbn	O
is	O
given	O
by	O
p	O
h	O
i	O
k	O
h	O
l	O
p	O
h	O
exp	O
b	O
l	O
h	O
b	O
i	O
w	O
b	O
p	O
v	O
i	O
k	O
l	O
h	O
w	O
h	O
h	O
l	O
i	O
k	O
l	O
i	O
w	O
i	O
h	O
k	O
in	O
the	O
case	O
of	O
real-valued	O
visible	O
units	O
substitute	O
n	O
v	O
w	O
v	O
b	O
chapter	O
deep	O
generative	O
models	O
with	O
diagonal	O
for	O
tractability	O
generalizations	O
to	O
other	O
exponential	O
family	O
visible	O
units	O
are	O
straightforward	O
at	O
least	O
in	O
theory	O
a	O
dbn	O
with	O
only	O
one	O
hidden	B
layer	I
is	O
just	O
an	O
rbm	O
to	O
generate	O
a	O
sample	O
from	O
a	O
dbn	O
we	O
first	O
run	O
several	O
steps	O
of	O
gibbs	O
sampling	O
on	O
the	O
top	O
two	O
hidden	O
layers	O
this	O
stage	O
is	O
essentially	O
drawing	O
a	O
sample	O
from	O
the	O
rbm	O
defined	O
by	O
the	O
top	O
two	O
hidden	O
layers	O
we	O
can	O
then	O
use	O
a	O
single	O
pass	O
of	O
ancestral	O
sampling	O
through	O
the	O
rest	O
of	O
the	O
model	O
to	O
draw	O
a	O
sample	O
from	O
the	O
visible	O
units	O
deep	O
belief	O
networks	O
incur	O
many	O
of	O
the	O
problems	O
associated	O
with	O
both	O
directed	O
models	O
and	O
undirected	O
models	O
inference	O
in	O
a	O
deep	O
belief	O
network	O
is	O
intractable	O
due	O
to	O
the	O
explaining	O
away	O
effect	O
within	O
each	O
directed	O
layer	O
and	O
due	O
to	O
the	O
interaction	O
between	O
the	O
two	O
hidden	O
layers	O
that	O
have	O
undirected	O
connections	O
evaluating	O
or	O
maximizing	O
the	O
standard	O
evidence	O
lower	O
bound	B
on	O
the	O
log-likelihood	O
is	O
also	O
intractable	O
because	O
the	O
evidence	O
lower	O
bound	B
takes	O
the	O
expectation	B
of	O
cliques	O
whose	O
size	O
is	O
equal	O
to	O
the	O
network	O
width	O
evaluating	O
or	O
maximizing	O
the	O
log-likelihood	O
requires	O
not	O
just	O
confronting	O
the	O
problem	O
of	O
intractable	O
inference	O
to	O
marginalize	O
out	O
the	O
latent	O
variables	O
but	O
also	O
the	O
problem	O
of	O
an	O
intractable	O
partition	O
function	O
within	O
the	O
undirected	B
model	I
of	O
the	O
top	O
two	O
layers	O
to	O
train	O
a	O
deep	O
belief	O
network	O
one	O
begins	O
by	O
training	O
an	O
rbm	O
to	O
maximize	O
log	O
pv	O
using	O
contrastive	O
divergence	O
or	O
stochastic	O
maximum	B
likelihood	I
pdata	O
ev	O
the	O
parameters	O
of	O
the	O
rbm	O
then	O
define	O
the	O
parameters	O
of	O
the	O
first	O
layer	O
of	O
the	O
dbn	O
next	O
a	O
second	O
rbm	O
is	O
trained	O
to	O
approximately	O
maximize	O
ev	O
v	O
log	O
where	O
is	O
the	O
probability	B
distribution	I
represented	O
by	O
the	O
first	O
rbm	O
and	O
is	O
the	O
probability	B
distribution	I
represented	O
by	O
the	O
second	O
rbm	O
in	O
other	O
words	O
the	O
second	O
rbm	O
is	O
trained	O
to	O
model	O
the	O
distribution	O
defined	O
by	O
sampling	O
the	O
hidden	O
units	O
of	O
the	O
first	O
rbm	O
when	O
the	O
first	O
rbm	O
is	O
driven	O
by	O
the	O
data	O
this	O
procedure	O
can	O
be	O
repeated	O
indefinitely	O
to	O
add	O
as	O
many	O
layers	O
to	O
the	O
dbn	O
as	O
desired	O
with	O
each	O
new	O
rbm	O
modeling	O
the	O
samples	O
of	O
the	O
previous	O
one	O
each	O
rbm	O
defines	O
another	O
layer	O
of	O
the	O
dbn	O
this	O
procedure	O
can	O
be	O
justified	O
as	O
increasing	O
a	O
variational	O
lower	O
bound	B
on	O
the	O
log-likelihood	O
of	O
the	O
data	O
under	O
the	O
dbn	O
et	O
al	O
in	O
most	O
applications	O
no	O
effort	O
is	O
made	O
to	O
jointly	O
train	O
the	O
dbn	O
after	O
the	O
greedy	O
layer-wise	O
procedure	O
is	O
complete	O
however	O
it	O
is	O
possible	O
to	O
perform	O
generative	O
fine-tuning	B
using	O
the	O
wake-sleep	O
algorithm	O
chapter	O
deep	O
generative	O
models	O
v	O
the	O
trained	O
dbn	O
may	O
be	O
used	O
directly	O
as	O
a	O
generative	O
model	O
but	O
most	O
of	O
the	O
interest	O
in	O
dbns	O
arose	O
from	O
their	O
ability	O
to	O
improve	O
classification	B
models	O
we	O
can	O
take	O
the	O
weights	B
from	O
the	O
dbn	O
and	O
use	O
them	O
to	O
define	O
an	O
mlp	O
w	O
l	O
m	O
l	O
w	O
h	O
b	O
i	O
h	O
after	O
initializing	O
this	O
mlp	O
with	O
the	O
weights	B
and	O
biases	O
learned	O
via	O
generative	O
training	O
of	O
the	O
dbn	O
we	O
may	O
train	O
the	O
mlp	O
to	O
perform	O
a	O
classification	B
task	O
this	O
additional	O
training	O
of	O
the	O
mlp	O
is	O
an	O
example	B
of	O
discriminative	O
fine-tuning	B
tight	O
this	O
specific	O
choice	O
of	O
mlp	O
is	O
somewhat	O
arbitrary	O
compared	O
to	O
many	O
of	O
the	O
inference	O
equations	O
in	O
chapter	O
that	O
are	O
derived	O
from	O
first	O
principles	O
this	O
mlp	O
is	O
a	O
heuristic	O
choice	O
that	O
seems	O
to	O
work	O
well	O
in	O
practice	O
and	O
is	O
used	O
consistently	O
in	O
the	O
literature	O
many	O
approximate	B
inference	I
techniques	O
are	O
motivated	O
by	O
their	O
ability	O
to	O
find	O
a	O
maximally	O
variational	O
lower	O
bound	B
on	O
the	O
log-likelihood	O
under	O
some	O
set	O
of	O
constraints	O
one	O
can	O
construct	O
a	O
variational	O
lower	O
bound	B
on	O
the	O
log-likelihood	O
using	O
the	O
hidden	O
unit	O
expectations	O
defined	O
by	O
the	O
dbn	O
s	O
mlp	O
but	O
this	O
is	O
true	O
of	O
probability	B
distribution	I
over	O
the	O
hidden	O
units	O
and	O
there	O
is	O
no	O
reason	O
to	O
believe	O
that	O
this	O
mlp	O
provides	O
a	O
particularly	O
tight	O
bound	B
in	O
particular	O
the	O
mlp	O
ignores	O
many	O
important	O
interactions	O
in	O
the	O
dbn	O
graphical	O
model	O
the	O
mlp	O
propagates	O
information	O
upward	O
from	O
the	O
visible	O
units	O
to	O
the	O
deepest	O
hidden	O
units	O
but	O
does	O
not	O
propagate	O
any	O
information	O
downward	O
or	O
sideways	O
the	O
dbn	O
graphical	O
model	O
has	O
explaining	O
away	O
interactions	O
between	O
all	O
of	O
the	O
hidden	O
units	O
within	O
the	O
same	O
layer	O
as	O
well	O
as	O
top-down	O
interactions	O
between	O
layers	O
any	O
while	O
the	O
log-likelihood	O
of	O
a	O
dbn	O
is	O
intractable	O
it	O
may	O
be	O
approximated	O
with	O
this	O
permits	O
evaluating	O
its	O
quality	O
as	O
a	O
ais	O
and	O
murray	O
generative	O
model	O
the	O
term	O
deep	O
belief	O
network	O
is	O
commonly	O
used	O
incorrectly	O
to	O
refer	O
to	O
any	O
kind	O
of	O
deep	O
neural	B
network	I
even	O
networks	O
without	O
latent	B
variable	I
semantics	O
the	O
term	O
deep	O
belief	O
network	O
should	O
refer	O
specifically	O
to	O
models	O
with	O
undirected	O
connections	O
in	O
the	O
deepest	O
layer	O
and	O
directed	O
connections	O
pointing	O
downward	O
between	O
all	O
other	O
pairs	O
of	O
consecutive	O
layers	O
the	O
term	O
deep	O
belief	O
network	O
may	O
also	O
cause	O
some	O
confusion	O
because	O
the	O
term	O
belief	O
network	O
is	O
sometimes	O
used	O
to	O
refer	O
to	O
purely	O
directed	O
models	O
while	O
deep	O
belief	O
networks	O
contain	O
an	O
undirected	O
layer	O
deep	O
belief	O
networks	O
also	O
share	O
the	O
acronym	O
dbn	O
with	O
dynamic	O
bayesian	O
networks	O
and	O
kanazawa	O
which	O
are	O
bayesian	O
networks	O
for	O
representing	O
markov	O
chains	O
chapter	O
deep	O
generative	O
models	O
figure	O
the	O
graphical	O
model	O
for	O
a	O
deep	O
boltzmann	O
machine	O
with	O
one	O
visible	B
layer	I
and	O
two	O
hidden	O
layers	O
connections	O
are	O
only	O
between	O
units	O
in	O
neighboring	O
layers	O
there	O
are	O
no	O
intralayer	O
layer	O
connections	O
deep	O
boltzmann	O
machines	O
a	O
deep	O
boltzmann	O
machine	O
or	O
dbm	O
and	O
hinton	O
is	O
another	O
kind	O
of	O
deep	O
generative	O
model	O
unlike	O
the	O
deep	O
belief	O
network	O
it	O
is	O
an	O
entirely	O
undirected	B
model	I
unlike	O
the	O
rbm	O
the	O
dbm	O
has	O
several	O
layers	O
of	O
latent	O
variables	O
have	O
just	O
one	O
but	O
like	O
the	O
rbm	O
within	O
each	O
layer	O
each	O
of	O
the	O
variables	O
are	O
mutually	O
independent	O
conditioned	O
on	O
the	O
variables	O
in	O
the	O
neighboring	O
layers	O
see	O
figure	O
for	O
the	O
graph	O
structure	O
deep	O
boltzmann	O
machines	O
have	O
been	O
applied	O
to	O
a	O
variety	O
of	O
tasks	O
including	O
document	O
modeling	O
et	O
al	O
like	O
rbms	O
and	O
dbns	O
dbms	O
typically	O
contain	O
only	O
binary	O
units	O
as	O
we	O
assume	O
for	O
simplicity	O
of	O
our	O
presentation	O
of	O
the	O
model	O
but	O
it	O
is	O
straightforward	O
to	O
include	O
real-valued	O
visible	O
units	O
a	O
dbm	O
is	O
an	O
energy-based	O
model	O
meaning	O
that	O
the	O
the	O
joint	B
probability	B
distribution	I
over	O
the	O
model	O
variables	O
is	O
parametrized	O
by	O
an	O
energy	B
function	I
e	O
in	O
the	O
case	O
of	O
a	O
deep	O
boltzmann	O
machine	O
with	O
one	O
visible	B
layer	I
v	O
and	O
three	O
hidden	O
layers	O
and	O
the	O
joint	B
probability	I
is	O
given	O
by	O
p	O
v	O
h	O
z	O
exp	O
e	O
to	O
simplify	O
our	O
presentation	O
we	O
omit	O
the	O
bias	O
parameters	O
below	O
the	O
dbm	O
energy	B
function	I
is	O
then	O
defined	O
as	O
follows	O
e	O
v	O
w	O
w	O
w	O
chapter	O
deep	O
generative	O
models	O
v	O
v	O
figure	O
a	O
deep	O
boltzmann	O
machine	O
re-arranged	O
to	O
reveal	O
its	O
bipartite	O
graph	O
structure	O
in	O
comparison	O
to	O
the	O
rbm	O
energy	B
function	I
the	O
dbm	O
energy	B
function	I
includes	O
connections	O
between	O
the	O
hidden	O
units	O
variables	O
in	O
the	O
form	O
of	O
the	O
weight	O
matrices	O
and	O
w	O
as	O
we	O
will	O
see	O
these	O
connections	O
have	O
significant	O
consequences	O
for	O
both	O
the	O
model	O
behavior	O
as	O
well	O
as	O
how	O
we	O
go	O
about	O
performing	O
inference	O
in	O
the	O
model	O
in	O
comparison	O
to	O
fully	O
connected	O
boltzmann	O
machines	O
every	O
unit	O
connected	O
to	O
every	O
other	O
unit	O
the	O
dbm	O
offers	O
some	O
advantages	O
that	O
are	O
similar	O
to	O
those	O
offered	O
by	O
the	O
rbm	O
specifically	O
as	O
illustrated	O
in	O
figure	O
the	O
dbm	O
layers	O
can	O
be	O
organized	O
into	O
a	O
bipartite	O
graph	O
with	O
odd	O
layers	O
on	O
one	O
side	O
and	O
even	O
layers	O
on	O
the	O
other	O
this	O
immediately	O
implies	O
that	O
when	O
we	O
condition	O
on	O
the	O
variables	O
in	O
the	O
even	O
layer	O
the	O
variables	O
in	O
the	O
odd	O
layers	O
become	O
conditionally	O
independent	O
of	O
course	O
when	O
we	O
condition	O
on	O
the	O
variables	O
in	O
the	O
odd	O
layers	O
the	O
variables	O
in	O
the	O
even	O
layers	O
also	O
become	O
conditionally	O
independent	O
the	O
bipartite	O
structure	O
of	O
the	O
dbm	O
means	O
that	O
we	O
can	O
apply	O
the	O
same	O
equations	O
we	O
have	O
previously	O
used	O
for	O
the	O
conditional	O
distributions	O
of	O
an	O
rbm	O
to	O
determine	O
the	O
conditional	O
distributions	O
in	O
a	O
dbm	O
the	O
units	O
within	O
a	O
layer	O
are	O
conditionally	O
independent	O
from	O
each	O
other	O
given	O
the	O
values	O
of	O
the	O
neighboring	O
layers	O
so	O
the	O
distributions	O
over	O
binary	O
variables	O
can	O
be	O
fully	O
described	O
by	O
the	O
bernoulli	O
parameters	O
giving	O
the	O
probability	O
of	O
each	O
unit	O
being	O
active	O
in	O
our	O
example	B
with	O
two	O
hidden	O
layers	O
the	O
activation	O
probabilities	O
are	O
given	O
by	O
p	O
v	O
i	O
w	O
i	O
chapter	O
deep	O
generative	O
models	O
and	O
p	O
h	O
i	O
p	O
h	O
k	O
v	O
v	O
h	O
h	O
i	O
w	O
w	O
h	O
w	O
the	O
bipartite	O
structure	O
makes	O
gibbs	O
sampling	O
in	O
a	O
deep	O
boltzmann	O
machine	O
efficient	O
the	O
naive	O
approach	O
to	O
gibbs	O
sampling	O
is	O
to	O
update	O
only	O
one	O
variable	O
at	O
a	O
time	O
rbms	O
allow	O
all	O
of	O
the	O
visible	O
units	O
to	O
be	O
updated	O
in	O
one	O
block	O
and	O
all	O
of	O
the	O
hidden	O
units	O
to	O
be	O
updated	O
in	O
a	O
second	O
block	O
one	O
might	O
naively	O
assume	O
that	O
a	O
dbm	O
with	O
l	O
layers	O
requires	O
l	O
updates	O
with	O
each	O
iteration	O
updating	O
a	O
block	O
consisting	O
of	O
one	O
layer	O
of	O
units	O
instead	O
it	O
is	O
possible	O
to	O
update	O
all	O
of	O
the	O
units	O
in	O
only	O
two	O
iterations	O
gibbs	O
sampling	O
can	O
be	O
divided	O
into	O
two	O
blocks	O
of	O
updates	O
one	O
including	O
all	O
even	O
layers	O
the	O
visible	B
layer	I
and	O
the	O
other	O
including	O
all	O
odd	O
layers	O
due	O
to	O
the	O
bipartite	O
dbm	O
connection	O
pattern	O
given	O
the	O
even	O
layers	O
the	O
distribution	O
over	O
the	O
odd	O
layers	O
is	O
factorial	O
and	O
thus	O
can	O
be	O
sampled	O
simultaneously	O
and	O
independently	O
as	O
a	O
block	O
likewise	O
given	O
the	O
odd	O
layers	O
the	O
even	O
layers	O
can	O
be	O
sampled	O
simultaneously	O
and	O
independently	O
as	O
a	O
block	O
efficient	O
sampling	O
is	O
especially	O
important	O
for	O
training	O
with	O
the	O
stochastic	O
maximum	B
likelihood	I
algorithm	O
interesting	O
properties	O
deep	O
boltzmann	O
machines	O
have	O
many	O
interesting	O
properties	O
dbms	O
were	O
developed	O
after	O
dbns	O
compared	O
to	O
dbns	O
the	O
posterior	O
distribu	O
is	O
simpler	O
for	O
dbms	O
somewhat	O
counterintuitively	O
the	O
simplicity	O
of	O
tion	B
ph	O
v	O
this	O
posterior	O
distribution	O
allows	O
richer	O
approximations	O
of	O
the	O
posterior	O
in	O
the	O
case	O
of	O
the	O
dbn	O
we	O
perform	O
classification	B
using	O
a	O
heuristically	O
motivated	O
approximate	B
inference	I
procedure	O
in	O
which	O
we	O
guess	O
that	O
a	O
reasonable	O
value	O
for	O
the	O
mean	O
field	O
expectation	B
of	O
the	O
hidden	O
units	O
can	O
be	O
provided	O
by	O
an	O
upward	O
pass	O
through	O
the	O
network	O
in	O
an	O
mlp	O
that	O
uses	O
sigmoid	O
activation	O
functions	O
and	O
the	O
same	O
weights	B
as	O
qh	O
may	O
be	O
used	O
to	O
obtain	O
a	O
variational	O
lower	O
the	O
original	O
dbn	O
bound	B
on	O
the	O
log-likelihood	O
this	O
heuristic	O
procedure	O
therefore	O
allows	O
us	O
to	O
obtain	O
such	O
a	O
bound	B
however	O
the	O
bound	B
is	O
not	O
explicitly	O
optimized	O
in	O
any	O
way	O
so	O
the	O
bound	B
may	O
be	O
far	O
from	O
tight	O
in	O
particular	O
the	O
heuristic	O
estimate	O
of	O
q	O
ignores	O
interactions	O
between	O
hidden	O
units	O
within	O
the	O
same	O
layer	O
as	O
well	O
as	O
the	O
top-down	O
feedback	O
influence	O
of	O
hidden	O
units	O
in	O
deeper	O
layers	O
on	O
hidden	O
units	O
that	O
are	O
closer	O
to	O
the	O
input	O
because	O
the	O
heuristic	O
mlp-based	O
inference	O
procedure	O
in	O
the	O
dbn	O
is	O
not	O
able	O
to	O
account	O
for	O
these	O
interactions	O
the	O
resulting	O
q	O
is	O
presumably	O
far	O
distribution	O
any	O
chapter	O
deep	O
generative	O
models	O
from	O
optimal	O
in	O
dbms	O
all	O
of	O
the	O
hidden	O
units	O
within	O
a	O
layer	O
are	O
conditionally	O
independent	O
given	O
the	O
other	O
layers	O
this	O
lack	O
of	O
intralayer	O
interaction	O
makes	O
it	O
possible	O
to	O
use	O
fixed	O
point	O
equations	O
to	O
actually	O
optimize	O
the	O
variational	O
lower	O
bound	B
and	O
find	O
the	O
true	O
optimal	O
mean	O
field	O
expectations	O
within	O
some	O
numerical	O
tolerance	O
the	O
use	O
of	O
proper	O
mean	O
field	O
allows	O
the	O
approximate	B
inference	I
procedure	O
for	O
dbms	O
to	O
capture	O
the	O
influence	O
of	O
top-down	O
feedback	O
interactions	O
this	O
makes	O
dbms	O
interesting	O
from	O
the	O
point	O
of	O
view	O
of	O
neuroscience	B
because	O
the	O
human	O
brain	O
is	O
known	O
to	O
use	O
many	O
top-down	O
feedback	O
connections	O
because	O
of	O
this	O
property	O
dbms	O
have	O
been	O
used	O
as	O
computational	O
models	O
of	O
real	O
neuroscientific	O
phenomena	O
series	O
et	O
al	O
reichert	O
et	O
al	O
one	O
unfortunate	O
property	O
of	O
dbms	O
is	O
that	O
sampling	O
from	O
them	O
is	O
relatively	O
difficult	O
dbns	O
only	O
need	O
to	O
use	O
mcmc	O
sampling	O
in	O
their	O
top	O
pair	O
of	O
layers	O
the	O
other	O
layers	O
are	O
used	O
only	O
at	O
the	O
end	O
of	O
the	O
sampling	O
process	O
in	O
one	O
efficient	O
ancestral	O
sampling	O
pass	O
to	O
generate	O
a	O
sample	O
from	O
a	O
dbm	O
it	O
is	O
necessary	O
to	O
use	O
mcmc	O
across	O
all	O
layers	O
with	O
every	O
layer	O
of	O
the	O
model	O
participating	O
in	O
every	O
markov	B
chain	I
transition	O
dbm	O
mean	O
field	O
inference	O
p	O
the	O
conditional	O
distribution	O
over	O
one	O
dbm	O
layer	O
given	O
the	O
neighboring	O
layers	O
is	O
factorial	O
in	O
the	O
example	B
of	O
the	O
dbm	O
with	O
two	O
hidden	O
layers	O
these	O
distributions	O
the	O
distribution	O
over	O
all	O
are	O
p	O
h	O
hidden	O
layers	O
generally	O
does	O
not	O
factorize	O
because	O
of	O
interactions	O
between	O
layers	O
in	O
the	O
example	B
with	O
two	O
hidden	O
layers	O
p	O
v	O
does	O
not	O
factorize	O
due	O
due	O
to	O
the	O
interaction	O
weights	B
w	O
between	O
and	O
which	O
render	O
these	O
variables	O
mutually	O
dependent	O
and	O
p	O
v	O
h	O
as	O
was	O
the	O
case	O
with	O
the	O
dbn	O
we	O
are	O
left	O
to	O
seek	O
out	O
methods	O
to	O
approximate	O
the	O
dbm	O
posterior	O
distribution	O
however	O
unlike	O
the	O
dbn	O
the	O
dbm	O
posterior	O
distribution	O
over	O
their	O
hidden	O
units	O
while	O
complicated	O
is	O
easy	O
to	O
approximate	O
with	O
a	O
variational	O
approximation	O
discussed	O
in	O
section	O
specifically	O
a	O
mean	O
field	O
approximation	O
the	O
mean	O
field	O
approximation	O
is	O
a	O
simple	O
form	O
of	O
variational	O
inference	O
where	O
we	O
restrict	O
the	O
approximating	O
distribution	O
to	O
fully	O
factorial	O
distributions	O
in	O
the	O
context	O
of	O
dbms	O
the	O
mean	O
field	O
equations	O
capture	O
the	O
bidirectional	O
interactions	O
between	O
layers	O
in	O
this	O
section	O
we	O
derive	O
the	O
iterative	O
approximate	B
inference	I
procedure	O
originally	O
introduced	O
in	O
salakhutdinov	O
and	O
hinton	O
in	O
variational	O
approximations	O
to	O
inference	O
we	O
approach	O
the	O
task	O
of	O
approxi	O
chapter	O
deep	O
generative	O
models	O
mating	O
a	O
particular	O
target	O
distribution	O
in	O
our	O
case	O
the	O
posterior	O
distribution	O
over	O
the	O
hidden	O
units	O
given	O
the	O
visible	O
units	O
by	O
some	O
reasonably	O
simple	O
family	O
of	O
distributions	O
in	O
the	O
case	O
of	O
the	O
mean	O
field	O
approximation	O
the	O
approximating	O
family	O
is	O
the	O
set	O
of	O
distributions	O
where	O
the	O
hidden	O
units	O
are	O
conditionally	O
independent	O
we	O
now	O
develop	O
the	O
mean	O
field	O
approach	O
for	O
the	O
example	B
with	O
two	O
hidden	O
v	O
the	O
mean	O
v	O
be	O
the	O
approximation	O
of	O
p	O
layers	O
let	O
field	O
assumption	O
implies	O
that	O
v	O
q	O
h	O
j	O
v	O
v	O
q	O
h	O
k	O
j	O
k	O
the	O
mean	O
field	O
approximation	O
attempts	O
to	O
find	O
a	O
member	O
of	O
this	O
family	O
of	O
distributions	O
that	O
best	O
fits	O
the	O
true	O
posterior	O
p	O
v	O
importantly	O
the	O
inference	O
process	O
must	O
be	O
run	O
again	O
to	O
find	O
a	O
different	O
distribution	O
q	O
every	O
time	O
we	O
use	O
a	O
new	O
value	O
of	O
one	O
can	O
conceive	O
of	O
many	O
ways	O
of	O
measuring	O
how	O
well	O
qh	O
v	O
fits	O
p	O
v	O
the	O
mean	O
field	O
approach	O
is	O
to	O
minimize	O
kl	O
v	O
log	O
q	O
p	O
h	O
p	O
v	O
v	O
in	O
general	O
we	O
do	O
not	O
have	O
to	O
provide	O
a	O
parametric	O
form	O
of	O
the	O
approximating	O
distribution	O
beyond	O
enforcing	O
the	O
independence	O
assumptions	O
the	O
variational	O
approximation	O
procedure	O
is	O
generally	O
able	O
to	O
recover	O
a	O
functional	O
form	O
of	O
the	O
approximate	O
distribution	O
however	O
in	O
the	O
case	O
of	O
a	O
mean	O
field	O
assumption	O
on	O
binary	O
hidden	O
units	O
case	O
we	O
are	O
developing	O
here	O
there	O
is	O
no	O
loss	O
of	O
generality	O
resulting	O
from	O
fixing	O
a	O
parametrization	O
of	O
the	O
model	O
in	O
advance	O
we	O
parametrize	O
q	O
as	O
a	O
product	O
of	O
bernoulli	O
distributions	O
that	O
is	O
we	O
associate	O
the	O
probability	O
of	O
each	O
element	O
of	O
with	O
a	O
parameter	O
specifically	O
for	O
each	O
j	O
j	O
v	O
j	O
where	O
k	O
thus	O
we	O
have	O
the	O
following	O
approximation	O
to	O
the	O
posterior	O
and	O
for	O
each	O
k	O
h	O
k	O
v	O
where	O
k	O
j	O
v	O
q	O
h	O
j	O
v	O
q	O
h	O
k	O
v	O
j	O
j	O
j	O
j	O
k	O
j	O
j	O
k	O
k	O
k	O
k	O
h	O
k	O
of	O
course	O
for	O
dbms	O
with	O
more	O
layers	O
the	O
approximate	O
posterior	O
parametrization	O
can	O
be	O
extended	O
in	O
the	O
obvious	O
way	O
exploiting	O
the	O
bipartite	O
structure	O
of	O
the	O
graph	O
chapter	O
deep	O
generative	O
models	O
to	O
update	O
all	O
of	O
the	O
even	O
layers	O
simultaneously	O
and	O
then	O
to	O
update	O
all	O
of	O
the	O
odd	O
layers	O
simultaneously	O
following	O
the	O
same	O
schedule	O
as	O
gibbs	O
sampling	O
now	O
that	O
we	O
have	O
specified	O
our	O
family	O
of	O
approximating	O
distributions	O
q	O
it	O
remains	O
to	O
specify	O
a	O
procedure	O
for	O
choosing	O
the	O
member	O
of	O
this	O
family	O
that	O
best	O
fits	O
p	O
the	O
most	O
straightforward	O
way	O
to	O
do	O
this	O
is	O
to	O
use	O
the	O
mean	O
field	O
equations	O
specified	O
by	O
equation	O
these	O
equations	O
were	O
derived	O
by	O
solving	O
for	O
where	O
the	O
derivatives	O
of	O
the	O
variational	O
lower	O
bound	B
are	O
zero	O
they	O
describe	O
in	O
an	O
abstract	O
manner	O
how	O
to	O
optimize	O
the	O
variational	O
lower	O
bound	B
for	O
any	O
model	O
simply	O
by	O
taking	O
expectations	O
with	O
respect	O
to	O
applying	O
these	O
general	O
equations	O
we	O
obtain	O
the	O
update	O
rules	O
ignoring	O
bias	O
terms	O
j	O
viw	O
ij	O
w	O
jk	O
h	O
k	O
j	O
i	O
k	O
k	O
j	O
j	O
j	O
k	O
l	O
at	O
a	O
fixed	O
point	O
of	O
this	O
system	O
of	O
equations	O
we	O
have	O
a	O
local	O
maximum	O
of	O
the	O
thus	O
these	O
fixed	O
point	O
update	O
equations	O
define	O
an	O
variational	O
lower	O
bound	B
iterative	O
algorithm	O
where	O
we	O
alternate	O
updates	O
of	O
h	O
and	O
updates	O
of	O
on	O
small	O
problems	O
such	O
as	O
mnist	O
as	O
few	O
k	O
as	O
ten	O
iterations	O
can	O
be	O
sufficient	O
to	O
find	O
an	O
approximate	O
positive	O
phase	O
gradient	B
for	O
learning	O
and	O
fifty	O
usually	O
suffice	O
to	O
obtain	O
a	O
high	O
quality	O
representation	O
of	O
a	O
single	O
specific	O
example	B
to	O
be	O
used	O
for	O
high-accuracy	O
classification	B
extending	O
approximate	O
variational	O
inference	O
to	O
deeper	O
dbms	O
is	O
straightforward	O
equation	O
equation	O
j	O
dbm	O
parameter	O
learning	O
learning	O
in	O
the	O
dbm	O
must	O
confront	O
both	O
the	O
challenge	B
of	O
an	O
intractable	O
partition	O
function	O
using	O
the	O
techniques	O
from	O
chapter	O
and	O
the	O
challenge	B
of	O
an	O
intractable	O
posterior	O
distribution	O
using	O
the	O
techniques	O
from	O
chapter	O
as	O
described	O
in	O
section	O
l	O
a	O
distribution	O
qh	O
v	O
proceeds	O
by	O
maximizing	O
log-likelihood	O
log	O
p	O
v	O
that	O
approximates	O
the	O
intractable	O
p	O
h	O
v	O
variational	O
inference	O
allows	O
the	O
construction	O
of	O
learning	O
then	O
the	O
variational	O
lower	O
bound	B
on	O
the	O
intractable	O
q	O
chapter	O
deep	O
generative	O
models	O
for	O
a	O
deep	O
boltzmann	O
machine	O
with	O
two	O
hidden	O
layers	O
is	O
given	O
by	O
l	O
h	O
l	O
q	O
j	O
i	O
vi	O
ij	O
j	O
j	O
w	O
k	O
j	O
j	O
k	O
log	O
z	O
this	O
expression	O
still	O
contains	O
the	O
log	O
partition	O
function	O
log	O
z	O
because	O
a	O
deep	O
boltzmann	O
machine	O
contains	O
restricted	O
boltzmann	O
machines	O
as	O
components	O
the	O
hardness	O
results	O
for	O
computing	O
the	O
partition	O
function	O
and	O
sampling	O
that	O
apply	O
to	O
restricted	O
boltzmann	O
machines	O
also	O
apply	O
to	O
deep	O
boltzmann	O
machines	O
this	O
means	O
that	O
evaluating	O
the	O
probability	B
mass	I
function	I
of	O
a	O
boltzmann	O
machine	O
requires	O
approximate	O
methods	O
such	O
as	O
annealed	O
importance	O
sampling	O
likewise	O
training	O
the	O
model	O
requires	O
approximations	O
to	O
the	O
gradient	B
of	O
the	O
log	O
partition	O
function	O
see	O
chapter	O
for	O
a	O
general	O
description	O
of	O
these	O
methods	O
dbms	O
are	O
typically	O
trained	O
using	O
stochastic	O
maximum	B
likelihood	I
many	O
of	O
the	O
other	O
techniques	O
described	O
in	O
chapter	O
are	O
not	O
applicable	O
techniques	O
such	O
as	O
pseudolikelihood	B
require	O
the	O
ability	O
to	O
evaluate	O
the	O
unnormalized	O
probabilities	O
rather	O
than	O
merely	O
obtain	O
a	O
variational	O
lower	O
bound	B
on	O
them	O
contrastive	O
divergence	O
is	O
slow	O
for	O
deep	O
boltzmann	O
machines	O
because	O
they	O
do	O
not	O
allow	O
efficient	O
sampling	O
of	O
the	O
hidden	O
units	O
given	O
the	O
visible	O
units	O
instead	O
contrastive	O
divergence	O
would	O
require	O
burning	O
in	O
a	O
markov	B
chain	I
every	O
time	O
a	O
new	O
negative	O
phase	O
sample	O
is	O
needed	O
the	O
non-variational	O
version	O
of	O
stochastic	O
maximum	B
likelihood	I
algorithm	O
was	O
variational	O
stochastic	O
maximum	B
likelihood	I
as	O
recall	B
that	O
we	O
describe	O
a	O
simplified	O
discussed	O
earlier	O
in	O
section	O
applied	O
to	O
the	O
dbm	O
is	O
given	O
in	O
algorithm	O
varient	O
of	O
the	O
dbm	O
that	O
lacks	O
bias	O
parameters	O
including	O
them	O
is	O
trivial	O
layer-wise	O
pretraining	O
unfortunately	O
training	O
a	O
dbm	O
using	O
stochastic	O
maximum	B
likelihood	I
described	O
above	O
from	O
a	O
random	O
initialization	B
usually	O
results	O
in	O
failure	O
in	O
some	O
cases	O
the	O
model	O
fails	O
to	O
learn	O
to	O
represent	O
the	O
distribution	O
adequately	O
in	O
other	O
cases	O
the	O
dbm	O
may	O
represent	O
the	O
distribution	O
well	O
but	O
with	O
no	O
higher	O
likelihood	O
than	O
could	O
be	O
obtained	O
with	O
just	O
an	O
rbm	O
a	O
dbm	O
with	O
very	O
small	O
weights	B
in	O
all	O
but	O
the	O
first	O
layer	O
represents	O
approximately	O
the	O
same	O
distribution	O
as	O
an	O
rbm	O
various	O
techniques	O
that	O
permit	O
joint	O
training	O
have	O
been	O
developed	O
and	O
are	O
however	O
the	O
original	O
and	O
most	O
popular	O
method	O
for	O
described	O
in	O
section	O
overcoming	O
the	O
joint	O
training	O
problem	O
of	O
dbms	O
is	O
greedy	O
layer-wise	O
pretraining	O
in	O
this	O
method	O
each	O
layer	O
of	O
the	O
dbm	O
is	O
trained	O
in	O
isolation	O
as	O
an	O
rbm	O
the	O
first	O
layer	O
is	O
trained	O
to	O
model	O
the	O
input	O
data	O
each	O
subsequent	O
rbm	O
is	O
trained	O
to	O
model	O
samples	O
from	O
the	O
previous	O
rbm	O
s	O
posterior	O
distribution	O
after	O
all	O
of	O
the	O
chapter	O
deep	O
generative	O
models	O
algorithm	O
the	O
variational	O
stochastic	O
maximum	B
likelihood	I
algorithm	O
for	O
training	O
a	O
dbm	O
with	O
two	O
hidden	O
layers	O
to	O
burn	O
in	O
starting	O
from	O
samples	O
from	O
pv	O
h	O
set	O
the	O
step	O
size	O
to	O
a	O
small	O
positive	O
number	O
set	O
k	O
the	O
number	O
of	O
gibbs	O
steps	O
high	O
enough	O
to	O
allow	O
a	O
markov	B
chain	I
of	O
pv	O
h	O
initialize	O
three	O
matrices	O
v	O
h	O
and	O
h	O
each	O
with	O
m	O
rows	O
set	O
to	O
random	O
values	O
from	O
bernoulli	O
distributions	O
possibly	O
with	O
marginals	O
matched	O
to	O
the	O
model	O
s	O
marginals	O
while	O
not	O
converged	O
loop	B
do	O
sample	O
a	O
minibatch	B
of	O
m	O
examples	O
from	O
the	O
training	O
data	O
and	O
arrange	O
them	O
as	O
the	O
rows	O
of	O
a	O
design	B
matrix	I
initialize	O
matrices	O
h	O
and	O
possibly	O
to	O
the	O
model	O
s	O
marginals	O
while	O
not	O
converged	O
field	O
inference	O
loop	B
do	O
h	O
h	O
v	O
w	O
h	O
l	O
w	O
w	O
h	O
v	O
h	O
k	O
sampling	O
end	O
while	O
m	O
m	O
to	O
for	O
gibbs	O
block	O
i	O
j	O
v	O
ij	O
sampled	O
from	O
p	O
vij	O
i	O
j	O
h	O
gibbs	O
block	O
i	O
j	O
h	O
ij	O
sampled	O
from	O
p	O
ij	O
sampled	O
from	O
p	O
do	O
i	O
w	O
j	O
ij	O
i	O
w	O
ij	O
viw	O
h	O
i	O
w	O
j	O
w	O
w	O
end	O
for	O
w	O
w	O
effective	O
algorithm	O
such	O
as	O
momentum	O
with	O
a	O
decaying	O
learning	B
rate	I
w	O
h	O
v	O
m	O
m	O
w	O
w	O
is	O
a	O
cartoon	O
illustration	O
in	O
practice	O
use	O
a	O
more	O
w	O
h	O
w	O
w	O
end	O
while	O
chapter	O
deep	O
generative	O
models	O
rbms	O
have	O
been	O
trained	O
in	O
this	O
way	O
they	O
can	O
be	O
combined	O
to	O
form	O
a	O
dbm	O
the	O
dbm	O
may	O
then	O
be	O
trained	O
with	O
pcd	O
typically	O
pcd	O
training	O
will	O
make	O
only	O
a	O
small	O
change	O
in	O
the	O
model	O
s	O
parameters	O
and	O
its	O
performance	O
as	O
measured	O
by	O
the	O
log-likelihood	O
it	O
assigns	O
to	O
the	O
data	O
or	O
its	O
ability	O
to	O
classify	O
inputs	O
see	O
figure	O
for	O
an	O
illustration	O
of	O
the	O
training	O
procedure	O
this	O
greedy	O
layer-wise	O
training	O
procedure	O
is	O
not	O
just	O
coordinate	O
ascent	O
it	O
bears	O
some	O
passing	O
resemblance	O
to	O
coordinate	O
ascent	O
because	O
we	O
optimize	O
one	O
subset	O
of	O
the	O
parameters	O
at	O
each	O
step	O
the	O
two	O
methods	O
differ	O
because	O
the	O
greedy	O
layer-wise	O
training	O
procedure	O
uses	O
a	O
different	O
objective	B
function	I
at	O
each	O
step	O
greedy	O
layer-wise	O
pretraining	O
of	O
a	O
dbm	O
differs	O
from	O
greedy	O
layer-wise	O
pretraining	O
of	O
a	O
dbn	O
the	O
parameters	O
of	O
each	O
individual	O
rbm	O
may	O
be	O
copied	O
to	O
the	O
corresponding	O
dbn	O
directly	O
in	O
the	O
case	O
of	O
the	O
dbm	O
the	O
rbm	O
parameters	O
must	O
be	O
modified	O
before	O
inclusion	O
in	O
the	O
dbm	O
a	O
layer	O
in	O
the	O
middle	O
of	O
the	O
stack	O
of	O
rbms	O
is	O
trained	O
with	O
only	O
bottom-up	O
input	O
but	O
after	O
the	O
stack	O
is	O
combined	O
to	O
form	O
the	O
dbm	O
the	O
layer	O
will	O
have	O
both	O
bottom-up	O
and	O
top-down	O
input	O
to	O
account	O
for	O
this	O
effect	O
salakhutdinov	O
and	O
hinton	O
advocate	O
dividing	O
the	O
weights	B
of	O
all	O
but	O
the	O
top	O
and	O
bottom	O
rbm	O
in	O
half	O
before	O
inserting	O
them	O
into	O
the	O
dbm	O
additionally	O
the	O
bottom	O
rbm	O
must	O
be	O
trained	O
using	O
two	O
copies	O
of	O
each	O
visible	O
unit	O
and	O
the	O
weights	B
tied	O
to	O
be	O
equal	O
between	O
the	O
two	O
copies	O
this	O
means	O
that	O
the	O
weights	B
are	O
effectively	O
doubled	O
during	O
the	O
upward	O
pass	O
similarly	O
the	O
top	O
rbm	O
should	O
be	O
trained	O
with	O
two	O
copies	O
of	O
the	O
topmost	O
layer	O
obtaining	O
the	O
state	O
of	O
the	O
art	O
results	O
with	O
the	O
deep	O
boltzmann	O
machine	O
requires	O
a	O
modification	O
of	O
the	O
standard	O
sml	O
algorithm	O
which	O
is	O
to	O
use	O
a	O
small	O
amount	O
of	O
mean	O
field	O
during	O
the	O
negative	O
phase	O
of	O
the	O
joint	O
pcd	O
training	O
step	O
and	O
hinton	O
specifically	O
the	O
expectation	B
of	O
the	O
energy	O
gradient	B
should	O
be	O
computed	O
with	O
respect	O
to	O
the	O
mean	O
field	O
distribution	O
in	O
which	O
all	O
of	O
the	O
units	O
are	O
independent	O
from	O
each	O
other	O
the	O
parameters	O
of	O
this	O
mean	O
field	O
distribution	O
should	O
be	O
obtained	O
by	O
running	O
the	O
mean	O
field	O
fixed	O
point	O
equations	O
for	O
just	O
one	O
step	O
see	O
for	O
a	O
comparison	O
of	O
the	O
performance	O
of	O
centered	O
dbms	O
with	O
and	O
without	O
the	O
use	O
of	O
partial	O
mean	O
field	O
in	O
the	O
negative	O
phase	O
goodfellow	O
et	O
al	O
jointly	O
training	O
deep	O
boltzmann	O
machines	O
classic	O
dbms	O
require	O
greedy	O
unsupervised	B
pretraining	I
and	O
to	O
perform	O
classification	B
well	O
require	O
a	O
separate	O
mlp-based	O
classifier	O
on	O
top	O
of	O
the	O
hidden	O
features	O
they	O
extract	O
this	O
has	O
some	O
undesirable	O
properties	O
it	O
is	O
hard	O
to	O
track	O
performance	O
during	O
training	O
because	O
we	O
cannot	O
evaluate	O
properties	O
of	O
the	O
full	O
dbm	O
while	O
training	O
the	O
first	O
rbm	O
thus	O
it	O
is	O
hard	O
to	O
tell	O
how	O
well	O
our	O
hyperparameters	O
chapter	O
deep	O
generative	O
models	O
a	O
b	O
c	O
d	O
et	O
al	O
figure	O
the	O
deep	O
boltzmann	O
machine	O
training	O
procedure	O
used	O
to	O
classify	O
the	O
mnist	O
dataset	B
and	O
hinton	O
srivastava	O
train	O
an	O
rbm	O
by	O
using	O
cd	O
to	O
approximately	O
maximize	O
log	O
pv	O
train	O
a	O
second	O
rbm	O
that	O
models	O
and	O
target	O
class	O
y	O
by	O
using	O
cd-k	O
to	O
approximately	O
maximize	O
log	O
p	O
y	O
where	O
is	O
drawn	O
from	O
the	O
first	O
rbm	O
s	O
posterior	O
conditioned	O
on	O
the	O
data	O
increase	O
k	O
from	O
combine	O
the	O
two	O
rbms	O
into	O
a	O
dbm	O
train	O
it	O
to	O
approximately	O
to	O
during	O
learning	O
maximize	O
log	O
pv	O
y	O
using	O
stochastic	O
maximum	B
likelihood	I
with	O
k	O
y	O
from	O
the	O
model	O
define	O
a	O
new	O
set	O
of	O
features	O
and	O
that	O
are	O
obtained	O
by	O
running	O
mean	O
field	O
inference	O
in	O
the	O
model	O
lacking	O
y	O
use	O
these	O
features	O
as	O
input	O
to	O
an	O
mlp	O
whose	O
structure	O
is	O
the	O
same	O
as	O
an	O
additional	O
pass	O
of	O
mean	O
field	O
with	O
an	O
additional	O
output	O
layer	O
for	O
the	O
estimate	O
of	O
y	O
initialize	O
the	O
mlp	O
s	O
weights	B
to	O
be	O
the	O
same	O
as	O
the	O
dbm	O
s	O
weights	B
train	O
the	O
mlp	O
to	O
approximately	O
maximize	O
log	O
p	O
v	O
using	O
stochastic	O
gradient	B
descent	O
and	O
dropout	O
figure	O
reprinted	O
from	O
goodfellow	O
et	O
al	O
delete	O
chapter	O
deep	O
generative	O
models	O
are	O
working	O
until	O
quite	O
late	O
in	O
the	O
training	O
process	O
software	O
implementations	O
of	O
dbms	O
need	O
to	O
have	O
many	O
different	O
components	O
for	O
cd	O
training	O
of	O
individual	O
rbms	O
pcd	O
training	O
of	O
the	O
full	O
dbm	O
and	O
training	O
based	O
on	O
back-propagation	B
through	O
the	O
mlp	O
finally	O
the	O
mlp	O
on	O
top	O
of	O
the	O
boltzmann	O
machine	O
loses	O
many	O
of	O
the	O
advantages	O
of	O
the	O
boltzmann	O
machine	O
probabilistic	O
model	O
such	O
as	O
being	O
able	O
to	O
perform	O
inference	O
when	O
some	O
input	O
values	O
are	O
missing	O
there	O
are	O
two	O
main	O
ways	O
to	O
resolve	O
the	O
joint	O
training	O
problem	O
of	O
the	O
deep	O
boltzmann	O
machine	O
the	O
first	O
is	O
the	O
centered	O
deep	O
boltzmann	O
machine	O
and	O
muller	O
which	O
reparametrizes	O
the	O
model	O
in	O
order	O
to	O
make	O
the	O
hessian	B
of	O
the	O
cost	O
function	O
better-conditioned	O
at	O
the	O
beginning	O
of	O
the	O
learning	O
process	O
this	O
yields	O
a	O
model	O
that	O
can	O
be	O
trained	O
without	O
a	O
greedy	O
layer-wise	O
pretraining	O
stage	O
the	O
resulting	O
model	O
obtains	O
excellent	O
test	B
set	I
log-likelihood	O
and	O
produces	O
high	O
quality	O
samples	O
unfortunately	O
it	O
remains	O
unable	O
to	O
compete	O
with	O
appropriately	O
regularized	O
mlps	O
as	O
a	O
classifier	O
the	O
second	O
way	O
to	O
jointly	O
train	O
a	O
deep	O
boltzmann	O
machine	O
is	O
to	O
use	O
a	O
multi-prediction	O
deep	O
boltzmann	O
machine	O
this	O
model	O
uses	O
an	O
alternative	O
training	O
criterion	O
that	O
allows	O
the	O
use	O
of	O
the	O
back-propagation	B
algorithm	O
in	O
order	O
to	O
avoid	O
the	O
problems	O
with	O
mcmc	O
estimates	O
of	O
the	O
gradient	B
unfortunately	O
the	O
new	O
criterion	O
does	O
not	O
lead	O
to	O
good	O
likelihood	O
or	O
samples	O
but	O
compared	O
to	O
the	O
mcmc	O
approach	O
it	O
does	O
lead	O
to	O
superior	O
classification	B
performance	O
and	O
ability	O
to	O
reason	O
well	O
about	O
missing	B
inputs	I
et	O
al	O
the	O
centering	O
trick	B
for	O
the	O
boltzmann	O
machine	O
is	O
easiest	O
to	O
describe	O
if	O
we	O
return	O
to	O
the	O
general	O
view	O
of	O
a	O
boltzmann	O
machine	O
as	O
consisting	O
of	O
a	O
set	O
of	O
units	O
x	O
with	O
a	O
weight	O
matrix	O
u	O
and	O
biases	O
b	O
recall	B
from	O
equation	O
that	O
he	O
energy	B
function	I
is	O
given	O
by	O
x	O
e	O
x	O
u	O
x	O
b	O
x	O
using	O
different	O
sparsity	O
patterns	O
in	O
the	O
weight	O
matrix	O
u	O
we	O
can	O
implement	O
structures	O
of	O
boltzmann	O
machines	O
such	O
as	O
rbms	O
or	O
dbms	O
with	O
different	O
numbers	O
of	O
layers	O
this	O
is	O
accomplished	O
by	O
partitioning	O
x	O
into	O
visible	O
and	O
hidden	O
units	O
and	O
zeroing	O
out	O
elements	O
of	O
u	O
for	O
units	O
that	O
do	O
not	O
interact	O
the	O
centered	O
boltzmann	O
machine	O
introduces	O
a	O
vector	O
that	O
is	O
subtracted	O
from	O
all	O
of	O
the	O
states	O
x	O
x	O
u	O
x	O
b	O
e	O
x	O
u	O
b	O
typically	O
is	O
a	O
hyperparameter	O
fixed	O
at	O
the	O
beginning	O
of	O
training	O
it	O
is	O
usually	O
chosen	O
to	O
make	O
sure	O
that	O
x	O
when	O
the	O
model	O
is	O
initialized	O
this	O
reparametrization	O
does	O
not	O
change	O
the	O
set	O
of	O
probability	O
distributions	O
that	O
the	O
model	O
can	O
represent	O
but	O
it	O
does	O
change	O
the	O
dynamics	O
of	O
stochastic	O
gradient	B
descent	O
applied	O
to	O
the	O
likelihood	O
specifically	O
in	O
many	O
cases	O
this	O
reparametrization	O
results	O
chapter	O
deep	O
generative	O
models	O
experimentally	O
in	O
a	O
hessian	B
matrix	O
that	O
is	O
better	O
conditioned	O
confirmed	O
that	O
the	O
conditioning	O
of	O
the	O
hessian	B
matrix	O
improves	O
and	O
observed	O
that	O
the	O
centering	O
trick	B
is	O
equivalent	O
to	O
another	O
boltzmann	O
machine	B
learning	I
technique	O
the	O
enhanced	O
gradient	B
the	O
improved	O
conditioning	O
of	O
the	O
hessian	B
matrix	O
allows	O
learning	O
to	O
succeed	O
even	O
in	O
difficult	O
cases	O
like	O
training	O
a	O
deep	O
boltzmann	O
machine	O
with	O
multiple	O
layers	O
melchior	O
et	O
al	O
cho	O
et	O
al	O
the	O
other	O
approach	O
to	O
jointly	O
training	O
deep	O
boltzmann	O
machines	O
is	O
the	O
multiprediction	O
deep	O
boltzmann	O
machine	O
which	O
works	O
by	O
viewing	O
the	O
mean	O
field	O
equations	O
as	O
defining	O
a	O
family	O
of	O
recurrent	O
networks	O
for	O
approximately	O
solving	O
every	O
possible	O
inference	O
problem	O
rather	O
than	O
training	O
the	O
model	O
to	O
maximize	O
the	O
likelihood	O
the	O
model	O
is	O
trained	O
to	O
make	O
each	O
recurrent	B
network	I
obtain	O
an	O
accurate	O
answer	O
to	O
the	O
corresponding	O
inference	O
problem	O
the	O
training	O
process	O
is	O
illustrated	O
in	O
figure	O
it	O
consists	O
of	O
randomly	O
sampling	O
a	O
training	O
example	B
randomly	O
sampling	O
a	O
subset	O
of	O
inputs	O
to	O
the	O
inference	O
network	O
and	O
then	O
training	O
the	O
inference	O
network	O
to	O
predict	O
the	O
values	O
of	O
the	O
remaining	O
units	O
goodfellow	O
et	O
al	O
et	O
al	O
this	O
general	O
principle	O
of	O
back-propagating	O
through	O
the	O
computational	B
graph	I
for	O
approximate	B
inference	I
has	O
been	O
applied	O
to	O
other	O
models	O
in	O
these	O
models	O
and	O
in	O
the	O
mp-dbm	O
the	O
final	O
loss	O
is	O
not	O
brakel	O
the	O
lower	O
bound	B
on	O
the	O
likelihood	O
instead	O
the	O
final	O
loss	O
is	O
typically	O
based	O
on	O
the	O
approximate	O
conditional	O
distribution	O
that	O
the	O
approximate	B
inference	I
network	O
imposes	O
over	O
the	O
missing	O
values	O
this	O
means	O
that	O
the	O
training	O
of	O
these	O
models	O
is	O
somewhat	O
heuristically	O
motivated	O
if	O
we	O
inspect	O
the	O
pv	O
represented	O
by	O
the	O
boltzmann	O
machine	O
learned	O
by	O
the	O
mp-dbm	O
it	O
tends	O
to	O
be	O
somewhat	O
defective	O
in	O
the	O
sense	O
that	O
gibbs	O
sampling	O
yields	O
poor	O
samples	O
et	O
al	O
back-propagation	B
through	O
the	O
inference	O
graph	O
has	O
two	O
main	O
advantages	O
first	O
it	O
trains	O
the	O
model	O
as	O
it	O
is	O
really	O
used	O
with	O
approximate	B
inference	I
this	O
means	O
that	O
approximate	B
inference	I
for	O
example	B
to	O
fill	O
in	O
missing	B
inputs	I
or	O
to	O
perform	O
classification	B
despite	O
the	O
presence	O
of	O
missing	B
inputs	I
is	O
more	O
accurate	O
in	O
the	O
mpdbm	O
than	O
in	O
the	O
original	O
dbm	O
the	O
original	O
dbm	O
does	O
not	O
make	O
an	O
accurate	O
classifier	O
on	O
its	O
own	O
the	O
best	O
classification	B
results	O
with	O
the	O
original	O
dbm	O
were	O
based	O
on	O
training	O
a	O
separate	O
classifier	O
to	O
use	O
features	O
extracted	O
by	O
the	O
dbm	O
rather	O
than	O
by	O
using	O
inference	O
in	O
the	O
dbm	O
to	O
compute	O
the	O
distribution	O
over	O
the	O
class	O
labels	O
mean	O
field	O
inference	O
in	O
the	O
mp-dbm	O
performs	O
well	O
as	O
a	O
classifier	O
without	O
special	O
modifications	O
the	O
other	O
advantage	O
of	O
back-propagating	O
through	O
approximate	B
inference	I
is	O
that	O
back-propagation	B
computes	O
the	O
exact	O
gradient	B
of	O
the	O
loss	O
this	O
is	O
better	O
for	O
optimization	O
than	O
the	O
approximate	O
gradients	O
of	O
sml	O
training	O
which	O
suffer	O
from	O
both	O
bias	O
and	O
variance	O
this	O
probably	O
explains	O
why	O
mp	O
chapter	O
deep	O
generative	O
models	O
figure	O
an	O
illustration	O
of	O
the	O
multi-prediction	O
training	O
process	O
for	O
a	O
deep	O
boltzmann	O
machine	O
each	O
row	O
indicates	O
a	O
different	O
example	B
within	O
a	O
minibatch	B
for	O
the	O
same	O
training	O
step	O
each	O
column	O
represents	O
a	O
time	O
step	O
within	O
the	O
mean	O
field	O
inference	O
process	O
for	O
each	O
example	B
we	O
sample	O
a	O
subset	O
of	O
the	O
data	O
variables	O
to	O
serve	O
as	O
inputs	O
to	O
the	O
inference	O
process	O
these	O
variables	O
are	O
shaded	O
black	O
to	O
indicate	O
conditioning	O
we	O
then	O
run	O
the	O
mean	O
field	O
inference	O
process	O
with	O
arrows	O
indicating	O
which	O
variables	O
influence	O
which	O
other	O
variables	O
in	O
the	O
process	O
in	O
practical	O
applications	O
we	O
unroll	O
mean	O
field	O
for	O
several	O
steps	O
in	O
this	O
illustration	O
we	O
unroll	O
for	O
only	O
two	O
steps	O
dashed	O
arrows	O
indicate	O
how	O
the	O
process	O
could	O
be	O
unrolled	O
for	O
more	O
steps	O
the	O
data	O
variables	O
that	O
were	O
not	O
used	O
as	O
inputs	O
to	O
the	O
inference	O
process	O
become	O
targets	O
shaded	O
in	O
gray	O
we	O
can	O
view	O
the	O
inference	O
process	O
for	O
each	O
example	B
as	O
a	O
recurrent	B
network	I
we	O
use	O
gradient	B
descent	O
and	O
back-propagation	B
to	O
train	O
these	O
recurrent	O
networks	O
to	O
produce	O
the	O
correct	O
targets	O
given	O
their	O
inputs	O
this	O
trains	O
the	O
mean	O
field	O
process	O
for	O
the	O
mp-dbm	O
to	O
produce	O
accurate	O
estimates	O
figure	O
adapted	O
from	O
goodfellow	O
et	O
al	O
chapter	O
deep	O
generative	O
models	O
dbms	O
may	O
be	O
trained	O
jointly	O
while	O
dbms	O
require	O
a	O
greedy	O
layer-wise	O
pretraining	O
the	O
disadvantage	O
of	O
back-propagating	O
through	O
the	O
approximate	B
inference	I
graph	O
is	O
that	O
it	O
does	O
not	O
provide	O
a	O
way	O
to	O
optimize	O
the	O
log-likelihood	O
but	O
rather	O
a	O
heuristic	O
approximation	O
of	O
the	O
generalized	O
pseudolikelihood	B
the	O
mp-dbm	O
inspired	O
the	O
nade-k	O
extension	O
to	O
the	O
nade	B
framework	O
which	O
is	O
described	O
in	O
section	O
et	O
al	O
the	O
mp-dbm	O
has	O
some	O
connections	O
to	O
dropout	O
dropout	O
shares	O
the	O
same	O
parameters	O
among	O
many	O
different	O
computational	O
graphs	O
with	O
the	O
difference	O
between	O
each	O
graph	O
being	O
whether	O
it	O
includes	O
or	O
excludes	O
each	O
unit	O
the	O
mp-dbm	O
also	O
shares	O
parameters	O
across	O
many	O
computational	O
graphs	O
in	O
the	O
case	O
of	O
the	O
mp-dbm	O
the	O
difference	O
between	O
the	O
graphs	O
is	O
whether	O
each	O
input	O
unit	O
is	O
observed	O
or	O
not	O
when	O
a	O
unit	O
is	O
not	O
observed	O
the	O
mp-dbm	O
does	O
not	O
delete	O
it	O
entirely	O
as	O
dropout	O
does	O
instead	O
the	O
mp-dbm	O
treats	O
it	O
as	O
a	O
latent	B
variable	I
to	O
be	O
inferred	O
one	O
could	O
imagine	O
applying	O
dropout	O
to	O
the	O
mp-dbm	O
by	O
additionally	O
removing	O
some	O
units	O
rather	O
than	O
making	O
them	O
latent	O
boltzmann	O
machines	O
for	O
real-valued	O
data	O
while	O
boltzmann	O
machines	O
were	O
originally	O
developed	O
for	O
use	O
with	O
binary	O
data	O
many	O
applications	O
such	O
as	O
image	O
and	O
audio	O
modeling	O
seem	O
to	O
require	O
the	O
ability	O
to	O
represent	O
probability	O
distributions	O
over	O
real	O
values	O
in	O
some	O
cases	O
it	O
is	O
possible	O
to	O
treat	O
real-valued	O
data	O
in	O
the	O
interval	O
as	O
representing	O
the	O
expectation	B
of	O
a	O
binary	O
variable	O
for	O
example	B
treats	O
grayscale	O
images	O
in	O
the	O
training	O
set	O
as	O
defining	O
probability	O
values	O
each	O
pixel	O
defines	O
the	O
probability	O
of	O
a	O
binary	O
value	O
being	O
and	O
the	O
binary	O
pixels	O
are	O
all	O
sampled	O
independently	O
from	O
each	O
other	O
this	O
is	O
a	O
common	O
procedure	O
for	O
evaluating	O
binary	O
models	O
on	O
grayscale	O
image	O
datasets	O
however	O
it	O
is	O
not	O
a	O
particularly	O
theoretically	O
satisfying	O
approach	O
and	O
binary	O
images	O
sampled	O
independently	O
in	O
this	O
way	O
have	O
a	O
noisy	O
appearance	O
in	O
this	O
section	O
we	O
present	O
boltzmann	O
machines	O
that	O
define	O
a	O
probability	O
density	O
over	O
real-valued	O
data	O
hinton	O
gaussian-bernoulli	O
rbms	O
restricted	O
boltzmann	O
machines	O
may	O
be	O
developed	O
for	O
many	O
exponential	O
family	O
conditional	O
distributions	O
of	O
these	O
the	O
most	O
common	O
is	O
the	O
rbm	O
with	O
binary	O
hidden	O
units	O
and	O
real-valued	O
visible	O
units	O
with	O
the	O
conditional	O
distribution	O
over	O
the	O
visible	O
units	O
being	O
a	O
gaussian	O
distribution	O
whose	O
mean	O
is	O
a	O
function	O
of	O
the	O
hidden	O
units	O
et	O
al	O
chapter	O
deep	O
generative	O
models	O
there	O
are	O
many	O
ways	O
of	O
parametrizing	O
gaussian-bernoulli	O
rbms	O
one	O
choice	O
is	O
whether	O
to	O
use	O
a	O
covariance	B
matrix	I
or	O
a	O
precision	B
matrix	O
for	O
the	O
gaussian	O
distribution	O
here	O
we	O
present	O
the	O
precision	B
formulation	O
the	O
modification	O
to	O
obtain	O
the	O
covariance	O
formulation	O
is	O
straightforward	O
we	O
wish	O
to	O
have	O
the	O
conditional	O
distribution	O
v	O
h	O
p	O
n	O
v	O
w	O
h	O
we	O
can	O
find	O
the	O
terms	O
we	O
need	O
to	O
add	O
to	O
the	O
energy	B
function	I
by	O
expanding	O
the	O
unnormalized	O
log	O
conditional	O
distribution	O
n	O
log	O
v	O
w	O
h	O
v	O
w	O
h	O
v	O
w	O
h	O
here	O
f	O
encapsulates	O
all	O
the	O
terms	O
that	O
are	O
a	O
function	O
only	O
of	O
the	O
parameters	O
and	O
not	O
the	O
random	O
variables	O
in	O
the	O
model	O
we	O
can	O
discard	O
f	O
because	O
its	O
only	O
role	O
is	O
to	O
normalize	O
the	O
distribution	O
and	O
the	O
partition	O
function	O
of	O
whatever	O
energy	B
function	I
we	O
choose	O
will	O
carry	O
out	O
that	O
role	O
if	O
we	O
include	O
all	O
of	O
the	O
terms	O
their	O
sign	O
flipped	O
involving	O
v	O
from	O
equav	O
then	O
in	O
our	O
energy	B
function	I
and	O
do	O
not	O
add	O
any	O
other	O
terms	O
involving	O
tion	B
our	O
energy	B
function	I
will	O
represent	O
the	O
desired	O
conditional	O
we	O
have	O
some	O
freedom	O
regarding	O
the	O
other	O
conditional	O
distribution	O
ph	O
v	O
v	O
h	O
p	O
note	O
that	O
equation	O
contains	O
a	O
term	O
h	O
w	O
w	O
h	O
this	O
term	O
cannot	O
be	O
included	O
in	O
its	O
entirety	O
because	O
it	O
includes	O
hihj	O
terms	O
these	O
correspond	O
to	O
edges	O
between	O
the	O
hidden	O
units	O
if	O
we	O
included	O
these	O
terms	O
we	O
would	O
have	O
a	O
linear	O
factor	O
model	O
instead	O
of	O
a	O
restricted	O
boltzmann	O
machine	O
when	O
designing	O
our	O
boltzmann	O
machine	O
we	O
simply	O
omit	O
these	O
hi	O
hj	O
cross	O
terms	O
omitting	O
them	O
does	O
not	O
change	O
the	O
conditional	O
pv	O
h	O
is	O
still	O
respected	O
however	O
we	O
still	O
have	O
a	O
choice	O
about	O
whether	O
to	O
include	O
the	O
terms	O
involving	O
only	O
a	O
single	O
hi	O
if	O
we	O
assume	O
a	O
diagonal	O
precision	B
matrix	O
we	O
find	O
that	O
for	O
each	O
hidden	O
unit	O
hi	O
we	O
have	O
a	O
term	O
so	O
equation	O
h	O
i	O
jw	O
ji	O
in	O
the	O
above	O
we	O
used	O
the	O
fact	O
that	O
if	O
we	O
include	O
this	O
term	O
its	O
sign	O
flipped	O
in	O
the	O
energy	B
function	I
then	O
it	O
will	O
naturally	O
bias	O
h	O
i	O
to	O
be	O
turned	O
off	O
when	O
the	O
weights	B
for	O
that	O
unit	O
are	O
large	O
and	O
connected	O
to	O
visible	O
units	O
with	O
high	O
precision	B
the	O
choice	O
of	O
whether	O
or	O
not	O
to	O
include	O
this	O
bias	O
term	O
does	O
not	O
affect	O
the	O
family	O
of	O
distributions	O
the	O
model	O
can	O
represent	O
that	O
j	O
i	O
hi	O
because	O
hi	O
chapter	O
deep	O
generative	O
models	O
we	O
include	O
bias	O
parameters	O
for	O
the	O
hidden	O
units	O
but	O
it	O
does	O
affect	O
the	O
learning	O
dynamics	O
of	O
the	O
model	O
including	O
the	O
term	O
may	O
help	O
the	O
hidden	O
unit	O
activations	O
remain	O
reasonable	O
even	O
when	O
the	O
weights	B
rapidly	O
increase	O
in	O
magnitude	O
one	O
way	O
to	O
define	O
the	O
energy	B
function	I
on	O
a	O
gaussian-bernoulli	O
rbm	O
is	O
thus	O
e	O
h	O
v	O
v	O
v	O
w	O
h	O
b	O
h	O
but	O
we	O
may	O
also	O
add	O
extra	O
terms	O
or	O
parametrize	O
the	O
energy	O
in	O
terms	O
of	O
the	O
variance	O
rather	O
than	O
precision	B
if	O
we	O
choose	O
in	O
this	O
derivation	O
we	O
have	O
not	O
included	O
a	O
bias	O
term	O
on	O
the	O
visible	O
units	O
but	O
one	O
could	O
easily	O
be	O
added	O
one	O
final	O
source	O
of	O
variability	O
in	O
the	O
parametrization	O
of	O
a	O
gaussian-bernoulli	O
rbm	O
is	O
the	O
choice	O
of	O
how	O
to	O
treat	O
the	O
precision	B
matrix	O
it	O
may	O
either	O
be	O
fixed	O
to	O
a	O
constant	O
estimated	O
based	O
on	O
the	O
marginal	O
precision	B
of	O
the	O
data	O
or	O
learned	O
it	O
may	O
also	O
be	O
a	O
scalar	O
times	O
the	O
identity	B
matrix	I
or	O
it	O
may	O
be	O
a	O
diagonal	B
matrix	I
typically	O
we	O
do	O
not	O
allow	O
the	O
precision	B
matrix	O
to	O
be	O
non-diagonal	O
in	O
this	O
context	O
because	O
some	O
operations	O
on	O
the	O
gaussian	O
distribution	O
require	O
inverting	O
the	O
matrix	O
and	O
a	O
diagonal	B
matrix	I
can	O
be	O
inverted	O
trivially	O
in	O
the	O
sections	O
ahead	O
we	O
will	O
see	O
that	O
other	O
forms	O
of	O
boltzmann	O
machines	O
permit	O
modeling	O
the	O
covariance	O
structure	O
using	O
various	O
techniques	O
to	O
avoid	O
inverting	O
the	O
precision	B
matrix	O
undirected	O
models	O
of	O
conditional	O
covariance	O
ranzato	O
et	O
al	O
while	O
the	O
gaussian	O
rbm	O
has	O
been	O
the	O
canonical	O
energy	O
model	O
for	O
real-valued	O
data	O
argue	O
that	O
the	O
gaussian	O
rbm	O
inductive	O
bias	O
is	O
not	O
well	O
suited	O
to	O
the	O
statistical	O
variations	O
present	O
in	O
some	O
types	O
of	O
real-valued	O
data	O
especially	O
natural	O
images	O
the	O
problem	O
is	O
that	O
much	O
of	O
the	O
information	O
content	O
present	O
in	O
natural	O
images	O
is	O
embedded	O
in	O
the	O
covariance	O
between	O
pixels	O
rather	O
than	O
in	O
the	O
raw	O
pixel	O
values	O
in	O
other	O
words	O
it	O
is	O
the	O
relationships	O
between	O
pixels	O
and	O
not	O
their	O
absolute	O
values	O
where	O
most	O
of	O
the	O
useful	O
information	O
in	O
images	O
resides	O
since	O
the	O
gaussian	O
rbm	O
only	O
models	O
the	O
conditional	O
mean	O
of	O
the	O
input	O
given	O
the	O
hidden	O
units	O
it	O
cannot	O
capture	O
conditional	O
covariance	O
information	O
in	O
response	O
to	O
these	O
criticisms	O
alternative	O
models	O
have	O
been	O
proposed	O
that	O
attempt	O
to	O
better	O
account	O
for	O
the	O
covariance	O
of	O
real-valued	O
data	O
these	O
models	O
include	O
the	O
mean	O
and	O
covariance	O
rbm	O
the	O
mean-product	O
of	O
t-distribution	O
model	O
and	O
the	O
spike	O
and	O
slab	O
rbm	O
term	O
mcrbm	O
is	O
pronounced	O
by	O
saying	O
the	O
name	O
of	O
the	O
letters	O
m-c-r-b-m	O
the	O
mc	O
is	O
not	O
pronounced	O
like	O
the	O
mc	O
in	O
mcdonald	O
s	O
chapter	O
deep	O
generative	O
models	O
mean	O
and	O
covariance	O
rbm	O
the	O
mcrbm	O
uses	O
its	O
hidden	O
units	O
to	O
independently	O
encode	O
the	O
conditional	O
mean	O
and	O
covariance	O
of	O
all	O
observed	O
units	O
the	O
mcrbm	O
hidden	B
layer	I
is	O
divided	O
into	O
two	O
groups	O
of	O
units	O
mean	O
units	O
and	O
covariance	O
units	O
the	O
group	O
that	O
models	O
the	O
conditional	O
mean	O
is	O
simply	O
a	O
gaussian	O
rbm	O
the	O
other	O
half	O
is	O
a	O
covariance	O
rbm	O
also	O
called	O
a	O
crbm	O
whose	O
components	O
model	O
the	O
conditional	O
covariance	O
structure	O
as	O
described	O
below	O
ranzato	O
et	O
al	O
specifically	O
with	O
binary	O
mean	O
units	O
h	O
and	O
binary	O
covariance	O
units	O
h	O
the	O
mcrbm	O
model	O
is	O
defined	O
as	O
the	O
combination	O
of	O
two	O
energy	O
functions	O
emcx	O
h	O
h	O
emx	O
h	O
ecx	O
h	O
where	O
em	O
is	O
the	O
standard	O
gaussian-bernoulli	O
rbm	O
energy	O
emx	O
h	O
x	O
x	O
j	O
h	O
b	O
j	O
j	O
x	O
wjh	O
j	O
j	O
and	O
ec	O
is	O
the	O
crbm	O
energy	B
function	I
that	O
models	O
the	O
conditional	O
covariance	O
information	O
ec	O
h	O
j	O
h	O
j	O
x	O
r	O
j	O
b	O
j	O
h	O
j	O
the	O
parameter	O
r	O
corresponds	O
to	O
the	O
covariance	O
weight	O
vector	O
associated	O
with	O
h	O
and	O
b	O
is	O
a	O
vector	O
of	O
covariance	O
offsets	O
the	O
combined	O
energy	B
function	I
defines	O
j	O
a	O
joint	O
distribution	O
z	O
emcx	O
h	O
pmcx	O
h	O
h	O
exp	O
h	O
and	O
a	O
corresponding	O
conditional	O
distribution	O
over	O
the	O
observations	O
given	O
h	O
h	O
as	O
a	O
multivariate	O
gaussian	O
distribution	O
and	O
n	O
h	O
pmcx	O
h	O
x	O
c	O
mc	O
x	O
h	O
wjh	O
j	O
c	O
mc	O
x	O
h	O
is	O
non-diagonal	O
note	O
that	O
the	O
covariance	B
matrix	I
cmc	O
x	O
h	O
and	O
that	O
w	O
is	O
the	O
weight	O
matrix	O
associated	O
with	O
the	O
gaussian	O
rbm	O
modeling	O
the	O
i	O
j	O
r	O
r	O
j	O
h	O
version	O
of	O
the	O
gaussian-bernoulli	O
rbm	O
energy	B
function	I
assumes	O
the	O
image	O
data	O
has	O
zero	O
mean	O
per	O
pixel	O
pixel	O
offsets	O
can	O
easily	O
be	O
added	O
to	O
the	O
model	O
to	O
account	O
for	O
nonzero	O
pixel	O
means	O
j	O
chapter	O
deep	O
generative	O
models	O
conditional	O
means	O
it	O
is	O
difficult	O
to	O
train	O
the	O
mcrbm	O
via	O
contrastive	O
divergence	O
or	O
persistent	O
contrastive	O
divergence	O
because	O
of	O
its	O
non-diagonal	O
conditional	O
covariance	O
h	O
structure	O
cd	O
and	O
pcd	O
require	O
sampling	O
from	O
the	O
joint	O
distribution	O
of	O
x	O
h	O
which	O
in	O
a	O
standard	O
rbm	O
is	O
accomplished	O
by	O
gibbs	O
sampling	O
over	O
the	O
conditionals	O
h	O
requires	O
computing	O
however	O
in	O
the	O
mcrbm	O
sampling	O
from	O
pmcx	O
h	O
at	O
every	O
iteration	O
of	O
learning	O
this	O
can	O
be	O
an	O
impractical	O
computational	O
burden	O
for	O
larger	O
observations	O
ranzato	O
and	O
hinton	O
avoid	O
direct	O
sampling	O
h	O
by	O
sampling	O
directly	O
from	O
the	O
marginal	O
from	O
the	O
conditional	O
pmc	O
h	O
px	O
using	O
hamiltonian	O
monte	O
carlo	O
on	O
the	O
mcrbm	O
free	O
energy	O
neal	O
t	O
extends	O
the	O
pot	O
model	O
the	O
mean-product	O
of	O
student	O
s	O
mean-product	O
of	O
student	O
s	O
t-distribution	O
model	O
welling	O
ranzato	O
et	O
al	O
et	O
al	O
in	O
a	O
manner	O
similar	O
to	O
how	O
the	O
mcrbm	O
extends	O
the	O
crbm	O
this	O
is	O
achieved	O
by	O
including	O
nonzero	O
gaussian	O
means	O
by	O
the	O
addition	O
of	O
gaussian	O
rbm-like	O
hidden	O
units	O
like	O
the	O
mcrbm	O
the	O
pot	O
conditional	O
distribution	O
over	O
the	O
observation	O
is	O
a	O
multivariate	O
gaussian	O
non-diagonal	O
covariance	O
distribution	O
however	O
unlike	O
the	O
mcrbm	O
the	O
complementary	O
conditional	O
distribution	O
over	O
the	O
hidden	O
variables	O
is	O
given	O
by	O
conditionally	O
independent	O
gamma	O
distributions	O
the	O
is	O
a	O
probability	B
distribution	I
over	O
positive	O
real	O
numbers	O
gamma	O
distribution	O
with	O
mean	O
k	O
it	O
is	O
not	O
necessary	O
to	O
have	O
a	O
more	O
detailed	O
understanding	O
of	O
the	O
gamma	O
distribution	O
to	O
understand	O
the	O
basic	O
ideas	O
underlying	O
the	O
mpot	O
model	O
g	O
the	O
mpot	O
energy	B
function	I
is	O
h	O
empotx	O
h	O
emx	O
h	O
h	O
j	O
j	O
r	O
x	O
j	O
log	O
h	O
j	O
where	O
r	O
is	O
as	O
defined	O
in	O
equation	O
is	O
the	O
covariance	O
weight	O
vector	O
associated	O
with	O
unit	O
h	O
j	O
and	O
emx	O
h	O
just	O
as	O
with	O
the	O
mcrbm	O
the	O
mpot	O
model	O
energy	B
function	I
specifies	O
a	O
multivariate	O
gaussian	O
with	O
a	O
conditional	O
distribution	O
over	O
x	O
that	O
has	O
non-diagonal	O
covariance	O
learning	O
in	O
the	O
mpot	O
model	O
again	O
like	O
the	O
mcrbm	O
is	O
complicated	O
by	O
the	O
inability	O
to	O
sample	O
from	O
the	O
non-diagonal	O
gaussian	O
conditional	O
h	O
so	O
pmpotx	O
h	O
also	O
advocate	O
direct	O
sampling	O
of	O
p	O
via	O
hamiltonian	O
monte	O
carlo	O
ranzato	O
et	O
al	O
chapter	O
deep	O
generative	O
models	O
courville	O
et	O
al	O
spike	O
and	O
slab	O
restricted	O
boltzmann	O
machines	O
spike	O
and	O
slab	O
restricted	O
boltzmann	O
machines	O
or	O
ssrbms	O
provide	O
another	O
means	O
of	O
modeling	O
the	O
covariance	O
structure	O
of	O
real-valued	O
data	O
compared	O
to	O
mcrbms	O
ssrbms	O
have	O
the	O
advantage	O
of	O
requiring	O
neither	O
matrix	O
inversion	O
nor	O
hamiltonian	O
monte	O
carlo	O
methods	O
like	O
the	O
mcrbm	O
and	O
the	O
mpot	O
model	O
the	O
ssrbm	O
s	O
binary	O
hidden	O
units	O
encode	O
the	O
conditional	O
covariance	O
across	O
pixels	O
through	O
the	O
use	O
of	O
auxiliary	O
real-valued	O
variables	O
the	O
spike	O
and	O
slab	O
rbm	O
has	O
two	O
sets	O
of	O
hidden	O
units	O
binary	O
spike	O
units	O
h	O
and	O
real-valued	O
slab	O
units	O
s	O
the	O
mean	O
of	O
the	O
visible	O
units	O
conditioned	O
on	O
the	O
hidden	O
units	O
is	O
given	O
by	O
s	O
in	O
other	O
words	O
each	O
column	O
w	O
defines	O
a	O
component	O
that	O
can	O
appear	O
in	O
the	O
input	O
when	O
hi	O
the	O
corresponding	O
spike	O
variable	O
hi	O
determines	O
whether	O
that	O
component	O
is	O
present	O
at	O
all	O
the	O
corresponding	O
slab	O
variable	O
si	O
determines	O
the	O
intensity	O
of	O
that	O
component	O
if	O
it	O
is	O
present	O
when	O
a	O
spike	O
variable	O
is	O
active	O
the	O
corresponding	O
slab	O
variable	O
adds	O
variance	O
to	O
the	O
input	O
along	O
the	O
axis	O
defined	O
by	O
wi	O
this	O
allows	O
us	O
to	O
model	O
the	O
covariance	O
of	O
the	O
inputs	O
fortunately	O
contrastive	O
divergence	O
and	O
persistent	O
contrastive	O
divergence	O
with	O
gibbs	O
sampling	O
are	O
still	O
applicable	O
there	O
is	O
no	O
need	O
to	O
invert	O
any	O
matrix	O
formally	O
the	O
ssrbm	O
model	O
is	O
defined	O
via	O
its	O
energy	B
function	I
e	O
ss	O
x	O
s	O
h	O
x	O
i	O
isih	O
i	O
wisihi	O
ihi	O
i	O
i	O
i	O
i	O
i	O
i	O
bih	O
i	O
i	O
i	O
hi	O
i	O
x	O
x	O
where	O
bi	O
is	O
the	O
offset	O
of	O
the	O
spike	O
hi	O
and	O
is	O
a	O
diagonal	O
precision	B
matrix	O
on	O
the	O
observations	O
x	O
the	O
parameter	O
i	O
is	O
a	O
scalar	O
precision	B
parameter	O
for	O
the	O
real-valued	O
slab	O
variable	O
si	O
the	O
parameter	O
i	O
is	O
a	O
non-negative	O
diagonal	B
matrix	I
that	O
defines	O
an	O
h-modulated	O
quadratic	O
penalty	O
on	O
x	O
each	O
i	O
is	O
a	O
mean	O
parameter	O
for	O
the	O
slab	O
variable	O
si	O
with	O
the	O
joint	O
distribution	O
defined	O
via	O
the	O
energy	B
function	I
it	O
is	O
relatively	O
straightforward	O
to	O
derive	O
the	O
ssrbm	O
conditional	O
distributions	O
for	O
example	B
by	O
marginalizing	O
out	O
the	O
slab	O
variables	O
s	O
the	O
conditional	O
distribution	O
over	O
the	O
observations	O
given	O
the	O
binary	O
spike	O
variables	O
exp	O
is	O
given	O
by	O
h	O
e	O
x	O
s	O
h	O
ds	O
z	O
p	O
n	O
pss	O
x	O
h	O
x	O
c	O
ss	O
x	O
h	O
wi	O
ih	O
i	O
css	O
x	O
h	O
i	O
chapter	O
deep	O
generative	O
models	O
i	O
i	O
hiwiw	O
is	O
positive	B
definite	I
where	O
c	O
ss	O
ihi	O
x	O
h	O
the	O
covariance	B
matrix	I
c	O
ss	O
x	O
h	O
gating	O
by	O
the	O
spike	O
variables	O
means	O
that	O
the	O
true	O
marginal	O
distribution	O
over	O
is	O
sparse	O
this	O
is	O
different	O
from	O
sparse	O
coding	O
where	O
samples	O
from	O
the	O
model	O
h	O
s	O
almost	O
never	O
the	O
measure	O
theoretic	O
sense	O
contain	O
zeros	O
in	O
the	O
code	O
and	O
map	O
inference	O
is	O
required	O
to	O
impose	O
sparsity	O
the	O
last	O
equality	O
holds	O
only	O
if	O
i	O
as	O
i	O
j	O
h	O
j	O
r	O
r	O
comparing	O
the	O
ssrbm	O
to	O
the	O
mcrbm	O
and	O
the	O
mpot	O
models	O
the	O
ssrbm	O
parametrizes	O
the	O
conditional	O
covariance	O
of	O
the	O
observation	O
in	O
a	O
significantly	O
different	O
way	O
the	O
mcrbm	O
and	O
mpot	O
both	O
model	O
the	O
covariance	O
structure	O
of	O
the	O
observation	O
using	O
the	O
activation	O
of	O
the	O
hidden	O
units	O
hj	O
to	O
enforce	O
constraints	O
on	O
the	O
conditional	O
covariance	O
in	O
the	O
direction	O
r	O
in	O
contrast	B
the	O
ssrbm	O
specifies	O
the	O
conditional	O
covariance	O
of	O
the	O
observations	O
using	O
the	O
hidden	O
spike	O
activations	O
hi	O
to	O
pinch	O
the	O
precision	B
matrix	O
along	O
the	O
direction	O
specified	O
by	O
the	O
corresponding	O
weight	O
vector	O
the	O
ssrbm	O
conditional	O
covariance	O
is	O
very	O
similar	O
to	O
that	O
given	O
by	O
a	O
different	O
model	O
the	O
product	O
of	O
probabilistic	O
principal	O
components	O
analysis	O
and	O
agakov	O
in	O
the	O
overcomplete	O
setting	O
sparse	O
activations	O
with	O
the	O
ssrbm	O
parametrization	O
permit	O
significant	O
only	O
in	O
the	O
selected	O
directions	O
variance	O
the	O
nominal	O
variance	O
given	O
by	O
of	O
the	O
sparsely	O
activated	O
hi	O
in	O
the	O
mcrbm	O
or	O
mpot	O
models	O
an	O
overcomplete	O
representation	O
would	O
mean	O
that	O
to	O
capture	O
variation	O
in	O
a	O
particular	O
direction	O
in	O
the	O
observation	O
space	O
requires	O
removing	O
potentially	O
all	O
constraints	O
with	O
positive	O
projection	O
in	O
that	O
direction	O
this	O
would	O
suggest	O
that	O
these	O
models	O
are	O
less	O
well	O
suited	O
to	O
the	O
overcomplete	O
setting	O
the	O
primary	O
disadvantage	O
of	O
the	O
spike	O
and	O
slab	O
restricted	O
boltzmann	O
machine	O
is	O
that	O
some	O
settings	O
of	O
the	O
parameters	O
can	O
correspond	O
to	O
a	O
covariance	B
matrix	I
that	O
is	O
not	O
positive	B
definite	I
such	O
a	O
covariance	B
matrix	I
places	O
more	O
unnormalized	O
probability	O
on	O
values	O
that	O
are	O
farther	O
from	O
the	O
mean	O
causing	O
the	O
integral	O
over	O
all	O
possible	O
outcomes	O
to	O
diverge	O
generally	O
this	O
issue	O
can	O
be	O
avoided	O
with	O
simple	O
heuristic	O
tricks	O
there	O
is	O
not	O
yet	O
any	O
theoretically	O
satisfying	O
solution	O
using	O
constrained	O
optimization	O
to	O
explicitly	O
avoid	O
the	O
regions	O
where	O
the	O
probability	O
is	O
undefined	O
is	O
difficult	O
to	O
do	O
without	O
being	O
overly	O
conservative	O
and	O
also	O
preventing	O
the	O
model	O
from	O
accessing	O
high-performing	O
regions	O
of	O
parameter	O
space	O
qualitatively	O
convolutional	O
variants	O
of	O
the	O
ssrbm	O
produce	O
excellent	O
samples	O
of	O
natural	O
images	O
some	O
examples	O
are	O
shown	O
in	O
figure	O
the	O
ssrbm	O
allows	O
for	O
several	O
extensions	O
including	O
higher-order	O
interactions	O
and	O
average-pooling	O
of	O
the	O
slab	O
variables	O
enables	O
the	O
model	O
to	O
learn	O
excellent	O
features	O
for	O
a	O
classifier	O
when	O
labeled	O
data	O
is	O
scarce	O
adding	O
a	O
courville	O
et	O
al	O
chapter	O
deep	O
generative	O
models	O
term	O
to	O
the	O
energy	B
function	I
that	O
prevents	O
the	O
partition	O
function	O
from	O
becoming	O
undefined	O
results	O
in	O
a	O
sparse	O
coding	O
model	O
spike	O
and	O
slab	O
sparse	O
coding	O
et	O
al	O
also	O
known	O
as	O
convolutional	O
boltzmann	O
machines	O
as	O
seen	O
in	O
chapter	O
extremely	O
high	O
dimensional	O
inputs	O
such	O
as	O
images	O
place	O
great	O
strain	O
on	O
the	O
computation	O
memory	O
and	O
statistical	O
requirements	O
of	O
machine	B
learning	I
models	O
replacing	O
matrix	O
multiplication	O
by	O
discrete	O
convolution	O
with	O
a	O
small	O
kernel	O
is	O
the	O
standard	O
way	O
of	O
solving	O
these	O
problems	O
for	O
inputs	O
that	O
have	O
translation	O
invariant	O
spatial	O
or	O
temporal	O
structure	O
desjardins	O
and	O
bengio	O
showed	O
that	O
this	O
approach	O
works	O
well	O
when	O
applied	O
to	O
rbms	O
deep	O
convolutional	O
networks	O
usually	O
require	O
a	O
pooling	O
operation	B
so	O
that	O
the	O
spatial	O
size	O
of	O
each	O
successive	O
layer	O
decreases	O
feedforward	O
convolutional	O
networks	O
often	O
use	O
a	O
pooling	O
function	O
such	O
as	O
the	O
maximum	O
of	O
the	O
elements	O
to	O
be	O
pooled	O
it	O
is	O
unclear	O
how	O
to	O
generalize	O
this	O
to	O
the	O
setting	O
of	O
energy-based	O
models	O
we	O
could	O
introduce	O
a	O
binary	O
pooling	O
unit	O
p	O
over	O
n	O
binary	O
detector	O
units	O
d	O
and	O
enforce	O
p	O
maxi	O
di	O
by	O
setting	O
the	O
energy	B
function	I
to	O
be	O
whenever	O
that	O
constraint	O
is	O
violated	O
this	O
does	O
not	O
scale	O
well	O
though	O
as	O
it	O
requires	O
evaluating	O
n	O
different	O
energy	O
configurations	O
to	O
compute	O
the	O
normalization	O
constant	O
for	O
a	O
small	O
pooling	O
region	O
this	O
requires	O
energy	B
function	I
evaluations	O
per	O
pooling	O
unit	O
lee	O
et	O
al	O
developed	O
a	O
solution	O
to	O
this	O
problem	O
called	O
probabilistic	B
max	B
pooling	I
to	O
be	O
confused	O
with	O
stochastic	B
pooling	I
which	O
is	O
a	O
technique	O
for	O
implicitly	O
constructing	O
ensembles	O
of	O
convolutional	O
feedforward	O
networks	O
the	O
strategy	O
behind	O
probabilistic	B
max	B
pooling	I
is	O
to	O
constrain	O
the	O
detector	O
units	O
so	O
at	O
most	O
one	O
may	O
be	O
active	O
at	O
a	O
time	O
this	O
means	O
there	O
are	O
only	O
n	O
total	O
states	O
state	O
for	O
each	O
of	O
the	O
n	O
detector	O
units	O
being	O
on	O
and	O
an	O
additional	O
state	O
corresponding	O
to	O
all	O
of	O
the	O
detector	O
units	O
being	O
off	O
the	O
pooling	O
unit	O
is	O
on	O
if	O
and	O
only	O
if	O
one	O
of	O
the	O
detector	O
units	O
is	O
on	O
the	O
state	O
with	O
all	O
units	O
off	O
is	O
assigned	O
energy	O
zero	O
we	O
can	O
think	O
of	O
this	O
as	O
describing	O
a	O
model	O
with	O
a	O
single	O
variable	O
that	O
has	O
n	O
states	O
or	O
equivalently	O
as	O
a	O
model	O
that	O
has	O
n	O
variables	O
that	O
assigns	O
energy	O
joint	O
assignments	O
of	O
variables	O
to	O
all	O
but	O
n	O
while	O
efficient	O
probabilistic	B
max	B
pooling	I
does	O
force	O
the	O
detector	O
units	O
to	O
be	O
mutually	O
exclusive	O
which	O
may	O
be	O
a	O
useful	O
regularizing	O
constraint	O
in	O
some	O
contexts	O
or	O
a	O
harmful	O
limit	O
on	O
model	O
capacity	O
in	O
other	O
contexts	O
it	O
also	O
does	O
not	O
support	O
overlapping	O
pooling	O
regions	O
overlapping	O
pooling	O
regions	O
are	O
usually	O
required	O
to	O
obtain	O
the	O
best	O
performance	O
from	O
feedforward	O
convolutional	O
networks	O
so	O
this	O
constraint	O
probably	O
greatly	O
reduces	O
the	O
performance	O
of	O
convolutional	O
boltzmann	O
chapter	O
deep	O
generative	O
models	O
machines	O
lee	O
et	O
al	O
demonstrated	O
that	O
probabilistic	B
max	B
pooling	I
could	O
be	O
used	O
to	O
build	O
convolutional	O
deep	O
boltzmann	O
this	O
model	O
is	O
able	O
to	O
perform	O
operations	O
such	O
as	O
filling	O
in	O
missing	O
portions	O
of	O
its	O
input	O
while	O
intellectually	O
appealing	O
this	O
model	O
is	O
challenging	O
to	O
make	O
work	O
in	O
practice	O
and	O
usually	O
does	O
not	O
perform	O
as	O
well	O
as	O
a	O
classifier	O
as	O
traditional	O
convolutional	O
networks	O
trained	O
with	O
supervised	B
learning	I
many	O
convolutional	O
models	O
work	O
equally	O
well	O
with	O
inputs	O
of	O
many	O
different	O
spatial	O
sizes	O
for	O
boltzmann	O
machines	O
it	O
is	O
difficult	O
to	O
change	O
the	O
input	O
size	O
for	O
a	O
variety	O
of	O
reasons	O
the	O
partition	O
function	O
changes	O
as	O
the	O
size	O
of	O
the	O
input	O
changes	O
moreover	O
many	O
convolutional	O
networks	O
achieve	O
size	O
invariance	B
by	O
scaling	O
up	O
the	O
size	O
of	O
their	O
pooling	O
regions	O
proportional	O
to	O
the	O
size	O
of	O
the	O
input	O
but	O
scaling	O
boltzmann	O
machine	O
pooling	O
regions	O
is	O
awkward	O
traditional	O
convolutional	O
neural	O
networks	O
can	O
use	O
a	O
fixed	O
number	O
of	O
pooling	O
units	O
and	O
dynamically	O
increase	O
the	O
size	O
of	O
their	O
pooling	O
regions	O
in	O
order	O
to	O
obtain	O
a	O
fixed-size	O
representation	O
of	O
a	O
variable-sized	O
input	O
for	O
boltzmann	O
machines	O
large	O
pooling	O
regions	O
become	O
too	O
expensive	O
for	O
the	O
naive	O
approach	O
the	O
approach	O
of	O
of	O
making	O
each	O
of	O
the	O
detector	O
units	O
in	O
the	O
same	O
pooling	O
region	O
mutually	O
exclusive	O
solves	O
the	O
computational	O
problems	O
but	O
still	O
does	O
not	O
allow	O
variable-size	O
pooling	O
regions	O
for	O
example	B
suppose	O
we	O
learn	O
a	O
model	O
with	O
probabilistic	B
max	B
pooling	I
over	O
detector	O
units	O
that	O
learn	O
edge	O
detectors	O
this	O
enforces	O
the	O
constraint	O
that	O
only	O
one	O
of	O
these	O
edges	O
may	O
appear	O
in	O
each	O
region	O
if	O
we	O
then	O
increase	O
the	O
size	O
of	O
the	O
input	O
image	O
by	O
in	O
each	O
direction	O
we	O
would	O
expect	O
the	O
number	O
of	O
edges	O
to	O
increase	O
correspondingly	O
instead	O
if	O
we	O
increase	O
the	O
size	O
of	O
the	O
pooling	O
regions	O
by	O
in	O
each	O
direction	O
to	O
then	O
the	O
mutual	O
exclusivity	O
constraint	O
now	O
specifies	O
that	O
each	O
of	O
these	O
edges	O
may	O
only	O
appear	O
once	O
in	O
a	O
region	O
as	O
we	O
grow	O
a	O
model	O
s	O
input	O
image	O
in	O
this	O
way	O
the	O
model	O
generates	O
edges	O
with	O
less	O
density	O
of	O
course	O
these	O
issues	O
only	O
arise	O
when	O
the	O
model	O
must	O
use	O
variable	O
amounts	O
of	O
pooling	O
in	O
order	O
to	O
emit	O
a	O
fixed-size	O
output	O
vector	O
models	O
that	O
use	O
probabilistic	B
max	B
pooling	I
may	O
still	O
accept	O
variable-sized	O
input	O
images	O
so	O
long	O
as	O
the	O
output	O
of	O
the	O
model	O
is	O
a	O
feature	B
map	O
that	O
can	O
scale	O
in	O
size	O
proportional	O
to	O
the	O
input	O
image	O
lee	O
et	O
al	O
pixels	O
at	O
the	O
boundary	O
of	O
the	O
image	O
also	O
pose	O
some	O
difficulty	O
which	O
is	O
exacerbated	O
by	O
the	O
fact	O
that	O
connections	O
in	O
a	O
boltzmann	O
machine	O
are	O
symmetric	O
if	O
we	O
do	O
not	O
implicitly	O
zero-pad	O
the	O
input	O
then	O
there	O
are	O
fewer	O
hidden	O
units	O
than	O
visible	O
units	O
and	O
the	O
visible	O
units	O
at	O
the	O
boundary	O
of	O
the	O
image	O
are	O
not	O
modeled	O
publication	O
describes	O
the	O
model	O
as	O
a	O
deep	O
belief	O
network	O
but	O
because	O
it	O
can	O
be	O
described	O
as	O
a	O
purely	O
undirected	B
model	I
with	O
tractable	O
layer-wise	O
mean	O
field	O
fixed	O
point	O
updates	O
it	O
best	O
fits	O
the	O
definition	O
of	O
a	O
deep	O
boltzmann	O
machine	O
chapter	O
deep	O
generative	O
models	O
well	O
because	O
they	O
lie	O
in	O
the	O
receptive	B
field	I
of	O
fewer	O
hidden	O
units	O
however	O
if	O
we	O
do	O
implicitly	O
zero-pad	O
the	O
input	O
then	O
the	O
hidden	O
units	O
at	O
the	O
boundary	O
are	O
driven	O
by	O
fewer	O
input	O
pixels	O
and	O
may	O
fail	O
to	O
activate	O
when	O
needed	O
boltzmann	O
machines	O
for	O
structured	O
or	O
sequential	O
outputs	O
in	O
the	O
structured	O
output	O
scenario	O
we	O
wish	O
to	O
train	O
a	O
model	O
that	O
can	O
map	O
from	O
some	O
input	O
x	O
to	O
some	O
output	O
y	O
and	O
the	O
different	O
entries	O
of	O
y	O
are	O
related	O
to	O
each	O
other	O
and	O
must	O
obey	O
some	O
constraints	O
for	O
example	B
in	O
the	O
speech	O
synthesis	O
task	O
y	O
is	O
a	O
waveform	O
and	O
the	O
entire	O
waveform	O
must	O
sound	O
like	O
a	O
coherent	O
utterance	O
a	O
natural	O
way	O
to	O
represent	O
the	O
relationships	O
between	O
the	O
entries	O
in	O
y	O
is	O
to	O
x	O
boltzmann	O
machines	O
extended	O
to	O
model	O
use	O
a	O
probability	B
distribution	I
py	O
conditional	O
distributions	O
can	O
supply	O
this	O
probabilistic	O
model	O
the	O
same	O
tool	O
of	O
conditional	O
modeling	O
with	O
a	O
boltzmann	O
machine	O
can	O
be	O
used	O
not	O
just	O
for	O
structured	O
output	O
tasks	O
but	O
also	O
for	O
sequence	O
modeling	O
in	O
the	O
latter	O
case	O
rather	O
than	O
mapping	O
an	O
input	O
x	O
to	O
an	O
output	O
y	O
the	O
model	O
must	O
estimate	O
a	O
probability	B
distribution	I
over	O
a	O
sequence	O
of	O
variables	O
x	O
conditional	O
boltzmann	O
machines	O
can	O
represent	O
factors	O
of	O
the	O
form	O
px	O
in	O
order	O
to	O
accomplish	O
this	O
task	O
t	O
x	O
x	O
x	O
t	O
an	O
important	O
sequence	O
modeling	O
task	O
for	O
the	O
video	O
game	O
and	O
film	O
industry	O
is	O
modeling	O
sequences	O
of	O
joint	O
angles	O
of	O
skeletons	O
used	O
to	O
render	O
characters	O
these	O
sequences	O
are	O
often	O
collected	O
using	O
motion	O
capture	O
systems	O
to	O
record	O
the	O
movements	O
of	O
actors	O
a	O
probabilistic	O
model	O
of	O
a	O
character	O
s	O
movement	O
allows	O
the	O
generation	O
of	O
new	O
previously	O
unseen	O
but	O
realistic	O
animations	O
to	O
solve	O
et	O
al	O
this	O
sequence	O
modeling	O
task	O
taylor	O
introduced	O
a	O
conditional	B
rbm	I
modeling	O
px	O
t	O
m	O
for	O
small	O
m	O
the	O
model	O
is	O
an	O
rbm	O
over	O
px	O
whose	O
bias	O
parameters	O
are	O
a	O
linear	O
function	O
of	O
the	O
preceding	O
m	O
values	O
of	O
x	O
when	O
we	O
condition	O
on	O
different	O
values	O
of	O
x	O
t	O
and	O
earlier	O
variables	O
we	O
get	O
a	O
new	O
rbm	O
over	O
x	O
the	O
weights	B
in	O
the	O
rbm	O
over	O
x	O
never	O
change	O
but	O
by	O
conditioning	O
on	O
different	O
past	O
values	O
we	O
can	O
change	O
the	O
probability	O
of	O
different	O
hidden	O
units	O
in	O
the	O
rbm	O
being	O
active	O
by	O
activating	O
and	O
deactivating	O
different	O
subsets	O
of	O
hidden	O
units	O
we	O
can	O
make	O
large	O
changes	O
to	O
the	O
probability	B
distribution	I
induced	O
on	O
x	O
other	O
variants	O
of	O
conditional	B
rbm	I
and	O
other	O
variants	O
of	O
sequence	O
modeling	O
using	O
conditional	O
rbms	O
are	O
possible	O
and	O
hinton	O
sutskever	O
et	O
al	O
boulanger-lewandowski	O
mnih	O
et	O
al	O
et	O
al	O
another	O
sequence	O
modeling	O
task	O
is	O
to	O
model	O
the	O
distribution	O
over	O
sequences	O
chapter	O
deep	O
generative	O
models	O
et	O
al	O
of	O
musical	O
notes	O
used	O
to	O
compose	O
songs	O
boulanger-lewandowski	O
introduced	O
the	O
rnn-rbm	O
sequence	O
model	O
and	O
applied	O
it	O
to	O
this	O
task	O
the	O
rnn-rbm	O
is	O
a	O
generative	O
model	O
of	O
a	O
sequence	O
of	O
frames	O
x	O
consisting	O
of	O
an	O
rnn	O
that	O
emits	O
the	O
rbm	O
parameters	O
for	O
each	O
time	O
step	O
unlike	O
previous	O
approaches	O
in	O
which	O
only	O
the	O
bias	O
parameters	O
of	O
the	O
rbm	O
varied	O
from	O
one	O
time	O
step	O
to	O
the	O
next	O
the	O
rnn-rbm	O
uses	O
the	O
rnn	O
to	O
emit	O
all	O
of	O
the	O
parameters	O
of	O
the	O
rbm	O
including	O
the	O
weights	B
to	O
train	O
the	O
model	O
we	O
need	O
to	O
be	O
able	O
to	O
back-propagate	O
the	O
gradient	B
of	O
the	O
loss	O
function	O
through	O
the	O
rnn	O
the	O
loss	O
function	O
is	O
not	O
applied	O
directly	O
to	O
the	O
rnn	O
outputs	O
instead	O
it	O
is	O
applied	O
to	O
the	O
rbm	O
this	O
means	O
that	O
we	O
must	O
approximately	O
differentiate	O
the	O
loss	O
with	O
respect	O
to	O
the	O
rbm	O
parameters	O
using	O
contrastive	O
divergence	O
or	O
a	O
related	O
algorithm	O
this	O
approximate	O
gradient	B
may	O
then	O
be	O
back-propagated	O
through	O
the	O
rnn	O
using	O
the	O
usual	O
back-propagation	B
through	I
time	I
algorithm	O
other	O
boltzmann	O
machines	O
many	O
other	O
variants	O
of	O
boltzmann	O
machines	O
are	O
possible	O
boltzmann	O
machines	O
may	O
be	O
extended	O
with	O
different	O
training	O
criteria	O
we	O
have	O
focused	O
on	O
boltzmann	O
machines	O
trained	O
to	O
approximately	O
maximize	O
the	O
generative	O
criterion	O
log	O
pv	O
it	O
is	O
also	O
possible	O
to	O
train	O
discriminative	O
rbms	O
that	O
aim	O
to	O
maximize	O
log	O
py	O
this	O
approach	O
often	O
performs	O
the	O
best	O
when	O
using	O
a	O
linear	B
combination	I
of	O
both	O
the	O
generative	O
and	O
the	O
discriminative	O
criteria	O
unfortunately	O
rbms	O
do	O
not	O
seem	O
to	O
be	O
as	O
powerful	O
supervised	O
learners	O
as	O
mlps	O
at	O
least	O
using	O
existing	O
methodology	O
larochelle	O
and	O
bengio	O
v	O
instead	O
sejnowski	O
most	O
boltzmann	O
machines	O
used	O
in	O
practice	O
have	O
only	O
second-order	O
interactions	O
in	O
their	O
energy	O
functions	O
meaning	O
that	O
their	O
energy	O
functions	O
are	O
the	O
sum	O
of	O
many	O
terms	O
and	O
each	O
individual	O
term	O
only	O
includes	O
the	O
product	O
between	O
two	O
random	O
variables	O
an	O
example	B
of	O
such	O
a	O
term	O
is	O
viwijhj	O
it	O
is	O
also	O
possible	O
to	O
train	O
higher-order	O
boltzmann	O
machines	O
whose	O
energy	B
function	I
terms	O
involve	O
the	O
products	O
between	O
many	O
variables	O
three-way	O
interactions	O
between	O
a	O
hidden	O
unit	O
and	O
two	O
different	O
images	O
can	O
model	O
spatial	O
transformations	O
from	O
one	O
frame	O
of	O
video	O
to	O
the	O
next	O
and	O
hinton	O
multiplication	O
by	O
a	O
one-hot	O
class	O
variable	O
can	O
change	O
the	O
relationship	O
between	O
visible	O
and	O
hidden	O
units	O
depending	O
on	O
which	O
class	O
is	O
present	O
one	O
recent	O
example	B
of	O
the	O
use	O
of	O
higher-order	O
interactions	O
is	O
a	O
boltzmann	O
machine	O
with	O
two	O
groups	O
of	O
hidden	O
units	O
with	O
one	O
group	O
of	O
hidden	O
units	O
that	O
interact	O
with	O
both	O
the	O
visible	O
units	O
v	O
and	O
the	O
class	O
label	O
y	O
and	O
another	O
group	O
of	O
hidden	O
units	O
that	O
interact	O
only	O
with	O
the	O
v	O
input	O
values	O
this	O
can	O
be	O
interpreted	O
as	O
encouraging	O
nair	O
and	O
hinton	O
luo	O
et	O
al	O
chapter	O
deep	O
generative	O
models	O
some	O
hidden	O
units	O
to	O
learn	O
to	O
model	O
the	O
input	O
using	O
features	O
that	O
are	O
relevant	O
to	O
the	O
class	O
but	O
also	O
to	O
learn	O
extra	O
hidden	O
units	O
that	O
explain	O
nuisance	O
details	O
that	O
are	O
necessary	O
for	O
the	O
samples	O
of	O
v	O
to	O
be	O
realistic	O
but	O
do	O
not	O
determine	O
the	O
class	O
of	O
the	O
example	B
another	O
use	O
of	O
higher-order	O
interactions	O
is	O
to	O
gate	O
some	O
features	O
sohn	O
introduced	O
a	O
boltzmann	O
machine	O
with	O
third-order	O
interactions	O
with	O
binary	O
mask	O
variables	O
associated	O
with	O
each	O
visible	O
unit	O
when	O
these	O
masking	O
variables	O
are	O
set	O
to	O
zero	O
they	O
remove	O
the	O
influence	O
of	O
a	O
visible	O
unit	O
on	O
the	O
hidden	O
units	O
this	O
allows	O
visible	O
units	O
that	O
are	O
not	O
relevant	O
to	O
the	O
classification	B
problem	O
to	O
be	O
removed	O
from	O
the	O
inference	O
pathway	O
that	O
estimates	O
the	O
class	O
et	O
al	O
more	O
generally	O
the	O
boltzmann	O
machine	O
framework	O
is	O
a	O
rich	O
space	O
of	O
models	O
permitting	O
many	O
more	O
model	O
structures	O
than	O
have	O
been	O
explored	O
so	O
far	O
developing	O
a	O
new	O
form	O
of	O
boltzmann	O
machine	O
requires	O
some	O
more	O
care	O
and	O
creativity	O
than	O
developing	O
a	O
new	O
neural	B
network	I
layer	O
because	O
it	O
is	O
often	O
difficult	O
to	O
find	O
an	O
energy	B
function	I
that	O
maintains	O
tractability	O
of	O
all	O
of	O
the	O
different	O
conditional	O
distributions	O
needed	O
to	O
use	O
the	O
boltzmann	O
machine	O
but	O
despite	O
this	O
required	O
effort	O
the	O
field	O
remains	O
open	O
to	O
innovation	O
back-propagation	B
through	O
random	O
operations	O
traditional	O
neural	O
networks	O
implement	O
a	O
deterministic	O
transformation	O
of	O
some	O
input	O
variables	O
x	O
when	O
developing	O
generative	O
models	O
we	O
often	O
wish	O
to	O
extend	O
neural	O
networks	O
to	O
implement	O
stochastic	O
transformations	O
of	O
x	O
one	O
straightforward	O
way	O
to	O
do	O
this	O
is	O
to	O
augment	O
the	O
neural	B
network	I
with	O
extra	O
inputs	O
z	O
that	O
are	O
sampled	O
from	O
some	O
simple	O
probability	B
distribution	I
such	O
as	O
a	O
uniform	O
or	O
gaussian	O
distribution	O
the	O
neural	B
network	I
can	O
then	O
continue	O
to	O
perform	O
deterministic	O
computation	O
internally	O
but	O
the	O
function	O
f	O
z	O
will	O
appear	O
stochastic	O
to	O
an	O
observer	O
who	O
does	O
not	O
have	O
access	O
to	O
z	O
provided	O
that	O
f	O
is	O
continuous	O
and	O
differentiable	O
we	O
can	O
then	O
compute	O
the	O
gradients	O
necessary	O
for	O
training	O
using	O
back-propagation	B
as	O
usual	O
as	O
an	O
example	B
let	O
us	O
consider	O
the	O
operation	B
consisting	O
of	O
drawing	O
samples	O
y	O
from	O
a	O
gaussian	O
distribution	O
with	O
mean	O
n	O
y	O
and	O
variance	O
because	O
an	O
individual	O
sample	O
of	O
y	O
is	O
not	O
produced	O
by	O
a	O
function	O
but	O
rather	O
by	O
a	O
sampling	O
process	O
whose	O
output	O
changes	O
every	O
time	O
we	O
query	O
it	O
it	O
may	O
seem	O
counterintuitive	O
to	O
take	O
the	O
derivatives	O
of	O
y	O
with	O
respect	O
to	O
the	O
parameters	O
of	O
its	O
distribution	O
and	O
however	O
we	O
can	O
rewrite	O
the	O
sampling	O
process	O
as	O
chapter	O
deep	O
generative	O
models	O
transforming	O
an	O
underlying	O
random	O
value	O
z	O
the	O
desired	O
distribution	O
n	O
to	O
obtain	O
a	O
sample	O
from	O
y	O
z	O
we	O
are	O
now	O
able	O
to	O
back-propagate	O
through	O
the	O
sampling	O
operation	B
by	O
regarding	O
it	O
as	O
a	O
deterministic	O
operation	B
with	O
an	O
extra	O
input	O
z	O
crucially	O
the	O
extra	O
input	O
is	O
a	O
random	B
variable	I
whose	O
distribution	O
is	O
not	O
a	O
function	O
of	O
any	O
of	O
the	O
variables	O
whose	O
derivatives	O
we	O
want	O
to	O
calculate	O
the	O
result	O
tells	O
us	O
how	O
an	O
infinitesimal	O
change	O
in	O
or	O
would	O
change	O
the	O
output	O
if	O
we	O
could	O
repeat	O
the	O
sampling	O
operation	B
again	O
with	O
the	O
same	O
value	O
of	O
z	O
being	O
able	O
to	O
back-propagate	O
through	O
this	O
sampling	O
operation	B
allows	O
us	O
to	O
incorporate	O
it	O
into	O
a	O
larger	O
graph	O
we	O
can	O
build	O
elements	O
of	O
the	O
graph	O
on	O
top	O
of	O
the	O
output	O
of	O
the	O
sampling	O
distribution	O
for	O
example	B
we	O
can	O
compute	O
the	O
derivatives	O
of	O
some	O
loss	O
function	O
jy	O
we	O
can	O
also	O
build	O
elements	O
of	O
the	O
graph	O
whose	O
outputs	O
are	O
the	O
inputs	O
or	O
the	O
parameters	O
of	O
the	O
sampling	O
operation	B
for	O
example	B
we	O
could	O
build	O
a	O
larger	O
graph	O
with	O
f	O
and	O
gx	O
in	O
this	O
augmented	O
graph	O
we	O
can	O
use	O
back-propagation	B
through	O
these	O
functions	O
to	O
derive	O
j	O
y	O
the	O
principle	O
used	O
in	O
this	O
gaussian	O
sampling	O
example	B
is	O
more	O
generally	O
applix	O
where	O
is	O
a	O
variable	O
containing	O
both	O
parameters	O
and	O
if	O
applicable	O
where	O
may	O
in	O
cable	O
we	O
can	O
express	O
any	O
probability	B
distribution	I
of	O
the	O
form	O
py	O
or	O
p	O
as	O
py	O
the	O
inputs	O
x	O
given	O
a	O
value	O
y	O
sampled	O
from	O
distribution	O
py	O
turn	O
be	O
a	O
function	O
of	O
other	O
variables	O
we	O
can	O
rewrite	O
y	O
p	O
as	O
y	O
y	O
z	O
where	O
z	O
is	O
a	O
source	O
of	O
randomness	O
we	O
may	O
then	O
compute	O
the	O
derivatives	O
of	O
y	O
with	O
respect	O
to	O
using	O
traditional	O
tools	O
such	O
as	O
the	O
back-propagation	B
algorithm	O
applied	O
to	O
f	O
so	O
long	O
as	O
f	O
is	O
continuous	O
and	O
differentiable	O
almost	B
everywhere	I
crucially	O
must	O
not	O
be	O
a	O
function	O
of	O
z	O
and	O
z	O
must	O
not	O
be	O
a	O
function	O
of	O
this	O
technique	O
is	O
often	O
called	O
the	O
reparametrization	B
trick	B
stochastic	O
back-propagation	B
or	O
perturbation	O
analysis	O
the	O
requirement	O
that	O
f	O
be	O
continuous	O
and	O
differentiable	O
of	O
course	O
requires	O
y	O
to	O
be	O
continuous	O
if	O
we	O
wish	O
to	O
back-propagate	O
through	O
a	O
sampling	O
process	O
that	O
produces	O
discrete-valued	O
samples	O
it	O
may	O
still	O
be	O
possible	O
to	O
estimate	O
a	O
gradient	B
on	O
using	O
reinforcement	O
learning	O
algorithms	O
such	O
as	O
variants	O
of	O
the	O
reinforce	B
algorithm	O
discussed	O
in	O
section	O
williams	O
chapter	O
deep	O
generative	O
models	O
in	O
neural	B
network	I
applications	O
we	O
typically	O
choose	O
z	O
to	O
be	O
drawn	O
from	O
some	O
simple	O
distribution	O
such	O
as	O
a	O
unit	O
uniform	O
or	O
unit	O
gaussian	O
distribution	O
and	O
achieve	O
more	O
complex	O
distributions	O
by	O
allowing	O
the	O
deterministic	O
portion	O
of	O
the	O
network	O
to	O
reshape	O
its	O
input	O
price	O
bonnet	O
the	O
idea	O
of	O
propagating	O
gradients	O
or	O
optimizing	O
through	O
stochastic	O
operations	O
and	O
was	O
dates	O
back	O
to	O
the	O
mid-twentieth	O
century	O
williams	O
first	O
used	O
for	O
machine	B
learning	I
in	O
the	O
context	O
of	O
reinforcement	O
learning	O
more	O
recently	O
it	O
has	O
been	O
applied	O
to	O
variational	O
approximations	O
and	O
stochastic	O
or	O
generative	O
neural	O
networks	O
and	O
archambeau	O
et	O
al	O
goodfellow	O
many	O
networks	O
such	O
as	O
denoising	O
autoencoders	O
or	O
networks	O
regularized	O
with	O
dropout	O
are	O
also	O
naturally	O
designed	O
to	O
take	O
noise	O
as	O
an	O
input	O
without	O
requiring	O
any	O
special	O
reparametrization	O
to	O
make	O
the	O
noise	O
independent	O
from	O
the	O
model	O
kingma	O
kingma	O
and	O
welling	O
a	O
rezende	O
et	O
al	O
et	O
al	O
back-propagating	O
through	O
discrete	O
stochastic	O
operations	O
when	O
a	O
model	O
emits	O
a	O
discrete	O
variable	O
y	O
the	O
reparametrization	B
trick	B
is	O
not	O
applicable	O
suppose	O
that	O
the	O
model	O
takes	O
inputs	O
x	O
and	O
parameters	O
both	O
encapsulated	O
in	O
the	O
vector	O
and	O
combines	O
them	O
with	O
random	O
noise	O
z	O
to	O
produce	O
y	O
y	O
z	O
because	O
y	O
is	O
discrete	O
f	O
must	O
be	O
a	O
step	O
function	O
the	O
derivatives	O
of	O
a	O
step	O
function	O
are	O
not	O
useful	O
at	O
any	O
point	O
right	O
at	O
each	O
step	O
boundary	O
the	O
derivatives	O
are	O
undefined	O
but	O
that	O
is	O
a	O
small	O
problem	O
the	O
large	O
problem	O
is	O
that	O
the	O
derivatives	O
are	O
zero	O
almost	B
everywhere	I
on	O
the	O
regions	O
between	O
step	O
boundaries	O
the	O
derivatives	O
of	O
any	O
cost	O
function	O
j	O
therefore	O
do	O
not	O
give	O
any	O
information	O
for	O
how	O
to	O
update	O
the	O
model	O
parameters	O
the	O
reinforce	B
algorithm	O
increment	O
non-negative	O
factor	O
characteristic	O
eligibility	O
provides	O
a	O
framework	O
defining	O
a	O
offset	O
reinforcement	O
the	O
core	O
idea	O
is	O
that	O
family	O
of	O
simple	O
but	O
powerful	O
solutions	O
even	O
though	O
j	O
is	O
a	O
step	O
function	O
with	O
useless	O
derivatives	O
the	O
expected	O
z	O
is	O
often	O
a	O
smooth	O
function	O
amenable	O
to	O
gradient	B
descent	O
p	O
f	O
cost	O
ez	O
although	O
that	O
expectation	B
is	O
typically	O
not	O
tractable	O
when	O
y	O
is	O
high-dimensional	O
is	O
the	O
result	O
of	O
the	O
composition	O
of	O
many	O
discrete	O
stochastic	O
decisions	O
it	O
can	O
be	O
estimated	O
without	O
bias	O
using	O
a	O
monte	O
carlo	O
average	O
the	O
stochastic	O
estimate	O
of	O
the	O
gradient	B
can	O
be	O
used	O
with	O
sgd	O
or	O
other	O
stochastic	O
gradient-based	O
optimization	O
techniques	O
williams	O
z	O
chapter	O
deep	O
generative	O
models	O
the	O
simplest	O
version	O
of	O
reinforce	B
can	O
be	O
derived	O
by	O
simply	O
differentiating	O
the	O
expected	O
cost	O
ez	O
j	O
y	O
je	O
j	O
p	O
j	O
p	O
p	O
log	O
p	O
y	O
y	O
j	O
y	O
m	O
y	O
m	O
p	O
i	O
j	O
log	O
p	O
relies	O
on	O
the	O
assumption	O
that	O
equation	O
trivial	O
to	O
extend	O
the	O
approach	O
to	O
relax	O
this	O
assumption	O
equation	O
the	O
derivative	B
rule	O
for	O
the	O
logarithm	O
p	O
an	O
unbiased	B
monte	O
carlo	O
estimator	O
of	O
the	O
gradient	B
j	O
does	O
not	O
reference	O
directly	O
it	O
is	O
exploits	O
gives	O
equation	O
log	O
p	O
p	O
anywhere	O
we	O
write	O
py	O
in	O
this	O
section	O
one	O
could	O
equally	O
write	O
py	O
x	O
this	O
is	O
because	O
py	O
is	O
parametrized	O
by	O
and	O
contains	O
both	O
and	O
x	O
if	O
x	O
is	O
present	O
one	O
issue	O
with	O
the	O
above	O
simple	O
reinforce	B
estimator	O
is	O
that	O
it	O
has	O
a	O
very	O
high	O
variance	O
so	O
that	O
many	O
samples	O
of	O
y	O
need	O
to	O
be	O
drawn	O
to	O
obtain	O
a	O
good	O
estimator	O
of	O
the	O
gradient	B
or	O
equivalently	O
if	O
only	O
one	O
sample	O
is	O
drawn	O
sgd	O
will	O
converge	O
very	O
slowly	O
and	O
will	O
require	O
a	O
smaller	O
learning	B
rate	I
it	O
is	O
possible	O
to	O
considerably	O
reduce	O
the	O
variance	O
of	O
that	O
estimator	O
by	O
using	O
variance	O
reduction	O
methods	O
the	O
idea	O
is	O
to	O
modify	O
the	O
estimator	O
so	O
that	O
its	O
expected	O
value	O
remains	O
unchanged	O
but	O
its	O
variance	O
get	O
reduced	O
in	O
the	O
context	O
of	O
reinforce	B
the	O
proposed	O
variance	O
reduction	O
methods	O
involve	O
the	O
computation	O
of	O
a	O
baseline	O
that	O
is	O
used	O
to	O
offset	O
j	O
note	O
that	O
any	O
offset	O
b	O
that	O
does	O
not	O
depend	O
on	O
y	O
would	O
not	O
change	O
the	O
expectation	B
of	O
the	O
estimated	O
gradient	B
because	O
wilson	O
l	O
ecuyer	O
ep	O
log	O
p	O
log	O
p	O
p	O
p	O
p	O
y	O
y	O
y	O
chapter	O
deep	O
generative	O
models	O
which	O
means	O
that	O
ep	O
j	O
y	O
b	O
log	O
p	O
ep	O
j	O
log	O
p	O
b	O
e	O
p	O
log	O
p	O
furthermore	O
we	O
can	O
obtain	O
the	O
optimal	O
b	O
by	O
computing	O
the	O
variance	O
of	O
b	O
that	O
this	O
optimal	O
baseline	O
b	O
under	O
py	O
and	O
minimizing	O
with	O
respect	O
to	O
b	O
what	O
we	O
find	O
is	O
i	O
is	O
different	O
for	O
each	O
element	O
i	O
of	O
the	O
vector	O
log	O
p	O
ep	O
j	O
log	O
p	O
i	O
b	O
ep	O
j	O
log	O
p	O
i	O
ep	O
log	O
p	O
i	O
the	O
gradient	B
estimator	O
with	O
respect	O
to	O
i	O
then	O
becomes	O
j	O
y	O
b	O
i	O
p	O
log	O
i	O
log	O
p	O
i	O
and	O
ep	O
where	O
b	O
estimates	O
the	O
above	O
b	O
the	O
estimate	O
b	O
is	O
usually	O
obtained	O
by	O
adding	O
extra	O
outputs	O
to	O
the	O
neural	B
network	I
and	O
training	O
the	O
new	O
outputs	O
to	O
estimate	O
ep	O
for	O
each	O
element	O
of	O
these	O
extra	O
outputs	O
can	O
be	O
trained	O
with	O
the	O
mean	B
squared	I
error	I
objective	O
using	O
respectively	O
jy	O
as	O
targets	O
when	O
y	O
is	O
sampled	O
from	O
py	O
for	O
a	O
given	O
the	O
estimate	O
b	O
may	O
then	O
be	O
recovered	O
by	O
substituting	O
these	O
estimates	O
into	O
preferred	O
to	O
use	O
a	O
single	O
shared	O
output	O
equation	O
all	O
elements	O
i	O
of	O
trained	O
with	O
the	O
target	O
jy	O
using	O
as	O
baseline	O
b	O
ep	O
j	O
y	O
mnih	O
and	O
gregor	O
p	O
log	O
i	O
log	O
p	O
i	O
and	O
log	O
p	O
i	O
et	O
al	O
variance	O
reduction	O
methods	O
have	O
been	O
introduced	O
in	O
the	O
reinforcement	O
learning	O
generalizing	O
previous	O
work	O
sutton	O
et	O
al	O
weaver	O
and	O
tao	O
context	O
bengio	O
mnih	O
on	O
the	O
case	O
of	O
binary	O
reward	O
by	O
dayan	O
see	O
and	O
gregor	O
ba	O
for	O
or	O
et	O
al	O
examples	O
of	O
modern	O
uses	O
of	O
the	O
reinforce	B
algorithm	O
with	O
reduced	O
variance	O
in	O
the	O
context	O
of	O
deep	O
learning	O
in	O
addition	O
to	O
the	O
use	O
of	O
an	O
input-dependent	O
baseline	O
b	O
b	O
could	O
be	O
adjusted	O
during	O
training	O
by	O
dividing	O
it	O
by	O
its	O
standard	B
deviation	I
estimated	O
by	O
a	O
moving	O
average	O
during	O
training	O
as	O
a	O
kind	O
of	O
adaptive	O
learning	B
rate	I
to	O
counter	O
the	O
effect	O
of	O
important	O
variations	O
that	O
occur	O
during	O
the	O
course	O
of	O
training	O
in	O
the	O
found	O
that	O
the	O
scale	O
of	O
mnih	O
and	O
gregor	O
et	O
al	O
xu	O
mnih	O
et	O
al	O
jy	O
chapter	O
deep	O
generative	O
models	O
magnitude	O
of	O
this	O
quantity	O
normalization	O
mnih	O
and	O
gregor	O
called	O
this	O
heuristic	O
variance	O
reinforce-based	O
estimators	O
can	O
be	O
understood	O
as	O
estimating	O
the	O
gradient	B
by	O
correlating	O
choices	O
of	O
y	O
with	O
corresponding	O
values	O
of	O
j	O
if	O
a	O
good	O
value	O
of	O
y	O
is	O
unlikely	O
under	O
the	O
current	O
parametrization	O
it	O
might	O
take	O
a	O
long	O
time	O
to	O
obtain	O
it	O
by	O
chance	O
and	O
get	O
the	O
required	O
signal	O
that	O
this	O
configuration	O
should	O
be	O
reinforced	O
directed	O
generative	O
nets	O
as	O
discussed	O
in	O
chapter	O
directed	O
graphical	O
models	O
make	O
up	O
a	O
prominent	O
class	O
of	O
graphical	O
models	O
while	O
directed	O
graphical	O
models	O
have	O
been	O
very	O
popular	O
within	O
the	O
greater	O
machine	B
learning	I
community	O
within	O
the	O
smaller	O
deep	O
learning	O
community	O
they	O
have	O
until	O
roughly	O
been	O
overshadowed	O
by	O
undirected	O
models	O
such	O
as	O
the	O
rbm	O
in	O
this	O
section	O
we	O
review	O
some	O
of	O
the	O
standard	O
directed	O
graphical	O
models	O
that	O
have	O
traditionally	O
been	O
associated	O
with	O
the	O
deep	O
learning	O
community	O
we	O
have	O
already	O
described	O
deep	O
belief	O
networks	O
which	O
are	O
a	O
partially	O
directed	O
model	O
we	O
have	O
also	O
already	O
described	O
sparse	O
coding	O
models	O
which	O
can	O
be	O
thought	O
of	O
as	O
shallow	O
directed	O
generative	O
models	O
they	O
are	O
often	O
used	O
as	O
feature	B
learners	O
in	O
the	O
context	O
of	O
deep	O
learning	O
though	O
they	O
tend	O
to	O
perform	O
poorly	O
at	O
sample	O
generation	O
and	O
density	B
estimation	I
we	O
now	O
describe	O
a	O
variety	O
of	O
deep	O
fully	O
directed	O
models	O
sigmoid	O
belief	O
nets	O
neal	O
sigmoid	O
belief	O
networks	O
are	O
a	O
simple	O
form	O
of	O
directed	O
graphical	O
model	O
with	O
a	O
specific	O
kind	O
of	O
conditional	B
probability	B
distribution	I
in	O
general	O
we	O
can	O
think	O
of	O
a	O
sigmoid	B
belief	I
network	I
as	O
having	O
a	O
vector	O
of	O
binary	O
states	O
s	O
with	O
each	O
element	O
of	O
the	O
state	O
influenced	O
by	O
its	O
ancestors	O
p	O
s	O
i	O
wjisj	O
bi	O
ji	O
the	O
most	O
common	O
structure	O
of	O
sigmoid	B
belief	I
network	I
is	O
one	O
that	O
is	O
divided	O
into	O
many	O
layers	O
with	O
ancestral	O
sampling	O
proceeding	O
through	O
a	O
series	O
of	O
many	O
hidden	O
layers	O
and	O
then	O
ultimately	O
generating	O
the	O
visible	B
layer	I
this	O
structure	O
is	O
very	O
similar	O
to	O
the	O
deep	O
belief	O
network	O
except	O
that	O
the	O
units	O
at	O
the	O
beginning	O
of	O
chapter	O
deep	O
generative	O
models	O
the	O
sampling	O
process	O
are	O
independent	O
from	O
each	O
other	O
rather	O
than	O
sampled	O
from	O
a	O
restricted	O
boltzmann	O
machine	O
such	O
a	O
structure	O
is	O
interesting	O
for	O
a	O
variety	O
of	O
reasons	O
one	O
reason	O
is	O
that	O
the	O
structure	O
is	O
a	O
universal	B
approximator	I
of	O
probability	O
distributions	O
over	O
the	O
visible	O
units	O
in	O
the	O
sense	O
that	O
it	O
can	O
approximate	O
any	O
probability	B
distribution	I
over	O
binary	O
variables	O
arbitrarily	O
well	O
given	O
enough	O
depth	O
even	O
if	O
the	O
width	O
of	O
the	O
individual	O
layers	O
is	O
restricted	O
to	O
the	O
dimensionality	O
of	O
the	O
visible	B
layer	I
and	O
hinton	O
while	O
generating	O
a	O
sample	O
of	O
the	O
visible	O
units	O
is	O
very	O
efficient	O
in	O
a	O
sigmoid	B
belief	I
network	I
most	O
other	O
operations	O
are	O
not	O
inference	O
over	O
the	O
hidden	O
units	O
given	O
the	O
visible	O
units	O
is	O
intractable	O
mean	O
field	O
inference	O
is	O
also	O
intractable	O
because	O
the	O
variational	O
lower	O
bound	B
involves	O
taking	O
expectations	O
of	O
cliques	O
that	O
encompass	O
entire	O
layers	O
this	O
problem	O
has	O
remained	O
difficult	O
enough	O
to	O
restrict	O
the	O
popularity	O
of	O
directed	O
discrete	O
networks	O
et	O
al	O
dayan	O
and	O
hinton	O
one	O
approach	O
for	O
performing	O
inference	O
in	O
a	O
sigmoid	B
belief	I
network	I
is	O
to	O
construct	O
a	O
different	O
lower	O
bound	B
that	O
is	O
specialized	O
for	O
sigmoid	O
belief	O
networks	O
saul	O
et	O
al	O
this	O
approach	O
has	O
only	O
been	O
applied	O
to	O
very	O
small	O
networks	O
another	O
approach	O
is	O
to	O
use	O
learned	O
inference	O
mechanisms	O
as	O
described	O
in	O
section	O
the	O
helmholtz	O
machine	O
is	O
a	O
sigmoid	B
belief	I
network	I
combined	O
with	O
an	O
inference	O
network	O
that	O
predicts	O
the	O
parameters	O
of	O
the	O
mean	O
field	O
distribution	O
over	O
the	O
hidden	O
units	O
modern	O
approaches	O
gregor	O
et	O
al	O
mnih	O
and	O
gregor	O
to	O
sigmoid	O
belief	O
networks	O
still	O
use	O
this	O
inference	O
network	O
approach	O
these	O
techniques	O
remain	O
difficult	O
due	O
to	O
the	O
discrete	O
nature	O
of	O
the	O
latent	O
variables	O
one	O
cannot	O
simply	O
back-propagate	O
through	O
the	O
output	O
of	O
the	O
inference	O
network	O
but	O
instead	O
must	O
use	O
the	O
relatively	O
unreliable	O
machinery	O
for	O
backpropagating	O
through	O
discrete	O
sampling	O
processes	O
described	O
in	O
section	O
recent	O
approaches	O
based	O
on	O
importance	O
sampling	O
reweighted	O
wake-sleep	O
and	O
bengio	O
make	O
it	O
possible	O
to	O
quickly	O
train	O
sigmoid	O
belief	O
networks	O
and	O
reach	O
state-of-the-art	O
performance	O
on	O
benchmark	O
tasks	O
and	O
bidirectional	O
helmholtz	O
machines	O
bornschein	O
et	O
al	O
a	O
special	O
case	O
of	O
sigmoid	O
belief	O
networks	O
is	O
the	O
case	O
where	O
there	O
are	O
no	O
latent	O
variables	O
learning	O
in	O
this	O
case	O
is	O
efficient	O
because	O
there	O
is	O
no	O
need	O
to	O
marginalize	O
latent	O
variables	O
out	O
of	O
the	O
likelihood	O
a	O
family	O
of	O
models	O
called	O
auto-regressive	O
networks	O
generalize	O
this	O
fully	O
visible	O
belief	O
network	O
to	O
other	O
kinds	O
of	O
variables	O
besides	O
binary	O
variables	O
and	O
other	O
structures	O
of	O
conditional	O
distributions	O
besides	O
loglinear	O
relationships	O
auto-regressive	O
networks	O
are	O
described	O
later	O
in	O
section	O
chapter	O
deep	O
generative	O
models	O
differentiable	O
generator	O
nets	O
many	O
generative	O
models	O
are	O
based	O
on	O
the	O
idea	O
of	O
using	O
a	O
differentiable	O
generator	B
network	I
the	O
model	O
transforms	O
samples	O
of	O
latent	O
variables	O
z	O
to	O
samples	O
x	O
or	O
to	O
distributions	O
over	O
samples	O
x	O
using	O
a	O
differentiable	O
function	O
gz	O
which	O
is	O
typically	O
represented	O
by	O
a	O
neural	B
network	I
this	O
model	O
class	O
includes	O
variational	O
autoencoders	O
which	O
pair	O
the	O
generator	O
net	O
with	O
an	O
inference	O
net	O
generative	O
adversarial	O
networks	O
which	O
pair	O
the	O
generator	B
network	I
with	O
a	O
discriminator	O
network	O
and	O
techniques	O
that	O
train	O
generator	O
networks	O
in	O
isolation	O
generator	O
networks	O
are	O
essentially	O
just	O
parametrized	O
computational	O
procedures	O
for	O
generating	O
samples	O
where	O
the	O
architecture	O
provides	O
the	O
family	O
of	O
possible	O
distributions	O
to	O
sample	O
from	O
and	O
the	O
parameters	O
select	O
a	O
distribution	O
from	O
within	O
that	O
family	O
as	O
an	O
example	B
the	O
standard	O
procedure	O
for	O
drawing	O
samples	O
from	O
a	O
normal	O
distribution	O
with	O
mean	O
and	O
covariance	O
is	O
to	O
feed	O
samples	O
z	O
from	O
a	O
normal	O
distribution	O
with	O
zero	O
mean	O
and	O
identity	O
covariance	O
into	O
a	O
very	O
simple	O
generator	B
network	I
this	O
generator	B
network	I
contains	O
just	O
one	O
affine	B
layer	O
x	O
z	O
lz	O
where	O
l	O
is	O
given	O
by	O
the	O
cholesky	O
decomposition	O
of	O
pseudorandom	O
number	O
generators	O
can	O
also	O
use	O
nonlinear	O
transformations	O
of	O
simple	O
distributions	O
for	O
example	B
inverse	O
transform	O
sampling	O
draws	O
a	O
scalar	O
z	O
from	O
u	O
and	O
applies	O
a	O
nonlinear	O
transformation	O
to	O
a	O
scalar	O
x	O
in	O
this	O
case	O
gz	O
is	O
given	O
by	O
the	O
inverse	O
of	O
the	O
cumulative	O
distribution	O
function	O
x	O
pvdv	O
if	O
we	O
are	O
able	O
to	O
specify	O
px	O
integrate	O
over	O
x	O
and	O
invert	O
the	O
f	O
resulting	O
function	O
we	O
can	O
sample	O
from	O
without	O
using	O
machine	B
learning	I
p	O
x	O
to	O
generate	O
samples	O
from	O
more	O
complicated	O
distributions	O
that	O
are	O
difficult	O
to	O
specify	O
directly	O
difficult	O
to	O
integrate	O
over	O
or	O
whose	O
resulting	O
integrals	O
are	O
difficult	O
to	O
invert	O
we	O
use	O
a	O
feedforward	O
network	O
to	O
represent	O
a	O
parametric	O
family	O
of	O
nonlinear	O
functions	O
g	O
and	O
use	O
training	O
data	O
to	O
infer	O
the	O
parameters	O
selecting	O
the	O
desired	O
function	O
we	O
can	O
think	O
of	O
g	O
as	O
providing	O
a	O
nonlinear	O
change	O
of	O
variables	O
that	O
transforms	O
the	O
distribution	O
over	O
z	O
into	O
the	O
desired	O
distribution	O
over	O
x	O
recall	B
from	O
equation	O
that	O
for	O
invertible	O
differentiable	O
continuous	O
g	O
pz	O
z	O
px	O
g	O
z	O
det	O
g	O
z	O
chapter	O
deep	O
generative	O
models	O
this	O
implicitly	O
imposes	O
a	O
probability	B
distribution	I
over	O
pz	O
det	O
g	O
z	O
px	O
of	O
course	O
this	O
formula	O
may	O
be	O
difficult	O
to	O
evaluate	O
depending	O
on	O
the	O
choice	O
of	O
g	O
so	O
we	O
often	O
use	O
indirect	O
means	O
of	O
learning	O
g	O
rather	O
than	O
trying	O
to	O
maximize	O
log	O
p	O
x	O
directly	O
in	O
some	O
cases	O
rather	O
than	O
using	O
g	O
to	O
provide	O
a	O
sample	O
of	O
x	O
directly	O
we	O
use	O
g	O
to	O
define	O
a	O
conditional	O
distribution	O
over	O
x	O
for	O
example	B
we	O
could	O
use	O
a	O
generator	O
net	O
whose	O
final	O
layer	O
consists	O
of	O
sigmoid	O
outputs	O
to	O
provide	O
the	O
mean	O
parameters	O
of	O
bernoulli	O
distributions	O
pxi	O
in	O
this	O
case	O
when	O
we	O
use	O
g	O
to	O
define	O
px	O
z	O
marginalizing	O
z	O
g	O
z	O
i	O
we	O
impose	O
a	O
distribution	O
over	O
x	O
by	O
x	O
z	O
ezp	O
p	O
x	O
both	O
approaches	O
define	O
a	O
distribution	O
pgx	O
and	O
allow	O
us	O
to	O
train	O
various	O
criteria	O
of	O
pg	O
using	O
the	O
reparametrization	B
trick	B
of	O
section	O
the	O
two	O
different	O
approaches	O
to	O
formulating	O
generator	O
nets	O
emitting	O
the	O
parameters	O
of	O
a	O
conditional	O
distribution	O
versus	O
directly	O
emitting	O
samples	O
have	O
complementary	O
strengths	O
and	O
weaknesses	O
when	O
the	O
generator	O
net	O
defines	O
a	O
conditional	O
distribution	O
over	O
x	O
it	O
is	O
capable	O
of	O
generating	O
discrete	O
data	O
as	O
well	O
as	O
continuous	O
data	O
when	O
the	O
generator	O
net	O
provides	O
samples	O
directly	O
it	O
is	O
capable	O
of	O
generating	O
only	O
continuous	O
data	O
could	O
introduce	O
discretization	O
in	O
the	O
forward	B
propagation	I
but	O
doing	O
so	O
would	O
mean	O
the	O
model	O
could	O
no	O
longer	O
be	O
trained	O
using	O
back-propagation	B
the	O
advantage	O
to	O
direct	O
sampling	O
is	O
that	O
we	O
are	O
no	O
longer	O
forced	O
to	O
use	O
conditional	O
distributions	O
whose	O
form	O
can	O
be	O
easily	O
written	O
down	O
and	O
algebraically	O
manipulated	O
by	O
a	O
human	O
designer	O
approaches	O
based	O
on	O
differentiable	O
generator	O
networks	O
are	O
motivated	O
by	O
the	O
success	O
of	O
gradient	B
descent	O
applied	O
to	O
differentiable	O
feedforward	O
networks	O
for	O
classification	B
in	O
the	O
context	O
of	O
supervised	B
learning	I
deep	O
feedforward	O
networks	O
trained	O
with	O
gradient-based	O
learning	O
seem	O
practically	O
guaranteed	O
to	O
succeed	O
given	O
enough	O
hidden	O
units	O
and	O
enough	O
training	O
data	O
can	O
this	O
same	O
recipe	O
for	O
success	O
transfer	O
to	O
generative	O
modeling	O
generative	O
modeling	O
seems	O
to	O
be	O
more	O
difficult	O
than	O
classification	B
or	O
regression	B
because	O
the	O
learning	O
process	O
requires	O
optimizing	O
intractable	O
criteria	O
in	O
the	O
context	O
chapter	O
deep	O
generative	O
models	O
of	O
differentiable	O
generator	O
nets	O
the	O
criteria	O
are	O
intractable	O
because	O
the	O
data	O
does	O
not	O
specify	O
both	O
the	O
inputs	O
z	O
and	O
the	O
outputs	O
x	O
of	O
the	O
generator	O
net	O
in	O
the	O
case	O
of	O
supervised	B
learning	I
both	O
the	O
inputs	O
x	O
and	O
the	O
outputs	O
y	O
were	O
given	O
and	O
the	O
optimization	O
procedure	O
needs	O
only	O
to	O
learn	O
how	O
to	O
produce	O
the	O
specified	O
mapping	O
in	O
the	O
case	O
of	O
generative	O
modeling	O
the	O
learning	O
procedure	O
needs	O
to	O
determine	O
how	O
to	O
arrange	O
space	O
in	O
a	O
useful	O
way	O
and	O
additionally	O
how	O
to	O
map	O
from	O
to	O
x	O
z	O
z	O
et	O
al	O
dosovitskiy	O
studied	O
a	O
simplified	O
problem	O
where	O
the	O
correspondence	O
between	O
z	O
and	O
x	O
is	O
given	O
specifically	O
the	O
training	O
data	O
is	O
computer-rendered	O
imagery	O
of	O
chairs	O
the	O
latent	O
variables	O
z	O
are	O
parameters	O
given	O
to	O
the	O
rendering	O
engine	O
describing	O
the	O
choice	O
of	O
which	O
chair	O
model	O
to	O
use	O
the	O
position	O
of	O
the	O
chair	O
and	O
other	O
configuration	O
details	O
that	O
affect	O
the	O
rendering	O
of	O
the	O
image	O
using	O
this	O
synthetically	O
generated	O
data	O
a	O
convolutional	B
network	I
is	O
able	O
to	O
learn	O
to	O
map	O
z	O
descriptions	O
of	O
the	O
content	O
of	O
an	O
image	O
to	O
x	O
approximations	O
of	O
rendered	O
images	O
this	O
suggests	O
that	O
contemporary	O
differentiable	O
generator	O
networks	O
have	O
sufficient	O
model	O
capacity	O
to	O
be	O
good	O
generative	O
models	O
and	O
that	O
contemporary	O
optimization	O
algorithms	O
have	O
the	O
ability	O
to	O
fit	O
them	O
the	O
difficulty	O
lies	O
in	O
determining	O
how	O
to	O
train	O
generator	O
networks	O
when	O
the	O
value	O
of	O
z	O
for	O
each	O
x	O
is	O
not	O
fixed	O
and	O
known	O
ahead	O
of	O
each	O
time	O
the	O
following	O
sections	O
describe	O
several	O
approaches	O
to	O
training	O
differentiable	O
generator	O
nets	O
given	O
only	O
training	O
samples	O
of	O
variational	O
autoencoders	O
the	O
variational	O
autoencoder	O
or	O
vae	O
is	O
a	O
directed	O
model	O
that	O
uses	O
learned	O
approximate	B
inference	I
and	O
can	O
be	O
trained	O
purely	O
with	O
gradient-based	O
methods	O
kingma	O
rezende	O
et	O
al	O
to	O
generate	O
a	O
sample	O
from	O
the	O
model	O
the	O
vae	O
first	O
draws	O
a	O
sample	O
z	O
from	O
the	O
code	O
distribution	O
pmodel	O
the	O
sample	O
is	O
then	O
run	O
through	O
a	O
differentiable	O
generator	B
network	I
gz	O
finally	O
x	O
is	O
sampled	O
from	O
a	O
distribution	O
pmodelx	O
gz	O
pmodelx	O
z	O
however	O
during	O
training	O
the	O
approximate	B
inference	I
network	O
encoder	B
qz	O
x	O
is	O
then	O
viewed	O
as	O
a	O
decoder	B
network	O
is	O
used	O
to	O
obtain	O
z	O
and	O
pmodelx	O
z	O
the	O
key	O
insight	O
behind	O
variational	O
autoencoders	O
is	O
that	O
they	O
may	O
be	O
trained	O
l	O
by	O
maximizing	O
the	O
variational	O
lower	O
bound	B
h	O
z	O
x	O
q	O
z	O
q	O
q	O
z	O
x	O
z	O
x	O
log	O
pmodel	O
log	O
pmodel	O
l	O
q	O
ez	O
ez	O
x	O
q	O
z	O
dkl	O
x	O
pmodel	O
x	O
z	O
associated	O
with	O
data	O
point	O
x	O
log	O
p	O
model	O
chapter	O
deep	O
generative	O
models	O
we	O
recognize	O
the	O
first	O
term	O
as	O
the	O
joint	O
log-likelihood	O
of	O
the	O
visible	O
in	O
equation	O
and	O
hidden	O
variables	O
under	O
the	O
approximate	O
posterior	O
over	O
the	O
latent	O
variables	O
like	O
with	O
em	O
except	O
that	O
we	O
use	O
an	O
approximate	O
rather	O
than	O
the	O
exact	O
posterior	O
we	O
recognize	O
also	O
a	O
second	O
term	O
the	O
entropy	O
of	O
the	O
approximate	O
posterior	O
when	O
q	O
is	O
chosen	O
to	O
be	O
a	O
gaussian	O
distribution	O
with	O
noise	O
added	O
to	O
a	O
predicted	O
mean	O
value	O
maximizing	O
this	O
entropy	O
term	O
encourages	O
increasing	O
the	O
standard	B
deviation	I
of	O
this	O
noise	O
more	O
generally	O
this	O
entropy	O
term	O
encourages	O
the	O
variational	O
posterior	O
to	O
place	O
high	O
probability	O
mass	O
on	O
many	O
z	O
values	O
that	O
could	O
have	O
generated	O
x	O
rather	O
than	O
collapsing	O
to	O
a	O
single	O
point	O
estimate	O
of	O
the	O
most	O
likely	O
value	O
in	O
equation	O
we	O
recognize	O
the	O
first	O
term	O
as	O
the	O
reconstruction	O
log-likelihood	O
found	O
in	O
other	O
autoencoders	O
the	O
second	O
term	O
tries	O
to	O
make	O
the	O
approximate	O
posterior	O
distribution	O
qz	O
x	O
and	O
the	O
model	O
prior	O
pmodelz	O
approach	O
each	O
other	O
traditional	O
approaches	O
to	O
variational	O
inference	O
and	O
learning	O
infer	O
q	O
via	O
an	O
opti	O
these	O
mization	O
algorithm	O
typically	O
iterated	O
fixed	O
point	O
equations	O
q	O
log	O
p	O
modelz	O
x	O
approaches	O
are	O
slow	O
and	O
often	O
require	O
the	O
ability	O
to	O
compute	O
ez	O
in	O
closed	O
form	O
the	O
main	O
idea	O
behind	O
the	O
variational	O
autoencoder	O
is	O
to	O
train	O
a	O
parametric	O
encoder	B
sometimes	O
called	O
an	O
inference	O
network	O
or	O
recognition	O
model	O
that	O
produces	O
the	O
parameters	O
of	O
q	O
so	O
long	O
as	O
z	O
is	O
a	O
continuous	O
variable	O
we	O
can	O
then	O
back-propagate	O
through	O
samples	O
of	O
z	O
drawn	O
from	O
qz	O
x	O
q	O
fx	O
in	O
order	O
to	O
obtain	O
a	O
gradient	B
with	O
respect	O
to	O
learning	O
then	O
consists	O
solely	O
of	O
maximizing	O
with	O
respect	O
to	O
the	O
parameters	O
of	O
the	O
encoder	B
and	O
decoder	B
all	O
of	O
the	O
expectations	O
in	O
may	O
be	O
approximated	O
by	O
monte	O
carlo	O
sampling	O
l	O
l	O
the	O
variational	O
autoencoder	O
approach	O
is	O
elegant	O
theoretically	O
pleasing	O
and	O
simple	O
to	O
implement	O
it	O
also	O
obtains	O
excellent	O
results	O
and	O
is	O
among	O
the	O
state	O
of	O
the	O
art	O
approaches	O
to	O
generative	O
modeling	O
its	O
main	O
drawback	O
is	O
that	O
samples	O
from	O
variational	O
autoencoders	O
trained	O
on	O
images	O
tend	O
to	O
be	O
somewhat	O
blurry	O
the	O
causes	O
of	O
this	O
phenomenon	O
are	O
not	O
yet	O
known	O
one	O
possibility	O
is	O
that	O
the	O
blurriness	O
is	O
an	O
intrinsic	O
effect	O
of	O
maximum	B
likelihood	I
which	O
minimizes	O
dklpdata	O
pmodel	O
as	O
illustrated	O
in	O
figure	O
this	O
means	O
that	O
the	O
model	O
will	O
assign	O
high	O
probability	O
to	O
points	O
that	O
occur	O
in	O
the	O
training	O
set	O
but	O
may	O
also	O
assign	O
high	O
probability	O
to	O
other	O
points	O
these	O
other	O
points	O
may	O
include	O
blurry	O
images	O
part	O
of	O
the	O
reason	O
that	O
the	O
model	O
would	O
choose	O
to	O
put	O
probability	O
mass	O
on	O
blurry	O
images	O
rather	O
than	O
some	O
other	O
part	O
of	O
the	O
space	O
is	O
that	O
the	O
variational	O
autoencoders	O
used	O
in	O
practice	O
usually	O
have	O
a	O
gaussian	O
distribution	O
for	O
pmodelx	O
gz	O
maximizing	O
a	O
lower	O
bound	B
on	O
the	O
likelihood	O
of	O
such	O
a	O
distribution	O
is	O
similar	O
to	O
training	O
a	O
traditional	O
autoencoder	O
with	O
mean	B
squared	I
error	I
in	O
the	O
sense	O
that	O
it	O
has	O
a	O
tendency	O
to	O
ignore	O
features	O
of	O
the	O
input	O
that	O
occupy	O
few	O
pixels	O
or	O
that	O
cause	O
only	O
a	O
small	O
change	O
in	O
the	O
brightness	O
of	O
the	O
pixels	O
that	O
they	O
occupy	O
this	O
issue	O
is	O
not	O
specific	O
to	O
vaes	O
and	O
chapter	O
deep	O
generative	O
models	O
pmodel	O
as	O
argued	O
by	O
is	O
shared	O
with	O
generative	O
models	O
that	O
optimize	O
a	O
log-likelihood	O
or	O
equivalently	O
dklp	O
data	O
another	O
troubling	O
issue	O
with	O
contemporary	O
vae	O
models	O
is	O
that	O
they	O
tend	O
to	O
use	O
only	O
a	O
small	O
subset	O
of	O
the	O
dimensions	O
of	O
z	O
as	O
if	O
the	O
encoder	B
was	O
not	O
able	O
to	O
transform	O
enough	O
of	O
the	O
local	O
directions	O
in	O
input	O
space	O
to	O
a	O
space	O
where	O
the	O
marginal	O
distribution	O
matches	O
the	O
factorized	O
prior	O
theis	O
et	O
al	O
huszar	O
and	O
by	O
the	O
vae	O
framework	O
is	O
very	O
straightforward	O
to	O
extend	O
to	O
a	O
wide	O
range	O
of	O
model	O
architectures	O
this	O
is	O
a	O
key	O
advantage	O
over	O
boltzmann	O
machines	O
which	O
require	O
extremely	O
careful	O
model	O
design	O
to	O
maintain	O
tractability	O
vaes	O
work	O
very	O
well	O
with	O
a	O
diverse	O
family	O
of	O
differentiable	O
operators	O
one	O
particularly	O
sophisticated	O
vae	O
is	O
the	O
deep	O
recurrent	O
attention	O
writer	O
or	O
draw	O
model	O
draw	O
uses	O
a	O
recurrent	O
encoder	B
and	O
recurrent	O
decoder	B
combined	O
with	O
an	O
attention	O
mechanism	O
the	O
generation	O
process	O
for	O
the	O
draw	O
model	O
consists	O
of	O
sequentially	O
visiting	O
different	O
small	O
image	O
patches	O
and	O
drawing	O
the	O
values	O
of	O
the	O
pixels	O
at	O
those	O
points	O
vaes	O
can	O
also	O
be	O
extended	O
to	O
generate	O
sequences	O
by	O
defining	O
variational	O
rnns	O
by	O
using	O
a	O
recurrent	O
encoder	B
and	O
decoder	B
within	O
the	O
vae	O
framework	O
generating	O
a	O
sample	O
from	O
a	O
traditional	O
rnn	O
involves	O
only	O
non-deterministic	O
operations	O
at	O
the	O
output	O
space	O
variational	O
rnns	O
also	O
have	O
random	O
variability	O
at	O
the	O
potentially	O
more	O
abstract	O
level	O
captured	O
by	O
the	O
vae	O
latent	O
variables	O
chung	O
et	O
al	O
gregor	O
et	O
al	O
the	O
vae	O
framework	O
has	O
been	O
extended	O
to	O
maximize	O
not	O
just	O
the	O
traditional	O
variational	O
lower	O
bound	B
but	O
instead	O
the	O
importance	B
weighted	I
autoencoder	I
burda	O
et	O
al	O
objective	O
l	O
k	O
x	O
q	O
qz	O
x	O
log	O
k	O
k	O
pmodelx	O
z	O
x	O
qz	O
l	O
this	O
new	O
objective	O
is	O
equivalent	O
to	O
the	O
traditional	O
lower	O
bound	B
when	O
k	O
however	O
it	O
may	O
also	O
be	O
interpreted	O
as	O
forming	O
an	O
estimate	O
of	O
the	O
true	O
log	O
pmodelx	O
using	O
importance	O
sampling	O
of	O
z	O
from	O
proposal	O
distribution	O
qz	O
x	O
the	O
importance	B
weighted	I
autoencoder	I
objective	O
is	O
also	O
a	O
lower	O
bound	B
on	O
log	O
pmodel	O
and	O
becomes	O
tighter	O
as	O
increases	O
k	O
variational	O
autoencoders	O
have	O
some	O
interesting	O
connections	O
to	O
the	O
mp-dbm	O
and	O
other	O
approaches	O
that	O
involve	O
back-propagation	B
through	O
the	O
approximate	B
inference	I
graph	O
these	O
previous	O
approaches	O
required	O
an	O
inference	O
procedure	O
such	O
as	O
mean	O
field	O
fixed	O
point	O
equations	O
to	O
provide	O
the	O
computational	B
graph	I
the	O
variational	O
autoencoder	O
is	O
defined	O
for	O
arbitrary	O
computational	O
graphs	O
which	O
makes	O
it	O
applicable	O
to	O
a	O
wider	O
range	O
of	O
probabilistic	O
model	O
families	O
because	O
there	O
is	O
no	O
need	O
to	O
restrict	O
the	O
choice	O
stoyanov	O
brakel	O
et	O
al	O
et	O
al	O
et	O
al	O
chapter	O
deep	O
generative	O
models	O
of	O
models	O
to	O
those	O
with	O
tractable	O
mean	O
field	O
fixed	O
point	O
equations	O
the	O
variational	O
autoencoder	O
also	O
has	O
the	O
advantage	O
that	O
it	O
increases	O
a	O
bound	B
on	O
the	O
log-likelihood	O
of	O
the	O
model	O
while	O
the	O
criteria	O
for	O
the	O
mp-dbm	O
and	O
related	O
models	O
are	O
more	O
heuristic	O
and	O
have	O
little	O
probabilistic	O
interpretation	O
beyond	O
making	O
the	O
results	O
of	O
approximate	B
inference	I
accurate	O
one	O
disadvantage	O
of	O
the	O
variational	O
autoencoder	O
is	O
that	O
it	O
learns	O
an	O
inference	O
network	O
for	O
only	O
one	O
problem	O
inferring	O
z	O
given	O
x	O
the	O
older	O
methods	O
are	O
able	O
to	O
perform	O
approximate	B
inference	I
over	O
any	O
subset	O
of	O
variables	O
given	O
any	O
other	O
subset	O
of	O
variables	O
because	O
the	O
mean	O
field	O
fixed	O
point	O
equations	O
specify	O
how	O
to	O
share	O
parameters	O
between	O
the	O
computational	O
graphs	O
for	O
all	O
of	O
these	O
different	O
problems	O
one	O
very	O
nice	O
property	O
of	O
the	O
variational	O
autoencoder	O
is	O
that	O
simultaneously	O
training	O
a	O
parametric	O
encoder	B
in	O
combination	O
with	O
the	O
generator	B
network	I
forces	O
the	O
model	O
to	O
learn	O
a	O
predictable	O
coordinate	O
system	O
that	O
the	O
encoder	B
can	O
capture	O
this	O
makes	O
it	O
an	O
excellent	O
manifold	B
learning	I
algorithm	O
see	O
figure	O
for	O
examples	O
of	O
low-dimensional	O
manifolds	O
learned	O
by	O
the	O
variational	O
autoencoder	O
in	O
one	O
of	O
the	O
cases	O
demonstrated	O
in	O
the	O
figure	O
the	O
algorithm	O
discovered	O
two	O
independent	O
factors	B
of	I
variation	I
present	O
in	O
images	O
of	O
faces	O
angle	O
of	O
rotation	O
and	O
emotional	O
expression	O
generative	O
adversarial	O
networks	O
generative	O
adversarial	O
networks	O
or	O
gans	O
generative	O
modeling	O
approach	O
based	O
on	O
differentiable	O
generator	O
networks	O
goodfellow	O
et	O
al	O
are	O
another	O
generative	O
adversarial	O
networks	O
are	O
based	O
on	O
a	O
game	O
theoretic	O
scenario	O
in	O
which	O
the	O
generator	B
network	I
must	O
compete	O
against	O
an	O
adversary	O
the	O
generator	B
network	I
directly	O
produces	O
samples	O
x	O
gz	O
its	O
adversary	O
the	O
discriminator	O
network	O
attempts	O
to	O
distinguish	O
between	O
samples	O
drawn	O
from	O
the	O
training	O
data	O
and	O
samples	O
drawn	O
from	O
the	O
generator	O
the	O
discriminator	O
emits	O
a	O
probability	O
value	O
given	O
by	O
dx	O
indicating	O
the	O
probability	O
that	O
x	O
is	O
a	O
real	O
training	O
example	B
rather	O
than	O
a	O
fake	O
sample	O
drawn	O
from	O
the	O
model	O
the	O
simplest	O
way	O
to	O
formulate	O
learning	O
in	O
generative	O
adversarial	O
networks	O
is	O
as	O
a	O
zero-sum	O
game	O
in	O
which	O
a	O
function	O
v	O
determines	O
the	O
payoff	O
of	O
the	O
v	O
as	O
its	O
own	O
payoff	O
during	O
discriminator	O
the	O
generator	O
receives	O
learning	O
each	O
player	O
attempts	O
to	O
maximize	O
its	O
own	O
payoff	O
so	O
that	O
at	O
convergence	O
g	O
arg	O
min	O
g	O
v	O
g	O
d	O
max	O
d	O
the	O
default	O
choice	O
for	O
isv	O
v	O
ex	O
p	O
data	O
log	O
d	O
x	O
pmodel	O
e	O
x	O
log	O
d	O
x	O
chapter	O
deep	O
generative	O
models	O
figure	O
examples	O
of	O
two-dimensional	O
coordinate	O
systems	O
for	O
high-dimensional	O
manifolds	O
learned	O
by	O
a	O
variational	O
autoencoder	O
and	O
welling	O
two	O
dimensions	O
may	O
be	O
plotted	O
directly	O
on	O
the	O
page	O
for	O
visualization	O
so	O
we	O
can	O
gain	O
an	O
understanding	O
of	O
how	O
the	O
model	O
works	O
by	O
training	O
a	O
model	O
with	O
a	O
latent	O
code	O
even	O
if	O
we	O
believe	O
the	O
intrinsic	O
dimensionality	O
of	O
the	O
data	O
manifold	B
is	O
much	O
higher	O
the	O
images	O
shown	O
are	O
not	O
examples	O
from	O
the	O
training	O
set	O
but	O
images	O
x	O
actually	O
generated	O
by	O
the	O
model	O
px	O
z	O
simply	O
by	O
changing	O
the	O
code	O
z	O
image	O
corresponds	O
to	O
a	O
different	O
choice	O
of	O
code	O
z	O
on	O
a	O
uniform	O
grid	O
two-dimensional	O
map	O
of	O
the	O
frey	O
faces	O
manifold	B
one	O
dimension	O
that	O
has	O
been	O
discovered	O
mostly	O
corresponds	O
to	O
a	O
rotation	O
of	O
the	O
face	O
while	O
the	O
other	O
corresponds	O
to	O
the	O
emotional	O
expression	O
the	O
two-dimensional	O
map	O
of	O
the	O
mnist	O
manifold	B
this	O
drives	O
the	O
discriminator	O
to	O
attempt	O
to	O
learn	O
to	O
correctly	O
classify	O
samples	O
as	O
real	O
or	O
fake	O
simultaneously	O
the	O
generator	O
attempts	O
to	O
fool	O
the	O
classifier	O
into	O
believing	O
its	O
samples	O
are	O
real	O
at	O
convergence	O
the	O
generator	O
s	O
samples	O
are	O
indistinguishable	O
from	O
real	O
data	O
and	O
the	O
discriminator	O
outputs	O
everywhere	O
the	O
discriminator	O
may	O
then	O
be	O
discarded	O
the	O
main	O
motivation	O
for	O
the	O
design	O
of	O
gans	O
is	O
that	O
the	O
learning	O
process	O
requires	O
neither	O
approximate	B
inference	I
nor	O
approximation	O
of	O
a	O
partition	O
function	O
gradient	B
in	O
the	O
case	O
where	O
maxd	O
vg	O
d	O
is	O
convex	O
in	O
as	O
the	O
case	O
where	O
optimization	O
is	O
performed	O
directly	O
in	O
the	O
space	O
of	O
probability	O
density	O
functions	O
the	O
procedure	O
is	O
guaranteed	O
to	O
converge	O
and	O
is	O
asymptotically	O
consistent	O
unfortunately	O
learning	O
in	O
gans	O
can	O
be	O
difficult	O
in	O
practice	O
when	O
g	O
and	O
d	O
are	O
represented	O
by	O
neural	O
networks	O
and	O
maxd	O
vg	O
d	O
is	O
not	O
convex	O
goodfellow	O
chapter	O
deep	O
generative	O
models	O
identified	O
non-convergence	O
as	O
an	O
issue	O
that	O
may	O
cause	O
gans	O
to	O
underfit	O
in	O
general	O
simultaneous	O
gradient	B
descent	O
on	O
two	O
players	O
costs	O
is	O
not	O
guaranteed	O
to	O
reach	O
an	O
equilibrium	O
consider	O
for	O
example	B
the	O
value	O
function	O
va	O
b	O
ab	O
where	O
one	O
player	O
controls	O
a	O
and	O
incurs	O
cost	O
ab	O
while	O
the	O
other	O
player	O
controls	O
b	O
and	O
receives	O
a	O
cost	O
ab	O
if	O
we	O
model	O
each	O
player	O
as	O
making	O
infinitesimally	O
small	O
gradient	B
steps	O
each	O
player	O
reducing	O
their	O
own	O
cost	O
at	O
the	O
expense	O
of	O
the	O
other	O
player	O
then	O
a	O
and	O
b	O
go	O
into	O
a	O
stable	O
circular	O
orbit	O
rather	O
than	O
arriving	O
at	O
the	O
equilibrium	O
point	O
at	O
the	O
origin	O
note	O
that	O
the	O
equilibria	O
for	O
a	O
minimax	O
game	O
are	O
not	O
local	O
minima	O
of	O
v	O
instead	O
they	O
are	O
points	O
that	O
are	O
simultaneously	O
minima	O
for	O
both	O
players	O
costs	O
this	O
means	O
that	O
they	O
are	O
saddle	B
points	I
of	O
v	O
that	O
are	O
local	O
minima	O
with	O
respect	O
to	O
the	O
first	O
player	O
s	O
parameters	O
and	O
local	O
maxima	O
with	O
respect	O
to	O
the	O
second	O
player	O
s	O
parameters	O
it	O
is	O
possible	O
for	O
the	O
two	O
players	O
to	O
take	O
turns	O
increasing	O
then	O
decreasing	O
v	O
forever	O
rather	O
than	O
landing	O
exactly	O
on	O
the	O
saddle	O
point	O
where	O
neither	O
player	O
is	O
capable	O
of	O
reducing	O
its	O
cost	O
it	O
is	O
not	O
known	O
to	O
what	O
extent	O
this	O
non-convergence	O
problem	O
affects	O
gans	O
goodfellow	O
identified	O
an	O
alternative	O
formulation	O
of	O
the	O
payoffs	O
in	O
which	O
the	O
game	O
is	O
no	O
longer	O
zero-sum	O
that	O
has	O
the	O
same	O
expected	O
gradient	B
as	O
maximum	B
likelihood	I
learning	O
whenever	O
the	O
discriminator	O
is	O
optimal	O
because	O
maximum	B
likelihood	I
training	O
converges	O
this	O
reformulation	O
of	O
the	O
gan	O
game	O
should	O
also	O
converge	O
given	O
enough	O
samples	O
unfortunately	O
this	O
alternative	O
formulation	O
does	O
not	O
seem	O
to	O
improve	O
convergence	O
in	O
practice	O
possibly	O
due	O
to	O
suboptimality	O
of	O
the	O
discriminator	O
or	O
possibly	O
due	O
to	O
high	O
variance	O
around	O
the	O
expected	O
gradient	B
goodfellow	O
et	O
al	O
in	O
realistic	O
experiments	O
the	O
best-performing	O
formulation	O
of	O
the	O
gan	O
game	O
is	O
a	O
different	O
formulation	O
that	O
is	O
neither	O
zero-sum	O
nor	O
equivalent	O
to	O
maximum	B
likelihood	I
introduced	O
by	O
with	O
a	O
heuristic	O
motivation	O
in	O
this	O
best-performing	O
formulation	O
the	O
generator	O
aims	O
to	O
increase	O
the	O
log	O
probability	O
that	O
the	O
discriminator	O
makes	O
a	O
mistake	O
rather	O
than	O
aiming	O
to	O
decrease	O
the	O
log	O
probability	O
that	O
the	O
discriminator	O
makes	O
the	O
correct	O
prediction	O
this	O
reformulation	O
is	O
motivated	O
solely	O
by	O
the	O
observation	O
that	O
it	O
causes	O
the	O
derivative	B
of	O
the	O
generator	O
s	O
cost	O
function	O
with	O
respect	O
to	O
the	O
discriminator	O
s	O
logits	O
to	O
remain	O
large	O
even	O
in	O
the	O
situation	O
where	O
the	O
discriminator	O
confidently	O
rejects	O
all	O
generator	O
samples	O
stabilization	O
of	O
gan	O
learning	O
remains	O
an	O
open	O
problem	O
fortunately	O
gan	O
learning	O
performs	O
well	O
when	O
the	O
model	O
architecture	O
and	O
hyperparameters	O
are	O
carefully	O
selected	O
crafted	O
a	O
deep	O
convolutional	O
gan	O
that	O
performs	O
very	O
well	O
for	O
image	O
synthesis	O
tasks	O
and	O
showed	O
that	O
its	O
latent	O
representation	O
space	O
captures	O
important	O
factors	B
of	I
variation	I
as	O
shown	O
in	O
figure	O
see	O
figure	O
for	O
examples	O
of	O
images	O
generated	O
by	O
a	O
dcgan	O
generator	O
radford	O
et	O
al	O
the	O
gan	O
learning	O
problem	O
can	O
also	O
be	O
simplified	O
by	O
breaking	O
the	O
generation	O
chapter	O
deep	O
generative	O
models	O
figure	O
images	O
generated	O
by	O
gans	O
trained	O
on	O
the	O
lsun	O
dataset	B
of	O
bedrooms	O
generated	O
by	O
a	O
dcgan	O
model	O
reproduced	O
with	O
permission	O
from	O
radford	O
et	O
al	O
images	O
of	O
churches	O
generated	O
by	O
a	O
lapgan	B
model	O
reproduced	O
with	O
permission	O
from	O
denton	O
et	O
al	O
that	O
learn	O
to	O
sample	O
from	O
a	O
distribution	O
px	O
y	O
process	O
into	O
many	O
levels	O
of	O
detail	O
it	O
is	O
possible	O
to	O
train	O
conditional	O
gans	O
rather	O
and	O
osindero	O
than	O
simply	O
sampling	O
from	O
a	O
marginal	O
distribution	O
px	O
denton	O
et	O
al	O
showed	O
that	O
a	O
series	O
of	O
conditional	O
gans	O
can	O
be	O
trained	O
to	O
first	O
generate	O
a	O
very	O
low-resolution	O
version	O
of	O
an	O
image	O
then	O
incrementally	O
add	O
details	O
to	O
the	O
image	O
this	O
technique	O
is	O
called	O
the	O
lapgan	B
model	O
due	O
to	O
the	O
use	O
of	O
a	O
laplacian	O
pyramid	O
to	O
generate	O
the	O
images	O
containing	O
varying	O
levels	O
of	O
detail	O
lapgan	B
generators	O
are	O
able	O
to	O
fool	O
not	O
only	O
discriminator	O
networks	O
but	O
also	O
human	O
observers	O
with	O
experimental	O
subjects	O
identifying	O
up	O
to	O
of	O
the	O
outputs	O
of	O
the	O
network	O
as	O
being	O
real	O
data	O
see	O
figure	O
for	O
examples	O
of	O
images	O
generated	O
by	O
a	O
lapgan	B
generator	O
one	O
unusual	O
capability	O
of	O
the	O
gan	O
training	O
procedure	O
is	O
that	O
it	O
can	O
fit	O
probability	O
distributions	O
that	O
assign	O
zero	O
probability	O
to	O
the	O
training	O
points	O
rather	O
than	O
maximizing	O
the	O
log	O
probability	O
of	O
specific	O
points	O
the	O
generator	O
net	O
learns	O
to	O
trace	O
out	O
a	O
manifold	B
whose	O
points	O
resemble	O
training	O
points	O
in	O
some	O
way	O
somewhat	O
paradoxically	O
this	O
means	O
that	O
the	O
model	O
may	O
assign	O
a	O
log-likelihood	O
of	O
negative	O
infinity	O
to	O
the	O
test	B
set	I
while	O
still	O
representing	O
a	O
manifold	B
that	O
a	O
human	O
observer	O
judges	O
to	O
capture	O
the	O
essence	O
of	O
the	O
generation	O
task	O
this	O
is	O
not	O
clearly	O
an	O
advantage	O
or	O
a	O
disadvantage	O
and	O
one	O
may	O
also	O
guarantee	O
that	O
the	O
generator	B
network	I
assigns	O
non-zero	O
probability	O
to	O
all	O
points	O
simply	O
by	O
making	O
the	O
last	O
layer	O
of	O
the	O
generator	B
network	I
add	O
gaussian	O
noise	O
to	O
all	O
of	O
the	O
generated	O
values	O
generator	O
networks	O
that	O
add	O
gaussian	O
noise	O
in	O
this	O
manner	O
sample	O
from	O
the	O
same	O
distribution	O
that	O
one	O
obtains	O
by	O
using	O
the	O
generator	B
network	I
to	O
parametrize	O
the	O
mean	O
of	O
a	O
conditional	O
chapter	O
deep	O
generative	O
models	O
gaussian	O
distribution	O
dropout	O
seems	O
to	O
be	O
important	O
in	O
the	O
discriminator	O
network	O
in	O
particular	O
units	O
should	O
be	O
stochastically	O
dropped	O
while	O
computing	O
the	O
gradient	B
for	O
the	O
generator	B
network	I
to	O
follow	O
following	O
the	O
gradient	B
of	O
the	O
deterministic	O
version	O
of	O
the	O
discriminator	O
with	O
its	O
weights	B
divided	O
by	O
two	O
does	O
not	O
seem	O
to	O
be	O
as	O
effective	O
likewise	O
never	O
using	O
dropout	O
seems	O
to	O
yield	O
poor	O
results	O
while	O
the	O
gan	O
framework	O
is	O
designed	O
for	O
differentiable	O
generator	O
networks	O
similar	O
principles	O
can	O
be	O
used	O
to	O
train	O
other	O
kinds	O
of	O
models	O
for	O
example	B
selfsupervised	O
boosting	O
can	O
be	O
used	O
to	O
train	O
an	O
rbm	O
generator	O
to	O
fool	O
a	O
logistic	O
regression	B
discriminator	O
et	O
al	O
generative	B
moment	B
matching	I
networks	I
generative	B
moment	B
matching	I
networks	I
li	O
et	O
al	O
dziugaite	O
et	O
al	O
are	O
another	O
form	O
of	O
generative	O
model	O
based	O
on	O
differentiable	O
generator	O
networks	O
unlike	O
vaes	O
and	O
gans	O
they	O
do	O
not	O
need	O
to	O
pair	O
the	O
generator	B
network	I
with	O
any	O
other	O
network	O
neither	O
an	O
inference	O
network	O
as	O
used	O
with	O
vaes	O
nor	O
a	O
discriminator	O
network	O
as	O
used	O
with	O
gans	O
these	O
networks	O
are	O
trained	O
with	O
a	O
technique	O
called	O
moment	B
matching	I
the	O
basic	O
idea	O
behind	O
moment	B
matching	I
is	O
to	O
train	O
the	O
generator	O
in	O
such	O
a	O
way	O
that	O
many	O
of	O
the	O
statistics	O
of	O
samples	O
generated	O
by	O
the	O
model	O
are	O
as	O
similar	O
as	O
possible	O
to	O
those	O
of	O
the	O
statistics	O
of	O
the	O
examples	O
in	O
the	O
training	O
set	O
in	O
this	O
context	O
a	O
moment	O
is	O
an	O
expectation	B
of	O
different	O
powers	O
of	O
a	O
random	B
variable	I
for	O
example	B
the	O
first	O
moment	O
is	O
the	O
mean	O
the	O
second	O
moment	O
is	O
the	O
mean	O
of	O
the	O
squared	O
values	O
and	O
so	O
on	O
in	O
multiple	O
dimensions	O
each	O
element	O
of	O
the	O
random	O
vector	O
may	O
be	O
raised	O
to	O
different	O
powers	O
so	O
that	O
a	O
moment	O
may	O
be	O
any	O
quantity	O
of	O
the	O
form	O
where	O
n	O
n	O
nd	O
ex	O
i	O
xni	O
i	O
is	O
a	O
vector	O
of	O
non-negative	O
integers	O
upon	O
first	O
examination	O
this	O
approach	O
seems	O
to	O
be	O
computationally	O
infeasible	O
for	O
example	B
if	O
we	O
want	O
to	O
match	O
all	O
the	O
moments	O
of	O
the	O
form	O
xixj	O
then	O
we	O
need	O
to	O
minimize	O
the	O
difference	O
between	O
a	O
number	O
of	O
values	O
that	O
is	O
quadratic	O
in	O
the	O
dimension	O
of	O
x	O
moreover	O
even	O
matching	O
all	O
of	O
the	O
first	O
and	O
second	O
moments	O
would	O
only	O
be	O
sufficient	O
to	O
fit	O
a	O
multivariate	O
gaussian	O
distribution	O
which	O
captures	O
only	O
linear	O
relationships	O
between	O
values	O
our	O
ambitions	O
for	O
neural	O
networks	O
are	O
to	O
capture	O
complex	O
nonlinear	O
relationships	O
which	O
would	O
require	O
far	O
more	O
moments	O
gans	O
avoid	O
this	O
problem	O
of	O
exhaustively	O
enumerating	O
all	O
moments	O
by	O
using	O
a	O
chapter	O
deep	O
generative	O
models	O
dynamically	O
updated	O
discriminator	O
that	O
automatically	O
focuses	O
its	O
attention	O
on	O
whichever	O
statistic	B
the	O
generator	B
network	I
is	O
matching	O
the	O
least	O
effectively	O
et	O
al	O
instead	O
generative	B
moment	B
matching	I
networks	I
can	O
be	O
trained	O
by	O
minimizing	O
a	O
cost	O
function	O
called	O
maximum	O
mean	O
discrepancy	O
lkopf	O
and	O
smola	O
gretton	O
or	O
mmd	O
this	O
cost	O
function	O
measures	O
the	O
error	O
in	O
the	O
first	O
moments	O
in	O
an	O
infinite-dimensional	O
space	O
using	O
an	O
implicit	O
mapping	O
to	O
feature	B
space	O
defined	O
by	O
a	O
kernel	O
function	O
in	O
order	O
to	O
make	O
computations	O
on	O
infinite-dimensional	O
vectors	O
tractable	O
the	O
mmd	O
cost	O
is	O
zero	O
if	O
and	O
only	O
if	O
the	O
two	O
distributions	O
being	O
compared	O
are	O
equal	O
visually	O
the	O
samples	O
from	O
generative	B
moment	B
matching	I
networks	I
are	O
somewhat	O
disappointing	O
fortunately	O
they	O
can	O
be	O
improved	O
by	O
combining	O
the	O
generator	B
network	I
with	O
an	O
autoencoder	O
first	O
an	O
autoencoder	O
is	O
trained	O
to	O
reconstruct	O
the	O
training	O
set	O
next	O
the	O
encoder	B
of	O
the	O
autoencoder	O
is	O
used	O
to	O
transform	O
the	O
entire	O
training	O
set	O
into	O
code	O
space	O
the	O
generator	B
network	I
is	O
then	O
trained	O
to	O
generate	O
code	O
samples	O
which	O
may	O
be	O
mapped	O
to	O
visually	O
pleasing	O
samples	O
via	O
the	O
decoder	B
unlike	O
gans	O
the	O
cost	O
function	O
is	O
defined	O
only	O
with	O
respect	O
to	O
a	O
batch	O
of	O
examples	O
from	O
both	O
the	O
training	O
set	O
and	O
the	O
generator	B
network	I
it	O
is	O
not	O
possible	O
to	O
make	O
a	O
training	O
update	O
as	O
a	O
function	O
of	O
only	O
one	O
training	O
example	B
or	O
only	O
one	O
sample	O
from	O
the	O
generator	B
network	I
this	O
is	O
because	O
the	O
moments	O
must	O
be	O
computed	O
as	O
an	O
empirical	O
average	O
across	O
many	O
samples	O
when	O
the	O
batch	O
size	O
is	O
too	O
small	O
mmd	O
can	O
underestimate	O
the	O
true	O
amount	O
of	O
variation	O
in	O
the	O
distributions	O
being	O
sampled	O
no	O
finite	O
batch	O
size	O
is	O
sufficiently	O
large	O
to	O
eliminate	O
this	O
problem	O
entirely	O
but	O
larger	O
batches	O
reduce	O
the	O
amount	O
of	O
underestimation	O
when	O
the	O
batch	O
size	O
is	O
too	O
large	O
the	O
training	O
procedure	O
becomes	O
infeasibly	O
slow	O
because	O
many	O
examples	O
must	O
be	O
processed	O
in	O
order	O
to	O
compute	O
a	O
single	O
small	O
gradient	B
step	O
as	O
with	O
gans	O
it	O
is	O
possible	O
to	O
train	O
a	O
generator	O
net	O
using	O
mmd	O
even	O
if	O
that	O
generator	O
net	O
assigns	O
zero	O
probability	O
to	O
the	O
training	O
points	O
convolutional	O
generative	O
networks	O
when	O
generating	O
images	O
it	O
is	O
often	O
useful	O
to	O
use	O
a	O
generator	B
network	I
that	O
includes	O
a	O
convolutional	O
structure	O
for	O
example	B
goodfellow	O
dosovitskiy	O
to	O
do	O
so	O
we	O
use	O
the	O
transpose	O
of	O
the	O
convolution	O
operator	O
et	O
al	O
described	O
in	O
section	O
this	O
approach	O
often	O
yields	O
more	O
realistic	O
images	O
and	O
does	O
so	O
using	O
fewer	O
parameters	O
than	O
using	O
fully	O
connected	O
layers	O
without	O
parameter	O
sharing	O
et	O
al	O
or	O
convolutional	O
networks	O
for	O
recognition	O
tasks	O
have	O
information	O
flow	O
from	O
the	O
image	O
to	O
some	O
summarization	O
layer	O
at	O
the	O
top	O
of	O
the	O
network	O
often	O
a	O
class	O
label	O
chapter	O
deep	O
generative	O
models	O
as	O
this	O
image	O
flows	O
upward	O
through	O
the	O
network	O
information	O
is	O
discarded	O
as	O
the	O
representation	O
of	O
the	O
image	O
becomes	O
more	O
invariant	O
to	O
nuisance	O
transformations	O
in	O
a	O
generator	B
network	I
the	O
opposite	O
is	O
true	O
rich	O
details	O
must	O
be	O
added	O
as	O
the	O
representation	O
of	O
the	O
image	O
to	O
be	O
generated	O
propagates	O
through	O
the	O
network	O
culminating	O
in	O
the	O
final	O
representation	O
of	O
the	O
image	O
which	O
is	O
of	O
course	O
the	O
image	O
itself	O
in	O
all	O
of	O
its	O
detailed	O
glory	O
with	O
object	O
positions	O
and	O
poses	O
and	O
textures	O
and	O
lighting	O
the	O
primary	O
mechanism	O
for	O
discarding	O
information	O
in	O
a	O
convolutional	O
recognition	O
network	O
is	O
the	O
pooling	O
layer	O
the	O
generator	B
network	I
seems	O
to	O
need	O
to	O
add	O
information	O
we	O
cannot	O
put	O
the	O
inverse	O
of	O
a	O
pooling	O
layer	O
into	O
the	O
generator	B
network	I
because	O
most	O
pooling	O
functions	O
are	O
not	O
invertible	O
a	O
simpler	O
operation	B
is	O
to	O
merely	O
increase	O
the	O
spatial	O
size	O
of	O
the	O
representation	O
an	O
approach	O
that	O
seems	O
to	O
perform	O
acceptably	O
is	O
to	O
use	O
an	O
un-pooling	O
as	O
introduced	O
by	O
dosovitskiy	O
et	O
al	O
this	O
layer	O
corresponds	O
to	O
the	O
inverse	O
of	O
the	O
max-pooling	O
operation	B
under	O
certain	O
simplifying	O
conditions	O
first	O
the	O
stride	O
of	O
the	O
max-pooling	O
operation	B
is	O
constrained	O
to	O
be	O
equal	O
to	O
the	O
width	O
of	O
the	O
pooling	O
region	O
second	O
the	O
maximum	O
input	O
within	O
each	O
pooling	O
region	O
is	O
assumed	O
to	O
be	O
the	O
input	O
in	O
the	O
upper-left	O
corner	O
finally	O
all	O
non-maximal	O
inputs	O
within	O
each	O
pooling	O
region	O
are	O
assumed	O
to	O
be	O
zero	O
these	O
are	O
very	O
strong	O
and	O
unrealistic	O
assumptions	O
but	O
they	O
do	O
allow	O
the	O
max-pooling	O
operator	O
to	O
be	O
inverted	O
the	O
inverse	O
un-pooling	O
operation	B
allocates	O
a	O
tensor	O
of	O
zeros	O
then	O
copies	O
each	O
value	O
from	O
spatial	O
coordinate	O
i	O
of	O
the	O
input	O
to	O
spatial	O
coordinate	O
i	O
of	O
the	O
output	O
the	O
integer	O
value	O
k	O
defines	O
the	O
size	O
of	O
the	O
pooling	O
region	O
even	O
though	O
the	O
assumptions	O
motivating	O
the	O
definition	O
of	O
the	O
un-pooling	O
operator	O
are	O
unrealistic	O
the	O
subsequent	O
layers	O
are	O
able	O
to	O
learn	O
to	O
compensate	O
for	O
its	O
unusual	O
output	O
so	O
the	O
samples	O
generated	O
by	O
the	O
model	O
as	O
a	O
whole	O
are	O
visually	O
pleasing	O
k	O
auto-regressive	O
networks	O
auto-regressive	O
networks	O
are	O
directed	O
probabilistic	O
models	O
with	O
no	O
latent	O
random	O
variables	O
the	O
conditional	B
probability	I
distributions	O
in	O
these	O
models	O
are	O
represented	O
by	O
neural	O
networks	O
extremely	O
simple	O
neural	O
networks	O
such	O
as	O
logistic	O
regression	B
the	O
graph	O
structure	O
of	O
these	O
models	O
is	O
the	O
complete	O
graph	O
they	O
decompose	O
a	O
joint	B
probability	I
over	O
the	O
observed	O
variables	O
using	O
the	O
chain	O
rule	O
of	O
xd	O
probability	O
to	O
obtain	O
a	O
product	O
of	O
conditionals	O
of	O
the	O
form	O
pxd	O
such	O
models	O
have	O
been	O
called	O
fully-visible	O
bayes	O
networks	O
and	O
used	O
successfully	O
in	O
many	O
forms	O
first	O
with	O
logistic	O
regression	B
for	O
each	O
conditional	O
and	O
then	O
with	O
neural	O
networks	O
with	O
hidden	O
units	O
distribution	O
in	O
some	O
forms	O
of	O
autoand	O
bengio	O
larochelle	O
and	O
murray	O
regressive	O
networks	O
such	O
as	O
nade	B
described	O
larochelle	O
and	O
murray	O
chapter	O
deep	O
generative	O
models	O
below	O
we	O
can	O
introduce	O
a	O
form	O
of	O
parameter	O
sharing	O
that	O
in	O
section	O
brings	O
both	O
a	O
statistical	O
advantage	O
unique	O
parameters	O
and	O
a	O
computational	O
advantage	O
computation	O
this	O
is	O
one	O
more	O
instance	O
of	O
the	O
recurring	O
deep	O
learning	O
motif	O
of	O
reuse	O
of	O
features	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
x	O
x	O
x	O
x	O
figure	O
a	O
fully	O
visible	O
belief	O
network	O
predicts	O
the	O
i-th	O
variable	O
from	O
the	O
i	O
previous	O
ones	O
corresponding	O
computational	B
graph	I
in	O
the	O
case	O
of	O
the	O
logistic	O
fvbn	B
where	O
each	O
prediction	O
is	O
made	O
by	O
a	O
linear	O
predictor	O
the	O
directed	O
graphical	O
model	O
for	O
an	O
fvbn	B
linear	O
auto-regressive	O
networks	O
the	O
simplest	O
form	O
of	O
auto-regressive	O
network	O
has	O
no	O
hidden	O
units	O
and	O
no	O
sharing	O
xi	O
is	O
parametrized	O
as	O
a	O
linear	O
of	O
parameters	O
or	O
features	O
each	O
p	O
model	O
regression	B
for	O
real-valued	O
data	O
logistic	O
regression	B
for	O
binary	O
data	O
softmax	O
regression	B
for	O
discrete	O
data	O
this	O
model	O
was	O
introduced	O
by	O
frey	O
and	O
has	O
parameters	O
when	O
there	O
are	O
d	O
variables	O
to	O
model	O
it	O
is	O
illustrated	O
in	O
figure	O
if	O
the	O
variables	O
are	O
continuous	O
a	O
linear	O
auto-regressive	O
model	O
is	O
merely	O
another	O
way	O
to	O
formulate	O
a	O
multivariate	O
gaussian	O
distribution	O
capturing	O
linear	O
pairwise	O
interactions	O
between	O
the	O
observed	O
variables	O
linear	O
auto-regressive	O
networks	O
are	O
essentially	O
the	O
generalization	B
of	O
linear	O
classification	B
methods	O
to	O
generative	O
modeling	O
they	O
therefore	O
have	O
the	O
same	O
chapter	O
deep	O
generative	O
models	O
advantages	O
and	O
disadvantages	O
as	O
linear	O
classifiers	O
like	O
linear	O
classifiers	O
they	O
may	O
be	O
trained	O
with	O
convex	O
loss	O
functions	O
and	O
sometimes	O
admit	O
closed	O
form	O
solutions	O
in	O
the	O
gaussian	O
case	O
like	O
linear	O
classifiers	O
the	O
model	O
itself	O
does	O
not	O
offer	O
a	O
way	O
of	O
increasing	O
its	O
capacity	O
so	O
capacity	O
must	O
be	O
raised	O
using	O
techniques	O
like	O
basis	O
expansions	O
of	O
the	O
input	O
or	O
the	O
kernel	B
trick	B
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
x	O
x	O
x	O
x	O
figure	O
a	O
neural	O
auto-regressive	O
network	O
predicts	O
the	O
i-th	O
variable	O
xi	O
from	O
the	O
i	O
previous	O
ones	O
but	O
is	O
parametrized	O
so	O
that	O
features	O
of	O
hidden	O
units	O
denoted	O
hi	O
that	O
are	O
functions	O
of	O
xi	O
can	O
be	O
reused	O
in	O
predicting	O
all	O
of	O
the	O
subsequent	O
variables	O
xd	O
neural	O
auto-regressive	O
networks	O
bengio	O
and	O
bengio	O
b	O
have	O
the	O
same	O
neural	O
auto-regressive	O
networks	O
left-to-right	O
graphical	O
model	O
as	O
logistic	O
auto-regressive	O
networks	O
but	O
employ	O
a	O
different	O
parametrization	O
of	O
the	O
conditional	O
distributions	O
within	O
that	O
graphical	O
model	O
structure	O
the	O
new	O
parametrization	O
is	O
more	O
powerful	O
in	O
the	O
sense	O
that	O
its	O
capacity	O
can	O
be	O
increased	O
as	O
much	O
as	O
needed	O
allowing	O
approximation	O
of	O
any	O
joint	O
distribution	O
the	O
new	O
parametrization	O
can	O
also	O
improve	O
generalization	B
by	O
introducing	O
a	O
parameter	O
sharing	O
and	O
feature	B
sharing	O
principle	O
common	O
to	O
deep	O
learning	O
in	O
general	O
the	O
models	O
were	O
motivated	O
by	O
the	O
objective	O
of	O
avoiding	O
the	O
curse	B
of	I
dimensionality	I
arising	O
out	O
of	O
traditional	O
tabular	O
graphical	O
models	O
sharing	O
the	O
same	O
structure	O
as	O
figure	O
in	O
tabular	O
discrete	O
probabilistic	O
models	O
each	O
conditional	O
distribution	O
is	O
represented	O
by	O
a	O
table	O
of	O
probabilities	O
with	O
one	O
entry	O
and	O
one	O
parameter	O
for	O
each	O
possible	O
configuration	O
of	O
the	O
variables	O
involved	O
by	O
using	O
a	O
neural	B
network	I
instead	O
two	O
advantages	O
are	O
obtained	O
chapter	O
deep	O
generative	O
models	O
the	O
parametrization	O
of	O
each	O
p	O
xi	O
by	O
a	O
neural	B
network	I
with	O
k	O
inputs	O
and	O
k	O
outputs	O
the	O
variables	O
are	O
discrete	O
and	O
take	O
k	O
values	O
encoded	O
one-hot	O
allows	O
one	O
to	O
estimate	O
the	O
conditional	B
probability	I
without	O
requiring	O
an	O
exponential	O
number	O
of	O
parameters	O
examples	O
yet	O
still	O
is	O
able	O
to	O
capture	O
high-order	O
dependencies	O
between	O
the	O
random	O
variables	O
left-to-right	O
connectivity	O
illustrated	O
in	O
figure	O
instead	O
of	O
having	O
a	O
different	O
neural	B
network	I
for	O
the	O
prediction	O
of	O
each	O
xi	O
a	O
allows	O
one	O
to	O
merge	O
all	O
the	O
neural	O
networks	O
into	O
one	O
equivalently	O
it	O
means	O
that	O
the	O
hidden	B
layer	I
features	O
computed	O
for	O
predicting	O
xi	O
can	O
be	O
reused	O
for	O
predicting	O
xi	O
k	O
the	O
hidden	O
units	O
are	O
thus	O
organized	O
in	O
groups	O
that	O
have	O
the	O
particularity	O
that	O
all	O
the	O
units	O
in	O
the	O
i-th	O
group	O
only	O
depend	O
on	O
the	O
input	O
values	O
xi	O
the	O
parameters	O
used	O
to	O
compute	O
these	O
hidden	O
units	O
are	O
jointly	O
optimized	O
to	O
improve	O
the	O
prediction	O
of	O
all	O
the	O
variables	O
in	O
the	O
sequence	O
this	O
is	O
an	O
instance	O
of	O
the	O
reuse	O
principle	O
that	O
recurs	O
throughout	O
deep	O
learning	O
in	O
scenarios	O
ranging	O
from	O
recurrent	O
and	O
convolutional	B
network	I
architectures	O
to	O
multi-task	O
and	O
transfer	B
learning	I
each	O
pxi	O
xi	O
can	O
represent	O
a	O
conditional	O
distribution	O
by	O
having	O
outputs	O
of	O
the	O
neural	B
network	I
predict	O
parameters	O
of	O
the	O
conditional	O
distribution	O
of	O
xi	O
as	O
discussed	O
in	O
section	O
although	O
the	O
original	O
neural	O
auto-regressive	O
networks	O
were	O
initially	O
evaluated	O
in	O
the	O
context	O
of	O
purely	O
discrete	O
multivariate	O
data	O
a	O
sigmoid	O
output	O
for	O
a	O
bernoulli	O
variable	O
or	O
softmax	O
output	O
for	O
a	O
multinoulli	O
variable	O
it	O
is	O
natural	O
to	O
extend	O
such	O
models	O
to	O
continuous	O
variables	O
or	O
joint	O
distributions	O
involving	O
both	O
discrete	O
and	O
continuous	O
variables	O
nade	B
the	O
neural	O
autoregressive	O
density	O
estimator	O
is	O
a	O
very	O
successful	O
recent	O
form	O
of	O
neural	O
auto-regressive	O
network	O
and	O
murray	O
the	O
connectivity	O
is	O
the	O
same	O
as	O
for	O
the	O
original	O
neural	O
auto-regressive	O
network	O
of	O
bengio	O
but	O
nade	B
introduces	O
an	O
additional	O
parameter	O
sharing	O
scheme	O
and	O
bengio	O
as	O
illustrated	O
in	O
figure	O
the	O
parameters	O
of	O
the	O
hidden	O
units	O
of	O
different	O
groups	O
j	O
are	O
shared	O
the	O
weights	B
w	O
of	O
hidden	O
unit	O
h	O
k	O
jki	O
from	O
the	O
i-th	O
input	O
xi	O
to	O
the	O
k	O
element	O
of	O
the	O
j-th	O
group	O
j	O
are	O
shared	O
among	O
the	O
groups	O
i	O
jki	O
wki	O
w	O
the	O
remaining	O
weights	B
where	O
j	O
i	O
are	O
zero	O
chapter	O
deep	O
generative	O
models	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
p	O
x	O
w	O
w	O
w	O
w	O
w	O
w	O
x	O
x	O
x	O
x	O
figure	O
an	O
illustration	O
of	O
the	O
neural	O
autoregressive	O
density	O
estimator	O
the	O
hidden	O
units	O
are	O
organized	O
in	O
groups	O
h	O
so	O
that	O
only	O
the	O
inputs	O
x	O
i	O
participate	O
in	O
computing	O
h	O
and	O
predicting	O
p	O
for	O
j	O
i	O
nade	B
is	O
differentiated	O
from	O
earlier	O
neural	O
auto-regressive	O
networks	O
by	O
the	O
use	O
of	O
a	O
particular	O
weight	O
sharing	O
pattern	O
w	O
jki	O
wki	O
is	O
shared	O
in	O
the	O
figure	O
by	O
the	O
use	O
of	O
the	O
same	O
line	O
pattern	O
for	O
every	O
instance	O
of	O
a	O
replicated	O
weight	O
for	O
all	O
the	O
weights	B
going	O
out	O
from	O
xi	O
to	O
the	O
k-th	O
unit	O
of	O
any	O
group	O
wni	O
is	O
denoted	O
wi	O
recall	B
that	O
the	O
vector	O
i	O
xj	O
j	O
larochelle	O
and	O
murray	O
chose	O
this	O
sharing	O
scheme	O
so	O
that	O
forward	B
propagation	I
in	O
a	O
nade	B
model	O
loosely	O
resembles	O
the	O
computations	O
performed	O
in	O
mean	O
field	O
inference	O
to	O
fill	O
in	O
missing	B
inputs	I
in	O
an	O
rbm	O
this	O
mean	O
field	O
inference	O
corresponds	O
to	O
running	O
a	O
recurrent	B
network	I
with	O
shared	O
weights	B
and	O
the	O
first	O
step	O
of	O
that	O
inference	O
is	O
the	O
same	O
as	O
in	O
nade	B
the	O
only	O
difference	O
is	O
that	O
with	O
nade	B
the	O
output	O
weights	B
connecting	O
the	O
hidden	O
units	O
to	O
the	O
output	O
are	O
parametrized	O
independently	O
from	O
the	O
weights	B
connecting	O
the	O
input	O
units	O
to	O
the	O
hidden	O
units	O
in	O
the	O
rbm	O
the	O
hidden-to-output	O
weights	B
are	O
the	O
transpose	O
of	O
the	O
input-to-hidden	O
weights	B
the	O
nade	B
architecture	O
can	O
be	O
extended	O
to	O
mimic	O
not	O
just	O
one	O
time	O
step	O
of	O
the	O
mean	O
field	O
recurrent	O
inference	O
but	O
to	O
mimic	O
k	O
steps	O
this	O
approach	O
is	O
called	O
nade	B
k	O
raiko	O
et	O
al	O
as	O
mentioned	O
previously	O
auto-regressive	O
networks	O
may	O
be	O
extend	O
to	O
process	O
continuous-valued	O
data	O
a	O
particularly	O
powerful	O
and	O
generic	O
way	O
of	O
parametrizing	O
a	O
continuous	O
density	O
is	O
as	O
a	O
gaussian	O
mixture	O
in	O
section	O
with	O
mixture	O
weights	B
i	O
coefficient	O
or	O
prior	O
probability	O
for	O
component	O
i	O
percomponent	O
conditional	O
mean	O
i	O
and	O
per-component	O
conditional	O
variance	O
i	O
a	O
uses	O
this	O
parametrization	O
to	O
extend	O
nade	B
model	O
called	O
rnade	O
to	O
real	O
values	O
as	O
with	O
other	O
mixture	B
density	I
networks	I
the	O
parameters	O
of	O
this	O
uria	O
et	O
al	O
chapter	O
deep	O
generative	O
models	O
distribution	O
are	O
outputs	O
of	O
the	O
network	O
with	O
the	O
mixture	O
weight	O
probabilities	O
produced	O
by	O
a	O
softmax	O
unit	O
and	O
the	O
variances	O
parametrized	O
so	O
that	O
they	O
are	O
positive	O
stochastic	O
gradient	B
descent	O
can	O
be	O
numerically	O
ill-behaved	O
due	O
to	O
the	O
interactions	O
between	O
the	O
conditional	O
means	O
i	O
and	O
the	O
conditional	O
variances	O
i	O
to	O
reduce	O
this	O
difficulty	O
use	O
a	O
pseudo-gradient	O
that	O
replaces	O
the	O
gradient	B
on	O
the	O
mean	O
in	O
the	O
back-propagation	B
phase	O
uria	O
et	O
al	O
another	O
very	O
interesting	O
extension	O
of	O
the	O
neural	O
auto-regressive	O
architectures	O
gets	O
rid	O
of	O
the	O
need	O
to	O
choose	O
an	O
arbitrary	O
order	O
for	O
the	O
observed	O
variables	O
and	O
larochelle	O
in	O
auto-regressive	O
networks	O
the	O
idea	O
is	O
to	O
train	O
the	O
network	O
to	O
be	O
able	O
to	O
cope	O
with	O
any	O
order	O
by	O
randomly	O
sampling	O
orders	O
and	O
providing	O
the	O
information	O
to	O
hidden	O
units	O
specifying	O
which	O
of	O
the	O
inputs	O
are	O
observed	O
the	O
right	O
side	O
of	O
the	O
conditioning	O
bar	O
and	O
which	O
are	O
to	O
be	O
predicted	O
and	O
are	O
thus	O
considered	O
missing	O
the	O
left	O
side	O
of	O
the	O
conditioning	O
bar	O
this	O
is	O
nice	O
because	O
it	O
allows	O
one	O
to	O
use	O
a	O
trained	O
auto-regressive	O
network	O
to	O
perform	O
any	O
inference	O
problem	O
predict	O
or	O
sample	O
from	O
the	O
probability	B
distribution	I
over	O
any	O
subset	O
of	O
variables	O
given	O
any	O
subset	O
extremely	O
efficiently	O
finally	O
since	O
many	O
orders	O
of	O
variables	O
are	O
possible	O
for	O
n	O
variables	O
and	O
each	O
order	O
o	O
of	O
variables	O
yields	O
a	O
different	O
we	O
can	O
form	O
an	O
ensemble	O
of	O
models	O
for	O
many	O
values	O
of	O
o	O
o	O
p	O
pensemble	O
p	O
o	O
k	O
k	O
this	O
ensemble	O
model	O
usually	O
generalizes	O
better	O
and	O
assigns	O
higher	O
probability	O
to	O
the	O
test	B
set	I
than	O
does	O
an	O
individual	O
model	O
defined	O
by	O
a	O
single	O
ordering	O
bengio	O
and	O
bengio	O
in	O
the	O
same	O
paper	O
the	O
authors	O
propose	O
deep	O
versions	O
of	O
the	O
architecture	O
but	O
unfortunately	O
that	O
immediately	O
makes	O
computation	O
as	O
expensive	O
as	O
in	O
the	O
original	O
neural	O
auto-regressive	O
neural	B
network	I
the	O
first	O
layer	O
and	O
the	O
output	O
layer	O
can	O
still	O
be	O
computed	O
in	O
onh	O
multiply-add	O
operations	O
as	O
in	O
the	O
regular	O
nade	B
where	O
h	O
is	O
the	O
number	O
of	O
hidden	O
units	O
size	O
of	O
the	O
in	O
bengio	O
and	O
bengio	O
groups	O
hi	O
in	O
figures	O
o	O
if	O
every	O
previous	O
group	O
at	O
layer	O
l	O
participates	O
in	O
predicting	O
the	O
next	O
group	O
at	O
layer	O
l	O
assuming	O
n	O
groups	O
of	O
h	O
hidden	O
units	O
at	O
each	O
layer	O
making	O
the	O
i-th	O
group	O
at	O
layer	O
l	O
only	O
depend	O
on	O
the	O
i	O
group	O
as	O
in	O
murray	O
and	O
larochelle	O
at	O
layer	O
l	O
reduces	O
it	O
to	O
o	O
nh	O
however	O
for	O
the	O
other	O
hidden	O
layers	O
the	O
computation	O
is	O
times	O
worse	O
than	O
the	O
regular	O
nade	B
which	O
is	O
still	O
whereas	O
it	O
is	O
and	O
h	O
chapter	O
deep	O
generative	O
models	O
drawing	O
samples	O
from	O
autoencoders	O
in	O
chapter	O
we	O
saw	O
that	O
many	O
kinds	O
of	O
autoencoders	O
learn	O
the	O
data	O
distribution	O
there	O
are	O
close	O
connections	O
between	O
score	O
matching	O
denoising	O
autoencoders	O
and	O
contractive	O
autoencoders	O
these	O
connections	O
demonstrate	O
that	O
some	O
kinds	O
of	O
autoencoders	O
learn	O
the	O
data	O
distribution	O
in	O
some	O
way	O
we	O
have	O
not	O
yet	O
seen	O
how	O
to	O
draw	O
samples	O
from	O
such	O
models	O
some	O
kinds	O
of	O
autoencoders	O
such	O
as	O
the	O
variational	O
autoencoder	O
explicitly	O
represent	O
a	O
probability	B
distribution	I
and	O
admit	O
straightforward	O
ancestral	O
sampling	O
most	O
other	O
kinds	O
of	O
autoencoders	O
require	O
mcmc	O
sampling	O
contractive	O
autoencoders	O
are	O
designed	O
to	O
recover	O
an	O
estimate	O
of	O
the	O
tangent	B
plane	I
of	O
the	O
data	O
manifold	B
this	O
means	O
that	O
repeated	O
encoding	O
and	O
decoding	O
with	O
injected	O
noise	O
will	O
induce	O
a	O
random	O
walk	O
along	O
the	O
surface	O
of	O
the	O
manifold	B
et	O
al	O
this	O
manifold	B
diffusion	O
technique	O
is	O
a	O
kind	O
of	O
markov	B
chain	I
mesnil	O
et	O
al	O
there	O
is	O
also	O
a	O
more	O
general	O
markov	B
chain	I
that	O
can	O
sample	O
from	O
any	O
denoising	O
autoencoder	O
markov	B
chain	I
associated	O
with	O
any	O
denoising	O
autoen	O
coder	O
the	O
above	O
discussion	O
left	O
open	O
the	O
question	O
of	O
what	O
noise	O
to	O
inject	O
and	O
where	O
in	O
order	O
to	O
obtain	O
a	O
markov	B
chain	I
that	O
would	O
generate	O
from	O
the	O
distribution	O
estimated	O
by	O
the	O
autoencoder	O
showed	O
how	O
to	O
construct	O
such	O
a	O
markov	B
chain	I
for	O
generalized	O
denoising	O
autoencoders	O
generalized	O
denoising	O
autoencoders	O
are	O
specified	O
by	O
a	O
denoising	O
distribution	O
for	O
sampling	O
an	O
estimate	O
of	O
the	O
clean	O
input	O
given	O
the	O
corrupted	O
input	O
bengio	O
et	O
al	O
each	O
step	O
of	O
the	O
markov	B
chain	I
that	O
generates	O
from	O
the	O
estimated	O
distribution	O
consists	O
of	O
the	O
following	O
sub-steps	O
illustrated	O
in	O
figure	O
starting	O
from	O
the	O
previous	O
state	O
x	O
inject	O
corruption	O
noise	O
sampling	O
x	O
from	O
c	O
x	O
x	O
encode	O
x	O
into	O
h	O
x	O
decode	O
h	O
x	O
p	O
h	O
p	O
x	O
g	O
x	O
to	O
obtain	O
the	O
parameters	O
h	O
of	O
sample	O
the	O
next	O
state	O
fromx	O
p	O
x	O
g	O
h	O
p	O
chapter	O
deep	O
generative	O
models	O
hh	O
g	O
f	O
x	O
x	O
c	O
x	O
x	O
xx	O
p	O
x	O
x	O
x	O
figure	O
each	O
step	O
of	O
the	O
markov	B
chain	I
associated	O
with	O
a	O
trained	O
denoising	O
autoencoder	O
that	O
generates	O
the	O
samples	O
from	O
the	O
probabilistic	O
model	O
implicitly	O
trained	O
by	O
the	O
denoising	O
log-likelihood	O
criterion	O
each	O
step	O
consists	O
in	O
injecting	O
noise	O
via	O
corruption	O
process	O
c	O
in	O
state	O
x	O
yielding	O
x	O
encoding	O
it	O
with	O
function	O
f	O
yielding	O
h	O
f	O
x	O
decoding	O
the	O
result	O
with	O
function	O
g	O
yielding	O
parameters	O
for	O
the	O
reconstruction	O
distribution	O
and	O
given	O
sampling	O
a	O
new	O
state	O
from	O
the	O
reconstruction	O
distribution	O
gf	O
x	O
in	O
the	O
typical	O
squared	O
reconstruction	O
error	O
case	O
g	O
x	O
which	O
px	O
estimates	O
ex	O
x	O
corruption	O
consists	O
in	O
adding	O
gaussian	O
noise	O
and	O
sampling	O
from	O
consists	O
in	O
adding	O
gaussian	O
noise	O
a	O
second	O
time	O
to	O
the	O
reconstruction	O
x	O
the	O
px	O
latter	O
noise	O
level	O
should	O
correspond	O
to	O
the	O
mean	B
squared	I
error	I
of	O
reconstructions	O
whereas	O
the	O
injected	O
noise	O
is	O
a	O
hyperparameter	O
that	O
controls	O
the	O
mixing	O
speed	O
as	O
well	O
as	O
the	O
extent	O
to	O
which	O
the	O
estimator	O
smooths	O
the	O
empirical	B
distribution	I
in	O
the	O
example	B
illustrated	O
here	O
only	O
the	O
c	O
and	O
p	O
conditionals	O
are	O
stochastic	O
steps	O
and	O
g	O
are	O
deterministic	O
computations	O
although	O
noise	O
can	O
also	O
be	O
injected	O
inside	O
the	O
autoencoder	O
as	O
in	O
generative	O
stochastic	O
networks	O
bengio	O
et	O
al	O
vincent	O
chapter	O
deep	O
generative	O
models	O
showed	O
that	O
if	O
the	O
autoencoder	O
p	O
x	O
et	O
al	O
x	O
forms	O
a	O
consistent	O
bengio	O
estimator	O
of	O
the	O
corresponding	O
true	O
conditional	O
distribution	O
then	O
the	O
stationary	O
distribution	O
of	O
the	O
above	O
markov	B
chain	I
forms	O
a	O
consistent	O
estimator	O
an	O
implicit	O
one	O
of	O
the	O
data	O
generating	O
distribution	O
of	O
clamping	O
and	O
conditional	O
sampling	O
similarly	O
to	O
boltzmann	O
machines	O
denoising	O
autoencoders	O
and	O
their	O
generalizations	O
as	O
gsns	O
described	O
below	O
can	O
be	O
used	O
to	O
sample	O
from	O
a	O
conditional	O
distrixo	O
simply	O
by	O
clamping	O
the	O
observed	O
units	O
xf	O
and	O
only	O
resampling	O
bution	O
pxf	O
the	O
free	O
units	O
xo	O
given	O
xf	O
and	O
the	O
sampled	O
latent	O
variables	O
any	O
for	O
example	B
mp-dbms	O
can	O
be	O
interpreted	O
as	O
a	O
form	O
of	O
denoising	O
autoencoder	O
and	O
are	O
able	O
to	O
sample	O
missing	B
inputs	I
gsns	O
later	O
generalized	O
some	O
of	O
the	O
ideas	O
present	O
in	O
mp-dbms	O
to	O
perform	O
the	O
same	O
operation	B
bengio	O
et	O
al	O
alain	O
et	O
al	O
identified	O
a	O
missing	O
condition	O
from	O
proposition	O
of	O
which	O
is	O
that	O
the	O
transition	O
operator	O
by	O
the	O
stochastic	O
mapping	O
going	O
from	O
one	O
state	O
of	O
the	O
chain	O
to	O
the	O
next	O
should	O
satisfy	O
a	O
property	O
called	O
detailed	O
balance	O
which	O
specifies	O
that	O
a	O
markov	B
chain	I
at	O
equilibrium	O
will	O
remain	O
in	O
equilibrium	O
whether	O
the	O
transition	O
operator	O
is	O
run	O
in	O
forward	O
or	O
reverse	O
bengio	O
et	O
al	O
an	O
experiment	O
in	O
clamping	O
half	O
of	O
the	O
pixels	O
right	O
part	O
of	O
the	O
image	O
and	O
running	O
the	O
markov	B
chain	I
on	O
the	O
other	O
half	O
is	O
shown	O
in	O
figure	O
chapter	O
deep	O
generative	O
models	O
figure	O
illustration	O
of	O
clamping	O
the	O
right	O
half	O
of	O
the	O
image	O
and	O
running	O
the	O
markov	B
chain	I
by	O
resampling	O
only	O
the	O
left	O
half	O
at	O
each	O
step	O
these	O
samples	O
come	O
from	O
a	O
gsn	O
trained	O
to	O
reconstruct	O
mnist	O
digits	O
at	O
each	O
time	O
step	O
using	O
the	O
walkback	O
procedure	O
walk-back	O
training	O
procedure	O
bengio	O
et	O
al	O
the	O
walk-back	O
training	O
procedure	O
was	O
proposed	O
by	O
as	O
a	O
way	O
to	O
accelerate	O
the	O
convergence	O
of	O
generative	O
training	O
of	O
denoising	O
autoencoders	O
instead	O
of	O
performing	O
a	O
one-step	O
encode-decode	O
reconstruction	O
this	O
procedure	O
consists	O
in	O
alternative	O
multiple	O
stochastic	O
encode-decode	O
steps	O
in	O
the	O
generative	O
markov	B
chain	I
initialized	O
at	O
a	O
training	O
example	B
like	O
with	O
the	O
contrastive	O
divergence	O
algorithm	O
described	O
in	O
section	O
and	O
penalizing	O
the	O
last	O
probabilistic	O
reconstructions	O
all	O
of	O
the	O
reconstructions	O
along	O
the	O
way	O
training	O
with	O
k	O
steps	O
is	O
equivalent	O
the	O
sense	O
of	O
achieving	O
the	O
same	O
stationary	O
distribution	O
as	O
training	O
with	O
one	O
step	O
but	O
practically	O
has	O
the	O
advantage	O
that	O
spurious	O
modes	O
further	O
from	O
the	O
data	O
can	O
be	O
removed	O
more	O
efficiently	O
generative	O
stochastic	O
networks	O
generative	O
stochastic	O
networks	O
or	O
gsns	O
are	O
generalizations	O
of	O
denoising	O
autoencoders	O
that	O
include	O
latent	O
variables	O
h	O
in	O
the	O
generative	O
bengio	O
et	O
al	O
chapter	O
deep	O
generative	O
models	O
markov	B
chain	I
in	O
addition	O
to	O
the	O
visible	O
variables	O
denoted	O
a	O
gsn	O
is	O
parametrized	O
by	O
two	O
conditional	B
probability	I
distributions	O
which	O
specify	O
one	O
step	O
of	O
the	O
markov	B
chain	I
px	O
h	O
tells	O
how	O
to	O
generate	O
the	O
next	O
visible	O
variable	O
given	O
the	O
current	O
latent	O
state	O
such	O
a	O
reconstruction	O
distribution	O
is	O
also	O
found	O
in	O
denoising	O
autoencoders	O
rbms	O
dbns	O
and	O
dbms	O
ph	O
h	O
k	O
k	O
x	O
tells	O
how	O
to	O
update	O
the	O
latent	O
state	O
variable	O
given	O
the	O
previous	O
latent	O
state	O
and	O
visible	O
variable	O
denoising	O
autoencoders	O
and	O
gsns	O
differ	O
from	O
classical	O
probabilistic	O
models	O
or	O
undirected	O
in	O
that	O
they	O
parametrize	O
the	O
generative	O
process	O
itself	O
rather	O
than	O
the	O
mathematical	O
specification	O
of	O
the	O
joint	O
distribution	O
of	O
visible	O
and	O
latent	O
variables	O
instead	O
the	O
latter	O
is	O
defined	O
as	O
the	O
stationary	O
distribution	O
of	O
the	O
generative	O
markov	B
chain	I
the	O
conditions	O
for	O
existence	O
of	O
the	O
stationary	O
distribution	O
are	O
mild	O
and	O
are	O
the	O
same	O
conditions	O
required	O
by	O
standard	O
mcmc	O
methods	O
section	O
these	O
conditions	O
are	O
necessary	O
to	O
guarantee	O
that	O
the	O
chain	O
mixes	O
but	O
they	O
can	O
be	O
violated	O
by	O
some	O
choices	O
of	O
the	O
transition	O
distributions	O
example	B
if	O
they	O
were	O
deterministic	O
implicitly	O
if	O
it	O
exists	O
bengio	O
et	O
al	O
one	O
could	O
imagine	O
different	O
training	O
criteria	O
for	O
gsns	O
the	O
one	O
proposed	O
and	O
evaluated	O
by	O
is	O
simply	O
reconstruction	O
log-probability	O
on	O
the	O
visible	O
units	O
just	O
like	O
for	O
denoising	O
autoencoders	O
this	O
is	O
achieved	O
by	O
clamping	O
x	O
to	O
the	O
observed	O
example	B
and	O
maximizing	O
the	O
probability	O
of	O
generating	O
x	O
at	O
some	O
subsequent	O
time	O
steps	O
i	O
e	O
maximizing	O
log	O
px	O
x	O
h	O
where	O
h	O
is	O
sampled	O
from	O
the	O
chain	O
given	O
x	O
in	O
order	O
to	O
estimate	O
the	O
gradient	B
of	O
log	O
px	O
x	O
h	O
with	O
respect	O
to	O
the	O
other	O
pieces	O
of	O
the	O
model	O
bengio	O
et	O
al	O
use	O
the	O
reparametrization	B
trick	B
introduced	O
in	O
section	O
the	O
walk-back	O
training	O
protocol	O
in	O
section	O
to	O
improve	O
training	O
convergence	O
of	O
gsns	O
et	O
al	O
gio	O
discriminant	O
gsns	O
was	O
used	O
ben	O
the	O
original	O
formulation	O
of	O
gsns	O
was	O
meant	O
for	O
unsupervised	O
learning	O
and	O
implicitly	O
modeling	O
px	O
for	O
observed	O
data	O
x	O
but	O
it	O
is	O
possible	O
to	O
modify	O
the	O
framework	O
to	O
optimize	O
bengio	O
et	O
al	O
x	O
p	O
y	O
for	O
example	B
zhou	O
and	O
troyanskaya	O
generalize	O
gsns	O
in	O
this	O
way	O
by	O
only	O
back-propagating	O
the	O
reconstruction	O
log-probability	O
over	O
the	O
output	O
variables	O
keeping	O
the	O
input	O
variables	O
fixed	O
they	O
applied	O
this	O
successfully	O
to	O
model	O
sequences	O
chapter	O
deep	O
generative	O
models	O
secondary	O
structure	O
and	O
introduced	O
a	O
convolutional	O
structure	O
in	O
the	O
transition	O
operator	O
of	O
the	O
markov	B
chain	I
it	O
is	O
important	O
to	O
remember	O
that	O
for	O
each	O
step	O
of	O
the	O
markov	B
chain	I
one	O
generates	O
a	O
new	O
sequence	O
for	O
each	O
layer	O
and	O
that	O
sequence	O
is	O
the	O
input	O
for	O
computing	O
other	O
layer	O
values	O
the	O
one	O
below	O
and	O
the	O
one	O
above	O
at	O
the	O
next	O
time	O
step	O
hence	O
the	O
markov	B
chain	I
is	O
really	O
over	O
the	O
output	O
variable	O
associated	O
higherlevel	O
hidden	O
layers	O
and	O
the	O
input	O
sequence	O
only	O
serves	O
to	O
condition	O
that	O
chain	O
with	O
back-propagation	B
allowing	O
to	O
learn	O
how	O
the	O
input	O
sequence	O
can	O
condition	O
the	O
output	O
distribution	O
implicitly	O
represented	O
by	O
the	O
markov	B
chain	I
it	O
is	O
therefore	O
a	O
case	O
of	O
using	O
the	O
gsn	O
in	O
the	O
context	O
of	O
structured	O
outputs	O
z	O
hrer	O
and	O
pernkopf	O
introduced	O
a	O
hybrid	O
model	O
that	O
combines	O
a	O
supervised	O
objective	O
in	O
the	O
above	O
work	O
and	O
an	O
unsupervised	O
objective	O
in	O
the	O
original	O
gsn	O
work	O
by	O
simply	O
adding	O
a	O
different	O
weight	O
the	O
supervised	O
and	O
unsupervised	O
costs	O
i	O
e	O
the	O
reconstruction	O
log-probabilities	O
of	O
y	O
and	O
x	O
respectively	O
such	O
a	O
hybrid	O
criterion	O
had	O
previously	O
been	O
introduced	O
for	O
rbms	O
by	O
larochelle	O
and	O
bengio	O
they	O
show	O
improved	O
classification	B
performance	O
using	O
this	O
scheme	O
other	O
generation	O
schemes	O
the	O
methods	O
we	O
have	O
described	O
so	O
far	O
use	O
either	O
mcmc	O
sampling	O
ancestral	O
sampling	O
or	O
some	O
mixture	O
of	O
the	O
two	O
to	O
generate	O
samples	O
while	O
these	O
are	O
the	O
most	O
popular	O
approaches	O
to	O
generative	O
modeling	O
they	O
are	O
by	O
no	O
means	O
the	O
only	O
approaches	O
et	O
al	O
sohl-dickstein	O
developed	O
a	O
diffusion	O
inversion	O
training	O
scheme	O
for	O
learning	O
a	O
generative	O
model	O
based	O
on	O
non-equilibrium	O
thermodynamics	O
the	O
approach	O
is	O
based	O
on	O
the	O
idea	O
that	O
the	O
probability	O
distributions	O
we	O
wish	O
to	O
sample	O
from	O
have	O
structure	O
this	O
structure	O
can	O
gradually	O
be	O
destroyed	O
by	O
a	O
diffusion	O
process	O
that	O
incrementally	O
changes	O
the	O
probability	B
distribution	I
to	O
have	O
more	O
entropy	O
to	O
form	O
a	O
generative	O
model	O
we	O
can	O
run	O
the	O
process	O
in	O
reverse	O
by	O
training	O
a	O
model	O
that	O
gradually	O
restores	O
the	O
structure	O
to	O
an	O
unstructured	O
distribution	O
by	O
iteratively	O
applying	O
a	O
process	O
that	O
brings	O
a	O
distribution	O
closer	O
to	O
the	O
target	O
one	O
we	O
can	O
gradually	O
approach	O
that	O
target	O
distribution	O
this	O
approach	O
resembles	O
mcmc	O
methods	O
in	O
the	O
sense	O
that	O
it	O
involves	O
many	O
iterations	O
to	O
produce	O
a	O
sample	O
however	O
the	O
model	O
is	O
defined	O
to	O
be	O
the	O
probability	B
distribution	I
produced	O
by	O
the	O
final	O
step	O
of	O
the	O
chain	O
in	O
this	O
sense	O
there	O
is	O
no	O
approximation	O
induced	O
by	O
the	O
iterative	O
procedure	O
the	O
approach	O
introduced	O
by	O
sohl-dickstein	O
et	O
al	O
is	O
also	O
very	O
close	O
to	O
the	O
generative	O
interpretation	O
of	O
the	O
denoising	O
autoencoder	O
chapter	O
deep	O
generative	O
models	O
as	O
with	O
the	O
denoising	O
autoencoder	O
diffusion	O
inversion	O
trains	O
a	O
transition	O
operator	O
that	O
attempts	O
to	O
probabilistically	O
undo	O
the	O
effect	O
of	O
adding	O
some	O
noise	O
the	O
difference	O
is	O
that	O
diffusion	O
inversion	O
requres	O
undoing	O
only	O
one	O
step	O
of	O
the	O
diffusion	O
process	O
rather	O
than	O
traveling	O
all	O
the	O
way	O
back	O
to	O
a	O
clean	O
data	O
point	O
this	O
addresses	O
the	O
following	O
dilemma	O
present	O
with	O
the	O
ordinary	O
reconstruction	O
log-likelihood	O
objective	O
of	O
denoising	O
autoencoders	O
with	O
small	O
levels	O
of	O
noise	O
the	O
learner	O
only	O
sees	O
configurations	O
near	O
the	O
data	O
points	O
while	O
with	O
large	O
levels	O
of	O
noise	O
it	O
is	O
asked	O
to	O
do	O
an	O
almost	O
impossible	O
job	O
the	O
denoising	O
distribution	O
is	O
highly	O
complex	O
and	O
multi-modal	O
with	O
the	O
diffusion	O
inversion	O
objective	O
the	O
learner	O
can	O
learn	O
the	O
shape	O
of	O
the	O
density	O
around	O
the	O
data	O
points	O
more	O
precisely	O
as	O
well	O
as	O
remove	O
spurious	O
modes	O
that	O
could	O
show	O
up	O
far	O
from	O
the	O
data	O
points	O
rubin	O
et	O
al	O
another	O
approach	O
to	O
sample	O
generation	O
is	O
the	O
approximate	O
bayesian	O
com	O
in	O
this	O
approach	O
samples	O
are	O
putation	O
framework	O
rejected	O
or	O
modified	O
in	O
order	O
to	O
make	O
the	O
moments	O
of	O
selected	O
functions	O
of	O
the	O
samples	O
match	O
those	O
of	O
the	O
desired	O
distribution	O
while	O
this	O
idea	O
uses	O
the	O
moments	O
of	O
the	O
samples	O
like	O
in	O
moment	B
matching	I
it	O
is	O
different	O
from	O
moment	B
matching	I
because	O
it	O
modifies	O
the	O
samples	O
themselves	O
rather	O
than	O
training	O
the	O
model	O
to	O
automatically	O
emit	O
samples	O
with	O
the	O
correct	O
moments	O
bachman	O
and	O
precup	O
showed	O
how	O
to	O
use	O
ideas	O
from	O
abc	O
in	O
the	O
context	O
of	O
deep	O
learning	O
by	O
using	O
abc	O
to	O
shape	O
the	O
mcmc	O
trajectories	O
of	O
gsns	O
we	O
expect	O
that	O
many	O
other	O
possible	O
approaches	O
to	O
generative	O
modeling	O
await	O
discovery	O
evaluating	O
generative	O
models	O
researchers	O
studying	O
generative	O
models	O
often	O
need	O
to	O
compare	O
one	O
generative	O
model	O
to	O
another	O
usually	O
in	O
order	O
to	O
demonstrate	O
that	O
a	O
newly	O
invented	O
generative	O
model	O
is	O
better	O
at	O
capturing	O
some	O
distribution	O
than	O
the	O
pre-existing	O
models	O
this	O
can	O
be	O
a	O
difficult	O
and	O
subtle	O
task	O
in	O
many	O
cases	O
we	O
can	O
not	O
actually	O
evaluate	O
the	O
log	O
probability	O
of	O
the	O
data	O
under	O
the	O
model	O
but	O
only	O
an	O
approximation	O
in	O
these	O
cases	O
it	O
is	O
important	O
to	O
think	O
and	O
communicate	O
clearly	O
about	O
exactly	O
what	O
is	O
being	O
measured	O
for	O
example	B
suppose	O
we	O
can	O
evaluate	O
a	O
stochastic	O
estimate	O
of	O
the	O
log-likelihood	O
for	O
model	O
a	O
and	O
a	O
deterministic	O
lower	O
bound	B
on	O
the	O
log-likelihood	O
for	O
model	O
b	O
if	O
model	O
a	O
gets	O
a	O
higher	O
score	O
than	O
model	O
b	O
which	O
is	O
better	O
if	O
we	O
care	O
about	O
determining	O
which	O
model	O
has	O
a	O
better	O
internal	O
representation	O
of	O
the	O
distribution	O
we	O
actually	O
cannot	O
tell	O
unless	O
we	O
have	O
some	O
way	O
of	O
determining	O
how	O
loose	O
the	O
bound	B
for	O
model	O
b	O
is	O
however	O
if	O
we	O
care	O
about	O
how	O
well	O
we	O
can	O
use	O
the	O
model	O
in	O
practice	O
for	O
example	B
to	O
perform	O
anomaly	O
detection	O
then	O
it	O
is	O
fair	O
to	O
chapter	O
deep	O
generative	O
models	O
say	O
that	O
a	O
model	O
is	O
preferable	O
based	O
on	O
a	O
criterion	O
specific	O
to	O
the	O
practical	O
task	O
of	O
interest	O
e	O
g	O
based	O
on	O
ranking	O
test	O
examples	O
and	O
ranking	O
criteria	O
such	O
as	O
precision	B
and	O
recall	B
another	O
subtlety	O
of	O
evaluating	O
generative	O
models	O
is	O
that	O
the	O
evaluation	O
metrics	O
are	O
often	O
hard	O
research	O
problems	O
in	O
and	O
of	O
themselves	O
it	O
can	O
be	O
very	O
difficult	O
to	O
establish	O
that	O
models	O
are	O
being	O
compared	O
fairly	O
for	O
example	B
suppose	O
we	O
use	O
ais	O
to	O
estimate	O
log	O
z	O
in	O
order	O
to	O
compute	O
log	O
px	O
log	O
z	O
for	O
a	O
new	O
model	O
we	O
have	O
just	O
invented	O
a	O
computationally	O
economical	O
implementation	O
of	O
ais	O
may	O
fail	O
to	O
find	O
several	O
modes	O
of	O
the	O
model	O
distribution	O
and	O
underestimate	O
z	O
which	O
will	O
result	O
in	O
us	O
overestimating	O
log	O
px	O
it	O
can	O
thus	O
be	O
difficult	O
to	O
tell	O
whether	O
a	O
high	O
likelihood	O
estimate	O
is	O
due	O
to	O
a	O
good	O
model	O
or	O
a	O
bad	O
ais	O
implementation	O
other	O
fields	O
of	O
machine	B
learning	I
usually	O
allow	O
for	O
some	O
variation	O
in	O
the	O
preprocessing	B
of	O
the	O
data	O
for	O
example	B
when	O
comparing	O
the	O
accuracy	B
of	O
object	B
recognition	I
algorithms	O
it	O
is	O
usually	O
acceptable	O
to	O
preprocess	O
the	O
input	O
images	O
slightly	O
differently	O
for	O
each	O
algorithm	O
based	O
on	O
what	O
kind	O
of	O
input	O
requirements	O
it	O
has	O
generative	O
modeling	O
is	O
different	O
because	O
changes	O
in	O
preprocessing	B
even	O
very	O
small	O
and	O
subtle	O
ones	O
are	O
completely	O
unacceptable	O
any	O
change	O
to	O
the	O
input	O
data	O
changes	O
the	O
distribution	O
to	O
be	O
captured	O
and	O
fundamentally	O
alters	O
the	O
task	O
for	O
example	B
multiplying	O
the	O
input	O
by	O
will	O
artificially	O
increase	O
likelihood	O
by	O
a	O
factor	O
of	O
issues	O
with	O
preprocessing	B
commonly	O
arise	O
when	O
benchmarking	O
generative	O
models	O
on	O
the	O
mnist	O
dataset	B
one	O
of	O
the	O
more	O
popular	O
generative	O
modeling	O
benchmarks	O
mnist	O
consists	O
of	O
grayscale	O
images	O
some	O
models	O
treat	O
mnist	O
images	O
as	O
points	O
in	O
a	O
real	O
vector	O
space	O
while	O
others	O
treat	O
them	O
as	O
binary	O
yet	O
others	O
treat	O
the	O
grayscale	O
values	O
as	O
probabilities	O
for	O
a	O
binary	O
samples	O
it	O
is	O
essential	O
to	O
compare	O
real-valued	O
models	O
only	O
to	O
other	O
real-valued	O
models	O
and	O
binary-valued	O
models	O
only	O
to	O
other	O
binary-valued	O
models	O
otherwise	O
the	O
likelihoods	O
measured	O
are	O
not	O
on	O
the	O
same	O
space	O
for	O
binary-valued	O
models	O
the	O
log-likelihood	O
can	O
be	O
at	O
most	O
zero	O
while	O
for	O
real-valued	O
models	O
it	O
can	O
be	O
arbitrarily	O
high	O
since	O
it	O
is	O
the	O
measurement	O
of	O
a	O
density	O
among	O
binary	O
models	O
it	O
is	O
important	O
to	O
compare	O
models	O
using	O
exactly	O
the	O
same	O
kind	O
of	O
binarization	O
for	O
example	B
we	O
might	O
binarize	O
a	O
gray	O
pixel	O
to	O
or	O
by	O
thresholding	O
at	O
or	O
by	O
drawing	O
a	O
random	O
sample	O
whose	O
probability	O
of	O
being	O
is	O
given	O
by	O
the	O
gray	O
pixel	O
intensity	O
if	O
we	O
use	O
the	O
random	O
binarization	O
we	O
might	O
binarize	O
the	O
whole	O
dataset	B
once	O
or	O
we	O
might	O
draw	O
a	O
different	O
random	O
example	B
for	O
each	O
step	O
of	O
training	O
and	O
then	O
draw	O
multiple	O
samples	O
for	O
evaluation	O
each	O
of	O
these	O
three	O
schemes	O
yields	O
wildly	O
different	O
likelihood	O
numbers	O
and	O
when	O
comparing	O
different	O
models	O
it	O
is	O
important	O
that	O
both	O
models	O
use	O
the	O
same	O
binarization	O
scheme	O
for	O
training	O
and	O
for	O
evaluation	O
in	O
fact	O
researchers	O
who	O
apply	O
a	O
single	O
random	O
chapter	O
deep	O
generative	O
models	O
binarization	O
step	O
share	O
a	O
file	O
containing	O
the	O
results	O
of	O
the	O
random	O
binarization	O
so	O
that	O
there	O
is	O
no	O
difference	O
in	O
results	O
based	O
on	O
different	O
outcomes	O
of	O
the	O
binarization	O
step	O
et	O
al	O
because	O
being	O
able	O
to	O
generate	O
realistic	O
samples	O
from	O
the	O
data	O
distribution	O
is	O
one	O
of	O
the	O
goals	O
of	O
a	O
generative	O
model	O
practitioners	O
often	O
evaluate	O
generative	O
models	O
by	O
visually	O
inspecting	O
the	O
samples	O
in	O
the	O
best	O
case	O
this	O
is	O
done	O
not	O
by	O
the	O
researchers	O
themselves	O
but	O
by	O
experimental	O
subjects	O
who	O
do	O
not	O
know	O
the	O
source	O
of	O
the	O
samples	O
unfortunately	O
it	O
is	O
possible	O
for	O
a	O
very	O
poor	O
probabilistic	O
model	O
to	O
produce	O
very	O
good	O
samples	O
a	O
common	O
practice	O
to	O
verify	O
if	O
the	O
model	O
only	O
copies	O
some	O
of	O
the	O
training	O
examples	O
is	O
illustrated	O
in	O
figure	O
the	O
idea	O
is	O
to	O
show	O
for	O
some	O
of	O
the	O
generated	O
samples	O
their	O
nearest	O
neighbor	O
in	O
the	O
training	O
set	O
according	O
to	O
euclidean	O
distance	O
in	O
the	O
space	O
of	O
x	O
this	O
test	O
is	O
intended	O
to	O
detect	O
the	O
case	O
where	O
the	O
model	O
overfits	O
the	O
training	O
set	O
and	O
just	O
reproduces	O
training	O
instances	O
it	O
is	O
even	O
possible	O
to	O
simultaneously	O
underfit	O
and	O
overfit	O
yet	O
still	O
produce	O
samples	O
that	O
individually	O
look	O
good	O
imagine	O
a	O
generative	O
model	O
trained	O
on	O
images	O
of	O
dogs	O
and	O
cats	O
that	O
simply	O
learns	O
to	O
reproduce	O
the	O
training	O
images	O
of	O
dogs	O
such	O
a	O
model	O
has	O
clearly	O
overfit	O
because	O
it	O
does	O
not	O
produces	O
images	O
that	O
were	O
not	O
in	O
the	O
training	O
set	O
but	O
it	O
has	O
also	O
underfit	O
because	O
it	O
assigns	O
no	O
probability	O
to	O
the	O
training	O
images	O
of	O
cats	O
yet	O
a	O
human	O
observer	O
would	O
judge	O
each	O
individual	O
image	O
of	O
a	O
dog	O
to	O
be	O
high	O
quality	O
in	O
this	O
simple	O
example	B
it	O
would	O
be	O
easy	O
for	O
a	O
human	O
observer	O
who	O
can	O
inspect	O
many	O
samples	O
to	O
determine	O
that	O
the	O
cats	O
are	O
absent	O
in	O
more	O
realistic	O
settings	O
a	O
generative	O
model	O
trained	O
on	O
data	O
with	O
tens	O
of	O
thousands	O
of	O
modes	O
may	O
ignore	O
a	O
small	O
number	O
of	O
modes	O
and	O
a	O
human	O
observer	O
would	O
not	O
easily	O
be	O
able	O
to	O
inspect	O
or	O
remember	O
enough	O
images	O
to	O
detect	O
the	O
missing	O
variation	O
since	O
the	O
visual	O
quality	O
of	O
samples	O
is	O
not	O
a	O
reliable	O
guide	O
we	O
often	O
also	O
evaluate	O
the	O
log-likelihood	O
that	O
the	O
model	O
assigns	O
to	O
the	O
test	O
data	O
when	O
this	O
is	O
computationally	O
feasible	O
unfortunately	O
in	O
some	O
cases	O
the	O
likelihood	O
seems	O
not	O
to	O
measure	O
any	O
attribute	O
of	O
the	O
model	O
that	O
we	O
really	O
care	O
about	O
for	O
example	B
real-valued	O
models	O
of	O
mnist	O
can	O
obtain	O
arbitrarily	O
high	O
likelihood	O
by	O
assigning	O
arbitrarily	O
low	O
variance	O
to	O
background	O
pixels	O
that	O
never	O
change	O
models	O
and	O
algorithms	O
that	O
detect	O
these	O
constant	O
features	O
can	O
reap	O
unlimited	O
rewards	O
even	O
though	O
this	O
is	O
not	O
a	O
very	O
useful	O
thing	O
to	O
do	O
the	O
potential	O
to	O
achieve	O
a	O
cost	O
approaching	O
negative	O
infinity	O
is	O
present	O
for	O
any	O
kind	O
of	O
maximum	B
likelihood	I
problem	O
with	O
real	O
values	O
but	O
it	O
is	O
especially	O
problematic	O
for	O
generative	O
models	O
of	O
mnist	O
because	O
so	O
many	O
of	O
the	O
output	O
values	O
are	O
trivial	O
to	O
predict	O
this	O
strongly	O
suggests	O
a	O
need	O
for	O
developing	O
other	O
ways	O
of	O
evaluating	O
generative	O
models	O
theis	O
et	O
al	O
review	O
many	O
of	O
the	O
issues	O
involved	O
in	O
evaluating	O
generative	O
chapter	O
deep	O
generative	O
models	O
models	O
including	O
many	O
of	O
the	O
ideas	O
described	O
above	O
they	O
highlight	O
the	O
fact	O
that	O
there	O
are	O
many	O
different	O
uses	O
of	O
generative	O
models	O
and	O
that	O
the	O
choice	O
of	O
metric	O
must	O
match	O
the	O
intended	O
use	O
of	O
the	O
model	O
for	O
example	B
some	O
generative	O
models	O
are	O
better	O
at	O
assigning	O
high	O
probability	O
to	O
most	O
realistic	O
points	O
while	O
other	O
generative	O
models	O
are	O
better	O
at	O
rarely	O
assigning	O
high	O
probability	O
to	O
unrealistic	O
points	O
these	O
differences	O
can	O
result	O
from	O
whether	O
a	O
generative	O
model	O
is	O
designed	O
to	O
minimize	O
d	O
klpdata	O
unfortunately	O
even	O
when	O
we	O
restrict	O
the	O
use	O
of	O
each	O
metric	O
to	O
the	O
task	O
it	O
is	O
most	O
suited	O
for	O
all	O
of	O
the	O
metrics	O
currently	O
in	O
use	O
continue	O
to	O
have	O
serious	O
weaknesses	O
one	O
of	O
the	O
most	O
important	O
research	O
topics	O
in	O
generative	O
modeling	O
is	O
therefore	O
not	O
just	O
how	O
to	O
improve	O
generative	O
models	O
but	O
in	O
fact	O
designing	O
new	O
techniques	O
to	O
measure	O
our	O
progress	O
pdata	O
as	O
illustrated	O
in	O
figure	O
pmodel	O
or	O
d	O
klpmodel	O
conclusion	O
training	O
generative	O
models	O
with	O
hidden	O
units	O
is	O
a	O
powerful	O
way	O
to	O
make	O
models	O
understand	O
the	O
world	O
represented	O
in	O
the	O
given	O
training	O
data	O
by	O
learning	O
a	O
model	O
pmodelx	O
and	O
a	O
representation	O
pmodel	O
x	O
a	O
generative	O
model	O
can	O
provide	O
answers	O
to	O
many	O
inference	O
problems	O
about	O
the	O
relationships	O
between	O
input	O
variables	O
in	O
x	O
and	O
can	O
provide	O
many	O
different	O
ways	O
of	O
representing	O
x	O
by	O
taking	O
expectations	O
of	O
h	O
at	O
different	O
layers	O
of	O
the	O
hierarchy	O
generative	O
models	O
hold	O
the	O
promise	O
to	O
provide	O
ai	O
systems	O
with	O
a	O
framework	O
for	O
all	O
of	O
the	O
many	O
different	O
intuitive	O
concepts	O
they	O
need	O
to	O
understand	O
and	O
the	O
ability	O
to	O
reason	O
about	O
these	O
concepts	O
in	O
the	O
face	O
of	O
uncertainty	O
we	O
hope	O
that	O
our	O
readers	O
will	O
find	O
new	O
ways	O
to	O
make	O
these	O
approaches	O
more	O
powerful	O
and	O
continue	O
the	O
journey	O
to	O
understanding	O
the	O
principles	O
that	O
underlie	O
learning	O
and	O
intelligence	O
bibliography	O
abadi	O
m	O
agarwal	O
a	O
barham	O
p	O
brevdo	O
e	O
chen	O
z	O
citro	O
c	O
corrado	O
g	O
s	O
davis	O
a	O
dean	O
j	O
devin	O
m	O
ghemawat	O
s	O
goodfellow	O
i	O
harp	O
a	O
irving	O
g	O
isard	O
m	O
jia	O
y	O
jozefowicz	O
r	O
kaiser	O
l	O
kudlur	O
m	O
levenberg	O
j	O
man	O
d	O
monga	O
r	O
moore	O
s	O
murray	O
d	O
olah	O
c	O
schuster	O
m	O
shlens	O
j	O
steiner	O
b	O
sutskever	O
i	O
talwar	O
k	O
tucker	O
p	O
vanhoucke	O
v	O
vasudevan	O
v	O
vi	O
gas	O
f	O
vinyals	O
o	O
warden	O
p	O
wattenberg	O
m	O
wicke	O
m	O
yu	O
y	O
and	O
zheng	O
x	O
tensorflow	O
large-scale	O
machine	B
learning	I
on	O
heterogeneous	O
systems	O
software	O
available	O
from	O
tensorflow	O
org	O
ackley	O
d	O
h	O
hinton	O
g	O
e	O
and	O
sejnowski	O
t	O
j	O
a	O
learning	O
algorithm	O
for	O
boltzmann	O
machines	O
cognitive	O
science	O
alain	O
g	O
and	O
bengio	O
y	O
what	O
regularized	O
auto-encoders	O
learn	O
from	O
the	O
data	O
generating	O
distribution	O
in	O
iclr	O
alain	O
g	O
bengio	O
y	O
yao	O
l	O
ric	O
thibodeau-laufer	O
yosinski	O
j	O
and	O
vincent	O
p	O
gsns	O
generative	O
stochastic	O
networks	O
anderson	O
e	O
the	O
irises	O
of	O
the	O
gasp	O
peninsula	O
bulletin	O
of	O
the	O
american	O
iris	O
society	O
ba	O
j	O
mnih	O
v	O
and	O
kavukcuoglu	O
k	O
multiple	O
object	B
recognition	I
with	O
visual	O
attention	O
bachman	O
p	O
and	O
precup	O
d	O
variational	O
generative	O
stochastic	O
networks	O
with	O
collaborative	O
shaping	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
machine	B
learning	I
icml	O
lille	O
france	O
july	O
pages	O
bacon	O
p	O
-l	O
bengio	O
e	O
pineau	O
j	O
and	O
precup	O
d	O
conditional	O
computation	O
in	O
neural	O
networks	O
using	O
a	O
decision-theoretic	O
approach	O
in	O
multidisciplinary	O
conference	O
on	O
reinforcement	O
learning	O
and	O
decision	O
making	O
bagnell	O
j	O
a	O
and	O
bradley	O
d	O
m	O
differentiable	O
sparse	O
coding	O
in	O
d	O
koller	O
d	O
schuurmans	O
y	O
bengio	O
and	O
l	O
bottou	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
bibliography	O
bahdanau	O
d	O
cho	O
k	O
and	O
bengio	O
y	O
neural	O
machine	B
translation	I
by	O
jointly	O
iclr	O
learning	O
to	O
align	O
and	O
translate	O
in	O
bahl	O
l	O
r	O
brown	O
p	O
de	O
souza	O
p	O
v	O
and	O
mercer	O
r	O
l	O
speech	O
recognition	O
with	O
continuous-parameter	O
hidden	O
markov	O
models	O
computer	O
speech	O
and	O
language	O
baldi	O
p	O
and	O
hornik	O
k	O
neural	O
networks	O
and	O
principal	O
component	O
analysis	O
learning	O
from	O
examples	O
without	O
local	O
minima	O
neural	O
networks	O
baldi	O
p	O
brunak	O
s	O
frasconi	O
p	O
soda	O
g	O
and	O
pollastri	O
g	O
exploiting	O
the	O
bioinformatics	O
past	O
and	O
the	O
future	O
in	O
protein	O
secondary	O
structure	O
prediction	O
baldi	O
p	O
sadowski	O
p	O
and	O
whiteson	O
d	O
searching	O
for	O
exotic	O
particles	O
in	O
high-energy	O
physics	O
with	O
deep	O
learning	O
nature	O
communications	O
ballard	O
d	O
h	O
hinton	O
g	O
e	O
and	O
sejnowski	O
t	O
j	O
parallel	O
vision	O
computation	O
nature	O
barlow	O
h	O
b	O
unsupervised	O
learning	O
neural	O
computation	O
barron	O
a	O
e	O
universal	O
approximation	O
bounds	O
for	O
superpositions	O
of	O
a	O
sigmoidal	O
function	O
ieee	O
trans	O
on	O
information	O
theory	O
bartholomew	O
d	O
j	O
latent	B
variable	I
models	O
and	O
factor	B
analysis	I
oxford	O
university	O
press	O
basilevsky	O
a	O
statistical	O
factor	B
analysis	I
and	O
related	O
methods	O
theory	O
and	O
applications	O
wiley	O
bastien	O
f	O
lamblin	O
p	O
pascanu	O
r	O
bergstra	O
j	O
goodfellow	O
i	O
j	O
bergeron	O
a	O
bouchard	O
n	O
and	O
bengio	O
y	O
theano	O
new	O
features	O
and	O
speed	O
improvements	O
deep	O
learning	O
and	O
unsupervised	O
feature	B
learning	O
nips	O
workshop	O
basu	O
s	O
and	O
christensen	O
j	O
teaching	O
classification	B
boundaries	O
to	O
humans	O
in	O
aaai	O
baxter	O
j	O
learning	O
internal	O
representations	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
computational	O
learning	O
theory	O
pages	O
santa	O
cruz	O
california	O
acm	O
press	O
bayer	O
j	O
and	O
osendorfer	O
c	O
learning	O
stochastic	O
recurrent	O
networks	O
arxiv	O
e-prints	O
becker	O
s	O
and	O
hinton	O
g	O
a	O
self-organizing	O
neural	B
network	I
that	O
discovers	O
surfaces	O
in	O
random-dot	O
stereograms	O
nature	O
bibliography	O
behnke	O
s	O
learning	O
iterative	O
image	O
reconstruction	O
in	O
the	O
neural	O
abstraction	O
pyramid	O
int	O
j	O
computational	O
intelligence	O
and	O
applications	O
beiu	O
v	O
quintana	O
j	O
m	O
and	O
avedillo	O
m	O
j	O
vlsi	O
implementations	O
of	O
threshold	O
logic-a	O
comprehensive	O
survey	O
neural	O
networks	O
ieee	O
transactions	O
on	O
belkin	O
m	O
and	O
niyogi	O
p	O
laplacian	O
eigenmaps	O
and	O
spectral	O
techniques	O
for	O
embedding	B
and	O
clustering	O
in	O
t	O
dietterich	O
s	O
becker	O
and	O
z	O
ghahramani	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
cambridge	O
ma	O
mit	O
press	O
belkin	O
m	O
and	O
niyogi	O
p	O
laplacian	O
eigenmaps	O
for	O
dimensionality	O
reduction	O
and	O
data	O
representation	O
neural	O
computation	O
bengio	O
e	O
bacon	O
p	O
-l	O
pineau	O
j	O
and	O
precup	O
d	O
conditional	O
computation	O
in	O
neural	O
networks	O
for	O
faster	O
models	O
bengio	O
s	O
and	O
bengio	O
y	O
taking	O
on	O
the	O
curse	B
of	I
dimensionality	I
in	O
joint	O
distributions	O
using	O
neural	O
networks	O
ieee	O
transactions	O
on	O
neural	O
networks	O
special	O
issue	O
on	O
data	O
mining	O
and	O
knowledge	O
discovery	O
bengio	O
s	O
vinyals	O
o	O
jaitly	O
n	O
and	O
shazeer	O
n	O
scheduled	O
sampling	O
for	O
sequence	O
prediction	O
with	O
recurrent	O
neural	O
networks	O
technical	O
report	O
bengio	O
y	O
artificial	O
neural	O
networks	O
and	O
their	O
application	O
to	O
sequence	O
recognition	O
ph	O
d	O
thesis	O
mcgill	O
university	O
science	O
montreal	O
canada	O
bengio	O
y	O
gradient-based	O
optimization	O
of	O
hyperparameters	O
neural	O
computation	O
bengio	O
y	O
new	O
distributed	O
probabilistic	O
language	O
models	O
technical	O
report	O
dept	O
iro	O
universit	O
de	O
montr	O
al	O
bengio	O
y	O
learning	O
deep	O
architectures	O
for	O
ai	O
now	O
publishers	O
bengio	O
y	O
deep	O
learning	O
of	O
representations	O
looking	O
forward	O
in	O
statistical	O
language	O
and	O
speech	O
processing	O
volume	O
of	O
lecture	O
notes	O
in	O
computer	O
science	O
pages	O
springer	O
also	O
in	O
arxiv	O
at	O
bengio	O
y	O
early	O
inference	O
in	O
energy-based	O
models	O
approximates	O
back-propagation	B
technical	O
report	O
universite	O
de	O
montreal	O
bengio	O
y	O
and	O
bengio	O
s	O
modeling	O
high-dimensional	O
discrete	O
data	O
with	O
multi	O
layer	O
neural	O
networks	O
in	O
nips	O
pages	O
mit	O
press	O
bengio	O
y	O
and	O
delalleau	O
o	O
justifying	O
and	O
generalizing	O
contrastive	O
divergence	O
neural	O
computation	O
bibliography	O
bengio	O
y	O
and	O
grandvalet	O
y	O
no	O
unbiased	B
estimator	O
of	O
the	O
variance	O
of	O
k-fold	O
cross-validation	B
in	O
s	O
thrun	O
l	O
saul	O
and	O
b	O
sch	O
lkopf	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
cambridge	O
ma	O
mit	O
press	O
cambridge	O
bengio	O
y	O
and	O
lecun	O
y	O
scaling	O
learning	O
algorithms	O
towards	O
ai	O
in	O
large	O
scale	O
kernel	O
machines	O
bengio	O
y	O
and	O
monperrus	O
m	O
non-local	O
manifold	B
tangent	O
learning	O
in	O
l	O
saul	O
y	O
weiss	O
and	O
l	O
bottou	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
bengio	O
y	O
and	O
s	O
n	O
cal	O
j	O
-s	O
quick	O
training	O
of	O
probabilistic	O
neural	O
nets	O
by	O
importance	O
sampling	O
in	O
proceedings	O
of	O
aistats	O
bengio	O
y	O
and	O
s	O
n	O
cal	O
j	O
-s	O
adaptive	O
importance	O
sampling	O
to	O
accelerate	O
training	O
of	O
a	O
neural	O
probabilistic	O
language	O
model	O
ieee	O
trans	O
neural	O
networks	O
bengio	O
y	O
de	O
mori	O
r	O
flammia	O
g	O
and	O
kompe	O
r	O
phonetically	O
motivated	O
acoustic	O
parameters	O
for	O
continuous	O
speech	O
recognition	O
using	O
artificial	O
neural	O
networks	O
in	O
proceedings	O
of	O
eurospeech	O
bengio	O
y	O
de	O
mori	O
r	O
flammia	O
g	O
and	O
kompe	O
r	O
neural	O
network-gaussian	O
pages	O
mixture	O
hybrid	O
for	O
speech	O
recognition	O
or	O
density	B
estimation	I
in	O
morgan	O
kaufmann	O
nips	O
bengio	O
y	O
frasconi	O
p	O
and	O
simard	O
p	O
the	O
problem	O
of	O
learning	O
long-term	O
in	O
ieee	O
international	O
conference	O
on	O
neural	O
dependencies	O
in	O
recurrent	O
networks	O
networks	O
pages	O
san	O
francisco	O
ieee	O
press	O
paper	O
bengio	O
y	O
simard	O
p	O
and	O
frasconi	O
p	O
learning	O
long-term	O
dependencies	O
with	O
gradient	B
descent	O
is	O
difficult	O
ieee	O
tr	O
neural	O
nets	O
bengio	O
y	O
latendresse	O
s	O
and	O
dugas	O
c	O
gradient-based	O
learning	O
of	O
hyper	O
parameters	O
learning	O
conference	O
snowbird	O
bengio	O
y	O
ducharme	O
r	O
and	O
vincent	O
p	O
a	O
neural	O
probabilistic	O
language	O
model	O
pages	O
mit	O
nips	O
in	O
t	O
k	O
leen	O
t	O
g	O
dietterich	O
and	O
v	O
tresp	O
editors	O
press	O
bengio	O
y	O
ducharme	O
r	O
vincent	O
p	O
and	O
jauvin	O
c	O
a	O
neural	O
probabilistic	O
language	O
model	O
jmlr	O
bengio	O
y	O
le	O
roux	O
n	O
vincent	O
p	O
delalleau	O
o	O
and	O
marcotte	O
p	O
convex	O
neural	O
networks	O
in	O
nips	O
pages	O
bengio	O
y	O
delalleau	O
o	O
and	O
le	O
roux	O
n	O
the	O
curse	O
of	O
highly	O
variable	O
functions	O
for	O
local	O
kernel	O
machines	O
in	O
nips	O
bibliography	O
bengio	O
y	O
larochelle	O
h	O
and	O
vincent	O
p	O
non-local	O
manifold	B
parzen	O
windows	O
in	O
nips	O
mit	O
press	O
bengio	O
y	O
lamblin	O
p	O
popovici	O
d	O
and	O
larochelle	O
h	O
greedy	O
layer-wise	O
training	O
of	O
deep	O
networks	O
in	O
nips	O
bengio	O
y	O
louradour	O
j	O
collobert	O
r	O
and	O
weston	O
j	O
curriculum	B
learning	I
in	O
icml	O
bengio	O
y	O
mesnil	O
g	O
dauphin	O
y	O
and	O
rifai	O
s	O
better	O
mixing	O
via	O
deep	O
representations	O
in	O
icml	O
bengio	O
y	O
l	O
onard	O
n	O
and	O
courville	O
a	O
estimating	O
or	O
propagating	O
gradients	O
through	O
stochastic	O
neurons	O
for	O
conditional	O
computation	O
bengio	O
y	O
yao	O
l	O
alain	O
g	O
and	O
vincent	O
p	O
generalized	O
denoising	O
auto	O
encoders	O
as	O
generative	O
models	O
in	O
nips	O
bengio	O
y	O
courville	O
a	O
and	O
vincent	O
p	O
representation	B
learning	I
a	O
review	O
and	O
new	O
perspectives	O
ieee	O
trans	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
bengio	O
y	O
thibodeau-laufer	O
e	O
alain	O
g	O
and	O
yosinski	O
j	O
deep	O
generative	O
stochastic	O
networks	O
trainable	O
by	O
backprop	O
in	O
icml	O
bennett	O
c	O
efficient	O
estimation	O
of	O
free	O
energy	O
differences	O
from	O
monte	O
carlo	O
data	O
journal	O
of	O
computational	O
physics	O
bennett	O
j	O
and	O
lanning	O
s	O
the	O
netflix	O
prize	O
berger	O
a	O
l	O
della	O
pietra	O
v	O
j	O
and	O
della	O
pietra	O
s	O
a	O
a	O
maximum	O
entropy	O
approach	O
to	O
natural	B
language	I
processing	I
computational	O
linguistics	O
berglund	O
m	O
and	O
raiko	O
t	O
stochastic	O
gradient	B
estimate	O
variance	O
in	O
contrastive	O
divergence	O
and	O
persistent	O
contrastive	O
divergence	O
corr	O
bergstra	O
j	O
incorporating	O
complex	O
cells	O
into	O
neural	O
networks	O
for	O
pattern	O
classification	B
ph	O
d	O
thesis	O
universit	O
de	O
montr	O
al	O
bergstra	O
j	O
and	O
bengio	O
y	O
slow	O
decorrelated	O
features	O
for	O
pretraining	O
complex	O
cell-like	O
networks	O
in	O
nips	O
bergstra	O
j	O
and	O
bengio	O
y	O
random	B
search	I
for	O
hyper-parameter	O
optimization	O
j	O
machine	B
learning	I
res	O
bergstra	O
j	O
breuleux	O
o	O
bastien	O
f	O
lamblin	O
p	O
pascanu	O
r	O
desjardins	O
g	O
turian	O
j	O
warde-farley	O
d	O
and	O
bengio	O
y	O
theano	O
a	O
cpu	O
and	O
gpu	O
math	O
expression	O
compiler	O
in	O
proc	O
scipy	O
bibliography	O
bergstra	O
j	O
bardenet	O
r	O
bengio	O
y	O
and	O
k	O
gl	O
b	O
algorithms	O
for	O
hyper-parameter	O
optimization	O
in	O
nips	O
berkes	O
p	O
and	O
wiskott	O
l	O
slow	B
feature	B
analysis	I
yields	O
a	O
rich	O
repertoire	O
of	O
complex	B
cell	I
properties	O
journal	O
of	O
vision	O
bertsekas	O
d	O
p	O
and	O
tsitsiklis	O
j	O
neuro-dynamic	O
programming	O
athena	O
scientific	O
besag	O
j	O
statistical	O
analysis	O
of	O
non-lattice	O
data	O
the	O
statistician	O
bishop	O
c	O
m	O
mixture	B
density	I
networks	I
bishop	O
c	O
m	O
regularization	O
and	O
complexity	O
control	O
in	O
feed-forward	O
networks	O
in	O
proceedings	O
international	O
conference	O
on	O
artificial	O
neural	O
networks	O
icann	O
volume	O
page	O
bishop	O
c	O
m	O
training	O
with	O
noise	O
is	O
equivalent	O
to	O
tikhonov	O
regularization	O
neural	O
computation	O
bishop	O
c	O
m	O
pattern	O
recognition	O
and	O
machine	B
learning	I
springer	O
blum	O
a	O
l	O
and	O
rivest	O
r	O
l	O
training	O
a	O
neural	B
network	I
is	O
np-complete	O
blumer	O
a	O
ehrenfeucht	O
a	O
haussler	O
d	O
and	O
warmuth	O
m	O
k	O
learnability	O
and	O
the	O
vapnik	O
chervonenkis	O
dimension	O
journal	O
of	O
the	O
acm	O
bonnet	O
g	O
transformations	O
des	O
signaux	O
al	O
atoires	O
travers	O
les	O
syst	O
mes	O
non	O
lin	O
aires	O
sans	O
m	O
moire	O
annales	O
des	O
t	O
l	O
communications	O
bordes	O
a	O
weston	O
j	O
collobert	O
r	O
and	O
bengio	O
y	O
learning	O
structured	O
embeddings	O
of	O
knowledge	O
bases	O
in	O
aaai	O
bordes	O
a	O
glorot	O
x	O
weston	O
j	O
and	O
bengio	O
y	O
joint	O
learning	O
of	O
words	O
and	O
meaning	O
representations	O
for	O
open-text	O
semantic	O
parsing	O
aistats	O
bordes	O
a	O
glorot	O
x	O
weston	O
j	O
and	O
bengio	O
y	O
a	O
semantic	O
matching	O
energy	B
function	I
for	O
learning	O
with	O
multi-relational	O
data	O
machine	B
learning	I
special	O
issue	O
on	O
learning	O
semantics	O
bordes	O
a	O
usunier	O
n	O
garcia-duran	O
a	O
weston	O
j	O
and	O
yakhnenko	O
o	O
translating	O
embeddings	O
for	O
modeling	O
multi-relational	O
data	O
in	O
c	O
burges	O
l	O
bottou	O
m	O
welling	O
z	O
ghahramani	O
and	O
k	O
weinberger	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
curran	O
associates	O
inc	O
bornschein	O
j	O
and	O
bengio	O
y	O
reweighted	O
wake-sleep	O
in	O
iclr	O
bibliography	O
bornschein	O
j	O
shabanian	O
s	O
fischer	O
a	O
and	O
bengio	O
y	O
training	O
bidirectional	O
helmholtz	O
machines	O
technical	O
report	O
boser	O
b	O
e	O
guyon	O
i	O
m	O
and	O
vapnik	O
v	O
n	O
a	O
training	O
algorithm	O
for	O
optimal	O
margin	O
classifiers	O
in	O
colt	O
proceedings	O
of	O
the	O
fifth	O
annual	O
workshop	O
on	O
computational	O
learning	O
theory	O
pages	O
new	O
york	O
ny	O
usa	O
acm	O
bottou	O
l	O
online	O
algorithms	O
and	O
stochastic	O
approximations	O
in	O
d	O
saad	O
editor	O
online	O
learning	O
in	O
neural	O
networks	O
cambridge	O
university	O
press	O
cambridge	O
uk	O
bottou	O
l	O
from	O
machine	B
learning	I
to	O
machine	O
reasoning	O
technical	O
report	O
bottou	O
l	O
multilayer	O
neural	O
networks	O
deep	O
learning	O
summer	O
school	O
bottou	O
l	O
and	O
bousquet	O
o	O
the	O
tradeoffs	O
of	O
large	O
scale	O
learning	O
in	O
nips	O
boulanger-lewandowski	O
n	O
bengio	O
y	O
and	O
vincent	O
p	O
modeling	O
temporal	O
dependencies	O
in	O
high-dimensional	O
sequences	O
application	O
to	O
polyphonic	O
music	O
generation	O
and	O
transcription	B
in	O
icml	O
boureau	O
y	O
ponce	O
j	O
and	O
lecun	O
y	O
a	O
theoretical	O
analysis	O
of	O
feature	B
pooling	O
in	O
vision	O
algorithms	O
in	O
proc	O
international	O
conference	O
on	O
machine	B
learning	I
boureau	O
y	O
le	O
roux	O
n	O
bach	O
f	O
ponce	O
j	O
and	O
lecun	O
y	O
ask	O
the	O
locals	O
multi-way	O
local	O
pooling	O
for	O
image	O
recognition	O
in	O
proc	O
international	O
conference	O
on	O
computer	B
vision	I
ieee	O
bourlard	O
h	O
and	O
kamp	O
y	O
auto-association	O
by	O
multilayer	O
perceptrons	O
and	O
singular	B
value	I
decomposition	O
biological	O
cybernetics	O
bourlard	O
h	O
and	O
wellekens	O
c	O
speech	O
pattern	O
discrimination	O
and	O
multi-layered	O
perceptrons	O
computer	O
speech	O
and	O
language	O
boyd	O
s	O
and	O
vandenberghe	O
l	O
convex	B
optimization	I
cambridge	O
university	O
press	O
new	O
york	O
ny	O
usa	O
brady	O
m	O
l	O
raghavan	O
r	O
and	O
slawny	O
j	O
back-propagation	B
fails	O
to	O
separate	O
where	O
perceptrons	O
succeed	O
ieee	O
transactions	O
on	O
circuits	O
and	O
systems	O
brakel	O
p	O
stroobandt	O
d	O
and	O
schrauwen	O
b	O
training	O
energy-based	O
models	O
for	O
time-series	O
imputation	O
journal	O
of	O
machine	B
learning	I
research	O
brand	O
m	O
charting	O
a	O
manifold	B
in	O
nips	O
pages	O
mit	O
press	O
bibliography	O
breiman	O
l	O
bagging	B
predictors	O
machine	B
learning	I
breiman	O
l	O
friedman	O
j	O
h	O
olshen	O
r	O
a	O
and	O
stone	O
c	O
j	O
classification	B
and	O
regression	B
trees	O
wadsworth	O
international	O
group	O
belmont	O
ca	O
bridle	O
j	O
s	O
alphanets	O
a	O
recurrent	B
neural	B
network	I
architecture	O
with	O
a	O
hidden	O
markov	O
model	O
interpretation	O
speech	O
communication	O
briggman	O
k	O
denk	O
w	O
seung	O
s	O
helmstaedter	O
m	O
n	O
and	O
turaga	O
s	O
c	O
maximin	O
affinity	O
learning	O
of	O
image	O
segmentation	O
in	O
pages	O
nips	O
brown	O
p	O
f	O
cocke	O
j	O
pietra	O
s	O
a	O
d	O
pietra	O
v	O
j	O
d	O
jelinek	O
f	O
lafferty	O
j	O
d	O
mercer	O
r	O
l	O
and	O
roossin	O
p	O
s	O
a	O
statistical	O
approach	O
to	O
machine	B
translation	I
computational	O
linguistics	O
brown	O
p	O
f	O
pietra	O
v	O
j	O
d	O
desouza	O
p	O
v	O
lai	O
j	O
c	O
and	O
mercer	O
r	O
l	O
classcomputational	O
linguistics	O
n	O
based	O
models	O
of	O
natural	O
language	O
bryson	O
a	O
and	O
ho	O
y	O
applied	O
optimal	O
control	O
optimization	O
estimation	O
and	O
control	O
blaisdell	O
pub	O
co	O
bryson	O
jr	O
a	O
e	O
and	O
denham	O
w	O
f	O
a	O
steepest-ascent	O
method	O
for	O
solving	O
optimum	O
programming	O
problems	O
technical	O
report	O
raytheon	O
company	O
missle	O
and	O
space	O
division	O
bucilu	O
a	O
c	O
caruana	O
r	O
and	O
niculescu-mizil	O
a	O
model	B
compression	I
in	O
proceedings	O
of	O
the	O
acm	O
sigkdd	O
international	O
conference	O
on	O
knowledge	O
discovery	O
and	O
data	O
mining	O
pages	O
acm	O
burda	O
y	O
grosse	O
r	O
and	O
salakhutdinov	O
r	O
importance	O
weighted	O
autoencoders	O
arxiv	O
preprint	O
cai	O
m	O
shi	O
y	O
and	O
liu	O
j	O
deep	O
maxout	O
neural	O
networks	O
for	O
speech	O
recognition	O
in	O
automatic	B
speech	I
recognition	I
and	O
understanding	O
ieee	O
workshop	O
on	O
pages	O
ieee	O
carreira-perpi	O
an	O
m	O
a	O
and	O
hinton	O
g	O
e	O
on	O
contrastive	O
divergence	O
learning	O
in	O
r	O
g	O
cowell	O
and	O
z	O
ghahramani	O
editors	O
proceedings	O
of	O
the	O
tenth	O
international	O
workshop	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
pages	O
society	O
for	O
artificial	B
intelligence	I
and	O
statistics	O
caruana	O
r	O
multitask	O
connectionist	O
learning	O
in	O
proc	O
connectionist	O
models	O
summer	O
school	O
pages	O
cauchy	O
a	O
m	O
thode	O
g	O
n	O
rale	O
pour	O
la	O
r	O
solution	O
de	O
syst	O
mes	O
d	O
quations	O
tan	O
es	O
in	O
compte	O
rendu	O
des	O
s	O
ances	O
de	O
l	O
acad	O
mie	O
des	O
sciences	O
pages	O
bibliography	O
cayton	O
l	O
algorithms	O
for	O
manifold	B
learning	I
technical	O
report	O
ucsd	O
chandola	O
v	O
banerjee	O
a	O
and	O
kumar	O
v	O
anomaly	O
detection	O
a	O
survey	O
acm	O
computing	O
surveys	O
chapelle	O
o	O
weston	O
j	O
and	O
sch	O
lkopf	O
b	O
cluster	O
kernels	O
for	O
semi-supervised	B
learning	I
in	O
s	O
becker	O
s	O
thrun	O
and	O
k	O
obermayer	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
cambridge	O
ma	O
mit	O
press	O
chapelle	O
o	O
sch	O
lkopf	O
b	O
and	O
zien	O
a	O
editors	O
semi-supervised	B
learning	I
mit	O
press	O
cambridge	O
ma	O
chellapilla	O
k	O
puri	O
s	O
and	O
simard	O
p	O
high	O
performance	O
convolutional	O
neural	O
in	O
guy	O
lorette	O
editor	O
tenth	O
international	O
networks	O
for	O
document	O
processing	O
workshop	O
on	O
frontiers	O
in	O
handwriting	O
recognition	O
la	O
baule	O
universit	O
de	O
rennes	O
suvisoft	O
httpwww	O
suvisoft	O
com	O
chen	O
b	O
ting	O
j	O
-a	O
marlin	O
b	O
m	O
and	O
de	O
freitas	O
n	O
deep	O
learning	O
of	O
invariant	O
spatio-temporal	O
features	O
from	O
video	O
deep	O
learning	O
and	O
unsupervised	O
feature	B
learning	O
workshop	O
chen	O
s	O
f	O
and	O
goodman	O
j	O
t	O
an	O
empirical	O
study	O
of	O
smoothing	O
techniques	O
for	O
language	O
modeling	O
computer	O
speech	O
and	O
language	O
chen	O
t	O
du	O
z	O
sun	O
n	O
wang	O
j	O
wu	O
c	O
chen	O
y	O
and	O
temam	O
o	O
diannao	O
a	O
small-footprint	O
high-throughput	O
accelerator	O
for	O
ubiquitous	O
machine-learning	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
architectural	O
support	O
for	O
programming	O
languages	O
and	O
operating	O
systems	O
pages	O
acm	O
chen	O
t	O
li	O
m	O
li	O
y	O
lin	O
m	O
wang	O
n	O
wang	O
m	O
xiao	O
t	O
xu	O
b	O
zhang	O
c	O
and	O
zhang	O
z	O
mxnet	O
a	O
flexible	O
and	O
efficient	O
machine	B
learning	I
library	O
for	O
heterogeneous	O
distributed	O
systems	O
arxiv	O
preprint	O
dadiannao	O
a	O
machine-learning	O
supercomputer	O
in	O
chen	O
y	O
luo	O
t	O
liu	O
s	O
zhang	O
s	O
he	O
l	O
wang	O
j	O
li	O
l	O
chen	O
t	O
xu	O
z	O
sun	O
n	O
et	O
al	O
microarchitecture	O
annual	O
ieeeacm	O
international	O
symposium	O
on	O
pages	O
ieee	O
chilimbi	O
t	O
suzue	O
y	O
apacible	O
j	O
and	O
kalyanaraman	O
k	O
project	O
adam	O
building	O
an	O
efficient	O
and	O
scalable	O
deep	O
learning	O
training	O
system	O
in	O
usenix	O
symposium	O
on	O
operating	O
systems	O
design	O
and	O
implementation	O
cho	O
k	O
raiko	O
t	O
and	O
ilin	O
a	O
parallel	O
tempering	B
is	O
efficient	O
for	O
learning	O
restricted	O
boltzmann	O
machines	O
in	O
ijcnn	O
bibliography	O
cho	O
k	O
raiko	O
t	O
and	O
ilin	O
a	O
enhanced	O
gradient	B
and	O
adaptive	O
learning	B
rate	I
for	O
training	O
restricted	O
boltzmann	O
machines	O
in	O
icml	O
pages	O
cho	O
k	O
van	O
merri	O
nboer	O
b	O
gulcehre	O
c	O
bougares	O
f	O
schwenk	O
h	O
and	O
bengio	O
y	O
learning	O
phrase	O
representations	O
using	O
rnn	O
encoder-decoder	O
for	O
statistical	O
machine	B
translation	I
in	O
proceedings	O
of	O
the	O
empiricial	O
methods	O
in	O
natural	B
language	I
processing	I
cho	O
k	O
van	O
merri	O
nboer	O
b	O
bahdanau	O
d	O
and	O
bengio	O
y	O
on	O
the	O
prop	O
arxiv	O
e-prints	O
erties	O
of	O
neural	O
machine	B
translation	I
encoder-decoder	O
approaches	O
choromanska	O
a	O
henaff	O
m	O
mathieu	O
m	O
arous	O
g	O
b	O
and	O
lecun	O
y	O
the	O
loss	O
surface	O
of	O
multilayer	O
networks	O
chorowski	O
j	O
bahdanau	O
d	O
cho	O
k	O
and	O
bengio	O
y	O
end-to-end	O
continuous	O
speech	O
recognition	O
using	O
attention-based	O
recurrent	O
nn	O
first	O
results	O
christianson	O
b	O
automatic	O
hessians	O
by	O
reverse	O
accumulation	O
ima	O
journal	O
of	O
numerical	O
analysis	O
chrupala	O
g	O
kadar	O
a	O
and	O
alishahi	O
a	O
learning	O
language	O
through	O
pictures	O
arxiv	O
chung	O
j	O
gulcehre	O
c	O
cho	O
k	O
and	O
bengio	O
y	O
empirical	O
evaluation	O
of	O
gated	O
recurrent	O
neural	O
networks	O
on	O
sequence	O
modeling	O
nips	O
deep	O
learning	O
workshop	O
arxiv	O
chung	O
j	O
g	O
l	O
ehre	O
cho	O
k	O
and	O
bengio	O
y	O
gated	O
feedback	O
recurrent	O
neural	O
networks	O
in	O
icml	O
chung	O
j	O
kastner	O
k	O
dinh	O
l	O
goel	O
k	O
courville	O
a	O
and	O
bengio	O
y	O
a	O
recurrent	O
latent	B
variable	I
model	O
for	O
sequential	O
data	O
in	O
nips	O
ciresan	O
d	O
meier	O
u	O
masci	O
j	O
and	O
schmidhuber	O
j	O
multi-column	O
deep	O
neural	B
network	I
for	O
traffic	O
sign	O
classification	B
neural	O
networks	O
ciresan	O
d	O
c	O
meier	O
u	O
gambardella	O
l	O
m	O
and	O
schmidhuber	O
j	O
deep	O
big	O
simple	O
neural	O
nets	O
for	O
handwritten	O
digit	O
recognition	O
neural	O
computation	O
coates	O
a	O
and	O
ng	O
a	O
y	O
the	O
importance	O
of	O
encoding	O
versus	O
training	O
with	O
sparse	O
coding	O
and	O
vector	O
quantization	O
in	O
icml	O
coates	O
a	O
lee	O
h	O
and	O
ng	O
a	O
y	O
an	O
analysis	O
of	O
single-layer	O
networks	O
in	O
unsupervised	O
feature	B
learning	O
in	O
proceedings	O
of	O
the	O
thirteenth	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
bibliography	O
coates	O
a	O
huval	O
b	O
wang	O
t	O
wu	O
d	O
catanzaro	O
b	O
and	O
andrew	O
n	O
deep	O
learning	O
with	O
cots	O
hpc	O
systems	O
in	O
s	O
dasgupta	O
and	O
d	O
mcallester	O
editors	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
machine	B
learning	I
volume	O
pages	O
jmlr	O
workshop	O
and	O
conference	O
proceedings	O
cohen	O
n	O
sharir	O
o	O
and	O
shashua	O
a	O
on	O
the	O
expressive	O
power	O
of	O
deep	O
learning	O
a	O
tensor	O
analysis	O
collobert	O
r	O
large	O
scale	O
machine	B
learning	I
ph	O
d	O
thesis	O
universit	O
de	O
paris	O
vi	O
collobert	O
r	O
deep	O
learning	O
for	O
efficient	O
discriminative	O
parsing	O
in	O
aistats	O
collobert	O
r	O
and	O
weston	O
j	O
a	O
unified	O
architecture	O
for	O
natural	B
language	I
processing	I
deep	O
neural	O
networks	O
with	O
multitask	O
learning	O
in	O
icml	O
collobert	O
r	O
and	O
weston	O
j	O
a	O
unified	O
architecture	O
for	O
natural	B
language	I
processing	I
deep	O
neural	O
networks	O
with	O
multitask	O
learning	O
in	O
icml	O
collobert	O
r	O
bengio	O
s	O
and	O
bengio	O
y	O
a	O
parallel	O
mixture	O
of	O
svms	O
for	O
very	O
large	O
scale	O
problems	O
technical	O
report	O
idiap	O
collobert	O
r	O
bengio	O
s	O
and	O
bengio	O
y	O
parallel	O
mixture	O
of	O
svms	O
for	O
very	O
large	O
scale	O
problems	O
neural	O
computation	O
collobert	O
r	O
weston	O
j	O
bottou	O
l	O
karlen	O
m	O
kavukcuoglu	O
k	O
and	O
kuksa	O
p	O
natural	B
language	I
processing	I
from	O
scratch	O
the	O
journal	O
of	O
machine	B
learning	I
research	O
collobert	O
r	O
kavukcuoglu	O
k	O
and	O
farabet	O
c	O
a	O
matlab-like	O
environ	O
ment	O
for	O
machine	B
learning	I
in	O
biglearn	O
nips	O
workshop	O
comon	O
p	O
independent	B
component	I
analysis	I
a	O
new	O
concept	O
signal	O
processing	O
cortes	O
c	O
and	O
vapnik	O
v	O
support	O
vector	O
networks	O
machine	B
learning	I
couprie	O
c	O
farabet	O
c	O
najman	O
l	O
and	O
lecun	O
y	O
indoor	O
semantic	O
segmentation	O
using	O
depth	O
information	O
in	O
international	O
conference	O
on	O
learning	O
representations	O
courbariaux	O
m	O
bengio	O
y	O
and	O
david	O
j	O
-p	O
low	O
precision	B
arithmetic	O
for	O
deep	O
learning	O
in	O
iclr	O
workshop	O
courville	O
a	O
bergstra	O
j	O
and	O
bengio	O
y	O
unsupervised	O
models	O
of	O
images	O
by	O
spike-and-slab	O
rbms	O
in	O
icml	O
bibliography	O
courville	O
a	O
desjardins	O
g	O
bergstra	O
j	O
and	O
bengio	O
y	O
the	O
spike-and-slab	O
rbm	O
and	O
extensions	O
to	O
discrete	O
and	O
sparse	O
data	O
distributions	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
ieee	O
transactions	O
on	O
cover	O
t	O
m	O
and	O
thomas	O
j	O
a	O
elements	O
of	O
information	O
theory	O
edition	O
wiley-interscience	O
cox	O
d	O
and	O
pinto	O
n	O
beyond	O
simple	O
features	O
a	O
large-scale	O
feature	B
search	O
approach	O
to	O
unconstrained	O
face	O
recognition	O
in	O
automatic	O
face	O
gesture	O
recognition	O
and	O
workshops	O
ieee	O
international	O
conference	O
on	O
pages	O
ieee	O
cram	O
r	O
h	O
mathematical	O
methods	O
of	O
statistics	O
princeton	O
university	O
press	O
crick	O
f	O
h	O
c	O
and	O
mitchison	O
g	O
the	O
function	O
of	O
dream	O
sleep	O
nature	O
cybenko	O
g	O
approximation	O
by	O
superpositions	O
of	O
a	O
sigmoidal	O
function	O
mathematics	O
of	O
control	O
signals	O
and	O
systems	O
dahl	O
g	O
e	O
ranzato	O
m	O
mohamed	O
a	O
and	O
hinton	O
g	O
e	O
phone	O
recognition	O
with	O
the	O
mean-covariance	O
restricted	O
boltzmann	O
machine	O
in	O
nips	O
dahl	O
g	O
e	O
yu	O
d	O
deng	O
l	O
and	O
acero	O
a	O
context-dependent	O
pre-trained	O
deep	O
neural	O
networks	O
for	O
large	O
vocabulary	O
speech	O
recognition	O
ieee	O
transactions	O
on	O
audio	O
speech	O
and	O
language	O
processing	O
dahl	O
g	O
e	O
sainath	O
t	O
n	O
and	O
hinton	O
g	O
e	O
improving	O
deep	O
neural	O
networks	O
for	O
lvcsr	O
using	O
rectified	O
linear	O
units	O
and	O
dropout	O
in	O
icassp	O
dahl	O
g	O
e	O
jaitly	O
n	O
and	O
salakhutdinov	O
r	O
multi-task	O
neural	O
networks	O
for	O
qsar	O
predictions	O
dauphin	O
y	O
and	O
bengio	O
y	O
stochastic	O
ratio	B
matching	I
of	O
rbms	O
for	O
sparse	O
high-dimensional	O
inputs	O
in	O
nips	O
foundation	O
dauphin	O
y	O
glorot	O
x	O
and	O
bengio	O
y	O
large-scale	O
learning	O
of	O
embeddings	O
with	O
reconstruction	O
sampling	O
in	O
icml	O
dauphin	O
y	O
pascanu	O
r	O
gulcehre	O
c	O
cho	O
k	O
ganguli	O
s	O
and	O
bengio	O
y	O
identifying	O
and	O
attacking	O
the	O
saddle	O
point	O
problem	O
in	O
high-dimensional	O
non-convex	O
optimization	O
in	O
nips	O
davis	O
a	O
rubinstein	O
m	O
wadhwa	O
n	O
mysore	O
g	O
durand	O
f	O
and	O
freeman	O
w	O
t	O
the	O
visual	O
microphone	O
passive	O
recovery	O
of	O
sound	O
from	O
video	O
acm	O
transactions	O
on	O
graphics	O
siggraph	O
bibliography	O
dayan	O
p	O
reinforcement	O
comparison	O
in	O
connectionist	O
models	O
proceedings	O
of	O
the	O
connectionist	O
summer	O
school	O
san	O
mateo	O
ca	O
dayan	O
p	O
and	O
hinton	O
g	O
e	O
varieties	O
of	O
helmholtz	O
machine	O
neural	O
networks	O
dayan	O
p	O
hinton	O
g	O
e	O
neal	O
r	O
m	O
and	O
zemel	O
r	O
s	O
the	O
helmholtz	O
machine	O
neural	O
computation	O
dean	O
j	O
corrado	O
g	O
monga	O
r	O
chen	O
k	O
devin	O
m	O
le	O
q	O
mao	O
m	O
ranzato	O
m	O
senior	O
a	O
tucker	O
p	O
yang	O
k	O
and	O
ng	O
a	O
y	O
large	O
scale	O
distributed	O
deep	O
networks	O
in	O
nips	O
dean	O
t	O
and	O
kanazawa	O
k	O
a	O
model	O
for	O
reasoning	O
about	O
persistence	O
and	O
causation	O
computational	O
intelligence	O
deerwester	O
s	O
dumais	O
s	O
t	O
furnas	O
g	O
w	O
landauer	O
t	O
k	O
and	O
harshman	O
r	O
indexing	O
by	O
latent	O
semantic	O
analysis	O
journal	O
of	O
the	O
american	O
society	O
for	O
information	O
science	O
delalleau	O
o	O
and	O
bengio	O
y	O
shallow	O
vs	O
deep	O
sum-product	O
networks	O
in	O
nips	O
deng	O
j	O
dong	O
w	O
socher	O
r	O
li	O
l	O
-j	O
li	O
k	O
and	O
fei-fei	O
l	O
imagenet	O
a	O
large-scale	O
hierarchical	O
image	O
database	O
in	O
deng	O
j	O
berg	O
a	O
c	O
li	O
k	O
and	O
fei-fei	O
l	O
what	O
does	O
classifying	O
more	O
than	O
image	O
categories	O
tell	O
us	O
in	O
proceedings	O
of	O
the	O
european	O
conference	O
on	O
computer	B
vision	I
part	O
v	O
eccv	O
pages	O
berlin	O
heidelberg	O
springer-verlag	O
deng	O
l	O
and	O
yu	O
d	O
deep	O
learning	O
methods	O
and	O
applications	O
foundations	O
and	O
trends	O
in	O
signal	O
processing	O
deng	O
l	O
seltzer	O
m	O
yu	O
d	O
acero	O
a	O
mohamed	O
a	O
and	O
hinton	O
g	O
binary	O
coding	O
of	O
speech	O
spectrograms	O
using	O
a	O
deep	O
auto-encoder	O
in	O
interspeech	O
makuhari	O
chiba	O
japan	O
denil	O
m	O
bazzani	O
l	O
larochelle	O
h	O
and	O
de	O
freitas	O
n	O
learning	O
where	O
to	O
attend	O
with	O
deep	O
architectures	O
for	O
image	O
tracking	O
neural	O
computation	O
denton	O
e	O
chintala	O
s	O
szlam	O
a	O
and	O
fergus	O
r	O
deep	O
generative	O
image	O
models	O
using	O
a	O
laplacian	O
pyramid	O
of	O
adversarial	O
networks	O
nips	O
desjardins	O
g	O
and	O
bengio	O
y	O
empirical	O
evaluation	O
of	O
convolutional	O
rbms	O
for	O
vision	O
technical	O
report	O
d	O
partement	O
d	O
informatique	O
et	O
de	O
recherche	O
op	O
rationnelle	O
universit	O
de	O
montr	O
al	O
bibliography	O
desjardins	O
g	O
courville	O
a	O
c	O
bengio	O
y	O
vincent	O
p	O
and	O
delalleau	O
o	O
tempered	O
markov	B
chain	I
monte	I
carlo	I
for	O
training	O
of	O
restricted	O
boltzmann	O
machines	O
in	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
pages	O
desjardins	O
g	O
courville	O
a	O
and	O
bengio	O
y	O
on	O
tracking	O
the	O
partition	O
function	O
in	O
nips	O
desjardins	O
g	O
simonyan	O
k	O
pascanu	O
r	O
et	O
al	O
natural	O
neural	O
networks	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
devlin	O
j	O
zbib	O
r	O
huang	O
z	O
lamar	O
t	O
schwartz	O
r	O
and	O
makhoul	O
j	O
fast	O
and	O
robust	O
neural	B
network	I
joint	O
models	O
for	O
statistical	O
machine	B
translation	I
in	O
proc	O
acl	O
devroye	O
l	O
non-uniform	O
random	O
variate	O
generation	O
springerlink	O
b	O
cher	O
springer	O
new	O
york	O
dicarlo	O
j	O
j	O
mechanisms	O
underlying	O
visual	O
object	B
recognition	I
humans	O
vs	O
neurons	O
vs	O
machines	O
nips	O
tutorial	O
dinh	O
l	O
krueger	O
d	O
and	O
bengio	O
y	O
nice	O
non-linear	O
independent	O
components	O
estimation	O
donahue	O
j	O
hendricks	O
l	O
a	O
guadarrama	O
s	O
rohrbach	O
m	O
venugopalan	O
s	O
saenko	O
k	O
and	O
darrell	O
t	O
long-term	O
recurrent	O
convolutional	O
networks	O
for	O
visual	O
recognition	O
and	O
description	O
donoho	O
d	O
l	O
and	O
grimes	O
c	O
hessian	B
eigenmaps	O
new	O
locally	O
linear	O
embedding	B
techniques	O
for	O
high-dimensional	O
data	O
technical	O
report	O
dept	O
statistics	O
stanford	O
university	O
dosovitskiy	O
a	O
springenberg	O
j	O
t	O
and	O
brox	O
t	O
learning	O
to	O
generate	O
chairs	O
with	O
convolutional	O
neural	O
networks	O
in	O
proceedings	O
of	O
the	O
ieee	O
conference	O
on	O
computer	B
vision	I
and	O
pattern	O
recognition	O
pages	O
doya	O
k	O
bifurcations	O
of	O
recurrent	O
neural	O
networks	O
in	O
gradient	B
descent	O
learning	O
ieee	O
transactions	O
on	O
neural	O
networks	O
dreyfus	O
s	O
e	O
the	O
numerical	O
solution	O
of	O
variational	O
problems	O
journal	O
of	O
mathematical	O
analysis	O
and	O
applications	O
dreyfus	O
s	O
e	O
the	O
computational	O
solution	O
of	O
optimal	O
control	O
problems	O
with	O
time	O
lag	O
ieee	O
transactions	O
on	O
automatic	O
control	O
drucker	O
h	O
and	O
lecun	O
y	O
improving	O
generalisation	O
performance	O
using	O
double	O
back-propagation	B
ieee	O
transactions	O
on	O
neural	O
networks	O
bibliography	O
duchi	O
j	O
hazan	O
e	O
and	O
singer	O
y	O
adaptive	O
subgradient	O
methods	O
for	O
online	O
learning	O
and	O
stochastic	O
optimization	O
journal	O
of	O
machine	B
learning	I
research	O
dudik	O
m	O
langford	O
j	O
and	O
li	O
l	O
doubly	O
robust	O
policy	B
evaluation	O
and	O
learning	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
machine	B
learning	I
icml	O
dugas	O
c	O
bengio	O
y	O
b	O
lisle	O
f	O
and	O
nadeau	O
c	O
incorporating	O
second-order	O
functional	O
knowledge	O
for	O
better	O
option	O
pricing	O
in	O
t	O
leen	O
t	O
dietterich	O
and	O
v	O
tresp	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
dziugaite	O
g	O
k	O
roy	O
d	O
m	O
and	O
ghahramani	O
z	O
training	O
generative	O
neural	O
networks	O
via	O
maximum	O
mean	O
discrepancy	O
optimization	O
arxiv	O
preprint	O
el	O
hihi	O
s	O
and	O
bengio	O
y	O
hierarchical	O
recurrent	O
neural	O
networks	O
for	O
long-term	O
dependencies	O
in	O
nips	O
elkahky	O
a	O
m	O
song	O
y	O
and	O
he	O
x	O
a	O
multi-view	O
deep	O
learning	O
approach	O
for	O
cross	O
domain	O
user	O
modeling	O
in	O
recommendation	O
systems	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
world	O
wide	O
web	O
pages	O
elman	O
j	O
l	O
learning	O
and	O
development	O
in	O
neural	O
networks	O
the	O
importance	O
of	O
starting	O
small	O
cognition	O
erhan	O
d	O
manzagol	O
p	O
-a	O
bengio	O
y	O
bengio	O
s	O
and	O
vincent	O
p	O
the	O
difficulty	O
of	O
training	O
deep	O
architectures	O
and	O
the	O
effect	O
of	O
unsupervised	O
pre-training	O
in	O
proceedings	O
of	O
aistats	O
erhan	O
d	O
bengio	O
y	O
courville	O
a	O
manzagol	O
p	O
vincent	O
p	O
and	O
bengio	O
s	O
why	O
does	O
unsupervised	O
pre-training	O
help	O
deep	O
learning	O
j	O
machine	B
learning	I
res	O
fahlman	O
s	O
e	O
hinton	O
g	O
e	O
and	O
sejnowski	O
t	O
j	O
massively	O
parallel	O
architectures	O
in	O
proceedings	O
of	O
the	O
national	O
for	O
ai	O
netl	O
thistle	O
and	O
boltzmann	O
machines	O
conference	O
on	O
artificial	B
intelligence	I
fang	O
h	O
gupta	O
s	O
iandola	O
f	O
srivastava	O
r	O
deng	O
l	O
doll	O
r	O
p	O
gao	O
j	O
he	O
x	O
mitchell	O
m	O
platt	O
j	O
c	O
zitnick	O
c	O
l	O
and	O
zweig	O
g	O
from	O
captions	O
to	O
visual	O
concepts	O
and	O
back	O
farabet	O
c	O
lecun	O
y	O
kavukcuoglu	O
k	O
culurciello	O
e	O
martini	O
b	O
akselrod	O
p	O
and	O
talay	O
s	O
large-scale	O
fpga-based	O
convolutional	O
networks	O
in	O
r	O
bekkerman	O
m	O
bilenko	O
and	O
j	O
langford	O
editors	O
scaling	O
up	O
machine	B
learning	I
parallel	O
and	O
distributed	O
approaches	O
cambridge	O
university	O
press	O
bibliography	O
farabet	O
c	O
couprie	O
c	O
najman	O
l	O
and	O
lecun	O
y	O
learning	O
hierarchical	O
features	O
for	O
scene	O
labeling	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
fei-fei	O
l	O
fergus	O
r	O
and	O
perona	O
p	O
one-shot	B
learning	I
of	O
object	O
categories	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
finn	O
c	O
tan	O
x	O
y	O
duan	O
y	O
darrell	O
t	O
levine	O
s	O
and	O
abbeel	O
p	O
learning	O
visual	O
feature	B
spaces	O
for	O
robotic	O
manipulation	O
with	O
deep	O
spatial	O
autoencoders	O
arxiv	O
preprint	O
fisher	O
r	O
a	O
the	O
use	O
of	O
multiple	O
measurements	O
in	O
taxonomic	O
problems	O
annals	O
of	O
eugenics	O
f	O
ldi	O
k	O
p	O
adaptive	O
network	O
for	O
optimal	O
linear	O
feature	B
extraction	O
in	O
international	O
joint	O
conference	O
on	O
neural	O
networks	O
volume	O
pages	O
washington	O
ieee	O
new	O
york	O
franzius	O
m	O
sprekeler	O
h	O
and	O
wiskott	O
l	O
slowness	O
and	O
sparseness	O
lead	O
to	O
place	O
head-direction	O
and	O
spatial-view	O
cells	O
franzius	O
m	O
wilbert	O
n	O
and	O
wiskott	O
l	O
invariant	O
object	B
recognition	I
with	O
slow	B
feature	B
analysis	I
in	O
artificial	O
neural	O
networks-icann	O
pages	O
springer	O
frasconi	O
p	O
gori	O
m	O
and	O
sperduti	O
a	O
on	O
the	O
efficient	O
classification	B
of	O
data	O
structures	O
by	O
neural	O
networks	O
in	O
proc	O
int	O
joint	O
conf	O
on	O
artificial	B
intelligence	I
frasconi	O
p	O
gori	O
m	O
and	O
sperduti	O
a	O
a	O
general	O
framework	O
for	O
adaptive	O
processing	O
of	O
data	O
structures	O
ieee	O
transactions	O
on	O
neural	O
networks	O
freund	O
y	O
and	O
schapire	O
r	O
e	O
experiments	O
with	O
a	O
new	O
boosting	O
algorithm	O
in	O
machine	B
learning	I
proceedings	O
of	O
thirteenth	O
international	O
conference	O
pages	O
usa	O
acm	O
freund	O
y	O
and	O
schapire	O
r	O
e	O
game	O
theory	O
on-line	O
prediction	O
and	O
boosting	O
in	O
proceedings	O
of	O
the	O
ninth	O
annual	O
conference	O
on	O
computational	O
learning	O
theory	O
pages	O
frey	O
b	O
j	O
graphical	O
models	O
for	O
machine	B
learning	I
and	O
digital	O
communication	O
mit	O
press	O
frey	O
b	O
j	O
hinton	O
g	O
e	O
and	O
dayan	O
p	O
does	O
the	O
wake-sleep	O
algorithm	O
learn	O
good	O
density	O
estimators	O
in	O
d	O
touretzky	O
m	O
mozer	O
and	O
m	O
hasselmo	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
cambridge	O
ma	O
bibliography	O
frobenius	O
g	O
ber	O
matrizen	O
aus	O
positiven	O
elementen	O
s	O
b	O
preuss	O
akad	O
wiss	O
berlin	O
germany	O
fukushima	O
k	O
cognitron	O
a	O
self-organizing	O
multilayered	O
neural	B
network	I
biological	O
cybernetics	O
fukushima	O
k	O
neocognitron	O
a	O
self-organizing	O
neural	B
network	I
model	O
for	O
a	O
mechanism	O
of	O
pattern	O
recognition	O
unaffected	O
by	O
shift	O
in	O
position	O
biological	O
cybernetics	O
gal	O
y	O
and	O
ghahramani	O
z	O
bayesian	O
convolutional	O
neural	O
networks	O
with	O
bernoulli	O
approximate	O
variational	O
inference	O
arxiv	O
preprint	O
gallinari	O
p	O
lecun	O
y	O
thiria	O
s	O
and	O
fogelman-soulie	O
f	O
memoires	O
associatives	O
distribuees	O
in	O
proceedings	O
of	O
cognitiva	O
paris	O
la	O
villette	O
garcia-duran	O
a	O
bordes	O
a	O
usunier	O
n	O
and	O
grandvalet	O
y	O
combining	O
two	O
and	O
three-way	O
embeddings	O
models	O
for	O
link	B
prediction	I
in	O
knowledge	O
bases	O
arxiv	O
preprint	O
garofolo	O
j	O
s	O
lamel	O
l	O
f	O
fisher	O
w	O
m	O
fiscus	O
j	O
g	O
and	O
pallett	O
d	O
s	O
darpa	O
timit	O
acoustic-phonetic	O
continous	O
speech	O
corpus	O
cd-rom	O
nist	O
speech	O
disc	O
nasa	O
stirecon	O
technical	O
report	O
n	O
garson	O
j	O
the	O
metric	O
system	O
of	O
identification	O
of	O
criminals	O
as	O
used	O
in	O
great	O
britain	O
and	O
ireland	O
the	O
journal	O
of	O
the	O
anthropological	O
institute	O
of	O
great	O
britain	O
and	O
ireland	O
gers	O
f	O
a	O
schmidhuber	O
j	O
and	O
cummins	O
f	O
learning	O
to	O
forget	O
continual	O
prediction	O
with	O
lstm	O
neural	O
computation	O
ghahramani	O
z	O
and	O
hinton	O
g	O
e	O
the	O
em	O
algorithm	O
for	O
mixtures	O
of	O
factor	O
analyzers	O
technical	O
report	O
dpt	O
of	O
comp	O
sci	O
univ	O
of	O
toronto	O
gillick	O
d	O
brunk	O
c	O
vinyals	O
o	O
and	O
subramanya	O
a	O
multilingual	O
language	O
processing	O
from	O
bytes	O
arxiv	O
preprint	O
girshick	O
r	O
donahue	O
j	O
darrell	O
t	O
and	O
malik	O
j	O
region-based	O
convolutional	O
networks	O
for	O
accurate	O
object	B
detection	I
and	O
segmentation	O
giudice	O
m	O
d	O
manera	O
v	O
and	O
keysers	O
c	O
programmed	O
to	O
learn	O
the	O
ontogeny	O
of	O
mirror	O
neurons	O
dev	O
sci	O
glorot	O
x	O
and	O
bengio	O
y	O
understanding	O
the	O
difficulty	O
of	O
training	O
deep	O
feedforward	O
neural	O
networks	O
in	O
aistats	O
glorot	O
x	O
bordes	O
a	O
and	O
bengio	O
y	O
deep	O
sparse	O
rectifier	O
neural	O
networks	O
in	O
aistats	O
bibliography	O
glorot	O
x	O
bordes	O
a	O
and	O
bengio	O
y	O
domain	B
adaptation	I
for	O
large-scale	O
sentiment	O
classification	B
a	O
deep	O
learning	O
approach	O
in	O
icml	O
goldberger	O
j	O
roweis	O
s	O
hinton	O
g	O
e	O
and	O
salakhutdinov	O
r	O
neighbourhood	O
components	O
analysis	O
in	O
l	O
saul	O
y	O
weiss	O
and	O
l	O
bottou	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
mit	O
press	O
gong	O
s	O
mckenna	O
s	O
and	O
psarrou	O
a	O
dynamic	O
vision	O
from	O
images	O
to	O
face	O
recognition	O
imperial	O
college	O
press	O
goodfellow	O
i	O
le	O
q	O
saxe	O
a	O
and	O
ng	O
a	O
measuring	O
invariances	O
in	O
deep	O
networks	O
in	O
nips	O
pages	O
goodfellow	O
i	O
koenig	O
n	O
muja	O
m	O
pantofaru	O
c	O
sorokin	O
a	O
and	O
takayama	O
l	O
help	O
me	O
help	O
you	O
interfaces	O
for	O
personal	O
robots	O
in	O
proc	O
of	O
human	O
robot	O
interaction	O
osaka	O
japan	O
acm	O
press	O
acm	O
press	O
goodfellow	O
i	O
j	O
technical	O
report	O
multidimensional	O
downsampled	O
convolution	O
for	O
autoencoders	O
technical	O
report	O
universit	O
de	O
montr	O
al	O
goodfellow	O
i	O
j	O
on	O
distinguishability	O
criteria	O
for	O
estimating	O
generative	O
models	O
in	O
international	O
conference	O
on	O
learning	O
representations	O
workshops	O
track	O
goodfellow	O
i	O
j	O
courville	O
a	O
and	O
bengio	O
y	O
spike-and-slab	O
sparse	O
coding	O
in	O
nips	O
workshop	O
on	O
challenges	O
in	O
learning	O
for	O
unsupervised	O
feature	B
discovery	O
hierarchical	O
models	O
goodfellow	O
i	O
j	O
warde-farley	O
d	O
mirza	O
m	O
courville	O
a	O
and	O
bengio	O
y	O
pages	O
maxout	O
networks	O
in	O
s	O
dasgupta	O
and	O
d	O
mcallester	O
editors	O
icml	O
goodfellow	O
i	O
j	O
mirza	O
m	O
courville	O
a	O
and	O
bengio	O
y	O
multi-prediction	O
deep	O
nips	O
foundation	O
boltzmann	O
machines	O
in	O
goodfellow	O
i	O
j	O
warde-farley	O
d	O
lamblin	O
p	O
dumoulin	O
v	O
mirza	O
m	O
pascanu	O
r	O
bergstra	O
j	O
bastien	O
f	O
and	O
bengio	O
y	O
a	O
machine	B
learning	I
research	O
library	O
arxiv	O
preprint	O
goodfellow	O
i	O
j	O
courville	O
a	O
and	O
bengio	O
y	O
scaling	O
up	O
spike-and-slab	O
models	O
for	O
unsupervised	O
feature	B
learning	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
goodfellow	O
i	O
j	O
mirza	O
m	O
xiao	O
d	O
courville	O
a	O
and	O
bengio	O
y	O
an	O
empirical	O
iclr	O
investigation	O
of	O
catastrophic	O
forgeting	O
in	O
gradient-based	O
neural	O
networks	O
in	O
bibliography	O
goodfellow	O
i	O
j	O
shlens	O
j	O
and	O
szegedy	O
c	O
explaining	O
and	O
harnessing	O
adver	O
sarial	O
examples	O
corr	O
goodfellow	O
i	O
j	O
pouget-abadie	O
j	O
mirza	O
m	O
xu	O
b	O
warde-farley	O
d	O
ozair	O
s	O
nips	O
courville	O
a	O
and	O
bengio	O
y	O
generative	O
adversarial	O
networks	O
in	O
goodfellow	O
i	O
j	O
bulatov	O
y	O
ibarz	O
j	O
arnoud	O
s	O
and	O
shet	O
v	O
multi-digit	O
number	O
recognition	O
from	O
street	O
view	O
imagery	O
using	O
deep	O
convolutional	O
neural	O
networks	O
in	O
international	O
conference	O
on	O
learning	O
representations	O
goodfellow	O
i	O
j	O
vinyals	O
o	O
and	O
saxe	O
a	O
m	O
qualitatively	O
characterizing	O
neural	B
network	I
optimization	O
problems	O
in	O
international	O
conference	O
on	O
learning	O
representations	O
goodman	O
j	O
classes	O
for	O
fast	O
maximum	O
entropy	O
training	O
in	O
international	O
conference	O
on	O
acoustics	O
speech	O
and	O
signal	O
processing	O
utah	O
gori	O
m	O
and	O
tesi	O
a	O
on	O
the	O
problem	O
of	O
local	O
minima	O
in	O
backpropagation	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
gosset	O
w	O
s	O
the	O
probable	O
error	O
of	O
a	O
mean	O
biometrika	O
originally	O
published	O
under	O
the	O
pseudonym	O
student	O
gouws	O
s	O
bengio	O
y	O
and	O
corrado	O
g	O
bilbowa	O
fast	O
bilingual	O
distributed	O
representations	O
without	O
word	O
alignments	O
technical	O
report	O
graf	O
h	O
p	O
and	O
jackel	O
l	O
d	O
analog	O
electronic	O
neural	B
network	I
circuits	O
circuits	O
and	O
devices	O
magazine	O
ieee	O
graves	O
a	O
practical	O
variational	O
inference	O
for	O
neural	O
networks	O
in	O
nips	O
graves	O
a	O
supervised	O
sequence	O
labelling	O
with	O
recurrent	O
neural	O
networks	O
studies	O
in	O
computational	O
intelligence	O
springer	O
graves	O
a	O
generating	O
sequences	O
with	O
recurrent	O
neural	O
networks	O
technical	O
report	O
graves	O
a	O
and	O
jaitly	O
n	O
towards	O
end-to-end	O
speech	O
recognition	O
with	O
recurrent	O
neural	O
networks	O
in	O
icml	O
graves	O
a	O
and	O
schmidhuber	O
j	O
framewise	O
phoneme	O
classification	B
with	O
bidirectional	O
lstm	O
and	O
other	O
neural	B
network	I
architectures	O
neural	O
networks	O
graves	O
a	O
and	O
schmidhuber	O
j	O
o	O
ine	O
handwriting	O
recognition	O
with	O
multidimensional	O
recurrent	O
neural	O
networks	O
in	O
d	O
koller	O
d	O
schuurmans	O
y	O
bengio	O
and	O
l	O
bottou	O
editors	O
pages	O
nips	O
bibliography	O
graves	O
a	O
fern	O
ndez	O
s	O
gomez	O
f	O
and	O
schmidhuber	O
j	O
connectionist	B
temporal	I
classification	B
labelling	O
unsegmented	O
sequence	O
data	O
with	O
recurrent	O
neural	O
networks	O
in	O
icml	O
pages	O
pittsburgh	O
usa	O
graves	O
a	O
liwicki	O
m	O
bunke	O
h	O
schmidhuber	O
j	O
and	O
fern	O
ndez	O
s	O
unconstrained	O
on-line	O
handwriting	O
recognition	O
with	O
recurrent	O
neural	O
networks	O
in	O
j	O
platt	O
d	O
koller	O
y	O
singer	O
and	O
s	O
roweis	O
editors	O
pages	O
nips	O
graves	O
a	O
liwicki	O
m	O
fern	O
ndez	O
s	O
bertolami	O
r	O
bunke	O
h	O
and	O
schmidhuber	O
j	O
a	O
novel	O
connectionist	O
system	O
for	O
unconstrained	O
handwriting	O
recognition	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
ieee	O
transactions	O
on	O
graves	O
a	O
mohamed	O
a	O
and	O
hinton	O
g	O
speech	O
recognition	O
with	O
deep	O
recurrent	O
neural	O
networks	O
in	O
icassp	O
pages	O
graves	O
a	O
wayne	O
g	O
and	O
danihelka	O
i	O
neural	O
turing	O
machines	O
graves	O
a	O
wayne	O
g	O
and	O
danihelka	O
i	O
neural	O
turing	O
machines	O
arxiv	O
preprint	O
grefenstette	O
e	O
hermann	O
k	O
m	O
suleyman	O
m	O
and	O
blunsom	O
p	O
learning	O
to	O
transduce	O
with	O
unbounded	O
memory	O
in	O
nips	O
greff	O
k	O
srivastava	O
r	O
k	O
koutn	O
k	O
j	O
steunebrink	O
b	O
r	O
and	O
schmidhuber	O
j	O
lstm	O
a	O
search	O
space	O
odyssey	O
arxiv	O
preprint	O
gregor	O
k	O
and	O
lecun	O
y	O
emergence	O
of	O
complex-like	O
cells	O
in	O
a	O
temporal	O
product	O
network	O
with	O
local	O
receptive	O
fields	O
technical	O
report	O
gregor	O
k	O
and	O
lecun	O
y	O
learning	O
fast	O
approximations	O
of	O
sparse	O
coding	O
in	O
l	O
bottou	O
and	O
m	O
littman	O
editors	O
proceedings	O
of	O
the	O
twenty-seventh	O
international	O
conference	O
on	O
machine	B
learning	I
acm	O
gregor	O
k	O
danihelka	O
i	O
mnih	O
a	O
blundell	O
c	O
and	O
wierstra	O
d	O
deep	O
autoregressive	O
networks	O
in	O
international	O
conference	O
on	O
machine	B
learning	I
gregor	O
k	O
danihelka	O
i	O
graves	O
a	O
and	O
wierstra	O
d	O
draw	O
a	O
recurrent	B
neural	B
network	I
for	O
image	O
generation	O
arxiv	O
preprint	O
gretton	O
a	O
borgwardt	O
k	O
m	O
rasch	O
m	O
j	O
sch	O
lkopf	O
b	O
and	O
smola	O
a	O
a	O
kernel	O
two-sample	O
test	O
the	O
journal	O
of	O
machine	B
learning	I
research	O
g	O
l	O
ehre	O
and	O
bengio	O
y	O
knowledge	O
matters	O
importance	O
of	O
prior	O
information	O
for	O
optimization	O
in	O
international	O
conference	O
on	O
learning	O
representations	O
bibliography	O
guo	O
h	O
and	O
gelfand	O
s	O
b	O
classification	B
trees	O
with	O
neural	B
network	I
feature	B
extraction	O
neural	O
networks	O
ieee	O
transactions	O
on	O
gupta	O
s	O
agrawal	O
a	O
gopalakrishnan	O
k	O
and	O
narayanan	O
p	O
deep	O
learning	O
with	O
limited	O
numerical	O
precision	B
corr	O
gutmann	O
m	O
and	O
hyvarinen	O
a	O
noise-contrastive	B
estimation	I
a	O
new	O
estimation	O
principle	O
for	O
unnormalized	O
statistical	O
models	O
in	O
proceedings	O
of	O
the	O
thirteenth	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
hadsell	O
r	O
sermanet	O
p	O
ben	O
j	O
erkan	O
a	O
han	O
j	O
muller	O
u	O
and	O
lecun	O
y	O
online	O
learning	O
for	O
offroad	O
robots	O
spatial	O
label	O
propagation	O
to	O
learn	O
long-range	O
traversability	O
in	O
proceedings	O
of	O
robotics	O
science	O
and	O
systems	O
atlanta	O
ga	O
usa	O
hajnal	O
a	O
maass	O
w	O
pudlak	O
p	O
szegedy	O
m	O
and	O
turan	O
g	O
threshold	O
circuits	O
of	O
bounded	O
depth	O
j	O
comput	O
system	O
sci	O
h	O
stad	O
j	O
almost	O
optimal	O
lower	O
bounds	O
for	O
small	O
depth	O
circuits	O
in	O
proceedings	O
of	O
the	O
annual	O
acm	O
symposium	O
on	O
theory	O
of	O
computing	O
pages	O
berkeley	O
california	O
acm	O
press	O
h	O
stad	O
j	O
and	O
goldmann	O
m	O
on	O
the	O
power	O
of	O
small-depth	O
threshold	O
circuits	O
computational	O
complexity	O
hastie	O
t	O
tibshirani	O
r	O
and	O
friedman	O
j	O
the	O
elements	O
of	O
statistical	O
learning	O
data	O
mining	O
inference	O
and	O
prediction	O
springer	O
series	O
in	O
statistics	O
springer	O
verlag	O
he	O
k	O
zhang	O
x	O
ren	O
s	O
and	O
sun	O
j	O
delving	O
deep	O
into	O
rectifiers	O
surpassing	O
human-level	O
performance	O
on	O
imagenet	O
classification	B
arxiv	O
preprint	O
hebb	O
d	O
o	O
the	O
organization	O
of	O
behavior	O
wiley	O
new	O
york	O
henaff	O
m	O
jarrett	O
k	O
kavukcuoglu	O
k	O
and	O
lecun	O
y	O
unsupervised	O
learning	O
of	O
sparse	O
features	O
for	O
scalable	O
audio	O
classification	B
in	O
ismir	O
henderson	O
j	O
inducing	O
history	O
representations	O
for	O
broad	O
coverage	B
statistical	O
parsing	O
in	O
hlt-naacl	O
pages	O
henderson	O
j	O
discriminative	O
training	O
of	O
a	O
neural	B
network	I
statistical	O
parser	O
in	O
proceedings	O
of	O
the	O
annual	O
meeting	O
on	O
association	O
for	O
computational	O
linguistics	O
page	O
henniges	O
m	O
puertas	O
g	O
bornschein	O
j	O
eggert	O
j	O
and	O
l	O
cke	O
j	O
binary	O
sparse	O
coding	O
in	O
latent	B
variable	I
analysis	O
and	O
signal	O
separation	O
pages	O
springer	O
bibliography	O
herault	O
j	O
and	O
ans	O
b	O
circuits	O
neuronaux	O
synapses	O
modifiables	O
d	O
codage	O
de	O
messages	O
composites	O
par	O
apprentissage	O
non	O
supervis	O
comptes	O
rendus	O
de	O
l	O
acad	O
mie	O
des	O
sciences	O
hinton	O
g	O
neural	O
networks	O
for	O
machine	B
learning	I
coursera	O
video	O
lectures	O
hinton	O
g	O
deng	O
l	O
dahl	O
g	O
e	O
mohamed	O
a	O
jaitly	O
n	O
senior	O
a	O
vanhoucke	O
v	O
nguyen	O
p	O
sainath	O
t	O
and	O
kingsbury	O
b	O
deep	O
neural	O
networks	O
for	O
acoustic	O
modeling	O
in	O
speech	O
recognition	O
ieee	O
signal	O
processing	O
magazine	O
hinton	O
g	O
vinyals	O
o	O
and	O
dean	O
j	O
distilling	O
the	O
knowledge	O
in	O
a	O
neural	B
network	I
arxiv	O
preprint	O
hinton	O
g	O
e	O
connectionist	O
learning	O
procedures	O
artificial	B
intelligence	I
hinton	O
g	O
e	O
mapping	O
part-whole	O
hierarchies	O
into	O
connectionist	O
networks	O
artificial	B
intelligence	I
hinton	O
g	O
e	O
products	O
of	O
experts	O
in	O
icann	O
hinton	O
g	O
e	O
training	O
products	O
of	O
experts	O
by	O
minimizing	O
contrastive	O
divergence	O
technical	O
report	O
gcnu	O
tr	O
gatsby	O
unit	O
university	O
college	O
london	O
hinton	O
g	O
e	O
to	O
recognize	O
shapes	O
first	O
learn	O
to	O
generate	O
images	O
technical	O
report	O
utml	O
tr	O
university	O
of	O
toronto	O
hinton	O
g	O
e	O
how	O
to	O
do	O
backpropagation	O
in	O
a	O
brain	O
invited	O
talk	O
at	O
the	O
nips	O
deep	O
learning	O
workshop	O
hinton	O
g	O
e	O
learning	O
multiple	O
layers	O
of	O
representation	O
trends	O
in	O
cognitive	O
sciences	O
hinton	O
g	O
e	O
a	O
practical	O
guide	O
to	O
training	O
restricted	O
boltzmann	O
machines	O
technical	O
report	O
utml	O
tr	O
department	O
of	O
computer	O
science	O
university	O
of	O
toronto	O
hinton	O
g	O
e	O
and	O
ghahramani	O
z	O
generative	O
models	O
for	O
discovering	O
sparse	O
distributed	O
representations	O
philosophical	O
transactions	O
of	O
the	O
royal	O
society	O
of	O
london	O
hinton	O
g	O
e	O
and	O
mcclelland	O
j	O
l	O
learning	O
representations	O
by	O
recirculation	O
in	O
nips	O
pages	O
hinton	O
g	O
e	O
and	O
roweis	O
s	O
stochastic	O
neighbor	O
embedding	B
in	O
nips	O
bibliography	O
hinton	O
g	O
e	O
and	O
salakhutdinov	O
r	O
reducing	O
the	O
dimensionality	O
of	O
data	O
with	O
neural	O
networks	O
science	O
hinton	O
g	O
e	O
and	O
sejnowski	O
t	O
j	O
learning	O
and	O
relearning	O
in	O
boltzmann	O
machines	O
in	O
d	O
e	O
rumelhart	O
and	O
j	O
l	O
mcclelland	O
editors	O
parallel	B
distributed	I
processing	I
volume	O
chapter	O
pages	O
mit	O
press	O
cambridge	O
hinton	O
g	O
e	O
and	O
sejnowski	O
t	O
j	O
unsupervised	O
learning	O
foundations	O
of	O
neural	O
computation	O
mit	O
press	O
hinton	O
g	O
e	O
and	O
shallice	O
t	O
lesioning	O
an	O
attractor	O
network	O
investigations	O
of	O
acquired	O
dyslexia	O
psychological	O
review	O
hinton	O
g	O
e	O
and	O
zemel	O
r	O
s	O
autoencoders	O
minimum	O
description	O
length	O
and	O
helmholtz	O
free	O
energy	O
in	O
nips	O
hinton	O
g	O
e	O
sejnowski	O
t	O
j	O
and	O
ackley	O
d	O
h	O
boltzmann	O
machines	O
constraint	O
satisfaction	O
networks	O
that	O
learn	O
technical	O
report	O
carnegie-mellon	O
university	O
dept	O
of	O
computer	O
science	O
hinton	O
g	O
e	O
mcclelland	O
j	O
and	O
rumelhart	O
d	O
distributed	O
representations	O
in	O
d	O
e	O
rumelhart	O
and	O
j	O
l	O
mcclelland	O
editors	O
parallel	B
distributed	I
processing	I
explorations	O
in	O
the	O
microstructure	O
of	O
cognition	O
volume	O
pages	O
mit	O
press	O
cambridge	O
hinton	O
g	O
e	O
revow	O
m	O
and	O
dayan	O
p	O
recognizing	O
handwritten	O
digits	O
using	O
mixtures	O
of	O
linear	O
models	O
in	O
g	O
tesauro	O
d	O
touretzky	O
and	O
t	O
leen	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
cambridge	O
ma	O
hinton	O
g	O
e	O
dayan	O
p	O
frey	O
b	O
j	O
and	O
neal	O
r	O
m	O
the	O
wake-sleep	O
algorithm	O
for	O
unsupervised	O
neural	O
networks	O
science	O
hinton	O
g	O
e	O
dayan	O
p	O
and	O
revow	O
m	O
modelling	O
the	O
manifolds	O
of	O
images	O
of	O
handwritten	O
digits	O
ieee	O
transactions	O
on	O
neural	O
networks	O
hinton	O
g	O
e	O
welling	O
m	O
teh	O
y	O
w	O
and	O
osindero	O
s	O
a	O
new	O
view	O
of	O
ica	O
in	O
proceedings	O
of	O
international	O
conference	O
on	O
independent	B
component	I
analysis	I
and	O
blind	O
signal	O
separation	O
pages	O
san	O
diego	O
ca	O
hinton	O
g	O
e	O
osindero	O
s	O
and	O
teh	O
y	O
a	O
fast	O
learning	O
algorithm	O
for	O
deep	O
belief	O
nets	O
neural	O
computation	O
hinton	O
g	O
e	O
deng	O
l	O
yu	O
d	O
dahl	O
g	O
e	O
mohamed	O
a	O
jaitly	O
n	O
senior	O
a	O
vanhoucke	O
v	O
nguyen	O
p	O
sainath	O
t	O
n	O
and	O
kingsbury	O
b	O
deep	O
neural	O
networks	O
for	O
acoustic	O
modeling	O
in	O
speech	O
recognition	O
the	O
shared	O
views	O
of	O
four	O
research	O
groups	O
ieee	O
signal	O
process	O
mag	O
bibliography	O
hinton	O
g	O
e	O
srivastava	O
n	O
krizhevsky	O
a	O
sutskever	O
i	O
and	O
salakhutdinov	O
r	O
improving	O
neural	O
networks	O
by	O
preventing	O
co-adaptation	O
of	O
feature	B
detectors	O
technical	O
report	O
hinton	O
g	O
e	O
vinyals	O
o	O
and	O
dean	O
j	O
dark	O
knowledge	O
invited	O
talk	O
at	O
the	O
baylearn	O
bay	O
area	O
machine	B
learning	I
symposium	O
hochreiter	O
s	O
untersuchungen	O
zu	O
dynamischen	O
neuronalen	O
netzen	O
diploma	O
thesis	O
t	O
u	O
m	O
nchen	O
hochreiter	O
s	O
and	O
schmidhuber	O
j	O
simplifying	O
neural	O
nets	O
by	O
discovering	O
flat	O
minima	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
hochreiter	O
s	O
and	O
schmidhuber	O
j	O
long	O
short-term	O
memory	O
neural	O
computation	O
hochreiter	O
s	O
bengio	O
y	O
and	O
frasconi	O
p	O
gradient	B
flow	O
in	O
recurrent	O
nets	O
the	O
difficulty	O
of	O
learning	O
long-term	O
dependencies	O
in	O
j	O
kolen	O
and	O
s	O
kremer	O
editors	O
field	O
guide	O
to	O
dynamical	O
recurrent	O
networks	O
ieee	O
press	O
holi	O
j	O
l	O
and	O
hwang	O
j	O
-n	O
finite	O
precision	B
error	O
analysis	O
of	O
neural	B
network	I
hardware	O
implementations	O
computers	O
ieee	O
transactions	O
on	O
holt	O
j	O
l	O
and	O
baker	O
t	O
e	O
back	O
propagation	O
simulations	O
using	O
limited	O
precision	B
calculations	O
in	O
neural	O
networks	O
international	O
joint	O
conference	O
on	O
volume	O
pages	O
ieee	O
hornik	O
k	O
stinchcombe	O
m	O
and	O
white	O
h	O
multilayer	O
feedforward	O
networks	O
are	O
universal	O
approximators	O
neural	O
networks	O
hornik	O
k	O
stinchcombe	O
m	O
and	O
white	O
h	O
universal	O
approximation	O
of	O
an	O
unknown	O
mapping	O
and	O
its	O
derivatives	O
using	O
multilayer	O
feedforward	O
networks	O
neural	O
networks	O
hsu	O
f	O
-h	O
behind	O
deep	B
blue	I
building	O
the	O
computer	O
that	O
defeated	O
the	O
world	O
chess	B
champion	O
princeton	O
university	O
press	O
princeton	O
nj	O
usa	O
huang	O
f	O
and	O
ogata	O
y	O
generalized	O
pseudo-likelihood	O
estimates	O
for	O
markov	O
random	O
fields	O
on	O
lattice	O
annals	O
of	O
the	O
institute	O
of	O
statistical	O
mathematics	O
huang	O
p	O
-s	O
he	O
x	O
gao	O
j	O
deng	O
l	O
acero	O
a	O
and	O
heck	O
l	O
learning	O
deep	O
structured	O
semantic	O
models	O
for	O
web	O
search	O
using	O
clickthrough	O
data	O
in	O
proceedings	O
of	O
the	O
acm	O
international	O
conference	O
on	O
conference	O
on	O
information	O
knowledge	O
management	O
pages	O
acm	O
hubel	O
d	O
and	O
wiesel	O
t	O
receptive	O
fields	O
and	O
functional	O
architecture	O
of	O
monkey	O
striate	O
cortex	O
journal	O
of	O
physiology	O
bibliography	O
hubel	O
d	O
h	O
and	O
wiesel	O
t	O
n	O
receptive	O
fields	O
of	O
single	O
neurons	O
in	O
the	O
cat	O
s	O
striate	O
cortex	O
journal	O
of	O
physiology	O
hubel	O
d	O
h	O
and	O
wiesel	O
t	O
n	O
receptive	O
fields	O
binocular	O
interaction	O
and	O
functional	O
architecture	O
in	O
the	O
cat	O
s	O
visual	O
cortex	O
journal	O
of	O
physiology	O
huszar	O
f	O
how	O
to	O
train	O
your	O
generative	O
model	O
schedule	O
sampling	O
likelihood	O
adversary	O
hutter	O
f	O
hoos	O
h	O
and	O
leyton-brown	O
k	O
sequential	O
model-based	O
optimization	O
extended	O
version	O
as	O
ubc	O
tech	O
report	O
for	O
general	O
algorithm	O
configuration	O
in	O
hyotyniemi	O
h	O
turing	O
machines	O
are	O
recurrent	O
neural	O
networks	O
in	O
step	O
pages	O
hyv	O
rinen	O
a	O
survey	O
on	O
independent	B
component	I
analysis	I
neural	O
computing	O
surveys	O
hyv	O
rinen	O
a	O
estimation	O
of	O
non-normalized	O
statistical	O
models	O
using	O
score	O
matching	O
journal	O
of	O
machine	B
learning	I
research	O
hyv	O
rinen	O
a	O
connections	O
between	O
score	O
matching	O
contrastive	O
divergence	O
and	O
pseudolikelihood	B
for	O
continuous-valued	O
variables	O
ieee	O
transactions	O
on	O
neural	O
networks	O
hyv	O
rinen	O
a	O
some	O
extensions	O
of	O
score	O
matching	O
computational	O
statistics	O
and	O
data	O
analysis	O
hyv	O
rinen	O
a	O
and	O
hoyer	O
p	O
o	O
emergence	O
of	O
topography	O
and	O
complex	B
cell	I
properties	O
from	O
natural	O
images	O
using	O
extensions	O
of	O
ica	O
in	O
pages	O
nips	O
hyv	O
rinen	O
a	O
and	O
pajunen	O
p	O
nonlinear	O
independent	B
component	I
analysis	I
existence	O
and	O
uniqueness	O
results	O
neural	O
networks	O
hyv	O
rinen	O
a	O
karhunen	O
j	O
and	O
oja	O
e	O
independent	B
component	I
analysis	I
wiley-interscience	O
hyv	O
rinen	O
a	O
hoyer	O
p	O
o	O
and	O
inki	O
m	O
o	O
topographic	O
independent	B
component	I
analysis	I
neural	O
computation	O
hyv	O
rinen	O
a	O
hurri	O
j	O
and	O
hoyer	O
p	O
o	O
natural	B
image	I
statistics	O
a	O
probabilistic	O
approach	O
to	O
early	O
computational	O
vision	O
springer-verlag	O
iba	O
y	O
extended	O
ensemble	O
monte	O
carlo	O
international	O
journal	O
of	O
modern	O
physics	O
bibliography	O
inayoshi	O
h	O
and	O
kurita	O
t	O
improved	O
generalization	B
by	O
adding	O
both	O
autoassociation	O
and	O
hidden-layer	O
noise	O
to	O
neural-network-based-classifiers	O
ieee	O
workshop	O
on	O
machine	B
learning	I
for	O
signal	O
processing	O
pages	O
ioffe	O
s	O
and	O
szegedy	O
c	O
batch	O
normalization	O
accelerating	O
deep	O
network	O
training	O
by	O
reducing	O
internal	O
covariate	O
shift	O
jacobs	O
r	O
a	O
increased	O
rates	O
of	O
convergence	O
through	O
learning	B
rate	I
adaptation	O
neural	O
networks	O
jacobs	O
r	O
a	O
jordan	O
m	O
i	O
nowlan	O
s	O
j	O
and	O
hinton	O
g	O
e	O
adaptive	O
mixtures	O
of	O
local	O
experts	O
neural	O
computation	O
jaeger	O
h	O
adaptive	O
nonlinear	O
system	O
identification	O
with	O
echo	O
state	O
networks	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
jaeger	O
h	O
discovering	O
multiscale	O
dynamical	O
features	O
with	O
hierarchical	O
echo	O
state	O
networks	O
technical	O
report	O
jacobs	O
university	O
jaeger	O
h	O
echo	O
state	O
network	O
scholarpedia	O
jaeger	O
h	O
long	O
short-term	O
memory	O
in	O
echo	O
state	O
networks	O
details	O
of	O
a	O
simulation	O
study	O
technical	O
report	O
technical	O
report	O
jacobs	O
university	O
bremen	O
jaeger	O
h	O
and	O
haas	O
h	O
harnessing	O
nonlinearity	O
predicting	O
chaotic	O
systems	O
and	O
saving	O
energy	O
in	O
wireless	O
communication	O
science	O
jaeger	O
h	O
lukosevicius	O
m	O
popovici	O
d	O
and	O
siewert	O
u	O
optimization	O
and	O
applications	O
of	O
echo	O
state	O
networks	O
with	O
leaky-	O
integrator	O
neurons	O
neural	O
networks	O
jain	O
v	O
murray	O
j	O
f	O
roth	O
f	O
turaga	O
s	O
zhigulin	O
v	O
briggman	O
k	O
l	O
helmstaedter	O
m	O
n	O
denk	O
w	O
and	O
seung	O
h	O
s	O
supervised	B
learning	I
of	O
image	O
restoration	O
with	O
convolutional	O
networks	O
in	O
computer	B
vision	I
iccv	O
ieee	O
international	O
conference	O
on	O
pages	O
ieee	O
jaitly	O
n	O
and	O
hinton	O
g	O
learning	O
a	O
better	O
representation	O
of	O
speech	O
soundwaves	O
in	O
acoustics	O
speech	O
and	O
signal	O
processing	O
using	O
restricted	O
boltzmann	O
machines	O
ieee	O
international	O
conference	O
on	O
pages	O
ieee	O
jaitly	O
n	O
and	O
hinton	O
g	O
e	O
vocal	O
tract	O
length	O
perturbation	O
improves	O
speech	O
recognition	O
in	O
icml	O
jarrett	O
k	O
kavukcuoglu	O
k	O
ranzato	O
m	O
and	O
lecun	O
y	O
what	O
is	O
the	O
best	O
iccv	O
multi-stage	O
architecture	O
for	O
object	B
recognition	I
in	O
jarzynski	O
c	O
nonequilibrium	O
equality	O
for	O
free	O
energy	O
differences	O
phys	O
rev	O
lett	O
bibliography	O
jaynes	O
e	O
t	O
probability	O
theory	O
the	O
logic	O
of	O
science	O
cambridge	O
university	O
press	O
jean	O
s	O
cho	O
k	O
memisevic	O
r	O
and	O
bengio	O
y	O
on	O
using	O
very	O
large	O
target	O
vocabulary	O
for	O
neural	O
machine	B
translation	I
jelinek	O
f	O
and	O
mercer	O
r	O
l	O
interpolated	O
estimation	O
of	O
markov	O
source	O
parameters	O
from	O
sparse	O
data	O
in	O
e	O
s	O
gelsema	O
and	O
l	O
n	O
kanal	O
editors	O
pattern	O
recognition	O
in	O
practice	O
north-holland	O
amsterdam	O
jia	O
y	O
caffe	O
an	O
open	O
source	O
convolutional	O
architecture	O
for	O
fast	O
feature	B
embedding	B
httpcaffe	O
berkeleyvision	O
org	O
jia	O
y	O
huang	O
c	O
and	O
darrell	O
t	O
beyond	O
spatial	O
pyramids	O
receptive	B
field	I
in	O
computer	B
vision	I
and	O
pattern	O
recognition	O
learning	O
for	O
pooled	O
image	O
features	O
ieee	O
conference	O
on	O
pages	O
ieee	O
jim	O
k	O
-c	O
giles	O
c	O
l	O
and	O
horne	O
b	O
g	O
an	O
analysis	O
of	O
noise	O
in	O
recurrent	O
neural	O
networks	O
convergence	O
and	O
generalization	B
ieee	O
transactions	O
on	O
neural	O
networks	O
jordan	O
m	O
i	O
learning	O
in	O
graphical	O
models	O
kluwer	O
dordrecht	O
netherlands	O
joulin	O
a	O
and	O
mikolov	O
t	O
inferring	O
algorithmic	O
patterns	O
with	O
stack-augmented	O
recurrent	O
nets	O
arxiv	O
preprint	O
jozefowicz	O
r	O
zaremba	O
w	O
and	O
sutskever	O
i	O
an	O
empirical	O
evaluation	O
of	O
recurrent	B
network	I
architectures	O
in	O
icml	O
judd	O
j	O
s	O
neural	B
network	I
design	O
and	O
the	O
complexity	O
of	O
learning	O
mit	O
press	O
jutten	O
c	O
and	O
herault	O
j	O
blind	O
separation	O
of	O
sources	O
part	O
i	O
an	O
adaptive	O
algorithm	O
based	O
on	O
neuromimetic	O
architecture	O
signal	O
processing	O
kahou	O
s	O
e	O
pal	O
c	O
bouthillier	O
x	O
froumenty	O
p	O
g	O
l	O
ehre	O
c	O
memisevic	O
r	O
vincent	O
p	O
courville	O
a	O
bengio	O
y	O
ferrari	O
r	O
c	O
mirza	O
m	O
jean	O
s	O
carrier	O
p	O
l	O
dauphin	O
y	O
boulanger-lewandowski	O
n	O
aggarwal	O
a	O
zumer	O
j	O
lamblin	O
p	O
raymond	O
j	O
-p	O
desjardins	O
g	O
pascanu	O
r	O
warde-farley	O
d	O
torabi	O
a	O
sharma	O
a	O
bengio	O
e	O
c	O
t	O
m	O
konda	O
k	O
r	O
and	O
wu	O
z	O
combining	O
modality	O
specific	O
deep	O
neural	O
networks	O
for	O
emotion	O
recognition	O
in	O
video	O
in	O
proceedings	O
of	O
the	O
acm	O
on	O
international	O
conference	O
on	O
multimodal	O
interaction	O
kalchbrenner	O
n	O
and	O
blunsom	O
p	O
recurrent	O
continuous	O
translation	O
models	O
in	O
emnlp	O
kalchbrenner	O
n	O
danihelka	O
i	O
and	O
graves	O
a	O
grid	O
long	O
short-term	O
memory	O
arxiv	O
preprint	O
bibliography	O
kamyshanska	O
h	O
and	O
memisevic	O
r	O
the	O
potential	O
energy	O
of	O
an	O
autoencoder	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
karpathy	O
a	O
and	O
li	O
f	O
-f	O
deep	O
visual-semantic	O
alignments	O
for	O
generating	O
image	O
descriptions	O
in	O
cvpr	O
karpathy	O
a	O
toderici	O
g	O
shetty	O
s	O
leung	O
t	O
sukthankar	O
r	O
and	O
fei-fei	O
l	O
large-scale	O
video	O
classification	B
with	O
convolutional	O
neural	O
networks	O
in	O
cvpr	O
karush	O
w	O
minima	O
of	O
functions	O
of	O
several	O
variables	O
with	O
inequalities	O
as	O
side	O
constraints	O
master	O
s	O
thesis	O
dept	O
of	O
mathematics	O
univ	O
of	O
chicago	O
katz	O
s	O
m	O
estimation	O
of	O
probabilities	O
from	O
sparse	O
data	O
for	O
the	O
language	O
model	O
component	O
of	O
a	O
speech	O
recognizer	O
ieee	O
transactions	O
on	O
acoustics	O
speech	O
and	O
signal	O
processing	O
kavukcuoglu	O
k	O
ranzato	O
m	O
and	O
lecun	O
y	O
fast	O
inference	O
in	O
sparse	O
coding	O
algorithms	O
with	O
applications	O
to	O
object	B
recognition	I
technical	O
report	O
computational	O
and	O
biological	O
learning	O
lab	O
courant	O
institute	O
nyu	O
tech	O
report	O
kavukcuoglu	O
k	O
ranzato	O
m	O
-a	O
fergus	O
r	O
and	O
lecun	O
y	O
learning	O
invariant	O
features	O
through	O
topographic	O
filter	O
maps	O
in	O
cvpr	O
kavukcuoglu	O
k	O
sermanet	O
p	O
boureau	O
y	O
-l	O
gregor	O
k	O
mathieu	O
m	O
and	O
lecun	O
y	O
nips	O
learning	O
convolutional	O
feature	B
hierarchies	O
for	O
visual	O
recognition	O
in	O
kelley	O
h	O
j	O
gradient	B
theory	O
of	O
optimal	O
flight	O
paths	O
ars	O
journal	O
khan	O
f	O
zhu	O
x	O
and	O
mutlu	O
b	O
how	O
do	O
humans	O
teach	O
on	O
curriculum	B
learning	I
and	O
teaching	O
dimension	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
kim	O
s	O
k	O
mcafee	O
l	O
c	O
mcmahon	O
p	O
l	O
and	O
olukotun	O
k	O
a	O
highly	O
scalable	O
restricted	O
boltzmann	O
machine	O
fpga	O
implementation	O
in	O
field	O
programmable	O
logic	O
and	O
applications	O
fpl	O
international	O
conference	O
on	O
pages	O
ieee	O
kindermann	O
r	O
markov	O
random	O
fields	O
and	O
their	O
applications	O
mathematics	O
v	O
american	O
mathematical	O
society	O
kingma	O
d	O
and	O
ba	O
j	O
adam	O
a	O
method	O
for	O
stochastic	O
optimization	O
arxiv	O
preprint	O
kingma	O
d	O
and	O
lecun	O
y	O
regularized	O
estimation	O
of	O
image	O
statistics	O
by	O
score	O
matching	O
in	O
nips	O
bibliography	O
kingma	O
d	O
rezende	O
d	O
mohamed	O
s	O
and	O
welling	O
m	O
semi-supervised	B
learning	I
with	O
deep	O
generative	O
models	O
in	O
nips	O
kingma	O
d	O
p	O
fast	O
gradient-based	O
inference	O
with	O
continuous	O
latent	B
variable	I
models	O
in	O
auxiliary	O
form	O
technical	O
report	O
kingma	O
d	O
p	O
and	O
welling	O
m	O
auto-encoding	O
variational	O
bayes	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
learning	O
representations	O
kingma	O
d	O
p	O
and	O
welling	O
m	O
efficient	O
gradient-based	O
inference	O
through	O
transformations	O
between	O
bayes	O
nets	O
and	O
neural	O
nets	O
technical	O
report	O
kirkpatrick	O
s	O
jr	O
c	O
d	O
g	O
and	O
vecchi	O
m	O
p	O
optimization	O
by	O
simulated	O
annealing	O
science	O
kiros	O
r	O
salakhutdinov	O
r	O
and	O
zemel	O
r	O
multimodal	O
neural	O
language	O
models	O
in	O
icml	O
kiros	O
r	O
salakhutdinov	O
r	O
and	O
zemel	O
r	O
unifying	O
visual-semantic	O
embeddings	O
with	O
multimodal	O
neural	O
language	O
models	O
klementiev	O
a	O
titov	O
i	O
and	O
bhattarai	O
b	O
inducing	O
crosslingual	O
distributed	O
representations	O
of	O
words	O
in	O
proceedings	O
of	O
coling	O
knowles-barley	O
s	O
jones	O
t	O
r	O
morgan	O
j	O
lee	O
d	O
kasthuri	O
n	O
lichtman	O
j	O
w	O
and	O
pfister	O
h	O
deep	O
learning	O
for	O
the	O
connectome	O
gpu	O
technology	O
conference	O
koller	O
d	O
and	O
friedman	O
n	O
probabilistic	O
graphical	O
models	O
principles	O
and	O
techniques	O
mit	O
press	O
konig	O
y	O
bourlard	O
h	O
and	O
morgan	O
n	O
remap	O
recursive	O
estimation	O
and	O
maximization	O
of	O
a	O
posteriori	O
probabilities	O
application	O
to	O
transition-based	O
connectionist	O
speech	O
recognition	O
in	O
d	O
touretzky	O
m	O
mozer	O
and	O
m	O
hasselmo	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
mit	O
press	O
cambridge	O
ma	O
koren	O
y	O
the	O
bellkor	O
solution	O
to	O
the	O
netflix	O
grand	O
prize	O
kotzias	O
d	O
denil	O
m	O
de	O
freitas	O
n	O
and	O
smyth	O
p	O
from	O
group	O
to	O
individual	O
labels	O
using	O
deep	O
features	O
in	O
acm	O
sigkdd	O
koutnik	O
j	O
greff	O
k	O
gomez	O
f	O
and	O
schmidhuber	O
j	O
a	O
clockwork	O
rnn	O
in	O
icml	O
ko	O
isk	O
t	O
hermann	O
k	O
m	O
and	O
blunsom	O
p	O
learning	O
bilingual	O
word	O
repre	O
sentations	O
by	O
marginalizing	O
alignments	O
in	O
proceedings	O
of	O
acl	O
krause	O
o	O
fischer	O
a	O
glasmachers	O
t	O
and	O
igel	O
c	O
approximation	O
properties	O
of	O
dbns	O
with	O
binary	O
hidden	O
units	O
and	O
real-valued	O
visible	O
units	O
in	O
icml	O
bibliography	O
krizhevsky	O
a	O
convolutional	O
deep	O
belief	O
networks	O
on	O
technical	O
report	O
university	O
of	O
toronto	O
unpublished	O
manuscript	O
httpwww	O
cs	O
utoronto	O
ca	O
krizhevsky	O
a	O
and	O
hinton	O
g	O
learning	O
multiple	O
layers	O
of	O
features	O
from	O
tiny	O
images	O
technical	O
report	O
university	O
of	O
toronto	O
krizhevsky	O
a	O
and	O
hinton	O
g	O
e	O
using	O
very	O
deep	O
autoencoders	O
for	O
content-based	O
image	O
retrieval	O
in	O
esann	O
krizhevsky	O
a	O
sutskever	O
i	O
and	O
hinton	O
g	O
imagenet	O
classification	B
with	O
deep	O
convolutional	O
neural	O
networks	O
in	O
nips	O
krueger	O
k	O
a	O
and	O
dayan	O
p	O
flexible	O
shaping	O
how	O
learning	O
in	O
small	O
steps	O
helps	O
cognition	O
kuhn	O
h	O
w	O
and	O
tucker	O
a	O
w	O
nonlinear	O
programming	O
in	O
proceedings	O
of	O
the	O
second	O
berkeley	O
symposium	O
on	O
mathematical	O
statistics	O
and	O
probability	O
pages	O
berkeley	O
calif	O
university	O
of	O
california	O
press	O
kumar	O
a	O
irsoy	O
o	O
su	O
j	O
bradbury	O
j	O
english	O
r	O
pierce	O
b	O
ondruska	O
p	O
iyyer	O
m	O
gulrajani	O
i	O
and	O
socher	O
r	O
ask	O
me	O
anything	O
dynamic	O
memory	O
networks	O
for	O
natural	B
language	I
processing	I
kumar	O
m	O
p	O
packer	O
b	O
and	O
koller	O
d	O
self-paced	O
learning	O
for	O
latent	B
variable	I
models	O
in	O
nips	O
lang	O
k	O
j	O
and	O
hinton	O
g	O
e	O
the	O
development	O
of	O
the	O
time-delay	O
neural	B
network	I
architecture	O
for	O
speech	O
recognition	O
technical	O
report	O
carnegie-mellon	O
university	O
lang	O
k	O
j	O
waibel	O
a	O
h	O
and	O
hinton	O
g	O
e	O
a	O
time-delay	O
neural	B
network	I
architecture	O
for	O
isolated	O
word	O
recognition	O
neural	O
networks	O
langford	O
j	O
and	O
zhang	O
t	O
the	O
epoch-greedy	O
algorithm	O
for	O
contextual	O
multi-armed	O
bandits	O
in	O
nips	O
pages	O
lappalainen	O
h	O
giannakopoulos	O
x	O
honkela	O
a	O
and	O
karhunen	O
j	O
nonlinear	O
independent	B
component	I
analysis	I
using	O
ensemble	O
learning	O
experiments	O
and	O
discussion	O
in	O
proc	O
ica	O
citeseer	O
larochelle	O
h	O
and	O
bengio	O
y	O
classification	B
using	O
discriminative	O
restricted	O
boltzmann	O
machines	O
in	O
icml	O
larochelle	O
h	O
and	O
hinton	O
g	O
e	O
learning	O
to	O
combine	O
foveal	O
glimpses	O
with	O
a	O
third-order	O
boltzmann	O
machine	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
bibliography	O
larochelle	O
h	O
and	O
murray	O
i	O
the	O
neural	O
autoregressive	O
distribution	O
estimator	O
in	O
aistats	O
larochelle	O
h	O
erhan	O
d	O
and	O
bengio	O
y	O
zero-data	O
learning	O
of	O
new	O
tasks	O
in	O
aaai	O
conference	O
on	O
artificial	B
intelligence	I
larochelle	O
h	O
bengio	O
y	O
louradour	O
j	O
and	O
lamblin	O
p	O
exploring	O
strategies	O
for	O
training	O
deep	O
neural	O
networks	O
journal	O
of	O
machine	B
learning	I
research	O
lasserre	O
j	O
a	O
bishop	O
c	O
m	O
and	O
minka	O
t	O
p	O
principled	O
hybrids	O
of	O
generative	O
and	O
discriminative	O
models	O
in	O
proceedings	O
of	O
the	O
computer	B
vision	I
and	O
pattern	O
recognition	O
conference	O
pages	O
washington	O
dc	O
usa	O
ieee	O
computer	O
society	O
le	O
q	O
ngiam	O
j	O
chen	O
z	O
hao	O
chia	O
d	O
j	O
koh	O
p	O
w	O
and	O
ng	O
a	O
tiled	O
in	O
j	O
lafferty	O
c	O
k	O
i	O
williams	O
j	O
shawe-taylor	O
convolutional	O
neural	O
networks	O
r	O
zemel	O
and	O
a	O
culotta	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
le	O
q	O
ngiam	O
j	O
coates	O
a	O
lahiri	O
a	O
prochnow	O
b	O
and	O
ng	O
a	O
on	O
optimization	O
methods	O
for	O
deep	O
learning	O
in	O
proc	O
icml	O
acm	O
le	O
q	O
ranzato	O
m	O
monga	O
r	O
devin	O
m	O
corrado	O
g	O
chen	O
k	O
dean	O
j	O
and	O
ng	O
a	O
building	O
high-level	O
features	O
using	O
large	O
scale	O
unsupervised	O
learning	O
in	O
icml	O
le	O
roux	O
n	O
and	O
bengio	O
y	O
representational	O
power	O
of	O
restricted	O
boltzmann	O
machines	O
and	O
deep	O
belief	O
networks	O
neural	O
computation	O
le	O
roux	O
n	O
and	O
bengio	O
y	O
deep	O
belief	O
networks	O
are	O
compact	O
universal	O
approxi	O
mators	O
neural	O
computation	O
lecun	O
y	O
une	O
proc	O
dure	O
d	O
apprentissage	O
pour	O
r	O
seau	O
seuil	O
assym	O
trique	O
in	O
cognitiva	O
a	O
la	O
fronti	O
re	O
de	O
l	O
intelligence	O
artificielle	O
des	O
sciences	O
de	O
la	O
connaissance	O
et	O
des	O
neurosciences	O
pages	O
paris	O
cesta	O
paris	O
lecun	O
y	O
learning	O
processes	O
in	O
an	O
asymmetric	O
threshold	O
network	O
in	O
f	O
fogelmansouli	O
e	O
bienenstock	O
and	O
g	O
weisbuch	O
editors	O
disordered	O
systems	O
and	O
biological	O
organization	O
pages	O
springer-verlag	O
les	O
houches	O
france	O
lecun	O
y	O
mod	O
les	O
connexionistes	O
de	O
l	O
apprentissage	O
ph	O
d	O
thesis	O
universit	O
de	O
paris	O
vi	O
lecun	O
y	O
generalization	B
and	O
network	O
design	O
strategies	O
technical	O
report	O
university	O
of	O
toronto	O
bibliography	O
lecun	O
y	O
jackel	O
l	O
d	O
boser	O
b	O
denker	O
j	O
s	O
graf	O
h	O
p	O
guyon	O
i	O
henderson	O
d	O
howard	O
r	O
e	O
and	O
hubbard	O
w	O
handwritten	O
digit	O
recognition	O
applications	O
of	O
neural	B
network	I
chips	O
and	O
automatic	O
learning	O
ieee	O
communications	O
magazine	O
lecun	O
y	O
bottou	O
l	O
orr	O
g	O
b	O
and	O
m	O
ller	O
k	O
-r	O
efficient	O
backprop	O
in	O
neural	O
networks	O
tricks	O
of	O
the	O
trade	O
lecture	O
notes	O
in	O
computer	O
science	O
lncs	O
springer	O
verlag	O
lecun	O
y	O
bottou	O
l	O
bengio	O
y	O
and	O
haffner	O
p	O
gradient	B
based	O
learning	O
applied	O
to	O
document	O
recognition	O
proc	O
ieee	O
lecun	O
y	O
kavukcuoglu	O
k	O
and	O
farabet	O
c	O
convolutional	O
networks	O
and	O
applications	O
in	O
vision	O
in	O
circuits	O
and	O
systems	O
proceedings	O
of	O
ieee	O
international	O
symposium	O
on	O
pages	O
ieee	O
l	O
ecuyer	O
p	O
efficiency	O
improvement	O
and	O
variance	O
reduction	O
in	O
proceedings	O
of	O
the	O
winter	O
simulation	O
conference	O
pages	O
lee	O
c	O
-y	O
xie	O
s	O
gallagher	O
p	O
zhang	O
z	O
and	O
tu	O
z	O
deeply-supervised	O
nets	O
arxiv	O
preprint	O
lee	O
h	O
battle	O
a	O
raina	O
r	O
and	O
ng	O
a	O
efficient	O
sparse	O
coding	O
algorithms	O
in	O
b	O
sch	O
lkopf	O
j	O
platt	O
and	O
t	O
hoffman	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
lee	O
h	O
ekanadham	O
c	O
and	O
ng	O
a	O
sparse	O
deep	O
belief	O
net	O
model	O
for	O
visual	O
area	O
in	O
nips	O
lee	O
h	O
grosse	O
r	O
ranganath	O
r	O
and	O
ng	O
a	O
y	O
convolutional	O
deep	O
belief	O
networks	O
for	O
scalable	O
unsupervised	O
learning	O
of	O
hierarchical	O
representations	O
in	O
l	O
bottou	O
and	O
m	O
littman	O
editors	O
proceedings	O
of	O
the	O
twenty-sixth	O
international	O
conference	O
on	O
machine	B
learning	I
acm	O
montreal	O
canada	O
lee	O
y	O
j	O
and	O
grauman	O
k	O
learning	O
the	O
easy	O
things	O
first	O
self-paced	O
visual	O
category	O
discovery	O
in	O
cvpr	O
leibniz	O
g	O
w	O
memoir	O
using	O
the	O
chain	O
rule	O
in	O
tmme	O
p	O
lenat	O
d	O
b	O
and	O
guha	O
r	O
v	O
building	O
large	O
knowledge-based	O
systems	O
representation	O
and	O
inference	O
in	O
the	O
cyc	B
project	O
addison-wesley	O
longman	O
publishing	O
co	O
inc	O
leshno	O
m	O
lin	O
v	O
y	O
pinkus	O
a	O
and	O
schocken	O
s	O
multilayer	O
feedforward	O
networks	O
with	O
a	O
nonpolynomial	O
activation	B
function	I
can	O
approximate	O
any	O
function	O
neural	O
networks	O
bibliography	O
levenberg	O
k	O
a	O
method	O
for	O
the	O
solution	O
of	O
certain	O
non-linear	O
problems	O
in	O
least	O
squares	O
quarterly	O
journal	O
of	O
applied	O
mathematics	O
ii	O
l	O
h	O
pital	O
g	O
f	O
a	O
analyse	O
des	O
infiniment	O
petits	O
pour	O
l	O
intelligence	O
des	O
lignes	O
courbes	O
paris	O
l	O
imprimerie	O
royale	O
li	O
y	O
swersky	O
k	O
and	O
zemel	O
r	O
s	O
generative	B
moment	B
matching	I
networks	I
corr	O
lin	O
t	O
horne	O
b	O
g	O
tino	O
p	O
and	O
giles	O
c	O
l	O
learning	O
long-term	O
dependencies	O
is	O
not	O
as	O
difficult	O
with	O
narx	O
recurrent	O
neural	O
networks	O
ieee	O
transactions	O
on	O
neural	O
networks	O
lin	O
y	O
liu	O
z	O
sun	O
m	O
liu	O
y	O
and	O
zhu	O
x	O
learning	O
entity	O
and	O
relation	O
embeddings	O
for	O
knowledge	O
graph	O
completion	O
in	O
proc	O
aaai	O
linde	O
n	O
the	O
machine	O
that	O
changed	O
the	O
world	O
episode	O
documentary	O
miniseries	O
lindsey	O
c	O
and	O
lindblad	O
t	O
review	O
of	O
hardware	O
neural	O
networks	O
a	O
user	O
s	O
perspective	O
in	O
proc	O
third	O
workshop	O
on	O
neural	O
networks	O
from	O
biology	O
to	O
high	O
energy	O
physics	O
pages	O
isola	O
d	O
elba	O
italy	O
linnainmaa	O
s	O
taylor	O
expansion	O
of	O
the	O
accumulated	O
rounding	O
error	O
bit	O
numerical	O
mathematics	O
lisa	O
deep	O
learning	O
tutorials	O
restricted	O
boltzmann	O
machines	O
technical	O
report	O
lisa	O
lab	O
universit	O
de	O
montr	O
al	O
long	O
p	O
m	O
and	O
servedio	O
r	O
a	O
restricted	O
boltzmann	O
machines	O
are	O
hard	O
to	O
approximately	O
evaluate	O
or	O
simulate	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
machine	B
learning	I
lotter	O
w	O
kreiman	O
g	O
and	O
cox	O
d	O
unsupervised	O
learning	O
of	O
visual	O
structure	O
using	O
predictive	O
generative	O
networks	O
arxiv	O
preprint	O
lovelace	O
a	O
notes	O
upon	O
l	O
f	O
menabrea	O
s	O
sketch	O
of	O
the	O
analytical	O
engine	O
invented	O
by	O
charles	O
babbage	O
lu	O
l	O
zhang	O
x	O
cho	O
k	O
and	O
renals	O
s	O
a	O
study	O
of	O
the	O
recurrent	B
neural	B
network	I
encoder-decoder	O
for	O
large	O
vocabulary	O
speech	O
recognition	O
in	O
proc	O
interspeech	O
lu	O
t	O
p	O
l	O
d	O
and	O
p	O
l	O
m	O
contextual	O
multi-armed	O
bandits	O
in	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
pages	O
luenberger	O
d	O
g	O
linear	O
and	O
nonlinear	O
programming	O
addison	O
wesley	O
luko	O
evi	O
ius	O
m	O
and	O
jaeger	O
h	O
reservoir	O
computing	O
approaches	O
to	O
recurrent	B
neural	B
network	I
training	O
computer	O
science	O
review	O
bibliography	O
luo	O
h	O
shen	O
r	O
niu	O
c	O
and	O
ullrich	O
c	O
learning	O
class-relevant	O
features	O
and	O
class-irrelevant	O
features	O
via	O
a	O
hybrid	O
third-order	O
rbm	O
in	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
pages	O
luo	O
h	O
carrier	O
p	O
l	O
courville	O
a	O
and	O
bengio	O
y	O
texture	O
modeling	O
with	O
convolutional	O
spike-and-slab	O
rbms	O
and	O
deep	O
extensions	O
in	O
aistats	O
lyu	O
s	O
interpretation	O
and	O
generalization	B
of	O
score	O
matching	O
in	O
proceedings	O
of	O
the	O
twenty-fifth	O
conference	O
in	O
uncertainty	O
in	O
artificial	B
intelligence	I
ma	O
j	O
sheridan	O
r	O
p	O
liaw	O
a	O
dahl	O
g	O
e	O
and	O
svetnik	O
v	O
deep	O
neural	O
nets	O
as	O
a	O
method	O
for	O
quantitative	O
structure	O
activity	O
relationships	O
j	O
chemical	O
information	O
and	O
modeling	O
maas	O
a	O
l	O
hannun	O
a	O
y	O
and	O
ng	O
a	O
y	O
rectifier	O
nonlinearities	O
improve	O
neural	B
network	I
acoustic	O
models	O
in	O
icml	O
workshop	O
on	O
deep	O
learning	O
for	O
audio	O
speech	O
and	O
language	O
processing	O
maass	O
w	O
bounds	O
for	O
the	O
computational	O
power	O
and	O
learning	O
complexity	O
of	O
analog	O
neural	O
nets	O
abstract	O
in	O
proc	O
of	O
the	O
acm	O
symp	O
theory	O
of	O
computing	O
pages	O
maass	O
w	O
schnitger	O
g	O
and	O
sontag	O
e	O
d	O
a	O
comparison	O
of	O
the	O
computational	O
power	O
of	O
sigmoid	O
and	O
boolean	O
threshold	O
circuits	O
theoretical	O
advances	O
in	O
neural	O
computation	O
and	O
learning	O
pages	O
maass	O
w	O
natschlaeger	O
t	O
and	O
markram	O
h	O
real-time	O
computing	O
without	O
stable	O
states	O
a	O
new	O
framework	O
for	O
neural	O
computation	O
based	O
on	O
perturbations	O
neural	O
computation	O
mackay	O
d	O
information	O
theory	O
inference	O
and	O
learning	O
algorithms	O
cambridge	O
university	O
press	O
maclaurin	O
d	O
duvenaud	O
d	O
and	O
adams	O
r	O
p	O
gradient-based	O
hyperparameter	B
optimization	I
through	O
reversible	O
learning	O
arxiv	O
preprint	O
mao	O
j	O
xu	O
w	O
yang	O
y	O
wang	O
j	O
huang	O
z	O
and	O
yuille	O
a	O
l	O
deep	O
captioning	O
with	O
multimodal	O
recurrent	O
neural	O
networks	O
in	O
iclr	O
marcotte	O
p	O
and	O
savard	O
g	O
novel	O
approaches	O
to	O
the	O
discrimination	O
problem	O
zeitschrift	O
f	O
r	O
operations	O
research	O
marlin	O
b	O
and	O
de	O
freitas	O
n	O
asymptotic	O
efficiency	O
of	O
deterministic	O
estimators	O
for	O
uai	O
discrete	O
energy-based	O
models	O
ratio	B
matching	I
and	O
pseudolikelihood	B
in	O
bibliography	O
marlin	O
b	O
swersky	O
k	O
chen	O
b	O
and	O
de	O
freitas	O
n	O
inductive	O
principles	O
for	O
restricted	O
boltzmann	O
machine	B
learning	I
in	O
proceedings	O
of	O
the	O
thirteenth	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
volume	O
pages	O
marquardt	O
d	O
w	O
an	O
algorithm	O
for	O
least-squares	O
estimation	O
of	O
non-linear	O
parameters	O
journal	O
of	O
the	O
society	O
of	O
industrial	O
and	O
applied	O
mathematics	O
marr	O
d	O
and	O
poggio	O
t	O
cooperative	O
computation	O
of	O
stereo	O
disparity	O
science	O
martens	O
j	O
deep	O
learning	O
via	O
hessian-free	O
optimization	O
in	O
l	O
bottou	O
and	O
m	O
littman	O
editors	O
proceedings	O
of	O
the	O
twenty-seventh	O
international	O
conference	O
on	O
machine	B
learning	I
pages	O
acm	O
martens	O
j	O
and	O
medabalimi	O
v	O
on	O
the	O
expressive	O
efficiency	O
of	O
sum	O
product	O
networks	O
martens	O
j	O
and	O
sutskever	O
i	O
learning	O
recurrent	O
neural	O
networks	O
with	O
hessian-free	O
optimization	O
in	O
proc	O
icml	O
acm	O
mase	O
s	O
consistency	O
of	O
the	O
maximum	O
pseudo-likelihood	O
estimator	O
of	O
continuous	O
state	O
space	O
gibbsian	O
processes	O
the	O
annals	O
of	O
applied	O
probability	O
pp	O
mcclelland	O
j	O
rumelhart	O
d	O
and	O
hinton	O
g	O
the	O
appeal	O
of	O
parallel	B
distributed	I
processing	I
in	O
computation	O
intelligence	O
pages	O
american	O
association	O
for	O
artificial	B
intelligence	I
mcculloch	O
w	O
s	O
and	O
pitts	O
w	O
a	O
logical	O
calculus	O
of	O
ideas	O
immanent	O
in	O
nervous	O
activity	O
bulletin	O
of	O
mathematical	O
biophysics	O
mead	O
c	O
and	O
ismail	O
m	O
analog	O
vlsi	O
implementation	O
of	O
neural	O
systems	O
volume	O
springer	O
science	O
business	O
media	O
melchior	O
j	O
fischer	O
a	O
and	O
wiskott	O
l	O
how	O
to	O
center	O
binary	O
deep	O
boltzmann	O
machines	O
arxiv	O
preprint	O
memisevic	O
r	O
and	O
hinton	O
g	O
e	O
unsupervised	O
learning	O
of	O
image	O
transformations	O
in	O
proceedings	O
of	O
the	O
computer	B
vision	I
and	O
pattern	O
recognition	O
conference	O
memisevic	O
r	O
and	O
hinton	O
g	O
e	O
learning	O
to	O
represent	O
spatial	O
transformations	O
with	O
factored	O
higher-order	O
boltzmann	O
machines	O
neural	O
computation	O
bibliography	O
mesnil	O
g	O
dauphin	O
y	O
glorot	O
x	O
rifai	O
s	O
bengio	O
y	O
goodfellow	O
i	O
lavoie	O
e	O
muller	O
x	O
desjardins	O
g	O
warde-farley	O
d	O
vincent	O
p	O
courville	O
a	O
and	O
bergstra	O
j	O
unsupervised	O
and	O
transfer	B
learning	I
challenge	B
a	O
deep	O
learning	O
approach	O
in	O
jmlr	O
wcp	O
proc	O
unsupervised	O
and	O
transfer	B
learning	I
volume	O
mesnil	O
g	O
rifai	O
s	O
dauphin	O
y	O
bengio	O
y	O
and	O
vincent	O
p	O
surfing	O
on	O
the	O
manifold	B
learning	I
workshop	O
snowbird	O
miikkulainen	O
r	O
and	O
dyer	O
m	O
g	O
natural	B
language	I
processing	I
with	O
modular	O
pdp	O
networks	O
and	O
distributed	O
lexicon	O
cognitive	O
science	O
mikolov	O
t	O
statistical	O
language	O
models	O
based	O
on	O
neural	O
networks	O
ph	O
d	O
thesis	O
brno	O
university	O
of	O
technology	O
mikolov	O
t	O
deoras	O
a	O
kombrink	O
s	O
burget	O
l	O
and	O
cernocky	O
j	O
empirical	O
evaluation	O
and	O
combination	O
of	O
advanced	O
language	O
modeling	O
techniques	O
in	O
proc	O
annual	O
conference	O
of	O
the	O
international	O
speech	O
communication	O
association	O
mikolov	O
t	O
deoras	O
a	O
povey	O
d	O
burget	O
l	O
and	O
cernocky	O
j	O
strategies	O
for	O
training	O
large	O
scale	O
neural	B
network	I
language	O
models	O
in	O
proc	O
asru	O
mikolov	O
t	O
chen	O
k	O
corrado	O
g	O
and	O
dean	O
j	O
efficient	O
estimation	O
of	O
word	O
representations	O
in	O
vector	O
space	O
in	O
international	O
conference	O
on	O
learning	O
representations	O
workshops	O
track	O
mikolov	O
t	O
le	O
q	O
v	O
and	O
sutskever	O
i	O
exploiting	O
similarities	O
among	O
languages	O
for	O
machine	B
translation	I
technical	O
report	O
minka	O
t	O
divergence	O
measures	O
and	O
message	O
passing	O
microsoft	O
research	O
cambridge	O
uk	O
tech	O
rep	O
minsky	O
m	O
l	O
and	O
papert	O
s	O
a	O
perceptrons	O
mit	O
press	O
cambridge	O
mirza	O
m	O
and	O
osindero	O
s	O
conditional	O
generative	O
adversarial	O
nets	O
arxiv	O
preprint	O
mishkin	O
d	O
and	O
matas	O
j	O
all	O
you	O
need	O
is	O
a	O
good	O
init	O
arxiv	O
preprint	O
misra	O
j	O
and	O
saha	O
i	O
artificial	O
neural	O
networks	O
in	O
hardware	O
a	O
survey	O
of	O
two	O
decades	O
of	O
progress	O
neurocomputing	O
mitchell	O
t	O
m	O
machine	B
learning	I
mcgraw-hill	O
new	O
york	O
miyato	O
t	O
maeda	O
s	O
koyama	O
m	O
nakae	O
k	O
and	O
ishii	O
s	O
distributional	O
smoothing	O
with	O
virtual	O
adversarial	O
training	O
in	O
preprint	O
iclr	O
bibliography	O
mnih	O
a	O
and	O
gregor	O
k	O
neural	O
variational	O
inference	O
and	O
learning	O
in	O
belief	O
networks	O
in	O
icml	O
mnih	O
a	O
and	O
hinton	O
g	O
e	O
three	O
new	O
graphical	O
models	O
for	O
statistical	O
language	O
modelling	O
in	O
z	O
ghahramani	O
editor	O
proceedings	O
of	O
the	O
twenty-fourth	O
international	O
conference	O
on	O
machine	B
learning	I
pages	O
acm	O
mnih	O
a	O
and	O
hinton	O
g	O
e	O
a	O
scalable	O
hierarchical	O
distributed	O
language	O
model	O
in	O
d	O
koller	O
d	O
schuurmans	O
y	O
bengio	O
and	O
l	O
bottou	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mnih	O
a	O
and	O
kavukcuoglu	O
k	O
learning	O
word	O
embeddings	O
efficiently	O
with	O
noisecontrastive	O
estimation	O
in	O
c	O
burges	O
l	O
bottou	O
m	O
welling	O
z	O
ghahramani	O
and	O
k	O
weinberger	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
curran	O
associates	O
inc	O
mnih	O
a	O
and	O
teh	O
y	O
w	O
a	O
fast	O
and	O
simple	O
algorithm	O
for	O
training	O
neural	O
probabilistic	O
language	O
models	O
in	O
icml	O
pages	O
mnih	O
v	O
and	O
hinton	O
g	O
learning	O
to	O
detect	O
roads	O
in	O
high-resolution	O
aerial	O
images	O
in	O
proceedings	O
of	O
the	O
european	O
conference	O
on	O
computer	B
vision	I
mnih	O
v	O
larochelle	O
h	O
and	O
hinton	O
g	O
conditional	O
restricted	O
boltzmann	O
machines	O
for	O
structure	O
output	O
prediction	O
in	O
proc	O
conf	O
on	O
uncertainty	O
in	O
artificial	B
intelligence	I
mnih	O
v	O
kavukcuoglo	O
k	O
silver	O
d	O
graves	O
a	O
antonoglou	O
i	O
and	O
wierstra	O
d	O
playing	O
atari	O
with	O
deep	O
reinforcement	O
learning	O
technical	O
report	O
mnih	O
v	O
heess	O
n	O
graves	O
a	O
and	O
kavukcuoglu	O
k	O
recurrent	O
models	O
of	O
visual	O
attention	O
in	O
z	O
ghahramani	O
m	O
welling	O
c	O
cortes	O
n	O
lawrence	O
and	O
k	O
weinberger	O
editors	O
pages	O
nips	O
mnih	O
v	O
kavukcuoglo	O
k	O
silver	O
d	O
rusu	O
a	O
a	O
veness	O
j	O
bellemare	O
m	O
g	O
graves	O
a	O
riedmiller	O
m	O
fidgeland	O
a	O
k	O
ostrovski	O
g	O
petersen	O
s	O
beattie	O
c	O
sadik	O
a	O
antonoglou	O
i	O
king	O
h	O
kumaran	O
d	O
wierstra	O
d	O
legg	O
s	O
and	O
hassabis	O
d	O
human-level	O
control	O
through	O
deep	O
reinforcement	O
learning	O
nature	O
mobahi	O
h	O
and	O
fisher	O
iii	O
j	O
w	O
a	O
theoretical	O
analysis	O
of	O
optimization	O
by	O
gaussian	O
continuation	O
in	O
aaai	O
mobahi	O
h	O
collobert	O
r	O
and	O
weston	O
j	O
deep	O
learning	O
from	O
temporal	O
coherence	O
in	O
video	O
in	O
l	O
bottou	O
and	O
m	O
littman	O
editors	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
machine	B
learning	I
pages	O
montreal	O
omnipress	O
mohamed	O
a	O
dahl	O
g	O
and	O
hinton	O
g	O
deep	O
belief	O
networks	O
for	O
phone	O
recognition	O
bibliography	O
mohamed	O
a	O
sainath	O
t	O
n	O
dahl	O
g	O
ramabhadran	O
b	O
hinton	O
g	O
e	O
and	O
picheny	O
m	O
a	O
deep	O
belief	O
networks	O
using	O
discriminative	O
features	O
for	O
phone	O
recognition	O
in	O
acoustics	O
speech	O
and	O
signal	O
processing	O
ieee	O
international	O
conference	O
on	O
pages	O
ieee	O
mohamed	O
a	O
dahl	O
g	O
and	O
hinton	O
g	O
acoustic	O
modeling	O
using	O
deep	O
belief	O
networks	O
ieee	O
trans	O
on	O
audio	O
speech	O
and	O
language	O
processing	O
mohamed	O
a	O
hinton	O
g	O
and	O
penn	O
g	O
understanding	O
how	O
deep	O
belief	O
networks	O
perform	O
acoustic	O
modelling	O
in	O
acoustics	O
speech	O
and	O
signal	O
processing	O
ieee	O
international	O
conference	O
on	O
pages	O
ieee	O
moller	O
m	O
f	O
a	O
scaled	O
conjugate	O
gradient	B
algorithm	O
for	O
fast	O
supervised	B
learning	I
neural	O
networks	O
montavon	O
g	O
and	O
muller	O
k	O
-r	O
deep	O
boltzmann	O
machines	O
and	O
the	O
centering	O
trick	B
in	O
g	O
montavon	O
g	O
orr	O
and	O
k	O
-r	O
m	O
ller	O
editors	O
neural	O
networks	O
tricks	O
of	O
the	O
trade	O
volume	O
of	O
lecture	O
notes	O
in	O
computer	O
science	O
pages	O
preprint	O
mont	O
far	O
g	O
universal	O
approximation	O
depth	O
and	O
errors	O
of	O
narrow	O
belief	O
networks	O
with	O
discrete	O
units	O
neural	O
computation	O
mont	O
far	O
g	O
and	O
ay	O
n	O
refinements	O
of	O
universal	O
approximation	O
results	O
for	O
deep	O
belief	O
networks	O
and	O
restricted	O
boltzmann	O
machines	O
neural	O
computation	O
montufar	O
g	O
f	O
pascanu	O
r	O
cho	O
k	O
and	O
bengio	O
y	O
on	O
the	O
number	O
of	O
linear	O
regions	O
of	O
deep	O
neural	O
networks	O
in	O
nips	O
mor-yosef	O
s	O
samueloff	O
a	O
modan	O
b	O
navot	O
d	O
and	O
schenker	O
j	O
g	O
ranking	O
the	O
risk	B
factors	O
for	O
cesarean	O
logistic	O
regression	B
analysis	O
of	O
a	O
nationwide	O
study	O
obstet	O
gynecol	O
morin	O
f	O
and	O
bengio	O
y	O
hierarchical	O
probabilistic	O
neural	B
network	I
language	O
model	O
in	O
aistats	O
mozer	O
m	O
c	O
the	O
induction	O
of	O
multiscale	O
temporal	O
structure	O
in	O
j	O
m	O
s	O
hanson	O
and	O
r	O
lippmann	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
san	O
mateo	O
ca	O
morgan	O
kaufmann	O
murphy	O
k	O
p	O
machine	B
learning	I
a	O
probabilistic	O
perspective	O
mit	O
press	O
cambridge	O
ma	O
usa	O
murray	O
b	O
u	O
i	O
and	O
larochelle	O
h	O
a	O
deep	O
and	O
tractable	O
density	O
estimator	O
in	O
icml	O
nair	O
v	O
and	O
hinton	O
g	O
rectified	O
linear	O
units	O
improve	O
restricted	O
boltzmann	O
machines	O
in	O
icml	O
bibliography	O
nair	O
v	O
and	O
hinton	O
g	O
e	O
object	B
recognition	I
with	O
deep	O
belief	O
nets	O
in	O
y	O
bengio	O
d	O
schuurmans	O
j	O
d	O
lafferty	O
c	O
k	O
i	O
williams	O
and	O
a	O
culotta	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
curran	O
associates	O
inc	O
narayanan	O
h	O
and	O
mitter	O
s	O
sample	O
complexity	O
of	O
testing	O
the	O
manifold	B
hypothesis	I
in	O
nips	O
naumann	O
u	O
optimal	O
jacobian	O
accumulation	O
is	O
np-complete	O
mathematical	O
programming	O
navigli	O
r	O
and	O
velardi	O
p	O
structural	O
semantic	O
interconnections	O
a	O
knowledgebased	O
approach	O
to	O
word	O
sense	O
disambiguation	O
ieee	O
trans	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
neal	O
r	O
and	O
hinton	O
g	O
a	O
view	O
of	O
the	O
em	O
algorithm	O
that	O
justifies	O
incremental	O
sparse	O
and	O
other	O
variants	O
in	O
m	O
i	O
jordan	O
editor	O
learning	O
in	O
graphical	O
models	O
mit	O
press	O
cambridge	O
ma	O
neal	O
r	O
m	O
learning	O
stochastic	O
feedforward	O
networks	O
technical	O
report	O
neal	O
r	O
m	O
probabilistic	O
inference	O
using	O
markov	B
chain	I
monte-carlo	O
methods	O
technical	O
report	O
dept	O
of	O
computer	O
science	O
university	O
of	O
toronto	O
neal	O
r	O
m	O
sampling	O
from	O
multimodal	O
distributions	O
using	O
tempered	O
transitions	O
technical	O
report	O
dept	O
of	O
statistics	O
university	O
of	O
toronto	O
neal	O
r	O
m	O
bayesian	O
learning	O
for	O
neural	O
networks	O
lecture	O
notes	O
in	O
statistics	O
springer	O
neal	O
r	O
m	O
annealed	O
importance	O
sampling	O
statistics	O
and	O
computing	O
neal	O
r	O
m	O
estimating	O
ratios	O
of	O
normalizing	O
constants	O
using	O
linked	O
importance	O
sampling	O
nesterov	O
y	O
a	O
method	O
of	O
solving	O
a	O
convex	O
programming	O
problem	O
with	O
convergence	O
rate	O
o	O
soviet	O
mathematics	O
doklady	O
nesterov	O
y	O
introductory	O
lectures	O
on	O
convex	B
optimization	I
a	O
basic	O
course	O
applied	O
optimization	O
kluwer	O
academic	O
publ	O
boston	O
dordrecht	O
london	O
netzer	O
y	O
wang	O
t	O
coates	O
a	O
bissacco	O
a	O
wu	O
b	O
and	O
ng	O
a	O
y	O
reading	O
digits	O
in	O
natural	O
images	O
with	O
unsupervised	O
feature	B
learning	O
deep	O
learning	O
and	O
unsupervised	O
feature	B
learning	O
workshop	O
nips	O
ney	O
h	O
and	O
kneser	O
r	O
improved	O
clustering	O
techniques	O
for	O
class-based	O
statistical	O
language	O
modelling	O
in	O
european	O
conference	O
on	O
speech	O
communication	O
and	O
technology	O
pages	O
berlin	O
bibliography	O
ng	O
a	O
advice	O
for	O
applying	O
machine	B
learning	I
niesler	O
t	O
r	O
whittaker	O
e	O
w	O
d	O
and	O
woodland	O
p	O
c	O
comparison	O
of	O
part-ofspeech	O
and	O
automatically	O
derived	O
category-based	O
language	O
models	O
for	O
speech	O
recognition	O
in	O
international	O
conference	O
on	O
acoustics	O
speech	O
and	O
signal	O
processing	O
pages	O
ning	O
f	O
delhomme	O
d	O
lecun	O
y	O
piano	O
f	O
bottou	O
l	O
and	O
barbano	O
p	O
e	O
toward	O
automatic	O
phenotyping	O
of	O
developing	O
embryos	O
from	O
videos	O
image	O
processing	O
ieee	O
transactions	O
on	O
nocedal	O
j	O
and	O
wright	O
s	O
numerical	O
optimization	O
springer	O
norouzi	O
m	O
and	O
fleet	O
d	O
j	O
minimal	O
loss	O
hashing	O
for	O
compact	O
binary	O
codes	O
in	O
icml	O
nowlan	O
s	O
j	O
competing	O
experts	O
an	O
experimental	O
investigation	O
of	O
associative	O
mixture	O
models	O
technical	O
report	O
university	O
of	O
toronto	O
nowlan	O
s	O
j	O
and	O
hinton	O
g	O
e	O
simplifying	O
neural	O
networks	O
by	O
soft	O
weight-sharing	O
neural	O
computation	O
olshausen	O
b	O
and	O
field	O
d	O
j	O
how	O
close	O
are	O
we	O
to	O
understanding	O
neural	O
computation	O
olshausen	O
b	O
a	O
and	O
field	O
d	O
j	O
emergence	O
of	O
simple-cell	O
receptive	B
field	I
properties	O
by	O
learning	O
a	O
sparse	O
code	O
for	O
natural	O
images	O
nature	O
olshausen	O
b	O
a	O
anderson	O
c	O
h	O
and	O
van	O
essen	O
d	O
c	O
a	O
neurobiological	O
model	O
of	O
visual	O
attention	O
and	O
invariant	O
pattern	O
recognition	O
based	O
on	O
dynamic	O
routing	O
of	O
information	O
j	O
neurosci	O
opper	O
m	O
and	O
archambeau	O
c	O
the	O
variational	O
gaussian	O
approximation	O
revisited	O
neural	O
computation	O
oquab	O
m	O
bottou	O
l	O
laptev	O
i	O
and	O
sivic	O
j	O
learning	O
and	O
transferring	O
mid-level	O
image	O
representations	O
using	O
convolutional	O
neural	O
networks	O
in	O
computer	B
vision	I
and	O
pattern	O
recognition	O
ieee	O
conference	O
on	O
pages	O
ieee	O
osindero	O
s	O
and	O
hinton	O
g	O
e	O
modeling	O
image	O
patches	O
with	O
a	O
directed	O
hierarchy	O
of	O
markov	O
random	O
fields	O
in	O
j	O
platt	O
d	O
koller	O
y	O
singer	O
and	O
s	O
roweis	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
cambridge	O
ma	O
mit	O
press	O
ovid	O
and	O
martin	O
c	O
metamorphoses	O
w	O
w	O
norton	O
bibliography	O
paccanaro	O
a	O
and	O
hinton	O
g	O
e	O
extracting	O
distributed	O
representations	O
of	O
concepts	O
and	O
relations	B
from	O
positive	O
and	O
negative	O
propositions	O
in	O
international	O
joint	O
conference	O
on	O
neural	O
networks	O
como	O
italy	O
ieee	O
new	O
york	O
paine	O
t	O
l	O
khorrami	O
p	O
han	O
w	O
and	O
huang	O
t	O
s	O
an	O
analysis	O
of	O
unsupervised	O
pre-training	O
in	O
light	O
of	O
recent	O
advances	O
arxiv	O
preprint	O
palatucci	O
m	O
pomerleau	O
d	O
hinton	O
g	O
e	O
and	O
mitchell	O
t	O
m	O
zero-shot	B
learning	I
with	O
semantic	O
output	O
codes	O
in	O
y	O
bengio	O
d	O
schuurmans	O
j	O
d	O
lafferty	O
c	O
k	O
i	O
williams	O
and	O
a	O
culotta	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
curran	O
associates	O
inc	O
parker	O
d	O
b	O
learning-logic	O
technical	O
report	O
center	O
for	O
comp	O
research	O
in	O
economics	O
and	O
management	O
sci	O
mit	O
pascanu	O
r	O
mikolov	O
t	O
and	O
bengio	O
y	O
on	O
the	O
difficulty	O
of	O
training	O
recurrent	O
neural	O
networks	O
in	O
icml	O
pascanu	O
r	O
g	O
l	O
ehre	O
cho	O
k	O
and	O
bengio	O
y	O
how	O
to	O
construct	O
deep	O
recurrent	O
neural	O
networks	O
in	O
iclr	O
pascanu	O
r	O
montufar	O
g	O
and	O
bengio	O
y	O
on	O
the	O
number	O
of	O
inference	O
regions	O
iclr	O
of	O
deep	O
feed	O
forward	O
networks	O
with	O
piece-wise	O
linear	O
activations	O
in	O
pati	O
y	O
rezaiifar	O
r	O
and	O
krishnaprasad	O
p	O
orthogonal	O
matching	O
pursuit	O
recursive	O
function	O
approximation	O
with	O
applications	O
to	O
wavelet	O
decomposition	O
in	O
proceedings	O
of	O
the	O
th	O
annual	O
asilomar	O
conference	O
on	O
signals	O
systems	O
and	O
computers	O
pages	O
pearl	O
j	O
bayesian	O
networks	O
a	O
model	O
of	O
self-activated	O
memory	O
for	O
evidential	O
in	O
proceedings	O
of	O
the	O
conference	O
of	O
the	O
cognitive	O
science	O
society	O
reasoning	O
university	O
of	O
california	O
irvine	O
pages	O
pearl	O
j	O
probabilistic	O
reasoning	O
in	O
intelligent	O
systems	O
networks	O
of	O
plausible	O
inference	O
morgan	O
kaufmann	O
perron	O
o	O
zur	O
theorie	O
der	O
matrices	O
mathematische	O
annalen	O
petersen	O
k	O
b	O
and	O
pedersen	O
m	O
s	O
the	O
matrix	O
cookbook	O
version	O
peterson	O
g	O
b	O
a	O
day	O
of	O
great	O
illumination	O
b	O
f	O
skinner	O
s	O
discovery	O
of	O
shaping	O
journal	O
of	O
the	O
experimental	O
analysis	O
of	O
behavior	O
pham	O
d	O
-t	O
garat	O
p	O
and	O
jutten	O
c	O
separation	O
of	O
a	O
mixture	O
of	O
independent	O
sources	O
through	O
a	O
maximum	B
likelihood	I
approach	O
in	O
eusipco	O
pages	O
bibliography	O
pham	O
p	O
-h	O
jelaca	O
d	O
farabet	O
c	O
martini	O
b	O
lecun	O
y	O
and	O
culurciello	O
e	O
neuflow	O
dataflow	O
vision	O
processing	O
system-on-a-chip	O
in	O
circuits	O
and	O
systems	O
ieee	O
international	O
midwest	O
symposium	O
on	O
pages	O
ieee	O
pinheiro	O
p	O
h	O
o	O
and	O
collobert	O
r	O
recurrent	O
convolutional	O
neural	O
networks	O
for	O
scene	O
labeling	O
in	O
icml	O
pinheiro	O
p	O
h	O
o	O
and	O
collobert	O
r	O
from	O
image-level	O
to	O
pixel-level	O
labeling	O
with	O
convolutional	O
networks	O
in	O
conference	O
on	O
computer	B
vision	I
and	O
pattern	O
recognition	O
pinto	O
n	O
cox	O
d	O
d	O
and	O
dicarlo	O
j	O
j	O
why	O
is	O
real-world	O
visual	O
object	B
recognition	I
hard	O
plos	O
comput	O
biol	O
pinto	O
n	O
stone	O
z	O
zickler	O
t	O
and	O
cox	O
d	O
scaling	O
up	O
biologically-inspired	O
computer	B
vision	I
a	O
case	O
study	O
in	O
unconstrained	O
face	O
recognition	O
on	O
facebook	O
in	O
computer	B
vision	I
and	O
pattern	O
recognition	O
workshops	O
ieee	O
computer	O
society	O
conference	O
on	O
pages	O
ieee	O
pollack	O
j	O
b	O
recursive	O
distributed	O
representations	O
artificial	B
intelligence	I
polyak	O
b	O
and	O
juditsky	O
a	O
acceleration	O
of	O
stochastic	O
approximation	O
by	O
averaging	O
siam	O
j	O
control	O
and	O
optimization	O
polyak	O
b	O
t	O
some	O
methods	O
of	O
speeding	O
up	O
the	O
convergence	O
of	O
iteration	O
methods	O
ussr	O
computational	O
mathematics	O
and	O
mathematical	O
physics	O
poole	O
b	O
sohl-dickstein	O
j	O
and	O
ganguli	O
s	O
analyzing	O
noise	O
in	O
autoencoders	O
and	O
deep	O
networks	O
corr	O
poon	O
h	O
and	O
domingos	O
p	O
sum-product	O
networks	O
a	O
new	O
deep	O
architecture	O
in	O
proceedings	O
of	O
the	O
twenty-seventh	O
conference	O
in	O
uncertainty	O
in	O
artificial	B
intelligence	I
barcelona	O
spain	O
presley	O
r	O
k	O
and	O
haggard	O
r	O
l	O
a	O
fixed	O
point	O
implementation	O
of	O
the	O
backpropagation	O
learning	O
algorithm	O
in	O
southeastcon	O
creative	O
technology	O
transfer-a	O
global	O
affair	O
proceedings	O
of	O
the	O
ieee	O
pages	O
ieee	O
price	O
r	O
a	O
useful	O
theorem	O
for	O
nonlinear	O
devices	O
having	O
gaussian	O
inputs	O
ieee	O
transactions	O
on	O
information	O
theory	O
quiroga	O
r	O
q	O
reddy	O
l	O
kreiman	O
g	O
koch	O
c	O
and	O
fried	O
i	O
invariant	O
visual	O
representation	O
by	O
single	O
neurons	O
in	O
the	O
human	O
brain	O
nature	O
bibliography	O
radford	O
a	O
metz	O
l	O
and	O
chintala	O
s	O
unsupervised	O
representation	B
learning	I
with	O
deep	O
convolutional	O
generative	O
adversarial	O
networks	O
arxiv	O
preprint	O
raiko	O
t	O
yao	O
l	O
cho	O
k	O
and	O
bengio	O
y	O
iterative	O
neural	O
autoregressive	O
distribution	O
estimator	O
technical	O
report	O
raina	O
r	O
madhavan	O
a	O
and	O
ng	O
a	O
y	O
large-scale	O
deep	O
unsupervised	O
learning	O
using	O
graphics	O
processors	O
in	O
l	O
bottou	O
and	O
m	O
littman	O
editors	O
proceedings	O
of	O
the	O
twenty-sixth	O
international	O
conference	O
on	O
machine	B
learning	I
pages	O
new	O
york	O
ny	O
usa	O
acm	O
ramsey	O
f	O
p	O
truth	O
and	O
probability	O
in	O
r	O
b	O
braithwaite	O
editor	O
the	O
foundations	O
of	O
mathematics	O
and	O
other	O
logical	O
essays	O
chapter	O
pages	O
mcmaster	O
university	O
archive	O
for	O
the	O
history	O
of	O
economic	O
thought	O
ranzato	O
m	O
and	O
hinton	O
g	O
h	O
modeling	O
pixel	O
means	O
and	O
covariances	O
using	O
factorized	O
third-order	O
boltzmann	O
machines	O
in	O
cvpr	O
pages	O
ranzato	O
m	O
poultney	O
c	O
chopra	O
s	O
and	O
lecun	O
y	O
efficient	O
learning	O
of	O
sparse	O
representations	O
with	O
an	O
energy-based	O
model	O
in	O
nips	O
ranzato	O
m	O
huang	O
f	O
boureau	O
y	O
and	O
lecun	O
y	O
unsupervised	O
learning	O
of	O
invariant	O
feature	B
hierarchies	O
with	O
applications	O
to	O
object	B
recognition	I
in	O
proceedings	O
of	O
the	O
computer	B
vision	I
and	O
pattern	O
recognition	O
conference	O
ieee	O
press	O
ranzato	O
m	O
boureau	O
y	O
and	O
lecun	O
y	O
sparse	O
feature	B
learning	O
for	O
deep	O
belief	O
networks	O
in	O
nips	O
ranzato	O
m	O
krizhevsky	O
a	O
and	O
hinton	O
g	O
e	O
factored	O
restricted	O
boltzmann	O
machines	O
for	O
modeling	O
natural	O
images	O
in	O
proceedings	O
of	O
aistats	O
ranzato	O
m	O
mnih	O
v	O
and	O
hinton	O
g	O
generating	O
more	O
realistic	O
images	O
using	O
gated	O
mrfs	O
in	O
nips	O
rao	O
c	O
information	O
and	O
the	O
accuracy	B
attainable	O
in	O
the	O
estimation	O
of	O
statistical	O
parameters	O
bulletin	O
of	O
the	O
calcutta	O
mathematical	O
society	O
rasmus	O
a	O
valpola	O
h	O
honkala	O
m	O
berglund	O
m	O
and	O
raiko	O
t	O
semi-supervised	B
learning	I
with	O
ladder	O
network	O
arxiv	O
preprint	O
recht	O
b	O
re	O
c	O
wright	O
s	O
and	O
niu	O
f	O
hogwild	O
a	O
lock-free	O
approach	O
to	O
parallelizing	O
stochastic	O
gradient	B
descent	O
in	O
nips	O
reichert	O
d	O
p	O
seri	O
s	O
p	O
and	O
storkey	O
a	O
j	O
neuronal	O
adaptation	O
for	O
samplingbased	O
probabilistic	O
inference	O
in	O
perceptual	O
bistability	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
bibliography	O
rezende	O
d	O
j	O
mohamed	O
s	O
and	O
wierstra	O
d	O
stochastic	O
backpropagation	O
preprint	O
and	O
approximate	B
inference	I
in	O
deep	O
generative	O
models	O
icml	O
in	O
rifai	O
s	O
vincent	O
p	O
muller	O
x	O
glorot	O
x	O
and	O
bengio	O
y	O
contractive	O
icml	O
auto-encoders	O
explicit	O
invariance	B
during	O
feature	B
extraction	O
in	O
rifai	O
s	O
mesnil	O
g	O
vincent	O
p	O
muller	O
x	O
bengio	O
y	O
dauphin	O
y	O
and	O
glorot	O
x	O
higher	O
order	O
contractive	O
auto-encoder	O
in	O
ecml	O
pkdd	O
rifai	O
s	O
dauphin	O
y	O
vincent	O
p	O
bengio	O
y	O
and	O
muller	O
x	O
the	O
manifold	B
tangent	I
classifier	I
in	O
nips	O
rifai	O
s	O
bengio	O
y	O
dauphin	O
y	O
and	O
vincent	O
p	O
a	O
generative	O
process	O
for	O
sampling	O
contractive	O
auto-encoders	O
in	O
icml	O
ringach	O
d	O
and	O
shapley	O
r	O
reverse	O
correlation	B
in	O
neurophysiology	O
cognitive	O
science	O
roberts	O
s	O
and	O
everson	O
r	O
independent	B
component	I
analysis	I
principles	O
and	O
practice	O
cambridge	O
university	O
press	O
robinson	O
a	O
j	O
and	O
fallside	O
f	O
a	O
recurrent	O
error	O
propagation	O
network	O
speech	O
recognition	O
system	O
computer	O
speech	O
and	O
language	O
rockafellar	O
r	O
t	O
convex	O
analysis	O
princeton	O
landmarks	O
in	O
mathematics	O
romero	O
a	O
ballas	O
n	O
ebrahimi	O
kahou	O
s	O
chassang	O
a	O
gatta	O
c	O
and	O
bengio	O
y	O
fitnets	O
hints	O
for	O
thin	O
deep	O
nets	O
in	O
iclr	O
rosen	O
j	O
b	O
the	O
gradient	B
projection	O
method	O
for	O
nonlinear	O
programming	O
part	O
i	O
linear	O
constraints	O
journal	O
of	O
the	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
pp	O
rosenblatt	O
f	O
the	O
perceptron	O
a	O
probabilistic	O
model	O
for	O
information	O
storage	O
and	O
organization	O
in	O
the	O
brain	O
psychological	O
review	O
rosenblatt	O
f	O
principles	O
of	O
neurodynamics	O
spartan	O
new	O
york	O
roweis	O
s	O
and	O
saul	O
l	O
k	O
nonlinear	O
dimensionality	O
reduction	O
by	O
locally	O
linear	O
embedding	B
science	O
roweis	O
s	O
saul	O
l	O
and	O
hinton	O
g	O
global	O
coordination	O
of	O
local	O
linear	O
models	O
in	O
t	O
dietterich	O
s	O
becker	O
and	O
z	O
ghahramani	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
cambridge	O
ma	O
mit	O
press	O
rubin	O
d	O
b	O
et	O
al	O
bayesianly	O
justifiable	O
and	O
relevant	O
frequency	O
calculations	O
for	O
the	O
applied	O
statistician	O
the	O
annals	O
of	O
statistics	O
bibliography	O
rumelhart	O
d	O
hinton	O
g	O
and	O
williams	O
r	O
learning	O
representations	O
by	O
back-propagating	O
errors	O
nature	O
rumelhart	O
d	O
e	O
hinton	O
g	O
e	O
and	O
williams	O
r	O
j	O
learning	O
internal	O
representations	O
by	O
error	O
propagation	O
in	O
d	O
e	O
rumelhart	O
and	O
j	O
l	O
mcclelland	O
editors	O
parallel	B
distributed	I
processing	I
volume	O
chapter	O
pages	O
mit	O
press	O
cambridge	O
rumelhart	O
d	O
e	O
mcclelland	O
j	O
l	O
and	O
the	O
pdp	O
research	O
group	O
parallel	B
distributed	I
processing	I
explorations	O
in	O
the	O
microstructure	O
of	O
cognition	O
mit	O
press	O
cambridge	O
russakovsky	O
o	O
deng	O
j	O
su	O
h	O
krause	O
j	O
satheesh	O
s	O
ma	O
s	O
huang	O
z	O
karpathy	O
a	O
khosla	O
a	O
bernstein	O
m	O
berg	O
a	O
c	O
and	O
fei-fei	O
l	O
imagenet	O
large	O
scale	O
visual	O
recognition	O
challenge	B
russakovsky	O
o	O
deng	O
j	O
su	O
h	O
krause	O
j	O
satheesh	O
s	O
ma	O
s	O
huang	O
z	O
karpathy	O
imagenet	O
large	O
scale	O
visual	O
recognition	O
et	O
al	O
a	O
khosla	O
a	O
bernstein	O
m	O
challenge	B
arxiv	O
preprint	O
russel	O
s	O
j	O
and	O
norvig	O
p	O
artificial	B
intelligence	I
a	O
modern	O
approach	O
prentice	O
hall	O
rust	O
n	O
schwartz	O
o	O
movshon	O
j	O
a	O
and	O
simoncelli	O
e	O
spatiotemporal	O
elements	O
of	O
macaque	O
receptive	O
fields	O
neuron	O
sainath	O
t	O
mohamed	O
a	O
kingsbury	O
b	O
and	O
ramabhadran	O
b	O
deep	O
convolu	O
tional	O
neural	O
networks	O
for	O
lvcsr	O
in	O
icassp	O
salakhutdinov	O
r	O
learning	O
in	O
markov	O
random	O
fields	O
using	O
tempered	O
transitions	O
in	O
y	O
bengio	O
d	O
schuurmans	O
c	O
williams	O
j	O
lafferty	O
and	O
a	O
culotta	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
salakhutdinov	O
r	O
and	O
hinton	O
g	O
deep	O
boltzmann	O
machines	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
volume	O
pages	O
salakhutdinov	O
r	O
and	O
hinton	O
g	O
semantic	B
hashing	I
in	O
international	O
journal	O
of	O
approximate	O
reasoning	O
salakhutdinov	O
r	O
and	O
hinton	O
g	O
e	O
learning	O
a	O
nonlinear	O
embedding	B
by	O
preserving	O
class	O
neighbourhood	O
structure	O
in	O
proceedings	O
of	O
the	O
eleventh	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
san	O
juan	O
porto	O
rico	O
omnipress	O
salakhutdinov	O
r	O
and	O
hinton	O
g	O
e	O
semantic	B
hashing	I
in	O
sigir	O
bibliography	O
salakhutdinov	O
r	O
and	O
hinton	O
g	O
e	O
using	O
deep	O
belief	O
nets	O
to	O
learn	O
covariance	O
kernels	O
for	O
gaussian	O
processes	O
in	O
j	O
platt	O
d	O
koller	O
y	O
singer	O
and	O
s	O
roweis	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
cambridge	O
ma	O
mit	O
press	O
salakhutdinov	O
r	O
and	O
larochelle	O
h	O
efficient	O
learning	O
of	O
deep	O
boltzmann	O
machines	O
in	O
proceedings	O
of	O
the	O
thirteenth	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
jmlr	O
wcp	O
volume	O
pages	O
salakhutdinov	O
r	O
and	O
mnih	O
a	O
probabilistic	O
matrix	O
factorization	O
in	O
nips	O
salakhutdinov	O
r	O
and	O
murray	O
i	O
on	O
the	O
quantitative	O
analysis	O
of	O
deep	O
belief	O
networks	O
in	O
w	O
w	O
cohen	O
a	O
mccallum	O
and	O
s	O
t	O
roweis	O
editors	O
proceedings	O
of	O
the	O
twenty-fifth	O
international	O
conference	O
on	O
machine	B
learning	I
volume	O
pages	O
acm	O
salakhutdinov	O
r	O
mnih	O
a	O
and	O
hinton	O
g	O
restricted	O
boltzmann	O
machines	O
for	O
collaborative	B
filtering	I
in	O
icml	O
sanger	O
t	O
d	O
neural	B
network	I
learning	O
control	O
of	O
robot	O
manipulators	O
using	O
gradually	O
increasing	O
task	O
difficulty	O
ieee	O
transactions	O
on	O
robotics	O
and	O
automation	O
saul	O
l	O
k	O
and	O
jordan	O
m	O
i	O
exploiting	O
tractable	O
substructures	O
in	O
intractable	O
networks	O
in	O
d	O
touretzky	O
m	O
mozer	O
and	O
m	O
hasselmo	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
mit	O
press	O
cambridge	O
ma	O
saul	O
l	O
k	O
jaakkola	O
t	O
and	O
jordan	O
m	O
i	O
mean	O
field	O
theory	O
for	O
sigmoid	O
belief	O
networks	O
journal	O
of	O
artificial	B
intelligence	I
research	O
savich	O
a	O
w	O
moussa	O
m	O
and	O
areibi	O
s	O
the	O
impact	O
of	O
arithmetic	O
representation	O
on	O
implementing	O
mlp-bp	O
on	O
fpgas	O
a	O
study	O
neural	O
networks	O
ieee	O
transactions	O
on	O
saxe	O
a	O
m	O
koh	O
p	O
w	O
chen	O
z	O
bhand	O
m	O
suresh	O
b	O
and	O
ng	O
a	O
on	O
random	O
weights	B
and	O
unsupervised	O
feature	B
learning	O
in	O
proc	O
icml	O
acm	O
saxe	O
a	O
m	O
mcclelland	O
j	O
l	O
and	O
ganguli	O
s	O
exact	O
solutions	O
to	O
the	O
nonlinear	O
dynamics	O
of	O
learning	O
in	O
deep	O
linear	O
neural	O
networks	O
in	O
iclr	O
schaul	O
t	O
antonoglou	O
i	O
and	O
silver	O
d	O
unit	O
tests	O
for	O
stochastic	O
optimization	O
in	O
international	O
conference	O
on	O
learning	O
representations	O
schmidhuber	O
j	O
learning	O
complex	O
extended	O
sequences	O
using	O
the	O
principle	O
of	O
history	O
compression	O
neural	O
computation	O
schmidhuber	O
j	O
sequential	O
neural	O
text	O
compression	O
ieee	O
transactions	O
on	O
neural	O
networks	O
bibliography	O
schmidhuber	O
j	O
self-delimiting	O
neural	O
networks	O
arxiv	O
preprint	O
sch	O
lkopf	O
b	O
and	O
smola	O
a	O
j	O
learning	O
with	O
kernels	O
support	O
vector	O
machines	O
regularization	O
optimization	O
and	O
beyond	O
mit	O
press	O
sch	O
lkopf	O
b	O
smola	O
a	O
and	O
m	O
ller	O
k	O
-r	O
nonlinear	O
component	O
analysis	O
as	O
a	O
kernel	O
eigenvalue	B
problem	O
neural	O
computation	O
sch	O
lkopf	O
b	O
burges	O
c	O
j	O
c	O
and	O
smola	O
a	O
j	O
advances	O
in	O
kernel	O
methods	O
support	O
vector	O
learning	O
mit	O
press	O
cambridge	O
ma	O
sch	O
lkopf	O
b	O
janzing	O
d	O
peters	O
j	O
sgouritsa	O
e	O
zhang	O
k	O
and	O
mooij	O
j	O
on	O
causal	O
and	O
anticausal	O
learning	O
in	O
icml	O
pages	O
schuster	O
m	O
on	O
supervised	B
learning	I
from	O
sequential	O
data	O
with	O
applications	O
for	O
speech	O
recognition	O
schuster	O
m	O
and	O
paliwal	O
k	O
bidirectional	O
recurrent	O
neural	O
networks	O
ieee	O
transactions	O
on	O
signal	O
processing	O
schwenk	O
h	O
continuous	O
space	O
language	O
models	O
computer	O
speech	O
and	O
language	O
schwenk	O
h	O
continuous	O
space	O
language	O
models	O
for	O
statistical	O
machine	B
translation	I
the	O
prague	O
bulletin	O
of	O
mathematical	O
linguistics	O
schwenk	O
h	O
cleaned	O
subset	O
of	O
wmt	O
dataset	B
schwenk	O
h	O
and	O
bengio	O
y	O
training	O
methods	O
for	O
adaptive	O
boosting	O
of	O
neural	O
networks	O
in	O
m	O
jordan	O
m	O
kearns	O
and	O
s	O
solla	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
schwenk	O
h	O
and	O
gauvain	O
j	O
-l	O
connectionist	O
language	O
modeling	O
for	O
large	O
vocabulary	O
continuous	O
speech	O
recognition	O
in	O
international	O
conference	O
on	O
acoustics	O
speech	O
and	O
signal	O
processing	O
pages	O
orlando	O
florida	O
schwenk	O
h	O
costa-juss	O
m	O
r	O
and	O
fonollosa	O
j	O
a	O
r	O
continuous	O
space	O
in	O
international	O
workshop	O
on	O
spoken	O
language	O
models	O
for	O
the	O
iwslt	O
task	O
language	O
translation	O
pages	O
seide	O
f	O
li	O
g	O
and	O
yu	O
d	O
conversational	O
speech	O
transcription	B
using	O
context	O
dependent	O
deep	O
neural	O
networks	O
in	O
interspeech	O
pages	O
sejnowski	O
t	O
higher-order	O
boltzmann	O
machines	O
in	O
aip	O
conference	O
proceedings	O
on	O
neural	O
networks	O
for	O
computing	O
pages	O
american	O
institute	O
of	O
physics	O
inc	O
bibliography	O
series	O
p	O
reichert	O
d	O
p	O
and	O
storkey	O
a	O
j	O
hallucinations	O
in	O
charles	O
bonnet	O
syndrome	O
induced	O
by	O
homeostasis	O
a	O
deep	O
boltzmann	O
machine	O
model	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
sermanet	O
p	O
chintala	O
s	O
and	O
lecun	O
y	O
convolutional	O
neural	O
networks	O
applied	O
to	O
house	O
numbers	O
digit	O
classification	B
corr	O
sermanet	O
p	O
kavukcuoglu	O
k	O
chintala	O
s	O
and	O
lecun	O
y	O
pedestrian	O
detection	O
with	O
unsupervised	O
multi-stage	O
feature	B
learning	O
in	O
proc	O
international	O
conference	O
on	O
computer	B
vision	I
and	O
pattern	O
recognition	O
ieee	O
shilov	O
g	O
linear	O
algebra	O
dover	O
books	O
on	O
mathematics	O
series	O
dover	O
publications	O
siegelmann	O
h	O
computation	O
beyond	O
the	O
turing	O
limit	O
science	O
siegelmann	O
h	O
and	O
sontag	O
e	O
turing	O
computability	O
with	O
neural	O
nets	O
applied	O
mathematics	O
letters	O
siegelmann	O
h	O
t	O
and	O
sontag	O
e	O
d	O
on	O
the	O
computational	O
power	O
of	O
neural	O
nets	O
journal	O
of	O
computer	O
and	O
systems	O
sciences	O
sietsma	O
j	O
and	O
dow	O
r	O
creating	O
artificial	O
neural	O
networks	O
that	O
generalize	O
neural	O
networks	O
simard	O
d	O
steinkraus	O
p	O
y	O
and	O
platt	O
j	O
c	O
best	O
practices	O
for	O
convolutional	O
neural	O
networks	O
in	O
icdar	O
simard	O
p	O
and	O
graf	O
h	O
p	O
backpropagation	O
without	O
multiplication	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
simard	O
p	O
victorri	O
b	O
lecun	O
y	O
and	O
denker	O
j	O
tangent	B
prop	I
a	O
formalism	O
nips	O
for	O
specifying	O
selected	O
invariances	O
in	O
an	O
adaptive	O
network	O
in	O
simard	O
p	O
y	O
lecun	O
y	O
and	O
denker	O
j	O
efficient	O
pattern	O
recognition	O
using	O
a	O
new	O
transformation	O
distance	O
in	O
nips	O
simard	O
p	O
y	O
lecun	O
y	O
a	O
denker	O
j	O
s	O
and	O
victorri	O
b	O
transformation	O
invariance	B
in	O
pattern	O
recognition	O
tangent	B
distance	I
and	O
tangent	O
propagation	O
lecture	O
notes	O
in	O
computer	O
science	O
simons	O
d	O
j	O
and	O
levin	O
d	O
t	O
failure	O
to	O
detect	O
changes	O
to	O
people	O
during	O
a	O
real-world	O
interaction	O
psychonomic	O
bulletin	O
review	O
simonyan	O
k	O
and	O
zisserman	O
a	O
very	O
deep	O
convolutional	O
networks	O
for	O
large-scale	O
image	O
recognition	O
in	O
iclr	O
bibliography	O
sj	O
berg	O
j	O
and	O
ljung	O
l	O
overtraining	O
regularization	O
and	O
searching	O
for	O
a	O
minimum	O
with	O
application	O
to	O
neural	O
networks	O
international	O
journal	O
of	O
control	O
skinner	O
b	O
f	O
reinforcement	O
today	O
american	O
psychologist	O
smolensky	O
p	O
information	O
processing	O
in	O
dynamical	O
systems	O
foundations	O
of	O
harmony	B
theory	I
in	O
d	O
e	O
rumelhart	O
and	O
j	O
l	O
mcclelland	O
editors	O
parallel	B
distributed	I
processing	I
volume	O
chapter	O
pages	O
mit	O
press	O
cambridge	O
snoek	O
j	O
larochelle	O
h	O
and	O
adams	O
r	O
p	O
practical	O
bayesian	O
optimization	O
of	O
machine	B
learning	I
algorithms	O
in	O
nips	O
socher	O
r	O
huang	O
e	O
h	O
pennington	O
j	O
ng	O
a	O
y	O
and	O
manning	O
c	O
d	O
dynamic	O
nips	O
pooling	O
and	O
unfolding	O
recursive	O
autoencoders	O
for	O
paraphrase	O
detection	O
in	O
socher	O
r	O
manning	O
c	O
and	O
ng	O
a	O
y	O
parsing	O
natural	O
scenes	O
and	O
natural	O
language	O
with	O
recursive	O
neural	O
networks	O
in	O
proceedings	O
of	O
the	O
twenty-eighth	O
international	O
conference	O
on	O
machine	B
learning	I
socher	O
r	O
pennington	O
j	O
huang	O
e	O
h	O
ng	O
a	O
y	O
and	O
manning	O
c	O
d	O
in	O
semi-supervised	O
recursive	O
autoencoders	O
for	O
predicting	O
sentiment	O
distributions	O
emnlp	O
socher	O
r	O
perelygin	O
a	O
wu	O
j	O
y	O
chuang	O
j	O
manning	O
c	O
d	O
ng	O
a	O
y	O
and	O
potts	O
c	O
recursive	O
deep	O
models	O
for	O
semantic	O
compositionality	O
over	O
a	O
sentiment	O
treebank	O
in	O
emnlp	O
socher	O
r	O
ganjoo	O
m	O
manning	O
c	O
d	O
and	O
ng	O
a	O
y	O
zero-shot	B
learning	I
through	O
cross-modal	O
transfer	O
in	O
annual	O
conference	O
on	O
neural	O
information	O
processing	O
systems	O
sohl-dickstein	O
j	O
weiss	O
e	O
a	O
maheswaranathan	O
n	O
and	O
ganguli	O
s	O
deep	O
unsupervised	O
learning	O
using	O
nonequilibrium	O
thermodynamics	O
sohn	O
k	O
zhou	O
g	O
and	O
lee	O
h	O
learning	O
and	O
selecting	O
features	O
jointly	O
with	O
point-wise	O
gated	O
boltzmann	O
machines	O
in	O
icml	O
solomonoff	O
r	O
j	O
a	O
system	O
for	O
incremental	O
learning	O
based	O
on	O
algorithmic	O
proba	O
bility	O
sontag	O
e	O
d	O
vc	O
dimension	O
of	O
neural	O
networks	O
nato	O
asi	O
series	O
f	O
computer	O
and	O
systems	O
sciences	O
sontag	O
e	O
d	O
and	O
sussman	O
h	O
j	O
backpropagation	O
can	O
give	O
rise	O
to	O
spurious	O
local	O
minima	O
even	O
for	O
networks	O
without	O
hidden	O
layers	O
complex	O
systems	O
bibliography	O
sparkes	O
b	O
the	O
red	O
and	O
the	O
black	O
studies	O
in	O
greek	O
pottery	O
routledge	O
spitkovsky	O
v	O
i	O
alshawi	O
h	O
and	O
jurafsky	O
d	O
from	O
baby	O
steps	O
to	O
leapfrog	O
how	O
less	O
is	O
more	O
in	O
unsupervised	O
dependency	O
parsing	O
in	O
hlt	O
squire	O
w	O
and	O
trapp	O
g	O
using	O
complex	O
variables	O
to	O
estimate	O
derivatives	O
of	O
real	O
functions	O
siam	O
rev	O
srebro	O
n	O
and	O
shraibman	O
a	O
rank	O
trace-norm	O
and	O
max-norm	O
in	O
proceedings	O
of	O
the	O
annual	O
conference	O
on	O
learning	O
theory	O
pages	O
springer-verlag	O
srivastava	O
n	O
improving	O
neural	O
networks	O
with	O
dropout	O
master	O
s	O
thesis	O
u	O
toronto	O
srivastava	O
n	O
and	O
salakhutdinov	O
r	O
multimodal	O
learning	O
with	O
deep	O
boltzmann	O
machines	O
in	O
nips	O
srivastava	O
n	O
salakhutdinov	O
r	O
r	O
and	O
hinton	O
g	O
e	O
modeling	O
documents	O
with	O
deep	O
boltzmann	O
machines	O
arxiv	O
preprint	O
srivastava	O
n	O
hinton	O
g	O
krizhevsky	O
a	O
sutskever	O
i	O
and	O
salakhutdinov	O
r	O
dropout	O
a	O
simple	O
way	O
to	O
prevent	O
neural	O
networks	O
from	O
overfitting	O
journal	O
of	O
machine	B
learning	I
research	O
srivastava	O
r	O
k	O
greff	O
k	O
and	O
schmidhuber	O
j	O
highway	O
networks	O
steinkrau	O
d	O
simard	O
p	O
y	O
and	O
buck	O
i	O
using	O
gpus	O
for	O
machine	B
learning	I
algorithms	O
international	O
conference	O
on	O
document	O
analysis	O
and	O
recognition	O
stoyanov	O
v	O
ropson	O
a	O
and	O
eisner	O
j	O
empirical	B
risk	B
minimization	I
of	O
graphical	O
model	O
parameters	O
given	O
approximate	B
inference	I
decoding	O
and	O
model	O
structure	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
pages	O
fort	O
lauderdale	O
supplementary	O
material	O
pages	O
also	O
available	O
jmlr	O
workshop	O
and	O
conference	O
proceedings	O
volume	O
of	O
sukhbaatar	O
s	O
szlam	O
a	O
weston	O
j	O
and	O
fergus	O
r	O
weakly	O
supervised	O
memory	O
networks	O
arxiv	O
preprint	O
supancic	O
j	O
and	O
ramanan	O
d	O
self-paced	O
learning	O
for	O
long-term	O
tracking	O
in	O
cvpr	O
sussillo	O
d	O
random	O
walks	O
training	O
very	O
deep	O
nonlinear	O
feed-forward	O
networks	O
with	O
smart	O
initialization	B
corr	O
sutskever	O
i	O
training	O
recurrent	O
neural	O
networks	O
ph	O
d	O
thesis	O
department	O
of	O
computer	O
science	O
university	O
of	O
toronto	O
bibliography	O
sutskever	O
i	O
and	O
hinton	O
g	O
e	O
deep	O
narrow	O
sigmoid	O
belief	O
networks	O
are	O
universal	O
approximators	O
neural	O
computation	O
sutskever	O
i	O
and	O
tieleman	O
t	O
on	O
the	O
convergence	O
properties	O
of	O
contrastive	O
divergence	O
in	O
y	O
w	O
teh	O
and	O
m	O
titterington	O
editors	O
proc	O
of	O
the	O
international	O
conference	O
on	O
artificial	B
intelligence	I
and	O
statistics	O
volume	O
pages	O
sutskever	O
i	O
hinton	O
g	O
and	O
taylor	O
g	O
the	O
recurrent	O
temporal	O
restricted	O
boltzmann	O
machine	O
in	O
nips	O
sutskever	O
i	O
martens	O
j	O
and	O
hinton	O
g	O
e	O
generating	O
text	O
with	O
recurrent	O
neural	O
networks	O
in	O
icml	O
pages	O
sutskever	O
i	O
martens	O
j	O
dahl	O
g	O
and	O
hinton	O
g	O
on	O
the	O
importance	O
of	O
initialization	B
and	O
momentum	O
in	O
deep	O
learning	O
in	O
icml	O
sutskever	O
i	O
vinyals	O
o	O
and	O
le	O
q	O
v	O
sequence	O
to	O
sequence	O
learning	O
with	O
neural	O
networks	O
in	O
nips	O
sutton	O
r	O
and	O
barto	O
a	O
reinforcement	O
learning	O
an	O
introduction	O
mit	O
press	O
sutton	O
r	O
s	O
mcallester	O
d	O
singh	O
s	O
and	O
mansour	O
y	O
policy	B
gradient	B
methods	O
pages	O
for	O
reinforcement	O
learning	O
with	O
function	O
approximation	O
in	O
mit	O
press	O
nips	O
swersky	O
k	O
ranzato	O
m	O
buchman	O
d	O
marlin	O
b	O
and	O
de	O
freitas	O
n	O
on	O
autoencoders	O
and	O
score	O
matching	O
for	O
energy	O
based	O
models	O
in	O
icml	O
acm	O
swersky	O
k	O
snoek	O
j	O
and	O
adams	O
r	O
p	O
freeze-thaw	O
bayesian	O
optimization	O
arxiv	O
preprint	O
szegedy	O
c	O
liu	O
w	O
jia	O
y	O
sermanet	O
p	O
reed	O
s	O
anguelov	O
d	O
erhan	O
d	O
vanhoucke	O
v	O
and	O
rabinovich	O
a	O
going	O
deeper	O
with	O
convolutions	O
technical	O
report	O
szegedy	O
c	O
zaremba	O
w	O
sutskever	O
i	O
bruna	O
j	O
erhan	O
d	O
goodfellow	O
i	O
j	O
and	O
iclr	O
fergus	O
r	O
intriguing	O
properties	O
of	O
neural	O
networks	O
szegedy	O
c	O
vanhoucke	O
v	O
ioffe	O
s	O
shlens	O
j	O
and	O
wojna	O
z	O
rethinking	O
the	O
inception	O
architecture	O
for	O
computer	B
vision	I
arxiv	O
e-prints	O
taigman	O
y	O
yang	O
m	O
ranzato	O
m	O
and	O
wolf	O
l	O
deepface	O
closing	O
the	O
gap	O
to	O
human-level	O
performance	O
in	O
face	O
verification	O
in	O
cvpr	O
tandy	O
d	O
w	O
works	O
and	O
days	O
a	O
translation	O
and	O
commentary	O
for	O
the	O
social	O
sciences	O
university	O
of	O
california	O
press	O
bibliography	O
tang	O
y	O
and	O
eliasmith	O
c	O
deep	O
networks	O
for	O
robust	O
visual	O
recognition	O
in	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
machine	B
learning	I
june	O
haifa	O
israel	O
tang	O
y	O
salakhutdinov	O
r	O
and	O
hinton	O
g	O
deep	O
mixtures	O
of	O
factor	O
analysers	O
arxiv	O
preprint	O
taylor	O
g	O
and	O
hinton	O
g	O
factored	O
conditional	O
restricted	O
boltzmann	O
machines	O
for	O
modeling	O
motion	O
style	O
in	O
l	O
bottou	O
and	O
m	O
littman	O
editors	O
proceedings	O
of	O
the	O
twenty-sixth	O
international	O
conference	O
on	O
machine	B
learning	I
pages	O
montreal	O
quebec	O
canada	O
acm	O
taylor	O
g	O
hinton	O
g	O
e	O
and	O
roweis	O
s	O
modeling	O
human	O
motion	O
using	O
binary	O
latent	O
variables	O
in	O
b	O
sch	O
lkopf	O
j	O
platt	O
and	O
t	O
hoffman	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
cambridge	O
ma	O
teh	O
y	O
welling	O
m	O
osindero	O
s	O
and	O
hinton	O
g	O
e	O
energy-based	O
models	O
for	O
sparse	O
overcomplete	O
representations	O
journal	O
of	O
machine	B
learning	I
research	O
tenenbaum	O
j	O
de	O
silva	O
v	O
and	O
langford	O
j	O
c	O
a	O
global	O
geometric	O
framework	O
for	O
nonlinear	O
dimensionality	O
reduction	O
science	O
theis	O
l	O
van	O
den	O
oord	O
a	O
and	O
bethge	O
m	O
a	O
note	O
on	O
the	O
evaluation	O
of	O
generative	O
models	O
thompson	O
j	O
jain	O
a	O
lecun	O
y	O
and	O
bregler	O
c	O
joint	O
training	O
of	O
a	O
convolutional	B
network	I
and	O
a	O
graphical	O
model	O
for	O
human	O
pose	O
estimation	O
in	O
nips	O
thrun	O
s	O
learning	O
to	O
play	O
the	O
game	O
of	O
chess	B
in	O
nips	O
tibshirani	O
r	O
j	O
regression	B
shrinkage	O
and	O
selection	O
via	O
the	O
lasso	O
journal	O
of	O
the	O
royal	O
statistical	O
society	O
b	O
tieleman	O
t	O
training	O
restricted	O
boltzmann	O
machines	O
using	O
approximations	O
to	O
the	O
likelihood	O
gradient	B
in	O
w	O
w	O
cohen	O
a	O
mccallum	O
and	O
s	O
t	O
roweis	O
editors	O
proceedings	O
of	O
the	O
twenty-fifth	O
international	O
conference	O
on	O
machine	B
learning	I
pages	O
acm	O
tieleman	O
t	O
and	O
hinton	O
g	O
using	O
fast	O
weights	B
to	O
improve	O
persistent	O
contrastive	O
divergence	O
in	O
l	O
bottou	O
and	O
m	O
littman	O
editors	O
proceedings	O
of	O
the	O
twenty-sixth	O
international	O
conference	O
on	O
machine	B
learning	I
pages	O
acm	O
tipping	O
m	O
e	O
and	O
bishop	O
c	O
m	O
probabilistic	O
principal	O
components	O
analysis	O
journal	O
of	O
the	O
royal	O
statistical	O
society	O
b	O
bibliography	O
torralba	O
a	O
fergus	O
r	O
and	O
weiss	O
y	O
small	O
codes	O
and	O
large	O
databases	O
for	O
recognition	O
in	O
proceedings	O
of	O
the	O
computer	B
vision	I
and	O
pattern	O
recognition	O
conference	O
pages	O
touretzky	O
d	O
s	O
and	O
minton	O
g	O
e	O
symbols	O
among	O
the	O
neurons	O
details	O
of	O
a	O
connectionist	O
inference	O
architecture	O
in	O
proceedings	O
of	O
the	O
international	O
joint	O
conference	O
on	O
artificial	B
intelligence	I
volume	O
ijcai	O
pages	O
san	O
francisco	O
ca	O
usa	O
morgan	O
kaufmann	O
publishers	O
inc	O
tu	O
k	O
and	O
honavar	O
v	O
on	O
the	O
utility	O
of	O
curricula	O
in	O
unsupervised	O
learning	O
of	O
probabilistic	O
grammars	O
in	O
ijcai	O
turaga	O
s	O
c	O
murray	O
j	O
f	O
jain	O
v	O
roth	O
f	O
helmstaedter	O
m	O
briggman	O
k	O
denk	O
w	O
and	O
seung	O
h	O
s	O
convolutional	O
networks	O
can	O
learn	O
to	O
generate	O
affinity	O
graphs	O
for	O
image	O
segmentation	O
neural	O
computation	O
turian	O
j	O
ratinov	O
l	O
and	O
bengio	O
y	O
word	O
representations	O
a	O
simple	O
and	O
general	O
method	O
for	O
semi-supervised	B
learning	I
in	O
proc	O
acl	O
pages	O
t	O
scher	O
a	O
jahrer	O
m	O
and	O
bell	O
r	O
m	O
the	O
bigchaos	O
solution	O
to	O
the	O
netflix	O
grand	O
prize	O
uria	O
b	O
murray	O
i	O
and	O
larochelle	O
h	O
rnade	O
the	O
real-valued	O
neural	O
autoregres	O
sive	O
density-estimator	O
in	O
nips	O
van	O
den	O
o	O
rd	O
a	O
dieleman	O
s	O
and	O
schrauwen	O
b	O
deep	O
content-based	O
music	O
recommendation	O
in	O
nips	O
van	O
der	O
maaten	O
l	O
and	O
hinton	O
g	O
e	O
visualizing	O
data	O
using	O
t-sne	O
j	O
machine	B
learning	I
res	O
vanhoucke	O
v	O
senior	O
a	O
and	O
mao	O
m	O
z	O
improving	O
the	O
speed	O
of	O
neural	O
networks	O
on	O
cpus	O
in	O
proc	O
deep	O
learning	O
and	O
unsupervised	O
feature	B
learning	O
nips	O
workshop	O
vapnik	O
v	O
n	O
estimation	O
of	O
dependences	O
based	O
on	O
empirical	O
data	O
springer	O
verlag	O
berlin	O
vapnik	O
v	O
n	O
the	O
nature	O
of	O
statistical	B
learning	I
theory	I
springer	O
new	O
york	O
vapnik	O
v	O
n	O
and	O
chervonenkis	O
a	O
y	O
on	O
the	O
uniform	O
convergence	O
of	O
relative	O
frequencies	O
of	O
events	O
to	O
their	O
probabilities	O
theory	O
of	O
probability	O
and	O
its	O
applications	O
vincent	O
p	O
a	O
connection	O
between	O
score	O
matching	O
and	O
denoising	O
autoencoders	O
neural	O
computation	O
bibliography	O
vincent	O
p	O
and	O
bengio	O
y	O
manifold	B
parzen	O
windows	O
in	O
nips	O
mit	O
press	O
vincent	O
p	O
larochelle	O
h	O
bengio	O
y	O
and	O
manzagol	O
p	O
-a	O
extracting	O
and	O
composing	O
robust	O
features	O
with	O
denoising	O
autoencoders	O
in	O
icml	O
vincent	O
p	O
larochelle	O
h	O
lajoie	O
i	O
bengio	O
y	O
and	O
manzagol	O
p	O
-a	O
stacked	O
denoising	O
autoencoders	O
learning	O
useful	O
representations	O
in	O
a	O
deep	O
network	O
with	O
a	O
local	O
denoising	O
criterion	O
j	O
machine	B
learning	I
res	O
vincent	O
p	O
de	O
br	O
bisson	O
a	O
and	O
bouthillier	O
x	O
efficient	O
exact	O
gradient	B
update	O
for	O
training	O
deep	O
networks	O
with	O
very	O
large	O
sparse	O
targets	O
in	O
c	O
cortes	O
n	O
d	O
lawrence	O
d	O
d	O
lee	O
m	O
sugiyama	O
and	O
r	O
garnett	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
curran	O
associates	O
inc	O
vinyals	O
o	O
kaiser	O
l	O
koo	O
t	O
petrov	O
s	O
sutskever	O
i	O
and	O
hinton	O
g	O
grammar	O
as	O
a	O
foreign	O
language	O
technical	O
report	O
vinyals	O
o	O
toshev	O
a	O
bengio	O
s	O
and	O
erhan	O
d	O
show	O
and	O
tell	O
a	O
neural	O
image	O
caption	O
generator	O
arxiv	O
vinyals	O
o	O
fortunato	O
m	O
and	O
jaitly	O
n	O
pointer	O
networks	O
arxiv	O
preprint	O
vinyals	O
o	O
toshev	O
a	O
bengio	O
s	O
and	O
erhan	O
d	O
show	O
and	O
tell	O
a	O
neural	O
image	O
caption	O
generator	O
in	O
cvpr	O
viola	O
p	O
and	O
jones	O
m	O
robust	O
real-time	O
object	B
detection	I
in	O
international	O
journal	O
of	O
computer	B
vision	I
visin	O
f	O
kastner	O
k	O
cho	O
k	O
matteucci	O
m	O
courville	O
a	O
and	O
bengio	O
y	O
renet	O
a	O
recurrent	B
neural	B
network	I
based	O
alternative	O
to	O
convolutional	O
networks	O
arxiv	O
preprint	O
von	O
melchner	O
l	O
pallas	O
s	O
l	O
and	O
sur	O
m	O
visual	O
behaviour	O
mediated	O
by	O
retinal	O
projections	O
directed	O
to	O
the	O
auditory	O
pathway	O
nature	O
wager	O
s	O
wang	O
s	O
and	O
liang	O
p	O
dropout	O
training	O
as	O
adaptive	O
regularization	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
waibel	O
a	O
hanazawa	O
t	O
hinton	O
g	O
e	O
shikano	O
k	O
and	O
lang	O
k	O
phoneme	O
recognition	O
using	O
time-delay	O
neural	O
networks	O
ieee	O
transactions	O
on	O
acoustics	O
speech	O
and	O
signal	O
processing	O
wan	O
l	O
zeiler	O
m	O
zhang	O
s	O
lecun	O
y	O
and	O
fergus	O
r	O
regularization	O
of	O
neural	O
networks	O
using	O
dropconnect	B
in	O
icml	O
wang	O
s	O
and	O
manning	O
c	O
fast	O
dropout	O
training	O
in	O
icml	O
bibliography	O
wang	O
z	O
zhang	O
j	O
feng	O
j	O
and	O
chen	O
z	O
knowledge	O
graph	O
and	O
text	O
jointly	O
embedding	B
in	O
proc	O
emnlp	O
wang	O
z	O
zhang	O
j	O
feng	O
j	O
and	O
chen	O
z	O
knowledge	O
graph	O
embedding	B
by	O
translating	O
on	O
hyperplanes	O
in	O
proc	O
aaai	O
warde-farley	O
d	O
goodfellow	O
i	O
j	O
courville	O
a	O
and	O
bengio	O
y	O
an	O
empirical	O
analysis	O
of	O
dropout	O
in	O
piecewise	O
linear	O
networks	O
in	O
iclr	O
wawrzynek	O
j	O
asanovic	O
k	O
kingsbury	O
b	O
johnson	O
d	O
beck	O
j	O
and	O
morgan	O
n	O
spert-ii	O
a	O
vector	O
microprocessor	O
system	O
computer	O
weaver	O
l	O
and	O
tao	O
n	O
the	O
optimal	O
reward	O
baseline	O
for	O
gradient-based	O
reinforce	B
ment	O
learning	O
in	O
proc	O
uai	O
pages	O
weinberger	O
k	O
q	O
and	O
saul	O
l	O
k	O
unsupervised	O
learning	O
of	O
image	O
manifolds	O
by	O
semidefinite	O
programming	O
in	O
cvpr	O
pages	O
weiss	O
y	O
torralba	O
a	O
and	O
fergus	O
r	O
spectral	O
hashing	O
in	O
nips	O
pages	O
welling	O
m	O
zemel	O
r	O
s	O
and	O
hinton	O
g	O
e	O
self	O
supervised	O
boosting	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
welling	O
m	O
hinton	O
g	O
e	O
and	O
osindero	O
s	O
learning	O
sparse	O
topographic	O
representations	O
with	O
products	O
of	O
student-t	O
distributions	O
in	O
nips	O
welling	O
m	O
zemel	O
r	O
and	O
hinton	O
g	O
e	O
self-supervised	O
boosting	O
in	O
s	O
becker	O
s	O
thrun	O
and	O
k	O
obermayer	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
welling	O
m	O
rosen-zvi	O
m	O
and	O
hinton	O
g	O
e	O
exponential	O
family	O
harmoniums	O
with	O
an	O
application	O
to	O
information	B
retrieval	I
in	O
l	O
saul	O
y	O
weiss	O
and	O
l	O
bottou	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
volume	O
cambridge	O
ma	O
mit	O
press	O
werbos	O
p	O
j	O
applications	O
of	O
advances	O
in	O
nonlinear	O
sensitivity	O
analysis	O
in	O
proceedings	O
of	O
the	O
ifip	O
conference	O
nyc	O
pages	O
weston	O
j	O
bengio	O
s	O
and	O
usunier	O
n	O
large	O
scale	O
image	O
annotation	O
learning	O
to	O
rank	O
with	O
joint	O
word-image	O
embeddings	O
machine	B
learning	I
weston	O
j	O
chopra	O
s	O
and	O
bordes	O
a	O
memory	O
networks	O
arxiv	O
preprint	O
widrow	O
b	O
and	O
hoff	O
m	O
e	O
adaptive	O
switching	O
circuits	O
in	O
ire	O
wescon	O
convention	O
record	O
volume	O
pages	O
ire	O
new	O
york	O
bibliography	O
wikipedia	O
list	O
of	O
animals	O
by	O
number	O
of	O
neurons	O
wikipedia	O
the	O
free	O
encyclopedia	O
accessed	O
williams	O
c	O
k	O
i	O
and	O
agakov	O
f	O
v	O
products	O
of	O
gaussians	O
and	O
probabilistic	O
minor	O
component	O
analysis	O
neural	O
computation	O
williams	O
c	O
k	O
i	O
and	O
rasmussen	O
c	O
e	O
gaussian	O
processes	O
for	O
regression	B
in	O
d	O
touretzky	O
m	O
mozer	O
and	O
m	O
hasselmo	O
editors	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
pages	O
mit	O
press	O
cambridge	O
ma	O
williams	O
r	O
j	O
simple	O
statistical	O
gradient-following	O
algorithms	O
connectionist	O
reinforcement	O
learning	O
machine	B
learning	I
williams	O
r	O
j	O
and	O
zipser	O
d	O
a	O
learning	O
algorithm	O
for	O
continually	O
running	O
fully	O
recurrent	O
neural	O
networks	O
neural	O
computation	O
wilson	O
d	O
r	O
and	O
martinez	O
t	O
r	O
the	O
general	O
inefficiency	O
of	O
batch	O
training	O
for	O
gradient	B
descent	O
learning	O
neural	O
networks	O
wilson	O
j	O
r	O
variance	O
reduction	O
techniques	O
for	O
digital	O
simulation	O
american	O
journal	O
of	O
mathematical	O
and	O
management	O
sciences	O
wiskott	O
l	O
and	O
sejnowski	O
t	O
j	O
slow	B
feature	B
analysis	I
unsupervised	O
learning	O
of	O
invariances	O
neural	O
computation	O
wolpert	O
d	O
and	O
macready	O
w	O
no	O
free	O
lunch	O
theorems	O
for	O
optimization	O
ieee	O
transactions	O
on	O
evolutionary	O
computation	O
wolpert	O
d	O
h	O
the	O
lack	O
of	O
a	O
priori	O
distinction	O
between	O
learning	O
algorithms	O
neural	O
computation	O
wu	O
r	O
yan	O
s	O
shan	O
y	O
dang	O
q	O
and	O
sun	O
g	O
deep	O
image	O
scaling	O
up	O
image	O
recognition	O
wu	O
z	O
global	O
continuation	O
for	O
distance	O
geometry	O
problems	O
siam	O
journal	O
of	O
optimization	O
xiong	O
h	O
y	O
barash	O
y	O
and	O
frey	O
b	O
j	O
bayesian	O
prediction	O
of	O
tissue-regulated	O
bioinformatics	O
splicing	O
using	O
rna	O
sequence	O
and	O
cellular	O
context	O
xu	O
k	O
ba	O
j	O
l	O
kiros	O
r	O
cho	O
k	O
courville	O
a	O
salakhutdinov	O
r	O
zemel	O
r	O
s	O
and	O
bengio	O
y	O
show	O
attend	O
and	O
tell	O
neural	O
image	O
caption	O
generation	O
with	O
visual	O
attention	O
in	O
icml	O
yildiz	O
i	O
b	O
jaeger	O
h	O
and	O
kiebel	O
s	O
j	O
re-visiting	O
the	O
echo	O
state	O
property	O
neural	O
networks	O
bibliography	O
yosinski	O
j	O
clune	O
j	O
bengio	O
y	O
and	O
lipson	O
h	O
how	O
transferable	O
are	O
features	O
in	O
deep	O
neural	O
networks	O
in	O
nips	O
younes	O
l	O
on	O
the	O
convergence	O
of	O
markovian	O
stochastic	O
algorithms	O
with	O
rapidly	O
decreasing	O
ergodicity	O
rates	O
in	O
stochastics	O
and	O
stochastics	O
models	O
pages	O
yu	O
d	O
wang	O
s	O
and	O
deng	O
l	O
sequential	O
labeling	O
using	O
deep-structured	O
conditional	O
random	O
fields	O
ieee	O
journal	O
of	O
selected	O
topics	O
in	O
signal	O
processing	O
zaremba	O
w	O
and	O
sutskever	O
i	O
learning	O
to	O
execute	O
arxiv	O
zaremba	O
w	O
and	O
sutskever	O
i	O
reinforcement	O
learning	O
neural	O
turing	O
machines	O
zaslavsky	O
t	O
facing	O
up	O
to	O
arrangements	O
face-count	O
formulas	O
for	O
partitions	O
of	O
space	O
by	O
hyperplanes	O
number	O
no	O
in	O
memoirs	O
of	O
the	O
american	O
mathematical	O
society	O
american	O
mathematical	O
society	O
zeiler	O
m	O
d	O
and	O
fergus	O
r	O
visualizing	O
and	O
understanding	O
convolutional	O
networks	O
in	O
eccv	O
zeiler	O
m	O
d	O
ranzato	O
m	O
monga	O
r	O
mao	O
m	O
yang	O
k	O
le	O
q	O
nguyen	O
p	O
senior	O
a	O
vanhoucke	O
v	O
dean	O
j	O
and	O
hinton	O
g	O
e	O
on	O
rectified	O
linear	O
units	O
for	O
speech	O
processing	O
in	O
icassp	O
zhou	O
b	O
khosla	O
a	O
lapedriza	O
a	O
oliva	O
a	O
and	O
torralba	O
a	O
object	O
detectors	O
emerge	O
in	O
deep	O
scene	O
cnns	O
iclr	O
zhou	O
j	O
and	O
troyanskaya	O
o	O
g	O
deep	O
supervised	O
and	O
convolutional	O
generative	O
stochastic	O
network	O
for	O
protein	O
secondary	O
structure	O
prediction	O
in	O
icml	O
zhou	O
y	O
and	O
chellappa	O
r	O
computation	O
of	O
optical	O
flow	O
using	O
a	O
neural	B
network	I
in	O
neural	O
networks	O
ieee	O
international	O
conference	O
on	O
pages	O
ieee	O
z	O
hrer	O
m	O
and	O
pernkopf	O
f	O
general	O
stochastic	O
networks	O
for	O
classification	B
in	O
nips	O
index	O
loss	O
absolute	B
value	I
rectification	I
accuracy	B
activation	B
function	I
active	B
constraint	I
adagrad	B
adaline	O
see	O
adaptive	O
linear	O
element	O
adam	O
adaptive	O
linear	O
element	O
adversarial	B
example	B
adversarial	O
training	O
affine	B
ais	O
see	O
annealed	O
importance	O
sampling	O
almost	B
everywhere	I
almost	B
sure	I
convergence	I
ancestral	O
sampling	O
ann	O
see	O
artificial	O
neural	B
network	I
annealed	O
importance	O
sampling	O
approximate	B
bayesian	I
computation	I
approximate	B
inference	I
artificial	B
intelligence	I
artificial	O
neural	B
network	I
see	O
neural	O
net	O
work	O
bag	B
of	I
words	I
bagging	B
batch	O
normalization	O
bayes	B
error	I
bayes	O
rule	O
bayesian	B
hyperparameter	B
optimization	I
bayesian	O
network	O
see	O
directed	O
graphical	O
model	O
bayesian	B
probability	I
bayesian	B
statistics	I
belief	O
network	O
see	O
directed	O
graphical	O
model	O
bernoulli	B
distribution	I
bfgs	B
bias	O
bias	B
parameter	I
biased	B
importance	I
sampling	I
bigram	B
binary	B
relation	I
block	B
gibbs	I
sampling	I
boltzmann	B
distribution	I
boltzmann	O
machine	O
bptt	O
see	O
back-propagation	B
through	I
time	I
broadcasting	B
burn-in	B
asr	O
see	O
automatic	B
speech	I
recognition	I
asymptotically	B
unbiased	B
audio	O
autoencoder	O
automatic	B
speech	I
recognition	I
back-propagation	B
back-propagation	B
through	I
time	I
backprop	O
see	O
back-propagation	B
cae	O
see	O
contractive	B
autoencoder	I
calculus	B
of	I
variations	I
categorical	O
distribution	O
see	O
multinoulli	O
dis	O
tribution	O
cd	O
see	O
contrastive	O
divergence	O
centering	O
trick	B
central	B
limit	I
theorem	I
chain	O
rule	O
chain	B
rule	I
of	I
probability	I
index	O
chess	B
chord	B
chordal	B
graph	I
class-based	B
language	I
models	I
classical	B
dynamical	I
system	I
classification	B
clique	O
potential	O
see	O
factor	O
model	O
cnn	O
see	O
convolutional	O
neural	B
network	I
collaborative	B
filtering	I
collider	O
see	O
explaining	O
away	O
color	B
images	I
complex	B
cell	I
computational	B
graph	I
computer	B
vision	I
concept	B
drift	I
condition	B
number	I
conditional	O
computation	O
see	O
dynamic	O
struc	O
ture	B
conditional	O
independence	O
conditional	B
probability	I
conditional	B
rbm	I
connectionism	B
connectionist	B
temporal	I
classification	B
consistency	O
constrained	O
optimization	O
content-based	B
addressing	I
content-based	B
recommender	B
systems	I
context-specific	B
independence	I
contextual	B
bandits	I
continuation	B
methods	I
contractive	B
autoencoder	I
contrast	B
contrastive	O
divergence	O
convex	B
optimization	I
convolution	O
convolutional	B
network	I
convolutional	O
neural	B
network	I
coordinate	O
descent	O
correlation	B
cost	O
function	O
see	O
objective	B
function	I
covariance	O
covariance	B
matrix	I
coverage	B
critical	B
temperature	I
cross-correlation	B
cross-entropy	B
cross-validation	B
ctc	O
see	O
connectionist	O
temporal	O
classifica	O
tion	B
curriculum	B
learning	I
curse	B
of	I
dimensionality	I
cyc	B
d-separation	B
dae	O
see	O
denoising	O
autoencoder	O
data	O
generating	O
distribution	O
data	B
generating	I
process	I
data	B
parallelism	I
dataset	B
dataset	B
augmentation	O
dbm	O
see	O
deep	O
boltzmann	O
machine	O
dcgan	O
decision	O
tree	O
decoder	B
deep	O
belief	O
network	O
deep	B
blue	I
deep	O
boltzmann	O
machine	O
deep	O
feedforward	O
network	O
deep	O
learning	O
denoising	O
autoencoder	O
denoising	B
score	I
matching	I
density	B
estimation	I
derivative	B
design	B
matrix	I
detector	B
layer	I
determinant	O
xii	O
diagonal	B
matrix	I
differential	O
entropy	O
dirac	B
delta	I
function	I
directed	O
graphical	O
model	O
directional	B
derivative	B
discriminative	O
fine-tuning	B
see	O
supervised	O
fine-tuning	B
discriminative	B
rbm	I
distributed	O
representation	O
domain	B
adaptation	I
index	O
dot	O
product	O
double	B
backprop	I
doubly	B
block	I
circulant	I
matrix	I
dream	O
sleep	O
dropconnect	B
dropout	O
dynamic	B
structure	I
e-step	B
early	O
stopping	O
ebm	O
see	O
energy-based	O
model	O
echo	O
state	O
network	O
effective	B
capacity	I
eigendecomposition	B
eigenvalue	B
eigenvector	B
elbo	O
see	O
evidence	O
lower	O
bound	B
element-wise	O
product	O
see	O
hadamard	O
prod	O
uct	O
see	O
hadamard	O
product	O
em	O
see	O
expectation	B
maximization	I
embedding	B
empirical	B
distribution	I
empirical	B
risk	B
empirical	B
risk	B
minimization	I
encoder	B
energy	B
function	I
energy-based	O
model	O
ensemble	B
methods	I
epoch	B
equality	B
constraint	I
equivariance	B
error	O
function	O
see	O
objective	B
function	I
esn	O
see	O
echo	O
state	O
network	O
euclidean	B
norm	I
euler-lagrange	B
equation	I
evidence	O
lower	O
bound	B
example	B
expectation	B
expectation	B
maximization	I
expected	O
value	O
see	O
expectation	B
explaining	O
away	O
exploitation	B
exploration	B
exponential	B
distribution	I
f-score	B
factor	O
model	O
factor	B
analysis	I
factor	B
graph	I
factors	B
of	I
variation	I
feature	B
feature	B
selection	I
feedforward	B
neural	B
network	I
fine-tuning	B
finite	B
differences	I
forget	B
gate	I
forward	B
propagation	I
fourier	O
transform	O
fovea	B
fpcd	B
free	O
energy	O
freebase	B
frequentist	B
probability	I
frequentist	B
statistics	I
frobenius	B
norm	I
fully-visible	B
bayes	I
network	I
functional	B
derivatives	I
fvbn	B
see	O
fully-visible	B
bayes	I
network	I
gabor	B
function	I
gans	O
see	O
generative	O
adversarial	O
networks	O
gated	B
recurrent	I
unit	I
gaussian	O
distribution	O
see	O
normal	O
distribu	O
tion	B
gaussian	B
kernel	I
gaussian	O
mixture	O
gcn	O
see	O
global	B
contrast	B
normalization	I
geneontology	B
generalization	B
generalized	O
lagrange	O
function	O
see	O
general	O
ized	O
lagrangian	O
generalized	B
lagrangian	I
generative	O
adversarial	O
networks	O
generative	B
moment	B
matching	I
networks	I
generator	B
network	I
gibbs	B
distribution	I
gibbs	O
sampling	O
global	B
contrast	B
normalization	I
gpu	O
see	O
graphics	B
processing	I
unit	I
gradient	B
index	O
gradient	B
clipping	O
gradient	B
descent	O
graph	O
xii	O
graphical	O
model	O
see	O
structured	O
probabilis	O
tic	O
model	O
graphics	B
processing	I
unit	I
greedy	B
algorithm	I
greedy	O
layer-wise	O
unsupervised	B
pretraining	I
greedy	B
supervised	I
pretraining	I
grid	B
search	I
hadamard	O
product	O
hard	O
harmonium	O
see	O
restricted	O
boltzmann	O
ma	O
tanh	O
chine	B
harmony	B
theory	I
helmholtz	O
free	O
energy	O
see	O
evidence	O
lower	O
bound	B
hessian	B
hessian	B
matrix	O
heteroscedastic	B
hidden	B
layer	I
hill	B
climbing	I
hyperparameter	B
optimization	I
hyperparameters	O
hypothesis	O
space	O
i	O
i	O
d	O
assumptions	O
identity	B
matrix	I
ilsvrc	O
see	O
imagenet	O
large	O
scale	O
visual	O
recognition	O
challenge	B
imagenet	O
large	O
scale	O
visual	O
recognition	O
challenge	B
immorality	B
importance	O
sampling	O
importance	B
weighted	I
autoencoder	I
independence	O
independent	O
and	O
identically	O
distributed	O
see	O
i	O
i	O
d	O
assumptions	O
independent	B
component	I
analysis	I
independent	B
subspace	I
analysis	I
inequality	B
constraint	I
inference	O
information	B
retrieval	I
initialization	B
integral	O
xiii	O
invariance	B
isotropic	B
jacobian	O
matrix	O
joint	B
probability	I
xiii	O
k-means	O
k-nearest	O
neighbors	O
karush-kuhn-tucker	O
conditions	O
karush	O
kuhn	O
tucker	O
kernel	O
kernel	B
machine	I
kernel	B
trick	B
kkt	O
see	O
karush	O
kuhn	O
tucker	O
kkt	O
conditions	O
see	O
karush-kuhn-tucker	O
conditions	O
kl	O
divergence	O
see	O
kullback-leibler	O
diver	O
gence	O
knowledge	O
base	O
krylov	B
methods	I
kullback-leibler	B
divergence	I
label	B
smoothing	I
lagrange	O
multipliers	O
lagrangian	O
see	O
generalized	B
lagrangian	I
lapgan	B
laplace	O
distribution	O
latent	B
variable	I
layer	O
network	O
lcn	O
see	O
local	B
contrast	B
normalization	I
leaky	B
relu	I
leaky	B
units	I
learning	B
rate	I
line	O
search	O
linear	B
combination	I
linear	B
dependence	I
linear	B
factor	I
models	I
linear	O
regression	B
link	B
prediction	I
lipschitz	B
constant	I
lipschitz	B
continuous	I
liquid	B
state	I
machine	I
index	O
local	O
conditional	B
probability	B
distribution	I
local	B
contrast	B
normalization	I
logistic	O
regression	B
logistic	O
sigmoid	O
long	O
short-term	O
memory	O
loop	B
loopy	B
belief	I
propagation	I
loss	O
function	O
see	O
objective	B
function	I
lp	B
norm	I
lstm	O
see	O
long	O
short-term	O
memory	O
m-step	B
machine	B
learning	I
machine	B
translation	I
main	B
diagonal	I
manifold	B
manifold	B
hypothesis	I
manifold	B
learning	I
manifold	B
tangent	I
classifier	I
map	O
approximation	O
marginal	B
probability	I
markov	B
chain	I
markov	B
chain	I
monte	I
carlo	I
markov	O
network	O
see	O
undirected	B
model	I
markov	O
random	O
field	O
see	O
undirected	B
model	I
matrix	O
xi	O
xii	O
matrix	B
inverse	I
matrix	B
product	I
max	B
norm	I
max	B
pooling	I
maximum	B
likelihood	I
maxout	O
mcmc	O
see	O
markov	B
chain	I
monte	I
carlo	I
mean	O
field	O
mean	B
squared	I
error	I
measure	B
theory	I
measure	B
zero	I
memory	O
network	O
method	O
of	O
steepest	O
descent	O
see	O
gradient	B
descent	O
minibatch	B
missing	B
inputs	I
mixing	O
chain	O
mixture	B
density	I
networks	I
mixture	B
distribution	I
mixture	O
model	O
mixture	O
of	O
experts	O
mlp	O
see	O
multilayer	B
perception	I
mnist	O
model	B
averaging	I
model	B
compression	I
model	B
identifiability	I
model	B
parallelism	I
moment	B
matching	I
moore-penrose	O
pseudoinverse	O
moralized	B
graph	I
mp-dbm	O
see	O
multi-prediction	B
dbm	I
mrf	O
random	O
field	O
see	O
undi	O
rected	O
model	O
mse	O
see	O
mean	B
squared	I
error	I
multi-modal	B
learning	I
multi-prediction	B
dbm	I
multi-task	O
learning	O
multilayer	B
perception	I
multilayer	B
perceptron	I
multinomial	B
distribution	I
multinoulli	B
distribution	I
n-gram	B
nade	B
naive	B
bayes	I
nat	B
natural	B
image	I
natural	B
language	I
processing	I
nearest	B
neighbor	I
regression	B
negative	B
definite	I
negative	O
phase	O
neocognitron	O
nesterov	B
momentum	I
netflix	O
grand	O
prize	O
neural	O
language	O
model	O
neural	B
network	I
neural	B
turing	I
machine	I
neuroscience	B
newton	O
s	O
method	O
nlm	O
see	O
neural	O
language	O
model	O
nlp	O
see	O
natural	B
language	I
processing	I
no	B
free	I
lunch	I
theorem	I
index	O
noise-contrastive	B
estimation	I
non-parametric	B
model	I
norm	O
normal	O
distribution	O
normal	O
equations	O
normalized	B
initialization	B
numerical	O
differentiation	O
see	O
finite	O
differ	O
ences	O
object	B
detection	I
object	B
recognition	I
objective	B
function	I
omp-	O
see	O
orthogonal	O
matching	O
pursuit	O
one-shot	B
learning	I
operation	B
optimization	O
orthodox	O
statistics	O
see	O
frequentist	B
statistics	I
orthogonal	O
matching	O
pursuit	O
orthogonal	B
matrix	I
orthogonality	B
output	O
layer	O
parallel	B
distributed	I
processing	I
parameter	O
initialization	B
parameter	O
sharing	O
parameter	O
tying	O
see	O
parameter	O
sharing	O
parametric	B
model	I
parametric	B
relu	I
partial	B
derivative	B
partition	O
function	O
pca	O
see	O
principal	O
components	O
analysis	O
pcd	O
see	O
stochastic	O
maximum	B
likelihood	I
perceptron	O
persistent	O
contrastive	O
divergence	O
see	O
stochas	O
tic	O
maximum	B
likelihood	I
perturbation	O
analysis	O
see	O
reparametrization	B
trick	B
point	B
estimator	I
policy	B
pooling	O
positive	B
definite	I
positive	O
phase	O
precision	B
precision	B
a	O
normal	O
distribution	O
predictive	B
sparse	I
decomposition	I
preprocessing	B
pretraining	O
primary	B
visual	I
cortex	I
principal	O
components	O
analysis	O
prior	B
probability	B
distribution	I
probabilistic	B
max	B
pooling	I
probabilistic	O
pca	O
probability	B
density	I
function	I
probability	B
distribution	I
probability	B
mass	I
function	I
probability	B
mass	I
function	I
estimation	I
product	B
of	I
experts	I
product	O
rule	O
of	O
probability	O
see	O
chain	B
rule	I
of	I
probability	I
psd	O
see	O
predictive	B
sparse	I
decomposition	I
pseudolikelihood	B
quadrature	B
pair	I
quasi-newton	O
methods	O
radial	B
basis	I
function	I
random	B
search	I
random	B
variable	I
ratio	B
matching	I
rbf	B
rbm	O
see	O
restricted	O
boltzmann	O
machine	O
recall	B
receptive	B
field	I
recommender	B
systems	I
rectified	O
linear	O
unit	O
recurrent	B
network	I
recurrent	B
neural	B
network	I
regression	B
regularization	O
regularizer	B
reinforce	B
reinforcement	O
learning	O
relational	B
database	I
relations	B
reparametrization	B
trick	B
representation	B
learning	I
representational	B
capacity	I
restricted	O
boltzmann	O
machine	O
index	O
ridge	O
regression	B
see	O
weight	O
decay	O
risk	B
rnn-rbm	O
saddle	B
points	I
sample	B
mean	I
scalar	O
xi	O
xii	O
score	O
matching	O
second	B
derivative	B
second	B
derivative	B
test	I
self-information	B
semantic	B
hashing	I
semi-supervised	B
learning	I
separable	B
convolution	I
separation	O
modeling	O
set	O
xii	O
sgd	O
see	O
stochastic	O
gradient	B
descent	O
shannon	O
entropy	O
shortlist	B
sigmoid	O
sigmoid	B
belief	I
network	I
simple	B
cell	I
singular	B
value	I
see	O
singular	B
value	I
decompo	O
see	O
logistic	O
sigmoid	O
sition	O
singular	B
value	I
decomposition	O
singular	O
vector	O
see	O
singular	B
value	I
decom	O
position	O
xiv	O
slow	B
feature	B
analysis	I
sml	O
see	O
stochastic	O
maximum	B
likelihood	I
softmax	O
softplus	O
spam	B
detection	I
sparse	O
coding	O
sparse	O
initialization	B
sparse	O
representation	O
spearmint	B
spectral	B
radius	I
speech	O
recognition	O
see	O
automatic	B
speech	I
recognition	I
sphering	O
see	O
whitening	B
spike	O
and	O
slab	O
restricted	O
boltzmann	O
ma	O
chine	B
spn	O
see	O
sum-product	B
network	I
square	B
matrix	I
ssrbm	O
see	O
spike	O
and	O
slab	O
restricted	O
boltz	O
mann	O
machine	O
standard	B
deviation	I
standard	B
error	I
standard	B
error	I
of	O
the	O
mean	O
statistic	B
statistical	B
learning	I
theory	I
steepest	O
descent	O
see	O
gradient	B
descent	O
stochastic	O
back-propagation	B
see	O
reparametriza	O
tion	B
trick	B
stochastic	O
gradient	B
descent	O
stochastic	O
maximum	B
likelihood	I
stochastic	B
pooling	I
structure	B
learning	I
structured	O
output	O
structured	O
probabilistic	O
model	O
sum	B
rule	I
of	I
probability	I
sum-product	B
network	I
supervised	O
fine-tuning	B
supervised	B
learning	I
support	B
vector	I
machine	I
surrogate	B
loss	I
function	I
svd	O
see	O
singular	B
value	I
decomposition	O
symmetric	O
matrix	O
xi	O
xii	O
tangent	B
distance	I
tangent	B
plane	I
tangent	B
prop	I
tdnn	O
see	O
time-delay	O
neural	B
network	I
teacher	O
forcing	O
tempering	B
template	B
matching	I
tensor	O
test	B
set	I
tikhonov	O
regularization	O
see	O
weight	O
decay	O
tiled	B
convolution	I
time-delay	O
neural	B
network	I
toeplitz	B
matrix	I
topographic	B
ica	I
trace	B
operator	I
training	B
error	I
transcription	B
transfer	B
learning	I
index	O
transpose	O
triangle	B
inequality	I
triangulated	O
graph	O
see	O
chordal	B
graph	I
trigram	B
zero-data	O
learning	O
see	O
zero-shot	B
learning	I
zero-shot	B
learning	I
unbiased	B
undirected	O
graphical	O
model	O
undirected	B
model	I
uniform	B
distribution	I
unigram	B
unit	B
norm	I
unit	B
vector	I
universal	B
approximation	I
theorem	I
universal	B
approximator	I
unnormalized	B
probability	B
distribution	I
unsupervised	O
learning	O
unsupervised	B
pretraining	I
v-structure	O
see	O
explaining	O
away	O
vae	O
see	O
variational	O
autoencoder	O
vapnik-chervonenkis	B
dimension	I
variance	O
variational	O
autoencoder	O
variational	O
derivatives	O
see	O
functional	O
deriva	O
xiii	O
tives	O
variational	O
free	O
energy	O
see	O
evidence	O
lower	O
bound	B
vc	O
dimension	O
see	O
vapnik-chervonenkis	O
di	O
mension	O
xi	O
xii	O
vector	O
virtual	B
adversarial	I
examples	I
visible	B
layer	I
volumetric	O
data	O
wake-sleep	O
weight	O
decay	O
weight	B
space	I
symmetry	I
weights	B
whitening	B
wikibase	B
wikibase	B
word	B
embedding	B
word-sense	B
disambiguation	I
wordnet	B
