a	O
course	O
inmachine	O
learninghal	O
daum	O
iii	O
copyright	O
hal	O
daum	O
iii	O
published	O
by	O
todo	O
todo	O
first	O
printing	O
september	O
for	O
my	O
students	O
and	O
teachers	O
often	O
the	O
same	O
table	O
of	O
contents	O
about	O
this	O
book	O
decision	B
trees	I
geometry	O
and	O
nearest	O
neighbors	O
the	O
perceptron	B
practical	O
issues	O
beyond	O
binary	O
classification	O
linear	O
models	O
probabilistic	B
modeling	B
neural	B
networks	I
kernel	B
methods	O
learning	O
theory	O
ensemble	B
methods	O
efficient	O
learning	O
unsupervised	B
learning	I
expectation	B
maximization	I
semi-supervised	B
learning	I
graphical	O
models	O
online	B
learning	I
structured	O
learning	O
tasks	O
bayesian	O
learning	O
code	O
and	O
datasets	O
notation	O
bibliography	O
index	O
about	O
this	O
book	O
machine	O
learning	O
is	O
a	O
broad	O
and	O
fascinating	O
field	O
it	O
has	O
been	O
called	O
one	O
of	O
the	O
attractive	O
fields	O
to	O
work	O
it	O
has	O
applications	O
in	O
an	O
incredibly	O
wide	O
variety	O
of	O
application	O
areas	O
from	O
medicine	O
to	O
advertising	O
from	O
military	O
to	O
pedestrian	O
its	O
importance	O
is	O
likely	O
to	O
grow	O
as	O
more	O
and	O
more	O
areas	O
turn	O
to	O
it	O
as	O
a	O
way	O
of	O
dealing	O
with	O
the	O
massive	O
amounts	O
of	O
data	O
available	O
how	O
to	O
use	O
this	O
book	O
why	O
another	O
textbook	O
mitchell	O
the	O
purpose	O
of	O
this	O
book	O
is	O
to	O
provide	O
a	O
gentle	O
and	O
pedagogically	O
organized	O
introduction	O
to	O
the	O
field	O
this	O
is	O
in	O
contrast	O
to	O
most	O
existing	O
machine	O
learning	O
texts	O
which	O
tend	O
to	O
organize	O
things	O
topically	O
rather	O
than	O
pedagogically	O
exception	O
is	O
mitchell	O
s	O
but	O
unfortunately	O
that	O
is	O
getting	O
more	O
and	O
more	O
outdated	O
this	O
makes	O
sense	O
for	O
researchers	O
in	O
the	O
field	O
but	O
less	O
sense	O
for	O
learners	O
a	O
second	O
goal	O
of	O
this	O
book	O
is	O
to	O
provide	O
a	O
view	O
of	O
machine	O
learning	O
that	O
focuses	O
on	O
ideas	O
and	O
models	O
not	O
on	O
math	O
it	O
is	O
not	O
possible	O
even	O
advisable	O
to	O
avoid	O
math	O
but	O
math	O
should	O
be	O
there	O
to	O
aid	O
understanding	O
not	O
hinder	O
it	O
finally	O
this	O
book	O
attempts	O
to	O
have	O
minimal	O
dependencies	O
so	O
that	O
one	O
can	O
fairly	O
easily	O
pick	O
and	O
choose	O
chapters	O
to	O
read	O
when	O
dependencies	O
exist	O
they	O
are	O
listed	O
at	O
the	O
start	O
of	O
the	O
chapter	O
as	O
well	O
as	O
the	O
list	O
of	O
dependencies	O
at	O
the	O
end	O
of	O
this	O
chapter	O
the	O
audience	O
of	O
this	O
book	O
is	O
anyone	O
who	O
knows	O
differential	O
calculus	O
and	O
discrete	O
math	O
and	O
can	O
program	O
reasonably	O
well	O
little	O
bit	O
of	O
linear	O
algebra	O
and	O
probability	O
will	O
not	O
hurt	O
an	O
undergraduate	O
in	O
their	O
fourth	O
or	O
fifth	O
semester	O
should	O
be	O
fully	O
capable	O
of	O
understanding	O
this	O
material	O
however	O
it	O
should	O
also	O
be	O
suitable	O
for	O
first	O
year	O
graduate	O
students	O
perhaps	O
at	O
a	O
slightly	O
faster	O
pace	O
organization	O
and	O
auxilary	O
material	O
there	O
is	O
an	O
associated	O
web	O
page	O
which	O
contains	O
an	O
online	B
copy	O
of	O
this	O
book	O
as	O
well	O
as	O
associated	O
code	O
and	O
data	O
it	O
also	O
contains	O
errate	O
for	O
instructors	O
there	O
is	O
the	O
ability	O
to	O
get	O
a	O
solutions	O
manual	O
this	O
book	O
is	O
suitable	O
for	O
a	O
single-semester	O
undergraduate	O
course	O
graduate	O
course	O
or	O
two	O
semester	O
course	O
the	O
latter	O
supplemented	O
with	O
readings	O
decided	O
upon	O
by	O
the	O
instructor	O
here	O
are	O
suggested	O
course	O
plans	O
for	O
the	O
first	O
two	O
courses	O
a	O
year-long	O
course	O
could	O
be	O
obtained	O
simply	O
by	O
covering	O
the	O
entire	O
book	O
acknowledgements	O
decision	B
trees	I
learning	O
objectives	O
explain	O
the	O
difference	O
between	O
memorization	O
and	O
generalization	O
define	O
inductive	B
bias	B
and	O
recog	O
nize	O
the	O
role	O
of	O
inductive	B
bias	B
in	O
learning	O
take	O
a	O
concrete	O
task	O
and	O
cast	O
it	O
as	O
a	O
learning	O
problem	O
with	O
a	O
formal	O
notion	O
of	O
input	O
space	O
features	B
output	O
space	O
generating	O
distribution	O
and	O
loss	B
function	I
illustrate	O
how	O
regularization	O
trades	O
off	O
between	O
underfitting	B
and	O
overfitting	B
evaluate	O
whether	O
a	O
use	O
of	O
test	B
data	I
is	O
cheating	O
or	O
not	O
dependencies	O
none	O
the	O
words	O
printed	O
here	O
are	O
concepts	O
you	O
must	O
go	O
through	O
the	O
experiences	O
carl	O
frederick	O
at	O
a	O
basic	O
level	O
machine	O
learning	O
is	O
about	O
predicting	O
the	O
future	O
based	O
on	O
the	O
past	O
for	O
instance	O
you	O
might	O
wish	O
to	O
predict	B
how	O
much	O
a	O
user	O
alice	O
will	O
like	O
a	O
movie	O
that	O
she	O
hasn	O
t	O
seen	O
based	O
on	O
her	O
ratings	O
of	O
movies	O
that	O
she	O
has	O
seen	O
this	O
means	O
making	O
informed	O
guesses	O
about	O
some	O
unobserved	O
property	O
of	O
some	O
object	O
based	O
on	O
observed	O
properties	O
of	O
that	O
object	O
the	O
first	O
question	O
we	O
ll	O
ask	O
is	O
what	O
does	O
it	O
mean	O
to	O
learn	O
in	O
order	O
to	O
develop	O
learning	O
machines	O
we	O
must	O
know	O
what	O
learning	O
actually	O
means	O
and	O
how	O
to	O
determine	O
success	O
failure	O
you	O
ll	O
see	O
this	O
question	O
answered	O
in	O
a	O
very	O
limited	O
learning	O
setting	O
which	O
will	O
be	O
progressively	O
loosened	O
and	O
adapted	O
throughout	O
the	O
rest	O
of	O
this	O
book	O
for	O
concreteness	O
our	O
focus	O
will	O
be	O
on	O
a	O
very	O
simple	O
model	B
of	O
learning	O
called	O
a	O
decision	B
tree	I
vignette	O
alice	O
decides	O
which	O
classes	O
to	O
take	O
todo	O
what	O
does	O
it	O
mean	O
to	O
learn	O
alice	O
has	O
just	O
begun	O
taking	O
a	O
course	O
on	O
machine	O
learning	O
she	O
knows	O
that	O
at	O
the	O
end	O
of	O
the	O
course	O
she	O
will	O
be	O
expected	O
to	O
have	O
learned	O
all	O
about	O
this	O
topic	O
a	O
common	O
way	O
of	O
gauging	O
whether	O
or	O
not	O
she	O
has	O
learned	O
is	O
for	O
her	O
teacher	O
bob	O
to	O
give	O
her	O
a	O
exam	O
she	O
has	O
done	O
well	O
at	O
learning	O
if	O
she	O
does	O
well	O
on	O
the	O
exam	O
but	O
what	O
makes	O
a	O
reasonable	O
exam	O
if	O
bob	O
spends	O
the	O
entire	O
semester	O
talking	O
about	O
machine	O
learning	O
and	O
then	O
gives	O
alice	O
an	O
exam	O
on	O
history	O
of	O
pottery	O
then	O
alice	O
s	O
performance	O
on	O
this	O
exam	O
will	O
not	O
be	O
representative	O
of	O
her	O
learning	O
on	O
the	O
other	O
hand	O
if	O
the	O
exam	O
only	O
asks	O
questions	O
that	O
bob	O
has	O
answered	O
exactly	O
during	O
lectures	O
then	O
this	O
is	O
also	O
a	O
bad	O
test	O
of	O
alice	O
s	O
learning	O
especially	O
if	O
it	O
s	O
an	O
open	O
notes	O
exam	O
what	O
is	O
desired	O
is	O
that	O
alice	O
observes	O
specific	O
examples	B
from	O
the	O
course	O
and	O
then	O
has	O
to	O
answer	O
new	O
but	O
related	O
questions	O
on	O
the	O
exam	O
this	O
tests	O
whether	O
alice	O
has	O
the	O
ability	O
to	O
generalize	B
generalization	O
is	O
perhaps	O
the	O
most	O
central	O
concept	B
in	O
machine	O
learning	O
as	O
a	O
running	O
concrete	O
example	O
in	O
this	O
book	O
we	O
will	O
use	O
that	O
of	O
a	O
course	O
recommendation	O
system	O
for	O
undergraduate	O
computer	O
science	O
students	O
we	O
have	O
a	O
collection	O
of	O
students	O
and	O
a	O
collection	O
of	O
courses	O
each	O
student	O
has	O
taken	O
and	O
evaluated	O
a	O
subset	O
of	O
the	O
courses	O
the	O
evaluation	O
is	O
simply	O
a	O
score	O
from	O
to	O
the	O
job	O
of	O
the	O
recommender	O
system	O
is	O
to	O
predict	B
how	O
much	O
a	O
particular	O
student	O
alice	O
will	O
like	O
a	O
particular	O
course	O
algorithms	O
given	O
historical	O
data	O
from	O
course	O
ratings	O
the	O
past	O
we	O
are	O
trying	O
to	O
predict	B
unseen	O
ratings	O
the	O
future	O
now	O
we	O
could	O
be	O
unfair	O
to	O
this	O
system	O
as	O
well	O
we	O
could	O
ask	O
it	O
whether	O
alice	O
is	O
likely	O
to	O
enjoy	O
the	O
history	O
of	O
pottery	O
course	O
this	O
is	O
unfair	O
because	O
the	O
system	O
has	O
no	O
idea	O
what	O
history	O
of	O
pottery	O
even	O
is	O
and	O
has	O
no	O
prior	B
experience	O
with	O
this	O
course	O
on	O
the	O
other	O
hand	O
we	O
could	O
ask	O
it	O
how	O
much	O
alice	O
will	O
like	O
artificial	O
intelligence	O
which	O
she	O
took	O
last	O
year	O
and	O
rated	O
as	O
we	O
would	O
expect	O
the	O
system	O
to	O
predict	B
that	O
she	O
would	O
really	O
like	O
it	O
but	O
this	O
isn	O
t	O
demonstrating	O
that	O
the	O
system	O
has	O
learned	O
it	O
s	O
simply	O
recalling	O
its	O
past	O
experience	O
in	O
the	O
former	O
case	O
we	O
re	O
expecting	O
the	O
system	O
to	O
generalize	B
beyond	O
its	O
experience	O
which	O
is	O
unfair	O
in	O
the	O
latter	O
case	O
we	O
re	O
not	O
expecting	O
it	O
to	O
generalize	B
at	O
all	O
this	O
general	O
set	O
up	O
of	O
predicting	O
the	O
future	O
based	O
on	O
the	O
past	O
is	O
at	O
the	O
core	O
of	O
most	O
machine	O
learning	O
the	O
objects	O
that	O
our	O
algorithm	B
will	O
make	O
predictions	O
about	O
are	O
examples	B
in	O
the	O
recommender	O
system	O
setting	O
an	O
example	O
would	O
be	O
some	O
particular	O
studentcourse	O
pair	O
as	O
alicealgorithms	O
the	O
desired	O
prediction	O
would	O
be	O
the	O
rating	O
that	O
alice	O
would	O
give	O
to	O
algorithms	O
to	O
make	O
this	O
concrete	O
figure	O
shows	O
the	O
general	O
framework	O
of	O
induction	B
we	O
are	O
given	O
training	B
data	I
on	O
which	O
our	O
algorithm	B
is	O
expected	O
to	O
learn	O
this	O
training	B
data	I
is	O
the	O
examples	B
that	O
alice	O
observes	O
in	O
her	O
machine	O
learning	O
course	O
or	O
the	O
historical	O
ratings	O
data	O
for	O
the	O
recommender	O
system	O
based	O
on	O
this	O
training	B
data	I
our	O
learning	O
algorithm	B
induces	O
a	O
function	O
f	O
that	O
will	O
map	O
a	O
new	O
example	O
to	O
a	O
corresponding	O
prediction	O
for	O
example	O
our	O
function	O
might	O
guess	O
that	O
f	O
learning	O
might	O
be	O
high	O
because	O
our	O
training	B
data	I
said	O
that	O
alice	O
liked	O
artificial	O
intelligence	O
we	O
want	O
our	O
algorithm	B
to	O
be	O
able	O
to	O
make	O
lots	O
of	O
predictions	O
so	O
we	O
refer	O
to	O
the	O
collection	O
of	O
examples	B
on	O
which	O
we	O
will	O
evaluate	O
our	O
algorithm	B
as	O
the	O
test	B
set	I
the	O
test	B
set	I
is	O
a	O
closely	O
guarded	O
secret	O
it	O
is	O
the	O
final	O
exam	O
on	O
which	O
our	O
learning	O
algorithm	B
is	O
being	O
tested	O
if	O
our	O
algorithm	B
gets	O
to	O
peek	O
at	O
it	O
ahead	O
of	O
time	O
it	O
s	O
going	O
to	O
cheat	O
and	O
do	O
better	O
than	O
it	O
should	O
decision	B
trees	I
figure	O
the	O
general	O
supervised	O
approach	O
to	O
machine	O
learning	O
a	O
learning	O
algorithm	B
reads	O
in	O
training	B
data	I
and	O
computes	O
a	O
learned	O
function	O
f	O
this	O
function	O
can	O
then	O
automatically	O
label	B
future	O
text	O
examples	B
why	O
is	O
it	O
bad	O
if	O
the	O
learning	O
algorithm	B
gets	O
to	O
peek	O
at	O
the	O
test	B
data	I
a	O
course	O
in	O
machine	O
learning	O
the	O
goal	O
of	O
inductive	O
machine	O
learning	O
is	O
to	O
take	O
some	O
training	B
data	I
and	O
use	O
it	O
to	O
induce	B
a	O
function	O
f	O
this	O
function	O
f	O
will	O
be	O
evaluated	O
on	O
the	O
test	B
data	I
the	O
machine	O
learning	O
algorithm	B
has	O
succeeded	O
if	O
its	O
performance	O
on	O
the	O
test	B
data	I
is	O
high	O
some	O
canonical	O
learning	O
problems	O
there	O
are	O
a	O
large	O
number	O
of	O
typical	O
inductive	O
learning	O
problems	O
the	O
primary	O
difference	O
between	O
them	O
is	O
in	O
what	O
type	O
of	O
thing	O
they	O
re	O
trying	O
to	O
predict	B
here	O
are	O
some	O
examples	B
regression	O
trying	O
to	O
predict	B
a	O
real	O
value	O
for	O
instance	O
predict	B
the	O
value	O
of	O
a	O
stock	O
tomorrow	O
given	O
its	O
past	O
performance	O
or	O
predict	B
alice	O
s	O
score	O
on	O
the	O
machine	O
learning	O
final	O
exam	O
based	O
on	O
her	O
homework	O
scores	O
binary	O
classification	O
trying	O
to	O
predict	B
a	O
simple	O
yesno	O
response	O
for	O
instance	O
predict	B
whether	O
alice	O
will	O
enjoy	O
a	O
course	O
or	O
not	O
or	O
predict	B
whether	O
a	O
user	O
review	O
of	O
the	O
newest	O
apple	O
product	O
is	O
positive	O
or	O
negative	O
about	O
the	O
product	O
multiclass	O
classification	O
trying	O
to	O
put	O
an	O
example	O
into	O
one	O
of	O
a	O
number	O
of	O
classes	O
for	O
instance	O
predict	B
whether	O
a	O
news	O
story	O
is	O
about	O
entertainment	O
sports	O
politics	O
religion	O
etc	O
or	O
predict	B
whether	O
a	O
cs	O
course	O
is	O
systems	O
theory	O
ai	O
or	O
other	O
ranking	O
trying	O
to	O
put	O
a	O
set	O
of	O
objects	O
in	O
order	O
of	O
relevance	O
for	O
in	O
stance	O
predicting	O
what	O
order	O
to	O
put	O
web	O
pages	O
in	O
in	O
response	O
to	O
a	O
user	O
query	O
or	O
predict	B
alice	O
s	O
ranked	O
preferences	O
over	O
courses	O
she	O
hasn	O
t	O
taken	O
the	O
reason	O
that	O
it	O
is	O
convenient	O
to	O
break	O
machine	O
learning	O
problems	O
down	O
by	O
the	O
type	O
of	O
object	O
that	O
they	O
re	O
trying	O
to	O
predict	B
has	O
to	O
do	O
with	O
measuring	O
error	O
recall	B
that	O
our	O
goal	O
is	O
to	O
build	O
a	O
system	O
that	O
can	O
make	O
good	O
predictions	O
this	O
begs	O
the	O
question	O
what	O
does	O
it	O
mean	O
for	O
a	O
prediction	O
to	O
be	O
good	O
the	O
different	O
types	O
of	O
learning	O
problems	O
differ	O
in	O
how	O
they	O
define	O
goodness	O
for	O
instance	O
in	O
regression	O
predicting	O
a	O
stock	O
price	O
that	O
is	O
off	O
by	O
is	O
perhaps	O
much	O
better	O
than	O
being	O
off	O
by	O
the	O
same	O
does	O
not	O
hold	O
of	O
multiclass	O
classification	O
there	O
accidentally	O
predicting	O
entertainment	O
instead	O
of	O
sports	O
is	O
no	O
better	O
or	O
worse	O
than	O
predicting	O
politics	O
the	O
decision	B
tree	I
model	B
of	O
learning	O
the	O
decision	B
tree	I
is	O
a	O
classic	O
and	O
natural	O
model	B
of	O
learning	O
it	O
is	O
closely	O
related	O
to	O
the	O
fundamental	O
computer	O
science	O
notion	O
of	O
divide	O
and	O
conquer	O
although	O
decision	B
trees	I
can	O
be	O
applied	O
to	O
many	O
for	O
each	O
of	O
these	O
types	O
of	O
canonical	O
machine	O
learning	O
problems	O
come	O
up	O
with	O
one	O
or	O
two	O
concrete	O
examples	B
learning	O
problems	O
we	O
will	O
begin	O
with	O
the	O
simplest	O
case	O
binary	O
classification	O
suppose	O
that	O
your	O
goal	O
is	O
to	O
predict	B
whether	O
some	O
unknown	O
user	O
will	O
enjoy	O
some	O
unknown	O
course	O
you	O
must	O
simply	O
answer	O
yes	O
or	O
no	O
in	O
order	O
to	O
make	O
a	O
guess	O
you	O
re	O
allowed	O
to	O
ask	O
binary	O
questions	O
about	O
the	O
usercourse	O
under	O
consideration	O
for	O
example	O
you	O
is	O
the	O
course	O
under	O
consideration	O
in	O
systems	O
me	O
yes	O
you	O
has	O
this	O
student	O
taken	O
any	O
other	O
systems	O
courses	O
me	O
yes	O
you	O
has	O
this	O
student	O
liked	O
most	O
previous	O
systems	O
courses	O
me	O
no	O
you	O
i	O
predict	B
this	O
student	O
will	O
not	O
like	O
this	O
course	O
the	O
goal	O
in	O
learning	O
is	O
to	O
figure	O
out	O
what	O
questions	O
to	O
ask	O
in	O
what	O
order	O
to	O
ask	O
them	O
and	O
what	O
answer	O
to	O
predict	B
once	O
you	O
have	O
asked	O
enough	O
questions	O
the	O
decision	B
tree	I
is	O
so-called	O
because	O
we	O
can	O
write	O
our	O
set	O
of	O
ques	O
tions	O
and	O
guesses	O
in	O
a	O
tree	O
format	O
such	O
as	O
that	O
in	O
figure	O
in	O
this	O
figure	O
the	O
questions	O
are	O
written	O
in	O
the	O
internal	O
tree	O
nodes	O
and	O
the	O
guesses	O
are	O
written	O
in	O
the	O
leaves	O
each	O
non-terminal	O
node	O
has	O
two	O
children	O
the	O
left	O
child	O
specifies	O
what	O
to	O
do	O
if	O
the	O
answer	O
to	O
the	O
question	O
is	O
no	O
and	O
the	O
right	O
child	O
specifies	O
what	O
to	O
do	O
if	O
it	O
is	O
yes	O
in	O
order	O
to	O
learn	O
i	O
will	O
give	O
you	O
training	B
data	I
this	O
data	O
consists	O
of	O
a	O
set	O
of	O
usercourse	O
examples	B
paired	O
with	O
the	O
correct	O
answer	O
for	O
these	O
examples	B
the	O
given	O
user	O
enjoy	O
the	O
given	O
course	O
from	O
this	O
you	O
must	O
construct	O
your	O
questions	O
for	O
concreteness	O
there	O
is	O
a	O
small	O
data	O
set	O
in	O
table	O
in	O
the	O
appendix	O
of	O
this	O
book	O
this	O
training	B
data	I
consists	O
of	O
course	O
rating	O
examples	B
with	O
course	O
ratings	O
and	O
answers	O
to	O
questions	O
that	O
you	O
might	O
ask	O
about	O
this	O
pair	O
we	O
will	O
interpret	O
ratings	O
of	O
and	O
as	O
liked	O
and	O
ratings	O
of	O
and	O
as	O
hated	O
in	O
what	O
follows	O
we	O
will	O
refer	O
to	O
the	O
questions	O
that	O
you	O
can	O
ask	O
as	O
features	B
and	O
the	O
responses	O
to	O
these	O
questions	O
as	O
feature	B
values	I
the	O
rating	O
is	O
called	O
the	O
label	B
an	O
example	O
is	O
just	O
a	O
set	O
of	O
feature	B
values	I
and	O
our	O
training	B
data	I
is	O
a	O
set	O
of	O
examples	B
paired	O
with	O
labels	O
there	O
are	O
a	O
lot	O
of	O
logically	O
possible	O
trees	O
that	O
you	O
could	O
build	O
even	O
over	O
just	O
this	O
small	O
number	O
of	O
features	B
number	O
is	O
in	O
the	O
millions	O
it	O
is	O
computationally	O
infeasible	O
to	O
consider	O
all	O
of	O
these	O
to	O
try	O
to	O
choose	O
the	O
best	O
one	O
instead	O
we	O
will	O
build	O
our	O
decision	B
tree	I
greedily	O
we	O
will	O
begin	O
by	O
asking	O
if	O
i	O
could	O
only	O
ask	O
one	O
question	O
what	O
question	O
would	O
i	O
ask	O
you	O
want	O
to	O
find	O
a	O
feature	O
that	O
is	O
most	O
useful	O
in	O
helping	O
you	O
guess	O
whether	O
this	O
student	O
will	O
enjoy	O
this	O
a	O
useful	O
way	O
to	O
think	O
decision	B
trees	I
figure	O
a	O
decision	B
tree	I
for	O
a	O
course	O
recommender	O
system	O
from	O
which	O
the	O
in-text	O
dialog	O
is	O
drawn	O
figure	O
a	O
histogram	B
of	O
labels	O
for	O
the	O
entire	O
data	O
set	O
the	O
examples	B
in	O
the	O
data	O
set	O
for	O
each	O
value	O
of	O
the	O
first	O
four	O
features	B
a	O
colleague	O
related	O
the	O
story	O
of	O
getting	O
his	O
old	O
nephew	O
to	O
guess	O
a	O
number	O
between	O
and	O
his	O
nephew	O
s	O
first	O
four	O
questions	O
were	O
is	O
it	O
bigger	O
than	O
is	O
it	O
even	O
does	O
it	O
have	O
a	O
in	O
it	O
a	O
course	O
in	O
machine	O
learning	O
about	O
this	O
is	O
to	O
look	O
at	O
the	O
histogram	B
of	O
labels	O
for	O
each	O
feature	O
this	O
is	O
shown	O
for	O
the	O
first	O
four	O
features	B
in	O
figure	O
each	O
histogram	B
shows	O
the	O
frequency	O
of	O
like	O
hate	O
labels	O
for	O
each	O
possible	O
value	O
of	O
an	O
associated	O
feature	O
from	O
this	O
figure	O
you	O
can	O
see	O
that	O
asking	O
the	O
first	O
feature	O
is	O
not	O
useful	O
if	O
the	O
value	O
is	O
no	O
then	O
it	O
s	O
hard	O
to	O
guess	O
the	O
label	B
similarly	O
if	O
the	O
answer	O
is	O
yes	O
on	O
the	O
other	O
hand	O
asking	O
the	O
second	O
feature	O
is	O
useful	O
if	O
the	O
value	O
is	O
no	O
you	O
can	O
be	O
pretty	O
confident	O
that	O
this	O
student	O
will	O
hate	O
this	O
course	O
if	O
the	O
answer	O
is	O
yes	O
you	O
can	O
be	O
pretty	O
confident	O
that	O
this	O
student	O
will	O
like	O
this	O
course	O
more	O
formally	O
you	O
will	O
consider	O
each	O
feature	O
in	O
turn	O
you	O
might	O
consider	O
the	O
feature	O
is	O
this	O
a	O
system	O
s	O
course	O
this	O
feature	O
has	O
two	O
possible	O
value	O
no	O
and	O
yes	O
some	O
of	O
the	O
training	O
examples	B
have	O
an	O
answer	O
of	O
no	O
let	O
s	O
call	O
that	O
the	O
no	O
set	O
some	O
of	O
the	O
training	O
examples	B
have	O
an	O
answer	O
of	O
yes	O
let	O
s	O
call	O
that	O
the	O
yes	O
set	O
for	O
each	O
set	O
and	O
yes	O
we	O
will	O
build	O
a	O
histogram	B
over	O
the	O
labels	O
this	O
is	O
the	O
second	O
histogram	B
in	O
figure	O
now	O
suppose	O
you	O
were	O
to	O
ask	O
this	O
question	O
on	O
a	O
random	O
example	O
and	O
observe	O
a	O
value	O
of	O
no	O
further	O
suppose	O
that	O
you	O
must	O
immediately	O
guess	O
the	O
label	B
for	O
this	O
example	O
you	O
will	O
guess	O
like	O
because	O
that	O
s	O
the	O
more	O
prevalent	O
label	B
in	O
the	O
no	O
set	O
it	O
s	O
the	O
only	O
label	B
in	O
the	O
no	O
set	O
alternatively	O
if	O
you	O
recieve	O
an	O
answer	O
of	O
yes	O
you	O
will	O
guess	O
hate	O
because	O
that	O
is	O
more	O
prevalent	O
in	O
the	O
yes	O
set	O
so	O
for	O
this	O
single	O
feature	O
you	O
know	O
what	O
you	O
would	O
guess	O
if	O
you	O
had	O
to	O
now	O
you	O
can	O
ask	O
yourself	O
if	O
i	O
made	O
that	O
guess	O
on	O
the	O
training	B
data	I
how	O
well	O
would	O
i	O
have	O
done	O
in	O
particular	O
how	O
many	O
examples	B
would	O
i	O
classify	O
correctly	O
in	O
the	O
no	O
set	O
you	O
guessed	O
like	O
you	O
would	O
classify	O
all	O
of	O
them	O
correctly	O
in	O
the	O
yes	O
set	O
you	O
guessed	O
hate	O
you	O
would	O
classify	O
of	O
of	O
them	O
correctly	O
so	O
overall	O
you	O
would	O
classify	O
of	O
correctly	O
thus	O
we	O
ll	O
say	O
that	O
the	O
score	O
of	O
the	O
is	O
this	O
a	O
system	O
s	O
course	O
question	O
is	O
you	O
will	O
then	O
repeat	O
this	O
computation	O
for	O
each	O
of	O
the	O
available	O
features	B
to	O
us	O
compute	O
the	O
scores	O
for	O
each	O
of	O
them	O
when	O
you	O
must	O
choose	O
which	O
feature	O
consider	O
first	O
you	O
will	O
want	O
to	O
choose	O
the	O
one	O
with	O
the	O
highest	O
score	O
but	O
this	O
only	O
lets	O
you	O
choose	O
the	O
first	O
feature	O
to	O
ask	O
about	O
this	O
is	O
the	O
feature	O
that	O
goes	O
at	O
the	O
root	O
of	O
the	O
decision	B
tree	I
how	O
do	O
we	O
choose	O
subsequent	O
features	B
this	O
is	O
where	O
the	O
notion	O
of	O
divide	O
and	O
conquer	O
comes	O
in	O
you	O
ve	O
already	O
decided	O
on	O
your	O
first	O
feature	O
is	O
this	O
a	O
systems	O
course	O
you	O
can	O
now	O
partition	O
the	O
data	O
into	O
two	O
parts	O
the	O
no	O
part	O
and	O
the	O
yes	O
part	O
the	O
no	O
part	O
is	O
the	O
subset	O
of	O
the	O
data	O
on	O
which	O
value	O
for	O
this	O
feature	O
is	O
no	O
the	O
yes	O
half	O
is	O
the	O
rest	O
this	O
is	O
the	O
divide	O
step	O
how	O
many	O
training	O
examples	B
would	O
you	O
classify	O
correctly	O
for	O
each	O
of	O
the	O
other	O
three	O
features	B
from	O
figure	O
decision	B
trees	I
return	O
leafguess	O
algorithm	B
decisiontreetraindata	O
remaining	O
features	B
guess	O
most	O
frequent	O
answer	O
in	O
data	O
if	O
the	O
labels	O
in	O
data	O
are	O
unambiguous	O
then	O
else	O
if	O
remaining	O
features	B
is	O
empty	O
then	O
else	O
return	O
leafguess	O
for	O
all	O
f	O
remaining	O
features	B
do	O
no	O
the	O
subset	O
of	O
data	O
on	O
which	O
f	O
yes	O
the	O
subset	O
of	O
data	O
on	O
which	O
f	O
scoref	O
of	O
majority	O
vote	B
answers	O
in	O
no	O
of	O
majority	O
vote	B
answers	O
in	O
yes	O
default	O
answer	O
for	O
this	O
data	O
base	O
case	O
no	O
need	O
to	O
split	O
further	O
base	O
case	O
cannot	O
split	O
further	O
we	O
need	O
to	O
query	O
more	O
features	B
the	O
accuracy	O
we	O
would	O
get	O
if	O
we	O
only	O
queried	O
on	O
f	O
end	O
for	O
f	O
the	O
feature	O
with	O
maximal	O
scoref	O
no	O
the	O
subset	O
of	O
data	O
on	O
which	O
f	O
yes	O
the	O
subset	O
of	O
data	O
on	O
which	O
f	O
left	O
decisiontreetrainno	O
remaining	O
features	B
right	O
decisiontreetrainyes	O
remaining	O
features	B
return	O
nodef	O
left	O
right	O
end	O
if	O
algorithm	B
decisiontreetesttree	O
test	O
point	O
if	O
tree	O
is	O
of	O
the	O
form	O
leafguess	O
then	O
else	O
if	O
tree	O
is	O
of	O
the	O
form	O
nodef	O
left	O
right	O
then	O
if	O
f	O
yes	O
in	O
test	O
point	O
then	O
return	O
guess	O
return	O
decisiontreetestleft	O
test	O
point	O
else	O
return	O
decisiontreetestright	O
test	O
point	O
end	O
if	O
end	O
if	O
the	O
conquer	O
step	O
is	O
to	O
recurse	O
and	O
run	O
the	O
same	O
routine	O
the	O
feature	O
with	O
the	O
highest	O
score	O
on	O
the	O
no	O
set	O
get	O
the	O
left	O
half	O
of	O
the	O
tree	O
and	O
then	O
separately	O
on	O
the	O
yes	O
set	O
get	O
the	O
right	O
half	O
of	O
the	O
tree	O
at	O
some	O
point	O
it	O
will	O
become	O
useless	O
to	O
query	O
on	O
additional	O
fea	O
tures	O
for	O
instance	O
once	O
you	O
know	O
that	O
this	O
is	O
a	O
systems	O
course	O
you	O
know	O
that	O
everyone	O
will	O
hate	O
it	O
so	O
you	O
can	O
immediately	O
predict	B
hate	O
without	O
asking	O
any	O
additional	O
questions	O
similarly	O
at	O
some	O
point	O
you	O
might	O
have	O
already	O
queried	O
every	O
available	O
feature	O
and	O
still	O
not	O
whittled	O
down	O
to	O
a	O
single	O
answer	O
in	O
both	O
cases	O
you	O
will	O
need	O
to	O
create	O
a	O
leaf	O
node	O
and	O
guess	O
the	O
most	O
prevalent	O
answer	O
in	O
the	O
current	O
piece	O
of	O
the	O
training	B
data	I
that	O
you	O
are	O
looking	O
at	O
putting	O
this	O
all	O
together	O
we	O
arrive	O
at	O
the	O
algorithm	B
shown	O
in	O
algorithm	B
this	O
function	O
decisiontreetrain	O
takes	O
two	O
argu	O
there	O
are	O
more	O
nuanced	O
algorithms	O
for	O
building	O
decision	B
trees	I
some	O
of	O
which	O
are	O
discussed	O
in	O
later	O
chapters	O
of	O
this	O
book	O
they	O
primarily	O
differ	O
in	O
how	O
they	O
compute	O
the	O
score	O
funciton	O
a	O
course	O
in	O
machine	O
learning	O
ments	O
our	O
data	O
and	O
the	O
set	O
of	O
as-yet	O
unused	O
features	B
it	O
has	O
two	O
base	O
cases	O
either	O
the	O
data	O
is	O
unambiguous	O
or	O
there	O
are	O
no	O
remaining	O
features	B
in	O
either	O
case	O
it	O
returns	O
a	O
leaf	O
node	O
containing	O
the	O
most	O
likely	O
guess	O
at	O
this	O
point	O
otherwise	O
it	O
loops	O
over	O
all	O
remaining	O
features	B
to	O
find	O
the	O
one	O
with	O
the	O
highest	O
score	O
it	O
then	O
partitions	O
the	O
data	O
into	O
a	O
noyes	O
split	O
based	O
on	O
the	O
best	O
feature	O
it	O
constructs	O
its	O
left	O
and	O
right	O
subtrees	O
by	O
recursing	O
on	O
itself	O
in	O
each	O
recursive	O
call	O
it	O
uses	O
one	O
of	O
the	O
partitions	O
of	O
the	O
data	O
and	O
removes	O
the	O
just-selected	O
feature	O
from	O
consideration	O
the	O
corresponding	O
prediction	O
algorithm	B
is	O
shown	O
in	O
algorithm	B
this	O
function	O
recurses	O
down	O
the	O
decision	B
tree	I
following	O
the	O
edges	O
specified	O
by	O
the	O
feature	B
values	I
in	O
some	O
test	O
point	O
when	O
it	O
reaches	O
a	O
leaf	O
it	O
returns	O
the	O
guess	O
associated	O
with	O
that	O
leaf	O
todo	O
define	O
outlier	O
somewhere	O
formalizing	O
the	O
learning	O
problem	O
as	O
you	O
ve	O
seen	O
there	O
are	O
several	O
issues	O
that	O
we	O
must	O
take	O
into	O
account	O
when	O
formalizing	O
the	O
notion	O
of	O
learning	O
the	O
performance	O
of	O
the	O
learning	O
algorithm	B
should	O
be	O
measured	O
on	O
unseen	O
test	B
data	I
the	O
way	O
in	O
which	O
we	O
measure	O
performance	O
should	O
depend	O
on	O
the	O
problem	O
we	O
are	O
trying	O
to	O
solve	O
there	O
should	O
be	O
a	O
strong	O
relationship	O
between	O
the	O
data	O
that	O
our	O
algorithm	B
sees	O
at	O
training	O
time	O
and	O
the	O
data	O
it	O
sees	O
at	O
test	O
time	O
in	O
order	O
to	O
accomplish	O
this	O
let	O
s	O
assume	O
that	O
someone	O
gives	O
us	O
a	O
loss	B
function	I
of	O
two	O
arguments	O
the	O
job	O
of	O
is	O
to	O
tell	O
us	O
how	O
bad	O
a	O
system	O
s	O
prediction	O
is	O
in	O
comparison	O
to	O
the	O
truth	O
in	O
particular	O
if	O
y	O
is	O
the	O
truth	O
and	O
y	O
is	O
the	O
system	O
s	O
prediction	O
then	O
y	O
is	O
a	O
measure	O
of	O
error	O
for	O
three	O
of	O
the	O
canonical	O
tasks	O
discussed	O
above	O
we	O
might	O
use	O
the	O
following	O
loss	O
functions	O
regression	O
squared	B
loss	I
y	O
or	O
absolute	B
loss	I
y	O
y	O
binary	O
classification	O
zeroone	O
loss	O
y	O
multiclass	O
classification	O
also	O
zeroone	O
loss	O
if	O
y	O
y	O
otherwise	O
note	O
that	O
the	O
loss	B
function	I
is	O
something	O
that	O
you	O
must	O
decide	O
on	O
based	O
on	O
the	O
goals	O
of	O
learning	O
is	O
algorithm	B
guaranteed	O
to	O
terminate	O
this	O
notation	O
means	O
that	O
the	O
loss	O
is	O
zero	O
if	O
the	O
prediction	O
is	O
correct	O
and	O
is	O
one	O
otherwise	O
why	O
might	O
it	O
be	O
a	O
bad	O
idea	O
to	O
use	O
zeroone	O
loss	O
to	O
measure	O
performance	O
for	O
a	O
regression	O
problem	O
now	O
that	O
we	O
have	O
defined	O
our	O
loss	B
function	I
we	O
need	O
to	O
consider	O
where	O
the	O
data	O
and	O
test	O
comes	O
from	O
the	O
model	B
that	O
we	O
will	O
use	O
is	O
the	O
probabilistic	O
model	B
of	O
learning	O
namely	O
there	O
is	O
a	O
probability	O
distribution	O
d	O
over	O
inputoutput	O
pairs	O
this	O
is	O
often	O
called	O
the	O
data	B
generating	I
distribution	I
if	O
we	O
write	O
x	O
for	O
the	O
input	O
usercourse	O
pair	O
and	O
y	O
for	O
the	O
output	O
rating	O
then	O
d	O
is	O
a	O
distribution	O
over	O
y	O
pairs	O
a	O
useful	O
way	O
to	O
think	O
about	O
d	O
is	O
that	O
it	O
gives	O
high	O
probability	O
to	O
reasonable	O
y	O
pairs	O
and	O
low	O
probability	O
to	O
unreasonable	O
y	O
pairs	O
a	O
y	O
pair	O
can	O
be	O
unreasonable	O
in	O
two	O
ways	O
first	O
x	O
might	O
be	O
an	O
unusual	O
input	O
for	O
example	O
a	O
x	O
related	O
to	O
an	O
intro	O
to	O
java	O
course	O
might	O
be	O
highly	O
probable	O
a	O
x	O
related	O
to	O
a	O
geometric	O
and	O
solid	O
modeling	B
course	O
might	O
be	O
less	O
probable	O
second	O
y	O
might	O
be	O
an	O
unusual	O
rating	O
for	O
the	O
paired	O
x	O
for	O
instance	O
if	O
alice	O
were	O
to	O
take	O
ai	O
times	O
remembering	O
that	O
she	O
took	O
it	O
before	O
she	O
would	O
give	O
the	O
course	O
a	O
almost	O
every	O
time	O
perhaps	O
some	O
semesters	O
she	O
might	O
give	O
a	O
slightly	O
lower	O
score	O
but	O
it	O
would	O
be	O
unlikely	O
to	O
see	O
x	O
paired	O
with	O
y	O
it	O
is	O
important	O
to	O
remember	O
that	O
we	O
are	O
not	O
making	O
any	O
assumptions	O
about	O
what	O
the	O
distribution	O
d	O
looks	O
like	O
instance	O
we	O
re	O
not	O
assuming	O
it	O
looks	O
like	O
a	O
gaussian	O
or	O
some	O
other	O
common	O
distribution	O
we	O
are	O
also	O
not	O
assuming	O
that	O
we	O
know	O
what	O
d	O
is	O
in	O
fact	O
if	O
you	O
know	O
a	O
priori	O
what	O
your	O
data	B
generating	I
distribution	I
is	O
your	O
learning	O
problem	O
becomes	O
significantly	O
easier	O
perhaps	O
the	O
hardest	O
thing	O
about	O
machine	O
learning	O
is	O
that	O
we	O
don	O
t	O
know	O
what	O
d	O
is	O
all	O
we	O
get	O
is	O
a	O
random	O
sample	O
from	O
it	O
this	O
random	O
sample	O
is	O
our	O
training	B
data	I
our	O
learning	O
problem	O
then	O
is	O
defined	O
by	O
two	O
quantities	O
the	O
loss	B
function	I
which	O
captures	O
our	O
notion	O
of	O
what	O
is	O
important	O
to	O
learn	O
the	O
data	B
generating	I
distribution	I
d	O
which	O
defines	O
what	O
sort	O
of	O
data	O
we	O
expect	O
to	O
see	O
decision	B
trees	I
consider	O
the	O
following	O
prediction	O
task	O
given	O
a	O
paragraph	O
written	O
about	O
a	O
course	O
we	O
have	O
to	O
predict	B
whether	O
the	O
paragraph	O
is	O
a	O
positive	O
or	O
negative	O
review	O
of	O
the	O
course	O
is	O
the	O
sentiment	O
analysis	O
problem	O
what	O
is	O
a	O
reasonable	O
loss	B
function	I
how	O
would	O
you	O
define	O
the	O
data	B
generating	I
distribution	I
we	O
are	O
given	O
access	O
to	O
training	B
data	I
which	O
is	O
a	O
random	O
sample	O
of	O
inputoutput	O
pairs	O
drawn	O
from	O
d	O
based	O
on	O
this	O
training	B
data	I
we	O
need	O
to	O
induce	B
a	O
function	O
f	O
that	O
maps	O
new	O
inputs	O
x	O
to	O
corresponding	O
prediction	O
y	O
the	O
key	O
property	O
that	O
f	O
should	O
obey	O
is	O
that	O
it	O
should	O
do	O
well	O
measured	O
by	O
on	O
future	O
examples	B
that	O
are	O
also	O
drawn	O
from	O
d	O
formally	O
it	O
s	O
expected	B
loss	I
over	O
d	O
with	O
repsect	O
to	O
should	O
be	O
as	O
small	O
as	O
possible	O
f	O
e	O
dx	O
f	O
a	O
course	O
in	O
machine	O
learning	O
the	O
difficulty	O
in	O
minimizing	O
our	O
expected	B
loss	I
from	O
eq	O
is	O
that	O
we	O
don	O
t	O
know	O
what	O
d	O
is	O
all	O
we	O
have	O
access	O
to	O
is	O
some	O
training	B
data	I
sampled	O
from	O
it	O
suppose	O
that	O
we	O
denote	O
our	O
training	B
data	I
set	O
by	O
d	O
the	O
training	B
data	I
consists	O
of	O
n-many	O
inputoutput	O
pairs	O
yn	O
given	O
a	O
learned	O
function	O
f	O
we	O
can	O
compute	O
our	O
training	B
error	I
n	O
n	O
f	O
that	O
is	O
our	O
training	B
error	I
is	O
simply	O
our	O
average	O
error	O
over	O
the	O
train	O
ing	O
data	O
of	O
course	O
we	O
can	O
drive	O
to	O
zero	O
by	O
simply	O
memorizing	O
our	O
train	O
ing	O
data	O
but	O
as	O
alice	O
might	O
find	O
in	O
memorizing	O
past	O
exams	O
this	O
might	O
not	O
generalize	B
well	O
to	O
a	O
new	O
exam	O
this	O
is	O
the	O
fundamental	O
difficulty	O
in	O
machine	O
learning	O
the	O
thing	O
we	O
have	O
access	O
to	O
is	O
our	O
training	B
error	I
but	O
the	O
thing	O
we	O
care	O
about	O
minimizing	O
is	O
our	O
expected	O
error	O
in	O
order	O
to	O
get	O
the	O
expected	O
error	O
down	O
our	O
learned	O
function	O
needs	O
to	O
generalize	B
beyond	O
the	O
training	B
data	I
to	O
some	O
future	O
data	O
that	O
it	O
might	O
not	O
have	O
seen	O
yet	O
so	O
putting	O
it	O
all	O
together	O
we	O
get	O
a	O
formal	O
definition	O
of	O
induction	B
machine	O
learning	O
given	O
a	O
loss	B
function	I
and	O
a	O
sample	O
d	O
from	O
some	O
unknown	O
distribution	O
d	O
you	O
must	O
compute	O
a	O
function	O
f	O
that	O
has	O
low	O
expected	O
error	O
over	O
d	O
with	O
respect	O
to	O
inductive	B
bias	B
what	O
we	O
know	O
before	O
the	O
data	O
arrives	O
d	O
f	O
by	O
thinking	O
verify	O
by	O
calculation	O
that	O
we	O
can	O
write	O
our	O
training	B
error	I
as	O
e	O
of	O
d	O
as	O
a	O
distribution	O
that	O
places	O
probability	O
to	O
each	O
example	O
in	O
d	O
and	O
probabiliy	O
on	O
everything	O
else	O
decision	B
trees	I
math	O
review	O
expectated	O
values	O
f	O
for	O
the	O
expected	B
loss	I
here	O
as	O
always	O
in	O
this	O
book	O
we	O
will	O
often	O
write	O
things	O
like	O
e	O
expectation	O
means	O
average	O
in	O
words	O
this	O
is	O
saying	O
if	O
you	O
drew	O
a	O
bunch	O
of	O
y	O
pairs	O
independently	B
at	O
random	O
from	O
d	O
what	O
would	O
your	O
average	O
loss	O
be	O
formally	O
what	O
would	O
be	O
the	O
average	O
of	O
f	O
be	O
over	O
these	O
random	O
draws	O
more	O
formally	O
if	O
d	O
is	O
a	O
discrete	O
probability	O
distribution	O
then	O
this	O
expectation	O
can	O
be	O
expanded	O
as	O
e	O
f	O
d	O
f	O
this	O
is	O
exactly	O
the	O
weighted	O
average	O
loss	O
over	O
the	O
all	O
y	O
pairs	O
in	O
d	O
weighted	O
by	O
their	O
probability	O
dx	O
y	O
under	O
this	O
distribution	O
d	O
in	O
particular	O
if	O
d	O
is	O
a	O
finite	O
discrete	B
distribution	I
for	O
instance	O
one	O
defined	O
by	O
a	O
finite	O
data	O
set	O
yn	O
that	O
puts	O
equal	O
weight	O
on	O
each	O
example	O
this	O
case	O
equal	O
weight	O
means	O
probability	O
then	O
we	O
get	O
e	O
f	O
d	O
n	O
f	O
f	O
definition	O
of	O
expectation	O
d	O
is	O
discrete	O
and	O
finite	O
definition	O
of	O
d	O
rearranging	O
terms	O
n	O
n	O
n	O
n	O
f	O
f	O
which	O
is	O
exactly	O
the	O
average	O
loss	O
on	O
that	O
dataset	O
in	O
the	O
case	O
that	O
the	O
distribution	O
is	O
continuous	O
we	O
need	O
to	O
replace	O
the	O
discrete	O
sum	O
with	O
a	O
continuous	O
integral	O
over	O
some	O
space	O
e	O
f	O
dx	O
f	O
this	O
is	O
exactly	O
the	O
same	O
but	O
in	O
continuous	O
space	O
rather	O
than	O
discrete	O
space	O
the	O
most	O
important	O
thing	O
to	O
remember	O
is	O
that	O
there	O
are	O
two	O
equivalent	O
ways	O
to	O
think	O
about	O
expections	O
the	O
expectation	O
of	O
some	O
function	O
g	O
is	O
the	O
weighted	O
average	O
value	O
of	O
g	O
where	O
the	O
weights	B
are	O
given	O
by	O
the	O
underlying	O
probability	O
distribution	O
the	O
expectation	O
of	O
some	O
function	O
g	O
is	O
your	O
best	O
guess	O
of	O
the	O
value	O
of	O
g	O
if	O
you	O
were	O
to	O
draw	O
a	O
single	O
item	O
from	O
the	O
underlying	O
probability	O
distribution	O
figure	O
a	O
course	O
in	O
machine	O
learning	O
in	O
figure	O
you	O
ll	O
find	O
training	B
data	I
for	O
a	O
binary	O
classification	O
problem	O
the	O
two	O
labels	O
are	O
a	O
and	O
b	O
and	O
you	O
can	O
see	O
five	O
examples	B
for	O
each	O
label	B
below	O
in	O
figure	O
you	O
will	O
see	O
some	O
test	B
data	I
these	O
images	O
are	O
left	O
unlabeled	O
go	O
through	O
quickly	O
and	O
based	O
on	O
the	O
training	B
data	I
label	B
these	O
images	O
do	O
it	O
before	O
you	O
read	O
further	O
i	O
ll	O
wait	O
most	O
likely	O
you	O
produced	O
one	O
of	O
two	O
labelings	O
either	O
abbaab	O
or	O
abbaba	O
which	O
of	O
these	O
solutions	O
is	O
right	O
the	O
answer	O
is	O
that	O
you	O
cannot	O
tell	O
based	O
on	O
the	O
training	B
data	I
if	O
you	O
give	O
this	O
same	O
example	O
to	O
people	O
of	O
them	O
come	O
up	O
with	O
the	O
abbaab	O
prediction	O
and	O
come	O
up	O
with	O
the	O
abbaba	O
prediction	O
why	O
are	O
they	O
doing	O
this	O
presumably	O
because	O
the	O
first	O
group	O
believes	O
that	O
the	O
relevant	O
distinction	O
is	O
between	O
bird	O
and	O
non-bird	O
while	O
the	O
second	O
group	O
believes	O
that	O
the	O
relevant	O
distinction	O
is	O
between	O
fly	O
and	O
no-fly	O
this	O
preference	O
for	O
one	O
distinction	O
over	O
another	O
is	O
a	O
bias	B
that	O
different	O
human	O
learners	O
have	O
in	O
the	O
context	O
of	O
machine	O
learning	O
it	O
is	O
called	O
inductive	B
bias	B
in	O
the	O
absense	O
of	O
data	O
that	O
narrow	O
down	O
the	O
relevant	O
concept	B
what	O
type	O
of	O
solutions	O
are	O
we	O
more	O
likely	O
to	O
prefer	O
two	O
thirds	O
of	O
people	O
seem	O
to	O
have	O
an	O
inductive	B
bias	B
in	O
favor	O
of	O
birdnon-bird	O
and	O
one	O
third	O
seem	O
to	O
have	O
an	O
inductive	B
bias	B
in	O
favor	O
of	O
flyno-fly	O
throughout	O
this	O
book	O
you	O
will	O
learn	O
about	O
several	O
approaches	O
to	O
machine	O
learning	O
the	O
decision	B
tree	I
model	B
is	O
the	O
first	O
such	O
approach	O
these	O
approaches	O
differ	O
primarily	O
in	O
the	O
sort	O
of	O
inductive	B
bias	B
that	O
they	O
exhibit	O
consider	O
a	O
variant	O
of	O
the	O
decision	B
tree	I
learning	O
algorithm	B
in	O
this	O
variant	O
we	O
will	O
not	O
allow	O
the	O
trees	O
to	O
grow	O
beyond	O
some	O
pre-defined	O
maximum	B
depth	I
d	O
that	O
is	O
once	O
we	O
have	O
queried	O
on	O
d-many	O
features	B
we	O
cannot	O
query	O
on	O
any	O
more	O
and	O
must	O
just	O
make	O
the	O
best	O
guess	O
we	O
can	O
at	O
that	O
point	O
this	O
variant	O
is	O
called	O
a	O
shallow	B
decision	B
tree	I
the	O
key	O
question	O
is	O
what	O
is	O
the	O
inductive	B
bias	B
of	O
shallow	O
decision	B
trees	I
roughly	O
their	O
bias	B
is	O
that	O
decisions	O
can	O
be	O
made	O
by	O
only	O
looking	O
at	O
a	O
small	O
number	O
of	O
features	B
for	O
instance	O
a	O
shallow	B
decision	B
tree	I
would	O
be	O
very	O
good	O
at	O
learning	O
a	O
function	O
like	O
students	O
only	O
like	O
ai	O
courses	O
it	O
would	O
be	O
very	O
bad	O
at	O
learning	O
a	O
function	O
like	O
if	O
this	O
student	O
has	O
liked	O
an	O
odd	O
number	O
of	O
his	O
past	O
courses	O
he	O
will	O
like	O
the	O
next	O
one	O
otherwise	O
he	O
will	O
not	O
this	O
latter	O
is	O
the	O
parity	B
function	I
which	O
requires	O
you	O
to	O
inspect	O
every	O
feature	O
to	O
make	O
a	O
prediction	O
the	O
inductive	B
bias	B
of	O
a	O
decision	B
tree	I
is	O
that	O
the	O
sorts	O
of	O
things	O
we	O
want	O
to	O
learn	O
to	O
predict	B
are	O
more	O
like	O
the	O
first	O
example	O
and	O
less	O
like	O
the	O
second	O
example	O
figure	O
dtbird	O
bird	O
training	O
images	O
figure	O
dtbirdtest	O
bird	O
test	O
images	O
it	O
is	O
also	O
possible	O
that	O
the	O
correct	O
classification	O
on	O
the	O
test	B
data	I
is	O
babaaa	O
this	O
corresponds	O
to	O
the	O
bias	B
is	O
the	O
background	O
in	O
focus	O
somehow	O
no	O
one	O
seems	O
to	O
come	O
up	O
with	O
this	O
classification	O
rule	O
decision	B
trees	I
not	O
everything	O
is	O
learnable	O
although	O
machine	O
learning	O
works	O
well	O
perhaps	O
astonishingly	O
well	O
in	O
many	O
cases	O
it	O
is	O
important	O
to	O
keep	O
in	O
mind	O
that	O
it	O
is	O
not	O
magical	O
there	O
are	O
many	O
reasons	O
why	O
a	O
machine	O
learning	O
algorithm	B
might	O
fail	O
on	O
some	O
learning	O
task	O
there	O
could	O
be	O
noise	B
in	O
the	O
training	B
data	I
noise	B
can	O
occur	O
both	O
at	O
the	O
feature	O
level	O
and	O
at	O
the	O
label	B
level	O
some	O
features	B
might	O
correspond	O
to	O
measurements	O
taken	O
by	O
sensors	O
for	O
instance	O
a	O
robot	O
might	O
use	O
a	O
laser	O
range	O
finder	O
to	O
compute	O
its	O
distance	B
to	O
a	O
wall	O
however	O
this	O
sensor	O
might	O
fail	O
and	O
return	O
an	O
incorrect	O
value	O
in	O
a	O
sentiment	O
classification	O
problem	O
someone	O
might	O
have	O
a	O
typo	O
in	O
their	O
review	O
of	O
a	O
course	O
these	O
would	O
lead	O
to	O
noise	B
at	O
the	O
feature	O
level	O
there	O
might	O
also	O
be	O
noise	B
at	O
the	O
label	B
level	O
a	O
student	O
might	O
write	O
a	O
scathingly	O
negative	O
review	O
of	O
a	O
course	O
but	O
then	O
accidentally	O
click	O
the	O
wrong	O
button	O
for	O
the	O
course	O
rating	O
the	O
features	B
available	O
for	O
learning	O
might	O
simply	O
be	O
insufficient	O
for	O
example	O
in	O
a	O
medical	O
context	O
you	O
might	O
wish	O
to	O
diagnose	O
whether	O
a	O
patient	O
has	O
cancer	O
or	O
not	O
you	O
may	O
be	O
able	O
to	O
collect	O
a	O
large	O
amount	O
of	O
data	O
about	O
this	O
patient	O
such	O
as	O
gene	O
expressions	O
x-rays	O
family	O
histories	O
etc	O
but	O
even	O
knowing	O
all	O
of	O
this	O
information	O
exactly	O
it	O
might	O
still	O
be	O
impossible	O
to	O
judge	O
for	O
sure	O
whether	O
this	O
patient	O
has	O
cancer	O
or	O
not	O
as	O
a	O
more	O
contrived	O
example	O
you	O
might	O
try	O
to	O
classify	O
course	O
reviews	O
as	O
positive	O
or	O
negative	O
but	O
you	O
may	O
have	O
erred	O
when	O
downloading	O
the	O
data	O
and	O
only	O
gotten	O
the	O
first	O
five	O
characters	O
of	O
each	O
review	O
if	O
you	O
had	O
the	O
rest	O
of	O
the	O
features	B
you	O
might	O
be	O
able	O
to	O
do	O
well	O
but	O
with	O
this	O
limited	O
feature	O
set	O
there	O
s	O
not	O
much	O
you	O
can	O
do	O
some	O
examples	B
may	O
not	O
have	O
a	O
single	O
correct	O
answer	O
you	O
might	O
be	O
building	O
a	O
system	O
for	O
safe	O
web	O
search	O
which	O
removes	O
offensive	O
web	O
pages	O
from	O
search	O
results	O
to	O
build	O
this	O
system	O
you	O
would	O
collect	O
a	O
set	O
of	O
web	O
pages	O
and	O
ask	O
people	O
to	O
classify	O
them	O
as	O
offensive	O
or	O
not	O
however	O
what	O
one	O
person	O
considers	O
offensive	O
might	O
be	O
completely	O
reasonable	O
for	O
another	O
person	O
it	O
is	O
common	O
to	O
consider	O
this	O
as	O
a	O
form	O
of	O
label	B
noise	B
nevertheless	O
since	O
you	O
as	O
the	O
designer	O
of	O
the	O
learning	O
system	O
have	O
some	O
control	O
over	O
this	O
problem	O
it	O
is	O
sometimes	O
helpful	O
to	O
isolate	O
it	O
as	O
a	O
source	O
of	O
difficulty	O
finally	O
learning	O
might	O
fail	O
because	O
the	O
inductive	B
bias	B
of	O
the	O
learning	O
algorithm	B
is	O
too	O
far	O
away	O
from	O
the	O
concept	B
that	O
is	O
being	O
learned	O
in	O
the	O
birdnon-bird	O
data	O
you	O
might	O
think	O
that	O
if	O
you	O
had	O
gotten	O
a	O
few	O
more	O
training	O
examples	B
you	O
might	O
have	O
been	O
able	O
to	O
tell	O
whether	O
this	O
was	O
intended	O
to	O
be	O
a	O
birdnon-bird	O
classification	O
or	O
a	O
flyno-fly	O
classification	O
however	O
no	O
one	O
i	O
ve	O
talked	O
to	O
has	O
ever	O
come	O
up	O
with	O
the	O
background	O
is	O
in	O
focus	O
classification	O
even	O
with	O
many	O
a	O
course	O
in	O
machine	O
learning	O
more	O
training	O
points	O
this	O
is	O
such	O
an	O
unusual	O
distinction	O
that	O
it	O
may	O
be	O
hard	O
for	O
anyone	O
to	O
figure	O
out	O
it	O
in	O
this	O
case	O
the	O
inductive	B
bias	B
of	O
the	O
learner	O
is	O
simply	O
too	O
misaligned	O
with	O
the	O
target	O
classification	O
to	O
learn	O
note	O
that	O
the	O
inductive	B
bias	B
source	O
of	O
error	O
is	O
fundamentally	O
dif	O
ferent	O
than	O
the	O
other	O
three	O
sources	O
of	O
error	O
in	O
the	O
inductive	B
bias	B
case	O
it	O
is	O
the	O
particular	O
learning	O
algorithm	B
that	O
you	O
are	O
using	O
that	O
cannot	O
cope	O
with	O
the	O
data	O
maybe	O
if	O
you	O
switched	O
to	O
a	O
different	O
learning	O
algorithm	B
you	O
would	O
be	O
able	O
to	O
learn	O
well	O
for	O
instance	O
neptunians	O
might	O
have	O
evolved	O
to	O
care	O
greatly	O
about	O
whether	O
backgrounds	O
are	O
in	O
focus	O
and	O
for	O
them	O
this	O
would	O
be	O
an	O
easy	O
classification	O
to	O
learn	O
for	O
the	O
other	O
three	O
sources	O
of	O
error	O
it	O
is	O
not	O
an	O
issue	O
to	O
do	O
with	O
the	O
particular	O
learning	O
algorithm	B
the	O
error	O
is	O
a	O
fundamental	O
part	O
of	O
the	O
learning	O
problem	O
underfitting	B
and	O
overfitting	B
as	O
with	O
many	O
problems	O
it	O
is	O
useful	O
to	O
think	O
about	O
the	O
extreme	O
cases	O
of	O
learning	O
algorithms	O
in	O
particular	O
the	O
extreme	O
cases	O
of	O
decision	B
trees	I
in	O
one	O
extreme	O
the	O
tree	O
is	O
empty	O
and	O
we	O
do	O
not	O
ask	O
any	O
questions	O
at	O
all	O
we	O
simply	O
immediately	O
make	O
a	O
prediction	O
in	O
the	O
other	O
extreme	O
the	O
tree	O
is	O
full	O
that	O
is	O
every	O
possible	O
question	O
is	O
asked	O
along	O
every	O
branch	O
in	O
the	O
full	O
tree	O
there	O
may	O
be	O
leaves	O
with	O
no	O
associated	O
training	B
data	I
for	O
these	O
we	O
must	O
simply	O
choose	O
arbitrarily	O
whether	O
to	O
say	O
yes	O
or	O
no	O
consider	O
the	O
course	O
recommendation	O
data	O
from	O
table	O
sup	O
pose	O
we	O
were	O
to	O
build	O
an	O
empty	O
decision	B
tree	I
on	O
this	O
data	O
such	O
a	O
decision	B
tree	I
will	O
make	O
the	O
same	O
prediction	O
regardless	O
of	O
its	O
input	O
because	O
it	O
is	O
not	O
allowed	O
to	O
ask	O
any	O
questions	O
about	O
its	O
input	O
since	O
there	O
are	O
more	O
likes	O
than	O
hates	O
in	O
the	O
training	B
data	I
versus	O
our	O
empty	O
decision	B
tree	I
will	O
simply	O
always	O
predict	B
likes	O
the	O
training	B
error	I
is	O
on	O
the	O
other	O
hand	O
we	O
could	O
build	O
a	O
full	O
decision	B
tree	I
since	O
each	O
row	O
in	O
this	O
data	O
is	O
unique	O
we	O
can	O
guarantee	O
that	O
any	O
leaf	O
in	O
a	O
full	O
decision	B
tree	I
will	O
have	O
either	O
or	O
examples	B
assigned	O
to	O
it	O
of	O
the	O
leaves	O
will	O
have	O
one	O
example	O
the	O
rest	O
will	O
have	O
none	O
for	O
the	O
leaves	O
corresponding	O
to	O
training	O
points	O
the	O
full	O
decision	B
tree	I
will	O
always	O
make	O
the	O
correct	O
prediction	O
given	O
this	O
the	O
training	B
error	I
is	O
of	O
course	O
our	O
goal	O
is	O
not	O
to	O
build	O
a	O
model	B
that	O
gets	O
error	O
on	O
the	O
training	B
data	I
this	O
would	O
be	O
easy	O
our	O
goal	O
is	O
a	O
model	B
that	O
will	O
do	O
well	O
on	O
future	O
unseen	O
data	O
how	O
well	O
might	O
we	O
expect	O
these	O
two	O
models	O
to	O
do	O
on	O
future	O
data	O
the	O
empty	O
tree	O
is	O
likely	O
to	O
do	O
not	O
much	O
better	O
and	O
not	O
much	O
worse	O
on	O
future	O
data	O
we	O
might	O
expect	O
decision	B
trees	I
convince	O
yourself	O
by	O
proof	O
or	O
by	O
simulation	O
that	O
even	O
in	O
the	O
case	O
of	O
imbalanced	B
data	I
for	O
instance	O
data	O
that	O
is	O
on	O
average	O
positive	O
and	O
negative	O
a	O
predictor	O
that	O
guesses	O
randomly	O
positivenegative	O
will	O
get	O
about	O
error	O
which	O
feature	O
is	O
it	O
and	O
what	O
is	O
it	O
s	O
training	B
error	I
that	O
it	O
would	O
continue	O
to	O
get	O
around	O
error	O
life	O
is	O
more	O
complicated	O
for	O
the	O
full	O
decision	B
tree	I
certainly	O
if	O
it	O
is	O
given	O
a	O
test	O
example	O
that	O
is	O
identical	O
to	O
one	O
of	O
the	O
training	O
examples	B
it	O
will	O
do	O
the	O
right	O
thing	O
no	O
noise	B
but	O
for	O
everything	O
else	O
it	O
will	O
only	O
get	O
about	O
error	O
this	O
means	O
that	O
even	O
if	O
every	O
other	O
test	O
point	O
happens	O
to	O
be	O
identical	O
to	O
one	O
of	O
the	O
training	O
points	O
it	O
would	O
only	O
get	O
about	O
error	O
in	O
practice	O
this	O
is	O
probably	O
optimistic	O
and	O
maybe	O
only	O
one	O
in	O
every	O
examples	B
would	O
match	O
a	O
training	O
example	O
yielding	O
a	O
error	O
so	O
in	O
one	O
case	O
tree	O
we	O
ve	O
achieved	O
about	O
error	O
and	O
in	O
the	O
other	O
case	O
tree	O
we	O
ve	O
achieved	O
error	O
this	O
is	O
not	O
very	O
promising	O
one	O
would	O
hope	O
to	O
do	O
better	O
in	O
fact	O
you	O
might	O
notice	O
that	O
if	O
you	O
simply	O
queried	O
on	O
a	O
single	O
feature	O
for	O
this	O
data	O
you	O
would	O
be	O
able	O
to	O
get	O
very	O
low	O
training	B
error	I
but	O
wouldn	O
t	O
be	O
forced	O
to	O
guess	O
randomly	O
this	O
example	O
illustrates	O
the	O
key	O
concepts	O
of	O
underfitting	B
and	O
overfitting	B
underfitting	B
is	O
when	O
you	O
had	O
the	O
opportunity	O
to	O
learn	O
something	O
but	O
didn	O
t	O
a	O
student	O
who	O
hasn	O
t	O
studied	O
much	O
for	O
an	O
upcoming	O
exam	O
will	O
be	O
underfit	O
to	O
the	O
exam	O
and	O
consequently	O
will	O
not	O
do	O
well	O
this	O
is	O
also	O
what	O
the	O
empty	O
tree	O
does	O
overfitting	B
is	O
when	O
you	O
pay	O
too	O
much	O
attention	O
to	O
idiosyncracies	O
of	O
the	O
training	B
data	I
and	O
aren	O
t	O
able	O
to	O
generalize	B
well	O
often	O
this	O
means	O
that	O
your	O
model	B
is	O
fitting	O
noise	B
rather	O
than	O
whatever	O
it	O
is	O
supposed	O
to	O
fit	O
a	O
student	O
who	O
memorizes	O
answers	O
to	O
past	O
exam	O
questions	O
without	O
understanding	O
them	O
has	O
overfit	O
the	O
training	B
data	I
like	O
the	O
full	O
tree	O
this	O
student	O
also	O
will	O
not	O
do	O
well	O
on	O
the	O
exam	O
a	O
model	B
that	O
is	O
neither	O
overfit	O
nor	O
underfit	O
is	O
the	O
one	O
that	O
is	O
expected	O
to	O
do	O
best	O
in	O
the	O
future	O
separation	O
of	O
training	O
and	O
test	B
data	I
suppose	O
that	O
after	O
graduating	O
you	O
get	O
a	O
job	O
working	O
for	O
a	O
company	O
that	O
provides	O
personalized	O
recommendations	O
for	O
pottery	O
you	O
go	O
in	O
and	O
implement	O
new	O
algorithms	O
based	O
on	O
what	O
you	O
learned	O
in	O
your	O
machine	O
learning	O
class	O
have	O
learned	O
the	O
power	O
of	O
generalization	O
all	O
you	O
need	O
to	O
do	O
now	O
is	O
convince	O
your	O
boss	O
that	O
you	O
have	O
done	O
a	O
good	O
job	O
and	O
deserve	O
a	O
raise	O
how	O
can	O
you	O
convince	O
your	O
boss	O
that	O
your	O
fancy	O
learning	O
algo	O
rithms	O
are	O
really	O
working	O
based	O
on	O
what	O
we	O
ve	O
talked	O
about	O
already	O
with	O
underfitting	B
and	O
overfitting	B
it	O
is	O
not	O
enough	O
to	O
just	O
tell	O
your	O
boss	O
what	O
your	O
training	B
error	I
is	O
noise	B
notwithstanding	O
it	O
is	O
easy	O
to	O
get	O
a	O
training	B
error	I
of	O
zero	O
using	O
a	O
simple	O
database	O
query	O
grep	O
if	O
you	O
prefer	O
your	O
boss	O
will	O
not	O
fall	O
for	O
that	O
the	O
easiest	O
approach	O
is	O
to	O
set	O
aside	O
some	O
of	O
your	O
available	O
data	O
as	O
a	O
course	O
in	O
machine	O
learning	O
test	B
data	I
and	O
use	O
this	O
to	O
evaluate	O
the	O
performance	O
of	O
your	O
learning	O
algorithm	B
for	O
instance	O
the	O
pottery	O
recommendation	O
service	O
that	O
you	O
work	O
for	O
might	O
have	O
collected	O
examples	B
of	O
pottery	O
ratings	O
you	O
will	O
select	O
of	O
these	O
as	O
training	B
data	I
and	O
set	O
aside	O
the	O
final	O
as	O
test	B
data	I
you	O
will	O
run	O
your	O
learning	O
algorithms	O
only	O
on	O
the	O
training	O
points	O
only	O
once	O
you	O
re	O
done	O
will	O
you	O
apply	O
your	O
learned	O
model	B
to	O
the	O
test	O
points	O
and	O
report	O
your	O
test	B
error	I
on	O
those	O
points	O
to	O
your	O
boss	O
the	O
hope	O
in	O
this	O
process	O
is	O
that	O
however	O
well	O
you	O
do	O
on	O
the	O
test	O
points	O
will	O
be	O
indicative	O
of	O
how	O
well	O
you	O
are	O
likely	O
to	O
do	O
in	O
the	O
future	O
this	O
is	O
analogous	O
to	O
estimating	O
support	O
for	O
a	O
presidential	O
candidate	O
by	O
asking	O
a	O
small	O
sample	O
of	O
people	O
for	O
their	O
opinions	O
statistics	O
concentration	O
bounds	O
of	O
which	O
the	O
central	O
limit	O
theorem	O
is	O
a	O
famous	O
example	O
tells	O
us	O
that	O
if	O
the	O
sample	O
is	O
large	O
enough	O
it	O
will	O
be	O
a	O
good	O
representative	O
the	O
split	O
is	O
not	O
magic	O
it	O
s	O
simply	O
fairly	O
well	O
established	O
occasionally	O
people	O
use	O
a	O
split	O
instead	O
especially	O
if	O
they	O
have	O
a	O
lot	O
of	O
data	O
the	O
cardinal	O
rule	O
of	O
machine	O
learning	O
is	O
never	O
touch	O
your	O
test	B
data	I
ever	O
if	O
that	O
s	O
not	O
clear	O
enough	O
never	O
ever	O
touch	O
your	O
test	B
data	I
if	O
there	O
is	O
only	O
one	O
thing	O
you	O
learn	O
from	O
this	O
book	O
let	O
it	O
be	O
that	O
do	O
not	O
look	O
at	O
your	O
test	B
data	I
even	O
once	O
even	O
a	O
tiny	O
peek	O
once	O
you	O
do	O
that	O
it	O
is	O
not	O
test	B
data	I
any	O
more	O
yes	O
perhaps	O
your	O
algorithm	B
hasn	O
t	O
seen	O
it	O
but	O
you	O
have	O
and	O
you	O
are	O
likely	O
a	O
better	O
learner	O
than	O
your	O
learning	O
algorithm	B
consciously	O
or	O
otherwise	O
you	O
might	O
make	O
decisions	O
based	O
on	O
whatever	O
you	O
might	O
have	O
seen	O
once	O
you	O
look	O
at	O
the	O
test	B
data	I
your	O
model	B
s	O
performance	O
on	O
it	O
is	O
no	O
longer	O
indicative	O
of	O
it	O
s	O
performance	O
on	O
future	O
unseen	O
data	O
this	O
is	O
simply	O
because	O
future	O
data	O
is	O
unseen	O
but	O
your	O
test	B
data	I
no	O
longer	O
is	O
models	O
parameters	O
and	O
hyperparameters	O
the	O
general	O
approach	O
to	O
machine	O
learning	O
which	O
captures	O
many	O
existing	O
learning	O
algorithms	O
is	O
the	O
modeling	B
approach	O
the	O
idea	O
is	O
that	O
we	O
come	O
up	O
with	O
some	O
formal	O
model	B
of	O
our	O
data	O
for	O
instance	O
we	O
might	O
model	B
the	O
classification	O
decision	O
of	O
a	O
studentcourse	O
pair	O
as	O
a	O
decision	B
tree	I
the	O
choice	O
of	O
using	O
a	O
tree	O
to	O
represent	O
this	O
model	B
is	O
our	O
choice	O
we	O
also	O
could	O
have	O
used	O
an	O
arithmetic	O
circuit	O
or	O
a	O
polynomial	O
or	O
some	O
other	O
function	O
the	O
model	B
tells	O
us	O
what	O
sort	O
of	O
things	O
we	O
can	O
learn	O
and	O
also	O
tells	O
us	O
what	O
our	O
inductive	B
bias	B
is	O
for	O
most	O
models	O
there	O
will	O
be	O
associated	O
parameters	O
these	O
are	O
the	O
things	O
that	O
we	O
use	O
the	O
data	O
to	O
decide	O
on	O
parameters	O
in	O
a	O
decision	O
if	O
you	O
have	O
more	O
data	O
at	O
your	O
disposal	O
why	O
might	O
a	O
split	O
be	O
preferable	O
to	O
an	O
split	O
decision	B
trees	I
go	O
back	O
to	O
the	O
decisiontreetrain	O
algorithm	B
and	O
modify	O
it	O
so	O
that	O
it	O
takes	O
a	O
maximum	B
depth	I
parameter	O
this	O
should	O
require	O
adding	O
two	O
lines	O
of	O
code	O
and	O
modifying	O
three	O
others	O
tree	O
include	O
the	O
specific	O
questions	O
we	O
asked	O
the	O
order	O
in	O
which	O
we	O
asked	O
them	O
and	O
the	O
classification	O
decisions	O
at	O
the	O
leaves	O
the	O
job	O
of	O
our	O
decision	B
tree	I
learning	O
algorithm	B
decisiontreetrain	O
is	O
to	O
take	O
data	O
and	O
figure	O
out	O
a	O
good	O
set	O
of	O
parameters	O
many	O
learning	O
algorithms	O
will	O
have	O
additional	O
knobs	O
that	O
you	O
can	O
adjust	O
in	O
most	O
cases	O
these	O
knobs	O
amount	O
to	O
tuning	O
the	O
inductive	B
bias	B
of	O
the	O
algorithm	B
in	O
the	O
case	O
of	O
the	O
decision	B
tree	I
an	O
obvious	O
knob	O
that	O
one	O
can	O
tune	O
is	O
the	O
maximum	B
depth	I
of	O
the	O
decision	B
tree	I
that	O
is	O
we	O
could	O
modify	O
the	O
decisiontreetrain	O
function	O
so	O
that	O
it	O
stops	O
recursing	O
once	O
it	O
reaches	O
some	O
pre-defined	O
maximum	B
depth	I
by	O
playing	O
with	O
this	O
depth	O
knob	O
we	O
can	O
adjust	O
between	O
underfitting	B
empty	O
tree	O
depth	O
and	O
overfitting	B
full	O
tree	O
depth	O
such	O
a	O
knob	O
is	O
called	O
a	O
hyperparameter	B
it	O
is	O
so	O
called	O
because	O
it	O
is	O
a	O
parameter	O
that	O
controls	O
other	O
parameters	O
of	O
the	O
model	B
the	O
exact	O
definition	O
of	O
hyperparameter	B
is	O
hard	O
to	O
pin	O
down	O
it	O
s	O
one	O
of	O
those	O
things	O
that	O
are	O
easier	O
to	O
identify	O
than	O
define	O
however	O
one	O
of	O
the	O
key	O
identifiers	O
for	O
hyperparameters	O
the	O
main	O
reason	O
that	O
they	O
cause	O
consternation	O
is	O
that	O
they	O
cannot	O
be	O
naively	O
adjusted	O
using	O
the	O
training	B
data	I
in	O
decisiontreetrain	O
as	O
in	O
most	O
machine	O
learning	O
the	O
learn	O
ing	O
algorithm	B
is	O
essentially	O
trying	O
to	O
adjust	O
the	O
parameters	O
of	O
the	O
model	B
so	O
as	O
to	O
minimize	O
training	B
error	I
this	O
suggests	O
an	O
idea	O
for	O
choosing	O
hyperparameters	O
choose	O
them	O
so	O
that	O
they	O
minimize	O
training	B
error	I
what	O
is	O
wrong	O
with	O
this	O
suggestion	O
suppose	O
that	O
you	O
were	O
to	O
treat	O
maximum	B
depth	I
as	O
a	O
hyperparameter	B
and	O
tried	O
to	O
tune	O
it	O
on	O
your	O
training	B
data	I
to	O
do	O
this	O
maybe	O
you	O
simply	O
build	O
a	O
collection	O
of	O
decision	B
trees	I
where	O
treed	O
is	O
a	O
tree	O
of	O
maximum	B
depth	I
d	O
we	O
then	O
computed	O
the	O
training	B
error	I
of	O
each	O
of	O
these	O
trees	O
and	O
chose	O
the	O
ideal	O
maximum	B
depth	I
as	O
that	O
which	O
minimizes	O
training	B
error	I
which	O
one	O
would	O
it	O
pick	O
the	O
answer	O
is	O
that	O
it	O
would	O
pick	O
d	O
or	O
in	O
general	O
it	O
would	O
pick	O
d	O
as	O
large	O
as	O
possible	O
why	O
because	O
choosing	O
a	O
bigger	O
d	O
will	O
never	O
hurt	O
on	O
the	O
training	B
data	I
by	O
making	O
d	O
larger	O
you	O
are	O
simply	O
encouraging	O
overfitting	B
but	O
by	O
evaluating	O
on	O
the	O
training	B
data	I
overfitting	B
actually	O
looks	O
like	O
a	O
good	O
idea	O
an	O
alternative	O
idea	O
would	O
be	O
to	O
tune	O
the	O
maximum	B
depth	I
on	O
test	B
data	I
this	O
is	O
promising	O
because	O
test	B
data	I
peformance	O
is	O
what	O
we	O
really	O
want	O
to	O
optimize	O
so	O
tuning	O
this	O
knob	O
on	O
the	O
test	B
data	I
seems	O
like	O
a	O
good	O
idea	O
that	O
is	O
it	O
won	O
t	O
accidentally	O
reward	O
overfitting	B
of	O
course	O
it	O
breaks	O
our	O
cardinal	O
rule	O
about	O
test	B
data	I
that	O
you	O
should	O
never	O
touch	O
your	O
test	B
data	I
so	O
that	O
idea	O
is	O
immediately	O
off	O
the	O
table	O
however	O
our	O
test	B
data	I
wasn	O
t	O
magic	O
we	O
simply	O
took	O
our	O
examples	B
called	O
of	O
them	O
training	B
data	I
and	O
called	O
the	O
other	O
some	O
people	O
call	O
this	O
validation	B
data	I
or	O
held-out	B
data	I
in	O
step	O
you	O
could	O
either	O
choose	O
the	O
model	B
on	O
the	O
training	B
data	I
that	O
did	O
the	O
best	O
on	O
the	O
development	B
data	I
or	O
you	O
could	O
choose	O
the	O
hyperparameter	B
settings	O
that	O
did	O
best	O
and	O
retrain	O
the	O
model	B
on	O
the	O
union	O
of	O
training	O
and	O
development	B
data	I
is	O
either	O
of	O
these	O
options	O
obviously	O
better	O
or	O
worse	O
a	O
course	O
in	O
machine	O
learning	O
test	B
data	I
so	O
instead	O
let	O
s	O
do	O
the	O
following	O
let	O
s	O
take	O
our	O
original	O
data	O
points	O
and	O
select	O
of	O
them	O
as	O
training	B
data	I
from	O
the	O
remainder	O
take	O
as	O
development	O
and	O
the	O
remaining	O
as	O
test	B
data	I
the	O
job	O
of	O
the	O
development	B
data	I
is	O
to	O
allow	O
us	O
to	O
tune	O
hyperparameters	O
the	O
general	O
approach	O
is	O
as	O
follows	O
split	O
your	O
data	O
into	O
training	B
data	I
development	B
data	I
and	O
test	B
data	I
for	O
each	O
possible	O
setting	O
of	O
your	O
hyperparameters	O
train	O
a	O
model	B
using	O
that	O
setting	O
of	O
hyperparameters	O
on	O
the	O
training	B
data	I
compute	O
this	O
model	B
s	O
error	B
rate	I
on	O
the	O
development	B
data	I
from	O
the	O
above	O
collection	O
of	O
models	O
choose	O
the	O
one	O
that	O
achieved	O
the	O
lowest	O
error	B
rate	I
on	O
development	B
data	I
evaluate	O
that	O
model	B
on	O
the	O
test	B
data	I
to	O
estimate	O
future	O
test	O
perfor	O
mance	O
chapter	O
summary	O
and	O
outlook	O
at	O
this	O
point	O
you	O
should	O
be	O
able	O
to	O
use	O
decision	B
trees	I
to	O
do	O
machine	O
learning	O
someone	O
will	O
give	O
you	O
data	O
you	O
ll	O
split	O
it	O
into	O
training	O
development	O
and	O
test	O
portions	O
using	O
the	O
training	O
and	O
development	B
data	I
you	O
ll	O
find	O
a	O
good	O
value	O
for	O
maximum	B
depth	I
that	O
trades	O
off	O
between	O
underfitting	B
and	O
overfitting	B
you	O
ll	O
then	O
run	O
the	O
resulting	O
decision	B
tree	I
model	B
on	O
the	O
test	B
data	I
to	O
get	O
an	O
estimate	O
of	O
how	O
well	O
you	O
are	O
likely	O
to	O
do	O
in	O
the	O
future	O
you	O
might	O
think	O
why	O
should	O
i	O
read	O
the	O
rest	O
of	O
this	O
book	O
aside	O
from	O
the	O
fact	O
that	O
machine	O
learning	O
is	O
just	O
an	O
awesome	O
fun	O
field	O
to	O
learn	O
about	O
there	O
s	O
a	O
lot	O
left	O
to	O
cover	O
in	O
the	O
next	O
two	O
chapters	O
you	O
ll	O
learn	O
about	O
two	O
models	O
that	O
have	O
very	O
different	O
inductive	O
biases	O
than	O
decision	B
trees	I
you	O
ll	O
also	O
get	O
to	O
see	O
a	O
very	O
useful	O
way	O
of	O
thinking	O
about	O
learning	O
the	O
geometric	B
view	I
of	O
data	O
this	O
will	O
guide	O
much	O
of	O
what	O
follows	O
after	O
that	O
you	O
ll	O
learn	O
how	O
to	O
solve	O
problems	O
more	O
complicated	O
that	O
simple	O
binary	O
classification	O
learning	O
people	O
like	O
binary	O
classification	O
a	O
lot	O
because	O
it	O
s	O
one	O
of	O
the	O
simplest	O
non-trivial	O
problems	O
that	O
we	O
can	O
work	O
on	O
after	O
that	O
things	O
will	O
diverge	O
you	O
ll	O
learn	O
about	O
ways	O
to	O
think	O
about	O
learning	O
as	O
a	O
formal	O
optimization	B
problem	I
ways	O
to	O
speed	O
up	O
learning	O
ways	O
to	O
learn	O
without	O
labeled	O
data	O
with	O
very	O
little	O
labeled	O
data	O
and	O
all	O
sorts	O
of	O
other	O
fun	O
topics	O
decision	B
trees	I
but	O
throughout	O
we	O
will	O
focus	O
on	O
the	O
view	O
of	O
machine	O
learning	O
that	O
you	O
ve	O
seen	O
here	O
you	O
select	O
a	O
model	B
its	O
associated	O
inductive	O
biases	O
you	O
use	O
data	O
to	O
find	O
parameters	O
of	O
that	O
model	B
that	O
work	O
well	O
on	O
the	O
training	B
data	I
you	O
use	O
development	B
data	I
to	O
avoid	O
underfitting	B
and	O
overfitting	B
and	O
you	O
use	O
test	B
data	I
you	O
ll	O
never	O
look	O
at	O
or	O
touch	O
right	O
to	O
estimate	O
future	O
model	B
performance	O
then	O
you	O
conquer	O
the	O
world	O
exercises	O
exercise	O
todo	O
geometry	O
and	O
nearest	O
neighbors	O
learning	O
objectives	O
describe	O
a	O
data	O
set	O
as	O
points	O
in	O
a	O
high	O
dimensional	O
space	O
explain	O
the	B
curse	I
of	I
dimensionality	I
compute	O
distances	O
between	O
points	O
in	O
high	O
dimensional	O
space	O
implement	O
a	O
k-nearest	O
neighbor	O
model	B
of	O
learning	O
draw	O
decision	O
boundaries	O
implement	O
the	O
k-means	O
algorithm	B
for	O
clustering	B
dependencies	O
chapter	O
our	O
brains	O
have	O
evolved	O
to	O
get	O
us	O
out	O
of	O
the	O
rain	O
find	O
where	O
the	O
berries	O
are	O
and	O
keep	O
us	O
from	O
getting	O
killed	O
our	O
brains	O
did	O
not	O
evolve	O
to	O
help	O
us	O
grasp	O
really	O
large	O
numbers	O
or	O
to	O
look	O
at	O
things	O
in	O
a	O
hundred	O
thousand	O
dimensions	O
ronald	O
graham	O
you	O
can	O
think	O
of	O
prediction	O
tasks	O
as	O
mapping	O
inputs	O
reviews	O
to	O
outputs	O
ratings	O
as	O
you	O
learned	O
in	O
the	O
previous	O
chapter	O
decomposing	O
an	O
input	O
into	O
a	O
collection	O
of	O
features	B
words	O
that	O
occur	O
in	O
the	O
review	O
forms	O
a	O
useful	O
abstraction	O
for	O
learning	O
therefore	O
inputs	O
are	O
nothing	O
more	O
than	O
lists	O
of	O
feature	B
values	I
this	O
suggests	O
a	O
geometric	B
view	I
of	O
data	O
where	O
we	O
have	O
one	O
dimension	O
for	O
every	O
feature	O
in	O
this	O
view	O
examples	B
are	O
points	O
in	O
a	O
highdimensional	O
space	O
once	O
we	O
think	O
of	O
a	O
data	O
set	O
as	O
a	O
collection	O
of	O
points	O
in	O
high	O
dimen	O
sional	O
space	O
we	O
can	O
start	O
performing	O
geometric	O
operations	O
on	O
this	O
data	O
for	O
instance	O
suppose	O
you	O
need	O
to	O
predict	B
whether	O
alice	O
will	O
like	O
algorithms	O
perhaps	O
we	O
can	O
try	O
to	O
find	O
another	O
student	O
who	O
is	O
most	O
similar	O
to	O
alice	O
in	O
terms	O
of	O
favorite	O
courses	O
say	O
this	O
student	O
is	O
jeremy	O
if	O
jeremy	O
liked	O
algorithms	O
then	O
we	O
might	O
guess	O
that	O
alice	O
will	O
as	O
well	O
this	O
is	O
an	O
example	O
of	O
a	O
nearest	B
neighbor	I
model	B
of	O
learning	O
by	O
inspecting	O
this	O
model	B
we	O
ll	O
see	O
a	O
completely	O
different	O
set	O
of	O
answers	O
to	O
the	O
key	O
learning	O
questions	O
we	O
discovered	O
in	O
chapter	O
from	O
data	O
to	O
feature	O
vectors	O
an	O
example	O
is	O
just	O
a	O
collection	O
of	O
feature	B
values	I
about	O
that	O
example	O
for	O
instance	O
the	O
data	O
in	O
table	O
from	O
the	O
appendix	O
to	O
a	O
person	O
these	O
features	B
have	O
meaning	O
one	O
feature	O
might	O
count	O
how	O
many	O
times	O
the	O
reviewer	O
wrote	O
excellent	O
in	O
a	O
course	O
review	O
another	O
might	O
count	O
the	O
number	O
of	O
exclamation	O
points	O
a	O
third	O
might	O
tell	O
us	O
if	O
any	O
text	O
is	O
underlined	O
in	O
the	O
review	O
to	O
a	O
machine	O
the	O
features	B
themselves	O
have	O
no	O
meaning	O
only	O
the	O
feature	B
values	I
and	O
how	O
they	O
vary	O
across	O
examples	B
mean	O
something	O
to	O
the	O
machine	O
from	O
this	O
perspective	O
you	O
can	O
think	O
about	O
an	O
example	O
as	O
being	O
represented	O
by	O
a	O
feature	B
vector	B
consisting	O
of	O
one	O
dimension	O
for	O
each	O
feature	O
where	O
each	O
dimenion	O
is	O
simply	O
some	O
real	O
value	O
consider	O
a	O
review	O
that	O
said	O
excellent	O
three	O
times	O
had	O
one	O
excla	O
geometry	O
and	O
nearest	O
neighbors	O
mation	O
point	O
and	O
no	O
underlined	O
text	O
this	O
could	O
be	O
represented	O
by	O
the	O
feature	B
vector	B
an	O
almost	O
identical	O
review	O
that	O
happened	O
to	O
have	O
underlined	O
text	O
would	O
have	O
the	O
feature	B
vector	B
note	O
here	O
that	O
we	O
have	O
imposed	O
the	O
convention	O
that	O
for	O
binary	B
features	B
features	B
the	O
corresponding	O
feature	B
values	I
are	O
and	O
respectively	O
this	O
was	O
an	O
arbitrary	O
choice	O
we	O
could	O
have	O
made	O
them	O
and	O
if	O
we	O
wanted	O
but	O
is	O
convenient	O
and	O
helps	O
us	O
interpret	O
the	O
feature	B
values	I
when	O
we	O
discuss	O
practical	O
issues	O
in	O
chapter	O
you	O
will	O
see	O
other	O
reasons	O
why	O
is	O
a	O
good	O
choice	O
figure	O
shows	O
the	O
data	O
from	O
table	O
in	O
three	O
views	O
these	O
three	O
views	O
are	O
constructed	O
by	O
considering	O
two	O
features	B
at	O
a	O
time	O
in	O
different	O
pairs	O
in	O
all	O
cases	O
the	O
plusses	O
denote	O
positive	O
examples	B
and	O
the	O
minuses	O
denote	O
negative	O
examples	B
in	O
some	O
cases	O
the	O
points	O
fall	O
on	O
top	O
of	O
each	O
other	O
which	O
is	O
why	O
you	O
cannot	O
see	O
unique	O
points	O
in	O
all	O
figures	O
the	O
mapping	O
from	O
feature	B
values	I
to	O
vectors	O
is	O
straighforward	O
in	O
the	O
case	O
of	O
real	O
valued	O
features	B
and	O
binary	B
features	B
to	O
zero	O
or	O
one	O
it	O
is	O
less	O
clear	O
what	O
to	O
do	O
with	O
categorical	B
features	B
for	O
example	O
if	O
our	O
goal	O
is	O
to	O
identify	O
whether	O
an	O
object	O
in	O
an	O
image	O
is	O
a	O
tomato	O
blueberry	O
cucumber	O
or	O
cockroach	O
we	O
might	O
want	O
to	O
know	O
its	O
color	O
is	O
it	O
red	O
blue	O
green	O
or	O
black	O
one	O
option	O
would	O
be	O
to	O
map	O
red	O
to	O
a	O
value	O
of	O
blue	O
to	O
a	O
value	O
of	O
green	O
to	O
a	O
value	O
of	O
and	O
black	O
to	O
a	O
value	O
of	O
the	O
problem	O
with	O
this	O
mapping	O
is	O
that	O
it	O
turns	O
an	O
unordered	O
set	O
set	O
of	O
colors	O
into	O
an	O
ordered	O
set	O
set	O
in	O
itself	O
this	O
is	O
not	O
necessarily	O
a	O
bad	O
thing	O
but	O
when	O
we	O
go	O
to	O
use	O
these	O
features	B
we	O
will	O
measure	O
examples	B
based	O
on	O
their	O
distances	O
to	O
each	O
other	O
by	O
doing	O
this	O
mapping	O
we	O
are	O
essentially	O
saying	O
that	O
red	O
and	O
blue	O
are	O
more	O
similar	O
of	O
than	O
red	O
and	O
black	O
of	O
this	O
is	O
probably	O
not	O
what	O
we	O
want	O
to	O
say	O
a	O
solution	O
is	O
to	O
turn	O
a	O
categorical	O
feature	O
that	O
can	O
take	O
four	O
different	O
values	O
red	O
blue	O
green	O
and	O
black	O
into	O
four	O
binary	B
features	B
isitred	O
isitblue	O
isitgreen	O
and	O
isitblack	O
in	O
general	O
if	O
we	O
start	O
from	O
a	O
categorical	O
feature	O
that	O
takes	O
v	O
values	O
we	O
can	O
map	O
it	O
to	O
v-many	O
binary	O
indicator	O
features	B
with	O
that	O
you	O
should	O
be	O
able	O
to	O
take	O
a	O
data	O
set	O
and	O
map	O
each	O
example	O
to	O
a	O
feature	B
vector	B
through	O
the	O
following	O
mapping	O
real-valued	O
features	B
get	O
copied	O
directly	O
binary	B
features	B
become	O
false	O
or	O
true	O
categorical	B
features	B
with	O
v	O
possible	O
values	O
get	O
mapped	O
to	O
v-many	O
binary	O
indicator	O
features	B
figure	O
a	O
figure	O
showing	O
projections	O
of	O
data	O
in	O
two	O
dimension	O
in	O
three	O
ways	O
see	O
text	O
top	O
horizontal	O
axis	O
corresponds	O
to	O
the	O
first	O
feature	O
and	O
the	O
vertical	O
axis	O
corresponds	O
to	O
the	O
second	O
feature	O
middle	O
horizonal	O
is	O
second	O
feature	O
and	O
vertical	O
is	O
third	O
bottom	O
horizonal	O
is	O
first	O
and	O
vertical	O
is	O
third	O
match	O
the	O
example	O
ids	O
from	O
table	O
with	O
the	O
points	O
in	O
figure	O
the	O
computer	O
scientist	O
in	O
you	O
might	O
be	O
saying	O
actually	O
we	O
could	O
map	O
it	O
to	O
v-many	O
binary	B
features	B
is	O
this	O
a	O
good	O
idea	O
or	O
not	O
a	O
course	O
in	O
machine	O
learning	O
after	O
this	O
mapping	O
you	O
can	O
think	O
of	O
a	O
single	O
example	O
as	O
a	O
vector	B
in	O
a	O
high-dimensional	O
feature	B
space	I
if	O
you	O
have	O
d-many	O
features	B
expanding	O
categorical	B
features	B
then	O
this	O
feature	B
vector	B
will	O
have	O
d-many	O
components	O
we	O
will	O
denote	O
feature	O
vectors	O
as	O
x	O
so	O
that	O
xd	O
denotes	O
the	O
value	O
of	O
the	O
dth	O
feature	O
of	O
x	O
since	O
these	O
are	O
vectors	O
with	O
real-valued	O
components	O
in	O
d-dimensions	O
we	O
say	O
that	O
they	O
belong	O
to	O
the	O
space	O
rd	O
for	O
d	O
our	O
feature	O
vectors	O
are	O
just	O
points	O
in	O
the	O
plane	O
like	O
in	O
figure	O
for	O
d	O
this	O
is	O
three	O
dimensional	O
space	O
for	O
d	O
it	O
becomes	O
quite	O
hard	O
to	O
visualize	B
should	O
resist	O
the	O
temptation	O
to	O
think	O
of	O
d	O
as	O
time	O
this	O
will	O
just	O
make	O
things	O
confusing	O
unfortunately	O
for	O
the	O
sorts	O
of	O
problems	O
you	O
will	O
encounter	O
in	O
machine	O
learning	O
d	O
is	O
considered	O
low	O
dimensional	O
d	O
is	O
medium	O
dimensional	O
and	O
d	O
is	O
high	O
dimensional	O
k-nearest	B
neighbors	I
can	O
you	O
think	O
of	O
problems	O
ones	O
already	O
mentioned	O
in	O
this	O
book	O
that	O
are	O
low	O
dimensional	O
that	O
are	O
medium	O
dimensional	O
that	O
are	O
high	O
dimensional	O
the	O
biggest	O
advantage	O
to	O
thinking	O
of	O
examples	B
as	O
vectors	O
in	O
a	O
high	O
dimensional	O
space	O
is	O
that	O
it	O
allows	O
us	O
to	O
apply	O
geometric	O
concepts	O
to	O
machine	O
learning	O
for	O
instance	O
one	O
of	O
the	O
most	O
basic	O
things	O
that	O
one	O
can	O
do	O
in	O
a	O
vector	B
space	O
is	O
compute	O
distances	O
in	O
twodimensional	O
space	O
the	O
distance	B
between	O
and	O
is	O
given	O
in	O
general	O
in	O
d-dimensional	O
space	O
the	O
euclidean	B
distance	B
between	O
vectors	O
a	O
and	O
b	O
is	O
given	O
by	O
eq	O
figure	O
for	O
geometric	O
intuition	O
in	O
three	O
dimensions	O
d	O
da	O
b	O
now	O
that	O
you	O
have	O
access	O
to	O
distances	O
between	O
examples	B
you	O
can	O
start	O
thinking	O
about	O
what	O
it	O
means	O
to	O
learn	O
again	O
consider	O
figure	O
we	O
have	O
a	O
collection	O
of	O
training	B
data	I
consisting	O
of	O
positive	O
examples	B
and	O
negative	O
examples	B
there	O
is	O
a	O
test	O
point	O
marked	O
by	O
a	O
question	O
mark	O
your	O
job	O
is	O
to	O
guess	O
the	O
correct	O
label	B
for	O
that	O
point	O
most	O
likely	O
you	O
decided	O
that	O
the	O
label	B
of	O
this	O
test	O
point	O
is	O
positive	O
one	O
reason	O
why	O
you	O
might	O
have	O
thought	O
that	O
is	O
that	O
you	O
believe	O
that	O
the	O
label	B
for	O
an	O
example	O
should	O
be	O
similar	O
to	O
the	O
label	B
of	O
nearby	O
points	O
this	O
is	O
an	O
example	O
of	O
a	O
new	O
form	O
of	O
inductive	B
bias	B
the	O
nearest	B
neighbor	I
classifier	O
is	O
build	O
upon	O
this	O
insight	O
in	O
com	O
parison	O
to	O
decision	B
trees	I
the	O
algorithm	B
is	O
ridiculously	O
simple	O
at	O
training	O
time	O
we	O
simply	O
store	O
the	O
entire	O
training	O
set	O
at	O
test	O
time	O
we	O
get	O
a	O
test	O
example	O
x	O
to	O
predict	B
its	O
label	B
we	O
find	O
the	O
training	O
example	O
x	O
that	O
is	O
most	O
similar	O
to	O
x	O
in	O
particular	O
we	O
find	O
the	O
training	O
figure	O
a	O
figure	O
showing	O
euclidean	B
distance	B
in	O
three	O
dimensions	O
verify	O
that	O
d	O
from	O
eq	O
gives	O
the	O
same	O
result	O
for	O
the	O
previous	O
computation	O
geometry	O
and	O
nearest	O
neighbors	O
store	O
distance	B
to	O
training	O
example	O
n	O
put	O
lowest-distance	O
objects	O
first	O
s	O
s	O
x	O
algorithm	B
knn-predictd	O
k	O
x	O
s	O
for	O
n	O
to	O
n	O
do	O
end	O
for	O
s	O
sorts	O
y	O
for	O
k	O
to	O
k	O
do	O
sk	O
y	O
y	O
yn	O
end	O
for	O
return	O
sign	B
y	O
n	O
this	O
is	O
the	O
kth	O
closest	O
data	O
point	O
vote	B
according	O
to	O
the	O
label	B
for	O
the	O
nth	O
training	O
point	O
return	O
if	O
y	O
and	O
if	O
y	O
example	O
x	O
that	O
minimizes	O
dx	O
x	O
since	O
x	O
is	O
a	O
training	O
example	O
it	O
has	O
a	O
corresponding	O
label	B
y	O
we	O
predict	B
that	O
the	O
label	B
of	O
x	O
is	O
also	O
y	O
despite	O
its	O
simplicity	O
this	O
nearest	B
neighbor	I
classifier	O
is	O
incredibly	O
effective	O
might	O
say	O
frustratingly	O
effective	O
however	O
it	O
is	O
particularly	O
prone	O
to	O
overfitting	B
label	B
noise	B
consider	O
the	O
data	O
in	O
figure	O
you	O
would	O
probably	O
want	O
to	O
label	B
the	O
test	O
point	O
positive	O
unfortunately	O
it	O
s	O
nearest	B
neighbor	I
happens	O
to	O
be	O
negative	O
since	O
the	O
nearest	B
neighbor	I
algorithm	B
only	O
looks	O
at	O
the	O
single	O
nearest	B
neighbor	I
it	O
cannot	O
consider	O
the	O
preponderance	O
of	O
evidence	B
that	O
this	O
point	O
should	O
probably	O
actually	O
be	O
a	O
positive	O
example	O
it	O
will	O
make	O
an	O
unnecessary	O
error	O
a	O
solution	O
to	O
this	O
problem	O
is	O
to	O
consider	O
more	O
than	O
just	O
the	O
single	O
nearest	B
neighbor	I
when	O
making	O
a	O
classification	O
decision	O
we	O
can	O
consider	O
the	O
k-nearest	B
neighbors	I
and	O
let	O
them	O
vote	B
on	O
the	O
correct	O
class	O
for	O
this	O
test	O
point	O
if	O
you	O
consider	O
the	O
neighbors	O
of	O
the	O
test	O
point	O
in	O
figure	O
you	O
will	O
see	O
that	O
two	O
of	O
them	O
are	O
positive	O
and	O
one	O
is	O
negative	O
through	O
voting	B
positive	O
would	O
win	O
the	O
full	O
algorithm	B
for	O
k-nearest	O
neighbor	O
classification	O
is	O
given	O
in	O
algorithm	B
note	O
that	O
there	O
actually	O
is	O
no	O
training	O
phase	O
for	O
k-nearest	B
neighbors	I
in	O
this	O
algorithm	B
we	O
have	O
introduced	O
five	O
new	O
conventions	O
the	O
training	B
data	I
is	O
denoted	O
by	O
d	O
we	O
assume	O
that	O
there	O
are	O
n-many	O
training	O
examples	B
these	O
examples	B
are	O
pairs	O
yn	O
do	O
not	O
confuse	O
xn	O
the	O
nth	O
training	O
example	O
with	O
xd	O
the	O
dth	O
feature	O
for	O
example	O
x	O
we	O
use	O
denote	O
an	O
empty	O
list	O
and	O
to	O
append	O
to	O
that	O
list	O
our	O
prediction	O
on	O
x	O
is	O
called	O
y	O
figure	O
a	O
figure	O
showing	O
an	O
easy	O
nn	O
classification	O
problem	O
where	O
the	O
test	O
point	O
is	O
a	O
and	O
should	O
be	O
positive	O
but	O
its	O
nn	O
is	O
actually	O
a	O
negative	O
point	O
that	O
s	O
noisy	O
why	O
is	O
it	O
a	O
good	O
idea	O
to	O
use	O
an	O
odd	O
number	O
for	O
k	O
a	O
course	O
in	O
machine	O
learning	O
the	O
first	O
step	O
in	O
this	O
algorithm	B
is	O
to	O
compute	O
distances	O
from	O
the	O
test	O
point	O
to	O
all	O
training	O
points	O
the	O
data	O
points	O
are	O
then	O
sorted	O
according	O
to	O
distance	B
we	O
then	O
apply	O
a	O
clever	O
trick	O
of	O
summing	O
the	O
class	O
labels	O
for	O
each	O
of	O
the	O
k	O
nearest	O
neighbors	O
and	O
using	O
the	O
sign	B
of	O
this	O
sum	O
as	O
our	O
prediction	O
the	O
big	O
question	O
of	O
course	O
is	O
how	O
to	O
choose	O
k	O
as	O
we	O
ve	O
seen	O
with	O
k	O
we	O
run	O
the	O
risk	O
of	O
overfitting	B
on	O
the	O
other	O
hand	O
if	O
k	O
is	O
large	O
instance	O
k	O
n	O
then	O
knn-predict	O
will	O
always	O
predict	B
the	O
majority	O
class	O
clearly	O
that	O
is	O
underfitting	B
so	O
k	O
is	O
a	O
hyperparameter	B
of	O
the	O
knn	O
algorithm	B
that	O
allows	O
us	O
to	O
trade-off	O
between	O
overfitting	B
value	O
of	O
k	O
and	O
underfitting	B
value	O
of	O
k	O
one	O
aspect	O
of	O
inductive	B
bias	B
that	O
we	O
ve	O
seen	O
for	O
knn	O
is	O
that	O
it	O
assumes	O
that	O
nearby	O
points	O
should	O
have	O
the	O
same	O
label	B
another	O
aspect	O
which	O
is	O
quite	O
different	O
from	O
decision	B
trees	I
is	O
that	O
all	O
features	B
are	O
equally	O
important	O
recall	B
that	O
for	O
decision	B
trees	I
the	O
key	O
question	O
was	O
which	O
features	B
are	O
most	O
useful	O
for	O
classification	O
the	O
whole	O
learning	O
algorithm	B
for	O
a	O
decision	B
tree	I
hinged	O
on	O
finding	O
a	O
small	O
set	O
of	O
good	O
features	B
this	O
is	O
all	O
thrown	O
away	O
in	O
knn	O
classifiers	O
every	O
feature	O
is	O
used	O
and	O
they	O
are	O
all	O
used	O
the	O
same	O
amount	O
this	O
means	O
that	O
if	O
you	O
have	O
data	O
with	O
only	O
a	O
few	O
relevant	O
features	B
and	O
lots	O
of	O
irrelevant	O
features	B
knn	O
is	O
likely	O
to	O
do	O
poorly	O
a	O
related	O
issue	O
with	O
knn	O
is	O
feature	B
scale	I
suppose	O
that	O
we	O
are	O
trying	O
to	O
classify	O
whether	O
some	O
object	O
is	O
a	O
ski	O
or	O
a	O
snowboard	O
figure	O
we	O
are	O
given	O
two	O
features	B
about	O
this	O
data	O
the	O
width	O
and	O
height	O
as	O
is	O
standard	O
in	O
skiing	O
width	O
is	O
measured	O
in	O
millimeters	O
and	O
height	O
is	O
measured	O
in	O
centimeters	O
since	O
there	O
are	O
only	O
two	O
features	B
we	O
can	O
actually	O
plot	O
the	O
entire	O
training	O
set	O
see	O
figure	O
where	O
ski	O
is	O
the	O
positive	O
class	O
based	O
on	O
this	O
data	O
you	O
might	O
guess	O
that	O
a	O
knn	O
classifier	O
would	O
do	O
well	O
suppose	O
however	O
that	O
our	O
measurement	O
of	O
the	O
width	O
was	O
com	O
puted	O
in	O
millimeters	O
of	O
centimeters	O
this	O
yields	O
the	O
data	O
shown	O
in	O
figure	O
since	O
the	O
width	O
values	O
are	O
now	O
tiny	O
in	O
comparison	O
to	O
the	O
height	O
values	O
a	O
knn	O
classifier	O
will	O
effectively	O
ignore	O
the	O
width	O
values	O
and	O
classify	O
almost	O
purely	O
based	O
on	O
height	O
the	O
predicted	O
class	O
for	O
the	O
displayed	O
test	O
point	O
had	O
changed	O
because	O
of	O
this	O
feature	O
scaling	O
we	O
will	O
discuss	O
feature	O
scaling	O
more	O
in	O
chapter	O
for	O
now	O
it	O
is	O
just	O
important	O
to	O
keep	O
in	O
mind	O
that	O
knn	O
does	O
not	O
have	O
the	O
power	O
to	O
decide	O
which	O
features	B
are	O
important	O
why	O
is	O
the	O
sign	B
of	O
the	O
sum	O
computed	O
in	O
lines	O
the	O
same	O
as	O
the	O
majority	O
vote	B
of	O
the	O
associated	O
training	O
examples	B
why	O
can	O
t	O
you	O
simply	O
pick	O
the	O
value	O
of	O
k	O
that	O
does	O
best	O
on	O
the	O
training	B
data	I
in	O
other	O
words	O
why	O
do	O
we	O
have	O
to	O
treat	O
it	O
like	O
a	O
hyperparameter	B
rather	O
than	O
just	O
a	O
parameter	O
figure	O
a	O
figure	O
of	O
a	O
ski	O
and	O
snowboard	O
with	O
width	O
and	O
height	O
figure	O
classification	O
data	O
for	O
ski	O
vs	O
snowboard	O
in	O
geometry	O
and	O
nearest	O
neighbors	O
decision	O
boundaries	O
the	O
standard	O
way	O
that	O
we	O
ve	O
been	O
thinking	O
about	O
learning	O
algorithms	O
up	O
to	O
now	O
is	O
in	O
the	O
query	O
model	B
based	O
on	O
training	B
data	I
you	O
learn	O
something	O
i	O
then	O
give	O
you	O
a	O
query	O
example	O
and	O
you	O
have	O
to	O
guess	O
it	O
s	O
label	B
an	O
alternative	O
less	O
passive	O
way	O
to	O
think	O
about	O
a	O
learned	O
model	B
is	O
to	O
ask	O
what	O
sort	O
of	O
test	O
examples	B
will	O
it	O
classify	O
as	O
positive	O
and	O
what	O
sort	O
will	O
it	O
classify	O
as	O
negative	O
in	O
figure	O
we	O
have	O
a	O
set	O
of	O
training	B
data	I
the	O
background	O
of	O
the	O
image	O
is	O
colored	O
blue	O
in	O
regions	O
that	O
would	O
be	O
classified	O
as	O
positive	O
a	O
query	O
were	O
issued	O
there	O
and	O
colored	O
red	O
in	O
regions	O
that	O
would	O
be	O
classified	O
as	O
negative	O
this	O
coloring	O
is	O
based	O
on	O
a	O
neighbor	O
classifier	O
in	O
figure	O
there	O
is	O
a	O
solid	O
line	O
separating	O
the	O
positive	O
regions	O
from	O
the	O
negative	O
regions	O
this	O
line	O
is	O
called	O
the	O
decision	B
boundary	I
for	O
this	O
classifier	O
it	O
is	O
the	O
line	O
with	O
positive	O
land	O
on	O
one	O
side	O
and	O
negative	O
land	O
on	O
the	O
other	O
side	O
decision	O
boundaries	O
are	O
useful	O
ways	O
to	O
visualize	B
the	O
complex	O
ity	O
of	O
a	O
learned	O
model	B
intuitively	O
a	O
learned	O
model	B
with	O
a	O
decision	B
boundary	I
that	O
is	O
really	O
jagged	O
the	O
coastline	O
of	O
norway	O
is	O
really	O
complex	O
and	O
prone	O
to	O
overfitting	B
a	O
learned	O
model	B
with	O
a	O
decision	B
boundary	I
that	O
is	O
really	O
simple	O
the	O
bounary	O
between	O
arizona	O
and	O
utah	O
is	O
potentially	O
underfit	O
in	O
figure	O
you	O
can	O
see	O
the	O
decision	O
boundaries	O
for	O
knn	O
models	O
with	O
k	O
as	O
you	O
can	O
see	O
the	O
boundaries	O
become	O
simpler	O
and	O
simpler	O
as	O
k	O
gets	O
bigger	O
now	O
that	O
you	O
know	O
about	O
decision	O
boundaries	O
it	O
is	O
natural	O
to	O
ask	O
what	O
do	O
decision	O
boundaries	O
for	O
decision	B
trees	I
look	O
like	O
in	O
order	O
to	O
answer	O
this	O
question	O
we	O
have	O
to	O
be	O
a	O
bit	O
more	O
formal	O
about	O
how	O
to	O
build	O
a	O
decision	B
tree	I
on	O
real-valued	O
features	B
that	O
the	O
algorithm	B
you	O
learned	O
in	O
the	O
previous	O
chapter	O
implicitly	O
assumed	O
binary	O
feature	B
values	I
the	O
idea	O
is	O
to	O
allow	O
the	O
decision	B
tree	I
to	O
ask	O
questions	O
of	O
the	O
form	O
is	O
the	O
value	O
of	O
feature	O
greater	O
than	O
that	O
is	O
for	O
real-valued	O
features	B
the	O
decision	B
tree	I
nodes	O
are	O
parameterized	O
by	O
a	O
feature	O
and	O
a	O
threshold	B
for	O
that	O
feature	O
an	O
example	O
decision	B
tree	I
for	O
classifying	O
skis	O
versus	O
snowboards	O
is	O
shown	O
in	O
figure	O
now	O
that	O
a	O
decision	B
tree	I
can	O
handle	O
feature	O
vectors	O
we	O
can	O
talk	O
about	O
decision	O
boundaries	O
by	O
example	O
the	O
decision	B
boundary	I
for	O
the	O
decision	B
tree	I
in	O
figure	O
is	O
shown	O
in	O
figure	O
in	O
the	O
figure	O
space	O
is	O
first	O
split	O
in	O
half	O
according	O
to	O
the	O
first	O
query	O
along	O
one	O
axis	O
then	O
depending	O
on	O
which	O
half	O
of	O
the	O
space	O
you	O
look	O
at	O
it	O
is	O
either	O
split	O
again	O
along	O
the	O
other	O
axis	O
or	O
simply	O
classified	O
figure	O
is	O
a	O
good	O
visualization	O
of	O
decision	O
boundaries	O
for	O
decision	B
trees	I
in	O
general	O
their	O
decision	O
boundaries	O
are	O
axis-aligned	O
figure	O
decision	B
boundary	I
for	O
figure	O
decision	B
boundary	I
for	O
knn	O
with	O
figure	O
decision	B
tree	I
for	O
ski	O
vs	O
snowboard	O
figure	O
decision	B
boundary	I
for	O
dt	O
in	O
previous	O
figure	O
a	O
course	O
in	O
machine	O
learning	O
cuts	O
the	O
cuts	O
must	O
be	O
axis-aligned	O
because	O
nodes	O
can	O
only	O
query	O
on	O
a	O
single	O
feature	O
at	O
a	O
time	O
in	O
this	O
case	O
since	O
the	O
decision	B
tree	I
was	O
so	O
shallow	O
the	O
decision	B
boundary	I
was	O
relatively	O
simple	O
k-means	O
clustering	B
up	O
through	O
this	O
point	O
you	O
have	O
learned	O
all	O
about	O
supervised	O
learning	O
particular	O
binary	O
classification	O
as	O
another	O
example	O
of	O
the	O
use	O
of	O
geometric	O
intuitions	O
and	O
data	O
we	O
are	O
going	O
to	O
temporarily	O
consider	O
an	O
unsupervised	B
learning	I
problem	O
in	O
unsupervised	B
learning	I
our	O
data	O
consists	O
only	O
of	O
examples	B
xn	O
and	O
does	O
not	O
contain	O
corresponding	O
labels	O
your	O
job	O
is	O
to	O
make	O
sense	O
of	O
this	O
data	O
even	O
though	O
no	O
one	O
has	O
provided	O
you	O
with	O
correct	O
labels	O
the	O
particular	O
notion	O
of	O
making	O
sense	O
of	O
that	O
we	O
will	O
talk	O
about	O
now	O
is	O
the	O
clustering	B
task	O
consider	O
the	O
data	O
shown	O
in	O
figure	O
since	O
this	O
is	O
unsupervised	B
learning	I
and	O
we	O
do	O
not	O
have	O
access	O
to	O
labels	O
the	O
data	O
points	O
are	O
simply	O
drawn	O
as	O
black	O
dots	O
your	O
job	O
is	O
to	O
split	O
this	O
data	O
set	O
into	O
three	O
clusters	O
that	O
is	O
you	O
should	O
label	B
each	O
data	O
point	O
as	O
a	O
b	O
or	O
c	O
in	O
whatever	O
way	O
you	O
want	O
for	O
this	O
data	O
set	O
it	O
s	O
pretty	O
clear	O
what	O
you	O
should	O
do	O
you	O
prob	O
ably	O
labeled	O
the	O
upper-left	O
set	O
of	O
points	O
a	O
the	O
upper-right	O
set	O
of	O
points	O
b	O
and	O
the	O
bottom	O
set	O
of	O
points	O
c	O
or	O
perhaps	O
you	O
permuted	O
these	O
labels	O
but	O
chances	O
are	O
your	O
clusters	O
were	O
the	O
same	O
as	O
mine	O
the	O
k-means	O
clustering	B
algorithm	B
is	O
a	O
particularly	O
simple	O
and	O
effective	O
approach	O
to	O
producing	O
clusters	O
on	O
data	O
like	O
you	O
see	O
in	O
figure	O
the	O
idea	O
is	O
to	O
represent	O
each	O
cluster	O
by	O
it	O
s	O
cluster	O
center	O
given	O
cluster	O
centers	O
we	O
can	O
simply	O
assign	O
each	O
point	O
to	O
its	O
nearest	O
center	O
similarly	O
if	O
we	O
know	O
the	O
assignment	O
of	O
points	O
to	O
clusters	O
we	O
can	O
compute	O
the	O
centers	O
this	O
introduces	O
a	O
chicken-and-egg	O
problem	O
if	O
we	O
knew	O
the	O
clusters	O
we	O
could	O
compute	O
the	O
centers	O
if	O
we	O
knew	O
the	O
centers	O
we	O
could	O
compute	O
the	O
clusters	O
but	O
we	O
don	O
t	O
know	O
either	O
the	O
general	O
computer	O
science	O
answer	O
to	O
chicken-and-egg	O
problems	O
is	O
iteration	B
we	O
will	O
start	O
with	O
a	O
guess	O
of	O
the	O
cluster	O
centers	O
based	O
on	O
that	O
guess	O
we	O
will	O
assign	O
each	O
data	O
point	O
to	O
its	O
closest	O
center	O
given	O
these	O
new	O
assignments	O
we	O
can	O
recompute	O
the	O
cluster	O
centers	O
we	O
repeat	O
this	O
process	O
until	O
clusters	O
stop	O
moving	O
the	O
first	O
few	O
iterations	O
of	O
the	O
k-means	O
algorithm	B
are	O
shown	O
in	O
figure	O
in	O
this	O
example	O
the	O
clusters	O
converge	O
very	O
quickly	O
algorithm	B
spells	O
out	O
the	O
k-means	O
clustering	B
algorithm	B
in	O
detail	O
the	O
cluster	O
centers	O
are	O
initialized	O
randomly	O
in	O
line	O
data	O
point	O
xn	O
is	O
compared	O
against	O
each	O
cluster	O
center	O
k	O
it	O
is	O
assigned	O
to	O
cluster	O
k	O
if	O
k	O
is	O
the	O
center	O
with	O
the	O
smallest	O
distance	B
is	O
the	O
argmin	O
step	O
the	O
variable	O
zn	O
stores	O
the	O
assignment	O
value	O
from	O
to	O
k	O
of	O
example	O
n	O
in	O
lines	O
the	O
cluster	O
centers	O
are	O
re-computed	O
first	O
xk	O
what	O
sort	O
of	O
data	O
might	O
yield	O
a	O
very	O
simple	O
decision	B
boundary	I
with	O
a	O
decision	B
tree	I
and	O
very	O
complex	O
decision	B
boundary	I
with	O
neighbor	O
what	O
about	O
the	O
other	O
way	O
around	O
figure	O
simple	O
clustering	B
data	O
clusters	O
in	O
ul	O
ur	O
and	O
bc	O
figure	O
first	O
few	O
iterations	O
of	O
k-means	O
running	O
on	O
previous	O
data	O
set	O
k	O
some	O
random	O
location	O
algorithm	B
k-meansd	O
k	O
for	O
k	O
to	O
k	O
do	O
end	O
for	O
repeat	O
for	O
n	O
to	O
n	O
do	O
zn	O
argmink	O
k	O
xn	O
end	O
for	O
for	O
k	O
to	O
k	O
do	O
xk	O
xn	O
zn	O
k	O
k	O
meanxk	O
end	O
for	O
until	O
s	O
stop	O
changing	O
return	O
z	O
geometry	O
and	O
nearest	O
neighbors	O
randomly	O
initialize	O
mean	O
for	O
kth	O
cluster	O
assign	O
example	O
n	O
to	O
closest	O
center	O
points	O
assigned	O
to	O
cluster	O
k	O
re-estimate	O
mean	O
of	O
cluster	O
k	O
return	O
cluster	O
assignments	O
math	O
review	O
vector	B
arithmetic	O
norms	O
and	O
means	O
define	O
vector	B
addition	O
scalar	O
addition	O
subtraction	O
scalar	O
multiplication	O
and	O
norms	O
define	O
mean	O
figure	O
stores	O
all	O
examples	B
that	O
have	O
been	O
assigned	O
to	O
cluster	O
k	O
the	O
center	O
of	O
cluster	O
k	O
k	O
is	O
then	O
computed	O
as	O
the	O
mean	O
of	O
the	O
points	O
assigned	O
to	O
it	O
this	O
process	O
repeats	O
until	O
the	O
means	O
converge	O
an	O
obvious	O
question	O
about	O
this	O
algorithm	B
is	O
does	O
it	O
converge	O
a	O
second	O
question	O
is	O
how	O
long	O
does	O
it	O
take	O
to	O
converge	O
the	O
first	O
question	O
is	O
actually	O
easy	O
to	O
answer	O
yes	O
it	O
does	O
and	O
in	O
practice	O
it	O
usually	O
converges	O
quite	O
quickly	O
fewer	O
than	O
iterations	O
in	O
chapter	O
we	O
will	O
actually	O
prove	O
that	O
it	O
converges	O
the	O
question	O
of	O
how	O
long	O
it	O
takes	O
to	O
converge	O
is	O
actually	O
a	O
really	O
interesting	O
question	O
even	O
though	O
the	O
k-means	O
algorithm	B
dates	O
back	O
to	O
the	O
mid	O
the	O
best	O
known	O
convergence	O
rates	O
were	O
terrible	O
for	O
a	O
long	O
time	O
here	O
terrible	O
means	O
exponential	O
in	O
the	O
number	O
of	O
data	O
points	O
this	O
was	O
a	O
sad	O
situation	O
because	O
empirically	O
we	O
knew	O
that	O
it	O
converged	O
very	O
quickly	O
new	O
algorithm	B
analysis	O
techniques	O
called	O
smoothed	B
analysis	I
were	O
invented	O
in	O
and	O
have	O
been	O
used	O
to	O
show	O
very	O
fast	O
convergence	O
for	O
k-means	O
other	O
algorithms	O
these	O
techniques	O
are	O
well	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
this	O
author	O
but	O
suffice	O
it	O
to	O
say	O
that	O
k-means	O
is	O
fast	O
in	O
practice	O
and	O
is	O
provably	O
fast	O
in	O
theory	O
it	O
is	O
important	O
to	O
note	O
that	O
although	O
k-means	O
is	O
guaranteed	O
to	O
converge	O
and	O
guaranteed	O
to	O
converge	O
quickly	O
it	O
is	O
not	O
guaranteed	O
to	O
converge	O
to	O
the	O
right	O
answer	O
the	O
key	O
problem	O
with	O
unsupervised	B
learning	I
is	O
that	O
we	O
have	O
no	O
way	O
of	O
knowing	O
what	O
the	O
right	O
answer	O
is	O
convergence	O
to	O
a	O
bad	O
solution	O
is	O
usually	O
due	O
to	O
poor	O
initialization	O
for	O
example	O
poor	O
initialization	O
in	O
the	O
data	O
set	O
from	O
before	O
yields	O
convergence	O
like	O
that	O
seen	O
in	O
figure	O
as	O
you	O
can	O
see	O
the	O
algorithm	B
a	O
course	O
in	O
machine	O
learning	O
has	O
converged	O
it	O
has	O
just	O
converged	O
to	O
something	O
less	O
than	O
satisfactory	O
warning	O
high	O
dimensions	O
are	O
scary	O
visualizing	O
one	O
hundred	O
dimensional	O
space	O
is	O
incredibly	O
difficult	O
for	O
humans	O
after	O
huge	O
amounts	O
of	O
training	O
some	O
people	O
have	O
reported	O
that	O
they	O
can	O
visualize	B
four	O
dimensional	O
space	O
in	O
their	O
heads	O
but	O
beyond	O
that	O
seems	O
in	O
addition	O
to	O
being	O
hard	O
to	O
visualize	B
there	O
are	O
at	O
least	O
two	O
additional	O
problems	O
in	O
high	O
dimensions	O
both	O
refered	O
to	O
as	O
the	B
curse	I
of	I
dimensionality	I
one	O
is	O
computational	O
the	O
other	O
is	O
mathematical	O
from	O
a	O
computational	O
perspective	O
consider	O
the	O
following	O
problem	O
for	O
k-nearest	B
neighbors	I
the	O
speed	O
of	O
prediction	O
is	O
slow	O
for	O
a	O
very	O
large	O
data	O
set	O
at	O
the	O
very	O
least	O
you	O
have	O
to	O
look	O
at	O
every	O
training	O
example	O
every	O
time	O
you	O
want	O
to	O
make	O
a	O
prediction	O
to	O
speed	O
things	O
up	O
you	O
might	O
want	O
to	O
create	O
an	O
indexing	O
data	O
structure	O
you	O
can	O
break	O
the	O
plane	O
up	O
into	O
a	O
grid	O
like	O
that	O
shown	O
in	O
figure	O
now	O
when	O
the	O
test	O
point	O
comes	O
in	O
you	O
can	O
quickly	O
identify	O
the	O
grid	O
cell	O
in	O
which	O
it	O
lies	O
now	O
instead	O
of	O
considering	O
all	O
training	O
points	O
you	O
can	O
limit	O
yourself	O
to	O
training	O
points	O
in	O
that	O
grid	O
cell	O
perhaps	O
the	O
neighboring	O
cells	O
this	O
can	O
potentially	O
lead	O
to	O
huge	O
computational	O
savings	O
space	O
up	O
into	O
a	O
grid	O
whose	O
cells	O
are	O
we	O
can	O
clearly	O
do	O
this	O
with	O
grid	O
cells	O
in	O
two	O
dimensions	O
the	O
range	O
of	O
the	O
features	B
is	O
to	O
for	O
simplicity	O
in	O
three	O
dimensions	O
we	O
ll	O
need	O
grid	O
cells	O
in	O
four	O
dimensions	O
we	O
ll	O
need	O
by	O
the	O
time	O
we	O
get	O
to	O
low	O
dimensional	O
data	O
in	O
dimensions	O
we	O
ll	O
need	O
grid	O
cells	O
s	O
trillion	O
which	O
is	O
about	O
to	O
times	O
the	O
us	O
national	O
debt	O
as	O
of	O
january	O
so	O
if	O
you	O
re	O
in	O
dimensions	O
this	O
gridding	O
technique	O
will	O
only	O
be	O
useful	O
if	O
you	O
have	O
at	O
least	O
trillion	O
training	O
examples	B
in	O
two	O
dimensions	O
this	O
procedure	O
is	O
effective	O
if	O
we	O
want	O
to	O
break	O
for	O
medium	O
dimensional	O
data	O
dimesions	O
the	O
number	O
of	O
grid	O
cells	O
is	O
a	O
followed	O
by	O
numbers	O
before	O
the	O
decimal	O
point	O
for	O
comparison	O
the	O
number	O
of	O
atoms	O
in	O
the	O
universe	O
is	O
approximately	O
followed	O
by	O
zeros	O
so	O
even	O
if	O
each	O
atom	O
yielded	O
a	O
googul	O
training	O
examples	B
we	O
d	O
still	O
have	O
far	O
fewer	O
examples	B
than	O
grid	O
cells	O
for	O
high	O
dimensional	O
data	O
dimensions	O
we	O
have	O
a	O
followed	O
by	O
just	O
under	O
zeros	O
far	O
too	O
big	O
a	O
number	O
to	O
even	O
really	O
comprehend	O
suffice	O
it	O
to	O
say	O
that	O
for	O
even	O
moderately	O
high	O
dimensions	O
the	O
amount	O
of	O
computation	O
involved	O
in	O
these	O
problems	O
is	O
enormous	O
in	O
addition	O
to	O
the	O
computational	O
difficulties	O
of	O
working	O
in	O
high	O
what	O
is	O
the	O
difference	O
between	O
unsupervised	O
and	O
supervised	O
learning	O
that	O
means	O
that	O
we	O
know	O
what	O
the	O
right	O
answer	O
is	O
for	O
supervised	O
learning	O
but	O
not	O
for	O
unsupervised	B
learning	I
if	O
you	O
want	O
to	O
try	O
to	O
get	O
an	O
intuitive	O
sense	O
of	O
what	O
four	O
dimensions	O
looks	O
like	O
i	O
highly	O
recommend	O
the	O
short	O
book	O
flatland	O
a	O
romance	O
of	O
many	O
dimensions	O
by	O
edwin	O
abbott	O
abbott	O
you	O
can	O
even	O
read	O
it	O
online	B
at	O
figure	O
knn	O
with	O
an	O
overlaid	O
grid	O
cell	O
with	O
test	O
point	O
highlighted	O
how	O
does	O
the	O
above	O
analysis	O
relate	O
to	O
the	O
number	O
of	O
data	O
points	O
you	O
would	O
need	O
to	O
fill	O
out	O
a	O
full	O
decision	B
tree	I
with	O
d-many	O
features	B
what	O
does	O
this	O
say	O
about	O
the	O
importance	O
of	O
shallow	O
trees	O
geometry	O
and	O
nearest	O
neighbors	O
dimensions	O
there	O
are	O
a	O
large	O
number	O
of	O
strange	O
mathematical	O
occurances	O
there	O
in	O
particular	O
many	O
of	O
your	O
intuitions	O
that	O
you	O
ve	O
built	O
up	O
from	O
working	O
in	O
two	O
and	O
three	O
dimensions	O
just	O
do	O
not	O
carry	O
over	O
to	O
high	O
dimensions	O
we	O
will	O
consider	O
two	O
effects	O
but	O
there	O
are	O
countless	O
others	O
the	O
first	O
is	O
that	O
high	O
dimensional	O
spheres	O
look	O
more	O
like	O
porcupines	O
than	O
like	O
the	O
second	O
is	O
that	O
distances	O
between	O
points	O
in	O
high	O
dimensions	O
are	O
all	O
approximately	O
the	O
same	O
let	O
s	O
start	O
in	O
two	O
dimensions	O
as	O
in	O
figure	O
we	O
ll	O
start	O
with	O
four	O
green	O
spheres	O
each	O
of	O
radius	O
one	O
and	O
each	O
touching	O
exactly	O
two	O
other	O
green	O
spheres	O
that	O
in	O
two	O
dimensions	O
a	O
sphere	O
is	O
just	O
a	O
circle	O
we	O
ll	O
place	O
a	O
red	O
sphere	O
in	O
the	O
middle	O
so	O
that	O
it	O
touches	O
all	O
four	O
green	O
spheres	O
we	O
can	O
easily	O
compute	O
the	O
radius	O
of	O
this	O
small	O
sphere	O
the	O
pythagorean	O
theorem	O
says	O
that	O
thus	O
by	O
calculation	O
so	O
solving	O
for	O
r	O
we	O
get	O
r	O
the	O
blue	O
sphere	O
lies	O
entirely	O
within	O
the	O
cube	O
square	O
that	O
contains	O
the	O
grey	O
spheres	O
this	O
is	O
also	O
obvious	O
from	O
the	O
picture	O
but	O
perhaps	O
you	O
can	O
see	O
where	O
this	O
is	O
going	O
now	O
we	O
can	O
do	O
the	O
same	O
experiment	O
in	O
three	O
dimensions	O
as	O
shown	O
in	O
figure	O
again	O
we	O
can	O
use	O
the	O
pythagorean	O
theorem	O
to	O
compute	O
the	O
radius	O
of	O
the	O
blue	O
sphere	O
now	O
we	O
get	O
this	O
is	O
still	O
entirely	O
enclosed	O
in	O
the	O
so	O
r	O
cube	O
of	O
width	O
four	O
that	O
holds	O
all	O
eight	O
grey	O
spheres	O
at	O
this	O
point	O
it	O
becomes	O
difficult	O
to	O
produce	O
figures	O
so	O
you	O
ll	O
have	O
to	O
apply	O
your	O
imagination	O
in	O
four	O
dimensions	O
we	O
would	O
have	O
green	O
spheres	O
hyperspheres	B
each	O
of	O
radius	O
one	O
they	O
would	O
still	O
be	O
inside	O
a	O
cube	O
a	O
hypercube	B
of	O
width	O
four	O
the	O
continuing	O
blue	O
hypersphere	O
would	O
have	O
radius	O
r	O
to	O
five	O
dimensions	O
the	O
blue	O
hypersphere	O
embedded	O
in	O
green	O
hyperspheres	B
would	O
have	O
radius	O
r	O
and	O
so	O
on	O
in	O
general	O
in	O
d-dimensional	O
space	O
there	O
will	O
be	O
green	O
hyper	O
spheres	O
of	O
radius	O
one	O
each	O
green	O
hypersphere	O
will	O
touch	O
exactly	O
n-many	O
other	O
hyperspheres	B
the	O
blue	O
hyperspheres	B
in	O
the	O
middle	O
will	O
touch	O
them	O
all	O
and	O
will	O
have	O
radius	O
r	O
d	O
this	O
result	O
was	O
related	O
to	O
me	O
by	O
mark	O
reid	O
who	O
heard	O
about	O
it	O
from	O
marcus	O
hutter	O
figure	O
spheres	O
in	O
spheres	O
figure	O
spheres	O
in	O
spheres	O
think	O
about	O
this	O
for	O
a	O
moment	O
as	O
the	O
number	O
of	O
dimensions	O
grows	O
the	O
radius	O
of	O
the	O
blue	O
hypersphere	O
grows	O
without	O
bound	O
for	O
example	O
in	O
the	O
radius	O
of	O
the	O
blue	O
hypersphere	O
is	O
now	O
but	O
with	O
a	O
radius	O
of	O
two	O
the	O
blue	O
hypersphere	O
is	O
now	O
squeezing	O
between	O
the	O
green	O
hypersphere	O
and	O
touching	O
the	O
edges	O
of	O
the	O
hypercube	B
in	O
dimensional	O
space	O
the	O
radius	O
is	O
approximately	O
and	O
it	O
pokes	O
outside	O
the	O
cube	O
this	O
is	O
why	O
we	O
say	O
that	O
high	O
dimensional	O
spheres	O
look	O
like	O
porcupines	O
and	O
not	O
balls	O
figure	O
the	O
moral	O
of	O
this	O
story	O
from	O
a	O
machine	O
learning	O
perspective	O
is	O
that	O
intuitions	O
you	O
have	O
about	O
space	O
might	O
not	O
carry	O
over	O
to	O
high	O
dimensions	O
for	O
example	O
what	O
you	O
figure	O
porcupine	O
versus	O
ball	O
a	O
course	O
in	O
machine	O
learning	O
think	O
looks	O
like	O
a	O
round	O
cluster	O
in	O
two	O
or	O
three	O
dimensions	O
might	O
not	O
look	O
so	O
round	O
in	O
high	O
dimensions	O
the	O
second	O
strange	O
fact	O
we	O
will	O
consider	O
has	O
to	O
do	O
with	O
the	O
distances	O
between	O
points	O
in	O
high	O
dimensions	O
we	O
start	O
by	O
considering	O
random	O
points	O
in	O
one	O
dimension	O
that	O
is	O
we	O
generate	O
a	O
fake	O
data	O
set	O
consisting	O
of	O
random	O
points	O
between	O
zero	O
and	O
one	O
we	O
can	O
do	O
the	O
same	O
in	O
two	O
dimensions	O
and	O
in	O
three	O
dimensions	O
see	O
figure	O
for	O
data	O
distributed	O
uniformly	O
on	O
the	O
unit	B
hypercube	B
in	O
different	O
dimensions	O
now	O
pick	O
two	O
of	O
these	O
points	O
at	O
random	O
and	O
compute	O
the	O
distance	B
between	O
them	O
repeat	O
this	O
process	O
for	O
all	B
pairs	I
of	O
points	O
and	O
average	O
the	O
results	O
for	O
the	O
data	O
shown	O
in	O
figure	O
the	O
average	O
distance	B
between	O
points	O
in	O
one	O
dimension	O
is	O
about	O
in	O
two	O
dimensions	O
is	O
about	O
and	O
in	O
three	O
dimensions	O
is	O
the	O
fact	O
that	O
these	O
increase	O
as	O
the	O
dimension	O
increases	O
is	O
not	O
surprising	O
the	O
furthest	O
two	O
points	O
can	O
be	O
in	O
a	O
hypercube	B
is	O
the	O
furthest	O
in	O
a	O
hypercube	B
is	O
corners	O
the	O
furthest	O
in	O
a	O
hypercube	B
is	O
the	O
furthest	O
two	O
points	O
in	O
a	O
d-dimensional	O
hypercube	B
will	O
be	O
d	O
you	O
can	O
actually	O
compute	O
these	O
values	O
analytically	O
write	O
unid	O
for	O
the	O
uniform	O
distribution	O
in	O
d	O
dimensions	O
the	O
quantity	O
we	O
are	O
interested	O
in	O
computing	O
is	O
and	O
so	O
on	O
in	O
general	O
avgdistd	O
ea	O
unid	O
eb	O
unid	O
we	O
can	O
actually	O
compute	O
this	O
in	O
closed	O
form	O
exercise	O
for	O
a	O
bit	O
of	O
calculus	O
refresher	O
and	O
arrive	O
at	O
avgdistd	O
we	O
know	O
that	O
the	O
maximum	O
distance	B
between	O
two	O
points	O
grows	O
like	O
d	O
this	O
says	O
that	O
the	O
ratio	O
between	O
average	O
distance	B
and	O
maximum	O
because	O
distance	B
converges	O
to	O
what	O
is	O
more	O
interesting	O
however	O
is	O
the	O
variance	B
of	O
the	O
distribution	O
of	O
distances	O
you	O
can	O
show	O
that	O
in	O
d	O
dimensions	O
the	O
variance	B
is	O
constant	O
independent	O
of	O
d	O
this	O
means	O
that	O
when	O
you	O
look	O
at	O
divided-by	O
distance	B
the	O
variance	B
behaves	O
like	O
as	O
d	O
grows	O
which	O
means	O
that	O
the	O
effective	O
variance	B
continues	O
to	O
shrink	O
when	O
i	O
first	O
saw	O
and	O
re-proved	O
this	O
result	O
i	O
was	O
skeptical	O
as	O
i	O
imagine	O
you	O
are	O
so	O
i	O
implemented	O
it	O
in	O
figure	O
you	O
can	O
see	O
the	O
results	O
this	O
presents	O
a	O
histogram	B
of	O
distances	O
between	O
random	O
points	O
in	O
d	O
dimensions	O
for	O
d	O
as	O
you	O
can	O
see	O
d	O
even	O
for	O
all	O
of	O
these	O
distances	O
begin	O
to	O
concentrate	O
around	O
medium	O
dimension	O
problems	O
you	O
should	O
now	O
be	O
terrified	O
the	O
only	O
bit	O
of	O
information	O
that	O
knn	O
gets	O
is	O
distances	O
and	O
you	O
ve	O
just	O
seen	O
that	O
in	O
moderately	O
high	O
dimensions	O
all	O
distances	O
becomes	O
equal	O
so	O
then	O
isn	O
t	O
it	O
the	O
case	O
that	O
figure	O
uniform	O
random	O
points	O
in	O
and	O
dimensions	O
sergey	O
brin	O
near	O
neighbor	O
search	O
in	O
large	O
metric	O
spaces	O
in	O
conference	O
on	O
very	O
large	O
databases	O
figure	O
histogram	B
of	O
distances	O
in	O
of	O
pairs	O
of	O
points	O
at	O
that	O
distancedimensionality	O
versus	O
uniform	O
point	O
dims	O
geometry	O
and	O
nearest	O
neighbors	O
knn	O
simply	O
cannot	O
work	O
the	O
answer	O
has	O
to	O
be	O
no	O
the	O
reason	O
is	O
that	O
the	O
data	O
that	O
we	O
get	O
is	O
not	O
uniformly	O
distributed	O
over	O
the	O
unit	B
hypercube	B
we	O
can	O
see	O
this	O
by	O
looking	O
at	O
two	O
real-world	O
data	O
sets	O
the	O
first	O
is	O
an	O
image	O
data	O
set	O
of	O
hand-written	O
digits	O
through	O
nine	O
see	O
section	O
although	O
this	O
data	O
is	O
originally	O
in	O
dimensions	O
pixels	O
by	O
pixels	O
we	O
can	O
artifically	O
reduce	O
the	O
dimensionality	O
of	O
this	O
data	O
in	O
figure	O
you	O
can	O
see	O
the	O
histogram	B
of	O
average	O
distances	O
between	O
points	O
in	O
this	O
data	O
at	O
a	O
number	O
of	O
dimensions	O
as	O
you	O
can	O
see	O
from	O
these	O
histograms	O
distances	O
have	O
not	O
concentrated	O
around	O
a	O
single	O
value	O
this	O
is	O
very	O
good	O
news	O
it	O
means	O
that	O
there	O
is	O
hope	O
for	O
learning	O
algorithms	O
to	O
work	O
nevertheless	O
the	O
moral	O
is	O
that	O
high	O
dimensions	O
are	O
weird	O
extensions	O
to	O
knn	O
there	O
are	O
several	O
fundamental	O
problems	O
with	O
knn	O
classifiers	O
first	O
some	O
neighbors	O
might	O
be	O
better	O
than	O
others	O
second	O
test-time	O
performance	O
scales	O
badly	O
as	O
your	O
number	O
of	O
training	O
examples	B
increases	O
third	O
it	O
treats	O
each	O
dimension	O
independently	B
we	O
will	O
not	O
address	O
the	O
third	O
issue	O
as	O
it	O
has	O
not	O
really	O
been	O
solved	O
it	O
makes	O
a	O
great	O
thought	O
question	O
regarding	O
neighborliness	O
consider	O
figure	O
using	O
k	O
nearest	O
neighbors	O
the	O
test	O
point	O
would	O
be	O
classified	O
as	O
positive	O
however	O
we	O
might	O
actually	O
believe	O
that	O
it	O
should	O
be	O
classified	O
negative	O
because	O
the	O
two	O
negative	O
neighbors	O
are	O
much	O
closer	O
than	O
the	O
three	O
positive	O
neighbors	O
there	O
are	O
at	O
least	O
two	O
ways	O
of	O
addressing	O
this	O
issue	O
the	O
first	O
is	O
the	O
solution	O
instead	O
of	O
connecting	O
each	O
data	O
point	O
to	O
some	O
fixed	O
number	O
of	O
nearest	O
neighbors	O
we	O
simply	O
connect	O
it	O
to	O
all	O
neighbors	O
that	O
fall	O
within	O
some	O
ball	O
of	O
radius	O
then	O
the	O
majority	O
class	O
of	O
all	O
the	O
points	O
in	O
the	O
ball	O
wins	O
in	O
the	O
case	O
of	O
a	O
tie	O
you	O
would	O
have	O
to	O
either	O
guess	O
or	O
report	O
the	O
majority	O
class	O
figure	O
shows	O
an	O
ball	O
around	O
the	O
test	O
point	O
that	O
happens	O
to	O
yield	O
the	O
proper	O
classification	O
when	O
using	O
nearest	O
neighbors	O
rather	O
than	O
knn	O
the	O
hyperparameter	B
changes	O
from	O
k	O
to	O
you	O
would	O
need	O
to	O
set	O
it	O
in	O
the	O
same	O
way	O
as	O
you	O
would	O
for	O
knn	O
an	O
alternative	O
to	O
the	O
solution	O
is	O
to	O
do	O
weighted	B
nearest	I
neighbors	I
the	O
idea	O
here	O
is	O
to	O
still	O
consider	O
the	O
k-nearest	B
neighbors	I
of	O
a	O
test	O
point	O
but	O
give	O
them	O
uneven	O
votes	O
closer	O
points	O
get	O
more	O
vote	B
than	O
further	O
points	O
when	O
classifying	O
a	O
point	O
x	O
the	O
usual	O
strategy	O
is	O
to	O
give	O
a	O
training	O
point	O
xn	O
a	O
vote	B
that	O
decays	O
exponentially	O
in	O
the	O
distance	B
between	O
x	O
and	O
xn	O
mathematically	O
the	O
vote	B
that	O
neigh	O
figure	O
knnmnist	O
histogram	B
of	O
distances	O
in	O
multiple	O
d	O
for	O
mnist	O
figure	O
data	O
set	O
with	O
test	O
point	O
closest	O
to	O
two	O
negatives	O
then	O
to	O
three	O
far	O
positives	O
figure	O
same	O
as	O
previous	O
with	O
ball	O
one	O
issue	O
with	O
is	O
that	O
the	O
for	O
some	O
test	O
point	O
might	O
be	O
empty	O
how	O
would	O
you	O
handle	O
this	O
a	O
course	O
in	O
machine	O
learning	O
bor	O
n	O
gets	O
is	O
exp	O
x	O
thus	O
nearby	O
points	O
get	O
a	O
vote	B
very	O
close	O
to	O
and	O
far	O
away	O
points	O
get	O
a	O
vote	B
very	O
close	O
to	O
the	O
overall	O
prediction	O
is	O
positive	O
if	O
the	O
sum	O
of	O
votes	O
from	O
positive	O
neighbors	O
outweighs	O
the	O
sum	O
of	O
votes	O
from	O
negative	O
neighbors	O
the	O
second	O
issue	O
with	O
knn	O
is	O
scaling	O
to	O
predict	B
the	O
label	B
of	O
a	O
single	O
test	O
point	O
we	O
need	O
to	O
find	O
the	O
k	O
nearest	O
neighbors	O
of	O
that	O
test	O
point	O
in	O
the	O
training	B
data	I
with	O
a	O
standard	O
implementation	O
this	O
will	O
take	O
ond	O
k	O
log	O
k	O
for	O
very	O
large	O
data	O
sets	O
this	O
is	O
impractical	O
a	O
first	O
attempt	O
to	O
speed	O
up	O
the	O
computation	O
is	O
to	O
represent	O
each	O
class	O
by	O
a	O
representative	O
a	O
natural	O
choice	O
for	O
a	O
representative	O
would	O
be	O
the	O
mean	O
we	O
would	O
collapse	O
all	O
positive	O
examples	B
down	O
to	O
their	O
mean	O
and	O
all	O
negative	O
examples	B
down	O
to	O
their	O
mean	O
we	O
could	O
then	O
just	O
run	O
neighbor	O
and	O
check	O
whether	O
a	O
test	O
point	O
is	O
closer	O
to	O
the	O
mean	O
of	O
the	O
positive	O
points	O
or	O
the	O
mean	O
of	O
the	O
negative	O
points	O
figure	O
shows	O
an	O
example	O
in	O
which	O
this	O
would	O
probably	O
work	O
well	O
and	O
an	O
example	O
in	O
which	O
this	O
would	O
probably	O
work	O
poorly	O
the	O
problem	O
is	O
that	O
collapsing	O
each	O
class	O
to	O
its	O
mean	O
is	O
too	O
aggressive	O
a	O
less	O
aggressive	O
approach	O
is	O
to	O
make	O
use	O
of	O
the	O
k-means	O
algorithm	B
for	O
clustering	B
you	O
can	O
cluster	O
the	O
positive	O
examples	B
into	O
l	O
clusters	O
are	O
using	O
l	O
to	O
avoid	O
variable	O
overloading	O
and	O
then	O
cluster	O
the	O
negative	O
examples	B
into	O
l	O
separate	O
clusters	O
this	O
is	O
shown	O
in	O
figure	O
with	O
l	O
instead	O
of	O
storing	O
the	O
entire	O
data	O
set	O
you	O
would	O
only	O
store	O
the	O
means	O
of	O
the	O
l	O
positive	O
clusters	O
and	O
the	O
means	O
of	O
the	O
l	O
negative	O
clusters	O
at	O
test	O
time	O
you	O
would	O
run	O
the	O
k-nearest	B
neighbors	I
algorithm	B
against	O
these	O
means	O
rather	O
than	O
against	O
the	O
full	O
training	O
set	O
this	O
leads	O
to	O
a	O
much	O
faster	O
runtime	O
of	O
just	O
old	O
k	O
log	O
k	O
which	O
is	O
probably	O
dominated	O
by	O
ld	O
could	O
you	O
combine	O
the	O
idea	O
with	O
the	O
weighted	O
voting	B
idea	O
does	O
it	O
make	O
sense	O
or	O
does	O
one	O
idea	O
seem	O
to	O
trump	O
the	O
other	O
the	O
nd	O
term	O
comes	O
from	O
computing	O
distances	O
between	O
the	O
test	O
point	O
and	O
all	O
training	O
points	O
the	O
k	O
log	O
k	O
term	O
comes	O
from	O
finding	O
the	O
k	O
smallest	O
values	O
in	O
the	O
list	O
of	O
distances	O
using	O
a	O
median-finding	O
algorithm	B
of	O
course	O
nd	O
almost	O
always	O
dominates	B
k	O
log	O
k	O
in	O
practice	O
exercises	O
exercise	O
todo	O
figure	O
knncollapse	O
two	O
figures	O
of	O
points	O
collapsed	O
to	O
mean	O
one	O
with	O
good	O
results	O
and	O
one	O
with	O
dire	O
results	O
figure	O
data	O
from	O
previous	O
bad	O
case	O
collapsed	O
into	O
cluster	O
and	O
test	O
point	O
classified	O
based	O
on	O
means	O
and	O
clustering	B
of	O
classes	O
was	O
introduced	O
as	O
a	O
way	O
of	O
making	O
things	O
faster	O
will	O
it	O
make	O
things	O
worse	O
or	O
the	O
perceptron	B
so	O
far	O
you	O
ve	O
seen	O
two	O
types	O
of	O
learning	O
models	O
in	O
decision	B
trees	I
only	O
a	O
small	O
number	O
of	O
features	B
are	O
used	O
to	O
make	O
decisions	O
in	O
nearest	B
neighbor	I
algorithms	O
all	O
features	B
are	O
used	O
equally	O
neither	O
of	O
these	O
extremes	O
is	O
always	O
desirable	O
in	O
some	O
problems	O
we	O
might	O
want	O
to	O
use	O
most	O
of	O
the	O
features	B
but	O
use	O
some	O
more	O
than	O
others	O
in	O
this	O
chapter	O
we	O
ll	O
discuss	O
the	O
perceptron	B
algorithm	B
for	O
learning	O
weights	B
for	O
features	B
as	O
we	O
ll	O
see	O
learning	O
weights	B
for	O
features	B
amounts	O
to	O
learning	O
a	O
hyperplane	B
classifier	O
that	O
is	O
basically	O
a	O
division	O
of	O
space	O
into	O
two	O
halves	O
by	O
a	O
straight	O
line	O
where	O
one	O
half	O
is	O
positive	O
and	O
one	O
half	O
is	O
negative	O
in	O
this	O
sense	O
the	O
perceptron	B
can	O
be	O
seen	O
as	O
explicitly	O
finding	O
a	O
good	O
linear	B
decision	B
boundary	I
learning	O
objectives	O
describe	O
the	O
biological	O
motivation	O
behind	O
the	O
perceptron	B
classify	O
learning	O
algorithms	O
based	O
on	O
whether	O
they	O
are	O
error-driven	O
or	O
not	O
implement	O
the	O
perceptron	B
algorithm	B
for	O
binary	O
classification	O
draw	O
perceptron	B
weight	O
vectors	O
and	O
the	O
corresponding	O
decision	O
boundaries	O
in	O
two	O
dimensions	O
contrast	O
the	O
decision	O
boundaries	O
of	O
decision	B
trees	I
nearest	B
neighbor	I
algorithms	O
and	O
perceptrons	O
compute	O
the	O
margin	B
of	O
a	O
given	O
weight	O
vector	B
on	O
a	O
given	O
data	O
set	O
bio-inspired	O
learning	O
dependencies	O
chapter	O
chapter	O
folk	O
biology	O
tells	O
us	O
that	O
our	O
brains	O
are	O
made	O
up	O
of	O
a	O
bunch	O
of	O
little	O
units	O
called	O
neurons	B
that	O
send	O
electrical	O
signals	O
to	O
one	O
another	O
the	O
rate	O
of	O
firing	O
tells	O
us	O
how	O
activated	O
a	O
neuron	O
is	O
a	O
single	O
neuron	O
like	O
that	O
shown	O
in	O
figure	O
might	O
have	O
three	O
incoming	O
neurons	B
these	O
incoming	O
neurons	B
are	O
firing	O
at	O
different	O
rates	O
have	O
different	O
activations	B
based	O
on	O
how	O
much	O
these	O
incoming	O
neurons	B
are	O
firing	O
and	O
how	O
strong	O
the	O
neural	O
connections	O
are	O
our	O
main	O
neuron	O
will	O
decide	O
how	O
strongly	O
it	O
wants	O
to	O
fire	O
and	O
so	O
on	O
through	O
the	O
whole	O
brain	O
learning	O
in	O
the	O
brain	O
happens	O
by	O
neurons	B
becomming	O
connected	O
to	O
other	O
neurons	B
and	O
the	O
strengths	O
of	O
connections	O
adapting	O
over	O
time	O
the	O
real	O
biological	O
world	O
is	O
much	O
more	O
complicated	O
than	O
this	O
however	O
our	O
goal	O
isn	O
t	O
to	O
build	O
a	O
brain	O
but	O
to	O
simply	O
be	O
inspired	O
by	O
how	O
they	O
work	O
we	O
are	O
going	O
to	O
think	O
of	O
our	O
learning	O
algorithm	B
as	O
a	O
single	O
neuron	O
it	O
receives	O
input	O
from	O
d-many	O
other	O
neurons	B
one	O
for	O
each	O
input	O
feature	O
the	O
strength	O
of	O
these	O
inputs	O
are	O
the	O
feature	B
values	I
this	O
is	O
shown	O
schematically	O
in	O
figure	O
each	O
incoming	O
connection	O
has	O
a	O
weight	O
and	O
the	O
neuron	O
simply	O
sums	O
up	O
all	O
the	O
weighted	O
inputs	O
based	O
on	O
this	O
sum	O
it	O
decides	O
whether	O
to	O
fire	O
or	O
figure	O
a	O
picture	O
of	O
a	O
neuron	O
figure	O
figure	O
showing	O
feature	B
vector	B
and	O
weight	O
vector	B
and	O
products	O
and	O
sum	O
a	O
course	O
in	O
machine	O
learning	O
not	O
firing	O
is	O
interpreted	O
as	O
being	O
a	O
positive	O
example	O
and	O
not	O
firing	O
is	O
interpreted	O
as	O
being	O
a	O
negative	O
example	O
in	O
particular	O
if	O
the	O
weighted	O
sum	O
is	O
positive	O
it	O
fires	O
and	O
otherwise	O
it	O
doesn	O
t	O
fire	O
this	O
is	O
shown	O
diagramatically	O
in	O
figure	O
mathematically	O
an	O
input	O
vector	B
x	O
arrives	O
the	O
neuron	O
stores	O
d-many	O
weights	B
wd	O
the	O
neuron	O
computes	O
the	O
sum	O
d	O
a	O
wdxd	O
to	O
determine	O
it	O
s	O
amount	O
of	O
activation	O
if	O
this	O
activiation	O
is	O
positive	O
a	O
it	O
predicts	O
that	O
this	O
example	O
is	O
a	O
positive	O
example	O
otherwise	O
it	O
predicts	O
a	O
negative	O
example	O
the	O
weights	B
of	O
this	O
neuron	O
are	O
fairly	O
easy	O
to	O
interpret	O
suppose	O
that	O
a	O
feature	O
for	O
instance	O
is	O
this	O
a	O
system	O
s	O
class	O
gets	O
a	O
zero	O
weight	O
then	O
the	O
activation	O
is	O
the	O
same	O
regardless	O
of	O
the	O
value	O
of	O
this	O
feature	O
so	O
features	B
with	O
zero	O
weight	O
are	O
ignored	O
features	B
with	O
positive	O
weights	B
are	O
indicative	O
of	O
positive	O
examples	B
because	O
they	O
cause	O
the	O
activation	O
to	O
increase	O
features	B
with	O
negative	O
weights	B
are	O
indicative	O
of	O
negative	O
examples	B
because	O
they	O
cause	O
the	O
activiation	O
to	O
decrease	O
it	O
is	O
often	O
convenient	O
to	O
have	O
a	O
non-zero	O
threshold	B
in	O
other	O
words	O
we	O
might	O
want	O
to	O
predict	B
positive	O
if	O
a	O
for	O
some	O
value	O
the	O
way	O
that	O
is	O
most	O
convenient	O
to	O
achieve	O
this	O
is	O
to	O
introduce	O
a	O
bias	B
term	O
into	O
the	O
neuron	O
so	O
that	O
the	O
activation	O
is	O
always	O
increased	O
by	O
some	O
fixed	O
value	O
b	O
thus	O
we	O
compute	O
d	O
a	O
wdxd	O
b	O
what	O
would	O
happen	O
if	O
we	O
encoded	O
binary	B
features	B
like	O
is	O
this	O
a	O
system	O
s	O
class	O
as	O
and	O
yes	O
than	O
the	O
standard	O
and	O
this	O
is	O
the	O
complete	O
neural	O
model	B
of	O
learning	O
the	O
model	B
is	O
parameterized	O
by	O
d-many	O
weights	B
wd	O
and	O
a	O
single	O
scalar	O
bias	B
value	O
b	O
if	O
you	O
wanted	O
the	O
activation	O
threshold	B
to	O
be	O
a	O
instead	O
of	O
a	O
what	O
value	O
would	O
b	O
have	O
to	O
be	O
error-driven	O
updating	O
the	O
perceptron	B
algorithm	B
vignette	O
the	O
history	O
of	O
the	O
perceptron	B
todo	O
the	O
perceptron	B
is	O
a	O
classic	O
learning	O
algorithm	B
for	O
the	O
neural	O
model	B
of	O
learning	O
like	O
k-nearest	B
neighbors	I
it	O
is	O
one	O
of	O
those	O
frustrating	O
algorithms	O
that	O
is	O
incredibly	O
simple	O
and	O
yet	O
works	O
amazingly	O
well	O
for	O
some	O
types	O
of	O
problems	O
the	O
perceptron	B
initialize	O
weights	B
initialize	O
bias	B
algorithm	B
perceptrontraind	O
maxiter	O
wd	O
for	O
all	O
d	O
d	O
b	O
for	O
iter	O
maxiter	O
do	O
for	O
all	O
d	O
do	O
wd	O
xd	O
b	O
a	O
d	O
if	O
ya	O
then	O
wd	O
wd	O
yxd	O
for	O
all	O
d	O
d	O
b	O
b	O
y	O
compute	O
activation	O
for	O
this	O
example	O
update	O
weights	B
update	O
bias	B
end	O
if	O
end	O
for	O
end	O
for	O
return	O
wd	O
b	O
algorithm	B
wd	O
b	O
x	O
a	O
d	O
return	O
signa	O
wd	O
xd	O
b	O
compute	O
activation	O
for	O
the	O
test	O
example	O
the	O
algorithm	B
is	O
actually	O
quite	O
different	O
than	O
either	O
the	O
decision	B
tree	I
algorithm	B
or	O
the	O
knn	O
algorithm	B
first	O
it	O
is	O
online	B
this	O
means	O
that	O
instead	O
of	O
considering	O
the	O
entire	O
data	O
set	O
at	O
the	O
same	O
time	O
it	O
only	O
ever	O
looks	O
at	O
one	O
example	O
it	O
processes	O
that	O
example	O
and	O
then	O
goes	O
on	O
to	O
the	O
next	O
one	O
second	O
it	O
is	O
error	B
driven	I
this	O
means	O
that	O
so	O
long	O
as	O
it	O
is	O
doing	O
well	O
it	O
doesn	O
t	O
bother	O
updating	O
its	O
parameters	O
the	O
algorithm	B
maintains	O
a	O
guess	O
at	O
good	O
parameters	O
and	O
bias	B
as	O
it	O
runs	O
it	O
processes	O
one	O
example	O
at	O
a	O
time	O
for	O
a	O
given	O
example	O
it	O
makes	O
a	O
prediction	O
it	O
checks	O
to	O
see	O
if	O
this	O
prediction	O
is	O
correct	O
that	O
this	O
is	O
training	B
data	I
so	O
we	O
have	O
access	O
to	O
true	O
labels	O
if	O
the	O
prediction	O
is	O
correct	O
it	O
does	O
nothing	O
only	O
when	O
the	O
prediction	O
is	O
incorrect	O
does	O
it	O
change	O
its	O
parameters	O
and	O
it	O
changes	O
them	O
in	O
such	O
a	O
way	O
that	O
it	O
would	O
do	O
better	O
on	O
this	O
example	O
next	O
time	O
around	O
it	O
then	O
goes	O
on	O
to	O
the	O
next	O
example	O
once	O
it	O
hits	O
the	O
last	O
example	O
in	O
the	O
training	O
set	O
it	O
loops	O
back	O
around	O
for	O
a	O
specified	O
number	O
of	O
iterations	O
the	O
training	O
algorithm	B
for	O
the	O
perceptron	B
is	O
shown	O
in	O
algo	O
rithm	O
and	O
the	O
corresponding	O
prediction	O
algorithm	B
is	O
shown	O
in	O
algorithm	B
there	O
is	O
one	O
trick	O
in	O
the	O
training	O
algorithm	B
which	O
probably	O
seems	O
silly	O
but	O
will	O
be	O
useful	O
later	O
it	O
is	O
in	O
line	O
when	O
we	O
check	O
to	O
see	O
if	O
we	O
want	O
to	O
make	O
an	O
update	O
or	O
not	O
we	O
want	O
to	O
make	O
an	O
update	O
if	O
the	O
current	O
prediction	O
signa	O
is	O
incorrect	O
the	O
trick	O
is	O
to	O
multiply	O
the	O
true	O
label	B
y	O
by	O
the	O
activation	O
a	O
and	O
compare	O
this	O
against	O
zero	O
since	O
the	O
label	B
y	O
is	O
either	O
or	O
you	O
just	O
need	O
to	O
realize	O
that	O
ya	O
is	O
positive	O
whenever	O
a	O
and	O
y	O
have	O
the	O
same	O
sign	B
in	O
other	O
words	O
the	O
product	O
ya	O
is	O
positive	O
if	O
the	O
current	O
prediction	O
is	O
correct	O
it	O
is	O
very	O
very	O
important	O
to	O
check	O
ya	O
rather	O
than	O
ya	O
why	O
a	O
course	O
in	O
machine	O
learning	O
the	O
particular	O
form	O
of	O
update	O
for	O
the	O
perceptron	B
is	O
quite	O
simple	O
the	O
weight	O
wd	O
is	O
increased	O
by	O
yxd	O
and	O
the	O
bias	B
is	O
increased	O
by	O
y	O
the	O
goal	O
of	O
the	O
update	O
is	O
to	O
adjust	O
the	O
parameters	O
so	O
that	O
they	O
are	O
better	O
for	O
the	O
current	O
example	O
in	O
other	O
words	O
if	O
we	O
saw	O
this	O
example	O
twice	O
in	O
a	O
row	O
we	O
should	O
do	O
a	O
better	O
job	O
the	O
second	O
time	O
around	O
to	O
see	O
why	O
this	O
particular	O
update	O
achieves	O
this	O
consider	O
the	O
fol	O
lowing	O
scenario	O
we	O
have	O
some	O
current	O
set	O
of	O
parameters	O
wd	O
b	O
we	O
observe	O
an	O
example	O
y	O
for	O
simplicity	O
suppose	O
this	O
is	O
a	O
positive	O
example	O
so	O
y	O
we	O
compute	O
an	O
activation	O
a	O
and	O
make	O
an	O
error	O
namely	O
a	O
we	O
now	O
update	O
our	O
weights	B
and	O
bias	B
let	O
s	O
call	O
the	O
new	O
weights	B
d	O
suppose	O
we	O
observe	O
the	O
same	O
example	O
again	O
and	O
need	O
to	O
compute	O
a	O
new	O
activation	O
we	O
proceed	O
by	O
a	O
little	O
algebra	O
d	O
d	O
d	O
dxd	O
xdxd	O
wdxd	O
b	O
d	O
xdxd	O
a	O
d	O
d	O
a	O
d	O
but	O
so	O
the	O
difference	O
between	O
the	O
old	O
activation	O
a	O
and	O
the	O
new	O
activad	O
since	O
it	O
s	O
squared	O
so	O
this	O
value	O
is	O
tion	O
is	O
d	O
always	O
at	O
least	O
one	O
thus	O
the	O
new	O
activation	O
is	O
always	O
at	O
least	O
the	O
old	O
activation	O
plus	O
one	O
since	O
this	O
was	O
a	O
positive	O
example	O
we	O
have	O
successfully	O
moved	O
the	O
activation	O
in	O
the	O
proper	O
direction	O
note	O
that	O
there	O
s	O
no	O
guarantee	O
that	O
we	O
will	O
correctly	O
classify	O
this	O
point	O
the	O
second	O
third	O
or	O
even	O
fourth	O
time	O
around	O
the	O
only	O
hyperparameter	B
of	O
the	O
perceptron	B
algorithm	B
is	O
maxiter	O
the	O
number	O
of	O
passes	O
to	O
make	O
over	O
the	O
training	B
data	I
if	O
we	O
make	O
many	O
many	O
passes	O
over	O
the	O
training	B
data	I
then	O
the	O
algorithm	B
is	O
likely	O
to	O
overfit	O
would	O
be	O
like	O
studying	O
too	O
long	O
for	O
an	O
exam	O
and	O
just	O
confusing	O
yourself	O
on	O
the	O
other	O
hand	O
going	O
over	O
the	O
data	O
only	O
one	O
time	O
might	O
lead	O
to	O
underfitting	B
this	O
is	O
shown	O
experimentally	O
in	O
figure	O
the	O
x-axis	O
shows	O
the	O
number	O
of	O
passes	O
over	O
the	O
data	O
and	O
the	O
y-axis	O
shows	O
the	O
training	B
error	I
and	O
the	O
test	B
error	I
as	O
you	O
can	O
see	O
there	O
is	O
a	O
sweet	O
spot	O
at	O
which	O
test	O
performance	O
begins	O
to	O
degrade	O
due	O
to	O
overfitting	B
one	O
aspect	O
of	O
the	O
perceptron	B
algorithm	B
that	O
is	O
left	O
underspecified	O
is	O
line	O
which	O
says	O
loop	O
over	O
all	O
the	O
training	O
examples	B
the	O
natural	O
implementation	O
of	O
this	O
would	O
be	O
to	O
loop	O
over	O
them	O
in	O
a	O
constant	O
order	O
the	O
is	O
actually	O
a	O
bad	O
idea	O
this	O
analysis	O
hold	O
for	O
the	O
case	O
positive	O
examples	B
it	O
should	O
also	O
hold	O
for	O
negative	O
examples	B
work	O
it	O
out	O
figure	O
training	O
and	O
test	B
error	I
via	O
early	B
stopping	I
consider	O
what	O
the	O
perceptron	B
algorithm	B
would	O
do	O
on	O
a	O
data	O
set	O
that	O
consisted	O
of	O
positive	O
examples	B
followed	O
by	O
negative	O
examples	B
after	O
seeing	O
the	O
first	O
few	O
positive	O
examples	B
five	O
it	O
would	O
likely	O
decide	O
that	O
every	O
example	O
is	O
positive	O
and	O
would	O
stop	O
learning	O
anything	O
it	O
would	O
do	O
well	O
for	O
a	O
while	O
examples	B
until	O
it	O
hit	O
the	O
batch	B
of	O
negative	O
examples	B
then	O
it	O
would	O
take	O
a	O
while	O
ten	O
examples	B
before	O
it	O
would	O
start	O
predicting	O
everything	O
as	O
negative	O
by	O
the	O
end	O
of	O
one	O
pass	O
through	O
the	O
data	O
it	O
would	O
really	O
only	O
have	O
learned	O
from	O
a	O
handful	O
of	O
examples	B
in	O
this	O
case	O
so	O
one	O
thing	O
you	O
need	O
to	O
avoid	O
is	O
presenting	O
the	O
examples	B
in	O
some	O
fixed	O
order	O
this	O
can	O
easily	O
be	O
accomplished	O
by	O
permuting	O
the	O
order	O
of	O
examples	B
once	O
in	O
the	O
beginning	O
and	O
then	O
cycling	O
over	O
the	O
data	O
set	O
in	O
the	O
same	O
order	O
each	O
iteration	B
however	O
it	O
turns	O
out	O
that	O
you	O
can	O
actually	O
do	O
better	O
if	O
you	O
re-permute	O
the	O
examples	B
in	O
each	O
iteration	B
figure	O
shows	O
the	O
effect	O
of	O
re-permuting	O
on	O
convergence	O
speed	O
in	O
practice	O
permuting	O
each	O
iteration	B
tends	O
to	O
yield	O
about	O
savings	O
in	O
number	O
of	O
iterations	O
in	O
theory	O
you	O
can	O
actually	O
prove	O
that	O
it	O
s	O
expected	O
to	O
be	O
about	O
twice	O
as	O
fast	O
geometric	O
intrepretation	O
the	O
perceptron	B
figure	O
training	O
and	O
test	B
error	I
for	O
permuting	O
versus	O
not-permuting	O
if	O
permuting	O
the	O
data	O
each	O
iteration	B
saves	O
somewhere	O
between	O
and	O
of	O
your	O
time	O
are	O
there	O
any	O
cases	O
in	O
which	O
you	O
might	O
not	O
want	O
to	O
permute	O
the	O
data	O
every	O
iteration	B
a	O
question	O
you	O
should	O
be	O
asking	O
yourself	O
by	O
now	O
is	O
what	O
does	O
the	O
decision	B
boundary	I
of	O
a	O
perceptron	B
look	O
like	O
you	O
can	O
actually	O
answer	O
that	O
question	O
mathematically	O
for	O
a	O
perceptron	B
the	O
decision	B
boundary	I
is	O
precisely	O
where	O
the	O
sign	B
of	O
the	O
activation	O
a	O
changes	O
from	O
to	O
in	O
other	O
words	O
it	O
is	O
the	O
set	O
of	O
points	O
x	O
that	O
achieve	O
zero	O
activation	O
the	O
points	O
that	O
are	O
not	O
clearly	O
positive	O
nor	O
negative	O
for	O
simplicity	O
we	O
ll	O
first	O
consider	O
the	O
case	O
where	O
there	O
is	O
no	O
bias	B
term	O
equivalently	O
the	O
bias	B
is	O
zero	O
formally	O
the	O
decision	B
boundary	I
b	O
is	O
b	O
x	O
d	O
wdxd	O
we	O
can	O
now	O
apply	O
some	O
linear	O
algebra	O
recall	B
that	O
d	O
wdxd	O
is	O
just	O
the	O
dot	B
product	I
between	O
the	O
vector	B
w	O
and	O
the	O
vector	B
x	O
we	O
will	O
write	O
this	O
as	O
w	O
x	O
two	O
vectors	O
have	O
a	O
zero	O
dot	B
product	I
if	O
and	O
only	O
if	O
they	O
are	O
perpendicular	B
thus	O
if	O
we	O
think	O
of	O
the	O
weights	B
as	O
a	O
vector	B
w	O
then	O
the	O
decision	B
boundary	I
is	O
simply	O
the	O
plane	O
perpendicular	B
to	O
w	O
a	O
course	O
in	O
machine	O
learning	O
math	O
review	O
dot	O
products	O
dot	O
products	O
definition	O
perpendicular	B
normalization	O
and	O
projections	O
think	O
about	O
basis	O
vectors	O
for	O
projections	O
quadratic	O
rule	O
on	O
vectors	O
also	O
that	O
dot	O
products	O
onto	O
unit	O
vectors	O
are	O
maximized	O
when	O
they	O
point	O
in	O
the	O
same	O
direction	O
so	O
aa	O
ab	O
blah	O
blah	O
blah	O
figure	O
this	O
is	O
shown	O
pictorially	O
in	O
figure	O
here	O
the	O
weight	O
vector	B
is	O
shown	O
together	O
with	O
it	O
s	O
perpendicular	B
plane	O
this	O
plane	O
forms	O
the	O
decision	B
boundary	I
between	O
positive	O
points	O
and	O
negative	O
points	O
the	O
vector	B
points	O
in	O
the	O
direction	O
of	O
the	O
positive	O
examples	B
and	O
away	O
from	O
the	O
negative	O
examples	B
one	O
thing	O
to	O
notice	O
is	O
that	O
the	O
scale	O
of	O
the	O
weight	O
vector	B
is	O
irrele	O
vant	O
from	O
the	O
perspective	O
of	O
classification	O
suppose	O
you	O
take	O
a	O
weight	O
vector	B
w	O
and	O
replace	O
it	O
with	O
all	O
activations	B
are	O
now	O
doubled	O
but	O
their	O
sign	B
does	O
not	O
change	O
this	O
makes	O
complete	O
sense	O
geometrically	O
since	O
all	O
that	O
matters	O
is	O
which	O
side	O
of	O
the	O
plane	O
a	O
test	O
point	O
falls	O
on	O
now	O
how	O
far	O
it	O
is	O
from	O
that	O
plane	O
for	O
this	O
reason	O
it	O
is	O
common	O
to	O
work	O
with	O
normalized	O
weight	O
vectors	O
w	O
that	O
have	O
length	O
one	O
i	O
e	O
the	O
geometric	O
intuition	O
can	O
help	O
us	O
even	O
more	O
when	O
we	O
realize	O
that	O
dot	O
products	O
compute	O
projections	O
that	O
is	O
the	O
value	O
w	O
x	O
is	O
just	O
the	O
distance	B
of	O
x	O
from	O
the	O
origin	O
when	O
projected	O
onto	O
the	O
vector	B
w	O
this	O
is	O
shown	O
in	O
figure	O
in	O
that	O
figure	O
all	O
the	O
data	O
points	O
are	O
projected	O
onto	O
w	O
below	O
we	O
can	O
think	O
of	O
this	O
as	O
a	O
one-dimensional	O
version	O
of	O
the	O
data	O
where	O
each	O
data	O
point	O
is	O
placed	O
according	O
to	O
its	O
projection	O
along	O
w	O
this	O
distance	B
along	O
w	O
is	O
exactly	O
the	O
activiation	O
of	O
that	O
example	O
with	O
no	O
bias	B
from	O
here	O
you	O
can	O
start	O
thinking	O
about	O
the	O
role	O
of	O
the	O
bias	B
term	O
previously	O
the	O
threshold	B
would	O
be	O
at	O
zero	O
any	O
example	O
with	O
a	O
negative	O
projection	O
onto	O
w	O
would	O
be	O
classified	O
negative	O
any	O
example	O
with	O
a	O
positive	O
projection	O
positive	O
the	O
bias	B
simply	O
moves	O
this	O
threshold	B
now	O
after	O
the	O
projection	O
is	O
computed	O
b	O
is	O
added	O
to	O
get	O
the	O
overall	O
activation	O
the	O
projection	O
plus	O
b	O
is	O
then	O
compared	O
against	O
zero	O
thus	O
from	O
a	O
geometric	O
perspective	O
the	O
role	O
of	O
the	O
bias	B
is	O
to	O
shift	O
the	O
decision	B
boundary	I
away	O
from	O
the	O
origin	O
in	O
the	O
direction	O
of	O
w	O
it	O
is	O
shifted	O
exactly	O
b	O
units	O
so	O
if	O
b	O
is	O
positive	O
the	O
boundary	O
is	O
shifted	O
away	O
from	O
w	O
and	O
if	O
b	O
is	O
negative	O
the	O
boundary	O
is	O
shifted	O
toward	O
w	O
this	O
is	O
shown	O
in	O
figure	O
this	O
makes	O
intuitive	O
sense	O
a	O
positive	O
bias	B
means	O
that	O
more	O
examples	B
should	O
be	O
classified	O
positive	O
by	O
moving	O
the	O
decision	B
boundary	I
in	O
the	O
negative	O
direction	O
more	O
space	O
yields	O
a	O
figure	O
picture	O
of	O
data	O
points	O
with	O
hyperplane	B
and	O
weight	O
vector	B
if	O
i	O
give	O
you	O
an	O
arbitrary	O
non-zero	O
weight	O
vector	B
w	O
how	O
do	O
i	O
compute	O
a	O
weight	O
vector	B
that	O
points	O
in	O
the	O
same	O
direction	O
but	O
has	O
a	O
norm	O
of	O
one	O
figure	O
same	O
picture	O
as	O
before	O
but	O
with	O
projections	O
onto	O
weight	O
vector	B
todo	O
then	O
below	O
those	O
points	O
along	O
a	O
one-dimensional	O
axis	O
with	O
zero	O
marked	O
the	O
decision	B
boundary	I
for	O
a	O
perceptron	B
is	O
a	O
very	O
magical	O
thing	O
in	O
positive	O
classification	O
d	O
dimensional	O
space	O
it	O
is	O
always	O
a	O
d	O
hyperplane	B
two	O
dimensions	O
a	O
hyperplane	B
is	O
simply	O
a	O
line	O
in	O
three	O
dimensions	O
a	O
hyperplane	B
is	O
like	O
a	O
sheet	O
of	O
paper	O
this	O
hyperplane	B
divides	O
space	O
in	O
half	O
in	O
the	O
rest	O
of	O
this	O
book	O
we	O
ll	O
refer	O
to	O
the	O
weight	O
vector	B
and	O
to	O
hyperplane	B
it	O
defines	O
interchangeably	O
the	O
perceptron	B
update	O
can	O
also	O
be	O
considered	O
geometrically	O
simplicity	O
we	O
will	O
consider	O
the	O
unbiased	B
case	O
consider	O
the	O
situation	O
in	O
figure	O
here	O
we	O
have	O
a	O
current	O
guess	O
as	O
to	O
the	O
hyperplane	B
and	O
positive	O
training	O
example	O
comes	O
in	O
that	O
is	O
currently	O
misclassified	O
the	O
weights	B
are	O
updated	O
w	O
w	O
yx	O
this	O
yields	O
the	O
new	O
weight	O
vector	B
also	O
shown	O
in	O
the	O
figure	O
in	O
this	O
case	O
the	O
weight	O
vector	B
changed	O
enough	O
that	O
this	O
training	O
example	O
is	O
now	O
correctly	O
classified	O
interpreting	O
perceptron	B
weights	B
todo	O
perceptron	B
convergence	O
and	O
linear	O
separability	O
you	O
already	O
have	O
an	O
intuitive	O
feeling	O
for	O
why	O
the	O
perceptron	B
works	O
it	O
moves	O
the	O
decision	B
boundary	I
in	O
the	O
direction	O
of	O
the	O
training	O
examples	B
a	O
question	O
you	O
should	O
be	O
asking	O
yourself	O
is	O
does	O
the	O
perceptron	B
converge	O
if	O
so	O
what	O
does	O
it	O
converge	O
to	O
and	O
how	O
long	O
does	O
it	O
take	O
it	O
is	O
easy	O
to	O
construct	O
data	O
sets	O
on	O
which	O
the	O
perceptron	B
algorithm	B
will	O
never	O
converge	O
in	O
fact	O
consider	O
the	O
uninteresting	O
learning	O
problem	O
with	O
no	O
features	B
you	O
have	O
a	O
data	O
set	O
consisting	O
of	O
one	O
positive	O
example	O
and	O
one	O
negative	O
example	O
since	O
there	O
are	O
no	O
features	B
the	O
only	O
thing	O
the	O
perceptron	B
algorithm	B
will	O
ever	O
do	O
is	O
adjust	O
the	O
bias	B
given	O
this	O
data	O
you	O
can	O
run	O
the	O
perceptron	B
for	O
a	O
bajillion	O
iterations	O
and	O
it	O
will	O
never	O
settle	O
down	O
as	O
long	O
as	O
the	O
bias	B
is	O
nonnegative	O
the	O
negative	O
example	O
will	O
cause	O
it	O
to	O
decrease	O
as	O
long	O
as	O
it	O
is	O
non-positive	O
the	O
positive	O
example	O
will	O
cause	O
it	O
to	O
increase	O
ad	O
infinitum	O
this	O
is	O
a	O
very	O
contrived	O
example	O
what	O
does	O
it	O
mean	O
for	O
the	O
perceptron	B
to	O
converge	O
it	O
means	O
that	O
it	O
can	O
make	O
an	O
entire	O
pass	O
through	O
the	O
training	B
data	I
without	O
making	O
any	O
more	O
updates	O
in	O
other	O
words	O
it	O
has	O
correctly	O
classified	O
every	O
training	O
example	O
geometrically	O
this	O
means	O
that	O
it	O
was	O
found	O
some	O
hyperplane	B
that	O
correctly	O
segregates	O
the	O
data	O
into	O
positive	O
and	O
negative	O
examples	B
like	O
that	O
shown	O
in	O
figure	O
in	O
this	O
case	O
this	O
data	O
is	O
linearly	B
separable	I
this	O
means	O
that	O
there	O
the	O
perceptron	B
figure	O
perceptron	B
picture	O
with	O
update	O
no	O
bias	B
figure	O
separable	O
data	O
a	O
course	O
in	O
machine	O
learning	O
exists	O
some	O
hyperplane	B
that	O
puts	O
all	O
the	O
positive	O
examples	B
on	O
one	O
side	O
and	O
all	O
the	O
negative	O
examples	B
on	O
the	O
other	O
side	O
if	O
the	O
training	O
is	O
not	O
linearly	B
separable	I
like	O
that	O
shown	O
in	O
figure	O
then	O
the	O
perceptron	B
has	O
no	O
hope	O
of	O
converging	O
it	O
could	O
never	O
possibly	O
classify	O
each	O
point	O
correctly	O
the	O
somewhat	O
surprising	O
thing	O
about	O
the	O
perceptron	B
algorithm	B
is	O
that	O
if	O
the	O
data	O
is	O
linearly	B
separable	I
then	O
it	O
will	O
converge	O
to	O
a	O
weight	O
vector	B
that	O
separates	O
the	O
data	O
if	O
the	O
data	O
is	O
inseparable	O
then	O
it	O
will	O
never	O
converge	O
this	O
is	O
great	O
news	O
it	O
means	O
that	O
the	O
perceptron	B
converges	O
whenever	O
it	O
is	O
even	O
remotely	O
possible	O
to	O
converge	O
the	O
second	O
question	O
is	O
how	O
long	O
does	O
it	O
take	O
to	O
converge	O
by	O
how	O
long	O
what	O
we	O
really	O
mean	O
is	O
how	O
many	O
updates	O
as	O
is	O
the	O
case	O
for	O
much	O
learning	O
theory	O
you	O
will	O
not	O
be	O
able	O
to	O
get	O
an	O
answer	O
of	O
the	O
form	O
it	O
will	O
converge	O
after	O
updates	O
this	O
is	O
asking	O
too	O
much	O
the	O
sort	O
of	O
answer	O
we	O
can	O
hope	O
to	O
get	O
is	O
of	O
the	O
form	O
it	O
will	O
converge	O
after	O
at	O
most	O
updates	O
what	O
you	O
might	O
expect	O
to	O
see	O
is	O
that	O
the	O
perceptron	B
will	O
con	O
verge	O
more	O
quickly	O
for	O
easy	O
learning	O
problems	O
than	O
for	O
hard	O
learning	O
problems	O
this	O
certainly	O
fits	O
intuition	O
the	O
question	O
is	O
how	O
to	O
define	O
easy	O
and	O
hard	O
in	O
a	O
meaningful	O
way	O
one	O
way	O
to	O
make	O
this	O
definition	O
is	O
through	O
the	O
notion	O
of	O
margin	B
if	O
i	O
give	O
you	O
a	O
data	O
set	O
and	O
hyperplane	B
that	O
separates	O
it	O
that	O
shown	O
in	O
figure	O
then	O
the	O
margin	B
is	O
the	O
distance	B
between	O
the	O
hyperplane	B
and	O
the	O
nearest	O
point	O
intuitively	O
problems	O
with	O
large	O
margins	O
should	O
be	O
easy	O
s	O
lots	O
of	O
wiggle	O
room	O
to	O
find	O
a	O
separating	B
hyperplane	B
and	O
problems	O
with	O
small	O
margins	O
should	O
be	O
hard	O
really	O
have	O
to	O
get	O
a	O
very	O
specific	O
well	O
tuned	O
weight	O
vector	B
formally	O
given	O
a	O
data	O
set	O
d	O
a	O
weight	O
vector	B
w	O
and	O
bias	B
b	O
the	O
margin	B
of	O
w	O
b	O
on	O
d	O
is	O
defined	O
as	O
minxy	O
d	O
x	O
margind	O
w	O
b	O
if	O
w	O
separates	O
d	O
otherwise	O
in	O
words	O
the	O
margin	B
is	O
only	O
defined	O
if	O
w	O
b	O
actually	O
separate	O
the	O
data	O
it	O
is	O
just	O
in	O
the	O
case	O
that	O
it	O
separates	O
the	O
data	O
we	O
find	O
the	O
point	O
with	O
the	O
minimum	O
activation	O
after	O
the	O
activation	O
is	O
multiplied	O
by	O
the	O
label	B
for	O
some	O
historical	O
reason	O
is	O
unknown	O
to	O
the	O
author	O
margins	O
are	O
always	O
denoted	O
by	O
the	O
greek	O
letter	O
one	O
often	O
talks	O
about	O
the	O
margin	B
of	I
a	I
data	I
set	I
the	O
margin	B
of	I
a	I
data	I
set	I
is	O
the	O
largest	O
attainable	O
margin	B
on	O
this	O
data	O
formally	O
margind	O
sup	O
wb	O
margind	O
w	O
b	O
in	O
words	O
to	O
compute	O
the	O
margin	B
of	I
a	I
data	I
set	I
you	O
try	O
every	O
possible	O
w	O
b	O
pair	O
for	O
each	O
pair	O
you	O
compute	O
its	O
margin	B
we	O
then	O
take	O
the	O
so	O
long	O
as	O
the	O
margin	B
is	O
not	O
it	O
is	O
always	O
positive	O
geometrically	O
this	O
makes	O
sense	O
but	O
what	O
does	O
eq	O
yeild	O
this	O
the	O
perceptron	B
you	O
can	O
read	O
sup	O
as	O
max	O
if	O
you	O
like	O
the	O
only	O
difference	O
is	O
a	O
technical	O
difference	O
in	O
how	O
the	O
case	O
is	O
handled	O
rosenblatt	O
largest	O
of	O
these	O
as	O
the	O
overall	O
margin	B
of	O
the	O
if	O
the	O
data	O
is	O
not	O
linearly	B
separable	I
then	O
the	O
value	O
of	O
the	O
sup	O
and	O
therefore	O
the	O
value	O
of	O
the	O
margin	B
is	O
there	O
is	O
a	O
famous	O
theorem	O
due	O
to	O
that	O
shows	O
that	O
the	O
number	O
of	O
errors	O
that	O
the	O
perceptron	B
algorithm	B
makes	O
is	O
bounded	O
by	O
more	O
formally	O
theorem	O
convergence	O
theorem	O
suppose	O
the	O
perceptron	B
algorithm	B
is	O
run	O
on	O
a	O
linearly	B
separable	I
data	O
set	O
d	O
with	O
margin	B
assume	O
that	O
for	O
all	O
x	O
d	O
then	O
the	O
algorithm	B
will	O
converge	O
after	O
at	O
most	O
updates	O
todo	O
comment	O
on	O
norm	O
of	O
w	O
and	O
norm	O
of	O
x	O
also	O
some	O
picture	O
about	O
maximum	O
margins	O
the	O
proof	O
of	O
this	O
theorem	O
is	O
elementary	O
in	O
the	O
sense	O
that	O
it	O
does	O
not	O
use	O
any	O
fancy	O
tricks	O
it	O
s	O
all	O
just	O
algebra	O
the	O
idea	O
behind	O
the	O
proof	O
is	O
as	O
follows	O
if	O
the	O
data	O
is	O
linearly	B
separable	I
with	O
margin	B
then	O
there	O
exists	O
some	O
weight	O
vector	B
w	O
that	O
achieves	O
this	O
margin	B
obviously	O
we	O
don	O
t	O
know	O
what	O
w	O
is	O
but	O
we	O
know	O
it	O
exists	O
the	O
perceptron	B
algorithm	B
is	O
trying	O
to	O
find	O
a	O
weight	O
vector	B
w	O
that	O
points	O
roughly	O
in	O
the	O
same	O
direction	O
as	O
w	O
large	O
roughly	O
can	O
be	O
very	O
rough	O
for	O
small	O
roughly	O
is	O
quite	O
precise	O
every	O
time	O
the	O
perceptron	B
makes	O
an	O
update	O
the	O
angle	O
between	O
w	O
and	O
w	O
changes	O
what	O
we	O
prove	O
is	O
that	O
the	O
angle	O
actually	O
decreases	O
we	O
show	O
this	O
in	O
two	O
steps	O
first	O
the	O
dot	B
product	I
w	O
w	O
increases	O
a	O
lot	O
second	O
the	O
norm	O
does	O
not	O
increase	O
very	O
much	O
since	O
the	O
dot	B
product	I
is	O
increasing	O
but	O
w	O
isn	O
t	O
getting	O
too	O
long	O
the	O
angle	O
between	O
them	O
has	O
to	O
be	O
shrinking	O
the	O
rest	O
is	O
algebra	O
proof	O
of	O
theorem	O
the	O
margin	B
must	O
be	O
realized	O
by	O
some	O
set	O
of	O
parameters	O
say	O
x	O
suppose	O
we	O
train	O
a	O
perceptron	B
on	O
this	O
data	O
denote	O
by	O
the	O
initial	O
weight	O
vector	B
the	O
weight	O
vector	B
after	O
the	O
first	O
update	O
and	O
wk	O
the	O
weight	O
vector	B
after	O
the	O
kth	O
update	O
are	O
essentially	O
ignoring	O
data	O
points	O
on	O
which	O
the	O
perceptron	B
doesn	O
t	O
update	O
itself	O
first	O
we	O
will	O
show	O
that	O
w	O
wk	O
grows	O
quicky	O
as	O
a	O
function	O
of	O
k	O
second	O
we	O
will	O
show	O
does	O
not	O
grow	O
quickly	O
first	O
suppose	O
that	O
the	O
kth	O
update	O
happens	O
on	O
example	O
y	O
we	O
are	O
trying	O
to	O
show	O
that	O
wk	O
is	O
becoming	O
aligned	O
with	O
w	O
because	O
we	O
updated	O
know	O
that	O
this	O
example	O
was	O
misclassified	O
x	O
after	O
the	O
update	O
we	O
get	O
wk	O
yx	O
we	O
do	O
a	O
little	O
computation	O
w	O
wk	O
w	O
yx	O
w	O
yw	O
x	O
w	O
definition	O
of	O
wk	O
vector	B
algebra	O
w	O
has	O
margin	B
a	O
course	O
in	O
machine	O
learning	O
thus	O
every	O
time	O
wk	O
is	O
updated	O
its	O
projection	O
onto	O
w	O
incrases	O
by	O
at	O
least	O
therefore	O
w	O
wk	O
k	O
because	O
wk	O
is	O
getting	O
closer	O
to	O
w	O
not	O
just	O
because	O
it	O
s	O
getting	O
exceptionally	O
long	O
to	O
do	O
this	O
we	O
compute	O
the	O
norm	O
of	O
wk	O
next	O
we	O
need	O
to	O
show	O
that	O
the	O
increase	O
of	O
along	O
w	O
occurs	O
yx	O
x	O
definition	O
of	O
wk	O
quadratic	O
rule	O
on	O
vectors	O
assumption	O
on	O
and	O
a	O
thus	O
the	O
squared	O
norm	O
of	O
wk	O
increases	O
by	O
at	O
most	O
one	O
every	O
up	O
date	O
therefore	O
k	O
w	O
wk	O
putting	O
this	O
together	O
we	O
have	O
k	O
w	O
wk	O
k	O
now	O
we	O
put	O
together	O
the	O
two	O
things	O
we	O
have	O
learned	O
before	O
by	O
our	O
first	O
conclusion	O
we	O
know	O
w	O
wk	O
k	O
but	O
our	O
second	O
conclusion	O
k	O
finally	O
because	O
w	O
is	O
a	O
unit	O
vector	B
we	O
know	O
taking	O
the	O
left-most	O
and	O
right-most	O
terms	O
we	O
get	O
that	O
dividing	O
both	O
sides	O
by	O
k	O
we	O
get	O
k	O
this	O
means	O
that	O
once	O
we	O
ve	O
made	O
updates	O
we	O
cannot	O
make	O
any	O
more	O
k	O
k	O
and	O
therefore	O
k	O
it	O
is	O
important	O
to	O
keep	O
in	O
mind	O
what	O
this	O
proof	O
shows	O
and	O
what	O
it	O
does	O
not	O
show	O
it	O
shows	O
that	O
if	O
i	O
give	O
the	O
perceptron	B
data	O
that	O
is	O
linearly	B
separable	I
with	O
margin	B
then	O
the	O
perceptron	B
will	O
converge	O
to	O
a	O
solution	O
that	O
separates	O
the	O
data	O
and	O
it	O
will	O
converge	O
quickly	O
when	O
is	O
large	O
it	O
does	O
not	O
say	O
anything	O
about	O
the	O
solution	O
other	O
than	O
the	O
fact	O
that	O
it	O
separates	O
the	O
data	O
in	O
particular	O
the	O
proof	O
makes	O
use	O
of	O
the	O
maximum	O
margin	B
separator	O
but	O
the	O
perceptron	B
is	O
not	O
guaranteed	O
to	O
find	O
this	O
maximum	O
margin	B
separator	O
the	O
data	O
may	O
be	O
separable	O
with	O
margin	B
and	O
the	O
perceptron	B
might	O
still	O
find	O
a	O
separating	B
hyperplane	B
with	O
a	O
margin	B
of	O
only	O
later	O
chapter	O
we	O
will	O
see	O
algorithms	O
that	O
explicitly	O
try	O
to	O
find	O
the	O
maximum	O
margin	B
solution	O
improved	O
generalization	O
voting	B
and	O
averaging	O
in	O
the	O
beginning	O
of	O
this	O
chapter	O
there	O
was	O
a	O
comment	O
that	O
the	O
perceptron	B
works	O
amazingly	O
well	O
this	O
was	O
a	O
half-truth	O
the	O
vanilla	O
perhaps	O
we	O
don	O
t	O
want	O
to	O
assume	O
that	O
all	O
x	O
have	O
norm	O
at	O
most	O
if	O
they	O
have	O
all	O
have	O
norm	O
at	O
most	O
r	O
you	O
can	O
achieve	O
a	O
very	O
similar	O
bound	O
modify	O
the	O
perceptron	B
convergence	O
proof	O
to	O
handle	O
this	O
case	O
why	O
does	O
the	O
perceptron	B
convergence	O
bound	O
not	O
contradict	O
the	O
earlier	O
claim	O
that	O
poorly	O
ordered	O
data	O
points	O
all	O
positives	O
followed	O
by	O
all	O
negatives	O
will	O
cause	O
the	O
perceptron	B
to	O
take	O
an	O
astronomically	O
long	O
time	O
to	O
learn	O
the	O
perceptron	B
perceptron	B
algorithm	B
does	O
well	O
but	O
not	O
amazingly	O
well	O
in	O
order	O
to	O
make	O
it	O
more	O
competitive	O
with	O
other	O
learning	O
algorithms	O
you	O
need	O
to	O
modify	O
it	O
a	O
bit	O
to	O
get	O
better	O
generalization	O
the	O
key	O
issue	O
with	O
the	O
vanilla	O
perceptron	B
is	O
that	O
it	O
counts	O
later	O
points	O
more	O
than	O
it	O
counts	O
earlier	O
points	O
to	O
see	O
why	O
consider	O
a	O
data	O
set	O
with	O
examples	B
suppose	O
that	O
after	O
the	O
first	O
examples	B
the	O
perceptron	B
has	O
learned	O
a	O
really	O
good	O
classifier	O
it	O
s	O
so	O
good	O
that	O
it	O
goes	O
over	O
the	O
next	O
examples	B
without	O
making	O
any	O
updates	O
it	O
reaches	O
the	O
example	O
and	O
makes	O
an	O
error	O
it	O
updates	O
for	O
all	O
we	O
know	O
the	O
update	O
on	O
this	O
example	O
completely	O
ruines	O
the	O
weight	O
vector	B
that	O
has	O
done	O
so	O
well	O
on	O
of	O
the	O
data	O
what	O
we	O
would	O
like	O
is	O
for	O
weight	O
vectors	O
that	O
survive	O
a	O
long	O
time	O
to	O
get	O
more	O
say	O
than	O
weight	O
vectors	O
that	O
are	O
overthrown	O
quickly	O
one	O
way	O
to	O
achieve	O
this	O
is	O
by	O
voting	B
as	O
the	O
perceptron	B
learns	O
it	O
remembers	O
how	O
long	O
each	O
hyperplane	B
survives	O
at	O
test	O
time	O
each	O
hyperplane	B
encountered	O
during	O
training	O
votes	O
on	O
the	O
class	O
of	O
a	O
test	O
example	O
if	O
a	O
particular	O
hyperplane	B
survived	O
for	O
examples	B
then	O
it	O
gets	O
a	O
vote	B
of	O
if	O
it	O
only	O
survived	O
for	O
one	O
example	O
it	O
only	O
gets	O
a	O
vote	B
of	O
in	O
particular	O
let	O
bk	O
be	O
the	O
k	O
weight	O
vectors	O
encountered	O
during	O
training	O
and	O
ck	O
be	O
the	O
survival	O
times	O
for	O
each	O
of	O
these	O
weight	O
vectors	O
weight	O
vector	B
that	O
gets	O
immediately	O
updated	O
gets	O
c	O
one	O
that	O
survives	O
another	O
round	O
gets	O
c	O
and	O
so	O
on	O
then	O
the	O
prediction	O
on	O
a	O
test	O
point	O
is	O
k	O
wk	O
x	O
y	O
sign	B
cksign	O
this	O
algorithm	B
known	O
as	O
the	O
voted	B
perceptron	B
works	O
quite	O
well	O
in	O
practice	O
and	O
there	O
is	O
some	O
nice	O
theory	O
showing	O
that	O
it	O
is	O
guaranteed	O
to	O
generalize	B
better	O
than	O
the	O
vanilla	O
perceptron	B
unfortunately	O
it	O
is	O
also	O
completely	O
impractical	O
if	O
there	O
are	O
updates	O
made	O
during	O
perceptron	B
learning	O
the	O
voted	B
perceptron	B
requires	O
that	O
you	O
store	O
weight	O
vectors	O
together	O
with	O
their	O
counts	O
this	O
requires	O
an	O
absurd	O
amount	O
of	O
storage	O
and	O
makes	O
prediction	O
times	O
slower	O
than	O
the	O
vanilla	O
perceptron	B
a	O
much	O
more	O
practical	O
alternative	O
is	O
the	O
averaged	B
perceptron	B
the	O
idea	O
is	O
similar	O
you	O
maintain	O
a	O
collection	O
of	O
weight	O
vectors	O
and	O
survival	O
times	O
however	O
at	O
test	O
time	O
you	O
predict	B
according	O
to	O
the	O
average	O
weight	O
vector	B
rather	O
than	O
the	O
voting	B
in	O
particular	O
the	O
prediction	O
is	O
k	O
wk	O
x	O
y	O
sign	B
the	O
only	O
difference	O
between	O
the	O
voted	O
prediction	O
eq	O
and	O
the	O
the	O
training	O
algorithm	B
for	O
the	O
voted	B
perceptron	B
is	O
the	O
same	O
as	O
the	O
vanilla	O
perceptron	B
in	O
particular	O
in	O
line	O
of	O
algorithm	B
the	O
activation	O
on	O
a	O
training	O
example	O
is	O
computed	O
based	O
on	O
the	O
current	O
weight	O
vector	B
not	O
based	O
on	O
the	O
voted	O
prediction	O
why	O
a	O
course	O
in	O
machine	O
learning	O
algorithm	B
averagedperceptrontraind	O
maxiter	O
w	O
u	O
c	O
for	O
iter	O
maxiter	O
do	O
b	O
initialize	O
weights	B
and	O
bias	B
initialize	O
cached	O
weights	B
and	O
bias	B
initialize	O
example	O
counter	O
to	O
one	O
if	O
yw	O
x	O
b	O
then	O
for	O
all	O
d	O
do	O
w	O
w	O
y	O
x	O
b	O
b	O
y	O
u	O
u	O
y	O
c	O
x	O
y	O
c	O
end	O
if	O
c	O
c	O
end	O
for	O
end	O
for	O
return	O
w	O
c	O
u	O
b	O
c	O
update	O
weights	B
update	O
bias	B
update	O
cached	O
weights	B
update	O
cached	O
bias	B
increment	O
counter	O
regardless	O
of	O
update	O
return	O
averaged	O
weights	B
and	O
bias	B
averaged	O
prediction	O
eq	O
is	O
the	O
presense	O
of	O
the	O
interior	O
sign	B
operator	O
with	O
a	O
little	O
bit	O
of	O
algebra	O
we	O
can	O
rewrite	O
the	O
test-time	O
prediction	O
as	O
k	O
y	O
sign	B
ckwk	O
x	O
k	O
ckbk	O
the	O
advantage	O
of	O
the	O
averaged	B
perceptron	B
is	O
that	O
we	O
can	O
simply	O
maintain	O
a	O
running	O
sum	O
of	O
the	O
averaged	O
weight	O
vector	B
blue	O
term	O
and	O
averaged	O
bias	B
red	O
term	O
test-time	O
prediction	O
is	O
then	O
just	O
as	O
efficient	O
as	O
it	O
is	O
with	O
the	O
vanilla	O
perceptron	B
the	O
full	O
training	O
algorithm	B
for	O
the	O
averaged	B
perceptron	B
is	O
shown	O
in	O
algorithm	B
some	O
of	O
the	O
notation	O
is	O
changed	O
from	O
the	O
original	O
perceptron	B
namely	O
vector	B
operations	O
are	O
written	O
as	O
vector	B
operations	O
and	O
the	O
activation	O
computation	O
is	O
folded	O
into	O
the	O
error	O
checking	O
it	O
is	O
probably	O
not	O
immediately	O
apparent	O
from	O
algorithm	B
that	O
the	O
computation	O
unfolding	O
is	O
precisely	O
the	O
calculation	O
of	O
the	O
averaged	O
weights	B
and	O
bias	B
the	O
most	O
natural	O
implementation	O
would	O
be	O
to	O
keep	O
track	O
of	O
an	O
averaged	O
weight	O
vector	B
u	O
at	O
the	O
end	O
of	O
every	O
example	O
you	O
would	O
increase	O
u	O
u	O
w	O
similarly	O
for	O
the	O
bias	B
however	O
such	O
an	O
implementation	O
would	O
require	O
that	O
you	O
updated	O
the	O
averaged	O
vector	B
on	O
every	O
example	O
rather	O
than	O
just	O
on	O
the	O
examples	B
that	O
were	O
incorrectly	O
classified	O
since	O
we	O
hope	O
that	O
eventually	O
the	O
perceptron	B
learns	O
to	O
do	O
a	O
good	O
job	O
we	O
would	O
hope	O
that	O
it	O
will	O
not	O
make	O
updates	O
on	O
every	O
example	O
so	O
ideally	O
you	O
would	O
like	O
to	O
only	O
update	O
the	O
averaged	O
weight	O
vector	B
when	O
the	O
actual	O
weight	O
vector	B
changes	O
the	O
slightly	O
clever	O
computation	O
in	O
algorithm	B
achieves	O
this	O
the	O
averaged	B
perceptron	B
is	O
almost	O
always	O
better	O
than	O
the	O
per	O
by	O
writing	O
out	O
the	O
computation	O
of	O
the	O
averaged	O
weights	B
from	O
eq	O
as	O
a	O
telescoping	O
sum	O
derive	O
the	O
computation	O
from	O
algorithm	B
ceptron	O
in	O
the	O
sense	O
that	O
it	O
generalizes	O
better	O
to	O
test	B
data	I
however	O
that	O
does	O
not	O
free	O
you	O
from	O
having	O
to	O
do	O
early	B
stopping	I
it	O
will	O
eventually	O
overfit	O
figure	O
shows	O
the	O
performance	O
of	O
the	O
vanilla	O
perceptron	B
and	O
the	O
averaged	B
perceptron	B
on	O
the	O
same	O
data	O
set	O
with	O
both	O
training	O
and	O
test	O
performance	O
as	O
you	O
can	O
see	O
the	O
averaged	B
perceptron	B
does	O
generalize	B
better	O
but	O
it	O
also	O
does	O
begin	O
to	O
overfit	O
eventually	O
limitations	O
of	O
the	O
perceptron	B
although	O
the	O
perceptron	B
is	O
very	O
useful	O
it	O
is	O
fundamentally	O
limited	O
in	O
a	O
way	O
that	O
neither	O
decision	B
trees	I
nor	O
knn	O
are	O
its	O
limitation	O
is	O
that	O
its	O
decision	O
boundaries	O
can	O
only	O
be	O
linear	O
the	O
classic	O
way	O
of	O
showing	O
this	O
limitation	O
is	O
through	O
the	O
xor	O
problem	O
exclusive	O
or	O
the	O
xor	O
problem	O
is	O
shown	O
graphically	O
in	O
figure	O
it	O
consists	O
of	O
four	O
data	O
points	O
each	O
at	O
a	O
corner	O
of	O
the	O
unit	O
square	O
the	O
labels	O
for	O
these	O
points	O
are	O
the	O
same	O
along	O
the	O
diagonals	O
you	O
can	O
try	O
but	O
you	O
will	O
not	O
be	O
able	O
to	O
find	O
a	O
linear	B
decision	B
boundary	I
that	O
perfectly	O
separates	O
these	O
data	O
points	O
one	O
question	O
you	O
might	O
ask	O
is	O
do	O
xor-like	O
problems	O
exist	O
in	O
the	O
real	O
world	O
unfortunately	O
for	O
the	O
perceptron	B
the	O
answer	O
is	O
yes	O
consider	O
a	O
sentiment	O
classification	O
problem	O
that	O
has	O
three	O
features	B
that	O
simply	O
say	O
whether	O
a	O
given	O
word	O
is	O
contained	O
in	O
a	O
review	O
of	O
a	O
course	O
these	O
features	B
are	O
excellent	O
terrible	O
and	O
not	O
the	O
excellent	O
feature	O
is	O
indicative	O
of	O
positive	O
reviews	O
and	O
the	O
terrible	O
feature	O
is	O
indicative	O
of	O
negative	O
reviews	O
but	O
in	O
the	O
presence	O
of	O
the	O
not	O
feature	O
this	O
categorization	O
flips	O
one	O
way	O
to	O
address	O
this	O
problem	O
is	O
by	O
adding	O
feature	B
combinations	I
we	O
could	O
add	O
two	O
additional	O
features	B
excellent-and-not	O
and	O
terrible-and-not	O
that	O
indicate	O
a	O
conjunction	O
of	O
these	O
base	O
features	B
by	O
assigning	O
weights	B
as	O
follows	O
you	O
can	O
achieve	O
the	O
desired	O
effect	O
wexecellent	O
wexecllent-and-not	O
wterrible	O
wterrible-and-not	O
wnot	O
in	O
this	O
particular	O
case	O
we	O
have	O
addressed	O
the	O
problem	O
however	O
if	O
we	O
start	O
with	O
d-many	O
features	B
if	O
we	O
want	O
to	O
add	O
all	B
pairs	I
we	O
ll	O
blow	O
features	B
through	O
this	O
feature	B
mapping	I
and	O
up	O
to	O
there	O
s	O
no	O
guarantee	O
that	O
pairs	O
of	O
features	B
is	O
enough	O
we	O
might	O
need	O
features	B
these	O
triples	O
of	O
features	B
and	O
now	O
we	O
re	O
up	O
to	O
additional	O
features	B
will	O
drastically	O
increase	O
computation	O
and	O
will	O
often	O
result	O
in	O
a	O
stronger	O
propensity	O
to	O
overfitting	B
in	O
fact	O
the	O
xor	O
problem	O
is	O
so	O
significant	O
that	O
it	O
basically	O
killed	O
research	O
in	O
classifiers	O
with	O
linear	O
decision	O
boundaries	O
for	O
a	O
decade	O
the	O
perceptron	B
figure	O
picture	O
of	O
xor	O
problem	O
suppose	O
that	O
you	O
took	O
the	O
xor	O
problem	O
and	O
added	O
one	O
new	O
feature	O
logical	O
and	O
of	O
the	O
two	O
existing	O
features	B
write	O
out	O
feature	O
weights	B
and	O
a	O
bias	B
that	O
would	O
achieve	O
perfect	O
classification	O
on	O
this	O
data	O
a	O
course	O
in	O
machine	O
learning	O
or	O
two	O
later	O
in	O
this	O
book	O
we	O
will	O
see	O
two	O
alternative	O
approaches	O
to	O
taking	O
key	O
ideas	O
from	O
the	O
perceptron	B
and	O
generating	O
classifiers	O
with	O
non-linear	B
decision	O
boundaries	O
one	O
approach	O
is	O
to	O
combine	O
multiple	O
perceptrons	O
in	O
a	O
single	O
framework	O
this	O
is	O
the	O
neural	B
networks	I
approach	O
chapter	O
the	O
second	O
approach	O
is	O
to	O
find	O
computationally	O
efficient	O
ways	O
of	O
doing	O
feature	B
mapping	I
in	O
a	O
computationally	O
and	O
statistically	O
efficient	O
way	O
this	O
is	O
the	O
kernels	B
approach	O
chapter	O
exercises	O
exercise	O
todo	O
practical	O
issues	O
learning	O
objectives	O
translate	O
between	O
a	O
problem	O
description	O
and	O
a	O
concrete	O
learning	O
problem	O
perform	O
basic	O
feature	O
engineering	O
on	O
image	O
and	O
text	O
data	O
explain	O
how	O
to	O
use	O
cross-validation	O
to	O
tune	O
hyperparameters	O
and	O
estimate	O
future	O
performance	O
compare	O
and	O
contrast	O
the	O
differences	O
between	O
several	O
evaluation	O
metrics	O
explain	O
why	O
feature	B
combinations	I
are	O
important	O
for	O
learning	O
with	O
some	O
models	O
but	O
not	O
others	O
explain	O
the	O
relationship	O
between	O
the	O
three	O
learning	O
techniques	O
you	O
have	O
seen	O
so	O
far	O
apply	O
several	O
debugging	O
techniques	O
to	O
learning	O
algorithms	O
dependencies	O
chapter	O
in	O
theory	O
there	O
is	O
no	O
difference	O
between	O
theory	O
and	O
practice	O
but	O
in	O
practice	O
there	O
is	O
jan	O
l	O
a	O
van	O
de	O
snepscheut	O
todo	O
one	O
two	O
two	O
examples	B
per	O
feature	O
at	O
this	O
point	O
you	O
have	O
seen	O
three	O
qualitatively	O
different	O
models	O
for	O
learning	O
decision	B
trees	I
nearest	O
neighbors	O
and	O
perceptrons	O
you	O
have	O
also	O
learned	O
about	O
clustering	B
with	O
the	O
k-means	O
algorithm	B
you	O
will	O
shortly	O
learn	O
about	O
more	O
complex	O
models	O
most	O
of	O
which	O
are	O
variants	O
on	O
things	O
you	O
already	O
know	O
however	O
before	O
attempting	O
to	O
understand	O
more	O
complex	O
models	O
of	O
learning	O
it	O
is	O
important	O
to	O
have	O
a	O
firm	O
grasp	O
on	O
how	O
to	O
use	O
machine	O
learning	O
in	O
practice	O
this	O
chapter	O
is	O
all	O
about	O
how	O
to	O
go	O
from	O
an	O
abstract	O
learning	O
problem	O
to	O
a	O
concrete	O
implementation	O
you	O
will	O
see	O
some	O
examples	B
of	O
best	O
practices	O
along	O
with	O
justifications	O
of	O
these	O
practices	O
in	O
many	O
ways	O
going	O
from	O
an	O
abstract	O
problem	O
to	O
a	O
concrete	O
learn	O
ing	O
task	O
is	O
more	O
of	O
an	O
art	O
than	O
a	O
science	O
however	O
this	O
art	O
can	O
have	O
a	O
huge	O
impact	O
on	O
the	O
practical	O
performance	O
of	O
learning	O
systems	O
in	O
many	O
cases	O
moving	O
to	O
a	O
more	O
complicated	O
learning	O
algorithm	B
will	O
gain	O
you	O
a	O
few	O
percent	O
improvement	O
going	O
to	O
a	O
better	O
representation	O
will	O
gain	O
you	O
an	O
order	O
of	O
magnitude	O
improvement	O
to	O
this	O
end	O
we	O
will	O
discuss	O
several	O
high	O
level	O
ideas	O
to	O
help	O
you	O
develop	O
a	O
better	O
artistic	O
sensibility	O
the	O
importance	O
of	O
good	O
features	B
machine	O
learning	O
is	O
magical	O
you	O
give	O
it	O
data	O
and	O
it	O
manages	O
to	O
classify	O
that	O
data	O
for	O
many	O
it	O
can	O
actually	O
outperform	O
a	O
human	O
but	O
like	O
so	O
many	O
problems	O
in	O
the	O
world	O
there	O
is	O
a	O
significant	O
garbage	O
in	O
garbage	O
out	O
aspect	O
to	O
machine	O
learning	O
if	O
the	O
data	O
you	O
give	O
it	O
is	O
trash	O
the	O
learning	O
algorithm	B
is	O
unlikely	O
to	O
be	O
able	O
to	O
overcome	O
it	O
with	O
a	O
pixel	O
image	O
a	O
very	O
easy	O
feature	O
representation	O
of	O
this	O
image	O
is	O
as	O
a	O
dimensional	O
vector	B
where	O
each	O
dimension	O
corresponds	O
to	O
the	O
red	O
green	O
or	O
blue	O
component	O
of	O
some	O
pixel	O
in	O
the	O
image	O
so	O
perhaps	O
feature	O
is	O
the	O
amount	O
of	O
red	O
in	O
pixel	O
feature	O
is	O
the	O
amount	O
of	O
green	O
in	O
that	O
pixel	O
and	O
so	O
on	O
this	O
is	O
the	O
consider	O
a	O
problem	O
of	O
object	O
recognition	O
from	O
images	O
if	O
you	O
start	O
a	O
course	O
in	O
machine	O
learning	O
pixel	B
representation	I
of	O
images	O
one	O
thing	O
to	O
keep	O
in	O
mind	O
is	O
that	O
the	O
pixel	B
representation	I
throws	O
away	O
all	O
locality	O
information	O
in	O
the	O
image	O
learning	O
algorithms	O
don	O
t	O
care	O
about	O
features	B
they	O
only	O
care	O
about	O
feature	B
values	I
so	O
i	O
can	O
permute	O
all	O
of	O
the	O
features	B
with	O
no	O
effect	O
on	O
the	O
learning	O
algorithm	B
long	O
as	O
i	O
apply	O
the	O
same	O
permutation	O
to	O
all	O
training	O
and	O
test	O
examples	B
figure	O
shows	O
some	O
images	O
whos	O
pixels	O
have	O
been	O
randomly	O
permuted	O
this	O
case	O
only	O
the	O
pixels	O
are	O
permuted	O
not	O
the	O
colors	O
all	O
of	O
these	O
objects	O
are	O
things	O
that	O
you	O
ve	O
seen	O
plenty	O
of	O
examples	B
of	O
can	O
you	O
identify	O
them	O
should	O
you	O
expect	O
a	O
machine	O
to	O
be	O
able	O
to	O
an	O
alternative	O
representation	O
of	O
images	O
is	O
the	O
patch	O
represen	O
tation	O
where	O
the	O
unit	O
of	O
interest	O
is	O
a	O
small	O
rectangular	O
block	O
of	O
an	O
image	O
rather	O
than	O
a	O
single	O
pixel	O
again	O
permuting	O
the	O
patches	O
has	O
no	O
effect	O
on	O
the	O
classifier	O
figure	O
shows	O
the	O
same	O
images	O
in	O
patch	B
representation	I
can	O
you	O
identify	O
them	O
a	O
final	O
representation	O
is	O
a	O
shape	B
representation	I
here	O
we	O
throw	O
out	O
all	O
color	O
and	O
pixel	O
information	O
and	O
simply	O
provide	O
a	O
bounding	O
polygon	O
figure	O
shows	O
the	O
same	O
images	O
in	O
this	O
representation	O
is	O
this	O
now	O
enough	O
to	O
identify	O
them	O
not	O
you	O
can	O
find	O
the	O
answers	O
at	O
the	O
end	O
of	O
this	O
chapter	O
in	O
the	O
context	O
of	O
text	B
categorization	I
instance	O
the	O
sentiment	O
recognition	O
task	O
one	O
standard	O
representation	O
is	O
the	O
bag	B
of	I
words	I
representation	O
here	O
we	O
have	O
one	O
feature	O
for	O
each	O
unique	O
word	O
that	O
appears	O
in	O
a	O
document	O
for	O
the	O
feature	O
happy	O
the	O
feature	O
value	O
is	O
the	O
number	O
of	O
times	O
that	O
the	O
word	O
happy	O
appears	O
in	O
the	O
document	O
the	O
bag	B
of	I
words	I
representation	O
throws	O
away	O
all	O
position	O
information	O
figure	O
shows	O
a	O
bow	O
representation	O
for	O
two	O
documents	O
one	O
positive	O
and	O
one	O
negative	O
can	O
you	O
tell	O
which	O
is	O
which	O
irrelevant	O
and	O
redundant	B
features	B
one	O
big	O
difference	O
between	O
learning	O
models	O
is	O
how	O
robust	O
they	O
are	O
to	O
the	O
addition	O
of	O
noisy	O
or	O
irrelevant	O
features	B
intuitively	O
an	O
irrelevant	O
feature	O
is	O
one	O
that	O
is	O
completely	O
uncorrelated	O
with	O
the	O
prediction	O
task	O
a	O
feature	O
f	O
whose	O
expectation	O
does	O
not	O
depend	O
on	O
the	O
label	B
e	O
f	O
y	O
e	O
f	O
might	O
be	O
irrelevant	O
for	O
instance	O
the	O
presence	O
of	O
the	O
word	O
the	O
might	O
be	O
largely	O
irrelevant	O
for	O
predicting	O
whether	O
a	O
course	O
review	O
is	O
positive	O
or	O
negative	O
a	O
secondary	O
issue	O
is	O
how	O
well	O
these	O
algorithms	O
deal	O
with	O
redun	O
dant	O
features	B
two	O
features	B
are	O
redundant	O
if	O
they	O
are	O
highly	O
correlated	O
regardless	O
of	O
whether	O
they	O
are	O
correlated	O
with	O
the	O
task	O
or	O
not	O
for	O
example	O
having	O
a	O
bright	O
red	O
pixel	O
in	O
an	O
image	O
at	O
position	O
is	O
probably	O
highly	O
redundant	O
with	O
having	O
a	O
bright	O
red	O
pixel	O
figure	O
pracimagepix	O
object	O
recognition	O
in	O
pixels	O
figure	O
pracimagepatch	O
object	O
recognition	O
in	O
patches	O
figure	O
pracimageshape	O
object	O
recognition	O
in	O
shapes	O
figure	O
pracbow	O
bow	O
repr	O
of	O
one	O
positive	O
and	O
one	O
negative	O
review	O
is	O
it	O
possible	O
to	O
have	O
a	O
feature	O
f	O
practical	O
issues	O
you	O
might	O
think	O
it	O
s	O
crazy	O
to	O
have	O
so	O
many	O
irrelevant	O
features	B
but	O
the	O
cases	O
you	O
ve	O
seen	O
so	O
far	O
of	O
words	O
bag	O
of	O
pixels	O
are	O
both	O
reasonable	O
examples	B
of	O
this	O
how	O
many	O
words	O
out	O
of	O
the	O
entire	O
english	O
vocabulary	O
words	O
are	O
actually	O
useful	O
for	O
predicting	O
positive	O
and	O
negative	O
course	O
reviews	O
at	O
position	O
both	O
might	O
be	O
useful	O
for	O
identifying	O
fire	O
hydrants	O
but	O
because	O
of	O
how	O
images	O
are	O
structured	O
these	O
two	O
features	B
are	O
likely	O
to	O
co-occur	O
frequently	O
when	O
thinking	O
about	O
robustness	O
to	O
irrelevant	O
or	O
redundant	O
fea	O
tures	O
it	O
is	O
usually	O
not	O
worthwhile	O
thinking	O
of	O
the	O
case	O
where	O
one	O
has	O
great	O
features	B
and	O
bad	O
feature	O
the	O
interesting	O
case	O
is	O
when	O
the	O
bad	O
features	B
outnumber	O
the	O
good	O
features	B
and	O
often	O
outnumber	O
by	O
a	O
large	O
degree	O
for	O
instance	O
perhaps	O
the	O
number	O
of	O
good	O
features	B
is	O
something	O
like	O
log	O
d	O
out	O
of	O
a	O
set	O
of	O
d	O
total	O
features	B
the	O
question	O
is	O
how	O
robust	O
are	O
algorithms	O
in	O
this	O
for	O
shallow	O
decision	B
trees	I
the	O
model	B
explicitly	O
selects	O
features	B
that	O
are	O
highly	O
correlated	O
with	O
the	O
label	B
in	O
particular	O
by	O
limiting	O
the	O
depth	O
of	O
the	O
decision	B
tree	I
one	O
can	O
at	O
least	O
hope	O
that	O
the	O
model	B
will	O
be	O
able	O
to	O
throw	O
away	O
irrelevant	O
features	B
redundant	B
features	B
are	O
almost	O
certainly	O
thrown	O
out	O
once	O
you	O
select	O
one	O
feature	O
the	O
second	O
feature	O
now	O
looks	O
mostly	O
useless	O
the	O
only	O
possible	O
issue	O
with	O
irrelevant	O
features	B
is	O
that	O
even	O
though	O
they	O
re	O
irrelevant	O
they	O
happen	O
to	O
correlate	O
with	O
the	O
class	O
label	B
on	O
the	O
training	B
data	I
but	O
chance	O
as	O
a	O
thought	O
experiment	O
suppose	O
that	O
we	O
have	O
n	O
training	O
ex	O
amples	O
and	O
exactly	O
half	O
are	O
positive	O
examples	B
and	O
half	O
are	O
negative	O
examples	B
suppose	O
there	O
s	O
some	O
binary	O
feature	O
f	O
that	O
is	O
completely	O
uncorrelated	O
with	O
the	O
label	B
this	O
feature	O
has	O
a	O
chance	O
of	O
appearing	O
in	O
any	O
example	O
regardless	O
of	O
the	O
label	B
in	O
principle	O
the	O
decision	B
tree	I
should	O
not	O
select	O
this	O
feature	O
but	O
by	O
chance	O
especially	O
if	O
n	O
is	O
small	O
the	O
feature	O
might	O
look	O
correlated	O
with	O
the	O
label	B
this	O
is	O
analogous	O
to	O
flipping	O
two	O
coins	O
simultaneously	O
n	O
times	O
even	O
though	O
the	O
coins	O
are	O
independent	O
it	O
s	O
entirely	O
possible	O
that	O
you	O
will	O
observe	O
a	O
sequence	O
like	O
h	O
t	O
h	O
h	O
which	O
makes	O
them	O
look	O
entirely	O
correlated	O
the	O
hope	O
is	O
that	O
as	O
n	O
grows	O
this	O
becomes	O
less	O
and	O
less	O
likely	O
in	O
fact	O
we	O
can	O
explicitly	O
compute	O
how	O
likely	O
this	O
is	O
to	O
happen	O
to	O
do	O
this	O
let	O
s	O
fix	O
the	O
sequence	O
of	O
n	O
labels	O
we	O
now	O
flip	O
a	O
coin	O
n	O
times	O
and	O
consider	O
how	O
likely	O
it	O
is	O
that	O
it	O
exactly	O
matches	O
the	O
label	B
this	O
is	O
easy	O
the	O
probability	O
is	O
now	O
we	O
would	O
also	O
be	O
confused	O
if	O
it	O
exactly	O
matched	O
not	O
the	O
label	B
which	O
has	O
the	O
same	O
probability	O
so	O
the	O
chance	O
that	O
it	O
looks	O
perfectly	O
correlated	O
is	O
thankfully	O
this	O
shrinks	O
down	O
very	O
small	O
after	O
only	O
data	O
points	O
this	O
makes	O
us	O
happy	O
the	O
problem	O
is	O
that	O
we	O
don	O
t	O
have	O
one	O
irrelevant	O
feature	O
we	O
have	O
d	O
log	O
d	O
irrelevant	O
features	B
if	O
we	O
randomly	O
pick	O
two	O
irrelevant	O
feature	B
values	I
each	O
has	O
the	O
same	O
probability	O
of	O
perfectly	O
correlating	O
but	O
since	O
there	O
are	O
two	O
and	O
they	O
re	O
independent	O
coins	O
the	O
chance	O
that	O
either	O
correlates	O
perfectly	O
is	O
in	O
general	O
if	O
we	O
have	O
k	O
irrelevant	O
features	B
all	O
a	O
course	O
in	O
machine	O
learning	O
of	O
which	O
are	O
random	O
independent	O
coins	O
the	O
chance	O
that	O
at	O
least	O
one	O
of	O
them	O
perfectly	O
correlates	O
is	O
k	O
this	O
suggests	O
that	O
if	O
we	O
have	O
a	O
sizeable	O
number	O
k	O
of	O
irrelevant	O
features	B
we	O
d	O
better	O
have	O
at	O
least	O
k	O
training	O
examples	B
unfortunately	O
the	O
situation	O
is	O
actually	O
worse	O
than	O
this	O
in	O
the	O
above	O
analysis	O
we	O
only	O
considered	O
the	O
case	O
of	O
perfect	O
correlation	O
we	O
could	O
also	O
consider	O
the	O
case	O
of	O
partial	O
correlation	O
which	O
would	O
yield	O
even	O
higher	O
probabilities	O
is	O
left	O
as	O
exercise	O
for	O
those	O
who	O
want	O
some	O
practice	O
with	O
probabilistic	O
analysis	O
suffice	O
it	O
to	O
say	O
that	O
even	O
decision	B
trees	I
can	O
become	O
confused	O
in	O
the	O
case	O
of	O
k-nearest	B
neighbors	I
the	O
situation	O
is	O
perhaps	O
more	O
dire	O
since	O
knn	O
weighs	O
each	O
feature	O
just	O
as	O
much	O
as	O
another	O
feature	O
the	O
introduction	O
of	O
irrelevant	O
features	B
can	O
completely	O
mess	O
up	O
knn	O
prediction	O
in	O
fact	O
as	O
you	O
saw	O
in	O
high	O
dimensional	O
space	O
randomly	O
distributed	O
points	O
all	O
look	O
approximately	O
the	O
same	O
distance	B
apart	O
if	O
we	O
add	O
lots	O
and	O
lots	O
of	O
randomly	O
distributed	O
features	B
to	O
a	O
data	O
set	O
then	O
all	O
distances	O
still	O
converge	O
this	O
is	O
shown	O
experimentally	O
in	O
figure	O
where	O
we	O
start	O
with	O
the	O
digit	O
categorization	O
data	O
and	O
continually	O
add	O
irrelevant	O
uniformly	O
distributed	O
features	B
and	O
generate	O
a	O
histogram	B
of	O
distances	O
eventually	O
all	O
distances	O
converge	O
in	O
the	O
case	O
of	O
the	O
perceptron	B
one	O
can	O
hope	O
that	O
it	O
might	O
learn	O
to	O
assign	O
zero	O
weight	O
to	O
irrelevant	O
features	B
for	O
instance	O
consider	O
a	O
binary	O
feature	O
is	O
randomly	O
one	O
or	O
zero	O
independent	O
of	O
the	O
label	B
if	O
the	O
perceptron	B
makes	O
just	O
as	O
many	O
updates	O
for	O
positive	O
examples	B
as	O
for	O
negative	O
examples	B
there	O
is	O
a	O
reasonable	O
chance	O
this	O
feature	O
weight	O
will	O
be	O
zero	O
at	O
the	O
very	O
least	O
it	O
should	O
be	O
small	O
to	O
get	O
a	O
better	O
practical	O
sense	O
of	O
how	O
sensitive	O
these	O
algorithms	O
are	O
to	O
irrelevant	O
features	B
figure	O
shows	O
the	O
test	O
performance	O
of	O
the	O
three	O
algorithms	O
with	O
an	O
increasing	O
number	O
of	O
compltely	O
noisy	O
features	B
in	O
all	O
cases	O
the	O
hyperparameters	O
were	O
tuned	O
on	O
validation	B
data	I
todo	O
feature	O
pruning	O
and	O
normalization	O
in	O
text	B
categorization	I
problems	O
some	O
words	O
simply	O
do	O
not	O
appear	O
very	O
often	O
perhaps	O
the	O
word	O
groovy	O
appears	O
in	O
exactly	O
one	O
training	O
document	O
which	O
is	O
positive	O
is	O
it	O
really	O
worth	O
keeping	O
this	O
word	O
around	O
as	O
a	O
feature	O
it	O
s	O
a	O
dangerous	O
endeavor	O
because	O
it	O
s	O
hard	O
to	O
tell	O
with	O
just	O
one	O
training	O
example	O
if	O
it	O
is	O
really	O
correlated	O
with	O
the	O
positive	O
class	O
or	O
is	O
it	O
just	O
noise	B
you	O
could	O
hope	O
that	O
your	O
learning	O
algorithm	B
is	O
smart	O
enough	O
to	O
figure	O
it	O
out	O
or	O
you	O
could	O
just	O
remove	O
it	O
that	O
means	O
that	O
the	O
learning	O
algorithm	B
won	O
t	O
have	O
to	O
figure	O
it	O
out	O
and	O
you	O
ve	O
reduced	O
the	O
number	O
of	O
dimensions	O
you	O
have	O
so	O
things	O
should	O
be	O
more	O
efficient	O
and	O
less	O
scary	O
figure	O
pracaddirel	O
data	O
from	O
high	O
dimensional	O
warning	O
interpolated	O
what	O
happens	O
with	O
the	O
perceptron	B
with	O
truly	O
redundant	B
features	B
one	O
is	O
literally	O
a	O
copy	O
of	O
the	O
other	O
figure	O
pracnoisy	O
dtknnperc	O
on	O
increasing	O
amounts	O
of	O
noise	B
this	O
is	O
typically	O
positive	O
indicator	O
or	O
at	O
least	O
it	O
was	O
back	O
in	O
the	O
us	O
in	O
the	O
practical	O
issues	O
figure	O
according	O
to	O
google	O
the	O
following	O
words	O
many	O
others	O
appear	O
times	O
on	O
the	O
web	O
moudlings	O
agaggagctg	O
setgravity	O
rogov	O
prosomeric	O
spunlaid	O
piyushtwok	O
telelesson	O
nesmysl	O
brighnasa	O
for	O
comparison	O
the	O
word	O
the	O
appears	O
billion	O
times	O
figure	O
pracvariance	O
effect	O
of	O
pruning	O
on	O
vision	O
earlier	O
we	O
discussed	O
the	O
problem	O
of	O
scale	O
of	O
features	B
millimeters	O
versus	O
centimeters	O
does	O
this	O
have	O
an	O
impact	O
on	O
variance-based	O
feature	O
pruning	O
math	O
review	O
data	O
statistics	O
means	O
and	O
variances	O
data	O
mean	O
variance	B
moments	O
expectations	O
etc	O
this	O
idea	O
of	O
feature	O
pruning	O
is	O
very	O
useful	O
and	O
applied	O
in	O
many	O
applications	O
it	O
is	O
easiest	O
in	O
the	O
case	O
of	O
binary	B
features	B
if	O
a	O
binary	O
feature	O
only	O
appears	O
some	O
small	O
number	O
k	O
times	O
the	O
training	B
data	I
no	O
fair	O
looking	O
at	O
the	O
test	B
data	I
you	O
simply	O
remove	O
it	O
from	O
consideration	O
might	O
also	O
want	O
to	O
remove	O
features	B
that	O
appear	O
in	O
all-but-k	O
many	O
documents	O
for	O
instance	O
the	O
word	O
the	O
appears	O
in	O
pretty	O
much	O
every	O
english	O
document	O
ever	O
written	O
typical	O
choices	O
for	O
k	O
are	O
mostly	O
depending	O
on	O
the	O
size	O
of	O
the	O
data	O
on	O
a	O
text	O
data	O
set	O
with	O
documents	O
a	O
cutoff	O
of	O
is	O
probably	O
reasonable	O
on	O
a	O
text	O
data	O
set	O
the	O
size	O
of	O
the	O
web	O
a	O
cut	O
of	O
of	O
or	O
even	O
or	O
is	O
probably	O
figure	O
shows	O
the	O
effect	O
of	O
pruning	O
on	O
a	O
sentiment	O
analysis	O
task	O
in	O
the	O
beginning	O
pruning	O
does	O
not	O
hurt	O
sometimes	O
helps	O
but	O
eventually	O
we	O
prune	O
away	O
all	O
the	O
interesting	O
words	O
and	O
performance	O
suffers	O
in	O
the	O
case	O
of	O
real-valued	O
features	B
the	O
question	O
is	O
how	O
to	O
extend	O
the	O
idea	O
of	O
does	O
not	O
occur	O
much	O
to	O
real	O
values	O
a	O
reasonable	O
definition	O
is	O
to	O
look	O
for	O
features	B
with	O
low	O
variance	B
in	O
fact	O
for	O
binary	B
features	B
ones	O
that	O
almost	O
never	O
appear	O
or	O
almost	O
always	O
appear	O
will	O
also	O
have	O
low	O
variance	B
figure	O
shows	O
the	O
result	O
of	O
pruning	O
lowvariance	O
features	B
on	O
the	O
digit	O
recognition	O
task	O
again	O
at	O
first	O
pruning	O
does	O
not	O
hurt	O
sometimes	O
helps	O
but	O
eventually	O
we	O
have	O
thrown	O
out	O
all	O
the	O
useful	O
features	B
once	O
you	O
have	O
pruned	O
away	O
irrelevant	O
features	B
it	O
is	O
often	O
useful	O
to	O
normalize	B
the	O
data	O
so	O
that	O
it	O
is	O
consistent	O
in	O
some	O
way	O
there	O
are	O
two	O
basic	O
types	O
of	O
normalization	O
feature	B
normalization	I
and	O
example	B
normalization	I
in	O
feature	B
normalization	I
you	O
go	O
through	O
each	O
feature	O
and	O
adjust	O
it	O
the	O
same	O
way	O
across	O
all	O
examples	B
in	O
example	B
normalization	I
each	O
example	O
is	O
adjusted	O
individually	O
the	O
goal	O
of	O
both	O
types	O
of	O
normalization	O
is	O
to	O
make	O
it	O
easier	O
for	O
your	O
learning	O
algorithm	B
to	O
learn	O
in	O
feature	B
normalization	I
there	O
are	O
two	O
standard	O
things	O
to	O
do	O
centering	O
moving	O
the	O
entire	O
data	O
set	O
so	O
that	O
it	O
is	O
centered	O
around	O
the	O
origin	O
scaling	O
rescaling	O
each	O
feature	O
so	O
that	O
one	O
of	O
the	O
following	O
holds	O
each	O
feature	O
has	O
variance	B
across	O
the	O
training	B
data	I
each	O
feature	O
has	O
maximum	O
absolute	O
value	O
across	O
the	O
train	O
ing	O
data	O
a	O
course	O
in	O
machine	O
learning	O
these	O
transformations	O
are	O
shown	O
geometrically	O
in	O
figure	O
the	O
goal	O
of	O
centering	O
is	O
to	O
make	O
sure	O
that	O
no	O
features	B
are	O
arbitrarily	O
large	O
the	O
goal	O
of	O
scaling	O
is	O
to	O
make	O
sure	O
that	O
all	O
features	B
have	O
roughly	O
the	O
same	O
scale	O
avoid	O
the	O
issue	O
of	O
centimeters	O
versus	O
millimeters	O
these	O
computations	O
are	O
fairly	O
straightforward	O
here	O
xnd	O
refers	O
to	O
the	O
dth	O
feature	O
of	O
example	O
n	O
since	O
it	O
is	O
very	O
rare	O
to	O
apply	O
scaling	O
without	O
previously	O
applying	O
centering	O
the	O
expressions	O
below	O
for	O
scaling	O
assume	O
that	O
the	O
data	O
is	O
already	O
centered	O
for	O
the	O
three	O
models	O
you	O
know	O
about	O
dt	O
perceptron	B
which	O
are	O
most	O
sensitive	O
to	O
centering	O
which	O
are	O
most	O
sensitive	O
to	O
scaling	O
centering	O
variance	B
scaling	O
absolute	O
scaling	O
where	O
xnd	O
xnd	O
d	O
xnd	O
xnd	O
d	O
xnd	O
xndrd	O
xnd	O
d	O
n	O
n	O
d	O
n	O
rd	O
max	O
n	O
n	O
in	O
practice	O
if	O
the	O
dynamic	O
range	O
of	O
your	O
features	B
is	O
already	O
some	O
subset	O
of	O
or	O
then	O
it	O
is	O
probably	O
not	O
worth	O
the	O
effort	O
of	O
centering	O
and	O
scaling	O
s	O
an	O
effort	O
because	O
you	O
have	O
to	O
keep	O
around	O
your	O
centering	O
and	O
scaling	O
calculations	O
so	O
that	O
you	O
can	O
apply	O
them	O
to	O
the	O
test	B
data	I
as	O
well	O
however	O
if	O
some	O
of	O
your	O
features	B
are	O
orders	O
of	O
magnitude	O
larger	O
than	O
others	O
it	O
might	O
be	O
helpful	O
remember	O
that	O
you	O
might	O
know	O
best	O
if	O
the	O
difference	O
in	O
scale	O
is	O
actually	O
significant	O
for	O
your	O
problem	O
then	O
rescaling	O
might	O
throw	O
away	O
useful	O
information	O
one	O
thing	O
to	O
be	O
wary	O
of	O
is	O
centering	O
binary	O
data	O
in	O
many	O
cases	O
binary	O
data	O
is	O
very	O
sparse	B
for	O
a	O
given	O
example	O
only	O
a	O
few	O
of	O
the	O
features	B
are	O
on	O
for	O
instance	O
out	O
of	O
a	O
vocabulary	O
of	O
or	O
words	O
a	O
given	O
document	O
probably	O
only	O
contains	O
about	O
from	O
a	O
storage	O
and	O
computation	O
perspective	O
this	O
is	O
very	O
useful	O
however	O
after	O
centering	O
the	O
data	O
will	O
no	O
longer	O
sparse	B
and	O
you	O
will	O
pay	O
dearly	O
with	O
outrageously	O
slow	O
implementations	O
in	O
example	B
normalization	I
you	O
view	O
examples	B
one	O
at	O
a	O
time	O
the	O
most	O
standard	O
normalization	O
is	O
to	O
ensure	O
that	O
the	O
length	O
of	O
each	O
example	O
vector	B
is	O
one	O
namely	O
each	O
example	O
lies	O
somewhere	O
on	O
the	O
unit	O
hypersphere	O
this	O
is	O
a	O
simple	O
transformation	O
example	B
normalization	I
xn	O
xn	O
figure	O
pracexnorm	O
example	O
of	O
example	B
normalization	I
this	O
transformation	O
is	O
depicted	O
in	O
figure	O
the	O
main	O
advantage	O
to	O
example	B
normalization	I
is	O
that	O
it	O
makes	O
comparisons	O
more	O
straightforward	O
across	O
data	O
sets	O
if	O
i	O
hand	O
you	O
practical	O
issues	O
figure	O
pracdttoperc	O
turning	O
a	O
dt	O
into	O
a	O
set	O
of	O
meta	O
features	B
figure	O
praclog	O
performance	O
on	O
text	O
categ	O
with	O
word	O
counts	O
versus	O
log	O
word	O
counts	O
two	O
data	O
sets	O
that	O
differ	O
only	O
in	O
the	O
norm	O
of	O
the	O
feature	O
vectors	O
one	O
is	O
just	O
a	O
scaled	O
version	O
of	O
the	O
other	O
it	O
is	O
difficult	O
to	O
compare	O
the	O
learned	O
models	O
example	B
normalization	I
makes	O
this	O
more	O
straightforward	O
moreover	O
as	O
you	O
saw	O
in	O
the	O
perceptron	B
convergence	O
proof	O
it	O
is	O
often	O
just	O
mathematically	O
easier	O
to	O
assume	O
normalized	O
data	O
combinatorial	O
feature	O
explosion	O
you	O
learned	O
in	O
chapter	O
that	O
linear	O
models	O
the	O
perceptron	B
cannot	O
solve	O
the	O
xor	O
problem	O
you	O
also	O
learned	O
that	O
by	O
performing	O
a	O
combinatorial	O
feature	O
explosion	O
they	O
could	O
but	O
that	O
came	O
at	O
the	O
computational	O
expense	O
of	O
gigantic	O
feature	O
vectors	O
of	O
the	O
algorithms	O
that	O
you	O
ve	O
seen	O
so	O
far	O
the	O
perceptron	B
is	O
the	O
one	O
that	O
has	O
the	O
most	O
to	O
gain	O
by	O
feature	O
combination	O
and	O
the	O
decision	B
tree	I
is	O
the	O
one	O
that	O
has	O
the	O
least	O
to	O
gain	O
in	O
fact	O
the	O
decision	B
tree	I
construction	O
is	O
essentially	O
building	O
meta	O
features	B
for	O
you	O
at	O
least	O
it	O
is	O
building	O
meta	O
features	B
constructed	O
purely	O
through	O
logical	O
ands	O
this	O
observation	O
leads	O
to	O
a	O
heuristic	O
for	O
constructing	O
meta	O
features	B
for	O
perceptrons	O
from	O
decision	B
trees	I
the	O
idea	O
is	O
to	O
train	O
a	O
decision	B
tree	I
on	O
the	O
training	B
data	I
from	O
that	O
decision	B
tree	I
you	O
can	O
extract	O
meta	O
features	B
by	O
looking	O
at	O
feature	B
combinations	I
along	O
branches	O
you	O
can	O
then	O
add	O
only	O
those	O
feature	B
combinations	I
as	O
meta	O
features	B
to	O
the	O
feature	O
set	O
for	O
the	O
perceptron	B
figure	O
shows	O
a	O
small	O
decision	B
tree	I
and	O
a	O
set	O
of	O
meta	O
features	B
that	O
you	O
might	O
extract	O
from	O
it	O
there	O
is	O
a	O
hyperparameter	B
here	O
of	O
what	O
length	O
paths	O
to	O
extract	O
from	O
the	O
tree	O
in	O
this	O
case	O
only	O
paths	O
of	O
length	O
two	O
are	O
extracted	O
for	O
bigger	O
trees	O
or	O
if	O
you	O
have	O
more	O
data	O
you	O
might	O
benefit	O
from	O
longer	O
paths	O
in	O
addition	O
to	O
combinatorial	O
transformations	O
the	O
logarithmic	B
transformation	I
can	O
be	O
quite	O
useful	O
in	O
practice	O
it	O
seems	O
like	O
a	O
strange	O
thing	O
to	O
be	O
useful	O
since	O
it	O
doesn	O
t	O
seem	O
to	O
fundamentally	O
change	O
the	O
data	O
however	O
since	O
many	O
learning	O
algorithms	O
operate	O
by	O
linear	O
operations	O
on	O
the	O
features	B
perceptron	B
and	O
knn	O
do	O
this	O
the	O
log-transform	O
is	O
a	O
way	O
to	O
get	O
product-like	O
operations	O
the	O
question	O
is	O
which	O
of	O
the	O
following	O
feels	O
more	O
applicable	O
to	O
your	O
data	O
every	O
time	O
this	O
feature	O
increases	O
by	O
one	O
i	O
m	O
equally	O
more	O
likely	O
to	O
predict	B
a	O
positive	O
label	B
every	O
time	O
this	O
feature	O
doubles	O
i	O
m	O
equally	O
more	O
like	O
to	O
predict	B
a	O
positive	O
label	B
in	O
the	O
first	O
case	O
you	O
should	O
stick	O
with	O
linear	O
features	B
and	O
in	O
the	O
second	O
case	O
you	O
should	O
switch	O
to	O
a	O
log-transform	O
this	O
is	O
an	O
important	O
transformation	O
in	O
text	O
data	O
where	O
the	O
presence	O
of	O
the	O
word	O
excellent	O
once	O
is	O
a	O
good	O
indicator	O
of	O
a	O
positive	O
review	O
seeing	O
excellent	O
twice	O
is	O
a	O
better	O
indicator	O
but	O
the	O
difference	O
between	O
seeing	O
excellent	O
times	O
and	O
seeing	O
it	O
times	O
really	O
isn	O
t	O
a	O
big	O
deal	O
any	O
more	O
a	O
log-transform	O
achieves	O
a	O
course	O
in	O
machine	O
learning	O
this	O
experimentally	O
you	O
can	O
see	O
the	O
difference	O
in	O
test	O
performance	O
between	O
word	O
count	O
data	O
and	O
log-word	O
count	O
data	O
in	O
figure	O
here	O
the	O
transformation	O
is	O
actually	O
xd	O
to	O
ensure	O
that	O
zeros	O
remain	O
zero	O
and	O
sparsity	O
is	O
retained	O
evaluating	O
model	B
performance	O
so	O
far	O
our	O
focus	O
has	O
been	O
on	O
classifiers	O
that	O
achieve	O
high	O
accuracy	O
in	O
some	O
cases	O
this	O
is	O
not	O
what	O
you	O
might	O
want	O
for	O
instance	O
if	O
you	O
are	O
trying	O
to	O
predict	B
whether	O
a	O
patient	O
has	O
cancer	O
or	O
not	O
it	O
might	O
be	O
better	O
to	O
err	O
on	O
one	O
side	O
they	O
have	O
cancer	O
when	O
they	O
don	O
t	O
than	O
the	O
other	O
then	O
they	O
die	O
similarly	O
letting	O
a	O
little	O
spam	O
slip	O
through	O
might	O
be	O
better	O
than	O
accidentally	O
blocking	O
one	O
email	O
from	O
your	O
boss	O
there	O
are	O
two	O
major	O
types	O
of	O
binary	O
classification	O
problems	O
one	O
is	O
x	O
versus	O
y	O
for	O
instance	O
positive	O
versus	O
negative	O
sentiment	O
another	O
is	O
x	O
versus	O
not-x	O
for	O
instance	O
spam	O
versus	O
non-spam	O
argument	O
being	O
that	O
there	O
are	O
lots	O
of	O
types	O
of	O
non-spam	O
or	O
in	O
the	O
context	O
of	O
web	O
search	O
relevant	O
document	O
versus	O
irrelevant	O
document	O
this	O
is	O
a	O
subtle	O
and	O
subjective	O
decision	O
but	O
x	O
versus	O
notx	O
problems	O
often	O
have	O
more	O
of	O
the	O
feel	O
of	O
x	O
spotting	O
rather	O
than	O
a	O
true	O
distinction	O
between	O
x	O
and	O
y	O
you	O
spot	O
the	O
spam	O
can	O
you	O
spot	O
the	O
relevant	O
documents	O
for	O
spotting	O
problems	O
versus	O
not-x	O
there	O
are	O
often	O
more	O
appropriate	O
success	O
metrics	O
than	O
accuracy	O
a	O
very	O
popular	O
one	O
from	O
information	O
retrieval	O
is	O
the	O
precisionrecall	O
metric	O
precision	B
asks	O
the	O
question	O
of	O
all	O
the	O
x	O
s	O
that	O
you	O
found	O
how	O
many	O
of	O
them	O
were	O
actually	O
x	O
s	O
recall	B
asks	O
of	O
all	O
the	O
x	O
s	O
that	O
were	O
out	O
there	O
how	O
many	O
of	O
them	O
did	O
you	O
formally	O
precision	B
and	O
recall	B
are	O
defined	O
as	O
p	O
r	O
i	O
s	O
i	O
t	O
s	O
number	O
of	O
xs	O
that	O
your	O
system	O
found	O
t	O
number	O
of	O
xs	O
in	O
the	O
data	O
i	O
number	O
of	O
correct	O
xs	O
that	O
your	O
system	O
found	O
here	O
s	O
is	O
mnemonic	O
for	O
system	O
t	O
is	O
mnemonic	O
for	O
truth	O
and	O
i	O
is	O
mnemonic	O
for	O
intersection	O
it	O
is	O
generally	O
accepted	O
that	O
in	O
these	O
definitions	O
thus	O
if	O
you	O
system	O
found	O
nothing	O
your	O
precision	B
is	O
always	O
perfect	O
and	O
if	O
there	O
is	O
nothing	O
to	O
find	O
your	O
recall	B
is	O
always	O
perfect	O
once	O
you	O
can	O
compute	O
precision	B
and	O
recall	B
you	O
are	O
often	O
able	O
to	O
produce	O
precisionrecall	O
curves	O
suppose	O
that	O
you	O
are	O
attempting	O
a	O
colleague	O
make	O
the	O
analogy	O
to	O
the	O
us	O
court	O
system	O
s	O
saying	O
do	O
you	O
promise	O
to	O
tell	O
the	O
whole	O
truth	O
and	O
nothing	O
but	O
the	O
truth	O
in	O
this	O
case	O
the	O
whole	O
truth	O
means	O
high	O
recall	B
and	O
nothing	O
but	O
the	O
truth	O
means	O
high	O
precision	B
figure	O
pracspam	O
show	O
a	O
bunch	O
of	O
emails	O
spamnospam	O
sorted	O
by	O
model	B
predicion	O
not	O
perfect	O
practical	O
issues	O
how	O
would	O
you	O
get	O
a	O
confidence	O
out	O
of	O
a	O
decision	B
tree	I
or	O
knn	O
figure	O
pracprcurve	O
precision	B
recall	B
curve	O
table	O
table	O
of	O
f-measures	O
when	O
varying	O
precision	B
and	O
recall	B
values	O
to	O
identify	O
spam	O
you	O
run	O
a	O
learning	O
algorithm	B
to	O
make	O
predictions	O
on	O
a	O
test	B
set	I
but	O
instead	O
of	O
just	O
taking	O
a	O
yesno	O
answer	O
you	O
allow	O
your	O
algorithm	B
to	O
produce	O
its	O
confidence	O
for	O
instance	O
in	O
perceptron	B
you	O
might	O
use	O
the	O
distance	B
from	O
the	O
hyperplane	B
as	O
a	O
confidence	O
measure	O
you	O
can	O
then	O
sort	O
all	O
of	O
your	O
test	O
emails	O
according	O
to	O
this	O
ranking	O
you	O
may	O
put	O
the	O
most	O
spam-like	O
emails	O
at	O
the	O
top	O
and	O
the	O
least	O
spam-like	O
emails	O
at	O
the	O
bottom	O
like	O
in	O
figure	O
once	O
you	O
have	O
this	O
sorted	O
list	O
you	O
can	O
choose	O
how	O
aggressively	O
you	O
want	O
your	O
spam	O
filter	O
to	O
be	O
by	O
setting	O
a	O
threshold	B
anywhere	O
on	O
this	O
list	O
one	O
would	O
hope	O
that	O
if	O
you	O
set	O
the	O
threshold	B
very	O
high	O
you	O
are	O
likely	O
to	O
have	O
high	O
precision	B
low	O
recall	B
if	O
you	O
set	O
the	O
threshold	B
very	O
low	O
you	O
ll	O
have	O
high	O
recall	B
low	O
precision	B
by	O
considering	O
every	O
possible	O
place	O
you	O
could	O
put	O
this	O
threshold	B
you	O
can	O
trace	O
out	O
a	O
curve	O
of	O
precisionrecall	O
values	O
like	O
the	O
one	O
in	O
figure	O
this	O
allows	O
us	O
to	O
ask	O
the	O
question	O
for	O
some	O
fixed	O
precision	B
what	O
sort	O
of	O
recall	B
can	O
i	O
get	O
obviously	O
the	O
closer	O
your	O
curve	O
is	O
to	O
the	O
upper-right	O
corner	O
the	O
better	O
and	O
when	O
comparing	O
learning	O
algorithms	O
a	O
and	O
b	O
you	O
can	O
say	O
that	O
a	O
dominates	B
b	O
if	O
a	O
s	O
precisionrecall	O
curve	O
is	O
always	O
higher	O
than	O
b	O
s	O
precisionrecall	O
curves	O
are	O
nice	O
because	O
they	O
allow	O
us	O
to	O
visualize	B
many	O
ways	O
in	O
which	O
we	O
could	O
use	O
the	O
system	O
however	O
sometimes	O
we	O
like	O
to	O
have	O
a	O
single	O
number	O
that	O
informs	O
us	O
of	O
the	O
quality	O
of	O
the	O
solution	O
a	O
popular	O
way	O
of	O
combining	O
precision	B
and	O
recall	B
into	O
a	O
single	O
number	O
is	O
by	O
taking	O
their	O
harmonic	O
mean	O
this	O
is	O
known	O
as	O
the	O
balanced	O
f-measure	O
f-score	O
f	O
p	O
r	O
p	O
r	O
the	O
reason	O
that	O
you	O
want	O
to	O
use	O
a	O
harmonic	O
mean	O
rather	O
than	O
an	O
arithmetic	O
mean	O
one	O
you	O
re	O
more	O
used	O
to	O
is	O
that	O
it	O
favors	O
systems	O
that	O
achieve	O
roughly	O
equal	O
precision	B
and	O
recall	B
in	O
the	O
extreme	O
case	O
where	O
p	O
r	O
then	O
f	O
p	O
r	O
but	O
in	O
the	O
imbalanced	O
case	O
for	O
instance	O
p	O
and	O
r	O
the	O
overall	O
f-measure	O
is	O
a	O
modest	O
table	O
shows	O
f-measures	O
as	O
a	O
function	O
of	O
precision	B
and	O
recall	B
so	O
that	O
you	O
can	O
see	O
how	O
important	O
it	O
is	O
to	O
get	O
balanced	O
values	O
in	O
some	O
cases	O
you	O
might	O
believe	O
that	O
precision	B
is	O
more	O
important	O
than	O
recall	B
this	O
idea	O
leads	O
to	O
the	O
weighted	O
f-measure	O
which	O
is	O
parameterized	O
by	O
a	O
weight	O
f	O
p	O
r	O
p	O
r	O
for	O
this	O
reduces	O
to	O
the	O
standard	O
f-measure	O
for	O
it	O
focuses	O
entirely	O
on	O
recall	B
and	O
for	O
it	O
focuses	O
entirely	O
on	O
precision	B
the	O
interpretation	O
of	O
the	O
weight	O
is	O
that	O
f	O
measures	O
the	O
perfor	O
a	O
course	O
in	O
machine	O
learning	O
mance	O
for	O
a	O
user	O
who	O
cares	O
times	O
as	O
much	O
about	O
precision	B
as	O
about	O
recall	B
one	O
thing	O
to	O
keep	O
in	O
mind	O
is	O
that	O
precision	B
and	O
recall	B
hence	O
f-measure	O
depend	O
crucially	O
on	O
which	O
class	O
is	O
considered	O
the	O
thing	O
you	O
wish	O
to	O
find	O
in	O
particular	O
if	O
you	O
take	O
a	O
binary	O
data	O
set	O
if	O
flip	O
what	O
it	O
means	O
to	O
be	O
a	O
positive	O
or	O
negative	O
example	O
you	O
will	O
end	O
up	O
with	O
completely	O
difference	O
precision	B
and	O
recall	B
values	O
it	O
is	O
not	O
the	O
case	O
that	O
precision	B
on	O
the	O
flipped	O
task	O
is	O
equal	O
to	O
recall	B
on	O
the	O
original	O
task	O
vice	O
versa	O
consequently	O
f-measure	O
is	O
also	O
not	O
the	O
same	O
for	O
some	O
tasks	O
where	O
people	O
are	O
less	O
sure	O
about	O
what	O
they	O
want	O
they	O
will	O
occasionally	O
report	O
two	O
sets	O
of	O
precisionrecallfmeasure	O
numbers	O
which	O
vary	O
based	O
on	O
which	O
class	O
is	O
considered	O
the	O
thing	O
to	O
spot	O
there	O
are	O
other	O
standard	O
metrics	O
that	O
are	O
used	O
in	O
different	O
communities	O
for	O
instance	O
the	O
medical	O
community	O
is	O
fond	O
of	O
the	O
sensitivityspecificity	O
metric	O
a	O
sensitive	O
classifier	O
is	O
one	O
which	O
almost	O
always	O
finds	O
everything	O
it	O
is	O
looking	O
for	O
it	O
has	O
high	O
recall	B
in	O
fact	O
sensitivity	B
is	O
exactly	O
the	O
same	O
as	O
recall	B
a	O
specific	O
classifier	O
is	O
one	O
which	O
does	O
a	O
good	O
job	O
not	O
finding	O
the	O
things	O
that	O
it	O
doesn	O
t	O
want	O
to	O
find	O
specificity	B
is	O
precision	B
on	O
the	O
negation	O
of	O
the	O
task	O
at	O
hand	O
you	O
can	O
compute	O
curves	O
for	O
sensitivity	B
and	O
specificity	B
much	O
like	O
those	O
for	O
precision	B
and	O
recall	B
the	O
typical	O
plot	O
referred	O
to	O
as	O
the	O
receiver	B
operating	I
characteristic	I
roc	B
curve	I
plots	O
the	O
sensitivity	B
against	O
specificity	B
given	O
an	O
roc	B
curve	I
you	O
can	O
compute	O
the	O
area	B
under	I
the	I
curve	I
auc	B
metric	O
which	O
also	O
provides	O
a	O
meaningful	O
single	O
number	O
for	O
a	O
system	O
s	O
performance	O
unlike	O
f-measures	O
which	O
tend	O
to	O
be	O
low	O
because	O
the	O
require	O
agreement	O
auc	B
scores	O
tend	O
to	O
be	O
very	O
high	O
even	O
for	O
not	O
great	O
systems	O
this	O
is	O
because	O
random	O
chance	O
will	O
give	O
you	O
an	O
auc	B
of	O
and	O
the	O
best	O
possible	O
auc	B
is	O
the	O
main	O
message	O
for	O
evaluation	O
metrics	O
is	O
that	O
you	O
should	O
choose	O
whichever	O
one	O
makes	O
the	O
most	O
sense	O
in	O
many	O
cases	O
several	O
might	O
make	O
sense	O
in	O
that	O
case	O
you	O
should	O
do	O
whatever	O
is	O
more	O
commonly	O
done	O
in	O
your	O
field	O
there	O
is	O
no	O
reason	O
to	O
be	O
an	O
outlier	O
without	O
cause	O
cross	B
validation	I
in	O
chapter	O
you	O
learned	O
about	O
using	O
development	B
data	I
held-out	B
data	I
to	O
set	O
hyperparameters	O
the	O
main	O
disadvantage	O
to	O
the	O
development	B
data	I
approach	O
is	O
that	O
you	O
throw	O
out	O
some	O
of	O
your	O
training	B
data	I
just	O
for	O
estimating	O
one	O
or	O
two	O
hyperparameters	O
an	O
alternative	O
is	O
the	O
idea	O
of	O
cross	B
validation	I
in	O
cross	B
validation	I
you	O
break	O
your	O
training	B
data	I
up	O
into	O
equally-sized	O
partitions	O
you	O
train	O
a	O
learning	O
algorithm	B
on	O
of	O
them	O
and	O
test	O
it	O
on	O
the	O
remaining	O
practical	O
issues	O
algorithm	B
crossvalidatelearningalgorithm	O
data	O
k	O
unknown	O
for	O
all	O
hyperparameter	B
settings	O
do	O
store	O
lowest	O
error	O
encountered	O
so	O
far	O
store	O
the	O
hyperparameter	B
setting	O
that	O
yielded	O
it	O
keep	O
track	O
of	O
the	O
k-many	O
error	O
estimates	O
err	O
for	O
k	O
to	O
k	O
do	O
train	O
yn	O
data	O
n	O
mod	O
k	O
k	O
test	O
yn	O
data	O
n	O
mod	O
k	O
k	O
test	O
every	O
kth	O
example	O
model	B
run	O
learningalgorithm	O
on	O
train	O
err	O
err	O
error	O
of	O
model	B
on	O
test	O
add	O
current	O
error	O
to	O
list	O
of	O
errors	O
end	O
for	O
avgerr	O
mean	O
of	O
set	O
err	O
if	O
avgerr	O
then	O
avgerr	O
remember	O
these	O
settings	O
because	O
they	O
re	O
the	O
best	O
so	O
far	O
end	O
if	O
end	O
for	O
you	O
do	O
this	O
times	O
each	O
time	O
holding	O
out	O
a	O
different	O
partition	O
as	O
the	O
development	O
part	O
you	O
can	O
then	O
average	O
your	O
performance	O
over	O
all	O
ten	O
parts	O
to	O
get	O
an	O
estimate	O
of	O
how	O
well	O
your	O
model	B
will	O
perform	O
in	O
the	O
future	O
you	O
can	O
repeat	O
this	O
process	O
for	O
every	O
possible	O
choice	O
of	O
hyperparameters	O
to	O
get	O
an	O
estimate	O
of	O
which	O
one	O
performs	O
best	O
the	O
general	O
k-fold	O
cross	B
validation	I
technique	O
is	O
shown	O
in	O
algorithm	B
where	O
k	O
in	O
the	O
preceeding	O
discussion	O
in	O
fact	O
the	O
development	B
data	I
approach	O
can	O
be	O
seen	O
as	O
an	O
approximation	O
to	O
cross	B
validation	I
wherein	O
only	O
one	O
of	O
the	O
k	O
loops	O
in	O
algorithm	B
is	O
executed	O
typical	O
choices	O
for	O
k	O
are	O
and	O
n	O
by	O
far	O
the	O
most	O
com	O
mon	O
is	O
k	O
cross	B
validation	I
sometimes	O
is	O
used	O
for	O
efficiency	O
reasons	O
and	O
sometimes	O
is	O
used	O
for	O
subtle	O
statistical	O
reasons	O
but	O
that	O
is	O
quite	O
rare	O
in	O
the	O
case	O
that	O
k	O
n	O
this	O
is	O
known	O
as	O
leave-one-out	B
cross	B
validation	I
abbreviated	O
as	O
loo	B
cross	B
validation	I
after	O
running	O
cross	B
validation	I
you	O
have	O
two	O
choices	O
you	O
can	O
either	O
select	O
one	O
of	O
the	O
k	O
trained	O
models	O
as	O
your	O
final	O
model	B
to	O
make	O
predictions	O
with	O
or	O
you	O
can	O
train	O
a	O
new	O
model	B
on	O
all	O
of	O
the	O
data	O
using	O
the	O
hyperparameters	O
selected	O
by	O
cross-validation	O
if	O
you	O
have	O
the	O
time	O
the	O
latter	O
is	O
probably	O
a	O
better	O
options	O
it	O
may	O
seem	O
that	O
loo	B
cross	B
validation	I
is	O
prohibitively	O
expensive	O
to	O
run	O
this	O
is	O
true	O
for	O
most	O
learning	O
algorithms	O
except	O
for	O
k-nearest	B
neighbors	I
for	O
knn	O
leave-one-out	O
is	O
actually	O
very	O
natural	O
we	O
loop	O
through	O
each	O
training	O
point	O
and	O
ask	O
ourselves	O
whether	O
this	O
example	O
would	O
be	O
correctly	O
classified	O
for	O
all	O
different	O
possible	O
values	O
of	O
k	O
this	O
requires	O
only	O
as	O
much	O
computation	O
as	O
computing	O
the	O
k	O
nearest	O
neighbors	O
for	O
the	O
highest	O
value	O
of	O
k	O
this	O
is	O
such	O
a	O
popular	O
and	O
effective	O
approach	O
for	O
knn	O
classification	O
that	O
it	O
is	O
spelled	O
out	O
in	O
a	O
course	O
in	O
machine	O
learning	O
algorithm	B
knn-train-lood	O
errk	O
k	O
n	O
for	O
n	O
to	O
n	O
do	O
sm	O
xm	O
m	O
n	O
s	O
sorts	O
y	O
for	O
k	O
to	O
n	O
do	O
sk	O
y	O
y	O
ym	O
if	O
y	O
ym	O
then	O
errk	O
errk	O
end	O
if	O
end	O
for	O
end	O
for	O
return	O
argmink	O
errk	O
errk	O
stores	O
how	O
well	O
you	O
do	O
with	O
knn	O
compute	O
distances	O
to	O
other	O
points	O
put	O
lowest-distance	O
objects	O
first	O
current	O
label	B
prediction	O
let	O
kth	O
closest	O
point	O
vote	B
one	O
more	O
error	O
for	O
knn	O
return	O
the	O
k	O
that	O
achieved	O
lowest	O
error	O
algorithm	B
overall	O
the	O
main	O
advantage	O
to	O
cross	B
validation	I
over	O
develop	O
ment	O
data	O
is	O
robustness	O
the	O
main	O
advantage	O
of	O
development	B
data	I
is	O
speed	O
one	O
warning	O
to	O
keep	O
in	O
mind	O
is	O
that	O
the	O
goal	O
of	O
both	O
cross	B
validation	I
and	O
development	B
data	I
is	O
to	O
estimate	O
how	O
well	O
you	O
will	O
do	O
in	O
the	O
future	O
this	O
is	O
a	O
question	O
of	O
statistics	O
and	O
holds	O
only	O
if	O
your	O
test	B
data	I
really	O
looks	O
like	O
your	O
training	B
data	I
that	O
is	O
it	O
is	O
drawn	O
from	O
the	O
same	O
distribution	O
in	O
many	O
practical	O
cases	O
this	O
is	O
not	O
entirely	O
true	O
for	O
example	O
in	O
person	O
identification	O
we	O
might	O
try	O
to	O
classify	O
every	O
pixel	O
in	O
an	O
image	O
based	O
on	O
whether	O
it	O
contains	O
a	O
person	O
or	O
not	O
if	O
we	O
have	O
training	O
images	O
each	O
with	O
pixels	O
then	O
we	O
have	O
a	O
total	O
of	O
training	O
examples	B
the	O
classification	O
for	O
a	O
pixel	O
in	O
image	O
is	O
highly	O
dependent	O
on	O
the	O
classification	O
for	O
a	O
neighboring	O
pixel	O
in	O
the	O
same	O
image	O
so	O
if	O
one	O
of	O
those	O
pixels	O
happens	O
to	O
fall	O
in	O
training	B
data	I
and	O
the	O
other	O
in	O
development	O
cross	B
validation	B
data	I
your	O
model	B
will	O
do	O
unreasonably	O
well	O
in	O
this	O
case	O
it	O
is	O
important	O
that	O
when	O
you	O
cross	O
validate	O
use	O
development	B
data	I
you	O
do	O
so	O
over	O
images	O
not	O
over	O
pixels	O
the	O
same	O
goes	O
for	O
text	O
problems	O
where	O
you	O
sometimes	O
want	O
to	O
classify	O
things	O
at	O
a	O
word	O
level	O
but	O
are	O
handed	O
a	O
collection	O
of	O
documents	O
the	O
important	O
thing	O
to	O
keep	O
in	O
mind	O
is	O
that	O
it	O
is	O
the	O
images	O
documents	O
that	O
are	O
drawn	O
independently	B
from	O
your	O
data	O
distribution	O
and	O
not	O
the	O
pixels	O
words	O
which	O
are	O
drawn	O
dependently	O
practical	O
issues	O
hypothesis	B
testing	I
and	O
statistical	O
significance	O
vignette	O
the	O
lady	O
drinking	O
tea	O
story	O
suppose	O
that	O
you	O
ve	O
presented	O
a	O
machine	O
learning	O
solution	O
to	O
your	O
boss	O
that	O
achieves	O
error	O
on	O
cross	B
validation	I
your	O
nemesis	O
gabe	O
gives	O
a	O
solution	O
to	O
your	O
boss	O
that	O
achieves	O
error	O
on	O
cross	B
validation	I
how	O
impressed	O
should	O
your	O
boss	O
be	O
it	O
depends	O
if	O
this	O
improvement	O
was	O
measured	O
over	O
examples	B
perhaps	O
not	O
too	O
impressed	O
it	O
would	O
mean	O
that	O
gabe	O
got	O
exactly	O
one	O
more	O
example	O
right	O
than	O
you	O
did	O
fact	O
he	O
probably	O
got	O
more	O
right	O
and	O
more	O
wrong	O
if	O
this	O
impressed	O
was	O
measured	O
over	O
examples	B
perhaps	O
this	O
is	O
more	O
impressive	O
this	O
is	O
one	O
of	O
the	O
most	O
fundamental	O
questions	O
in	O
statistics	O
you	O
have	O
a	O
scientific	O
hypothesis	B
of	O
the	O
form	O
gabe	O
s	O
algorithm	B
is	O
better	O
than	O
mine	O
you	O
wish	O
to	O
test	O
whether	O
this	O
hypothesis	B
is	O
true	O
you	O
are	O
testing	O
it	O
against	O
the	O
null	B
hypothesis	B
which	O
is	O
that	O
gabe	O
s	O
algorithm	B
is	O
no	O
better	O
than	O
yours	O
you	O
ve	O
collected	O
data	O
or	O
data	O
points	O
to	O
measure	O
the	O
strength	O
of	O
this	O
hypothesis	B
you	O
want	O
to	O
ensure	O
that	O
the	O
difference	O
in	O
performance	O
of	O
these	O
two	O
algorithms	O
is	O
statistically	B
significant	I
i	O
e	O
is	O
probably	O
not	O
just	O
due	O
to	O
random	O
luck	O
more	O
common	O
question	O
statisticians	O
ask	O
is	O
whether	O
one	O
drug	O
treatment	O
is	O
better	O
than	O
another	O
where	O
another	O
is	O
either	O
a	O
placebo	O
or	O
the	O
competitor	O
s	O
drug	O
there	O
are	O
about	O
ways	O
of	O
doing	O
hypothesis	B
testing	I
like	O
evaluation	O
metrics	O
and	O
the	O
number	O
of	O
folds	O
of	O
cross	B
validation	I
this	O
is	O
something	O
that	O
is	O
very	O
discipline	O
specific	O
here	O
we	O
will	O
discuss	O
two	O
popular	O
tests	O
the	O
paired	B
t-test	B
and	O
bootstrapping	B
these	O
tests	O
and	O
other	O
statistical	O
tests	O
have	O
underlying	O
assumptions	O
instance	O
assumptions	O
about	O
the	O
distribution	O
of	O
observations	O
and	O
strengths	O
instance	O
small	O
or	O
large	O
samples	O
in	O
most	O
cases	O
the	O
goal	O
of	O
hypothesis	B
testing	I
is	O
to	O
compute	O
a	O
p-value	B
namely	O
the	O
probability	O
that	O
the	O
observed	O
difference	O
in	O
performance	O
was	O
by	O
chance	O
the	O
standard	O
way	O
of	O
reporting	O
results	O
is	O
to	O
say	O
something	O
like	O
there	O
is	O
a	O
chance	O
that	O
this	O
difference	O
was	O
not	O
by	O
chance	O
the	O
value	O
is	O
arbitrary	O
and	O
occasionally	O
people	O
use	O
weaker	O
test	O
or	O
stronger	O
tests	O
the	O
t-test	B
is	O
an	O
example	O
of	O
a	O
parametric	B
test	I
it	O
is	O
applicable	O
when	O
the	O
null	B
hypothesis	B
states	O
that	O
the	O
difference	O
between	O
two	O
responses	O
has	O
mean	O
zero	O
and	O
unknown	O
variance	B
the	O
t-test	B
actually	O
assumes	O
that	O
data	O
is	O
distributed	O
according	O
to	O
a	O
gaussian	B
distribution	I
which	O
is	O
a	O
course	O
in	O
machine	O
learning	O
probably	O
not	O
true	O
of	O
binary	O
responses	O
fortunately	O
for	O
large	O
samples	O
least	O
a	O
few	O
hundred	O
binary	O
seamples	O
are	O
well	O
approximated	O
by	O
a	O
gaussian	B
distribution	I
so	O
long	O
as	O
your	O
sample	O
is	O
sufficiently	O
large	O
the	O
t-test	B
is	O
reasonable	O
either	O
for	O
regression	O
or	O
classification	O
problems	O
suppose	O
that	O
you	O
evaluate	O
two	O
algorithm	B
on	O
n-many	O
examples	B
on	O
each	O
example	O
you	O
can	O
compute	O
whether	O
the	O
algorithm	B
made	O
the	O
correct	O
prediction	O
let	O
an	O
denote	O
the	O
error	O
of	O
the	O
first	O
algorithm	B
on	O
each	O
example	O
let	O
bn	O
denote	O
the	O
error	O
of	O
the	O
second	O
algorithm	B
you	O
can	O
compute	O
a	O
and	O
b	O
as	O
the	O
means	O
of	O
a	O
and	O
b	O
respecitively	O
finally	O
center	O
the	O
data	O
as	O
a	O
a	O
a	O
and	O
b	O
b	O
b	O
the	O
t-statistic	O
is	O
defined	O
as	O
t	O
a	O
b	O
nn	O
n	O
an	O
t	O
significance	O
table	O
table	O
of	O
significance	O
values	O
for	O
the	O
t-test	B
after	O
computing	O
the	O
t-value	O
you	O
can	O
compare	O
it	O
to	O
a	O
list	O
of	O
values	O
for	O
computing	O
confidence	B
intervals	I
assuming	O
you	O
have	O
a	O
lot	O
of	O
data	O
is	O
a	O
few	O
hundred	O
or	O
more	O
then	O
you	O
can	O
compare	O
your	O
t-value	O
to	O
table	O
to	O
determine	O
the	O
significance	O
level	O
of	O
the	O
difference	O
one	O
disadvantage	O
to	O
the	O
t-test	B
is	O
that	O
it	O
cannot	O
easily	O
be	O
applied	O
to	O
evaluation	O
metrics	O
like	O
f-score	O
this	O
is	O
because	O
f-score	O
is	O
a	O
computed	O
over	O
an	O
entire	O
test	B
set	I
and	O
does	O
not	O
decompose	O
into	O
a	O
set	O
of	O
individual	O
errors	O
this	O
means	O
that	O
the	O
t-test	B
cannot	O
be	O
applied	O
fortunately	O
cross	B
validation	I
gives	O
you	O
a	O
way	O
around	O
this	O
problem	O
what	O
does	O
it	O
mean	O
for	O
the	O
means	O
a	O
and	O
b	O
to	O
become	O
further	O
apart	O
how	O
does	O
this	O
affect	O
the	O
t-value	O
what	O
happens	O
if	O
the	O
variance	B
of	O
a	O
increases	O
when	O
you	O
do	O
k-fold	O
cross	B
validation	I
you	O
are	O
able	O
to	O
compute	O
k	O
error	O
metrics	O
over	O
the	O
same	O
data	O
for	O
example	O
you	O
might	O
run	O
cross	B
validation	I
and	O
compute	O
f-score	O
for	O
every	O
fold	O
perhaps	O
the	O
fscores	O
are	O
and	O
this	O
gives	O
you	O
an	O
average	O
f-score	O
of	O
over	O
the	O
folds	O
the	O
standard	O
deviation	O
of	O
this	O
set	O
of	O
f-scores	O
is	O
n	O
n	O
you	O
can	O
now	O
assume	O
that	O
the	O
distribution	O
of	O
scores	O
is	O
approximately	O
gaussian	O
if	O
this	O
is	O
true	O
then	O
approximately	O
of	O
the	O
probability	O
mass	O
lies	O
in	O
the	O
range	O
lies	O
in	O
the	O
range	O
and	O
lies	O
in	O
the	O
range	O
so	O
if	O
we	O
were	O
comparing	O
our	O
algorithm	B
against	O
one	O
whose	O
average	O
f-score	O
was	O
we	O
could	O
be	O
certain	O
that	O
our	O
superior	O
performance	O
was	O
not	O
due	O
to	O
warning	O
a	O
confidence	O
of	O
does	O
not	O
mean	O
there	O
is	O
a	O
chance	O
that	O
i	O
am	O
better	O
all	O
it	O
means	O
is	O
that	O
if	O
i	O
reran	O
the	O
same	O
ex	O
had	O
we	O
run	O
cross	B
validation	I
we	O
might	O
be	O
been	O
able	O
to	O
get	O
tighter	O
confidence	B
intervals	I
practical	O
issues	O
algorithm	B
bootstrapevaluatey	O
y	O
numfolds	O
scores	O
for	O
k	O
to	O
numfolds	O
do	O
truth	O
pred	O
for	O
n	O
to	O
n	O
do	O
m	O
uniform	O
random	O
value	O
from	O
to	O
n	O
truth	O
truth	O
ym	O
pred	O
pred	O
ym	O
list	O
of	O
values	O
we	O
want	O
to	O
predict	B
list	O
of	O
values	O
we	O
actually	O
predicted	O
sample	O
a	O
test	O
point	O
add	O
on	O
the	O
truth	O
add	O
on	O
our	O
prediction	O
evaluate	O
end	O
for	O
scores	O
scores	O
f-scoretruth	O
pred	O
end	O
for	O
return	O
stddevscores	O
periment	O
times	O
then	O
in	O
of	O
those	O
experiments	O
i	O
would	O
still	O
win	O
these	O
are	O
very	O
different	O
statements	O
if	O
you	O
say	O
the	O
first	O
one	O
people	O
who	O
know	O
about	O
statistics	O
will	O
get	O
very	O
mad	O
at	O
you	O
one	O
disadvantage	O
to	O
cross	B
validation	I
is	O
that	O
it	O
is	O
computationally	O
expensive	O
more	O
folds	O
typically	O
leads	O
to	O
better	O
estimates	O
but	O
every	O
new	O
fold	O
requires	O
training	O
a	O
new	O
classifier	O
this	O
can	O
get	O
very	O
time	O
consuming	O
the	O
technique	O
of	O
bootstrapping	B
closely	O
related	O
idea	O
of	O
jack-knifing	B
can	O
address	O
this	O
problem	O
suppose	O
that	O
you	O
didn	O
t	O
want	O
to	O
run	O
cross	B
validation	I
all	O
you	O
have	O
is	O
a	O
single	O
held-out	O
test	B
set	I
with	O
data	O
points	O
in	O
it	O
you	O
can	O
run	O
your	O
classifier	O
and	O
get	O
predictions	O
on	O
these	O
data	O
points	O
you	O
would	O
like	O
to	O
be	O
able	O
to	O
compute	O
a	O
metric	O
like	O
f-score	O
on	O
this	O
test	B
set	I
but	O
also	O
get	O
confidence	B
intervals	I
the	O
idea	O
behind	O
bootstrapping	B
is	O
that	O
this	O
set	O
of	O
is	O
a	O
random	O
draw	O
from	O
some	O
distribution	O
we	O
would	O
like	O
to	O
get	O
multiple	O
random	O
draws	O
from	O
this	O
distribution	O
on	O
which	O
to	O
evaluate	O
we	O
can	O
simulate	O
multiple	O
draws	O
by	O
repeatedly	O
subsampling	O
from	O
these	O
examples	B
with	O
replacement	O
to	O
perform	O
a	O
single	O
bootstrap	O
you	O
will	O
sample	O
random	O
points	O
from	O
your	O
test	B
set	I
of	O
random	O
points	O
this	O
sampling	O
must	O
be	O
done	O
with	O
replacement	O
that	O
the	O
same	O
example	O
can	O
be	O
sampled	O
more	O
than	O
once	O
otherwise	O
you	O
ll	O
just	O
end	O
up	O
with	O
your	O
original	O
test	B
set	I
this	O
gives	O
you	O
a	O
bootstrapped	O
sample	O
on	O
this	O
sample	O
you	O
can	O
compute	O
f-score	O
whatever	O
metric	O
you	O
want	O
you	O
then	O
do	O
this	O
more	O
times	O
to	O
get	O
a	O
bootstrap	O
for	O
each	O
bootstrapped	O
sample	O
you	O
will	O
be	O
a	O
different	O
f-score	O
the	O
mean	O
and	O
standard	O
deviation	O
of	O
this	O
set	O
of	O
f-scores	O
can	O
be	O
used	O
to	O
estimate	O
a	O
confidence	O
interval	O
for	O
your	O
algorithm	B
the	O
bootstrap	B
resampling	I
procedure	O
is	O
sketched	O
in	O
algorithm	B
this	O
takes	O
three	O
arguments	O
the	O
true	O
labels	O
y	O
the	O
predicted	O
labels	O
y	O
and	O
the	O
number	O
of	O
folds	O
to	O
run	O
it	O
returns	O
the	O
mean	O
and	O
standard	O
deviation	O
from	O
which	O
you	O
can	O
compute	O
a	O
confidence	O
interval	O
a	O
course	O
in	O
machine	O
learning	O
debugging	O
learning	O
algorithms	O
learning	O
algorithms	O
are	O
notoriously	O
hard	O
to	O
debug	O
as	O
you	O
may	O
have	O
already	O
experienced	O
if	O
you	O
have	O
implemented	O
any	O
of	O
the	O
models	O
presented	O
so	O
far	O
the	O
main	O
issue	O
is	O
that	O
when	O
a	O
learning	O
algorithm	B
doesn	O
t	O
learn	O
it	O
s	O
unclear	O
if	O
this	O
is	O
because	O
there	O
s	O
a	O
bug	O
or	O
because	O
the	O
learning	O
problem	O
is	O
too	O
hard	O
there	O
s	O
too	O
much	O
noise	B
or	O
moreover	O
sometimes	O
bugs	O
lead	O
to	O
learning	O
algorithms	O
performing	O
better	O
than	O
they	O
should	O
these	O
are	O
especially	O
hard	O
to	O
catch	O
always	O
a	O
bit	O
disappointing	O
when	O
you	O
do	O
catch	O
them	O
obviously	O
if	O
you	O
have	O
a	O
reference	O
implementation	O
you	O
can	O
at	O
tempt	O
to	O
match	O
its	O
output	O
otherwise	O
there	O
are	O
two	O
things	O
you	O
can	O
do	O
to	O
try	O
to	O
help	O
debug	O
the	O
first	O
is	O
to	O
do	O
everything	O
in	O
your	O
power	O
to	O
get	O
the	O
learning	O
algorithm	B
to	O
overfit	O
if	O
it	O
cannot	O
at	O
least	O
overfit	O
the	O
training	B
data	I
there	O
s	O
definitely	O
something	O
wrong	O
the	O
second	O
is	O
to	O
feed	O
it	O
some	O
tiny	O
hand-specified	O
two	O
dimensional	O
data	O
set	O
on	O
which	O
you	O
know	O
what	O
it	O
should	O
do	O
and	O
you	O
can	O
plot	O
the	O
output	O
the	O
easiest	O
way	O
to	O
try	O
to	O
get	O
a	O
learning	O
algorithm	B
to	O
overfit	O
is	O
to	O
add	O
a	O
new	O
feature	O
to	O
it	O
you	O
can	O
call	O
this	O
feature	O
the	O
cheatingisfun	O
the	O
feature	O
value	O
associated	O
with	O
this	O
feature	O
is	O
if	O
this	O
is	O
a	O
positive	O
example	O
and	O
zero	O
if	O
this	O
is	O
a	O
negative	O
example	O
in	O
other	O
words	O
this	O
feature	O
is	O
a	O
perfect	O
indicator	O
of	O
the	O
class	O
of	O
this	O
example	O
if	O
you	O
add	O
the	O
cheatingisfun	O
feature	O
and	O
your	O
algorithm	B
does	O
not	O
get	O
near	O
training	B
error	I
this	O
could	O
be	O
because	O
there	O
are	O
too	O
many	O
noisy	O
features	B
confusing	O
it	O
you	O
could	O
either	O
remove	O
a	O
lot	O
of	O
the	O
other	O
features	B
or	O
make	O
the	O
feature	O
value	O
for	O
cheatingisfun	O
either	O
or	O
so	O
that	O
the	O
algorithm	B
really	O
looks	O
at	O
it	O
if	O
you	O
do	O
this	O
and	O
your	O
algorithm	B
still	O
cannot	O
overfit	O
then	O
you	O
likely	O
have	O
a	O
bug	O
to	O
remove	O
the	O
cheatingisfun	O
feature	O
from	O
your	O
final	O
implementation	O
a	O
second	O
thing	O
to	O
try	O
is	O
to	O
hand-craft	O
a	O
data	O
set	O
on	O
which	O
you	O
know	O
your	O
algorithm	B
should	O
work	O
this	O
is	O
also	O
useful	O
if	O
you	O
ve	O
managed	O
to	O
get	O
your	O
model	B
to	O
overfit	O
and	O
have	O
simply	O
noticed	O
that	O
it	O
does	O
not	O
generalize	B
for	O
instance	O
you	O
could	O
run	O
knn	O
on	O
the	O
xor	O
data	O
or	O
you	O
could	O
run	O
perceptron	B
on	O
some	O
easily	O
linearly	B
separable	I
data	O
instance	O
positive	O
points	O
along	O
the	O
line	O
and	O
negative	O
points	O
along	O
the	O
line	O
or	O
a	O
decision	B
tree	I
on	O
nice	O
axis-aligned	O
data	O
when	O
debugging	O
on	O
hand-crafted	O
data	O
remember	O
whatever	O
you	O
know	O
about	O
the	O
models	O
you	O
are	O
considering	O
for	O
instance	O
you	O
know	O
that	O
the	O
perceptron	B
should	O
converge	O
on	O
linearly	B
separable	I
data	O
so	O
try	O
it	O
on	O
a	O
linearly	B
separable	I
data	O
set	O
you	O
know	O
that	O
decision	B
trees	I
should	O
do	O
well	O
on	O
data	O
with	O
only	O
a	O
few	O
relevant	O
features	B
so	O
make	O
note	O
cheating	O
is	O
actually	O
not	O
fun	O
and	O
you	O
shouldn	O
t	O
do	O
it	O
practical	O
issues	O
your	O
label	B
some	O
easy	O
combination	O
of	O
features	B
such	O
as	O
y	O
you	O
know	O
that	O
knn	O
should	O
work	O
well	O
on	O
data	O
sets	O
where	O
the	O
classes	O
are	O
well	O
separated	O
so	O
try	O
such	O
data	O
sets	O
the	O
most	O
important	O
thing	O
to	O
keep	O
in	O
mind	O
is	O
that	O
a	O
lot	O
goes	O
in	O
to	O
getting	O
good	O
test	B
set	I
performance	O
first	O
the	O
model	B
has	O
to	O
be	O
right	O
for	O
the	O
data	O
so	O
crafting	O
your	O
own	O
data	O
is	O
helpful	O
second	O
the	O
model	B
has	O
to	O
fit	O
the	O
training	B
data	I
well	O
so	O
try	O
to	O
get	O
it	O
to	O
overfit	O
third	O
the	O
model	B
has	O
to	O
generalize	B
so	O
make	O
sure	O
you	O
tune	O
hyperparameters	O
well	O
todo	O
answers	O
to	O
image	O
questions	O
exercises	O
exercise	O
todo	O
figure	O
pracimageanswers	O
object	O
recognition	O
answers	O
beyond	O
binary	O
classification	O
learning	O
objectives	O
represent	O
complex	O
prediction	O
prob	O
lems	O
in	O
a	O
formal	O
learning	O
setting	O
be	O
able	O
to	O
artifically	O
balance	O
imbalanced	B
data	I
understand	O
the	O
positive	O
and	O
negative	O
aspects	O
of	O
several	O
reductions	B
from	O
multiclass	O
classification	O
to	O
binary	O
classification	O
recognize	O
the	O
difference	O
between	O
regression	O
and	O
ordinal	O
regression	O
implement	O
stacking	B
as	O
a	O
method	O
of	O
collective	B
classification	I
dependencies	O
in	O
the	O
preceeding	O
chapters	O
you	O
have	O
learned	O
all	O
about	O
a	O
very	O
simple	O
form	O
of	O
prediction	O
predicting	O
bits	O
in	O
the	O
real	O
world	O
however	O
we	O
often	O
need	O
to	O
predict	B
much	O
more	O
complex	O
objects	O
you	O
may	O
need	O
to	O
categorize	O
a	O
document	O
into	O
one	O
of	O
several	O
categories	O
sports	O
entertainment	O
news	O
politics	O
etc	O
you	O
may	O
need	O
to	O
rank	O
web	O
pages	O
or	O
ads	O
based	O
on	O
relevance	O
to	O
a	O
query	O
you	O
may	O
need	O
to	O
simultaneously	O
classify	O
a	O
collection	O
of	O
objects	O
such	O
as	O
web	O
pages	O
that	O
have	O
important	O
information	O
in	O
the	O
links	O
between	O
them	O
these	O
problems	O
are	O
all	O
commonly	O
encountered	O
yet	O
fundamentally	O
more	O
complex	O
than	O
binary	O
classification	O
in	O
this	O
chapter	O
you	O
will	O
learn	O
how	O
to	O
use	O
everything	O
you	O
already	O
know	O
about	O
binary	O
classification	O
to	O
solve	O
these	O
more	O
complicated	O
problems	O
you	O
will	O
see	O
that	O
it	O
s	O
relatively	O
easy	O
to	O
think	O
of	O
a	O
binary	O
classifier	O
as	O
a	O
black	O
box	O
which	O
you	O
can	O
reuse	O
for	O
solving	O
these	O
more	O
complex	O
problems	O
this	O
is	O
a	O
very	O
useful	O
abstraction	O
since	O
it	O
allows	O
us	O
to	O
reuse	O
knowledge	O
rather	O
than	O
having	O
to	O
build	O
new	O
learning	O
models	O
and	O
algorithms	O
from	O
scratch	O
learning	O
with	O
imbalanced	B
data	I
your	O
boss	O
tells	O
you	O
to	O
build	O
a	O
classifier	O
that	O
can	O
identify	O
fraudulent	O
transactions	O
in	O
credit	O
card	O
histories	O
fortunately	O
most	O
transactions	O
are	O
legitimate	O
so	O
perhaps	O
only	O
of	O
the	O
data	O
is	O
a	O
positive	O
instance	O
the	O
imbalanced	B
data	I
problem	O
refers	O
to	O
the	O
fact	O
that	O
for	O
a	O
large	O
number	O
of	O
real	O
world	O
problems	O
the	O
number	O
of	O
positive	O
examples	B
is	O
dwarfed	O
by	O
the	O
number	O
of	O
negative	O
examples	B
vice	O
versa	O
this	O
is	O
actually	O
something	O
of	O
a	O
misnomer	O
it	O
is	O
not	O
the	O
data	O
that	O
is	O
imbalanced	O
but	O
the	O
distribution	O
from	O
which	O
the	O
data	O
is	O
drawn	O
since	O
the	O
distribution	O
is	O
imbalanced	O
so	O
must	O
the	O
data	O
be	O
imbalanced	B
data	I
is	O
a	O
problem	O
because	O
machine	O
learning	O
algorithms	O
are	O
too	O
smart	O
for	O
your	O
own	O
good	O
for	O
most	O
learning	O
algorithms	O
if	O
you	O
give	O
them	O
data	O
that	O
is	O
negative	O
and	O
positive	O
they	O
will	O
simply	O
learn	O
to	O
always	O
predict	B
negative	O
why	O
because	O
beyond	O
binary	O
classification	O
they	O
are	O
trying	O
to	O
minimize	O
error	O
and	O
they	O
can	O
achieve	O
error	O
by	O
doing	O
nothing	O
if	O
a	O
teacher	O
told	O
you	O
to	O
study	O
for	O
an	O
exam	O
with	O
truefalse	O
questions	O
and	O
only	O
one	O
of	O
them	O
is	O
true	O
it	O
is	O
unlikely	O
you	O
will	O
study	O
very	O
long	O
really	O
the	O
problem	O
is	O
not	O
with	O
the	O
data	O
but	O
rather	O
with	O
the	O
way	O
that	O
you	O
have	O
defined	O
the	O
learning	O
problem	O
that	O
is	O
to	O
say	O
what	O
you	O
care	O
about	O
is	O
not	O
accuracy	O
you	O
care	O
about	O
something	O
else	O
if	O
you	O
want	O
a	O
learning	O
algorithm	B
to	O
do	O
a	O
reasonable	O
job	O
you	O
have	O
to	O
tell	O
it	O
what	O
you	O
want	O
most	O
likely	O
what	O
you	O
want	O
is	O
not	O
to	O
optimize	O
accuracy	O
but	O
rather	O
to	O
optimize	O
some	O
other	O
measure	O
like	O
f-score	O
or	O
auc	B
you	O
want	O
your	O
algorithm	B
to	O
make	O
some	O
positive	O
predictions	O
and	O
simply	O
prefer	O
those	O
to	O
be	O
good	O
we	O
will	O
shortly	O
discuss	O
two	O
heuristics	O
for	O
dealing	O
with	O
this	O
problem	O
subsampling	O
and	O
weighting	O
in	O
subsampling	O
you	O
throw	O
out	O
some	O
of	O
you	O
negative	O
examples	B
so	O
that	O
you	O
are	O
left	O
with	O
a	O
balanced	O
data	O
set	O
positive	O
negative	O
this	O
might	O
scare	O
you	O
a	O
bit	O
since	O
throwing	O
out	O
data	O
seems	O
like	O
a	O
bad	O
idea	O
but	O
at	O
least	O
it	O
makes	O
learning	O
much	O
more	O
efficient	O
in	O
weighting	O
instead	O
of	O
throwing	O
out	O
positive	O
examples	B
we	O
just	O
given	O
them	O
lower	O
weight	O
if	O
you	O
assign	O
an	O
importance	B
weight	I
of	O
to	O
each	O
of	O
the	O
positive	O
examples	B
then	O
there	O
will	O
be	O
as	O
much	O
weight	O
associated	O
with	O
positive	O
examples	B
as	O
negative	O
examples	B
before	O
formally	O
defining	O
these	O
heuristics	O
we	O
need	O
to	O
have	O
a	O
mech	O
anism	O
for	O
formally	O
defining	O
supervised	O
learning	O
problems	O
we	O
will	O
proceed	O
by	O
example	O
using	O
binary	O
classification	O
as	O
the	O
canonical	O
learning	O
problem	O
task	O
binary	O
classification	O
given	O
an	O
input	O
space	O
x	O
an	O
unknown	O
distribution	O
d	O
over	O
x	O
compute	O
a	O
function	O
f	O
minimizing	O
e	O
f	O
as	O
in	O
all	O
the	O
binary	O
classification	O
examples	B
you	O
ve	O
seen	O
you	O
have	O
some	O
input	O
space	O
has	O
always	O
been	O
rd	O
there	O
is	O
some	O
distribution	O
that	O
produces	O
labeled	O
examples	B
over	O
the	O
input	O
space	O
you	O
do	O
not	O
have	O
access	O
to	O
that	O
distribution	O
but	O
can	O
obtain	O
samples	O
from	O
it	O
your	O
goal	O
is	O
to	O
find	O
a	O
classifier	O
that	O
minimizes	O
error	O
on	O
that	O
distribution	O
a	O
small	O
modification	O
on	O
this	O
definition	O
gives	O
a	O
classification	O
problem	O
where	O
you	O
believe	O
that	O
the	O
positive	O
class	O
is	O
as	O
a	O
course	O
in	O
machine	O
learning	O
algorithm	B
subsamplemapdweighted	O
while	O
true	O
do	O
y	O
dweighted	O
u	O
uniform	O
random	O
variable	O
in	O
if	O
y	O
or	O
u	O
return	O
y	O
then	O
draw	O
an	O
example	O
from	O
the	O
weighted	O
distribution	O
end	O
if	O
end	O
while	O
important	O
as	O
the	O
negative	O
class	O
task	O
binary	O
classification	O
given	O
an	O
input	O
space	O
x	O
an	O
unknown	O
distribution	O
d	O
over	O
x	O
compute	O
a	O
function	O
f	O
minimizing	O
e	O
d	O
f	O
the	O
objects	O
given	O
to	O
you	O
in	O
weighted	O
binary	O
classification	O
are	O
iden	O
tical	O
to	O
standard	O
binary	O
classification	O
the	O
only	O
difference	O
is	O
that	O
the	O
cost	O
of	O
misprediction	O
for	O
y	O
is	O
while	O
the	O
cost	O
of	O
misprediction	O
for	O
y	O
is	O
in	O
what	O
follows	O
we	O
assume	O
that	O
if	O
it	O
is	O
not	O
you	O
can	O
simply	O
swap	O
the	O
labels	O
and	O
use	O
the	O
question	O
we	O
will	O
ask	O
is	O
suppose	O
that	O
i	O
have	O
a	O
good	O
algorithm	B
for	O
solving	O
the	O
binary	O
classification	O
problem	O
can	O
i	O
turn	O
that	O
into	O
a	O
good	O
algorithm	B
for	O
solving	O
the	O
binary	O
classification	O
problem	O
in	O
order	O
to	O
do	O
this	O
you	O
need	O
to	O
define	O
a	O
transformation	O
that	O
maps	O
a	O
concrete	O
weighted	O
problem	O
into	O
a	O
concrete	O
unweighted	O
problem	O
this	O
transformation	O
needs	O
to	O
happen	O
both	O
at	O
training	O
time	O
and	O
at	O
test	O
time	O
it	O
need	O
not	O
be	O
the	O
same	O
transformation	O
algorithm	B
sketches	O
a	O
training-time	O
sub-sampling	B
transformation	O
and	O
algorithm	B
sketches	O
a	O
test-time	O
transformation	O
in	O
this	O
case	O
is	O
trivial	O
all	O
the	O
training	O
algorithm	B
is	O
doing	O
is	O
retaining	O
all	O
positive	O
examples	B
and	O
a	O
fraction	O
of	O
all	O
negative	O
examples	B
the	O
algorithm	B
is	O
explicitly	O
turning	O
the	O
distribution	O
over	O
weighted	O
examples	B
into	O
a	O
distribution	O
over	O
binary	O
examples	B
a	O
vanilla	O
binary	O
classifier	O
is	O
trained	O
on	O
this	O
induced	B
distribution	I
aside	O
from	O
the	O
fact	O
that	O
this	O
algorithm	B
throws	O
out	O
a	O
lot	O
of	O
data	O
for	O
large	O
it	O
does	O
seem	O
to	O
be	O
doing	O
a	O
reasonable	O
thing	O
in	O
fact	O
from	O
a	O
reductions	B
perspective	O
it	O
is	O
an	O
optimal	O
algorithm	B
you	O
can	O
prove	O
the	O
following	O
result	O
beyond	O
binary	O
classification	O
why	O
is	O
it	O
unreasonable	O
to	O
expect	O
to	O
be	O
able	O
to	O
achieve	O
for	O
instance	O
an	O
error	O
of	O
sublinear	O
in	O
or	O
anything	O
that	O
is	O
theorem	O
optimality	O
suppose	O
the	O
binary	O
classifier	O
trained	O
in	O
algorithm	B
achieves	O
a	O
binary	O
error	B
rate	I
of	O
then	O
the	O
error	B
rate	I
of	O
the	O
weighted	O
predictor	O
is	O
equal	O
to	O
this	O
theorem	O
states	O
that	O
if	O
your	O
binary	O
classifier	O
does	O
well	O
the	O
induced	B
distribution	I
then	O
the	O
learned	O
predictor	O
will	O
also	O
do	O
well	O
the	O
original	O
distribution	O
thus	O
we	O
have	O
successfully	O
converted	O
a	O
weighted	O
learning	O
problem	O
into	O
a	O
plain	O
classification	O
problem	O
the	O
fact	O
that	O
the	O
error	B
rate	I
of	O
the	O
weighted	O
predictor	O
is	O
exactly	O
times	O
more	O
than	O
that	O
of	O
the	O
unweighted	O
predictor	O
is	O
unavoidable	O
the	O
error	O
metric	O
on	O
which	O
it	O
is	O
evaluated	O
is	O
times	O
bigger	O
the	O
proof	O
of	O
this	O
theorem	O
is	O
so	O
straightforward	O
that	O
we	O
will	O
prove	O
it	O
here	O
it	O
simply	O
involves	O
some	O
algebra	O
on	O
expected	O
values	O
proof	O
of	O
theorem	O
let	O
dw	O
be	O
the	O
original	O
distribution	O
and	O
let	O
db	O
be	O
the	O
induced	B
distribution	I
let	O
f	O
be	O
the	O
binary	O
classifier	O
trained	O
on	O
data	O
from	O
db	O
that	O
achieves	O
a	O
binary	O
error	B
rate	I
of	O
on	O
that	O
distribution	O
we	O
will	O
compute	O
the	O
expected	O
error	O
of	O
f	O
on	O
the	O
weighted	O
problem	O
f	O
dwx	O
y	O
f	O
f	O
dwx	O
f	O
f	O
dbx	O
f	O
f	O
dw	O
y	O
e	O
x	O
x	O
x	O
x	O
x	O
x	O
db	O
e	O
and	O
we	O
re	O
done	O
implicitly	O
assumed	O
x	O
is	O
discrete	O
in	O
the	O
case	O
of	O
continuous	O
data	O
you	O
need	O
to	O
replace	O
all	O
the	O
sums	O
over	O
x	O
with	O
integrals	O
over	O
x	O
but	O
the	O
result	O
still	O
holds	O
instead	O
of	O
subsampling	O
the	O
low-cost	O
class	O
you	O
could	O
alternatively	O
oversample	B
the	O
high-cost	O
class	O
the	O
easiest	O
case	O
is	O
when	O
is	O
an	O
integer	O
say	O
now	O
whenever	O
you	O
get	O
a	O
positive	O
point	O
you	O
include	O
copies	O
of	O
it	O
in	O
the	O
induced	B
distribution	I
whenever	O
you	O
get	O
a	O
negative	O
point	O
you	O
include	O
a	O
single	O
copy	O
this	O
oversampling	O
algorithm	B
achieves	O
exactly	O
the	O
same	O
theoretical	O
result	O
as	O
the	O
subsampling	O
algorithm	B
the	O
main	O
advantage	O
to	O
the	O
oversampling	O
algorithm	B
is	O
that	O
it	O
does	O
not	O
throw	O
out	O
any	O
data	O
the	O
main	O
advantage	O
to	O
the	O
subsampling	O
algorithm	B
is	O
that	O
it	O
is	O
more	O
computationally	O
efficient	O
how	O
can	O
you	O
handle	O
non-integral	O
for	O
instance	O
modify	O
the	O
proof	O
of	O
optimality	O
for	O
the	O
subsampling	O
algorithm	B
so	O
that	O
it	O
applies	O
to	O
the	O
oversampling	O
algorithm	B
a	O
course	O
in	O
machine	O
learning	O
you	O
might	O
be	O
asking	O
yourself	O
intuitively	O
the	O
oversampling	O
algo	O
rithm	O
seems	O
like	O
a	O
much	O
better	O
idea	O
than	O
the	O
subsampling	O
algorithm	B
at	O
least	O
if	O
you	O
don	O
t	O
care	O
about	O
computational	O
efficiency	O
but	O
the	O
theory	O
tells	O
us	O
that	O
they	O
are	O
the	O
same	O
what	O
is	O
going	O
on	O
of	O
course	O
the	O
theory	O
isn	O
t	O
wrong	O
it	O
s	O
just	O
that	O
the	O
assumptions	O
are	O
effectively	O
different	O
in	O
the	O
two	O
cases	O
both	O
theorems	O
state	O
that	O
if	O
you	O
can	O
get	O
error	O
of	O
on	O
the	O
binary	O
problem	O
you	O
automatically	O
get	O
error	O
of	O
on	O
the	O
weighted	O
problem	O
but	O
they	O
do	O
not	O
say	O
anything	O
about	O
how	O
possible	O
it	O
is	O
to	O
get	O
error	O
on	O
the	O
binary	O
problem	O
since	O
the	O
oversampling	O
algorithm	B
produces	O
more	O
data	O
points	O
than	O
the	O
subsampling	O
algorithm	B
it	O
is	O
very	O
concievable	O
that	O
you	O
could	O
get	O
lower	O
binary	O
error	O
with	O
oversampling	O
than	O
subsampling	O
the	O
primary	O
drawback	O
to	O
oversampling	O
is	O
computational	O
ineffi	O
ciency	O
however	O
for	O
many	O
learning	O
algorithms	O
it	O
is	O
straightforward	O
to	O
include	O
weighted	O
copies	O
of	O
data	O
points	O
at	O
no	O
cost	O
the	O
idea	O
is	O
to	O
store	O
only	O
the	O
unique	O
data	O
points	O
and	O
maintain	O
a	O
counter	O
saying	O
how	O
many	O
times	O
they	O
are	O
replicated	O
this	O
is	O
not	O
easy	O
to	O
do	O
for	O
the	O
perceptron	B
can	O
be	O
done	O
but	O
takes	O
work	O
but	O
it	O
is	O
easy	O
for	O
both	O
decision	B
trees	I
and	O
knn	O
for	O
example	O
for	O
decision	B
trees	I
algorithm	B
the	O
only	O
changes	O
are	O
to	O
ensure	O
that	O
line	O
computes	O
the	O
most	O
frequent	O
weighted	O
answer	O
and	O
change	O
lines	O
and	O
to	O
compute	O
weighted	O
errors	O
multiclass	O
classification	O
multiclass	O
classification	O
is	O
a	O
natural	O
extension	O
of	O
binary	O
classification	O
the	O
goal	O
is	O
still	O
to	O
assign	O
a	O
discrete	O
label	B
to	O
examples	B
instance	O
is	O
a	O
document	O
about	O
entertainment	O
sports	O
finance	O
or	O
world	O
news	O
the	O
difference	O
is	O
that	O
you	O
have	O
k	O
classes	O
to	O
choose	O
from	O
task	O
multiclass	O
classification	O
given	O
an	O
input	O
space	O
x	O
and	O
number	O
of	O
classes	O
k	O
an	O
unknown	O
distribution	O
d	O
over	O
x	O
compute	O
a	O
function	O
f	O
minimizing	O
e	O
f	O
note	O
that	O
this	O
is	O
identical	O
to	O
binary	O
classification	O
except	O
for	O
the	O
presence	O
of	O
k	O
classes	O
the	O
above	O
k	O
in	O
fact	O
if	O
you	O
set	O
k	O
you	O
exactly	O
recover	O
binary	O
classification	O
the	O
game	O
we	O
play	O
is	O
the	O
same	O
someone	O
gives	O
you	O
a	O
binary	O
classifier	O
and	O
you	O
have	O
to	O
use	O
it	O
to	O
solve	O
the	O
multiclass	O
classification	O
prob	O
why	O
is	O
it	O
hard	O
to	O
change	O
the	O
perceptron	B
it	O
has	O
to	O
do	O
with	O
the	O
fact	O
that	O
perceptron	B
is	O
online	B
how	O
would	O
you	O
modify	O
knn	O
to	O
take	O
into	O
account	O
weights	B
beyond	O
binary	O
classification	O
algorithm	B
oneversusalltraindmulticlass	O
binarytrain	O
for	O
i	O
to	O
k	O
do	O
dbin	O
relabel	O
dmulticlass	O
so	O
class	O
i	O
is	O
positive	O
and	O
i	O
is	O
negative	O
fi	O
binarytraindbin	O
end	O
for	O
return	O
fk	O
algorithm	B
oneversusalltest	O
fk	O
x	O
score	O
for	O
i	O
to	O
k	O
do	O
y	O
fi	O
x	O
scorei	O
scorei	O
y	O
end	O
for	O
return	O
argmaxk	O
scorek	O
initialize	O
k-many	O
scores	O
to	O
zero	O
lem	O
a	O
very	O
common	O
approach	O
is	O
the	O
one	B
versus	I
all	I
technique	O
called	O
ova	B
or	O
one	B
versus	I
rest	I
to	O
perform	O
ova	B
you	O
train	O
k-many	O
binary	O
classifiers	O
fk	O
each	O
classifier	O
sees	O
all	O
of	O
the	O
training	B
data	I
classifier	O
fi	O
receives	O
all	O
examples	B
labeled	O
class	O
i	O
as	O
positives	O
and	O
all	O
other	O
examples	B
as	O
negatives	O
at	O
test	O
time	O
whichever	O
classifier	O
predicts	O
positive	O
wins	O
with	O
ties	O
broken	O
randomly	O
the	O
training	O
and	O
test	O
algorithms	O
for	O
ova	B
are	O
sketched	O
in	O
algo	O
rithms	O
and	O
in	O
the	O
testing	O
procedure	O
the	O
prediction	O
of	O
the	O
ith	O
classifier	O
is	O
added	O
to	O
the	O
overall	O
score	O
for	O
class	O
i	O
thus	O
if	O
the	O
prediction	O
is	O
positive	O
class	O
i	O
gets	O
a	O
vote	B
if	O
the	O
prdiction	O
is	O
negative	O
everyone	O
else	O
gets	O
a	O
vote	B
fact	O
if	O
your	O
learning	O
algorithm	B
can	O
output	O
a	O
confidence	O
as	O
discussed	O
in	O
section	O
you	O
can	O
often	O
do	O
better	O
by	O
using	O
the	O
confidence	O
as	O
y	O
rather	O
than	O
a	O
simple	O
ova	B
is	O
very	O
natural	O
easy	O
to	O
implement	O
and	O
quite	O
natural	O
it	O
also	O
works	O
very	O
well	O
in	O
practice	O
so	O
long	O
as	O
you	O
do	O
a	O
good	O
job	O
choosing	O
a	O
good	O
binary	O
classification	O
algorithm	B
tuning	O
its	O
hyperparameters	O
well	O
its	O
weakness	O
is	O
that	O
it	O
can	O
be	O
somewhat	O
brittle	O
intuitively	O
it	O
is	O
not	O
particularly	O
robust	O
to	O
errors	O
in	O
the	O
underlying	O
classifiers	O
if	O
one	O
classifier	O
makes	O
a	O
mistake	O
it	O
eis	O
possible	O
that	O
the	O
entire	O
prediction	O
is	O
erroneous	O
in	O
fact	O
it	O
is	O
entirely	O
possible	O
that	O
none	O
of	O
the	O
k	O
classifiers	O
predicts	O
positive	O
is	O
actually	O
the	O
worst-case	O
scenario	O
from	O
a	O
theoretical	O
perspective	O
this	O
is	O
made	O
explicit	O
in	O
the	O
ova	B
error	O
bound	O
below	O
theorem	O
error	O
bound	O
suppose	O
the	O
average	O
binary	O
error	O
of	O
the	O
k	O
binary	O
classifiers	O
is	O
then	O
the	O
error	B
rate	I
of	O
the	O
ova	B
multiclass	O
predictor	O
is	O
at	O
most	O
proof	O
of	O
theorem	O
the	O
key	O
question	O
is	O
erroneous	O
predictions	O
from	O
the	O
binary	O
classifiers	O
lead	O
to	O
multiclass	O
errors	O
we	O
break	O
it	O
down	O
into	O
false	O
negatives	O
when	O
the	O
truth	O
is	O
and	O
false	O
positives	O
suppose	O
that	O
you	O
have	O
n	O
data	O
points	O
in	O
k	O
classes	O
evenly	O
divided	O
how	O
long	O
does	O
it	O
take	O
to	O
train	O
an	O
ova	B
classifier	O
if	O
the	O
base	O
binary	O
classifier	O
takes	O
on	O
time	O
to	O
train	O
what	O
if	O
the	O
base	O
classifier	O
takes	O
time	O
why	O
would	O
using	O
a	O
confidence	O
help	O
a	O
course	O
in	O
machine	O
learning	O
when	O
the	O
truth	O
is	O
when	O
a	O
false	O
negative	O
occurs	O
then	O
the	O
testing	O
procedure	O
chooses	O
randomly	O
between	O
available	O
options	O
which	O
is	O
all	O
labels	O
this	O
gives	O
a	O
probability	O
of	O
multiclass	O
error	O
since	O
only	O
one	O
binary	O
error	O
is	O
necessary	O
to	O
make	O
this	O
happen	O
the	O
efficiency	O
of	O
this	O
error	O
mode	O
is	O
multiple	O
false	O
positives	O
can	O
occur	O
simultaneously	O
suppose	O
there	O
are	O
m	O
false	O
positives	O
if	O
there	O
is	O
simultaneously	O
a	O
false	O
negative	O
the	O
error	O
is	O
in	O
order	O
for	O
this	O
to	O
happen	O
there	O
have	O
to	O
be	O
m	O
errors	O
so	O
the	O
efficiency	O
is	O
in	O
the	O
case	O
that	O
there	O
is	O
not	O
a	O
simultaneous	O
false	O
negative	O
the	O
error	O
probability	O
is	O
mm	O
this	O
requires	O
m	O
errors	O
leading	O
to	O
an	O
efficiency	O
of	O
the	O
worse	O
case	O
therefore	O
is	O
the	O
false	O
negative	O
case	O
which	O
gives	O
an	O
efficiency	O
of	O
since	O
we	O
have	O
k-many	O
opportunities	O
to	O
err	O
we	O
multiply	O
this	O
by	O
k	O
and	O
get	O
a	O
bound	O
of	O
the	O
constants	O
in	O
this	O
are	O
relatively	O
unimportant	O
the	O
aspect	O
that	O
matters	O
is	O
that	O
this	O
scales	O
linearly	O
in	O
k	O
that	O
is	O
as	O
the	O
number	O
of	O
classes	O
grows	O
so	O
does	O
your	O
expected	O
error	O
to	O
develop	O
alternative	O
approaches	O
a	O
useful	O
way	O
to	O
think	O
about	O
turning	O
multiclass	O
classification	O
problems	O
into	O
binary	O
classification	O
problems	O
is	O
to	O
think	O
of	O
them	O
like	O
tournaments	O
soccer	O
aka	O
football	O
cricket	O
tennis	O
or	O
whatever	O
appeals	O
to	O
you	O
you	O
have	O
k	O
teams	O
entering	O
a	O
tournament	O
but	O
unfortunately	O
the	O
sport	O
they	O
are	O
playing	O
only	O
allows	O
two	O
to	O
compete	O
at	O
a	O
time	O
you	O
want	O
to	O
set	O
up	O
a	O
way	O
of	O
pairing	O
the	O
teams	O
and	O
having	O
them	O
compete	O
so	O
that	O
you	O
can	O
figure	O
out	O
which	O
team	O
is	O
best	O
in	O
learning	O
the	O
teams	O
are	O
now	O
the	O
classes	O
and	O
you	O
re	O
trying	O
to	O
figure	O
out	O
which	O
class	O
is	O
one	O
natural	O
approach	O
is	O
to	O
have	O
every	O
team	O
compete	O
against	O
ev	O
ery	O
other	O
team	O
the	O
team	O
that	O
wins	O
the	O
majority	O
of	O
its	O
matches	O
is	O
declared	O
the	O
winner	O
this	O
is	O
the	O
all	B
versus	I
all	I
ava	B
approach	O
called	O
all	B
pairs	I
the	O
most	O
natural	O
way	O
to	O
think	O
about	O
it	O
classifiers	O
say	O
fij	O
for	O
i	O
j	O
k	O
is	O
the	O
classifier	O
is	O
as	O
training	O
that	O
pits	O
class	O
i	O
against	O
class	O
j	O
this	O
classifier	O
receives	O
all	O
of	O
the	O
class	O
i	O
examples	B
as	O
positive	O
and	O
all	O
of	O
the	O
class	O
j	O
examples	B
as	O
negative	O
when	O
a	O
test	O
point	O
arrives	O
it	O
is	O
run	O
through	O
all	O
fij	O
classifiers	O
every	O
time	O
fij	O
predicts	O
positive	O
class	O
i	O
gets	O
a	O
point	O
otherwise	O
class	O
j	O
gets	O
a	O
point	O
after	O
running	O
all	O
classifiers	O
the	O
class	O
with	O
the	O
most	O
votes	O
wins	O
the	O
training	O
and	O
test	O
algorithms	O
for	O
ava	B
are	O
sketched	O
in	O
algo	O
rithms	O
and	O
in	O
theory	O
the	O
ava	B
mapping	O
is	O
more	O
complicated	O
than	O
the	O
weighted	O
binary	O
case	O
the	O
result	O
is	O
stated	O
below	O
but	O
the	O
proof	O
is	O
omitted	O
theorem	O
error	O
bound	O
suppose	O
the	O
average	O
binary	O
error	O
of	O
the	O
sporting	O
analogy	O
breaks	O
down	O
a	O
bit	O
for	O
ova	B
k	O
games	O
are	O
played	O
wherein	O
each	O
team	O
will	O
play	O
simultaneously	O
against	O
all	O
other	O
teams	O
suppose	O
that	O
you	O
have	O
n	O
data	O
points	O
in	O
k	O
classes	O
evenly	O
divided	O
how	O
long	O
does	O
it	O
take	O
to	O
train	O
an	O
ava	B
classifier	O
if	O
the	O
base	O
binary	O
classifier	O
takes	O
on	O
time	O
to	O
train	O
what	O
if	O
the	O
base	O
classifier	O
takes	O
time	O
how	O
does	O
this	O
compare	O
to	O
ova	B
beyond	O
binary	O
classification	O
algorithm	B
allversusalltraindmulticlass	O
binarytrain	O
fij	O
i	O
j	O
k	O
for	O
i	O
to	O
do	O
dpos	O
all	O
x	O
dmulticlass	O
labeled	O
i	O
for	O
j	O
to	O
k	O
do	O
dneg	O
all	O
x	O
dmulticlass	O
labeled	O
j	O
dbin	O
x	O
dpos	O
x	O
dneg	O
fij	O
binarytraindbin	O
end	O
for	O
end	O
for	O
return	O
all	O
fijs	O
algorithm	B
allversusalltestall	O
fij	O
x	O
score	O
for	O
i	O
to	O
do	O
initialize	O
k-many	O
scores	O
to	O
zero	O
for	O
j	O
to	O
k	O
do	O
y	O
fij	O
x	O
scorei	O
scorei	O
y	O
scorej	O
scorej	O
y	O
end	O
for	O
end	O
for	O
return	O
argmaxk	O
scorek	O
binary	O
classifiers	O
is	O
then	O
the	O
error	B
rate	I
of	O
the	O
ava	B
multiclass	O
the	O
predictor	O
is	O
at	O
most	O
at	O
this	O
point	O
you	O
might	O
be	O
wondering	O
if	O
it	O
s	O
possible	O
to	O
do	O
better	O
than	O
something	O
linear	O
in	O
k	O
fortunately	O
the	O
answer	O
is	O
yes	O
the	O
solution	O
like	O
so	O
much	O
in	O
computer	O
science	O
is	O
divide	O
and	O
conquer	O
the	O
idea	O
is	O
to	O
construct	O
a	O
binary	O
tree	O
of	O
classifiers	O
the	O
leaves	O
of	O
this	O
tree	O
correspond	O
to	O
the	O
k	O
labels	O
since	O
there	O
are	O
only	O
k	O
decisions	O
made	O
to	O
get	O
from	O
the	O
root	O
to	O
a	O
leaf	O
then	O
there	O
are	O
only	O
k	O
chances	O
to	O
make	O
an	O
error	O
an	O
example	O
of	O
a	O
classification	O
tree	O
for	O
k	O
classes	O
is	O
shown	O
in	O
figure	O
at	O
the	O
root	O
you	O
distinguish	O
between	O
classes	O
and	O
classes	O
this	O
means	O
that	O
you	O
will	O
train	O
a	O
binary	O
classifier	O
whose	O
positive	O
examples	B
are	O
all	O
data	O
points	O
with	O
multiclass	O
label	B
and	O
whose	O
negative	O
examples	B
are	O
all	O
data	O
points	O
with	O
multiclass	O
label	B
based	O
on	O
what	O
decision	O
is	O
made	O
by	O
this	O
classifier	O
you	O
can	O
walk	O
down	O
the	O
appropriate	O
path	O
in	O
the	O
tree	O
when	O
k	O
is	O
not	O
a	O
powwr	O
of	O
the	O
tree	O
will	O
not	O
be	O
full	O
this	O
classification	O
tree	O
algorithm	B
achieves	O
the	O
following	O
bound	O
theorem	O
error	O
bound	O
suppose	O
the	O
average	O
binary	O
classifiers	O
error	O
is	O
then	O
the	O
error	B
rate	I
of	O
the	O
tree	O
classifier	O
is	O
at	O
most	O
proof	O
of	O
theorem	O
a	O
multiclass	O
error	O
is	O
made	O
if	O
any	O
classifier	O
on	O
the	O
bound	O
for	O
ava	B
is	O
the	O
bound	O
for	O
ova	B
is	O
does	O
this	O
mean	O
that	O
ova	B
is	O
necessarily	O
better	O
than	O
ava	B
why	O
or	O
why	O
not	O
figure	O
data	O
set	O
on	O
which	O
ova	B
will	O
do	O
terribly	O
with	O
linear	B
classifiers	I
consider	O
the	O
data	O
in	O
figure	O
and	O
assume	O
that	O
you	O
are	O
using	O
a	O
perceptron	B
as	O
the	O
base	O
classifier	O
how	O
well	O
will	O
ova	B
do	O
on	O
this	O
data	O
what	O
about	O
ava	B
a	O
course	O
in	O
machine	O
learning	O
the	O
path	O
from	O
the	O
root	O
to	O
the	O
correct	O
leaf	O
makes	O
an	O
error	O
each	O
has	O
probability	O
of	O
making	O
an	O
error	O
and	O
the	O
path	O
consists	O
of	O
at	O
most	O
binary	O
decisions	O
one	O
think	O
to	O
keep	O
in	O
mind	O
with	O
tree	O
classifiers	O
is	O
that	O
you	O
have	O
control	O
over	O
how	O
the	O
tree	O
is	O
defined	O
in	O
ova	B
and	O
ava	B
you	O
have	O
no	O
say	O
in	O
what	O
classification	O
problems	O
are	O
created	O
in	O
tree	O
classifiers	O
the	O
only	O
thing	O
that	O
matters	O
is	O
that	O
at	O
the	O
root	O
half	O
of	O
the	O
classes	O
are	O
considered	O
positive	O
and	O
half	O
are	O
considered	O
negative	O
you	O
want	O
to	O
split	O
the	O
classes	O
in	O
such	O
a	O
way	O
that	O
this	O
classification	O
decision	O
is	O
as	O
easy	O
as	O
possible	O
you	O
can	O
use	O
whatever	O
you	O
happen	O
to	O
know	O
about	O
your	O
classification	O
problem	O
to	O
try	O
to	O
separate	O
the	O
classes	O
out	O
in	O
a	O
reasonable	O
way	O
can	O
you	O
do	O
better	O
than	O
it	O
turns	O
out	O
the	O
answer	O
is	O
yes	O
but	O
the	O
algorithms	O
to	O
do	O
so	O
are	O
relatively	O
complicated	O
you	O
can	O
actually	O
do	O
as	O
well	O
as	O
using	O
the	O
idea	O
of	O
error-correcting	O
tournaments	O
moreover	O
you	O
can	O
prove	O
a	O
lower	O
bound	O
that	O
states	O
that	O
the	O
best	O
you	O
could	O
possible	O
do	O
is	O
this	O
means	O
that	O
error-correcting	O
tournaments	O
are	O
at	O
most	O
a	O
factor	O
of	O
four	O
worse	O
than	O
optimal	O
ranking	O
you	O
start	O
a	O
new	O
web	O
search	O
company	O
called	O
goohooing	O
like	O
other	O
search	O
engines	O
a	O
user	O
inputs	O
a	O
query	O
and	O
a	O
set	O
of	O
documents	O
is	O
retrieved	O
your	O
goal	O
is	O
to	O
rank	O
the	O
resulting	O
documents	O
based	O
on	O
relevance	O
to	O
the	O
query	O
the	O
ranking	O
problem	O
is	O
to	O
take	O
a	O
collection	O
of	O
items	O
and	O
sort	O
them	O
according	O
to	O
some	O
notion	O
of	O
preference	O
one	O
of	O
the	O
trickiest	O
parts	O
of	O
doing	O
ranking	O
through	O
learning	O
is	O
to	O
properly	O
define	O
the	O
loss	B
function	I
toward	O
the	O
end	O
of	O
this	O
section	O
you	O
will	O
see	O
a	O
very	O
general	O
loss	B
function	I
but	O
before	O
that	O
let	O
s	O
consider	O
a	O
few	O
special	O
cases	O
continuing	O
the	O
web	O
search	O
example	O
you	O
are	O
given	O
a	O
collection	O
of	O
queries	O
for	O
each	O
query	O
you	O
are	O
also	O
given	O
a	O
collection	O
of	O
documents	O
together	O
with	O
a	O
desired	O
ranking	O
over	O
those	O
documents	O
in	O
the	O
following	O
we	O
ll	O
assume	O
that	O
you	O
have	O
n-many	O
queries	O
and	O
for	O
each	O
query	O
you	O
have	O
m-many	O
documents	O
practice	O
m	O
will	O
probably	O
vary	O
by	O
query	O
but	O
for	O
ease	O
we	O
ll	O
consider	O
the	O
simplified	O
case	O
the	O
goal	O
is	O
to	O
train	O
a	O
binary	O
classifier	O
to	O
predict	B
a	O
preference	B
function	I
given	O
a	O
query	O
q	O
and	O
two	O
documents	O
di	O
and	O
dj	O
the	O
classifier	O
should	O
predict	B
whether	O
di	O
should	O
be	O
preferred	O
to	O
dj	O
with	O
respect	O
to	O
the	O
query	O
q	O
as	O
in	O
all	O
the	O
previous	O
examples	B
there	O
are	O
two	O
things	O
we	O
have	O
to	O
take	O
care	O
of	O
how	O
to	O
train	O
the	O
classifier	O
that	O
predicts	O
preferences	O
how	O
to	O
turn	O
the	O
predicted	O
preferences	O
into	O
a	O
ranking	O
unlike	O
the	O
previous	O
examples	B
the	O
second	O
step	O
is	O
somewhat	O
complicated	O
in	O
the	O
beyond	O
binary	O
classification	O
algorithm	B
naiveranktrainrankingdata	O
binarytrain	O
d	O
for	O
n	O
to	O
n	O
do	O
for	O
all	O
i	O
j	O
to	O
m	O
and	O
i	O
j	O
do	O
if	O
i	O
is	O
prefered	O
to	O
j	O
on	O
query	O
n	O
then	O
d	O
d	O
d	O
d	O
else	O
if	O
j	O
is	O
prefered	O
to	O
i	O
on	O
query	O
n	O
then	O
end	O
if	O
end	O
for	O
end	O
for	O
return	O
binarytraind	O
algorithm	B
naiveranktest	O
f	O
x	O
score	O
for	O
all	O
i	O
j	O
to	O
m	O
and	O
i	O
j	O
do	O
y	O
f	O
xij	O
scorei	O
scorei	O
y	O
scorej	O
scorej	O
y	O
end	O
for	O
return	O
argsortscore	O
initialize	O
m-many	O
scores	O
to	O
zero	O
get	O
predicted	O
ranking	O
of	O
i	O
and	O
j	O
return	O
queries	O
sorted	O
by	O
score	O
ranking	O
case	O
this	O
is	O
because	O
we	O
need	O
to	O
predict	B
an	O
entire	O
ranking	O
of	O
a	O
large	O
number	O
of	O
documents	O
somehow	O
assimilating	O
the	O
preference	B
function	I
into	O
an	O
overall	O
permutation	O
for	O
notationally	O
simplicity	O
let	O
xnij	O
denote	O
the	O
features	B
associated	O
with	O
comparing	O
document	O
i	O
to	O
document	O
j	O
on	O
query	O
n	O
training	O
is	O
fairly	O
straightforward	O
for	O
every	O
n	O
and	O
every	O
pair	O
i	O
j	O
we	O
will	O
create	O
a	O
binary	O
classification	O
example	O
based	O
on	O
features	B
xnij	O
this	O
example	O
is	O
positive	O
if	O
i	O
is	O
preferred	O
to	O
j	O
in	O
the	O
true	O
ranking	O
it	O
is	O
negative	O
if	O
j	O
is	O
preferred	O
to	O
i	O
some	O
cases	O
the	O
true	O
ranking	O
will	O
not	O
express	O
a	O
preference	O
between	O
two	O
objects	O
in	O
which	O
case	O
we	O
exclude	O
the	O
i	O
j	O
and	O
j	O
i	O
pair	O
from	O
training	O
now	O
you	O
might	O
be	O
tempted	O
to	O
evaluate	O
the	O
classification	O
perfor	O
mance	O
of	O
this	O
binary	O
classifier	O
on	O
its	O
own	O
the	O
problem	O
with	O
this	O
approach	O
is	O
that	O
it	O
s	O
impossible	O
to	O
tell	O
just	O
by	O
looking	O
at	O
its	O
output	O
on	O
one	O
i	O
j	O
pair	O
how	O
good	O
the	O
overall	O
ranking	O
is	O
this	O
is	O
because	O
there	O
is	O
the	O
intermediate	O
step	O
of	O
turning	O
these	O
pairwise	O
predictions	O
into	O
a	O
coherent	O
ranking	O
what	O
you	O
need	O
to	O
do	O
is	O
measure	O
how	O
well	O
the	O
ranking	O
based	O
on	O
your	O
predicted	O
preferences	O
compares	O
to	O
the	O
true	O
ordering	O
algorithms	O
and	O
show	O
naive	O
algorithms	O
for	O
training	O
and	O
testing	O
a	O
ranking	O
function	O
these	O
algorithms	O
actually	O
work	O
quite	O
well	O
in	O
the	O
case	O
of	O
bipartite	B
ranking	I
problems	I
a	O
bipartite	O
ranking	O
problem	O
is	O
one	O
in	O
which	O
you	O
are	O
only	O
ever	O
trying	O
to	O
predict	B
a	O
binary	O
response	O
for	O
instance	O
is	O
this	O
a	O
course	O
in	O
machine	O
learning	O
document	O
relevant	O
or	O
not	O
but	O
are	O
being	O
evaluated	O
according	O
to	O
a	O
metric	O
like	O
auc	B
this	O
is	O
essentially	O
because	O
the	O
only	O
goal	O
in	O
bipartite	O
problems	O
to	O
to	O
ensure	O
that	O
all	O
the	O
relevant	O
documents	O
are	O
ahead	O
of	O
all	O
the	O
irrelevant	O
documents	O
there	O
is	O
no	O
notion	O
that	O
one	O
relevant	O
document	O
is	O
more	O
relevant	O
than	O
another	O
for	O
non-bipartite	O
ranking	O
problems	O
you	O
can	O
do	O
better	O
first	O
when	O
the	O
preferences	O
that	O
you	O
get	O
at	O
training	O
time	O
are	O
more	O
nuanced	O
than	O
relevant	O
or	O
not	O
you	O
can	O
incorporate	O
these	O
preferences	O
at	O
training	O
time	O
effectively	O
you	O
want	O
to	O
give	O
a	O
higher	O
weight	O
to	O
binary	O
problems	O
that	O
are	O
very	O
different	O
in	O
terms	O
of	O
perference	O
than	O
others	O
second	O
rather	O
than	O
producing	O
a	O
list	O
of	O
scores	O
and	O
then	O
calling	O
an	O
arbitrary	O
sorting	O
algorithm	B
you	O
can	O
actually	O
use	O
the	O
preference	B
function	I
as	O
the	O
sorting	O
function	O
inside	O
your	O
own	O
implementation	O
of	O
quicksort	O
we	O
can	O
now	O
formalize	O
the	O
problem	O
define	O
a	O
ranking	O
as	O
a	O
function	O
that	O
maps	O
the	O
objects	O
we	O
are	O
ranking	O
to	O
the	O
desired	O
position	O
in	O
the	O
list	O
m	O
if	O
u	O
v	O
then	O
u	O
is	O
preferred	O
to	O
v	O
appears	O
earlier	O
on	O
the	O
ranked	O
document	O
list	O
given	O
data	O
with	O
observed	O
rankings	O
our	O
goal	O
is	O
to	O
learn	O
to	O
predict	B
rankings	O
for	O
new	O
objects	O
we	O
define	O
m	O
as	O
the	O
set	O
of	O
all	O
ranking	O
functions	O
over	O
m	O
objects	O
we	O
also	O
wish	O
to	O
express	O
the	O
fact	O
that	O
making	O
a	O
mistake	O
on	O
some	O
pairs	O
is	O
worse	O
than	O
making	O
a	O
mistake	O
on	O
others	O
this	O
will	O
be	O
encoded	O
in	O
a	O
cost	O
function	O
where	O
j	O
is	O
the	O
cost	O
for	O
accidentally	O
putting	O
something	O
in	O
position	O
j	O
when	O
it	O
should	O
have	O
gone	O
in	O
position	O
i	O
to	O
be	O
a	O
valid	O
cost	O
function	O
valid	O
must	O
be	O
symmetric	O
monotonic	O
and	O
satisfy	O
the	O
triangle	O
inequality	O
namely	O
j	O
i	O
if	O
i	O
j	O
k	O
or	O
i	O
j	O
k	O
then	O
j	O
k	O
j	O
k	O
k	O
with	O
these	O
definitions	O
we	O
can	O
properly	O
define	O
the	O
ranking	O
problem	O
task	O
given	O
an	O
input	O
space	O
x	O
an	O
unknown	O
distribution	O
d	O
over	O
x	O
m	O
compute	O
a	O
function	O
f	O
x	O
m	O
minimizing	O
e	O
d	O
u	O
v	O
v	O
u	O
u	O
v	O
where	O
f	O
in	O
this	O
definition	O
the	O
only	O
complex	O
aspect	O
is	O
the	O
loss	B
function	I
this	O
loss	O
sums	O
over	O
all	B
pairs	I
of	O
objects	O
u	O
and	O
v	O
if	O
the	O
true	O
ranking	O
beyond	O
binary	O
classification	O
algorithm	B
ranktraindrank	O
binarytrain	O
dbin	O
for	O
all	O
drank	O
do	O
for	O
all	O
u	O
v	O
do	O
y	O
sign	B
v	O
u	O
w	O
u	O
v	O
dbin	O
dbin	O
w	O
xuv	O
end	O
for	O
end	O
for	O
return	O
binarytraindbin	O
y	O
is	O
if	O
u	O
is	O
prefered	O
to	O
v	O
w	O
is	O
the	O
cost	O
of	O
misclassification	O
prefers	O
u	O
to	O
v	O
but	O
the	O
predicted	O
ranking	O
prefers	O
v	O
to	O
u	O
then	O
you	O
incur	O
a	O
cost	O
of	O
u	O
v	O
depending	O
on	O
the	O
problem	O
you	O
care	O
about	O
you	O
can	O
set	O
to	O
many	O
standard	O
options	O
if	O
j	O
whenever	O
i	O
j	O
then	O
you	O
achieve	O
the	O
kemeny	O
distance	B
measure	O
which	O
simply	O
counts	O
the	O
number	O
of	O
pairwise	O
misordered	O
items	O
in	O
many	O
applications	O
you	O
may	O
only	O
care	O
about	O
getting	O
the	O
top	O
k	O
predictions	O
correct	O
for	O
instance	O
your	O
web	O
search	O
algorithm	B
may	O
only	O
display	O
k	O
results	O
to	O
a	O
user	O
in	O
this	O
case	O
you	O
can	O
define	O
j	O
if	O
mini	O
j	O
k	O
and	O
i	O
j	O
otherwise	O
in	O
this	O
case	O
only	O
errors	O
in	O
the	O
top	O
k	O
elements	O
are	O
penalized	O
swapping	O
items	O
and	O
is	O
irrelevant	O
k	O
finally	O
in	O
the	O
bipartite	O
ranking	O
case	O
you	O
can	O
express	O
the	O
area	B
under	I
the	I
curve	I
metric	O
as	O
j	O
mm	O
m	O
if	O
i	O
m	O
and	O
j	O
m	O
if	O
j	O
m	O
and	O
i	O
m	O
otherwise	O
here	O
m	O
is	O
the	O
total	O
number	O
of	O
objects	O
to	O
be	O
ranked	O
and	O
m	O
is	O
the	O
number	O
that	O
are	O
actually	O
good	O
m	O
m	O
is	O
the	O
number	O
that	O
are	O
actually	O
bad	O
since	O
this	O
is	O
a	O
bipartite	O
problem	O
you	O
are	O
only	O
penalized	O
if	O
you	O
rank	O
a	O
good	O
item	O
in	O
position	O
greater	O
than	O
m	O
or	O
if	O
you	O
rank	O
a	O
bad	O
item	O
in	O
a	O
position	O
less	O
than	O
or	O
equal	O
to	O
m	O
in	O
order	O
to	O
solve	O
this	O
problem	O
you	O
can	O
follow	O
a	O
recipe	O
similar	O
to	O
the	O
naive	O
approach	O
sketched	O
earlier	O
at	O
training	O
time	O
the	O
biggest	O
change	O
is	O
that	O
you	O
can	O
weight	O
each	O
training	O
example	O
by	O
how	O
bad	O
it	O
would	O
be	O
to	O
mess	O
it	O
up	O
this	O
change	O
is	O
depicted	O
in	O
algorithm	B
where	O
the	O
binary	O
classiciation	O
data	O
has	O
weights	B
w	O
provided	O
for	O
saying	O
how	O
important	O
a	O
given	O
example	O
is	O
these	O
weights	B
are	O
derived	O
from	O
the	O
cost	O
function	O
at	O
test	O
time	O
instead	O
of	O
predicting	O
scores	O
and	O
then	O
sorting	O
the	O
list	O
you	O
essentially	O
run	O
the	O
quicksort	O
algorith	O
using	O
f	O
as	O
a	O
comparison	O
a	O
course	O
in	O
machine	O
learning	O
algorithm	B
ranktest	O
f	O
x	O
obj	O
if	O
obj	O
contains	O
or	O
elements	O
then	O
else	O
return	O
obj	O
p	O
randomly	O
chosen	O
object	O
in	O
obj	O
left	O
right	O
for	O
all	O
u	O
obj	O
do	O
end	O
if	O
left	O
left	O
u	O
right	O
right	O
u	O
else	O
end	O
if	O
end	O
for	O
left	O
ranktest	O
f	O
x	O
left	O
right	O
ranktest	O
f	O
x	O
right	O
return	O
left	O
right	O
pick	O
pivot	O
elements	O
that	O
seem	O
smaller	O
than	O
p	O
elements	O
that	O
seem	O
larger	O
than	O
p	O
y	O
f	O
if	O
uniform	O
random	O
variable	O
y	O
then	O
what	O
is	O
the	O
probability	O
that	O
u	O
precedes	O
p	O
sort	O
earlier	O
elements	O
sort	O
later	O
elements	O
function	O
at	O
each	O
step	O
in	O
algorithm	B
a	O
pivot	O
p	O
is	O
chosen	O
every	O
other	O
object	O
u	O
is	O
compared	O
to	O
p	O
using	O
f	O
if	O
f	O
thinks	O
u	O
is	O
better	O
then	O
it	O
is	O
sorted	O
on	O
the	O
left	O
otherwise	O
it	O
is	O
sorted	O
on	O
the	O
right	O
there	O
is	O
one	O
major	O
difference	O
between	O
this	O
algorithmand	O
quicksort	O
the	O
comparison	O
function	O
is	O
allowed	O
to	O
be	O
probabilistic	O
if	O
f	O
outputs	O
probabilities	O
for	O
instance	O
it	O
predicts	O
that	O
u	O
has	O
an	O
probability	O
of	O
being	O
better	O
than	O
p	O
then	O
it	O
puts	O
it	O
on	O
the	O
left	O
with	O
probability	O
and	O
on	O
the	O
right	O
with	O
probability	O
pseudocode	O
is	O
written	O
in	O
such	O
a	O
way	O
that	O
even	O
if	O
f	O
just	O
predicts	O
the	O
algorithm	B
still	O
works	O
this	O
algorithm	B
is	O
better	O
than	O
the	O
naive	O
algorithm	B
in	O
at	O
least	O
two	O
ways	O
first	O
it	O
only	O
makes	O
om	O
m	O
calls	O
to	O
f	O
expectation	O
rather	O
than	O
calls	O
in	O
the	O
naive	O
case	O
second	O
it	O
achieves	O
a	O
better	O
error	O
bound	O
shown	O
below	O
theorem	O
error	O
bound	O
suppose	O
the	O
average	O
binary	O
error	O
of	O
f	O
is	O
then	O
the	O
ranking	O
algorithm	B
achieves	O
a	O
test	B
error	I
of	O
at	O
most	O
in	O
the	O
general	O
case	O
and	O
in	O
the	O
bipartite	O
case	O
collective	B
classification	I
you	O
are	O
writing	O
new	O
software	O
for	O
a	O
digital	O
camera	O
that	O
does	O
face	O
identification	O
however	O
instead	O
of	O
simply	O
finding	O
a	O
bounding	O
box	O
around	O
faces	O
in	O
an	O
image	O
you	O
must	O
predict	B
where	O
a	O
face	O
is	O
at	O
the	O
pixel	O
level	O
so	O
your	O
input	O
is	O
an	O
image	O
pixels	O
this	O
is	O
a	O
really	O
low	O
resolution	O
camera	O
and	O
your	O
output	O
is	O
a	O
set	O
of	O
binary	O
predictions	O
about	O
each	O
pixel	O
you	O
are	O
given	O
a	O
large	O
collection	O
figure	O
example	O
face	O
finding	O
image	O
and	O
pixel	O
mask	O
beyond	O
binary	O
classification	O
of	O
training	O
examples	B
an	O
example	O
inputoutput	O
pair	O
is	O
shown	O
in	O
figure	O
your	O
first	O
attempt	O
might	O
be	O
to	O
train	O
a	O
binary	O
classifier	O
to	O
predict	B
whether	O
pixel	O
j	O
is	O
part	O
of	O
a	O
face	O
or	O
not	O
you	O
might	O
feed	O
in	O
features	B
to	O
this	O
classifier	O
about	O
the	O
rgb	O
values	O
of	O
pixel	O
j	O
as	O
well	O
as	O
pixels	O
in	O
a	O
window	O
arround	O
that	O
for	O
instance	O
pixels	O
in	O
the	O
region	O
k	O
j	O
l	O
k	O
l	O
you	O
run	O
your	O
classifier	O
and	O
notice	O
that	O
it	O
predicts	O
weird	O
things	O
like	O
what	O
you	O
see	O
in	O
figure	O
you	O
then	O
realize	O
that	O
predicting	O
each	O
pixel	O
independently	B
is	O
a	O
bad	O
idea	O
if	O
pixel	O
j	O
is	O
part	O
of	O
a	O
face	O
then	O
this	O
significantly	O
increases	O
the	O
chances	O
that	O
pixel	O
j	O
is	O
also	O
part	O
of	O
a	O
face	O
similarly	O
for	O
other	O
pixels	O
this	O
is	O
a	O
collective	B
classification	I
problem	O
because	O
you	O
are	O
trying	O
to	O
predict	B
multiple	O
correlated	O
objects	O
at	O
the	O
same	O
time	O
the	O
most	O
general	O
way	O
to	O
formulate	O
these	O
problems	O
is	O
as	O
graph	B
prediction	O
problems	O
our	O
input	O
now	O
takes	O
the	O
form	O
of	O
a	O
graph	B
where	O
the	O
vertices	O
are	O
inputoutput	O
pairs	O
and	O
the	O
edges	O
represent	O
the	O
correlations	O
among	O
the	O
putputs	O
that	O
edges	O
do	O
not	O
need	O
to	O
express	O
correlations	O
among	O
the	O
inputs	O
these	O
can	O
simply	O
be	O
encoded	O
on	O
the	O
nodes	O
themselves	O
for	O
example	O
in	O
the	O
face	O
identification	O
case	O
each	O
pixel	O
would	O
correspond	O
to	O
an	O
vertex	O
in	O
the	O
graph	B
for	O
the	O
vertex	O
that	O
corresponds	O
to	O
pixel	O
the	O
input	O
would	O
be	O
whatever	O
set	O
of	O
features	B
we	O
want	O
about	O
that	O
pixel	O
features	B
about	O
neighboring	O
pixels	O
there	O
would	O
be	O
edges	O
between	O
that	O
vertex	O
and	O
instance	O
vertices	O
and	O
if	O
we	O
are	O
predicting	O
one	O
of	O
k	O
classes	O
at	O
each	O
vertex	O
then	O
we	O
are	O
given	O
a	O
graph	B
whose	O
vertices	O
are	O
labeled	O
by	O
pairs	O
k	O
x	O
we	O
will	O
write	O
gx	O
to	O
denote	O
the	O
set	O
of	O
all	O
such	O
graphs	O
a	O
graph	B
in	O
this	O
set	O
is	O
denoted	O
as	O
g	O
e	O
with	O
vertices	O
v	O
and	O
edges	O
e	O
our	O
goal	O
is	O
a	O
function	O
f	O
that	O
takes	O
as	O
input	O
a	O
graph	B
from	O
gx	O
and	O
predicts	O
a	O
label	B
from	O
for	O
each	O
of	O
its	O
vertices	O
task	O
collective	B
classification	I
given	O
an	O
input	O
space	O
x	O
and	O
number	O
of	O
classes	O
k	O
an	O
unknown	O
distribution	O
d	O
over	O
gx	O
compute	O
a	O
function	O
f	O
e	O
with	O
vertex	O
v	O
in	O
g	O
and	O
yv	O
is	O
the	O
label	B
predicted	O
by	O
f	O
where	O
yv	O
is	O
the	O
label	B
associated	O
v	O
v	O
yv	O
yv	O
gx	O
gk	O
minimizing	O
in	O
collective	B
classification	I
you	O
would	O
like	O
to	O
be	O
able	O
to	O
use	O
the	O
figure	O
bad	O
pixel	O
mask	O
for	O
previous	O
image	O
similar	O
problems	O
come	O
up	O
all	O
the	O
time	O
cast	O
the	O
following	O
as	O
collective	B
classification	I
problems	O
web	O
page	O
categorization	O
labeling	O
words	O
in	O
a	O
sentence	O
as	O
noun	O
verb	O
adjective	O
etc	O
finding	O
genes	O
in	O
dna	O
sequences	O
predicting	O
the	O
stock	O
market	O
formulate	O
the	O
example	O
problems	O
above	O
as	O
graph	B
prediction	O
problems	O
a	O
course	O
in	O
machine	O
learning	O
labels	O
of	O
neighboring	O
vertices	O
to	O
help	O
predict	B
the	O
label	B
of	O
a	O
given	O
vertex	O
for	O
instance	O
you	O
might	O
want	O
to	O
add	O
features	B
to	O
the	O
predict	B
of	O
a	O
given	O
vertex	O
based	O
on	O
the	O
labels	O
of	O
each	O
neighbor	O
at	O
training	O
time	O
this	O
is	O
easy	O
you	O
get	O
to	O
see	O
the	O
true	O
labels	O
of	O
each	O
neighbor	O
however	O
at	O
test	O
time	O
it	O
is	O
much	O
more	O
difficult	O
you	O
are	O
yourself	O
predicting	O
the	O
labels	O
of	O
each	O
neighbor	O
this	O
presents	O
a	O
chicken	O
and	O
egg	O
problem	O
you	O
are	O
trying	O
to	O
predict	B
a	O
collection	O
of	O
labels	O
but	O
the	O
prediction	O
of	O
each	O
label	B
depends	O
on	O
the	O
prediction	O
of	O
other	O
labels	O
if	O
you	O
remember	O
from	O
before	O
a	O
general	O
solution	O
to	O
this	O
problem	O
is	O
iteration	B
you	O
can	O
begin	O
with	O
some	O
guesses	O
and	O
then	O
try	O
to	O
improve	O
these	O
guesses	O
over	O
time	O
this	O
is	O
the	O
idea	O
of	O
stacking	B
for	O
solving	O
collective	B
classification	I
figure	O
you	O
can	O
train	O
classifiers	O
the	O
first	O
classifier	O
just	O
predicts	O
the	O
value	O
of	O
each	O
pixel	O
independently	B
like	O
in	O
figure	O
this	O
doesn	O
t	O
use	O
any	O
of	O
the	O
graph	B
structure	O
at	O
all	O
in	O
the	O
second	O
level	O
you	O
can	O
repeat	O
the	O
classification	O
however	O
you	O
can	O
use	O
the	O
outputs	O
from	O
the	O
first	O
level	O
as	O
initial	O
guesses	O
of	O
labels	O
in	O
general	O
for	O
the	O
kth	O
level	O
in	O
the	O
stack	O
you	O
can	O
use	O
the	O
inputs	O
values	O
as	O
well	O
as	O
the	O
predictions	O
for	O
all	O
of	O
the	O
k	O
previous	O
levels	O
of	O
the	O
stack	O
this	O
means	O
training	O
k-many	O
binary	O
classifiers	O
based	O
on	O
different	O
feature	O
sets	O
the	O
prediction	O
technique	O
for	O
stacking	B
is	O
sketched	O
in	O
algorithm	B
this	O
takes	O
a	O
list	O
of	O
k	O
classifiers	O
corresponding	O
to	O
each	O
level	O
in	O
the	O
stack	O
and	O
an	O
input	O
graph	B
g	O
the	O
variable	O
ykv	O
stores	O
the	O
prediction	O
of	O
classifier	O
k	O
on	O
vertex	O
v	O
in	O
the	O
graph	B
you	O
first	O
predict	B
every	O
node	O
in	O
the	O
vertex	O
using	O
the	O
first	O
layer	O
in	O
the	O
stack	O
and	O
no	O
neighboring	O
information	O
for	O
the	O
rest	O
of	O
the	O
layers	O
you	O
add	O
on	O
features	B
to	O
each	O
node	O
based	O
on	O
the	O
predictions	O
made	O
by	O
lower	O
levels	O
in	O
the	O
stack	O
for	O
neighboring	O
nodes	O
denotes	O
the	O
neighbors	O
of	O
u	O
the	O
training	O
procedure	O
follows	O
a	O
similar	O
scheme	O
sketched	O
in	O
algorithm	B
it	O
largely	O
follows	O
the	O
same	O
schematic	O
as	O
the	O
prediction	O
algorithm	B
but	O
with	O
training	O
fed	O
in	O
after	O
the	O
classifier	O
for	O
the	O
k	O
level	O
has	O
been	O
trained	O
it	O
is	O
used	O
to	O
predict	B
labels	O
on	O
every	O
node	O
in	O
the	O
graph	B
these	O
labels	O
are	O
used	O
by	O
later	O
levels	O
in	O
the	O
stack	O
as	O
features	B
one	O
thing	O
to	O
be	O
aware	O
of	O
is	O
that	O
multiclasstrain	O
could	O
conceivably	O
overfit	O
its	O
training	B
data	I
for	O
example	O
it	O
is	O
possible	O
that	O
the	O
first	O
layer	O
might	O
actually	O
achieve	O
error	O
in	O
which	O
case	O
there	O
is	O
no	O
reason	O
to	O
iterate	O
but	O
at	O
test	O
time	O
it	O
will	O
probably	O
not	O
get	O
error	O
so	O
this	O
is	O
misleading	O
there	O
are	O
least	O
two	O
ways	O
to	O
address	O
this	O
issue	O
the	O
first	O
is	O
to	O
use	O
cross-validation	O
during	O
training	O
and	O
to	O
use	O
the	O
predictions	O
obtained	O
during	O
cross-validation	O
as	O
the	O
predictions	O
from	O
stacktest	B
this	O
is	O
typically	O
very	O
safe	O
but	O
somewhat	O
expensive	O
the	O
alternative	O
is	O
to	O
simply	O
over-regularize	O
your	O
training	O
algorithm	B
in	O
particular	O
instead	O
of	O
trying	O
to	O
find	O
hyperparameters	O
that	O
get	O
the	O
alternatively	O
the	O
fact	O
that	O
we	O
re	O
using	O
a	O
graph	B
might	O
scream	O
to	O
you	O
dynamic	O
programming	O
rest	O
assured	O
that	O
you	O
can	O
do	O
this	O
too	O
skip	O
forward	O
to	O
chapter	O
for	O
lots	O
more	O
detail	O
here	O
figure	O
a	O
charicature	O
of	O
how	O
stacking	B
works	O
beyond	O
binary	O
classification	O
algorithm	B
stacktraindcc	O
k	O
multiclasstrain	O
dmc	O
yknv	O
k	O
n	O
v	O
gn	O
for	O
k	O
to	O
k	O
do	O
for	O
n	O
to	O
n	O
do	O
for	O
all	O
v	O
gn	O
do	O
our	O
generated	O
multiclass	O
data	O
initialize	O
predictions	O
for	O
all	O
levels	O
y	O
features	B
and	O
label	B
for	O
node	O
v	O
x	O
x	O
ylnu	O
u	O
n	O
l	O
dmc	O
dmc	O
x	O
add	O
on	O
features	B
for	O
neighboring	O
nodes	O
from	O
lower	O
levels	O
in	O
the	O
stack	O
add	O
to	O
multiclass	O
data	O
end	O
for	O
end	O
for	O
fk	O
multiclasstraindbin	O
for	O
n	O
to	O
n	O
do	O
yknv	O
stacktest	B
fk	O
gn	O
end	O
for	O
end	O
for	O
return	O
fk	O
algorithm	B
stacktest	B
fk	O
g	O
ykv	O
k	O
v	O
g	O
for	O
k	O
to	O
k	O
do	O
for	O
all	O
v	O
g	O
do	O
train	O
kth	O
level	O
classifier	O
predict	B
using	O
kth	O
level	O
classifier	O
return	O
all	O
classifiers	O
initialize	O
predictions	O
for	O
all	O
levels	O
x	O
features	B
for	O
node	O
v	O
x	O
x	O
ylu	O
u	O
n	O
l	O
ykv	O
fkx	O
add	O
on	O
features	B
for	O
neighboring	O
nodes	O
from	O
lower	O
levels	O
in	O
the	O
stack	O
predict	B
according	O
to	O
kth	O
level	O
end	O
for	O
end	O
for	O
return	O
ykv	O
v	O
g	O
return	O
predictions	O
for	O
every	O
node	O
from	O
the	O
last	O
layer	O
best	O
development	B
data	I
performance	O
try	O
to	O
find	O
hyperparameters	O
that	O
make	O
your	O
training	O
performance	O
approximately	O
equal	O
to	O
your	O
development	O
performance	O
this	O
will	O
ensure	O
that	O
your	O
predictions	O
at	O
the	O
kth	O
layer	O
are	O
indicative	O
of	O
how	O
well	O
the	O
algorithm	B
will	O
actually	O
do	O
at	O
test	O
time	O
todo	O
finish	O
this	O
discussion	O
exercises	O
exercise	O
todo	O
linear	O
models	O
learning	O
objectives	O
define	O
and	O
plot	O
four	O
surrogate	B
loss	I
functions	O
squared	B
loss	I
logistic	B
loss	I
exponential	B
loss	I
and	O
hinge	B
loss	I
compare	O
and	O
contrast	O
the	O
optimiza	O
tion	O
of	O
loss	O
and	O
surrogate	B
loss	I
functions	O
solve	O
the	O
optimization	B
problem	I
for	O
squared	B
loss	I
with	O
a	O
quadratic	O
regularizer	B
in	O
closed	O
form	O
implement	O
and	O
debug	O
gradient	B
descent	I
and	O
subgradient	B
descent	I
dependencies	O
the	O
essence	O
of	O
mathematics	O
is	O
not	O
to	O
make	O
simple	O
things	O
complicated	O
but	O
to	O
make	O
complicated	O
things	O
simple	O
stanley	O
gudder	O
in	O
chapter	O
you	O
learned	O
about	O
the	O
perceptron	B
algorithm	B
for	O
linear	O
classification	O
this	O
was	O
both	O
a	O
model	B
classifier	O
and	O
algorithm	B
perceptron	B
update	O
rule	O
in	O
one	O
in	O
this	O
section	O
we	O
will	O
separate	O
these	O
two	O
and	O
consider	O
general	O
ways	O
for	O
optimizing	O
linear	O
models	O
this	O
will	O
lead	O
us	O
into	O
some	O
aspects	O
of	O
optimization	O
mathematical	O
programming	O
but	O
not	O
very	O
far	O
at	O
the	O
end	O
of	O
this	O
chapter	O
there	O
are	O
pointers	O
to	O
more	O
literature	O
on	O
optimization	O
for	O
those	O
who	O
are	O
interested	O
the	O
basic	O
idea	O
of	O
the	O
perceptron	B
is	O
to	O
run	O
a	O
particular	O
algorithm	B
until	O
a	O
linear	O
separator	O
is	O
found	O
you	O
might	O
ask	O
are	O
there	O
better	O
algorithms	O
for	O
finding	O
such	O
a	O
linear	O
separator	O
we	O
will	O
follow	O
this	O
idea	O
and	O
formulate	O
a	O
learning	O
problem	O
as	O
an	O
explicit	O
optimization	B
problem	I
find	O
me	O
a	O
linear	O
separator	O
that	O
is	O
not	O
too	O
complicated	O
we	O
will	O
see	O
that	O
finding	O
an	O
optimal	O
separator	O
is	O
actually	O
computationally	O
prohibitive	O
and	O
so	O
will	O
need	O
to	O
relax	O
the	O
optimality	O
requirement	O
this	O
will	O
lead	O
us	O
to	O
a	O
convex	B
objective	O
that	O
combines	O
a	O
loss	B
function	I
well	O
are	O
we	O
doing	O
on	O
the	O
training	B
data	I
and	O
a	O
regularizer	B
complicated	O
is	O
our	O
learned	O
model	B
this	O
learning	O
framework	O
is	O
known	O
as	O
both	O
tikhonov	B
regularization	I
and	O
structural	B
risk	I
minimization	I
the	O
optimization	O
framework	O
for	O
linear	O
models	O
you	O
have	O
already	O
seen	O
the	O
perceptron	B
as	O
a	O
way	O
of	O
finding	O
a	O
weight	O
vector	B
w	O
and	O
bias	B
b	O
that	O
do	O
a	O
good	O
job	O
of	O
separating	O
positive	O
training	O
examples	B
from	O
negative	O
training	O
examples	B
the	O
perceptron	B
is	O
a	O
model	B
and	O
algorithm	B
in	O
one	O
here	O
we	O
are	O
interested	O
in	O
separating	O
these	O
issues	O
we	O
will	O
focus	O
on	O
linear	O
models	O
like	O
the	O
perceptron	B
but	O
we	O
will	O
think	O
about	O
other	O
more	O
generic	O
ways	O
of	O
finding	O
good	O
parameters	O
of	O
these	O
models	O
the	O
goal	O
of	O
the	O
perceptron	B
was	O
to	O
find	O
a	O
separating	B
hyperplane	B
for	O
some	O
training	B
data	I
set	O
for	O
simplicity	O
you	O
can	O
ignore	O
the	O
issue	O
of	O
overfitting	B
just	O
for	O
now	O
not	O
all	O
data	O
sets	O
are	O
linearly	O
sepa	O
linear	O
models	O
you	O
should	O
remember	O
the	O
yw	O
trick	O
from	O
the	O
perceptron	B
discussion	O
if	O
not	O
re-convince	O
yourself	O
that	O
this	O
is	O
doing	O
the	O
right	O
thing	O
x	O
rable	O
in	O
the	O
case	O
that	O
your	O
training	B
data	I
isn	O
t	O
linearly	B
separable	I
you	O
might	O
want	O
to	O
find	O
the	O
hyperplane	B
that	O
makes	O
the	O
fewest	O
errors	O
on	O
the	O
training	B
data	I
we	O
can	O
write	O
this	O
down	O
as	O
a	O
formal	O
mathematics	O
optimization	B
problem	I
as	O
follows	O
min	O
wb	O
n	O
xn	O
b	O
in	O
this	O
expression	O
you	O
are	O
optimizing	O
over	O
two	O
variables	O
w	O
and	O
b	O
the	O
objective	B
function	I
is	O
the	O
thing	O
you	O
are	O
trying	O
to	O
minimize	O
in	O
this	O
case	O
the	O
objective	B
function	I
is	O
simply	O
the	O
error	B
rate	I
loss	O
of	O
the	O
linear	B
classifier	I
parameterized	O
by	O
w	O
b	O
in	O
this	O
expression	O
is	O
the	O
indicator	B
function	I
it	O
is	O
one	O
when	O
is	O
true	O
and	O
zero	O
otherwise	O
we	O
know	O
that	O
the	O
perceptron	B
algorithm	B
is	O
guaranteed	O
to	O
find	O
parameters	O
for	O
this	O
model	B
if	O
the	O
data	O
is	O
linearly	B
separable	I
in	O
other	O
words	O
if	O
the	O
optimum	O
of	O
eq	O
is	O
zero	O
then	O
the	O
perceptron	B
will	O
efficiently	O
find	O
parameters	O
for	O
this	O
model	B
the	O
notion	O
of	O
efficiency	O
depends	O
on	O
the	O
margin	B
of	O
the	O
data	O
for	O
the	O
perceptron	B
you	O
might	O
ask	O
what	O
happens	O
if	O
the	O
data	O
is	O
not	O
linearly	B
separable	I
is	O
there	O
an	O
efficient	O
algorithm	B
for	O
finding	O
an	O
optimal	O
setting	O
of	O
the	O
parameters	O
unfortunately	O
the	O
answer	O
is	O
no	O
there	O
is	O
no	O
polynomial	O
time	O
algorithm	B
for	O
solving	O
eq	O
unless	O
pnp	O
in	O
other	O
words	O
this	O
problem	O
is	O
np-hard	O
sadly	O
the	O
proof	O
of	O
this	O
is	O
quite	O
complicated	O
and	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
but	O
it	O
relies	O
on	O
a	O
reduction	O
from	O
a	O
variant	O
of	O
satisfiability	O
the	O
key	O
idea	O
is	O
to	O
turn	O
a	O
satisfiability	O
problem	O
into	O
an	O
optimization	B
problem	I
where	O
a	O
clause	O
is	O
satisfied	O
exactly	O
when	O
the	O
hyperplane	B
correctly	O
separates	O
the	O
data	O
you	O
might	O
then	O
come	O
back	O
and	O
say	O
okay	O
well	O
i	O
don	O
t	O
really	O
need	O
an	O
exact	O
solution	O
i	O
m	O
willing	O
to	O
have	O
a	O
solution	O
that	O
makes	O
one	O
or	O
two	O
more	O
errors	O
than	O
it	O
has	O
to	O
unfortunately	O
the	O
situation	O
is	O
really	O
bad	O
zeroone	O
loss	O
is	O
np-hard	O
to	O
even	O
appproximately	O
minimize	O
in	O
other	O
words	O
there	O
is	O
no	O
efficient	O
algorithm	B
for	O
even	O
finding	O
a	O
solution	O
that	O
s	O
a	O
small	O
constant	O
worse	O
than	O
optimal	O
best	O
known	O
constant	O
at	O
this	O
time	O
is	O
however	O
before	O
getting	O
too	O
disillusioned	O
about	O
this	O
whole	O
enterprise	O
there	O
s	O
an	O
entire	O
chapter	O
about	O
this	O
framework	O
so	O
it	O
must	O
be	O
going	O
somewhere	O
you	O
should	O
remember	O
that	O
optimizing	O
eq	O
perhaps	O
isn	O
t	O
even	O
what	O
you	O
want	O
to	O
do	O
in	O
particular	O
all	O
it	O
says	O
is	O
that	O
you	O
will	O
get	O
minimal	O
training	B
error	I
it	O
says	O
nothing	O
about	O
what	O
your	O
test	B
error	I
will	O
be	O
like	O
in	O
order	O
to	O
try	O
to	O
find	O
a	O
solution	O
that	O
will	O
generalize	B
well	O
to	O
test	B
data	I
you	O
need	O
to	O
ensure	O
that	O
you	O
do	O
not	O
overfit	O
the	O
data	O
to	O
do	O
this	O
you	O
can	O
introduce	O
a	O
regularizer	B
over	O
the	O
parameters	O
of	O
the	O
model	B
for	O
now	O
we	O
will	O
be	O
vague	O
about	O
what	O
this	O
regularizer	B
looks	O
like	O
and	O
simply	O
call	O
it	O
an	O
arbitrary	O
function	O
rw	O
b	O
a	O
course	O
in	O
machine	O
learning	O
this	O
leads	O
to	O
the	O
following	O
regularized	B
objective	I
min	O
wb	O
n	O
xn	O
b	O
rw	O
b	O
in	O
eq	O
we	O
are	O
now	O
trying	O
to	O
optimize	O
a	O
trade-off	O
between	O
a	O
solution	O
that	O
gives	O
low	O
training	B
error	I
first	O
term	O
and	O
a	O
solution	O
that	O
is	O
simple	O
second	O
term	O
you	O
can	O
think	O
of	O
the	O
maximum	B
depth	I
hyperparameter	B
of	O
a	O
decision	B
tree	I
as	O
a	O
form	O
of	O
regularization	O
for	O
trees	O
here	O
r	O
is	O
a	O
form	O
of	O
regularization	O
for	O
hyperplanes	O
in	O
this	O
formulation	O
becomes	O
a	O
hyperparameter	B
for	O
the	O
optimization	O
the	O
key	O
remaining	O
questions	O
given	O
this	O
formalism	O
are	O
how	O
can	O
we	O
adjust	O
the	O
optimization	B
problem	I
so	O
that	O
there	O
are	O
efficient	O
algorithms	O
for	O
solving	O
it	O
what	O
are	O
good	O
regularizers	O
rw	O
b	O
for	O
hyperplanes	O
assuming	O
we	O
can	O
adjust	O
the	O
optimization	B
problem	I
appropriately	O
what	O
algorithms	O
exist	O
for	O
efficiently	O
solving	O
this	O
regularized	O
optimization	B
problem	I
we	O
will	O
address	O
these	O
three	O
questions	O
in	O
the	O
next	O
sections	O
convex	B
surrogate	B
loss	I
functions	O
you	O
might	O
ask	O
why	O
is	O
optimizing	O
zeroone	O
loss	O
so	O
hard	O
intuitively	O
one	O
reason	O
is	O
that	O
small	O
changes	O
to	O
w	O
b	O
can	O
have	O
a	O
large	O
impact	O
on	O
the	O
value	O
of	O
the	O
objective	B
function	I
for	O
instance	O
if	O
there	O
is	O
a	O
positive	O
training	O
example	O
with	O
w	O
x	O
then	O
adjusting	O
b	O
upwards	O
by	O
will	O
decrease	O
your	O
error	B
rate	I
by	O
but	O
adjusting	O
it	O
upwards	O
by	O
will	O
have	O
no	O
effect	O
this	O
makes	O
it	O
really	O
difficult	O
to	O
figure	O
out	O
good	O
ways	O
to	O
adjust	O
the	O
parameters	O
to	O
see	O
this	O
more	O
clearly	O
it	O
is	O
useful	O
to	O
look	O
at	O
plots	O
that	O
relate	O
margin	B
to	O
loss	O
such	O
a	O
plot	O
for	O
zeroone	O
loss	O
is	O
shown	O
in	O
figure	O
in	O
this	O
plot	O
the	O
horizontal	O
axis	O
measure	O
the	O
margin	B
of	O
a	O
data	O
point	O
and	O
the	O
vertical	O
axis	O
measures	O
the	O
loss	O
associated	O
with	O
that	O
margin	B
for	O
zeroone	O
loss	O
the	O
story	O
is	O
simple	O
if	O
you	O
get	O
a	O
positive	O
margin	B
yw	O
x	O
b	O
then	O
you	O
get	O
a	O
loss	O
of	O
zero	O
otherwise	O
you	O
get	O
a	O
loss	O
of	O
one	O
by	O
thinking	O
about	O
this	O
plot	O
you	O
can	O
see	O
how	O
changes	O
to	O
the	O
parameters	O
that	O
change	O
the	O
margin	B
just	O
a	O
little	O
bit	O
can	O
have	O
an	O
enormous	O
effect	O
on	O
the	O
overall	O
loss	O
you	O
might	O
decide	O
that	O
a	O
reasonable	O
way	O
to	O
address	O
this	O
problem	O
is	O
to	O
replace	O
the	O
non-smooth	O
zeroone	O
loss	O
with	O
a	O
smooth	O
approximation	O
with	O
a	O
bit	O
of	O
effort	O
you	O
could	O
probably	O
concoct	O
an	O
s	O
function	O
like	O
that	O
shown	O
in	O
figure	O
the	O
benefit	O
of	O
using	O
such	O
an	O
s-function	O
is	O
that	O
it	O
is	O
smooth	O
and	O
potentially	O
easier	O
to	O
optimize	O
the	O
difficulty	O
is	O
that	O
it	O
is	O
not	O
convex	B
assuming	O
r	O
does	O
the	O
right	O
thing	O
what	O
values	O
of	O
will	O
lead	O
to	O
overfitting	B
what	O
values	O
will	O
lead	O
to	O
underfitting	B
figure	O
plot	O
of	O
zeroone	O
versus	O
margin	B
figure	O
plot	O
of	O
zeroone	O
versus	O
margin	B
and	O
an	O
s	O
version	O
of	O
it	O
linear	O
models	O
figure	O
surrogate	B
loss	I
fns	O
if	O
you	O
remember	O
from	O
calculus	O
a	O
convex	B
function	O
is	O
one	O
that	O
looks	O
like	O
a	O
happy	O
face	O
the	O
other	O
hand	O
a	O
concave	B
function	O
is	O
one	O
that	O
looks	O
like	O
a	O
sad	O
face	O
an	O
easy	O
mnemonic	O
is	O
that	O
you	O
can	O
hide	O
under	O
a	O
concave	B
function	O
there	O
are	O
two	O
equivalent	O
definitions	O
of	O
a	O
concave	B
function	O
the	O
first	O
is	O
that	O
it	O
s	O
second	O
derivative	O
is	O
always	O
non-negative	O
the	O
second	O
more	O
geometric	O
defition	O
is	O
that	O
any	O
chord	B
of	O
the	O
function	O
lies	O
above	O
it	O
this	O
is	O
shown	O
in	O
figure	O
there	O
you	O
can	O
see	O
a	O
convex	B
function	O
and	O
a	O
non-convex	B
function	O
both	O
with	O
two	O
chords	O
drawn	O
in	O
in	O
the	O
case	O
of	O
the	O
convex	B
function	O
the	O
chords	O
lie	O
above	O
the	O
function	O
in	O
the	O
case	O
of	O
the	O
non-convex	B
function	O
there	O
are	O
parts	O
of	O
the	O
chord	B
that	O
lie	O
below	O
the	O
function	O
convex	B
functions	O
are	O
nice	O
because	O
they	O
are	O
easy	O
to	O
minimize	O
intuitively	O
if	O
you	O
drop	O
a	O
ball	O
anywhere	O
in	O
a	O
convex	B
function	O
it	O
will	O
eventually	O
get	O
to	O
the	O
minimum	O
this	O
is	O
not	O
true	O
for	O
non-convex	B
functions	O
for	O
example	O
if	O
you	O
drop	O
a	O
ball	O
on	O
the	O
very	O
left	O
end	O
of	O
the	O
s-function	O
from	O
figure	O
it	O
will	O
not	O
go	O
anywhere	O
this	O
leads	O
to	O
the	O
idea	O
of	O
convex	B
surrogate	B
loss	I
functions	O
since	O
zeroone	O
loss	O
is	O
hard	O
to	O
optimize	O
you	O
want	O
to	O
optimize	O
something	O
else	O
instead	O
since	O
convex	B
functions	O
are	O
easy	O
to	O
optimize	O
we	O
want	O
to	O
approximate	O
zeroone	O
loss	O
with	O
a	O
convex	B
function	O
this	O
approximating	O
function	O
will	O
be	O
called	O
a	O
surrogate	B
loss	I
the	O
surrogate	O
losses	O
we	O
construct	O
will	O
always	O
be	O
upper	O
bounds	O
on	O
the	O
true	O
loss	B
function	I
this	O
guarantees	O
that	O
if	O
you	O
minimize	O
the	O
surrogate	B
loss	I
you	O
are	O
also	O
pushing	O
down	O
the	O
real	O
loss	O
there	O
are	O
four	O
common	O
surrogate	B
loss	B
function	I
each	O
with	O
their	O
own	O
properties	O
hinge	B
loss	I
logistic	B
loss	I
exponential	B
loss	I
and	O
squared	B
loss	I
these	O
are	O
shown	O
in	O
figure	O
and	O
defined	O
below	O
these	O
are	O
defined	O
in	O
terms	O
of	O
the	O
true	O
label	B
y	O
is	O
just	O
and	O
the	O
predicted	O
value	O
y	O
w	O
x	O
b	O
zeroone	O
hinge	O
logistic	O
exponential	O
squared	O
y	O
y	O
y	O
y	O
y	O
y	O
y	O
exp	O
y	O
y	O
y	O
log	O
log	O
exp	O
y	O
y	O
log	O
term	O
out	O
front	O
is	O
there	O
sim	O
in	O
the	O
definition	O
of	O
logistic	B
loss	I
the	O
ply	O
to	O
ensure	O
that	O
this	O
ensures	O
like	O
all	O
the	O
other	O
surrogate	B
loss	I
functions	O
that	O
logistic	B
loss	I
upper	O
bounds	O
the	O
zeroone	O
loss	O
practice	O
people	O
typically	O
omit	O
this	O
constant	O
since	O
it	O
does	O
not	O
affect	O
the	O
optimization	O
there	O
are	O
two	O
big	O
differences	O
in	O
these	O
loss	O
functions	O
the	O
first	O
difference	O
is	O
how	O
upset	O
they	O
get	O
by	O
erroneous	O
predictions	O
in	O
the	O
a	O
course	O
in	O
machine	O
learning	O
case	O
of	O
hinge	B
loss	I
and	O
logistic	B
loss	I
the	O
growth	O
of	O
the	O
function	O
as	O
y	O
goes	O
negative	O
is	O
linear	O
for	O
squared	B
loss	I
and	O
exponential	B
loss	I
it	O
is	O
super-linear	O
this	O
means	O
that	O
exponential	B
loss	I
would	O
rather	O
get	O
a	O
few	O
examples	B
a	O
little	O
wrong	O
than	O
one	O
example	O
really	O
wrong	O
the	O
other	O
difference	O
is	O
how	O
they	O
deal	O
with	O
very	O
confident	O
correct	O
predictions	O
once	O
y	O
y	O
hinge	B
loss	I
does	O
not	O
care	O
any	O
more	O
but	O
logistic	O
and	O
exponential	O
still	O
think	O
you	O
can	O
do	O
better	O
on	O
the	O
other	O
hand	O
squared	B
loss	I
thinks	O
it	O
s	O
just	O
as	O
bad	O
to	O
predict	B
on	O
a	O
positive	O
example	O
as	O
it	O
is	O
to	O
predict	B
on	O
a	O
positive	O
example	O
weight	O
regularization	O
in	O
our	O
learning	O
objective	O
eq	O
we	O
had	O
a	O
term	O
correspond	O
to	O
the	O
zeroone	O
loss	O
on	O
the	O
training	B
data	I
plus	O
a	O
regularizer	B
whose	O
goal	O
was	O
to	O
ensure	O
that	O
the	O
learned	O
function	O
didn	O
t	O
get	O
too	O
crazy	O
more	O
formally	O
to	O
ensure	O
that	O
the	O
function	O
did	O
not	O
overfit	O
if	O
you	O
replace	O
to	O
zeroone	O
loss	O
with	O
a	O
surrogate	B
loss	I
you	O
obtain	O
the	O
following	O
objective	O
min	O
wb	O
n	O
w	O
xn	O
b	O
rw	O
b	O
the	O
question	O
is	O
what	O
should	O
rw	O
b	O
look	O
like	O
from	O
the	O
discussion	O
of	O
surrogate	B
loss	B
function	I
we	O
would	O
like	O
to	O
ensure	O
that	O
r	O
is	O
convex	B
otherwise	O
we	O
will	O
be	O
back	O
to	O
the	O
point	O
where	O
optimization	O
becomes	O
difficult	O
beyond	O
that	O
a	O
common	O
desire	O
is	O
that	O
the	O
components	O
of	O
the	O
weight	O
vector	B
the	O
wds	O
should	O
be	O
small	O
to	O
zero	O
this	O
is	O
a	O
form	O
of	O
inductive	B
bias	B
why	O
are	O
small	O
values	O
of	O
wd	O
good	O
or	O
more	O
precisely	O
why	O
do	O
small	O
values	O
of	O
wd	O
correspond	O
to	O
simple	O
functions	O
suppose	O
that	O
we	O
have	O
an	O
example	O
x	O
with	O
label	B
we	O
might	O
believe	O
that	O
other	O
examples	B
that	O
are	O
nearby	O
x	O
should	O
also	O
have	O
label	B
for	O
example	O
if	O
i	O
obtain	O
by	O
taking	O
x	O
and	O
changing	O
the	O
first	O
component	O
by	O
some	O
small	O
value	O
and	O
leaving	O
the	O
rest	O
the	O
same	O
you	O
might	O
think	O
that	O
the	O
classification	O
would	O
be	O
the	O
same	O
if	O
you	O
do	O
this	O
the	O
difference	O
between	O
y	O
and	O
will	O
be	O
exactly	O
so	O
if	O
is	O
reasonably	O
small	O
this	O
is	O
unlikely	O
to	O
have	O
much	O
of	O
an	O
effect	O
on	O
the	O
classification	O
decision	O
on	O
the	O
other	O
hand	O
if	O
is	O
large	O
this	O
could	O
have	O
a	O
large	O
effect	O
another	O
way	O
of	O
saying	O
the	O
same	O
thing	O
is	O
to	O
look	O
at	O
the	O
derivative	O
of	O
the	O
predictions	O
as	O
a	O
function	O
of	O
the	O
derivative	O
of	O
w	O
x	O
with	O
respect	O
to	O
is	O
d	O
wdxd	O
b	O
w	O
x	O
interpreting	O
the	O
derivative	O
as	O
the	O
rate	O
of	O
change	O
we	O
can	O
see	O
that	O
the	O
rate	O
of	O
change	O
of	O
the	O
prediction	O
function	O
is	O
proportional	O
to	O
the	O
individual	O
weights	B
so	O
if	O
you	O
want	O
the	O
function	O
to	O
change	O
slowly	O
you	O
want	O
to	O
ensure	O
that	O
the	O
weights	B
stay	O
small	O
one	O
way	O
to	O
accomplish	O
this	O
is	O
to	O
simply	O
use	O
the	O
norm	O
of	O
the	O
d	O
weight	O
vector	B
namely	O
rnormw	O
b	O
is	O
convex	B
and	O
smooth	O
which	O
makes	O
it	O
easy	O
to	O
minimize	O
in	O
practice	O
it	O
s	O
often	O
easier	O
to	O
use	O
the	O
squared	O
norm	O
namely	O
rsqrw	O
b	O
d	O
remains	O
convex	B
an	O
alternative	O
to	O
using	O
the	O
sum	O
of	O
squared	O
weights	B
is	O
to	O
use	O
the	O
sum	O
of	O
absolute	O
weights	B
rabsw	O
b	O
d	O
both	O
of	O
these	O
norms	O
are	O
convex	B
d	O
because	O
it	O
removes	O
the	O
ugly	O
square	O
root	O
term	O
and	O
d	O
this	O
function	O
in	O
addition	O
to	O
small	O
weights	B
being	O
good	O
you	O
could	O
argue	O
that	O
zero	O
weights	B
are	O
better	O
if	O
a	O
weight	O
wd	O
goes	O
to	O
zero	O
then	O
this	O
means	O
that	O
feature	O
d	O
is	O
not	O
used	O
at	O
all	O
in	O
the	O
classification	O
decision	O
if	O
there	O
are	O
a	O
large	O
number	O
of	O
irrelevant	O
features	B
you	O
might	O
want	O
as	O
many	O
weights	B
to	O
go	O
to	O
zero	O
as	O
possible	O
this	O
suggests	O
an	O
alternative	O
regularizer	B
rcntw	O
b	O
d	O
this	O
line	O
of	O
thinking	O
leads	O
to	O
the	O
general	O
concept	B
of	O
p-norms	B
these	O
are	O
called	O
ell	O
p	O
norms	O
but	O
this	O
notation	O
clashes	O
with	O
the	O
use	O
of	O
for	O
loss	O
this	O
is	O
a	O
family	O
of	O
norms	O
that	O
all	O
have	O
the	O
same	O
general	O
flavor	O
we	O
write	O
to	O
denote	O
the	O
p-norm	O
of	O
w	O
p	O
d	O
you	O
can	O
check	O
that	O
the	O
exactly	O
corresponds	O
to	O
the	O
usual	O
euclidean	O
norm	O
and	O
that	O
the	O
corresponds	O
to	O
the	O
absolute	O
regularizer	B
described	O
above	O
when	O
p-norms	B
are	O
used	O
to	O
regularize	O
weight	O
vectors	O
the	O
interest	O
ing	O
aspect	O
is	O
how	O
they	O
trade-off	O
multiple	O
features	B
to	O
see	O
the	O
behavior	O
of	O
p-norms	B
in	O
two	O
dimensions	O
we	O
can	O
plot	O
their	O
contour	B
levelset	O
figure	O
shows	O
the	O
contours	O
for	O
the	O
same	O
p	O
norms	O
in	O
two	O
dimensions	O
each	O
line	O
denotes	O
the	O
two-dimensional	O
vectors	O
to	O
which	O
this	O
norm	O
assignes	O
a	O
total	O
value	O
of	O
by	O
changing	O
the	O
value	O
of	O
p	O
you	O
can	O
interpolate	O
between	O
a	O
square	O
so-called	O
max	O
norm	O
down	O
to	O
a	O
circle	O
diamond	O
and	O
pointy-star-shaped-thing	O
norm	O
in	O
general	O
smaller	O
values	O
of	O
p	O
prefer	O
sparser	O
vectors	O
you	O
can	O
see	O
this	O
by	O
noticing	O
that	O
the	O
contours	O
of	O
small	O
p-norms	B
stretch	O
out	O
along	O
the	O
axes	O
it	O
is	O
for	O
this	O
reason	O
that	O
small	O
p-norms	B
tend	O
to	O
yield	O
weight	O
vectors	O
with	O
many	O
zero	O
entries	O
sparse	B
weight	O
vectors	O
unfortunately	O
for	O
p	O
the	O
norm	O
becomes	O
non-convex	B
as	O
you	O
might	O
guess	O
this	O
means	O
that	O
the	O
is	O
a	O
popular	O
choice	O
for	O
sparsity-seeking	O
applications	O
linear	O
models	O
why	O
do	O
we	O
not	O
regularize	O
the	O
bias	B
term	O
b	O
why	O
might	O
you	O
not	O
want	O
to	O
use	O
rcnt	O
as	O
a	O
regularizer	B
you	O
can	O
actually	O
identify	O
the	O
rcnt	O
regularizer	B
with	O
a	O
p-norm	O
as	O
well	O
which	O
value	O
of	O
p	O
gives	O
it	O
to	O
you	O
you	O
may	O
have	O
to	O
take	O
a	O
limit	O
figure	O
level	O
sets	O
of	O
the	O
same	O
p-norms	B
the	O
max	O
norm	O
corresponds	O
to	O
limp	O
why	O
is	O
this	O
called	O
the	O
max	O
norm	O
a	O
course	O
in	O
machine	O
learning	O
math	O
review	O
gradients	O
be	O
sure	O
to	O
do	O
enough	O
to	O
do	O
the	O
closed	O
for	O
squared	O
error	O
algorithm	B
gradientdescentf	O
k	O
for	O
k	O
k	O
do	O
gk	O
zk	O
end	O
for	O
return	O
zk	O
initialize	O
variable	O
we	O
are	O
optimizing	O
compute	O
gradient	B
at	O
current	O
location	O
take	O
a	O
step	O
down	O
the	O
gradient	B
figure	O
optimization	O
with	O
gradient	B
descent	I
envision	O
the	O
following	O
problem	O
you	O
re	O
taking	O
up	O
a	O
new	O
hobby	O
blindfolded	O
mountain	O
climbing	O
someone	O
blindfolds	O
you	O
and	O
drops	O
you	O
on	O
the	O
side	O
of	O
a	O
mountain	O
your	O
goal	O
is	O
to	O
get	O
to	O
the	O
peak	O
of	O
the	O
mountain	O
as	O
quickly	O
as	O
possible	O
all	O
you	O
can	O
do	O
is	O
feel	O
the	O
mountain	O
where	O
you	O
are	O
standing	O
and	O
take	O
steps	O
how	O
would	O
you	O
get	O
to	O
the	O
top	O
of	O
the	O
mountain	O
perhaps	O
you	O
would	O
feel	O
to	O
find	O
out	O
what	O
direction	O
feels	O
the	O
most	O
upward	O
and	O
take	O
a	O
step	O
in	O
that	O
direction	O
if	O
you	O
do	O
this	O
repeatedly	O
you	O
might	O
hope	O
to	O
get	O
the	O
the	O
top	O
of	O
the	O
mountain	O
if	O
your	O
friend	O
promises	O
always	O
to	O
drop	O
you	O
on	O
purely	O
concave	B
mountains	O
you	O
will	O
eventually	O
get	O
to	O
the	O
peak	O
the	O
idea	O
of	O
gradient-based	O
methods	O
of	O
optimization	O
is	O
exactly	O
the	O
same	O
suppose	O
you	O
are	O
trying	O
to	O
find	O
the	O
maximum	O
of	O
a	O
function	O
f	O
the	O
optimizer	O
maintains	O
a	O
current	O
estimate	O
of	O
the	O
parameter	O
of	O
interest	O
x	O
at	O
each	O
step	O
it	O
measures	O
the	O
gradient	B
of	O
the	O
function	O
it	O
is	O
trying	O
optimize	O
this	O
measurement	O
occurs	O
at	O
the	O
current	O
location	O
x	O
call	O
the	O
gradient	B
g	O
it	O
then	O
takes	O
a	O
step	O
in	O
the	O
direction	O
of	O
the	O
gradient	B
where	O
the	O
size	O
of	O
the	O
step	O
is	O
controlled	O
by	O
a	O
parameter	O
the	O
complete	O
step	O
is	O
x	O
x	O
g	O
this	O
is	O
the	O
basic	O
idea	O
of	O
gradient	B
ascent	I
the	O
opposite	O
of	O
gradient	B
ascent	I
is	O
gradient	B
descent	I
all	O
of	O
our	O
learning	O
problems	O
will	O
be	O
framed	O
as	O
minimization	O
problems	O
to	O
reach	O
the	O
bottom	O
of	O
a	O
ditch	O
rather	O
than	O
the	O
top	O
of	O
a	O
hill	O
therefore	O
descent	O
is	O
the	O
primary	O
approach	O
you	O
will	O
use	O
one	O
of	O
the	O
major	O
conditions	O
for	O
gradient	B
ascent	I
being	O
able	O
to	O
find	O
the	O
true	O
global	B
minimum	I
of	O
its	O
objective	B
function	I
is	O
convexity	O
without	O
convexity	O
all	O
is	O
lost	O
the	O
gradient	B
descent	I
algorithm	B
is	O
sketched	O
in	O
algorithm	B
the	O
function	O
takes	O
as	O
arguments	O
the	O
function	O
f	O
to	O
be	O
minimized	O
the	O
number	O
of	O
iterations	O
k	O
to	O
run	O
and	O
a	O
sequence	O
of	O
learning	O
rates	O
linear	O
models	O
k	O
is	O
to	O
address	O
the	O
case	O
that	O
you	O
might	O
want	O
to	O
start	O
your	O
mountain	O
climbing	O
taking	O
large	O
steps	O
but	O
only	O
take	O
small	O
steps	O
when	O
you	O
are	O
close	O
to	O
the	O
peak	O
the	O
only	O
real	O
work	O
you	O
need	O
to	O
do	O
to	O
apply	O
a	O
gradient	B
descent	I
method	O
is	O
be	O
able	O
to	O
compute	O
derivatives	O
for	O
concreteness	O
suppose	O
that	O
you	O
choose	O
exponential	B
loss	I
as	O
a	O
loss	B
function	I
and	O
the	O
as	O
a	O
regularizer	B
then	O
the	O
regularized	B
objective	B
function	I
is	O
ynw	O
xn	O
lw	O
b	O
n	O
the	O
only	O
strange	O
thing	O
in	O
this	O
objective	O
is	O
that	O
we	O
have	O
replaced	O
with	O
the	O
reason	O
for	O
this	O
change	O
is	O
just	O
to	O
make	O
the	O
gradients	O
cleaner	O
we	O
can	O
first	O
compute	O
derivatives	O
with	O
respect	O
to	O
b	O
l	O
b	O
n	O
b	O
ynw	O
xn	O
ynw	O
xn	O
yn	O
ynw	O
xn	O
ynw	O
xn	O
b	O
b	O
b	O
n	O
n	O
n	O
b	O
ynw	O
xn	O
before	O
proceeding	O
it	O
is	O
worth	O
thinking	O
about	O
what	O
this	O
says	O
from	O
a	O
practical	O
perspective	O
the	O
optimization	O
will	O
operate	O
by	O
updating	O
b	O
b	O
l	O
b	O
consider	O
positive	O
examples	B
examples	B
with	O
yn	O
we	O
would	O
hope	O
for	O
these	O
examples	B
that	O
the	O
current	O
prediction	O
w	O
xn	O
b	O
is	O
as	O
large	O
as	O
possible	O
as	O
this	O
value	O
tends	O
toward	O
the	O
term	O
in	O
the	O
exp	O
goes	O
to	O
zero	O
thus	O
such	O
points	O
will	O
not	O
contribute	O
to	O
the	O
step	O
however	O
if	O
the	O
current	O
prediction	O
is	O
small	O
then	O
the	O
exp	O
term	O
will	O
be	O
positive	O
and	O
non-zero	O
this	O
means	O
that	O
the	O
bias	B
term	O
b	O
will	O
be	O
increased	O
which	O
is	O
exactly	O
what	O
you	O
would	O
want	O
moreover	O
once	O
all	O
points	O
are	O
very	O
well	O
classified	O
the	O
derivative	O
goes	O
to	O
zero	O
now	O
that	O
we	O
have	O
done	O
the	O
easy	O
case	O
let	O
s	O
do	O
the	O
gradient	B
with	O
respect	O
to	O
w	O
wl	O
w	O
n	O
ynw	O
xn	O
w	O
w	O
ynw	O
xn	O
b	O
ynw	O
xn	O
w	O
ynxn	O
ynw	O
xn	O
w	O
n	O
n	O
now	O
you	O
can	O
repeat	O
the	O
previous	O
exercise	O
the	O
update	O
is	O
of	O
the	O
form	O
w	O
w	O
wl	O
for	O
well	O
classified	O
points	O
that	O
are	O
tend	O
toward	O
yn	O
the	O
gradient	B
is	O
near	O
zero	O
for	O
poorly	O
classified	O
points	O
this	O
considered	O
the	O
case	O
of	O
positive	O
examples	B
what	O
happens	O
with	O
negative	O
examples	B
a	O
course	O
in	O
machine	O
learning	O
the	O
gradient	B
points	O
in	O
the	O
direction	O
ynxn	O
so	O
the	O
update	O
is	O
of	O
the	O
form	O
w	O
w	O
cynxn	O
where	O
c	O
is	O
some	O
constant	O
this	O
is	O
just	O
like	O
the	O
perceptron	B
update	O
note	O
that	O
c	O
is	O
large	O
for	O
very	O
poorly	O
classified	O
points	O
and	O
small	O
for	O
relatively	O
well	O
classified	O
points	O
by	O
looking	O
at	O
the	O
part	O
of	O
the	O
gradient	B
related	O
to	O
the	O
regularizer	B
the	O
update	O
says	O
w	O
w	O
w	O
this	O
has	O
the	O
effect	O
of	O
shrinking	O
the	O
weights	B
toward	O
zero	O
this	O
is	O
exactly	O
what	O
we	O
expect	O
the	O
regulaizer	O
to	O
be	O
doing	O
the	O
success	O
of	O
gradient	B
descent	I
hinges	O
on	O
appropriate	O
choices	O
for	O
the	O
step	O
size	O
figure	O
shows	O
what	O
can	O
happen	O
with	O
gradient	B
descent	I
with	O
poorly	O
chosen	O
step	O
sizes	O
if	O
the	O
step	O
size	O
is	O
too	O
big	O
you	O
can	O
accidentally	O
step	O
over	O
the	O
optimum	O
and	O
end	O
up	O
oscillating	O
if	O
the	O
step	O
size	O
is	O
too	O
small	O
it	O
will	O
take	O
way	O
too	O
long	O
to	O
get	O
to	O
the	O
optimum	O
for	O
a	O
well-chosen	O
step	O
size	O
you	O
can	O
show	O
that	O
gradient	B
descent	I
will	O
approach	O
the	O
optimal	O
value	O
at	O
a	O
fast	O
rate	O
the	O
notion	O
of	O
convergence	O
here	O
is	O
that	O
the	O
objective	O
value	O
converges	O
to	O
the	O
true	O
minimum	O
figure	O
good	O
and	O
bad	O
step	O
sizes	O
theorem	O
descent	O
convergence	O
under	O
suitable	O
for	O
an	O
appropriately	O
chosen	O
constant	O
step	O
size	O
the	O
convergence	B
rate	I
of	O
gradient	B
descent	I
is	O
more	O
specifically	O
letting	O
z	O
be	O
the	O
global	B
minimum	I
of	O
f	O
we	O
have	O
f	O
f	O
z	O
k	O
specifically	O
the	O
function	O
to	O
be	O
optimized	O
needs	O
to	O
be	O
strongly	B
convex	B
this	O
is	O
true	O
for	O
all	O
our	O
problems	O
provided	O
for	O
the	O
rate	O
could	O
be	O
as	O
bad	O
as	O
k	O
a	O
naive	O
reading	O
of	O
this	O
theorem	O
seems	O
to	O
say	O
that	O
you	O
should	O
choose	O
huge	O
values	O
of	O
it	O
should	O
be	O
obvious	O
that	O
this	O
cannot	O
be	O
right	O
what	O
is	O
missing	O
the	O
proof	O
of	O
this	O
theorem	O
is	O
a	O
bit	O
complicated	O
because	O
it	O
makes	O
heavy	O
use	O
of	O
some	O
linear	O
algebra	O
the	O
key	O
is	O
to	O
set	O
the	O
learning	O
rate	O
to	O
where	O
l	O
is	O
the	O
maximum	O
curvature	B
of	O
the	O
function	O
that	O
is	O
being	O
optimized	O
the	O
curvature	B
is	O
simply	O
the	O
size	O
of	O
the	O
second	O
derivative	O
functions	O
with	O
high	O
curvature	B
have	O
gradients	O
that	O
change	O
quickly	O
which	O
means	O
that	O
you	O
need	O
to	O
take	O
small	O
steps	O
to	O
avoid	O
overstepping	O
the	O
optimum	O
this	O
convergence	O
result	O
suggests	O
a	O
simple	O
approach	O
to	O
decid	O
ing	O
when	O
to	O
stop	O
optimizing	O
wait	O
until	O
the	O
objective	B
function	I
stops	O
changing	O
by	O
much	O
an	O
alternative	O
is	O
to	O
wait	O
until	O
the	O
parameters	O
stop	O
changing	O
by	O
much	O
a	O
final	O
example	O
is	O
to	O
do	O
what	O
you	O
did	O
for	O
perceptron	B
early	B
stopping	I
every	O
iteration	B
you	O
can	O
check	O
the	O
performance	O
of	O
the	O
current	O
model	B
on	O
some	O
held-out	B
data	I
and	O
stop	O
optimizing	O
when	O
performance	O
plateaus	O
from	O
gradients	O
to	O
subgradients	O
as	O
a	O
good	O
exercise	O
you	O
should	O
try	O
deriving	O
gradient	B
descent	I
update	O
rules	O
for	O
the	O
different	O
loss	O
functions	O
and	O
different	O
regularizers	O
you	O
ve	O
learned	O
about	O
however	O
if	O
you	O
do	O
this	O
you	O
might	O
notice	O
that	O
hinge	B
loss	I
and	O
the	O
regularizer	B
are	O
not	O
differentiable	O
everywhere	O
in	O
particular	O
the	O
is	O
not	O
differentiable	O
around	O
wd	O
and	O
the	O
hinge	B
loss	I
is	O
not	O
differentiable	O
around	O
y	O
y	O
linear	O
models	O
the	O
solution	O
to	O
this	O
is	O
to	O
use	O
subgradient	B
optimization	O
one	O
way	O
to	O
think	O
about	O
subgradients	O
is	O
just	O
to	O
not	O
think	O
about	O
it	O
you	O
essentially	O
need	O
to	O
just	O
ignore	O
the	O
fact	O
that	O
you	O
forgot	O
that	O
your	O
function	O
wasn	O
t	O
differentiable	O
and	O
just	O
try	O
to	O
apply	O
gradient	B
descent	I
anyway	O
z	O
this	O
function	O
is	O
differentiable	O
for	O
z	O
and	O
differentiable	O
for	O
z	O
but	O
not	O
differentiable	O
at	O
z	O
you	O
can	O
derive	O
this	O
using	O
differentiation	O
by	O
parts	O
to	O
be	O
more	O
concrete	O
consider	O
the	O
hinge	O
function	O
f	O
z	O
f	O
z	O
z	O
z	O
z	O
z	O
if	O
z	O
if	O
z	O
if	O
z	O
if	O
z	O
if	O
z	O
if	O
z	O
thus	O
the	O
derivative	O
is	O
zero	O
for	O
z	O
and	O
for	O
z	O
matching	O
intuition	O
from	O
the	O
figure	O
at	O
the	O
non-differentiable	O
point	O
z	O
we	O
can	O
use	O
a	O
subderivative	B
a	O
generalization	O
of	O
derivatives	O
to	O
nondifferentiable	O
functions	O
intuitively	O
you	O
can	O
think	O
of	O
the	O
derivative	O
of	O
f	O
at	O
z	O
as	O
the	O
tangent	O
line	O
namely	O
it	O
is	O
the	O
line	O
that	O
touches	O
f	O
at	O
z	O
that	O
is	O
always	O
below	O
f	O
convex	B
functions	O
the	O
subderivative	B
denoted	O
f	O
is	O
the	O
set	O
of	O
all	O
such	O
lines	O
at	O
differentiable	O
positions	O
this	O
set	O
consists	O
just	O
of	O
the	O
actual	O
derivative	O
at	O
non-differentiable	O
positions	O
this	O
contains	O
all	O
slopes	O
that	O
define	O
lines	O
that	O
always	O
lie	O
under	O
the	O
function	O
and	O
make	O
contact	O
at	O
the	O
operating	O
point	O
this	O
is	O
shown	O
pictorally	O
in	O
figure	O
where	O
example	O
subderivatives	O
are	O
shown	O
for	O
the	O
hinge	B
loss	B
function	I
in	O
the	O
particular	O
case	O
of	O
hinge	B
loss	I
any	O
value	O
between	O
and	O
is	O
a	O
valid	O
subderivative	B
at	O
z	O
in	O
fact	O
the	O
subderivative	B
is	O
always	O
a	O
closed	O
set	O
of	O
the	O
form	O
b	O
where	O
a	O
and	O
b	O
can	O
be	O
derived	O
by	O
looking	O
at	O
limits	O
from	O
the	O
left	O
and	O
right	O
figure	O
hinge	B
loss	I
with	O
sub	O
this	O
gives	O
you	O
a	O
way	O
of	O
computing	O
derivative-like	O
things	O
for	O
nondifferentiable	O
functions	O
take	O
hinge	B
loss	I
as	O
an	O
example	O
for	O
a	O
given	O
example	O
n	O
the	O
subgradient	B
of	O
hinge	B
loss	I
can	O
be	O
computed	O
as	O
w	O
ynw	O
xn	O
b	O
otherwise	O
w	O
ynw	O
xn	O
b	O
wynw	O
xn	O
b	O
otherwise	O
if	O
ynw	O
xn	O
b	O
ynxn	O
otherwise	O
if	O
ynw	O
xn	O
b	O
if	O
ynw	O
xn	O
b	O
a	O
course	O
in	O
machine	O
learning	O
algorithm	B
hingeregularizedgdd	O
maxiter	O
w	O
for	O
iter	O
maxiter	O
do	O
g	O
for	O
all	O
d	O
do	O
b	O
g	O
if	O
yw	O
x	O
b	O
then	O
initialize	O
weights	B
and	O
bias	B
initialize	O
gradient	B
of	O
weights	B
and	O
bias	B
g	O
g	O
y	O
x	O
g	O
g	O
y	O
end	O
if	O
end	O
for	O
g	O
g	O
w	O
w	O
w	O
g	O
b	O
b	O
g	O
end	O
for	O
return	O
w	O
b	O
update	O
weight	O
gradient	B
update	O
bias	B
derivative	O
add	O
in	O
regularization	O
term	O
update	O
weights	B
update	O
bias	B
math	O
review	O
matrix	O
multiplication	O
and	O
inversion	O
figure	O
if	O
you	O
plug	O
this	O
subgradient	B
form	O
into	O
algorithm	B
you	O
obtain	O
algorithm	B
this	O
is	O
the	O
subgradient	B
descent	I
for	O
regularized	O
hinge	B
loss	I
a	O
regularizer	B
closed-form	O
optimization	O
for	O
squared	B
loss	I
although	O
gradient	B
descent	I
is	O
a	O
good	O
generic	O
optimization	O
algorithm	B
there	O
are	O
cases	O
when	O
you	O
can	O
do	O
better	O
an	O
example	O
is	O
the	O
case	O
of	O
a	O
regularizer	B
and	O
squared	O
error	O
loss	B
function	I
for	O
this	O
you	O
can	O
actually	O
obtain	O
a	O
closed	O
form	O
solution	O
for	O
the	O
optimal	O
weights	B
however	O
to	O
obtain	O
this	O
you	O
need	O
to	O
rewrite	O
the	O
optimization	B
problem	I
in	O
terms	O
of	O
matrix	O
operations	O
for	O
simplicity	O
we	O
will	O
only	O
consider	O
the	O
unbiased	B
version	O
but	O
the	O
extension	O
is	O
exercise	O
this	O
is	O
precisely	O
the	O
linear	B
regression	I
setting	O
you	O
can	O
think	O
of	O
the	O
training	B
data	I
as	O
a	O
large	O
matrix	O
x	O
of	O
size	O
n	O
d	O
where	O
xnd	O
is	O
the	O
value	O
of	O
the	O
dth	O
feature	O
on	O
the	O
nth	O
example	O
you	O
can	O
think	O
of	O
the	O
labels	O
as	O
a	O
column	O
tall	O
vector	B
y	O
of	O
dimension	O
n	O
finally	O
you	O
can	O
think	O
of	O
the	O
weights	B
as	O
a	O
column	O
vector	B
w	O
of	O
size	O
d	O
thus	O
the	O
matrix-vector	O
product	O
a	O
xw	O
has	O
dimension	O
n	O
in	O
particular	O
an	O
d	O
xndwd	O
this	O
means	O
in	O
particular	O
that	O
a	O
is	O
actually	O
the	O
predictions	O
of	O
the	O
model	B
instead	O
of	O
calling	O
this	O
a	O
we	O
will	O
call	O
it	O
y	O
the	O
squared	O
error	O
linear	O
models	O
verify	O
that	O
the	O
squared	O
error	O
can	O
actually	O
be	O
written	O
as	O
this	O
vector	B
norm	O
says	O
that	O
we	O
should	O
minimize	O
in	O
vector	B
form	O
as	O
a	O
minimization	O
of	O
this	O
can	O
be	O
expanded	O
visually	O
as	O
n	O
yn	O
which	O
can	O
be	O
written	O
xnd	O
x	O
y	O
d	O
d	O
d	O
xndwd	O
y	O
wd	O
w	O
yn	O
y	O
so	O
compactly	O
our	O
optimization	B
problem	I
can	O
be	O
written	O
as	O
min	O
w	O
lw	O
if	O
you	O
recall	B
from	O
calculus	O
you	O
can	O
minimize	O
a	O
function	O
by	O
setting	O
its	O
derivative	O
to	O
zero	O
we	O
start	O
with	O
the	O
weights	B
w	O
and	O
take	O
gradients	O
we	O
can	O
equate	O
this	O
to	O
zero	O
and	O
solve	O
yielding	O
wlw	O
y	O
w	O
w	O
w	O
i	O
i	O
id	O
w	O
w	O
id	O
w	O
thus	O
the	O
optimal	O
solution	O
of	O
the	O
weights	B
can	O
be	O
computed	O
by	O
a	O
few	O
matrix	O
multiplications	O
and	O
a	O
matrix	O
inversion	O
as	O
a	O
sanity	O
check	O
you	O
can	O
make	O
sure	O
that	O
the	O
dimensions	O
match	O
the	O
matrix	O
has	O
dimension	O
d	O
d	O
and	O
therefore	O
so	O
does	O
the	O
inverse	O
term	O
the	O
inverse	O
is	O
d	O
d	O
and	O
is	O
d	O
n	O
so	O
that	O
product	O
is	O
d	O
n	O
multiplying	O
through	O
by	O
the	O
n	O
vector	B
y	O
yields	O
a	O
d	O
vector	B
which	O
is	O
precisely	O
what	O
we	O
want	O
for	O
the	O
weights	B
note	O
that	O
this	O
gives	O
an	O
exact	O
solution	O
modulo	O
numerical	O
innacu	O
racies	O
with	O
computing	O
matrix	O
inverses	O
in	O
contrast	O
gradient	B
descent	I
will	O
give	O
you	O
progressively	O
better	O
solutions	O
and	O
will	O
eventually	O
converge	O
to	O
the	O
optimum	O
at	O
a	O
rate	O
of	O
this	O
means	O
that	O
if	O
you	O
want	O
an	O
answer	O
that	O
s	O
within	O
an	O
accuracy	O
of	O
you	O
will	O
need	O
something	O
on	O
the	O
order	O
of	O
one	O
thousand	O
steps	O
the	O
question	O
is	O
whether	O
getting	O
this	O
exact	O
solution	O
is	O
always	O
more	O
efficient	O
to	O
run	O
gradient	B
descent	I
for	O
one	O
step	O
will	O
take	O
ond	O
time	O
with	O
a	O
relatively	O
small	O
constant	O
you	O
will	O
have	O
to	O
run	O
k	O
iterations	O
for	O
those	O
who	O
are	O
keen	O
on	O
linear	O
algebra	O
you	O
might	O
be	O
worried	O
that	O
the	O
matrix	O
you	O
must	O
invert	O
might	O
not	O
be	O
invertible	O
is	O
this	O
actually	O
a	O
problem	O
a	O
course	O
in	O
machine	O
learning	O
yielding	O
an	O
overall	O
runtime	O
of	O
oknd	O
on	O
the	O
other	O
hand	O
the	O
closed	O
form	O
solution	O
requires	O
constructing	O
which	O
takes	O
time	O
the	O
inversion	O
take	O
time	O
using	O
standard	O
matrix	O
inversion	O
routines	O
the	O
final	O
multiplications	O
take	O
ond	O
time	O
thus	O
the	O
overall	O
runtime	O
is	O
on	O
the	O
order	O
in	O
most	O
standard	O
cases	O
this	O
is	O
becoming	O
less	O
true	O
over	O
time	O
n	O
d	O
so	O
this	O
is	O
dominated	O
by	O
thus	O
the	O
overall	O
question	O
is	O
whether	O
you	O
will	O
need	O
to	O
run	O
more	O
than	O
d-many	O
iterations	O
of	O
gradient	B
descent	I
if	O
so	O
then	O
the	O
matrix	O
inversion	O
will	O
be	O
faster	O
otherwise	O
gradient	B
descent	I
will	O
be	O
faster	O
for	O
low-	O
and	O
medium-dimensional	O
problems	O
d	O
it	O
is	O
probably	O
faster	O
to	O
do	O
the	O
closed	O
form	O
solution	O
via	O
matrix	O
inversion	O
for	O
high	O
dimensional	O
problems	O
it	O
is	O
probably	O
faster	O
to	O
do	O
gradient	B
descent	I
for	O
things	O
in	O
the	O
middle	O
it	O
s	O
hard	O
to	O
say	O
for	O
sure	O
support	O
vector	B
machines	O
at	O
the	O
beginning	O
of	O
this	O
chapter	O
you	O
may	O
have	O
looked	O
at	O
the	O
convex	B
surrogate	B
loss	I
functions	O
and	O
asked	O
yourself	O
where	O
did	O
these	O
come	O
from	O
they	O
are	O
all	O
derived	O
from	O
different	O
underlying	O
principles	O
which	O
essentially	O
correspond	O
to	O
different	O
inductive	O
biases	O
let	O
s	O
start	O
by	O
thinking	O
back	O
to	O
the	O
original	O
goal	O
of	O
linear	B
classifiers	I
to	O
find	O
a	O
hyperplane	B
that	O
separates	O
the	O
positive	O
training	O
examples	B
from	O
the	O
negative	O
ones	O
figure	O
shows	O
some	O
data	O
and	O
three	O
potential	O
hyperplanes	O
red	O
green	O
and	O
blue	O
which	O
one	O
do	O
you	O
like	O
best	O
most	O
likely	O
you	O
chose	O
the	O
green	O
hyperplane	B
and	O
most	O
likely	O
you	O
chose	O
it	O
because	O
it	O
was	O
furthest	O
away	O
from	O
the	O
closest	O
training	O
points	O
in	O
other	O
words	O
it	O
had	O
a	O
large	O
margin	B
the	O
desire	O
for	O
hyperplanes	O
with	O
large	O
margins	O
is	O
a	O
perfect	O
example	O
of	O
an	O
inductive	B
bias	B
the	O
data	O
does	O
not	O
tell	O
us	O
which	O
of	O
the	O
three	O
hyperplanes	O
is	O
best	O
we	O
have	O
to	O
choose	O
one	O
using	O
some	O
other	O
source	O
of	O
information	O
following	O
this	O
line	O
of	O
thinking	O
leads	O
us	O
to	O
the	O
support	O
vector	B
ma	O
chine	O
this	O
is	O
simply	O
a	O
way	O
of	O
setting	O
up	O
an	O
optimization	B
problem	I
that	O
attempts	O
to	O
find	O
a	O
separating	B
hyperplane	B
with	O
as	O
large	O
a	O
margin	B
as	O
possible	O
it	O
is	O
written	O
as	O
a	O
constrained	B
optimization	B
problem	I
figure	O
picture	O
of	O
data	O
points	O
with	O
three	O
hyperplanes	O
rgb	O
with	O
g	O
the	O
best	O
b	O
min	O
wb	O
subj	O
to	O
yn	O
xn	O
b	O
n	O
in	O
this	O
optimization	O
you	O
are	O
trying	O
to	O
find	O
parameters	O
that	O
maximize	O
the	O
margin	B
denoted	O
minimize	O
the	O
reciprocal	O
of	O
the	O
margin	B
linear	O
models	O
figure	O
hyperplane	B
with	O
margins	O
on	O
sides	O
figure	O
one	O
bad	O
point	O
with	O
slack	B
subject	O
to	O
the	O
constraint	O
that	O
all	O
training	O
examples	B
are	O
correctly	O
classified	O
the	O
odd	O
thing	O
about	O
this	O
optimization	B
problem	I
is	O
that	O
we	O
re	O
quire	O
the	O
classification	O
of	O
each	O
point	O
to	O
be	O
greater	O
than	O
one	O
rather	O
than	O
simply	O
greater	O
than	O
zero	O
however	O
the	O
problem	O
doesn	O
t	O
fundamentally	O
change	O
if	O
you	O
replace	O
the	O
with	O
any	O
other	O
positive	O
constant	O
exercise	O
as	O
shown	O
in	O
figure	O
the	O
constant	O
one	O
can	O
be	O
interpreted	O
visually	O
as	O
ensuring	O
that	O
there	O
is	O
a	O
non-trivial	O
margin	B
between	O
the	O
positive	O
points	O
and	O
negative	O
points	O
the	O
difficulty	O
with	O
the	O
optimization	B
problem	I
in	O
eq	O
is	O
what	O
happens	O
with	O
data	O
that	O
is	O
not	O
linearly	B
separable	I
in	O
that	O
case	O
there	O
is	O
no	O
set	O
of	O
parameters	O
w	O
b	O
that	O
can	O
simultaneously	O
satisfy	O
all	O
the	O
constraints	O
in	O
optimization	O
terms	O
you	O
would	O
say	O
that	O
the	O
feasible	B
region	I
is	O
empty	O
feasible	B
region	I
is	O
simply	O
the	O
set	O
of	O
all	O
parameters	O
that	O
satify	O
the	O
constraints	O
for	O
this	O
reason	O
this	O
is	O
refered	O
to	O
as	O
the	O
hard-margin	B
svm	I
because	O
enforcing	O
the	O
margin	B
is	O
a	O
hard	O
constraint	O
the	O
question	O
is	O
how	O
to	O
modify	O
this	O
optimization	B
problem	I
so	O
that	O
it	O
can	O
handle	O
inseparable	O
data	O
the	O
key	O
idea	O
is	O
the	O
use	O
of	O
slack	B
parameters	I
the	O
intuition	O
behind	O
slack	B
parameters	I
is	O
the	O
following	O
suppose	O
we	O
find	O
a	O
set	O
of	O
parameters	O
w	O
b	O
that	O
do	O
a	O
really	O
good	O
job	O
on	O
data	O
points	O
the	O
points	O
are	O
perfectly	O
classifed	O
and	O
you	O
achieve	O
a	O
large	O
margin	B
but	O
there	O
s	O
one	O
pesky	O
data	O
point	O
left	O
that	O
cannot	O
be	O
put	O
on	O
the	O
proper	O
side	O
of	O
the	O
margin	B
perhaps	O
it	O
is	O
noisy	O
figure	O
you	O
want	O
to	O
be	O
able	O
to	O
pretend	O
that	O
you	O
can	O
move	O
that	O
point	O
across	O
the	O
hyperplane	B
on	O
to	O
the	O
proper	O
side	O
you	O
will	O
have	O
to	O
pay	O
a	O
little	O
bit	O
to	O
do	O
so	O
but	O
as	O
long	O
as	O
you	O
aren	O
t	O
moving	O
a	O
lot	O
of	O
points	O
around	O
it	O
should	O
be	O
a	O
good	O
idea	O
to	O
do	O
this	O
in	O
this	O
picture	O
the	O
amount	O
that	O
you	O
move	O
the	O
point	O
is	O
denoted	O
by	O
introducing	O
one	O
slack	B
parameter	O
for	O
each	O
training	O
example	O
and	O
penalizing	O
yourself	O
for	O
having	O
to	O
use	O
slack	B
you	O
can	O
create	O
an	O
objective	B
function	I
like	O
the	O
following	O
soft-margin	B
svm	I
c	O
n	O
n	O
b	O
subj	O
to	O
yn	O
xn	O
b	O
n	O
large	O
margin	B
small	O
slack	B
min	O
wb	O
n	O
n	O
n	O
the	O
goal	O
of	O
this	O
objective	B
function	I
is	O
to	O
ensure	O
that	O
all	O
points	O
are	O
correctly	O
classified	O
first	O
constraint	O
but	O
if	O
a	O
point	O
n	O
cannot	O
be	O
correctly	O
classified	O
then	O
you	O
can	O
set	O
the	O
slack	B
n	O
to	O
something	O
greater	O
than	O
zero	O
to	O
move	O
it	O
in	O
the	O
correct	O
direction	O
however	O
for	O
all	O
nonzero	O
slacks	O
you	O
have	O
to	O
pay	O
in	O
the	O
objective	B
function	I
proportional	O
to	O
the	O
amount	O
of	O
slack	B
the	O
hyperparameter	B
c	O
controls	O
overfitting	B
what	O
values	O
of	O
c	O
will	O
lead	O
to	O
overfitting	B
what	O
values	O
will	O
lead	O
to	O
underfitting	B
suppose	O
i	O
give	O
you	O
a	O
data	O
set	O
without	O
even	O
looking	O
at	O
the	O
data	O
construct	O
for	O
me	O
a	O
feasible	O
solution	O
to	O
the	O
soft-margin	B
svm	I
what	O
is	O
the	O
value	O
of	O
the	O
objective	O
for	O
this	O
solution	O
a	O
course	O
in	O
machine	O
learning	O
versus	O
underfitting	B
the	O
second	O
constraint	O
simply	O
says	O
that	O
you	O
must	O
not	O
have	O
negative	O
slack	B
one	O
major	O
advantage	O
of	O
the	O
soft-margin	B
svm	I
over	O
the	O
original	O
hard-margin	B
svm	I
is	O
that	O
the	O
feasible	B
region	I
is	O
never	O
empty	O
that	O
is	O
there	O
is	O
always	O
going	O
to	O
be	O
some	O
solution	O
regardless	O
of	O
whether	O
your	O
training	B
data	I
is	O
linearly	B
separable	I
or	O
not	O
it	O
s	O
one	O
thing	O
to	O
write	O
down	O
an	O
optimization	B
problem	I
it	O
s	O
another	O
thing	O
to	O
try	O
to	O
solve	O
it	O
there	O
are	O
a	O
very	O
large	O
number	O
of	O
ways	O
to	O
optimize	O
svms	O
essentially	O
because	O
they	O
are	O
such	O
a	O
popular	O
learning	O
model	B
here	O
we	O
will	O
talk	O
just	O
about	O
one	O
very	O
simple	O
way	O
more	O
complex	O
methods	O
will	O
be	O
discussed	O
later	O
in	O
this	O
book	O
once	O
you	O
have	O
a	O
bit	O
more	O
background	O
by	O
this	O
observation	O
there	O
is	O
some	O
positive	O
example	O
that	O
that	O
lies	O
to	O
make	O
progress	O
you	O
need	O
to	O
be	O
able	O
to	O
measure	O
the	O
size	O
of	O
the	O
margin	B
suppose	O
someone	O
gives	O
you	O
parameters	O
w	O
b	O
that	O
optimize	O
the	O
hard-margin	B
svm	I
we	O
wish	O
to	O
measure	O
the	O
size	O
of	O
the	O
margin	B
the	O
first	O
observation	O
is	O
that	O
the	O
hyperplane	B
will	O
lie	O
exactly	O
halfway	O
between	O
the	O
nearest	O
positive	O
point	O
and	O
nearest	O
negative	O
point	O
if	O
not	O
the	O
margin	B
could	O
be	O
made	O
bigger	O
by	O
simply	O
sliding	O
it	O
one	O
way	O
or	O
the	O
other	O
by	O
adjusting	O
the	O
bias	B
b	O
exactly	O
unit	O
from	O
the	O
hyperplane	B
call	O
it	O
x	O
so	O
that	O
w	O
x	O
b	O
similarly	O
there	O
is	O
some	O
negative	O
example	O
x	O
that	O
lies	O
exactly	O
on	O
the	O
other	O
side	O
of	O
the	O
margin	B
for	O
which	O
w	O
x	O
b	O
these	O
two	O
points	O
x	O
and	O
x	O
give	O
us	O
a	O
way	O
to	O
measure	O
the	O
size	O
of	O
the	O
margin	B
as	O
shown	O
in	O
figure	O
we	O
can	O
measure	O
the	O
size	O
of	O
the	O
margin	B
by	O
looking	O
at	O
the	O
difference	O
between	O
the	O
lengths	O
of	O
projections	O
of	O
x	O
and	O
x	O
onto	O
the	O
hyperplane	B
since	O
projection	O
requires	O
a	O
normalized	O
vector	B
we	O
can	O
measure	O
the	O
distances	O
as	O
d	O
d	O
w	O
x	O
b	O
w	O
x	O
b	O
d	O
w	O
x	O
w	O
x	O
b	O
w	O
x	O
b	O
w	O
x	O
we	O
can	O
then	O
compute	O
the	O
margin	B
by	O
algebra	O
figure	O
copy	O
of	O
figure	O
from	O
of	O
svm	O
tutorial	O
linear	O
models	O
this	O
is	O
a	O
remarkable	O
conclusion	O
the	O
size	O
of	O
the	O
margin	B
is	O
inversely	O
proportional	O
to	O
the	O
norm	O
of	O
the	O
weight	O
vector	B
thus	O
maximizing	O
the	O
margin	B
is	O
equivalent	O
to	O
minimizing	O
this	O
serves	O
as	O
an	O
additional	O
justification	O
of	O
the	O
regularizer	B
having	O
small	O
weights	B
means	O
having	O
large	O
margins	O
however	O
our	O
goal	O
wasn	O
t	O
to	O
justify	O
the	O
regularizer	B
it	O
was	O
to	O
understand	O
hinge	B
loss	I
so	O
let	O
us	O
go	O
back	O
to	O
the	O
soft-margin	B
svm	I
and	O
plug	O
in	O
our	O
new	O
knowledge	O
about	O
margins	O
min	O
wb	O
c	O
n	O
large	O
margin	B
subj	O
to	O
yn	O
xn	O
b	O
n	O
small	O
slack	B
n	O
n	O
n	O
n	O
now	O
let	O
s	O
play	O
a	O
thought	O
experiment	O
suppose	O
someone	O
handed	O
you	O
a	O
solution	O
to	O
this	O
optimization	B
problem	I
that	O
consisted	O
of	O
weights	B
and	O
a	O
bias	B
but	O
they	O
forgot	O
to	O
give	O
you	O
the	O
slacks	O
could	O
you	O
recover	O
the	O
slacks	O
from	O
the	O
information	O
you	O
have	O
in	O
fact	O
the	O
answer	O
is	O
yes	O
for	O
simplicity	O
let	O
s	O
consider	O
positive	O
examples	B
suppose	O
that	O
you	O
look	O
at	O
some	O
positive	O
example	O
xn	O
you	O
need	O
to	O
figure	O
out	O
what	O
the	O
slack	B
n	O
would	O
have	O
been	O
there	O
are	O
two	O
cases	O
either	O
w	O
xn	O
b	O
is	O
at	O
least	O
or	O
it	O
is	O
not	O
if	O
it	O
s	O
large	O
enough	O
then	O
you	O
want	O
to	O
set	O
n	O
why	O
it	O
cannot	O
be	O
less	O
than	O
zero	O
by	O
the	O
second	O
constraint	O
moreover	O
if	O
you	O
set	O
it	O
greater	O
than	O
zero	O
you	O
will	O
pay	O
unnecessarily	O
in	O
the	O
objective	O
so	O
in	O
this	O
case	O
n	O
next	O
suppose	O
that	O
w	O
xn	O
b	O
so	O
it	O
is	O
not	O
big	O
enough	O
in	O
order	O
to	O
satisfy	O
the	O
first	O
constraint	O
you	O
ll	O
need	O
to	O
set	O
n	O
but	O
because	O
of	O
the	O
objective	O
you	O
ll	O
not	O
want	O
to	O
set	O
it	O
any	O
larger	O
than	O
necessary	O
so	O
you	O
ll	O
set	O
n	O
exactly	O
following	O
this	O
argument	O
through	O
for	O
both	O
positive	O
and	O
negative	O
points	O
if	O
someone	O
gives	O
you	O
solutions	O
for	O
w	O
b	O
you	O
can	O
automatically	O
compute	O
the	O
optimal	O
variables	O
as	O
n	O
ynw	O
xn	O
b	O
otherwise	O
if	O
ynw	O
xn	O
b	O
in	O
other	O
words	O
the	O
optimal	O
value	O
for	O
a	O
slack	B
variable	O
is	O
exactly	O
the	O
hinge	B
loss	I
on	O
the	O
corresponding	O
example	O
thus	O
we	O
can	O
write	O
the	O
svm	O
objective	O
as	O
an	O
unconstrained	O
optimization	B
problem	I
min	O
wb	O
large	O
margin	B
c	O
n	O
w	O
xn	O
b	O
small	O
slack	B
multiplying	O
this	O
objective	O
through	O
by	O
we	O
obtain	O
exactly	O
the	O
regularized	B
objective	I
from	O
eq	O
with	O
hinge	B
loss	I
as	O
the	O
loss	B
function	I
and	O
the	O
as	O
the	O
regularizer	B
a	O
course	O
in	O
machine	O
learning	O
todo	O
justify	O
in	O
term	O
of	O
one	O
dimensional	O
projections	O
exercises	O
exercise	O
todo	O
probabilistic	B
modeling	B
learning	O
objectives	O
define	O
the	O
generative	B
story	I
for	O
a	O
naive	O
bayes	O
classifier	O
derive	O
relative	O
frequency	O
as	O
the	O
solution	O
to	O
a	O
constrained	B
optimization	B
problem	I
compare	O
and	O
contrast	O
generative	O
conditional	O
and	O
discriminative	O
learning	O
explain	O
when	O
generative	O
models	O
are	O
likely	O
to	O
fail	O
derive	O
logistic	B
loss	I
with	O
an	O
regularizer	B
from	O
a	O
probabilistic	O
perspective	O
dependencies	O
many	O
of	O
the	O
models	O
and	O
algorithms	O
you	O
have	O
learned	O
about	O
thus	O
far	O
are	O
relatively	O
disconnected	O
there	O
is	O
an	O
alternative	O
view	O
of	O
machine	O
learning	O
that	O
unites	O
and	O
generalizes	O
much	O
of	O
what	O
you	O
have	O
already	O
learned	O
this	O
is	O
the	O
probabilistic	B
modeling	B
framework	O
in	O
which	O
you	O
will	O
explicitly	O
think	O
of	O
learning	O
as	O
a	O
problem	O
of	O
statistical	B
inference	I
in	O
this	O
chapter	O
you	O
will	O
learn	O
about	O
two	O
flavors	O
of	O
probabilistic	O
models	O
generative	O
and	O
conditional	O
you	O
will	O
see	O
that	O
many	O
of	O
the	O
approaches	O
supervised	O
and	O
unsupervised	O
we	O
have	O
seen	O
already	O
can	O
be	O
cast	O
as	O
probabilistic	O
models	O
through	O
this	O
new	O
view	O
you	O
will	O
be	O
able	O
to	O
develop	O
learning	O
algorithms	O
that	O
have	O
inductive	O
biases	O
closer	O
to	O
what	O
you	O
as	O
a	O
designer	O
believe	O
moreover	O
the	O
two	O
chapters	O
that	O
follow	O
will	O
make	O
heavy	O
use	O
of	O
the	O
probabilistic	B
modeling	B
approach	O
to	O
open	O
doors	O
to	O
other	O
learning	O
problems	O
classification	O
by	O
density	O
estimation	O
our	O
underlying	O
assumption	O
for	O
the	O
majority	O
of	O
this	O
book	O
is	O
that	O
learning	O
problems	O
are	O
characterized	O
by	O
some	O
unknown	O
probability	O
distribution	O
d	O
over	O
inputoutput	O
pairs	O
y	O
x	O
y	O
suppose	O
that	O
someone	O
told	O
you	O
what	O
d	O
was	O
in	O
particular	O
they	O
gave	O
you	O
a	O
python	O
function	O
computed	O
that	O
took	O
two	O
inputs	O
x	O
and	O
y	O
and	O
returned	O
the	O
probability	O
of	O
that	O
x	O
y	O
pair	O
under	O
d	O
if	O
you	O
had	O
access	O
to	O
such	O
a	O
function	O
classification	O
becomes	O
simple	O
we	O
can	O
define	O
the	O
bayes	B
optimal	I
classifier	I
as	O
the	O
classifier	O
that	O
for	O
any	O
test	O
input	O
x	O
simply	O
returns	O
the	O
y	O
that	O
maximizes	O
computed	O
x	O
y	O
or	O
more	O
formally	O
f	O
x	O
arg	O
max	O
y	O
y	O
d	O
x	O
y	O
this	O
classifier	O
is	O
optimal	O
in	O
one	O
specific	O
sense	O
of	O
all	O
possible	O
classifiers	O
it	O
achieves	O
the	O
smallest	O
zeroone	O
error	O
theorem	O
optimal	O
classifier	O
the	O
bayes	B
optimal	I
classifier	I
f	O
achieves	O
minimal	O
zeroone	O
error	O
of	O
any	O
deterministic	O
classifier	O
figure	O
a	O
course	O
in	O
machine	O
learning	O
math	O
review	O
rules	O
of	O
probability	O
chain	B
rule	I
marginalization	O
and	O
bayes	O
rule	O
this	O
theorem	O
assumes	O
that	O
you	O
are	O
comparing	O
against	O
deterministic	O
classifiers	O
you	O
can	O
actually	O
prove	O
a	O
stronger	O
result	O
that	O
f	O
is	O
optimal	O
for	O
randomized	O
classifiers	O
as	O
well	O
but	O
the	O
proof	O
is	O
a	O
bit	O
messier	O
however	O
the	O
intuition	O
is	O
the	O
same	O
for	O
a	O
given	O
x	O
f	O
chooses	O
the	O
label	B
with	O
highest	O
probability	O
thus	O
minimizing	O
the	O
probability	O
that	O
it	O
makes	O
an	O
error	O
proof	O
of	O
theorem	O
consider	O
some	O
other	O
classifier	O
g	O
that	O
claims	O
to	O
be	O
better	O
than	O
f	O
then	O
there	O
must	O
be	O
some	O
x	O
on	O
which	O
gx	O
f	O
fix	O
such	O
an	O
x	O
now	O
the	O
probability	O
that	O
f	O
makes	O
an	O
error	O
on	O
this	O
particular	O
x	O
is	O
dx	O
f	O
and	O
the	O
probability	O
that	O
g	O
makes	O
an	O
error	O
on	O
this	O
x	O
is	O
dx	O
gx	O
but	O
f	O
was	O
chosen	O
in	O
such	O
a	O
way	O
to	O
maximize	O
dx	O
f	O
so	O
this	O
must	O
be	O
greater	O
than	O
dx	O
gx	O
thus	O
the	O
probability	O
that	O
f	O
errs	O
on	O
this	O
particular	O
x	O
is	O
smaller	O
than	O
the	O
probability	O
that	O
g	O
errs	O
on	O
it	O
this	O
applies	O
to	O
any	O
x	O
for	O
which	O
f	O
gx	O
and	O
therefore	O
f	O
achieves	O
smaller	O
zeroone	O
error	O
than	O
any	O
g	O
the	O
bayes	B
error	B
rate	I
bayes	B
optimal	I
error	B
rate	I
is	O
the	O
error	B
rate	I
of	O
the	O
bayes	B
optimal	I
classifier	I
it	O
is	O
the	O
best	O
error	B
rate	I
you	O
can	O
ever	O
hope	O
to	O
achieve	O
on	O
this	O
classification	O
problem	O
zeroone	O
loss	O
the	O
take-home	O
message	O
is	O
that	O
if	O
someone	O
gave	O
you	O
access	O
to	O
the	O
data	O
distribution	O
forming	O
an	O
optimal	O
classifier	O
would	O
be	O
trivial	O
unfortunately	O
no	O
one	O
gave	O
you	O
this	O
distribution	O
but	O
this	O
analysis	O
suggests	O
that	O
good	O
way	O
to	O
build	O
a	O
classifier	O
is	O
to	O
try	O
to	O
estimate	O
d	O
in	O
other	O
words	O
you	O
try	O
to	O
learn	O
a	O
distribution	O
d	O
which	O
you	O
hope	O
to	O
very	O
similar	O
to	O
d	O
and	O
then	O
use	O
this	O
distribution	O
for	O
classification	O
just	O
as	O
in	O
the	O
preceding	O
chapters	O
you	O
can	O
try	O
to	O
form	O
your	O
estimate	O
of	O
d	O
based	O
on	O
a	O
finite	O
training	O
set	O
the	O
most	O
direct	O
way	O
that	O
you	O
can	O
attempt	O
to	O
construct	O
such	O
a	O
probability	O
distribution	O
is	O
to	O
select	O
a	O
family	O
of	O
parametric	O
distributions	O
for	O
instance	O
a	O
gaussian	O
normal	B
distribution	I
is	O
parametric	O
it	O
s	O
parameters	O
are	O
its	O
mean	O
and	O
covariance	O
the	O
job	O
of	O
learning	O
is	O
then	O
to	O
infer	O
which	O
parameters	O
are	O
best	O
as	O
far	O
as	O
the	O
observed	O
training	B
data	I
is	O
concerned	O
as	O
well	O
as	O
whatever	O
inductive	B
bias	B
you	O
bring	O
a	O
key	O
assumption	O
that	O
you	O
will	O
need	O
to	O
make	O
is	O
that	O
the	O
training	B
data	I
you	O
have	O
access	O
to	O
is	O
drawn	O
independently	B
from	O
d	O
in	O
particular	O
as	O
you	O
draw	O
examples	B
d	O
then	O
d	O
and	O
so	O
on	O
the	O
nth	O
draw	O
yn	O
is	O
drawn	O
from	O
d	O
and	O
does	O
not	O
otherwise	O
depend	O
probabilistic	B
modeling	B
describe	O
a	O
case	O
in	O
which	O
at	O
least	O
one	O
of	O
the	O
assumptions	O
we	O
are	O
making	O
about	O
the	O
coin	O
flip	O
is	O
false	O
on	O
the	O
previous	O
n	O
samples	O
this	O
assumption	O
is	O
usually	O
false	O
but	O
is	O
also	O
usually	O
sufficiently	O
close	O
to	O
being	O
true	O
to	O
be	O
useful	O
together	O
with	O
the	O
assumption	O
that	O
all	O
the	O
training	B
data	I
is	O
drawn	O
from	O
the	O
same	O
distribution	O
d	O
leads	O
to	O
the	O
i	O
i	O
d	O
assumption	O
or	O
independently	B
and	O
identically	O
distributed	O
assumption	O
this	O
is	O
a	O
key	O
assumption	O
in	O
almost	O
all	O
of	O
machine	O
learning	O
statistical	O
estimation	O
suppose	O
you	O
need	O
to	O
model	B
a	O
coin	O
that	O
is	O
possibly	O
biased	O
can	O
think	O
of	O
this	O
as	O
modeling	B
the	O
label	B
in	O
a	O
binary	O
classification	O
problem	O
and	O
that	O
you	O
observe	O
data	O
hhth	O
h	O
means	O
a	O
flip	O
came	O
up	O
heads	O
and	O
t	O
means	O
it	O
came	O
up	O
tails	O
you	O
can	O
assume	O
that	O
all	O
the	O
flips	O
came	O
from	O
the	O
same	O
coin	O
and	O
that	O
each	O
flip	O
was	O
independent	O
the	O
data	O
was	O
i	O
i	O
d	O
further	O
you	O
may	O
choose	O
to	O
believe	O
that	O
the	O
coin	O
has	O
a	O
fixed	O
probability	O
of	O
coming	O
up	O
heads	O
hence	O
of	O
coming	O
up	O
tails	O
thus	O
the	O
parameter	O
of	O
your	O
model	B
is	O
simply	O
the	O
scalar	O
the	O
most	O
basic	O
computation	O
you	O
might	O
perform	O
is	O
maximum	O
like	O
lihood	O
estimation	O
namely	O
select	O
the	O
paramter	O
the	O
maximizes	O
the	O
probability	O
of	O
the	O
data	O
under	O
that	O
parameter	O
in	O
order	O
to	O
do	O
so	O
you	O
need	O
to	O
compute	O
the	O
probability	O
of	O
the	O
data	O
p	O
p	O
p	O
definition	O
of	O
d	O
data	O
is	O
independent	O
thus	O
if	O
you	O
want	O
the	O
parameter	O
that	O
maximizes	O
the	O
probability	O
of	O
the	O
data	O
you	O
can	O
take	O
the	O
derivative	O
of	O
with	O
respect	O
to	O
set	O
it	O
equal	O
to	O
zero	O
and	O
solve	O
for	O
thus	O
the	O
maximum	O
likelihood	B
is	O
which	O
is	O
probably	O
what	O
you	O
would	O
have	O
selected	O
by	O
intuition	O
you	O
can	O
solve	O
this	O
problem	O
more	O
generally	O
as	O
follows	O
if	O
you	O
have	O
h-many	O
heads	O
and	O
t-many	O
tails	O
the	O
probability	O
of	O
your	O
data	O
sequence	O
is	O
you	O
can	O
try	O
to	O
take	O
the	O
derivative	O
of	O
this	O
with	O
respect	O
to	O
and	O
follow	O
the	O
same	O
recipe	O
but	O
all	O
of	O
the	O
products	O
make	O
things	O
difficult	O
a	O
more	O
how	O
do	O
you	O
know	O
that	O
the	O
solution	O
of	O
hh	O
t	O
is	O
actually	O
a	O
maximum	O
a	O
course	O
in	O
machine	O
learning	O
friendly	O
solution	O
is	O
to	O
work	O
with	O
the	O
log	B
likelihood	B
or	O
log	B
probability	I
instead	O
the	O
log	B
likelihood	B
of	O
this	O
data	O
sequence	O
is	O
h	O
log	O
t	O
differentiating	O
with	O
respect	O
to	O
you	O
get	O
h	O
to	O
solve	O
you	O
obtain	O
h	O
so	O
t	O
thus	O
h	O
h	O
t	O
and	O
so	O
h	O
t	O
finally	O
yeilding	O
that	O
hh	O
t	O
or	O
simply	O
the	O
fraction	O
of	O
observed	O
data	O
that	O
came	O
up	O
heads	O
in	O
this	O
case	O
the	O
maximum	O
likelihood	B
estimate	O
is	O
nothing	O
but	O
the	O
relative	O
frequency	O
of	O
observing	O
heads	O
now	O
suppose	O
that	O
instead	O
of	O
flipping	O
a	O
coin	O
you	O
re	O
rolling	O
a	O
k	O
sided	O
die	O
instance	O
to	O
pick	O
the	O
label	B
for	O
a	O
multiclass	O
classification	O
problem	O
you	O
might	O
model	B
this	O
by	O
saying	O
that	O
there	O
are	O
parameters	O
k	O
specifying	O
respectively	O
the	O
probabilities	O
that	O
any	O
given	O
side	O
comes	O
up	O
on	O
a	O
role	O
since	O
these	O
are	O
themselves	O
probabilities	O
each	O
k	O
should	O
be	O
at	O
least	O
zero	O
and	O
the	O
sum	O
of	O
the	O
ks	O
should	O
be	O
one	O
given	O
a	O
data	O
set	O
that	O
consists	O
of	O
rolls	O
of	O
rolls	O
of	O
and	O
so	O
on	O
the	O
probability	O
of	O
this	O
data	O
is	O
k	O
k	O
xk	O
log	O
k	O
if	O
you	O
pick	O
some	O
particular	O
parameter	O
say	O
the	O
derivative	O
of	O
this	O
with	O
respect	O
to	O
is	O
which	O
you	O
want	O
to	O
equate	O
to	O
zero	O
this	O
leads	O
to	O
xk	O
k	O
yielding	O
a	O
log	B
probability	I
of	O
this	O
is	O
obviously	O
wrong	O
from	O
the	O
mathematical	O
formulation	O
xk	O
k	O
it	O
s	O
correct	O
in	O
fact	O
setting	O
all	O
of	O
the	O
ks	O
to	O
does	O
maximize	O
k	O
for	O
any	O
xks	O
the	O
problem	O
is	O
that	O
you	O
need	O
to	O
constrain	O
the	O
s	O
to	O
sum	O
to	O
one	O
in	O
particular	O
you	O
have	O
a	O
constraint	O
that	O
k	O
k	O
that	O
you	O
forgot	O
to	O
enforce	O
a	O
convenient	O
way	O
to	O
enforce	O
such	O
constraints	O
is	O
through	O
the	O
technique	O
of	O
lagrange	B
multipliers	I
to	O
make	O
this	O
problem	O
consistent	O
with	O
standard	O
minimization	O
problems	O
it	O
is	O
convenient	O
to	O
minimize	O
negative	O
log	O
probabilities	O
instead	O
of	O
maximizing	O
log	O
probabilities	O
thus	O
the	O
constrainted	O
optimization	B
problem	I
is	O
k	O
xk	O
log	O
k	O
k	O
min	O
subj	O
to	O
k	O
the	O
lagrange	O
multiplier	O
approach	O
involves	O
adding	O
a	O
new	O
variable	O
to	O
the	O
problem	O
the	O
lagrange	B
variable	I
corresponding	O
to	O
the	O
constraint	O
and	O
to	O
use	O
that	O
to	O
move	O
the	O
constraint	O
into	O
the	O
objective	O
the	O
result	O
in	O
this	O
case	O
is	O
max	O
min	O
xk	O
log	O
k	O
k	O
k	O
k	O
turning	O
a	O
constrained	B
optimization	B
problem	I
into	O
it	O
s	O
corresponding	O
lagrangian	B
is	O
straightforward	O
the	O
mystical	O
aspect	O
is	O
why	O
it	O
works	O
in	O
this	O
case	O
the	O
idea	O
is	O
as	O
follows	O
think	O
of	O
as	O
an	O
adversary	O
probabilistic	B
modeling	B
is	O
trying	O
to	O
maximize	O
this	O
function	O
re	O
trying	O
to	O
minimize	O
it	O
if	O
you	O
pick	O
some	O
parameters	O
that	O
actually	O
satisfy	O
the	O
constraint	O
then	O
the	O
green	O
term	O
in	O
eq	O
goes	O
to	O
zero	O
and	O
therefore	O
does	O
not	O
matter	O
the	O
adversary	O
cannot	O
do	O
anything	O
on	O
the	O
other	O
hand	O
if	O
the	O
constraint	O
is	O
even	O
slightly	O
unsatisfied	O
then	O
can	O
tend	O
toward	O
or	O
to	O
blow	O
up	O
the	O
objective	O
so	O
in	O
order	O
to	O
have	O
a	O
non-infinite	O
objective	O
value	O
the	O
optimizer	O
must	O
find	O
values	O
of	O
that	O
satisfy	O
the	O
constraint	O
if	O
we	O
solve	O
the	O
inner	O
optimization	O
of	O
eq	O
by	O
differentiating	O
with	O
respect	O
to	O
we	O
get	O
yielding	O
in	O
general	O
the	O
solution	O
is	O
k	O
xk	O
remembering	O
that	O
the	O
goal	O
of	O
is	O
to	O
enforce	O
the	O
sums-to-one	O
constraint	O
we	O
can	O
set	O
k	O
xk	O
and	O
verify	O
that	O
this	O
is	O
a	O
solution	O
thus	O
our	O
optimal	O
k	O
xk	O
k	O
xk	O
which	O
again	O
completely	O
corresponds	O
to	O
intuition	O
naive	O
bayes	O
models	O
now	O
consider	O
the	O
binary	O
classification	O
problem	O
you	O
are	O
looking	O
for	O
a	O
parameterized	O
probability	O
distribution	O
that	O
can	O
describe	O
the	O
training	B
data	I
you	O
have	O
to	O
be	O
concrete	O
your	O
task	O
might	O
be	O
to	O
predict	B
whether	O
a	O
movie	O
review	O
is	O
positive	O
or	O
negative	O
based	O
on	O
what	O
words	O
appear	O
in	O
that	O
review	O
thus	O
the	O
probability	O
for	O
a	O
single	O
data	O
point	O
can	O
be	O
written	O
as	O
p	O
x	O
p	O
xd	O
the	O
challenge	O
in	O
working	O
with	O
a	O
probability	O
distribution	O
like	O
eq	O
is	O
that	O
it	O
s	O
a	O
distribution	O
over	O
a	O
lot	O
of	O
variables	O
you	O
can	O
try	O
to	O
simplify	O
it	O
by	O
applying	O
the	O
chain	B
rule	I
of	O
probabilities	O
p	O
xd	O
y	O
p	O
yp	O
y	O
y	O
p	O
y	O
xd	O
p	O
y	O
xd	O
p	O
d	O
at	O
this	O
point	O
this	O
equality	O
is	O
exact	O
for	O
any	O
probability	O
distribution	O
however	O
it	O
might	O
be	O
difficult	O
to	O
craft	O
a	O
probability	O
distribution	O
for	O
the	O
feature	O
given	O
the	O
previous	O
even	O
if	O
you	O
could	O
it	O
might	O
be	O
difficult	O
to	O
accurately	O
estimate	O
it	O
at	O
this	O
point	O
you	O
can	O
make	O
assumptions	O
a	O
classic	O
assumption	O
called	O
the	O
naive	B
bayes	I
assumption	I
is	O
that	O
the	O
features	B
are	O
independent	O
conditioned	O
on	O
the	O
label	B
in	O
the	O
movie	O
review	O
example	O
this	O
is	O
saying	O
that	O
once	O
you	O
know	O
that	O
it	O
s	O
a	O
positive	O
review	O
the	O
probability	O
that	O
the	O
word	O
excellent	O
appears	O
is	O
independent	O
of	O
whether	O
amazing	O
also	O
appeared	O
that	O
this	O
does	O
not	O
imply	O
that	O
these	O
words	O
are	O
independent	O
when	O
you	O
a	O
course	O
in	O
machine	O
learning	O
don	O
t	O
know	O
the	O
label	B
they	O
most	O
certainly	O
are	O
not	O
formally	O
this	O
assumption	O
states	O
that	O
assumption	O
d	O
under	O
this	O
assumption	O
you	O
can	O
simplify	O
eq	O
to	O
pxd	O
y	O
pxd	O
y	O
p	O
x	O
p	O
d	O
p	O
y	O
naive	B
bayes	I
assumption	I
at	O
this	O
point	O
you	O
can	O
start	O
parameterizing	O
p	O
suppose	O
for	O
now	O
that	O
your	O
labels	O
are	O
binary	O
and	O
your	O
features	B
are	O
also	O
binary	O
in	O
this	O
case	O
you	O
could	O
model	B
the	O
label	B
as	O
a	O
biased	O
coin	O
with	O
probability	O
of	O
heads	O
positive	O
review	O
given	O
by	O
then	O
for	O
each	O
label	B
you	O
can	O
imagine	O
having	O
one	O
coin	O
for	O
each	O
feature	O
so	O
if	O
there	O
are	O
d-many	O
features	B
you	O
ll	O
have	O
total	O
coins	O
one	O
for	O
the	O
label	B
it	O
and	O
one	O
for	O
each	O
labelfeature	O
combination	O
these	O
and	O
as	O
in	O
the	O
movie	O
review	O
example	O
we	O
might	O
expect	O
percent	O
of	O
movie	O
reviews	O
are	O
positive	O
and	O
also	O
that	O
might	O
give	O
high	O
probability	O
to	O
words	O
like	O
excellent	O
and	O
amazing	O
and	O
good	O
and	O
might	O
give	O
high	O
probability	O
to	O
words	O
like	O
terrible	O
and	O
boring	O
and	O
hate	O
you	O
can	O
rewrite	O
the	O
probability	O
of	O
a	O
single	O
example	O
as	O
follows	O
eventually	O
leading	O
to	O
the	O
log	B
probability	I
of	O
the	O
entire	O
data	O
set	O
p	O
x	O
p	O
p	O
y	O
d	O
naive	B
bayes	I
assumption	I
model	B
assumptions	O
d	O
solving	O
for	O
is	O
identical	O
to	O
solving	O
for	O
the	O
biased	O
coin	O
case	O
from	O
before	O
it	O
is	O
just	O
the	O
relative	O
frequency	O
of	O
positive	O
labels	O
in	O
your	O
data	O
doesn	O
t	O
depend	O
on	O
x	O
at	O
all	O
for	O
the	O
other	O
parameters	O
you	O
can	O
repeat	O
the	O
same	O
exercise	O
as	O
before	O
for	O
each	O
of	O
the	O
coins	O
independently	B
this	O
yields	O
n	O
n	O
nyn	O
xnd	O
nyn	O
xnd	O
nyn	O
nyn	O
in	O
the	O
case	O
that	O
the	O
features	B
are	O
not	O
binary	O
you	O
need	O
to	O
choose	O
a	O
different	O
model	B
for	O
pxd	O
y	O
the	O
model	B
we	O
chose	O
here	O
is	O
the	O
bernouilli	B
distribution	I
which	O
is	O
effectively	O
a	O
distribution	O
over	O
independent	O
probabilistic	B
modeling	B
math	O
review	O
common	O
probability	O
distributions	O
remove	O
people	O
about	O
discrete	O
bernoulli	O
binomial	O
multinomial	O
and	O
gaussian	O
distributions	O
figure	O
coin	O
flips	O
for	O
other	O
types	O
of	O
data	O
other	O
distributions	O
become	O
more	O
appropriate	O
the	O
die	O
example	O
from	O
before	O
corresponds	O
to	O
a	O
discrete	B
distribution	I
if	O
the	O
data	O
is	O
continuous	O
you	O
might	O
choose	O
to	O
use	O
a	O
gaussian	B
distribution	I
normal	B
distribution	I
the	O
choice	O
of	O
distribution	O
is	O
a	O
form	O
of	O
inductive	B
bias	B
by	O
which	O
you	O
can	O
inject	O
your	O
knowledge	O
of	O
the	O
problem	O
into	O
the	O
learning	O
algorithm	B
prediction	O
consider	O
the	O
predictions	O
made	O
by	O
the	O
naive	O
bayes	O
model	B
with	O
bernoulli	O
features	B
in	O
eq	O
you	O
can	O
better	O
understand	O
this	O
model	B
by	O
considering	O
its	O
decision	B
boundary	I
in	O
the	O
case	O
of	O
probabilistic	O
models	O
the	O
decision	B
boundary	I
is	O
the	O
set	O
of	O
inputs	O
for	O
which	O
the	O
likelihood	B
of	O
y	O
is	O
precisely	O
or	O
in	O
other	O
words	O
the	O
set	O
of	O
inputs	O
x	O
for	O
which	O
py	O
xpy	O
x	O
in	O
order	O
to	O
do	O
this	O
the	O
first	O
thing	O
to	O
notice	O
is	O
that	O
py	O
x	O
py	O
xpx	O
in	O
the	O
ratio	O
the	O
px	O
terms	O
cancel	O
leaving	O
py	O
xpy	O
x	O
instead	O
of	O
computing	O
this	O
ratio	O
it	O
is	O
easier	O
to	O
compute	O
the	O
log-likelihood	B
ratio	I
llr	O
log	O
py	O
x	O
log	O
py	O
x	O
computed	O
below	O
llr	O
log	O
d	O
log	O
d	O
log	O
log	O
log	O
d	O
d	O
d	O
xd	O
log	O
log	O
d	O
log	O
log	O
log	O
d	O
d	O
xd	O
log	O
xd	O
log	O
x	O
w	O
b	O
model	B
assumptions	O
take	O
logs	O
and	O
rearrange	O
simplify	O
log	O
terms	O
group	O
x-terms	O
a	O
course	O
in	O
machine	O
learning	O
wd	O
log	O
b	O
d	O
log	O
log	O
the	O
result	O
of	O
the	O
algebra	O
is	O
that	O
the	O
naive	O
bayes	O
model	B
has	O
precisely	O
the	O
form	O
of	O
a	O
linear	O
model	B
thus	O
like	O
perceptron	B
and	O
many	O
of	O
the	O
other	O
models	O
you	O
ve	O
previous	O
studied	O
the	O
decision	B
boundary	I
is	O
linear	O
todo	O
mbr	O
generative	O
stories	O
a	O
useful	O
way	O
to	O
develop	O
probabilistic	O
models	O
is	O
to	O
tell	O
a	O
generative	B
story	I
this	O
is	O
a	O
fictional	O
story	O
that	O
explains	O
how	O
you	O
believe	O
your	O
training	B
data	I
came	O
into	O
existence	O
to	O
make	O
things	O
interesting	O
consider	O
a	O
multiclass	O
classification	O
problem	O
with	O
continuous	O
features	B
modeled	O
by	O
independent	O
gaussians	O
since	O
the	O
label	B
can	O
take	O
values	O
k	O
you	O
can	O
use	O
a	O
discrete	B
distribution	I
roll	O
to	O
model	B
it	O
opposed	O
to	O
the	O
bernoilli	O
distribution	O
from	O
before	O
for	O
each	O
example	O
n	O
n	O
choose	O
a	O
label	B
yn	O
disc	O
for	O
each	O
feature	O
d	O
d	O
i	O
choose	O
feature	O
value	O
xnd	O
nor	O
ynd	O
ynd	O
this	O
generative	B
story	I
can	O
be	O
directly	O
translated	O
into	O
a	O
likelihood	B
function	O
by	O
replacing	O
the	O
for	O
each	O
s	O
with	O
products	O
n	O
pd	O
for	O
each	O
example	O
exp	O
ynd	O
choose	O
label	B
d	O
ynd	O
choose	O
feature	O
value	O
for	O
each	O
feature	O
you	O
can	O
take	O
logs	O
to	O
arrive	O
at	O
the	O
log-likelihood	O
log	O
pd	O
n	O
log	O
yn	O
d	O
log	O
ynd	O
ynd	O
const	O
to	O
optimize	O
for	O
you	O
need	O
to	O
add	O
a	O
sums	O
to	O
one	O
constraint	O
as	O
before	O
this	O
leads	O
to	O
the	O
previous	O
solution	O
where	O
the	O
ks	O
are	O
proportional	O
to	O
the	O
number	O
of	O
examples	B
with	O
label	B
k	O
in	O
the	O
case	O
of	O
the	O
s	O
probabilistic	B
modeling	B
you	O
can	O
take	O
a	O
derivative	O
with	O
respect	O
to	O
say	O
ki	O
and	O
obtain	O
log	O
pd	O
ki	O
ki	O
n	O
d	O
ynd	O
ki	O
nynk	O
kd	O
nynk	O
kd	O
ki	O
setting	O
this	O
equal	O
to	O
zero	O
and	O
solving	O
yields	O
ki	O
nynk	O
xni	O
nynk	O
ignore	O
irrelevant	O
terms	O
ignore	O
irrelevant	O
terms	O
take	O
derivative	O
namely	O
the	O
sample	O
mean	O
of	O
the	O
ith	O
feature	O
of	O
the	O
data	O
points	O
that	O
fall	O
in	O
class	O
k	O
a	O
similar	O
analysis	O
for	O
ki	O
yields	O
log	O
pd	O
ki	O
ki	O
yynk	O
log	O
ki	O
ki	O
yynk	O
ki	O
ki	O
yynk	O
k	O
ki	O
ignore	O
irrelevant	O
terms	O
take	O
derivative	O
simplify	O
you	O
can	O
now	O
set	O
this	O
equal	O
to	O
zero	O
and	O
solve	O
yielding	O
ki	O
nynkxni	O
nynk	O
which	O
is	O
just	O
the	O
sample	O
variance	B
of	O
feature	O
i	O
for	O
class	O
k	O
conditional	O
models	O
in	O
the	O
foregoing	O
examples	B
the	O
task	O
was	O
formulated	O
as	O
attempting	O
to	O
model	B
the	O
joint	B
distribution	O
of	O
y	O
pairs	O
this	O
may	O
seem	O
wasteful	O
at	O
prediction	O
time	O
all	O
you	O
care	O
about	O
is	O
py	O
x	O
so	O
why	O
not	O
model	B
it	O
directly	O
starting	O
with	O
the	O
case	O
of	O
regression	O
is	O
actually	O
somewhat	O
simpler	O
than	O
starting	O
with	O
classification	O
in	O
this	O
case	O
suppose	O
you	O
believe	O
what	O
would	O
the	O
estimate	O
be	O
if	O
you	O
decided	O
that	O
for	O
a	O
given	O
class	O
k	O
all	O
features	B
had	O
equal	O
variance	B
what	O
if	O
you	O
assumed	O
feature	O
i	O
had	O
equal	O
variance	B
for	O
each	O
class	O
under	O
what	O
circumstances	O
might	O
it	O
be	O
a	O
good	O
idea	O
to	O
make	O
such	O
assumptions	O
a	O
course	O
in	O
machine	O
learning	O
that	O
the	O
relationship	O
between	O
the	O
real	O
value	O
y	O
and	O
the	O
vector	B
x	O
should	O
be	O
linear	O
that	O
is	O
you	O
expect	O
that	O
y	O
w	O
x	O
b	O
should	O
hold	O
for	O
some	O
parameters	O
b	O
of	O
course	O
the	O
data	O
that	O
you	O
get	O
does	O
not	O
exactly	O
obey	O
this	O
that	O
s	O
fine	O
you	O
can	O
think	O
of	O
deviations	O
from	O
y	O
w	O
x	O
b	O
as	O
noise	B
to	O
form	O
a	O
probabilistic	O
model	B
you	O
must	O
assume	O
some	O
distribution	O
over	O
noise	B
a	O
convenient	O
choice	O
is	O
zero-mean	O
gaussian	O
noise	B
this	O
leads	O
to	O
the	O
following	O
generative	B
story	I
for	O
each	O
example	O
n	O
n	O
compute	O
tn	O
w	O
xn	O
b	O
choose	O
noise	B
en	O
return	O
yn	O
tn	O
en	O
in	O
this	O
story	O
the	O
variable	O
tn	O
stands	O
for	O
target	O
it	O
is	O
the	O
noiseless	O
variable	O
that	O
you	O
do	O
not	O
get	O
to	O
observe	O
similarly	O
en	O
is	O
the	O
error	O
on	O
example	O
n	O
the	O
value	O
that	O
you	O
actually	O
get	O
to	O
observe	O
is	O
yn	O
tn	O
en	O
see	O
figure	O
a	O
basic	O
property	O
of	O
the	O
gaussian	B
distribution	I
is	O
additivity	O
namely	O
that	O
if	O
a	O
nor	O
and	O
b	O
a	O
c	O
then	O
b	O
nor	O
c	O
given	O
this	O
from	O
the	O
generative	B
story	I
above	O
you	O
can	O
derive	O
a	O
shorter	O
generative	B
story	I
for	O
each	O
example	O
n	O
n	O
choose	O
yn	O
norw	O
xn	O
b	O
figure	O
pictorial	O
view	O
of	O
targets	O
versus	O
labels	O
reading	O
off	O
the	O
log	B
likelihood	B
of	O
a	O
dataset	O
from	O
this	O
generative	B
story	I
you	O
obtain	O
log	O
pd	O
n	O
log	O
xn	O
b	O
n	O
xn	O
b	O
const	O
model	B
assumptions	O
remove	O
constants	O
this	O
is	O
precisely	O
the	O
linear	B
regression	I
model	B
you	O
encountered	O
in	O
section	O
to	O
minimizing	O
the	O
negative	O
log	B
probability	I
you	O
need	O
only	O
solve	O
for	O
the	O
regression	O
coefficients	O
w	O
b	O
as	O
before	O
in	O
the	O
case	O
of	O
binary	O
classification	O
using	O
a	O
gaussian	O
noise	B
model	B
does	O
not	O
make	O
sense	O
switching	O
to	O
a	O
bernoulli	O
model	B
which	O
describes	O
binary	O
outcomes	O
makes	O
more	O
sense	O
the	O
only	O
remaining	O
difficulty	O
is	O
that	O
the	O
parameter	O
of	O
a	O
bernoulli	O
is	O
a	O
value	O
between	O
zero	O
and	O
one	O
probability	O
of	O
heads	O
so	O
your	O
model	B
must	O
produce	O
such	O
values	O
a	O
classic	O
approach	O
is	O
to	O
produce	O
a	O
real-valued	O
target	O
as	O
before	O
and	O
then	O
transform	O
this	O
target	O
into	O
a	O
value	O
between	O
zero	O
and	O
one	O
so	O
that	O
maps	O
to	O
and	O
maps	O
to	O
a	O
function	O
that	O
does	O
this	O
is	O
the	O
logistic	O
defined	O
below	O
and	O
plotted	O
in	O
figure	O
logistic	O
function	O
exp	O
z	O
exp	O
z	O
exp	O
z	O
the	O
logistic	O
function	O
has	O
several	O
nice	O
properties	O
that	O
you	O
can	O
verify	O
for	O
yourself	O
z	O
and	O
z	O
z	O
using	O
the	O
logistic	O
function	O
you	O
can	O
write	O
down	O
a	O
generative	B
story	I
probabilistic	B
modeling	B
also	O
called	O
the	O
sigmoid	B
function	I
because	O
of	O
it	O
s	O
s	O
figure	O
sketch	O
of	O
logistic	O
function	O
for	O
binary	O
classification	O
for	O
each	O
example	O
n	O
n	O
compute	O
tn	O
xn	O
b	O
compute	O
zn	O
bertn	O
return	O
yn	O
make	O
it	O
the	O
log-likelihood	O
for	O
this	O
model	B
is	O
log	O
pd	O
n	O
log	O
xn	O
b	O
log	O
w	O
xn	O
b	O
log	O
xn	O
b	O
n	O
n	O
n	O
log	O
exp	O
yn	O
xn	O
b	O
w	O
xn	O
b	O
model	B
and	O
properties	O
of	O
join	O
terms	O
definition	O
of	O
definition	O
of	O
as	O
you	O
can	O
see	O
the	O
log-likelihood	O
is	O
precisely	O
the	O
negative	O
of	O
scaled	O
version	O
of	O
the	O
logistic	B
loss	I
from	O
chapter	O
this	O
model	B
is	O
the	O
logistic	B
regression	I
model	B
and	O
this	O
is	O
where	O
logisitic	O
loss	O
originally	O
derived	O
from	O
todo	O
conditional	O
versus	O
joint	B
regularization	O
via	O
priors	O
in	O
the	O
foregoing	O
discussion	O
parameters	O
of	O
the	O
model	B
were	O
selected	O
according	O
to	O
the	O
maximum	O
likelihood	B
criteria	O
find	O
the	O
parameters	O
that	O
maximize	O
p	O
the	O
trouble	O
with	O
this	O
approach	O
is	O
easy	O
to	O
see	O
even	O
in	O
a	O
simple	O
coin	O
flipping	O
example	O
if	O
you	O
flip	O
a	O
coin	O
twice	O
and	O
it	O
comes	O
up	O
heads	O
both	O
times	O
the	O
maximum	O
likelihood	B
estimate	O
a	O
course	O
in	O
machine	O
learning	O
for	O
the	O
bias	B
of	O
the	O
coin	O
is	O
it	O
will	O
always	O
come	O
up	O
heads	O
this	O
is	O
true	O
even	O
if	O
you	O
had	O
only	O
flipped	O
it	O
once	O
if	O
course	O
if	O
you	O
had	O
flipped	O
it	O
one	O
million	O
times	O
and	O
it	O
had	O
come	O
up	O
heads	O
every	O
time	O
then	O
you	O
might	O
find	O
this	O
to	O
be	O
a	O
reasonable	O
solution	O
this	O
is	O
clearly	O
undesirable	O
behavior	O
especially	O
since	O
data	O
is	O
expensive	O
in	O
a	O
machine	O
learning	O
setting	O
one	O
solution	O
are	O
others	O
is	O
to	O
seek	O
parameters	O
that	O
balance	O
a	O
tradeoff	O
between	O
the	O
likelihood	B
of	O
the	O
data	O
and	O
some	O
prior	B
belief	O
you	O
have	O
about	O
what	O
values	O
of	O
those	O
parameters	O
are	O
likely	O
taking	O
the	O
case	O
of	O
the	O
logistic	B
regression	I
you	O
might	O
a	O
priori	O
believe	O
that	O
small	O
values	O
of	O
w	O
are	O
more	O
likely	O
than	O
large	O
values	O
and	O
choose	O
to	O
represent	O
this	O
as	O
a	O
gaussian	O
prior	B
on	O
each	O
component	O
of	O
w	O
the	O
maximum	B
a	I
posteriori	I
principle	O
is	O
a	O
method	O
for	O
incoporat	O
ing	O
both	O
data	O
and	O
prior	B
beliefs	O
to	O
obtain	O
a	O
more	O
balanced	O
parameter	O
estimate	O
in	O
abstract	O
terms	O
consider	O
a	O
probabilistic	O
model	B
over	O
data	O
d	O
that	O
is	O
parameterized	O
by	O
parameters	O
if	O
you	O
think	O
of	O
the	O
parameters	O
as	O
just	O
another	O
random	O
variable	O
then	O
you	O
can	O
write	O
this	O
model	B
as	O
pd	O
and	O
maximum	O
likelihood	B
amounts	O
to	O
choosing	O
to	O
maximize	O
pd	O
however	O
you	O
might	O
instead	O
with	O
to	O
maximize	O
the	O
probability	O
of	O
the	O
parameters	O
given	O
the	O
data	O
namely	O
maximize	O
p	O
d	O
this	O
term	O
is	O
known	O
as	O
the	O
posterior	B
distribution	O
on	O
and	O
can	O
be	O
computed	O
by	O
bayes	O
rule	O
p	O
d	O
posterior	B
evidence	B
likelihood	B
prior	B
p	O
pd	O
pd	O
d	O
p	O
where	O
pd	O
this	O
reads	O
the	O
posterior	B
is	O
equal	O
to	O
the	O
prior	B
times	O
the	O
likelihood	B
divided	O
by	O
the	O
the	O
evidence	B
is	O
a	O
scary-looking	O
term	O
has	O
an	O
integral	O
but	O
note	O
that	O
from	O
the	O
perspective	O
of	O
seeking	O
parameters	O
than	O
maximize	O
the	O
posterior	B
the	O
evidence	B
is	O
just	O
a	O
constant	O
does	O
not	O
depend	O
on	O
and	O
therefore	O
can	O
be	O
ignored	O
returning	O
to	O
the	O
logistic	B
regression	I
example	O
with	O
gaussian	O
priors	O
on	O
the	O
weights	B
the	O
log	B
posterior	B
looks	O
like	O
the	O
evidence	B
is	O
sometimes	O
called	O
the	O
marginal	B
likelihood	B
log	O
p	O
d	O
n	O
w	O
xn	O
b	O
d	O
d	O
const	O
n	O
w	O
xn	O
b	O
model	B
definition	O
and	O
therefore	O
reduces	O
to	O
a	O
regularized	O
logistic	O
function	O
with	O
a	O
squared	O
regularizer	B
on	O
the	O
weights	B
regularizer	B
probabilistic	B
modeling	B
can	O
be	O
obtained	O
by	O
using	O
a	O
laplace	O
prior	B
on	O
w	O
rather	O
than	O
a	O
gaussian	O
prior	B
on	O
w	O
exercises	O
exercise	O
todo	O
neural	B
networks	I
the	O
first	O
learning	O
models	O
you	O
learned	O
about	O
trees	O
and	O
nearest	B
neighbor	I
models	O
created	O
complex	O
non-linear	B
decision	O
boundaries	O
we	O
moved	O
from	O
there	O
to	O
the	O
perceptron	B
perhaps	O
the	O
most	O
classic	O
linear	O
model	B
at	O
this	O
point	O
we	O
will	O
move	O
back	O
to	O
nonlinear	O
learning	O
models	O
but	O
using	O
all	O
that	O
we	O
have	O
learned	O
about	O
linear	O
learning	O
thus	O
far	O
this	O
chapter	O
presents	O
an	O
extension	O
of	O
perceptron	B
learning	O
to	O
nonlinear	O
decision	O
boundaries	O
taking	O
the	O
biological	O
inspiration	O
of	O
neurons	B
even	O
further	O
in	O
the	O
perceptron	B
we	O
thought	O
of	O
the	O
input	O
data	O
point	O
an	O
image	O
as	O
being	O
directly	O
connected	O
to	O
an	O
output	O
label	B
this	O
is	O
often	O
called	O
a	O
single-layer	B
network	I
because	O
there	O
is	O
one	O
layer	O
of	O
weights	B
now	O
instead	O
of	O
directly	O
connecting	O
the	O
inputs	O
to	O
the	O
outputs	O
we	O
will	O
insert	O
a	O
layer	O
of	O
hidden	O
nodes	O
moving	O
from	O
a	O
single-layer	B
network	I
to	O
a	O
multi-layer	B
network	I
but	O
introducing	O
a	O
non-linearity	O
at	O
inner	O
layers	O
this	O
will	O
give	O
us	O
non-linear	B
decision	O
boundaires	O
in	O
fact	O
such	O
networks	O
are	O
able	O
to	O
express	O
almost	O
any	O
function	O
we	O
want	O
not	O
just	O
linear	O
functions	O
the	O
trade-off	O
for	O
this	O
flexibility	O
is	O
increased	O
complexity	B
in	O
parameter	O
tuning	O
and	O
model	B
design	O
bio-inspired	O
multi-layer	O
networks	O
one	O
of	O
the	O
major	O
weaknesses	O
of	O
linear	O
models	O
like	O
perceptron	B
and	O
the	O
regularized	O
linear	O
models	O
from	O
the	O
previous	O
chapter	O
is	O
that	O
they	O
are	O
linear	O
namely	O
they	O
are	O
unable	O
to	O
learn	O
arbitrary	O
decision	O
boundaries	O
in	O
contrast	O
decision	B
trees	I
and	O
knn	O
could	O
learn	O
arbitrarily	O
complicated	O
decision	O
boundaries	O
one	O
approach	O
to	O
doing	O
this	O
is	O
to	O
chain	O
together	O
a	O
collection	O
of	O
perceptrons	O
to	O
build	O
more	O
complex	O
neural	B
networks	I
an	O
example	O
of	O
a	O
two-layer	B
network	I
is	O
shown	O
in	O
figure	O
here	O
you	O
can	O
see	O
five	O
inputs	O
that	O
are	O
fed	O
into	O
two	O
hidden	B
units	I
these	O
hidden	B
units	I
are	O
then	O
fed	O
in	O
to	O
a	O
single	O
output	B
unit	I
each	O
edge	O
in	O
this	O
figure	O
corresponds	O
to	O
a	O
different	O
weight	O
though	O
it	O
looks	O
like	O
there	O
are	O
three	O
layers	O
this	O
is	O
called	O
a	O
two-layer	B
network	I
because	O
we	O
don	O
t	O
count	O
learning	O
objectives	O
explain	O
the	O
biological	O
inspiration	O
for	O
multi-layer	O
neural	B
networks	I
construct	O
a	O
two-layer	B
network	I
that	O
can	O
solve	O
the	O
xor	O
problem	O
implement	O
the	O
back-propogation	O
algorithm	B
for	O
training	O
multi-layer	O
networks	O
explain	O
the	O
trade-off	O
between	O
depth	O
and	O
breadth	O
in	O
network	O
structure	O
contrast	O
neural	B
networks	I
with	O
radial	O
basis	O
functions	O
with	O
k-nearest	O
neighbor	O
learning	O
dependencies	O
figure	O
picture	O
of	O
a	O
two-layer	B
network	I
with	O
inputs	O
and	O
two	O
hidden	B
units	I
the	O
inputs	O
as	O
a	O
real	O
layer	O
that	O
is	O
it	O
s	O
two	O
layers	O
of	O
trained	O
weights	B
prediction	O
with	O
a	O
neural	B
network	I
is	O
a	O
straightforward	O
generalization	O
of	O
prediction	O
with	O
a	O
perceptron	B
first	O
you	O
compute	O
activations	B
of	O
the	O
nodes	O
in	O
the	O
hidden	O
unit	O
based	O
on	O
the	O
inputs	O
and	O
the	O
input	O
weights	B
then	O
you	O
compute	O
activations	B
of	O
the	O
output	B
unit	I
given	O
the	O
hidden	O
unit	O
activations	B
and	O
the	O
second	O
layer	O
of	O
weights	B
the	O
only	O
major	O
difference	O
between	O
this	O
computation	O
and	O
the	O
per	O
ceptron	O
computation	O
is	O
that	O
the	O
hidden	B
units	I
compute	O
a	O
non-linear	B
function	O
of	O
their	O
inputs	O
this	O
is	O
usually	O
called	O
the	O
activation	B
function	I
or	O
link	B
function	I
more	O
formally	O
if	O
wid	O
is	O
the	O
weights	B
on	O
the	O
edge	O
connecting	O
input	O
d	O
to	O
hidden	O
unit	O
i	O
then	O
the	O
activation	O
of	O
hidden	O
unit	O
i	O
is	O
computed	O
as	O
hi	O
f	O
x	O
where	O
f	O
is	O
the	O
link	B
function	I
and	O
wi	O
refers	O
to	O
the	O
vector	B
of	O
weights	B
feeding	O
in	O
to	O
node	O
i	O
one	O
example	O
link	B
function	I
is	O
the	O
sign	B
function	O
that	O
is	O
if	O
the	O
incoming	O
signal	O
is	O
negative	O
the	O
activation	O
is	O
otherwise	O
the	O
activation	O
is	O
this	O
is	O
a	O
potentially	O
useful	O
activiation	O
function	O
but	O
you	O
might	O
already	O
have	O
guessed	O
the	O
problem	O
with	O
it	O
it	O
is	O
nondifferentiable	O
explain	O
bias	B
a	O
more	O
popular	O
link	B
function	I
is	O
the	O
hyperbolic	B
tangent	I
function	O
tanh	O
a	O
comparison	O
between	O
the	O
sign	B
function	O
and	O
the	O
tanh	O
function	O
is	O
in	O
figure	O
as	O
you	O
can	O
see	O
it	O
is	O
a	O
reasonable	O
approximation	O
to	O
the	O
sign	B
function	O
but	O
is	O
convenient	O
in	O
that	O
it	O
is	O
because	O
it	O
looks	O
like	O
an	O
s	O
and	O
because	O
the	O
greek	O
character	O
for	O
s	O
is	O
sigma	O
such	O
functions	O
are	O
usually	O
called	O
sigmoid	B
functions	O
assuming	O
for	O
now	O
that	O
we	O
are	O
using	O
tanh	O
as	O
the	O
link	B
function	I
the	O
overall	O
prediction	O
made	O
by	O
a	O
two-layer	B
network	I
can	O
be	O
computed	O
using	O
algorithm	B
this	O
function	O
takes	O
a	O
matrix	O
of	O
weights	B
w	O
corresponding	O
to	O
the	O
first	O
layer	O
weights	B
and	O
a	O
vector	B
of	O
weights	B
v	O
corresponding	O
to	O
the	O
second	O
layer	O
you	O
can	O
write	O
this	O
entire	O
computation	O
out	O
in	O
one	O
line	O
as	O
vi	O
tanhwi	O
x	O
y	O
i	O
v	O
tanhw	O
x	O
where	O
the	O
second	O
line	O
is	O
short	O
hand	O
assuming	O
that	O
tanh	O
can	O
take	O
a	O
vector	B
as	O
input	O
and	O
product	O
a	O
vector	B
as	O
output	O
neural	B
networks	I
figure	O
picture	O
of	O
sign	B
versus	O
tanh	O
it	O
s	O
derivative	O
is	O
just	O
is	O
it	O
necessary	O
to	O
use	O
a	O
link	B
function	I
at	O
all	O
what	O
would	O
happen	O
if	O
you	O
just	O
used	O
the	O
identify	O
function	O
as	O
a	O
link	O
a	O
course	O
in	O
machine	O
learning	O
algorithm	B
twolayernetworkpredictw	O
v	O
x	O
for	O
i	O
to	O
number	O
of	O
hidden	B
units	I
do	O
end	O
for	O
return	O
v	O
h	O
hi	O
tanhwi	O
x	O
compute	O
activation	O
of	O
hidden	O
unit	O
i	O
compute	O
output	B
unit	I
the	O
claim	O
is	O
that	O
two-layer	O
neural	B
networks	I
are	O
more	O
expressive	O
than	O
single	O
layer	O
networks	O
perceptrons	O
to	O
see	O
this	O
you	O
can	O
construct	O
a	O
very	O
small	O
two-layer	B
network	I
for	O
solving	O
the	O
xor	O
problem	O
for	O
simplicity	O
suppose	O
that	O
the	O
data	O
set	O
consists	O
of	O
four	O
data	O
points	O
given	O
in	O
table	O
the	O
classification	O
rule	O
is	O
that	O
y	O
if	O
an	O
only	O
if	O
where	O
the	O
features	B
are	O
just	O
to	O
achieve	O
the	O
or	O
behavior	O
you	O
can	O
start	O
by	O
setting	O
the	O
bias	B
to	O
you	O
can	O
solve	O
this	O
problem	O
using	O
a	O
two	O
layer	O
network	O
with	O
two	O
hidden	B
units	I
the	O
key	O
idea	O
is	O
to	O
make	O
the	O
first	O
hidden	O
unit	O
compute	O
an	O
or	O
function	O
the	O
second	O
hidden	O
unit	O
can	O
compute	O
an	O
and	O
function	O
the	O
the	O
output	O
can	O
combine	O
these	O
into	O
a	O
single	O
prediction	O
that	O
mimics	O
xor	O
once	O
you	O
have	O
the	O
first	O
hidden	O
unit	O
activate	O
for	O
or	O
and	O
the	O
second	O
for	O
and	O
you	O
need	O
only	O
set	O
the	O
output	O
weights	B
as	O
and	O
respectively	O
and	O
the	O
weights	B
for	O
the	O
two	O
real	O
features	B
as	O
both	O
being	O
you	O
can	O
check	O
for	O
yourself	O
that	O
this	O
will	O
do	O
the	O
right	O
thing	O
if	O
the	O
link	B
function	I
were	O
the	O
sign	B
function	O
of	O
course	O
it	O
s	O
not	O
it	O
s	O
tanh	O
to	O
get	O
tanh	O
to	O
mimic	O
sign	B
you	O
need	O
to	O
make	O
the	O
dot	B
product	I
either	O
really	O
really	O
large	O
or	O
really	O
really	O
small	O
you	O
can	O
accomplish	O
this	O
by	O
setting	O
the	O
bias	B
to	O
and	O
both	O
of	O
the	O
two	O
weights	B
to	O
now	O
the	O
activation	O
of	O
this	O
unit	O
will	O
be	O
just	O
slightly	O
above	O
for	O
x	O
and	O
just	O
slightly	O
below	O
for	O
the	O
other	O
three	O
examples	B
at	O
this	O
point	O
you	O
ve	O
seen	O
that	O
one-layer	O
networks	O
perceptrons	O
can	O
represent	O
any	O
linear	O
function	O
and	O
only	O
linear	O
functions	O
you	O
ve	O
also	O
seen	O
that	O
two-layer	O
networks	O
can	O
represent	O
non-linear	B
functions	O
like	O
xor	O
a	O
natural	O
question	O
is	O
do	O
you	O
get	O
additional	O
representational	O
power	O
by	O
moving	O
beyond	O
two	O
layers	O
the	O
answer	O
is	O
partially	O
provided	O
in	O
the	O
following	O
theorem	O
due	O
originally	O
to	O
george	O
cybenko	O
for	O
one	O
particular	O
type	O
of	O
link	B
function	I
and	O
extended	O
later	O
by	O
kurt	O
hornik	O
to	O
arbitrary	O
link	O
functions	O
theorem	O
networks	O
are	O
universal	O
function	O
approximators	O
let	O
f	O
be	O
a	O
continuous	O
function	O
on	O
a	O
bounded	O
subset	O
of	O
d-dimensional	O
space	O
then	O
there	O
exists	O
a	O
two-layer	O
neural	B
network	I
f	O
with	O
a	O
finite	O
number	O
of	O
hidden	B
units	I
that	O
approximate	O
f	O
arbitrarily	O
well	O
namely	O
for	O
all	O
x	O
in	O
the	O
domain	O
of	O
or	O
in	O
colloquial	O
terms	O
two-layer	O
networks	O
can	O
approximate	O
any	O
y	O
table	O
small	O
xor	O
data	O
set	O
verify	O
that	O
these	O
output	O
weights	B
will	O
actually	O
give	O
you	O
xor	O
this	O
shows	O
how	O
to	O
create	O
an	O
or	O
function	O
how	O
can	O
you	O
create	O
an	O
and	O
function	O
neural	B
networks	I
function	O
this	O
is	O
a	O
remarkable	O
theorem	O
practically	O
it	O
says	O
that	O
if	O
you	O
give	O
me	O
a	O
function	O
f	O
and	O
some	O
error	O
tolerance	O
parameter	O
i	O
can	O
construct	O
a	O
two	O
layer	O
network	O
that	O
computes	O
f	O
in	O
a	O
sense	O
it	O
says	O
that	O
going	O
from	O
one	O
layer	O
to	O
two	O
layers	O
completely	O
changes	O
the	O
representational	O
capacity	O
of	O
your	O
model	B
when	O
working	O
with	O
two-layer	O
networks	O
the	O
key	O
question	O
is	O
how	O
many	O
hidden	B
units	I
should	O
i	O
have	O
if	O
your	O
data	O
is	O
d	O
dimensional	O
and	O
you	O
have	O
k	O
hidden	B
units	I
then	O
the	O
total	O
number	O
of	O
parameters	O
is	O
first	O
is	O
from	O
the	O
bias	B
the	O
second	O
is	O
from	O
the	O
second	O
layer	O
of	O
weights	B
following	O
on	O
from	O
the	O
heuristic	O
that	O
you	O
should	O
have	O
one	O
to	O
two	O
examples	B
for	O
each	O
parameter	O
you	O
are	O
trying	O
to	O
estimate	O
this	O
suggests	O
a	O
method	O
for	O
choosing	O
the	O
number	O
of	O
hidden	B
units	I
as	O
roughly	O
n	O
in	O
other	O
words	O
if	O
you	O
have	O
tons	O
and	O
tons	O
of	O
examples	B
you	O
can	O
safely	O
have	O
lots	O
of	O
hidden	B
units	I
if	O
you	O
only	O
have	O
a	O
few	O
examples	B
you	O
should	O
probably	O
restrict	O
the	O
number	O
of	O
hidden	B
units	I
in	O
your	O
network	O
the	O
number	O
of	O
units	O
is	O
both	O
a	O
form	O
of	O
inductive	B
bias	B
and	O
a	O
form	O
of	O
regularization	O
in	O
both	O
view	O
the	O
number	O
of	O
hidden	B
units	I
controls	O
how	O
complex	O
your	O
function	O
will	O
be	O
lots	O
of	O
hidden	B
units	I
very	O
complicated	O
function	O
figure	O
shows	O
training	O
and	O
test	B
error	I
for	O
neural	B
networks	I
trained	O
with	O
different	O
numbers	O
of	O
hidden	B
units	I
as	O
the	O
number	O
increases	O
training	O
performance	O
continues	O
to	O
get	O
better	O
but	O
at	O
some	O
point	O
test	O
performance	O
gets	O
worse	O
because	O
the	O
network	O
has	O
overfit	O
the	O
data	O
the	O
back-propagation	B
algorithm	B
the	O
back-propagation	B
algorithm	B
is	O
a	O
classic	O
approach	O
to	O
training	O
neural	B
networks	I
although	O
it	O
was	O
not	O
originally	O
seen	O
this	O
way	O
based	O
on	O
what	O
you	O
know	O
from	O
the	O
last	O
chapter	O
you	O
can	O
summarize	O
backpropagation	O
as	O
back-propagation	B
gradient	B
descent	I
chain	B
rule	I
more	O
specifically	O
the	O
set	O
up	O
is	O
exactly	O
the	O
same	O
as	O
before	O
you	O
are	O
going	O
to	O
optimize	O
the	O
weights	B
in	O
the	O
network	O
to	O
minimize	O
some	O
objective	B
function	I
the	O
only	O
difference	O
is	O
that	O
the	O
predictor	O
is	O
no	O
longer	O
linear	O
y	O
w	O
x	O
b	O
but	O
now	O
non-linear	B
v	O
tanhw	O
x	O
the	O
only	O
question	O
is	O
how	O
to	O
do	O
gradient	B
descent	I
on	O
this	O
more	O
complicated	O
objective	O
for	O
now	O
we	O
will	O
ignore	O
the	O
idea	O
of	O
regularization	O
this	O
is	O
for	O
two	O
reasons	O
the	O
first	O
is	O
that	O
you	O
already	O
know	O
how	O
to	O
deal	O
with	O
regularization	O
so	O
everything	O
you	O
ve	O
learned	O
before	O
applies	O
the	O
second	O
is	O
that	O
historically	O
neural	B
networks	I
have	O
not	O
been	O
regularized	O
instead	O
a	O
course	O
in	O
machine	O
learning	O
people	O
have	O
used	O
early	B
stopping	I
as	O
a	O
method	O
for	O
controlling	O
overfitting	B
presently	O
it	O
s	O
not	O
obvious	O
which	O
is	O
a	O
better	O
solution	O
both	O
are	O
valid	O
options	O
to	O
be	O
completely	O
explicit	O
we	O
will	O
focus	O
on	O
optimizing	O
squared	O
error	O
again	O
this	O
is	O
mostly	O
for	O
historic	O
reasons	O
you	O
could	O
easily	O
replace	O
squared	O
error	O
with	O
your	O
loss	B
function	I
of	O
choice	O
our	O
overall	O
objective	O
is	O
min	O
wv	O
n	O
yn	O
i	O
vi	O
f	O
xn	O
here	O
f	O
is	O
some	O
link	B
function	I
like	O
tanh	O
the	O
easy	O
case	O
is	O
to	O
differentiate	O
this	O
with	O
respect	O
to	O
v	O
the	O
weights	B
for	O
the	O
output	B
unit	I
without	O
even	O
doing	O
any	O
math	O
you	O
should	O
be	O
able	O
to	O
guess	O
what	O
this	O
looks	O
like	O
the	O
way	O
to	O
think	O
about	O
it	O
is	O
that	O
from	O
vs	O
perspective	O
it	O
is	O
just	O
a	O
linear	O
model	B
attempting	O
to	O
minimize	O
squared	O
error	O
the	O
only	O
funny	O
thing	O
is	O
that	O
its	O
inputs	O
are	O
the	O
activations	B
h	O
rather	O
than	O
the	O
examples	B
x	O
so	O
the	O
gradient	B
with	O
respect	O
to	O
v	O
is	O
just	O
as	O
for	O
the	O
linear	O
case	O
to	O
make	O
things	O
notationally	O
more	O
convenient	O
let	O
en	O
denote	O
the	O
error	O
on	O
the	O
nth	O
example	O
the	O
blue	O
term	O
above	O
and	O
let	O
hn	O
denote	O
the	O
vector	B
of	O
hidden	O
unit	O
activations	B
on	O
that	O
example	O
then	O
v	O
n	O
enhn	O
this	O
is	O
exactly	O
like	O
the	O
linear	O
case	O
one	O
way	O
of	O
interpreting	O
this	O
is	O
how	O
would	O
the	O
output	O
weights	B
have	O
to	O
change	O
to	O
make	O
the	O
prediction	O
better	O
this	O
is	O
an	O
easy	O
question	O
to	O
answer	O
because	O
they	O
can	O
easily	O
measure	O
how	O
their	O
changes	O
affect	O
the	O
output	O
the	O
more	O
complicated	O
aspect	O
to	O
deal	O
with	O
is	O
the	O
weights	B
corre	O
sponding	O
to	O
the	O
first	O
layer	O
the	O
reason	O
this	O
is	O
difficult	O
is	O
because	O
the	O
weights	B
in	O
the	O
first	O
layer	O
aren	O
t	O
necessarily	O
trying	O
to	O
produce	O
specific	O
values	O
say	O
or	O
or	O
they	O
are	O
simply	O
trying	O
to	O
produce	O
activations	B
that	O
get	O
fed	O
to	O
the	O
output	O
layer	O
so	O
the	O
change	O
they	O
want	O
to	O
make	O
depends	O
crucially	O
on	O
how	O
the	O
output	O
layer	O
interprets	O
them	O
thankfully	O
the	O
chain	B
rule	I
of	O
calculus	O
saves	O
us	O
ignoring	O
the	O
sum	O
over	O
data	O
points	O
we	O
can	O
compute	O
vi	O
f	O
x	O
lw	O
y	O
i	O
l	O
fi	O
fi	O
wi	O
y	O
i	O
f	O
xx	O
l	O
wi	O
l	O
fi	O
fi	O
wi	O
vi	O
evi	O
vi	O
f	O
x	O
neural	B
networks	I
algorithm	B
twolayernetworktraind	O
k	O
maxiter	O
w	O
d	O
k	O
matrix	O
of	O
small	O
random	O
values	O
v	O
k-vector	O
of	O
small	O
random	O
values	O
for	O
iter	O
maxiter	O
do	O
g	O
d	O
k	O
matrix	O
of	O
zeros	O
g	O
k-vector	O
of	O
zeros	O
for	O
all	O
d	O
do	O
for	O
i	O
to	O
k	O
do	O
ai	O
wi	O
x	O
hi	O
tanhai	O
initialize	O
input	O
layer	O
weights	B
initialize	O
output	O
layer	O
weights	B
initialize	O
input	O
layer	O
gradient	B
initialize	O
output	O
layer	O
gradient	B
end	O
for	O
w	O
w	O
g	O
end	O
for	O
v	O
v	O
g	O
end	O
for	O
return	O
w	O
v	O
end	O
for	O
y	O
v	O
h	O
e	O
y	O
y	O
g	O
g	O
eh	O
for	O
i	O
to	O
k	O
do	O
gi	O
gi	O
compute	O
activation	O
of	O
hidden	O
unit	O
i	O
compute	O
output	B
unit	I
compute	O
error	O
update	O
gradient	B
for	O
output	O
layer	O
update	O
gradient	B
for	O
input	O
layer	O
update	O
input	O
layer	O
weights	B
update	O
output	O
layer	O
weights	B
putting	O
this	O
together	O
we	O
get	O
that	O
the	O
gradient	B
with	O
respect	O
to	O
wi	O
is	O
wi	O
evi	O
f	O
xx	O
intuitively	O
you	O
can	O
make	O
sense	O
of	O
this	O
if	O
the	O
overall	O
error	O
of	O
the	O
predictor	O
is	O
small	O
you	O
want	O
to	O
make	O
small	O
steps	O
if	O
vi	O
is	O
small	O
for	O
hidden	O
unit	O
i	O
then	O
this	O
means	O
that	O
the	O
output	O
is	O
not	O
particularly	O
sensitive	O
to	O
the	O
activation	O
of	O
the	O
ith	O
hidden	O
unit	O
thus	O
its	O
gradient	B
should	O
be	O
small	O
if	O
vi	O
flips	O
sign	B
the	O
gradient	B
at	O
wi	O
should	O
also	O
flip	O
signs	O
the	O
name	O
back-propagation	B
comes	O
from	O
the	O
fact	O
that	O
you	O
propagate	O
gradients	O
backward	O
through	O
the	O
network	O
starting	O
at	O
the	O
end	O
the	O
complete	O
instantiation	O
of	O
gradient	B
descent	I
for	O
a	O
two	O
layer	O
network	O
with	O
k	O
hidden	B
units	I
is	O
sketched	O
in	O
algorithm	B
note	O
that	O
this	O
really	O
is	O
exactly	O
a	O
gradient	B
descent	I
algorithm	B
the	O
only	O
different	O
is	O
that	O
the	O
computation	O
of	O
the	O
gradients	O
of	O
the	O
input	O
layer	O
is	O
moderately	O
complicated	O
as	O
a	O
bit	O
of	O
practical	O
advice	O
implementing	O
the	O
back-propagation	B
algorithm	B
can	O
be	O
a	O
bit	O
tricky	O
sign	B
errors	O
often	O
abound	O
a	O
useful	O
trick	O
is	O
first	O
to	O
keep	O
w	O
fixed	O
and	O
work	O
on	O
just	O
training	O
v	O
then	O
keep	O
v	O
fixed	O
and	O
work	O
on	O
training	O
w	O
then	O
put	O
them	O
together	O
what	O
would	O
happen	O
to	O
this	O
algorithm	B
if	O
you	O
wanted	O
to	O
optimize	O
exponential	B
loss	I
instead	O
of	O
squared	O
error	O
what	O
if	O
you	O
wanted	O
to	O
add	O
in	O
weight	O
regularization	O
if	O
you	O
like	O
matrix	O
calculus	O
derive	O
the	O
same	O
algorithm	B
starting	O
from	O
eq	O
a	O
course	O
in	O
machine	O
learning	O
initialization	O
and	O
convergence	O
of	O
neural	B
networks	I
based	O
on	O
what	O
you	O
know	O
about	O
linear	O
models	O
you	O
might	O
be	O
tempted	O
to	O
initialize	O
all	O
the	O
weights	B
in	O
a	O
neural	B
network	I
to	O
zero	O
you	O
might	O
also	O
have	O
noticed	O
that	O
in	O
algorithm	B
this	O
is	O
not	O
what	O
s	O
done	O
they	O
re	O
initialized	O
to	O
small	O
random	O
values	O
the	O
question	O
is	O
why	O
the	O
answer	O
is	O
because	O
an	O
initialization	O
of	O
w	O
and	O
v	O
will	O
lead	O
to	O
uninteresting	O
solutions	O
in	O
other	O
words	O
if	O
you	O
initialize	O
the	O
model	B
in	O
this	O
way	O
it	O
will	O
eventually	O
get	O
stuck	O
in	O
a	O
bad	O
local	O
optimum	O
to	O
see	O
this	O
first	O
realize	O
that	O
on	O
any	O
example	O
x	O
the	O
activation	O
hi	O
of	O
the	O
hidden	B
units	I
will	O
all	O
be	O
zero	O
since	O
w	O
this	O
means	O
that	O
on	O
the	O
first	O
iteration	B
the	O
gradient	B
on	O
the	O
output	O
weights	B
will	O
be	O
zero	O
so	O
they	O
will	O
stay	O
put	O
furthermore	O
the	O
gradient	B
for	O
the	O
dth	O
feature	O
on	O
the	O
ith	O
unit	O
will	O
be	O
exactly	O
the	O
same	O
as	O
the	O
gradient	B
for	O
the	O
same	O
feature	O
on	O
the	O
second	O
unit	O
this	O
means	O
that	O
the	O
weight	O
matrix	O
after	O
a	O
gradient	B
step	O
will	O
change	O
in	O
exactly	O
the	O
same	O
way	O
for	O
every	O
hidden	O
unit	O
thinking	O
through	O
this	O
example	O
for	O
iterations	O
the	O
values	O
of	O
the	O
hidden	B
units	I
will	O
always	O
be	O
exactly	O
the	O
same	O
which	O
means	O
that	O
the	O
weights	B
feeding	O
in	O
to	O
any	O
of	O
the	O
hidden	B
units	I
will	O
be	O
exactly	O
the	O
same	O
eventually	O
the	O
model	B
will	O
converge	O
but	O
it	O
will	O
converge	O
to	O
a	O
solution	O
that	O
does	O
not	O
take	O
advantage	O
of	O
having	O
access	O
to	O
the	O
hidden	B
units	I
this	O
shows	O
that	O
neural	B
networks	I
are	O
sensitive	O
to	O
their	O
initialization	O
in	O
particular	O
the	O
function	O
that	O
they	O
optimize	O
is	O
non-convex	B
meaning	O
that	O
it	O
might	O
have	O
plentiful	O
local	O
optima	O
of	O
which	O
is	O
the	O
trivial	O
local	O
optimum	O
described	O
in	O
the	O
preceding	O
paragraph	O
in	O
a	O
sense	O
neural	B
networks	I
must	O
have	O
local	O
optima	O
suppose	O
you	O
have	O
a	O
two	O
layer	O
network	O
with	O
two	O
hidden	B
units	I
that	O
s	O
been	O
optimized	O
you	O
have	O
weights	B
from	O
inputs	O
to	O
the	O
first	O
hidden	O
unit	O
weights	B
from	O
inputs	O
to	O
the	O
second	O
hidden	O
unit	O
and	O
weights	B
from	O
the	O
hidden	B
units	I
to	O
the	O
output	O
if	O
i	O
give	O
you	O
back	O
another	O
network	O
with	O
and	O
swapped	O
and	O
and	O
swapped	O
the	O
network	O
computes	O
exactly	O
the	O
same	O
thing	O
but	O
with	O
a	O
markedly	O
different	O
weight	O
structure	O
this	O
phenomena	O
is	O
known	O
as	O
symmetric	B
modes	I
mode	O
referring	O
to	O
an	O
optima	O
meaning	O
that	O
there	O
are	O
symmetries	O
in	O
the	O
weight	O
space	O
it	O
would	O
be	O
one	O
thing	O
if	O
there	O
were	O
lots	O
of	O
modes	O
and	O
they	O
were	O
all	O
symmetric	O
then	O
finding	O
one	O
of	O
them	O
would	O
be	O
as	O
good	O
as	O
finding	O
any	O
other	O
unfortunately	O
there	O
are	O
additional	O
local	O
optima	O
that	O
are	O
not	O
global	O
optima	O
random	O
initialization	O
of	O
the	O
weights	B
of	O
a	O
network	O
is	O
a	O
way	O
to	O
address	O
both	O
of	O
these	O
problems	O
by	O
initializing	O
a	O
network	O
with	O
small	O
random	O
weights	B
uniform	O
between	O
and	O
the	O
network	O
is	O
unlikely	O
to	O
fall	O
into	O
the	O
trivial	O
symmetric	O
local	O
optimum	O
moreover	O
by	O
training	O
a	O
collection	O
of	O
networks	O
each	O
with	O
a	O
different	O
random	O
figure	O
convergence	O
of	O
randomly	O
initialized	O
networks	O
initialization	O
you	O
can	O
often	O
obtain	O
better	O
solutions	O
that	O
with	O
just	O
one	O
initialization	O
in	O
other	O
words	O
you	O
can	O
train	O
ten	O
networks	O
with	O
different	O
random	O
seeds	O
and	O
then	O
pick	O
the	O
one	O
that	O
does	O
best	O
on	O
heldout	O
data	O
figure	O
shows	O
prototypical	O
test-set	O
performance	O
for	O
ten	O
networks	O
with	O
different	O
random	O
initialization	O
plus	O
an	O
eleventh	O
plot	O
for	O
the	O
trivial	O
symmetric	O
network	O
initialized	O
with	O
zeros	O
one	O
of	O
the	O
typical	O
complaints	O
about	O
neural	B
networks	I
is	O
that	O
they	O
are	O
finicky	O
in	O
particular	O
they	O
have	O
a	O
rather	O
large	O
number	O
of	O
knobs	O
to	O
tune	O
the	O
number	O
of	O
layers	O
the	O
number	O
of	O
hidden	B
units	I
per	O
layer	O
the	O
gradient	B
descent	I
learning	O
rate	O
the	O
initialization	O
the	O
stopping	O
iteration	B
or	O
weight	O
regularization	O
the	O
last	O
of	O
these	O
is	O
minor	O
stopping	O
is	O
an	O
easy	O
regularization	O
method	O
that	O
does	O
not	O
require	O
much	O
effort	O
to	O
tune	O
but	O
the	O
others	O
are	O
somewhat	O
significant	O
even	O
for	O
two	O
layer	O
networks	O
having	O
to	O
choose	O
the	O
number	O
of	O
hidden	B
units	I
and	O
then	O
get	O
the	O
learning	O
rate	O
and	O
initialization	O
right	O
can	O
take	O
a	O
bit	O
of	O
work	O
clearly	O
it	O
can	O
be	O
automated	O
but	O
nonetheless	O
it	O
takes	O
time	O
another	O
difficulty	O
of	O
neural	B
networks	I
is	O
that	O
their	O
weights	B
can	O
be	O
difficult	O
to	O
interpret	O
you	O
ve	O
seen	O
that	O
for	O
linear	O
networks	O
you	O
can	O
often	O
interpret	O
high	O
weights	B
as	O
indicative	O
of	O
positive	O
examples	B
and	O
low	O
weights	B
as	O
indicative	O
of	O
negative	O
examples	B
in	O
multilayer	O
networks	O
it	O
becomes	O
very	O
difficult	O
to	O
try	O
to	O
understand	O
what	O
the	O
different	O
hidden	B
units	I
are	O
doing	O
beyond	O
two	O
layers	O
the	O
definition	O
of	O
neural	B
networks	I
and	O
the	O
back-propagation	B
algorithm	B
can	O
be	O
generalized	O
beyond	O
two	O
layers	O
to	O
any	O
arbitrary	O
directed	O
acyclic	O
graph	B
in	O
practice	O
it	O
is	O
most	O
common	O
to	O
use	O
a	O
layered	O
network	O
like	O
that	O
shown	O
in	O
figure	O
unless	O
one	O
has	O
a	O
very	O
strong	O
reason	O
inductive	B
bias	B
to	O
do	O
something	O
different	O
however	O
the	O
view	O
as	O
a	O
directed	O
graph	B
sheds	O
a	O
different	O
sort	O
of	O
insight	O
on	O
the	O
backpropagation	O
algorithm	B
suppose	O
that	O
your	O
network	O
structure	O
is	O
stored	O
in	O
some	O
directed	O
acyclic	O
graph	B
like	O
that	O
in	O
figure	O
we	O
index	O
nodes	O
in	O
this	O
graph	B
as	O
u	O
v	O
the	O
activation	O
before	O
applying	O
non-linearity	O
at	O
a	O
node	O
is	O
au	O
and	O
after	O
non-linearity	O
is	O
hu	O
the	O
graph	B
has	O
a	O
single	O
sink	O
which	O
is	O
the	O
output	O
node	O
y	O
with	O
activation	O
ay	O
non-linearity	O
is	O
performed	O
neural	B
networks	I
figure	O
multi-layer	B
network	I
figure	O
dag	O
network	O
a	O
course	O
in	O
machine	O
learning	O
hu	O
corresponding	O
feature	O
of	O
x	O
algorithm	B
forwardpropagationx	O
for	O
all	O
input	O
nodes	O
u	O
do	O
end	O
for	O
for	O
all	O
nodes	O
v	O
in	O
the	O
network	O
whose	O
parent	O
s	O
are	O
computed	O
do	O
av	O
u	O
parv	O
wuvhu	O
hv	O
tanhav	O
end	O
for	O
return	O
ay	O
algorithm	B
backpropagationx	O
y	O
run	O
forwardpropagationx	O
to	O
compute	O
activations	B
ey	O
y	O
ay	O
for	O
all	O
nodes	O
v	O
in	O
the	O
network	O
whose	O
error	O
ev	O
is	O
computed	O
do	O
for	O
all	O
u	O
parv	O
do	O
compute	O
overall	O
network	O
error	O
guv	O
evhu	O
compute	O
gradient	B
of	O
this	O
edge	O
eu	O
eu	O
compute	O
the	O
error	O
of	O
the	O
parent	O
node	O
end	O
for	O
end	O
for	O
return	O
all	O
gradients	O
ge	O
on	O
the	O
output	B
unit	I
the	O
graph	B
has	O
d-many	O
inputs	O
nodes	O
with	O
no	O
parent	O
whose	O
activations	B
hu	O
are	O
given	O
by	O
an	O
input	O
example	O
an	O
edge	O
v	O
is	O
from	O
a	O
parent	O
to	O
a	O
child	O
from	O
an	O
input	O
to	O
a	O
hidden	O
unit	O
or	O
from	O
a	O
hidden	O
unit	O
to	O
the	O
sink	O
each	O
edge	O
has	O
a	O
weight	O
wuv	O
we	O
say	O
that	O
paru	O
is	O
the	O
set	O
of	O
parents	O
of	O
u	O
there	O
are	O
two	O
relevant	O
algorithms	O
forward-propagation	B
and	O
back	O
propagation	O
forward-propagation	B
tells	O
you	O
how	O
to	O
compute	O
the	O
activation	O
of	O
the	O
sink	O
y	O
given	O
the	O
inputs	O
back-propagation	B
computes	O
derivatives	O
of	O
the	O
edge	O
weights	B
for	O
a	O
given	O
input	O
the	O
key	O
aspect	O
of	O
the	O
forward-propagation	B
algorithm	B
is	O
to	O
iteratively	O
compute	O
activations	B
going	O
deeper	O
and	O
deeper	O
in	O
the	O
dag	O
once	O
the	O
activations	B
of	O
all	O
the	O
parents	O
of	O
a	O
node	O
u	O
have	O
been	O
computed	O
you	O
can	O
compute	O
the	O
activation	O
of	O
node	O
u	O
this	O
is	O
spelled	O
out	O
in	O
algorithm	B
this	O
is	O
also	O
explained	O
pictorially	O
in	O
figure	O
back-propagation	B
algorithm	B
does	O
the	O
opposite	O
it	O
com	O
putes	O
gradients	O
top-down	O
in	O
the	O
network	O
the	O
key	O
idea	O
is	O
to	O
compute	O
an	O
error	O
for	O
each	O
node	O
in	O
the	O
network	O
the	O
error	O
at	O
the	O
output	B
unit	I
is	O
the	O
true	O
error	O
for	O
any	O
input	O
unit	O
the	O
error	O
is	O
the	O
amount	O
of	O
gradient	B
that	O
we	O
see	O
coming	O
from	O
our	O
children	O
higher	O
in	O
the	O
network	O
these	O
errors	O
are	O
computed	O
backwards	O
in	O
the	O
network	O
the	O
name	O
back-propagation	B
along	O
with	O
the	O
gradients	O
themselves	O
this	O
is	O
also	O
explained	O
pictorially	O
in	O
figure	O
given	O
the	O
back-propagation	B
algorithm	B
you	O
can	O
directly	O
run	O
gradi	O
ent	O
descent	O
using	O
it	O
as	O
a	O
subroutine	O
for	O
computing	O
the	O
gradients	O
figure	O
picture	O
of	O
forward	O
prop	O
figure	O
picture	O
of	O
back	O
prop	O
breadth	O
versus	O
depth	O
at	O
this	O
point	O
you	O
ve	O
seen	O
how	O
to	O
train	O
two-layer	O
networks	O
and	O
how	O
to	O
train	O
arbitrary	O
networks	O
you	O
ve	O
also	O
seen	O
a	O
theorem	O
that	O
says	O
that	O
two-layer	O
networks	O
are	O
universal	O
function	O
approximators	O
this	O
begs	O
the	O
question	O
if	O
two-layer	O
networks	O
are	O
so	O
great	O
why	O
do	O
we	O
care	O
about	O
deeper	O
networks	O
to	O
understand	O
the	O
answer	O
we	O
can	O
borrow	O
some	O
ideas	O
from	O
cs	O
theory	O
namely	O
the	O
idea	O
of	O
circuit	B
complexity	B
the	O
goal	O
is	O
to	O
show	O
that	O
there	O
are	O
functions	O
for	O
which	O
it	O
might	O
be	O
a	O
good	O
idea	O
to	O
use	O
a	O
deep	O
network	O
in	O
other	O
words	O
there	O
are	O
functions	O
that	O
will	O
require	O
a	O
huge	O
number	O
of	O
hidden	B
units	I
if	O
you	O
force	O
the	O
network	O
to	O
be	O
shallow	O
but	O
can	O
be	O
done	O
in	O
a	O
small	O
number	O
of	O
units	O
if	O
you	O
allow	O
it	O
to	O
be	O
deep	O
the	O
example	O
that	O
we	O
ll	O
use	O
is	O
the	O
parity	B
function	I
which	O
ironically	O
enough	O
is	O
just	O
a	O
generalization	O
of	O
the	O
xor	O
problem	O
the	O
function	O
is	O
defined	O
over	O
binary	O
inputs	O
as	O
xd	O
mod	O
parityx	O
d	O
if	O
the	O
number	O
of	O
in	O
x	O
is	O
odd	O
if	O
the	O
number	O
of	O
in	O
x	O
is	O
even	O
it	O
is	O
easy	O
to	O
define	O
a	O
circuit	O
of	O
depth	O
d	O
with	O
od-many	O
gates	O
for	O
computing	O
the	O
parity	B
function	I
each	O
gate	O
is	O
an	O
xor	O
arranged	O
in	O
a	O
complete	O
binary	O
tree	O
as	O
shown	O
in	O
figure	O
you	O
want	O
to	O
disallow	O
xor	O
as	O
a	O
gate	O
you	O
can	O
fix	O
this	O
by	O
allowing	O
the	O
depth	O
to	O
be	O
doubled	O
and	O
replacing	O
each	O
xor	O
with	O
an	O
and	O
or	O
and	O
not	O
combination	O
like	O
you	O
did	O
at	O
the	O
beginning	O
of	O
this	O
chapter	O
this	O
shows	O
that	O
if	O
you	O
are	O
allowed	O
to	O
be	O
deep	O
you	O
can	O
construct	O
a	O
circuit	O
with	O
that	O
computes	O
parity	O
using	O
a	O
number	O
of	O
hidden	B
units	I
that	O
is	O
linear	O
in	O
the	O
dimensionality	O
so	O
can	O
you	O
do	O
the	O
same	O
with	O
shallow	O
circuits	O
the	O
answer	O
is	O
no	O
it	O
s	O
a	O
famous	O
result	O
of	O
circuit	B
complexity	B
that	O
parity	O
requires	O
exponentially	O
many	O
gates	O
to	O
compute	O
in	O
constant	O
depth	O
the	O
formal	O
theorem	O
is	O
below	O
theorem	O
function	O
complexity	B
any	O
circuit	O
of	O
depth	O
k	O
d	O
that	O
computes	O
the	O
parity	B
function	I
of	O
d	O
input	O
bits	O
must	O
contain	O
oed	O
gates	O
this	O
is	O
a	O
very	O
famous	O
result	O
because	O
it	O
shows	O
that	O
constant-depth	O
circuits	O
are	O
less	O
powerful	O
that	O
deep	O
circuits	O
although	O
a	O
neural	B
network	I
isn	O
t	O
exactly	O
the	O
same	O
as	O
a	O
circuit	O
the	O
is	O
generally	O
believed	O
that	O
the	O
same	O
result	O
holds	O
for	O
neural	B
networks	I
at	O
the	O
very	O
least	O
this	O
gives	O
a	O
strong	O
indication	O
that	O
depth	O
might	O
be	O
an	O
important	O
consideration	O
in	O
neural	B
networks	I
one	O
way	O
of	O
thinking	O
about	O
the	O
issue	O
of	O
breadth	O
versus	O
depth	O
has	O
to	O
do	O
with	O
the	O
number	O
of	O
parameters	O
that	O
need	O
to	O
be	O
estimated	O
by	O
neural	B
networks	I
figure	O
nnetparitydeep	O
deep	O
function	O
for	O
computing	O
parity	O
what	O
is	O
it	O
about	O
neural	B
networks	I
that	O
makes	O
it	O
so	O
that	O
the	O
theorem	O
about	O
circuits	O
does	O
not	O
apply	O
directly	O
a	O
course	O
in	O
machine	O
learning	O
the	O
heuristic	O
that	O
you	O
need	O
roughly	O
one	O
or	O
two	O
examples	B
for	O
every	O
parameter	O
a	O
deep	O
model	B
could	O
potentially	O
require	O
exponentially	O
fewer	O
examples	B
to	O
train	O
than	O
a	O
shallow	O
model	B
this	O
now	O
flips	O
the	O
question	O
if	O
deep	O
is	O
potentially	O
so	O
much	O
better	O
why	O
doesn	O
t	O
everyone	O
use	O
deep	O
networks	O
there	O
are	O
at	O
least	O
two	O
answers	O
first	O
it	O
makes	O
the	O
architecture	B
selection	I
problem	O
more	O
significant	O
namely	O
when	O
you	O
use	O
a	O
two-layer	B
network	I
the	O
only	O
hyperparameter	B
to	O
choose	O
is	O
how	O
many	O
hidden	B
units	I
should	O
go	O
in	O
the	O
middle	O
layer	O
when	O
you	O
choose	O
a	O
deep	O
network	O
you	O
need	O
to	O
choose	O
how	O
many	O
layers	O
and	O
what	O
is	O
the	O
width	O
of	O
all	O
those	O
layers	O
this	O
can	O
be	O
somewhat	O
daunting	O
a	O
second	O
issue	O
has	O
to	O
do	O
with	O
training	O
deep	O
models	O
with	O
backpropagation	O
in	O
general	O
as	O
back-propagation	B
works	O
its	O
way	O
down	O
through	O
the	O
model	B
the	O
sizes	O
of	O
the	O
gradients	O
shrink	O
you	O
can	O
work	O
this	O
out	O
mathematically	O
but	O
the	O
intuition	O
is	O
simpler	O
if	O
you	O
are	O
the	O
beginning	O
of	O
a	O
very	O
deep	O
network	O
changing	O
one	O
single	O
weight	O
is	O
unlikely	O
to	O
have	O
a	O
significant	O
effect	O
on	O
the	O
output	O
since	O
it	O
has	O
to	O
go	O
through	O
so	O
many	O
other	O
units	O
before	O
getting	O
there	O
this	O
directly	O
implies	O
that	O
the	O
derivatives	O
are	O
small	O
this	O
in	O
turn	O
means	O
that	O
backpropagation	O
essentially	O
never	O
moves	O
far	O
from	O
its	O
initialization	O
when	O
run	O
on	O
very	O
deep	O
networks	O
finding	O
good	O
ways	O
to	O
train	O
deep	O
networks	O
is	O
an	O
active	O
research	O
area	O
there	O
are	O
two	O
general	O
strategies	O
the	O
first	O
is	O
to	O
attempt	O
to	O
initialize	O
the	O
weights	B
better	O
often	O
by	O
a	O
layer-wise	B
initialization	O
strategy	O
this	O
can	O
be	O
often	O
done	O
using	O
unlabeled	O
data	O
after	O
this	O
initialization	O
back-propagation	B
can	O
be	O
run	O
to	O
tweak	O
the	O
weights	B
for	O
whatever	O
classification	O
problem	O
you	O
care	O
about	O
a	O
second	O
approach	O
is	O
to	O
use	O
a	O
more	O
complex	O
optimization	O
procedure	O
rather	O
than	O
gradient	B
descent	I
you	O
will	O
learn	O
about	O
some	O
such	O
procedures	O
later	O
in	O
this	O
book	O
basis	O
functions	O
at	O
this	O
point	O
we	O
ve	O
seen	O
that	O
neural	B
networks	I
can	O
mimic	O
linear	O
functions	O
and	O
they	O
can	O
learn	O
more	O
complex	O
functions	O
a	O
reasonable	O
question	O
is	O
whether	O
they	O
can	O
mimic	O
a	O
knn	O
classifier	O
and	O
whether	O
they	O
can	O
do	O
it	O
efficiently	O
with	O
not-too-many	O
hidden	B
units	I
a	O
natural	O
way	O
to	O
train	O
a	O
neural	B
network	I
to	O
mimic	O
a	O
knn	O
classifier	O
while	O
these	O
small	O
derivatives	O
might	O
make	O
training	O
difficult	O
they	O
might	O
be	O
good	O
for	O
other	O
reasons	O
what	O
reasons	O
is	O
to	O
replace	O
the	O
sigmoid	B
link	B
function	I
with	O
a	O
radial	B
basis	I
function	I
in	O
a	O
sigmoid	B
network	I
a	O
network	O
with	O
sigmoid	B
links	O
the	O
hidden	B
units	I
were	O
computed	O
as	O
hi	O
tanhwi	O
x	O
in	O
an	O
rbf	B
network	I
the	O
hidden	B
units	I
are	O
computed	O
as	O
i	O
hi	O
exp	O
in	O
other	O
words	O
the	O
hidden	B
units	I
behave	O
like	O
little	O
gaussian	O
bumps	O
centered	O
around	O
locations	O
specified	O
by	O
the	O
vectors	O
wi	O
a	O
one-dimensional	O
example	O
is	O
shown	O
in	O
figure	O
the	O
parameter	O
i	O
specifies	O
the	O
width	O
of	O
the	O
gaussian	O
bump	O
if	O
i	O
is	O
large	O
then	O
only	O
data	O
points	O
that	O
are	O
really	O
close	O
to	O
wi	O
have	O
non-zero	O
activations	B
to	O
distinguish	O
sigmoid	B
networks	O
from	O
rbf	O
networks	O
the	O
hidden	B
units	I
are	O
typically	O
drawn	O
with	O
sigmoids	O
or	O
with	O
gaussian	O
bumps	O
as	O
in	O
figure	O
training	O
rbf	O
networks	O
involves	O
finding	O
good	O
values	O
for	O
the	O
gassian	O
widths	O
i	O
the	O
centers	O
of	O
the	O
gaussian	O
bumps	O
wi	O
and	O
the	O
connections	O
between	O
the	O
gaussian	O
bumps	O
and	O
the	O
output	B
unit	I
v	O
this	O
can	O
all	O
be	O
done	O
using	O
back-propagation	B
the	O
gradient	B
terms	O
for	O
v	O
remain	O
unchanged	O
from	O
before	O
the	O
the	O
derivates	O
for	O
the	O
other	O
variables	O
differ	O
exercise	O
one	O
of	O
the	O
big	O
questions	O
with	O
rbf	O
networks	O
is	O
where	O
should	O
the	O
gaussian	O
bumps	O
be	O
centered	O
one	O
can	O
of	O
course	O
apply	O
backpropagation	O
to	O
attempt	O
to	O
find	O
the	O
centers	O
another	O
option	O
is	O
to	O
specify	O
them	O
ahead	O
of	O
time	O
for	O
instance	O
one	O
potential	O
approach	O
is	O
to	O
have	O
one	O
rbf	O
unit	O
per	O
data	O
point	O
centered	O
on	O
that	O
data	O
point	O
if	O
you	O
carefully	O
choose	O
the	O
s	O
and	O
vs	O
you	O
can	O
obtain	O
something	O
that	O
looks	O
nearly	O
identical	O
to	O
distance-weighted	O
knn	O
by	O
doing	O
so	O
this	O
has	O
the	O
added	O
advantage	O
that	O
you	O
can	O
go	O
futher	O
and	O
use	O
back-propagation	B
to	O
learn	O
good	O
gaussian	O
widths	O
and	O
voting	B
factors	O
for	O
the	O
nearest	B
neighbor	I
algorithm	B
exercises	O
exercise	O
todo	O
neural	B
networks	I
figure	O
nnetrbfpicture	O
a	O
one-d	O
picture	O
of	O
rbf	O
bumps	O
figure	O
nnetunitsymbols	O
picture	O
of	O
nnet	O
with	O
sigmoidrbf	O
units	O
consider	O
an	O
rbf	B
network	I
with	O
one	O
hidden	O
unit	O
per	O
training	O
point	O
centered	O
at	O
that	O
point	O
what	O
bad	O
thing	O
might	O
happen	O
if	O
you	O
use	O
backpropagation	O
to	O
estimate	O
the	O
s	O
and	O
v	O
on	O
this	O
data	O
if	O
you	O
re	O
not	O
careful	O
how	O
could	O
you	O
be	O
careful	O
kernel	B
methods	O
learning	O
objectives	O
explain	O
how	O
kernels	B
generalize	B
both	O
feature	B
combinations	I
and	O
basis	O
functions	O
contrast	O
dot	O
products	O
with	O
kernel	B
products	O
implement	O
kernelized	O
perceptron	B
derive	O
a	O
kernelized	O
version	O
of	O
regularized	O
least	O
squares	O
regression	O
implement	O
a	O
kernelized	O
version	O
of	O
the	O
perceptron	B
derive	O
the	O
dual	O
formulation	O
of	O
the	O
support	B
vector	B
machine	I
dependencies	O
linear	O
models	O
are	O
great	O
because	O
they	O
are	O
easy	O
to	O
understand	O
and	O
easy	O
to	O
optimize	O
they	O
suffer	O
because	O
they	O
can	O
only	O
learn	O
very	O
simple	O
decision	O
boundaries	O
neural	B
networks	I
can	O
learn	O
more	O
complex	O
decision	O
boundaries	O
but	O
lose	O
the	O
nice	O
convexity	O
properties	O
of	O
many	O
linear	O
models	O
one	O
way	O
of	O
getting	O
a	O
linear	O
model	B
to	O
behave	O
non-linearly	O
is	O
to	O
transform	O
the	O
input	O
for	O
instance	O
by	O
adding	O
feature	O
pairs	O
as	O
additional	O
inputs	O
learning	O
a	O
linear	O
model	B
on	O
such	O
a	O
representation	O
is	O
convex	B
but	O
is	O
computationally	O
prohibitive	O
in	O
all	O
but	O
very	O
low	O
dimensional	O
spaces	O
you	O
might	O
ask	O
instead	O
of	O
explicitly	O
expanding	O
the	O
feature	B
space	I
is	O
it	O
possible	O
to	O
stay	O
with	O
our	O
original	O
data	O
representation	O
and	O
do	O
all	O
the	O
feature	O
blow	O
up	O
implicitly	O
surprisingly	O
the	O
answer	O
is	O
often	O
yes	O
and	O
the	O
family	O
of	O
techniques	O
that	O
makes	O
this	O
possible	O
are	O
known	O
as	O
kernel	B
approaches	O
from	O
feature	B
combinations	I
to	O
kernels	B
in	O
section	O
you	O
learned	O
one	O
method	O
for	O
increasing	O
the	O
expressive	O
power	O
of	O
linear	O
models	O
explode	O
the	O
feature	B
space	I
for	O
instance	O
a	O
quadratic	O
feature	O
explosion	O
might	O
map	O
a	O
feature	B
vector	B
x	O
to	O
an	O
expanded	O
version	O
denoted	O
that	O
there	O
are	O
repetitions	O
here	O
but	O
hopefully	O
most	O
learning	O
algorithms	O
can	O
deal	O
well	O
with	O
redundant	B
features	B
in	O
particular	O
the	O
terms	O
are	O
due	O
to	O
collapsing	O
some	O
repetitions	O
kernel	B
methods	O
you	O
could	O
then	O
train	O
a	O
classifier	O
on	O
this	O
expanded	O
feature	B
space	I
there	O
are	O
two	O
primary	O
concerns	O
in	O
doing	O
so	O
the	O
first	O
is	O
computational	O
if	O
your	O
learning	O
algorithm	B
scales	O
linearly	O
in	O
the	O
number	O
of	O
features	B
then	O
you	O
ve	O
just	O
squared	O
the	O
amount	O
of	O
computation	O
you	O
need	O
to	O
perform	O
you	O
ve	O
also	O
squared	O
the	O
amount	O
of	O
memory	O
you	O
ll	O
need	O
the	O
second	O
is	O
statistical	O
if	O
you	O
go	O
by	O
the	O
heuristic	O
that	O
you	O
should	O
have	O
about	O
two	O
examples	B
for	O
every	O
feature	O
then	O
you	O
will	O
now	O
need	O
quadratically	O
many	O
training	O
examples	B
in	O
order	O
to	O
avoid	O
overfitting	B
this	O
chapter	O
is	O
all	O
about	O
dealing	O
with	O
the	O
computational	O
issue	O
it	O
will	O
turn	O
out	O
in	O
chapter	O
that	O
you	O
can	O
also	O
deal	O
with	O
the	O
statistical	O
issue	O
for	O
now	O
you	O
can	O
just	O
hope	O
that	O
regularization	O
will	O
be	O
sufficient	O
to	O
attenuate	O
overfitting	B
the	O
key	O
insight	O
in	O
kernel-based	O
learning	O
is	O
that	O
you	O
can	O
rewrite	O
many	O
linear	O
models	O
in	O
a	O
way	O
that	O
doesn	O
t	O
require	O
you	O
to	O
ever	O
explicitly	O
compute	O
to	O
start	O
with	O
you	O
can	O
think	O
of	O
this	O
purely	O
as	O
a	O
computational	O
trick	O
that	O
enables	O
you	O
to	O
use	O
the	O
power	O
of	O
a	O
quadratic	O
feature	B
mapping	I
without	O
actually	O
having	O
to	O
compute	O
and	O
store	O
the	O
mapped	O
vectors	O
later	O
you	O
will	O
see	O
that	O
it	O
s	O
actually	O
quite	O
a	O
bit	O
deeper	O
most	O
algorithms	O
we	O
discuss	O
involve	O
a	O
product	O
of	O
the	O
form	O
w	O
after	O
performing	O
the	O
feature	B
mapping	I
the	O
goal	O
is	O
to	O
rewrite	O
these	O
algorithms	O
so	O
that	O
they	O
only	O
ever	O
depend	O
on	O
dot	O
products	O
between	O
two	O
examples	B
say	O
x	O
and	O
z	O
namely	O
they	O
depend	O
on	O
to	O
understand	O
why	O
this	O
is	O
helpful	O
consider	O
the	O
quadratic	O
expansion	O
from	O
above	O
and	O
the	O
dot-product	O
between	O
two	O
vectors	O
you	O
get	O
xdzd	O
d	O
xdzd	O
e	O
d	O
d	O
z	O
x	O
xdxezdze	O
thus	O
you	O
can	O
compute	O
in	O
exactly	O
the	O
same	O
amount	O
of	O
time	O
as	O
you	O
can	O
compute	O
x	O
z	O
the	O
time	O
it	O
takes	O
to	O
perform	O
an	O
addition	O
and	O
a	O
multiply	O
about	O
nanoseconds	O
on	O
a	O
circa	O
processor	O
the	O
rest	O
of	O
the	O
practical	O
challenge	O
is	O
to	O
rewrite	O
your	O
algorithms	O
so	O
that	O
they	O
only	O
depend	O
on	O
dot	O
products	O
between	O
examples	B
and	O
not	O
on	O
any	O
explicit	O
weight	O
vectors	O
kernelized	O
perceptron	B
consider	O
the	O
original	O
perceptron	B
algorithm	B
from	O
chapter	O
re	O
peated	O
in	O
algorithm	B
using	O
linear	O
algebra	O
notation	O
and	O
using	O
feature	O
expansion	O
notation	O
in	O
this	O
algorithm	B
there	O
are	O
two	O
places	O
a	O
course	O
in	O
machine	O
learning	O
algorithm	B
perceptrontraind	O
maxiter	O
w	O
b	O
for	O
iter	O
maxiter	O
do	O
initialize	O
weights	B
and	O
bias	B
compute	O
activation	O
for	O
this	O
example	O
update	O
weights	B
update	O
bias	B
for	O
all	O
d	O
do	O
a	O
w	O
b	O
if	O
ya	O
then	O
w	O
w	O
y	O
b	O
b	O
y	O
end	O
if	O
end	O
for	O
end	O
for	O
return	O
w	O
b	O
math	O
review	O
spans	O
and	O
null	O
spaces	O
reminder	O
if	O
u	O
is	O
a	O
set	O
of	O
vectors	O
in	O
rd	O
then	O
the	O
span	B
of	O
u	O
is	O
the	O
set	O
of	O
vectors	O
that	O
can	O
be	O
written	O
as	O
linear	O
combinations	O
of	O
uis	O
namely	O
spanu	O
i	O
aiui	O
r	O
ai	O
r	O
the	O
null	O
space	O
of	O
u	O
is	O
everything	O
that	O
s	O
left	O
rdspanu	O
todo	O
pictures	O
figure	O
where	O
is	O
used	O
explicitly	O
the	O
first	O
is	O
in	O
computing	O
the	O
activation	O
and	O
the	O
second	O
is	O
in	O
updating	O
the	O
weights	B
the	O
goal	O
is	O
to	O
remove	O
the	O
explicit	O
dependence	O
of	O
this	O
algorithm	B
on	O
and	O
on	O
the	O
weight	O
vector	B
to	O
do	O
so	O
you	O
can	O
observe	O
that	O
at	O
any	O
point	O
in	O
the	O
algorithm	B
the	O
weight	O
vector	B
w	O
can	O
be	O
written	O
as	O
a	O
linear	O
combination	O
of	O
expanded	O
training	B
data	I
in	O
particular	O
at	O
any	O
point	O
w	O
n	O
n	O
for	O
some	O
parameters	O
initially	O
w	O
so	O
choosing	O
yields	O
this	O
if	O
the	O
first	O
update	O
occurs	O
on	O
the	O
nth	O
training	O
example	O
then	O
the	O
resolution	O
weight	O
vector	B
is	O
simply	O
yn	O
which	O
is	O
equivalent	O
to	O
setting	O
n	O
yn	O
if	O
the	O
second	O
update	O
occurs	O
on	O
the	O
mth	O
training	O
example	O
then	O
all	O
you	O
need	O
to	O
do	O
is	O
update	O
m	O
m	O
ym	O
this	O
is	O
true	O
even	O
if	O
you	O
make	O
multiple	O
passes	O
over	O
the	O
data	O
this	O
observation	O
leads	O
to	O
the	O
following	O
representer	B
theorem	I
which	O
states	O
that	O
the	O
weight	O
vector	B
of	O
the	O
perceptron	B
lies	O
in	O
the	O
span	B
of	O
the	O
training	B
data	I
theorem	O
representer	B
theorem	I
during	O
a	O
run	O
of	O
the	O
perceptron	B
algorithm	B
the	O
weight	O
vector	B
w	O
is	O
always	O
in	O
the	O
span	B
of	O
the	O
non-empty	O
training	B
data	I
proof	O
of	O
theorem	O
by	O
induction	B
base	O
case	O
the	O
span	B
of	O
any	O
nonempty	O
set	O
contains	O
the	O
zero	O
vector	B
which	O
is	O
the	O
initial	O
weight	O
vector	B
inductive	O
case	O
suppose	O
that	O
the	O
theorem	O
is	O
true	O
before	O
the	O
kth	O
update	O
and	O
suppose	O
that	O
the	O
kth	O
update	O
happens	O
on	O
example	O
n	O
by	O
the	O
inductive	O
hypothesis	B
you	O
can	O
write	O
w	O
i	O
i	O
before	O
kernel	B
methods	O
algorithm	B
kernelizedperceptrontraind	O
maxiter	O
b	O
for	O
iter	O
maxiter	O
do	O
for	O
all	O
d	O
do	O
initialize	O
coefficients	O
and	O
bias	B
a	O
m	O
m	O
b	O
if	O
yna	O
then	O
n	O
n	O
yn	O
b	O
b	O
y	O
compute	O
activation	O
for	O
this	O
example	O
update	O
coefficients	O
update	O
bias	B
end	O
if	O
end	O
for	O
end	O
for	O
return	O
b	O
the	O
update	O
the	O
new	O
weight	O
vector	B
is	O
i	O
i	O
yn	O
i	O
i	O
yni	O
n	O
which	O
is	O
still	O
in	O
the	O
span	B
of	O
the	O
training	B
data	I
now	O
that	O
you	O
know	O
that	O
you	O
can	O
always	O
write	O
w	O
n	O
n	O
for	O
some	O
is	O
you	O
can	O
additionall	O
compute	O
the	O
activations	B
as	O
w	O
b	O
n	O
n	O
b	O
b	O
n	O
n	O
definition	O
of	O
w	O
dot	O
products	O
are	O
linear	O
this	O
now	O
depends	O
only	O
on	O
dot-products	O
between	O
data	O
points	O
and	O
never	O
explicitly	O
requires	O
a	O
weight	O
vector	B
you	O
can	O
now	O
rewrite	O
the	O
entire	O
perceptron	B
algorithm	B
so	O
that	O
it	O
never	O
refers	O
explicitly	O
to	O
the	O
weights	B
and	O
only	O
ever	O
depends	O
on	O
pairwise	O
dot	O
products	O
between	O
examples	B
this	O
is	O
shown	O
in	O
algorithm	B
the	O
advantage	O
to	O
this	O
kernelized	O
algorithm	B
is	O
that	O
you	O
can	O
per	O
form	O
feature	O
expansions	O
like	O
the	O
quadratic	O
feature	O
expansion	O
from	O
the	O
introduction	O
for	O
free	O
for	O
example	O
for	O
exactly	O
the	O
same	O
cost	O
as	O
the	O
quadratic	O
features	B
you	O
can	O
use	O
a	O
cubic	B
feature	I
map	I
computed	O
x	O
which	O
corresponds	O
to	O
three-way	O
interas	O
actions	O
between	O
variables	O
in	O
general	O
you	O
can	O
do	O
so	O
for	O
any	O
polynomial	O
degree	O
p	O
at	O
the	O
same	O
computational	O
complexity	B
kernelized	O
k-means	O
for	O
a	O
complete	O
change	O
of	O
pace	O
consider	O
the	O
k-means	O
algorithm	B
from	O
section	O
this	O
algorithm	B
is	O
for	O
clustering	B
where	O
there	O
is	O
no	O
notion	O
of	O
training	O
labels	O
instead	O
you	O
want	O
to	O
partition	O
the	O
data	O
into	O
coherent	O
clusters	O
for	O
data	O
in	O
rd	O
it	O
involves	O
randomly	O
initializing	O
k-many	O
a	O
course	O
in	O
machine	O
learning	O
cluster	O
means	O
the	O
algorithm	B
then	O
alternates	O
between	O
the	O
following	O
two	O
steps	O
until	O
convergence	O
with	O
x	O
replaced	O
by	O
since	O
that	O
is	O
the	O
eventual	O
goal	O
for	O
each	O
example	O
n	O
set	O
cluster	O
label	B
zn	O
arg	O
mink	O
for	O
each	O
cluster	O
k	O
update	O
nk	O
nznk	O
where	O
nk	O
is	O
the	O
number	O
of	O
n	O
with	O
zn	O
k	O
the	O
question	O
is	O
whether	O
you	O
can	O
perform	O
these	O
steps	O
without	O
explicitly	O
computing	O
the	O
representer	B
theorem	I
is	O
more	O
straightforward	O
here	O
than	O
in	O
the	O
perceptron	B
the	O
mean	O
of	O
a	O
set	O
of	O
data	O
is	O
almost	O
by	O
definition	O
in	O
the	O
span	B
of	O
that	O
data	O
the	O
ais	O
all	O
to	O
be	O
equal	O
to	O
thus	O
so	O
long	O
as	O
you	O
initialize	O
the	O
means	O
in	O
the	O
span	B
of	O
the	O
data	O
you	O
are	O
guaranteed	O
always	O
to	O
have	O
the	O
means	O
in	O
the	O
span	B
of	O
the	O
data	O
given	O
this	O
you	O
know	O
that	O
you	O
can	O
write	O
each	O
mean	O
as	O
an	O
expansion	O
of	O
the	O
data	O
say	O
that	O
n	O
n	O
for	O
some	O
parameters	O
n	O
are	O
n	O
k-many	O
such	O
parameters	O
given	O
this	O
expansion	O
in	O
order	O
to	O
execute	O
step	O
you	O
need	O
to	O
compute	O
norms	O
this	O
can	O
be	O
done	O
as	O
follows	O
m	O
m	O
zn	O
arg	O
min	O
k	O
arg	O
min	O
k	O
arg	O
min	O
k	O
m	O
m	O
m	O
m	O
definition	O
of	O
zn	O
definition	O
of	O
expand	O
quadratic	O
term	O
linearity	O
and	O
constant	O
k	O
m	O
m	O
arg	O
min	O
m	O
const	O
this	O
computation	O
can	O
replace	O
the	O
assignments	O
in	O
step	O
of	O
k-means	O
the	O
mean	O
updates	O
are	O
more	O
direct	O
in	O
step	O
m	O
nk	O
if	O
zn	O
k	O
otherwise	O
nk	O
nznk	O
n	O
what	O
makes	O
a	O
kernel	B
a	O
kernel	B
is	O
just	O
a	O
form	O
of	O
generalized	O
dot	B
product	I
you	O
can	O
also	O
think	O
of	O
it	O
as	O
simply	O
shorthand	O
for	O
which	O
is	O
commonly	O
written	O
k	O
z	O
or	O
when	O
is	O
clear	O
from	O
context	O
simply	O
kx	O
z	O
kernel	B
methods	O
this	O
is	O
often	O
refered	O
to	O
as	O
the	O
kernel	B
product	O
between	O
x	O
and	O
z	O
the	O
mapping	O
in	O
this	O
view	O
what	O
you	O
ve	O
seen	O
in	O
the	O
preceding	O
two	O
sections	O
is	O
that	O
you	O
can	O
rewrite	O
both	O
the	O
perceptron	B
algorithm	B
and	O
the	O
k-means	O
algorithm	B
so	O
that	O
they	O
only	O
ever	O
depend	O
on	O
kernel	B
products	O
between	O
data	O
points	O
and	O
never	O
on	O
the	O
actual	O
datapoints	O
themselves	O
this	O
is	O
a	O
very	O
powerful	O
notion	O
as	O
it	O
has	O
enabled	O
the	O
development	O
of	O
a	O
large	O
number	O
of	O
non-linear	B
algorithms	O
essentially	O
for	O
free	O
applying	O
the	O
so-called	O
kernel	B
trick	I
that	O
you	O
ve	O
just	O
seen	O
twice	O
this	O
raises	O
an	O
interesting	O
question	O
if	O
you	O
have	O
rewritten	O
these	O
algorithms	O
so	O
that	O
they	O
only	O
depend	O
on	O
the	O
data	O
through	O
a	O
function	O
k	O
x	O
x	O
r	O
can	O
you	O
stick	O
any	O
function	O
k	O
in	O
these	O
algorithms	O
or	O
are	O
there	O
some	O
k	O
that	O
are	O
forbidden	O
in	O
one	O
sense	O
you	O
could	O
use	O
any	O
k	O
but	O
the	O
real	O
question	O
is	O
for	O
what	O
types	O
of	O
functions	O
k	O
do	O
these	O
algorithms	O
retain	O
the	O
properties	O
that	O
we	O
expect	O
them	O
to	O
have	O
convergence	O
optimality	O
etc	O
one	O
way	O
to	O
answer	O
this	O
question	O
is	O
to	O
say	O
that	O
k	O
is	O
a	O
valid	O
kernel	B
if	O
it	O
corresponds	O
to	O
the	O
inner	O
product	O
between	O
two	O
vectors	O
that	O
is	O
k	O
is	O
valid	O
if	O
there	O
exists	O
a	O
function	O
such	O
that	O
kx	O
z	O
this	O
is	O
a	O
direct	O
definition	O
and	O
it	O
should	O
be	O
clear	O
that	O
if	O
k	O
satisfies	O
this	O
then	O
the	O
algorithms	O
go	O
through	O
as	O
expected	O
this	O
is	O
how	O
we	O
derived	O
them	O
you	O
ve	O
already	O
seen	O
the	O
general	O
class	O
of	O
polynomial	B
kernels	B
which	O
have	O
the	O
form	O
kpoly	O
d	O
z	O
x	O
z	O
where	O
d	O
is	O
a	O
hyperparameter	B
of	O
the	O
kernel	B
these	O
kernels	B
correspond	O
to	O
polynomial	O
feature	O
expansions	O
there	O
is	O
an	O
alternative	O
characterization	O
of	O
a	O
valid	O
kernel	B
function	O
that	O
is	O
more	O
mathematical	O
it	O
states	O
that	O
k	O
x	O
x	O
r	O
is	O
a	O
kernel	B
if	O
k	O
is	O
positive	B
semi-definite	I
in	O
shorthand	O
psd	B
this	O
property	O
is	O
also	O
sometimes	O
called	O
mercer	O
s	O
condition	O
in	O
this	O
context	O
this	O
means	O
the	O
for	O
all	O
functions	O
f	O
that	O
are	O
square	O
integrable	O
f	O
other	O
than	O
the	O
zero	O
function	O
the	O
following	O
property	O
holds	O
f	O
z	O
f	O
this	O
likely	O
seems	O
like	O
it	O
came	O
out	O
of	O
nowhere	O
unfortunately	O
the	O
connection	O
is	O
well	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
but	O
is	O
covered	O
well	O
is	O
external	O
sources	O
for	O
now	O
simply	O
take	O
it	O
as	O
a	O
given	O
that	O
this	O
is	O
an	O
equivalent	O
requirement	O
those	O
so	O
inclined	O
the	O
appendix	O
of	O
this	O
book	O
gives	O
a	O
proof	O
but	O
it	O
requires	O
a	O
bit	O
of	O
knowledge	O
of	O
function	O
spaces	O
to	O
understand	O
the	O
question	O
is	O
why	O
is	O
this	O
alternative	O
characterization	O
useful	O
it	O
is	O
useful	O
because	O
it	O
gives	O
you	O
an	O
alternative	O
way	O
to	O
construct	O
kernel	B
a	O
course	O
in	O
machine	O
learning	O
functions	O
for	O
instance	O
using	O
it	O
you	O
can	O
easily	O
prove	O
the	O
following	O
which	O
would	O
be	O
difficult	O
from	O
the	O
definition	O
of	O
kernels	B
as	O
inner	O
products	O
after	O
feature	O
mappings	O
theorem	O
addition	O
if	O
and	O
are	O
kernels	B
the	O
k	O
defined	O
by	O
kx	O
z	O
z	O
z	O
is	O
also	O
a	O
kernel	B
proof	O
of	O
theorem	O
you	O
need	O
to	O
verify	O
the	O
positive	B
semi-definite	I
property	O
on	O
k	O
you	O
can	O
do	O
this	O
as	O
follows	O
f	O
z	O
f	O
f	O
z	O
z	O
f	O
definition	O
of	O
k	O
f	O
z	O
f	O
f	O
z	O
f	O
distributive	O
rule	O
and	O
are	O
psd	B
more	O
generally	O
any	O
positive	O
linear	O
combination	O
of	O
kernels	B
is	O
still	O
a	O
kernel	B
specifically	O
if	O
km	O
are	O
all	O
kernels	B
and	O
m	O
then	O
kx	O
z	O
m	O
mkmx	O
z	O
is	O
also	O
a	O
kernel	B
you	O
can	O
also	O
use	O
this	O
property	O
to	O
show	O
that	O
the	O
following	O
gaus	O
sian	O
kernel	B
called	O
the	O
rbf	B
kernel	B
is	O
also	O
psd	B
krbf	O
z	O
exp	O
here	O
is	O
a	O
hyperparameter	B
that	O
controls	O
the	O
width	O
of	O
this	O
gaussianlike	O
bumps	O
to	O
gain	O
an	O
intuition	O
for	O
what	O
the	O
rbf	B
kernel	B
is	O
doing	O
consider	O
what	O
prediction	O
looks	O
like	O
in	O
the	O
perceptron	B
f	O
n	O
n	O
nkxn	O
x	O
b	O
n	O
exp	O
in	O
this	O
computation	O
each	O
training	O
example	O
is	O
getting	O
to	O
vote	B
on	O
the	O
label	B
of	O
the	O
test	O
point	O
x	O
the	O
amount	O
of	O
vote	B
that	O
the	O
nth	O
training	O
example	O
gets	O
is	O
proportional	O
to	O
the	O
negative	O
exponential	O
of	O
the	O
distance	B
between	O
the	O
test	O
point	O
and	O
itself	O
this	O
is	O
very	O
much	O
like	O
an	O
rbf	O
neural	B
network	I
in	O
which	O
there	O
is	O
a	O
gaussian	O
bump	O
at	O
each	O
training	O
example	O
with	O
variance	B
and	O
where	O
the	O
ns	O
act	O
as	O
the	O
weights	B
connecting	O
these	O
rbf	O
bumps	O
to	O
the	O
output	O
showing	O
that	O
this	O
kernel	B
is	O
positive	O
definite	O
is	O
a	O
bit	O
of	O
an	O
exercise	O
in	O
analysis	O
integration	O
by	O
parts	O
but	O
otherwise	O
not	O
difficult	O
again	O
the	O
proof	O
is	O
provided	O
in	O
the	O
appendix	O
kernel	B
methods	O
so	O
far	O
you	O
have	O
seen	O
two	O
bsaic	O
classes	O
of	O
kernels	B
polynomial	B
kernels	B
vz	O
x	O
zd	O
which	O
includes	O
the	O
linear	O
kernel	B
z	O
x	O
z	O
and	O
rbf	O
kernels	B
z	O
exp	O
the	O
former	O
have	O
a	O
direct	O
connection	O
to	O
feature	O
expansion	O
the	O
latter	O
to	O
rbf	O
networks	O
you	O
also	O
know	O
how	O
to	O
combine	O
kernels	B
to	O
get	O
new	O
kernels	B
by	O
addition	O
in	O
fact	O
you	O
can	O
do	O
more	O
than	O
that	O
the	O
product	O
of	O
two	O
kernels	B
is	O
also	O
a	O
kernel	B
as	O
far	O
as	O
a	O
library	O
of	O
kernels	B
goes	O
there	O
are	O
many	O
polynomial	O
and	O
rbf	O
are	O
by	O
far	O
the	O
most	O
popular	O
a	O
commonly	O
used	O
but	O
technically	O
invalid	O
kernel	B
is	O
the	O
hyperbolic-tangent	O
kernel	B
which	O
mimics	O
the	O
behavior	O
of	O
a	O
two-layer	O
neural	B
network	I
it	O
is	O
defined	O
as	O
ktanh	O
x	O
z	O
warning	O
not	O
psd	B
a	O
final	O
example	O
which	O
is	O
not	O
very	O
common	O
but	O
is	O
nonetheless	O
interesting	O
is	O
the	O
all-subsets	O
kernel	B
suppose	O
that	O
your	O
d	O
features	B
are	O
all	O
binary	O
all	O
take	O
values	O
or	O
let	O
a	O
d	O
be	O
a	O
subset	O
of	O
features	B
and	O
let	O
fax	O
d	O
a	O
xd	O
be	O
the	O
conjunction	O
of	O
all	O
the	O
features	B
in	O
a	O
let	O
be	O
a	O
feature	B
vector	B
over	O
all	O
such	O
as	O
so	O
that	O
there	O
are	O
features	B
in	O
the	O
vector	B
you	O
can	O
compute	O
the	O
kernel	B
associated	O
with	O
this	O
feature	B
mapping	I
as	O
ksubsx	O
z	O
d	O
xdzd	O
verifying	O
the	O
relationship	O
between	O
this	O
kernel	B
and	O
the	O
all-subsets	O
feature	B
mapping	I
is	O
left	O
as	O
an	O
exercise	O
closely	O
resembles	O
the	O
expansion	O
for	O
the	O
quadratic	O
kernel	B
support	O
vector	B
machines	O
kernelization	O
predated	O
support	O
vector	B
machines	O
but	O
svms	O
are	O
definitely	O
the	O
model	B
that	O
popularized	O
the	O
idea	O
recall	B
the	O
definition	O
of	O
the	O
soft-margin	B
svm	I
from	O
chapter	O
and	O
in	O
particular	O
the	O
optimization	B
problem	I
which	O
attempts	O
to	O
balance	O
a	O
large	O
margin	B
with	O
a	O
small	O
loss	O
ns	O
where	O
n	O
is	O
the	O
slack	B
on	O
the	O
nth	O
training	O
example	O
this	O
problem	O
is	O
repeated	O
below	O
n	O
min	O
wb	O
c	O
n	O
subj	O
to	O
yn	O
xn	O
b	O
n	O
n	O
n	O
n	O
previously	O
you	O
optimized	O
this	O
by	O
explicitly	O
computing	O
the	O
slack	B
variables	O
n	O
given	O
a	O
solution	O
to	O
the	O
decision	B
boundary	I
w	O
and	O
b	O
however	O
you	O
are	O
now	O
an	O
expert	O
with	O
using	O
lagrange	B
multipliers	I
a	O
course	O
in	O
machine	O
learning	O
to	O
optimize	O
constrained	O
problems	O
the	O
overall	O
goal	O
is	O
going	O
to	O
be	O
to	O
rewrite	O
the	O
svm	O
optimization	B
problem	I
in	O
a	O
way	O
that	O
it	O
no	O
longer	O
explicitly	O
depends	O
on	O
the	O
weights	B
w	O
and	O
only	O
depends	O
on	O
the	O
examples	B
xn	O
through	O
kernel	B
products	O
there	O
are	O
constraints	O
in	O
this	O
optimization	O
one	O
for	O
each	O
slack	B
constraint	O
and	O
one	O
for	O
the	O
requirement	O
that	O
the	O
slacks	O
are	O
nonnegative	O
unlike	O
the	O
last	O
time	O
these	O
constraints	O
are	O
now	O
inequalities	O
which	O
require	O
a	O
slightly	O
different	O
solution	O
first	O
you	O
rewrite	O
all	O
the	O
inequalities	O
so	O
that	O
they	O
read	O
as	O
something	O
and	O
then	O
add	O
corresponding	O
lagrange	B
multipliers	I
the	O
main	O
difference	O
is	O
that	O
the	O
lagrange	B
multipliers	I
are	O
now	O
constrained	O
to	O
be	O
non-negative	O
and	O
their	O
sign	B
in	O
the	O
augmented	O
objective	B
function	I
matters	O
the	O
second	O
set	O
of	O
constraints	O
is	O
already	O
in	O
the	O
proper	O
form	O
the	O
first	O
set	O
can	O
be	O
rewritten	O
as	O
yn	O
xn	O
b	O
n	O
you	O
re	O
now	O
ready	O
to	O
construct	O
the	O
lagrangian	B
using	O
multipliers	O
n	O
for	O
the	O
first	O
set	O
of	O
constraints	O
and	O
n	O
for	O
the	O
second	O
set	O
lw	O
b	O
n	O
n	O
n	O
c	O
n	O
n	O
n	O
n	O
xn	O
b	O
n	O
the	O
new	O
optimization	B
problem	I
is	O
min	O
wb	O
max	O
max	O
lw	O
b	O
the	O
intuition	O
is	O
exactly	O
the	O
same	O
as	O
before	O
if	O
you	O
are	O
able	O
to	O
find	O
a	O
solution	O
that	O
satisfies	O
the	O
constraints	O
the	O
purple	O
term	O
is	O
properly	O
non-negative	O
then	O
the	O
ns	O
cannot	O
do	O
anything	O
to	O
hurt	O
the	O
solution	O
on	O
the	O
other	O
hand	O
if	O
the	O
purple	O
term	O
is	O
negative	O
then	O
the	O
corresponding	O
n	O
can	O
go	O
to	O
breaking	O
the	O
solution	O
you	O
can	O
solve	O
this	O
problem	O
by	O
taking	O
gradients	O
this	O
is	O
a	O
bit	O
te	O
dious	O
but	O
and	O
important	O
step	O
to	O
realize	O
how	O
everything	O
fits	O
together	O
since	O
your	O
goal	O
is	O
to	O
remove	O
the	O
dependence	O
on	O
w	O
the	O
first	O
step	O
is	O
to	O
take	O
a	O
gradient	B
with	O
respect	O
to	O
w	O
set	O
it	O
equal	O
to	O
zero	O
and	O
solve	O
for	O
w	O
in	O
terms	O
of	O
the	O
other	O
variables	O
wl	O
w	O
n	O
nynxn	O
w	O
n	O
nynxn	O
at	O
this	O
point	O
you	O
should	O
immediately	O
recognize	O
a	O
similarity	O
to	O
the	O
kernelized	O
perceptron	B
the	O
optimal	O
weight	O
vector	B
takes	O
exactly	O
the	O
same	O
form	O
in	O
both	O
algorithms	O
you	O
can	O
now	O
take	O
this	O
new	O
expression	O
for	O
w	O
and	O
plug	O
it	O
back	O
in	O
to	O
the	O
expression	O
for	O
l	O
thus	O
removing	O
w	O
from	O
consideration	O
to	O
avoid	O
subscript	O
overloading	O
you	O
should	O
replace	O
the	O
n	O
in	O
the	O
expression	O
for	O
kernel	B
methods	O
w	O
with	O
say	O
m	O
this	O
yields	O
lb	O
m	O
n	O
m	O
mymxm	O
n	O
yn	O
c	O
n	O
n	O
n	O
n	O
n	O
mymxm	O
xn	O
b	O
n	O
at	O
this	O
point	O
it	O
s	O
convenient	O
to	O
rewrite	O
these	O
terms	O
be	O
sure	O
you	O
understand	O
where	O
the	O
following	O
comes	O
from	O
lb	O
n	O
m	O
n	O
n	O
mynymxn	O
xm	O
n	O
mynymxn	O
xm	O
m	O
n	O
n	O
n	O
n	O
n	O
n	O
n	O
mynymxn	O
xm	O
n	O
m	O
b	O
nyn	O
n	O
n	O
n	O
n	O
n	O
n	O
n	O
things	O
are	O
starting	O
to	O
look	O
good	O
you	O
ve	O
successfully	O
removed	O
the	O
dependence	O
on	O
w	O
and	O
everything	O
is	O
now	O
written	O
in	O
terms	O
of	O
dot	O
products	O
between	O
input	O
vectors	O
this	O
might	O
still	O
be	O
a	O
difficult	O
problem	O
to	O
solve	O
so	O
you	O
need	O
to	O
continue	O
and	O
attempt	O
to	O
remove	O
the	O
remaining	O
variables	O
b	O
and	O
the	O
derivative	O
with	O
respect	O
to	O
b	O
is	O
l	O
b	O
n	O
nyn	O
this	O
doesn	O
t	O
allow	O
you	O
to	O
substitute	O
b	O
with	O
something	O
you	O
did	O
with	O
w	O
but	O
it	O
does	O
mean	O
that	O
the	O
fourth	O
term	O
n	O
nyn	O
goes	O
to	O
zero	O
at	O
the	O
optimum	O
the	O
last	O
of	O
the	O
original	O
variables	O
is	O
n	O
the	O
derivatives	O
in	O
this	O
case	O
look	O
like	O
l	O
n	O
c	O
n	O
n	O
c	O
n	O
n	O
again	O
this	O
doesn	O
t	O
allow	O
you	O
to	O
substitute	O
but	O
it	O
does	O
mean	O
that	O
you	O
can	O
rewrite	O
the	O
second	O
term	O
which	O
as	O
nc	O
n	O
n	O
as	O
n	O
n	O
n	O
this	O
then	O
cancels	O
with	O
of	O
the	O
final	O
term	O
however	O
you	O
need	O
to	O
be	O
careful	O
to	O
remember	O
something	O
when	O
we	O
optimize	O
both	O
n	O
and	O
n	O
are	O
constrained	O
to	O
be	O
non-negative	O
what	O
this	O
means	O
is	O
that	O
since	O
we	O
are	O
dropping	O
from	O
the	O
optimization	O
we	O
need	O
to	O
ensure	O
that	O
n	O
c	O
otherwise	O
the	O
corresponding	O
will	O
need	O
to	O
be	O
negative	O
which	O
is	O
not	O
a	O
course	O
in	O
machine	O
learning	O
allowed	O
you	O
finally	O
wind	O
up	O
with	O
the	O
following	O
where	O
xn	O
xm	O
has	O
been	O
replaced	O
by	O
kxn	O
xm	O
l	O
n	O
n	O
n	O
m	O
n	O
mynymkxn	O
xm	O
if	O
you	O
are	O
comfortable	O
with	O
matrix	O
notation	O
this	O
has	O
a	O
very	O
compact	O
form	O
let	O
denote	O
the	O
n-dimensional	O
vector	B
of	O
all	O
let	O
y	O
denote	O
the	O
vector	B
of	O
labels	O
and	O
let	O
g	O
be	O
the	O
n	O
n	O
matrix	O
where	O
gnm	O
ynymkxn	O
xm	O
then	O
this	O
has	O
the	O
following	O
form	O
l	O
the	O
resulting	O
optimization	B
problem	I
is	O
to	O
maximize	O
l	O
as	O
a	O
function	O
of	O
subject	O
to	O
the	O
constraint	O
that	O
the	O
ns	O
are	O
all	O
non-negative	O
and	O
less	O
than	O
c	O
of	O
the	O
constraint	O
added	O
when	O
removing	O
the	O
variables	O
thus	O
your	O
problem	O
is	O
min	O
l	O
subj	O
to	O
n	O
c	O
n	O
m	O
n	O
mynymkxn	O
xm	O
n	O
n	O
n	O
one	O
way	O
to	O
solve	O
this	O
problem	O
is	O
gradient	B
descent	I
on	O
the	O
only	O
complication	O
is	O
making	O
sure	O
that	O
the	O
s	O
satisfy	O
the	O
constraints	O
in	O
this	O
case	O
you	O
can	O
use	O
a	O
projected	B
gradient	B
algorithm	B
after	O
each	O
gradient	B
update	O
you	O
adjust	O
your	O
parameters	O
to	O
satisfy	O
the	O
constraints	O
by	O
projecting	O
them	O
into	O
the	O
feasible	B
region	I
in	O
this	O
case	O
the	O
projection	O
is	O
trivial	O
if	O
after	O
a	O
gradient	B
step	O
any	O
n	O
simply	O
set	O
it	O
to	O
if	O
any	O
n	O
c	O
set	O
it	O
to	O
c	O
understanding	O
support	O
vector	B
machines	O
the	O
prior	B
discussion	O
involved	O
quite	O
a	O
bit	O
of	O
math	O
to	O
derive	O
a	O
representation	O
of	O
the	O
support	B
vector	B
machine	I
in	O
terms	O
of	O
the	O
lagrange	O
variables	O
this	O
mapping	O
is	O
actually	O
sufficiently	O
standard	O
that	O
everything	O
in	O
it	O
has	O
a	O
name	O
the	O
original	O
problem	O
variables	O
b	O
are	O
called	O
the	O
primal	B
variables	I
the	O
lagrange	O
variables	O
are	O
called	O
the	O
dual	B
variables	I
the	O
optimization	B
problem	I
that	O
results	O
after	O
removing	O
all	O
of	O
the	O
primal	B
variables	I
is	O
called	O
the	O
dual	B
problem	I
a	O
succinct	O
way	O
of	O
saying	O
what	O
you	O
ve	O
done	O
is	O
you	O
found	O
that	O
after	O
converting	O
the	O
svm	O
into	O
its	O
dual	O
it	O
is	O
possible	O
to	O
kernelize	O
to	O
understand	O
svms	O
a	O
first	O
step	O
is	O
to	O
peek	O
into	O
the	O
dual	O
formulation	O
eq	O
the	O
objective	O
has	O
two	O
terms	O
the	O
first	O
depends	O
on	O
the	O
data	O
and	O
the	O
second	O
depends	O
only	O
on	O
the	O
dual	B
variables	I
the	O
first	O
thing	O
to	O
notice	O
is	O
that	O
because	O
of	O
the	O
second	O
term	O
the	O
s	O
want	O
to	O
kernel	B
methods	O
get	O
as	O
large	O
as	O
possible	O
the	O
constraint	O
ensures	O
that	O
they	O
cannot	O
exceed	O
c	O
which	O
means	O
that	O
the	O
general	O
tendency	O
is	O
for	O
the	O
s	O
to	O
grow	O
as	O
close	O
to	O
c	O
as	O
possible	O
to	O
further	O
understand	O
the	O
dual	O
optimization	B
problem	I
it	O
is	O
useful	O
to	O
think	O
of	O
the	O
kernel	B
as	O
being	O
a	O
measure	O
of	O
similarity	O
between	O
two	O
data	O
points	O
this	O
analogy	O
is	O
most	O
clear	O
in	O
the	O
case	O
of	O
rbf	O
kernels	B
but	O
even	O
in	O
the	O
case	O
of	O
linear	O
kernels	B
if	O
your	O
examples	B
all	O
have	O
unit	O
norm	O
then	O
their	O
dot	B
product	I
is	O
still	O
a	O
measure	O
of	O
similarity	O
since	O
you	O
can	O
write	O
the	O
prediction	O
function	O
as	O
f	O
x	O
sign	B
n	O
nynkxn	O
x	O
it	O
is	O
natural	O
to	O
think	O
of	O
n	O
as	O
the	O
importance	O
of	O
training	O
example	O
n	O
where	O
n	O
means	O
that	O
it	O
is	O
not	O
used	O
at	O
all	O
at	O
test	O
time	O
consider	O
two	O
data	O
points	O
that	O
have	O
the	O
same	O
label	B
namely	O
yn	O
ym	O
this	O
means	O
that	O
ynym	O
and	O
the	O
objective	B
function	I
has	O
a	O
term	O
that	O
looks	O
like	O
n	O
mkxn	O
xm	O
since	O
the	O
goal	O
is	O
to	O
make	O
this	O
term	O
small	O
then	O
one	O
of	O
two	O
things	O
has	O
to	O
happen	O
either	O
k	O
has	O
to	O
be	O
small	O
or	O
n	O
m	O
has	O
to	O
be	O
small	O
if	O
k	O
is	O
already	O
small	O
then	O
this	O
doesn	O
t	O
affect	O
the	O
setting	O
of	O
the	O
corresponding	O
s	O
but	O
if	O
k	O
is	O
large	O
then	O
this	O
strongly	O
encourages	O
at	O
least	O
one	O
of	O
n	O
or	O
m	O
to	O
go	O
to	O
zero	O
so	O
if	O
you	O
have	O
two	O
data	O
points	O
that	O
are	O
very	O
similar	O
and	O
have	O
the	O
same	O
label	B
at	O
least	O
one	O
of	O
the	O
corresponding	O
s	O
will	O
be	O
small	O
this	O
makes	O
intuitive	O
sense	O
if	O
you	O
have	O
two	O
data	O
points	O
that	O
are	O
basically	O
the	O
same	O
in	O
the	O
x	O
and	O
y	O
sense	O
then	O
you	O
only	O
need	O
to	O
keep	O
one	O
of	O
them	O
around	O
suppose	O
that	O
you	O
have	O
two	O
data	O
points	O
with	O
different	O
labels	O
ynym	O
again	O
if	O
kxn	O
xm	O
is	O
small	O
nothing	O
happens	O
but	O
if	O
it	O
is	O
large	O
then	O
the	O
corresponding	O
s	O
are	O
encouraged	O
to	O
be	O
as	O
large	O
as	O
possible	O
in	O
other	O
words	O
if	O
you	O
have	O
two	O
similar	O
examples	B
with	O
different	O
labels	O
you	O
are	O
strongly	O
encouraged	O
to	O
keep	O
the	O
corresponding	O
s	O
as	O
large	O
as	O
c	O
an	O
alternative	O
way	O
of	O
understanding	O
the	O
svm	O
dual	B
problem	I
is	O
geometrically	O
remember	O
that	O
the	O
whole	O
point	O
of	O
introducing	O
the	O
variable	O
n	O
was	O
to	O
ensure	O
that	O
the	O
nth	O
training	O
example	O
was	O
correctly	O
classified	O
modulo	O
slack	B
more	O
formally	O
the	O
goal	O
of	O
n	O
is	O
to	O
ensure	O
that	O
ynw	O
xn	O
b	O
n	O
suppose	O
that	O
this	O
constraint	O
it	O
not	O
satisfied	O
there	O
is	O
an	O
important	O
result	O
in	O
optimization	O
theory	O
called	O
the	O
karush-kuhn-tucker	B
conditions	I
kkt	B
conditions	I
for	O
short	O
that	O
states	O
that	O
at	O
the	O
optimum	O
the	O
product	O
of	O
the	O
lagrange	O
multiplier	O
for	O
a	O
constraint	O
and	O
the	O
value	O
of	O
that	O
constraint	O
will	O
equal	O
zero	O
in	O
this	O
case	O
this	O
says	O
that	O
at	O
the	O
optimum	O
you	O
have	O
yn	O
xn	O
b	O
n	O
n	O
in	O
order	O
for	O
this	O
to	O
be	O
true	O
it	O
means	O
that	O
least	O
one	O
of	O
the	O
following	O
must	O
be	O
true	O
n	O
or	O
yn	O
xn	O
b	O
n	O
a	O
course	O
in	O
machine	O
learning	O
a	O
reasonable	O
question	O
to	O
ask	O
is	O
under	O
what	O
circumstances	O
will	O
n	O
be	O
non-zero	O
from	O
the	O
kkt	B
conditions	I
you	O
can	O
discern	O
that	O
n	O
can	O
be	O
non-zero	O
only	O
when	O
the	O
constraint	O
holds	O
exactly	O
namely	O
that	O
yn	O
xn	O
b	O
n	O
when	O
does	O
that	O
constraint	O
hold	O
exactly	O
it	O
holds	O
exactly	O
only	O
for	O
those	O
points	O
precisely	O
on	O
the	O
margin	B
of	O
the	O
hyperplane	B
in	O
other	O
words	O
the	O
only	O
training	O
examples	B
for	O
which	O
n	O
are	O
those	O
that	O
lie	O
precisely	O
unit	O
away	O
from	O
the	O
maximum	O
margin	B
decision	B
boundary	I
those	O
that	O
are	O
moved	O
there	O
by	O
the	O
corresponding	O
slack	B
these	O
points	O
are	O
called	O
the	O
support	B
vectors	I
because	O
they	O
support	O
the	O
decision	B
boundary	I
in	O
general	O
the	O
number	O
of	O
support	B
vectors	I
is	O
far	O
smaller	O
than	O
the	O
number	O
of	O
training	O
examples	B
and	O
therefore	O
you	O
naturally	O
end	O
up	O
with	O
a	O
solution	O
that	O
only	O
uses	O
a	O
subset	O
of	O
the	O
training	B
data	I
from	O
the	O
first	O
discussion	O
you	O
know	O
that	O
the	O
points	O
that	O
wind	O
up	O
being	O
support	B
vectors	I
are	O
exactly	O
those	O
that	O
are	O
confusable	O
in	O
the	O
sense	O
that	O
you	O
have	O
to	O
examples	B
that	O
are	O
nearby	O
but	O
have	O
different	O
labels	O
this	O
is	O
a	O
completely	O
in	O
line	O
with	O
the	O
previous	O
discussion	O
if	O
you	O
have	O
a	O
decision	B
boundary	I
it	O
will	O
pass	O
between	O
these	O
confusable	O
points	O
and	O
therefore	O
they	O
will	O
end	O
up	O
being	O
part	O
of	O
the	O
set	O
of	O
support	B
vectors	I
exercises	O
exercise	O
todo	O
learning	O
theory	O
learning	O
objectives	O
explain	O
why	O
inductive	B
bias	B
is	O
necessary	O
define	O
the	O
pac	B
model	B
and	O
explain	O
why	O
both	O
the	O
p	O
and	O
a	O
are	O
necessary	O
explain	O
the	O
relationship	O
between	O
complexity	B
measures	O
and	O
regularizers	O
identify	O
the	O
role	O
of	O
complexity	B
in	O
generalization	O
formalize	O
the	O
relationship	O
between	O
margins	O
and	O
complexity	B
dependencies	O
for	O
nothing	O
ought	O
to	O
be	O
posited	O
without	O
a	O
reason	O
given	O
unless	O
it	O
is	O
self-evident	O
or	O
known	O
by	O
experience	O
or	O
proved	O
by	O
the	O
authority	O
of	O
sacred	O
scripture	O
william	O
of	O
occam	O
c	O
by	O
now	O
you	O
are	O
an	O
expert	O
at	O
building	O
learning	O
algorithms	O
you	O
probably	O
understand	O
how	O
they	O
work	O
intuitively	O
and	O
you	O
understand	O
why	O
they	O
should	O
generalize	B
however	O
there	O
are	O
several	O
basic	O
questions	O
you	O
might	O
want	O
to	O
know	O
the	O
answer	O
to	O
is	O
learning	O
always	O
possible	O
how	O
many	O
training	O
examples	B
will	O
i	O
need	O
to	O
do	O
a	O
good	O
job	O
learning	O
is	O
my	O
test	O
performance	O
going	O
to	O
be	O
much	O
worse	O
than	O
my	O
training	O
performance	O
the	O
key	O
idea	O
that	O
underlies	O
all	O
these	O
answer	O
is	O
that	O
simple	O
functions	O
generalize	B
well	O
the	O
amazing	O
thing	O
is	O
that	O
you	O
can	O
actually	O
prove	O
strong	O
results	O
that	O
address	O
the	O
above	O
questions	O
in	O
this	O
chapter	O
you	O
will	O
learn	O
some	O
of	O
the	O
most	O
important	O
results	O
in	O
learning	O
theory	O
that	O
attempt	O
to	O
answer	O
these	O
questions	O
the	O
goal	O
of	O
this	O
chapter	O
is	O
not	O
theory	O
for	O
theory	O
s	O
sake	O
but	O
rather	O
as	O
a	O
way	O
to	O
better	O
understand	O
why	O
learning	O
models	O
work	O
and	O
how	O
to	O
use	O
this	O
theory	O
to	O
build	O
better	O
algorithms	O
as	O
a	O
concrete	O
example	O
we	O
will	O
see	O
how	O
regularization	O
provably	O
leads	O
to	O
better	O
generalization	O
performance	O
thus	O
justifying	O
our	O
common	O
practice	O
the	O
role	O
of	O
theory	O
in	O
contrast	O
to	O
the	O
quote	O
at	O
the	O
start	O
of	O
this	O
chapter	O
a	O
practitioner	O
friend	O
once	O
said	O
i	O
would	O
happily	O
give	O
up	O
a	O
few	O
percent	O
performance	O
for	O
an	O
algorithm	B
that	O
i	O
can	O
understand	O
both	O
perspectives	O
are	O
completely	O
valid	O
and	O
are	O
actually	O
not	O
contradictory	O
the	O
second	O
statement	O
is	O
presupposing	O
that	O
theory	O
helps	O
you	O
understand	O
which	O
hopefully	O
you	O
ll	O
find	O
to	O
be	O
the	O
case	O
in	O
this	O
chapter	O
theory	O
can	O
serve	O
two	O
roles	O
it	O
can	O
justify	O
and	O
help	O
understand	O
why	O
common	O
practice	O
works	O
this	O
is	O
the	O
theory	O
after	O
view	O
it	O
can	O
also	O
serve	O
to	O
suggest	O
new	O
algorithms	O
and	O
approaches	O
that	O
turn	O
out	O
to	O
work	O
well	O
in	O
practice	O
this	O
is	O
the	O
theory	O
before	O
view	O
often	O
it	O
turns	O
out	O
to	O
be	O
a	O
mix	O
practitioners	O
discover	O
something	O
that	O
works	O
surprisingly	O
well	O
theorists	O
figure	O
out	O
why	O
it	O
works	O
and	O
prove	O
something	O
about	O
it	O
and	O
in	O
the	O
process	O
they	O
make	O
it	O
better	O
or	O
find	O
new	O
algo	O
a	O
course	O
in	O
machine	O
learning	O
rithms	O
that	O
more	O
directly	O
exploit	O
whatever	O
property	O
it	O
is	O
that	O
made	O
the	O
theory	O
go	O
through	O
theory	O
can	O
also	O
help	O
you	O
understand	O
what	O
s	O
possible	O
and	O
what	O
s	O
not	O
possible	O
one	O
of	O
the	O
first	O
things	O
we	O
ll	O
see	O
is	O
that	O
in	O
general	O
machine	O
learning	O
can	O
not	O
work	O
of	O
course	O
it	O
does	O
work	O
so	O
this	O
means	O
that	O
we	O
need	O
to	O
think	O
harder	O
about	O
what	O
it	O
means	O
for	O
learning	O
algorithms	O
to	O
work	O
by	O
understanding	O
what	O
s	O
not	O
possible	O
you	O
can	O
focus	O
our	O
energy	O
on	O
things	O
that	O
are	O
probably	O
the	O
biggest	O
practical	O
success	O
story	O
for	O
theoretical	O
machine	O
learning	O
is	O
the	O
theory	O
of	O
boosting	B
which	O
you	O
won	O
t	O
actually	O
see	O
in	O
this	O
chapter	O
ll	O
have	O
to	O
wait	O
for	O
chapter	O
boosting	B
is	O
a	O
very	O
simple	O
style	O
of	O
algorithm	B
that	O
came	O
out	O
of	O
theoretical	O
machine	O
learning	O
and	O
has	O
proven	O
to	O
be	O
incredibly	O
successful	O
in	O
practice	O
so	O
much	O
so	O
that	O
it	O
is	O
one	O
of	O
the	O
de	O
facto	O
algorithms	O
to	O
run	O
when	O
someone	O
gives	O
you	O
a	O
new	O
data	O
set	O
in	O
fact	O
in	O
yoav	O
freund	O
and	O
rob	O
schapire	O
won	O
the	O
acm	O
s	O
paris	O
kanellakis	O
award	O
for	O
their	O
boosting	B
algorithm	B
adaboost	B
this	O
award	O
is	O
given	O
for	O
theoretical	O
accomplishments	O
that	O
have	O
had	O
a	O
significant	O
and	O
demonstrable	O
effect	O
on	O
the	O
practice	O
of	O
induction	B
is	O
impossible	O
one	O
nice	O
thing	O
about	O
theory	O
is	O
that	O
it	O
forces	O
you	O
to	O
be	O
precise	O
about	O
what	O
you	O
are	O
trying	O
to	O
do	O
you	O
ve	O
already	O
seen	O
a	O
formal	O
definition	O
of	O
binary	O
classification	O
in	O
chapter	O
but	O
let	O
s	O
take	O
a	O
step	O
back	O
and	O
re-analyze	O
what	O
it	O
means	O
to	O
learn	O
to	O
do	O
binary	O
classification	O
from	O
an	O
algorithmic	O
perspective	O
a	O
natural	O
question	O
is	O
whether	O
there	O
is	O
an	O
ultimate	O
learning	O
algorithm	B
aawesome	O
that	O
solves	O
the	O
binary	O
classification	O
problem	O
above	O
in	O
other	O
words	O
have	O
you	O
been	O
wasting	O
your	O
time	O
learning	O
about	O
knn	O
and	O
perceptron	B
and	O
decision	B
trees	I
when	O
aawesome	O
is	O
out	O
there	O
what	O
would	O
such	O
an	O
ultimate	O
learning	O
algorithm	B
do	O
you	O
would	O
like	O
it	O
to	O
take	O
in	O
a	O
data	O
set	O
d	O
and	O
produce	O
a	O
function	O
f	O
no	O
matter	O
what	O
d	O
looks	O
like	O
this	O
function	O
f	O
should	O
get	O
perfect	O
classification	O
on	O
all	O
future	O
examples	B
drawn	O
from	O
the	O
same	O
distribution	O
that	O
produced	O
d	O
a	O
little	O
bit	O
of	O
introspection	O
should	O
demonstrate	O
that	O
this	O
is	O
impossible	O
for	O
instance	O
there	O
might	O
be	O
label	B
noise	B
in	O
our	O
distribution	O
as	O
a	O
very	O
simple	O
example	O
let	O
x	O
a	O
one-dimensional	O
binary	O
distribution	O
define	O
the	O
data	O
distribution	O
as	O
in	O
other	O
words	O
of	O
data	O
points	O
in	O
this	O
distrubtion	O
have	O
x	O
y	O
in	O
corinna	O
cortes	O
and	O
vladimir	O
vapnik	O
won	O
it	O
for	O
support	O
vector	B
machines	O
learning	O
theory	O
it	O
s	O
clear	O
that	O
if	O
your	O
algorithm	B
produces	O
a	O
deterministic	O
function	O
that	O
it	O
cannot	O
do	O
better	O
than	O
error	O
what	O
if	O
it	O
produces	O
a	O
stochastic	O
randomized	O
function	O
leslie	O
valiant	O
invented	O
the	O
notion	O
of	O
pac	B
learning	O
in	O
in	O
he	O
received	O
the	O
turing	O
award	O
the	O
highest	O
honor	O
in	O
computing	O
for	O
his	O
work	O
in	O
learning	O
theory	O
computational	O
complexity	B
and	O
parallel	O
systems	O
and	O
don	O
t	O
no	O
matter	O
what	O
function	O
your	O
learning	O
algorithm	B
produces	O
there	O
s	O
no	O
way	O
that	O
it	O
can	O
do	O
better	O
than	O
error	O
on	O
this	O
data	O
given	O
this	O
it	O
seems	O
hopeless	O
to	O
have	O
an	O
algorithm	B
aawesome	O
that	O
always	O
achieves	O
an	O
error	B
rate	I
of	O
zero	O
the	O
best	O
that	O
we	O
can	O
hope	O
is	O
that	O
the	O
error	B
rate	I
is	O
not	O
too	O
large	O
unfortunately	O
simply	O
weakening	O
our	O
requirement	O
on	O
the	O
error	B
rate	I
is	O
not	O
enough	O
to	O
make	O
learning	O
possible	O
the	O
second	O
source	O
of	O
difficulty	O
comes	O
from	O
the	O
fact	O
that	O
the	O
only	O
access	O
we	O
have	O
to	O
the	O
data	O
distribution	O
is	O
through	O
sampling	O
in	O
particular	O
when	O
trying	O
to	O
learn	O
about	O
a	O
distribution	O
like	O
that	O
in	O
you	O
only	O
get	O
to	O
see	O
data	O
points	O
drawn	O
from	O
that	O
distribution	O
you	O
know	O
that	O
eventually	O
you	O
will	O
see	O
enough	O
data	O
points	O
that	O
your	O
sample	O
is	O
representative	O
of	O
the	O
distribution	O
but	O
it	O
might	O
not	O
happen	O
immediately	O
for	O
instance	O
even	O
though	O
a	O
fair	O
coin	O
will	O
come	O
up	O
heads	O
only	O
with	O
probability	O
it	O
s	O
completely	O
plausible	O
that	O
in	O
a	O
sequence	O
of	O
four	O
coin	O
flips	O
you	O
never	O
see	O
a	O
tails	O
or	O
perhaps	O
only	O
see	O
one	O
tails	O
aawesome	O
will	O
always	O
work	O
in	O
particular	O
if	O
we	O
happen	O
to	O
get	O
a	O
lousy	O
sample	O
of	O
data	O
from	O
d	O
we	O
need	O
to	O
allow	O
aawesome	O
to	O
do	O
something	O
completely	O
unreasonable	O
thus	O
we	O
cannot	O
hope	O
that	O
aawesome	O
will	O
do	O
perfectly	O
every	O
time	O
we	O
cannot	O
even	O
hope	O
that	O
it	O
will	O
do	O
pretty	O
well	O
all	O
of	O
the	O
time	O
nor	O
can	O
we	O
hope	O
that	O
it	O
will	O
do	O
perfectly	O
most	O
of	O
the	O
time	O
the	O
best	O
best	O
we	O
can	O
reasonably	O
hope	O
of	O
aawesome	O
is	O
that	O
it	O
it	O
will	O
do	O
pretty	O
well	O
most	O
of	O
the	O
time	O
so	O
the	O
second	O
thing	O
that	O
we	O
have	O
to	O
give	O
up	O
is	O
the	O
hope	O
that	O
probably	B
approximately	I
correct	I
learning	O
probably	B
approximately	I
correct	I
learning	O
is	O
a	O
formalism	O
of	O
inductive	O
learning	O
based	O
on	O
the	O
realization	O
that	O
the	O
best	O
we	O
can	O
hope	O
of	O
an	O
algorithm	B
is	O
that	O
it	O
does	O
a	O
good	O
job	O
is	O
approximately	O
correct	O
most	O
of	O
the	O
time	O
it	O
is	O
probably	O
appoximately	O
consider	O
a	O
hypothetical	O
learning	O
algorithm	B
you	O
run	O
it	O
on	O
ten	O
different	O
binary	O
classification	O
data	O
sets	O
for	O
each	O
one	O
it	O
comes	O
back	O
with	O
functions	O
for	O
some	O
reason	O
whenever	O
you	O
run	O
on	O
a	O
test	O
point	O
it	O
crashes	O
your	O
computer	O
for	O
the	O
other	O
learned	O
functions	O
their	O
performance	O
on	O
test	B
data	I
is	O
always	O
at	O
most	O
error	O
if	O
this	O
situtation	O
is	O
guaranteed	O
to	O
happen	O
then	O
this	O
hypothetical	O
learning	O
algorithm	B
is	O
a	O
pac	B
learning	O
algorithm	B
it	O
satisfies	O
probably	O
because	O
it	O
only	O
failed	O
in	O
one	O
out	O
of	O
ten	O
cases	O
and	O
it	O
s	O
approximate	O
because	O
it	O
achieved	O
low	O
but	O
non-zero	O
error	O
on	O
the	O
remainder	O
of	O
the	O
cases	O
this	O
leads	O
to	O
the	O
formal	O
definition	O
of	O
an	O
pac-learning	O
algo	O
rithm	O
in	O
this	O
definition	O
plays	O
the	O
role	O
of	O
measuring	O
accuracy	O
a	O
course	O
in	O
machine	O
learning	O
the	O
previous	O
example	O
and	O
plays	O
the	O
role	O
of	O
measuring	O
failure	O
the	O
previous	O
definitions	O
an	O
algorithm	B
a	O
is	O
an	O
learning	O
algorithm	B
if	O
for	O
all	O
distributions	O
d	O
given	O
samples	O
from	O
d	O
the	O
probability	O
that	O
it	O
returns	O
a	O
bad	O
function	O
is	O
at	O
most	O
where	O
a	O
bad	O
function	O
is	O
one	O
with	O
test	B
error	B
rate	I
more	O
than	O
on	O
d	O
there	O
are	O
two	O
notions	O
of	O
efficiency	O
that	O
matter	O
in	O
pac	B
learning	O
the	O
first	O
is	O
the	O
usual	O
notion	O
of	O
computational	O
complexity	B
you	O
would	O
prefer	O
an	O
algorithm	B
that	O
runs	O
quickly	O
to	O
one	O
that	O
takes	O
forever	O
the	O
second	O
is	O
the	O
notion	O
of	O
sample	B
complexity	B
the	O
number	O
of	O
examples	B
required	O
for	O
your	O
algorithm	B
to	O
achieve	O
its	O
goals	O
note	O
that	O
the	O
goal	O
of	O
both	O
of	O
these	O
measure	O
of	O
complexity	B
is	O
to	O
bound	O
how	O
much	O
of	O
a	O
scarse	O
resource	O
your	O
algorithm	B
uses	O
in	O
the	O
computational	O
case	O
the	O
resource	O
is	O
cpu	O
cycles	O
in	O
the	O
sample	O
case	O
the	O
resource	O
is	O
labeled	O
examples	B
definition	O
an	O
algorithm	B
a	O
is	O
an	O
efficient	O
learning	O
algorithm	B
if	O
it	O
is	O
an	O
learning	O
algorithm	B
whose	O
runtime	O
is	O
polynomial	O
in	O
and	O
in	O
other	O
words	O
suppose	O
that	O
you	O
want	O
your	O
algorithm	B
to	O
achieve	O
error	B
rate	I
rather	O
than	O
the	O
runtime	O
required	O
to	O
do	O
so	O
should	O
no	O
go	O
up	O
by	O
an	O
exponential	O
factor	O
pac	B
learning	O
of	O
conjunctions	O
to	O
get	O
a	O
better	O
sense	O
of	O
pac	B
learning	O
we	O
will	O
start	O
with	O
a	O
completely	O
irrelevant	O
and	O
uninteresting	O
example	O
the	O
purpose	O
of	O
this	O
example	O
is	O
only	O
to	O
help	O
understand	O
how	O
pac	B
learning	O
works	O
the	O
setting	O
is	O
learning	O
conjunctions	O
your	O
data	O
points	O
are	O
binary	O
vectors	O
for	O
instance	O
x	O
someone	O
guarantees	O
for	O
you	O
that	O
there	O
is	O
some	O
boolean	O
conjunction	O
that	O
defines	O
the	O
true	O
labeling	O
of	O
this	O
data	O
for	O
instance	O
or	O
is	O
not	O
allowed	O
in	O
formal	O
terms	O
we	O
often	O
call	O
the	O
true	O
underlying	O
classification	O
function	O
the	O
concept	B
so	O
this	O
is	O
saying	O
that	O
the	O
concept	B
you	O
are	O
trying	O
to	O
learn	O
is	O
a	O
conjunction	O
in	O
this	O
case	O
the	O
boolean	O
function	O
would	O
assign	O
a	O
negative	O
label	B
to	O
the	O
example	O
above	O
since	O
you	O
know	O
that	O
the	O
concept	B
you	O
are	O
trying	O
to	O
learn	O
is	O
a	O
conjunction	O
it	O
makes	O
sense	O
that	O
you	O
would	O
represent	O
your	O
function	O
as	O
a	O
conjunction	O
as	O
well	O
for	O
historical	O
reasons	O
the	O
function	O
that	O
you	O
learn	O
is	O
often	O
called	O
a	O
hypothesis	B
and	O
is	O
often	O
denoted	O
h	O
however	O
in	O
keeping	O
with	O
the	O
other	O
notation	O
in	O
this	O
book	O
we	O
will	O
continue	O
to	O
denote	O
it	O
f	O
formally	O
the	O
set	O
up	O
is	O
as	O
follows	O
there	O
is	O
some	O
distribution	O
dx	O
over	O
binary	O
data	O
points	O
x	O
there	O
is	O
a	O
fixed	O
concept	B
conjunction	O
c	O
that	O
we	O
are	O
trying	O
to	O
learn	O
there	O
is	O
no	O
noise	B
so	O
for	O
any	O
example	O
x	O
its	O
true	O
label	B
is	O
simply	O
y	O
cx	O
what	O
is	O
a	O
reasonable	O
algorithm	B
in	O
this	O
case	O
suppose	O
that	O
you	O
observe	O
the	O
example	O
in	O
table	O
from	O
the	O
first	O
example	O
we	O
know	O
that	O
the	O
true	O
formula	O
cannot	O
include	O
the	O
term	O
if	O
it	O
did	O
this	O
example	O
would	O
have	O
to	O
be	O
negative	O
which	O
it	O
is	O
not	O
by	O
the	O
same	O
reasoning	O
it	O
cannot	O
include	O
by	O
analogous	O
reasoning	O
it	O
also	O
can	O
neither	O
include	O
the	O
term	O
nor	O
the	O
term	O
this	O
suggests	O
the	O
algorithm	B
in	O
algorithm	B
colloquially	O
the	O
learning	O
theory	O
y	O
table	O
data	O
set	O
for	O
learning	O
conjunctions	O
verify	O
that	O
algorithm	B
maintains	O
an	O
invariant	O
that	O
it	O
always	O
errs	O
on	O
the	O
side	O
of	O
classifying	O
examples	B
negative	O
and	O
never	O
errs	O
the	O
other	O
way	O
throw	O
out	O
bad	O
terms	O
algorithm	B
in	O
this	O
algorith	O
you	O
begin	O
with	O
a	O
function	O
that	O
includes	O
all	O
possible	O
terms	O
note	O
that	O
this	O
function	O
will	O
initially	O
classify	O
everything	O
as	O
negative	O
you	O
then	O
process	O
each	O
example	O
in	O
sequence	O
on	O
a	O
negative	O
example	O
you	O
do	O
nothing	O
on	O
a	O
positive	O
example	O
you	O
throw	O
out	O
terms	O
from	O
f	O
that	O
contradict	O
the	O
given	O
positive	O
example	O
if	O
you	O
run	O
this	O
algorithm	B
on	O
the	O
data	O
in	O
table	O
the	O
sequence	O
of	O
f	O
s	O
that	O
you	O
cycle	O
through	O
are	O
f	O
f	O
f	O
f	O
the	O
first	O
thing	O
to	O
notice	O
about	O
this	O
algorithm	B
is	O
that	O
after	O
processing	O
an	O
example	O
it	O
is	O
guaranteed	O
to	O
classify	O
that	O
example	O
correctly	O
this	O
observation	O
requires	O
that	O
there	O
is	O
no	O
noise	B
in	O
the	O
data	O
the	O
second	O
thing	O
to	O
notice	O
is	O
that	O
it	O
s	O
very	O
computationally	O
efficient	O
given	O
a	O
data	O
set	O
of	O
n	O
examples	B
in	O
d	O
dimensions	O
it	O
takes	O
ond	O
time	O
to	O
process	O
the	O
data	O
this	O
is	O
linear	O
in	O
the	O
size	O
of	O
the	O
data	O
set	O
however	O
in	O
order	O
to	O
be	O
an	O
efficient	O
learning	O
algorithm	B
you	O
need	O
to	O
be	O
able	O
to	O
get	O
a	O
bound	O
on	O
the	O
sample	B
complexity	B
of	O
this	O
algorithm	B
sure	O
you	O
know	O
that	O
its	O
run	O
time	O
is	O
linear	O
in	O
the	O
number	O
of	O
example	O
n	O
but	O
how	O
many	O
examples	B
n	O
do	O
you	O
need	O
to	O
see	O
in	O
order	O
to	O
guarantee	O
that	O
it	O
achieves	O
an	O
error	B
rate	I
of	O
at	O
most	O
all	O
but	O
many	O
cases	O
perhaps	O
n	O
has	O
to	O
be	O
gigantic	O
to	O
guarantee	O
a	O
small	O
error	O
the	O
goal	O
is	O
to	O
prove	O
that	O
the	O
number	O
of	O
samples	O
n	O
required	O
to	O
achieve	O
a	O
small	O
error	O
is	O
not-too-big	O
the	O
general	O
proof	O
technique	O
for	O
this	O
has	O
essentially	O
the	O
same	O
flavor	O
as	O
almost	O
every	O
pac	B
learning	O
proof	O
around	O
first	O
you	O
define	O
a	O
bad	O
thing	O
in	O
this	O
case	O
a	O
bad	O
thing	O
is	O
that	O
there	O
is	O
some	O
term	O
that	O
should	O
have	O
been	O
thrown	O
out	O
but	O
wasn	O
t	O
then	O
you	O
say	O
well	O
bad	O
things	O
happen	O
then	O
you	O
notice	O
that	O
if	O
this	O
bad	O
thing	O
happened	O
you	O
must	O
not	O
have	O
a	O
course	O
in	O
machine	O
learning	O
algorithm	B
binaryconjunctiontraind	O
f	O
xd	O
xd	O
for	O
all	O
positive	O
examples	B
in	O
d	O
do	O
for	O
d	O
d	O
do	O
if	O
xd	O
then	O
else	O
f	O
f	O
without	O
term	O
xd	O
f	O
f	O
without	O
term	O
xd	O
end	O
if	O
end	O
for	O
end	O
for	O
return	O
f	O
initialize	O
function	O
seen	O
any	O
positive	O
training	O
examples	B
with	O
so	O
example	O
with	O
must	O
have	O
low	O
probability	O
you	O
would	O
have	O
seen	O
them	O
so	O
bad	O
things	O
must	O
not	O
be	O
that	O
common	O
theorem	O
with	O
probability	O
at	O
least	O
algorithm	B
requires	O
at	O
most	O
n	O
examples	B
to	O
achieve	O
an	O
error	B
rate	I
proof	O
of	O
theorem	O
let	O
c	O
be	O
the	O
concept	B
you	O
are	O
trying	O
to	O
learn	O
and	O
let	O
d	O
be	O
the	O
distribution	O
that	O
generates	O
the	O
data	O
a	O
learned	O
function	O
f	O
can	O
make	O
a	O
mistake	O
if	O
it	O
contains	O
any	O
term	O
t	O
that	O
is	O
not	O
in	O
c	O
there	O
are	O
initially	O
many	O
terms	O
in	O
f	O
and	O
any	O
all	O
of	O
them	O
might	O
not	O
be	O
in	O
c	O
we	O
want	O
to	O
ensure	O
that	O
the	O
probability	O
that	O
f	O
makes	O
an	O
error	O
is	O
at	O
most	O
it	O
is	O
sufficient	O
to	O
ensure	O
that	O
for	O
a	O
term	O
t	O
we	O
say	O
that	O
t	O
negates	O
an	O
example	O
x	O
if	O
tx	O
call	O
a	O
term	O
t	O
bad	O
if	O
it	O
does	O
not	O
appear	O
in	O
c	O
and	O
has	O
probability	O
at	O
least	O
of	O
appearing	O
respect	O
to	O
the	O
unknown	O
distribution	O
d	O
over	O
data	O
points	O
first	O
we	O
show	O
that	O
if	O
we	O
have	O
no	O
bad	O
terms	O
left	O
in	O
f	O
then	O
f	O
has	O
an	O
error	B
rate	I
at	O
most	O
we	O
know	O
that	O
f	O
contains	O
at	O
most	O
terms	O
since	O
is	O
begins	O
with	O
terms	O
and	O
throws	O
them	O
out	O
the	O
algorithm	B
begins	O
with	O
terms	O
for	O
each	O
variable	O
and	O
one	O
for	O
each	O
negated	O
variable	O
note	O
that	O
f	O
will	O
only	O
make	O
one	O
type	O
of	O
error	O
it	O
can	O
call	O
positive	O
examples	B
negative	O
but	O
can	O
never	O
call	O
a	O
negative	O
example	O
positive	O
let	O
c	O
be	O
the	O
true	O
concept	B
boolean	O
formula	O
and	O
call	O
a	O
term	O
bad	O
if	O
it	O
does	O
not	O
appear	O
in	O
c	O
a	O
specific	O
bad	O
term	O
will	O
cause	O
f	O
to	O
err	O
only	O
on	O
positive	O
examples	B
that	O
contain	O
a	O
corresponding	O
bad	O
value	O
todo	O
finish	O
this	O
what	O
we	O
ve	O
shown	O
in	O
this	O
theorem	O
is	O
that	O
if	O
the	O
true	O
underly	O
ing	O
concept	B
is	O
a	O
boolean	O
conjunction	O
and	O
there	O
is	O
no	O
noise	B
then	O
the	O
throw	O
out	O
bad	O
terms	O
algorithm	B
needs	O
n	O
examples	B
in	O
order	O
learning	O
theory	O
to	O
learn	O
a	O
boolean	O
conjunction	O
that	O
is	O
to	O
achieve	O
an	O
error	O
of	O
at	O
most	O
that	O
is	O
to	O
say	O
that	O
the	O
sample	B
complexity	B
of	O
throw	O
out	O
bad	O
terms	O
is	O
moreover	O
since	O
the	O
algorithm	B
s	O
runtime	O
is	O
linear	O
in	O
n	O
it	O
is	O
an	O
efficient	O
pac	B
learning	O
algorithm	B
occam	O
s	O
razor	O
simple	O
solutions	O
generalize	B
the	O
previous	O
example	O
of	O
boolean	O
conjunctions	O
is	O
mostly	O
just	O
a	O
warmup	O
exercise	O
to	O
understand	O
pac-style	O
proofs	O
in	O
a	O
concrete	O
setting	O
in	O
this	O
section	O
you	O
get	O
to	O
generalize	B
the	O
above	O
argument	O
to	O
a	O
much	O
larger	O
range	O
of	O
learning	O
problems	O
we	O
will	O
still	O
assume	O
that	O
there	O
is	O
no	O
noise	B
because	O
it	O
makes	O
the	O
analysis	O
much	O
simpler	O
t	O
worry	O
noise	B
will	O
be	O
added	O
eventually	O
william	O
of	O
occam	O
c	O
was	O
an	O
english	O
friar	O
and	O
philosopher	O
is	O
is	O
most	O
famous	O
for	O
what	O
later	O
became	O
known	O
as	O
occam	O
s	O
razor	O
and	O
popularized	O
by	O
bertrand	O
russell	O
the	O
principle	O
basically	O
states	O
that	O
you	O
should	O
only	O
assume	O
as	O
much	O
as	O
you	O
need	O
or	O
more	O
verbosely	O
if	O
one	O
can	O
explain	O
a	O
phenomenon	O
without	O
assuming	O
this	O
or	O
that	O
hypothetical	O
entity	O
then	O
there	O
is	O
no	O
ground	O
for	O
assuming	O
it	O
i	O
e	O
that	O
one	O
should	O
always	O
opt	O
for	O
an	O
explanation	O
in	O
terms	O
of	O
the	O
fewest	O
possible	O
number	O
of	O
causes	O
factors	O
or	O
variables	O
what	O
occam	O
actually	O
wrote	O
is	O
the	O
quote	O
that	O
began	O
this	O
chapter	O
in	O
a	O
machine	O
learning	O
context	O
a	O
reasonable	O
paraphrase	O
is	O
simple	O
solutions	O
generalize	B
well	O
in	O
other	O
words	O
you	O
have	O
features	B
you	O
could	O
be	O
looking	O
at	O
if	O
you	O
re	O
able	O
to	O
explain	O
your	O
predictions	O
using	O
just	O
of	O
them	O
or	O
using	O
all	O
of	O
them	O
then	O
you	O
should	O
just	O
use	O
the	O
the	O
occam	O
s	O
razor	O
theorem	O
states	O
that	O
this	O
is	O
a	O
good	O
idea	O
theoretically	O
it	O
essentially	O
states	O
that	O
if	O
you	O
are	O
learning	O
some	O
unknown	O
concept	B
and	O
if	O
you	O
are	O
able	O
to	O
fit	O
your	O
training	B
data	I
perfectly	O
but	O
you	O
don	O
t	O
need	O
to	O
resort	O
to	O
a	O
huge	O
class	O
of	O
possible	O
functions	O
to	O
do	O
so	O
then	O
your	O
learned	O
function	O
will	O
generalize	B
well	O
it	O
s	O
an	O
amazing	O
theorem	O
due	O
partly	O
to	O
the	O
simplicity	O
of	O
its	O
proof	O
in	O
some	O
ways	O
the	O
proof	O
is	O
actually	O
easier	O
than	O
the	O
proof	O
of	O
the	O
boolean	O
conjunctions	O
though	O
it	O
follows	O
the	O
same	O
basic	O
argument	O
in	O
order	O
to	O
state	O
the	O
theorem	O
explicitly	O
you	O
need	O
to	O
be	O
able	O
to	O
think	O
about	O
a	O
hypothesis	B
class	I
this	O
is	O
the	O
set	O
of	O
possible	O
hypotheses	O
that	O
your	O
algorithm	B
searches	O
through	O
to	O
find	O
the	O
best	O
one	O
in	O
the	O
case	O
of	O
the	O
boolean	O
conjunctions	O
example	O
the	O
hypothesis	B
class	I
h	O
is	O
the	O
set	O
of	O
all	O
boolean	O
formulae	O
over	O
d-many	O
variables	O
in	O
the	O
case	O
of	O
a	O
perceptron	B
your	O
hypothesis	B
class	I
is	O
the	O
set	O
of	O
all	O
possible	O
linear	B
classifiers	I
the	O
hypothesis	B
class	I
for	O
boolean	O
conjunctions	O
is	O
finite	O
the	O
hypothesis	B
class	I
for	O
linear	B
classifiers	I
is	O
infinite	O
for	O
occam	O
s	O
razor	O
we	O
can	O
only	O
work	O
with	O
finite	O
hypothesis	B
classes	O
a	O
course	O
in	O
machine	O
learning	O
theorem	O
s	O
bound	O
suppose	O
a	O
is	O
an	O
algorithm	B
that	O
learns	O
a	O
function	O
f	O
from	O
some	O
finite	O
hypothesis	B
class	I
h	O
suppose	O
the	O
learned	O
function	O
always	O
gets	O
zero	O
error	O
on	O
the	O
training	B
data	I
then	O
the	O
sample	B
complexity	B
of	O
f	O
is	O
at	O
most	O
logh	O
todo	O
comments	O
proof	O
of	O
theorem	O
todo	O
this	O
theorem	O
applies	O
directly	O
to	O
the	O
throw	O
out	O
bad	O
terms	O
algorithm	B
since	O
the	O
hypothesis	B
class	I
is	O
finite	O
and	O
the	O
learned	O
function	O
always	O
achieves	O
zero	O
error	O
on	O
the	O
training	B
data	I
to	O
apply	O
occam	O
s	O
bound	O
you	O
need	O
only	O
compute	O
the	O
size	O
of	O
the	O
hypothesis	B
class	I
h	O
of	O
boolean	O
conjunctions	O
you	O
can	O
compute	O
this	O
by	O
noticing	O
that	O
there	O
are	O
a	O
total	O
of	O
possible	O
terms	O
in	O
any	O
formula	O
in	O
h	O
moreover	O
each	O
term	O
may	O
or	O
may	O
not	O
be	O
in	O
a	O
formula	O
so	O
there	O
are	O
possible	O
formulae	O
thus	O
applying	O
occam	O
s	O
bound	O
we	O
see	O
that	O
the	O
sample	B
complexity	B
of	O
this	O
algorithm	B
is	O
n	O
of	O
course	O
occam	O
s	O
bound	O
is	O
general	O
enough	O
to	O
capture	O
other	O
learning	O
algorithms	O
as	O
well	O
in	O
particular	O
it	O
can	O
capture	O
decision	B
trees	I
in	O
the	O
no-noise	O
setting	O
a	O
decision	B
tree	I
will	O
always	O
fit	O
the	O
training	B
data	I
perfectly	O
the	O
only	O
remaining	O
difficulty	O
is	O
to	O
compute	O
the	O
size	O
of	O
the	O
hypothesis	B
class	I
of	O
a	O
decision	B
tree	I
learner	O
for	O
simplicity	O
s	O
sake	O
suppose	O
that	O
our	O
decision	B
tree	I
algorithm	B
always	O
learns	O
complete	O
trees	O
i	O
e	O
every	O
branch	O
from	O
root	O
to	O
leaf	O
is	O
length	O
d	O
so	O
the	O
number	O
of	O
split	O
points	O
in	O
the	O
tree	O
places	O
where	O
a	O
feature	O
is	O
queried	O
is	O
figure	O
each	O
split	O
point	O
needs	O
to	O
be	O
assigned	O
a	O
feature	O
there	O
d-many	O
choices	O
here	O
this	O
gives	O
trees	O
the	O
last	O
thing	O
is	O
that	O
there	O
are	O
leaves	O
of	O
the	O
tree	O
each	O
of	O
which	O
can	O
take	O
two	O
possible	O
values	O
depending	O
on	O
whether	O
this	O
leaf	O
is	O
classified	O
as	O
or	O
this	O
is	O
possibilities	O
putting	O
this	O
all	O
togeter	O
gives	O
a	O
total	O
number	O
of	O
trees	O
applying	O
occam	O
s	O
bound	O
we	O
see	O
that	O
todo	O
examples	B
is	O
enough	O
to	O
learn	O
a	O
decision	B
tree	I
complexity	B
of	O
infinite	O
hypothesis	B
spaces	O
occam	O
s	O
bound	O
is	O
a	O
fantastic	O
result	O
for	O
learning	O
over	O
finite	O
hypothesis	B
spaces	O
unfortunately	O
it	O
is	O
completely	O
useless	O
when	O
this	O
is	O
because	O
the	O
proof	O
works	O
by	O
using	O
each	O
of	O
the	O
n	O
training	O
examples	B
to	O
throw	O
out	O
bad	O
hypotheses	O
until	O
only	O
a	O
small	O
number	O
are	O
left	O
but	O
if	O
and	O
you	O
re	O
throwing	O
out	O
a	O
finite	O
number	O
at	O
each	O
step	O
there	O
will	O
always	O
be	O
an	O
infinite	O
number	O
remaining	O
this	O
means	O
that	O
if	O
you	O
want	O
to	O
establish	O
sample	B
complexity	B
results	O
for	O
infinite	O
hypothesis	B
spaces	O
you	O
need	O
some	O
new	O
way	O
of	O
measuring	O
figure	O
thydt	O
picture	O
of	O
full	O
decision	B
tree	I
learning	O
theory	O
figure	O
thyvcex	O
figure	O
with	O
three	O
and	O
four	O
examples	B
yes	O
this	O
is	O
the	O
same	O
vapnik	O
who	O
is	O
credited	O
with	O
the	O
creation	O
of	O
the	O
support	B
vector	B
machine	I
what	O
is	O
that	O
labeling	O
what	O
is	O
it	O
s	O
name	O
their	O
size	O
or	O
complexity	B
a	O
prototypical	O
way	O
of	O
doing	O
this	O
is	O
to	O
measure	O
the	O
complexity	B
of	O
a	O
hypothesis	B
class	I
as	O
the	O
number	O
of	O
different	O
things	O
it	O
can	O
do	O
as	O
a	O
silly	O
example	O
consider	O
boolean	O
conjunctions	O
again	O
your	O
input	O
is	O
a	O
vector	B
of	O
binary	B
features	B
however	O
instead	O
of	O
representing	O
your	O
hypothesis	B
as	O
a	O
boolean	O
conjunction	O
you	O
choose	O
to	O
represent	O
it	O
as	O
a	O
conjunction	O
of	O
inequalities	O
that	O
is	O
instead	O
of	O
writing	O
you	O
write	O
in	O
this	O
representation	O
for	O
each	O
feature	O
you	O
need	O
to	O
choose	O
an	O
inequality	O
or	O
and	O
a	O
threshold	B
since	O
the	O
thresholds	O
can	O
be	O
arbitrary	O
real	O
values	O
there	O
are	O
now	O
infinitely	O
many	O
possibilities	O
however	O
you	O
can	O
immediately	O
recognize	O
that	O
on	O
binary	B
features	B
there	O
really	O
is	O
no	O
difference	O
between	O
and	O
and	O
any	O
other	O
number	O
of	O
infinitely	O
many	O
possibilities	O
in	O
other	O
words	O
even	O
though	O
there	O
are	O
infinitely	O
many	O
hypotheses	O
there	O
are	O
only	O
finitely	O
many	O
behaviors	O
the	O
vapnik-chernovenkis	B
dimension	I
vc	B
dimension	I
is	O
a	O
classic	O
measure	O
of	O
complexity	B
of	O
infinite	O
hypothesis	B
classes	O
based	O
on	O
this	O
the	O
vc	B
dimension	I
is	O
a	O
very	O
classification-oriented	O
notion	O
of	O
complexity	B
the	O
idea	O
is	O
to	O
look	O
at	O
a	O
finite	O
set	O
of	O
unlabeled	O
examples	B
such	O
as	O
those	O
in	O
figure	O
the	O
question	O
is	O
no	O
matter	O
how	O
these	O
points	O
were	O
labeled	O
would	O
we	O
be	O
able	O
to	O
find	O
a	O
hypothesis	B
that	O
correctly	O
classifies	O
them	O
the	O
idea	O
is	O
that	O
as	O
you	O
add	O
more	O
points	O
being	O
able	O
to	O
represent	O
an	O
arbitrary	O
labeling	O
becomes	O
harder	O
and	O
harder	O
for	O
instance	O
regardless	O
of	O
how	O
the	O
three	O
points	O
are	O
labeled	O
you	O
can	O
find	O
a	O
linear	B
classifier	I
that	O
agrees	O
with	O
that	O
classification	O
however	O
for	O
the	O
four	O
points	O
there	O
exists	O
a	O
labeling	O
for	O
which	O
you	O
cannot	O
find	O
a	O
perfect	O
classifier	O
the	O
vc	B
dimension	I
is	O
the	O
maximum	O
number	O
of	O
points	O
for	O
which	O
you	O
can	O
always	O
find	O
such	O
a	O
classifier	O
you	O
can	O
think	O
of	O
vc	B
dimension	I
as	O
a	O
game	O
between	O
you	O
and	O
an	O
adversary	O
to	O
play	O
this	O
game	O
you	O
choose	O
k	O
unlabeled	O
points	O
however	O
you	O
want	O
then	O
your	O
adversary	O
looks	O
at	O
those	O
k	O
points	O
and	O
assigns	O
binary	O
labels	O
to	O
them	O
them	O
however	O
he	O
wants	O
you	O
must	O
then	O
find	O
a	O
hypothesis	B
that	O
agrees	O
with	O
his	O
labeling	O
you	O
win	O
if	O
you	O
can	O
find	O
such	O
a	O
hypothesis	B
he	O
wins	O
if	O
you	O
cannot	O
the	O
vc	B
dimension	I
of	O
your	O
hypothesis	B
class	I
is	O
the	O
maximum	O
number	O
of	O
points	O
k	O
so	O
that	O
you	O
can	O
always	O
win	O
this	O
game	O
this	O
leads	O
to	O
the	O
following	O
formal	O
definition	O
where	O
you	O
can	O
interpret	O
there	O
exists	O
as	O
your	O
move	O
and	O
for	O
all	O
as	O
adversary	O
s	O
move	O
definitions	O
for	O
data	O
drawn	O
from	O
some	O
space	O
x	O
the	O
vc	B
dimension	I
of	O
a	O
hypothesis	B
space	O
h	O
over	O
x	O
is	O
the	O
maximal	O
k	O
such	O
that	O
there	O
exists	O
a	O
set	O
x	O
x	O
of	O
size	O
k	O
such	O
that	O
for	O
all	O
binary	O
labelings	O
of	O
x	O
there	O
exists	O
a	O
function	O
f	O
h	O
that	O
matches	O
this	O
labeling	O
a	O
course	O
in	O
machine	O
learning	O
in	O
general	O
it	O
is	O
much	O
easier	O
to	O
show	O
that	O
the	O
vc	B
dimension	I
is	O
at	O
least	O
some	O
value	O
it	O
is	O
much	O
harder	O
to	O
show	O
that	O
it	O
is	O
at	O
most	O
some	O
value	O
for	O
example	O
following	O
on	O
the	O
example	O
from	O
figure	O
the	O
image	O
of	O
three	O
points	O
a	O
little	O
argumentation	O
is	O
enough	O
to	O
show	O
that	O
the	O
vc	B
dimension	I
of	O
linear	B
classifiers	I
in	O
two	O
dimension	O
is	O
at	O
least	O
three	O
to	O
show	O
that	O
the	O
vc	B
dimension	I
is	O
exactly	O
three	O
it	O
suffices	O
to	O
show	O
that	O
you	O
cannot	O
find	O
a	O
set	O
of	O
four	O
points	O
such	O
that	O
you	O
win	O
this	O
game	O
against	O
the	O
adversary	O
this	O
is	O
much	O
more	O
difficult	O
in	O
the	O
proof	O
that	O
the	O
vc	B
dimension	I
is	O
at	O
least	O
three	O
you	O
simply	O
need	O
to	O
provide	O
an	O
example	O
of	O
three	O
points	O
and	O
then	O
work	O
through	O
the	O
small	O
number	O
of	O
possible	O
labelings	O
of	O
that	O
data	O
to	O
show	O
that	O
it	O
is	O
at	O
most	O
three	O
you	O
need	O
to	O
argue	O
that	O
no	O
matter	O
what	O
set	O
of	O
four	O
point	O
you	O
pick	O
you	O
cannot	O
win	O
the	O
game	O
vc	O
margins	O
small	O
norms	O
learning	O
with	O
noise	B
agnostic	O
learning	O
error	O
versus	O
regret	O
despite	O
the	O
fact	O
that	O
there	O
s	O
no	O
way	O
to	O
get	O
better	O
than	O
error	O
on	O
this	O
distribution	O
it	O
would	O
be	O
nice	O
to	O
say	O
that	O
you	O
can	O
still	O
learn	O
something	O
from	O
it	O
for	O
instance	O
the	O
predictor	O
that	O
always	O
guesses	O
y	O
x	O
seems	O
like	O
the	O
right	O
thing	O
to	O
do	O
based	O
on	O
this	O
observation	O
maybe	O
we	O
can	O
rephrase	O
the	O
goal	O
of	O
learning	O
as	O
to	O
find	O
a	O
function	O
that	O
does	O
as	O
well	O
as	O
the	O
distribution	O
allows	O
in	O
other	O
words	O
on	O
this	O
data	O
you	O
would	O
hope	O
to	O
get	O
error	O
on	O
some	O
other	O
distribution	O
you	O
would	O
hope	O
to	O
get	O
x	O
error	O
where	O
x	O
is	O
the	O
best	O
you	O
could	O
do	O
this	O
notion	O
of	O
best	O
you	O
could	O
do	O
is	O
sufficiently	O
important	O
that	O
it	O
has	O
a	O
name	O
the	O
bayes	B
error	B
rate	I
this	O
is	O
the	O
error	B
rate	I
of	O
the	O
best	O
possible	O
classifier	O
the	O
so-called	O
bayes	B
optimal	I
classifier	I
if	O
you	O
knew	O
the	O
underlying	O
distribution	O
d	O
you	O
could	O
actually	O
write	O
down	O
the	O
exact	O
bayes	B
optimal	I
classifier	I
explicitly	O
is	O
why	O
learning	O
is	O
uninteresting	O
in	O
the	O
case	O
that	O
you	O
know	O
d	O
it	O
simply	O
has	O
the	O
form	O
f	O
bayesx	O
if	O
dx	O
dx	O
otherwise	O
the	O
bayes	B
optimal	I
error	B
rate	I
is	O
the	O
error	B
rate	I
that	O
this	O
classifier	O
achieves	O
f	O
e	O
exercises	O
exercise	O
todo	O
learning	O
theory	O
ensemble	B
methods	O
learning	O
objectives	O
implement	O
bagging	B
and	O
explain	O
how	O
it	O
reduces	O
variance	B
in	O
a	O
predictor	O
explain	O
the	O
difference	O
between	O
a	O
weak	B
learner	I
and	O
a	O
strong	B
learner	I
derive	O
the	O
adaboost	B
algorithm	B
understand	O
the	O
relationship	O
between	O
boosting	B
decision	O
stumps	O
and	O
linear	O
classification	O
dependencies	O
groups	O
of	O
people	O
can	O
often	O
make	O
better	O
decisions	O
than	O
individuals	O
especially	O
when	O
group	O
members	O
each	O
come	O
in	O
with	O
their	O
own	O
biases	O
the	O
same	O
is	O
true	O
in	O
machine	O
learning	O
ensemble	B
methods	O
are	O
learning	O
models	O
that	O
achieve	O
performance	O
by	O
combining	O
the	O
opinions	O
of	O
multiple	O
learners	O
in	O
doing	O
so	O
you	O
can	O
often	O
get	O
away	O
with	O
using	O
much	O
simpler	O
learners	O
and	O
still	O
achieve	O
great	O
performance	O
moreover	O
ensembles	O
are	O
inherantly	O
parallel	O
which	O
can	O
make	O
them	O
much	O
more	O
efficient	O
at	O
training	O
and	O
test	O
time	O
if	O
you	O
have	O
access	O
to	O
multiple	O
processors	O
in	O
this	O
chapter	O
you	O
will	O
learn	O
about	O
various	O
ways	O
of	O
combining	O
base	O
learners	O
into	O
ensembles	O
one	O
of	O
the	O
shocking	O
results	O
we	O
will	O
see	O
is	O
that	O
you	O
can	O
take	O
a	O
learning	O
model	B
that	O
only	O
ever	O
does	O
slightly	O
better	O
than	O
chance	O
and	O
turn	O
it	O
into	O
an	O
arbitrarily	O
good	O
learning	O
model	B
though	O
a	O
technique	O
known	O
as	O
boosting	B
you	O
will	O
also	O
learn	O
how	O
ensembles	O
can	O
decrease	O
the	O
variance	B
of	O
predictors	O
as	O
well	O
as	O
perform	O
regularization	O
voting	B
multiple	O
classifiers	O
all	O
of	O
the	O
learning	O
algorithms	O
you	O
have	O
seen	O
so	O
far	O
are	O
deterministic	O
if	O
you	O
train	O
a	O
decision	B
tree	I
multiple	O
times	O
on	O
the	O
same	O
data	O
set	O
you	O
will	O
always	O
get	O
the	O
same	O
tree	O
back	O
in	O
order	O
to	O
get	O
an	O
effect	O
out	O
of	O
voting	B
multiple	O
classifiers	O
they	O
need	O
to	O
differ	O
there	O
are	O
two	O
primary	O
ways	O
to	O
get	O
variability	O
you	O
can	O
either	O
change	O
the	O
learning	O
algorithm	B
or	O
change	O
the	O
data	O
set	O
building	O
an	O
emsemble	O
by	O
training	O
different	O
classifiers	O
is	O
the	O
most	O
straightforward	O
approach	O
as	O
in	O
single-model	O
learning	O
you	O
are	O
given	O
a	O
data	O
set	O
for	O
classification	O
instead	O
of	O
learning	O
a	O
single	O
classifier	O
a	O
decision	B
tree	I
on	O
this	O
data	O
set	O
you	O
learn	O
multiple	O
different	O
classifiers	O
for	O
instance	O
you	O
might	O
train	O
a	O
decision	B
tree	I
a	O
perceptron	B
a	O
knn	O
and	O
multiple	O
neural	B
networks	I
with	O
different	O
architectures	O
call	O
these	O
classifiers	O
fm	O
at	O
test	O
time	O
you	O
can	O
make	O
a	O
prediction	O
by	O
voting	B
on	O
a	O
test	O
example	O
x	O
you	O
compute	O
x	O
ensemble	B
methods	O
which	O
of	O
the	O
classifiers	O
you	O
ve	O
learned	O
about	O
so	O
far	O
have	O
high	O
variance	B
figure	O
picture	O
of	O
sampling	O
with	O
replacement	O
to	O
sample	O
with	O
replacement	O
imagine	O
putting	O
all	O
items	O
from	O
d	O
in	O
a	O
hat	O
to	O
draw	O
a	O
single	O
sample	O
pick	O
an	O
element	O
at	O
random	O
from	O
that	O
hat	O
write	O
it	O
down	O
and	O
then	O
put	O
it	O
back	O
ym	O
fm	O
x	O
if	O
there	O
are	O
more	O
in	O
the	O
list	O
ym	O
then	O
you	O
predict	B
otherwise	O
you	O
predict	B
the	O
main	O
advantage	O
of	O
ensembles	O
of	O
different	O
classifiers	O
is	O
that	O
it	O
is	O
unlikely	O
that	O
all	O
classifiers	O
will	O
make	O
the	O
same	O
mistake	O
in	O
fact	O
as	O
long	O
as	O
every	O
error	O
is	O
made	O
by	O
a	O
minority	O
of	O
the	O
classifiers	O
you	O
will	O
achieve	O
optimal	O
classification	O
unfortunately	O
the	O
inductive	O
biases	O
of	O
different	O
learning	O
algorithms	O
are	O
highly	O
correlated	O
this	O
means	O
that	O
different	O
algorithms	O
are	O
prone	O
to	O
similar	O
types	O
of	O
errors	O
in	O
particular	O
ensembles	O
tend	O
to	O
reduce	O
the	O
variance	B
of	O
classifiers	O
so	O
if	O
you	O
have	O
a	O
classification	O
algorithm	B
that	O
tends	O
to	O
be	O
very	O
sensitive	O
to	O
small	O
changes	O
in	O
the	O
training	B
data	I
ensembles	O
are	O
likely	O
to	O
be	O
useful	O
note	O
that	O
the	O
voting	B
scheme	O
naturally	O
extends	O
to	O
multiclass	O
classification	O
however	O
it	O
does	O
not	O
make	O
sense	O
in	O
the	O
contexts	O
of	O
regression	O
ranking	O
or	O
collective	B
classification	I
this	O
is	O
because	O
you	O
will	O
rarely	O
see	O
the	O
same	O
exact	O
output	O
predicted	O
twice	O
by	O
two	O
different	O
regression	O
models	O
ranking	O
models	O
or	O
collective	B
classification	I
models	O
for	O
regression	O
a	O
simple	O
solution	O
is	O
to	O
take	O
the	O
mean	O
or	O
median	O
prediction	O
from	O
the	O
different	O
models	O
for	O
ranking	O
and	O
collective	B
classification	I
different	O
approaches	O
are	O
required	O
instead	O
of	O
training	O
different	O
types	O
of	O
classifiers	O
on	O
the	O
same	O
data	O
set	O
you	O
can	O
train	O
a	O
single	O
type	O
of	O
classifier	O
decision	B
tree	I
on	O
multiple	O
data	O
sets	O
the	O
question	O
is	O
where	O
do	O
these	O
multiple	O
data	O
sets	O
come	O
from	O
since	O
you	O
re	O
only	O
given	O
one	O
at	O
training	O
time	O
one	O
option	O
is	O
to	O
fragment	O
your	O
original	O
data	O
set	O
for	O
instance	O
you	O
could	O
break	O
it	O
into	O
pieces	O
and	O
build	O
decision	B
trees	I
on	O
each	O
of	O
these	O
pieces	O
individually	O
unfortunately	O
this	O
means	O
that	O
each	O
decision	B
tree	I
is	O
trained	O
on	O
only	O
a	O
very	O
small	O
part	O
of	O
the	O
entire	O
data	O
set	O
and	O
is	O
likely	O
to	O
perform	O
poorly	O
a	O
better	O
solution	O
is	O
to	O
use	O
bootstrap	B
resampling	I
this	O
is	O
a	O
technique	O
from	O
the	O
statistics	O
literature	O
based	O
on	O
the	O
following	O
observation	O
the	O
data	O
set	O
we	O
are	O
given	O
d	O
is	O
a	O
sample	O
drawn	O
i	O
i	O
d	O
from	O
an	O
unknown	O
distribution	O
d	O
if	O
we	O
draw	O
a	O
new	O
data	O
set	O
d	O
by	O
random	O
sampling	O
from	O
d	O
with	O
then	O
d	O
is	O
also	O
a	O
sample	O
from	O
d	O
figure	O
shows	O
the	O
process	O
of	O
bootstrap	B
resampling	I
of	O
ten	O
objects	O
applying	O
this	O
idea	O
to	O
ensemble	B
methods	O
yields	O
a	O
technique	O
known	O
as	O
bagging	B
you	O
start	O
with	O
a	O
single	O
data	O
set	O
d	O
that	O
contains	O
n	O
training	O
examples	B
from	O
this	O
single	O
data	O
set	O
you	O
create	O
m-many	O
bootstrapped	O
training	O
sets	O
dm	O
each	O
of	O
these	O
bootstrapped	O
sets	O
also	O
contains	O
n	O
training	O
examples	B
drawn	O
randomly	O
from	O
d	O
with	O
replacement	O
you	O
can	O
then	O
train	O
a	O
decision	B
tree	I
other	O
model	B
seperately	O
on	O
each	O
of	O
these	O
data	O
sets	O
to	O
obtain	O
classifiers	O
fm	O
as	O
before	O
you	O
can	O
use	O
these	O
classifiers	O
to	O
vote	B
on	O
new	O
test	O
points	O
note	O
that	O
the	O
bootstrapped	O
data	O
sets	O
will	O
be	O
similar	O
however	O
they	O
will	O
not	O
be	O
too	O
similar	O
for	O
example	O
if	O
n	O
is	O
large	O
then	O
the	O
number	O
of	O
figure	O
graph	B
depicting	O
overfitting	B
using	O
regularization	O
versus	O
bagging	B
a	O
course	O
in	O
machine	O
learning	O
examples	B
that	O
are	O
not	O
present	O
in	O
any	O
particular	O
bootstrapped	O
sample	O
is	O
relatively	O
large	O
the	O
probability	O
that	O
the	O
first	O
training	O
example	O
is	O
not	O
selected	O
once	O
is	O
the	O
probability	O
that	O
it	O
is	O
not	O
selected	O
at	O
all	O
is	O
as	O
n	O
this	O
tends	O
to	O
for	O
n	O
this	O
is	O
correct	O
to	O
four	O
decimal	O
points	O
so	O
only	O
about	O
of	O
the	O
original	O
training	O
examples	B
will	O
be	O
represented	O
in	O
any	O
given	O
bootstrapped	O
set	O
since	O
bagging	B
tends	O
to	O
reduce	O
variance	B
it	O
provides	O
an	O
alternative	O
approach	O
to	O
regularization	O
that	O
is	O
even	O
if	O
each	O
of	O
the	O
learned	O
classifiers	O
fm	O
are	O
individually	O
overfit	O
they	O
are	O
likely	O
to	O
be	O
overfit	O
to	O
different	O
things	O
through	O
voting	B
you	O
are	O
able	O
to	O
overcome	O
a	O
significant	O
portion	O
of	O
this	O
overfitting	B
figure	O
shows	O
this	O
effect	O
by	O
comparing	O
regularization	O
via	O
hyperparameters	O
to	O
regularization	O
via	O
bagging	B
boosting	B
weak	O
learners	O
boosting	B
is	O
the	O
process	O
of	O
taking	O
a	O
crummy	O
learning	O
algorithm	B
called	O
a	O
weak	B
learner	I
and	O
turning	O
it	O
into	O
a	O
great	O
learning	O
algorithm	B
a	O
strong	B
learner	I
of	O
all	O
the	O
ideas	O
that	O
originated	O
in	O
the	O
theoretical	O
machine	O
learning	O
community	O
boosting	B
has	O
had	O
perhaps	O
the	O
greatest	O
practical	O
impact	O
the	O
idea	O
of	O
boosting	B
is	O
reminiscent	O
of	O
what	O
you	O
me	O
might	O
have	O
thought	O
when	O
you	O
first	O
learned	O
about	O
file	O
compression	O
if	O
i	O
compress	O
a	O
file	O
and	O
then	O
re-compress	O
it	O
and	O
then	O
re-compress	O
it	O
eventually	O
i	O
ll	O
end	O
up	O
with	O
a	O
final	O
that	O
s	O
only	O
one	O
byte	O
in	O
size	O
to	O
be	O
more	O
formal	O
let	O
s	O
define	O
a	O
strong	B
learning	I
algorithm	B
l	O
as	O
follows	O
when	O
given	O
a	O
desired	O
error	B
rate	I
a	O
failure	O
probability	O
and	O
access	O
to	O
enough	O
labeled	O
examples	B
from	O
some	O
distribution	O
d	O
then	O
with	O
high	O
probability	O
least	O
l	O
learns	O
a	O
classifier	O
f	O
that	O
has	O
error	O
at	O
most	O
this	O
is	O
precisely	O
the	O
definition	O
of	O
pac	B
learning	O
that	O
you	O
learned	O
about	O
in	O
chapter	O
building	O
a	O
strong	B
learning	I
algorithm	B
might	O
be	O
difficult	O
we	O
can	O
as	O
if	O
instead	O
it	O
is	O
possible	O
to	O
build	O
a	O
weak	B
learning	I
algorithm	B
w	O
that	O
only	O
has	O
to	O
achieve	O
an	O
error	B
rate	I
of	O
rather	O
than	O
some	O
arbitrary	O
user-defined	O
parameter	O
is	O
arbitrary	O
anything	O
strictly	O
less	O
than	O
would	O
be	O
fine	O
work	O
for	O
taking	O
a	O
weak	B
learning	I
algorithm	B
w	O
and	O
turning	O
it	O
into	O
a	O
strong	B
learning	I
algorithm	B
the	O
particular	O
boosting	B
algorithm	B
discussed	O
here	O
is	O
adaboost	B
short	O
for	O
adaptive	O
boosting	B
algorithm	B
adaboost	B
is	O
famous	O
because	O
it	O
was	O
one	O
of	O
the	O
first	O
practical	O
boosting	B
algorithms	O
it	O
runs	O
in	O
polynomial	O
time	O
and	O
does	O
not	O
require	O
you	O
to	O
define	O
a	O
large	O
number	O
of	O
hyperparameters	O
it	O
gets	O
its	O
name	O
from	O
the	O
latter	O
benefit	O
it	O
automatically	O
adapts	O
to	O
the	O
data	O
that	O
you	O
give	O
it	O
boosting	B
is	O
more	O
of	O
a	O
framework	O
than	O
an	O
algorithm	B
it	O
s	O
a	O
frame	O
ensemble	B
methods	O
what	O
happens	O
if	O
the	O
weak	O
learning	O
assumption	O
is	O
violated	O
and	O
is	O
equal	O
to	O
what	O
if	O
it	O
is	O
worse	O
than	O
what	O
does	O
this	O
mean	O
in	O
practice	O
n	O
algorithm	B
adaboostw	O
d	O
k	O
for	O
k	O
k	O
do	O
n	O
f	O
w	O
yn	O
f	O
n	O
n	O
yn	O
exp	O
yn	O
n	O
n	O
dk	O
n	O
log	O
z	O
n	O
end	O
for	O
return	O
f	O
x	O
k	O
f	O
initialize	O
uniform	O
importance	O
to	O
each	O
example	O
train	O
kth	O
classifier	O
on	O
weighted	O
data	O
make	O
predictions	O
on	O
training	B
data	I
compute	O
weighted	O
training	B
error	I
compute	O
adaptive	O
parameter	O
re-weight	O
examples	B
and	O
normalize	B
return	O
voted	O
classifier	O
the	O
intuition	O
behind	O
adaboost	B
is	O
like	O
studying	O
for	O
an	O
exam	O
by	O
using	O
a	O
past	O
exam	O
you	O
take	O
the	O
past	O
exam	O
and	O
grade	O
yourself	O
the	O
questions	O
that	O
you	O
got	O
right	O
you	O
pay	O
less	O
attention	O
to	O
those	O
that	O
you	O
got	O
wrong	O
you	O
study	O
more	O
then	O
you	O
take	O
the	O
exam	O
again	O
and	O
repeat	O
this	O
process	O
you	O
continually	O
down-weight	O
the	O
importance	O
of	O
questions	O
you	O
routinely	O
answer	O
correctly	O
and	O
up-weight	O
the	O
importance	O
of	O
questions	O
you	O
routinely	O
answer	O
incorrectly	O
after	O
going	O
over	O
the	O
exam	O
multiple	O
times	O
you	O
hope	O
to	O
have	O
mastered	O
everything	O
the	O
precise	O
adaboost	B
training	O
algorithm	B
is	O
shown	O
in	O
algorithm	B
the	O
basic	O
functioning	O
of	O
the	O
algorithm	B
is	O
to	O
maintain	O
a	O
weight	O
distribution	O
d	O
over	O
data	O
points	O
a	O
weak	B
learner	I
f	O
is	O
trained	O
on	O
this	O
weighted	O
data	O
that	O
we	O
implicitly	O
assume	O
that	O
our	O
weak	B
learner	I
can	O
accept	O
weighted	O
training	B
data	I
a	O
relatively	O
mild	O
assumption	O
that	O
is	O
nearly	O
always	O
true	O
the	O
error	B
rate	I
of	O
f	O
is	O
used	O
to	O
determine	O
the	O
adaptive	O
parameter	O
which	O
controls	O
how	O
important	O
f	O
is	O
as	O
long	O
as	O
the	O
weak	B
learner	I
does	O
indeed	O
achieve	O
error	O
then	O
will	O
be	O
greater	O
than	O
zero	O
as	O
the	O
error	O
drops	O
to	O
zero	O
grows	O
without	O
bound	O
after	O
the	O
adaptive	O
parameter	O
is	O
computed	O
the	O
weight	O
distibution	O
is	O
updated	O
for	O
the	O
next	O
iteration	B
as	O
desired	O
examples	B
that	O
are	O
correctly	O
classified	O
which	O
yn	O
yn	O
have	O
their	O
weight	O
decreased	O
multiplicatively	O
examples	B
that	O
are	O
incorrectly	O
classified	O
yn	O
have	O
their	O
weight	O
increased	O
multiplicatively	O
the	O
z	O
term	O
is	O
a	O
nomralization	O
constant	O
to	O
ensure	O
that	O
the	O
sum	O
of	O
d	O
is	O
one	O
d	O
can	O
be	O
interpreted	O
as	O
a	O
distribution	O
the	O
final	O
classifier	O
returned	O
by	O
adaboost	B
is	O
a	O
weighted	O
vote	B
of	O
the	O
individual	O
classifiers	O
with	O
weights	B
given	O
by	O
the	O
adaptive	O
parameters	O
to	O
better	O
understand	O
why	O
is	O
defined	O
as	O
it	O
is	O
suppose	O
that	O
our	O
weak	B
learner	I
simply	O
returns	O
a	O
constant	O
function	O
that	O
returns	O
the	O
majority	O
class	O
so	O
if	O
the	O
total	O
weight	O
of	O
positive	O
examples	B
exceeds	O
that	O
of	O
negative	O
examples	B
f	O
for	O
all	O
x	O
otherwise	O
f	O
for	O
all	O
x	O
to	O
make	O
the	O
problem	O
moderately	O
interesting	O
suppose	O
that	O
in	O
the	O
original	O
training	O
set	O
there	O
are	O
positive	O
ex	O
a	O
course	O
in	O
machine	O
learning	O
log	O
log	O
we	O
can	O
compute	O
z	O
amples	O
and	O
negative	O
examples	B
in	O
this	O
case	O
f	O
it	O
s	O
weighted	O
error	B
rate	I
will	O
be	O
because	O
it	O
gets	O
every	O
negative	O
example	O
wrong	O
computing	O
we	O
get	O
log	O
before	O
normalization	O
we	O
get	O
the	O
new	O
weight	O
for	O
each	O
positive	O
example	O
to	O
be	O
exp	O
the	O
weight	O
for	O
each	O
negative	O
example	O
becomes	O
exp	O
therefore	O
after	O
normalization	O
the	O
weight	O
distribution	O
on	O
any	O
single	O
positive	O
example	O
is	O
and	O
the	O
weight	O
on	O
any	O
negative	O
example	O
is	O
however	O
since	O
there	O
are	O
positive	O
examples	B
and	O
negative	O
examples	B
the	O
cumulative	O
weight	O
on	O
all	O
positive	O
examples	B
is	O
the	O
cumulative	O
weight	O
on	O
all	O
negative	O
examples	B
is	O
thus	O
after	O
a	O
single	O
boosting	B
iteration	B
the	O
data	O
has	O
become	O
precisely	O
evenly	O
weighted	O
this	O
guarantees	O
that	O
in	O
the	O
next	O
iteration	B
our	O
weak	B
learner	I
must	O
do	O
something	O
more	O
interesting	O
than	O
majority	O
voting	B
if	O
it	O
is	O
to	O
achieve	O
an	O
error	B
rate	I
less	O
than	O
as	O
required	O
one	O
of	O
the	O
major	O
attractions	O
of	O
boosting	B
is	O
that	O
it	O
is	O
perhaps	O
easy	O
to	O
design	O
computationally	O
efficient	O
weak	O
learners	O
a	O
very	O
popular	O
type	O
of	O
weak	B
learner	I
is	O
a	O
shallow	B
decision	B
tree	I
a	O
decision	B
tree	I
with	O
a	O
small	O
depth	O
limit	O
figure	O
shows	O
test	B
error	I
rates	O
for	O
decision	B
trees	I
of	O
different	O
maximum	O
depths	O
different	O
curves	O
run	O
for	O
differing	O
numbers	O
of	O
boosting	B
iterations	O
x-axis	O
as	O
you	O
can	O
see	O
if	O
you	O
are	O
willing	O
to	O
boost	O
for	O
many	O
iterations	O
very	O
shallow	O
trees	O
are	O
quite	O
effective	O
in	O
fact	O
a	O
very	O
popular	O
weak	B
learner	I
is	O
a	O
decision	O
decision	B
stump	I
a	O
decision	B
tree	I
that	O
can	O
only	O
ask	O
one	O
question	O
this	O
may	O
seem	O
like	O
a	O
silly	O
model	B
in	O
fact	O
it	O
is	O
on	O
it	O
s	O
own	O
but	O
when	O
combined	O
with	O
boosting	B
it	O
becomes	O
very	O
effective	O
to	O
understand	O
why	O
suppose	O
for	O
a	O
moment	O
that	O
our	O
data	O
consists	O
only	O
of	O
binary	B
features	B
so	O
that	O
any	O
question	O
that	O
a	O
decision	B
tree	I
might	O
ask	O
is	O
of	O
the	O
form	O
is	O
feature	O
on	O
by	O
concentrating	O
on	O
decision	O
stumps	O
all	O
weak	O
functions	O
must	O
have	O
the	O
form	O
f	O
where	O
s	O
and	O
d	O
indexes	O
some	O
feature	O
now	O
consider	O
the	O
final	O
form	O
of	O
a	O
function	O
learned	O
by	O
adaboost	B
this	O
example	O
uses	O
concrete	O
numbers	O
but	O
the	O
same	O
result	O
holds	O
no	O
matter	O
what	O
the	O
data	O
distribution	O
looks	O
like	O
nor	O
how	O
many	O
examples	B
there	O
are	O
write	O
out	O
the	O
general	O
case	O
to	O
see	O
that	O
you	O
will	O
still	O
arrive	O
at	O
an	O
even	O
weighting	O
after	O
one	O
iteration	B
we	O
can	O
expand	O
it	O
as	O
follow	O
where	O
we	O
let	O
fk	O
denote	O
the	O
single	O
feature	O
selected	O
by	O
the	O
kth	O
decision	B
stump	I
and	O
let	O
sk	O
denote	O
its	O
sign	B
f	O
sgn	O
sgn	O
k	O
f	O
fk	O
kskx	O
fk	O
ksk	O
k	O
sgn	O
sgn	O
x	O
b	O
k	O
k	O
k	O
figure	O
perf	O
comparison	O
of	O
depth	O
vs	O
boost	O
why	O
do	O
the	O
functions	O
have	O
this	O
form	O
ensemble	B
methods	O
algorithm	B
randomforesttraind	O
depth	O
k	O
for	O
k	O
k	O
do	O
tk	O
complete	O
binary	O
tree	O
of	O
depth	O
depth	O
with	O
random	O
feature	O
splits	O
f	O
the	O
function	O
computed	O
by	O
tk	O
with	O
leaves	O
filled	O
in	O
by	O
d	O
end	O
for	O
return	O
f	O
x	O
k	O
f	O
return	O
voted	O
classifier	O
where	O
wd	O
k	O
fkd	O
ksk	O
and	O
b	O
k	O
ksk	O
thus	O
when	O
working	O
with	O
decision	O
stumps	O
adaboost	B
actually	O
provides	O
an	O
algorithm	B
for	O
learning	O
linear	B
classifiers	I
in	O
fact	O
this	O
connection	O
has	O
recently	O
been	O
strengthened	O
you	O
can	O
show	O
that	O
adaboost	B
provides	O
an	O
algorithm	B
for	O
optimizing	O
exponential	B
loss	I
this	O
connection	O
is	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
as	O
a	O
further	O
example	O
consider	O
the	O
case	O
of	O
boosting	B
a	O
linear	B
classifier	I
in	O
this	O
case	O
if	O
we	O
let	O
the	O
kth	O
weak	O
classifier	O
be	O
parameterized	O
by	O
wk	O
and	O
bk	O
the	O
overall	O
predictor	O
will	O
have	O
the	O
form	O
wk	O
x	O
f	O
sgn	O
k	O
ksgn	O
you	O
can	O
notice	O
that	O
this	O
is	O
nothing	O
but	O
a	O
two-layer	O
neural	B
network	I
with	O
k-many	O
hidden	B
units	I
of	O
course	O
it	O
s	O
not	O
a	O
classifically	O
trained	O
neural	B
network	I
you	O
learn	O
wk	O
you	O
never	O
go	O
back	O
and	O
update	O
it	O
but	O
the	O
structure	O
is	O
identical	O
random	O
ensembles	O
one	O
of	O
the	O
most	O
computationally	O
expensive	O
aspects	O
of	O
ensembles	O
of	O
decision	B
trees	I
is	O
training	O
the	O
decision	B
trees	I
this	O
is	O
very	O
fast	O
for	O
decision	O
stumps	O
but	O
for	O
deeper	O
trees	O
it	O
can	O
be	O
prohibitively	O
expensive	O
the	O
expensive	O
part	O
is	O
choosing	O
the	O
tree	O
structure	O
once	O
the	O
tree	O
structure	O
is	O
chosen	O
it	O
is	O
very	O
cheap	O
to	O
fill	O
in	O
the	O
leaves	O
the	O
predictions	O
of	O
the	O
trees	O
using	O
the	O
training	B
data	I
an	O
efficient	O
and	O
surprisingly	O
effective	O
alternative	O
is	O
to	O
use	O
trees	O
with	O
fixed	O
structures	O
and	O
random	O
features	B
collections	O
of	O
trees	O
are	O
called	O
forests	O
and	O
so	O
classifiers	O
built	O
like	O
this	O
are	O
called	O
random	B
forests	I
the	O
random	O
forest	O
training	O
algorithm	B
shown	O
in	O
algorithm	B
is	O
quite	O
short	O
it	O
takes	O
three	O
arguments	O
the	O
data	O
a	O
desired	O
depth	O
of	O
the	O
decision	B
trees	I
and	O
a	O
number	O
k	O
of	O
total	O
decision	B
trees	I
to	O
build	O
the	O
algorithm	B
generates	O
each	O
of	O
the	O
k	O
trees	O
independently	B
which	O
makes	O
it	O
very	O
easy	O
to	O
parallelize	O
for	O
each	O
trees	O
it	O
constructs	O
a	O
full	O
binary	O
tree	O
of	O
depth	O
depth	O
the	O
features	B
used	O
at	O
the	O
branches	O
of	O
this	O
a	O
course	O
in	O
machine	O
learning	O
tree	O
are	O
selected	O
randomly	O
typically	O
with	O
replacement	O
meaning	O
that	O
the	O
same	O
feature	O
can	O
appear	O
multiple	O
times	O
even	O
in	O
one	O
branch	O
the	O
leaves	O
of	O
this	O
tree	O
where	O
predictions	O
are	O
made	O
are	O
filled	O
in	O
based	O
on	O
the	O
training	B
data	I
this	O
last	O
step	O
is	O
the	O
only	O
point	O
at	O
which	O
the	O
training	B
data	I
is	O
used	O
the	O
resulting	O
classifier	O
is	O
then	O
just	O
a	O
voting	B
of	O
the	O
kmany	O
random	O
trees	O
the	O
most	O
amazing	O
thing	O
about	O
this	O
approach	O
is	O
that	O
it	O
actually	O
works	O
remarkably	O
well	O
it	O
tends	O
to	O
work	O
best	O
when	O
all	O
of	O
the	O
features	B
are	O
at	O
least	O
marginally	O
relevant	O
since	O
the	O
number	O
of	O
features	B
selected	O
for	O
any	O
given	O
tree	O
is	O
small	O
an	O
intuitive	O
reason	O
that	O
it	O
works	O
well	O
is	O
the	O
following	O
some	O
of	O
the	O
trees	O
will	O
query	O
on	O
useless	O
features	B
these	O
trees	O
will	O
essentially	O
make	O
random	O
predictions	O
but	O
some	O
of	O
the	O
trees	O
will	O
happen	O
to	O
query	O
on	O
good	O
features	B
and	O
will	O
make	O
good	O
predictions	O
the	O
leaves	O
are	O
estimated	O
based	O
on	O
the	O
training	B
data	I
if	O
you	O
have	O
enough	O
trees	O
the	O
random	O
ones	O
will	O
wash	O
out	O
as	O
noise	B
and	O
only	O
the	O
good	O
trees	O
will	O
have	O
an	O
effect	O
on	O
the	O
final	O
classification	O
exercises	O
exercise	O
todo	O
efficient	O
learning	O
learning	O
objectives	O
understand	O
and	O
be	O
able	O
to	O
implement	O
stochastic	B
gradient	B
descent	I
algorithms	O
compare	O
and	O
contrast	O
small	O
versus	O
large	O
batch	B
sizes	O
in	O
stochastic	B
optimization	I
derive	O
subgradients	O
for	O
sparse	B
regularizers	O
implement	O
feature	O
hashing	O
dependencies	O
so	O
far	O
our	O
focus	O
has	O
been	O
on	O
models	O
of	O
learning	O
and	O
basic	O
algorithms	O
for	O
those	O
models	O
we	O
have	O
not	O
placed	O
much	O
emphasis	O
on	O
how	O
to	O
learn	O
quickly	O
the	O
basic	O
techniques	O
you	O
learned	O
about	O
so	O
far	O
are	O
enough	O
to	O
get	O
learning	O
algorithms	O
running	O
on	O
tens	O
or	O
hundreds	O
of	O
thousands	O
of	O
examples	B
but	O
if	O
you	O
want	O
to	O
build	O
an	O
algorithm	B
for	O
web	O
page	O
ranking	O
you	O
will	O
need	O
to	O
deal	O
with	O
millions	O
or	O
billions	O
of	O
examples	B
in	O
hundreds	O
of	O
thousands	O
of	O
dimensions	O
the	O
basic	O
approaches	O
you	O
have	O
seen	O
so	O
far	O
are	O
insufficient	O
to	O
achieve	O
such	O
a	O
massive	O
scale	O
in	O
this	O
chapter	O
you	O
will	O
learn	O
some	O
techniques	O
for	O
scaling	O
learning	O
algorithms	O
this	O
are	O
useful	O
even	O
when	O
you	O
do	O
not	O
have	O
billions	O
of	O
training	O
examples	B
because	O
it	O
s	O
always	O
nice	O
to	O
have	O
a	O
program	O
that	O
runs	O
quickly	O
you	O
will	O
see	O
techniques	O
for	O
speeding	O
up	O
both	O
model	B
training	O
and	O
model	B
prediction	O
the	O
focus	O
in	O
this	O
chapter	O
is	O
on	O
linear	O
models	O
simplicity	O
but	O
most	O
of	O
what	O
you	O
will	O
learn	O
applies	O
more	O
generally	O
what	O
does	O
it	O
mean	O
to	O
be	O
fast	O
everyone	O
always	O
wants	O
fast	O
algorithms	O
in	O
the	O
context	O
of	O
machine	O
learning	O
this	O
can	O
mean	O
many	O
things	O
you	O
might	O
want	O
fast	O
training	O
algorithms	O
or	O
perhaps	O
training	O
algorithms	O
that	O
scale	O
to	O
very	O
large	O
data	O
sets	O
instance	O
ones	O
that	O
will	O
not	O
fit	O
in	O
main	O
memory	O
you	O
might	O
want	O
training	O
algorithms	O
that	O
can	O
be	O
easily	O
parallelized	O
or	O
you	O
might	O
not	O
care	O
about	O
training	O
efficiency	O
since	O
it	O
is	O
an	O
offline	O
process	O
and	O
only	O
care	O
about	O
how	O
quickly	O
your	O
learned	O
functions	O
can	O
make	O
classification	O
decisions	O
it	O
is	O
important	O
to	O
separate	O
out	O
these	O
desires	O
if	O
you	O
care	O
about	O
efficiency	O
at	O
training	O
time	O
then	O
what	O
you	O
are	O
really	O
asking	O
for	O
are	O
more	O
efficient	O
learning	O
algorithms	O
on	O
the	O
other	O
hand	O
if	O
you	O
care	O
about	O
efficiency	O
at	O
test	O
time	O
then	O
you	O
are	O
asking	O
for	O
models	O
that	O
can	O
be	O
quickly	O
evaluated	O
one	O
issue	O
that	O
is	O
not	O
covered	O
in	O
this	O
chapter	O
is	O
parallel	O
learning	O
a	O
course	O
in	O
machine	O
learning	O
this	O
is	O
largely	O
because	O
it	O
is	O
currently	O
not	O
a	O
well-understood	O
area	O
in	O
machine	O
learning	O
there	O
are	O
many	O
aspects	O
of	O
parallelism	O
that	O
come	O
into	O
play	O
such	O
as	O
the	O
speed	O
of	O
communication	O
across	O
the	O
network	O
whether	O
you	O
have	O
shared	O
memory	O
etc	O
right	O
now	O
this	O
the	O
general	O
poor-man	O
s	O
approach	O
to	O
parallelization	O
is	O
to	O
employ	O
ensembles	O
stochastic	B
optimization	I
during	O
training	O
of	O
most	O
learning	O
algorithms	O
you	O
consider	O
the	O
entire	O
data	O
set	O
simultaneously	O
this	O
is	O
certainly	O
true	O
of	O
gradient	B
descent	I
algorithms	O
for	O
regularized	O
linear	B
classifiers	I
algorithm	B
in	O
which	O
you	O
first	O
compute	O
a	O
gradient	B
over	O
the	O
entire	O
training	B
data	I
simplicity	O
consider	O
the	O
unbiased	B
case	O
g	O
n	O
w	O
xn	O
w	O
where	O
y	O
is	O
some	O
loss	B
function	I
then	O
you	O
update	O
the	O
weights	B
by	O
w	O
w	O
g	O
in	O
this	O
algorithm	B
in	O
order	O
to	O
make	O
a	O
single	O
update	O
you	O
have	O
to	O
look	O
at	O
every	O
training	O
example	O
when	O
there	O
are	O
billions	O
of	O
training	O
examples	B
it	O
is	O
a	O
bit	O
silly	O
to	O
look	O
at	O
every	O
one	O
before	O
doing	O
anything	O
perhaps	O
just	O
on	O
the	O
basis	O
of	O
the	O
first	O
few	O
examples	B
you	O
can	O
already	O
start	O
learning	O
something	O
stochastic	B
optimization	I
involves	O
thinking	O
of	O
your	O
training	B
data	I
as	O
a	O
big	O
distribution	O
over	O
examples	B
a	O
draw	O
from	O
this	O
distribution	O
corresponds	O
to	O
picking	O
some	O
example	O
at	O
random	O
from	O
your	O
data	O
set	O
viewed	O
this	O
way	O
the	O
optimization	B
problem	I
becomes	O
a	O
stochastic	B
optimization	B
problem	I
because	O
you	O
are	O
trying	O
to	O
optimize	O
some	O
function	O
a	O
regularized	O
linear	B
classifier	I
over	O
a	O
probability	O
distribution	O
you	O
can	O
derive	O
this	O
intepretation	O
directly	O
as	O
follows	O
w	O
arg	O
max	O
w	O
arg	O
max	O
w	O
arg	O
max	O
w	O
n	O
n	O
n	O
arg	O
max	O
w	O
e	O
d	O
rw	O
w	O
xn	O
rw	O
w	O
xn	O
n	O
w	O
xn	O
w	O
x	O
n	O
rw	O
n	O
rw	O
definition	O
move	O
r	O
inside	O
sum	O
divide	O
through	O
by	O
n	O
write	O
as	O
expectation	O
where	O
d	O
is	O
the	O
training	B
data	I
distribution	O
given	O
this	O
framework	O
you	O
have	O
the	O
following	O
general	O
form	O
of	O
an	O
efficient	O
learning	O
algorithm	B
stochasticgradientdescentf	O
d	O
s	O
k	O
for	O
k	O
k	O
do	O
initialize	O
variable	O
we	O
are	O
optimizing	O
gk	O
zf	O
dk	O
s-many	O
random	O
data	O
points	O
from	O
d	O
zk	O
compute	O
gradient	B
on	O
sample	O
take	O
a	O
step	O
down	O
the	O
gradient	B
end	O
for	O
return	O
zk	O
optimization	B
problem	I
min	O
e	O
z	O
in	O
the	O
example	O
denotes	O
the	O
random	O
choice	O
of	O
examples	B
over	O
the	O
dataset	O
z	O
denotes	O
the	O
weight	O
vector	B
and	O
f	O
denotes	O
the	O
loss	O
on	O
that	O
example	O
plus	O
a	O
fraction	O
of	O
the	O
regularizer	B
stochastic	B
optimization	I
problems	O
are	O
formally	O
harder	O
than	O
regular	O
optimization	O
problems	O
because	O
you	O
do	O
not	O
even	O
get	O
access	O
to	O
exact	O
function	O
values	O
and	O
gradients	O
the	O
only	O
access	O
you	O
have	O
to	O
the	O
function	O
f	O
that	O
you	O
wish	O
to	O
optimize	O
are	O
noisy	O
measurements	O
governed	O
by	O
the	O
distribution	O
over	O
despite	O
this	O
lack	O
of	O
information	O
you	O
can	O
still	O
run	O
a	O
gradient-based	O
algorithm	B
where	O
you	O
simply	O
compute	O
local	O
gradients	O
on	O
a	O
current	O
sample	O
of	O
data	O
more	O
precisely	O
you	O
can	O
draw	O
a	O
data	O
point	O
at	O
random	O
from	O
your	O
data	O
set	O
this	O
is	O
analogous	O
to	O
drawing	O
a	O
single	O
value	O
from	O
its	O
distribution	O
you	O
can	O
compute	O
the	O
gradient	B
of	O
f	O
just	O
at	O
that	O
point	O
in	O
this	O
case	O
of	O
a	O
regularized	O
linear	O
model	B
this	O
is	O
simply	O
g	O
w	O
x	O
n	O
w	O
where	O
x	O
is	O
the	O
random	O
point	O
you	O
selected	O
given	O
this	O
estimate	O
of	O
the	O
gradient	B
s	O
an	O
estimate	O
because	O
it	O
s	O
based	O
on	O
a	O
single	O
random	O
draw	O
you	O
can	O
take	O
a	O
small	O
gradient	B
step	O
w	O
w	O
g	O
this	O
is	O
the	O
stochastic	B
gradient	B
descent	I
algorithm	B
in	O
prac	O
tice	O
taking	O
gradients	O
with	O
respect	O
to	O
a	O
single	O
data	O
point	O
might	O
be	O
too	O
myopic	O
in	O
such	O
cases	O
it	O
is	O
useful	O
to	O
use	O
a	O
small	O
batch	B
of	O
data	O
here	O
you	O
can	O
draw	O
random	O
examples	B
from	O
the	O
training	B
data	I
and	O
compute	O
a	O
small	O
gradient	B
based	O
on	O
those	O
examples	B
g	O
n	O
w	O
where	O
you	O
need	O
to	O
include	O
counts	O
of	O
the	O
regularizer	B
popular	O
batch	B
sizes	O
are	O
points	O
and	O
the	O
generic	O
sgd	B
algorithm	B
is	O
depicted	O
in	O
algorithm	B
which	O
takes	O
k-many	O
steps	O
over	O
batches	O
of	O
s-many	O
examples	B
w	O
xm	O
in	O
stochastic	B
gradient	B
descent	I
it	O
is	O
imperative	O
to	O
choose	O
good	O
step	O
sizes	O
it	O
is	O
also	O
very	O
important	O
that	O
the	O
steps	O
get	O
smaller	O
over	O
time	O
at	O
a	O
reasonable	O
slow	O
rate	O
in	O
particular	O
convergence	O
can	O
be	O
guaranteed	O
for	O
learning	O
rates	O
of	O
the	O
form	O
k	O
where	O
is	O
a	O
fixed	O
initial	O
step	O
size	O
typically	O
or	O
depending	O
on	O
how	O
quickly	O
you	O
ex	O
a	O
course	O
in	O
machine	O
learning	O
pect	O
the	O
algorithm	B
to	O
converge	O
unfortunately	O
in	O
comparisong	O
to	O
gradient	B
descent	I
stochastic	O
gradient	B
is	O
quite	O
sensitive	O
to	O
the	O
selection	O
of	O
a	O
good	O
learning	O
rate	O
there	O
is	O
one	O
more	O
practical	O
issues	O
related	O
to	O
the	O
use	O
of	O
sgd	B
as	O
a	O
learning	O
algorithm	B
do	O
you	O
really	O
select	O
a	O
random	O
point	O
subset	O
of	O
random	O
points	O
at	O
each	O
step	O
or	O
do	O
you	O
stream	O
through	O
the	O
data	O
in	O
order	O
the	O
answer	O
is	O
akin	O
to	O
the	O
answer	O
of	O
the	O
same	O
question	O
for	O
the	O
perceptron	B
algorithm	B
if	O
you	O
do	O
not	O
permute	O
your	O
data	O
at	O
all	O
very	O
bad	O
things	O
can	O
happen	O
if	O
you	O
do	O
permute	O
your	O
data	O
once	O
and	O
then	O
do	O
multiple	O
passes	O
over	O
that	O
same	O
permutation	O
it	O
will	O
converge	O
but	O
more	O
slowly	O
in	O
theory	O
you	O
really	O
should	O
permute	O
every	O
iteration	B
if	O
your	O
data	O
is	O
small	O
enough	O
to	O
fit	O
in	O
memory	O
this	O
is	O
not	O
a	O
big	O
deal	O
you	O
will	O
only	O
pay	O
for	O
cache	O
misses	O
however	O
if	O
your	O
data	O
is	O
too	O
large	O
for	O
memory	O
and	O
resides	O
on	O
a	O
magnetic	O
disk	O
that	O
has	O
a	O
slow	O
seek	O
time	O
randomly	O
seeking	O
to	O
new	O
data	O
points	O
for	O
each	O
example	O
is	O
prohibitivly	O
slow	O
and	O
you	O
will	O
likely	O
need	O
to	O
forgo	O
permuting	O
the	O
data	O
the	O
speed	O
hit	O
in	O
convergence	O
speed	O
will	O
almost	O
certainly	O
be	O
recovered	O
by	O
the	O
speed	O
gain	O
in	O
not	O
having	O
to	O
seek	O
on	O
disk	O
routinely	O
that	O
the	O
story	O
is	O
very	O
different	O
for	O
solid	O
state	O
disks	O
on	O
which	O
random	O
accesses	O
really	O
are	O
quite	O
efficient	O
sparse	B
regularization	O
for	O
many	O
learning	O
algorithms	O
the	O
test-time	O
efficiency	O
is	O
governed	O
by	O
how	O
many	O
features	B
are	O
used	O
for	O
prediction	O
this	O
is	O
one	O
reason	O
decision	B
trees	I
tend	O
to	O
be	O
among	O
the	O
fastest	O
predictors	O
they	O
only	O
use	O
a	O
small	O
number	O
of	O
features	B
especially	O
in	O
cases	O
where	O
the	O
actual	O
computation	O
of	O
these	O
features	B
is	O
expensive	O
cutting	O
down	O
on	O
the	O
number	O
that	O
are	O
used	O
at	O
test	O
time	O
can	O
yield	O
huge	O
gains	O
in	O
efficiency	O
moreover	O
the	O
amount	O
of	O
memory	O
used	O
to	O
make	O
predictions	O
is	O
also	O
typically	O
governed	O
by	O
the	O
number	O
of	O
features	B
this	O
is	O
not	O
true	O
of	O
kernel	B
methods	O
like	O
support	O
vector	B
machines	O
in	O
which	O
the	O
dominant	O
cost	O
is	O
the	O
number	O
of	O
support	B
vectors	I
furthermore	O
you	O
may	O
simply	O
believe	O
that	O
your	O
learning	O
problem	O
can	O
be	O
solved	O
with	O
a	O
very	O
small	O
number	O
of	O
features	B
this	O
is	O
a	O
very	O
reasonable	O
form	O
of	O
inductive	B
bias	B
this	O
is	O
the	O
idea	O
behind	O
sparse	B
models	O
and	O
in	O
particular	O
sparse	B
regularizers	O
one	O
of	O
the	O
disadvantages	O
of	O
a	O
regularizer	B
for	O
linear	O
models	O
is	O
that	O
they	O
tend	O
to	O
never	O
produce	O
weights	B
that	O
are	O
exactly	O
zero	O
they	O
get	O
close	O
to	O
zero	O
but	O
never	O
hit	O
it	O
to	O
understand	O
why	O
as	O
a	O
weight	O
wd	O
approaches	O
zero	O
its	O
gradient	B
also	O
approaches	O
zero	O
thus	O
even	O
if	O
the	O
weight	O
should	O
be	O
zero	O
it	O
will	O
essentially	O
never	O
get	O
there	O
because	O
of	O
the	O
constantly	O
shrinking	O
gradient	B
this	O
suggests	O
that	O
an	O
alternative	O
regularizer	B
is	O
required	O
to	O
yield	O
a	O
sparse	B
inductive	B
bias	B
an	O
ideal	O
case	O
would	O
be	O
the	O
zero-norm	O
regular	O
efficient	O
learning	O
izer	O
which	O
simply	O
counts	O
the	O
number	O
of	O
non-zero	O
values	O
in	O
a	O
vector	B
dwd	O
if	O
you	O
could	O
minimize	O
this	O
regularizer	B
you	O
would	O
be	O
explicitly	O
minimizing	O
the	O
number	O
of	O
non-zero	O
features	B
unfortunately	O
not	O
only	O
is	O
the	O
zero-norm	O
non-convex	B
it	O
s	O
also	O
discrete	O
optimizing	O
it	O
is	O
np-hard	O
a	O
reasonable	O
middle-ground	O
is	O
the	O
one-norm	O
d	O
it	O
is	O
indeed	O
convex	B
in	O
fact	O
it	O
is	O
the	O
tighest	O
norm	O
that	O
is	O
convex	B
moreover	O
its	O
gradients	O
do	O
not	O
go	O
to	O
zero	O
as	O
in	O
the	O
two-norm	O
just	O
as	O
hinge-loss	O
is	O
the	O
tightest	O
convex	B
upper	O
bound	O
on	O
zero-one	O
error	O
the	O
one-norm	O
is	O
the	O
tighest	O
convex	B
upper	O
bound	O
on	O
the	O
zero-norm	O
at	O
this	O
point	O
you	O
should	O
be	O
content	O
you	O
can	O
take	O
your	O
subgradient	B
optimizer	O
for	O
arbitrary	O
functions	O
and	O
plug	O
in	O
the	O
one-norm	O
as	O
a	O
regularizer	B
the	O
one-norm	O
is	O
surely	O
non-differentiable	O
at	O
wd	O
but	O
you	O
can	O
simply	O
choose	O
any	O
value	O
in	O
the	O
range	O
as	O
a	O
subgradient	B
at	O
that	O
point	O
should	O
choose	O
zero	O
unfortunately	O
this	O
does	O
not	O
quite	O
work	O
the	O
way	O
you	O
might	O
expect	O
the	O
issue	O
is	O
that	O
the	O
gradient	B
might	O
overstep	O
zero	O
and	O
you	O
will	O
never	O
end	O
up	O
with	O
a	O
solution	O
that	O
is	O
particularly	O
sparse	B
for	O
example	O
at	O
the	O
end	O
of	O
one	O
gradient	B
step	O
you	O
might	O
have	O
your	O
gradient	B
might	O
have	O
and	O
your	O
gradient	B
step	O
will	O
update	O
so	O
that	O
the	O
new	O
in	O
the	O
subsequent	O
iteration	B
you	O
might	O
have	O
and	O
step	O
to	O
this	O
observation	O
leads	O
to	O
the	O
idea	O
of	O
trucated	B
gradients	I
the	O
idea	O
is	O
simple	O
if	O
you	O
have	O
a	O
gradient	B
that	O
would	O
step	O
you	O
over	O
wd	O
then	O
just	O
set	O
wd	O
in	O
the	O
easy	O
case	O
when	O
the	O
learning	O
rate	O
is	O
this	O
means	O
that	O
if	O
the	O
sign	B
of	O
wd	O
gd	O
is	O
different	O
than	O
the	O
sign	B
of	O
wd	O
then	O
you	O
truncate	O
the	O
gradient	B
step	O
and	O
simply	O
set	O
wd	O
in	O
other	O
words	O
gd	O
should	O
never	O
be	O
larger	O
than	O
wd	O
once	O
you	O
incorporate	O
learning	O
rates	O
you	O
can	O
express	O
this	O
as	O
gd	O
gd	O
gd	O
if	O
wd	O
and	O
gd	O
if	O
wd	O
and	O
gd	O
otherwise	O
wd	O
wd	O
this	O
works	O
quite	O
well	O
in	O
the	O
case	O
of	O
subgradient	B
descent	I
it	O
works	O
somewhat	O
less	O
well	O
in	O
the	O
case	O
of	O
stochastic	O
subgradient	B
descent	I
the	O
problem	O
that	O
arises	O
in	O
the	O
stochastic	O
case	O
is	O
that	O
wherever	O
you	O
choose	O
to	O
stop	O
optimizing	O
you	O
will	O
have	O
just	O
touched	O
a	O
single	O
example	O
small	O
batch	B
of	O
examples	B
which	O
will	O
increase	O
the	O
weights	B
for	O
a	O
lot	O
of	O
features	B
before	O
the	O
regularizer	B
has	O
time	O
to	O
shrink	O
them	O
back	O
down	O
to	O
zero	O
you	O
will	O
still	O
end	O
up	O
with	O
somewhat	O
sparse	B
solutions	O
but	O
not	O
as	O
sparse	B
as	O
they	O
could	O
be	O
there	O
are	O
algorithms	O
for	O
dealing	O
with	O
this	O
situation	O
but	O
they	O
all	O
have	O
a	O
heuristic	O
flavor	O
to	O
them	O
and	O
are	O
beyond	O
the	O
scope	O
of	O
this	O
book	O
a	O
course	O
in	O
machine	O
learning	O
feature	O
hashing	O
as	O
much	O
as	O
speed	O
is	O
a	O
bottleneck	O
in	O
prediction	O
so	O
often	O
is	O
memory	O
usage	O
if	O
you	O
have	O
a	O
very	O
large	O
number	O
of	O
features	B
the	O
amount	O
of	O
memory	O
that	O
it	O
takes	O
to	O
store	O
weights	B
for	O
all	O
of	O
them	O
can	O
become	O
prohibitive	O
especially	O
if	O
you	O
wish	O
to	O
run	O
your	O
algorithm	B
on	O
small	O
devices	O
feature	O
hashing	O
is	O
an	O
incredibly	O
simple	O
technique	O
for	O
reducing	O
the	O
memory	O
footprint	O
of	O
linear	O
models	O
with	O
very	O
small	O
sacrifices	O
in	O
accuracy	O
the	O
basic	O
idea	O
is	O
to	O
replace	O
all	O
of	O
your	O
features	B
with	O
hashed	O
versions	O
of	O
those	O
features	B
thus	O
reducing	O
your	O
space	O
from	O
d-many	O
feature	O
weights	B
to	O
p-many	O
feature	O
weights	B
where	O
p	O
is	O
the	O
range	O
of	O
the	O
hash	O
function	O
you	O
can	O
actually	O
think	O
of	O
hashing	O
as	O
a	O
feature	B
mapping	I
rd	O
rp	O
for	O
some	O
p	O
d	O
the	O
idea	O
is	O
as	O
follows	O
first	O
you	O
choose	O
a	O
hash	O
function	O
h	O
whose	O
domain	O
is	O
d	O
and	O
whose	O
range	O
is	O
then	O
when	O
you	O
receive	O
a	O
feature	B
vector	B
x	O
rd	O
you	O
map	O
it	O
to	O
a	O
shorter	O
feature	B
vector	B
x	O
rp	O
algorithmically	O
you	O
can	O
think	O
of	O
this	O
mapping	O
as	O
follows	O
initialize	O
x	O
for	O
each	O
d	O
d	O
hash	O
d	O
to	O
position	O
p	O
hd	O
update	O
the	O
pth	O
position	O
by	O
adding	O
xd	O
xp	O
xp	O
xd	O
return	O
x	O
mathematically	O
the	O
mapping	O
looks	O
like	O
d	O
pxd	O
d	O
h	O
xd	O
where	O
h	O
hd	O
p	O
in	O
the	O
case	O
where	O
p	O
d	O
and	O
h	O
simply	O
encodes	O
a	O
per	O
mutation	O
then	O
this	O
mapping	O
does	O
not	O
change	O
the	O
learning	O
problem	O
at	O
all	O
all	O
it	O
does	O
is	O
rename	O
all	O
of	O
the	O
features	B
in	O
practice	O
p	O
d	O
and	O
there	O
will	O
be	O
collisions	O
in	O
this	O
context	O
a	O
collision	O
means	O
that	O
two	O
features	B
which	O
are	O
really	O
different	O
end	O
up	O
looking	O
the	O
same	O
to	O
the	O
learning	O
algorithm	B
for	O
instance	O
is	O
it	O
sunny	O
today	O
and	O
did	O
my	O
favorite	O
sports	O
team	O
win	O
last	O
night	O
might	O
get	O
mapped	O
to	O
the	O
same	O
location	O
after	O
hashing	O
the	O
hope	O
is	O
that	O
the	O
learning	O
algorithm	B
is	O
sufficiently	O
robust	O
to	O
noise	B
that	O
it	O
can	O
handle	O
this	O
case	O
well	O
consider	O
the	O
kernel	B
defined	O
by	O
this	O
hash	O
mapping	O
namely	O
khashx	O
z	O
de	O
p	O
p	O
d	O
e	O
h	O
x	O
z	O
d	O
xdze	O
e	O
h	O
pzd	O
d	O
pxd	O
d	O
phe	O
pxdze	O
xdze	O
efficient	O
learning	O
this	O
hash	B
kernel	B
has	O
the	O
form	O
of	O
a	O
linear	O
kernel	B
plus	O
a	O
small	O
number	O
of	O
quadratic	O
terms	O
the	O
particular	O
quadratic	O
terms	O
are	O
exactly	O
those	O
given	O
by	O
collisions	O
of	O
the	O
hash	O
function	O
there	O
are	O
two	O
things	O
to	O
notice	O
about	O
this	O
the	O
first	O
is	O
that	O
collisions	O
might	O
not	O
actually	O
be	O
bad	O
things	O
in	O
a	O
sense	O
they	O
re	O
giving	O
you	O
a	O
little	O
extra	O
representational	O
power	O
in	O
particular	O
if	O
the	O
hash	O
function	O
happens	O
to	O
select	O
out	O
feature	O
pairs	O
that	O
benefit	O
from	O
being	O
paired	O
then	O
you	O
now	O
have	O
a	O
better	O
representation	O
the	O
second	O
is	O
that	O
even	O
if	O
this	O
doesn	O
t	O
happen	O
the	O
quadratic	O
term	O
in	O
the	O
kernel	B
has	O
only	O
a	O
small	O
effect	O
on	O
the	O
overall	O
prediction	O
in	O
particular	O
if	O
you	O
assume	O
that	O
your	O
hash	O
function	O
is	O
pairwise	O
independent	O
common	O
assumption	O
of	O
hash	O
functions	O
then	O
the	O
expected	O
value	O
of	O
this	O
quadratic	O
term	O
is	O
zero	O
and	O
its	O
variance	B
decreases	O
at	O
a	O
rate	O
of	O
op	O
in	O
other	O
words	O
if	O
you	O
choose	O
p	O
then	O
the	O
variance	B
is	O
on	O
the	O
order	O
of	O
exercises	O
exercise	O
todo	O
unsupervised	B
learning	I
learning	O
objectives	O
explain	O
the	O
difference	O
between	O
linear	O
and	O
non-linear	B
dimensionality	B
reduction	I
relate	O
the	O
view	O
of	O
pca	B
as	O
maximiz	O
ing	O
variance	B
with	O
the	O
view	O
of	O
it	O
as	O
minimizing	O
reconstruction	B
error	I
implement	O
latent	O
semantic	O
analysis	O
for	O
text	O
data	O
motivate	O
manifold	O
learning	O
from	O
the	O
perspective	O
of	O
reconstruction	B
error	I
understand	O
k-means	O
clustering	B
as	O
distance	B
minimization	O
explain	O
the	O
importance	O
of	O
initial	O
ization	O
in	O
k-means	O
and	O
furthest-first	B
heuristic	I
implement	O
agglomerative	O
clustering	B
argue	O
whether	O
spectral	O
clustering	B
is	O
a	O
clustering	B
algorithm	B
or	O
a	O
dimensionality	B
reduction	I
algorithm	B
dependencies	O
if	O
you	O
have	O
access	O
to	O
labeled	O
training	B
data	I
you	O
know	O
what	O
to	O
do	O
this	O
is	O
the	O
supervised	O
setting	O
in	O
which	O
you	O
have	O
a	O
teacher	O
telling	O
you	O
the	O
right	O
answers	O
unfortunately	O
finding	O
such	O
a	O
teacher	O
is	O
often	O
difficult	O
expensive	O
or	O
down	O
right	O
impossible	O
in	O
those	O
cases	O
you	O
might	O
still	O
want	O
to	O
be	O
able	O
to	O
analyze	O
your	O
data	O
even	O
though	O
you	O
do	O
not	O
have	O
labels	O
unsupervised	B
learning	I
is	O
learning	O
without	O
a	O
teacher	O
one	O
basic	O
thing	O
that	O
you	O
might	O
want	O
to	O
do	O
with	O
data	O
is	O
to	O
visualize	B
it	O
sadly	O
it	O
is	O
difficult	O
to	O
visualize	B
things	O
in	O
more	O
than	O
two	O
three	O
dimensions	O
and	O
most	O
data	O
is	O
in	O
hundreds	O
of	O
dimensions	O
more	O
dimensionality	B
reduction	I
is	O
the	O
problem	O
of	O
taking	O
high	O
dimensional	O
data	O
and	O
embedding	B
it	O
in	O
a	O
lower	O
dimension	O
space	O
another	O
thing	O
you	O
might	O
want	O
to	O
do	O
is	O
automatically	O
derive	O
a	O
partitioning	O
of	O
the	O
data	O
into	O
clusters	O
you	O
ve	O
already	O
learned	O
a	O
basic	O
approach	O
for	O
doing	O
this	O
the	O
k-means	O
algorithm	B
here	O
you	O
will	O
analyze	O
this	O
algorithm	B
to	O
see	O
why	O
it	O
works	O
you	O
will	O
also	O
learn	O
more	O
advanced	O
clustering	B
approaches	O
k-means	O
clustering	B
revisited	O
the	O
k-means	O
clustering	B
algorithm	B
is	O
re-presented	O
in	O
algorithm	B
there	O
are	O
two	O
very	O
basic	O
questions	O
about	O
this	O
algorithm	B
does	O
it	O
converge	O
if	O
so	O
how	O
quickly	O
how	O
sensitive	O
it	O
is	O
to	O
initialization	O
the	O
answers	O
to	O
these	O
questions	O
detailed	O
below	O
are	O
yes	O
it	O
converges	O
and	O
it	O
converges	O
very	O
quickly	O
in	O
practice	O
slowly	O
in	O
theory	O
yes	O
it	O
is	O
sensitive	O
to	O
initialization	O
but	O
there	O
are	O
good	O
ways	O
to	O
initialize	O
it	O
consider	O
the	O
question	O
of	O
convergence	O
the	O
following	O
theorem	O
states	O
that	O
the	O
k-means	O
algorithm	B
converges	O
though	O
it	O
does	O
not	O
say	O
how	O
quickly	O
it	O
happens	O
the	O
method	O
of	O
proving	O
the	O
convergence	O
is	O
to	O
specify	O
a	O
clustering	B
quality	I
objective	B
function	I
and	O
then	O
to	O
show	O
that	O
the	O
k-means	O
algorithm	B
converges	O
to	O
a	O
optimum	O
of	O
that	O
objective	B
function	I
the	O
particular	O
objective	B
function	I
that	O
k-means	O
algorithm	B
k-meansd	O
k	O
for	O
k	O
to	O
k	O
do	O
k	O
some	O
random	O
location	O
end	O
for	O
repeat	O
for	O
n	O
to	O
n	O
do	O
zn	O
argmink	O
k	O
xn	O
end	O
for	O
for	O
k	O
to	O
k	O
do	O
k	O
mean	O
xn	O
zn	O
k	O
end	O
for	O
until	O
converged	O
return	O
z	O
unsupervised	B
learning	I
randomly	O
initialize	O
mean	O
for	O
kth	O
cluster	O
assign	O
example	O
n	O
to	O
closest	O
center	O
re-estimate	O
mean	O
of	O
cluster	O
k	O
return	O
cluster	O
assignments	O
is	O
optimizing	O
is	O
the	O
sum	O
of	O
squared	O
distances	O
from	O
any	O
data	O
point	O
to	O
its	O
assigned	O
center	O
this	O
is	O
a	O
natural	O
generalization	O
of	O
the	O
definition	O
of	O
a	O
mean	O
the	O
mean	O
of	O
a	O
set	O
of	O
points	O
is	O
the	O
single	O
point	O
that	O
minimizes	O
the	O
sum	O
of	O
squared	O
distances	O
from	O
the	O
mean	O
to	O
every	O
point	O
in	O
the	O
data	O
formally	O
the	O
k-means	O
objective	O
is	O
k	O
zn	O
lz	O
d	O
n	O
nznk	O
theorem	O
convergence	O
theorem	O
for	O
any	O
dataset	O
d	O
and	O
any	O
number	O
of	O
clusters	O
k	O
the	O
k-means	O
algorithm	B
converges	O
in	O
a	O
finite	O
number	O
of	O
iterations	O
where	O
convergence	O
is	O
measured	O
by	O
l	O
ceasing	O
the	O
change	O
proof	O
of	O
theorem	O
the	O
proof	O
works	O
as	O
follows	O
there	O
are	O
only	O
two	O
points	O
in	O
which	O
the	O
k-means	O
algorithm	B
changes	O
the	O
values	O
of	O
or	O
z	O
lines	O
and	O
we	O
will	O
show	O
that	O
both	O
of	O
these	O
operations	O
can	O
never	O
increase	O
the	O
value	O
of	O
l	O
assuming	O
this	O
is	O
true	O
the	O
rest	O
of	O
the	O
argument	O
is	O
as	O
follows	O
after	O
the	O
first	O
pass	O
through	O
the	O
data	O
there	O
are	O
are	O
only	O
finitely	O
many	O
possible	O
assignments	O
to	O
z	O
and	O
because	O
z	O
is	O
discrete	O
and	O
because	O
can	O
only	O
take	O
on	O
a	O
finite	O
number	O
of	O
values	O
means	O
of	O
some	O
subset	O
of	O
the	O
data	O
furthermore	O
l	O
is	O
lower-bounded	O
by	O
zero	O
together	O
this	O
means	O
that	O
l	O
cannot	O
decrease	O
more	O
than	O
a	O
finite	O
number	O
of	O
times	O
thus	O
it	O
must	O
stop	O
decreasing	O
at	O
some	O
point	O
and	O
at	O
that	O
point	O
the	O
algorithm	B
has	O
converged	O
it	O
remains	O
to	O
show	O
that	O
lines	O
and	O
decrease	O
l	O
for	O
line	O
when	O
looking	O
at	O
example	O
n	O
suppose	O
that	O
the	O
previous	O
value	O
of	O
zn	O
is	O
a	O
and	O
the	O
new	O
value	O
is	O
b	O
it	O
must	O
be	O
the	O
case	O
that	O
b	O
b	O
thus	O
changing	O
from	O
a	O
to	O
b	O
can	O
only	O
decrease	O
l	O
for	O
line	O
consider	O
the	O
second	O
form	O
of	O
l	O
line	O
computes	O
k	O
as	O
the	O
mean	O
of	O
the	O
data	O
points	O
for	O
which	O
zn	O
k	O
which	O
is	O
precisely	O
the	O
point	O
that	O
minimizes	O
squared	O
sitances	O
thus	O
this	O
update	O
to	O
k	O
can	O
only	O
decrease	O
l	O
there	O
are	O
several	O
aspects	O
of	O
k-means	O
that	O
are	O
unfortunate	O
first	O
the	O
convergence	O
is	O
only	O
to	O
a	O
local	O
optimum	O
of	O
l	O
in	O
practice	O
this	O
a	O
course	O
in	O
machine	O
learning	O
means	O
that	O
you	O
should	O
usually	O
run	O
it	O
times	O
with	O
different	O
initializations	O
and	O
pick	O
the	O
one	O
with	O
minimal	O
resulting	O
l	O
second	O
one	O
can	O
show	O
that	O
there	O
are	O
input	O
datasets	O
and	O
initializations	O
on	O
which	O
it	O
might	O
take	O
an	O
exponential	O
amount	O
of	O
time	O
to	O
converge	O
fortunately	O
these	O
cases	O
almost	O
never	O
happen	O
in	O
practice	O
and	O
in	O
fact	O
it	O
has	O
recently	O
been	O
shown	O
that	O
if	O
you	O
limit	O
the	O
floating	O
point	O
precision	B
of	O
your	O
machine	O
k-means	O
will	O
converge	O
in	O
polynomial	O
time	O
still	O
only	O
to	O
a	O
local	O
optimum	O
using	O
techniques	O
of	O
smoothed	B
analysis	I
the	O
biggest	O
practical	O
issue	O
in	O
k-means	O
is	O
initialization	O
if	O
the	O
cluster	O
means	O
are	O
initialized	O
poorly	O
you	O
often	O
get	O
convergence	O
to	O
uninteresting	O
solutions	O
a	O
useful	O
heuristic	O
is	O
the	O
furthest-first	B
heuristic	I
this	O
gives	O
a	O
way	O
to	O
perform	O
a	O
semi-random	O
initialization	O
that	O
attempts	O
to	O
pick	O
initial	O
means	O
as	O
far	O
from	O
each	O
other	O
as	O
possible	O
the	O
heuristic	O
is	O
sketched	O
below	O
pick	O
a	O
random	O
example	O
m	O
and	O
set	O
xm	O
for	O
k	O
k	O
find	O
the	O
example	O
m	O
that	O
is	O
as	O
far	O
as	O
possible	O
from	O
all	O
previ	O
ously	O
selected	O
means	O
namely	O
m	O
arg	O
maxm	O
and	O
set	O
k	O
xm	O
in	O
this	O
heuristic	O
the	O
only	O
bit	O
of	O
randomness	O
is	O
the	O
selection	O
of	O
the	O
first	O
data	O
point	O
after	O
that	O
it	O
is	O
completely	O
deterministic	O
in	O
the	O
rare	O
case	O
that	O
there	O
are	O
multiple	O
equidistant	O
points	O
in	O
step	O
it	O
is	O
extremely	O
important	O
that	O
when	O
selecting	O
the	O
mean	O
you	O
select	O
that	O
point	O
that	O
maximizes	O
the	O
minimum	O
distance	B
to	O
the	O
closest	O
other	O
mean	O
you	O
want	O
the	O
point	O
that	O
s	O
as	O
far	O
away	O
from	O
all	O
previous	O
means	O
as	O
possible	O
the	O
furthest-first	B
heuristic	I
is	O
just	O
that	O
a	O
heuristic	O
it	O
works	O
very	O
well	O
in	O
practice	O
though	O
can	O
be	O
somewhat	O
sensitive	O
to	O
outliers	O
will	O
often	O
get	O
selected	O
as	O
some	O
of	O
the	O
initial	O
means	O
however	O
this	O
outlier	O
sensitivity	B
is	O
usually	O
reduced	O
after	O
one	O
iteration	B
through	O
the	O
k-means	O
algorithm	B
despite	O
being	O
just	O
a	O
heuristic	O
it	O
is	O
quite	O
useful	O
in	O
practice	O
you	O
can	O
turn	O
the	O
heuristic	O
into	O
an	O
algorithm	B
by	O
adding	O
a	O
bit	O
more	O
randomness	O
this	O
is	O
the	O
idea	O
of	O
the	O
k-means	O
algorithm	B
which	O
is	O
a	O
simple	O
randomized	O
tweak	O
on	O
the	O
furthest-first	B
heuristic	I
the	O
idea	O
is	O
that	O
when	O
you	O
select	O
the	O
kth	O
mean	O
instead	O
of	O
choosing	O
the	O
absolute	O
furthest	O
data	O
point	O
you	O
choose	O
a	O
data	O
point	O
at	O
random	O
with	O
probability	O
proportional	O
to	O
its	O
distance	B
squared	O
this	O
is	O
made	O
formal	O
in	O
algorithm	B
if	O
you	O
use	O
k-means	O
as	O
an	O
initialization	O
for	O
k-means	O
then	O
you	O
are	O
able	O
to	O
achieve	O
an	O
approximation	O
guarantee	O
on	O
the	O
final	O
value	O
unsupervised	B
learning	I
algorithm	B
k-meansd	O
k	O
xm	O
for	O
m	O
chosen	O
uniformly	O
at	O
random	O
randomly	O
initialize	O
first	O
point	O
for	O
k	O
to	O
k	O
do	O
compute	O
distances	O
normalize	B
to	O
probability	O
distribution	O
pick	O
an	O
example	O
at	O
random	O
dn	O
n	O
p	O
n	O
nd	O
m	O
random	O
sample	O
from	O
p	O
k	O
xm	O
d	O
end	O
for	O
run	O
k-means	O
using	O
as	O
initial	O
centers	O
of	O
the	O
objective	O
this	O
doesn	O
t	O
tell	O
you	O
that	O
you	O
will	O
reach	O
the	O
global	O
optimum	O
but	O
it	O
does	O
tell	O
you	O
that	O
you	O
will	O
get	O
reasonably	O
close	O
in	O
particular	O
if	O
l	O
is	O
the	O
value	O
obtained	O
by	O
running	O
k-means	O
then	O
this	O
will	O
not	O
be	O
too	O
far	O
from	O
lopt	O
the	O
true	O
global	B
minimum	I
theorem	O
approximation	O
guarantee	O
the	O
expected	O
value	O
of	O
the	O
objective	O
returned	O
by	O
k-means	O
is	O
never	O
more	O
than	O
olog	O
k	O
from	O
optimal	O
and	O
can	O
be	O
as	O
close	O
as	O
from	O
optimal	O
even	O
in	O
the	O
former	O
case	O
with	O
random	O
restarts	O
one	O
restart	O
will	O
be	O
from	O
optimal	O
high	O
probability	O
formally	O
k	O
moreover	O
if	O
the	O
data	O
is	O
well	O
suited	O
for	O
clustering	B
then	O
the	O
notion	O
of	O
well	O
suited	O
for	O
clustering	B
informally	O
states	O
that	O
the	O
advantage	O
of	O
going	O
from	O
k	O
clusters	O
to	O
k	O
clusters	O
is	O
large	O
formally	O
it	O
means	O
that	O
lk	O
is	O
the	O
optimal	O
value	O
for	O
clustering	B
with	O
k	O
clusters	O
and	O
is	O
the	O
desired	O
degree	O
of	O
approximation	O
the	O
idea	O
is	O
that	O
if	O
this	O
condition	O
does	O
not	O
hold	O
then	O
you	O
shouldn	O
t	O
bother	O
clustering	B
the	O
data	O
where	O
lk	O
one	O
of	O
the	O
biggest	O
practical	O
issues	O
with	O
k-means	O
clustering	B
is	O
choosing	O
k	O
namely	O
if	O
someone	O
just	O
hands	O
you	O
a	O
dataset	O
and	O
asks	O
you	O
to	O
cluster	O
it	O
how	O
many	O
clusters	O
should	O
you	O
produce	O
this	O
is	O
difficult	O
because	O
increasing	O
k	O
will	O
always	O
decrease	O
lk	O
k	O
n	O
and	O
so	O
simply	O
using	O
l	O
as	O
a	O
notion	O
of	O
goodness	O
is	O
insufficient	O
to	O
overfitting	B
in	O
a	O
supervised	O
setting	O
a	O
number	O
of	O
information	O
criteria	O
have	O
been	O
proposed	O
to	O
try	O
to	O
address	O
this	O
problem	O
they	O
all	O
effectively	O
boil	O
down	O
to	O
regularizing	O
k	O
so	O
that	O
the	O
model	B
cannot	O
grow	O
to	O
be	O
too	O
complicated	O
the	O
two	O
most	O
popular	O
are	O
the	O
bayes	O
information	O
criteria	O
and	O
the	O
akaike	O
information	O
criteria	O
defined	O
below	O
in	O
the	O
context	O
of	O
k-means	O
bic	O
aic	O
arg	O
min	O
k	O
arg	O
min	O
k	O
lk	O
k	O
log	O
d	O
lk	O
the	O
informal	O
intuition	O
behind	O
these	O
criteria	O
is	O
that	O
increasing	O
k	O
is	O
going	O
to	O
make	O
lk	O
go	O
down	O
however	O
if	O
it	O
doesn	O
t	O
go	O
down	O
by	O
enough	O
then	O
it	O
s	O
not	O
worth	O
doing	O
in	O
the	O
case	O
of	O
bic	O
by	O
enough	O
a	O
course	O
in	O
machine	O
learning	O
means	O
by	O
an	O
amount	O
proportional	O
to	O
log	O
d	O
in	O
the	O
case	O
of	O
aic	O
it	O
s	O
proportional	O
to	O
thus	O
aic	O
provides	O
a	O
much	O
stronger	O
penalty	O
for	O
many	O
clusters	O
than	O
does	O
bic	O
especially	O
in	O
high	O
dimensions	O
a	O
more	O
formal	O
intuition	O
for	O
bic	O
is	O
the	O
following	O
you	O
ask	O
yourself	O
the	O
question	O
if	O
i	O
wanted	O
to	O
send	O
this	O
data	O
across	O
a	O
network	O
how	O
many	O
bits	O
would	O
i	O
need	O
to	O
send	O
clearly	O
you	O
could	O
simply	O
send	O
all	O
of	O
the	O
n	O
examples	B
each	O
of	O
which	O
would	O
take	O
roughly	O
log	O
d	O
bits	O
to	O
send	O
this	O
gives	O
n	O
log	O
d	O
to	O
send	O
all	O
the	O
data	O
alternatively	O
you	O
could	O
first	O
cluster	O
the	O
data	O
and	O
send	O
the	O
cluster	O
centers	O
this	O
will	O
take	O
k	O
log	O
d	O
bits	O
then	O
for	O
each	O
data	O
point	O
you	O
send	O
its	O
center	O
as	O
well	O
as	O
its	O
deviation	O
from	O
that	O
center	O
it	O
turns	O
out	O
this	O
will	O
cost	O
exactly	O
lk	O
bits	O
therefore	O
the	O
bic	O
is	O
precisely	O
measuring	O
how	O
many	O
bits	O
it	O
will	O
take	O
to	O
send	O
your	O
data	O
using	O
k	O
clusters	O
the	O
k	O
that	O
minimizes	O
this	O
number	O
of	O
bits	O
is	O
the	O
optimal	O
value	O
linear	O
dimensionality	B
reduction	I
dimensionality	B
reduction	I
is	O
the	O
task	O
of	O
taking	O
a	O
dataset	O
in	O
high	O
dimensions	O
and	O
reducing	O
it	O
to	O
low	O
dimensions	O
while	O
retaining	O
the	O
important	O
characteristics	O
of	O
the	O
data	O
since	O
this	O
is	O
an	O
unsupervised	O
setting	O
the	O
notion	O
of	O
important	O
characteristics	O
is	O
difficult	O
to	O
define	O
consider	O
the	O
dataset	O
in	O
figure	O
which	O
lives	O
in	O
high	O
dimensions	O
and	O
you	O
want	O
to	O
reduce	O
to	O
low	O
dimensions	O
in	O
the	O
case	O
of	O
linear	O
dimensionality	B
reduction	I
the	O
only	O
thing	O
you	O
can	O
do	O
is	O
to	O
project	O
the	O
data	O
onto	O
a	O
vector	B
and	O
use	O
the	O
projected	O
distances	O
as	O
the	O
embeddings	O
figure	O
shows	O
a	O
projection	O
of	O
this	O
data	O
onto	O
the	O
vector	B
that	O
points	O
in	O
the	O
direction	O
of	O
maximal	O
variance	B
of	O
the	O
original	O
dataset	O
intuitively	O
this	O
is	O
a	O
reasonable	O
notion	O
of	O
importance	O
since	O
this	O
is	O
the	O
direction	O
in	O
which	O
most	O
information	O
is	O
encoded	O
in	O
the	O
data	O
for	O
the	O
rest	O
of	O
this	O
section	O
assume	O
that	O
the	O
data	O
is	O
centered	O
namely	O
the	O
mean	O
of	O
all	O
the	O
data	O
is	O
at	O
the	O
origin	O
will	O
simply	O
make	O
the	O
math	O
easier	O
suppose	O
the	O
two	O
dimensional	O
data	O
is	O
xn	O
and	O
you	O
re	O
looking	O
for	O
a	O
vector	B
u	O
that	O
points	O
in	O
the	O
direction	O
of	O
maximal	O
variance	B
you	O
can	O
compute	O
this	O
by	O
projecting	O
each	O
point	O
onto	O
u	O
and	O
looking	O
at	O
the	O
variance	B
of	O
the	O
result	O
in	O
order	O
for	O
the	O
projection	O
to	O
make	O
sense	O
you	O
need	O
to	O
constrain	O
in	O
this	O
case	O
the	O
projections	O
are	O
u	O
xn	O
u	O
call	O
these	O
values	O
pn	O
the	O
goal	O
is	O
to	O
compute	O
the	O
variance	B
of	O
the	O
and	O
then	O
choose	O
u	O
to	O
maximize	O
this	O
variance	B
to	O
compute	O
the	O
variance	B
you	O
first	O
need	O
to	O
compute	O
the	O
mean	O
because	O
the	O
mean	O
of	O
the	O
xns	O
was	O
zero	O
the	O
math	O
review	O
eigenvalues	O
and	O
eigenvectors	O
the	O
usual	O
unsupervised	B
learning	I
figure	O
mean	O
of	O
the	O
ps	O
is	O
also	O
zero	O
this	O
can	O
be	O
seen	O
as	O
follows	O
n	O
pn	O
n	O
xn	O
u	O
n	O
xn	O
u	O
u	O
the	O
variance	B
of	O
the	O
is	O
then	O
just	O
n	O
n	O
finding	O
the	O
optimal	O
u	O
the	O
perspective	O
of	O
variance	B
maximization	O
reduces	O
to	O
the	O
following	O
optimization	B
problem	I
max	O
u	O
n	O
subj	O
to	O
in	O
this	O
problem	O
it	O
becomes	O
apparent	O
why	O
keeping	O
u	O
unit	O
length	O
is	O
important	O
if	O
not	O
u	O
would	O
simply	O
stretch	O
to	O
have	O
infinite	O
length	O
to	O
maximize	O
the	O
objective	O
it	O
is	O
now	O
helpful	O
to	O
write	O
the	O
collection	O
of	O
datapoints	O
xn	O
as	O
a	O
n	O
d	O
matrix	O
x	O
if	O
you	O
take	O
this	O
matrix	O
x	O
and	O
multiply	O
it	O
by	O
u	O
which	O
has	O
dimensions	O
d	O
you	O
end	O
up	O
with	O
a	O
n	O
vector	B
whose	O
values	O
are	O
exactly	O
the	O
values	O
p	O
the	O
objective	O
in	O
eq	O
is	O
then	O
just	O
the	O
squared	O
norm	O
of	O
p	O
this	O
simplifies	O
eq	O
to	O
subj	O
to	O
max	O
u	O
where	O
the	O
constraint	O
has	O
been	O
rewritten	O
to	O
make	O
it	O
amenable	O
to	O
constructing	O
the	O
lagrangian	B
doing	O
so	O
and	O
taking	O
gradients	O
yields	O
lu	O
ul	O
u	O
u	O
u	O
you	O
can	O
solve	O
this	O
expression	O
u	O
by	O
computing	O
the	O
first	O
eigenvector	O
and	O
eigenvalue	O
of	O
the	O
matrix	O
this	O
gives	O
you	O
the	O
solution	O
to	O
a	O
projection	O
into	O
a	O
one-dimensional	O
space	O
to	O
get	O
a	O
second	O
dimension	O
you	O
want	O
to	O
find	O
a	O
new	O
vector	B
v	O
on	O
which	O
the	O
data	O
has	O
maximal	O
variance	B
however	O
to	O
avoid	O
redundancy	O
you	O
want	O
v	O
to	O
be	O
orthogonal	O
to	O
u	O
namely	O
u	O
v	O
this	O
gives	O
subj	O
to	O
and	O
u	O
v	O
max	O
v	O
following	O
the	O
same	O
procedure	O
as	O
before	O
you	O
can	O
construct	O
a	O
la	O
a	O
course	O
in	O
machine	O
learning	O
algorithm	B
pcad	O
k	O
meanx	O
x	O
d	O
x	O
k	O
uk	O
top	O
k	O
eigenvalueseigenvectors	O
of	O
d	O
return	O
u	O
compute	O
data	O
mean	O
for	O
centering	O
compute	O
covariance	O
is	O
a	O
vector	B
of	O
ones	O
grangian	O
and	O
differentiate	O
lv	O
ul	O
v	O
v	O
project	O
data	O
using	O
u	O
however	O
you	O
know	O
that	O
u	O
is	O
the	O
first	O
eigenvector	O
of	O
so	O
the	O
solution	O
to	O
this	O
problem	O
for	O
and	O
v	O
is	O
given	O
by	O
the	O
second	O
eigenvalueeigenvector	O
pair	O
of	O
repeating	O
this	O
analysis	O
inductively	O
tells	O
you	O
that	O
if	O
you	O
want	O
to	O
project	O
onto	O
k	O
mutually	O
orthogonal	O
dimensions	O
you	O
simply	O
need	O
to	O
take	O
the	O
first	O
k	O
eigenvectors	O
of	O
the	O
matrix	O
this	O
matrix	O
is	O
often	O
called	O
the	O
data	B
covariance	I
matrix	I
because	O
n	O
m	O
xnixmj	O
which	O
is	O
the	O
sample	O
covariance	O
between	O
features	B
i	O
and	O
j	O
this	O
leads	O
to	O
the	O
technique	O
of	O
principle	B
components	I
analysis	I
or	O
pca	B
for	O
completeness	O
the	O
is	O
depicted	O
in	O
algorithm	B
the	O
important	O
thing	O
to	O
note	O
is	O
that	O
the	O
eigenanalysis	O
only	O
gives	O
you	O
the	O
projection	O
directions	O
it	O
does	O
not	O
give	O
you	O
the	O
embedded	O
data	O
to	O
embed	O
a	O
data	O
point	O
x	O
you	O
need	O
to	O
compute	O
its	O
embedding	B
as	O
x	O
x	O
if	O
you	O
write	O
u	O
for	O
the	O
d	O
k	O
matrix	O
of	O
us	O
then	O
this	O
is	O
just	O
xu	O
there	O
is	O
an	O
alternative	O
derivation	O
of	O
pca	B
that	O
can	O
be	O
informative	O
based	O
on	O
reconstruction	B
error	I
consider	O
the	O
one-dimensional	O
case	O
again	O
where	O
you	O
are	O
looking	O
for	O
a	O
single	O
projection	O
direction	O
u	O
if	O
you	O
were	O
to	O
use	O
this	O
direction	O
your	O
projected	O
data	O
would	O
be	O
z	O
xu	O
each	O
zn	O
gives	O
the	O
position	O
of	O
the	O
nth	O
datapoint	O
along	O
u	O
you	O
can	O
project	O
this	O
one-dimensional	O
data	O
back	O
into	O
the	O
original	O
space	O
by	O
multiplying	O
it	O
by	O
this	O
gives	O
you	O
reconstructed	O
values	O
instead	O
of	O
maximizing	O
variance	B
you	O
might	O
instead	O
want	O
to	O
minimize	O
the	O
reconstruction	B
error	I
defined	O
by	O
definition	O
of	O
z	O
quadratic	O
rule	O
unsupervised	B
learning	I
quadratic	O
rule	O
u	O
is	O
a	O
unit	O
vector	B
c	O
join	O
constants	O
rewrite	O
last	O
term	O
minimizing	O
this	O
final	O
term	O
is	O
equivalent	O
to	O
maximizing	O
which	O
is	O
exactly	O
the	O
form	O
of	O
the	O
maximum	O
variance	B
derivation	O
of	O
pca	B
thus	O
you	O
can	O
see	O
that	O
maximizing	O
variance	B
is	O
identical	O
to	O
minimizing	O
reconstruction	B
error	I
the	O
same	O
question	O
of	O
what	O
should	O
k	O
be	O
arises	O
in	O
dimensionality	B
reduction	I
as	O
in	O
clustering	B
if	O
the	O
purpose	O
of	O
dimensionality	B
reduction	I
is	O
to	O
visualize	B
then	O
k	O
should	O
be	O
or	O
however	O
an	O
alternative	O
purpose	O
of	O
dimensionality	B
reduction	I
is	O
to	O
avoid	O
the	B
curse	I
of	I
dimensionality	I
for	O
instance	O
even	O
if	O
you	O
have	O
labeled	O
data	O
it	O
might	O
be	O
worthwhile	O
to	O
reduce	O
the	O
dimensionality	O
before	O
applying	O
supervised	O
learning	O
essentially	O
as	O
a	O
form	O
of	O
regularization	O
in	O
this	O
case	O
the	O
question	O
of	O
an	O
optimal	O
k	O
comes	O
up	O
again	O
in	O
this	O
case	O
the	O
same	O
criteria	O
and	O
bic	O
that	O
can	O
be	O
used	O
for	O
clustering	B
can	O
be	O
used	O
for	O
pca	B
the	O
only	O
difference	O
is	O
the	O
quality	O
measure	O
changes	O
from	O
a	O
sum	O
of	O
squared	O
distances	O
to	O
means	O
clustering	B
to	O
a	O
sum	O
of	O
squared	O
distances	O
to	O
original	O
data	O
points	O
pca	B
in	O
particular	O
for	O
bic	O
you	O
get	O
the	O
reconstruction	B
error	I
plus	O
k	O
log	O
d	O
for	O
aic	O
you	O
get	O
the	O
reconstruction	B
error	I
plus	O
manifolds	O
and	O
graphs	O
what	O
is	O
a	O
manifold	O
graph	B
construction	O
non-linear	B
dimensionality	B
reduction	I
isomap	O
lle	O
mvu	O
mds	O
non-linear	B
clustering	B
spectral	O
methods	O
what	O
is	O
a	O
spectrum	O
spectral	O
clustering	B
a	O
course	O
in	O
machine	O
learning	O
exercises	O
exercise	O
todo	O
expectation	B
maximization	I
learning	O
objectives	O
explain	O
the	O
relationship	O
between	O
parameters	O
and	O
hidden	B
variables	I
construct	O
generative	O
stories	O
for	O
clustering	B
and	O
dimensionality	B
reduction	I
draw	O
a	O
graph	B
explaining	O
how	O
em	O
works	O
by	O
constructing	O
convex	B
lower	O
bounds	O
implement	O
em	O
for	O
clustering	B
with	O
mixtures	O
of	O
gaussians	O
and	O
contrasting	O
it	O
with	O
k-means	O
evaluate	O
the	O
differences	O
betweem	O
em	O
and	O
gradient	B
descent	I
for	O
hidden	O
variable	O
models	O
dependencies	O
suppose	O
you	O
were	O
building	O
a	O
naive	O
bayes	O
model	B
for	O
a	O
text	B
categorization	I
problem	O
after	O
you	O
were	O
done	O
your	O
boss	O
told	O
you	O
that	O
it	O
became	O
prohibitively	O
expensive	O
to	O
obtain	O
labeled	O
data	O
you	O
now	O
have	O
a	O
probabilistic	O
model	B
that	O
assumes	O
access	O
to	O
labels	O
but	O
you	O
don	O
t	O
have	O
any	O
labels	O
can	O
you	O
still	O
do	O
something	O
amazingly	O
you	O
can	O
you	O
can	O
treat	O
the	O
labels	O
as	O
hidden	B
variables	I
and	O
attempt	O
to	O
learn	O
them	O
at	O
the	O
same	O
time	O
as	O
you	O
learn	O
the	O
parameters	O
of	O
your	O
model	B
a	O
very	O
broad	O
family	O
of	O
algorithms	O
for	O
solving	O
problems	O
just	O
like	O
this	O
is	O
the	O
expectation	B
maximization	I
family	O
in	O
this	O
chapter	O
you	O
will	O
derive	O
expectation	B
maximization	I
algorithms	O
for	O
clustering	B
and	O
dimensionality	B
reduction	I
and	O
then	O
see	O
why	O
em	O
works	O
clustering	B
with	O
a	O
mixture	O
of	O
gaussians	O
in	O
chapter	O
you	O
learned	O
about	O
probabilitic	O
models	O
for	O
classification	O
based	O
on	O
density	O
estimation	O
let	O
s	O
start	O
with	O
a	O
fairly	O
simple	O
classification	O
model	B
that	O
assumes	O
we	O
have	O
labeled	O
data	O
we	O
will	O
shortly	O
remove	O
this	O
assumption	O
our	O
model	B
will	O
state	O
that	O
we	O
have	O
k	O
classes	O
and	O
data	O
from	O
class	O
k	O
is	O
drawn	O
from	O
a	O
gaussian	O
with	O
mean	O
k	O
and	O
variance	B
k	O
the	O
choice	O
of	O
classes	O
is	O
parameterized	O
by	O
the	O
generative	B
story	I
for	O
this	O
model	B
is	O
for	O
each	O
example	O
n	O
n	O
choose	O
a	O
label	B
yn	O
disc	O
choose	O
example	O
xn	O
nor	O
yn	O
yn	O
this	O
generative	B
story	I
can	O
be	O
directly	O
translated	O
into	O
a	O
likelihood	B
as	O
before	O
pd	O
n	O
multyn	O
yn	O
yn	O
a	O
course	O
in	O
machine	O
learning	O
n	O
choose	O
label	B
yn	O
for	O
each	O
example	O
d	O
exp	O
yn	O
choose	O
feature	B
values	I
yn	O
if	O
you	O
had	O
access	O
to	O
labels	O
this	O
would	O
be	O
all	O
well	O
and	O
good	O
and	O
you	O
could	O
obtain	O
closed	O
form	O
solutions	O
for	O
the	O
maximum	O
likelihood	B
estimates	O
of	O
all	O
parameters	O
by	O
taking	O
a	O
log	O
and	O
then	O
taking	O
gradients	O
of	O
the	O
log	B
likelihood	B
k	O
fraction	O
of	O
training	O
examples	B
in	O
class	O
k	O
n	O
n	O
k	O
k	O
mean	O
of	O
training	O
examples	B
in	O
class	O
k	O
nyn	O
kxn	O
nyn	O
k	O
k	O
variance	B
of	O
training	O
examples	B
in	O
class	O
k	O
nyn	O
k	O
k	O
nyn	O
k	O
you	O
should	O
be	O
able	O
to	O
derive	O
the	O
maximum	O
likelihood	B
solution	O
results	O
formally	O
by	O
now	O
suppose	O
that	O
you	O
don	O
t	O
have	O
labels	O
analogously	O
to	O
the	O
k-means	O
algorithm	B
one	O
potential	O
solution	O
is	O
to	O
iterate	O
you	O
can	O
start	O
off	O
with	O
guesses	O
for	O
the	O
values	O
of	O
the	O
unknown	O
variables	O
and	O
then	O
iteratively	O
improve	O
them	O
over	O
time	O
in	O
k-means	O
the	O
approach	O
was	O
the	O
assign	O
examples	B
to	O
labels	O
clusters	O
this	O
time	O
instead	O
of	O
making	O
hard	O
assignments	O
example	O
belongs	O
to	O
cluster	O
we	O
ll	O
make	O
soft	B
assignments	I
example	O
belongs	O
half	O
to	O
cluster	O
a	O
quarter	O
to	O
cluster	O
and	O
a	O
quarter	O
to	O
cluster	O
so	O
as	O
not	O
to	O
confuse	O
ourselves	O
too	O
much	O
we	O
ll	O
introduce	O
a	O
new	O
variable	O
zn	O
znk	O
sums	O
to	O
one	O
to	O
denote	O
a	O
fractional	O
assignment	O
of	O
examples	B
to	O
clusters	O
this	O
notion	O
of	O
soft-assignments	O
is	O
visualized	O
in	O
figure	O
here	O
we	O
ve	O
depicted	O
each	O
example	O
as	O
a	O
pie	O
chart	O
and	O
it	O
s	O
coloring	O
denotes	O
the	O
degree	O
to	O
which	O
it	O
s	O
been	O
assigned	O
to	O
each	O
three	O
clusters	O
the	O
size	O
of	O
the	O
pie	O
pieces	O
correspond	O
to	O
the	O
zn	O
values	O
formally	O
znk	O
denotes	O
the	O
probability	O
that	O
example	O
n	O
is	O
assigned	O
to	O
cluster	O
k	O
znk	O
pyn	O
k	O
xn	O
pyn	O
k	O
xn	O
zn	O
pxn	O
multk	O
k	O
k	O
figure	O
empiecharts	O
a	O
figure	O
showing	O
pie	O
charts	O
here	O
the	O
normalizer	O
zn	O
is	O
to	O
ensure	O
that	O
zn	O
sums	O
to	O
one	O
given	O
a	O
set	O
of	O
parameters	O
s	O
s	O
and	O
the	O
fractional	B
assignments	I
znk	O
are	O
easy	O
to	O
compute	O
now	O
akin	O
to	O
k-means	O
given	O
algorithm	B
gmmx	O
k	O
expectation	B
maximization	I
randomly	O
initialize	O
mean	O
for	O
kth	O
cluster	O
initialize	O
variances	O
each	O
cluster	O
equally	O
likely	O
a	O
priori	O
for	O
k	O
to	O
k	O
do	O
k	O
some	O
random	O
location	O
k	O
k	O
end	O
for	O
repeat	O
for	O
n	O
to	O
n	O
do	O
d	O
for	O
k	O
to	O
k	O
do	O
znk	O
k	O
fractional	B
assignments	I
exp	O
k	O
k	O
end	O
for	O
zn	O
k	O
znk	O
zn	O
end	O
for	O
for	O
k	O
to	O
k	O
do	O
k	O
n	O
n	O
znk	O
k	O
n	O
znkxn	O
n	O
znk	O
k	O
n	O
znkxn	O
k	O
n	O
znk	O
end	O
for	O
until	O
converged	O
return	O
z	O
compute	O
normalize	B
fractional	B
assignments	I
re-estimate	O
prior	B
probability	O
of	O
cluster	O
k	O
re-estimate	O
mean	O
of	O
cluster	O
k	O
re-estimate	O
variance	B
of	O
cluster	O
k	O
return	O
cluster	O
assignments	O
fractional	B
assignments	I
you	O
need	O
to	O
recompute	O
estimates	O
of	O
the	O
model	B
parameters	O
in	O
analogy	O
to	O
the	O
maximum	O
likelihood	B
solution	O
you	O
can	O
do	O
this	O
by	O
counting	O
fractional	O
points	O
rather	O
than	O
full	O
points	O
this	O
gives	O
the	O
following	O
re-estimation	O
updates	O
k	O
fraction	O
of	O
training	O
examples	B
in	O
class	O
k	O
n	O
n	O
znk	O
k	O
mean	O
of	O
fractional	O
examples	B
in	O
class	O
k	O
n	O
znkxn	O
n	O
znk	O
k	O
variance	B
of	O
fractional	O
examples	B
in	O
class	O
k	O
n	O
znk	O
k	O
n	O
znk	O
all	O
that	O
has	O
happened	O
here	O
is	O
that	O
the	O
hard	O
assignments	O
k	O
have	O
been	O
replaced	O
with	O
soft	B
assignments	I
znk	O
as	O
a	O
bit	O
of	O
foreshadowing	O
of	O
what	O
is	O
to	O
come	O
what	O
we	O
ve	O
done	O
is	O
essentially	O
replace	O
known	O
labels	O
with	O
expected	O
labels	O
hence	O
the	O
name	O
expectation	B
maximization	I
putting	O
this	O
together	O
yields	O
algorithm	B
this	O
is	O
the	O
gmm	B
gaussian	B
mixture	I
models	I
algorithm	B
because	O
the	O
probabilitic	O
model	B
being	O
learned	O
describes	O
a	O
dataset	O
as	O
being	O
drawn	O
from	O
a	O
mixture	O
distribution	O
where	O
each	O
component	O
of	O
this	O
distribution	O
is	O
a	O
a	O
course	O
in	O
machine	O
learning	O
gaussian	O
just	O
as	O
in	O
the	O
k-means	O
algorithm	B
this	O
approach	O
is	O
succeptible	O
to	O
local	O
optima	O
and	O
quality	O
of	O
initialization	O
the	O
heuristics	O
for	O
computing	O
better	O
initializers	O
for	O
k-means	O
are	O
also	O
useful	O
here	O
aside	O
from	O
the	O
fact	O
that	O
gmms	O
use	O
soft	B
assignments	I
and	O
k-means	O
uses	O
hard	O
assignments	O
there	O
are	O
other	O
differences	O
between	O
the	O
two	O
approaches	O
what	O
are	O
they	O
the	O
expectation	B
maximization	I
framework	O
figure	O
emlowerbound	O
a	O
figure	O
showing	O
successive	O
lower	O
bounds	O
at	O
this	O
point	O
you	O
ve	O
seen	O
a	O
method	O
for	O
learning	O
in	O
a	O
particular	O
probabilistic	O
model	B
with	O
hidden	B
variables	I
two	O
questions	O
remain	O
can	O
you	O
apply	O
this	O
idea	O
more	O
generally	O
and	O
why	O
is	O
it	O
even	O
a	O
reasonable	O
thing	O
to	O
do	O
expectation	B
maximization	I
is	O
a	O
family	O
of	O
algorithms	O
for	O
performing	O
maximum	B
likelihood	B
estimation	I
in	O
probabilistic	O
models	O
with	O
hidden	B
variables	I
the	O
general	O
flavor	O
of	O
how	O
we	O
will	O
proceed	O
is	O
as	O
follows	O
we	O
want	O
to	O
maximize	O
the	O
log	B
likelihood	B
l	O
but	O
this	O
will	O
turn	O
out	O
to	O
be	O
difficult	O
to	O
do	O
directly	O
instead	O
we	O
ll	O
pick	O
a	O
surrogate	O
function	O
l	O
that	O
s	O
a	O
lower	O
bound	O
on	O
l	O
l	O
l	O
everywhere	O
that	O
s	O
easier	O
to	O
maximize	O
we	O
ll	O
construct	O
the	O
surrogate	O
in	O
such	O
a	O
way	O
that	O
increasing	O
it	O
will	O
force	O
the	O
true	O
likelihood	B
to	O
also	O
go	O
up	O
after	O
maximizing	O
l	O
we	O
ll	O
construct	O
a	O
new	O
lower	O
bound	O
and	O
optimize	O
that	O
this	O
process	O
is	O
shown	O
pictorially	O
in	O
figure	O
to	O
proceed	O
consider	O
an	O
arbitrary	O
probabilistic	O
model	B
px	O
y	O
where	O
x	O
denotes	O
the	O
observed	O
data	O
y	O
denotes	O
the	O
hidden	O
data	O
and	O
denotes	O
the	O
parameters	O
in	O
the	O
case	O
of	O
gaussian	B
mixture	I
models	I
x	O
was	O
the	O
data	O
points	O
y	O
was	O
the	O
labels	O
and	O
included	O
the	O
cluster	O
prior	B
probabilities	O
the	O
cluster	O
means	O
and	O
the	O
cluster	O
variances	O
now	O
given	O
access	O
only	O
to	O
a	O
number	O
of	O
examples	B
xn	O
you	O
would	O
like	O
to	O
estimate	O
the	O
parameters	O
of	O
the	O
model	B
probabilistically	O
this	O
means	O
that	O
some	O
of	O
the	O
variables	O
are	O
unknown	O
and	O
therefore	O
you	O
need	O
to	O
marginalize	O
sum	O
over	O
their	O
possible	O
values	O
now	O
your	O
data	O
consists	O
only	O
of	O
x	O
not	O
the	O
y	O
pairs	O
in	O
d	O
you	O
can	O
then	O
write	O
the	O
likelihood	B
as	O
px	O
yn	O
px	O
yn	O
yn	O
n	O
pxn	O
yn	O
n	O
yn	O
pxn	O
yn	O
marginalization	O
examples	B
are	O
independent	O
algebra	O
at	O
this	O
point	O
the	O
natural	O
thing	O
to	O
do	O
is	O
to	O
take	O
logs	O
and	O
then	O
start	O
taking	O
gradients	O
however	O
once	O
you	O
start	O
taking	O
logs	O
you	O
run	O
into	O
a	O
problem	O
the	O
log	O
cannot	O
eat	O
the	O
sum	O
pxn	O
yn	O
lx	O
n	O
log	O
yn	O
expectation	B
maximization	I
the	O
next	O
step	O
is	O
to	O
apply	O
the	O
somewhat	O
strange	O
but	O
strangely	O
namely	O
the	O
log	O
gets	O
stuck	O
outside	O
the	O
sum	O
and	O
cannot	O
move	O
in	O
to	O
decompose	O
the	O
rest	O
of	O
the	O
likelihood	B
term	O
useful	O
trick	O
of	O
multiplying	O
by	O
in	O
particular	O
let	O
q	O
be	O
an	O
arbitrary	O
probability	O
distribution	O
we	O
will	O
multiply	O
the	O
p	O
term	O
above	O
by	O
qynqyn	O
a	O
valid	O
step	O
so	O
long	O
as	O
q	O
is	O
never	O
zero	O
this	O
leads	O
to	O
lx	O
n	O
log	O
yn	O
qyn	O
pxn	O
yn	O
qyn	O
we	O
will	O
now	O
construct	O
a	O
lower	O
bound	O
using	O
jensen	O
s	O
inequality	O
this	O
is	O
a	O
very	O
useful	O
easy	O
to	O
prove	O
result	O
that	O
states	O
that	O
f	O
i	O
ixi	O
i	O
i	O
f	O
so	O
long	O
as	O
i	O
for	O
all	O
i	O
i	O
i	O
and	O
f	O
is	O
concave	B
if	O
this	O
looks	O
familiar	O
that	O
s	O
just	O
because	O
it	O
s	O
a	O
direct	O
result	O
of	O
the	O
definition	O
of	O
concavity	B
recall	B
that	O
f	O
is	O
concave	B
if	O
f	O
by	O
a	O
f	O
b	O
f	O
whenever	O
a	O
b	O
you	O
can	O
now	O
apply	O
jensen	O
s	O
inequality	O
to	O
the	O
log	B
likelihood	B
by	O
identifying	O
the	O
list	O
of	O
qyns	O
as	O
the	O
s	O
log	O
as	O
f	O
is	O
indeed	O
concave	B
and	O
each	O
x	O
as	O
the	O
pq	O
term	O
this	O
yields	O
prove	O
jensen	O
s	O
inequality	O
using	O
the	O
definition	O
of	O
concavity	B
and	O
induction	B
pxn	O
yn	O
lx	O
n	O
n	O
lx	O
yn	O
yn	O
qyn	O
log	O
qyn	O
log	O
pxn	O
yn	O
qyn	O
log	O
qyn	O
qyn	O
note	O
that	O
this	O
inequality	O
holds	O
for	O
any	O
choice	O
of	O
function	O
q	O
so	O
long	O
as	O
its	O
non-negative	O
and	O
sums	O
to	O
one	O
in	O
particular	O
it	O
needn	O
t	O
even	O
by	O
the	O
same	O
function	O
q	O
for	O
each	O
n	O
we	O
will	O
need	O
to	O
take	O
advantage	O
of	O
both	O
of	O
these	O
properties	O
we	O
have	O
succeeded	O
in	O
our	O
first	O
goal	O
constructing	O
a	O
lower	O
bound	O
on	O
l	O
when	O
you	O
go	O
to	O
optimize	O
this	O
lower	O
bound	O
for	O
the	O
only	O
part	O
that	O
matters	O
is	O
the	O
first	O
term	O
the	O
second	O
term	O
q	O
log	O
q	O
drops	O
out	O
as	O
a	O
function	O
of	O
this	O
means	O
that	O
the	O
the	O
maximization	O
you	O
need	O
to	O
be	O
able	O
to	O
compute	O
for	O
fixed	O
qns	O
is	O
arg	O
max	O
n	O
yn	O
qnyn	O
log	O
pxn	O
yn	O
this	O
is	O
exactly	O
the	O
sort	O
of	O
maximization	O
done	O
for	O
gaussian	B
mixture	I
models	I
when	O
we	O
recomputed	O
new	O
means	O
variances	O
and	O
cluster	O
prior	B
probabilities	O
a	O
course	O
in	O
machine	O
learning	O
the	O
second	O
question	O
is	O
what	O
should	O
qn	O
actually	O
be	O
any	O
rea	O
sonable	O
q	O
will	O
lead	O
to	O
a	O
lower	O
bound	O
so	O
in	O
order	O
to	O
choose	O
one	O
q	O
over	O
another	O
we	O
need	O
another	O
criterion	O
recall	B
that	O
we	O
are	O
hoping	O
to	O
maximize	O
l	O
by	O
instead	O
maximizing	O
a	O
lower	O
bound	O
in	O
order	O
to	O
ensure	O
that	O
an	O
increase	O
in	O
the	O
lower	O
bound	O
implies	O
an	O
increase	O
in	O
l	O
we	O
need	O
to	O
ensure	O
that	O
lx	O
lx	O
in	O
words	O
l	O
should	O
be	O
a	O
lower	O
bound	O
on	O
l	O
that	O
makes	O
contact	O
at	O
the	O
current	O
point	O
this	O
is	O
shown	O
in	O
figure	O
including	O
a	O
case	O
where	O
the	O
lower	O
bound	O
does	O
not	O
make	O
contact	O
and	O
thereby	O
does	O
not	O
guarantee	O
an	O
increase	O
in	O
l	O
with	O
an	O
increase	O
in	O
l	O
em	O
versus	O
gradient	B
descent	I
computing	O
gradients	O
through	O
marginals	O
step	O
size	O
dimensionality	B
reduction	I
with	O
probabilistic	O
pca	B
derivation	O
advantages	O
over	O
pca	B
exercises	O
exercise	O
todo	O
semi-supervised	B
learning	I
you	O
may	O
find	O
yourself	O
in	O
a	O
setting	O
where	O
you	O
have	O
access	O
to	O
some	O
labeled	O
data	O
and	O
some	O
unlabeled	O
data	O
you	O
would	O
like	O
to	O
use	O
the	O
labeled	O
data	O
to	O
learn	O
a	O
classifier	O
but	O
it	O
seems	O
wasteful	O
to	O
throw	O
out	O
all	O
that	O
unlabeled	O
data	O
the	O
key	O
question	O
is	O
what	O
can	O
you	O
do	O
with	O
that	O
unlabeled	O
data	O
to	O
aid	O
learning	O
and	O
what	O
assumptions	O
do	O
we	O
have	O
to	O
make	O
in	O
order	O
for	O
this	O
to	O
be	O
helpful	O
one	O
idea	O
is	O
to	O
try	O
to	O
use	O
the	O
unlabeled	O
data	O
to	O
learn	O
a	O
better	O
decision	B
boundary	I
in	O
a	O
discriminative	O
setting	O
you	O
can	O
accomplish	O
this	O
by	O
trying	O
to	O
find	O
decision	O
boundaries	O
that	O
don	O
t	O
pass	O
too	O
closely	O
to	O
unlabeled	O
data	O
in	O
a	O
generative	O
setting	O
you	O
can	O
simply	O
treat	O
some	O
of	O
the	O
labels	O
as	O
observed	O
and	O
some	O
as	O
hidden	O
this	O
is	O
semi-supervised	B
learning	I
an	O
alternative	O
idea	O
is	O
to	O
spend	O
a	O
small	O
amount	O
of	O
money	O
to	O
get	O
labels	O
for	O
some	O
subset	O
of	O
the	O
unlabeled	O
data	O
however	O
you	O
would	O
like	O
to	O
get	O
the	O
most	O
out	O
of	O
your	O
money	O
so	O
you	O
would	O
only	O
like	O
to	O
pay	O
for	O
labels	O
that	O
are	O
useful	O
this	O
is	O
active	B
learning	I
learning	O
objectives	O
explain	O
the	O
cluster	O
assumption	O
for	O
semi-supervised	O
discriminative	O
learning	O
and	O
why	O
it	O
is	O
necessary	O
dervive	O
an	O
em	O
algorithm	B
for	O
generative	O
semi-supervised	O
text	B
categorization	I
compare	O
and	O
contrast	O
the	O
query	O
by	O
uncertainty	O
and	O
query	O
by	O
committee	O
heuristics	O
for	O
active	B
learning	I
dependencies	O
em	O
for	O
semi-supervised	B
learning	I
naive	O
bayes	O
model	B
graph-based	O
semi-supervised	B
learning	I
key	O
assumption	O
graphs	O
and	O
manifolds	O
label	B
prop	O
loss-based	O
semi-supervised	B
learning	I
density	O
assumption	O
loss	B
function	I
non-convex	B
a	O
course	O
in	O
machine	O
learning	O
active	B
learning	I
motivation	O
qbc	O
qbu	O
dangers	O
of	O
semi-supervised	O
learing	O
unlab	O
overwhelms	O
lab	O
biased	O
data	O
from	O
active	O
exercises	O
exercise	O
todo	O
exercises	O
exercise	O
todo	O
graphical	O
models	O
learning	O
objectives	O
foo	O
dependencies	O
none	O
online	B
learning	I
learning	O
objectives	O
explain	O
the	O
experts	O
model	B
and	O
why	O
it	O
is	O
hard	O
even	O
to	O
compete	O
with	O
the	O
single	O
best	O
expert	O
define	O
what	O
it	O
means	O
for	O
an	O
online	B
learning	I
algorithm	B
to	O
have	O
no	O
regret	O
implement	O
the	O
follow-the-leader	O
algorithm	B
categorize	O
online	B
learning	I
algo	O
rithms	O
in	O
terms	O
of	O
how	O
they	O
measure	O
changes	O
in	O
parameters	O
and	O
how	O
they	O
measure	O
error	O
dependencies	O
all	O
of	O
the	O
learning	O
algorithms	O
that	O
you	O
know	O
about	O
at	O
this	O
point	O
are	O
based	O
on	O
the	O
idea	O
of	O
training	O
a	O
model	B
on	O
some	O
data	O
and	O
evaluating	O
it	O
on	O
other	O
data	O
this	O
is	O
the	O
batch	B
learning	I
model	B
however	O
you	O
may	O
find	O
yourself	O
in	O
a	O
situation	O
where	O
students	O
are	O
constantly	O
rating	O
courses	O
and	O
also	O
constantly	O
asking	O
for	O
recommendations	O
online	B
learning	I
focuses	O
on	O
learning	O
over	O
a	O
stream	O
of	O
data	O
on	O
which	O
you	O
have	O
to	O
make	O
predictions	O
continually	O
you	O
have	O
actually	O
already	O
seen	O
an	O
example	O
of	O
an	O
online	B
learning	I
algorithm	B
the	O
perceptron	B
however	O
our	O
use	O
of	O
the	O
perceptron	B
and	O
our	O
analysis	O
of	O
its	O
performance	O
have	O
both	O
been	O
in	O
a	O
batch	B
setting	O
in	O
this	O
chapter	O
you	O
will	O
see	O
a	O
formalization	O
of	O
online	B
learning	I
differs	O
from	O
the	O
batch	B
learning	I
formalization	O
and	O
several	O
algorithms	O
for	O
online	B
learning	I
with	O
different	O
properties	O
online	B
learning	I
framework	O
regret	O
follow	O
the	O
leader	O
agnostic	O
learning	O
algorithm	B
versus	O
problem	O
learning	O
with	O
features	B
change	O
but	O
not	O
too	O
much	O
littlestone	O
analysis	O
for	O
gd	O
and	O
egd	O
passive	O
agressive	O
learning	O
pa	O
algorithm	B
online	B
analysis	O
online	B
learning	I
learning	O
with	O
lots	O
of	O
irrelevant	O
features	B
winnow	O
relationship	O
to	O
egd	O
exercises	O
exercise	O
todo	O
structured	O
learning	O
tasks	O
learning	O
objectives	O
todo	O
hidden	O
markov	O
models	O
viterbi	O
hidden	O
markov	O
models	O
forward-backward	O
maximum	O
entropy	O
markov	O
models	O
structured	O
perceptronn	O
conditional	O
random	O
fields	O
exercises	O
exercise	O
todo	O
dependencies	O
exercises	O
exercise	O
todo	O
bayesian	O
learning	O
learning	O
objectives	O
todo	O
dependencies	O
code	O
and	O
datasets	O
rating	O
easy	O
ai	O
sys	O
thy	O
morning	O
y	O
y	O
n	O
n	O
n	O
y	O
y	O
n	O
n	O
y	O
n	O
y	O
y	O
n	O
n	O
y	O
n	O
n	O
y	O
y	O
y	O
y	O
y	O
n	O
y	O
y	O
y	O
y	O
n	O
n	O
y	O
y	O
y	O
n	O
n	O
n	O
n	O
y	O
n	O
n	O
n	O
n	O
n	O
n	O
y	O
n	O
n	O
n	O
n	O
n	O
n	O
y	O
y	O
y	O
y	O
y	O
y	O
y	O
y	O
y	O
y	O
y	O
n	O
y	O
n	O
n	O
y	O
y	O
n	O
y	O
y	O
y	O
n	O
y	O
n	O
n	O
y	O
n	O
n	O
n	O
n	O
n	O
n	O
n	O
y	O
n	O
n	O
n	O
y	O
y	O
n	O
y	O
y	O
n	O
y	O
y	O
n	O
y	O
n	O
y	O
notation	O
bibliography	O
sergey	O
brin	O
near	O
neighbor	O
search	O
in	O
large	O
metric	O
spaces	O
in	O
conference	O
on	O
very	O
large	O
databases	O
tom	O
m	O
mitchell	O
machine	O
learning	O
mcgraw	O
hill	O
frank	O
rosenblatt	O
the	O
perceptron	B
a	O
probabilistic	O
model	B
for	O
information	O
storage	O
and	O
organization	O
in	O
the	O
brain	O
psychological	O
review	O
reprinted	O
in	O
neurocomputing	O
press	O
index	O
k-nearest	B
neighbors	I
p-norms	B
loss	O
absolute	B
loss	I
activation	B
function	I
activations	B
active	B
learning	I
adaboost	B
algorithm	B
all	B
pairs	I
all	B
versus	I
all	I
architecture	B
selection	I
area	B
under	I
the	I
curve	I
auc	B
ava	B
averaged	B
perceptron	B
back-propagation	B
bag	B
of	I
words	I
bagging	B
base	B
learner	I
batch	B
batch	B
learning	I
bayes	B
error	B
rate	I
bayes	B
optimal	I
classifier	I
bayes	B
optimal	I
error	B
rate	I
bernouilli	B
distribution	I
bias	B
binary	B
features	B
bipartite	B
ranking	I
problems	I
boosting	B
bootstrap	B
resampling	I
bootstrapping	B
categorical	B
features	B
chain	B
rule	I
chord	B
circuit	B
complexity	B
clustering	B
clustering	B
quality	I
collective	B
classification	I
complexity	B
concave	B
concavity	B
concept	B
confidence	B
intervals	I
constrained	B
optimization	B
problem	I
contour	B
convergence	B
rate	I
convex	B
cross	B
validation	I
cubic	B
feature	I
map	I
curvature	B
data	B
covariance	I
matrix	I
data	B
generating	I
distribution	I
decision	B
boundary	I
decision	B
stump	I
decision	B
tree	I
decision	B
trees	I
development	B
data	I
dimensionality	B
reduction	I
discrete	B
distribution	I
distance	B
dominates	B
dot	B
product	I
dual	B
problem	I
dual	B
variables	I
early	B
stopping	I
embedding	B
ensemble	B
error	B
driven	I
error	B
rate	I
euclidean	B
distance	B
evidence	B
example	B
normalization	I
examples	B
expectation	B
maximization	I
expected	B
loss	I
exponential	B
loss	I
feasible	B
region	I
feature	B
combinations	I
feature	B
mapping	I
feature	B
normalization	I
feature	B
scale	I
feature	B
space	I
feature	B
values	I
feature	B
vector	B
features	B
forward-propagation	B
fractional	B
assignments	I
furthest-first	B
heuristic	I
gaussian	B
distribution	I
gaussian	B
kernel	B
gaussian	B
mixture	I
models	I
generalize	B
generative	B
story	I
geometric	B
view	I
global	B
minimum	I
gmm	B
gradient	B
gradient	B
ascent	I
gradient	B
descent	I
graph	B
hard-margin	B
svm	I
hash	B
kernel	B
held-out	B
data	I
hidden	B
units	I
hidden	B
variables	I
hinge	B
loss	I
histogram	B
a	O
course	O
in	O
machine	O
learning	O
hyperbolic	B
tangent	I
hypercube	B
hyperparameter	B
hyperplane	B
hyperspheres	B
hypothesis	B
hypothesis	B
class	I
hypothesis	B
testing	I
i	O
i	O
d	O
assumption	O
imbalanced	B
data	I
importance	B
weight	I
independently	B
independently	B
and	O
identically	O
dis	O
tributed	B
indicator	B
function	I
induce	B
induced	B
distribution	I
induction	B
inductive	B
bias	B
iteration	B
jack-knifing	B
jensen	O
s	O
inequality	O
joint	B
k-nearest	B
neighbors	I
karush-kuhn-tucker	B
conditions	I
kernel	B
kernel	B
trick	I
kernels	B
kkt	B
conditions	I
label	B
lagrange	B
multipliers	I
lagrange	B
variable	I
lagrangian	B
layer-wise	B
leave-one-out	B
cross	B
validation	I
level-set	B
license	B
likelihood	B
linear	B
classifier	I
linear	B
classifiers	I
linear	B
decision	B
boundary	I
linear	B
regression	I
linearly	B
separable	I
link	B
function	I
log	B
likelihood	B
log	B
posterior	B
log	B
probability	I
log-likelihood	B
ratio	I
logarithmic	B
transformation	I
logistic	B
loss	I
logistic	B
regression	I
loo	B
cross	B
validation	I
loss	B
function	I
margin	B
margin	B
of	I
a	I
data	I
set	I
marginal	B
likelihood	B
maximum	B
a	I
posteriori	I
maximum	B
depth	I
maximum	B
likelihood	B
estimation	I
mercer	O
s	O
condition	O
model	B
modeling	B
multi-layer	B
network	I
naive	B
bayes	I
assumption	I
nearest	B
neighbor	I
neural	B
network	I
neural	B
networks	I
neurons	B
noise	B
non-convex	B
non-linear	B
normal	B
distribution	I
normalize	B
null	B
hypothesis	B
objective	B
function	I
one	B
versus	I
all	I
one	B
versus	I
rest	I
online	B
online	B
learning	I
optimization	B
problem	I
output	B
unit	I
ova	B
overfitting	B
oversample	B
p-value	B
pac	B
paired	B
t-test	B
parametric	B
test	I
parity	B
function	I
patch	B
representation	I
pca	B
perceptron	B
perpendicular	B
pixel	B
representation	I
polynomial	B
kernels	B
positive	B
semi-definite	I
posterior	B
precision	B
precisionrecall	O
curves	O
predict	B
preference	B
function	I
primal	B
variables	I
principle	B
components	I
analysis	I
prior	B
probabilistic	B
modeling	B
probably	B
approximately	I
correct	I
projected	B
gradient	B
psd	B
radial	B
basis	I
function	I
random	B
forests	I
rbf	B
kernel	B
rbf	B
network	I
recall	B
receiver	B
operating	I
characteristic	I
reconstruction	B
error	I
reductions	B
redundant	B
features	B
regularized	B
objective	I
regularizer	B
representer	B
theorem	I
roc	B
curve	I
sample	B
complexity	B
semi-supervised	B
learning	I
sensitivity	B
separating	B
hyperplane	B
sgd	B
shallow	B
decision	B
tree	I
shape	B
representation	I
sigmoid	B
sigmoid	B
function	I
sigmoid	B
network	I
sign	B
single-layer	B
network	I
slack	B
slack	B
parameters	I
smoothed	B
analysis	I
soft	B
assignments	I
soft-margin	B
svm	I
span	B
sparse	B
specificity	B
squared	B
loss	I
stacking	B
stacktest	B
statistical	B
inference	I
statistically	B
significant	I
stochastic	B
gradient	B
descent	I
stochastic	B
optimization	I
strong	B
learner	I
strong	B
learning	I
algorithm	B
strongly	B
convex	B
structural	B
risk	I
minimization	I
sub-sampling	B
subderivative	B
subgradient	B
subgradient	B
descent	I
support	B
vector	B
machine	I
support	B
vectors	I
surrogate	B
loss	I
symmetric	B
modes	I
t-test	B
test	B
data	I
test	B
error	I
test	B
set	I
text	B
categorization	I
the	B
curse	I
of	I
dimensionality	I
threshold	B
tikhonov	B
regularization	I
training	B
data	I
training	B
error	I
trucated	B
gradients	I
two-layer	B
network	I
unbiased	B
underfitting	B
unit	B
hypercube	B
unsupervised	B
learning	I
index	O
validation	B
data	I
vapnik-chernovenkis	B
dimension	I
variance	B
vc	B
dimension	I
vector	B
visualize	B
vote	B
voted	B
perceptron	B
voting	B
weak	B
learner	I
weak	B
learning	I
algorithm	B
weighted	B
nearest	I
neighbors	I
weights	B
zeroone	O
loss	O
