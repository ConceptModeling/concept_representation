a	O
brief	O
introduction	O
to	O
neural	O
networks	O
david	O
kriesel	O
dkriesel	O
com	O
download	O
locationhttpwww	O
dkriesel	O
comenscienceneural	O
networksnew	O
for	O
the	O
programmers	O
scalable	O
and	O
efficient	O
nn	O
framework	O
written	O
in	O
java	O
httpwww	O
dkriesel	O
comentechsnipe	O
dkriesel	O
com	O
in	O
remembrance	O
of	O
dr	O
peter	O
kemp	O
notary	O
bonn	O
germany	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
iii	O
a	O
small	O
preface	O
this	O
work	O
has	O
been	O
prepared	O
in	O
the	O
framework	O
of	O
a	O
seminar	O
of	O
the	O
university	O
of	O
bonn	O
in	O
germany	O
but	O
it	O
has	O
been	O
and	O
will	O
be	O
extended	O
being	O
presented	O
and	O
published	O
online	B
under	O
www	O
dkriesel	O
com	O
on	O
first	O
and	O
foremost	O
to	O
provide	O
a	O
comprehensive	O
overview	O
of	O
the	O
subject	O
of	O
neural	O
networks	O
and	O
second	O
just	O
to	O
acquire	O
more	O
and	O
more	O
knowledge	O
about	O
latex	O
and	O
who	O
knows	O
maybe	O
one	O
day	O
this	O
summary	O
will	O
become	O
a	O
real	O
preface	O
abstract	O
of	O
this	O
work	O
end	O
of	O
the	O
above	O
abstract	O
has	O
not	O
yet	O
become	O
a	O
preface	O
but	O
at	O
least	O
a	O
little	O
preface	O
ever	O
since	O
the	O
extended	O
text	O
pages	O
long	O
has	O
turned	O
out	O
to	O
be	O
a	O
download	O
hit	O
ambition	O
and	O
intention	O
of	O
this	O
manuscript	O
the	O
entire	O
text	O
is	O
written	O
and	O
laid	O
out	O
more	O
effectively	O
and	O
with	O
more	O
illustrations	O
than	O
before	O
i	O
did	O
all	O
the	O
illustrations	O
myself	O
most	O
of	O
them	O
directly	O
in	O
latex	O
by	O
using	O
xypic	O
they	O
reflect	O
what	O
i	O
would	O
have	O
liked	O
to	O
see	O
when	O
becoming	O
acquainted	O
with	O
the	O
subject	O
text	O
and	O
illustrations	O
should	O
be	O
memorable	O
and	O
easy	O
to	O
understand	O
to	O
offer	O
as	O
many	O
people	O
as	O
possible	O
access	O
to	O
the	O
field	O
of	O
neural	O
networks	O
nevertheless	O
the	O
mathematically	O
and	O
formally	O
skilled	O
readers	O
will	O
be	O
able	O
to	O
under	O
stand	O
the	O
definitions	O
without	O
reading	O
the	O
running	O
text	O
while	O
the	O
opposite	O
holds	O
for	O
readers	O
only	O
interested	O
in	O
the	O
subject	O
matter	O
everything	O
is	O
explained	O
in	O
both	O
colloquial	O
and	O
formal	O
language	O
please	O
let	O
me	O
know	O
if	O
you	O
find	O
out	O
that	O
i	O
have	O
violated	O
this	O
principle	O
the	O
sections	O
of	O
this	O
text	O
are	O
mostly	O
independent	O
from	O
each	O
other	O
the	O
document	O
itself	O
is	O
divided	O
into	O
different	O
parts	O
which	O
are	O
again	O
divided	O
into	O
chapters	O
although	O
the	O
chapters	O
contain	O
cross-references	O
they	O
are	O
also	O
individually	O
accessible	O
to	O
readers	O
with	O
little	O
previous	O
knowledge	O
there	O
are	O
larger	O
and	O
smaller	O
chapters	O
while	O
the	O
larger	O
chapters	O
should	O
provide	O
profound	O
insight	O
into	O
a	O
paradigm	O
of	O
neural	O
networks	O
the	O
classic	O
neural	B
network	I
structure	O
the	O
perceptron	B
and	O
its	O
learning	O
procedures	O
the	O
smaller	O
chapters	O
give	O
a	O
short	O
overview	O
but	O
this	O
is	O
also	O
ex	O
v	O
dkriesel	O
com	O
the	O
original	O
high-performance	O
simulation	O
design	O
goal	O
those	O
of	O
you	O
who	O
are	O
up	O
for	O
learning	O
by	O
doing	O
andor	O
have	O
to	O
use	O
a	O
fast	O
and	O
stable	O
neural	O
networks	O
implementation	O
for	O
some	O
reasons	O
should	O
definetely	O
have	O
a	O
look	O
at	O
snipe	O
however	O
the	O
aspects	O
covered	O
by	O
snipe	O
are	O
not	O
entirely	O
congruent	O
with	O
those	O
covered	O
by	O
this	O
manuscript	O
some	O
of	O
the	O
kinds	O
of	O
neural	O
networks	O
are	O
not	O
supported	O
by	O
snipe	O
while	O
when	O
it	O
comes	O
to	O
other	O
kinds	O
of	O
neural	O
networks	O
snipe	O
may	O
have	O
lots	O
and	O
lots	O
more	O
capabilities	O
than	O
may	O
ever	O
be	O
covered	O
in	O
the	O
manuscript	O
in	O
the	O
form	O
of	O
practical	O
hints	O
anyway	O
in	O
my	O
experience	O
almost	O
all	O
of	O
the	O
implementation	O
requirements	O
of	O
my	O
readers	O
are	O
covered	O
well	O
on	O
the	O
snipe	O
download	O
page	O
look	O
for	O
the	O
section	O
started	O
with	O
snipe	O
you	O
will	O
find	O
an	O
easy	O
step-by-step	O
guide	O
concerning	O
snipe	O
and	O
its	O
documentation	O
as	O
well	O
as	O
some	O
examples	O
snipe	O
this	O
manuscript	O
frequently	O
incorporates	O
snipe	O
shaded	O
snipe-paragraphs	O
like	O
this	O
one	O
are	O
scattered	O
among	O
large	O
parts	O
of	O
the	O
manuscript	O
providing	O
information	O
on	O
how	O
to	O
implement	O
their	O
context	B
in	O
snipe	O
this	O
also	O
implies	O
that	O
those	O
who	O
do	O
not	O
want	O
to	O
use	O
snipe	O
just	O
have	O
to	O
skip	O
the	O
shaded	O
snipeparagraphs	O
the	O
snipe-paragraphs	O
assume	O
the	O
reader	O
has	O
had	O
a	O
close	O
look	O
at	O
the	O
started	O
with	O
snipe	O
section	O
often	O
class	O
names	O
are	O
used	O
as	O
snipe	O
consists	O
of	O
only	O
a	O
few	O
different	O
packages	O
i	O
omitted	O
the	O
package	O
names	O
within	O
the	O
qualified	O
class	O
names	O
for	O
the	O
sake	O
of	O
readability	O
plained	O
in	O
the	O
introduction	O
of	O
each	O
chapter	O
in	O
addition	O
to	O
all	O
the	O
definitions	O
and	O
explanations	O
i	O
have	O
included	O
some	O
excursuses	O
to	O
provide	O
interesting	O
information	O
not	O
directly	O
related	O
to	O
the	O
subject	O
unfortunately	O
i	O
was	O
not	O
able	O
to	O
find	O
free	O
german	O
sources	O
that	O
are	O
multi-faceted	O
in	O
respect	O
of	O
content	O
the	O
paradigms	O
of	O
neural	O
networks	O
and	O
nevertheless	O
written	O
in	O
coherent	O
style	O
the	O
aim	O
of	O
this	O
work	O
is	O
if	O
it	O
could	O
not	O
be	O
fulfilled	O
at	O
first	O
go	O
to	O
close	O
this	O
gap	O
bit	O
by	O
bit	O
and	O
to	O
provide	O
easy	O
access	O
to	O
the	O
subject	O
want	O
to	O
learn	O
not	O
only	O
by	O
reading	O
but	O
also	O
by	O
coding	O
use	O
snipe	O
is	O
a	O
well-documented	O
java	O
library	O
that	O
implements	O
a	O
framework	O
for	O
neural	O
networks	O
in	O
a	O
speedy	O
feature-rich	O
and	O
usable	O
way	O
it	O
is	O
available	O
at	O
no	O
cost	O
for	O
non-commercial	O
purposes	O
it	O
was	O
originally	O
designed	O
for	O
high	O
performance	O
simulations	O
with	O
lots	O
and	O
lots	O
of	O
neural	O
networks	O
large	O
ones	O
being	O
trained	O
simultaneously	O
recently	O
i	O
decided	O
to	O
give	O
it	O
away	O
as	O
a	O
professional	O
reference	O
implementation	O
that	O
covers	O
network	O
aspects	O
handled	O
within	O
this	O
work	O
while	O
at	O
the	O
same	O
time	O
being	O
faster	O
and	O
more	O
efficient	O
than	O
lots	O
of	O
other	O
implementations	O
due	O
to	O
scalable	O
and	O
generalized	O
neural	O
information	B
processing	I
engine	O
downloadable	O
at	O
httpwww	O
dkriesel	O
comtechsnipe	O
online	B
javadoc	O
at	O
httpsnipe	O
dkriesel	O
com	O
vi	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
it	O
s	O
easy	O
to	O
print	O
this	O
manuscript	O
this	O
text	O
is	O
completely	O
illustrated	O
in	O
color	O
but	O
it	O
can	O
also	O
be	O
printed	O
as	O
is	O
in	O
monochrome	O
the	O
colors	O
of	O
figures	O
tables	O
and	O
text	O
are	O
well-chosen	O
so	O
that	O
in	O
addition	O
to	O
an	O
appealing	O
design	O
the	O
colors	O
are	O
still	O
easy	O
to	O
distinguish	O
when	O
printed	O
in	O
monochrome	O
there	O
are	O
many	O
tools	O
directly	O
integrated	O
into	O
the	O
text	O
different	O
aids	O
are	O
directly	O
integrated	O
in	O
the	O
document	O
to	O
make	O
reading	O
more	O
flexible	O
however	O
anyone	O
me	O
who	O
prefers	O
reading	O
words	O
on	O
paper	O
rather	O
than	O
on	O
screen	O
can	O
also	O
enjoy	O
some	O
features	O
in	O
the	O
table	O
of	O
contents	O
different	O
types	O
of	O
chapters	O
are	O
marked	O
different	O
types	O
of	O
chapters	O
are	O
directly	O
marked	O
within	O
the	O
table	O
of	O
contents	O
chapters	O
that	O
are	O
marked	O
as	O
are	O
definitely	O
ones	O
to	O
read	O
because	O
almost	O
all	O
subsequent	O
chapters	O
heavily	O
depend	O
on	O
them	O
other	O
chapters	O
additionally	O
depend	O
on	O
information	O
given	O
in	O
other	O
chapters	O
which	O
then	O
is	O
marked	O
in	O
the	O
table	O
of	O
contents	O
too	O
speaking	O
headlines	O
throughout	O
the	O
text	O
short	O
ones	O
in	O
the	O
table	O
of	O
contents	O
the	O
whole	O
manuscript	O
is	O
now	O
pervaded	O
by	O
such	O
headlines	O
speaking	O
headlines	O
are	O
not	O
just	O
title-like	O
learning	O
but	O
centralize	O
the	O
information	O
given	O
in	O
the	O
associated	O
section	O
to	O
a	O
single	O
sentence	O
in	O
the	O
named	O
instance	O
an	O
appropriate	O
headline	O
would	O
be	O
learning	O
methods	O
provide	O
feedback	O
to	O
the	O
network	O
whether	O
it	O
behaves	O
good	O
or	O
bad	O
however	O
such	O
long	O
headlines	O
would	O
bloat	O
the	O
table	O
of	O
contents	O
in	O
an	O
unacceptable	O
way	O
so	O
i	O
used	O
short	O
titles	O
like	O
the	O
first	O
one	O
in	O
the	O
table	O
of	O
contents	O
and	O
speaking	O
ones	O
like	O
the	O
latter	O
throughout	O
the	O
text	O
marginal	O
notes	O
are	O
a	O
navigational	O
aid	O
the	O
entire	O
document	O
contains	O
marginal	O
notes	O
in	O
colloquial	O
language	O
the	O
exam-	O
hypertext	O
ple	O
in	O
the	O
margin	O
allowing	O
you	O
to	O
on	O
paper	O
the	O
document	O
quickly	O
to	O
find	O
a	O
certain	O
passage	O
in	O
the	O
text	O
the	O
titles	O
new	O
mathematical	O
symbols	O
are	O
marked	O
by	O
specific	B
marginal	O
notes	O
for	O
easy	O
finding	O
the	O
example	O
for	O
x	O
in	O
the	O
margin	O
there	O
are	O
several	O
kinds	O
of	O
indexing	O
this	O
document	O
contains	O
different	O
types	O
of	O
indexing	O
if	O
you	O
have	O
found	O
a	O
word	O
in	O
the	O
index	O
and	O
opened	O
the	O
corresponding	O
page	O
you	O
can	O
easily	O
find	O
it	O
by	O
searching	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
vii	O
dkriesel	O
com	O
for	O
highlighted	O
text	O
all	O
indexed	O
words	O
are	O
highlighted	O
like	O
this	O
mathematical	O
symbols	O
appearing	O
in	O
several	O
chapters	O
of	O
this	O
document	O
for	O
an	O
output	B
neuron	B
i	O
tried	O
to	O
maintain	O
a	O
consistent	O
nomenclature	O
for	O
regularly	O
recurring	O
elements	O
are	O
separately	O
indexed	O
under	O
symbols	O
so	O
they	O
can	O
easily	O
be	O
assigned	O
to	O
the	O
corresponding	O
term	O
names	O
of	O
persons	O
written	O
in	O
small	O
caps	O
are	O
indexed	O
in	O
the	O
category	O
and	O
ordered	O
by	O
the	O
last	O
names	O
you	O
must	O
maintain	O
the	O
author	O
s	O
attribution	O
of	O
the	O
document	O
at	O
all	O
times	O
you	O
may	O
not	O
use	O
the	O
attribution	O
to	O
imply	O
that	O
the	O
author	O
endorses	O
you	O
or	O
your	O
document	O
use	O
for	O
i	O
m	O
no	O
lawyer	O
the	O
above	O
bullet-point	O
summary	O
is	O
just	O
informational	O
if	O
there	O
is	O
any	O
conflict	O
in	O
interpretation	O
between	O
the	O
summary	O
and	O
the	O
actual	O
license	O
the	O
actual	O
license	O
always	O
takes	O
precedence	O
note	O
that	O
this	O
license	O
does	O
not	O
extend	O
to	O
the	O
source	O
files	O
used	O
to	O
produce	O
the	O
document	O
those	O
are	O
still	O
mine	O
terms	O
of	O
use	O
and	O
license	O
beginning	O
with	O
the	O
epsilon	O
edition	O
the	O
text	O
is	O
licensed	O
under	O
the	O
creative	O
commons	O
attribution-no	O
derivative	O
works	O
unported	O
except	O
for	O
some	O
little	O
portions	O
of	O
the	O
work	O
licensed	O
under	O
more	O
liberal	O
licenses	O
as	O
mentioned	O
some	O
figures	O
from	O
wikimedia	O
commons	O
a	O
quick	O
license	O
summary	O
you	O
are	O
free	O
to	O
redistribute	O
this	O
document	O
though	O
it	O
is	O
a	O
much	O
better	O
idea	O
to	O
just	O
distribute	O
the	O
url	O
of	O
my	O
homepage	O
for	O
it	O
always	O
contains	O
the	O
most	O
recent	O
version	O
of	O
the	O
text	O
you	O
may	O
not	O
modify	O
transform	O
or	O
build	O
upon	O
the	O
document	O
except	O
for	O
personal	O
use	O
httpcreativecommons	O
orglicenses	O
how	O
to	O
cite	O
this	O
manuscript	O
there	O
s	O
no	O
official	O
publisher	O
so	O
you	O
need	O
to	O
be	O
careful	O
with	O
your	O
citation	O
please	O
find	O
more	O
information	O
in	O
english	O
and	O
german	O
language	O
on	O
my	O
homepage	O
respectively	O
the	O
subpage	O
concerning	O
the	O
acknowledgement	O
now	O
i	O
would	O
like	O
to	O
express	O
my	O
gratitude	O
to	O
all	O
the	O
people	O
who	O
contributed	O
in	O
whatever	O
manner	O
to	O
the	O
success	O
of	O
this	O
work	O
since	O
a	O
work	O
like	O
this	O
needs	O
many	O
helpers	O
first	O
of	O
all	O
i	O
want	O
to	O
thank	O
the	O
proofreaders	O
of	O
this	O
text	O
who	O
helped	O
me	O
and	O
my	O
readers	O
very	O
much	O
in	O
alphabetical	O
order	O
wolfgang	O
apolinarski	O
kathrin	O
gr	O
ve	O
paul	O
imhoff	O
thomas	O
httpwww	O
dkriesel	O
comenscience	O
neural	O
networks	O
viii	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
k	O
hn	O
christoph	O
kunze	O
malte	O
lohmeyer	O
joachim	O
nock	O
daniel	O
plohmann	O
daniel	O
rosenthal	O
christian	O
schulz	O
and	O
tobias	O
wilken	O
additionally	O
i	O
want	O
to	O
thank	O
the	O
readers	O
dietmar	O
berger	O
igor	O
buchm	O
ller	O
marie	O
christ	O
julia	O
damaschek	O
jochen	O
d	O
ll	O
maximilian	O
ernestus	O
hardy	O
falk	O
anne	O
feldmeier	O
sascha	O
fink	O
andreas	O
friedmann	O
jan	O
gassen	O
markus	O
gerhards	O
sebastian	O
hirsch	O
andreas	O
hochrath	O
nico	O
h	O
ft	O
thomas	O
ihme	O
boris	O
jentsch	O
tim	O
hussein	O
thilo	O
keller	O
mario	O
krenn	O
mirko	O
kunze	O
maikel	O
linke	O
adam	O
maciak	O
benjamin	O
meier	O
david	O
m	O
ller	O
andreas	O
m	O
ller	O
rainer	O
penninger	O
lena	O
reichel	O
alexander	O
schier	O
matthias	O
siegmund	O
mathias	O
tirtasana	O
oliver	O
tischler	O
maximilian	O
voit	O
igor	O
wall	O
achim	O
weber	O
frank	O
weinreis	O
gideon	O
maillette	O
de	O
buij	O
wenniger	O
philipp	O
woock	O
and	O
many	O
others	O
for	O
their	O
feedback	O
suggestions	O
and	O
remarks	O
additionally	O
i	O
d	O
like	O
to	O
thank	O
sebastian	O
merzbach	O
who	O
examined	O
this	O
work	O
in	O
a	O
very	O
conscientious	O
way	O
finding	O
inconsistencies	O
and	O
errors	O
in	O
particular	O
he	O
cleared	O
lots	O
and	O
lots	O
of	O
language	O
clumsiness	O
from	O
the	O
english	O
version	O
especially	O
i	O
would	O
like	O
to	O
thank	O
beate	O
kuhl	O
for	O
translating	O
the	O
entire	O
text	O
from	O
german	O
to	O
english	O
and	O
for	O
her	O
questions	O
which	O
made	O
me	O
think	O
of	O
changing	O
the	O
phrasing	O
of	O
some	O
paragraphs	O
i	O
would	O
particularly	O
like	O
to	O
thank	O
prof	O
rolf	B
eckmiller	O
and	O
dr	O
nils	O
goerke	O
as	O
well	O
as	O
the	O
entire	O
division	O
of	O
neuroinformatics	O
department	O
of	O
computer	O
science	O
of	O
the	O
university	O
of	O
bonn	O
they	O
all	O
made	O
sure	O
that	O
i	O
always	O
learned	O
also	O
had	O
to	O
learn	O
something	O
new	O
about	O
neural	O
networks	O
and	O
related	O
subjects	O
especially	O
dr	O
goerke	O
has	O
always	O
been	O
willing	O
to	O
respond	O
to	O
any	O
questions	O
i	O
was	O
not	O
able	O
to	O
answer	O
myself	O
during	O
the	O
writing	O
process	O
conversations	O
with	O
prof	O
eckmiller	O
made	O
me	O
step	O
back	O
from	O
the	O
whiteboard	O
to	O
get	O
a	O
better	O
overall	O
view	O
on	O
what	O
i	O
was	O
doing	O
and	O
what	O
i	O
should	O
do	O
next	O
globally	O
and	O
not	O
only	O
in	O
the	O
context	B
of	O
this	O
work	O
i	O
want	O
to	O
thank	O
my	O
parents	O
who	O
never	O
get	O
tired	O
to	O
buy	O
me	O
specialized	O
and	O
therefore	O
expensive	O
books	O
and	O
who	O
have	O
always	O
supported	O
me	O
in	O
my	O
studies	O
for	O
many	O
and	O
the	O
very	O
special	O
and	O
cordial	O
atmosphere	O
i	O
want	O
to	O
thank	O
andreas	O
huber	O
and	O
tobias	O
treutler	O
since	O
our	O
first	O
semester	O
it	O
has	O
rarely	O
been	O
boring	O
with	O
you	O
now	O
i	O
would	O
like	O
to	O
think	O
back	O
to	O
my	O
school	O
days	O
and	O
cordially	O
thank	O
some	O
teachers	O
who	O
my	O
opinion	O
had	O
imparted	O
some	O
scientific	O
knowledge	O
to	O
me	O
although	O
my	O
class	O
participation	O
had	O
not	O
always	O
been	O
wholehearted	O
mr	O
wilfried	O
hartmann	O
mr	O
hubert	O
peters	O
and	O
mr	O
frank	O
n	O
kel	O
furthermore	O
i	O
would	O
like	O
to	O
thank	O
the	O
whole	O
team	O
at	O
the	O
notary	O
s	O
office	O
of	O
dr	O
kemp	O
and	O
dr	O
kolb	O
in	O
bonn	O
where	O
i	O
have	O
always	O
felt	O
to	O
be	O
in	O
good	O
hands	O
and	O
who	O
have	O
helped	O
me	O
to	O
keep	O
my	O
printing	O
costs	O
low	O
in	O
particular	O
christiane	O
flamme	O
and	O
dr	O
kemp	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
ix	O
dkriesel	O
com	O
thanks	O
go	O
also	O
to	O
the	O
wikimedia	O
commons	O
where	O
i	O
took	O
some	O
images	O
and	O
altered	O
them	O
to	O
suit	O
this	O
text	O
last	O
but	O
not	O
least	O
i	O
want	O
to	O
thank	O
two	O
people	O
who	O
made	O
outstanding	O
contributions	O
to	O
this	O
work	O
who	O
occupy	O
so	O
to	O
speak	O
a	O
place	O
of	O
honor	O
my	O
girlfriend	O
verena	O
thomas	O
who	O
found	O
many	O
mathematical	O
and	O
logical	O
errors	O
in	O
my	O
text	O
and	O
discussed	O
them	O
with	O
me	O
although	O
she	O
has	O
lots	O
of	O
other	O
things	O
to	O
do	O
and	O
christiane	O
schultze	O
who	O
carefully	O
reviewed	O
the	O
text	O
for	O
spelling	O
mistakes	O
and	O
inconsistencies	O
david	O
kriesel	O
x	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
contents	O
a	O
small	O
preface	O
i	O
from	O
biology	O
to	O
formalization	O
motivation	O
philosophy	O
history	O
and	O
realization	O
of	O
neural	O
models	O
v	O
introduction	O
motivation	O
and	O
history	O
why	O
neural	O
networks	O
the	O
rule	O
simple	O
application	O
examples	O
history	O
of	O
neural	O
networks	O
the	O
beginning	O
golden	O
age	O
long	O
silence	O
and	O
slow	O
reconstruction	O
renaissance	O
exercises	O
biological	O
neural	O
networks	O
the	O
vertebrate	O
nervous	B
system	I
peripheral	O
and	O
central	B
nervous	B
system	I
cerebrum	B
cerebellum	B
diencephalon	O
brainstem	B
the	O
neuron	B
components	O
electrochemical	O
processes	O
in	O
the	O
neuron	B
receptor	O
cells	O
various	O
types	O
information	B
processing	I
within	O
the	O
nervous	B
system	I
light	O
sensing	O
organs	O
the	O
amount	O
of	O
neurons	O
in	O
living	O
organisms	O
xi	O
contents	O
dkriesel	O
com	O
technical	O
neurons	O
as	O
caricature	O
of	O
biology	O
exercises	O
components	O
of	O
artificial	O
neural	O
networks	O
the	O
concept	O
of	O
time	O
in	O
neural	O
networks	O
components	O
of	O
neural	O
networks	O
connections	O
propagation	B
function	I
and	O
network	B
input	B
activation	B
threshold	B
value	I
activation	B
function	I
common	O
activation	B
functions	O
output	B
function	I
learning	B
strategy	I
network	O
topologies	O
feedforward	B
recurrent	B
networks	O
completely	O
linked	O
networks	O
the	O
bias	B
neuron	B
representing	O
neurons	O
orders	O
of	O
activation	B
synchronous	B
activation	B
asynchronous	O
activation	B
input	B
and	O
output	B
of	O
data	O
exercises	O
supervised	B
learning	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
paradigms	O
of	O
learning	O
unsupervised	B
learning	O
reinforcement	B
learning	I
o	O
ine	O
or	O
online	B
learning	O
questions	O
in	O
advance	O
training	O
patterns	O
and	O
teaching	B
input	B
using	O
training	O
samples	O
division	O
of	O
the	O
training	B
set	I
order	O
of	O
pattern	O
representation	O
learning	O
curve	O
and	O
error	O
measurement	O
when	O
do	O
we	O
stop	O
learning	O
xii	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
contents	O
problems	B
of	O
gradient	B
procedures	O
gradient	B
optimization	O
procedures	O
exemplary	O
problems	B
boolean	O
functions	O
the	O
parity	O
function	O
the	O
problem	O
the	O
checkerboard	O
problem	O
the	O
identity	B
function	O
other	O
exemplary	O
problems	B
original	O
rule	O
generalized	B
form	I
hebbian	B
rule	I
exercises	O
ii	O
supervised	B
learning	O
network	O
paradigms	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
the	O
singlelayer	B
perceptron	B
perceptron	B
learning	I
algorithm	B
and	O
convergence	O
theorem	O
delta	B
rule	I
linear	B
separability	I
the	O
multilayer	B
perceptron	B
backpropagation	B
of	I
error	I
derivation	O
boiling	O
backpropagation	B
down	O
to	O
the	O
delta	B
rule	I
selecting	O
a	O
learning	B
rate	I
resilient	B
backpropagation	B
adaption	O
of	O
weights	O
dynamic	O
learning	B
rate	I
adjustment	O
rprop	O
in	O
practice	O
further	O
variations	O
and	O
extensions	O
to	O
backpropagation	B
momentum	B
term	I
flat	O
spot	O
elimination	O
second	B
order	I
backpropagation	B
weight	B
decay	O
pruning	B
and	O
optimal	B
brain	B
damage	I
initial	O
configuration	O
of	O
a	O
multilayer	B
perceptron	B
number	O
of	O
layers	O
the	O
number	O
of	O
neurons	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
xiii	O
contents	O
dkriesel	O
com	O
selecting	O
an	O
activation	B
function	I
initializing	O
weights	O
the	O
encoding	O
problem	O
and	O
related	O
problems	B
exercises	O
radial	O
basis	B
functions	O
information	B
processing	I
in	O
rbf	B
neurons	O
components	O
and	O
structure	O
information	B
processing	I
of	O
an	O
rbf	B
network	I
analytical	O
thoughts	O
prior	O
to	O
the	O
training	O
training	O
of	O
rbf	B
networks	O
adding	O
neurons	O
limiting	O
the	O
number	O
of	O
neurons	O
deleting	O
neurons	O
comparing	O
rbf	B
networks	O
and	O
multilayer	B
perceptrons	O
exercises	O
centers	O
and	O
widths	O
of	O
rbf	B
neurons	O
growing	B
rbf	B
networks	O
recurrent	B
perceptron-like	O
networks	O
on	O
chapter	O
jordan	B
networks	O
elman	B
networks	O
training	O
recurrent	B
networks	O
unfolding	B
in	I
time	I
teacher	B
forcing	I
recurrent	B
backpropagation	B
training	O
with	O
evolution	O
hopfield	B
networks	I
inspired	O
by	O
magnetism	O
structure	O
and	O
functionality	O
input	B
and	O
output	B
of	O
a	O
hopfield	O
network	O
significance	O
of	O
weights	O
change	O
in	O
the	O
state	B
of	O
neurons	O
generating	O
the	O
weight	B
matrix	I
autoassociation	O
and	O
traditional	O
application	O
heteroassociation	O
and	O
analogies	O
to	O
neural	O
data	O
storage	O
generating	O
the	O
heteroassociative	O
matrix	O
stabilizing	O
the	O
heteroassociations	O
biological	O
motivation	O
of	O
heterassociation	O
xiv	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
contents	O
continuous	B
hopfield	B
networks	I
exercises	O
learning	B
vector	I
quantization	B
about	O
quantization	B
purpose	O
of	O
lvq	O
using	O
codebook	O
vectors	O
adjusting	O
codebook	O
vectors	O
the	O
procedure	O
of	O
learning	O
connection	B
to	O
neural	O
networks	O
exercises	O
iii	O
unsupervised	B
learning	O
network	O
paradigms	O
self-organizing	B
feature	I
maps	I
examples	O
structure	O
functionality	O
and	O
output	B
interpretation	O
training	O
the	O
topology	B
function	I
monotonically	O
decreasing	O
learning	B
rate	I
and	O
neighborhood	O
topological	O
defects	O
adjustment	O
of	O
resolution	O
and	O
position-dependent	O
learning	B
rate	I
application	O
interaction	O
with	O
rbf	B
networks	O
variations	O
neural	B
gas	I
multi-soms	O
multi-neural	O
gas	O
growing	B
neural	B
gas	I
exercises	O
adaptive	B
resonance	B
theory	I
task	O
and	O
structure	O
of	O
an	O
art	O
network	O
resonance	B
learning	O
process	O
pattern	O
input	B
and	O
top-down	B
learning	O
resonance	B
and	O
bottom-up	B
learning	O
adding	O
an	O
output	B
neuron	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
xv	O
contents	O
dkriesel	O
com	O
extensions	O
iv	O
excursi	O
appendices	O
and	O
registers	O
a	O
excursus	O
cluster	B
analysis	I
and	O
regional	B
and	I
online	B
learnable	I
fields	I
k-means	B
clustering	I
k-nearest	B
neighboring	I
neighboring	O
the	O
silhouette	O
coefficient	O
regional	B
and	I
online	B
learnable	I
fields	I
structure	O
of	O
a	O
rolf	B
training	O
a	O
rolf	B
evaluating	O
a	O
rolf	B
comparison	O
with	O
popular	O
clustering	O
methods	O
initializing	O
radii	O
learning	O
rates	O
and	O
multiplier	O
application	O
examples	O
exercises	O
b	O
excursus	O
neural	O
networks	O
used	O
for	O
prediction	O
about	O
time	B
series	I
one-step-ahead	B
prediction	I
two-step-ahead	B
prediction	I
recursive	O
two-step-ahead	B
prediction	I
direct	B
two-step-ahead	B
prediction	I
additional	O
optimization	O
approaches	O
for	O
prediction	O
changing	O
temporal	O
parameters	O
heterogeneous	B
prediction	O
remarks	O
on	O
the	O
prediction	O
of	O
share	O
prices	O
c	O
excursus	O
reinforcement	B
learning	I
system	O
structure	O
the	O
gridworld	B
agent	B
und	O
environment	B
states	O
situations	O
and	O
actions	O
reward	B
and	O
return	B
the	O
policy	B
learning	O
process	O
rewarding	O
strategies	O
the	O
state-value	B
function	I
xvi	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
contents	O
monte	B
carlo	I
method	I
temporal	B
difference	I
learning	I
the	O
action-value	B
function	I
q	B
learning	I
example	O
applications	O
td	B
gammon	I
the	O
car	O
in	O
the	O
pit	O
the	O
pole	B
balancer	I
reinforcement	B
learning	I
in	O
connection	B
with	O
neural	O
networks	O
exercises	O
bibliography	O
list	O
of	O
figures	O
index	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
xvii	O
part	O
i	O
from	O
biology	O
to	O
formalization	O
motivation	O
philosophy	O
history	O
and	O
realization	O
of	O
neural	O
models	O
chapter	O
introduction	O
motivation	O
and	O
history	O
how	O
to	O
teach	O
a	O
computer	O
you	O
can	O
either	O
write	O
a	O
fixed	O
program	O
or	O
you	O
can	O
enable	O
the	O
computer	O
to	O
learn	O
on	O
its	O
own	O
living	O
beings	O
do	O
not	O
have	O
any	O
programmer	O
writing	O
a	O
program	O
for	O
developing	O
their	O
skills	O
which	O
then	O
only	O
has	O
to	O
be	O
executed	O
they	O
learn	O
by	O
themselves	O
without	O
the	O
previous	O
knowledge	O
from	O
external	O
impressions	O
and	O
thus	O
can	O
solve	O
problems	B
better	O
than	O
any	O
computer	O
today	O
what	O
qualities	O
are	O
needed	O
to	O
achieve	O
such	O
a	O
behavior	O
for	O
devices	O
like	O
computers	O
can	O
such	O
cognition	O
be	O
adapted	O
from	O
biology	O
history	O
development	O
decline	O
and	O
resurgence	O
of	O
a	O
wide	O
approach	O
to	O
solve	O
problems	B
why	O
neural	O
networks	O
there	O
are	O
problem	O
categories	O
that	O
cannot	O
be	O
formulated	O
as	O
an	O
algorithm	B
problems	B
that	O
depend	O
on	O
many	O
subtle	O
factors	O
for	O
example	O
the	O
purchase	O
price	O
of	O
a	O
real	O
estate	O
which	O
our	O
brain	B
can	O
calculate	O
without	O
an	O
algorithm	B
a	O
computer	O
cannot	O
do	O
the	O
same	O
therefore	O
the	O
question	O
to	O
be	O
asked	O
is	O
how	O
do	O
we	O
learn	O
to	O
explore	O
such	O
problems	B
exactly	O
we	O
learn	O
a	O
capability	O
computers	O
obviously	O
do	O
not	O
have	O
humans	O
have	O
a	O
brain	B
that	O
can	O
learn	O
computers	O
have	O
some	O
processing	O
units	O
and	O
memory	O
they	O
allow	O
the	O
computer	O
to	O
perform	O
the	O
most	O
complex	O
numerical	O
calculations	O
in	O
a	O
very	O
short	O
time	O
but	O
they	O
are	O
not	O
adaptive	O
if	O
we	O
compare	O
computer	O
and	O
we	O
will	O
note	O
that	O
theoretically	O
the	O
computer	O
should	O
be	O
more	O
powerful	O
than	O
our	O
brain	B
it	O
comprises	O
transistors	O
with	O
a	O
switching	O
time	O
of	O
seconds	O
the	O
brain	B
contains	O
neurons	O
but	O
these	O
only	O
have	O
a	O
switching	O
time	O
of	O
about	O
seconds	O
the	O
largest	O
part	O
of	O
the	O
brain	B
is	O
working	O
continuously	O
while	O
the	O
largest	O
part	O
of	O
the	O
computer	O
is	O
only	O
passive	O
data	O
storage	O
thus	O
the	O
brain	B
is	O
parallel	O
and	O
therefore	O
performing	O
close	O
to	O
its	O
theoretical	O
of	O
course	O
this	O
comparison	O
is	O
for	O
obvious	O
reasons	O
controversially	O
discussed	O
by	O
biologists	O
and	O
computer	O
scientists	O
since	O
response	O
time	O
and	O
quantity	O
do	O
not	O
tell	O
anything	O
about	O
quality	O
and	O
performance	O
of	O
the	O
processing	O
units	O
as	O
well	O
as	O
neurons	O
and	O
transistors	O
cannot	O
be	O
compared	O
directly	O
nevertheless	O
the	O
comparison	O
serves	O
its	O
purpose	O
and	O
indicates	O
the	O
advantage	O
of	O
parallelism	B
by	O
means	O
of	O
processing	O
time	O
parallelism	B
computers	O
cannot	O
learn	O
chapter	O
introduction	O
motivation	O
and	O
history	O
dkriesel	O
com	O
no	O
of	O
processing	O
units	O
type	O
of	O
processing	O
units	O
type	O
of	O
calculation	O
data	O
storage	O
switching	O
time	O
possible	O
switching	O
operations	O
actual	O
switching	O
operations	O
brain	B
neurons	O
massively	O
parallel	O
associative	O
s	O
s	O
computer	O
transistors	O
usually	O
serial	O
address-based	O
s	O
s	O
table	O
the	O
comparison	O
between	O
brain	B
and	O
computer	O
at	O
a	O
glance	O
inspired	O
by	O
mum	O
from	O
which	O
the	O
computer	O
is	O
orders	O
of	O
magnitude	O
away	O
additionally	O
a	O
computer	O
is	O
static	O
the	O
brain	B
as	O
a	O
biological	O
neural	B
network	I
can	O
reorganize	O
itself	O
during	O
its	O
and	O
therefore	O
is	O
able	O
to	O
learn	O
to	O
compensate	O
errors	O
and	O
so	O
forth	O
within	O
this	O
text	O
i	O
want	O
to	O
outline	O
how	O
we	O
can	O
use	O
the	O
said	O
characteristics	O
of	O
our	O
brain	B
for	O
a	O
computer	O
system	O
so	O
the	O
study	O
of	O
artificial	O
neural	O
networks	O
is	O
motivated	O
by	O
their	O
similarity	O
to	O
successfully	O
working	O
biological	O
systems	O
which	O
in	O
comparison	O
to	O
the	O
overall	O
system	O
consist	O
of	O
very	O
simple	O
but	O
numerous	O
nerve	O
cells	O
that	O
work	O
massively	O
in	O
parallel	O
and	O
is	O
probably	O
one	O
of	O
the	O
most	O
significant	O
aspects	O
have	O
the	O
capability	B
to	I
learn	I
there	O
is	O
no	O
need	O
to	O
explicitly	O
program	O
a	O
neural	B
network	I
for	O
instance	O
it	O
can	O
learn	O
from	O
training	O
samples	O
or	O
by	O
means	O
of	O
encouragement	O
with	O
a	O
carrot	O
and	O
a	O
stick	O
so	O
to	O
speak	O
learning	O
one	O
result	O
from	O
this	O
learning	O
procedure	O
is	O
the	O
capability	O
of	O
neural	O
networks	O
to	O
gen	O
eralize	O
and	O
associate	O
data	O
after	O
successful	O
training	O
a	O
neural	B
network	I
can	O
find	O
reasonable	O
solutions	O
for	O
similar	O
problems	B
of	O
the	O
same	O
class	O
that	O
were	O
not	O
explicitly	O
trained	O
this	O
in	O
turn	O
results	O
in	O
a	O
high	O
degree	O
of	O
fault	B
tolerance	I
against	O
noisy	O
input	B
data	O
fault	B
tolerance	I
is	O
closely	O
related	O
to	O
biological	O
neural	O
networks	O
in	O
which	O
this	O
characteristic	O
is	O
very	O
distinct	O
as	O
previously	O
mentioned	O
a	O
human	O
has	O
about	O
neurons	O
that	O
continuously	O
reorganize	O
themselves	O
or	O
are	O
reorganized	O
by	O
external	O
influences	O
neurons	O
can	O
be	O
destroyed	O
while	O
in	O
a	O
drunken	O
stupor	O
some	O
types	O
of	O
food	O
or	O
environmental	O
influences	O
can	O
also	O
destroy	O
brain	B
cells	O
nevertheless	O
our	O
cognitive	O
abilities	O
are	O
not	O
significantly	O
affected	O
thus	O
the	O
brain	B
is	O
tolerant	O
against	O
internal	O
errors	O
and	O
also	O
against	O
external	O
errors	O
for	O
we	O
can	O
often	O
read	O
a	O
really	O
scrawl	O
although	O
the	O
individual	O
letters	O
are	O
nearly	O
impossible	O
to	O
read	O
our	O
modern	O
technology	O
however	O
is	O
not	O
automatically	O
fault-tolerant	O
i	O
have	O
never	O
heard	O
that	O
someone	O
forgot	O
to	O
install	O
the	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
simple	O
but	O
many	O
processing	O
units	O
n	O
network	O
capable	O
to	O
learn	O
n	O
network	O
fault	O
tolerant	O
dkriesel	O
com	O
why	O
neural	O
networks	O
i	O
e	O
hard	O
disk	O
controller	O
into	O
a	O
computer	O
and	O
therefore	O
the	O
graphics	O
card	O
automatically	O
took	O
over	O
its	O
tasks	O
removed	O
conductors	O
and	O
developed	O
communication	O
so	O
that	O
the	O
system	O
as	O
a	O
whole	O
was	O
affected	O
by	O
the	O
missing	O
component	O
but	O
not	O
completely	O
destroyed	O
a	O
disadvantage	O
of	O
this	O
distributed	O
faulttolerant	O
storage	O
is	O
certainly	O
the	O
fact	O
that	O
we	O
cannot	O
realize	O
at	O
first	O
sight	O
what	O
a	O
neural	O
neutwork	O
knows	O
and	O
performs	O
or	O
where	O
its	O
faults	O
lie	O
usually	O
it	O
is	O
easier	O
to	O
perform	O
such	O
analyses	O
for	O
conventional	O
algorithms	O
most	O
often	O
we	O
can	O
only	O
transfer	O
knowledge	O
into	O
our	O
neural	B
network	I
by	O
means	O
of	O
a	O
learning	O
procedure	O
which	O
can	O
cause	O
several	O
errors	O
and	O
is	O
not	O
always	O
easy	O
to	O
manage	O
fault	B
tolerance	I
of	O
data	O
on	O
the	O
other	O
hand	O
is	O
already	O
more	O
sophisticated	O
in	O
state-ofthe-art	O
technology	O
let	O
us	O
compare	O
a	O
record	O
and	O
a	O
cd	O
if	O
there	O
is	O
a	O
scratch	O
on	O
a	O
record	O
the	O
audio	O
information	O
on	O
this	O
spot	O
will	O
be	O
completely	O
lost	O
will	O
hear	O
a	O
pop	O
and	O
then	O
the	O
music	O
goes	O
on	O
on	O
a	O
cd	O
the	O
audio	O
data	O
are	O
distributedly	O
stored	O
a	O
scratch	O
causes	O
a	O
blurry	O
sound	O
in	O
its	O
vicinity	O
but	O
the	O
data	O
stream	O
remains	O
largely	O
unaffected	O
the	O
listener	O
won	O
t	O
notice	O
anything	O
so	O
let	O
us	O
summarize	O
the	O
main	O
characteristics	O
we	O
try	O
to	O
adapt	O
from	O
biology	O
self-organization	O
and	O
learning	O
capa	O
bility	O
generalization	B
capability	O
and	O
fault	B
tolerance	I
what	O
types	O
of	O
neural	O
networks	O
particularly	O
develop	O
what	O
kinds	O
of	O
abilities	O
and	O
can	O
be	O
used	O
for	O
what	O
problem	O
classes	O
will	O
be	O
discussed	O
in	O
the	O
course	O
of	O
this	O
work	O
in	O
the	O
introductory	O
chapter	O
i	O
want	O
to	O
neural	O
netclarify	O
the	O
following	O
work	O
does	O
not	O
exist	O
there	O
are	O
different	O
paradigms	O
for	O
neural	O
networks	O
how	O
they	O
are	O
trained	O
and	O
where	O
they	O
are	O
used	O
my	O
goal	O
is	O
to	O
introduce	O
some	O
of	O
these	O
paradigms	O
and	O
supplement	O
some	O
remarks	O
for	O
practical	O
application	O
we	O
have	O
already	O
mentioned	O
that	O
our	O
brain	B
works	O
massively	O
in	O
parallel	O
in	O
contrast	O
to	O
the	O
functioning	O
of	O
a	O
computer	O
i	O
e	O
every	O
component	O
is	O
active	O
at	O
any	O
time	O
if	O
we	O
want	O
to	O
state	B
an	O
argument	O
for	O
massive	O
parallel	O
processing	O
then	O
the	O
rule	O
can	O
be	O
cited	O
the	O
rule	O
experiments	O
showed	O
that	O
a	O
human	O
can	O
recognize	O
the	O
picture	O
of	O
a	O
familiar	O
object	O
or	O
person	O
in	O
seconds	O
which	O
corresponds	O
to	O
a	O
neuron	B
switching	O
time	O
of	O
seconds	O
in	O
discrete	B
time	O
steps	O
of	O
parallel	O
processing	O
a	O
computer	O
following	O
the	O
von	O
neumann	O
architecture	O
however	O
can	O
do	O
practically	O
nothing	O
in	O
time	O
steps	O
of	O
sequential	O
processing	O
which	O
are	O
assembler	O
steps	O
or	O
cycle	O
steps	O
now	O
we	O
want	O
to	O
look	O
at	O
a	O
simple	O
application	O
example	O
for	O
a	O
neural	B
network	I
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
important	O
parallel	O
processing	O
chapter	O
introduction	O
motivation	O
and	O
history	O
dkriesel	O
com	O
put	O
is	O
called	O
h	O
for	O
signal	O
therefore	O
we	O
need	O
a	O
mapping	O
f	O
that	O
applies	O
the	O
input	B
signals	O
to	O
a	O
robot	O
activity	O
the	O
classical	O
way	O
there	O
are	O
two	O
ways	O
of	O
realizing	O
this	O
mapping	O
on	O
the	O
one	O
hand	O
there	O
is	O
the	O
classical	O
way	O
we	O
sit	O
down	O
and	O
think	O
for	O
a	O
while	O
and	O
finally	O
the	O
result	O
is	O
a	O
circuit	O
or	O
a	O
small	O
computer	O
program	O
which	O
realizes	O
the	O
mapping	O
is	O
easily	O
possible	O
since	O
the	O
example	O
is	O
very	O
simple	O
after	O
that	O
we	O
refer	O
to	O
the	O
technical	O
reference	O
of	O
the	O
sensors	O
study	O
their	O
characteristic	O
curve	O
in	O
order	O
to	O
learn	O
the	O
values	O
for	O
the	O
different	O
obstacle	O
distances	O
and	O
embed	O
these	O
values	O
into	O
the	O
aforementioned	O
set	B
of	I
rules	O
such	O
procedures	O
are	O
applied	O
in	O
the	O
classic	O
artificial	B
intelligence	I
and	O
if	O
you	O
know	O
the	O
exact	O
rules	O
of	O
a	O
mapping	O
algorithm	B
you	O
are	O
always	O
well	O
advised	O
to	O
follow	O
this	O
scheme	O
the	O
way	O
of	O
learning	O
on	O
the	O
other	O
hand	O
more	O
interesting	O
and	O
more	O
successful	O
for	O
many	O
mappings	O
and	O
problems	B
that	O
are	O
hard	O
to	O
comprehend	O
straightaway	O
is	O
the	O
way	O
of	O
learning	O
we	O
show	O
different	O
possible	O
situations	O
to	O
the	O
robot	O
on	O
page	O
and	O
the	O
robot	O
shall	O
learn	O
on	O
its	O
own	O
what	O
to	O
do	O
in	O
the	O
course	O
of	O
its	O
robot	O
life	O
in	O
this	O
example	O
the	O
robot	O
shall	O
simply	O
learn	O
when	O
to	O
stop	O
we	O
first	O
treat	O
the	O
figure	O
a	O
small	O
robot	O
with	O
eight	O
sensors	O
and	O
two	O
motors	O
the	O
arrow	O
indicates	O
the	O
driving	O
direction	O
simple	O
application	O
examples	O
let	O
us	O
assume	O
that	O
we	O
have	O
a	O
small	O
robot	O
as	O
shown	O
in	O
fig	O
this	O
robot	O
has	O
eight	O
distance	O
sensors	O
from	O
which	O
it	O
extracts	O
input	B
data	O
three	O
sensors	O
are	O
placed	O
on	O
the	O
front	O
right	O
three	O
on	O
the	O
front	O
left	O
and	O
two	O
on	O
the	O
back	O
each	O
sensor	O
provides	O
a	O
real	O
numeric	O
value	O
at	O
any	O
time	O
that	O
means	O
we	O
are	O
always	O
receiving	O
an	O
input	B
i	O
despite	O
its	O
two	O
motors	O
will	O
be	O
needed	O
later	O
the	O
robot	O
in	O
our	O
simple	O
example	O
is	O
not	O
capable	O
to	O
do	O
much	O
it	O
shall	O
only	O
drive	O
on	O
but	O
stop	O
when	O
it	O
might	O
collide	O
with	O
an	O
obstacle	O
thus	O
our	O
output	B
is	O
binary	B
h	O
for	O
is	O
okay	O
drive	O
on	O
and	O
h	O
for	O
out	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
why	O
neural	O
networks	O
our	O
example	O
can	O
be	O
optionally	O
expanded	O
for	O
the	O
purpose	O
of	O
direction	O
control	O
it	O
would	O
be	O
possible	O
to	O
control	O
the	O
motors	O
of	O
our	O
robot	O
with	O
the	O
sensor	O
layout	O
being	O
the	O
same	O
in	O
this	O
case	O
we	O
are	O
looking	O
for	O
a	O
mapping	O
f	O
which	O
gradually	O
controls	O
the	O
two	O
motors	O
by	O
means	O
of	O
the	O
sensor	O
inputs	O
and	O
thus	O
cannot	O
only	O
for	O
example	O
stop	O
the	O
robot	O
but	O
also	O
lets	O
it	O
avoid	O
obstacles	O
here	O
it	O
is	O
more	O
difficult	O
to	O
analytically	O
derive	O
the	O
rules	O
and	O
de	O
facto	O
a	O
neural	B
network	I
would	O
be	O
more	O
appropriate	O
our	O
goal	O
is	O
not	O
to	O
learn	O
the	O
samples	O
by	O
heart	O
but	O
to	O
realize	O
the	O
principle	O
behind	O
them	O
ideally	O
the	O
robot	O
should	O
apply	O
the	O
neural	B
network	I
in	O
any	O
situation	B
and	O
be	O
able	O
to	O
avoid	O
obstacles	O
in	O
particular	O
the	O
robot	O
should	O
query	O
the	O
network	O
continuously	O
and	O
repeatedly	O
while	O
driving	O
in	O
order	O
to	O
continously	O
avoid	O
obstacles	O
the	O
result	O
is	O
a	O
constant	O
cycle	O
the	O
robot	O
queries	O
the	O
network	O
as	O
a	O
consequence	O
it	O
will	O
drive	O
in	O
one	O
direction	O
which	O
changes	O
the	O
sensors	O
values	O
again	O
the	O
robot	O
queries	O
the	O
network	O
and	O
changes	O
its	O
position	O
the	O
sensor	O
values	O
are	O
changed	O
once	O
again	O
and	O
so	O
on	O
it	O
is	O
obvious	O
that	O
this	O
system	O
can	O
also	O
be	O
adapted	O
to	O
dynamic	O
i	O
e	O
changing	O
environments	O
the	O
moving	O
obstacles	O
in	O
our	O
example	O
there	O
is	O
a	O
robot	O
called	O
khepera	O
with	O
more	O
or	O
less	O
similar	O
characteristics	O
it	O
is	O
round-shaped	O
approx	O
cm	O
in	O
diameter	O
has	O
two	O
motors	O
with	O
wheels	O
and	O
various	O
sensors	O
for	O
more	O
information	O
i	O
recommend	O
to	O
refer	O
to	O
the	O
internet	O
figure	O
initially	O
we	O
regard	O
the	O
robot	O
control	O
as	O
a	O
black	B
box	I
whose	O
inner	O
life	O
is	O
unknown	O
the	O
black	B
box	I
receives	O
eight	O
real	O
sensor	O
values	O
and	O
maps	O
these	O
values	O
to	O
a	O
binary	B
output	B
value	O
neural	B
network	I
as	O
a	O
kind	O
of	O
black	B
box	I
this	O
means	O
we	O
do	O
not	O
know	O
its	O
structure	O
but	O
just	O
regard	O
its	O
behavior	O
in	O
practice	O
the	O
situations	O
in	O
form	O
of	O
simply	O
measured	O
sensor	O
values	O
placing	O
the	O
robot	O
in	O
front	O
of	O
an	O
obstacle	O
see	O
illustration	O
which	O
we	O
show	O
to	O
the	O
robot	O
and	O
for	O
which	O
we	O
specify	O
whether	O
to	O
drive	O
on	O
or	O
to	O
stop	O
are	O
called	O
training	O
samples	O
thus	O
a	O
training	O
sample	O
consists	O
of	O
an	O
exemplary	O
input	B
and	O
a	O
corresponding	O
desired	O
output	B
now	O
the	O
question	O
is	O
how	O
to	O
transfer	O
this	O
knowledge	O
the	O
information	O
into	O
the	O
neural	B
network	I
the	O
samples	O
can	O
be	O
taught	O
to	O
a	O
neural	B
network	I
by	O
using	O
a	O
simple	O
learning	O
procedure	O
learning	O
procedure	O
is	O
a	O
simple	O
algorithm	B
or	O
a	O
mathematical	O
formula	O
if	O
we	O
have	O
done	O
everything	O
right	O
and	O
chosen	O
good	O
samples	O
the	O
neural	B
network	I
will	O
generalize	O
from	O
these	O
samples	O
and	O
find	O
a	O
universal	B
rule	O
when	O
it	O
has	O
to	O
stop	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
introduction	O
motivation	O
and	O
history	O
dkriesel	O
com	O
figure	O
the	O
robot	O
is	O
positioned	O
in	O
a	O
landscape	O
that	O
provides	O
sensor	O
values	O
for	O
different	O
situations	O
we	O
add	O
the	O
desired	O
output	B
values	O
h	O
and	O
so	O
receive	O
our	O
learning	O
samples	O
the	O
directions	O
in	O
which	O
the	O
sensors	O
are	O
oriented	O
are	O
exemplarily	O
applied	O
to	O
two	O
robots	O
a	O
brief	O
history	O
of	O
neural	O
networks	O
the	O
field	O
of	O
neural	O
networks	O
has	O
like	O
any	O
other	O
field	O
of	O
science	O
a	O
long	O
history	B
of	I
development	I
with	O
many	O
ups	O
and	O
downs	O
as	O
we	O
will	O
see	O
soon	O
to	O
continue	O
the	O
style	O
of	O
my	O
work	O
i	O
will	O
not	O
represent	O
this	O
history	O
in	O
text	O
form	O
but	O
more	O
compact	O
in	O
form	O
of	O
a	O
timeline	O
citations	O
and	O
bibliographical	O
references	O
are	O
added	O
mainly	O
for	O
those	O
topics	O
that	O
will	O
not	O
be	O
further	O
discussed	O
in	O
this	O
text	O
citations	O
for	O
keywords	O
that	O
will	O
be	O
explained	O
later	O
are	O
mentioned	O
in	O
the	O
corresponding	O
chapters	O
the	O
history	O
of	O
neural	O
networks	O
begins	O
in	O
the	O
early	O
s	O
and	O
thus	O
nearly	O
simulta	O
neously	O
with	O
the	O
history	O
of	O
programmable	O
electronic	O
computers	O
the	O
youth	O
of	O
this	O
field	O
of	O
research	O
as	O
with	O
the	O
field	O
of	O
computer	O
science	O
itself	O
can	O
be	O
easily	O
recognized	O
due	O
to	O
the	O
fact	O
that	O
many	O
of	O
the	O
cited	O
persons	O
are	O
still	O
with	O
us	O
the	O
beginning	O
as	O
soon	O
as	O
warren	O
mcculloch	O
and	O
walter	O
pitts	O
introduced	O
models	O
of	O
neurological	O
networks	O
recreated	O
threshold	O
switches	O
based	O
on	O
neurons	O
and	O
showed	O
that	O
even	O
simple	O
networks	O
of	O
this	O
kind	O
are	O
able	O
to	O
calculate	O
nearly	O
any	O
logic	O
or	O
arithmetic	O
function	O
further	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
history	O
of	O
neural	O
networks	O
figure	O
some	O
institutions	O
of	O
the	O
field	O
of	O
neural	O
networks	O
from	O
left	O
to	O
right	O
john	O
von	O
neumann	O
donald	O
o	O
hebb	O
marvin	O
minsky	O
bernard	O
widrow	O
seymour	O
papert	O
teuvo	O
kohonen	O
john	O
hopfield	O
the	O
order	O
of	O
appearance	O
as	O
far	O
as	O
possible	O
more	O
the	O
first	O
computer	O
precursors	O
brainswere	O
developed	O
among	O
others	O
supported	O
by	O
konrad	O
zuse	O
who	O
was	O
tired	O
of	O
calculating	O
ballistic	O
trajectories	O
by	O
hand	O
walter	O
pitts	O
and	O
warren	O
mcculloch	O
indicated	O
a	O
practical	O
field	O
of	O
application	O
was	O
not	O
mentioned	O
in	O
their	O
work	O
from	O
namely	O
the	O
recognition	O
of	O
spacial	O
patterns	O
by	O
neural	O
networks	O
donald	O
o	O
hebb	O
formulated	O
the	O
classical	O
hebbian	B
rule	I
which	O
represents	O
in	O
its	O
more	O
generalized	B
form	I
the	O
basis	B
of	O
nearly	O
all	O
neural	O
learning	O
procedures	O
the	O
rule	O
implies	O
that	O
the	O
connection	B
between	O
two	O
neurons	O
is	O
strengthened	O
when	O
both	O
neurons	O
are	O
active	O
at	O
the	O
same	O
time	O
this	O
change	O
in	O
strength	O
is	O
proportional	O
to	O
the	O
product	O
of	O
the	O
two	O
activities	O
hebb	O
could	O
postulate	O
this	O
rule	O
but	O
due	O
to	O
the	O
absence	O
of	O
neurological	O
research	O
he	O
was	O
not	O
able	O
to	O
verify	O
it	O
neuropsychologist	O
karl	O
lashley	O
defended	O
the	O
thesis	O
that	O
the	O
brain	B
information	O
storage	O
is	O
realized	O
as	O
a	O
distributed	O
system	O
his	O
thesis	O
was	O
based	O
on	O
experiments	O
on	O
rats	O
where	O
only	O
the	O
extent	O
but	O
not	O
the	O
location	O
of	O
the	O
destroyed	O
nerve	O
tissue	O
influences	O
the	O
rats	O
performance	O
to	O
find	O
their	O
way	O
out	O
of	O
a	O
labyrinth	O
golden	O
age	O
for	O
his	O
dissertation	O
marvin	O
minsky	O
developed	O
the	O
neurocomputer	O
snark	B
which	O
has	O
already	O
been	O
capable	O
to	O
adjust	O
its	O
automatically	O
but	O
it	O
has	O
never	O
been	O
practically	O
implemented	O
since	O
it	O
is	O
capable	O
to	O
busily	O
calculate	O
but	O
nobody	O
really	O
knows	O
what	O
it	O
calculates	O
well-known	O
scientists	O
and	O
ambitious	O
students	O
met	O
at	O
the	O
dartmouth	O
summer	O
research	O
project	O
and	O
discussed	O
to	O
put	O
it	O
crudely	O
how	O
to	O
simulate	O
a	O
brain	B
differences	O
between	O
top-down	B
and	O
bottom-up	B
research	O
developed	O
while	O
the	O
early	O
we	O
will	O
learn	O
soon	O
what	O
weights	O
are	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
introduction	O
motivation	O
and	O
history	O
dkriesel	O
com	O
supporters	O
of	O
artificial	B
intelligence	I
wanted	O
to	O
simulate	O
capabilities	O
by	O
means	O
of	O
software	O
supporters	O
of	O
neural	O
networks	O
wanted	O
to	O
achieve	O
system	O
behavior	O
by	O
imitating	O
the	O
smallest	O
parts	O
of	O
the	O
system	O
the	O
neurons	O
at	O
the	O
mit	O
frank	O
rosenblatt	O
charles	O
wightman	O
and	O
their	O
coworkers	O
developed	O
the	O
first	O
successful	O
neurocomputer	O
the	O
mark	B
i	I
perceptron	B
which	O
was	O
capable	O
to	O
recognize	O
simple	O
numerics	O
by	O
means	O
of	O
a	O
pixel	O
image	O
sensor	O
and	O
electromechanically	O
worked	O
with	O
motor	O
driven	O
potentiometers	O
each	O
potentiometer	O
representing	O
one	O
variable	B
weight	B
frank	O
rosenblatt	O
described	O
different	O
versions	O
of	O
the	O
perceptron	B
formulated	O
and	O
verified	O
his	O
perceptron	B
convergence	I
theorem	I
he	O
described	O
neuron	B
layers	O
mimicking	O
the	O
retina	B
threshold	O
switches	O
and	O
a	O
learning	O
rule	O
adjusting	O
the	O
connecting	O
weights	O
bernard	O
widrow	O
and	O
marcian	O
e	O
hoff	O
introduced	O
the	O
adaline	O
linear	O
neuron	B
a	O
fast	O
and	O
precise	B
adaptive	O
learning	O
system	O
being	O
the	O
first	O
widely	O
commercially	O
used	O
neural	B
network	I
it	O
could	O
be	O
found	O
in	O
nearly	O
every	O
analog	O
telephone	O
for	O
realtime	O
adaptive	O
echo	O
filtering	O
and	O
was	O
trained	O
by	O
menas	O
of	O
the	O
widrow-hoff	O
rule	O
or	O
delta	B
rule	I
at	O
that	O
time	O
hoff	O
later	O
co-founder	O
of	O
intel	O
corporation	O
was	O
a	O
phd	O
student	O
of	O
widrow	O
who	O
himself	O
is	O
known	O
as	O
the	O
inventor	O
of	O
modern	O
microprocessors	O
one	O
advantage	O
the	O
delta	B
rule	I
had	O
over	O
the	O
original	O
perceptron	B
learning	I
algorithm	B
was	O
its	O
adaptivity	O
if	O
the	O
difference	O
between	O
the	O
actual	O
output	B
and	O
the	O
correct	O
solution	O
was	O
large	O
the	O
connecting	O
weights	O
also	O
changed	O
in	O
larger	O
steps	O
the	O
smaller	O
the	O
steps	O
the	O
closer	O
the	O
target	B
was	O
disadvantage	O
missapplication	O
led	O
to	O
infinitesimal	O
small	O
steps	O
close	O
to	O
the	O
target	B
in	O
the	O
following	O
stagnation	O
and	O
out	O
of	O
fear	O
of	O
scientific	O
unpopularity	O
of	O
the	O
neural	O
networks	O
adaline	O
was	O
renamed	O
in	O
adaptive	O
linear	O
element	O
which	O
was	O
undone	O
again	O
later	O
on	O
karl	O
steinbuch	O
introduced	O
technical	O
realizations	O
of	O
associative	O
memory	O
which	O
can	O
be	O
seen	O
as	O
predecessors	O
of	O
today	O
s	O
neural	O
associative	O
memories	O
additionally	O
he	O
described	O
concepts	O
for	O
neural	O
techniques	O
and	O
analyzed	O
their	O
possibilities	O
and	O
limits	O
in	O
his	O
book	O
learning	O
machines	O
nils	O
nilsson	O
gave	O
an	O
overview	O
of	O
the	O
progress	O
and	O
works	O
of	O
this	O
period	B
of	O
neural	B
network	I
research	O
it	O
was	O
assumed	O
that	O
the	O
basic	O
principles	O
of	O
self-learning	O
and	O
therefore	O
generally	O
speaking	O
systems	O
had	O
already	O
been	O
discovered	O
today	O
this	O
assumption	O
seems	O
to	O
be	O
an	O
exorbitant	O
overestimation	O
but	O
at	O
that	O
time	O
it	O
provided	O
for	O
high	O
popularity	O
and	O
sufficient	O
research	O
funds	O
marvin	O
minsky	O
and	O
seymour	O
papert	O
published	O
a	O
precise	B
mathe	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
development	O
accelerates	O
first	O
spread	O
use	O
backprop	O
developed	O
dkriesel	O
com	O
history	O
of	O
neural	O
networks	O
research	O
funds	O
were	O
stopped	O
matical	O
analysis	O
of	O
the	O
perceptron	B
to	O
show	O
that	O
the	O
perceptron	B
model	O
was	O
not	O
capable	O
of	O
representing	O
many	O
important	O
problems	B
xor	O
problem	O
and	O
linear	B
separability	I
and	O
so	O
put	O
an	O
end	O
to	O
overestimation	O
popularity	O
and	O
research	O
funds	O
the	O
implication	O
that	O
more	O
powerful	O
models	O
would	O
show	O
exactly	O
the	O
same	O
problems	B
and	O
the	O
forecast	O
that	O
the	O
entire	O
field	O
would	O
be	O
a	O
research	O
dead	O
end	O
resulted	O
in	O
a	O
nearly	O
complete	O
decline	O
in	O
research	O
funds	O
for	O
the	O
next	O
years	O
no	O
matter	O
how	O
incorrect	O
these	O
forecasts	O
were	O
from	O
today	O
s	O
point	O
of	O
view	O
long	O
silence	O
and	O
slow	O
reconstruction	O
the	O
research	O
funds	O
were	O
as	O
previouslymentioned	O
extremely	O
short	O
everywhere	O
research	O
went	O
on	O
but	O
there	O
were	O
neither	O
conferences	O
nor	O
other	O
events	O
and	O
therefore	O
only	O
few	O
publications	O
this	O
isolation	O
of	O
individual	O
researchers	O
provided	O
for	O
many	O
independently	O
developed	O
neural	B
network	I
paradigms	O
they	O
researched	O
but	O
there	O
was	O
no	O
discourse	O
among	O
them	O
in	O
spite	O
of	O
the	O
poor	O
appreciation	O
the	O
field	O
received	O
the	O
basic	O
theories	O
for	O
the	O
still	O
continuing	O
renaissance	O
were	O
laid	O
at	O
that	O
time	O
teuvo	O
kohonen	O
introduced	O
a	O
the	O
linear	O
associator	O
model	O
of	O
a	O
model	O
of	O
an	O
associative	O
memory	O
in	O
the	O
same	O
year	O
such	O
a	O
model	O
was	O
presented	O
independently	O
and	O
from	O
a	O
neurophysiologist	O
s	O
point	O
of	O
view	O
by	O
james	O
a	O
anderson	O
christoph	O
von	O
der	O
malsburg	O
used	O
a	O
neuron	B
model	O
that	O
was	O
nonlinear	O
and	O
biologically	O
more	O
motivated	O
for	O
his	O
dissertation	O
in	O
harvard	O
paul	O
werbos	O
developed	O
a	O
learning	O
procedure	O
called	O
backpropagation	B
of	I
error	I
but	O
it	O
was	O
not	O
until	O
one	O
decade	O
later	O
that	O
this	O
procedure	O
reached	O
today	O
s	O
importance	O
and	O
thereafter	O
stephen	O
instance	O
grossberg	O
presented	O
many	O
papers	O
in	O
which	O
numerous	O
neural	O
models	O
are	O
analyzed	O
mathematically	O
furthermore	O
he	O
dedicated	O
himself	O
to	O
the	O
problem	O
of	O
keeping	O
a	O
neural	B
network	I
capable	O
of	O
destroying	O
already	O
learned	O
associations	O
under	O
cooperation	O
of	O
gail	O
carpenter	O
led	O
to	O
models	O
of	O
adaptive	O
this	O
resonance	B
theory	O
learning	O
without	O
teuvo	O
kohonen	O
described	O
the	O
feature	O
maps	O
self-organizing	O
also	O
known	O
as	O
kohonen	O
maps	O
he	O
was	O
looking	O
for	O
the	O
mechanisms	O
involving	O
self-organization	O
in	O
the	O
brain	B
knew	O
that	O
the	O
information	O
about	O
the	O
creation	O
of	O
a	O
being	O
is	O
stored	O
in	O
the	O
genome	O
which	O
has	O
however	O
not	O
enough	O
memory	O
for	O
a	O
structure	O
like	O
the	O
brain	B
as	O
a	O
consequence	O
the	O
brain	B
has	O
to	O
organize	O
and	O
create	O
itself	O
for	O
the	O
most	O
part	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
introduction	O
motivation	O
and	O
history	O
dkriesel	O
com	O
john	O
hopfield	O
also	O
invented	O
the	O
so-called	O
hopfield	B
networks	I
which	O
are	O
inspired	O
by	O
the	O
laws	O
of	O
magnetism	O
in	O
physics	O
they	O
were	O
not	O
widely	O
used	O
in	O
technical	O
applications	O
but	O
the	O
field	O
of	O
neural	O
networks	O
slowly	O
regained	O
importance	O
fukushima	B
miyake	B
and	O
ito	B
introduced	O
the	O
neural	O
model	O
of	O
the	O
neocognitron	B
which	O
could	O
recognize	O
handwritten	O
characters	O
and	O
was	O
an	O
extension	O
of	O
the	O
cognitron	O
network	O
already	O
developed	O
in	O
renaissance	O
through	O
the	O
influence	O
of	O
john	O
hopfield	O
who	O
had	O
personally	O
convinced	O
many	O
researchers	O
of	O
the	O
importance	O
of	O
the	O
field	O
and	O
the	O
wide	O
publication	O
of	O
backpropagation	B
by	O
rumelhart	B
hinton	B
and	O
williams	B
the	O
field	O
of	O
neural	O
networks	O
slowly	O
showed	O
signs	O
of	O
upswing	O
john	O
hopfield	O
published	O
an	O
article	O
describing	O
a	O
way	O
of	O
finding	O
acceptable	O
solutions	O
for	O
the	O
travelling	O
salesman	O
problem	O
by	O
using	O
hopfield	O
nets	O
the	O
backpropagation	B
of	I
error	I
learning	O
procedure	O
as	O
a	O
generalization	B
of	O
the	O
delta	B
rule	I
was	O
separately	O
developed	O
and	O
widely	O
published	O
by	O
the	O
parallel	O
distributed	O
processing	O
group	O
non-linearly-separable	O
problems	B
could	O
be	O
solved	O
by	O
multilayer	B
perceptrons	O
and	O
marvin	O
minsky	O
s	O
negative	O
evaluations	O
were	O
disproven	O
at	O
a	O
single	O
blow	O
at	O
the	O
same	O
time	O
a	O
certain	O
kind	O
of	O
fatigue	O
spread	O
in	O
the	O
field	O
of	O
artificial	B
intelligence	I
caused	O
by	O
a	O
series	O
of	O
failures	O
and	O
unfulfilled	O
hopes	O
from	O
this	O
time	O
on	O
the	O
development	O
of	O
the	O
field	O
of	O
research	O
has	O
almost	O
been	O
explosive	O
it	O
can	O
no	O
longer	O
be	O
itemized	O
but	O
some	O
of	O
its	O
results	O
will	O
be	O
seen	O
in	O
the	O
following	O
exercises	O
exercise	O
give	O
one	O
example	O
for	O
each	O
of	O
the	O
following	O
topics	O
a	O
book	O
on	O
neural	O
networks	O
or	O
neuroin	O
formatics	O
a	O
collaborative	O
group	O
of	O
a	O
university	O
working	O
with	O
neural	O
networks	O
a	O
software	O
tool	O
realizing	O
neural	O
net	O
works	O
a	O
company	O
using	O
neural	O
networks	O
and	O
a	O
product	O
or	O
service	O
being	O
realized	O
by	O
means	O
of	O
neural	O
networks	O
exercise	O
show	O
at	O
least	O
four	O
applications	O
of	O
technical	O
neural	O
networks	O
two	O
from	O
the	O
field	O
of	O
pattern	B
recognition	I
and	O
two	O
from	O
the	O
field	O
of	O
function	B
approximation	B
exercise	O
briefly	O
characterize	O
the	O
four	O
development	O
phases	O
of	O
neural	O
networks	O
and	O
give	O
expressive	O
examples	O
for	O
each	O
phase	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
renaissance	O
chapter	O
biological	O
neural	O
networks	O
how	O
do	O
biological	O
systems	O
solve	O
problems	B
how	O
does	O
a	O
system	O
of	O
neurons	O
work	O
how	O
can	O
we	O
understand	O
its	O
functionality	O
what	O
are	O
different	O
quantities	O
of	O
neurons	O
able	O
to	O
do	O
where	O
in	O
the	O
nervous	B
system	I
does	O
information	B
processing	I
occur	O
a	O
short	O
biological	O
overview	O
of	O
the	O
complexity	O
of	O
simple	O
elements	O
of	O
neural	O
information	B
processing	I
followed	O
by	O
some	O
thoughts	O
about	O
their	O
simplification	O
in	O
order	O
to	O
technically	O
adapt	O
them	O
before	O
we	O
begin	O
to	O
describe	O
the	O
technical	O
side	O
of	O
neural	O
networks	O
it	O
would	O
be	O
useful	O
to	O
briefly	O
discuss	O
the	O
biology	O
of	O
neural	O
networks	O
and	O
the	O
cognition	O
of	O
living	O
organisms	O
the	O
reader	O
may	O
skip	O
the	O
following	O
chapter	O
without	O
missing	O
any	O
technical	O
information	O
on	O
the	O
other	O
hand	O
i	O
recommend	O
to	O
read	O
the	O
said	O
excursus	O
if	O
you	O
want	O
to	O
learn	O
something	O
about	O
the	O
underlying	O
neurophysiology	O
and	O
see	O
that	O
our	O
small	O
approaches	O
the	O
technical	O
neural	O
networks	O
are	O
only	O
caricatures	O
of	O
nature	O
and	O
how	O
powerful	O
their	O
natural	O
counterparts	O
must	O
be	O
when	O
our	O
small	O
approaches	O
are	O
already	O
that	O
effective	O
now	O
we	O
want	O
to	O
take	O
a	O
brief	O
look	O
at	O
the	O
nervous	B
system	I
of	O
vertebrates	O
we	O
will	O
start	O
with	O
a	O
very	O
rough	O
granularity	O
and	O
then	O
proceed	O
with	O
the	O
brain	B
and	O
up	O
to	O
the	O
neural	O
level	O
for	O
further	O
reading	O
i	O
want	O
to	O
recommend	O
the	O
books	O
which	O
helped	O
me	O
a	O
lot	O
during	O
this	O
chapter	O
the	O
vertebrate	O
nervous	B
system	I
the	O
entire	O
information	B
processing	I
system	O
i	O
e	O
the	O
vertebrate	O
nervous	B
system	I
consists	O
of	O
the	O
central	B
nervous	B
system	I
and	O
the	O
peripheral	B
nervous	B
system	I
which	O
is	O
only	O
a	O
first	O
and	O
simple	O
subdivision	O
in	O
reality	O
such	O
a	O
rigid	O
subdivision	O
does	O
not	O
make	O
sense	O
but	O
here	O
it	O
is	O
helpful	O
to	O
outline	O
the	O
information	B
processing	I
in	O
a	O
body	O
peripheral	O
and	O
central	B
nervous	B
system	I
the	O
peripheral	B
nervous	B
system	I
comprises	O
the	O
nerves	O
that	O
are	O
situated	O
outside	O
of	O
the	O
brain	B
or	O
the	O
spinal	B
cord	I
these	O
nerves	O
form	O
a	O
branched	O
and	O
very	O
dense	O
network	O
throughout	O
the	O
whole	O
body	O
the	O
pe	O
chapter	O
biological	O
neural	O
networks	O
dkriesel	O
com	O
ripheral	O
nervous	B
system	I
includes	O
for	O
example	O
the	O
spinal	O
nerves	O
which	O
pass	O
out	O
of	O
the	O
spinal	B
cord	I
within	O
the	O
level	O
of	O
each	O
vertebra	O
of	O
the	O
spine	O
and	O
supply	O
extremities	O
neck	O
and	O
trunk	O
but	O
also	O
the	O
cranial	O
nerves	O
directly	O
leading	O
to	O
the	O
brain	B
the	O
central	B
nervous	B
system	I
however	O
is	O
the	O
within	O
the	O
vertebrate	O
it	O
is	O
the	O
place	O
where	O
information	O
received	O
by	O
the	O
sense	O
organs	O
are	O
stored	O
and	O
managed	O
furthermore	O
it	O
controls	O
the	O
inner	O
processes	O
in	O
the	O
body	O
and	O
last	O
but	O
not	O
least	O
coordinates	O
the	O
motor	O
functions	O
of	O
the	O
organism	O
the	O
vertebrate	O
central	B
nervous	B
system	I
consists	O
of	O
the	O
brain	B
and	O
the	O
spinal	B
cord	I
however	O
we	O
want	O
to	O
focus	O
on	O
the	O
brain	B
which	O
can	O
for	O
the	O
purpose	O
of	O
simplification	O
be	O
divided	O
into	O
four	O
areas	O
on	O
the	O
next	O
page	O
to	O
be	O
discussed	O
here	O
the	O
cerebrum	B
is	O
responsible	O
for	O
abstract	O
thinking	O
processes	O
the	O
cerebrum	B
is	O
one	O
of	O
the	O
areas	O
of	O
the	O
brain	B
that	O
changed	O
most	O
during	O
evolution	O
along	O
an	O
axis	O
running	O
from	O
the	O
lateral	B
face	O
to	O
the	O
back	O
of	O
the	O
head	O
this	O
area	O
is	O
divided	O
into	O
two	O
hemispheres	O
which	O
are	O
organized	O
in	O
a	O
folded	O
structure	O
these	O
cerebral	O
hemispheres	O
are	O
connected	O
by	O
one	O
strong	O
nerve	O
cord	O
and	O
several	O
small	O
ones	O
a	O
large	O
number	O
of	O
neurons	O
are	O
located	O
in	O
the	O
cerebral	B
cortex	I
which	O
is	O
approx	O
cm	O
thick	O
and	O
divided	O
into	O
different	O
cortical	O
fields	O
each	O
having	O
a	O
specific	B
task	O
to	O
figure	O
illustration	O
of	O
the	O
central	B
nervous	B
system	I
with	O
spinal	B
cord	I
and	O
brain	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
vertebrate	O
nervous	B
system	I
and	O
errors	O
are	O
continually	O
corrected	O
for	O
this	O
purpose	O
the	O
cerebellum	B
has	O
direct	B
sensory	O
information	O
about	O
muscle	O
lengths	O
as	O
well	O
as	O
acoustic	O
and	O
visual	B
information	O
furthermore	O
it	O
also	O
receives	O
messages	O
about	O
more	O
abstract	O
motor	O
signals	O
coming	O
from	O
the	O
cerebrum	B
in	O
the	O
human	O
brain	B
the	O
cerebellum	B
is	O
considerably	O
smaller	O
than	O
the	O
cerebrum	B
but	O
this	O
is	O
rather	O
an	O
exception	O
in	O
many	O
vertebrates	O
this	O
ratio	O
is	O
less	O
pronounced	O
if	O
we	O
take	O
a	O
look	O
at	O
vertebrate	O
evolution	O
we	O
will	O
notice	O
that	O
the	O
cerebellum	B
is	O
not	O
small	O
but	O
the	O
cerebum	O
is	O
large	O
least	O
it	O
is	O
the	O
most	O
highly	O
developed	O
structure	O
in	O
the	O
vertebrate	O
brain	B
the	O
two	O
remaining	O
brain	B
areas	O
should	O
also	O
be	O
briefly	O
discussed	O
the	O
diencephalon	O
and	O
the	O
brainstem	B
the	O
diencephalon	O
controls	O
fundamental	O
physiological	O
processes	O
the	O
interbrain	B
includes	O
parts	O
of	O
which	O
only	O
the	O
thalamus	B
will	O
be	O
briefly	O
discussed	O
this	O
part	O
of	O
the	O
diencephalon	O
mediates	O
between	O
sensory	O
and	O
motor	O
signals	O
and	O
the	O
cerebrum	B
particularly	O
the	O
thalamus	B
decides	O
which	O
part	O
of	O
the	O
information	O
is	O
transferred	O
to	O
the	O
cerebrum	B
so	O
that	O
especially	O
less	O
important	O
sensory	O
perceptions	O
can	O
be	O
suppressed	O
at	O
short	O
notice	O
to	O
avoid	O
overloads	O
another	O
part	O
of	O
the	O
diencephalon	O
is	O
the	O
hypothalamus	B
which	O
controls	O
a	O
number	O
of	O
processes	O
within	O
the	O
body	O
the	O
diencephalon	O
thalamus	B
filters	O
incoming	O
data	O
figure	O
illustration	O
of	O
the	O
brain	B
the	O
colored	O
areas	O
of	O
the	O
brain	B
are	O
discussed	O
in	O
the	O
text	O
the	O
more	O
we	O
turn	O
from	O
abstract	O
information	B
processing	I
to	O
direct	B
reflexive	O
processing	O
the	O
darker	O
the	O
areas	O
of	O
the	O
brain	B
are	O
colored	O
fulfill	O
primary	B
cortical	O
fields	O
are	O
responsible	O
for	O
processing	O
qualitative	O
information	O
such	O
as	O
the	O
management	O
of	O
differthe	O
visual	B
cortex	O
ent	O
perceptions	O
is	O
responsible	O
for	O
the	O
management	O
of	O
vision	O
association	B
cortical	O
fields	O
however	O
perform	O
more	O
abstract	O
association	B
and	O
thinking	O
processes	O
they	O
also	O
contain	O
our	O
memory	O
the	O
cerebellum	B
controls	O
and	O
coordinates	O
motor	O
functions	O
the	O
cerebellum	B
is	O
located	O
below	O
the	O
cerebrum	B
therefore	O
it	O
is	O
closer	O
to	O
the	O
spinal	B
cord	I
accordingly	O
it	O
serves	O
less	O
abstract	O
functions	O
with	O
higher	O
priority	O
here	O
large	O
parts	O
of	O
motor	O
coordination	O
are	O
performed	O
i	O
e	O
balance	O
and	O
movements	O
are	O
controlled	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
biological	O
neural	O
networks	O
dkriesel	O
com	O
is	O
also	O
heavily	O
involved	O
in	O
the	O
human	O
circadian	O
rhythm	O
clock	O
and	O
the	O
sensation	O
of	O
pain	O
the	O
brainstem	B
connects	O
the	O
brain	B
with	O
the	O
spinal	B
cord	I
and	O
controls	O
reflexes	O
in	O
comparison	O
with	O
the	O
diencephalon	O
the	O
brainstem	B
or	O
the	O
cerebri	O
respectively	O
is	O
phylogenetically	O
much	O
older	O
roughly	O
speaking	O
it	O
is	O
the	O
spinal	B
cord	I
and	O
thus	O
the	O
connection	B
between	O
brain	B
and	O
spinal	B
cord	I
the	O
brainstem	B
can	O
also	O
be	O
divided	O
into	O
different	O
areas	O
some	O
of	O
which	O
will	O
be	O
exemplarily	O
introduced	O
in	O
this	O
chapter	O
the	O
functions	O
will	O
be	O
discussed	O
from	O
abstract	O
functions	O
towards	O
more	O
fundamental	O
ones	O
one	O
important	O
component	O
is	O
the	O
pons	B
a	O
kind	O
of	O
transit	O
station	O
for	O
many	O
nerve	O
signals	O
from	O
brain	B
to	O
body	O
and	O
vice	O
versa	O
if	O
the	O
pons	B
is	O
damaged	O
by	O
a	O
cerebral	O
infarct	O
then	O
the	O
result	O
could	O
be	O
the	O
locked-in	B
syndrome	I
a	O
condition	O
in	O
which	O
a	O
patient	O
is	O
within	O
his	O
own	O
body	O
he	O
is	O
conscious	O
and	O
aware	O
with	O
no	O
loss	O
of	O
cognitive	O
function	O
but	O
cannot	O
move	O
or	O
communicate	O
by	O
any	O
means	O
only	O
his	O
senses	O
of	O
sight	O
hearing	O
smell	O
and	O
taste	O
are	O
generally	O
working	O
perfectly	O
normal	O
locked-in	O
patients	O
may	O
often	O
be	O
able	O
to	O
communicate	O
with	O
others	O
by	O
blinking	O
or	O
moving	O
their	O
eyes	O
furthermore	O
the	O
brainstem	B
is	O
responsible	O
for	O
many	O
fundamental	O
reflexes	O
such	O
as	O
the	O
blinking	O
reflex	O
or	O
coughing	O
all	O
parts	O
of	O
the	O
nervous	B
system	I
have	O
one	O
thing	O
in	O
common	O
information	B
processing	I
this	O
is	O
accomplished	O
by	O
huge	O
accumulations	O
of	O
billions	O
of	O
very	O
similar	O
cells	O
whose	O
structure	O
is	O
very	O
simple	O
but	O
which	O
communicate	O
continuously	O
large	O
groups	O
of	O
these	O
cells	O
send	O
coordinated	O
signals	O
and	O
thus	O
reach	O
the	O
enormous	O
information	B
processing	I
capacity	O
we	O
are	O
familiar	O
with	O
from	O
our	O
brain	B
we	O
will	O
now	O
leave	O
the	O
level	O
of	O
brain	B
areas	O
and	O
continue	O
with	O
the	O
cellular	O
level	O
of	O
the	O
body	O
the	O
level	O
of	O
neurons	O
neurons	O
are	O
information	B
processing	I
cells	O
before	O
specifying	O
the	O
functions	O
and	O
processes	O
within	O
a	O
neuron	B
we	O
will	O
give	O
a	O
rough	O
description	O
of	O
neuron	B
functions	O
a	O
neuron	B
is	O
nothing	O
more	O
than	O
a	O
switch	O
with	O
information	O
input	B
and	O
output	B
the	O
switch	O
will	O
be	O
activated	O
if	O
there	O
are	O
enough	O
stimuli	O
of	O
other	O
neurons	O
hitting	O
the	O
information	O
input	B
then	O
at	O
the	O
information	O
output	B
a	O
pulse	O
is	O
sent	O
to	O
for	O
example	O
other	O
neurons	O
components	O
of	O
a	O
neuron	B
now	O
we	O
want	O
to	O
take	O
a	O
look	O
at	O
the	O
components	O
of	O
a	O
neuron	B
on	O
the	O
facing	O
page	O
in	O
doing	O
so	O
we	O
will	O
follow	O
the	O
way	O
the	O
electrical	B
information	O
takes	O
within	O
the	O
neuron	B
the	O
dendrites	O
of	O
a	O
neuron	B
receive	O
the	O
information	O
by	O
special	O
connections	O
the	O
synapses	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
neuron	B
figure	O
illustration	O
of	O
a	O
biological	O
neuron	B
with	O
the	O
components	O
discussed	O
in	O
this	O
text	O
synapses	B
weight	B
the	O
individual	O
parts	O
of	O
information	O
incoming	O
signals	O
from	O
other	O
neurons	O
or	O
cells	O
are	O
transferred	O
to	O
a	O
neuron	B
by	O
special	O
connections	O
the	O
synapses	B
such	O
connections	O
can	O
usually	O
be	O
found	O
at	O
the	O
dendrites	O
of	O
a	O
neuron	B
sometimes	O
also	O
directly	O
at	O
the	O
soma	B
we	O
distinguish	O
between	O
electrical	B
and	O
chemical	B
synapses	B
the	O
electrical	B
synapse	O
is	O
the	O
simpler	O
variant	O
an	O
electrical	B
signal	O
received	O
by	O
the	O
synapse	O
i	O
e	O
coming	O
from	O
the	O
presynaptic	O
side	O
is	O
directly	O
transferred	O
to	O
the	O
postsynaptic	O
nucleus	O
of	O
the	O
cell	O
thus	O
there	O
is	O
a	O
direct	B
strong	O
unadjustable	O
connection	B
between	O
the	O
signal	O
transmitter	O
and	O
the	O
signal	O
receiver	O
which	O
is	O
for	O
example	O
relevant	O
to	O
shortening	O
reactions	O
that	O
must	O
be	O
coded	O
within	O
a	O
living	O
organism	O
the	O
chemical	B
synapse	O
is	O
the	O
more	O
distinctive	O
variant	O
here	O
the	O
electrical	B
coupling	O
of	O
source	O
and	O
target	B
does	O
not	O
take	O
place	O
the	O
coupling	O
is	O
interrupted	O
by	O
the	O
synaptic	B
cleft	I
this	O
cleft	O
electrically	O
separates	O
the	O
presynaptic	O
side	O
from	O
the	O
postsynaptic	O
one	O
you	O
might	O
think	O
that	O
nevertheless	O
the	O
information	O
has	O
to	O
flow	O
so	O
we	O
will	O
discuss	O
how	O
this	O
happens	O
it	O
is	O
not	O
an	O
electrical	B
but	O
a	O
chemical	B
process	O
on	O
the	O
presynaptic	O
side	O
of	O
the	O
synaptic	B
cleft	I
the	O
electrical	B
signal	O
is	O
converted	O
into	O
a	O
chemical	B
signal	O
a	O
process	O
induced	O
by	O
chemical	B
cues	O
released	O
there	O
so-called	O
neurotransmitters	B
these	O
neurotransmitters	B
cross	O
the	O
synaptic	B
cleft	I
and	O
transfer	O
the	O
information	O
into	O
the	O
nucleus	O
of	O
the	O
cell	O
is	O
a	O
very	O
simple	O
explanation	O
but	O
later	O
on	O
we	O
will	O
see	O
how	O
this	O
exactly	O
works	O
where	O
it	O
is	O
reconverted	O
into	O
electrical	B
information	O
the	O
neurotransmitters	B
are	O
degraded	O
very	O
fast	O
so	O
that	O
it	O
is	O
possible	O
to	O
re	O
electrical	B
synapse	O
simple	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
cemical	O
synapse	O
is	O
more	O
complex	O
but	O
also	O
more	O
powerful	O
chapter	O
biological	O
neural	O
networks	O
dkriesel	O
com	O
lease	O
very	O
precise	B
information	O
pulses	O
here	O
too	O
in	O
spite	O
of	O
the	O
more	O
complex	O
functioning	O
the	O
chemical	B
synapse	O
has	O
compared	O
with	O
the	O
electrical	B
synapse	O
utmost	O
advantages	O
one-way	O
connection	B
a	O
chemical	B
synapse	O
is	O
a	O
one-way	O
connection	B
due	O
to	O
the	O
fact	O
that	O
there	O
is	O
no	O
direct	B
electrical	B
connection	B
between	O
the	O
pre-	O
and	O
postsynaptic	O
area	O
electrical	B
pulses	O
area	O
cannot	O
flash	O
over	O
to	O
the	O
presynaptic	O
area	O
in	O
the	O
postsynaptic	O
adjustability	O
there	O
is	O
a	O
large	O
number	O
of	O
different	O
neurotransmitters	B
that	O
can	O
also	O
be	O
released	O
in	O
various	O
quantities	O
in	O
a	O
synaptic	B
cleft	I
there	O
are	O
neurotransmitters	B
that	O
stimulate	O
the	O
postsynaptic	O
cell	O
nucleus	O
and	O
others	O
that	O
slow	O
down	O
such	O
stimulation	O
some	O
synapses	B
transfer	O
a	O
strongly	O
stimulating	O
signal	O
some	O
only	O
weakly	O
stimulating	O
ones	O
the	O
adjustability	O
varies	O
a	O
lot	O
and	O
one	O
of	O
the	O
central	O
points	O
in	O
the	O
examination	O
of	O
the	O
learning	O
ability	O
of	O
the	O
brain	B
is	O
that	O
here	O
the	O
synapses	B
are	O
variable	B
too	O
that	O
is	O
over	O
time	O
they	O
can	O
form	O
a	O
stronger	O
or	O
weaker	O
connection	B
dendrites	O
collect	O
all	O
parts	O
of	O
information	O
dendrites	O
branch	O
like	O
trees	O
from	O
the	O
cell	O
nucleus	O
of	O
the	O
neuron	B
is	O
called	O
soma	B
and	O
receive	O
electrical	B
signals	O
from	O
many	O
different	O
sources	O
which	O
are	O
then	O
transferred	O
into	O
the	O
nucleus	O
of	O
the	O
cell	O
the	O
amount	O
of	O
branching	O
dendrites	O
is	O
also	O
called	O
dendrite	B
tree	B
in	O
the	O
soma	B
the	O
weighted	O
information	O
is	O
accumulated	O
after	O
the	O
cell	O
nucleus	O
has	O
received	O
a	O
plenty	O
of	O
activating	O
and	O
inhibiting	O
signals	O
by	O
synapses	B
or	O
dendrites	O
the	O
soma	B
accumulates	O
these	O
signals	O
as	O
soon	O
as	O
the	O
accumulated	O
signal	O
exceeds	O
a	O
certain	O
value	O
threshold	B
value	I
the	O
cell	O
nucleus	O
of	O
the	O
neuron	B
activates	O
an	O
electrical	B
pulse	O
which	O
then	O
is	O
transmitted	O
to	O
the	O
neurons	O
connected	O
to	O
the	O
current	O
one	O
the	O
axon	B
transfers	O
outgoing	O
pulses	O
the	O
pulse	O
is	O
transferred	O
to	O
other	O
neurons	O
by	O
means	O
of	O
the	O
axon	B
the	O
axon	B
is	O
a	O
long	O
slender	O
extension	O
of	O
the	O
soma	B
in	O
an	O
extreme	O
case	O
an	O
axon	B
can	O
stretch	O
up	O
to	O
one	O
meter	O
within	O
the	O
spinal	B
cord	I
the	O
axon	B
is	O
electrically	O
isolated	O
in	O
order	O
to	O
achieve	O
a	O
better	O
conduction	O
of	O
the	O
electrical	B
signal	O
will	O
return	B
to	O
this	O
point	O
later	O
on	O
and	O
it	O
leads	O
to	O
dendrites	O
which	O
transfer	O
the	O
information	O
to	O
for	O
example	O
other	O
neurons	O
so	O
now	O
we	O
are	O
back	O
at	O
the	O
beginning	O
of	O
our	O
description	O
of	O
the	O
neuron	B
elements	O
an	O
axon	B
can	O
however	O
transfer	O
information	O
to	O
other	O
kinds	O
of	O
cells	O
in	O
order	O
to	O
control	O
them	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
neuron	B
electrochemical	O
processes	O
in	O
the	O
neuron	B
and	O
its	O
components	O
after	O
having	O
pursued	O
the	O
path	O
of	O
an	O
electrical	B
signal	O
from	O
the	O
dendrites	O
via	O
the	O
synapses	B
to	O
the	O
nucleus	O
of	O
the	O
cell	O
and	O
from	O
there	O
via	O
the	O
axon	B
into	O
other	O
dendrites	O
we	O
now	O
want	O
to	O
take	O
a	O
small	O
step	O
from	O
biology	O
towards	O
technology	O
in	O
doing	O
so	O
a	O
simplified	O
introduction	O
of	O
the	O
electrochemical	O
information	B
processing	I
should	O
be	O
provided	O
neurons	O
maintain	O
electrical	B
membrane	B
potential	O
one	O
fundamental	O
aspect	O
is	O
the	O
fact	O
that	O
compared	O
to	O
their	O
environment	B
the	O
neurons	O
show	O
a	O
difference	O
in	O
electrical	B
charge	O
a	O
potential	O
in	O
the	O
membrane	B
of	O
the	O
neuron	B
the	O
charge	O
is	O
different	O
from	O
the	O
charge	O
on	O
the	O
outside	O
this	O
difference	O
in	O
charge	O
is	O
a	O
central	O
concept	O
that	O
is	O
important	O
to	O
understand	O
the	O
processes	O
within	O
the	O
neuron	B
the	O
difference	O
is	O
called	O
membrane	B
potential	O
the	O
membrane	B
potential	O
i	O
e	O
the	O
difference	O
in	O
charge	O
is	O
created	O
by	O
several	O
kinds	O
of	O
charged	O
atoms	O
whose	O
concentration	O
varies	O
within	O
and	O
outside	O
of	O
the	O
neuron	B
if	O
we	O
penetrate	O
the	O
membrane	B
from	O
the	O
inside	O
outwards	O
we	O
will	O
find	O
certain	O
kinds	O
of	O
ions	O
more	O
often	O
or	O
less	O
often	O
than	O
on	O
the	O
inside	O
this	O
descent	O
or	O
ascent	O
of	O
concentration	O
is	O
called	O
a	O
concentration	B
gradient	B
let	O
us	O
first	O
take	O
a	O
look	O
at	O
the	O
membrane	B
potential	O
in	O
the	O
resting	O
state	B
of	O
the	O
neu	O
ron	O
i	O
e	O
we	O
assume	O
that	O
no	O
electrical	B
signals	O
are	O
received	O
from	O
the	O
outside	O
in	O
this	O
case	O
the	O
membrane	B
potential	O
is	O
mv	O
since	O
we	O
have	O
learned	O
that	O
this	O
potential	O
depends	O
on	O
the	O
concentration	O
gradients	O
of	O
various	O
ions	O
there	O
is	O
of	O
course	O
the	O
central	O
question	O
of	O
how	O
to	O
maintain	O
these	O
concentration	O
gradients	O
normally	O
diffusion	O
predominates	O
and	O
therefore	O
each	O
ion	B
is	O
eager	O
to	O
decrease	O
concentration	O
gradients	O
and	O
to	O
spread	O
out	O
evenly	O
if	O
this	O
happens	O
the	O
membrane	B
potential	O
will	O
move	O
towards	O
mv	O
so	O
finally	O
there	O
would	O
be	O
no	O
membrane	B
potential	O
anymore	O
thus	O
the	O
neuron	B
actively	O
maintains	O
its	O
membrane	B
potential	O
to	O
be	O
able	O
to	O
process	O
information	O
how	O
does	O
this	O
work	O
the	O
secret	O
is	O
the	O
membrane	B
itself	O
which	O
is	O
permeable	O
to	O
some	O
ions	O
but	O
not	O
for	O
others	O
to	O
maintain	O
the	O
potential	O
various	O
mechanisms	O
are	O
in	O
progress	O
at	O
the	O
same	O
time	O
concentration	B
gradient	B
as	O
if	O
the	O
described	O
above	O
the	O
ions	O
try	O
to	O
be	O
as	O
uniformly	O
distributed	O
as	O
possible	O
the	O
concentration	O
of	O
an	O
ion	B
is	O
higher	O
on	O
the	O
inside	O
of	O
the	O
neuron	B
than	O
on	O
it	O
will	O
try	O
to	O
diffuse	O
the	O
outside	O
and	O
vice	O
versa	O
to	O
outside	O
charged	O
ion	B
k	O
the	O
positively	O
occurs	O
very	O
frequently	O
within	O
the	O
neuron	B
but	O
less	O
frequently	O
outside	O
of	O
the	O
neuron	B
and	O
therefore	O
it	O
slowly	O
diffuses	O
out	O
through	O
the	O
neuron	B
s	O
membrane	B
but	O
another	O
group	O
of	O
negative	O
ions	O
collectively	O
called	O
a	O
remains	O
within	O
the	O
neuron	B
since	O
the	O
membrane	B
is	O
not	O
permeable	O
to	O
them	O
thus	O
the	O
inside	O
of	O
the	O
neuron	B
becomes	O
negatively	O
charged	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
biological	O
neural	O
networks	O
dkriesel	O
com	O
negative	O
a	O
ions	O
remain	O
positive	O
k	O
ions	O
disappear	O
and	O
so	O
the	O
inside	O
of	O
the	O
cell	O
becomes	O
more	O
negative	O
the	O
result	O
is	O
another	O
gradient	B
electrical	B
gradient	B
the	O
electrical	B
gradient	B
acts	O
contrary	O
to	O
the	O
concentration	B
gradient	B
the	O
intracellular	O
charge	O
is	O
now	O
very	O
strong	O
therefore	O
it	O
attracts	O
positive	O
ions	O
k	O
wants	O
to	O
get	O
back	O
into	O
the	O
cell	O
if	O
these	O
two	O
gradients	O
were	O
now	O
left	O
alone	O
they	O
would	O
eventually	O
balance	O
out	O
reach	O
a	O
steady	O
state	B
and	O
a	O
membrane	B
potential	O
of	O
mv	O
would	O
develop	O
but	O
we	O
want	O
to	O
achieve	O
a	O
resting	O
membrane	B
potential	O
of	O
mv	O
thus	O
there	O
seem	O
to	O
exist	O
some	O
disturbances	O
which	O
prevent	O
this	O
furthermore	O
there	O
is	O
another	O
important	O
ion	B
na	O
for	O
which	O
the	O
membrane	B
is	O
not	O
very	O
permeable	O
but	O
which	O
however	O
slowly	O
pours	O
through	O
the	O
membrane	B
into	O
the	O
cell	O
as	O
a	O
result	O
the	O
sodium	O
is	O
driven	O
into	O
the	O
cell	O
all	O
the	O
more	O
on	O
the	O
one	O
hand	O
there	O
is	O
less	O
sodium	O
within	O
the	O
neuron	B
than	O
outside	O
the	O
neuron	B
on	O
the	O
other	O
hand	O
sodium	O
is	O
positively	O
charged	O
but	O
the	O
interior	O
of	O
the	O
cell	O
has	O
negative	O
charge	O
which	O
is	O
a	O
second	O
reason	O
for	O
the	O
sodium	O
wanting	O
to	O
get	O
into	O
the	O
cell	O
due	O
to	O
the	O
low	O
diffusion	O
of	O
sodium	O
into	O
the	O
cell	O
the	O
intracellular	O
sodium	O
concentration	O
increases	O
but	O
at	O
the	O
same	O
time	O
the	O
inside	O
of	O
the	O
cell	O
becomes	O
less	O
negative	O
so	O
that	O
k	O
pours	O
in	O
more	O
slowly	O
can	O
see	O
that	O
this	O
is	O
a	O
complex	O
mechanism	O
where	O
everything	O
is	O
influenced	O
by	O
everything	O
the	O
sodium	O
shifts	O
the	O
intracellular	O
equilibrium	O
from	O
negative	O
to	O
less	O
negative	O
compared	O
with	O
its	O
environment	B
but	O
even	O
with	O
these	O
two	O
ions	O
a	O
standstill	O
with	O
all	O
gradients	O
being	O
balanced	O
out	O
could	O
still	O
be	O
achieved	O
now	O
the	O
last	O
piece	O
of	O
the	O
puzzle	O
gets	O
into	O
the	O
game	O
a	O
rather	O
the	O
protein	O
atp	B
actively	O
transports	O
ions	O
against	O
the	O
direction	O
they	O
actually	O
want	O
to	O
take	O
sodium	O
is	O
actively	O
pumped	O
out	O
of	O
the	O
cell	O
although	O
it	O
tries	O
to	O
get	O
into	O
the	O
cell	O
along	O
the	O
concentration	B
gradient	B
and	O
the	O
electrical	B
gradient	B
potassium	O
however	O
diffuses	O
strongly	O
out	O
of	O
the	O
cell	O
but	O
is	O
actively	O
pumped	O
back	O
into	O
it	O
for	O
this	O
reason	O
the	O
pump	O
is	O
also	O
called	O
sodium-potassium	B
pump	I
the	O
pump	O
maintains	O
the	O
concentration	B
gradient	B
for	O
the	O
sodium	O
as	O
well	O
as	O
for	O
the	O
potassium	O
so	O
that	O
some	O
sort	O
of	O
steady	O
state	B
equilibrium	O
is	O
created	O
and	O
finally	O
the	O
resting	O
potential	O
is	O
mv	O
as	O
observed	O
all	O
in	O
all	O
the	O
membrane	B
potential	O
is	O
maintained	O
by	O
the	O
fact	O
that	O
the	O
membrane	B
is	O
impermeable	O
to	O
some	O
ions	O
and	O
other	O
ions	O
are	O
actively	O
pumped	O
against	O
the	O
concentration	O
and	O
electrical	B
gradients	O
now	O
that	O
we	O
know	O
that	O
each	O
neuron	B
has	O
a	O
membrane	B
potential	O
we	O
want	O
to	O
observe	O
how	O
a	O
neuron	B
receives	O
and	O
transmits	O
signals	O
the	O
neuron	B
is	O
activated	O
by	O
changes	O
in	O
the	O
membrane	B
potential	O
above	O
we	O
have	O
learned	O
that	O
sodium	O
and	O
potassium	O
can	O
diffuse	O
through	O
the	O
membrane	B
sodium	O
slowly	O
potassium	O
faster	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
neuron	B
they	O
move	O
through	O
channels	O
within	O
the	O
membrane	B
the	O
sodium	O
and	O
potassium	O
channels	O
in	O
addition	O
to	O
these	O
permanently	O
open	O
channels	O
responsible	O
for	O
diffusion	O
and	O
balanced	O
by	O
the	O
sodiumpotassium	O
pump	O
there	O
also	O
exist	O
channels	O
that	O
are	O
not	O
always	O
open	O
but	O
which	O
only	O
response	O
required	O
since	O
the	O
opening	O
of	O
these	O
channels	O
changes	O
the	O
concentration	O
of	O
ions	O
within	O
and	O
outside	O
of	O
the	O
membrane	B
it	O
also	O
changes	O
the	O
membrane	B
potential	O
these	O
controllable	O
channels	O
are	O
opened	O
as	O
soon	O
as	O
the	O
accumulated	O
received	O
stimulus	B
exceeds	O
a	O
certain	O
threshold	O
for	O
example	O
stimuli	O
can	O
be	O
received	O
from	O
other	O
neurons	O
or	O
have	O
other	O
causes	O
there	O
exist	O
for	O
example	O
specialized	O
forms	O
of	O
neurons	O
the	O
sensory	O
cells	O
for	O
which	O
a	O
light	O
incidence	O
could	O
be	O
such	O
a	O
stimulus	B
if	O
the	O
incoming	O
amount	O
of	O
light	O
exceeds	O
the	O
threshold	O
controllable	O
channels	O
are	O
opened	O
the	O
said	O
threshold	O
threshold	B
potential	I
lies	O
at	O
about	O
mv	O
as	O
soon	O
as	O
the	O
received	O
stimuli	O
reach	O
this	O
value	O
the	O
neuron	B
is	O
activated	O
and	O
an	O
electrical	B
signal	O
an	O
action	B
potential	I
is	O
initiated	O
then	O
this	O
signal	O
is	O
transmitted	O
to	O
the	O
cells	O
connected	O
to	O
the	O
observed	O
neuron	B
i	O
e	O
the	O
cells	O
to	O
the	O
neuron	B
now	O
we	O
want	O
to	O
take	O
a	O
closer	O
look	O
at	O
the	O
different	O
stages	O
of	O
the	O
action	B
potential	I
on	O
the	O
next	O
page	O
resting	O
state	B
only	O
permanently	O
open	O
sodium	O
and	O
potassium	O
channels	O
are	O
permeable	O
the	O
membrane	B
potential	O
is	O
at	O
mv	O
and	O
actively	O
kept	O
there	O
by	O
the	O
neuron	B
the	O
stimulus	B
up	O
to	O
the	O
threshold	O
a	O
stimulus	B
opens	O
channels	O
so	O
that	O
sodium	O
can	O
pour	O
in	O
the	O
intracellular	O
charge	O
becomes	O
more	O
positive	O
as	O
soon	O
as	O
the	O
membrane	B
potential	O
exceeds	O
the	O
threshold	O
of	O
mv	O
the	O
action	B
potential	I
is	O
initiated	O
by	O
the	O
opening	O
of	O
many	O
sodium	O
channels	O
depolarization	B
sodium	O
is	O
pouring	O
in	O
remember	O
sodium	O
wants	O
to	O
pour	O
into	O
the	O
cell	O
because	O
there	O
is	O
a	O
lower	O
intracellular	O
than	O
extracellular	O
concentration	O
of	O
sodium	O
additionally	O
the	O
cell	O
is	O
dominated	O
by	O
a	O
negative	O
environment	B
which	O
attracts	O
the	O
positive	O
sodium	O
ions	O
this	O
massive	O
influx	O
of	O
sodium	O
drastically	O
increases	O
the	O
membrane	B
potential	O
up	O
to	O
approx	O
mv	O
which	O
is	O
the	O
electrical	B
pulse	O
i	O
e	O
the	O
action	B
potential	I
repolarization	B
now	O
the	O
sodium	O
channels	O
are	O
closed	O
and	O
the	O
potassium	O
channels	O
are	O
opened	O
the	O
positively	O
charged	O
ions	O
want	O
to	O
leave	O
the	O
positive	O
interior	O
of	O
the	O
cell	O
additionally	O
the	O
intracellular	O
concentration	O
is	O
much	O
higher	O
than	O
the	O
extracellular	O
one	O
which	O
increases	O
the	O
e	O
ux	O
of	O
ions	O
even	O
more	O
the	O
interior	O
of	O
the	O
cell	O
is	O
once	O
again	O
more	O
negatively	O
charged	O
than	O
the	O
exterior	O
hyperpolarization	B
sodium	O
as	O
well	O
as	O
potassium	O
channels	O
are	O
closed	O
again	O
at	O
first	O
the	O
membrane	B
potential	O
is	O
slightly	O
more	O
negative	O
than	O
the	O
resting	O
potential	O
this	O
is	O
due	O
to	O
the	O
fact	O
that	O
the	O
potassium	O
channels	O
close	O
more	O
slowly	O
as	O
a	O
result	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
biological	O
neural	O
networks	O
dkriesel	O
com	O
figure	O
initiation	O
of	O
action	B
potential	I
over	O
time	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
neuron	B
charged	O
potassium	O
effuses	O
because	O
of	O
its	O
lower	O
extracellular	O
concentration	O
after	O
a	O
refractory	B
period	B
of	O
ms	O
the	O
resting	O
state	B
is	O
re-established	O
so	O
that	O
the	O
neuron	B
can	O
react	O
to	O
newly	O
applied	O
stimuli	O
with	O
an	O
action	B
potential	I
in	O
simple	O
terms	O
the	O
refractory	B
period	B
is	O
a	O
mandatory	O
break	O
a	O
neuron	B
has	O
to	O
take	O
in	O
order	O
to	O
regenerate	O
the	O
shorter	O
this	O
break	O
is	O
the	O
more	O
often	O
a	O
neuron	B
can	O
fire	O
per	O
time	O
then	O
the	O
resulting	O
pulse	O
is	O
transmitted	O
by	O
the	O
axon	B
in	O
the	O
axon	B
a	O
pulse	O
is	O
conducted	O
in	O
a	O
saltatory	O
way	O
we	O
have	O
already	O
learned	O
that	O
the	O
axon	B
is	O
used	O
to	O
transmit	O
the	O
action	B
potential	I
across	O
long	O
distances	O
you	O
will	O
find	O
an	O
illustration	O
of	O
a	O
neuron	B
including	O
an	O
axon	B
in	O
fig	O
on	O
page	O
the	O
axon	B
is	O
a	O
long	O
slender	O
extension	O
of	O
the	O
soma	B
in	O
vertebrates	O
it	O
is	O
normally	O
coated	O
by	O
a	O
myelin	B
sheath	I
that	O
consists	O
of	O
schwann	O
cells	O
the	O
pns	O
or	O
oligodendrocytes	B
the	O
cns	O
which	O
insulate	O
the	O
axon	B
very	O
well	O
from	O
electrical	B
activity	O
at	O
a	O
distance	O
of	O
there	O
are	O
gaps	O
between	O
these	O
cells	O
the	O
so-called	O
nodes	B
of	I
ranvier	I
the	O
said	O
gaps	O
appear	O
where	O
one	O
insulate	O
cell	O
ends	O
and	O
the	O
next	O
one	O
begins	O
it	O
is	O
obvious	O
that	O
at	O
such	O
a	O
node	O
the	O
axon	B
is	O
less	O
insulated	O
schwann	O
cells	O
as	O
well	O
as	O
oligodendrocytes	B
are	O
varieties	O
of	O
the	O
glial	O
cells	O
there	O
are	O
about	O
times	O
more	O
glial	O
cells	O
than	O
neurons	O
they	O
surround	O
the	O
neurons	O
glue	O
insulate	O
them	O
from	O
each	O
other	O
provide	O
energy	O
etc	O
now	O
you	O
may	O
assume	O
that	O
these	O
less	O
insulated	O
nodes	O
are	O
a	O
disadvantage	O
of	O
the	O
axon	B
however	O
they	O
are	O
not	O
at	O
the	O
nodes	O
mass	O
can	O
be	O
transferred	O
between	O
the	O
intracellular	O
and	O
extracellular	O
area	O
a	O
transfer	O
that	O
is	O
impossible	O
at	O
those	O
parts	O
of	O
the	O
axon	B
which	O
are	O
situated	O
between	O
two	O
nodes	O
and	O
therefore	O
insulated	O
by	O
the	O
myelin	B
sheath	I
this	O
mass	O
transfer	O
permits	O
the	O
generation	O
of	O
signals	O
similar	O
to	O
the	O
generation	O
of	O
the	O
action	B
potential	I
within	O
the	O
soma	B
the	O
action	B
potential	I
is	O
transferred	O
as	O
follows	O
it	O
does	O
not	O
continuously	O
travel	O
along	O
the	O
axon	B
but	O
jumps	O
from	O
node	O
to	O
node	O
thus	O
a	O
series	O
of	O
depolarization	B
travels	O
along	O
the	O
nodes	B
of	I
ranvier	I
one	O
action	B
potential	I
initiates	O
the	O
next	O
one	O
and	O
mostly	O
even	O
several	O
nodes	O
are	O
active	O
at	O
the	O
same	O
time	O
here	O
the	O
pulse	O
from	O
node	O
to	O
node	O
is	O
responsible	O
for	O
the	O
name	O
of	O
this	O
pulse	O
conductor	O
saltatory	B
conductor	I
obviously	O
the	O
pulse	O
will	O
move	O
faster	O
if	O
its	O
jumps	O
are	O
larger	O
axons	O
with	O
large	O
internodes	B
mm	O
achieve	O
a	O
signal	O
dispersion	O
of	O
approx	O
meters	O
per	O
second	O
however	O
the	O
internodes	B
cannot	O
grow	O
indefinitely	O
since	O
the	O
action	B
potential	I
to	O
be	O
transferred	O
would	O
fade	O
too	O
much	O
until	O
it	O
reaches	O
the	O
next	O
node	O
so	O
the	O
nodes	O
have	O
a	O
task	O
too	O
to	O
constantly	O
amplify	O
the	O
signal	O
the	O
cells	O
receiving	O
the	O
action	B
potential	I
are	O
attached	O
to	O
the	O
end	O
of	O
the	O
axon	B
often	O
connected	O
by	O
dendrites	O
and	O
synapses	B
as	O
already	O
indicated	O
above	O
the	O
action	B
potentials	O
are	O
not	O
only	O
generated	O
by	O
information	O
received	O
by	O
the	O
dendrites	O
from	O
other	O
neurons	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
biological	O
neural	O
networks	O
dkriesel	O
com	O
receptor	O
cells	O
are	O
modified	O
neurons	O
there	O
are	O
different	O
receptor	O
cells	O
for	O
various	O
types	O
of	O
perceptions	O
action	B
potentials	O
can	O
also	O
be	O
generated	O
by	O
sensory	O
information	O
an	O
organism	O
receives	O
from	O
its	O
environment	B
through	O
its	O
sensory	O
cells	O
specialized	O
receptor	O
cells	O
are	O
able	O
to	O
perceive	O
specific	B
stimulus	B
energies	O
such	O
as	O
light	O
temperature	O
and	O
sound	O
or	O
the	O
existence	O
of	O
certain	O
molecules	O
for	O
example	O
the	O
sense	O
of	O
smell	O
this	O
is	O
working	O
because	O
of	O
the	O
fact	O
that	O
these	O
sensory	O
cells	O
are	O
actually	O
modified	O
neurons	O
they	O
do	O
not	O
receive	O
electrical	B
signals	O
via	O
dendrites	O
but	O
the	O
existence	O
of	O
the	O
stimulus	B
being	O
specific	B
for	O
the	O
receptor	B
cell	I
ensures	O
that	O
the	O
ion	B
channels	O
open	O
and	O
an	O
action	B
potential	I
is	O
developed	O
this	O
process	O
of	O
transforming	O
stimulus	B
energy	O
into	O
changes	O
in	O
the	O
membrane	B
potential	O
is	O
called	O
sensory	B
transduction	I
usually	O
the	O
stimulus	B
energy	O
itself	O
is	O
too	O
weak	O
to	O
directly	O
cause	O
nerve	O
signals	O
therefore	O
the	O
signals	O
are	O
amplified	O
either	O
during	O
transduction	O
or	O
by	O
means	O
of	O
the	O
stimulus-conducting	B
apparatus	I
the	O
resulting	O
action	B
potential	I
can	O
be	O
processed	O
by	O
other	O
neurons	O
and	O
is	O
then	O
transmitted	O
into	O
the	O
thalamus	B
which	O
is	O
as	O
we	O
have	O
already	O
learned	O
a	O
gateway	O
to	O
the	O
cerebral	B
cortex	I
and	O
therefore	O
can	O
reject	O
sensory	O
impressions	O
according	O
to	O
current	O
relevance	O
and	O
thus	O
prevent	O
an	O
abundance	O
of	O
information	O
to	O
be	O
managed	O
primary	B
receptors	O
transmit	O
their	O
pulses	O
directly	O
to	O
the	O
nervous	B
system	I
a	O
good	O
example	O
for	O
this	O
is	O
the	O
sense	O
of	O
pain	O
here	O
the	O
stimulus	B
intensity	O
is	O
proportional	O
to	O
the	O
amplitude	O
of	O
the	O
action	B
potential	I
technically	O
this	O
is	O
an	O
amplitude	O
modulation	O
secondary	B
receptors	O
however	O
continuously	O
transmit	O
pulses	O
these	O
pulses	O
control	O
the	O
amount	O
of	O
the	O
related	O
neurotransmitter	O
which	O
is	O
responsible	O
for	O
transferring	O
the	O
stimulus	B
the	O
stimulus	B
in	O
turn	O
controls	O
the	O
frequency	O
of	O
the	O
action	B
potential	I
of	O
the	O
receiving	O
neuron	B
this	O
process	O
is	O
a	O
frequency	O
modulation	O
an	O
encoding	O
of	O
the	O
stimulus	B
which	O
allows	O
to	O
better	O
perceive	O
the	O
increase	O
and	O
decrease	O
of	O
a	O
stimulus	B
there	O
can	O
be	O
individual	O
receptor	O
cells	O
or	O
cells	O
forming	O
complex	O
sensory	O
organs	O
eyes	O
or	O
ears	O
they	O
can	O
receive	O
stimuli	O
within	O
the	O
body	O
means	O
of	O
the	O
interoceptors	O
as	O
well	O
as	O
stimuli	O
outside	O
of	O
the	O
body	O
means	O
of	O
the	O
exteroceptors	O
after	O
having	O
outlined	O
how	O
information	O
is	O
received	O
from	O
the	O
environment	B
it	O
will	O
be	O
interesting	O
to	O
look	O
at	O
how	O
the	O
information	O
is	O
processed	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
receptor	O
cells	O
information	O
is	O
processed	O
on	O
every	O
level	O
of	O
the	O
nervous	B
system	I
there	O
is	O
no	O
reason	O
to	O
believe	O
that	O
all	O
received	O
information	O
is	O
transmitted	O
to	O
the	O
brain	B
and	O
processed	O
there	O
and	O
that	O
the	O
brain	B
ensures	O
that	O
it	O
is	O
in	O
the	O
form	O
of	O
motor	O
pulses	O
only	O
thing	O
an	O
organism	O
can	O
actually	O
do	O
within	O
its	O
environment	B
is	O
to	O
move	O
the	O
information	B
processing	I
is	O
entirely	O
decentralized	O
in	O
order	O
to	O
illustrate	O
this	O
principle	O
we	O
want	O
to	O
take	O
a	O
look	O
at	O
some	O
examples	O
which	O
leads	O
us	O
again	O
from	O
the	O
abstract	O
to	O
the	O
fundamental	O
in	O
our	O
hierarchy	O
of	O
information	B
processing	I
it	O
is	O
certain	O
that	O
information	O
is	O
processed	O
in	O
the	O
cerebrum	B
which	O
is	O
the	O
most	O
developed	O
natural	O
information	B
processing	I
structure	O
the	O
midbrain	O
and	O
the	O
thalamus	B
which	O
serves	O
as	O
we	O
have	O
already	O
learned	O
as	O
a	O
gateway	O
to	O
the	O
cerebral	B
cortex	I
are	O
situated	O
much	O
lower	O
in	O
the	O
hierarchy	O
the	O
filtering	O
of	O
information	O
with	O
respect	O
to	O
the	O
current	O
relevance	O
executed	O
by	O
the	O
midbrain	O
is	O
a	O
very	O
important	O
method	O
of	O
information	B
processing	I
too	O
but	O
even	O
the	O
thalamus	B
does	O
not	O
receive	O
any	O
preprocessed	O
stimuli	O
from	O
the	O
outside	O
now	O
let	O
us	O
continue	O
with	O
the	O
lowest	O
level	O
the	O
sensory	O
cells	O
on	O
the	O
lowest	O
level	O
i	O
e	O
at	O
the	O
receptor	O
cells	O
the	O
information	O
is	O
not	O
only	O
received	O
and	O
transferred	O
but	O
directly	O
processed	O
one	O
of	O
the	O
main	O
aspects	O
of	O
this	O
subject	O
is	O
to	O
prevent	O
the	O
transmission	O
of	O
stimuli	O
to	O
the	O
central	B
nervous	B
system	I
because	O
of	O
sensory	B
adaptation	I
due	O
to	O
continuous	B
stimulation	O
many	O
receptor	O
cells	O
automatically	O
become	O
insensitive	O
to	O
stimuli	O
thus	O
receptor	O
cells	O
are	O
not	O
a	O
direct	B
mapping	O
of	O
specific	B
stimulus	B
energy	O
onto	O
action	B
potentials	O
but	O
depend	O
on	O
the	O
past	O
other	O
sensors	O
change	O
their	O
sensitivity	O
according	O
to	O
the	O
situation	B
there	O
are	O
taste	O
receptors	O
which	O
respond	O
more	O
or	O
less	O
to	O
the	O
same	O
stimulus	B
according	O
to	O
the	O
nutritional	O
condition	O
of	O
the	O
organism	O
even	O
before	O
a	O
stimulus	B
reaches	O
the	O
receptor	O
cells	O
information	B
processing	I
can	O
already	O
be	O
executed	O
by	O
a	O
preceding	O
signal	O
carrying	O
apparatus	O
for	O
example	O
in	O
the	O
form	O
of	O
amplification	O
the	O
external	O
and	O
the	O
internal	O
ear	O
have	O
a	O
specific	B
shape	O
to	O
amplify	O
the	O
sound	O
which	O
also	O
allows	O
in	O
association	B
with	O
the	O
sensory	O
cells	O
of	O
the	O
sense	O
of	O
hearing	O
the	O
sensory	O
stimulus	B
only	O
to	O
increase	O
logarithmically	O
with	O
the	O
intensity	O
of	O
the	O
heard	O
signal	O
on	O
closer	O
examination	O
this	O
is	O
necessary	O
since	O
the	O
sound	O
pressure	O
of	O
the	O
signals	O
for	O
which	O
the	O
ear	O
is	O
constructed	O
can	O
vary	O
over	O
a	O
wide	O
exponential	O
range	O
here	O
a	O
logarithmic	O
measurement	O
is	O
an	O
advantage	O
firstly	O
an	O
overload	O
is	O
prevented	O
and	O
secondly	O
the	O
fact	O
that	O
the	O
intensity	O
measurement	O
of	O
intensive	O
signals	O
will	O
be	O
less	O
precise	B
doesn	O
t	O
matter	O
as	O
well	O
if	O
a	O
jet	O
fighter	O
is	O
starting	O
next	O
to	O
you	O
small	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
biological	O
neural	O
networks	O
dkriesel	O
com	O
changes	O
in	O
the	O
noise	O
level	O
can	O
be	O
ignored	O
just	O
to	O
get	O
a	O
feeling	O
for	O
sensory	O
organs	O
and	O
information	B
processing	I
in	O
the	O
organism	O
we	O
will	O
briefly	O
describe	O
light	O
sensing	O
organs	O
i	O
e	O
organs	O
often	O
found	O
in	O
nature	O
for	O
the	O
third	O
light	O
sensing	O
organ	O
described	O
below	O
the	O
single	O
lens	B
eye	O
we	O
will	O
discuss	O
the	O
information	B
processing	I
in	O
the	O
eye	O
an	O
outline	O
of	O
common	O
light	O
sensing	O
organs	O
for	O
many	O
organisms	O
it	O
turned	O
out	O
to	O
be	O
extremely	O
useful	O
to	O
be	O
able	O
to	O
perceive	O
electromagnetic	O
radiation	O
in	O
certain	O
regions	O
of	O
the	O
spectrum	O
consequently	O
sensory	O
organs	O
have	O
been	O
developed	O
which	O
can	O
detect	O
such	O
electromagnetic	O
radiation	O
and	O
the	O
wavelength	O
range	O
of	O
the	O
radiation	O
perceivable	O
by	O
the	O
human	O
eye	O
is	O
called	O
visible	O
range	O
or	O
simply	O
light	O
the	O
different	O
wavelengths	O
of	O
this	O
electromagnetic	O
radiation	O
are	O
perceived	O
by	O
the	O
human	O
eye	O
as	O
different	O
colors	O
the	O
visible	O
range	O
of	O
the	O
electromagnetic	O
radiation	O
is	O
different	O
for	O
each	O
organism	O
some	O
organisms	O
cannot	O
see	O
the	O
colors	O
ranges	O
we	O
can	O
see	O
others	O
can	O
even	O
perceive	O
additional	O
wavelength	O
ranges	O
in	O
the	O
uv	O
range	O
before	O
we	O
begin	O
with	O
the	O
human	O
being	O
in	O
order	O
to	O
get	O
a	O
broader	O
knowledge	O
of	O
the	O
sense	O
of	O
sight	O
we	O
briefly	O
want	O
to	O
look	O
at	O
two	O
organs	O
of	O
sight	O
which	O
from	O
an	O
evolutionary	O
point	O
of	O
view	O
exist	O
much	O
longer	O
than	O
the	O
human	O
compound	O
eyes	O
and	O
pinhole	O
eyes	O
only	O
provide	O
high	O
temporal	O
or	O
spatial	O
resolution	O
let	O
us	O
first	O
take	O
a	O
look	O
at	O
the	O
so-called	O
compound	B
eye	I
on	O
the	O
next	O
page	O
which	O
is	O
for	O
example	O
common	O
in	O
insects	O
and	O
crustaceans	O
the	O
compound	B
eye	I
consists	O
of	O
a	O
great	O
number	O
of	O
small	O
individual	O
eyes	O
if	O
we	O
look	O
at	O
the	O
compound	B
eye	I
from	O
the	O
outside	O
the	O
individual	O
eyes	O
are	O
clearly	O
visible	O
and	O
arranged	O
in	O
a	O
hexagonal	O
pattern	O
each	O
individual	O
eye	O
has	O
its	O
own	O
nerve	O
fiber	O
which	O
is	O
connected	O
to	O
the	O
insect	O
brain	B
since	O
the	O
individual	O
eyes	O
can	O
be	O
distinguished	O
it	O
is	O
obvious	O
that	O
the	O
number	O
of	O
pixels	O
i	O
e	O
the	O
spatial	O
resolution	O
of	O
compound	O
eyes	O
must	O
be	O
very	O
low	O
and	O
the	O
image	O
is	O
blurred	O
but	O
compound	O
eyes	O
have	O
advantages	O
too	O
especially	O
for	O
fast-flying	O
insects	O
certain	O
compound	O
eyes	O
process	O
more	O
than	O
images	O
per	O
second	O
the	O
human	O
eye	O
however	O
movies	O
with	O
images	O
per	O
second	O
appear	O
as	O
a	O
fluent	O
motion	O
compound	B
eye	I
high	O
temp	O
low	O
spatial	O
resolution	O
pinhole	O
eyes	O
are	O
for	O
example	O
found	O
in	O
octopus	O
species	O
and	O
work	O
as	O
you	O
can	O
guess	O
similar	O
to	O
a	O
pinhole	O
camera	O
a	O
pinhole	O
pinhole	B
eye	I
has	O
a	O
very	O
small	O
opening	O
for	O
camera	O
high	O
spat	O
light	O
entry	O
which	O
projects	O
a	O
sharp	O
image	O
low	O
onto	O
the	O
sensory	O
cells	O
behind	O
thus	O
the	O
temporal	O
spatial	O
resolution	O
is	O
much	O
higher	O
than	O
in	O
resolution	O
the	O
compound	B
eye	I
but	O
due	O
to	O
the	O
very	O
small	O
opening	O
for	O
light	O
entry	O
the	O
resulting	O
image	O
is	O
less	O
bright	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
receptor	O
cells	O
the	O
retina	B
does	O
not	O
only	O
receive	O
information	O
but	O
is	O
also	O
responsible	O
for	O
information	B
processing	I
the	O
light	O
signals	O
falling	O
on	O
the	O
eye	O
are	O
received	O
by	O
the	O
retina	B
and	O
directly	O
preprocessed	O
by	O
several	O
layers	O
of	O
informationprocessing	O
cells	O
we	O
want	O
to	O
briefly	O
discuss	O
the	O
different	O
steps	O
of	O
this	O
information	B
processing	I
and	O
in	O
doing	O
so	O
we	O
follow	O
the	O
way	O
of	O
the	O
information	O
carried	O
by	O
the	O
light	O
photoreceptors	O
receive	O
the	O
light	O
signal	O
und	O
cause	O
action	B
potentials	O
are	O
different	O
receptors	O
for	O
different	O
color	O
components	O
and	O
light	O
intensities	O
these	O
receptors	O
are	O
the	O
real	O
light-receiving	O
part	O
of	O
the	O
retina	B
and	O
they	O
are	O
sensitive	O
to	O
such	O
an	O
extent	O
that	O
only	O
one	O
single	O
photon	O
falling	O
on	O
the	O
retina	B
can	O
cause	O
an	O
action	B
potential	I
then	O
several	O
photoreceptors	O
transmit	O
their	O
signals	O
to	O
one	O
single	O
bipolar	B
cell	I
this	O
means	O
that	O
here	O
the	O
information	O
has	O
already	O
been	O
summarized	O
finally	O
the	O
now	O
transformed	O
light	O
signal	O
travels	O
from	O
several	O
bipolar	O
cells	O
into	O
ganglion	O
cells	O
various	O
bipolar	O
cells	O
can	O
transmit	O
their	O
information	O
to	O
one	O
ganglion	B
cell	I
the	O
higher	O
the	O
number	O
of	O
photoreceptors	O
that	O
affect	O
the	O
ganglion	B
cell	I
the	O
larger	O
the	O
field	O
of	O
perception	O
the	O
receptive	B
field	I
which	O
covers	O
the	O
ganglions	O
and	O
the	O
less	O
there	O
are	O
different	O
kinds	O
of	O
bipolar	O
cells	O
as	O
well	O
but	O
to	O
discuss	O
all	O
of	O
them	O
would	O
go	O
too	O
far	O
figure	O
compound	B
eye	I
of	O
a	O
robber	O
fly	O
single	O
lens	B
eyes	O
combine	O
the	O
advantages	O
of	O
the	O
other	O
two	O
eye	O
types	O
but	O
they	O
are	O
more	O
complex	O
the	O
light	O
sensing	O
organ	O
common	O
in	O
vertebrates	O
is	O
the	O
single	B
lense	I
eye	I
the	O
resulting	O
image	O
is	O
a	O
sharp	O
high-resolution	O
image	O
of	O
the	O
environment	B
at	O
high	O
or	O
variable	B
light	O
intensity	O
on	O
the	O
other	O
hand	O
it	O
is	O
more	O
complex	O
similar	O
to	O
the	O
pinhole	B
eye	I
the	O
light	O
enters	O
through	O
an	O
opening	O
and	O
is	O
projected	O
onto	O
a	O
layer	O
of	O
sensory	O
cells	O
in	O
the	O
eye	O
but	O
in	O
contrast	O
to	O
the	O
pinhole	B
eye	I
the	O
size	O
of	O
the	O
pupil	B
can	O
be	O
adapted	O
to	O
the	O
lighting	O
conditions	O
means	O
of	O
the	O
iris	B
muscle	O
which	O
expands	O
or	O
contracts	O
the	O
pupil	B
these	O
differences	O
in	O
pupil	B
dilation	O
require	O
to	O
actively	O
focus	O
the	O
image	O
therefore	O
the	O
single	O
lens	B
eye	O
contains	O
an	O
additional	O
adjustable	O
lens	B
single	B
lense	I
eye	I
high	O
temp	O
and	O
spat	O
resolution	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
biological	O
neural	O
networks	O
dkriesel	O
com	O
sharp	O
is	O
the	O
image	O
in	O
the	O
area	O
of	O
this	O
ganglion	B
cell	I
so	O
the	O
information	O
is	O
already	O
reduced	O
directly	O
in	O
the	O
retina	B
and	O
the	O
overall	O
image	O
is	O
for	O
example	O
blurred	O
in	O
the	O
peripheral	O
field	O
of	O
vision	O
so	O
far	O
we	O
have	O
learned	O
about	O
the	O
information	B
processing	I
in	O
the	O
retina	B
only	O
as	O
a	O
top-down	B
structure	O
now	O
we	O
want	O
to	O
take	O
a	O
look	O
at	O
the	O
horizontal	O
and	O
amacrine	O
cells	O
these	O
and	O
compressing	O
cells	O
are	O
not	O
connected	O
from	O
the	O
front	O
backwards	O
but	O
laterally	O
they	O
allow	O
the	O
light	O
signals	O
to	O
influence	O
themselves	O
laterally	O
directly	O
during	O
the	O
information	B
processing	I
in	O
the	O
retina	B
a	O
much	O
more	O
powerful	O
information	B
processing	I
method	O
of	O
than	O
blurring	O
when	O
the	O
horizontal	O
cells	O
are	O
excited	O
by	O
a	O
photoreceptor	O
they	O
are	O
able	O
to	O
excite	O
other	O
nearby	O
photoreceptors	O
and	O
at	O
the	O
same	O
time	O
inhibit	O
more	O
distant	O
bipolar	O
cells	O
and	O
receptors	O
this	O
ensures	O
the	O
clear	O
perception	O
of	O
outlines	O
and	O
bright	O
points	O
amacrine	O
cells	O
can	O
further	O
intensify	O
certain	O
stimuli	O
by	O
distributing	O
information	O
from	O
bipolar	O
cells	O
to	O
several	O
ganglion	O
cells	O
or	O
by	O
inhibiting	O
ganglions	O
these	O
first	O
steps	O
of	O
transmitting	O
visual	B
information	O
to	O
the	O
brain	B
show	O
that	O
information	O
is	O
processed	O
from	O
the	O
first	O
moment	O
the	O
information	O
is	O
received	O
and	O
on	O
the	O
other	O
hand	O
is	O
processed	O
in	O
parallel	O
within	O
millions	O
of	O
information-processing	O
cells	O
the	O
system	O
s	O
power	O
and	O
resistance	O
to	O
errors	O
is	O
based	O
upon	O
this	O
massive	O
division	O
of	O
work	O
the	O
amount	O
of	O
neurons	O
in	O
living	O
organisms	O
at	O
different	O
stages	O
of	O
development	O
an	O
overview	O
of	O
different	O
organisms	O
and	O
their	O
neural	O
capacity	O
large	O
part	O
from	O
neurons	O
are	O
required	O
by	O
the	O
nervous	B
system	I
of	O
a	O
nematode	O
worm	O
which	O
serves	O
as	O
a	O
popular	O
model	O
organism	O
in	O
biology	O
nematodes	O
live	O
in	O
the	O
soil	O
and	O
feed	O
on	O
bacteria	O
neurons	O
make	O
an	O
ant	O
simplify	O
matters	O
we	O
neglect	O
the	O
fact	O
that	O
some	O
ant	O
species	O
also	O
can	O
have	O
more	O
or	O
less	O
efficient	O
nervous	O
systems	O
due	O
to	O
the	O
use	O
of	O
different	O
attractants	O
and	O
odors	O
ants	O
are	O
able	O
to	O
engage	O
in	O
complex	O
social	O
behavior	O
and	O
form	O
huge	O
states	O
with	O
millions	O
of	O
individuals	O
if	O
you	O
regard	O
such	O
an	O
ant	O
state	B
as	O
an	O
individual	O
it	O
has	O
a	O
cognitive	O
capacity	O
similar	O
to	O
a	O
chimpanzee	O
or	O
even	O
a	O
human	O
with	O
neurons	O
the	O
nervous	B
system	I
of	O
a	O
fly	O
can	O
be	O
constructed	O
a	O
fly	O
can	O
evade	O
an	O
object	O
in	O
real-time	O
in	O
threedimensional	O
space	O
it	O
can	O
land	O
upon	O
the	O
ceiling	O
upside	O
down	O
has	O
a	O
considerable	O
sensory	O
system	O
because	O
of	O
compound	O
eyes	O
vibrissae	O
nerves	O
at	O
the	O
end	O
of	O
its	O
legs	O
and	O
much	O
more	O
thus	O
a	O
fly	O
has	O
considerable	O
differential	O
and	O
integral	O
calculus	O
in	O
high	O
dimensions	O
implemented	O
hardware	O
we	O
all	O
know	O
that	O
a	O
fly	O
is	O
not	O
easy	O
to	O
catch	O
of	O
course	O
the	O
bodily	O
functions	O
are	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
amount	O
of	O
neurons	O
in	O
living	O
organisms	O
also	O
controlled	O
by	O
neurons	O
but	O
these	O
should	O
be	O
ignored	O
here	O
with	O
neurons	O
we	O
have	O
enough	O
cerebral	O
matter	O
to	O
create	O
a	O
honeybee	O
honeybees	O
build	O
colonies	O
and	O
have	O
amazing	O
capabilities	O
in	O
the	O
field	O
of	O
aerial	O
reconnaissance	O
and	O
navigation	O
neurons	O
result	O
in	O
a	O
mouse	O
and	O
here	O
the	O
world	O
of	O
vertebrates	O
already	O
begins	O
neurons	O
are	O
sufficient	O
for	O
a	O
rat	O
an	O
animal	O
which	O
is	O
denounced	O
as	O
being	O
extremely	O
intelligent	O
and	O
are	O
often	O
used	O
to	O
participate	O
in	O
a	O
variety	O
of	O
intelligence	O
tests	O
representative	O
for	O
the	O
animal	O
world	O
rats	O
have	O
an	O
extraordinary	O
sense	O
of	O
smell	O
and	O
orientation	O
and	O
they	O
also	O
show	O
social	O
behavior	O
the	O
brain	B
of	O
a	O
frog	O
can	O
be	O
positioned	O
within	O
the	O
same	O
dimension	O
the	O
frog	O
has	O
a	O
complex	O
build	O
with	O
many	O
functions	O
it	O
can	O
swim	O
and	O
has	O
evolved	O
complex	O
behavior	O
a	O
frog	O
can	O
continuously	O
target	B
the	O
said	O
fly	O
by	O
means	O
of	O
his	O
eyes	O
while	O
jumping	O
in	O
three-dimensional	O
space	O
and	O
and	O
catch	O
it	O
with	O
its	O
tongue	O
with	O
considerable	O
probability	O
neurons	O
make	O
a	O
bat	O
the	O
bat	O
can	O
navigate	O
in	O
total	B
darkness	O
through	O
a	O
room	O
exact	O
up	O
to	O
several	O
centimeters	O
by	O
only	O
using	O
their	O
sense	O
of	O
hearing	O
it	O
uses	O
acoustic	O
signals	O
to	O
localize	O
self-camouflaging	O
insects	O
some	O
moths	O
have	O
a	O
certain	O
wing	O
structure	O
that	O
reflects	O
less	O
sound	O
waves	O
and	O
the	O
echo	O
will	O
be	O
small	O
and	O
also	O
eats	O
its	O
prey	O
while	O
flying	O
neurons	O
are	O
required	O
by	O
the	O
brain	B
of	O
a	O
dog	O
companion	O
of	O
man	O
for	O
ages	O
now	O
take	O
a	O
look	O
at	O
another	O
popular	O
companion	O
of	O
man	O
neurons	O
can	O
be	O
found	O
in	O
a	O
cat	O
which	O
is	O
about	O
twice	O
as	O
much	O
as	O
in	O
a	O
dog	O
we	O
know	O
that	O
cats	O
are	O
very	O
elegant	O
patient	O
carnivores	O
that	O
can	O
show	O
a	O
variety	O
of	O
behaviors	O
by	O
the	O
way	O
an	O
octopus	O
can	O
be	O
positioned	O
within	O
the	O
same	O
magnitude	O
only	O
very	O
few	O
people	O
know	O
that	O
for	O
example	O
in	O
labyrinth	O
orientation	O
the	O
octopus	O
is	O
vastly	O
superior	O
to	O
the	O
rat	O
for	O
neurons	O
you	O
already	O
get	O
a	O
chimpanzee	O
one	O
of	O
the	O
animals	O
being	O
very	O
similar	O
to	O
the	O
human	O
neurons	O
make	O
a	O
human	O
usually	O
the	O
human	O
has	O
considerable	O
cognitive	O
capabilities	O
is	O
able	O
to	O
speak	O
to	O
abstract	O
to	O
remember	O
and	O
to	O
use	O
tools	O
as	O
well	O
as	O
the	O
knowledge	O
of	O
other	O
humans	O
to	O
develop	O
advanced	O
technologies	O
and	O
manifold	O
social	O
structures	O
with	O
neurons	O
there	O
are	O
nervous	O
systems	O
having	O
more	O
neurons	O
than	O
the	O
human	O
nervous	B
system	I
here	O
we	O
should	O
mention	O
elephants	O
and	O
certain	O
whale	O
species	O
our	O
state-of-the-art	O
computers	O
are	O
not	O
able	O
to	O
keep	O
up	O
with	O
the	O
aforementioned	O
processing	O
power	O
of	O
a	O
fly	O
recent	O
research	O
results	O
suggest	O
that	O
the	O
processes	O
in	O
nervous	O
systems	O
might	O
be	O
vastly	O
more	O
powerful	O
than	O
people	O
thought	O
until	O
not	O
long	O
ago	O
michaeva	O
et	O
al	O
describe	O
a	O
separate	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
biological	O
neural	O
networks	O
dkriesel	O
com	O
synapse-integrated	O
information	O
way	O
of	O
information	B
processing	I
posterity	O
will	O
show	O
if	O
they	O
are	O
right	O
therefore	O
it	O
is	O
a	O
vector	O
in	O
nature	O
a	O
neuron	B
receives	O
pulses	O
of	O
to	O
other	O
neurons	O
on	O
average	O
transition	O
to	O
technical	O
neurons	O
neural	O
networks	O
are	O
a	O
caricature	O
of	O
biology	O
how	O
do	O
we	O
change	O
from	O
biological	O
neural	O
networks	O
to	O
the	O
technical	O
ones	O
through	O
radical	O
simplification	O
i	O
want	O
to	O
briefly	O
summarize	O
the	O
conclusions	O
relevant	O
for	O
the	O
technical	O
part	O
we	O
have	O
learned	O
that	O
the	O
biological	O
neurons	O
are	O
linked	O
to	O
each	O
other	O
in	O
a	O
weighted	O
way	O
and	O
when	O
stimulated	O
they	O
electrically	O
transmit	O
their	O
signal	O
via	O
the	O
axon	B
from	O
the	O
axon	B
they	O
are	O
not	O
directly	O
transferred	O
to	O
the	O
succeeding	O
neurons	O
but	O
they	O
first	O
have	O
to	O
cross	O
the	O
synaptic	B
cleft	I
where	O
the	O
signal	O
is	O
changed	O
again	O
by	O
variable	B
chemical	B
processes	O
in	O
the	O
receiving	O
neuron	B
the	O
various	O
inputs	O
that	O
have	O
been	O
postprocessed	O
in	O
the	O
synaptic	B
cleft	I
are	O
summarized	O
or	O
accumulated	O
to	O
one	O
single	O
pulse	O
depending	O
on	O
how	O
the	O
neuron	B
is	O
stimulated	O
by	O
the	O
cumulated	O
input	B
the	O
neuron	B
itself	O
emits	O
a	O
pulse	O
or	O
not	O
thus	O
the	O
output	B
is	O
non-linear	O
and	O
not	O
proportional	O
to	O
the	O
cumulated	O
input	B
our	O
brief	O
summary	O
corresponds	O
exactly	O
with	O
the	O
few	O
elements	O
of	O
biological	O
neural	O
networks	O
we	O
want	O
to	O
take	O
over	O
into	O
the	O
technical	O
approximation	B
scalar	O
output	B
the	O
output	B
of	O
a	O
neuron	B
is	O
a	O
scalar	O
which	O
means	O
that	O
the	O
neuron	B
only	O
consists	O
of	O
one	O
component	O
several	O
scalar	O
outputs	O
in	O
turn	O
form	O
the	O
vectorial	O
input	B
of	O
another	O
neuron	B
this	O
particularly	O
means	O
that	O
somewhere	O
in	O
the	O
neuron	B
the	O
various	O
input	B
components	O
have	O
to	O
be	O
summarized	O
in	O
such	O
a	O
way	O
that	O
only	O
one	O
component	O
remains	O
synapses	B
change	O
input	B
in	O
technical	O
neural	O
networks	O
the	O
inputs	O
are	O
preprocessed	O
too	O
they	O
are	O
multiplied	O
by	O
a	O
number	O
weight	B
they	O
are	O
weighted	O
the	O
set	B
of	I
such	O
weights	O
represents	O
the	O
information	O
storage	O
of	O
a	O
neural	B
network	I
in	O
both	O
biological	O
original	O
and	O
technical	O
adaptation	O
accumulating	O
the	O
inputs	O
in	O
biology	O
the	O
inputs	O
are	O
summarized	O
to	O
a	O
pulse	O
according	O
to	O
the	O
chemical	B
change	O
i	O
e	O
they	O
are	O
accumulated	O
on	O
the	O
technical	O
side	O
this	O
is	O
often	O
realized	O
by	O
the	O
weighted	B
sum	I
which	O
we	O
will	O
get	O
to	O
know	O
later	O
on	O
this	O
means	O
that	O
after	O
accumulation	O
we	O
continue	O
with	O
only	O
one	O
value	O
a	O
scalar	O
instead	O
of	O
a	O
vector	O
non-linear	O
characteristic	O
the	O
input	B
of	O
our	O
technical	O
neurons	O
is	O
also	O
not	O
proportional	O
to	O
the	O
output	B
vectorial	O
input	B
the	O
input	B
of	O
technical	O
neurons	O
consists	O
of	O
many	O
components	O
adjustable	O
weights	O
the	O
weights	O
weighting	O
the	O
inputs	O
are	O
variable	B
similar	O
to	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
technical	O
neurons	O
as	O
caricature	O
of	O
biology	O
bits	O
of	O
information	O
na	O
vely	O
calculated	O
how	O
much	O
storage	O
capacity	O
does	O
the	O
brain	B
have	O
note	O
the	O
information	O
which	O
neuron	B
is	O
connected	O
to	O
which	O
other	O
neuron	B
is	O
also	O
important	O
the	O
chemical	B
processes	O
at	O
the	O
synaptic	B
cleft	I
this	O
adds	O
a	O
great	O
dynamic	O
to	O
the	O
network	O
because	O
a	O
large	O
part	O
of	O
the	O
of	O
a	O
neural	B
network	I
is	O
saved	O
in	O
the	O
weights	O
and	O
in	O
the	O
form	O
and	O
power	O
of	O
the	O
chemical	B
processes	O
in	O
a	O
synaptic	B
cleft	I
so	O
our	O
current	O
only	O
casually	O
formulated	O
and	O
very	O
simple	O
neuron	B
model	O
receives	O
a	O
vectorial	O
input	B
with	O
components	O
xi	O
these	O
are	O
multiplied	O
by	O
the	O
appropriate	O
weights	O
wi	O
and	O
accumulated	O
x	O
i	O
wixi	O
aforementioned	O
term	O
is	O
the	O
weighted	B
sum	I
mapping	O
f	O
defines	O
the	O
scalar	O
output	B
y	O
called	O
then	O
the	O
nonlinear	O
x	O
y	O
f	O
wixi	O
i	O
after	O
this	O
transition	O
we	O
now	O
want	O
to	O
specify	O
more	O
precisely	O
our	O
neuron	B
model	O
and	O
add	O
some	O
odds	O
and	O
ends	O
afterwards	O
we	O
will	O
take	O
a	O
look	O
at	O
how	O
the	O
weights	O
can	O
be	O
adjusted	O
exercises	O
exercise	O
it	O
is	O
estimated	O
that	O
a	O
human	O
brain	B
consists	O
of	O
approx	O
nerve	O
cells	O
each	O
of	O
which	O
has	O
about	O
to	O
synapses	B
for	O
this	O
exercise	O
we	O
assume	O
synapses	B
per	O
neuron	B
let	O
us	O
further	O
assume	O
that	O
a	O
single	O
synapse	O
could	O
save	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
components	O
of	O
artificial	O
neural	O
networks	O
formal	O
definitions	O
and	O
colloquial	O
explanations	O
of	O
the	O
components	O
that	O
realize	O
the	O
technical	O
adaptations	O
of	O
biological	O
neural	O
networks	O
initial	O
descriptions	O
of	O
how	O
to	O
combine	O
these	O
components	O
into	O
a	O
neural	B
network	I
this	O
chapter	O
contains	O
the	O
formal	O
definitions	O
for	O
most	O
of	O
the	O
neural	B
network	I
components	O
used	O
later	O
in	O
the	O
text	O
after	O
this	O
chapter	O
you	O
will	O
be	O
able	O
to	O
read	O
the	O
individual	O
chapters	O
of	O
this	O
work	O
without	O
having	O
to	O
know	O
the	O
preceding	O
ones	O
this	O
would	O
be	O
useful	O
the	O
concept	O
of	O
time	O
in	O
neural	O
networks	O
certain	O
point	O
in	O
time	O
the	O
notation	O
will	O
be	O
for	O
example	O
netjt	O
or	O
oit	O
from	O
a	O
biological	O
point	O
of	O
view	O
this	O
is	O
of	O
course	O
not	O
very	O
plausible	O
the	O
human	O
brain	B
a	O
neuron	B
does	O
not	O
wait	O
for	O
another	O
one	O
but	O
it	O
significantly	O
simplifies	O
the	O
implementation	O
in	O
some	O
definitions	O
of	O
this	O
text	O
we	O
use	O
the	O
term	O
time	O
or	O
the	O
number	O
of	O
cycles	O
of	O
the	O
neural	B
network	I
respectively	O
time	O
is	O
divided	O
into	O
discrete	B
time	O
steps	O
discrete	B
time	O
steps	O
definition	O
concept	O
of	O
time	O
the	O
current	O
time	O
time	O
is	O
referred	O
to	O
as	O
the	O
next	O
time	O
step	O
as	O
the	O
preceding	O
one	O
as	O
all	O
other	O
time	O
steps	O
are	O
referred	O
to	O
analogously	O
if	O
in	O
the	O
following	O
chapters	O
several	O
mathematical	O
variables	O
netj	O
or	O
oi	O
refer	O
to	O
a	O
components	O
of	O
neural	O
networks	O
a	O
technical	O
neural	B
network	I
consists	O
of	O
simple	O
processing	O
units	O
the	O
neurons	O
and	O
directed	O
weighted	O
connections	O
between	O
those	O
neurons	O
here	O
the	O
strength	O
of	O
a	O
connection	B
the	O
connecting	O
weight	B
be	O
chapter	O
components	O
of	O
artificial	O
neural	O
networks	O
dkriesel	O
com	O
n	O
network	O
neurons	O
weighted	O
connection	B
tween	O
two	O
neurons	O
i	O
and	O
j	O
is	O
referred	O
to	O
as	O
wij	O
definition	O
network	O
a	O
neural	B
network	I
is	O
a	O
sorted	O
triple	O
v	O
w	O
with	O
two	O
sets	O
n	O
v	O
and	O
a	O
function	O
w	O
where	O
n	O
is	O
the	O
set	B
of	I
neurons	O
and	O
v	O
a	O
set	O
ji	O
j	O
n	O
whose	O
elements	O
are	O
called	O
connections	O
between	O
neuron	B
i	O
and	O
neuron	B
j	O
the	O
function	O
w	O
v	O
r	O
defines	O
the	O
weights	O
where	O
wi	O
j	O
the	O
weight	B
of	O
the	O
connection	B
between	O
neuron	B
i	O
and	O
neuron	B
j	O
is	O
shortened	O
to	O
wij	O
depending	O
on	O
the	O
point	O
of	O
view	O
it	O
is	O
either	O
undefined	O
or	O
for	O
connections	O
that	O
do	O
not	O
exist	O
in	O
the	O
network	O
snipe	O
in	O
snipe	O
an	O
instance	O
of	O
the	O
class	O
neuralnetworkdescriptor	O
is	O
created	O
in	O
the	O
first	O
place	O
the	O
descriptor	O
object	O
roughly	O
outlines	O
a	O
class	O
of	O
neural	O
networks	O
e	O
g	O
it	O
defines	O
the	O
number	O
of	O
neuron	B
layers	O
in	O
a	O
neural	B
network	I
in	O
a	O
second	O
step	O
the	O
descriptor	O
object	O
is	O
used	O
to	O
instantiate	O
an	O
arbitrary	O
number	O
of	O
neuralnetwork	O
objects	O
to	O
get	O
started	O
with	O
snipe	O
programming	O
the	O
documentations	O
of	O
exactly	O
these	O
two	O
classes	O
are	O
in	O
that	O
order	O
the	O
right	O
thing	O
to	O
read	O
the	O
presented	O
layout	O
involving	O
descriptor	O
and	O
dependent	O
neural	O
networks	O
is	O
very	O
reasonable	O
from	O
the	O
implementation	O
point	O
of	O
view	O
because	O
it	O
is	O
enables	O
to	O
create	O
and	O
maintain	O
general	O
parameters	O
of	O
even	O
very	O
large	O
sets	O
of	O
similar	O
not	O
neccessarily	O
equal	O
networks	O
so	O
the	O
weights	O
can	O
be	O
implemented	O
in	O
a	O
square	O
weight	B
matrix	I
w	O
or	O
optionally	O
in	O
a	O
weight	B
vector	I
w	O
with	O
the	O
row	O
note	O
in	O
some	O
of	O
the	O
cited	O
literature	O
i	O
and	O
j	O
could	O
be	O
interchanged	O
in	O
wij	O
here	O
a	O
consistent	O
standard	O
does	O
not	O
exist	O
but	O
in	O
this	O
text	O
i	O
try	O
to	O
use	O
the	O
notation	O
i	O
found	O
more	O
frequently	O
and	O
in	O
the	O
more	O
significant	O
citations	O
ber	O
of	O
the	O
matrix	O
indicating	O
where	O
the	O
connection	B
begins	O
and	O
the	O
column	O
number	O
of	O
the	O
matrix	O
indicating	O
which	O
neuron	B
is	O
the	O
target	B
indeed	O
in	O
this	O
case	O
the	O
numeric	O
marks	O
a	O
non-existing	O
connection	B
this	O
matrix	O
representation	O
is	O
also	O
called	O
hinton	B
the	O
neurons	O
and	O
connections	O
comprise	O
the	O
following	O
components	O
and	O
variables	O
m	O
following	O
the	O
path	O
of	O
the	O
data	O
within	O
a	O
neuron	B
which	O
is	O
according	O
to	O
fig	O
on	O
the	O
facing	O
page	O
in	O
top-down	B
direction	O
connections	O
carry	O
information	O
that	O
is	O
processed	O
by	O
neurons	O
data	O
are	O
transferred	O
between	O
neurons	O
via	O
connections	O
with	O
the	O
connecting	O
weight	B
being	O
either	O
excitatory	O
or	O
inhibitory	O
the	O
definition	O
of	O
connections	O
has	O
already	O
been	O
included	O
in	O
the	O
definition	O
of	O
the	O
neural	B
network	I
be	O
set	O
weights	O
the	O
method	O
connection	B
snipe	O
can	O
neuralnetwork	O
setsynapse	O
using	O
the	O
propagation	B
function	I
converts	O
vector	O
inputs	O
to	O
scalar	O
network	O
inputs	O
looking	O
at	O
a	O
neuron	B
j	O
we	O
will	O
usually	O
find	O
a	O
lot	O
of	O
neurons	O
with	O
a	O
connection	B
to	O
j	O
i	O
e	O
which	O
transfer	O
their	O
output	B
to	O
j	O
note	O
that	O
here	O
again	O
in	O
some	O
of	O
the	O
cited	O
literature	O
axes	O
and	O
rows	O
could	O
be	O
interchanged	O
the	O
published	O
literature	O
is	O
not	O
consistent	O
here	O
as	O
well	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
components	O
of	O
neural	O
networks	O
inputs	O
for	O
a	O
neuron	B
j	O
the	O
propagation	B
function	I
receives	O
the	O
outputs	O
oin	O
of	O
other	O
neurons	O
in	O
are	O
connected	O
to	O
j	O
and	O
transforms	O
them	O
in	O
con-	O
manages	O
sideration	O
of	O
the	O
connecting	O
weights	O
wij	O
into	O
the	O
network	B
input	B
netj	O
that	O
can	O
be	O
further	O
processed	O
by	O
the	O
activation	B
function	I
thus	O
the	O
network	B
input	B
is	O
the	O
result	O
of	O
the	O
propagation	B
function	I
definition	O
function	O
and	O
let	O
i	O
in	O
be	O
the	O
set	B
of	I
neurons	O
such	O
that	O
z	O
n	O
wizj	O
then	O
the	O
network	B
input	B
of	O
j	O
called	O
netj	O
is	O
calculated	O
by	O
the	O
propagation	B
function	I
fprop	O
as	O
follows	O
network	B
input	B
netj	O
oin	O
winj	O
here	O
the	O
weighted	B
sum	I
is	O
very	O
popular	O
the	O
multiplication	O
of	O
the	O
output	B
of	O
each	O
neuron	B
i	O
by	O
wij	O
and	O
the	O
summation	O
of	O
the	O
results	O
netj	O
i	O
i	O
wij	O
figure	O
data	O
processing	O
of	O
a	O
neuron	B
the	O
activation	B
function	I
of	O
a	O
neuron	B
implies	O
the	O
threshold	B
value	I
snipe	O
the	O
propagation	B
function	I
in	O
snipe	O
was	O
implemented	O
using	O
the	O
weighted	B
sum	I
the	O
activation	B
is	O
the	O
status	O
of	O
a	O
neuron	B
based	O
on	O
the	O
model	O
of	O
nature	O
every	O
neuron	B
is	O
to	O
a	O
certain	O
extent	O
at	O
all	O
times	O
active	O
excited	O
or	O
whatever	O
you	O
will	O
call	O
it	O
the	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
propagierungsfunktion	O
gewichtete	O
summe	O
verarbeitet	O
eingaben	O
zur	O
netzeingabe	O
ausgabefunktion	O
aus	O
aktivierung	O
die	O
ausgabe	O
ist	O
oft	O
identit	O
t	O
aktivierungsfunktion	O
aus	O
netzeingabe	O
und	O
alter	O
aktivierung	O
die	O
neue	O
aktivierungeingaben	O
anderer	O
neuronen	O
netzeingabeaktivierungausgabe	O
zu	O
anderen	O
neuronen	O
propagation	B
function	I
weighted	B
sum	I
transforms	O
outputs	O
of	O
other	O
neurons	O
to	O
net	O
input	B
output	B
function	I
identity	B
function	O
transforms	O
activation	B
to	O
output	B
for	O
other	O
neurons	O
activation	B
function	I
net	O
input	B
and	O
sometimes	O
old	O
activation	B
to	O
new	O
activationdata	O
input	B
of	O
other	O
neurons	O
network	O
inputactivationdata	O
output	B
to	O
other	O
neurons	O
chapter	O
components	O
of	O
artificial	O
neural	O
networks	O
dkriesel	O
com	O
how	O
active	O
is	O
a	O
neuron	B
reactions	O
of	O
the	O
neurons	O
to	O
the	O
input	B
values	O
depend	O
on	O
this	O
activation	B
state	B
the	O
activation	B
state	B
indicates	O
the	O
extent	O
of	O
a	O
neuron	B
s	O
activation	B
and	O
is	O
often	O
shortly	O
referred	O
to	O
as	O
activation	B
its	O
formal	O
definition	O
is	O
included	O
in	O
the	O
following	O
definition	O
of	O
the	O
activation	B
function	I
but	O
generally	O
it	O
can	O
be	O
defined	O
as	O
follows	O
definition	O
state	B
activation	B
in	O
general	O
let	O
j	O
be	O
a	O
neuron	B
the	O
activation	B
state	B
aj	O
in	O
short	O
activation	B
is	O
explicitly	O
assigned	O
to	O
j	O
indicates	O
the	O
extent	O
of	O
the	O
neuron	B
s	O
activity	O
and	O
results	O
from	O
the	O
activation	B
function	I
snipe	O
it	O
is	O
possible	O
to	O
get	O
and	O
set	O
activation	B
states	O
of	O
neurons	O
by	O
using	O
the	O
methods	O
getactivation	O
or	O
setactivation	O
in	O
the	O
class	O
neuralnetwork	O
the	O
activation	B
function	I
determines	O
the	O
activation	B
of	O
a	O
neuron	B
dependent	O
on	O
network	B
input	B
and	O
treshold	O
value	O
at	O
a	O
certain	O
time	O
as	O
we	O
have	O
already	O
learned	O
the	O
activation	B
aj	O
of	O
a	O
neuron	B
j	O
depends	O
on	O
the	O
activation	B
state	B
of	O
the	O
neuron	B
and	O
the	O
external	O
input	B
definition	O
function	O
and	O
activation	B
let	O
j	O
be	O
a	O
neuron	B
the	O
activation	B
function	I
is	O
defined	O
as	O
ajt	O
factnetjt	O
ajt	O
j	O
it	O
transforms	O
the	O
network	B
input	B
netj	O
as	O
well	O
as	O
the	O
previous	O
activation	B
state	B
ajt	O
into	O
a	O
new	O
activation	B
state	B
ajt	O
with	O
the	O
threshold	B
value	I
playing	O
an	O
important	O
role	O
as	O
already	O
mentioned	O
calculates	O
activation	B
neurons	O
get	O
activated	O
if	O
the	O
network	B
input	B
exceeds	O
their	O
treshold	O
value	O
near	O
the	O
threshold	B
value	I
the	O
activation	B
function	I
of	O
a	O
neuron	B
reacts	O
particularly	O
sensitive	O
from	O
the	O
biological	O
point	O
of	O
view	O
the	O
threshold	B
value	I
represents	O
the	O
threshold	O
at	O
which	O
a	O
neuron	B
starts	O
firing	O
the	O
threshold	B
value	I
is	O
also	O
mostly	O
included	O
in	O
the	O
definition	O
of	O
the	O
activation	B
function	I
but	O
generally	O
the	O
definition	O
is	O
the	O
following	O
definition	O
value	O
in	O
general	O
let	O
j	O
be	O
a	O
neuron	B
the	O
threshold	B
value	I
j	O
is	O
uniquely	O
assigned	O
to	O
j	O
and	O
marks	O
the	O
position	O
of	O
the	O
maximum	O
gradient	B
value	O
of	O
the	O
activation	B
function	I
unlike	O
the	O
other	O
variables	O
within	O
the	O
neural	B
network	I
unlike	O
the	O
ones	O
defined	O
so	O
far	O
the	O
activation	B
function	I
is	O
often	O
defined	O
globally	O
for	O
all	O
neurons	O
or	O
at	O
least	O
for	O
a	O
set	B
of	I
neurons	O
and	O
only	O
the	O
threshold	O
values	O
are	O
different	O
for	O
each	O
neuron	B
we	O
should	O
also	O
keep	O
in	O
mind	O
that	O
the	O
threshold	O
values	O
can	O
be	O
changed	O
for	O
example	O
by	O
a	O
learning	O
procedure	O
so	O
it	O
can	O
in	O
particular	O
become	O
necessary	O
to	O
relate	O
the	O
threshold	B
value	I
to	O
the	O
time	O
and	O
to	O
write	O
for	O
instance	O
j	O
as	O
jt	O
for	O
reasons	O
of	O
clarity	O
i	O
omitted	O
this	O
here	O
the	O
activation	B
function	I
is	O
also	O
called	O
transfer	O
function	O
the	O
previous	O
activation	B
is	O
not	O
always	O
relevant	O
for	O
the	O
current	O
we	O
will	O
see	O
examples	O
for	O
both	O
variants	O
highest	O
point	O
of	O
sensation	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
components	O
of	O
neural	O
networks	O
snipe	O
in	O
snipe	O
activation	B
functions	O
are	O
generalized	O
to	O
neuron	B
behaviors	O
such	O
behaviors	O
can	O
represent	O
just	O
normal	O
activation	B
functions	O
or	O
even	O
incorporate	O
internal	O
states	O
and	O
dynamics	O
corresponding	O
parts	O
of	O
snipe	O
can	O
be	O
found	O
in	O
the	O
package	O
neuronbehavior	O
which	O
also	O
contains	O
some	O
of	O
the	O
activation	B
functions	O
introduced	O
in	O
the	O
next	O
section	O
the	O
interface	O
neuronbehavior	O
allows	O
for	O
implementation	O
of	O
custom	O
behaviors	O
objects	O
that	O
inherit	O
from	O
this	O
interface	O
can	O
be	O
passed	O
to	O
a	O
neuralnetworkdescriptor	O
instance	O
it	O
is	O
possible	O
to	O
define	O
individual	O
behaviors	O
per	O
neuron	B
layer	O
common	O
activation	B
functions	O
the	O
simplest	O
activation	B
function	I
is	O
the	O
binary	B
threshold	I
function	I
on	O
the	O
next	O
page	O
which	O
can	O
only	O
take	O
on	O
two	O
values	O
referred	O
to	O
as	O
heaviside	O
function	O
if	O
the	O
input	B
is	O
above	O
a	O
certain	O
threshold	O
the	O
function	O
changes	O
from	O
one	O
value	O
to	O
another	O
but	O
otherwise	O
remains	O
constant	O
this	O
implies	O
that	O
the	O
function	O
is	O
not	O
differentiable	O
at	O
the	O
threshold	O
and	O
for	O
the	O
rest	O
the	O
derivative	O
is	O
due	O
to	O
this	O
fact	O
backpropagation	B
learning	O
for	O
example	O
is	O
impossible	O
we	O
will	O
see	O
later	O
also	O
very	O
popular	O
is	O
the	O
fermi	B
function	I
or	O
logistic	O
function	O
e	O
x	O
which	O
maps	O
to	O
the	O
range	O
of	O
values	O
of	O
and	O
the	O
hyperbolic	B
tangent	I
which	O
maps	O
to	O
both	O
functions	O
are	O
differentiable	O
the	O
fermi	B
function	I
can	O
be	O
expanded	O
by	O
a	O
temperature	B
parameter	I
t	O
into	O
the	O
form	O
e	O
x	O
t	O
the	O
smaller	O
this	O
parameter	O
the	O
more	O
does	O
it	O
compress	O
the	O
function	O
on	O
the	O
x	O
axis	O
thus	O
one	O
can	O
arbitrarily	O
approximate	O
the	O
heaviside	O
function	O
incidentally	O
there	O
exist	O
activation	B
functions	O
which	O
are	O
not	O
explicitly	O
defined	O
but	O
depend	O
on	O
the	O
input	B
according	O
to	O
a	O
random	O
distribution	O
activation	B
function	I
a	O
alternative	O
to	O
the	O
hypberbolic	O
tangent	O
that	O
is	O
really	O
worth	O
mentioning	O
was	O
suggested	O
by	O
anguita	B
et	O
al	O
who	O
have	O
been	O
tired	O
of	O
the	O
slowness	O
of	O
the	O
workstations	O
back	O
in	O
thinking	O
about	O
how	O
to	O
make	O
neural	B
network	I
propagations	O
faster	O
they	O
quickly	O
identified	O
the	O
approximation	B
of	O
the	O
e-function	O
used	O
in	O
the	O
hyperbolic	B
tangent	I
as	O
one	O
of	O
the	O
causes	O
of	O
slowness	O
consequently	O
they	O
an	O
approximation	B
to	O
the	O
hyperbolic	B
tangent	I
just	O
using	O
two	O
parabola	O
pieces	O
and	O
two	O
half-lines	O
at	O
the	O
price	O
of	O
delivering	O
a	O
slightly	O
smaller	O
range	O
of	O
values	O
than	O
the	O
hyperbolic	B
tangent	I
instead	O
of	O
dependent	O
on	O
what	O
cpu	O
one	O
uses	O
it	O
can	O
be	O
calculated	O
times	O
faster	O
because	O
it	O
just	O
needs	O
two	O
multiplications	O
and	O
one	O
addition	O
what	O
s	O
more	O
it	O
has	O
some	O
other	O
advantages	O
that	O
will	O
be	O
mentioned	O
later	O
snipe	O
the	O
activation	B
functions	O
introduced	O
here	O
are	O
implemented	O
within	O
the	O
classes	O
fermi	B
and	O
tangenshyperbolicus	O
both	O
of	O
which	O
are	O
located	O
in	O
the	O
package	O
neuronbehavior	O
the	O
fast	O
hyperbolic	B
tangent	I
approximation	B
is	O
located	O
within	O
the	O
class	O
tangenshyperbolicusanguita	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
components	O
of	O
artificial	O
neural	O
networks	O
dkriesel	O
com	O
an	O
output	B
function	I
may	O
be	O
used	O
to	O
process	O
the	O
activation	B
once	O
again	O
the	O
output	B
function	I
of	O
a	O
neuron	B
j	O
calculates	O
the	O
values	O
which	O
are	O
transferred	O
to	O
the	O
other	O
neurons	O
connected	O
to	O
j	O
more	O
formally	O
definition	O
function	O
let	O
j	O
be	O
a	O
neuron	B
the	O
output	B
function	I
foutaj	O
oj	O
informs	O
other	O
neurons	O
calculates	O
the	O
output	B
value	O
oj	O
of	O
the	O
neu-	O
ron	O
j	O
from	O
its	O
activation	B
state	B
aj	O
generally	O
the	O
output	B
function	I
is	O
defined	O
globally	O
too	O
often	O
this	O
function	O
is	O
the	O
identity	B
i	O
e	O
the	O
activation	B
aj	O
is	O
directly	O
foutaj	O
aj	O
so	O
oj	O
aj	O
unless	O
explicitly	O
specified	O
differently	O
we	O
will	O
use	O
the	O
identity	B
as	O
output	B
function	I
within	O
this	O
text	O
learning	O
strategies	O
adjust	O
a	O
network	O
to	O
fit	O
our	O
needs	O
since	O
we	O
will	O
address	O
this	O
subject	O
later	O
in	O
detail	O
and	O
at	O
first	O
want	O
to	O
get	O
to	O
know	O
the	O
principles	O
of	O
neural	B
network	I
structures	O
i	O
will	O
only	O
provide	O
a	O
brief	O
and	O
general	O
definition	O
here	O
other	O
definitions	O
of	O
output	B
functions	O
may	O
be	O
useful	O
if	O
the	O
range	O
of	O
values	O
of	O
the	O
activation	B
function	I
is	O
not	O
sufficient	O
figure	O
various	O
popular	O
activation	B
functions	O
from	O
top	O
to	O
bottom	O
heaviside	O
or	O
binary	B
threshold	I
function	I
fermi	B
function	I
hyperbolic	B
tangent	I
the	O
fermi	B
function	I
was	O
expanded	O
by	O
a	O
temperature	B
parameter	I
the	O
original	O
fermi	B
function	I
is	O
represented	O
by	O
dark	O
colors	O
the	O
temperature	O
parameters	O
of	O
the	O
modified	O
fermi	B
tions	O
are	O
ordered	O
ascending	O
by	O
steepness	O
und	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
function	O
function	O
with	O
temperature	B
parameter	I
tangent	O
network	O
of	O
layers	O
dkriesel	O
com	O
network	O
topologies	O
definition	O
learning	O
rule	O
the	O
learning	B
strategy	I
is	O
an	O
algorithm	B
that	O
can	O
be	O
used	O
to	O
change	O
and	O
thereby	O
train	O
the	O
neural	B
network	I
so	O
that	O
the	O
network	O
produces	O
a	O
desired	O
output	B
for	O
a	O
given	O
input	B
network	O
topologies	O
after	O
we	O
have	O
become	O
acquainted	O
with	O
the	O
composition	O
of	O
the	O
elements	O
of	O
a	O
neural	B
network	I
i	O
want	O
to	O
give	O
an	O
overview	O
of	O
the	O
usual	O
topologies	O
designs	O
of	O
neural	O
networks	O
i	O
e	O
to	O
construct	O
networks	O
consisting	O
of	O
these	O
elements	O
every	O
topology	B
described	O
in	O
this	O
text	O
is	O
illustrated	O
by	O
a	O
map	O
and	O
its	O
hinton	B
diagram	I
so	O
that	O
the	O
reader	O
can	O
immediately	O
see	O
the	O
characteristics	O
and	O
apply	O
them	O
to	O
other	O
networks	O
in	O
the	O
hinton	B
diagram	I
the	O
dotted	O
weights	O
are	O
represented	O
by	O
light	O
grey	O
fields	O
the	O
solid	O
ones	O
by	O
dark	O
grey	O
fields	O
the	O
input	B
and	O
output	B
arrows	O
which	O
were	O
added	O
for	O
reasons	O
of	O
clarity	O
cannot	O
be	O
found	O
in	O
the	O
hinton	B
diagram	I
in	O
order	O
to	O
clarify	O
that	O
the	O
connections	O
are	O
between	O
the	O
line	O
neurons	O
and	O
the	O
column	O
neurons	O
i	O
have	O
inserted	O
the	O
small	O
arrow	O
in	O
the	O
upper-left	O
cell	O
snipe	O
snipe	O
is	O
designed	O
for	O
realization	O
of	O
arbitrary	O
network	O
topologies	O
in	O
this	O
respect	O
snipe	O
defines	O
different	O
kinds	O
of	O
synapses	B
depending	O
on	O
their	O
source	O
and	O
their	O
target	B
any	O
kind	O
of	O
synapse	O
can	O
separately	O
be	O
allowed	O
or	O
forbidden	O
for	O
a	O
set	B
of	I
networks	O
using	O
the	O
setallowed	O
methods	O
in	O
a	O
neuralnetworkdescriptor	O
instance	O
feedforward	B
networks	O
consist	O
of	O
layers	O
and	O
connections	O
towards	O
each	O
following	O
layer	O
feedforward	B
in	O
this	O
text	O
feedforward	B
networks	O
on	O
the	O
following	O
page	O
are	O
the	O
networks	O
we	O
will	O
first	O
explore	O
if	O
we	O
will	O
use	O
different	O
topologies	O
later	O
the	O
neurons	O
are	O
grouped	O
in	O
the	O
following	O
layers	O
one	O
input	B
layer	O
n	O
hidden	B
processing	O
layers	O
from	O
the	O
outside	O
that	O
s	O
why	O
the	O
neurons	O
are	O
also	O
referred	O
to	O
as	O
hidden	B
neurons	O
and	O
one	O
output	B
layer	O
in	O
a	O
feedforward	B
network	O
each	O
neuron	B
in	O
one	O
layer	O
has	O
only	O
directed	O
connections	O
to	O
the	O
neurons	O
of	O
the	O
next	O
layer	O
the	O
output	B
layer	O
in	O
fig	O
on	O
the	O
next	O
page	O
the	O
connections	O
permitted	O
for	O
a	O
feedforward	B
network	O
are	O
represented	O
by	O
solid	O
lines	O
we	O
will	O
often	O
be	O
confronted	O
with	O
feedforward	B
networks	O
in	O
which	O
every	O
neuron	B
i	O
is	O
connected	O
to	O
all	O
neurons	O
of	O
the	O
next	O
layer	O
layers	O
are	O
called	O
completely	O
linked	O
to	O
prevent	O
naming	O
conflicts	O
the	O
output	B
neurons	O
are	O
often	O
referred	O
to	O
as	O
definition	O
network	O
the	O
neuron	B
layers	O
of	O
a	O
feedforward	B
network	O
on	O
the	O
following	O
page	O
are	O
clearly	O
separated	O
one	O
input	B
layer	O
one	O
output	B
layer	O
and	O
one	O
or	O
more	O
processing	O
layers	O
which	O
are	O
invisible	O
from	O
the	O
outside	O
called	O
hidden	B
layers	O
connections	O
are	O
only	O
permitted	O
to	O
neurons	O
of	O
the	O
following	O
layer	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
shortcuts	O
skip	O
layers	O
chapter	O
components	O
of	O
artificial	O
neural	O
networks	O
dkriesel	O
com	O
shortcut	B
connections	I
skip	O
layers	O
gfed	O
gfed	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
aaaaaaaaa	O
aaaaaaaaa	O
gfed	O
gfed	O
gfed	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
aaaaaaaaa	O
aaaaaaaaa	O
gfed	O
gfed	O
some	O
feedforward	B
networks	O
permit	O
the	O
socalled	O
shortcut	B
connections	I
on	O
the	O
next	O
page	O
connections	O
that	O
skip	O
one	O
or	O
more	O
levels	O
these	O
connections	O
may	O
only	O
be	O
directed	O
towards	O
the	O
output	B
layer	O
too	O
definition	O
network	O
with	O
shortcut	B
connections	I
similar	O
to	O
the	O
feedforward	B
network	O
but	O
the	O
connections	O
may	O
not	O
only	O
be	O
directed	O
towards	O
the	O
next	O
layer	O
but	O
also	O
towards	O
any	O
other	O
subsequent	O
layer	O
recurrent	B
networks	O
have	O
influence	O
on	O
themselves	O
figure	O
a	O
feedforward	B
network	O
with	O
three	O
layers	O
two	O
input	B
neurons	O
three	O
hidden	B
neurons	O
and	O
two	O
output	B
neurons	O
characteristic	O
for	O
the	O
hinton	B
diagram	I
of	O
completely	O
linked	O
feedforward	B
networks	O
is	O
the	O
formation	O
of	O
blocks	O
above	O
the	O
diagonal	O
recurrence	B
is	O
defined	O
as	O
the	O
process	O
of	O
a	O
neuron	B
influencing	O
itself	O
by	O
any	O
means	O
or	O
by	O
any	O
connection	B
recurrent	B
networks	O
do	O
not	O
always	O
have	O
explicitly	O
defined	O
input	B
or	O
output	B
neurons	O
therefore	O
in	O
the	O
figures	O
i	O
omitted	O
all	O
markings	O
that	O
concern	O
this	O
matter	O
and	O
only	O
numbered	O
the	O
neurons	O
direct	B
recurrences	O
start	O
and	O
end	O
at	O
the	O
same	O
neuron	B
some	O
networks	O
allow	O
for	O
neurons	O
to	O
be	O
connected	O
to	O
themselves	O
which	O
is	O
called	O
direct	B
recurrence	B
sometimes	O
selfrecurrence	O
on	O
the	O
facing	O
page	O
as	O
a	O
result	O
neurons	O
inhibit	O
and	O
therefore	O
strengthen	O
themselves	O
in	O
order	O
to	O
reach	O
their	O
activation	B
limits	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
t	O
t	O
dkriesel	O
com	O
network	O
topologies	O
gfed	O
figure	O
a	O
network	O
similar	O
to	O
a	O
feedforward	B
network	O
with	O
directly	O
recurrent	B
neurons	O
the	O
direct	B
recurrences	O
are	O
represented	O
by	O
solid	O
lines	O
and	O
exactly	O
correspond	O
to	O
the	O
diagonal	O
in	O
the	O
hinton	B
diagram	I
matrix	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
figure	O
a	O
feedforward	B
network	O
with	O
shortcut	B
connections	I
which	O
are	O
represented	O
by	O
solid	O
lines	O
on	O
the	O
right	O
side	O
of	O
the	O
feedforward	B
blocks	O
new	O
connections	O
have	O
been	O
added	O
to	O
the	O
hinton	B
diagram	I
definition	O
recurrence	B
now	O
we	O
expand	O
the	O
feedforward	B
network	O
by	O
connecting	O
a	O
neuron	B
j	O
to	O
itself	O
with	O
the	O
weights	O
of	O
these	O
connections	O
being	O
referred	O
to	O
as	O
wjj	O
in	O
other	O
words	O
the	O
diagonal	O
of	O
the	O
weight	B
matrix	I
w	O
may	O
be	O
different	O
from	O
neurons	O
influence	O
themselves	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
s	O
s	O
t	O
t	O
t	O
t	O
v	O
v	O
v	O
v	O
u	O
u	O
v	O
v	O
v	O
v	O
v	O
v	O
u	O
u	O
v	O
v	O
v	O
v	O
chapter	O
components	O
of	O
artificial	O
neural	O
networks	O
dkriesel	O
com	O
indirect	B
recurrences	O
can	O
influence	O
their	O
starting	O
neuron	B
only	O
by	O
making	O
detours	O
if	O
connections	O
are	O
allowed	O
towards	O
the	O
input	B
layer	O
they	O
will	O
be	O
called	O
indirect	B
recurrences	O
then	O
a	O
neuron	B
j	O
can	O
use	O
indirect	B
forwards	O
connections	O
to	O
influence	O
itself	O
for	O
example	O
by	O
influencing	O
the	O
neurons	O
of	O
the	O
next	O
layer	O
and	O
the	O
neurons	O
of	O
this	O
next	O
layer	O
influencing	O
j	O
definition	O
recurrence	B
again	O
our	O
network	O
is	O
based	O
on	O
a	O
feedforward	B
network	O
now	O
with	O
additional	O
connections	O
between	O
neurons	O
and	O
their	O
preceding	O
layer	O
being	O
allowed	O
therefore	O
below	O
the	O
diagonal	O
of	O
w	O
is	O
different	O
from	O
lateral	B
recurrences	O
connect	O
neurons	O
within	O
one	O
layer	O
connections	O
between	O
neurons	O
within	O
one	O
layer	O
are	O
called	O
lateral	B
recurrences	O
on	O
the	O
facing	O
page	O
here	O
each	O
neuron	B
often	O
inhibits	O
the	O
other	O
neurons	O
of	O
the	O
layer	O
and	O
strengthens	O
itself	O
as	O
a	O
result	O
only	O
the	O
strongest	O
neuron	B
becomes	O
active	O
scheme	O
definition	O
recurrence	B
a	O
laterally	O
recurrent	B
network	O
permits	O
connections	O
within	O
one	O
layer	O
completely	O
linked	O
networks	O
allow	O
any	O
possible	O
connection	B
completely	O
linked	O
networks	O
permit	O
connections	O
between	O
all	O
neurons	O
except	O
for	O
direct	B
figure	O
a	O
network	O
similar	O
to	O
a	O
feedforward	B
network	O
with	O
indirectly	O
recurrent	B
neurons	O
the	O
indirect	B
recurrences	O
are	O
represented	O
by	O
solid	O
lines	O
as	O
we	O
can	O
see	O
connections	O
to	O
the	O
preceding	O
layers	O
can	O
exist	O
here	O
too	O
the	O
fields	O
that	O
are	O
symmetric	O
to	O
the	O
feedforward	B
blocks	O
in	O
the	O
hinton	B
diagram	I
are	O
now	O
occupied	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
u	O
u	O
x	O
x	O
x	O
x	O
g	O
g	O
u	O
u	O
x	O
x	O
g	O
g	O
x	O
x	O
dkriesel	O
com	O
the	O
bias	B
neuron	B
figure	O
a	O
network	O
similar	O
to	O
a	O
feedforward	B
network	O
with	O
laterally	O
recurrent	B
neurons	O
the	O
direct	B
recurrences	O
are	O
represented	O
by	O
solid	O
lines	O
here	O
recurrences	O
only	O
exist	O
within	O
the	O
layer	O
in	O
the	O
hinton	B
diagram	I
filled	O
squares	O
are	O
concentrated	O
around	O
the	O
diagonal	O
in	O
the	O
height	O
of	O
the	O
feedforward	B
blocks	O
but	O
the	O
diagonal	O
is	O
left	O
uncovered	O
recurrences	O
furthermore	O
the	O
connections	O
must	O
be	O
symmetric	O
on	O
the	O
next	O
page	O
a	O
popular	O
example	O
are	O
the	O
selforganizing	O
maps	O
which	O
will	O
be	O
introduced	O
in	O
chapter	O
definition	O
interconnection	O
in	O
this	O
case	O
every	O
neuron	B
is	O
always	O
allowed	O
to	O
be	O
connected	O
to	O
every	O
other	O
neuron	B
but	O
as	O
a	O
result	O
every	O
neuron	B
can	O
become	O
an	O
input	B
neuron	B
therefore	O
direct	B
recurrences	O
normally	O
cannot	O
be	O
applied	O
here	O
and	O
clearly	O
defined	O
layers	O
do	O
not	O
longer	O
exist	O
thus	O
the	O
matrix	O
w	O
may	O
be	O
unequal	O
to	O
everywhere	O
except	O
along	O
its	O
diagonal	O
the	O
bias	B
neuron	B
is	O
a	O
technical	O
trick	O
to	O
consider	O
threshold	O
values	O
as	O
connection	B
weights	O
by	O
now	O
we	O
know	O
that	O
in	O
many	O
network	O
paradigms	O
neurons	O
have	O
a	O
threshold	B
value	I
that	O
indicates	O
when	O
a	O
neuron	B
becomes	O
active	O
thus	O
the	O
threshold	B
value	I
is	O
an	O
activation	B
function	I
parameter	O
of	O
a	O
neuron	B
from	O
the	O
biological	O
point	O
of	O
view	O
this	O
sounds	O
most	O
plausible	O
but	O
it	O
is	O
complicated	O
to	O
access	O
the	O
activation	B
function	I
at	O
runtime	O
in	O
order	O
to	O
train	O
the	O
threshold	B
value	I
but	O
threshold	O
values	O
jn	O
for	O
neurons	O
jn	O
can	O
also	O
be	O
realized	O
as	O
connecting	O
weight	B
of	O
a	O
continuously	O
firing	O
neuron	B
for	O
this	O
purpose	O
an	O
additional	O
bias	B
neuron	B
whose	O
output	B
value	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
k	O
k	O
u	O
u	O
k	O
k	O
j	O
j	O
k	O
k	O
u	O
u	O
k	O
k	O
chapter	O
components	O
of	O
artificial	O
neural	O
networks	O
dkriesel	O
com	O
i	O
ujjjjjjjjjjjjjjjjjjjjjjj	O
o	O
i	O
ujjjjjjjjjjjjjjjjjjjjjjj	O
figure	O
a	O
completely	O
linked	O
network	O
with	O
symmetric	O
connections	O
and	O
without	O
direct	B
recurrences	O
in	O
the	O
hinton	B
diagram	I
only	O
the	O
diagonal	O
is	O
left	O
blank	O
is	O
always	O
is	O
integrated	O
in	O
the	O
network	O
and	O
connected	O
to	O
the	O
neurons	O
jn	O
these	O
new	O
connections	O
get	O
the	O
weights	O
jn	O
i	O
e	O
they	O
get	O
the	O
negative	O
threshold	O
values	O
definition	O
a	O
bias	B
neuron	B
is	O
a	O
neuron	B
whose	O
output	B
value	O
is	O
always	O
and	O
which	O
is	O
represented	O
by	O
it	O
is	O
used	O
to	O
represent	O
neuron	B
biases	O
as	O
connection	B
weights	O
which	O
enables	O
any	O
weighttraining	O
algorithm	B
to	O
train	O
the	O
biases	O
at	O
the	O
same	O
time	O
gfed	O
bias	O
then	O
the	O
threshold	B
value	I
of	O
the	O
neurons	O
jn	O
is	O
set	O
to	O
now	O
the	O
threshold	O
values	O
are	O
implemented	O
as	O
connection	B
weights	O
on	O
page	O
and	O
can	O
directly	O
be	O
trained	O
together	O
with	O
the	O
connection	B
weights	O
which	O
considerably	O
facilitates	O
the	O
learning	O
process	O
in	O
other	O
words	O
instead	O
of	O
including	O
the	O
threshold	B
value	I
in	O
the	O
activation	B
function	I
it	O
is	O
now	O
included	O
in	O
the	O
propagation	B
function	I
or	O
even	O
shorter	O
the	O
threshold	B
value	I
is	O
subtracted	O
from	O
the	O
network	B
input	B
i	O
e	O
it	O
is	O
part	O
of	O
the	O
network	B
input	B
more	O
formally	O
let	O
jn	O
be	O
neurons	O
with	O
threshold	O
values	O
jn	O
by	O
inserting	O
a	O
bias	B
neuron	B
whose	O
output	B
value	O
is	O
always	O
generating	O
connections	O
between	O
the	O
said	O
bias	B
neuron	B
and	O
the	O
neurons	O
jn	O
and	O
connections	O
wbiasjnwith	O
jn	O
we	O
can	O
set	O
jn	O
and	O
weighting	O
these	O
bias	B
neuron	B
replaces	O
thresh	O
value	O
with	O
weights	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
i	O
i	O
i	O
o	O
o	O
o	O
o	O
u	O
o	O
i	O
o	O
j	O
j	O
u	O
o	O
o	O
o	O
o	O
dkriesel	O
com	O
orders	O
of	O
activation	B
receive	O
an	O
equivalent	O
neural	B
network	I
whose	O
threshold	O
values	O
are	O
realized	O
by	O
connection	B
weights	O
undoubtedly	O
the	O
advantage	O
of	O
the	O
bias	B
neuron	B
is	O
the	O
fact	O
that	O
it	O
is	O
much	O
easier	O
to	O
implement	O
it	O
in	O
the	O
network	O
one	O
disadvantage	O
is	O
that	O
the	O
representation	O
of	O
the	O
network	O
already	O
becomes	O
quite	O
ugly	O
with	O
only	O
a	O
few	O
neurons	O
let	O
alone	O
with	O
a	O
great	O
number	O
of	O
them	O
by	O
the	O
way	O
a	O
bias	B
neuron	B
is	O
often	O
referred	O
to	O
as	O
on	O
neuron	B
from	O
now	O
on	O
the	O
bias	B
neuron	B
is	O
omitted	O
for	O
clarity	O
in	O
the	O
following	O
illustrations	O
but	O
we	O
know	O
that	O
it	O
exists	O
and	O
that	O
the	O
threshold	O
values	O
can	O
simply	O
be	O
treated	O
as	O
weights	O
because	O
of	O
it	O
snipe	O
in	O
snipe	O
a	O
bias	B
neuron	B
was	O
implemented	O
instead	O
of	O
neuron-individual	O
biases	O
the	O
neuron	B
index	O
of	O
the	O
bias	B
neuron	B
is	O
gau	O
wvut	O
pqrs	O
wvut	O
pqrs	O
tanh	B
gfed	O
wvut	O
pqrs	O
fermi	B
onml	O
hijk	O
onml	O
hijk	O
fact	O
lh	O
wvut	O
pqrs	O
gfed	O
bias	O
figure	O
different	O
types	O
of	O
neurons	O
that	O
will	O
appear	O
in	O
the	O
following	O
text	O
take	O
care	O
of	O
the	O
order	O
in	O
which	O
neuron	B
activations	O
are	O
calculated	O
for	O
a	O
neural	B
network	I
it	O
is	O
very	O
important	O
in	O
which	O
order	O
the	O
individual	O
neurons	O
receive	O
and	O
process	O
the	O
input	B
and	O
output	B
the	O
results	O
here	O
we	O
distinguish	O
two	O
model	O
classes	O
representing	O
neurons	O
synchronous	B
activation	B
we	O
have	O
already	O
seen	O
that	O
we	O
can	O
either	O
write	O
its	O
name	O
or	O
its	O
threshold	B
value	I
into	O
a	O
neuron	B
another	O
useful	O
representation	O
which	O
we	O
will	O
use	O
several	O
times	O
in	O
the	O
following	O
is	O
to	O
illustrate	O
neurons	O
according	O
to	O
their	O
type	O
of	O
data	O
processing	O
see	O
fig	O
for	O
some	O
examples	O
without	O
further	O
explanation	O
the	O
different	O
types	O
of	O
neurons	O
are	O
explained	O
as	O
soon	O
as	O
we	O
need	O
them	O
all	O
neurons	O
change	O
their	O
values	O
synchronously	O
i	O
e	O
they	O
simultaneously	O
calculate	O
network	O
inputs	O
activation	B
and	O
output	B
and	O
pass	O
them	O
on	O
synchronous	B
activation	B
corresponds	O
closest	O
to	O
its	O
biological	O
counterpart	O
but	O
it	O
is	O
if	O
to	O
be	O
implemented	O
in	O
hardware	O
only	O
useful	O
on	O
certain	O
parallel	O
computers	O
and	O
especially	O
not	O
for	O
feedforward	B
networks	O
this	O
order	B
of	I
activation	B
is	O
the	O
most	O
generic	O
and	O
can	O
be	O
used	O
with	O
networks	O
of	O
arbitrary	O
topology	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
components	O
of	O
artificial	O
neural	O
networks	O
dkriesel	O
com	O
gfed	O
bbbbbbbbb	O
gfed	O
gfed	O
bias	O
gfed	O
tttttttttt	O
aaaa	O
aaaa	O
figure	O
two	O
equivalent	O
neural	O
networks	O
one	O
without	O
bias	B
neuron	B
on	O
the	O
left	O
one	O
with	O
bias	B
neuron	B
on	O
the	O
right	O
the	O
neuron	B
threshold	O
values	O
can	O
be	O
found	O
in	O
the	O
neurons	O
the	O
connecting	O
weights	O
at	O
the	O
connections	O
furthermore	O
i	O
omitted	O
the	O
weights	O
of	O
the	O
already	O
existing	O
connections	O
by	O
dotted	O
lines	O
on	O
the	O
right	O
side	O
biologically	O
plausible	O
definition	O
activation	B
all	O
neurons	O
of	O
a	O
network	O
calculate	O
network	O
inputs	O
at	O
the	O
same	O
time	O
by	O
means	O
of	O
the	O
propagation	B
function	I
activation	B
by	O
means	O
of	O
the	O
activation	B
function	I
and	O
output	B
by	O
means	O
of	O
the	O
output	B
function	I
after	O
that	O
the	O
activation	B
cycle	O
is	O
complete	O
snipe	O
when	O
implementing	O
in	O
software	O
one	O
could	O
model	O
this	O
very	O
general	O
activation	B
order	O
by	O
every	O
time	O
step	O
calculating	O
and	O
caching	O
every	O
single	O
network	B
input	B
and	O
after	O
that	O
calculating	O
all	O
activations	O
this	O
is	O
exactly	O
how	O
it	O
is	O
done	O
in	O
snipe	O
because	O
snipe	O
has	O
to	O
be	O
able	O
to	O
realize	O
arbitrary	O
network	O
topologies	O
asynchronous	O
activation	B
of	O
time	O
for	O
this	O
there	O
exist	O
different	O
orders	O
some	O
of	O
which	O
i	O
want	O
to	O
introduce	O
in	O
the	O
following	O
easier	O
to	O
implement	O
random	B
order	I
definition	O
order	B
of	I
activation	B
with	O
random	B
order	B
of	I
activation	B
a	O
neuron	B
i	O
is	O
randomly	O
chosen	O
and	O
its	O
neti	O
ai	O
and	O
oi	O
are	O
updated	O
for	O
n	O
neurons	O
a	O
cycle	O
is	O
the	O
n-fold	O
execution	O
of	O
this	O
step	O
obviously	O
some	O
neurons	O
are	O
repeatedly	O
updated	O
during	O
one	O
cycle	O
and	O
others	O
however	O
not	O
at	O
all	O
here	O
the	O
neurons	O
do	O
not	O
change	O
their	O
values	O
simultaneously	O
but	O
at	O
different	O
points	O
apparently	O
this	O
order	B
of	I
activation	B
is	O
not	O
always	O
useful	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
orders	O
of	O
activation	B
random	O
permutation	O
with	O
random	O
permutation	O
each	O
neuron	B
is	O
chosen	O
exactly	O
once	O
but	O
in	O
random	B
order	I
during	O
one	O
cycle	O
definition	O
permutation	O
initially	O
a	O
permutation	O
of	O
the	O
neurons	O
is	O
calculated	O
randomly	O
and	O
therefore	O
defines	O
the	O
order	B
of	I
activation	B
then	O
the	O
neurons	O
are	O
successively	O
processed	O
in	O
this	O
order	O
this	O
order	B
of	I
activation	B
is	O
as	O
well	O
used	O
rarely	O
because	O
firstly	O
the	O
order	O
is	O
generally	O
useless	O
and	O
secondly	O
it	O
is	O
very	O
timeconsuming	O
to	O
compute	O
a	O
new	O
permutation	O
for	O
every	O
cycle	O
a	O
hopfield	O
network	O
is	O
a	O
topology	B
nominally	O
having	O
a	O
random	O
or	O
a	O
randomly	B
permuted	I
order	B
of	I
activation	B
but	O
note	O
that	O
in	O
practice	O
for	O
the	O
previously	O
mentioned	O
reasons	O
a	O
fixed	O
order	B
of	I
activation	B
is	O
preferred	O
for	O
all	O
orders	O
either	O
the	O
previous	O
neuron	B
activations	O
at	O
time	O
t	O
or	O
if	O
already	O
existing	O
the	O
neuron	B
activations	O
at	O
time	O
t	O
for	O
which	O
we	O
are	O
calculating	O
the	O
activations	O
can	O
be	O
taken	O
as	O
a	O
starting	O
point	O
topological	B
order	I
often	O
very	O
useful	O
definition	O
activation	B
with	O
topological	B
order	B
of	I
activation	B
the	O
neurons	O
are	O
updated	O
during	O
one	O
cycle	O
and	O
according	O
to	O
a	O
fixed	O
order	O
the	O
order	O
is	O
defined	O
by	O
the	O
network	O
topology	B
since	O
otherwise	O
there	O
is	O
no	O
order	B
of	I
activation	B
thus	O
in	O
feedforward	B
networks	O
which	O
the	O
procedure	O
is	O
very	O
reasonable	O
the	O
input	B
neurons	O
would	O
be	O
updated	O
first	O
then	O
the	O
inner	O
neurons	O
and	O
finally	O
the	O
output	B
neurons	O
this	O
may	O
save	O
us	O
a	O
lot	O
of	O
time	O
given	O
a	O
synchronous	B
activation	B
order	O
a	O
feedforward	B
network	O
with	O
n	O
layers	O
of	O
neurons	O
would	O
need	O
n	O
full	O
propagation	O
cycles	O
in	O
order	O
to	O
enable	O
input	B
data	O
to	O
have	O
influence	O
on	O
the	O
output	B
of	O
the	O
network	O
given	O
the	O
topological	O
activation	B
order	O
we	O
just	O
need	O
one	O
single	O
propagation	O
however	O
not	O
every	O
network	O
topology	B
allows	O
for	O
finding	O
a	O
special	O
activation	B
order	O
that	O
enables	O
saving	O
time	O
feature	O
snipe	O
those	O
who	O
want	O
to	O
use	O
snipe	O
for	O
implementing	O
feedforward	B
networks	O
may	O
save	O
some	O
calculation	O
time	O
by	O
using	O
the	O
fastprop	B
within	O
the	O
documentation	O
of	O
the	O
class	O
neuralnetworkdescriptor	O
once	O
fastprop	B
is	O
enabled	O
it	O
will	O
cause	O
the	O
data	O
propagation	O
to	O
be	O
carried	O
out	O
in	O
a	O
slightly	O
different	O
way	O
in	O
the	O
standard	O
mode	O
all	O
net	O
inputs	O
are	O
calculated	O
first	O
followed	O
by	O
all	O
activations	O
in	O
the	O
fastprop	B
mode	O
for	O
every	O
neuron	B
the	O
activation	B
is	O
calculated	O
right	O
after	O
the	O
net	O
input	B
the	O
neuron	B
values	O
are	O
calculated	O
in	O
ascending	O
neuron	B
index	O
order	O
the	O
neuron	B
numbers	O
are	O
ascending	O
from	O
input	B
to	O
output	B
layer	O
which	O
provides	O
us	O
with	O
the	O
perfect	O
topological	O
activation	B
order	O
for	O
feedforward	B
networks	O
fixed	O
orders	O
of	O
activation	B
during	O
implementation	O
this	O
procedure	O
can	O
only	O
be	O
considered	O
for	O
non-cyclic	O
i	O
e	O
non-recurrent	O
networks	O
obviously	O
fixed	O
orders	O
of	O
activation	B
can	O
be	O
defined	O
as	O
well	O
therefore	O
when	O
implementing	O
feedforward	B
for	O
instance	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
components	O
of	O
artificial	O
neural	O
networks	O
dkriesel	O
com	O
networks	O
it	O
is	O
very	O
popular	O
to	O
determine	O
the	O
order	B
of	I
activation	B
once	O
according	O
to	O
the	O
topology	B
and	O
to	O
use	O
this	O
order	O
without	O
further	O
verification	O
at	O
runtime	O
but	O
this	O
is	O
not	O
necessarily	O
useful	O
for	O
networks	O
that	O
are	O
capable	O
to	O
change	O
their	O
topology	B
outputs	O
ym	O
they	O
are	O
regarded	O
as	O
output	B
vector	I
y	O
ym	O
thus	O
the	O
output	B
dimension	I
is	O
referred	O
to	O
as	O
m	O
data	O
is	O
output	B
by	O
a	O
neural	O
net-	O
work	O
by	O
the	O
output	B
neurons	O
adopting	O
the	O
components	O
of	O
the	O
output	B
vector	I
in	O
their	O
output	B
values	O
communication	O
with	O
the	O
outside	O
world	O
input	B
and	O
output	B
of	O
data	O
in	O
and	O
from	O
neural	O
networks	O
finally	O
let	O
us	O
take	O
a	O
look	O
at	O
the	O
fact	O
that	O
of	O
course	O
many	O
types	O
of	O
neural	O
networks	O
permit	O
the	O
input	B
of	O
data	O
then	O
these	O
data	O
are	O
processed	O
and	O
can	O
produce	O
output	B
let	O
us	O
for	O
example	O
regard	O
the	O
feedforward	B
network	O
shown	O
in	O
fig	O
on	O
page	O
it	O
has	O
two	O
input	B
neurons	O
and	O
two	O
output	B
neurons	O
which	O
means	O
that	O
it	O
also	O
has	O
two	O
numerical	O
inputs	O
and	O
outputs	O
as	O
a	O
simplification	O
we	O
summarize	O
the	O
input	B
and	O
output	B
components	O
for	O
n	O
input	B
or	O
output	B
neurons	O
within	O
the	O
vectors	O
x	O
xn	O
and	O
y	O
yn	O
definition	O
vector	O
a	O
network	O
with	O
n	O
input	B
neurons	O
needs	O
n	O
inputs	O
xn	O
they	O
are	O
considered	O
as	O
input	B
vector	I
x	O
xn	O
as	O
a	O
consequence	O
the	O
input	B
dimension	I
is	O
referred	O
to	O
as	O
n	O
data	O
is	O
put	O
into	O
a	O
neural	B
network	I
by	O
using	O
the	O
components	O
of	O
the	O
input	B
vector	I
as	O
network	O
inputs	O
of	O
the	O
input	B
neurons	O
definition	O
vector	O
a	O
network	O
with	O
m	O
output	B
neurons	O
provides	O
m	O
snipe	O
in	O
order	O
to	O
propagate	O
data	O
through	O
a	O
neuralnetwork-instance	O
the	O
propagate	O
method	O
is	O
used	O
it	O
receives	O
the	O
input	B
vector	I
as	O
array	O
of	O
doubles	O
and	O
returns	O
the	O
output	B
vector	I
in	O
the	O
same	O
way	O
now	O
we	O
have	O
defined	O
and	O
closely	O
examined	O
the	O
basic	O
components	O
of	O
neural	O
networks	O
without	O
having	O
seen	O
a	O
network	O
in	O
action	B
but	O
first	O
we	O
will	O
continue	O
with	O
theoretical	O
explanations	O
and	O
generally	O
describe	O
how	O
a	O
neural	B
network	I
could	O
learn	O
exercises	O
exercise	O
would	O
it	O
be	O
useful	O
your	O
point	O
of	O
view	O
to	O
insert	O
one	O
bias	B
neuron	B
in	O
each	O
layer	O
of	O
a	O
layer-based	O
network	O
such	O
as	O
a	O
feedforward	B
network	O
discuss	O
this	O
in	O
relation	O
to	O
the	O
representation	O
and	O
implementation	O
of	O
the	O
network	O
will	O
the	O
result	O
of	O
the	O
network	O
change	O
exercise	O
show	O
for	O
the	O
fermi	B
function	I
fx	O
as	O
well	O
as	O
for	O
the	O
hyperbolic	B
tangent	I
tanhx	O
that	O
their	O
derivatives	O
can	O
be	O
expressed	O
by	O
the	O
respective	O
functions	O
themselves	O
so	O
that	O
the	O
two	O
statements	O
fx	O
fx	O
and	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
are	O
true	O
input	B
and	O
output	B
of	O
data	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
approaches	O
and	O
thoughts	O
of	O
how	O
to	O
teach	O
machines	O
should	O
neural	O
networks	O
be	O
corrected	O
should	O
they	O
only	O
be	O
encouraged	O
or	O
should	O
they	O
even	O
learn	O
without	O
any	O
help	O
thoughts	O
about	O
what	O
we	O
want	O
to	O
change	O
during	O
the	O
learning	O
procedure	O
and	O
how	O
we	O
will	O
change	O
it	O
about	O
the	O
measurement	O
of	O
errors	O
and	O
when	O
we	O
have	O
learned	O
enough	O
as	O
written	O
above	O
the	O
most	O
interesting	O
characteristic	O
of	O
neural	O
networks	O
is	O
their	O
capability	O
to	O
familiarize	O
with	O
problems	B
by	O
means	O
of	O
training	O
and	O
after	O
sufficient	O
training	O
to	O
be	O
able	O
to	O
solve	O
unknown	O
problems	B
of	O
the	O
same	O
class	O
this	O
approach	O
is	O
referred	O
to	O
as	O
generalization	B
before	O
introducing	O
specific	B
learning	O
procedures	O
i	O
want	O
to	O
propose	O
some	O
basic	O
principles	O
about	O
the	O
learning	O
procedure	O
in	O
this	O
chapter	O
there	O
are	O
different	O
paradigms	O
of	O
learning	O
learning	O
is	O
a	O
comprehensive	O
term	O
a	O
learning	O
system	O
changes	O
itself	O
in	O
order	O
to	O
adapt	O
to	O
e	O
g	O
environmental	O
changes	O
a	O
neural	B
network	I
could	O
learn	O
from	O
many	O
things	O
but	O
of	O
course	O
there	O
will	O
always	O
be	O
in	O
the	O
question	O
of	O
how	O
to	O
implement	O
it	O
principle	O
a	O
neural	B
network	I
changes	O
when	O
its	O
components	O
are	O
changing	O
as	O
we	O
have	O
learned	O
above	O
theoretically	O
a	O
neural	B
network	I
could	O
learn	O
by	O
developing	O
new	O
connections	O
deleting	O
existing	O
connections	O
changing	O
connecting	O
weights	O
changing	O
the	O
threshold	O
values	O
of	O
neu	O
rons	O
varying	O
one	O
or	O
more	O
of	O
the	O
three	O
neuron	B
functions	O
activation	B
function	I
propagation	B
function	I
and	O
output	B
function	I
developing	O
new	O
neurons	O
or	O
deleting	O
existing	O
neurons	O
so	O
of	O
course	O
existing	O
connections	O
from	O
what	O
do	O
we	O
learn	O
chapter	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
dkriesel	O
com	O
as	O
mentioned	O
above	O
we	O
assume	O
the	O
change	B
in	I
weight	B
to	O
be	O
the	O
most	O
common	O
procedure	O
furthermore	O
deletion	O
of	O
connections	O
can	O
be	O
realized	O
by	O
additionally	O
taking	O
care	O
that	O
a	O
connection	B
is	O
no	O
longer	O
trained	O
when	O
it	O
is	O
set	O
to	O
moreover	O
we	O
can	O
develop	O
further	O
connections	O
by	O
setting	O
a	O
non-existing	O
connection	B
the	O
value	O
in	O
the	O
connection	B
matrix	O
to	O
a	O
value	O
different	O
from	O
as	O
for	O
the	O
modification	O
of	O
threshold	O
values	O
i	O
refer	O
to	O
the	O
possibility	O
of	O
implementing	O
them	O
as	O
weights	O
thus	O
we	O
perform	O
any	O
of	O
the	O
first	O
four	O
of	O
the	O
learning	O
paradigms	O
by	O
just	O
training	O
synaptic	O
weights	O
the	O
change	O
of	O
neuron	B
functions	O
is	O
difficult	O
to	O
implement	O
not	O
very	O
intuitive	O
and	O
not	O
exactly	O
biologically	O
motivated	O
therefore	O
it	O
is	O
not	O
very	O
popular	O
and	O
i	O
will	O
omit	O
this	O
topic	O
here	O
the	O
possibilities	O
to	O
develop	O
or	O
delete	O
neurons	O
do	O
not	O
only	O
provide	O
well	O
adjusted	O
weights	O
during	O
the	O
training	O
of	O
a	O
neural	B
network	I
but	O
also	O
optimize	O
the	O
network	O
topology	B
thus	O
they	O
attract	O
a	O
growing	B
interest	O
and	O
are	O
often	O
realized	O
by	O
using	O
evolutionary	O
procedures	O
but	O
since	O
we	O
accept	O
that	O
a	O
large	O
part	O
of	O
learning	O
possibilities	O
can	O
already	O
be	O
covered	O
by	O
changes	O
in	O
weight	B
they	O
are	O
also	O
not	O
the	O
subject	O
matter	O
of	O
this	O
text	O
it	O
is	O
planned	O
to	O
extend	O
the	O
text	O
towards	O
those	O
aspects	O
of	O
training	O
of	O
allow	O
for	O
the	O
changes	O
class	O
snipe	O
methods	O
in	O
neuralnetwork	O
connection	B
weights	O
and	O
addition	O
and	O
removal	O
of	O
both	O
connections	O
and	O
neurons	O
methods	O
in	O
neuralnetworkdescriptor	O
enable	O
the	O
change	O
of	O
neuron	B
behaviors	O
respectively	O
per	O
layer	O
activation	B
functions	O
learning	O
by	O
changes	O
in	O
weight	B
thus	O
we	O
let	O
our	O
neural	B
network	I
learn	O
by	O
modifying	O
the	O
connecting	O
weights	O
according	O
to	O
rules	O
that	O
can	O
be	O
formulated	O
as	O
algorithms	O
therefore	O
a	O
learning	O
procedure	O
is	O
always	O
an	O
algorithm	B
that	O
can	O
easily	O
be	O
implemented	O
by	O
means	O
of	O
a	O
programming	O
language	O
later	O
in	O
the	O
text	O
i	O
will	O
assume	O
that	O
the	O
definition	O
of	O
the	O
term	O
desired	O
output	B
which	O
is	O
worth	O
learning	O
is	O
known	O
i	O
will	O
define	O
formally	O
what	O
a	O
training	B
pattern	I
is	O
and	O
that	O
we	O
have	O
a	O
training	B
set	B
of	I
learning	O
samples	O
let	O
a	O
training	B
set	I
be	O
defined	O
as	O
follows	O
definition	O
set	O
a	O
train-	O
ing	O
set	O
p	O
is	O
a	O
set	B
of	I
training	O
patterns	O
which	O
we	O
use	O
to	O
train	O
our	O
neural	O
net	O
i	O
will	O
now	O
introduce	O
the	O
three	O
essential	O
paradigms	O
of	O
learning	O
by	O
presenting	O
the	O
differences	O
between	O
their	O
regarding	O
training	O
sets	O
unsupervised	B
learning	O
provides	O
input	B
patterns	I
to	O
the	O
network	O
but	O
no	O
learning	O
aides	O
unsupervised	B
learning	O
is	O
the	O
biologically	O
most	O
plausible	O
method	O
but	O
is	O
not	O
suitable	O
for	O
all	O
problems	B
only	O
the	O
input	B
patterns	I
are	O
given	O
the	O
network	O
tries	O
to	O
identify	O
similar	O
patterns	O
and	O
to	O
classify	O
them	O
into	O
similar	O
categories	O
definition	O
learning	O
the	O
training	B
set	I
only	O
consists	O
of	O
input	B
patterns	I
the	O
network	O
tries	O
by	O
itself	O
to	O
detect	O
similarities	O
and	O
to	O
generate	O
pattern	O
classes	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
paradigms	O
of	O
learning	O
here	O
i	O
want	O
to	O
refer	O
again	O
to	O
the	O
popular	O
example	O
of	O
kohonen	O
s	O
self-organising	O
maps	O
reinforcement	B
learning	I
methods	O
provide	O
feedback	O
to	O
the	O
network	O
whether	O
it	O
behaves	O
well	O
or	O
bad	O
in	O
reinforcement	B
learning	I
the	O
network	O
receives	O
a	O
logical	O
or	O
a	O
real	O
value	O
after	O
completion	O
of	O
a	O
sequence	O
which	O
defines	O
whether	O
the	O
result	O
is	O
right	O
or	O
wrong	O
intuitively	O
it	O
is	O
clear	O
that	O
this	O
procedure	O
should	O
be	O
more	O
effective	O
than	O
unsupervised	B
learning	O
since	O
the	O
network	O
receives	O
specific	B
critera	O
for	O
problem-solving	O
definition	O
learning	O
the	O
training	B
set	I
consists	O
of	O
input	B
patterns	I
after	O
completion	O
of	O
a	O
sequence	O
a	O
value	O
is	O
returned	O
to	O
the	O
network	O
indicating	O
whether	O
the	O
result	O
was	O
right	O
or	O
wrong	O
and	O
possibly	O
how	O
right	O
or	O
wrong	O
it	O
was	O
supervised	B
learning	O
methods	O
provide	O
training	O
patterns	O
together	O
with	O
appropriate	O
desired	O
outputs	O
in	O
supervised	B
learning	O
the	O
training	B
set	I
consists	O
of	O
input	B
patterns	I
as	O
well	O
as	O
their	O
correct	O
results	O
in	O
the	O
form	O
of	O
the	O
precise	B
activation	B
of	O
all	O
output	B
neurons	O
thus	O
for	O
each	O
training	B
set	I
that	O
is	O
fed	O
into	O
the	O
network	O
the	O
output	B
for	O
instance	O
can	O
directly	O
be	O
compared	O
with	O
the	O
correct	O
solution	O
and	O
and	O
the	O
network	O
weights	O
can	O
be	O
changed	O
according	O
to	O
their	O
difference	O
the	O
objective	O
is	O
to	O
change	O
the	O
weights	O
to	O
the	O
effect	O
that	O
the	O
network	O
cannot	O
only	O
associate	O
input	B
and	O
output	B
patterns	O
independently	O
after	O
the	O
training	O
but	O
can	O
provide	O
plausible	O
results	O
to	O
unknown	O
similar	O
input	B
patterns	I
i	O
e	O
it	O
generalises	O
definition	O
learning	O
the	O
training	B
set	I
consists	O
of	O
input	B
patterns	I
with	O
correct	O
results	O
so	O
that	O
the	O
network	O
can	O
receive	O
a	O
precise	B
error	O
can	O
be	O
returned	O
this	O
learning	O
procedure	O
is	O
not	O
always	O
biologically	O
plausible	O
but	O
it	O
is	O
extremely	O
effective	O
and	O
therefore	O
very	O
practicable	O
at	O
first	O
we	O
want	O
to	O
look	O
at	O
the	O
the	O
supervised	B
learning	O
procedures	O
in	O
general	O
which	O
in	O
this	O
text	O
are	O
corresponding	O
to	O
the	O
following	O
steps	O
entering	O
the	O
input	B
pattern	O
of	O
input	B
neurons	O
forward	O
propagation	O
of	O
the	O
input	B
by	O
the	O
network	O
generation	O
of	O
the	O
output	B
comparing	O
the	O
output	B
with	O
the	O
desired	O
output	B
input	B
provides	O
error	B
vector	I
vector	O
corrections	O
of	O
the	O
network	O
are	O
calculated	O
based	O
on	O
the	O
error	B
vector	I
corrections	O
are	O
applied	O
the	O
term	O
error	B
vector	I
will	O
be	O
defined	O
in	O
section	O
where	O
mathematical	O
formalisation	O
of	O
learning	O
is	O
discussed	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
network	O
receives	O
reward	B
or	O
punishment	O
network	O
receives	O
correct	O
results	O
for	O
samples	O
learning	O
scheme	O
chapter	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
dkriesel	O
com	O
o	O
ine	O
or	O
online	B
learning	O
it	O
must	O
be	O
noted	O
that	O
learning	O
can	O
be	O
o	O
ine	O
set	B
of	I
training	O
samples	O
is	O
presented	O
then	O
the	O
weights	O
are	O
changed	O
the	O
total	B
error	O
is	O
calculated	O
by	O
means	O
of	O
a	O
error	B
function	I
operation	O
or	O
simply	O
accumulated	O
see	O
also	O
section	O
or	O
online	B
every	O
sample	O
presented	O
the	O
weights	O
are	O
changed	O
both	O
procedures	O
have	O
advantages	O
and	O
disadvantages	O
which	O
will	O
be	O
discussed	O
in	O
the	O
learning	O
procedures	O
section	O
if	O
necessary	O
o	O
ine	O
training	O
procedures	O
are	O
also	O
called	O
batch	O
training	O
procedures	O
since	O
a	O
batch	O
of	O
results	O
is	O
corrected	O
all	O
at	O
once	O
such	O
a	O
training	O
section	O
of	O
a	O
whole	O
batch	O
of	O
training	O
samples	O
including	O
the	O
related	O
change	B
in	I
weight	B
values	O
is	O
called	O
epoch	B
definition	O
ine	O
learning	O
several	O
training	O
patterns	O
are	O
entered	O
into	O
the	O
network	O
at	O
once	O
the	O
errors	O
are	O
accumulated	O
and	O
it	O
learns	O
for	O
all	O
patterns	O
at	O
the	O
same	O
time	O
definition	O
learning	O
the	O
network	O
learns	O
directly	O
from	O
the	O
errors	O
of	O
each	O
training	O
sample	O
how	O
must	O
the	O
weights	O
be	O
modified	O
to	O
allow	O
fast	O
and	O
reliable	O
learning	O
how	O
can	O
the	O
success	O
of	O
a	O
learning	O
process	O
be	O
measured	O
in	O
an	O
objective	O
way	O
is	O
it	O
possible	O
to	O
determine	O
the	O
learning	O
procedure	O
is	O
it	O
possible	O
to	O
predict	O
if	O
a	O
learning	O
procedure	O
terminates	O
i	O
e	O
whether	O
it	O
will	O
reach	O
an	O
optimal	O
state	B
after	O
a	O
finite	O
time	O
or	O
if	O
it	O
for	O
example	O
will	O
oscillate	O
between	O
different	O
states	O
how	O
can	O
the	O
learned	O
patterns	O
be	O
stored	O
in	O
the	O
network	O
is	O
it	O
possible	O
to	O
avoid	O
that	O
newly	O
learned	O
patterns	O
destroy	O
previously	O
learned	O
associations	O
so-called	O
stabilityplasticity	O
dilemma	O
we	O
will	O
see	O
that	O
all	O
these	O
questions	O
cannot	O
be	O
generally	O
answered	O
but	O
that	O
they	O
have	O
to	O
be	O
discussed	O
for	O
each	O
learning	O
procedure	O
no	O
easy	O
and	O
each	O
network	O
topology	B
individually	O
answers	O
training	O
patterns	O
and	O
teaching	B
input	B
questions	O
you	O
should	O
answer	O
before	O
learning	O
the	O
application	O
of	O
such	O
schemes	O
certainly	O
requires	O
preliminary	O
thoughts	O
about	O
some	O
questions	O
which	O
i	O
want	O
to	O
introduce	O
now	O
as	O
a	O
check	O
list	O
and	O
if	O
possible	O
answer	O
them	O
in	O
the	O
course	O
of	O
this	O
text	O
where	O
does	O
the	O
learning	O
input	B
come	O
from	O
and	O
in	O
what	O
form	O
before	O
we	O
get	O
to	O
know	O
our	O
first	O
learning	O
rule	O
we	O
need	O
to	O
introduce	O
the	O
teaching	B
input	B
in	O
case	O
of	O
supervised	B
learning	O
we	O
assume	O
a	O
training	B
set	I
consisting	O
of	O
training	O
patterns	O
and	O
the	O
corresponding	O
correct	O
output	B
values	O
we	O
want	O
to	O
see	O
at	O
the	O
output	B
neurons	O
after	O
the	O
training	O
while	O
the	O
network	O
has	O
not	O
finished	O
training	O
i	O
e	O
as	O
long	O
as	O
it	O
is	O
generating	O
wrong	O
outputs	O
these	O
output	B
values	O
are	O
referred	O
desired	O
output	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
training	O
patterns	O
and	O
teaching	B
input	B
desired	O
output	B
to	O
as	O
teaching	B
input	B
and	O
that	O
for	O
each	O
neuron	B
individually	O
thus	O
for	O
a	O
neuron	B
j	O
with	O
the	O
incorrect	O
output	B
oj	O
tj	O
is	O
the	O
teaching	B
input	B
which	O
means	O
it	O
is	O
the	O
correct	O
or	O
desired	O
output	B
for	O
a	O
training	B
pattern	I
p	O
definition	O
patterns	O
a	O
training	B
pattern	I
is	O
an	O
input	B
vector	I
p	O
with	O
the	O
components	O
pn	O
whose	O
desired	O
output	B
is	O
known	O
by	O
entering	O
the	O
training	B
pattern	I
into	O
the	O
network	O
we	O
receive	O
an	O
output	B
that	O
can	O
be	O
compared	O
with	O
the	O
teaching	B
input	B
which	O
is	O
the	O
desired	O
output	B
the	O
set	B
of	I
training	O
patterns	O
is	O
called	O
p	O
it	O
contains	O
a	O
finite	O
number	O
of	O
ordered	O
pairsp	O
t	O
of	O
training	O
patterns	O
with	O
corresponding	O
desired	O
output	B
training	O
patterns	O
are	O
often	O
simply	O
called	O
patterns	O
that	O
is	O
why	O
they	O
are	O
referred	O
to	O
as	O
p	O
in	O
the	O
literature	O
as	O
well	O
as	O
in	O
this	O
text	O
they	O
are	O
called	O
synonymously	O
patterns	O
training	O
samples	O
etc	O
definition	O
input	B
let	O
j	O
be	O
an	O
output	B
neuron	B
the	O
teaching	B
input	B
tj	O
is	O
the	O
desired	O
and	O
correct	O
value	O
j	O
should	O
output	B
after	O
the	O
input	B
of	O
a	O
certain	O
training	B
pattern	I
analogously	O
to	O
the	O
vector	O
p	O
the	O
teaching	O
inputs	O
tn	O
of	O
the	O
neurons	O
can	O
also	O
be	O
combined	O
into	O
a	O
vector	O
t	O
t	O
always	O
refers	O
to	O
a	O
specific	B
training	B
pattern	I
p	O
and	O
is	O
as	O
already	O
mentioned	O
contained	O
in	O
the	O
set	O
p	O
of	O
the	O
training	O
patterns	O
are	O
that	O
relevant	O
snipe	O
classes	O
in	O
for	O
training	O
the	O
package	O
class	O
trainingsamplelesson	O
allows	O
for	O
storage	O
of	O
training	O
patterns	O
and	O
teaching	O
inputs	O
data	O
are	O
training	O
located	O
the	O
as	O
well	O
as	O
simple	O
preprocessing	O
of	O
the	O
training	O
data	O
definition	O
vector	O
for	O
sev-	O
eral	O
output	B
neurons	O
n	O
the	O
difference	O
between	O
output	B
vector	I
and	O
teaching	B
input	B
under	O
a	O
training	O
input	B
p	O
tn	O
yn	O
ep	O
is	O
referred	O
to	O
as	O
error	B
vector	I
sometimes	O
it	O
is	O
also	O
called	O
difference	O
vector	O
depending	O
on	O
whether	O
you	O
are	O
learning	O
offline	O
or	O
online	B
the	O
difference	O
vector	O
refers	O
to	O
a	O
specific	B
training	B
pattern	I
or	O
to	O
the	O
error	O
of	O
a	O
set	B
of	I
training	O
patterns	O
which	O
is	O
normalized	O
in	O
a	O
certain	O
way	O
now	O
i	O
want	O
to	O
briefly	O
summarize	O
the	O
vectors	O
we	O
have	O
yet	O
defined	O
there	O
is	O
the	O
input	B
vector	I
x	O
which	O
can	O
be	O
entered	O
into	O
the	O
neural	B
network	I
depending	O
on	O
the	O
type	O
of	O
network	O
being	O
used	O
the	O
neural	B
network	I
will	O
output	B
an	O
output	B
vector	I
y	O
basically	O
the	O
training	O
sample	O
p	O
is	O
nothing	O
more	O
than	O
an	O
input	B
vector	I
we	O
only	O
use	O
it	O
for	O
training	O
purposes	O
because	O
we	O
know	O
the	O
corresponding	O
teaching	B
input	B
t	O
which	O
is	O
nothing	O
more	O
than	O
the	O
desired	O
output	B
vector	I
to	O
the	O
training	O
sample	O
the	O
error	B
vector	I
ep	O
is	O
the	O
difference	O
between	O
the	O
teaching	B
input	B
t	O
and	O
the	O
actural	O
output	B
y	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
dkriesel	O
com	O
important	O
so	O
what	O
x	O
and	O
y	O
are	O
for	O
the	O
general	O
network	O
operation	O
are	O
p	O
and	O
t	O
for	O
the	O
network	O
training	O
and	O
during	O
training	O
we	O
try	O
to	O
bring	O
y	O
as	O
close	O
to	O
t	O
as	O
possible	O
one	O
advice	O
concerning	O
notation	O
we	O
referred	O
to	O
the	O
output	B
values	O
of	O
a	O
neuron	B
i	O
as	O
oi	O
thus	O
the	O
output	B
of	O
an	O
output	B
neuron	B
is	O
called	O
o	O
but	O
the	O
output	B
values	O
of	O
a	O
network	O
are	O
referred	O
to	O
as	O
y	O
certainly	O
these	O
network	O
outputs	O
are	O
only	O
neuron	B
outputs	O
too	O
but	O
they	O
are	O
outputs	O
of	O
output	B
neurons	O
in	O
this	O
respect	O
y	O
o	O
is	O
true	O
using	O
training	O
samples	O
we	O
have	O
seen	O
how	O
we	O
can	O
learn	O
in	O
principle	O
and	O
which	O
steps	O
are	O
required	O
to	O
do	O
so	O
now	O
we	O
should	O
take	O
a	O
look	O
at	O
the	O
selection	B
of	I
training	O
data	O
and	O
the	O
learning	O
curve	O
after	O
successful	O
learning	O
it	O
is	O
particularly	O
interesting	O
whether	O
the	O
network	O
has	O
only	O
memorized	B
i	O
e	O
whether	O
it	O
can	O
use	O
our	O
training	O
samples	O
to	O
quite	O
exactly	O
produce	O
the	O
right	O
output	B
but	O
to	O
provide	O
wrong	O
answers	O
for	O
all	O
other	O
problems	B
of	O
the	O
same	O
class	O
suppose	O
that	O
we	O
want	O
the	O
network	O
to	O
train	O
a	O
mapping	O
and	O
therefor	O
use	O
the	O
training	O
samples	O
from	O
fig	O
then	O
there	O
could	O
be	O
a	O
chance	O
that	O
finally	O
the	O
network	O
will	O
exactly	O
mark	O
the	O
colored	O
areas	O
around	O
the	O
training	O
samples	O
with	O
the	O
output	B
top	O
and	O
otherwise	O
will	O
output	B
thus	O
it	O
has	O
sufficient	O
storage	O
capacity	O
to	O
concentrate	O
on	O
the	O
six	O
training	O
figure	O
visualization	O
of	O
training	O
results	O
of	O
the	O
same	O
training	B
set	I
on	O
networks	O
with	O
a	O
capacity	O
being	O
too	O
high	O
correct	O
or	O
too	O
low	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
using	O
training	O
samples	O
samples	O
with	O
the	O
output	B
this	O
implies	O
an	O
oversized	O
network	O
with	O
too	O
much	O
free	O
storage	O
capacity	O
on	O
the	O
other	O
hand	O
a	O
network	O
could	O
have	O
insufficient	O
capacity	O
bottom	O
this	O
rough	O
presentation	O
of	O
input	B
data	O
does	O
not	O
correspond	O
to	O
the	O
good	O
generalization	B
performance	O
we	O
desire	O
thus	O
we	O
have	O
to	O
find	O
the	O
balance	O
middle	O
it	O
is	O
useful	O
to	O
divide	O
the	O
set	B
of	I
training	O
samples	O
an	O
often	O
proposed	O
solution	O
for	O
these	O
problems	B
is	O
to	O
divide	O
the	O
training	B
set	I
into	O
one	O
training	B
set	I
really	O
used	O
to	O
train	O
and	O
one	O
verification	O
set	O
to	O
test	O
our	O
progress	O
provided	O
that	O
there	O
are	O
enough	O
training	O
samples	O
the	O
usual	O
division	O
relations	O
are	O
for	O
instance	O
for	O
training	O
data	O
and	O
for	O
verification	O
data	O
chosen	O
we	O
can	O
finish	O
the	O
training	O
when	O
the	O
network	O
provides	O
good	O
results	O
on	O
the	O
training	O
data	O
as	O
well	O
as	O
on	O
the	O
verification	O
data	O
snipe	O
the	O
method	O
splitlesson	O
within	O
the	O
class	O
trainingsamplelesson	O
allows	O
for	O
splitting	O
a	O
trainingsamplelesson	O
with	O
respect	O
to	O
a	O
given	O
ratio	O
but	O
note	O
if	O
the	O
verification	O
data	O
provide	O
poor	O
results	O
do	O
not	O
modify	O
the	O
network	O
structure	O
until	O
these	O
data	O
provide	O
good	O
results	O
otherwise	O
you	O
run	O
the	O
risk	O
of	O
tailoring	O
the	O
network	O
to	O
the	O
verification	O
data	O
this	O
means	O
that	O
these	O
data	O
are	O
included	O
in	O
the	O
training	O
even	O
if	O
they	O
are	O
not	O
used	O
explicitly	O
for	O
the	O
training	O
the	O
solution	O
is	O
a	O
third	O
set	B
of	I
validation	O
data	O
used	O
only	O
for	O
validation	O
after	O
a	O
supposably	O
successful	O
training	O
by	O
training	O
less	O
patterns	O
we	O
obviously	O
withhold	O
information	O
from	O
the	O
network	O
and	O
risk	O
to	O
worsen	O
the	O
learning	O
performance	O
but	O
this	O
text	O
is	O
not	O
about	O
exact	O
reproduction	O
of	O
given	O
samples	O
but	O
about	O
successful	O
generalization	B
and	O
approximation	B
of	O
a	O
whole	O
function	O
for	O
which	O
it	O
can	O
definitely	O
be	O
useful	O
to	O
train	O
less	O
information	O
into	O
the	O
network	O
order	O
of	O
pattern	O
representation	O
you	O
can	O
find	O
different	O
strategies	O
to	O
choose	O
the	O
order	O
of	O
pattern	O
presentation	O
if	O
patterns	O
are	O
presented	O
in	O
random	O
sequence	O
there	O
is	O
no	O
guarantee	O
that	O
the	O
patterns	O
are	O
learned	O
equally	O
well	O
this	O
is	O
the	O
standard	O
method	O
always	O
the	O
same	O
sequence	O
of	O
patterns	O
on	O
the	O
other	O
hand	O
provokes	O
that	O
the	O
patterns	O
will	O
be	O
memorized	B
when	O
using	O
recurrent	B
networks	O
we	O
will	O
learn	O
more	O
about	O
this	O
type	O
of	O
networks	O
a	O
random	O
permutation	O
would	O
solve	O
both	O
problems	B
but	O
it	O
is	O
as	O
already	O
mentioned	O
very	O
time-consuming	O
to	O
calculate	O
such	O
a	O
permutation	O
snipe	O
the	O
method	O
shufflesamples	O
located	O
in	O
the	O
class	O
trainingsamplelesson	O
permutes	O
a	O
lesson	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
dkriesel	O
com	O
norm	O
to	O
compare	O
learning	O
curve	O
and	O
error	O
measurement	O
the	O
learning	O
curve	O
indicates	O
the	O
progress	O
of	O
the	O
error	O
which	O
can	O
be	O
determined	O
in	O
various	O
ways	O
the	O
motivation	O
to	O
create	O
a	O
learning	O
curve	O
is	O
that	O
such	O
a	O
curve	O
can	O
indicate	O
whether	O
the	O
network	O
is	O
progressing	O
or	O
not	O
for	O
this	O
the	O
error	O
should	O
be	O
normalized	O
i	O
e	O
represent	O
a	O
distance	O
measure	O
between	O
the	O
correct	O
and	O
the	O
current	O
output	B
of	O
the	O
network	O
for	O
example	O
we	O
can	O
take	O
the	O
same	O
pattern-specific	O
squared	B
error	O
with	O
a	O
prefactor	O
which	O
we	O
are	O
also	O
going	O
to	O
use	O
to	O
derive	O
the	O
backpropagation	B
of	I
error	I
be	O
output	B
neurons	O
and	O
o	O
the	O
set	B
of	I
output	B
neurons	O
x	O
o	O
errp	O
y	O
definition	O
error	O
the	O
specific	B
error	O
errp	O
is	O
based	O
on	O
a	O
single	O
training	O
sample	O
which	O
means	O
it	O
is	O
generated	O
online	B
additionally	O
the	O
root	B
mean	I
square	I
rms	O
and	O
the	O
euclidean	B
distance	O
are	O
often	O
used	O
the	O
euclidean	B
distance	O
of	O
the	O
theorem	O
of	O
pythagoras	B
is	O
useful	O
for	O
lower	O
dimensions	O
where	O
we	O
can	O
still	O
visualize	O
its	O
usefulness	O
definition	O
distance	O
the	O
euclidean	B
distance	O
between	O
two	O
vectors	O
t	O
and	O
y	O
is	O
defined	O
as	O
sx	O
o	O
errp	O
generally	O
the	O
root	B
mean	I
square	I
is	O
commonly	O
used	O
since	O
it	O
considers	O
extreme	O
outliers	O
to	O
a	O
greater	O
extent	O
definition	O
mean	O
square	O
the	O
root	B
mean	I
square	I
of	O
two	O
vectors	O
t	O
and	O
y	O
is	O
defined	O
as	O
sp	O
errp	O
ot	O
y	O
as	O
for	O
o	O
ine	O
learning	O
the	O
total	B
error	O
in	O
the	O
course	O
of	O
one	O
training	O
epoch	B
is	O
interesting	O
and	O
useful	O
too	O
err	O
x	O
p	O
p	O
errp	O
definition	O
error	O
the	O
total	B
error	O
err	O
is	O
based	O
on	O
all	O
training	O
samples	O
that	O
means	O
it	O
is	O
generated	O
o	O
ine	O
analogously	O
we	O
can	O
generate	O
a	O
total	B
rms	O
and	O
a	O
total	B
euclidean	B
distance	O
in	O
the	O
course	O
of	O
a	O
whole	O
epoch	B
of	O
course	O
it	O
is	O
possible	O
to	O
use	O
other	O
types	O
of	O
error	O
measurement	O
to	O
get	O
used	O
to	O
further	O
error	O
measurement	O
methods	O
i	O
suggest	O
to	O
have	O
a	O
look	O
into	O
the	O
technical	O
report	O
of	O
prechelt	O
in	O
this	O
report	O
both	O
error	O
measurement	O
methods	O
and	O
sample	O
problems	B
are	O
discussed	O
is	O
why	O
there	O
will	O
be	O
a	O
simmilar	O
suggestion	O
during	O
the	O
discussion	O
of	O
exemplary	O
problems	B
snipe	O
there	O
are	O
several	O
static	O
methods	O
representing	O
different	O
methods	O
of	O
error	O
measurement	O
implemented	O
in	O
the	O
class	O
errormeasurement	O
y	O
depending	O
on	O
our	O
method	O
of	O
error	O
measurement	O
our	O
learning	O
curve	O
certainly	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
objectivity	O
dkriesel	O
com	O
learning	O
curve	O
and	O
error	O
measurement	O
changes	O
too	O
a	O
perfect	O
learning	O
curve	O
looks	O
like	O
a	O
negative	O
exponential	O
function	O
that	O
means	O
it	O
is	O
proportional	O
to	O
e	O
t	O
on	O
the	O
following	O
page	O
thus	O
the	O
representation	O
of	O
the	O
learning	O
curve	O
can	O
be	O
illustrated	O
by	O
means	O
of	O
a	O
logarithmic	O
scale	O
second	O
diagram	O
from	O
the	O
bottom	O
with	O
the	O
said	O
scaling	O
combination	O
a	O
descending	O
line	O
implies	O
an	O
exponential	O
descent	O
of	O
the	O
error	O
with	O
the	O
network	O
doing	O
a	O
good	O
job	O
the	O
problems	B
being	O
not	O
too	O
difficult	O
and	O
the	O
logarithmic	O
representation	O
of	O
err	O
you	O
can	O
see	O
metaphorically	O
speaking	O
a	O
descending	O
line	O
that	O
often	O
forms	O
at	O
the	O
bottom	O
here	O
we	O
reach	O
the	O
limit	O
of	O
the	O
resolution	O
of	O
our	O
computer	O
and	O
our	O
network	O
has	O
actually	O
learned	O
the	O
optimum	O
of	O
what	O
it	O
is	O
capable	O
of	O
learning	O
i	O
e	O
typical	O
learning	O
curves	O
can	O
show	O
a	O
few	O
flat	O
areas	O
as	O
well	O
they	O
can	O
show	O
some	O
steps	O
which	O
is	O
no	O
sign	O
of	O
a	O
malfunctioning	O
learning	O
process	O
as	O
we	O
can	O
also	O
see	O
in	O
fig	O
a	O
well-suited	O
representation	O
can	O
make	O
any	O
slightly	O
decreasing	O
learning	O
curve	O
look	O
good	O
so	O
just	O
be	O
cautious	O
when	O
reading	O
the	O
literature	O
when	O
do	O
we	O
stop	O
learning	O
now	O
the	O
big	O
question	O
is	O
when	O
do	O
we	O
stop	O
learning	O
generally	O
the	O
training	O
is	O
stopped	O
when	O
the	O
user	O
in	O
front	O
of	O
the	O
learning	O
computer	O
the	O
error	O
was	O
small	O
enough	O
indeed	O
there	O
is	O
no	O
easy	O
answer	O
and	O
thus	O
i	O
can	O
once	O
again	O
only	O
give	O
you	O
something	O
to	O
think	O
about	O
which	O
however	O
depends	O
on	O
a	O
more	O
objective	O
view	O
on	O
the	O
comparison	O
of	O
several	O
learning	O
curves	O
confidence	O
in	O
the	O
results	O
for	O
example	O
is	O
boosted	O
when	O
the	O
network	O
always	O
reaches	O
nearly	O
the	O
same	O
final	O
error-rate	O
for	O
different	O
random	O
initializations	O
so	O
repeated	O
initialization	O
and	O
training	O
will	O
provide	O
a	O
more	O
objective	O
result	O
on	O
the	O
other	O
hand	O
it	O
can	O
be	O
possible	O
that	O
a	O
curve	O
descending	O
fast	O
in	O
the	O
beginning	O
can	O
after	O
a	O
longer	O
time	O
of	O
learning	O
be	O
overtaken	O
by	O
another	O
curve	O
this	O
can	O
indicate	O
that	O
either	O
the	O
learning	B
rate	I
of	O
the	O
worse	O
curve	O
was	O
too	O
high	O
or	O
the	O
worse	O
curve	O
itself	O
simply	O
got	O
stuck	O
in	O
a	O
local	O
minimum	O
but	O
was	O
the	O
first	O
to	O
find	O
it	O
remember	O
larger	O
error	O
values	O
are	O
worse	O
than	O
the	O
small	O
ones	O
but	O
in	O
any	O
case	O
note	O
many	O
people	O
only	O
generate	O
a	O
learning	O
curve	O
in	O
respect	O
of	O
the	O
training	O
data	O
then	O
they	O
are	O
surprised	O
that	O
only	O
a	O
few	O
things	O
will	O
work	O
but	O
for	O
reasons	O
of	O
objectivity	O
and	O
clarity	O
it	O
should	O
not	O
be	O
forgotten	O
to	O
plot	O
the	O
verification	O
data	O
on	O
a	O
second	O
learning	O
curve	O
which	O
generally	O
provides	O
values	O
that	O
are	O
slightly	O
worse	O
and	O
with	O
stronger	O
oscillation	O
but	O
with	O
good	O
generalization	B
the	O
curve	O
can	O
decrease	O
too	O
when	O
the	O
network	O
eventually	O
begins	O
to	O
memorize	O
the	O
samples	O
the	O
shape	O
of	O
the	O
learning	O
curve	O
can	O
provide	O
an	O
indication	O
if	O
the	O
learning	O
curve	O
of	O
the	O
verification	O
samples	O
is	O
suddenly	O
and	O
rapidly	O
rising	O
while	O
the	O
learning	O
curve	O
of	O
the	O
verification	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
dkriesel	O
com	O
figure	O
all	O
four	O
illustrations	O
show	O
the	O
same	O
because	O
very	O
smooth	O
learning	O
curve	O
note	O
the	O
alternating	O
logarithmic	O
and	O
linear	O
scalings	O
also	O
note	O
the	O
small	O
spikes	O
visible	O
in	O
the	O
sharp	O
bend	O
of	O
the	O
curve	O
in	O
the	O
first	O
and	O
second	O
diagram	O
from	O
bottom	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
gradient	B
optimization	O
procedures	O
data	O
is	O
continuously	O
falling	O
this	O
could	O
indicate	O
memorizing	O
and	O
a	O
generalization	B
getting	O
poorer	O
and	O
poorer	O
at	O
this	O
point	O
it	O
could	O
be	O
decided	O
whether	O
the	O
network	O
has	O
already	O
learned	O
well	O
enough	O
at	O
the	O
next	O
point	O
of	O
the	O
two	O
curves	O
and	O
maybe	O
the	O
final	O
point	O
of	O
learning	O
is	O
to	O
be	O
applied	O
here	O
procedure	O
is	O
called	O
early	B
stopping	I
once	O
again	O
i	O
want	O
to	O
remind	O
you	O
that	O
they	O
are	O
all	O
acting	O
as	O
indicators	O
and	O
not	O
to	O
draw	O
if-then	O
conclusions	O
gradient	B
optimization	O
procedures	O
in	O
order	O
to	O
establish	O
the	O
mathematical	O
basis	B
for	O
some	O
of	O
the	O
following	O
learning	O
procedures	O
i	O
want	O
to	O
explain	O
briefly	O
what	O
is	O
meant	O
by	O
gradient	B
descent	I
the	O
backpropagation	B
of	I
error	I
learning	O
procedure	O
for	O
example	O
involves	O
this	O
mathematical	O
basis	B
and	O
thus	O
inherits	O
the	O
advantages	O
and	O
disadvantages	O
of	O
the	O
gradient	B
descent	I
gradient	B
descent	I
procedures	O
are	O
generally	O
used	O
where	O
we	O
want	O
to	O
maximize	O
or	O
minimize	O
n-dimensional	O
functions	O
due	O
to	O
clarity	O
the	O
illustration	O
on	O
the	O
next	O
page	O
shows	O
only	O
two	O
dimensions	O
but	O
principally	O
there	O
is	O
no	O
limit	O
to	O
the	O
number	O
of	O
dimensions	O
the	O
gradient	B
is	O
a	O
vector	O
g	O
that	O
is	O
defined	O
for	O
any	O
differentiable	O
point	O
of	O
a	O
function	O
that	O
points	O
from	O
this	O
point	O
exactly	O
towards	O
the	O
steepest	O
ascent	O
and	O
indicates	O
the	O
gradient	B
in	O
this	O
direction	O
by	O
means	O
gradient	B
is	O
multi-dim	O
derivative	O
of	O
its	O
norm	O
thus	O
the	O
gradient	B
is	O
a	O
generalization	B
of	O
the	O
derivative	O
for	O
multidimensional	O
functions	O
accordingly	O
the	O
negative	O
gradient	B
g	O
exactly	O
points	O
towards	O
the	O
steepest	O
descent	O
the	O
gradient	B
operator	O
is	O
referred	O
to	O
as	O
nabla	O
op-	O
erator	O
the	O
overall	O
notation	O
of	O
the	O
the	O
gradient	B
g	O
of	O
the	O
point	O
y	O
of	O
a	O
twodimensional	O
function	O
f	O
being	O
gx	O
y	O
fx	O
y	O
definition	O
let	O
g	O
be	O
a	O
gradient	B
then	O
g	O
is	O
a	O
vector	O
with	O
n	O
components	O
that	O
is	O
defined	O
for	O
any	O
point	O
of	O
a	O
n-dimensional	O
function	O
xn	O
the	O
gradient	B
operator	O
notation	O
is	O
defined	O
as	O
xn	O
xn	O
g	O
directs	O
from	O
any	O
point	O
of	O
f	O
towards	O
the	O
steepest	O
ascent	O
from	O
this	O
point	O
with	O
corresponding	O
to	O
the	O
degree	O
of	O
this	O
ascent	O
gradient	B
descent	I
means	O
to	O
going	O
downhill	O
in	O
small	O
steps	O
from	O
any	O
starting	O
point	O
of	O
our	O
function	O
towards	O
the	O
gradient	B
g	O
means	O
vividly	O
speaking	O
the	O
direction	O
to	O
which	O
a	O
ball	O
would	O
roll	O
from	O
the	O
starting	O
point	O
with	O
the	O
size	O
of	O
the	O
steps	O
being	O
proportional	O
to	O
steeper	O
the	O
descent	O
the	O
longer	O
the	O
steps	O
therefore	O
we	O
move	O
slowly	O
on	O
a	O
flat	O
plateau	O
and	O
on	O
a	O
steep	O
ascent	O
we	O
run	O
downhill	O
rapidly	O
if	O
we	O
came	O
into	O
a	O
valley	O
we	O
would	O
depending	O
on	O
the	O
size	O
of	O
our	O
steps	O
jump	O
over	O
it	O
or	O
we	O
would	O
return	B
into	O
the	O
valley	O
across	O
the	O
opposite	O
hillside	O
in	O
order	O
to	O
come	O
closer	O
and	O
closer	O
to	O
the	O
deepest	O
point	O
of	O
the	O
valley	O
by	O
walking	O
back	O
and	O
forth	O
similar	O
to	O
our	O
ball	O
moving	O
within	O
a	O
round	O
bowl	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
dkriesel	O
com	O
figure	O
visualization	O
of	O
the	O
gradient	B
descent	I
on	O
a	O
two-dimensional	O
error	B
function	I
we	O
move	O
forward	O
in	O
the	O
opposite	O
direction	O
of	O
g	O
i	O
e	O
with	O
the	O
steepest	O
descent	O
towards	O
the	O
lowest	O
point	O
with	O
the	O
step	O
width	O
being	O
proportional	O
to	O
steeper	O
the	O
descent	O
the	O
faster	O
the	O
steps	O
on	O
the	O
left	O
the	O
area	O
is	O
shown	O
in	O
on	O
the	O
right	O
the	O
steps	O
over	O
the	O
contour	O
lines	O
are	O
shown	O
in	O
here	O
it	O
is	O
obvious	O
how	O
a	O
movement	O
is	O
made	O
in	O
the	O
opposite	O
direction	O
of	O
g	O
towards	O
the	O
minimum	O
of	O
the	O
function	O
and	O
continuously	O
slows	O
down	O
proportionally	O
to	O
source	O
patternclassificationgraddescent	O
pdf	O
we	O
go	O
towards	O
the	O
gradient	B
definition	O
descent	O
let	O
f	O
be	O
an	O
n-dimensional	O
function	O
and	O
s	O
sn	O
the	O
given	O
starting	O
point	O
gradient	B
descent	I
means	O
going	O
from	O
fs	O
against	O
the	O
direction	O
of	O
g	O
i	O
e	O
towards	O
g	O
with	O
steps	O
of	O
the	O
size	O
of	O
towards	O
smaller	O
and	O
smaller	O
values	O
of	O
f	O
gradient	B
descent	I
procedures	O
are	O
not	O
an	O
errorless	O
optimization	O
procedure	O
at	O
all	O
we	O
will	O
see	O
in	O
the	O
following	O
sections	O
however	O
they	O
work	O
still	O
well	O
on	O
many	O
problems	B
which	O
makes	O
them	O
an	O
optimization	O
paradigm	O
that	O
is	O
frequently	O
used	O
anyway	O
let	O
us	O
have	O
a	O
look	O
on	O
their	O
potential	O
disadvantages	O
so	O
we	O
can	O
keep	O
them	O
in	O
mind	O
a	O
bit	O
gradient	B
procedures	O
incorporate	O
several	O
problems	B
as	O
already	O
implied	O
in	O
section	O
the	O
gradient	B
descent	I
therefore	O
the	O
backpropagation	B
is	O
promising	O
but	O
not	O
foolproof	O
one	O
problem	O
is	O
that	O
the	O
result	O
does	O
not	O
always	O
reveal	O
if	O
an	O
error	O
has	O
occurred	O
often	O
gradient	B
descents	O
converge	O
against	O
suboptimal	O
minima	O
every	O
gradient	B
descent	I
procedure	O
can	O
for	O
example	O
get	O
stuck	O
within	O
a	O
local	O
minimum	O
a	O
of	O
fig	O
on	O
the	O
facing	O
page	O
gradient	B
descent	I
with	O
errors	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
gradient	B
optimization	O
procedures	O
figure	O
possible	O
errors	O
during	O
a	O
gradient	B
descent	I
a	O
detecting	O
bad	O
minima	O
b	O
quasi-standstill	O
with	O
small	O
gradient	B
c	O
oscillation	O
in	O
canyons	O
d	O
leaving	O
good	O
minima	O
this	O
problem	O
is	O
increasing	O
proportionally	O
to	O
the	O
size	O
of	O
the	O
error	O
surface	O
and	O
there	O
is	O
no	O
universal	B
solution	O
in	O
reality	O
one	O
cannot	O
know	O
if	O
the	O
optimal	O
minimum	O
is	O
reached	O
and	O
considers	O
a	O
training	O
successful	O
if	O
an	O
acceptable	O
minimum	O
is	O
found	O
flat	O
plataeus	O
on	O
the	O
error	O
surface	O
may	O
cause	O
training	O
slowness	O
when	O
passing	O
a	O
flat	O
plateau	O
for	O
instance	O
the	O
gradient	B
also	O
becomes	O
negligibly	O
small	O
because	O
there	O
is	O
hardly	O
a	O
descent	O
b	O
of	O
fig	O
which	O
requires	O
many	O
further	O
steps	O
a	O
hypothetically	O
possible	O
gradient	B
of	O
would	O
completely	O
stop	O
the	O
descent	O
even	O
if	O
good	O
minima	O
are	O
reached	O
they	O
may	O
be	O
left	O
afterwards	O
on	O
the	O
other	O
hand	O
the	O
gradient	B
is	O
very	O
large	O
at	O
a	O
steep	O
slope	O
so	O
that	O
large	O
steps	O
can	O
be	O
made	O
and	O
a	O
good	O
minimum	O
can	O
possibly	O
be	O
missed	O
d	O
of	O
fig	O
steep	O
canyons	O
in	O
the	O
error	O
surface	O
may	O
cause	O
oscillations	O
a	O
sudden	O
alternation	O
from	O
one	O
very	O
strong	O
negative	O
gradient	B
to	O
a	O
very	O
strong	O
positive	O
one	O
can	O
even	O
result	O
in	O
oscillation	O
c	O
of	O
fig	O
in	O
nature	O
such	O
an	O
error	O
does	O
not	O
occur	O
very	O
often	O
so	O
that	O
we	O
can	O
think	O
about	O
the	O
possibilities	O
b	O
and	O
d	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
dkriesel	O
com	O
exemplary	O
problems	B
allow	O
for	O
testing	O
self-coded	O
learning	O
strategies	O
we	O
looked	O
at	O
learning	O
from	O
the	O
formal	O
point	O
of	O
view	O
not	O
much	O
yet	O
but	O
a	O
little	O
now	O
it	O
is	O
time	O
to	O
look	O
at	O
a	O
few	O
exemplary	O
problem	O
you	O
can	O
later	O
use	O
to	O
test	O
implemented	O
networks	O
and	O
learning	O
rules	O
boolean	O
functions	O
table	O
illustration	O
of	O
the	O
parity	O
function	O
with	O
three	O
inputs	O
a	O
popular	O
example	O
is	O
the	O
one	O
that	O
did	O
not	O
work	O
in	O
the	O
nineteen-sixties	O
the	O
xor	O
function	O
we	O
need	O
a	O
hidden	B
neuron	B
layer	O
which	O
we	O
have	O
discussed	O
in	O
detail	O
thus	O
we	O
need	O
at	O
least	O
two	O
neurons	O
in	O
the	O
inner	O
layer	O
let	O
the	O
activation	B
function	I
in	O
all	O
layers	O
in	O
the	O
input	B
layer	O
of	O
course	O
be	O
the	O
hyperbolic	B
tangent	I
trivially	O
we	O
now	O
expect	O
the	O
outputs	O
or	O
depending	O
on	O
whether	O
the	O
function	O
xor	O
outputs	O
or	O
and	O
exactly	O
here	O
is	O
where	O
the	O
first	O
beginner	O
s	O
mistake	O
occurs	O
for	O
outputs	O
close	O
to	O
or	O
i	O
e	O
close	O
to	O
the	O
limits	O
of	O
the	O
hyperbolic	B
tangent	I
in	O
case	O
of	O
the	O
fermi	B
function	I
or	O
we	O
need	O
very	O
large	O
network	O
inputs	O
the	O
only	O
chance	O
to	O
reach	O
these	O
network	O
inputs	O
are	O
large	O
weights	O
which	O
have	O
to	O
be	O
learned	O
the	O
learning	O
process	O
is	O
largely	O
extended	O
therefore	O
it	O
is	O
wiser	O
to	O
enter	O
the	O
teaching	O
inputs	O
or	O
as	O
desired	O
outputs	O
or	O
to	O
be	O
satisfied	O
when	O
the	O
network	O
outputs	O
those	O
values	O
instead	O
of	O
and	O
another	O
favourite	O
example	O
for	O
singlelayer	B
perceptrons	O
are	O
the	O
boolean	O
functions	O
and	O
and	O
or	O
the	O
parity	O
function	O
the	O
parity	O
function	O
maps	O
a	O
set	B
of	I
bits	O
to	O
or	O
depending	O
on	O
whether	O
an	O
even	O
number	O
of	O
input	B
bits	O
is	O
set	O
to	O
or	O
not	O
basically	O
this	O
is	O
the	O
function	O
bn	O
it	O
is	O
characterized	O
by	O
easy	O
learnability	B
up	O
to	O
approx	O
n	O
in	O
table	O
but	O
the	O
learning	O
effort	O
rapidly	O
increases	O
from	O
n	O
the	O
reader	O
may	O
create	O
a	O
score	O
table	O
for	O
the	O
parity	O
function	O
what	O
is	O
conspicuous	O
the	O
problem	O
as	O
a	O
training	O
sample	O
for	O
a	O
function	O
let	O
us	O
take	O
two	O
spirals	O
coiled	O
into	O
each	O
other	O
on	O
the	O
facing	O
page	O
with	O
the	O
function	O
certainly	O
representing	O
a	O
mapping	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
exemplary	O
problems	B
figure	O
illustration	O
of	O
the	O
training	O
samples	O
of	O
the	O
problem	O
figure	O
illustration	O
of	O
training	O
samples	O
for	O
the	O
checkerboard	O
problem	O
one	O
of	O
the	O
spirals	O
is	O
assigned	O
to	O
the	O
output	B
value	O
the	O
other	O
spiral	O
to	O
here	O
memorizing	O
does	O
not	O
help	O
the	O
network	O
has	O
to	O
understand	O
the	O
mapping	O
itself	O
this	O
example	O
can	O
be	O
solved	O
by	O
means	O
of	O
an	O
mlp	O
too	O
the	O
checkerboard	O
problem	O
we	O
again	O
create	O
a	O
two-dimensional	O
function	O
of	O
the	O
form	O
and	O
specify	O
checkered	O
training	O
samples	O
with	O
one	O
colored	O
field	O
representing	O
and	O
all	O
the	O
rest	O
of	O
them	O
representing	O
the	O
difficulty	O
increases	O
proportionally	O
to	O
the	O
size	O
of	O
the	O
function	O
while	O
a	O
field	O
is	O
easy	O
to	O
learn	O
the	O
larger	O
fields	O
are	O
more	O
difficult	O
we	O
eventually	O
use	O
methods	O
that	O
are	O
more	O
suitable	O
for	O
this	O
kind	O
of	O
problems	B
than	O
the	O
mlp	O
the	O
problem	O
is	O
very	O
similar	O
to	O
the	O
checkerboard	O
problem	O
only	O
that	O
mathematically	O
speaking	O
the	O
first	O
problem	O
is	O
using	O
polar	O
coordinates	O
instead	O
of	O
cartesian	O
coordinates	O
i	O
just	O
want	O
to	O
introduce	O
as	O
an	O
example	O
one	O
last	O
trivial	O
case	O
the	O
identity	B
the	O
identity	B
function	O
by	O
using	O
linear	O
activation	B
functions	O
the	O
identity	B
mapping	O
from	O
to	O
course	O
only	O
within	O
the	O
parameters	O
of	O
the	O
used	O
activation	B
function	I
is	O
no	O
problem	O
for	O
the	O
network	O
but	O
we	O
put	O
some	O
obstacles	O
in	O
its	O
way	O
by	O
using	O
our	O
sigmoid	O
functions	O
so	O
that	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
fundamentals	O
on	O
learning	O
and	O
training	O
samples	O
dkriesel	O
com	O
it	O
would	O
be	O
difficult	O
for	O
the	O
network	O
to	O
learn	O
the	O
identity	B
just	O
try	O
it	O
for	O
the	O
fun	O
of	O
it	O
now	O
it	O
is	O
time	O
to	O
hava	O
a	O
look	O
at	O
our	O
first	O
mathematical	O
learning	O
rule	O
there	O
are	O
lots	O
of	O
other	O
exemplary	O
problems	B
for	O
lots	O
and	O
lots	O
of	O
further	O
exemplary	O
problems	B
i	O
want	O
to	O
recommend	O
the	O
technical	O
report	O
written	O
by	O
prechelt	O
which	O
also	O
has	O
been	O
named	O
in	O
the	O
sections	O
about	O
error	O
measurement	O
procedures	O
the	O
hebbian	O
learning	O
rule	O
is	O
the	O
basis	B
for	O
most	O
other	O
learning	O
rules	O
in	O
donald	O
o	O
hebb	O
formulated	O
the	O
hebbian	B
rule	I
which	O
is	O
the	O
basis	B
for	O
most	O
of	O
the	O
more	O
complicated	O
learning	O
rules	O
we	O
will	O
discuss	O
in	O
this	O
text	O
we	O
distinguish	O
between	O
the	O
original	O
form	O
and	O
the	O
more	O
general	O
form	O
which	O
is	O
a	O
kind	O
of	O
principle	O
for	O
other	O
learning	O
rules	O
original	O
rule	O
definition	O
rule	O
neuron	B
j	O
receives	O
an	O
input	B
from	O
neuron	B
i	O
and	O
if	O
both	O
neurons	O
are	O
strongly	O
active	O
at	O
the	O
same	O
time	O
then	O
increase	O
the	O
weight	B
wij	O
the	O
strength	O
of	O
the	O
connection	B
between	O
i	O
and	O
j	O
mathematically	O
speaking	O
the	O
rule	O
is	O
wij	O
oiaj	O
with	O
wij	O
being	O
the	O
change	B
in	I
weight	B
from	O
i	O
to	O
j	O
which	O
is	O
proportional	O
to	O
the	O
wij	O
following	O
factors	O
the	O
output	B
oi	O
of	O
the	O
predecessor	O
neu	O
ron	O
i	O
as	O
well	O
as	O
the	O
activation	B
aj	O
of	O
the	O
successor	O
neu	O
ron	O
j	O
a	O
constant	O
i	O
e	O
the	O
learning	B
rate	I
which	O
will	O
be	O
discussed	O
in	O
section	O
the	O
changes	O
in	O
weight	B
wij	O
are	O
simply	O
added	O
to	O
the	O
weight	B
wij	O
why	O
am	O
i	O
speaking	O
twice	O
about	O
activation	B
but	O
in	O
the	O
formula	O
i	O
am	O
using	O
oi	O
and	O
aj	O
i	O
e	O
the	O
output	B
of	O
neuron	B
of	O
neuron	B
i	O
and	O
the	O
activation	B
of	O
neuron	B
j	O
remember	O
that	O
the	O
identity	B
is	O
often	O
used	O
as	O
output	B
function	I
and	O
therefore	O
ai	O
and	O
oi	O
of	O
a	O
neuron	B
are	O
often	O
the	O
same	O
besides	O
hebb	O
postulated	O
his	O
rule	O
long	O
before	O
the	O
specification	O
of	O
technical	O
neurons	O
considering	O
that	O
this	O
learning	O
rule	O
was	O
preferred	O
in	O
binary	B
activations	O
it	O
is	O
clear	O
that	O
with	O
the	O
possible	O
activations	O
the	O
weights	O
will	O
either	O
increase	O
or	O
remain	O
constant	O
sooner	O
or	O
later	O
they	O
would	O
go	O
ad	O
infinitum	O
since	O
they	O
can	O
only	O
be	O
corrected	O
when	O
an	O
error	O
occurs	O
this	O
can	O
be	O
compensated	O
by	O
using	O
the	O
activations	O
thus	O
the	O
weights	O
are	O
decreased	O
when	O
the	O
activation	B
of	O
the	O
predecessor	O
neuron	B
dissents	O
from	O
the	O
one	O
of	O
the	O
successor	O
neuron	B
otherwise	O
they	O
are	O
increased	O
but	O
that	O
is	O
no	O
longer	O
the	O
version	O
of	O
the	O
hebbian	B
rule	I
weights	O
go	O
ad	O
infinitum	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
early	O
form	O
of	O
the	O
rule	O
dkriesel	O
com	O
hebbian	B
rule	I
generalized	B
form	I
exercises	O
exercise	O
calculate	O
the	O
average	O
value	O
and	O
the	O
standard	O
deviation	O
for	O
the	O
following	O
data	O
points	O
most	O
of	O
the	O
learning	O
rules	O
discussed	O
before	O
are	O
a	O
specialization	O
of	O
the	O
mathematically	O
more	O
general	O
form	O
of	O
the	O
hebbian	B
rule	I
definition	O
rule	O
more	O
general	O
the	O
generalized	B
form	I
of	O
the	O
hebbian	B
rule	I
only	O
specifies	O
the	O
proportionality	O
of	O
the	O
change	B
in	I
weight	B
to	O
the	O
product	O
of	O
two	O
undefined	O
functions	O
but	O
with	O
defined	O
input	B
values	O
wij	O
hoi	O
wij	O
gaj	O
tj	O
thus	O
the	O
product	O
of	O
the	O
functions	O
gaj	O
tj	O
and	O
hoi	O
wij	O
as	O
well	O
as	O
the	O
constant	O
learning	B
rate	I
results	O
in	O
the	O
change	B
in	I
weight	B
as	O
you	O
can	O
see	O
h	O
receives	O
the	O
output	B
of	O
the	O
predecessor	O
cell	O
oi	O
as	O
well	O
as	O
the	O
weight	B
from	O
predecessor	O
to	O
successor	O
wij	O
while	O
g	O
expects	O
the	O
actual	O
and	O
desired	O
activation	B
of	O
the	O
successor	O
aj	O
and	O
tj	O
t	O
stands	O
for	O
the	O
aforementioned	O
teaching	B
input	B
as	O
already	O
mentioned	O
g	O
and	O
h	O
are	O
not	O
specified	O
in	O
this	O
general	O
definition	O
therefore	O
we	O
will	O
now	O
return	B
to	O
the	O
path	O
of	O
specialization	O
we	O
discussed	O
before	O
equation	O
after	O
we	O
have	O
had	O
a	O
short	O
picture	O
of	O
what	O
a	O
learning	O
rule	O
could	O
look	O
like	O
and	O
of	O
our	O
thoughts	O
about	O
learning	O
itself	O
we	O
will	O
be	O
introduced	O
to	O
our	O
first	O
network	O
paradigm	O
including	O
the	O
learning	O
procedure	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
part	O
ii	O
supervised	B
learning	O
network	O
paradigms	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
a	O
classic	O
among	O
the	O
neural	O
networks	O
if	O
we	O
talk	O
about	O
a	O
neural	B
network	I
then	O
in	O
the	O
majority	O
of	O
cases	O
we	O
speak	O
about	O
a	O
percepton	O
or	O
a	O
variation	O
of	O
it	O
perceptrons	O
are	O
multilayer	B
networks	O
without	O
recurrence	B
and	O
with	O
fixed	O
input	B
and	O
output	B
layers	O
description	O
of	O
a	O
perceptron	B
its	O
limits	O
and	O
extensions	O
that	O
should	O
avoid	O
the	O
limitations	O
derivation	O
of	O
learning	O
procedures	O
and	O
discussion	O
of	O
their	O
problems	B
as	O
already	O
mentioned	O
in	O
the	O
history	O
of	O
neural	O
networks	O
the	O
perceptron	B
was	O
described	O
by	O
frank	O
rosenblatt	O
in	O
initially	O
rosenblatt	O
defined	O
the	O
already	O
discussed	O
weighted	B
sum	I
and	O
a	O
non-linear	O
activation	B
function	I
as	O
components	O
of	O
the	O
perceptron	B
there	O
is	O
no	O
established	O
definition	O
for	O
a	O
perceptron	B
but	O
most	O
of	O
the	O
time	O
the	O
term	O
is	O
used	O
to	O
describe	O
a	O
feedforward	B
network	O
with	O
shortcut	B
connections	I
this	O
network	O
has	O
a	O
layer	O
of	O
scanner	O
neurons	O
with	O
statically	O
weighted	O
connections	O
to	O
the	O
following	O
layer	O
and	O
is	O
called	O
input	B
layer	O
on	O
the	O
next	O
page	O
but	O
the	O
weights	O
of	O
all	O
other	O
layers	O
are	O
allowed	O
to	O
be	O
changed	O
all	O
neurons	O
subordinate	O
to	O
the	O
retina	B
are	O
pattern	O
detectors	O
here	O
we	O
initially	O
use	O
a	O
binary	B
perceptron	B
with	O
every	O
output	B
neuron	B
having	O
exactly	O
two	O
possi	O
ble	O
output	B
values	O
or	O
thus	O
a	O
binary	B
threshold	I
function	I
is	O
used	O
as	O
activation	B
function	I
depending	O
on	O
the	O
threshold	B
value	I
of	O
the	O
output	B
neuron	B
in	O
a	O
way	O
the	O
binary	B
activation	B
function	I
represents	O
an	O
if	O
query	O
which	O
can	O
also	O
be	O
negated	O
by	O
means	O
of	O
negative	O
weights	O
the	O
perceptron	B
can	O
thus	O
be	O
used	O
to	O
accomplish	O
true	O
logical	O
information	B
processing	I
whether	O
this	O
method	O
is	O
reasonable	O
is	O
another	O
matter	O
of	O
course	O
this	O
is	O
not	O
the	O
easiest	O
way	O
to	O
achieve	O
boolean	O
logic	O
i	O
just	O
want	O
to	O
illustrate	O
that	O
perceptrons	O
can	O
be	O
used	O
as	O
simple	O
logical	O
components	O
and	O
that	O
theoretically	O
speaking	O
any	O
boolean	O
function	O
can	O
be	O
realized	O
by	O
means	O
of	O
perceptrons	O
being	O
connected	O
in	O
series	O
or	O
interconnected	O
in	O
a	O
sophisticated	O
way	O
but	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
figure	O
architecture	O
of	O
a	O
perceptron	B
with	O
one	O
layer	O
of	O
variable	B
connections	O
in	O
different	O
views	O
the	O
solid-drawn	O
weight	B
layer	O
in	O
the	O
two	O
illustrations	O
on	O
the	O
bottom	O
can	O
be	O
trained	O
left	O
side	O
example	O
of	O
scanning	O
information	O
in	O
the	O
eye	O
right	O
side	O
upper	O
part	O
drawing	O
of	O
the	O
same	O
example	O
with	O
indicated	O
fixed-weight	O
layer	O
using	O
the	O
defined	O
designs	O
of	O
the	O
functional	O
descriptions	O
for	O
neurons	O
right	O
side	O
lower	O
part	O
without	O
indicated	O
fixed-weight	O
layer	O
with	O
the	O
name	O
of	O
each	O
neuron	B
corresponding	O
to	O
our	O
convention	O
the	O
fixed-weight	O
layer	O
will	O
no	O
longer	O
be	O
taken	O
into	O
account	O
in	O
the	O
course	O
of	O
this	O
work	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
einkleiner	O
uberblick	O
uberneuronalenetzeepsilon-de	O
input	B
neuron	B
only	O
forwards	O
data	O
dkriesel	O
com	O
we	O
will	O
see	O
that	O
this	O
is	O
not	O
possible	O
without	O
connecting	O
them	O
serially	O
before	O
providing	O
the	O
definition	O
of	O
the	O
perceptron	B
i	O
want	O
to	O
define	O
some	O
types	O
of	O
neurons	O
used	O
in	O
this	O
chapter	O
definition	O
neuron	B
an	O
input	B
neuron	B
is	O
an	O
identity	B
neuron	B
it	O
exactly	O
forwards	O
the	O
information	O
received	O
thus	O
it	O
represents	O
the	O
identity	B
function	O
which	O
should	O
be	O
indicated	O
by	O
the	O
symbol	O
therefore	O
the	O
input	B
neuron	B
is	O
repre	O
sented	O
by	O
the	O
symbolgfed	O
definition	O
processing	O
neuron	B
information	B
processing	I
neurons	O
somehow	O
process	O
the	O
input	B
information	O
i	O
e	O
do	O
not	O
represent	O
the	O
identity	B
function	O
a	O
binary	B
neuron	B
sums	O
up	O
all	O
inputs	O
by	O
using	O
the	O
weighted	B
sum	I
as	O
propagation	B
function	I
which	O
we	O
want	O
to	O
illustrate	O
by	O
the	O
sign	O
then	O
the	O
activation	B
function	I
of	O
the	O
neuron	B
is	O
the	O
binary	B
threshold	I
function	I
which	O
can	O
be	O
illustrated	O
by	O
lh	O
this	O
leads	O
us	O
to	O
the	O
complete	O
depiction	O
of	O
information	B
processing	I
neurons	O
lh	O
other	O
neurons	O
that	O
use	O
the	O
weighted	B
sum	I
as	O
propagation	B
function	I
but	O
the	O
activation	B
functions	O
hyperbolic	B
tangent	I
or	O
fermi	B
function	I
or	O
with	O
a	O
separately	O
defined	O
activation	B
function	I
fact	O
are	O
similarly	O
represented	O
by	O
namely	O
wvut	O
pqrs	O
these	O
neurons	O
are	O
also	O
referred	O
to	O
as	O
fermi	B
neurons	O
or	O
tanh	B
neuron	B
wvut	O
pqrs	O
tanh	B
wvut	O
pqrs	O
fermi	B
onml	O
hijk	O
fact	O
now	O
that	O
we	O
know	O
the	O
components	O
of	O
a	O
perceptron	B
we	O
should	O
be	O
able	O
to	O
define	O
it	O
definition	O
the	O
perceptron	B
on	O
the	O
facing	O
page	O
a	O
feedforward	B
network	O
containing	O
a	O
retina	B
that	O
is	O
used	O
only	O
for	O
data	O
acquisition	O
and	O
which	O
has	O
fixed-weighted	O
connections	O
with	O
the	O
first	O
neuron	B
layer	O
layer	O
the	O
fixed-weight	O
layer	O
is	O
followed	O
by	O
at	O
least	O
one	O
trainable	O
weight	B
layer	O
one	O
neuron	B
layer	O
is	O
completely	O
linked	O
with	O
the	O
following	O
layer	O
the	O
first	O
layer	O
of	O
the	O
perceptron	B
consists	O
of	O
the	O
input	B
neurons	O
defined	O
above	O
a	O
feedforward	B
network	O
often	O
contains	O
shortcuts	O
which	O
does	O
not	O
exactly	O
correspond	O
to	O
the	O
original	O
description	O
and	O
therefore	O
is	O
not	O
included	O
in	O
the	O
definition	O
we	O
can	O
see	O
that	O
the	O
retina	B
is	O
not	O
included	O
in	O
the	O
lower	O
part	O
of	O
fig	O
as	O
a	O
matter	O
of	O
fact	O
the	O
first	O
neuron	B
layer	O
is	O
often	O
understood	O
and	O
sufficient	O
for	O
this	O
method	O
as	O
input	B
layer	O
because	O
this	O
layer	O
only	O
forwards	O
the	O
input	B
values	O
the	O
retina	B
itself	O
and	O
the	O
static	O
weights	O
behind	O
it	O
are	O
no	O
longer	O
mentioned	O
or	O
displayed	O
since	O
they	O
do	O
not	O
process	O
information	O
in	O
any	O
case	O
so	O
the	O
depiction	O
of	O
a	O
perceptron	B
starts	O
with	O
the	O
input	B
neurons	O
it	O
may	O
confuse	O
some	O
readers	O
that	O
i	O
claim	O
that	O
there	O
is	O
no	O
definition	O
of	O
a	O
perceptron	B
but	O
then	O
define	O
the	O
perceptron	B
in	O
the	O
following	O
section	O
i	O
therefore	O
suggest	O
keeping	O
my	O
definition	O
in	O
the	O
back	O
of	O
your	O
mind	O
and	O
just	O
take	O
it	O
for	O
granted	O
in	O
the	O
course	O
of	O
this	O
work	O
retina	B
is	O
unconsidered	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
the	O
methods	O
snipe	O
setsettingstopologyfeedforward	O
and	O
the	O
variation	O
in	O
neuralnetworkdescriptor-instance	O
a	O
apply	O
settings	O
to	O
a	O
descriptor	O
which	O
are	O
appropriate	O
for	O
feedforward	B
networks	O
or	O
feedforward	B
networks	O
with	O
shortcuts	O
the	O
respective	O
kinds	O
of	O
connections	O
are	O
allowed	O
all	O
others	O
are	O
not	O
and	O
fastprop	B
is	O
activated	O
the	O
singlelayer	B
perceptron	B
provides	O
only	O
one	O
trainable	O
weight	B
layer	O
trainable	O
here	O
connections	O
with	O
trainable	O
weights	O
go	O
from	O
the	O
input	B
layer	O
to	O
an	O
output	B
neuron	B
which	O
returns	O
the	O
information	O
layer	O
whether	O
the	O
pattern	O
entered	O
at	O
the	O
input	B
neurons	O
was	O
recognized	O
or	O
not	O
thus	O
a	O
singlelayer	B
perception	O
slp	O
has	O
only	O
one	O
level	O
of	O
trainable	O
weights	O
on	O
page	O
definition	O
perceptron	B
a	O
singlelayer	B
perceptron	B
is	O
a	O
perceptron	B
having	O
only	O
one	O
layer	O
of	O
variable	B
weights	O
and	O
one	O
layer	O
of	O
output	B
neurons	O
the	O
technical	O
view	O
of	O
an	O
slp	O
is	O
shown	O
in	O
fig	O
important	O
certainly	O
the	O
existence	O
of	O
several	O
output	B
neurons	O
n	O
does	O
not	O
considerably	O
change	O
the	O
concept	O
of	O
the	O
perceptron	B
a	O
perceptron	B
with	O
several	O
output	B
neurons	O
can	O
also	O
be	O
regarded	O
as	O
several	O
different	O
perceptrons	O
with	O
the	O
same	O
input	B
bias	O
gfed	O
wbias	O
gfed	O
gfed	O
figure	O
a	O
singlelayer	B
perceptron	B
with	O
two	O
input	B
neurons	O
and	O
one	O
output	B
neuron	B
the	O
network	O
returns	O
the	O
output	B
by	O
means	O
of	O
the	O
arrow	O
leaving	O
the	O
network	O
the	O
trainable	O
layer	O
of	O
weights	O
is	O
situated	O
in	O
the	O
center	O
as	O
a	O
reminder	O
the	O
bias	B
neuron	B
is	O
again	O
included	O
here	O
although	O
the	O
weight	B
wbias	O
is	O
a	O
normal	O
weight	B
and	O
also	O
treated	O
like	O
this	O
i	O
have	O
represented	O
it	O
by	O
a	O
dotted	O
line	O
which	O
significantly	O
increases	O
the	O
clarity	O
of	O
larger	O
networks	O
in	O
future	O
the	O
bias	B
neuron	B
will	O
no	O
longer	O
be	O
included	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
vnnnnnnnnnnnnnnnnnn	O
wnnnnnnnnnnnnnnnnn	O
aaaaaaaaa	O
aaaaaaaaa	O
gfed	O
gfed	O
gfed	O
figure	O
singlelayer	B
perceptron	B
with	O
several	O
output	B
neurons	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
v	O
t	O
w	O
dkriesel	O
com	O
the	O
singlelayer	B
perceptron	B
gfed	O
gfed	O
gfed	O
aaaa	O
gfed	O
aaaa	O
aaaa	O
gfed	O
aaaa	O
gfed	O
figure	O
two	O
singlelayer	B
perceptrons	O
for	O
boolean	O
functions	O
the	O
upper	O
singlelayer	B
perceptron	B
realizes	O
an	O
and	O
the	O
lower	O
one	O
realizes	O
an	O
or	O
the	O
activation	B
function	I
of	O
the	O
information	B
processing	I
neuron	B
is	O
the	O
binary	B
threshold	I
function	I
where	O
available	O
the	O
threshold	O
values	O
are	O
written	O
into	O
the	O
neurons	O
the	O
boolean	O
functions	O
and	O
and	O
or	O
shown	O
in	O
fig	O
are	O
trivial	O
examples	O
that	O
can	O
easily	O
be	O
composed	O
now	O
we	O
want	O
to	O
know	O
how	O
to	O
train	O
a	O
singlelayer	B
perceptron	B
we	O
will	O
therefore	O
at	O
first	O
take	O
a	O
look	O
at	O
the	O
perceptron	B
learning	I
algorithm	B
and	O
then	O
we	O
will	O
look	O
at	O
the	O
delta	B
rule	I
perceptron	B
learning	I
algorithm	B
and	O
convergence	O
theorem	O
the	O
original	O
perceptron	B
learning	I
algorithm	B
with	O
binary	B
neuron	B
activation	B
function	I
is	O
described	O
in	O
alg	O
it	O
has	O
been	O
proven	O
that	O
the	O
algorithm	B
converges	O
in	O
finite	O
time	O
so	O
in	O
finite	O
time	O
the	O
perceptron	B
can	O
learn	O
anything	O
it	O
can	O
represent	O
convergence	O
theorem	O
but	O
please	O
do	O
not	O
get	O
your	O
hopes	O
up	O
too	O
soon	O
what	O
the	O
perceptron	B
is	O
capable	O
to	O
represent	O
will	O
be	O
explored	O
later	O
during	O
the	O
exploration	O
of	O
linear	B
separability	I
of	O
problems	B
we	O
will	O
cover	O
the	O
fact	O
that	O
at	O
least	O
the	O
singlelayer	B
perceptron	B
unfortunately	O
cannot	O
represent	O
a	O
lot	O
of	O
problems	B
the	O
delta	B
rule	I
as	O
a	O
gradient	B
based	O
learning	B
strategy	I
for	O
slps	O
in	O
the	O
following	O
we	O
deviate	O
from	O
our	O
binary	B
threshold	B
value	I
as	O
activation	B
function	I
because	O
at	O
least	O
for	O
backpropagation	B
of	I
error	I
we	O
need	O
as	O
you	O
will	O
see	O
a	O
differentiable	O
or	O
even	O
a	O
semi-linear	O
activation	B
function	I
for	O
the	O
now	O
following	O
delta	B
rule	I
backpropagation	B
derived	O
in	O
it	O
is	O
not	O
always	O
necessary	O
but	O
useful	O
this	O
fact	O
however	O
will	O
also	O
be	O
pointed	O
out	O
in	O
the	O
appropriate	O
part	O
of	O
this	O
work	O
compared	O
with	O
the	O
aforementioned	O
perceptron	B
learning	I
algorithm	B
the	O
delta	B
rule	I
has	O
the	O
advantage	O
to	O
be	O
suitable	O
for	O
non-binary	O
activation	B
functions	O
and	O
being	O
far	O
away	O
from	O
fact	O
now	O
differentiable	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
if	O
y	O
t	O
then	O
else	O
output	B
is	O
okay	O
no	O
correction	O
of	O
weights	O
end	O
for	O
end	O
if	O
if	O
y	O
then	O
for	O
all	O
input	B
neurons	O
i	O
do	O
wi	O
wi	O
oi	O
weight	B
towards	O
by	O
oi	O
input	B
p	O
into	O
the	O
network	O
calculate	O
output	B
y	O
set	B
of	I
training	O
patterns	O
for	O
all	O
output	B
neurons	O
do	O
while	O
p	O
p	O
and	O
error	O
too	O
large	O
do	O
end	O
if	O
end	O
for	O
end	O
while	O
algorithm	B
perceptron	B
learning	I
algorithm	B
the	O
perceptron	B
learning	I
algorithm	B
reduces	O
the	O
weights	O
to	O
output	B
neurons	O
that	O
return	B
instead	O
of	O
and	O
in	O
the	O
inverse	O
case	O
increases	O
weights	O
wi	O
wi	O
oi	O
weight	B
towards	O
by	O
oi	O
end	O
for	O
end	O
if	O
if	O
y	O
then	O
for	O
all	O
input	B
neurons	O
i	O
do	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
singlelayer	B
perceptron	B
the	O
learning	O
target	B
to	O
automatically	O
learn	O
faster	O
suppose	O
that	O
we	O
have	O
a	O
singlelayer	B
perceptron	B
with	O
randomly	O
set	O
weights	O
which	O
we	O
want	O
to	O
teach	O
a	O
function	O
by	O
means	O
of	O
training	O
samples	O
the	O
set	B
of	I
these	O
training	O
samples	O
is	O
called	O
p	O
it	O
contains	O
as	O
already	O
defined	O
the	O
pairs	O
t	O
of	O
the	O
training	O
samples	O
p	O
and	O
the	O
associated	O
teaching	B
input	B
t	O
i	O
also	O
want	O
to	O
remind	O
you	O
that	O
x	O
is	O
the	O
input	B
vector	I
and	O
y	O
is	O
the	O
output	B
vector	I
of	O
a	O
neural	O
net	O
work	O
output	B
neurons	O
are	O
referred	O
to	O
as	O
i	O
is	O
the	O
input	B
and	O
o	O
is	O
the	O
output	B
of	O
a	O
neuron	B
additionally	O
we	O
defined	O
that	O
the	O
error	B
vector	I
ep	O
represents	O
the	O
difference	O
y	O
under	O
a	O
certain	O
training	O
sample	O
p	O
furthermore	O
let	O
o	O
be	O
the	O
set	B
of	I
out	O
put	O
neurons	O
and	O
i	O
be	O
the	O
set	B
of	I
input	B
neurons	O
another	O
naming	O
convention	O
shall	O
be	O
that	O
for	O
example	O
for	O
an	O
output	B
o	O
and	O
a	O
teaching	B
input	B
t	O
an	O
additional	O
index	O
p	O
may	O
be	O
set	O
in	O
order	O
to	O
indicate	O
that	O
these	O
values	O
are	O
pattern-specific	O
sometimes	O
this	O
will	O
considerably	O
enhance	O
clarity	O
now	O
our	O
learning	O
target	B
will	O
certainly	O
be	O
that	O
for	O
all	O
training	O
samples	O
the	O
output	B
y	O
of	O
the	O
network	O
is	O
approximately	O
the	O
desired	O
output	B
t	O
formally	O
it	O
is	O
true	O
that	O
i	O
e	O
p	O
y	O
t	O
or	O
p	O
ep	O
this	O
means	O
we	O
first	O
have	O
to	O
understand	O
the	O
total	B
error	O
err	O
as	O
a	O
function	O
of	O
the	O
weights	O
the	O
total	B
error	O
increases	O
or	O
decreases	O
depending	O
on	O
how	O
we	O
change	O
the	O
weights	O
definition	O
function	O
the	O
error	B
function	I
err	O
w	O
r	O
regards	O
the	O
of	O
weights	O
w	O
as	O
a	O
vector	O
and	O
maps	O
the	O
values	O
onto	O
the	O
normalized	O
output	B
error	O
because	O
otherwise	O
not	O
all	O
errors	O
can	O
be	O
mapped	O
onto	O
one	O
single	O
e	O
r	O
to	O
perform	O
a	O
gradient	B
descent	I
it	O
is	O
obvious	O
that	O
a	O
specific	B
error	B
function	I
can	O
analogously	O
be	O
generated	O
for	O
a	O
single	O
pattern	O
p	O
error	O
as	O
function	O
as	O
already	O
shown	O
in	O
section	O
gradient	B
descent	I
procedures	O
calculate	O
the	O
gradient	B
of	O
an	O
arbitrary	O
but	O
finite-dimensional	O
function	O
of	O
the	O
error	B
function	I
errw	O
and	O
move	O
down	O
against	O
the	O
direction	O
of	O
the	O
gradient	B
until	O
a	O
minimum	O
is	O
reached	O
errw	O
is	O
defined	O
on	O
the	O
set	B
of	I
all	O
weights	O
which	O
we	O
here	O
regard	O
as	O
the	O
vector	O
w	O
so	O
we	O
try	O
to	O
decrease	O
or	O
to	O
minimize	O
the	O
error	O
by	O
simply	O
tweaking	O
the	O
weights	O
thus	O
one	O
receives	O
information	O
about	O
how	O
to	O
change	O
the	O
weights	O
change	O
in	O
all	O
following	O
the	O
tradition	O
of	O
the	O
literature	O
i	O
previously	O
defined	O
w	O
as	O
a	O
weight	B
matrix	I
i	O
am	O
aware	O
of	O
this	O
conflict	O
but	O
it	O
should	O
not	O
bother	O
us	O
here	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
thus	O
we	O
tweak	O
every	O
single	O
weight	B
and	O
observe	O
how	O
the	O
error	B
function	I
changes	O
i	O
e	O
we	O
derive	O
the	O
error	B
function	I
according	O
to	O
a	O
weight	B
wi	O
and	O
obtain	O
the	O
value	O
wi	O
of	O
how	O
to	O
change	O
this	O
weight	B
wi	O
errw	O
wi	O
now	O
the	O
following	O
question	O
arises	O
how	O
is	O
our	O
error	B
function	I
defined	O
exactly	O
it	O
is	O
not	O
good	O
if	O
many	O
results	O
are	O
far	O
away	O
from	O
the	O
desired	O
ones	O
the	O
error	B
function	I
should	O
then	O
provide	O
large	O
values	O
on	O
the	O
other	O
hand	O
it	O
is	O
similarly	O
bad	O
if	O
many	O
results	O
are	O
close	O
to	O
the	O
desired	O
ones	O
but	O
there	O
exists	O
an	O
extremely	O
far	O
outlying	O
result	O
the	O
squared	B
distance	O
between	O
the	O
output	B
vector	I
y	O
and	O
the	O
teaching	B
input	B
t	O
appears	O
adequate	O
to	O
our	O
needs	O
it	O
provides	O
the	O
error	O
errp	O
that	O
is	O
specific	B
for	O
a	O
training	O
sample	O
p	O
over	O
the	O
output	B
of	O
all	O
output	B
neurons	O
errpw	O
x	O
o	O
yp	O
figure	O
exemplary	O
error	O
surface	O
of	O
a	O
neural	B
network	I
with	O
two	O
trainable	O
connections	O
und	O
generally	O
neural	O
networks	O
have	O
more	O
than	O
two	O
connections	O
but	O
this	O
would	O
have	O
made	O
the	O
illustration	O
too	O
complex	O
and	O
most	O
of	O
the	O
time	O
the	O
error	O
surface	O
is	O
too	O
craggy	O
which	O
complicates	O
the	O
search	O
for	O
the	O
minimum	O
weights	O
is	O
referred	O
to	O
as	O
w	O
by	O
calculating	O
the	O
gradient	B
errw	O
of	O
the	O
error	B
function	I
errw	O
w	O
errw	O
due	O
to	O
this	O
relation	O
there	O
is	O
a	O
proportionality	O
constant	O
for	O
which	O
equality	O
holds	O
will	O
soon	O
get	O
another	O
meaning	O
and	O
a	O
real	O
practical	O
use	O
beyond	O
the	O
mere	O
meaning	O
of	O
a	O
proportionality	O
constant	O
i	O
just	O
ask	O
the	O
reader	O
to	O
be	O
patient	O
for	O
a	O
while	O
w	O
errw	O
to	O
simplify	O
further	O
analysis	O
we	O
now	O
rewrite	O
the	O
gradient	B
of	O
the	O
error-function	O
according	O
to	O
all	O
weights	O
as	O
an	O
usual	O
partial	O
derivative	O
according	O
to	O
a	O
single	O
weight	B
wi	O
only	O
variable	B
weights	O
exists	O
between	O
the	O
hidden	B
and	O
the	O
output	B
layer	O
thus	O
we	O
calculate	O
the	O
squared	B
difference	O
of	O
the	O
components	O
of	O
the	O
vectors	O
t	O
and	O
y	O
given	O
the	O
pattern	O
p	O
and	O
sum	O
up	O
these	O
squares	O
the	O
summation	O
of	O
the	O
specific	B
errors	O
errpw	O
of	O
all	O
patterns	O
p	O
then	O
yields	O
the	O
definition	O
of	O
the	O
error	O
err	O
and	O
there	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
singlelayer	B
perceptron	B
fore	O
the	O
definition	O
of	O
the	O
error	B
function	I
errw	O
results	O
from	O
the	O
sum	O
of	O
the	O
specific	B
errors	O
errpw	O
sum	O
over	O
all	O
p	O
x	O
o	O
yp	O
sum	O
over	O
all	O
errw	O
x	O
z	O
x	O
p	O
p	O
p	O
p	O
the	O
observant	O
reader	O
will	O
certainly	O
wonder	O
where	O
the	O
factor	O
in	O
equation	O
on	O
the	O
preceding	O
page	O
suddenly	O
came	O
from	O
and	O
why	O
there	O
is	O
no	O
root	O
in	O
the	O
equation	O
as	O
this	O
formula	O
looks	O
very	O
similar	O
to	O
the	O
euclidean	B
distance	O
both	O
facts	O
result	O
from	O
simple	O
pragmatics	O
our	O
intention	O
is	O
to	O
minimize	O
the	O
error	O
because	O
the	O
root	O
function	O
decreases	O
with	O
its	O
argument	O
we	O
can	O
simply	O
omit	O
it	O
for	O
reasons	O
of	O
calculation	O
and	O
implementation	O
efforts	O
since	O
we	O
do	O
not	O
need	O
it	O
for	O
minimization	O
similarly	O
it	O
does	O
not	O
matter	O
if	O
the	O
term	O
to	O
be	O
minimized	O
is	O
divided	O
by	O
therefore	O
i	O
am	O
allowed	O
to	O
multiply	O
by	O
this	O
is	O
just	O
done	O
so	O
that	O
it	O
cancels	O
with	O
a	O
in	O
the	O
course	O
of	O
our	O
calculation	O
now	O
we	O
want	O
to	O
continue	O
deriving	O
the	O
delta	B
rule	I
for	O
linear	O
activation	B
functions	O
we	O
have	O
already	O
discussed	O
that	O
we	O
tweak	O
the	O
individual	O
weights	O
wi	O
a	O
bit	O
and	O
see	O
how	O
the	O
error	O
errw	O
is	O
changing	O
which	O
corresponds	O
to	O
the	O
derivative	O
of	O
the	O
error	B
function	I
errw	O
according	O
to	O
the	O
very	O
same	O
weight	B
wi	O
this	O
derivative	O
corresponds	O
to	O
the	O
sum	O
of	O
the	O
derivatives	O
of	O
all	O
specific	B
errors	O
errp	O
according	O
to	O
this	O
weight	B
the	O
total	B
error	O
errw	O
wi	O
x	O
p	O
p	O
errw	O
wi	O
errpw	O
wi	O
once	O
again	O
i	O
want	O
to	O
think	O
about	O
the	O
question	O
of	O
how	O
a	O
neural	B
network	I
processes	O
data	O
basically	O
the	O
data	O
is	O
only	O
transferred	O
through	O
a	O
function	O
the	O
result	O
of	O
the	O
function	O
is	O
sent	O
through	O
another	O
one	O
and	O
so	O
on	O
if	O
we	O
ignore	O
the	O
output	B
function	I
the	O
path	O
of	O
the	O
neuron	B
outputs	O
and	O
which	O
the	O
neurons	O
and	O
entered	O
into	O
a	O
neuron	B
initially	O
is	O
the	O
propagation	B
function	I
weighted	B
sum	I
from	O
which	O
the	O
network	B
input	B
is	O
going	O
to	O
be	O
received	O
this	O
is	O
then	O
sent	O
through	O
the	O
activation	B
function	I
of	O
the	O
neuron	B
so	O
that	O
we	O
receive	O
the	O
output	B
of	O
this	O
neuron	B
which	O
is	O
at	O
the	O
same	O
time	O
a	O
component	O
of	O
the	O
output	B
vector	I
y	O
net	O
fact	O
factnet	O
o	O
y	O
as	O
we	O
can	O
see	O
this	O
output	B
results	O
from	O
many	O
nested	O
functions	O
o	O
factnet	O
it	O
is	O
clear	O
that	O
we	O
could	O
break	O
down	O
the	O
output	B
into	O
the	O
single	O
input	B
neurons	O
is	O
unnecessary	O
here	O
since	O
they	O
do	O
not	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
process	O
information	O
in	O
an	O
slp	O
thus	O
we	O
want	O
to	O
calculate	O
the	O
derivatives	O
of	O
equation	O
on	O
the	O
preceding	O
page	O
and	O
due	O
to	O
the	O
nested	O
functions	O
we	O
can	O
apply	O
the	O
chain	O
rule	O
to	O
factorize	O
the	O
derivative	O
errpw	O
in	O
equation	O
on	O
the	O
previous	O
wi	O
page	O
errpw	O
wi	O
errpw	O
op	O
op	O
wi	O
i	O
e	O
let	O
us	O
take	O
a	O
look	O
at	O
the	O
first	O
multiplicative	O
factor	O
of	O
the	O
above	O
equation	O
which	O
represents	O
the	O
derivative	O
of	O
the	O
specific	B
error	O
errpw	O
according	O
to	O
the	O
output	B
the	O
change	O
of	O
the	O
error	O
errp	O
with	O
an	O
output	B
op	O
the	O
examination	O
of	O
errp	O
on	O
page	O
clearly	O
shows	O
that	O
this	O
change	O
is	O
exactly	O
the	O
difference	O
between	O
teaching	B
input	B
and	O
output	B
op	O
since	O
is	O
an	O
output	B
neuron	B
op	O
yp	O
the	O
closer	O
the	O
output	B
is	O
to	O
the	O
teaching	B
input	B
the	O
smaller	O
is	O
the	O
specific	B
error	O
thus	O
we	O
can	O
replace	O
one	O
by	O
the	O
other	O
this	O
difference	O
is	O
also	O
called	O
p	O
is	O
the	O
reason	O
for	O
the	O
name	O
delta	B
rule	I
errpw	O
wi	O
op	O
op	O
wi	O
p	O
op	O
wi	O
the	O
second	O
multiplicative	O
factor	O
of	O
equation	O
and	O
of	O
the	O
following	O
one	O
is	O
the	O
derivative	O
of	O
the	O
output	B
specific	B
to	O
the	O
pattern	O
p	O
of	O
the	O
neuron	B
according	O
to	O
the	O
weight	B
wi	O
so	O
how	O
does	O
op	O
change	O
when	O
the	O
weight	B
from	O
i	O
to	O
is	O
changed	O
errpw	O
wi	O
i	O
iopiwi	O
wi	O
due	O
to	O
the	O
requirement	O
at	O
the	O
beginning	O
of	O
the	O
derivation	O
we	O
only	O
have	O
a	O
linear	O
activation	B
function	I
fact	O
therefore	O
we	O
can	O
just	O
as	O
well	O
look	O
at	O
the	O
change	O
of	O
the	O
network	B
input	B
when	O
wi	O
is	O
changing	O
p	O
p	O
the	O
resulting	O
derivative	O
p	O
p	O
p	O
i	O
iopiwi	O
wi	O
can	O
now	O
be	O
simplified	O
the	O
function	O
i	O
iopiwi	O
to	O
be	O
derived	O
consists	O
of	O
many	O
summands	O
and	O
only	O
the	O
summand	O
opiwi	O
contains	O
the	O
variable	B
wi	O
according	O
to	O
which	O
we	O
derive	O
thus	O
i	O
iopiwi	O
wi	O
opi	O
and	O
therefore	O
errpw	O
wi	O
p	O
opi	O
opi	O
p	O
we	O
insert	O
this	O
in	O
equation	O
on	O
the	O
previous	O
page	O
which	O
results	O
in	O
our	O
modification	O
rule	O
for	O
a	O
weight	B
wi	O
opi	O
p	O
wi	O
x	O
p	O
p	O
however	O
from	O
the	O
very	O
beginning	O
the	O
derivation	O
has	O
been	O
intended	O
as	O
an	O
o	O
ine	O
rule	O
by	O
means	O
of	O
the	O
question	O
of	O
how	O
to	O
add	O
the	O
errors	O
of	O
all	O
patterns	O
and	O
how	O
to	O
learn	O
them	O
after	O
all	O
patterns	O
have	O
been	O
represented	O
although	O
this	O
approach	O
is	O
mathematically	O
correct	O
the	O
implementation	O
is	O
far	O
more	O
time-consuming	O
and	O
as	O
we	O
will	O
see	O
later	O
in	O
this	O
chapter	O
partially	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
linear	B
separability	I
needs	O
a	O
lot	O
of	O
compuational	O
effort	O
during	O
training	O
the	O
version	O
of	O
the	O
delta	B
rule	I
simply	O
omits	O
the	O
summation	O
and	O
learning	O
is	O
realized	O
immediately	O
after	O
the	O
presentation	O
of	O
each	O
pattern	O
this	O
also	O
simplifies	O
the	O
notation	O
is	O
no	O
longer	O
necessarily	O
related	O
to	O
a	O
pattern	O
p	O
wi	O
oi	O
this	O
version	O
of	O
the	O
delta	B
rule	I
shall	O
be	O
used	O
for	O
the	O
following	O
definition	O
definition	O
rule	O
if	O
we	O
determine	O
analogously	O
to	O
the	O
aforementioned	O
derivation	O
that	O
the	O
function	O
h	O
of	O
the	O
hebbian	O
theory	O
on	O
page	O
only	O
provides	O
the	O
output	B
oi	O
of	O
the	O
predecessor	O
neuron	B
i	O
and	O
if	O
the	O
function	O
g	O
is	O
the	O
difference	O
between	O
the	O
desired	O
activation	B
t	O
and	O
the	O
actual	O
activation	B
a	O
we	O
will	O
receive	O
the	O
delta	B
rule	I
also	O
known	O
as	O
widrowhoff	O
rule	O
wi	O
oi	O
a	O
oi	O
if	O
we	O
use	O
the	O
desired	O
output	B
of	O
the	O
activation	B
as	O
teaching	B
input	B
and	O
therefore	O
the	O
output	B
function	I
of	O
the	O
output	B
neurons	O
does	O
not	O
represent	O
an	O
identity	B
we	O
obtain	O
wi	O
oi	O
o	O
oi	O
and	O
then	O
corresponds	O
to	O
the	O
difference	O
between	O
t	O
and	O
o	O
in	O
the	O
case	O
of	O
the	O
delta	B
rule	I
the	O
change	O
of	O
all	O
weights	O
to	O
an	O
output	B
neuron	B
is	O
proportional	O
in	O
in	O
output	B
table	O
definition	O
of	O
the	O
logical	O
xor	O
the	O
input	B
values	O
are	O
shown	O
of	O
the	O
left	O
the	O
output	B
values	O
on	O
the	O
right	O
to	O
the	O
difference	O
between	O
the	O
current	O
activation	B
or	O
output	B
a	O
or	O
o	O
and	O
the	O
corresponding	O
teaching	B
input	B
t	O
we	O
want	O
to	O
refer	O
to	O
this	O
factor	O
as	O
which	O
is	O
also	O
referred	O
to	O
as	O
apparently	O
the	O
delta	B
rule	I
only	O
applies	O
for	O
slps	O
since	O
the	O
formula	O
is	O
always	O
related	O
to	O
the	O
teaching	B
input	B
and	O
there	O
is	O
no	O
teaching	B
input	B
for	O
the	O
inner	O
processing	O
layers	O
of	O
neurons	O
delta	B
rule	I
only	O
for	O
slp	O
a	O
slp	O
is	O
only	O
capable	O
of	O
representing	O
linearly	O
separable	O
data	O
let	O
f	O
be	O
the	O
xor	O
function	O
which	O
expects	O
two	O
binary	B
inputs	O
and	O
generates	O
a	O
binary	B
output	B
the	O
precise	B
definition	O
see	O
table	O
let	O
us	O
try	O
to	O
represent	O
the	O
xor	O
function	O
by	O
means	O
of	O
an	O
slp	O
with	O
two	O
input	B
neurons	O
and	O
one	O
output	B
neuron	B
on	O
the	O
following	O
page	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
gfed	O
gfed	O
bbbb	O
bbbb	O
xor	O
figure	O
sketch	O
of	O
a	O
singlelayer	B
perceptron	B
that	O
shall	O
represent	O
the	O
xor	O
function	O
which	O
is	O
impossible	O
here	O
we	O
use	O
the	O
weighted	B
sum	I
as	O
propagation	B
function	I
a	O
binary	B
activation	B
function	I
with	O
the	O
threshold	B
value	I
and	O
the	O
identity	B
as	O
output	B
function	I
depending	O
on	O
and	O
has	O
to	O
output	B
the	O
value	O
if	O
the	O
following	O
holds	O
net	O
we	O
assume	O
a	O
positive	O
weight	B
the	O
inequality	O
is	O
then	O
equivalent	O
to	O
with	O
a	O
constant	O
threshold	B
value	I
the	O
right	O
part	O
of	O
inequation	O
is	O
a	O
straight	O
line	O
through	O
a	O
coordinate	O
system	O
defined	O
by	O
the	O
possible	O
outputs	O
und	O
of	O
the	O
input	B
neurons	O
and	O
for	O
a	O
required	O
for	O
inequation	O
positive	O
the	O
output	B
neuron	B
fires	O
for	O
figure	O
linear	O
separation	O
of	O
n	O
inputs	O
of	O
the	O
input	B
neurons	O
and	O
by	O
a	O
straight	O
line	O
a	O
and	O
b	O
show	O
the	O
corners	O
belonging	O
to	O
the	O
sets	O
of	O
the	O
xor	O
function	O
that	O
are	O
to	O
be	O
separated	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
linear	B
separability	I
n	O
number	O
of	O
share	O
lin	O
separable	O
ones	O
binary	B
functions	O
table	O
number	O
of	O
functions	O
concerning	O
n	O
binary	B
inputs	O
and	O
number	O
and	O
proportion	O
of	O
the	O
functions	O
thereof	O
which	O
can	O
be	O
linearly	O
separated	O
in	O
accordance	O
with	O
input	B
combinations	O
lying	O
above	O
the	O
generated	O
straight	O
line	O
for	O
a	O
negative	O
it	O
would	O
fire	O
for	O
all	O
input	B
combinations	O
lying	O
below	O
the	O
straight	O
line	O
note	O
that	O
only	O
the	O
four	O
corners	O
of	O
the	O
unit	O
square	O
are	O
possible	O
inputs	O
because	O
the	O
xor	O
function	O
only	O
knows	O
binary	B
inputs	O
in	O
order	O
to	O
solve	O
the	O
xor	O
problem	O
we	O
have	O
to	O
turn	O
and	O
move	O
the	O
straight	O
line	O
so	O
that	O
input	B
set	O
a	O
is	O
separated	O
from	O
input	B
set	O
b	O
this	O
is	O
obviously	O
impossible	O
generally	O
the	O
input	B
parameters	O
of	O
n	O
many	O
input	B
neurons	O
can	O
be	O
represented	O
in	O
an	O
ndimensional	O
cube	O
which	O
is	O
separated	O
by	O
an	O
slp	O
through	O
an	O
hyperplane	O
only	O
sets	O
that	O
can	O
be	O
separated	O
by	O
such	O
a	O
hyperplane	O
i	O
e	O
which	O
are	O
linearly	O
separable	O
can	O
be	O
classified	O
by	O
an	O
slp	O
slp	O
cannot	O
do	O
everything	O
figure	O
linear	O
separation	O
of	O
n	O
inputs	O
from	O
input	B
neurons	O
and	O
by	O
plane	O
unfortunately	O
it	O
seems	O
that	O
the	O
percentage	O
of	O
the	O
linearly	O
separable	O
problems	B
rapidly	O
decreases	O
with	O
increasing	O
n	O
table	O
which	O
limits	O
the	O
functionality	O
of	O
the	O
slp	O
additionally	O
tests	O
for	O
linear	B
separability	I
are	O
difficult	O
thus	O
for	O
more	O
difficult	O
tasks	O
with	O
more	O
inputs	O
we	O
need	O
something	O
more	O
powerful	O
than	O
slp	O
the	O
xor	O
problem	O
itself	O
is	O
one	O
of	O
these	O
tasks	O
since	O
a	O
perceptron	B
that	O
is	O
supposed	O
to	O
represent	O
the	O
xor	O
function	O
already	O
needs	O
a	O
hidden	B
layer	O
on	O
the	O
next	O
page	O
few	O
tasks	O
are	O
linearly	O
separable	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
gfed	O
aaaa	O
gfed	O
gfed	O
aaaa	O
gfed	O
xor	O
figure	O
neural	B
network	I
realizing	O
the	O
xor	O
function	O
threshold	O
values	O
far	O
as	O
they	O
are	O
existing	O
are	O
located	O
within	O
the	O
neurons	O
a	O
multilayer	B
perceptron	B
contains	O
more	O
trainable	O
weight	B
layers	O
a	O
perceptron	B
with	O
two	O
or	O
more	O
trainable	O
weight	B
layers	O
multilayer	B
perceptron	B
or	O
mlp	O
is	O
more	O
powerful	O
than	O
an	O
slp	O
as	O
we	O
know	O
a	O
singlelayer	B
perceptron	B
can	O
divide	O
the	O
input	B
space	O
by	O
means	O
of	O
a	O
hyperplane	O
a	O
two-dimensional	O
input	B
space	O
by	O
means	O
of	O
a	O
straight	O
line	O
a	O
twostage	O
perceptron	B
trainable	O
weight	B
layers	O
three	O
neuron	B
layers	O
can	O
classify	O
convex	O
polygons	O
by	O
further	O
processing	O
these	O
straight	O
lines	O
e	O
g	O
in	O
the	O
form	O
patterns	O
lying	O
above	O
straight	O
line	O
below	O
straight	O
line	O
and	O
below	O
straight	O
line	O
thus	O
we	O
metaphorically	O
speaking	O
took	O
an	O
slp	O
with	O
several	O
output	B
neurons	O
and	O
another	O
slp	O
more	O
planes	O
it	O
part	O
of	O
fig	O
on	O
the	O
facing	O
page	O
a	O
multilayer	B
perceptron	B
represents	O
an	O
universal	B
function	O
approximator	O
which	O
is	O
proven	O
by	O
the	O
theorem	O
of	O
cybenko	O
another	O
trainable	O
weight	B
layer	O
proceeds	O
analogously	O
now	O
with	O
the	O
convex	O
polygons	O
those	O
can	O
be	O
added	O
subtracted	O
or	O
somehow	O
processed	O
with	O
other	O
operations	O
part	O
of	O
fig	O
on	O
the	O
next	O
page	O
generally	O
can	O
be	O
mathematically	O
proven	O
that	O
even	O
a	O
multilayer	B
perceptron	B
with	O
one	O
layer	O
of	O
hidden	B
neurons	O
can	O
arbitrarily	O
precisely	O
approximate	O
functions	O
with	O
only	O
finitely	O
many	O
discontinuities	O
as	O
well	O
as	O
their	O
first	O
derivatives	O
unfortunately	O
this	O
proof	O
is	O
not	O
constructive	O
and	O
therefore	O
it	O
is	O
left	O
to	O
us	O
to	O
find	O
the	O
correct	O
number	O
of	O
neurons	O
and	O
weights	O
in	O
the	O
following	O
we	O
want	O
to	O
use	O
a	O
widespread	O
abbreviated	O
form	O
for	O
different	O
multilayer	B
perceptrons	O
we	O
denote	O
a	O
twostage	O
perceptron	B
with	O
neurons	O
in	O
the	O
input	B
layer	O
neurons	O
in	O
the	O
hidden	B
layer	O
and	O
neurons	O
in	O
the	O
output	B
layer	O
as	O
a	O
definition	O
perceptron	B
perceptrons	O
with	O
more	O
than	O
one	O
layer	O
of	O
variably	O
weighted	O
connections	O
are	O
referred	O
to	O
as	O
multilayer	B
perceptrons	O
an	O
n-layer	O
or	O
n-stage	O
perceptron	B
has	O
thereby	O
exactly	O
n	O
variable	B
weight	B
layers	O
and	O
n	O
neuron	B
layers	O
retina	B
is	O
disregarded	O
here	O
with	O
neuron	B
layer	O
being	O
the	O
input	B
layer	O
since	O
three-stage	O
perceptrons	O
can	O
classify	O
sets	O
of	O
any	O
form	O
by	O
combining	O
and	O
sepa	O
mlp	O
is	O
sufficient	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
multilayer	B
perceptron	B
gfed	O
gfed	O
tjjjjjjjjjjjjjjjjjjjjjjjjj	O
gfed	O
gfed	O
gfed	O
wooooooooooooooooo	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
wnnnnnnnnnnnnnnnnn	O
gfed	O
gfed	O
figure	O
we	O
know	O
that	O
an	O
slp	O
represents	O
a	O
straight	O
line	O
with	O
trainable	O
weight	B
layers	O
several	O
straight	O
lines	O
can	O
be	O
combined	O
to	O
form	O
convex	O
polygons	O
by	O
using	O
trainable	O
weight	B
layers	O
several	O
polygons	O
can	O
be	O
formed	O
into	O
arbitrary	O
sets	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
t	O
w	O
t	O
t	O
u	O
u	O
w	O
w	O
t	O
t	O
r	O
r	O
w	O
q	O
q	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
n	O
classifiable	O
sets	O
hyperplane	O
convex	O
polygon	O
any	O
set	O
any	O
set	O
as	O
well	O
i	O
e	O
no	O
advantage	O
table	O
representation	O
of	O
which	O
perceptron	B
can	O
classify	O
which	O
types	O
of	O
sets	O
with	O
n	O
being	O
the	O
number	O
of	O
trainable	O
weight	B
layers	O
rating	O
arbitrarily	O
many	O
convex	O
polygons	O
another	O
step	O
will	O
not	O
be	O
advantageous	O
with	O
respect	O
to	O
function	O
representations	O
be	O
cautious	O
when	O
reading	O
the	O
literature	O
there	O
are	O
many	O
different	O
definitions	O
of	O
what	O
is	O
counted	O
as	O
a	O
layer	O
some	O
sources	O
count	O
the	O
neuron	B
layers	O
some	O
count	O
the	O
weight	B
layers	O
some	O
sources	O
include	O
the	O
retina	B
some	O
the	O
trainable	O
weight	B
layers	O
some	O
exclude	O
some	O
reason	O
the	O
output	B
neuron	B
layer	O
in	O
this	O
work	O
i	O
chose	O
the	O
definition	O
that	O
provides	O
in	O
my	O
opinion	O
the	O
most	O
information	O
about	O
the	O
learning	O
capabilities	O
and	O
i	O
will	O
use	O
it	O
cosistently	O
remember	O
an	O
n-stage	O
perceptron	B
has	O
exactly	O
n	O
trainable	O
weight	B
layers	O
you	O
can	O
find	O
a	O
summary	O
of	O
which	O
perceptrons	O
can	O
classify	O
which	O
types	O
of	O
sets	O
in	O
table	O
we	O
now	O
want	O
to	O
face	O
the	O
challenge	O
of	O
training	O
perceptrons	O
with	O
more	O
than	O
one	O
weight	B
layer	O
backpropagation	B
of	I
error	I
generalizes	O
the	O
delta	B
rule	I
to	O
allow	O
for	O
mlp	O
training	O
next	O
i	O
want	O
to	O
derive	O
and	O
explain	O
the	O
backpropagation	B
of	I
error	I
learning	O
rule	O
backpropagation	B
backprop	O
or	O
bp	O
which	O
can	O
be	O
used	O
to	O
train	O
multistage	O
perceptrons	O
with	O
activation	B
functions	O
binary	B
threshold	O
functions	O
and	O
other	O
non-differentiable	O
functions	O
are	O
no	O
longer	O
supported	O
but	O
that	O
doesn	O
t	O
matter	O
we	O
have	O
seen	O
that	O
the	O
fermi	B
function	I
or	O
the	O
hyperbolic	B
tangent	I
can	O
arbitrarily	O
approximate	O
the	O
binary	B
threshold	I
function	I
by	O
means	O
of	O
a	O
temperature	B
parameter	I
t	O
to	O
a	O
large	O
extent	O
i	O
will	O
follow	O
the	O
derivation	O
according	O
to	O
and	O
once	O
again	O
i	O
want	O
to	O
point	O
out	O
that	O
this	O
procedure	O
had	O
previously	O
been	O
published	O
by	O
paul	O
werbos	O
in	O
but	O
had	O
consideraby	O
less	O
readers	O
than	O
in	O
backpropagation	B
is	O
a	O
gradient	B
descent	I
procedure	O
all	O
strengths	O
and	O
weaknesses	O
of	O
the	O
gradient	B
descent	I
with	O
the	O
error	B
function	I
errw	O
receiving	O
all	O
n	O
weights	O
as	O
arguments	O
on	O
page	O
and	O
assigning	O
them	O
to	O
the	O
output	B
error	O
i	O
e	O
being	O
n-dimensional	O
on	O
errw	O
a	O
point	O
of	O
small	O
error	O
or	O
even	O
a	O
point	O
of	O
the	O
smallest	O
error	O
is	O
sought	O
by	O
means	O
of	O
the	O
gradient	B
descent	I
thus	O
in	O
analogy	O
to	O
the	O
delta	B
rule	I
backpropagation	B
trains	O
the	O
weights	O
of	O
the	O
neural	B
network	I
and	O
it	O
is	O
exactly	O
semilinear	O
functions	O
are	O
monotonous	O
and	O
differen	O
tiable	O
but	O
generally	O
they	O
are	O
not	O
linear	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
backpropagation	B
of	I
error	I
the	O
delta	B
rule	I
or	O
its	O
variable	B
i	O
for	O
a	O
neuron	B
i	O
which	O
is	O
expanded	O
from	O
one	O
trainable	O
weight	B
layer	O
to	O
several	O
ones	O
by	O
backpropagation	B
the	O
derivation	O
is	O
similar	O
to	O
the	O
one	O
of	O
the	O
delta	B
rule	I
but	O
with	O
a	O
generalized	O
delta	B
let	O
us	O
define	O
in	O
advance	O
that	O
the	O
network	B
input	B
of	O
the	O
individual	O
neurons	O
i	O
results	O
from	O
the	O
weighted	B
sum	I
furthermore	O
as	O
with	O
the	O
derivation	O
of	O
the	O
delta	B
rule	I
let	O
opi	O
netpi	O
etc	O
be	O
defined	O
as	O
the	O
already	O
familiar	O
oi	O
neti	O
etc	O
under	O
the	O
input	B
pattern	O
p	O
we	O
used	O
for	O
the	O
training	O
let	O
the	O
output	B
function	I
be	O
the	O
identity	B
again	O
thus	O
oi	O
factnetpi	O
holds	O
for	O
any	O
neuron	B
i	O
since	O
this	O
is	O
a	O
generalization	B
of	O
the	O
delta	B
rule	I
we	O
use	O
the	O
same	O
formula	O
framework	O
as	O
with	O
the	O
delta	B
rule	I
on	O
page	O
as	O
already	O
indicated	O
we	O
have	O
to	O
generalize	O
the	O
variable	B
for	O
every	O
neuron	B
first	O
of	O
all	O
where	O
is	O
the	O
neuron	B
for	O
which	O
we	O
want	O
to	O
calculate	O
it	O
is	O
obvious	O
to	O
select	O
an	O
arbitrary	O
inner	O
neuron	B
h	O
having	O
a	O
set	O
k	O
of	O
predecessor	O
neurons	O
k	O
as	O
well	O
as	O
a	O
set	B
of	I
l	O
successor	O
neurons	O
l	O
which	O
are	O
also	O
inner	O
neurons	O
fig	O
it	O
is	O
therefore	O
irrelevant	O
whether	O
the	O
predecessor	O
neurons	O
are	O
already	O
the	O
input	B
neurons	O
now	O
we	O
perform	O
the	O
same	O
derivation	O
as	O
for	O
the	O
delta	B
rule	I
and	O
split	O
functions	O
by	O
means	O
the	O
chain	O
rule	O
i	O
will	O
not	O
discuss	O
this	O
derivation	O
in	O
great	O
detail	O
but	O
the	O
principal	O
is	O
similar	O
to	O
that	O
of	O
the	O
delta	B
rule	I
generalization	B
of	O
onml	O
hijk	O
xrrrrrrrrrrrrrrr	O
fact	O
wppppppp	O
nnnnnnn	O
pppppppp	O
wkh	O
h	O
whl	O
k	O
h	O
l	O
figure	O
illustration	O
of	O
the	O
position	O
of	O
our	O
neuron	B
h	O
within	O
the	O
neural	B
network	I
it	O
is	O
lying	O
in	O
layer	O
h	O
the	O
preceding	O
layer	O
is	O
k	O
the	O
subsequent	O
layer	O
is	O
l	O
differences	O
are	O
as	O
already	O
mentioned	O
in	O
the	O
generalized	O
we	O
initially	O
derive	O
the	O
error	B
function	I
err	O
according	O
to	O
a	O
weight	B
wkh	O
errwkh	O
wkh	O
neth	O
wkh	O
err	O
neth	O
h	O
the	O
first	O
factor	O
of	O
equation	O
is	O
h	O
which	O
we	O
will	O
deal	O
with	O
later	O
in	O
this	O
text	O
the	O
numerator	O
of	O
the	O
second	O
factor	O
of	O
the	O
equation	O
includes	O
the	O
network	B
input	B
i	O
e	O
the	O
weighted	B
sum	I
is	O
included	O
in	O
the	O
numerator	O
so	O
that	O
we	O
can	O
immediately	O
derive	O
it	O
again	O
all	O
summands	O
of	O
the	O
sum	O
drop	O
out	O
apart	O
from	O
the	O
summand	O
containing	O
wkh	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
w	O
x	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
this	O
summand	O
is	O
referred	O
to	O
as	O
wkh	O
ok	O
if	O
we	O
calculate	O
the	O
derivative	O
the	O
output	B
of	O
neuron	B
k	O
becomes	O
according	O
to	O
the	O
definition	O
of	O
the	O
multidimensional	O
chain	O
rule	O
we	O
immediately	O
obtain	O
equation	O
neth	O
wkh	O
k	O
k	O
wkhok	O
wkh	O
p	O
ok	O
l	O
l	O
err	O
oh	O
err	O
netl	O
netl	O
oh	O
as	O
promised	O
we	O
will	O
now	O
discuss	O
the	O
h	O
of	O
equation	O
on	O
the	O
previous	O
page	O
which	O
is	O
split	O
up	O
again	O
according	O
of	O
the	O
chain	O
rule	O
the	O
sum	O
in	O
equation	O
contains	O
two	O
factors	O
now	O
we	O
want	O
to	O
discuss	O
these	O
factors	O
being	O
added	O
over	O
the	O
subsequent	O
layer	O
l	O
we	O
simply	O
calculate	O
the	O
second	O
factor	O
in	O
the	O
following	O
equation	O
h	O
err	O
neth	O
err	O
oh	O
oh	O
neth	O
netl	O
oh	O
p	O
whl	O
h	O
h	O
whl	O
oh	O
oh	O
the	O
derivation	O
of	O
the	O
output	B
according	O
to	O
the	O
network	B
input	B
second	O
factor	O
in	O
equation	O
clearly	O
equals	O
the	O
derivation	O
of	O
the	O
activation	B
function	I
according	O
to	O
the	O
network	B
input	B
the	O
same	O
applies	O
for	O
the	O
first	O
factor	O
according	O
to	O
the	O
definition	O
of	O
our	O
err	O
netl	O
l	O
oh	O
neth	O
factneth	O
neth	O
fact	O
now	O
we	O
insert	O
err	O
oh	O
l	O
l	O
lwhl	O
consider	O
this	O
an	O
important	O
passage	O
we	O
now	O
analogously	O
derive	O
the	O
first	O
factor	O
in	O
equation	O
therefore	O
we	O
have	O
to	O
point	O
out	O
that	O
the	O
derivation	O
of	O
the	O
error	B
function	I
according	O
to	O
the	O
output	B
of	O
an	O
inner	O
neuron	B
layer	O
depends	O
on	O
the	O
vector	O
of	O
all	O
network	O
inputs	O
of	O
the	O
next	O
following	O
layer	O
this	O
is	O
reflected	O
in	O
equation	O
netll	O
err	O
oh	O
oh	O
you	O
can	O
find	O
a	O
graphic	O
version	O
of	O
the	O
generalization	B
including	O
all	O
splittings	O
in	O
fig	O
on	O
the	O
facing	O
page	O
the	O
reader	O
might	O
already	O
have	O
noticed	O
that	O
some	O
intermediate	O
results	O
were	O
shown	O
in	O
frames	O
exactly	O
those	O
intermediate	O
results	O
were	O
highlighted	O
in	O
that	O
way	O
which	O
are	O
a	O
factor	O
in	O
the	O
change	B
in	I
weight	B
of	O
wkh	O
if	O
the	O
aforementioned	O
equations	O
are	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
backpropagation	B
of	I
error	I
h	O
err	O
neth	O
oh	O
neth	O
err	O
oh	O
actneth	O
err	O
netl	O
l	O
l	O
l	O
netl	O
oh	O
p	O
p	O
whl	O
oh	O
h	O
h	O
oh	O
whl	O
figure	O
graphical	O
representation	O
of	O
the	O
equations	O
equal	O
signs	O
and	O
chain	O
rule	O
splittings	O
arrows	O
in	O
the	O
framework	O
of	O
the	O
backpropagation	B
derivation	O
the	O
leaves	O
of	O
the	O
tree	B
reflect	O
the	O
final	O
results	O
from	O
the	O
generalization	B
of	O
which	O
are	O
framed	O
in	O
the	O
derivation	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
combined	O
with	O
the	O
highlighted	O
intermediate	O
results	O
the	O
outcome	O
of	O
this	O
will	O
be	O
the	O
wanted	O
change	B
in	I
weight	B
wkh	O
to	O
actneth	O
x	O
l	O
l	O
h	O
f	O
wkh	O
ok	O
h	O
with	O
lwhl	O
of	O
course	O
only	O
in	O
case	O
of	O
h	O
being	O
an	O
inner	O
neuron	B
there	O
would	O
not	O
be	O
a	O
subsequent	O
layer	O
l	O
the	O
case	O
of	O
h	O
being	O
an	O
output	B
neuron	B
has	O
already	O
been	O
discussed	O
during	O
the	O
derivation	O
of	O
the	O
delta	B
rule	I
all	O
in	O
all	O
the	O
result	O
is	O
the	O
generalization	B
of	O
the	O
delta	B
rule	I
called	O
backpropagation	B
of	I
error	I
wkh	O
ok	O
h	O
with	O
h	O
actneth	O
yh	O
outside	O
l	O
l	O
lwhl	O
inside	O
in	O
contrast	O
to	O
the	O
delta	B
rule	I
is	O
treated	O
differently	O
depending	O
on	O
whether	O
h	O
is	O
an	O
output	B
or	O
an	O
inner	O
hidden	B
neuron	B
actneth	O
p	O
if	O
h	O
is	O
an	O
output	B
neuron	B
then	O
ph	O
f	O
actnetph	O
yph	O
thus	O
under	O
our	O
training	B
pattern	I
p	O
the	O
weight	B
wkh	O
from	O
k	O
to	O
h	O
is	O
changed	O
proportionally	O
according	O
to	O
the	O
learning	B
rate	I
the	O
output	B
opk	O
of	O
the	O
predeces	O
sor	O
neuron	B
k	O
the	O
gradient	B
of	O
the	O
activation	B
function	I
at	O
the	O
position	O
of	O
the	O
network	B
input	B
of	O
the	O
successor	O
neuron	B
actnetph	O
and	O
teach	O
input	B
changed	O
for	O
the	O
outer	O
weight	B
layer	O
backpropagation	B
for	O
inner	O
layers	O
the	O
difference	O
between	O
teaching	B
input	B
tph	O
and	O
output	B
yph	O
of	O
the	O
successor	O
neuron	B
h	O
in	O
this	O
case	O
backpropagation	B
is	O
working	O
on	O
two	O
neuron	B
layers	O
the	O
output	B
layer	O
with	O
the	O
successor	O
neuron	B
h	O
and	O
the	O
preceding	O
layer	O
with	O
the	O
predecessor	O
neuron	B
k	O
if	O
h	O
is	O
an	O
inner	O
hidden	B
neuron	B
then	O
pl	O
whl	O
actnetph	O
x	O
ph	O
f	O
l	O
l	O
holds	O
i	O
want	O
to	O
explicitly	O
mention	O
that	O
backpropagation	B
is	O
now	O
working	O
on	O
three	O
layers	O
here	O
neuron	B
k	O
is	O
the	O
predecessor	O
of	O
the	O
connection	B
to	O
be	O
changed	O
with	O
the	O
weight	B
wkh	O
the	O
neuron	B
h	O
is	O
the	O
successor	O
of	O
the	O
connection	B
to	O
be	O
changed	O
and	O
the	O
neurons	O
l	O
are	O
lying	O
in	O
the	O
layer	O
following	O
the	O
successor	O
neuron	B
thus	O
according	O
to	O
our	O
training	B
pattern	I
p	O
the	O
weight	B
wkh	O
from	O
k	O
to	O
h	O
is	O
proportionally	O
changed	O
according	O
to	O
the	O
learning	B
rate	I
the	O
output	B
of	O
the	O
predecessor	O
neuron	B
opk	O
the	O
gradient	B
of	O
the	O
activation	B
function	I
at	O
the	O
position	O
of	O
the	O
network	B
input	B
of	O
the	O
successor	O
neuron	B
actnetph	O
as	O
well	O
as	O
and	O
this	O
according	O
the	O
difference	O
the	O
weighted	B
sum	I
of	O
the	O
changes	O
in	O
weight	B
to	O
all	O
neurons	O
following	O
h	O
p	O
l	O
l	O
pl	O
whl	O
is	O
to	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
backprop	O
expands	O
delta	B
rule	I
dkriesel	O
com	O
backpropagation	B
of	I
error	I
definition	O
if	O
we	O
summarize	O
formulas	O
on	O
the	O
preceding	O
page	O
and	O
on	O
the	O
facing	O
page	O
we	O
receive	O
the	O
following	O
final	O
formula	O
for	O
backpropagation	B
identifiers	O
p	O
are	O
ommited	O
for	O
reasons	O
of	O
clarity	O
wkh	O
ok	O
h	O
with	O
h	O
actneth	O
p	O
actneth	O
yh	O
outside	O
l	O
l	O
lwhl	O
inside	O
snipe	O
an	O
online	B
variant	O
of	O
backpropagation	B
is	O
implemented	O
in	O
the	O
method	O
trainbackpropagationoferror	O
within	O
the	O
class	O
neuralnetwork	O
heading	O
back	O
boiling	O
backpropagation	B
down	O
to	O
delta	B
rule	I
as	O
explained	O
above	O
the	O
delta	B
rule	I
is	O
a	O
special	O
case	O
of	O
backpropagation	B
for	O
onestage	O
perceptrons	O
and	O
linear	O
activation	B
functions	O
i	O
want	O
to	O
briefly	O
explain	O
this	O
circumstance	O
and	O
develop	O
the	O
delta	B
rule	I
out	O
of	O
backpropagation	B
in	O
order	O
to	O
augment	O
the	O
understanding	O
of	O
both	O
rules	O
we	O
have	O
seen	O
that	O
backpropagation	B
is	O
defined	O
by	O
wkh	O
ok	O
h	O
with	O
h	O
actneth	O
p	O
actneth	O
yh	O
outside	O
l	O
l	O
lwhl	O
inside	O
it	O
is	O
obvious	O
that	O
backpropagation	B
initially	O
processes	O
the	O
last	O
weight	B
layer	O
directly	O
by	O
means	O
of	O
the	O
teaching	B
input	B
and	O
then	O
works	O
backwards	O
from	O
layer	O
to	O
layer	O
while	O
considering	O
each	O
preceding	O
change	O
in	O
weights	O
thus	O
the	O
teaching	B
input	B
leaves	O
traces	O
in	O
all	O
weight	B
layers	O
here	O
i	O
describe	O
the	O
first	O
rule	O
and	O
the	O
second	O
part	O
of	O
backpropagation	B
delta	B
rule	I
on	O
more	O
layers	O
in	O
one	O
go	O
which	O
may	O
meet	O
the	O
requirements	O
of	O
the	O
matter	O
but	O
not	O
of	O
the	O
research	O
the	O
first	O
part	O
is	O
obvious	O
which	O
you	O
will	O
soon	O
see	O
in	O
the	O
framework	O
of	O
a	O
mathematical	O
gimmick	O
decades	O
of	O
development	O
time	O
and	O
work	O
lie	O
between	O
the	O
first	O
and	O
the	O
second	O
recursive	O
part	O
like	O
many	O
groundbreaking	O
inventions	O
it	O
was	O
not	O
until	O
its	O
development	O
that	O
it	O
was	O
recognized	O
how	O
plausible	O
this	O
invention	O
was	O
since	O
we	O
only	O
use	O
it	O
for	O
one-stage	O
perceptrons	O
the	O
second	O
part	O
of	O
backpropagation	B
is	O
omitted	O
without	O
substitution	O
the	O
result	O
is	O
wkh	O
ok	O
h	O
with	O
h	O
actneth	O
oh	O
furthermore	O
we	O
only	O
want	O
to	O
use	O
linear	O
activation	B
functions	O
so	O
that	O
act	O
is	O
constant	O
as	O
is	O
generally	O
known	O
constants	O
can	O
be	O
combined	O
and	O
therefore	O
we	O
directly	O
merge	O
the	O
constant	O
derivative	O
act	O
and	O
constant	O
for	O
at	O
least	O
one	O
lerning	O
cycle	O
the	O
learning	B
rate	I
light-colored	O
in	O
thus	O
the	O
result	O
is	O
wkh	O
ok	O
h	O
ok	O
oh	O
this	O
exactly	O
corresponds	O
to	O
the	O
delta	B
rule	I
definition	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
the	O
selection	B
of	I
the	O
learning	B
rate	I
has	O
heavy	O
influence	O
on	O
the	O
learning	O
process	O
variation	O
of	O
the	O
learning	B
rate	I
over	O
time	O
in	O
the	O
meantime	O
we	O
have	O
often	O
seen	O
that	O
the	O
change	B
in	I
weight	B
is	O
in	O
any	O
case	O
proportional	O
to	O
the	O
learning	B
rate	I
thus	O
the	O
selection	B
of	I
is	O
crucial	O
for	O
the	O
behaviour	O
of	O
backpropagation	B
and	O
for	O
learning	O
procedures	O
in	O
general	O
how	O
fast	O
will	O
be	O
learned	O
definition	O
rate	O
speed	O
and	O
accuracy	O
of	O
a	O
learning	O
procedure	O
can	O
always	O
be	O
controlled	O
by	O
and	O
are	O
always	O
proportional	O
to	O
a	O
learning	B
rate	I
which	O
is	O
written	O
as	O
if	O
the	O
value	O
of	O
the	O
chosen	O
is	O
too	O
large	O
the	O
jumps	O
on	O
the	O
error	O
surface	O
are	O
also	O
too	O
large	O
and	O
for	O
example	O
narrow	O
valleys	O
could	O
simply	O
be	O
jumped	O
over	O
additionally	O
the	O
movements	O
across	O
the	O
error	O
surface	O
would	O
be	O
very	O
uncontrolled	O
thus	O
a	O
small	O
is	O
the	O
desired	O
input	B
which	O
however	O
can	O
cost	O
a	O
huge	O
often	O
unacceptable	O
amount	O
of	O
time	O
experience	O
shows	O
that	O
good	O
learning	B
rate	I
values	O
are	O
in	O
the	O
range	O
of	O
the	O
selection	B
of	I
significantly	O
depends	O
on	O
the	O
problem	O
the	O
network	O
and	O
the	O
training	O
data	O
so	O
that	O
it	O
is	O
barely	O
possible	O
to	O
give	O
practical	O
advise	O
but	O
for	O
instance	O
it	O
is	O
popular	O
to	O
start	O
with	O
a	O
relatively	O
large	O
e	O
g	O
and	O
to	O
slowly	O
decrease	O
it	O
down	O
to	O
for	O
simpler	O
problems	B
can	O
often	O
be	O
kept	O
constant	O
during	O
training	O
another	O
stylistic	O
device	O
can	O
be	O
a	O
variable	B
learning	B
rate	I
in	O
the	O
beginning	O
a	O
large	O
learning	B
rate	I
leads	O
to	O
good	O
results	O
but	O
later	O
it	O
results	O
in	O
inaccurate	O
learning	O
a	O
smaller	O
learning	B
rate	I
is	O
more	O
time-consuming	O
but	O
the	O
result	O
is	O
more	O
precise	B
thus	O
during	O
the	O
learning	O
process	O
the	O
learning	B
rate	I
needs	O
to	O
be	O
decreased	O
by	O
one	O
order	O
of	O
magnitude	O
once	O
or	O
repeatedly	O
a	O
common	O
error	O
also	O
seems	O
to	O
be	O
a	O
very	O
neat	O
solution	O
at	O
first	O
glance	O
is	O
to	O
continually	O
decrease	O
the	O
learning	B
rate	I
here	O
it	O
quickly	O
happens	O
that	O
the	O
descent	O
of	O
the	O
learning	B
rate	I
is	O
larger	O
than	O
the	O
ascent	O
of	O
a	O
hill	O
of	O
the	O
error	B
function	I
we	O
are	O
climbing	O
the	O
result	O
is	O
that	O
we	O
simply	O
get	O
stuck	O
at	O
this	O
ascent	O
solution	O
rather	O
reduce	O
the	O
learning	B
rate	I
gradually	O
as	O
mentioned	O
above	O
different	O
layers	O
different	O
learning	O
rates	O
the	O
farer	O
we	O
move	O
away	O
from	O
the	O
output	B
layer	O
during	O
the	O
learning	O
process	O
the	O
slower	O
backpropagation	B
is	O
learning	O
thus	O
it	O
is	O
a	O
good	O
idea	O
to	O
select	O
a	O
larger	O
learning	B
rate	I
for	O
the	O
weight	B
layers	O
close	O
to	O
the	O
input	B
layer	O
than	O
for	O
the	O
weight	B
layers	O
close	O
to	O
the	O
output	B
layer	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
resilient	B
backpropagation	B
resilient	B
backpropagation	B
is	O
an	O
extension	O
to	O
backpropagation	B
of	I
error	I
we	O
have	O
just	O
raised	O
two	O
backpropagationspecific	O
properties	O
that	O
can	O
occasionally	O
be	O
a	O
problem	O
addition	O
to	O
those	O
which	O
are	O
already	O
caused	O
by	O
gradient	B
descent	I
itself	O
on	O
the	O
one	O
hand	O
users	O
of	O
backpropagation	B
can	O
choose	O
a	O
bad	O
learning	B
rate	I
on	O
the	O
other	O
hand	O
the	O
further	O
the	O
weights	O
are	O
from	O
the	O
output	B
layer	O
the	O
slower	O
backpropagation	B
learns	O
for	O
this	O
reason	O
martin	O
riedmiller	O
et	O
al	O
enhanced	O
backpropagation	B
and	O
called	O
their	O
version	O
resilient	B
backpropagation	B
rprop	O
i	O
want	O
to	O
compare	O
backpropagation	B
and	O
rprop	O
without	O
explicitly	O
declaring	O
one	O
version	O
superior	O
to	O
the	O
other	O
before	O
actually	O
dealing	O
with	O
formulas	O
let	O
us	O
informally	O
compare	O
the	O
two	O
primary	B
ideas	O
behind	O
rprop	O
their	O
consequences	O
to	O
the	O
already	O
familiar	O
backpropagation	B
learning	O
rates	O
backpropagation	B
uses	O
by	O
default	O
a	O
learning	B
rate	I
which	O
is	O
selected	O
by	O
the	O
user	O
and	O
applies	O
to	O
the	O
entire	O
network	O
it	O
remains	O
static	O
until	O
it	O
is	O
manually	O
changed	O
we	O
have	O
already	O
explored	O
the	O
disadvantages	O
of	O
this	O
approach	O
here	O
rprop	O
pursues	O
a	O
completely	O
different	O
approach	O
there	O
is	O
no	O
global	O
learning	B
rate	I
first	O
each	O
weight	B
wij	O
has	O
its	O
own	O
learning	B
rate	I
ij	O
and	O
second	O
these	O
learning	O
rates	O
are	O
not	O
chosen	O
by	O
the	O
user	O
but	O
are	O
automatically	O
set	O
by	O
rprop	O
itself	O
third	O
the	O
weight	B
changes	O
are	O
not	O
static	O
but	O
are	O
adapted	O
for	O
each	O
time	O
step	O
of	O
rprop	O
to	O
account	O
for	O
the	O
temporal	O
change	O
we	O
have	O
to	O
correctly	O
call	O
it	O
ijt	O
this	O
not	O
only	O
enables	O
more	O
focused	O
learning	O
also	O
the	O
problem	O
of	O
an	O
increasingly	O
slowed	O
down	O
learning	O
throughout	O
the	O
layers	O
is	O
solved	O
in	O
an	O
elegant	O
way	O
weight	B
change	O
when	O
using	O
backpropagation	B
weights	O
are	O
changed	O
proportionally	O
to	O
the	O
gradient	B
of	O
the	O
error	B
function	I
at	O
first	O
glance	O
this	O
is	O
really	O
intuitive	O
however	O
we	O
incorporate	O
every	O
jagged	O
feature	O
of	O
the	O
error	O
surface	O
into	O
the	O
weight	B
changes	O
it	O
is	O
at	O
least	O
questionable	O
whether	O
this	O
is	O
always	O
useful	O
here	O
rprop	O
takes	O
other	O
ways	O
as	O
well	O
the	O
amount	O
of	O
weight	B
change	O
wij	O
simply	O
directly	O
corresponds	O
to	O
the	O
automatically	O
adjusted	O
learning	B
rate	I
ij	O
thus	O
the	O
change	B
in	I
weight	B
is	O
not	O
proportional	O
to	O
the	O
gradient	B
it	O
is	O
only	O
influenced	O
by	O
the	O
sign	O
of	O
the	O
gradient	B
until	O
now	O
we	O
still	O
do	O
not	O
know	O
how	O
exactly	O
the	O
ij	O
are	O
adapted	O
at	O
run	O
time	O
but	O
let	O
me	O
anticipate	O
that	O
the	O
resulting	O
process	O
looks	O
consider-	O
much	O
ably	O
less	O
rugged	O
than	O
an	O
error	B
function	I
smoother	O
learning	O
in	O
contrast	O
to	O
backprop	O
the	O
weight	B
update	O
step	O
is	O
replaced	O
and	O
an	O
additional	O
step	O
for	O
the	O
adjustment	O
of	O
the	O
learning	B
rate	I
is	O
added	O
now	O
how	O
exactly	O
are	O
these	O
ideas	O
being	O
implemented	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
one	O
learningrate	O
per	O
weight	B
automatic	O
learning	B
rate	I
adjustment	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
change	O
in	O
definition	O
rprop	O
weight	B
changes	O
are	O
not	O
proportional	O
to	O
the	O
gradient	B
let	O
us	O
first	O
consider	O
the	O
change	B
in	I
weight	B
we	O
have	O
already	O
noticed	O
that	O
the	O
weightspecific	O
learning	O
rates	O
directly	O
serve	O
as	O
absolute	O
values	O
for	O
the	O
changes	O
of	O
the	O
respective	O
weights	O
there	O
remains	O
the	O
question	O
of	O
where	O
the	O
sign	O
comes	O
from	O
this	O
is	O
a	O
point	O
at	O
which	O
the	O
gradient	B
comes	O
into	O
play	O
as	O
with	O
the	O
derivation	O
of	O
backpropagation	B
we	O
derive	O
the	O
error	B
function	I
errw	O
by	O
the	O
individual	O
weights	O
wij	O
and	O
obtain	O
gradients	O
errw	O
now	O
the	O
big	O
wij	O
difference	O
rather	O
than	O
multiplicatively	O
incorporating	O
the	O
absolute	O
value	O
of	O
the	O
gradient	B
into	O
the	O
weight	B
change	O
we	O
consider	O
only	O
the	O
sign	O
of	O
the	O
gradient	B
the	O
gradient	B
hence	O
no	O
longer	O
determines	O
the	O
strength	O
but	O
only	O
the	O
direction	O
of	O
the	O
weight	B
change	O
if	O
the	O
sign	O
of	O
the	O
gradient	B
errw	O
is	O
pos	O
wij	O
itive	O
we	O
must	O
decrease	O
the	O
weight	B
wij	O
so	O
the	O
weight	B
is	O
reduced	O
by	O
ij	O
if	O
the	O
sign	O
of	O
the	O
gradient	B
is	O
negative	O
the	O
weight	B
needs	O
to	O
be	O
increased	O
so	O
ij	O
is	O
added	O
to	O
it	O
if	O
the	O
gradient	B
is	O
exactly	O
nothing	O
happens	O
at	O
all	O
let	O
us	O
now	O
create	O
a	O
formula	O
from	O
this	O
colloquial	O
description	O
the	O
corresponding	O
terms	O
are	O
affixed	O
with	O
a	O
to	O
show	O
that	O
everything	O
happens	O
at	O
the	O
same	O
time	O
step	O
this	O
might	O
decrease	O
clarity	O
at	O
first	O
glance	O
but	O
is	O
nevertheless	O
important	O
because	O
we	O
will	O
soon	O
look	O
at	O
another	O
formula	O
that	O
operates	O
on	O
different	O
time	O
steps	O
instead	O
we	O
shorten	O
the	O
gradient	B
to	O
g	O
errw	O
wij	O
gradient	B
determines	O
only	O
direction	O
of	O
the	O
updates	O
wijt	O
ijt	O
ijt	O
if	O
gt	O
if	O
gt	O
otherwise	O
we	O
now	O
know	O
how	O
the	O
weights	O
are	O
changed	O
now	O
remains	O
the	O
question	O
how	O
the	O
learning	O
rates	O
are	O
adjusted	O
finally	O
once	O
we	O
have	O
understood	O
the	O
overall	O
system	O
we	O
will	O
deal	O
with	O
the	O
remaining	O
details	O
like	O
initialization	O
and	O
some	O
specific	B
constants	O
many	O
dynamically	O
adjusted	O
learning	O
rates	O
instead	O
of	O
one	O
static	O
to	O
adjust	O
the	O
learning	B
rate	I
ij	O
we	O
again	O
have	O
to	O
consider	O
the	O
associated	O
gradients	O
g	O
of	O
two	O
time	O
steps	O
the	O
gradient	B
that	O
has	O
just	O
passed	O
and	O
the	O
current	O
one	O
again	O
only	O
the	O
sign	O
of	O
the	O
gradient	B
matters	O
and	O
we	O
now	O
must	O
ask	O
ourselves	O
what	O
can	O
happen	O
to	O
the	O
sign	O
over	O
two	O
time	O
steps	O
it	O
can	O
stay	O
the	O
same	O
and	O
it	O
can	O
flip	O
if	O
the	O
sign	O
changes	O
from	O
gt	O
to	O
gt	O
we	O
have	O
skipped	O
a	O
local	O
minimum	O
in	O
the	O
gradient	B
hence	O
the	O
last	O
update	O
was	O
too	O
large	O
and	O
ijt	O
has	O
to	O
be	O
reduced	O
as	O
compared	O
to	O
the	O
previous	O
ijt	O
one	O
can	O
say	O
that	O
the	O
search	O
needs	O
to	O
be	O
more	O
accurate	O
in	O
mathematical	O
terms	O
we	O
obtain	O
a	O
new	O
ijt	O
by	O
multiplying	O
the	O
old	O
ijt	O
with	O
a	O
constant	O
which	O
is	O
between	O
and	O
in	O
this	O
case	O
we	O
know	O
that	O
in	O
the	O
last	O
time	O
step	O
something	O
went	O
wrong	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
resilient	B
backpropagation	B
hence	O
we	O
additionally	O
reset	O
the	O
weight	B
update	O
for	O
the	O
weight	B
wij	O
at	O
time	O
step	O
to	O
so	O
that	O
it	O
not	O
applied	O
at	O
all	O
shown	O
in	O
the	O
following	O
formula	O
however	O
if	O
the	O
sign	O
remains	O
the	O
same	O
one	O
can	O
perform	O
a	O
increase	O
of	O
ij	O
to	O
get	O
past	O
shallow	O
areas	O
of	O
the	O
error	B
function	I
here	O
we	O
obtain	O
our	O
new	O
ijt	O
by	O
multiplying	O
the	O
old	O
ijt	O
with	O
a	O
constant	O
which	O
is	O
greater	O
than	O
definition	O
of	O
learning	O
rates	O
in	O
rprop	O
gt	O
gt	O
otherwise	O
ijt	O
ijt	O
ijt	O
ijt	O
rprop	O
only	O
learns	O
o	O
ine	O
caution	O
this	O
also	O
implies	O
that	O
rprop	O
is	O
exclusively	O
designed	O
for	O
o	O
ine	O
if	O
the	O
gradients	O
do	O
not	O
have	O
a	O
certain	O
continuity	O
the	O
learning	O
process	O
slows	O
down	O
to	O
the	O
lowest	O
rates	O
remains	O
there	O
when	O
learning	O
online	B
one	O
changes	O
loosely	O
speaking	O
the	O
error	B
function	I
with	O
each	O
new	O
epoch	B
since	O
it	O
is	O
based	O
on	O
only	O
one	O
training	B
pattern	I
this	O
may	O
be	O
often	O
well	O
applicable	O
in	O
backpropagation	B
and	O
it	O
is	O
very	O
often	O
even	O
faster	O
than	O
the	O
o	O
ine	O
version	O
which	O
is	O
why	O
it	O
is	O
used	O
there	O
frequently	O
it	O
lacks	O
however	O
a	O
clear	O
mathematical	O
motivation	O
and	O
that	O
is	O
exactly	O
what	O
we	O
need	O
here	O
max	O
we	O
are	O
still	O
missing	O
a	O
few	O
details	O
to	O
use	O
rprop	O
in	O
practice	O
a	O
few	O
minor	O
issues	O
remain	O
unanswered	O
namely	O
how	O
large	O
are	O
and	O
how	O
much	O
are	O
learning	O
rates	O
reinforced	O
or	O
weakened	O
how	O
to	O
choose	O
how	O
are	O
the	O
weight-specific	O
learning	O
rates	O
what	O
are	O
the	O
upper	O
and	O
lower	O
bounds	O
min	O
and	O
max	O
for	O
ij	O
set	O
we	O
now	O
answer	O
these	O
questions	O
with	O
a	O
quick	O
motivation	O
the	O
initial	O
value	O
for	O
the	O
learning	O
rates	O
should	O
be	O
somewhere	O
in	O
the	O
order	O
of	O
the	O
initialization	O
of	O
the	O
weights	O
has	O
proven	O
to	O
be	O
a	O
good	O
choice	O
the	O
authors	O
of	O
the	O
rprop	O
paper	O
explain	O
in	O
an	O
obvious	O
way	O
that	O
this	O
value	O
as	O
long	O
as	O
it	O
is	O
positive	O
and	O
without	O
an	O
exorbitantly	O
high	O
absolute	O
value	O
does	O
not	O
need	O
to	O
be	O
dealt	O
with	O
very	O
critically	O
as	O
it	O
will	O
be	O
quickly	O
overridden	O
by	O
the	O
automatic	O
adaptation	O
anyway	O
equally	O
uncritical	O
is	O
max	O
for	O
which	O
they	O
recommend	O
without	O
further	O
mathematical	O
justification	O
a	O
value	O
of	O
which	O
is	O
used	O
throughout	O
most	O
of	O
the	O
literature	O
one	O
can	O
set	O
this	O
parameter	O
to	O
lower	O
values	O
in	O
order	O
to	O
allow	O
only	O
very	O
cautious	O
updates	O
small	O
update	O
steps	O
should	O
be	O
allowed	O
in	O
any	O
case	O
so	O
we	O
set	O
min	O
protipp	O
since	O
the	O
ij	O
can	O
be	O
changed	O
only	O
by	O
multiplication	O
would	O
be	O
a	O
rather	O
suboptimal	O
initialization	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
now	O
we	O
have	O
left	O
only	O
the	O
parameters	O
and	O
let	O
us	O
start	O
with	O
if	O
this	O
value	O
is	O
used	O
we	O
have	O
skipped	O
a	O
minimum	O
from	O
which	O
we	O
do	O
not	O
know	O
where	O
exactly	O
it	O
lies	O
on	O
the	O
skipped	O
track	O
analogous	O
to	O
the	O
procedure	O
of	O
binary	B
search	O
where	O
the	O
target	B
object	O
is	O
often	O
skipped	O
as	O
well	O
we	O
assume	O
it	O
was	O
in	O
the	O
middle	O
of	O
the	O
skipped	O
track	O
so	O
we	O
need	O
to	O
halve	O
the	O
learning	B
rate	I
which	O
is	O
why	O
the	O
canonical	O
choice	O
is	O
being	O
selected	O
if	O
the	O
value	O
of	O
is	O
used	O
learning	O
rates	O
shall	O
be	O
increased	O
with	O
caution	O
here	O
we	O
cannot	O
generalize	O
the	O
principle	O
of	O
binary	B
search	O
and	O
simply	O
use	O
the	O
value	O
otherwise	O
the	O
learning	B
rate	I
update	O
will	O
end	O
up	O
consisting	O
almost	O
exclusively	O
of	O
changes	O
in	O
direction	O
independent	O
of	O
the	O
particular	O
problems	B
a	O
value	O
of	O
has	O
proven	O
to	O
be	O
promising	O
slight	O
changes	O
of	O
this	O
value	O
have	O
not	O
significantly	O
affected	O
the	O
rate	O
of	O
convergence	O
this	O
fact	O
allowed	O
for	O
setting	O
this	O
value	O
as	O
a	O
constant	O
as	O
well	O
with	O
advancing	O
computational	O
capabilities	O
of	O
computers	O
one	O
can	O
observe	O
a	O
more	O
and	O
more	O
widespread	O
distribution	O
of	O
networks	O
that	O
consist	O
of	O
a	O
big	O
number	O
of	O
layers	O
i	O
e	O
deep	B
networks	I
for	O
such	O
networks	O
it	O
is	O
crucial	O
to	O
prefer	O
rprop	O
over	O
the	O
original	O
backpropagation	B
because	O
backprop	O
as	O
already	O
indicated	O
learns	O
very	O
slowly	O
at	O
weights	O
wich	O
are	O
far	O
from	O
the	O
output	B
layer	O
for	O
problems	B
with	O
a	O
smaller	O
number	O
of	O
layers	O
i	O
would	O
recommend	O
testing	O
the	O
more	O
widespread	O
backpropagation	B
both	O
o	O
ine	O
and	O
online	B
learning	O
and	O
the	O
less	O
common	O
rprop	O
equivalently	O
in	O
snipe	O
resilient	O
backpropasnipe	O
gation	O
is	O
supported	O
via	O
the	O
method	O
trainresilientbackpropagation	O
of	O
the	O
class	O
neuralnetwork	O
furthermore	O
you	O
can	O
also	O
use	O
an	O
additional	O
improvement	B
to	O
resilient	O
propagation	O
which	O
is	O
however	O
not	O
dealt	O
with	O
in	O
this	O
work	O
there	O
are	O
getters	O
and	O
setters	O
for	O
the	O
different	O
parameters	O
of	O
rprop	O
backpropagation	B
has	O
often	O
been	O
extended	O
and	O
altered	O
besides	O
rprop	O
backpropagation	B
has	O
often	O
been	O
extended	O
many	O
of	O
these	O
extensions	O
can	O
simply	O
be	O
implemented	O
as	O
optional	O
features	O
of	O
backpropagation	B
in	O
order	O
to	O
have	O
a	O
larger	O
scope	O
for	O
testing	O
in	O
the	O
following	O
i	O
want	O
to	O
briefly	O
describe	O
some	O
of	O
them	O
adding	O
momentum	B
to	O
learning	O
let	O
us	O
assume	O
to	O
descent	O
a	O
steep	O
slope	O
on	O
skis	O
what	O
prevents	O
us	O
from	O
immediately	O
stopping	O
at	O
the	O
edge	O
of	O
the	O
slope	O
to	O
the	O
plateau	O
exactly	O
our	O
momentum	B
with	O
backpropagation	B
the	O
momentum	B
term	I
is	O
responsible	O
for	O
the	O
fact	O
that	O
a	O
kind	O
of	O
moment	O
of	O
inertia	O
is	O
added	O
to	O
every	O
step	O
size	O
on	O
the	O
next	O
page	O
by	O
always	O
adding	O
a	O
fraction	O
of	O
the	O
previous	O
change	O
to	O
every	O
new	O
change	B
in	I
weight	B
pwijnow	O
opi	O
pj	O
pwijprevious	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
rprop	O
is	O
very	O
good	O
for	O
deep	B
networks	I
dkriesel	O
com	O
further	O
variations	O
and	O
extensions	O
to	O
backpropagation	B
moment	O
of	O
inertia	O
of	O
course	O
this	O
notation	O
is	O
only	O
used	O
for	O
a	O
better	O
understanding	O
generally	O
as	O
already	O
defined	O
by	O
the	O
concept	O
of	O
time	O
when	O
referring	O
to	O
the	O
current	O
cycle	O
as	O
then	O
the	O
previous	O
cycle	O
is	O
identified	O
by	O
which	O
is	O
continued	O
successively	O
and	O
now	O
we	O
come	O
to	O
the	O
formal	O
definition	O
of	O
the	O
momentum	B
term	I
definition	O
term	O
the	O
variation	O
of	O
backpropagation	B
by	O
means	O
of	O
the	O
momentum	B
term	I
is	O
defined	O
as	O
follows	O
wijt	O
oi	O
j	O
wijt	O
we	O
accelerate	O
on	O
plateaus	O
quasistandstill	O
on	O
plateaus	O
and	O
slow	O
down	O
on	O
craggy	O
surfaces	O
oscillations	O
moreover	O
the	O
effect	O
of	O
inertia	O
can	O
be	O
varied	O
via	O
the	O
prefactor	O
common	O
values	O
are	O
between	O
und	O
additionally	O
the	O
momentum	B
enables	O
the	O
positive	O
effect	O
that	O
our	O
skier	O
swings	O
back	O
and	O
forth	O
several	O
times	O
in	O
a	O
minimum	O
and	O
finally	O
lands	O
in	O
the	O
minimum	O
despite	O
its	O
nice	O
one-dimensional	O
appearance	O
the	O
otherwise	O
very	O
rare	O
error	O
of	O
leaving	O
good	O
minima	O
unfortunately	O
occurs	O
more	O
frequently	O
because	O
of	O
the	O
momentum	B
term	I
which	O
means	O
that	O
this	O
is	O
again	O
no	O
optimal	O
solution	O
we	O
are	O
by	O
now	O
accustomed	O
to	O
this	O
condition	O
flat	O
spot	O
elimination	O
prevents	O
neurons	O
from	O
getting	O
stuck	O
it	O
must	O
be	O
pointed	O
out	O
that	O
with	O
the	O
hyperbolic	B
tangent	I
as	O
well	O
as	O
with	O
the	O
fermi	B
figure	O
we	O
want	O
to	O
execute	O
the	O
gradient	B
descent	I
like	O
a	O
skier	O
crossing	O
a	O
slope	O
who	O
would	O
hardly	O
stop	O
immediately	O
at	O
the	O
edge	O
to	O
the	O
plateau	O
neurons	O
get	O
stuck	O
function	O
the	O
derivative	O
outside	O
of	O
the	O
close	O
proximity	O
of	O
is	O
nearly	O
this	O
results	O
in	O
the	O
fact	O
that	O
it	O
becomes	O
very	O
difficult	O
to	O
move	O
neurons	O
away	O
from	O
the	O
limits	O
of	O
the	O
activation	B
spots	O
which	O
could	O
extremely	O
extend	O
the	O
learning	O
time	O
this	O
problem	O
can	O
be	O
dealt	O
with	O
by	O
modifying	O
the	O
derivative	O
for	O
example	O
by	O
adding	O
a	O
constant	O
which	O
is	O
called	O
flat	O
spot	O
elimination	O
or	O
more	O
colloquial	O
fudging	O
it	O
is	O
an	O
interesting	O
observation	O
that	O
success	O
has	O
also	O
been	O
achieved	O
by	O
using	O
derivatives	O
defined	O
as	O
constants	O
a	O
nice	O
example	O
making	O
use	O
of	O
this	O
effect	O
is	O
the	O
fast	O
hyperbolic	B
tangent	I
approximation	B
by	O
anguita	B
et	O
al	O
introduced	O
in	O
section	O
on	O
page	O
in	O
the	O
outer	O
regions	O
of	O
it	O
s	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
well	O
approximated	O
and	O
accelerated	O
derivative	O
it	O
makes	O
use	O
of	O
a	O
small	O
constant	O
weight	B
decay	O
punishment	O
of	O
large	O
weights	O
the	O
second	O
derivative	O
can	O
be	O
used	O
too	O
according	O
to	O
david	O
parker	O
second	B
order	I
backpropagation	B
also	O
usese	O
the	O
second	O
gradient	B
i	O
e	O
the	O
second	O
multi-dimensional	O
derivative	O
of	O
the	O
error	B
function	I
to	O
obtain	O
more	O
precise	B
estimates	O
of	O
the	O
correct	O
wij	O
even	O
higher	O
derivatives	O
only	O
rarely	O
improve	O
the	O
estimations	O
thus	O
less	O
training	O
cycles	O
are	O
needed	O
but	O
those	O
require	O
much	O
more	O
computational	O
effort	O
in	O
general	O
we	O
use	O
further	O
derivatives	O
hessian	O
matrices	O
since	O
the	O
functions	O
are	O
multidimensional	O
for	O
higher	O
order	O
methods	O
as	O
expected	O
the	O
procedures	O
reduce	O
the	O
number	O
of	O
learning	O
epochs	O
but	O
significantly	O
increase	O
the	O
computational	O
effort	O
of	O
the	O
individual	O
epochs	O
so	O
in	O
the	O
end	O
these	O
procedures	O
often	O
need	O
more	O
learning	O
time	O
than	O
backpropagation	B
the	O
quickpropagation	B
learning	O
procedure	O
uses	O
the	O
second	O
derivative	O
of	O
the	O
error	O
propagation	O
and	O
locally	O
understands	O
the	O
error	B
function	I
to	O
be	O
a	O
parabola	O
we	O
analytically	O
determine	O
the	O
vertex	O
the	O
lowest	O
point	O
of	O
the	O
said	O
parabola	O
and	O
directly	O
jump	O
to	O
this	O
point	O
thus	O
this	O
learning	O
procedure	O
is	O
a	O
second-order	O
procedure	O
of	O
course	O
this	O
does	O
not	O
work	O
with	O
error	O
surfaces	O
that	O
cannot	O
locally	O
be	O
approximated	O
by	O
a	O
parabola	O
it	O
is	O
not	O
always	O
possible	O
to	O
directly	O
say	O
whether	O
this	O
is	O
the	O
case	O
the	O
weight	B
decay	O
according	O
to	O
paul	O
werbos	O
is	O
a	O
modification	O
that	O
extends	O
the	O
error	O
by	O
a	O
term	O
punishing	O
large	O
weights	O
so	O
the	O
error	O
under	O
weight	B
decay	O
errwd	O
does	O
not	O
only	O
increase	O
proportionally	O
to	O
the	O
actual	O
error	O
but	O
also	O
proportionally	O
to	O
the	O
square	O
of	O
the	O
weights	O
as	O
a	O
result	O
the	O
network	O
is	O
keeping	O
the	O
weights	O
small	O
during	O
learning	O
errwd	O
err	O
x	O
w	O
w	O
punishment	O
this	O
approach	O
is	O
inspired	O
by	O
nature	O
where	O
synaptic	O
weights	O
cannot	O
become	O
infinitely	O
strong	O
as	O
well	O
additionally	O
due	O
to	O
these	O
small	O
weights	O
the	O
error	B
function	I
often	O
shows	O
weaker	O
fluctuations	O
allowing	O
easier	O
and	O
more	O
controlled	O
learning	O
the	O
prefactor	O
again	O
resulted	O
from	O
simple	O
pragmatics	O
the	O
factor	O
controls	O
the	O
strength	O
of	O
punishment	O
values	O
from	O
to	O
are	O
often	O
used	O
here	O
keep	O
weights	O
small	O
cutting	O
networks	O
down	O
pruning	B
and	O
optimal	B
brain	B
damage	I
if	O
we	O
have	O
executed	O
the	O
weight	B
decay	O
long	O
enough	O
and	O
notice	O
that	O
for	O
a	O
neuron	B
in	O
the	O
input	B
layer	O
all	O
successor	O
weights	O
are	O
or	O
close	O
to	O
we	O
can	O
remove	O
the	O
neuron	B
prune	O
the	O
network	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
initial	O
configuration	O
of	O
a	O
multilayer	B
perceptron	B
hence	O
losing	O
this	O
neuron	B
and	O
some	O
weights	O
and	O
thereby	O
reduce	O
the	O
possibility	O
that	O
the	O
network	O
will	O
memorize	O
this	O
procedure	O
is	O
called	O
pruning	B
such	O
a	O
method	O
to	O
detect	O
and	O
delete	O
unnecessary	O
weights	O
and	O
neurons	O
is	O
referred	O
to	O
as	O
optimal	B
brain	B
damage	I
i	O
only	O
want	O
to	O
describe	O
it	O
briefly	O
the	O
mean	O
error	O
per	O
output	B
neuron	B
is	O
composed	O
of	O
two	O
competing	O
terms	O
while	O
one	O
term	O
as	O
usual	O
considers	O
the	O
difference	O
between	O
output	B
and	O
teaching	B
input	B
the	O
other	O
one	O
tries	O
to	O
a	O
weight	B
towards	O
if	O
a	O
weight	B
is	O
strongly	O
needed	O
to	O
minimize	O
the	O
error	O
the	O
first	O
term	O
will	O
win	O
if	O
this	O
is	O
not	O
the	O
case	O
the	O
second	O
term	O
will	O
win	O
neurons	O
which	O
only	O
have	O
zero	O
weights	O
can	O
be	O
pruned	O
again	O
in	O
the	O
end	O
there	O
are	O
many	O
other	O
variations	O
of	O
backprop	O
and	O
whole	O
books	O
only	O
about	O
this	O
subject	O
but	O
since	O
my	O
aim	O
is	O
to	O
offer	O
an	O
overview	O
of	O
neural	O
networks	O
i	O
just	O
want	O
to	O
mention	O
the	O
variations	O
above	O
as	O
a	O
motivation	O
to	O
read	O
on	O
for	O
some	O
of	O
these	O
extensions	O
it	O
is	O
obvious	O
that	O
they	O
cannot	O
only	O
be	O
applied	O
to	O
feedforward	B
networks	O
with	O
backpropagation	B
learning	O
procedures	O
we	O
have	O
gotten	O
to	O
know	O
backpropagation	B
and	O
feedforward	B
topology	B
now	O
we	O
have	O
to	O
learn	O
how	O
to	O
build	O
a	O
neural	B
network	I
it	O
is	O
of	O
course	O
impossible	O
to	O
fully	O
communicate	O
this	O
experience	O
in	O
the	O
framework	O
of	O
this	O
work	O
to	O
obtain	O
at	O
least	O
some	O
of	O
this	O
knowledge	O
i	O
now	O
advise	O
you	O
to	O
deal	O
with	O
some	O
of	O
the	O
exemplary	O
problems	B
from	O
getting	O
started	O
initial	O
configuration	O
of	O
a	O
multilayer	B
perceptron	B
after	O
having	O
discussed	O
the	O
backpropagation	B
of	I
error	I
learning	O
procedure	O
and	O
knowing	O
how	O
to	O
train	O
an	O
existing	O
network	O
it	O
would	O
be	O
useful	O
to	O
consider	O
how	O
to	O
implement	O
such	O
a	O
network	O
number	O
of	O
layers	O
two	O
or	O
three	O
may	O
often	O
do	O
the	O
job	O
but	O
more	O
are	O
also	O
used	O
let	O
us	O
begin	O
with	O
the	O
trivial	O
circumstance	O
that	O
a	O
network	O
should	O
have	O
one	O
layer	O
of	O
input	B
neurons	O
and	O
one	O
layer	O
of	O
output	B
neurons	O
which	O
results	O
in	O
at	O
least	O
two	O
layers	O
additionally	O
we	O
need	O
as	O
we	O
have	O
already	O
learned	O
during	O
the	O
examination	O
of	O
linear	B
separability	I
at	O
least	O
one	O
hidden	B
layer	O
of	O
neurons	O
if	O
our	O
problem	O
is	O
not	O
linearly	O
separable	O
is	O
as	O
we	O
have	O
seen	O
very	O
likely	O
it	O
is	O
possible	O
as	O
already	O
mentioned	O
to	O
mathematically	O
prove	O
that	O
this	O
mlp	O
with	O
one	O
hidden	B
neuron	B
layer	O
is	O
already	O
capable	O
of	O
approximating	O
arbitrary	O
functions	O
with	O
any	O
accuracy	O
but	O
it	O
is	O
necessary	O
not	O
only	O
to	O
discuss	O
the	O
representability	B
of	O
a	O
problem	O
by	O
means	O
of	O
a	O
perceptron	B
but	O
also	O
the	O
learnability	B
representability	B
means	O
that	O
a	O
perceptron	B
can	O
in	O
principle	O
realize	O
note	O
we	O
have	O
not	O
indicated	O
the	O
number	O
of	O
neurons	O
in	O
the	O
hidden	B
layer	O
we	O
only	O
mentioned	O
the	O
hypothetical	O
possibility	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
a	O
mapping	O
but	O
learnability	B
means	O
that	O
we	O
are	O
also	O
able	O
to	O
teach	O
it	O
in	O
this	O
respect	O
experience	O
shows	O
that	O
two	O
hidden	B
neuron	B
layers	O
three	O
trainable	O
weight	B
layers	O
can	O
be	O
very	O
useful	O
to	O
solve	O
a	O
problem	O
since	O
many	O
problems	B
can	O
be	O
represented	O
by	O
a	O
hidden	B
layer	O
but	O
are	O
very	O
difficult	O
to	O
learn	O
one	O
should	O
keep	O
in	O
mind	O
that	O
any	O
additional	O
layer	O
generates	O
additional	O
subminima	O
of	O
the	O
error	B
function	I
in	O
which	O
we	O
can	O
get	O
stuck	O
all	O
these	O
things	O
considered	O
a	O
promising	O
way	O
is	O
to	O
try	O
it	O
with	O
one	O
hidden	B
layer	O
at	O
first	O
and	O
if	O
that	O
fails	O
retry	O
with	O
two	O
layers	O
only	O
if	O
that	O
fails	O
one	O
should	O
consider	O
more	O
layers	O
however	O
given	O
the	O
increasing	O
calculation	O
power	O
of	O
current	O
computers	O
deep	B
networks	I
with	O
a	O
lot	O
of	O
layers	O
are	O
also	O
used	O
with	O
success	O
the	O
number	O
of	O
neurons	O
has	O
to	O
be	O
tested	O
the	O
number	O
of	O
neurons	O
from	O
input	B
and	O
output	B
layer	O
where	O
the	O
number	O
of	O
input	B
and	O
output	B
neurons	O
is	O
already	O
defined	O
by	O
the	O
problem	O
statement	O
principally	O
corresponds	O
to	O
the	O
number	O
of	O
free	O
parameters	O
of	O
the	O
problem	O
to	O
be	O
represented	O
since	O
we	O
have	O
already	O
discussed	O
the	O
network	O
capacity	O
with	O
respect	O
to	O
memorizing	O
or	O
a	O
too	O
imprecise	O
problem	O
representation	O
it	O
is	O
clear	O
that	O
our	O
goal	O
is	O
to	O
have	O
as	O
few	O
free	O
parameters	O
as	O
possible	O
but	O
as	O
many	O
as	O
necessary	O
but	O
we	O
also	O
know	O
that	O
there	O
is	O
no	O
standard	O
solution	O
for	O
the	O
question	O
of	O
how	O
many	O
neurons	O
should	O
be	O
used	O
thus	O
the	O
most	O
useful	O
approach	O
is	O
to	O
initially	O
train	O
with	O
only	O
a	O
few	O
neurons	O
and	O
to	O
repeatedly	O
train	O
new	O
networks	O
with	O
more	O
neurons	O
until	O
the	O
result	O
significantly	O
improves	O
and	O
particularly	O
the	O
generalization	B
performance	O
is	O
not	O
affected	O
approach	O
selecting	O
an	O
activation	B
function	I
another	O
very	O
important	O
parameter	O
for	O
the	O
way	O
of	O
information	B
processing	I
of	O
a	O
neural	B
network	I
is	O
the	O
selection	B
of	I
an	O
activation	B
function	I
the	O
activation	B
function	I
for	O
input	B
neurons	O
is	O
fixed	O
to	O
the	O
identity	B
function	O
since	O
they	O
do	O
not	O
process	O
information	O
the	O
first	O
question	O
to	O
be	O
asked	O
is	O
whether	O
we	O
actually	O
want	O
to	O
use	O
the	O
same	O
activation	B
function	I
in	O
the	O
hidden	B
layer	O
and	O
in	O
the	O
ouput	O
layer	O
no	O
one	O
prevents	O
us	O
from	O
choosing	O
different	O
functions	O
generally	O
the	O
activation	B
function	I
is	O
the	O
same	O
for	O
all	O
hidden	B
neurons	O
as	O
well	O
as	O
for	O
the	O
output	B
neurons	O
respectively	O
for	O
tasks	O
of	O
function	B
approximation	B
it	O
has	O
been	O
found	O
reasonable	O
to	O
use	O
the	O
hyperbolic	B
tangent	I
part	O
of	O
fig	O
on	O
page	O
as	O
activation	B
function	I
of	O
the	O
hidden	B
neurons	O
while	O
a	O
linear	O
activation	B
function	I
is	O
used	O
in	O
the	O
output	B
the	O
latter	O
is	O
absolutely	O
necessary	O
so	O
that	O
we	O
do	O
not	O
generate	O
a	O
limited	O
output	B
intervall	O
contrary	O
to	O
the	O
input	B
layer	O
which	O
uses	O
linear	O
activation	B
functions	O
as	O
well	O
the	O
output	B
layer	O
still	O
processes	O
information	O
because	O
it	O
has	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
the	O
encoding	O
problem	O
and	O
related	O
problems	B
threshold	O
values	O
however	O
linear	O
activation	B
functions	O
in	O
the	O
output	B
can	O
also	O
cause	O
huge	O
learning	O
steps	O
and	O
jumping	O
over	O
good	O
minima	O
in	O
the	O
error	O
surface	O
this	O
can	O
be	O
avoided	O
by	O
setting	O
the	O
learning	B
rate	I
to	O
very	O
small	O
values	O
in	O
the	O
output	B
layer	O
an	O
unlimited	O
output	B
interval	O
is	O
not	O
essential	O
for	O
pattern	B
recognition	I
if	O
the	O
hyperbolic	B
tangent	I
is	O
used	O
in	O
any	O
case	O
the	O
output	B
interval	O
will	O
be	O
a	O
bit	O
larger	O
unlike	O
with	O
the	O
hyperbolic	B
tangent	I
with	O
the	O
fermi	B
function	I
part	O
of	O
fig	O
on	O
the	O
following	O
page	O
it	O
is	O
difficult	O
to	O
learn	O
something	O
far	O
from	O
the	O
threshold	B
value	I
its	O
result	O
is	O
close	O
to	O
however	O
here	O
a	O
lot	O
of	O
freedom	O
is	O
given	O
for	O
selecting	O
an	O
activation	B
function	I
but	O
generally	O
the	O
disadvantage	O
of	O
sigmoid	O
functions	O
is	O
the	O
fact	O
that	O
they	O
hardly	O
learn	O
something	O
for	O
values	O
far	O
from	O
thei	O
threshold	B
value	I
unless	O
the	O
network	O
is	O
modified	O
range	O
of	O
random	O
values	O
could	O
be	O
the	O
interval	O
not	O
including	O
or	O
values	O
very	O
close	O
to	O
this	O
random	O
initialization	O
has	O
a	O
nice	O
side	O
effect	O
chances	O
are	O
that	O
the	O
average	O
of	O
network	O
inputs	O
is	O
close	O
to	O
a	O
value	O
that	O
hits	O
most	O
activation	B
functions	O
the	O
region	O
of	O
the	O
greatest	O
derivative	O
allowing	O
for	O
strong	O
learning	O
impulses	O
right	O
from	O
the	O
start	O
of	O
learning	O
a	O
in	O
snipe	O
weights	O
are	O
initialsnipe	O
synapse	O
initialized	O
randomly	O
the	O
maximum	O
ization	O
is	O
wanted	O
synapse	O
of	O
absolute	O
weight	B
value	O
initialized	O
at	O
set	O
in	O
a	O
neuralnetworkdescriptor	O
using	O
the	O
method	O
setsynapseinitialrange	O
a	O
random	O
can	O
be	O
the	O
encoding	O
problem	O
and	O
related	O
problems	B
weights	O
should	O
be	O
initialized	O
with	O
small	O
randomly	O
chosen	O
values	O
the	O
initialization	O
of	O
weights	O
is	O
not	O
as	O
trivial	O
as	O
one	O
might	O
think	O
if	O
they	O
are	O
simply	O
initialized	O
with	O
there	O
will	O
be	O
no	O
change	O
in	O
weights	O
at	O
all	O
if	O
they	O
are	O
all	O
initialized	O
by	O
the	O
same	O
value	O
they	O
will	O
all	O
change	O
equally	O
during	O
training	O
the	O
simple	O
solution	O
of	O
this	O
problem	O
is	O
called	O
symmetry	B
breaking	I
which	O
is	O
the	O
initialization	O
of	O
weights	O
with	O
small	O
random	O
values	O
the	O
generally	O
pattern	B
recognition	I
is	O
understood	O
as	O
a	O
special	O
case	O
of	O
function	B
approximation	B
with	O
a	O
few	O
discrete	B
output	B
possibilities	O
the	O
encoding	O
problem	O
is	O
a	O
classic	O
among	O
the	O
multilayer	B
perceptron	B
test	O
training	O
problems	B
in	O
our	O
mlp	O
we	O
have	O
an	O
input	B
layer	O
with	O
eight	O
neurons	O
an	O
output	B
layer	O
with	O
eight	O
neurons	O
and	O
one	O
hidden	B
layer	O
with	O
three	O
neurons	O
thus	O
this	O
network	O
represents	O
a	O
function	O
now	O
the	O
training	O
task	O
is	O
that	O
an	O
input	B
of	O
a	O
value	O
into	O
the	O
neuron	B
ij	O
should	O
lead	O
to	O
an	O
output	B
of	O
a	O
value	O
from	O
the	O
neuron	B
j	O
one	O
neuron	B
should	O
be	O
activated	O
which	O
results	O
in	O
training	O
samples	O
during	O
the	O
analysis	O
of	O
the	O
trained	O
network	O
we	O
will	O
see	O
that	O
the	O
network	O
with	O
the	O
random	O
initial	O
weights	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
figure	O
as	O
a	O
reminder	O
the	O
illustration	O
of	O
the	O
hyperbolic	B
tangent	I
and	O
the	O
fermi	B
function	I
the	O
fermi	B
function	I
was	O
expanded	O
by	O
a	O
temperature	B
parameter	I
the	O
original	O
fermi	B
function	I
is	O
thereby	O
represented	O
by	O
dark	O
colors	O
the	O
temperature	B
parameter	I
of	O
the	O
modified	O
fermi	B
functions	O
are	O
ordered	O
ascending	O
by	O
steepness	O
and	O
hidden	B
neurons	O
represents	O
some	O
kind	O
of	O
binary	B
encoding	O
and	O
that	O
the	O
above	O
mapping	O
is	O
possible	O
training	O
time	O
epochs	O
thus	O
our	O
network	O
is	O
a	O
machine	O
in	O
which	O
the	O
input	B
is	O
first	O
encoded	O
and	O
afterwards	O
decoded	O
again	O
analogously	O
we	O
can	O
train	O
a	O
encoding	O
problem	O
but	O
is	O
it	O
possible	O
to	O
improve	O
the	O
efficiency	O
of	O
this	O
procedure	O
could	O
there	O
be	O
for	O
example	O
a	O
or	O
an	O
network	O
yes	O
even	O
that	O
is	O
possible	O
since	O
the	O
network	O
does	O
not	O
depend	O
on	O
binary	B
encodings	O
thus	O
an	O
network	O
is	O
sufficient	O
for	O
our	O
problem	O
but	O
the	O
encoding	O
of	O
the	O
network	O
is	O
far	O
more	O
difficult	O
to	O
understand	O
on	O
the	O
next	O
page	O
and	O
the	O
training	O
of	O
the	O
networks	O
requires	O
a	O
lot	O
more	O
time	O
the	O
static	O
method	O
snipe	O
getencodersamplelesson	O
in	O
the	O
class	O
trainingsamplelesson	O
allows	O
for	O
creating	O
simple	O
training	O
sample	O
lessons	O
of	O
arbitrary	O
dimensionality	O
for	O
encoder	O
problems	B
like	O
the	O
above	O
an	O
network	O
however	O
does	O
not	O
work	O
since	O
the	O
possibility	O
that	O
the	O
output	B
of	O
one	O
neuron	B
is	O
compensated	O
by	O
another	O
one	O
is	O
essential	O
and	O
if	O
there	O
is	O
only	O
one	O
hidden	B
neuron	B
there	O
is	O
certainly	O
no	O
compensatory	O
neuron	B
exercises	O
exercise	O
fig	O
on	O
page	O
shows	O
a	O
small	O
network	O
for	O
the	O
boolean	O
functions	O
and	O
and	O
or	O
write	O
tables	O
with	O
all	O
computational	O
parameters	O
of	O
neural	O
networks	O
network	B
input	B
activation	B
etc	O
perform	O
the	O
calculations	O
for	O
the	O
four	O
possible	O
inputs	O
of	O
the	O
networks	O
and	O
write	O
down	O
the	O
values	O
of	O
these	O
variables	O
for	O
each	O
input	B
do	O
the	O
same	O
for	O
the	O
xor	O
network	O
on	O
page	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
tangent	O
function	O
with	O
temperature	B
parameter	I
dkriesel	O
com	O
the	O
encoding	O
problem	O
and	O
related	O
problems	B
exercise	O
list	O
all	O
boolean	O
functions	O
that	O
are	O
linearly	O
separable	O
and	O
characterize	O
them	O
exactly	O
list	O
those	O
that	O
are	O
not	O
linearly	O
separable	O
and	O
characterize	O
them	O
exactly	O
too	O
exercise	O
a	O
simple	O
network	O
shall	O
be	O
trained	O
with	O
one	O
single	O
pattern	O
by	O
means	O
of	O
backpropagation	B
of	I
error	I
and	O
verify	O
if	O
the	O
error	O
err	O
errp	O
converges	O
and	O
if	O
so	O
at	O
what	O
value	O
how	O
does	O
the	O
error	O
curve	O
look	O
like	O
let	O
the	O
pattern	O
t	O
be	O
defined	O
by	O
p	O
and	O
t	O
randomly	O
initalize	O
the	O
weights	O
in	O
the	O
interval	O
exercise	O
a	O
one-stage	O
perceptron	B
with	O
two	O
input	B
neurons	O
bias	B
neuron	B
and	O
binary	B
threshold	I
function	I
as	O
activation	B
function	I
divides	O
the	O
two-dimensional	O
space	O
into	O
two	O
regions	O
by	O
means	O
of	O
a	O
straight	O
line	O
g	O
analytically	O
calculate	O
a	O
set	B
of	I
weight	B
values	O
for	O
such	O
a	O
perceptron	B
so	O
that	O
the	O
following	O
set	O
p	O
of	O
the	O
patterns	O
of	O
the	O
form	O
t	O
with	O
is	O
correctly	O
classified	O
p	O
figure	O
illustration	O
of	O
the	O
functionality	O
of	O
network	O
encoding	O
the	O
marked	O
points	O
represent	O
the	O
vectors	O
of	O
the	O
inner	O
neuron	B
activation	B
associated	O
to	O
the	O
samples	O
as	O
you	O
can	O
see	O
it	O
is	O
possible	O
to	O
find	O
inner	O
activation	B
formations	O
so	O
that	O
each	O
point	O
can	O
be	O
separated	O
from	O
the	O
rest	O
of	O
the	O
points	O
by	O
a	O
straight	O
line	O
the	O
illustration	O
shows	O
an	O
exemplary	O
separation	O
of	O
one	O
point	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
the	O
perceptron	B
backpropagation	B
and	O
its	O
variants	O
dkriesel	O
com	O
exercise	O
calculate	O
in	O
a	O
comprehensible	O
way	O
one	O
vector	O
w	O
of	O
all	O
changes	O
in	O
weight	B
by	O
means	O
of	O
the	O
backpropagation	B
of	I
error	I
procedure	O
with	O
let	O
a	O
mlp	O
with	O
bias	B
neuron	B
be	O
given	O
and	O
let	O
the	O
pattern	O
be	O
defined	O
by	O
p	O
t	O
for	O
all	O
weights	O
with	O
the	O
target	B
the	O
initial	O
value	O
of	O
the	O
weights	O
should	O
be	O
for	O
all	O
other	O
weights	O
the	O
initial	O
value	O
should	O
be	O
what	O
is	O
conspicuous	O
about	O
the	O
changes	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
radial	O
basis	B
functions	O
rbf	B
networks	O
approximate	O
functions	O
by	O
stretching	O
and	O
compressing	O
gaussian	O
bells	O
and	O
then	O
summing	O
them	O
spatially	O
shifted	O
description	O
of	O
their	O
functions	O
and	O
their	O
learning	O
process	O
comparison	O
with	O
multilayer	B
perceptrons	O
according	O
to	O
poggio	B
and	O
girosi	B
radial	O
basis	B
function	O
networks	O
networks	O
are	O
a	O
paradigm	O
of	O
neural	O
networks	O
which	O
was	O
developed	O
considerably	O
later	O
than	O
that	O
of	O
perceptrons	O
like	O
perceptrons	O
the	O
rbf	B
networks	O
are	O
built	O
in	O
layers	O
but	O
in	O
this	O
case	O
they	O
have	O
exactly	O
three	O
layers	O
i	O
e	O
only	O
one	O
single	O
layer	O
of	O
hidden	B
neurons	O
like	O
perceptrons	O
the	O
networks	O
have	O
a	O
feedforward	B
structure	O
and	O
their	O
layers	O
are	O
completely	O
linked	O
here	O
the	O
input	B
layer	O
again	O
does	O
not	O
participate	O
in	O
information	B
processing	I
the	O
rbf	B
networks	O
are	O
like	O
mlps	O
universal	B
function	O
approximators	O
despite	O
all	O
things	O
in	O
common	O
what	O
is	O
the	O
difference	O
between	O
rbf	B
networks	O
and	O
perceptrons	O
the	O
difference	O
lies	O
in	O
the	O
information	B
processing	I
itself	O
and	O
in	O
the	O
computational	O
rules	O
within	O
the	O
neurons	O
outside	O
of	O
the	O
input	B
layer	O
so	O
in	O
a	O
moment	O
we	O
will	O
define	O
a	O
so	O
far	O
unknown	O
type	O
of	O
neurons	O
components	O
and	O
structure	O
of	O
an	O
rbf	B
network	I
initially	O
we	O
want	O
to	O
discuss	O
colloquially	O
and	O
then	O
define	O
some	O
concepts	O
concerning	O
rbf	B
networks	O
output	B
neurons	O
in	O
an	O
rbf	B
network	I
the	O
output	B
neurons	O
only	O
contain	O
the	O
identity	B
as	O
activation	B
function	I
and	O
one	O
weighted	B
sum	I
as	O
propagation	B
function	I
thus	O
they	O
do	O
little	O
more	O
than	O
adding	O
all	O
input	B
values	O
and	O
returning	O
the	O
sum	O
hidden	B
neurons	O
are	O
also	O
called	O
rbf	B
neurons	O
well	O
as	O
the	O
layer	O
in	O
which	O
they	O
are	O
located	O
is	O
referred	O
to	O
as	O
rbf	B
layer	O
as	O
propagation	B
function	I
each	O
hidden	B
neuron	B
calculates	O
a	O
norm	O
that	O
represents	O
the	O
distance	O
between	O
the	O
input	B
to	O
the	O
network	O
and	O
the	O
so-called	O
position	O
of	O
the	O
neuron	B
this	O
is	O
inserted	O
into	O
a	O
radial	O
activation	B
input	B
is	O
linear	O
again	O
position	O
in	O
the	O
input	B
space	O
important	O
only	O
sums	O
up	O
chapter	O
radial	O
basis	B
functions	O
dkriesel	O
com	O
function	O
which	O
calculates	O
and	O
outputs	O
the	O
activation	B
of	O
the	O
neuron	B
definition	O
input	B
neuron	B
definition	O
and	O
representation	O
is	O
identical	O
to	O
the	O
definition	O
on	O
page	O
of	O
the	O
input	B
neuron	B
definition	O
of	B
an	I
rbf	B
neuron	B
the	O
center	O
ch	O
of	B
an	I
rbf	B
neuron	B
h	O
is	O
the	O
point	O
in	O
the	O
input	B
space	O
where	O
the	O
rbf	B
neuron	B
is	O
located	O
in	O
general	O
the	O
closer	O
the	O
input	B
vector	I
is	O
to	O
the	O
center	O
vector	O
of	B
an	I
rbf	B
neuron	B
the	O
higher	O
is	O
its	O
activation	B
definition	O
neuron	B
the	O
socalled	O
rbf	B
neurons	O
h	O
have	O
a	O
propagation	B
function	I
fprop	O
that	O
determines	O
the	O
distance	O
between	O
the	O
center	O
ch	O
of	O
a	O
neuron	B
and	O
the	O
input	B
vector	I
y	O
this	O
distance	O
represents	O
the	O
network	B
input	B
then	O
the	O
network	B
input	B
is	O
sent	O
through	O
a	O
radial	O
basis	B
function	O
fact	O
which	O
returns	O
the	O
activation	B
or	O
the	O
output	B
of	O
the	O
neuron	B
rbf	B
neurons	O
are	O
represented	O
by	O
the	O
symbol	O
wvut	O
pqrs	O
definition	O
output	B
neuron	B
rbf	B
output	B
neurons	O
use	O
the	O
weighted	B
sum	I
as	O
propagation	B
function	I
fprop	O
and	O
the	O
identity	B
as	O
activation	B
function	I
fact	O
they	O
are	O
represented	O
by	O
the	O
sym	O
gau	O
bolonml	O
hijk	O
definition	O
network	O
an	O
rbf	B
network	I
has	O
exactly	O
three	O
layers	O
in	O
the	O
following	O
order	O
the	O
input	B
layer	O
consisting	O
of	O
input	B
neurons	O
the	O
hidden	B
layer	O
called	O
rbf	B
layer	O
consisting	O
of	O
rbf	B
neurons	O
and	O
the	O
output	B
layer	O
consisting	O
of	O
layers	O
feedforward	B
rbf	B
output	B
neurons	O
each	O
layer	O
is	O
completely	O
linked	O
with	O
the	O
following	O
one	O
shortcuts	O
do	O
not	O
exist	O
on	O
the	O
next	O
page	O
it	O
is	O
a	O
feedforward	B
topology	B
the	O
connections	O
between	O
input	B
layer	O
and	O
rbf	B
layer	O
are	O
unweighted	O
i	O
e	O
they	O
only	O
transmit	O
the	O
input	B
the	O
connections	O
between	O
rbf	B
layer	O
and	O
output	B
layer	O
are	O
weighted	O
the	O
original	O
definition	O
of	O
an	O
rbf	B
network	I
only	O
referred	O
to	O
an	O
output	B
neuron	B
but	O
in	O
analogy	O
to	O
the	O
perceptrons	O
it	O
is	O
apparent	O
that	O
such	O
a	O
definition	O
can	O
be	O
generalized	O
a	O
bias	B
neuron	B
is	O
not	O
used	O
in	O
rbf	B
networks	O
the	O
set	B
of	I
input	B
neurons	O
shall	O
be	O
represented	O
by	O
i	O
the	O
set	B
of	I
hidden	B
neurons	O
by	O
h	O
o	O
h	O
and	O
the	O
set	B
of	I
output	B
neurons	O
by	O
o	O
therefore	O
the	O
inner	O
neurons	O
are	O
called	O
radial	O
basis	B
neurons	O
because	O
from	O
their	O
definition	O
follows	O
directly	O
that	O
all	O
input	B
vectors	O
with	O
the	O
same	O
distance	O
from	O
the	O
center	O
of	O
a	O
neuron	B
also	O
produce	O
the	O
same	O
output	B
value	O
on	O
page	O
information	B
processing	I
of	O
an	O
rbf	B
network	I
now	O
the	O
question	O
is	O
what	O
can	O
be	O
realized	O
by	O
such	O
a	O
network	O
and	O
what	O
is	O
its	O
purpose	O
let	O
us	O
go	O
over	O
the	O
rbf	B
network	I
from	O
top	O
to	O
bottom	O
an	O
rbf	B
network	I
receives	O
the	O
input	B
by	O
means	O
of	O
the	O
unweighted	O
connections	O
then	O
the	O
input	B
vector	I
is	O
sent	O
through	O
a	O
norm	O
so	O
that	O
the	O
result	O
is	O
a	O
scalar	O
this	O
scalar	O
by	O
the	O
way	O
can	O
only	O
be	O
positive	O
due	O
to	O
the	O
norm	O
is	O
processed	O
by	O
a	O
radial	O
basis	B
function	O
for	O
exam	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
information	B
processing	I
of	O
an	O
rbf	B
network	I
gau	O
gfed	O
gfed	O
shhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh	O
vllllllllllllllllllll	O
wvut	O
pqrs	O
wvut	O
pqrs	O
wvut	O
pqrs	O
wvut	O
pqrs	O
wvut	O
pqrs	O
thhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh	O
vmmmmmmmmmmmmmmmmmmmm	O
vmmmmmmmmmmmmmmmmmmmm	O
onml	O
hijk	O
onml	O
hijk	O
onml	O
hijk	O
gau	O
gau	O
gau	O
gau	O
ii	O
hh	O
figure	O
an	O
exemplary	O
rbf	B
network	I
with	O
two	O
input	B
neurons	O
five	O
hidden	B
neurons	O
and	O
three	O
output	B
neurons	O
the	O
connections	O
to	O
the	O
hidden	B
neurons	O
are	O
not	O
weighted	O
they	O
only	O
transmit	O
the	O
input	B
right	O
of	O
the	O
illustration	O
you	O
can	O
find	O
the	O
names	O
of	O
the	O
neurons	O
which	O
coincide	O
with	O
the	O
names	O
of	O
the	O
mlp	O
neurons	O
input	B
neurons	O
are	O
called	O
i	O
hidden	B
neurons	O
are	O
called	O
h	O
and	O
output	B
neurons	O
are	O
called	O
the	O
associated	O
sets	O
are	O
referred	O
to	O
as	O
i	O
h	O
and	O
o	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
v	O
s	O
v	O
t	O
v	O
chapter	O
radial	O
basis	B
functions	O
dkriesel	O
com	O
ging	O
compressing	O
and	O
removing	O
gaussian	O
bells	O
and	O
subsequently	O
accumulating	O
them	O
here	O
the	O
parameters	O
for	O
the	O
superposition	O
of	O
the	O
gaussian	O
bells	O
are	O
in	O
the	O
weights	O
of	O
the	O
connections	O
between	O
the	O
rbf	B
layer	O
and	O
the	O
output	B
layer	O
furthermore	O
the	O
network	O
architecture	O
offers	O
the	O
possibility	O
to	O
freely	O
define	O
or	O
train	O
height	O
and	O
width	O
of	O
the	O
gaussian	O
bells	O
due	O
to	O
which	O
the	O
network	O
paradigm	O
becomes	O
even	O
more	O
versatile	O
we	O
will	O
get	O
to	O
know	O
methods	O
and	O
approches	O
for	O
this	O
later	O
input	B
distance	O
gaussian	B
bell	I
sum	O
output	B
figure	O
let	O
ch	O
be	O
the	O
center	O
of	B
an	I
rbf	B
neuron	B
h	O
then	O
the	O
activation	B
function	I
facth	O
is	O
radially	O
symmetric	O
around	O
ch	O
information	B
processing	I
in	O
rbf	B
neurons	O
ple	O
by	O
a	O
gaussian	B
bell	I
on	O
the	O
next	O
page	O
the	O
output	B
values	O
of	O
the	O
different	O
neurons	O
of	O
the	O
rbf	B
layer	O
or	O
of	O
the	O
different	O
gaussian	O
bells	O
are	O
added	O
within	O
the	O
third	O
layer	O
basically	O
in	O
relation	O
to	O
the	O
whole	O
input	B
space	O
gaussian	O
bells	O
are	O
added	O
here	O
suppose	O
that	O
we	O
have	O
a	O
second	O
a	O
third	O
and	O
a	O
fourth	O
rbf	B
neuron	B
and	O
therefore	O
four	O
differently	O
located	O
centers	O
each	O
of	O
these	O
neurons	O
now	O
measures	O
another	O
distance	O
from	O
the	O
input	B
to	O
its	O
own	O
center	O
and	O
de	O
facto	O
provides	O
different	O
values	O
even	O
if	O
the	O
gaussian	B
bell	I
is	O
the	O
same	O
since	O
these	O
values	O
are	O
finally	O
simply	O
accumulated	O
in	O
the	O
output	B
layer	O
one	O
can	O
easily	O
see	O
that	O
any	O
surface	O
can	O
be	O
shaped	O
by	O
drag	O
rbf	B
neurons	O
process	O
information	O
by	O
using	O
norms	O
and	O
radial	O
basis	B
functions	O
at	O
first	O
let	O
us	O
take	O
as	O
an	O
example	O
a	O
simple	O
rbf	B
network	I
it	O
is	O
apparent	O
that	O
we	O
will	O
receive	O
a	O
one-dimensional	O
output	B
which	O
can	O
be	O
represented	O
as	O
a	O
function	O
on	O
the	O
facing	O
page	O
additionally	O
the	O
network	O
includes	O
the	O
centers	O
of	O
the	O
four	O
inner	O
neurons	O
and	O
therefore	O
it	O
has	O
gaussian	O
bells	O
which	O
are	O
finally	O
added	O
within	O
the	O
output	B
neuron	B
the	O
network	O
also	O
possesses	O
four	O
values	O
which	O
influence	O
the	O
width	O
of	O
the	O
gaussian	O
bells	O
on	O
the	O
contrary	O
the	O
height	O
of	O
the	O
gaussian	B
bell	I
is	O
influenced	O
by	O
the	O
subsequent	O
weights	O
since	O
the	O
individual	O
output	B
values	O
of	O
the	O
bells	O
are	O
multiplied	O
by	O
those	O
weights	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
information	B
processing	I
of	O
an	O
rbf	B
network	I
figure	O
two	O
individual	O
one-	O
or	O
two-dimensional	O
gaussian	O
bells	O
in	O
both	O
cases	O
holds	O
and	O
the	O
centers	O
of	O
the	O
gaussian	O
bells	O
lie	O
in	O
the	O
coordinate	O
origin	O
the	O
distance	O
r	O
to	O
the	O
center	O
is	O
simply	O
calculated	O
according	O
to	O
the	O
pythagorean	O
theorem	O
r	O
figure	O
four	O
different	O
gaussian	O
bells	O
in	O
one-dimensional	O
space	O
generated	O
by	O
means	O
of	O
rbf	B
neurons	O
are	O
added	O
by	O
an	O
output	B
neuron	B
of	O
the	O
rbf	B
network	I
the	O
gaussian	O
bells	O
have	O
different	O
heights	O
widths	O
and	O
positions	O
their	O
centers	O
are	O
located	O
at	O
the	O
widths	O
at	O
you	O
can	O
see	O
a	O
two-dimensional	O
example	O
in	O
fig	O
on	O
the	O
following	O
page	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
in	O
in	O
chapter	O
radial	O
basis	B
functions	O
dkriesel	O
com	O
gau	O
wvut	O
pqrs	O
gau	O
gau	O
wvut	O
pqrs	O
gau	O
wvut	O
pqrs	O
wvut	O
pqrs	O
vmmmmmmmmmmmmmmmmmmm	O
aaaaaaaaaa	O
onml	O
hijk	O
neurons	O
are	O
added	O
by	O
an	O
output	B
neuron	B
of	O
the	O
rbf	B
network	I
once	O
again	O
r	O
figure	O
four	O
different	O
gaussian	O
bells	O
in	O
two-dimensional	O
space	O
generated	O
by	O
means	O
of	O
rbf	B
applies	O
for	O
the	O
distance	O
the	O
heights	O
w	O
widths	O
and	O
centers	O
c	O
y	O
are	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
gaussian	O
of	O
the	O
gaussians	O
v	O
dkriesel	O
com	O
information	B
processing	I
of	O
an	O
rbf	B
network	I
since	O
we	O
use	O
a	O
norm	O
to	O
calculate	O
the	O
distance	O
between	O
the	O
input	B
vector	I
and	O
the	O
center	O
of	O
a	O
neuron	B
h	O
we	O
have	O
different	O
choices	O
often	O
the	O
euclidian	O
norm	O
is	O
chosen	O
to	O
calculate	O
the	O
distance	O
rh	O
ch	O
sx	O
i	O
i	O
remember	O
the	O
input	B
vector	I
was	O
referred	O
to	O
as	O
x	O
here	O
the	O
index	O
i	O
runs	O
through	O
the	O
input	B
neurons	O
and	O
thereby	O
through	O
the	O
input	B
vector	I
components	O
and	O
the	O
neuron	B
center	O
components	O
as	O
we	O
can	O
see	O
the	O
euclidean	B
distance	O
generates	O
the	O
squared	B
differences	O
of	O
all	O
vector	O
components	O
adds	O
them	O
and	O
extracts	O
the	O
root	O
of	O
the	O
sum	O
in	O
two-dimensional	O
space	O
this	O
corresponds	O
to	O
the	O
pythagorean	O
theorem	O
from	O
the	O
definition	O
of	O
a	O
norm	O
directly	O
follows	O
that	O
the	O
distance	O
can	O
only	O
be	O
positive	O
strictly	O
speaking	O
we	O
hence	O
only	O
use	O
the	O
positive	O
part	O
of	O
the	O
activation	B
function	I
by	O
the	O
way	O
activation	B
functions	O
other	O
than	O
the	O
gaussian	B
bell	I
are	O
possible	O
normally	O
functions	O
that	O
are	O
monotonically	O
decreasing	O
over	O
the	O
interval	O
are	O
chosen	O
now	O
that	O
we	O
know	O
the	O
distance	O
rh	O
between	O
the	O
input	B
vector	I
x	O
and	O
the	O
center	O
ch	O
of	O
the	O
rbf	B
neuron	B
h	O
this	O
distance	O
has	O
to	O
be	O
passed	O
through	O
the	O
activation	B
function	I
here	O
we	O
use	O
as	O
already	O
mentioned	O
a	O
gaussian	B
bell	I
h	O
h	O
factrh	O
e	O
activation	B
function	I
fact	O
and	O
hence	O
the	O
activation	B
functions	O
should	O
not	O
be	O
referred	O
to	O
as	O
fact	O
simultaneously	O
one	O
solution	O
would	O
be	O
to	O
number	O
the	O
activation	B
functions	O
like	O
facth	O
with	O
h	O
being	O
the	O
set	B
of	I
hidden	B
neurons	O
but	O
as	O
a	O
result	O
the	O
explanation	O
would	O
be	O
very	O
confusing	O
so	O
i	O
simply	O
use	O
the	O
name	O
fact	O
for	O
all	O
activation	B
functions	O
and	O
regard	O
and	O
c	O
as	O
variables	O
that	O
are	O
defined	O
for	O
individual	O
neurons	O
but	O
no	O
directly	O
included	O
in	O
the	O
activation	B
function	I
the	O
reader	O
will	O
certainly	O
notice	O
that	O
in	O
the	O
literature	O
the	O
gaussian	B
bell	I
is	O
often	O
normalized	O
by	O
a	O
multiplicative	O
factor	O
we	O
can	O
however	O
avoid	O
this	O
factor	O
because	O
we	O
are	O
multiplying	O
anyway	O
with	O
the	O
subsequent	O
weights	O
and	O
consecutive	O
multiplications	O
first	O
by	O
a	O
normalization	O
factor	O
and	O
then	O
by	O
the	O
connections	O
weights	O
would	O
only	O
yield	O
different	O
factors	O
there	O
we	O
do	O
not	O
need	O
this	O
factor	O
because	O
for	O
our	O
purpose	O
the	O
integral	O
of	O
the	O
gaussian	B
bell	I
must	O
not	O
always	O
be	O
and	O
therefore	O
simply	O
leave	O
it	O
out	O
some	O
analytical	O
thoughts	O
prior	O
to	O
the	O
training	O
the	O
output	B
y	O
of	O
an	O
rbf	B
output	B
neuron	B
results	O
from	O
combining	O
the	O
functions	O
of	B
an	I
rbf	B
neuron	B
to	O
wh	O
fact	O
ch	O
y	O
x	O
h	O
h	O
it	O
is	O
obvious	O
that	O
both	O
the	O
center	O
ch	O
and	O
the	O
width	O
h	O
can	O
be	O
seen	O
as	O
part	O
of	O
the	O
suppose	O
that	O
similar	O
to	O
the	O
multilayer	B
perceptron	B
we	O
have	O
a	O
set	O
p	O
that	O
contains	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
radial	O
basis	B
functions	O
dkriesel	O
com	O
training	O
samples	O
t	O
then	O
we	O
obtain	O
functions	O
of	O
the	O
form	O
wh	O
fact	O
ch	O
y	O
x	O
h	O
h	O
i	O
e	O
one	O
function	O
for	O
each	O
training	O
sample	O
of	O
course	O
with	O
this	O
effort	O
we	O
are	O
aiming	O
at	O
letting	O
the	O
output	B
y	O
for	O
all	O
training	O
patterns	O
p	O
converge	O
to	O
the	O
corresponding	O
teaching	B
input	B
t	O
weights	O
can	O
simply	O
be	O
computed	O
as	O
solution	O
of	O
a	O
system	O
of	O
equations	O
thus	O
we	O
have	O
equations	O
now	O
let	O
us	O
assume	O
that	O
the	O
widths	O
k	O
the	O
centers	O
ck	O
and	O
the	O
training	O
samples	O
p	O
including	O
the	O
teaching	B
input	B
t	O
are	O
given	O
we	O
are	O
looking	O
for	O
the	O
weights	O
wh	O
with	O
weights	O
for	O
one	O
output	B
neuron	B
thus	O
our	O
problem	O
can	O
be	O
seen	O
as	O
a	O
system	O
of	O
equations	O
since	O
the	O
only	O
thing	O
we	O
want	O
to	O
change	O
at	O
the	O
moment	O
are	O
the	O
weights	O
this	O
demands	O
a	O
distinction	O
of	O
cases	O
concerning	O
the	O
number	O
of	O
training	O
samples	O
and	O
the	O
number	O
of	O
rbf	B
neurons	O
if	O
the	O
number	O
of	O
rbf	B
neurons	O
equals	O
the	O
number	O
of	O
patterns	O
i	O
e	O
the	O
equation	O
can	O
be	O
reduced	O
to	O
a	O
matrix	O
multiplication	O
simply	O
calculate	O
weights	O
t	O
m	O
g	O
t	O
m	O
t	O
e	O
g	O
t	O
g	O
m	O
g	O
m	O
m	O
m	O
where	O
t	O
is	O
the	O
vector	O
of	O
the	O
teaching	O
inputs	O
for	O
all	O
training	O
samples	O
m	O
is	O
the	O
matrix	O
of	O
the	O
outputs	O
of	O
all	O
rbf	B
neurons	O
to	O
samples	O
the	O
matrix	O
is	O
squared	B
and	O
we	O
can	O
therefore	O
attempt	O
to	O
invert	O
it	O
g	O
is	O
the	O
vector	O
of	O
the	O
desired	O
weights	O
and	O
e	O
is	O
a	O
unit	O
matrix	O
with	O
the	O
same	O
size	O
as	O
g	O
mathematically	O
speaking	O
we	O
can	O
simply	O
calculate	O
the	O
weights	O
in	O
the	O
case	O
of	O
there	O
is	O
exactly	O
one	O
rbf	B
neuron	B
available	O
per	O
training	O
sample	O
this	O
means	O
that	O
the	O
network	O
exactly	O
meets	O
the	O
existing	O
nodes	O
after	O
having	O
calculated	O
the	O
weights	O
i	O
e	O
it	O
performs	O
a	O
precise	B
interpolation	O
to	O
calculate	O
such	O
an	O
equation	O
we	O
certainly	O
do	O
not	O
need	O
an	O
rbf	B
network	I
and	O
therefore	O
we	O
can	O
proceed	O
to	O
the	O
next	O
case	O
exact	O
interpolation	O
must	O
not	O
be	O
mistaken	O
for	O
the	O
memorizing	O
ability	O
mentioned	O
with	O
the	O
mlps	O
first	O
we	O
are	O
not	O
talking	O
about	O
the	O
training	O
of	O
rbf	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
information	B
processing	I
of	O
an	O
rbf	B
network	I
networks	O
at	O
the	O
moment	O
second	O
it	O
could	O
be	O
advantageous	O
for	O
us	O
and	O
might	O
in	O
fact	O
be	O
intended	O
if	O
the	O
network	O
exactly	O
interpolates	O
between	O
the	O
nodes	O
the	O
system	O
of	O
equations	O
is	O
under-determined	O
there	O
are	O
more	O
rbf	B
neurons	O
than	O
training	O
samples	O
certainly	O
this	O
case	O
i	O
e	O
normally	O
does	O
not	O
occur	O
very	O
often	O
in	O
this	O
case	O
there	O
is	O
a	O
huge	O
variety	O
of	O
solutions	O
which	O
we	O
do	O
not	O
need	O
in	O
such	O
detail	O
we	O
can	O
select	O
one	O
set	B
of	I
weights	O
out	O
of	O
many	O
obviously	O
possible	O
ones	O
but	O
most	O
interesting	O
for	O
further	O
discussion	O
is	O
the	O
case	O
if	O
there	O
are	O
significantly	O
more	O
training	O
samples	O
than	O
rbf	B
neurons	O
that	O
means	O
thus	O
we	O
again	O
want	O
to	O
use	O
the	O
generalization	B
capability	O
of	O
the	O
neural	B
network	I
if	O
we	O
have	O
more	O
training	O
samples	O
than	O
rbf	B
neurons	O
we	O
cannot	O
assume	O
that	O
every	O
training	O
sample	O
is	O
exactly	O
hit	O
so	O
if	O
we	O
cannot	O
exactly	O
hit	O
the	O
points	O
and	O
therefore	O
cannot	O
just	O
interpolate	O
as	O
in	O
the	O
aforementioned	O
ideal	O
case	O
with	O
we	O
must	O
try	O
to	O
find	O
a	O
function	O
that	O
approximates	O
our	O
training	B
set	I
p	O
as	O
closely	O
as	O
possible	O
as	O
with	O
the	O
mlp	O
we	O
try	O
to	O
reduce	O
the	O
sum	O
of	O
the	O
squared	B
error	O
to	O
a	O
minimum	O
how	O
do	O
we	O
continue	O
the	O
calculation	O
in	O
the	O
case	O
of	O
as	O
above	O
to	O
solve	O
the	O
system	O
of	O
equations	O
we	O
have	O
to	O
find	O
the	O
solution	O
m	O
of	O
a	O
matrix	O
multiplication	O
t	O
m	O
g	O
the	O
problem	O
is	O
that	O
this	O
time	O
we	O
cannot	O
invert	O
the	O
matrix	O
m	O
because	O
it	O
is	O
not	O
a	O
square	O
matrix	O
is	O
true	O
here	O
we	O
have	O
to	O
use	O
the	O
moore-penrose	B
pseudo	I
inverse	I
m	O
which	O
is	O
defined	O
by	O
m	O
t	O
m	O
m	O
t	O
although	O
the	O
moore-penrose	B
pseudo	I
inverse	I
is	O
not	O
the	O
inverse	O
of	O
a	O
matrix	O
it	O
can	O
be	O
used	O
similarly	O
in	O
this	O
we	O
get	O
equations	O
that	O
are	O
very	O
similar	O
to	O
those	O
in	O
the	O
case	O
of	O
t	O
m	O
g	O
m	O
t	O
m	O
m	O
g	O
m	O
t	O
e	O
g	O
m	O
t	O
g	O
another	O
reason	O
for	O
the	O
use	O
of	O
the	O
moore-penrose	B
pseudo	I
inverse	I
is	O
the	O
fact	O
that	O
it	O
minimizes	O
the	O
squared	B
error	O
is	O
our	O
goal	O
the	O
estimate	O
of	O
the	O
vector	O
g	O
in	O
equation	O
corresponds	O
to	O
the	O
gauss-markov	B
model	I
known	O
from	O
statistics	O
which	O
is	O
used	O
to	O
minimize	O
the	O
squared	B
error	O
in	O
the	O
aforementioned	O
equations	O
and	O
the	O
following	O
ones	O
please	O
do	O
not	O
mistake	O
the	O
t	O
in	O
m	O
t	O
the	O
transpose	O
of	O
the	O
matrix	O
m	O
for	O
the	O
t	O
of	O
the	O
vector	O
of	O
all	O
teaching	O
inputs	O
m	O
particularly	O
m	O
is	O
true	O
if	O
m	O
is	O
invertible	O
i	O
do	O
not	O
want	O
to	O
go	O
into	O
detail	O
of	O
the	O
reasons	O
for	O
they	O
these	O
circumstances	O
and	O
applications	O
of	O
m	O
can	O
easily	O
be	O
found	O
in	O
literature	O
for	O
linear	O
algebra	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
radial	O
basis	B
functions	O
dkriesel	O
com	O
the	O
generalization	B
on	O
several	O
outputs	O
is	O
trivial	O
and	O
not	O
quite	O
computationally	O
expensive	O
we	O
have	O
found	O
a	O
mathematically	O
exact	O
way	O
to	O
directly	O
calculate	O
the	O
weights	O
what	O
will	O
happen	O
if	O
there	O
are	O
several	O
output	B
neurons	O
i	O
e	O
with	O
o	O
being	O
as	O
usual	O
the	O
set	B
of	I
the	O
output	B
neurons	O
in	O
this	O
case	O
as	O
we	O
have	O
already	O
indicated	O
it	O
does	O
not	O
change	O
much	O
the	O
additional	O
output	B
neurons	O
have	O
their	O
own	O
set	B
of	I
weights	O
while	O
we	O
do	O
not	O
change	O
the	O
and	O
c	O
of	O
the	O
rbf	B
layer	O
thus	O
in	O
an	O
rbf	B
network	I
it	O
is	O
easy	O
for	O
given	O
and	O
c	O
to	O
realize	O
a	O
lot	O
of	O
output	B
neurons	O
since	O
we	O
only	O
have	O
to	O
calculate	O
the	O
individual	O
vector	O
of	O
weights	O
g	O
m	O
t	O
for	O
every	O
new	O
output	B
neuron	B
whereas	O
the	O
matrix	O
m	O
which	O
generally	O
requires	O
a	O
lot	O
of	O
computational	O
effort	O
always	O
stays	O
the	O
same	O
so	O
it	O
is	O
quite	O
inexpensive	O
at	O
least	O
concerning	O
the	O
computational	O
complexity	O
to	O
add	O
more	O
output	B
neurons	O
inexpensive	O
output	B
dimension	I
computational	O
effort	O
and	O
accuracy	O
for	O
realistic	O
problems	B
it	O
normally	O
applies	O
that	O
there	O
are	O
considerably	O
more	O
training	O
samples	O
than	O
rbf	B
neurons	O
i	O
e	O
you	O
can	O
without	O
any	O
difficulty	O
use	O
training	O
samples	O
if	O
you	O
like	O
theoretically	O
we	O
could	O
find	O
the	O
terms	O
for	O
the	O
mathematically	O
correct	O
solution	O
on	O
the	O
blackboard	O
a	O
very	O
long	O
time	O
but	O
such	O
calculations	O
often	O
seem	O
to	O
be	O
imprecise	O
m	O
complex	O
and	O
imprecise	O
and	O
very	O
time-consuming	O
inversions	O
require	O
a	O
lot	O
of	O
computational	O
effort	O
furthermore	O
our	O
moore-penrose	O
pseudoinverse	O
is	O
in	O
spite	O
of	O
numeric	O
stability	O
no	O
guarantee	O
that	O
the	O
output	B
vector	I
corresponds	O
to	O
the	O
teaching	O
vector	O
because	O
such	O
extensive	O
computations	O
can	O
be	O
prone	O
to	O
many	O
inaccuracies	O
even	O
though	O
the	O
calculation	O
is	O
mathematically	O
correct	O
our	O
computers	O
can	O
only	O
provide	O
us	O
with	O
very	O
good	O
approximations	O
of	O
the	O
pseudo-inverse	O
matrices	O
this	O
means	O
that	O
we	O
also	O
get	O
only	O
approximations	O
of	O
the	O
correct	O
weights	O
with	O
a	O
lot	O
of	O
accumulated	O
numerical	O
errors	O
and	O
therefore	O
only	O
an	O
approximation	B
very	O
rough	O
or	O
even	O
unrecognizable	O
of	O
the	O
desired	O
output	B
if	O
we	O
have	O
enough	O
computing	O
power	O
to	O
analytically	O
determine	O
a	O
weight	B
vector	I
we	O
should	O
use	O
it	O
nevertheless	O
only	O
as	O
an	O
initial	O
value	O
for	O
our	O
learning	O
process	O
which	O
leads	O
us	O
to	O
the	O
real	O
training	O
methods	O
but	O
otherwise	O
it	O
would	O
be	O
boring	O
wouldn	O
t	O
it	O
combinations	O
of	O
equation	O
system	O
and	O
gradient	B
strategies	O
are	O
useful	O
for	O
training	O
analogous	O
to	O
the	O
mlp	O
we	O
perform	O
a	O
gradient	B
descent	I
to	O
find	O
the	O
suitable	O
weights	O
by	O
means	O
of	O
the	O
already	O
well	O
known	O
delta	B
rule	I
here	O
backpropagation	B
is	O
unnecessary	O
since	O
we	O
only	O
have	O
to	O
train	O
one	O
single	O
retraining	O
delta	B
rule	I
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
training	O
of	O
rbf	B
networks	O
weight	B
layer	O
which	O
requires	O
less	O
computing	O
time	O
we	O
know	O
that	O
the	O
delta	B
rule	I
is	O
wh	O
oh	O
in	O
which	O
we	O
now	O
insert	O
as	O
follows	O
wh	O
y	O
factp	O
ch	O
here	O
again	O
i	O
explicitly	O
want	O
to	O
mention	O
that	O
it	O
is	O
very	O
popular	O
to	O
divide	O
the	O
training	O
into	O
two	O
phases	O
by	O
analytically	O
computing	O
a	O
set	B
of	I
weights	O
and	O
then	O
refining	O
it	O
by	O
training	O
with	O
the	O
delta	B
rule	I
there	O
is	O
still	O
the	O
question	O
whether	O
to	O
learn	O
o	O
ine	O
or	O
online	B
here	O
the	O
answer	O
is	O
similar	O
to	O
the	O
answer	O
for	O
the	O
multilayer	B
perceptron	B
initially	O
one	O
often	O
trains	O
online	B
movement	O
across	O
the	O
error	O
surface	O
then	O
after	O
having	O
approximated	O
the	O
solution	O
the	O
errors	O
are	O
once	O
again	O
accumulated	O
and	O
for	O
a	O
more	O
precise	B
approximation	B
one	O
trains	O
o	O
ine	O
in	O
a	O
third	O
learning	O
phase	O
however	O
similar	O
to	O
the	O
mlps	O
you	O
can	O
be	O
successful	O
by	O
using	O
many	O
methods	O
as	O
already	O
indicated	O
in	O
an	O
rbf	B
network	I
not	O
only	O
the	O
weights	O
between	O
the	O
hidden	B
and	O
the	O
output	B
layer	O
can	O
be	O
optimized	O
so	O
let	O
us	O
now	O
take	O
a	O
look	O
at	O
the	O
possibility	O
to	O
vary	O
and	O
c	O
training	O
in	O
phases	O
it	O
is	O
not	O
always	O
trivial	O
to	O
determine	O
centers	O
and	O
widths	O
of	O
rbf	B
neurons	O
it	O
is	O
obvious	O
that	O
the	O
approximation	B
accuracy	O
of	O
rbf	B
networks	O
can	O
be	O
increased	O
by	O
adapting	O
the	O
widths	O
and	O
positions	O
of	O
the	O
gaussian	O
bells	O
in	O
the	O
input	B
space	O
to	O
the	O
problem	O
that	O
needs	O
to	O
be	O
approximated	O
there	O
are	O
several	O
methods	O
to	O
deal	O
with	O
the	O
centers	O
c	O
and	O
the	O
widths	O
of	O
the	O
gaussian	O
bells	O
fixed	O
selection	O
the	O
centers	O
and	O
widths	O
can	O
be	O
selected	O
in	O
a	O
fixed	O
manner	O
and	O
regardless	O
of	O
the	O
training	O
samples	O
this	O
is	O
what	O
we	O
have	O
assumed	O
until	O
now	O
conditional	O
fixed	O
selection	O
again	O
centers	O
and	O
widths	O
are	O
selected	O
fixedly	O
but	O
we	O
have	O
previous	O
knowledge	O
about	O
the	O
functions	O
to	O
be	O
approximated	O
and	O
comply	O
with	O
it	O
vary	O
and	O
c	O
adaptive	O
to	O
the	O
learning	O
process	O
this	O
too	O
a	O
realization	O
of	O
is	O
definitely	O
the	O
most	O
elegant	O
variant	O
but	O
certainly	O
the	O
most	O
challenging	O
one	O
this	O
approach	O
will	O
not	O
be	O
discussed	O
in	O
this	O
chapter	O
but	O
it	O
can	O
be	O
found	O
in	O
connection	B
with	O
another	O
network	O
topology	B
fixed	O
selection	O
in	O
any	O
case	O
the	O
goal	O
is	O
to	O
cover	O
the	O
input	B
space	O
as	O
evenly	O
as	O
possible	O
here	O
widths	O
of	O
of	O
the	O
distance	O
between	O
the	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
radial	O
basis	B
functions	O
dkriesel	O
com	O
responsible	O
for	O
the	O
fact	O
that	O
six-	O
to	O
tendimensional	O
problems	B
in	O
rbf	B
networks	O
are	O
already	O
called	O
mlp	O
for	O
example	O
does	O
not	O
cause	O
any	O
problems	B
here	O
conditional	O
fixed	O
selection	O
suppose	O
that	O
our	O
training	O
samples	O
are	O
not	O
evenly	O
distributed	O
across	O
the	O
input	B
space	O
it	O
then	O
seems	O
obvious	O
to	O
arrange	O
the	O
centers	O
and	O
sigmas	O
of	O
the	O
rbf	B
neurons	O
by	O
means	O
of	O
the	O
pattern	O
distribution	O
so	O
the	O
training	O
patterns	O
can	O
be	O
analyzed	O
by	O
statistical	O
techniques	O
such	O
as	O
a	O
cluster	B
analysis	I
and	O
so	O
it	O
can	O
be	O
determined	O
whether	O
there	O
are	O
statistical	O
factors	O
according	O
to	O
which	O
we	O
should	O
distribute	O
the	O
centers	O
and	O
sigmas	O
on	O
the	O
facing	O
page	O
a	O
more	O
trivial	O
alternative	O
would	O
be	O
to	O
set	O
centers	O
on	O
positions	O
randomly	O
selected	O
from	O
the	O
set	B
of	I
patterns	O
so	O
this	O
method	O
would	O
allow	O
for	O
every	O
training	B
pattern	I
p	O
to	O
be	O
directly	O
in	O
the	O
center	O
of	O
a	O
neuron	B
on	O
the	O
next	O
page	O
this	O
is	O
not	O
yet	O
very	O
elegant	O
but	O
a	O
good	O
solution	O
when	O
time	O
is	O
an	O
issue	O
generally	O
for	O
this	O
method	O
the	O
widths	O
are	O
fixedly	O
selected	O
if	O
we	O
have	O
reason	O
to	O
believe	O
that	O
the	O
set	B
of	I
training	O
samples	O
is	O
clustered	O
we	O
can	O
use	O
clustering	O
methods	O
to	O
determine	O
them	O
there	O
are	O
different	O
methods	O
to	O
determine	O
clusters	B
in	O
an	O
arbitrarily	O
dimensional	O
set	B
of	I
points	O
we	O
will	O
be	O
introduced	O
to	O
some	O
of	O
them	O
in	O
excursus	O
a	O
one	O
neural	O
clustering	O
method	O
are	O
the	O
so-called	O
rolfs	O
and	O
self-organizing	O
maps	O
are	O
figure	O
example	O
for	O
an	O
even	O
coverage	O
of	O
a	O
two-dimensional	O
input	B
space	O
by	O
applying	O
radial	O
basis	B
functions	O
centers	O
can	O
be	O
selected	O
so	O
that	O
the	O
gaussian	O
bells	O
overlap	O
by	O
approx	O
the	O
closer	O
the	O
bells	O
are	O
set	O
the	O
more	O
precise	B
but	O
the	O
more	O
time-consuming	O
the	O
whole	O
thing	O
becomes	O
this	O
may	O
seem	O
to	O
be	O
very	O
inelegant	O
but	O
in	O
the	O
field	O
of	O
function	B
approximation	B
we	O
cannot	O
avoid	O
even	O
coverage	O
here	O
it	O
is	O
useless	O
if	O
the	O
function	O
to	O
be	O
approximated	O
is	O
precisely	O
represented	O
at	O
some	O
positions	O
but	O
at	O
other	O
positions	O
the	O
return	B
value	O
is	O
only	O
however	O
the	O
high	O
input	B
dimension	I
requires	O
a	O
great	O
many	O
rbf	B
neurons	O
which	O
increases	O
the	O
computational	O
effort	O
exponentially	O
with	O
the	O
dimension	O
and	O
is	O
it	O
is	O
apparent	O
that	O
a	O
gaussian	B
bell	I
is	O
mathematically	O
infinitely	O
wide	O
therefore	O
i	O
ask	O
the	O
reader	O
to	O
apologize	O
this	O
sloppy	O
formulation	O
input	B
dimension	I
very	O
expensive	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
training	O
of	O
rbf	B
networks	O
figure	O
example	O
of	O
an	O
uneven	O
coverage	O
of	O
a	O
two-dimensional	O
input	B
space	O
of	O
which	O
we	O
have	O
previous	O
knowledge	O
by	O
applying	O
radial	O
basis	B
functions	O
also	O
useful	O
in	O
connection	B
with	O
determining	O
the	O
position	O
of	O
rbf	B
neurons	O
using	O
rolfs	O
one	O
can	O
also	O
receive	O
indicators	O
for	O
useful	O
radii	O
of	O
the	O
rbf	B
neurons	O
learning	O
vector	O
quantisation	O
has	O
also	O
provided	O
good	O
results	O
all	O
these	O
methods	O
have	O
nothing	O
to	O
do	O
with	O
the	O
rbf	B
networks	O
themselves	O
but	O
are	O
only	O
used	O
to	O
generate	O
some	O
previous	O
knowledge	O
therefore	O
we	O
will	O
not	O
discuss	O
them	O
in	O
this	O
chapter	O
but	O
independently	O
in	O
the	O
indicated	O
chapters	O
another	O
approach	O
is	O
to	O
use	O
the	O
approved	O
methods	O
we	O
could	O
slightly	O
move	O
the	O
positions	O
of	O
the	O
centers	O
and	O
observe	O
how	O
our	O
error	B
function	I
err	O
is	O
changing	O
a	O
gradient	B
descent	I
as	O
already	O
known	O
from	O
the	O
mlps	O
figure	O
example	O
of	O
an	O
uneven	O
coverage	O
of	O
a	O
two-dimensional	O
input	B
space	O
by	O
applying	O
radial	O
basis	B
functions	O
the	O
widths	O
were	O
fixedly	O
selected	O
the	O
centers	O
of	O
the	O
neurons	O
were	O
randomly	O
distributed	O
throughout	O
the	O
training	O
patterns	O
this	O
distribution	O
can	O
certainly	O
lead	O
to	O
slightly	O
unrepresentative	O
results	O
which	O
can	O
be	O
seen	O
at	O
the	O
single	O
data	O
point	O
down	O
to	O
the	O
left	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
radial	O
basis	B
functions	O
dkriesel	O
com	O
in	O
a	O
similar	O
manner	O
we	O
could	O
look	O
how	O
the	O
error	O
depends	O
on	O
the	O
values	O
analogous	O
to	O
the	O
derivation	O
of	O
backpropagation	B
we	O
derive	O
in	O
the	O
following	O
text	O
only	O
simple	O
mechanisms	O
are	O
sketched	O
for	O
more	O
information	O
i	O
refer	O
to	O
err	O
hch	O
h	O
and	O
err	O
hch	O
ch	O
neurons	O
are	O
added	O
to	O
places	O
with	O
large	O
error	O
values	O
since	O
the	O
derivation	O
of	O
these	O
terms	O
corresponds	O
to	O
the	O
derivation	O
of	O
backpropagation	B
we	O
do	O
not	O
want	O
to	O
discuss	O
it	O
here	O
but	O
experience	O
shows	O
that	O
no	O
convincing	O
results	O
are	O
obtained	O
by	O
regarding	O
how	O
the	O
error	O
behaves	O
depending	O
on	O
the	O
centers	O
and	O
sigmas	O
even	O
if	O
mathematics	O
claim	O
that	O
such	O
methods	O
are	O
promising	O
the	O
gradient	B
descent	I
as	O
we	O
already	O
know	O
leads	O
to	O
problems	B
with	O
very	O
craggy	O
error	O
surfaces	O
and	O
that	O
is	O
the	O
crucial	O
point	O
naturally	O
rbf	B
networks	O
generate	O
very	O
craggy	O
error	O
surfaces	O
because	O
if	O
we	O
considerably	O
change	O
a	O
c	O
or	O
a	O
we	O
will	O
significantly	O
change	O
the	O
appearance	O
of	O
the	O
error	B
function	I
growing	B
rbf	B
networks	O
automatically	O
adjust	O
the	O
neuron	B
density	O
in	O
growing	B
rbf	B
networks	O
the	O
number	O
of	O
rbf	B
neurons	O
is	O
not	O
constant	O
a	O
certain	O
number	O
of	O
neurons	O
as	O
well	O
as	O
their	O
centers	O
ch	O
and	O
widths	O
h	O
are	O
previously	O
selected	O
by	O
means	O
of	O
a	O
clustering	O
method	O
and	O
then	O
extended	O
or	O
reduced	O
after	O
generating	O
this	O
initial	O
configuration	O
the	O
vector	O
of	O
the	O
weights	O
g	O
is	O
analytically	O
calculated	O
then	O
all	O
specific	B
errors	O
errp	O
concerning	O
the	O
set	O
p	O
of	O
the	O
training	O
samples	O
are	O
calculated	O
and	O
the	O
maximum	O
specific	B
error	O
max	O
p	O
is	O
sought	O
the	O
extension	O
of	O
the	O
network	O
is	O
simple	O
we	O
replace	O
this	O
maximum	O
error	O
with	O
a	O
new	O
replace	O
rbf	B
neuron	B
of	O
course	O
we	O
have	O
to	O
exererror	O
with	O
neuron	B
cise	O
care	O
in	O
doing	O
this	O
if	O
the	O
are	O
small	O
the	O
neurons	O
will	O
only	O
influence	O
each	O
other	O
if	O
the	O
distance	O
between	O
them	O
is	O
short	O
but	O
if	O
the	O
are	O
large	O
the	O
already	O
exisiting	O
neurons	O
are	O
considerably	O
influenced	O
by	O
the	O
new	O
neuron	B
because	O
of	O
the	O
overlapping	O
of	O
the	O
gaussian	O
bells	O
so	O
it	O
is	O
obvious	O
that	O
we	O
will	O
adjust	O
the	O
already	O
existing	O
rbf	B
neurons	O
when	O
adding	O
the	O
new	O
neuron	B
to	O
put	O
it	O
simply	O
this	O
adjustment	O
is	O
made	O
by	O
moving	O
the	O
centers	O
c	O
of	O
the	O
other	O
neurons	O
away	O
from	O
the	O
new	O
neuron	B
and	O
reducing	O
their	O
width	O
a	O
bit	O
then	O
the	O
current	O
output	B
vector	I
y	O
of	O
the	O
network	O
is	O
compared	O
to	O
the	O
teaching	B
input	B
t	O
and	O
the	O
weight	B
vector	I
g	O
is	O
improved	O
by	O
means	O
of	O
training	O
subsequently	O
a	O
new	O
neuron	B
can	O
be	O
inserted	O
if	O
necessary	O
this	O
method	O
is	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
comparing	O
rbf	B
networks	O
and	O
multilayer	B
perceptrons	O
particularly	O
suited	O
for	O
function	O
approximations	O
two	O
paradigms	O
and	O
look	O
at	O
their	O
advantages	O
and	O
disadvantages	O
limiting	O
the	O
number	O
of	O
neurons	O
here	O
it	O
is	O
mandatory	O
to	O
see	O
that	O
the	O
network	O
will	O
not	O
grow	O
ad	O
infinitum	O
which	O
can	O
happen	O
very	O
fast	O
thus	O
it	O
is	O
very	O
useful	O
to	O
previously	O
define	O
a	O
maximum	O
number	O
for	O
neurons	O
less	O
important	O
neurons	O
are	O
deleted	O
which	O
leads	O
to	O
the	O
question	O
whether	O
it	O
is	O
possible	O
to	O
continue	O
learning	O
when	O
this	O
limit	O
is	O
reached	O
the	O
answer	O
is	O
this	O
would	O
not	O
stop	O
learning	O
we	O
only	O
have	O
to	O
look	O
for	O
the	O
unimportant	O
neuron	B
and	O
delete	O
it	O
a	O
neuron	B
is	O
for	O
example	O
unimportant	O
for	O
the	O
network	O
if	O
there	O
is	O
another	O
neuron	B
that	O
has	O
a	O
similar	O
function	O
it	O
often	O
occurs	O
that	O
two	O
gaussian	O
bells	O
exactly	O
overlap	O
and	O
at	O
such	O
a	O
position	O
for	O
instance	O
one	O
single	O
neuron	B
with	O
a	O
higher	O
gaussian	B
bell	I
would	O
be	O
appropriate	O
but	O
to	O
develop	O
automated	O
procedures	O
in	O
order	O
to	O
find	O
less	O
relevant	O
neurons	O
is	O
highly	O
problem	O
dependent	O
and	O
we	O
want	O
to	O
leave	O
this	O
to	O
the	O
programmer	O
with	O
rbf	B
networks	O
and	O
multilayer	B
perceptrons	O
we	O
have	O
already	O
become	O
acquainted	O
with	O
and	O
extensivley	O
discussed	O
two	O
network	O
paradigms	O
for	O
similar	O
problems	B
therefore	O
we	O
want	O
to	O
compare	O
these	O
delete	O
unimportant	O
neurons	O
comparing	O
rbf	B
networks	O
and	O
multilayer	B
perceptrons	O
networks	O
we	O
will	O
compare	O
multilayer	B
perceptrons	O
and	O
rbf	B
networks	O
with	O
respect	O
to	O
different	O
aspects	O
input	B
dimension	I
we	O
must	O
be	O
careful	O
highwith	O
rbf	B
dimensional	O
functional	O
spaces	O
since	O
the	O
network	O
could	O
very	O
quickly	O
require	O
huge	O
memory	O
storage	O
and	O
computational	O
a	O
multilayer	B
perceptron	B
would	O
cause	O
less	O
problems	B
because	O
its	O
number	O
of	O
neuons	O
does	O
not	O
grow	O
exponentially	O
with	O
the	O
input	B
dimension	I
in	O
effort	O
here	O
center	O
selection	O
however	O
selecting	O
the	O
centers	O
c	O
for	O
rbf	B
networks	O
is	O
the	O
introduced	O
approaches	O
still	O
a	O
major	O
problem	O
please	O
use	O
any	O
previous	O
knowledge	O
you	O
have	O
when	O
applying	O
them	O
such	O
problems	B
do	O
not	O
occur	O
with	O
the	O
mlp	O
output	B
dimension	I
the	O
advantage	O
of	O
rbf	B
networks	O
is	O
that	O
the	O
training	O
is	O
not	O
much	O
influenced	O
when	O
the	O
output	B
dimension	I
of	O
the	O
network	O
is	O
high	O
for	O
an	O
mlp	O
a	O
learning	O
procedure	O
such	O
as	O
backpropagation	B
thereby	O
will	O
be	O
very	O
time-consuming	O
extrapolation	O
advantage	O
as	O
well	O
as	O
disadvantage	O
of	O
rbf	B
networks	O
is	O
the	O
lack	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
radial	O
basis	B
functions	O
dkriesel	O
com	O
exercises	O
exercise	O
an	O
rbf	B
network	I
with	O
fixed	O
widths	O
and	O
centers	O
of	O
the	O
neurons	O
should	O
approximate	O
a	O
target	B
function	O
u	O
for	O
this	O
training	O
samples	O
of	O
the	O
form	O
t	O
of	O
the	O
function	O
u	O
are	O
given	O
let	O
be	O
true	O
the	O
weights	O
should	O
be	O
analytically	O
determined	O
by	O
means	O
of	O
the	O
moore-penrose	B
pseudo	I
inverse	I
indicate	O
the	O
running	O
time	O
behavior	O
regarding	O
and	O
as	O
precisely	O
as	O
possible	O
note	O
there	O
are	O
methods	O
for	O
matrix	O
multiplications	O
and	O
matrix	O
inversions	O
that	O
are	O
more	O
efficient	O
than	O
the	O
canonical	O
methods	O
for	O
better	O
estimations	O
i	O
recommend	O
to	O
look	O
for	O
such	O
methods	O
their	O
complexity	O
in	O
addition	O
to	O
your	O
complexity	O
calculations	O
please	O
indicate	O
the	O
used	O
methods	O
together	O
with	O
their	O
complexity	O
important	O
of	O
extrapolation	O
capability	O
an	O
rbf	B
network	I
returns	O
the	O
result	O
far	O
away	O
from	O
the	O
centers	O
of	O
the	O
rbf	B
layer	O
on	O
the	O
one	O
hand	O
it	O
does	O
not	O
extrapolate	O
unlike	O
the	O
mlp	O
it	O
cannot	O
be	O
used	O
for	O
extrapolation	O
we	O
could	O
never	O
know	O
if	O
the	O
extrapolated	O
values	O
of	O
the	O
mlp	O
are	O
reasonable	O
but	O
experience	O
shows	O
that	O
mlps	O
are	O
suitable	O
for	O
that	O
matter	O
on	O
the	O
other	O
hand	O
unlike	O
the	O
mlp	O
the	O
network	O
is	O
capable	O
to	O
use	O
this	O
to	O
tell	O
us	O
don	O
t	O
know	O
which	O
could	O
be	O
an	O
advantage	O
lesion	O
tolerance	O
for	O
the	O
output	B
of	O
an	O
mlp	O
it	O
is	O
no	O
so	O
important	O
if	O
a	O
weight	B
it	O
will	O
only	O
or	O
a	O
neuron	B
is	O
missing	O
worsen	O
a	O
little	O
in	O
total	B
if	O
a	O
weight	B
or	O
a	O
neuron	B
is	O
missing	O
in	O
an	O
rbf	B
network	I
then	O
large	O
parts	O
of	O
the	O
output	B
remain	O
practically	O
uninfluenced	O
but	O
one	O
part	O
of	O
the	O
output	B
is	O
heavily	O
affected	O
because	O
a	O
gaussian	B
bell	I
is	O
directly	O
missing	O
thus	O
we	O
can	O
choose	O
between	O
a	O
strong	O
local	O
error	O
for	O
lesion	O
and	O
a	O
weak	O
but	O
global	O
error	O
spread	O
here	O
the	O
mlp	O
is	O
since	O
rbf	B
networks	O
are	O
used	O
considerably	O
less	O
often	O
which	O
is	O
not	O
always	O
understood	O
by	O
professionals	O
least	O
as	O
far	O
as	O
low-dimensional	O
input	B
spaces	O
are	O
concerned	O
the	O
mlps	O
seem	O
to	O
have	O
a	O
considerably	O
longer	O
tradition	O
and	O
they	O
are	O
working	O
too	O
good	O
to	O
take	O
the	O
effort	O
to	O
read	O
some	O
pages	O
of	O
this	O
work	O
about	O
rbf	B
networks	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
recurrent	B
perceptron-like	O
networks	O
some	O
thoughts	O
about	O
networks	O
with	O
internal	O
states	O
generally	O
recurrent	B
networks	O
are	O
networks	O
that	O
are	O
capable	O
of	O
influencing	O
themselves	O
by	O
means	O
of	O
recurrences	O
e	O
g	O
by	O
including	O
the	O
network	O
output	B
in	O
the	O
following	O
computation	O
steps	O
there	O
are	O
many	O
types	O
of	O
recurrent	B
networks	O
of	O
nearly	O
arbitrary	O
form	O
and	O
nearly	O
all	O
of	O
them	O
are	O
referred	O
to	O
as	O
recurrent	B
neural	O
networks	O
as	O
a	O
result	O
for	O
the	O
few	O
paradigms	O
introduced	O
here	O
i	O
use	O
the	O
name	O
recurrent	B
multilayer	B
perceptrons	O
apparently	O
such	O
a	O
recurrent	B
network	O
is	O
capable	O
to	O
compute	O
more	O
than	O
the	O
ordinary	O
mlp	O
if	O
the	O
recurrent	B
weights	O
are	O
set	O
to	O
the	O
recurrent	B
network	O
will	O
be	O
reduced	O
to	O
an	O
ordinary	O
mlp	O
additionally	O
the	O
recurrence	B
generates	O
different	O
network-internal	O
states	O
so	O
that	O
different	O
inputs	O
can	O
produce	O
different	O
outputs	O
in	O
the	O
context	B
of	O
the	O
network	O
state	B
recurrent	B
networks	O
in	O
themselves	O
have	O
a	O
great	O
dynamic	O
that	O
is	O
mathematically	O
difficult	O
to	O
conceive	O
and	O
has	O
to	O
be	O
discussed	O
extensively	O
the	O
aim	O
of	O
this	O
chapter	O
is	O
only	O
to	O
briefly	O
discuss	O
how	O
recurrences	O
can	O
be	O
structured	O
and	O
how	O
network-internal	O
states	O
can	O
be	O
generated	O
thus	O
i	O
will	O
briefly	O
introduce	O
two	O
paradigms	O
of	O
recurrent	B
networks	O
and	O
afterwards	O
roughly	O
outline	O
their	O
training	O
with	O
a	O
recurrent	B
network	O
an	O
input	B
x	O
that	O
is	O
constant	O
over	O
time	O
may	O
lead	O
to	O
different	O
results	O
on	O
the	O
one	O
hand	O
the	O
network	O
could	O
converge	O
i	O
e	O
it	O
could	O
transform	O
itself	O
into	O
a	O
fixed	O
state	B
and	O
at	O
some	O
time	O
return	B
a	O
fixed	O
output	B
value	O
y	O
on	O
the	O
other	O
hand	O
it	O
could	O
never	O
converge	O
or	O
at	O
least	O
not	O
until	O
a	O
long	O
time	O
later	O
so	O
that	O
it	O
can	O
no	O
longer	O
be	O
recognized	O
and	O
as	O
a	O
consequence	O
y	O
constantly	O
changes	O
if	O
the	O
network	O
does	O
not	O
converge	O
it	O
is	O
for	O
example	O
possible	O
to	O
check	O
if	O
periodicals	O
or	O
attractors	O
on	O
the	O
following	O
page	O
are	O
returned	O
here	O
we	O
can	O
expect	O
the	O
complete	O
variety	O
of	O
dynamical	O
systems	O
that	O
is	O
the	O
reason	O
why	O
i	O
particularly	O
want	O
to	O
refer	O
to	O
the	O
literature	O
concerning	O
dynamical	O
systems	O
state	B
dynamics	O
more	O
capable	O
than	O
mlp	O
chapter	O
recurrent	B
perceptron-like	O
networks	O
on	O
chapter	O
dkriesel	O
com	O
further	O
discussions	O
could	O
reveal	O
what	O
will	O
happen	O
if	O
the	O
input	B
of	O
recurrent	B
networks	O
is	O
changed	O
in	O
this	O
chapter	O
the	O
related	O
paradigms	O
of	O
recurrent	B
networks	O
according	O
to	O
jordan	B
and	O
elman	B
will	O
be	O
introduced	O
jordan	B
networks	O
a	O
jordan	B
network	I
is	O
a	O
multilayer	B
perceptron	B
with	O
a	O
set	O
k	O
of	O
so-called	O
context	B
neurons	O
kk	O
there	O
is	O
one	O
context	B
neuron	B
per	O
output	B
neuron	B
on	O
the	O
next	O
page	O
in	O
principle	O
a	O
context	B
neuron	B
just	O
memorizes	O
an	O
output	B
until	O
it	O
can	O
be	O
processed	O
in	O
the	O
next	O
time	O
step	O
therefore	O
there	O
are	O
weighted	O
connections	O
between	O
each	O
output	B
neuron	B
and	O
one	O
context	B
neuron	B
the	O
stored	O
values	O
are	O
returned	O
to	O
the	O
actual	O
network	O
by	O
means	O
of	O
complete	O
links	O
between	O
the	O
context	B
neurons	O
and	O
the	O
input	B
layer	O
in	O
the	O
originial	O
definition	O
of	O
a	O
jordan	B
network	I
the	O
context	B
neurons	O
are	O
also	O
recurrent	B
to	O
themselves	O
via	O
a	O
connecting	O
weight	B
but	O
most	O
applications	O
omit	O
this	O
recurrence	B
since	O
the	O
jordan	B
network	I
is	O
already	O
very	O
dynamic	O
and	O
difficult	O
to	O
analyze	O
even	O
without	O
these	O
additional	O
recurrences	O
definition	O
neuron	B
a	O
context	B
neuron	B
k	O
receives	O
the	O
output	B
value	O
of	O
another	O
neuron	B
i	O
at	O
a	O
time	O
t	O
and	O
then	O
reenters	O
it	O
into	O
the	O
network	O
at	O
a	O
time	O
definition	O
network	O
a	O
jordan	B
network	I
is	O
a	O
multilayer	B
perceptron	B
output	B
neurons	O
are	O
buffered	O
figure	O
the	O
roessler	O
attractor	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
elman	B
networks	O
gfed	O
gfed	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
aaaaaaaaa	O
aaaaaaaaa	O
gfed	O
gfed	O
gfed	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
aaaaaaaaa	O
aaaaaaaaa	O
gfed	O
gfed	O
gfed	O
gfed	O
bc	O
figure	O
illustration	O
of	O
a	O
jordan	B
network	I
the	O
network	O
output	B
is	O
buffered	O
in	O
the	O
context	B
neurons	O
and	O
with	O
the	O
next	O
time	O
step	O
it	O
is	O
entered	O
into	O
the	O
network	O
together	O
with	O
the	O
new	O
input	B
with	O
one	O
context	B
neuron	B
per	O
output	B
neuron	B
the	O
set	B
of	I
context	B
neurons	O
is	O
called	O
k	O
the	O
context	B
neurons	O
are	O
completely	O
linked	O
toward	O
the	O
input	B
layer	O
of	O
the	O
network	O
elman	B
networks	O
the	O
elman	B
networks	O
variation	O
of	O
the	O
jordan	B
networks	O
have	O
context	B
neurons	O
too	O
but	O
one	O
layer	O
of	O
context	B
neurons	O
per	O
information	B
processing	I
neuron	B
layer	O
on	O
the	O
following	O
page	O
thus	O
the	O
outputs	O
of	O
each	O
hidden	B
neuron	B
or	O
output	B
neuron	B
are	O
led	O
into	O
the	O
associated	O
context	B
layer	O
exactly	O
one	O
context	B
neuron	B
per	O
neuron	B
and	O
from	O
there	O
it	O
is	O
reentered	O
into	O
the	O
complete	O
neuron	B
layer	O
during	O
the	O
next	O
time	O
step	O
again	O
a	O
complete	O
link	O
on	O
the	O
way	O
back	O
so	O
the	O
complete	O
information	B
processing	I
of	O
the	O
mlp	O
exists	O
a	O
second	O
time	O
as	O
a	O
version	O
which	O
once	O
again	O
considerably	O
increases	O
dynamics	O
and	O
state	B
variety	O
compared	O
with	O
jordan	B
networks	O
the	O
elman	B
networks	O
often	O
have	O
the	O
advantage	O
to	O
act	O
more	O
purposeful	O
since	O
every	O
layer	O
can	O
access	O
its	O
own	O
context	B
definition	O
network	O
an	O
elman	B
network	I
is	O
an	O
mlp	O
with	O
one	O
context	B
neuron	B
per	O
information	B
processing	I
neuron	B
the	O
set	B
of	I
context	B
neurons	O
is	O
called	O
k	O
this	O
means	O
that	O
there	O
exists	O
one	O
context	B
layer	O
per	O
information	B
processing	I
remember	O
the	O
input	B
layer	O
does	O
not	O
process	O
in	O
formation	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
nearly	O
everything	O
is	O
buffered	O
t	O
x	O
x	O
v	O
v	O
t	O
o	O
o	O
o	O
o	O
chapter	O
recurrent	B
perceptron-like	O
networks	O
on	O
chapter	O
dkriesel	O
com	O
gfed	O
gfed	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
gfed	O
gfed	O
gfed	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
gfed	O
gfed	O
onml	O
onml	O
onml	O
hijkk	O
onml	O
onml	O
hijkk	O
figure	O
illustration	O
of	O
an	O
elman	B
network	I
the	O
entire	O
information	B
processing	I
part	O
of	O
the	O
network	O
exists	O
in	O
a	O
way	O
twice	O
the	O
output	B
of	O
each	O
neuron	B
for	O
the	O
output	B
of	O
the	O
input	B
neurons	O
is	O
buffered	O
and	O
reentered	O
into	O
the	O
associated	O
layer	O
for	O
the	O
reason	O
of	O
clarity	O
i	O
named	O
the	O
context	B
neurons	O
on	O
the	O
basis	B
of	O
their	O
models	O
in	O
the	O
actual	O
network	O
but	O
it	O
is	O
not	O
mandatory	O
to	O
do	O
so	O
neuron	B
layer	O
with	O
exactly	O
the	O
same	O
number	O
of	O
context	B
neurons	O
every	O
neuron	B
has	O
a	O
weighted	O
connection	B
to	O
exactly	O
one	O
context	B
neuron	B
while	O
the	O
context	B
layer	O
is	O
completely	O
linked	O
towards	O
its	O
original	O
layer	O
now	O
it	O
is	O
interesting	O
to	O
take	O
a	O
look	O
at	O
the	O
training	O
of	O
recurrent	B
networks	O
since	O
for	O
instance	O
ordinary	O
backpropagation	B
of	I
error	I
cannot	O
work	O
on	O
recurrent	B
networks	O
once	O
again	O
the	O
style	O
of	O
the	O
following	O
part	O
is	O
rather	O
informal	O
which	O
means	O
that	O
i	O
will	O
not	O
use	O
any	O
formal	O
definitions	O
training	O
recurrent	B
networks	O
in	O
order	O
to	O
explain	O
the	O
training	O
as	O
comprehensible	O
as	O
possible	O
we	O
have	O
to	O
agree	O
on	O
some	O
simplifications	O
that	O
do	O
not	O
affect	O
the	O
learning	O
principle	O
itself	O
so	O
for	O
the	O
training	O
let	O
us	O
assume	O
that	O
in	O
the	O
beginning	O
the	O
context	B
neurons	O
are	O
initiated	O
with	O
an	O
input	B
since	O
otherwise	O
they	O
would	O
have	O
an	O
undefined	O
input	B
is	O
no	O
simplification	O
but	O
reality	O
furthermore	O
we	O
use	O
a	O
jordan	B
network	I
without	O
a	O
hidden	B
neuron	B
layer	O
for	O
our	O
training	O
attempts	O
so	O
that	O
the	O
output	B
neu	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
t	O
t	O
u	O
u	O
z	O
z	O
v	O
v	O
w	O
w	O
u	O
u	O
t	O
t	O
v	O
v	O
u	O
u	O
t	O
t	O
u	O
u	O
w	O
w	O
u	O
u	O
v	O
v	O
attach	O
the	O
same	O
network	O
to	O
each	O
context	B
layer	O
dkriesel	O
com	O
training	O
recurrent	B
networks	O
rons	O
can	O
directly	O
provide	O
input	B
this	O
approach	O
is	O
a	O
strong	O
simplification	O
because	O
generally	O
more	O
complicated	O
networks	O
are	O
used	O
but	O
this	O
does	O
not	O
change	O
the	O
learning	O
principle	O
unfolding	B
in	I
time	I
remember	O
our	O
actual	O
learning	O
procedure	O
for	O
mlps	O
the	O
backpropagation	B
of	I
error	I
which	O
backpropagates	O
the	O
delta	B
values	O
so	O
in	O
case	O
of	O
recurrent	B
networks	O
the	O
delta	B
values	O
would	O
backpropagate	O
cyclically	O
through	O
the	O
network	O
again	O
and	O
again	O
which	O
makes	O
the	O
training	O
more	O
difficult	O
on	O
the	O
one	O
hand	O
we	O
cannot	O
know	O
which	O
of	O
the	O
many	O
generated	O
delta	B
values	O
for	O
a	O
weight	B
should	O
be	O
selected	O
for	O
training	O
i	O
e	O
which	O
values	O
are	O
useful	O
on	O
the	O
other	O
hand	O
we	O
cannot	O
definitely	O
know	O
when	O
learning	O
should	O
be	O
stopped	O
the	O
advantage	O
of	O
recurrent	B
networks	O
are	O
great	O
state	B
dynamics	O
within	O
the	O
network	O
the	O
disadvantage	O
of	O
recurrent	B
networks	O
is	O
that	O
these	O
dynamics	O
are	O
also	O
granted	O
to	O
the	O
training	O
and	O
therefore	O
make	O
it	O
difficult	O
one	O
learning	O
approach	O
would	O
be	O
the	O
attempt	O
to	O
unfold	O
the	O
temporal	O
states	O
of	O
the	O
network	O
on	O
the	O
next	O
page	O
recursions	O
are	O
deleted	O
by	O
putting	O
a	O
similar	O
network	O
above	O
the	O
context	B
neurons	O
i	O
e	O
the	O
context	B
neurons	O
are	O
as	O
a	O
manner	O
of	O
speaking	O
the	O
output	B
neurons	O
of	O
the	O
attached	O
network	O
more	O
generally	O
spoken	O
we	O
have	O
to	O
backtrack	O
the	O
recurrences	O
and	O
place	O
earlier	O
instances	O
of	O
neurons	O
in	O
the	O
network	O
thus	O
creating	O
a	O
larger	O
but	O
forward-oriented	O
network	O
without	O
recurrences	O
this	O
enables	O
training	O
a	O
recurrent	B
network	O
with	O
any	O
training	O
strategy	O
developed	O
for	O
non-recurrent	O
ones	O
here	O
the	O
input	B
is	O
entered	O
as	O
teaching	B
input	B
into	O
every	O
of	O
the	O
input	B
neurons	O
this	O
can	O
be	O
done	O
for	O
a	O
discrete	B
number	O
of	O
time	O
steps	O
these	O
training	O
paradigms	O
are	O
called	O
unfolding	B
in	I
time	I
after	O
the	O
unfolding	O
a	O
training	O
by	O
means	O
of	O
backpropagation	B
of	I
error	I
is	O
possible	O
but	O
obviously	O
for	O
one	O
weight	B
wij	O
several	O
changing	O
values	O
wij	O
are	O
received	O
which	O
can	O
be	O
treated	O
differently	O
accumulation	O
averaging	O
etc	O
a	O
simple	O
accumulation	O
could	O
possibly	O
result	O
in	O
enormous	O
changes	O
per	O
weight	B
if	O
all	O
changes	O
have	O
the	O
same	O
sign	O
hence	O
also	O
the	O
average	O
is	O
not	O
to	O
be	O
underestimated	O
we	O
could	O
also	O
introduce	O
a	O
discounting	O
factor	O
which	O
weakens	O
the	O
influence	O
of	O
wij	O
of	O
the	O
past	O
unfolding	B
in	I
time	I
is	O
particularly	O
useful	O
if	O
we	O
receive	O
the	O
impression	O
that	O
the	O
closer	O
past	O
is	O
more	O
important	O
for	O
the	O
network	O
than	O
the	O
one	O
being	O
further	O
away	O
the	O
reason	O
for	O
this	O
is	O
that	O
backpropagation	B
has	O
only	O
little	O
influence	O
in	O
the	O
layers	O
farther	O
away	O
from	O
the	O
output	B
the	O
farther	O
we	O
are	O
from	O
the	O
output	B
layer	O
the	O
smaller	O
the	O
influence	O
of	O
backpropagation	B
disadvantages	O
the	O
training	O
of	O
such	O
an	O
unfolded	O
network	O
will	O
take	O
a	O
long	O
time	O
since	O
a	O
large	O
number	O
of	O
layers	O
could	O
possibly	O
be	O
produced	O
a	O
problem	O
that	O
is	O
no	O
longer	O
negligible	O
is	O
the	O
limited	O
computational	O
accuracy	O
of	O
ordinary	O
computers	O
which	O
is	O
exhausted	O
very	O
fast	O
because	O
of	O
so	O
many	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
recurrent	B
perceptron-like	O
networks	O
on	O
chapter	O
dkriesel	O
com	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
wnnnnnnnnnnnnnnnnn	O
wnnnnnnnnnnnnnnnnn	O
aaaaaaaaa	O
gfed	O
gfed	O
bc	O
tjjjjjjjjjjjjjjjjjjjjj	O
woooooooooooooo	O
woooooooooooooo	O
tjjjjjjjjjjjjjjjjjjjjjjj	O
vnnnnnnnnnnnnnnnn	O
wppppppppppppppp	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
wnnnnnnnnnnnnnnnnn	O
wnnnnnnnnnnnnnnnnn	O
aaaaaaaaa	O
gfed	O
gfed	O
figure	O
illustration	O
of	O
the	O
unfolding	B
in	I
time	I
with	O
a	O
small	O
exemplary	O
recurrent	B
mlp	O
top	O
the	O
recurrent	B
mlp	O
bottom	O
the	O
unfolded	O
network	O
for	O
reasons	O
of	O
clarity	O
i	O
only	O
added	O
names	O
to	O
the	O
lowest	O
part	O
of	O
the	O
unfolded	O
network	O
dotted	O
arrows	O
leading	O
into	O
the	O
network	O
mark	O
the	O
inputs	O
dotted	O
arrows	O
leading	O
out	O
of	O
the	O
network	O
mark	O
the	O
outputs	O
each	O
copy	O
represents	O
a	O
time	O
step	O
of	O
the	O
network	O
with	O
the	O
most	O
recent	O
time	O
step	O
being	O
at	O
the	O
bottom	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
w	O
t	O
w	O
o	O
o	O
o	O
o	O
w	O
t	O
w	O
v	O
t	O
w	O
w	O
t	O
w	O
dkriesel	O
com	O
training	O
recurrent	B
networks	O
are	O
chosen	O
suitably	O
so	O
for	O
example	O
neurons	O
and	O
weights	O
can	O
be	O
adjusted	O
and	O
the	O
network	O
topology	B
can	O
be	O
optimized	O
course	O
the	O
result	O
of	O
learning	O
is	O
not	O
necessarily	O
a	O
jordan	B
or	O
elman	B
network	I
with	O
ordinary	O
mlps	O
however	O
evolutionary	O
strategies	O
are	O
less	O
popular	O
since	O
they	O
certainly	O
need	O
a	O
lot	O
more	O
time	O
than	O
a	O
directed	O
learning	O
procedure	O
such	O
as	O
backpropagation	B
teaching	B
input	B
applied	O
at	O
context	B
neurons	O
nested	O
computations	O
farther	O
we	O
are	O
from	O
the	O
output	B
layer	O
the	O
smaller	O
the	O
influence	O
of	O
backpropagation	B
so	O
that	O
this	O
limit	O
is	O
reached	O
furthermore	O
with	O
several	O
levels	O
of	O
context	B
neurons	O
this	O
procedure	O
could	O
produce	O
very	O
large	O
networks	O
to	O
be	O
trained	O
teacher	B
forcing	I
the	O
other	O
procedures	O
are	O
equivalent	O
teacher	B
forcing	I
and	O
open	B
loop	I
learning	I
they	O
detach	O
the	O
recurrence	B
during	O
the	O
learning	O
process	O
we	O
simply	O
pretend	O
that	O
the	O
recurrence	B
does	O
not	O
exist	O
and	O
apply	O
the	O
teaching	B
input	B
to	O
the	O
context	B
neurons	O
during	O
the	O
training	O
so	O
backpropagation	B
becomes	O
possible	O
too	O
disadvantage	O
with	O
elman	B
networks	O
a	O
teaching	B
input	B
for	O
non-output-neurons	O
is	O
not	O
given	O
recurrent	B
backpropagation	B
another	O
popular	O
procedure	O
without	O
limited	O
time	B
horizon	I
is	O
the	O
recurrent	B
backpropagation	B
using	O
methods	O
of	O
differential	O
calculus	O
to	O
solve	O
the	O
problem	O
training	O
with	O
evolution	O
due	O
to	O
the	O
already	O
long	O
lasting	O
training	O
time	O
evolutionary	B
algorithms	I
have	O
proved	O
to	O
be	O
of	O
value	O
especially	O
with	O
recurrent	B
networks	O
one	O
reason	O
for	O
this	O
is	O
that	O
they	O
are	O
not	O
only	O
unrestricted	O
with	O
respect	O
to	O
recurrences	O
but	O
they	O
also	O
have	O
other	O
advantages	O
when	O
the	O
mutation	O
mechanisms	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
hopfield	B
networks	I
in	O
a	O
magnetic	O
field	O
each	O
particle	O
applies	O
a	O
force	O
to	O
any	O
other	O
particle	O
so	O
that	O
all	O
particles	O
adjust	O
their	O
movements	O
in	O
the	O
energetically	O
most	O
favorable	O
way	O
this	O
natural	O
mechanism	O
is	O
copied	O
to	O
adjust	O
noisy	O
inputs	O
in	O
order	O
to	O
match	O
their	O
real	O
models	O
another	O
supervised	B
learning	O
example	O
of	O
the	O
wide	O
range	O
of	O
neural	O
networks	O
was	O
developed	O
by	O
john	O
hopfield	O
the	O
socalled	O
hopfield	B
networks	I
hopfield	O
and	O
his	O
physically	O
motivated	O
networks	O
have	O
contributed	O
a	O
lot	O
to	O
the	O
renaissance	O
of	O
neural	O
networks	O
hopfield	B
networks	I
are	O
inspired	O
by	O
particles	O
in	O
a	O
magnetic	O
field	O
the	O
idea	O
for	O
the	O
hopfield	B
networks	I
originated	O
from	O
the	O
behavior	O
of	O
particles	O
in	O
a	O
magnetic	O
field	O
every	O
particle	O
means	O
of	O
magnetic	O
forces	O
with	O
every	O
other	O
particle	O
linked	O
with	O
each	O
particle	O
trying	O
to	O
reach	O
an	O
energetically	O
favorable	O
state	B
a	O
minimum	O
of	O
the	O
energy	O
function	O
as	O
for	O
the	O
neurons	O
this	O
state	B
is	O
known	O
as	O
activation	B
thus	O
all	O
particles	O
or	O
neurons	O
rotate	O
and	O
thereby	O
encourage	O
each	O
other	O
to	O
continue	O
this	O
rotation	O
as	O
a	O
manner	O
of	O
speaking	O
our	O
neural	B
network	I
is	O
a	O
cloud	O
of	O
particles	O
based	O
on	O
the	O
fact	O
that	O
the	O
particles	O
automatically	O
detect	O
the	O
minima	O
of	O
the	O
energy	O
function	O
hopfield	O
had	O
the	O
idea	O
to	O
use	O
the	O
of	O
the	O
particles	O
to	O
process	O
information	O
why	O
not	O
letting	O
the	O
particles	O
search	O
minima	O
on	O
arbitrary	O
functions	O
even	O
if	O
we	O
only	O
use	O
two	O
of	O
those	O
spins	O
i	O
e	O
a	O
binary	B
activation	B
we	O
will	O
recognize	O
that	O
the	O
developed	O
hopfield	O
network	O
shows	O
considerable	O
dynamics	O
in	O
a	O
hopfield	O
network	O
all	O
neurons	O
influence	O
each	O
other	O
symmetrically	O
briefly	O
speaking	O
a	O
hopfield	O
network	O
consists	O
of	O
a	O
set	O
k	O
of	O
completely	O
linked	O
neu-	O
rons	O
with	O
binary	B
activation	B
we	O
only	O
chapter	O
hopfield	B
networks	I
i	O
ukkkkkkkkkkkkkkkkkkkkkkkk	O
i	O
ukkkkkkkkkkkkkkkkkkkkkkkk	O
figure	O
illustration	O
of	O
an	O
exemplary	O
hopfield	O
network	O
the	O
arrows	O
and	O
mark	O
the	O
binary	B
due	O
to	O
the	O
completely	O
linked	O
neurons	O
the	O
layers	O
cannot	O
be	O
separated	O
which	O
means	O
that	O
a	O
hopfield	O
network	O
simply	O
includes	O
a	O
set	B
of	I
neurons	O
dkriesel	O
com	O
definition	O
network	O
a	O
hopfield	O
network	O
consists	O
of	O
a	O
set	O
k	O
of	O
completely	O
linked	O
neurons	O
without	O
direct	B
recurrences	O
the	O
activation	B
function	I
of	O
the	O
neurons	O
is	O
the	O
binary	B
threshold	I
function	I
with	O
outputs	O
definition	O
of	O
a	O
hopfield	O
network	O
the	O
state	B
of	O
the	O
network	O
consists	O
of	O
the	O
activation	B
states	O
of	O
all	O
neurons	O
thus	O
the	O
state	B
of	O
the	O
network	O
can	O
be	O
understood	O
as	O
a	O
binary	B
string	O
z	O
input	B
and	O
output	B
of	O
a	O
hopfield	O
network	O
are	O
represented	O
by	O
neuron	B
states	O
use	O
two	O
spins	O
with	O
the	O
weights	O
being	O
symmetric	O
between	O
the	O
individual	O
neurons	O
and	O
without	O
any	O
neuron	B
being	O
directly	O
connected	O
to	O
itself	O
thus	O
the	O
state	B
of	O
neurons	O
with	O
two	O
possible	O
states	O
can	O
be	O
described	O
by	O
a	O
string	O
x	O
the	O
complete	O
link	O
provides	O
a	O
full	O
square	O
matrix	O
of	O
weights	O
between	O
the	O
neurons	O
the	O
meaning	O
of	O
the	O
weights	O
will	O
be	O
discussed	O
in	O
the	O
following	O
furthermore	O
we	O
will	O
soon	O
recognize	O
according	O
to	O
which	O
rules	O
the	O
neurons	O
are	O
spinning	O
i	O
e	O
are	O
changing	O
their	O
state	B
additionally	O
the	O
complete	O
link	O
leads	O
to	O
the	O
fact	O
that	O
we	O
do	O
not	O
know	O
any	O
input	B
output	B
or	O
hidden	B
neurons	O
thus	O
we	O
have	O
to	O
think	O
about	O
how	O
we	O
can	O
input	B
something	O
into	O
the	O
neurons	O
we	O
have	O
learned	O
that	O
a	O
network	O
i	O
e	O
a	O
set	B
of	I
particles	O
that	O
is	O
in	O
a	O
state	B
is	O
automatically	O
looking	O
for	O
a	O
minimum	O
an	O
input	B
pattern	O
of	O
a	O
hopfield	O
network	O
is	O
exactly	O
such	O
a	O
state	B
a	O
binary	B
string	O
x	O
that	O
initializes	O
the	O
neurons	O
then	O
the	O
network	O
is	O
looking	O
for	O
the	O
minimum	O
to	O
be	O
taken	O
we	O
have	O
previously	O
defined	O
by	O
the	O
input	B
of	O
training	O
samples	O
on	O
its	O
energy	O
surface	O
but	O
when	O
do	O
we	O
know	O
that	O
the	O
minimum	O
has	O
been	O
found	O
this	O
is	O
simple	O
too	O
when	O
the	O
network	O
stops	O
it	O
can	O
be	O
proven	O
that	O
a	O
hopfield	O
network	O
with	O
a	O
symmetric	O
weight	B
matrix	I
that	O
has	O
zeros	O
on	O
its	O
diagonal	O
always	O
converges	O
i	O
e	O
at	O
some	O
point	O
it	O
will	O
stand	O
still	O
then	O
the	O
output	B
is	O
a	O
binary	B
string	O
y	O
namely	O
the	O
state	B
string	O
of	O
the	O
network	O
that	O
has	O
found	O
a	O
minimum	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
input	B
and	O
output	B
network	O
states	O
always	O
converges	O
completely	O
linked	O
set	B
of	I
neurons	O
i	O
i	O
i	O
o	O
o	O
o	O
o	O
u	O
o	O
o	O
i	O
o	O
j	O
j	O
u	O
o	O
o	O
o	O
o	O
dkriesel	O
com	O
structure	O
and	O
functionality	O
now	O
let	O
us	O
take	O
a	O
closer	O
look	O
at	O
the	O
contents	O
of	O
the	O
weight	B
matrix	I
and	O
the	O
rules	O
for	O
the	O
state	B
change	O
of	O
the	O
neurons	O
definition	O
and	O
output	B
of	O
a	O
hopfield	O
network	O
the	O
input	B
of	O
a	O
hopfield	O
network	O
is	O
binary	B
string	O
x	O
that	O
initializes	O
the	O
state	B
of	O
the	O
network	O
after	O
the	O
convergence	O
of	O
the	O
network	O
the	O
output	B
is	O
the	O
binary	B
string	O
y	O
generated	O
from	O
the	O
new	O
network	O
state	B
significance	O
of	O
weights	O
i	O
e	O
we	O
have	O
already	O
said	O
that	O
the	O
neurons	O
change	O
their	O
states	O
their	O
direction	O
from	O
to	O
or	O
vice	O
versa	O
these	O
spins	O
occur	O
dependent	O
on	O
the	O
current	O
states	O
of	O
the	O
other	O
neurons	O
and	O
the	O
associated	O
weights	O
thus	O
the	O
weights	O
are	O
capable	O
to	O
control	O
the	O
complete	O
change	O
of	O
the	O
network	O
the	O
weights	O
can	O
be	O
positive	O
negative	O
or	O
colloquially	O
speaking	O
for	O
a	O
weight	B
wij	O
between	O
two	O
neurons	O
i	O
and	O
j	O
the	O
following	O
holds	O
if	O
wij	O
is	O
positive	O
it	O
will	O
try	O
to	O
force	O
the	O
two	O
neurons	O
to	O
become	O
equal	O
the	O
larger	O
they	O
are	O
the	O
harder	O
the	O
network	O
will	O
try	O
if	O
the	O
neuron	B
i	O
is	O
in	O
state	B
and	O
the	O
neuron	B
j	O
is	O
in	O
state	B
a	O
high	O
positive	O
weight	B
will	O
advise	O
the	O
two	O
neurons	O
that	O
it	O
is	O
energetically	O
more	O
favorable	O
to	O
be	O
equal	O
if	O
wij	O
is	O
negative	O
its	O
behavior	O
will	O
be	O
analoguous	O
only	O
that	O
i	O
and	O
j	O
are	O
urged	O
to	O
be	O
different	O
a	O
neuron	B
i	O
in	O
state	B
would	O
try	O
to	O
urge	O
a	O
neuron	B
j	O
into	O
state	B
x	O
j	O
k	O
zero	O
weights	O
lead	O
to	O
the	O
two	O
involved	O
neurons	O
not	O
influencing	O
each	O
other	O
the	O
weights	O
as	O
a	O
whole	O
apparently	O
take	O
the	O
way	O
from	O
the	O
current	O
state	B
of	O
the	O
network	O
towards	O
the	O
next	O
minimum	O
of	O
the	O
energy	O
function	O
we	O
now	O
want	O
to	O
discuss	O
how	O
the	O
neurons	O
follow	O
this	O
way	O
a	O
neuron	B
changes	O
its	O
state	B
according	O
to	O
the	O
influence	O
of	O
the	O
other	O
neurons	O
once	O
a	O
network	O
has	O
been	O
trained	O
and	O
initialized	O
with	O
some	O
starting	O
state	B
the	O
change	O
of	O
state	B
xk	O
of	O
the	O
individual	O
neurons	O
k	O
occurs	O
according	O
to	O
the	O
scheme	O
xkt	O
fact	O
wjk	O
xjt	O
in	O
each	O
time	O
step	O
where	O
the	O
function	O
fact	O
generally	O
is	O
the	O
binary	B
threshold	I
function	I
on	O
the	O
next	O
page	O
with	O
threshold	O
colloquially	O
speaking	O
a	O
neuron	B
k	O
calculates	O
the	O
sum	O
of	O
wjk	O
xjt	O
which	O
indicates	O
how	O
strong	O
and	O
into	O
which	O
direction	O
the	O
neuron	B
k	O
is	O
forced	O
by	O
the	O
other	O
neurons	O
j	O
thus	O
the	O
new	O
state	B
of	O
the	O
network	O
t	O
results	O
from	O
the	O
state	B
of	O
the	O
network	O
at	O
the	O
previous	O
time	O
t	O
this	O
sum	O
is	O
the	O
direction	O
into	O
which	O
the	O
neuron	B
k	O
is	O
pushed	O
depending	O
on	O
the	O
sign	O
of	O
the	O
sum	O
the	O
neuron	B
takes	O
state	B
or	O
another	O
difference	O
between	O
hopfield	B
networks	I
and	O
other	O
already	O
known	O
network	O
topologies	O
is	O
the	O
asynchronous	O
update	O
a	O
neuron	B
k	O
is	O
randomly	O
chosen	O
every	O
time	O
which	O
then	O
recalculates	O
the	O
activation	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
hopfield	B
networks	I
dkriesel	O
com	O
a	O
minimum	O
then	O
there	O
is	O
the	O
question	O
of	O
how	O
to	O
teach	O
the	O
weights	O
to	O
force	O
the	O
network	O
towards	O
a	O
certain	O
minimum	O
the	O
weight	B
matrix	I
is	O
generated	O
directly	O
out	O
of	O
the	O
training	O
patterns	O
figure	O
illustration	O
of	O
the	O
binary	B
threshold	I
function	I
thus	O
the	O
new	O
activation	B
of	O
the	O
previously	O
changed	O
neurons	O
immediately	O
influences	O
the	O
network	O
i	O
e	O
one	O
time	O
step	O
indicates	O
the	O
change	O
of	O
a	O
single	O
neuron	B
regardless	O
of	O
the	O
aforementioned	O
random	O
selection	B
of	I
the	O
neuron	B
a	O
hopfield	O
network	O
is	O
often	O
much	O
easier	O
to	O
implement	O
the	O
neurons	O
are	O
simply	O
processed	O
one	O
after	O
the	O
other	O
and	O
their	O
activations	O
are	O
recalculated	O
until	O
no	O
more	O
changes	O
occur	O
definition	O
in	O
the	O
state	B
of	O
a	O
hopfield	O
network	O
the	O
change	O
of	O
state	B
of	O
the	O
neurons	O
occurs	O
asynchronously	O
with	O
the	O
neuron	B
to	O
be	O
updated	O
being	O
randomly	O
chosen	O
and	O
the	O
new	O
state	B
being	O
generated	O
by	O
means	O
of	O
this	O
rule	O
xkt	O
fact	O
wjk	O
xjt	O
x	O
j	O
j	O
the	O
aim	O
is	O
to	O
generate	O
minima	O
on	O
the	O
mentioned	O
energy	O
surface	O
so	O
that	O
at	O
an	O
input	B
the	O
network	O
can	O
converge	O
to	O
them	O
as	O
with	O
many	O
other	O
network	O
paradigms	O
we	O
use	O
a	O
set	O
p	O
of	O
training	O
patterns	O
p	O
representing	O
the	O
minima	O
of	O
our	O
energy	O
surface	O
unlike	O
many	O
other	O
network	O
paradigms	O
we	O
do	O
not	O
look	O
for	O
the	O
minima	O
of	O
an	O
unknown	O
error	B
function	I
but	O
define	O
minima	O
on	O
such	O
a	O
function	O
the	O
purpose	O
is	O
that	O
the	O
network	O
shall	O
automatically	O
take	O
the	O
closest	O
minimum	O
when	O
the	O
input	B
is	O
presented	O
for	O
now	O
this	O
seems	O
unusual	O
but	O
we	O
will	O
understand	O
the	O
whole	O
purpose	O
later	O
roughly	O
speaking	O
the	O
training	O
of	O
a	O
hopfield	O
network	O
is	O
done	O
by	O
training	O
each	O
training	B
pattern	I
exactly	O
once	O
using	O
the	O
rule	O
described	O
in	O
the	O
following	O
shot	O
learning	O
where	O
pi	O
and	O
pj	O
are	O
the	O
states	O
of	O
the	O
neurons	O
i	O
and	O
j	O
under	O
p	O
p	O
wij	O
x	O
p	O
p	O
pi	O
pj	O
random	O
neuron	B
calculates	O
new	O
activation	B
now	O
that	O
we	O
know	O
how	O
the	O
weights	O
influence	O
the	O
changes	O
in	O
the	O
states	O
of	O
the	O
neurons	O
and	O
force	O
the	O
entire	O
network	O
towards	O
this	O
results	O
in	O
the	O
weight	B
matrix	I
w	O
colloquially	O
speaking	O
we	O
initialize	O
the	O
network	O
by	O
means	O
of	O
a	O
training	B
pattern	I
and	O
then	O
process	O
weights	O
wij	O
one	O
after	O
another	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
function	O
dkriesel	O
com	O
autoassociation	O
and	O
traditional	O
application	O
for	O
each	O
of	O
these	O
weights	O
we	O
verify	O
are	O
the	O
neurons	O
i	O
j	O
n	O
the	O
same	O
state	B
or	O
do	O
the	O
states	O
vary	O
in	O
the	O
first	O
case	O
we	O
add	O
to	O
the	O
weight	B
in	O
the	O
second	O
case	O
we	O
add	O
this	O
we	O
repeat	O
for	O
each	O
training	B
pattern	I
p	O
p	O
finally	O
the	O
values	O
of	O
the	O
weights	O
wij	O
are	O
high	O
when	O
i	O
and	O
j	O
corresponded	O
with	O
many	O
training	O
patterns	O
colloquially	O
speaking	O
this	O
high	O
value	O
tells	O
the	O
neurons	O
it	O
is	O
energetically	O
favorable	O
to	O
hold	O
the	O
same	O
state	B
the	O
same	O
applies	O
to	O
negative	O
weights	O
due	O
to	O
this	O
training	O
we	O
can	O
store	O
a	O
certain	O
fixed	O
number	O
of	O
patterns	O
p	O
in	O
the	O
weight	B
matrix	I
at	O
an	O
input	B
x	O
the	O
network	O
will	O
converge	O
to	O
the	O
stored	O
pattern	O
that	O
is	O
closest	O
to	O
the	O
input	B
p	O
unfortunately	O
the	O
number	O
of	O
the	O
maximum	O
storable	O
and	O
reconstructible	O
patterns	O
p	O
is	O
limited	O
to	O
which	O
in	O
turn	O
only	O
applies	O
to	O
orthogonal	O
patterns	O
this	O
was	O
shown	O
by	O
precise	B
time-consuming	O
mathematical	O
analyses	O
which	O
we	O
do	O
not	O
want	O
to	O
specify	O
now	O
if	O
more	O
patterns	O
are	O
entered	O
already	O
stored	O
information	O
will	O
be	O
destroyed	O
definition	O
rule	O
for	O
hopfield	B
networks	I
the	O
individual	O
elements	O
of	O
the	O
weight	B
matrix	I
w	O
are	O
defined	O
by	O
a	O
single	O
processing	O
of	O
the	O
learning	O
rule	O
wij	O
x	O
p	O
p	O
pi	O
pj	O
where	O
the	O
diagonal	O
of	O
the	O
matrix	O
is	O
covered	O
with	O
zeros	O
here	O
no	O
more	O
than	O
training	O
samples	O
can	O
be	O
trained	O
and	O
at	O
the	O
same	O
time	O
maintain	O
their	O
function	O
now	O
we	O
know	O
the	O
functionality	O
of	O
hopfield	B
networks	I
but	O
nothing	O
about	O
their	O
practical	O
use	O
autoassociation	O
and	O
traditional	O
application	O
hopfield	B
networks	I
like	O
those	O
mentioned	O
above	O
are	O
called	O
autoassociators	O
an	O
autoassociator	B
a	O
exactly	O
shows	O
the	O
afore-	O
mentioned	O
behavior	O
firstly	O
when	O
a	O
known	O
pattern	O
p	O
is	O
entered	O
exactly	O
this	O
known	O
pattern	O
is	O
returned	O
thus	O
ap	O
p	O
with	O
a	O
being	O
the	O
associative	O
mapping	O
secondly	O
and	O
that	O
is	O
the	O
practical	O
use	O
this	O
also	O
works	O
with	O
inputs	O
that	O
are	O
close	O
to	O
a	O
pattern	O
ap	O
p	O
afterwards	O
the	O
autoassociator	B
is	O
in	O
any	O
case	O
in	O
a	O
stable	O
state	B
namely	O
in	O
the	O
state	B
p	O
if	O
the	O
set	B
of	I
patterns	O
p	O
consists	O
of	O
for	O
example	O
letters	O
or	O
other	O
characters	O
in	O
the	O
form	O
of	O
pixels	O
the	O
network	O
will	O
be	O
able	O
to	O
correctly	O
recognize	O
deformed	O
or	O
noisy	O
letters	O
with	O
high	O
probability	O
on	O
the	O
following	O
page	O
the	O
primary	B
fields	O
of	O
application	O
of	O
hopfield	B
networks	I
are	O
pattern	B
recognition	I
and	O
pattern	O
completion	O
such	O
as	O
the	O
zip	O
network	O
restores	O
damaged	O
inputs	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
hopfield	B
networks	I
dkriesel	O
com	O
code	O
recognition	O
on	O
letters	O
in	O
the	O
eighties	O
but	O
soon	O
the	O
hopfield	B
networks	I
were	O
replaced	O
by	O
other	O
systems	O
in	O
most	O
of	O
their	O
fields	O
of	O
application	O
for	O
example	O
by	O
ocr	O
systems	O
in	O
the	O
field	O
of	O
letter	O
recognition	O
today	O
hopfield	B
networks	I
are	O
virtually	O
no	O
longer	O
used	O
they	O
have	O
not	O
become	O
established	O
in	O
practice	O
heteroassociation	O
and	O
analogies	O
to	O
neural	O
data	O
storage	O
so	O
far	O
we	O
have	O
been	O
introduced	O
to	O
hopfield	B
networks	I
that	O
converge	O
from	O
an	O
arbitrary	O
input	B
into	O
the	O
closest	O
minimum	O
of	O
a	O
static	O
energy	O
surface	O
another	O
variant	O
is	O
a	O
dynamic	O
energy	O
surface	O
here	O
the	O
appearance	O
of	O
the	O
energy	O
surface	O
depends	O
on	O
the	O
current	O
state	B
and	O
we	O
receive	O
a	O
heteroassociator	B
instead	O
of	O
an	O
autoassociator	B
for	O
a	O
heteroassociator	B
ap	O
p	O
is	O
no	O
longer	O
true	O
but	O
rather	O
hp	O
q	O
which	O
means	O
that	O
a	O
pattern	O
is	O
mapped	O
onto	O
another	O
one	O
h	O
is	O
the	O
heteroasso-	O
ciative	O
mapping	O
such	O
heteroassociations	O
are	O
achieved	O
by	O
means	O
of	O
an	O
asymmetric	O
weight	B
matrix	I
v	O
figure	O
illustration	O
of	O
the	O
convergence	O
of	O
an	O
exemplary	O
hopfield	O
network	O
each	O
of	O
the	O
pictures	O
has	O
binary	B
pixels	O
in	O
the	O
hopfield	O
network	O
each	O
pixel	O
corresponds	O
to	O
one	O
neuron	B
the	O
upper	O
illustration	O
shows	O
the	O
training	O
samples	O
the	O
lower	O
shows	O
the	O
convergence	O
of	O
a	O
heavily	O
noisy	O
to	O
the	O
corresponding	O
training	O
sample	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
heteroassociation	O
and	O
analogies	O
to	O
neural	O
data	O
storage	O
heteroassociations	O
connected	O
in	O
series	O
of	O
the	O
form	O
hp	O
q	O
hq	O
r	O
hr	O
s	O
hz	O
p	O
can	O
provoke	O
a	O
fast	O
cycle	O
of	O
states	O
p	O
q	O
r	O
s	O
z	O
p	O
whereby	O
a	O
single	O
pattern	O
is	O
never	O
completely	O
accepted	O
before	O
a	O
pattern	O
is	O
entirely	O
completed	O
the	O
heteroassociation	O
already	O
tries	O
to	O
generate	O
the	O
successor	O
of	O
this	O
pattern	O
additionally	O
the	O
network	O
would	O
never	O
stop	O
since	O
after	O
having	O
reached	O
the	O
last	O
state	B
z	O
it	O
would	O
proceed	O
to	O
the	O
first	O
state	B
p	O
again	O
generating	O
the	O
heteroassociative	O
matrix	O
v	O
we	O
generate	O
the	O
matrix	O
v	O
by	O
means	O
of	O
elements	O
v	O
very	O
similar	O
to	O
the	O
autoassociative	O
matrix	O
with	O
p	O
being	O
transition	O
the	O
training	O
sample	O
before	O
the	O
transition	O
and	O
q	O
being	O
the	O
training	O
sample	O
to	O
be	O
generated	O
from	O
p	O
vij	O
x	O
pq	O
piqj	O
netword	O
is	O
instable	O
while	O
changing	O
states	O
the	O
diagonal	O
of	O
the	O
matrix	O
is	O
again	O
filled	O
with	O
zeros	O
the	O
neuron	B
states	O
are	O
as	O
always	O
adapted	O
during	O
operation	O
several	O
transitions	O
can	O
be	O
introduced	O
into	O
the	O
matrix	O
by	O
a	O
simple	O
addition	O
whereby	O
the	O
said	O
limitation	O
exists	O
here	O
too	O
definition	O
rule	O
for	O
the	O
heteroassociative	O
matrix	O
for	O
two	O
training	O
samples	O
p	O
being	O
predecessor	O
and	O
q	O
being	O
successor	O
of	O
a	O
heteroassociative	O
transition	O
the	O
weights	O
of	O
the	O
heteroassociative	O
matrix	O
v	O
result	O
from	O
the	O
learning	O
rule	O
vij	O
x	O
piqj	O
pq	O
with	O
several	O
heteroassociations	O
being	O
introduced	O
into	O
the	O
network	O
by	O
a	O
simple	O
addition	O
stabilizing	O
the	O
heteroassociations	O
we	O
have	O
already	O
mentioned	O
the	O
problem	O
that	O
the	O
patterns	O
are	O
not	O
completely	O
generated	O
but	O
that	O
the	O
next	O
pattern	O
is	O
already	O
beginning	O
before	O
the	O
generation	O
of	O
the	O
previous	O
pattern	O
is	O
finished	O
this	O
problem	O
can	O
be	O
avoided	O
by	O
not	O
only	O
influencing	O
the	O
network	O
by	O
means	O
of	O
the	O
heteroassociative	O
matrix	O
v	O
but	O
also	O
by	O
the	O
already	O
known	O
autoassociative	O
matrix	O
w	O
additionally	O
the	O
neuron	B
adaptation	O
rule	O
is	O
changed	O
so	O
that	O
competing	O
terms	O
are	O
generated	O
one	O
term	O
autoassociating	O
an	O
existing	O
pattern	O
and	O
one	O
term	O
trying	O
to	O
convert	O
the	O
very	O
same	O
pattern	O
into	O
its	O
successor	O
the	O
associative	O
rule	O
provokes	O
that	O
the	O
network	O
stabilizes	O
a	O
pattern	O
remains	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
hopfield	B
networks	I
dkriesel	O
com	O
there	O
for	O
a	O
while	O
goes	O
on	O
to	O
the	O
next	O
pattern	O
and	O
so	O
on	O
xit	O
x	O
fact	O
wijxjt	O
j	O
k	O
autoassociation	O
k	O
k	O
vikxkt	O
t	O
heteroassociation	O
stable	O
change	O
in	O
states	O
here	O
the	O
value	O
t	O
causes	O
descriptively	O
speaking	O
the	O
influence	O
of	O
the	O
matrix	O
v	O
to	O
be	O
delayed	O
since	O
it	O
only	O
refers	O
to	O
a	O
network	O
being	O
t	O
versions	O
behind	O
the	O
result	O
is	O
a	O
change	O
in	O
state	B
during	O
which	O
the	O
individual	O
states	O
are	O
stable	O
for	O
a	O
short	O
while	O
if	O
t	O
is	O
set	O
to	O
for	O
example	O
twenty	O
steps	O
then	O
the	O
asymmetric	O
weight	B
matrix	I
will	O
realize	O
any	O
change	O
in	O
the	O
network	O
only	O
twenty	O
steps	O
later	O
so	O
that	O
it	O
initially	O
works	O
with	O
the	O
autoassociative	O
matrix	O
it	O
still	O
perceives	O
the	O
predecessor	O
pattern	O
of	O
the	O
current	O
one	O
and	O
only	O
after	O
that	O
it	O
will	O
work	O
against	O
it	O
biological	O
motivation	O
of	O
heterassociation	O
from	O
a	O
biological	O
point	O
of	O
view	O
the	O
transition	O
of	O
stable	O
states	O
into	O
other	O
stable	O
states	O
is	O
highly	O
motivated	O
at	O
least	O
in	O
the	O
beginning	O
of	O
the	O
nineties	O
it	O
was	O
assumed	O
that	O
the	O
hopfield	O
modell	O
will	O
achieve	O
an	O
approximation	B
of	O
the	O
state	B
dynamics	O
in	O
the	O
brain	B
which	O
realizes	O
much	O
by	O
means	O
of	O
state	B
chains	O
when	O
i	O
would	O
ask	O
you	O
dear	O
reader	O
to	O
recite	O
the	O
alphabet	O
you	O
generally	O
will	O
manage	O
this	O
better	O
than	O
try	O
it	O
immediately	O
to	O
answer	O
the	O
following	O
question	O
which	O
letter	O
in	O
the	O
alphabet	O
follows	O
the	O
letter	O
p	O
another	O
example	O
is	O
the	O
phenomenon	O
that	O
one	O
cannot	O
remember	O
a	O
situation	B
but	O
the	O
place	O
at	O
which	O
one	O
memorized	B
it	O
the	O
last	O
time	O
is	O
perfectly	O
known	O
if	O
one	O
returns	O
to	O
this	O
place	O
the	O
forgotten	O
situation	B
often	O
comes	O
back	O
to	O
mind	O
continuous	B
hopfield	B
networks	I
so	O
far	O
we	O
only	O
have	O
discussed	O
hopfield	B
networks	I
with	O
binary	B
activations	O
but	O
hopfield	O
also	O
described	O
a	O
version	O
of	O
his	O
networks	O
with	O
continuous	B
activations	O
which	O
we	O
want	O
to	O
cover	O
at	O
least	O
briefly	O
continuous	B
hopfield	B
networks	I
here	O
the	O
activation	B
is	O
no	O
longer	O
calculated	O
by	O
the	O
binary	B
threshold	I
function	I
but	O
by	O
the	O
fermi	B
function	I
with	O
temperature	O
parameters	O
on	O
the	O
next	O
page	O
here	O
the	O
network	O
is	O
stable	O
for	O
symmetric	O
weight	B
matrices	O
with	O
zeros	O
on	O
the	O
diagonal	O
too	O
hopfield	O
also	O
stated	O
that	O
continuous	B
hopfield	B
networks	I
can	O
be	O
applied	O
to	O
find	O
acceptable	O
solutions	O
for	O
the	O
np-hard	O
travelling	O
salesman	O
problem	O
according	O
to	O
some	O
verification	O
trials	O
this	O
statement	O
can	O
t	O
be	O
kept	O
up	O
any	O
more	O
but	O
today	O
there	O
are	O
faster	O
algorithms	O
for	O
handling	O
this	O
problem	O
and	O
therefore	O
the	O
hopfield	O
network	O
is	O
no	O
longer	O
used	O
here	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
continuous	B
hopfield	B
networks	I
figure	O
the	O
already	O
known	O
fermi	B
function	I
with	O
different	O
temperature	B
parameter	I
variations	O
exercises	O
exercise	O
indicate	O
the	O
storage	O
requirements	O
for	O
a	O
hopfield	O
network	O
with	O
neurons	O
when	O
the	O
weights	O
wij	O
shall	O
be	O
stored	O
as	O
integers	O
is	O
it	O
possible	O
to	O
limit	O
the	O
value	O
range	O
of	O
the	O
weights	O
in	O
order	O
to	O
save	O
storage	O
space	O
exercise	O
compute	O
the	O
weights	O
wij	O
for	O
a	O
hopfield	O
network	O
using	O
the	O
training	B
set	I
p	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
function	O
with	O
temperature	B
parameter	I
chapter	O
learning	B
vector	I
quantization	B
learning	B
vector	I
quantization	B
is	O
a	O
learning	O
procedure	O
with	O
the	O
aim	O
to	O
represent	O
the	O
vector	O
training	O
sets	O
divided	O
into	O
predefined	O
classes	O
as	O
well	O
as	O
possible	O
by	O
using	O
a	O
few	O
representative	O
vectors	O
if	O
this	O
has	O
been	O
managed	O
vectors	O
which	O
were	O
unkown	O
until	O
then	O
could	O
easily	O
be	O
assigned	O
to	O
one	O
of	O
these	O
classes	O
slowly	O
part	O
ii	O
of	O
this	O
text	O
is	O
nearing	O
its	O
end	O
and	O
therefore	O
i	O
want	O
to	O
write	O
a	O
last	O
chapter	O
for	O
this	O
part	O
that	O
will	O
be	O
a	O
smooth	O
transition	O
into	O
the	O
next	O
one	O
a	O
chapter	O
about	O
the	O
learning	B
vector	I
quantization	B
lvq	O
described	O
by	O
teuvo	O
kohonen	O
which	O
can	O
be	O
characterized	O
as	O
being	O
related	O
to	O
the	O
self	O
organizing	O
feature	O
maps	O
these	O
soms	O
are	O
described	O
in	O
the	O
next	O
chapter	O
that	O
already	O
belongs	O
to	O
part	O
iii	O
of	O
this	O
text	O
since	O
soms	O
learn	O
unsupervised	B
thus	O
after	O
the	O
exploration	O
of	O
lvq	O
i	O
want	O
to	O
bid	O
farewell	O
to	O
supervised	B
learning	O
previously	O
i	O
want	O
to	O
announce	O
that	O
there	O
are	O
different	O
variations	O
of	O
lvq	O
which	O
will	O
be	O
mentioned	O
but	O
not	O
exactly	O
represented	O
the	O
goal	O
of	O
this	O
chapter	O
is	O
rather	O
to	O
analyze	O
the	O
underlying	O
principle	O
about	O
quantization	B
in	O
order	O
to	O
explore	O
the	O
learning	B
vector	I
quantization	B
we	O
should	O
at	O
first	O
get	O
a	O
clearer	O
picture	O
of	O
what	O
quantization	B
can	O
also	O
be	O
referred	O
to	O
as	O
discretization	O
is	O
everybody	O
knows	O
the	O
sequence	O
of	O
discrete	B
numbers	O
n	O
which	O
contains	O
the	O
natural	O
numbers	O
discrete	B
means	O
that	O
this	O
sequence	O
consists	O
of	O
separated	O
elements	O
that	O
are	O
not	O
interconnected	O
the	O
elements	O
of	O
our	O
example	O
are	O
exactly	O
such	O
numbers	O
because	O
the	O
natural	O
numbers	O
do	O
not	O
include	O
for	O
example	O
numbers	O
between	O
and	O
on	O
the	O
other	O
hand	O
the	O
sequence	O
of	O
real	O
numbers	O
r	O
for	O
instance	O
is	O
continuous	B
it	O
does	O
not	O
matter	O
how	O
close	O
two	O
selected	O
numbers	O
are	O
there	O
will	O
always	O
be	O
a	O
number	O
between	O
them	O
discrete	B
separated	O
chapter	O
learning	B
vector	I
quantization	B
dkriesel	O
com	O
quantization	B
means	O
that	O
a	O
continuous	B
space	O
is	O
divided	O
into	O
discrete	B
sections	O
by	O
deleting	O
for	O
example	O
all	O
decimal	O
places	O
of	O
the	O
real	O
number	O
it	O
could	O
be	O
assigned	O
to	O
the	O
natural	O
number	O
here	O
it	O
is	O
obvious	O
that	O
any	O
other	O
number	O
having	O
a	O
in	O
front	O
of	O
the	O
comma	O
would	O
also	O
be	O
assigned	O
to	O
the	O
natural	O
number	O
i	O
e	O
would	O
be	O
some	O
kind	O
of	O
representative	O
for	O
all	O
real	O
numbers	O
within	O
the	O
interval	O
it	O
must	O
be	O
noted	O
that	O
a	O
sequence	O
can	O
be	O
irregularly	O
quantized	O
too	O
for	O
instance	O
the	O
timeline	O
for	O
a	O
week	O
could	O
be	O
quantized	O
into	O
working	O
days	O
and	O
weekend	O
a	O
special	O
case	O
of	O
quantization	B
is	O
digitization	B
in	O
case	O
of	O
digitization	B
we	O
always	O
talk	O
about	O
regular	O
quantization	B
of	O
a	O
continuous	B
space	O
into	O
a	O
number	O
system	O
with	O
respect	O
to	O
a	O
certain	O
basis	B
if	O
we	O
enter	O
for	O
example	O
some	O
numbers	O
into	O
the	O
computer	O
these	O
numbers	O
will	O
be	O
digitized	O
into	O
the	O
binary	B
system	O
definition	O
separation	O
of	O
a	O
continuous	B
space	O
into	O
discrete	B
sections	O
definition	O
regular	O
quantization	B
lvq	O
divides	O
the	O
input	B
space	O
into	O
separate	O
areas	O
now	O
it	O
is	O
almost	O
possible	O
to	O
describe	O
by	O
means	O
of	O
its	O
name	O
what	O
lvq	O
should	O
enable	O
us	O
to	O
do	O
a	O
set	B
of	I
representatives	O
should	O
be	O
used	O
to	O
divide	O
an	O
input	B
space	O
input	B
space	O
reduced	O
to	O
vector	O
representatives	O
into	O
classes	O
that	O
reflect	O
the	O
input	B
space	O
as	O
well	O
as	O
possible	O
on	O
the	O
facing	O
page	O
thus	O
each	O
element	O
of	O
the	O
input	B
space	O
should	O
be	O
assigned	O
to	O
a	O
vector	O
as	O
a	O
representative	O
i	O
e	O
to	O
a	O
class	O
where	O
the	O
set	B
of	I
these	O
representatives	O
should	O
represent	O
the	O
entire	O
input	B
space	O
as	O
precisely	O
as	O
possible	O
such	O
a	O
vector	O
is	O
called	O
codebook	B
vector	I
a	O
codebook	B
vector	I
is	O
the	O
representative	O
of	O
exactly	O
those	O
input	B
space	O
vectors	O
lying	O
closest	O
to	O
it	O
which	O
divides	O
the	O
input	B
space	O
into	O
the	O
said	O
discrete	B
areas	O
it	O
is	O
to	O
be	O
emphasized	O
that	O
we	O
have	O
to	O
know	O
in	O
advance	O
how	O
many	O
classes	O
we	O
have	O
and	O
which	O
training	O
sample	O
belongs	O
to	O
which	O
class	O
furthermore	O
it	O
is	O
important	O
that	O
the	O
classes	O
must	O
not	O
be	O
disjoint	O
which	O
means	O
they	O
may	O
overlap	O
such	O
separation	O
of	O
data	O
into	O
classes	O
is	O
interesting	O
for	O
many	O
problems	B
for	O
which	O
it	O
is	O
useful	O
to	O
explore	O
only	O
some	O
characteristic	O
representatives	O
instead	O
of	O
the	O
possibly	O
huge	O
set	B
of	I
all	O
vectors	O
be	O
it	O
because	O
it	O
is	O
less	O
time-consuming	O
or	O
because	O
it	O
is	O
sufficiently	O
precise	B
using	O
codebook	O
vectors	O
the	O
nearest	O
one	O
is	O
the	O
winner	B
the	O
use	O
of	O
a	O
prepared	O
set	B
of	I
codebook	O
vectors	O
is	O
very	O
simple	O
for	O
an	O
input	B
vector	I
y	O
the	O
class	O
association	B
is	O
easily	O
decided	O
by	O
considering	O
which	O
codebook	B
vector	I
is	O
the	O
closest	O
so	O
the	O
codebook	O
vectors	O
build	O
a	O
voronoi	B
diagram	I
out	O
of	O
the	O
set	O
since	O
closest	O
vector	O
wins	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
adjusting	O
codebook	O
vectors	O
figure	O
bexamples	O
for	O
quantization	B
of	O
a	O
two-dimensional	O
input	B
space	O
dthe	O
lines	O
represent	O
the	O
class	O
limit	O
the	O
mark	O
the	O
codebook	O
vectors	O
each	O
codebook	B
vector	I
can	O
clearly	O
be	O
associated	O
to	O
a	O
class	O
each	O
input	B
vector	I
is	O
associated	O
to	O
a	O
class	O
too	O
are	O
used	O
to	O
cause	O
a	O
previously	O
defined	O
number	O
of	O
randomly	O
initialized	O
codebook	O
vectors	O
to	O
reflect	O
the	O
training	O
data	O
as	O
precisely	O
as	O
possible	O
adjusting	O
codebook	O
vectors	O
as	O
we	O
have	O
already	O
indicated	O
the	O
lvq	O
is	O
a	O
supervised	B
learning	O
procedure	O
thus	O
we	O
have	O
a	O
teaching	B
input	B
that	O
tells	O
the	O
learning	O
procedure	O
whether	O
the	O
classification	O
of	O
the	O
input	B
pattern	O
is	O
right	O
or	O
wrong	O
in	O
other	O
words	O
we	O
have	O
to	O
know	O
in	O
advance	O
the	O
number	O
of	O
classes	O
to	O
be	O
represented	O
or	O
the	O
number	O
of	O
codebook	O
vectors	O
roughly	O
speaking	O
it	O
is	O
the	O
aim	O
of	O
the	O
learning	O
procedure	O
that	O
training	O
samples	O
the	O
procedure	O
of	O
learning	O
learning	O
works	O
according	O
to	O
a	O
simple	O
scheme	O
we	O
have	O
learning	O
is	O
supervised	B
a	O
set	O
p	O
of	O
training	O
samples	O
additionally	O
we	O
already	O
know	O
that	O
classes	O
are	O
predefined	O
too	O
i	O
e	O
we	O
also	O
have	O
a	O
set	B
of	I
classes	O
c	O
a	O
codebook	B
vector	I
is	O
clearly	O
assigned	O
to	O
each	O
class	O
thus	O
we	O
can	O
say	O
that	O
the	O
set	B
of	I
classes	O
contains	O
many	O
codebook	O
vectors	O
cc	O
this	O
leads	O
to	O
the	O
structure	O
of	O
the	O
training	O
samples	O
they	O
are	O
of	O
the	O
form	O
c	O
and	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
learning	B
vector	I
quantization	B
dkriesel	O
com	O
therefore	O
contain	O
the	O
training	O
input	B
vector	I
p	O
and	O
its	O
class	O
affiliation	O
c	O
for	O
the	O
class	O
affiliation	O
c	O
holds	O
which	O
means	O
that	O
it	O
clearly	O
assigns	O
the	O
training	O
sample	O
to	O
a	O
class	O
or	O
a	O
codebook	B
vector	I
intuitively	O
we	O
could	O
say	O
about	O
learning	O
a	O
learning	O
procedure	O
we	O
calculate	O
the	O
average	O
of	O
all	O
class	O
members	O
and	O
place	O
their	O
codebook	O
vectors	O
there	O
and	O
that	O
s	O
it	O
but	O
we	O
will	O
see	O
soon	O
that	O
our	O
learning	O
procedure	O
can	O
do	O
a	O
lot	O
more	O
i	O
only	O
want	O
to	O
briefly	O
discuss	O
the	O
steps	O
of	O
the	O
fundamental	O
lvq	O
learning	O
procedure	O
initialization	O
we	O
place	O
our	O
set	B
of	I
codebook	O
vectors	O
on	O
random	O
positions	O
in	O
the	O
input	B
space	O
training	O
sample	O
a	O
training	O
sample	O
p	O
of	O
our	O
training	B
set	I
p	O
is	O
selected	O
and	O
presented	O
distance	O
measurement	O
we	O
measure	O
the	O
distance	O
c	O
between	O
all	O
codebook	O
vectors	O
cc	O
and	O
our	O
input	B
p	O
winner	B
the	O
wins	O
i	O
e	O
the	O
one	O
with	O
closest	O
codebook	B
vector	I
ci	O
min	O
ci	O
c	O
learning	O
process	O
the	O
learning	O
process	O
takes	O
place	O
according	O
to	O
the	O
rule	O
ci	O
hp	O
ci	O
ci	O
cit	O
cit	O
ci	O
which	O
we	O
now	O
want	O
to	O
break	O
down	O
we	O
have	O
already	O
seen	O
that	O
the	O
first	O
factor	O
is	O
a	O
time-dependent	O
learning	B
rate	I
allowing	O
us	O
to	O
differentiate	O
between	O
large	O
learning	O
steps	O
and	O
fine	O
tuning	O
the	O
last	O
factor	O
ci	O
is	O
obviously	O
the	O
direction	O
toward	O
which	O
the	O
codebook	B
vector	I
is	O
moved	O
but	O
the	O
function	O
hp	O
ci	O
is	O
the	O
core	O
of	O
the	O
rule	O
it	O
implements	O
a	O
distinction	O
of	O
cases	O
assignment	O
is	O
correct	O
the	O
winner	B
vector	O
is	O
the	O
codebook	B
vector	I
of	O
the	O
class	O
that	O
includes	O
p	O
in	O
this	O
case	O
the	O
function	O
provides	O
positive	O
values	O
and	O
the	O
codebook	B
vector	I
moves	O
towards	O
p	O
assignment	O
is	O
wrong	O
the	O
winner	B
vector	O
does	O
not	O
represent	O
the	O
class	O
that	O
includes	O
p	O
therefore	O
it	O
moves	O
away	O
from	O
p	O
we	O
can	O
see	O
that	O
our	O
definition	O
of	O
the	O
function	O
h	O
was	O
not	O
precise	B
enough	O
with	O
good	O
reason	O
from	O
here	O
on	O
the	O
lvq	O
is	O
divided	O
into	O
different	O
nuances	O
dependent	O
of	O
how	O
exactly	O
h	O
and	O
the	O
learning	B
rate	I
should	O
be	O
defined	O
important	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
connection	B
to	O
neural	O
networks	O
olvq	B
etc	O
the	O
differences	O
are	O
for	O
instance	O
in	O
the	O
strength	O
of	O
the	O
codebook	B
vector	I
movements	O
they	O
are	O
not	O
all	O
based	O
on	O
the	O
same	O
principle	O
described	O
here	O
and	O
as	O
announced	O
i	O
don	O
t	O
want	O
to	O
discuss	O
them	O
any	O
further	O
therefore	O
i	O
don	O
t	O
give	O
any	O
formal	O
definition	O
regarding	O
the	O
aforementioned	O
learning	O
rule	O
and	O
lvq	O
exercises	O
exercise	O
indicate	O
a	O
quantization	B
which	O
equally	O
distributes	O
all	O
vectors	O
h	O
h	O
in	O
the	O
five-dimensional	O
unit	O
cube	O
h	O
into	O
one	O
of	O
classes	O
vectors	O
neurons	O
connection	B
to	O
neural	O
networks	O
until	O
now	O
in	O
spite	O
of	O
the	O
learning	O
process	O
the	O
question	O
was	O
what	O
lvq	O
has	O
to	O
do	O
with	O
neural	O
networks	O
the	O
codebook	O
vectors	O
can	O
be	O
understood	O
as	O
neurons	O
with	O
a	O
fixed	O
position	O
within	O
the	O
input	B
space	O
similar	O
to	O
rbf	B
networks	O
additionally	O
in	O
nature	O
it	O
often	O
occurs	O
that	O
in	O
a	O
group	O
one	O
neuron	B
may	O
fire	O
winner	B
neuron	B
here	O
a	O
codebook	B
vector	I
and	O
in	O
return	B
inhibits	O
all	O
other	O
neurons	O
i	O
decided	O
to	O
place	O
this	O
brief	O
chapter	O
about	O
learning	B
vector	I
quantization	B
here	O
so	O
that	O
this	O
approach	O
can	O
be	O
continued	O
in	O
the	O
following	O
chapter	O
about	O
self-organizing	O
maps	O
we	O
will	O
classify	O
further	O
inputs	O
by	O
means	O
of	O
neurons	O
distributed	O
throughout	O
the	O
input	B
space	O
only	O
that	O
this	O
time	O
we	O
do	O
not	O
know	O
which	O
input	B
belongs	O
to	O
which	O
class	O
now	O
let	O
us	O
take	O
a	O
look	O
at	O
the	O
unsupervised	B
learning	O
networks	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
part	O
iii	O
unsupervised	B
learning	O
network	O
paradigms	O
chapter	O
self-organizing	B
feature	I
maps	I
a	O
paradigm	O
of	O
unsupervised	B
learning	O
neural	O
networks	O
which	O
maps	O
an	O
input	B
space	O
by	O
its	O
fixed	O
topology	B
and	O
thus	O
independently	O
looks	O
for	O
simililarities	O
function	O
learning	O
procedure	O
variations	O
and	O
neural	B
gas	I
no	O
output	B
but	O
active	O
neuron	B
if	O
you	O
take	O
a	O
look	O
at	O
the	O
concepts	O
of	O
biological	O
neural	O
networks	O
mentioned	O
in	O
the	O
introduction	O
one	O
question	O
will	O
arise	O
how	O
does	O
our	O
brain	B
store	O
and	O
recall	O
the	O
impressions	O
it	O
receives	O
every	O
day	O
let	O
me	O
point	O
out	O
that	O
the	O
brain	B
does	O
not	O
have	O
any	O
training	O
samples	O
and	O
therefore	O
no	O
output	B
and	O
while	O
already	O
considering	O
this	O
subject	O
we	O
realize	O
that	O
there	O
is	O
no	O
output	B
in	O
this	O
sense	O
at	O
all	O
too	O
our	O
brain	B
responds	O
to	O
external	O
input	B
by	O
changes	O
in	O
state	B
these	O
are	O
so	O
to	O
speak	O
its	O
output	B
how	O
are	O
data	O
stored	O
in	O
the	O
brain	B
based	O
on	O
this	O
principle	O
and	O
exploring	O
the	O
question	O
of	O
how	O
biological	O
neural	O
networks	O
organize	O
themselves	O
teuvo	O
kohonen	O
developed	O
in	O
the	O
eighties	O
his	O
selforganizing	O
feature	O
maps	O
shortly	O
referred	O
to	O
as	O
self-organizing	O
maps	O
or	O
soms	O
a	O
paradigm	O
of	O
neural	O
networks	O
where	O
the	O
output	B
is	O
the	O
state	B
of	O
the	O
network	O
which	O
learns	O
completely	O
unsupervised	B
i	O
e	O
without	O
a	O
teacher	O
unlike	O
the	O
other	O
network	O
paradigms	O
we	O
have	O
already	O
got	O
to	O
know	O
for	O
soms	O
it	O
is	O
unnecessary	O
to	O
ask	O
what	O
the	O
neurons	O
calculate	O
we	O
only	O
ask	O
which	O
neuron	B
is	O
active	O
at	O
the	O
moment	O
biologically	O
this	O
is	O
very	O
motivated	O
if	O
in	O
biology	O
the	O
neurons	O
are	O
connected	O
to	O
certain	O
muscles	O
it	O
will	O
be	O
less	O
interesting	O
to	O
know	O
how	O
strong	O
a	O
certain	O
muscle	O
is	O
contracted	O
but	O
which	O
muscle	O
is	O
activated	O
in	O
other	O
words	O
we	O
are	O
not	O
interested	O
in	O
the	O
exact	O
output	B
of	O
the	O
neuron	B
but	O
in	O
knowing	O
which	O
neuron	B
provides	O
output	B
thus	O
soms	O
are	O
considerably	O
more	O
related	O
to	O
biology	O
than	O
for	O
example	O
the	O
feedforward	B
networks	O
which	O
are	O
increasingly	O
used	O
for	O
calculations	O
structure	O
of	O
a	O
self-organizing	B
map	I
typically	O
soms	O
have	O
like	O
our	O
brain	B
the	O
task	O
to	O
map	O
a	O
high-dimensional	O
input	B
dimensions	O
onto	O
areas	O
in	O
a	O
low	O
chapter	O
self-organizing	B
feature	I
maps	I
dkriesel	O
com	O
dimensional	O
grid	B
of	O
cells	O
dimensions	O
to	O
draw	O
a	O
map	O
of	O
the	O
high-dimensional	O
space	O
so	O
to	O
speak	O
to	O
generate	O
this	O
map	O
the	O
som	O
simply	O
obtains	O
arbitrary	O
many	O
points	O
of	O
the	O
input	B
space	O
during	O
the	O
input	B
of	O
the	O
points	O
the	O
som	O
will	O
try	O
to	O
cover	O
as	O
good	O
as	O
possible	O
the	O
positions	O
on	O
which	O
the	O
points	O
appear	O
by	O
its	O
neurons	O
this	O
particularly	O
means	O
that	O
every	O
neuron	B
can	O
be	O
assigned	O
to	O
a	O
certain	O
position	O
in	O
the	O
input	B
space	O
at	O
first	O
these	O
facts	O
seem	O
to	O
be	O
a	O
bit	O
confusing	O
and	O
it	O
is	O
recommended	O
to	O
briefly	O
reflect	O
about	O
them	O
there	O
are	O
two	O
spaces	O
in	O
which	O
soms	O
are	O
working	O
the	O
n-dimensional	O
input	B
space	O
and	O
the	O
g-dimensional	O
grid	B
on	O
which	O
the	O
neurons	O
are	O
lying	O
and	O
which	O
indicates	O
the	O
neighborhood	O
relationships	O
between	O
the	O
neurons	O
and	O
therefore	O
the	O
network	O
topology	B
in	O
a	O
one-dimensional	O
grid	B
the	O
neurons	O
could	O
be	O
for	O
instance	O
like	O
pearls	O
on	O
a	O
string	O
every	O
neuron	B
would	O
have	O
exactly	O
two	O
neighbors	O
for	O
the	O
two	O
end	O
neurons	O
a	O
two-dimensional	O
grid	B
could	O
be	O
a	O
square	O
array	O
of	O
neurons	O
another	O
possible	O
array	O
in	O
two-dimensional	O
space	O
would	O
be	O
some	O
kind	O
of	O
honeycomb	O
shape	O
irregular	O
topologies	O
are	O
possible	O
too	O
but	O
not	O
very	O
often	O
topolgies	O
with	O
more	O
dimensions	O
and	O
considerably	O
more	O
neighborhood	O
relationships	O
would	O
also	O
be	O
possible	O
but	O
due	O
to	O
their	O
lack	O
of	O
visualization	O
capability	O
they	O
are	O
not	O
employed	O
very	O
often	O
high-dim	O
input	B
low-dim	O
map	O
input	B
space	O
and	O
topology	B
important	O
topologies	O
of	O
a	O
selffigure	O
example	O
organizing	O
map	O
above	O
we	O
can	O
see	O
a	O
onedimensional	O
topology	B
below	O
a	O
two-dimensional	O
one	O
even	O
if	O
n	O
g	O
is	O
true	O
the	O
two	O
spaces	O
are	O
not	O
equal	O
and	O
have	O
to	O
be	O
distinguished	O
in	O
this	O
special	O
case	O
they	O
only	O
have	O
the	O
same	O
dimension	O
initially	O
we	O
will	O
briefly	O
and	O
formally	O
regard	O
the	O
functionality	O
of	O
a	O
self-organizing	B
map	I
and	O
then	O
make	O
it	O
clear	O
by	O
means	O
of	O
some	O
examples	O
definition	O
neuron	B
similar	O
to	O
the	O
neurons	O
in	O
an	O
rbf	B
network	I
a	O
som	O
neuron	B
k	O
does	O
not	O
occupy	O
a	O
fixed	O
position	O
ck	O
center	O
in	O
the	O
input	B
space	O
definition	O
map	O
a	O
self-organizing	B
map	I
is	O
a	O
set	O
k	O
of	O
som	O
neurons	O
if	O
an	O
input	B
vector	I
is	O
entered	O
ex-	O
actly	O
that	O
neuron	B
k	O
k	O
is	O
activated	O
which	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
input	B
winner	B
dkriesel	O
com	O
training	O
is	O
closest	O
to	O
the	O
input	B
pattern	O
in	O
the	O
input	B
space	O
the	O
dimension	O
of	O
the	O
input	B
space	O
is	O
referred	O
to	O
as	O
n	O
definition	O
the	O
neurons	O
are	O
interconnected	O
by	O
neighborhood	O
relationships	O
these	O
neighborhood	O
relationships	O
are	O
called	O
topology	B
the	O
training	O
of	O
a	O
som	O
is	O
highly	O
influenced	O
by	O
the	O
it	O
is	O
defined	O
by	O
the	O
topology	B
topology	B
function	I
hi	O
k	O
t	O
where	O
i	O
is	O
the	O
winner	B
ist	O
k	O
the	O
neuron	B
to	O
be	O
adapted	O
will	O
be	O
discussed	O
later	O
and	O
t	O
the	O
timestep	O
the	O
dimension	O
of	O
the	O
topology	B
is	O
referred	O
to	O
as	O
g	O
soms	O
always	O
activate	O
the	O
neuron	B
with	O
the	O
least	O
distance	O
to	O
an	O
input	B
pattern	O
like	O
many	O
other	O
neural	O
networks	O
the	O
som	O
has	O
to	O
be	O
trained	O
before	O
it	O
can	O
be	O
used	O
but	O
let	O
us	O
regard	O
the	O
very	O
simple	O
functionality	O
of	O
a	O
complete	O
self-organizing	B
map	I
before	O
training	O
since	O
there	O
are	O
many	O
analogies	O
to	O
the	O
training	O
functionality	O
consists	O
of	O
the	O
following	O
steps	O
input	B
of	O
an	O
arbitrary	O
value	O
p	O
of	O
the	O
input	B
space	O
rn	O
calculation	O
of	O
the	O
distance	O
between	O
every	O
neuron	B
k	O
and	O
p	O
by	O
means	O
of	O
a	O
norm	O
i	O
e	O
calculation	O
of	O
ck	O
one	O
neuron	B
becomes	O
active	O
namely	O
such	O
neuron	B
i	O
with	O
the	O
shortest	O
we	O
will	O
learn	O
soon	O
what	O
a	O
winner	B
neuron	B
is	O
calculated	O
distance	B
to	I
the	I
input	B
all	O
other	O
neurons	O
remain	O
inactive	O
this	O
paradigm	O
of	O
activity	O
is	O
also	O
called	O
winner-takes-all	B
scheme	I
the	O
output	B
we	O
expect	O
due	O
to	O
the	O
input	B
of	O
a	O
som	O
shows	O
which	O
neuron	B
becomes	O
active	O
in	O
many	O
literature	O
citations	O
the	O
description	O
of	O
soms	O
is	O
more	O
formal	O
often	O
an	O
input	B
layer	O
is	O
described	O
that	O
is	O
completely	O
linked	O
towards	O
an	O
som	O
layer	O
then	O
the	O
input	B
layer	O
neurons	O
forwards	O
all	O
inputs	O
to	O
the	O
som	O
layer	O
the	O
som	O
layer	O
is	O
laterally	O
linked	O
in	O
itself	O
so	O
that	O
a	O
winner	B
neuron	B
can	O
be	O
established	O
and	O
inhibit	O
the	O
other	O
neurons	O
i	O
think	O
that	O
this	O
explanation	O
of	O
a	O
som	O
is	O
not	O
very	O
descriptive	O
and	O
therefore	O
i	O
tried	O
to	O
provide	O
a	O
clearer	O
description	O
of	O
the	O
network	O
structure	O
now	O
the	O
question	O
is	O
which	O
neuron	B
is	O
activated	O
by	O
which	O
input	B
and	O
the	O
answer	O
is	O
given	O
by	O
the	O
network	O
itself	O
during	O
training	O
training	O
makes	O
the	O
som	O
topology	B
cover	O
the	O
input	B
space	O
the	O
training	O
of	O
a	O
som	O
is	O
nearly	O
as	O
straightforward	O
as	O
the	O
functionality	O
described	O
above	O
basically	O
it	O
is	O
structured	O
into	O
five	O
steps	O
which	O
partially	O
correspond	O
to	O
those	O
of	O
functionality	O
initialization	O
the	O
network	O
starts	O
with	O
random	O
neuron	B
centers	O
ck	O
rn	O
from	O
the	O
input	B
space	O
creating	O
an	O
input	B
pattern	O
a	O
stimulus	B
i	O
e	O
a	O
point	O
p	O
is	O
selected	O
from	O
the	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
self-organizing	B
feature	I
maps	I
dkriesel	O
com	O
training	O
input	B
winner	B
i	O
change	O
in	O
position	O
i	O
and	O
neighbors	O
input	B
space	O
rn	O
now	O
this	O
stimulus	B
is	O
entered	O
into	O
the	O
network	O
distance	O
measurement	O
then	O
the	O
distance	O
ck	O
is	O
determined	O
for	O
every	O
neuron	B
k	O
in	O
the	O
network	O
winner	B
takes	O
all	O
the	O
winner	B
neuron	B
i	O
is	O
determined	O
which	O
has	O
the	O
smallest	O
distance	O
to	O
p	O
i	O
e	O
which	O
fulfills	O
the	O
condition	O
ci	O
ck	O
k	O
i	O
you	O
can	O
see	O
that	O
from	O
several	O
winner	B
neurons	O
one	O
can	O
be	O
selected	O
at	O
will	O
adapting	O
the	O
centers	O
the	O
neuron	B
centers	O
are	O
moved	O
within	O
the	O
input	B
space	O
according	O
to	O
the	O
ck	O
hi	O
k	O
t	O
ck	O
where	O
the	O
values	O
ck	O
are	O
simply	O
added	O
to	O
the	O
existing	O
centers	O
the	O
last	O
factor	O
shows	O
that	O
the	O
change	O
in	O
position	O
of	O
the	O
neurons	O
k	O
is	O
proportional	O
to	O
the	O
distance	B
to	I
the	I
input	B
pattern	O
p	O
and	O
as	O
usual	O
to	O
a	O
timedependent	O
learning	B
rate	I
the	O
above-mentioned	O
network	O
topology	B
exerts	O
its	O
influence	O
by	O
means	O
of	O
the	O
function	O
hi	O
k	O
t	O
which	O
will	O
be	O
discussed	O
in	O
the	O
following	O
note	O
in	O
many	O
sources	O
this	O
rule	O
is	O
written	O
hp	O
ck	O
which	O
wrongly	O
leads	O
the	O
reader	O
to	O
believe	O
that	O
h	O
is	O
a	O
constant	O
this	O
problem	O
can	O
easily	O
be	O
solved	O
by	O
not	O
omitting	O
the	O
multiplication	O
dots	O
definition	O
learning	O
rule	O
a	O
som	O
is	O
trained	O
by	O
presenting	O
an	O
input	B
pattern	O
and	O
determining	O
the	O
associated	O
winner	B
neuron	B
the	O
winner	B
neuron	B
and	O
its	O
neighbor	O
neurons	O
which	O
are	O
defined	O
by	O
the	O
topology	B
function	I
then	O
adapt	O
their	O
centers	O
according	O
to	O
the	O
rule	O
ck	O
hi	O
k	O
t	O
ck	O
ckt	O
ckt	O
ckt	O
the	O
topology	B
function	I
defines	O
how	O
a	O
learning	O
neuron	B
influences	O
its	O
neighbors	O
the	O
topology	B
function	I
h	O
is	O
not	O
defined	O
on	O
the	O
input	B
space	O
but	O
on	O
the	O
grid	B
and	O
represents	O
the	O
neighborhood	O
relationships	O
between	O
the	O
neurons	O
i	O
e	O
the	O
topology	B
of	O
the	O
network	O
it	O
can	O
be	O
time-dependent	O
it	O
often	O
is	O
which	O
explains	O
the	O
parameter	O
t	O
the	O
parameter	O
k	O
is	O
the	O
index	O
running	O
through	O
all	O
neurons	O
and	O
the	O
parameter	O
i	O
is	O
the	O
index	O
of	O
the	O
winner	B
neuron	B
in	O
principle	O
the	O
function	O
shall	O
take	O
a	O
large	O
value	O
if	O
k	O
is	O
the	O
neighbor	O
of	O
the	O
winner	B
neuron	B
or	O
even	O
the	O
winner	B
neuron	B
itself	O
and	O
small	O
values	O
if	O
not	O
smore	O
precise	B
definition	O
the	O
topology	B
function	I
must	O
be	O
unimodal	O
i	O
e	O
it	O
must	O
have	O
exactly	O
one	O
maximum	O
this	O
maximum	O
must	O
be	O
next	O
to	O
the	O
winner	B
neuron	B
i	O
for	O
which	O
the	O
distance	O
to	O
itself	O
certainly	O
is	O
additionally	O
the	O
time-dependence	O
enables	O
us	O
for	O
example	O
to	O
reduce	O
the	O
neighborhood	O
in	O
the	O
course	O
of	O
time	O
defined	O
on	O
the	O
grid	B
only	O
maximum	O
for	O
the	O
winner	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
training	O
in	O
order	O
to	O
be	O
able	O
to	O
output	B
large	O
values	O
for	O
the	O
neighbors	O
of	O
i	O
and	O
small	O
values	O
for	O
non-neighbors	O
the	O
function	O
h	O
needs	O
some	O
kind	O
of	O
distance	O
notion	O
on	O
the	O
grid	B
because	O
from	O
somewhere	O
it	O
has	O
to	O
know	O
how	O
far	O
i	O
and	O
k	O
are	O
apart	O
from	O
each	O
other	O
on	O
the	O
grid	B
there	O
are	O
different	O
methods	O
to	O
calculate	O
this	O
distance	O
on	O
a	O
two-dimensional	O
grid	B
we	O
could	O
apply	O
for	O
instance	O
the	O
euclidean	B
distance	O
part	O
of	O
fig	O
or	O
on	O
a	O
one-dimensional	O
grid	B
we	O
could	O
simply	O
use	O
the	O
number	O
of	O
the	O
connections	O
between	O
the	O
neurons	O
i	O
and	O
k	O
part	O
of	O
the	O
same	O
figure	O
definition	O
function	O
the	O
topology	B
function	I
hi	O
k	O
t	O
describes	O
the	O
neighborhood	O
relationships	O
in	O
the	O
topology	B
it	O
can	O
be	O
any	O
unimodal	O
function	O
that	O
reaches	O
its	O
maximum	O
when	O
i	O
k	O
gilt	O
time-dependence	O
is	O
optional	O
but	O
often	O
used	O
introduction	O
of	O
common	O
distance	O
and	O
topology	B
functions	O
a	O
common	O
distance	O
function	O
would	O
be	O
for	O
example	O
the	O
already	O
known	O
gaussian	B
bell	I
fig	O
on	O
page	O
it	O
is	O
unimodal	O
with	O
a	O
maximum	O
close	O
to	O
additionally	O
its	O
width	O
can	O
be	O
changed	O
by	O
applying	O
its	O
parameter	O
which	O
can	O
be	O
used	O
to	O
realize	O
the	O
neighborhood	O
being	O
reduced	O
in	O
the	O
course	O
of	O
time	O
we	O
simply	O
relate	O
the	O
time-dependence	O
to	O
the	O
and	O
the	O
result	O
is	O
figure	O
example	O
distances	O
of	O
a	O
onedimensional	O
som	O
topology	B
and	O
a	O
twodimensional	O
som	O
topology	B
between	O
two	O
neurons	O
i	O
and	O
k	O
in	O
the	O
lower	O
case	O
the	O
euclidean	B
distance	O
is	O
determined	O
two-dimensional	O
space	O
equivalent	O
to	O
the	O
pythagoream	O
theorem	O
in	O
the	O
upper	O
case	O
we	O
simply	O
count	O
the	O
discrete	B
path	O
length	O
between	O
i	O
and	O
k	O
to	O
simplify	O
matters	O
i	O
required	O
a	O
fixed	O
grid	B
edge	O
length	O
of	O
in	O
both	O
cases	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
o	O
o	O
o	O
x	O
x	O
o	O
o	O
o	O
chapter	O
self-organizing	B
feature	I
maps	I
dkriesel	O
com	O
a	O
monotonically	O
decreasing	O
then	O
our	O
topology	B
function	I
could	O
look	O
like	O
this	O
typical	O
sizes	O
of	O
the	O
target	B
value	O
of	O
a	O
learning	B
rate	I
are	O
two	O
sizes	O
smaller	O
than	O
the	O
initial	O
value	O
e	O
g	O
hi	O
k	O
t	O
e	O
where	O
gi	O
and	O
gk	O
represent	O
the	O
neuron	B
positions	O
on	O
the	O
grid	B
not	O
the	O
neuron	B
positions	O
in	O
the	O
input	B
space	O
which	O
would	O
be	O
referred	O
to	O
as	O
ci	O
and	O
ck	O
other	O
functions	O
that	O
can	O
be	O
used	O
instead	O
of	O
the	O
gaussian	O
function	O
are	O
for	O
instance	O
the	O
cone	B
function	I
the	O
cylinder	B
function	I
or	O
the	O
mexican	B
hat	I
function	I
on	O
the	O
facing	O
page	O
here	O
the	O
mexican	B
hat	I
function	I
offers	O
a	O
particular	O
biological	O
motivation	O
due	O
to	O
its	O
negative	O
digits	O
it	O
rejects	O
some	O
neurons	O
close	O
to	O
the	O
winner	B
neuron	B
a	O
behavior	O
that	O
has	O
already	O
been	O
observed	O
in	O
nature	O
this	O
can	O
cause	O
sharply	O
separated	O
map	O
areas	O
and	O
that	O
is	O
exactly	O
why	O
the	O
mexican	B
hat	I
function	I
has	O
been	O
suggested	O
by	O
teuvo	O
kohonen	O
himself	O
but	O
this	O
adjustment	O
characteristic	O
is	O
not	O
necessary	O
for	O
the	O
functionality	O
of	O
the	O
map	O
it	O
could	O
even	O
be	O
possible	O
that	O
the	O
map	O
would	O
diverge	O
i	O
e	O
it	O
could	O
virtually	O
explode	O
learning	O
rates	O
and	O
neighborhoods	O
can	O
decrease	O
monotonically	O
over	O
time	O
to	O
avoid	O
that	O
the	O
later	O
training	O
phases	O
forcefully	O
pull	O
the	O
entire	O
map	O
towards	O
a	O
new	O
pattern	O
the	O
soms	O
often	O
work	O
with	O
temporally	O
monotonically	O
decreasing	O
learning	O
rates	O
and	O
neighborhood	O
sizes	O
at	O
first	O
let	O
us	O
talk	O
about	O
the	O
learning	B
rate	I
could	O
be	O
true	O
but	O
this	O
size	O
must	O
also	O
depend	O
on	O
the	O
network	O
topology	B
or	O
the	O
size	O
of	O
the	O
neighborhood	O
as	O
we	O
have	O
already	O
seen	O
a	O
decreasing	O
neighborhood	O
size	O
can	O
be	O
realized	O
for	O
example	O
by	O
means	O
of	O
a	O
time-dependent	O
monotonically	O
decreasing	O
with	O
the	O
gaussin	O
bell	O
being	O
used	O
in	O
the	O
topology	B
function	I
the	O
advantage	O
of	O
a	O
decreasing	O
neighborhood	O
size	O
is	O
that	O
in	O
the	O
beginning	O
a	O
moving	O
neuron	B
along	O
many	O
neurons	O
in	O
its	O
vicinity	O
i	O
e	O
the	O
randomly	O
initialized	O
network	O
can	O
unfold	O
fast	O
and	O
properly	O
in	O
the	O
beginning	O
in	O
the	O
end	O
of	O
the	O
learning	O
process	O
only	O
a	O
few	O
neurons	O
are	O
influenced	O
at	O
the	O
same	O
time	O
which	O
stiffens	O
the	O
network	O
as	O
a	O
whole	O
but	O
enables	O
a	O
good	O
tuning	O
of	O
the	O
individual	O
neurons	O
it	O
must	O
be	O
noted	O
that	O
h	O
must	O
always	O
be	O
true	O
since	O
otherwise	O
the	O
neurons	O
would	O
constantly	O
miss	O
the	O
current	O
training	O
sample	O
but	O
enough	O
of	O
theory	O
let	O
us	O
take	O
a	O
look	O
at	O
a	O
som	O
in	O
action	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
training	O
figure	O
gaussian	B
bell	I
cone	B
function	I
cylinder	B
function	I
and	O
the	O
mexican	B
hat	I
function	I
suggested	O
by	O
kohonen	O
as	O
examples	O
for	O
topology	B
functions	O
of	O
a	O
som	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
in	O
function	O
funktion	O
hat	O
function	O
chapter	O
self-organizing	B
feature	I
maps	I
dkriesel	O
com	O
p	O
figure	O
illustration	O
of	O
the	O
two-dimensional	O
input	B
space	O
and	O
the	O
one-dimensional	O
topolgy	O
space	O
of	O
a	O
self-organizing	B
map	I
neuron	B
is	O
the	O
winner	B
neuron	B
since	O
it	O
is	O
closest	O
to	O
p	O
in	O
the	O
topology	B
the	O
neurons	O
and	O
are	O
the	O
neighbors	O
of	O
the	O
arrows	O
mark	O
the	O
movement	O
of	O
the	O
winner	B
neuron	B
and	O
its	O
neighbors	O
towards	O
the	O
training	O
sample	O
p	O
to	O
illustrate	O
the	O
one-dimensional	O
topology	B
of	O
the	O
network	O
it	O
is	O
plotted	O
into	O
the	O
input	B
space	O
by	O
the	O
dotted	O
line	O
the	O
arrows	O
mark	O
the	O
movement	O
of	O
the	O
winner	B
neuron	B
and	O
its	O
neighbors	O
towards	O
the	O
pattern	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
examples	O
examples	O
for	O
the	O
functionality	O
of	O
soms	O
let	O
us	O
begin	O
with	O
a	O
simple	O
mentally	O
comprehensible	O
example	O
in	O
this	O
example	O
we	O
use	O
a	O
two-dimensional	O
input	B
space	O
i	O
e	O
n	O
is	O
true	O
let	O
the	O
grid	B
structure	O
be	O
one-dimensional	O
furthermore	O
our	O
example	O
som	O
should	O
consist	O
of	O
neurons	O
and	O
the	O
learning	B
rate	I
should	O
be	O
the	O
neighborhood	O
function	O
is	O
also	O
kept	O
simple	O
so	O
that	O
we	O
will	O
be	O
able	O
to	O
mentally	O
comprehend	O
the	O
network	O
hi	O
k	O
t	O
k	O
direct	B
neighbor	O
of	O
i	O
k	O
i	O
otherw	O
now	O
let	O
us	O
take	O
a	O
look	O
at	O
the	O
abovementioned	O
network	O
with	O
random	O
initialization	O
of	O
the	O
centers	O
on	O
the	O
preceding	O
page	O
and	O
enter	O
a	O
training	O
sample	O
p	O
obviously	O
in	O
our	O
example	O
the	O
input	B
pattern	O
is	O
closest	O
to	O
neuron	B
i	O
e	O
this	O
is	O
the	O
winning	O
neuron	B
we	O
remember	O
soms	O
learning	O
rule	O
the	O
for	O
ck	O
hi	O
k	O
t	O
ck	O
thus	O
the	O
factor	O
ck	O
indicates	O
the	O
vector	O
of	O
the	O
neuron	B
k	O
to	O
the	O
pattern	O
p	O
this	O
is	O
now	O
multiplied	O
by	O
different	O
scalars	O
our	O
topology	B
function	I
h	O
indicates	O
that	O
only	O
the	O
winner	B
neuron	B
and	O
its	O
two	O
closest	O
neighbors	O
and	O
are	O
allowed	O
to	O
learn	O
by	O
returning	O
for	O
all	O
other	O
neurons	O
a	O
time-dependence	O
is	O
not	O
specified	O
thus	O
our	O
vector	O
ck	O
is	O
multiplied	O
by	O
either	O
or	O
the	O
learning	B
rate	I
indicates	O
as	O
always	O
the	O
strength	O
of	O
learning	O
as	O
already	O
mentioned	O
i	O
e	O
all	O
in	O
all	O
the	O
result	O
is	O
that	O
the	O
winner	B
neuron	B
and	O
its	O
neighbors	O
and	O
approximate	O
the	O
pattern	O
p	O
half	O
the	O
way	O
the	O
figure	O
marked	O
by	O
arrows	O
although	O
the	O
center	O
of	O
neuron	B
seen	O
from	O
the	O
input	B
space	O
is	O
considerably	O
closer	O
to	O
the	O
input	B
pattern	O
p	O
than	O
neuron	B
neuron	B
is	O
learning	O
and	O
neuron	B
is	O
not	O
i	O
want	O
to	O
remind	O
that	O
the	O
network	O
topology	B
specifies	O
which	O
neuron	B
is	O
allowed	O
to	O
learn	O
and	O
not	O
its	O
position	O
in	O
the	O
input	B
space	O
this	O
is	O
exactly	O
the	O
mechanism	O
by	O
which	O
a	O
topology	B
can	O
significantly	O
cover	O
an	O
input	B
space	O
without	O
having	O
to	O
be	O
related	O
to	O
it	O
by	O
any	O
sort	O
topology	B
specifies	O
who	O
will	O
learn	O
and	O
process	O
the	O
three	O
factors	O
from	O
the	O
back	O
learning	O
direction	O
remember	O
that	O
the	O
neuron	B
centers	O
ck	O
are	O
vectors	O
in	O
the	O
input	B
space	O
as	O
well	O
as	O
the	O
pattern	O
p	O
after	O
the	O
adaptation	O
of	O
the	O
neurons	O
and	O
the	O
next	O
pattern	O
is	O
applied	O
and	O
so	O
on	O
another	O
example	O
of	O
how	O
such	O
a	O
onedimensional	O
som	O
can	O
develop	O
in	O
a	O
twodimensional	O
input	B
space	O
with	O
uniformly	O
distributed	O
input	B
patterns	I
in	O
the	O
course	O
of	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
self-organizing	B
feature	I
maps	I
dkriesel	O
com	O
time	O
can	O
be	O
seen	O
in	O
figure	O
on	O
the	O
facing	O
page	O
end	O
states	O
of	O
one-	O
and	O
two-dimensional	O
soms	O
with	O
differently	O
shaped	O
input	B
spaces	O
can	O
be	O
seen	O
in	O
figure	O
on	O
page	O
as	O
we	O
can	O
see	O
not	O
every	O
input	B
space	O
can	O
be	O
neatly	O
covered	O
by	O
every	O
network	O
topology	B
there	O
are	O
so	O
called	O
exposed	O
neurons	O
neurons	O
which	O
are	O
located	O
in	O
an	O
area	O
where	O
no	O
input	B
pattern	O
has	O
ever	O
been	O
occurred	O
a	O
one-dimensional	O
topology	B
generally	O
produces	O
less	O
exposed	O
neurons	O
than	O
a	O
two-dimensional	O
one	O
for	O
instance	O
during	O
training	O
on	O
circularly	O
arranged	O
input	B
patterns	I
it	O
is	O
nearly	O
impossible	O
with	O
a	O
twodimensional	O
squared	B
topology	B
to	O
avoid	O
the	O
exposed	O
neurons	O
in	O
the	O
center	O
of	O
the	O
circle	O
these	O
are	O
pulled	O
in	O
every	O
direction	O
during	O
the	O
training	O
so	O
that	O
they	O
finally	O
remain	O
in	O
the	O
center	O
but	O
this	O
does	O
not	O
make	O
the	O
one-dimensional	O
topology	B
an	O
optimal	O
topology	B
since	O
it	O
can	O
only	O
find	O
less	O
complex	O
neighborhood	O
relationships	O
than	O
a	O
multi-dimensional	O
one	O
topological	O
defects	O
are	O
failures	O
in	O
som	O
unfolding	O
in	O
map	O
during	O
the	O
unfolding	O
of	O
a	O
som	O
it	O
could	O
happen	O
that	O
a	O
topological	B
defect	I
occurs	O
i	O
e	O
the	O
som	O
does	O
not	O
unfold	O
correctly	O
a	O
topological	B
defect	I
can	O
be	O
described	O
at	O
best	O
by	O
means	O
of	O
the	O
word	O
figure	O
a	O
topological	B
defect	I
in	O
a	O
twodimensional	O
som	O
neighborhood	O
size	O
because	O
the	O
more	O
complex	O
the	O
topology	B
is	O
the	O
more	O
neighbors	O
each	O
neuron	B
has	O
respectively	O
since	O
a	O
three-dimensional	O
or	O
a	O
honeycombed	O
twodimensional	O
topology	B
could	O
also	O
be	O
generated	O
the	O
more	O
difficult	O
it	O
is	O
for	O
a	O
randomly	O
initialized	O
map	O
to	O
unfold	O
it	O
is	O
possible	O
to	O
adjust	O
the	O
resolution	O
of	O
certain	O
areas	O
in	O
a	O
som	O
a	O
remedy	O
for	O
topological	O
defects	O
could	O
be	O
to	O
increase	O
the	O
initial	O
values	O
for	O
the	O
we	O
have	O
seen	O
that	O
a	O
som	O
is	O
trained	O
by	O
entering	O
input	B
patterns	I
of	O
the	O
input	B
space	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
adjustment	O
of	O
resolution	O
and	O
position-dependent	O
learning	B
rate	I
figure	O
behavior	O
of	O
a	O
som	O
with	O
one-dimensional	O
topology	B
after	O
the	O
input	B
of	O
and	O
randomly	O
distributed	O
input	B
patterns	I
p	O
during	O
the	O
training	O
decreased	O
from	O
to	O
the	O
parameter	O
of	O
the	O
gauss	O
function	O
decreased	O
from	O
to	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
self-organizing	B
feature	I
maps	I
dkriesel	O
com	O
figure	O
end	O
states	O
of	O
one-dimensional	O
column	O
and	O
two-dimensional	O
column	O
soms	O
on	O
different	O
input	B
spaces	O
neurons	O
were	O
used	O
for	O
the	O
one-dimensional	O
topology	B
neurons	O
for	O
the	O
two-dimensionsal	O
topology	B
and	O
input	B
patterns	I
for	O
all	O
maps	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
more	O
patterns	O
higher	O
resolution	O
dkriesel	O
com	O
application	O
rn	O
one	O
after	O
another	O
again	O
and	O
again	O
so	O
that	O
the	O
som	O
will	O
be	O
aligned	O
with	O
these	O
patterns	O
and	O
map	O
them	O
it	O
could	O
happen	O
that	O
we	O
want	O
a	O
certain	O
subset	O
u	O
of	O
the	O
input	B
space	O
to	O
be	O
mapped	O
more	O
precise	B
than	O
the	O
other	O
ones	O
this	O
problem	O
can	O
easily	O
be	O
solved	O
by	O
means	O
of	O
soms	O
during	O
the	O
training	O
disproportionally	O
many	O
input	B
patterns	I
of	O
the	O
area	O
u	O
are	O
presented	O
to	O
the	O
som	O
if	O
the	O
number	O
of	O
training	O
patterns	O
of	O
u	O
rn	O
presented	O
to	O
the	O
som	O
exceeds	O
the	O
number	O
of	O
those	O
patterns	O
of	O
the	O
remaining	O
rn	O
u	O
then	O
more	O
neurons	O
will	O
group	O
there	O
while	O
the	O
remaining	O
neurons	O
are	O
sparsely	O
distributed	O
on	O
rn	O
u	O
on	O
the	O
next	O
page	O
as	O
you	O
can	O
see	O
in	O
the	O
illustration	O
the	O
edge	O
of	O
the	O
som	O
could	O
be	O
deformed	O
this	O
can	O
be	O
compensated	O
by	O
assigning	O
to	O
the	O
edge	O
of	O
the	O
input	B
space	O
a	O
slightly	O
higher	O
probability	O
of	O
being	O
hit	O
by	O
training	O
patterns	O
often	O
applied	O
approach	O
for	O
reaching	O
every	O
corner	O
with	O
the	O
soms	O
also	O
a	O
higher	O
learning	B
rate	I
is	O
often	O
used	O
for	O
edge	O
and	O
corner	O
neurons	O
since	O
they	O
are	O
only	O
pulled	O
into	O
the	O
center	O
by	O
the	O
topology	B
this	O
also	O
results	O
in	O
a	O
significantly	O
improved	O
corner	O
coverage	O
application	O
of	O
soms	O
regarding	O
the	O
biologically	O
inspired	O
associative	B
data	I
storage	I
there	O
are	O
many	O
fields	O
of	O
application	O
for	O
self-organizing	O
maps	O
and	O
their	O
variations	O
for	O
example	O
the	O
different	O
phonemes	O
of	O
the	O
finnish	O
language	O
have	O
successfully	O
been	O
mapped	O
onto	O
a	O
som	O
with	O
a	O
two	O
dimensional	O
discrete	B
grid	B
topology	B
and	O
therefore	O
neighborhoods	O
have	O
been	O
found	O
som	O
does	O
nothing	O
else	O
than	O
finding	O
neighborhood	O
relationships	O
so	O
one	O
tries	O
once	O
more	O
to	O
break	O
down	O
a	O
high-dimensional	O
space	O
into	O
a	O
low-dimensional	O
space	O
topology	B
looks	O
if	O
some	O
structures	O
have	O
been	O
developed	O
et	O
voil	O
clearly	O
defined	O
areas	O
for	O
the	O
individual	O
phenomenons	O
are	O
formed	O
teuvo	O
kohonen	O
himself	O
made	O
the	O
effort	O
to	O
search	O
many	O
papers	O
mentioning	O
his	O
soms	O
in	O
their	O
keywords	O
in	O
this	O
large	O
input	B
space	O
the	O
individual	O
papers	O
now	O
individual	O
positions	O
depending	O
on	O
the	O
occurrence	O
of	O
keywords	O
then	O
kohonen	O
created	O
a	O
som	O
with	O
g	O
and	O
used	O
it	O
to	O
map	O
the	O
high-dimensional	O
space	O
developed	O
by	O
him	O
thus	O
it	O
is	O
possible	O
to	O
enter	O
any	O
paper	O
into	O
the	O
completely	O
trained	O
som	O
and	O
look	O
which	O
neuron	B
in	O
the	O
som	O
is	O
activated	O
it	O
will	O
be	O
likely	O
to	O
discover	O
that	O
the	O
neighbored	O
papers	O
in	O
the	O
topology	B
are	O
interesting	O
too	O
this	O
type	O
of	O
brain-like	O
contextbased	O
search	O
also	O
works	O
with	O
many	O
other	O
input	B
spaces	O
it	O
is	O
to	O
be	O
noted	O
that	O
the	O
system	O
itself	O
similar	O
defines	O
what	O
is	O
neighbored	O
i	O
e	O
within	O
the	O
topology	B
and	O
that	O
s	O
why	O
it	O
is	O
so	O
interesting	O
this	O
example	O
shows	O
that	O
the	O
position	O
c	O
of	O
the	O
neurons	O
in	O
the	O
input	B
space	O
is	O
not	O
significant	O
it	O
is	O
rather	O
interesting	O
to	O
see	O
which	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
som	O
finds	O
similarities	O
chapter	O
self-organizing	B
feature	I
maps	I
dkriesel	O
com	O
figure	O
training	O
of	O
a	O
som	O
with	O
g	O
on	O
a	O
two-dimensional	O
input	B
space	O
on	O
the	O
left	O
side	O
the	O
chance	O
to	O
become	O
a	O
training	B
pattern	I
was	O
equal	O
for	O
each	O
coordinate	O
of	O
the	O
input	B
space	O
on	O
the	O
right	O
side	O
for	O
the	O
central	O
circle	O
in	O
the	O
input	B
space	O
this	O
chance	O
is	O
more	O
than	O
ten	O
times	O
larger	O
than	O
for	O
the	O
remaining	O
input	B
space	O
in	O
the	O
larger	O
pattern	O
density	O
in	O
the	O
background	O
in	O
this	O
circle	O
the	O
neurons	O
are	O
obviously	O
more	O
crowded	O
and	O
the	O
remaining	O
area	O
is	O
covered	O
less	O
dense	O
but	O
in	O
both	O
cases	O
the	O
neurons	O
are	O
still	O
evenly	O
distributed	O
the	O
two	O
soms	O
were	O
trained	O
by	O
means	O
of	O
training	O
samples	O
and	O
decreasing	O
as	O
well	O
as	O
decreasing	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
variations	O
neuron	B
is	O
activated	O
when	O
an	O
unknown	O
input	B
pattern	O
is	O
entered	O
next	O
we	O
can	O
look	O
at	O
which	O
of	O
the	O
previous	O
inputs	O
this	O
neuron	B
was	O
also	O
activated	O
and	O
will	O
immediately	O
discover	O
a	O
group	O
of	O
very	O
similar	O
inputs	O
the	O
more	O
the	O
inputs	O
within	O
the	O
topology	B
are	O
diverging	O
the	O
less	O
things	O
they	O
have	O
in	O
common	O
virtually	O
the	O
topology	B
generates	O
a	O
map	O
of	O
the	O
input	B
characteristics	O
reduced	O
to	O
descriptively	O
few	O
dimensions	O
in	O
relation	O
to	O
the	O
input	B
dimension	I
therefore	O
the	O
topology	B
of	O
a	O
som	O
often	O
is	O
two-dimensional	O
so	O
that	O
it	O
can	O
be	O
easily	O
visualized	O
while	O
the	O
input	B
space	O
can	O
be	O
very	O
high-dimensional	O
soms	O
can	O
be	O
used	O
to	O
determine	O
centers	O
for	O
rbf	B
neurons	O
soms	O
arrange	O
themselves	O
exactly	O
towards	O
the	O
positions	O
of	O
the	O
outgoing	O
inputs	O
as	O
a	O
result	O
they	O
are	O
used	O
for	O
example	O
to	O
select	O
the	O
centers	O
of	O
an	O
rbf	B
network	I
we	O
have	O
already	O
been	O
introduced	O
to	O
the	O
paradigm	O
of	O
the	O
rbf	B
network	I
in	O
chapter	O
as	O
we	O
have	O
already	O
seen	O
it	O
is	O
possible	O
to	O
control	O
which	O
areas	O
of	O
the	O
input	B
space	O
should	O
be	O
covered	O
with	O
higher	O
resolution	O
or	O
in	O
connection	B
with	O
rbf	B
networks	O
on	O
which	O
areas	O
of	O
our	O
function	O
should	O
the	O
rbf	B
network	I
work	O
with	O
more	O
neurons	O
i	O
e	O
work	O
more	O
exactly	O
as	O
a	O
further	O
useful	O
feature	O
of	O
the	O
combination	O
of	O
rbf	B
networks	O
with	O
soms	O
one	O
can	O
use	O
the	O
topology	B
obtained	O
through	O
the	O
som	O
during	O
the	O
final	O
training	O
of	O
a	O
rbf	B
neuron	B
it	O
can	O
be	O
used	O
to	O
influence	O
neighboring	O
rbf	B
neurons	O
in	O
different	O
ways	O
for	O
this	O
many	O
neural	B
network	I
simulators	O
offer	O
an	O
additional	O
so-called	O
som	O
layer	O
in	O
connection	B
with	O
the	O
simulation	O
of	O
rbf	B
networks	O
variations	O
of	O
soms	O
there	O
are	O
different	O
variations	O
of	O
soms	O
for	O
different	O
variations	O
of	O
representation	O
tasks	O
a	O
neural	B
gas	I
is	O
a	O
som	O
without	O
a	O
static	O
topology	B
the	O
neural	B
gas	I
is	O
a	O
variation	O
of	O
the	O
selforganizing	O
maps	O
of	O
thomas	O
martinetz	O
which	O
has	O
been	O
developed	O
from	O
the	O
difficulty	O
of	O
mapping	O
complex	O
input	B
information	O
that	O
partially	O
only	O
occur	O
in	O
the	O
subspaces	O
of	O
the	O
input	B
space	O
or	O
even	O
change	O
the	O
subspaces	O
on	O
the	O
following	O
page	O
the	O
idea	O
of	O
a	O
neural	B
gas	I
is	O
roughly	O
speaking	O
to	O
realize	O
a	O
som	O
without	O
a	O
grid	B
structure	O
due	O
to	O
the	O
fact	O
that	O
they	O
are	O
derived	O
from	O
the	O
soms	O
the	O
learning	O
steps	O
are	O
very	O
similar	O
to	O
the	O
som	O
learning	O
steps	O
but	O
they	O
include	O
an	O
additional	O
intermediate	O
step	O
again	O
random	O
initialization	O
of	O
ck	O
rn	O
selection	O
and	O
presentation	O
of	O
a	O
pat	O
tern	O
of	O
the	O
input	B
space	O
p	O
rn	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
self-organizing	B
feature	I
maps	I
dkriesel	O
com	O
dynamic	O
neighborhood	O
figure	O
a	O
figure	O
filling	O
different	O
subspaces	O
of	O
the	O
actual	O
input	B
space	O
of	O
different	O
positions	O
therefore	O
can	O
hardly	O
be	O
filled	O
by	O
a	O
som	O
neuron	B
distance	O
measurement	O
identification	O
of	O
the	O
winner	B
neuron	B
i	O
intermediate	O
step	O
generation	O
of	O
a	O
list	O
l	O
of	O
neurons	O
sorted	O
in	O
ascending	O
order	O
by	O
their	O
distance	B
to	I
the	I
winner	B
neuron	B
thus	O
the	O
first	O
neuron	B
in	O
the	O
list	O
l	O
is	O
the	O
neuron	B
that	O
is	O
closest	O
to	O
the	O
winner	B
neuron	B
changing	O
the	O
centers	O
by	O
means	O
of	O
the	O
known	O
rule	O
but	O
with	O
the	O
slightly	O
modified	O
topology	B
function	I
hli	O
k	O
t	O
the	O
function	O
hli	O
k	O
t	O
which	O
is	O
slightly	O
modified	O
compared	O
with	O
the	O
original	O
function	O
hi	O
k	O
t	O
now	O
regards	O
the	O
first	O
elements	O
of	O
the	O
list	O
as	O
the	O
neighborhood	O
of	O
the	O
winner	B
neuron	B
i	O
the	O
direct	B
result	O
is	O
that	O
similar	O
to	O
the	O
free-floating	O
molecules	O
in	O
a	O
gas	O
the	O
neighborhood	O
relationships	O
between	O
the	O
neurons	O
can	O
change	O
anytime	O
and	O
the	O
number	O
of	O
neighbors	O
is	O
almost	O
arbitrary	O
too	O
the	O
distance	O
within	O
the	O
neighborhood	O
is	O
now	O
represented	O
by	O
the	O
distance	O
within	O
the	O
input	B
space	O
the	O
bulk	O
of	O
neurons	O
can	O
become	O
as	O
stiffened	O
as	O
a	O
som	O
by	O
means	O
of	O
a	O
constantly	O
decreasing	O
neighborhood	O
size	O
it	O
does	O
not	O
have	O
a	O
fixed	O
dimension	O
but	O
it	O
can	O
take	O
the	O
dimension	O
that	O
is	O
locally	O
needed	O
at	O
the	O
moment	O
which	O
can	O
be	O
very	O
advantageous	O
a	O
disadvantage	O
could	O
be	O
that	O
there	O
is	O
no	O
fixed	O
grid	B
forcing	O
the	O
input	B
space	O
to	O
become	O
regularly	O
covered	O
and	O
therefore	O
wholes	O
can	O
occur	O
in	O
the	O
cover	O
or	O
neurons	O
can	O
be	O
isolated	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
can	O
classify	O
complex	O
figure	O
dkriesel	O
com	O
variations	O
in	O
spite	O
of	O
all	O
practical	O
hints	O
it	O
is	O
as	O
always	O
the	O
user	O
s	O
responsibility	O
not	O
to	O
understand	O
this	O
text	O
as	O
a	O
catalog	O
for	O
easy	O
answers	O
but	O
to	O
explore	O
all	O
advantages	O
and	O
disadvantages	O
himself	O
unlike	O
a	O
som	O
the	O
neighborhood	O
of	O
a	O
neural	B
gas	I
must	O
initially	O
refer	O
to	O
all	O
neurons	O
since	O
otherwise	O
some	O
outliers	O
of	O
the	O
random	O
initialization	O
may	O
never	O
reach	O
the	O
remaining	O
group	O
to	O
forget	O
this	O
is	O
a	O
popular	O
error	O
during	O
the	O
implementation	O
of	O
a	O
neural	B
gas	I
with	O
a	O
neural	B
gas	I
it	O
is	O
possible	O
to	O
learn	O
a	O
kind	O
of	O
complex	O
input	B
such	O
as	O
in	O
fig	O
on	O
the	O
preceding	O
page	O
since	O
we	O
are	O
not	O
bound	O
to	O
a	O
fixed-dimensional	O
grid	B
but	O
some	O
computational	O
effort	O
could	O
be	O
necessary	O
for	O
the	O
permanent	O
sorting	O
of	O
the	O
list	O
it	O
could	O
be	O
effective	O
to	O
store	O
the	O
list	O
in	O
an	O
ordered	O
data	O
structure	O
right	O
from	O
the	O
start	O
definition	O
gas	O
a	O
neural	B
gas	I
differs	O
from	O
a	O
som	O
by	O
a	O
completely	O
dynamic	O
neighborhood	O
function	O
with	O
every	O
learning	O
cycle	O
it	O
is	O
decided	O
anew	O
which	O
neurons	O
are	O
the	O
neigborhood	O
neurons	O
of	O
the	O
winner	B
neuron	B
generally	O
the	O
criterion	O
for	O
this	O
decision	O
is	O
the	O
distance	O
between	O
the	O
neurosn	O
and	O
the	O
winner	B
neuron	B
in	O
the	O
input	B
space	O
a	O
multi-som	O
consists	O
of	O
several	O
separate	O
soms	O
in	O
order	O
to	O
present	O
another	O
variant	O
of	O
the	O
soms	O
i	O
want	O
to	O
formulate	O
an	O
extended	O
problem	O
what	O
do	O
we	O
do	O
with	O
input	B
patterns	I
from	O
which	O
we	O
know	O
that	O
they	O
are	O
confined	O
in	O
different	O
disjoint	O
areas	O
here	O
the	O
idea	O
is	O
to	O
use	O
not	O
only	O
one	O
som	O
but	O
several	O
ones	O
a	O
multi-selforganizing	O
map	O
shortly	O
referred	O
to	O
as	O
m-som	O
it	O
is	O
unnecessary	O
that	O
the	O
soms	O
have	O
the	O
same	O
topology	B
or	O
size	O
an	O
m-som	O
is	O
just	O
a	O
combination	O
of	O
m	O
soms	O
this	O
learning	O
process	O
is	O
analog	O
to	O
that	O
of	O
the	O
soms	O
however	O
only	O
the	O
neurons	O
belonging	O
to	O
the	O
winner	B
som	O
of	O
each	O
training	O
step	O
are	O
adapted	O
thus	O
it	O
is	O
easy	O
to	O
represent	O
two	O
disjoint	O
clusters	B
of	O
data	O
by	O
means	O
of	O
two	O
soms	O
even	O
if	O
one	O
of	O
the	O
clusters	B
is	O
not	O
represented	O
in	O
every	O
dimension	O
of	O
the	O
input	B
space	O
rn	O
actually	O
the	O
individual	O
soms	O
exactly	O
reflect	O
these	O
clusters	B
definition	O
a	O
multisom	O
is	O
nothing	O
more	O
than	O
the	O
simultaneous	O
use	O
of	O
m	O
soms	O
a	O
multi-neural	O
gas	O
consists	O
of	O
several	O
separate	O
neural	O
gases	O
analogous	O
to	O
the	O
multi-som	O
we	O
also	O
have	O
a	O
set	B
of	I
m	O
neural	O
gases	O
a	O
multi-neural	O
gas	O
this	O
construct	O
behaves	O
analogous	O
to	O
neural	B
gas	I
and	O
m-som	O
again	O
only	O
the	O
neurons	O
of	O
the	O
winner	B
gas	O
are	O
adapted	O
the	O
reader	O
certainly	O
wonders	O
what	O
advantage	O
is	O
there	O
to	O
use	O
a	O
multi-neural	O
gas	O
since	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
several	O
soms	O
several	O
gases	O
less	O
computational	O
effort	O
chapter	O
self-organizing	B
feature	I
maps	I
dkriesel	O
com	O
an	O
individual	O
neural	B
gas	I
is	O
already	O
capable	O
to	O
divide	O
into	O
clusters	B
and	O
to	O
work	O
on	O
complex	O
input	B
patterns	I
with	O
changing	O
dimensions	O
basically	O
this	O
is	O
correct	O
but	O
a	O
multi-neural	O
gas	O
has	O
two	O
serious	O
advantages	O
over	O
a	O
simple	O
neural	B
gas	I
with	O
several	O
gases	O
we	O
can	O
directly	O
tell	O
which	O
neuron	B
belongs	O
to	O
which	O
gas	O
this	O
is	O
particularly	O
important	O
for	O
clustering	O
tasks	O
for	O
which	O
multineural	O
gases	O
have	O
been	O
used	O
recently	O
simple	O
neural	O
gases	O
can	O
also	O
find	O
and	O
cover	O
clusters	B
but	O
now	O
we	O
cannot	O
recognize	O
which	O
neuron	B
belongs	O
to	O
which	O
cluster	O
a	O
lot	O
of	O
computational	O
effort	O
is	O
saved	O
when	O
large	O
original	O
gases	O
are	O
divided	O
into	O
several	O
smaller	O
ones	O
since	O
already	O
mentioned	O
the	O
sorting	O
of	O
the	O
list	O
l	O
could	O
use	O
a	O
lot	O
of	O
computational	O
effort	O
while	O
the	O
sorting	O
of	O
several	O
smaller	O
lists	O
lm	O
is	O
less	O
time-consuming	O
even	O
if	O
these	O
lists	O
in	O
total	B
contain	O
the	O
same	O
number	O
of	O
neurons	O
as	O
a	O
result	O
we	O
will	O
only	O
obtain	O
local	O
instead	O
of	O
global	O
sortings	O
but	O
in	O
most	O
cases	O
these	O
local	O
sortings	O
are	O
sufficient	O
now	O
we	O
can	O
choose	O
between	O
two	O
extreme	O
cases	O
of	O
multi-neural	O
gases	O
one	O
extreme	O
case	O
is	O
the	O
ordinary	O
neural	B
gas	I
m	O
i	O
e	O
we	O
only	O
use	O
one	O
single	O
neural	B
gas	I
interesting	O
enough	O
the	O
other	O
extreme	O
case	O
large	O
m	O
a	O
few	O
or	O
only	O
one	O
neuron	B
per	O
gas	O
behaves	O
analogously	O
to	O
the	O
k-means	B
clustering	I
more	O
information	O
on	O
clustering	O
procedures	O
see	O
excursus	O
a	O
definition	O
gas	O
a	O
multi-neural	O
gas	O
is	O
nothing	O
more	O
than	O
the	O
simultaneous	O
use	O
of	O
m	O
neural	O
gases	O
growing	B
neural	O
gases	O
can	O
add	O
neurons	O
to	O
themselves	O
a	O
growing	B
neural	B
gas	I
is	O
a	O
variation	O
of	O
the	O
aforementioned	O
neural	B
gas	I
to	O
which	O
more	O
and	O
more	O
neurons	O
are	O
added	O
according	O
to	O
certain	O
rules	O
thus	O
this	O
is	O
an	O
attempt	O
to	O
work	O
against	O
the	O
isolation	O
of	O
neurons	O
or	O
the	O
generation	O
of	O
larger	O
wholes	O
in	O
the	O
cover	O
here	O
this	O
subject	O
should	O
only	O
be	O
mentioned	O
but	O
not	O
discussed	O
to	O
build	O
a	O
growing	B
som	O
is	O
more	O
difficult	O
because	O
new	O
neurons	O
have	O
to	O
be	O
integrated	O
in	O
the	O
neighborhood	O
exercises	O
exercise	O
a	O
regular	O
two-dimensional	O
grid	B
shall	O
cover	O
a	O
two-dimensional	O
surface	O
as	O
as	O
possible	O
which	O
grid	B
structure	O
would	O
suit	O
best	O
for	O
this	O
purpose	O
which	O
criteria	O
did	O
you	O
use	O
for	O
and	O
the	O
very	O
imprecise	O
formulation	O
of	O
this	O
exercise	O
is	O
intentional	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
chapter	O
adaptive	B
resonance	B
theory	I
an	O
art	O
network	O
in	O
its	O
original	O
form	O
shall	O
classify	O
binary	B
input	B
vectors	O
i	O
e	O
to	O
assign	O
them	O
to	O
a	O
output	B
simultaneously	O
the	O
so	O
far	O
unclassified	O
patterns	O
shall	O
be	O
recognized	O
and	O
assigned	O
to	O
a	O
new	O
class	O
as	O
in	O
the	O
other	O
smaller	O
chapters	O
we	O
want	O
to	O
try	O
to	O
figure	O
out	O
the	O
basic	O
idea	O
of	O
the	O
adaptive	B
resonance	B
theory	I
art	O
without	O
discussing	O
its	O
theory	O
profoundly	O
in	O
several	O
sections	O
we	O
have	O
already	O
mentioned	O
that	O
it	O
is	O
difficult	O
to	O
use	O
neural	O
networks	O
for	O
the	O
learning	O
of	O
new	O
information	O
in	O
addition	O
to	O
but	O
without	O
destroying	O
the	O
already	O
existing	O
information	O
this	O
circumstance	O
is	O
called	O
stability	O
plasticity	O
dilemma	O
in	O
stephen	O
grossberg	O
and	O
gail	O
carpenter	O
published	O
the	O
first	O
version	O
of	O
their	O
art	O
network	O
in	O
order	O
to	O
alleviate	O
this	O
problem	O
this	O
was	O
followed	O
by	O
a	O
whole	O
family	O
of	O
art	O
improvements	O
we	O
want	O
to	O
discuss	O
briefly	O
too	O
it	O
is	O
the	O
idea	O
of	O
unsupervised	B
learning	O
whose	O
aim	O
is	O
the	O
binary	B
pattern	B
recognition	I
or	O
more	O
precisely	O
the	O
categorization	O
of	O
patterns	O
into	O
classes	O
but	O
addi	O
tionally	O
an	O
art	O
network	O
shall	O
be	O
capable	O
to	O
find	O
new	O
classes	O
task	O
and	O
structure	O
of	O
an	O
art	O
network	O
an	O
art	O
network	O
comprises	O
exactly	O
two	O
layers	O
the	O
input	B
layer	O
i	O
and	O
the	O
recognition	O
layer	O
o	O
with	O
the	O
input	B
layer	O
being	O
completely	O
linked	O
towards	O
the	O
recognition	O
layer	O
this	O
complete	O
link	O
induces	O
a	O
top-down	B
weight	B
matrix	I
w	O
that	O
contains	O
the	O
weight	B
values	O
of	O
the	O
connections	O
between	O
each	O
neuron	B
in	O
the	O
input	B
layer	O
and	O
each	O
neuron	B
in	O
the	O
recognition	O
layer	O
on	O
the	O
following	O
page	O
simple	O
binary	B
patterns	O
are	O
entered	O
into	O
the	O
input	B
layer	O
and	O
transferred	O
to	O
the	O
recognition	O
layer	O
while	O
the	O
recognition	O
layer	O
shall	O
return	B
a	O
encoding	O
i	O
e	O
it	O
should	O
follow	O
the	O
winner-takes-all	O
pattern	B
recognition	I
chapter	O
adaptive	B
resonance	B
theory	I
dkriesel	O
com	O
gfed	O
gfed	O
gfed	O
gfed	O
issssssssssssssssssssssssssssssssssssss	O
gooooooooooooooooooooooooooooo	O
gooooooooooooooooooooooooooooo	O
ukkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk	O
cfffffffffffffffffffff	O
cfffffffffffffffffffff	O
cfffffffffffffffffffff	O
e	O
e	O
e	O
e	O
wooooooooooooooooooooooooooooo	O
wooooooooooooooooooooooooooooo	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
gfed	O
figure	O
simplified	O
illustration	O
of	O
the	O
art	O
network	O
structure	O
top	O
the	O
input	B
layer	O
bottom	O
the	O
recognition	O
layer	O
in	O
this	O
illustration	O
the	O
lateral	B
inhibition	O
of	O
the	O
recognition	O
layer	O
and	O
the	O
control	O
neurons	O
are	O
omitted	O
scheme	O
for	O
instance	O
to	O
realize	O
this	O
encoding	O
the	O
principle	O
of	O
lateral	B
inhibition	O
can	O
be	O
used	O
or	O
in	O
the	O
implementation	O
the	O
most	O
activated	O
neuron	B
can	O
be	O
searched	O
for	O
practical	O
reasons	O
an	O
if	O
query	O
would	O
suit	O
this	O
task	O
best	O
put	O
layer	O
causes	O
an	O
activity	O
within	O
the	O
recognition	O
layer	O
while	O
in	O
turn	O
in	O
the	O
recognition	O
layer	O
every	O
activity	O
causes	O
an	O
activity	O
within	O
the	O
input	B
layer	O
layers	O
activate	O
one	O
another	O
resonance	B
takes	O
place	O
by	O
activities	O
being	O
tossed	O
and	O
turned	O
v	O
but	O
there	O
also	O
exists	O
a	O
bottom-up	B
weight	B
matrix	I
v	O
which	O
propagates	O
the	O
activities	O
within	O
the	O
recognition	O
layer	O
back	O
into	O
the	O
input	B
layer	O
now	O
it	O
is	O
obvious	O
that	O
these	O
activities	O
are	O
bounced	O
forth	O
and	O
back	O
again	O
and	O
again	O
a	O
fact	O
that	O
leads	O
us	O
to	O
resonance	B
every	O
activity	O
within	O
the	O
in	O
in	O
addition	O
to	O
the	O
two	O
mentioned	O
layers	O
in	O
an	O
art	O
network	O
also	O
exist	O
a	O
few	O
neurons	O
that	O
exercise	O
control	O
functions	O
such	O
as	O
signal	O
enhancement	O
but	O
we	O
do	O
not	O
want	O
to	O
discuss	O
this	O
theory	O
further	O
since	O
here	O
only	O
the	O
basic	O
principle	O
of	O
the	O
art	O
network	O
should	O
become	O
explicit	O
i	O
have	O
only	O
mentioned	O
it	O
to	O
explain	O
that	O
in	O
spite	O
of	O
the	O
recurrences	O
the	O
art	O
network	O
will	O
achieve	O
a	O
stable	O
state	B
after	O
an	O
input	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
w	O
u	O
w	O
e	O
o	O
o	O
e	O
y	O
o	O
o	O
e	O
c	O
y	O
o	O
o	O
e	O
g	O
c	O
y	O
o	O
o	O
i	O
g	O
c	O
y	O
dkriesel	O
com	O
extensions	O
the	O
learning	O
process	O
of	O
an	O
art	O
network	O
is	O
divided	O
to	O
top-down	B
and	O
bottom-up	B
learning	O
the	O
trick	O
of	O
adaptive	B
resonance	B
theory	I
is	O
not	O
only	O
the	O
configuration	O
of	O
the	O
art	O
network	O
but	O
also	O
the	O
two-piece	O
learning	O
procedure	O
of	O
the	O
theory	O
on	O
the	O
one	O
hand	O
we	O
train	O
the	O
top-down	B
matrix	O
w	O
on	O
the	O
other	O
hand	O
we	O
train	O
the	O
bottom-up	B
matrix	O
v	O
on	O
the	O
next	O
page	O
pattern	O
input	B
and	O
top-down	B
learning	O
when	O
a	O
pattern	O
is	O
entered	O
into	O
the	O
network	O
it	O
causes	O
as	O
already	O
mentioned	O
an	O
activation	B
at	O
the	O
output	B
neurons	O
and	O
the	O
strongest	O
neuron	B
wins	O
then	O
the	O
weights	O
of	O
the	O
matrix	O
w	O
going	O
towards	O
the	O
output	B
neuron	B
are	O
changed	O
such	O
that	O
the	O
output	B
of	O
the	O
strongest	O
neuron	B
is	O
still	O
enhanced	O
i	O
e	O
the	O
class	O
affiliation	O
of	O
the	O
input	B
vector	I
to	O
the	O
class	O
of	O
the	O
output	B
neuron	B
becomes	O
enhanced	O
resonance	B
and	O
bottom-up	B
learning	O
the	O
training	O
of	O
the	O
backward	O
weights	O
of	O
the	O
matrix	O
v	O
is	O
a	O
bit	O
tricky	O
only	O
the	O
weights	O
of	O
the	O
respective	O
winner	B
neuron	B
are	O
trained	O
towards	O
the	O
input	B
layer	O
and	O
our	O
current	O
input	B
pattern	O
is	O
used	O
as	O
teaching	B
input	B
thus	O
the	O
network	O
is	O
trained	O
to	O
enhance	O
input	B
vectors	O
adding	O
an	O
output	B
neuron	B
of	O
course	O
it	O
could	O
happen	O
that	O
the	O
neurons	O
are	O
nearly	O
equally	O
activated	O
or	O
that	O
several	O
neurons	O
are	O
activated	O
i	O
e	O
that	O
the	O
network	O
is	O
indecisive	O
in	O
this	O
case	O
the	O
mechanisms	O
of	O
the	O
control	O
neurons	O
activate	O
a	O
signal	O
that	O
adds	O
a	O
new	O
output	B
neuron	B
then	O
the	O
current	O
pattern	O
is	O
assigned	O
to	O
this	O
output	B
neuron	B
and	O
the	O
weight	B
sets	O
of	O
the	O
new	O
neuron	B
are	O
trained	O
as	O
usual	O
thus	O
the	O
advantage	O
of	O
this	O
system	O
is	O
not	O
only	O
to	O
divide	O
inputs	O
into	O
classes	O
and	O
to	O
find	O
new	O
classes	O
it	O
can	O
also	O
tell	O
us	O
after	O
the	O
activation	B
of	O
an	O
output	B
neuron	B
what	O
a	O
typical	O
representative	O
of	O
a	O
class	O
looks	O
like	O
which	O
is	O
a	O
significant	O
feature	O
often	O
however	O
the	O
system	O
can	O
only	O
moderately	O
distinguish	O
the	O
patterns	O
the	O
question	O
is	O
when	O
a	O
new	O
neuron	B
is	O
permitted	O
to	O
become	O
active	O
and	O
when	O
it	O
should	O
learn	O
in	O
an	O
art	O
network	O
there	O
are	O
different	O
additional	O
control	O
neurons	O
which	O
answer	O
this	O
question	O
according	O
to	O
different	O
mathematical	O
rules	O
and	O
which	O
are	O
responsible	O
for	O
intercepting	O
special	O
cases	O
at	O
the	O
same	O
time	O
one	O
of	O
the	O
largest	O
objections	O
to	O
an	O
art	O
is	O
the	O
fact	O
that	O
an	O
art	O
network	O
uses	O
a	O
special	O
distinction	O
of	O
cases	O
similar	O
to	O
an	O
if	O
query	O
that	O
has	O
been	O
forced	O
into	O
the	O
mechanism	O
of	O
a	O
neural	B
network	I
extensions	O
as	O
already	O
mentioned	O
above	O
the	O
art	O
networks	O
have	O
often	O
been	O
extended	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
winner	B
neuron	B
is	O
amplified	O
input	B
is	O
teach	O
inp	O
for	O
backward	O
weights	O
chapter	O
adaptive	B
resonance	B
theory	I
dkriesel	O
com	O
is	O
extended	O
to	O
continuous	B
inputs	O
and	O
additionally	O
offers	O
an	O
extension	O
called	O
enhancements	O
of	O
the	O
learning	O
speed	O
which	O
results	O
in	O
additional	O
control	O
neurons	O
and	O
layers	O
improves	O
the	O
learning	O
ability	O
of	O
by	O
adapting	O
additional	O
biological	O
processes	O
such	O
as	O
the	O
chemical	B
processes	O
within	O
the	O
apart	O
from	O
the	O
described	O
ones	O
there	O
exist	O
many	O
other	O
extensions	O
figure	O
simplified	O
illustration	O
of	O
the	O
twopiece	O
training	O
of	O
an	O
art	O
network	O
the	O
trained	O
weights	O
are	O
represented	O
by	O
solid	O
lines	O
let	O
us	O
assume	O
that	O
a	O
pattern	O
has	O
been	O
entered	O
into	O
the	O
network	O
and	O
that	O
the	O
numbers	O
mark	O
the	O
outputs	O
top	O
we	O
can	O
see	O
that	O
is	O
the	O
winner	B
neuron	B
middle	O
so	O
the	O
weights	O
are	O
trained	O
towards	O
the	O
winner	B
neuron	B
and	O
the	O
weights	O
of	O
the	O
winner	B
neuron	B
are	O
trained	O
towards	O
the	O
input	B
layer	O
because	O
of	O
the	O
frequent	O
extensions	O
of	O
the	O
adaptive	B
resonance	B
theory	I
wagging	O
tongues	O
already	O
call	O
them	O
networks	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
gfedabc	O
atzlichebiolo-gischevorg	O
angewiez	O
b	O
diechemischenvorg	O
aufigenerweiterungenderadaptiveresonancetheorysprechenb	O
osezungenbereitsvon	O
art-n-netzen	O
einkleiner	O
uberblick	O
uberneuronalenetzeepsilon-de	O
part	O
iv	O
excursi	O
appendices	O
and	O
registers	O
appendix	O
a	O
excursus	O
cluster	B
analysis	I
and	O
regional	B
and	I
online	B
learnable	I
fields	I
in	O
grimm	O
s	O
dictionary	O
the	O
extinct	O
german	O
word	O
is	O
described	O
by	O
dicht	O
und	O
dick	O
zusammensitzet	O
thick	O
and	O
dense	O
group	O
of	O
sth	O
in	O
static	O
cluster	B
analysis	I
the	O
formation	O
of	O
groups	O
within	O
point	O
clouds	O
is	O
explored	O
introduction	O
of	O
some	O
procedures	O
comparison	O
of	O
their	O
advantages	O
and	O
disadvantages	O
discussion	O
of	O
an	O
adaptive	O
clustering	O
method	O
based	O
on	O
neural	O
networks	O
a	O
regional	O
and	O
online	B
learnable	O
field	O
models	O
from	O
a	O
point	O
cloud	O
possibly	O
with	O
a	O
lot	O
of	O
points	O
a	O
comparatively	O
small	O
set	B
of	I
neurons	O
being	O
representative	O
for	O
the	O
point	O
cloud	O
as	O
already	O
mentioned	O
many	O
problems	B
can	O
be	O
traced	O
back	O
to	O
problems	B
in	O
cluster	B
analysis	I
therefore	O
it	O
is	O
necessary	O
to	O
research	O
procedures	O
that	O
examine	O
whether	O
groups	O
clusters	B
exist	O
within	O
point	O
clouds	O
since	O
cluster	B
analysis	I
procedures	O
need	O
a	O
notion	O
of	O
distance	O
between	O
two	O
points	O
a	O
metric	B
must	O
be	O
defined	O
on	O
the	O
space	O
where	O
these	O
points	O
are	O
situated	O
we	O
briefly	O
want	O
to	O
specify	O
what	O
a	O
metric	B
is	O
definition	O
a	O
relation	O
defined	O
for	O
two	O
objects	O
is	O
referred	O
to	O
as	O
metric	B
if	O
each	O
of	O
the	O
following	O
criteria	O
applies	O
if	O
and	O
only	O
if	O
i	O
e	O
metry	O
sym	O
i	O
e	O
inequality	O
holds	O
the	O
triangle	O
colloquially	O
speaking	O
a	O
metric	B
is	O
a	O
tool	O
for	O
determining	O
distances	O
between	O
points	O
in	O
any	O
space	O
here	O
the	O
distances	O
have	O
to	O
be	O
symmetrical	O
and	O
the	O
distance	O
between	O
to	O
points	O
may	O
only	O
be	O
if	O
the	O
two	O
points	O
are	O
equal	O
additionally	O
the	O
triangle	O
inequality	O
must	O
apply	O
metrics	O
are	O
provided	O
by	O
for	O
example	O
the	O
squared	B
distance	O
and	O
the	O
euclidean	B
distance	O
which	O
have	O
already	O
been	O
introduced	O
based	O
on	O
such	O
metrics	O
we	O
can	O
de	O
number	O
of	O
cluster	O
must	O
be	O
known	O
previously	O
appendix	O
a	O
excursus	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	B
learnable	O
fieldsdkriesel	O
com	O
fine	O
a	O
clustering	O
procedure	O
that	O
uses	O
a	O
metric	B
as	O
distance	O
measure	O
continue	O
with	O
until	O
the	O
assignments	O
are	O
no	O
longer	O
changed	O
now	O
we	O
want	O
to	O
introduce	O
and	O
briefly	O
discuss	O
different	O
clustering	O
procedures	O
k-means	B
clustering	I
allocates	O
data	O
to	O
a	O
predefined	O
number	O
of	O
clusters	B
k-means	B
clustering	I
according	O
to	O
j	O
macqueen	O
is	O
an	O
algorithm	B
that	O
is	O
often	O
used	O
because	O
of	O
its	O
low	O
computation	O
and	O
storage	O
complexity	O
and	O
which	O
is	O
regarded	O
as	O
and	O
good	O
the	O
operation	O
sequence	O
of	O
the	O
k-means	B
clustering	I
algorithm	B
is	O
the	O
following	O
provide	O
data	O
to	O
be	O
examined	O
define	O
k	O
which	O
is	O
the	O
number	O
of	O
clus	O
ter	O
centers	O
select	O
k	O
random	O
vectors	O
for	O
the	O
cluster	O
centers	O
referred	O
to	O
as	O
codebook	O
vectors	O
assign	O
each	O
data	O
point	O
to	O
the	O
next	O
codebook	O
compute	O
cluster	O
centers	O
for	O
all	O
clus	O
ters	O
set	O
codebook	O
vectors	O
to	O
new	O
cluster	O
centers	O
the	O
name	O
codebook	B
vector	I
was	O
created	O
because	O
the	O
often	O
used	O
name	O
cluster	O
vector	O
was	O
too	O
unclear	O
step	O
already	O
shows	O
one	O
of	O
the	O
great	O
questions	O
of	O
the	O
k-means	O
algorithm	B
the	O
number	O
k	O
of	O
the	O
cluster	O
centers	O
has	O
to	O
be	O
determined	O
in	O
advance	O
this	O
cannot	O
be	O
done	O
by	O
the	O
algorithm	B
the	O
problem	O
is	O
that	O
it	O
is	O
not	O
necessarily	O
known	O
in	O
advance	O
how	O
k	O
can	O
be	O
determined	O
best	O
another	O
problem	O
is	O
that	O
the	O
procedure	O
can	O
become	O
quite	O
instable	O
if	O
the	O
codebook	O
vectors	O
are	O
badly	O
initialized	O
but	O
since	O
this	O
is	O
random	O
it	O
is	O
often	O
useful	O
to	O
restart	O
the	O
procedure	O
this	O
has	O
the	O
advantage	O
of	O
not	O
requiring	O
much	O
computational	O
effort	O
if	O
you	O
are	O
fully	O
aware	O
of	O
those	O
weaknesses	O
you	O
will	O
receive	O
quite	O
good	O
results	O
however	O
complex	O
structures	O
such	O
as	O
in	O
clusters	B
cannot	O
be	O
recognized	O
if	O
k	O
is	O
high	O
the	O
outer	O
ring	O
of	O
the	O
construction	O
in	O
the	O
following	O
illustration	O
will	O
be	O
recognized	O
as	O
many	O
single	O
clusters	B
if	O
k	O
is	O
low	O
the	O
ring	O
with	O
the	O
small	O
inner	O
clusters	B
will	O
be	O
recognized	O
as	O
one	O
cluster	O
for	O
an	O
illustration	O
see	O
the	O
upper	O
right	O
part	O
of	O
fig	O
on	O
page	O
k-nearest	B
neighboring	I
looks	O
for	O
the	O
k	O
nearest	O
neighbors	O
of	O
each	O
data	O
point	O
the	O
k-nearest	B
neighboring	I
procedure	O
connects	O
each	O
data	O
point	O
to	O
the	O
k	O
closest	O
neighbors	O
which	O
often	O
results	O
in	O
a	O
division	O
of	O
the	O
groups	O
then	O
such	O
a	O
group	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
clustering	O
radii	O
around	O
points	O
dkriesel	O
com	O
the	O
silhouette	O
coefficient	O
builds	O
a	O
cluster	O
the	O
advantage	O
is	O
that	O
the	O
number	O
of	O
clusters	B
occurs	O
all	O
by	O
itself	O
the	O
disadvantage	O
is	O
that	O
a	O
large	O
storage	O
and	O
computational	O
effort	O
is	O
required	O
to	O
find	O
the	O
next	O
neighbor	O
distances	O
between	O
all	O
data	O
points	O
must	O
be	O
computed	O
and	O
stored	O
clustering	O
next	O
points	O
there	O
are	O
some	O
special	O
cases	O
in	O
which	O
the	O
procedure	O
combines	O
data	O
points	O
belonging	O
to	O
different	O
clusters	B
if	O
k	O
is	O
too	O
high	O
the	O
two	O
small	O
clusters	B
in	O
the	O
upper	O
right	O
of	O
the	O
illustration	O
clusters	B
consisting	O
of	O
only	O
one	O
single	O
data	O
point	O
are	O
basically	O
conncted	O
to	O
another	O
cluster	O
which	O
is	O
not	O
always	O
intentional	O
furthermore	O
it	O
is	O
not	O
mandatory	O
that	O
the	O
links	O
between	O
the	O
points	O
are	O
symmetric	O
but	O
this	O
procedure	O
allows	O
a	O
recognition	O
of	O
rings	O
and	O
therefore	O
of	O
in	O
clusters	B
which	O
is	O
a	O
clear	O
advantage	O
another	O
advantage	O
is	O
that	O
the	O
procedure	O
adaptively	O
responds	O
to	O
the	O
distances	O
in	O
and	O
between	O
the	O
clusters	B
for	O
an	O
illustration	O
see	O
the	O
lower	O
left	O
part	O
of	O
fig	O
which	O
is	O
the	O
reason	O
for	O
the	O
name	O
epsilonnearest	O
neighboring	O
points	O
are	O
neigbors	O
if	O
they	O
are	O
at	O
most	O
apart	O
from	O
each	O
other	O
here	O
the	O
storage	O
and	O
computational	O
effort	O
is	O
obviously	O
very	O
high	O
which	O
is	O
a	O
disadvantage	O
but	O
note	O
that	O
there	O
are	O
some	O
special	O
cases	O
two	O
separate	O
clusters	B
can	O
easily	O
be	O
connected	O
due	O
to	O
the	O
unfavorable	O
situation	B
of	O
a	O
single	O
data	O
point	O
this	O
can	O
also	O
happen	O
with	O
k-nearest	B
neighboring	I
but	O
it	O
would	O
be	O
more	O
difficult	O
since	O
in	O
this	O
case	O
the	O
number	O
of	O
neighbors	O
per	O
point	O
is	O
limited	O
an	O
advantage	O
is	O
the	O
symmetric	O
nature	O
of	O
the	O
neighborhood	O
relationships	O
another	O
advantage	O
is	O
that	O
the	O
combination	O
of	O
minimal	O
clusters	B
due	O
to	O
a	O
fixed	O
number	O
of	O
neighbors	O
is	O
avoided	O
on	O
the	O
other	O
hand	O
it	O
is	O
necessary	O
to	O
skillfully	O
initialize	O
in	O
order	O
to	O
be	O
successful	O
i	O
e	O
smaller	O
than	O
half	O
the	O
smallest	O
distance	O
between	O
two	O
clusters	B
with	O
variable	B
cluster	O
and	O
point	O
distances	O
within	O
clusters	B
this	O
can	O
possibly	O
be	O
a	O
problem	O
for	O
an	O
illustration	O
see	O
the	O
lower	O
right	O
part	O
of	O
fig	O
neighboring	O
looks	O
for	O
neighbors	O
within	O
the	O
radius	O
for	O
each	O
data	O
point	O
the	O
silhouette	O
coefficient	O
determines	O
how	O
accurate	O
a	O
given	O
clustering	O
is	O
another	O
approach	O
of	O
neighboring	O
here	O
the	O
neighborhood	O
detection	O
does	O
not	O
use	O
a	O
fixed	O
number	O
k	O
of	O
neighbors	O
but	O
a	O
radius	O
as	O
we	O
can	O
see	O
above	O
there	O
is	O
no	O
easy	O
answer	O
for	O
clustering	O
problems	B
each	O
procedure	O
described	O
has	O
very	O
specific	B
disadvantages	O
in	O
this	O
respect	O
it	O
is	O
useful	O
to	O
have	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
a	O
excursus	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	B
learnable	O
fieldsdkriesel	O
com	O
figure	O
top	O
left	O
our	O
set	B
of	I
points	O
we	O
will	O
use	O
this	O
set	O
to	O
explore	O
the	O
different	O
clustering	O
methods	O
top	O
right	O
k-means	B
clustering	I
using	O
this	O
procedure	O
we	O
chose	O
k	O
as	O
we	O
can	O
see	O
the	O
procedure	O
is	O
not	O
capable	O
to	O
recognize	O
in	O
clusters	B
left	O
of	O
the	O
illustration	O
long	O
of	O
points	O
are	O
a	O
problem	O
too	O
they	O
would	O
be	O
recognized	O
as	O
many	O
small	O
clusters	B
k	O
is	O
sufficiently	O
large	O
bottom	O
left	O
k-nearest	B
neighboring	I
if	O
k	O
is	O
selected	O
too	O
high	O
than	O
the	O
number	O
of	O
points	O
in	O
the	O
smallest	O
cluster	O
this	O
will	O
result	O
in	O
cluster	O
combinations	O
shown	O
in	O
the	O
upper	O
right	O
of	O
the	O
illustration	O
bottom	O
right	O
neighboring	O
this	O
procedure	O
will	O
cause	O
difficulties	O
if	O
is	O
selected	O
larger	O
than	O
the	O
minimum	O
distance	O
between	O
two	O
clusters	B
upper	O
left	O
of	O
the	O
illustration	O
which	O
will	O
then	O
be	O
combined	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
regional	B
and	I
online	B
learnable	I
fields	I
a	O
criterion	O
to	O
decide	O
how	O
good	O
our	O
cluster	O
division	O
is	O
this	O
possibility	O
is	O
offered	O
by	O
the	O
silhouette	O
coefficient	O
according	O
to	O
this	O
coefficient	O
measures	O
how	O
well	O
the	O
clusters	B
are	O
delimited	O
from	O
each	O
other	O
and	O
indicates	O
if	O
points	O
may	O
be	O
assigned	O
to	O
the	O
wrong	O
clusters	B
apparently	O
the	O
whole	O
term	O
sp	O
can	O
only	O
be	O
within	O
the	O
interval	O
a	O
value	O
close	O
to	O
indicates	O
a	O
bad	O
classification	O
of	O
p	O
the	O
silhouette	O
coefficient	O
sp	O
results	O
from	O
the	O
average	O
of	O
all	O
values	O
sp	O
sp	O
x	O
p	O
p	O
sp	O
as	O
above	O
the	O
total	B
quality	O
of	O
the	O
cluster	O
division	O
is	O
expressed	O
by	O
the	O
interval	O
as	O
different	O
clustering	O
strategies	O
with	O
different	O
characteristics	O
have	O
been	O
presented	O
now	O
of	O
further	O
material	O
is	O
presented	O
in	O
as	O
well	O
as	O
a	O
measure	O
to	O
indicate	O
the	O
quality	O
of	O
an	O
existing	O
arrangement	O
of	O
given	O
data	O
into	O
clusters	B
i	O
want	O
to	O
introduce	O
a	O
clustering	O
method	O
based	O
on	O
an	O
unsupervised	B
learning	O
neural	B
network	I
which	O
was	O
published	O
in	O
like	O
all	O
the	O
other	O
methods	O
this	O
one	O
may	O
not	O
be	O
perfect	O
but	O
it	O
eliminates	O
large	O
standard	O
weaknesses	O
of	O
the	O
known	O
clustering	O
methods	O
regional	B
and	I
online	B
learnable	I
fields	I
are	O
a	O
neural	O
clustering	O
strategy	O
the	O
paradigm	O
of	O
neural	O
networks	O
which	O
i	O
want	O
to	O
introduce	O
now	O
are	O
the	O
regional	B
and	I
online	B
learnable	I
fields	I
shortly	O
referred	O
to	O
as	O
rolfs	O
clustering	O
quality	O
is	O
measureable	O
let	O
p	O
be	O
a	O
point	O
cloud	O
and	O
p	O
a	O
point	O
in	O
p	O
let	O
c	O
p	O
be	O
a	O
cluster	O
within	O
the	O
point	O
cloud	O
and	O
p	O
be	O
part	O
of	O
this	O
cluster	O
i	O
e	O
p	O
c	O
the	O
set	B
of	I
clusters	B
is	O
called	O
c	O
summary	O
p	O
c	O
p	O
applies	O
to	O
calculate	O
the	O
silhouette	O
coefficient	O
we	O
initially	O
need	O
the	O
average	O
distance	O
between	O
point	O
p	O
and	O
all	O
its	O
cluster	O
neighbors	O
this	O
variable	B
is	O
referred	O
to	O
as	O
ap	O
and	O
defined	O
as	O
follows	O
ap	O
x	O
q	O
distp	O
q	O
furthermore	O
let	O
bp	O
be	O
the	O
average	O
distance	O
between	O
our	O
point	O
p	O
and	O
all	O
points	O
of	O
the	O
next	O
cluster	O
represents	O
all	O
clusters	B
except	O
for	O
c	O
bp	O
min	O
g	O
distp	O
q	O
x	O
q	O
g	O
the	O
point	O
p	O
is	O
classified	O
well	O
if	O
the	O
distance	B
to	I
the	I
center	O
of	O
the	O
own	O
cluster	O
is	O
minimal	O
and	O
the	O
distance	B
to	I
the	I
centers	O
of	O
the	O
other	O
clusters	B
is	O
maximal	O
in	O
this	O
case	O
the	O
following	O
term	O
provides	O
a	O
value	O
close	O
to	O
sp	O
bp	O
ap	O
maxap	O
bp	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
a	O
excursus	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	B
learnable	O
fieldsdkriesel	O
com	O
network	O
covers	O
point	O
cloud	O
rolfs	O
try	O
to	O
cover	O
data	O
with	O
neurons	O
roughly	O
speaking	O
the	O
regional	B
and	I
online	B
learnable	I
fields	I
are	O
a	O
set	O
k	O
of	O
neurons	O
which	O
try	O
to	O
cover	O
a	O
set	B
of	I
points	O
as	O
well	O
as	O
possible	O
by	O
means	O
of	O
their	O
distribution	O
in	O
the	O
input	B
space	O
for	O
this	O
neurons	O
are	O
added	O
moved	O
or	O
changed	O
in	O
their	O
size	O
during	O
training	O
if	O
necessary	O
the	O
parameters	O
of	O
the	O
individual	O
neurons	O
will	O
be	O
discussed	O
later	O
definition	O
and	O
online	B
learnable	O
field	O
a	O
regional	O
and	O
online	B
learnable	O
field	O
rolf	B
or	O
rolf	B
network	O
is	O
a	O
set	O
k	O
of	O
neurons	O
that	O
are	O
trained	O
to	O
cover	O
a	O
certain	O
set	O
in	O
the	O
input	B
space	O
as	O
well	O
as	O
possible	O
figure	O
structure	O
of	B
a	I
rolf	B
neuron	B
rolf	B
neurons	O
feature	O
a	O
position	O
and	O
a	O
radius	O
in	O
the	O
input	B
space	O
here	O
a	O
rolf	B
neuron	B
k	O
k	O
has	O
two	O
parameters	O
similar	O
to	O
the	O
rbf	B
networks	O
it	O
has	O
a	O
center	O
ck	O
i	O
e	O
a	O
position	O
in	O
the	O
input	B
space	O
but	O
it	O
has	O
yet	O
another	O
parameter	O
the	O
radius	O
which	O
defines	O
the	O
radius	O
of	O
the	O
perceptive	O
surface	O
surrounding	O
the	O
a	O
neuron	B
covers	O
the	O
part	O
of	O
the	O
input	B
space	O
that	O
is	O
situated	O
within	O
this	O
radius	O
neuron	B
represents	O
surface	O
ck	O
and	O
k	O
are	O
locally	O
defined	O
for	O
each	O
neu	O
i	O
write	O
and	O
not	O
because	O
the	O
actual	O
radius	O
is	O
specified	O
by	O
ron	O
this	O
particularly	O
means	O
that	O
the	O
neurons	O
are	O
capable	O
to	O
cover	O
surfaces	O
of	O
different	O
sizes	O
the	O
radius	O
of	O
the	O
perceptive	O
surface	O
is	O
specified	O
by	O
r	O
with	O
the	O
multiplier	O
being	O
globally	O
defined	O
and	O
previously	O
specified	O
for	O
all	O
neurons	O
intuitively	O
the	O
reader	O
will	O
wonder	O
what	O
this	O
multiplicator	O
is	O
used	O
for	O
its	O
significance	O
will	O
be	O
discussed	O
later	O
furthermore	O
the	O
following	O
has	O
to	O
be	O
observed	O
it	O
is	O
not	O
necessary	O
for	O
the	O
perceptive	O
surface	O
of	O
the	O
different	O
neurons	O
to	O
be	O
of	O
the	O
same	O
size	O
definition	O
neuron	B
the	O
parameters	O
of	B
a	I
rolf	B
neuron	B
k	O
are	O
a	O
center	O
ck	O
and	O
a	O
radius	O
k	O
definition	O
surface	O
the	O
perceptive	O
surface	O
of	B
a	I
rolf	B
neuron	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
regional	B
and	I
online	B
learnable	I
fields	I
k	O
consists	O
of	O
all	O
points	O
within	O
the	O
radius	O
in	O
the	O
input	B
space	O
a	O
rolf	B
learns	O
unsupervised	B
by	O
presenting	O
training	O
samples	O
online	B
like	O
many	O
other	O
paradigms	O
of	O
neural	O
networks	O
our	O
rolf	B
network	O
learns	O
by	O
receiving	O
many	O
training	O
samples	O
p	O
of	O
a	O
training	B
set	I
p	O
the	O
learning	O
is	O
unsupervised	B
for	O
each	O
training	O
sample	O
p	O
entered	O
into	O
the	O
network	O
two	O
cases	O
can	O
occur	O
there	O
is	O
one	O
accepting	B
neuron	B
k	O
for	O
p	O
or	O
there	O
is	O
no	O
accepting	B
neuron	B
at	O
all	O
if	O
in	O
the	O
first	O
case	O
several	O
neurons	O
are	O
suitable	O
then	O
there	O
will	O
be	O
exactly	O
one	O
accepting	B
neuron	B
insofar	O
as	O
the	O
closest	O
neuron	B
is	O
the	O
accepting	B
one	O
for	O
the	O
accepting	B
neuron	B
k	O
ck	O
and	O
k	O
are	O
adapted	O
definition	O
neuron	B
the	O
criterion	O
for	O
a	O
rolf	B
neuron	B
k	O
to	O
be	O
an	O
accepting	B
neuron	B
of	O
a	O
point	O
p	O
is	O
that	O
the	O
point	O
p	O
must	O
be	O
located	O
within	O
the	O
perceptive	O
surface	O
of	O
k	O
if	O
p	O
is	O
located	O
in	O
the	O
perceptive	O
surfaces	O
of	O
several	O
neurons	O
then	O
the	O
closest	O
neuron	B
will	O
be	O
the	O
accepting	B
one	O
if	O
there	O
are	O
several	O
closest	O
neurons	O
one	O
can	O
be	O
chosen	O
randomly	O
both	O
positions	O
and	O
radii	O
are	O
adapted	O
throughout	O
learning	O
adapting	O
existing	O
neurons	O
let	O
us	O
assume	O
that	O
we	O
entered	O
a	O
training	O
sample	O
p	O
into	O
the	O
network	O
and	O
that	O
there	O
is	O
an	O
accepting	B
neuron	B
k	O
then	O
the	O
radius	O
moves	O
towards	O
ck	O
towards	O
the	O
distance	O
between	O
p	O
and	O
ck	O
and	O
the	O
center	O
ck	O
towards	O
p	O
additionally	O
let	O
us	O
define	O
the	O
two	O
learning	O
rates	O
and	O
c	O
for	O
radii	O
c	O
and	O
centers	O
ckt	O
ckt	O
cp	O
ckt	O
kt	O
kt	O
ckt	O
kt	O
note	O
that	O
here	O
k	O
is	O
a	O
scalar	O
while	O
ck	O
is	O
a	O
vector	O
in	O
the	O
input	B
space	O
definition	O
a	O
rolf	B
neuron	B
a	O
neuron	B
k	O
accepted	O
by	O
a	O
point	O
p	O
is	O
adapted	O
according	O
to	O
the	O
following	O
rules	O
ckt	O
ckt	O
cp	O
ckt	O
kt	O
kt	O
ckt	O
kt	O
the	O
radius	O
multiplier	O
allows	O
neurons	O
to	O
be	O
able	O
not	O
only	O
to	O
shrink	O
now	O
we	O
can	O
understand	O
the	O
function	O
of	O
the	O
multiplier	O
due	O
to	O
this	O
multiplier	O
the	O
per-	O
ceptive	O
surface	O
of	O
a	O
neuron	B
includes	O
more	O
than	O
only	O
all	O
points	O
surrounding	O
the	O
neuron	B
in	O
the	O
radius	O
this	O
means	O
that	O
due	O
to	O
the	O
aforementioned	O
learning	O
rule	O
cannot	O
only	O
decrease	O
but	O
also	O
increase	O
definition	O
multiplier	O
the	O
radius	O
multiplier	O
is	O
globally	O
defined	O
and	O
expands	O
the	O
perceptive	O
surface	O
of	O
a	O
neuron	B
k	O
to	O
a	O
multiple	O
of	O
k	O
so	O
it	O
is	O
ensured	O
that	O
the	O
radius	O
k	O
cannot	O
only	O
decrease	O
but	O
also	O
increase	O
so	O
the	O
neurons	O
can	O
grow	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
a	O
excursus	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	B
learnable	O
fieldsdkriesel	O
com	O
generally	O
the	O
radius	O
multiplier	O
is	O
set	O
to	O
values	O
in	O
the	O
lower	O
one-digit	O
range	O
such	O
as	O
or	O
so	O
far	O
we	O
only	O
have	O
discussed	O
the	O
case	O
in	O
the	O
rolf	B
training	O
that	O
there	O
is	O
an	O
accepting	B
neuron	B
for	O
the	O
training	O
sample	O
p	O
as	O
required	O
new	O
neurons	O
are	O
generated	O
this	O
suggests	O
to	O
discuss	O
the	O
approach	O
for	O
the	O
case	O
that	O
there	O
is	O
no	O
accepting	B
neuron	B
in	O
this	O
case	O
a	O
new	O
accepting	B
neuron	B
k	O
is	O
generated	O
for	O
our	O
training	O
sample	O
the	O
result	O
is	O
of	O
course	O
that	O
ck	O
and	O
k	O
have	O
to	O
be	O
initialized	O
the	O
initialization	O
of	O
ck	O
can	O
be	O
understood	O
intuitively	O
the	O
center	O
of	O
the	O
new	O
neuron	B
is	O
simply	O
set	O
on	O
the	O
training	O
sample	O
i	O
e	O
ck	O
p	O
we	O
generate	O
a	O
new	O
neuron	B
because	O
there	O
is	O
no	O
neuron	B
close	O
to	O
p	O
for	O
logical	O
reasons	O
we	O
place	O
the	O
neuron	B
exactly	O
on	O
p	O
but	O
how	O
to	O
set	O
a	O
when	O
a	O
new	O
neuron	B
is	O
generated	O
for	O
this	O
purpose	O
there	O
exist	O
different	O
options	O
init-	O
we	O
always	O
select	O
a	O
predefined	O
static	O
minimum	O
we	O
take	O
a	O
look	O
at	O
the	O
of	O
each	O
neuron	B
and	O
select	O
the	O
minimum	O
maximum	O
we	O
take	O
a	O
look	O
at	O
the	O
of	O
each	O
neuron	B
and	O
select	O
the	O
maximum	O
mean	O
we	O
select	O
the	O
mean	O
of	O
all	O
neu	O
rons	O
currently	O
the	O
mean-	O
variant	O
is	O
the	O
favorite	O
one	O
although	O
the	O
learning	O
procedure	O
also	O
works	O
with	O
the	O
other	O
ones	O
in	O
the	O
minimum-	O
variant	O
the	O
neurons	O
tend	O
to	O
cover	O
less	O
of	O
the	O
surface	O
in	O
the	O
maximum	O
variant	O
they	O
tend	O
to	O
cover	O
more	O
of	O
the	O
surface	O
definition	O
a	O
rolf	B
neuron	B
if	O
a	O
new	O
rolf	B
neuron	B
k	O
is	O
generated	O
by	O
entering	O
a	O
training	O
sample	O
p	O
then	O
ck	O
is	O
intialized	O
with	O
p	O
and	O
k	O
according	O
to	O
one	O
of	O
the	O
aforementioned	O
strategies	O
minimum-	O
maximum-	O
mean-	O
the	O
training	O
is	O
complete	O
when	O
after	O
repeated	O
randomly	O
permuted	O
pattern	O
presentation	O
no	O
new	O
neuron	B
has	O
been	O
generated	O
in	O
an	O
epoch	B
and	O
the	O
positions	O
of	O
the	O
neurons	O
barely	O
change	O
evaluating	O
a	O
rolf	B
the	O
result	O
of	O
the	O
training	O
algorithm	B
is	O
that	O
the	O
training	B
set	I
is	O
gradually	O
covered	O
well	O
and	O
precisely	O
by	O
the	O
rolf	B
neurons	O
and	O
that	O
a	O
high	O
concentration	O
of	O
points	O
on	O
a	O
spot	O
of	O
the	O
input	B
space	O
does	O
not	O
automatically	O
generate	O
more	O
neurons	O
thus	O
a	O
possibly	O
very	O
large	O
point	O
cloud	O
is	O
reduced	O
to	O
very	O
few	O
representatives	O
on	O
the	O
input	B
set	O
then	O
it	O
is	O
very	O
easy	O
to	O
define	O
the	O
number	O
of	O
clusters	B
two	O
neurons	O
are	O
to	O
the	O
definition	O
of	O
the	O
rolf	B
connected	O
when	O
their	O
perceptive	O
surfaces	O
over	O
initialization	O
of	O
a	O
neurons	O
cluster	O
connected	O
neurons	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
regional	B
and	I
online	B
learnable	I
fields	I
some	O
kind	O
of	O
nearest	O
neighborlap	O
ing	O
is	O
executed	O
with	O
the	O
variable	B
perceptive	O
surfaces	O
a	O
cluster	O
is	O
a	O
group	O
of	O
connected	O
neurons	O
or	O
a	O
group	O
of	O
points	O
of	O
the	O
input	B
space	O
covered	O
by	O
these	O
neurons	O
of	O
course	O
the	O
complete	O
rolf	B
network	O
can	O
be	O
evaluated	O
by	O
means	O
of	O
other	O
clustering	O
methods	O
i	O
e	O
the	O
neurons	O
can	O
be	O
searched	O
for	O
clusters	B
particularly	O
with	O
clustering	O
methods	O
whose	O
storage	O
effort	O
grows	O
quadratic	O
to	O
the	O
storage	O
effort	O
can	O
be	O
reduced	O
dramatically	O
since	O
generally	O
there	O
are	O
considerably	O
less	O
rolf	B
neurons	O
than	O
original	O
data	O
points	O
but	O
the	O
neurons	O
represent	O
the	O
data	O
points	O
quite	O
well	O
comparison	O
with	O
popular	O
clustering	O
methods	O
it	O
is	O
obvious	O
that	O
storing	O
the	O
neurons	O
rather	O
than	O
storing	O
the	O
input	B
points	O
takes	O
the	O
biggest	O
part	O
of	O
the	O
storage	O
effort	O
of	O
the	O
rolfs	O
this	O
is	O
a	O
great	O
advantage	O
for	O
huge	O
point	O
clouds	O
with	O
a	O
lot	O
of	O
points	O
since	O
it	O
is	O
unnecessary	O
to	O
store	O
the	O
entire	O
point	O
cloud	O
our	O
rolf	B
as	O
a	O
neural	O
clustering	O
method	O
has	O
the	O
capability	B
to	I
learn	I
online	B
which	O
is	O
definitely	O
a	O
great	O
advantage	O
furthermore	O
it	O
can	O
to	O
nearest	O
neighboring	O
or	O
k	O
nearest	O
neighboring	O
distinguish	O
clusters	B
from	O
enclosed	O
clusters	B
but	O
due	O
to	O
the	O
online	B
presentation	O
of	O
the	O
data	O
without	O
a	O
quadratically	O
growing	B
storage	O
effort	O
which	O
is	O
by	O
far	O
the	O
greatest	O
disadvantage	O
of	O
the	O
two	O
neighboring	O
methods	O
less	O
storage	O
effort	O
recognize	O
in	O
clusters	B
figure	O
the	O
clustering	O
process	O
top	O
the	O
input	B
set	O
middle	O
the	O
input	B
space	O
covered	O
by	O
rolf	B
neurons	O
bottom	O
the	O
input	B
space	O
only	O
covered	O
by	O
the	O
neurons	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
a	O
excursus	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	B
learnable	O
fieldsdkriesel	O
com	O
additionally	O
the	O
issue	O
of	O
the	O
size	O
of	O
the	O
individual	O
clusters	B
proportional	O
to	O
their	O
distance	O
from	O
each	O
other	O
is	O
addressed	O
by	O
using	O
variable	B
perceptive	O
surfaces	O
which	O
is	O
also	O
not	O
always	O
the	O
case	O
for	O
the	O
two	O
mentioned	O
methods	O
the	O
rolf	B
compares	O
favorably	O
with	O
kmeans	O
clustering	O
as	O
well	O
firstly	O
it	O
is	O
unnecessary	O
to	O
previously	O
know	O
the	O
number	O
of	O
clusters	B
and	O
secondly	O
k-means	B
clustering	I
recognizes	O
clusters	B
enclosed	O
by	O
other	O
clusters	B
as	O
separate	O
clusters	B
initializing	O
radii	O
learning	O
rates	O
and	O
multiplier	O
is	O
not	O
trivial	O
certainly	O
the	O
disadvantages	O
of	O
the	O
rolf	B
shall	O
not	O
be	O
concealed	O
it	O
is	O
not	O
always	O
easy	O
to	O
select	O
the	O
appropriate	O
initial	O
value	O
for	O
and	O
the	O
previous	O
knowledge	O
about	O
the	O
data	O
set	O
can	O
so	O
to	O
say	O
be	O
included	O
in	O
and	O
the	O
initial	O
value	O
of	O
of	O
the	O
rolf	B
fine-grained	O
data	O
clusters	B
should	O
use	O
a	O
small	O
and	O
a	O
small	O
initial	O
value	O
but	O
the	O
smaller	O
the	O
the	O
smaller	O
the	O
chance	O
that	O
the	O
neurons	O
will	O
grow	O
if	O
necessary	O
here	O
again	O
there	O
is	O
no	O
easy	O
answer	O
just	O
like	O
for	O
the	O
learning	O
rates	O
c	O
and	O
for	O
the	O
multipliers	O
in	O
the	O
lower	O
singledigit	O
range	O
such	O
as	O
or	O
are	O
very	O
popular	O
c	O
and	O
successfully	O
work	O
with	O
values	O
about	O
to	O
variations	O
during	O
run-time	O
are	O
also	O
imaginable	O
for	O
this	O
type	O
of	O
network	O
initial	O
values	O
for	O
generally	O
depend	O
on	O
the	O
cluster	O
and	O
data	O
distribution	O
they	O
often	O
have	O
to	O
be	O
tested	O
but	O
compared	O
to	O
wrong	O
initializations	O
at	O
least	O
with	O
the	O
mean-	O
strategy	O
they	O
are	O
relatively	O
robust	O
after	O
some	O
training	O
time	O
as	O
a	O
whole	O
the	O
rolf	B
is	O
on	O
a	O
par	O
with	O
the	O
other	O
clustering	O
methods	O
and	O
is	O
particularly	O
very	O
interesting	O
for	O
systems	O
with	O
low	O
storage	O
capacity	O
or	O
huge	O
data	O
sets	O
application	O
examples	O
a	O
first	O
application	O
example	O
could	O
be	O
finding	O
color	O
clusters	B
in	O
rgb	O
images	O
another	O
field	O
of	O
application	O
directly	O
described	O
in	O
the	O
rolf	B
publication	O
is	O
the	O
recognition	O
of	O
words	O
transferred	O
into	O
a	O
feature	O
space	O
thus	O
we	O
can	O
see	O
that	O
rolfs	O
are	O
relatively	O
robust	O
against	O
higher	O
dimensions	O
further	O
applications	O
can	O
be	O
found	O
in	O
the	O
field	O
of	O
analysis	O
of	O
attacks	O
on	O
network	O
systems	O
and	O
their	O
classification	O
exercises	O
exercise	O
determine	O
at	O
least	O
four	O
adaptation	O
steps	O
for	O
one	O
single	O
rolf	B
neuron	B
k	O
if	O
the	O
four	O
patterns	O
stated	O
below	O
are	O
presented	O
one	O
after	O
another	O
in	O
the	O
indicated	O
order	O
let	O
the	O
initial	O
values	O
for	O
the	O
rolf	B
neuron	B
be	O
ck	O
and	O
k	O
furthermore	O
let	O
c	O
and	O
let	O
p	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
b	O
excursus	O
neural	O
networks	O
used	O
for	O
prediction	O
discussion	O
of	O
an	O
application	O
of	O
neural	O
networks	O
a	O
look	O
ahead	O
into	O
the	O
future	O
of	O
time	B
series	I
after	O
discussing	O
the	O
different	O
paradigms	O
of	O
neural	O
networks	O
it	O
is	O
now	O
useful	O
to	O
take	O
a	O
look	O
at	O
an	O
application	O
of	O
neural	O
networks	O
which	O
is	O
brought	O
up	O
often	O
and	O
we	O
will	O
see	O
is	O
also	O
used	O
for	O
fraud	O
the	O
application	O
of	O
time	B
series	I
prediction	I
this	O
excursus	O
is	O
structured	O
into	O
the	O
description	O
of	O
time	B
series	I
and	O
estimations	O
about	O
the	O
requirements	O
that	O
are	O
actually	O
needed	O
to	O
predict	O
the	O
values	O
of	O
a	O
time	B
series	I
finally	O
i	O
will	O
say	O
something	O
about	O
the	O
range	O
of	O
software	O
which	O
should	O
predict	O
share	O
prices	O
or	O
other	O
economic	O
characteristics	O
by	O
means	O
of	O
neural	O
networks	O
or	O
other	O
procedures	O
about	O
time	B
series	I
a	O
time	B
series	I
is	O
a	O
series	O
of	O
values	O
discretized	O
in	O
time	O
for	O
example	O
daily	O
measured	O
temperature	O
values	O
or	O
other	O
meteorological	O
data	O
of	O
a	O
specific	B
site	O
could	O
be	O
represented	O
by	O
a	O
time	B
series	I
share	O
price	O
values	O
also	O
represent	O
a	O
time	B
series	I
often	O
the	O
measurement	O
of	O
time	B
series	I
is	O
timely	O
equidistant	O
and	O
in	O
many	O
time	B
series	I
the	O
future	O
development	O
of	O
their	O
values	O
is	O
very	O
interesting	O
e	O
g	O
the	O
daily	O
weather	O
forecast	O
this	O
chapter	O
should	O
not	O
be	O
a	O
detailed	O
description	O
but	O
rather	O
indicate	O
some	O
approaches	O
for	O
time	B
series	I
prediction	I
in	O
this	O
respect	O
i	O
will	O
again	O
try	O
to	O
avoid	O
formal	O
definitions	O
time	B
series	I
of	O
values	O
time	B
series	I
can	O
also	O
be	O
values	O
of	O
an	O
actually	O
continuous	B
function	O
read	O
in	O
a	O
certain	O
distance	O
of	O
time	O
t	O
on	O
the	O
next	O
t	O
page	O
if	O
we	O
want	O
to	O
predict	O
a	O
time	B
series	I
we	O
will	O
look	O
for	O
a	O
neural	B
network	I
that	O
maps	O
the	O
previous	O
series	O
values	O
to	O
future	O
developments	O
of	O
the	O
time	B
series	I
i	O
e	O
if	O
we	O
know	O
longer	O
sections	O
of	O
the	O
time	B
series	I
we	O
will	O
appendix	O
b	O
excursus	O
neural	O
networks	O
used	O
for	O
prediction	O
dkriesel	O
com	O
have	O
enough	O
training	O
samples	O
of	O
course	O
these	O
are	O
not	O
examples	O
for	O
the	O
future	O
to	O
be	O
predicted	O
but	O
it	O
is	O
tried	O
to	O
generalize	O
and	O
to	O
extrapolate	O
the	O
past	O
by	O
means	O
of	O
the	O
said	O
samples	O
but	O
before	O
we	O
begin	O
to	O
predict	O
a	O
time	B
series	I
we	O
have	O
to	O
answer	O
some	O
questions	O
about	O
this	O
time	B
series	I
we	O
are	O
dealing	O
with	O
and	O
ensure	O
that	O
it	O
fulfills	O
some	O
requirements	O
do	O
we	O
have	O
any	O
evidence	O
which	O
suggests	O
that	O
future	O
values	O
depend	O
in	O
any	O
way	O
on	O
the	O
past	O
values	O
of	O
the	O
time	B
series	I
does	O
the	O
past	O
of	O
a	O
time	B
series	I
include	O
information	O
about	O
its	O
future	O
do	O
we	O
have	O
enough	O
past	O
values	O
of	O
the	O
time	B
series	I
that	O
can	O
be	O
used	O
as	O
training	O
patterns	O
in	O
case	O
of	O
a	O
prediction	O
of	O
a	O
continuous	B
function	O
what	O
must	O
a	O
useful	O
t	O
look	O
like	O
now	O
these	O
questions	O
shall	O
be	O
explored	O
in	O
detail	O
how	O
much	O
information	O
about	O
the	O
future	O
is	O
included	O
in	O
the	O
past	O
values	O
of	O
a	O
time	B
series	I
this	O
is	O
the	O
most	O
important	O
question	O
to	O
be	O
answered	O
for	O
any	O
time	B
series	I
that	O
should	O
be	O
mapped	O
into	O
the	O
future	O
if	O
the	O
future	O
values	O
of	O
a	O
time	B
series	I
for	O
instance	O
do	O
not	O
depend	O
on	O
the	O
past	O
values	O
then	O
a	O
time	B
series	I
prediction	I
based	O
on	O
them	O
will	O
be	O
impossible	O
in	O
this	O
chapter	O
we	O
assume	O
systems	O
whose	O
future	O
values	O
can	O
be	O
deduced	O
from	O
their	O
states	O
the	O
deterministic	O
systems	O
this	O
figure	O
a	O
function	O
x	O
that	O
depends	O
on	O
the	O
time	O
is	O
sampled	O
at	O
discrete	B
time	O
steps	O
discretized	O
this	O
means	O
that	O
the	O
result	O
is	O
a	O
time	B
series	I
the	O
sampled	O
values	O
are	O
entered	O
into	O
a	O
neural	B
network	I
this	O
example	O
an	O
slp	O
which	O
shall	O
learn	O
to	O
predict	O
the	O
future	O
values	O
of	O
the	O
time	B
series	I
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
one-step-ahead	B
prediction	I
leads	O
us	O
to	O
the	O
question	O
of	O
what	O
a	O
system	O
state	B
is	O
one-step-ahead	B
prediction	I
a	O
system	O
state	B
completely	O
describes	O
a	O
system	O
for	O
a	O
certain	O
point	O
of	O
time	O
the	O
future	O
of	O
a	O
deterministic	O
system	O
would	O
be	O
clearly	O
defined	O
by	O
means	O
of	O
the	O
complete	O
description	O
of	O
its	O
current	O
state	B
the	O
problem	O
in	O
the	O
real	O
world	O
is	O
that	O
such	O
a	O
state	B
concept	O
includes	O
all	O
things	O
that	O
influence	O
our	O
system	O
by	O
any	O
means	O
in	O
case	O
of	O
our	O
weather	O
forecast	O
for	O
a	O
specific	B
site	O
we	O
could	O
definitely	O
determine	O
the	O
temperature	O
the	O
atmospheric	O
pressure	O
and	O
the	O
cloud	O
density	O
as	O
the	O
meteorological	O
state	B
of	O
the	O
place	O
at	O
a	O
time	O
t	O
but	O
the	O
whole	O
state	B
would	O
include	O
significantly	O
more	O
information	O
here	O
the	O
worldwide	O
phenomena	O
that	O
control	O
the	O
weather	O
would	O
be	O
interesting	O
as	O
well	O
as	O
small	O
local	O
pheonomena	O
such	O
as	O
the	O
cooling	O
system	O
of	O
the	O
local	O
power	O
plant	O
so	O
we	O
shall	O
note	O
that	O
the	O
system	O
state	B
is	O
desirable	O
for	O
prediction	O
but	O
not	O
always	O
possible	O
to	O
obtain	O
often	O
only	O
fragments	O
of	O
the	O
current	O
states	O
can	O
be	O
acquired	O
e	O
g	O
for	O
a	O
weather	O
forecast	O
these	O
fragments	O
are	O
the	O
said	O
weather	O
data	O
however	O
we	O
can	O
partially	O
overcome	O
these	O
weaknesses	O
by	O
using	O
not	O
only	O
one	O
single	O
state	B
last	O
one	O
for	O
the	O
prediction	O
but	O
by	O
using	O
several	O
past	O
states	O
from	O
this	O
we	O
want	O
to	O
derive	O
our	O
first	O
prediction	O
system	O
predict	O
the	O
next	O
value	O
the	O
first	O
attempt	O
to	O
predict	O
the	O
next	O
future	O
value	O
of	O
a	O
time	B
series	I
out	O
of	O
past	O
values	O
is	O
called	O
one-step-ahead	B
prediction	I
on	O
the	O
following	O
page	O
such	O
a	O
predictor	O
system	O
receives	O
the	O
last	O
n	O
observed	O
state	B
parts	O
of	O
the	O
system	O
as	O
input	B
and	O
outputs	O
the	O
prediction	O
for	O
the	O
next	O
state	B
state	B
part	O
the	O
idea	O
of	O
a	O
state	B
space	O
with	O
predictable	O
states	O
is	O
called	O
state	B
space	I
forecasting	I
the	O
aim	O
of	O
the	O
predictor	O
is	O
to	O
realize	O
a	O
function	O
fxt	O
xt	O
xt	O
which	O
receives	O
exactly	O
n	O
past	O
values	O
in	O
order	O
to	O
predict	O
the	O
future	O
value	O
predicted	O
values	O
shall	O
be	O
headed	O
by	O
a	O
tilde	O
x	O
x	O
to	O
distinguish	O
them	O
from	O
the	O
actual	O
future	O
values	O
the	O
most	O
intuitive	O
and	O
simplest	O
approach	O
would	O
be	O
to	O
find	O
a	O
linear	O
combination	O
ajxi	O
j	O
that	O
approximately	O
fulfills	O
our	O
tions	O
condi	O
such	O
a	O
construction	O
is	O
called	O
digital	B
filter	I
here	O
we	O
use	O
the	O
fact	O
that	O
time	B
series	I
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
b	O
excursus	O
neural	O
networks	O
used	O
for	O
prediction	O
dkriesel	O
com	O
xt	O
xt	O
xt	O
xt	O
predictor	O
figure	O
representation	O
of	O
the	O
one-step-ahead	B
prediction	I
it	O
is	O
tried	O
to	O
calculate	O
the	O
future	O
value	O
from	O
a	O
series	O
of	O
past	O
values	O
the	O
predicting	O
element	O
this	O
case	O
a	O
neural	B
network	I
is	O
referred	O
to	O
as	O
predictor	O
usually	O
have	O
a	O
lot	O
of	O
past	O
values	O
so	O
that	O
we	O
can	O
set	O
up	O
a	O
series	O
of	O
means	O
of	O
the	O
delta	B
rule	I
provides	O
results	O
very	O
close	O
to	O
the	O
analytical	O
solution	O
xt	O
ajxt	O
xt	O
ajxt	O
xt	O
n	O
n	O
ajxt	O
n	O
thus	O
n	O
equations	O
could	O
be	O
found	O
for	O
n	O
unknown	O
coefficients	O
and	O
solve	O
them	O
possible	O
or	O
another	O
better	O
approach	O
we	O
could	O
use	O
m	O
n	O
equations	O
for	O
n	O
unknowns	O
in	O
such	O
a	O
way	O
that	O
the	O
sum	O
of	O
the	O
mean	O
squared	B
errors	O
of	O
the	O
already	O
known	O
prediction	O
is	O
minimized	O
this	O
is	O
called	O
moving	B
average	I
procedure	I
but	O
this	O
linear	O
structure	O
corresponds	O
to	O
a	O
singlelayer	B
perceptron	B
with	O
a	O
linear	O
activation	B
function	I
which	O
has	O
been	O
trained	O
by	O
means	O
of	O
data	O
from	O
the	O
past	O
experimental	O
setup	O
would	O
comply	O
with	O
fig	O
on	O
page	O
in	O
fact	O
the	O
training	O
by	O
without	O
going	O
into	O
detail	O
i	O
want	O
to	O
remark	O
that	O
the	O
prediction	O
becomes	O
easier	O
the	O
more	O
past	O
values	O
of	O
the	O
time	B
series	I
are	O
available	O
i	O
would	O
like	O
to	O
ask	O
the	O
reader	O
to	O
read	O
up	O
on	O
the	O
nyquist-shannon	O
sampling	O
theorem	O
even	O
if	O
this	O
approach	O
often	O
provides	O
satisfying	O
results	O
we	O
have	O
seen	O
that	O
many	O
problems	B
cannot	O
be	O
solved	O
by	O
using	O
a	O
singlelayer	B
perceptron	B
additional	O
layers	O
with	O
linear	O
activation	B
function	I
are	O
useless	O
as	O
well	O
since	O
a	O
multilayer	B
perceptron	B
with	O
only	O
linear	O
activation	B
functions	O
can	O
be	O
reduced	O
to	O
a	O
singlelayer	B
perceptron	B
such	O
considerations	O
lead	O
to	O
a	O
non-linear	O
approach	O
the	O
multilayer	B
perceptron	B
and	O
non-linear	O
activation	B
functions	O
provide	O
a	O
universal	B
non-linear	O
function	O
approximator	O
i	O
e	O
we	O
can	O
use	O
an	O
for	O
n	O
n	O
inputs	O
out	O
of	O
the	O
past	O
an	O
rbf	B
network	I
could	O
also	O
be	O
used	O
but	O
remember	O
that	O
here	O
the	O
number	O
n	O
has	O
to	O
remain	O
low	O
since	O
in	O
rbf	B
networks	O
high	O
input	B
dimensions	O
are	O
very	O
complex	O
to	O
realize	O
so	O
if	O
we	O
want	O
to	O
include	O
many	O
past	O
values	O
a	O
multilayer	B
perceptron	B
will	O
require	O
considerably	O
less	O
computational	O
effort	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
k	O
k	O
dkriesel	O
com	O
additional	O
optimization	O
approaches	O
for	O
prediction	O
two-step-ahead	B
prediction	I
additional	O
optimization	O
approaches	O
for	O
prediction	O
what	O
approaches	O
can	O
we	O
use	O
to	O
to	O
see	O
farther	O
into	O
the	O
future	O
recursive	O
two-step-ahead	B
prediction	I
in	O
order	O
to	O
extend	O
the	O
prediction	O
to	O
for	O
instance	O
two	O
time	O
steps	O
into	O
the	O
future	O
we	O
could	O
perform	O
two	O
one-step-ahead	O
predictions	O
in	O
a	O
row	O
on	O
the	O
following	O
i	O
e	O
a	O
recursive	O
two-step-ahead	O
page	O
prediction	O
unfortunately	O
the	O
value	O
determined	O
by	O
means	O
of	O
a	O
one-step-ahead	B
prediction	I
is	O
generally	O
imprecise	O
so	O
that	O
errors	O
can	O
be	O
built	O
up	O
and	O
the	O
more	O
predictions	O
are	O
performed	O
in	O
a	O
row	O
the	O
more	O
imprecise	O
becomes	O
the	O
result	O
direct	B
two-step-ahead	B
prediction	I
we	O
have	O
already	O
guessed	O
that	O
there	O
exists	O
a	O
better	O
approach	O
just	O
like	O
the	O
system	O
can	O
be	O
trained	O
to	O
predict	O
the	O
next	O
value	O
we	O
can	O
certainly	O
train	O
it	O
to	O
predict	O
the	O
next	O
but	O
one	O
value	O
this	O
means	O
we	O
directly	O
train	O
for	O
example	O
a	O
neural	B
network	I
to	O
look	O
two	O
time	O
steps	O
ahead	O
into	O
the	O
future	O
which	O
is	O
referred	O
to	O
as	O
direct	B
twostep-ahead	O
prediction	O
on	O
the	O
next	O
page	O
obviously	O
the	O
direct	B
two-stepahead	O
prediction	O
is	O
technically	O
identical	O
to	O
the	O
one-step-ahead	B
prediction	I
the	O
only	O
difference	O
is	O
the	O
training	O
the	O
possibility	O
to	O
predict	O
values	O
far	O
away	O
in	O
the	O
future	O
is	O
not	O
only	O
important	O
because	O
we	O
try	O
to	O
look	O
farther	O
ahead	O
into	O
the	O
future	O
there	O
can	O
also	O
be	O
periodic	O
time	B
series	I
where	O
other	O
approaches	O
are	O
hardly	O
possible	O
if	O
a	O
lecture	O
begins	O
at	O
a	O
m	O
every	O
thursday	O
it	O
is	O
not	O
very	O
useful	O
to	O
know	O
how	O
many	O
people	O
sat	O
in	O
the	O
lecture	O
room	O
on	O
monday	O
to	O
predict	O
the	O
number	O
of	O
lecture	O
participants	O
the	O
same	O
applies	O
for	O
example	O
to	O
periodically	O
occurring	O
commuter	O
jams	O
changing	O
temporal	O
parameters	O
thus	O
it	O
can	O
be	O
useful	O
to	O
intentionally	O
leave	O
gaps	O
in	O
the	O
future	O
values	O
as	O
well	O
as	O
in	O
the	O
past	O
values	O
of	O
the	O
time	B
series	I
i	O
e	O
to	O
introduce	O
the	O
parameter	O
t	O
which	O
indicates	O
which	O
past	O
value	O
is	O
used	O
for	O
prediction	O
technically	O
speaking	O
we	O
still	O
use	O
a	O
onestep-ahead	O
prediction	O
only	O
that	O
we	O
extend	O
the	O
input	B
space	O
or	O
train	O
the	O
system	O
to	O
predict	O
values	O
lying	O
farther	O
away	O
it	O
is	O
also	O
possible	O
to	O
combine	O
different	O
t	O
in	O
case	O
of	O
the	O
traffic	O
jam	O
prediction	O
for	O
a	O
monday	O
the	O
values	O
of	O
the	O
last	O
few	O
days	O
could	O
be	O
used	O
as	O
data	O
input	B
in	O
addition	O
to	O
the	O
values	O
of	O
the	O
previous	O
mondays	O
thus	O
we	O
use	O
the	O
last	O
values	O
of	O
several	O
periods	O
in	O
this	O
case	O
the	O
values	O
of	O
a	O
weekly	O
and	O
a	O
daily	O
period	B
we	O
could	O
also	O
include	O
an	O
annual	O
period	B
in	O
the	O
form	O
of	O
the	O
beginning	O
of	O
the	O
holidays	O
sure	O
everyone	O
of	O
us	O
has	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
predict	O
future	O
values	O
direct	B
prediction	O
is	O
better	O
extent	O
input	B
period	B
appendix	O
b	O
excursus	O
neural	O
networks	O
used	O
for	O
prediction	O
dkriesel	O
com	O
predictor	O
xt	O
xt	O
xt	O
xt	O
predictor	O
figure	O
representation	O
of	O
the	O
two-step-ahead	B
prediction	I
attempt	O
to	O
predict	O
the	O
second	O
future	O
value	O
out	O
of	O
a	O
past	O
value	O
series	O
by	O
means	O
of	O
a	O
second	O
predictor	O
and	O
the	O
involvement	O
of	O
an	O
already	O
predicted	O
value	O
xt	O
xt	O
xt	O
xt	O
predictor	O
figure	O
representation	O
of	O
the	O
direct	B
two-step-ahead	B
prediction	I
here	O
the	O
second	O
time	O
step	O
is	O
predicted	O
directly	O
the	O
first	O
one	O
is	O
omitted	O
technically	O
it	O
does	O
not	O
differ	O
from	O
a	O
one-step-ahead	B
prediction	I
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
o	O
o	O
j	O
j	O
e	O
e	O
use	O
information	O
outside	O
of	O
time	B
series	I
dkriesel	O
com	O
remarks	O
on	O
the	O
prediction	O
of	O
share	O
prices	O
already	O
spent	O
a	O
lot	O
of	O
time	O
on	O
the	O
highway	O
because	O
he	O
forgot	O
the	O
beginning	O
of	O
the	O
holidays	O
heterogeneous	B
prediction	O
another	O
prediction	O
approach	O
would	O
be	O
to	O
predict	O
the	O
future	O
values	O
of	O
a	O
single	O
time	B
series	I
out	O
of	O
several	O
time	B
series	I
if	O
it	O
is	O
assumed	O
that	O
the	O
additional	O
time	B
series	I
is	O
related	O
to	O
the	O
future	O
of	O
the	O
first	O
one	O
one-step-ahead	B
prediction	I
fig	O
on	O
the	O
following	O
page	O
if	O
we	O
want	O
to	O
predict	O
two	O
outputs	O
of	O
two	O
related	O
time	B
series	I
it	O
is	O
certainly	O
possible	O
to	O
perform	O
two	O
parallel	O
one-step-ahead	O
predictions	O
this	O
is	O
done	O
very	O
often	O
because	O
otherwise	O
the	O
equations	O
would	O
become	O
very	O
confusing	O
or	O
in	O
case	O
of	O
the	O
neural	O
networks	O
an	O
additional	O
output	B
neuron	B
is	O
attached	O
and	O
the	O
knowledge	O
of	O
both	O
time	B
series	I
is	O
used	O
for	O
both	O
outputs	O
on	O
the	O
next	O
page	O
you	O
ll	O
find	O
more	O
and	O
more	O
general	O
material	O
on	O
time	B
series	I
in	O
remarks	O
on	O
the	O
prediction	O
of	O
share	O
prices	O
many	O
people	O
observe	O
the	O
changes	O
of	O
a	O
share	O
price	O
in	O
the	O
past	O
and	O
try	O
to	O
conclude	O
the	O
future	O
from	O
those	O
values	O
in	O
order	O
to	O
benefit	O
from	O
this	O
knowledge	O
share	O
prices	O
are	O
discontinuous	O
and	O
therefore	O
they	O
are	O
principally	O
difficult	O
functions	O
furthermore	O
the	O
functions	O
can	O
only	O
be	O
used	O
for	O
discrete	B
values	O
often	O
for	O
example	O
in	O
a	O
daily	O
rhythm	O
the	O
maximum	O
and	O
minimum	O
values	O
per	O
day	O
if	O
we	O
are	O
lucky	O
with	O
the	O
daily	O
variations	O
certainly	O
being	O
eliminated	O
but	O
this	O
makes	O
the	O
whole	O
thing	O
even	O
more	O
difficult	O
there	O
are	O
chartists	O
i	O
e	O
people	O
who	O
look	O
at	O
many	O
diagrams	O
and	O
decide	O
by	O
means	O
of	O
a	O
lot	O
of	O
background	O
knowledge	O
and	O
decade-long	O
experience	O
whether	O
the	O
equities	O
should	O
be	O
bought	O
or	O
not	O
often	O
they	O
are	O
very	O
successful	O
apart	O
from	O
the	O
share	O
prices	O
it	O
is	O
very	O
interesting	O
to	O
predict	O
the	O
exchange	O
rates	O
of	O
currencies	O
if	O
we	O
exchange	O
euros	O
into	O
dollars	O
the	O
dollars	O
into	O
pounds	O
and	O
the	O
pounds	O
back	O
into	O
euros	O
it	O
could	O
be	O
possible	O
that	O
we	O
will	O
finally	O
receive	O
euros	O
but	O
once	O
found	O
out	O
we	O
would	O
do	O
this	O
more	O
often	O
and	O
thus	O
we	O
would	O
change	O
the	O
exchange	O
rates	O
into	O
a	O
state	B
in	O
which	O
such	O
an	O
increasing	O
circulation	O
would	O
no	O
longer	O
be	O
possible	O
we	O
could	O
produce	O
money	O
by	O
generating	O
so	O
to	O
speak	O
a	O
financial	O
perpetual	O
motion	O
machine	O
at	O
the	O
stock	O
exchange	O
successful	O
stock	O
and	O
currency	O
brokers	O
raise	O
or	O
lower	O
their	O
thumbs	O
and	O
thereby	O
indicate	O
whether	O
in	O
their	O
opinion	O
a	O
share	O
price	O
or	O
an	O
exchange	O
rate	O
will	O
increase	O
or	O
decrease	O
mathematically	O
speaking	O
they	O
indicate	O
the	O
first	O
bit	O
of	O
the	O
first	O
derivative	O
of	O
the	O
exchange	O
rate	O
in	O
that	O
way	O
excellent	O
worldclass	O
brokers	O
obtain	O
success	O
rates	O
of	O
about	O
in	O
great	O
britain	O
the	O
heterogeneous	B
onestep-ahead	O
prediction	O
was	O
successfully	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
b	O
excursus	O
neural	O
networks	O
used	O
for	O
prediction	O
dkriesel	O
com	O
xt	O
xt	O
xt	O
xt	O
predictor	O
yt	O
yt	O
yt	O
yt	O
figure	O
representation	O
of	O
the	O
heterogeneous	B
one-step-ahead	B
prediction	I
prediction	O
of	O
a	O
time	B
series	I
under	O
consideration	O
of	O
a	O
second	O
one	O
xt	O
xt	O
xt	O
xt	O
yt	O
yt	O
yt	O
yt	O
predictor	O
figure	O
heterogeneous	B
one-step-ahead	B
prediction	I
of	O
two	O
time	B
series	I
at	O
the	O
same	O
time	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
k	O
k	O
k	O
k	O
dkriesel	O
com	O
remarks	O
on	O
the	O
prediction	O
of	O
share	O
prices	O
again	O
and	O
again	O
some	O
software	O
appears	O
which	O
uses	O
scientific	O
key	O
words	O
such	O
as	O
neural	O
networks	O
to	O
purport	O
that	O
it	O
is	O
capable	O
to	O
predict	O
where	O
share	O
prices	O
are	O
going	O
do	O
not	O
buy	O
such	O
software	O
in	O
addition	O
to	O
the	O
aforementioned	O
scientific	O
exclusions	O
there	O
is	O
one	O
simple	O
reason	O
for	O
this	O
if	O
these	O
tools	O
work	O
why	O
should	O
the	O
manufacturer	O
sell	O
them	O
normally	O
useful	O
economic	O
knowledge	O
is	O
kept	O
secret	O
if	O
we	O
knew	O
a	O
way	O
to	O
definitely	O
gain	O
wealth	O
by	O
means	O
of	O
shares	O
we	O
would	O
earn	O
our	O
millions	O
by	O
using	O
this	O
knowledge	O
instead	O
of	O
selling	O
it	O
for	O
euros	O
wouldn	O
t	O
we	O
used	O
to	O
increase	O
the	O
accuracy	O
of	O
such	O
predictions	O
to	O
in	O
addition	O
to	O
the	O
time	B
series	I
of	O
the	O
values	O
indicators	O
such	O
as	O
the	O
oil	O
price	O
in	O
rotterdam	O
or	O
the	O
us	O
national	O
debt	O
were	O
included	O
this	O
is	O
just	O
an	O
example	O
to	O
show	O
the	O
magnitude	O
of	O
the	O
accuracy	O
of	O
stock-exchange	O
evaluations	O
since	O
we	O
are	O
still	O
talking	O
only	O
about	O
the	O
first	O
bit	O
of	O
the	O
first	O
derivation	O
we	O
still	O
do	O
not	O
know	O
how	O
strong	O
the	O
expected	O
increase	O
or	O
decrease	O
will	O
be	O
and	O
also	O
whether	O
the	O
effort	O
will	O
pay	O
off	O
probably	O
one	O
wrong	O
prediction	O
could	O
nullify	O
the	O
profit	O
of	O
one	O
hundred	O
correct	O
predictions	O
how	O
can	O
neural	O
networks	O
be	O
used	O
to	O
predict	O
share	O
prices	O
intuitively	O
we	O
assume	O
that	O
future	O
share	O
prices	O
are	O
a	O
function	O
of	O
the	O
previous	O
share	O
values	O
but	O
this	O
assumption	O
is	O
wrong	O
share	O
prices	O
are	O
no	O
function	O
of	O
their	O
past	O
values	O
but	O
a	O
function	O
of	O
their	O
assumed	O
future	O
value	O
we	O
do	O
not	O
buy	O
shares	O
because	O
their	O
values	O
have	O
been	O
increased	O
during	O
the	O
last	O
days	O
but	O
because	O
we	O
believe	O
that	O
they	O
will	O
futher	O
increase	O
tomorrow	O
if	O
as	O
a	O
consequence	O
many	O
people	O
buy	O
a	O
share	O
they	O
will	O
boost	O
the	O
price	O
therefore	O
their	O
assumption	O
was	O
right	O
a	O
self-fulfilling	B
prophecy	I
has	O
been	O
generated	O
a	O
phenomenon	O
long	O
known	O
in	O
economics	O
the	O
same	O
applies	O
the	O
other	O
way	O
around	O
we	O
sell	O
shares	O
because	O
we	O
believe	O
that	O
tomorrow	O
the	O
prices	O
will	O
decrease	O
this	O
will	O
beat	O
down	O
the	O
prices	O
the	O
next	O
day	O
and	O
generally	O
even	O
more	O
the	O
day	O
after	O
the	O
next	O
share	O
price	O
function	O
of	O
assumed	O
future	O
value	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
c	O
excursus	O
reinforcement	B
learning	I
what	O
if	O
there	O
were	O
no	O
training	O
samples	O
but	O
it	O
would	O
nevertheless	O
be	O
possible	O
to	O
evaluate	O
how	O
well	O
we	O
have	O
learned	O
to	O
solve	O
a	O
problem	O
let	O
us	O
examine	O
a	O
learning	O
paradigm	O
that	O
is	O
situated	O
between	O
supervised	B
and	O
unsupervised	B
learning	O
i	O
now	O
want	O
to	O
introduce	O
a	O
more	O
exotic	O
approach	O
of	O
learning	O
just	O
to	O
leave	O
the	O
usual	O
paths	O
we	O
know	O
learning	O
procedures	O
in	O
which	O
the	O
network	O
is	O
exactly	O
told	O
what	O
to	O
do	O
i	O
e	O
we	O
provide	O
exemplary	O
output	B
values	O
we	O
also	O
know	O
learning	O
procedures	O
like	O
those	O
of	O
the	O
self-organizing	O
maps	O
into	O
which	O
only	O
input	B
values	O
are	O
entered	O
now	O
we	O
want	O
to	O
explore	O
something	O
inbetween	O
the	O
learning	O
paradigm	O
of	O
reinforcement	B
learning	I
reinforcement	B
learning	I
according	O
to	O
sutton	O
and	O
barto	O
reinforcement	B
learning	I
in	O
itself	O
is	O
no	O
neural	B
network	I
but	O
only	O
one	O
of	O
the	O
three	O
learning	O
paradigms	O
already	O
mentioned	O
in	O
chapter	O
in	O
some	O
sources	O
it	O
is	O
counted	O
among	O
the	O
supervised	B
learning	O
procedures	O
since	O
a	O
feedback	O
is	O
given	O
due	O
to	O
its	O
very	O
rudimentary	O
feedback	O
it	O
is	O
reasonable	O
to	O
separate	O
it	O
from	O
the	O
supervised	B
learning	O
procedures	O
apart	O
from	O
the	O
fact	O
that	O
there	O
are	O
no	O
training	O
samples	O
at	O
all	O
no	O
samples	O
but	O
feedback	O
from	O
cognitive	O
science	O
i	O
e	O
term	O
reinforcement	B
while	O
it	O
is	O
generally	O
known	O
that	O
procedures	O
such	O
as	O
backpropagation	B
cannot	O
work	O
in	O
the	O
human	O
brain	B
itself	O
reinforcement	B
learning	I
is	O
usually	O
considered	O
as	O
being	O
biologically	O
more	O
motivated	O
learning	O
the	O
and	O
comes	O
psychology	O
and	O
it	O
describes	O
the	O
learning	O
system	O
of	O
carrot	O
and	O
stick	O
which	O
occurs	O
everywhere	O
in	O
nature	O
learning	O
by	O
means	O
of	O
good	O
or	O
bad	O
experience	O
reward	B
and	O
punishment	O
but	O
there	O
is	O
no	O
learning	O
aid	O
that	O
exactly	O
explains	O
what	O
we	O
have	O
to	O
do	O
we	O
only	O
receive	O
a	O
total	B
result	O
for	O
a	O
process	O
we	O
win	O
the	O
game	O
of	O
chess	O
or	O
not	O
and	O
how	O
sure	O
was	O
this	O
victory	O
but	O
no	O
results	O
for	O
the	O
individual	O
intermediate	O
steps	O
for	O
example	O
if	O
we	O
ride	O
our	O
bike	O
with	O
worn	O
tires	O
and	O
at	O
a	O
speed	O
of	O
exactly	O
km	O
h	O
through	O
a	O
turn	O
over	O
some	O
sand	O
with	O
a	O
grain	O
size	O
of	O
on	O
the	O
average	O
then	O
nobody	O
could	O
tell	O
us	O
exactly	O
which	O
han	O
appendix	O
c	O
excursus	O
reinforcement	B
learning	I
dkriesel	O
com	O
dlebar	O
angle	O
we	O
have	O
to	O
adjust	O
or	O
even	O
worse	O
how	O
strong	O
the	O
great	O
number	O
of	O
muscle	O
parts	O
in	O
our	O
arms	O
or	O
legs	O
have	O
to	O
contract	O
for	O
this	O
depending	O
on	O
whether	O
we	O
reach	O
the	O
end	O
of	O
the	O
curve	O
unharmed	O
or	O
not	O
we	O
soon	O
have	O
to	O
face	O
the	O
learning	O
experience	O
a	O
feedback	O
or	O
a	O
reward	B
be	O
it	O
good	O
or	O
bad	O
thus	O
the	O
reward	B
is	O
very	O
simple	O
but	O
on	O
the	O
other	O
hand	O
it	O
is	O
considerably	O
easier	O
to	O
obtain	O
if	O
we	O
now	O
have	O
tested	O
different	O
velocities	O
and	O
turning	O
angles	O
often	O
enough	O
and	O
received	O
some	O
rewards	O
we	O
will	O
get	O
a	O
feel	O
for	O
what	O
works	O
and	O
what	O
does	O
not	O
the	O
aim	O
of	O
reinforcement	B
learning	I
is	O
to	O
maintain	O
exactly	O
this	O
feeling	O
another	O
the	O
quasiimpossibility	O
to	O
achieve	O
a	O
sort	O
of	O
cost	O
or	O
utility	O
function	O
is	O
a	O
tennis	O
player	O
who	O
tries	O
to	O
maximize	O
his	O
athletic	O
success	O
on	O
the	O
long	O
term	O
by	O
means	O
of	O
complex	O
movements	O
and	O
ballistic	O
trajectories	O
in	O
the	O
three-dimensional	O
space	O
including	O
the	O
wind	O
direction	O
the	O
importance	O
of	O
the	O
tournament	O
private	O
factors	O
and	O
many	O
more	O
to	O
get	O
straight	O
to	O
the	O
point	O
since	O
we	O
receive	O
only	O
little	O
feedback	O
reinforcement	B
learning	I
often	O
means	O
trial	O
and	O
error	O
and	O
therefore	O
it	O
is	O
very	O
slow	O
example	O
for	O
system	O
structure	O
now	O
we	O
want	O
to	O
briefly	O
discuss	O
different	O
sizes	O
and	O
components	O
of	O
the	O
system	O
we	O
will	O
define	O
them	O
more	O
precisely	O
in	O
the	O
following	O
sections	O
broadly	O
speaking	O
reinforcement	B
learning	I
represents	O
the	O
mutual	O
interaction	O
between	O
an	O
agent	B
and	O
an	O
environmental	O
system	O
the	O
agent	B
shall	O
solve	O
some	O
problem	O
he	O
could	O
for	O
instance	O
be	O
an	O
autonomous	O
robot	O
that	O
shall	O
avoid	O
obstacles	O
the	O
agent	B
performs	O
some	O
actions	O
within	O
the	O
environment	B
and	O
in	O
return	B
receives	O
a	O
feedback	O
from	O
the	O
environment	B
which	O
in	O
the	O
following	O
is	O
called	O
reward	B
this	O
cycle	O
of	O
action	B
and	O
reward	B
is	O
characteristic	O
for	O
reinforcement	B
learning	I
the	O
agent	B
influences	O
the	O
system	O
the	O
system	O
provides	O
a	O
reward	B
and	O
then	O
changes	O
the	O
reward	B
is	O
a	O
real	O
or	O
discrete	B
scalar	O
which	O
describes	O
as	O
mentioned	O
above	O
how	O
well	O
we	O
achieve	O
our	O
aim	O
but	O
it	O
does	O
not	O
give	O
any	O
guidance	O
how	O
we	O
can	O
achieve	O
it	O
the	O
aim	O
is	O
always	O
to	O
make	O
the	O
sum	O
of	O
rewards	O
as	O
high	O
as	O
possible	O
on	O
the	O
long	O
term	O
the	O
gridworld	B
as	O
a	O
learning	O
example	O
for	O
reinforcement	B
learning	I
i	O
would	O
like	O
to	O
use	O
the	O
so-called	O
gridworld	B
we	O
will	O
see	O
that	O
its	O
structure	O
is	O
very	O
simple	O
and	O
easy	O
to	O
figure	O
out	O
and	O
therefore	O
reinforcement	B
is	O
actually	O
not	O
necessary	O
however	O
it	O
is	O
very	O
suitable	O
for	O
representing	O
the	O
approach	O
of	O
reinforcement	B
learning	I
now	O
let	O
us	O
exemplary	O
define	O
the	O
individual	O
components	O
of	O
the	O
reinforcement	B
system	O
by	O
means	O
of	O
the	O
gridworld	B
later	O
each	O
of	O
these	O
components	O
will	O
be	O
examined	O
more	O
exactly	O
environment	B
the	O
gridworld	B
on	O
the	O
facing	O
page	O
is	O
a	O
simple	O
discrete	B
simple	O
examplary	O
world	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
system	O
structure	O
world	O
in	O
two	O
dimensions	O
which	O
in	O
the	O
following	O
we	O
want	O
to	O
use	O
as	O
environmental	O
system	O
agent	B
as	O
an	O
agent	B
we	O
use	O
a	O
simple	O
robot	O
being	O
situated	O
in	O
our	O
gridworld	B
state	B
space	O
as	O
we	O
can	O
see	O
our	O
gridworld	B
has	O
fields	O
with	O
fields	O
being	O
unaccessible	O
therefore	O
our	O
agent	B
can	O
occupy	O
positions	O
in	O
the	O
grid	B
world	O
these	O
positions	O
are	O
regarded	O
as	O
states	O
for	O
the	O
agent	B
action	B
space	I
the	O
actions	O
are	O
still	O
missing	O
we	O
simply	O
define	O
that	O
the	O
robot	O
could	O
move	O
one	O
field	O
up	O
or	O
down	O
to	O
the	O
right	O
or	O
to	O
the	O
left	O
long	O
as	O
there	O
is	O
no	O
obstacle	O
or	O
the	O
edge	O
of	O
our	O
gridworld	B
task	O
our	O
agent	B
s	O
task	O
is	O
to	O
leave	O
the	O
gridworld	B
the	O
exit	O
is	O
located	O
on	O
the	O
right	O
of	O
the	O
light-colored	O
field	O
non-determinism	O
the	O
two	O
obstacles	O
can	O
be	O
connected	O
by	O
a	O
when	O
the	O
door	O
is	O
closed	O
part	O
of	O
the	O
illustration	O
the	O
corresponding	O
field	O
is	O
inaccessible	O
the	O
position	O
of	O
the	O
door	O
cannot	O
change	O
during	O
a	O
cycle	O
but	O
only	O
between	O
the	O
cycles	O
we	O
now	O
have	O
created	O
a	O
small	O
world	O
that	O
will	O
accompany	O
us	O
through	O
the	O
following	O
learning	O
strategies	O
and	O
illustrate	O
them	O
agent	B
und	O
environment	B
our	O
aim	O
is	O
that	O
the	O
agent	B
learns	O
what	O
happens	O
by	O
means	O
of	O
the	O
reward	B
thus	O
it	O
figure	O
a	O
graphical	O
representation	O
of	O
our	O
gridworld	B
dark-colored	O
cells	O
are	O
obstacles	O
and	O
therefore	O
inaccessible	O
the	O
exit	O
is	O
located	O
on	O
the	O
right	O
side	O
of	O
the	O
light-colored	O
field	O
the	O
symbol	O
marks	O
the	O
starting	O
position	O
of	O
our	O
agent	B
in	O
the	O
upper	O
part	O
of	O
our	O
figure	O
the	O
door	O
is	O
open	O
in	O
the	O
lower	O
part	O
it	O
is	O
closed	O
agent	B
reward	B
new	O
situation	B
action	B
environment	B
figure	O
the	O
agent	B
performs	O
some	O
actions	O
within	O
the	O
environment	B
and	O
in	O
return	B
receives	O
a	O
reward	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
agent	B
acts	O
in	O
environment	B
appendix	O
c	O
excursus	O
reinforcement	B
learning	I
dkriesel	O
com	O
is	O
trained	O
over	O
of	O
and	O
by	O
means	O
of	O
a	O
dynamic	O
system	O
the	O
environment	B
in	O
order	O
to	O
reach	O
an	O
aim	O
but	O
what	O
does	O
learning	O
mean	O
in	O
this	O
context	B
the	O
agent	B
shall	O
learn	O
a	O
mapping	O
of	O
situations	O
to	O
actions	O
policy	B
i	O
e	O
it	O
shall	O
learn	O
what	O
to	O
do	O
in	O
which	O
situation	B
to	O
achieve	O
a	O
certain	O
aim	O
the	O
aim	O
is	O
simply	O
shown	O
to	O
the	O
agent	B
by	O
giving	O
an	O
award	O
for	O
the	O
achievement	O
such	O
an	O
award	O
must	O
not	O
be	O
mistaken	O
for	O
the	O
reward	B
on	O
the	O
agent	B
s	O
way	O
to	O
the	O
solution	O
it	O
may	O
sometimes	O
be	O
useful	O
to	O
receive	O
a	O
smaller	O
award	O
or	O
a	O
punishment	O
when	O
in	O
return	B
the	O
longterm	O
result	O
is	O
maximum	O
to	O
the	O
situation	B
when	O
an	O
investor	O
just	O
sits	O
out	O
the	O
downturn	O
of	O
the	O
share	O
price	O
or	O
to	O
a	O
pawn	O
sacrifice	O
in	O
a	O
chess	O
game	O
so	O
if	O
the	O
agent	B
is	O
heading	O
into	O
the	O
right	O
direction	O
towards	O
the	O
target	B
it	O
receives	O
a	O
positive	O
reward	B
and	O
if	O
not	O
it	O
receives	O
no	O
reward	B
at	O
all	O
or	O
even	O
a	O
negative	O
reward	B
the	O
award	O
is	O
so	O
to	O
speak	O
the	O
final	O
sum	O
of	O
all	O
rewards	O
which	O
is	O
also	O
called	O
return	B
after	O
having	O
colloquially	O
named	O
all	O
the	O
basic	O
components	O
we	O
want	O
to	O
discuss	O
more	O
precisely	O
which	O
components	O
can	O
be	O
used	O
to	O
make	O
up	O
our	O
abstract	O
reinforcement	B
learning	I
system	O
in	O
the	O
gridworld	B
in	O
the	O
gridworld	B
the	O
agent	B
is	O
a	O
simple	O
robot	O
that	O
should	O
find	O
the	O
exit	O
of	O
the	O
gridworld	B
the	O
environment	B
is	O
the	O
gridworld	B
itself	O
which	O
is	O
a	O
discrete	B
gridworld	B
definition	O
in	O
reinforcement	B
learning	I
the	O
agent	B
can	O
be	O
formally	O
described	O
as	O
a	O
mapping	O
of	O
the	O
situation	B
space	I
s	O
into	O
the	O
action	B
space	I
ast	O
the	O
meaning	O
of	O
situations	O
st	O
will	O
be	O
defined	O
later	O
and	O
should	O
only	O
indicate	O
that	O
the	O
action	B
space	I
depends	O
on	O
the	O
current	O
situation	B
agent	B
s	O
ast	O
definition	O
the	O
environment	B
represents	O
a	O
stochastic	O
mapping	O
of	O
an	O
action	B
a	O
in	O
the	O
current	O
situation	B
st	O
to	O
a	O
reward	B
rt	O
and	O
a	O
new	O
situation	B
environment	B
s	O
a	O
ps	O
rt	O
states	O
situations	O
and	O
actions	O
as	O
already	O
mentioned	O
an	O
agent	B
can	O
be	O
in	O
different	O
states	O
in	O
case	O
of	O
the	O
gridworld	B
for	O
example	O
it	O
can	O
be	O
in	O
different	O
positions	O
we	O
get	O
a	O
two-dimensional	O
state	B
vector	O
for	O
an	O
agent	B
is	O
ist	O
not	O
always	O
possible	O
to	O
realize	O
all	O
information	O
about	O
its	O
current	O
state	B
so	O
that	O
we	O
have	O
to	O
introduce	O
the	O
term	O
situation	B
a	O
situation	B
is	O
a	O
state	B
from	O
the	O
agent	B
s	O
point	O
of	O
view	O
i	O
e	O
only	O
a	O
more	O
or	O
less	O
precise	B
approximation	B
of	O
a	O
state	B
therefore	O
situations	O
generally	O
do	O
not	O
allow	O
to	O
clearly	O
successor	O
situations	O
even	O
with	O
a	O
completely	O
deterministic	O
system	O
this	O
may	O
not	O
be	O
applicable	O
if	O
we	O
knew	O
all	O
states	O
and	O
the	O
transitions	O
between	O
them	O
exactly	O
the	O
complete	O
system	O
it	O
would	O
be	O
possible	O
to	O
plan	O
optimally	O
and	O
also	O
easy	O
to	O
find	O
an	O
optimal	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
system	O
structure	O
policy	B
are	O
provided	O
for	O
example	O
by	O
dynamic	O
programming	O
now	O
we	O
know	O
that	O
reinforcement	B
learning	I
is	O
an	O
interaction	O
between	O
the	O
agent	B
and	O
the	O
system	O
including	O
actions	O
at	O
and	O
situations	O
st	O
the	O
agent	B
cannot	O
determine	O
by	O
itself	O
whether	O
the	O
current	O
situation	B
is	O
good	O
or	O
bad	O
this	O
is	O
exactly	O
the	O
reason	O
why	O
it	O
receives	O
the	O
said	O
reward	B
from	O
the	O
environment	B
in	O
the	O
gridworld	B
states	O
are	O
positions	O
where	O
the	O
agent	B
can	O
be	O
situated	O
simply	O
said	O
the	O
situations	O
equal	O
the	O
states	O
in	O
the	O
gridworld	B
possible	O
actions	O
would	O
be	O
to	O
move	O
towards	O
north	O
south	O
east	O
or	O
west	O
situation	B
and	O
action	B
can	O
be	O
vectorial	O
the	O
reward	B
is	O
always	O
a	O
scalar	O
an	O
extreme	O
case	O
even	O
only	O
a	O
binary	B
value	O
since	O
the	O
aim	O
of	O
reinforcement	B
learning	I
is	O
to	O
get	O
along	O
with	O
little	O
feedback	O
a	O
complex	O
vectorial	O
reward	B
would	O
equal	O
a	O
real	O
teaching	B
input	B
by	O
the	O
way	O
the	O
cost	O
function	O
should	O
be	O
minimized	O
which	O
would	O
not	O
be	O
possible	O
however	O
with	O
a	O
vectorial	O
reward	B
since	O
we	O
do	O
not	O
have	O
any	O
intuitive	O
order	O
relations	O
in	O
multi-dimensional	O
space	O
i	O
e	O
we	O
do	O
not	O
directly	O
know	O
what	O
is	O
better	O
or	O
worse	O
definition	O
within	O
its	O
environment	B
the	O
agent	B
is	O
in	O
a	O
state	B
states	O
contain	O
any	O
information	O
about	O
the	O
agent	B
within	O
the	O
environmental	O
system	O
thus	O
it	O
is	O
theoretically	O
possible	O
to	O
clearly	O
predict	O
a	O
successor	O
state	B
to	O
a	O
performed	O
action	B
within	O
a	O
deterministic	O
system	O
out	O
of	O
this	O
godlike	O
state	B
knowledge	O
definition	O
situations	O
st	O
at	O
time	O
t	O
of	O
a	O
situation	B
space	I
s	O
are	O
the	O
agent	B
s	O
limited	O
approximate	O
knowledge	O
about	O
its	O
state	B
this	O
approximation	B
which	O
the	O
agent	B
cannot	O
even	O
know	O
how	O
good	O
it	O
is	O
makes	O
clear	O
predictions	O
impossible	O
definition	O
actions	O
at	O
can	O
be	O
performed	O
by	O
the	O
agent	B
it	O
could	O
be	O
possible	O
that	O
depending	O
on	O
the	O
situation	B
another	O
action	B
space	I
as	O
ex-	O
ists	O
they	O
cause	O
state	B
transitions	O
and	O
therefore	O
a	O
new	O
situation	B
from	O
the	O
agent	B
s	O
point	O
of	O
view	O
reward	B
and	O
return	B
as	O
in	O
real	O
life	O
it	O
is	O
our	O
aim	O
to	O
receive	O
an	O
award	O
that	O
is	O
as	O
high	O
as	O
possible	O
i	O
e	O
to	O
maximize	O
the	O
sum	O
of	O
the	O
expected	O
rewards	O
r	O
called	O
return	B
r	O
on	O
the	O
long	O
term	O
for	O
finitely	O
many	O
time	O
the	O
rewards	O
can	O
simply	O
be	O
added	O
rt	O
x	O
rtx	O
certainly	O
the	O
return	B
is	O
only	O
estimated	O
here	O
we	O
knew	O
all	O
rewards	O
and	O
therefore	O
the	O
return	B
completely	O
it	O
would	O
no	O
longer	O
be	O
necessary	O
to	O
learn	O
definition	O
a	O
reward	B
rt	O
is	O
a	O
scalar	O
real	O
or	O
discrete	B
sometimes	O
only	O
binary	B
reward	B
or	O
punishment	O
which	O
in	O
practice	O
only	O
finitely	O
many	O
time	O
steps	O
will	O
be	O
possible	O
even	O
though	O
the	O
formulas	O
are	O
stated	O
with	O
an	O
infinite	O
sum	O
in	O
the	O
first	O
place	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
c	O
excursus	O
reinforcement	B
learning	I
dkriesel	O
com	O
the	O
environmental	O
system	O
returns	O
to	O
the	O
agent	B
as	O
reaction	O
to	O
an	O
action	B
definition	O
the	O
return	B
rt	O
is	O
the	O
accumulation	O
of	O
all	O
received	O
rewards	O
until	O
time	O
t	O
dealing	O
with	O
long	O
periods	O
of	O
time	O
however	O
not	O
every	O
problem	O
has	O
an	O
explicit	O
target	B
and	O
therefore	O
a	O
finite	O
sum	O
our	O
agent	B
can	O
be	O
a	O
robot	O
having	O
the	O
task	O
to	O
drive	O
around	O
again	O
and	O
again	O
and	O
to	O
avoid	O
obstacles	O
in	O
order	O
not	O
to	O
receive	O
a	O
diverging	O
sum	O
in	O
case	O
of	O
an	O
infinite	O
series	O
of	O
reward	B
estimations	O
a	O
weakening	O
factor	O
is	O
used	O
which	O
weakens	O
the	O
influence	O
of	O
future	O
rewards	O
this	O
is	O
not	O
only	O
useful	O
if	O
there	O
exists	O
no	O
target	B
but	O
also	O
if	O
the	O
target	B
is	O
very	O
far	O
away	O
rt	O
x	O
x	O
the	O
farther	O
the	O
reward	B
is	O
away	O
the	O
smaller	O
is	O
the	O
influence	O
it	O
has	O
in	O
the	O
agent	B
s	O
decisions	O
another	O
possibility	O
to	O
handle	O
the	O
return	B
sum	O
would	O
be	O
a	O
limited	O
time	B
horizon	I
so	O
that	O
only	O
many	O
following	O
rewards	O
rt	O
are	O
regarded	O
rt	O
x	O
x	O
the	O
thus	O
we	O
divide	O
into	O
episodes	O
usually	O
one	O
of	O
the	O
two	O
methods	O
is	O
used	O
to	O
limit	O
the	O
sum	O
if	O
not	O
both	O
methods	O
together	O
timeline	O
as	O
in	O
daily	O
living	O
we	O
try	O
to	O
approximate	O
our	O
current	O
situation	B
to	O
a	O
desired	O
state	B
since	O
it	O
is	O
not	O
mandatory	O
that	O
only	O
the	O
next	O
expected	O
reward	B
but	O
the	O
expected	O
total	B
sum	O
decides	O
what	O
the	O
agent	B
will	O
do	O
it	O
is	O
also	O
possible	O
to	O
perform	O
actions	O
that	O
on	O
short	O
notice	O
result	O
in	O
a	O
negative	O
reward	B
the	O
pawn	O
sacrifice	O
in	O
a	O
chess	O
game	O
but	O
will	O
pay	O
off	O
later	O
the	O
policy	B
after	O
having	O
considered	O
and	O
formalized	O
some	O
system	O
components	O
of	O
reinforcement	B
learning	I
the	O
actual	O
aim	O
is	O
still	O
to	O
be	O
discussed	O
during	O
reinforcement	B
learning	I
the	O
agent	B
learns	O
a	O
policy	B
s	O
pa	O
thus	O
it	O
continuously	O
adjusts	O
a	O
mapping	O
of	O
the	O
situations	O
to	O
the	O
probabilities	O
pa	O
with	O
which	O
any	O
action	B
a	O
is	O
performed	O
in	O
any	O
situation	B
s	O
a	O
policy	B
can	O
be	O
defined	O
as	O
a	O
strategy	O
to	O
select	O
actions	O
that	O
would	O
maximize	O
the	O
reward	B
in	O
the	O
long	O
term	O
in	O
the	O
gridworld	B
in	O
the	O
gridworld	B
the	O
policy	B
is	O
the	O
strategy	O
according	O
to	O
which	O
the	O
agent	B
tries	O
to	O
exit	O
the	O
gridworld	B
definition	O
the	O
policy	B
s	O
a	O
mapping	O
of	O
situations	O
to	O
probabilities	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
system	O
structure	O
to	O
perform	O
every	O
action	B
out	O
of	O
the	O
action	B
space	I
so	O
it	O
can	O
be	O
formalized	O
as	O
s	O
pa	O
basically	O
we	O
distinguish	O
between	O
two	O
policy	B
paradigms	O
an	O
open	B
loop	I
policy	B
represents	O
an	O
open	O
control	O
chain	O
and	O
creates	O
out	O
of	O
an	O
initial	O
situation	B
a	O
sequence	O
of	O
actions	O
with	O
ai	O
aisi	O
i	O
thus	O
in	O
the	O
beginning	O
the	O
agent	B
develops	O
a	O
plan	O
and	O
consecutively	O
executes	O
it	O
to	O
the	O
end	O
without	O
considering	O
the	O
intermediate	O
situations	O
ai	O
aisi	O
actions	O
after	O
do	O
not	O
depend	O
on	O
the	O
situations	O
in	O
the	O
gridworld	B
in	O
the	O
gridworld	B
an	O
open-loop	O
policy	B
would	O
provide	O
a	O
precise	B
direction	O
towards	O
the	O
exit	O
such	O
as	O
the	O
way	O
from	O
the	O
given	O
starting	O
position	O
to	O
abbreviations	O
of	O
the	O
directions	O
eeeen	O
so	O
an	O
open-loop	O
policy	B
is	O
a	O
sequence	O
of	O
actions	O
without	O
interim	O
feedback	O
a	O
sequence	O
of	O
actions	O
is	O
generated	O
out	O
of	O
a	O
starting	O
situation	B
if	O
the	O
system	O
is	O
known	O
well	O
and	O
truly	O
such	O
an	O
open-loop	O
policy	B
can	O
be	O
used	O
successfully	O
and	O
lead	O
to	O
useful	O
results	O
but	O
for	O
example	O
to	O
know	O
the	O
chess	O
game	O
well	O
and	O
truly	O
it	O
would	O
be	O
necessary	O
to	O
try	O
every	O
possible	O
move	O
which	O
would	O
be	O
very	O
time-consuming	O
thus	O
for	O
such	O
problems	B
we	O
have	O
to	O
find	O
an	O
alternative	O
to	O
the	O
open-loop	O
policy	B
which	O
incorporates	O
the	O
current	O
situations	O
into	O
the	O
action	B
plan	O
a	O
closed	B
loop	I
policy	B
is	O
a	O
closed	B
loop	I
a	O
function	O
si	O
ai	O
with	O
ai	O
aisi	O
in	O
a	O
manner	O
of	O
speaking	O
here	O
the	O
environment	B
influences	O
our	O
action	B
or	O
the	O
agent	B
responds	O
to	O
the	O
input	B
of	O
the	O
environment	B
respectively	O
as	O
already	O
illustrated	O
in	O
fig	O
a	O
closed-loop	O
policy	B
so	O
to	O
speak	O
is	O
a	O
reactive	O
plan	O
to	O
map	O
current	O
situations	O
to	O
actions	O
to	O
be	O
performed	O
in	O
the	O
gridworld	B
a	O
closed-loop	O
policy	B
would	O
be	O
responsive	O
to	O
the	O
current	O
position	O
and	O
choose	O
the	O
direction	O
according	O
to	O
the	O
action	B
in	O
particular	O
when	O
an	O
obstacle	O
appears	O
dynamically	O
such	O
a	O
policy	B
is	O
the	O
better	O
choice	O
when	O
selecting	O
the	O
actions	O
to	O
be	O
performed	O
again	O
two	O
basic	O
strategies	O
can	O
be	O
examined	O
exploitation	O
vs	O
exploration	O
as	O
in	O
real	O
life	O
during	O
reinforcement	B
learning	I
often	O
the	O
question	O
arises	O
whether	O
the	O
exisiting	O
knowledge	O
is	O
only	O
willfully	O
exploited	O
or	O
new	O
ways	O
are	O
also	O
explored	O
initially	O
we	O
want	O
to	O
discuss	O
the	O
two	O
extremes	O
a	O
greedy	B
policy	B
always	O
chooses	O
the	O
way	O
of	O
the	O
highest	O
reward	B
that	O
can	O
be	O
determined	O
in	O
advance	O
i	O
e	O
the	O
way	O
of	O
the	O
highest	O
known	O
reward	B
this	O
policy	B
represents	O
the	O
exploitation	B
approach	I
and	O
is	O
very	O
promising	O
when	O
the	O
used	O
system	O
is	O
already	O
known	O
in	O
contrast	O
to	O
the	O
exploitation	B
approach	I
it	O
is	O
the	O
aim	O
of	O
the	O
exploration	B
approach	I
to	O
explore	O
a	O
system	O
as	O
detailed	O
as	O
possible	O
so	O
that	O
also	O
such	O
paths	O
leading	O
to	O
the	O
target	B
can	O
be	O
found	O
which	O
may	O
be	O
not	O
very	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
research	O
or	O
safety	O
appendix	O
c	O
excursus	O
reinforcement	B
learning	I
dkriesel	O
com	O
promising	O
at	O
first	O
glance	O
but	O
are	O
in	O
fact	O
very	O
successful	O
let	O
us	O
assume	O
that	O
we	O
are	O
looking	O
for	O
the	O
way	O
to	O
a	O
restaurant	O
a	O
safe	O
policy	B
would	O
be	O
to	O
always	O
take	O
the	O
way	O
we	O
already	O
know	O
not	O
matter	O
how	O
unoptimal	O
and	O
long	O
it	O
may	O
be	O
and	O
not	O
to	O
try	O
to	O
explore	O
better	O
ways	O
another	O
approach	O
would	O
be	O
to	O
explore	O
shorter	O
ways	O
every	O
now	O
and	O
then	O
even	O
at	O
the	O
risk	O
of	O
taking	O
a	O
long	O
time	O
and	O
being	O
unsuccessful	O
and	O
therefore	O
finally	O
having	O
to	O
take	O
the	O
original	O
way	O
and	O
arrive	O
too	O
late	O
at	O
the	O
restaurant	O
in	O
reality	O
often	O
a	O
combination	O
of	O
both	O
methods	O
is	O
applied	O
in	O
the	O
beginning	O
of	O
the	O
learning	O
process	O
it	O
is	O
researched	O
with	O
a	O
higher	O
probability	O
while	O
at	O
the	O
end	O
more	O
existing	O
knowledge	O
is	O
exploited	O
here	O
a	O
static	O
probability	O
distribution	O
is	O
also	O
possible	O
and	O
often	O
applied	O
in	O
the	O
gridworld	B
for	O
finding	O
the	O
way	O
in	O
the	O
gridworld	B
the	O
restaurant	O
example	O
applies	O
equally	O
learning	O
process	O
let	O
us	O
again	O
take	O
a	O
look	O
at	O
daily	O
life	O
actions	O
can	O
lead	O
us	O
from	O
one	O
situation	B
into	O
different	O
subsituations	O
from	O
each	O
subsituation	O
into	O
further	O
sub-subsituations	O
in	O
a	O
sense	O
we	O
get	O
a	O
situation	B
tree	B
where	O
links	O
between	O
the	O
nodes	O
must	O
be	O
considered	O
there	O
are	O
several	O
ways	O
to	O
reach	O
a	O
situation	B
so	O
the	O
tree	B
could	O
more	O
accurately	O
be	O
referred	O
to	O
as	O
a	O
situation	B
graph	O
he	O
leaves	O
of	O
such	O
a	O
tree	B
are	O
the	O
end	O
situations	O
of	O
the	O
system	O
the	O
exploration	B
approach	I
would	O
search	O
the	O
tree	B
as	O
thoroughly	O
as	O
possible	O
and	O
become	O
acquainted	O
with	O
all	O
leaves	O
the	O
exploitation	B
approach	I
would	O
unerringly	O
go	O
to	O
the	O
best	O
known	O
leave	O
analogous	O
to	O
the	O
situation	B
tree	B
we	O
also	O
can	O
create	O
an	O
action	B
tree	B
here	O
the	O
rewards	O
for	O
the	O
actions	O
are	O
within	O
the	O
nodes	O
now	O
we	O
have	O
to	O
adapt	O
from	O
daily	O
life	O
how	O
we	O
learn	O
exactly	O
rewarding	O
strategies	O
interesting	O
and	O
very	O
important	O
is	O
the	O
question	O
for	O
what	O
a	O
reward	B
and	O
what	O
kind	O
of	O
reward	B
is	O
awarded	O
since	O
the	O
design	O
of	O
the	O
reward	B
significantly	O
controls	O
system	O
behavior	O
as	O
we	O
have	O
seen	O
above	O
there	O
generally	O
are	O
as	O
in	O
daily	O
life	O
various	O
actions	O
that	O
can	O
be	O
performed	O
in	O
any	O
situation	B
there	O
are	O
different	O
strategies	O
to	O
evaluate	O
the	O
selected	O
situations	O
and	O
to	O
learn	O
which	O
series	O
of	O
actions	O
would	O
lead	O
to	O
the	O
target	B
first	O
of	O
all	O
this	O
principle	O
should	O
be	O
explained	O
in	O
the	O
following	O
we	O
now	O
want	O
to	O
indicate	O
some	O
extreme	O
cases	O
as	O
design	O
examples	O
for	O
the	O
reward	B
a	O
rewarding	O
similar	O
to	O
the	O
rewarding	O
in	O
a	O
chess	O
game	O
is	O
referred	O
to	O
as	O
pure	B
delayed	I
reward	B
we	O
only	O
receive	O
the	O
reward	B
at	O
the	O
end	O
of	O
and	O
not	O
during	O
the	O
game	O
this	O
method	O
is	O
always	O
advantageous	O
when	O
we	O
finally	O
can	O
say	O
whether	O
we	O
were	O
succesful	O
or	O
not	O
but	O
the	O
interim	O
steps	O
do	O
not	O
allow	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
learning	O
process	O
an	O
estimation	O
of	O
our	O
situation	B
if	O
we	O
win	O
then	O
rt	O
t	O
as	O
well	O
as	O
r	O
if	O
we	O
lose	O
then	O
r	O
with	O
this	O
rewarding	O
strategy	O
a	O
reward	B
is	O
only	O
returned	O
by	O
the	O
leaves	O
of	O
the	O
situation	B
tree	B
pure	B
negative	I
reward	B
here	O
rt	O
t	O
this	O
system	O
finds	O
the	O
most	O
rapid	O
way	O
to	O
reach	O
the	O
target	B
because	O
this	O
way	O
is	O
automatically	O
the	O
most	O
favorable	O
one	O
in	O
respect	O
of	O
the	O
reward	B
the	O
agent	B
receives	O
punishment	O
for	O
anything	O
it	O
does	O
even	O
if	O
it	O
does	O
nothing	O
as	O
a	O
result	O
it	O
is	O
the	O
most	O
inexpensive	O
method	O
for	O
the	O
agent	B
to	O
reach	O
the	O
target	B
fast	O
another	O
strategy	O
is	O
the	O
avoidance	B
strategy	I
harmful	O
situations	O
are	O
avoided	O
here	O
rt	O
most	O
situations	O
do	O
not	O
receive	O
any	O
reward	B
only	O
a	O
few	O
of	O
them	O
receive	O
a	O
negative	O
reward	B
the	O
agent	B
agent	B
will	O
avoid	O
getting	O
too	O
close	O
to	O
such	O
negative	O
situations	O
warning	O
rewarding	O
strategies	O
can	O
have	O
unexpected	O
consequences	O
a	O
robot	O
that	O
is	O
told	O
it	O
your	O
own	O
way	O
but	O
if	O
you	O
touch	O
an	O
obstacle	O
you	O
will	O
be	O
punished	O
will	O
simply	O
stand	O
still	O
if	O
standing	O
still	O
is	O
also	O
punished	O
it	O
will	O
drive	O
in	O
small	O
circles	O
reconsidering	O
this	O
we	O
will	O
understand	O
that	O
this	O
behavior	O
optimally	O
fulfills	O
the	O
return	B
of	O
the	O
robot	O
but	O
unfortunately	O
was	O
not	O
intended	O
to	O
do	O
so	O
furthermore	O
we	O
can	O
show	O
that	O
especially	O
small	O
tasks	O
can	O
be	O
solved	O
better	O
by	O
means	O
of	O
negative	O
rewards	O
while	O
positive	O
more	O
differentiated	O
rewards	O
are	O
useful	O
for	O
large	O
complex	O
tasks	O
for	O
our	O
gridworld	B
we	O
want	O
to	O
apply	O
the	O
pure	B
negative	I
reward	B
strategy	O
the	O
robot	O
shall	O
find	O
the	O
exit	O
as	O
fast	O
as	O
possible	O
the	O
state-value	B
function	I
evaluation	B
unlike	O
our	O
agent	B
we	O
have	O
a	O
godlike	O
view	O
state	B
of	O
our	O
gridworld	B
so	O
that	O
we	O
can	O
swiftly	O
determine	O
which	O
robot	O
starting	O
position	O
can	O
provide	O
which	O
optimal	O
return	B
in	O
figure	O
on	O
the	O
next	O
page	O
these	O
optimal	O
returns	O
are	O
applied	O
per	O
field	O
in	O
the	O
gridworld	B
the	O
state-value	B
function	I
for	O
our	O
gridworld	B
exactly	O
represents	O
such	O
a	O
function	O
per	O
situation	B
position	O
with	O
the	O
difference	O
being	O
that	O
here	O
the	O
function	O
is	O
unknown	O
and	O
has	O
to	O
be	O
learned	O
thus	O
we	O
can	O
see	O
that	O
it	O
would	O
be	O
more	O
practical	O
for	O
the	O
robot	O
to	O
be	O
capable	O
to	O
evaluate	O
the	O
current	O
and	O
future	O
situations	O
so	O
let	O
us	O
take	O
a	O
look	O
at	O
another	O
system	O
component	O
of	O
reinforcement	B
learning	I
the	O
state-value	B
function	I
v	O
which	O
with	O
regard	O
to	O
a	O
policy	B
is	O
often	O
called	O
v	O
because	O
whether	O
a	O
situation	B
is	O
bad	O
often	O
depends	O
on	O
the	O
general	O
behavior	O
of	O
the	O
agent	B
a	O
situation	B
being	O
bad	O
under	O
a	O
policy	B
that	O
is	O
searching	O
risks	O
and	O
checking	O
out	O
limits	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
appendix	O
c	O
excursus	O
reinforcement	B
learning	I
dkriesel	O
com	O
figure	O
representation	O
of	O
each	O
optimal	O
return	B
per	O
field	O
in	O
our	O
gridworld	B
by	O
means	O
of	O
pure	B
negative	I
reward	B
awarding	O
at	O
the	O
top	O
with	O
an	O
open	O
and	O
at	O
the	O
bottom	O
with	O
a	O
closed	O
door	O
would	O
be	O
for	O
instance	O
if	O
an	O
agent	B
on	O
a	O
bicycle	O
turns	O
a	O
corner	O
and	O
the	O
front	O
wheel	O
begins	O
to	O
slide	O
out	O
and	O
due	O
to	O
its	O
daredevil	O
policy	B
the	O
agent	B
would	O
not	O
brake	O
in	O
this	O
situation	B
with	O
a	O
risk-aware	O
policy	B
the	O
same	O
situations	O
would	O
look	O
much	O
better	O
thus	O
it	O
would	O
be	O
evaluated	O
higher	O
by	O
a	O
good	O
state-value	B
function	I
v	O
simply	O
returns	O
the	O
value	O
the	O
current	O
situation	B
s	O
has	O
for	O
the	O
agent	B
under	O
policy	B
abstractly	O
speaking	O
according	O
to	O
the	O
above	O
definitions	O
the	O
value	O
of	O
the	O
statevalue	O
function	O
corresponds	O
to	O
the	O
return	B
rt	O
expected	O
value	O
of	O
a	O
situation	B
st	O
v	O
e	O
denotes	O
the	O
set	B
of	I
the	O
expected	O
returns	O
under	O
and	O
the	O
current	O
situation	B
st	O
v	O
e	O
st	O
definition	O
function	O
the	O
state-value	B
function	I
v	O
has	O
the	O
task	O
of	O
determining	O
the	O
value	O
of	O
situations	O
under	O
a	O
policy	B
i	O
e	O
to	O
answer	O
the	O
agent	B
s	O
question	O
of	O
whether	O
a	O
situation	B
s	O
is	O
good	O
or	O
bad	O
or	O
how	O
good	O
or	O
bad	O
it	O
is	O
for	O
this	O
purpose	O
it	O
returns	O
the	O
expectation	O
of	O
the	O
return	B
under	O
the	O
situation	B
v	O
e	O
st	O
the	O
optimal	O
state-value	B
function	I
is	O
called	O
v	O
unfortunaely	O
unlike	O
us	O
our	O
robot	O
does	O
not	O
have	O
a	O
godlike	O
view	O
of	O
its	O
environment	B
it	O
does	O
not	O
have	O
a	O
table	O
with	O
optimal	O
returns	O
like	O
the	O
one	O
shown	O
above	O
to	O
orient	O
itself	O
the	O
aim	O
of	O
reinforcement	B
learning	I
is	O
that	O
the	O
robot	O
generates	O
its	O
state-value	B
function	I
bit	O
by	O
bit	O
on	O
the	O
basis	B
of	O
the	O
returns	O
of	O
many	O
trials	O
and	O
approximates	O
the	O
optimal	O
state-value	B
function	I
v	O
there	O
is	O
one	O
in	O
this	O
context	B
i	O
want	O
to	O
introduce	O
two	O
terms	O
closely	O
related	O
to	O
the	O
cycle	O
between	O
state-value	B
function	I
and	O
policy	B
policy	B
evaluation	B
policy	B
evaluation	B
is	O
the	O
approach	O
to	O
try	O
a	O
policy	B
a	O
few	O
times	O
to	O
provide	O
many	O
rewards	O
that	O
way	O
and	O
to	O
gradually	O
accumulate	O
a	O
state-value	B
function	I
by	O
means	O
of	O
these	O
rewards	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
learning	O
process	O
v	O
v	O
figure	O
the	O
cycle	O
of	O
reinforcement	B
learning	I
which	O
ideally	O
leads	O
to	O
optimal	O
and	O
v	O
policy	B
improvement	B
policy	B
improvement	B
means	O
to	O
improve	O
a	O
policy	B
itself	O
i	O
e	O
to	O
turn	O
it	O
into	O
a	O
new	O
and	O
better	O
one	O
in	O
order	O
to	O
improve	O
the	O
policy	B
we	O
have	O
to	O
aim	O
at	O
the	O
return	B
finally	O
having	O
a	O
larger	O
value	O
than	O
before	O
i	O
e	O
until	O
we	O
have	O
found	O
a	O
shorter	O
way	O
to	O
the	O
restaurant	O
and	O
have	O
walked	O
it	O
successfully	O
the	O
principle	O
of	O
reinforcement	B
learning	I
is	O
to	O
realize	O
an	O
interaction	O
it	O
is	O
tried	O
to	O
evaluate	O
how	O
good	O
a	O
policy	B
is	O
in	O
individual	O
situations	O
the	O
changed	O
state-value	B
function	I
provides	O
information	O
about	O
the	O
system	O
with	O
which	O
we	O
again	O
improve	O
our	O
policy	B
these	O
two	O
values	O
lift	O
each	O
other	O
which	O
can	O
mathematically	O
be	O
proved	O
so	O
that	O
the	O
final	O
result	O
is	O
an	O
optimal	O
policy	B
and	O
an	O
optimal	O
state-value	B
function	I
v	O
this	O
cycle	O
sounds	O
simple	O
but	O
is	O
very	O
timeconsuming	O
at	O
first	O
let	O
us	O
regard	O
a	O
simple	O
random	O
policy	B
by	O
which	O
our	O
robot	O
could	O
slowly	O
fulfill	O
and	O
improve	O
its	O
state-value	B
function	I
without	O
any	O
previous	O
knowledge	O
monte	B
carlo	I
method	I
the	O
easiest	O
approach	O
to	O
accumulate	O
a	O
state-value	B
function	I
is	O
mere	O
trial	O
and	O
error	O
thus	O
we	O
select	O
a	O
randomly	O
behaving	O
policy	B
which	O
does	O
not	O
consider	O
the	O
accumulated	O
state-value	B
function	I
for	O
its	O
random	O
decisions	O
it	O
can	O
be	O
proved	O
that	O
at	O
some	O
point	O
we	O
will	O
find	O
the	O
exit	O
of	O
our	O
gridworld	B
by	O
chance	O
inspired	O
by	O
random-based	O
games	O
of	O
chance	O
this	O
approach	O
is	O
called	O
monte	B
carlo	I
method	I
if	O
we	O
additionally	O
assume	O
a	O
pure	B
negative	I
reward	B
it	O
is	O
obvious	O
that	O
we	O
can	O
receive	O
an	O
optimum	O
value	O
of	O
for	O
our	O
starting	O
field	O
in	O
the	O
state-value	B
function	I
depending	O
on	O
the	O
random	O
way	O
the	O
random	O
policy	B
takes	O
values	O
other	O
than	O
can	O
occur	O
for	O
the	O
starting	O
field	O
intuitively	O
we	O
want	O
to	O
memorize	O
only	O
the	O
better	O
value	O
for	O
one	O
state	B
one	O
field	O
but	O
here	O
caution	O
is	O
advised	O
in	O
this	O
way	O
the	O
learning	O
procedure	O
would	O
work	O
only	O
with	O
deterministic	O
systems	O
our	O
door	O
which	O
can	O
be	O
open	O
or	O
closed	O
during	O
a	O
cycle	O
would	O
produce	O
oscillations	O
for	O
all	O
fields	O
and	O
such	O
oscillations	O
would	O
influence	O
their	O
shortest	O
way	O
to	O
the	O
target	B
with	O
the	O
monte	B
carlo	I
method	I
we	O
prefer	O
to	O
use	O
the	O
learning	O
v	O
v	O
v	O
in	O
which	O
the	O
update	O
of	O
the	O
state-value	B
function	I
is	O
obviously	O
influenced	O
by	O
both	O
the	O
the	O
learning	O
rule	O
is	O
among	O
others	O
derived	O
by	O
means	O
of	O
the	O
bellman	O
equation	O
but	O
this	O
derivation	O
is	O
not	O
discussed	O
in	O
this	O
chapter	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
i	O
i	O
appendix	O
c	O
excursus	O
reinforcement	B
learning	I
dkriesel	O
com	O
old	O
state	B
value	O
and	O
the	O
received	O
return	B
is	O
the	O
learning	B
rate	I
thus	O
the	O
agent	B
gets	O
some	O
kind	O
of	O
memory	O
new	O
findings	O
always	O
change	O
the	O
situation	B
value	O
just	O
a	O
little	O
bit	O
an	O
exemplary	O
learning	O
step	O
is	O
shown	O
in	O
fig	O
in	O
this	O
example	O
the	O
computation	O
of	O
the	O
state	B
value	O
was	O
applied	O
for	O
only	O
one	O
single	O
state	B
initial	O
state	B
it	O
should	O
be	O
obvious	O
that	O
it	O
is	O
possible	O
often	O
done	O
to	O
train	O
the	O
values	O
for	O
the	O
states	O
visited	O
inbetween	O
case	O
of	O
the	O
gridworld	B
our	O
ways	O
to	O
the	O
target	B
at	O
the	O
same	O
time	O
the	O
result	O
of	O
such	O
a	O
calculation	O
related	O
to	O
our	O
example	O
is	O
illustrated	O
in	O
fig	O
on	O
the	O
facing	O
page	O
the	O
monte	B
carlo	I
method	I
seems	O
to	O
be	O
suboptimal	O
and	O
usually	O
it	O
is	O
significantly	O
slower	O
than	O
the	O
following	O
methods	O
of	O
reinforcement	B
learning	I
but	O
this	O
method	O
is	O
the	O
only	O
one	O
for	O
which	O
it	O
can	O
be	O
mathematically	O
proved	O
that	O
it	O
works	O
and	O
therefore	O
it	O
is	O
very	O
useful	O
for	O
theoretical	O
considerations	O
definition	O
carlo	O
learning	O
actions	O
are	O
randomly	O
performed	O
regardless	O
of	O
the	O
state-value	B
function	I
and	O
in	O
the	O
long	O
term	O
an	O
expressive	O
state-value	B
function	I
is	O
accumulated	O
by	O
means	O
of	O
the	O
following	O
learning	O
rule	O
v	O
v	O
v	O
temporal	B
difference	I
learning	I
most	O
of	O
the	O
learning	O
is	O
the	O
result	O
of	O
experiences	O
e	O
g	O
walking	O
or	O
riding	O
a	O
bicycle	O
figure	O
application	O
of	O
the	O
monte	O
carlo	O
learning	O
rule	O
with	O
a	O
learning	B
rate	I
of	O
top	O
two	O
exemplary	O
ways	O
the	O
agent	B
randomly	O
selects	O
are	O
applied	O
with	O
an	O
open	O
and	O
one	O
with	O
a	O
closed	O
door	O
bottom	O
the	O
result	O
of	O
the	O
learning	O
rule	O
for	O
the	O
value	O
of	O
the	O
initial	O
state	B
considering	O
both	O
ways	O
due	O
to	O
the	O
fact	O
that	O
in	O
the	O
course	O
of	O
time	O
many	O
different	O
ways	O
are	O
walked	O
given	O
a	O
random	O
policy	B
a	O
very	O
expressive	O
statevalue	O
function	O
is	O
obtained	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
learning	O
process	O
figure	O
extension	O
of	O
the	O
learning	O
example	O
in	O
fig	O
in	O
which	O
the	O
returns	O
for	O
intermediate	O
states	O
are	O
also	O
used	O
to	O
accumulate	O
the	O
statevalue	O
function	O
here	O
the	O
low	O
value	O
on	O
the	O
door	O
field	O
can	O
be	O
seen	O
very	O
well	O
if	O
this	O
state	B
is	O
possible	O
it	O
must	O
be	O
very	O
positive	O
if	O
the	O
door	O
is	O
closed	O
this	O
state	B
is	O
impossible	O
evaluation	B
q	O
policy	B
improvement	B
figure	O
we	O
try	O
different	O
actions	O
within	O
the	O
environment	B
and	O
as	O
a	O
result	O
we	O
learn	O
and	O
improve	O
the	O
policy	B
without	O
getting	O
injured	O
not	O
even	O
mental	O
skills	O
like	O
mathematical	O
problem	O
solving	O
benefit	O
a	O
lot	O
from	O
experience	O
and	O
simple	O
trial	O
and	O
error	O
thus	O
we	O
initialize	O
our	O
policy	B
with	O
arbitrary	O
values	O
we	O
try	O
learn	O
and	O
improve	O
the	O
policy	B
due	O
to	O
experience	O
in	O
contrast	O
to	O
the	O
monte	B
carlo	I
method	I
we	O
want	O
to	O
do	O
this	O
in	O
a	O
more	O
directed	O
manner	O
just	O
as	O
we	O
learn	O
from	O
experience	O
to	O
react	O
on	O
different	O
situations	O
in	O
different	O
ways	O
the	O
temporal	B
difference	I
learning	I
td	O
learning	O
does	O
the	O
same	O
by	O
training	O
v	O
the	O
agent	B
learns	O
to	O
estimate	O
which	O
situations	O
are	O
worth	O
a	O
lot	O
and	O
which	O
are	O
not	O
again	O
the	O
current	O
situation	B
is	O
identified	O
with	O
st	O
the	O
following	O
situations	O
with	O
and	O
so	O
on	O
thus	O
the	O
learning	O
formula	O
for	O
the	O
state-value	B
function	I
v	O
is	O
v	O
v	O
v	O
change	O
of	O
previous	O
value	O
we	O
can	O
see	O
that	O
the	O
change	O
in	O
value	O
of	O
the	O
current	O
situation	B
st	O
which	O
is	O
proportional	O
to	O
the	O
learning	B
rate	I
is	O
influenced	O
by	O
the	O
received	O
reward	B
the	O
previous	O
return	B
weighted	O
with	O
a	O
factor	O
of	O
the	O
following	O
situation	B
v	O
the	O
previous	O
value	O
of	O
the	O
situation	B
v	O
unlike	O
definition	O
difference	O
learning	O
the	O
monte	B
carlo	I
method	I
td	O
learning	O
looks	O
ahead	O
by	O
regarding	O
the	O
following	O
situation	B
thus	O
the	O
learning	O
rule	O
is	O
given	O
by	O
v	O
v	O
v	O
change	O
of	O
previous	O
value	O
the	O
action-value	B
function	I
analogous	O
v	O
to	O
the	O
state-value	B
function	I
the	O
action-value	B
function	I
action	B
evaluation	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
a	O
a	O
appendix	O
c	O
excursus	O
reinforcement	B
learning	I
dkriesel	O
com	O
q	B
learning	I
this	O
implies	O
q	O
a	O
as	O
learning	O
fomula	O
for	O
the	O
action-value	B
function	I
and	O
analogously	O
to	O
td	O
learning	O
its	O
application	O
is	O
called	O
q	B
learning	I
figure	O
exemplary	O
values	O
of	O
an	O
actionvalue	O
function	O
for	O
the	O
position	O
moving	O
right	O
one	O
remains	O
on	O
the	O
fastest	O
way	O
towards	O
the	O
target	B
moving	O
up	O
is	O
still	O
a	O
quite	O
fast	O
way	O
moving	O
down	O
is	O
not	O
a	O
good	O
way	O
at	O
all	O
that	O
the	O
door	O
is	O
open	O
for	O
all	O
cases	O
q	O
a	O
is	O
another	O
system	O
component	O
of	O
q	O
reinforcement	B
learning	I
which	O
evaluates	O
a	O
certain	O
action	B
a	O
under	O
a	O
certain	O
situation	B
s	O
and	O
the	O
policy	B
in	O
the	O
gridworld	B
in	O
the	O
gridworld	B
the	O
action-value	B
function	I
tells	O
us	O
how	O
good	O
it	O
is	O
to	O
move	O
from	O
a	O
certain	O
field	O
into	O
a	O
certain	O
direction	O
definition	O
function	O
like	O
the	O
state-value	B
function	I
the	O
actionvalue	O
function	O
q	O
a	O
evaluates	O
certain	O
actions	O
on	O
the	O
basis	B
of	O
certain	O
situations	O
under	O
a	O
policy	B
the	O
optimal	O
action-value	B
function	I
is	O
called	O
q	O
a	O
q	O
as	O
shown	O
in	O
fig	O
the	O
actions	O
are	O
performed	O
until	O
a	O
target	B
situation	B
referred	O
to	O
as	O
s	O
is	O
achieved	O
there	O
exists	O
a	O
target	B
situation	B
otherwise	O
the	O
actions	O
are	O
simply	O
performed	O
again	O
and	O
again	O
qst	O
anew	O
a	O
max	O
a	O
qst	O
a	O
a	O
greedy	B
strategy	O
change	O
of	O
previous	O
value	O
again	O
we	O
break	O
down	O
the	O
change	O
of	O
the	O
current	O
action	B
value	O
to	O
the	O
learning	B
rate	I
under	O
the	O
current	O
situation	B
it	O
is	O
influenced	O
by	O
the	O
received	O
reward	B
the	O
maximum	O
action	B
over	O
the	O
following	O
actions	O
weighted	O
with	O
a	O
greedy	B
strategy	O
is	O
applied	O
since	O
it	O
can	O
be	O
assumed	O
that	O
the	O
best	O
known	O
action	B
is	O
selected	O
with	O
td	O
learning	O
on	O
the	O
other	O
hand	O
we	O
do	O
not	O
mind	O
to	O
always	O
get	O
into	O
the	O
best	O
known	O
next	O
situation	B
the	O
previous	O
value	O
of	O
the	O
action	B
under	O
our	O
situation	B
st	O
known	O
as	O
qst	O
a	O
that	O
this	O
is	O
also	O
weighted	O
by	O
means	O
of	O
usually	O
the	O
action-value	B
function	I
learns	O
considerably	O
faster	O
than	O
the	O
state-value	B
function	I
but	O
we	O
must	O
not	O
disregard	O
that	O
reinforcement	B
learning	I
is	O
generally	O
quite	O
slow	O
the	O
system	O
has	O
to	O
find	O
out	O
itself	O
what	O
is	O
good	O
but	O
the	O
advantage	O
of	O
q	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
example	O
applications	O
gfed	O
gfed	O
direction	O
of	O
actions	O
gfed	O
a	O
r	O
direction	O
of	O
reward	B
s	O
onml	O
hijk	O
a	O
r	O
gfed	O
figure	O
actions	O
are	O
performed	O
until	O
the	O
desired	O
target	B
situation	B
is	O
achieved	O
attention	O
should	O
be	O
paid	O
to	O
numbering	O
rewards	O
are	O
numbered	O
beginning	O
with	O
actions	O
and	O
situations	O
beginning	O
with	O
has	O
simply	O
been	O
adopted	O
as	O
a	O
convention	O
qst	O
anew	O
a	O
max	O
a	O
a	O
qst	O
a	O
played	O
backgammon	O
knows	O
that	O
the	O
situation	B
space	I
is	O
huge	O
situations	O
as	O
a	O
result	O
the	O
state-value	O
functions	O
cannot	O
be	O
computed	O
explicitly	O
in	O
the	O
late	O
eighties	O
when	O
td	B
gammon	I
was	O
introduced	O
the	O
selected	O
rewarding	O
strategy	O
was	O
the	O
pure	B
delayed	I
reward	B
i	O
e	O
the	O
system	O
receives	O
the	O
reward	B
not	O
before	O
the	O
end	O
of	O
the	O
game	O
and	O
at	O
the	O
same	O
time	O
the	O
reward	B
is	O
the	O
return	B
then	O
the	O
system	O
was	O
allowed	O
to	O
practice	O
itself	O
against	O
a	O
backgammon	O
program	O
then	O
against	O
an	O
entity	O
of	O
itself	O
the	O
result	O
was	O
that	O
it	O
achieved	O
the	O
highest	O
ranking	O
in	O
a	O
computer-backgammon	O
league	O
and	O
strikingly	O
disproved	O
the	O
theory	O
that	O
a	O
computer	O
programm	O
is	O
not	O
capable	O
to	O
master	O
a	O
task	O
better	O
than	O
its	O
programmer	O
learning	O
is	O
can	O
be	O
initialized	O
arbitrarily	O
and	O
by	O
means	O
of	O
q	B
learning	I
the	O
result	O
is	O
always	O
q	O
definition	O
learning	O
q	B
learning	I
trains	O
the	O
action-value	B
function	I
by	O
means	O
of	O
the	O
learning	O
rule	O
and	O
thus	O
finds	O
q	O
in	O
any	O
case	O
example	O
applications	O
td	B
gammon	I
the	O
car	O
in	O
the	O
pit	O
td	B
gammon	I
is	O
a	O
very	O
successful	O
backgammon	O
game	O
based	O
on	O
td	O
learning	O
invented	O
by	O
gerald	O
tesauro	O
the	O
situation	B
here	O
is	O
the	O
current	O
configuration	O
of	O
the	O
board	O
anyone	O
who	O
has	O
ever	O
let	O
us	O
take	O
a	O
look	O
at	O
a	O
car	O
parking	O
on	O
a	O
one-dimensional	O
road	O
at	O
the	O
bottom	O
of	O
a	O
deep	O
pit	O
without	O
being	O
able	O
to	O
get	O
over	O
the	O
slope	O
on	O
both	O
sides	O
straight	O
away	O
by	O
means	O
of	O
its	O
engine	O
power	O
in	O
order	O
to	O
leave	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
k	O
k	O
k	O
k	O
k	O
k	O
l	O
l	O
h	O
h	O
appendix	O
c	O
excursus	O
reinforcement	B
learning	I
dkriesel	O
com	O
the	O
pit	O
trivially	O
the	O
executable	O
actions	O
here	O
are	O
the	O
possibilities	O
to	O
drive	O
forwards	O
and	O
backwards	O
the	O
intuitive	O
solution	O
we	O
think	O
of	O
immediately	O
is	O
to	O
move	O
backwards	O
to	O
gain	O
momentum	B
at	O
the	O
opposite	O
slope	O
and	O
oscillate	O
in	O
this	O
way	O
several	O
times	O
to	O
dash	O
out	O
of	O
the	O
pit	O
the	O
actions	O
of	O
a	O
reinforcement	B
learning	I
system	O
would	O
be	O
throttle	O
forward	O
reverse	O
and	O
nothing	O
here	O
costs	O
would	O
be	O
a	O
good	O
choice	O
for	O
awarding	O
the	O
reward	B
so	O
that	O
the	O
system	O
learns	O
fast	O
how	O
to	O
leave	O
the	O
pit	O
and	O
realizes	O
that	O
our	O
problem	O
cannot	O
be	O
solved	O
by	O
means	O
of	O
mere	O
forward	O
directed	O
engine	O
power	O
so	O
the	O
system	O
will	O
slowly	O
build	O
up	O
the	O
movement	O
the	O
policy	B
can	O
no	O
longer	O
be	O
stored	O
as	O
a	O
table	O
since	O
the	O
state	B
space	O
is	O
hard	O
to	O
discretize	O
as	O
policy	B
a	O
function	O
has	O
to	O
be	O
generated	O
the	O
pole	B
balancer	I
the	O
pole	B
balancer	I
was	O
developed	O
by	O
barto	O
sutton	O
and	O
anderson	O
let	O
be	O
given	O
a	O
situation	B
including	O
a	O
vehicle	O
that	O
is	O
capable	O
to	O
move	O
either	O
to	O
the	O
right	O
at	O
full	O
throttle	O
or	O
to	O
the	O
left	O
at	O
full	O
throttle	O
bang	O
control	O
only	O
these	O
two	O
actions	O
can	O
be	O
performed	O
standing	O
still	O
is	O
impossible	O
on	O
the	O
top	O
of	O
this	O
car	O
is	O
hinged	O
an	O
upright	O
pole	O
that	O
could	O
tip	O
over	O
to	O
both	O
sides	O
the	O
pole	O
is	O
built	O
in	O
such	O
a	O
way	O
that	O
it	O
always	O
tips	O
over	O
to	O
one	O
side	O
so	O
it	O
never	O
stands	O
still	O
us	O
assume	O
that	O
the	O
pole	O
is	O
rounded	O
at	O
the	O
lower	O
end	O
the	O
angle	O
of	O
the	O
pole	O
relative	O
to	O
the	O
vertical	O
line	O
is	O
referred	O
to	O
as	O
furthermore	O
the	O
vehicle	O
always	O
has	O
a	O
fixed	O
position	O
x	O
an	O
our	O
one-dimensional	O
world	O
and	O
a	O
velocity	O
of	O
x	O
our	O
one-dimensional	O
world	O
is	O
limited	O
i	O
e	O
there	O
are	O
maximum	O
values	O
and	O
minimum	O
values	O
x	O
can	O
adopt	O
the	O
aim	O
of	O
our	O
system	O
is	O
to	O
learn	O
to	O
steer	O
the	O
car	O
in	O
such	O
a	O
way	O
that	O
it	O
can	O
balance	O
the	O
pole	O
to	O
prevent	O
the	O
pole	O
from	O
tipping	O
over	O
this	O
is	O
achieved	O
best	O
by	O
an	O
avoidance	B
strategy	I
as	O
long	O
as	O
the	O
pole	O
is	O
balanced	O
the	O
reward	B
is	O
if	O
the	O
pole	O
tips	O
over	O
the	O
reward	B
is	O
interestingly	O
the	O
system	O
is	O
soon	O
capable	O
to	O
keep	O
the	O
pole	O
balanced	O
by	O
tilting	O
it	O
sufficiently	O
fast	O
and	O
with	O
small	O
movements	O
at	O
this	O
the	O
system	O
mostly	O
is	O
in	O
the	O
center	O
of	O
the	O
space	O
since	O
this	O
is	O
farthest	O
from	O
the	O
walls	O
which	O
it	O
understands	O
as	O
negative	O
it	O
touches	O
the	O
wall	O
the	O
pole	O
will	O
tip	O
over	O
swinging	O
up	O
an	O
inverted	O
pendulum	O
more	O
difficult	O
for	O
the	O
system	O
is	O
the	O
following	O
initial	O
situation	B
the	O
pole	O
initially	O
hangs	O
down	O
has	O
to	O
be	O
swung	O
up	O
over	O
the	O
vehicle	O
and	O
finally	O
has	O
to	O
be	O
stabilized	O
in	O
the	O
literature	O
this	O
task	O
is	O
called	O
swing	B
up	I
an	I
inverted	I
pendulum	I
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
reinforcement	B
learning	I
in	O
connection	B
with	O
neural	O
networks	O
ment	O
learning	O
to	O
find	O
a	O
strategy	O
in	O
order	O
to	O
exit	O
a	O
maze	O
as	O
fast	O
as	O
possible	O
what	O
could	O
an	O
appropriate	O
state	B
value	O
function	O
look	O
like	O
how	O
would	O
you	O
generate	O
an	O
appropri	O
ate	O
reward	B
assume	O
that	O
the	O
robot	O
is	O
capable	O
to	O
avoid	O
obstacles	O
and	O
at	O
any	O
time	O
knows	O
its	O
position	O
y	O
and	O
orientation	O
exercise	O
describe	O
the	O
function	O
of	O
the	O
two	O
components	O
ase	O
and	O
ace	O
as	O
they	O
have	O
been	O
proposed	O
by	O
barto	O
sutton	O
and	O
anderson	O
to	O
control	O
the	O
pole	B
balancer	I
bibliography	O
exercise	O
indicate	O
several	O
problems	B
of	O
informatics	O
which	O
could	O
be	O
solved	O
efficiently	O
by	O
means	O
of	O
reinforcement	B
learning	I
please	O
give	O
reasons	O
for	O
your	O
answers	O
reinforcement	B
learning	I
in	O
connection	B
with	O
neural	O
networks	O
finally	O
the	O
reader	O
would	O
like	O
to	O
ask	O
why	O
a	O
text	O
on	O
networks	O
includes	O
a	O
chapter	O
about	O
reinforcement	B
learning	I
the	O
answer	O
is	O
very	O
simple	O
we	O
have	O
already	O
been	O
introduced	O
to	O
supervised	B
and	O
unsupervised	B
learning	O
procedures	O
although	O
we	O
do	O
not	O
always	O
have	O
an	O
omniscient	O
teacher	O
who	O
makes	O
unsupervised	B
learning	O
possible	O
this	O
does	O
not	O
mean	O
that	O
we	O
do	O
not	O
receive	O
any	O
feedback	O
at	O
all	O
there	O
is	O
often	O
something	O
in	O
between	O
some	O
kind	O
of	O
criticism	O
or	O
school	O
mark	O
problems	B
like	O
this	O
can	O
be	O
solved	O
by	O
means	O
of	O
reinforcement	B
learning	I
but	O
not	O
every	O
problem	O
is	O
that	O
easily	O
solved	O
like	O
our	O
gridworld	B
in	O
our	O
backgammon	O
example	O
we	O
have	O
approx	O
situations	O
and	O
the	O
situation	B
tree	B
has	O
a	O
large	O
branching	O
factor	O
let	O
alone	O
other	O
games	O
here	O
the	O
tables	O
used	O
in	O
the	O
gridworld	B
can	O
no	O
longer	O
be	O
realized	O
as	O
state-	O
and	O
action-value	O
functions	O
thus	O
we	O
have	O
to	O
find	O
approximators	O
for	O
these	O
functions	O
and	O
which	O
learning	O
approximators	O
for	O
these	O
reinforcement	B
learning	I
components	O
come	O
immediately	O
into	O
our	O
mind	O
exactly	O
neural	O
networks	O
exercises	O
exercise	O
a	O
robot	O
control	O
system	O
shall	O
be	O
persuaded	O
by	O
means	O
of	O
reinforce	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
bibliography	O
james	O
a	O
anderson	O
a	O
simple	O
neural	B
network	I
generating	O
an	O
interactive	O
memory	O
mathematical	O
biosciences	O
d	O
anguita	B
g	O
parodi	O
and	O
r	O
zunino	O
speed	O
improvement	B
of	O
the	O
backpropagation	B
on	O
current-generation	O
workstations	O
in	O
wcnn	O
portland	O
world	O
congress	O
on	O
neural	O
networks	O
july	O
oregon	O
convention	O
center	O
portland	O
oregon	O
volume	O
lawrence	O
erlbaum	O
a	O
barto	O
r	O
sutton	O
and	O
c	O
anderson	O
neuron-like	O
adaptive	O
elements	O
that	O
can	O
solve	O
difficult	O
learning	O
control	O
problems	B
ieee	O
transactions	O
on	O
systems	O
man	O
and	O
cybernetics	O
september	O
g	O
a	O
carpenter	O
and	O
s	O
grossberg	O
self-organization	O
of	O
stable	O
category	O
recognition	O
codes	O
for	O
analog	O
input	B
patterns	I
applied	O
optics	O
m	O
a	O
cohen	O
and	O
s	O
grossberg	O
absolute	O
stability	O
of	O
global	O
pattern	O
formation	O
and	O
parallel	O
memory	O
storage	O
by	O
competitive	O
neural	O
networks	O
computer	O
society	O
press	O
technology	O
series	O
neural	O
networks	O
pages	O
g	O
a	O
carpenter	O
and	O
s	O
grossberg	O
art	O
hierarchical	O
search	O
using	O
chemical	B
transmitters	O
in	O
self-organising	O
pattern	B
recognition	I
architectures	O
neural	O
networks	O
t	O
cover	O
and	O
p	O
hart	O
nearest	O
neighbor	O
pattern	O
classification	O
transactions	O
on	O
information	O
theory	O
n	O
a	O
campbell	O
and	O
jb	O
reece	O
biologie	O
spektrum	O
akademischer	O
verlag	O
g	O
cybenko	O
approximation	B
by	O
superpositions	O
of	O
a	O
sigmoidal	O
function	O
mathematics	O
of	O
control	O
signals	O
and	O
systems	O
r	O
o	O
duda	O
p	O
e	O
hart	O
and	O
d	O
g	O
stork	O
pattern	O
classification	O
wiley	O
new	O
york	O
ieee	O
bibliography	O
dkriesel	O
com	O
jeffrey	O
l	O
elman	B
finding	O
structure	O
in	O
time	O
cognitive	O
science	O
april	O
s	O
e	O
fahlman	O
an	O
empirical	O
sudy	O
of	O
learning	O
speed	O
in	O
back-propagation	O
networks	O
technical	O
report	O
cmu	O
k	O
fukushima	B
s	O
miyake	B
and	O
t	O
ito	B
neocognitron	B
a	O
neural	B
network	I
model	O
for	O
a	O
mechanism	O
of	O
visual	B
pattern	B
recognition	I
ieee	O
transactions	O
on	O
systems	O
man	O
and	O
cybernetics	O
septemberoctober	O
b	O
fritzke	O
fast	O
learning	O
with	O
incremental	O
rbf	B
networks	O
neural	O
processing	O
letters	O
n	O
goerke	O
f	O
kintzler	O
and	O
r	O
eckmiller	O
self	O
organized	O
classification	O
of	O
chaotic	O
domains	O
from	O
a	O
nonlinearattractor	O
in	O
neural	O
networks	O
proceedings	O
ijcnn	O
international	O
joint	O
conference	O
on	O
volume	O
n	O
goerke	O
f	O
kintzler	O
and	O
r	O
eckmiller	O
self	O
organized	O
partitioning	O
of	O
chaotic	O
attractors	O
for	O
control	O
lecture	O
notes	O
in	O
computer	O
science	O
pages	O
s	O
grossberg	O
adaptive	O
pattern	O
classification	O
and	O
universal	B
recoding	O
i	O
parallel	O
development	O
and	O
coding	O
of	O
neural	O
feature	O
detectors	O
biological	O
cybernetics	O
nils	O
goerke	O
and	O
alexandra	O
scherbart	O
classification	O
using	O
multi-soms	O
and	O
multi-neural	O
gas	O
in	O
ijcnn	O
pages	O
donald	O
o	O
hebb	O
the	O
organization	O
of	O
behavior	O
a	O
neuropsychological	O
theory	O
wiley	O
new	O
york	O
john	O
j	O
hopfield	O
neural	O
networks	O
and	O
physical	O
systems	O
with	O
emergent	O
collective	O
computational	O
abilities	O
proc	O
of	O
the	O
national	O
academy	O
of	O
science	O
usa	O
jj	O
hopfield	O
neurons	O
with	O
graded	O
response	O
have	O
collective	O
computational	O
properties	O
like	O
those	O
of	O
two-state	O
neurons	O
proceedings	O
of	O
the	O
national	O
academy	O
of	O
sciences	O
jj	O
hopfield	O
and	O
dw	O
tank	O
neural	O
computation	O
of	O
decisions	O
in	O
optimization	O
problems	B
biological	O
cybernetics	O
m	O
i	O
jordan	B
attractor	B
dynamics	O
and	O
parallelism	B
in	O
a	O
connectionist	O
sequential	O
machine	O
in	O
proceedings	O
of	O
the	O
eighth	O
conference	O
of	O
the	O
cognitive	O
science	O
society	O
pages	O
erlbaum	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
bibliography	O
l	O
kaufman	O
finding	O
groups	O
in	O
data	O
an	O
introduction	O
to	O
cluster	B
analysis	I
in	O
finding	O
groups	O
in	O
data	O
an	O
introduction	O
to	O
cluster	B
analysis	I
wiley	O
new	O
york	O
t	O
kohonen	O
correlation	O
matrix	O
memories	O
ieeetc	O
teuvo	O
kohonen	O
self-organized	O
formation	O
of	O
topologically	O
correct	O
feature	O
maps	O
biological	O
cybernetics	O
teuvo	O
kohonen	O
self-organization	O
and	O
associative	O
memory	O
springerverlag	O
berlin	O
third	O
edition	O
t	O
kohonen	O
the	O
self-organizing	B
map	I
neurocomputing	O
e	O
r	O
kandel	O
j	O
h	O
schwartz	O
and	O
t	O
m	O
jessell	O
principles	O
of	O
neural	O
science	O
appleton	O
lange	O
y	O
le	O
cun	O
j	O
s	O
denker	O
and	O
s	O
a	O
solla	O
optimal	B
brain	B
damage	I
in	O
d	O
touretzky	O
editor	O
advances	O
in	O
neural	O
information	B
processing	I
systems	O
pages	O
morgan	O
kaufmann	O
j	O
macqueen	O
some	O
methods	O
for	O
classification	O
and	O
analysis	O
of	O
multivariate	O
observations	O
in	O
proceedings	O
of	O
the	O
fifth	O
berkeley	O
symposium	O
on	O
mathematics	O
statistics	O
and	O
probability	O
vol	O
pages	O
thomas	O
m	O
martinetz	O
stanislav	O
g	O
berkovich	O
and	O
klaus	O
j	O
schulten	O
neural-gas	O
network	O
for	O
vector	O
quantization	B
and	O
its	O
application	O
to	O
timeseries	O
prediction	O
ieee	O
trans	O
on	O
neural	O
networks	O
k	O
d	O
micheva	O
b	O
busse	O
n	O
c	O
weiler	O
n	O
o	O
rourke	O
and	O
s	O
j	O
smith	O
singlesynapse	O
analysis	O
of	O
a	O
diverse	O
synapse	O
population	O
proteomic	O
imaging	O
methods	O
and	O
markers	O
neuron	B
w	O
s	O
mcculloch	O
and	O
w	O
pitts	O
a	O
logical	O
calculus	O
of	O
the	O
ideas	O
immanent	O
in	O
nervous	O
activity	O
bulletin	O
of	O
mathematical	O
biology	O
m	O
minsky	O
and	O
s	O
papert	O
perceptrons	O
mit	O
press	O
cambridge	O
mass	O
j	O
l	O
mcclelland	O
and	O
d	O
e	O
rumelhart	B
parallel	O
distributed	O
processing	O
explorations	O
in	O
the	O
microstructure	O
of	O
cognition	O
volume	O
mit	O
press	O
cambridge	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
bibliography	O
dkriesel	O
com	O
david	O
r	O
parker	O
optimal	O
algorithms	O
for	O
adaptive	O
networks	O
second	B
order	I
back	O
propagation	O
second	B
order	I
direct	B
propagation	O
and	O
second	B
order	I
hebbian	O
learning	O
in	O
maureen	O
caudill	O
and	O
charles	O
butler	O
editors	O
ieee	O
first	O
international	O
conference	O
on	O
neural	O
networks	O
volume	O
ii	O
pages	O
ii	O
ii	O
san	O
diego	O
ca	O
june	O
ieee	O
t	O
poggio	B
and	O
f	O
girosi	B
a	O
theory	O
of	O
networks	O
for	O
approximation	B
and	O
learning	O
mit	O
press	O
cambridge	O
mass	O
f	O
j	O
pineda	O
generalization	B
of	O
back-propagation	O
to	O
recurrent	B
neural	O
networks	O
physical	O
review	O
letters	O
w	O
pitts	O
and	O
w	O
s	O
mcculloch	O
how	O
we	O
know	O
universals	O
the	O
perception	O
of	O
auditory	O
and	O
visual	B
forms	O
bulletin	O
of	O
mathematical	O
biology	O
l	O
prechelt	O
a	O
set	B
of	I
neural	B
network	I
benchmark	O
problems	B
and	O
benchmarking	O
rules	O
technical	O
report	O
m	O
riedmiller	O
and	O
h	O
braun	O
a	O
direct	B
adaptive	O
method	O
for	O
faster	O
backpropagation	B
learning	O
the	O
rprop	O
algorithm	B
in	O
neural	O
networks	O
ieee	O
international	O
conference	O
on	O
pages	O
ieee	O
g	O
roth	O
and	O
u	O
dicke	O
evolution	O
of	O
the	O
brain	B
and	O
intelligence	O
trends	O
in	O
cognitive	O
sciences	O
d	O
rumelhart	B
g	O
hinton	B
and	O
r	O
williams	B
learning	O
representations	O
by	O
back-propagating	O
errors	O
nature	O
october	O
david	O
e	O
rumelhart	B
geoffrey	O
e	O
hinton	B
and	O
r	O
j	O
williams	B
learning	O
internal	O
representations	O
by	O
error	O
propagation	O
in	O
d	O
e	O
rumelhart	B
j	O
l	O
mcclelland	O
and	O
the	O
pdp	O
research	O
group	O
editors	O
parallel	O
distributed	O
processing	O
explorations	O
in	O
the	O
microstructure	O
of	O
cognition	O
volume	O
foundations	O
mit	O
press	O
m	O
riedmiller	O
rprop	O
description	O
and	O
implementation	O
details	O
technical	O
report	O
university	O
of	O
karlsruhe	O
f	O
rosenblatt	O
the	O
perceptron	B
a	O
probabilistic	O
model	O
for	O
information	O
storage	O
and	O
organization	O
in	O
the	O
brain	B
psychological	O
review	O
f	O
rosenblatt	O
principles	O
of	O
neurodynamics	O
spartan	O
new	O
york	O
r	O
s	O
sutton	O
and	O
a	O
g	O
barto	O
reinforcement	B
learning	I
an	O
introduction	O
mit	O
press	O
cambridge	O
ma	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
bibliography	O
a	O
scherbart	O
and	O
n	O
goerke	O
unsupervised	B
system	O
for	O
discovering	O
patterns	O
in	O
time-series	O
rolf	B
schatten	O
nils	O
goerke	O
and	O
rolf	B
eckmiller	O
regional	B
and	I
online	B
learnable	I
fields	I
in	O
sameer	O
singh	O
maneesha	O
singh	O
chidanand	O
apt	O
and	O
petra	O
perner	O
editors	O
icapr	O
volume	O
of	O
lecture	O
notes	O
in	O
computer	O
science	O
pages	O
springer	O
k	O
steinbuch	O
die	O
lernmatrix	O
kybernetik	O
cybernetics	O
c	O
von	O
der	O
malsburg	O
self-organizing	O
of	O
orientation	O
sensitive	O
cells	O
in	O
striate	O
cortex	O
kybernetik	O
p	O
d	O
wasserman	O
neural	O
computing	O
theory	O
and	O
practice	O
new	O
york	O
van	O
nostrand	O
reinhold	O
p	O
j	O
werbos	O
beyond	O
regression	O
new	O
tools	O
for	O
prediction	O
and	O
analysis	O
in	O
the	O
behavioral	O
sciences	O
phd	O
thesis	O
harvard	O
university	O
p	O
j	O
werbos	O
backpropagation	B
past	O
and	O
future	O
in	O
proceedings	O
san	O
diego	O
pages	O
a	O
s	O
weigend	O
and	O
n	O
a	O
gershenfeld	O
time	B
series	I
prediction	I
addisonwesley	O
b	O
widrow	O
and	O
m	O
e	O
hoff	O
adaptive	O
switching	O
circuits	O
in	O
proceedings	O
wescon	O
pages	O
r	O
widner	O
single-stage	O
logic	O
aiee	O
fall	O
general	O
meeting	O
wasserman	O
p	O
neural	O
computing	O
theory	O
and	O
practice	O
van	O
nostrand	O
reinhold	O
andreas	O
zell	O
simulation	O
neuronaler	O
netze	O
addison-wesley	O
german	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
list	O
of	O
figures	O
robot	O
with	O
sensors	O
and	O
motors	O
black	B
box	I
with	O
eight	O
inputs	O
and	O
two	O
outputs	O
learning	O
samples	O
for	O
the	O
example	O
robot	O
institutions	O
of	O
the	O
field	O
of	O
neural	O
networks	O
central	B
nervous	B
system	I
brain	B
biological	O
neuron	B
action	B
potential	I
compound	B
eye	I
data	O
processing	O
of	O
a	O
neuron	B
various	O
popular	O
activation	B
functions	O
feedforward	B
network	O
feedforward	B
network	O
with	O
shortcuts	O
directly	O
recurrent	B
network	O
indirectly	O
recurrent	B
network	O
laterally	O
recurrent	B
network	O
completely	O
linked	O
network	O
examples	O
for	O
different	O
types	O
of	O
neurons	O
example	O
network	O
with	O
and	O
without	O
bias	B
neuron	B
training	O
samples	O
and	O
network	O
capacities	O
learning	O
curve	O
with	O
different	O
scalings	O
gradient	B
descent	I
visualization	O
possible	O
errors	O
during	O
a	O
gradient	B
descent	I
the	O
problem	O
checkerboard	O
problem	O
the	O
perceptron	B
in	O
three	O
different	O
views	O
singlelayer	B
perceptron	B
singlelayer	B
perceptron	B
with	O
several	O
output	B
neurons	O
and	O
and	O
or	O
singlelayer	B
perceptron	B
list	O
of	O
figures	O
dkriesel	O
com	O
error	O
surface	O
of	O
a	O
network	O
with	O
connections	O
sketch	O
of	O
a	O
xor-slp	O
two-dimensional	O
linear	O
separation	O
three-dimensional	O
linear	O
separation	O
the	O
xor	O
network	O
multilayer	B
perceptrons	O
and	O
output	B
sets	O
position	O
of	O
an	O
inner	O
neuron	B
for	O
derivation	O
of	O
backpropagation	B
illustration	O
of	O
the	O
backpropagation	B
derivation	O
momentum	B
term	I
fermi	B
function	I
and	O
hyperbolic	B
tangent	I
functionality	O
of	O
encoding	O
rbf	B
network	I
distance	O
function	O
in	O
the	O
rbf	B
network	I
individual	O
gaussian	O
bells	O
in	O
one-	O
and	O
two-dimensional	O
space	O
accumulating	O
gaussian	O
bells	O
in	O
one-dimensional	O
space	O
accumulating	O
gaussian	O
bells	O
in	O
two-dimensional	O
space	O
even	O
coverage	O
of	O
an	O
input	B
space	O
with	O
radial	O
basis	B
functions	O
uneven	O
coverage	O
of	O
an	O
input	B
space	O
with	O
radial	O
basis	B
functions	O
random	O
uneven	O
coverage	O
of	O
an	O
input	B
space	O
with	O
radial	O
basis	B
functions	O
roessler	O
attractor	B
jordan	B
network	I
elman	B
network	I
unfolding	B
in	I
time	I
hopfield	O
network	O
binary	B
threshold	I
function	I
convergence	O
of	O
a	O
hopfield	O
network	O
fermi	B
function	I
examples	O
for	O
quantization	B
example	O
topologies	O
of	O
a	O
som	O
example	O
distances	O
of	O
som	O
topologies	O
som	O
topology	B
functions	O
first	O
example	O
of	O
a	O
som	O
topological	B
defect	I
of	O
a	O
som	O
training	O
a	O
som	O
with	O
one-dimensional	O
topology	B
soms	O
with	O
one-	O
and	O
two-dimensional	O
topologies	O
and	O
different	O
input	B
resolution	O
optimization	O
of	O
a	O
som	O
to	O
certain	O
areas	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
list	O
of	O
figures	O
shape	O
to	O
be	O
classified	O
by	O
neural	B
gas	I
structure	O
of	O
an	O
art	O
network	O
learning	O
process	O
of	O
an	O
art	O
network	O
comparing	O
cluster	B
analysis	I
methods	O
rolf	B
neuron	B
clustering	O
by	O
means	O
of	O
a	O
rolf	B
neural	B
network	I
reading	O
time	B
series	I
one-step-ahead	B
prediction	I
two-step-ahead	B
prediction	I
direct	B
two-step-ahead	B
prediction	I
heterogeneous	B
one-step-ahead	B
prediction	I
heterogeneous	B
one-step-ahead	B
prediction	I
with	O
two	O
outputs	O
gridworld	B
reinforcement	B
learning	I
gridworld	B
with	O
optimal	O
returns	O
reinforcement	B
learning	I
cycle	O
the	O
monte	B
carlo	I
method	I
extended	O
monte	B
carlo	I
method	I
improving	O
the	O
policy	B
action-value	B
function	I
reinforcement	B
learning	I
timeline	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
index	O
rule	O
atp	B
attractor	B
autoassociator	B
axon	B
a	O
action	B
action	B
potential	I
action	B
space	I
action-value	B
function	I
activation	B
activation	B
function	I
selection	B
of	I
adaline	O
see	O
adaptive	B
linear	I
neuron	B
adaptive	O
linear	O
element	O
see	O
adaptive	B
linear	I
neuron	B
adaptive	B
linear	I
neuron	B
adaptive	B
resonance	B
theory	I
agent	B
algorithm	B
amacrine	B
cell	I
approximation	B
art	O
see	O
adaptive	B
resonance	B
theory	I
artificial	B
intelligence	I
associative	B
data	I
storage	I
b	O
backpropagation	B
second	B
order	I
backpropagation	B
of	I
error	I
recurrent	B
bar	B
basis	B
bias	B
neuron	B
binary	B
threshold	I
function	I
bipolar	B
cell	I
black	B
box	I
brain	B
brainstem	B
c	O
capability	B
to	I
learn	I
center	O
of	B
a	I
rolf	B
neuron	B
of	B
a	I
som	I
neuron	B
index	O
dkriesel	O
com	O
of	B
an	I
rbf	B
neuron	B
distance	B
to	I
the	I
central	B
nervous	B
system	I
cerebellum	B
cerebral	B
cortex	I
cerebrum	B
change	B
in	I
weight	B
cluster	B
analysis	I
clusters	B
cns	O
see	O
central	B
nervous	B
system	I
codebook	B
vector	I
complete	B
linkage	I
compound	B
eye	I
concentration	B
gradient	B
cone	B
function	I
connection	B
context-based	B
search	I
continuous	B
cortex	O
see	O
cerebral	B
cortex	I
visual	B
cortical	B
field	I
association	B
primary	B
cylinder	B
function	I
d	O
dartmouth	O
summer	O
research	O
deep	B
networks	I
delta	B
delta	B
rule	I
dendrite	B
tree	B
depolarization	B
diencephalon	O
see	O
interbrain	B
difference	O
vector	O
see	O
error	B
vector	I
digital	B
filter	I
digitization	B
discrete	B
discretization	O
see	O
quantization	B
distance	O
euclidean	B
squared	B
dynamical	B
system	I
e	O
early	B
stopping	I
electronic	B
brain	B
elman	B
network	I
environment	B
episode	B
epoch	B
epsilon-nearest	B
neighboring	I
error	O
specific	B
total	B
error	B
function	I
specific	B
error	B
vector	I
evolutionary	B
algorithms	I
exploitation	B
approach	I
exploration	B
approach	I
exteroceptor	B
f	O
fastprop	B
fault	B
tolerance	I
feedforward	B
fermi	B
function	I
flat	O
spot	O
elimination	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
index	O
fudging	O
see	O
flat	O
spot	O
elimination	O
function	B
approximation	B
function	O
approximator	O
universal	B
g	O
ganglion	B
cell	I
gauss-markov	B
model	I
gaussian	B
bell	I
generalization	B
glial	B
cell	I
gradient	B
gradient	B
descent	I
problems	B
grid	B
gridworld	B
h	O
heaviside	O
function	O
see	O
binary	B
threshold	I
function	I
hebbian	B
rule	I
generalized	B
form	I
heteroassociator	B
hinton	B
diagram	I
history	B
of	I
development	I
hopfield	B
networks	I
continuous	B
horizontal	B
cell	I
hyperbolic	B
tangent	I
hyperpolarization	B
hypothalamus	B
i	O
individual	O
eye	O
see	O
ommatidium	O
input	B
dimension	I
input	B
patterns	I
input	B
vector	I
interbrain	B
internodes	B
interoceptor	B
interpolation	O
precise	B
ion	B
iris	B
j	O
jordan	B
network	I
k	O
k-means	B
clustering	I
k-nearest	B
neighboring	I
l	O
layer	O
hidden	B
input	B
output	B
learnability	B
learning	O
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
index	O
dkriesel	O
com	O
batch	O
learning	O
o	O
ine	O
o	O
ine	O
online	B
reinforcement	B
supervised	B
unsupervised	B
learning	B
rate	I
variable	B
learning	B
strategy	I
learning	B
vector	I
quantization	B
lens	B
linear	B
separability	I
linearer	B
associator	I
locked-in	B
syndrome	I
logistic	O
function	O
see	O
fermi	B
function	I
temperature	B
parameter	I
lvq	O
see	O
learning	B
vector	I
quantization	B
m	O
m-som	O
see	O
self-organizing	B
map	I
multi	O
mark	B
i	I
perceptron	B
mathematical	O
symbols	O
see	O
time	B
concept	I
as	O
see	O
action	B
space	I
ep	O
see	O
error	B
vector	I
g	O
see	O
topology	B
n	O
see	O
self-organizing	B
map	I
input	B
dimension	I
p	O
see	O
training	B
set	I
q	O
a	O
see	O
action-value	B
function	I
q	O
a	O
see	O
action-value	B
function	I
rt	O
see	O
return	B
optimal	O
optimal	O
s	O
see	O
situation	B
space	I
t	O
see	O
temperature	B
parameter	I
v	O
see	O
state-value	B
function	I
v	O
see	O
state-value	B
function	I
w	O
see	O
weight	B
matrix	I
wij	O
see	O
change	B
in	I
weight	B
see	O
policy	B
threshold	B
value	I
see	O
momentum	B
see	O
weight	B
decay	O
see	O
delta	B
learning	B
rate	I
see	O
rprop	O
see	O
rprop	O
max	O
rprop	O
min	O
see	O
rprop	O
ij	O
see	O
rprop	O
see	O
nabla	B
operator	I
see	O
radius	O
multiplier	O
err	O
see	O
error	O
total	B
errw	O
see	O
error	B
function	I
errp	O
see	O
error	O
specific	B
errpwsee	O
error	B
function	I
specific	B
errwd	O
see	O
weight	B
decay	O
at	O
see	O
action	B
c	O
center	O
of	B
an	I
rbf	B
neuron	B
see	O
neuron	B
self-organizing	B
map	I
center	O
m	O
see	O
output	B
dimension	I
n	O
see	O
input	B
dimension	I
p	O
see	O
training	B
pattern	I
rh	O
see	O
center	O
of	B
an	I
rbf	B
neuron	B
distance	B
to	I
the	I
rt	O
see	O
reward	B
st	O
see	O
situation	B
t	O
see	O
teaching	B
input	B
wij	O
see	O
weight	B
x	O
see	O
input	B
vector	I
y	O
see	O
output	B
vector	I
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
index	O
fact	O
see	O
activation	B
function	I
fout	O
see	O
output	B
function	I
membrane	B
memorized	B
metric	B
mexican	B
hat	I
function	I
mlp	O
perceptron	B
multilayer	B
momentum	B
momentum	B
term	I
monte	B
carlo	I
method	I
moore-penrose	B
pseudo	I
inverse	I
moving	B
average	I
procedure	I
myelin	B
sheath	I
n	O
nabla	B
operator	I
neocognitron	B
nervous	B
system	I
network	B
input	B
neural	B
gas	I
growing	B
multi-	B
neural	B
network	I
recurrent	B
neuron	B
accepting	B
binary	B
context	B
fermi	B
identity	B
information	B
processing	I
input	B
rbf	B
output	B
rolf	B
self-organizing	B
map	I
tanh	B
winner	B
neuron	B
layers	O
layer	O
neurotransmitters	B
nodes	B
of	I
ranvier	I
o	O
oligodendrocytes	B
olvq	B
on-neuron	O
see	O
bias	B
neuron	B
one-step-ahead	B
prediction	I
heterogeneous	B
open	B
loop	I
learning	I
optimal	B
brain	B
damage	I
order	B
of	I
activation	B
asynchronous	O
fixed	O
order	O
random	B
order	I
randomly	B
permuted	I
order	I
topological	B
order	I
synchronous	B
output	B
dimension	I
output	B
function	I
output	B
vector	I
p	O
parallelism	B
pattern	O
see	O
training	B
pattern	I
pattern	B
recognition	I
perceptron	B
multilayer	B
recurrent	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
index	O
dkriesel	O
com	O
singlelayer	B
perceptron	B
convergence	I
theorem	I
perceptron	B
learning	I
algorithm	B
period	B
peripheral	B
nervous	B
system	I
persons	O
anderson	O
f	O
anderson	O
james	O
a	O
anguita	B
barto	O
f	O
carpenter	O
gail	O
elman	B
fukushima	B
girosi	B
grossberg	O
stephen	O
hebb	O
donald	O
o	O
hinton	B
hoff	O
marcian	O
e	O
hopfield	O
john	O
f	O
ito	B
jordan	B
kohonen	O
teuvo	O
lashley	O
karl	O
macqueen	O
j	O
martinetz	O
thomas	O
mcculloch	O
warren	O
f	O
minsky	O
marvin	O
f	O
miyake	B
nilsson	O
nils	O
papert	O
seymour	O
parker	O
david	O
pitts	O
walter	O
f	O
poggio	B
pythagoras	B
riedmiller	O
martin	O
rosenblatt	O
frank	O
rumelhart	B
steinbuch	O
karl	O
sutton	O
f	O
tesauro	O
gerald	O
von	O
der	O
malsburg	O
christoph	O
werbos	O
paul	O
widrow	O
bernard	O
wightman	O
charles	O
williams	B
zuse	O
konrad	O
pinhole	B
eye	I
pns	O
see	O
peripheral	B
nervous	B
system	I
pole	B
balancer	I
policy	B
closed	B
loop	I
evaluation	B
greedy	B
improvement	B
open	B
loop	I
pons	B
propagation	B
function	I
pruning	B
pupil	B
q	O
q	B
learning	I
quantization	B
quickpropagation	B
r	O
rbf	B
network	I
growing	B
receptive	B
field	I
receptor	B
cell	I
photo-	B
primary	B
secondary	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
dkriesel	O
com	O
index	O
recurrence	B
direct	B
indirect	B
lateral	B
refractory	B
period	B
regional	B
and	I
online	B
learnable	I
fields	I
reinforcement	B
learning	I
repolarization	B
representability	B
resilient	B
backpropagation	B
resonance	B
retina	B
return	B
reward	B
avoidance	B
strategy	I
pure	B
delayed	I
pure	B
negative	I
rms	O
see	O
root	B
mean	I
square	I
rolfs	O
regional	B
and	I
online	B
learnable	I
fields	I
root	B
mean	I
square	I
rprop	O
see	O
resilient	B
backpropagation	B
s	O
saltatory	B
conductor	I
schwann	B
cell	I
self-fulfilling	B
prophecy	I
self-organizing	B
feature	I
maps	I
self-organizing	B
map	I
multi-	B
sensory	B
adaptation	I
sensory	B
transduction	I
shortcut	B
connections	I
silhouette	O
coefficient	O
single	B
lense	I
eye	I
single	B
shot	I
learning	I
situation	B
situation	B
space	I
situation	B
tree	B
slp	O
see	O
perceptron	B
singlelayer	B
snark	B
snipe	O
sodium-potassium	B
pump	I
som	O
see	O
self-organizing	B
map	I
soma	B
spin	B
spinal	B
cord	I
stability	O
plasticity	O
dilemma	O
state	B
state	B
space	I
forecasting	I
state-value	B
function	I
stimulus	B
stimulus-conducting	B
apparatus	I
surface	O
perceptive	O
swing	B
up	I
an	I
inverted	I
pendulum	I
symmetry	B
breaking	I
synapse	O
chemical	B
electrical	B
synapses	B
synaptic	B
cleft	I
t	O
target	B
td	B
gammon	I
td	O
learning	O
temporal	B
difference	I
learning	I
teacher	B
forcing	I
teaching	B
input	B
telencephalon	O
see	O
cerebrum	B
temporal	B
difference	I
learning	I
thalamus	B
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
index	O
dkriesel	O
com	O
weighted	B
sum	I
widrow-hoff	O
rule	O
see	O
delta	B
rule	I
winner-takes-all	B
scheme	I
threshold	B
potential	I
threshold	B
value	I
time	B
concept	I
time	B
horizon	I
time	B
series	I
time	B
series	I
prediction	I
topological	B
defect	I
topology	B
topology	B
function	I
training	B
pattern	I
set	B
of	I
training	B
set	I
transfer	O
functionsee	O
activation	B
function	I
truncus	O
cerebri	O
see	O
brainstem	B
two-step-ahead	B
prediction	I
direct	B
u	O
unfolding	B
in	I
time	I
v	O
voronoi	B
diagram	I
w	O
weight	B
weight	B
matrix	I
bottom-up	B
top-down	B
weight	B
vector	I
d	O
kriesel	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
