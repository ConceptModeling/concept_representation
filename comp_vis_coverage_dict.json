{
    "surveys face":[
        "the algorithm can be initialized by randomly sampling k centers from the input feature vectors. ex 11.11: shape from silhouettes build a silhouette-based volume reconstruction algorithm (section 11.6.2). when the cameras are calibrated, the \ufb01ve-point algorithm of nist\u00b4er (2004) can be used in conjunction with ransac to obtain initial reconstructions from the minimum number of points. 13 when a dslr chip does not \ufb01ll the 35mm full frame, it results in a multiplier effect on the lens focal length. applications to non-rigid or elastic deformations (bookstein 1989; szeliski and lavall\u00b4ee 1996; torresani, hertzmann, and bregler 2008) are examined in sections 8.3 and 12.6.4.  yxsimilarityeuclideanaffineprojectivetranslation\f312  computer vision: algorithms and applications (september 3, 2010 draft)  transform  matrix  parameters p  jacobian j  translation  euclidean  similarity  af\ufb01ne  projective  tx  tx  b  s\u03b8  c\u03b8  0 1  (cid:34) 1 0 tx ty (cid:35) ty (cid:35) (cid:34) c\u03b8 \u2212s\u03b8 (cid:34) 1 + a \u2212b 1 + a ty (cid:35) (cid:34) 1 + a00 ty (cid:35) \uf8ee\uf8ef\uf8f0 \uf8f9\uf8fa\uf8fb  h02 1 + h11 h12 1  1 + h00  1 + a11  h10 h20  h01  h21  a01  a10  tx  (tx, ty)  (tx, ty, \u03b8)  (tx, ty, a, b)  (tx, ty, a00, a01, a10, a11)  0  0  (cid:34) 1 (cid:34) 1 (cid:34) 1 (cid:34) 1  0  0  0  1 (cid:35) c\u03b8x \u2212 s\u03b8y (cid:35) 0 \u2212s\u03b8x \u2212 c\u03b8y 1 x (cid:35) 0 x \u2212y 1 0 x y (cid:35)  0 x y 1  0  0  0  y  (h00, h01, .",
        "this particular formulation is commonly used in image-stitching applications (section 9.1.3). c.2 software  785  meshlab: software for processing, editing, and visualizing unstructured 3d triangular meshes, http://meshlab.sourceforge.net/. 538\u2013545, bielefeld. reduction operation. as we will see in this section, it can greatly improve the performance of object recognition algorithms (divvala, hoiem, hays et al.",
        "adelson, e. h. and bergen, j. and rehg, j. m. (1999). maes, f., collignon, a., vandermeulen, d., marchal, g., and suetens, p. (1997). however, such conditions rarely arise in image registration. for example, such a spatially varying kernel can be used to model blur in an image due to variable depth-dependent defocus.",
        "a closely related concept is that of wavelets, which are a special kind of pyramid with higher frequency selectivity and other useful properties (section 3.5.4). milgram, d. l. (1977). (this can be seen in the classic rotating necker cube visual illusion.) in order for the photoconsistency volume to be meaningful, matching costs need to be computed in some robust fashion, e.g., using sets of limited views or by aggregating multiple depth maps. acquire an interesting light \ufb01eld of a specular scene or object, or download one from  http://light\ufb01eld.stanford.edu/.",
        "2003; criminisi, p\u00b4erez, and toyama 2004), as discussed in sections 5.1.4 and 10.5.1. object tracking: a survey. 183\u2013190. continuous versions of pyramids using the concept of scale-space processing were also developed (witkin 1983; witkin, terzopoulos, and kass 1986; lindeberg 1990). by replacing the rightmost two transformations in figure 7.7 with the transformations shown in figure 7.8b, we can simultaneously recover the position of the robot at each time and the calibration of each camera with respect to the rig, in addition to the 3d structure of the world."
    ],
    "cube map feathering":[
        "moving gradients: a path-based method for plausible image interpolation. this pose estimation problem is also known as extrinsic calibration, as opposed to the intrinsic calibration of internal camera parameters such as focal length, which we discuss in section 6.3. (5.20)  for any two adjacent regions with at least one edge connecting their vertices, the difference between these regions is de\ufb01ned as the minimum weight edge connecting the two regions,  dif (r1, r2) =  min  e=(v1,v2)|v1\u2208r1,v2\u2208r2  w(e). alternatively, use the matting test images published on http://alphamatting.com/. (2007), russell, torralba, liu et al.",
        "minimizing the above quadratic form is equivalent to solving the sparse linear system  (3.102)  (3.103) 22 we use x instead of f because this is the more common form in the numerical analysis literature (golub and  ax = b,  van loan 1996). iterative algorithms . 238\u2013249, prague. because both these algorithms use a binary mrf optimization inside their inner loop, they are subject to the kind of constraints on the energy functions that occur in the binary labeling case (kolmogorov and zabih 2004). it is possible, however, to estimate a value for j 1 using a least squares \ufb01t to a series of larger displacements in order to increase the range of convergence (jurie and dhome 2002) or to \u201clearn\u201d a special-purpose recognizer for a given patch (avidan 2001; williams, blake, and cipolla 2003; lepetit, pilet, and fua 2006; hinterstoisser, benhimane, navab et al.",
        "figure 5.25 shows an example where the directed graph cut correctly segments the light gray liver from its dark gray surround. pattern recognition, 31(8):1019\u20131031. haralick, r. m., lee, c.-n., ottenberg, k., and n\u00a8olle, m. (1994). international journal of computer vision, 72(2):195\u2013215. interpolation .",
        "the use of bayesian modeling has several potential advantages over regularization (see also appendix b). 14.8 exercises  729  ex 14.15: tiny images download the tiny images database from http://people.csail.mit. computer, 39(8):28\u2013  29. according to their updated technical report (baker, scharstein, lewis et al. some early segmentation techniques include those describerd by brice and fennema (1970); pavlidis (1977); riseman and arbib (1977); ohlander, price, and reddy (1978); rosenfeld and davis (1979); haralick and shapiro (1985), while examples of newer techniques are developed by leclerc (1989); mumford and shah (1989); shi and malik (2000); felzenszwalb and huttenlocher (2004b).",
        "284 . instead of associating a separate depth map with each input image, a single 3d model is created for the scene, but different images are used as texture map sources depending on the virtual camera\u2019s current position (figure 13.3a).3  in more detail, given a new virtual camera position, the similarity of this camera\u2019s view of each polygon (or pixel) is compared to that of potential source images. chuang et al.\u2019s results are slightly smoother and closer to the ground truth. as the threshold is changed, the area of each component (region) is monitored; regions whose rate of change of area with respect to the threshold is minimal are de\ufb01ned as maximally stable. matthies, l., kanade, t., and szeliski, r.  estimating depth from image sequences."
    ],
    "image registration image":[
        "442\u2013447, santa barbara. (see the discussion of related techniques in section 14.3.2.) li, s. z. and jain, a. k. (eds). in advances in neural information processing systems. (2008) show how to mitigate quantization problems in visual words selection using soft assignment, where each feature descriptor is mapped to a number of visual words based on its distance from the cluster prototypes.",
        "10.3 super-resolution and blur removal  10.2 high dynamic range imaging . 11 tomasi and kanade (1992) \ufb01rst take the square root of \u03c3 and distribute this to u and v , but there is no  particular reason to do this. other techniques that use part-based recognition include those developed by dork\u00b4o and schmid (2003) and bar-hillel, hertz, and weinshall (2005). context by region ancestry. 447\u2013454, kauai, hawaii.",
        "in  british machine vision conference, pp. database construction (off-line)  (a) compute term frequencies for the visual word in each image, document fre quencies for each word, and normalized tf-idf vectors for each document. (10.8)  (in order to remove the overall shift ambiguity in the response curve and irradiance values, the middle of the response curve is set to 0.) for more general motion of patches or images, the parametric motion estimator described in section 8.2 or the feature-based approaches described in section 6.1 need to be used. see if you can come up with a model for what your camera does, e.g., whether it treats color balance as a diagonal or full 3 \u00d7 3 matrix multiply, whether it uses non-linearities in addition to gamma, whether it sharpens the image while \u201cdeveloping\u201d the jpeg image, etc.",
        "either average all of the matched pixels or choose the sharpest image, if trying to compensate for blur. diffuse re\ufb02ection also often imparts a strong body color to the light since it is caused by selective absorption and re-emission of light inside the object\u2019s material (shafer 1985; glassner 1995). to prevent aliasing, we need to pre-\ufb01lter the image f(x) with a \ufb01lter whose frequency response is the projection of the \ufb01nal desired spectrum through the a\u2212t transform (szeliski, winder, and uyttendaele 2010). lempitsky, v., roth, s., and rother., c. (2008). we begin in section 11.1 with a review of the geometry of stereo image matching, i.e., how to compute for a given pixel in one image the range of possible locations the pixel might appear at in the other image, i.e., its epipolar line.",
        "2007), full af\ufb01ne invariance is preferred. 334 . preattentive processing in vision. as a measure of \ufb01tness, count how many pairwise estimates are consistent with the global alignment. in the mid-1990s, image alignment techniques started being applied to the construction of wide-angle seamless panoramas from regular hand-held cameras (mann and picard 1994; chen 1995; szeliski 1996)."
    ],
    "heteroscedastic ampli\ufb01er ef\ufb01ciency image anisotropic probabilistic aggregation motion models translation af\ufb01ne projective triangle mesh linear total variation video direct unsharp mask optical \ufb02ow spline-based kernel recall pure translation feature difference direct intensity-based non-linear line process cascade of classi\ufb01ers band-pass robust smoothness aperture problem constellation model coarse-to-\ufb01ne strategy mechanical re-normalization lines splines half-octave":[
        "9.2.1 bundle adjustment  one way to register a large number of images is to add new images to the panorama one at a time, aligning the most recent image with the previous ones already in the collection (szeliski and shum 1997) and discovering, if necessary, which images it overlaps (sawhney and kumar 1999). explicit surface representations, such as triangle meshes, splines (farin 1992, 1996), and subdivision surfaces (stollnitz, derose, and salesin 1996; zorin, schr\u00a8oder, and sweldens 1996; warren and weimer 2001; peters and reif 2008), enable not only the creation of highly detailed models but also processing operations, such as interpolation (section 12.3.1), fairing or smoothing, and decimation and simpli\ufb01cation (section 12.3.2). a disadvantage of factorization approaches is that they require a complete set of tracks, i.e., each point must be visible in each frame, in order for the factorization approach to work. 778  computer vision: algorithms and applications (september 3, 2010 draft)  in this \ufb01nal appendix, i summarize some of the supplementary materials that may be useful to students, instructors, and researchers. 371 .",
        "1986; black and rangarajan 1996; stewart 1999), which involves applying a robust penalty function \u03c1(r) to the residuals  erls(\u2206p) =(cid:88)i  \u03c1((cid:107)ri(cid:107))  (6.25)  (6.26)  instead of squaring them. international journal of computer vision, 17(1):43\u201375. face recognition can also be used in a variety of additional applications, including human\u2013computer interaction (hci), identity veri\ufb01cation (kirovski, jojic, and jancke 2004), desktop login, parental controls, and patient monitoring (zhao, chellappa, phillips et al. (optional) compensate for images that are blurry because of fast motion by \u201cstealing\u201d  higher frequencies from adjacent frames. in international conference on pattern recognition (icpr 2006), pp.",
        "freeman, w., perona, p., and sch\u00a8olkopf, b. chapter 13: image-based rendering  the (new) stanford light field archive, http://light\ufb01eld.stanford.edu/ (wilburn, joshi, vaish et al. this is also where i began my long-term collaboration with daniel scharstein, now at middlebury college. displacement map...(a)(b)(c)(d)(e)......===== l1l2ll-2ll-1lll  (t)1l  (t)2l    (t)l-2l    (t)l-1l (t)l    displacement map    displacement map    displacement map    displacement mapd    (t) l-1d (t) ld    (t) l-2d  (t) 2d  (t) 1type=(cid:147)boat(cid:148)type=(cid:147)still(cid:148)type=(cid:147)tree(cid:148)type=(cid:147)cloud(cid:148)type=(cid:147)water(cid:148)figure2overviewofoursystem.theinputstillimage(a)ismanuallysegmentedintoseverallayers(b).eachlayerliisthenanimatedwithadifferentstochasticmotiontexturedi(t)(c).finally,theanimatedlayersli(t)(d)arecompositedbacktogethertoproducethe\ufb01nalanimationi(t)(e).[grif\ufb01ths1997],buttheresultingeffectmaynotmaintainaviewer\u2019sinterestovermorethanashortperiodoftime,onaccountofitspe-riodicityandpredictability.theapproachweultimatelysettledupon\u2014whichhastheadvan-tagesofbeingquitesimpleforuserstospecify,andofcreatinginteresting,complex,andplausiblyrealisticmotion\u2014istobreaktheimageupintoseverallayersandtothensynthesizeadiffer-entmotiontexture1foreachlayer.amotiontextureisessentiallyatime-varyingdisplacementmapde\ufb01nedbyamotiontype,asetofmotionparameters,andinsomecasesamotionarmature.thisdisplacementmapd(p,t)isafunctionofpixelcoordinatespandtimet.applyingitdirectlytoanimagelayerlresultsinaforwardwarpedimagelayerl0suchthatl0(p+d(p,t))=l(p)(1)however,sinceforwardmappingisfraughtwithproblemssuchasaliasingandholes,weactuallyuseinversewarping,de\ufb01nedasl0(p)=l(p+d0(p,t))(2)wedenotethisoperationasl0=l\u2297d0.wecouldcomputetheinversedisplacementmapd0fromdusingthetwo-passmethodsuggestedbyshadeetal.[1998].instead,sinceourmotion\ufb01eldsareallverysmooth,wesimplydilatethembytheextentofthelargestpossiblemotionandreversetheirsign.withthisnotationinplace,wecannowdescribethebasicwork\ufb02owofoursystem(figure2),whichconsistsofthreesteps:layeringandmatting,motionspeci\ufb01cationandediting,and\ufb01nallyrendering.layeringandmatting.the\ufb01rststep,layering,istosegmenttheinputimageiintolayerssothat,withineachlayer,thesamemotiontexturecanbeapplied.forexample,forthepaintinginfig-ure2(a),wehavethefollowinglayers:oneforeachofthewater,sky,bridgeandshore;oneforeachofthethreeboats;andoneforeachoftheeleventreesinthebackground(figure2(b)).toaccom-plishthis,weuseaninteractiveobjectselectiontoolsuchasapaint-ingtoolorintelligentscissors[mortensenandbarrett1995].thetoolisusedtospecifyatrimapforalayer;wethenapplybayesian1weusethetermsmotiontextureandstochasticmotiontextureinter-changeablyinthispaper.thetermmotiontexturewasalsousedbyliet.al[2002]torefertoalineardynamicsystemlearnedfrommotioncapturedata.mattingtoextractthecolorimageandasoftalphamatteforthatlayer[chuangetal.2001].becausesomelayerswillbemoving,occludedpartsoftheback-groundmightbecomevisible.hence,afterextractingalayer,weuseanenhancedinpaintingalgorithmto\ufb01lltheholeintheback-groundbehindtheforegroundlayer.weuseanexample-basedin-paintingalgorithmbasedontheworkofcriminisietal.[2003]be-causeofitssimplicityanditscapacitytohandlebothlinearstruc-turesandtexturedregions.notethattheinpaintingalgorithmdoesnothavetobeperfectsinceonlypixelsneartheboundaryoftheholearelikelytobecomevis-ible.wecanthereforeacceleratetheinpaintingalgorithmbycon-sideringonlynearbypixelsinthesearchforsimilarpatches.thisshortcutmaysacri\ufb01cesomequality,soincaseswheretheautomaticinpaintingalgorithmproducespoorresults,weprovideatouch-upinterfacewithwhichausercanselectregionstoberepainted.theautomaticalgorithmisthenreappliedtothesesmallerregionsus-ingalargersearchradius.wehavefoundthatmostsigni\ufb01cantin-paintingartifactscanberemovedafteronlyoneortwosuchbrush-strokes.althoughthismayseemlessef\ufb01cientthanafullyautomaticalgorithm,wehavefoundthatexploitingthehumaneyeinthissim-plefashioncanproducesuperiorresultsinlessthanhalfthetimeofthefullyautomaticalgorithm.notethatifalayerexhibitslargemotions(suchasawildlyswingingbranch),artifactsdeepinsidetheinpaintedregionsbehindthatlayermayberevealed.inprac-tice,theseartifactsmaynotbeobjectionable,asthemotiontendstodrawattentionawayfromthem.whentheyareobjectionable,theuserhastheoptionofimprovingtheinpaintingresults.afterthebackgroundimagehasbeeninpainted,weworkonthisimagetoextractthenextlayer.werepeatthisprocessfromtheclosestlayertothefurthestlayertogeneratethedesirednumberoflayers.eachlayerlicontainsacolorimageci,amatte\u03b1i,andacompositingorderzi.thecompositingorderispresentlyspeci\ufb01edbyhand,butcouldinprinciplebeautomaticallyassignedwiththeorderinwhichthelayersareextracted.motionspeci\ufb01cationandediting.thesecondcomponentofoursystemletsusspecifyandeditthemotiontextureforeachlayer.currently,weprovidethefollowingmotiontypes:trees(swaying),water(rippling),boats(bobbing),clouds(translation),andstill(nomotion).foreachmotiontype,theusercantunethemotionparam-etersandspecifyamotionarmature,whereapplicable.wedescribethemotionparametersandarmaturesinmoredetailforeachmotiontypeinsection3. taking the dot product of both sides with \u02c6x1 yields  d0 \u02c6xt  1 ([t]\u00d7r)\u02c6x0 = d1 \u02c6xt  1 [t]\u00d7 \u02c6x1 = 0,  (7.9)  since the right hand side is a triple product with two identical entries.",
        "convolution has additional nice properties, e.g., it is both commutative and associative. this can be written more compactly as  [xi1 xt  i0] \u2297 e = zi \u2297 e = zi \u00b7 f = 0,  (7.13)  (7.14)  where \u2297 indicates an element-wise multiplication and summation of matrix elements, and zi i0 and e matrices.2 given n \u2265 8 and f are the rasterized (vector) forms of the zi = \u02c6xi1 \u02c6xt such equations, we can compute an estimate (up to scale) for the entries in e using an svd. f(i,j)sx(i,j)f(i,j+1)sy(i,j)w(i,j)d(i,j)f(i+1,j)f(i+1,j+1)\f190  computer vision: algorithms and applications (september 3, 2010 draft)  figure 3.63 graphical model for a discriminative random \ufb01eld (drf). reconstructing occluded surfaces using synthetic apertures: shape from focus vs. shape from stereo. ikeuchi, k. and sato, y.",
        "6.5 exercises  341  3. interna tional journal of computer vision, 80(1):3\u201315. the usual way to do this is to use least squares, i.e., to minimize the sum of squared residuals  where  els =(cid:88)i  (cid:107)ri(cid:107)2 =(cid:88)i  (cid:107)f(xi; p) \u2212 x(cid:48)i(cid:107)2,  ri = f(xi; p) \u2212 x(cid:48)i = \u02c6x(cid:48)i \u2212 \u02dcx(cid:48)i  (6.2)  (6.3)  is the residual between the measured location \u02c6x(cid:48)i and its corresponding current predicted location \u02dcx(cid:48)i = f(xi; p). matte extraction proceeds in strips starting from known color values growing into the unknown regions, so that recently computed f and b colors can be used in later stages. (c) use dense stereo matching to estimate the 3d shape."
    ],
    "decentering tangential":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "seam selection pixel selection image multiple direct optical \ufb02ow blending feathering":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "lines points":[
        "in this chapter, we address the question of how to build a more complete 3d model, e.g., a sparse or dense depth map that assigns relative depths to pixels in the input images. depth painting for image-based rendering applications. 87\u201393, kerkyra, greece. the exercises at the end of each chapter contain numerous suggestions for smaller mid-term projects, as well as more open-ended problems whose solutions are still active research topics. hinckley, k., sinclair, m., hanson, e., szeliski, r., and conway, m. (1999).",
        "an experimental study on pedestrian classi\ufb01cation. compute the three images corresponding to the outer products of these gradients. 225 . on certain simple homogeneous problems (such as solving poisson equations), multigrid techniques can achieve optimal performance, i.e., computation times linear in the number of variables. szeliski, r.  (1999).",
        "(8.71)  if we replace the per-pixel (rank 1) hessians ai = [j ij t i ] and residuals bi = j iei with areaaggregated versions (8.40\u20138.41), we obtain a global minimization algorithm where regionbased brightness constraints are used. the radial distortion parameters can then be adjusted until all of the lines in the image are straight, which is commonly called the plumb-line method (brown 1971; kang 2001; el-melegy and farag 2003). somewhat surprisingly, freeman and adelson (1991) showed that, for directional gaussian derivatives, it is possible  \f120  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  (c)  (d)  figure 3.16 fourth-order steerable \ufb01lter (freeman and adelson 1991) c(cid:13) 1991 ieee: (a) test image containing bars (lines) and step edges at different orientations; (b) average oriented energy; (c) dominant orientation; (d) oriented energy as a function of angle (polar plot). figure 2.25 shows a highfrequency chirp image (so called because the frequencies increase over time), along with the results of sampling it with a 25% \ufb01ll-factor area sensor, a 100% \ufb01ll-factor sensor, and a highquality 9-tap \ufb01lter. in order to make such a technique practical, a number issues need to be addressed:  \u2022 the amount of blur increase in both directions as you move away from the focus plane.",
        "in kanade, t. noborio, h., fukada, s., and arimoto, s. (1988). note, however, that the ncc score is unde\ufb01ned if either of the two patches has zero variance (and, in fact, its performance degrades for noisy low-contrast regions). (the image on the right is scaled up for better visibility. this ensures that corresponding epipolar lines are horizontal and that the disparity for points at in\ufb01nity is 0.",
        "shi and tomasi (1994) and triggs (2004) also provide nice reviews of feature detection techniques. he also has a wealth of tips for hdr photography and work\ufb02ow. journal of machine learning research, 8:725\u2013760. (3.70)  taking the negative logarithm of both sides of (3.68) and setting \u00b5 = 0 for simplicity, we  get  \u2212 log p(s|o) = \u2212 log p(o|s) \u2212 log p(s) + c n (s \u2212 o)2 + 1/2p \u22121  = 1/2p \u22121  s s2 + c,  (3.71) (3.72)  11 wiener is pronounced \u201cveener\u201d since, in german, the \u201cw\u201d is pronounced \u201cv\u201d. london."
    ],
    "barrel pincushion":[
        "if a multi-resolution (coarse-to-\ufb01ne) strategy is being used, it is important to re-scale these smoothness terms while going from level to level. rom\u00b4an, a. and lensch, h. p. a. 768 . as the size of the database being matched increases, it becomes more ef\ufb01cient to quantize the visual descriptors into words (sivic and zisserman 2003; schindler, brown, and szeliski 2007; sivic and zisserman 2009; turcot and lowe 2009), and to then use informationretrieval techniques, such as inverted indices (nist\u00b4er and stew\u00b4enius 2006; philbin, chum, isard et al. ordinal-valued mrfs  in addition to binary images, markov random \ufb01elds can be applied to ordinal-valued labels such as grayscale images or depth maps.",
        "siggraph 2002), 21(3):547\u2013556. the condensation algorithm presented in section 5.1.2 is one possible method for modeling and updating such multi-modal distributions but is just one example of more general particle \ufb01ltering and markov chain monte carlo (mcmc) techniques (andrieu, de freitas, doucet et al. consider for example the image in figure 3.8a, which has a wide range of luminance values. projective. 147\u2013152.",
        "tales of shape and radiance in multiview stereo. (this makes particular sense if the data is being acquired from  14 this ordering is preferable when there are fewer cameras than 3d points, which is the usual case. while this approach works well in practice, it suffers from two potential disadvantages. find some historic monochrome photographs and some modern color ones. 12.7.2 application: 3d photography  the techniques described in this chapter for building complete 3d models from multiple images and then recovering their surface appearance have opened up a whole new range of applications that often go under the name 3d photography.",
        "koenderink, j. j. in this case, the loopy  \f186  computer vision: algorithms and applications (september 3, 2010 draft)  figure 3.59 graphical model for a markov random \ufb01eld with a more complex measurement model. torr, p. h. s. and fitzgibbon, a. w. (2004). to \ufb01x this, either pick one frame as being at the origin or add a constraint to make the average frame offsets be 0. the magicbook: a transitional ar  interface.",
        "international journal of computer vision, 12(1):5\u201316. 2005), as well as some books describing related photographic techniques (freeman 2008; gulbins and gulbins 2009). if you want to \ufb01nd out what your camera actually does, continue on to the next exercise. seitz, p.  (1989). since such boundaries are what active contours usually follow, active contour algorithms (mortensen and barrett 1999; li, sun, tang et al."
    ],
    "kinematic models probabilistic models adaptive shape modeling background subtraction initialization background subtraction":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "mean shift probabilistic aggregation normalized cuts splitting active contours snakes":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "faces recognition self-calibration automated":[
        "of course, keypoints are not the only features that can be used for registering images. russell, b. c., torralba, a., liu, c., fergus, r., and freeman, w. t. (2007). in addition to a schematic map in the lower left corner and adjacent room names along the top navigation bar, icons appear along the bottom whenever items of interest, such as a homeowner\u2019s art pieces, are visible in the main window. zhao, g. and pietik\u00a8ainen, m. (2007). couprie, c., grady, l., najman, l., and talbot, h. (2009).",
        "note that the map estimate may not always be desirable, since it selects the \u201cpeak\u201d in the posterior distribution rather than some more stable statistic\u2014see the discussion in appendix b.2 and by levin, weiss, durand et al. once the entries in p have been recovered, it is possible to recover both the intrinsic calibration matrix k and the rigid transformation (r, t) by observing from equation (2.56) that  p = k[r|t]. extract edges and link them (exercises 4.7\u20134.8). international journal of computer vision, 59(2):167\u2013181. 2003) c(cid:13) 2003 acm.",
        "komodakis and tziritas (2007b) present an mrf-based version of this block synthesis algorithm that uses a new, ef\ufb01cient version of loopy belief propagation they call \u201cpriority-bp\u201d. deformed lattice detection in real-world images using mean-shift belief propagation. (b) a weighted gradient orientation histogram is then computed in each subregion, using trilinear interpolation. papert, s.  (1966). in equation (b.5), we have indicated that ni is a zero-mean normal (gaussian) random variable with a covariance matrix \u03c3i.",
        "international journal of computer vision, 13(2):119\u2013152. singaraju, d., rother, c., and rhemann, c. (2009). (optional) use your sparse 3d structure, interpolated to a dense depth map, to improve  your rendering (zheng, kang, cohen et al. the numbers underneath each detail image are the accuracy of each of these techniques measured in millimeters. for many applications, keeping the simpli\ufb01ed diagonal form of (2.59) is still an adequate model.",
        "an updated set of basic linear algebra subprograms (blas). (2006), the \ufb01eld of multi-view stereo has continued to advance at a rapid pace (strecha, fransens, and van gool 2006; hernandez, vogiatzis, and cipolla 2007; habbecke and kobbelt 2007; furukawa and ponce 2007; vogiatzis, hernandez, torr et al. 2009; gulbins and gulbins 2009). pentland, a. p.  (1986). (purchasing a remote shutter release is a good investment if you own a dslr.)"
    ],
    "weighting de-ghosting parallax removal video summarization global alignment planar perspective motion motion models planar perspective motion":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "estimation human body photometric stereo":[
        "references  859  levoy, m. (2008). spectral segmentation with multiscale graph decomposition. a region based stereo matching algorithm using cooperative optimization. 751 . a visual category \ufb01lter for google images.",
        "criminisi, a., sharp, t., and blake, a. society for industrial  and applied mathematics. ieee transactions on pattern analysis and machine intelligence, 18(8):814\u2013830. chen, s. and williams, l. (1993). detect and match feature points across neighboring frames and chain them into feature  tracks.",
        "geodesic active contours and level sets for the deieee transactions on pattern analysis and  tection and tracking of moving objects. however, the even samples still contain an aliased sample of the low-frequency signal. in practice, motion estimation is usually applied to video, where a whole sequence of frames is available to perform this task. when video sequences are available, the additional information present in the optic \ufb02ow and motion discontinuities can greatly aid in the detection task, as discussed by efros, berg, mori et al. westover, l. (1989).",
        "poisson matting (sun, jia, tang et al. journal of cognitive neuro science, 3(1):59\u201370. (2005) gives a nice example of a dynamic appearance and illumination acquisition system.) during the forward pass, each non-zero pixel in b is replaced by the minimum of 1 + the distance of its north or west neighbor. 382\u2013390.",
        "evaluate the quality of the demosaicing algorithm by taking pictures of challenging  scenes which contain strong color edges (such as those shown in in section 10.3.1). (the response curves are calibrated separately for each color channel.) 2.5 exercises  97  6. note the wide range of illumination variation, which can be more dramatic than inter-personal variations. visual correspondence using energy minin ninth international conference on computer  imization and mutual information."
    ],
    "two-dimensional non-photorealistic rendering layout consistent data sets radiosity global illumination non-rigid inference adaptive shape modeling learning local successive approximation optics bilinear high dynamic range non-linear mean shift recognition smoke support region constraint probabilistic octree surface local scene completion preconditioned within-class frame interpolation between-class weighted bilinear patch-based photogrammetry camera motion multi-frontal lighting windowed sinc exponential twist k-means sprites separable active contours missing data correspondence decision stump video stabilization eight-point algorithm machine inspection augmented reality automated sparse image texture snakes intensity-based direct af\ufb01nities spline directional derivative image linking demosaicing image computational theory chain code global illumination video denoising simpli\ufb01cation silhouettes space carving active illumination industrial tonal adjustment linking af\ufb01ne invariance extrinsic stochastic gradient descent stiffness matrix visual effects non-parametric hue di-chromatic feature-based re\ufb02ectance recognition surface head interactive pedestrian car agglomerative densi\ufb01cation instance aliasing homogeneous coordinates elastic bunch graph matching robust color noise matching physics-based antipodal incomplete dilation steerable \ufb01lter with depth bundle adjustment image level sets support vector machines regularization rank-de\ufb01cient patch test images pro\ufb01les noise dynamic walkthroughs demosaicing para-perspective energy-based merging up vector selection octave blending joint feature space sinc lighting surface bag of words diffuse stereo recognition fast marching method geodesic active contour surface interactive image-based radial distortion equations error rates nearest neighbor bilinear bicubic edge editing hysteresis twisted pair for recognition weighted windowed repeatability tion detection cooperative algorithms points image match move merging localization and mapping expansion move total variation projective factorization intelligent photo editing iterative conjugate gradient matrix decompositions octree volumetric color similarity lines vanishing points point spread function normal vector selectivity examples multiple trilinear interpolation intensity-based cliques binomial anisotropic smoothness range kernel shading texture deblocking scratch removal neural networks rendering compression iterated conditional modes k-d trees motion models compositional preemptive divisive calibration matrix stop list erosion perspective projective texture hashing bilateral gaze correction boundary detection":[
        "(2009) uses unary (pixelwise) potentials based on image-speci\ufb01c color distributions (section 5.5) (boykov and jolly 2001; rother, kolmogorov, and blake 2004), location information (e.g., foreground objects are more likely to be in the middle of the image, sky is likely to be higher, and road is likely to be lower), and novel texture-layout classi\ufb01ers trained using shared boosting. off-line systems were also developed for estimating 3d multi-viewpoint geometry from video streams (section 13.5.4) (kanade, rander, and narayanan 1997; carranza, theobalt, magnor et al. an early example of using implicit functions to model 3d objects in computer vision are superquadrics, which are a generalization of quadric (e.g., ellipsoidal) parametric volumetric models,  f (x, y, z) =(cid:32)(cid:18) x  a1(cid:19)2/\u00012  a2(cid:19)2/\u00012(cid:33)\u00012/\u00011 +(cid:18) y  +(cid:18) x a1(cid:19)2/\u00011  \u2212 1 = 0  (12.8)  (pentland 1986; solina and bajcsy 1990; waithe and ferrie 1991; leonardis, jakli\u02c7c, and solina 1997). 18  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (d)  (b)  (e)  (c)  (f)  figure 1.10 recent examples of computer vision algorithms: (a) image-based rendering (gortler, grzeszczuk, szeliski et al. recovering the position and orientation of free-form objects from image contours using 3-d distance maps.",
        "trobin, w., pock, t., cremers, d., and bischof, h. (2008). if we are given a dense enough set of images, we can \ufb01nd such strips and reason about their relationships in order to both reconstruct the 3d scene and make inferences about translucent objects (tsin, kang, and szeliski 2006) and specular re\ufb02ections (swaminathan, kang, szeliski et al. (optional) re-represent each contour using an arc-length or some other re-parameterization. the unknowns are therefore the per-pixel exposures ei and the response values gk = g(k), where g can be discretized according to the 256 pixel values commonly observed in eight-bit images. whatever the outcome of these research endeavors, computer vision is already having a tremendous impact in many areas, including digital photography, visual effects, medical imaging, safety and surveillance, and web-based search.",
        "10.4.3 optimization-based matting . at the time, it was believed by some of the early pioneers of arti\ufb01cial intelligence and robotics (at places such as mit, stanford, and cmu) that solving the \u201cvisual input\u201d problem would be an easy step along the path to solving more dif\ufb01cult problems such as higher-level reasoning and planning. 7.3.2 application: sparse 3d model extraction . for instance recognition (section 14.3.1), this can sometimes be achieved by backprojecting the object model into  \f14.4 category recognition  705  (a)  (b)  (c)  figure 14.42 part-based recognition (fergus, perona, and zisserman 2007) c(cid:13) 2007 springer: (a) locations and covariance ellipses for each part, along with their occurrence probabilities (top) and relative log-scale densities (bottom); (b) part examples drawn from the training images that best match the average appearance; (c) recognition results for the motorcycle class, showing detected features (pink dots) and parts (colored circles). b.5.4 graph cuts  the computer vision community has adopted \u201cgraph cuts\u201d as an informal name to describe a large family of mrf inference algorithms based on solving one or more min-cut or max\ufb02ow problems (boykov, veksler, and zabih 2001; boykov and kolmogorov 2010; boykov,  \fb.5 markov random \ufb01elds  771  (a)  (b)  figure b.3 graph cuts for minimizing binary sub-modular mrf energies (boykov and jolly 2001) c(cid:13) 2001 ieee: (a) energy function encoded as a max \ufb02ow problem; (b) the minimum cut determines the region boundary.",
        "this is then generalized to spline-based motion models (section 8.3) and \ufb01nally to general per-pixel optical \ufb02ow (section 8.4), including layered and learned motion models (section 8.5). batra, d., sukthankar, r., and chen, t. (2008). society for industrial  and applied mathematics, philadephia. in situations where the camera is translating a lot in 3d, e.g., when the videographer is walking, an even better approach is to compute a full structure from motion reconstruction of the camera motion and 3d scene. i\u2019m also grateful to the many other computer vision researchers who have given me so many constructive suggestions about the book, including sing bing kang, who was my informal book editor, vladimir kolmogorov, who contributed appendix b.5.5 on linear programming techniques for mrf inference, daniel scharstein, richard hartley, simon baker, noah snavely, bill freeman, svetlana lazebnik, matthew turk, jitendra malik, alyosha efros, michael black, brian curless, sameer agarwal, li zhang, deva ramanan, olga veksler, yuri boykov, carsten rother, phil torr, bill triggs, bruce maxwell, jana ko\u02c7seck\u00b4a, eero simoncelli, aaron hertzmann, antonio torralba, tomaso poggio, theo pavlidis, baba vemuri, nando de freitas, chuck dyer, song yi, falk schubert, roman p\ufb02ugfelder, marshall tappen, james coughlan, sammy rogmans, klaus strobel, shanmuganathan, andreas siebert, yongjun wu, fred pighin, juan cockburn, ronald mallet, tim soper, georgios evangelidis, dwight fowler, itzik bayaz, daniel o\u2019connor, and srikrishna bhat.",
        "in addition to computing the weight matrix using interpolation-based coarsening, additional region statistics are used to modulate the weights. the existence of multiple depth maps enables more accurate reasoning about occlusions, as regions which are occluded in one image may be visible (and matchable) in others. 844  computer vision: algorithms and applications (september 3, 2010 draft)  irani, m. and peleg, s.  (1991). in this section, we brie\ufb02y review some of the more seminal and widely cited papers in the areas of background subtraction, initialization and detection, tracking with \ufb02ow, 3d kinematic models, probabilistic models, adaptive shape modeling, and activity recognition. text-to-speech synthesis."
    ],
    "transparent":[
        "a review of statistical approaches to level set segmentation: integrating color, texture, motion and shape. reconstructing building interiors from images. world-scale mining of objects and events from community photo collections. in 25th international conference on very large data bases (vldb\u201999), pp. we also ask the students to propose a \ufb01nal project (we provide a set of suggested topics for those who need ideas) by the middle of the course and reserve the last week of the class for student presentations.",
        "real-time visibility-based fusion of depth maps. 774  computer vision: algorithms and applications (september 3, 2010 draft)  this relaxation has been extensively studied in the literature, starting with the work of schlesinger (1976). a maximum likelihood  stereo algorithm. rosenfeld, a. and davis, l. s. (1979). this low frequency sampling gives the features some robustness to interest point location error and is achieved by sampling at a higher pyramid level than the detection scale.",
        "in this section, we look at alternative formulations (which may not involve the full solution of a non-linear regression problem), the use of alternative calibration targets, and the estimation of the non-linear part of camera optics such as radial distortion.12  6.3.1 calibration patterns  the use of a calibration pattern or set of markers is one of the more reliable ways to estimate a camera\u2019s intrinsic parameters. (2000)  http://www.frvt.org/feret  frvt  http://www.frvt.org/ cmu pie database  centered face images  faces in various poses  centered face image  faces in various poses  phillips, scruggs, o\u2019toole et al. 2002) c(cid:13) 2002 acm. a commonly occurring example of this is the aperture problem, \ufb01rst identi\ufb01ed in some of the early papers on optical \ufb02ow (horn and schunck 1981) and then studied more extensively by anandan (1989). 72\u201385, marseilles.",
        "9.1 motion models  433  figure 9.3 pure 3d camera rotation. an alternative to grouping lines into coplanar subsets is to group lines by parallelism. representative papers in this area include those by torralba (2003), torralba, murphy, freeman et al. the sub-pixel location of this crossing can be obtained by computing the \u201cx-intercept\u201d of  the \u201cline\u201d connecting s(xi) and s(xj),  xz =  xis(xj) \u2212 xjs(xi)  s(xj) \u2212 s(xi)  . since computer vision involves going from images to a structural description of the scene (and computer graphics the converse), i have positioned the chapters horizontally in terms of which major component they address, in addition to vertically according to their dependence.",
        "in their system, the synchronized video streams from the six cameras (figure 13.16a) are stitched together into 360\u25e6 panoramas using a variety of techniques developed speci\ufb01cally for this project. sch\u00a8olkopf, b. and smola, a. aedcbleftmiddlerightfxt\f11.6 multi-view stereo  561  (a)  (b)  figure 11.16 spatio-temporally shiftable windows (kang, szeliski, and chai 2001) c(cid:13) 2001 ieee: a simple three-image sequence (the middle image is the reference image), which has a moving frontal gray square (marked f) and a stationary background. if so, when you convert back to rgb space, do you need a full 3 \u00d7 3 color twist matrix to achieve the same effect? if we know the 3d shape of the object or scene whose light \ufb01eld is being modeled, we can effectively compress the \ufb01eld because nearby rays emanating from nearby surface elements have similar color values."
    ],
    "location recognition patterns":[
        "329 . lischinski, d., farbman, z., uyttendaele, m., and szeliski, r. (2006b). interna tional journal of computer vision, 32(1):63\u201377. isidoro, j. and sclaroff, s. (2003). let \u02c6mi and \u02c6mj be the (unit norm) line equations for a pair of line segments and li and lj be their corresponding segment lengths.",
        "perform temporal high-pass \ufb01ltering on the motion parameters to remove the low frequency component (smooth the motion). an incremental quaternion is then computed and multiplied by the starting rotation quaternion. in  ninth european conference on computer vision (eccv 2006), pp. while this is acceptable for small shifts and comparably sized images, it makes no sense when the images overlap by a small amount or one image is a small subset of the other. some of these are compared in recent surveys and evaluations of matching costs (scharstein and szeliski 2002; hirschm\u00a8uller and scharstein 2009).",
        "stereo classi\ufb01cation and performance evaluation of different aggregation costs for stereo matching, http://www.vision.deis.unibo.it/spe/spehome.aspx (tombari, mattoccia, di stefano et al. \u00a8ozuysal, m., calonder, m., lepetit, v., and fua, p. (2010). the gradient of the smoothed image can therefore be written as  j \u03c3(x) = \u2207[g\u03c3(x) \u2217 i(x)] = [\u2207g\u03c3](x) \u2217 i(x),  (4.20)  i.e., we can convolve the image with the horizontal and vertical derivatives of the gaussian kernel function,  \u2207g\u03c3(x) = ( \u2202g\u03c3  \u2202x  ,  \u2202g\u03c3 \u2202y  )(x) = [\u2212x \u2212 y]  1  \u03c33 exp(cid:18)\u2212  x2 + y2  2\u03c32 (cid:19)  (4.21)  (the parameter \u03c3 indicates the width of the gaussian.) these are described in specialized textbooks on iterative solution techniques (axelsson 1996; saad 2003) as well as in more general books on numerical linear algebra and least squares techniques (bj\u00a8orck 1996; golub and van loan 1996; trefethen and bau 1997; nocedal and wright 2006; bj\u00a8orck and dahlquist 2010). the literature on texture synthesis and hole \ufb01lling includes traditional approaches to texture synthesis, which try to match image statistics between source and destination images (heeger and bergen 1995; de bonet 1997; portilla and simoncelli 2000), as well as newer approaches, which search for matching neighborhoods or patches inside the source sample (efros and leung 1999; wei and levoy 2000; efros and freeman 2001).",
        "a closely related concept is that of wavelets, which are a special kind of pyramid with higher frequency selectivity and other useful properties (section 3.5.4). milgram, d. l. (1977). (this can be seen in the classic rotating necker cube visual illusion.) in order for the photoconsistency volume to be meaningful, matching costs need to be computed in some robust fashion, e.g., using sets of limited views or by aggregating multiple depth maps. acquire an interesting light \ufb01eld of a specular scene or object, or download one from  http://light\ufb01eld.stanford.edu/.",
        "one popular approach used generalized cylinders, i.e., solids of revolution and swept closed curves (agin and binford 1976; nevatia and binford 1977), often arranged into parts relationships7 (hinton 1977; marr 1982) (figure 1.7c). the bidirectional re\ufb02ectance distribution function (brdf)  the most general model of light scattering is the bidirectional re\ufb02ectance distribution function (brdf).5 relative to some local coordinate frame on the surface, the brdf is a fourdimensional function that describes how much of each wavelength arriving at an incident direction \u02c6vi is emitted in a re\ufb02ected direction \u02c6vr (figure 2.15b). face swapping: automatically replacing faces in photographs. local distance functions: a taxonomy, new algorithms, in twelfth international conference on computer vision (iccv  and an evaluation. unfortunately, voxel coloring is only guaranteed to work if all of the cameras lie on the same side of the sweep planes, which is not possible in general ring con\ufb01gurations of cameras."
    ],
    "part-based scene understanding":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "linearity":[
        "optionally, estimate radial distortion parameters as well or support \ufb01sheye lenses (section 2.1.6). 802\u2013815, marseilles. in fifth european conference on computer vision (eccv\u201998), pp. surface reconstruction from feature based stereo. human-assisted motion in ieee computer society conference on computer vision and pattern  annotation.",
        "trobin, w., pock, t., cremers, d., and bischof, h. (2008). if we are given a dense enough set of images, we can \ufb01nd such strips and reason about their relationships in order to both reconstruct the 3d scene and make inferences about translucent objects (tsin, kang, and szeliski 2006) and specular re\ufb02ections (swaminathan, kang, szeliski et al. (optional) re-represent each contour using an arc-length or some other re-parameterization. the unknowns are therefore the per-pixel exposures ei and the response values gk = g(k), where g can be discretized according to the 256 pixel values commonly observed in eight-bit images. whatever the outcome of these research endeavors, computer vision is already having a tremendous impact in many areas, including digital photography, visual effects, medical imaging, safety and surveillance, and web-based search.",
        "soille, p. (2006). using dynamic programming for solving variational problems in vision. their newer system (csurka, dance, perronnin et al. international  journal of computer vision, 51(2):91\u2013109. consider the discrete analog (8.35) to the analytic global energy (8.70),  ehsd =(cid:88)i  i [j ij t ut  i ]ui + 2eij t  i ui + e2 i .",
        "once the two meshes have been speci\ufb01ed, intermediate warps can be generated using linear interpolation and the displacements at mesh nodes can be interpolated using splines. symbolic reasoning among 3-d models and 2-d images. how do these relate  to exposure values (evs)? multi-view stereo via graph cuts on the dual of an adaptive tetrahedral mesh. 11.5.3 application: z-keying and background replacement .",
        "however, if each feature in the query is matched to its closest analog in all the class images, a good match can be found. unfortunately, it still suffers from the same streaking artifacts as dynamic programming. 2003), a camera centrally located between the two input cameras is preferable, since it provides the needed per-pixel disparities to hallucinate the virtual middle image. computer graphics:  principles and practice. some local algorithms, however, combine steps 1 and 2 and use a matching cost that is based on a support region, e.g."
    ],
    "view-dependent texture maps cylindrical view interpolation pairs":[
        "a survey of skin-color model ing and detection methods. figure 5.13 shows the results of running the watershed algorithm with some manually placed markers on a confocal microscopy image. ott, m., lewis, j. p., and cox, i. j. cham, t.-j. 1989).",
        "signal  processing, 85(2):246\u2013263. this technique segments an image into several catchment basins, which are the regions of an image (interpreted as a height \ufb01eld or landscape) where  \f5.2 split and merge  285  (a)  (b)  (c)  figure 5.13 locally constrained watershed segmentation (beare 2006) c(cid:13) 2006 ieee: (a) original confocal microscopy image with marked seeds (line segments); (b) standard watershed segmentation; (c) locally constrained watershed segmentation. (2001) and illustrated in figure 10.41f. the topic of active contours has a long history, beginning with the seminal work on snakes and other energy-minimizing variational methods (kass, witkin, and terzopoulos 1988; cootes, cooper, taylor et al. the original algorithm proposed by shi and malik (2000) used spatial position and image  feature differences to compute the pixel-wise af\ufb01nities,  wij = exp(cid:18)\u2212(cid:107)f i \u2212 f j(cid:107)2  \u03c32 f  \u2212 (cid:107)xi \u2212 xj(cid:107)2  \u03c32 s  (cid:19) ,  (5.48)  for pixels within a radius (cid:107)xi \u2212 xj(cid:107) < r, where f is a feature vector that consists of intensities, colors, or oriented \ufb01lter histograms.",
        "farenzena, m., fusiello, a., and gherardi, r. (2009). 2010), can require solving non-linear least squares problems with millions of measurements (feature matches) and tens of thousands of unknown parameters (3d point positions and camera poses). ashdown, i. (1997a). analysis of human faces using a measurement-based skin re\ufb02ectance model.",
        "which has a minimum at dj = \u02c6vj \u00b7 (p \u2212 cj). kadir, t., zisserman, a., and brady, m. (2004). 368 . such panoramas can be captured by placing a camera on a boom on a tripod, or even more simply, by holding a camera at arm\u2019s length while rotating your body around a \ufb01xed axis. the input should be a grayscale or color image and the output should be a multi-banded \u25e6 \u25e6 image consisting of g0 1 and g90 .",
        "1335\u20131342, nice, france. section 2.2 describes how lighting, surface properties (figure 2.1b), and camera optics (figure 2.1c) interact in order to produce the color values that fall onto the image sensor. unit quaternions live on the unit sphere (cid:107)q(cid:107) = 1 and antipodal (opposite sign) quaternions, q and \u2212q, represent the same rotation (figure 2.6). making faces. 14.1 object detection  661  figure 14.4 learning a mixture of gaussians model for face detection (sung and poggio 1998) c(cid:13) 1998 ieee."
    ],
    "\ufb01xed pattern shot noise ampli\ufb01er dark current noise ampli\ufb01er":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "generalized shading image constraint":[
        "exposure fusion. brox, t., bregler, c., and malik, j. 2.1.5 2.1.6 lens distortions . international journal of computer vision, 1(3):211\u2013221. realistic surface reconstruction of 3d scenes from uncalibrated image sequences.",
        "szeliski, r. and torr, p. (1998). virtualized reality: constructing  virtual worlds from real scenes. exploiting the sparse derivative prior for super-resolution and image demosaicing. today, most image search engines rely mostly on textual keywords found in captions, nearby text, and \ufb01lenames, augmented by user click-through data (craswell and szummer 2007). figure 5.20 shows an actual weight matrix for which these area sums can be computed.",
        "computer vision and image understanding, 84(1):77\u2013103. poynton, in his color faq, http://www.poynton.com/ colorfaq.html, notes that the perceptually motivated l*a*b* system is qualitatively similar to the gamma-compressed r\u2019g\u2019b\u2019 system we mostly deal with, since both have a fractional power scaling (which approximates a logarithmic response) between the actual intensity values and the numbers being manipulated. the answer is yes, if you are willing to \ufb01rst segment the image into different layers and then animate each layer separately. these include:  \u2022 stitching: turning overlapping photos into a single seamlessly stitched panorama (figure 1.5a), as described in chapter 9; \u2022 exposure bracketing: merging multiple exposures taken under challenging lighting conditions (strong sunlight and shadows) into a single perfectly exposed image (figure 1.5b), as described in section 10.2; \u2022 morphing: turning a picture of one of your friends into another, using a seamless morph transition (figure 1.5c); \u2022 3d modeling: converting one or more snapshots into a 3d model of the object or person you are photographing (figure 1.5d), as described in section 12.6 \u2022 video match move and stabilization: inserting 2d pictures or 3d models into your videos by automatically tracking nearby reference points (see section 7.4.2)3 or using motion estimates to remove shake from your videos (see section 8.2.1); \u2022 photo-based walkthroughs: navigating a large collection of photographs, such as the interior of your house, by \ufb02ying between different photos in 3d (see sections 13.1.2 and 13.5.5) \u2022 face detection: for improved camera focusing as well as more relevant image searching (see section 14.1.1); \u2022 visual authentication: automatically logging family members onto your home computer as they sit down in front of the webcam (see section 14.2). note that radial distortion needs to be removed from such images before the feature points can be used for calibration.",
        "(1991). the sx(i, j) and sy(i, j) black boxes denote arbitrary interaction potentials between adjacent nodes in the random \ufb01eld, and the w(i, j) denote the data penalty functions. the answer is to plot the histogram of the individual color channels and luminance values, as shown in figure 3.7b.2 from this distribution, we can compute relevant statistics such as the minimum, maximum, and average intensity values. computer vision and image understanding, 104(2-3):178\u2013189. 2.1 geometric primitives and transformations  59  (a)  (b)  (c)  figure 2.13 radial lens distortions: (a) barrel, (b) pincushion, and (c) \ufb01sheye.",
        "figure 9.9 shows a full 3d rotational panorama unwrapped onto the surface of a sphere (szeliski and shum 1997). 744  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  figure a.2 least squares regression. 2009), level sets (faugeras and keriven 1998; pons, keriven, and faugeras 2007), polygonal meshes (fua and leclerc 1995; narayanan, rander, and kanade 1998; hernandez and schmitt 2004; furukawa and ponce 2009), and multiple depth maps (kolmogorov and zabih 2002). human and machine recognition of  faces: a survey. 1194\u20131201, nice, france."
    ],
    "rendering view interpolation":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "parameters examples smoke color halos aliasing demosaicing ray space blur removal":[
        "725  . once these have been estimated, the desired location of a 3d point xi can be estimated as the average of the backprojected 3d locations,  \u00afxi \u223c(cid:88)j  cij \u02dcxi(\u02c6xij; rj, fj)(cid:44)(cid:88)j  cij ,  (9.35)  which can be projected into each image j to obtain a target location \u00afxij. 407\u2013414. the average rank serves as an approximate measure of performance under the selected metric/statistic. a boundary-fragment-model for object detection.",
        "here, the y axis points at the north pole instead of the z axis, since we are used to viewing images taken horizontally, i.e., with the y axis pointing in the direction of the gravity vector. kutulakos, k. n. (2000). once the desired excess regions of difference have been removed, the \ufb01nal composite can be created by feathering (figure 9.14f). once the rough geometry has been estimated, more detailed offset maps can be computed for each planar face using a local plane sweep, which debevec, taylor, and malik (1996) call model-based stereo. martin, d., fowlkes, c., tal, d., and malik, j.",
        "the effects of majority are a subtle rounding of sharp corners. as we saw in our discussion of plane sweep (section 11.1.2), it is possible to resample all neighboring k images at each disparity hypothesis d into a generalized disparity space volume \u02dci(x, y, d, k). pizer, s. m., amburn, e. p., austin, j. d., cromartie, r., geselowitz, a. et al. click on a ground plane point to establish your origin and click on a point a known distance away to establish the scene scale. ieee transactions on image processing, 14(4):499\u2013520.",
        "white laser, synced scan. 2d lines. computer,  39(8):57\u201365. the \ufb01lters we have previously studied in this chapter, which involve the image with a \ufb01nite extent kernel, are known as \ufb01nite impulse response (fir). a k peters, wellesley, mas sachusetts, second edition.",
        "multilinear (tensor) image synthesis,  analysis, and recognition. yang, m.-h., kriegman, d. j., and ahuja, n. (2002). 10.4 image matting and compositing  509  difference matting. control systems and computers, 2007(2):3\u201318. a more compact representation is the radiance format (.pic, .hdr) (ward 1994), which uses a single common exponent and per-channel mantissas (10.19b)."
    ],
    "discrete order transfer example-based":[
        "in addition to computing the weight matrix using interpolation-based coarsening, additional region statistics are used to modulate the weights. the existence of multiple depth maps enables more accurate reasoning about occlusions, as regions which are occluded in one image may be visible (and matchable) in others. 844  computer vision: algorithms and applications (september 3, 2010 draft)  irani, m. and peleg, s.  (1991). in this section, we brie\ufb02y review some of the more seminal and widely cited papers in the areas of background subtraction, initialization and detection, tracking with \ufb02ow, 3d kinematic models, probabilistic models, adaptive shape modeling, and activity recognition. text-to-speech synthesis.",
        "one \ufb01nal element discussed by seitz, curless, diebel et al. kannala, j., rahtu, e., brandt, s. s., and heikkila, j. because the homography mapping the ideal target to the sensed image is estimated in the central (undistorted) part of the image, any (per-channel) shifts induced by the optics manifest themselves as a displacement in the psf centers.10 compensating for these shifts eliminates both the achromatic radial distortion and the inter-channel shifts that result in visible chromatic aberration. more complicated transforms, which are sometimes the result of mapping to xyz space and back,  (a)(b)rgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbbgbggrgrgbgrgrbg\f2.3 the digital camera  87  figure 2.31 gamma compression: (a) the relationship between the input signal luminance y and the transmitted signal y (cid:48) is given by y (cid:48) = y 1/\u03b3. instead of computing the complete dsi all at once, evaluate each plane one at a time  from front to back.",
        "it is also possible to create such animations from still pictures or paintings, by segmenting the image into separately moving regions and animating them using stochastic motion \ufb01elds (section 13.5.3). sato, y., wheeler, m., and ikeuchi, k.  (1997). unfortunately, taking image derivatives accentuates high frequencies and hence ampli\ufb01es noise, since the proportion of noise to signal is larger at high frequencies. instead, a natural way to explore a space is often to just walk through it along some prespeci\ufb01ed paths, just as museums or home tours guide users along a particular path, say down the middle of each room.13 similarly, city-level exploration can be achieved by driving down the middle of each street and allowing the user to branch at each intersection. figures 11.22a\u2013b show an example of a 3d octree model and its associated colored tree, where black nodes are interior to the model, white  \f11.6 multi-view stereo  569  (a)  (c)  (b)  (d)  figure 11.22 volumetric octree reconstruction from binary silhouettes (szeliski 1993) c(cid:13) 1993 elsevier: (a) octree representation and its corresponding (b) tree structure; (c) input image of an object on a turntable; (d) computed 3d volumetric octree model.",
        "one example of such a scheme is compressed sparse row (csr) storage. during the forward warping process, multiple pixels (which occlude one another) may land on the same destination pixel. note that because of the initial depth reversal ambiguity, both reconstructions have to be tried while calculating \u03b7j. instead of using generic feature detectors and descriptors, some authors have been investigating learning class-speci\ufb01c features (ferencz, learned-miller, and malik 2008), often using randomized forests (philbin, chum, isard et al. (3.3)  the parameters a > 0 and b are often called the gain and bias parameters; sometimes these parameters are said to control contrast and brightness, respectively (figures 3.2b\u2013c).1 the 1 an image\u2019s luminance characteristics can also be summarized by its key (average luminanance) and range  (kopf, uyttendaele, deussen et al.",
        "siggraph 2004), 23(3):292\u2013300. observe that the object-centered projection model (2.76) rxj \u00b7 pi + txj 1 + \u03b7jrzj \u00b7 pi ryj \u00b7 pi + tyj 1 + \u03b7jrzj \u00b7 pi  xji = sj  yji = sj  (7.46)  (7.47)  differs from the scaled orthographic projection model (7.40) by the inclusion of the denominator terms (1 + \u03b7jrzj \u00b7 pi).12 12 assuming that the optical center (cx, cy) lies at (0, 0) and that pixels are square. 1997) c(cid:13) 1997 ieee. estimates for  i , d2  i , d6  i , d4  2  pi= (xi,yi,zi,wi)xipjdijdidjxj\u03b8ijc\f324  computer vision: algorithms and applications (september 3, 2010 draft)  i can computed as ratios of successive d2n+2 d2 obtain a \ufb01nal estimate of d2  i (and hence di). 806  computer vision: algorithms and applications (september 3, 2010 draft)  brooks, r. a."
    ],
    "local global context faces multilevel":[
        "to make the detector run faster, a separate network operating on 30\u00d730 patches is trained to detect both faces and faces shifted by \u00b15 pixels. the associated matrix c is positive semi-de\ufb01nite  xt cx \u2265 0, \u2200x. nocedal, j. and wright, s. j. in their evaluation, mikolajczyk and schmid (2005) found that gloh, which has the best performance overall, outperforms sift by a small margin. n^vidxn^vr^dy^\u03b8i\u03c6i\u03c6r\u03b8r^^\f2.2 photometric image formation  63  most surfaces are isotropic, i.e., there are no preferred directions on the surface as far (the exceptions are anisotropic surfaces such as brushed as light transport is concerned.",
        "one way to do this is to use a general correspondence algorithm, such as optical \ufb02ow (section 8.4), but to only consider locations along the epipolar line (or to project any \ufb02ow vectors that fall off back onto the line). marroquin, j., mitter, s., and poggio, t. (1985). 64  computer vision: algorithms and applications (september 3, 2010 draft)  figure 2.16 this close-up of a statue shows both diffuse (smooth shading) and specular (shiny highlight) re\ufb02ection, as well as darkening in the grooves and creases due to reduced light visibility and interre\ufb02ections. 11.5.2 segmentation-based techniques 11.5.3 application: z-keying and background replacement . variational methods (section 3.7.1), especially those using non-quadratic (robust) norms such as the l1 norm (which is called total variation), are also often used.",
        "the resulting plot can be resampled on a regular (say, integral) s grid before further processing. model and compress the remaining portion of the lumisphere using one of the techniques suggested by wood, azuma, aldinger et al. we begin with view interpolation (section 13.1), which creates a seamless transition between a pair of reference images using one or more pre-computed depth maps. figure a.1 shows how the principal components of the covariance matrix c denote the principal axes uj of the uncertainty ellipsoid corresponding to this  point distribution and how the \u03c3j =(cid:112)\u03bbj denote the standard deviations along each axis. they devise an ef\ufb01cient way to associate suppression radii with all local maxima by \ufb01rst sorting them by their response strength and then creating a second list sorted by decreasing suppression radius (brown, szeliski, and winder 2005).",
        "this is the trickiest part of the problem, as you need to tease apart the (low-frequency) rainbow pattern and the natural image hiding behind it. wang, h. and oliensis, j. area light sources are more complicated. one approach is to \ufb01rst \ufb01nd a consensus mosaic and to then selectively compute radiances in under- and over-exposed regions (eden, uyttendaele, and szeliski 2006), as shown in figure 10.17. in their paper, they develop two different algorithms, called the swap move and the expansion move, which iterate among a series of binary labeling sub-problems to \ufb01nd a good solution (figure 3.58).",
        "this latter work also argues that blending in the log domain, i.e., using multiplicative rather than additive offsets, is preferable, as it more closely matches texture contrasts across seam boundaries. rubner, y., tomasi, c., and guibas, l. j. flowfusion: discrete-continuous optimization for optical \ufb02ow estimation. panoramic photography. if a gaussian weighting function is used (brown, szeliski, and winder 2005), this average gradient is equivalent to a \ufb01rst-order steerable \ufb01lter (section 3.2.3), i.e., it can be computed using an image convolution with the horizontal and vertical derivatives of gaussian \ufb01lter (freeman and adelson 1991)."
    ],
    "detection successive approximation matching feature":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "trilinear anisotropic \ufb01ltering references anisotropic \ufb01ltering":[
        "for alternative approaches, please see some of the more recent papers listed above. while splicing the apple and orange images together along the midline produces a noticeable cut, splining them together (as burt and adelson (1983b) called their procedure) creates a beautiful illusion of a truly hybrid fruit. 1067\u20131073, san juan, puerto rico. fischler, m. a. and firschein, o. 584 .",
        "learning opencv: computer vision with the opencv  library. (recall that the human visual system has poorer  24 if you are at a loss for questions at a conference, you can always ask why the speaker did not use a perceptual color space, such as l*a*b*. 5.6 additional reading . springer verlag, new york. westin, s. h., arvo, j. r., and torrance, k. e. (1992).",
        "girod, b., greiner, g., and niemann, h. (eds). a different approach to pixel selection and seam placement is described by agarwala, dontcheva, agrawala et al. make3d: learning 3d scene structure from a single still image. chum, o. and matas, j. the actual vision memo was authored by seymour  papert (1966) and involved a whole cohort of students.",
        "a convenient tool to analyze (and sometimes accelerate) such neighborhood operations is the fourier transform, which we cover in section 3.4. 14.2.2 active appearance and 3d shape models . calculate a color (chromaticity) distribution for these pixels. siggraph 2004), 23(3):584\u2013591. multiview registration for large data sets.",
        "arti\ufb01cial intelligence, 2:79\u2013116. for example, polynomial \ufb01tting can be written as  epls =(cid:88)i  p(cid:88)j=0 |yi \u2212 (  ajxj  i )|2,  (a.26)  while sinusoid \ufb01tting with unknown amplitude a and phase \u03c6 (but known frequency f) can be written as  esls =(cid:88)i  |yi \u2212 a sin(2\u03c0f xi + \u03c6)|2 =(cid:88)i  which is linear in (b, c). a survey on pixel-based skin color  detection techniques. all of the fourier transform properties from table 3.1 carry over to two dimensions if we replace the scalar variables x, \u03c9, x0 and a with their 2d vector counterparts x = (x, y), \u03c9 = (\u03c9x, \u03c9y), x0 = (x0, y0), and a = (ax, ay), and use vector inner products instead of multiplications. 38\u201344, killington, vt.  juan, o. and boykov, y."
    ],
    "image tion scene alignment neural networks support vector machines":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "eigenvalues feature face eigenface prior distribution inverse projective isotropic diffuse specular recall af\ufb01ne linear windowed posterior distribution square root ratios signed":[
        "computer vision and image understanding, 84(1):77\u2013103. poynton, in his color faq, http://www.poynton.com/ colorfaq.html, notes that the perceptually motivated l*a*b* system is qualitatively similar to the gamma-compressed r\u2019g\u2019b\u2019 system we mostly deal with, since both have a fractional power scaling (which approximates a logarithmic response) between the actual intensity values and the numbers being manipulated. the answer is yes, if you are willing to \ufb01rst segment the image into different layers and then animate each layer separately. these include:  \u2022 stitching: turning overlapping photos into a single seamlessly stitched panorama (figure 1.5a), as described in chapter 9; \u2022 exposure bracketing: merging multiple exposures taken under challenging lighting conditions (strong sunlight and shadows) into a single perfectly exposed image (figure 1.5b), as described in section 10.2; \u2022 morphing: turning a picture of one of your friends into another, using a seamless morph transition (figure 1.5c); \u2022 3d modeling: converting one or more snapshots into a 3d model of the object or person you are photographing (figure 1.5d), as described in section 12.6 \u2022 video match move and stabilization: inserting 2d pictures or 3d models into your videos by automatically tracking nearby reference points (see section 7.4.2)3 or using motion estimates to remove shake from your videos (see section 8.2.1); \u2022 photo-based walkthroughs: navigating a large collection of photographs, such as the interior of your house, by \ufb02ying between different photos in 3d (see sections 13.1.2 and 13.5.5) \u2022 face detection: for improved camera focusing as well as more relevant image searching (see section 14.1.1); \u2022 visual authentication: automatically logging family members onto your home computer as they sit down in front of the webcam (see section 14.2). note that radial distortion needs to be removed from such images before the feature points can be used for calibration.",
        "a simple way to compute a covariance matrix that ignores the gauge freedom (indeterminacy) is to throw away the seven smallest eigenvalues of the information matrix (inverse covariance), whose values are equivalent to the problem hessian a up to noise scaling (see section 6.1.4 and appendix b.6). multi-view stereo reconstruction and scene \ufb02ow estimation with a global image-based matching score. implement one or more of the natural image matting algorithms described in section 10.4 and compare your results to the ground truth values you computed. ieee transactions on pattern analysis and machine intelligence, 28(1):44\u201358. dataset issues in object recognition.",
        "references  901  smeulders, a. w. m., worring, m., santini, s., gupta, a., and jain, r. c. (2000). the standard operations used in binary morphology include:  \u2022 dilation: dilate(f, s) = \u03b8(c, 1); \u2022 erosion: erode(f, s) = \u03b8(c, s); \u2022 majority: maj(f, s) = \u03b8(c, s/2); \u2022 opening: open(f, s) = dilate(erode(f, s), s);  \f3.3 more neighborhood operators  129  \u2022 closing: close(f, s) = erode(dilate(f, s), s). the axis/angle representation is minimal, and hence does not require any additional constraints on the parameters (no need to re-normalize after each update). 10 http://research.microsoft.com/en-us/um/redmond/groups/ivm/vvv/. 4.1 points and patches  215  (a)  (b)  (c)  figure 4.8 interest operator responses: (a) sample image, (b) harris response, and (c) dog response.",
        "another approach might be to \ufb01nd the average value in the image, push it towards middle gray, and expand the range so that it more closely \ufb01lls the displayable values (kopf, uyttendaele, deussen et al. more \ufb01gures of this kind can be found in the paper by bobick and intille (1999). (14.9)  we can apply the eigenvalue decomposition (a.6) to represent this matrix as  m\u22121(cid:88)i=0  n\u22121(cid:88)i=0  c = u\u03bbu t =  \u03bbiuiut i ,  (14.10)  where the \u03bbi are the eigenvalues of c and the ui are the eigenvectors. morgan kaufmann  publishers, san francisco, 2nd edition. 2008; \u00a8ozuysal, calonder, lepetit et al.",
        "com/theuncannyvalley/proceedings2005/uncannyvalley.html. the phase correlation image alignment method. instead of generating a single pixel at a time, larger blocks are copied from the source texture. a simple area light source such as a \ufb02uorescent ceiling light \ufb01xture with a diffuser can be modeled as a \ufb01nite rectangular area emitting light equally in all directions (cohen and wallace 1993; sillion and puech 1994; glassner 1995). the goal is then to \ufb01nd a globally consistent set of alignment parameters that minimize the mis-registration between all pairs of images (szeliski and shum 1997; shum and szeliski 2000; sawhney and kumar 1999; coorg and teller 2000)."
    ],
    "two-frame cluster analysis feature specular morphing color physics-based biometrics image scale invariance color activity recognition alignment video compression video":[
        "4.1 points and patches  223  bias and gain normalization (mops). in seventh european conference on computer vision (eccv 2002), pp. multi-view stereo revisited. visual comparisons between their preferred approach and what they call optimal seam on the gradients (which is equivalent to the approach of agarwala, dontcheva, agrawala et al. texture and re\ufb02ection in computer generated images.",
        "this is then generalized to spline-based motion models (section 8.3) and \ufb01nally to general per-pixel optical \ufb02ow (section 8.4), including layered and learned motion models (section 8.5). batra, d., sukthankar, r., and chen, t. (2008). society for industrial  and applied mathematics, philadephia. in situations where the camera is translating a lot in 3d, e.g., when the videographer is walking, an even better approach is to compute a full structure from motion reconstruction of the camera motion and 3d scene. i\u2019m also grateful to the many other computer vision researchers who have given me so many constructive suggestions about the book, including sing bing kang, who was my informal book editor, vladimir kolmogorov, who contributed appendix b.5.5 on linear programming techniques for mrf inference, daniel scharstein, richard hartley, simon baker, noah snavely, bill freeman, svetlana lazebnik, matthew turk, jitendra malik, alyosha efros, michael black, brian curless, sameer agarwal, li zhang, deva ramanan, olga veksler, yuri boykov, carsten rother, phil torr, bill triggs, bruce maxwell, jana ko\u02c7seck\u00b4a, eero simoncelli, aaron hertzmann, antonio torralba, tomaso poggio, theo pavlidis, baba vemuri, nando de freitas, chuck dyer, song yi, falk schubert, roman p\ufb02ugfelder, marshall tappen, james coughlan, sammy rogmans, klaus strobel, shanmuganathan, andreas siebert, yongjun wu, fred pighin, juan cockburn, ronald mallet, tim soper, georgios evangelidis, dwight fowler, itzik bayaz, daniel o\u2019connor, and srikrishna bhat.",
        "149\u2013155, new orleans. 82  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  figure 2.28 standard cie color matching functions: (a) \u00afr(\u03bb), \u00afg(\u03bb), \u00afb(\u03bb) color spectra obtained from matching pure colors to the r=700.0nm, g=546.1nm, and b=435.8nm primaries; (b) \u00afx(\u03bb), \u00afy(\u03bb), \u00afz(\u03bb) color matching functions, which are linear combinations of the (\u00afr(\u03bb), \u00afg(\u03bb), \u00afb(\u03bb)) spectra. 157\u2013168, pisa, italy. the second is the idea of morphing (section 3.6.3) (figure 3.53), where correspondences between pairs of images are used to warp each reference image to an in-between location while simultaneously cross-dissolving between the two warped images. 311\u2013326, freiburg, germany.",
        "14  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (d)  (b)  (e)  (c)  (f)  figure 1.8 examples of computer vision algorithms from the 1980s: (a) pyramid blending (burt and adelson 1983b) c(cid:13) 1983 acm, (b) shape from shading (freeman and adelson 1991) c(cid:13) 1991 ieee, (c) edge detection (freeman and adelson 1991) c(cid:13) 1991 ieee, (d) physically based models (terzopoulos and witkin 1988) c(cid:13) 1988 ieee, (e) regularizationbased surface reconstruction (terzopoulos 1988) c(cid:13) 1988 ieee, (f) range data acquisition and merging (banno, masuda, oishi et al. at each iteration, set up the banded linear system of equations (quadratic energy func tion) and solve it using banded cholesky factorization (appendix a.4). bobick, a. f. (1997). 7.4 bundle adjustment  369  (a)  (b)  figure 7.10 3d augmented reality: (a) darth vader and a horde of ewoks battle it out on a table-top recovered using real-time, keyframe-based structure from motion (klein and murray 2007) c(cid:13) 2007 ieee; (b) a virtual teapot is \ufb01xed to the top of a real-world coffee cup, whose pose is re-recognized at each time frame (gordon and lowe 2006) c(cid:13) 2007 springer. ieee transactions on circuits and systems for video technology, 10(3):344\u2013358.",
        "a convenient way to get a rough model of a real-world environment map is to take an image of a re\ufb02ective mirrored sphere and to unwrap this image onto the desired environment map (debevec 1998). a better approach is to hallucinate virtual point correspondences within the areas from which each homography was computed and to feed them into a standard structure from motion algorithm (szeliski and torr 1998). it is also possible to use larger neighborhoods, such as n8, which can lead to better boundaries (boykov and kolmogorov 2003), or to use second-order smoothness terms (woodford, reid, torr et al. other good sources of recent research are courses on this topic, such as the iccv 2009 short course (fei-fei, fergus, and torralba 2009) and antonio torralba\u2019s more comprehensive mit course (torralba 2008). 1  1,500  25,000  400,000  2,000,000  figure 10.11 relative brightness of different scenes, ranging from 1 inside a dark room lit by a monitor to 2,000,000 looking at the sun."
    ],
    "compositing registration calibration natural layers motion estimation recognition recognition":[
        "the latter, which is also known as category-level or generic object recognition (ponce, hebert, schmid et al. 380\u2013387, san diego, ca. the uv plane can be placed at in\ufb01nity, which corresponds to all the virtual cameras looking in the same direction. as we mentioned in section 14.4.3, the existence of large databases of partially labeled internet imagery has given rise to a new sub-\ufb01eld of internet computer vision, with its own workshops21 and a special journal issue (avidan, baker, and shan 2010). the ambient (no-\ufb02ash) image a is \ufb01ltered with a regular bilateral \ufb01lter to produce abase, which is used in shadow and specularity regions, and a joint bilaterally \ufb01ltered noise reduced image anr.",
        "cam bridge university press. computing the voronoi diagram is one way to select the seams between regions where different images contribute to the \ufb01nal composite. 1999; cootes, edwards, and taylor 2001; gross, baker, matthews et al. the breadth of the problems and techniques inherent in this \ufb01eld, combined with the richness of the mathematics and the utility of the resulting algorithms, will ensure that this remains an exciting area of study for years to come. originally, z-keying systems required expensive custom-built hardware to produce the desired depth maps in real time and were, therefore, restricted to broadcast studio applications (kanade, yoshida, oda et al.",
        "the development of fully automated stereo matching algorithms was a major advance in this \ufb01eld, enabling much more rapid and less expensive processing of aerial imagery (hannah 1974; hsieh, mckeown, and perlant 1992). for some practical mrf problems, lp-based techniques can produce globally minimal solutions (meltzer, yanover, and weiss 2005), even though mrf inference is in general np-hard. 436  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  figure 9.5 gap closing (szeliski and shum 1997) c(cid:13) 1997 acm: (a) a gap is visible when the focal length is wrong (f = 510). (2007)  50 toys  lecun, huang, and bottou (2004)  75,000 (wordnet) things  torralba, freeman, and fergus (2008)  imagenet  http://www.image-net.org/  complete images  14,000 (wordnet) things  deng, dong, socher et al. we can do this if we represent perspective projection using a full-rank 4 \u00d7 4 matrix, as in (2.64).",
        "(a.11)  (a.12)  from this, we see that \u03bbi = \u03c32 c.  i and that the left singular vectors of a are the eigenvectors of  this relationship gives us an ef\ufb01cient method for computing the eigenvalue decomposition of large matrices that are rank de\ufb01cient, such as the scatter matrices observed in computing eigenfaces (section 14.2.1). note that the original formulation of the hough transform, which assumed no knowledge of the edgel orientation \u03b8, has an additional loop inside step 2 that iterates over all possible values of \u03b8 and increments a whole series of accumulators. an alternative approach is to estimate local color statistics in regions around each pixel (ruzon and tomasi 2001; martin, fowlkes, and malik 2004). 14.6 recognition databases and test sets  719  name / url  extents  contents / reference  face and person recognition  yale face database  centered face images  frontal faces  http://www1.cs.columbia.edu/\u223cbelhumeur/  resources for face detection  various databases  http://vision.ai.uiuc.edu/mhyang/face-detection-survey.html centered face images  feret  belhumeur, hespanha, and kriegman (1997)  faces in various poses  yang, kriegman, and ahuja (2002)  frontal faces  phillips, moon, rizvi et al. stereo matching by compact windows via minimum ratio cycle.",
        "xyx\u2019y\u2019xyx\u2019y\u2019xyx\u2019y\u2019ay\u2019yay\u2019xax\u2019xax\u2019y(a)(b)(c)major axisminor axis\f168  computer vision: algorithms and applications (september 3, 2010 draft)  pyramid (figure 3.32), where each level is pre-\ufb01ltered with a high-quality \ufb01lter rather than a poorer quality approximation, such as burt and adelson\u2019s (1983b) \ufb01ve-tap binomial. 8 this section was contributed by vladimir kolmogorov. doll`ar, p., wojek, c., schiele, b., and perona, p. (2009). technical re port aim-249, arti\ufb01cial intelligence laboratory, stanford university. we begin this chapter with the simplest kind of image transforms, namely those that manipulate each pixel independently of its neighbors (section 3.1)."
    ],
    "video video textures representations and algorithms matting video texture view-dependent layered interpolation cubic shadow animating pictures":[
        "in ninth international conference on computer vision (iccv 2003), pp. once this has been established, a suitable search technique must be devised. instead, the existence of three primaries is a result of the tri-stimulus (or trichromatic) nature of the human visual system, since we have three different kinds of cone, each of which responds selectively to a different portion of the color spectrum (glassner 1995; wyszecki and stiles 2000; fairchild 2005; reinhard, ward, pattanaik et al. it has the same effect on the amount of light reaching the sensor as doubling the exposure duration, e.g., from 1/125 to 1/250, see exercise 2.5.) the cosine law for triangle \u2206(c, pi, pj) gives us  pi = di \u02c6xi + c  fij(di, dj) = d2  i + d2  j \u2212 2didjcij \u2212 d2  ij = 0,  where  and  cij = cos \u03b8ij = \u02c6xi \u00b7 \u02c6xj  ij = (cid:107)pi \u2212 pj(cid:107)2. d2  (6.36)  (6.37)  (6.38)  (6.39)  (6.40)  we can take any triplet of constraints (fij, fik, fjk) and eliminate the dj and dk using  sylvester resultants (cox, little, and o\u2019shea 2007) to obtain a quartic equation in d2 i ,  gijk(d2  i ) = a4d8  i + a3d6  i + a2d4  i + a1d2  i + a0 = 0.",
        "newer techniques can perform the same task based purely on visual feature tracking, sometimes not even requiring a stereo camera rig (davison, reid, molton et al. in practice, a = 3/8, which results in the familiar binomial kernel,  b a b  c  c ,  1 16  1 4 6 4 1 ,  (3.83)  which is particularly easy to implement using shifts and adds. (optional) using a series of cast stick shadows, estimate the deformation \ufb01eld for the destination scene in order to correctly warp (drape) the shadows across the new geometry. gabor functions are often used for oriented and band-pass \ufb01ltering, since they can be more frequency selective than gaussian derivatives. 6.4 additional reading  hartley and zisserman (2004) provide a wonderful introduction to the topics of feature-based alignment and optimal motion estimation, as well as an in-depth discussion of camera calibration and pose estimation techniques.",
        "combined segmentation and recognition. morgan kaufmann, san francisco. once an initial 3d scene has been reconstructed, a dominant plane is estimated (in this case, the table-top) and 3d animated characters are virtually inserted. the resulting composite is sometimes called a \ufb02at panorama, since the projection onto the \ufb01nal surface is still a perspective projection, and hence straight lines remain straight (which is often a desirable attribute).12  for larger \ufb01elds of view, however, we cannot maintain a \ufb02at representation without excessively stretching pixels near the border of the image. xiong and turkowski (1998) use this voronoi idea (local maximum of the grass\ufb01re transform) to select seams for laplacian pyramid blending (which is discussed below).",
        "2003)). in subsequent frames, searching for locations where the corresponding patch has low squared difference (4.1) often works well enough. context also plays an important role in 3d inference from single images (figure 14.47), using computer vision techniques for labeling pixels as belonging to the ground, vertical surfaces, or sky (hoiem, efros, and hebert 2005a,b). compute accurate per-pixel \ufb02ow. it is is also possible to infer local shape information from specular \ufb02ow, i.e., the motion of specularities when viewed from a moving camera (oren and nayar 1997; zisserman, giblin, and blake 1989; swaminathan, kang, szeliski et al.",
        "bias and gain compensation is also used in video codecs, where it is known as weighted prediction (richardson 2003). you can \ufb01nd additional details on morphology in other textbooks on computer vision and image processing (haralick and shapiro 1992, section 5.2) (bovik 2000, section 2.2) (ritter and wilson 2000, section 7) as well as articles and books speci\ufb01cally on this topic (serra 1982; serra and vincent 1992; yuille, vincent, and geiger 1992; soille 2006). in follow-on work, fergus, fei-fei, perona et al. the results of this match computation gives us a jump table or, equivalently, a transition probability between any two frames in the original video. here, i try to come up with the best possible models of the physics of the system at hand: how the scene is created, how light interacts with the scene and atmospheric effects, and how the sensors work, including sources of noise and uncertainty."
    ],
    "inverse photometric re\ufb02ectance":[
        "if the focal plane (vertical zo gray line next to c) is moved forward, the images are no longer in focus and the circle of confusion c (small thick line segments) depends on the distance of the image plane motion \u2206zi relative to the lens aperture diameter d. the \ufb01eld of view (f.o.v.) ieee  transactions on image processing, 8(9):1221\u20131228. if the background is already known, i.e., for blue screen or difference matting applications, its measured color value and variance are used instead. store the edgels either in a 2d array (say, an integer image with indices into the edgel list) or pre-sort the edgel list \ufb01rst by (integer) x coordinates and then y coordinates, for faster neighbor \ufb01nding. the topics of projective geometry and structure from motion are extremely rich and some excellent textbooks and surveys have been written on them (faugeras and luong 2001; hartley and zisserman 2004; moons, van gool, and vergauwen 2010).",
        "using multiple segmentations to discover objects and their extent in image collections. the general optical \ufb02ow analog to equation (8.1) can thus be written as  essd\u2212of({ui}) =(cid:88)i  [i1(xi + ui) \u2212 i0(xi)]2. the reason they call their resulting pyramid a gaussian pyramid is that repeated convolutions of the binomial kernel converge to a gaussian.16  to compute the laplacian pyramid, burt and adelson \ufb01rst interpolate a lower resolution image to obtain a reconstructed low-pass version of the original image (figure 3.34b). 2004) c(cid:13) 2004 elsevier; (c) edges (elder and goldberg 2001) c(cid:13) 2001 ieee; (d) straight lines (sinha, steedly, szeliski et al. journal of the optical society of america a, 57(9):1105\u20131114.",
        "where pn is a normal (gaussian) distribution with covariance \u03c3i and  |2\u03c0\u03c3i|1/2 = (2\u03c0)m/2  \u03bb1/2 j  m(cid:89)j=1  is its volume. the \ufb01rst kind of feature that you may notice are speci\ufb01c locations in the images, such as mountain peaks, building corners, doorways, or interestingly shaped patches of snow. a collection of some of these papers can be found in the book by benosman and kang (2001). the best way to predict the amount of aliasing that an imaging system (or even an image processing algorithm) will produce is to estimate the point spread function (psf), which represents the response of a particular pixel sensor to an ideal point light source. after transform coding, the coef\ufb01cient values are quantized into a set of small integer values that can be coded using a variable bit length scheme such as a huffman code or an arithmetic code (wallace 1991).",
        "a comparative study of energy minimization methods for ieee transactions on pattern markov random \ufb01elds with smoothness-based priors. ideally, each surface triangle should select the source image where it is seen most directly (perpendicular to its normal) and at the resolution best matching the texture map resolution.14 this can be posed as a graph cut optimization problem, where the smoothness term encourages adjacent triangles to use similar source images, followed by blending to compensate for exposure differences (lempitsky and ivanov 2007; sinha, steedly, szeliski et al. figure 8.10 shows an example of the kybic and unser system being used to register a patient\u2019s brain mri with a labeled brain atlas image. (2000). van den hengel, dick, thormhlen et al.",
        "technical  report msr-tr-2006-37, microsoft research. an alternative proposed by komodakis and tziritas (2007a); komodakis, tziritas, and paragios (2007) is to search for primal and dual solutions such that they satisfy approximate complementary slackness conditions and the primal solution is already integer-valued. this convergence is not guaranteed for regular gradient descent unless appropriate step size control is used. in  computer analysis of images and patterns (caip\u201999), pp. does this invalidate the  basic compositing equation (3.8); if so, how should it be \ufb01xed?"
    ],
    "tion image normalized median connected components segmentation watershed mean shift transform image":[
        "unfortunately, computing the optimal normalized cut is np-complete. journal of machine learning research, (sumbitted). the quadric reference surface: theory and applications. gelb, a. discuss how you could handle the case of translations and rotations only (no scale).",
        "this is then generalized to spline-based motion models (section 8.3) and \ufb01nally to general per-pixel optical \ufb02ow (section 8.4), including layered and learned motion models (section 8.5). batra, d., sukthankar, r., and chen, t. (2008). society for industrial  and applied mathematics, philadephia. in situations where the camera is translating a lot in 3d, e.g., when the videographer is walking, an even better approach is to compute a full structure from motion reconstruction of the camera motion and 3d scene. i\u2019m also grateful to the many other computer vision researchers who have given me so many constructive suggestions about the book, including sing bing kang, who was my informal book editor, vladimir kolmogorov, who contributed appendix b.5.5 on linear programming techniques for mrf inference, daniel scharstein, richard hartley, simon baker, noah snavely, bill freeman, svetlana lazebnik, matthew turk, jitendra malik, alyosha efros, michael black, brian curless, sameer agarwal, li zhang, deva ramanan, olga veksler, yuri boykov, carsten rother, phil torr, bill triggs, bruce maxwell, jana ko\u02c7seck\u00b4a, eero simoncelli, aaron hertzmann, antonio torralba, tomaso poggio, theo pavlidis, baba vemuri, nando de freitas, chuck dyer, song yi, falk schubert, roman p\ufb02ugfelder, marshall tappen, james coughlan, sammy rogmans, klaus strobel, shanmuganathan, andreas siebert, yongjun wu, fred pighin, juan cockburn, ronald mallet, tim soper, georgios evangelidis, dwight fowler, itzik bayaz, daniel o\u2019connor, and srikrishna bhat.",
        "a computational model for periodic pattern perception based on frieze and wallpaper groups. 519\u2013526, new york, ny. the per-pixel gradient estimates are then integrated into a continuous \u03b1(x) \ufb01eld using the regularization (least squares) technique \ufb01rst described in section 3.7.1 (3.100) and subsequently used in poisson blending (section 9.3.4, 9.44) and gradient-based dynamic range compression mapping (section 10.2.1, 10.19). normalized correlation works well when matching images taken with different exposures, e.g., when creating high dynamic range images (section 10.2). intelligence, 28(10):1537\u20131552.",
        "sophisticated machine learning techniques are also becoming a key component of successful object detection and recognition algorithms (varma and ray 2007; felzenszwalb, mcallester, and ramanan 2008; fritz and schiele 2008; sivic, russell, zisserman et al. in order to do this, however, full hilbert transform pairs need to be used for second-order and higher \ufb01lters, as described in (freeman and adelson 1991). once the parametric motions and pixel-wise layer assignments have been computed for each frame independently, layers are constructed by warping and merging the various layer pieces from all of the frames together. i prefer students to have either an image processing or a computer graphics course as a prerequisite so that they can spend less time learning general background mathematics and more time studying computer vision techniques. weight the color and spatial scales differently, e.g., using values of (hs, hr, m) = (16, 19, 40) as shown in figure 5.18.",
        "weiss, y. and freeman, w. t.  (2001a). if we sweep the monochromatic color \u03bb parameter in figure 2.28b from \u03bb = 380nm to \u03bb = 800nm, we obtain the familiar chromaticity diagram shown in figure 2.29. b.5.3 belief propagation  belief propagation is an inference technique originally developed for trees (pearl 1988) but more recently extended to \u201cloopy\u201d (cyclic) graphs such as mrfs (frey and mackay 1997; freeman, pasztor, and carmichael 2000; yedidia, freeman, and weiss 2001; weiss and freeman 2001a,b; yuille 2002; sun, zheng, and shum 2003; felzenszwalb and huttenlocher 2006). is modi\ufb01ed so that the smoothness terms sx(x, y) and sy(x, y) in figure 3.56 and (3.113) depend on the magnitude of the gradient between adjacent pixels.25  since the smoothness term now depends on the data, bayes\u2019 rule (3.117) no longer applies. this results in perfect reconstruction when q is the identity."
    ],
    "radial distortion radial":[
        "locally adapted projections to reduce panorama distortions. the classic \ufb01ve seidel aberrations, which arise when using third-order optics, include spherical aberration, coma, astigmatism, curvature of \ufb01eld, and distortion (m\u00a8oller 1988; hecht 2001; ray 2002). c.4 bibliography . witkin, a., terzopoulos, d., and kass, m. (1986). 371\u2013378, san francisco.",
        "2007), full af\ufb01ne invariance is preferred. 334 . preattentive processing in vision. as a measure of \ufb01tness, count how many pairwise estimates are consistent with the global alignment. in the mid-1990s, image alignment techniques started being applied to the construction of wide-angle seamless panoramas from regular hand-held cameras (mann and picard 1994; chen 1995; szeliski 1996).",
        "0  f\u00a8orstner\u2013harris. acm siggraph 2000 conference proceedings, pp. by the calibration matrix k and non-linear effects such as radial distortion (section 6.3.5). kybic, j. and unser, m. (2003). 485\u2013488, montreal.",
        "sawhney and kumar (1999) use a hierarchy of motion models (translation, af\ufb01ne, projective) in a coarse-to-\ufb01ne strategy coupled with a quadratic radial distortion correction term. (2010); agarwal, snavely, seitz et al. another approach to dealing with large variability in appearance is to create view-based (view-speci\ufb01c) eigenspaces, as shown in figure 14.19 (moghaddam and pentland 1997). this depends on the motion model being used. 650  655 .",
        "evaluate the quality of the demosaicing algorithm by taking pictures of challenging  scenes which contain strong color edges (such as those shown in in section 10.3.1). (the response curves are calibrated separately for each color channel.) 2.5 exercises  97  6. note the wide range of illumination variation, which can be more dramatic than inter-personal variations. visual correspondence using energy minin ninth international conference on computer  imization and mutual information."
    ],
    "image recognition match veri\ufb01cation veri\ufb01cation visual words histogram":[
        "(2004), lazebnik, schmid, and ponce (2006), csurka, dance, perronnin et al. estimate the rotation angle and focal length from the vanishing points. the motion in this sequence is caused by the translational motion of the checkered background and the rotation of the foreground hand. vision and pattern recognition (cvpr 2009), miami beach, fl. azarbayejani, a. and pentland, a. p. (1995).",
        "this is then generalized to spline-based motion models (section 8.3) and \ufb01nally to general per-pixel optical \ufb02ow (section 8.4), including layered and learned motion models (section 8.5). batra, d., sukthankar, r., and chen, t. (2008). society for industrial  and applied mathematics, philadephia. in situations where the camera is translating a lot in 3d, e.g., when the videographer is walking, an even better approach is to compute a full structure from motion reconstruction of the camera motion and 3d scene. i\u2019m also grateful to the many other computer vision researchers who have given me so many constructive suggestions about the book, including sing bing kang, who was my informal book editor, vladimir kolmogorov, who contributed appendix b.5.5 on linear programming techniques for mrf inference, daniel scharstein, richard hartley, simon baker, noah snavely, bill freeman, svetlana lazebnik, matthew turk, jitendra malik, alyosha efros, michael black, brian curless, sameer agarwal, li zhang, deva ramanan, olga veksler, yuri boykov, carsten rother, phil torr, bill triggs, bruce maxwell, jana ko\u02c7seck\u00b4a, eero simoncelli, aaron hertzmann, antonio torralba, tomaso poggio, theo pavlidis, baba vemuri, nando de freitas, chuck dyer, song yi, falk schubert, roman p\ufb02ugfelder, marshall tappen, james coughlan, sammy rogmans, klaus strobel, shanmuganathan, andreas siebert, yongjun wu, fred pighin, juan cockburn, ronald mallet, tim soper, georgios evangelidis, dwight fowler, itzik bayaz, daniel o\u2019connor, and srikrishna bhat.",
        "13.2.1 impostors, sprites, and layers . the biggest difference from instance recognition is the absence of a geometric veri\ufb01cation stage (section 14.3.1), since individual instances of generic visual categories, such as those shown in figure 14.35, have relatively little spatial coherence to their features (but see the work by lazebnik, schmid, and  \f698  computer vision: algorithms and applications (september 3, 2010 draft)  ponce (2006)). 2004) c(cid:13) 2004 acm: (a) input color image; (b) color-based segmentation; (c) initial disparity estimates; (d) \ufb01nal piecewise-smoothed disparities; (e) mrf neighborhood de\ufb01ned over the segments in the disparity space distribution (zitnick and kang 2007) c(cid:13) 2007 springer. vincent, l. and soille, p.  (1991). kluwer  academic publishers, boston.",
        "2009; kumar, torr, and zisserman 2010), which produce some of the best results on the dif\ufb01cult pascal voc segmentation challenge (shotton, johnson, and cipolla 2008; kohli, ladick\u00b4y, and torr 2009). if someone asked you to point out the most \u201csalient\u201d or \u201cstrongest\u201d edges or the object boundaries (martin, fowlkes, and malik 2004; arbel\u00b4aez, maire, fowlkes et al. the forward models that we use in computer vision are usually developed in physics (radiometry, optics, and sensor design) and in computer graphics. wavelets provide a smooth way to decompose a signal into frequency components without blocking and are closely related to pyramids. in this chapter, we look at the topic of geometric image registration, i.e., the computation of 2d and 3d transformations that map features in one image to another (section 6.1).",
        "ex 4.15: vanishing point uncertainty perform an uncertainty analysis on your estimated vanishing points. 786  computer vision: algorithms and applications (september 3, 2010 draft)  section 14.4.1: bag of words  two bag of words classi\ufb01ers, http://people.csail.mit.edu/fergus/iccv2005/bagwords.html (fei-fei and perona 2005; sivic, russell, efros et al. 909\u2013918,  the same scene. lowe (2004) computes a 36-bin histogram of edge orientations weighted by both gradient magnitude and gaussian distance to the center, \ufb01nds all peaks within 80% of the global maximum, and then computes a more accurate orientation estimate using a three-bin parabolic \ufb01t (figure 4.12). sturm, p. and triggs, w. (1996)."
    ],
    "pipeline volumetric visibility architecture faces impostors motion compensated photometric stereo texture sensor z-keying performance-driven animation time of \ufb02ight registration alignment point-based":[
        "combining vision algorithms with general inference techniques that reason about the real world will likely lead to more breakthroughs, although some of the problems may turn out to be \u201cai-complete\u201d, in the sense that a full emulation of human experience and intelligence may be necessary. this model can then be \ufb01tted to each frame in one or more video streams either by matching silhouettes extracted from known backgrounds or by matching and tracking the locations of occluding edges (gavrila and davis 1996; kakadiaris and metaxas 2000; bregler, malik, and pullen 2004; kehl and van gool 2006). when the sampled vertical values yi are assumed to be noisy versions of points on the line y = mx + b, the optimal estimates for (m, b) can be found by minimizing the squared vertical residuals  evls =(cid:88)i  |yi \u2212 (mxi + b)|2. 540\u2013547, vancouver, canada. note that while beier and neely describe this algorithm as a forward warp, an equivalent algorithm can be written by sequencing through the destination pixels.",
        "soille, p. (2006). using dynamic programming for solving variational problems in vision. their newer system (csurka, dance, perronnin et al. international  journal of computer vision, 51(2):91\u2013109. consider the discrete analog (8.35) to the analytic global energy (8.70),  ehsd =(cid:88)i  i [j ij t ut  i ]ui + 2eij t  i ui + e2 i .",
        "in particular, for small (in\ufb01nitesimal or instantaneous) rotations and \u03b8 expressed in radians, rodriguez\u2019s formula simpli\ufb01es to  r(\u03c9) \u2248 i + sin \u03b8[\u02c6n]\u00d7 \u2248 i + [\u03b8\u02c6n]\u00d7 =\uf8ee\uf8ef\uf8f0  1 \u03c9z \u2212\u03c9y  \u2212\u03c9z 1 \u03c9x  \u03c9y \u2212\u03c9x 1  \uf8f9\uf8fa\uf8fb ,  (2.35)  \f2.1 geometric primitives and transformations  43  which gives a nice linearized relationship between the rotation parameters \u03c9 and r. we can also write r(\u03c9)v \u2248 v + \u03c9 \u00d7 v, which is handy when we want to compute the derivative of rv with respect to \u03c9,  \u2202rv  \u2202\u03c9t = \u2212[v]\u00d7 =\uf8ee\uf8ef\uf8f0  0 z \u2212y 0 \u2212z x 0 y \u2212x  \uf8f9\uf8fa\uf8fb . vision and pattern recognition (cvpr 2007), minneapolis, mn. 1999) c(cid:13) 1999 acm: (a) top view of the mouse; (b) view of the mouse showing the curved base for rocking; (c) moving the mouse pad with the other hand extends the interaction capabilities; (d) the resulting movement seen on the screen. 155\u2013170, freiburg. deriche, r. (1987).",
        "at matching time, each new feature is hashed into a bucket, and a search of nearby buckets is used to return potential candidates, which can then be sorted or graded to determine which are valid matches. for extremely large databases (millions of images or more), even more ef\ufb01cient structures based on ideas from document retrieval (e.g., vocabulary trees, (nist\u00b4er and stew\u00b4enius 2006)) can be used (section 14.3.2). area sums s (green) are computed by combining the four values at the rectangle corners (purple) (3.32). 2009; furukawa, curless, seitz et al. (2.57)  (2.58)  (2.59)  which uses independent focal lengths fx and fy for the sensor x and y dimensions.",
        "in ninth international conference on computer vision (iccv 2003), pp. once this has been established, a suitable search technique must be devised. instead, the existence of three primaries is a result of the tri-stimulus (or trichromatic) nature of the human visual system, since we have three different kinds of cone, each of which responds selectively to a different portion of the color spectrum (glassner 1995; wyszecki and stiles 2000; fairchild 2005; reinhard, ward, pattanaik et al. it has the same effect on the amount of light reaching the sensor as doubling the exposure duration, e.g., from 1/125 to 1/250, see exercise 2.5.) the cosine law for triangle \u2206(c, pi, pj) gives us  pi = di \u02c6xi + c  fij(di, dj) = d2  i + d2  j \u2212 2didjcij \u2212 d2  ij = 0,  where  and  cij = cos \u03b8ij = \u02c6xi \u00b7 \u02c6xj  ij = (cid:107)pi \u2212 pj(cid:107)2. d2  (6.36)  (6.37)  (6.38)  (6.39)  (6.40)  we can take any triplet of constraints (fij, fik, fjk) and eliminate the dj and dk using  sylvester resultants (cox, little, and o\u2019shea 2007) to obtain a quartic equation in d2 i ,  gijk(d2  i ) = a4d8  i + a3d6  i + a2d4  i + a1d2  i + a0 = 0."
    ],
    "ordering constraint monotonicity":[
        "references  803  blostein, d. and ahuja, n. (1987). if suf\ufb01cient training data is available (hua, brown, and winder 2007), it is sometimes possible to learn different thresholds for different features. edinburgh. technical report msr-tr-2010-10, microsoft research. sung and poggio (1998) and rowley, baluja, and kanade (1998a) present two of the earliest appearance-based face detectors and introduce a number of innovations that are widely used in later work by others.",
        "references  833  gong, m., yang, r., wang, l., and gong, m. (2007). pighin, f., szeliski, r., and salesin, d. h. (2002). taylor, c. j. (2008) improve on these results by combining the detector based on local appearance with a spectral (segmentation-based) dein more recent work, arbel\u00b4aez, maire, fowlkes et al. softly distributing values to adjacent histogram bins is generally a good idea in any application where histograms are being computed, e.g., for hough transforms (section 4.3.2) or local histogram equalization (section 3.1.4).",
        "however, this is actually not true. (2009); jeong, nist\u00b4er, steedly et al. figures 8.17 and 8.18 show the results of applying these techniques to two different picture frames with re\ufb02ections. (2000) or invent one of your own. 1995; sawhney and ayer 1996; massey and bender 1996; irani and anandan 1998; sawhney, arpa, kumar et al.",
        "international journal of computer vision, 80(2):189\u2013210. 2007) and panorama and location recognition (brown and lowe 2007; schindler, brown, and szeliski 2007). matching the frequency characteristics, which is equivalent to matching spatial correlations, is in itself not suf\ufb01cient. the color-dependent blurring caused by chromatic aberration (figure 2.21) can also be removed using the de-blurring techniques discussed in  10 this process confounds the distinction between geometric and photometric calibration. for higher bit depths, a table with the appropriate number of entries (probably fewer than the full number of gray levels) should be used.",
        "these square nodes can also be interpreted as factors in a factor graph version of the undirected graphical model (bishop 2006; wainwright and jordan 2008; koller and friedman 2009), which is another name for interaction potentials. crandall, d., felzenszwalb, p., and huttenlocher, d. (2005). arbel\u00b4aez, p., maire, m., fowlkes, c., and malik, j. how good are they at doing this? morgan  kaufmann."
    ],
    "estimation iterative estimation extrinsic alignment iterative camera intrinsic calibration":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "shot noise self-inverting transform sinc orthographic textbooks inpainting hole \ufb01lling":[
        "656  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (d)  (g)  (b)  (c)  (e)  (h)  (f)  (i)  figure 14.1 recognition: face recognition with (a) pictorial structures (fischler and elschlager 1973) c(cid:13) 1973 ieee and (b) eigenfaces (turk and pentland 1991b); (c) realtime face detection (viola and jones 2004) c(cid:13) 2004 springer; (d) instance (known object) recognition (lowe 1999) c(cid:13) 1999 ieee; (e) feature-based recognition (fergus, perona, and zisserman 2007); (f) region-based recognition (mori, ren, efros et al. 3.8 additional reading  if you are interested in exploring the topic of image processing in more depth, some popular textbooks have been written by lim (1990); crane (1997); gomes and velho (1997); j\u00a8ahne (1997); pratt (2007); russ (2007); burger and burge (2008); gonzales and woods (2008). 526  computer vision: algorithms and applications (september 3, 2010 draft)  telea 2004). biased anisotropic diffusion: a uni\ufb01ed regularization and diffusion  approach to edge detection. (3.29)  furthermore, each of the basis \ufb01lters, while not itself necessarily separable, can be computed using a linear combination of a small number of separable \ufb01lters (freeman and adelson 1991).",
        "modeling the shape of the scene: a holistic representation of the spatial envelope. siam reviews,  31(4):614\u2013627. (2010)  http://vis-www.cs.umass.edu/lfw/  huang, ramesh, berg et al. bregler, malik, and pullen (2004) use a full 3d model of limb and body motion, as described below. would be reduced (after applying the gamma at the receiver) in the darker regions of the signal where it was more visible (figure 2.31).22 (remember that our visual system is roughly sensitive to relative differences in luminance.)",
        "11.8 exercises  575  merge these depth maps into a coherent 3d model, e.g., using poisson surface reconstruc tion (kazhdan, bolitho, and hoppe 2006). bracewell, r. n. (1986). the basic radiosity algorithm does not take into account certain near \ufb01eld effects, such as the darkening inside corners and scratches, or the limited ambient illumination caused by partial shadowing from other surfaces. 1995), which can be extended to reason about likely patterns of occlusion (nakamura, matsuura, satoh et al. pavlovi\u00b4c, v., sharma, r., and huang, t. s. (1997).",
        "the bottom rows show the distributions of parts that make up each object. for example, the boundaries of objects, which also correspond to occlusion events in 3d, are usually delineated by visible contours. 6.5 exercises  337  3. 7.6 additional reading  7.6 additional reading  377  the topic of structure from motion is extensively covered in books and review articles on multi-view geometry (faugeras and luong 2001; hartley and zisserman 2004; moons, van gool, and vergauwen 2010). lafferty, j., mccallum, a., and pereira, f. (2001).",
        "more commonly, however, iir \ufb01lters are used inside one-dimensional separable \ufb01ltering stages to compute large-extent smoothing kernels, such as ef\ufb01cient approximations to gaussians and edge \ufb01lters (deriche 1990; nielsen, florack, and deriche 1997). (another name for the inverse covariance matrix, which is equal to the hessian in such simple cases, is the information matrix.) \u2022 a brief history \u2022 book overview \u2022 sample syllabus \u2022 notation  2 image formation  geometric primitives and transformations \u2022  photometric image formation \u2022  the digital camera  3 image processing  1  29  99  point operators \u2022 linear \ufb01ltering \u2022  more neighborhood operators \u2022 fourier transforms \u2022 pyramids and wavelets \u2022 geometric transformations \u2022  global optimization  4 feature detection and matching  205  points and patches \u2022 edges \u2022 lines  5 segmentation  mean shift and mode \ufb01nding \u2022 normalized cuts \u2022  active contours \u2022 split and merge \u2022 graph cuts and energy-based methods  6 feature-based alignment  2d and 3d feature-based alignment \u2022  pose estimation \u2022  geometric intrinsic calibration  7 structure from motion  267  309  343  triangulation \u2022 two-frame structure from motion \u2022  factorization \u2022 bundle adjustment \u2022 constrained structure and motion  n^\f8 dense motion estimation  translational alignment \u2022 parametric motion \u2022  spline-based motion \u2022 optical \ufb02ow \u2022  layered motion  9 image stitching  motion models \u2022 global alignment \u2022  compositing  381  427  10 computational photography 467 photometric calibration \u2022 high dynamic range imaging \u2022  super-resolution and blur removal \u2022 image matting and compositing \u2022 texture analysis and synthesis  11 stereo correspondence  533  epipolar geometry \u2022 sparse correspondence \u2022 dense correspondence \u2022 local methods \u2022 global optimization \u2022 multi-view stereo  12 3d reconstruction  577  shape from x \u2022 active range\ufb01nding \u2022  surface representations \u2022 point-based representations \u2022 volumetric representations \u2022 model-based reconstruction \u2022 619 13 image-based rendering  recovering texture maps and albedos  view interpolation \u2022 layered depth images \u2022  light \ufb01elds and lumigraphs \u2022 environment mattes \u2022  video-based rendering  14 recognition  655  instance recognition \u2022 category recognition \u2022  object detection \u2022 face recognition \u2022 context and scene understanding \u2022 recognition databases and test sets  \f\fpreface  the seeds for this book were \ufb01rst planted in 2001 when steve seitz at the university of washington invited me to co-teach a course called \u201ccomputer vision for computer graphics\u201d. platel, b., balmachnova, e., florack, l., and ter haar romeny, b. lowe (1989) and taubin (1995) describe techniques that compensate for this shrinkage by adding an offset term based on second derivative estimates or a larger smoothing kernel (figure 4.37b)."
    ],
    "aggregation methods segmentation-based":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "cliques belief propagation probabilistic models simulated annealing graph cuts dynamic programming graph cuts highest con\ufb01dence \ufb01rst simulated annealing uncertainty modeling":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "motion estimation stereo motion estimation motion alignment incremental planar perspective motion translational feature tracks iteratively reweighted bas-relief ambiguity motion models translational incremental re\ufb01nement panography hierarchical coarse-to-\ufb01ne motion estimation aliasing color hierarchical coarse-to-\ufb01ne":[
        "this representation has only four degrees of freedom, since l is homogeneous and also satis\ufb01es det(l) = 0, which results in a quadratic constraint on the pl\u00a8ucker coordinates. torr and fitzgibbon (2004) recommend a variant on this algorithm where the norm of the upper 2 \u00d7 2 sub-matrix of e is set to 1 and show that it has even better stability with respect to 2d coordinate transformations. for general images, kirby and sirovich (1990) call these vectors eigenpictures; for faces, turk and pentland  7 in previous chapters, we used i to indicate images; in this chapter, we use the more abstract quantities x and u  to indicate collections of pixels in an image turned into a vector. 1463\u20131470, new york city, ny. 2009), as mentioned in section 2.1.6.",
        "what happens if the glass is tinted, especially to a non-gray hue? higher-order cliques can also be used to develop more sophisticated models (potetz and lee 2008; kohli, ladick\u00b4y, and torr 2009; kohli, kumar, and torr 2009). the problem of simultaneously inferring the blur kernel and the sharp image is known as blind image deconvolution (kundur and hatzinakos 1996; levin 2006).18  given an estimate of \u02c6hk and bk(x), (10.27) can be re-written using matrix/vector notation as a large sparse least squares problem in the unknown values of the super-resolved pixels s,  (cid:88)k  (cid:107)ok \u2212 dbkw ks(cid:107)2. a qualitative approach to understanding intensities and shading variations and explaining them by the effects of image formation phenomena, such as surface orientation and shadows, was championed by barrow and tenenbaum (1981) in their paper on intrinsic images (figure 1.7d), along with the related 2 1/2 -d sketch ideas of marr (1982). we can take the  xji = \u02dcp j \u00afpi,  centroid (average) of the projected point locations xji in frame j,  \u00afxj =  1  n (cid:88)i  xji = \u02dcp j  1  n (cid:88)i  \u00afpi = \u02dcp j\u00afc,  (7.41)  where \u00afc = ( \u00afx, \u00afy , \u00afz, 1) is the augmented 3d centroid of the point cloud.",
        "this can be quite convenient in many cases since, for cameras moving around outdoors, the inverse depth to the camera is often a more well-conditioned parameterization than direct 3d distance. students may also want to look in other textbooks on computer vision for material that we do not cover here, as well as for additional project ideas (ballard and brown 1982; faugeras 1993; nalwa 1993; trucco and verri 1998; forsyth and ponce 2003). interpolate adjacent cdfs for \ufb01nal lookup. 8.1 translational alignment  397  uncertainty modeling. as you align more and more pairs, the solution may drift so that it is no longer globally consistent.",
        "2007), provide useful parameterizations for light \ufb01elds captured with panning cameras. 5 segmentation  269  image segmentation is the task of \ufb01nding groups of pixels that \u201cgo together\u201d. b.5.5 linear programming  8 many successful algorithms for mrf optimization are based on the linear programming (lp) relaxation of the energy function (weiss, yanover, and meltzer 2010). kohli, kumar, and torr (2009) and alahari, kohli, and torr (2011) develop alternative ways for dealing with higher-order cliques in the context of graph cut algorithms. ), estimate the values of some unknown structure or parameter (camera positions, object shape, etc.).",
        "over the years, a large number of datasets have been developed for testing and evaluating computer vision algorithms. (optional) write down a different least squares problem that involves pairwise matching of images. (2007)  consumer image person db  complete images  people  http://chenlab.ece.cornell.edu/people/andy/gallagherdataset.html  gallagher and chen (2008)  object recognition  caltech 101  segmentation masks http://www.vision.caltech.edu/image datasets/caltech101/  101 categories  fei-fei, fergus, and perona (2006)  caltech 256  centered objects  256 categories and clutter  http://www.vision.caltech.edu/image datasets/caltech256/  grif\ufb01n, holub, and perona (2007)  coil-100  centered objects  100 instances  http://www1.cs.columbia.edu/cave/software/softlib/coil-100.php  nene, nayar, and murase (1996)  eth-80  centered objects  http://www.mis.tu-darmstadt.de/datasets  8 instances, 10 views  leibe and schiele (2003)  instance recognition benchmark objects in various poses  2550 objects  http://vis.uky.edu/\u223cstewe/ukbench/  oxford buildings dataset  pictures of buildings  5062 images  nist\u00b4er and stew\u00b4enius (2006)  norb  tiny images  bounding box  complete images  http://www.robots.ox.ac.uk/\u223cvgg/data/oxbuildings/  http://www.cs.nyu.edu/\u223cylclab/data/norb-v1.0/  http://people.csail.mit.edu/torralba/tinyimages/  philbin, chum, isard et al. 718 . 2009; hasinoff, durand, and freeman 2010), or use coded aperture techniques to simultaneously  19 for face super-resolution, where all the images are pre-aligned, only corresponding pixels in different images  are examined."
    ],
    "focus splitting human motion body equations properties region-based physically based mean shift facial animation watershed multi-view stereo adaptive blue screen boosting multiple hypothesis digital heritage translation bandwidth selection oriented feature-based robust hierarchical model-based factorization architecture hole \ufb01lling projections scene representation recti\ufb01cation local feature analysis image-based parametric particle \ufb01ltering volumetric intelligent scissors sparse noise dynamic programming nearest neighbor":[
        "in addition to computing the weight matrix using interpolation-based coarsening, additional region statistics are used to modulate the weights. the existence of multiple depth maps enables more accurate reasoning about occlusions, as regions which are occluded in one image may be visible (and matchable) in others. 844  computer vision: algorithms and applications (september 3, 2010 draft)  irani, m. and peleg, s.  (1991). in this section, we brie\ufb02y review some of the more seminal and widely cited papers in the areas of background subtraction, initialization and detection, tracking with \ufb02ow, 3d kinematic models, probabilistic models, adaptive shape modeling, and activity recognition. text-to-speech synthesis.",
        "35\u201346, stockholm, sweden. lyu and simoncelli (2009) use gaussian scale mixtures (gsms) to construct an inhomogeneous multi-scale mrf, with one (positive exponential) gmrf modulating the variance (amplitude) of another gaussian mrf. the two-dimensional version of the dct is de\ufb01ned similarly,  f (k, l) =  n\u22121(cid:88)i=0  n\u22121(cid:88)j=0  cos(cid:18) \u03c0  n  (i +  1 2  )k(cid:19) cos(cid:18) \u03c0  n  (j +  1 2  )l(cid:19) f(i, j). 1 http://www.cs.cmu.edu/\u223ccil/vision.html, although it has not been maintained since 2004. consider, for example, the camera matrix calibration problem (section 6.2.1): given an image of a calibration pattern consisting of known 3d point positions, compute the 3\u00d7 4 camera matrix p that maps these points onto the image plane.",
        "even after convolution with a 100% \ufb01ll factor box \ufb01lter, the two signals, while no longer of the same magnitude, are still aliased in the sense that the sampled red signal looks like an inverted lower magnitude version of the blue signal. 183\u2013196, marseilles. ieee transactions on information theory, 51(11):3697\u20133717. in addition to the three color rgb channels, an alpha-matted image contains a fourth alpha channel \u03b1 (or a) that describes the relative amount of opacity or fractional coverage at each pixel (figures 3.4c and 3.5b). in general, the noise need not be gaussian and, in fact, it is usually prudent to assume that some measurements may be outliers.",
        "computer vision and image understanding, 84(1):77\u2013103. poynton, in his color faq, http://www.poynton.com/ colorfaq.html, notes that the perceptually motivated l*a*b* system is qualitatively similar to the gamma-compressed r\u2019g\u2019b\u2019 system we mostly deal with, since both have a fractional power scaling (which approximates a logarithmic response) between the actual intensity values and the numbers being manipulated. the answer is yes, if you are willing to \ufb01rst segment the image into different layers and then animate each layer separately. these include:  \u2022 stitching: turning overlapping photos into a single seamlessly stitched panorama (figure 1.5a), as described in chapter 9; \u2022 exposure bracketing: merging multiple exposures taken under challenging lighting conditions (strong sunlight and shadows) into a single perfectly exposed image (figure 1.5b), as described in section 10.2; \u2022 morphing: turning a picture of one of your friends into another, using a seamless morph transition (figure 1.5c); \u2022 3d modeling: converting one or more snapshots into a 3d model of the object or person you are photographing (figure 1.5d), as described in section 12.6 \u2022 video match move and stabilization: inserting 2d pictures or 3d models into your videos by automatically tracking nearby reference points (see section 7.4.2)3 or using motion estimates to remove shake from your videos (see section 8.2.1); \u2022 photo-based walkthroughs: navigating a large collection of photographs, such as the interior of your house, by \ufb02ying between different photos in 3d (see sections 13.1.2 and 13.5.5) \u2022 face detection: for improved camera focusing as well as more relevant image searching (see section 14.1.1); \u2022 visual authentication: automatically logging family members onto your home computer as they sit down in front of the webcam (see section 14.2). note that radial distortion needs to be removed from such images before the feature points can be used for calibration.",
        "more commonly, however, iir \ufb01lters are used inside one-dimensional separable \ufb01ltering stages to compute large-extent smoothing kernels, such as ef\ufb01cient approximations to gaussians and edge \ufb01lters (deriche 1990; nielsen, florack, and deriche 1997). (another name for the inverse covariance matrix, which is equal to the hessian in such simple cases, is the information matrix.) \u2022 a brief history \u2022 book overview \u2022 sample syllabus \u2022 notation  2 image formation  geometric primitives and transformations \u2022  photometric image formation \u2022  the digital camera  3 image processing  1  29  99  point operators \u2022 linear \ufb01ltering \u2022  more neighborhood operators \u2022 fourier transforms \u2022 pyramids and wavelets \u2022 geometric transformations \u2022  global optimization  4 feature detection and matching  205  points and patches \u2022 edges \u2022 lines  5 segmentation  mean shift and mode \ufb01nding \u2022 normalized cuts \u2022  active contours \u2022 split and merge \u2022 graph cuts and energy-based methods  6 feature-based alignment  2d and 3d feature-based alignment \u2022  pose estimation \u2022  geometric intrinsic calibration  7 structure from motion  267  309  343  triangulation \u2022 two-frame structure from motion \u2022  factorization \u2022 bundle adjustment \u2022 constrained structure and motion  n^\f8 dense motion estimation  translational alignment \u2022 parametric motion \u2022  spline-based motion \u2022 optical \ufb02ow \u2022  layered motion  9 image stitching  motion models \u2022 global alignment \u2022  compositing  381  427  10 computational photography 467 photometric calibration \u2022 high dynamic range imaging \u2022  super-resolution and blur removal \u2022 image matting and compositing \u2022 texture analysis and synthesis  11 stereo correspondence  533  epipolar geometry \u2022 sparse correspondence \u2022 dense correspondence \u2022 local methods \u2022 global optimization \u2022 multi-view stereo  12 3d reconstruction  577  shape from x \u2022 active range\ufb01nding \u2022  surface representations \u2022 point-based representations \u2022 volumetric representations \u2022 model-based reconstruction \u2022 619 13 image-based rendering  recovering texture maps and albedos  view interpolation \u2022 layered depth images \u2022  light \ufb01elds and lumigraphs \u2022 environment mattes \u2022  video-based rendering  14 recognition  655  instance recognition \u2022 category recognition \u2022  object detection \u2022 face recognition \u2022 context and scene understanding \u2022 recognition databases and test sets  \f\fpreface  the seeds for this book were \ufb01rst planted in 2001 when steve seitz at the university of washington invited me to co-teach a course called \u201ccomputer vision for computer graphics\u201d. platel, b., balmachnova, e., florack, l., and ter haar romeny, b. lowe (1989) and taubin (1995) describe techniques that compensate for this shrinkage by adding an offset term based on second derivative estimates or a larger smoothing kernel (figure 4.37b)."
    ],
    "colorization multi-view spline-based edge-preserving pipeline":[
        "goldberg, a. v. and tarjan, r. e. (1988). non-photorealistic rendering. total least squares and errors-in variables modeling, springer. p\u00b4erez, gangnet, and blake (2003) show how gradient domain reconstruction can be used to do seamless object insertion in image editing applications (figure 9.18). 206\u2013 212, san diego, ca.",
        "successive approximation . vaish, szeliski, zitnick et al. 2006; litwinowicz and williams 1994; buck, finkelstein, jacobs et al. here are some possible guidelines for constructing your test sets:  1. outlier correcton in image sequences for the af\ufb01ne camera.",
        "to only estimate disparity. brown, m. z., burschka, d., and hager, g. d. (2003). computer graphics and image processing, 8(3):313\u2013333. alternatively, generalize a previously developed connected component algorithm (ex ercise 3.14) to perform the linking in just two raster passes. reconstructing images from their gradient \ufb01elds has a long history in computer vision (horn 1986), starting originally with work in  \f460  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  (c)  figure 9.18 poisson image editing (p\u00b4erez, gangnet, and blake 2003) c(cid:13) 2003 acm: (a) the dog and the two children are chosen as source images to be pasted into the destination swimming pool.",
        "weiss, y. and freeman, w. t.  (2001a). if we sweep the monochromatic color \u03bb parameter in figure 2.28b from \u03bb = 380nm to \u03bb = 800nm, we obtain the familiar chromaticity diagram shown in figure 2.29. b.5.3 belief propagation  belief propagation is an inference technique originally developed for trees (pearl 1988) but more recently extended to \u201cloopy\u201d (cyclic) graphs such as mrfs (frey and mackay 1997; freeman, pasztor, and carmichael 2000; yedidia, freeman, and weiss 2001; weiss and freeman 2001a,b; yuille 2002; sun, zheng, and shum 2003; felzenszwalb and huttenlocher 2006). is modi\ufb01ed so that the smoothness terms sx(x, y) and sy(x, y) in figure 3.56 and (3.113) depend on the magnitude of the gradient between adjacent pixels.25  since the smoothness term now depends on the data, bayes\u2019 rule (3.117) no longer applies. this results in perfect reconstruction when q is the identity.",
        "the formulas for each of these modes are left to the reader (exercise 3.8). kang, s. b., uyttendaele, m., winder, s., and szeliski, r. (2003). another common characteristic of architecture is the repeated use of primitives such as windows, doors, and colonnades. (a) features in the query region on the left are matched to corresponding features in a highly ranked video frame. nene, s. and nayar, s. k.  (1997)."
    ],
    "windowed weighted homography normalizing superposition linear af\ufb01ne non-linear transform perimeter linear appearance variation":[
        "149\u2013155, new orleans. 82  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  figure 2.28 standard cie color matching functions: (a) \u00afr(\u03bb), \u00afg(\u03bb), \u00afb(\u03bb) color spectra obtained from matching pure colors to the r=700.0nm, g=546.1nm, and b=435.8nm primaries; (b) \u00afx(\u03bb), \u00afy(\u03bb), \u00afz(\u03bb) color matching functions, which are linear combinations of the (\u00afr(\u03bb), \u00afg(\u03bb), \u00afb(\u03bb)) spectra. 157\u2013168, pisa, italy. the second is the idea of morphing (section 3.6.3) (figure 3.53), where correspondences between pairs of images are used to warp each reference image to an in-between location while simultaneously cross-dissolving between the two warped images. 311\u2013326, freiburg, germany.",
        "inspired by this work, lazebnik, schmid, and ponce (2006) show how a similar idea can be employed to augment bags of keypoints with loose notions of 2d spatial location  getthefollowingde\ufb01nitionofapyramidmatchkernel:\u03bal(x,y)=il+l\u22121(cid:1)(cid:1)=012l\u2212(cid:1)(cid:2)i(cid:1)\u2212i(cid:1)+1(cid:3)(2)=12li0+l(cid:1)(cid:1)=112l\u2212(cid:1)+1i(cid:1).(3)boththehistogramintersectionandthepyramidmatchker-nelaremercerkernels[7].3.2.spatialmatchingschemeasintroducedin[7],apyramidmatchkernelworkswithanorderlessimagerepresentation.itallowsforpre-cisematchingoftwocollectionsoffeaturesinahigh-dimensionalappearancespace,butdiscardsallspatialin-formation.thispaperadvocatesan\u201corthogonal\u201dapproach:performpyramidmatchinginthetwo-dimensionalimagespace,andusetraditionalclusteringtechniquesinfeaturespace.1speci\ufb01cally,wequantizeallfeaturevectorsintomdiscretetypes,andmakethesimplifyingassumptionthatonlyfeaturesofthesametypecanbematchedtoonean-other.eachchannelmgivesustwosetsoftwo-dimensionalvectors,xmandym,representingthecoordinatesoffea-turesoftypemfoundintherespectiveimages.the\ufb01nalkernelisthenthesumoftheseparatechannelkernels:kl(x,y)=m(cid:1)m=1\u03bal(xm,ym).(4)thisapproachhastheadvantageofmaintainingcontinuitywiththepopular\u201cvisualvocabulary\u201dparadigm\u2014infact,itreducestoastandardbagoffeatureswhenl=0.becausethepyramidmatchkernel(3)issimplyaweightedsumofhistogramintersections,andbecausecmin(a,b)=min(ca,cb)forpositivenumbers,wecanimplementklasasinglehistogramintersectionof\u201clong\u201dvectorsformedbyconcatenatingtheappropriatelyweightedhistogramsofallchannelsatallresolutions(fig.1).forllevelsandmchannels,theresultingvectorhasdimen-sionalitym(cid:4)l(cid:1)=04(cid:1)=m13(4l+1\u22121).severalexperi-mentsreportedinsection5usethesettingsofm=400andl=3,resultingin34000-dimensionalhistogramin-tersections.however,theseoperationsareef\ufb01cientbecausethehistogramvectorsareextremelysparse(infact,justasin[7],thecomputationalcomplexityofthekernelislinearinthenumberoffeatures).itmustalsobenotedthatwedidnotobserveanysigni\ufb01cantincreaseinperformancebeyondm=200andl=2,wheretheconcatenatedhistogramsareonly4200-dimensional.1inprinciple,itispossibletointegrategeometricinformationdirectlyintotheoriginalpyramidmatchingframeworkbytreatingimagecoordi-natesastwoextradimensionsinthefeaturespace.++++++++++++++++++++++++++++++++++++level2level1level0\u00b41/4\u00b41/4\u00b41/2+++figure1.toyexampleofconstructingathree-levelpyramid.theimagehasthreefeaturetypes,indicatedbycircles,diamonds,andcrosses.atthetop,wesubdividetheimageatthreedifferentlev-elsofresolution.next,foreachlevelofresolutionandeachchan-nel,wecountthefeaturesthatfallineachspatialbin.finally,weweighteachspatialhistogramaccordingtoeq.(3).the\ufb01nalimplementationissueisthatofnormalization.formaximumcomputationalef\ufb01ciency,wenormalizeallhistogramsbythetotalweightofallfeaturesintheimage,ineffectforcingthetotalnumberoffeaturesinallimagestobethesame.becauseweuseadensefeaturerepresentation(seesection4),andthusdonotneedtoworryaboutspuri-ousfeaturedetectionsresultingfromclutter,thispracticeissuf\ufb01cienttodealwiththeeffectsofvariableimagesize.4.featureextractionthissectionbrie\ufb02ydescribesthetwokindsoffeaturesusedintheexperimentsofsection5.first,wehaveso-called\u201cweakfeatures,\u201dwhichareorientededgepoints,i.e.,pointswhosegradientmagnitudeinagivendirectionex-ceedsaminimumthreshold.weextractedgepointsattwoscalesandeightorientations,foratotalofm=16chan-nels.wedesignedthesefeaturestoobtainarepresentationsimilartothe\u201cgist\u201d[21]ortoaglobalsiftdescriptor[12]oftheimage.forbetterdiscriminativepower,wealsoutilizehigher-dimensional\u201cstrongfeatures,\u201dwhicharesiftdescriptorsof16\u00d716pixelpatchescomputedoveragridwithspacingof8pixels.ourdecisiontouseadenseregulargridin-steadofinterestpointswasbasedonthecomparativeevalu-ationoffei-feiandperona[4],whohaveshownthatdensefeaturesworkbetterforsceneclassi\ufb01cation.intuitively,adenseimagedescriptionisnecessarytocaptureuniformre-gionssuchassky,calmwater,orroadsurface(todealwithlow-contrastregions,weskiptheusualsiftnormalizationprocedurewhentheoverallgradientmagnitudeofthepatchistooweak).weperformk-meansclusteringofarandomsubsetofpatchesfromthetrainingsettoformavisualvo-cabulary.typicalvocabularysizesforourexperimentsarem=200andm=400. hasinoff, s. w., durand, f., and freeman, w. t. (2010). the problem with this \u201cbrute force\u201d approach is that, for higher dimensions, it becomes computationally prohibitive to evaluate f(x) over the complete search space.10 instead, mean shift uses a variant of what is known in the optimization literature as multiple restart gradient descent. 774\u2013781, hilton head island. cambridge university press, cambridge.",
        "4  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (c)  (b)  (d)  figure 1.3 some common optical illusions and what they might tell us about the visual system: (a) the classic m\u00a8uller-lyer illusion, where the length of the two horizontal lines appear different, probably due to the imagined perspective effects. 382  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (c)  (e)  (b)  \ufb02ow  initial layers \ufb01nal layers  layers with pixel assignments and \ufb02ow  (d)  (f)  figure 8.1 motion estimation: (a\u2013b) regularization-based optical \ufb02ow (nagel and enkelmann 1986) c(cid:13) 1986 ieee; (c\u2013d) layered motion estimation (wang and adelson 1994) c(cid:13) 1994 ieee; (e\u2013f) sample image and ground truth \ufb02ow from evaluation database (baker, black, lewis et al. hershberger and snoeyink (1992) provide a more ef\ufb01cient implementation and also cite some of the other related work in this area. compute and plot the focus distance zo as a function of the distance traveled from the focal length \u2206zi = f \u2212 zi for a lens of focal length f (say, 100mm). an alternative approach is to re-cast the problem in a segmentation framework, where the energy measures the consistency of the image statistics (e.g., color, texture, motion) inside and outside the segmented regions (cremers, rousson, and deriche 2007; rousson and paragios 2008; houhou, thiran, and bresson 2008).",
        "in ieee computer society conference on computer vision and pattern recognition (cvpr\u201986), pp. if you have any suggestions for improving the book, please send me an e-mail, as i would  like to keep the book as accurate, informative, and timely as possible. for more information on level sets and their applications, please see the collection of papers edited by osher and paragios (2003) as well as the series of workshops on variational and level set methods in computer vision (paragios, faugeras, chan et al. ex 14.2: determining the threshold for adaboost given a set of function evaluations on the training examples xi, fi = f(xi) \u2208 \u00b11, training labels yi \u2208 \u00b11, and weights wi \u2208 (0, 1),  \f726  computer vision: algorithms and applications (september 3, 2010 draft)  as explained in algorithm 14.1, devise an ef\ufb01cient algorithm to \ufb01nd values of \u03b8 and s = \u00b11 that maximize (14.43)  wiyih(sfi, \u03b8),  (cid:88)i  where h(x, \u03b8) = sign(x \u2212 \u03b8). 1999) c(cid:13) 1999 ieee: shaded images, (a\u2013b) with light from in front (0, 0, 1) and (c\u2013d) with light the front right (1, 0, 1); (e\u2013f) corresponding shape from shading reconstructions using the technique of tsai and shah (1994).",
        "at matching time, each new feature is hashed into a bucket, and a search of nearby buckets is used to return potential candidates, which can then be sorted or graded to determine which are valid matches. for extremely large databases (millions of images or more), even more ef\ufb01cient structures based on ideas from document retrieval (e.g., vocabulary trees, (nist\u00b4er and stew\u00b4enius 2006)) can be used (section 14.3.2). area sums s (green) are computed by combining the four values at the rectangle corners (purple) (3.32). 2009; furukawa, curless, seitz et al. (2.57)  (2.58)  (2.59)  which uses independent focal lengths fx and fy for the sensor x and y dimensions."
    ],
    "optical \ufb02ow image-based rendering segmentation stereo":[
        "consensus surfaces for modeling 3d in sixth international conference on computer  objects from multiple range images. 2006), with (nagel 1986; barron, fleet, and beauchemin 1994; baker, black, lewis et al. this manifests itself in (8.39) as a rank-de\ufb01cient matrix a, i.e., one whose smaller eigenvalue is very close to zero.9  when equation (8.39) is solved, the component of the displacement along the edge is very poorly conditioned and can result in wild guesses under small noise perturbations. the simplest such choice is the square root of the diagonal matrix s = d1/2, with d = diag(c). (2007) and blake, rother, brown et al.",
        "in  acm siggraph 1996 conference proceedings, pp. f\u00a8orstner (1986) and harris and stephens  \f4.1 points and patches  213  figure 4.6 uncertainty ellipse corresponding to an eigenvalue analysis of the autocorrelation matrix a. repeat the above experiment with a \u201cpillbox\u201d (disc) blurring kernel, which is characteristic of a \ufb01nite aperture lens (section 2.2.3). 1998) c(cid:13) 1998 acm; (d) surface light \ufb01eld (wood, azuma, aldinger et al. ieee transactions on pattern analysis and machine intelligence, 14(2):125\u2013145.",
        "0  f\u00a8orstner\u2013harris. acm siggraph 2000 conference proceedings, pp. by the calibration matrix k and non-linear effects such as radial distortion (section 6.3.5). kybic, j. and unser, m. (2003). 485\u2013488, montreal.",
        "kang, s. b., szeliski, r., and uyttendaele, m.  (2004). fergus, r., perona, p., and zisserman, a.  fergus, r., fei-fei, l., perona, p., and zisserman, a. 587  the time it takes to scan an object using a light stripe technique is proportional to the number of depth planes used, which is usually comparable to the number of pixels across an image. in acm sig graph 1994 conference proceedings, pp. 571\u2013577.",
        "as we continue to capture and manipulate increasingly larger quantities of visual data, research into these aspects of image-based modeling and rendering will continue to evolve. they compare a number of feature detectors (harris\u2013laplace (mikolajczyk and schmid 2004) and laplacian (lindeberg 1998b)), descriptors (sift, rift, and spin (lazebnik, schmid, and ponce 2005)), and svm kernel functions. enhancing resolution along multiple imaging dimensions using assorted pixels. in interactive applications, a variety of user-placed constraints can also be added, e.g.,  attractive (spring) forces towards anchor points d(i),  espring = ki(cid:107)f(i) \u2212 d(i)(cid:107)2,  (5.6)  as well as repulsive 1/r (\u201cvolcano\u201d) forces (figure 5.2a). over the years, a number of different techniques have been developed for reconstructing surface shape from pro\ufb01le curves (giblin and weiss 1987; cipolla and blake 1992; vaillant and faugeras 1992; zheng 1994; boyer and berger 1997; szeliski and weiss 1998)."
    ],
    "global alignment motion estimation optical \ufb02ow alignment optical \ufb02ow optical blur whiteboard and document scanning video summarization panography formats global parametric transform rotations and scale gap closing gamma global and local":[
        "324 . a key advantage of keypoints is that they permit matching even in the presence of clutter (occlusion) and large scale and orientation changes. one way to eliminate blocking artifacts is to use a moving window, i.e., to recompute the histogram for every m \u00d7 m block centered at each pixel. (a.14)  this \ufb01nal step is essentially computing the eigenfaces as linear combinations of the difference images (turk and pentland 1991a). if we divide the xyz values by the sum of x+y+z, we obtain the chromaticity coordi nates  x =  x  x + y + z  , y =  y  x + y + z  , z =  z  x + y + z  ,  (2.104)  which sum up to 1.",
        "237\u2013243, san juan, puerto rico. as figure 3.38 demonstrates, rather than \ufb01rst \ufb01ltering the whole input sequence (image)  hl\u21932\u21932l1qfi\u21912\u21912lh0hh0hl0lh0hh0hl0l1hh\u21932hl1lh0hh0hl0hv\u21932vlv\u21932vlh\u21932hhv\u21932vlv\u21932vl1lh0hh0hl0qqqfh\u21912hfv\u21912viv\u21912vih\u21912hfv\u21912viv\u21912v\f3.5 pyramids and wavelets  157  (a)  (b)  figure 3.38 one-dimensional wavelet transform: (a) usual high-pass + low-pass \ufb01lters followed by odd (\u2193 2o) and even (\u2193 2e) downsampling; (b) lifted version, which \ufb01rst selects the odd and even subsequences and then applies a low-pass prediction stage l and a high-pass correction stage c in an easily reversible manner. zhang, z., deriche, r., faugeras, o., and luong, q. because of the linearity of the fourier transform, we can write  o(\u03c9x, \u03c9y) = s(\u03c9x, \u03c9y) + n(\u03c9x, \u03c9y),  (3.67)  where each quantity in the above equation is the fourier transform of the corresponding image. (2001) describes how to select such pixels by combining a number of \ufb01delity criteria, including epipole consistency (distance of rays to a source camera\u2019s center), angular deviation (similar incidence direction on the surface), resolution (similar sampling density along the surface), continuity (to nearby pixels), and consistency (along the ray).",
        "stanley, the robot that won the darpa grand challenge. 536  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  (c)  (d)  (e)  (f)  (g)  (h)  (i)  (j)  figure 11.2 applications of stereo vision: (a) input image, (b) computed depth map, and (c) new view generation from multi-view stereo (matthies, kanade, and szeliski 1989) c(cid:13) 1989 springer; (d) view morphing between two images (seitz and dyer 1996) c(cid:13) 1996 acm; (e\u2013f) 3d face modeling (images courtesy of fr\u00b4ed\u00b4eric devernay); (g) z-keying live and computergenerated imagery (kanade, yoshida, oda et al. one of the most signi\ufb01cant extensions is to construct 3d models of shape (matthews, xiao, and baker 2007), which are much better at capturing and explaining the full variability of facial appearance across wide changes in pose. siggraph 2005), 24(3):756\u2013764. figure 4.43 2d line equation expressed in terms of the normal \u02c6n and distance to the origin d.  where each edgel votes for a number of possible orientation or location pairs centered around the estimate orientation, may be desirable in some cases.",
        "149\u2013155, new orleans. 82  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  figure 2.28 standard cie color matching functions: (a) \u00afr(\u03bb), \u00afg(\u03bb), \u00afb(\u03bb) color spectra obtained from matching pure colors to the r=700.0nm, g=546.1nm, and b=435.8nm primaries; (b) \u00afx(\u03bb), \u00afy(\u03bb), \u00afz(\u03bb) color matching functions, which are linear combinations of the (\u00afr(\u03bb), \u00afg(\u03bb), \u00afb(\u03bb)) spectra. 157\u2013168, pisa, italy. the second is the idea of morphing (section 3.6.3) (figure 3.53), where correspondences between pairs of images are used to warp each reference image to an in-between location while simultaneously cross-dissolving between the two warped images. 311\u2013326, freiburg, germany.",
        "the segment is bounded at one end by the projection of the original viewing ray at in\ufb01nity p and at the other end by the projection of the original camera center c0 into the second camera, which is known as the epipole e1. in second european workshop on 3d structure from multiple images of large-scale environments (smile 2000), pp. ex 5.3: intelligent scissors implement the intelligent scissors (live-wire) interactive segmentation algorithm (mortensen and barrett 1995) and design a graphical user interface (gui) to let you draw such curves over an image and use them for segmentation. ruzon, m. a. and tomasi, c. (2000). figure 8.16 shows the \ufb01nal results obtained with this algorithm."
    ],
    "cascaded transform af\ufb01ne":[
        "(2009) uses unary (pixelwise) potentials based on image-speci\ufb01c color distributions (section 5.5) (boykov and jolly 2001; rother, kolmogorov, and blake 2004), location information (e.g., foreground objects are more likely to be in the middle of the image, sky is likely to be higher, and road is likely to be lower), and novel texture-layout classi\ufb01ers trained using shared boosting. off-line systems were also developed for estimating 3d multi-viewpoint geometry from video streams (section 13.5.4) (kanade, rander, and narayanan 1997; carranza, theobalt, magnor et al. an early example of using implicit functions to model 3d objects in computer vision are superquadrics, which are a generalization of quadric (e.g., ellipsoidal) parametric volumetric models,  f (x, y, z) =(cid:32)(cid:18) x  a1(cid:19)2/\u00012  a2(cid:19)2/\u00012(cid:33)\u00012/\u00011 +(cid:18) y  +(cid:18) x a1(cid:19)2/\u00011  \u2212 1 = 0  (12.8)  (pentland 1986; solina and bajcsy 1990; waithe and ferrie 1991; leonardis, jakli\u02c7c, and solina 1997). 18  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (d)  (b)  (e)  (c)  (f)  figure 1.10 recent examples of computer vision algorithms: (a) image-based rendering (gortler, grzeszczuk, szeliski et al. recovering the position and orientation of free-form objects from image contours using 3-d distance maps.",
        "instead, it gives a recipe, i.e., convolve the \ufb01lter with a sinusoid, observe the magnitude and phase shift, repeat. (8.28)  the desired rotation can then be estimated using a fast fourier transform (fft) shift-based technique. 1995) or a geometry image (section 12.3.3) (gu, gortler, and hoppe 2002). b.1 estimation theory  b.1 estimation theory  757  the study of such inference problems from noisy data is often called estimation theory (gelb 1974), and its extension to problems where we explicitly choose a loss function is called statistical decision theory (berger 1993; hastie, tibshirani, and friedman 2001; bishop 2006; robert 2007). porter, t. and duff, t.  (1984).",
        "finding groups in data: an introduction to  cluster analysis. how well does your algorithm do against local aggregation (yoon and kweon 2006)? determining the best bandwidth parameters h to use with mean shift remains something of an art, although a number of approaches have been explored. for example, simon, snavely, and seitz (2007) show how the match graph between images of popular tourist sites  \f626  computer vision: algorithms and applications (september 3, 2010 draft)  can be used to \ufb01nd the most iconic (commonly photographed) objects in the collection, along with their related tags. appendix b: bayesian modeling and inference  middlebury source code for mrf minimization, http://vision.middlebury.edu/mrf/ code/ (szeliski, zabih, scharstein et al.",
        "blanz and vetter (1999) describe a system where they \ufb01rst capture a set of 200 colored range scans of faces (figure 12.19a), which can be represented as a large collection of (x, y, z, r, g, b) samples (vertices).9 in order for 3d morphing to be meaningful, corresponding vertices in different people\u2019s scans must \ufb01rst be put into correspondence (pighin, hecker, lischinski et al. international journal of computer vision, 49(2/3):117\u2013141. the process of copying a pixel f(x) to a location x(cid:48) in g is not well de\ufb01ned when x(cid:48) has a non-integer value. more precisely, the frequency of occurrence of particular words in a document is used to quickly \ufb01nd documents that match a particular query. lempitsky, roth, and rother.",
        "crc press. (2009)  labelme dataset  polygonal boundary  >500 categories  http://labelme.csail.mit.edu/  russell, torralba, murphy et al. while all of these global illumination effects can have a strong effect on the appearance of a scene, and hence its 3d interpretation, they are not covered in more detail in this book. for example, in large structure from motion problems, a large sparse hessian normally results in a full dense covariance matrix. algebraic multigrid theory: the symmetric case."
    ],
    "rotation invariance power spectrum similarity af\ufb01ne bias and gain weighting balance inliers matching region patch photometric linear":[
        "in fourth international conference on computer vision (iccv\u201993), pp. mcmillan, l. and bishop, g.  (1995). this \ufb01gure shows the (x, y) value for every color value perceivable by most humans. 390\u2013397, san diego, ca. again, because of the large number of papers published on this topic, rather than citing them here, we refer you to the material in section 11.6.1, the survey by seitz, curless, diebel et al.",
        "plenoptic modeling: an image-based rendering  system. high-accuracy stereo depth maps using structured light. sivic and zisserman (2003) perform this mapping using k-means clustering, while some of newer methods discussed below (nist\u00b4er and stew\u00b4enius 2006; philbin, chum, isard et al. unfortunately, the icp algorithm and its variants can only \ufb01nd a locally optimal alignment between 3d surfaces. multigrid.",
        "(8.3)  1 the usual justi\ufb01cation for using least squares is that it is the optimal estimate with respect to gaussian noise. the lumigraph. once a resampling rate has been speci\ufb01ed, a fractional pyramid level is computed using  the base 2 logarithm,  l = log2 r.  (3.91) one simple solution is to resample the texture from the next higher or lower pyramid level, depending on whether it is preferable to reduce aliasing or blur. animating images with drawings. high performance imaging using large camera arrays.",
        "to reduce the zippering effect, most techniques use the edge or  \f10.3 super-resolution and blur removal  503  figure 10.34 bayer rgb pattern: (a) color \ufb01lter array layout; (b) interpolated pixel values, with unknown (guessed) values shown as lower case. smith, a. r. and blinn, j. f.  (1996). radiosity and realistic image synthesis. weiss, y. under these conditions, we can reduce the 5d plenoptic function to  4 since we are counting dimensions, we ignore for now any sampling or resolution issues.",
        "once the two meshes have been speci\ufb01ed, intermediate warps can be generated using linear interpolation and the displacements at mesh nodes can be interpolated using splines. symbolic reasoning among 3-d models and 2-d images. how do these relate  to exposure values (evs)? multi-view stereo via graph cuts on the dual of an adaptive tetrahedral mesh. 11.5.3 application: z-keying and background replacement ."
    ],
    "neighborhood forward":[
        "the algorithm can be initialized by randomly sampling k centers from the input feature vectors. ex 11.11: shape from silhouettes build a silhouette-based volume reconstruction algorithm (section 11.6.2). when the cameras are calibrated, the \ufb01ve-point algorithm of nist\u00b4er (2004) can be used in conjunction with ransac to obtain initial reconstructions from the minimum number of points. 13 when a dslr chip does not \ufb01ll the 35mm full frame, it results in a multiplier effect on the lens focal length. applications to non-rigid or elastic deformations (bookstein 1989; szeliski and lavall\u00b4ee 1996; torresani, hertzmann, and bregler 2008) are examined in sections 8.3 and 12.6.4.  yxsimilarityeuclideanaffineprojectivetranslation\f312  computer vision: algorithms and applications (september 3, 2010 draft)  transform  matrix  parameters p  jacobian j  translation  euclidean  similarity  af\ufb01ne  projective  tx  tx  b  s\u03b8  c\u03b8  0 1  (cid:34) 1 0 tx ty (cid:35) ty (cid:35) (cid:34) c\u03b8 \u2212s\u03b8 (cid:34) 1 + a \u2212b 1 + a ty (cid:35) (cid:34) 1 + a00 ty (cid:35) \uf8ee\uf8ef\uf8f0 \uf8f9\uf8fa\uf8fb  h02 1 + h11 h12 1  1 + h00  1 + a11  h10 h20  h01  h21  a01  a10  tx  (tx, ty)  (tx, ty, \u03b8)  (tx, ty, a, b)  (tx, ty, a00, a01, a10, a11)  0  0  (cid:34) 1 (cid:34) 1 (cid:34) 1 (cid:34) 1  0  0  0  1 (cid:35) c\u03b8x \u2212 s\u03b8y (cid:35) 0 \u2212s\u03b8x \u2212 c\u03b8y 1 x (cid:35) 0 x \u2212y 1 0 x y (cid:35)  0 x y 1  0  0  0  y  (h00, h01, .",
        "robust error metrics. interna tional journal of computer vision, 28(2):155\u2013174. (a)  (b)  (c)  figure 10.32 example-based super-resolution: (a) original 32 \u00d7 32 low-resolution image; (b) example-based super-resolved 256 \u00d7 256 image (freeman, jones, and pasztor 2002) c(cid:13) 2002 ieee; (c) upsampling via imposed edge statistics (fattal 2007) c(cid:13) 2007 acm. rioux, m., bechthold, g., taylor, d., and duggan, m. (1987). bolles, r. c., baker, h. h., and hannah, m. j.",
        "acm transactions on graphics, 18(1):1\u201334. pyramid match hashing: sub-linear time indexing over partial correspondences. in international conference on image processing (icip-2000), pp. however, rather than being projected orthogonally to this plane, they are projected parallel to the line of sight to the object center (figure 2.7d). to ensure that overlapping patches are similar in appearance, a markov random \ufb01eld is used and optimized using either belief propagation (freeman, pasztor, and carmichael 2000) or a raster-scan deterministic variant (freeman, jones, and pasztor 2002).",
        "the resulting plot can be resampled on a regular (say, integral) s grid before further processing. model and compress the remaining portion of the lumisphere using one of the techniques suggested by wood, azuma, aldinger et al. we begin with view interpolation (section 13.1), which creates a seamless transition between a pair of reference images using one or more pre-computed depth maps. figure a.1 shows how the principal components of the covariance matrix c denote the principal axes uj of the uncertainty ellipsoid corresponding to this  point distribution and how the \u03c3j =(cid:112)\u03bbj denote the standard deviations along each axis. they devise an ef\ufb01cient way to associate suppression radii with all local maxima by \ufb01rst sorting them by their response strength and then creating a second list sorted by decreasing suppression radius (brown, szeliski, and winder 2005).",
        "the early work in simultaneously recovering 3d structure and camera motion (see chapter 7) also began around this time (ullman 1979; longuet-higgins 1981). references  821  dork\u00b4o, g. and schmid, c. (2003). rowland, d. a. and perrett, d. i. in these games, people help each other guess the identity of a hidden image by giving textual clues as to its contents, which implicitly labels either the whole image or just regions. notice, however, that minimizing(cid:80)i(aix)2 in (a.35) is only statistically optimal (ap pendix b.1.1) if all of the measured terms in the ai, e.g., the (xi, yi, 1) measurements, have equal noise."
    ],
    "compound color balance patch feature":[
        "442\u2013447, santa barbara. (see the discussion of related techniques in section 14.3.2.) li, s. z. and jain, a. k. (eds). in advances in neural information processing systems. (2008) show how to mitigate quantization problems in visual words selection using soft assignment, where each feature descriptor is mapped to a number of visual words based on its distance from the cluster prototypes.",
        "10.3 super-resolution and blur removal  10.2 high dynamic range imaging . 11 tomasi and kanade (1992) \ufb01rst take the square root of \u03c3 and distribute this to u and v , but there is no  particular reason to do this. other techniques that use part-based recognition include those developed by dork\u00b4o and schmid (2003) and bar-hillel, hertz, and weinshall (2005). context by region ancestry. 447\u2013454, kauai, hawaii.",
        "in  british machine vision conference, pp. database construction (off-line)  (a) compute term frequencies for the visual word in each image, document fre quencies for each word, and normalized tf-idf vectors for each document. (10.8)  (in order to remove the overall shift ambiguity in the response curve and irradiance values, the middle of the response curve is set to 0.) for more general motion of patches or images, the parametric motion estimator described in section 8.2 or the feature-based approaches described in section 6.1 need to be used. see if you can come up with a model for what your camera does, e.g., whether it treats color balance as a diagonal or full 3 \u00d7 3 matrix multiply, whether it uses non-linearities in addition to gamma, whether it sharpens the image while \u201cdeveloping\u201d the jpeg image, etc.",
        "either average all of the matched pixels or choose the sharpest image, if trying to compensate for blur. diffuse re\ufb02ection also often imparts a strong body color to the light since it is caused by selective absorption and re-emission of light inside the object\u2019s material (shafer 1985; glassner 1995). to prevent aliasing, we need to pre-\ufb01lter the image f(x) with a \ufb01lter whose frequency response is the projection of the \ufb01nal desired spectrum through the a\u2212t transform (szeliski, winder, and uyttendaele 2010). lempitsky, v., roth, s., and rother., c. (2008). we begin in section 11.1 with a review of the geometry of stereo image matching, i.e., how to compute for a given pixel in one image the range of possible locations the pixel might appear at in the other image, i.e., its epipolar line.",
        "2007), full af\ufb01ne invariance is preferred. 334 . preattentive processing in vision. as a measure of \ufb01tness, count how many pairwise estimates are consistent with the global alignment. in the mid-1990s, image alignment techniques started being applied to the construction of wide-angle seamless panoramas from regular hand-held cameras (mann and picard 1994; chen 1995; szeliski 1996)."
    ],
    "re\ufb02ections head constrained transparency motion points planes":[
        "the resulting plot can be resampled on a regular (say, integral) s grid before further processing. model and compress the remaining portion of the lumisphere using one of the techniques suggested by wood, azuma, aldinger et al. we begin with view interpolation (section 13.1), which creates a seamless transition between a pair of reference images using one or more pre-computed depth maps. figure a.1 shows how the principal components of the covariance matrix c denote the principal axes uj of the uncertainty ellipsoid corresponding to this  point distribution and how the \u03c3j =(cid:112)\u03bbj denote the standard deviations along each axis. they devise an ef\ufb01cient way to associate suppression radii with all local maxima by \ufb01rst sorting them by their response strength and then creating a second list sorted by decreasing suppression radius (brown, szeliski, and winder 2005).",
        "ex 3.21: wavelet construction and applications implement one of the wavelet families described in section 3.5.4 or by simoncelli and adelson (1990b), as well as the basic laplacian pyramid (exercise 3.19). an adequate model of 3d lines can be obtained by estimating their direction (which may be known ahead of time, e.g., for architecture) and some point within the visible portion of the line (see section 7.5.1) or by using the two endpoints, since lines are most often visible as \ufb01nite line segments. sch\u00a8odl, a. and essa, i. 2005; komodakis and tziritas 2007b; wexler, shechtman, and irani 2007). edge, junction, and corner detection using color distributions.",
        "gai, j. and kang, s. b. http://www. in practice, a small number of levels, i.e., as few as two (brown and lowe 2007), may be adequate to compensate for differences in exposure. get out an old rubik\u2019s cube (or get one from your parents). once a binary or multi-valued image has been segmented into its connected components, it is often useful to compute the area statistics for each individual region r. such statistics include:  \u2022 the area (number of pixels); \u2022 the perimeter (number of boundary pixels); \u2022 the centroid (average x and y values); \u2022 the second moments,  m = (cid:88)(x,y)\u2208r  y \u2212 y (cid:35)(cid:104) x \u2212 x y \u2212 y (cid:105) , (cid:34) x \u2212 x  (3.46)  from which the major and minor axis orientation and lengths can be computed using eigenvalue analysis.7  these statistics can then be used for further processing, e.g., for sorting the regions by the area size (to consider the largest regions \ufb01rst) or for preliminary matching of regions in different images.",
        "newer techniques can perform the same task based purely on visual feature tracking, sometimes not even requiring a stereo camera rig (davison, reid, molton et al. in practice, a = 3/8, which results in the familiar binomial kernel,  b a b  c  c ,  1 16  1 4 6 4 1 ,  (3.83)  which is particularly easy to implement using shifts and adds. (optional) using a series of cast stick shadows, estimate the deformation \ufb01eld for the destination scene in order to correctly warp (drape) the shadows across the new geometry. gabor functions are often used for oriented and band-pass \ufb01ltering, since they can be more frequency selective than gaussian derivatives. 6.4 additional reading  hartley and zisserman (2004) provide a wonderful introduction to the topics of feature-based alignment and optimal motion estimation, as well as an in-depth discussion of camera calibration and pose estimation techniques.",
        "in more recent work, felzenszwalb, mcallester, and ramanan (2008) extend the his togram of oriented gradients person detector to incorporate \ufb02exible parts models (section 14.4.2). siggraph 2002), 21(3):309\u2013312. in addition, it is common to add a stage for radial distortion parameter estimation (2.78),  f rd(x) = (1 + \u03ba1r2 + \u03ba2r4)x,  (7.50)  if the cameras being used have not been pre-calibrated, as shown in figure 7.7. replacing the single camera with two or more cameras enables a virtual view to be constructed right at the position where they are looking resulting in virtual eye contact. 2006) as data terms, or implicitly, because even pixel-wise disparity costs look at several pixels in either the left or right image (barnard 1989; boykov, veksler, and zabih 2001)."
    ],
    "scale selection smoothing":[
        "durand, f. and dorsey, j. nonlocal image and movie denoising. aggregation is done by summing the matching cost over square windows with constant  disparity. 163 . in many instances, recognition depends heavily on the context of surrounding objects and scene elements (section 14.5).",
        "(to do the latter, you may need to use simulated data.) many global methods are formulated in an energy-minimization framework, where, as we saw in sections 3.7 (3.100\u20133.102) and 8.4, the objective is to \ufb01nd a solution d that minimizes a global energy,  e(d) = ed(d) + \u03bbes(d). 2008; xu, chen, and jia 2008; lempitsky, roth, and rother. figure 9.16 shows the photomontage system developed by agarwala, dontcheva, agrawala  et al. consider for example the set of photographs in figure 14.35, which shows objects taken from 10 different visual categories.",
        "active shape models\u2014their  training and application. does the amount of noise vary a lot with iso/gain? 73\u201380, san francisco. 237\u2013246, birmingham, england. the equations to map points on the surface of a 3d triangle to a 2d image are straightforward: just pass the local 2d coordinates on the triangle through the 3 \u00d7 4 camera projection matrix to obtain a 3 \u00d7 3 homography (planar perspective projection).",
        "(2005); tuytelaars and mikolajczyk (2007) while shi and tomasi (1994) and triggs (2004) also provide nice reviews. porter and duff (1984) describe a number of additional operations that can be useful in photo editing and visual effects applications. reconstruction algorithm. extract textures for each model face from your photographs, either by performing the appropriate resampling or by \ufb01guring out how to use the texture mapping software to directly access the source images. journal visualization and computer animation, 11:115\u2013127.",
        "trottenberg, u., oosterlee, c. w., and schuller, a. 1.2 a brief history  11  figure 1.6 a rough timeline of some of the most active topics of research in computer vision. it is also important that colors be linearized before processing, which is the case for all image matting algorithms. this problem is the converse of the pose estimation problem we studied in section 6.2. scape: shape completion and animation of people."
    ],
    "direct visual hull":[
        "robust higher order potentials for enforc ing label consistency. figure 8.15 shows the results of this process on the \ufb02ower garden sequence. 8.7 exercises  425  ex 8.6: motion-based user interaction write a program to compute a low-resolution motion \ufb01eld in order to interactively control a simple application (cutler and turk 1998). platt, j. c. (2000). randomized clustering forests for imieee transactions on pattern analysis and machine intelligence,  age classi\ufb01cation.",
        "(2003), doretto, chiuso, wu et al. one approach is to estimate the translations from the centroids and then estimate rotation in polar coordinates. if we convolve the sinusoidal signal s(x) with a \ufb01lter whose impulse response is h(x),  we get another sinusoid of the same frequency but different magnitude a and phase \u03c6o,  o(x) = h(x) \u2217 s(x) = a sin(\u03c9x + \u03c6o),  (3.48)  as shown in figure 3.24. vision.caltech.edu/archive.html.) applied mathematics  and computation, 19(1-4):23\u201356.",
        "7.3 factorization  361  if we knew the correct values of \u03b7j = t\u22121  zj and the structure and motion parameters rj and pi, we could cross-multiply the left hand side (visible point measurements xji and yji) by the denominator and get corrected values, for which the bilinear projection model (7.40) is exact. 22(8):781\u2013796. (a)  (b)  figure 14.34 locating star \ufb01elds using astrometry, http://astrometry.net/. for wide baselines, all possible homographies corresponding to planes passing through the 3d line are used to warp pixels and the maximum correlation score is used. 173\u2013178, princeton, new jersey.",
        "graphical models and image processing, 58(5):437\u2013451. in the second half of the chapter, we address the most challenging variant of recognition, namely the problem of category recognition (section 14.4). bilayer segmentation of live video. figure 5.14 shows two examples of images segmented using their technique. 10.3 super-resolution and blur removal  501  ing set of sample images can be used to \ufb01nd plausible mappings between low-frequency originals and the missing higher frequencies.",
        "in kanade, t. noborio, h., fukada, s., and arimoto, s. (1988). note, however, that the ncc score is unde\ufb01ned if either of the two patches has zero variance (and, in fact, its performance degrades for noisy low-contrast regions). (the image on the right is scaled up for better visibility. this ensures that corresponding epipolar lines are horizontal and that the disparity for points at in\ufb01nity is 0."
    ],
    "lifting second generation":[
        "kopf, j., lischinski, d., deussen, o., cohen-or, d., and cohen, m.  (2009). malisiewicz and efros (2008) start by over-segmenting each image and then use the labelme database to search for similar images and con\ufb01gurations in order to obtain per-pixel category labelings. carranza, j., theobalt, c., magnor, m. a., and seidel, h.-p. (2003). extend your algorithm to handle this case in some useful way. 2008), while some newer systems use video footage to control the animation (buck, finkelstein, jacobs et al.",
        "an even better approach is to use full bundle adjustment with explicit plane equations, as well as additional constraints to force reconstructed co-planar features to lie exactly on their corresponding planes. a more reliable technique is to look at the histogram of orientations computed around the keypoint. after a segmentation has been identi\ufb01ed at a coarser level, the exact memberships of each pixel are computed by propagating coarse-level assignments to their \ufb01ner-level \u201cchildren\u201d (sharon, galun, sharon et al. in viola and jones\u2019 face detector, the features are differences of rectangular regions in the input patch, as shown in figure 14.6. a general method for human activity recognition in  video.",
        "a feature-based correspondence algorithm for image matching. it is usually solved by iteratively relinearizing (a.23) around the current estimate of p using the gradient derivative (jacobian) j = \u2202f /\u2202p and computing an incremental improvement \u2206p. the convolution kernel  (4.23)  \u22072g\u03c3(x) =  1  \u03c33(cid:18)2 \u2212  x2 + y2  2\u03c32 (cid:19) exp(cid:18)\u2212  x2 + y2  2\u03c32 (cid:19)  is therefore called the laplacian of gaussian (log) kernel (marr and hildreth 1980). 11.8 exercises  ex 11.1: stereo pair recti\ufb01cation implement the following simple algorithm (section 11.1.1):  1. instead, the incremental lucas\u2013 kanade algorithm can be generalized to parametric motion models and used in conjunction with a hierarchical search algorithm (lucas and kanade 1981; rehg and witkin 1991; fuh and maragos 1991; bergen, anandan, hanna et al.",
        "in the forward pass, each node sends messages to its right and bottom neighbors. one potential way of describing this distribution would be by the location \u00afxk and 2d covariance ck of each individual point xk. rother, c. (2002). can you name all of the objects in images (a\u2013b), especially those that are circled in (c\u2013d). for larger motions, it is usual to combine the incremental update rule with a hierarchical coarse-to-\ufb01ne search strategy, as described in section 8.1.1.",
        "edge-preserving decompositions for multi-scale tone and detail manipulation. 792  computer vision: algorithms and applications (september 3, 2010 draft)  agarwala, a., hertzmann, a., seitz, s., and salesin, d. (2004). references  829  fukunaga, k. and hostetler, l. d.  (1975). fattal, r. (2009). surfels: surface elements as rendering primitives."
    ],
    "pyramid texture local spacetime stereo":[
        "the latter, which is also known as category-level or generic object recognition (ponce, hebert, schmid et al. 380\u2013387, san diego, ca. the uv plane can be placed at in\ufb01nity, which corresponds to all the virtual cameras looking in the same direction. as we mentioned in section 14.4.3, the existence of large databases of partially labeled internet imagery has given rise to a new sub-\ufb01eld of internet computer vision, with its own workshops21 and a special journal issue (avidan, baker, and shan 2010). the ambient (no-\ufb02ash) image a is \ufb01ltered with a regular bilateral \ufb01lter to produce abase, which is used in shadow and specularity regions, and a joint bilaterally \ufb01ltered noise reduced image anr.",
        "computer vision and image understanding, 84(1):77\u2013103. poynton, in his color faq, http://www.poynton.com/ colorfaq.html, notes that the perceptually motivated l*a*b* system is qualitatively similar to the gamma-compressed r\u2019g\u2019b\u2019 system we mostly deal with, since both have a fractional power scaling (which approximates a logarithmic response) between the actual intensity values and the numbers being manipulated. the answer is yes, if you are willing to \ufb01rst segment the image into different layers and then animate each layer separately. these include:  \u2022 stitching: turning overlapping photos into a single seamlessly stitched panorama (figure 1.5a), as described in chapter 9; \u2022 exposure bracketing: merging multiple exposures taken under challenging lighting conditions (strong sunlight and shadows) into a single perfectly exposed image (figure 1.5b), as described in section 10.2; \u2022 morphing: turning a picture of one of your friends into another, using a seamless morph transition (figure 1.5c); \u2022 3d modeling: converting one or more snapshots into a 3d model of the object or person you are photographing (figure 1.5d), as described in section 12.6 \u2022 video match move and stabilization: inserting 2d pictures or 3d models into your videos by automatically tracking nearby reference points (see section 7.4.2)3 or using motion estimates to remove shake from your videos (see section 8.2.1); \u2022 photo-based walkthroughs: navigating a large collection of photographs, such as the interior of your house, by \ufb02ying between different photos in 3d (see sections 13.1.2 and 13.5.5) \u2022 face detection: for improved camera focusing as well as more relevant image searching (see section 14.1.1); \u2022 visual authentication: automatically logging family members onto your home computer as they sit down in front of the webcam (see section 14.2). note that radial distortion needs to be removed from such images before the feature points can be used for calibration.",
        "10.4.3 optimization-based matting . at the time, it was believed by some of the early pioneers of arti\ufb01cial intelligence and robotics (at places such as mit, stanford, and cmu) that solving the \u201cvisual input\u201d problem would be an easy step along the path to solving more dif\ufb01cult problems such as higher-level reasoning and planning. 7.3.2 application: sparse 3d model extraction . for instance recognition (section 14.3.1), this can sometimes be achieved by backprojecting the object model into  \f14.4 category recognition  705  (a)  (b)  (c)  figure 14.42 part-based recognition (fergus, perona, and zisserman 2007) c(cid:13) 2007 springer: (a) locations and covariance ellipses for each part, along with their occurrence probabilities (top) and relative log-scale densities (bottom); (b) part examples drawn from the training images that best match the average appearance; (c) recognition results for the motorcycle class, showing detected features (pink dots) and parts (colored circles). b.5.4 graph cuts  the computer vision community has adopted \u201cgraph cuts\u201d as an informal name to describe a large family of mrf inference algorithms based on solving one or more min-cut or max\ufb02ow problems (boykov, veksler, and zabih 2001; boykov and kolmogorov 2010; boykov,  \fb.5 markov random \ufb01elds  771  (a)  (b)  figure b.3 graph cuts for minimizing binary sub-modular mrf energies (boykov and jolly 2001) c(cid:13) 2001 ieee: (a) energy function encoded as a max \ufb02ow problem; (b) the minimum cut determines the region boundary.",
        "if the scene is mostly specular (the classic example being scenes made of glass objects and mirrored or highly polished balls), the preferred approach is ray tracing or path tracing (glassner 1995; akeninem\u00a8oller and haines 2002; shirley 2005), which follows individual rays from the camera across multiple bounces towards the light sources (or vice versa). (2.60)  for conventional \ufb01lm cameras, w = 35mm, and hence f is also expressed in millimeters. (optional) compute a reordering for the variables, taking into ac count any block structure inherent in the problem. a better way to measure the quality is to use a perceptually based similarity metric, such as the structural similarity (ssim) index (wang, bovik, sheikh et al. take a new set of photographs a week later and use them as your test set.",
        "the signal is \ufb01rst (theoretically) interpolated to a continuous waveform, (ideally) low-pass \ufb01ltered to below the new nyquist rate, and then re-sampled to the \ufb01nal desired resolution. compute an optimal 2d translation and rotation between the \ufb01rst image and all subsequent images, using least squares (section 6.1.1) with optional ransac for robustness (section 6.1.4). the amount of mis-focus is measured by the circle of confusion c (shown as short thick blue line segments on the gray plane).7 the equation for the circle of confusion can be derived using similar triangles; it depends on the distance of travel in the focal plane \u2206zi relative to the original focus distance zi and the diameter of the aperture d (see exercise 2.4). the quality of a compression algorithm is usually reported using its peak signal-to-noise  ratio (psnr), which is derived from the average mean square error,  m se =  1  n(cid:88)x (cid:104)i(x) \u2212 \u02c6i(x)(cid:105)2  ,  (2.117)  where i(x) is the original uncompressed image and \u02c6i(x) is its compressed counterpart, or equivalently, the root mean square error (rms error), which is de\ufb01ned as  rm s = \u221am se. for example, for a summed area table, an impulse generates an in\ufb01nite rectangle of 1s below and to the right of the impulse."
    ],
    "photoconsistency blending morphing prior seam selection blending cylindrical spherical weighting de-ghosting non-photorealistic rendering image hallucination sparse robust sampling pitch coordinate transformations color splitting":[
        "next to each score, the corresponding rank in the current column is indicated by a smaller blue number. recently, some questions have been raised about the advisability of \ufb01tting correlation curves to integer-sampled matching costs (shimizu and okutomi 2001). irani, m., rousso, b., and peleg, s. (1997). because there exists such a large variety of techniques to perform 3d modeling, this chapter does not go into detail on any one of these. journal of the acm, 23(2):368\u2013388.",
        "(a) a regular ssd algorithm will make mistakes when matching pixels in these regions (e.g. (optional) compare your algorithm to local histogram equalization (section 3.1.4). at run time, for each new camera view, select the best source image for each visible  model face. parameter-free radial distortion correction with center of distortion estimation. while we will not use mathematical morphology much in the rest of this book, it is a handy tool to have around whenever you need to clean up some thresholded images.",
        "unfortunately, this particular gap-closing heuristic only works for the kind of \u201cone-dimensional\u201d  panorama where the camera is continuously turning in the same direction. the advantage of this approach is that a whole family of \ufb01lters can be evaluated with very little cost. 3.1.5 application: tonal adjustment  one of the most widely used applications of point-wise image processing operators is the manipulation of contrast or tone in photographs, to make them look either more attractive or more interpretable. fraction, so that the second row adds up to one, i.e., the rgb triplet (1, 1, 1) maps to a y value of 1. this can be achieved by looking for maxima in the edge strength (gradient magnitude) in a direction perpendicular to the edge orientation, i.e., along the gradient direction.",
        "if you can take the same exact picture after changing the color balance values in your  camera, compare how these settings affect this processing. foundations and trends in computer graphics and computer vision, 4(1):1\u201373. wang, z.-f. and zheng, z.-g.  (2008). during the interactive photogrammetric modeling phase, the user selects block elements and aligns their edges with visible edges in the input images (figure 12.14a). you can round the value of x(cid:48) to the nearest integer coordinate and copy the pixel there, but the resulting image has severe aliasing and pixels that jump around a lot when animating the transformation.",
        "if we estimate each pixel separately based on just its noisy version, we cannot make any progress, as there are a large number of values that could lead to each noisy measurement.4 instead, we need to rely on typical properties of images, e.g., that they tend to be piecewise smooth (section 3.7.1). optimol: automatic object picture collection via incre mental model learning. 2 brightness constancy (horn 1974) is the tendency for objects to maintain their perceived brightness under  varying illumination conditions. cartographers have also developed a number of alternative methods for representing the globe (bugayevskiy and snyder 1995). while learning parameters in mrfs and their variants is not a topic that we cover in this book, interested readers can \ufb01nd more details in recently published articles (kumar and hebert 2006; roth and black 2007a; tappen, liu, freeman et al."
    ],
    "radiometric motion whiteboard scanning calibration":[
        "this is just one instance of computational photography, where image analysis and processing algorithms are applied to one or more photographs to create images that go beyond the capabilities of traditional imaging systems. the reliability of a particular patch-based motion estimate can be captured more formally with an uncertainty model. test the various order \ufb01lters on a number of images of your choice and see if you can reliably \ufb01nd corner and intersection features. n (the value 0 can be reserved for \u201cno input\u201d). vision (iccv 2003), pp.",
        "articulated mesh animation  from multi-view silhouettes. we do not explain the details of the algorithm here, except to say that it involves a series of log2 n stages, where each stage performs small 2\u00d7 2 transforms (matrix multiplications with known coef\ufb01cients) followed by some semi-global permutations. more recent splitting algorithms often optimize some metric of intra-region similarity and  inter-region dissimilarity. one commonly used technique is called the orthogonal procrustes algorithm (golub and van loan 1996, p. 601) and involves computing the singular value decomposition (svd) of  8 when full covariances are used, they are transformed by the rotation and so a closed-form solution for transla tion is not possible. since these techniques are fairly involved, you will need to read several of the research papers in this area, select which general approach you want to follow, and then implement your algorithm.",
        "\u2022 tent: the piecewise linear tent function,  tent(x) = max(0, 1 \u2212 |x|),  has a sinc2 fourier transform. 3.3 more neighborhood operators . because these eigenvectors can be interpreted as the large modes of vibration in a spring-mass system, normalized cuts is an example of a spectral method for image segmentation. ruzon and tomasi (2001) and gevers, van de weijer, and stokman (2006) provide good reviews of these approaches, which include ideas such as fusing outputs from multiple channels, using multidimensional gradients, and vector-based  7 instead of using the raw rgb space, a more perceptually uniform color space such as l*a*b* (see section 2.3.2) can be used instead. going from left to right, we see the major column headings as images (which are 2d in nature), geometry (which encompasses 3d descriptions), and photometry (which encompasses object appearance).",
        "the algorithm therefore prefers removing regions that are near the edge of the image, which reduces the likelihood that partially visible objects will appear in the \ufb01nal composite. the problem of recovering pose from three correspondences, which is the minimal amount of information necessary, is known as the perspective-3-point-problem (p3p), with extensions to larger numbers of points collectively known as pnp (haralick, lee, ottenberg et al. prior knowledge, level set representations, and visual  grouping. given a suf\ufb01cient number of independent homography estimates \u02dch ij, we can recover a (up to a scale) using either svd or eigenvalue analysis and then recover k through cholesky decomposition (appendix a.1.4). 3.2.1 .",
        "bias and gain compensation is also used in video codecs, where it is known as weighted prediction (richardson 2003). you can \ufb01nd additional details on morphology in other textbooks on computer vision and image processing (haralick and shapiro 1992, section 5.2) (bovik 2000, section 2.2) (ritter and wilson 2000, section 7) as well as articles and books speci\ufb01cally on this topic (serra 1982; serra and vincent 1992; yuille, vincent, and geiger 1992; soille 2006). in follow-on work, fergus, fei-fei, perona et al. the results of this match computation gives us a jump table or, equivalently, a transition probability between any two frames in the original video. here, i try to come up with the best possible models of the physics of the system at hand: how the scene is created, how light interacts with the scene and atmospheric effects, and how the sensors work, including sources of noise and uncertainty."
    ],
    "video compression image quilting vocabulary tree accuracy vignetting bundle adjustment hierarchical":[
        "this is then generalized to spline-based motion models (section 8.3) and \ufb01nally to general per-pixel optical \ufb02ow (section 8.4), including layered and learned motion models (section 8.5). batra, d., sukthankar, r., and chen, t. (2008). society for industrial  and applied mathematics, philadephia. in situations where the camera is translating a lot in 3d, e.g., when the videographer is walking, an even better approach is to compute a full structure from motion reconstruction of the camera motion and 3d scene. i\u2019m also grateful to the many other computer vision researchers who have given me so many constructive suggestions about the book, including sing bing kang, who was my informal book editor, vladimir kolmogorov, who contributed appendix b.5.5 on linear programming techniques for mrf inference, daniel scharstein, richard hartley, simon baker, noah snavely, bill freeman, svetlana lazebnik, matthew turk, jitendra malik, alyosha efros, michael black, brian curless, sameer agarwal, li zhang, deva ramanan, olga veksler, yuri boykov, carsten rother, phil torr, bill triggs, bruce maxwell, jana ko\u02c7seck\u00b4a, eero simoncelli, aaron hertzmann, antonio torralba, tomaso poggio, theo pavlidis, baba vemuri, nando de freitas, chuck dyer, song yi, falk schubert, roman p\ufb02ugfelder, marshall tappen, james coughlan, sammy rogmans, klaus strobel, shanmuganathan, andreas siebert, yongjun wu, fred pighin, juan cockburn, ronald mallet, tim soper, georgios evangelidis, dwight fowler, itzik bayaz, daniel o\u2019connor, and srikrishna bhat.",
        "a convenient way to get a rough model of a real-world environment map is to take an image of a re\ufb02ective mirrored sphere and to unwrap this image onto the desired environment map (debevec 1998). a better approach is to hallucinate virtual point correspondences within the areas from which each homography was computed and to feed them into a standard structure from motion algorithm (szeliski and torr 1998). it is also possible to use larger neighborhoods, such as n8, which can lead to better boundaries (boykov and kolmogorov 2003), or to use second-order smoothness terms (woodford, reid, torr et al. other good sources of recent research are courses on this topic, such as the iccv 2009 short course (fei-fei, fergus, and torralba 2009) and antonio torralba\u2019s more comprehensive mit course (torralba 2008). 1  1,500  25,000  400,000  2,000,000  figure 10.11 relative brightness of different scenes, ranging from 1 inside a dark room lit by a monitor to 2,000,000 looking at the sun.",
        "dense matching of multiple widebaseline views. for the second pair, we may wish to establish a dense set of correspondences so that a 3d model can be constructed or an in-between view can be generated (chapter 11). (a) the line y = mx + b is \ufb01t to the four noisy data points, {(xi, yi)}, denoted by \u00d7 by minimizing the squared vertical residuals between the data points and the line,(cid:80)i (cid:107)yi \u2212 (mxi + b)(cid:107)2. as you can see in figure 3.7e, the resulting image maintains more of its original grayscale distribution while having a more appealing balance. algorithms for instance recognition, i.e., the detection of static man-made objects that only vary slightly in appearance but may vary in 3d pose, are mostly based on detecting 2d points of interest and describing them using viewpoint-invariant descriptors (lowe 2004; rothganger, lazebnik, schmid et al.",
        "in chapters 6\u20137, we described techniques for recovering camera positions and building sparse 3d models of scenes or objects. (8.25)  \f8.1 translational alignment  391  the output of phase correlation (under ideal conditions) is therefore a single spike (impulse) located at the correct value of u, which (in principle) makes it easier to \ufb01nd the correct estimate. for example, boykov and jolly (2001) used this idea for interactive segmentation, as shown in figure 3.61, and it is now widely used in image segmentation (section 5.5) (blake, rother,  25 an alternative formulation that also uses detected edges to modulate the smoothness of a depth or motion \ufb01eld  and hence to integrate multiple lower level vision modules is presented by poggio, gamble, and little (1988). their system computes the label assignment that optimizes the sum of two objective functions. lim, j. j., arbel\u00b4aez, p., gu, c., and malik, j.",
        "yatziv, l. and sapiro, g. (2006). even more recent work converts high-dimensional descriptor vectors into binary codes that can be compared using hamming distances (torralba, weiss, and fergus 2008; weiss, torralba, and fergus 2008) or that can accommodate arbitrary kernel functions (kulis and grauman 2009; raginsky and lazebnik 2009). all of these properties are relatively straightforward to prove (see exercise 3.15) and they will come in handy later in the book, e.g., when designing optimum wiener \ufb01lters (section 3.4.3) or performing fast image correlations (section 8.1.2). ieee transactions on pattern analysis and machine intelligence, 6(2):212\u2013 222. a wide variety of more sophisticated preconditioners have been developed over the years (bj\u00a8orck 1996; golub and van loan 1996; trefethen and bau 1997; saad 2003; nocedal and wright 2006), many of which can be directly applied to problems in computer vision (byr\u00a8od and \u00f8astr\u00a8om 2009; jeong, nist\u00b4er, steedly et al."
    ],
    "discrete separable noise removal":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "learned inference recognition":[
        "some sharpening is also often applied at this stage. while traditional systems require prior knowledge about the scene or object being visually tracked (rosten and drummond 2005), newer systems can  15 http://www.2d3.com/. using color to separate re\ufb02ection components. this is both because the letters i and j are used for the imaginary number (the usage depends on whether you are reading complex variables or electrical engineering literature) and because it is clearer how to distinguish the horizontal (x) and vertical (y) components in frequency space. the visual analysis of human movement: a survey.",
        "8.2.2 learned motion models . wolberg, g. (1990). international journal of computer vision, 78(2-3):223\u2013236. iddan, g. j. and yahav, g. (2001). robust regression and outlier detection.",
        "3d (multiview) video coding and compression is also an active area of research (smolic and kauff 2005; gotchev and rosenhahn 2009), with 3d blu-ray discs, encoded using the multiview video coding (mvc) extension to h.264/mpeg-4 avc, expected by the end of 2010. memo 777, arti\ufb01cial intelligence laboratory, massachusetts institute of technology. freeman, w. t. and adelson, e. h. (1991). scene collages and \ufb02exible camera arrays. an ef\ufb01cient solution to the \ufb01ve-point relative pose problem.",
        "curless, b. and levoy, m.  (1995). 926  computer vision: algorithms and applications (september 3, 2010 draft)  ieee transactions on pattern analysis and machine intelligence, 31(3):492\u2013504. a bayesian method for probable surface  reconstruction and decimation. computer vision and image under standing, 68(2):146\u2013157. 10.5 texture analysis and synthesis  10.6 additional reading .",
        "and view (reference image). 871\u2013878, new york city, ny. an alternative approach, which places seams along strong consistent edges in overlapping images using a watershed computation is described by soille (2006). principal component analysis with missieee transactions on pattern  ing data and its application to polyhedral modeling. menet, s., saint-marc, p., and medioni, g. (1990b)."
    ],
    "snakes region region modeling":[
        "2008; komodakis and paragios 2008; schraudolph 2010). raginsky, m. and lazebnik, s. (2009). figure 3.49 shows how this works in one dimension. 18(10):840\u2013850. madsen, k., nielsen, h. b., and tingleff, o.",
        "acm transactions on graphics, 18(1):1\u201334. pyramid match hashing: sub-linear time indexing over partial correspondences. in international conference on image processing (icip-2000), pp. however, rather than being projected orthogonally to this plane, they are projected parallel to the line of sight to the object center (figure 2.7d). to ensure that overlapping patches are similar in appearance, a markov random \ufb01eld is used and optimized using either belief propagation (freeman, pasztor, and carmichael 2000) or a raster-scan deterministic variant (freeman, jones, and pasztor 2002).",
        "leibowitz, d. (2001). the taxonomy consists of a set of algorithmic \u201cbuilding blocks\u201d from which a large set of algorithms can be constructed. first, segment the image into such regions and \ufb01t a constant or linear function inside each region. starting with a video sequence, each pixel is modeled as a linear combination of its (unknown) background color and a constant foreground (smoke) color that is common to all pixels. segment-based stereo matching using belief propagation and a self-adapting dissimilarity measure.",
        "in acm siggraph 2001 conference proceedings, pp. can you think of how you might do this? flash photography enhancement via intrinsic relight ing. leyvand, t., cohen-or, d., dror, g., and lischinski, d. (2008). in british machine vision conference (bmvc 2010), aberystwyth, wales, uk.",
        "exercise 8.3 has you implement and test some of these ideas. note that even once q has been recovered, there still exists a bas-relief ambiguity, i.e., we can never be sure if the object is rotating left to right or if its depth reversed version is moving the other way. (2000) and de agapito, hayman, and reid (2001). in practice, the \ufb01ltering is usually broken down into two separable sub-stages, as shown in figure 3.37b. as we can see from figure 3.21, dilation grows (thickens) objects consisting of 1s, while erosion shrinks (thins) them."
    ],
    "perfect reconstruction equation radiosity multi-frame marching cubes phase correlation":[
        "the canadian cartographer, 10(2):112\u2013122. 8.1.2 . digital  signal processing, 17(2):414\u2013432. estimating motion in image sequences: a tutorial on modeling and computation of 2d motion. (2010) provide a good review of automatic segmentation techniques and also compare their performance on the berkeley segmentation dataset and benchmark (martin, fowlkes, tal et al.",
        "to reduce the zippering effect, most techniques use the edge or  \f10.3 super-resolution and blur removal  503  figure 10.34 bayer rgb pattern: (a) color \ufb01lter array layout; (b) interpolated pixel values, with unknown (guessed) values shown as lower case. smith, a. r. and blinn, j. f.  (1996). radiosity and realistic image synthesis. weiss, y. under these conditions, we can reduce the 5d plenoptic function to  4 since we are counting dimensions, we ignore for now any sampling or resolution issues.",
        "1992; zhang 2000; grossberg and nayar 2001). build separate detectors for these three (or four) kinds of region, either using a subspace  (pca) approach or one of the techniques presented in section 14.1.1. acm transactions on graphics, 25(3):1025\u20131034. hu, w., tan, t., wang, l., and maybank, s. (2004). this fact can be used to save space and to double the speed of image ffts by packing alternating scanlines into the real and imaginary parts of the signal being transformed.",
        "this technique works well when good foreground and background color estimates are available and these colors vary slowly. under such conditions, a reasonable approach is to de\ufb01ne an edge as a location of rapid  \f4.2 edges  239  figure 4.31 human boundary detection (martin, fowlkes, and malik 2004) c(cid:13) 2004 ieee. 2004; doretto and soatto 2006) treat the video as a 3d spatio-temporal volume with textural properties, which can be described using auto-regressive temporal models. here, just keeping the minimum scalar distance to the boundary during the two passes is not suf\ufb01cient. environment matting extensions: towards higher accuracy and real-time capture.",
        "can you do it without peeking at the literature (danielsson 1980; borgefors 1986)? 1995; watt 1995; opengl-arb 1997). advances in computational stereo. 14.2.1 eigenfaces 14.2.2 active appearance and 3d shape models . this transformation, also known as a perspective transform or homography, operates on homogeneous coordinates,  \u02dcx(cid:48) = \u02dch \u02dcx,  (2.20) where \u02dch is an arbitrary 3 \u00d7 3 matrix."
    ],
    "multi-pass sampling":[
        "cambridge university press. a., kenyon, r. v., and troxel, d. e. (1983). because of the problem associated with mixing negative light, the cie also developed a new color space called xyz, which contains all of the pure spectral colors within its positive octant. shape from shading therefore needs to be combined with some other technique or extended in some way to make it useful. 276 .",
        "1605\u20131612, new york city, ny. feature matching stage (section 4.1.3) ef\ufb01ciently searches for likely matching candidates in other images. (optional) mean shift divides the kernel density function estimate by the local weighting to obtain a step size that is guaranteed to converge but may be slow. in acm siggraph 1996 confer ence proceedings, pp. how would you segment this image based on color alone?",
        "754\u2013760, bombay. in practice, we usually only evaluate the convolution at every rth sample,  g(i, j) =(cid:88)k,l  f(k, l)h(ri \u2212 k, rj \u2212 l),  (3.80)  as shown in figure 3.30. 850  computer vision: algorithms and applications (september 3, 2010 draft)  klaus, a., sormann, m., and karner, k. (2006). small codes and large databases of images for object recognition. while fourier-based alignment is mostly used to estimate translational shifts between images, it can, under certain limited conditions, also be used to estimate in-plane rotations and scales.",
        "williams, l.  (1983). 487\u2013501, copenhagen. references  911  toint, p. l. (1987). 2.4 additional reading  as we mentioned at the beginning of this chapter, it provides but a brief summary of a very rich and deep set of topics, traditionally covered in a number of separate \ufb01elds. vezhnevets, v., sazonov, v., and andreeva, a.",
        "christy, s. and horaud, r. (1996). wiskott, l., fellous, j.-m., kr\u00a8uger, n., and von der malsburg, c. (1997). 2003), which all use global 3d geometric models (surface-based (section 12.3) or volumetric (section 12.5)) as their proxies for rendering. 14.4.2 part-based models  recognizing an object by \ufb01nding its constituent parts and measuring their geometric relationships is one of the oldest approaches to object recognition (fischler and elschlager 1973; kanade 1977; yuille 1991). median \ufb01ltering  a better \ufb01lter to use in this case is the median \ufb01lter, which selects the median value from each pixel\u2019s neighborhood (figure 3.19a)."
    ],
    "quadtree spline-based motion estimation inpainting quadtree":[
        "2008; li, wu, zach et al. instead, a vector-valued distance consisting of both the x and y coordinates of the distance to the boundary must be kept and compared using the squared distance (hypotenuse) rule. 403 . 6 http://www.face-rec.org/. another is the scene completion system of hays and efros (2007), which tackles the same inpainting problem we studied in section 10.5.",
        "(3.77)  like the 2d fast fourier transform, the 2d dct can be implemented separably, i.e., \ufb01rst computing the dct of each line in the block and then computing the dct of each resulting column. while these techniques can generate reasonable pixel-accurate segmentations, they fail to capture the subtle interplay of foreground and background colors at mixed pixels along the boundary (szeliski and golland 1999) (figure 10.38a). ieee transactions on pattern analysis and machine intelligence, 32(9):1627\u20131645. the original constellation model was developed by burl, weber, and perona (1998) and consists of a number of parts whose relative positions are encoded by their mean locations and a full covariance matrix, which is used to denote not only positional uncertainty but also potential correlations (covariance) between different parts (figure 14.42a). in section 10.5, we describe how to generate novel textures from real-world samples for applications such as \ufb01lling holes in images (figure 10.1d).",
        "komodakis and tziritas (2007b) present an mrf-based version of this block synthesis algorithm that uses a new, ef\ufb01cient version of loopy belief propagation they call \u201cpriority-bp\u201d. deformed lattice detection in real-world images using mean-shift belief propagation. (b) a weighted gradient orientation histogram is then computed in each subregion, using trilinear interpolation. papert, s.  (1966). in equation (b.5), we have indicated that ni is a zero-mean normal (gaussian) random variable with a covariance matrix \u03c3i.",
        "in this chapter, we address the question of how to build a more complete 3d model, e.g., a sparse or dense depth map that assigns relative depths to pixels in the input images. depth painting for image-based rendering applications. 87\u201393, kerkyra, greece. the exercises at the end of each chapter contain numerous suggestions for smaller mid-term projects, as well as more open-ended problems whose solutions are still active research topics. hinckley, k., sinclair, m., hanson, e., szeliski, r., and conway, m. (1999).",
        "articulated mesh animation  from multi-view silhouettes. we do not explain the details of the algorithm here, except to say that it involves a series of log2 n stages, where each stage performs small 2\u00d7 2 transforms (matrix multiplications with known coef\ufb01cients) followed by some semi-global permutations. more recent splitting algorithms often optimize some metric of intra-region similarity and  inter-region dissimilarity. one commonly used technique is called the orthogonal procrustes algorithm (golub and van loan 1996, p. 601) and involves computing the singular value decomposition (svd) of  8 when full covariances are used, they are transformed by the rotation and so a closed-form solution for transla tion is not possible. since these techniques are fairly involved, you will need to read several of the research papers in this area, select which general approach you want to follow, and then implement your algorithm."
    ],
    "splines evaluation structure from motion learning":[
        "482  computer vision: algorithms and applications (september 3, 2010 draft)  figure 10.13 radiometric calibration using multiple exposures (debevec and malik 1997). sederberg, t. w., gao, p., wang, g., and mu, h. (1993). 18 in their actual implementation, nist\u00b4er and stew\u00b4enius (2006) use an l1 metric. 704  computer vision: algorithms and applications (september 3, 2010 draft)  part model (bouchard and triggs 2005; carneiro and lowe 2006). pro ceedings of the royal society of london, b 204:301\u2013328.",
        "this is then generalized to spline-based motion models (section 8.3) and \ufb01nally to general per-pixel optical \ufb02ow (section 8.4), including layered and learned motion models (section 8.5). batra, d., sukthankar, r., and chen, t. (2008). society for industrial  and applied mathematics, philadephia. in situations where the camera is translating a lot in 3d, e.g., when the videographer is walking, an even better approach is to compute a full structure from motion reconstruction of the camera motion and 3d scene. i\u2019m also grateful to the many other computer vision researchers who have given me so many constructive suggestions about the book, including sing bing kang, who was my informal book editor, vladimir kolmogorov, who contributed appendix b.5.5 on linear programming techniques for mrf inference, daniel scharstein, richard hartley, simon baker, noah snavely, bill freeman, svetlana lazebnik, matthew turk, jitendra malik, alyosha efros, michael black, brian curless, sameer agarwal, li zhang, deva ramanan, olga veksler, yuri boykov, carsten rother, phil torr, bill triggs, bruce maxwell, jana ko\u02c7seck\u00b4a, eero simoncelli, aaron hertzmann, antonio torralba, tomaso poggio, theo pavlidis, baba vemuri, nando de freitas, chuck dyer, song yi, falk schubert, roman p\ufb02ugfelder, marshall tappen, james coughlan, sammy rogmans, klaus strobel, shanmuganathan, andreas siebert, yongjun wu, fred pighin, juan cockburn, ronald mallet, tim soper, georgios evangelidis, dwight fowler, itzik bayaz, daniel o\u2019connor, and srikrishna bhat.",
        "in ninth international conference on computer vision (iccv 2003), pp. once this has been established, a suitable search technique must be devised. instead, the existence of three primaries is a result of the tri-stimulus (or trichromatic) nature of the human visual system, since we have three different kinds of cone, each of which responds selectively to a different portion of the color spectrum (glassner 1995; wyszecki and stiles 2000; fairchild 2005; reinhard, ward, pattanaik et al. it has the same effect on the amount of light reaching the sensor as doubling the exposure duration, e.g., from 1/125 to 1/250, see exercise 2.5.) the cosine law for triangle \u2206(c, pi, pj) gives us  pi = di \u02c6xi + c  fij(di, dj) = d2  i + d2  j \u2212 2didjcij \u2212 d2  ij = 0,  where  and  cij = cos \u03b8ij = \u02c6xi \u00b7 \u02c6xj  ij = (cid:107)pi \u2212 pj(cid:107)2. d2  (6.36)  (6.37)  (6.38)  (6.39)  (6.40)  we can take any triplet of constraints (fij, fik, fjk) and eliminate the dj and dk using  sylvester resultants (cox, little, and o\u2019shea 2007) to obtain a quartic equation in d2 i ,  gijk(d2  i ) = a4d8  i + a3d6  i + a2d4  i + a1d2  i + a0 = 0.",
        "a convenient way to get a rough model of a real-world environment map is to take an image of a re\ufb02ective mirrored sphere and to unwrap this image onto the desired environment map (debevec 1998). a better approach is to hallucinate virtual point correspondences within the areas from which each homography was computed and to feed them into a standard structure from motion algorithm (szeliski and torr 1998). it is also possible to use larger neighborhoods, such as n8, which can lead to better boundaries (boykov and kolmogorov 2003), or to use second-order smoothness terms (woodford, reid, torr et al. other good sources of recent research are courses on this topic, such as the iccv 2009 short course (fei-fei, fergus, and torralba 2009) and antonio torralba\u2019s more comprehensive mit course (torralba 2008). 1  1,500  25,000  400,000  2,000,000  figure 10.11 relative brightness of different scenes, ranging from 1 inside a dark room lit by a monitor to 2,000,000 looking at the sun.",
        "acm transactions on graphics, 25(3):1013\u20131024. in cvpr 2007 short course on recognizing and learning object categories. this approach is sometimes called the nplanes calibration approach (gremban, thorpe, and kanade 1988; champleboux, lavall\u00b4ee, szeliski et al. however, unlike simple coarse-to-\ufb01ne techniques, which use the coarse solutions to initialize the \ufb01ne solution, multigrid techniques only correct the low-frequency component of the current solution and use multiple rounds of coarsening and re\ufb01nement (in what are often called \u201cv\u201d and \u201cw\u201d patterns of motion across the pyramid) to obtain rapid convergence. (we number the pixel coordinates accordingly, i.e., place pixel (x, y) = (0, 0) at the center of the image.)"
    ],
    "perspective conjugate gradient normalized cuts":[
        "and kweon, i.-s.  (2006). poxels: probabilistic voxelized volume reconstruction. robust anisotropic  diffusion. figure 3.45 shows a few ex fxhffghghhgxfxgxyxsimilarityeuclideanaffineprojectivetranslation\f164  computer vision: algorithms and applications (september 3, 2010 draft)  transformation  matrix  # dof preserves  icon  translation  rigid (euclidean)  similarity  af\ufb01ne  projective  (cid:104) i t (cid:105)2\u00d73 (cid:104) r t (cid:105)2\u00d73 (cid:104) sr t (cid:105)2\u00d73 (cid:104) a (cid:105)2\u00d73 (cid:104) \u02dch (cid:105)3\u00d73  2  3  4  6  8  orientation  lengths  angles  \u001a\u001a ss ss \u001a\u001a \u001a s s \u001a \u0002\u0002 \u0002\u0002    straight lines ``  parallelism  table 3.5 hierarchy of 2d coordinate transformations. 7.3 factorization  when processing video sequences, we often get extended feature tracks (section 4.1.4) from which it is possible to recover the structure and motion using a process called factorization.",
        "note that the map estimate may not always be desirable, since it selects the \u201cpeak\u201d in the posterior distribution rather than some more stable statistic\u2014see the discussion in appendix b.2 and by levin, weiss, durand et al. once the entries in p have been recovered, it is possible to recover both the intrinsic calibration matrix k and the rigid transformation (r, t) by observing from equation (2.56) that  p = k[r|t]. extract edges and link them (exercises 4.7\u20134.8). international journal of computer vision, 59(2):167\u2013181. 2003) c(cid:13) 2003 acm.",
        "edge detector evaluation using  empirical roc curves. edges and lines provide information that is complementary to both keypoint and region-based descriptors and are well-suited to describing object boundaries and man-made objects. image does not pass through the input data points) that produces soft images with reduced high-frequency detail. convert your similarity table into a jump probability table through some exponential distribution. frequency response to color than to luminance changes.)",
        "active shape models\u2014their  training and application. does the amount of noise vary a lot with iso/gain? 73\u201380, san francisco. 237\u2013246, birmingham, england. the equations to map points on the surface of a 3d triangle to a 2d image are straightforward: just pass the local 2d coordinates on the triangle through the 3 \u00d7 4 camera projection matrix to obtain a 3 \u00d7 3 homography (planar perspective projection).",
        "grimson, w. e. l. (1983). and levoy, m. (2000). elimination of seams from photomosaics. weiss, y., torralba, a., and fergus, r. (2008). (2.19)  parallel lines remain parallel under af\ufb01ne transformations."
    ],
    "normal vectors lines lines":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "focus chromatic aberration blooming virtual viewpoint video \ufb02ash and non-\ufb02ash evolution visual effects medical imaging chromatic aberration tone mapping":[
        "weizmann segmentation evaluation database of 100 grayscale images with ground truth segmentations, http://www.wisdom.weizmann.ac.il/\u223cvision/seg evaluation db/ index.html (alpert, galun, basri et al. magnor, m., ramanathan, p., and girod, b. singaraju, d., grady, l., sinop, a. k., and vidal, r. (2010). speci\ufb01ed chrominance (u, v) values to the whole image, which are then re-combined with the input luminance channel to produce a \ufb01nal colorized image, as shown in figure 10.37b. this can be useful for dealing with local variations such as the vignetting caused by wide-angle lenses, wide apertures, or lens housings.",
        "creating full view panoramic image mosaics and texture-mapped models. a faster approach is to randomly subsample the input points xi and to keep track of each point\u2019s temporal evolution. chine intelligence, 29(12):2217\u20132233. signals and systems. \u201cserious\u201d volunteer effort is the labelme database, in which vision researchers contribute manual polygonal region annotations in return for gaining access to the database (russell, torralba, murphy et al.",
        "reconstruct the \ufb01nal image from the blended laplacian pyramid. to this end, i have attempted wherever possible to at least cite the newest research in each sub-\ufb01eld, even if the  \fviii  computer vision: algorithms and applications (september 3, 2010 draft)  technical details are too complex to cover in the book itself. instead of forming c = aat , which is p \u00d7 p , we form the matrix  \u02c6c = at a,  (a.13)  which is n \u00d7 n. (this involves taking the dot product between every pair of difference images ai and aj.) these location distributions are then used with classic object detectors to improve the performance of the detectors. in this chapter, we have already seen lots of techniques borrowed from the machine learning, statistics, and pattern recognition communities.",
        "2009; hiep, keriven, pons et al. make sure that the images you are taking are linearized (exercise 10.1 and section 10.1) and that your camera exposure is \ufb01xed (full manual mode), at least when taking multiple shots of the same scene. learning the statistics of people in images and  video. real-time object detection for smart vehicles. 299\u2013306, los angeles.",
        "once a query image or region has been mapped into its constituent visual words, likely matching images or video frames must then be retrieved from the database. for example, \u03c1p can be a hyper-laplacian penalty  \u03c1p(d) = |d|p, p < 1,  (3.114)  which better encodes the distribution of gradients (mainly edges) in an image than either a quadratic or linear (total variation) penalty.24 levin and weiss (2007) use such a penalty to separate a transmitted and re\ufb02ected image (figure 8.17) by encouraging gradients to lie in one or the other image, but not both. because e is rank-de\ufb01cient, it turns out that we actually only need seven correspondences of the form of equation (7.14) instead of eight to estimate this matrix (hartley 1994a; torr and murray 1997; hartley and zisserman 2004). 594  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  (c)  (d)  figure 12.11 progressive mesh representation of an airplane model (hoppe 1996) c(cid:13) 1996 acm: (a) base mesh m 0 (150 faces); (b) mesh m 175 (500 faces); (c) mesh m 425 (1000 faces); (d) original mesh m = m n (13,546 faces). 289 ."
    ],
    "random walker weighting bilateral \ufb01lter steerable query expansion plane-based automatic quantization algorithm":[
        "195\u2013202, madison, wi. in his system, he uses an af\ufb01ne transformation between the database object and the collection of scene features, which works well for objects that are mostly planar, or where at least several corresponding features share a quasi-planar geometry.16  since sift features carry with them their own location, scale, and orientation, lowe uses a four-dimensional similarity transformation as the original hough binning structure, i.e., each bin denotes a particular location for the object center, scale, and in-plane rotation. international journal of computer vision, 37(2):151\u2013172. however, in addition to computing the motion, occlusion information is critical to prevent colors from being contaminated by moving foreground objects that might obscure a particular pixel in a preceding or subsequent frame. image and vision computing, 10(3):132\u2013144.",
        "blanz and vetter (1999) describe a system where they \ufb01rst capture a set of 200 colored range scans of faces (figure 12.19a), which can be represented as a large collection of (x, y, z, r, g, b) samples (vertices).9 in order for 3d morphing to be meaningful, corresponding vertices in different people\u2019s scans must \ufb01rst be put into correspondence (pighin, hecker, lischinski et al. international journal of computer vision, 49(2/3):117\u2013141. the process of copying a pixel f(x) to a location x(cid:48) in g is not well de\ufb01ned when x(cid:48) has a non-integer value. more precisely, the frequency of occurrence of particular words in a document is used to quickly \ufb01nd documents that match a particular query. lempitsky, roth, and rother.",
        "pickup, l. c., capel, d. p., roberts, s. j., and zisserman, a. the main dif\ufb01culty in location recognition is in dealing with the extremely large community (user-generated) photo collections on web sites such as flickr (philbin, chum, isard et al. for example, if we fail to match the motions of the clock pendulum in figure 13.13a, it can suddenly change direction in mid-swing. contentbased image retrieval at the end of the early years. this idea (gamble and poggio 1987; fua 1993; bobick and intille 1999; boykov, veksler, and zabih 2001) encourages disparity discontinuities to coincide with intensity or color edges and appears to account for some of the good performance of global optimization approaches.",
        "7.4 bundle adjustment  363  figure 7.7 a set of chained transforms for projecting a 3d point pi into a 2d measurement xij through a series of transformations f (k), each of which is controlled by its own set of parameters. freeman, w. t., pasztor, e. c., and carmichael, o. t. (2000). luong, q.-t. and vi\u00b4eville, t.  (1996). 874  computer vision: algorithms and applications (september 3, 2010 draft)  nayar, s. k. and nakagawa, y. in twelfth ieee international conference on computer vision (iccv 2009), kyoto, japan.",
        "when an image has some cutout regions, down-weighting pixels near the edges of both cutouts and the image is preferable. in practice, a bilinear interpolant is often used but bicubic interpolation can yield slightly better results (szeliski and scharstein 2004). kyoto, japan. 2000) c(cid:13) 2000 acm; (i) video view interpolation (zitnick, kang, uyttendaele et al. society  for industrial and applied mathematics, philadelphia, second edition."
    ],
    "linear projective image stitching kernel gradient domain":[
        "jim  \f38  computer vision: algorithms and applications (september 3, 2010 draft)  transformation  matrix  # dof preserves  icon  translation  rigid (euclidean)  similarity  af\ufb01ne  projective  (cid:104) i t (cid:105)2\u00d73 (cid:104) r t (cid:105)2\u00d73 (cid:104) sr t (cid:105)2\u00d73 (cid:104) a (cid:105)2\u00d73 (cid:104) \u02dch (cid:105)3\u00d73  2  3  4  6  8  orientation  lengths  angles  \u001a\u001a ss ss \u001a\u001a \u001a s s \u001a \u0002\u0002 \u0002\u0002    straight lines ``  parallelism  table 2.1 hierarchy of 2d coordinate transformations. figure 8.16 shows an example of such a pseudo-color mapping. instead, we can write the relationship  \u02c6x = u\u03c3v t = [u q][q\u22121\u03c3v t ]  (7.44)  and set \u02c6m = u q and \u02c6s = q\u22121\u03c3v t .11  how can we recover the values of the 3\u00d7 3 matrix q? 2000; telea 2004). image segmentation and image models.",
        "(2006). take the left and right singular vectors {u0, u1, v0, v1} of the fundamental matrix f (7.30) and their associated singular values {\u03c30, \u03c31) and form the following set of equations:  ut 1 d0u1 \u03c32 0vt 0 d1v0  = \u2212  ut  0 d0u1  \u03c30\u03c31vt  0 d1v1  =  ut 0 d0u0 \u03c32 1vt 1 d1v1  ,  where the two matrices  (7.35)  (7.36)  dj = kjkt  j = diag(f 2  j , f 2  j , 1) =\uf8ee\uf8ef\uf8f0  f 2 j  f 2 j  1  \uf8f9\uf8fa\uf8fb  encode the unknown focal lengths. in acm siggraph 1999 conference proceedings, pp. ieee transactions on pattern analysis and machine intelligence, 16(7):673\u2013 689. computer vision (iccv 2009), kyoto, japan.",
        "ieee journal of solid state circuits, 34(12):1821\u20131834. segmenting the image into such superpixels (mori, ren, efros et al. to compute the value of f(x) at a non-integer location x, we simply apply our usual fir  resampling \ufb01lter,  g(x, y) =(cid:88)k,l  f(k, l)h(x \u2212 k, y \u2212 l),  (3.89)  where (x, y) are the sub-pixel coordinate values and h(x, y) is some interpolating or smoothing kernel. its fourier transform can be written as  f {essd(u)} = f(cid:40)(cid:88)i = \u03b4(\u03c9)(cid:88)i  [i1(xi + u) \u2212 i0(xi)]2(cid:41)  [i 2  0 (xi) + i 2  1 (xi)] \u2212 2i0(\u03c9)i\u22171 (\u03c9). in proceedings of eurographics 2010.",
        "if you can take the same exact picture after changing the color balance values in your  camera, compare how these settings affect this processing. foundations and trends in computer graphics and computer vision, 4(1):1\u201373. wang, z.-f. and zheng, z.-g.  (2008). during the interactive photogrammetric modeling phase, the user selects block elements and aligns their edges with visible edges in the input images (figure 12.14a). you can round the value of x(cid:48) to the nearest integer coordinate and copy the pixel there, but the resulting image has severe aliasing and pixels that jump around a lot when animating the transformation.",
        "the algorithm can be initialized by randomly sampling k centers from the input feature vectors. ex 11.11: shape from silhouettes build a silhouette-based volume reconstruction algorithm (section 11.6.2). when the cameras are calibrated, the \ufb01ve-point algorithm of nist\u00b4er (2004) can be used in conjunction with ransac to obtain initial reconstructions from the minimum number of points. 13 when a dslr chip does not \ufb01ll the 35mm full frame, it results in a multiplier effect on the lens focal length. applications to non-rigid or elastic deformations (bookstein 1989; szeliski and lavall\u00b4ee 1996; torresani, hertzmann, and bregler 2008) are examined in sections 8.3 and 12.6.4.  yxsimilarityeuclideanaffineprojectivetranslation\f312  computer vision: algorithms and applications (september 3, 2010 draft)  transform  matrix  parameters p  jacobian j  translation  euclidean  similarity  af\ufb01ne  projective  tx  tx  b  s\u03b8  c\u03b8  0 1  (cid:34) 1 0 tx ty (cid:35) ty (cid:35) (cid:34) c\u03b8 \u2212s\u03b8 (cid:34) 1 + a \u2212b 1 + a ty (cid:35) (cid:34) 1 + a00 ty (cid:35) \uf8ee\uf8ef\uf8f0 \uf8f9\uf8fa\uf8fb  h02 1 + h11 h12 1  1 + h00  1 + a11  h10 h20  h01  h21  a01  a10  tx  (tx, ty)  (tx, ty, \u03b8)  (tx, ty, a, b)  (tx, ty, a00, a01, a10, a11)  0  0  (cid:34) 1 (cid:34) 1 (cid:34) 1 (cid:34) 1  0  0  0  1 (cid:35) c\u03b8x \u2212 s\u03b8y (cid:35) 0 \u2212s\u03b8x \u2212 c\u03b8y 1 x (cid:35) 0 x \u2212y 1 0 x y (cid:35)  0 x y 1  0  0  0  y  (h00, h01, ."
    ],
    "strategy pure translation nodal point axis/angle exponential twist pure rotation rotational motion":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "line-based de-ghosting view morphing projective points lines self-calibration perspective motion plane-based view morphing sparse surface light \ufb01eld":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "tion spacetime shading":[
        "more commonly, however, iir \ufb01lters are used inside one-dimensional separable \ufb01ltering stages to compute large-extent smoothing kernels, such as ef\ufb01cient approximations to gaussians and edge \ufb01lters (deriche 1990; nielsen, florack, and deriche 1997). (another name for the inverse covariance matrix, which is equal to the hessian in such simple cases, is the information matrix.) \u2022 a brief history \u2022 book overview \u2022 sample syllabus \u2022 notation  2 image formation  geometric primitives and transformations \u2022  photometric image formation \u2022  the digital camera  3 image processing  1  29  99  point operators \u2022 linear \ufb01ltering \u2022  more neighborhood operators \u2022 fourier transforms \u2022 pyramids and wavelets \u2022 geometric transformations \u2022  global optimization  4 feature detection and matching  205  points and patches \u2022 edges \u2022 lines  5 segmentation  mean shift and mode \ufb01nding \u2022 normalized cuts \u2022  active contours \u2022 split and merge \u2022 graph cuts and energy-based methods  6 feature-based alignment  2d and 3d feature-based alignment \u2022  pose estimation \u2022  geometric intrinsic calibration  7 structure from motion  267  309  343  triangulation \u2022 two-frame structure from motion \u2022  factorization \u2022 bundle adjustment \u2022 constrained structure and motion  n^\f8 dense motion estimation  translational alignment \u2022 parametric motion \u2022  spline-based motion \u2022 optical \ufb02ow \u2022  layered motion  9 image stitching  motion models \u2022 global alignment \u2022  compositing  381  427  10 computational photography 467 photometric calibration \u2022 high dynamic range imaging \u2022  super-resolution and blur removal \u2022 image matting and compositing \u2022 texture analysis and synthesis  11 stereo correspondence  533  epipolar geometry \u2022 sparse correspondence \u2022 dense correspondence \u2022 local methods \u2022 global optimization \u2022 multi-view stereo  12 3d reconstruction  577  shape from x \u2022 active range\ufb01nding \u2022  surface representations \u2022 point-based representations \u2022 volumetric representations \u2022 model-based reconstruction \u2022 619 13 image-based rendering  recovering texture maps and albedos  view interpolation \u2022 layered depth images \u2022  light \ufb01elds and lumigraphs \u2022 environment mattes \u2022  video-based rendering  14 recognition  655  instance recognition \u2022 category recognition \u2022  object detection \u2022 face recognition \u2022 context and scene understanding \u2022 recognition databases and test sets  \f\fpreface  the seeds for this book were \ufb01rst planted in 2001 when steve seitz at the university of washington invited me to co-teach a course called \u201ccomputer vision for computer graphics\u201d. platel, b., balmachnova, e., florack, l., and ter haar romeny, b. lowe (1989) and taubin (1995) describe techniques that compensate for this shrinkage by adding an offset term based on second derivative estimates or a larger smoothing kernel (figure 4.37b).",
        "129 . this can come in particularly handy when setting up multi-view stereo reconstruction algorithms, since it allows us to sweep a series of planes (section 11.1.2) through space with a variable (projective) sampling that best matches the sensed image motions (collins 1996; szeliski and golland 1999; saito and kanade 1999). 246\u2013252, fort collins. convolving the linear tent function with itself yields the cubic approximating spline, which is called the \u201cgaussian\u201d kernel (figure 3.14c) in burt and adelson\u2019s (1983a) laplacian pyramid representation (section 3.5). sinha, p., balas, b., ostrovsky, y., and russell, r. (2006).",
        "real-time stereo matching is used to construct an accurate 3d head model and view interpolation (section 13.1) is used to synthesize the novel in-between view (criminisi, shotton, blake et al. (2003) show how evaluating equation (8.47) at just the most reliable (highest gradient) pixels does not signi\ufb01cantly reduce performance for large enough images, even if only 5\u201310% of the pixels are used. for some vision applications, algorithms based on relaxation (b.36) produce excellent results. (2006) present a recently developed algorithm along with some good references, while longere, delahunt, zhang et al. spacetime faces: high resolution capture for modeling and animation.",
        "a convenient tool to analyze (and sometimes accelerate) such neighborhood operations is the fourier transform, which we cover in section 3.4. 14.2.2 active appearance and 3d shape models . calculate a color (chromaticity) distribution for these pixels. siggraph 2004), 23(3):584\u2013591. multiview registration for large data sets.",
        "computer graphics (sig graph \u201990), 24(4):235\u2013242. the term superresolution usually describes techniques for aligning and merging multiple images to produce higher-resolution composites (keren, peleg, and brada 1988; irani and peleg 1991; cheeseman, kanefsky, hanson et al. 9.1 motion models  9.2 global alignment  . this kind of active illumination has been used from the earliest days of machine vision to construct highly reliable  surfaceccdlaser(a)direction of travelobjectccdccd image    planelasercylindrical lenslaser sheet\u03c3z\u03c3x(b)(c)(d)\f586  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  (c)  figure 12.6 shape scanning using cast shadows (bouguet and perona 1999) c(cid:13) 1999 springer: (a) camera setup with a point light source (a desk lamp without its re\ufb02ector), a hand-held stick casting a shadow, and (b) the objects being scanned in front of two planar backgrounds. grady, l. (2008)."
    ],
    "de-interlacing":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "registration iterative uncertainty":[
        "13.5 video-based rendering  643  figure 13.14 animating still pictures (chuang, goldman, zheng et al. heisele, serre, and poggio 2007) and are a widely used tool in object recognition in general. in most of the examples seen on the web, the images are aligned by hand for best artistic effect.4 however, it is also possible to use feature matching and alignment techniques to perform the registration automatically (nomura, zhang, and nayar 2007; zelnik-manor and perona 2007). 8.7 exercises  ex 8.1: correlation implement and compare the performance of the following correlation algorithms:  \u2022 sum of squared differences (8.1) \u2022 sum of robust differences (8.2) \u2022 sum of absolute differences (8.3) \u2022 bias\u2013gain compensated squared differences (8.9) \u2022 normalized cross-correlation (8.11)  \f8.7 exercises  423  \u2022 windowed versions of the above (8.22\u20138.23) \u2022 fourier-based implementations of the above measures (8.18\u20138.20) \u2022 phase correlation (8.24) \u2022 gradient cross-correlation (argyriou and vlachos 2003). a., and liu, y.",
        "however, we defer this discussion to appendix b.3, after we have explored the simpler gaussian noise case more fully. the resulting 4 \u00d7 4 system of equations can be solved to simultaneously estimate the translational displacement update \u2206u and the bias and gain parameters \u03b2 and \u03b1. in the information retrieval (or document retrieval) literature (baeza-yates and ribeironeto 1999; manning, raghavan, and sch\u00a8utze 2008), the term precision (how many returned documents are relevant) is used instead of ppv and recall (what fraction of relevant documents was found) is used instead of tpr. in iccv workshop on emergent issues in large amounts of visual data (ws-lavd), kyoto, japan. evaluate your algorithm by running it on the middlebury stereo data sets.",
        "international journal of computer vision, 87(1-2):4\u201327. c.4 bibliography  while a bibliography (bibtex .bib \ufb01le) for all of the references cited in this book is available on the book\u2019s web site, a much more comprehensive partially annotated bibliography of nearly all computer vision publications is maintained by keith price at http://iris.usc.edu/ vision-notes/bibliography/contents.html. similarly, the parameters of the prior distribution can often be learned by observing samples from the class we are modeling (roth and black 2007a; tappen 2007; li and huttenlocher 2008). a physical approach to color image understanding. (pure wavelength light can be obtained using either a prism or specially manufactured color \ufb01lters.)",
        "149\u2013155, new orleans. 82  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  figure 2.28 standard cie color matching functions: (a) \u00afr(\u03bb), \u00afg(\u03bb), \u00afb(\u03bb) color spectra obtained from matching pure colors to the r=700.0nm, g=546.1nm, and b=435.8nm primaries; (b) \u00afx(\u03bb), \u00afy(\u03bb), \u00afz(\u03bb) color matching functions, which are linear combinations of the (\u00afr(\u03bb), \u00afg(\u03bb), \u00afb(\u03bb)) spectra. 157\u2013168, pisa, italy. the second is the idea of morphing (section 3.6.3) (figure 3.53), where correspondences between pairs of images are used to warp each reference image to an in-between location while simultaneously cross-dissolving between the two warped images. 311\u2013326, freiburg, germany.",
        "in ninth international conference on computer vision (iccv 2003), pp. once this has been established, a suitable search technique must be devised. instead, the existence of three primaries is a result of the tri-stimulus (or trichromatic) nature of the human visual system, since we have three different kinds of cone, each of which responds selectively to a different portion of the color spectrum (glassner 1995; wyszecki and stiles 2000; fairchild 2005; reinhard, ward, pattanaik et al. it has the same effect on the amount of light reaching the sensor as doubling the exposure duration, e.g., from 1/125 to 1/250, see exercise 2.5.) the cosine law for triangle \u2206(c, pi, pj) gives us  pi = di \u02c6xi + c  fij(di, dj) = d2  i + d2  j \u2212 2didjcij \u2212 d2  ij = 0,  where  and  cij = cos \u03b8ij = \u02c6xi \u00b7 \u02c6xj  ij = (cid:107)pi \u2212 pj(cid:107)2. d2  (6.36)  (6.37)  (6.38)  (6.39)  (6.40)  we can take any triplet of constraints (fij, fik, fjk) and eliminate the dj and dk using  sylvester resultants (cox, little, and o\u2019shea 2007) to obtain a quartic equation in d2 i ,  gijk(d2  i ) = a4d8  i + a3d6  i + a2d4  i + a1d2  i + a0 = 0."
    ],
    "graph-based mask":[
        "finkelstein, a. and salesin, d. h. (1994). translation and rotation are also usually adequate motion models to compensate for small camera motions in applications such as photo and video stabilization and merging (exercise 6.1 and section 8.2.1). the main idea behind multigrid is to form coarser (lower-resolution) versions of the problems and use them to compute the low-frequency components of the solution. notice how the higher frequencies are aliased into visible frequencies with the lower quality \ufb01lters, while the 9-tap \ufb01lter completely removes these higher frequencies. ieee transactions on pattern analysis and machine intelligence, 17(4):378\u2013390.",
        "a., and hebert, m. (2005b). exercise 6.10 gives some more details on how to implement such a technique. segmentation-based adaptive support in paci\ufb01c-rim symposium on image and video  for accurate stereo correspondence. the results of applying these techniques to the multi-frame \ufb02ower garden image sequence are shown in figure 11.17, which compares the results of using regular (non-shifted) sssd with spatially shifted windows and full spatio-temporal window selection. klein, s., staring, m., and pluim, j. p. w.  (2007).",
        "for example, the plumb-line method (brown 1971; kang 2001; el-melegy and farag 2003) adjusts radial distortion parameters until slightly curved lines become straight, while mosaicbased approaches adjust them until mis-registration is reduced in image overlap areas (stein 1997; sawhney and kumar 1999). \u2022 the amount of defocus must be reliably estimated. bertalmio, vese, sapiro et al. szeliski, r. (2006b). computer description of curved objects.",
        "it is also possible to generalize the bilinear factorization implicit in pca and svd approaches to multilinear (tensor) formulations that can model several interacting factors simultaneously (vasilescu and terzopoulos 2007). shape from texture without boundaries. in this way, the algorithm avoids \u201ccutting through\u201d moving objects where a seam would look unnatural (davis 1998). radial distortion snakes. nodes are exterior, and gray nodes are of mixed occupancy.",
        "more recently, max-\ufb02ow and graph cut methods have been proposed to solve a special class of global optimization problems (roy and cox 1998; boykov, veksler, and zabih 2001; ishikawa 2003). gooch, b. and gooch, a. scale & af\ufb01ne invariant interest point detectors. 3.1.4 histogram equalization  while the brightness and gain controls described in section 3.1.1 can improve the appearance of an image, how can we automatically determine their best values? field, d. j."
    ],
    "recovery epipolar geometry":[
        "tune the algorithm parameters to give you good results. bartoli, a., coquerelle, m., and sturm, p.  (2004). zhang, l., dugas-phocion, g., samson, j.-s., and seitz, s. m. (2002). in the 1980s, a lot of attention was focused on more sophisticated mathematical  1980s. fast image-based tracking by selective pixel integration.",
        "in ninth international conference on computer vision (iccv 2003), pp. once this has been established, a suitable search technique must be devised. instead, the existence of three primaries is a result of the tri-stimulus (or trichromatic) nature of the human visual system, since we have three different kinds of cone, each of which responds selectively to a different portion of the color spectrum (glassner 1995; wyszecki and stiles 2000; fairchild 2005; reinhard, ward, pattanaik et al. it has the same effect on the amount of light reaching the sensor as doubling the exposure duration, e.g., from 1/125 to 1/250, see exercise 2.5.) the cosine law for triangle \u2206(c, pi, pj) gives us  pi = di \u02c6xi + c  fij(di, dj) = d2  i + d2  j \u2212 2didjcij \u2212 d2  ij = 0,  where  and  cij = cos \u03b8ij = \u02c6xi \u00b7 \u02c6xj  ij = (cid:107)pi \u2212 pj(cid:107)2. d2  (6.36)  (6.37)  (6.38)  (6.39)  (6.40)  we can take any triplet of constraints (fij, fik, fjk) and eliminate the dj and dk using  sylvester resultants (cox, little, and o\u2019shea 2007) to obtain a quartic equation in d2 i ,  gijk(d2  i ) = a4d8  i + a3d6  i + a2d4  i + a1d2  i + a0 = 0.",
        "real-time scene stabilization and mosaic construction. hoiem, d., rother, c., and winn, j. triangulate to the remaining points on each curve to get a 3d stripe and display the  stripes using a 3d graphics engine. over-parameterized variational optical  \ufb02ow. automatic camera recovery for closed and open image sequences.",
        "international journal of computer vision, 80(2):189\u2013210. 2007) and panorama and location recognition (brown and lowe 2007; schindler, brown, and szeliski 2007). matching the frequency characteristics, which is equivalent to matching spatial correlations, is in itself not suf\ufb01cient. the color-dependent blurring caused by chromatic aberration (figure 2.21) can also be removed using the de-blurring techniques discussed in  10 this process confounds the distinction between geometric and photometric calibration. for higher bit depths, a table with the appropriate number of entries (probably fewer than the full number of gray levels) should be used.",
        "modeling and recogin tenth european  nition of landmark image collections using iconic scene graphs. carroll, r., agrawala, m., and agarwala, a. murphy-chutorian, e. and trivedi, m. m.  (2009). 9.1.5 application: video summarization and compression . of course, real lenses are not in\ufb01nitely thin and therefore suffer from geometric aberrations, unless compound elements are used to correct for them."
    ],
    "quaternions absolute orientation":[
        "quadtrees and pyramids for pattern recognition and image processing. you may need to put your camera on a tripod and align the images manually or automatically to make this work. 2003; criminisi, p\u00b4erez, and toyama 2004; sun, yuan, jia et al. in ieee workshop on applications of computer vision (wacv 2009), snowbird, utah. for simple energy functions, e.g., those where the penalty for non-identical neighboring pixels is a constant, this algorithm is guaranteed to produce the global minimum.",
        "international journal of  computer vision, 1(1):279\u2013302. sullivan, s. and ponce, j. a burst of activity in using projective invariants for recognition (mundy and zisserman 1992) evolved into a concerted effort to solve the structure from motion problem (see chapter 7). 263\u2013274. zhu, s. c. and yuille, a. l. (1996).",
        "single view modeling of free-form scenes. the last part of this chapter explores the topic of video-based rendering, which uses one or more videos in order to create novel video-based experiences (section 13.5). for example, most of the top-performing algorithms on the middlebury stereo evaluation page either use belief propagation or graph cuts. until it can guarantee that the nearest neighbor has been found. 148 .",
        "the quality and reliability of matting algorithms can also be enhanced using more sophisticated acquisition systems. machine learning for high-speed corner detection. a different kind of implicit shape model can be constructed by de\ufb01ning a signed distance function over a regular three-dimensional grid, optionally using an octree spline to represent this function more coarsely away from its surface (zero-set) (lavall\u00b4ee and szeliski 1995; szeliski and lavall\u00b4ee 1996; frisken, perry, rockwood et al. when using the newer color de\ufb01nitions for hdtv in bt.709, the formula is  y (cid:48)709 = 0.2125r(cid:48) + 0.7154g(cid:48) + 0.0721b(cid:48). therefore, the likelihood that s such trials will all fail is  and the required minimum number of trials is  1 \u2212 p = (1 \u2212 pk)s  (6.29)  (6.30)  s =  log(1 \u2212 p ) log(1 \u2212 pk) .",
        "komodakis and tziritas (2007b) present an mrf-based version of this block synthesis algorithm that uses a new, ef\ufb01cient version of loopy belief propagation they call \u201cpriority-bp\u201d. deformed lattice detection in real-world images using mean-shift belief propagation. (b) a weighted gradient orientation histogram is then computed in each subregion, using trilinear interpolation. papert, s.  (1966). in equation (b.5), we have indicated that ni is a zero-mean normal (gaussian) random variable with a covariance matrix \u03c3i."
    ],
    "view interpolation gradient descent update rule":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "camera joint geometric medical image medical imaging":[
        "223\u2013229, vancouver, canada. 4.1.2 . implementations for the fft can be found in most numerical and signal processing libraries. figure 10.8b shows how the radial distortion and chromatic aberration manifest themselves as elongated and displaced psfs, along with the result of removing these effects in a region of the calibration target. at query time, only the primary (closest) indices are used, so only a single three-dimensional bin needs to  \f4.1 points and patches  233  (a)  (b)  figure 4.27 k-d tree and best bin \ufb01rst (bbf) search (beis and lowe 1999) c(cid:13) 1999 ieee: (a) the spatial arrangement of the axis-aligned cutting planes is shown using dashed lines.",
        "articulated mesh animation  from multi-view silhouettes. we do not explain the details of the algorithm here, except to say that it involves a series of log2 n stages, where each stage performs small 2\u00d7 2 transforms (matrix multiplications with known coef\ufb01cients) followed by some semi-global permutations. more recent splitting algorithms often optimize some metric of intra-region similarity and  inter-region dissimilarity. one commonly used technique is called the orthogonal procrustes algorithm (golub and van loan 1996, p. 601) and involves computing the singular value decomposition (svd) of  8 when full covariances are used, they are transformed by the rotation and so a closed-form solution for transla tion is not possible. since these techniques are fairly involved, you will need to read several of the research papers in this area, select which general approach you want to follow, and then implement your algorithm.",
        "the signal is \ufb01rst (theoretically) interpolated to a continuous waveform, (ideally) low-pass \ufb01ltered to below the new nyquist rate, and then re-sampled to the \ufb01nal desired resolution. compute an optimal 2d translation and rotation between the \ufb01rst image and all subsequent images, using least squares (section 6.1.1) with optional ransac for robustness (section 6.1.4). the amount of mis-focus is measured by the circle of confusion c (shown as short thick blue line segments on the gray plane).7 the equation for the circle of confusion can be derived using similar triangles; it depends on the distance of travel in the focal plane \u2206zi relative to the original focus distance zi and the diameter of the aperture d (see exercise 2.4). the quality of a compression algorithm is usually reported using its peak signal-to-noise  ratio (psnr), which is derived from the average mean square error,  m se =  1  n(cid:88)x (cid:104)i(x) \u2212 \u02c6i(x)(cid:105)2  ,  (2.117)  where i(x) is the original uncompressed image and \u02c6i(x) is its compressed counterpart, or equivalently, the root mean square error (rms error), which is de\ufb01ned as  rm s = \u221am se. for example, for a summed area table, an impulse generates an in\ufb01nite rectangle of 1s below and to the right of the impulse.",
        "the former involves re-recognizing a known 2d or 3d rigid object, potentially being viewed from a novel viewpoint, against a cluttered background, and with partial occlusions. ex 12.7: body tracker download the video sequences from the humaneva web site.16 either implement a human motion tracker from scratch or extend the code on that web site (sigal, balan, and black 2010) in some interesting way. komodakis, n. and paragios, n. (2008). shafer, s. a., healey, g., and wolff, l.  (1992). (2008) show how to adapt the baselines used to the expected depth in order to get the best tradeoff between geometric accuracy (wide baseline) and robustness to occlusion (narrow baseline).",
        "as with de-interlacing, information from novel in-between frames needs to be interpolated from preceding and subsequent frames. figure 5.18 shows an example of mean-shift clustering in the joint domain, with parameters (hs, hr, m) = (16, 19, 40), where spatial regions containing less than m pixels are eliminated. to reduce the amount of computation required, only a small strip (frontier) around the locations of the current zero-crossing needs to updated at each step, which results in what are called fast marching methods (sethian 1999). a discriminatively trained, multiscale, deformable part model. ieee transactions on pattern  analysis and machine intelligence, 28(11):1768\u20131783."
    ],
    "interpolation hole \ufb01lling":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "global locally adaptive graph cut smoothness af\ufb01ne optical \ufb02ow stereo matching shape priors":[
        "litvinov, a. and schechner, y. y. 2001), see section 10.5.2. in order to allow the viewer to look around in all directions, it is preferable to use a panoramic video camera (uyttendaele, criminisi, kang et al. unfortunately, because the dense system solving is cubic in the number of data points, basis function approaches can only be used for small problems such as feature-based image morphing (beier and neely 1992). replace the current value with this weighted mean and iterate until either the motion is  below a threshold or a \ufb01nite number of steps has been taken.",
        "local, global, and multilevel stereo matching. 7.7 exercises  . (optional) if you have a denser 3d model (e.g., from stereo), decide what to do at the  \u201ccracks\u201d. proceedings, los angeles. 3.5.3 multi-resolution representations  now that we have described interpolation and decimation algorithms, we can build a complete image pyramid (figure 3.32).",
        "again, fourier transforms can be used to ef\ufb01ciently compute all the correlations needed to perform the linear regression in the bias and gain parameters in order to estimate the exposure-compensated difference for each potential shift (exercise 8.1). for example, only three basis functions are required for the second-order directional derivative,  g\u02c6u\u02c6u = u2gxx + 2uvgxy + v2gyy. highly accurate international journal of  optic \ufb02ow computation with theoretically justi\ufb01ed warping. debevec and malik (1997) show how this can be implemented in 21 lines of matlab code, which partially accounts for the popularity of their technique. fast approximate energy minimization ieee transactions on pattern analysis and machine intelligence,  via graph cuts.",
        "active shape models\u2014their  training and application. does the amount of noise vary a lot with iso/gain? 73\u201380, san francisco. 237\u2013246, birmingham, england. the equations to map points on the surface of a 3d triangle to a 2d image are straightforward: just pass the local 2d coordinates on the triangle through the 3 \u00d7 4 camera projection matrix to obtain a 3 \u00d7 3 homography (planar perspective projection).",
        "xyx\u2019y\u2019xyx\u2019y\u2019xyx\u2019y\u2019ay\u2019yay\u2019xax\u2019xax\u2019y(a)(b)(c)major axisminor axis\f168  computer vision: algorithms and applications (september 3, 2010 draft)  pyramid (figure 3.32), where each level is pre-\ufb01ltered with a high-quality \ufb01lter rather than a poorer quality approximation, such as burt and adelson\u2019s (1983b) \ufb01ve-tap binomial. 8 this section was contributed by vladimir kolmogorov. doll`ar, p., wojek, c., schiele, b., and perona, p. (2009). technical re port aim-249, arti\ufb01cial intelligence laboratory, stanford university. we begin this chapter with the simplest kind of image transforms, namely those that manipulate each pixel independently of its neighbors (section 3.1)."
    ],
    "motion homography":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "belief propagation loopy belief propagation":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "scanline optimization alpha expansion sparse edge-based semi-global optimization":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "inference regularization graph cuts random walker light \ufb01eld view morphing parameters image search anisotropic spherical pairs twist coarse-to-\ufb01ne":[
        "control point (szeliski and kang 1995; szeliski and coughlan 1997). in the absence of inter-re\ufb02ections (e.g., a convex object in a large open space), each surface point simply re\ufb02ects the far-\ufb01eld environment map (section 2.2.1), which again is two-dimensional. 306  \f268  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (c)  (e)  (b)  (d)  (f)  figure 5.1 some popular image segmentation techniques: (a) active contours (isard and blake 1998) c(cid:13) 1998 springer; (b) level sets (cremers, rousson, and deriche 2007) c(cid:13) 2007 springer; (c) graph-based merging (felzenszwalb and huttenlocher 2004b) c(cid:13) 2004 springer; (d) mean shift (comaniciu and meer 2002) c(cid:13) 2002 ieee; (e) texture and intervening contour-based normalized cuts (malik, belongie, leung et al. the \ufb01rst three columns show correct detections, while the rightmost column shows false positives. common plane seen by all the cameras (rother and carlsson 2002).",
        "learning a spatially smooth in ieee computer society conference on computer  subspace for face recognition. optical \ufb02ow using spatiotemporal \ufb01lters. the measurement equation is ai = (xi, yi, 1) and the unknown  parameters are x = (a, b, c). mitiche, a. and bouthemy, p.  (1996). (2000) suggest matching triplets or larger neighborhoods of adjacent video frames, much in the same way as video rewrite matches triphones.",
        "computer vision and image understanding, 84(1):77\u2013103. poynton, in his color faq, http://www.poynton.com/ colorfaq.html, notes that the perceptually motivated l*a*b* system is qualitatively similar to the gamma-compressed r\u2019g\u2019b\u2019 system we mostly deal with, since both have a fractional power scaling (which approximates a logarithmic response) between the actual intensity values and the numbers being manipulated. the answer is yes, if you are willing to \ufb01rst segment the image into different layers and then animate each layer separately. these include:  \u2022 stitching: turning overlapping photos into a single seamlessly stitched panorama (figure 1.5a), as described in chapter 9; \u2022 exposure bracketing: merging multiple exposures taken under challenging lighting conditions (strong sunlight and shadows) into a single perfectly exposed image (figure 1.5b), as described in section 10.2; \u2022 morphing: turning a picture of one of your friends into another, using a seamless morph transition (figure 1.5c); \u2022 3d modeling: converting one or more snapshots into a 3d model of the object or person you are photographing (figure 1.5d), as described in section 12.6 \u2022 video match move and stabilization: inserting 2d pictures or 3d models into your videos by automatically tracking nearby reference points (see section 7.4.2)3 or using motion estimates to remove shake from your videos (see section 8.2.1); \u2022 photo-based walkthroughs: navigating a large collection of photographs, such as the interior of your house, by \ufb02ying between different photos in 3d (see sections 13.1.2 and 13.5.5) \u2022 face detection: for improved camera focusing as well as more relevant image searching (see section 14.1.1); \u2022 visual authentication: automatically logging family members onto your home computer as they sit down in front of the webcam (see section 14.2). note that radial distortion needs to be removed from such images before the feature points can be used for calibration.",
        "10.4.3 optimization-based matting . at the time, it was believed by some of the early pioneers of arti\ufb01cial intelligence and robotics (at places such as mit, stanford, and cmu) that solving the \u201cvisual input\u201d problem would be an easy step along the path to solving more dif\ufb01cult problems such as higher-level reasoning and planning. 7.3.2 application: sparse 3d model extraction . for instance recognition (section 14.3.1), this can sometimes be achieved by backprojecting the object model into  \f14.4 category recognition  705  (a)  (b)  (c)  figure 14.42 part-based recognition (fergus, perona, and zisserman 2007) c(cid:13) 2007 springer: (a) locations and covariance ellipses for each part, along with their occurrence probabilities (top) and relative log-scale densities (bottom); (b) part examples drawn from the training images that best match the average appearance; (c) recognition results for the motorcycle class, showing detected features (pink dots) and parts (colored circles). b.5.4 graph cuts  the computer vision community has adopted \u201cgraph cuts\u201d as an informal name to describe a large family of mrf inference algorithms based on solving one or more min-cut or max\ufb02ow problems (boykov, veksler, and zabih 2001; boykov and kolmogorov 2010; boykov,  \fb.5 markov random \ufb01elds  771  (a)  (b)  figure b.3 graph cuts for minimizing binary sub-modular mrf energies (boykov and jolly 2001) c(cid:13) 2001 ieee: (a) energy function encoded as a max \ufb02ow problem; (b) the minimum cut determines the region boundary.",
        "the development of fully automated stereo matching algorithms was a major advance in this \ufb01eld, enabling much more rapid and less expensive processing of aerial imagery (hannah 1974; hsieh, mckeown, and perlant 1992). for some practical mrf problems, lp-based techniques can produce globally minimal solutions (meltzer, yanover, and weiss 2005), even though mrf inference is in general np-hard. 436  computer vision: algorithms and applications (september 3, 2010 draft)  (a)  (b)  figure 9.5 gap closing (szeliski and shum 1997) c(cid:13) 1997 acm: (a) a gap is visible when the focal length is wrong (f = 510). (2007)  50 toys  lecun, huang, and bottou (2004)  75,000 (wordnet) things  torralba, freeman, and fergus (2008)  imagenet  http://www.image-net.org/  complete images  14,000 (wordnet) things  deng, dong, socher et al. we can do this if we represent perspective projection using a full-rank 4 \u00d7 4 matrix, as in (2.64)."
    ],
    "object-centered image restoration unstructured":[
        "and kweon, i.-s.  (2006). poxels: probabilistic voxelized volume reconstruction. robust anisotropic  diffusion. figure 3.45 shows a few ex fxhffghghhgxfxgxyxsimilarityeuclideanaffineprojectivetranslation\f164  computer vision: algorithms and applications (september 3, 2010 draft)  transformation  matrix  # dof preserves  icon  translation  rigid (euclidean)  similarity  af\ufb01ne  projective  (cid:104) i t (cid:105)2\u00d73 (cid:104) r t (cid:105)2\u00d73 (cid:104) sr t (cid:105)2\u00d73 (cid:104) a (cid:105)2\u00d73 (cid:104) \u02dch (cid:105)3\u00d73  2  3  4  6  8  orientation  lengths  angles  \u001a\u001a ss ss \u001a\u001a \u001a s s \u001a \u0002\u0002 \u0002\u0002    straight lines ``  parallelism  table 3.5 hierarchy of 2d coordinate transformations. 7.3 factorization  when processing video sequences, we often get extended feature tracks (section 4.1.4) from which it is possible to recover the structure and motion using a process called factorization.",
        "note that the map estimate may not always be desirable, since it selects the \u201cpeak\u201d in the posterior distribution rather than some more stable statistic\u2014see the discussion in appendix b.2 and by levin, weiss, durand et al. once the entries in p have been recovered, it is possible to recover both the intrinsic calibration matrix k and the rigid transformation (r, t) by observing from equation (2.56) that  p = k[r|t]. extract edges and link them (exercises 4.7\u20134.8). international journal of computer vision, 59(2):167\u2013181. 2003) c(cid:13) 2003 acm.",
        "edge detector evaluation using  empirical roc curves. edges and lines provide information that is complementary to both keypoint and region-based descriptors and are well-suited to describing object boundaries and man-made objects. image does not pass through the input data points) that produces soft images with reduced high-frequency detail. convert your similarity table into a jump probability table through some exponential distribution. frequency response to color than to luminance changes.)",
        "active shape models\u2014their  training and application. does the amount of noise vary a lot with iso/gain? 73\u201380, san francisco. 237\u2013246, birmingham, england. the equations to map points on the surface of a 3d triangle to a 2d image are straightforward: just pass the local 2d coordinates on the triangle through the 3 \u00d7 4 camera projection matrix to obtain a 3 \u00d7 3 homography (planar perspective projection).",
        "grimson, w. e. l. (1983). and levoy, m. (2000). elimination of seams from photomosaics. weiss, y., torralba, a., and fergus, r. (2008). (2.19)  parallel lines remain parallel under af\ufb01ne transformations."
    ],
    "\ufb02ux directed edges parallax removal triangulation global optimization contour-based closing":[
        "finding groups in data: an introduction to  cluster analysis. how well does your algorithm do against local aggregation (yoon and kweon 2006)? determining the best bandwidth parameters h to use with mean shift remains something of an art, although a number of approaches have been explored. for example, simon, snavely, and seitz (2007) show how the match graph between images of popular tourist sites  \f626  computer vision: algorithms and applications (september 3, 2010 draft)  can be used to \ufb01nd the most iconic (commonly photographed) objects in the collection, along with their related tags. appendix b: bayesian modeling and inference  middlebury source code for mrf minimization, http://vision.middlebury.edu/mrf/ code/ (szeliski, zabih, scharstein et al.",
        "image completion using ef\ufb01cient belief propieee transactions on image  komodakis, n., paragios, n., and tziritas, g. (2007). transforming an arbitrary minsum problem into a  binary one. create a morph by partially warping the images towards each other and cross-dissolving  (section 3.6.3). compute a scalar interest measure using one of the formulas discussed above. with accurate physical models of radiance transport and color image formation created its own sub\ufb01eld known as physics-based vision.",
        "in this particular model, each smoothness term depends only on its adjacent pair of data values, i.e., terms are of the form vp,q(xp, xq, yp, yq) in (3.118). map estimation via agreement on trees: message-passing and linear programming. some of these techniques are described in more detail in section 6.3.5, which discusses how to calibrate lens distortions. 101 . sceneradiancedsprawsensor chipcamera bodyopticsaperturesensor(ccd/cmos)adcdemosaic(sharpen)white balancegamma/curvecompressshuttergain(iso)jpegadcrawdspsensor chipcamera bodyscene radianceopticsaperturesensor(ccd/cmos)demosaic(sharpen)white balancegamma/curvecompressshuttergain(iso)jpegblur kern.",
        "computer vision and image understanding, 84(1):77\u2013103. poynton, in his color faq, http://www.poynton.com/ colorfaq.html, notes that the perceptually motivated l*a*b* system is qualitatively similar to the gamma-compressed r\u2019g\u2019b\u2019 system we mostly deal with, since both have a fractional power scaling (which approximates a logarithmic response) between the actual intensity values and the numbers being manipulated. the answer is yes, if you are willing to \ufb01rst segment the image into different layers and then animate each layer separately. these include:  \u2022 stitching: turning overlapping photos into a single seamlessly stitched panorama (figure 1.5a), as described in chapter 9; \u2022 exposure bracketing: merging multiple exposures taken under challenging lighting conditions (strong sunlight and shadows) into a single perfectly exposed image (figure 1.5b), as described in section 10.2; \u2022 morphing: turning a picture of one of your friends into another, using a seamless morph transition (figure 1.5c); \u2022 3d modeling: converting one or more snapshots into a 3d model of the object or person you are photographing (figure 1.5d), as described in section 12.6 \u2022 video match move and stabilization: inserting 2d pictures or 3d models into your videos by automatically tracking nearby reference points (see section 7.4.2)3 or using motion estimates to remove shake from your videos (see section 8.2.1); \u2022 photo-based walkthroughs: navigating a large collection of photographs, such as the interior of your house, by \ufb02ying between different photos in 3d (see sections 13.1.2 and 13.5.5) \u2022 face detection: for improved camera focusing as well as more relevant image searching (see section 14.1.1); \u2022 visual authentication: automatically logging family members onto your home computer as they sit down in front of the webcam (see section 14.2). note that radial distortion needs to be removed from such images before the feature points can be used for calibration.",
        "320 . (optional) write a simple tool to let the user adjust the ordering and opacity, and add  or remove images. figure 14.30b shows some typical images from the database of objects taken under varying viewpoints and illumination that was used to train and test the vocabulary tree recognition system. 5.3.1 k-means and mixtures of gaussians  while k-means implicitly models the probability density as a superposition of spherically symmetric distributions, it does not require any probabilistic reasoning or modeling (bishop 2006). (2006)  toys, boxes, magazines  ferrari, tuytelaars, and van gool (2006b)  motorbikes, cars, cows  leibe, leonardis, and schiele (2008)  23 classes  http://research.microsoft.com/en-us/projects/objectclassrecognition/  shotton, winn, rother et al."
    ],
    "face pedestrian car sub-pixel re\ufb01nement arc length parameterization modeling recovery support vector machines concentric mosaic tight frame direct vs. feature-based face examples primaries boosting neural networks automotive safety gist heads and faces initialization light slab boosting algorithm initialization requirements color texture motion facial feature active appearance model head tracking":[
        "ferencz, a., learned-miller, e. g., and malik, j. motion estimation algorithms often use a similarity transform to handle camera translations, rotations, and zooming. representative papers in this area include (sawhney and ayer 1996; jojic and frey 2001; xiao and shah 2005; kumar, torr, and zisserman 2008; thayananthan, iwasaki, and cipolla 2008; schoenemann and cremers 2008). if the images are not pre-recti\ufb01ed, compute the homography that resamples the target image into the reference image\u2019s coordinate system for each plane. (the latter was a course i co-taught with david fleet in 2003.)",
        "(in fact, this formula is a smallde\ufb02ection approximation to the surface area, which is what soap bubbles minimize.) the discrete form of the fourier transform (3.54) is known as the discrete fourier transform (dft). 14.2.1 eigenfaces  eigenfaces rely on the observation \ufb01rst made by kirby and sirovich (1990) that an arbitrary face image x can be compressed and reconstructed by starting with a mean image m (figure 14.1b) and adding a small number of scaled signed images ui,7  \u02dcx = m +  aiui,  (14.8)  where the signed basis images (figure 14.13b) can be derived from an ensemble of training images using principal component analysis (also known as eigenvalue analysis or the karhunen\u2013lo`eve transform). use the feature detector, descriptor, and matcher developed in exercises 4.1\u20134.4 (or  existing software) to match features among the images. wavelets and the lifting scheme: a 5 minute tour.",
        "the \ufb01rst question, then, is how to estimate the density function given a sparse set of samples. the af\ufb01ne transformation is written as x(cid:48) = a\u00afx, where a is an arbitrary 2 \u00d7 3 matrix, i.e.,  x(cid:48) =(cid:34) a00 a01 a02  a10 a11 a12 (cid:35) \u00afx. 823\u2013826, lausanne. devising techniques to estimate these unknowns despite the underconstrained nature of the problem is the essence of image matting. conditional models for contextual human motion recognition.",
        "image registration methods: a survey. 2031, geometric methods in computer vision ii, pp. algorithms for stabilization run inside both hardware devices, such as camcorders and still cameras, and software packages for improving the visual quality of shaky videos. in this case, the inclusion of the third row of the camera matrix in (7.40) is equivalent to multiplying each reconstructed measurement xji = m jpi by its inverse (projective) depth \u03b7ji = d\u22121 ji = 1/(p j2pi) or, equivalently, multiplying each measured position by its projective depth dji,  = \u02c6m \u02c6s. the seminal paper on markov random \ufb01elds is the work of geman and geman (1984), who introduced this formalism to computer vision researchers and also introduced the notion of line processes, additional binary variables that control whether smoothness penalties are enforced or not.",
        "at the top level, the distributions of objects relative to each other (say, buildings with respect to cars) is modeled as a gaussian (figure 14.50c, upper right corners). 3d grids can be used to compute globally optimal segmentations in 3d volumetric medical images (boykov and funka-lea 2006) (section 5.5.1). veksler, o. however, if video is being captured, a rolling shutter, which exposes and transfers each line separately, is often used. master\u2019s thesis, rochester institute of technology."
    ],
    "dynamic mean average precision image restoration parametric estimation robust seed and grow multiplication color model auto-correlation intervening contour over operator regularization least squares pre-multiplied opening weighted radial color equations reduced motion slippery spring basins zero crossing global alignment similarity color texture strategy robust whiteboard and document scanning environment matte precision":[
        "the signal is \ufb01rst (theoretically) interpolated to a continuous waveform, (ideally) low-pass \ufb01ltered to below the new nyquist rate, and then re-sampled to the \ufb01nal desired resolution. compute an optimal 2d translation and rotation between the \ufb01rst image and all subsequent images, using least squares (section 6.1.1) with optional ransac for robustness (section 6.1.4). the amount of mis-focus is measured by the circle of confusion c (shown as short thick blue line segments on the gray plane).7 the equation for the circle of confusion can be derived using similar triangles; it depends on the distance of travel in the focal plane \u2206zi relative to the original focus distance zi and the diameter of the aperture d (see exercise 2.4). the quality of a compression algorithm is usually reported using its peak signal-to-noise  ratio (psnr), which is derived from the average mean square error,  m se =  1  n(cid:88)x (cid:104)i(x) \u2212 \u02c6i(x)(cid:105)2  ,  (2.117)  where i(x) is the original uncompressed image and \u02c6i(x) is its compressed counterpart, or equivalently, the root mean square error (rms error), which is de\ufb01ned as  rm s = \u221am se. for example, for a summed area table, an impulse generates an in\ufb01nite rectangle of 1s below and to the right of the impulse.",
        "we also discuss tone mapping operators, which map rich images back into regular display devices, such as screens and printers, as well as algorithms that merge \ufb02ash and regular images to obtain better exposures (figure 10.1b). if it does not work, does aligning sub-sections (e.g., quarters) do better? an approach to automatic morphing of face images in frontal view. for second-order problems, the crease variables cx(i, j), cm(i, j), and cy(i, j) control the locations of creases in the surface (terzopoulos 1988; szeliski 1990a). before describing the dp algorithm, let us re-write the potential function of equation (b.24)  in a more general but succinct form,  e(x) = (cid:88)(i,j)\u2208n  vi,j(xi, xj) +(cid:88)i  vi(xi),  (b.26)  where instead of using pixel indices (i, j) and (k, l), we just use scalar index variables i and j.",
        "cam bridge university press. computing the voronoi diagram is one way to select the seams between regions where different images contribute to the \ufb01nal composite. 1999; cootes, edwards, and taylor 2001; gross, baker, matthews et al. the breadth of the problems and techniques inherent in this \ufb01eld, combined with the richness of the mathematics and the utility of the resulting algorithms, will ensure that this remains an exciting area of study for years to come. originally, z-keying systems required expensive custom-built hardware to produce the desired depth maps in real time and were, therefore, restricted to broadcast studio applications (kanade, yoshida, oda et al.",
        "terzopoulos, d. and metaxas, d. (1991). an example of such a descriptor is the spin image, which is a local circular projection of a 3d surface patch around the local normal axis (johnson and hebert 1999). among the techniques they survey, they \ufb01nd that the improved (gaussian derivative) version of the harris operator with \u03c3d = 1 (scale of the derivative gaussian) and \u03c3i = 2 (scale of the integration gaussian) works best. more sophisticated derivatives can sometimes lead to noticeable performance improvements. figure 9.9 a spherical panorama constructed from 54 photographs (szeliski and shum 1997) c(cid:13) 1997 acm.",
        "more sophisticated kernels can be created by \ufb01rst smoothing the image with a (unit area) gaussian \ufb01lter,  and then taking the \ufb01rst or second derivatives (marr 1982; witkin 1983; freeman and adelson 1991). in this case, morphing, i.e., warping and blending frames during transitions (section 3.6.3) can be used to hide the visual differences (figure 13.13c). one of the more popular 3d representations is a uniform grid of 3d voxels,7 which can be reconstructed using a variety of carving (seitz and dyer 1999; kutulakos and seitz 2000) or optimization (sinha and pollefeys 2005; vogiatzis, hernandez, torr et al. tracking with \ufb02ow. xkvikxjxivjk.........xrvijxkvijkxjxi.........\f768  computer vision: algorithms and applications (september 3, 2010 draft)  dynamic programming is not restricted to trees with pairwise potentials."
    ],
    "hardware implementation":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "layers specularities surface reconstruction intrinsic graph cuts":[
        "inf.ed.ac.uk/rbf/cvonline/), visionbib.com (http://datasets.visionbib.com/), and computer vision online (http://computervisiononline.com/), have more recent pointers. for problems where the posterior energy is non-quadratic, e.g., in non-linear or robusti\ufb01ed least squares, it is still often possible to obtain an estimate of the hessian in the vicinity of the optimal solution. an alternative approach to global optimization is to sweep through the 3d volume while computing both photoconsistency and visibility simultaneously. one \ufb01nal coordinate mapping worth mentioning is the polar mapping, where the north  8see also http://gigapan.org. model-based estimation of 3d human motion.",
        "1986; black and rangarajan 1996; stewart 1999), which involves applying a robust penalty function \u03c1(r) to the residuals  erls(\u2206p) =(cid:88)i  \u03c1((cid:107)ri(cid:107))  (6.25)  (6.26)  instead of squaring them. international journal of computer vision, 17(1):43\u201375. face recognition can also be used in a variety of additional applications, including human\u2013computer interaction (hci), identity veri\ufb01cation (kirovski, jojic, and jancke 2004), desktop login, parental controls, and patient monitoring (zhao, chellappa, phillips et al. (optional) compensate for images that are blurry because of fast motion by \u201cstealing\u201d  higher frequencies from adjacent frames. in international conference on pattern recognition (icpr 2006), pp.",
        "recovering consistent video depth in ieee computer society conference on computer  maps via bundle optimization. 636 . a method for registration of 3-d shapes. they also describe how trimaps drawn at sparse keyframes can be interpolated to in-between frames using bi-direction optic \ufb02ow. we also look at the topic of multi-view stereo algorithms that produce complete 3d volumetric or surface-based object models.",
        "computer vision and image understanding, 84(1):77\u2013103. poynton, in his color faq, http://www.poynton.com/ colorfaq.html, notes that the perceptually motivated l*a*b* system is qualitatively similar to the gamma-compressed r\u2019g\u2019b\u2019 system we mostly deal with, since both have a fractional power scaling (which approximates a logarithmic response) between the actual intensity values and the numbers being manipulated. the answer is yes, if you are willing to \ufb01rst segment the image into different layers and then animate each layer separately. these include:  \u2022 stitching: turning overlapping photos into a single seamlessly stitched panorama (figure 1.5a), as described in chapter 9; \u2022 exposure bracketing: merging multiple exposures taken under challenging lighting conditions (strong sunlight and shadows) into a single perfectly exposed image (figure 1.5b), as described in section 10.2; \u2022 morphing: turning a picture of one of your friends into another, using a seamless morph transition (figure 1.5c); \u2022 3d modeling: converting one or more snapshots into a 3d model of the object or person you are photographing (figure 1.5d), as described in section 12.6 \u2022 video match move and stabilization: inserting 2d pictures or 3d models into your videos by automatically tracking nearby reference points (see section 7.4.2)3 or using motion estimates to remove shake from your videos (see section 8.2.1); \u2022 photo-based walkthroughs: navigating a large collection of photographs, such as the interior of your house, by \ufb02ying between different photos in 3d (see sections 13.1.2 and 13.5.5) \u2022 face detection: for improved camera focusing as well as more relevant image searching (see section 14.1.1); \u2022 visual authentication: automatically logging family members onto your home computer as they sit down in front of the webcam (see section 14.2). note that radial distortion needs to be removed from such images before the feature points can be used for calibration.",
        "the resulting data structure, which is called a layered depth image (ldi), can be used to render new views using a back-to-front forward warping (splatting) algorithm (shade, gortler, he et al. this has the advantage that any scalar change in variables (e.g., using radians instead of degrees for angular measurements) has no effect on the range of convergence of the iterative technique. next, the ideal pattern, whose analytic form is known, is warped (using a homography) to  \f10.1 photometric calibration  477  figure 10.7 calibration pattern with edges equally distributed at all orientations that can be used for psf and radial distortion estimation (joshi, szeliski, and kriegman 2008) c(cid:13) 2008 ieee. the gradients for this function are set to lie along oriented surface normals near known surface points and 0 elsewhere. tappen, m. f., freeman, w. t., and adelson, e. h. (2005)."
    ],
    "total least squares taxonomy large scale probabilistic symmetry-seeking":[
        "(2004) present a related approach where the user draws interactive lines to indicate where structures should be preferentially propagated. wavelets are \ufb01lters that localize a signal in both space and frequency (like the gabor \ufb01lter in table 3.2) and are de\ufb01ned over a hierarchy of scales. 900\u2013907, nice, france. ex 8.8: motion segmentation write a program to segment an image into separately moving regions or to reliably \ufb01nd motion boundaries. since pixel values are more reliable in the middle of their range (and the g function becomes singular near saturation values), they also add a weighting (hat) function w(k) that decays to zero at both ends of the pixel value range,  w(z) =(cid:40) z \u2212 zmin  zmax \u2212 z  z \u2264 (zmin + zmax)/2 z > (zmin + zmax)/2.",
        "computer vision and image understanding, 84(1):77\u2013103. poynton, in his color faq, http://www.poynton.com/ colorfaq.html, notes that the perceptually motivated l*a*b* system is qualitatively similar to the gamma-compressed r\u2019g\u2019b\u2019 system we mostly deal with, since both have a fractional power scaling (which approximates a logarithmic response) between the actual intensity values and the numbers being manipulated. the answer is yes, if you are willing to \ufb01rst segment the image into different layers and then animate each layer separately. these include:  \u2022 stitching: turning overlapping photos into a single seamlessly stitched panorama (figure 1.5a), as described in chapter 9; \u2022 exposure bracketing: merging multiple exposures taken under challenging lighting conditions (strong sunlight and shadows) into a single perfectly exposed image (figure 1.5b), as described in section 10.2; \u2022 morphing: turning a picture of one of your friends into another, using a seamless morph transition (figure 1.5c); \u2022 3d modeling: converting one or more snapshots into a 3d model of the object or person you are photographing (figure 1.5d), as described in section 12.6 \u2022 video match move and stabilization: inserting 2d pictures or 3d models into your videos by automatically tracking nearby reference points (see section 7.4.2)3 or using motion estimates to remove shake from your videos (see section 8.2.1); \u2022 photo-based walkthroughs: navigating a large collection of photographs, such as the interior of your house, by \ufb02ying between different photos in 3d (see sections 13.1.2 and 13.5.5) \u2022 face detection: for improved camera focusing as well as more relevant image searching (see section 14.1.1); \u2022 visual authentication: automatically logging family members onto your home computer as they sit down in front of the webcam (see section 14.2). note that radial distortion needs to be removed from such images before the feature points can be used for calibration.",
        "in fifth international joint conference on arti\ufb01cial intelligence (ijcai\u201977), p. 584, cambridge, massachusetts. note that when top-down maps of the buildings being modeled are available, these can be used to further constrain the 3d modeling process (robertson and cipolla 2002, 2009). pixels along each line segment are transferred from source to destination exactly as speci\ufb01ed, and other pixels are warped using a smooth interpolation of these displacements. consider \ufb01rst the case of the rotation matrix being known. somewhere in the 80 million images, there are enough examples to associate some set of images with each of the 75,000 non-abstract nouns in wordnet that they use in their system.",
        "11.1 epipolar geometry  537  the general taxonomy proposed by scharstein and szeliski (2002). 2.2.2 re\ufb02ectance and shading . a multiresolution spline with applications to image  mosaics. these kinds of problems are in general called inverse problems because they involve estimating unknown model parameters instead of simulating the forward formation equations.1 computer graphics is a classic forward modeling problem (given some objects, cameras, and lighting, simulate the images that would result), while computer vision problems are usually of the inverse kind (given one or more images, recover the scene that gave rise to these images). with the advent of hdtv and newer monitors, a new standard called itu-r bt.709 was created, which speci\ufb01es the xyz  19 another perceptually motivated color space called l*u*v* was developed and standardized simultaneously  (fairchild 2005).",
        "if the focal plane (vertical zo gray line next to c) is moved forward, the images are no longer in focus and the circle of confusion c (small thick line segments) depends on the distance of the image plane motion \u2206zi relative to the lens aperture diameter d. the \ufb01eld of view (f.o.v.) ieee  transactions on image processing, 8(9):1221\u20131228. if the background is already known, i.e., for blue screen or difference matting applications, its measured color value and variance are used instead. store the edgels either in a 2d array (say, an integer image with indices into the edgel list) or pre-sort the edgel list \ufb01rst by (integer) x coordinates and then y coordinates, for faster neighbor \ufb01nding. the topics of projective geometry and structure from motion are extremely rich and some excellent textbooks and surveys have been written on them (faugeras and luong 2001; hartley and zisserman 2004; moons, van gool, and vergauwen 2010)."
    ],
    "image stitching gist exposure compensation pyramid feathering blending":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ],
    "similarity background replacement z-keying window-based matching background replacement dense correspondence sparse correspondence direct intensity-based rotoscoping color image overcomplete epipolar plane image points lines planes projective sampling robust regularization plane sweep thresholding thin inverse warping algorithm incremental light stripe reconstruction algorithm exposure compensation pro\ufb01le learning parameters hierarchy match move weighted tobogganing local perspective bias and gain normalization inverse warping layered depth image plumb-line method face modeling collineation shiftable window motion camera alpha matte image stitching merging local window-based merging modeling morphing blending texture surface standard recti\ufb01ed geometry tion histogram vanishing points optimization-based minimum degree layers layered window-based example-based non-parametric texture image depth map weighting pixel selection kinematic models voxel coloring inliers forward warping trimap moving average impostors sprites geometric alignment video-based walkthroughs recognizing panoramas multidimensional bias and gain similarity measure bicubic depth map performance-driven animation interactive recognition face smoke shadow axis/angle edge-based local methods dynamic programming algorithm coded pattern lines color skeletal set cooperative algorithms cooperative algorithms nested dissection opacity restricted \ufb02ash":[
        "more commonly, however, iir \ufb01lters are used inside one-dimensional separable \ufb01ltering stages to compute large-extent smoothing kernels, such as ef\ufb01cient approximations to gaussians and edge \ufb01lters (deriche 1990; nielsen, florack, and deriche 1997). (another name for the inverse covariance matrix, which is equal to the hessian in such simple cases, is the information matrix.) \u2022 a brief history \u2022 book overview \u2022 sample syllabus \u2022 notation  2 image formation  geometric primitives and transformations \u2022  photometric image formation \u2022  the digital camera  3 image processing  1  29  99  point operators \u2022 linear \ufb01ltering \u2022  more neighborhood operators \u2022 fourier transforms \u2022 pyramids and wavelets \u2022 geometric transformations \u2022  global optimization  4 feature detection and matching  205  points and patches \u2022 edges \u2022 lines  5 segmentation  mean shift and mode \ufb01nding \u2022 normalized cuts \u2022  active contours \u2022 split and merge \u2022 graph cuts and energy-based methods  6 feature-based alignment  2d and 3d feature-based alignment \u2022  pose estimation \u2022  geometric intrinsic calibration  7 structure from motion  267  309  343  triangulation \u2022 two-frame structure from motion \u2022  factorization \u2022 bundle adjustment \u2022 constrained structure and motion  n^\f8 dense motion estimation  translational alignment \u2022 parametric motion \u2022  spline-based motion \u2022 optical \ufb02ow \u2022  layered motion  9 image stitching  motion models \u2022 global alignment \u2022  compositing  381  427  10 computational photography 467 photometric calibration \u2022 high dynamic range imaging \u2022  super-resolution and blur removal \u2022 image matting and compositing \u2022 texture analysis and synthesis  11 stereo correspondence  533  epipolar geometry \u2022 sparse correspondence \u2022 dense correspondence \u2022 local methods \u2022 global optimization \u2022 multi-view stereo  12 3d reconstruction  577  shape from x \u2022 active range\ufb01nding \u2022  surface representations \u2022 point-based representations \u2022 volumetric representations \u2022 model-based reconstruction \u2022 619 13 image-based rendering  recovering texture maps and albedos  view interpolation \u2022 layered depth images \u2022  light \ufb01elds and lumigraphs \u2022 environment mattes \u2022  video-based rendering  14 recognition  655  instance recognition \u2022 category recognition \u2022  object detection \u2022 face recognition \u2022 context and scene understanding \u2022 recognition databases and test sets  \f\fpreface  the seeds for this book were \ufb01rst planted in 2001 when steve seitz at the university of washington invited me to co-teach a course called \u201ccomputer vision for computer graphics\u201d. platel, b., balmachnova, e., florack, l., and ter haar romeny, b. lowe (1989) and taubin (1995) describe techniques that compensate for this shrinkage by adding an offset term based on second derivative estimates or a larger smoothing kernel (figure 4.37b).",
        "templates for the solution of linear systems: building blocks for iterative methods, 2nd edition. the basic idea behind fusion moves is to replace portions of the current best estimate with hypotheses generated by more basic techniques (or their shifted versions) and to alternate them with local gradient descent for better energy minimization. the fourier transform and its applications. in multi-view stereo, algorithms have a choice of computing these measures directly on the surface of the model, i.e., in scene space, or projecting pixel values from one image (or from a textured model) back into another image, i.e., in image space. journal of mathematical imaging and vision, 7(4):291\u2013307.",
        "bertalmio, m., sapiro, g., caselles, v., and ballester, c.  (2000). hierarchical part-based visual object categorization. another commonly used dyadic (two-input) operator is the linear blend operator,  g(x) = (1 \u2212 \u03b1)f0(x) + \u03b1f1(x). image segmentation (see chapter 5) (figure 1.9e), a topic which has been active since the earliest days of computer vision (brice and fennema 1970; horowitz and pavlidis 1976; riseman and arbib 1977; rosenfeld and davis 1979; haralick and shapiro 1985; pavlidis and liow 1990), was also an active topic of research, producing techniques based on minimum energy (mumford and shah 1989) and minimum description length (leclerc 1989), normalized cuts (shi and malik 2000), and mean shift (comaniciu and meer 2002). most shape from shading algorithms assume that the surface under consideration is of a uniform albedo and re\ufb02ectance, and that the light source directions are either known or can be calibrated by the use of a reference object.",
        "the signal is \ufb01rst (theoretically) interpolated to a continuous waveform, (ideally) low-pass \ufb01ltered to below the new nyquist rate, and then re-sampled to the \ufb01nal desired resolution. compute an optimal 2d translation and rotation between the \ufb01rst image and all subsequent images, using least squares (section 6.1.1) with optional ransac for robustness (section 6.1.4). the amount of mis-focus is measured by the circle of confusion c (shown as short thick blue line segments on the gray plane).7 the equation for the circle of confusion can be derived using similar triangles; it depends on the distance of travel in the focal plane \u2206zi relative to the original focus distance zi and the diameter of the aperture d (see exercise 2.4). the quality of a compression algorithm is usually reported using its peak signal-to-noise  ratio (psnr), which is derived from the average mean square error,  m se =  1  n(cid:88)x (cid:104)i(x) \u2212 \u02c6i(x)(cid:105)2  ,  (2.117)  where i(x) is the original uncompressed image and \u02c6i(x) is its compressed counterpart, or equivalently, the root mean square error (rms error), which is de\ufb01ned as  rm s = \u221am se. for example, for a summed area table, an impulse generates an in\ufb01nite rectangle of 1s below and to the right of the impulse.",
        "in ieee computer society conference on  computer vision and pattern recognition (cvpr\u201991), pp. 5.3 mean shift and mode \ufb01nding  291  based on their statistics, and for accelerating the process of \ufb01nding the nearest mean center (bishop 2006). the \ufb01rst is the earth mover\u2019s distance (emd) (rubner, tomasi, and guibas 2000),  em d(s, s(cid:48)) = (cid:80)i(cid:80)j fijd(mi, m(cid:48)j)  (cid:80)i(cid:80)j fij  ,  (14.37)  where fij is a \ufb02ow value that can be computed using a linear program and d(mi, m(cid:48)j) is the ground distance (euclidean distance) between mi and m(cid:48)j. perspective transformations preserve straight lines (i.e., they remain straight after the transformation). since we are trying to recover the unknown function f(x, y) from which the data point d(xi, yi) were sampled, such problems are also often called  \f3.7 global optimization  175  (a)  (b)  figure 3.54 a simple surface interpolation problem: (a) nine data points of various height scattered on a grid; (b) second-order, controlled-continuity, thin-plate spline interpolator, with a tear along its left edge and a crease along its right (szeliski 1989) c(cid:13) 1989 springer."
    ],
    "difference low-pass":[
        "sparse \ufb02exible models of local features. ieee  transactions on pattern analysis and machine intelligence, 30(12):2109\u20132125. opelt, a., pinz, a., fussenegger, m., and auer, p. (2006). for non-linear problems such as structure from motion, an extended kalman \ufb01lter, which linearizes measurement and update equations around the current estimate, needs to be used (gelb 1974; vi\u00b4eville and faugeras 1990). 12.4 point-based representations .",
        "celniker, g. and gossard, d. (1991). 1993) c(cid:13) 1993 ieee; (b) searching for the strongest gradient along the normal to each control point (cootes, cooper, taylor et al. 136 . acm transactions on graphics, 23(3):679\u2013688. for each combination of image and noise, determine by eye which width of a gaussian blurring \ufb01lter \u03c3s gives the best denoised result.",
        "unfortunately, this trick only applies when the images have large overlap (small translational motion). active appearance models revisited. an mrf-based deinterlacing algorithm with exemplar-based re\ufb01nement. (a.15)  \f740  computer vision: algorithms and applications (september 3, 2010 draft)  (this can be derived from (a.6) by post-multiplying both sides by ui.) in their system, they \ufb01rst \ufb01nd lines and group them by common vanishing points in each image (section 4.3.3).",
        "notice how, in the second sequence, the amount of re\ufb02ected light is quite low compared to the transmitted light (the picture of the girl) and yet the algorithm is still able to recover both layers. another recent application is the detection of visual continuity errors in \ufb01lms, i.e., differences in the background when a shot is re-taken at later time (pickup and zisserman 2009). 13.2.1 impostors, sprites, and layers  an alternative to keeping lists of color-depth values at each pixel, as is done in the ldi, is to organize objects into different layers or sprites. devise a fall-back strategy for areas where you don\u2019t think the \ufb02ow estimates are accu rate enough. the appearance of human skin: a survey.",
        "regions b, c, d, and e are partially occluded. only (a) and (b) are currently used for evaluation. computer vision, graphics, and image processing, 24:52\u201396. adiv, g.  (1989). template-based approaches, such as active appearance models (aams) (section 14.2.2), can deal with a wide range of pose and expression variability."
    ],
    "detection matching references specularities image":[
        "image completion using ef\ufb01cient belief propieee transactions on image  komodakis, n., paragios, n., and tziritas, g. (2007). transforming an arbitrary minsum problem into a  binary one. create a morph by partially warping the images towards each other and cross-dissolving  (section 3.6.3). compute a scalar interest measure using one of the formulas discussed above. with accurate physical models of radiance transport and color image formation created its own sub\ufb01eld known as physics-based vision.",
        "\ufb01cation stages (yang, jin, sukthankar et al. it is easy to see by inspection that both of these moves result in binary mrfs with well-de\ufb01ned energy functions. furukawa, y. and ponce, j. in practice, however, higher iso settings usually amplify the sensor noise. , f /22.",
        "international journal of computer vision, 87(1-2):4\u201327. c.4 bibliography  while a bibliography (bibtex .bib \ufb01le) for all of the references cited in this book is available on the book\u2019s web site, a much more comprehensive partially annotated bibliography of nearly all computer vision publications is maintained by keith price at http://iris.usc.edu/ vision-notes/bibliography/contents.html. similarly, the parameters of the prior distribution can often be learned by observing samples from the class we are modeling (roth and black 2007a; tappen 2007; li and huttenlocher 2008). a physical approach to color image understanding. (pure wavelength light can be obtained using either a prism or specially manufactured color \ufb01lters.)",
        "13.5 video-based rendering  643  figure 13.14 animating still pictures (chuang, goldman, zheng et al. heisele, serre, and poggio 2007) and are a widely used tool in object recognition in general. in most of the examples seen on the web, the images are aligned by hand for best artistic effect.4 however, it is also possible to use feature matching and alignment techniques to perform the registration automatically (nomura, zhang, and nayar 2007; zelnik-manor and perona 2007). 8.7 exercises  ex 8.1: correlation implement and compare the performance of the following correlation algorithms:  \u2022 sum of squared differences (8.1) \u2022 sum of robust differences (8.2) \u2022 sum of absolute differences (8.3) \u2022 bias\u2013gain compensated squared differences (8.9) \u2022 normalized cross-correlation (8.11)  \f8.7 exercises  423  \u2022 windowed versions of the above (8.22\u20138.23) \u2022 fourier-based implementations of the above measures (8.18\u20138.20) \u2022 phase correlation (8.24) \u2022 gradient cross-correlation (argyriou and vlachos 2003). a., and liu, y.",
        "this is then generalized to spline-based motion models (section 8.3) and \ufb01nally to general per-pixel optical \ufb02ow (section 8.4), including layered and learned motion models (section 8.5). batra, d., sukthankar, r., and chen, t. (2008). society for industrial  and applied mathematics, philadephia. in situations where the camera is translating a lot in 3d, e.g., when the videographer is walking, an even better approach is to compute a full structure from motion reconstruction of the camera motion and 3d scene. i\u2019m also grateful to the many other computer vision researchers who have given me so many constructive suggestions about the book, including sing bing kang, who was my informal book editor, vladimir kolmogorov, who contributed appendix b.5.5 on linear programming techniques for mrf inference, daniel scharstein, richard hartley, simon baker, noah snavely, bill freeman, svetlana lazebnik, matthew turk, jitendra malik, alyosha efros, michael black, brian curless, sameer agarwal, li zhang, deva ramanan, olga veksler, yuri boykov, carsten rother, phil torr, bill triggs, bruce maxwell, jana ko\u02c7seck\u00b4a, eero simoncelli, aaron hertzmann, antonio torralba, tomaso poggio, theo pavlidis, baba vemuri, nando de freitas, chuck dyer, song yi, falk schubert, roman p\ufb02ugfelder, marshall tappen, james coughlan, sammy rogmans, klaus strobel, shanmuganathan, andreas siebert, yongjun wu, fred pighin, juan cockburn, ronald mallet, tim soper, georgios evangelidis, dwight fowler, itzik bayaz, daniel o\u2019connor, and srikrishna bhat."
    ],
    "hierarchy translation scaled rotation distance metrics rigid body translation similarity":[
        "790\u2013798, bombay. in section 9.2, we look at how each of these previously developed techniques can be modi\ufb01ed to take advantage of the imaging setups commonly used to create panoramas. we then devise an algorithm that will give us an estimate (or set of estimates) that are both insensitive to the noise (as best they can be) and also quantify the reliability of these estimates. unfortunately, these downhill methods tend to get easily stuck in local minima. mrf optimization via dual decomin eleventh international conference on com position: message-passing revisited.",
        "once all of the computations have been performed, the appropriate gamma should be applied before display. blinn, j. for this reason, dynamic programming is normally exponential in complexity in the order of the clique size, i.e., a clique of size n with l labels at each node requires the evaluation of ln\u22121 possible states (potetz and lee 2008; kohli, kumar, and torr 2009). in ninth interna tional conference on computer vision (iccv 2003), pp. digitally archiving cultural objects, springer,  boston, ma.",
        "a fast algorithm for active contours and curvature  estimation. we now look at several of these representations in more detail. curless, b. image-based procedural mod eling of facades. lapack  users\u2019 guide.",
        "a lighting reproduction approach to live-action compositing. 14\u201321, kerkyra, greece. to \ufb01nd the features and decision stumps that work best in a shared manner, they introduce a novel joint boosting algorithm that optimizes, at each stage, a summed expected exponential loss function using the \u201cgentleboost\u201d algorithm of friedman, hastie, and tibshirani (2000). a k peters, ltd, natick,  massachusetts. while this may not appear to matter, people prefer that the \ufb01nal stitched image is \u201cupright\u201d rather than twisted or tilted.",
        "in this case, the eigenvalues  can be both positive and negative.2  \u03bb0 \u2265 \u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\u22121  (a.7)  a special case of the symmetric matrix c occurs when it is constructed as the sum of a  number of outer products  aiat  i = aat ,  (a.8)  c =(cid:88)i  which often occurs when solving least squares problems (appendix a.2), where the matrix a consists of all the ai column vectors stacked side-by-side. tamaraberg.com/teaching/fall 08/. however, the computational complexity of each linearized gauss\u2013newton step can be reduced using sparse matrix techniques (section 7.4.1) (szeliski and kang 1994; triggs, mclauchlan, hartley et al. iterative solution methods. pro ceedings of the ieee, 76(8):869\u2013889."
    ]
}