a	O
brief	O
introduction	O
to	O
neural	O
networks	O
david	O
kriesel	O
in	O
remembrance	O
of	O
dr.	O
peter	O
kemp	O
,	O
notary	O
(	O
ret	O
.	O
)	O
,	O
bonn	O
,	O
germany	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
iii	O
a	O
small	O
preface	O
''	O
originally	O
,	O
this	O
work	O
has	O
been	O
prepared	O
in	O
the	O
framework	O
of	O
a	O
seminar	O
of	O
the	O
university	O
of	O
bonn	O
in	O
germany	O
,	O
but	O
it	O
has	O
been	O
and	O
will	O
be	O
extended	O
(	O
after	O
being	O
presented	O
and	O
published	O
online	O
under	O
www.dkriesel.com	O
on	O
5/27/2005	O
)	O
.	O
first	O
and	O
foremost	O
,	O
to	O
provide	O
a	O
comprehensive	O
overview	O
of	O
the	O
subject	O
of	O
neural	O
networks	O
and	O
,	O
second	O
,	O
just	O
to	O
acquire	O
more	O
and	O
more	O
knowledge	O
about	O
latex	O
.	O
and	O
who	O
knows	O
–	O
maybe	O
one	O
day	O
this	O
summary	O
will	O
become	O
a	O
real	O
preface	O
!	O
''	O
abstract	O
of	O
this	O
work	O
,	O
end	O
of	O
2005	O
the	O
above	O
abstract	O
has	O
not	O
yet	O
become	O
a	O
preface	O
but	O
at	O
least	O
a	O
little	O
preface	O
,	O
ever	O
since	O
the	O
extended	O
text	O
(	O
then	O
40	O
pages	O
long	O
)	O
has	O
turned	O
out	O
to	O
be	O
a	O
download	O
hit	O
.	O
ambition	O
and	O
intention	O
of	O
this	O
manuscript	O
the	O
entire	O
text	O
is	O
written	O
and	O
laid	O
out	O
more	O
eﬀectively	O
and	O
with	O
more	O
illustra-	O
tions	O
than	O
before	O
.	O
i	O
did	O
all	O
the	O
illustra-	O
tions	O
myself	O
,	O
most	O
of	O
them	O
directly	O
in	O
latex	O
by	O
using	O
xypic	O
.	O
they	O
reﬂect	O
what	O
i	O
would	O
have	O
liked	O
to	O
see	O
when	O
becoming	O
acquainted	O
with	O
the	O
subject	O
:	O
text	O
and	O
il-	O
lustrations	O
should	O
be	O
memorable	O
and	O
easy	O
to	O
understand	O
to	O
oﬀer	O
as	O
many	O
people	O
as	O
possible	O
access	O
to	O
the	O
ﬁeld	O
of	O
neural	O
net-	O
works	O
.	O
nevertheless	O
,	O
the	O
mathematically	O
and	O
for-	O
mally	O
skilled	O
readers	O
will	O
be	O
able	O
to	O
under-	O
stand	O
the	O
deﬁnitions	O
without	O
reading	O
the	O
running	O
text	O
,	O
while	O
the	O
opposite	O
holds	O
for	O
readers	O
only	O
interested	O
in	O
the	O
subject	O
mat-	O
ter	O
;	O
everything	O
is	O
explained	O
in	O
both	O
collo-	O
quial	O
and	O
formal	O
language	O
.	O
please	O
let	O
me	O
know	O
if	O
you	O
ﬁnd	O
out	O
that	O
i	O
have	O
violated	O
this	O
principle	O
.	O
the	O
sections	O
of	O
this	O
text	O
are	O
mostly	O
independent	O
from	O
each	O
other	O
the	O
document	O
itself	O
is	O
divided	O
into	O
diﬀer-	O
ent	O
parts	O
,	O
which	O
are	O
again	O
divided	O
into	O
chapters	O
.	O
although	O
the	O
chapters	O
contain	O
cross-references	O
,	O
they	O
are	O
also	O
individually	O
accessible	O
to	O
readers	O
with	O
little	O
previous	O
knowledge	O
.	O
there	O
are	O
larger	O
and	O
smaller	O
chapters	O
:	O
while	O
the	O
larger	O
chapters	O
should	O
provide	O
profound	O
insight	O
into	O
a	O
paradigm	O
of	O
neural	O
networks	O
(	O
e.g	O
.	O
the	O
classic	O
neural	O
network	O
structure	O
:	O
the	O
perceptron	B
and	O
its	O
learning	B
procedures	O
)	O
,	O
the	O
smaller	O
chapters	O
give	O
a	O
short	O
overview	O
–	O
but	O
this	O
is	O
also	O
ex-	O
v	O
dkriesel.com	O
the	O
original	O
high-performance	O
simulation	O
design	O
goal	O
.	O
those	O
of	O
you	O
who	O
are	O
up	O
for	O
learning	B
by	O
doing	O
and/or	O
have	O
to	O
use	O
a	O
fast	O
and	O
stable	O
neural	O
networks	O
implemen-	O
tation	O
for	O
some	O
reasons	O
,	O
should	O
deﬁnetely	O
have	O
a	O
look	O
at	O
snipe	O
.	O
however	O
,	O
the	O
aspects	O
covered	O
by	O
snipe	O
are	O
not	O
entirely	O
congruent	O
with	O
those	O
covered	O
by	O
this	O
manuscript	O
.	O
some	O
of	O
the	O
kinds	O
of	O
neural	O
networks	O
are	O
not	O
supported	O
by	O
snipe	O
,	O
while	O
when	O
it	O
comes	O
to	O
other	O
kinds	O
of	O
neural	O
networks	O
,	O
snipe	O
may	O
have	O
lots	O
and	O
lots	O
more	O
capabilities	O
than	O
may	O
ever	O
be	O
covered	O
in	O
the	O
manuscript	O
in	O
the	O
form	O
of	O
practical	O
hints	O
.	O
anyway	O
,	O
in	O
my	O
experi-	O
ence	O
almost	O
all	O
of	O
the	O
implementation	O
re-	O
quirements	O
of	O
my	O
readers	O
are	O
covered	O
well	O
.	O
on	O
the	O
snipe	O
download	O
page	O
,	O
look	O
for	O
the	O
section	O
``	O
getting	O
started	O
with	O
snipe	O
''	O
–	O
you	O
will	O
ﬁnd	O
an	O
easy	O
step-by-step	O
guide	O
con-	O
cerning	O
snipe	O
and	O
its	O
documentation	O
,	O
as	O
well	O
as	O
some	O
examples	O
.	O
snipe	O
:	O
this	O
manuscript	O
frequently	O
incor-	O
porates	O
snipe	O
.	O
shaded	O
snipe-paragraphs	O
like	O
this	O
one	O
are	O
scattered	O
among	O
large	O
parts	O
of	O
the	O
manuscript	O
,	O
providing	O
infor-	O
mation	O
on	O
how	O
to	O
implement	O
their	O
con-	O
text	O
in	O
snipe	O
.	O
this	O
also	O
implies	O
that	O
those	O
who	O
do	O
not	O
want	O
to	O
use	O
snipe	O
,	O
just	O
have	O
to	O
skip	O
the	O
shaded	O
snipe-	O
paragraphs	O
!	O
the	O
snipe-paragraphs	O
as-	O
sume	O
the	O
reader	O
has	O
had	O
a	O
close	O
look	O
at	O
the	O
``	O
getting	O
started	O
with	O
snipe	O
''	O
section	O
.	O
often	O
,	O
class	O
names	O
are	O
used	O
.	O
as	O
snipe	O
con-	O
sists	O
of	O
only	O
a	O
few	O
diﬀerent	O
packages	O
,	O
i	O
omit-	O
ted	O
the	O
package	O
names	O
within	O
the	O
qualiﬁed	O
class	O
names	O
for	O
the	O
sake	O
of	O
readability	O
.	O
plained	O
in	O
the	O
introduction	O
of	O
each	O
chapter	O
.	O
in	O
addition	O
to	O
all	O
the	O
deﬁnitions	O
and	O
expla-	O
nations	O
i	O
have	O
included	O
some	O
excursuses	O
to	O
provide	O
interesting	O
information	O
not	O
di-	O
rectly	O
related	O
to	O
the	O
subject	O
.	O
unfortunately	O
,	O
i	O
was	O
not	O
able	O
to	O
ﬁnd	O
free	O
german	O
sources	O
that	O
are	O
multi-faceted	O
in	O
respect	O
of	O
content	O
(	O
concerning	O
the	O
paradigms	O
of	O
neural	O
networks	O
)	O
and	O
,	O
nev-	O
ertheless	O
,	O
written	O
in	O
coherent	O
style	O
.	O
the	O
aim	O
of	O
this	O
work	O
is	O
(	O
even	O
if	O
it	O
could	O
not	O
be	O
fulﬁlled	O
at	O
ﬁrst	O
go	O
)	O
to	O
close	O
this	O
gap	O
bit	O
by	O
bit	O
and	O
to	O
provide	O
easy	O
access	O
to	O
the	O
subject	O
.	O
want	O
to	O
learn	O
not	O
only	O
by	O
reading	O
,	O
but	O
also	O
by	O
coding	O
?	O
use	O
snipe	O
!	O
snipe1	O
is	O
a	O
well-documented	O
java	O
li-	O
brary	O
that	O
implements	O
a	O
framework	O
for	O
neural	O
networks	O
in	O
a	O
speedy	O
,	O
feature-rich	O
and	O
usable	O
way	O
.	O
it	O
is	O
available	O
at	O
no	O
cost	O
for	O
non-commercial	O
purposes	O
.	O
it	O
was	O
originally	O
designed	O
for	O
high	O
performance	O
simulations	O
with	O
lots	O
and	O
lots	O
of	O
neural	O
networks	O
(	O
even	O
large	O
ones	O
)	O
being	O
trained	O
simultaneously	O
.	O
recently	O
,	O
i	O
decided	O
to	O
give	O
it	O
away	O
as	O
a	O
professional	O
reference	O
im-	O
plementation	O
that	O
covers	O
network	O
aspects	O
handled	O
within	O
this	O
work	O
,	O
while	O
at	O
the	O
same	O
time	O
being	O
faster	O
and	O
more	O
eﬃcient	O
than	O
lots	O
of	O
other	O
implementations	O
due	O
to	O
1	O
scalable	O
and	O
generalized	O
neural	O
information	O
pro-	O
cessing	O
engine	O
,	O
downloadable	O
at	O
http	O
:	O
//www	O
.	O
dkriesel.com/tech/snipe	O
,	O
online	O
javadoc	O
at	O
http	O
:	O
//snipe.dkriesel.com	O
vi	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
it	O
’	O
s	O
easy	O
to	O
print	O
this	O
manuscript	O
this	O
text	O
is	O
completely	O
illustrated	O
in	O
color	O
,	O
but	O
it	O
can	O
also	O
be	O
printed	O
as	O
is	O
in	O
monochrome	O
:	O
the	O
colors	O
of	O
ﬁgures	O
,	O
tables	O
and	O
text	O
are	O
well-chosen	O
so	O
that	O
in	O
addi-	O
tion	O
to	O
an	O
appealing	O
design	O
the	O
colors	O
are	O
still	O
easy	O
to	O
distinguish	O
when	O
printed	O
in	O
monochrome	O
.	O
there	O
are	O
many	O
tools	O
directly	O
integrated	O
into	O
the	O
text	O
diﬀerent	O
aids	O
are	O
directly	O
integrated	O
in	O
the	O
document	O
to	O
make	O
reading	O
more	O
ﬂexible	O
:	O
however	O
,	O
anyone	O
(	O
like	O
me	O
)	O
who	O
prefers	O
reading	O
words	O
on	O
paper	O
rather	O
than	O
on	O
screen	O
can	O
also	O
enjoy	O
some	O
features	O
.	O
in	O
the	O
table	O
of	O
contents	O
,	O
diﬀerent	O
types	O
of	O
chapters	O
are	O
marked	O
diﬀerent	O
types	O
of	O
chapters	O
are	O
directly	O
marked	O
within	O
the	O
table	O
of	O
contents	O
.	O
chap-	O
ters	O
,	O
that	O
are	O
marked	O
as	O
``	O
fundamental	O
''	O
are	O
deﬁnitely	O
ones	O
to	O
read	O
because	O
almost	O
all	O
subsequent	O
chapters	O
heavily	O
depend	O
on	O
them	O
.	O
other	O
chapters	O
additionally	O
depend	O
on	O
information	O
given	O
in	O
other	O
(	O
preceding	O
)	O
chapters	O
,	O
which	O
then	O
is	O
marked	O
in	O
the	O
ta-	O
ble	O
of	O
contents	O
,	O
too	O
.	O
speaking	O
headlines	O
throughout	O
the	O
text	O
,	O
short	O
ones	O
in	O
the	O
table	O
of	O
contents	O
the	O
whole	O
manuscript	O
is	O
now	O
pervaded	O
by	O
such	O
headlines	O
.	O
speaking	O
headlines	O
are	O
not	O
just	O
title-like	O
(	O
``	O
reinforcement	O
learn-	O
ing	O
''	O
)	O
,	O
but	O
centralize	O
the	O
information	O
given	O
in	O
the	O
associated	O
section	O
to	O
a	O
single	O
sen-	O
tence	O
.	O
in	O
the	O
named	O
instance	O
,	O
an	O
appro-	O
priate	O
headline	O
would	O
be	O
``	O
reinforcement	B
learning	I
methods	O
provide	O
feedback	O
to	O
the	O
network	O
,	O
whether	O
it	O
behaves	O
good	O
or	O
bad	O
''	O
.	O
however	O
,	O
such	O
long	O
headlines	O
would	O
bloat	O
the	O
table	O
of	O
contents	O
in	O
an	O
unacceptable	O
way	O
.	O
so	O
i	O
used	O
short	O
titles	O
like	O
the	O
ﬁrst	O
one	O
in	O
the	O
table	O
of	O
contents	O
,	O
and	O
speaking	O
ones	O
,	O
like	O
the	O
latter	O
,	O
throughout	O
the	O
text	O
.	O
marginal	O
notes	O
are	O
a	O
navigational	O
aid	O
the	O
entire	O
document	O
contains	O
marginal	O
notes	O
in	O
colloquial	O
language	O
(	O
see	O
the	O
exam-	O
hypertext	O
ple	O
in	O
the	O
margin	O
)	O
,	O
allowing	O
you	O
to	O
``	O
scan	O
''	O
on	O
paper	O
:	O
-	O
)	O
the	O
document	O
quickly	O
to	O
ﬁnd	O
a	O
certain	O
pas-	O
sage	O
in	O
the	O
text	O
(	O
including	O
the	O
titles	O
)	O
.	O
new	O
mathematical	O
symbols	O
are	O
marked	O
by	O
speciﬁc	O
marginal	O
notes	O
for	O
easy	O
ﬁnding	O
(	O
cid:74	O
)	O
x	O
(	O
see	O
the	O
example	O
for	O
x	O
in	O
the	O
margin	O
)	O
.	O
there	O
are	O
several	O
kinds	O
of	O
indexing	O
this	O
document	O
contains	O
diﬀerent	O
types	O
of	O
indexing	O
:	O
if	O
you	O
have	O
found	O
a	O
word	O
in	O
the	O
index	O
and	O
opened	O
the	O
corresponding	O
page	O
,	O
you	O
can	O
easily	O
ﬁnd	O
it	O
by	O
searching	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
vii	O
dkriesel.com	O
for	O
highlighted	O
text	O
–	O
all	O
indexed	O
words	O
are	O
highlighted	O
like	O
this	O
.	O
mathematical	O
symbols	O
appearing	O
in	O
sev-	O
eral	O
chapters	O
of	O
this	O
document	O
(	O
e.g	O
.	O
ω	O
for	O
an	O
output	O
neuron	O
;	O
i	O
tried	O
to	O
maintain	O
a	O
consistent	O
nomenclature	O
for	O
regularly	O
re-	O
curring	O
elements	O
)	O
are	O
separately	O
indexed	O
under	O
``	O
mathematical	O
symbols	O
''	O
,	O
so	O
they	O
can	O
easily	O
be	O
assigned	O
to	O
the	O
correspond-	O
ing	O
term	O
.	O
names	O
of	O
persons	O
written	O
in	O
small	O
caps	O
are	O
indexed	O
in	O
the	O
category	O
``	O
persons	O
''	O
and	O
ordered	O
by	O
the	O
last	O
names	O
.	O
3.	O
you	O
must	O
maintain	O
the	O
author	O
’	O
s	O
attri-	O
bution	O
of	O
the	O
document	O
at	O
all	O
times	O
.	O
4.	O
you	O
may	O
not	O
use	O
the	O
attribution	O
to	O
imply	O
that	O
the	O
author	O
endorses	O
you	O
or	O
your	O
document	O
use	O
.	O
for	O
i	O
’	O
m	O
no	O
lawyer	O
,	O
the	O
above	O
bullet-point	O
summary	O
is	O
just	O
informational	O
:	O
if	O
there	O
is	O
any	O
conﬂict	O
in	O
interpretation	O
between	O
the	O
summary	O
and	O
the	O
actual	O
license	O
,	O
the	O
actual	O
license	O
always	O
takes	O
precedence	O
.	O
note	O
that	O
this	O
license	O
does	O
not	O
extend	O
to	O
the	O
source	O
ﬁles	O
used	O
to	O
produce	O
the	O
document	O
.	O
those	O
are	O
still	O
mine	O
.	O
terms	O
of	O
use	O
and	O
license	O
beginning	O
with	O
the	O
epsilon	O
edition	O
,	O
the	O
text	O
is	O
licensed	O
under	O
the	O
creative	O
com-	O
mons	O
attribution-no	O
derivative	O
works	O
3.0	O
unported	O
license2	O
,	O
except	O
for	O
some	O
little	O
portions	O
of	O
the	O
work	O
licensed	O
under	O
more	O
liberal	O
licenses	O
as	O
mentioned	O
(	O
mainly	O
some	O
ﬁgures	O
from	O
wikimedia	O
commons	O
)	O
.	O
a	O
quick	O
license	O
summary	O
:	O
1.	O
you	O
are	O
free	O
to	O
redistribute	O
this	O
docu-	O
ment	O
(	O
even	O
though	O
it	O
is	O
a	O
much	O
better	O
idea	O
to	O
just	O
distribute	O
the	O
url	O
of	O
my	O
homepage	O
,	O
for	O
it	O
always	O
contains	O
the	O
most	O
recent	O
version	O
of	O
the	O
text	O
)	O
.	O
2.	O
you	O
may	O
not	O
modify	O
,	O
transform	O
,	O
or	O
build	O
upon	O
the	O
document	O
except	O
for	O
personal	O
use	O
.	O
2	O
http	O
:	O
//creativecommons.org/licenses/	O
by-nd/3.0/	O
how	O
to	O
cite	O
this	O
manuscript	O
there	O
’	O
s	O
no	O
oﬃcial	O
publisher	O
,	O
so	O
you	O
need	O
to	O
be	O
careful	O
with	O
your	O
citation	O
.	O
please	O
ﬁnd	O
more	O
information	O
in	O
english	O
and	O
german	O
language	O
on	O
my	O
homepage	O
,	O
re-	O
spectively	O
the	O
subpage	O
concerning	O
the	O
manuscript3	O
.	O
acknowledgement	O
now	O
i	O
would	O
like	O
to	O
express	O
my	O
grati-	O
tude	O
to	O
all	O
the	O
people	O
who	O
contributed	O
,	O
in	O
whatever	O
manner	O
,	O
to	O
the	O
success	O
of	O
this	O
work	O
,	O
since	O
a	O
work	O
like	O
this	O
needs	O
many	O
helpers	O
.	O
first	O
of	O
all	O
,	O
i	O
want	O
to	O
thank	O
the	O
proofreaders	O
of	O
this	O
text	O
,	O
who	O
helped	O
me	O
and	O
my	O
readers	O
very	O
much	O
.	O
in	O
al-	O
phabetical	O
order	O
:	O
wolfgang	O
apolinarski	O
,	O
kathrin	O
gräve	O
,	O
paul	O
imhoﬀ	O
,	O
thomas	O
3	O
http	O
:	O
//www.dkriesel.com/en/science/	O
neural_networks	O
viii	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
kühn	O
,	O
christoph	O
kunze	O
,	O
malte	O
lohmeyer	O
,	O
joachim	O
nock	O
,	O
daniel	O
plohmann	O
,	O
daniel	O
rosenthal	O
,	O
christian	O
schulz	O
and	O
tobias	O
wilken	O
.	O
additionally	O
,	O
i	O
want	O
to	O
thank	O
the	O
readers	O
dietmar	O
berger	O
,	O
igor	O
buchmüller	O
,	O
marie	O
christ	O
,	O
julia	O
damaschek	O
,	O
jochen	O
döll	O
,	O
maximilian	O
ernestus	O
,	O
hardy	O
falk	O
,	O
anne	O
feldmeier	O
,	O
sascha	O
fink	O
,	O
andreas	O
fried-	O
mann	O
,	O
jan	O
gassen	O
,	O
markus	O
gerhards	O
,	O
se-	O
bastian	O
hirsch	O
,	O
andreas	O
hochrath	O
,	O
nico	O
höft	O
,	O
thomas	O
ihme	O
,	O
boris	O
jentsch	O
,	O
tim	O
hussein	O
,	O
thilo	O
keller	O
,	O
mario	O
krenn	O
,	O
mirko	O
kunze	O
,	O
maikel	O
linke	O
,	O
adam	O
maciak	O
,	O
benjamin	O
meier	O
,	O
david	O
möller	O
,	O
andreas	O
müller	O
,	O
rainer	O
penninger	O
,	O
lena	O
reichel	O
,	O
alexander	O
schier	O
,	O
matthias	O
siegmund	O
,	O
mathias	O
tirtasana	O
,	O
oliver	O
tischler	O
,	O
max-	O
imilian	O
voit	O
,	O
igor	O
wall	O
,	O
achim	O
weber	O
,	O
frank	O
weinreis	O
,	O
gideon	O
maillette	O
de	O
buij	O
wenniger	O
,	O
philipp	O
woock	O
and	O
many	O
oth-	O
ers	O
for	O
their	O
feedback	O
,	O
suggestions	O
and	O
re-	O
marks	O
.	O
additionally	O
,	O
i	O
’	O
d	O
like	O
to	O
thank	O
sebastian	O
merzbach	O
,	O
who	O
examined	O
this	O
work	O
in	O
a	O
very	O
conscientious	O
way	O
ﬁnding	O
inconsisten-	O
cies	O
and	O
errors	O
.	O
in	O
particular	O
,	O
he	O
cleared	O
lots	O
and	O
lots	O
of	O
language	O
clumsiness	O
from	O
the	O
english	O
version	O
.	O
especially	O
,	O
i	O
would	O
like	O
to	O
thank	O
beate	O
kuhl	O
for	O
translating	O
the	O
entire	O
text	O
from	O
german	O
to	O
english	O
,	O
and	O
for	O
her	O
questions	O
which	O
made	O
me	O
think	O
of	O
changing	O
the	O
phrasing	O
of	O
some	O
paragraphs	O
.	O
i	O
would	O
particularly	O
like	O
to	O
thank	O
prof.	O
rolf	O
eckmiller	O
and	O
dr.	O
nils	O
goerke	O
as	O
well	O
as	O
the	O
entire	O
division	O
of	O
neuroinfor-	O
matics	O
,	O
department	O
of	O
computer	O
science	O
of	O
the	O
university	O
of	O
bonn	O
–	O
they	O
all	O
made	O
sure	O
that	O
i	O
always	O
learned	O
(	O
and	O
also	O
had	O
to	O
learn	O
)	O
something	O
new	O
about	O
neural	O
net-	O
works	O
and	O
related	O
subjects	O
.	O
especially	O
dr.	O
goerke	O
has	O
always	O
been	O
willing	O
to	O
respond	O
to	O
any	O
questions	O
i	O
was	O
not	O
able	O
to	O
answer	O
myself	O
during	O
the	O
writing	O
process	O
.	O
conver-	O
sations	O
with	O
prof.	O
eckmiller	O
made	O
me	O
step	O
back	O
from	O
the	O
whiteboard	O
to	O
get	O
a	O
better	O
overall	O
view	O
on	O
what	O
i	O
was	O
doing	O
and	O
what	O
i	O
should	O
do	O
next	O
.	O
globally	O
,	O
and	O
not	O
only	O
in	O
the	O
context	O
of	O
this	O
work	O
,	O
i	O
want	O
to	O
thank	O
my	O
parents	O
who	O
never	O
get	O
tired	O
to	O
buy	O
me	O
specialized	O
and	O
therefore	O
expensive	O
books	O
and	O
who	O
have	O
always	O
supported	O
me	O
in	O
my	O
studies	O
.	O
for	O
many	O
``	O
remarks	O
''	O
and	O
the	O
very	O
special	O
and	O
cordial	O
atmosphere	O
;	O
-	O
)	O
i	O
want	O
to	O
thank	O
andreas	O
huber	O
and	O
tobias	O
treutler	O
.	O
since	O
our	O
ﬁrst	O
semester	O
it	O
has	O
rarely	O
been	O
boring	O
with	O
you	O
!	O
now	O
i	O
would	O
like	O
to	O
think	O
back	O
to	O
my	O
school	O
days	O
and	O
cordially	O
thank	O
some	O
teachers	O
who	O
(	O
in	O
my	O
opinion	O
)	O
had	O
im-	O
parted	O
some	O
scientiﬁc	O
knowledge	O
to	O
me	O
–	O
although	O
my	O
class	O
participation	O
had	O
not	O
always	O
been	O
wholehearted	O
:	O
mr.	O
wilfried	O
hartmann	O
,	O
mr.	O
hubert	O
peters	O
and	O
mr.	O
frank	O
nökel	O
.	O
furthermore	O
i	O
would	O
like	O
to	O
thank	O
the	O
whole	O
team	O
at	O
the	O
notary	O
’	O
s	O
oﬃce	O
of	O
dr.	O
kemp	O
and	O
dr.	O
kolb	O
in	O
bonn	O
,	O
where	O
i	O
have	O
always	O
felt	O
to	O
be	O
in	O
good	O
hands	O
and	O
who	O
have	O
helped	O
me	O
to	O
keep	O
my	O
printing	O
costs	O
low	O
-	O
in	O
particular	O
christiane	O
flamme	O
and	O
dr.	O
kemp	O
!	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
ix	O
dkriesel.com	O
thanks	O
go	O
also	O
to	O
the	O
wikimedia	O
com-	O
mons	O
,	O
where	O
i	O
took	O
some	O
(	O
few	O
)	O
images	O
and	O
altered	O
them	O
to	O
suit	O
this	O
text	O
.	O
last	O
but	O
not	O
least	O
i	O
want	O
to	O
thank	O
two	O
people	O
who	O
made	O
outstanding	O
contribu-	O
tions	O
to	O
this	O
work	O
who	O
occupy	O
,	O
so	O
to	O
speak	O
,	O
a	O
place	O
of	O
honor	O
:	O
my	O
girlfriend	O
verena	O
thomas	O
,	O
who	O
found	O
many	O
mathematical	O
and	O
logical	O
errors	O
in	O
my	O
text	O
and	O
dis-	O
cussed	O
them	O
with	O
me	O
,	O
although	O
she	O
has	O
lots	O
of	O
other	O
things	O
to	O
do	O
,	O
and	O
chris-	O
tiane	O
schultze	O
,	O
who	O
carefully	O
reviewed	O
the	O
text	O
for	O
spelling	O
mistakes	O
and	O
inconsisten-	O
cies	O
.	O
david	O
kriesel	O
x	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
contents	O
a	O
small	O
preface	O
i	O
from	O
biology	O
to	O
formalization	O
–	O
motivation	O
,	O
philosophy	O
,	O
history	O
and	O
realization	O
of	O
neural	O
models	O
v	O
1	O
1	O
introduction	O
,	O
motivation	O
and	O
history	O
3	O
3	O
1.1	O
why	O
neural	O
networks	O
?	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5	O
1.1.1	O
the	O
100-step	B
rule	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6	O
1.1.2	O
simple	O
application	O
examples	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8	O
1.2	O
history	O
of	O
neural	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8	O
1.2.1	O
the	O
beginning	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
1.2.2	O
golden	O
age	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9	O
1.2.3	O
long	O
silence	O
and	O
slow	O
reconstruction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11	O
1.2.4	O
renaissance	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12	O
exercises	O
2	O
biological	O
neural	O
networks	O
13	O
2.1	O
the	O
vertebrate	O
nervous	B
system	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13	O
2.1.1	O
peripheral	O
and	O
central	B
nervous	I
system	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13	O
2.1.2	O
cerebrum	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14	O
2.1.3	O
cerebellum	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
15	O
2.1.4	O
diencephalon	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
15	O
2.1.5	O
brainstem	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
16	O
2.2	O
the	O
neuron	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
16	O
2.2.1	O
components	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
16	O
2.2.2	O
electrochemical	O
processes	O
in	O
the	O
neuron	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
19	O
2.3	O
receptor	O
cells	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
24	O
2.3.1	O
various	O
types	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
24	O
2.3.2	O
information	O
processing	O
within	O
the	O
nervous	B
system	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
25	O
2.3.3	O
light	O
sensing	O
organs	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
26	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
28	O
2.4	O
the	O
amount	O
of	O
neurons	O
in	O
living	O
organisms	O
xi	O
contents	O
dkriesel.com	O
2.5	O
technical	O
neurons	O
as	O
caricature	O
of	O
biology	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
30	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
31	O
exercises	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
(	O
fundamental	O
)	O
33	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
33	O
3.1	O
the	O
concept	O
of	O
time	O
in	O
neural	O
networks	O
3.2	O
components	O
of	O
neural	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
33	O
3.2.1	O
connections	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
34	O
3.2.2	O
propagation	B
function	I
and	O
network	B
input	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
34	O
3.2.3	O
activation	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
35	O
3.2.4	O
threshold	B
value	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
36	O
3.2.5	O
activation	B
function	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
36	O
3.2.6	O
common	O
activation	B
functions	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
37	O
3.2.7	O
output	B
function	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
38	O
3.2.8	O
learning	B
strategy	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
38	O
3.3	O
network	O
topologies	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
39	O
3.3.1	O
feedforward	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
39	O
3.3.2	O
recurrent	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
40	O
3.3.3	O
completely	O
linked	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
42	O
3.4	O
the	O
bias	B
neuron	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
43	O
3.5	O
representing	O
neurons	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
45	O
3.6	O
orders	O
of	O
activation	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
45	O
3.6.1	O
synchronous	O
activation	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
45	O
3.6.2	O
asynchronous	O
activation	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
46	O
input	O
and	O
output	O
of	O
data	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
48	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
48	O
3.7	O
exercises	O
supervised	B
learning	I
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
(	O
fundamental	O
)	O
51	O
4.1	O
paradigms	O
of	O
learning	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
51	O
4.1.1	O
unsupervised	B
learning	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
52	O
4.1.2	O
reinforcement	B
learning	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
53	O
4.1.3	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
53	O
4.1.4	O
oﬄine	O
or	O
online	B
learning	I
?	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
54	O
4.1.5	O
questions	O
in	O
advance	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
54	O
4.2	O
training	O
patterns	O
and	O
teaching	B
input	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
54	O
4.3	O
using	O
training	O
samples	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
56	O
4.3.1	O
division	O
of	O
the	O
training	B
set	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
57	O
4.3.2	O
order	O
of	O
pattern	O
representation	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
57	O
4.4	O
learning	B
curve	O
and	O
error	O
measurement	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
58	O
4.4.1	O
when	O
do	O
we	O
stop	O
learning	B
?	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
59	O
xii	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
contents	O
4.5.1	O
problems	O
of	O
gradient	B
procedures	O
4.5	O
gradient	B
optimization	O
procedures	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
61	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
62	O
4.6	O
exemplary	O
problems	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
64	O
4.6.1	O
boolean	O
functions	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
64	O
4.6.2	O
the	O
parity	O
function	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
64	O
4.6.3	O
the	O
2-spiral	O
problem	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
64	O
4.6.4	O
the	O
checkerboard	O
problem	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
65	O
4.6.5	O
the	O
identity	O
function	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
65	O
4.6.6	O
other	O
exemplary	O
problems	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
66	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
66	O
4.7.1	O
original	O
rule	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
66	O
4.7.2	O
generalized	O
form	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
67	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
67	O
4.7	O
hebbian	O
rule	O
exercises	O
ii	O
supervised	B
learning	I
network	O
paradigms	O
69	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
71	O
5.1	O
the	O
singlelayer	B
perceptron	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
74	O
5.1.1	O
perceptron	B
learning	I
algorithm	I
and	O
convergence	O
theorem	O
.	O
.	O
.	O
.	O
.	O
75	O
5.1.2	O
delta	B
rule	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
75	O
5.2	O
linear	B
separability	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
81	O
5.3	O
the	O
multilayer	B
perceptron	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
84	O
5.4	O
backpropagation	B
of	I
error	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
86	O
5.4.1	O
derivation	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
87	O
5.4.2	O
boiling	O
backpropagation	B
down	O
to	O
the	O
delta	B
rule	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
91	O
5.4.3	O
selecting	O
a	O
learning	B
rate	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
92	O
5.5	O
resilient	B
backpropagation	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
93	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
94	O
5.5.1	O
adaption	O
of	O
weights	O
5.5.2	O
dynamic	O
learning	B
rate	I
adjustment	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
94	O
5.5.3	O
rprop	O
in	O
practice	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
95	O
5.6	O
further	O
variations	O
and	O
extensions	O
to	O
backpropagation	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
96	O
5.6.1	O
momentum	B
term	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
96	O
5.6.2	O
flat	B
spot	I
elimination	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
97	O
5.6.3	O
second	B
order	I
backpropagation	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
98	O
5.6.4	O
weight	B
decay	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
98	O
5.6.5	O
pruning	B
and	O
optimal	B
brain	I
damage	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
98	O
initial	O
conﬁguration	O
of	O
a	O
multilayer	B
perceptron	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
99	O
5.7.1	O
number	O
of	O
layers	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
99	O
5.7.2	O
the	O
number	O
of	O
neurons	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
100	O
5.7	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
xiii	O
contents	O
dkriesel.com	O
5.7.3	O
5.7.4	O
selecting	O
an	O
activation	B
function	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
100	O
initializing	O
weights	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
101	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
101	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
102	O
5.8	O
the	O
8-3-8	O
encoding	O
problem	O
and	O
related	O
problems	O
exercises	O
6	O
radial	O
basis	B
functions	O
information	O
processing	O
in	O
rbf	O
neurons	O
105	O
6.1	O
components	O
and	O
structure	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
105	O
information	O
processing	O
of	O
an	O
rbf	O
network	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
106	O
6.2	O
6.2.1	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
108	O
6.2.2	O
analytical	O
thoughts	O
prior	O
to	O
the	O
training	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
111	O
6.3	O
training	O
of	O
rbf	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
114	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
115	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
118	O
6.4.1	O
adding	O
neurons	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
118	O
6.4.2	O
limiting	O
the	O
number	O
of	O
neurons	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
119	O
6.4.3	O
deleting	O
neurons	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
119	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
119	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
120	O
6.5	O
comparing	O
rbf	O
networks	O
and	O
multilayer	O
perceptrons	O
exercises	O
6.3.1	O
centers	O
and	O
widths	O
of	O
rbf	O
neurons	O
6.4	O
growing	B
rbf	O
networks	O
7	O
recurrent	O
perceptron-like	O
networks	O
(	O
depends	O
on	O
chapter	O
5	O
)	O
121	O
7.1	O
jordan	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
122	O
7.2	O
elman	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
123	O
7.3	O
training	O
recurrent	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
124	O
7.3.1	O
unfolding	B
in	I
time	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
125	O
7.3.2	O
teacher	B
forcing	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
127	O
7.3.3	O
recurrent	O
backpropagation	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
127	O
7.3.4	O
training	O
with	O
evolution	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
127	O
8	O
hopﬁeld	O
networks	O
129	O
8.1	O
inspired	O
by	O
magnetism	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
129	O
8.2	O
structure	O
and	O
functionality	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
129	O
input	O
and	O
output	O
of	O
a	O
hopﬁeld	O
network	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
130	O
8.2.1	O
8.2.2	O
signiﬁcance	O
of	O
weights	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
131	O
8.2.3	O
change	O
in	O
the	O
state	B
of	O
neurons	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
131	O
8.3	O
generating	O
the	O
weight	B
matrix	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
132	O
8.4	O
autoassociation	O
and	O
traditional	O
application	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
133	O
8.5	O
heteroassociation	O
and	O
analogies	O
to	O
neural	O
data	O
storage	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
134	O
8.5.1	O
generating	O
the	O
heteroassociative	O
matrix	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
135	O
8.5.2	O
stabilizing	O
the	O
heteroassociations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
135	O
8.5.3	O
biological	O
motivation	O
of	O
heterassociation	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
136	O
xiv	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
contents	O
8.6	O
continuous	B
hopﬁeld	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
136	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
137	O
9	O
learning	B
vector	I
quantization	I
139	O
9.1	O
about	O
quantization	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
139	O
9.2	O
purpose	O
of	O
lvq	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
140	O
9.3	O
using	O
codebook	O
vectors	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
140	O
9.4	O
adjusting	O
codebook	O
vectors	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
141	O
9.4.1	O
the	O
procedure	O
of	O
learning	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
141	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
143	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
143	O
9.5	O
connection	B
to	O
neural	O
networks	O
exercises	O
iii	O
unsupervised	B
learning	I
network	O
paradigms	O
145	O
10	O
self-organizing	B
feature	I
maps	I
10.4	O
examples	O
147	O
10.1	O
structure	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
147	O
10.2	O
functionality	O
and	O
output	O
interpretation	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
149	O
10.3	O
training	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
149	O
10.3.1	O
the	O
topology	B
function	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
150	O
10.3.2	O
monotonically	O
decreasing	O
learning	B
rate	I
and	O
neighborhood	O
.	O
.	O
.	O
.	O
152	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
155	O
10.4.1	O
topological	O
defects	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
156	O
10.5	O
adjustment	O
of	O
resolution	O
and	O
position-dependent	O
learning	B
rate	I
.	O
.	O
.	O
.	O
.	O
156	O
10.6	O
application	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
159	O
10.6.1	O
interaction	O
with	O
rbf	O
networks	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
161	O
10.7	O
variations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
161	O
10.7.1	O
neural	O
gas	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
161	O
10.7.2	O
multi-soms	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
163	O
10.7.3	O
multi-neural	B
gas	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
163	O
10.7.4	O
growing	B
neural	I
gas	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
164	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
164	O
exercises	O
11	O
adaptive	B
resonance	I
theory	I
165	O
11.1	O
task	O
and	O
structure	O
of	O
an	O
art	O
network	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
165	O
11.1.1	O
resonance	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
166	O
11.2	O
learning	B
process	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
167	O
11.2.1	O
pattern	B
input	O
and	O
top-down	B
learning	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
167	O
11.2.2	O
resonance	B
and	O
bottom-up	B
learning	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
167	O
11.2.3	O
adding	O
an	O
output	O
neuron	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
167	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
xv	O
contents	O
dkriesel.com	O
11.3	O
extensions	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
167	O
iv	O
excursi	O
,	O
appendices	O
and	O
registers	O
169	O
a	O
excursus	O
:	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	O
learnable	O
ﬁelds	O
171	O
a.1	O
k-means	B
clustering	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
172	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
172	O
a.2	O
k-nearest	B
neighboring	I
a.3	O
ε-nearest	O
neighboring	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
173	O
a.4	O
the	O
silhouette	O
coeﬃcient	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
173	O
a.5	O
regional	O
and	O
online	O
learnable	O
ﬁelds	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
175	O
a.5.1	O
structure	O
of	O
a	O
rolf	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
176	O
a.5.2	O
training	O
a	O
rolf	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
177	O
a.5.3	O
evaluating	O
a	O
rolf	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
178	O
a.5.4	O
comparison	O
with	O
popular	O
clustering	O
methods	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
179	O
a.5.5	O
initializing	O
radii	O
,	O
learning	B
rates	O
and	O
multiplier	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
180	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
180	O
a.5.6	O
application	O
examples	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
180	O
exercises	O
b	O
excursus	O
:	O
neural	O
networks	O
used	O
for	O
prediction	O
181	O
b.1	O
about	O
time	B
series	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
181	O
b.2	O
one-step-ahead	B
prediction	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
183	O
b.3	O
two-step-ahead	B
prediction	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
185	O
b.3.1	O
recursive	O
two-step-ahead	B
prediction	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
185	O
b.3.2	O
direct	O
two-step-ahead	O
prediction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
185	O
b.4	O
additional	O
optimization	O
approaches	O
for	O
prediction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
185	O
b.4.1	O
changing	O
temporal	O
parameters	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
185	O
b.4.2	O
heterogeneous	B
prediction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
187	O
b.5	O
remarks	O
on	O
the	O
prediction	O
of	O
share	O
prices	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
187	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
191	O
c.1	O
system	O
structure	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
192	O
c.1.1	O
the	O
gridworld	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
192	O
c.1.2	O
agent	B
und	O
environment	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
193	O
c.1.3	O
states	O
,	O
situations	O
and	O
actions	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
194	O
c.1.4	O
reward	B
and	O
return	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
195	O
c.1.5	O
the	O
policy	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
196	O
c.2	O
learning	B
process	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
198	O
c.2.1	O
rewarding	O
strategies	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
198	O
c.2.2	O
the	O
state-value	B
function	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
199	O
xvi	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
contents	O
c.2.3	O
monte	O
carlo	O
method	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
201	O
c.2.4	O
temporal	O
diﬀerence	O
learning	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
202	O
c.2.5	O
the	O
action-value	B
function	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
203	O
c.2.6	O
q	O
learning	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
204	O
c.3	O
example	O
applications	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
205	O
c.3.1	O
td	O
gammon	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
205	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
205	O
c.3.2	O
the	O
car	O
in	O
the	O
pit	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
206	O
c.3.3	O
the	O
pole	B
balancer	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
207	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
207	O
c.4	O
reinforcement	B
learning	I
in	O
connection	B
with	O
neural	O
networks	O
exercises	O
bibliography	O
list	O
of	O
figures	O
index	O
209	O
215	O
219	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
xvii	O
part	O
i	O
from	O
biology	O
to	O
formalization	O
–	O
motivation	O
,	O
philosophy	O
,	O
history	O
and	O
realization	O
of	O
neural	O
models	O
1	O
chapter	O
1	O
introduction	O
,	O
motivation	O
and	O
history	O
how	O
to	O
teach	O
a	O
computer	O
?	O
you	O
can	O
either	O
write	O
a	O
ﬁxed	O
program	O
–	O
or	O
you	O
can	O
enable	O
the	O
computer	O
to	O
learn	O
on	O
its	O
own	O
.	O
living	O
beings	O
do	O
not	O
have	O
any	O
programmer	O
writing	O
a	O
program	O
for	O
developing	O
their	O
skills	O
,	O
which	O
then	O
only	O
has	O
to	O
be	O
executed	O
.	O
they	O
learn	O
by	O
themselves	O
–	O
without	O
the	O
previous	O
knowledge	O
from	O
external	O
impressions	O
–	O
and	O
thus	O
can	O
solve	O
problems	O
better	O
than	O
any	O
computer	O
today	O
.	O
what	O
qualities	O
are	O
needed	O
to	O
achieve	O
such	O
a	O
behavior	O
for	O
devices	O
like	O
computers	O
?	O
can	O
such	O
cognition	O
be	O
adapted	O
from	O
biology	O
?	O
history	O
,	O
development	O
,	O
decline	O
and	O
resurgence	O
of	O
a	O
wide	O
approach	O
to	O
solve	O
problems	O
.	O
1.1	O
why	O
neural	O
networks	O
?	O
there	O
are	O
problem	O
categories	O
that	O
can	O
not	O
be	O
formulated	O
as	O
an	O
algorithm	B
.	O
problems	O
that	O
depend	O
on	O
many	O
subtle	O
factors	O
,	O
for	O
ex-	O
ample	O
the	O
purchase	O
price	O
of	O
a	O
real	O
estate	O
which	O
our	O
brain	B
can	O
(	O
approximately	O
)	O
cal-	O
culate	O
.	O
without	O
an	O
algorithm	B
a	O
computer	O
can	O
not	O
do	O
the	O
same	O
.	O
therefore	O
the	O
ques-	O
tion	O
to	O
be	O
asked	O
is	O
:	O
how	O
do	O
we	O
learn	O
to	O
explore	O
such	O
problems	O
?	O
exactly	O
–	O
we	O
learn	O
;	O
a	O
capability	O
comput-	O
ers	O
obviously	O
do	O
not	O
have	O
.	O
humans	O
have	O
a	O
brain	B
that	O
can	O
learn	O
.	O
computers	O
have	O
some	O
processing	O
units	O
and	O
memory	O
.	O
they	O
allow	O
the	O
computer	O
to	O
perform	O
the	O
most	O
complex	O
numerical	O
calculations	O
in	O
a	O
very	O
short	O
time	O
,	O
but	O
they	O
are	O
not	O
adaptive	O
.	O
if	O
we	O
compare	O
computer	O
and	O
brain1	O
,	O
we	O
will	O
note	O
that	O
,	O
theoretically	O
,	O
the	O
computer	O
should	O
be	O
more	O
powerful	O
than	O
our	O
brain	B
:	O
it	O
comprises	O
109	O
transistors	O
with	O
a	O
switch-	O
ing	O
time	O
of	O
10−9	O
seconds	O
.	O
the	O
brain	B
con-	O
tains	O
1011	O
neurons	O
,	O
but	O
these	O
only	O
have	O
a	O
switching	O
time	O
of	O
about	O
10−3	O
seconds	O
.	O
the	O
largest	O
part	O
of	O
the	O
brain	B
is	O
work-	O
ing	O
continuously	O
,	O
while	O
the	O
largest	O
part	O
of	O
the	O
computer	O
is	O
only	O
passive	O
data	O
storage	O
.	O
thus	O
,	O
the	O
brain	B
is	O
parallel	O
and	O
therefore	O
performing	O
close	O
to	O
its	O
theoretical	O
maxi-	O
1	O
of	O
course	O
,	O
this	O
comparison	O
is	O
-	O
for	O
obvious	O
rea-	O
sons	O
-	O
controversially	O
discussed	O
by	O
biologists	O
and	O
computer	O
scientists	O
,	O
since	O
response	O
time	O
and	O
quan-	O
tity	O
do	O
not	O
tell	O
anything	O
about	O
quality	O
and	O
perfor-	O
mance	O
of	O
the	O
processing	O
units	O
as	O
well	O
as	O
neurons	O
and	O
transistors	O
can	O
not	O
be	O
compared	O
directly	O
.	O
nev-	O
ertheless	O
,	O
the	O
comparison	O
serves	O
its	O
purpose	O
and	O
indicates	O
the	O
advantage	O
of	O
parallelism	B
by	O
means	O
of	O
processing	O
time	O
.	O
parallelism	B
computers	O
can	O
not	O
learn	O
3	O
chapter	O
1	O
introduction	O
,	O
motivation	O
and	O
history	O
dkriesel.com	O
no	O
.	O
of	O
processing	O
units	O
type	O
of	O
processing	O
units	O
type	O
of	O
calculation	O
data	O
storage	O
switching	O
time	O
possible	O
switching	O
operations	O
actual	O
switching	O
operations	O
brain	B
≈	O
1011	O
neurons	O
massively	O
parallel	O
associative	O
≈	O
10−3s	O
≈	O
1013	O
1	O
≈	O
1012	O
1	O
s	O
s	O
computer	O
≈	O
109	O
transistors	O
usually	O
serial	O
address-based	O
≈	O
10−9s	O
≈	O
1018	O
1	O
≈	O
1010	O
1	O
s	O
s	O
table	O
1.1	O
:	O
the	O
(	O
ﬂawed	O
)	O
comparison	O
between	O
brain	B
and	O
computer	O
at	O
a	O
glance	O
.	O
inspired	O
by	O
:	O
[	O
zel94	O
]	O
mum	O
,	O
from	O
which	O
the	O
computer	O
is	O
orders	O
of	O
magnitude	O
away	O
(	O
table	O
1.1	O
)	O
.	O
addition-	O
ally	O
,	O
a	O
computer	O
is	O
static	O
-	O
the	O
brain	B
as	O
a	O
biological	O
neural	O
network	O
can	O
reorganize	O
itself	O
during	O
its	O
``	O
lifespan	O
''	O
and	O
therefore	O
is	O
able	O
to	O
learn	O
,	O
to	O
compensate	O
errors	O
and	O
so	O
forth	O
.	O
within	O
this	O
text	O
i	O
want	O
to	O
outline	O
how	O
we	O
can	O
use	O
the	O
said	O
characteristics	O
of	O
our	O
brain	B
for	O
a	O
computer	O
system	O
.	O
so	O
the	O
study	O
of	O
artiﬁcial	O
neural	O
networks	O
is	O
motivated	O
by	O
their	O
similarity	O
to	O
success-	O
fully	O
working	O
biological	O
systems	O
,	O
which	O
-	O
in	O
comparison	O
to	O
the	O
overall	O
system	O
-	O
consist	O
of	O
very	O
simple	O
but	O
numerous	O
nerve	O
cells	O
that	O
work	O
massively	O
in	O
parallel	O
and	O
(	O
which	O
is	O
probably	O
one	O
of	O
the	O
most	O
signiﬁcant	O
aspects	O
)	O
have	O
the	O
capability	B
to	I
learn	I
.	O
there	O
is	O
no	O
need	O
to	O
explicitly	O
program	O
a	O
neural	O
network	O
.	O
for	O
instance	O
,	O
it	O
can	O
learn	O
from	O
training	O
samples	O
or	O
by	O
means	O
of	O
en-	O
couragement	O
-	O
with	O
a	O
carrot	O
and	O
a	O
stick	O
,	O
so	O
to	O
speak	O
(	O
reinforcement	B
learning	I
)	O
.	O
one	O
result	O
from	O
this	O
learning	B
procedure	O
is	O
the	O
capability	O
of	O
neural	O
networks	O
to	O
gen-	O
eralize	O
and	O
associate	O
data	O
:	O
after	O
suc-	O
cessful	O
training	O
a	O
neural	O
network	O
can	O
ﬁnd	O
reasonable	O
solutions	O
for	O
similar	O
problems	O
of	O
the	O
same	O
class	O
that	O
were	O
not	O
explicitly	O
trained	O
.	O
this	O
in	O
turn	O
results	O
in	O
a	O
high	O
de-	O
gree	O
of	O
fault	B
tolerance	I
against	O
noisy	O
in-	O
put	O
data	O
.	O
fault	B
tolerance	I
is	O
closely	O
related	O
to	O
biolog-	O
ical	O
neural	O
networks	O
,	O
in	O
which	O
this	O
charac-	O
teristic	O
is	O
very	O
distinct	O
:	O
as	O
previously	O
men-	O
tioned	O
,	O
a	O
human	O
has	O
about	O
1011	O
neurons	O
that	O
continuously	O
reorganize	O
themselves	O
or	O
are	O
reorganized	O
by	O
external	O
inﬂuences	O
(	O
about	O
105	O
neurons	O
can	O
be	O
destroyed	O
while	O
in	O
a	O
drunken	O
stupor	O
,	O
some	O
types	O
of	O
food	O
or	O
environmental	O
inﬂuences	O
can	O
also	O
de-	O
stroy	O
brain	B
cells	O
)	O
.	O
nevertheless	O
,	O
our	O
cogni-	O
tive	O
abilities	O
are	O
not	O
signiﬁcantly	O
aﬀected	O
.	O
thus	O
,	O
the	O
brain	B
is	O
tolerant	O
against	O
internal	O
errors	O
–	O
and	O
also	O
against	O
external	O
errors	O
,	O
for	O
we	O
can	O
often	O
read	O
a	O
really	O
``	O
dreadful	O
scrawl	O
''	O
although	O
the	O
individual	O
letters	O
are	O
nearly	O
impossible	O
to	O
read	O
.	O
our	O
modern	O
technology	O
,	O
however	O
,	O
is	O
not	O
automatically	O
fault-tolerant	O
.	O
i	O
have	O
never	O
heard	O
that	O
someone	O
forgot	O
to	O
install	O
the	O
4	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
simple	O
but	O
many	O
processing	O
units	O
n.	O
network	O
capable	O
to	O
learn	O
n.	O
network	O
fault	O
tolerant	O
dkriesel.com	O
1.1	O
why	O
neural	O
networks	O
?	O
i.e	O
.	O
hard	O
disk	O
controller	O
into	O
a	O
computer	O
and	O
therefore	O
the	O
graphics	O
card	O
automatically	O
took	O
over	O
its	O
tasks	O
,	O
removed	O
con-	O
ductors	O
and	O
developed	O
communication	O
,	O
so	O
that	O
the	O
system	O
as	O
a	O
whole	O
was	O
aﬀected	O
by	O
the	O
missing	O
component	O
,	O
but	O
not	O
com-	O
pletely	O
destroyed	O
.	O
a	O
disadvantage	O
of	O
this	O
distributed	O
fault-	O
tolerant	O
storage	O
is	O
certainly	O
the	O
fact	O
that	O
we	O
can	O
not	O
realize	O
at	O
ﬁrst	O
sight	O
what	O
a	O
neu-	O
ral	O
neutwork	O
knows	O
and	O
performs	O
or	O
where	O
its	O
faults	O
lie	O
.	O
usually	O
,	O
it	O
is	O
easier	O
to	O
per-	O
form	O
such	O
analyses	O
for	O
conventional	O
algo-	O
rithms	O
.	O
most	O
often	O
we	O
can	O
only	O
trans-	O
fer	O
knowledge	O
into	O
our	O
neural	O
network	O
by	O
means	O
of	O
a	O
learning	B
procedure	O
,	O
which	O
can	O
cause	O
several	O
errors	O
and	O
is	O
not	O
always	O
easy	O
to	O
manage	O
.	O
fault	B
tolerance	I
of	O
data	O
,	O
on	O
the	O
other	O
hand	O
,	O
is	O
already	O
more	O
sophisticated	O
in	O
state-of-	O
the-art	O
technology	O
:	O
let	O
us	O
compare	O
a	O
record	O
and	O
a	O
cd	O
.	O
if	O
there	O
is	O
a	O
scratch	O
on	O
a	O
record	O
,	O
the	O
audio	O
information	O
on	O
this	O
spot	O
will	O
be	O
completely	O
lost	O
(	O
you	O
will	O
hear	O
a	O
pop	O
)	O
and	O
then	O
the	O
music	O
goes	O
on	O
.	O
on	O
a	O
cd	O
the	O
audio	O
data	O
are	O
distributedly	O
stored	O
:	O
a	O
scratch	O
causes	O
a	O
blurry	O
sound	O
in	O
its	O
vicin-	O
ity	O
,	O
but	O
the	O
data	O
stream	O
remains	O
largely	O
unaﬀected	O
.	O
the	O
listener	O
won	O
’	O
t	O
notice	O
any-	O
thing	O
.	O
so	O
let	O
us	O
summarize	O
the	O
main	O
characteris-	O
tics	O
we	O
try	O
to	O
adapt	O
from	O
biology	O
:	O
.	O
self-organization	O
and	O
learning	B
capa-	O
bility	O
,	O
.	O
generalization	B
capability	O
and	O
.	O
fault	B
tolerance	I
.	O
what	O
types	O
of	O
neural	O
networks	O
particu-	O
larly	O
develop	O
what	O
kinds	O
of	O
abilities	O
and	O
can	O
be	O
used	O
for	O
what	O
problem	O
classes	O
will	O
be	O
discussed	O
in	O
the	O
course	O
of	O
this	O
work	O
.	O
in	O
the	O
introductory	O
chapter	O
i	O
want	O
to	O
''	O
the	O
neural	O
net-	O
clarify	O
the	O
following	O
:	O
work	O
''	O
does	O
not	O
exist	O
.	O
there	O
are	O
diﬀer-	O
ent	O
paradigms	O
for	O
neural	O
networks	O
,	O
how	O
they	O
are	O
trained	O
and	O
where	O
they	O
are	O
used	O
.	O
my	O
goal	O
is	O
to	O
introduce	O
some	O
of	O
these	O
paradigms	O
and	O
supplement	O
some	O
remarks	O
for	O
practical	O
application	O
.	O
we	O
have	O
already	O
mentioned	O
that	O
our	O
brain	B
works	O
massively	O
in	O
parallel	O
,	O
in	O
contrast	O
to	O
the	O
functioning	O
of	O
a	O
computer	O
,	O
i.e	O
.	O
every	O
component	O
is	O
active	O
at	O
any	O
time	O
.	O
if	O
we	O
want	O
to	O
state	B
an	O
argument	O
for	O
massive	O
par-	O
allel	O
processing	O
,	O
then	O
the	O
100-step	B
rule	I
can	O
be	O
cited	O
.	O
1.1.1	O
the	O
100-step	B
rule	I
experiments	O
showed	O
that	O
a	O
human	O
can	O
recognize	O
the	O
picture	O
of	O
a	O
familiar	O
object	O
or	O
person	O
in	O
≈	O
0.1	O
seconds	O
,	O
which	O
cor-	O
responds	O
to	O
a	O
neuron	O
switching	O
time	O
of	O
≈	O
10−3	O
seconds	O
in	O
≈	O
100	O
discrete	B
time	O
steps	O
of	O
parallel	O
processing	O
.	O
a	O
computer	O
following	O
the	O
von	O
neumann	O
architecture	O
,	O
however	O
,	O
can	O
do	O
practically	O
nothing	O
in	O
100	O
time	O
steps	O
of	O
sequential	O
pro-	O
cessing	O
,	O
which	O
are	O
100	O
assembler	O
steps	O
or	O
cycle	O
steps	O
.	O
now	O
we	O
want	O
to	O
look	O
at	O
a	O
simple	O
applica-	O
tion	O
example	O
for	O
a	O
neural	O
network	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
5	O
important	O
!	O
parallel	O
processing	O
chapter	O
1	O
introduction	O
,	O
motivation	O
and	O
history	O
dkriesel.com	O
put	O
is	O
called	O
h	O
for	O
``	O
halt	O
signal	O
''	O
)	O
.	O
there-	O
fore	O
we	O
need	O
a	O
mapping	O
f	O
:	O
r8	O
→	O
b1	O
,	O
that	O
applies	O
the	O
input	O
signals	O
to	O
a	O
robot	O
activity	O
.	O
1.1.2.1	O
the	O
classical	O
way	O
there	O
are	O
two	O
ways	O
of	O
realizing	O
this	O
map-	O
ping	O
.	O
on	O
the	O
one	O
hand	O
,	O
there	O
is	O
the	O
clas-	O
sical	O
way	O
:	O
we	O
sit	O
down	O
and	O
think	O
for	O
a	O
while	O
,	O
and	O
ﬁnally	O
the	O
result	O
is	O
a	O
circuit	O
or	O
a	O
small	O
computer	O
program	O
which	O
realizes	O
the	O
mapping	O
(	O
this	O
is	O
easily	O
possible	O
,	O
since	O
the	O
example	O
is	O
very	O
simple	O
)	O
.	O
after	O
that	O
we	O
refer	O
to	O
the	O
technical	O
reference	O
of	O
the	O
sensors	O
,	O
study	O
their	O
characteristic	O
curve	O
in	O
order	O
to	O
learn	O
the	O
values	O
for	O
the	O
diﬀerent	O
obstacle	O
distances	O
,	O
and	O
embed	O
these	O
values	O
into	O
the	O
aforementioned	O
set	O
of	O
rules	O
.	O
such	O
procedures	O
are	O
applied	O
in	O
the	O
classic	O
artiﬁ-	O
cial	O
intelligence	O
,	O
and	O
if	O
you	O
know	O
the	O
exact	O
rules	O
of	O
a	O
mapping	O
algorithm	B
,	O
you	O
are	O
al-	O
ways	O
well	O
advised	O
to	O
follow	O
this	O
scheme	O
.	O
1.1.2.2	O
the	O
way	O
of	O
learning	B
on	O
the	O
other	O
hand	O
,	O
more	O
interesting	O
and	O
more	O
successful	O
for	O
many	O
mappings	O
and	O
problems	O
that	O
are	O
hard	O
to	O
comprehend	O
straightaway	O
is	O
the	O
way	O
of	O
learning	B
:	O
we	O
show	O
diﬀerent	O
possible	O
situations	O
to	O
the	O
robot	O
(	O
ﬁg	O
.	O
1.2	O
on	O
page	O
8	O
)	O
,	O
–	O
and	O
the	O
robot	O
shall	O
learn	O
on	O
its	O
own	O
what	O
to	O
do	O
in	O
the	O
course	O
of	O
its	O
robot	O
life	O
.	O
in	O
this	O
example	O
the	O
robot	O
shall	O
simply	O
learn	O
when	O
to	O
stop	O
.	O
we	O
ﬁrst	O
treat	O
the	O
figure	O
1.1	O
:	O
a	O
small	O
robot	O
with	O
eight	O
sensors	O
and	O
two	O
motors	O
.	O
the	O
arrow	O
indicates	O
the	O
driv-	O
ing	O
direction	O
.	O
1.1.2	O
simple	O
application	O
examples	O
let	O
us	O
assume	O
that	O
we	O
have	O
a	O
small	O
robot	O
as	O
shown	O
in	O
ﬁg	O
.	O
1.1.	O
this	O
robot	O
has	O
eight	O
distance	O
sensors	O
from	O
which	O
it	O
extracts	O
in-	O
put	O
data	O
:	O
three	O
sensors	O
are	O
placed	O
on	O
the	O
front	O
right	O
,	O
three	O
on	O
the	O
front	O
left	O
,	O
and	O
two	O
on	O
the	O
back	O
.	O
each	O
sensor	O
provides	O
a	O
real	O
numeric	O
value	O
at	O
any	O
time	O
,	O
that	O
means	O
we	O
are	O
always	O
receiving	O
an	O
input	O
i	O
∈	O
r8	O
.	O
despite	O
its	O
two	O
motors	O
(	O
which	O
will	O
be	O
needed	O
later	O
)	O
the	O
robot	O
in	O
our	O
simple	O
ex-	O
ample	O
is	O
not	O
capable	O
to	O
do	O
much	O
:	O
it	O
shall	O
only	O
drive	O
on	O
but	O
stop	O
when	O
it	O
might	O
col-	O
lide	O
with	O
an	O
obstacle	O
.	O
thus	O
,	O
our	O
output	O
is	O
binary	O
:	O
h	O
=	O
0	O
for	O
``	O
everything	O
is	O
okay	O
,	O
drive	O
on	O
''	O
and	O
h	O
=	O
1	O
for	O
``	O
stop	O
''	O
(	O
the	O
out-	O
6	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
1.1	O
why	O
neural	O
networks	O
?	O
our	O
example	O
can	O
be	O
optionally	O
expanded	O
.	O
for	O
the	O
purpose	O
of	O
direction	O
control	O
it	O
would	O
be	O
possible	O
to	O
control	O
the	O
motors	O
of	O
our	O
robot	O
separately2	O
,	O
with	O
the	O
sensor	O
layout	O
being	O
the	O
same	O
.	O
in	O
this	O
case	O
we	O
are	O
looking	O
for	O
a	O
mapping	O
f	O
:	O
r8	O
→	O
r2	O
,	O
which	O
gradually	O
controls	O
the	O
two	O
motors	O
by	O
means	O
of	O
the	O
sensor	O
inputs	O
and	O
thus	O
can	O
not	O
only	O
,	O
for	O
example	O
,	O
stop	O
the	O
robot	O
but	O
also	O
lets	O
it	O
avoid	O
obstacles	O
.	O
here	O
it	O
is	O
more	O
diﬃcult	O
to	O
analytically	O
derive	O
the	O
rules	O
,	O
and	O
de	O
facto	O
a	O
neural	O
network	O
would	O
be	O
more	O
appropriate	O
.	O
our	O
goal	O
is	O
not	O
to	O
learn	O
the	O
samples	O
by	O
heart	O
,	O
but	O
to	O
realize	O
the	O
principle	O
behind	O
them	O
:	O
ideally	O
,	O
the	O
robot	O
should	O
apply	O
the	O
neural	O
network	O
in	O
any	O
situation	B
and	O
be	O
able	O
to	O
avoid	O
obstacles	O
.	O
in	O
particular	O
,	O
the	O
robot	O
should	O
query	O
the	O
network	O
continu-	O
ously	O
and	O
repeatedly	O
while	O
driving	O
in	O
order	O
to	O
continously	O
avoid	O
obstacles	O
.	O
the	O
result	O
is	O
a	O
constant	O
cycle	O
:	O
the	O
robot	O
queries	O
the	O
network	O
.	O
as	O
a	O
consequence	O
,	O
it	O
will	O
drive	O
in	O
one	O
direction	O
,	O
which	O
changes	O
the	O
sen-	O
sors	O
values	O
.	O
again	O
the	O
robot	O
queries	O
the	O
network	O
and	O
changes	O
its	O
position	O
,	O
the	O
sen-	O
sor	O
values	O
are	O
changed	O
once	O
again	O
,	O
and	O
so	O
on	O
.	O
it	O
is	O
obvious	O
that	O
this	O
system	O
can	O
also	O
be	O
adapted	O
to	O
dynamic	O
,	O
i.e	O
changing	O
,	O
en-	O
vironments	O
(	O
e.g	O
.	O
the	O
moving	O
obstacles	O
in	O
our	O
example	O
)	O
.	O
2	O
there	O
is	O
a	O
robot	O
called	O
khepera	O
with	O
more	O
or	O
less	O
similar	O
characteristics	O
.	O
it	O
is	O
round-shaped	O
,	O
approx	O
.	O
7	O
cm	O
in	O
diameter	O
,	O
has	O
two	O
motors	O
with	O
wheels	O
and	O
various	O
sensors	O
.	O
for	O
more	O
information	O
i	O
rec-	O
ommend	O
to	O
refer	O
to	O
the	O
internet	O
.	O
figure	O
1.3	O
:	O
initially	O
,	O
we	O
regard	O
the	O
robot	O
control	O
as	O
a	O
black	B
box	I
whose	O
inner	O
life	O
is	O
unknown	O
.	O
the	O
black	B
box	I
receives	O
eight	O
real	O
sensor	O
values	O
and	O
maps	O
these	O
values	O
to	O
a	O
binary	O
output	O
value	O
.	O
neural	O
network	O
as	O
a	O
kind	O
of	O
black	B
box	I
(	O
ﬁg	O
.	O
1.3	O
)	O
.	O
this	O
means	O
we	O
do	O
not	O
know	O
its	O
structure	O
but	O
just	O
regard	O
its	O
behavior	O
in	O
practice	O
.	O
the	O
situations	O
in	O
form	O
of	O
simply	O
mea-	O
sured	O
sensor	O
values	O
(	O
e.g	O
.	O
placing	O
the	O
robot	O
in	O
front	O
of	O
an	O
obstacle	O
,	O
see	O
illustration	O
)	O
,	O
which	O
we	O
show	O
to	O
the	O
robot	O
and	O
for	O
which	O
we	O
specify	O
whether	O
to	O
drive	O
on	O
or	O
to	O
stop	O
,	O
are	O
called	O
training	O
samples	O
.	O
thus	O
,	O
a	O
train-	O
ing	O
sample	O
consists	O
of	O
an	O
exemplary	O
input	O
and	O
a	O
corresponding	O
desired	O
output	O
.	O
now	O
the	O
question	O
is	O
how	O
to	O
transfer	O
this	O
knowl-	O
edge	O
,	O
the	O
information	O
,	O
into	O
the	O
neural	O
net-	O
work	O
.	O
the	O
samples	O
can	O
be	O
taught	O
to	O
a	O
neural	O
network	O
by	O
using	O
a	O
simple	O
learning	B
pro-	O
cedure	O
(	O
a	O
learning	B
procedure	O
is	O
a	O
simple	O
algorithm	B
or	O
a	O
mathematical	O
formula	O
.	O
if	O
we	O
have	O
done	O
everything	O
right	O
and	O
chosen	O
good	O
samples	O
,	O
the	O
neural	O
network	O
will	O
gen-	O
eralize	O
from	O
these	O
samples	O
and	O
ﬁnd	O
a	O
uni-	O
versal	O
rule	O
when	O
it	O
has	O
to	O
stop	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
7	O
chapter	O
1	O
introduction	O
,	O
motivation	O
and	O
history	O
dkriesel.com	O
figure	O
1.2	O
:	O
the	O
robot	O
is	O
positioned	O
in	O
a	O
landscape	O
that	O
provides	O
sensor	O
values	O
for	O
diﬀerent	O
situa-	O
tions	O
.	O
we	O
add	O
the	O
desired	O
output	O
values	O
h	O
and	O
so	O
receive	O
our	O
learning	B
samples	O
.	O
the	O
directions	O
in	O
which	O
the	O
sensors	O
are	O
oriented	O
are	O
exemplarily	O
applied	O
to	O
two	O
robots	O
.	O
1.2	O
a	O
brief	O
history	O
of	O
neural	O
networks	O
the	O
ﬁeld	O
of	O
neural	O
networks	O
has	O
,	O
like	O
any	O
other	O
ﬁeld	O
of	O
science	O
,	O
a	O
long	O
history	B
of	I
development	I
with	O
many	O
ups	O
and	O
downs	O
,	O
as	O
we	O
will	O
see	O
soon	O
.	O
to	O
continue	O
the	O
style	O
of	O
my	O
work	O
i	O
will	O
not	O
represent	O
this	O
history	O
in	O
text	O
form	O
but	O
more	O
compact	O
in	O
form	O
of	O
a	O
timeline	O
.	O
citations	O
and	O
bibliographical	O
ref-	O
erences	O
are	O
added	O
mainly	O
for	O
those	O
topics	O
that	O
will	O
not	O
be	O
further	O
discussed	O
in	O
this	O
text	O
.	O
citations	O
for	O
keywords	O
that	O
will	O
be	O
explained	O
later	O
are	O
mentioned	O
in	O
the	O
corre-	O
sponding	O
chapters	O
.	O
the	O
history	O
of	O
neural	O
networks	O
begins	O
in	O
the	O
early	O
1940	O
’	O
s	O
and	O
thus	O
nearly	O
simulta-	O
neously	O
with	O
the	O
history	O
of	O
programmable	O
electronic	O
computers	O
.	O
the	O
youth	O
of	O
this	O
ﬁeld	O
of	O
research	O
,	O
as	O
with	O
the	O
ﬁeld	O
of	O
com-	O
puter	O
science	O
itself	O
,	O
can	O
be	O
easily	O
recog-	O
nized	O
due	O
to	O
the	O
fact	O
that	O
many	O
of	O
the	O
cited	O
persons	O
are	O
still	O
with	O
us	O
.	O
1.2.1	O
the	O
beginning	O
as	O
soon	O
as	O
1943	O
warren	O
mcculloch	O
and	O
walter	O
pitts	O
introduced	O
mod-	O
els	O
of	O
neurological	O
networks	O
,	O
recre-	O
ated	O
threshold	O
switches	O
based	O
on	O
neu-	O
rons	O
and	O
showed	O
that	O
even	O
simple	O
networks	O
of	O
this	O
kind	O
are	O
able	O
to	O
calculate	O
nearly	O
any	O
logic	O
or	O
arith-	O
metic	O
function	B
[	O
mp43	O
]	O
.	O
further-	O
8	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
1.2	O
history	O
of	O
neural	O
networks	O
figure	O
1.4	O
:	O
some	O
institutions	O
of	O
the	O
ﬁeld	O
of	O
neural	O
networks	O
.	O
from	O
left	O
to	O
right	O
:	O
john	O
von	O
neu-	O
mann	O
,	O
donald	O
o.	O
hebb	O
,	O
marvin	O
minsky	O
,	O
bernard	O
widrow	O
,	O
seymour	O
papert	O
,	O
teuvo	O
kohonen	O
,	O
john	O
hopﬁeld	O
,	O
``	O
in	O
the	O
order	O
of	O
appearance	O
''	O
as	O
far	O
as	O
possible	O
.	O
more	O
,	O
the	O
ﬁrst	O
computer	O
precur-	O
sors	O
(	O
``	O
electronic	O
brains	O
''	O
)	O
were	O
de-	O
veloped	O
,	O
among	O
others	O
supported	O
by	O
konrad	O
zuse	O
,	O
who	O
was	O
tired	O
of	O
cal-	O
culating	O
ballistic	O
trajectories	O
by	O
hand	O
.	O
1947	O
:	O
walter	O
pitts	O
and	O
warren	O
mc-	O
culloch	O
indicated	O
a	O
practical	O
ﬁeld	O
of	O
application	O
(	O
which	O
was	O
not	O
men-	O
tioned	O
in	O
their	O
work	O
from	O
1943	O
)	O
,	O
namely	O
the	O
recognition	O
of	O
spacial	O
pat-	O
terns	O
by	O
neural	O
networks	O
[	O
pm47	O
]	O
.	O
1949	O
:	O
donald	O
o.	O
hebb	O
formulated	O
the	O
classical	O
hebbian	O
rule	O
[	O
heb49	O
]	O
which	O
represents	O
in	O
its	O
more	O
generalized	O
form	O
the	O
basis	B
of	O
nearly	O
all	O
neural	O
learning	B
procedures	O
.	O
the	O
rule	O
im-	O
plies	O
that	O
the	O
connection	B
between	O
two	O
neurons	O
is	O
strengthened	O
when	O
both	O
neurons	O
are	O
active	O
at	O
the	O
same	O
time	O
.	O
this	O
change	O
in	O
strength	O
is	O
propor-	O
tional	O
to	O
the	O
product	O
of	O
the	O
two	O
activ-	O
ities	O
.	O
hebb	O
could	O
postulate	O
this	O
rule	O
,	O
but	O
due	O
to	O
the	O
absence	O
of	O
neurological	O
research	O
he	O
was	O
not	O
able	O
to	O
verify	O
it	O
.	O
neuropsychologist	O
karl	O
lashley	O
defended	O
the	O
thesis	O
that	O
1950	O
:	O
the	O
brain	B
information	O
storage	O
is	O
realized	O
as	O
a	O
distributed	O
system	O
.	O
his	O
thesis	O
was	O
based	O
on	O
experiments	O
on	O
rats	O
,	O
where	O
only	O
the	O
extent	O
but	O
not	O
the	O
location	O
of	O
the	O
destroyed	O
nerve	O
tissue	O
inﬂuences	O
the	O
rats	O
’	O
performance	O
to	O
ﬁnd	O
their	O
way	O
out	O
of	O
a	O
labyrinth	O
.	O
1.2.2	O
golden	O
age	O
1951	O
:	O
for	O
his	O
dissertation	O
marvin	O
min-	O
sky	O
developed	O
the	O
neurocomputer	O
snark	O
,	O
which	O
has	O
already	O
been	O
capa-	O
ble	O
to	O
adjust	O
its	O
weights3	O
automati-	O
cally	O
.	O
but	O
it	O
has	O
never	O
been	O
practi-	O
cally	O
implemented	O
,	O
since	O
it	O
is	O
capable	O
to	O
busily	O
calculate	O
,	O
but	O
nobody	O
really	O
knows	O
what	O
it	O
calculates	O
.	O
1956	O
:	O
well-known	O
scientists	O
and	O
ambi-	O
tious	O
students	O
met	O
at	O
the	O
dart-	O
mouth	O
summer	O
research	O
project	O
and	O
discussed	O
,	O
to	O
put	O
it	O
crudely	O
,	O
how	O
to	O
simulate	O
a	O
brain	B
.	O
diﬀerences	O
be-	O
tween	O
top-down	B
and	O
bottom-up	B
re-	O
search	O
developed	O
.	O
while	O
the	O
early	O
3	O
we	O
will	O
learn	O
soon	O
what	O
weights	O
are	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
9	O
chapter	O
1	O
introduction	O
,	O
motivation	O
and	O
history	O
dkriesel.com	O
supporters	O
of	O
artiﬁcial	O
intelligence	O
wanted	O
to	O
simulate	O
capabilities	O
by	O
means	O
of	O
software	O
,	O
supporters	O
of	O
neu-	O
ral	O
networks	O
wanted	O
to	O
achieve	O
sys-	O
tem	O
behavior	O
by	O
imitating	O
the	O
small-	O
est	O
parts	O
of	O
the	O
system	O
–	O
the	O
neurons	O
.	O
1957-1958	O
:	O
at	O
the	O
mit	O
,	O
frank	O
rosen-	O
blatt	O
,	O
charles	O
wightman	O
and	O
their	O
coworkers	O
developed	O
the	O
ﬁrst	O
successful	O
neurocomputer	O
,	O
the	O
mark	O
i	O
perceptron	B
,	O
which	O
was	O
capable	O
to	O
recognize	O
simple	O
numerics	O
by	O
means	O
of	O
a	O
20	O
×	O
20	O
pixel	O
image	O
sensor	O
and	O
electromechanically	O
worked	O
with	O
512	O
motor	O
driven	O
potentiometers	O
-	O
each	O
potentiometer	O
representing	O
one	O
vari-	O
able	O
weight	B
.	O
1959	O
:	O
frank	O
rosenblatt	O
described	O
dif-	O
ferent	O
versions	O
of	O
the	O
perceptron	B
,	O
for-	O
mulated	O
and	O
veriﬁed	O
his	O
perceptron	B
convergence	I
theorem	I
.	O
he	O
described	O
neuron	B
layers	I
mimicking	O
the	O
retina	B
,	O
threshold	O
switches	O
,	O
and	O
a	O
learning	B
rule	O
adjusting	O
the	O
connecting	O
weights	O
.	O
1960	O
:	O
bernard	O
widrow	O
and	O
mar-	O
cian	O
e.	O
hoff	O
introduced	O
the	O
ada-	O
line	O
(	O
adaptive	O
linear	O
neu-	O
ron	O
)	O
[	O
wh60	O
]	O
,	O
a	O
fast	O
and	O
precise	O
adaptive	O
learning	B
system	O
being	O
the	O
ﬁrst	O
widely	O
commercially	O
used	O
neu-	O
ral	O
network	O
:	O
it	O
could	O
be	O
found	O
in	O
nearly	O
every	O
analog	O
telephone	O
for	O
real-	O
time	O
adaptive	O
echo	O
ﬁltering	O
and	O
was	O
trained	O
by	O
menas	O
of	O
the	O
widrow-hoﬀ	O
rule	O
or	O
delta	B
rule	I
.	O
at	O
that	O
time	O
hoﬀ	O
,	O
later	O
co-founder	O
of	O
intel	O
corporation	O
,	O
was	O
a	O
phd	O
student	O
of	O
widrow	O
,	O
who	O
himself	O
is	O
known	O
as	O
the	O
inventor	O
of	O
modern	O
microprocessors	O
.	O
one	O
advan-	O
tage	O
the	O
delta	B
rule	I
had	O
over	O
the	O
origi-	O
nal	O
perceptron	B
learning	I
algorithm	I
was	O
its	O
adaptivity	O
:	O
if	O
the	O
diﬀerence	O
be-	O
tween	O
the	O
actual	O
output	O
and	O
the	O
cor-	O
rect	O
solution	O
was	O
large	O
,	O
the	O
connect-	O
ing	O
weights	O
also	O
changed	O
in	O
larger	O
steps	O
–	O
the	O
smaller	O
the	O
steps	O
,	O
the	O
closer	O
the	O
target	B
was	O
.	O
disadvantage	O
:	O
missapplication	O
led	O
to	O
inﬁnitesimal	O
small	O
steps	O
close	O
to	O
the	O
target	B
.	O
in	O
the	O
following	O
stagnation	O
and	O
out	O
of	O
fear	O
of	O
scientiﬁc	O
unpopularity	O
of	O
the	O
neu-	O
ral	O
networks	O
adaline	O
was	O
renamed	O
in	O
adaptive	O
linear	O
element	O
–	O
which	O
was	O
undone	O
again	O
later	O
on	O
.	O
1961	O
:	O
karl	O
steinbuch	O
introduced	O
tech-	O
nical	O
realizations	O
of	O
associative	O
mem-	O
ory	O
,	O
which	O
can	O
be	O
seen	O
as	O
predecessors	O
of	O
today	O
’	O
s	O
neural	O
associative	O
mem-	O
ories	O
[	O
ste61	O
]	O
.	O
additionally	O
,	O
he	O
de-	O
scribed	O
concepts	O
for	O
neural	O
techniques	O
and	O
analyzed	O
their	O
possibilities	O
and	O
limits	O
.	O
1965	O
:	O
in	O
his	O
book	O
learning	B
machines	O
,	O
nils	O
nilsson	O
gave	O
an	O
overview	O
of	O
the	O
progress	O
and	O
works	O
of	O
this	O
period	B
of	O
neural	O
network	O
research	O
.	O
it	O
was	O
assumed	O
that	O
the	O
basic	O
principles	O
of	O
self-learning	O
and	O
therefore	O
,	O
generally	O
speaking	O
,	O
``	O
intelligent	O
''	O
systems	O
had	O
al-	O
ready	O
been	O
discovered	O
.	O
today	O
this	O
as-	O
sumption	O
seems	O
to	O
be	O
an	O
exorbitant	O
overestimation	O
,	O
but	O
at	O
that	O
time	O
it	O
provided	O
for	O
high	O
popularity	O
and	O
suf-	O
ﬁcient	O
research	O
funds	O
.	O
1969	O
:	O
marvin	O
minsky	O
and	O
seymour	O
papert	O
published	O
a	O
precise	O
mathe-	O
10	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
development	O
accelerates	O
ﬁrst	O
spread	O
use	O
backprop	O
developed	O
dkriesel.com	O
1.2	O
history	O
of	O
neural	O
networks	O
research	O
funds	O
were	O
stopped	O
matical	O
analysis	O
of	O
the	O
perceptron	B
[	O
mp69	O
]	O
to	O
show	O
that	O
the	O
perceptron	B
model	O
was	O
not	O
capable	O
of	O
representing	O
many	O
important	O
problems	O
(	O
keywords	O
:	O
xor	O
problem	O
and	O
linear	B
separability	I
)	O
,	O
and	O
so	O
put	O
an	O
end	O
to	O
overestimation	O
,	O
popularity	O
and	O
research	O
funds	O
.	O
the	O
implication	O
that	O
more	O
powerful	O
mod-	O
els	O
would	O
show	O
exactly	O
the	O
same	O
prob-	O
lems	O
and	O
the	O
forecast	O
that	O
the	O
entire	O
ﬁeld	O
would	O
be	O
a	O
research	O
dead	O
end	O
re-	O
sulted	O
in	O
a	O
nearly	O
complete	O
decline	O
in	O
research	O
funds	O
for	O
the	O
next	O
15	O
years	O
–	O
no	O
matter	O
how	O
incorrect	O
these	O
fore-	O
casts	O
were	O
from	O
today	O
’	O
s	O
point	O
of	O
view	O
.	O
1.2.3	O
long	O
silence	O
and	O
slow	O
reconstruction	O
the	O
research	O
funds	O
were	O
,	O
as	O
previously-	O
mentioned	O
,	O
extremely	O
short	O
.	O
everywhere	O
research	O
went	O
on	O
,	O
but	O
there	O
were	O
neither	O
conferences	O
nor	O
other	O
events	O
and	O
therefore	O
only	O
few	O
publications	O
.	O
this	O
isolation	O
of	O
individual	O
researchers	O
provided	O
for	O
many	O
independently	O
developed	O
neural	O
network	O
paradigms	O
:	O
they	O
researched	O
,	O
but	O
there	O
was	O
no	O
discourse	O
among	O
them	O
.	O
in	O
spite	O
of	O
the	O
poor	O
appreciation	O
the	O
ﬁeld	O
received	O
,	O
the	O
basic	O
theories	O
for	O
the	O
still	O
continuing	O
renaissance	O
were	O
laid	O
at	O
that	O
time	O
:	O
1972	O
:	O
teuvo	O
kohonen	O
introduced	O
a	O
the	O
linear	O
associator	O
,	O
model	O
of	O
a	O
model	O
of	O
an	O
associative	O
memory	O
[	O
koh72	O
]	O
.	O
in	O
the	O
same	O
year	O
,	O
such	O
a	O
model	O
was	O
presented	O
independently	O
and	O
from	O
a	O
neurophysiologist	O
’	O
s	O
point	O
of	O
view	O
by	O
james	O
a.	O
anderson	O
[	O
and72	O
]	O
.	O
1973	O
:	O
christoph	O
von	O
der	O
malsburg	O
used	O
a	O
neuron	O
model	O
that	O
was	O
non-	O
linear	O
and	O
biologically	O
more	O
moti-	O
vated	O
[	O
vdm73	O
]	O
.	O
1974	O
:	O
for	O
his	O
dissertation	O
in	O
harvard	O
paul	O
werbos	O
developed	O
a	O
learning	B
procedure	O
called	O
backpropagation	B
of	I
error	I
[	O
wer74	O
]	O
,	O
but	O
it	O
was	O
not	O
until	O
one	O
decade	O
later	O
that	O
this	O
procedure	O
reached	O
today	O
’	O
s	O
importance	O
.	O
1976-1980	O
and	O
thereafter	O
:	O
stephen	O
instance	O
[	O
gro76	O
]	O
)	O
grossberg	O
presented	O
many	O
papers	O
(	O
for	O
in	O
which	O
numerous	O
neural	O
models	O
are	O
analyzed	O
mathematically	O
.	O
furthermore	O
,	O
he	O
dedicated	O
himself	O
to	O
the	O
problem	O
of	O
keeping	O
a	O
neural	O
network	O
capable	O
of	O
destroying	O
already	O
learned	O
associations	O
.	O
under	O
cooperation	O
of	O
gail	O
carpenter	O
led	O
to	O
models	O
of	O
adaptive	O
this	O
resonance	B
theory	O
(	O
art	O
)	O
.	O
learning	B
without	O
–	O
[	O
koh82	O
,	O
koh98	O
]	O
1982	O
:	O
teuvo	O
kohonen	O
described	O
the	O
feature	O
maps	O
self-organizing	O
(	O
som	O
)	O
also	O
known	O
as	O
kohonen	O
maps	O
.	O
he	O
was	O
looking	O
for	O
the	O
mechanisms	O
involving	O
self-organization	O
in	O
the	O
brain	B
(	O
he	O
knew	O
that	O
the	O
information	O
about	O
the	O
creation	O
of	O
a	O
being	O
is	O
stored	O
in	O
the	O
genome	O
,	O
which	O
has	O
,	O
however	O
,	O
not	O
enough	O
memory	O
for	O
a	O
structure	O
like	O
the	O
brain	B
.	O
as	O
a	O
consequence	O
,	O
the	O
brain	B
has	O
to	O
organize	O
and	O
create	O
itself	O
for	O
the	O
most	O
part	O
)	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
11	O
chapter	O
1	O
introduction	O
,	O
motivation	O
and	O
history	O
dkriesel.com	O
john	O
hopfield	O
also	O
invented	O
the	O
so-called	O
hopﬁeld	O
networks	O
[	O
hop82	O
]	O
which	O
are	O
inspired	O
by	O
the	O
laws	O
of	O
mag-	O
netism	O
in	O
physics	O
.	O
they	O
were	O
not	O
widely	O
used	O
in	O
technical	O
applications	O
,	O
but	O
the	O
ﬁeld	O
of	O
neural	O
networks	O
slowly	O
regained	O
importance	O
.	O
1983	O
:	O
fukushima	O
,	O
miyake	O
and	O
ito	O
in-	O
troduced	O
the	O
neural	O
model	O
of	O
the	O
neocognitron	O
which	O
could	O
recognize	O
handwritten	O
characters	O
[	O
fmi83	O
]	O
and	O
was	O
an	O
extension	O
of	O
the	O
cognitron	O
net-	O
work	O
already	O
developed	O
in	O
1975	O
.	O
1.2.4	O
renaissance	O
through	O
the	O
inﬂuence	O
of	O
john	O
hopfield	O
,	O
who	O
had	O
personally	O
convinced	O
many	O
re-	O
searchers	O
of	O
the	O
importance	O
of	O
the	O
ﬁeld	O
,	O
and	O
the	O
wide	O
publication	O
of	O
backpro-	O
pagation	O
by	O
rumelhart	O
,	O
hinton	O
and	O
williams	O
,	O
the	O
ﬁeld	O
of	O
neural	O
networks	O
slowly	O
showed	O
signs	O
of	O
upswing	O
.	O
1985	O
:	O
john	O
hopfield	O
published	O
an	O
arti-	O
cle	O
describing	O
a	O
way	O
of	O
ﬁnding	O
accept-	O
able	O
solutions	O
for	O
the	O
travelling	O
sales-	O
man	O
problem	O
by	O
using	O
hopﬁeld	O
nets	O
.	O
1986	O
:	O
the	O
backpropagation	B
of	I
error	I
learn-	O
ing	O
procedure	O
as	O
a	O
generalization	B
of	O
the	O
delta	B
rule	I
was	O
separately	O
devel-	O
oped	O
and	O
widely	O
published	O
by	O
the	O
par-	O
allel	O
distributed	O
processing	O
group	O
[	O
rhw86a	O
]	O
:	O
non-linearly-separable	O
problems	O
could	O
be	O
solved	O
by	O
multi-	O
layer	B
perceptrons	O
,	O
and	O
marvin	O
min-	O
sky	O
’	O
s	O
negative	O
evaluations	O
were	O
dis-	O
proven	O
at	O
a	O
single	O
blow	O
.	O
at	O
the	O
same	O
time	O
a	O
certain	O
kind	O
of	O
fatigue	O
spread	O
in	O
the	O
ﬁeld	O
of	O
artiﬁcial	O
intelligence	O
,	O
caused	O
by	O
a	O
series	O
of	O
failures	O
and	O
un-	O
fulﬁlled	O
hopes	O
.	O
from	O
this	O
time	O
on	O
,	O
the	O
development	O
of	O
the	O
ﬁeld	O
of	O
research	O
has	O
almost	O
been	O
explosive	O
.	O
it	O
can	O
no	O
longer	O
be	O
item-	O
ized	O
,	O
but	O
some	O
of	O
its	O
results	O
will	O
be	O
seen	O
in	O
the	O
following	O
.	O
exercises	O
exercise	O
1.	O
give	O
one	O
example	O
for	O
each	O
of	O
the	O
following	O
topics	O
:	O
.	O
a	O
book	O
on	O
neural	O
networks	O
or	O
neuroin-	O
formatics	O
,	O
.	O
a	O
collaborative	O
group	O
of	O
a	O
university	O
working	O
with	O
neural	O
networks	O
,	O
.	O
a	O
software	O
tool	O
realizing	O
neural	O
net-	O
works	O
(	O
``	O
simulator	O
''	O
)	O
,	O
.	O
a	O
company	O
using	O
neural	O
networks	O
,	O
and	O
.	O
a	O
product	O
or	O
service	O
being	O
realized	O
by	O
means	O
of	O
neural	O
networks	O
.	O
exercise	O
2.	O
show	O
at	O
least	O
four	O
applica-	O
tions	O
of	O
technical	O
neural	O
networks	O
:	O
two	O
from	O
the	O
ﬁeld	O
of	O
pattern	B
recognition	I
and	O
two	O
from	O
the	O
ﬁeld	O
of	O
function	B
approxima-	O
tion	O
.	O
exercise	O
3.	O
brieﬂy	O
characterize	O
the	O
four	O
development	O
phases	O
of	O
neural	O
networks	O
and	O
give	O
expressive	O
examples	O
for	O
each	O
phase	O
.	O
12	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
renaissance	O
chapter	O
2	O
biological	O
neural	O
networks	O
how	O
do	O
biological	O
systems	O
solve	O
problems	O
?	O
how	O
does	O
a	O
system	O
of	O
neurons	O
work	O
?	O
how	O
can	O
we	O
understand	O
its	O
functionality	O
?	O
what	O
are	O
diﬀerent	O
quantities	O
of	O
neurons	O
able	O
to	O
do	O
?	O
where	O
in	O
the	O
nervous	B
system	I
does	O
information	O
processing	O
occur	O
?	O
a	O
short	O
biological	O
overview	O
of	O
the	O
complexity	O
of	O
simple	O
elements	O
of	O
neural	O
information	O
processing	O
followed	O
by	O
some	O
thoughts	O
about	O
their	O
simpliﬁcation	O
in	O
order	O
to	O
technically	O
adapt	O
them	O
.	O
before	O
we	O
begin	O
to	O
describe	O
the	O
technical	O
side	O
of	O
neural	O
networks	O
,	O
it	O
would	O
be	O
use-	O
ful	O
to	O
brieﬂy	O
discuss	O
the	O
biology	O
of	O
neu-	O
ral	O
networks	O
and	O
the	O
cognition	O
of	O
living	O
organisms	O
–	O
the	O
reader	O
may	O
skip	O
the	O
fol-	O
lowing	O
chapter	O
without	O
missing	O
any	O
tech-	O
nical	O
information	O
.	O
on	O
the	O
other	O
hand	O
i	O
recommend	O
to	O
read	O
the	O
said	O
excursus	O
if	O
you	O
want	O
to	O
learn	O
something	O
about	O
the	O
underlying	O
neurophysiology	O
and	O
see	O
that	O
our	O
small	O
approaches	O
,	O
the	O
technical	O
neural	O
networks	O
,	O
are	O
only	O
caricatures	O
of	O
nature	O
–	O
and	O
how	O
powerful	O
their	O
natural	O
counter-	O
parts	O
must	O
be	O
when	O
our	O
small	O
approaches	O
are	O
already	O
that	O
eﬀective	O
.	O
now	O
we	O
want	O
to	O
take	O
a	O
brief	O
look	O
at	O
the	O
nervous	B
system	I
of	O
vertebrates	O
:	O
we	O
will	O
start	O
with	O
a	O
very	O
rough	O
granularity	O
and	O
then	O
proceed	O
with	O
the	O
brain	B
and	O
up	O
to	O
the	O
neural	O
level	O
.	O
for	O
further	O
reading	O
i	O
want	O
to	O
recommend	O
the	O
books	O
[	O
cr00	O
,	O
ksj00	O
]	O
,	O
which	O
helped	O
me	O
a	O
lot	O
during	O
this	O
chapter	O
.	O
2.1	O
the	O
vertebrate	O
nervous	B
system	I
the	O
entire	O
information	O
processing	O
system	O
,	O
i.e	O
.	O
the	O
vertebrate	O
nervous	B
system	I
,	O
con-	O
sists	O
of	O
the	O
central	B
nervous	I
system	I
and	O
the	O
peripheral	B
nervous	I
system	I
,	O
which	O
is	O
only	O
a	O
ﬁrst	O
and	O
simple	O
subdivision	O
.	O
in	O
real-	O
ity	O
,	O
such	O
a	O
rigid	O
subdivision	O
does	O
not	O
make	O
sense	O
,	O
but	O
here	O
it	O
is	O
helpful	O
to	O
outline	O
the	O
information	O
processing	O
in	O
a	O
body	O
.	O
2.1.1	O
peripheral	O
and	O
central	B
nervous	I
system	I
the	O
peripheral	B
nervous	I
system	I
(	O
pns	O
)	O
comprises	O
the	O
nerves	O
that	O
are	O
situated	O
out-	O
side	O
of	O
the	O
brain	B
or	O
the	O
spinal	B
cord	I
.	O
these	O
nerves	O
form	O
a	O
branched	O
and	O
very	O
dense	O
net-	O
work	O
throughout	O
the	O
whole	O
body	O
.	O
the	O
pe-	O
13	O
chapter	O
2	O
biological	O
neural	O
networks	O
dkriesel.com	O
ripheral	O
nervous	B
system	I
includes	O
,	O
for	O
ex-	O
ample	O
,	O
the	O
spinal	O
nerves	O
which	O
pass	O
out	O
of	O
the	O
spinal	B
cord	I
(	O
two	O
within	O
the	O
level	O
of	O
each	O
vertebra	O
of	O
the	O
spine	O
)	O
and	O
supply	O
ex-	O
tremities	O
,	O
neck	O
and	O
trunk	O
,	O
but	O
also	O
the	O
cra-	O
nial	O
nerves	O
directly	O
leading	O
to	O
the	O
brain	B
.	O
the	O
central	B
nervous	I
system	I
(	O
cns	O
)	O
,	O
however	O
,	O
is	O
the	O
``	O
main-frame	O
''	O
within	O
the	O
vertebrate	O
.	O
it	O
is	O
the	O
place	O
where	O
infor-	O
mation	O
received	O
by	O
the	O
sense	O
organs	O
are	O
stored	O
and	O
managed	O
.	O
furthermore	O
,	O
it	O
con-	O
trols	O
the	O
inner	O
processes	O
in	O
the	O
body	O
and	O
,	O
last	O
but	O
not	O
least	O
,	O
coordinates	O
the	O
mo-	O
tor	O
functions	O
of	O
the	O
organism	O
.	O
the	O
ver-	O
tebrate	O
central	B
nervous	I
system	I
consists	O
of	O
the	O
brain	B
and	O
the	O
spinal	B
cord	I
(	O
fig	O
.	O
2.1	O
)	O
.	O
however	O
,	O
we	O
want	O
to	O
focus	O
on	O
the	O
brain	B
,	O
which	O
can	O
-	O
for	O
the	O
purpose	O
of	O
simpliﬁca-	O
tion	O
-	O
be	O
divided	O
into	O
four	O
areas	O
(	O
fig	O
.	O
2.2	O
on	O
the	O
next	O
page	O
)	O
to	O
be	O
discussed	O
here	O
.	O
2.1.2	O
the	O
cerebrum	B
is	O
responsible	O
for	O
abstract	O
thinking	O
processes	O
.	O
the	O
cerebrum	B
(	O
telencephalon	B
)	O
is	O
one	O
of	O
the	O
areas	O
of	O
the	O
brain	B
that	O
changed	O
most	O
during	O
evolution	O
.	O
along	O
an	O
axis	O
,	O
running	O
from	O
the	O
lateral	O
face	O
to	O
the	O
back	O
of	O
the	O
head	O
,	O
this	O
area	O
is	O
divided	O
into	O
two	O
hemi-	O
spheres	O
,	O
which	O
are	O
organized	O
in	O
a	O
folded	O
structure	O
.	O
these	O
cerebral	O
hemispheres	O
are	O
connected	O
by	O
one	O
strong	O
nerve	O
cord	O
(	O
``	O
bar	B
''	O
)	O
and	O
several	O
small	O
ones	O
.	O
a	O
large	O
number	O
of	O
neurons	O
are	O
located	O
in	O
the	O
cere-	O
bral	O
cortex	O
(	O
cortex	O
)	O
which	O
is	O
approx	O
.	O
2-	O
4	O
cm	O
thick	O
and	O
divided	O
into	O
diﬀerent	O
cor-	O
tical	O
ﬁelds	O
,	O
each	O
having	O
a	O
speciﬁc	O
task	O
to	O
figure	O
2.1	O
:	O
illustration	O
of	O
the	O
central	B
nervous	I
system	I
with	O
spinal	B
cord	I
and	O
brain	B
.	O
14	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
2.1	O
the	O
vertebrate	O
nervous	B
system	I
and	O
errors	O
are	O
continually	O
corrected	O
.	O
for	O
this	O
purpose	O
,	O
the	O
cerebellum	B
has	O
direct	O
sensory	O
information	O
about	O
muscle	O
lengths	O
as	O
well	O
as	O
acoustic	O
and	O
visual	O
informa-	O
tion	O
.	O
furthermore	O
,	O
it	O
also	O
receives	O
mes-	O
sages	O
about	O
more	O
abstract	O
motor	O
signals	O
coming	O
from	O
the	O
cerebrum	B
.	O
in	O
the	O
human	O
brain	B
the	O
cerebellum	B
is	O
con-	O
siderably	O
smaller	O
than	O
the	O
cerebrum	B
,	O
but	O
this	O
is	O
rather	O
an	O
exception	O
.	O
in	O
many	O
ver-	O
tebrates	O
this	O
ratio	O
is	O
less	O
pronounced	O
.	O
if	O
we	O
take	O
a	O
look	O
at	O
vertebrate	O
evolution	O
,	O
we	O
will	O
notice	O
that	O
the	O
cerebellum	B
is	O
not	O
``	O
too	O
small	O
''	O
but	O
the	O
cerebum	O
is	O
``	O
too	O
large	O
''	O
(	O
at	O
least	O
,	O
it	O
is	O
the	O
most	O
highly	O
developed	O
struc-	O
ture	O
in	O
the	O
vertebrate	O
brain	B
)	O
.	O
the	O
two	O
re-	O
maining	O
brain	B
areas	O
should	O
also	O
be	O
brieﬂy	O
discussed	O
:	O
the	O
diencephalon	B
and	O
the	O
brain-	O
stem	O
.	O
2.1.4	O
the	O
diencephalon	B
controls	O
fundamental	O
physiological	O
processes	O
the	O
interbrain	B
(	O
diencephalon	B
)	O
includes	O
parts	O
of	O
which	O
only	O
the	O
thalamus	B
will	O
be	O
brieﬂy	O
discussed	O
:	O
this	O
part	O
of	O
the	O
di-	O
encephalon	O
mediates	O
between	O
sensory	O
and	O
motor	O
signals	O
and	O
the	O
cerebrum	B
.	O
particu-	O
larly	O
,	O
the	O
thalamus	B
decides	O
which	O
part	O
of	O
the	O
information	O
is	O
transferred	O
to	O
the	O
cere-	O
brum	O
,	O
so	O
that	O
especially	O
less	O
important	O
sensory	O
perceptions	O
can	O
be	O
suppressed	O
at	O
short	O
notice	O
to	O
avoid	O
overloads	O
.	O
another	O
part	O
of	O
the	O
diencephalon	B
is	O
the	O
hypotha-	O
lamus	O
,	O
which	O
controls	O
a	O
number	O
of	O
pro-	O
cesses	O
within	O
the	O
body	O
.	O
the	O
diencephalon	B
thalamus	O
ﬁlters	O
incoming	O
data	O
figure	O
2.2	O
:	O
illustration	O
of	O
the	O
brain	B
.	O
the	O
col-	O
ored	O
areas	O
of	O
the	O
brain	B
are	O
discussed	O
in	O
the	O
text	O
.	O
the	O
more	O
we	O
turn	O
from	O
abstract	O
information	O
pro-	O
cessing	O
to	O
direct	O
reﬂexive	O
processing	O
,	O
the	O
darker	O
the	O
areas	O
of	O
the	O
brain	B
are	O
colored	O
.	O
fulﬁll	O
.	O
primary	O
cortical	O
ﬁelds	O
are	O
re-	O
sponsible	O
for	O
processing	O
qualitative	O
infor-	O
mation	O
,	O
such	O
as	O
the	O
management	O
of	O
diﬀer-	O
the	O
visual	B
cortex	I
ent	O
perceptions	O
(	O
e.g	O
.	O
is	O
responsible	O
for	O
the	O
management	O
of	O
vi-	O
sion	O
)	O
.	O
association	O
cortical	O
ﬁelds	O
,	O
how-	O
ever	O
,	O
perform	O
more	O
abstract	O
association	O
and	O
thinking	O
processes	O
;	O
they	O
also	O
contain	O
our	O
memory	O
.	O
2.1.3	O
the	O
cerebellum	B
controls	O
and	O
coordinates	O
motor	O
functions	O
the	O
cerebellum	B
is	O
located	O
below	O
the	O
cere-	O
brum	O
,	O
therefore	O
it	O
is	O
closer	O
to	O
the	O
spinal	B
cord	I
.	O
accordingly	O
,	O
it	O
serves	O
less	O
abstract	O
functions	O
with	O
higher	O
priority	O
:	O
here	O
,	O
large	O
parts	O
of	O
motor	O
coordination	O
are	O
performed	O
,	O
i.e.	O
,	O
balance	O
and	O
movements	O
are	O
controlled	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
15	O
chapter	O
2	O
biological	O
neural	O
networks	O
dkriesel.com	O
is	O
also	O
heavily	O
involved	O
in	O
the	O
human	O
cir-	O
cadian	O
rhythm	O
(	O
``	O
internal	O
clock	O
''	O
)	O
and	O
the	O
sensation	O
of	O
pain	O
.	O
2.1.5	O
the	O
brainstem	B
connects	O
the	O
brain	B
with	O
the	O
spinal	B
cord	I
and	O
controls	O
reﬂexes	O
.	O
in	O
comparison	O
with	O
the	O
diencephalon	B
the	O
brainstem	B
or	O
the	O
(	O
truncus	B
cerebri	I
)	O
re-	O
spectively	O
is	O
phylogenetically	O
much	O
older	O
.	O
roughly	O
speaking	O
,	O
it	O
is	O
the	O
``	O
extended	O
spinal	B
cord	I
''	O
and	O
thus	O
the	O
connection	B
be-	O
tween	O
brain	B
and	O
spinal	B
cord	I
.	O
the	O
brain-	O
stem	O
can	O
also	O
be	O
divided	O
into	O
diﬀerent	O
ar-	O
eas	O
,	O
some	O
of	O
which	O
will	O
be	O
exemplarily	O
in-	O
troduced	O
in	O
this	O
chapter	O
.	O
the	O
functions	O
will	O
be	O
discussed	O
from	O
abstract	O
functions	O
towards	O
more	O
fundamental	O
ones	O
.	O
one	O
im-	O
portant	O
component	O
is	O
the	O
pons	B
(	O
=bridge	O
)	O
,	O
a	O
kind	O
of	O
transit	O
station	O
for	O
many	O
nerve	O
sig-	O
nals	O
from	O
brain	B
to	O
body	O
and	O
vice	O
versa	O
.	O
if	O
the	O
pons	B
is	O
damaged	O
(	O
e.g	O
.	O
by	O
a	O
cere-	O
bral	O
infarct	O
)	O
,	O
then	O
the	O
result	O
could	O
be	O
the	O
locked-in	B
syndrome	I
–	O
a	O
condition	O
in	O
which	O
a	O
patient	O
is	O
``	O
walled-in	O
''	O
within	O
his	O
own	O
body	O
.	O
he	O
is	O
conscious	O
and	O
aware	O
with	O
no	O
loss	O
of	O
cognitive	O
function	B
,	O
but	O
can-	O
not	O
move	O
or	O
communicate	O
by	O
any	O
means	O
.	O
only	O
his	O
senses	O
of	O
sight	O
,	O
hearing	O
,	O
smell	O
and	O
taste	O
are	O
generally	O
working	O
perfectly	O
nor-	O
mal	O
.	O
locked-in	O
patients	O
may	O
often	O
be	O
able	O
to	O
communicate	O
with	O
others	O
by	O
blinking	O
or	O
moving	O
their	O
eyes	O
.	O
furthermore	O
,	O
the	O
brainstem	B
is	O
responsible	O
for	O
many	O
fundamental	O
reﬂexes	O
,	O
such	O
as	O
the	O
blinking	O
reﬂex	O
or	O
coughing	O
.	O
all	O
parts	O
of	O
the	O
nervous	B
system	I
have	O
one	O
thing	O
in	O
common	O
:	O
information	O
processing	O
.	O
this	O
is	O
accomplished	O
by	O
huge	O
accumula-	O
tions	O
of	O
billions	O
of	O
very	O
similar	O
cells	O
,	O
whose	O
structure	O
is	O
very	O
simple	O
but	O
which	O
com-	O
municate	O
continuously	O
.	O
large	O
groups	O
of	O
these	O
cells	O
send	O
coordinated	O
signals	O
and	O
thus	O
reach	O
the	O
enormous	O
information	O
pro-	O
cessing	O
capacity	O
we	O
are	O
familiar	O
with	O
from	O
our	O
brain	B
.	O
we	O
will	O
now	O
leave	O
the	O
level	O
of	O
brain	B
areas	O
and	O
continue	O
with	O
the	O
cellular	O
level	O
of	O
the	O
body	O
-	O
the	O
level	O
of	O
neurons	O
.	O
2.2	O
neurons	O
are	O
information	O
processing	O
cells	O
before	O
specifying	O
the	O
functions	O
and	O
pro-	O
cesses	O
within	O
a	O
neuron	O
,	O
we	O
will	O
give	O
a	O
rough	O
description	O
of	O
neuron	O
functions	O
:	O
a	O
neuron	O
is	O
nothing	O
more	O
than	O
a	O
switch	O
with	O
information	O
input	O
and	O
output	O
.	O
the	O
switch	O
will	O
be	O
activated	O
if	O
there	O
are	O
enough	O
stim-	O
uli	O
of	O
other	O
neurons	O
hitting	O
the	O
informa-	O
tion	O
input	O
.	O
then	O
,	O
at	O
the	O
information	O
out-	O
put	O
,	O
a	O
pulse	O
is	O
sent	O
to	O
,	O
for	O
example	O
,	O
other	O
neurons	O
.	O
2.2.1	O
components	O
of	O
a	O
neuron	O
now	O
we	O
want	O
to	O
take	O
a	O
look	O
at	O
the	O
com-	O
ponents	O
of	O
a	O
neuron	O
(	O
fig	O
.	O
2.3	O
on	O
the	O
fac-	O
ing	O
page	O
)	O
.	O
in	O
doing	O
so	O
,	O
we	O
will	O
follow	O
the	O
way	O
the	O
electrical	O
information	O
takes	O
within	O
the	O
neuron	O
.	O
the	O
dendrites	O
of	O
a	O
neuron	O
receive	O
the	O
information	O
by	O
special	O
connec-	O
tions	O
,	O
the	O
synapses	B
.	O
16	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
2.2	O
the	O
neuron	O
figure	O
2.3	O
:	O
illustration	O
of	O
a	O
biological	O
neuron	O
with	O
the	O
components	O
discussed	O
in	O
this	O
text	O
.	O
2.2.1.1	O
synapses	B
weight	O
the	O
individual	O
parts	O
of	O
information	O
incoming	O
signals	O
from	O
other	O
neurons	O
or	O
cells	O
are	O
transferred	O
to	O
a	O
neuron	O
by	O
special	O
connections	O
,	O
the	O
synapses	B
.	O
such	O
connec-	O
tions	O
can	O
usually	O
be	O
found	O
at	O
the	O
dendrites	O
of	O
a	O
neuron	O
,	O
sometimes	O
also	O
directly	O
at	O
the	O
soma	B
.	O
we	O
distinguish	O
between	O
electrical	O
and	O
chemical	O
synapses	O
.	O
the	O
electrical	B
synapse	I
is	O
the	O
simpler	O
variant	O
.	O
an	O
electrical	O
signal	O
received	O
by	O
the	O
synapse	B
,	O
i.e	O
.	O
coming	O
from	O
the	O
presy-	O
naptic	O
side	O
,	O
is	O
directly	O
transferred	O
to	O
the	O
postsynaptic	O
nucleus	O
of	O
the	O
cell	O
.	O
thus	O
,	O
there	O
is	O
a	O
direct	O
,	O
strong	O
,	O
unadjustable	O
connection	B
between	O
the	O
signal	O
transmitter	O
and	O
the	O
signal	O
receiver	O
,	O
which	O
is	O
,	O
for	O
exam-	O
ple	O
,	O
relevant	O
to	O
shortening	O
reactions	O
that	O
must	O
be	O
``	O
hard	O
coded	O
''	O
within	O
a	O
living	O
or-	O
ganism	O
.	O
the	O
chemical	B
synapse	I
is	O
the	O
more	O
dis-	O
tinctive	O
variant	O
.	O
here	O
,	O
the	O
electrical	O
cou-	O
pling	O
of	O
source	O
and	O
target	B
does	O
not	O
take	O
place	O
,	O
the	O
coupling	O
is	O
interrupted	O
by	O
the	O
synaptic	B
cleft	I
.	O
this	O
cleft	O
electrically	O
sep-	O
arates	O
the	O
presynaptic	O
side	O
from	O
the	O
post-	O
synaptic	O
one	O
.	O
you	O
might	O
think	O
that	O
,	O
never-	O
theless	O
,	O
the	O
information	O
has	O
to	O
ﬂow	O
,	O
so	O
we	O
will	O
discuss	O
how	O
this	O
happens	O
:	O
it	O
is	O
not	O
an	O
electrical	O
,	O
but	O
a	O
chemical	O
process	O
.	O
on	O
the	O
presynaptic	O
side	O
of	O
the	O
synaptic	B
cleft	I
the	O
electrical	O
signal	O
is	O
converted	O
into	O
a	O
chemi-	O
cal	O
signal	O
,	O
a	O
process	O
induced	O
by	O
chemical	O
cues	O
released	O
there	O
(	O
the	O
so-called	O
neuro-	O
transmitters	O
)	O
.	O
these	O
neurotransmitters	B
cross	O
the	O
synaptic	B
cleft	I
and	O
transfer	O
the	O
information	O
into	O
the	O
nucleus	O
of	O
the	O
cell	O
(	O
this	O
is	O
a	O
very	O
simple	O
explanation	O
,	O
but	O
later	O
on	O
we	O
will	O
see	O
how	O
this	O
exactly	O
works	O
)	O
,	O
where	O
it	O
is	O
reconverted	O
into	O
electrical	O
in-	O
formation	O
.	O
the	O
neurotransmitters	B
are	O
de-	O
graded	O
very	O
fast	O
,	O
so	O
that	O
it	O
is	O
possible	O
to	O
re-	O
electrical	B
synapse	I
:	O
simple	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
17	O
cemical	O
synapse	B
is	O
more	O
complex	O
but	O
also	O
more	O
powerful	O
chapter	O
2	O
biological	O
neural	O
networks	O
dkriesel.com	O
lease	O
very	O
precise	O
information	O
pulses	O
here	O
,	O
too	O
.	O
in	O
spite	O
of	O
the	O
more	O
complex	O
function-	O
ing	O
,	O
the	O
chemical	B
synapse	I
has	O
-	O
compared	O
with	O
the	O
electrical	B
synapse	I
-	O
utmost	O
advan-	O
tages	O
:	O
one-way	O
connection	B
:	O
a	O
chemical	B
synapse	I
is	O
a	O
one-way	O
connection	B
.	O
due	O
to	O
the	O
fact	O
that	O
there	O
is	O
no	O
direct	O
electrical	O
connection	B
between	O
the	O
pre-	O
and	O
postsynaptic	O
area	O
,	O
electrical	O
pulses	O
area	O
can	O
not	O
ﬂash	O
over	O
to	O
the	O
presynaptic	O
area	O
.	O
in	O
the	O
postsynaptic	O
adjustability	O
:	O
there	O
is	O
a	O
large	O
number	O
of	O
diﬀerent	O
neurotransmitters	B
that	O
can	O
also	O
be	O
released	O
in	O
various	O
quantities	O
in	O
a	O
synaptic	B
cleft	I
.	O
there	O
are	O
neuro-	O
transmitters	O
that	O
stimulate	O
the	O
post-	O
synaptic	O
cell	O
nucleus	O
,	O
and	O
others	O
that	O
slow	O
down	O
such	O
stimulation	O
.	O
some	O
synapses	B
transfer	O
a	O
strongly	O
stimulat-	O
ing	O
signal	O
,	O
some	O
only	O
weakly	O
stimu-	O
lating	O
ones	O
.	O
the	O
adjustability	O
varies	O
a	O
lot	O
,	O
and	O
one	O
of	O
the	O
central	O
points	O
in	O
the	O
examination	O
of	O
the	O
learning	B
ability	O
of	O
the	O
brain	B
is	O
,	O
that	O
here	O
the	O
synapses	B
are	O
variable	O
,	O
too	O
.	O
that	O
is	O
,	O
over	O
time	O
they	O
can	O
form	O
a	O
stronger	O
or	O
weaker	O
connection	B
.	O
2.2.1.2	O
dendrites	O
collect	O
all	O
parts	O
of	O
information	O
dendrites	O
branch	O
like	O
trees	O
from	O
the	O
cell	O
nucleus	O
of	O
the	O
neuron	O
(	O
which	O
is	O
called	O
soma	B
)	O
and	O
receive	O
electrical	O
signals	O
from	O
many	O
diﬀerent	O
sources	O
,	O
which	O
are	O
then	O
transferred	O
into	O
the	O
nucleus	O
of	O
the	O
cell	O
.	O
the	O
amount	O
of	O
branching	O
dendrites	O
is	O
also	O
called	O
dendrite	B
tree	O
.	O
2.2.1.3	O
in	O
the	O
soma	B
the	O
weighted	O
information	O
is	O
accumulated	O
after	O
the	O
cell	O
nucleus	O
(	O
soma	B
)	O
has	O
re-	O
ceived	O
a	O
plenty	O
of	O
activating	O
(	O
=stimulat-	O
ing	O
)	O
and	O
inhibiting	O
(	O
=diminishing	O
)	O
signals	O
by	O
synapses	B
or	O
dendrites	O
,	O
the	O
soma	B
accu-	O
mulates	O
these	O
signals	O
.	O
as	O
soon	O
as	O
the	O
ac-	O
cumulated	O
signal	O
exceeds	O
a	O
certain	O
value	O
(	O
called	O
threshold	B
value	I
)	O
,	O
the	O
cell	O
nucleus	O
of	O
the	O
neuron	O
activates	O
an	O
electrical	O
pulse	O
which	O
then	O
is	O
transmitted	O
to	O
the	O
neurons	O
connected	O
to	O
the	O
current	O
one	O
.	O
2.2.1.4	O
the	O
axon	B
transfers	O
outgoing	O
pulses	O
the	O
pulse	O
is	O
transferred	O
to	O
other	O
neurons	O
by	O
means	O
of	O
the	O
axon	B
.	O
the	O
axon	B
is	O
a	O
long	O
,	O
slender	O
extension	O
of	O
the	O
soma	B
.	O
in	O
an	O
extreme	O
case	O
,	O
an	O
axon	B
can	O
stretch	O
up	O
to	O
one	O
meter	O
(	O
e.g	O
.	O
within	O
the	O
spinal	B
cord	I
)	O
.	O
the	O
axon	B
is	O
electrically	O
isolated	O
in	O
order	O
to	O
achieve	O
a	O
better	O
conduction	O
of	O
the	O
elec-	O
trical	O
signal	O
(	O
we	O
will	O
return	B
to	O
this	O
point	O
later	O
on	O
)	O
and	O
it	O
leads	O
to	O
dendrites	O
,	O
which	O
transfer	O
the	O
information	O
to	O
,	O
for	O
example	O
,	O
other	O
neurons	O
.	O
so	O
now	O
we	O
are	O
back	O
at	O
the	O
beginning	O
of	O
our	O
description	O
of	O
the	O
neuron	O
elements	O
.	O
an	O
axon	B
can	O
,	O
however	O
,	O
transfer	O
information	O
to	O
other	O
kinds	O
of	O
cells	O
in	O
order	O
to	O
control	O
them	O
.	O
18	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
2.2	O
the	O
neuron	O
2.2.2	O
electrochemical	O
processes	O
in	O
the	O
neuron	O
and	O
its	O
components	O
after	O
having	O
pursued	O
the	O
path	O
of	O
an	O
elec-	O
trical	O
signal	O
from	O
the	O
dendrites	O
via	O
the	O
synapses	B
to	O
the	O
nucleus	O
of	O
the	O
cell	O
and	O
from	O
there	O
via	O
the	O
axon	B
into	O
other	O
den-	O
drites	O
,	O
we	O
now	O
want	O
to	O
take	O
a	O
small	O
step	O
from	O
biology	O
towards	O
technology	O
.	O
in	O
doing	O
so	O
,	O
a	O
simpliﬁed	O
introduction	O
of	O
the	O
electro-	O
chemical	O
information	O
processing	O
should	O
be	O
provided	O
.	O
2.2.2.1	O
neurons	O
maintain	O
electrical	O
membrane	O
potential	O
one	O
fundamental	O
aspect	O
is	O
the	O
fact	O
that	O
compared	O
to	O
their	O
environment	B
the	O
neu-	O
rons	O
show	O
a	O
diﬀerence	O
in	O
electrical	O
charge	O
,	O
a	O
potential	O
.	O
in	O
the	O
membrane	O
(	O
=enve-	O
lope	O
)	O
of	O
the	O
neuron	O
the	O
charge	O
is	O
diﬀerent	O
from	O
the	O
charge	O
on	O
the	O
outside	O
.	O
this	O
dif-	O
ference	O
in	O
charge	O
is	O
a	O
central	O
concept	O
that	O
is	O
important	O
to	O
understand	O
the	O
processes	O
within	O
the	O
neuron	O
.	O
the	O
diﬀerence	O
is	O
called	O
membrane	O
potential	O
.	O
the	O
membrane	O
potential	O
,	O
i.e.	O
,	O
the	O
diﬀerence	O
in	O
charge	O
,	O
is	O
created	O
by	O
several	O
kinds	O
of	O
charged	O
atoms	O
(	O
ions	O
)	O
,	O
whose	O
concentration	O
varies	O
within	O
and	O
outside	O
of	O
the	O
neuron	O
.	O
if	O
we	O
penetrate	O
the	O
membrane	O
from	O
the	O
inside	O
outwards	O
,	O
we	O
will	O
ﬁnd	O
certain	O
kinds	O
of	O
ions	O
more	O
of-	O
ten	O
or	O
less	O
often	O
than	O
on	O
the	O
inside	O
.	O
this	O
descent	O
or	O
ascent	O
of	O
concentration	O
is	O
called	O
a	O
concentration	B
gradient	I
.	O
let	O
us	O
ﬁrst	O
take	O
a	O
look	O
at	O
the	O
membrane	O
potential	O
in	O
the	O
resting	O
state	B
of	O
the	O
neu-	O
ron	O
,	O
i.e.	O
,	O
we	O
assume	O
that	O
no	O
electrical	O
sig-	O
nals	O
are	O
received	O
from	O
the	O
outside	O
.	O
in	O
this	O
case	O
,	O
the	O
membrane	O
potential	O
is	O
−70	O
mv	O
.	O
since	O
we	O
have	O
learned	O
that	O
this	O
potential	O
depends	O
on	O
the	O
concentration	O
gradients	O
of	O
various	O
ions	O
,	O
there	O
is	O
of	O
course	O
the	O
central	O
question	O
of	O
how	O
to	O
maintain	O
these	O
concen-	O
tration	O
gradients	O
:	O
normally	O
,	O
diﬀusion	O
pre-	O
dominates	O
and	O
therefore	O
each	O
ion	B
is	O
eager	O
to	O
decrease	O
concentration	O
gradients	O
and	O
to	O
spread	O
out	O
evenly	O
.	O
if	O
this	O
happens	O
,	O
the	O
membrane	O
potential	O
will	O
move	O
towards	O
0	O
mv	O
,	O
so	O
ﬁnally	O
there	O
would	O
be	O
no	O
mem-	O
brane	O
potential	O
anymore	O
.	O
thus	O
,	O
the	O
neu-	O
ron	O
actively	O
maintains	O
its	O
membrane	O
po-	O
tential	O
to	O
be	O
able	O
to	O
process	O
information	O
.	O
how	O
does	O
this	O
work	O
?	O
the	O
secret	O
is	O
the	O
membrane	O
itself	O
,	O
which	O
is	O
permeable	O
to	O
some	O
ions	O
,	O
but	O
not	O
for	O
others	O
.	O
to	O
maintain	O
the	O
potential	O
,	O
various	O
mecha-	O
nisms	O
are	O
in	O
progress	O
at	O
the	O
same	O
time	O
:	O
concentration	B
gradient	I
:	O
as	O
if	O
the	O
described	O
above	O
the	O
ions	O
try	O
to	O
be	O
as	O
uniformly	O
distributed	O
as	O
possible	O
.	O
the	O
concentration	O
of	O
an	O
ion	B
is	O
higher	O
on	O
the	O
inside	O
of	O
the	O
neuron	O
than	O
on	O
it	O
will	O
try	O
to	O
diﬀuse	O
the	O
outside	O
,	O
and	O
vice	O
versa	O
.	O
to	O
outside	O
charged	O
ion	B
k+	O
the	O
positively	O
(	O
potassium	O
)	O
occurs	O
very	O
frequently	O
within	O
the	O
neuron	O
but	O
less	O
frequently	O
outside	O
of	O
the	O
neuron	O
,	O
and	O
therefore	O
it	O
slowly	O
diﬀuses	O
out	O
through	O
the	O
neuron	O
’	O
s	O
membrane	O
.	O
but	O
another	O
group	O
of	O
negative	O
ions	O
,	O
collectively	O
called	O
a−	O
,	O
remains	O
within	O
the	O
neuron	O
since	O
the	O
membrane	O
is	O
not	O
permeable	O
to	O
them	O
.	O
thus	O
,	O
the	O
inside	O
of	O
the	O
neuron	O
becomes	O
negatively	O
charged	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
19	O
chapter	O
2	O
biological	O
neural	O
networks	O
dkriesel.com	O
negative	O
a	O
ions	O
remain	O
,	O
positive	O
k	O
ions	O
disappear	O
,	O
and	O
so	O
the	O
inside	O
of	O
the	O
cell	O
becomes	O
more	O
negative	O
.	O
the	O
result	O
is	O
another	O
gradient	B
.	O
electrical	O
gradient	O
:	O
the	O
electrical	O
gradi-	O
ent	O
acts	O
contrary	O
to	O
the	O
concentration	B
gradient	I
.	O
the	O
intracellular	O
charge	O
is	O
now	O
very	O
strong	O
,	O
therefore	O
it	O
attracts	O
positive	O
ions	O
:	O
k+	O
wants	O
to	O
get	O
back	O
into	O
the	O
cell	O
.	O
if	O
these	O
two	O
gradients	O
were	O
now	O
left	O
alone	O
,	O
they	O
would	O
eventually	O
balance	O
out	O
,	O
reach	O
a	O
steady	O
state	B
,	O
and	O
a	O
membrane	O
poten-	O
tial	O
of	O
−85	O
mv	O
would	O
develop	O
.	O
but	O
we	O
want	O
to	O
achieve	O
a	O
resting	O
membrane	O
po-	O
tential	O
of	O
−70	O
mv	O
,	O
thus	O
there	O
seem	O
to	O
ex-	O
ist	O
some	O
disturbances	O
which	O
prevent	O
this	O
.	O
furthermore	O
,	O
there	O
is	O
another	O
important	O
ion	B
,	O
na+	O
(	O
sodium	O
)	O
,	O
for	O
which	O
the	O
mem-	O
brane	O
is	O
not	O
very	O
permeable	O
but	O
which	O
,	O
however	O
,	O
slowly	O
pours	O
through	O
the	O
mem-	O
brane	O
into	O
the	O
cell	O
.	O
as	O
a	O
result	O
,	O
the	O
sodium	O
is	O
driven	O
into	O
the	O
cell	O
all	O
the	O
more	O
:	O
on	O
the	O
one	O
hand	O
,	O
there	O
is	O
less	O
sodium	O
within	O
the	O
neuron	O
than	O
outside	O
the	O
neuron	O
.	O
on	O
the	O
other	O
hand	O
,	O
sodium	O
is	O
positively	O
charged	O
but	O
the	O
interior	O
of	O
the	O
cell	O
has	O
negative	O
charge	O
,	O
which	O
is	O
a	O
second	O
reason	O
for	O
the	O
sodium	O
wanting	O
to	O
get	O
into	O
the	O
cell	O
.	O
due	O
to	O
the	O
low	O
diﬀusion	O
of	O
sodium	O
into	O
the	O
cell	O
the	O
intracellular	O
sodium	O
concentration	O
increases	O
.	O
but	O
at	O
the	O
same	O
time	O
the	O
inside	O
of	O
the	O
cell	O
becomes	O
less	O
negative	O
,	O
so	O
that	O
k+	O
pours	O
in	O
more	O
slowly	O
(	O
we	O
can	O
see	O
that	O
this	O
is	O
a	O
complex	O
mechanism	O
where	O
every-	O
thing	O
is	O
inﬂuenced	O
by	O
everything	O
)	O
.	O
the	O
sodium	O
shifts	O
the	O
intracellular	O
equilibrium	O
from	O
negative	O
to	O
less	O
negative	O
,	O
compared	O
with	O
its	O
environment	B
.	O
but	O
even	O
with	O
these	O
two	O
ions	O
a	O
standstill	O
with	O
all	O
gradients	O
be-	O
ing	O
balanced	O
out	O
could	O
still	O
be	O
achieved	O
.	O
now	O
the	O
last	O
piece	O
of	O
the	O
puzzle	O
gets	O
into	O
the	O
game	O
:	O
a	O
``	O
pump	O
''	O
(	O
or	O
rather	O
,	O
the	O
protein	O
atp	O
)	O
actively	O
transports	O
ions	O
against	O
the	O
direction	O
they	O
actually	O
want	O
to	O
take	O
!	O
sodium	O
is	O
actively	O
pumped	O
out	O
of	O
the	O
cell	O
,	O
although	O
it	O
tries	O
to	O
get	O
into	O
the	O
cell	O
along	O
the	O
concentration	B
gradient	I
and	O
the	O
electrical	O
gradient	O
.	O
potassium	O
,	O
however	O
,	O
diﬀuses	O
strongly	O
out	O
of	O
the	O
cell	O
,	O
but	O
is	O
actively	O
pumped	O
back	O
into	O
it	O
.	O
for	O
this	O
reason	O
the	O
pump	O
is	O
also	O
called	O
sodium-potassium	B
pump	I
.	O
the	O
pump	O
maintains	O
the	O
concentration	B
gradient	I
for	O
the	O
sodium	O
as	O
well	O
as	O
for	O
the	O
potassium	O
,	O
so	O
that	O
some	O
sort	O
of	O
steady	O
state	B
equilib-	O
rium	O
is	O
created	O
and	O
ﬁnally	O
the	O
resting	O
po-	O
tential	O
is	O
−70	O
mv	O
as	O
observed	O
.	O
all	O
in	O
all	O
the	O
membrane	O
potential	O
is	O
maintained	O
by	O
the	O
fact	O
that	O
the	O
membrane	O
is	O
imperme-	O
able	O
to	O
some	O
ions	O
and	O
other	O
ions	O
are	O
ac-	O
tively	O
pumped	O
against	O
the	O
concentration	O
and	O
electrical	O
gradients	O
.	O
now	O
that	O
we	O
know	O
that	O
each	O
neuron	O
has	O
a	O
membrane	O
potential	O
we	O
want	O
to	O
observe	O
how	O
a	O
neu-	O
ron	O
receives	O
and	O
transmits	O
signals	O
.	O
2.2.2.2	O
the	O
neuron	O
is	O
activated	O
by	O
changes	O
in	O
the	O
membrane	O
potential	O
above	O
we	O
have	O
learned	O
that	O
sodium	O
and	O
potassium	O
can	O
diﬀuse	O
through	O
the	O
mem-	O
brane	O
-	O
sodium	O
slowly	O
,	O
potassium	O
faster	O
.	O
20	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
2.2	O
the	O
neuron	O
they	O
move	O
through	O
channels	O
within	O
the	O
membrane	O
,	O
the	O
sodium	O
and	O
potassium	O
channels	O
.	O
in	O
addition	O
to	O
these	O
per-	O
manently	O
open	O
channels	O
responsible	O
for	O
diﬀusion	O
and	O
balanced	O
by	O
the	O
sodium-	O
potassium	O
pump	O
,	O
there	O
also	O
exist	O
channels	O
that	O
are	O
not	O
always	O
open	O
but	O
which	O
only	O
response	O
``	O
if	O
required	O
''	O
.	O
since	O
the	O
opening	O
of	O
these	O
channels	O
changes	O
the	O
concentra-	O
tion	O
of	O
ions	O
within	O
and	O
outside	O
of	O
the	O
mem-	O
brane	O
,	O
it	O
also	O
changes	O
the	O
membrane	O
po-	O
tential	O
.	O
these	O
controllable	O
channels	O
are	O
opened	O
as	O
soon	O
as	O
the	O
accumulated	O
received	O
stimulus	B
exceeds	O
a	O
certain	O
threshold	O
.	O
for	O
example	O
,	O
stimuli	O
can	O
be	O
received	O
from	O
other	O
neurons	O
or	O
have	O
other	O
causes	O
.	O
there	O
exist	O
,	O
for	O
ex-	O
ample	O
,	O
specialized	O
forms	O
of	O
neurons	O
,	O
the	O
sensory	O
cells	O
,	O
for	O
which	O
a	O
light	O
incidence	O
could	O
be	O
such	O
a	O
stimulus	B
.	O
if	O
the	O
incom-	O
ing	O
amount	O
of	O
light	O
exceeds	O
the	O
threshold	O
,	O
controllable	O
channels	O
are	O
opened	O
.	O
the	O
said	O
threshold	O
(	O
the	O
threshold	O
poten-	O
tial	O
)	O
lies	O
at	O
about	O
−55	O
mv	O
.	O
as	O
soon	O
as	O
the	O
received	O
stimuli	O
reach	O
this	O
value	O
,	O
the	O
neu-	O
ron	O
is	O
activated	O
and	O
an	O
electrical	O
signal	O
,	O
an	O
action	B
potential	I
,	O
is	O
initiated	O
.	O
then	O
this	O
signal	O
is	O
transmitted	O
to	O
the	O
cells	O
con-	O
nected	O
to	O
the	O
observed	O
neuron	O
,	O
i.e	O
.	O
the	O
cells	O
``	O
listen	O
''	O
to	O
the	O
neuron	O
.	O
now	O
we	O
want	O
to	O
take	O
a	O
closer	O
look	O
at	O
the	O
diﬀerent	O
stages	O
of	O
the	O
action	B
potential	I
(	O
fig	O
.	O
2.4	O
on	O
the	O
next	O
page	O
)	O
:	O
resting	O
state	B
:	O
only	O
permanently	O
open	O
sodium	O
and	O
potassium	O
channels	O
are	O
permeable	O
.	O
the	O
membrane	O
potential	O
is	O
at	O
−70	O
mv	O
and	O
actively	O
kept	O
there	O
by	O
the	O
neuron	O
.	O
the	O
stimulus	B
up	O
to	O
the	O
threshold	O
:	O
a	O
stimu-	O
lus	O
opens	O
channels	O
so	O
that	O
sodium	O
can	O
pour	O
in	O
.	O
the	O
intracellular	O
charge	O
becomes	O
more	O
positive	O
.	O
as	O
soon	O
as	O
the	O
membrane	O
potential	O
exceeds	O
the	O
threshold	O
of	O
−55	O
mv	O
,	O
the	O
action	O
po-	O
tential	O
is	O
initiated	O
by	O
the	O
opening	O
of	O
many	O
sodium	O
channels	O
.	O
depolarization	B
:	O
sodium	O
is	O
pouring	O
in	O
.	O
re-	O
member	O
:	O
sodium	O
wants	O
to	O
pour	O
into	O
the	O
cell	O
because	O
there	O
is	O
a	O
lower	O
in-	O
tracellular	O
than	O
extracellular	O
concen-	O
tration	O
of	O
sodium	O
.	O
additionally	O
,	O
the	O
cell	O
is	O
dominated	O
by	O
a	O
negative	O
en-	O
vironment	O
which	O
attracts	O
the	O
posi-	O
tive	O
sodium	O
ions	O
.	O
this	O
massive	O
in-	O
ﬂux	O
of	O
sodium	O
drastically	O
increases	O
the	O
membrane	O
potential	O
-	O
up	O
to	O
ap-	O
prox	O
.	O
+30	O
mv	O
-	O
which	O
is	O
the	O
electrical	O
pulse	O
,	O
i.e.	O
,	O
the	O
action	B
potential	I
.	O
repolarization	B
:	O
now	O
the	O
sodium	O
channels	O
are	O
closed	O
and	O
the	O
potassium	O
channels	O
are	O
opened	O
.	O
the	O
positively	O
charged	O
ions	O
want	O
to	O
leave	O
the	O
positive	O
inte-	O
rior	O
of	O
the	O
cell	O
.	O
additionally	O
,	O
the	O
intra-	O
cellular	O
concentration	O
is	O
much	O
higher	O
than	O
the	O
extracellular	O
one	O
,	O
which	O
in-	O
creases	O
the	O
eﬄux	O
of	O
ions	O
even	O
more	O
.	O
the	O
interior	O
of	O
the	O
cell	O
is	O
once	O
again	O
more	O
negatively	O
charged	O
than	O
the	O
ex-	O
terior	O
.	O
hyperpolarization	B
:	O
sodium	O
as	O
well	O
as	O
potassium	O
channels	O
are	O
closed	O
again	O
.	O
at	O
ﬁrst	O
the	O
membrane	O
potential	O
is	O
slightly	O
more	O
negative	O
than	O
the	O
rest-	O
ing	O
potential	O
.	O
this	O
is	O
due	O
to	O
the	O
fact	O
that	O
the	O
potassium	O
channels	O
close	O
more	O
slowly	O
.	O
as	O
a	O
result	O
,	O
(	O
positively	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
21	O
chapter	O
2	O
biological	O
neural	O
networks	O
dkriesel.com	O
figure	O
2.4	O
:	O
initiation	O
of	O
action	B
potential	I
over	O
time	O
.	O
22	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
2.2	O
the	O
neuron	O
charged	O
)	O
potassium	O
eﬀuses	O
because	O
of	O
its	O
lower	O
extracellular	O
concentration	O
.	O
after	O
a	O
refractory	B
period	I
of	O
1	O
−	O
2	O
ms	O
the	O
resting	O
state	B
is	O
re-established	O
so	O
that	O
the	O
neuron	O
can	O
react	O
to	O
newly	O
applied	O
stimuli	O
with	O
an	O
action	O
poten-	O
tial	O
.	O
in	O
simple	O
terms	O
,	O
the	O
refractory	B
period	I
is	O
a	O
mandatory	O
break	O
a	O
neu-	O
ron	O
has	O
to	O
take	O
in	O
order	O
to	O
regenerate	O
.	O
the	O
shorter	O
this	O
break	O
is	O
,	O
the	O
more	O
often	O
a	O
neuron	O
can	O
ﬁre	O
per	O
time	O
.	O
then	O
the	O
resulting	O
pulse	O
is	O
transmitted	O
by	O
the	O
axon	B
.	O
2.2.2.3	O
in	O
the	O
axon	B
a	O
pulse	O
is	O
conducted	O
in	O
a	O
saltatory	O
way	O
we	O
have	O
already	O
learned	O
that	O
the	O
axon	B
is	O
used	O
to	O
transmit	O
the	O
action	B
potential	I
across	O
long	O
distances	O
(	O
remember	O
:	O
you	O
will	O
ﬁnd	O
an	O
illustration	O
of	O
a	O
neuron	O
including	O
an	O
axon	B
in	O
fig	O
.	O
2.3	O
on	O
page	O
17	O
)	O
.	O
the	O
axon	B
is	O
a	O
long	O
,	O
slender	O
extension	O
of	O
the	O
soma	B
.	O
in	O
vertebrates	O
it	O
is	O
normally	O
coated	O
by	O
a	O
myelin	B
sheath	I
that	O
consists	O
of	O
schwann	O
cells	O
(	O
in	O
the	O
pns	O
)	O
or	O
oligodendrocytes	B
(	O
in	O
the	O
cns	O
)	O
1	O
,	O
which	O
insulate	O
the	O
axon	B
very	O
well	O
from	O
electrical	O
activity	O
.	O
at	O
a	O
dis-	O
tance	O
of	O
0.1−2mm	O
there	O
are	O
gaps	O
between	O
these	O
cells	O
,	O
the	O
so-called	O
nodes	O
of	O
ran-	O
vier	O
.	O
the	O
said	O
gaps	O
appear	O
where	O
one	O
in-	O
sulate	O
cell	O
ends	O
and	O
the	O
next	O
one	O
begins	O
.	O
it	O
is	O
obvious	O
that	O
at	O
such	O
a	O
node	O
the	O
axon	B
is	O
less	O
insulated	O
.	O
1	O
schwann	O
cells	O
as	O
well	O
as	O
oligodendrocytes	B
are	O
vari-	O
eties	O
of	O
the	O
glial	O
cells	O
.	O
there	O
are	O
about	O
50	O
times	O
more	O
glial	O
cells	O
than	O
neurons	O
:	O
they	O
surround	O
the	O
neurons	O
(	O
glia	O
=	O
glue	O
)	O
,	O
insulate	O
them	O
from	O
each	O
other	O
,	O
provide	O
energy	O
,	O
etc	O
.	O
now	O
you	O
may	O
assume	O
that	O
these	O
less	O
in-	O
sulated	O
nodes	O
are	O
a	O
disadvantage	O
of	O
the	O
axon	B
-	O
however	O
,	O
they	O
are	O
not	O
.	O
at	O
the	O
nodes	O
,	O
mass	O
can	O
be	O
transferred	O
between	O
the	O
intracellular	O
and	O
extracellular	O
area	O
,	O
a	O
transfer	O
that	O
is	O
impossible	O
at	O
those	O
parts	O
of	O
the	O
axon	B
which	O
are	O
situated	O
between	O
two	O
nodes	O
(	O
internodes	B
)	O
and	O
therefore	O
in-	O
sulated	O
by	O
the	O
myelin	B
sheath	I
.	O
this	O
mass	O
transfer	O
permits	O
the	O
generation	O
of	O
signals	O
similar	O
to	O
the	O
generation	O
of	O
the	O
action	O
po-	O
tential	O
within	O
the	O
soma	B
.	O
the	O
action	O
po-	O
tential	O
is	O
transferred	O
as	O
follows	O
:	O
it	O
does	O
not	O
continuously	O
travel	O
along	O
the	O
axon	B
but	O
jumps	O
from	O
node	O
to	O
node	O
.	O
thus	O
,	O
a	O
series	O
of	O
depolarization	B
travels	O
along	O
the	O
nodes	O
of	O
ranvier	O
.	O
one	O
action	B
potential	I
initiates	O
the	O
next	O
one	O
,	O
and	O
mostly	O
even	O
several	O
nodes	O
are	O
active	O
at	O
the	O
same	O
time	O
here	O
.	O
the	O
pulse	O
``	O
jumping	O
''	O
from	O
node	O
to	O
node	O
is	O
re-	O
sponsible	O
for	O
the	O
name	O
of	O
this	O
pulse	O
con-	O
ductor	O
:	O
saltatory	B
conductor	I
.	O
obviously	O
,	O
the	O
pulse	O
will	O
move	O
faster	O
if	O
its	O
jumps	O
are	O
larger	O
.	O
axons	O
with	O
large	O
in-	O
ternodes	O
(	O
2	O
mm	O
)	O
achieve	O
a	O
signal	O
disper-	O
sion	O
of	O
approx	O
.	O
180	O
meters	O
per	O
second	O
.	O
however	O
,	O
the	O
internodes	B
can	O
not	O
grow	O
in-	O
deﬁnitely	O
,	O
since	O
the	O
action	B
potential	I
to	O
be	O
transferred	O
would	O
fade	O
too	O
much	O
until	O
it	O
reaches	O
the	O
next	O
node	O
.	O
so	O
the	O
nodes	O
have	O
a	O
task	O
,	O
too	O
:	O
to	O
constantly	O
amplify	O
the	O
sig-	O
nal	O
.	O
the	O
cells	O
receiving	O
the	O
action	O
poten-	O
tial	O
are	O
attached	O
to	O
the	O
end	O
of	O
the	O
axon	B
–	O
often	O
connected	O
by	O
dendrites	O
and	O
synapses	B
.	O
as	O
already	O
indicated	O
above	O
,	O
the	O
action	O
po-	O
tentials	O
are	O
not	O
only	O
generated	O
by	O
informa-	O
tion	O
received	O
by	O
the	O
dendrites	O
from	O
other	O
neurons	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
23	O
chapter	O
2	O
biological	O
neural	O
networks	O
dkriesel.com	O
2.3	O
receptor	O
cells	O
are	O
modiﬁed	O
neurons	O
2.3.1	O
there	O
are	O
diﬀerent	O
receptor	O
cells	O
for	O
various	O
types	O
of	O
perceptions	O
action	O
potentials	O
can	O
also	O
be	O
generated	O
by	O
sensory	O
information	O
an	O
organism	O
receives	O
from	O
its	O
environment	B
through	O
its	O
sensory	O
cells	O
.	O
specialized	O
receptor	O
cells	O
are	O
able	O
to	O
perceive	O
speciﬁc	O
stimulus	B
energies	O
such	O
as	O
light	O
,	O
temperature	O
and	O
sound	O
or	O
the	O
ex-	O
istence	O
of	O
certain	O
molecules	O
(	O
like	O
,	O
for	O
exam-	O
ple	O
,	O
the	O
sense	O
of	O
smell	O
)	O
.	O
this	O
is	O
working	O
because	O
of	O
the	O
fact	O
that	O
these	O
sensory	O
cells	O
are	O
actually	O
modiﬁed	O
neurons	O
.	O
they	O
do	O
not	O
receive	O
electrical	O
signals	O
via	O
dendrites	O
but	O
the	O
existence	O
of	O
the	O
stimulus	B
being	O
speciﬁc	O
for	O
the	O
receptor	B
cell	I
ensures	O
that	O
the	O
ion	B
channels	O
open	O
and	O
an	O
action	O
po-	O
tential	O
is	O
developed	O
.	O
this	O
process	O
of	O
trans-	O
forming	O
stimulus	B
energy	O
into	O
changes	O
in	O
the	O
membrane	O
potential	O
is	O
called	O
sensory	B
transduction	I
.	O
usually	O
,	O
the	O
stimulus	B
en-	O
ergy	O
itself	O
is	O
too	O
weak	O
to	O
directly	O
cause	O
nerve	O
signals	O
.	O
therefore	O
,	O
the	O
signals	O
are	O
ampliﬁed	O
either	O
during	O
transduction	O
or	O
by	O
means	O
of	O
the	O
stimulus-conducting	O
ap-	O
paratus	O
.	O
the	O
resulting	O
action	B
potential	I
can	O
be	O
processed	O
by	O
other	O
neurons	O
and	O
is	O
then	O
transmitted	O
into	O
the	O
thalamus	B
,	O
which	O
is	O
,	O
as	O
we	O
have	O
already	O
learned	O
,	O
a	O
gateway	O
to	O
the	O
cerebral	B
cortex	I
and	O
therefore	O
can	O
re-	O
ject	O
sensory	O
impressions	O
according	O
to	O
cur-	O
rent	O
relevance	O
and	O
thus	O
prevent	O
an	O
abun-	O
dance	O
of	O
information	O
to	O
be	O
managed	O
.	O
primary	O
receptors	O
transmit	O
their	O
pulses	O
directly	O
to	O
the	O
nervous	B
system	I
.	O
a	O
good	O
example	O
for	O
this	O
is	O
the	O
sense	O
of	O
pain	O
.	O
here	O
,	O
the	O
stimulus	B
intensity	O
is	O
propor-	O
tional	O
to	O
the	O
amplitude	O
of	O
the	O
action	O
po-	O
tential	O
.	O
technically	O
,	O
this	O
is	O
an	O
amplitude	O
modulation	O
.	O
secondary	O
receptors	O
,	O
however	O
,	O
continu-	O
ously	O
transmit	O
pulses	O
.	O
these	O
pulses	O
con-	O
trol	O
the	O
amount	O
of	O
the	O
related	O
neurotrans-	O
mitter	O
,	O
which	O
is	O
responsible	O
for	O
transfer-	O
ring	O
the	O
stimulus	B
.	O
the	O
stimulus	B
in	O
turn	O
controls	O
the	O
frequency	O
of	O
the	O
action	O
poten-	O
tial	O
of	O
the	O
receiving	O
neuron	O
.	O
this	O
process	O
is	O
a	O
frequency	O
modulation	O
,	O
an	O
encoding	O
of	O
the	O
stimulus	B
,	O
which	O
allows	O
to	O
better	O
per-	O
ceive	O
the	O
increase	O
and	O
decrease	O
of	O
a	O
stimu-	O
lus	O
.	O
there	O
can	O
be	O
individual	O
receptor	O
cells	O
or	O
cells	O
forming	O
complex	O
sensory	O
organs	O
(	O
e.g	O
.	O
eyes	O
or	O
ears	O
)	O
.	O
they	O
can	O
receive	O
stimuli	O
within	O
the	O
body	O
(	O
by	O
means	O
of	O
the	O
intero-	O
ceptors	O
)	O
as	O
well	O
as	O
stimuli	O
outside	O
of	O
the	O
body	O
(	O
by	O
means	O
of	O
the	O
exteroceptors	O
)	O
.	O
after	O
having	O
outlined	O
how	O
information	O
is	O
received	O
from	O
the	O
environment	B
,	O
it	O
will	O
be	O
interesting	O
to	O
look	O
at	O
how	O
the	O
information	O
is	O
processed	O
.	O
24	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
2.3	O
receptor	O
cells	O
2.3.2	O
information	O
is	O
processed	O
on	O
every	O
level	O
of	O
the	O
nervous	B
system	I
there	O
is	O
no	O
reason	O
to	O
believe	O
that	O
all	O
re-	O
ceived	O
information	O
is	O
transmitted	O
to	O
the	O
brain	B
and	O
processed	O
there	O
,	O
and	O
that	O
the	O
brain	B
ensures	O
that	O
it	O
is	O
``	O
output	O
''	O
in	O
the	O
form	O
of	O
motor	O
pulses	O
(	O
the	O
only	O
thing	O
an	O
organism	O
can	O
actually	O
do	O
within	O
its	O
envi-	O
ronment	O
is	O
to	O
move	O
)	O
.	O
the	O
information	O
pro-	O
cessing	O
is	O
entirely	O
decentralized	O
.	O
in	O
order	O
to	O
illustrate	O
this	O
principle	O
,	O
we	O
want	O
to	O
take	O
a	O
look	O
at	O
some	O
examples	O
,	O
which	O
leads	O
us	O
again	O
from	O
the	O
abstract	O
to	O
the	O
fundamen-	O
tal	O
in	O
our	O
hierarchy	O
of	O
information	O
process-	O
ing	O
.	O
.	O
it	O
is	O
certain	O
that	O
information	O
is	O
pro-	O
cessed	O
in	O
the	O
cerebrum	B
,	O
which	O
is	O
the	O
most	O
developed	O
natural	O
information	O
processing	O
structure	O
.	O
.	O
the	O
midbrain	O
and	O
the	O
thalamus	B
,	O
which	O
serves	O
–	O
as	O
we	O
have	O
already	O
learned	O
–	O
as	O
a	O
gateway	O
to	O
the	O
cere-	O
bral	O
cortex	O
,	O
are	O
situated	O
much	O
lower	O
in	O
the	O
hierarchy	O
.	O
the	O
ﬁltering	O
of	O
in-	O
formation	O
with	O
respect	O
to	O
the	O
current	O
relevance	O
executed	O
by	O
the	O
midbrain	O
is	O
a	O
very	O
important	O
method	O
of	O
infor-	O
mation	O
processing	O
,	O
too	O
.	O
but	O
even	O
the	O
thalamus	B
does	O
not	O
receive	O
any	O
prepro-	O
cessed	O
stimuli	O
from	O
the	O
outside	O
.	O
now	O
let	O
us	O
continue	O
with	O
the	O
lowest	O
level	O
,	O
the	O
sensory	O
cells	O
.	O
.	O
on	O
the	O
lowest	O
level	O
,	O
i.e	O
.	O
at	O
the	O
recep-	O
tor	O
cells	O
,	O
the	O
information	O
is	O
not	O
only	O
received	O
and	O
transferred	O
but	O
directly	O
processed	O
.	O
one	O
of	O
the	O
main	O
aspects	O
of	O
this	O
subject	O
is	O
to	O
prevent	O
the	O
transmis-	O
sion	O
of	O
``	O
continuous	B
stimuli	O
''	O
to	O
the	O
cen-	O
tral	O
nervous	B
system	I
because	O
of	O
sen-	O
sory	O
adaptation	O
:	O
due	O
to	O
continu-	O
ous	O
stimulation	O
many	O
receptor	O
cells	O
automatically	O
become	O
insensitive	O
to	O
stimuli	O
.	O
thus	O
,	O
receptor	O
cells	O
are	O
not	O
a	O
direct	O
mapping	O
of	O
speciﬁc	O
stimu-	O
lus	O
energy	O
onto	O
action	O
potentials	O
but	O
depend	O
on	O
the	O
past	O
.	O
other	O
sensors	O
change	O
their	O
sensitivity	O
according	O
to	O
the	O
situation	B
:	O
there	O
are	O
taste	O
recep-	O
tors	O
which	O
respond	O
more	O
or	O
less	O
to	O
the	O
same	O
stimulus	B
according	O
to	O
the	O
nutri-	O
tional	O
condition	O
of	O
the	O
organism	O
.	O
.	O
even	O
before	O
a	O
stimulus	B
reaches	O
the	O
receptor	O
cells	O
,	O
information	O
processing	O
can	O
already	O
be	O
executed	O
by	O
a	O
preced-	O
ing	O
signal	O
carrying	O
apparatus	O
,	O
for	O
ex-	O
ample	O
in	O
the	O
form	O
of	O
ampliﬁcation	O
:	O
the	O
external	O
and	O
the	O
internal	O
ear	O
have	O
a	O
speciﬁc	O
shape	O
to	O
amplify	O
the	O
sound	O
,	O
which	O
also	O
allows	O
–	O
in	O
asso-	O
ciation	O
with	O
the	O
sensory	O
cells	O
of	O
the	O
sense	O
of	O
hearing	O
–	O
the	O
sensory	O
stim-	O
ulus	O
only	O
to	O
increase	O
logarithmically	O
with	O
the	O
intensity	O
of	O
the	O
heard	O
sig-	O
nal	O
.	O
on	O
closer	O
examination	O
,	O
this	O
is	O
necessary	O
,	O
since	O
the	O
sound	O
pressure	O
of	O
the	O
signals	O
for	O
which	O
the	O
ear	O
is	O
con-	O
structed	O
can	O
vary	O
over	O
a	O
wide	O
expo-	O
nential	O
range	O
.	O
here	O
,	O
a	O
logarithmic	O
measurement	O
is	O
an	O
advantage	O
.	O
firstly	O
,	O
an	O
overload	O
is	O
prevented	O
and	O
secondly	O
,	O
the	O
fact	O
that	O
the	O
intensity	O
measure-	O
ment	O
of	O
intensive	O
signals	O
will	O
be	O
less	O
precise	O
,	O
doesn	O
’	O
t	O
matter	O
as	O
well	O
.	O
if	O
a	O
jet	O
ﬁghter	O
is	O
starting	O
next	O
to	O
you	O
,	O
small	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
25	O
chapter	O
2	O
biological	O
neural	O
networks	O
dkriesel.com	O
changes	O
in	O
the	O
noise	O
level	O
can	O
be	O
ig-	O
nored	O
.	O
just	O
to	O
get	O
a	O
feeling	O
for	O
sensory	O
organs	O
and	O
information	O
processing	O
in	O
the	O
organ-	O
ism	O
,	O
we	O
will	O
brieﬂy	O
describe	O
``	O
usual	O
''	O
light	O
sensing	O
organs	O
,	O
i.e	O
.	O
organs	O
often	O
found	O
in	O
nature	O
.	O
for	O
the	O
third	O
light	O
sensing	O
organ	O
described	O
below	O
,	O
the	O
single	O
lens	O
eye	O
,	O
we	O
will	O
discuss	O
the	O
information	O
processing	O
in	O
the	O
eye	O
.	O
2.3.3	O
an	O
outline	O
of	O
common	O
light	O
sensing	O
organs	O
for	O
many	O
organisms	O
it	O
turned	O
out	O
to	O
be	O
ex-	O
tremely	O
useful	O
to	O
be	O
able	O
to	O
perceive	O
elec-	O
tromagnetic	O
radiation	O
in	O
certain	O
regions	O
of	O
the	O
spectrum	O
.	O
consequently	O
,	O
sensory	O
or-	O
gans	O
have	O
been	O
developed	O
which	O
can	O
de-	O
tect	O
such	O
electromagnetic	O
radiation	O
and	O
the	O
wavelength	O
range	O
of	O
the	O
radiation	O
per-	O
ceivable	O
by	O
the	O
human	O
eye	O
is	O
called	O
visible	O
range	O
or	O
simply	O
light	O
.	O
the	O
diﬀerent	O
wave-	O
lengths	O
of	O
this	O
electromagnetic	O
radiation	O
are	O
perceived	O
by	O
the	O
human	O
eye	O
as	O
diﬀer-	O
ent	O
colors	O
.	O
the	O
visible	O
range	O
of	O
the	O
elec-	O
tromagnetic	O
radiation	O
is	O
diﬀerent	O
for	O
each	O
organism	O
.	O
some	O
organisms	O
can	O
not	O
see	O
the	O
colors	O
(	O
=wavelength	O
ranges	O
)	O
we	O
can	O
see	O
,	O
others	O
can	O
even	O
perceive	O
additional	O
wave-	O
length	O
ranges	O
(	O
e.g	O
.	O
in	O
the	O
uv	O
range	O
)	O
.	O
be-	O
fore	O
we	O
begin	O
with	O
the	O
human	O
being	O
–	O
in	O
order	O
to	O
get	O
a	O
broader	O
knowledge	O
of	O
the	O
sense	O
of	O
sight–	O
we	O
brieﬂy	O
want	O
to	O
look	O
at	O
two	O
organs	O
of	O
sight	O
which	O
,	O
from	O
an	O
evolu-	O
tionary	O
point	O
of	O
view	O
,	O
exist	O
much	O
longer	O
than	O
the	O
human	O
.	O
2.3.3.1	O
compound	O
eyes	O
and	O
pinhole	O
eyes	O
only	O
provide	O
high	O
temporal	O
or	O
spatial	O
resolution	O
let	O
us	O
ﬁrst	O
take	O
a	O
look	O
at	O
the	O
so-called	O
compound	B
eye	I
(	O
fig	O
.	O
2.5	O
on	O
the	O
next	O
page	O
)	O
,	O
which	O
is	O
,	O
for	O
example	O
,	O
common	O
in	O
insects	O
and	O
crustaceans	O
.	O
the	O
compound	B
eye	I
consists	O
of	O
a	O
great	O
number	O
of	O
small	O
,	O
individual	O
eyes	O
.	O
if	O
we	O
look	O
at	O
the	O
com-	O
pound	O
eye	O
from	O
the	O
outside	O
,	O
the	O
individ-	O
ual	O
eyes	O
are	O
clearly	O
visible	O
and	O
arranged	O
in	O
a	O
hexagonal	O
pattern	B
.	O
each	O
individual	B
eye	I
has	O
its	O
own	O
nerve	O
ﬁber	O
which	O
is	O
con-	O
nected	O
to	O
the	O
insect	O
brain	B
.	O
since	O
the	O
indi-	O
vidual	O
eyes	O
can	O
be	O
distinguished	O
,	O
it	O
is	O
ob-	O
vious	O
that	O
the	O
number	O
of	O
pixels	O
,	O
i.e	O
.	O
the	O
spatial	O
resolution	O
,	O
of	O
compound	O
eyes	O
must	O
be	O
very	O
low	O
and	O
the	O
image	O
is	O
blurred	O
.	O
but	O
compound	O
eyes	O
have	O
advantages	O
,	O
too	O
,	O
espe-	O
cially	O
for	O
fast-ﬂying	O
insects	O
.	O
certain	O
com-	O
pound	O
eyes	O
process	O
more	O
than	O
300	O
images	O
per	O
second	O
(	O
to	O
the	O
human	O
eye	O
,	O
however	O
,	O
movies	O
with	O
25	O
images	O
per	O
second	O
appear	O
as	O
a	O
ﬂuent	O
motion	O
)	O
.	O
compound	B
eye	I
:	O
high	O
temp.	O
,	O
low	O
spatial	O
resolution	O
pinhole	O
eyes	O
are	O
,	O
for	O
example	O
,	O
found	O
in	O
octopus	O
species	O
and	O
work	O
–	O
as	O
you	O
can	O
guess	O
–	O
similar	O
to	O
a	O
pinhole	O
camera	O
.	O
a	O
pinhole	O
pinhole	O
eye	O
has	O
a	O
very	O
small	O
opening	O
for	O
camera	O
:	O
high	O
spat.	O
,	O
light	O
entry	O
,	O
which	O
projects	O
a	O
sharp	O
image	O
low	O
onto	O
the	O
sensory	O
cells	O
behind	O
.	O
thus	O
,	O
the	O
temporal	O
spatial	O
resolution	O
is	O
much	O
higher	O
than	O
in	O
resolution	O
the	O
compound	B
eye	I
.	O
but	O
due	O
to	O
the	O
very	O
small	O
opening	O
for	O
light	O
entry	O
the	O
resulting	O
image	O
is	O
less	O
bright	O
.	O
26	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
2.3	O
receptor	O
cells	O
2.3.3.3	O
the	O
retina	B
does	O
not	O
only	O
receive	O
information	O
but	O
is	O
also	O
responsible	O
for	O
information	O
processing	O
the	O
light	O
signals	O
falling	O
on	O
the	O
eye	O
are	O
received	O
by	O
the	O
retina	B
and	O
directly	O
pre-	O
processed	O
by	O
several	O
layers	O
of	O
information-	O
processing	O
cells	O
.	O
we	O
want	O
to	O
brieﬂy	O
dis-	O
cuss	O
the	O
diﬀerent	O
steps	O
of	O
this	O
informa-	O
tion	O
processing	O
and	O
in	O
doing	O
so	O
,	O
we	O
follow	O
the	O
way	O
of	O
the	O
information	O
carried	O
by	O
the	O
light	O
:	O
photoreceptors	O
receive	O
the	O
light	O
signal	O
und	O
cause	O
action	O
potentials	O
(	O
there	O
are	O
diﬀerent	O
receptors	O
for	O
diﬀerent	O
color	O
components	O
and	O
light	O
intensi-	O
ties	O
)	O
.	O
these	O
receptors	O
are	O
the	O
real	O
light-receiving	O
part	O
of	O
the	O
retina	B
and	O
they	O
are	O
sensitive	O
to	O
such	O
an	O
extent	O
that	O
only	O
one	O
single	O
photon	O
falling	O
on	O
the	O
retina	B
can	O
cause	O
an	O
action	O
po-	O
tential	O
.	O
then	O
several	O
photoreceptors	O
transmit	O
their	O
signals	O
to	O
one	O
single	O
bipolar	O
cell	O
.	O
this	O
means	O
that	O
here	O
the	O
in-	O
formation	O
has	O
already	O
been	O
summa-	O
rized	O
.	O
finally	O
,	O
the	O
now	O
transformed	O
light	O
signal	O
travels	O
from	O
several	O
bipo-	O
lar	O
cells	O
2	O
into	O
ganglion	O
cells	O
.	O
various	O
bipolar	O
cells	O
can	O
transmit	O
their	O
information	O
to	O
one	O
gan-	O
glion	O
cell	O
.	O
the	O
higher	O
the	O
number	O
of	O
photoreceptors	O
that	O
aﬀect	O
the	O
gan-	O
glion	O
cell	O
,	O
the	O
larger	O
the	O
ﬁeld	O
of	O
per-	O
ception	O
,	O
the	O
receptive	O
ﬁeld	O
,	O
which	O
covers	O
the	O
ganglions	O
–	O
and	O
the	O
less	O
2	O
there	O
are	O
diﬀerent	O
kinds	O
of	O
bipolar	O
cells	O
,	O
as	O
well	O
,	O
but	O
to	O
discuss	O
all	O
of	O
them	O
would	O
go	O
too	O
far	O
.	O
figure	O
2.5	O
:	O
compound	B
eye	I
of	O
a	O
robber	O
ﬂy	O
2.3.3.2	O
single	O
lens	O
eyes	O
combine	O
the	O
advantages	O
of	O
the	O
other	O
two	O
eye	O
types	O
,	O
but	O
they	O
are	O
more	O
complex	O
the	O
light	O
sensing	O
organ	O
common	O
in	O
verte-	O
brates	O
is	O
the	O
single	B
lense	I
eye	I
.	O
the	O
result-	O
ing	O
image	O
is	O
a	O
sharp	O
,	O
high-resolution	O
image	O
of	O
the	O
environment	B
at	O
high	O
or	O
variable	O
light	O
intensity	O
.	O
on	O
the	O
other	O
hand	O
it	O
is	O
more	O
complex	O
.	O
similar	O
to	O
the	O
pinhole	B
eye	I
the	O
light	O
enters	O
through	O
an	O
opening	O
(	O
pupil	B
)	O
and	O
is	O
projected	O
onto	O
a	O
layer	B
of	O
sensory	O
cells	O
in	O
the	O
eye	O
.	O
(	O
retina	B
)	O
.	O
but	O
in	O
contrast	O
to	O
the	O
pinhole	B
eye	I
,	O
the	O
size	O
of	O
the	O
pupil	B
can	O
be	O
adapted	O
to	O
the	O
lighting	O
conditions	O
(	O
by	O
means	O
of	O
the	O
iris	B
muscle	O
,	O
which	O
expands	O
or	O
contracts	O
the	O
pupil	B
)	O
.	O
these	O
diﬀerences	O
in	O
pupil	B
dilation	O
require	O
to	O
actively	O
focus	O
the	O
image	O
.	O
therefore	O
,	O
the	O
single	O
lens	O
eye	O
contains	O
an	O
additional	O
adjustable	O
lens	B
.	O
single	B
lense	I
eye	I
:	O
high	O
temp	O
.	O
and	O
spat	O
.	O
resolution	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
27	O
chapter	O
2	O
biological	O
neural	O
networks	O
dkriesel.com	O
sharp	O
is	O
the	O
image	O
in	O
the	O
area	O
of	O
this	O
ganglion	B
cell	I
.	O
so	O
the	O
information	O
is	O
already	O
reduced	O
directly	O
in	O
the	O
retina	B
and	O
the	O
overall	O
image	O
is	O
,	O
for	O
exam-	O
ple	O
,	O
blurred	O
in	O
the	O
peripheral	O
ﬁeld	O
of	O
vision	O
.	O
so	O
far	O
,	O
we	O
have	O
learned	O
about	O
the	O
information	O
processing	O
in	O
the	O
retina	B
only	O
as	O
a	O
top-down	B
struc-	O
ture	O
.	O
now	O
we	O
want	O
to	O
take	O
a	O
look	O
at	O
the	O
horizontal	O
and	O
amacrine	O
cells	O
.	O
these	O
and	O
compressing	O
cells	O
are	O
not	O
connected	O
from	O
the	O
front	O
backwards	O
but	O
laterally	O
.	O
they	O
allow	O
the	O
light	O
signals	O
to	O
inﬂuence	O
themselves	O
laterally	O
directly	O
during	O
the	O
information	O
processing	O
in	O
the	O
retina	B
–	O
a	O
much	O
more	O
powerful	O
information	O
processing	O
method	O
of	O
than	O
blurring	O
.	O
when	O
the	O
horizontal	O
cells	O
are	O
excited	O
by	O
a	O
photoreceptor	O
,	O
they	O
are	O
able	O
to	O
excite	O
other	O
nearby	O
photoreceptors	O
and	O
at	O
the	O
same	O
time	O
inhibit	O
more	O
distant	O
bipolar	O
cells	O
and	O
receptors	O
.	O
this	O
ensures	O
the	O
clear	O
perception	O
of	O
outlines	O
and	O
bright	O
points	O
.	O
amacrine	O
cells	O
can	O
further	O
intensify	O
certain	O
stimuli	O
by	O
distributing	O
information	O
from	O
bipolar	O
cells	O
to	O
several	O
ganglion	O
cells	O
or	O
by	O
inhibiting	O
ganglions	O
.	O
these	O
ﬁrst	O
steps	O
of	O
transmitting	O
visual	O
in-	O
formation	O
to	O
the	O
brain	B
show	O
that	O
informa-	O
tion	O
is	O
processed	O
from	O
the	O
ﬁrst	O
moment	O
the	O
information	O
is	O
received	O
and	O
,	O
on	O
the	O
other	O
hand	O
,	O
is	O
processed	O
in	O
parallel	O
within	O
mil-	O
lions	O
of	O
information-processing	O
cells	O
.	O
the	O
system	O
’	O
s	O
power	O
and	O
resistance	O
to	O
errors	O
is	O
based	O
upon	O
this	O
massive	O
division	O
of	O
work	O
.	O
2.4	O
the	O
amount	O
of	O
neurons	O
in	O
living	O
organisms	O
at	O
diﬀerent	O
stages	O
of	O
development	O
an	O
overview	O
of	O
diﬀerent	O
organisms	O
and	O
their	O
neural	O
capacity	O
(	O
in	O
large	O
part	O
from	O
[	O
rd05	O
]	O
)	O
:	O
302	O
neurons	O
are	O
required	O
by	O
the	O
nervous	B
system	I
of	O
a	O
nematode	O
worm	O
,	O
which	O
serves	O
as	O
a	O
popular	O
model	O
organism	O
in	O
biology	O
.	O
nematodes	O
live	O
in	O
the	O
soil	O
and	O
feed	O
on	O
bacteria	O
.	O
104	O
neurons	O
make	O
an	O
ant	O
(	O
to	O
simplify	O
matters	O
we	O
neglect	O
the	O
fact	O
that	O
some	O
ant	O
species	O
also	O
can	O
have	O
more	O
or	O
less	O
eﬃcient	O
nervous	O
systems	O
)	O
.	O
due	O
to	O
the	O
use	O
of	O
diﬀerent	O
attractants	O
and	O
odors	O
,	O
ants	O
are	O
able	O
to	O
engage	O
in	O
complex	O
social	O
behavior	O
and	O
form	O
huge	O
states	O
with	O
millions	O
of	O
individuals	O
.	O
if	O
you	O
re-	O
gard	O
such	O
an	O
ant	O
state	B
as	O
an	O
individ-	O
ual	O
,	O
it	O
has	O
a	O
cognitive	O
capacity	O
similar	O
to	O
a	O
chimpanzee	O
or	O
even	O
a	O
human	O
.	O
with	O
105	O
neurons	O
the	O
nervous	B
system	I
of	O
a	O
ﬂy	O
can	O
be	O
constructed	O
.	O
a	O
ﬂy	O
can	O
evade	O
an	O
object	O
in	O
real-time	O
in	O
three-	O
dimensional	O
space	O
,	O
it	O
can	O
land	O
upon	O
the	O
ceiling	O
upside	O
down	O
,	O
has	O
a	O
consid-	O
erable	O
sensory	O
system	O
because	O
of	O
com-	O
pound	O
eyes	O
,	O
vibrissae	O
,	O
nerves	O
at	O
the	O
end	O
of	O
its	O
legs	O
and	O
much	O
more	O
.	O
thus	O
,	O
a	O
ﬂy	O
has	O
considerable	O
diﬀerential	O
and	O
integral	O
calculus	O
in	O
high	O
dimensions	O
implemented	O
``	O
in	O
hardware	O
''	O
.	O
we	O
all	O
know	O
that	O
a	O
ﬂy	O
is	O
not	O
easy	O
to	O
catch	O
.	O
of	O
course	O
,	O
the	O
bodily	O
functions	O
are	O
28	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
2.4	O
the	O
amount	O
of	O
neurons	O
in	O
living	O
organisms	O
also	O
controlled	O
by	O
neurons	O
,	O
but	O
these	O
should	O
be	O
ignored	O
here	O
.	O
with	O
0.8	O
·	O
106	O
neurons	O
we	O
have	O
enough	O
cerebral	O
matter	O
to	O
create	O
a	O
honeybee	O
.	O
honeybees	O
build	O
colonies	O
and	O
have	O
amazing	O
capabilities	O
in	O
the	O
ﬁeld	O
of	O
aerial	O
reconnaissance	O
and	O
navigation	O
.	O
4	O
·	O
106	O
neurons	O
result	O
in	O
a	O
mouse	O
,	O
and	O
here	O
the	O
world	O
of	O
vertebrates	O
already	O
begins	O
.	O
1.5	O
·	O
107	O
neurons	O
are	O
suﬃcient	O
for	O
a	O
rat	O
,	O
an	O
animal	O
which	O
is	O
denounced	O
as	O
be-	O
ing	O
extremely	O
intelligent	O
and	O
are	O
of-	O
ten	O
used	O
to	O
participate	O
in	O
a	O
variety	O
of	O
intelligence	O
tests	O
representative	O
for	O
the	O
animal	O
world	O
.	O
rats	O
have	O
an	O
ex-	O
traordinary	O
sense	O
of	O
smell	O
and	O
orien-	O
tation	O
,	O
and	O
they	O
also	O
show	O
social	O
be-	O
havior	O
.	O
the	O
brain	B
of	O
a	O
frog	O
can	O
be	O
positioned	O
within	O
the	O
same	O
dimension	O
.	O
the	O
frog	O
has	O
a	O
complex	O
build	O
with	O
many	O
functions	O
,	O
it	O
can	O
swim	O
and	O
has	O
evolved	O
complex	O
behavior	O
.	O
a	O
frog	O
can	O
continuously	O
target	B
the	O
said	O
ﬂy	O
by	O
means	O
of	O
his	O
eyes	O
while	O
jumping	O
in	O
three-dimensional	O
space	O
and	O
and	O
catch	O
it	O
with	O
its	O
tongue	O
with	O
consid-	O
erable	O
probability	O
.	O
5	O
·	O
107	O
neurons	O
make	O
a	O
bat	O
.	O
the	O
bat	O
can	O
navigate	O
in	O
total	O
darkness	O
through	O
a	O
room	O
,	O
exact	O
up	O
to	O
several	O
centime-	O
ters	O
,	O
by	O
only	O
using	O
their	O
sense	O
of	O
hear-	O
ing	O
.	O
it	O
uses	O
acoustic	O
signals	O
to	O
localize	O
self-camouﬂaging	O
insects	O
(	O
e.g	O
.	O
some	O
moths	O
have	O
a	O
certain	O
wing	O
structure	O
that	O
reﬂects	O
less	O
sound	O
waves	O
and	O
the	O
echo	O
will	O
be	O
small	O
)	O
and	O
also	O
eats	O
its	O
prey	O
while	O
ﬂying	O
.	O
1.6	O
·	O
108	O
neurons	O
are	O
required	O
by	O
the	O
brain	B
of	O
a	O
dog	O
,	O
companion	O
of	O
man	O
for	O
ages	O
.	O
now	O
take	O
a	O
look	O
at	O
another	O
pop-	O
ular	O
companion	O
of	O
man	O
:	O
3	O
·	O
108	O
neurons	O
can	O
be	O
found	O
in	O
a	O
cat	O
,	O
which	O
is	O
about	O
twice	O
as	O
much	O
as	O
in	O
a	O
dog	O
.	O
we	O
know	O
that	O
cats	O
are	O
very	O
elegant	O
,	O
patient	O
carnivores	O
that	O
can	O
show	O
a	O
variety	O
of	O
behaviors	O
.	O
by	O
the	O
way	O
,	O
an	O
octopus	O
can	O
be	O
positioned	O
within	O
the	O
same	O
magnitude	O
.	O
only	O
very	O
few	O
people	O
know	O
that	O
,	O
for	O
exam-	O
ple	O
,	O
in	O
labyrinth	O
orientation	O
the	O
octo-	O
pus	O
is	O
vastly	O
superior	O
to	O
the	O
rat	O
.	O
for	O
6	O
·	O
109	O
neurons	O
you	O
already	O
get	O
a	O
chimpanzee	O
,	O
one	O
of	O
the	O
animals	O
being	O
very	O
similar	O
to	O
the	O
human	O
.	O
1011	O
neurons	O
make	O
a	O
human	O
.	O
usually	O
,	O
the	O
human	O
has	O
considerable	O
cognitive	O
capabilities	O
,	O
is	O
able	O
to	O
speak	O
,	O
to	O
ab-	O
stract	O
,	O
to	O
remember	O
and	O
to	O
use	O
tools	O
as	O
well	O
as	O
the	O
knowledge	O
of	O
other	O
hu-	O
mans	O
to	O
develop	O
advanced	O
technolo-	O
gies	O
and	O
manifold	O
social	O
structures	O
.	O
with	O
2	O
·	O
1011	O
neurons	O
there	O
are	O
nervous	O
systems	O
having	O
more	O
neurons	O
than	O
the	O
human	O
nervous	B
system	I
.	O
here	O
we	O
should	O
mention	O
elephants	O
and	O
certain	O
whale	O
species	O
.	O
our	O
state-of-the-art	O
computers	O
are	O
not	O
able	O
to	O
keep	O
up	O
with	O
the	O
aforementioned	O
processing	O
power	O
of	O
a	O
ﬂy	O
.	O
recent	O
research	O
results	O
suggest	O
that	O
the	O
processes	O
in	O
ner-	O
vous	O
systems	O
might	O
be	O
vastly	O
more	O
pow-	O
erful	O
than	O
people	O
thought	O
until	O
not	O
long	O
ago	O
:	O
michaeva	O
et	O
al	O
.	O
describe	O
a	O
separate	O
,	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
29	O
chapter	O
2	O
biological	O
neural	O
networks	O
dkriesel.com	O
synapse-integrated	O
information	O
way	O
of	O
in-	O
formation	O
processing	O
[	O
mbw+10	O
]	O
.	O
poster-	O
ity	O
will	O
show	O
if	O
they	O
are	O
right	O
.	O
therefore	O
it	O
is	O
a	O
vector	O
.	O
in	O
nature	O
a	O
neuron	O
receives	O
pulses	O
of	O
103	O
to	O
104	O
other	O
neurons	O
on	O
average	O
.	O
2.5	O
transition	O
to	O
technical	O
neurons	O
:	O
neural	O
networks	O
are	O
a	O
caricature	O
of	O
biology	O
how	O
do	O
we	O
change	O
from	O
biological	O
neural	O
networks	O
to	O
the	O
technical	O
ones	O
?	O
through	O
radical	O
simpliﬁcation	O
.	O
i	O
want	O
to	O
brieﬂy	O
summarize	O
the	O
conclusions	O
relevant	O
for	O
the	O
technical	O
part	O
:	O
we	O
have	O
learned	O
that	O
the	O
biological	O
neu-	O
rons	O
are	O
linked	O
to	O
each	O
other	O
in	O
a	O
weighted	O
way	O
and	O
when	O
stimulated	O
they	O
electrically	O
transmit	O
their	O
signal	O
via	O
the	O
axon	B
.	O
from	O
the	O
axon	B
they	O
are	O
not	O
directly	O
transferred	O
to	O
the	O
succeeding	O
neurons	O
,	O
but	O
they	O
ﬁrst	O
have	O
to	O
cross	O
the	O
synaptic	B
cleft	I
where	O
the	O
signal	O
is	O
changed	O
again	O
by	O
variable	O
chem-	O
ical	O
processes	O
.	O
in	O
the	O
receiving	O
neuron	O
the	O
various	O
inputs	O
that	O
have	O
been	O
post-	O
processed	O
in	O
the	O
synaptic	B
cleft	I
are	O
summa-	O
rized	O
or	O
accumulated	O
to	O
one	O
single	O
pulse	O
.	O
depending	O
on	O
how	O
the	O
neuron	O
is	O
stimu-	O
lated	O
by	O
the	O
cumulated	O
input	O
,	O
the	O
neuron	O
itself	O
emits	O
a	O
pulse	O
or	O
not	O
–	O
thus	O
,	O
the	O
out-	O
put	O
is	O
non-linear	O
and	O
not	O
proportional	O
to	O
the	O
cumulated	O
input	O
.	O
our	O
brief	O
summary	O
corresponds	O
exactly	O
with	O
the	O
few	O
elements	O
of	O
biological	O
neural	O
networks	O
we	O
want	O
to	O
take	O
over	O
into	O
the	O
technical	O
approxima-	O
tion	O
:	O
scalar	O
output	O
:	O
the	O
output	O
of	O
a	O
neuron	O
is	O
a	O
scalar	O
,	O
which	O
means	O
that	O
the	O
neu-	O
ron	O
only	O
consists	O
of	O
one	O
component	O
.	O
several	O
scalar	O
outputs	O
in	O
turn	O
form	O
the	O
vectorial	O
input	O
of	O
another	O
neuron	O
.	O
this	O
particularly	O
means	O
that	O
some-	O
where	O
in	O
the	O
neuron	O
the	O
various	O
input	O
components	O
have	O
to	O
be	O
summarized	O
in	O
such	O
a	O
way	O
that	O
only	O
one	O
component	O
remains	O
.	O
synapses	B
change	O
input	O
:	O
in	O
technical	O
neu-	O
ral	O
networks	O
the	O
inputs	O
are	O
prepro-	O
cessed	O
,	O
too	O
.	O
they	O
are	O
multiplied	O
by	O
a	O
number	O
(	O
the	O
weight	B
)	O
–	O
they	O
are	O
weighted	O
.	O
the	O
set	O
of	O
such	O
weights	O
rep-	O
resents	O
the	O
information	O
storage	O
of	O
a	O
neural	O
network	O
–	O
in	O
both	O
biological	O
original	O
and	O
technical	O
adaptation	O
.	O
accumulating	O
the	O
inputs	O
:	O
in	O
biology	O
,	O
the	O
inputs	O
are	O
summarized	O
to	O
a	O
pulse	O
ac-	O
cording	O
to	O
the	O
chemical	O
change	O
,	O
i.e.	O
,	O
they	O
are	O
accumulated	O
–	O
on	O
the	O
techni-	O
cal	O
side	O
this	O
is	O
often	O
realized	O
by	O
the	O
weighted	B
sum	I
,	O
which	O
we	O
will	O
get	O
to	O
know	O
later	O
on	O
.	O
this	O
means	O
that	O
after	O
accumulation	O
we	O
continue	O
with	O
only	O
one	O
value	O
,	O
a	O
scalar	O
,	O
instead	O
of	O
a	O
vec-	O
tor	O
.	O
non-linear	O
characteristic	O
:	O
the	O
input	O
of	O
our	O
technical	O
neurons	O
is	O
also	O
not	O
pro-	O
portional	O
to	O
the	O
output	O
.	O
vectorial	O
input	O
:	O
the	O
input	O
of	O
technical	O
neurons	O
consists	O
of	O
many	O
components	O
,	O
adjustable	O
weights	O
:	O
the	O
weights	O
weight-	O
ing	O
the	O
inputs	O
are	O
variable	O
,	O
similar	O
to	O
30	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
2.5	O
technical	O
neurons	O
as	O
caricature	O
of	O
biology	O
bits	O
of	O
information	O
.	O
naïvely	O
calculated	O
:	O
how	O
much	O
storage	O
capacity	O
does	O
the	O
brain	B
have	O
?	O
note	O
:	O
the	O
information	O
which	O
neu-	O
ron	O
is	O
connected	O
to	O
which	O
other	O
neuron	O
is	O
also	O
important	O
.	O
the	O
chemical	O
processes	O
at	O
the	O
synap-	O
tic	O
cleft	O
.	O
this	O
adds	O
a	O
great	O
dynamic	O
to	O
the	O
network	O
because	O
a	O
large	O
part	O
of	O
the	O
``	O
knowledge	O
''	O
of	O
a	O
neural	O
network	O
is	O
saved	O
in	O
the	O
weights	O
and	O
in	O
the	O
form	O
and	O
power	O
of	O
the	O
chemical	O
processes	O
in	O
a	O
synaptic	B
cleft	I
.	O
so	O
our	O
current	O
,	O
only	O
casually	O
formulated	O
and	O
very	O
simple	O
neuron	O
model	O
receives	O
a	O
vectorial	O
input	O
~x	O
,	O
with	O
components	O
xi	O
.	O
these	O
are	O
multiplied	O
by	O
the	O
appropriate	O
weights	O
wi	O
and	O
accumu-	O
lated	O
:	O
x	O
i	O
wixi	O
.	O
aforementioned	O
term	O
is	O
the	O
weighted	B
sum	I
.	O
mapping	O
f	O
deﬁnes	O
the	O
scalar	O
output	O
y	O
:	O
called	O
then	O
the	O
nonlinear	O
x	O
!	O
y	O
=	O
f	O
wixi	O
.	O
i	O
after	O
this	O
transition	O
we	O
now	O
want	O
to	O
spec-	O
ify	O
more	O
precisely	O
our	O
neuron	O
model	O
and	O
add	O
some	O
odds	O
and	O
ends	O
.	O
afterwards	O
we	O
will	O
take	O
a	O
look	O
at	O
how	O
the	O
weights	O
can	O
be	O
adjusted	O
.	O
exercises	O
exercise	O
4.	O
it	O
is	O
estimated	O
that	O
a	O
hu-	O
man	O
brain	B
consists	O
of	O
approx	O
.	O
1011	O
nerve	O
cells	O
,	O
each	O
of	O
which	O
has	O
about	O
103	O
to	O
104	O
synapses	B
.	O
for	O
this	O
exercise	O
we	O
assume	O
103	O
synapses	B
per	O
neuron	O
.	O
let	O
us	O
further	O
as-	O
sume	O
that	O
a	O
single	O
synapse	O
could	O
save	O
4	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
31	O
chapter	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
formal	O
deﬁnitions	O
and	O
colloquial	O
explanations	O
of	O
the	O
components	O
that	O
realize	O
the	O
technical	O
adaptations	O
of	O
biological	O
neural	O
networks	O
.	O
initial	O
descriptions	O
of	O
how	O
to	O
combine	O
these	O
components	O
into	O
a	O
neural	O
network	O
.	O
this	O
chapter	O
contains	O
the	O
formal	O
deﬁni-	O
tions	O
for	O
most	O
of	O
the	O
neural	O
network	O
com-	O
ponents	O
used	O
later	O
in	O
the	O
text	O
.	O
after	O
this	O
chapter	O
you	O
will	O
be	O
able	O
to	O
read	O
the	O
indi-	O
vidual	O
chapters	O
of	O
this	O
work	O
without	O
hav-	O
ing	O
to	O
know	O
the	O
preceding	O
ones	O
(	O
although	O
this	O
would	O
be	O
useful	O
)	O
.	O
3.1	O
the	O
concept	O
of	O
time	O
in	O
neural	O
networks	O
certain	O
point	O
in	O
time	O
,	O
the	O
notation	O
will	O
be	O
,	O
for	O
example	O
,	O
netj	O
(	O
t	O
−	O
1	O
)	O
or	O
oi	O
(	O
t	O
)	O
.	O
from	O
a	O
biological	O
point	O
of	O
view	O
this	O
is	O
,	O
of	O
course	O
,	O
not	O
very	O
plausible	O
(	O
in	O
the	O
human	O
brain	B
a	O
neuron	O
does	O
not	O
wait	O
for	O
another	O
one	O
)	O
,	O
but	O
it	O
signiﬁcantly	O
simpliﬁes	O
the	O
im-	O
plementation	O
.	O
in	O
some	O
deﬁnitions	O
of	O
this	O
text	O
we	O
use	O
the	O
term	O
time	O
or	O
the	O
number	O
of	O
cycles	O
of	O
the	O
neural	O
network	O
,	O
respectively	O
.	O
time	O
is	O
di-	O
vided	O
into	O
discrete	B
time	O
steps	O
:	O
discrete	B
time	O
steps	O
deﬁnition	O
3.1	O
(	O
the	O
concept	O
of	O
time	O
)	O
.	O
the	O
current	O
time	O
(	O
present	O
time	O
)	O
is	O
referred	O
to	O
as	O
(	O
t	O
)	O
,	O
the	O
next	O
time	O
step	O
as	O
(	O
t	O
+	O
1	O
)	O
,	O
the	O
preceding	O
one	O
as	O
(	O
t	O
−	O
1	O
)	O
.	O
all	O
other	O
time	O
steps	O
are	O
referred	O
to	O
analogously	O
.	O
if	O
in	O
the	O
following	O
chapters	O
several	O
mathemati-	O
cal	O
variables	O
(	O
e.g	O
.	O
netj	O
or	O
oi	O
)	O
refer	O
to	O
a	O
(	O
t	O
)	O
(	O
cid:73	O
)	O
3.2	O
components	O
of	O
neural	O
networks	O
a	O
technical	O
neural	O
network	O
consists	O
of	O
sim-	O
ple	O
processing	O
units	O
,	O
the	O
neurons	O
,	O
and	O
directed	O
,	O
weighted	O
connections	O
between	O
those	O
neurons	O
.	O
here	O
,	O
the	O
strength	O
of	O
a	O
connection	B
(	O
or	O
the	O
connecting	O
weight	B
)	O
be-	O
33	O
chapter	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
(	O
fundamental	O
)	O
dkriesel.com	O
n.	O
network	O
=	O
neurons	O
+	O
weighted	O
connection	O
wi	O
,	O
j	O
(	O
cid:73	O
)	O
1.	O
tween	O
two	O
neurons	O
i	O
and	O
j	O
is	O
referred	O
to	O
as	O
wi	O
,	O
j	O
deﬁnition	O
3.2	O
(	O
neural	O
network	O
)	O
.	O
a	O
neural	O
network	O
is	O
a	O
sorted	O
triple	O
(	O
n	O
,	O
v	O
,	O
w	O
)	O
with	O
two	O
sets	O
n	O
,	O
v	O
and	O
a	O
func-	O
tion	O
w	O
,	O
where	O
n	O
is	O
the	O
set	O
of	O
neurons	O
and	O
v	O
a	O
set	O
{	O
(	O
i	O
,	O
j	O
)	O
|i	O
,	O
j	O
∈	O
n	O
}	O
whose	O
elements	O
are	O
called	O
connections	O
between	O
neuron	O
i	O
and	O
neuron	O
j.	O
the	O
function	B
w	O
:	O
v	O
→	O
r	O
deﬁnes	O
the	O
weights	O
,	O
where	O
w	O
(	O
(	O
i	O
,	O
j	O
)	O
)	O
,	O
the	O
weight	B
of	O
the	O
connection	B
between	O
neuron	O
i	O
and	O
neu-	O
ron	O
j	O
,	O
is	O
shortened	O
to	O
wi	O
,	O
j	O
.	O
depending	O
on	O
the	O
point	O
of	O
view	O
it	O
is	O
either	O
undeﬁned	O
or	O
0	O
for	O
connections	O
that	O
do	O
not	O
exist	O
in	O
the	O
network	O
.	O
snipe	O
:	O
in	O
snipe	O
,	O
an	O
instance	O
of	O
the	O
class	O
neuralnetworkdescriptor	O
is	O
created	O
in	O
the	O
ﬁrst	O
place	O
.	O
the	O
descriptor	O
object	O
roughly	O
outlines	O
a	O
class	O
of	O
neural	O
networks	O
,	O
e.g	O
.	O
it	O
deﬁnes	O
the	O
number	O
of	O
neuron	O
lay-	O
ers	O
in	O
a	O
neural	O
network	O
.	O
in	O
a	O
second	O
step	O
,	O
the	O
descriptor	O
object	O
is	O
used	O
to	O
instantiate	O
an	O
arbitrary	O
number	O
of	O
neuralnetwork	O
ob-	O
jects	O
.	O
to	O
get	O
started	O
with	O
snipe	O
program-	O
ming	O
,	O
the	O
documentations	O
of	O
exactly	O
these	O
two	O
classes	O
are	O
–	O
in	O
that	O
order	O
–	O
the	O
right	O
thing	O
to	O
read	O
.	O
the	O
presented	O
layout	O
involv-	O
ing	O
descriptor	O
and	O
dependent	O
neural	O
net-	O
works	O
is	O
very	O
reasonable	O
from	O
the	O
imple-	O
mentation	O
point	O
of	O
view	O
,	O
because	O
it	O
is	O
en-	O
ables	O
to	O
create	O
and	O
maintain	O
general	O
param-	O
eters	O
of	O
even	O
very	O
large	O
sets	O
of	O
similar	O
(	O
but	O
not	O
neccessarily	O
equal	O
)	O
networks	O
.	O
w	O
(	O
cid:73	O
)	O
so	O
the	O
weights	O
can	O
be	O
implemented	O
in	O
a	O
square	O
weight	B
matrix	I
w	O
or	O
,	O
optionally	O
,	O
in	O
a	O
weight	B
vector	I
w	O
with	O
the	O
row	O
num-	O
1	O
note	O
:	O
in	O
some	O
of	O
the	O
cited	O
literature	O
i	O
and	O
j	O
could	O
be	O
interchanged	O
in	O
wi	O
,	O
j	O
.	O
here	O
,	O
a	O
consistent	O
stan-	O
dard	O
does	O
not	O
exist	O
.	O
but	O
in	O
this	O
text	O
i	O
try	O
to	O
use	O
the	O
notation	O
i	O
found	O
more	O
frequently	O
and	O
in	O
the	O
more	O
signiﬁcant	O
citations	O
.	O
ber	O
of	O
the	O
matrix	O
indicating	O
where	O
the	O
con-	O
nection	O
begins	O
,	O
and	O
the	O
column	O
number	O
of	O
the	O
matrix	O
indicating	O
,	O
which	O
neuron	O
is	O
the	O
target	B
.	O
indeed	O
,	O
in	O
this	O
case	O
the	O
numeric	O
0	O
marks	O
a	O
non-existing	O
connection	B
.	O
this	O
matrix	O
representation	O
is	O
also	O
called	O
hin-	O
ton	O
diagram2	O
.	O
the	O
neurons	O
and	O
connections	O
comprise	O
the	O
following	O
components	O
and	O
variables	O
(	O
i	O
’	O
m	O
following	O
the	O
path	O
of	O
the	O
data	O
within	O
a	O
neuron	O
,	O
which	O
is	O
according	O
to	O
ﬁg	O
.	O
3.1	O
on	O
the	O
facing	O
page	O
in	O
top-down	B
direction	O
)	O
:	O
3.2.1	O
connections	O
carry	O
information	O
that	O
is	O
processed	O
by	O
neurons	O
data	O
are	O
transferred	O
between	O
neurons	O
via	O
connections	O
with	O
the	O
connecting	O
weight	B
be-	O
ing	O
either	O
excitatory	O
or	O
inhibitory	O
.	O
the	O
deﬁnition	O
of	O
connections	O
has	O
already	O
been	O
included	O
in	O
the	O
deﬁnition	O
of	O
the	O
neural	O
net-	O
work	O
.	O
be	O
set	O
weights	O
the	O
method	O
connection	B
snipe	O
:	O
can	O
neuralnetwork.setsynapse	O
.	O
using	O
3.2.2	O
the	O
propagation	B
function	I
converts	O
vector	O
inputs	O
to	O
scalar	O
network	O
inputs	O
looking	O
at	O
a	O
neuron	O
j	O
,	O
we	O
will	O
usually	O
ﬁnd	O
a	O
lot	O
of	O
neurons	O
with	O
a	O
connection	B
to	O
j	O
,	O
i.e	O
.	O
which	O
transfer	O
their	O
output	O
to	O
j	O
.	O
2	O
note	O
that	O
,	O
here	O
again	O
,	O
in	O
some	O
of	O
the	O
cited	O
liter-	O
ature	O
axes	O
and	O
rows	O
could	O
be	O
interchanged	O
.	O
the	O
published	O
literature	O
is	O
not	O
consistent	O
here	O
,	O
as	O
well	O
.	O
34	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
3.2	O
components	O
of	O
neural	O
networks	O
inputs	O
for	O
a	O
neuron	O
j	O
the	O
propagation	O
func-	O
tion	O
receives	O
the	O
outputs	O
oi1	O
,	O
.	O
.	O
.	O
,	O
oin	O
of	O
other	O
neurons	O
i1	O
,	O
i2	O
,	O
.	O
.	O
.	O
,	O
in	O
(	O
which	O
are	O
con-	O
nected	O
to	O
j	O
)	O
,	O
and	O
transforms	O
them	O
in	O
con-	O
manages	O
sideration	O
of	O
the	O
connecting	O
weights	O
wi	O
,	O
j	O
into	O
the	O
network	B
input	I
netj	O
that	O
can	O
be	O
fur-	O
ther	O
processed	O
by	O
the	O
activation	B
function	I
.	O
thus	O
,	O
the	O
network	B
input	I
is	O
the	O
result	O
of	O
the	O
propagation	B
function	I
.	O
deﬁnition	O
func-	O
tion	O
and	O
let	O
i	O
=	O
{	O
i1	O
,	O
i2	O
,	O
.	O
.	O
.	O
,	O
in	O
}	O
be	O
the	O
set	O
of	O
neurons	O
,	O
such	O
that	O
∀z	O
∈	O
{	O
1	O
,	O
.	O
.	O
.	O
,	O
n	O
}	O
:	O
∃wiz	O
,	O
j	O
.	O
then	O
the	O
network	B
input	I
of	O
j	O
,	O
called	O
netj	O
,	O
is	O
calculated	O
by	O
the	O
propagation	B
function	I
fprop	O
as	O
follows	O
:	O
3.3	O
network	O
(	O
propagation	O
input	O
)	O
.	O
netj	O
=	O
fprop	O
(	O
oi1	O
,	O
.	O
.	O
.	O
,	O
oin	O
,	O
wi1	O
,	O
j	O
,	O
.	O
.	O
.	O
,	O
win	O
,	O
j	O
)	O
(	O
3.1	O
)	O
here	O
the	O
weighted	B
sum	I
is	O
very	O
popular	O
:	O
the	O
multiplication	O
of	O
the	O
output	O
of	O
each	O
neuron	O
i	O
by	O
wi	O
,	O
j	O
,	O
and	O
the	O
summation	O
of	O
the	O
results	O
:	O
netj	O
=x	O
i∈i	O
(	O
oi	O
·	O
wi	O
,	O
j	O
)	O
(	O
3.2	O
)	O
figure	O
3.1	O
:	O
data	O
processing	O
of	O
a	O
neuron	O
.	O
the	O
activation	B
function	I
of	O
a	O
neuron	O
implies	O
the	O
threshold	B
value	I
.	O
snipe	O
:	O
the	O
propagation	B
function	I
in	O
snipe	O
was	O
implemented	O
using	O
the	O
weighted	B
sum	I
.	O
3.2.3	O
the	O
activation	B
is	O
the	O
''	O
switching	O
status	O
''	O
of	O
a	O
neuron	O
based	O
on	O
the	O
model	O
of	O
nature	O
every	O
neuron	O
is	O
,	O
to	O
a	O
certain	O
extent	O
,	O
at	O
all	O
times	O
active	O
,	O
excited	O
or	O
whatever	O
you	O
will	O
call	O
it	O
.	O
the	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
35	O
propagierungsfunktion	O
(	O
oft	O
gewichtete	O
summe	O
,	O
verarbeitet	O
eingaben	O
zur	O
netzeingabe	O
)	O
ausgabefunktion	O
(	O
erzeugt	O
aus	O
aktivierung	O
die	O
ausgabe	O
,	O
ist	O
oft	O
identität	O
)	O
aktivierungsfunktion	O
(	O
erzeugt	O
aus	O
netzeingabe	O
und	O
alter	O
aktivierung	O
die	O
neue	O
aktivierung	O
)	O
eingaben	O
anderer	O
neuronen	O
netzeingabeaktivierungausgabe	O
zu	O
anderen	O
neuronen	O
propagation	B
function	I
(	O
often	O
weighted	B
sum	I
,	O
transforms	O
outputs	O
of	O
other	O
neurons	O
to	O
net	O
input	O
)	O
output	B
function	I
(	O
often	O
identity	O
function	O
,	O
transforms	O
activation	B
to	O
output	O
for	O
other	O
neurons	O
)	O
activation	B
function	I
(	O
transforms	O
net	O
input	O
and	O
sometimes	O
old	O
activation	B
to	O
new	O
activation	B
)	O
data	O
input	O
of	O
other	O
neurons	O
network	O
inputactivationdata	O
output	O
to	O
other	O
neurons	O
chapter	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
(	O
fundamental	O
)	O
dkriesel.com	O
how	O
active	O
is	O
a	O
neuron	O
?	O
reactions	O
of	O
the	O
neurons	O
to	O
the	O
input	O
val-	O
ues	O
depend	O
on	O
this	O
activation	B
state	O
.	O
the	O
activation	B
state	O
indicates	O
the	O
extent	O
of	O
a	O
neuron	O
’	O
s	O
activation	B
and	O
is	O
often	O
shortly	O
re-	O
ferred	O
to	O
as	O
activation	B
.	O
its	O
formal	O
deﬁni-	O
tion	O
is	O
included	O
in	O
the	O
following	O
deﬁnition	O
of	O
the	O
activation	B
function	I
.	O
but	O
generally	O
,	O
it	O
can	O
be	O
deﬁned	O
as	O
follows	O
:	O
deﬁnition	O
3.4	O
(	O
activation	B
state	O
/	O
activa-	O
tion	O
in	O
general	O
)	O
.	O
let	O
j	O
be	O
a	O
neuron	O
.	O
the	O
activation	B
state	O
aj	O
,	O
in	O
short	O
activation	B
,	O
is	O
explicitly	O
assigned	O
to	O
j	O
,	O
indicates	O
the	O
ex-	O
tent	O
of	O
the	O
neuron	O
’	O
s	O
activity	O
and	O
results	O
from	O
the	O
activation	B
function	I
.	O
snipe	O
:	O
it	O
is	O
possible	O
to	O
get	O
and	O
set	O
activa-	O
tion	O
states	O
of	O
neurons	O
by	O
using	O
the	O
meth-	O
ods	O
getactivation	O
or	O
setactivation	O
in	O
the	O
class	O
neuralnetwork	O
.	O
3.2.5	O
the	O
activation	B
function	I
determines	O
the	O
activation	B
of	O
a	O
neuron	O
dependent	O
on	O
network	B
input	I
and	O
treshold	O
value	O
at	O
a	O
certain	O
time	O
–	O
as	O
we	O
have	O
already	O
learned	O
–	O
the	O
activation	B
aj	O
of	O
a	O
neuron	O
j	O
depends	O
on	O
the	O
previous3	O
activation	B
state	O
of	O
the	O
neuron	O
and	O
the	O
external	O
input	O
.	O
deﬁnition	O
3.6	O
(	O
activation	B
function	I
and	O
activation	B
)	O
.	O
let	O
j	O
be	O
a	O
neuron	O
.	O
the	O
ac-	O
tivation	O
function	B
is	O
deﬁned	O
as	O
aj	O
(	O
t	O
)	O
=	O
fact	O
(	O
netj	O
(	O
t	O
)	O
,	O
aj	O
(	O
t	O
−	O
1	O
)	O
,	O
θj	O
)	O
.	O
it	O
transforms	O
the	O
network	B
input	I
netj	O
,	O
(	O
cid:74	O
)	O
fact	O
as	O
well	O
as	O
the	O
previous	O
activation	B
state	O
aj	O
(	O
t	O
−	O
1	O
)	O
into	O
a	O
new	O
activation	B
state	O
aj	O
(	O
t	O
)	O
,	O
with	O
the	O
threshold	B
value	I
θ	O
playing	O
an	O
im-	O
portant	O
role	O
,	O
as	O
already	O
mentioned	O
.	O
(	O
3.3	O
)	O
calculates	O
activation	B
3.2.4	O
neurons	O
get	O
activated	O
if	O
the	O
network	B
input	I
exceeds	O
their	O
treshold	O
value	O
near	O
the	O
threshold	B
value	I
,	O
the	O
activation	B
function	I
of	O
a	O
neuron	O
reacts	O
particularly	O
sensitive	O
.	O
from	O
the	O
biological	O
point	O
of	O
view	O
the	O
threshold	B
value	I
represents	O
the	O
threshold	O
at	O
which	O
a	O
neuron	O
starts	O
ﬁr-	O
ing	O
.	O
the	O
threshold	B
value	I
is	O
also	O
mostly	O
included	O
in	O
the	O
deﬁnition	O
of	O
the	O
activation	B
function	I
,	O
but	O
generally	O
the	O
deﬁnition	O
is	O
the	O
following	O
:	O
deﬁnition	O
3.5	O
(	O
threshold	B
value	I
in	O
gen-	O
eral	O
)	O
.	O
let	O
j	O
be	O
a	O
neuron	O
.	O
the	O
threshold	B
value	I
θj	O
is	O
uniquely	O
assigned	O
to	O
j	O
and	O
marks	O
the	O
position	O
of	O
the	O
maximum	O
gradi-	O
ent	O
value	O
of	O
the	O
activation	B
function	I
.	O
unlike	O
the	O
other	O
variables	O
within	O
the	O
neu-	O
ral	O
network	O
(	O
particularly	O
unlike	O
the	O
ones	O
deﬁned	O
so	O
far	O
)	O
the	O
activation	B
function	I
is	O
often	O
deﬁned	O
globally	O
for	O
all	O
neurons	O
or	O
at	O
least	O
for	O
a	O
set	O
of	O
neurons	O
and	O
only	O
the	O
threshold	O
values	O
are	O
diﬀerent	O
for	O
each	O
neu-	O
ron	O
.	O
we	O
should	O
also	O
keep	O
in	O
mind	O
that	O
the	O
threshold	O
values	O
can	O
be	O
changed	O
,	O
for	O
example	O
by	O
a	O
learning	B
procedure	O
.	O
so	O
it	O
can	O
in	O
particular	O
become	O
necessary	O
to	O
re-	O
late	O
the	O
threshold	B
value	I
to	O
the	O
time	O
and	O
to	O
write	O
,	O
for	O
instance	O
θj	O
as	O
θj	O
(	O
t	O
)	O
(	O
but	O
for	O
rea-	O
sons	O
of	O
clarity	O
,	O
i	O
omitted	O
this	O
here	O
)	O
.	O
the	O
activation	B
function	I
is	O
also	O
called	O
transfer	B
function	I
.	O
3	O
the	O
previous	O
activation	B
is	O
not	O
always	O
relevant	O
for	O
the	O
current	O
–	O
we	O
will	O
see	O
examples	O
for	O
both	O
vari-	O
ants	O
.	O
highest	O
point	O
of	O
sensation	O
θ	O
(	O
cid:73	O
)	O
36	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
3.2	O
components	O
of	O
neural	O
networks	O
snipe	O
:	O
in	O
snipe	O
,	O
activation	B
functions	O
are	O
generalized	O
to	O
neuron	O
behaviors	O
.	O
such	O
behaviors	O
can	O
represent	O
just	O
normal	O
acti-	O
vation	O
functions	O
,	O
or	O
even	O
incorporate	O
in-	O
ternal	O
states	O
and	O
dynamics	O
.	O
correspond-	O
ing	O
parts	O
of	O
snipe	O
can	O
be	O
found	O
in	O
the	O
package	O
neuronbehavior	O
,	O
which	O
also	O
con-	O
tains	O
some	O
of	O
the	O
activation	B
functions	O
in-	O
troduced	O
in	O
the	O
next	O
section	O
.	O
the	O
inter-	O
face	O
neuronbehavior	O
allows	O
for	O
implemen-	O
tation	O
of	O
custom	O
behaviors	O
.	O
objects	O
that	O
inherit	O
from	O
this	O
interface	O
can	O
be	O
passed	O
to	O
a	O
neuralnetworkdescriptor	O
instance	O
.	O
it	O
is	O
possible	O
to	O
deﬁne	O
individual	O
behaviors	O
per	O
neuron	O
layer	O
.	O
3.2.6	O
common	O
activation	B
functions	O
the	O
simplest	O
activation	B
function	I
is	O
the	O
bi-	O
nary	O
threshold	O
function	O
(	O
ﬁg	O
.	O
3.2	O
on	O
the	O
next	O
page	O
)	O
,	O
which	O
can	O
only	O
take	O
on	O
two	O
val-	O
ues	O
(	O
also	O
referred	O
to	O
as	O
heaviside	O
func-	O
tion	O
)	O
.	O
if	O
the	O
input	O
is	O
above	O
a	O
certain	O
threshold	O
,	O
the	O
function	B
changes	O
from	O
one	O
value	O
to	O
another	O
,	O
but	O
otherwise	O
remains	O
constant	O
.	O
this	O
implies	O
that	O
the	O
function	B
is	O
not	O
diﬀerentiable	O
at	O
the	O
threshold	O
and	O
for	O
the	O
rest	O
the	O
derivative	O
is	O
0.	O
due	O
to	O
this	O
fact	O
,	O
backpropagation	B
learning	O
,	O
for	O
ex-	O
ample	O
,	O
is	O
impossible	O
(	O
as	O
we	O
will	O
see	O
later	O
)	O
.	O
also	O
very	O
popular	O
is	O
the	O
fermi	O
function	B
or	O
logistic	B
function	I
(	O
ﬁg	O
.	O
3.2	O
)	O
1	O
1	O
+	O
e−x	O
,	O
(	O
3.4	O
)	O
which	O
maps	O
to	O
the	O
range	O
of	O
values	O
of	O
(	O
0	O
,	O
1	O
)	O
and	O
the	O
hyperbolic	B
tangent	I
(	O
ﬁg	O
.	O
3.2	O
)	O
which	O
maps	O
to	O
(	O
−1	O
,	O
1	O
)	O
.	O
both	O
functions	O
are	O
diﬀerentiable	O
.	O
the	O
fermi	O
function	B
can	O
be	O
expanded	O
by	O
a	O
temperature	O
parameter	O
t	O
into	O
the	O
form	O
t	O
(	O
cid:73	O
)	O
1	O
1	O
+	O
e	O
−x	O
t	O
.	O
(	O
3.5	O
)	O
the	O
smaller	O
this	O
parameter	O
,	O
the	O
more	O
does	O
it	O
compress	O
the	O
function	B
on	O
the	O
x	O
axis	O
.	O
thus	O
,	O
one	O
can	O
arbitrarily	O
approximate	O
the	O
heaviside	O
function	B
.	O
incidentally	O
,	O
there	O
ex-	O
ist	O
activation	B
functions	O
which	O
are	O
not	O
ex-	O
plicitly	O
deﬁned	O
but	O
depend	O
on	O
the	O
input	O
ac-	O
cording	O
to	O
a	O
random	O
distribution	O
(	O
stochas-	O
tic	O
activation	B
function	I
)	O
.	O
a	O
alternative	O
to	O
the	O
hypberbolic	O
tangent	O
that	O
is	O
really	O
worth	O
mentioning	O
was	O
sug-	O
gested	O
by	O
anguita	O
et	O
al	O
.	O
[	O
apz93	O
]	O
,	O
who	O
have	O
been	O
tired	O
of	O
the	O
slowness	O
of	O
the	O
work-	O
stations	O
back	O
in	O
1993.	O
thinking	O
about	O
how	O
to	O
make	O
neural	O
network	O
propagations	O
faster	O
,	O
they	O
quickly	O
identiﬁed	O
the	O
approx-	O
imation	O
of	O
the	O
e-function	O
used	O
in	O
the	O
hy-	O
perbolic	O
tangent	O
as	O
one	O
of	O
the	O
causes	O
of	O
slowness	O
.	O
consequently	O
,	O
they	O
``	O
engineered	O
''	O
an	O
approximation	B
to	O
the	O
hyperbolic	O
tan-	O
gent	O
,	O
just	O
using	O
two	O
parabola	O
pieces	O
and	O
two	O
half-lines	O
.	O
at	O
the	O
price	O
of	O
delivering	O
a	O
slightly	O
smaller	O
range	O
of	O
values	O
than	O
the	O
hyperbolic	B
tangent	I
(	O
[	O
−0.96016	O
;	O
0.96016	O
]	O
in-	O
stead	O
of	O
[	O
−1	O
;	O
1	O
]	O
)	O
,	O
dependent	O
on	O
what	O
cpu	O
one	O
uses	O
,	O
it	O
can	O
be	O
calculated	O
200	O
times	O
faster	O
because	O
it	O
just	O
needs	O
two	O
multipli-	O
cations	O
and	O
one	O
addition	O
.	O
what	O
’	O
s	O
more	O
,	O
it	O
has	O
some	O
other	O
advantages	O
that	O
will	O
be	O
mentioned	O
later	O
.	O
snipe	O
:	O
the	O
activation	B
functions	O
intro-	O
duced	O
here	O
are	O
implemented	O
within	O
the	O
classes	O
fermi	O
and	O
tangenshyperbolicus	O
,	O
both	O
of	O
which	O
are	O
located	O
in	O
the	O
package	O
neuronbehavior	O
.	O
the	O
fast	O
hyperbolic	O
tan-	O
gent	O
approximation	B
is	O
located	O
within	O
the	O
class	O
tangenshyperbolicusanguita	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
37	O
chapter	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
(	O
fundamental	O
)	O
dkriesel.com	O
3.2.7	O
an	O
output	B
function	I
may	O
be	O
used	O
to	O
process	O
the	O
activation	B
once	O
again	O
the	O
output	B
function	I
of	O
a	O
neuron	O
j	O
cal-	O
culates	O
the	O
values	O
which	O
are	O
transferred	O
to	O
the	O
other	O
neurons	O
connected	O
to	O
j.	O
more	O
formally	O
:	O
deﬁnition	O
3.7	O
(	O
output	B
function	I
)	O
.	O
let	O
j	O
be	O
a	O
neuron	O
.	O
the	O
output	B
function	I
fout	O
(	O
aj	O
)	O
=	O
oj	O
(	O
3.6	O
)	O
informs	O
other	O
neurons	O
calculates	O
the	O
output	O
value	O
oj	O
of	O
the	O
neu-	O
(	O
cid:74	O
)	O
fout	O
ron	O
j	O
from	O
its	O
activation	B
state	O
aj	O
.	O
generally	O
,	O
the	O
output	B
function	I
is	O
deﬁned	O
globally	O
,	O
too	O
.	O
often	O
this	O
function	B
is	O
the	O
identity	O
,	O
i.e	O
.	O
the	O
activation	B
aj	O
is	O
directly	O
output4	O
:	O
fout	O
(	O
aj	O
)	O
=	O
aj	O
,	O
so	O
oj	O
=	O
aj	O
(	O
3.7	O
)	O
unless	O
explicitly	O
speciﬁed	O
diﬀerently	O
,	O
we	O
will	O
use	O
the	O
identity	O
as	O
output	B
function	I
within	O
this	O
text	O
.	O
3.2.8	O
learning	B
strategies	O
adjust	O
a	O
network	O
to	O
ﬁt	O
our	O
needs	O
since	O
we	O
will	O
address	O
this	O
subject	O
later	O
in	O
detail	O
and	O
at	O
ﬁrst	O
want	O
to	O
get	O
to	O
know	O
the	O
principles	O
of	O
neural	O
network	O
structures	O
,	O
i	O
will	O
only	O
provide	O
a	O
brief	O
and	O
general	O
deﬁ-	O
nition	O
here	O
:	O
4	O
other	O
deﬁnitions	O
of	O
output	O
functions	O
may	O
be	O
use-	O
ful	O
if	O
the	O
range	O
of	O
values	O
of	O
the	O
activation	B
function	I
is	O
not	O
suﬃcient	O
.	O
figure	O
3.2	O
:	O
various	O
popular	O
activation	B
func-	O
tions	O
,	O
from	O
top	O
to	O
bottom	O
:	O
heaviside	O
or	O
binary	B
threshold	I
function	I
,	O
fermi	O
function	B
,	O
hyperbolic	B
tangent	I
.	O
the	O
fermi	O
function	B
was	O
expanded	O
by	O
a	O
temperature	O
parameter	O
.	O
the	O
original	O
fermi	O
function	B
is	O
represented	O
by	O
dark	O
colors	O
,	O
the	O
tem-	O
perature	O
parameters	O
of	O
the	O
modiﬁed	O
fermi	O
func-	O
2	O
,	O
1	O
tions	O
are	O
,	O
ordered	O
ascending	O
by	O
steepness	O
,	O
1	O
5	O
,	O
10	O
und	O
1	O
1	O
25	O
.	O
38	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
−1−0.5	O
0	O
0.5	O
1−4−2	O
0	O
2	O
4f	O
(	O
x	O
)	O
xheaviside	O
function	B
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1−4−2	O
0	O
2	O
4f	O
(	O
x	O
)	O
xfermi	O
function	B
with	O
temperature	O
parameter−1−0.8−0.6−0.4−0.2	O
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1−4−2	O
0	O
2	O
4tanh	O
(	O
x	O
)	O
xhyperbolic	O
tangent	O
network	O
of	O
layers	O
dkriesel.com	O
3.3	O
network	O
topologies	O
deﬁnition	O
3.8	O
(	O
general	O
learning	B
rule	O
)	O
.	O
the	O
learning	B
strategy	I
is	O
an	O
algorithm	B
that	O
can	O
be	O
used	O
to	O
change	O
and	O
thereby	O
train	O
the	O
neural	O
network	O
,	O
so	O
that	O
the	O
net-	O
work	O
produces	O
a	O
desired	O
output	O
for	O
a	O
given	O
input	O
.	O
3.3	O
network	O
topologies	O
after	O
we	O
have	O
become	O
acquainted	O
with	O
the	O
composition	O
of	O
the	O
elements	O
of	O
a	O
neural	O
network	O
,	O
i	O
want	O
to	O
give	O
an	O
overview	O
of	O
the	O
usual	O
topologies	O
(	O
=	O
designs	O
)	O
of	O
neural	O
networks	O
,	O
i.e	O
.	O
to	O
construct	O
networks	O
con-	O
sisting	O
of	O
these	O
elements	O
.	O
every	O
topology	B
described	O
in	O
this	O
text	O
is	O
illustrated	O
by	O
a	O
map	O
and	O
its	O
hinton	O
diagram	O
so	O
that	O
the	O
reader	O
can	O
immediately	O
see	O
the	O
character-	O
istics	O
and	O
apply	O
them	O
to	O
other	O
networks	O
.	O
in	O
the	O
hinton	O
diagram	O
the	O
dotted	O
weights	O
are	O
represented	O
by	O
light	O
grey	O
ﬁelds	O
,	O
the	O
solid	O
ones	O
by	O
dark	O
grey	O
ﬁelds	O
.	O
the	O
input	O
and	O
output	O
arrows	O
,	O
which	O
were	O
added	O
for	O
reasons	O
of	O
clarity	O
,	O
can	O
not	O
be	O
found	O
in	O
the	O
hinton	O
diagram	O
.	O
in	O
order	O
to	O
clarify	O
that	O
the	O
connections	O
are	O
between	O
the	O
line	O
neu-	O
rons	O
and	O
the	O
column	O
neurons	O
,	O
i	O
have	O
in-	O
serted	O
the	O
small	O
arrow	O
(	O
cid:31	O
)	O
in	O
the	O
upper-left	O
cell	O
.	O
snipe	O
:	O
snipe	O
is	O
designed	O
for	O
realization	O
of	O
arbitrary	O
network	O
topologies	O
.	O
in	O
this	O
respect	O
,	O
snipe	O
deﬁnes	O
diﬀerent	O
kinds	O
of	O
synapses	B
depending	O
on	O
their	O
source	O
and	O
their	O
target	B
.	O
any	O
kind	O
of	O
synapse	B
can	O
sep-	O
arately	O
be	O
allowed	O
or	O
forbidden	O
for	O
a	O
set	O
of	O
networks	O
using	O
the	O
setallowed	O
methods	O
in	O
a	O
neuralnetworkdescriptor	O
instance	O
.	O
3.3.1	O
feedforward	B
networks	O
consist	O
of	O
layers	O
and	O
connections	O
towards	O
each	O
following	O
layer	B
feedforward	O
in	O
this	O
text	O
feedforward	B
net-	O
works	O
(	O
ﬁg	O
.	O
3.3	O
on	O
the	O
following	O
page	O
)	O
are	O
the	O
networks	O
we	O
will	O
ﬁrst	O
explore	O
(	O
even	O
if	O
we	O
will	O
use	O
diﬀerent	O
topologies	O
later	O
)	O
.	O
the	O
neurons	O
are	O
grouped	O
in	O
the	O
following	O
lay-	O
ers	O
:	O
one	O
input	B
layer	I
,	O
n	O
hidden	O
pro-	O
cessing	O
layers	O
(	O
invisible	O
from	O
the	O
out-	O
side	O
,	O
that	O
’	O
s	O
why	O
the	O
neurons	O
are	O
also	O
re-	O
ferred	O
to	O
as	O
hidden	O
neurons	O
)	O
and	O
one	O
out-	O
put	O
layer	B
.	O
in	O
a	O
feedforward	B
network	O
each	O
neuron	O
in	O
one	O
layer	B
has	O
only	O
directed	O
con-	O
nections	O
to	O
the	O
neurons	O
of	O
the	O
next	O
layer	B
(	O
towards	O
the	O
output	B
layer	I
)	O
.	O
in	O
ﬁg	O
.	O
3.3	O
on	O
the	O
next	O
page	O
the	O
connections	O
permitted	O
for	O
a	O
feedforward	B
network	O
are	O
represented	O
by	O
solid	O
lines	O
.	O
we	O
will	O
often	O
be	O
confronted	O
with	O
feedforward	B
networks	O
in	O
which	O
every	O
neuron	O
i	O
is	O
connected	O
to	O
all	O
neurons	O
of	O
the	O
next	O
layer	B
(	O
these	O
layers	O
are	O
called	O
com-	O
pletely	O
linked	O
)	O
.	O
to	O
prevent	O
naming	O
con-	O
ﬂicts	O
the	O
output	O
neurons	O
are	O
often	O
referred	O
to	O
as	O
ω.	O
deﬁnition	O
3.9	O
(	O
feedforward	B
network	O
)	O
.	O
the	O
neuron	B
layers	I
of	O
a	O
feedforward	B
net-	O
work	O
(	O
ﬁg	O
.	O
3.3	O
on	O
the	O
following	O
page	O
)	O
are	O
clearly	O
separated	O
:	O
one	O
input	B
layer	I
,	O
one	O
output	B
layer	I
and	O
one	O
or	O
more	O
processing	O
layers	O
which	O
are	O
invisible	O
from	O
the	O
outside	O
(	O
also	O
called	O
hidden	O
layers	O
)	O
.	O
connections	O
are	O
only	O
permitted	O
to	O
neurons	O
of	O
the	O
fol-	O
lowing	O
layer	B
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
39	O
shortcuts	O
skip	O
layers	O
chapter	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
(	O
fundamental	O
)	O
dkriesel.com	O
3.3.1.1	O
shortcut	B
connections	I
skip	O
layers	O
i1	O
i2	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
*uuuuuuuuuuuuuuuuuuuuuuuuuu	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
aaaaaaaaa	O
aaaaaaaaa	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
gfed	O
@	O
abch1	O
gfed	O
@	O
abch2	O
gfed	O
@	O
abch3	O
*uuuuuuuuuuuuuuuuuuuuuuuuuu	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
aaaaaaaaa	O
aaaaaaaaa	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
gfed	O
@	O
abcω2	O
gfed	O
@	O
abcω1	O
some	O
feedforward	B
networks	O
permit	O
the	O
so-	O
called	O
shortcut	B
connections	I
(	O
ﬁg	O
.	O
3.4	O
on	O
the	O
next	O
page	O
)	O
:	O
connections	O
that	O
skip	O
one	O
or	O
more	O
levels	O
.	O
these	O
connections	O
may	O
only	O
be	O
directed	O
towards	O
the	O
output	B
layer	I
,	O
too	O
.	O
deﬁnition	O
3.10	O
(	O
feedforward	B
network	O
with	O
shortcut	B
connections	I
)	O
.	O
similar	O
to	O
the	O
feedforward	B
network	O
,	O
but	O
the	O
connections	O
may	O
not	O
only	O
be	O
directed	O
towards	O
the	O
next	O
layer	B
but	O
also	O
towards	O
any	O
other	O
subse-	O
quent	O
layer	B
.	O
3.3.2	O
recurrent	O
networks	O
have	O
inﬂuence	O
on	O
themselves	O
i1	O
i2	O
h1	O
h2	O
h3	O
ω1	O
ω2	O
(	O
cid:31	O
)	O
i1	O
i2	O
h1	O
h2	O
h3	O
ω1	O
ω2	O
figure	O
3.3	O
:	O
a	O
feedforward	B
network	O
with	O
three	O
layers	O
:	O
two	O
input	O
neurons	O
,	O
three	O
hidden	O
neurons	O
and	O
two	O
output	O
neurons	O
.	O
characteristic	O
for	O
the	O
hinton	O
diagram	O
of	O
completely	O
linked	O
feedforward	B
networks	O
is	O
the	O
formation	O
of	O
blocks	O
above	O
the	O
diagonal	O
.	O
recurrence	B
is	O
deﬁned	O
as	O
the	O
process	O
of	O
a	O
neuron	O
inﬂuencing	O
itself	O
by	O
any	O
means	O
or	O
by	O
any	O
connection	B
.	O
recurrent	O
networks	O
do	O
not	O
always	O
have	O
explicitly	O
deﬁned	O
input	O
or	O
output	O
neurons	O
.	O
therefore	O
in	O
the	O
ﬁgures	O
i	O
omitted	O
all	O
markings	O
that	O
concern	O
this	O
matter	O
and	O
only	O
numbered	O
the	O
neurons	O
.	O
3.3.2.1	O
direct	O
recurrences	O
start	O
and	O
end	O
at	O
the	O
same	O
neuron	O
some	O
networks	O
allow	O
for	O
neurons	O
to	O
be	O
connected	O
to	O
themselves	O
,	O
which	O
is	O
called	O
direct	B
recurrence	I
(	O
or	O
sometimes	O
self-	O
recurrence	B
(	O
ﬁg	O
.	O
3.5	O
on	O
the	O
facing	O
page	O
)	O
.	O
as	O
a	O
result	O
,	O
neurons	O
inhibit	O
and	O
therefore	O
strengthen	O
themselves	O
in	O
order	O
to	O
reach	O
their	O
activation	B
limits	O
.	O
40	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
	O
	O
	O
~	O
*	O
t	O
~	O
*	O
~	O
~	O
t	O
	O
	O
	O
	O
dkriesel.com	O
3.3	O
network	O
topologies	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
1	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
6	O
1	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
4	O
2	O
3	O
4	O
5	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
2	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
7	O
6	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
5	O
7	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
3	O
(	O
cid:31	O
)	O
1	O
2	O
3	O
4	O
5	O
6	O
7	O
gfed	O
@	O
abch3	O
figure	O
3.5	O
:	O
a	O
network	O
similar	O
to	O
a	O
feedforward	B
network	O
with	O
directly	O
recurrent	O
neurons	O
.	O
the	O
di-	O
rect	O
recurrences	O
are	O
represented	O
by	O
solid	O
lines	O
and	O
exactly	O
correspond	O
to	O
the	O
diagonal	O
in	O
the	O
hinton	O
diagram	O
matrix	O
.	O
i1	O
gfed	O
@	O
abc	O
gfed	O
@	O
abcω1	O
gfed	O
@	O
abch2	O
i2	O
gfed	O
@	O
abc	O
gfed	O
@	O
abcω2	O
i1	O
i2	O
h1	O
h2	O
h3	O
ω1	O
ω2	O
gfed	O
@	O
abch1	O
(	O
cid:31	O
)	O
i1	O
i2	O
h1	O
h2	O
h3	O
ω1	O
ω2	O
figure	O
3.4	O
:	O
a	O
feedforward	B
network	O
with	O
short-	O
cut	O
connections	O
,	O
which	O
are	O
represented	O
by	O
solid	O
lines	O
.	O
on	O
the	O
right	O
side	O
of	O
the	O
feedforward	B
blocks	O
new	O
connections	O
have	O
been	O
added	O
to	O
the	O
hinton	O
diagram	O
.	O
deﬁnition	O
3.11	O
(	O
direct	B
recurrence	I
)	O
.	O
now	O
we	O
expand	O
the	O
feedforward	B
network	O
by	O
connecting	O
a	O
neuron	O
j	O
to	O
itself	O
,	O
with	O
the	O
weights	O
of	O
these	O
connections	O
being	O
referred	O
to	O
as	O
wj	O
,	O
j	O
.	O
in	O
other	O
words	O
:	O
the	O
diagonal	O
of	O
the	O
weight	B
matrix	I
w	O
may	O
be	O
diﬀerent	O
from	O
0.	O
neurons	O
inﬂuence	O
themselves	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
41	O
	O
	O
	O
	O
	O
	O
+	O
+	O
~	O
~	O
*	O
*	O
s	O
s	O
	O
	O
t	O
t	O
~	O
~	O
*	O
*	O
~	O
~	O
~	O
~	O
t	O
t	O
	O
	O
	O
	O
v	O
v	O
 	O
 	O
)	O
)	O
v	O
v	O
u	O
u	O
 	O
 	O
v	O
v	O
)	O
)	O
v	O
v	O
 	O
 	O
v	O
v	O
 	O
 	O
u	O
u	O
v	O
v	O
v	O
v	O
chapter	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
(	O
fundamental	O
)	O
dkriesel.com	O
3.3.2.2	O
indirect	O
recurrences	O
can	O
inﬂuence	O
their	O
starting	O
neuron	O
only	O
by	O
making	O
detours	O
if	O
connections	O
are	O
allowed	O
towards	O
the	O
in-	O
put	O
layer	B
,	O
they	O
will	O
be	O
called	O
indirect	O
re-	O
currences	O
.	O
then	O
a	O
neuron	O
j	O
can	O
use	O
in-	O
direct	O
forwards	O
connections	O
to	O
inﬂuence	O
it-	O
self	O
,	O
for	O
example	O
,	O
by	O
inﬂuencing	O
the	O
neu-	O
rons	O
of	O
the	O
next	O
layer	B
and	O
the	O
neurons	O
of	O
this	O
next	O
layer	B
inﬂuencing	O
j	O
(	O
ﬁg	O
.	O
3.6	O
)	O
.	O
deﬁnition	O
3.12	O
(	O
indirect	B
recurrence	I
)	O
.	O
again	O
our	O
network	O
is	O
based	O
on	O
a	O
feedfor-	O
ward	O
network	O
,	O
now	O
with	O
additional	O
connec-	O
tions	O
between	O
neurons	O
and	O
their	O
preceding	O
layer	B
being	O
allowed	O
.	O
therefore	O
,	O
below	O
the	O
diagonal	O
of	O
w	O
is	O
diﬀerent	O
from	O
0	O
.	O
3.3.2.3	O
lateral	O
recurrences	O
connect	O
neurons	O
within	O
one	O
layer	B
connections	O
between	O
neurons	O
within	O
one	O
layer	B
are	O
called	O
lateral	O
recurrences	O
(	O
ﬁg	O
.	O
3.7	O
on	O
the	O
facing	O
page	O
)	O
.	O
here	O
,	O
each	O
neuron	O
often	O
inhibits	O
the	O
other	O
neurons	O
of	O
the	O
layer	B
and	O
strengthens	O
itself	O
.	O
as	O
a	O
re-	O
sult	O
only	O
the	O
strongest	O
neuron	O
becomes	O
ac-	O
tive	O
(	O
winner-takes-all	B
scheme	I
)	O
.	O
deﬁnition	O
3.13	O
(	O
lateral	B
recurrence	I
)	O
.	O
a	O
laterally	O
recurrent	O
network	O
permits	O
con-	O
nections	O
within	O
one	O
layer	B
.	O
3.3.3	O
completely	O
linked	O
networks	O
allow	O
any	O
possible	O
connection	B
completely	O
linked	O
networks	O
permit	O
connec-	O
tions	O
between	O
all	O
neurons	O
,	O
except	O
for	O
direct	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
1	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
6	O
1	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
4	O
2	O
3	O
4	O
5	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
2	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
7	O
6	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
5	O
7	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
3	O
(	O
cid:31	O
)	O
1	O
2	O
3	O
4	O
5	O
6	O
7	O
figure	O
3.6	O
:	O
a	O
network	O
similar	O
to	O
a	O
feedforward	B
network	O
with	O
indirectly	O
recurrent	O
neurons	O
.	O
the	O
indirect	O
recurrences	O
are	O
represented	O
by	O
solid	O
lines	O
.	O
as	O
we	O
can	O
see	O
,	O
connections	O
to	O
the	O
preceding	O
lay-	O
ers	O
can	O
exist	O
here	O
,	O
too	O
.	O
the	O
ﬁelds	O
that	O
are	O
sym-	O
metric	B
to	O
the	O
feedforward	B
blocks	O
in	O
the	O
hinton	O
diagram	O
are	O
now	O
occupied	O
.	O
42	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
 	O
 	O
)	O
)	O
u	O
u	O
 	O
 	O
8	O
8	O
2	O
2	O
)	O
)	O
x	O
x	O
8	O
8	O
 	O
 	O
x	O
x	O
g	O
g	O
 	O
 	O
u	O
u	O
x	O
x	O
8	O
8	O
2	O
2	O
g	O
g	O
x	O
x	O
8	O
8	O
dkriesel.com	O
3.4	O
the	O
bias	B
neuron	I
?	O
>	O
=	O
<	O
89	O
:	O
;	O
1	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
6	O
1	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
4	O
2	O
3	O
4	O
5	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
2	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
7	O
6	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
5	O
7	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
3	O
(	O
cid:31	O
)	O
1	O
2	O
3	O
4	O
5	O
6	O
7	O
figure	O
3.7	O
:	O
a	O
network	O
similar	O
to	O
a	O
feedforward	B
network	O
with	O
laterally	O
recurrent	O
neurons	O
.	O
the	O
direct	O
recurrences	O
are	O
represented	O
by	O
solid	O
lines	O
.	O
here	O
,	O
recurrences	O
only	O
exist	O
within	O
the	O
layer	B
.	O
in	O
the	O
hinton	O
diagram	O
,	O
ﬁlled	O
squares	O
are	O
con-	O
centrated	O
around	O
the	O
diagonal	O
in	O
the	O
height	O
of	O
the	O
feedforward	B
blocks	O
,	O
but	O
the	O
diagonal	O
is	O
left	O
uncovered	O
.	O
recurrences	O
.	O
furthermore	O
,	O
the	O
connections	O
must	O
be	O
symmetric	O
(	O
ﬁg	O
.	O
3.8	O
on	O
the	O
next	O
page	O
)	O
.	O
a	O
popular	O
example	O
are	O
the	O
self-	O
organizing	O
maps	O
,	O
which	O
will	O
be	O
introduced	O
in	O
chapter	O
10.	O
deﬁnition	O
3.14	O
(	O
complete	O
interconnec-	O
tion	O
)	O
.	O
in	O
this	O
case	O
,	O
every	O
neuron	O
is	O
always	O
allowed	O
to	O
be	O
connected	O
to	O
every	O
other	O
neu-	O
ron	O
–	O
but	O
as	O
a	O
result	O
every	O
neuron	O
can	O
become	O
an	O
input	B
neuron	I
.	O
therefore	O
,	O
di-	O
rect	O
recurrences	O
normally	O
can	O
not	O
be	O
ap-	O
plied	O
here	O
and	O
clearly	O
deﬁned	O
layers	O
do	O
not	O
longer	O
exist	O
.	O
thus	O
,	O
the	O
matrix	O
w	O
may	O
be	O
unequal	O
to	O
0	O
everywhere	O
,	O
except	O
along	O
its	O
diagonal	O
.	O
3.4	O
the	O
bias	B
neuron	I
is	O
a	O
technical	O
trick	O
to	O
consider	O
threshold	O
values	O
as	O
connection	B
weights	O
by	O
now	O
we	O
know	O
that	O
in	O
many	O
network	O
paradigms	O
neurons	O
have	O
a	O
threshold	B
value	I
that	O
indicates	O
when	O
a	O
neuron	O
becomes	O
ac-	O
tive	O
.	O
thus	O
,	O
the	O
threshold	B
value	I
is	O
an	O
activation	B
function	I
parameter	O
of	O
a	O
neu-	O
ron	O
.	O
from	O
the	O
biological	O
point	O
of	O
view	O
this	O
sounds	O
most	O
plausible	O
,	O
but	O
it	O
is	O
com-	O
plicated	O
to	O
access	O
the	O
activation	B
function	I
at	O
runtime	O
in	O
order	O
to	O
train	O
the	O
threshold	B
value	I
.	O
but	O
threshold	O
values	O
θj1	O
,	O
.	O
.	O
.	O
,	O
θjn	O
for	O
neu-	O
rons	O
j1	O
,	O
j2	O
,	O
.	O
.	O
.	O
,	O
jn	O
can	O
also	O
be	O
realized	O
as	O
connecting	O
weight	B
of	O
a	O
continuously	O
ﬁr-	O
ing	O
neuron	O
:	O
for	O
this	O
purpose	O
an	O
addi-	O
tional	O
bias	B
neuron	I
whose	O
output	O
value	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
43	O
+	O
+	O
k	O
k	O
 	O
 	O
)	O
)	O
u	O
u	O
 	O
 	O
+	O
+	O
k	O
k	O
*	O
*	O
j	O
j	O
)	O
)	O
+	O
+	O
k	O
k	O
 	O
 	O
 	O
 	O
u	O
u	O
+	O
+	O
k	O
k	O
chapter	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
(	O
fundamental	O
)	O
dkriesel.com	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
1	O
i	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
25	O
)	O
ttttttttttttttttttttttt	O
ujjjjjjjjjjjjjjjjjjjjjjj	O
o	O
@	O
         	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
          	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
3	O
i	O
89	O
:	O
;	O
54	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
4	O
?	O
>	O
=	O
<	O
)	O
ttttttttttttttttttttttto	O
ujjjjjjjjjjjjjjjjjjjjjjj/	O
@	O
         	O
^	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
^	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
          	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
6	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
7/	O
7	O
1	O
4	O
2	O
3	O
5	O
6	O
(	O
cid:31	O
)	O
1	O
2	O
3	O
4	O
5	O
6	O
7	O
figure	O
3.8	O
:	O
a	O
completely	O
linked	O
network	O
with	O
symmetric	O
connections	O
and	O
without	O
direct	O
recur-	O
rences	O
.	O
in	O
the	O
hinton	O
diagram	O
only	O
the	O
diagonal	O
is	O
left	O
blank	O
.	O
is	O
always	O
1	O
is	O
integrated	O
in	O
the	O
network	O
and	O
connected	O
to	O
the	O
neurons	O
j1	O
,	O
j2	O
,	O
.	O
.	O
.	O
,	O
jn	O
.	O
these	O
new	O
connections	O
get	O
the	O
weights	O
−θj1	O
,	O
.	O
.	O
.	O
,	O
−θjn	O
,	O
i.e	O
.	O
they	O
get	O
the	O
negative	O
threshold	O
values	O
.	O
deﬁnition	O
3.15.	O
a	O
bias	B
neuron	I
is	O
a	O
neuron	O
whose	O
output	O
value	O
is	O
always	O
1	O
and	O
which	O
is	O
represented	O
by	O
it	O
is	O
used	O
to	O
represent	O
neuron	O
biases	O
as	O
con-	O
nection	O
weights	O
,	O
which	O
enables	O
any	O
weight-	O
training	O
algorithm	O
to	O
train	O
the	O
biases	O
at	O
the	O
same	O
time	O
.	O
gfed	O
@	O
abc	O
bias	O
.	O
then	O
the	O
threshold	B
value	I
of	O
the	O
neurons	O
j1	O
,	O
j2	O
,	O
.	O
.	O
.	O
,	O
jn	O
is	O
set	O
to	O
0.	O
now	O
the	O
thresh-	O
old	O
values	O
are	O
implemented	O
as	O
connection	B
weights	O
(	O
ﬁg	O
.	O
3.9	O
on	O
page	O
46	O
)	O
and	O
can	O
di-	O
rectly	O
be	O
trained	O
together	O
with	O
the	O
con-	O
nection	O
weights	O
,	O
which	O
considerably	O
facil-	O
itates	O
the	O
learning	B
process	O
.	O
in	O
other	O
words	O
:	O
instead	O
of	O
including	O
the	O
threshold	B
value	I
in	O
the	O
activation	B
function	I
,	O
it	O
is	O
now	O
included	O
in	O
the	O
propagation	O
func-	O
tion	O
.	O
or	O
even	O
shorter	O
:	O
the	O
threshold	B
value	I
is	O
subtracted	O
from	O
the	O
network	B
input	I
,	O
i.e	O
.	O
it	O
is	O
part	O
of	O
the	O
network	B
input	I
.	O
more	O
for-	O
mally	O
:	O
let	O
j1	O
,	O
j2	O
,	O
.	O
.	O
.	O
,	O
jn	O
be	O
neurons	O
with	O
thresh-	O
old	O
values	O
θj1	O
,	O
.	O
.	O
.	O
,	O
θjn	O
.	O
by	O
inserting	O
a	O
bias	B
neuron	I
whose	O
output	O
value	O
is	O
always	O
1	O
,	O
generating	O
connections	O
between	O
the	O
said	O
bias	B
neuron	I
and	O
the	O
neurons	O
j1	O
,	O
j2	O
,	O
.	O
.	O
.	O
,	O
jn	O
and	O
connections	O
wbias	O
,	O
j1	O
,	O
.	O
.	O
.	O
,	O
wbias	O
,	O
jnwith	O
−θj1	O
,	O
.	O
.	O
.	O
,	O
−θjn	O
,	O
we	O
can	O
set	O
θj1	O
=	O
.	O
.	O
.	O
=	O
θjn	O
=	O
0	O
and	O
weighting	O
these	O
bias	B
neuron	I
replaces	O
thresh	O
.	O
value	O
with	O
weights	O
44	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
i	O
	O
	O
i	O
i	O
)	O
o	O
o	O
	O
	O
o	O
o	O
/	O
/	O
^	O
^	O
5	O
u	O
o	O
	O
	O
@	O
@	O
 	O
^	O
^	O
i	O
)	O
o	O
/	O
/	O
 	O
 	O
@	O
4	O
j	O
j	O
5	O
5	O
u	O
/	O
o	O
o	O
@	O
@	O
 	O
5	O
5	O
 	O
 	O
@	O
^	O
/	O
o	O
o	O
^	O
dkriesel.com	O
3.6	O
orders	O
of	O
activation	B
receive	O
an	O
equivalent	O
neural	O
network	O
whose	O
threshold	O
values	O
are	O
realized	O
by	O
connection	B
weights	O
.	O
undoubtedly	O
,	O
the	O
advantage	O
of	O
the	O
bias	B
neuron	I
is	O
the	O
fact	O
that	O
it	O
is	O
much	O
easier	O
to	O
implement	O
it	O
in	O
the	O
network	O
.	O
one	O
dis-	O
advantage	O
is	O
that	O
the	O
representation	O
of	O
the	O
network	O
already	O
becomes	O
quite	O
ugly	O
with	O
only	O
a	O
few	O
neurons	O
,	O
let	O
alone	O
with	O
a	O
great	O
number	O
of	O
them	O
.	O
by	O
the	O
way	O
,	O
a	O
bias	O
neu-	O
ron	O
is	O
often	O
referred	O
to	O
as	O
on	O
neuron	O
.	O
from	O
now	O
on	O
,	O
the	O
bias	B
neuron	I
is	O
omit-	O
ted	O
for	O
clarity	O
in	O
the	O
following	O
illustrations	O
,	O
but	O
we	O
know	O
that	O
it	O
exists	O
and	O
that	O
the	O
threshold	O
values	O
can	O
simply	O
be	O
treated	O
as	O
weights	O
because	O
of	O
it	O
.	O
snipe	O
:	O
in	O
snipe	O
,	O
a	O
bias	B
neuron	I
was	O
imple-	O
mented	O
instead	O
of	O
neuron-individual	O
biases	O
.	O
the	O
neuron	O
index	O
of	O
the	O
bias	B
neuron	I
is	O
0	O
.	O
||c	O
,	O
x||	O
gauß	O
wvut	O
pqrs	O
wvut	O
pqrsς	O
tanh	B
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
wvut	O
pqrsς	O
fermi	O
(	O
cid:30	O
)	O
onml	O
hijkς	O
onml	O
hijkς	O
fact	O
l|h	O
wvut	O
pqrsς	O
gfed	O
@	O
abc	O
bias	O
figure	O
3.10	O
:	O
diﬀerent	O
types	O
of	O
neurons	O
that	O
will	O
appear	O
in	O
the	O
following	O
text	O
.	O
3.6	O
take	O
care	O
of	O
the	O
order	O
in	O
which	O
neuron	O
activations	O
are	O
calculated	O
for	O
a	O
neural	O
network	O
it	O
is	O
very	O
important	O
in	O
which	O
order	O
the	O
individual	O
neurons	O
re-	O
ceive	O
and	O
process	O
the	O
input	O
and	O
output	O
the	O
results	O
.	O
here	O
,	O
we	O
distinguish	O
two	O
model	O
classes	O
:	O
3.5	O
representing	O
neurons	O
3.6.1	O
synchronous	O
activation	B
we	O
have	O
already	O
seen	O
that	O
we	O
can	O
either	O
write	O
its	O
name	O
or	O
its	O
threshold	B
value	I
into	O
a	O
neuron	O
.	O
another	O
useful	O
representation	O
,	O
which	O
we	O
will	O
use	O
several	O
times	O
in	O
the	O
following	O
,	O
is	O
to	O
illustrate	O
neurons	O
accord-	O
ing	O
to	O
their	O
type	O
of	O
data	O
processing	O
.	O
see	O
ﬁg	O
.	O
3.10	O
for	O
some	O
examples	O
without	O
fur-	O
ther	O
explanation	O
–	O
the	O
diﬀerent	O
types	O
of	O
neurons	O
are	O
explained	O
as	O
soon	O
as	O
we	O
need	O
them	O
.	O
all	O
neurons	O
change	O
their	O
values	O
syn-	O
chronously	O
,	O
i.e	O
.	O
they	O
simultaneously	O
cal-	O
culate	O
network	O
inputs	O
,	O
activation	B
and	O
out-	O
put	O
,	O
and	O
pass	O
them	O
on	O
.	O
synchronous	O
ac-	O
tivation	O
corresponds	O
closest	O
to	O
its	O
biolog-	O
ical	O
counterpart	O
,	O
but	O
it	O
is	O
–	O
if	O
to	O
be	O
im-	O
plemented	O
in	O
hardware	O
–	O
only	O
useful	O
on	O
certain	O
parallel	O
computers	O
and	O
especially	O
not	O
for	O
feedforward	B
networks	O
.	O
this	O
order	B
of	I
activation	I
is	O
the	O
most	O
generic	O
and	O
can	O
be	O
used	O
with	O
networks	O
of	O
arbitrary	O
topol-	O
ogy	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
45	O
chapter	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
(	O
fundamental	O
)	O
dkriesel.com	O
gfed	O
@	O
abcθ1	O
bbbbbbbbb	O
~|||||||||	O
gfed	O
@	O
abcθ2	O
gfed	O
@	O
abcθ3	O
bias	O
gfed	O
@	O
abc	O
−θ1	O
tttttttttt	O
aaaa	O
−θ2	O
aaaa	O
−θ3	O
*tttttttttt	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
0	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
0	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
0	O
figure	O
3.9	O
:	O
two	O
equivalent	O
neural	O
networks	O
,	O
one	O
without	O
bias	B
neuron	I
on	O
the	O
left	O
,	O
one	O
with	O
bias	B
neuron	I
on	O
the	O
right	O
.	O
the	O
neuron	O
threshold	O
values	O
can	O
be	O
found	O
in	O
the	O
neurons	O
,	O
the	O
connecting	O
weights	O
at	O
the	O
connections	O
.	O
furthermore	O
,	O
i	O
omitted	O
the	O
weights	O
of	O
the	O
already	O
existing	O
connections	O
(	O
represented	O
by	O
dotted	O
lines	O
on	O
the	O
right	O
side	O
)	O
.	O
biologically	O
plausible	O
deﬁnition	O
3.16	O
(	O
synchronous	O
activa-	O
tion	O
)	O
.	O
all	O
neurons	O
of	O
a	O
network	O
calculate	O
network	O
inputs	O
at	O
the	O
same	O
time	O
by	O
means	O
of	O
the	O
propagation	B
function	I
,	O
activation	B
by	O
means	O
of	O
the	O
activation	B
function	I
and	O
out-	O
put	O
by	O
means	O
of	O
the	O
output	B
function	I
.	O
af-	O
ter	O
that	O
the	O
activation	B
cycle	O
is	O
complete	O
.	O
snipe	O
:	O
when	O
implementing	O
in	O
software	O
,	O
one	O
could	O
model	O
this	O
very	O
general	O
activa-	O
tion	O
order	O
by	O
every	O
time	O
step	O
calculating	O
and	O
caching	O
every	O
single	O
network	O
input	O
,	O
and	O
after	O
that	O
calculating	O
all	O
activations	O
.	O
this	O
is	O
exactly	O
how	O
it	O
is	O
done	O
in	O
snipe	O
,	O
be-	O
cause	O
snipe	O
has	O
to	O
be	O
able	O
to	O
realize	O
arbi-	O
trary	O
network	O
topologies	O
.	O
3.6.2	O
asynchronous	O
activation	B
of	O
time	O
.	O
for	O
this	O
,	O
there	O
exist	O
diﬀerent	O
or-	O
ders	O
,	O
some	O
of	O
which	O
i	O
want	O
to	O
introduce	O
in	O
the	O
following	O
:	O
easier	O
to	O
implement	O
3.6.2.1	O
random	O
order	O
deﬁnition	O
3.17	O
(	O
random	O
order	O
of	O
acti-	O
vation	O
)	O
.	O
with	O
random	O
order	O
of	O
acti-	O
vation	O
a	O
neuron	O
i	O
is	O
randomly	O
chosen	O
and	O
its	O
neti	O
,	O
ai	O
and	O
oi	O
are	O
updated	O
.	O
for	O
n	O
neu-	O
rons	O
a	O
cycle	O
is	O
the	O
n-fold	O
execution	O
of	O
this	O
step	O
.	O
obviously	O
,	O
some	O
neurons	O
are	O
repeat-	O
edly	O
updated	O
during	O
one	O
cycle	O
,	O
and	O
others	O
,	O
however	O
,	O
not	O
at	O
all	O
.	O
here	O
,	O
the	O
neurons	O
do	O
not	O
change	O
their	O
val-	O
ues	O
simultaneously	O
but	O
at	O
diﬀerent	O
points	O
apparently	O
,	O
this	O
order	B
of	I
activation	I
is	O
not	O
always	O
useful	O
.	O
46	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
	O
~	O
	O
	O
	O
	O
	O
	O
/	O
/	O
*	O
 	O
 	O
	O
	O
	O
	O
dkriesel.com	O
3.6	O
orders	O
of	O
activation	B
3.6.2.2	O
random	O
permutation	O
with	O
random	O
permutation	O
each	O
neuron	O
is	O
chosen	O
exactly	O
once	O
,	O
but	O
in	O
random	O
or-	O
der	O
,	O
during	O
one	O
cycle	O
.	O
deﬁnition	O
3.18	O
(	O
random	O
permutation	O
)	O
.	O
initially	O
,	O
a	O
permutation	O
of	O
the	O
neurons	O
is	O
calculated	O
randomly	O
and	O
therefore	O
deﬁnes	O
the	O
order	B
of	I
activation	I
.	O
then	O
the	O
neurons	O
are	O
successively	O
processed	O
in	O
this	O
order	O
.	O
this	O
order	B
of	I
activation	I
is	O
as	O
well	O
used	O
rarely	O
because	O
ﬁrstly	O
,	O
the	O
order	O
is	O
gener-	O
ally	O
useless	O
and	O
,	O
secondly	O
,	O
it	O
is	O
very	O
time-	O
consuming	O
to	O
compute	O
a	O
new	O
permutation	O
for	O
every	O
cycle	O
.	O
a	O
hopﬁeld	O
network	O
(	O
chap-	O
ter	O
8	O
)	O
is	O
a	O
topology	B
nominally	O
having	O
a	O
random	O
or	O
a	O
randomly	O
permuted	O
order	B
of	I
activation	I
.	O
but	O
note	O
that	O
in	O
practice	O
,	O
for	O
the	O
previously	O
mentioned	O
reasons	O
,	O
a	O
ﬁxed	O
order	B
of	I
activation	I
is	O
preferred	O
.	O
for	O
all	O
orders	O
either	O
the	O
previous	O
neuron	O
activations	O
at	O
time	O
t	O
or	O
,	O
if	O
already	O
existing	O
,	O
the	O
neuron	O
activations	O
at	O
time	O
t	O
+	O
1	O
,	O
for	O
which	O
we	O
are	O
calculating	O
the	O
activations	O
,	O
can	O
be	O
taken	O
as	O
a	O
starting	O
point	O
.	O
3.6.2.3	O
topological	O
order	O
often	O
very	O
useful	O
deﬁnition	O
3.19	O
(	O
topological	O
activation	O
)	O
.	O
with	O
topological	O
order	O
of	O
activation	B
the	O
neurons	O
are	O
updated	O
during	O
one	O
cycle	O
and	O
according	O
to	O
a	O
ﬁxed	O
order	O
.	O
the	O
order	O
is	O
deﬁned	O
by	O
the	O
network	O
topology	O
.	O
since	O
otherwise	O
there	O
is	O
no	O
order	O
of	O
activa-	O
tion	O
.	O
thus	O
,	O
in	O
feedforward	B
networks	O
(	O
for	O
which	O
the	O
procedure	O
is	O
very	O
reasonable	O
)	O
the	O
input	O
neurons	O
would	O
be	O
updated	O
ﬁrst	O
,	O
then	O
the	O
inner	O
neurons	O
and	O
ﬁnally	O
the	O
out-	O
put	O
neurons	O
.	O
this	O
may	O
save	O
us	O
a	O
lot	O
of	O
time	O
:	O
given	O
a	O
synchronous	O
activation	B
or-	O
der	O
,	O
a	O
feedforward	B
network	O
with	O
n	O
layers	O
of	O
neurons	O
would	O
need	O
n	O
full	O
propagation	O
cycles	O
in	O
order	O
to	O
enable	O
input	O
data	O
to	O
have	O
inﬂuence	O
on	O
the	O
output	O
of	O
the	O
net-	O
work	O
.	O
given	O
the	O
topological	O
activation	O
or-	O
der	O
,	O
we	O
just	O
need	O
one	O
single	O
propagation	O
.	O
however	O
,	O
not	O
every	O
network	O
topology	O
al-	O
lows	O
for	O
ﬁnding	O
a	O
special	O
activation	B
order	O
that	O
enables	O
saving	O
time	O
.	O
feature	O
snipe	O
:	O
those	O
who	O
want	O
to	O
use	O
snipe	O
for	O
implementing	O
feedforward	B
networks	O
may	O
save	O
some	O
calculation	O
time	O
by	O
us-	O
ing	O
the	O
fastprop	B
(	O
mentioned	O
within	O
the	O
documentation	O
of	O
the	O
class	O
neuralnetworkdescriptor	O
.	O
once	O
fastprop	B
is	O
enabled	O
,	O
it	O
will	O
cause	O
the	O
data	O
propaga-	O
tion	O
to	O
be	O
carried	O
out	O
in	O
a	O
slightly	O
diﬀerent	O
way	O
.	O
in	O
the	O
standard	O
mode	O
,	O
all	O
net	O
inputs	O
are	O
calculated	O
ﬁrst	O
,	O
followed	O
by	O
all	O
activa-	O
tions	O
.	O
in	O
the	O
fastprop	B
mode	O
,	O
for	O
every	O
neu-	O
ron	O
,	O
the	O
activation	B
is	O
calculated	O
right	O
after	O
the	O
net	O
input	O
.	O
the	O
neuron	O
values	O
are	O
calcu-	O
lated	O
in	O
ascending	O
neuron	O
index	O
order	O
.	O
the	O
neuron	O
numbers	O
are	O
ascending	O
from	O
input	O
to	O
output	B
layer	I
,	O
which	O
provides	O
us	O
with	O
the	O
perfect	O
topological	O
activation	O
order	O
for	O
feed-	O
forward	O
networks	O
.	O
3.6.2.4	O
fixed	O
orders	O
of	O
activation	B
during	O
implementation	O
this	O
procedure	O
can	O
only	O
be	O
considered	O
for	O
non-cyclic	O
,	O
i.e	O
.	O
non-recurrent	O
,	O
networks	O
,	O
obviously	O
,	O
ﬁxed	O
orders	O
of	O
activation	B
can	O
be	O
deﬁned	O
as	O
well	O
.	O
therefore	O
,	O
when	O
implementing	O
,	O
feedforward	B
for	O
instance	O
,	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
47	O
chapter	O
3	O
components	O
of	O
artiﬁcial	O
neural	O
networks	O
(	O
fundamental	O
)	O
dkriesel.com	O
networks	O
it	O
is	O
very	O
popular	O
to	O
determine	O
the	O
order	B
of	I
activation	I
once	O
according	O
to	O
the	O
topology	B
and	O
to	O
use	O
this	O
order	O
without	O
further	O
veriﬁcation	O
at	O
runtime	O
.	O
but	O
this	O
is	O
not	O
necessarily	O
useful	O
for	O
networks	O
that	O
are	O
capable	O
to	O
change	O
their	O
topology	B
.	O
outputs	O
y1	O
,	O
y2	O
,	O
.	O
.	O
.	O
,	O
ym	O
.	O
they	O
are	O
regarded	O
as	O
output	B
vector	I
y	O
=	O
(	O
y1	O
,	O
y2	O
,	O
.	O
.	O
.	O
,	O
ym	O
)	O
.	O
thus	O
,	O
the	O
output	B
dimension	I
is	O
referred	O
to	O
as	O
m.	O
data	O
is	O
output	O
by	O
a	O
neural	O
net-	O
(	O
cid:74	O
)	O
m	O
work	O
by	O
the	O
output	O
neurons	O
adopting	O
the	O
components	O
of	O
the	O
output	B
vector	I
in	O
their	O
output	O
values	O
.	O
3.7	O
communication	O
with	O
the	O
outside	O
world	O
:	O
input	O
and	O
output	O
of	O
data	O
in	O
and	O
from	O
neural	O
networks	O
finally	O
,	O
let	O
us	O
take	O
a	O
look	O
at	O
the	O
fact	O
that	O
,	O
of	O
course	O
,	O
many	O
types	O
of	O
neural	O
networks	O
permit	O
the	O
input	O
of	O
data	O
.	O
then	O
these	O
data	O
are	O
processed	O
and	O
can	O
produce	O
output	O
.	O
let	O
us	O
,	O
for	O
example	O
,	O
regard	O
the	O
feedfor-	O
ward	O
network	O
shown	O
in	O
ﬁg	O
.	O
3.3	O
on	O
page	O
40	O
:	O
it	O
has	O
two	O
input	O
neurons	O
and	O
two	O
output	O
neurons	O
,	O
which	O
means	O
that	O
it	O
also	O
has	O
two	O
numerical	O
inputs	O
x1	O
,	O
x2	O
and	O
outputs	O
y1	O
,	O
y2	O
.	O
as	O
a	O
simpliﬁcation	O
we	O
summarize	O
the	O
in-	O
put	O
and	O
output	O
components	O
for	O
n	O
input	O
or	O
output	O
neurons	O
within	O
the	O
vectors	O
x	O
=	O
(	O
x1	O
,	O
x2	O
,	O
.	O
.	O
.	O
,	O
xn	O
)	O
and	O
y	O
=	O
(	O
y1	O
,	O
y2	O
,	O
.	O
.	O
.	O
,	O
yn	O
)	O
.	O
deﬁnition	O
3.20	O
(	O
input	B
vector	I
)	O
.	O
a	O
net-	O
work	O
with	O
n	O
input	O
neurons	O
needs	O
n	O
inputs	O
x1	O
,	O
x2	O
,	O
.	O
.	O
.	O
,	O
xn	O
.	O
they	O
are	O
considered	O
as	O
in-	O
put	O
vector	O
x	O
=	O
(	O
x1	O
,	O
x2	O
,	O
.	O
.	O
.	O
,	O
xn	O
)	O
.	O
as	O
a	O
consequence	O
,	O
the	O
input	B
dimension	I
is	O
re-	O
ferred	O
to	O
as	O
n.	O
data	O
is	O
put	O
into	O
a	O
neural	O
network	O
by	O
using	O
the	O
components	O
of	O
the	O
in-	O
put	O
vector	O
as	O
network	O
inputs	O
of	O
the	O
input	O
neurons	O
.	O
deﬁnition	O
3.21	O
(	O
output	B
vector	I
)	O
.	O
a	O
net-	O
work	O
with	O
m	O
output	O
neurons	O
provides	O
m	O
snipe	O
:	O
in	O
order	O
to	O
propagate	O
data	O
through	O
a	O
neuralnetwork-instance	O
,	O
the	O
propagate	O
method	O
is	O
used	O
.	O
it	O
receives	O
the	O
input	B
vector	I
as	O
array	O
of	O
doubles	O
,	O
and	O
returns	O
the	O
output	B
vector	I
in	O
the	O
same	O
way	O
.	O
now	O
we	O
have	O
deﬁned	O
and	O
closely	O
examined	O
the	O
basic	O
components	O
of	O
neural	O
networks	O
–	O
without	O
having	O
seen	O
a	O
network	O
in	O
action	O
.	O
but	O
ﬁrst	O
we	O
will	O
continue	O
with	O
theoretical	O
explanations	O
and	O
generally	O
describe	O
how	O
a	O
neural	O
network	O
could	O
learn	O
.	O
exercises	O
exercise	O
5.	O
would	O
it	O
be	O
useful	O
(	O
from	O
your	O
point	O
of	O
view	O
)	O
to	O
insert	O
one	O
bias	O
neu-	O
ron	O
in	O
each	O
layer	B
of	O
a	O
layer-based	O
network	O
,	O
such	O
as	O
a	O
feedforward	B
network	O
?	O
discuss	O
this	O
in	O
relation	O
to	O
the	O
representation	O
and	O
implementation	O
of	O
the	O
network	O
.	O
will	O
the	O
result	O
of	O
the	O
network	O
change	O
?	O
exercise	O
6.	O
show	O
for	O
the	O
fermi	O
function	B
f	O
(	O
x	O
)	O
as	O
well	O
as	O
for	O
the	O
hyperbolic	B
tangent	I
tanh	O
(	O
x	O
)	O
,	O
that	O
their	O
derivatives	O
can	O
be	O
ex-	O
pressed	O
by	O
the	O
respective	O
functions	O
them-	O
selves	O
so	O
that	O
the	O
two	O
statements	O
1.	O
f0	O
(	O
x	O
)	O
=	O
f	O
(	O
x	O
)	O
·	O
(	O
1	O
−	O
f	O
(	O
x	O
)	O
)	O
and	O
2.	O
tanh0	O
(	O
x	O
)	O
=	O
1	O
−	O
tanh2	O
(	O
x	O
)	O
x	O
(	O
cid:73	O
)	O
n	O
(	O
cid:73	O
)	O
y	O
(	O
cid:73	O
)	O
48	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
are	O
true	O
.	O
3.7	O
input	O
and	O
output	O
of	O
data	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
49	O
chapter	O
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
approaches	O
and	O
thoughts	O
of	O
how	O
to	O
teach	O
machines	O
.	O
should	O
neural	O
networks	O
be	O
corrected	O
?	O
should	O
they	O
only	O
be	O
encouraged	O
?	O
or	O
should	O
they	O
even	O
learn	O
without	O
any	O
help	O
?	O
thoughts	O
about	O
what	O
we	O
want	O
to	O
change	O
during	O
the	O
learning	B
procedure	O
and	O
how	O
we	O
will	O
change	O
it	O
,	O
about	O
the	O
measurement	O
of	O
errors	O
and	O
when	O
we	O
have	O
learned	O
enough	O
.	O
as	O
written	O
above	O
,	O
the	O
most	O
interesting	O
characteristic	O
of	O
neural	O
networks	O
is	O
their	O
capability	O
to	O
familiarize	O
with	O
problems	O
by	O
means	O
of	O
training	O
and	O
,	O
after	O
suﬃcient	O
training	O
,	O
to	O
be	O
able	O
to	O
solve	O
unknown	O
prob-	O
lems	O
of	O
the	O
same	O
class	O
.	O
this	O
approach	O
is	O
re-	O
ferred	O
to	O
as	O
generalization	B
.	O
before	O
intro-	O
ducing	O
speciﬁc	O
learning	B
procedures	O
,	O
i	O
want	O
to	O
propose	O
some	O
basic	O
principles	O
about	O
the	O
learning	B
procedure	O
in	O
this	O
chapter	O
.	O
4.1	O
there	O
are	O
diﬀerent	O
paradigms	O
of	O
learning	B
learning	O
is	O
a	O
comprehensive	O
term	O
.	O
a	O
learning	B
system	O
changes	O
itself	O
in	O
order	O
to	O
adapt	O
to	O
e.g	O
.	O
environmental	O
changes	O
.	O
a	O
neural	O
network	O
could	O
learn	O
from	O
many	O
things	O
but	O
,	O
of	O
course	O
,	O
there	O
will	O
always	O
be	O
in	O
the	O
question	O
of	O
how	O
to	O
implement	O
it	O
.	O
principle	O
,	O
a	O
neural	O
network	O
changes	O
when	O
its	O
components	O
are	O
changing	O
,	O
as	O
we	O
have	O
learned	O
above	O
.	O
theoretically	O
,	O
a	O
neural	O
net-	O
work	O
could	O
learn	O
by	O
1.	O
developing	O
new	O
connections	O
,	O
2.	O
deleting	O
existing	O
connections	O
,	O
3.	O
changing	O
connecting	O
weights	O
,	O
4.	O
changing	O
the	O
threshold	O
values	O
of	O
neu-	O
rons	O
,	O
5.	O
varying	O
one	O
or	O
more	O
of	O
the	O
three	O
neu-	O
ron	O
functions	O
(	O
remember	O
:	O
activation	B
function	I
,	O
propagation	B
function	I
and	O
output	B
function	I
)	O
,	O
6.	O
developing	O
new	O
neurons	O
,	O
or	O
7.	O
deleting	O
existing	O
neurons	O
(	O
and	O
so	O
,	O
of	O
course	O
,	O
existing	O
connections	O
)	O
.	O
51	O
from	O
what	O
do	O
we	O
learn	O
?	O
chapter	O
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
(	O
fundamental	O
)	O
dkriesel.com	O
as	O
mentioned	O
above	O
,	O
we	O
assume	O
the	O
change	B
in	I
weight	I
to	O
be	O
the	O
most	O
common	O
procedure	O
.	O
furthermore	O
,	O
deletion	O
of	O
con-	O
nections	O
can	O
be	O
realized	O
by	O
additionally	O
taking	O
care	O
that	O
a	O
connection	B
is	O
no	O
longer	O
trained	O
when	O
it	O
is	O
set	O
to	O
0.	O
moreover	O
,	O
we	O
can	O
develop	O
further	O
connections	O
by	O
setting	O
a	O
non-existing	O
connection	B
(	O
with	O
the	O
value	O
0	O
in	O
the	O
connection	B
matrix	O
)	O
to	O
a	O
value	O
dif-	O
ferent	O
from	O
0.	O
as	O
for	O
the	O
modiﬁcation	O
of	O
threshold	O
values	O
i	O
refer	O
to	O
the	O
possibility	O
of	O
implementing	O
them	O
as	O
weights	O
(	O
section	O
3.4	O
)	O
.	O
thus	O
,	O
we	O
perform	O
any	O
of	O
the	O
ﬁrst	O
four	O
of	O
the	O
learning	B
paradigms	O
by	O
just	O
training	O
synaptic	O
weights	O
.	O
the	O
change	O
of	O
neuron	O
functions	O
is	O
diﬃcult	O
to	O
implement	O
,	O
not	O
very	O
intuitive	O
and	O
not	O
exactly	O
biologically	O
motivated	O
.	O
therefore	O
it	O
is	O
not	O
very	O
popular	O
and	O
i	O
will	O
omit	O
this	O
topic	O
here	O
.	O
the	O
possibilities	O
to	O
develop	O
or	O
delete	O
neurons	O
do	O
not	O
only	O
provide	O
well	O
adjusted	O
weights	O
during	O
the	O
training	O
of	O
a	O
neural	O
network	O
,	O
but	O
also	O
optimize	O
the	O
net-	O
work	O
topology	B
.	O
thus	O
,	O
they	O
attract	O
a	O
grow-	O
ing	O
interest	O
and	O
are	O
often	O
realized	O
by	O
using	O
evolutionary	O
procedures	O
.	O
but	O
,	O
since	O
we	O
ac-	O
cept	O
that	O
a	O
large	O
part	O
of	O
learning	B
possibil-	O
ities	O
can	O
already	O
be	O
covered	O
by	O
changes	O
in	O
weight	B
,	O
they	O
are	O
also	O
not	O
the	O
subject	O
mat-	O
ter	O
of	O
this	O
text	O
(	O
however	O
,	O
it	O
is	O
planned	O
to	O
extend	O
the	O
text	O
towards	O
those	O
aspects	O
of	O
training	O
)	O
.	O
of	O
allow	O
for	O
the	O
changes	O
class	O
snipe	O
:	O
methods	O
in	O
neuralnetwork	O
connection	B
weights	O
,	O
and	O
addition	O
and	O
removal	O
of	O
both	O
connections	O
and	O
neurons	O
.	O
methods	O
in	O
neuralnetworkdescriptor	O
enable	O
the	O
change	O
of	O
neuron	O
behaviors	O
,	O
respectively	O
per	O
layer	B
.	O
activation	B
functions	O
learning	B
by	O
changes	O
in	O
weight	B
thus	O
,	O
we	O
let	O
our	O
neural	O
network	O
learn	O
by	O
modifying	O
the	O
connecting	O
weights	O
accord-	O
ing	O
to	O
rules	O
that	O
can	O
be	O
formulated	O
as	O
al-	O
gorithms	O
.	O
therefore	O
a	O
learning	B
procedure	O
is	O
always	O
an	O
algorithm	B
that	O
can	O
easily	O
be	O
implemented	O
by	O
means	O
of	O
a	O
programming	O
language	O
.	O
later	O
in	O
the	O
text	O
i	O
will	O
assume	O
that	O
the	O
deﬁnition	O
of	O
the	O
term	O
desired	O
out-	O
put	O
which	O
is	O
worth	O
learning	B
is	O
known	O
(	O
and	O
i	O
will	O
deﬁne	O
formally	O
what	O
a	O
training	O
pat-	O
tern	O
is	O
)	O
and	O
that	O
we	O
have	O
a	O
training	B
set	I
of	O
learning	B
samples	O
.	O
let	O
a	O
training	B
set	I
be	O
deﬁned	O
as	O
follows	O
:	O
deﬁnition	O
4.1	O
(	O
training	B
set	I
)	O
.	O
a	O
train-	O
(	O
cid:74	O
)	O
p	O
ing	O
set	O
(	O
named	O
p	O
)	O
is	O
a	O
set	O
of	O
training	O
patterns	O
,	O
which	O
we	O
use	O
to	O
train	O
our	O
neu-	O
ral	O
net	O
.	O
i	O
will	O
now	O
introduce	O
the	O
three	O
essential	O
paradigms	O
of	O
learning	B
by	O
presenting	O
the	O
diﬀerences	O
between	O
their	O
regarding	O
train-	O
ing	O
sets	O
.	O
4.1.1	O
unsupervised	B
learning	I
provides	O
input	B
patterns	I
to	O
the	O
network	O
,	O
but	O
no	O
learning	B
aides	O
unsupervised	B
learning	I
is	O
the	O
biologi-	O
cally	O
most	O
plausible	O
method	O
,	O
but	O
is	O
not	O
suitable	O
for	O
all	O
problems	O
.	O
only	O
the	O
in-	O
put	O
patterns	O
are	O
given	O
;	O
the	O
network	O
tries	O
to	O
identify	O
similar	O
patterns	O
and	O
to	O
classify	O
them	O
into	O
similar	O
categories	O
.	O
deﬁnition	O
4.2	O
(	O
unsupervised	B
learning	I
)	O
.	O
the	O
training	B
set	I
only	O
consists	O
of	O
input	B
patterns	I
,	O
the	O
network	O
tries	O
by	O
itself	O
to	O
de-	O
tect	O
similarities	O
and	O
to	O
generate	O
pattern	B
classes	O
.	O
52	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
4.1	O
paradigms	O
of	O
learning	B
here	O
i	O
want	O
to	O
refer	O
again	O
to	O
the	O
popu-	O
lar	O
example	O
of	O
kohonen	O
’	O
s	O
self-organising	O
maps	O
(	O
chapter	O
10	O
)	O
.	O
4.1.2	O
reinforcement	B
learning	I
methods	O
provide	O
feedback	O
to	O
the	O
network	O
,	O
whether	O
it	O
behaves	O
well	O
or	O
bad	O
in	O
reinforcement	B
learning	I
the	O
network	O
receives	O
a	O
logical	O
or	O
a	O
real	O
value	O
after	O
completion	O
of	O
a	O
sequence	O
,	O
which	O
deﬁnes	O
whether	O
the	O
result	O
is	O
right	O
or	O
wrong	O
.	O
intu-	O
itively	O
it	O
is	O
clear	O
that	O
this	O
procedure	O
should	O
be	O
more	O
eﬀective	O
than	O
unsupervised	O
learn-	O
ing	O
since	O
the	O
network	O
receives	O
speciﬁc	O
crit-	O
era	O
for	O
problem-solving	O
.	O
deﬁnition	O
4.3	O
(	O
reinforcement	B
learning	I
)	O
.	O
the	O
training	B
set	I
consists	O
of	O
input	B
patterns	I
,	O
after	O
completion	O
of	O
a	O
sequence	O
a	O
value	O
is	O
re-	O
turned	O
to	O
the	O
network	O
indicating	O
whether	O
the	O
result	O
was	O
right	O
or	O
wrong	O
and	O
,	O
possibly	O
,	O
how	O
right	O
or	O
wrong	O
it	O
was	O
.	O
4.1.3	O
supervised	B
learning	I
methods	O
provide	O
training	O
patterns	O
together	O
with	O
appropriate	O
desired	O
outputs	O
in	O
supervised	B
learning	I
the	O
training	B
set	I
consists	O
of	O
input	B
patterns	I
as	O
well	O
as	O
their	O
correct	O
results	O
in	O
the	O
form	O
of	O
the	O
precise	O
ac-	O
tivation	O
of	O
all	O
output	O
neurons	O
.	O
thus	O
,	O
for	O
each	O
training	B
set	I
that	O
is	O
fed	O
into	O
the	O
net-	O
work	O
the	O
output	O
,	O
for	O
instance	O
,	O
can	O
directly	O
be	O
compared	O
with	O
the	O
correct	O
solution	O
and	O
and	O
the	O
network	O
weights	O
can	O
be	O
changed	O
according	O
to	O
their	O
diﬀerence	O
.	O
the	O
objec-	O
tive	O
is	O
to	O
change	O
the	O
weights	O
to	O
the	O
eﬀect	O
that	O
the	O
network	O
can	O
not	O
only	O
associate	O
in-	O
put	O
and	O
output	O
patterns	O
independently	O
af-	O
ter	O
the	O
training	O
,	O
but	O
can	O
provide	O
plausible	O
results	O
to	O
unknown	O
,	O
similar	O
input	B
patterns	I
,	O
i.e	O
.	O
it	O
generalises	O
.	O
deﬁnition	O
4.4	O
(	O
supervised	B
learning	I
)	O
.	O
the	O
training	B
set	I
consists	O
of	O
input	B
patterns	I
with	O
correct	O
results	O
so	O
that	O
the	O
network	O
can	O
receive	O
a	O
precise	O
error	O
vector1	O
can	O
be	O
re-	O
turned	O
.	O
this	O
learning	B
procedure	O
is	O
not	O
always	O
bio-	O
logically	O
plausible	O
,	O
but	O
it	O
is	O
extremely	O
ef-	O
fective	O
and	O
therefore	O
very	O
practicable	O
.	O
at	O
ﬁrst	O
we	O
want	O
to	O
look	O
at	O
the	O
the	O
su-	O
pervised	O
learning	B
procedures	O
in	O
general	O
,	O
which	O
-	O
in	O
this	O
text	O
-	O
are	O
corresponding	O
to	O
the	O
following	O
steps	O
:	O
entering	O
the	O
input	O
pattern	O
(	O
activation	B
of	O
input	O
neurons	O
)	O
,	O
forward	O
propagation	O
of	O
the	O
input	O
by	O
the	O
network	O
,	O
generation	O
of	O
the	O
output	O
,	O
comparing	O
the	O
output	O
with	O
the	O
desired	O
output	O
(	O
teaching	B
input	I
)	O
,	O
provides	O
er-	O
ror	O
vector	O
(	O
diﬀerence	O
vector	O
)	O
,	O
corrections	O
of	O
the	O
network	O
are	O
calculated	O
based	O
on	O
the	O
error	B
vector	I
,	O
corrections	O
are	O
applied	O
.	O
1	O
the	O
term	O
error	B
vector	I
will	O
be	O
deﬁned	O
in	O
section	O
4.2	O
,	O
where	O
mathematical	O
formalisation	O
of	O
learning	B
is	O
discussed	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
53	O
network	O
receives	O
reward	B
or	O
punishment	O
network	O
receives	O
correct	O
results	O
for	O
samples	O
learning	B
scheme	O
chapter	O
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
(	O
fundamental	O
)	O
dkriesel.com	O
4.1.4	O
oﬄine	O
or	O
online	B
learning	I
?	O
it	O
must	O
be	O
noted	O
that	O
learning	B
can	O
be	O
oﬄine	O
(	O
a	O
set	O
of	O
training	O
samples	O
is	O
pre-	O
sented	O
,	O
then	O
the	O
weights	O
are	O
changed	O
,	O
the	O
total	B
error	I
is	O
calculated	O
by	O
means	O
of	O
a	O
error	B
function	I
operation	O
or	O
simply	O
accumulated	O
-	O
see	O
also	O
section	O
4.4	O
)	O
or	O
online	O
(	O
after	O
every	O
sample	O
presented	O
the	O
weights	O
are	O
changed	O
)	O
.	O
both	O
procedures	O
have	O
advantages	O
and	O
dis-	O
advantages	O
,	O
which	O
will	O
be	O
discussed	O
in	O
the	O
learning	B
procedures	O
section	O
if	O
necessary	O
.	O
oﬄine	O
training	O
procedures	O
are	O
also	O
called	O
batch	O
training	O
procedures	O
since	O
a	O
batch	O
of	O
results	O
is	O
corrected	O
all	O
at	O
once	O
.	O
such	O
a	O
training	O
section	O
of	O
a	O
whole	O
batch	O
of	O
train-	O
ing	O
samples	O
including	O
the	O
related	O
change	B
in	I
weight	I
values	O
is	O
called	O
epoch	B
.	O
deﬁnition	O
4.5	O
(	O
oﬄine	O
learning	B
)	O
.	O
sev-	O
eral	O
training	O
patterns	O
are	O
entered	O
into	O
the	O
network	O
at	O
once	O
,	O
the	O
errors	O
are	O
accumu-	O
lated	O
and	O
it	O
learns	O
for	O
all	O
patterns	O
at	O
the	O
same	O
time	O
.	O
deﬁnition	O
4.6	O
(	O
online	B
learning	I
)	O
.	O
the	O
network	O
learns	O
directly	O
from	O
the	O
errors	O
of	O
each	O
training	O
sample	O
.	O
.	O
how	O
must	O
the	O
weights	O
be	O
modiﬁed	O
to	O
allow	O
fast	O
and	O
reliable	O
learning	B
?	O
.	O
how	O
can	O
the	O
success	O
of	O
a	O
learning	B
pro-	O
cess	O
be	O
measured	O
in	O
an	O
objective	O
way	O
?	O
.	O
is	O
it	O
possible	O
to	O
determine	O
the	O
``	O
best	O
''	O
learning	B
procedure	O
?	O
.	O
is	O
it	O
possible	O
to	O
predict	O
if	O
a	O
learning	B
procedure	O
terminates	O
,	O
i.e	O
.	O
whether	O
it	O
will	O
reach	O
an	O
optimal	O
state	O
after	O
a	O
ﬁ-	O
nite	O
time	O
or	O
if	O
it	O
,	O
for	O
example	O
,	O
will	O
os-	O
cillate	O
between	O
diﬀerent	O
states	O
?	O
.	O
how	O
can	O
the	O
learned	O
patterns	O
be	O
stored	O
in	O
the	O
network	O
?	O
.	O
is	O
it	O
possible	O
to	O
avoid	O
that	O
newly	O
learned	O
patterns	O
destroy	O
previously	O
learned	O
associations	O
(	O
the	O
so-called	O
sta-	O
bility/plasticity	O
dilemma	O
)	O
?	O
we	O
will	O
see	O
that	O
all	O
these	O
questions	O
can	O
not	O
be	O
generally	O
answered	O
but	O
that	O
they	O
have	O
(	O
cid:74	O
)	O
(	O
cid:74	O
)	O
(	O
cid:74	O
)	O
to	O
be	O
discussed	O
for	O
each	O
learning	B
procedure	O
no	O
easy	O
and	O
each	O
network	O
topology	O
individually	O
.	O
answers	O
!	O
4.2	O
training	O
patterns	O
and	O
teaching	B
input	I
4.1.5	O
questions	O
you	O
should	O
answer	O
before	O
learning	B
the	O
application	O
of	O
such	O
schemes	O
certainly	O
requires	O
preliminary	O
thoughts	O
about	O
some	O
questions	O
,	O
which	O
i	O
want	O
to	O
introduce	O
now	O
as	O
a	O
check	O
list	O
and	O
,	O
if	O
possible	O
,	O
answer	O
them	O
in	O
the	O
course	O
of	O
this	O
text	O
:	O
.	O
where	O
does	O
the	O
learning	B
input	O
come	O
from	O
and	O
in	O
what	O
form	O
?	O
before	O
we	O
get	O
to	O
know	O
our	O
ﬁrst	O
learning	B
rule	O
,	O
we	O
need	O
to	O
introduce	O
the	O
teaching	B
input	I
.	O
in	O
(	O
this	O
)	O
case	O
of	O
supervised	O
learn-	O
ing	O
we	O
assume	O
a	O
training	B
set	I
consisting	O
of	O
training	O
patterns	O
and	O
the	O
correspond-	O
ing	O
correct	O
output	O
values	O
we	O
want	O
to	O
see	O
at	O
the	O
output	O
neurons	O
after	O
the	O
training	O
.	O
while	O
the	O
network	O
has	O
not	O
ﬁnished	O
train-	O
ing	O
,	O
i.e	O
.	O
as	O
long	O
as	O
it	O
is	O
generating	O
wrong	O
outputs	O
,	O
these	O
output	O
values	O
are	O
referred	O
desired	O
output	O
54	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
4.2	O
training	O
patterns	O
and	O
teaching	B
input	I
p	O
(	O
cid:73	O
)	O
t	O
(	O
cid:73	O
)	O
desired	O
output	O
to	O
as	O
teaching	B
input	I
,	O
and	O
that	O
for	O
each	O
neu-	O
ron	O
individually	O
.	O
thus	O
,	O
for	O
a	O
neuron	O
j	O
with	O
the	O
incorrect	O
output	O
oj	O
,	O
tj	O
is	O
the	O
teaching	B
input	I
,	O
which	O
means	O
it	O
is	O
the	O
correct	O
or	O
de-	O
sired	O
output	O
for	O
a	O
training	B
pattern	I
p.	O
deﬁnition	O
4.7	O
(	O
training	O
patterns	O
)	O
.	O
a	O
training	B
pattern	I
is	O
an	O
input	B
vector	I
p	O
with	O
the	O
components	O
p1	O
,	O
p2	O
,	O
.	O
.	O
.	O
,	O
pn	O
whose	O
desired	O
output	O
is	O
known	O
.	O
by	O
entering	O
the	O
training	B
pattern	I
into	O
the	O
network	O
we	O
re-	O
ceive	O
an	O
output	O
that	O
can	O
be	O
compared	O
with	O
the	O
teaching	B
input	I
,	O
which	O
is	O
the	O
desired	O
output	O
.	O
the	O
set	O
of	O
training	O
patterns	O
is	O
called	O
p.	O
it	O
contains	O
a	O
ﬁnite	O
number	O
of	O
or-	O
dered	O
pairs	O
(	O
p	O
,	O
t	O
)	O
of	O
training	O
patterns	O
with	O
corresponding	O
desired	O
output	O
.	O
training	O
patterns	O
are	O
often	O
simply	O
called	O
patterns	O
,	O
that	O
is	O
why	O
they	O
are	O
referred	O
to	O
as	O
p.	O
in	O
the	O
literature	O
as	O
well	O
as	O
in	O
this	O
text	O
they	O
are	O
called	O
synonymously	O
pat-	O
terns	O
,	O
training	O
samples	O
etc	O
.	O
deﬁnition	O
4.8	O
(	O
teaching	B
input	I
)	O
.	O
let	O
j	O
be	O
an	O
output	O
neuron	O
.	O
the	O
teaching	O
in-	O
put	O
tj	O
is	O
the	O
desired	O
and	O
correct	O
value	O
j	O
should	O
output	O
after	O
the	O
input	O
of	O
a	O
certain	O
training	B
pattern	I
.	O
analogously	O
to	O
the	O
vec-	O
tor	O
p	O
the	O
teaching	O
inputs	O
t1	O
,	O
t2	O
,	O
.	O
.	O
.	O
,	O
tn	O
of	O
the	O
neurons	O
can	O
also	O
be	O
combined	O
into	O
a	O
vector	O
t.	O
t	O
always	O
refers	O
to	O
a	O
speciﬁc	O
train-	O
ing	O
pattern	B
p	O
and	O
is	O
,	O
as	O
already	O
mentioned	O
,	O
contained	O
in	O
the	O
set	O
p	O
of	O
the	O
training	O
pat-	O
terns	O
.	O
are	O
that	O
relevant	O
snipe	O
:	O
classes	O
in	O
for	O
training	O
the	O
package	O
class	O
trainingsamplelesson	O
allows	O
for	O
storage	O
of	O
training	O
patterns	O
and	O
teaching	O
inputs	O
,	O
data	O
are	O
training	O
.	O
located	O
the	O
as	O
well	O
as	O
simple	O
preprocessing	O
of	O
the	O
training	O
data	O
.	O
deﬁnition	O
4.9	O
(	O
error	B
vector	I
)	O
.	O
for	O
sev-	O
(	O
cid:74	O
)	O
ep	O
eral	O
output	O
neurons	O
ω1	O
,	O
ω2	O
,	O
.	O
.	O
.	O
,	O
ωn	O
the	O
dif-	O
ference	O
between	O
output	B
vector	I
and	O
teach-	O
ing	O
input	O
under	O
a	O
training	O
input	O
p	O
	O
t1	O
−	O
y1	O
...	O
tn	O
−	O
yn	O
	O
ep	O
=	O
is	O
referred	O
to	O
as	O
error	B
vector	I
,	O
sometimes	O
it	O
is	O
also	O
called	O
diﬀerence	O
vector	O
.	O
de-	O
pending	O
on	O
whether	O
you	O
are	O
learning	B
of-	O
ﬂine	O
or	O
online	O
,	O
the	O
diﬀerence	O
vector	O
refers	O
to	O
a	O
speciﬁc	O
training	B
pattern	I
,	O
or	O
to	O
the	O
er-	O
ror	O
of	O
a	O
set	O
of	O
training	O
patterns	O
which	O
is	O
normalized	O
in	O
a	O
certain	O
way	O
.	O
now	O
i	O
want	O
to	O
brieﬂy	O
summarize	O
the	O
vec-	O
tors	O
we	O
have	O
yet	O
deﬁned	O
.	O
there	O
is	O
the	O
input	B
vector	I
x	O
,	O
which	O
can	O
be	O
entered	O
into	O
the	O
neural	O
network	O
.	O
depending	O
on	O
the	O
type	O
of	O
network	O
being	O
used	O
the	O
neural	O
network	O
will	O
output	O
an	O
output	B
vector	I
y.	O
basically	O
,	O
the	O
training	O
sample	O
p	O
is	O
nothing	O
more	O
than	O
an	O
input	B
vector	I
.	O
we	O
only	O
use	O
it	O
for	O
training	O
purposes	O
because	O
we	O
know	O
the	O
corresponding	O
teaching	B
input	I
t	O
which	O
is	O
nothing	O
more	O
than	O
the	O
desired	O
output	B
vector	I
to	O
the	O
training	O
sample	O
.	O
the	O
error	B
vector	I
ep	O
is	O
the	O
diﬀerence	O
between	O
the	O
teaching	B
input	I
t	O
and	O
the	O
actural	O
output	O
y.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
55	O
chapter	O
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
(	O
fundamental	O
)	O
dkriesel.com	O
important	O
!	O
so	O
,	O
what	O
x	O
and	O
y	O
are	O
for	O
the	O
general	O
net-	O
work	O
operation	O
are	O
p	O
and	O
t	O
for	O
the	O
network	O
training	O
-	O
and	O
during	O
training	O
we	O
try	O
to	O
bring	O
y	O
as	O
close	O
to	O
t	O
as	O
possible	O
.	O
one	O
ad-	O
vice	O
concerning	O
notation	O
:	O
we	O
referred	O
to	O
the	O
output	O
values	O
of	O
a	O
neuron	O
i	O
as	O
oi	O
.	O
thus	O
,	O
the	O
output	O
of	O
an	O
output	O
neuron	O
ω	O
is	O
called	O
oω	O
.	O
but	O
the	O
output	O
values	O
of	O
a	O
network	O
are	O
referred	O
to	O
as	O
yω	O
.	O
certainly	O
,	O
these	O
network	O
outputs	O
are	O
only	O
neuron	O
outputs	O
,	O
too	O
,	O
but	O
they	O
are	O
outputs	O
of	O
output	O
neurons	O
.	O
in	O
this	O
respect	O
yω	O
=	O
oω	O
is	O
true	O
.	O
4.3	O
using	O
training	O
samples	O
we	O
have	O
seen	O
how	O
we	O
can	O
learn	O
in	O
prin-	O
ciple	O
and	O
which	O
steps	O
are	O
required	O
to	O
do	O
so	O
.	O
now	O
we	O
should	O
take	O
a	O
look	O
at	O
the	O
se-	O
lection	O
of	O
training	O
data	O
and	O
the	O
learning	B
curve	O
.	O
after	O
successful	O
learning	B
it	O
is	O
par-	O
ticularly	O
interesting	O
whether	O
the	O
network	O
has	O
only	O
memorized	B
–	O
i.e	O
.	O
whether	O
it	O
can	O
use	O
our	O
training	O
samples	O
to	O
quite	O
exactly	O
produce	O
the	O
right	O
output	O
but	O
to	O
provide	O
wrong	O
answers	O
for	O
all	O
other	O
problems	O
of	O
the	O
same	O
class	O
.	O
suppose	O
that	O
we	O
want	O
the	O
network	O
to	O
train	O
a	O
mapping	O
r2	O
→	O
b1	O
and	O
therefor	O
use	O
the	O
training	O
samples	O
from	O
ﬁg	O
.	O
4.1	O
:	O
then	O
there	O
could	O
be	O
a	O
chance	O
that	O
,	O
ﬁnally	O
,	O
the	O
net-	O
work	O
will	O
exactly	O
mark	O
the	O
colored	O
areas	O
around	O
the	O
training	O
samples	O
with	O
the	O
out-	O
put	O
1	O
(	O
ﬁg	O
.	O
4.1	O
,	O
top	O
)	O
,	O
and	O
otherwise	O
will	O
output	O
0	O
.	O
thus	O
,	O
it	O
has	O
suﬃcient	O
storage	O
capacity	O
to	O
concentrate	O
on	O
the	O
six	O
training	O
figure	O
4.1	O
:	O
visualization	O
of	O
training	O
results	O
of	O
the	O
same	O
training	B
set	I
on	O
networks	O
with	O
a	O
capacity	O
being	O
too	O
high	O
(	O
top	O
)	O
,	O
correct	O
(	O
middle	O
)	O
or	O
too	O
low	O
(	O
bottom	O
)	O
.	O
56	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
4.3	O
using	O
training	O
samples	O
samples	O
with	O
the	O
output	O
1.	O
this	O
implies	O
an	O
oversized	O
network	O
with	O
too	O
much	O
free	O
storage	O
capacity	O
.	O
on	O
the	O
other	O
hand	O
a	O
network	O
could	O
have	O
insuﬃcient	O
capacity	O
(	O
ﬁg	O
.	O
4.1	O
,	O
bottom	O
)	O
–	O
this	O
rough	O
presentation	O
of	O
input	O
data	O
does	O
not	O
correspond	O
to	O
the	O
good	O
generalization	B
performance	O
we	O
desire	O
.	O
thus	O
,	O
we	O
have	O
to	O
ﬁnd	O
the	O
balance	O
(	O
ﬁg	O
.	O
4.1	O
,	O
middle	O
)	O
.	O
4.3.1	O
it	O
is	O
useful	O
to	O
divide	O
the	O
set	O
of	O
training	O
samples	O
an	O
often	O
proposed	O
solution	O
for	O
these	O
prob-	O
lems	O
is	O
to	O
divide	O
,	O
the	O
training	B
set	I
into	O
.	O
one	O
training	B
set	I
really	O
used	O
to	O
train	O
,	O
.	O
and	O
one	O
veriﬁcation	O
set	O
to	O
test	O
our	O
progress	O
–	O
provided	O
that	O
there	O
are	O
enough	O
train-	O
ing	O
samples	O
.	O
the	O
usual	O
division	O
relations	O
are	O
,	O
for	O
instance	O
,	O
70	O
%	O
for	O
training	O
data	O
and	O
30	O
%	O
for	O
veriﬁcation	O
data	O
(	O
randomly	O
chosen	O
)	O
.	O
we	O
can	O
ﬁnish	O
the	O
training	O
when	O
the	O
network	O
provides	O
good	O
results	O
on	O
the	O
training	O
data	O
as	O
well	O
as	O
on	O
the	O
veriﬁcation	O
data	O
.	O
snipe	O
:	O
the	O
method	O
splitlesson	O
within	O
the	O
class	O
trainingsamplelesson	O
allows	O
for	O
splitting	O
a	O
trainingsamplelesson	O
with	O
re-	O
spect	O
to	O
a	O
given	O
ratio	O
.	O
but	O
note	O
:	O
if	O
the	O
veriﬁcation	O
data	O
provide	O
poor	O
results	O
,	O
do	O
not	O
modify	O
the	O
network	O
structure	O
until	O
these	O
data	O
provide	O
good	O
re-	O
sults	O
–	O
otherwise	O
you	O
run	O
the	O
risk	O
of	O
tai-	O
loring	O
the	O
network	O
to	O
the	O
veriﬁcation	O
data	O
.	O
this	O
means	O
,	O
that	O
these	O
data	O
are	O
included	O
in	O
the	O
training	O
,	O
even	O
if	O
they	O
are	O
not	O
used	O
explicitly	O
for	O
the	O
training	O
.	O
the	O
solution	O
is	O
a	O
third	O
set	O
of	O
validation	O
data	O
used	O
only	O
for	O
validation	O
after	O
a	O
supposably	O
success-	O
ful	O
training	O
.	O
by	O
training	O
less	O
patterns	O
,	O
we	O
obviously	O
withhold	O
information	O
from	O
the	O
network	O
and	O
risk	O
to	O
worsen	O
the	O
learning	B
perfor-	O
mance	O
.	O
but	O
this	O
text	O
is	O
not	O
about	O
100	O
%	O
exact	O
reproduction	O
of	O
given	O
samples	O
but	O
about	O
successful	O
generalization	B
and	O
ap-	O
proximation	O
of	O
a	O
whole	O
function	B
–	O
for	O
which	O
it	O
can	O
deﬁnitely	O
be	O
useful	O
to	O
train	O
less	O
information	O
into	O
the	O
network	O
.	O
4.3.2	O
order	O
of	O
pattern	O
representation	O
you	O
can	O
ﬁnd	O
diﬀerent	O
strategies	O
to	O
choose	O
the	O
order	O
of	O
pattern	O
presentation	O
:	O
if	O
pat-	O
terns	O
are	O
presented	O
in	O
random	O
sequence	O
,	O
there	O
is	O
no	O
guarantee	O
that	O
the	O
patterns	O
are	O
learned	O
equally	O
well	O
(	O
however	O
,	O
this	O
is	O
the	O
standard	O
method	O
)	O
.	O
always	O
the	O
same	O
sequence	O
of	O
patterns	O
,	O
on	O
the	O
other	O
hand	O
,	O
provokes	O
that	O
the	O
patterns	O
will	O
be	O
memo-	O
rized	O
when	O
using	O
recurrent	O
networks	O
(	O
later	O
,	O
we	O
will	O
learn	O
more	O
about	O
this	O
type	O
of	O
net-	O
works	O
)	O
.	O
a	O
random	O
permutation	O
would	O
solve	O
both	O
problems	O
,	O
but	O
it	O
is	O
–	O
as	O
already	O
mentioned	O
–	O
very	O
time-consuming	O
to	O
cal-	O
culate	O
such	O
a	O
permutation	O
.	O
snipe	O
:	O
the	O
method	O
shufflesamples	O
lo-	O
cated	O
in	O
the	O
class	O
trainingsamplelesson	O
permutes	O
a	O
lesson	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
57	O
chapter	O
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
(	O
fundamental	O
)	O
dkriesel.com	O
norm	O
to	O
compare	O
4.4	O
learning	B
curve	O
and	O
error	O
measurement	O
the	O
learning	B
curve	O
indicates	O
the	O
progress	O
of	O
the	O
error	O
,	O
which	O
can	O
be	O
determined	O
in	O
various	O
ways	O
.	O
the	O
motivation	O
to	O
create	O
a	O
learning	B
curve	O
is	O
that	O
such	O
a	O
curve	O
can	O
in-	O
dicate	O
whether	O
the	O
network	O
is	O
progressing	O
or	O
not	O
.	O
for	O
this	O
,	O
the	O
error	O
should	O
be	O
nor-	O
malized	O
,	O
i.e	O
.	O
represent	O
a	O
distance	O
measure	O
between	O
the	O
correct	O
and	O
the	O
current	O
out-	O
put	O
of	O
the	O
network	O
.	O
for	O
example	O
,	O
we	O
can	O
take	O
the	O
same	O
pattern-speciﬁc	O
,	O
squared	O
er-	O
ror	O
with	O
a	O
prefactor	O
,	O
which	O
we	O
are	O
also	O
go-	O
ing	O
to	O
use	O
to	O
derive	O
the	O
backpropagation	B
of	I
error	I
(	O
let	O
ω	O
be	O
output	O
neurons	O
and	O
o	O
the	O
set	O
of	O
output	O
neurons	O
)	O
:	O
x	O
ω∈o	O
errp	O
=	O
1	O
2	O
(	O
tω	O
−	O
yω	O
)	O
2	O
(	O
4.1	O
)	O
errp	O
(	O
cid:73	O
)	O
deﬁnition	O
4.10	O
(	O
speciﬁc	O
error	O
)	O
.	O
the	O
speciﬁc	O
error	O
errp	O
is	O
based	O
on	O
a	O
single	O
training	O
sample	O
,	O
which	O
means	O
it	O
is	O
gener-	O
ated	O
online	O
.	O
additionally	O
,	O
the	O
root	B
mean	I
square	I
(	O
ab-	O
breviated	O
:	O
rms	O
)	O
and	O
the	O
euclidean	O
distance	O
are	O
often	O
used	O
.	O
the	O
euclidean	O
distance	O
(	O
generalization	B
of	O
the	O
theorem	O
of	O
pythagoras	O
)	O
is	O
useful	O
for	O
lower	O
dimensions	O
where	O
we	O
can	O
still	O
visual-	O
ize	O
its	O
usefulness	O
.	O
deﬁnition	O
4.11	O
(	O
euclidean	O
distance	O
)	O
.	O
the	O
euclidean	O
distance	O
between	O
two	O
vec-	O
tors	O
t	O
and	O
y	O
is	O
deﬁned	O
as	O
sx	O
ω∈o	O
errp	O
=	O
generally	O
,	O
the	O
root	B
mean	I
square	I
is	O
com-	O
monly	O
used	O
since	O
it	O
considers	O
extreme	O
out-	O
liers	O
to	O
a	O
greater	O
extent	O
.	O
deﬁnition	O
4.12	O
(	O
root	B
mean	I
square	I
)	O
.	O
the	O
root	B
mean	I
square	I
of	O
two	O
vectors	O
t	O
and	O
y	O
is	O
deﬁned	O
as	O
sp	O
errp	O
=	O
ω∈o	O
(	O
tω	O
−	O
yω	O
)	O
2	O
|o|	O
.	O
(	O
4.3	O
)	O
as	O
for	O
oﬄine	O
learning	B
,	O
the	O
total	B
error	I
in	O
the	O
course	O
of	O
one	O
training	O
epoch	O
is	O
inter-	O
esting	O
and	O
useful	O
,	O
too	O
:	O
err	O
=	O
x	O
p∈p	O
errp	O
(	O
4.4	O
)	O
deﬁnition	O
4.13	O
(	O
total	B
error	I
)	O
.	O
the	O
total	B
error	I
err	O
is	O
based	O
on	O
all	O
training	O
samples	O
,	O
(	O
cid:74	O
)	O
err	O
that	O
means	O
it	O
is	O
generated	O
oﬄine	O
.	O
analogously	O
we	O
can	O
generate	O
a	O
total	O
rms	O
and	O
a	O
total	O
euclidean	O
distance	O
in	O
the	O
course	O
of	O
a	O
whole	O
epoch	B
.	O
of	O
course	O
,	O
it	O
is	O
possible	O
to	O
use	O
other	O
types	O
of	O
error	O
mea-	O
surement	O
.	O
to	O
get	O
used	O
to	O
further	O
error	O
measurement	O
methods	O
,	O
i	O
suggest	O
to	O
have	O
a	O
look	O
into	O
the	O
technical	O
report	O
of	O
prechelt	O
[	O
pre94	O
]	O
.	O
in	O
this	O
report	O
,	O
both	O
error	O
mea-	O
surement	O
methods	O
and	O
sample	O
problems	O
are	O
discussed	O
(	O
this	O
is	O
why	O
there	O
will	O
be	O
a	O
simmilar	O
suggestion	O
during	O
the	O
discussion	O
of	O
exemplary	O
problems	O
)	O
.	O
snipe	O
:	O
there	O
are	O
several	O
static	O
meth-	O
ods	O
representing	O
diﬀerent	O
methods	O
of	O
er-	O
ror	O
measurement	O
implemented	O
in	O
the	O
class	O
errormeasurement	O
.	O
(	O
tω	O
−	O
yω	O
)	O
2	O
.	O
(	O
4.2	O
)	O
depending	O
on	O
our	O
method	O
of	O
error	O
mea-	O
surement	O
our	O
learning	B
curve	O
certainly	O
58	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
objectivity	O
dkriesel.com	O
4.4	O
learning	B
curve	O
and	O
error	O
measurement	O
changes	O
,	O
too	O
.	O
a	O
perfect	O
learning	B
curve	O
looks	O
like	O
a	O
negative	O
exponential	O
func-	O
tion	O
,	O
that	O
means	O
it	O
is	O
proportional	O
to	O
e−t	O
(	O
ﬁg	O
.	O
4.2	O
on	O
the	O
following	O
page	O
)	O
.	O
thus	O
,	O
the	O
representation	O
of	O
the	O
learning	B
curve	O
can	O
be	O
illustrated	O
by	O
means	O
of	O
a	O
logarithmic	O
scale	O
(	O
ﬁg	O
.	O
4.2	O
,	O
second	O
diagram	O
from	O
the	O
bot-	O
tom	O
)	O
–	O
with	O
the	O
said	O
scaling	O
combination	O
a	O
descending	O
line	O
implies	O
an	O
exponential	O
descent	O
of	O
the	O
error	O
.	O
with	O
the	O
network	O
doing	O
a	O
good	O
job	O
,	O
the	O
problems	O
being	O
not	O
too	O
diﬃcult	O
and	O
the	O
logarithmic	O
representation	O
of	O
err	O
you	O
can	O
see	O
-	O
metaphorically	O
speaking	O
-	O
a	O
descend-	O
ing	O
line	O
that	O
often	O
forms	O
``	O
spikes	O
''	O
at	O
the	O
bottom	O
–	O
here	O
,	O
we	O
reach	O
the	O
limit	O
of	O
the	O
64-bit	O
resolution	O
of	O
our	O
computer	O
and	O
our	O
network	O
has	O
actually	O
learned	O
the	O
optimum	O
of	O
what	O
it	O
is	O
capable	O
of	O
learning	B
.	O
i.e	O
.	O
typical	O
learning	B
curves	O
can	O
show	O
a	O
few	O
ﬂat	O
areas	O
as	O
well	O
,	O
they	O
can	O
show	O
some	O
steps	O
,	O
which	O
is	O
no	O
sign	O
of	O
a	O
malfunctioning	O
learning	B
process	O
.	O
as	O
we	O
can	O
also	O
see	O
in	O
ﬁg	O
.	O
4.2	O
,	O
a	O
well-suited	O
representation	O
can	O
make	O
any	O
slightly	O
decreasing	O
learning	B
curve	O
look	O
good	O
–	O
so	O
just	O
be	O
cautious	O
when	O
reading	O
the	O
literature	O
.	O
4.4.1	O
when	O
do	O
we	O
stop	O
learning	B
?	O
now	O
,	O
the	O
big	O
question	O
is	O
:	O
when	O
do	O
we	O
stop	O
learning	B
?	O
generally	O
,	O
the	O
training	O
is	O
stopped	O
when	O
the	O
user	O
in	O
front	O
of	O
the	O
learn-	O
ing	O
computer	O
``	O
thinks	O
''	O
the	O
error	O
was	O
small	O
enough	O
.	O
indeed	O
,	O
there	O
is	O
no	O
easy	O
answer	O
and	O
thus	O
i	O
can	O
once	O
again	O
only	O
give	O
you	O
something	O
to	O
think	O
about	O
,	O
which	O
,	O
however	O
,	O
depends	O
on	O
a	O
more	O
objective	O
view	O
on	O
the	O
comparison	O
of	O
several	O
learning	B
curves	O
.	O
conﬁdence	O
in	O
the	O
results	O
,	O
for	O
example	O
,	O
is	O
boosted	O
,	O
when	O
the	O
network	O
always	O
reaches	O
nearly	O
the	O
same	O
ﬁnal	O
error-rate	O
for	O
diﬀer-	O
ent	O
random	O
initializations	O
–	O
so	O
repeated	O
initialization	O
and	O
training	O
will	O
provide	O
a	O
more	O
objective	O
result	O
.	O
on	O
the	O
other	O
hand	O
,	O
it	O
can	O
be	O
possible	O
that	O
a	O
curve	O
descending	O
fast	O
in	O
the	O
beginning	O
can	O
,	O
after	O
a	O
longer	O
time	O
of	O
learning	B
,	O
be	O
overtaken	O
by	O
another	O
curve	O
:	O
this	O
can	O
indi-	O
cate	O
that	O
either	O
the	O
learning	B
rate	I
of	O
the	O
worse	O
curve	O
was	O
too	O
high	O
or	O
the	O
worse	O
curve	O
itself	O
simply	O
got	O
stuck	O
in	O
a	O
local	O
min-	O
imum	O
,	O
but	O
was	O
the	O
ﬁrst	O
to	O
ﬁnd	O
it	O
.	O
remember	O
:	O
larger	O
error	O
values	O
are	O
worse	O
than	O
the	O
small	O
ones	O
.	O
but	O
,	O
in	O
any	O
case	O
,	O
note	O
:	O
many	O
people	O
only	O
generate	O
a	O
learning	B
curve	O
in	O
respect	O
of	O
the	O
training	O
data	O
(	O
and	O
then	O
they	O
are	O
surprised	O
that	O
only	O
a	O
few	O
things	O
will	O
work	O
)	O
–	O
but	O
for	O
reasons	O
of	O
objectivity	O
and	O
clarity	O
it	O
should	O
not	O
be	O
forgotten	O
to	O
plot	O
the	O
veriﬁcation	O
data	O
on	O
a	O
second	O
learning	O
curve	O
,	O
which	O
generally	O
provides	O
values	O
that	O
are	O
slightly	O
worse	O
and	O
with	O
stronger	O
oscillation	O
.	O
but	O
with	O
good	O
generalization	B
the	O
curve	O
can	O
de-	O
crease	O
,	O
too	O
.	O
when	O
the	O
network	O
eventually	O
begins	O
to	O
memorize	O
the	O
samples	O
,	O
the	O
shape	O
of	O
the	O
learning	B
curve	O
can	O
provide	O
an	O
indication	O
:	O
if	O
the	O
learning	B
curve	O
of	O
the	O
veriﬁcation	O
samples	O
is	O
suddenly	O
and	O
rapidly	O
rising	O
while	O
the	O
learning	B
curve	O
of	O
the	O
veriﬁcation	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
59	O
chapter	O
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
(	O
fundamental	O
)	O
dkriesel.com	O
figure	O
4.2	O
:	O
all	O
four	O
illustrations	O
show	O
the	O
same	O
(	O
idealized	O
,	O
because	O
very	O
smooth	O
)	O
learning	B
curve	O
.	O
note	O
the	O
alternating	O
logarithmic	O
and	O
linear	O
scalings	O
!	O
also	O
note	O
the	O
small	O
``	O
inaccurate	O
spikes	O
''	O
visible	O
in	O
the	O
sharp	O
bend	O
of	O
the	O
curve	O
in	O
the	O
ﬁrst	O
and	O
second	O
diagram	O
from	O
bottom	O
.	O
60	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
0	O
5e−005	O
0.0001	O
0.00015	O
0.0002	O
0.00025	O
0	O
100	O
200	O
300	O
400	O
500	O
600	O
700	O
800	O
900	O
1000fehlerepoche	O
0	O
2e−005	O
4e−005	O
6e−005	O
8e−005	O
0.0001	O
0.00012	O
0.00014	O
0.00016	O
0.00018	O
0.0002	O
1	O
10	O
100	O
1000fehlerepoche	O
1e−035	O
1e−030	O
1e−025	O
1e−020	O
1e−015	O
1e−010	O
1e−005	O
1	O
0	O
100	O
200	O
300	O
400	O
500	O
600	O
700	O
800	O
900	O
1000fehlerepoche	O
1e−035	O
1e−030	O
1e−025	O
1e−020	O
1e−015	O
1e−010	O
1e−005	O
1	O
1	O
10	O
100	O
1000fehlerepoche	O
dkriesel.com	O
4.5	O
gradient	B
optimization	O
procedures	O
data	O
is	O
continuously	O
falling	O
,	O
this	O
could	O
indi-	O
cate	O
memorizing	O
and	O
a	O
generalization	B
get-	O
ting	O
poorer	O
and	O
poorer	O
.	O
at	O
this	O
point	O
it	O
could	O
be	O
decided	O
whether	O
the	O
network	O
has	O
already	O
learned	O
well	O
enough	O
at	O
the	O
next	O
point	O
of	O
the	O
two	O
curves	O
,	O
and	O
maybe	O
the	O
ﬁnal	O
point	O
of	O
learning	B
is	O
to	O
be	O
applied	O
here	O
(	O
this	O
procedure	O
is	O
called	O
early	O
stop-	O
ping	O
)	O
.	O
once	O
again	O
i	O
want	O
to	O
remind	O
you	O
that	O
they	O
are	O
all	O
acting	O
as	O
indicators	O
and	O
not	O
to	O
draw	O
if-then	O
conclusions	O
.	O
4.5	O
gradient	B
optimization	O
procedures	O
in	O
order	O
to	O
establish	O
the	O
mathematical	O
ba-	O
sis	O
for	O
some	O
of	O
the	O
following	O
learning	B
pro-	O
cedures	O
i	O
want	O
to	O
explain	O
brieﬂy	O
what	O
is	O
meant	O
by	O
gradient	B
descent	I
:	O
the	O
backpro-	O
pagation	O
of	O
error	O
learning	O
procedure	O
,	O
for	O
example	O
,	O
involves	O
this	O
mathematical	O
basis	B
and	O
thus	O
inherits	O
the	O
advantages	O
and	O
dis-	O
advantages	O
of	O
the	O
gradient	B
descent	I
.	O
gradient	B
descent	I
procedures	O
are	O
generally	O
used	O
where	O
we	O
want	O
to	O
maximize	O
or	O
mini-	O
mize	O
n-dimensional	O
functions	O
.	O
due	O
to	O
clar-	O
ity	O
the	O
illustration	O
(	O
ﬁg	O
.	O
4.3	O
on	O
the	O
next	O
page	O
)	O
shows	O
only	O
two	O
dimensions	O
,	O
but	O
prin-	O
cipally	O
there	O
is	O
no	O
limit	O
to	O
the	O
number	O
of	O
dimensions	O
.	O
the	O
gradient	B
is	O
a	O
vector	O
g	O
that	O
is	O
de-	O
ﬁned	O
for	O
any	O
diﬀerentiable	O
point	O
of	O
a	O
func-	O
tion	O
,	O
that	O
points	O
from	O
this	O
point	O
exactly	O
towards	O
the	O
steepest	O
ascent	O
and	O
indicates	O
the	O
gradient	B
in	O
this	O
direction	O
by	O
means	O
gradient	B
is	O
multi-dim	O
.	O
derivative	O
of	O
its	O
norm	O
|g|	O
.	O
thus	O
,	O
the	O
gradient	B
is	O
a	O
generalization	B
of	O
the	O
derivative	O
for	O
multi-	O
dimensional	O
functions	O
.	O
accordingly	O
,	O
the	O
negative	O
gradient	B
−g	O
exactly	O
points	O
to-	O
wards	O
the	O
steepest	O
descent	O
.	O
the	O
gradient	B
operator	O
∇	O
is	O
referred	O
to	O
as	O
nabla	O
op-	O
(	O
cid:74	O
)	O
∇	O
erator	O
,	O
the	O
overall	O
notation	O
of	O
the	O
the	O
gradient	B
g	O
of	O
the	O
point	O
(	O
x	O
,	O
y	O
)	O
of	O
a	O
two-	O
dimensional	O
function	B
f	O
being	O
g	O
(	O
x	O
,	O
y	O
)	O
=	O
∇f	O
(	O
x	O
,	O
y	O
)	O
.	O
deﬁnition	O
4.14	O
(	O
gradient	B
)	O
.	O
let	O
g	O
be	O
a	O
gradient	B
.	O
then	O
g	O
is	O
a	O
vector	O
with	O
n	O
components	O
that	O
is	O
deﬁned	O
for	O
any	O
point	O
of	O
a	O
(	O
diﬀerential	O
)	O
n-dimensional	O
function	B
f	O
(	O
x1	O
,	O
x2	O
,	O
.	O
.	O
.	O
,	O
xn	O
)	O
.	O
the	O
gradient	B
operator	O
notation	O
is	O
deﬁned	O
as	O
g	O
(	O
x1	O
,	O
x2	O
,	O
.	O
.	O
.	O
,	O
xn	O
)	O
=	O
∇f	O
(	O
x1	O
,	O
x2	O
,	O
.	O
.	O
.	O
,	O
xn	O
)	O
.	O
g	O
directs	O
from	O
any	O
point	O
of	O
f	O
towards	O
the	O
steepest	O
ascent	O
from	O
this	O
point	O
,	O
with	O
|g|	O
corresponding	O
to	O
the	O
degree	O
of	O
this	O
as-	O
cent	O
.	O
gradient	B
descent	I
means	O
to	O
going	O
downhill	O
in	O
small	O
steps	O
from	O
any	O
starting	O
point	O
of	O
our	O
function	B
towards	O
the	O
gradient	B
g	O
(	O
which	O
means	O
,	O
vividly	O
speaking	O
,	O
the	O
direction	O
to	O
which	O
a	O
ball	O
would	O
roll	O
from	O
the	O
starting	O
point	O
)	O
,	O
with	O
the	O
size	O
of	O
the	O
steps	O
being	O
pro-	O
portional	O
to	O
|g|	O
(	O
the	O
steeper	O
the	O
descent	O
,	O
the	O
longer	O
the	O
steps	O
)	O
.	O
therefore	O
,	O
we	O
move	O
slowly	O
on	O
a	O
ﬂat	O
plateau	O
,	O
and	O
on	O
a	O
steep	O
as-	O
cent	O
we	O
run	O
downhill	O
rapidly	O
.	O
if	O
we	O
came	O
into	O
a	O
valley	O
,	O
we	O
would	O
-	O
depending	O
on	O
the	O
size	O
of	O
our	O
steps	O
-	O
jump	O
over	O
it	O
or	O
we	O
would	O
return	B
into	O
the	O
valley	O
across	O
the	O
opposite	O
hillside	O
in	O
order	O
to	O
come	O
closer	O
and	O
closer	O
to	O
the	O
deepest	O
point	O
of	O
the	O
valley	O
by	O
walk-	O
ing	O
back	O
and	O
forth	O
,	O
similar	O
to	O
our	O
ball	O
mov-	O
ing	O
within	O
a	O
round	O
bowl	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
61	O
chapter	O
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
(	O
fundamental	O
)	O
dkriesel.com	O
figure	O
4.3	O
:	O
visualization	O
of	O
the	O
gradient	B
descent	I
on	O
a	O
two-dimensional	O
error	B
function	I
.	O
we	O
move	O
forward	O
in	O
the	O
opposite	O
direction	O
of	O
g	O
,	O
i.e	O
.	O
with	O
the	O
steepest	O
descent	O
towards	O
the	O
lowest	O
point	O
,	O
with	O
the	O
step	O
width	O
being	O
proportional	O
to	O
|g|	O
(	O
the	O
steeper	O
the	O
descent	O
,	O
the	O
faster	O
the	O
steps	O
)	O
.	O
on	O
the	O
left	O
the	O
area	O
is	O
shown	O
in	O
3d	O
,	O
on	O
the	O
right	O
the	O
steps	O
over	O
the	O
contour	O
lines	O
are	O
shown	O
in	O
2d	O
.	O
here	O
it	O
is	O
obvious	O
how	O
a	O
movement	O
is	O
made	O
in	O
the	O
opposite	O
direction	O
of	O
g	O
towards	O
the	O
minimum	O
of	O
the	O
function	B
and	O
continuously	O
slows	O
down	O
proportionally	O
to	O
|g|	O
.	O
source	O
:	O
http	O
:	O
//webster.fhs-hagenberg.ac.at/staff/sdreisei/teaching/ws2001-2002/	O
patternclassification/graddescent.pdf	O
we	O
go	O
towards	O
the	O
gradient	B
deﬁnition	O
4.15	O
(	O
gradient	B
descent	I
)	O
.	O
let	O
f	O
be	O
an	O
n-dimensional	O
function	B
and	O
s	O
=	O
(	O
s1	O
,	O
s2	O
,	O
.	O
.	O
.	O
,	O
sn	O
)	O
the	O
given	O
starting	O
point	O
.	O
gradient	B
descent	I
means	O
going	O
from	O
f	O
(	O
s	O
)	O
against	O
the	O
direction	O
of	O
g	O
,	O
i.e	O
.	O
towards	O
−g	O
with	O
steps	O
of	O
the	O
size	O
of	O
|g|	O
towards	O
smaller	O
and	O
smaller	O
values	O
of	O
f.	O
gradient	B
descent	I
procedures	O
are	O
not	O
an	O
er-	O
rorless	O
optimization	O
procedure	O
at	O
all	O
(	O
as	O
we	O
will	O
see	O
in	O
the	O
following	O
sections	O
)	O
–	O
how-	O
ever	O
,	O
they	O
work	O
still	O
well	O
on	O
many	O
prob-	O
lems	O
,	O
which	O
makes	O
them	O
an	O
optimization	O
paradigm	O
that	O
is	O
frequently	O
used	O
.	O
anyway	O
,	O
let	O
us	O
have	O
a	O
look	O
on	O
their	O
potential	O
disad-	O
vantages	O
so	O
we	O
can	O
keep	O
them	O
in	O
mind	O
a	O
bit	O
.	O
4.5.1	O
gradient	B
procedures	O
incorporate	O
several	O
problems	O
as	O
already	O
implied	O
in	O
section	O
4.5	O
,	O
the	O
gra-	O
dient	O
descent	O
(	O
and	O
therefore	O
the	O
backpro-	O
pagation	O
)	O
is	O
promising	O
but	O
not	O
foolproof	O
.	O
one	O
problem	O
,	O
is	O
that	O
the	O
result	O
does	O
not	O
always	O
reveal	O
if	O
an	O
error	O
has	O
occurred	O
.	O
4.5.1.1	O
often	O
,	O
gradient	B
descents	O
converge	O
against	O
suboptimal	O
minima	O
every	O
gradient	B
descent	I
procedure	O
can	O
,	O
for	O
example	O
,	O
get	O
stuck	O
within	O
a	O
local	O
mini-	O
mum	O
(	O
part	O
a	O
of	O
ﬁg	O
.	O
4.4	O
on	O
the	O
facing	O
page	O
)	O
.	O
gradient	B
descent	I
with	O
errors	O
62	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
4.5	O
gradient	B
optimization	O
procedures	O
figure	O
4.4	O
:	O
possible	O
errors	O
during	O
a	O
gradient	B
descent	I
:	O
a	O
)	O
detecting	O
bad	O
minima	O
,	O
b	O
)	O
quasi-standstill	O
with	O
small	O
gradient	B
,	O
c	O
)	O
oscillation	O
in	O
canyons	O
,	O
d	O
)	O
leaving	O
good	O
minima	O
.	O
this	O
problem	O
is	O
increasing	O
proportionally	O
to	O
the	O
size	O
of	O
the	O
error	O
surface	O
,	O
and	O
there	O
is	O
no	O
universal	O
solution	O
.	O
in	O
reality	O
,	O
one	O
can	O
not	O
know	O
if	O
the	O
optimal	O
minimum	O
is	O
reached	O
and	O
considers	O
a	O
training	O
success-	O
ful	O
,	O
if	O
an	O
acceptable	O
minimum	O
is	O
found	O
.	O
4.5.1.2	O
flat	O
plataeus	O
on	O
the	O
error	O
surface	O
may	O
cause	O
training	O
slowness	O
when	O
passing	O
a	O
ﬂat	O
plateau	O
,	O
for	O
instance	O
,	O
the	O
gradient	B
also	O
becomes	O
negligibly	O
small	O
because	O
there	O
is	O
hardly	O
a	O
descent	O
(	O
part	O
b	O
of	O
ﬁg	O
.	O
4.4	O
)	O
,	O
which	O
requires	O
many	O
further	O
steps	O
.	O
a	O
hypothetically	O
possible	O
gradient	B
of	O
0	O
would	O
completely	O
stop	O
the	O
descent	O
.	O
4.5.1.3	O
even	O
if	O
good	O
minima	O
are	O
reached	O
,	O
they	O
may	O
be	O
left	O
afterwards	O
on	O
the	O
other	O
hand	O
the	O
gradient	B
is	O
very	O
large	O
at	O
a	O
steep	O
slope	O
so	O
that	O
large	O
steps	O
can	O
be	O
made	O
and	O
a	O
good	O
minimum	O
can	O
pos-	O
sibly	O
be	O
missed	O
(	O
part	O
d	O
of	O
ﬁg	O
.	O
4.4	O
)	O
.	O
4.5.1.4	O
steep	O
canyons	O
in	O
the	O
error	O
surface	O
may	O
cause	O
oscillations	O
a	O
sudden	O
alternation	O
from	O
one	O
very	O
strong	O
negative	O
gradient	B
to	O
a	O
very	O
strong	O
positive	O
one	O
can	O
even	O
result	O
in	O
oscillation	O
(	O
part	O
c	O
of	O
ﬁg	O
.	O
4.4	O
)	O
.	O
in	O
nature	O
,	O
such	O
an	O
error	O
does	O
not	O
occur	O
very	O
often	O
so	O
that	O
we	O
can	O
think	O
about	O
the	O
possibilities	O
b	O
and	O
d.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
63	O
chapter	O
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
(	O
fundamental	O
)	O
dkriesel.com	O
4.6	O
exemplary	O
problems	O
allow	O
for	O
testing	O
self-coded	O
learning	B
strategies	O
we	O
looked	O
at	O
learning	B
from	O
the	O
formal	O
point	O
of	O
view	O
–	O
not	O
much	O
yet	O
but	O
a	O
little	O
.	O
now	O
it	O
is	O
time	O
to	O
look	O
at	O
a	O
few	O
exemplary	O
problem	O
you	O
can	O
later	O
use	O
to	O
test	O
imple-	O
mented	O
networks	O
and	O
learning	B
rules	O
.	O
4.6.1	O
boolean	O
functions	O
i1	O
0	O
0	O
0	O
0	O
1	O
1	O
1	O
1	O
i2	O
0	O
0	O
1	O
1	O
0	O
0	O
1	O
1	O
i3	O
ω	O
0	O
1	O
0	O
1	O
0	O
0	O
1	O
1	O
0	O
0	O
1	O
1	O
0	O
1	O
1	O
0	O
table	O
4.1	O
:	O
illustration	O
of	O
the	O
parity	O
function	B
with	O
three	O
inputs	O
.	O
a	O
popular	O
example	O
is	O
the	O
one	O
that	O
did	O
not	O
work	O
in	O
the	O
nineteen-sixties	O
:	O
the	O
xor	O
function	B
(	O
b2	O
→	O
b1	O
)	O
.	O
we	O
need	O
a	O
hidden	O
neuron	O
layer	B
,	O
which	O
we	O
have	O
discussed	O
in	O
detail	O
.	O
thus	O
,	O
we	O
need	O
at	O
least	O
two	O
neu-	O
rons	O
in	O
the	O
inner	O
layer	B
.	O
let	O
the	O
activation	B
function	I
in	O
all	O
layers	O
(	O
except	O
in	O
the	O
input	B
layer	I
,	O
of	O
course	O
)	O
be	O
the	O
hyperbolic	B
tangent	I
.	O
trivially	O
,	O
we	O
now	O
expect	O
the	O
outputs	O
1.0	O
or	O
−1.0	O
,	O
depending	O
on	O
whether	O
the	O
func-	O
tion	O
xor	O
outputs	O
1	O
or	O
0	O
-	O
and	O
exactly	O
here	O
is	O
where	O
the	O
ﬁrst	O
beginner	O
’	O
s	O
mistake	O
occurs	O
.	O
for	O
outputs	O
close	O
to	O
1	O
or	O
-1	O
,	O
i.e	O
.	O
close	O
to	O
the	O
limits	O
of	O
the	O
hyperbolic	B
tangent	I
(	O
or	O
in	O
case	O
of	O
the	O
fermi	O
function	B
0	O
or	O
1	O
)	O
,	O
we	O
need	O
very	O
large	O
network	O
inputs	O
.	O
the	O
only	O
chance	O
to	O
reach	O
these	O
network	O
inputs	O
are	O
large	O
weights	O
,	O
which	O
have	O
to	O
be	O
learned	O
:	O
the	O
learning	B
process	O
is	O
largely	O
extended	O
.	O
therefore	O
it	O
is	O
wiser	O
to	O
enter	O
the	O
teaching	O
inputs	O
0.9	O
or	O
−0.9	O
as	O
desired	O
outputs	O
or	O
to	O
be	O
satisﬁed	O
when	O
the	O
network	O
outputs	O
those	O
values	O
instead	O
of	O
1	O
and	O
−1	O
.	O
another	O
favourite	O
example	O
for	O
singlelayer	O
perceptrons	O
are	O
the	O
boolean	O
functions	O
and	O
and	O
or	O
.	O
4.6.2	O
the	O
parity	O
function	B
the	O
parity	O
function	B
maps	O
a	O
set	O
of	O
bits	O
to	O
1	O
or	O
0	O
,	O
depending	O
on	O
whether	O
an	O
even	O
num-	O
ber	O
of	O
input	O
bits	O
is	O
set	O
to	O
1	O
or	O
not	O
.	O
ba-	O
sically	O
,	O
this	O
is	O
the	O
function	B
bn	O
→	O
b1	O
.	O
it	O
is	O
characterized	O
by	O
easy	O
learnability	B
up	O
to	O
approx	O
.	O
n	O
=	O
3	O
(	O
shown	O
in	O
table	O
4.1	O
)	O
,	O
but	O
the	O
learning	B
eﬀort	O
rapidly	O
increases	O
from	O
n	O
=	O
4.	O
the	O
reader	O
may	O
create	O
a	O
score	O
ta-	O
ble	O
for	O
the	O
2-bit	O
parity	O
function	B
.	O
what	O
is	O
conspicuous	O
?	O
4.6.3	O
the	O
2-spiral	O
problem	O
as	O
a	O
training	O
sample	O
for	O
a	O
function	B
let	O
us	O
take	O
two	O
spirals	O
coiled	O
into	O
each	O
other	O
(	O
ﬁg	O
.	O
4.5	O
on	O
the	O
facing	O
page	O
)	O
with	O
the	O
function	B
certainly	O
representing	O
a	O
mapping	O
64	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
4.6	O
exemplary	O
problems	O
figure	O
4.5	O
:	O
illustration	O
of	O
the	O
training	O
samples	O
of	O
the	O
2-spiral	O
problem	O
figure	O
4.6	O
:	O
illustration	O
of	O
training	O
samples	O
for	O
the	O
checkerboard	O
problem	O
r2	O
→	O
b1	O
.	O
one	O
of	O
the	O
spirals	O
is	O
assigned	O
to	O
the	O
output	O
value	O
1	O
,	O
the	O
other	O
spiral	O
to	O
0.	O
here	O
,	O
memorizing	O
does	O
not	O
help	O
.	O
the	O
network	O
has	O
to	O
understand	O
the	O
mapping	O
it-	O
self	O
.	O
this	O
example	O
can	O
be	O
solved	O
by	O
means	O
of	O
an	O
mlp	O
,	O
too	O
.	O
4.6.4	O
the	O
checkerboard	O
problem	O
we	O
again	O
create	O
a	O
two-dimensional	O
func-	O
tion	O
of	O
the	O
form	O
r2	O
→	O
b1	O
and	O
specify	O
checkered	O
training	O
samples	O
(	O
ﬁg	O
.	O
4.6	O
)	O
with	O
one	O
colored	O
ﬁeld	O
representing	O
1	O
and	O
all	O
the	O
rest	O
of	O
them	O
representing	O
0.	O
the	O
diﬃculty	O
increases	O
proportionally	O
to	O
the	O
size	O
of	O
the	O
function	B
:	O
while	O
a	O
3×3	O
ﬁeld	O
is	O
easy	O
to	O
learn	O
,	O
the	O
larger	O
ﬁelds	O
are	O
more	O
diﬃcult	O
(	O
here	O
we	O
eventually	O
use	O
methods	O
that	O
are	O
more	O
suitable	O
for	O
this	O
kind	O
of	O
problems	O
than	O
the	O
mlp	O
)	O
.	O
the	O
2-spiral	O
problem	O
is	O
very	O
similar	O
to	O
the	O
checkerboard	O
problem	O
,	O
only	O
that	O
,	O
mathe-	O
matically	O
speaking	O
,	O
the	O
ﬁrst	O
problem	O
is	O
us-	O
ing	O
polar	O
coordinates	O
instead	O
of	O
cartesian	O
coordinates	O
.	O
i	O
just	O
want	O
to	O
introduce	O
as	O
an	O
example	O
one	O
last	O
trivial	O
case	O
:	O
the	O
iden-	O
tity	O
.	O
4.6.5	O
the	O
identity	O
function	O
by	O
using	O
linear	O
activation	O
functions	O
the	O
identity	O
mapping	O
from	O
r1	O
to	O
r1	O
(	O
of	O
course	O
only	O
within	O
the	O
parameters	O
of	O
the	O
used	O
ac-	O
tivation	O
function	B
)	O
is	O
no	O
problem	O
for	O
the	O
network	O
,	O
but	O
we	O
put	O
some	O
obstacles	O
in	O
its	O
way	O
by	O
using	O
our	O
sigmoid	O
functions	O
so	O
that	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
65	O
chapter	O
4	O
fundamentals	O
on	O
learning	B
and	O
training	O
samples	O
(	O
fundamental	O
)	O
dkriesel.com	O
it	O
would	O
be	O
diﬃcult	O
for	O
the	O
network	O
to	O
learn	O
the	O
identity	O
.	O
just	O
try	O
it	O
for	O
the	O
fun	O
of	O
it	O
.	O
now	O
,	O
it	O
is	O
time	O
to	O
hava	O
a	O
look	O
at	O
our	O
ﬁrst	O
mathematical	O
learning	B
rule	O
.	O
4.6.6	O
there	O
are	O
lots	O
of	O
other	O
exemplary	O
problems	O
for	O
lots	O
and	O
lots	O
of	O
further	O
exemplary	O
prob-	O
lems	O
,	O
i	O
want	O
to	O
recommend	O
the	O
technical	O
report	O
written	O
by	O
prechelt	O
[	O
pre94	O
]	O
which	O
also	O
has	O
been	O
named	O
in	O
the	O
sections	O
about	O
error	O
measurement	O
procedures..	O
4.7	O
the	O
hebbian	O
learning	B
rule	O
is	O
the	O
basis	B
for	O
most	O
other	O
learning	B
rules	O
in	O
1949	O
,	O
donald	O
o.	O
hebb	O
formulated	O
the	O
hebbian	O
rule	O
[	O
heb49	O
]	O
which	O
is	O
the	O
ba-	O
sis	O
for	O
most	O
of	O
the	O
more	O
complicated	O
learn-	O
ing	O
rules	O
we	O
will	O
discuss	O
in	O
this	O
text	O
.	O
we	O
distinguish	O
between	O
the	O
original	O
form	O
and	O
the	O
more	O
general	O
form	O
,	O
which	O
is	O
a	O
kind	O
of	O
principle	O
for	O
other	O
learning	B
rules	O
.	O
4.7.1	O
original	O
rule	O
deﬁnition	O
4.16	O
(	O
hebbian	O
rule	O
)	O
.	O
``	O
if	O
neu-	O
ron	O
j	O
receives	O
an	O
input	O
from	O
neuron	O
i	O
and	O
if	O
both	O
neurons	O
are	O
strongly	O
active	O
at	O
the	O
same	O
time	O
,	O
then	O
increase	O
the	O
weight	B
wi	O
,	O
j	O
(	O
i.e	O
.	O
the	O
strength	O
of	O
the	O
connection	B
be-	O
tween	O
i	O
and	O
j	O
)	O
.	O
''	O
mathematically	O
speaking	O
,	O
the	O
rule	O
is	O
:	O
∆wi	O
,	O
j	O
∼	O
ηoiaj	O
(	O
4.5	O
)	O
with	O
∆wi	O
,	O
j	O
being	O
the	O
change	B
in	I
weight	I
from	O
i	O
to	O
j	O
,	O
which	O
is	O
proportional	O
to	O
the	O
(	O
cid:74	O
)	O
∆wi	O
,	O
j	O
following	O
factors	O
:	O
.	O
the	O
output	O
oi	O
of	O
the	O
predecessor	O
neu-	O
ron	O
i	O
,	O
as	O
well	O
as	O
,	O
.	O
the	O
activation	B
aj	O
of	O
the	O
successor	O
neu-	O
ron	O
j	O
,	O
.	O
a	O
constant	O
η	O
,	O
i.e	O
.	O
the	O
learning	B
rate	I
,	O
which	O
will	O
be	O
discussed	O
in	O
section	O
5.4.3.	O
the	O
changes	O
in	O
weight	B
∆wi	O
,	O
j	O
are	O
simply	O
added	O
to	O
the	O
weight	B
wi	O
,	O
j	O
.	O
why	O
am	O
i	O
speaking	O
twice	O
about	O
activation	B
,	O
but	O
in	O
the	O
formula	O
i	O
am	O
using	O
oi	O
and	O
aj	O
,	O
i.e	O
.	O
the	O
output	O
of	O
neuron	O
of	O
neuron	O
i	O
and	O
the	O
ac-	O
tivation	O
of	O
neuron	O
j	O
?	O
remember	O
that	O
the	O
identity	O
is	O
often	O
used	O
as	O
output	B
function	I
and	O
therefore	O
ai	O
and	O
oi	O
of	O
a	O
neuron	O
are	O
of-	O
ten	O
the	O
same	O
.	O
besides	O
,	O
hebb	O
postulated	O
his	O
rule	O
long	O
before	O
the	O
speciﬁcation	O
of	O
technical	O
neurons	O
.	O
considering	O
that	O
this	O
learning	B
rule	O
was	O
preferred	O
in	O
binary	O
acti-	O
vations	O
,	O
it	O
is	O
clear	O
that	O
with	O
the	O
possible	O
activations	O
(	O
1	O
,	O
0	O
)	O
the	O
weights	O
will	O
either	O
in-	O
crease	O
or	O
remain	O
constant	O
.	O
sooner	O
or	O
later	O
they	O
would	O
go	O
ad	O
inﬁnitum	O
,	O
since	O
they	O
can	O
only	O
be	O
corrected	O
``	O
upwards	O
''	O
when	O
an	O
error	O
occurs	O
.	O
this	O
can	O
be	O
compensated	O
by	O
using	O
the	O
activations	O
(	O
-1,1	O
)	O
2.	O
thus	O
,	O
the	O
weights	O
are	O
decreased	O
when	O
the	O
activation	B
of	O
the	O
predecessor	O
neuron	O
dissents	O
from	O
the	O
one	O
of	O
the	O
successor	O
neuron	O
,	O
otherwise	O
they	O
are	O
increased	O
.	O
2	O
but	O
that	O
is	O
no	O
longer	O
the	O
``	O
original	O
version	O
''	O
of	O
the	O
hebbian	O
rule	O
.	O
weights	O
go	O
ad	O
inﬁnitum	O
66	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
early	O
form	O
of	O
the	O
rule	O
dkriesel.com	O
4.7	O
hebbian	O
rule	O
4.7.2	O
generalized	O
form	O
exercises	O
exercise	O
7.	O
calculate	O
the	O
average	O
value	O
µ	O
and	O
the	O
standard	O
deviation	O
σ	O
for	O
the	O
fol-	O
lowing	O
data	O
points	O
.	O
p1	O
=	O
(	O
2	O
,	O
2	O
,	O
2	O
)	O
p2	O
=	O
(	O
3	O
,	O
3	O
,	O
3	O
)	O
p3	O
=	O
(	O
4	O
,	O
4	O
,	O
4	O
)	O
p4	O
=	O
(	O
6	O
,	O
0	O
,	O
0	O
)	O
p5	O
=	O
(	O
0	O
,	O
6	O
,	O
0	O
)	O
p6	O
=	O
(	O
0	O
,	O
0	O
,	O
6	O
)	O
most	O
of	O
the	O
learning	B
rules	O
discussed	O
before	O
are	O
a	O
specialization	O
of	O
the	O
mathematically	O
more	O
general	O
form	O
[	O
mr86	O
]	O
of	O
the	O
hebbian	O
rule	O
.	O
deﬁnition	O
4.17	O
(	O
hebbian	O
rule	O
,	O
more	O
gen-	O
eral	O
)	O
.	O
the	O
generalized	O
form	O
of	O
the	O
hebbian	O
rule	O
only	O
speciﬁes	O
the	O
propor-	O
tionality	O
of	O
the	O
change	B
in	I
weight	I
to	O
the	O
product	O
of	O
two	O
undeﬁned	O
functions	O
,	O
but	O
with	O
deﬁned	O
input	O
values	O
.	O
∆wi	O
,	O
j	O
=	O
η	O
·	O
h	O
(	O
oi	O
,	O
wi	O
,	O
j	O
)	O
·	O
g	O
(	O
aj	O
,	O
tj	O
)	O
(	O
4.6	O
)	O
thus	O
,	O
the	O
product	O
of	O
the	O
functions	O
.	O
g	O
(	O
aj	O
,	O
tj	O
)	O
and	O
.	O
h	O
(	O
oi	O
,	O
wi	O
,	O
j	O
)	O
.	O
as	O
well	O
as	O
the	O
constant	O
learning	B
rate	I
η	O
results	O
in	O
the	O
change	B
in	I
weight	I
.	O
as	O
you	O
can	O
see	O
,	O
h	O
receives	O
the	O
output	O
of	O
the	O
pre-	O
decessor	O
cell	O
oi	O
as	O
well	O
as	O
the	O
weight	B
from	O
predecessor	O
to	O
successor	O
wi	O
,	O
j	O
while	O
g	O
ex-	O
pects	O
the	O
actual	O
and	O
desired	O
activation	B
of	O
the	O
successor	O
aj	O
and	O
tj	O
(	O
here	O
t	O
stands	O
for	O
the	O
aforementioned	O
teaching	B
input	I
)	O
.	O
as	O
al-	O
ready	O
mentioned	O
g	O
and	O
h	O
are	O
not	O
speciﬁed	O
in	O
this	O
general	O
deﬁnition	O
.	O
therefore	O
,	O
we	O
will	O
now	O
return	B
to	O
the	O
path	O
of	O
specializa-	O
tion	O
we	O
discussed	O
before	O
equation	O
4.6.	O
af-	O
ter	O
we	O
have	O
had	O
a	O
short	O
picture	O
of	O
what	O
a	O
learning	B
rule	O
could	O
look	O
like	O
and	O
of	O
our	O
thoughts	O
about	O
learning	B
itself	O
,	O
we	O
will	O
be	O
introduced	O
to	O
our	O
ﬁrst	O
network	O
paradigm	O
including	O
the	O
learning	B
procedure	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
67	O
part	O
ii	O
supervised	B
learning	I
network	O
paradigms	O
69	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
a	O
classic	O
among	O
the	O
neural	O
networks	O
.	O
if	O
we	O
talk	O
about	O
a	O
neural	O
network	O
,	O
then	O
in	O
the	O
majority	O
of	O
cases	O
we	O
speak	O
about	O
a	O
percepton	O
or	O
a	O
variation	O
of	O
it	O
.	O
perceptrons	O
are	O
multilayer	O
networks	O
without	O
recurrence	B
and	O
with	O
ﬁxed	O
input	O
and	O
output	O
layers	O
.	O
description	O
of	O
a	O
perceptron	B
,	O
its	O
limits	O
and	O
extensions	O
that	O
should	O
avoid	O
the	O
limitations	O
.	O
derivation	O
of	O
learning	B
procedures	O
and	O
discussion	O
of	O
their	O
problems	O
.	O
as	O
already	O
mentioned	O
in	O
the	O
history	O
of	O
neu-	O
ral	O
networks	O
,	O
the	O
perceptron	B
was	O
described	O
by	O
frank	O
rosenblatt	O
in	O
1958	O
[	O
ros58	O
]	O
.	O
initially	O
,	O
rosenblatt	O
deﬁned	O
the	O
already	O
discussed	O
weighted	B
sum	I
and	O
a	O
non-linear	O
activation	B
function	I
as	O
components	O
of	O
the	O
perceptron	B
.	O
there	O
is	O
no	O
established	O
deﬁnition	O
for	O
a	O
per-	O
ceptron	O
,	O
but	O
most	O
of	O
the	O
time	O
the	O
term	O
is	O
used	O
to	O
describe	O
a	O
feedforward	B
network	O
with	O
shortcut	B
connections	I
.	O
this	O
network	O
has	O
a	O
layer	B
of	O
scanner	O
neurons	O
(	O
retina	B
)	O
with	O
statically	O
weighted	O
connections	O
to	O
the	O
following	O
layer	B
and	O
is	O
called	O
input	B
layer	I
(	O
ﬁg	O
.	O
5.1	O
on	O
the	O
next	O
page	O
)	O
;	O
but	O
the	O
weights	O
of	O
all	O
other	O
layers	O
are	O
allowed	O
to	O
be	O
changed	O
.	O
all	O
neurons	O
subordinate	O
to	O
the	O
retina	B
are	O
pattern	B
detectors	O
.	O
here	O
we	O
ini-	O
tially	O
use	O
a	O
binary	O
perceptron	O
with	O
every	O
output	O
neuron	O
having	O
exactly	O
two	O
possi-	O
ble	O
output	O
values	O
(	O
e.g	O
.	O
{	O
0	O
,	O
1	O
}	O
or	O
{	O
−1	O
,	O
1	O
}	O
)	O
.	O
thus	O
,	O
a	O
binary	B
threshold	I
function	I
is	O
used	O
as	O
activation	B
function	I
,	O
depending	O
on	O
the	O
threshold	B
value	I
θ	O
of	O
the	O
output	O
neuron	O
.	O
in	O
a	O
way	O
,	O
the	O
binary	O
activation	O
function	B
represents	O
an	O
if	O
query	O
which	O
can	O
also	O
be	O
negated	O
by	O
means	O
of	O
negative	O
weights	O
.	O
the	O
perceptron	B
can	O
thus	O
be	O
used	O
to	O
ac-	O
complish	O
true	O
logical	O
information	O
process-	O
ing	O
.	O
whether	O
this	O
method	O
is	O
reasonable	O
is	O
an-	O
other	O
matter	O
–	O
of	O
course	O
,	O
this	O
is	O
not	O
the	O
easiest	O
way	O
to	O
achieve	O
boolean	O
logic	O
.	O
i	O
just	O
want	O
to	O
illustrate	O
that	O
perceptrons	O
can	O
be	O
used	O
as	O
simple	O
logical	O
components	O
and	O
that	O
,	O
theoretically	O
speaking	O
,	O
any	O
boolean	O
function	B
can	O
be	O
realized	O
by	O
means	O
of	O
per-	O
ceptrons	O
being	O
connected	O
in	O
series	O
or	O
in-	O
terconnected	O
in	O
a	O
sophisticated	O
way	O
.	O
but	O
71	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
figure	O
5.1	O
:	O
architecture	O
of	O
a	O
perceptron	B
with	O
one	O
layer	B
of	O
variable	O
connections	O
in	O
diﬀerent	O
views	O
.	O
the	O
solid-drawn	O
weight	B
layer	O
in	O
the	O
two	O
illustrations	O
on	O
the	O
bottom	O
can	O
be	O
trained	O
.	O
left	O
side	O
:	O
example	O
of	O
scanning	O
information	O
in	O
the	O
eye	O
.	O
right	O
side	O
,	O
upper	O
part	O
:	O
drawing	O
of	O
the	O
same	O
example	O
with	O
indicated	O
ﬁxed-weight	O
layer	B
using	O
the	O
deﬁned	O
designs	O
of	O
the	O
functional	O
descriptions	O
for	O
neurons	O
.	O
right	O
side	O
,	O
lower	O
part	O
:	O
without	O
indicated	O
ﬁxed-weight	O
layer	B
,	O
with	O
the	O
name	O
of	O
each	O
neuron	O
corresponding	O
to	O
our	O
convention	O
.	O
the	O
ﬁxed-weight	O
layer	B
will	O
no	O
longer	O
be	O
taken	O
into	O
account	O
in	O
the	O
course	O
of	O
this	O
work	O
.	O
72	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
kapitel5dasperceptrondkriesel.com	O
''	O
''	O
)	O
)	O
++	O
,	O
,	O
#	O
#	O
)	O
)	O
++||	O
#	O
#	O
)	O
)	O
{	O
{	O
uu	O
''	O
''	O
{	O
{	O
uuss||uussrrgfed	O
@	O
abc	O
(	O
cid:30	O
)	O
''ooooooooooooooooogfed	O
@	O
abc	O
(	O
cid:30	O
)	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
~~~~~~~~~gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
wwooooooooooooooooowvutpqrsσl|hgfed	O
@	O
abci1	O
(	O
(	O
ppppppppppppppppppgfed	O
@	O
abci2	O
!	O
!	O
ccccccccccgfed	O
@	O
abci3gfed	O
@	O
abci4	O
}	O
}	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
gfed	O
@	O
abci5vvnnnnnnnnnnnnnnnnnn	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
ωabbildung5.1	O
:	O
aufbaueinesperceptronsmiteinerschichtvariablerverbindungeninverschiede-nenansichten.diedurchgezogenegewichtsschichtindenunterenbeidenabbildungenisttrainier-bar.oben	O
:	O
ambeispielderinformationsabtastungimauge.mitte	O
:	O
skizzedesselbenmiteingezeichneterfestergewichtsschichtunterverwendungderdeﬁnier-tenfunktionsbeschreibendendesignsf¨urneurone.unten	O
:	O
ohneeingezeichnetefestegewichtsschicht	O
,	O
mitbenennungdereinzelnenneuronennachunsererkonvention.wirwerdendiefestegewichtschichtimweiterenverlaufderarbeitnichtmehrbetrachten.70d.kriesel–einkleiner¨uberblick¨uberneuronalenetze	O
(	O
epsilon-de	O
)	O
input	B
neuron	I
only	O
forwards	O
data	O
dkriesel.com	O
we	O
will	O
see	O
that	O
this	O
is	O
not	O
possible	O
without	O
connecting	O
them	O
serially	O
.	O
before	O
providing	O
the	O
deﬁnition	O
of	O
the	O
perceptron	B
,	O
i	O
want	O
to	O
deﬁne	O
some	O
types	O
of	O
neurons	O
used	O
in	O
this	O
chapter	O
.	O
deﬁnition	O
5.1	O
(	O
input	B
neuron	I
)	O
.	O
an	O
in-	O
put	O
neuron	O
is	O
an	O
identity	B
neuron	I
.	O
it	O
exactly	O
forwards	O
the	O
information	O
received	O
.	O
thus	O
,	O
it	O
represents	O
the	O
identity	O
function	O
,	O
which	O
should	O
be	O
indicated	O
by	O
the	O
symbol	O
(	O
cid:30	O
)	O
.	O
therefore	O
the	O
input	B
neuron	I
is	O
repre-	O
sented	O
by	O
the	O
symbolgfed	O
@	O
abc	O
(	O
cid:30	O
)	O
.	O
deﬁnition	O
5.2	O
(	O
information	O
process-	O
ing	O
neuron	O
)	O
.	O
information	O
processing	O
neurons	O
somehow	O
process	O
the	O
input	O
infor-	O
mation	O
,	O
i.e	O
.	O
do	O
not	O
represent	O
the	O
identity	O
function	O
.	O
a	O
binary	B
neuron	I
sums	O
up	O
all	O
inputs	O
by	O
using	O
the	O
weighted	B
sum	I
as	O
prop-	O
agation	O
function	B
,	O
which	O
we	O
want	O
to	O
illus-	O
trate	O
by	O
the	O
sign	O
σ.	O
then	O
the	O
activation	B
function	I
of	O
the	O
neuron	O
is	O
the	O
binary	O
thresh-	O
old	O
function	B
,	O
which	O
can	O
be	O
illustrated	O
by	O
l|h	O
.	O
this	O
leads	O
us	O
to	O
the	O
complete	O
de-	O
piction	O
of	O
information	O
processing	O
neurons	O
,	O
l|h	O
.	O
other	O
neurons	O
that	O
use	O
the	O
weighted	B
sum	I
as	O
propagation	B
function	I
but	O
the	O
activation	B
functions	O
hyperbolic	O
tan-	O
gent	O
or	O
fermi	O
function	B
,	O
or	O
with	O
a	O
sepa-	O
rately	O
deﬁned	O
activation	B
function	I
fact	O
,	O
are	O
similarly	O
represented	O
by	O
namely	O
wvut	O
pqrsς	O
these	O
neurons	O
are	O
also	O
referred	O
to	O
as	O
fermi	O
neurons	O
or	O
tanh	B
neuron	O
.	O
wvut	O
pqrsς	O
tanh	B
wvut	O
pqrsς	O
fermi	O
onml	O
hijkς	O
fact	O
.	O
now	O
that	O
we	O
know	O
the	O
components	O
of	O
a	O
perceptron	B
we	O
should	O
be	O
able	O
to	O
deﬁne	O
it	O
.	O
deﬁnition	O
5.3	O
(	O
perceptron	B
)	O
.	O
the	O
per-	O
ceptron	O
(	O
ﬁg	O
.	O
5.1	O
on	O
the	O
facing	O
page	O
)	O
is1	O
a	O
feedforward	B
network	O
containing	O
a	O
retina	B
that	O
is	O
used	O
only	O
for	O
data	O
acquisition	O
and	O
which	O
has	O
ﬁxed-weighted	O
connections	O
with	O
the	O
ﬁrst	O
neuron	O
layer	O
(	O
input	B
layer	I
)	O
.	O
the	O
ﬁxed-weight	O
layer	B
is	O
followed	O
by	O
at	O
least	O
one	O
trainable	O
weight	B
layer	O
.	O
one	O
neuron	O
layer	O
is	O
completely	O
linked	O
with	O
the	O
follow-	O
ing	O
layer	B
.	O
the	O
ﬁrst	O
layer	B
of	O
the	O
percep-	O
tron	O
consists	O
of	O
the	O
input	O
neurons	O
deﬁned	O
above	O
.	O
a	O
feedforward	B
network	O
often	O
contains	O
shortcuts	O
which	O
does	O
not	O
exactly	O
corre-	O
spond	O
to	O
the	O
original	O
description	O
and	O
there-	O
fore	O
is	O
not	O
included	O
in	O
the	O
deﬁnition	O
.	O
we	O
can	O
see	O
that	O
the	O
retina	B
is	O
not	O
included	O
in	O
the	O
lower	O
part	O
of	O
ﬁg	O
.	O
5.1.	O
as	O
a	O
matter	O
of	O
fact	O
the	O
ﬁrst	O
neuron	O
layer	O
is	O
often	O
un-	O
derstood	O
(	O
simpliﬁed	O
and	O
suﬃcient	O
for	O
this	O
method	O
)	O
as	O
input	B
layer	I
,	O
because	O
this	O
layer	B
only	O
forwards	O
the	O
input	O
values	O
.	O
the	O
retina	B
itself	O
and	O
the	O
static	O
weights	O
behind	O
it	O
are	O
no	O
longer	O
mentioned	O
or	O
displayed	O
,	O
since	O
they	O
do	O
not	O
process	O
information	O
in	O
any	O
case	O
.	O
so	O
,	O
the	O
depiction	O
of	O
a	O
perceptron	B
starts	O
with	O
the	O
input	O
neurons	O
.	O
1	O
it	O
may	O
confuse	O
some	O
readers	O
that	O
i	O
claim	O
that	O
there	O
is	O
no	O
deﬁnition	O
of	O
a	O
perceptron	B
but	O
then	O
deﬁne	O
the	O
perceptron	B
in	O
the	O
following	O
section	O
.	O
i	O
therefore	O
suggest	O
keeping	O
my	O
deﬁnition	O
in	O
the	O
back	O
of	O
your	O
mind	O
and	O
just	O
take	O
it	O
for	O
granted	O
in	O
the	O
course	O
of	O
this	O
work	O
.	O
retina	B
is	O
unconsidered	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
73	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
the	O
methods	O
snipe	O
:	O
setsettingstopologyfeedforward	O
and	O
the	O
variation	O
-withshortcuts	O
in	O
neuralnetworkdescriptor-instance	O
a	O
apply	O
settings	O
to	O
a	O
descriptor	O
,	O
which	O
are	O
appropriate	O
for	O
feedforward	B
networks	O
or	O
feedforward	B
networks	O
with	O
shortcuts	O
.	O
the	O
respective	O
kinds	O
of	O
connections	O
are	O
allowed	O
,	O
all	O
others	O
are	O
not	O
,	O
and	O
fastprop	B
is	O
activated	O
.	O
5.1	O
the	O
singlelayer	B
perceptron	I
provides	O
only	O
one	O
trainable	O
weight	B
layer	O
1	O
trainable	O
here	O
,	O
connections	O
with	O
trainable	O
weights	O
go	O
from	O
the	O
input	B
layer	I
to	O
an	O
output	O
neuron	O
ω	O
,	O
which	O
returns	O
the	O
information	O
layer	O
whether	O
the	O
pattern	B
entered	O
at	O
the	O
input	O
neurons	O
was	O
recognized	O
or	O
not	O
.	O
thus	O
,	O
a	O
singlelayer	O
perception	O
(	O
abbreviated	O
slp	O
)	O
has	O
only	O
one	O
level	O
of	O
trainable	O
weights	O
(	O
ﬁg	O
.	O
5.1	O
on	O
page	O
72	O
)	O
.	O
deﬁnition	O
5.4	O
(	O
singlelayer	B
perceptron	I
)	O
.	O
a	O
singlelayer	B
perceptron	I
(	O
slp	O
)	O
is	O
a	O
perceptron	B
having	O
only	O
one	O
layer	B
of	O
vari-	O
able	O
weights	O
and	O
one	O
layer	B
of	O
output	O
neu-	O
rons	O
ω.	O
the	O
technical	O
view	O
of	O
an	O
slp	O
is	O
shown	O
in	O
ﬁg	O
.	O
5.2.	O
important	O
!	O
certainly	O
,	O
the	O
existence	O
of	O
several	O
output	O
neurons	O
ω1	O
,	O
ω2	O
,	O
.	O
.	O
.	O
,	O
ωn	O
does	O
not	O
consider-	O
ably	O
change	O
the	O
concept	O
of	O
the	O
perceptron	B
(	O
ﬁg	O
.	O
5.3	O
)	O
:	O
a	O
perceptron	B
with	O
several	O
out-	O
put	O
neurons	O
can	O
also	O
be	O
regarded	O
as	O
sev-	O
eral	O
diﬀerent	O
perceptrons	O
with	O
the	O
same	O
input	O
.	O
bias	O
gfed	O
@	O
abc	O
wbias	O
,	O
ω	O
gfed	O
@	O
abc	O
i2	O
	O
wi2	O
,	O
ω	O
	O
i1	O
wi1	O
,	O
ω	O
gfed	O
@	O
abc	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
ω	O
figure	O
5.2	O
:	O
a	O
singlelayer	B
perceptron	I
with	O
two	O
in-	O
put	O
neurons	O
and	O
one	O
output	O
neuron	O
.	O
the	O
net-	O
work	O
returns	O
the	O
output	O
by	O
means	O
of	O
the	O
ar-	O
row	O
leaving	O
the	O
network	O
.	O
the	O
trainable	O
layer	B
of	O
weights	O
is	O
situated	O
in	O
the	O
center	O
(	O
labeled	O
)	O
.	O
as	O
a	O
reminder	O
,	O
the	O
bias	B
neuron	I
is	O
again	O
included	O
here	O
.	O
although	O
the	O
weight	B
wbias	O
,	O
ω	O
is	O
a	O
normal	O
weight	B
and	O
also	O
treated	O
like	O
this	O
,	O
i	O
have	O
represented	O
it	O
by	O
a	O
dotted	O
line	O
–	O
which	O
signiﬁcantly	O
increases	O
the	O
clarity	O
of	O
larger	O
networks	O
.	O
in	O
future	O
,	O
the	O
bias	B
neuron	I
will	O
no	O
longer	O
be	O
included	O
.	O
i2	O
i3	O
i1	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
*uuuuuuuuuuuuuuuuuuuuuuuuuu	O
(	O
pppppppppppppppppp	O
'ppppppppppppppppp	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
vnnnnnnnnnnnnnnnnnn	O
wnnnnnnnnnnnnnnnnn	O
aaaaaaaaa	O
aaaaaaaaa	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
~~~~~~~~~~	O
gfed	O
@	O
abcω1	O
gfed	O
gfed	O
@	O
abcω3	O
@	O
abcω2	O
i4	O
i5	O
figure	O
5.3	O
:	O
singlelayer	B
perceptron	I
with	O
several	O
output	O
neurons	O
74	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
	O
	O
	O
	O
*	O
'	O
	O
	O
(	O
~	O
	O
	O
v	O
	O
	O
~	O
~	O
t	O
w	O
	O
	O
	O
	O
	O
	O
dkriesel.com	O
5.1	O
the	O
singlelayer	B
perceptron	I
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
}	O
}	O
}	O
}	O
1	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
1	O
~	O
}	O
}	O
}	O
}	O
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
aaaa	O
1	O
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
aaaa	O
1	O
aaaa	O
gfed	O
@	O
abc1.5	O
aaaa	O
gfed	O
@	O
abc0.5	O
figure	O
5.4	O
:	O
two	O
singlelayer	O
perceptrons	O
for	O
boolean	O
functions	O
.	O
the	O
upper	O
singlelayer	O
per-	O
ceptron	O
realizes	O
an	O
and	O
,	O
the	O
lower	O
one	O
realizes	O
an	O
or	O
.	O
the	O
activation	B
function	I
of	O
the	O
informa-	O
tion	O
processing	O
neuron	O
is	O
the	O
binary	B
threshold	I
function	I
.	O
where	O
available	O
,	O
the	O
threshold	O
values	O
are	O
written	O
into	O
the	O
neurons	O
.	O
the	O
boolean	O
functions	O
and	O
and	O
or	O
shown	O
in	O
ﬁg	O
.	O
5.4	O
are	O
trivial	O
examples	O
that	O
can	O
eas-	O
ily	O
be	O
composed	O
.	O
now	O
we	O
want	O
to	O
know	O
how	O
to	O
train	O
a	O
single-	O
layer	B
perceptron	O
.	O
we	O
will	O
therefore	O
at	O
ﬁrst	O
take	O
a	O
look	O
at	O
the	O
perceptron	O
learning	O
al-	O
gorithm	O
and	O
then	O
we	O
will	O
look	O
at	O
the	O
delta	B
rule	I
.	O
5.1.1	O
perceptron	B
learning	I
algorithm	I
and	O
convergence	O
theorem	O
the	O
original	O
perceptron	O
learning	O
algo-	O
rithm	O
with	O
binary	B
neuron	I
activation	O
func-	O
tion	O
is	O
described	O
in	O
alg	O
.	O
1.	O
it	O
has	O
been	O
proven	O
that	O
the	O
algorithm	B
converges	O
in	O
ﬁnite	O
time	O
–	O
so	O
in	O
ﬁnite	O
time	O
the	O
per-	O
ceptron	O
can	O
learn	O
anything	O
it	O
can	O
repre-	O
sent	O
(	O
perceptron	B
convergence	I
theorem	I
,	O
[	O
ros62	O
]	O
)	O
.	O
but	O
please	O
do	O
not	O
get	O
your	O
hopes	O
up	O
too	O
soon	O
!	O
what	O
the	O
perceptron	B
is	O
capa-	O
ble	O
to	O
represent	O
will	O
be	O
explored	O
later	O
.	O
during	O
the	O
exploration	O
of	O
linear	O
separabil-	O
ity	O
of	O
problems	O
we	O
will	O
cover	O
the	O
fact	O
that	O
at	O
least	O
the	O
singlelayer	B
perceptron	I
unfor-	O
tunately	O
can	O
not	O
represent	O
a	O
lot	O
of	O
prob-	O
lems	O
.	O
5.1.2	O
the	O
delta	B
rule	I
as	O
a	O
gradient	B
based	O
learning	B
strategy	I
for	O
slps	O
in	O
the	O
following	O
we	O
deviate	O
from	O
our	O
bi-	O
nary	O
threshold	B
value	I
as	O
activation	B
function	I
because	O
at	O
least	O
for	O
backpropagation	O
of	O
er-	O
ror	O
we	O
need	O
,	O
as	O
you	O
will	O
see	O
,	O
a	O
diﬀeren-	O
tiable	O
or	O
even	O
a	O
semi-linear	O
activation	B
func-	O
tion	O
.	O
for	O
the	O
now	O
following	O
delta	B
rule	I
(	O
like	O
backpropagation	B
derived	O
in	O
[	O
mr86	O
]	O
)	O
it	O
is	O
not	O
always	O
necessary	O
but	O
useful	O
.	O
this	O
fact	O
,	O
however	O
,	O
will	O
also	O
be	O
pointed	O
out	O
in	O
the	O
appropriate	O
part	O
of	O
this	O
work	O
.	O
compared	O
with	O
the	O
aforementioned	O
perceptron	B
learn-	O
ing	O
algorithm	B
,	O
the	O
delta	B
rule	I
has	O
the	O
ad-	O
vantage	O
to	O
be	O
suitable	O
for	O
non-binary	O
acti-	O
vation	O
functions	O
and	O
,	O
being	O
far	O
away	O
from	O
fact	O
now	O
diﬀer-	O
entiable	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
75	O
~	O
	O
	O
~	O
	O
	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
if	O
yω	O
=	O
tω	O
then	O
else	O
output	O
is	O
okay	O
,	O
no	O
correction	O
of	O
weights	O
end	O
for	O
end	O
if	O
if	O
yω	O
=	O
0	O
then	O
for	O
all	O
input	O
neurons	O
i	O
do	O
wi	O
,	O
ω	O
:	O
=	O
wi	O
,	O
ω	O
+	O
oi	O
{	O
...	O
increase	O
weight	B
towards	O
ω	O
by	O
oi	O
}	O
input	O
p	O
into	O
the	O
network	O
,	O
calculate	O
output	O
y	O
{	O
p	O
set	O
of	O
training	O
patterns	O
}	O
for	O
all	O
output	O
neurons	O
ω	O
do	O
1	O
:	O
while	O
∃p	O
∈	O
p	O
and	O
error	O
too	O
large	O
do	O
2	O
:	O
3	O
:	O
4	O
:	O
5	O
:	O
6	O
:	O
7	O
:	O
8	O
:	O
9	O
:	O
10	O
:	O
11	O
:	O
12	O
:	O
13	O
:	O
14	O
:	O
15	O
:	O
16	O
:	O
end	O
if	O
17	O
:	O
end	O
for	O
18	O
:	O
19	O
:	O
end	O
while	O
algorithm	B
1	O
:	O
perceptron	B
learning	I
algorithm	I
.	O
the	O
perceptron	B
learning	I
algorithm	I
reduces	O
the	O
weights	O
to	O
output	O
neurons	O
that	O
return	B
1	O
instead	O
of	O
0	O
,	O
and	O
in	O
the	O
inverse	O
case	O
increases	O
weights	O
.	O
wi	O
,	O
ω	O
:	O
=	O
wi	O
,	O
ω	O
−	O
oi	O
{	O
...	O
decrease	O
weight	B
towards	O
ω	O
by	O
oi	O
}	O
end	O
for	O
end	O
if	O
if	O
yω	O
=	O
1	O
then	O
for	O
all	O
input	O
neurons	O
i	O
do	O
76	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
5.1	O
the	O
singlelayer	B
perceptron	I
the	O
learning	B
target	O
,	O
to	O
automatically	O
learn	O
faster	O
.	O
suppose	O
that	O
we	O
have	O
a	O
singlelayer	O
percep-	O
tron	O
with	O
randomly	O
set	O
weights	O
which	O
we	O
want	O
to	O
teach	O
a	O
function	B
by	O
means	O
of	O
train-	O
ing	O
samples	O
.	O
the	O
set	O
of	O
these	O
training	O
sam-	O
ples	O
is	O
called	O
p.	O
it	O
contains	O
,	O
as	O
already	O
de-	O
ﬁned	O
,	O
the	O
pairs	O
(	O
p	O
,	O
t	O
)	O
of	O
the	O
training	O
sam-	O
ples	O
p	O
and	O
the	O
associated	O
teaching	B
input	I
t.	O
i	O
also	O
want	O
to	O
remind	O
you	O
that	O
.	O
x	O
is	O
the	O
input	B
vector	I
and	O
.	O
y	O
is	O
the	O
output	B
vector	I
of	O
a	O
neural	O
net-	O
work	O
,	O
.	O
output	O
neurons	O
are	O
referred	O
to	O
as	O
ω1	O
,	O
ω2	O
,	O
.	O
.	O
.	O
,	O
ω|o|	O
,	O
.	O
i	O
is	O
the	O
input	O
and	O
.	O
o	O
is	O
the	O
output	O
of	O
a	O
neuron	O
.	O
additionally	O
,	O
we	O
deﬁned	O
that	O
.	O
the	O
error	B
vector	I
ep	O
represents	O
the	O
dif-	O
ference	O
(	O
t−y	O
)	O
under	O
a	O
certain	O
training	O
sample	O
p.	O
.	O
furthermore	O
,	O
let	O
o	O
be	O
the	O
set	O
of	O
out-	O
put	O
neurons	O
and	O
.	O
i	O
be	O
the	O
set	O
of	O
input	O
neurons	O
.	O
another	O
naming	O
convention	O
shall	O
be	O
that	O
,	O
for	O
example	O
,	O
for	O
an	O
output	O
o	O
and	O
a	O
teach-	O
ing	O
input	O
t	O
an	O
additional	O
index	O
p	O
may	O
be	O
set	O
in	O
order	O
to	O
indicate	O
that	O
these	O
values	O
are	O
pattern-speciﬁc	O
.	O
sometimes	O
this	O
will	O
considerably	O
enhance	O
clarity	O
.	O
now	O
our	O
learning	B
target	O
will	O
certainly	O
be	O
,	O
that	O
for	O
all	O
training	O
samples	O
the	O
output	O
y	O
of	O
the	O
network	O
is	O
approximately	O
the	O
de-	O
sired	O
output	O
t	O
,	O
formally	O
it	O
is	O
true	O
that	O
i.e	O
.	O
∀p	O
:	O
y	O
≈	O
t	O
or	O
∀p	O
:	O
ep	O
≈	O
0.	O
this	O
means	O
we	O
ﬁrst	O
have	O
to	O
understand	O
the	O
total	B
error	I
err	O
as	O
a	O
function	B
of	O
the	O
weights	O
:	O
the	O
total	B
error	I
increases	O
or	O
decreases	O
de-	O
pending	O
on	O
how	O
we	O
change	O
the	O
weights	O
.	O
deﬁnition	O
5.5	O
(	O
error	B
function	I
)	O
.	O
the	O
er-	O
ror	O
function	B
err	O
:	O
w	O
→	O
r	O
(	O
cid:74	O
)	O
err	O
(	O
w	O
)	O
regards	O
the	O
set2	O
of	O
weights	O
w	O
as	O
a	O
vector	O
and	O
maps	O
the	O
values	O
onto	O
the	O
normalized	O
output	O
error	O
(	O
normalized	O
because	O
other-	O
wise	O
not	O
all	O
errors	O
can	O
be	O
mapped	O
onto	O
one	O
single	O
e	O
∈	O
r	O
to	O
perform	O
a	O
gradient	B
de-	O
scent	O
)	O
.	O
it	O
is	O
obvious	O
that	O
a	O
speciﬁc	O
error	B
function	I
can	O
analogously	O
be	O
generated	O
(	O
cid:74	O
)	O
errp	O
(	O
w	O
)	O
for	O
a	O
single	O
pattern	O
p.	O
error	O
as	O
function	B
as	O
already	O
shown	O
in	O
section	O
4.5	O
,	O
gradient	B
descent	I
procedures	O
calculate	O
the	O
gradient	B
of	O
an	O
arbitrary	O
but	O
ﬁnite-dimensional	O
func-	O
tion	O
(	O
here	O
:	O
of	O
the	O
error	B
function	I
err	O
(	O
w	O
)	O
)	O
and	O
move	O
down	O
against	O
the	O
direction	O
of	O
the	O
gradient	B
until	O
a	O
minimum	O
is	O
reached	O
.	O
err	O
(	O
w	O
)	O
is	O
deﬁned	O
on	O
the	O
set	O
of	O
all	O
weights	O
which	O
we	O
here	O
regard	O
as	O
the	O
vector	O
w.	O
so	O
we	O
try	O
to	O
decrease	O
or	O
to	O
minimize	O
the	O
error	O
by	O
simply	O
tweaking	O
the	O
weights	O
–	O
thus	O
one	O
receives	O
information	O
about	O
how	O
to	O
change	O
the	O
weights	O
(	O
the	O
change	O
in	O
all	O
2	O
following	O
the	O
tradition	O
of	O
the	O
literature	O
,	O
i	O
previ-	O
ously	O
deﬁned	O
w	O
as	O
a	O
weight	B
matrix	I
.	O
i	O
am	O
aware	O
of	O
this	O
conﬂict	O
but	O
it	O
should	O
not	O
bother	O
us	O
here	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
77	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
thus	O
,	O
we	O
tweak	O
every	O
single	O
weight	O
and	O
ob-	O
serve	O
how	O
the	O
error	B
function	I
changes	O
,	O
i.e	O
.	O
we	O
derive	O
the	O
error	B
function	I
according	O
to	O
a	O
weight	B
wi	O
,	O
ω	O
and	O
obtain	O
the	O
value	O
∆wi	O
,	O
ω	O
of	O
how	O
to	O
change	O
this	O
weight	B
.	O
∆wi	O
,	O
ω	O
=	O
−η	O
∂err	O
(	O
w	O
)	O
∂wi	O
,	O
ω	O
.	O
(	O
5.3	O
)	O
now	O
the	O
following	O
question	O
arises	O
:	O
how	O
is	O
our	O
error	B
function	I
deﬁned	O
exactly	O
?	O
it	O
is	O
not	O
good	O
if	O
many	O
results	O
are	O
far	O
away	O
from	O
the	O
desired	O
ones	O
;	O
the	O
error	B
function	I
should	O
then	O
provide	O
large	O
values	O
–	O
on	O
the	O
other	O
hand	O
,	O
it	O
is	O
similarly	O
bad	O
if	O
many	O
results	O
are	O
close	O
to	O
the	O
desired	O
ones	O
but	O
there	O
exists	O
an	O
extremely	O
far	O
outlying	O
re-	O
sult	O
.	O
the	O
squared	B
distance	I
between	O
the	O
output	B
vector	I
y	O
and	O
the	O
teaching	B
input	I
t	O
appears	O
adequate	O
to	O
our	O
needs	O
.	O
it	O
provides	O
the	O
error	O
errp	O
that	O
is	O
speciﬁc	O
for	O
a	O
train-	O
ing	O
sample	O
p	O
over	O
the	O
output	O
of	O
all	O
output	O
neurons	O
ω	O
:	O
errp	O
(	O
w	O
)	O
=	O
1	O
2	O
x	O
ω∈o	O
(	O
tp	O
,	O
ω	O
−	O
yp	O
,	O
ω	O
)	O
2	O
.	O
(	O
5.4	O
)	O
figure	O
5.5	O
:	O
exemplary	O
error	O
surface	O
of	O
a	O
neural	O
network	O
with	O
two	O
trainable	O
connections	O
w1	O
und	O
w2	O
.	O
generally	O
,	O
neural	O
networks	O
have	O
more	O
than	O
two	O
connections	O
,	O
but	O
this	O
would	O
have	O
made	O
the	O
illustration	O
too	O
complex	O
.	O
and	O
most	O
of	O
the	O
time	O
the	O
error	O
surface	O
is	O
too	O
craggy	O
,	O
which	O
complicates	O
the	O
search	O
for	O
the	O
minimum	O
.	O
weights	O
is	O
referred	O
to	O
as	O
∆w	O
)	O
by	O
calcu-	O
lating	O
the	O
gradient	B
∇err	O
(	O
w	O
)	O
of	O
the	O
error	B
function	I
err	O
(	O
w	O
)	O
:	O
∆w	O
∼	O
−∇err	O
(	O
w	O
)	O
.	O
(	O
5.1	O
)	O
due	O
to	O
this	O
relation	O
there	O
is	O
a	O
proportional-	O
ity	O
constant	O
η	O
for	O
which	O
equality	O
holds	O
(	O
η	O
will	O
soon	O
get	O
another	O
meaning	O
and	O
a	O
real	O
practical	O
use	O
beyond	O
the	O
mere	O
meaning	O
of	O
a	O
proportionality	O
constant	O
.	O
i	O
just	O
ask	O
the	O
reader	O
to	O
be	O
patient	O
for	O
a	O
while	O
.	O
)	O
:	O
∆w	O
=	O
−η∇err	O
(	O
w	O
)	O
.	O
(	O
5.2	O
)	O
to	O
simplify	O
further	O
analysis	O
,	O
we	O
now	O
rewrite	O
the	O
gradient	B
of	O
the	O
error-function	O
according	O
to	O
all	O
weights	O
as	O
an	O
usual	O
par-	O
tial	O
derivative	O
according	O
to	O
a	O
single	O
weight	O
wi	O
,	O
ω	O
(	O
the	O
only	O
variable	O
weights	O
exists	O
be-	O
tween	O
the	O
hidden	O
and	O
the	O
output	B
layer	I
ω	O
)	O
.	O
thus	O
,	O
we	O
calculate	O
the	O
squared	O
diﬀerence	O
of	O
the	O
components	O
of	O
the	O
vectors	O
t	O
and	O
y	O
,	O
given	O
the	O
pattern	B
p	O
,	O
and	O
sum	O
up	O
these	O
squares	O
.	O
the	O
summation	O
of	O
the	O
speciﬁc	O
er-	O
rors	O
errp	O
(	O
w	O
)	O
of	O
all	O
patterns	O
p	O
then	O
yields	O
the	O
deﬁnition	O
of	O
the	O
error	O
err	O
and	O
there-	O
78	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
−2−1	O
0	O
1	O
2w1−2−1	O
0	O
1	O
2w2	O
0	O
1	O
2	O
3	O
4	O
5	O
dkriesel.com	O
5.1	O
the	O
singlelayer	B
perceptron	I
fore	O
the	O
deﬁnition	O
of	O
the	O
error	B
function	I
err	O
(	O
w	O
)	O
:	O
results	O
from	O
the	O
sum	O
of	O
the	O
speciﬁc	O
er-	O
rors	O
)	O
:	O
errp	O
(	O
w	O
)	O
(	O
5.5	O
)	O
sum	O
over	O
all	O
p	O
x	O
|	O
ω∈o	O
}	O
|	O
(	O
tp	O
,	O
ω	O
−	O
yp	O
,	O
ω	O
)	O
2	O
{	O
z	O
sum	O
over	O
all	O
ω	O
{	O
	O
}	O
.	O
(	O
5.6	O
)	O
err	O
(	O
w	O
)	O
=	O
x	O
z	O
x	O
p∈p	O
=	O
1	O
2	O
p∈p	O
the	O
observant	O
reader	O
will	O
certainly	O
wonder	O
where	O
the	O
factor	O
1	O
2	O
in	O
equation	O
5.4	O
on	O
the	O
preceding	O
page	O
suddenly	O
came	O
from	O
and	O
why	O
there	O
is	O
no	O
root	O
in	O
the	O
equation	O
,	O
as	O
this	O
formula	O
looks	O
very	O
similar	O
to	O
the	O
eu-	O
clidean	O
distance	O
.	O
both	O
facts	O
result	O
from	O
simple	O
pragmatics	O
:	O
our	O
intention	O
is	O
to	O
minimize	O
the	O
error	O
.	O
because	O
the	O
root	O
func-	O
tion	O
decreases	O
with	O
its	O
argument	O
,	O
we	O
can	O
simply	O
omit	O
it	O
for	O
reasons	O
of	O
calculation	O
and	O
implementation	O
eﬀorts	O
,	O
since	O
we	O
do	O
not	O
need	O
it	O
for	O
minimization	O
.	O
similarly	O
,	O
it	O
does	O
not	O
matter	O
if	O
the	O
term	O
to	O
be	O
mini-	O
mized	O
is	O
divided	O
by	O
2	O
:	O
therefore	O
i	O
am	O
al-	O
lowed	O
to	O
multiply	O
by	O
1	O
2.	O
this	O
is	O
just	O
done	O
so	O
that	O
it	O
cancels	O
with	O
a	O
2	O
in	O
the	O
course	O
of	O
our	O
calculation	O
.	O
now	O
we	O
want	O
to	O
continue	O
deriving	O
the	O
delta	B
rule	I
for	O
linear	O
activation	O
functions	O
.	O
we	O
have	O
already	O
discussed	O
that	O
we	O
tweak	O
the	O
individual	O
weights	O
wi	O
,	O
ω	O
a	O
bit	O
and	O
see	O
how	O
the	O
error	O
err	O
(	O
w	O
)	O
is	O
changing	O
–	O
which	O
corresponds	O
to	O
the	O
derivative	O
of	O
the	O
er-	O
ror	O
function	B
err	O
(	O
w	O
)	O
according	O
to	O
the	O
very	O
same	O
weight	B
wi	O
,	O
ω	O
.	O
this	O
derivative	O
cor-	O
responds	O
to	O
the	O
sum	O
of	O
the	O
derivatives	O
of	O
all	O
speciﬁc	O
errors	O
errp	O
according	O
to	O
this	O
weight	B
(	O
since	O
the	O
total	B
error	I
err	O
(	O
w	O
)	O
∆wi	O
,	O
ω	O
=	O
−η	O
=	O
x	O
p∈p	O
∂err	O
(	O
w	O
)	O
∂wi	O
,	O
ω	O
−η	O
∂errp	O
(	O
w	O
)	O
∂wi	O
,	O
ω	O
(	O
5.7	O
)	O
(	O
5.8	O
)	O
.	O
once	O
again	O
i	O
want	O
to	O
think	O
about	O
the	O
ques-	O
tion	O
of	O
how	O
a	O
neural	O
network	O
processes	O
data	O
.	O
basically	O
,	O
the	O
data	O
is	O
only	O
trans-	O
ferred	O
through	O
a	O
function	B
,	O
the	O
result	O
of	O
the	O
function	B
is	O
sent	O
through	O
another	O
one	O
,	O
and	O
so	O
on	O
.	O
if	O
we	O
ignore	O
the	O
output	B
function	I
,	O
the	O
path	O
of	O
the	O
neuron	O
outputs	O
oi1	O
and	O
oi2	O
,	O
which	O
the	O
neurons	O
i1	O
and	O
i2	O
entered	O
into	O
a	O
neuron	O
ω	O
,	O
initially	O
is	O
the	O
propagation	O
func-	O
tion	O
(	O
here	O
weighted	B
sum	I
)	O
,	O
from	O
which	O
the	O
network	B
input	I
is	O
going	O
to	O
be	O
received	O
.	O
this	O
is	O
then	O
sent	O
through	O
the	O
activation	B
func-	O
tion	O
of	O
the	O
neuron	O
ω	O
so	O
that	O
we	O
receive	O
the	O
output	O
of	O
this	O
neuron	O
which	O
is	O
at	O
the	O
same	O
time	O
a	O
component	O
of	O
the	O
output	O
vec-	O
tor	O
y	O
:	O
netω	O
→	O
fact	O
=	O
fact	O
(	O
netω	O
)	O
=	O
oω	O
=	O
yω	O
.	O
as	O
we	O
can	O
see	O
,	O
this	O
output	O
results	O
from	O
many	O
nested	O
functions	O
:	O
oω	O
=	O
fact	O
(	O
netω	O
)	O
=	O
fact	O
(	O
oi1	O
·	O
wi1	O
,	O
ω	O
+	O
oi2	O
·	O
wi2	O
,	O
ω	O
)	O
.	O
(	O
5.9	O
)	O
(	O
5.10	O
)	O
it	O
is	O
clear	O
that	O
we	O
could	O
break	O
down	O
the	O
output	O
into	O
the	O
single	O
input	O
neurons	O
(	O
this	O
is	O
unnecessary	O
here	O
,	O
since	O
they	O
do	O
not	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
79	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
process	O
information	O
in	O
an	O
slp	O
)	O
.	O
thus	O
,	O
we	O
want	O
to	O
calculate	O
the	O
derivatives	O
of	O
equation	O
5.8	O
on	O
the	O
preceding	O
page	O
and	O
due	O
to	O
the	O
nested	O
functions	O
we	O
can	O
apply	O
the	O
chain	O
rule	O
to	O
factorize	O
the	O
derivative	O
∂errp	O
(	O
w	O
)	O
in	O
equation	O
5.8	O
on	O
the	O
previous	O
∂wi	O
,	O
ω	O
page	O
.	O
∂errp	O
(	O
w	O
)	O
∂wi	O
,	O
ω	O
=	O
∂errp	O
(	O
w	O
)	O
∂op	O
,	O
ω	O
·	O
∂op	O
,	O
ω	O
∂wi	O
,	O
ω	O
.	O
(	O
5.11	O
)	O
i.e	O
.	O
let	O
us	O
take	O
a	O
look	O
at	O
the	O
ﬁrst	O
multiplica-	O
tive	O
factor	O
of	O
the	O
above	O
equation	O
5.11	O
which	O
represents	O
the	O
derivative	O
of	O
the	O
spe-	O
ciﬁc	O
error	O
errp	O
(	O
w	O
)	O
according	O
to	O
the	O
out-	O
put	O
,	O
the	O
change	O
of	O
the	O
error	O
errp	O
with	O
an	O
output	O
op	O
,	O
ω	O
:	O
the	O
examination	O
of	O
errp	O
(	O
equation	O
5.4	O
on	O
page	O
78	O
)	O
clearly	O
shows	O
that	O
this	O
change	O
is	O
exactly	O
the	O
dif-	O
ference	O
between	O
teaching	B
input	I
and	O
out-	O
put	O
(	O
tp	O
,	O
ω	O
−	O
op	O
,	O
ω	O
)	O
(	O
remember	O
:	O
since	O
ω	O
is	O
an	O
output	O
neuron	O
,	O
op	O
,	O
ω	O
=	O
yp	O
,	O
ω	O
)	O
.	O
the	O
closer	O
the	O
output	O
is	O
to	O
the	O
teaching	B
input	I
,	O
the	O
smaller	O
is	O
the	O
speciﬁc	O
error	O
.	O
thus	O
we	O
can	O
replace	O
one	O
by	O
the	O
other	O
.	O
this	O
diﬀerence	O
is	O
also	O
called	O
δp	O
,	O
ω	O
(	O
which	O
is	O
the	O
reason	O
for	O
the	O
name	O
delta	B
rule	I
)	O
:	O
∂errp	O
(	O
w	O
)	O
∂wi	O
,	O
ω	O
=	O
−	O
(	O
tp	O
,	O
ω	O
−	O
op	O
,	O
ω	O
)	O
·	O
∂op	O
,	O
ω	O
∂wi	O
,	O
ω	O
(	O
5.12	O
)	O
=	O
−δp	O
,	O
ω	O
·	O
∂op	O
,	O
ω	O
∂wi	O
,	O
ω	O
(	O
5.13	O
)	O
the	O
second	O
multiplicative	O
factor	O
of	O
equa-	O
tion	O
5.11	O
and	O
of	O
the	O
following	O
one	O
is	O
the	O
derivative	O
of	O
the	O
output	O
speciﬁc	O
to	O
the	O
pat-	O
tern	O
p	O
of	O
the	O
neuron	O
ω	O
according	O
to	O
the	O
weight	B
wi	O
,	O
ω	O
.	O
so	O
how	O
does	O
op	O
,	O
ω	O
change	O
when	O
the	O
weight	B
from	O
i	O
to	O
ω	O
is	O
changed	O
?	O
∂errp	O
(	O
w	O
)	O
∂wi	O
,	O
ω	O
i∈i	O
(	O
op	O
,	O
iwi	O
,	O
ω	O
)	O
∂wi	O
,	O
ω	O
.	O
due	O
to	O
the	O
requirement	O
at	O
the	O
beginning	O
of	O
the	O
derivation	O
,	O
we	O
only	O
have	O
a	O
linear	O
acti-	O
vation	O
function	B
fact	O
,	O
therefore	O
we	O
can	O
just	O
as	O
well	O
look	O
at	O
the	O
change	O
of	O
the	O
network	B
input	I
when	O
wi	O
,	O
ω	O
is	O
changing	O
:	O
=	O
−δp	O
,	O
ω	O
·	O
∂p	O
the	O
resulting	O
derivative	O
∂p	O
p	O
∂p	O
i∈i	O
(	O
op	O
,	O
iwi	O
,	O
ω	O
)	O
∂wi	O
,	O
ω	O
can	O
now	O
be	O
simpliﬁed	O
:	O
the	O
function	B
i∈i	O
(	O
op	O
,	O
iwi	O
,	O
ω	O
)	O
to	O
be	O
derived	O
consists	O
of	O
many	O
summands	O
,	O
and	O
only	O
the	O
sum-	O
mand	O
op	O
,	O
iwi	O
,	O
ω	O
contains	O
the	O
variable	O
wi	O
,	O
ω	O
,	O
according	O
to	O
which	O
we	O
derive	O
.	O
thus	O
,	O
(	O
5.14	O
)	O
i∈i	O
(	O
op	O
,	O
iwi	O
,	O
ω	O
)	O
∂wi	O
,	O
ω	O
=	O
op	O
,	O
i	O
and	O
therefore	O
:	O
∂errp	O
(	O
w	O
)	O
∂wi	O
,	O
ω	O
=	O
−δp	O
,	O
ω	O
·	O
op	O
,	O
i	O
=	O
−op	O
,	O
i	O
·	O
δp	O
,	O
ω	O
.	O
(	O
5.15	O
)	O
(	O
5.16	O
)	O
we	O
insert	O
this	O
in	O
equation	O
5.8	O
on	O
the	O
previ-	O
ous	O
page	O
,	O
which	O
results	O
in	O
our	O
modiﬁcation	O
rule	O
for	O
a	O
weight	B
wi	O
,	O
ω	O
:	O
op	O
,	O
i	O
·	O
δp	O
,	O
ω	O
.	O
(	O
5.17	O
)	O
∆wi	O
,	O
ω	O
=	O
η	O
·x	O
p∈p	O
however	O
:	O
from	O
the	O
very	O
beginning	O
the	O
derivation	O
has	O
been	O
intended	O
as	O
an	O
oﬄine	O
rule	O
by	O
means	O
of	O
the	O
question	O
of	O
how	O
to	O
add	O
the	O
errors	O
of	O
all	O
patterns	O
and	O
how	O
to	O
learn	O
them	O
after	O
all	O
patterns	O
have	O
been	O
represented	O
.	O
although	O
this	O
approach	O
is	O
mathematically	O
correct	O
,	O
the	O
implementa-	O
tion	O
is	O
far	O
more	O
time-consuming	O
and	O
,	O
as	O
we	O
will	O
see	O
later	O
in	O
this	O
chapter	O
,	O
partially	O
80	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
5.2	O
linear	B
separability	I
needs	O
a	O
lot	O
of	O
compuational	O
eﬀort	O
during	O
training	O
.	O
the	O
``	O
online-learning	O
version	O
''	O
of	O
the	O
delta	B
rule	I
simply	O
omits	O
the	O
summation	O
and	O
learning	B
is	O
realized	O
immediately	O
after	O
the	O
presentation	O
of	O
each	O
pattern	B
,	O
this	O
also	O
sim-	O
pliﬁes	O
the	O
notation	O
(	O
which	O
is	O
no	O
longer	O
nec-	O
essarily	O
related	O
to	O
a	O
pattern	B
p	O
)	O
:	O
∆wi	O
,	O
ω	O
=	O
η	O
·	O
oi	O
·	O
δω	O
.	O
(	O
5.18	O
)	O
this	O
version	O
of	O
the	O
delta	B
rule	I
shall	O
be	O
used	O
for	O
the	O
following	O
deﬁnition	O
:	O
deﬁnition	O
5.6	O
(	O
delta	B
rule	I
)	O
.	O
if	O
we	O
deter-	O
mine	O
,	O
analogously	O
to	O
the	O
aforementioned	O
derivation	O
,	O
that	O
the	O
function	B
h	O
of	O
the	O
heb-	O
bian	O
theory	O
(	O
equation	O
4.6	O
on	O
page	O
67	O
)	O
only	O
provides	O
the	O
output	O
oi	O
of	O
the	O
predecessor	O
neuron	O
i	O
and	O
if	O
the	O
function	B
g	O
is	O
the	O
diﬀer-	O
ence	O
between	O
the	O
desired	O
activation	B
tω	O
and	O
the	O
actual	O
activation	B
aω	O
,	O
we	O
will	O
receive	O
the	O
delta	B
rule	I
,	O
also	O
known	O
as	O
widrow-	O
hoﬀ	O
rule	O
:	O
∆wi	O
,	O
ω	O
=	O
η	O
·	O
oi	O
·	O
(	O
tω	O
−	O
aω	O
)	O
=	O
ηoiδω	O
(	O
5.19	O
)	O
if	O
we	O
use	O
the	O
desired	O
output	O
(	O
instead	O
of	O
the	O
activation	B
)	O
as	O
teaching	B
input	I
,	O
and	O
there-	O
fore	O
the	O
output	B
function	I
of	O
the	O
output	O
neu-	O
rons	O
does	O
not	O
represent	O
an	O
identity	O
,	O
we	O
ob-	O
tain	O
∆wi	O
,	O
ω	O
=	O
η	O
·	O
oi	O
·	O
(	O
tω	O
−	O
oω	O
)	O
=	O
ηoiδω	O
(	O
5.20	O
)	O
and	O
δω	O
then	O
corresponds	O
to	O
the	O
diﬀerence	O
between	O
tω	O
and	O
oω	O
.	O
in	O
the	O
case	O
of	O
the	O
delta	B
rule	I
,	O
the	O
change	O
of	O
all	O
weights	O
to	O
an	O
output	O
neuron	O
ω	O
is	O
proportional	O
in	O
.	O
1	O
0	O
0	O
1	O
1	O
in	O
.	O
2	O
0	O
1	O
0	O
1	O
output	O
0	O
1	O
1	O
0	O
table	O
5.1	O
:	O
deﬁnition	O
of	O
the	O
logical	O
xor	O
.	O
the	O
input	O
values	O
are	O
shown	O
of	O
the	O
left	O
,	O
the	O
output	O
values	O
on	O
the	O
right	O
.	O
.	O
to	O
the	O
diﬀerence	O
between	O
the	O
current	O
activation	B
or	O
output	O
aω	O
or	O
oω	O
and	O
the	O
corresponding	O
teaching	B
input	I
tω	O
.	O
we	O
want	O
to	O
refer	O
to	O
this	O
factor	O
as	O
δω	O
,	O
(	O
cid:74	O
)	O
δ	O
which	O
is	O
also	O
referred	O
to	O
as	O
``	O
delta	O
''	O
.	O
apparently	O
the	O
delta	B
rule	I
only	O
applies	O
for	O
slps	O
,	O
since	O
the	O
formula	O
is	O
always	O
related	O
to	O
the	O
teaching	B
input	I
,	O
and	O
there	O
is	O
no	O
teaching	B
input	I
for	O
the	O
inner	O
processing	O
lay-	O
ers	O
of	O
neurons	O
.	O
delta	B
rule	I
only	O
for	O
slp	O
5.2	O
a	O
slp	O
is	O
only	O
capable	O
of	O
representing	O
linearly	O
separable	O
data	O
let	O
f	O
be	O
the	O
xor	O
function	B
which	O
expects	O
two	O
binary	O
inputs	O
and	O
generates	O
a	O
binary	O
output	O
(	O
for	O
the	O
precise	O
deﬁnition	O
see	O
ta-	O
ble	O
5.1	O
)	O
.	O
let	O
us	O
try	O
to	O
represent	O
the	O
xor	O
func-	O
tion	O
by	O
means	O
of	O
an	O
slp	O
with	O
two	O
input	O
neurons	O
i1	O
,	O
i2	O
and	O
one	O
output	O
neuron	O
ω	O
(	O
ﬁg	O
.	O
5.6	O
on	O
the	O
following	O
page	O
)	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
81	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
gfed	O
@	O
abc	O
i1	O
gfed	O
@	O
abc	O
i2	O
bbbb	O
wi1	O
,	O
ω	O
bbbb	O
||||	O
wi2	O
,	O
ω	O
~||||	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
ω	O
xor	O
?	O
figure	O
5.6	O
:	O
sketch	O
of	O
a	O
singlelayer	B
perceptron	I
that	O
shall	O
represent	O
the	O
xor	O
function	B
-	O
which	O
is	O
impossible	O
.	O
here	O
we	O
use	O
the	O
weighted	B
sum	I
as	O
propaga-	O
tion	O
function	B
,	O
a	O
binary	O
activation	O
function	B
with	O
the	O
threshold	B
value	I
θ	O
and	O
the	O
iden-	O
tity	O
as	O
output	B
function	I
.	O
depending	O
on	O
i1	O
and	O
i2	O
,	O
ω	O
has	O
to	O
output	O
the	O
value	O
1	O
if	O
the	O
following	O
holds	O
:	O
netω	O
=	O
oi1wi1	O
,	O
ω	O
+	O
oi2wi2	O
,	O
ω	O
≥	O
θω	O
(	O
5.21	O
)	O
we	O
assume	O
a	O
positive	O
weight	B
wi2	O
,	O
ω	O
,	O
the	O
in-	O
equality	O
5.21	O
is	O
then	O
equivalent	O
to	O
oi1	O
≥	O
1	O
wi1	O
,	O
ω	O
(	O
θω	O
−	O
oi2wi2	O
,	O
ω	O
)	O
(	O
5.22	O
)	O
with	O
a	O
constant	O
threshold	B
value	I
θω	O
,	O
the	O
right	O
part	O
of	O
inequation	O
5.22	O
is	O
a	O
straight	O
line	O
through	O
a	O
coordinate	O
system	O
deﬁned	O
by	O
the	O
possible	O
outputs	O
oi1	O
und	O
oi2	O
of	O
the	O
input	O
neurons	O
i1	O
and	O
i2	O
(	O
ﬁg	O
.	O
5.7	O
)	O
.	O
for	O
a	O
(	O
as	O
required	O
for	O
inequation	O
5.22	O
)	O
pos-	O
itive	O
wi2	O
,	O
ω	O
the	O
output	O
neuron	O
ω	O
ﬁres	O
for	O
figure	O
5.7	O
:	O
linear	O
separation	O
of	O
n	O
=	O
2	O
inputs	O
of	O
the	O
input	O
neurons	O
i1	O
and	O
i2	O
by	O
a	O
1-dimensional	O
straight	O
line	O
.	O
a	O
and	O
b	O
show	O
the	O
corners	O
belong-	O
ing	O
to	O
the	O
sets	O
of	O
the	O
xor	O
function	B
that	O
are	O
to	O
be	O
separated	O
.	O
82	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
	O
	O
	O
~	O
	O
	O
dkriesel.com	O
5.2	O
linear	B
separability	I
n	O
number	O
of	O
share	O
lin	O
.	O
separable	O
ones	O
4	O
14	O
104	O
1	O
,	O
772	O
94	O
,	O
572	O
5	O
,	O
028	O
,	O
134	O
binary	O
functions	O
4	O
16	O
256	O
65	O
,	O
536	O
4.3	O
·	O
109	O
1.8	O
·	O
1019	O
1	O
2	O
3	O
4	O
5	O
6	O
100	O
%	O
87.5	O
%	O
40.6	O
%	O
2.7	O
%	O
0.002	O
%	O
≈	O
0	O
%	O
table	O
5.2	O
:	O
number	O
of	O
functions	O
concerning	O
n	O
bi-	O
nary	O
inputs	O
,	O
and	O
number	O
and	O
proportion	O
of	O
the	O
functions	O
thereof	O
which	O
can	O
be	O
linearly	O
separated	O
.	O
in	O
accordance	O
with	O
[	O
zel94	O
,	O
wid89	O
,	O
was89	O
]	O
.	O
input	O
combinations	O
lying	O
above	O
the	O
gener-	O
ated	O
straight	O
line	O
.	O
for	O
a	O
negative	O
wi2	O
,	O
ω	O
it	O
would	O
ﬁre	O
for	O
all	O
input	O
combinations	O
lying	O
below	O
the	O
straight	O
line	O
.	O
note	O
that	O
only	O
the	O
four	O
corners	O
of	O
the	O
unit	O
square	O
are	O
possi-	O
ble	O
inputs	O
because	O
the	O
xor	O
function	B
only	O
knows	O
binary	O
inputs	O
.	O
in	O
order	O
to	O
solve	O
the	O
xor	O
problem	O
,	O
we	O
have	O
to	O
turn	O
and	O
move	O
the	O
straight	O
line	O
so	O
that	O
input	O
set	O
a	O
=	O
{	O
(	O
0	O
,	O
0	O
)	O
,	O
(	O
1	O
,	O
1	O
)	O
}	O
is	O
sepa-	O
rated	O
from	O
input	O
set	O
b	O
=	O
{	O
(	O
0	O
,	O
1	O
)	O
,	O
(	O
1	O
,	O
0	O
)	O
}	O
–	O
this	O
is	O
,	O
obviously	O
,	O
impossible	O
.	O
generally	O
,	O
the	O
input	O
parameters	O
of	O
n	O
many	O
input	O
neurons	O
can	O
be	O
represented	O
in	O
an	O
n-	O
dimensional	O
cube	O
which	O
is	O
separated	O
by	O
an	O
slp	O
through	O
an	O
(	O
n−1	O
)	O
-dimensional	O
hyper-	O
plane	O
(	O
ﬁg	O
.	O
5.8	O
)	O
.	O
only	O
sets	O
that	O
can	O
be	O
sep-	O
arated	O
by	O
such	O
a	O
hyperplane	O
,	O
i.e	O
.	O
which	O
are	O
linearly	O
separable	O
,	O
can	O
be	O
classiﬁed	O
by	O
an	O
slp	O
.	O
slp	O
can	O
not	O
do	O
everything	O
figure	O
5.8	O
:	O
linear	O
separation	O
of	O
n	O
=	O
3	O
inputs	O
from	O
input	O
neurons	O
i1	O
,	O
i2	O
and	O
i3	O
by	O
2-dimensional	O
plane	O
.	O
unfortunately	O
,	O
it	O
seems	O
that	O
the	O
percent-	O
age	O
of	O
the	O
linearly	O
separable	O
problems	O
rapidly	O
decreases	O
with	O
increasing	O
n	O
(	O
see	O
table	O
5.2	O
)	O
,	O
which	O
limits	O
the	O
functionality	O
of	O
the	O
slp	O
.	O
additionally	O
,	O
tests	O
for	O
linear	B
separability	I
are	O
diﬃcult	O
.	O
thus	O
,	O
for	O
more	O
diﬃcult	O
tasks	O
with	O
more	O
inputs	O
we	O
need	O
something	O
more	O
powerful	O
than	O
slp	O
.	O
the	O
xor	O
problem	O
itself	O
is	O
one	O
of	O
these	O
tasks	O
,	O
since	O
a	O
perceptron	B
that	O
is	O
supposed	O
to	O
rep-	O
resent	O
the	O
xor	O
function	B
already	O
needs	O
a	O
hidden	B
layer	I
(	O
ﬁg	O
.	O
5.9	O
on	O
the	O
next	O
page	O
)	O
.	O
few	O
tasks	O
are	O
linearly	O
separable	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
83	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
aaaa	O
11111111	O
1	O
1	O
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
}	O
}	O
}	O
}	O
gfed	O
@	O
abc1.5	O
aaaa	O
1	O
~	O
}	O
}	O
}	O
}	O
11111111	O
1	O
	O
gfed	O
@	O
abc0.5	O
−2	O
xor	O
figure	O
5.9	O
:	O
neural	O
network	O
realizing	O
the	O
xor	O
function	B
.	O
threshold	O
values	O
(	O
as	O
far	O
as	O
they	O
are	O
existing	O
)	O
are	O
located	O
within	O
the	O
neurons	O
.	O
5.3	O
a	O
multilayer	B
perceptron	I
contains	O
more	O
trainable	O
weight	B
layers	O
a	O
perceptron	B
with	O
two	O
or	O
more	O
trainable	O
weight	B
layers	O
(	O
called	O
multilayer	B
perceptron	I
or	O
mlp	O
)	O
is	O
more	O
powerful	O
than	O
an	O
slp	O
.	O
as	O
we	O
know	O
,	O
a	O
singlelayer	B
perceptron	I
can	O
di-	O
vide	O
the	O
input	O
space	O
by	O
means	O
of	O
a	O
hyper-	O
plane	O
(	O
in	O
a	O
two-dimensional	O
input	O
space	O
by	O
means	O
of	O
a	O
straight	O
line	O
)	O
.	O
a	O
two-	O
stage	O
perceptron	B
(	O
two	O
trainable	O
weight	B
lay-	O
ers	O
,	O
three	O
neuron	B
layers	I
)	O
can	O
classify	O
con-	O
vex	O
polygons	O
by	O
further	O
processing	O
these	O
straight	O
lines	O
,	O
e.g	O
.	O
in	O
the	O
form	O
``	O
recognize	O
patterns	O
lying	O
above	O
straight	O
line	O
1	O
,	O
be-	O
low	O
straight	O
line	O
2	O
and	O
below	O
straight	O
line	O
3	O
''	O
.	O
thus	O
,	O
we	O
–	O
metaphorically	O
speaking	O
-	O
took	O
an	O
slp	O
with	O
several	O
output	O
neu-	O
rons	O
and	O
``	O
attached	O
''	O
another	O
slp	O
(	O
upper	O
more	O
planes	O
it	O
part	O
of	O
ﬁg	O
.	O
5.10	O
on	O
the	O
facing	O
page	O
)	O
.	O
a	O
multilayer	B
perceptron	I
represents	O
an	O
uni-	O
versal	O
function	B
approximator	I
,	O
which	O
is	O
proven	O
by	O
the	O
theorem	O
of	O
cybenko	O
[	O
cyb89	O
]	O
.	O
another	O
trainable	O
weight	B
layer	O
proceeds	O
analogously	O
,	O
now	O
with	O
the	O
convex	O
poly-	O
gons	O
.	O
those	O
can	O
be	O
added	O
,	O
subtracted	O
or	O
somehow	O
processed	O
with	O
other	O
operations	O
(	O
lower	O
part	O
of	O
ﬁg	O
.	O
5.10	O
on	O
the	O
next	O
page	O
)	O
.	O
generally	O
,	O
can	O
be	O
mathematically	O
proven	O
that	O
even	O
a	O
multilayer	B
perceptron	I
with	O
one	O
layer	B
of	O
hidden	O
neurons	O
can	O
ar-	O
bitrarily	O
precisely	O
approximate	O
functions	O
with	O
only	O
ﬁnitely	O
many	O
discontinuities	O
as	O
well	O
as	O
their	O
ﬁrst	O
derivatives	O
.	O
unfortu-	O
nately	O
,	O
this	O
proof	O
is	O
not	O
constructive	O
and	O
therefore	O
it	O
is	O
left	O
to	O
us	O
to	O
ﬁnd	O
the	O
correct	O
number	O
of	O
neurons	O
and	O
weights	O
.	O
in	O
the	O
following	O
we	O
want	O
to	O
use	O
a	O
widespread	O
abbreviated	O
form	O
for	O
diﬀerent	O
multilayer	O
perceptrons	O
:	O
we	O
denote	O
a	O
two-	O
stage	O
perceptron	B
with	O
5	O
neurons	O
in	O
the	O
in-	O
put	O
layer	B
,	O
3	O
neurons	O
in	O
the	O
hidden	B
layer	I
and	O
4	O
neurons	O
in	O
the	O
output	B
layer	I
as	O
a	O
5-	O
3-4-mlp	O
.	O
deﬁnition	O
5.7	O
(	O
multilayer	B
perceptron	I
)	O
.	O
perceptrons	O
with	O
more	O
than	O
one	O
layer	B
of	O
variably	O
weighted	O
connections	O
are	O
referred	O
to	O
as	O
multilayer	O
perceptrons	O
(	O
mlp	O
)	O
.	O
an	O
n-layer	O
or	O
n-stage	O
perceptron	B
has	O
thereby	O
exactly	O
n	O
variable	O
weight	B
layers	O
and	O
n	O
+	O
1	O
neuron	B
layers	I
(	O
the	O
retina	B
is	O
dis-	O
regarded	O
here	O
)	O
with	O
neuron	O
layer	O
1	O
being	O
the	O
input	B
layer	I
.	O
since	O
three-stage	O
perceptrons	O
can	O
classify	O
sets	O
of	O
any	O
form	O
by	O
combining	O
and	O
sepa-	O
3-stage	O
mlp	O
is	O
suﬃcient	O
84	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
~	O
	O
	O
	O
	O
	O
dkriesel.com	O
5.3	O
the	O
multilayer	B
perceptron	I
i2	O
i1	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
*uuuuuuuuuuuuuuuuuuuuuuuuu	O
tjjjjjjjjjjjjjjjjjjjjjjjjj	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
	O
	O
gfed	O
@	O
abch3	O
gfed	O
@	O
abch2	O
gfed	O
@	O
abch1	O
'ppppppppppppppppp	O
wooooooooooooooooo	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
ω	O
i1	O
i2	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
~~~~~~~~~~	O
~~~~~~~~~~	O
gfed	O
@	O
abch1	O
gfed	O
@	O
abch2	O
gfed	O
@	O
abch3	O
gfed	O
gfed	O
@	O
abch6	O
gfed	O
@	O
abch4	O
@	O
abch5	O
'ppppppppppppppppp	O
wnnnnnnnnnnnnnnnnn	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
~~~~~~~~~~	O
gfed	O
@	O
abch7	O
gfed	O
@	O
abch8	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
~~~~~~~~~	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
ω	O
figure	O
5.10	O
:	O
we	O
know	O
that	O
an	O
slp	O
represents	O
a	O
straight	O
line	O
.	O
with	O
2	O
trainable	O
weight	B
layers	O
,	O
several	O
straight	O
lines	O
can	O
be	O
combined	O
to	O
form	O
convex	O
polygons	O
(	O
above	O
)	O
.	O
by	O
using	O
3	O
trainable	O
weight	B
layers	O
several	O
polygons	O
can	O
be	O
formed	O
into	O
arbitrary	O
sets	O
(	O
below	O
)	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
85	O
	O
*	O
	O
t	O
'	O
	O
	O
w	O
	O
	O
~	O
	O
	O
'	O
'	O
)	O
)	O
*	O
*	O
t	O
t	O
u	O
u	O
w	O
w	O
~	O
	O
	O
'	O
-	O
-	O
,	O
,	O
	O
	O
*	O
*	O
	O
	O
t	O
t	O
~	O
r	O
r	O
w	O
q	O
q	O
	O
	O
	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
n	O
1	O
2	O
3	O
4	O
classiﬁable	O
sets	O
hyperplane	O
convex	O
polygon	O
any	O
set	O
any	O
set	O
as	O
well	O
,	O
i.e	O
.	O
no	O
advantage	O
table	O
5.3	O
:	O
representation	O
of	O
which	O
perceptron	B
can	O
classify	O
which	O
types	O
of	O
sets	O
with	O
n	O
being	O
the	O
number	O
of	O
trainable	O
weight	B
layers	O
.	O
rating	O
arbitrarily	O
many	O
convex	O
polygons	O
,	O
another	O
step	O
will	O
not	O
be	O
advantageous	O
with	O
respect	O
to	O
function	B
representations	O
.	O
be	O
cautious	O
when	O
reading	O
the	O
literature	O
:	O
there	O
are	O
many	O
diﬀerent	O
deﬁnitions	O
of	O
what	O
is	O
counted	O
as	O
a	O
layer	B
.	O
some	O
sources	O
count	O
the	O
neuron	B
layers	I
,	O
some	O
count	O
the	O
weight	B
layers	O
.	O
some	O
sources	O
include	O
the	O
retina	B
,	O
some	O
the	O
trainable	O
weight	B
layers	O
.	O
some	O
exclude	O
(	O
for	O
some	O
reason	O
)	O
the	O
out-	O
put	O
neuron	O
layer	O
.	O
in	O
this	O
work	O
,	O
i	O
chose	O
the	O
deﬁnition	O
that	O
provides	O
,	O
in	O
my	O
opinion	O
,	O
the	O
most	O
information	O
about	O
the	O
learning	B
capabilities	O
–	O
and	O
i	O
will	O
use	O
it	O
cosistently	O
.	O
remember	O
:	O
an	O
n-stage	O
perceptron	B
has	O
ex-	O
actly	O
n	O
trainable	O
weight	B
layers	O
.	O
you	O
can	O
ﬁnd	O
a	O
summary	O
of	O
which	O
perceptrons	O
can	O
classify	O
which	O
types	O
of	O
sets	O
in	O
table	O
5.3.	O
we	O
now	O
want	O
to	O
face	O
the	O
challenge	O
of	O
train-	O
ing	O
perceptrons	O
with	O
more	O
than	O
one	O
weight	B
layer	O
.	O
5.4	O
backpropagation	B
of	I
error	I
generalizes	O
the	O
delta	B
rule	I
to	O
allow	O
for	O
mlp	O
training	O
next	O
,	O
i	O
want	O
to	O
derive	O
and	O
explain	O
the	O
backpropagation	B
of	I
error	I
learning	O
rule	O
(	O
abbreviated	O
:	O
backpropagation	B
,	O
backprop	O
or	O
bp	O
)	O
,	O
which	O
can	O
be	O
used	O
to	O
train	O
multi-	O
stage	O
perceptrons	O
with	O
semi-linear3	O
activa-	O
tion	O
functions	O
.	O
binary	O
threshold	O
functions	O
and	O
other	O
non-diﬀerentiable	O
functions	O
are	O
no	O
longer	O
supported	O
,	O
but	O
that	O
doesn	O
’	O
t	O
mat-	O
ter	O
:	O
we	O
have	O
seen	O
that	O
the	O
fermi	O
func-	O
tion	O
or	O
the	O
hyperbolic	B
tangent	I
can	O
arbi-	O
trarily	O
approximate	O
the	O
binary	B
threshold	I
function	I
by	O
means	O
of	O
a	O
temperature	O
pa-	O
rameter	O
t.	O
to	O
a	O
large	O
extent	O
i	O
will	O
fol-	O
low	O
the	O
derivation	O
according	O
to	O
[	O
zel94	O
]	O
and	O
[	O
mr86	O
]	O
.	O
once	O
again	O
i	O
want	O
to	O
point	O
out	O
that	O
this	O
procedure	O
had	O
previously	O
been	O
published	O
by	O
paul	O
werbos	O
in	O
[	O
wer74	O
]	O
but	O
had	O
consideraby	O
less	O
readers	O
than	O
in	O
[	O
mr86	O
]	O
.	O
backpropagation	B
is	O
a	O
gradient	B
descent	I
pro-	O
cedure	O
(	O
including	O
all	O
strengths	O
and	O
weak-	O
nesses	O
of	O
the	O
gradient	B
descent	I
)	O
with	O
the	O
error	B
function	I
err	O
(	O
w	O
)	O
receiving	O
all	O
n	O
weights	O
as	O
arguments	O
(	O
ﬁg	O
.	O
5.5	O
on	O
page	O
78	O
)	O
and	O
assigning	O
them	O
to	O
the	O
output	O
error	O
,	O
i.e	O
.	O
being	O
n-dimensional	O
.	O
on	O
err	O
(	O
w	O
)	O
a	O
point	O
of	O
small	O
error	O
or	O
even	O
a	O
point	O
of	O
the	O
small-	O
est	O
error	O
is	O
sought	O
by	O
means	O
of	O
the	O
gradi-	O
ent	O
descent	O
.	O
thus	O
,	O
in	O
analogy	O
to	O
the	O
delta	B
rule	I
,	O
backpropagation	B
trains	O
the	O
weights	O
of	O
the	O
neural	O
network	O
.	O
and	O
it	O
is	O
exactly	O
3	O
semilinear	O
functions	O
are	O
monotonous	O
and	O
diﬀeren-	O
tiable	O
–	O
but	O
generally	O
they	O
are	O
not	O
linear	O
.	O
86	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
5.4	O
backpropagation	B
of	I
error	I
the	O
delta	B
rule	I
or	O
its	O
variable	O
δi	O
for	O
a	O
neu-	O
ron	O
i	O
which	O
is	O
expanded	O
from	O
one	O
trainable	O
weight	B
layer	O
to	O
several	O
ones	O
by	O
backpropa-	O
gation	O
.	O
5.4.1	O
the	O
derivation	O
is	O
similar	O
to	O
the	O
one	O
of	O
the	O
delta	B
rule	I
,	O
but	O
with	O
a	O
generalized	O
delta	O
let	O
us	O
deﬁne	O
in	O
advance	O
that	O
the	O
network	B
input	I
of	O
the	O
individual	O
neurons	O
i	O
results	O
from	O
the	O
weighted	B
sum	I
.	O
furthermore	O
,	O
as	O
with	O
the	O
derivation	O
of	O
the	O
delta	B
rule	I
,	O
let	O
op	O
,	O
i	O
,	O
netp	O
,	O
i	O
etc	O
.	O
be	O
deﬁned	O
as	O
the	O
already	O
familiar	O
oi	O
,	O
neti	O
,	O
etc	O
.	O
under	O
the	O
input	O
pat-	O
tern	O
p	O
we	O
used	O
for	O
the	O
training	O
.	O
let	O
the	O
output	B
function	I
be	O
the	O
identity	O
again	O
,	O
thus	O
oi	O
=	O
fact	O
(	O
netp	O
,	O
i	O
)	O
holds	O
for	O
any	O
neuron	O
i.	O
since	O
this	O
is	O
a	O
generalization	B
of	O
the	O
delta	B
rule	I
,	O
we	O
use	O
the	O
same	O
formula	O
framework	O
as	O
with	O
the	O
delta	B
rule	I
(	O
equation	O
5.20	O
on	O
page	O
81	O
)	O
.	O
as	O
already	O
indicated	O
,	O
we	O
have	O
to	O
generalize	O
the	O
variable	O
δ	O
for	O
every	O
neu-	O
ron	O
.	O
first	O
of	O
all	O
:	O
where	O
is	O
the	O
neuron	O
for	O
which	O
we	O
want	O
to	O
calculate	O
δ	O
?	O
it	O
is	O
obvious	O
to	O
select	O
an	O
arbitrary	O
inner	O
neuron	O
h	O
having	O
a	O
set	O
k	O
of	O
predecessor	O
neurons	O
k	O
as	O
well	O
as	O
a	O
set	O
of	O
l	O
successor	O
neurons	O
l	O
,	O
which	O
are	O
also	O
inner	O
neurons	O
(	O
see	O
ﬁg	O
.	O
5.11	O
)	O
.	O
it	O
is	O
therefore	O
irrelevant	O
whether	O
the	O
prede-	O
cessor	O
neurons	O
are	O
already	O
the	O
input	O
neu-	O
rons	O
.	O
now	O
we	O
perform	O
the	O
same	O
derivation	O
as	O
for	O
the	O
delta	B
rule	I
and	O
split	O
functions	O
by	O
means	O
the	O
chain	O
rule	O
.	O
i	O
will	O
not	O
discuss	O
this	O
derivation	O
in	O
great	O
detail	O
,	O
but	O
the	O
prin-	O
cipal	O
is	O
similar	O
to	O
that	O
of	O
the	O
delta	B
rule	I
(	O
the	O
general-	O
ization	O
of	O
δ	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
&	O
lllllllllllllll	O
==========	O
onml	O
hijkς	O
xrrrrrrrrrrrrrrr	O
 	O
/.-	O
,	O
/.-	O
,	O
/.-	O
,	O
(	O
)	O
*+	O
(	O
)	O
*+	O
(	O
)	O
*+	O
fact	O
wppppppp	O
nnnnnnn	O
.	O
.	O
.	O
pppppppp	O
wk	O
,	O
h	O
h	O
'nnnnnnnn	O
wh	O
,	O
l	O
.	O
.	O
.	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
k	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
l	O
k	O
h	O
l	O
figure	O
5.11	O
:	O
illustration	O
of	O
the	O
position	O
of	O
our	O
neuron	O
h	O
within	O
the	O
neural	O
network	O
.	O
it	O
is	O
lying	O
in	O
layer	B
h	O
,	O
the	O
preceding	O
layer	B
is	O
k	O
,	O
the	O
subsequent	O
layer	B
is	O
l.	O
diﬀerences	O
are	O
,	O
as	O
already	O
mentioned	O
,	O
in	O
the	O
generalized	O
δ	O
)	O
.	O
we	O
initially	O
derive	O
the	O
error	B
function	I
err	O
according	O
to	O
a	O
weight	B
wk	O
,	O
h	O
.	O
∂err	O
(	O
wk	O
,	O
h	O
)	O
∂wk	O
,	O
h	O
·	O
∂neth	O
∂wk	O
,	O
h	O
=	O
∂err	O
|	O
{	O
z	O
}	O
∂neth	O
=−δh	O
(	O
5.23	O
)	O
the	O
ﬁrst	O
factor	O
of	O
equation	O
5.23	O
is	O
−δh	O
,	O
which	O
we	O
will	O
deal	O
with	O
later	O
in	O
this	O
text	O
.	O
the	O
numerator	O
of	O
the	O
second	O
factor	O
of	O
the	O
equation	O
includes	O
the	O
network	B
input	I
,	O
i.e	O
.	O
the	O
weighted	B
sum	I
is	O
included	O
in	O
the	O
numer-	O
ator	O
so	O
that	O
we	O
can	O
immediately	O
derive	O
it	O
.	O
again	O
,	O
all	O
summands	O
of	O
the	O
sum	O
drop	O
out	O
apart	O
from	O
the	O
summand	O
containing	O
wk	O
,	O
h	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
87	O
&	O
	O
	O
w	O
x	O
 	O
	O
	O
'	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
this	O
summand	O
is	O
referred	O
to	O
as	O
wk	O
,	O
h·	O
ok.	O
if	O
we	O
calculate	O
the	O
derivative	O
,	O
the	O
output	O
of	O
neuron	O
k	O
becomes	O
:	O
according	O
to	O
the	O
deﬁnition	O
of	O
the	O
multi-	O
dimensional	O
chain	O
rule	O
,	O
we	O
immediately	O
ob-	O
tain	O
equation	O
5.31	O
:	O
∂neth	O
∂wk	O
,	O
h	O
k∈k	O
wk	O
,	O
hok	O
∂wk	O
,	O
h	O
=	O
∂p	O
=	O
ok	O
(	O
cid:18	O
)	O
=x	O
l∈l	O
−	O
∂err	O
∂oh	O
(	O
5.24	O
)	O
(	O
5.25	O
)	O
(	O
cid:19	O
)	O
−	O
∂err	O
∂netl	O
·	O
∂netl	O
∂oh	O
(	O
5.31	O
)	O
as	O
promised	O
,	O
we	O
will	O
now	O
discuss	O
the	O
−δh	O
of	O
equation	O
5.23	O
on	O
the	O
previous	O
page	O
,	O
which	O
is	O
split	O
up	O
again	O
according	O
of	O
the	O
chain	O
rule	O
:	O
the	O
sum	O
in	O
equation	O
5.31	O
contains	O
two	O
fac-	O
tors	O
.	O
now	O
we	O
want	O
to	O
discuss	O
these	O
factors	O
being	O
added	O
over	O
the	O
subsequent	O
layer	B
l.	O
we	O
simply	O
calculate	O
the	O
second	O
factor	O
in	O
the	O
following	O
equation	O
5.33	O
:	O
δh	O
=	O
−	O
∂err	O
∂neth	O
=	O
−	O
∂err	O
∂oh	O
·	O
∂oh	O
∂neth	O
(	O
5.26	O
)	O
(	O
5.27	O
)	O
∂netl	O
∂oh	O
=	O
∂p	O
=	O
wh	O
,	O
l	O
h∈h	O
wh	O
,	O
l	O
·	O
oh	O
∂oh	O
(	O
5.32	O
)	O
(	O
5.33	O
)	O
the	O
derivation	O
of	O
the	O
output	O
according	O
to	O
the	O
network	B
input	I
(	O
the	O
second	O
factor	O
in	O
equation	O
5.27	O
)	O
clearly	O
equals	O
the	O
deriva-	O
tion	O
of	O
the	O
activation	B
function	I
according	O
to	O
the	O
network	B
input	I
:	O
the	O
same	O
applies	O
for	O
the	O
ﬁrst	O
factor	O
accord-	O
ing	O
to	O
the	O
deﬁnition	O
of	O
our	O
δ	O
:	O
−	O
∂err	O
∂netl	O
=	O
δl	O
(	O
5.34	O
)	O
∂oh	O
∂neth	O
=	O
∂fact	O
(	O
neth	O
)	O
∂neth	O
0	O
(	O
neth	O
)	O
=	O
fact	O
(	O
5.28	O
)	O
(	O
5.29	O
)	O
now	O
we	O
insert	O
:	O
⇒	O
−	O
∂err	O
∂oh	O
=x	O
l∈l	O
δlwh	O
,	O
l	O
(	O
5.35	O
)	O
consider	O
this	O
an	O
important	O
passage	O
!	O
we	O
now	O
analogously	O
derive	O
the	O
ﬁrst	O
factor	O
in	O
equation	O
5.27.	O
therefore	O
,	O
we	O
have	O
to	O
point	O
out	O
that	O
the	O
derivation	O
of	O
the	O
error	O
func-	O
tion	O
according	O
to	O
the	O
output	O
of	O
an	O
inner	O
neuron	O
layer	O
depends	O
on	O
the	O
vector	O
of	O
all	O
network	O
inputs	O
of	O
the	O
next	O
following	O
layer	B
.	O
this	O
is	O
reﬂected	O
in	O
equation	O
5.30	O
:	O
=	O
−	O
∂err	O
(	O
netl1	O
,	O
.	O
.	O
.	O
,	O
netl|l|	O
)	O
−	O
∂err	O
∂oh	O
(	O
5.30	O
)	O
∂oh	O
you	O
can	O
ﬁnd	O
a	O
graphic	O
version	O
of	O
the	O
δ	O
generalization	B
including	O
all	O
splittings	O
in	O
ﬁg	O
.	O
5.12	O
on	O
the	O
facing	O
page	O
.	O
the	O
reader	O
might	O
already	O
have	O
noticed	O
that	O
some	O
intermediate	O
results	O
were	O
shown	O
in	O
frames	O
.	O
exactly	O
those	O
intermediate	O
re-	O
sults	O
were	O
highlighted	O
in	O
that	O
way	O
,	O
which	O
are	O
a	O
factor	O
in	O
the	O
change	B
in	I
weight	I
of	O
wk	O
,	O
h	O
.	O
if	O
the	O
aforementioned	O
equations	O
are	O
88	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
5.4	O
backpropagation	B
of	I
error	I
δh	O
−	O
∂err	O
∂neth	O
∂oh	O
∂neth	O
−	O
∂err	O
∂oh	O
f0	O
act	O
(	O
neth	O
)	O
−	O
∂err	O
∂netl	O
δl	O
l∈l	O
∂netl	O
∂oh	O
p	O
∂p	O
wh	O
,	O
l·oh	O
h∈h	O
∂oh	O
wh	O
,	O
l	O
figure	O
5.12	O
:	O
graphical	O
representation	O
of	O
the	O
equations	O
(	O
by	O
equal	O
signs	O
)	O
and	O
chain	O
rule	O
splittings	O
(	O
by	O
arrows	O
)	O
in	O
the	O
framework	O
of	O
the	O
backpropagation	B
derivation	O
.	O
the	O
leaves	O
of	O
the	O
tree	O
reﬂect	O
the	O
ﬁnal	O
results	O
from	O
the	O
generalization	B
of	O
δ	O
,	O
which	O
are	O
framed	O
in	O
the	O
derivation	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
89	O
	O
	O
	O
	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
combined	O
with	O
the	O
highlighted	O
intermedi-	O
ate	O
results	O
,	O
the	O
outcome	O
of	O
this	O
will	O
be	O
the	O
wanted	O
change	B
in	I
weight	I
∆wk	O
,	O
h	O
to	O
act	O
(	O
neth	O
)	O
·x	O
0	O
l∈l	O
δh	O
=	O
f	O
∆wk	O
,	O
h	O
=	O
ηokδh	O
with	O
(	O
5.36	O
)	O
(	O
δlwh	O
,	O
l	O
)	O
–	O
of	O
course	O
only	O
in	O
case	O
of	O
h	O
being	O
an	O
inner	O
neuron	O
(	O
otherweise	O
there	O
would	O
not	O
be	O
a	O
subsequent	O
layer	B
l	O
)	O
.	O
the	O
case	O
of	O
h	O
being	O
an	O
output	O
neuron	O
has	O
already	O
been	O
discussed	O
during	O
the	O
deriva-	O
tion	O
of	O
the	O
delta	B
rule	I
.	O
all	O
in	O
all	O
,	O
the	O
re-	O
sult	O
is	O
the	O
generalization	B
of	O
the	O
delta	B
rule	I
,	O
called	O
backpropagation	B
of	I
error	I
:	O
∆wk	O
,	O
h	O
=	O
ηokδh	O
with	O
δh	O
=	O
act	O
(	O
neth	O
)	O
·	O
(	O
th	O
−	O
yh	O
)	O
(	O
h	O
outside	O
)	O
f0	O
f0	O
l∈l	O
(	O
δlwh	O
,	O
l	O
)	O
(	O
h	O
inside	O
)	O
(	O
5.37	O
)	O
in	O
contrast	O
to	O
the	O
delta	B
rule	I
,	O
δ	O
is	O
treated	O
diﬀerently	O
depending	O
on	O
whether	O
h	O
is	O
an	O
output	O
or	O
an	O
inner	O
(	O
i.e	O
.	O
hidden	O
)	O
neuron	O
:	O
act	O
(	O
neth	O
)	O
·p	O
(	O
1.	O
if	O
h	O
is	O
an	O
output	O
neuron	O
,	O
then	O
δp	O
,	O
h	O
=	O
f	O
act	O
(	O
netp	O
,	O
h	O
)	O
·	O
(	O
tp	O
,	O
h	O
−	O
yp	O
,	O
h	O
)	O
0	O
(	O
5.38	O
)	O
thus	O
,	O
under	O
our	O
training	B
pattern	I
p	O
the	O
weight	B
wk	O
,	O
h	O
from	O
k	O
to	O
h	O
is	O
changed	O
proportionally	O
according	O
to	O
.	O
the	O
learning	B
rate	I
η	O
,	O
.	O
the	O
output	O
op	O
,	O
k	O
of	O
the	O
predeces-	O
sor	O
neuron	O
k	O
,	O
.	O
the	O
gradient	B
of	O
the	O
activation	B
function	I
at	O
the	O
position	O
of	O
the	O
network	B
input	I
of	O
the	O
successor	O
neuron	O
f0	O
act	O
(	O
netp	O
,	O
h	O
)	O
and	O
teach	O
.	O
input	O
changed	O
for	O
the	O
outer	O
weight	B
layer	O
back-	O
propagation	O
for	O
inner	O
layers	O
.	O
the	O
diﬀerence	O
between	O
teaching	B
input	I
tp	O
,	O
h	O
and	O
output	O
yp	O
,	O
h	O
of	O
the	O
successor	O
neuron	O
h.	O
in	O
this	O
case	O
,	O
backpropagation	B
is	O
work-	O
ing	O
on	O
two	O
neuron	B
layers	I
,	O
the	O
output	B
layer	I
with	O
the	O
successor	O
neuron	O
h	O
and	O
the	O
preceding	O
layer	B
with	O
the	O
predeces-	O
sor	O
neuron	O
k.	O
2.	O
if	O
h	O
is	O
an	O
inner	O
,	O
hidden	O
neuron	O
,	O
then	O
(	O
δp	O
,	O
l	O
·	O
wh	O
,	O
l	O
)	O
act	O
(	O
netp	O
,	O
h	O
)	O
·x	O
δp	O
,	O
h	O
=	O
f	O
0	O
l∈l	O
(	O
5.39	O
)	O
holds	O
.	O
i	O
want	O
to	O
explicitly	O
mention	O
that	O
backpropagation	B
is	O
now	O
working	O
on	O
three	O
layers	O
.	O
here	O
,	O
neuron	O
k	O
is	O
the	O
predecessor	O
of	O
the	O
connection	B
to	O
be	O
changed	O
with	O
the	O
weight	B
wk	O
,	O
h	O
,	O
the	O
neuron	O
h	O
is	O
the	O
successor	O
of	O
the	O
con-	O
nection	O
to	O
be	O
changed	O
and	O
the	O
neu-	O
rons	O
l	O
are	O
lying	O
in	O
the	O
layer	B
follow-	O
ing	O
the	O
successor	O
neuron	O
.	O
thus	O
,	O
ac-	O
cording	O
to	O
our	O
training	B
pattern	I
p	O
,	O
the	O
weight	B
wk	O
,	O
h	O
from	O
k	O
to	O
h	O
is	O
proportion-	O
ally	O
changed	O
according	O
to	O
.	O
the	O
learning	B
rate	I
η	O
,	O
.	O
the	O
output	O
of	O
the	O
predecessor	O
neuron	O
op	O
,	O
k	O
,	O
.	O
the	O
gradient	B
of	O
the	O
activation	B
function	I
at	O
the	O
position	O
of	O
the	O
network	B
input	I
of	O
the	O
successor	O
neuron	O
f0	O
act	O
(	O
netp	O
,	O
h	O
)	O
,	O
.	O
as	O
well	O
as	O
,	O
and	O
this	O
according	O
the	O
diﬀerence	O
,	O
the	O
weighted	B
sum	I
of	O
the	O
changes	O
in	O
weight	B
to	O
all	O
neurons	O
following	O
h	O
,	O
p	O
l∈l	O
(	O
δp	O
,	O
l	O
·	O
wh	O
,	O
l	O
)	O
.	O
is	O
to	O
90	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
backprop	O
expands	O
delta	B
rule	I
dkriesel.com	O
5.4	O
backpropagation	B
of	I
error	I
deﬁnition	O
5.8	O
(	O
backpropagation	B
)	O
.	O
if	O
we	O
summarize	O
formulas	O
5.38	O
on	O
the	O
preceding	O
page	O
and	O
5.39	O
on	O
the	O
facing	O
page	O
,	O
we	O
re-	O
ceive	O
the	O
following	O
ﬁnal	O
formula	O
for	O
back-	O
propagation	O
(	O
the	O
identiﬁers	O
p	O
are	O
om-	O
mited	O
for	O
reasons	O
of	O
clarity	O
)	O
:	O
(	O
∆wk	O
,	O
h	O
=	O
ηokδh	O
with	O
δh	O
=	O
act	O
(	O
neth	O
)	O
·p	O
act	O
(	O
neth	O
)	O
·	O
(	O
th	O
−	O
yh	O
)	O
(	O
h	O
outside	O
)	O
f0	O
f0	O
l∈l	O
(	O
δlwh	O
,	O
l	O
)	O
(	O
h	O
inside	O
)	O
(	O
5.40	O
)	O
snipe	O
:	O
an	O
online	O
variant	O
of	O
backpro-	O
pagation	O
is	O
implemented	O
in	O
the	O
method	O
trainbackpropagationoferror	O
within	O
the	O
class	O
neuralnetwork	O
.	O
5.4.2	O
heading	O
back	O
:	O
boiling	O
backpropagation	B
down	O
to	O
delta	B
rule	I
as	O
explained	O
above	O
,	O
the	O
delta	B
rule	I
is	O
a	O
special	O
case	O
of	O
backpropagation	B
for	O
one-	O
stage	O
perceptrons	O
and	O
linear	O
activation	O
functions	O
–	O
i	O
want	O
to	O
brieﬂy	O
explain	O
this	O
circumstance	O
and	O
develop	O
the	O
delta	B
rule	I
out	O
of	O
backpropagation	B
in	O
order	O
to	O
aug-	O
ment	O
the	O
understanding	O
of	O
both	O
rules	O
.	O
we	O
have	O
seen	O
that	O
backpropagation	B
is	O
deﬁned	O
by	O
(	O
∆wk	O
,	O
h	O
=	O
ηokδh	O
with	O
δh	O
=	O
act	O
(	O
neth	O
)	O
·p	O
act	O
(	O
neth	O
)	O
·	O
(	O
th	O
−	O
yh	O
)	O
(	O
h	O
outside	O
)	O
f0	O
f0	O
l∈l	O
(	O
δlwh	O
,	O
l	O
)	O
(	O
h	O
inside	O
)	O
(	O
5.41	O
)	O
it	O
is	O
obvious	O
that	O
backpropagation	B
ini-	O
tially	O
processes	O
the	O
last	O
weight	B
layer	O
di-	O
rectly	O
by	O
means	O
of	O
the	O
teaching	B
input	I
and	O
then	O
works	O
backwards	O
from	O
layer	B
to	O
layer	B
while	O
considering	O
each	O
preceding	O
change	O
in	O
weights	O
.	O
thus	O
,	O
the	O
teaching	B
input	I
leaves	O
traces	O
in	O
all	O
weight	B
layers	O
.	O
here	O
i	O
describe	O
the	O
ﬁrst	O
(	O
delta	B
rule	I
)	O
and	O
the	O
second	O
part	O
of	O
backpropagation	B
(	O
generalized	O
delta	B
rule	I
on	O
more	O
layers	O
)	O
in	O
one	O
go	O
,	O
which	O
may	O
meet	O
the	O
requirements	O
of	O
the	O
matter	O
but	O
not	O
of	O
the	O
research	O
.	O
the	O
ﬁrst	O
part	O
is	O
obvious	O
,	O
which	O
you	O
will	O
soon	O
see	O
in	O
the	O
framework	O
of	O
a	O
mathematical	O
gimmick	O
.	O
decades	O
of	O
development	O
time	O
and	O
work	O
lie	O
between	O
the	O
ﬁrst	O
and	O
the	O
second	O
,	O
recursive	O
part	O
.	O
like	O
many	O
groundbreaking	O
inventions	O
,	O
it	O
was	O
not	O
until	O
its	O
development	O
that	O
it	O
was	O
recog-	O
nized	O
how	O
plausible	O
this	O
invention	O
was	O
.	O
since	O
we	O
only	O
use	O
it	O
for	O
one-stage	O
percep-	O
trons	O
,	O
the	O
second	O
part	O
of	O
backpropagation	B
(	O
light-colored	O
)	O
is	O
omitted	O
without	O
substitu-	O
tion	O
.	O
the	O
result	O
is	O
:	O
∆wk	O
,	O
h	O
=	O
ηokδh	O
with	O
δh	O
=	O
f0	O
act	O
(	O
neth	O
)	O
·	O
(	O
th	O
−	O
oh	O
)	O
(	O
5.42	O
)	O
furthermore	O
,	O
we	O
only	O
want	O
to	O
use	O
linear	O
activation	O
functions	O
so	O
that	O
f0	O
act	O
(	O
light-	O
colored	O
)	O
is	O
constant	O
.	O
as	O
is	O
generally	O
known	O
,	O
constants	O
can	O
be	O
combined	O
,	O
and	O
therefore	O
we	O
directly	O
merge	O
the	O
constant	O
derivative	O
f0	O
act	O
and	O
(	O
being	O
constant	O
for	O
at	O
least	O
one	O
lerning	O
cycle	O
)	O
the	O
learning	B
rate	I
η	O
(	O
also	O
light-colored	O
)	O
in	O
η.	O
thus	O
,	O
the	O
result	O
is	O
:	O
∆wk	O
,	O
h	O
=	O
ηokδh	O
=	O
ηok	O
·	O
(	O
th	O
−	O
oh	O
)	O
(	O
5.43	O
)	O
this	O
exactly	O
corresponds	O
to	O
the	O
delta	B
rule	I
deﬁnition	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
91	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
5.4.3	O
the	O
selection	O
of	O
the	O
learning	B
rate	I
has	O
heavy	O
inﬂuence	O
on	O
the	O
learning	B
process	O
5.4.3.1	O
variation	O
of	O
the	O
learning	B
rate	I
over	O
time	O
in	O
the	O
meantime	O
we	O
have	O
often	O
seen	O
that	O
the	O
change	B
in	I
weight	I
is	O
,	O
in	O
any	O
case	O
,	O
pro-	O
portional	O
to	O
the	O
learning	B
rate	I
η.	O
thus	O
,	O
the	O
selection	O
of	O
η	O
is	O
crucial	O
for	O
the	O
behaviour	O
of	O
backpropagation	B
and	O
for	O
learning	B
proce-	O
dures	O
in	O
general	O
.	O
how	O
fast	O
will	O
be	O
learned	O
?	O
deﬁnition	O
5.9	O
(	O
learning	B
rate	I
)	O
.	O
speed	O
and	O
accuracy	O
of	O
a	O
learning	B
procedure	O
can	O
always	O
be	O
controlled	O
by	O
and	O
are	O
always	O
pro-	O
portional	O
to	O
a	O
learning	B
rate	I
which	O
is	O
writ-	O
ten	O
as	O
η.	O
η	O
(	O
cid:73	O
)	O
if	O
the	O
value	O
of	O
the	O
chosen	O
η	O
is	O
too	O
large	O
,	O
the	O
jumps	O
on	O
the	O
error	O
surface	O
are	O
also	O
too	O
large	O
and	O
,	O
for	O
example	O
,	O
narrow	O
valleys	O
could	O
simply	O
be	O
jumped	O
over	O
.	O
addition-	O
ally	O
,	O
the	O
movements	O
across	O
the	O
error	O
sur-	O
face	O
would	O
be	O
very	O
uncontrolled	O
.	O
thus	O
,	O
a	O
small	O
η	O
is	O
the	O
desired	O
input	O
,	O
which	O
,	O
how-	O
ever	O
,	O
can	O
cost	O
a	O
huge	O
,	O
often	O
unacceptable	O
amount	O
of	O
time	O
.	O
experience	O
shows	O
that	O
good	O
learning	B
rate	I
values	O
are	O
in	O
the	O
range	O
of	O
0.01	O
≤	O
η	O
≤	O
0.9.	O
the	O
selection	O
of	O
η	O
signiﬁcantly	O
depends	O
on	O
the	O
problem	O
,	O
the	O
network	O
and	O
the	O
training	O
data	O
,	O
so	O
that	O
it	O
is	O
barely	O
possible	O
to	O
give	O
practical	O
advise	O
.	O
but	O
for	O
instance	O
it	O
is	O
pop-	O
ular	O
to	O
start	O
with	O
a	O
relatively	O
large	O
η	O
,	O
e.g	O
.	O
0.9	O
,	O
and	O
to	O
slowly	O
decrease	O
it	O
down	O
to	O
0.1.	O
for	O
simpler	O
problems	O
η	O
can	O
often	O
be	O
kept	O
constant	O
.	O
during	O
training	O
,	O
another	O
stylistic	O
device	O
can	O
be	O
a	O
variable	O
learning	B
rate	I
:	O
in	O
the	O
beginning	O
,	O
a	O
large	O
learning	B
rate	I
leads	O
to	O
good	O
results	O
,	O
but	O
later	O
it	O
results	O
in	O
inac-	O
curate	O
learning	B
.	O
a	O
smaller	O
learning	B
rate	I
is	O
more	O
time-consuming	O
,	O
but	O
the	O
result	O
is	O
more	O
precise	O
.	O
thus	O
,	O
during	O
the	O
learning	B
process	O
the	O
learning	B
rate	I
needs	O
to	O
be	O
de-	O
creased	O
by	O
one	O
order	O
of	O
magnitude	O
once	O
or	O
repeatedly	O
.	O
a	O
common	O
error	O
(	O
which	O
also	O
seems	O
to	O
be	O
a	O
very	O
neat	O
solution	O
at	O
ﬁrst	O
glance	O
)	O
is	O
to	O
con-	O
tinually	O
decrease	O
the	O
learning	B
rate	I
.	O
here	O
it	O
quickly	O
happens	O
that	O
the	O
descent	O
of	O
the	O
learning	B
rate	I
is	O
larger	O
than	O
the	O
ascent	O
of	O
a	O
hill	O
of	O
the	O
error	B
function	I
we	O
are	O
climb-	O
ing	O
.	O
the	O
result	O
is	O
that	O
we	O
simply	O
get	O
stuck	O
at	O
this	O
ascent	O
.	O
solution	O
:	O
rather	O
reduce	O
the	O
learning	B
rate	I
gradually	O
as	O
mentioned	O
above	O
.	O
5.4.3.2	O
diﬀerent	O
layers	O
–	O
diﬀerent	O
learning	B
rates	O
the	O
farer	O
we	O
move	O
away	O
from	O
the	O
out-	O
put	O
layer	B
during	O
the	O
learning	B
process	O
,	O
the	O
slower	O
backpropagation	B
is	O
learning	B
.	O
thus	O
,	O
it	O
is	O
a	O
good	O
idea	O
to	O
select	O
a	O
larger	O
learning	B
rate	I
for	O
the	O
weight	B
layers	O
close	O
to	O
the	O
in-	O
put	O
layer	B
than	O
for	O
the	O
weight	B
layers	O
close	O
to	O
the	O
output	B
layer	I
.	O
92	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
5.5	O
resilient	B
backpropagation	I
5.5	O
resilient	B
backpropagation	I
is	O
an	O
extension	O
to	O
backpropagation	B
of	I
error	I
we	O
have	O
just	O
raised	O
two	O
backpropagation-	O
speciﬁc	O
properties	O
that	O
can	O
occasionally	O
be	O
a	O
problem	O
(	O
in	O
addition	O
to	O
those	O
which	O
are	O
already	O
caused	O
by	O
gradient	B
descent	I
itself	O
)	O
:	O
on	O
the	O
one	O
hand	O
,	O
users	O
of	O
backpropaga-	O
tion	O
can	O
choose	O
a	O
bad	O
learning	B
rate	I
.	O
on	O
the	O
other	O
hand	O
,	O
the	O
further	O
the	O
weights	O
are	O
from	O
the	O
output	B
layer	I
,	O
the	O
slower	O
backpro-	O
pagation	O
learns	O
.	O
for	O
this	O
reason	O
,	O
mar-	O
tin	O
riedmiller	O
et	O
al	O
.	O
enhanced	O
back-	O
propagation	O
and	O
called	O
their	O
version	O
re-	O
silient	O
backpropagation	B
(	O
short	O
rprop	O
)	O
[	O
rb93	O
,	O
rie94	O
]	O
.	O
i	O
want	O
to	O
compare	O
back-	O
propagation	O
and	O
rprop	O
,	O
without	O
explic-	O
itly	O
declaring	O
one	O
version	O
superior	O
to	O
the	O
other	O
.	O
before	O
actually	O
dealing	O
with	O
formu-	O
las	O
,	O
let	O
us	O
informally	O
compare	O
the	O
two	O
pri-	O
mary	O
ideas	O
behind	O
rprop	O
(	O
and	O
their	O
con-	O
sequences	O
)	O
to	O
the	O
already	O
familiar	O
backpro-	O
pagation	O
.	O
learning	B
rates	O
:	O
backpropagation	B
uses	O
by	O
default	O
a	O
learning	B
rate	I
η	O
,	O
which	O
is	O
se-	O
lected	O
by	O
the	O
user	O
,	O
and	O
applies	O
to	O
the	O
entire	O
network	O
.	O
it	O
remains	O
static	O
un-	O
til	O
it	O
is	O
manually	O
changed	O
.	O
we	O
have	O
already	O
explored	O
the	O
disadvantages	O
of	O
this	O
approach	O
.	O
here	O
,	O
rprop	O
pursues	O
a	O
completely	O
diﬀerent	O
approach	O
:	O
there	O
is	O
no	O
global	O
learning	B
rate	I
.	O
first	O
,	O
each	O
weight	B
wi	O
,	O
j	O
has	O
its	O
own	O
learning	B
rate	I
ηi	O
,	O
j	O
,	O
and	O
second	O
,	O
these	O
learning	B
rates	O
are	O
not	O
chosen	O
by	O
the	O
user	O
,	O
but	O
are	O
au-	O
tomatically	O
set	O
by	O
rprop	O
itself	O
.	O
third	O
,	O
the	O
weight	B
changes	O
are	O
not	O
static	O
but	O
are	O
adapted	O
for	O
each	O
time	O
step	O
of	O
rprop	O
.	O
to	O
account	O
for	O
the	O
temporal	O
change	O
,	O
we	O
have	O
to	O
correctly	O
call	O
it	O
ηi	O
,	O
j	O
(	O
t	O
)	O
.	O
this	O
not	O
only	O
enables	O
more	O
focused	O
learning	B
,	O
also	O
the	O
problem	O
of	O
an	O
increasingly	O
slowed	O
down	O
learning	B
throughout	O
the	O
layers	O
is	O
solved	O
in	O
an	O
elegant	O
way	O
.	O
weight	B
change	O
:	O
when	O
using	O
backpropa-	O
gation	O
,	O
weights	O
are	O
changed	O
propor-	O
tionally	O
to	O
the	O
gradient	B
of	O
the	O
error	B
function	I
.	O
at	O
ﬁrst	O
glance	O
,	O
this	O
is	O
really	O
intuitive	O
.	O
however	O
,	O
we	O
incorporate	O
ev-	O
ery	O
jagged	O
feature	O
of	O
the	O
error	O
surface	O
into	O
the	O
weight	B
changes	O
.	O
it	O
is	O
at	O
least	O
questionable	O
,	O
whether	O
this	O
is	O
always	O
useful	O
.	O
here	O
,	O
rprop	O
takes	O
other	O
ways	O
as	O
well	O
:	O
the	O
amount	O
of	O
weight	B
change	O
∆wi	O
,	O
j	O
simply	O
directly	O
corresponds	O
to	O
the	O
automatically	O
adjusted	O
learning	B
rate	I
ηi	O
,	O
j	O
.	O
thus	O
the	O
change	B
in	I
weight	I
is	O
not	O
proportional	O
to	O
the	O
gradient	B
,	O
it	O
is	O
only	O
inﬂuenced	O
by	O
the	O
sign	O
of	O
the	O
gra-	O
dient	O
.	O
until	O
now	O
we	O
still	O
do	O
not	O
know	O
how	O
exactly	O
the	O
ηi	O
,	O
j	O
are	O
adapted	O
at	O
run	O
time	O
,	O
but	O
let	O
me	O
anticipate	O
that	O
the	O
resulting	O
process	O
looks	O
consider-	O
much	O
ably	O
less	O
rugged	O
than	O
an	O
error	O
func-	O
tion	O
.	O
smoother	O
learning	B
in	O
contrast	O
to	O
backprop	O
the	O
weight	B
update	O
step	O
is	O
replaced	O
and	O
an	O
additional	O
step	O
for	O
the	O
adjustment	O
of	O
the	O
learning	B
rate	I
is	O
added	O
.	O
now	O
how	O
exactly	O
are	O
these	O
ideas	O
being	O
implemented	O
?	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
93	O
one	O
learning-	O
rate	O
per	O
weight	B
ηi	O
,	O
j	O
(	O
cid:73	O
)	O
automatic	O
learning	B
rate	I
adjustment	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
change	O
in	O
deﬁnition	O
5.10	O
(	O
weight	B
rprop	O
)	O
.	O
5.5.1	O
weight	B
changes	O
are	O
not	O
proportional	O
to	O
the	O
gradient	B
let	O
us	O
ﬁrst	O
consider	O
the	O
change	B
in	I
weight	I
.	O
we	O
have	O
already	O
noticed	O
that	O
the	O
weight-	O
speciﬁc	O
learning	B
rates	O
directly	O
serve	O
as	O
ab-	O
solute	O
values	O
for	O
the	O
changes	O
of	O
the	O
re-	O
spective	O
weights	O
.	O
there	O
remains	O
the	O
ques-	O
tion	O
of	O
where	O
the	O
sign	O
comes	O
from	O
–	O
this	O
is	O
a	O
point	O
at	O
which	O
the	O
gradient	B
comes	O
into	O
play	O
.	O
as	O
with	O
the	O
derivation	O
of	O
back-	O
propagation	O
,	O
we	O
derive	O
the	O
error	B
function	I
err	O
(	O
w	O
)	O
by	O
the	O
individual	O
weights	O
wi	O
,	O
j	O
and	O
obtain	O
gradients	O
∂err	O
(	O
w	O
)	O
.	O
now	O
,	O
the	O
big	O
∂wi	O
,	O
j	O
diﬀerence	O
:	O
rather	O
than	O
multiplicatively	O
incorporating	O
the	O
absolute	O
value	O
of	O
the	O
gradient	B
into	O
the	O
weight	B
change	O
,	O
we	O
con-	O
sider	O
only	O
the	O
sign	O
of	O
the	O
gradient	B
.	O
the	O
gradient	B
hence	O
no	O
longer	O
determines	O
the	O
strength	O
,	O
but	O
only	O
the	O
direction	O
of	O
the	O
weight	B
change	O
.	O
if	O
the	O
sign	O
of	O
the	O
gradient	B
∂err	O
(	O
w	O
)	O
is	O
pos-	O
∂wi	O
,	O
j	O
itive	O
,	O
we	O
must	O
decrease	O
the	O
weight	B
wi	O
,	O
j	O
.	O
so	O
the	O
weight	B
is	O
reduced	O
by	O
ηi	O
,	O
j	O
.	O
if	O
the	O
sign	O
of	O
the	O
gradient	B
is	O
negative	O
,	O
the	O
weight	B
needs	O
to	O
be	O
increased	O
.	O
so	O
ηi	O
,	O
j	O
is	O
added	O
to	O
it	O
.	O
if	O
the	O
gradient	B
is	O
exactly	O
0	O
,	O
nothing	O
happens	O
at	O
all	O
.	O
let	O
us	O
now	O
create	O
a	O
for-	O
mula	O
from	O
this	O
colloquial	O
description	O
.	O
the	O
corresponding	O
terms	O
are	O
aﬃxed	O
with	O
a	O
(	O
t	O
)	O
to	O
show	O
that	O
everything	O
happens	O
at	O
the	O
same	O
time	O
step	O
.	O
this	O
might	O
decrease	O
clar-	O
ity	O
at	O
ﬁrst	O
glance	O
,	O
but	O
is	O
nevertheless	O
im-	O
portant	O
because	O
we	O
will	O
soon	O
look	O
at	O
an-	O
other	O
formula	O
that	O
operates	O
on	O
diﬀerent	O
time	O
steps	O
.	O
instead	O
,	O
we	O
shorten	O
the	O
gra-	O
dient	O
to	O
:	O
g	O
=	O
∂err	O
(	O
w	O
)	O
∂wi	O
,	O
j	O
.	O
gradient	B
determines	O
only	O
direction	O
of	O
the	O
updates	O
	O
∆wi	O
,	O
j	O
(	O
t	O
)	O
=	O
−ηi	O
,	O
j	O
(	O
t	O
)	O
,	O
+ηi	O
,	O
j	O
(	O
t	O
)	O
,	O
0	O
if	O
g	O
(	O
t	O
)	O
>	O
0	O
if	O
g	O
(	O
t	O
)	O
<	O
0	O
otherwise	O
.	O
(	O
5.44	O
)	O
we	O
now	O
know	O
how	O
the	O
weights	O
are	O
changed	O
–	O
now	O
remains	O
the	O
question	O
how	O
the	O
learn-	O
ing	O
rates	O
are	O
adjusted	O
.	O
finally	O
,	O
once	O
we	O
have	O
understood	O
the	O
overall	O
system	O
,	O
we	O
will	O
deal	O
with	O
the	O
remaining	O
details	O
like	O
ini-	O
tialization	O
and	O
some	O
speciﬁc	O
constants	O
.	O
5.5.2	O
many	O
dynamically	O
adjusted	O
learning	B
rates	O
instead	O
of	O
one	O
static	O
to	O
adjust	O
the	O
learning	B
rate	I
ηi	O
,	O
j	O
,	O
we	O
again	O
have	O
to	O
consider	O
the	O
associated	O
gradients	O
g	O
of	O
two	O
time	O
steps	O
:	O
the	O
gradient	B
that	O
has	O
just	O
passed	O
(	O
t	O
−	O
1	O
)	O
and	O
the	O
current	O
one	O
(	O
t	O
)	O
.	O
again	O
,	O
only	O
the	O
sign	O
of	O
the	O
gradient	B
matters	O
,	O
and	O
we	O
now	O
must	O
ask	O
ourselves	O
:	O
what	O
can	O
happen	O
to	O
the	O
sign	O
over	O
two	O
time	O
steps	O
?	O
it	O
can	O
stay	O
the	O
same	O
,	O
and	O
it	O
can	O
ﬂip	O
.	O
if	O
the	O
sign	O
changes	O
from	O
g	O
(	O
t	O
−	O
1	O
)	O
to	O
g	O
(	O
t	O
)	O
,	O
we	O
have	O
skipped	O
a	O
local	O
minimum	O
in	O
the	O
gradient	B
.	O
hence	O
,	O
the	O
last	O
update	O
was	O
too	O
large	O
and	O
ηi	O
,	O
j	O
(	O
t	O
)	O
has	O
to	O
be	O
reduced	O
as	O
com-	O
pared	O
to	O
the	O
previous	O
ηi	O
,	O
j	O
(	O
t	O
−	O
1	O
)	O
.	O
one	O
can	O
say	O
,	O
that	O
the	O
search	O
needs	O
to	O
be	O
more	O
accu-	O
rate	O
.	O
in	O
mathematical	O
terms	O
,	O
we	O
obtain	O
a	O
new	O
ηi	O
,	O
j	O
(	O
t	O
)	O
by	O
multiplying	O
the	O
old	O
ηi	O
,	O
j	O
(	O
t−1	O
)	O
with	O
a	O
constant	O
η↓	O
,	O
which	O
is	O
between	O
1	O
and	O
(	O
cid:74	O
)	O
η↓	O
0.	O
in	O
this	O
case	O
we	O
know	O
that	O
in	O
the	O
last	O
time	O
step	O
(	O
t	O
−	O
1	O
)	O
something	O
went	O
wrong	O
–	O
94	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
5.5	O
resilient	B
backpropagation	I
hence	O
we	O
additionally	O
reset	O
the	O
weight	B
up-	O
date	O
for	O
the	O
weight	B
wi	O
,	O
j	O
at	O
time	O
step	O
(	O
t	O
)	O
to	O
0	O
,	O
so	O
that	O
it	O
not	O
applied	O
at	O
all	O
(	O
not	O
shown	O
in	O
the	O
following	O
formula	O
)	O
.	O
however	O
,	O
if	O
the	O
sign	O
remains	O
the	O
same	O
,	O
one	O
can	O
perform	O
a	O
(	O
careful	O
!	O
)	O
increase	O
of	O
ηi	O
,	O
j	O
to	O
get	O
past	O
shallow	O
areas	O
of	O
the	O
error	B
function	I
.	O
here	O
we	O
obtain	O
our	O
new	O
ηi	O
,	O
j	O
(	O
t	O
)	O
by	O
multiply-	O
ing	O
the	O
old	O
ηi	O
,	O
j	O
(	O
t	O
−	O
1	O
)	O
with	O
a	O
constant	O
η↑	O
η↑	O
(	O
cid:73	O
)	O
which	O
is	O
greater	O
than	O
1.	O
deﬁnition	O
5.11	O
(	O
adaptation	O
of	O
learning	B
rates	O
in	O
rprop	O
)	O
.	O
g	O
(	O
t	O
−	O
1	O
)	O
g	O
(	O
t	O
)	O
>	O
0	O
g	O
(	O
t	O
−	O
1	O
)	O
g	O
(	O
t	O
)	O
<	O
0	O
otherwise	O
.	O
(	O
5.45	O
)	O
η↑ηi	O
,	O
j	O
(	O
t	O
−	O
1	O
)	O
,	O
η↓ηi	O
,	O
j	O
(	O
t	O
−	O
1	O
)	O
,	O
ηi	O
,	O
j	O
(	O
t	O
−	O
1	O
)	O
ηi	O
,	O
j	O
(	O
t	O
)	O
=	O
rprop	O
only	O
learns	O
oﬄine	O
caution	O
:	O
this	O
also	O
implies	O
that	O
rprop	O
is	O
exclusively	O
designed	O
for	O
oﬄine	O
.	O
if	O
the	O
gra-	O
dients	O
do	O
not	O
have	O
a	O
certain	O
continuity	O
,	O
the	O
learning	B
process	O
slows	O
down	O
to	O
the	O
lowest	O
rates	O
(	O
and	O
remains	O
there	O
)	O
.	O
when	O
learning	B
online	O
,	O
one	O
changes	O
–	O
loosely	O
speaking	O
–	O
the	O
error	B
function	I
with	O
each	O
new	O
epoch	B
,	O
since	O
it	O
is	O
based	O
on	O
only	O
one	O
training	O
pat-	O
tern	O
.	O
this	O
may	O
be	O
often	O
well	O
applicable	O
in	O
backpropagation	B
and	O
it	O
is	O
very	O
often	O
even	O
faster	O
than	O
the	O
oﬄine	O
version	O
,	O
which	O
is	O
why	O
it	O
is	O
used	O
there	O
frequently	O
.	O
it	O
lacks	O
,	O
however	O
,	O
a	O
clear	O
mathematical	O
motivation	O
,	O
and	O
that	O
is	O
exactly	O
what	O
we	O
need	O
here	O
.	O
(	O
cid:74	O
)	O
ηmin	O
(	O
cid:74	O
)	O
ηmax	O
5.5.3	O
we	O
are	O
still	O
missing	O
a	O
few	O
details	O
to	O
use	O
rprop	O
in	O
practice	O
a	O
few	O
minor	O
issues	O
remain	O
unanswered	O
,	O
namely	O
1.	O
how	O
large	O
are	O
η↑	O
and	O
η↓	O
(	O
i.e	O
.	O
how	O
much	O
are	O
learning	B
rates	O
reinforced	O
or	O
weakened	O
)	O
?	O
2.	O
how	O
to	O
choose	O
ηi	O
,	O
j	O
(	O
0	O
)	O
(	O
i.e	O
.	O
how	O
are	O
the	O
weight-speciﬁc	O
learning	B
rates	O
ini-	O
tialized	O
)	O
?	O
4	O
3.	O
what	O
are	O
the	O
upper	O
and	O
lower	O
bounds	O
ηmin	O
and	O
ηmax	O
for	O
ηi	O
,	O
j	O
set	O
?	O
we	O
now	O
answer	O
these	O
questions	O
with	O
a	O
quick	O
motivation	O
.	O
the	O
initial	O
value	O
for	O
the	O
learning	B
rates	O
should	O
be	O
somewhere	O
in	O
the	O
order	O
of	O
the	O
initialization	O
of	O
the	O
weights	O
.	O
ηi	O
,	O
j	O
(	O
0	O
)	O
=	O
0.1	O
has	O
proven	O
to	O
be	O
a	O
good	O
choice	O
.	O
the	O
authors	O
of	O
the	O
rprop	O
paper	O
explain	O
in	O
an	O
obvious	O
way	O
that	O
this	O
value	O
–	O
as	O
long	O
as	O
it	O
is	O
positive	O
and	O
without	O
an	O
ex-	O
orbitantly	O
high	O
absolute	O
value	O
–	O
does	O
not	O
need	O
to	O
be	O
dealt	O
with	O
very	O
critically	O
,	O
as	O
it	O
will	O
be	O
quickly	O
overridden	O
by	O
the	O
auto-	O
matic	O
adaptation	O
anyway	O
.	O
equally	O
uncritical	O
is	O
ηmax	O
,	O
for	O
which	O
they	O
recommend	O
,	O
without	O
further	O
mathemati-	O
cal	O
justiﬁcation	O
,	O
a	O
value	O
of	O
50	O
which	O
is	O
used	O
throughout	O
most	O
of	O
the	O
literature	O
.	O
one	O
can	O
set	O
this	O
parameter	O
to	O
lower	O
values	O
in	O
order	O
to	O
allow	O
only	O
very	O
cautious	O
updates	O
.	O
small	O
update	O
steps	O
should	O
be	O
allowed	O
in	O
any	O
case	O
,	O
so	O
we	O
set	O
ηmin	O
=	O
10−6	O
.	O
4	O
protipp	O
:	O
since	O
the	O
ηi	O
,	O
j	O
can	O
be	O
changed	O
only	O
by	O
multiplication	O
,	O
0	O
would	O
be	O
a	O
rather	O
suboptimal	O
ini-	O
tialization	O
:	O
-	O
)	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
95	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
now	O
we	O
have	O
left	O
only	O
the	O
parameters	O
η↑	O
and	O
η↓	O
.	O
let	O
us	O
start	O
with	O
η↓	O
:	O
if	O
this	O
value	O
is	O
used	O
,	O
we	O
have	O
skipped	O
a	O
minimum	O
,	O
from	O
which	O
we	O
do	O
not	O
know	O
where	O
exactly	O
it	O
lies	O
on	O
the	O
skipped	O
track	O
.	O
analogous	O
to	O
the	O
procedure	O
of	O
binary	O
search	O
,	O
where	O
the	O
tar-	O
get	O
object	O
is	O
often	O
skipped	O
as	O
well	O
,	O
we	O
as-	O
sume	O
it	O
was	O
in	O
the	O
middle	O
of	O
the	O
skipped	O
track	O
.	O
so	O
we	O
need	O
to	O
halve	O
the	O
learning	B
rate	I
,	O
which	O
is	O
why	O
the	O
canonical	O
choice	O
η↓	O
=	O
0.5	O
is	O
being	O
selected	O
.	O
if	O
the	O
value	O
of	O
η↑	O
is	O
used	O
,	O
learning	B
rates	O
shall	O
be	O
in-	O
creased	O
with	O
caution	O
.	O
here	O
we	O
can	O
not	O
gen-	O
eralize	O
the	O
principle	O
of	O
binary	O
search	O
and	O
simply	O
use	O
the	O
value	O
2.0	O
,	O
otherwise	O
the	O
learning	B
rate	I
update	O
will	O
end	O
up	O
consist-	O
ing	O
almost	O
exclusively	O
of	O
changes	O
in	O
direc-	O
tion	O
.	O
independent	O
of	O
the	O
particular	O
prob-	O
lems	O
,	O
a	O
value	O
of	O
η↑	O
=	O
1.2	O
has	O
proven	O
to	O
be	O
promising	O
.	O
slight	O
changes	O
of	O
this	O
value	O
have	O
not	O
signiﬁcantly	O
aﬀected	O
the	O
rate	O
of	O
convergence	O
.	O
this	O
fact	O
allowed	O
for	O
setting	O
this	O
value	O
as	O
a	O
constant	O
as	O
well	O
.	O
with	O
advancing	O
computational	O
capabili-	O
ties	O
of	O
computers	O
one	O
can	O
observe	O
a	O
more	O
and	O
more	O
widespread	O
distribution	O
of	O
net-	O
works	O
that	O
consist	O
of	O
a	O
big	O
number	O
of	O
lay-	O
ers	O
,	O
i.e	O
.	O
deep	B
networks	I
.	O
for	O
such	O
net-	O
works	O
it	O
is	O
crucial	O
to	O
prefer	O
rprop	O
over	O
the	O
original	O
backpropagation	B
,	O
because	O
back-	O
prop	O
,	O
as	O
already	O
indicated	O
,	O
learns	O
very	O
slowly	O
at	O
weights	O
wich	O
are	O
far	O
from	O
the	O
output	B
layer	I
.	O
for	O
problems	O
with	O
a	O
smaller	O
number	O
of	O
layers	O
,	O
i	O
would	O
recommend	O
test-	O
ing	O
the	O
more	O
widespread	O
backpropagation	B
(	O
with	O
both	O
oﬄine	O
and	O
online	B
learning	I
)	O
and	O
the	O
less	O
common	O
rprop	O
equivalently	O
.	O
in	O
snipe	O
resilient	O
backpropa-	O
snipe	O
:	O
gation	O
is	O
supported	O
via	O
the	O
method	O
trainresilientbackpropagation	O
of	O
the	O
class	O
neuralnetwork	O
.	O
furthermore	O
,	O
you	O
can	O
also	O
use	O
an	O
additional	O
improvement	B
to	O
resilient	O
propagation	O
,	O
which	O
is	O
,	O
however	O
,	O
not	O
dealt	O
with	O
in	O
this	O
work	O
.	O
there	O
are	O
get-	O
ters	O
and	O
setters	O
for	O
the	O
diﬀerent	O
parameters	O
of	O
rprop	O
.	O
5.6	O
backpropagation	B
has	O
often	O
been	O
extended	O
and	O
altered	O
besides	O
rprop	O
backpropagation	B
has	O
often	O
been	O
extended	O
.	O
many	O
of	O
these	O
extensions	O
can	O
simply	O
be	O
im-	O
plemented	O
as	O
optional	O
features	O
of	O
backpro-	O
pagation	O
in	O
order	O
to	O
have	O
a	O
larger	O
scope	O
for	O
testing	O
.	O
in	O
the	O
following	O
i	O
want	O
to	O
brieﬂy	O
describe	O
some	O
of	O
them	O
.	O
5.6.1	O
adding	O
momentum	B
to	O
learning	B
let	O
us	O
assume	O
to	O
descent	O
a	O
steep	O
slope	O
on	O
skis	O
-	O
what	O
prevents	O
us	O
from	O
immedi-	O
ately	O
stopping	O
at	O
the	O
edge	O
of	O
the	O
slope	O
to	O
the	O
plateau	O
?	O
exactly	O
-	O
our	O
momen-	O
tum	O
.	O
with	O
backpropagation	B
the	O
momen-	O
tum	O
term	O
[	O
rhw86b	O
]	O
is	O
responsible	O
for	O
the	O
fact	O
that	O
a	O
kind	O
of	O
moment	O
of	O
inertia	O
(	O
momentum	B
)	O
is	O
added	O
to	O
every	O
step	O
size	O
(	O
ﬁg	O
.	O
5.13	O
on	O
the	O
next	O
page	O
)	O
,	O
by	O
always	O
adding	O
a	O
fraction	O
of	O
the	O
previous	O
change	O
to	O
every	O
new	O
change	B
in	I
weight	I
:	O
(	O
∆pwi	O
,	O
j	O
)	O
now	O
=	O
ηop	O
,	O
iδp	O
,	O
j+α·	O
(	O
∆pwi	O
,	O
j	O
)	O
previous	O
.	O
96	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
rprop	O
is	O
very	O
good	O
for	O
deep	B
networks	I
dkriesel.com	O
5.6	O
further	O
variations	O
and	O
extensions	O
to	O
backpropagation	B
moment	O
of	O
inertia	O
α	O
(	O
cid:73	O
)	O
of	O
course	O
,	O
this	O
notation	O
is	O
only	O
used	O
for	O
a	O
better	O
understanding	O
.	O
generally	O
,	O
as	O
al-	O
ready	O
deﬁned	O
by	O
the	O
concept	O
of	O
time	O
,	O
when	O
referring	O
to	O
the	O
current	O
cycle	O
as	O
(	O
t	O
)	O
,	O
then	O
the	O
previous	O
cycle	O
is	O
identiﬁed	O
by	O
(	O
t	O
−	O
1	O
)	O
,	O
which	O
is	O
continued	O
successively	O
.	O
and	O
now	O
we	O
come	O
to	O
the	O
formal	O
deﬁnition	O
of	O
the	O
mo-	O
mentum	O
term	O
:	O
deﬁnition	O
5.12	O
(	O
momentum	B
term	I
)	O
.	O
the	O
variation	O
of	O
backpropagation	B
by	O
means	O
of	O
the	O
momentum	B
term	I
is	O
deﬁned	O
as	O
fol-	O
lows	O
:	O
∆wi	O
,	O
j	O
(	O
t	O
)	O
=	O
ηoiδj	O
+	O
α	O
·	O
∆wi	O
,	O
j	O
(	O
t	O
−	O
1	O
)	O
(	O
5.46	O
)	O
we	O
accelerate	O
on	O
plateaus	O
(	O
avoiding	O
quasi-	O
standstill	O
on	O
plateaus	O
)	O
and	O
slow	O
down	O
on	O
craggy	O
surfaces	O
(	O
preventing	O
oscillations	O
)	O
.	O
moreover	O
,	O
the	O
eﬀect	O
of	O
inertia	O
can	O
be	O
var-	O
ied	O
via	O
the	O
prefactor	O
α	O
,	O
common	O
val-	O
ues	O
are	O
between	O
0.6	O
und	O
0.9.	O
addition-	O
ally	O
,	O
the	O
momentum	B
enables	O
the	O
positive	O
eﬀect	O
that	O
our	O
skier	O
swings	O
back	O
and	O
forth	O
several	O
times	O
in	O
a	O
minimum	O
,	O
and	O
ﬁ-	O
nally	O
lands	O
in	O
the	O
minimum	O
.	O
despite	O
its	O
nice	O
one-dimensional	O
appearance	O
,	O
the	O
oth-	O
erwise	O
very	O
rare	O
error	O
of	O
leaving	O
good	O
min-	O
ima	O
unfortunately	O
occurs	O
more	O
frequently	O
because	O
of	O
the	O
momentum	B
term	I
–	O
which	O
means	O
that	O
this	O
is	O
again	O
no	O
optimal	O
solu-	O
tion	O
(	O
but	O
we	O
are	O
by	O
now	O
accustomed	O
to	O
this	O
condition	O
)	O
.	O
5.6.2	O
flat	B
spot	I
elimination	I
prevents	O
neurons	O
from	O
getting	O
stuck	O
it	O
must	O
be	O
pointed	O
out	O
that	O
with	O
the	O
hy-	O
perbolic	O
tangent	O
as	O
well	O
as	O
with	O
the	O
fermi	O
figure	O
5.13	O
:	O
we	O
want	O
to	O
execute	O
the	O
gradient	B
descent	I
like	O
a	O
skier	O
crossing	O
a	O
slope	O
,	O
who	O
would	O
hardly	O
stop	O
immediately	O
at	O
the	O
edge	O
to	O
the	O
plateau	O
.	O
neurons	O
get	O
stuck	O
function	B
the	O
derivative	O
outside	O
of	O
the	O
close	O
proximity	O
of	O
θ	O
is	O
nearly	O
0.	O
this	O
results	O
in	O
the	O
fact	O
that	O
it	O
becomes	O
very	O
diﬃcult	O
to	O
move	O
neurons	O
away	O
from	O
the	O
limits	O
of	O
the	O
activation	B
(	O
ﬂat	O
spots	O
)	O
,	O
which	O
could	O
ex-	O
tremely	O
extend	O
the	O
learning	B
time	O
.	O
this	O
problem	O
can	O
be	O
dealt	O
with	O
by	O
modifying	O
the	O
derivative	O
,	O
for	O
example	O
by	O
adding	O
a	O
constant	O
(	O
e.g	O
.	O
0.1	O
)	O
,	O
which	O
is	O
called	O
ﬂat	O
spot	O
elimination	O
or	O
–	O
more	O
colloquial	O
–	O
fudging	B
.	O
it	O
is	O
an	O
interesting	O
observation	O
,	O
that	O
suc-	O
cess	O
has	O
also	O
been	O
achieved	O
by	O
using	O
deriva-	O
tives	O
deﬁned	O
as	O
constants	O
[	O
fah88	O
]	O
.	O
a	O
nice	O
example	O
making	O
use	O
of	O
this	O
eﬀect	O
is	O
the	O
fast	O
hyperbolic	B
tangent	I
approximation	O
by	O
anguita	O
et	O
al	O
.	O
introduced	O
in	O
section	O
3.2.6	O
on	O
page	O
37.	O
in	O
the	O
outer	O
regions	O
of	O
it	O
’	O
s	O
(	O
as	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
97	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
well	O
approximated	O
and	O
accelerated	O
)	O
deriva-	O
tive	O
,	O
it	O
makes	O
use	O
of	O
a	O
small	O
constant	O
.	O
5.6.4	O
weight	B
decay	O
:	O
punishment	O
of	O
large	O
weights	O
5.6.3	O
the	O
second	O
derivative	O
can	O
be	O
used	O
,	O
too	O
according	O
to	O
david	O
parker	O
[	O
par87	O
]	O
,	O
second	B
order	I
backpropagation	I
also	O
us-	O
ese	O
the	O
second	O
gradient	O
,	O
i.e	O
.	O
the	O
second	O
multi-dimensional	O
derivative	O
of	O
the	O
error	B
function	I
,	O
to	O
obtain	O
more	O
precise	O
estimates	O
of	O
the	O
correct	O
∆wi	O
,	O
j	O
.	O
even	O
higher	O
deriva-	O
tives	O
only	O
rarely	O
improve	O
the	O
estimations	O
.	O
thus	O
,	O
less	O
training	O
cycles	O
are	O
needed	O
but	O
those	O
require	O
much	O
more	O
computational	O
ef-	O
fort	O
.	O
in	O
general	O
,	O
we	O
use	O
further	O
derivatives	O
(	O
i.e	O
.	O
hessian	O
matrices	O
,	O
since	O
the	O
functions	O
are	O
multidimensional	O
)	O
for	O
higher	O
order	O
meth-	O
ods	O
.	O
as	O
expected	O
,	O
the	O
procedures	O
reduce	O
the	O
number	O
of	O
learning	B
epochs	O
,	O
but	O
signiﬁ-	O
cantly	O
increase	O
the	O
computational	O
eﬀort	O
of	O
the	O
individual	O
epochs	O
.	O
so	O
in	O
the	O
end	O
these	O
procedures	O
often	O
need	O
more	O
learning	B
time	O
than	O
backpropagation	B
.	O
the	O
quickpropagation	B
learning	O
proce-	O
dure	O
[	O
fah88	O
]	O
uses	O
the	O
second	O
derivative	O
of	O
the	O
error	O
propagation	O
and	O
locally	O
under-	O
stands	O
the	O
error	B
function	I
to	O
be	O
a	O
parabola	O
.	O
we	O
analytically	O
determine	O
the	O
vertex	O
(	O
i.e	O
.	O
the	O
lowest	O
point	O
)	O
of	O
the	O
said	O
parabola	O
and	O
directly	O
jump	O
to	O
this	O
point	O
.	O
thus	O
,	O
this	O
learning	B
procedure	O
is	O
a	O
second-order	O
proce-	O
dure	O
.	O
of	O
course	O
,	O
this	O
does	O
not	O
work	O
with	O
error	O
surfaces	O
that	O
can	O
not	O
locally	O
be	O
ap-	O
proximated	O
by	O
a	O
parabola	O
(	O
certainly	O
it	O
is	O
not	O
always	O
possible	O
to	O
directly	O
say	O
whether	O
this	O
is	O
the	O
case	O
)	O
.	O
the	O
weight	B
decay	O
according	O
to	O
paul	O
werbos	O
[	O
wer88	O
]	O
is	O
a	O
modiﬁcation	O
that	O
ex-	O
tends	O
the	O
error	O
by	O
a	O
term	O
punishing	O
large	O
weights	O
.	O
so	O
the	O
error	O
under	O
weight	B
de-	O
cay	O
errwd	O
does	O
not	O
only	O
increase	O
proportionally	O
to	O
(	O
cid:74	O
)	O
errwd	O
the	O
actual	O
error	O
but	O
also	O
proportionally	O
to	O
the	O
square	O
of	O
the	O
weights	O
.	O
as	O
a	O
result	O
the	O
network	O
is	O
keeping	O
the	O
weights	O
small	O
dur-	O
ing	O
learning	B
.	O
errwd	O
=	O
err	O
+	O
β	O
·	O
1	O
|	O
2	O
x	O
{	O
z	O
w∈w	O
punishment	O
(	O
5.47	O
)	O
(	O
w	O
)	O
2	O
}	O
this	O
approach	O
is	O
inspired	O
by	O
nature	O
where	O
synaptic	O
weights	O
can	O
not	O
become	O
inﬁnitely	O
strong	O
as	O
well	O
.	O
additionally	O
,	O
due	O
to	O
these	O
small	O
weights	O
,	O
the	O
error	B
function	I
often	O
shows	O
weaker	O
ﬂuctuations	O
,	O
allowing	O
easier	O
and	O
more	O
controlled	O
learning	B
.	O
the	O
prefactor	O
1	O
2	O
again	O
resulted	O
from	O
sim-	O
ple	O
pragmatics	O
.	O
the	O
factor	O
β	O
controls	O
the	O
(	O
cid:74	O
)	O
β	O
strength	O
of	O
punishment	O
:	O
values	O
from	O
0.001	O
to	O
0.02	O
are	O
often	O
used	O
here	O
.	O
keep	O
weights	O
small	O
5.6.5	O
cutting	O
networks	O
down	O
:	O
pruning	B
and	O
optimal	B
brain	I
damage	I
if	O
we	O
have	O
executed	O
the	O
weight	B
decay	O
long	O
enough	O
and	O
notice	O
that	O
for	O
a	O
neuron	O
in	O
the	O
input	B
layer	I
all	O
successor	O
weights	O
are	O
0	O
or	O
close	O
to	O
0	O
,	O
we	O
can	O
remove	O
the	O
neuron	O
,	O
prune	O
the	O
network	O
98	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
5.7	O
initial	O
conﬁguration	O
of	O
a	O
multilayer	B
perceptron	I
hence	O
losing	O
this	O
neuron	O
and	O
some	O
weights	O
and	O
thereby	O
reduce	O
the	O
possibility	O
that	O
the	O
network	O
will	O
memorize	O
.	O
this	O
procedure	O
is	O
called	O
pruning	B
.	O
such	O
a	O
method	O
to	O
detect	O
and	O
delete	O
un-	O
necessary	O
weights	O
and	O
neurons	O
is	O
referred	O
to	O
as	O
optimal	B
brain	I
damage	I
[	O
lcds90	O
]	O
.	O
i	O
only	O
want	O
to	O
describe	O
it	O
brieﬂy	O
:	O
the	O
mean	O
error	O
per	O
output	O
neuron	O
is	O
composed	O
of	O
two	O
competing	O
terms	O
.	O
while	O
one	O
term	O
,	O
as	O
usual	O
,	O
considers	O
the	O
diﬀerence	O
between	O
output	O
and	O
teaching	B
input	I
,	O
the	O
other	O
one	O
tries	O
to	O
``	O
press	O
''	O
a	O
weight	B
towards	O
0.	O
if	O
a	O
weight	B
is	O
strongly	O
needed	O
to	O
minimize	O
the	O
error	O
,	O
the	O
ﬁrst	O
term	O
will	O
win	O
.	O
if	O
this	O
is	O
not	O
the	O
case	O
,	O
the	O
second	O
term	O
will	O
win	O
.	O
neu-	O
rons	O
which	O
only	O
have	O
zero	O
weights	O
can	O
be	O
pruned	O
again	O
in	O
the	O
end	O
.	O
there	O
are	O
many	O
other	O
variations	O
of	O
back-	O
prop	O
and	O
whole	O
books	O
only	O
about	O
this	O
subject	O
,	O
but	O
since	O
my	O
aim	O
is	O
to	O
oﬀer	O
an	O
overview	O
of	O
neural	O
networks	O
,	O
i	O
just	O
want	O
to	O
mention	O
the	O
variations	O
above	O
as	O
a	O
moti-	O
vation	O
to	O
read	O
on	O
.	O
for	O
some	O
of	O
these	O
extensions	O
it	O
is	O
obvi-	O
ous	O
that	O
they	O
can	O
not	O
only	O
be	O
applied	O
to	O
feedforward	B
networks	O
with	O
backpropaga-	O
tion	O
learning	B
procedures	O
.	O
we	O
have	O
gotten	O
to	O
know	O
backpropagation	B
and	O
feedforward	B
topology	O
–	O
now	O
we	O
have	O
to	O
learn	O
how	O
to	O
build	O
a	O
neural	O
network	O
.	O
it	O
is	O
of	O
course	O
impossible	O
to	O
fully	O
communi-	O
cate	O
this	O
experience	O
in	O
the	O
framework	O
of	O
this	O
work	O
.	O
to	O
obtain	O
at	O
least	O
some	O
of	O
this	O
knowledge	O
,	O
i	O
now	O
advise	O
you	O
to	O
deal	O
with	O
some	O
of	O
the	O
exemplary	O
problems	O
from	O
4.6	O
.	O
5.7	O
getting	O
started	O
–	O
initial	O
conﬁguration	O
of	O
a	O
multilayer	B
perceptron	I
after	O
having	O
discussed	O
the	O
backpropaga-	O
tion	O
of	O
error	O
learning	O
procedure	O
and	O
know-	O
ing	O
how	O
to	O
train	O
an	O
existing	O
network	O
,	O
it	O
would	O
be	O
useful	O
to	O
consider	O
how	O
to	O
imple-	O
ment	O
such	O
a	O
network	O
.	O
5.7.1	O
number	O
of	O
layers	O
:	O
two	O
or	O
three	O
may	O
often	O
do	O
the	O
job	O
,	O
but	O
more	O
are	O
also	O
used	O
let	O
us	O
begin	O
with	O
the	O
trivial	O
circumstance	O
that	O
a	O
network	O
should	O
have	O
one	O
layer	B
of	O
in-	O
put	O
neurons	O
and	O
one	O
layer	B
of	O
output	O
neu-	O
rons	O
,	O
which	O
results	O
in	O
at	O
least	O
two	O
layers	O
.	O
additionally	O
,	O
we	O
need	O
–	O
as	O
we	O
have	O
already	O
learned	O
during	O
the	O
examination	O
of	O
linear	B
separability	I
–	O
at	O
least	O
one	O
hidden	B
layer	I
of	O
neurons	O
,	O
if	O
our	O
problem	O
is	O
not	O
linearly	O
sep-	O
arable	O
(	O
which	O
is	O
,	O
as	O
we	O
have	O
seen	O
,	O
very	O
likely	O
)	O
.	O
it	O
is	O
possible	O
,	O
as	O
already	O
mentioned	O
,	O
to	O
mathematically	O
prove	O
that	O
this	O
mlp	O
with	O
one	O
hidden	O
neuron	O
layer	B
is	O
already	O
capable	O
of	O
approximating	O
arbitrary	O
functions	O
with	O
any	O
accuracy	O
5	O
–	O
but	O
it	O
is	O
necessary	O
not	O
only	O
to	O
discuss	O
the	O
representability	B
of	O
a	O
problem	O
by	O
means	O
of	O
a	O
perceptron	B
but	O
also	O
the	O
learnability	B
.	O
representability	B
means	O
that	O
a	O
perceptron	B
can	O
,	O
in	O
principle	O
,	O
realize	O
5	O
note	O
:	O
we	O
have	O
not	O
indicated	O
the	O
number	O
of	O
neu-	O
rons	O
in	O
the	O
hidden	B
layer	I
,	O
we	O
only	O
mentioned	O
the	O
hypothetical	O
possibility	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
99	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
a	O
mapping	O
-	O
but	O
learnability	B
means	O
that	O
we	O
are	O
also	O
able	O
to	O
teach	O
it	O
.	O
in	O
this	O
respect	O
,	O
experience	O
shows	O
that	O
two	O
hidden	O
neuron	O
layers	O
(	O
or	O
three	O
trainable	O
weight	B
layers	O
)	O
can	O
be	O
very	O
useful	O
to	O
solve	O
a	O
problem	O
,	O
since	O
many	O
problems	O
can	O
be	O
represented	O
by	O
a	O
hidden	B
layer	I
but	O
are	O
very	O
diﬃcult	O
to	O
learn	O
.	O
one	O
should	O
keep	O
in	O
mind	O
that	O
any	O
ad-	O
ditional	O
layer	B
generates	O
additional	O
sub-	O
minima	O
of	O
the	O
error	B
function	I
in	O
which	O
we	O
can	O
get	O
stuck	O
.	O
all	O
these	O
things	O
consid-	O
ered	O
,	O
a	O
promising	O
way	O
is	O
to	O
try	O
it	O
with	O
one	O
hidden	B
layer	I
at	O
ﬁrst	O
and	O
if	O
that	O
fails	O
,	O
retry	O
with	O
two	O
layers	O
.	O
only	O
if	O
that	O
fails	O
,	O
one	O
should	O
consider	O
more	O
layers	O
.	O
however	O
,	O
given	O
the	O
increasing	O
calculation	O
power	O
of	O
current	O
computers	O
,	O
deep	B
networks	I
with	O
a	O
lot	O
of	O
layers	O
are	O
also	O
used	O
with	O
success	O
.	O
5.7.2	O
the	O
number	O
of	O
neurons	O
has	O
to	O
be	O
tested	O
the	O
number	O
of	O
neurons	O
(	O
apart	O
from	O
input	O
and	O
output	B
layer	I
,	O
where	O
the	O
number	O
of	O
in-	O
put	O
and	O
output	O
neurons	O
is	O
already	O
deﬁned	O
by	O
the	O
problem	O
statement	O
)	O
principally	O
cor-	O
responds	O
to	O
the	O
number	O
of	O
free	O
parameters	O
of	O
the	O
problem	O
to	O
be	O
represented	O
.	O
since	O
we	O
have	O
already	O
discussed	O
the	O
net-	O
work	O
capacity	O
with	O
respect	O
to	O
memorizing	O
or	O
a	O
too	O
imprecise	O
problem	O
representation	O
,	O
it	O
is	O
clear	O
that	O
our	O
goal	O
is	O
to	O
have	O
as	O
few	O
free	O
parameters	O
as	O
possible	O
but	O
as	O
many	O
as	O
necessary	O
.	O
but	O
we	O
also	O
know	O
that	O
there	O
is	O
no	O
stan-	O
dard	O
solution	O
for	O
the	O
question	O
of	O
how	O
many	O
neurons	O
should	O
be	O
used	O
.	O
thus	O
,	O
the	O
most	O
useful	O
approach	O
is	O
to	O
initially	O
train	O
with	O
only	O
a	O
few	O
neurons	O
and	O
to	O
repeatedly	O
train	O
new	O
networks	O
with	O
more	O
neurons	O
until	O
the	O
result	O
signiﬁcantly	O
improves	O
and	O
,	O
particu-	O
larly	O
,	O
the	O
generalization	B
performance	O
is	O
not	O
aﬀected	O
(	O
bottom-up	B
approach	O
)	O
.	O
5.7.3	O
selecting	O
an	O
activation	B
function	I
another	O
very	O
important	O
parameter	O
for	O
the	O
way	O
of	O
information	O
processing	O
of	O
a	O
neural	O
network	O
is	O
the	O
selection	O
of	O
an	O
activa-	O
tion	O
function	B
.	O
the	O
activation	B
function	I
for	O
input	O
neurons	O
is	O
ﬁxed	O
to	O
the	O
identity	O
function	O
,	O
since	O
they	O
do	O
not	O
process	O
infor-	O
mation	O
.	O
the	O
ﬁrst	O
question	O
to	O
be	O
asked	O
is	O
whether	O
we	O
actually	O
want	O
to	O
use	O
the	O
same	O
acti-	O
vation	O
function	B
in	O
the	O
hidden	B
layer	I
and	O
in	O
the	O
ouput	O
layer	B
–	O
no	O
one	O
prevents	O
us	O
from	O
choosing	O
diﬀerent	O
functions	O
.	O
gener-	O
ally	O
,	O
the	O
activation	B
function	I
is	O
the	O
same	O
for	O
all	O
hidden	O
neurons	O
as	O
well	O
as	O
for	O
the	O
output	O
neurons	O
respectively	O
.	O
for	O
tasks	O
of	O
function	B
approximation	I
it	O
has	O
been	O
found	O
reasonable	O
to	O
use	O
the	O
hy-	O
perbolic	O
tangent	O
(	O
left	O
part	O
of	O
ﬁg	O
.	O
5.14	O
on	O
page	O
102	O
)	O
as	O
activation	B
function	I
of	O
the	O
hid-	O
den	O
neurons	O
,	O
while	O
a	O
linear	O
activation	O
func-	O
tion	O
is	O
used	O
in	O
the	O
output	O
.	O
the	O
latter	O
is	O
absolutely	O
necessary	O
so	O
that	O
we	O
do	O
not	O
gen-	O
erate	O
a	O
limited	O
output	O
intervall	O
.	O
contrary	O
to	O
the	O
input	B
layer	I
which	O
uses	O
linear	O
acti-	O
vation	O
functions	O
as	O
well	O
,	O
the	O
output	B
layer	I
still	O
processes	O
information	O
,	O
because	O
it	O
has	O
100	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
5.8	O
the	O
8-3-8	O
encoding	O
problem	O
and	O
related	O
problems	O
threshold	O
values	O
.	O
however	O
,	O
linear	O
activa-	O
tion	O
functions	O
in	O
the	O
output	O
can	O
also	O
cause	O
huge	O
learning	B
steps	O
and	O
jumping	O
over	O
good	O
minima	O
in	O
the	O
error	O
surface	O
.	O
this	O
can	O
be	O
avoided	O
by	O
setting	O
the	O
learning	B
rate	I
to	O
very	O
small	O
values	O
in	O
the	O
output	B
layer	I
.	O
an	O
unlimited	O
output	O
interval	O
is	O
not	O
essen-	O
tial	O
for	O
pattern	B
recognition	I
tasks6	O
.	O
if	O
the	O
hyperbolic	B
tangent	I
is	O
used	O
in	O
any	O
case	O
,	O
the	O
output	O
interval	O
will	O
be	O
a	O
bit	O
larger	O
.	O
un-	O
like	O
with	O
the	O
hyperbolic	B
tangent	I
,	O
with	O
the	O
fermi	O
function	B
(	O
right	O
part	O
of	O
ﬁg	O
.	O
5.14	O
on	O
the	O
following	O
page	O
)	O
it	O
is	O
diﬃcult	O
to	O
learn	O
something	O
far	O
from	O
the	O
threshold	B
value	I
(	O
where	O
its	O
result	O
is	O
close	O
to	O
0	O
)	O
.	O
however	O
,	O
here	O
a	O
lot	O
of	O
freedom	O
is	O
given	O
for	O
selecting	O
an	O
activation	B
function	I
.	O
but	O
generally	O
,	O
the	O
disadvantage	O
of	O
sigmoid	O
functions	O
is	O
the	O
fact	O
that	O
they	O
hardly	O
learn	O
something	O
for	O
values	O
far	O
from	O
thei	O
threshold	B
value	I
,	O
unless	O
the	O
network	O
is	O
modiﬁed	O
.	O
range	O
of	O
random	O
values	O
could	O
be	O
the	O
in-	O
terval	O
[	O
−0.5	O
;	O
0.5	O
]	O
not	O
including	O
0	O
or	O
values	O
very	O
close	O
to	O
0.	O
this	O
random	O
initialization	O
has	O
a	O
nice	O
side	O
eﬀect	O
:	O
chances	O
are	O
that	O
the	O
average	O
of	O
network	O
inputs	O
is	O
close	O
to	O
0	O
,	O
a	O
value	O
that	O
hits	O
(	O
in	O
most	O
activation	B
func-	O
tions	O
)	O
the	O
region	O
of	O
the	O
greatest	O
derivative	O
,	O
allowing	O
for	O
strong	O
learning	B
impulses	O
right	O
from	O
the	O
start	O
of	O
learning	B
.	O
a	O
in	O
snipe	O
,	O
weights	O
are	O
initial-	O
snipe	O
:	O
synapse	B
initial-	O
ized	O
randomly	O
(	O
if	O
the	O
maximum	O
ization	O
is	O
wanted	O
)	O
.	O
synapse	B
of	O
absolute	O
weight	B
value	O
initialized	O
at	O
set	O
in	O
a	O
neuralnetworkdescriptor	O
using	O
the	O
method	O
setsynapseinitialrange	O
.	O
a	O
random	O
can	O
be	O
5.8	O
the	O
8-3-8	O
encoding	O
problem	O
and	O
related	O
problems	O
5.7.4	O
weights	O
should	O
be	O
initialized	O
with	O
small	O
,	O
randomly	O
chosen	O
values	O
the	O
initialization	O
of	O
weights	O
is	O
not	O
as	O
triv-	O
ial	O
as	O
one	O
might	O
think	O
.	O
if	O
they	O
are	O
simply	O
initialized	O
with	O
0	O
,	O
there	O
will	O
be	O
no	O
change	O
in	O
weights	O
at	O
all	O
.	O
if	O
they	O
are	O
all	O
initialized	O
by	O
the	O
same	O
value	O
,	O
they	O
will	O
all	O
change	O
equally	O
during	O
training	O
.	O
the	O
simple	O
so-	O
lution	O
of	O
this	O
problem	O
is	O
called	O
symme-	O
try	O
breaking	O
,	O
which	O
is	O
the	O
initialization	O
of	O
weights	O
with	O
small	O
random	O
values	O
.	O
the	O
6	O
generally	O
,	O
pattern	B
recognition	I
is	O
understood	O
as	O
a	O
special	O
case	O
of	O
function	B
approximation	I
with	O
a	O
few	O
discrete	B
output	O
possibilities	O
.	O
the	O
8-3-8	O
encoding	O
problem	O
is	O
a	O
clas-	O
sic	O
among	O
the	O
multilayer	B
perceptron	I
test	O
training	O
problems	O
.	O
in	O
our	O
mlp	O
we	O
have	O
an	O
input	B
layer	I
with	O
eight	O
neurons	O
i1	O
,	O
i2	O
,	O
.	O
.	O
.	O
,	O
i8	O
,	O
an	O
output	B
layer	I
with	O
eight	O
neurons	O
ω1	O
,	O
ω2	O
,	O
.	O
.	O
.	O
,	O
ω8	O
and	O
one	O
hidden	B
layer	I
with	O
three	O
neurons	O
.	O
thus	O
,	O
this	O
net-	O
work	O
represents	O
a	O
function	B
b8	O
→	O
b8	O
.	O
now	O
the	O
training	O
task	O
is	O
that	O
an	O
input	O
of	O
a	O
value	O
1	O
into	O
the	O
neuron	O
ij	O
should	O
lead	O
to	O
an	O
out-	O
put	O
of	O
a	O
value	O
1	O
from	O
the	O
neuron	O
ωj	O
(	O
only	O
one	O
neuron	O
should	O
be	O
activated	O
,	O
which	O
re-	O
sults	O
in	O
8	O
training	O
samples	O
.	O
during	O
the	O
analysis	O
of	O
the	O
trained	O
network	O
we	O
will	O
see	O
that	O
the	O
network	O
with	O
the	O
3	O
random	O
initial	O
weights	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
101	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
figure	O
5.14	O
:	O
as	O
a	O
reminder	O
the	O
illustration	O
of	O
the	O
hyperbolic	B
tangent	I
(	O
left	O
)	O
and	O
the	O
fermi	O
function	B
(	O
right	O
)	O
.	O
the	O
fermi	O
function	B
was	O
expanded	O
by	O
a	O
temperature	O
parameter	O
.	O
the	O
original	O
fermi	O
function	B
is	O
thereby	O
represented	O
by	O
dark	O
colors	O
,	O
the	O
temperature	O
parameter	O
of	O
the	O
modiﬁed	O
fermi	O
functions	O
are	O
,	O
ordered	O
ascending	O
by	O
steepness	O
,	O
1	O
2	O
,	O
1	O
5	O
,	O
1	O
10	O
and	O
1	O
25.	O
hidden	O
neurons	O
represents	O
some	O
kind	O
of	O
bi-	O
nary	O
encoding	O
and	O
that	O
the	O
above	O
map-	O
ping	O
is	O
possible	O
(	O
assumed	O
training	O
time	O
:	O
≈	O
104	O
epochs	O
)	O
.	O
thus	O
,	O
our	O
network	O
is	O
a	O
ma-	O
chine	O
in	O
which	O
the	O
input	O
is	O
ﬁrst	O
encoded	O
and	O
afterwards	O
decoded	O
again	O
.	O
analogously	O
,	O
we	O
can	O
train	O
a	O
1024-10-1024	O
encoding	O
problem	O
.	O
but	O
is	O
it	O
possible	O
to	O
improve	O
the	O
eﬃciency	O
of	O
this	O
procedure	O
?	O
could	O
there	O
be	O
,	O
for	O
example	O
,	O
a	O
1024-9-	O
1024-	O
or	O
an	O
8-2-8-encoding	O
network	O
?	O
yes	O
,	O
even	O
that	O
is	O
possible	O
,	O
since	O
the	O
net-	O
work	O
does	O
not	O
depend	O
on	O
binary	O
encodings	O
:	O
thus	O
,	O
an	O
8-2-8	O
network	O
is	O
suﬃcient	O
for	O
our	O
problem	O
.	O
but	O
the	O
encoding	O
of	O
the	O
network	O
is	O
far	O
more	O
diﬃcult	O
to	O
understand	O
(	O
ﬁg	O
.	O
5.15	O
on	O
the	O
next	O
page	O
)	O
and	O
the	O
training	O
of	O
the	O
networks	O
requires	O
a	O
lot	O
more	O
time	O
.	O
the	O
static	O
method	O
snipe	O
:	O
getencodersamplelesson	O
in	O
the	O
class	O
trainingsamplelesson	O
allows	O
for	O
creating	O
simple	O
training	O
sample	O
lessons	O
of	O
arbitrary	O
dimensionality	O
for	O
encoder	O
problems	O
like	O
the	O
above	O
.	O
an	O
8-1-8	O
network	O
,	O
however	O
,	O
does	O
not	O
work	O
,	O
since	O
the	O
possibility	O
that	O
the	O
output	O
of	O
one	O
neuron	O
is	O
compensated	O
by	O
another	O
one	O
is	O
essential	O
,	O
and	O
if	O
there	O
is	O
only	O
one	O
hidden	O
neuron	O
,	O
there	O
is	O
certainly	O
no	O
compensatory	O
neuron	O
.	O
exercises	O
exercise	O
8.	O
fig	O
.	O
5.4	O
on	O
page	O
75	O
shows	O
a	O
small	O
network	O
for	O
the	O
boolean	O
functions	O
and	O
and	O
or	O
.	O
write	O
tables	O
with	O
all	O
computa-	O
tional	O
parameters	O
of	O
neural	O
networks	O
(	O
e.g	O
.	O
network	B
input	I
,	O
activation	B
etc.	O
)	O
.	O
perform	O
the	O
calculations	O
for	O
the	O
four	O
possible	O
in-	O
puts	O
of	O
the	O
networks	O
and	O
write	O
down	O
the	O
values	O
of	O
these	O
variables	O
for	O
each	O
input	O
.	O
do	O
the	O
same	O
for	O
the	O
xor	O
network	O
(	O
ﬁg	O
.	O
5.9	O
on	O
page	O
84	O
)	O
.	O
102	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
−1−0.8−0.6−0.4−0.2	O
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1−4−2	O
0	O
2	O
4tanh	O
(	O
x	O
)	O
xhyperbolic	O
tangent	O
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1−4−2	O
0	O
2	O
4f	O
(	O
x	O
)	O
xfermi	O
function	B
with	O
temperature	O
parameter	O
dkriesel.com	O
5.8	O
the	O
8-3-8	O
encoding	O
problem	O
and	O
related	O
problems	O
exercise	O
9	O
.	O
1.	O
list	O
all	O
boolean	O
functions	O
b3	O
→	O
b1	O
,	O
that	O
are	O
linearly	O
separable	O
and	O
char-	O
acterize	O
them	O
exactly	O
.	O
2.	O
list	O
those	O
that	O
are	O
not	O
linearly	O
sepa-	O
rable	O
and	O
characterize	O
them	O
exactly	O
,	O
too	O
.	O
exercise	O
10.	O
a	O
simple	O
2-1	O
network	O
shall	O
be	O
trained	O
with	O
one	O
single	O
pattern	O
by	O
means	O
of	O
backpropagation	B
of	I
error	I
and	O
η	O
=	O
0.1.	O
verify	O
if	O
the	O
error	O
err	O
=	O
errp	O
=	O
1	O
2	O
(	O
t	O
−	O
y	O
)	O
2	O
converges	O
and	O
if	O
so	O
,	O
at	O
what	O
value	O
.	O
how	O
does	O
the	O
error	O
curve	O
look	O
like	O
?	O
let	O
the	O
pattern	B
(	O
p	O
,	O
t	O
)	O
be	O
deﬁned	O
by	O
p	O
=	O
(	O
p1	O
,	O
p2	O
)	O
=	O
(	O
0.3	O
,	O
0.7	O
)	O
and	O
tω	O
=	O
0.4.	O
randomly	O
initalize	O
the	O
weights	O
in	O
the	O
interval	O
[	O
1	O
;	O
−1	O
]	O
.	O
exercise	O
11.	O
a	O
one-stage	O
perceptron	B
with	O
two	O
input	O
neurons	O
,	O
bias	B
neuron	I
and	O
binary	B
threshold	I
function	I
as	O
activa-	O
tion	O
function	B
divides	O
the	O
two-dimensional	O
space	O
into	O
two	O
regions	O
by	O
means	O
of	O
a	O
straight	O
line	O
g.	O
analytically	O
calculate	O
a	O
set	O
of	O
weight	O
values	O
for	O
such	O
a	O
perceptron	B
so	O
that	O
the	O
following	O
set	O
p	O
of	O
the	O
6	O
pat-	O
terns	O
of	O
the	O
form	O
(	O
p1	O
,	O
p2	O
,	O
tω	O
)	O
with	O
ε	O
(	O
cid:28	O
)	O
1	O
is	O
correctly	O
classiﬁed	O
.	O
p	O
=	O
{	O
(	O
0	O
,	O
0	O
,	O
−1	O
)	O
;	O
(	O
2	O
,	O
−1	O
,	O
1	O
)	O
;	O
(	O
7	O
+	O
ε	O
,	O
3	O
−	O
ε	O
,	O
1	O
)	O
;	O
(	O
7	O
−	O
ε	O
,	O
3	O
+	O
ε	O
,	O
−1	O
)	O
;	O
(	O
0	O
,	O
−2	O
−	O
ε	O
,	O
1	O
)	O
;	O
(	O
0	O
−	O
ε	O
,	O
−2	O
,	O
−1	O
)	O
}	O
figure	O
5.15	O
:	O
illustration	O
of	O
the	O
functionality	O
of	O
8-2-8	O
network	O
encoding	O
.	O
the	O
marked	O
points	O
rep-	O
resent	O
the	O
vectors	O
of	O
the	O
inner	O
neuron	O
activation	O
associated	O
to	O
the	O
samples	O
.	O
as	O
you	O
can	O
see	O
,	O
it	O
is	O
possible	O
to	O
ﬁnd	O
inner	O
activation	B
formations	O
so	O
that	O
each	O
point	O
can	O
be	O
separated	O
from	O
the	O
rest	O
of	O
the	O
points	O
by	O
a	O
straight	O
line	O
.	O
the	O
illustration	O
shows	O
an	O
exemplary	O
separation	O
of	O
one	O
point	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
103	O
chapter	O
5	O
the	O
perceptron	B
,	O
backpropagation	B
and	O
its	O
variants	O
dkriesel.com	O
exercise	O
12.	O
calculate	O
in	O
a	O
comprehen-	O
sible	O
way	O
one	O
vector	O
∆w	O
of	O
all	O
changes	O
in	O
weight	B
by	O
means	O
of	O
the	O
backpropagation	B
of	I
error	I
procedure	O
with	O
η	O
=	O
1.	O
let	O
a	O
2-2-1	O
mlp	O
with	O
bias	B
neuron	I
be	O
given	O
and	O
let	O
the	O
pattern	B
be	O
deﬁned	O
by	O
p	O
=	O
(	O
p1	O
,	O
p2	O
,	O
tω	O
)	O
=	O
(	O
2	O
,	O
0	O
,	O
0.1	O
)	O
.	O
for	O
all	O
weights	O
with	O
the	O
target	B
ω	O
the	O
ini-	O
tial	O
value	O
of	O
the	O
weights	O
should	O
be	O
1.	O
for	O
all	O
other	O
weights	O
the	O
initial	O
value	O
should	O
be	O
0.5.	O
what	O
is	O
conspicuous	O
about	O
the	O
changes	O
?	O
104	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
chapter	O
6	O
radial	O
basis	B
functions	O
rbf	O
networks	O
approximate	O
functions	O
by	O
stretching	O
and	O
compressing	O
gaussian	O
bells	O
and	O
then	O
summing	O
them	O
spatially	O
shifted	O
.	O
description	O
of	O
their	O
functions	O
and	O
their	O
learning	B
process	O
.	O
comparison	O
with	O
multilayer	O
perceptrons	O
.	O
according	O
to	O
poggio	O
and	O
girosi	O
[	O
pg89	O
]	O
radial	O
basis	B
function	O
networks	O
(	O
rbf	O
net-	O
works	O
)	O
are	O
a	O
paradigm	O
of	O
neural	O
networks	O
,	O
which	O
was	O
developed	O
considerably	O
later	O
than	O
that	O
of	O
perceptrons	O
.	O
like	O
percep-	O
trons	O
,	O
the	O
rbf	O
networks	O
are	O
built	O
in	O
layers	O
.	O
but	O
in	O
this	O
case	O
,	O
they	O
have	O
exactly	O
three	O
layers	O
,	O
i.e	O
.	O
only	O
one	O
single	O
layer	O
of	O
hidden	O
neurons	O
.	O
like	O
perceptrons	O
,	O
the	O
networks	O
have	O
a	O
feedforward	B
structure	O
and	O
their	O
layers	O
are	O
completely	O
linked	O
.	O
here	O
,	O
the	O
input	B
layer	I
again	O
does	O
not	O
participate	O
in	O
information	O
processing	O
.	O
the	O
rbf	O
networks	O
are	O
-	O
like	O
mlps	O
-	O
universal	O
function	B
approxima-	O
tors	O
.	O
despite	O
all	O
things	O
in	O
common	O
:	O
what	O
is	O
the	O
diﬀerence	O
between	O
rbf	O
networks	O
and	O
per-	O
ceptrons	O
?	O
the	O
diﬀerence	O
lies	O
in	O
the	O
infor-	O
mation	O
processing	O
itself	O
and	O
in	O
the	O
compu-	O
tational	O
rules	O
within	O
the	O
neurons	O
outside	O
of	O
the	O
input	B
layer	I
.	O
so	O
,	O
in	O
a	O
moment	O
we	O
will	O
deﬁne	O
a	O
so	O
far	O
unknown	O
type	O
of	O
neu-	O
rons	O
.	O
6.1	O
components	O
and	O
structure	O
of	O
an	O
rbf	O
network	O
initially	O
,	O
we	O
want	O
to	O
discuss	O
colloquially	O
and	O
then	O
deﬁne	O
some	O
concepts	O
concerning	O
rbf	O
networks	O
.	O
output	O
neurons	O
:	O
in	O
an	O
rbf	O
network	O
the	O
output	O
neurons	O
only	O
contain	O
the	O
iden-	O
tity	O
as	O
activation	B
function	I
and	O
one	O
weighted	B
sum	I
as	O
propagation	O
func-	O
tion	O
.	O
thus	O
,	O
they	O
do	O
little	O
more	O
than	O
adding	O
all	O
input	O
values	O
and	O
returning	O
the	O
sum	O
.	O
hidden	O
neurons	O
are	O
also	O
called	O
rbf	O
neu-	O
rons	O
(	O
as	O
well	O
as	O
the	O
layer	B
in	O
which	O
they	O
are	O
located	O
is	O
referred	O
to	O
as	O
rbf	O
layer	B
)	O
.	O
as	O
propagation	B
function	I
,	O
each	O
hidden	O
neuron	O
calculates	O
a	O
norm	O
that	O
represents	O
the	O
distance	O
between	O
the	O
input	O
to	O
the	O
network	O
and	O
the	O
so-called	O
position	O
of	O
the	O
neuron	O
(	O
center	O
)	O
.	O
this	O
is	O
inserted	O
into	O
a	O
radial	O
activation	B
105	O
input	O
is	O
linear	O
again	O
c	O
(	O
cid:73	O
)	O
position	O
in	O
the	O
input	O
space	O
important	O
!	O
only	O
sums	O
up	O
chapter	O
6	O
radial	O
basis	B
functions	O
dkriesel.com	O
function	B
which	O
calculates	O
and	O
outputs	O
the	O
activation	B
of	O
the	O
neuron	O
.	O
deﬁnition	O
6.1	O
(	O
rbf	O
input	B
neuron	I
)	O
.	O
def-	O
inition	O
and	O
representation	O
is	O
identical	O
to	O
the	O
deﬁnition	O
5.1	O
on	O
page	O
73	O
of	O
the	O
input	B
neuron	I
.	O
deﬁnition	O
6.2	O
(	O
center	O
of	O
an	O
rbf	O
neu-	O
ron	O
)	O
.	O
the	O
center	O
ch	O
of	O
an	O
rbf	O
neuron	O
h	O
is	O
the	O
point	O
in	O
the	O
input	O
space	O
where	O
the	O
rbf	O
neuron	O
is	O
located	O
.	O
in	O
general	O
,	O
the	O
closer	O
the	O
input	B
vector	I
is	O
to	O
the	O
center	O
vector	O
of	O
an	O
rbf	O
neuron	O
,	O
the	O
higher	O
is	O
its	O
activation	B
.	O
deﬁnition	O
6.3	O
(	O
rbf	O
neuron	O
)	O
.	O
the	O
so-	O
called	O
rbf	O
neurons	O
h	O
have	O
a	O
propaga-	O
tion	O
function	B
fprop	O
that	O
determines	O
the	O
dis-	O
tance	O
between	O
the	O
center	O
ch	O
of	O
a	O
neuron	O
and	O
the	O
input	B
vector	I
y.	O
this	O
distance	O
rep-	O
resents	O
the	O
network	B
input	I
.	O
then	O
the	O
net-	O
work	O
input	O
is	O
sent	O
through	O
a	O
radial	O
basis	B
function	O
fact	O
which	O
returns	O
the	O
activation	B
or	O
the	O
output	O
of	O
the	O
neuron	O
.	O
rbf	O
neurons	O
are	O
represented	O
by	O
the	O
symbol	O
wvut	O
pqrs	O
deﬁnition	O
6.4	O
(	O
rbf	O
output	O
neuron	O
)	O
.	O
rbf	O
output	O
neurons	O
ω	O
use	O
the	O
weighted	B
sum	I
as	O
propagation	B
function	I
fprop	O
,	O
and	O
the	O
identity	O
as	O
activation	B
func-	O
tion	O
fact	O
.	O
they	O
are	O
represented	O
by	O
the	O
sym-	O
||c	O
,	O
x||	O
gauß	O
.	O
bolonml	O
hijkς	O
(	O
cid:30	O
)	O
.	O
deﬁnition	O
6.5	O
(	O
rbf	O
network	O
)	O
.	O
an	O
rbf	O
network	O
has	O
exactly	O
three	O
layers	O
in	O
the	O
following	O
order	O
:	O
the	O
input	B
layer	I
con-	O
sisting	O
of	O
input	O
neurons	O
,	O
the	O
hidden	B
layer	I
(	O
also	O
called	O
rbf	O
layer	B
)	O
consisting	O
of	O
rbf	O
neurons	O
and	O
the	O
output	B
layer	I
consisting	O
of	O
3	O
layers	O
,	O
feedforward	B
rbf	O
output	O
neurons	O
.	O
each	O
layer	B
is	O
com-	O
pletely	O
linked	O
with	O
the	O
following	O
one	O
,	O
short-	O
cuts	O
do	O
not	O
exist	O
(	O
ﬁg	O
.	O
6.1	O
on	O
the	O
next	O
page	O
)	O
–	O
it	O
is	O
a	O
feedforward	B
topology	O
.	O
the	O
connec-	O
tions	O
between	O
input	B
layer	I
and	O
rbf	O
layer	B
are	O
unweighted	O
,	O
i.e	O
.	O
they	O
only	O
transmit	O
the	O
input	O
.	O
the	O
connections	O
between	O
rbf	O
layer	B
and	O
output	B
layer	I
are	O
weighted	O
.	O
the	O
original	O
deﬁnition	O
of	O
an	O
rbf	O
network	O
only	O
referred	O
to	O
an	O
output	O
neuron	O
,	O
but	O
–	O
in	O
anal-	O
ogy	O
to	O
the	O
perceptrons	O
–	O
it	O
is	O
apparent	O
that	O
such	O
a	O
deﬁnition	O
can	O
be	O
generalized	O
.	O
a	O
bias	B
neuron	I
is	O
not	O
used	O
in	O
rbf	O
networks	O
.	O
the	O
set	O
of	O
input	O
neurons	O
shall	O
be	O
repre-	O
sented	O
by	O
i	O
,	O
the	O
set	O
of	O
hidden	O
neurons	O
by	O
(	O
cid:74	O
)	O
i	O
,	O
h	O
,	O
o	O
h	O
and	O
the	O
set	O
of	O
output	O
neurons	O
by	O
o.	O
therefore	O
,	O
the	O
inner	O
neurons	O
are	O
called	O
ra-	O
dial	O
basis	B
neurons	O
because	O
from	O
their	O
def-	O
inition	O
follows	O
directly	O
that	O
all	O
input	O
vec-	O
tors	O
with	O
the	O
same	O
distance	O
from	O
the	O
cen-	O
ter	O
of	O
a	O
neuron	O
also	O
produce	O
the	O
same	O
out-	O
put	O
value	O
(	O
ﬁg	O
.	O
6.2	O
on	O
page	O
108	O
)	O
.	O
6.2	O
information	O
processing	O
of	O
an	O
rbf	O
network	O
now	O
the	O
question	O
is	O
,	O
what	O
can	O
be	O
realized	O
by	O
such	O
a	O
network	O
and	O
what	O
is	O
its	O
purpose	O
.	O
let	O
us	O
go	O
over	O
the	O
rbf	O
network	O
from	O
top	O
to	O
bottom	O
:	O
an	O
rbf	O
network	O
receives	O
the	O
input	O
by	O
means	O
of	O
the	O
unweighted	O
con-	O
nections	O
.	O
then	O
the	O
input	B
vector	I
is	O
sent	O
through	O
a	O
norm	O
so	O
that	O
the	O
result	O
is	O
a	O
scalar	O
.	O
this	O
scalar	O
(	O
which	O
,	O
by	O
the	O
way	O
,	O
can	O
only	O
be	O
positive	O
due	O
to	O
the	O
norm	O
)	O
is	O
pro-	O
cessed	O
by	O
a	O
radial	O
basis	B
function	O
,	O
for	O
exam-	O
106	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
6.2	O
information	O
processing	O
of	O
an	O
rbf	O
network	O
||c	O
,	O
x||	O
gauß	O
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
gfed	O
@	O
abc	O
(	O
cid:30	O
)	O
+vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv	O
(	O
rrrrrrrrrrrrrrrrrrrr	O
shhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh	O
vllllllllllllllllllll	O
''	O
eeeeeeeeee	O
''	O
eeeeeeeeee	O
|yyyyyyyyyy	O
|yyyyyyyyyy	O
wvut	O
pqrs	O
wvut	O
pqrs	O
wvut	O
pqrs	O
wvut	O
pqrs	O
wvut	O
pqrs	O
*vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv	O
thhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh	O
(	O
qqqqqqqqqqqqqqqqqqqq	O
(	O
qqqqqqqqqqqqqqqqqqqq	O
vmmmmmmmmmmmmmmmmmmmm	O
vmmmmmmmmmmmmmmmmmmmm	O
!	O
cccccccccc	O
!	O
cccccccccc	O
!	O
cccccccccc	O
}	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
}	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
}	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
{	O
onml	O
hijkς	O
onml	O
hijkς	O
onml	O
hijkς	O
||c	O
,	O
x||	O
gauß	O
||c	O
,	O
x||	O
gauß	O
(	O
cid:30	O
)	O
(	O
cid:30	O
)	O
(	O
cid:30	O
)	O
||c	O
,	O
x||	O
gauß	O
||c	O
,	O
x||	O
gauß	O
i1	O
,	O
i2	O
,	O
.	O
.	O
.	O
,	O
i|i|	O
h1	O
,	O
h2	O
,	O
.	O
.	O
.	O
,	O
h|h|	O
ω1	O
,	O
ω2	O
,	O
.	O
.	O
.	O
,	O
ω|o|	O
figure	O
6.1	O
:	O
an	O
exemplary	O
rbf	O
network	O
with	O
two	O
input	O
neurons	O
,	O
ﬁve	O
hidden	O
neurons	O
and	O
three	O
output	O
neurons	O
.	O
the	O
connections	O
to	O
the	O
hidden	O
neurons	O
are	O
not	O
weighted	O
,	O
they	O
only	O
transmit	O
the	O
input	O
.	O
right	O
of	O
the	O
illustration	O
you	O
can	O
ﬁnd	O
the	O
names	O
of	O
the	O
neurons	O
,	O
which	O
coincide	O
with	O
the	O
names	O
of	O
the	O
mlp	O
neurons	O
:	O
input	O
neurons	O
are	O
called	O
i	O
,	O
hidden	O
neurons	O
are	O
called	O
h	O
and	O
output	O
neurons	O
are	O
called	O
ω.	O
the	O
associated	O
sets	O
are	O
referred	O
to	O
as	O
i	O
,	O
h	O
and	O
o.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
107	O
	O
	O
	O
	O
|	O
	O
	O
''	O
(	O
+	O
''	O
	O
	O
|	O
v	O
s	O
!	O
(	O
*	O
	O
	O
!	O
(	O
}	O
	O
	O
!	O
v	O
}	O
	O
	O
t	O
v	O
}	O
	O
	O
	O
	O
	O
	O
chapter	O
6	O
radial	O
basis	B
functions	O
dkriesel.com	O
ging	O
,	O
compressing	O
and	O
removing	O
gaussian	O
bells	O
and	O
subsequently	O
accumulating	O
them	O
.	O
here	O
,	O
the	O
parameters	O
for	O
the	O
superposition	O
of	O
the	O
gaussian	O
bells	O
are	O
in	O
the	O
weights	O
of	O
the	O
connections	O
between	O
the	O
rbf	O
layer	B
and	O
the	O
output	B
layer	I
.	O
furthermore	O
,	O
the	O
network	O
architecture	O
of-	O
fers	O
the	O
possibility	O
to	O
freely	O
deﬁne	O
or	O
train	O
height	O
and	O
width	O
of	O
the	O
gaussian	O
bells	O
–	O
due	O
to	O
which	O
the	O
network	O
paradigm	O
be-	O
comes	O
even	O
more	O
versatile	O
.	O
we	O
will	O
get	O
to	O
know	O
methods	O
and	O
approches	O
for	O
this	O
later	O
.	O
input	O
→	O
distance	O
→	O
gaussian	O
bell	O
→	O
sum	O
→	O
output	O
figure	O
6.2	O
:	O
let	O
ch	O
be	O
the	O
center	O
of	O
an	O
rbf	O
neu-	O
ron	O
h.	O
then	O
the	O
activation	B
function	I
facth	O
is	O
ra-	O
dially	O
symmetric	O
around	O
ch	O
.	O
6.2.1	O
information	O
processing	O
in	O
rbf	O
neurons	O
ple	O
by	O
a	O
gaussian	O
bell	O
(	O
ﬁg	O
.	O
6.3	O
on	O
the	O
next	O
page	O
)	O
.	O
the	O
output	O
values	O
of	O
the	O
diﬀerent	O
neurons	O
of	O
the	O
rbf	O
layer	B
or	O
of	O
the	O
diﬀerent	O
gaus-	O
sian	O
bells	O
are	O
added	O
within	O
the	O
third	O
layer	B
:	O
basically	O
,	O
in	O
relation	O
to	O
the	O
whole	O
input	O
space	O
,	O
gaussian	O
bells	O
are	O
added	O
here	O
.	O
suppose	O
that	O
we	O
have	O
a	O
second	O
,	O
a	O
third	O
and	O
a	O
fourth	O
rbf	O
neuron	O
and	O
therefore	O
four	O
diﬀerently	O
located	O
centers	O
.	O
each	O
of	O
these	O
neurons	O
now	O
measures	O
another	O
dis-	O
tance	O
from	O
the	O
input	O
to	O
its	O
own	O
center	O
and	O
de	O
facto	O
provides	O
diﬀerent	O
values	O
,	O
even	O
if	O
the	O
gaussian	O
bell	O
is	O
the	O
same	O
.	O
since	O
these	O
values	O
are	O
ﬁnally	O
simply	O
accumu-	O
lated	O
in	O
the	O
output	B
layer	I
,	O
one	O
can	O
easily	O
see	O
that	O
any	O
surface	O
can	O
be	O
shaped	O
by	O
drag-	O
rbf	O
neurons	O
process	O
information	O
by	O
using	O
norms	O
and	O
radial	O
basis	B
functions	O
at	O
ﬁrst	O
,	O
let	O
us	O
take	O
as	O
an	O
example	O
a	O
sim-	O
ple	O
1-4-1	O
rbf	O
network	O
.	O
it	O
is	O
apparent	O
that	O
we	O
will	O
receive	O
a	O
one-dimensional	O
out-	O
put	O
which	O
can	O
be	O
represented	O
as	O
a	O
func-	O
tion	O
(	O
ﬁg	O
.	O
6.4	O
on	O
the	O
facing	O
page	O
)	O
.	O
ad-	O
ditionally	O
,	O
the	O
network	O
includes	O
the	O
cen-	O
ters	O
c1	O
,	O
c2	O
,	O
.	O
.	O
.	O
,	O
c4	O
of	O
the	O
four	O
inner	O
neurons	O
h1	O
,	O
h2	O
,	O
.	O
.	O
.	O
,	O
h4	O
,	O
and	O
therefore	O
it	O
has	O
gaus-	O
sian	O
bells	O
which	O
are	O
ﬁnally	O
added	O
within	O
the	O
output	O
neuron	O
ω.	O
the	O
network	O
also	O
possesses	O
four	O
values	O
σ1	O
,	O
σ2	O
,	O
.	O
.	O
.	O
,	O
σ4	O
which	O
inﬂuence	O
the	O
width	O
of	O
the	O
gaussian	O
bells	O
.	O
on	O
the	O
contrary	O
,	O
the	O
height	O
of	O
the	O
gaus-	O
sian	O
bell	O
is	O
inﬂuenced	O
by	O
the	O
subsequent	O
weights	O
,	O
since	O
the	O
individual	O
output	O
val-	O
ues	O
of	O
the	O
bells	O
are	O
multiplied	O
by	O
those	O
weights	O
.	O
108	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
6.2	O
information	O
processing	O
of	O
an	O
rbf	O
network	O
figure	O
6.3	O
:	O
two	O
individual	O
one-	O
or	O
two-dimensional	O
gaussian	O
bells	O
.	O
in	O
both	O
cases	O
σ	O
=	O
0.4	O
holds	O
and	O
the	O
centers	O
of	O
the	O
gaussian	O
bells	O
lie	O
in	O
the	O
coordinate	O
origin	O
.	O
the	O
distance	O
r	O
to	O
the	O
center	O
(	O
0	O
,	O
0	O
)	O
is	O
simply	O
calculated	O
according	O
to	O
the	O
pythagorean	O
theorem	O
:	O
r	O
=p	O
x2	O
+	O
y2	O
.	O
figure	O
6.4	O
:	O
four	O
diﬀerent	O
gaussian	O
bells	O
in	O
one-dimensional	O
space	O
generated	O
by	O
means	O
of	O
rbf	O
neurons	O
are	O
added	O
by	O
an	O
output	O
neuron	O
of	O
the	O
rbf	O
network	O
.	O
the	O
gaussian	O
bells	O
have	O
diﬀerent	O
heights	O
,	O
widths	O
and	O
positions	O
.	O
their	O
centers	O
c1	O
,	O
c2	O
,	O
.	O
.	O
.	O
,	O
c4	O
are	O
located	O
at	O
0	O
,	O
1	O
,	O
3	O
,	O
4	O
,	O
the	O
widths	O
σ1	O
,	O
σ2	O
,	O
.	O
.	O
.	O
,	O
σ4	O
at	O
0.4	O
,	O
1	O
,	O
0.2	O
,	O
0.8.	O
you	O
can	O
see	O
a	O
two-dimensional	O
example	O
in	O
ﬁg	O
.	O
6.5	O
on	O
the	O
following	O
page	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
109	O
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1−2−1.5−1−0.5	O
0	O
0.5	O
1	O
1.5	O
2h	O
(	O
r	O
)	O
rgaussian	O
in	O
1dgaussian	O
in	O
2d−2−1	O
0	O
1x−2−1	O
0	O
1	O
2y	O
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1h	O
(	O
r	O
)	O
−0.6−0.4−0.2	O
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1	O
1.2	O
1.4−2	O
0	O
2	O
4	O
6	O
8yx	O
chapter	O
6	O
radial	O
basis	B
functions	O
dkriesel.com	O
||c	O
,	O
x||	O
gauß	O
wvut	O
pqrs	O
||c	O
,	O
x||	O
gauß	O
||c	O
,	O
x||	O
gauß	O
wvut	O
pqrs	O
||c	O
,	O
x||	O
gauß	O
wvut	O
pqrs	O
wvut	O
pqrs	O
(	O
qqqqqqqqqqqqqqqqqqqq	O
vmmmmmmmmmmmmmmmmmmm	O
aaaaaaaaaa	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
onml	O
hijkς	O
(	O
cid:30	O
)	O
neurons	O
are	O
added	O
by	O
an	O
output	O
neuron	O
of	O
the	O
rbf	O
network	O
.	O
once	O
again	O
r	O
=p	O
figure	O
6.5	O
:	O
four	O
diﬀerent	O
gaussian	O
bells	O
in	O
two-dimensional	O
space	O
generated	O
by	O
means	O
of	O
rbf	O
x2	O
+	O
y2	O
applies	O
for	O
the	O
distance	O
.	O
the	O
heights	O
w	O
,	O
widths	O
σ	O
and	O
centers	O
c	O
=	O
(	O
x	O
,	O
y	O
)	O
are	O
:	O
w1	O
=	O
1	O
,	O
σ1	O
=	O
0.4	O
,	O
c1	O
=	O
(	O
0.5	O
,	O
0.5	O
)	O
,	O
w2	O
=	O
−1	O
,	O
σ2	O
=	O
0.6	O
,	O
c2	O
=	O
(	O
1.15	O
,	O
−1.15	O
)	O
,	O
w3	O
=	O
1.5	O
,	O
σ3	O
=	O
0.2	O
,	O
c3	O
=	O
(	O
−0.5	O
,	O
−1	O
)	O
,	O
w4	O
=	O
0.8	O
,	O
σ4	O
=	O
1.4	O
,	O
c4	O
=	O
(	O
−2	O
,	O
0	O
)	O
.	O
110	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
gaussian	O
1−2−1	O
0	O
1x−2−1	O
0	O
1	O
2y−1−0.5	O
0	O
0.5	O
1	O
1.5	O
2h	O
(	O
r	O
)	O
gaussian	O
2−2−1	O
0	O
1x−2−1	O
0	O
1	O
2y−1−0.5	O
0	O
0.5	O
1	O
1.5	O
2h	O
(	O
r	O
)	O
gaussian	O
3−2−1	O
0	O
1x−2−1	O
0	O
1	O
2y−1−0.5	O
0	O
0.5	O
1	O
1.5	O
2h	O
(	O
r	O
)	O
gaussian	O
4−2−1	O
0	O
1x−2−1	O
0	O
1	O
2y−1−0.5	O
0	O
0.5	O
1	O
1.5	O
2h	O
(	O
r	O
)	O
sum	O
of	O
the	O
4	O
gaussians−2−1.5−1−0.5	O
0	O
0.5	O
1	O
1.5	O
2x−2−1.5−1−0.5	O
0	O
0.5	O
1	O
1.5	O
2y−1−0.75−0.5−0.25	O
0	O
0.25	O
0.5	O
0.75	O
1	O
1.25	O
1.5	O
1.75	O
2	O
(	O
~	O
v	O
	O
	O
dkriesel.com	O
6.2	O
information	O
processing	O
of	O
an	O
rbf	O
network	O
since	O
we	O
use	O
a	O
norm	O
to	O
calculate	O
the	O
dis-	O
tance	O
between	O
the	O
input	B
vector	I
and	O
the	O
center	O
of	O
a	O
neuron	O
h	O
,	O
we	O
have	O
diﬀerent	O
choices	O
:	O
often	O
the	O
euclidian	O
norm	O
is	O
cho-	O
sen	O
to	O
calculate	O
the	O
distance	O
:	O
rh	O
=	O
||x	O
−	O
ch||	O
sx	O
i∈i	O
=	O
(	O
xi	O
−	O
ch	O
,	O
i	O
)	O
2	O
(	O
6.1	O
)	O
(	O
6.2	O
)	O
remember	O
:	O
the	O
input	B
vector	I
was	O
referred	O
to	O
as	O
x.	O
here	O
,	O
the	O
index	O
i	O
runs	O
through	O
the	O
input	O
neurons	O
and	O
thereby	O
through	O
the	O
input	B
vector	I
components	O
and	O
the	O
neuron	O
center	O
components	O
.	O
as	O
we	O
can	O
see	O
,	O
the	O
euclidean	O
distance	O
generates	O
the	O
squared	O
diﬀerences	O
of	O
all	O
vector	O
components	O
,	O
adds	O
them	O
and	O
extracts	O
the	O
root	O
of	O
the	O
sum	O
.	O
in	O
two-dimensional	O
space	O
this	O
corresponds	O
to	O
the	O
pythagorean	O
theorem	O
.	O
from	O
the	O
deﬁnition	O
of	O
a	O
norm	O
directly	O
follows	O
that	O
the	O
distance	O
can	O
only	O
be	O
positive	O
.	O
strictly	O
speaking	O
,	O
we	O
hence	O
only	O
use	O
the	O
positive	O
part	O
of	O
the	O
activation	B
function	I
.	O
by	O
the	O
way	O
,	O
activation	B
functions	O
other	O
than	O
the	O
gaussian	O
bell	O
are	O
possible	O
.	O
normally	O
,	O
func-	O
tions	O
that	O
are	O
monotonically	O
decreasing	O
over	O
the	O
interval	O
[	O
0	O
;	O
∞	O
]	O
are	O
chosen	O
.	O
now	O
that	O
we	O
know	O
the	O
distance	O
rh	O
be-	O
tween	O
the	O
input	B
vector	I
x	O
and	O
the	O
center	O
ch	O
of	O
the	O
rbf	O
neuron	O
h	O
,	O
this	O
distance	O
has	O
to	O
be	O
passed	O
through	O
the	O
activation	B
func-	O
tion	O
.	O
here	O
we	O
use	O
,	O
as	O
already	O
mentioned	O
,	O
a	O
gaussian	O
bell	O
:	O
(	O
cid:18	O
)	O
−r2	O
(	O
cid:19	O
)	O
h	O
2σ2	O
h	O
fact	O
(	O
rh	O
)	O
=	O
e	O
(	O
6.3	O
)	O
activation	B
function	I
fact	O
,	O
and	O
hence	O
the	O
ac-	O
tivation	O
functions	O
should	O
not	O
be	O
referred	O
to	O
as	O
fact	O
simultaneously	O
.	O
one	O
solution	O
would	O
be	O
to	O
number	O
the	O
activation	B
func-	O
tions	O
like	O
fact1	O
,	O
fact2	O
,	O
.	O
.	O
.	O
,	O
fact|h|	O
with	O
h	O
be-	O
ing	O
the	O
set	O
of	O
hidden	O
neurons	O
.	O
but	O
as	O
a	O
result	O
the	O
explanation	O
would	O
be	O
very	O
con-	O
fusing	O
.	O
so	O
i	O
simply	O
use	O
the	O
name	O
fact	O
for	O
all	O
activation	B
functions	O
and	O
regard	O
σ	O
and	O
c	O
as	O
variables	O
that	O
are	O
deﬁned	O
for	O
individ-	O
ual	O
neurons	O
but	O
no	O
directly	O
included	O
in	O
the	O
activation	B
function	I
.	O
the	O
reader	O
will	O
certainly	O
notice	O
that	O
in	O
the	O
literature	O
the	O
gaussian	O
bell	O
is	O
often	O
nor-	O
malized	O
by	O
a	O
multiplicative	O
factor	O
.	O
we	O
can	O
,	O
however	O
,	O
avoid	O
this	O
factor	O
because	O
we	O
are	O
multiplying	O
anyway	O
with	O
the	O
subse-	O
quent	O
weights	O
and	O
consecutive	O
multiplica-	O
tions	O
,	O
ﬁrst	O
by	O
a	O
normalization	O
factor	O
and	O
then	O
by	O
the	O
connections	O
’	O
weights	O
,	O
would	O
only	O
yield	O
diﬀerent	O
factors	O
there	O
.	O
we	O
do	O
not	O
need	O
this	O
factor	O
(	O
especially	O
because	O
for	O
our	O
purpose	O
the	O
integral	O
of	O
the	O
gaussian	O
bell	O
must	O
not	O
always	O
be	O
1	O
)	O
and	O
therefore	O
simply	O
leave	O
it	O
out	O
.	O
6.2.2	O
some	O
analytical	O
thoughts	O
prior	O
to	O
the	O
training	O
the	O
output	O
yω	O
of	O
an	O
rbf	O
output	O
neuron	O
ω	O
results	O
from	O
combining	O
the	O
functions	O
of	O
an	O
rbf	O
neuron	O
to	O
wh	O
,	O
ω	O
·	O
fact	O
(	O
||x	O
−	O
ch||	O
)	O
.	O
(	O
6.4	O
)	O
yω	O
=	O
x	O
h∈h	O
it	O
is	O
obvious	O
that	O
both	O
the	O
center	O
ch	O
and	O
the	O
width	O
σh	O
can	O
be	O
seen	O
as	O
part	O
of	O
the	O
suppose	O
that	O
similar	O
to	O
the	O
multilayer	O
per-	O
ceptron	O
we	O
have	O
a	O
set	O
p	O
,	O
that	O
contains	O
|p|	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
111	O
rh	O
(	O
cid:73	O
)	O
chapter	O
6	O
radial	O
basis	B
functions	O
dkriesel.com	O
training	O
samples	O
(	O
p	O
,	O
t	O
)	O
.	O
then	O
we	O
obtain	O
|p|	O
functions	O
of	O
the	O
form	O
wh	O
,	O
ω	O
·	O
fact	O
(	O
||p	O
−	O
ch||	O
)	O
,	O
(	O
6.5	O
)	O
yω	O
=	O
x	O
h∈h	O
i.e	O
.	O
one	O
function	B
for	O
each	O
training	O
sam-	O
ple	O
.	O
of	O
course	O
,	O
with	O
this	O
eﬀort	O
we	O
are	O
aiming	O
at	O
letting	O
the	O
output	O
y	O
for	O
all	O
training	O
patterns	O
p	O
converge	O
to	O
the	O
corresponding	O
teaching	B
input	I
t.	O
6.2.2.1	O
weights	O
can	O
simply	O
be	O
computed	O
as	O
solution	O
of	O
a	O
system	O
of	O
equations	O
thus	O
,	O
we	O
have	O
|p|	O
equations	O
.	O
now	O
let	O
us	O
assume	O
that	O
the	O
widths	O
σ1	O
,	O
σ2	O
,	O
.	O
.	O
.	O
,	O
σk	O
,	O
the	O
centers	O
c1	O
,	O
c2	O
,	O
.	O
.	O
.	O
,	O
ck	O
and	O
the	O
training	O
sam-	O
ples	O
p	O
including	O
the	O
teaching	B
input	I
t	O
are	O
given	O
.	O
we	O
are	O
looking	O
for	O
the	O
weights	O
wh	O
,	O
ω	O
with	O
|h|	O
weights	O
for	O
one	O
output	O
neuron	O
ω.	O
thus	O
,	O
our	O
problem	O
can	O
be	O
seen	O
as	O
a	O
system	O
of	O
equations	O
since	O
the	O
only	O
thing	O
we	O
want	O
to	O
change	O
at	O
the	O
moment	O
are	O
the	O
weights	O
.	O
this	O
demands	O
a	O
distinction	O
of	O
cases	O
con-	O
cerning	O
the	O
number	O
of	O
training	O
samples	O
|p|	O
and	O
the	O
number	O
of	O
rbf	O
neurons	O
|h|	O
:	O
|p|	O
=	O
|h|	O
:	O
if	O
the	O
number	O
of	O
rbf	O
neurons	O
equals	O
the	O
number	O
of	O
patterns	O
,	O
i.e	O
.	O
|p|	O
=	O
|h|	O
,	O
the	O
equation	O
can	O
be	O
re-	O
duced	O
to	O
a	O
matrix	O
multiplication	O
simply	O
calculate	O
weights	O
t	O
=	O
m	O
·	O
g	O
−1	O
·	O
t	O
=	O
m	O
−1	O
·	O
t	O
=	O
e	O
·	O
g	O
−1	O
·	O
t	O
=	O
g	O
,	O
(	O
6.6	O
)	O
−1	O
·	O
m	O
·	O
g	O
(	O
6.7	O
)	O
(	O
6.8	O
)	O
(	O
6.9	O
)	O
⇔	O
m	O
⇔	O
m	O
⇔	O
m	O
where	O
.	O
t	O
is	O
the	O
vector	O
of	O
the	O
teaching	O
(	O
cid:74	O
)	O
t	O
inputs	O
for	O
all	O
training	O
samples	O
,	O
.	O
m	O
is	O
the	O
|p|	O
×	O
|h|	O
matrix	O
of	O
(	O
cid:74	O
)	O
m	O
the	O
outputs	O
of	O
all	O
|h|	O
rbf	O
neu-	O
rons	O
to	O
|p|	O
samples	O
(	O
remember	O
:	O
|p|	O
=	O
|h|	O
,	O
the	O
matrix	O
is	O
squared	O
and	O
we	O
can	O
therefore	O
attempt	O
to	O
invert	O
it	O
)	O
,	O
.	O
g	O
is	O
the	O
vector	O
of	O
the	O
desired	O
(	O
cid:74	O
)	O
g	O
weights	O
and	O
.	O
e	O
is	O
a	O
unit	O
matrix	O
with	O
the	O
same	O
(	O
cid:74	O
)	O
e	O
size	O
as	O
g.	O
mathematically	O
speaking	O
,	O
we	O
can	O
sim-	O
ply	O
calculate	O
the	O
weights	O
:	O
in	O
the	O
case	O
of	O
|p|	O
=	O
|h|	O
there	O
is	O
exactly	O
one	O
rbf	O
neuron	O
available	O
per	O
training	O
sample	O
.	O
this	O
means	O
,	O
that	O
the	O
network	O
exactly	O
meets	O
the	O
|p|	O
existing	O
nodes	O
after	O
hav-	O
ing	O
calculated	O
the	O
weights	O
,	O
i.e	O
.	O
it	O
per-	O
forms	O
a	O
precise	B
interpolation	I
.	O
to	O
calculate	O
such	O
an	O
equation	O
we	O
cer-	O
tainly	O
do	O
not	O
need	O
an	O
rbf	O
network	O
,	O
and	O
therefore	O
we	O
can	O
proceed	O
to	O
the	O
next	O
case	O
.	O
exact	O
interpolation	B
must	O
not	O
be	O
mis-	O
taken	O
for	O
the	O
memorizing	O
ability	O
men-	O
tioned	O
with	O
the	O
mlps	O
:	O
first	O
,	O
we	O
are	O
not	O
talking	O
about	O
the	O
training	O
of	O
rbf	O
112	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
6.2	O
information	O
processing	O
of	O
an	O
rbf	O
network	O
networks	O
at	O
the	O
moment	O
.	O
second	O
,	O
it	O
could	O
be	O
advantageous	O
for	O
us	O
and	O
might	O
in	O
fact	O
be	O
intended	O
if	O
the	O
net-	O
work	O
exactly	O
interpolates	O
between	O
the	O
nodes	O
.	O
|p|	O
<	O
|h|	O
:	O
the	O
system	O
of	O
equations	O
is	O
under-determined	O
,	O
there	O
are	O
more	O
rbf	O
neurons	O
than	O
training	O
samples	O
,	O
|p|	O
<	O
|h|	O
.	O
certainly	O
,	O
this	O
case	O
i.e	O
.	O
normally	O
does	O
not	O
occur	O
very	O
often	O
.	O
in	O
this	O
case	O
,	O
there	O
is	O
a	O
huge	O
variety	O
of	O
solutions	O
which	O
we	O
do	O
not	O
need	O
in	O
such	O
detail	O
.	O
we	O
can	O
select	O
one	O
set	O
of	O
weights	O
out	O
of	O
many	O
obviously	O
possi-	O
ble	O
ones	O
.	O
|p|	O
>	O
|h|	O
:	O
but	O
most	O
interesting	O
for	O
fur-	O
ther	O
discussion	O
is	O
the	O
case	O
if	O
there	O
are	O
signiﬁcantly	O
more	O
training	O
sam-	O
ples	O
than	O
rbf	O
neurons	O
,	O
that	O
means	O
|p|	O
>	O
|h|	O
.	O
thus	O
,	O
we	O
again	O
want	O
to	O
use	O
the	O
generalization	B
capability	O
of	O
the	O
neural	O
network	O
.	O
if	O
we	O
have	O
more	O
training	O
samples	O
than	O
rbf	O
neurons	O
,	O
we	O
can	O
not	O
assume	O
that	O
every	O
training	O
sample	O
is	O
exactly	O
hit	O
.	O
so	O
,	O
if	O
we	O
can	O
not	O
exactly	O
hit	O
the	O
points	O
and	O
therefore	O
can	O
not	O
just	O
interpolate	O
as	O
in	O
the	O
aforementioned	O
ideal	O
case	O
with	O
|p|	O
=	O
|h|	O
,	O
we	O
must	O
try	O
to	O
ﬁnd	O
a	O
function	B
that	O
approximates	O
our	O
training	B
set	I
p	O
as	O
closely	O
as	O
possible	O
:	O
as	O
with	O
the	O
mlp	O
we	O
try	O
to	O
reduce	O
the	O
sum	O
of	O
the	O
squared	O
error	O
to	O
a	O
min-	O
imum	O
.	O
how	O
do	O
we	O
continue	O
the	O
calculation	O
in	O
the	O
case	O
of	O
|p|	O
>	O
|h|	O
?	O
as	O
above	O
,	O
to	O
solve	O
the	O
system	O
of	O
equations	O
,	O
we	O
have	O
to	O
ﬁnd	O
the	O
solution	O
m	O
of	O
a	O
ma-	O
trix	O
multiplication	O
t	O
=	O
m	O
·	O
g.	O
(	O
6.10	O
)	O
the	O
problem	O
is	O
that	O
this	O
time	O
we	O
can-	O
not	O
invert	O
the	O
|p|×|h|	O
matrix	O
m	O
be-	O
cause	O
it	O
is	O
not	O
a	O
square	O
matrix	O
(	O
here	O
,	O
|p|	O
6=	O
|h|	O
is	O
true	O
)	O
.	O
here	O
,	O
we	O
have	O
to	O
use	O
the	O
moore-penrose	O
pseudo	O
inverse	O
m	O
+	O
which	O
is	O
deﬁned	O
by	O
m	O
+	O
=	O
(	O
m	O
t	O
·	O
m	O
)	O
−1	O
·	O
m	O
t	O
(	O
6.11	O
)	O
(	O
cid:74	O
)	O
m	O
+	O
although	O
the	O
moore-penrose	O
pseudo	O
inverse	O
is	O
not	O
the	O
inverse	O
of	O
a	O
matrix	O
,	O
it	O
can	O
be	O
used	O
similarly	O
in	O
this	O
case1	O
.	O
we	O
get	O
equations	O
that	O
are	O
very	O
similar	O
to	O
those	O
in	O
the	O
case	O
of	O
|p|	O
=	O
|h|	O
:	O
t	O
=	O
m	O
·	O
g	O
(	O
6.12	O
)	O
⇔	O
m	O
+	O
·	O
t	O
=	O
m	O
+	O
·	O
m	O
·	O
g	O
(	O
6.13	O
)	O
⇔	O
m	O
+	O
·	O
t	O
=	O
e	O
·	O
g	O
(	O
6.14	O
)	O
⇔	O
m	O
+	O
·	O
t	O
=	O
g	O
(	O
6.15	O
)	O
another	O
reason	O
for	O
the	O
use	O
of	O
the	O
moore-penrose	O
pseudo	O
inverse	O
is	O
the	O
fact	O
that	O
it	O
minimizes	O
the	O
squared	O
error	O
(	O
which	O
is	O
our	O
goal	O
)	O
:	O
the	O
esti-	O
mate	O
of	O
the	O
vector	O
g	O
in	O
equation	O
6.15	O
corresponds	O
to	O
the	O
gauss-markov	O
model	O
known	O
from	O
statistics	O
,	O
which	O
is	O
used	O
to	O
minimize	O
the	O
squared	O
error	O
.	O
in	O
the	O
aforementioned	O
equations	O
6.11	O
and	O
the	O
following	O
ones	O
please	O
do	O
not	O
mistake	O
the	O
t	O
in	O
m	O
t	O
(	O
of	O
the	O
trans-	O
pose	O
of	O
the	O
matrix	O
m	O
)	O
for	O
the	O
t	O
of	O
the	O
vector	O
of	O
all	O
teaching	O
inputs	O
.	O
+	O
=	O
m	O
1	O
particularly	O
,	O
m	O
−1	O
is	O
true	O
if	O
m	O
is	O
invertible	O
.	O
i	O
do	O
not	O
want	O
to	O
go	O
into	O
detail	O
of	O
the	O
reasons	O
for	O
+	O
-	O
they	O
these	O
circumstances	O
and	O
applications	O
of	O
m	O
can	O
easily	O
be	O
found	O
in	O
literature	O
for	O
linear	O
algebra	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
113	O
chapter	O
6	O
radial	O
basis	B
functions	O
dkriesel.com	O
6.2.2.2	O
the	O
generalization	B
on	O
several	O
outputs	O
is	O
trivial	O
and	O
not	O
quite	O
computationally	O
expensive	O
we	O
have	O
found	O
a	O
mathematically	O
exact	O
way	O
to	O
directly	O
calculate	O
the	O
weights	O
.	O
what	O
will	O
happen	O
if	O
there	O
are	O
several	O
out-	O
put	O
neurons	O
,	O
i.e	O
.	O
|o|	O
>	O
1	O
,	O
with	O
o	O
being	O
,	O
as	O
usual	O
,	O
the	O
set	O
of	O
the	O
output	O
neurons	O
ω	O
?	O
in	O
this	O
case	O
,	O
as	O
we	O
have	O
already	O
indicated	O
,	O
it	O
does	O
not	O
change	O
much	O
:	O
the	O
additional	O
out-	O
put	O
neurons	O
have	O
their	O
own	O
set	O
of	O
weights	O
while	O
we	O
do	O
not	O
change	O
the	O
σ	O
and	O
c	O
of	O
the	O
rbf	O
layer	B
.	O
thus	O
,	O
in	O
an	O
rbf	O
network	O
it	O
is	O
easy	O
for	O
given	O
σ	O
and	O
c	O
to	O
realize	O
a	O
lot	O
of	O
output	O
neurons	O
since	O
we	O
only	O
have	O
to	O
cal-	O
culate	O
the	O
individual	O
vector	O
of	O
weights	O
gω	O
=	O
m	O
+	O
·	O
tω	O
(	O
6.16	O
)	O
for	O
every	O
new	O
output	O
neuron	O
ω	O
,	O
whereas	O
the	O
matrix	O
m	O
+	O
,	O
which	O
generally	O
requires	O
a	O
lot	O
of	O
computational	O
eﬀort	O
,	O
always	O
stays	O
the	O
same	O
:	O
so	O
it	O
is	O
quite	O
inexpensive	O
–	O
at	O
least	O
concerning	O
the	O
computational	O
com-	O
plexity	O
–	O
to	O
add	O
more	O
output	O
neurons	O
.	O
inexpensive	O
output	B
dimension	I
6.2.2.3	O
computational	O
eﬀort	O
and	O
accuracy	O
for	O
realistic	O
problems	O
it	O
normally	O
applies	O
that	O
there	O
are	O
considerably	O
more	O
training	O
|p|	O
(	O
cid:29	O
)	O
samples	O
than	O
rbf	O
neurons	O
,	O
i.e	O
.	O
|h|	O
:	O
you	O
can	O
,	O
without	O
any	O
diﬃculty	O
,	O
use	O
106	O
training	O
samples	O
,	O
if	O
you	O
like	O
.	O
theoreti-	O
cally	O
,	O
we	O
could	O
ﬁnd	O
the	O
terms	O
for	O
the	O
math-	O
ematically	O
correct	O
solution	O
on	O
the	O
black-	O
board	O
(	O
after	O
a	O
very	O
long	O
time	O
)	O
,	O
but	O
such	O
calculations	O
often	O
seem	O
to	O
be	O
imprecise	O
m+	O
complex	O
and	O
imprecise	O
and	O
very	O
time-consuming	O
(	O
matrix	O
inver-	O
sions	O
require	O
a	O
lot	O
of	O
computational	O
ef-	O
fort	O
)	O
.	O
furthermore	O
,	O
our	O
moore-penrose	O
pseudo-	O
inverse	O
is	O
,	O
in	O
spite	O
of	O
numeric	O
stabil-	O
ity	O
,	O
no	O
guarantee	O
that	O
the	O
output	B
vector	I
corresponds	O
to	O
the	O
teaching	O
vector	O
,	O
be-	O
cause	O
such	O
extensive	O
computations	O
can	O
be	O
prone	O
to	O
many	O
inaccuracies	O
,	O
even	O
though	O
the	O
calculation	O
is	O
mathematically	O
correct	O
:	O
our	O
computers	O
can	O
only	O
provide	O
us	O
with	O
(	O
nonetheless	O
very	O
good	O
)	O
approximations	O
of	O
the	O
pseudo-inverse	O
matrices	O
.	O
this	O
means	O
that	O
we	O
also	O
get	O
only	O
approximations	O
of	O
the	O
correct	O
weights	O
(	O
maybe	O
with	O
a	O
lot	O
of	O
accumulated	O
numerical	O
errors	O
)	O
and	O
there-	O
fore	O
only	O
an	O
approximation	B
(	O
maybe	O
very	O
rough	O
or	O
even	O
unrecognizable	O
)	O
of	O
the	O
de-	O
sired	O
output	O
.	O
if	O
we	O
have	O
enough	O
computing	O
power	O
to	O
an-	O
alytically	O
determine	O
a	O
weight	B
vector	I
,	O
we	O
should	O
use	O
it	O
nevertheless	O
only	O
as	O
an	O
initial	O
value	O
for	O
our	O
learning	B
process	O
,	O
which	O
leads	O
us	O
to	O
the	O
real	O
training	O
methods	O
–	O
but	O
oth-	O
erwise	O
it	O
would	O
be	O
boring	O
,	O
wouldn	O
’	O
t	O
it	O
?	O
6.3	O
combinations	O
of	O
equation	O
system	O
and	O
gradient	B
strategies	O
are	O
useful	O
for	O
training	O
analogous	O
to	O
the	O
mlp	O
we	O
perform	O
a	O
gra-	O
dient	O
descent	O
to	O
ﬁnd	O
the	O
suitable	O
weights	O
by	O
means	O
of	O
the	O
already	O
well	O
known	O
delta	B
rule	I
.	O
here	O
,	O
backpropagation	B
is	O
unneces-	O
sary	O
since	O
we	O
only	O
have	O
to	O
train	O
one	O
single	O
retraining	O
delta	B
rule	I
114	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
6.3	O
training	O
of	O
rbf	O
networks	O
weight	B
layer	O
–	O
which	O
requires	O
less	O
comput-	O
ing	O
time	O
.	O
we	O
know	O
that	O
the	O
delta	B
rule	I
is	O
∆wh	O
,	O
ω	O
=	O
η	O
·	O
δω	O
·	O
oh	O
,	O
(	O
6.17	O
)	O
in	O
which	O
we	O
now	O
insert	O
as	O
follows	O
:	O
∆wh	O
,	O
ω	O
=	O
η	O
·	O
(	O
tω	O
−	O
yω	O
)	O
·	O
fact	O
(	O
||p	O
−	O
ch||	O
)	O
(	O
6.18	O
)	O
here	O
again	O
i	O
explicitly	O
want	O
to	O
mention	O
that	O
it	O
is	O
very	O
popular	O
to	O
divide	O
the	O
train-	O
ing	O
into	O
two	O
phases	O
by	O
analytically	O
com-	O
puting	O
a	O
set	O
of	O
weights	O
and	O
then	O
reﬁning	O
it	O
by	O
training	O
with	O
the	O
delta	B
rule	I
.	O
there	O
is	O
still	O
the	O
question	O
whether	O
to	O
learn	O
oﬄine	O
or	O
online	O
.	O
here	O
,	O
the	O
answer	O
is	O
sim-	O
ilar	O
to	O
the	O
answer	O
for	O
the	O
multilayer	O
per-	O
ceptron	O
:	O
initially	O
,	O
one	O
often	O
trains	O
online	O
(	O
faster	O
movement	O
across	O
the	O
error	O
surface	O
)	O
.	O
then	O
,	O
after	O
having	O
approximated	O
the	O
so-	O
lution	O
,	O
the	O
errors	O
are	O
once	O
again	O
accumu-	O
lated	O
and	O
,	O
for	O
a	O
more	O
precise	O
approxima-	O
tion	O
,	O
one	O
trains	O
oﬄine	O
in	O
a	O
third	O
learn-	O
ing	O
phase	O
.	O
however	O
,	O
similar	O
to	O
the	O
mlps	O
,	O
you	O
can	O
be	O
successful	O
by	O
using	O
many	O
meth-	O
ods	O
.	O
as	O
already	O
indicated	O
,	O
in	O
an	O
rbf	O
network	O
not	O
only	O
the	O
weights	O
between	O
the	O
hidden	O
and	O
the	O
output	B
layer	I
can	O
be	O
optimized	O
.	O
so	O
let	O
us	O
now	O
take	O
a	O
look	O
at	O
the	O
possibility	O
to	O
vary	O
σ	O
and	O
c.	O
training	O
in	O
phases	O
6.3.1	O
it	O
is	O
not	O
always	O
trivial	O
to	O
determine	O
centers	O
and	O
widths	O
of	O
rbf	O
neurons	O
it	O
is	O
obvious	O
that	O
the	O
approximation	B
accu-	O
racy	O
of	O
rbf	O
networks	O
can	O
be	O
increased	O
by	O
adapting	O
the	O
widths	O
and	O
positions	O
of	O
the	O
gaussian	O
bells	O
in	O
the	O
input	O
space	O
to	O
the	O
problem	O
that	O
needs	O
to	O
be	O
approximated	O
.	O
there	O
are	O
several	O
methods	O
to	O
deal	O
with	O
the	O
centers	O
c	O
and	O
the	O
widths	O
σ	O
of	O
the	O
gaussian	O
bells	O
:	O
fixed	O
selection	O
:	O
the	O
centers	O
and	O
widths	O
can	O
be	O
selected	O
in	O
a	O
ﬁxed	O
manner	O
and	O
regardless	O
of	O
the	O
training	O
samples	O
–	O
this	O
is	O
what	O
we	O
have	O
assumed	O
until	O
now	O
.	O
conditional	O
,	O
ﬁxed	O
selection	O
:	O
again	O
cen-	O
ters	O
and	O
widths	O
are	O
selected	O
ﬁxedly	O
,	O
but	O
we	O
have	O
previous	O
knowledge	O
about	O
the	O
functions	O
to	O
be	O
approxi-	O
mated	O
and	O
comply	O
with	O
it	O
.	O
vary	O
σ	O
and	O
c	O
adaptive	O
to	O
the	O
learning	B
process	O
:	O
this	O
too	O
.	O
a	O
realization	O
of	O
is	O
deﬁnitely	O
the	O
most	O
elegant	O
variant	O
,	O
but	O
certainly	O
the	O
most	O
challenging	O
one	O
,	O
this	O
approach	O
will	O
not	O
be	O
discussed	O
in	O
this	O
chapter	O
but	O
it	O
can	O
be	O
found	O
in	O
connection	B
with	O
another	O
network	O
topology	O
(	O
section	O
10.6.1	O
)	O
.	O
6.3.1.1	O
fixed	O
selection	O
in	O
any	O
case	O
,	O
the	O
goal	O
is	O
to	O
cover	O
the	O
in-	O
put	O
space	O
as	O
evenly	O
as	O
possible	O
.	O
here	O
,	O
widths	O
of	O
2	O
3	O
of	O
the	O
distance	O
between	O
the	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
115	O
chapter	O
6	O
radial	O
basis	B
functions	O
dkriesel.com	O
responsible	O
for	O
the	O
fact	O
that	O
six-	O
to	O
ten-	O
dimensional	O
problems	O
in	O
rbf	O
networks	O
are	O
already	O
called	O
``	O
high-dimensional	O
''	O
(	O
an	O
mlp	O
,	O
for	O
example	O
,	O
does	O
not	O
cause	O
any	O
problems	O
here	O
)	O
.	O
6.3.1.2	O
conditional	O
,	O
ﬁxed	O
selection	O
suppose	O
that	O
our	O
training	O
samples	O
are	O
not	O
evenly	O
distributed	O
across	O
the	O
input	O
space	O
.	O
it	O
then	O
seems	O
obvious	O
to	O
arrange	O
the	O
cen-	O
ters	O
and	O
sigmas	O
of	O
the	O
rbf	O
neurons	O
by	O
means	O
of	O
the	O
pattern	B
distribution	O
.	O
so	O
the	O
training	O
patterns	O
can	O
be	O
analyzed	O
by	O
statis-	O
tical	O
techniques	O
such	O
as	O
a	O
cluster	B
analysis	I
,	O
and	O
so	O
it	O
can	O
be	O
determined	O
whether	O
there	O
are	O
statistical	O
factors	O
according	O
to	O
which	O
we	O
should	O
distribute	O
the	O
centers	O
and	O
sig-	O
mas	O
(	O
ﬁg	O
.	O
6.7	O
on	O
the	O
facing	O
page	O
)	O
.	O
a	O
more	O
trivial	O
alternative	O
would	O
be	O
to	O
set	O
|h|	O
centers	O
on	O
positions	O
randomly	O
se-	O
lected	O
from	O
the	O
set	O
of	O
patterns	O
.	O
so	O
this	O
method	O
would	O
allow	O
for	O
every	O
training	O
pat-	O
tern	O
p	O
to	O
be	O
directly	O
in	O
the	O
center	O
of	O
a	O
neu-	O
ron	O
(	O
ﬁg	O
.	O
6.8	O
on	O
the	O
next	O
page	O
)	O
.	O
this	O
is	O
not	O
yet	O
very	O
elegant	O
but	O
a	O
good	O
solution	O
when	O
time	O
is	O
an	O
issue	O
.	O
generally	O
,	O
for	O
this	O
method	O
the	O
widths	O
are	O
ﬁxedly	O
selected	O
.	O
if	O
we	O
have	O
reason	O
to	O
believe	O
that	O
the	O
set	O
of	O
training	O
samples	O
is	O
clustered	O
,	O
we	O
can	O
use	O
clustering	O
methods	O
to	O
determine	O
them	O
.	O
there	O
are	O
diﬀerent	O
methods	O
to	O
determine	O
clusters	B
in	O
an	O
arbitrarily	O
dimensional	O
set	O
of	O
points	O
.	O
we	O
will	O
be	O
introduced	O
to	O
some	O
of	O
them	O
in	O
excursus	O
a.	O
one	O
neural	O
cluster-	O
ing	O
method	O
are	O
the	O
so-called	O
rolfs	O
(	O
sec-	O
tion	O
a.5	O
)	O
,	O
and	O
self-organizing	O
maps	O
are	O
figure	O
6.6	O
:	O
example	O
for	O
an	O
even	O
coverage	O
of	O
a	O
two-dimensional	O
input	O
space	O
by	O
applying	O
radial	O
basis	B
functions	O
.	O
centers	O
can	O
be	O
selected	O
so	O
that	O
the	O
gaus-	O
sian	O
bells	O
overlap	O
by	O
approx	O
.	O
``	O
one	O
third	O
''	O
2	O
(	O
ﬁg	O
.	O
6.6	O
)	O
.	O
the	O
closer	O
the	O
bells	O
are	O
set	O
the	O
more	O
precise	O
but	O
the	O
more	O
time-consuming	O
the	O
whole	O
thing	O
becomes	O
.	O
this	O
may	O
seem	O
to	O
be	O
very	O
inelegant	O
,	O
but	O
in	O
the	O
ﬁeld	O
of	O
function	B
approximation	I
we	O
can	O
not	O
avoid	O
even	O
coverage	O
.	O
here	O
it	O
is	O
useless	O
if	O
the	O
function	B
to	O
be	O
approximated	O
is	O
precisely	O
represented	O
at	O
some	O
positions	O
but	O
at	O
other	O
positions	O
the	O
return	B
value	O
is	O
only	O
0.	O
however	O
,	O
the	O
high	O
input	O
dimen-	O
sion	O
requires	O
a	O
great	O
many	O
rbf	O
neurons	O
,	O
which	O
increases	O
the	O
computational	O
eﬀort	O
exponentially	O
with	O
the	O
dimension	O
–	O
and	O
is	O
2	O
it	O
is	O
apparent	O
that	O
a	O
gaussian	O
bell	O
is	O
mathemati-	O
cally	O
inﬁnitely	O
wide	O
,	O
therefore	O
i	O
ask	O
the	O
reader	O
to	O
apologize	O
this	O
sloppy	O
formulation	O
.	O
input	B
dimension	I
very	O
expensive	O
116	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
6.3	O
training	O
of	O
rbf	O
networks	O
figure	O
6.7	O
:	O
example	O
of	O
an	O
uneven	O
coverage	O
of	O
a	O
two-dimensional	O
input	O
space	O
,	O
of	O
which	O
we	O
have	O
previous	O
knowledge	O
,	O
by	O
applying	O
radial	O
ba-	O
sis	O
functions	O
.	O
also	O
useful	O
in	O
connection	B
with	O
determin-	O
ing	O
the	O
position	O
of	O
rbf	O
neurons	O
(	O
section	O
10.6.1	O
)	O
.	O
using	O
rolfs	O
,	O
one	O
can	O
also	O
receive	O
indicators	O
for	O
useful	O
radii	O
of	O
the	O
rbf	O
neu-	O
rons	O
.	O
learning	O
vector	O
quantisation	O
(	O
chap-	O
ter	O
9	O
)	O
has	O
also	O
provided	O
good	O
results	O
.	O
all	O
these	O
methods	O
have	O
nothing	O
to	O
do	O
with	O
the	O
rbf	O
networks	O
themselves	O
but	O
are	O
only	O
used	O
to	O
generate	O
some	O
previous	O
knowledge	O
.	O
therefore	O
we	O
will	O
not	O
discuss	O
them	O
in	O
this	O
chapter	O
but	O
independently	O
in	O
the	O
indicated	O
chapters	O
.	O
another	O
approach	O
is	O
to	O
use	O
the	O
approved	O
methods	O
:	O
we	O
could	O
slightly	O
move	O
the	O
po-	O
sitions	O
of	O
the	O
centers	O
and	O
observe	O
how	O
our	O
error	B
function	I
err	O
is	O
changing	O
–	O
a	O
gradient	B
descent	I
,	O
as	O
already	O
known	O
from	O
the	O
mlps	O
.	O
figure	O
6.8	O
:	O
example	O
of	O
an	O
uneven	O
coverage	O
of	O
a	O
two-dimensional	O
input	O
space	O
by	O
applying	O
radial	O
basis	B
functions	O
.	O
the	O
widths	O
were	O
ﬁxedly	O
selected	O
,	O
the	O
centers	O
of	O
the	O
neurons	O
were	O
randomly	O
dis-	O
tributed	O
throughout	O
the	O
training	O
patterns	O
.	O
this	O
distribution	O
can	O
certainly	O
lead	O
to	O
slightly	O
unrepre-	O
sentative	O
results	O
,	O
which	O
can	O
be	O
seen	O
at	O
the	O
single	O
data	O
point	O
down	O
to	O
the	O
left	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
117	O
chapter	O
6	O
radial	O
basis	B
functions	O
dkriesel.com	O
in	O
a	O
similar	O
manner	O
we	O
could	O
look	O
how	O
the	O
error	O
depends	O
on	O
the	O
values	O
σ.	O
analogous	O
to	O
the	O
derivation	O
of	O
backpropagation	B
we	O
derive	O
in	O
the	O
following	O
text	O
,	O
only	O
simple	O
mecha-	O
nisms	O
are	O
sketched	O
.	O
for	O
more	O
information	O
,	O
i	O
refer	O
to	O
[	O
fri94	O
]	O
.	O
∂err	O
(	O
σhch	O
)	O
∂σh	O
and	O
∂err	O
(	O
σhch	O
)	O
∂ch	O
.	O
6.4.1	O
neurons	O
are	O
added	O
to	O
places	O
with	O
large	O
error	O
values	O
since	O
the	O
derivation	O
of	O
these	O
terms	O
corre-	O
sponds	O
to	O
the	O
derivation	O
of	O
backpropaga-	O
tion	O
we	O
do	O
not	O
want	O
to	O
discuss	O
it	O
here	O
.	O
but	O
experience	O
shows	O
that	O
no	O
convincing	O
results	O
are	O
obtained	O
by	O
regarding	O
how	O
the	O
error	O
behaves	O
depending	O
on	O
the	O
centers	O
and	O
sigmas	O
.	O
even	O
if	O
mathematics	O
claim	O
that	O
such	O
methods	O
are	O
promising	O
,	O
the	O
gra-	O
dient	O
descent	O
,	O
as	O
we	O
already	O
know	O
,	O
leads	O
to	O
problems	O
with	O
very	O
craggy	O
error	O
sur-	O
faces	O
.	O
and	O
that	O
is	O
the	O
crucial	O
point	O
:	O
naturally	O
,	O
rbf	O
networks	O
generate	O
very	O
craggy	O
er-	O
ror	O
surfaces	O
because	O
,	O
if	O
we	O
considerably	O
change	O
a	O
c	O
or	O
a	O
σ	O
,	O
we	O
will	O
signiﬁcantly	O
change	O
the	O
appearance	O
of	O
the	O
error	O
func-	O
tion	O
.	O
6.4	O
growing	B
rbf	O
networks	O
automatically	O
adjust	O
the	O
neuron	O
density	O
in	O
growing	B
rbf	O
networks	O
,	O
the	O
number	O
|h|	O
of	O
rbf	O
neurons	O
is	O
not	O
constant	O
.	O
a	O
certain	O
number	O
|h|	O
of	O
neurons	O
as	O
well	O
as	O
their	O
centers	O
ch	O
and	O
widths	O
σh	O
are	O
previ-	O
ously	O
selected	O
(	O
e.g	O
.	O
by	O
means	O
of	O
a	O
cluster-	O
ing	O
method	O
)	O
and	O
then	O
extended	O
or	O
reduced	O
.	O
after	O
generating	O
this	O
initial	O
conﬁguration	O
the	O
vector	O
of	O
the	O
weights	O
g	O
is	O
analytically	O
calculated	O
.	O
then	O
all	O
speciﬁc	O
errors	O
errp	O
concerning	O
the	O
set	O
p	O
of	O
the	O
training	O
sam-	O
ples	O
are	O
calculated	O
and	O
the	O
maximum	O
spe-	O
ciﬁc	O
error	O
max	O
p	O
(	O
errp	O
)	O
is	O
sought	O
.	O
the	O
extension	O
of	O
the	O
network	O
is	O
simple	O
:	O
we	O
replace	O
this	O
maximum	O
error	O
with	O
a	O
new	O
replace	O
rbf	O
neuron	O
.	O
of	O
course	O
,	O
we	O
have	O
to	O
exer-	O
error	O
with	O
neuron	O
cise	O
care	O
in	O
doing	O
this	O
:	O
if	O
the	O
σ	O
are	O
small	O
,	O
the	O
neurons	O
will	O
only	O
inﬂuence	O
each	O
other	O
if	O
the	O
distance	O
between	O
them	O
is	O
short	O
.	O
but	O
if	O
the	O
σ	O
are	O
large	O
,	O
the	O
already	O
exisiting	O
neurons	O
are	O
considerably	O
inﬂuenced	O
by	O
the	O
new	O
neuron	O
because	O
of	O
the	O
overlapping	O
of	O
the	O
gaussian	O
bells	O
.	O
so	O
it	O
is	O
obvious	O
that	O
we	O
will	O
adjust	O
the	O
al-	O
ready	O
existing	O
rbf	O
neurons	O
when	O
adding	O
the	O
new	O
neuron	O
.	O
to	O
put	O
it	O
simply	O
,	O
this	O
adjustment	O
is	O
made	O
by	O
moving	O
the	O
centers	O
c	O
of	O
the	O
other	O
neu-	O
rons	O
away	O
from	O
the	O
new	O
neuron	O
and	O
re-	O
ducing	O
their	O
width	O
σ	O
a	O
bit	O
.	O
then	O
the	O
current	O
output	B
vector	I
y	O
of	O
the	O
network	O
is	O
compared	O
to	O
the	O
teaching	B
input	I
t	O
and	O
the	O
weight	B
vector	I
g	O
is	O
improved	O
by	O
means	O
of	O
training	O
.	O
subsequently	O
,	O
a	O
new	O
neuron	O
can	O
be	O
inserted	O
if	O
necessary	O
.	O
this	O
method	O
is	O
118	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
6.5	O
comparing	O
rbf	O
networks	O
and	O
multilayer	O
perceptrons	O
particularly	O
suited	O
for	O
function	B
approxima-	O
tions	O
.	O
two	O
paradigms	O
and	O
look	O
at	O
their	O
advan-	O
tages	O
and	O
disadvantages	O
.	O
6.4.2	O
limiting	O
the	O
number	O
of	O
neurons	O
here	O
it	O
is	O
mandatory	O
to	O
see	O
that	O
the	O
net-	O
work	O
will	O
not	O
grow	O
ad	O
inﬁnitum	O
,	O
which	O
can	O
happen	O
very	O
fast	O
.	O
thus	O
,	O
it	O
is	O
very	O
useful	O
to	O
previously	O
deﬁne	O
a	O
maximum	O
number	O
for	O
neurons	O
|h|max	O
.	O
6.4.3	O
less	O
important	O
neurons	O
are	O
deleted	O
which	O
leads	O
to	O
the	O
question	O
whether	O
it	O
is	O
possible	O
to	O
continue	O
learning	B
when	O
this	O
limit	O
|h|max	O
is	O
reached	O
.	O
the	O
answer	O
is	O
:	O
this	O
would	O
not	O
stop	O
learning	B
.	O
we	O
only	O
have	O
to	O
look	O
for	O
the	O
``	O
most	O
unimportant	O
''	O
neuron	O
and	O
delete	O
it	O
.	O
a	O
neuron	O
is	O
,	O
for	O
example	O
,	O
unimportant	O
for	O
the	O
network	O
if	O
there	O
is	O
an-	O
other	O
neuron	O
that	O
has	O
a	O
similar	O
function	B
:	O
it	O
often	O
occurs	O
that	O
two	O
gaussian	O
bells	O
ex-	O
actly	O
overlap	O
and	O
at	O
such	O
a	O
position	O
,	O
for	O
instance	O
,	O
one	O
single	O
neuron	O
with	O
a	O
higher	O
gaussian	O
bell	O
would	O
be	O
appropriate	O
.	O
but	O
to	O
develop	O
automated	O
procedures	O
in	O
order	O
to	O
ﬁnd	O
less	O
relevant	O
neurons	O
is	O
highly	O
problem	O
dependent	O
and	O
we	O
want	O
to	O
leave	O
this	O
to	O
the	O
programmer	O
.	O
with	O
rbf	O
networks	O
and	O
multilayer	O
per-	O
ceptrons	O
we	O
have	O
already	O
become	O
ac-	O
quainted	O
with	O
and	O
extensivley	O
discussed	O
two	O
network	O
paradigms	O
for	O
similar	O
prob-	O
lems	O
.	O
therefore	O
we	O
want	O
to	O
compare	O
these	O
delete	O
unimportant	O
neurons	O
6.5	O
comparing	O
rbf	O
networks	O
and	O
multilayer	O
perceptrons	O
networks	O
we	O
will	O
compare	O
multilayer	O
perceptrons	O
and	O
rbf	O
networks	O
with	O
respect	O
to	O
diﬀer-	O
ent	O
aspects	O
.	O
input	B
dimension	I
:	O
we	O
must	O
be	O
careful	O
high-	O
with	O
rbf	O
dimensional	O
functional	O
spaces	O
since	O
the	O
network	O
could	O
very	O
quickly	O
require	O
huge	O
memory	O
storage	O
and	O
computational	O
a	O
multilayer	B
perceptron	I
would	O
cause	O
less	O
problems	O
because	O
its	O
number	O
of	O
neuons	O
does	O
not	O
grow	O
exponentially	O
with	O
the	O
input	B
dimension	I
.	O
in	O
eﬀort	O
.	O
here	O
,	O
center	O
selection	O
:	O
however	O
,	O
selecting	O
the	O
centers	O
c	O
for	O
rbf	O
networks	O
is	O
(	O
despite	O
the	O
introduced	O
approaches	O
)	O
still	O
a	O
ma-	O
jor	O
problem	O
.	O
please	O
use	O
any	O
previous	O
knowledge	O
you	O
have	O
when	O
applying	O
them	O
.	O
such	O
problems	O
do	O
not	O
occur	O
with	O
the	O
mlp	O
.	O
output	B
dimension	I
:	O
the	O
advantage	O
of	O
rbf	O
networks	O
is	O
that	O
the	O
training	O
is	O
not	O
much	O
inﬂuenced	O
when	O
the	O
output	B
dimension	I
of	O
the	O
network	O
is	O
high	O
.	O
for	O
an	O
mlp	O
,	O
a	O
learning	B
procedure	O
such	O
as	O
backpropagation	B
thereby	O
will	O
be	O
very	O
time-consuming	O
.	O
extrapolation	O
:	O
advantage	O
as	O
well	O
as	O
dis-	O
advantage	O
of	O
rbf	O
networks	O
is	O
the	O
lack	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
119	O
chapter	O
6	O
radial	O
basis	B
functions	O
dkriesel.com	O
exercises	O
exercise	O
13.	O
an	O
|i|-|h|-|o|	O
rbf	O
net-	O
work	O
with	O
ﬁxed	O
widths	O
and	O
centers	O
of	O
the	O
neurons	O
should	O
approximate	O
a	O
target	B
func-	O
tion	O
u.	O
for	O
this	O
,	O
|p|	O
training	O
samples	O
of	O
the	O
form	O
(	O
p	O
,	O
t	O
)	O
of	O
the	O
function	B
u	O
are	O
given	O
.	O
let	O
|p|	O
>	O
|h|	O
be	O
true	O
.	O
the	O
weights	O
should	O
be	O
analytically	O
determined	O
by	O
means	O
of	O
the	O
moore-penrose	O
pseudo	O
inverse	O
.	O
indi-	O
cate	O
the	O
running	O
time	O
behavior	O
regarding	O
|p|	O
and	O
|o|	O
as	O
precisely	O
as	O
possible	O
.	O
note	O
:	O
there	O
are	O
methods	O
for	O
matrix	O
mul-	O
tiplications	O
and	O
matrix	O
inversions	O
that	O
are	O
more	O
eﬃcient	O
than	O
the	O
canonical	O
methods	O
.	O
for	O
better	O
estimations	O
,	O
i	O
recommend	O
to	O
look	O
for	O
such	O
methods	O
(	O
and	O
their	O
complex-	O
ity	O
)	O
.	O
in	O
addition	O
to	O
your	O
complexity	O
calcu-	O
lations	O
,	O
please	O
indicate	O
the	O
used	O
methods	O
together	O
with	O
their	O
complexity	O
.	O
important	O
!	O
of	O
extrapolation	O
capability	O
:	O
an	O
rbf	O
network	O
returns	O
the	O
result	O
0	O
far	O
away	O
from	O
the	O
centers	O
of	O
the	O
rbf	O
layer	B
.	O
on	O
the	O
one	O
hand	O
it	O
does	O
not	O
extrapolate	O
,	O
unlike	O
the	O
mlp	O
it	O
can	O
not	O
be	O
used	O
for	O
extrapolation	O
(	O
whereby	O
we	O
could	O
never	O
know	O
if	O
the	O
extrapolated	O
values	O
of	O
the	O
mlp	O
are	O
reasonable	O
,	O
but	O
expe-	O
rience	O
shows	O
that	O
mlps	O
are	O
suitable	O
for	O
that	O
matter	O
)	O
.	O
on	O
the	O
other	O
hand	O
,	O
unlike	O
the	O
mlp	O
the	O
network	O
is	O
capa-	O
ble	O
to	O
use	O
this	O
0	O
to	O
tell	O
us	O
``	O
i	O
don	O
’	O
t	O
know	O
''	O
,	O
which	O
could	O
be	O
an	O
advantage	O
.	O
lesion	O
tolerance	O
:	O
for	O
the	O
output	O
of	O
an	O
mlp	O
,	O
it	O
is	O
no	O
so	O
important	O
if	O
a	O
weight	B
it	O
will	O
only	O
or	O
a	O
neuron	O
is	O
missing	O
.	O
worsen	O
a	O
little	O
in	O
total	O
.	O
if	O
a	O
weight	B
or	O
a	O
neuron	O
is	O
missing	O
in	O
an	O
rbf	O
net-	O
work	O
then	O
large	O
parts	O
of	O
the	O
output	O
remain	O
practically	O
uninﬂuenced	O
.	O
but	O
one	O
part	O
of	O
the	O
output	O
is	O
heavily	O
af-	O
fected	O
because	O
a	O
gaussian	O
bell	O
is	O
di-	O
rectly	O
missing	O
.	O
thus	O
,	O
we	O
can	O
choose	O
between	O
a	O
strong	O
local	O
error	O
for	O
lesion	O
and	O
a	O
weak	O
but	O
global	O
error	O
.	O
spread	O
:	O
here	O
the	O
mlp	O
is	O
``	O
advantaged	O
''	O
since	O
rbf	O
networks	O
are	O
used	O
consid-	O
erably	O
less	O
often	O
–	O
which	O
is	O
not	O
always	O
understood	O
by	O
professionals	O
(	O
at	O
least	O
as	O
far	O
as	O
low-dimensional	O
input	O
spaces	O
are	O
concerned	O
)	O
.	O
the	O
mlps	O
seem	O
to	O
have	O
a	O
considerably	O
longer	O
tradition	O
and	O
they	O
are	O
working	O
too	O
good	O
to	O
take	O
the	O
eﬀort	O
to	O
read	O
some	O
pages	O
of	O
this	O
work	O
about	O
rbf	O
networks	O
)	O
:	O
-	O
)	O
.	O
120	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
chapter	O
7	O
recurrent	O
perceptron-like	O
networks	O
some	O
thoughts	O
about	O
networks	O
with	O
internal	O
states	O
.	O
generally	O
,	O
recurrent	O
networks	O
are	O
net-	O
works	O
that	O
are	O
capable	O
of	O
inﬂuencing	O
them-	O
selves	O
by	O
means	O
of	O
recurrences	O
,	O
e.g	O
.	O
by	O
including	O
the	O
network	O
output	O
in	O
the	O
follow-	O
ing	O
computation	O
steps	O
.	O
there	O
are	O
many	O
types	O
of	O
recurrent	O
networks	O
of	O
nearly	O
arbi-	O
trary	O
form	O
,	O
and	O
nearly	O
all	O
of	O
them	O
are	O
re-	O
ferred	O
to	O
as	O
recurrent	O
neural	O
networks	O
.	O
as	O
a	O
result	O
,	O
for	O
the	O
few	O
paradigms	O
in-	O
troduced	O
here	O
i	O
use	O
the	O
name	O
recurrent	O
multilayer	O
perceptrons	O
.	O
apparently	O
,	O
such	O
a	O
recurrent	O
network	O
is	O
ca-	O
pable	O
to	O
compute	O
more	O
than	O
the	O
ordinary	O
mlp	O
:	O
if	O
the	O
recurrent	O
weights	O
are	O
set	O
to	O
0	O
,	O
the	O
recurrent	O
network	O
will	O
be	O
reduced	O
to	O
an	O
ordinary	O
mlp	O
.	O
additionally	O
,	O
the	O
recur-	O
rence	O
generates	O
diﬀerent	O
network-internal	O
states	O
so	O
that	O
diﬀerent	O
inputs	O
can	O
produce	O
diﬀerent	O
outputs	O
in	O
the	O
context	O
of	O
the	O
net-	O
work	O
state	B
.	O
recurrent	O
networks	O
in	O
themselves	O
have	O
a	O
great	O
dynamic	O
that	O
is	O
mathematically	O
dif-	O
ﬁcult	O
to	O
conceive	O
and	O
has	O
to	O
be	O
discussed	O
extensively	O
.	O
the	O
aim	O
of	O
this	O
chapter	O
is	O
only	O
to	O
brieﬂy	O
discuss	O
how	O
recurrences	O
can	O
be	O
structured	O
and	O
how	O
network-internal	O
states	O
can	O
be	O
generated	O
.	O
thus	O
,	O
i	O
will	O
brieﬂy	O
introduce	O
two	O
paradigms	O
of	O
recur-	O
rent	O
networks	O
and	O
afterwards	O
roughly	O
out-	O
line	O
their	O
training	O
.	O
with	O
a	O
recurrent	O
network	O
an	O
input	O
x	O
that	O
is	O
constant	O
over	O
time	O
may	O
lead	O
to	O
diﬀer-	O
ent	O
results	O
:	O
on	O
the	O
one	O
hand	O
,	O
the	O
network	O
could	O
converge	O
,	O
i.e	O
.	O
it	O
could	O
transform	O
it-	O
self	O
into	O
a	O
ﬁxed	O
state	B
and	O
at	O
some	O
time	O
re-	O
turn	O
a	O
ﬁxed	O
output	O
value	O
y.	O
on	O
the	O
other	O
hand	O
,	O
it	O
could	O
never	O
converge	O
,	O
or	O
at	O
least	O
not	O
until	O
a	O
long	O
time	O
later	O
,	O
so	O
that	O
it	O
can	O
no	O
longer	O
be	O
recognized	O
,	O
and	O
as	O
a	O
conse-	O
quence	O
,	O
y	O
constantly	O
changes	O
.	O
if	O
the	O
network	O
does	O
not	O
converge	O
,	O
it	O
is	O
,	O
for	O
example	O
,	O
possible	O
to	O
check	O
if	O
periodicals	O
or	O
attractors	O
(	O
ﬁg	O
.	O
7.1	O
on	O
the	O
following	O
page	O
)	O
are	O
returned	O
.	O
here	O
,	O
we	O
can	O
expect	O
the	O
complete	O
variety	O
of	O
dynamical	O
sys-	O
tems	O
.	O
that	O
is	O
the	O
reason	O
why	O
i	O
particu-	O
larly	O
want	O
to	O
refer	O
to	O
the	O
literature	O
con-	O
cerning	O
dynamical	O
systems	O
.	O
state	B
dynamics	O
more	O
capable	O
than	O
mlp	O
121	O
chapter	O
7	O
recurrent	O
perceptron-like	O
networks	O
(	O
depends	O
on	O
chapter	O
5	O
)	O
dkriesel.com	O
further	O
discussions	O
could	O
reveal	O
what	O
will	O
happen	O
if	O
the	O
input	O
of	O
recurrent	O
networks	O
is	O
changed	O
.	O
in	O
this	O
chapter	O
the	O
related	O
paradigms	O
of	O
recurrent	O
networks	O
according	O
to	O
jordan	O
and	O
elman	O
will	O
be	O
introduced	O
.	O
7.1	O
jordan	O
networks	O
a	O
jordan	O
network	O
[	O
jor86	O
]	O
is	O
a	O
multi-	O
layer	B
perceptron	O
with	O
a	O
set	O
k	O
of	O
so-called	O
context	O
neurons	O
k1	O
,	O
k2	O
,	O
.	O
.	O
.	O
,	O
k|k|	O
.	O
there	O
is	O
one	O
context	B
neuron	I
per	O
output	O
neuron	O
(	O
ﬁg	O
.	O
7.2	O
on	O
the	O
next	O
page	O
)	O
.	O
in	O
principle	O
,	O
a	O
context	B
neuron	I
just	O
memorizes	O
an	O
output	O
until	O
it	O
can	O
be	O
processed	O
in	O
the	O
next	O
time	O
step	O
.	O
therefore	O
,	O
there	O
are	O
weighted	O
con-	O
nections	O
between	O
each	O
output	O
neuron	O
and	O
one	O
context	B
neuron	I
.	O
the	O
stored	O
values	O
are	O
returned	O
to	O
the	O
actual	O
network	O
by	O
means	O
of	O
complete	O
links	O
between	O
the	O
context	O
neu-	O
rons	O
and	O
the	O
input	B
layer	I
.	O
in	O
the	O
originial	O
deﬁnition	O
of	O
a	O
jordan	O
net-	O
work	O
the	O
context	O
neurons	O
are	O
also	O
recur-	O
rent	O
to	O
themselves	O
via	O
a	O
connecting	O
weight	B
λ.	O
but	O
most	O
applications	O
omit	O
this	O
recur-	O
rence	O
since	O
the	O
jordan	O
network	O
is	O
already	O
very	O
dynamic	O
and	O
diﬃcult	O
to	O
analyze	O
,	O
even	O
without	O
these	O
additional	O
recurrences	O
.	O
deﬁnition	O
7.1	O
(	O
context	B
neuron	I
)	O
.	O
a	O
con-	O
text	O
neuron	O
k	O
receives	O
the	O
output	O
value	O
of	O
another	O
neuron	O
i	O
at	O
a	O
time	O
t	O
and	O
then	O
reen-	O
ters	O
it	O
into	O
the	O
network	O
at	O
a	O
time	O
(	O
t	O
+	O
1	O
)	O
.	O
deﬁnition	O
7.2	O
(	O
jordan	O
network	O
)	O
.	O
a	O
jor-	O
dan	O
network	O
is	O
a	O
multilayer	B
perceptron	I
output	O
neurons	O
are	O
buﬀered	O
figure	O
7.1	O
:	O
the	O
roessler	O
attractor	B
122	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
7.2	O
elman	O
networks	O
i1	O
i2	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
*uuuuuuuuuuuuuuuuuuuuuuuuuu	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
aaaaaaaaa	O
aaaaaaaaa	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
gfed	O
@	O
abch2	O
gfed	O
@	O
abch1	O
gfed	O
@	O
abch3	O
*uuuuuuuuuuuuuuuuuuuuuuuuuu	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
aaaaaaaaa	O
aaaaaaaaa	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
gfed	O
@	O
abcω2	O
gfed	O
@	O
abcω1	O
	O
@	O
a	O
	O
gfed	O
@	O
abck2	O
	O
gfed	O
@	O
abck1	O
bc	O
figure	O
7.2	O
:	O
illustration	O
of	O
a	O
jordan	O
network	O
.	O
the	O
network	O
output	O
is	O
buﬀered	O
in	O
the	O
context	O
neurons	O
and	O
with	O
the	O
next	O
time	O
step	O
it	O
is	O
entered	O
into	O
the	O
network	O
together	O
with	O
the	O
new	O
input	O
.	O
with	O
one	O
context	B
neuron	I
per	O
output	O
neu-	O
ron	O
.	O
the	O
set	O
of	O
context	O
neurons	O
is	O
called	O
k.	O
the	O
context	O
neurons	O
are	O
completely	O
linked	O
toward	O
the	O
input	B
layer	I
of	O
the	O
net-	O
work	O
.	O
7.2	O
elman	O
networks	O
the	O
elman	O
networks	O
(	O
a	O
variation	O
of	O
the	O
jordan	O
networks	O
)	O
[	O
elm90	O
]	O
have	O
con-	O
text	O
neurons	O
,	O
too	O
,	O
but	O
one	O
layer	B
of	O
context	O
neurons	O
per	O
information	O
processing	O
neu-	O
ron	O
layer	B
(	O
ﬁg	O
.	O
7.3	O
on	O
the	O
following	O
page	O
)	O
.	O
thus	O
,	O
the	O
outputs	O
of	O
each	O
hidden	O
neuron	O
or	O
output	O
neuron	O
are	O
led	O
into	O
the	O
associ-	O
ated	O
context	O
layer	O
(	O
again	O
exactly	O
one	O
con-	O
text	O
neuron	O
per	O
neuron	O
)	O
and	O
from	O
there	O
it	O
is	O
reentered	O
into	O
the	O
complete	O
neuron	O
layer	B
during	O
the	O
next	O
time	O
step	O
(	O
i.e	O
.	O
again	O
a	O
com-	O
plete	O
link	O
on	O
the	O
way	O
back	O
)	O
.	O
so	O
the	O
com-	O
plete	O
information	O
processing	O
part1	O
of	O
the	O
mlp	O
exists	O
a	O
second	O
time	O
as	O
a	O
``	O
context	O
version	O
''	O
–	O
which	O
once	O
again	O
considerably	O
increases	O
dynamics	O
and	O
state	B
variety	O
.	O
compared	O
with	O
jordan	O
networks	O
the	O
el-	O
man	O
networks	O
often	O
have	O
the	O
advantage	O
to	O
act	O
more	O
purposeful	O
since	O
every	O
layer	B
can	O
access	O
its	O
own	O
context	O
.	O
deﬁnition	O
7.3	O
(	O
elman	O
network	O
)	O
.	O
an	O
el-	O
man	O
network	O
is	O
an	O
mlp	O
with	O
one	O
con-	O
text	O
neuron	O
per	O
information	B
processing	I
neuron	I
.	O
the	O
set	O
of	O
context	O
neurons	O
is	O
called	O
k.	O
this	O
means	O
that	O
there	O
exists	O
one	O
context	O
layer	O
per	O
information	O
processing	O
1	O
remember	O
:	O
the	O
input	B
layer	I
does	O
not	O
process	O
in-	O
formation	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
123	O
nearly	O
every-	O
thing	O
is	O
buﬀered	O
	O
	O
	O
	O
~	O
*	O
t	O
~	O
	O
	O
x	O
x	O
	O
	O
{	O
{	O
v	O
v	O
*	O
~	O
~	O
t	O
	O
o	O
o	O
	O
o	O
o	O
chapter	O
7	O
recurrent	O
perceptron-like	O
networks	O
(	O
depends	O
on	O
chapter	O
5	O
)	O
dkriesel.com	O
i2	O
i1	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
*uuuuuuuuuuuuuuuuuuuuuuuuuu	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
~~~~~~~~~~~	O
~~~~~~~~~~~	O
gfed	O
@	O
abch3	O
gfed	O
@	O
abch2	O
gfed	O
@	O
abch1	O
*uuuuuuuuuuuuuuuuuuuuuuuuuu	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
~~~~~~~~~	O
~~~~~~~~~	O
gfed	O
gfed	O
@	O
abcω1	O
@	O
abcω2	O
onml	O
hijkkh3	O
onml	O
hijkkh1	O
onml	O
hijkkω1	O
onml	O
hijkkh2	O
onml	O
hijkkω2	O
figure	O
7.3	O
:	O
illustration	O
of	O
an	O
elman	O
network	O
.	O
the	O
entire	O
information	O
processing	O
part	O
of	O
the	O
network	O
exists	O
,	O
in	O
a	O
way	O
,	O
twice	O
.	O
the	O
output	O
of	O
each	O
neuron	O
(	O
except	O
for	O
the	O
output	O
of	O
the	O
input	O
neurons	O
)	O
is	O
buﬀered	O
and	O
reentered	O
into	O
the	O
associated	O
layer	B
.	O
for	O
the	O
reason	O
of	O
clarity	O
i	O
named	O
the	O
context	O
neurons	O
on	O
the	O
basis	B
of	O
their	O
models	O
in	O
the	O
actual	O
network	O
,	O
but	O
it	O
is	O
not	O
mandatory	O
to	O
do	O
so	O
.	O
neuron	O
layer	O
with	O
exactly	O
the	O
same	O
num-	O
ber	O
of	O
context	O
neurons	O
.	O
every	O
neuron	O
has	O
a	O
weighted	O
connection	O
to	O
exactly	O
one	O
con-	O
text	O
neuron	O
while	O
the	O
context	O
layer	O
is	O
com-	O
pletely	O
linked	O
towards	O
its	O
original	O
layer	B
.	O
now	O
it	O
is	O
interesting	O
to	O
take	O
a	O
look	O
at	O
the	O
training	O
of	O
recurrent	O
networks	O
since	O
,	O
for	O
in-	O
stance	O
,	O
ordinary	O
backpropagation	B
of	I
error	I
can	O
not	O
work	O
on	O
recurrent	O
networks	O
.	O
once	O
again	O
,	O
the	O
style	O
of	O
the	O
following	O
part	O
is	O
rather	O
informal	O
,	O
which	O
means	O
that	O
i	O
will	O
not	O
use	O
any	O
formal	O
deﬁnitions	O
.	O
7.3	O
training	O
recurrent	O
networks	O
in	O
order	O
to	O
explain	O
the	O
training	O
as	O
compre-	O
hensible	O
as	O
possible	O
,	O
we	O
have	O
to	O
agree	O
on	O
some	O
simpliﬁcations	O
that	O
do	O
not	O
aﬀect	O
the	O
learning	B
principle	O
itself	O
.	O
so	O
for	O
the	O
training	O
let	O
us	O
assume	O
that	O
in	O
the	O
beginning	O
the	O
context	O
neurons	O
are	O
ini-	O
tiated	O
with	O
an	O
input	O
,	O
since	O
otherwise	O
they	O
would	O
have	O
an	O
undeﬁned	O
input	O
(	O
this	O
is	O
no	O
simpliﬁcation	O
but	O
reality	O
)	O
.	O
furthermore	O
,	O
we	O
use	O
a	O
jordan	O
network	O
without	O
a	O
hidden	O
neuron	O
layer	B
for	O
our	O
training	O
attempts	O
so	O
that	O
the	O
output	O
neu-	O
124	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
	O
	O
	O
~	O
*	O
t	O
~	O
*	O
4	O
4	O
	O
5	O
5	O
	O
t	O
5	O
5	O
u	O
u	O
z	O
z	O
v	O
v	O
w	O
w	O
u	O
u	O
t	O
t	O
v	O
v	O
u	O
u	O
t	O
t	O
	O
	O
5	O
5	O
5	O
5	O
	O
	O
u	O
u	O
w	O
w	O
u	O
u	O
v	O
v	O
attach	O
the	O
same	O
network	O
to	O
each	O
context	O
layer	O
dkriesel.com	O
7.3	O
training	O
recurrent	O
networks	O
rons	O
can	O
directly	O
provide	O
input	O
.	O
this	O
ap-	O
proach	O
is	O
a	O
strong	O
simpliﬁcation	O
because	O
generally	O
more	O
complicated	O
networks	O
are	O
used	O
.	O
but	O
this	O
does	O
not	O
change	O
the	O
learn-	O
ing	O
principle	O
.	O
7.3.1	O
unfolding	B
in	I
time	I
remember	O
our	O
actual	O
learning	B
procedure	O
for	O
mlps	O
,	O
the	O
backpropagation	B
of	I
error	I
,	O
which	O
backpropagates	O
the	O
delta	O
values	O
.	O
so	O
,	O
in	O
case	O
of	O
recurrent	O
networks	O
the	O
delta	O
values	O
would	O
backpropagate	O
cycli-	O
cally	O
through	O
the	O
network	O
again	O
and	O
again	O
,	O
which	O
makes	O
the	O
training	O
more	O
diﬃcult	O
.	O
on	O
the	O
one	O
hand	O
we	O
can	O
not	O
know	O
which	O
of	O
the	O
many	O
generated	O
delta	O
values	O
for	O
a	O
weight	B
should	O
be	O
selected	O
for	O
training	O
,	O
i.e	O
.	O
which	O
values	O
are	O
useful	O
.	O
on	O
the	O
other	O
hand	O
we	O
can	O
not	O
deﬁnitely	O
know	O
when	O
learning	B
should	O
be	O
stopped	O
.	O
the	O
advantage	O
of	O
re-	O
current	O
networks	O
are	O
great	O
state	B
dynamics	O
within	O
the	O
network	O
;	O
the	O
disadvantage	O
of	O
recurrent	O
networks	O
is	O
that	O
these	O
dynamics	O
are	O
also	O
granted	O
to	O
the	O
training	O
and	O
there-	O
fore	O
make	O
it	O
diﬃcult	O
.	O
one	O
learning	B
approach	O
would	O
be	O
the	O
at-	O
tempt	O
to	O
unfold	O
the	O
temporal	O
states	O
of	O
the	O
network	O
(	O
ﬁg	O
.	O
7.4	O
on	O
the	O
next	O
page	O
)	O
:	O
recursions	O
are	O
deleted	O
by	O
putting	O
a	O
sim-	O
ilar	O
network	O
above	O
the	O
context	O
neurons	O
,	O
i.e	O
.	O
the	O
context	O
neurons	O
are	O
,	O
as	O
a	O
man-	O
ner	O
of	O
speaking	O
,	O
the	O
output	O
neurons	O
of	O
the	O
attached	O
network	O
.	O
more	O
generally	O
spo-	O
ken	O
,	O
we	O
have	O
to	O
backtrack	O
the	O
recurrences	O
and	O
place	O
``	O
‘	O
earlier	O
''	O
’	O
instances	O
of	O
neurons	O
in	O
the	O
network	O
–	O
thus	O
creating	O
a	O
larger	O
,	O
but	O
forward-oriented	O
network	O
without	O
re-	O
currences	O
.	O
this	O
enables	O
training	O
a	O
recur-	O
rent	O
network	O
with	O
any	O
training	O
strategy	O
developed	O
for	O
non-recurrent	O
ones	O
.	O
here	O
,	O
the	O
input	O
is	O
entered	O
as	O
teaching	B
input	I
into	O
every	O
``	O
copy	O
''	O
of	O
the	O
input	O
neurons	O
.	O
this	O
can	O
be	O
done	O
for	O
a	O
discrete	B
number	O
of	O
time	O
steps	O
.	O
these	O
training	O
paradigms	O
are	O
called	O
unfolding	B
in	I
time	I
[	O
mp69	O
]	O
.	O
after	O
the	O
un-	O
folding	O
a	O
training	O
by	O
means	O
of	O
backpropa-	O
gation	O
of	O
error	O
is	O
possible	O
.	O
but	O
obviously	O
,	O
for	O
one	O
weight	B
wi	O
,	O
j	O
sev-	O
eral	O
changing	O
values	O
∆wi	O
,	O
j	O
are	O
received	O
,	O
which	O
can	O
be	O
treated	O
diﬀerently	O
:	O
accumu-	O
lation	O
,	O
averaging	O
etc	O
.	O
a	O
simple	O
accumu-	O
lation	O
could	O
possibly	O
result	O
in	O
enormous	O
changes	O
per	O
weight	B
if	O
all	O
changes	O
have	O
the	O
same	O
sign	O
.	O
hence	O
,	O
also	O
the	O
average	O
is	O
not	O
to	O
be	O
underestimated	O
.	O
we	O
could	O
also	O
intro-	O
duce	O
a	O
discounting	O
factor	O
,	O
which	O
weakens	O
the	O
inﬂuence	O
of	O
∆wi	O
,	O
j	O
of	O
the	O
past	O
.	O
unfolding	B
in	I
time	I
is	O
particularly	O
useful	O
if	O
we	O
receive	O
the	O
impression	O
that	O
the	O
closer	O
past	O
is	O
more	O
important	O
for	O
the	O
network	O
than	O
the	O
one	O
being	O
further	O
away	O
.	O
the	O
reason	O
for	O
this	O
is	O
that	O
backpropagation	B
has	O
only	O
little	O
inﬂuence	O
in	O
the	O
layers	O
far-	O
ther	O
away	O
from	O
the	O
output	O
(	O
remember	O
:	O
the	O
farther	O
we	O
are	O
from	O
the	O
output	B
layer	I
,	O
the	O
smaller	O
the	O
inﬂuence	O
of	O
backpropaga-	O
tion	O
)	O
.	O
disadvantages	O
:	O
the	O
training	O
of	O
such	O
an	O
un-	O
folded	O
network	O
will	O
take	O
a	O
long	O
time	O
since	O
a	O
large	O
number	O
of	O
layers	O
could	O
possibly	O
be	O
produced	O
.	O
a	O
problem	O
that	O
is	O
no	O
longer	O
negligible	O
is	O
the	O
limited	O
computational	O
ac-	O
curacy	O
of	O
ordinary	O
computers	O
,	O
which	O
is	O
exhausted	O
very	O
fast	O
because	O
of	O
so	O
many	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
125	O
chapter	O
7	O
recurrent	O
perceptron-like	O
networks	O
(	O
depends	O
on	O
chapter	O
5	O
)	O
dkriesel.com	O
i3	O
i1	O
i2	O
gfed	O
@	O
abc	O
gfed	O
@	O
abck1	O
gfed	O
@	O
abc	O
gfed	O
@	O
abck2	O
gfed	O
@	O
abc	O
*uuuuuuuuuuuuuuuuuuuuuuuuu	O
'ppppppppppppppppp	O
'oooooooooooooooo	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
wnnnnnnnnnnnnnnnnn	O
wnnnnnnnnnnnnnnnnn	O
aaaaaaaaa	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
gfed	O
@	O
abcω1	O
@	O
a	O
gfed	O
@	O
abcω2	O
	O
bc	O
...	O
...	O
...	O
...	O
...	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
*vvvvvvvvvvvvvvvvvvvvvvvv	O
(	O
rrrrrrrrrrrrrrrrr	O
(	O
ppppppppppppppp	O
tjjjjjjjjjjjjjjjjjjjjj	O
!	O
ccccccccc	O
?	O
?	O
?	O
?	O
?	O
?	O
?	O
?	O
woooooooooooooo	O
woooooooooooooo	O
	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
*vvvvvvvvvvvvvvvvvvvvvvvvvvv	O
(	O
rrrrrrrrrrrrrrrrrr	O
(	O
qqqqqqqqqqqqqqqqqq	O
tjjjjjjjjjjjjjjjjjjjjjjj	O
!	O
dddddddddd	O
!	O
ccccccccc	O
vnnnnnnnnnnnnnnnn	O
wppppppppppppppp	O
	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
gfed	O
@	O
abck1	O
gfed	O
@	O
abck2	O
*uuuuuuuuuuuuuuuuuuuuuuuuu	O
'ppppppppppppppppp	O
'oooooooooooooooo	O
tiiiiiiiiiiiiiiiiiiiiiiiiii	O
wnnnnnnnnnnnnnnnnn	O
wnnnnnnnnnnnnnnnnn	O
aaaaaaaaa	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
@	O
~	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
}	O
gfed	O
@	O
abcω2	O
gfed	O
@	O
abcω1	O
i3	O
i2	O
i1	O
figure	O
7.4	O
:	O
illustration	O
of	O
the	O
unfolding	B
in	I
time	I
with	O
a	O
small	O
exemplary	O
recurrent	O
mlp	O
.	O
top	O
:	O
the	O
recurrent	O
mlp	O
.	O
bottom	O
:	O
the	O
unfolded	O
network	O
.	O
for	O
reasons	O
of	O
clarity	O
,	O
i	O
only	O
added	O
names	O
to	O
the	O
lowest	O
part	O
of	O
the	O
unfolded	O
network	O
.	O
dotted	O
arrows	O
leading	O
into	O
the	O
network	O
mark	O
the	O
inputs	O
.	O
dotted	O
arrows	O
leading	O
out	O
of	O
the	O
network	O
mark	O
the	O
outputs	O
.	O
each	O
``	O
network	O
copy	O
''	O
represents	O
a	O
time	O
step	O
of	O
the	O
network	O
with	O
the	O
most	O
recent	O
time	O
step	O
being	O
at	O
the	O
bottom	O
.	O
126	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
	O
	O
	O
	O
	O
'	O
*	O
'	O
	O
	O
w	O
~	O
t	O
w	O
o	O
o	O
	O
	O
o	O
o	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
(	O
*	O
!	O
(	O
	O
	O
w	O
	O
t	O
w	O
	O
	O
	O
	O
	O
(	O
*	O
!	O
(	O
	O
	O
!	O
v	O
	O
t	O
w	O
'	O
*	O
'	O
	O
	O
w	O
~	O
t	O
w	O
	O
	O
	O
	O
dkriesel.com	O
7.3	O
training	O
recurrent	O
networks	O
are	O
chosen	O
suitably	O
:	O
so	O
,	O
for	O
example	O
,	O
neu-	O
rons	O
and	O
weights	O
can	O
be	O
adjusted	O
and	O
the	O
network	O
topology	O
can	O
be	O
optimized	O
(	O
of	O
course	O
the	O
result	O
of	O
learning	B
is	O
not	O
necessarily	O
a	O
jordan	O
or	O
elman	O
network	O
)	O
.	O
with	O
ordinary	O
mlps	O
,	O
however	O
,	O
evolution-	O
ary	O
strategies	O
are	O
less	O
popular	O
since	O
they	O
certainly	O
need	O
a	O
lot	O
more	O
time	O
than	O
a	O
di-	O
rected	O
learning	B
procedure	O
such	O
as	O
backpro-	O
pagation	O
.	O
teaching	B
input	I
applied	O
at	O
context	O
neurons	O
nested	O
computations	O
(	O
the	O
farther	O
we	O
are	O
from	O
the	O
output	B
layer	I
,	O
the	O
smaller	O
the	O
in-	O
ﬂuence	O
of	O
backpropagation	B
,	O
so	O
that	O
this	O
limit	O
is	O
reached	O
)	O
.	O
furthermore	O
,	O
with	O
sev-	O
eral	O
levels	O
of	O
context	O
neurons	O
this	O
proce-	O
dure	O
could	O
produce	O
very	O
large	O
networks	O
to	O
be	O
trained	O
.	O
7.3.2	O
teacher	B
forcing	I
the	O
other	O
procedures	O
are	O
equivalent	O
teacher	B
forcing	I
and	O
open	B
loop	I
learn-	O
ing	O
.	O
they	O
detach	O
the	O
recurrence	B
during	O
the	O
learning	B
process	O
:	O
we	O
simply	O
pretend	O
that	O
the	O
recurrence	B
does	O
not	O
exist	O
and	O
ap-	O
ply	O
the	O
teaching	B
input	I
to	O
the	O
context	O
neu-	O
rons	O
during	O
the	O
training	O
.	O
so	O
,	O
backpropaga-	O
tion	O
becomes	O
possible	O
,	O
too	O
.	O
disadvantage	O
:	O
with	O
elman	O
networks	O
a	O
teaching	B
input	I
for	O
non-output-neurons	O
is	O
not	O
given	O
.	O
7.3.3	O
recurrent	O
backpropagation	O
another	O
popular	O
procedure	O
without	O
lim-	O
ited	O
time	B
horizon	I
is	O
the	O
recurrent	O
back-	O
propagation	O
using	O
methods	O
of	O
diﬀer-	O
ential	O
calculus	O
to	O
solve	O
the	O
problem	O
[	O
pin87	O
]	O
.	O
7.3.4	O
training	O
with	O
evolution	O
due	O
to	O
the	O
already	O
long	O
lasting	O
train-	O
ing	O
time	O
,	O
evolutionary	B
algorithms	I
have	O
proved	O
to	O
be	O
of	O
value	O
,	O
especially	O
with	O
recur-	O
rent	O
networks	O
.	O
one	O
reason	O
for	O
this	O
is	O
that	O
they	O
are	O
not	O
only	O
unrestricted	O
with	O
respect	O
to	O
recurrences	O
but	O
they	O
also	O
have	O
other	O
ad-	O
vantages	O
when	O
the	O
mutation	O
mechanisms	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
127	O
chapter	O
8	O
hopﬁeld	O
networks	O
in	O
a	O
magnetic	O
ﬁeld	O
,	O
each	O
particle	O
applies	O
a	O
force	O
to	O
any	O
other	O
particle	O
so	O
that	O
all	O
particles	O
adjust	O
their	O
movements	O
in	O
the	O
energetically	O
most	O
favorable	O
way	O
.	O
this	O
natural	O
mechanism	O
is	O
copied	O
to	O
adjust	O
noisy	O
inputs	O
in	O
order	O
to	O
match	O
their	O
real	O
models	O
.	O
another	O
supervised	B
learning	I
example	O
of	O
the	O
wide	O
range	O
of	O
neural	O
networks	O
was	O
developed	O
by	O
john	O
hopfield	O
:	O
the	O
so-	O
called	O
hopﬁeld	O
networks	O
[	O
hop82	O
]	O
.	O
hop-	O
ﬁeld	O
and	O
his	O
physically	O
motivated	O
net-	O
works	O
have	O
contributed	O
a	O
lot	O
to	O
the	O
renais-	O
sance	O
of	O
neural	O
networks	O
.	O
8.1	O
hopﬁeld	O
networks	O
are	O
inspired	O
by	O
particles	O
in	O
a	O
magnetic	O
ﬁeld	O
the	O
idea	O
for	O
the	O
hopﬁeld	O
networks	O
origi-	O
nated	O
from	O
the	O
behavior	O
of	O
particles	O
in	O
a	O
magnetic	O
ﬁeld	O
:	O
every	O
particle	O
``	O
communi-	O
cates	O
''	O
(	O
by	O
means	O
of	O
magnetic	O
forces	O
)	O
with	O
every	O
other	O
particle	O
(	O
completely	O
linked	O
)	O
with	O
each	O
particle	O
trying	O
to	O
reach	O
an	O
ener-	O
getically	O
favorable	O
state	B
(	O
i.e	O
.	O
a	O
minimum	O
of	O
the	O
energy	O
function	B
)	O
.	O
as	O
for	O
the	O
neurons	O
this	O
state	B
is	O
known	O
as	O
activation	B
.	O
thus	O
,	O
all	O
particles	O
or	O
neurons	O
rotate	O
and	O
thereby	O
encourage	O
each	O
other	O
to	O
continue	O
this	O
rota-	O
tion	O
.	O
as	O
a	O
manner	O
of	O
speaking	O
,	O
our	O
neural	O
network	O
is	O
a	O
cloud	O
of	O
particles	O
based	O
on	O
the	O
fact	O
that	O
the	O
particles	O
auto-	O
matically	O
detect	O
the	O
minima	O
of	O
the	O
energy	O
function	B
,	O
hopﬁeld	O
had	O
the	O
idea	O
to	O
use	O
the	O
''	O
spin	B
''	O
of	O
the	O
particles	O
to	O
process	O
informa-	O
tion	O
:	O
why	O
not	O
letting	O
the	O
particles	O
search	O
minima	O
on	O
arbitrary	O
functions	O
?	O
even	O
if	O
we	O
only	O
use	O
two	O
of	O
those	O
spins	O
,	O
i.e	O
.	O
a	O
binary	O
activation	O
,	O
we	O
will	O
recognize	O
that	O
the	O
devel-	O
oped	O
hopﬁeld	O
network	O
shows	O
considerable	O
dynamics	O
.	O
8.2	O
in	O
a	O
hopﬁeld	O
network	O
,	O
all	O
neurons	O
inﬂuence	O
each	O
other	O
symmetrically	O
brieﬂy	O
speaking	O
,	O
a	O
hopﬁeld	O
network	O
con-	O
sists	O
of	O
a	O
set	O
k	O
of	O
completely	O
linked	O
neu-	O
(	O
cid:74	O
)	O
k	O
rons	O
with	O
binary	O
activation	O
(	O
since	O
we	O
only	O
129	O
chapter	O
8	O
hopﬁeld	O
networks	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
↓5	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
↑	O
i	O
)	O
ssssssssssssssssssssssss	O
ukkkkkkkkkkkkkkkkkkkkkkkk	O
@	O
	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
 	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
↑4	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
↓	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
↑	O
i	O
)	O
sssssssssssssssssssssssso	O
ukkkkkkkkkkkkkkkkkkkkkkkk/	O
@	O
	O
^	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
^	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
<	O
 	O
?	O
>	O
=	O
<	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
↓	O
89	O
:	O
;	O
↑/	O
figure	O
8.1	O
:	O
illustration	O
of	O
an	O
exemplary	O
hop-	O
ﬁeld	O
network	O
.	O
the	O
arrows	O
↑	O
and	O
↓	O
mark	O
the	O
binary	O
``	O
spin	B
''	O
.	O
due	O
to	O
the	O
completely	O
linked	O
neu-	O
rons	O
the	O
layers	O
can	O
not	O
be	O
separated	O
,	O
which	O
means	O
that	O
a	O
hopﬁeld	O
network	O
simply	O
includes	O
a	O
set	O
of	O
neurons	O
.	O
dkriesel.com	O
deﬁnition	O
8.1	O
(	O
hopﬁeld	O
network	O
)	O
.	O
a	O
hopﬁeld	O
network	O
consists	O
of	O
a	O
set	O
k	O
of	O
completely	O
linked	O
neurons	O
without	O
direct	O
recurrences	O
.	O
the	O
activation	B
function	I
of	O
the	O
neurons	O
is	O
the	O
binary	O
threshold	O
func-	O
tion	O
with	O
outputs	O
∈	O
{	O
1	O
,	O
−1	O
}	O
.	O
deﬁnition	O
8.2	O
(	O
state	B
of	O
a	O
hopﬁeld	O
net-	O
work	O
)	O
.	O
the	O
state	B
of	O
the	O
network	O
con-	O
sists	O
of	O
the	O
activation	B
states	O
of	O
all	O
neu-	O
rons	O
.	O
thus	O
,	O
the	O
state	B
of	O
the	O
network	O
can	O
be	O
understood	O
as	O
a	O
binary	O
string	O
z	O
∈	O
{	O
−1	O
,	O
1	O
}	O
|k|	O
.	O
8.2.1	O
input	O
and	O
output	O
of	O
a	O
hopﬁeld	O
network	O
are	O
represented	O
by	O
neuron	O
states	O
use	O
two	O
spins	O
)	O
,	O
with	O
the	O
weights	O
being	O
symmetric	O
between	O
the	O
individual	O
neurons	O
and	O
without	O
any	O
neuron	O
being	O
directly	O
con-	O
nected	O
to	O
itself	O
(	O
ﬁg	O
.	O
8.1	O
)	O
.	O
thus	O
,	O
the	O
state	B
of	O
|k|	O
neurons	O
with	O
two	O
possible	O
states	O
∈	O
{	O
−1	O
,	O
1	O
}	O
can	O
be	O
described	O
by	O
a	O
string	O
x	O
∈	O
{	O
−1	O
,	O
1	O
}	O
|k|	O
.	O
the	O
complete	O
link	O
provides	O
a	O
full	O
square	O
matrix	O
of	O
weights	O
between	O
the	O
neurons	O
.	O
the	O
meaning	O
of	O
the	O
weights	O
will	O
be	O
dis-	O
cussed	O
in	O
the	O
following	O
.	O
furthermore	O
,	O
we	O
will	O
soon	O
recognize	O
according	O
to	O
which	O
rules	O
the	O
neurons	O
are	O
spinning	O
,	O
i.e	O
.	O
are	O
changing	O
their	O
state	B
.	O
additionally	O
,	O
the	O
complete	O
link	O
leads	O
to	O
the	O
fact	O
that	O
we	O
do	O
not	O
know	O
any	O
input	O
,	O
output	O
or	O
hidden	O
neurons	O
.	O
thus	O
,	O
we	O
have	O
to	O
think	O
about	O
how	O
we	O
can	O
input	O
some-	O
thing	O
into	O
the	O
|k|	O
neurons	O
.	O
we	O
have	O
learned	O
that	O
a	O
network	O
,	O
i.e	O
.	O
a	O
set	O
of	O
|k|	O
particles	O
,	O
that	O
is	O
in	O
a	O
state	B
is	O
automatically	O
looking	O
for	O
a	O
minimum	O
.	O
an	O
input	O
pattern	O
of	O
a	O
hopﬁeld	O
network	O
is	O
exactly	O
such	O
a	O
state	B
:	O
a	O
binary	O
string	O
x	O
∈	O
{	O
−1	O
,	O
1	O
}	O
|k|	O
that	O
initializes	O
the	O
neurons	O
.	O
then	O
the	O
network	O
is	O
looking	O
for	O
the	O
min-	O
imum	O
to	O
be	O
taken	O
(	O
which	O
we	O
have	O
previ-	O
ously	O
deﬁned	O
by	O
the	O
input	O
of	O
training	O
sam-	O
ples	O
)	O
on	O
its	O
energy	O
surface	O
.	O
but	O
when	O
do	O
we	O
know	O
that	O
the	O
minimum	O
has	O
been	O
found	O
?	O
this	O
is	O
simple	O
,	O
too	O
:	O
when	O
the	O
network	O
stops	O
.	O
it	O
can	O
be	O
proven	O
that	O
a	O
hopﬁeld	O
network	O
with	O
a	O
symmetric	O
weight	B
matrix	I
that	O
has	O
zeros	O
on	O
its	O
diagonal	O
al-	O
ways	O
converges	O
[	O
cg88	O
]	O
,	O
i.e	O
.	O
at	O
some	O
point	O
it	O
will	O
stand	O
still	O
.	O
then	O
the	O
output	O
is	O
a	O
binary	O
string	O
y	O
∈	O
{	O
−1	O
,	O
1	O
}	O
|k|	O
,	O
namely	O
the	O
state	B
string	O
of	O
the	O
network	O
that	O
has	O
found	O
a	O
minimum	O
.	O
130	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
input	O
and	O
output	O
=	O
network	O
states	O
always	O
converges	O
completely	O
linked	O
set	O
of	O
neurons	O
i	O
	O
	O
i	O
i	O
)	O
o	O
o	O
	O
	O
o	O
o	O
/	O
/	O
^	O
^	O
5	O
u	O
o	O
o	O
	O
	O
@	O
@	O
 	O
^	O
^	O
i	O
)	O
o	O
/	O
/	O
 	O
 	O
@	O
4	O
j	O
j	O
5	O
5	O
u	O
/	O
o	O
o	O
@	O
@	O
 	O
6	O
6	O
 	O
 	O
@	O
^	O
/	O
o	O
o	O
^	O
dkriesel.com	O
8.2	O
structure	O
and	O
functionality	O
now	O
let	O
us	O
take	O
a	O
closer	O
look	O
at	O
the	O
con-	O
tents	O
of	O
the	O
weight	B
matrix	I
and	O
the	O
rules	O
for	O
the	O
state	B
change	O
of	O
the	O
neurons	O
.	O
deﬁnition	O
8.3	O
(	O
input	O
and	O
output	O
of	O
a	O
hopﬁeld	O
network	O
)	O
.	O
the	O
input	O
of	O
a	O
hopﬁeld	O
network	O
is	O
binary	O
string	O
x	O
∈	O
{	O
−1	O
,	O
1	O
}	O
|k|	O
that	O
initializes	O
the	O
state	B
of	O
the	O
network	O
.	O
after	O
the	O
convergence	O
of	O
the	O
network	O
,	O
the	O
output	O
is	O
the	O
binary	O
string	O
y	O
∈	O
{	O
−1	O
,	O
1	O
}	O
|k|	O
generated	O
from	O
the	O
new	O
net-	O
work	O
state	B
.	O
8.2.2	O
signiﬁcance	O
of	O
weights	O
i.e	O
.	O
we	O
have	O
already	O
said	O
that	O
the	O
neurons	O
change	O
their	O
states	O
,	O
their	O
direction	O
,	O
from	O
−1	O
to	O
1	O
or	O
vice	O
versa	O
.	O
these	O
spins	O
oc-	O
cur	O
dependent	O
on	O
the	O
current	O
states	O
of	O
the	O
other	O
neurons	O
and	O
the	O
associated	O
weights	O
.	O
thus	O
,	O
the	O
weights	O
are	O
capable	O
to	O
control	O
the	O
complete	O
change	O
of	O
the	O
network	O
.	O
the	O
weights	O
can	O
be	O
positive	O
,	O
negative	O
,	O
or	O
0.	O
colloquially	O
speaking	O
,	O
for	O
a	O
weight	B
wi	O
,	O
j	O
be-	O
tween	O
two	O
neurons	O
i	O
and	O
j	O
the	O
following	O
holds	O
:	O
if	O
wi	O
,	O
j	O
is	O
positive	O
,	O
it	O
will	O
try	O
to	O
force	O
the	O
two	O
neurons	O
to	O
become	O
equal	O
–	O
the	O
larger	O
they	O
are	O
,	O
the	O
harder	O
the	O
net-	O
work	O
will	O
try	O
.	O
if	O
the	O
neuron	O
i	O
is	O
in	O
state	B
1	O
and	O
the	O
neuron	O
j	O
is	O
in	O
state	B
−1	O
,	O
a	O
high	O
positive	O
weight	B
will	O
advise	O
the	O
two	O
neurons	O
that	O
it	O
is	O
energeti-	O
cally	O
more	O
favorable	O
to	O
be	O
equal	O
.	O
if	O
wi	O
,	O
j	O
is	O
negative	O
,	O
its	O
behavior	O
will	O
be	O
analoguous	O
only	O
that	O
i	O
and	O
j	O
are	O
urged	O
to	O
be	O
diﬀerent	O
.	O
a	O
neuron	O
i	O
in	O
state	B
−1	O
would	O
try	O
to	O
urge	O
a	O
neuron	O
j	O
into	O
state	B
1	O
.	O
x	O
j∈k	O
	O
(	O
8.1	O
)	O
zero	O
weights	O
lead	O
to	O
the	O
two	O
involved	O
neurons	O
not	O
inﬂuencing	O
each	O
other	O
.	O
the	O
weights	O
as	O
a	O
whole	O
apparently	O
take	O
the	O
way	O
from	O
the	O
current	O
state	B
of	O
the	O
net-	O
work	O
towards	O
the	O
next	O
minimum	O
of	O
the	O
en-	O
ergy	O
function	B
.	O
we	O
now	O
want	O
to	O
discuss	O
how	O
the	O
neurons	O
follow	O
this	O
way	O
.	O
8.2.3	O
a	O
neuron	O
changes	O
its	O
state	B
according	O
to	O
the	O
inﬂuence	O
of	O
the	O
other	O
neurons	O
once	O
a	O
network	O
has	O
been	O
trained	O
and	O
initialized	O
with	O
some	O
starting	O
state	B
,	O
the	O
change	O
of	O
state	B
xk	O
of	O
the	O
individual	O
neu-	O
rons	O
k	O
occurs	O
according	O
to	O
the	O
scheme	O
xk	O
(	O
t	O
)	O
=	O
fact	O
wj	O
,	O
k	O
·	O
xj	O
(	O
t	O
−	O
1	O
)	O
in	O
each	O
time	O
step	O
,	O
where	O
the	O
function	B
fact	O
generally	O
is	O
the	O
binary	B
threshold	I
function	I
(	O
ﬁg	O
.	O
8.2	O
on	O
the	O
next	O
page	O
)	O
with	O
threshold	O
0.	O
colloquially	O
speaking	O
:	O
a	O
neuron	O
k	O
cal-	O
culates	O
the	O
sum	O
of	O
wj	O
,	O
k	O
·	O
xj	O
(	O
t	O
−	O
1	O
)	O
,	O
which	O
indicates	O
how	O
strong	O
and	O
into	O
which	O
direc-	O
tion	O
the	O
neuron	O
k	O
is	O
forced	O
by	O
the	O
other	O
neurons	O
j.	O
thus	O
,	O
the	O
new	O
state	B
of	O
the	O
net-	O
work	O
(	O
time	O
t	O
)	O
results	O
from	O
the	O
state	B
of	O
the	O
network	O
at	O
the	O
previous	O
time	O
t	O
−	O
1.	O
this	O
sum	O
is	O
the	O
direction	O
into	O
which	O
the	O
neuron	O
k	O
is	O
pushed	O
.	O
depending	O
on	O
the	O
sign	O
of	O
the	O
sum	O
the	O
neuron	O
takes	O
state	B
1	O
or	O
−1	O
.	O
another	O
diﬀerence	O
between	O
hopﬁeld	O
net-	O
works	O
and	O
other	O
already	O
known	O
network	O
topologies	O
is	O
the	O
asynchronous	O
update	O
:	O
a	O
neuron	O
k	O
is	O
randomly	O
chosen	O
every	O
time	O
,	O
which	O
then	O
recalculates	O
the	O
activation	B
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
131	O
chapter	O
8	O
hopﬁeld	O
networks	O
dkriesel.com	O
a	O
minimum	O
,	O
then	O
there	O
is	O
the	O
question	O
of	O
how	O
to	O
teach	O
the	O
weights	O
to	O
force	O
the	O
net-	O
work	O
towards	O
a	O
certain	O
minimum	O
.	O
8.3	O
the	O
weight	B
matrix	I
is	O
generated	O
directly	O
out	O
of	O
the	O
training	O
patterns	O
figure	O
8.2	O
:	O
illustration	O
of	O
the	O
binary	B
threshold	I
function	I
.	O
thus	O
,	O
the	O
new	O
activation	B
of	O
the	O
previously	O
changed	O
neurons	O
immediately	O
inﬂuences	O
the	O
network	O
,	O
i.e	O
.	O
one	O
time	O
step	O
indicates	O
the	O
change	O
of	O
a	O
single	O
neuron	O
.	O
regardless	O
of	O
the	O
aforementioned	O
random	O
selection	O
of	O
the	O
neuron	O
,	O
a	O
hopﬁeld	O
net-	O
work	O
is	O
often	O
much	O
easier	O
to	O
implement	O
:	O
the	O
neurons	O
are	O
simply	O
processed	O
one	O
af-	O
ter	O
the	O
other	O
and	O
their	O
activations	O
are	O
re-	O
calculated	O
until	O
no	O
more	O
changes	O
occur	O
.	O
deﬁnition	O
8.4	O
(	O
change	O
in	O
the	O
state	B
of	O
a	O
hopﬁeld	O
network	O
)	O
.	O
the	O
change	O
of	O
state	B
of	O
the	O
neurons	O
occurs	O
asynchronously	O
with	O
the	O
neuron	O
to	O
be	O
updated	O
being	O
randomly	O
chosen	O
and	O
the	O
new	O
state	B
being	O
generated	O
by	O
means	O
of	O
this	O
rule	O
:	O
xk	O
(	O
t	O
)	O
=	O
fact	O
wj	O
,	O
k	O
·	O
xj	O
(	O
t	O
−	O
1	O
)	O
x	O
j∈j	O
	O
.	O
the	O
aim	O
is	O
to	O
generate	O
minima	O
on	O
the	O
mentioned	O
energy	O
surface	O
,	O
so	O
that	O
at	O
an	O
input	O
the	O
network	O
can	O
converge	O
to	O
them	O
.	O
as	O
with	O
many	O
other	O
network	O
paradigms	O
,	O
we	O
use	O
a	O
set	O
p	O
of	O
training	O
patterns	O
p	O
∈	O
{	O
1	O
,	O
−1	O
}	O
|k|	O
,	O
representing	O
the	O
minima	O
of	O
our	O
energy	O
surface	O
.	O
unlike	O
many	O
other	O
network	O
paradigms	O
,	O
we	O
do	O
not	O
look	O
for	O
the	O
minima	O
of	O
an	O
unknown	O
error	B
function	I
but	O
deﬁne	O
minima	O
on	O
such	O
a	O
function	B
.	O
the	O
purpose	O
is	O
that	O
the	O
network	O
shall	O
automatically	O
take	O
the	O
closest	O
min-	O
imum	O
when	O
the	O
input	O
is	O
presented	O
.	O
for	O
now	O
this	O
seems	O
unusual	O
,	O
but	O
we	O
will	O
un-	O
derstand	O
the	O
whole	O
purpose	O
later	O
.	O
roughly	O
speaking	O
,	O
the	O
training	O
of	O
a	O
hop-	O
ﬁeld	O
network	O
is	O
done	O
by	O
training	O
each	O
train-	O
ing	O
pattern	B
exactly	O
once	O
using	O
the	O
rule	O
described	O
in	O
the	O
following	O
(	O
single	O
shot	O
learning	B
)	O
,	O
where	O
pi	O
and	O
pj	O
are	O
the	O
states	O
of	O
the	O
neurons	O
i	O
and	O
j	O
under	O
p	O
∈	O
p	O
:	O
wi	O
,	O
j	O
=	O
x	O
p∈p	O
pi	O
·	O
pj	O
(	O
8.2	O
)	O
random	O
neuron	O
calculates	O
new	O
activation	B
now	O
that	O
we	O
know	O
how	O
the	O
weights	O
inﬂu-	O
ence	O
the	O
changes	O
in	O
the	O
states	O
of	O
the	O
neu-	O
rons	O
and	O
force	O
the	O
entire	O
network	O
towards	O
this	O
results	O
in	O
the	O
weight	B
matrix	I
w.	O
col-	O
loquially	O
speaking	O
:	O
we	O
initialize	O
the	O
net-	O
work	O
by	O
means	O
of	O
a	O
training	B
pattern	I
and	O
then	O
process	O
weights	O
wi	O
,	O
j	O
one	O
after	O
another	O
.	O
132	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
−1−0.5	O
0	O
0.5	O
1−4−2	O
0	O
2	O
4f	O
(	O
x	O
)	O
xheaviside	O
function	B
dkriesel.com	O
8.4	O
autoassociation	O
and	O
traditional	O
application	O
for	O
each	O
of	O
these	O
weights	O
we	O
verify	O
:	O
are	O
the	O
neurons	O
i	O
,	O
j	O
n	O
the	O
same	O
state	B
or	O
do	O
the	O
states	O
vary	O
?	O
in	O
the	O
ﬁrst	O
case	O
we	O
add	O
1	O
to	O
the	O
weight	B
,	O
in	O
the	O
second	O
case	O
we	O
add	O
−1	O
.	O
this	O
we	O
repeat	O
for	O
each	O
training	B
pattern	I
p	O
∈	O
p.	O
finally	O
,	O
the	O
values	O
of	O
the	O
weights	O
wi	O
,	O
j	O
are	O
high	O
when	O
i	O
and	O
j	O
corresponded	O
with	O
many	O
training	O
patterns	O
.	O
colloquially	O
speaking	O
,	O
this	O
high	O
value	O
tells	O
the	O
neurons	O
:	O
''	O
often	O
,	O
it	O
is	O
energetically	O
favorable	O
to	O
hold	O
the	O
same	O
state	B
''	O
.	O
the	O
same	O
applies	O
to	O
neg-	O
ative	O
weights	O
.	O
due	O
to	O
this	O
training	O
we	O
can	O
store	O
a	O
certain	O
ﬁxed	O
number	O
of	O
patterns	O
p	O
in	O
the	O
weight	B
matrix	I
.	O
at	O
an	O
input	O
x	O
the	O
network	O
will	O
converge	O
to	O
the	O
stored	O
pattern	B
that	O
is	O
clos-	O
est	O
to	O
the	O
input	O
p.	O
unfortunately	O
,	O
the	O
number	O
of	O
the	O
maxi-	O
mum	O
storable	O
and	O
reconstructible	O
patterns	O
p	O
is	O
limited	O
to	O
|p|max	O
≈	O
0.139	O
·	O
|k|	O
,	O
(	O
8.3	O
)	O
which	O
in	O
turn	O
only	O
applies	O
to	O
orthogo-	O
nal	O
patterns	O
.	O
this	O
was	O
shown	O
by	O
precise	O
(	O
and	O
time-consuming	O
)	O
mathematical	O
anal-	O
yses	O
,	O
which	O
we	O
do	O
not	O
want	O
to	O
specify	O
now	O
.	O
if	O
more	O
patterns	O
are	O
entered	O
,	O
already	O
stored	O
information	O
will	O
be	O
destroyed	O
.	O
deﬁnition	O
8.5	O
(	O
learning	B
rule	O
for	O
hop-	O
ﬁeld	O
networks	O
)	O
.	O
the	O
individual	O
elements	O
of	O
the	O
weight	B
matrix	I
w	O
are	O
deﬁned	O
by	O
a	O
single	O
processing	O
of	O
the	O
learning	B
rule	O
wi	O
,	O
j	O
=	O
x	O
p∈p	O
pi	O
·	O
pj	O
,	O
where	O
the	O
diagonal	O
of	O
the	O
matrix	O
is	O
covered	O
with	O
zeros	O
.	O
here	O
,	O
no	O
more	O
than	O
|p|max	O
≈	O
0.139·|k|	O
training	O
samples	O
can	O
be	O
trained	O
and	O
at	O
the	O
same	O
time	O
maintain	O
their	O
func-	O
tion	O
.	O
now	O
we	O
know	O
the	O
functionality	O
of	O
hopﬁeld	O
networks	O
but	O
nothing	O
about	O
their	O
practical	O
use	O
.	O
8.4	O
autoassociation	O
and	O
traditional	O
application	O
hopﬁeld	O
networks	O
,	O
like	O
those	O
mentioned	O
above	O
,	O
are	O
called	O
autoassociators	O
.	O
an	O
autoassociator	B
a	O
exactly	O
shows	O
the	O
afore-	O
(	O
cid:74	O
)	O
a	O
mentioned	O
behavior	O
:	O
firstly	O
,	O
when	O
a	O
known	O
pattern	B
p	O
is	O
entered	O
,	O
exactly	O
this	O
known	O
pattern	B
is	O
returned	O
.	O
thus	O
,	O
a	O
(	O
p	O
)	O
=	O
p	O
,	O
with	O
a	O
being	O
the	O
associative	O
mapping	O
.	O
sec-	O
ondly	O
,	O
and	O
that	O
is	O
the	O
practical	O
use	O
,	O
this	O
also	O
works	O
with	O
inputs	O
that	O
are	O
close	O
to	O
a	O
pattern	B
:	O
a	O
(	O
p	O
+	O
ε	O
)	O
=	O
p.	O
afterwards	O
,	O
the	O
autoassociator	B
is	O
,	O
in	O
any	O
case	O
,	O
in	O
a	O
stable	O
state	B
,	O
namely	O
in	O
the	O
state	B
p.	O
if	O
the	O
set	O
of	O
patterns	O
p	O
consists	O
of	O
,	O
for	O
ex-	O
ample	O
,	O
letters	O
or	O
other	O
characters	O
in	O
the	O
form	O
of	O
pixels	O
,	O
the	O
network	O
will	O
be	O
able	O
to	O
correctly	O
recognize	O
deformed	O
or	O
noisy	O
let-	O
ters	O
with	O
high	O
probability	O
(	O
ﬁg	O
.	O
8.3	O
on	O
the	O
following	O
page	O
)	O
.	O
the	O
primary	O
ﬁelds	O
of	O
application	O
of	O
hop-	O
ﬁeld	O
networks	O
are	O
pattern	B
recognition	I
and	O
pattern	B
completion	O
,	O
such	O
as	O
the	O
zip	O
network	O
restores	O
damaged	O
inputs	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
133	O
chapter	O
8	O
hopﬁeld	O
networks	O
dkriesel.com	O
code	O
recognition	O
on	O
letters	O
in	O
the	O
eighties	O
.	O
but	O
soon	O
the	O
hopﬁeld	O
networks	O
were	O
re-	O
placed	O
by	O
other	O
systems	O
in	O
most	O
of	O
their	O
ﬁelds	O
of	O
application	O
,	O
for	O
example	O
by	O
ocr	O
systems	O
in	O
the	O
ﬁeld	O
of	O
letter	O
recognition	O
.	O
today	O
hopﬁeld	O
networks	O
are	O
virtually	O
no	O
longer	O
used	O
,	O
they	O
have	O
not	O
become	O
estab-	O
lished	O
in	O
practice	O
.	O
8.5	O
heteroassociation	O
and	O
analogies	O
to	O
neural	O
data	O
storage	O
so	O
far	O
we	O
have	O
been	O
introduced	O
to	O
hopﬁeld	O
networks	O
that	O
converge	O
from	O
an	O
arbitrary	O
input	O
into	O
the	O
closest	O
minimum	O
of	O
a	O
static	O
energy	O
surface	O
.	O
another	O
variant	O
is	O
a	O
dynamic	O
energy	O
sur-	O
face	O
:	O
here	O
,	O
the	O
appearance	O
of	O
the	O
energy	O
surface	O
depends	O
on	O
the	O
current	O
state	B
and	O
we	O
receive	O
a	O
heteroassociator	B
instead	O
of	O
an	O
autoassociator	B
.	O
for	O
a	O
heteroassocia-	O
tor	O
a	O
(	O
p	O
+	O
ε	O
)	O
=	O
p	O
is	O
no	O
longer	O
true	O
,	O
but	O
rather	O
h	O
(	O
p	O
+	O
ε	O
)	O
=	O
q	O
,	O
which	O
means	O
that	O
a	O
pattern	B
is	O
mapped	O
onto	O
another	O
one	O
.	O
h	O
is	O
the	O
heteroasso-	O
(	O
cid:74	O
)	O
h	O
ciative	O
mapping	O
.	O
such	O
heteroassociations	O
are	O
achieved	O
by	O
means	O
of	O
an	O
asymmetric	O
weight	B
matrix	I
v	O
.	O
figure	O
8.3	O
:	O
illustration	O
of	O
the	O
convergence	O
of	O
an	O
exemplary	O
hopﬁeld	O
network	O
.	O
each	O
of	O
the	O
pic-	O
tures	O
has	O
10	O
×	O
12	O
=	O
120	O
binary	O
pixels	O
.	O
in	O
the	O
hopﬁeld	O
network	O
each	O
pixel	O
corresponds	O
to	O
one	O
neuron	O
.	O
the	O
upper	O
illustration	O
shows	O
the	O
train-	O
ing	O
samples	O
,	O
the	O
lower	O
shows	O
the	O
convergence	O
of	O
a	O
heavily	O
noisy	O
3	O
to	O
the	O
corresponding	O
training	O
sample	O
.	O
134	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
8.5	O
heteroassociation	O
and	O
analogies	O
to	O
neural	O
data	O
storage	O
heteroassociations	O
connected	O
in	O
series	O
of	O
the	O
form	O
h	O
(	O
p	O
+	O
ε	O
)	O
=	O
q	O
h	O
(	O
q	O
+	O
ε	O
)	O
=	O
r	O
h	O
(	O
r	O
+	O
ε	O
)	O
=	O
s	O
...	O
h	O
(	O
z	O
+	O
ε	O
)	O
=	O
p	O
can	O
provoke	O
a	O
fast	O
cycle	O
of	O
states	O
p	O
→	O
q	O
→	O
r	O
→	O
s	O
→	O
.	O
.	O
.	O
→	O
z	O
→	O
p	O
,	O
whereby	O
a	O
single	O
pattern	O
is	O
never	O
com-	O
pletely	O
accepted	O
:	O
before	O
a	O
pattern	B
is	O
en-	O
tirely	O
completed	O
,	O
the	O
heteroassociation	O
al-	O
ready	O
tries	O
to	O
generate	O
the	O
successor	O
of	O
this	O
pattern	B
.	O
additionally	O
,	O
the	O
network	O
would	O
never	O
stop	O
,	O
since	O
after	O
having	O
reached	O
the	O
last	O
state	B
z	O
,	O
it	O
would	O
proceed	O
to	O
the	O
ﬁrst	O
state	B
p	O
again	O
.	O
8.5.1	O
generating	O
the	O
heteroassociative	O
matrix	O
v	O
(	O
cid:73	O
)	O
v	O
(	O
cid:73	O
)	O
q	O
(	O
cid:73	O
)	O
we	O
generate	O
the	O
matrix	O
v	O
by	O
means	O
of	O
el-	O
ements	O
v	O
very	O
similar	O
to	O
the	O
autoassocia-	O
tive	O
matrix	O
with	O
p	O
being	O
(	O
per	O
transition	O
)	O
the	O
training	O
sample	O
before	O
the	O
transition	O
and	O
q	O
being	O
the	O
training	O
sample	O
to	O
be	O
gen-	O
erated	O
from	O
p	O
:	O
vi	O
,	O
j	O
=	O
x	O
p	O
,	O
q∈p	O
,	O
p6=q	O
piqj	O
(	O
8.4	O
)	O
netword	O
is	O
instable	O
while	O
changing	O
states	O
the	O
diagonal	O
of	O
the	O
matrix	O
is	O
again	O
ﬁlled	O
with	O
zeros	O
.	O
the	O
neuron	O
states	O
are	O
,	O
as	O
al-	O
ways	O
,	O
adapted	O
during	O
operation	O
.	O
several	O
transitions	O
can	O
be	O
introduced	O
into	O
the	O
ma-	O
trix	O
by	O
a	O
simple	O
addition	O
,	O
whereby	O
the	O
said	O
limitation	O
exists	O
here	O
,	O
too	O
.	O
deﬁnition	O
8.6	O
(	O
learning	B
rule	O
for	O
the	O
het-	O
eroassociative	O
matrix	O
)	O
.	O
for	O
two	O
training	O
samples	O
p	O
being	O
predecessor	O
and	O
q	O
being	O
successor	O
of	O
a	O
heteroassociative	O
transition	O
the	O
weights	O
of	O
the	O
heteroassociative	O
matrix	O
v	O
result	O
from	O
the	O
learning	B
rule	O
vi	O
,	O
j	O
=	O
x	O
piqj	O
,	O
p	O
,	O
q∈p	O
,	O
p6=q	O
with	O
several	O
heteroassociations	O
being	O
intro-	O
duced	O
into	O
the	O
network	O
by	O
a	O
simple	O
addi-	O
tion	O
.	O
8.5.2	O
stabilizing	O
the	O
heteroassociations	O
we	O
have	O
already	O
mentioned	O
the	O
problem	O
that	O
the	O
patterns	O
are	O
not	O
completely	O
gen-	O
erated	O
but	O
that	O
the	O
next	O
pattern	B
is	O
already	O
beginning	O
before	O
the	O
generation	O
of	O
the	O
pre-	O
vious	O
pattern	B
is	O
ﬁnished	O
.	O
this	O
problem	O
can	O
be	O
avoided	O
by	O
not	O
only	O
inﬂuencing	O
the	O
network	O
by	O
means	O
of	O
the	O
heteroassociative	O
matrix	O
v	O
but	O
also	O
by	O
the	O
already	O
known	O
autoassociative	O
matrix	O
w.	O
additionally	O
,	O
the	O
neuron	O
adaptation	O
rule	O
is	O
changed	O
so	O
that	O
competing	O
terms	O
are	O
generated	O
:	O
one	O
term	O
autoassociating	O
an	O
existing	O
pattern	B
and	O
one	O
term	O
trying	O
to	O
convert	O
the	O
very	O
same	O
pattern	B
into	O
its	O
suc-	O
cessor	O
.	O
the	O
associative	O
rule	O
provokes	O
that	O
the	O
network	O
stabilizes	O
a	O
pattern	B
,	O
remains	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
135	O
chapter	O
8	O
hopﬁeld	O
networks	O
dkriesel.com	O
there	O
for	O
a	O
while	O
,	O
goes	O
on	O
to	O
the	O
next	O
pat-	O
tern	O
,	O
and	O
so	O
on	O
.	O
xi	O
(	O
t	O
+	O
1	O
)	O
=	O
(	O
8.5	O
)	O
	O
x	O
|	O
fact	O
wi	O
,	O
jxj	O
(	O
t	O
)	O
j∈k	O
autoassociation	O
{	O
z	O
	O
+x	O
|	O
k∈k	O
}	O
vi	O
,	O
kxk	O
(	O
t	O
−	O
∆t	O
)	O
{	O
z	O
}	O
heteroassociation	O
∆t	O
(	O
cid:73	O
)	O
stable	O
change	O
in	O
states	O
here	O
,	O
the	O
value	O
∆t	O
causes	O
,	O
descriptively	O
speaking	O
,	O
the	O
inﬂuence	O
of	O
the	O
matrix	O
v	O
to	O
be	O
delayed	O
,	O
since	O
it	O
only	O
refers	O
to	O
a	O
network	O
being	O
∆t	O
versions	O
behind	O
.	O
the	O
result	O
is	O
a	O
change	O
in	O
state	O
,	O
during	O
which	O
the	O
individual	O
states	O
are	O
stable	O
for	O
a	O
short	O
while	O
.	O
if	O
∆t	O
is	O
set	O
to	O
,	O
for	O
example	O
,	O
twenty	O
steps	O
,	O
then	O
the	O
asymmetric	O
weight	B
matrix	I
will	O
realize	O
any	O
change	O
in	O
the	O
network	O
only	O
twenty	O
steps	O
later	O
so	O
that	O
it	O
initially	O
works	O
with	O
the	O
autoassociative	O
matrix	O
(	O
since	O
it	O
still	O
perceives	O
the	O
predecessor	O
pattern	B
of	O
the	O
current	O
one	O
)	O
,	O
and	O
only	O
after	O
that	O
it	O
will	O
work	O
against	O
it	O
.	O
8.5.3	O
biological	O
motivation	O
of	O
heterassociation	O
from	O
a	O
biological	O
point	O
of	O
view	O
the	O
transi-	O
tion	O
of	O
stable	O
states	O
into	O
other	O
stable	O
states	O
is	O
highly	O
motivated	O
:	O
at	O
least	O
in	O
the	O
begin-	O
ning	O
of	O
the	O
nineties	O
it	O
was	O
assumed	O
that	O
the	O
hopﬁeld	O
modell	O
will	O
achieve	O
an	O
ap-	O
proximation	O
of	O
the	O
state	B
dynamics	O
in	O
the	O
brain	B
,	O
which	O
realizes	O
much	O
by	O
means	O
of	O
state	B
chains	O
:	O
when	O
i	O
would	O
ask	O
you	O
,	O
dear	O
reader	O
,	O
to	O
recite	O
the	O
alphabet	O
,	O
you	O
gener-	O
ally	O
will	O
manage	O
this	O
better	O
than	O
(	O
please	O
try	O
it	O
immediately	O
)	O
to	O
answer	O
the	O
follow-	O
ing	O
question	O
:	O
which	O
letter	O
in	O
the	O
alphabet	O
follows	O
the	O
letter	O
p	O
?	O
another	O
example	O
is	O
the	O
phenomenon	O
that	O
one	O
can	O
not	O
remember	O
a	O
situation	B
,	O
but	O
the	O
place	O
at	O
which	O
one	O
memorized	B
it	O
the	O
last	O
time	O
is	O
perfectly	O
known	O
.	O
if	O
one	O
returns	O
to	O
this	O
place	O
,	O
the	O
forgotten	O
situation	B
often	O
comes	O
back	O
to	O
mind	O
.	O
8.6	O
continuous	B
hopﬁeld	O
networks	O
so	O
far	O
,	O
we	O
only	O
have	O
discussed	O
hopﬁeld	O
net-	O
works	O
with	O
binary	O
activations	O
.	O
but	O
hop-	O
ﬁeld	O
also	O
described	O
a	O
version	O
of	O
his	O
net-	O
works	O
with	O
continuous	B
activations	O
[	O
hop84	O
]	O
,	O
which	O
we	O
want	O
to	O
cover	O
at	O
least	O
brieﬂy	O
:	O
continuous	B
hopﬁeld	O
networks	O
.	O
here	O
,	O
the	O
activation	B
is	O
no	O
longer	O
calculated	O
by	O
the	O
binary	B
threshold	I
function	I
but	O
by	O
the	O
fermi	O
function	B
with	O
temperature	O
parame-	O
ters	O
(	O
ﬁg	O
.	O
8.4	O
on	O
the	O
next	O
page	O
)	O
.	O
here	O
,	O
the	O
network	O
is	O
stable	O
for	O
symmetric	O
weight	B
matrices	O
with	O
zeros	O
on	O
the	O
diagonal	O
,	O
too	O
.	O
hopﬁeld	O
also	O
stated	O
,	O
that	O
continuous	B
hop-	O
ﬁeld	O
networks	O
can	O
be	O
applied	O
to	O
ﬁnd	O
ac-	O
ceptable	O
solutions	O
for	O
the	O
np-hard	O
trav-	O
elling	O
salesman	O
problem	O
[	O
ht85	O
]	O
.	O
accord-	O
ing	O
to	O
some	O
veriﬁcation	O
trials	O
[	O
zel94	O
]	O
this	O
statement	O
can	O
’	O
t	O
be	O
kept	O
up	O
any	O
more	O
.	O
but	O
today	O
there	O
are	O
faster	O
algorithms	O
for	O
han-	O
dling	O
this	O
problem	O
and	O
therefore	O
the	O
hop-	O
ﬁeld	O
network	O
is	O
no	O
longer	O
used	O
here	O
.	O
136	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
8.6	O
continuous	B
hopﬁeld	O
networks	O
figure	O
8.4	O
:	O
the	O
already	O
known	O
fermi	O
function	B
with	O
diﬀerent	O
temperature	O
parameter	O
variations	O
.	O
exercises	O
exercise	O
14.	O
indicate	O
the	O
storage	O
re-	O
quirements	O
for	O
a	O
hopﬁeld	O
network	O
with	O
|k|	O
=	O
1000	O
neurons	O
when	O
the	O
weights	O
wi	O
,	O
j	O
shall	O
be	O
stored	O
as	O
integers	O
.	O
is	O
it	O
possible	O
to	O
limit	O
the	O
value	O
range	O
of	O
the	O
weights	O
in	O
order	O
to	O
save	O
storage	O
space	O
?	O
exercise	O
15.	O
compute	O
the	O
weights	O
wi	O
,	O
j	O
for	O
a	O
hopﬁeld	O
network	O
using	O
the	O
training	B
set	I
p	O
=	O
{	O
(	O
−1	O
,	O
−1	O
,	O
−1	O
,	O
−1	O
,	O
−1	O
,	O
1	O
)	O
;	O
(	O
−1	O
,	O
1	O
,	O
1	O
,	O
−1	O
,	O
−1	O
,	O
−1	O
)	O
;	O
(	O
1	O
,	O
−1	O
,	O
−1	O
,	O
1	O
,	O
−1	O
,	O
1	O
)	O
}	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
137	O
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1−4−2	O
0	O
2	O
4f	O
(	O
x	O
)	O
xfermi	O
function	B
with	O
temperature	O
parameter	O
chapter	O
9	O
learning	B
vector	I
quantization	I
learning	O
vector	O
quantization	B
is	O
a	O
learning	B
procedure	O
with	O
the	O
aim	O
to	O
represent	O
the	O
vector	O
training	O
sets	O
divided	O
into	O
predeﬁned	O
classes	O
as	O
well	O
as	O
possible	O
by	O
using	O
a	O
few	O
representative	O
vectors	O
.	O
if	O
this	O
has	O
been	O
managed	O
,	O
vectors	O
which	O
were	O
unkown	O
until	O
then	O
could	O
easily	O
be	O
assigned	O
to	O
one	O
of	O
these	O
classes	O
.	O
slowly	O
,	O
part	O
ii	O
of	O
this	O
text	O
is	O
nearing	O
its	O
end	O
–	O
and	O
therefore	O
i	O
want	O
to	O
write	O
a	O
last	O
chapter	O
for	O
this	O
part	O
that	O
will	O
be	O
a	O
smooth	O
transition	O
into	O
the	O
next	O
one	O
:	O
a	O
chapter	O
about	O
the	O
learning	B
vector	I
quantization	I
(	O
abbreviated	O
lvq	O
)	O
[	O
koh89	O
]	O
described	O
by	O
teuvo	O
kohonen	O
,	O
which	O
can	O
be	O
charac-	O
terized	O
as	O
being	O
related	O
to	O
the	O
self	O
orga-	O
nizing	O
feature	O
maps	O
.	O
these	O
soms	O
are	O
de-	O
scribed	O
in	O
the	O
next	O
chapter	O
that	O
already	O
belongs	O
to	O
part	O
iii	O
of	O
this	O
text	O
,	O
since	O
soms	O
learn	O
unsupervised	O
.	O
thus	O
,	O
after	O
the	O
explo-	O
ration	O
of	O
lvq	O
i	O
want	O
to	O
bid	O
farewell	O
to	O
supervised	B
learning	I
.	O
previously	O
,	O
i	O
want	O
to	O
announce	O
that	O
there	O
are	O
diﬀerent	O
variations	O
of	O
lvq	O
,	O
which	O
will	O
be	O
mentioned	O
but	O
not	O
exactly	O
represented	O
.	O
the	O
goal	O
of	O
this	O
chapter	O
is	O
rather	O
to	O
ana-	O
lyze	O
the	O
underlying	O
principle	O
.	O
9.1	O
about	O
quantization	B
in	O
order	O
to	O
explore	O
the	O
learning	B
vec-	O
tor	O
quantization	B
we	O
should	O
at	O
ﬁrst	O
get	O
a	O
clearer	O
picture	O
of	O
what	O
quantization	B
(	O
which	O
can	O
also	O
be	O
referred	O
to	O
as	O
dis-	O
cretization	O
)	O
is	O
.	O
everybody	O
knows	O
the	O
sequence	O
of	O
discrete	B
numbers	O
n	O
=	O
{	O
1	O
,	O
2	O
,	O
3	O
,	O
.	O
.	O
.	O
}	O
,	O
which	O
contains	O
the	O
natural	O
numbers	O
.	O
dis-	O
crete	O
means	O
,	O
that	O
this	O
sequence	O
consists	O
of	O
separated	O
elements	O
that	O
are	O
not	O
intercon-	O
nected	O
.	O
the	O
elements	O
of	O
our	O
example	O
are	O
exactly	O
such	O
numbers	O
,	O
because	O
the	O
natural	O
numbers	O
do	O
not	O
include	O
,	O
for	O
example	O
,	O
num-	O
bers	O
between	O
1	O
and	O
2.	O
on	O
the	O
other	O
hand	O
,	O
the	O
sequence	O
of	O
real	O
numbers	O
r	O
,	O
for	O
in-	O
stance	O
,	O
is	O
continuous	B
:	O
it	O
does	O
not	O
matter	O
how	O
close	O
two	O
selected	O
numbers	O
are	O
,	O
there	O
will	O
always	O
be	O
a	O
number	O
between	O
them	O
.	O
139	O
discrete	B
=	O
separated	O
chapter	O
9	O
learning	B
vector	I
quantization	I
dkriesel.com	O
quantization	B
means	O
that	O
a	O
continuous	B
space	O
is	O
divided	O
into	O
discrete	B
sections	O
:	O
by	O
deleting	O
,	O
for	O
example	O
,	O
all	O
decimal	O
places	O
of	O
the	O
real	O
number	O
2.71828	O
,	O
it	O
could	O
be	O
assigned	O
to	O
the	O
natural	O
number	O
2.	O
here	O
it	O
is	O
obvious	O
that	O
any	O
other	O
number	O
hav-	O
ing	O
a	O
2	O
in	O
front	O
of	O
the	O
comma	O
would	O
also	O
be	O
assigned	O
to	O
the	O
natural	O
number	O
2	O
,	O
i.e	O
.	O
2	O
would	O
be	O
some	O
kind	O
of	O
representative	O
for	O
all	O
real	O
numbers	O
within	O
the	O
interval	O
[	O
2	O
;	O
3	O
)	O
.	O
it	O
must	O
be	O
noted	O
that	O
a	O
sequence	O
can	O
be	O
ir-	O
regularly	O
quantized	O
,	O
too	O
:	O
for	O
instance	O
,	O
the	O
timeline	O
for	O
a	O
week	O
could	O
be	O
quantized	O
into	O
working	O
days	O
and	O
weekend	O
.	O
a	O
special	O
case	O
of	O
quantization	B
is	O
digiti-	O
zation	O
:	O
in	O
case	O
of	O
digitization	B
we	O
always	O
talk	O
about	O
regular	O
quantization	B
of	O
a	O
con-	O
tinuous	O
space	O
into	O
a	O
number	O
system	O
with	O
respect	O
to	O
a	O
certain	O
basis	B
.	O
if	O
we	O
enter	O
,	O
for	O
example	O
,	O
some	O
numbers	O
into	O
the	O
computer	O
,	O
these	O
numbers	O
will	O
be	O
digitized	O
into	O
the	O
bi-	O
nary	O
system	O
(	O
basis	B
2	O
)	O
.	O
deﬁnition	O
9.1	O
(	O
quantization	B
)	O
.	O
separa-	O
tion	O
of	O
a	O
continuous	B
space	O
into	O
discrete	B
sec-	O
tions	O
.	O
deﬁnition	O
9.2	O
(	O
digitization	B
)	O
.	O
regular	O
quantization	B
.	O
9.2	O
lvq	O
divides	O
the	O
input	O
space	O
into	O
separate	O
areas	O
now	O
it	O
is	O
almost	O
possible	O
to	O
describe	O
by	O
means	O
of	O
its	O
name	O
what	O
lvq	O
should	O
en-	O
able	O
us	O
to	O
do	O
:	O
a	O
set	O
of	O
representatives	O
should	O
be	O
used	O
to	O
divide	O
an	O
input	O
space	O
input	O
space	O
reduced	O
to	O
vector	O
repre-	O
sentatives	O
into	O
classes	O
that	O
reﬂect	O
the	O
input	O
space	O
as	O
well	O
as	O
possible	O
(	O
ﬁg	O
.	O
9.1	O
on	O
the	O
facing	O
page	O
)	O
.	O
thus	O
,	O
each	O
element	O
of	O
the	O
input	O
space	O
should	O
be	O
assigned	O
to	O
a	O
vector	O
as	O
a	O
representative	O
,	O
i.e	O
.	O
to	O
a	O
class	O
,	O
where	O
the	O
set	O
of	O
these	O
representatives	O
should	O
repre-	O
sent	O
the	O
entire	O
input	O
space	O
as	O
precisely	O
as	O
possible	O
.	O
such	O
a	O
vector	O
is	O
called	O
codebook	B
vector	I
.	O
a	O
codebook	B
vector	I
is	O
the	O
represen-	O
tative	O
of	O
exactly	O
those	O
input	O
space	O
vectors	O
lying	O
closest	O
to	O
it	O
,	O
which	O
divides	O
the	O
input	O
space	O
into	O
the	O
said	O
discrete	B
areas	O
.	O
it	O
is	O
to	O
be	O
emphasized	O
that	O
we	O
have	O
to	O
know	O
in	O
advance	O
how	O
many	O
classes	O
we	O
have	O
and	O
which	O
training	O
sample	O
belongs	O
to	O
which	O
class	O
.	O
furthermore	O
,	O
it	O
is	O
impor-	O
tant	O
that	O
the	O
classes	O
must	O
not	O
be	O
disjoint	O
,	O
which	O
means	O
they	O
may	O
overlap	O
.	O
such	O
separation	O
of	O
data	O
into	O
classes	O
is	O
in-	O
teresting	O
for	O
many	O
problems	O
for	O
which	O
it	O
is	O
useful	O
to	O
explore	O
only	O
some	O
characteris-	O
tic	O
representatives	O
instead	O
of	O
the	O
possibly	O
huge	O
set	O
of	O
all	O
vectors	O
–	O
be	O
it	O
because	O
it	O
is	O
less	O
time-consuming	O
or	O
because	O
it	O
is	O
suﬃ-	O
ciently	O
precise	O
.	O
9.3	O
using	O
codebook	O
vectors	O
:	O
the	O
nearest	O
one	O
is	O
the	O
winner	O
the	O
use	O
of	O
a	O
prepared	O
set	O
of	O
codebook	O
vec-	O
tors	O
is	O
very	O
simple	O
:	O
for	O
an	O
input	B
vector	I
y	O
the	O
class	O
association	O
is	O
easily	O
decided	O
by	O
considering	O
which	O
codebook	B
vector	I
is	O
the	O
closest	O
–	O
so	O
,	O
the	O
codebook	O
vectors	O
build	O
a	O
voronoi	B
diagram	I
out	O
of	O
the	O
set	O
.	O
since	O
closest	O
vector	O
wins	O
140	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
9.4	O
adjusting	O
codebook	O
vectors	O
figure	O
9.1	O
:	O
bexamples	O
for	O
quantization	B
of	O
a	O
two-dimensional	O
input	O
space	O
.	O
dthe	O
lines	O
represent	O
the	O
class	O
limit	O
,	O
the	O
×	O
mark	O
the	O
codebook	O
vectors	O
.	O
each	O
codebook	B
vector	I
can	O
clearly	O
be	O
asso-	O
ciated	O
to	O
a	O
class	O
,	O
each	O
input	B
vector	I
is	O
asso-	O
ciated	O
to	O
a	O
class	O
,	O
too	O
.	O
are	O
used	O
to	O
cause	O
a	O
previously	O
deﬁned	O
num-	O
ber	O
of	O
randomly	O
initialized	O
codebook	O
vec-	O
tors	O
to	O
reﬂect	O
the	O
training	O
data	O
as	O
precisely	O
as	O
possible	O
.	O
9.4	O
adjusting	O
codebook	O
vectors	O
as	O
we	O
have	O
already	O
indicated	O
,	O
the	O
lvq	O
is	O
a	O
supervised	B
learning	I
procedure	O
.	O
thus	O
,	O
we	O
have	O
a	O
teaching	B
input	I
that	O
tells	O
the	O
learn-	O
ing	O
procedure	O
whether	O
the	O
classiﬁcation	O
of	O
the	O
input	O
pattern	O
is	O
right	O
or	O
wrong	O
:	O
in	O
other	O
words	O
,	O
we	O
have	O
to	O
know	O
in	O
advance	O
the	O
number	O
of	O
classes	O
to	O
be	O
represented	O
or	O
the	O
number	O
of	O
codebook	O
vectors	O
.	O
roughly	O
speaking	O
,	O
it	O
is	O
the	O
aim	O
of	O
the	O
learning	B
procedure	O
that	O
training	O
samples	O
9.4.1	O
the	O
procedure	O
of	O
learning	B
learning	O
works	O
according	O
to	O
a	O
simple	O
scheme	O
.	O
we	O
have	O
(	O
since	O
learning	B
is	O
su-	O
pervised	O
)	O
a	O
set	O
p	O
of	O
|p|	O
training	O
samples	O
.	O
additionally	O
,	O
we	O
already	O
know	O
that	O
classes	O
are	O
predeﬁned	O
,	O
too	O
,	O
i.e	O
.	O
we	O
also	O
have	O
a	O
set	O
of	O
classes	O
c.	O
a	O
codebook	B
vector	I
is	O
clearly	O
assigned	O
to	O
each	O
class	O
.	O
thus	O
,	O
we	O
can	O
say	O
that	O
the	O
set	O
of	O
classes	O
|c|	O
contains	O
many	O
codebook	O
vectors	O
c1	O
,	O
c2	O
,	O
.	O
.	O
.	O
,	O
c|c|	O
.	O
this	O
leads	O
to	O
the	O
structure	O
of	O
the	O
training	O
samples	O
:	O
they	O
are	O
of	O
the	O
form	O
(	O
p	O
,	O
c	O
)	O
and	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
141	O
chapter	O
9	O
learning	B
vector	I
quantization	I
dkriesel.com	O
therefore	O
contain	O
the	O
training	O
input	O
vector	O
p	O
and	O
its	O
class	O
aﬃliation	O
c.	O
for	O
the	O
class	O
aﬃliation	O
c	O
∈	O
{	O
1	O
,	O
2	O
,	O
.	O
.	O
.	O
,	O
|c|	O
}	O
holds	O
,	O
which	O
means	O
that	O
it	O
clearly	O
assigns	O
the	O
training	O
sample	O
to	O
a	O
class	O
or	O
a	O
code-	O
book	O
vector	O
.	O
intuitively	O
,	O
we	O
could	O
say	O
about	O
learning	B
:	O
''	O
why	O
a	O
learning	B
procedure	O
?	O
we	O
calculate	O
the	O
average	O
of	O
all	O
class	O
members	O
and	O
place	O
their	O
codebook	O
vectors	O
there	O
–	O
and	O
that	O
’	O
s	O
it	O
.	O
''	O
but	O
we	O
will	O
see	O
soon	O
that	O
our	O
learning	B
procedure	O
can	O
do	O
a	O
lot	O
more	O
.	O
i	O
only	O
want	O
to	O
brieﬂy	O
discuss	O
the	O
steps	O
of	O
the	O
fundamental	O
lvq	O
learning	B
proce-	O
dure	O
:	O
initialization	O
:	O
we	O
place	O
our	O
set	O
of	O
code-	O
book	O
vectors	O
on	O
random	O
positions	O
in	O
the	O
input	O
space	O
.	O
training	O
sample	O
:	O
a	O
training	O
sample	O
p	O
of	O
our	O
training	B
set	I
p	O
is	O
selected	O
and	O
pre-	O
sented	O
.	O
distance	O
measurement	O
:	O
we	O
measure	O
the	O
distance	O
||p	O
−	O
c||	O
between	O
all	O
code-	O
book	O
vectors	O
c1	O
,	O
c2	O
,	O
.	O
.	O
.	O
,	O
c|c|	O
and	O
our	O
input	O
p.	O
winner	O
:	O
the	O
wins	O
,	O
i.e	O
.	O
the	O
one	O
with	O
closest	O
codebook	B
vector	I
||p	O
−	O
ci||	O
.	O
min	O
ci∈c	O
learning	B
process	O
:	O
the	O
learning	B
process	O
takes	O
place	O
according	O
to	O
the	O
rule	O
∆ci	O
=	O
η	O
(	O
t	O
)	O
·	O
h	O
(	O
p	O
,	O
ci	O
)	O
·	O
(	O
p	O
−	O
ci	O
)	O
(	O
9.1	O
)	O
(	O
9.2	O
)	O
ci	O
(	O
t	O
+	O
1	O
)	O
=	O
ci	O
(	O
t	O
)	O
+	O
∆ci	O
,	O
which	O
we	O
now	O
want	O
to	O
break	O
down	O
.	O
.	O
we	O
have	O
already	O
seen	O
that	O
the	O
ﬁrst	O
factor	O
η	O
(	O
t	O
)	O
is	O
a	O
time-dependent	O
learn-	O
ing	O
rate	O
allowing	O
us	O
to	O
diﬀerentiate	O
between	O
large	O
learning	B
steps	O
and	O
ﬁne	O
tuning	O
.	O
.	O
the	O
last	O
factor	O
(	O
p	O
−	O
ci	O
)	O
is	O
obviously	O
the	O
direction	O
toward	O
which	O
the	O
code-	O
book	O
vector	O
is	O
moved	O
.	O
.	O
but	O
the	O
function	B
h	O
(	O
p	O
,	O
ci	O
)	O
is	O
the	O
core	O
of	O
the	O
rule	O
:	O
it	O
implements	O
a	O
distinction	O
of	O
cases	O
.	O
assignment	O
is	O
correct	O
:	O
the	O
winner	O
vector	O
is	O
the	O
codebook	B
vector	I
of	O
the	O
class	O
that	O
includes	O
p.	O
in	O
this	O
case	O
,	O
the	O
function	B
provides	O
posi-	O
tive	O
values	O
and	O
the	O
codebook	O
vec-	O
tor	O
moves	O
towards	O
p.	O
assignment	O
is	O
wrong	O
:	O
the	O
winner	O
vector	O
does	O
not	O
represent	O
the	O
class	O
that	O
includes	O
p.	O
therefore	O
it	O
moves	O
away	O
from	O
p.	O
we	O
can	O
see	O
that	O
our	O
deﬁnition	O
of	O
the	O
func-	O
tion	O
h	O
was	O
not	O
precise	O
enough	O
.	O
with	O
good	O
reason	O
:	O
from	O
here	O
on	O
,	O
the	O
lvq	O
is	O
divided	O
into	O
diﬀerent	O
nuances	O
,	O
dependent	O
of	O
how	O
exactly	O
h	O
and	O
the	O
learning	B
rate	I
should	O
be	O
deﬁned	O
(	O
called	O
lvq1	O
,	O
lvq2	O
,	O
lvq3	O
,	O
important	O
!	O
142	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
9.5	O
connection	B
to	O
neural	O
networks	O
olvq	O
,	O
etc	O
)	O
.	O
the	O
diﬀerences	O
are	O
,	O
for	O
in-	O
stance	O
,	O
in	O
the	O
strength	O
of	O
the	O
codebook	O
vec-	O
tor	O
movements	O
.	O
they	O
are	O
not	O
all	O
based	O
on	O
the	O
same	O
principle	O
described	O
here	O
,	O
and	O
as	O
announced	O
i	O
don	O
’	O
t	O
want	O
to	O
discuss	O
them	O
any	O
further	O
.	O
therefore	O
i	O
don	O
’	O
t	O
give	O
any	O
formal	O
deﬁnition	O
regarding	O
the	O
aforemen-	O
tioned	O
learning	B
rule	O
and	O
lvq	O
.	O
exercises	O
exercise	O
16.	O
indicate	O
a	O
quantization	B
which	O
equally	O
distributes	O
all	O
vectors	O
h	O
∈	O
h	O
in	O
the	O
ﬁve-dimensional	O
unit	O
cube	O
h	O
into	O
one	O
of	O
1024	O
classes	O
.	O
vectors	O
=	O
neurons	O
?	O
9.5	O
connection	B
to	O
neural	O
networks	O
until	O
now	O
,	O
in	O
spite	O
of	O
the	O
learning	B
process	O
,	O
the	O
question	O
was	O
what	O
lvq	O
has	O
to	O
do	O
with	O
neural	O
networks	O
.	O
the	O
codebook	O
vectors	O
can	O
be	O
understood	O
as	O
neurons	O
with	O
a	O
ﬁxed	O
position	O
within	O
the	O
input	O
space	O
,	O
similar	O
to	O
rbf	O
networks	O
.	O
additionally	O
,	O
in	O
nature	O
it	O
often	O
occurs	O
that	O
in	O
a	O
group	O
one	O
neuron	O
may	O
ﬁre	O
(	O
a	O
winner	O
neuron	O
,	O
here	O
:	O
a	O
code-	O
book	O
vector	O
)	O
and	O
,	O
in	O
return	B
,	O
inhibits	O
all	O
other	O
neurons	O
.	O
i	O
decided	O
to	O
place	O
this	O
brief	O
chapter	O
about	O
learning	B
vector	I
quantization	I
here	O
so	O
that	O
this	O
approach	O
can	O
be	O
continued	O
in	O
the	O
fol-	O
lowing	O
chapter	O
about	O
self-organizing	O
maps	O
:	O
we	O
will	O
classify	O
further	O
inputs	O
by	O
means	O
of	O
neurons	O
distributed	O
throughout	O
the	O
input	O
space	O
,	O
only	O
that	O
this	O
time	O
,	O
we	O
do	O
not	O
know	O
which	O
input	O
belongs	O
to	O
which	O
class	O
.	O
now	O
let	O
us	O
take	O
a	O
look	O
at	O
the	O
unsupervised	B
learning	I
networks	O
!	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
143	O
part	O
iii	O
unsupervised	B
learning	I
network	O
paradigms	O
145	O
chapter	O
10	O
self-organizing	B
feature	I
maps	I
a	O
paradigm	O
of	O
unsupervised	B
learning	I
neural	O
networks	O
,	O
which	O
maps	O
an	O
input	O
space	O
by	O
its	O
ﬁxed	O
topology	B
and	O
thus	O
independently	O
looks	O
for	O
simililarities	O
.	O
function	B
,	O
learning	B
procedure	O
,	O
variations	O
and	O
neural	O
gas	O
.	O
no	O
output	O
,	O
but	O
active	O
neuron	O
if	O
you	O
take	O
a	O
look	O
at	O
the	O
concepts	O
of	O
biologi-	O
cal	O
neural	O
networks	O
mentioned	O
in	O
the	O
intro-	O
duction	O
,	O
one	O
question	O
will	O
arise	O
:	O
how	O
does	O
our	O
brain	B
store	O
and	O
recall	O
the	O
impressions	O
it	O
receives	O
every	O
day	O
.	O
let	O
me	O
point	O
out	O
that	O
the	O
brain	B
does	O
not	O
have	O
any	O
training	O
samples	O
and	O
therefore	O
no	O
``	O
desired	O
output	O
''	O
.	O
and	O
while	O
already	O
considering	O
this	O
subject	O
we	O
realize	O
that	O
there	O
is	O
no	O
output	O
in	O
this	O
sense	O
at	O
all	O
,	O
too	O
.	O
our	O
brain	B
responds	O
to	O
external	O
input	O
by	O
changes	O
in	O
state	B
.	O
these	O
are	O
,	O
so	O
to	O
speak	O
,	O
its	O
output	O
.	O
how	O
are	O
data	O
stored	O
in	O
the	O
brain	B
?	O
based	O
on	O
this	O
principle	O
and	O
exploring	O
the	O
question	O
of	O
how	O
biological	O
neural	O
net-	O
works	O
organize	O
themselves	O
,	O
teuvo	O
ko-	O
honen	O
developed	O
in	O
the	O
eighties	O
his	O
self-	O
organizing	O
feature	O
maps	O
[	O
koh82	O
,	O
koh98	O
]	O
,	O
shortly	O
referred	O
to	O
as	O
self-organizing	O
maps	O
or	O
soms	O
.	O
a	O
paradigm	O
of	O
neural	O
networks	O
where	O
the	O
output	O
is	O
the	O
state	B
of	O
the	O
network	O
,	O
which	O
learns	O
completely	O
un-	O
supervised	O
,	O
i.e	O
.	O
without	O
a	O
teacher	O
.	O
unlike	O
the	O
other	O
network	O
paradigms	O
we	O
have	O
already	O
got	O
to	O
know	O
,	O
for	O
soms	O
it	O
is	O
unnecessary	O
to	O
ask	O
what	O
the	O
neurons	O
calcu-	O
late	O
.	O
we	O
only	O
ask	O
which	O
neuron	O
is	O
active	O
at	O
the	O
moment	O
.	O
biologically	O
,	O
this	O
is	O
very	O
mo-	O
tivated	O
:	O
if	O
in	O
biology	O
the	O
neurons	O
are	O
con-	O
nected	O
to	O
certain	O
muscles	O
,	O
it	O
will	O
be	O
less	O
interesting	O
to	O
know	O
how	O
strong	O
a	O
certain	O
muscle	O
is	O
contracted	O
but	O
which	O
muscle	O
is	O
activated	O
.	O
in	O
other	O
words	O
:	O
we	O
are	O
not	O
in-	O
terested	O
in	O
the	O
exact	O
output	O
of	O
the	O
neuron	O
but	O
in	O
knowing	O
which	O
neuron	O
provides	O
out-	O
put	O
.	O
thus	O
,	O
soms	O
are	O
considerably	O
more	O
related	O
to	O
biology	O
than	O
,	O
for	O
example	O
,	O
the	O
feedforward	B
networks	O
,	O
which	O
are	O
increas-	O
ingly	O
used	O
for	O
calculations	O
.	O
10.1	O
structure	O
of	O
a	O
self-organizing	B
map	I
typically	O
,	O
soms	O
have	O
–	O
like	O
our	O
brain	B
–	O
the	O
task	O
to	O
map	O
a	O
high-dimensional	O
in-	O
put	O
(	O
n	O
dimensions	O
)	O
onto	O
areas	O
in	O
a	O
low-	O
147	O
chapter	O
10	O
self-organizing	B
feature	I
maps	I
dkriesel.com	O
dimensional	O
grid	B
of	O
cells	O
(	O
g	O
dimensions	O
)	O
to	O
draw	O
a	O
map	O
of	O
the	O
high-dimensional	O
space	O
,	O
so	O
to	O
speak	O
.	O
to	O
generate	O
this	O
map	O
,	O
the	O
som	O
simply	O
obtains	O
arbitrary	O
many	O
points	O
of	O
the	O
input	O
space	O
.	O
during	O
the	O
in-	O
put	O
of	O
the	O
points	O
the	O
som	O
will	O
try	O
to	O
cover	O
as	O
good	O
as	O
possible	O
the	O
positions	O
on	O
which	O
the	O
points	O
appear	O
by	O
its	O
neurons	O
.	O
this	O
par-	O
ticularly	O
means	O
,	O
that	O
every	O
neuron	O
can	O
be	O
assigned	O
to	O
a	O
certain	O
position	O
in	O
the	O
input	O
space	O
.	O
at	O
ﬁrst	O
,	O
these	O
facts	O
seem	O
to	O
be	O
a	O
bit	O
con-	O
fusing	O
,	O
and	O
it	O
is	O
recommended	O
to	O
brieﬂy	O
reﬂect	O
about	O
them	O
.	O
there	O
are	O
two	O
spaces	O
in	O
which	O
soms	O
are	O
working	O
:	O
.	O
the	O
n-dimensional	O
input	O
space	O
and	O
.	O
the	O
g-dimensional	O
grid	B
on	O
which	O
the	O
neurons	O
are	O
lying	O
and	O
which	O
indi-	O
cates	O
the	O
neighborhood	O
relationships	O
between	O
the	O
neurons	O
and	O
therefore	O
the	O
network	O
topology	O
.	O
in	O
a	O
one-dimensional	O
grid	B
,	O
the	O
neurons	O
could	O
be	O
,	O
for	O
instance	O
,	O
like	O
pearls	O
on	O
a	O
string	O
.	O
every	O
neuron	O
would	O
have	O
exactly	O
two	O
neighbors	O
(	O
except	O
for	O
the	O
two	O
end	O
neu-	O
rons	O
)	O
.	O
a	O
two-dimensional	O
grid	B
could	O
be	O
a	O
square	O
array	O
of	O
neurons	O
(	O
ﬁg	O
.	O
10.1	O
)	O
.	O
an-	O
other	O
possible	O
array	O
in	O
two-dimensional	O
space	O
would	O
be	O
some	O
kind	O
of	O
honeycomb	O
shape	O
.	O
irregular	O
topologies	O
are	O
possible	O
,	O
too	O
,	O
but	O
not	O
very	O
often	O
.	O
topolgies	O
with	O
more	O
dimensions	O
and	O
considerably	O
more	O
neighborhood	O
relationships	O
would	O
also	O
be	O
possible	O
,	O
but	O
due	O
to	O
their	O
lack	O
of	O
visualiza-	O
tion	O
capability	O
they	O
are	O
not	O
employed	O
very	O
often	O
.	O
high-dim	O
.	O
input	O
↓	O
low-dim	O
.	O
map	O
input	O
space	O
and	O
topology	B
important	O
!	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
topologies	O
of	O
a	O
self-	O
figure	O
10.1	O
:	O
example	O
organizing	O
map	O
.	O
above	O
we	O
can	O
see	O
a	O
one-	O
dimensional	O
topology	B
,	O
below	O
a	O
two-dimensional	O
one	O
.	O
even	O
if	O
n	O
=	O
g	O
is	O
true	O
,	O
the	O
two	O
spaces	O
are	O
not	O
equal	O
and	O
have	O
to	O
be	O
distinguished	O
.	O
in	O
this	O
special	O
case	O
they	O
only	O
have	O
the	O
same	O
dimension	O
.	O
initially	O
,	O
we	O
will	O
brieﬂy	O
and	O
formally	O
re-	O
gard	O
the	O
functionality	O
of	O
a	O
self-organizing	B
map	I
and	O
then	O
make	O
it	O
clear	O
by	O
means	O
of	O
some	O
examples	O
.	O
deﬁnition	O
10.1	O
(	O
som	O
neuron	O
)	O
.	O
similar	O
to	O
the	O
neurons	O
in	O
an	O
rbf	O
network	O
a	O
som	O
neuron	O
k	O
does	O
not	O
occupy	O
a	O
ﬁxed	O
position	O
ck	O
(	O
a	O
center	O
)	O
in	O
the	O
input	O
space	O
.	O
deﬁnition	O
10.2	O
(	O
self-organizing	B
map	I
)	O
.	O
a	O
self-organizing	B
map	I
is	O
a	O
set	O
k	O
of	O
som	O
neurons	O
.	O
if	O
an	O
input	B
vector	I
is	O
entered	O
,	O
ex-	O
(	O
cid:74	O
)	O
k	O
actly	O
that	O
neuron	O
k	O
∈	O
k	O
is	O
activated	O
which	O
(	O
cid:74	O
)	O
c	O
148	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
input	O
↓	O
winner	O
n	O
(	O
cid:73	O
)	O
i	O
(	O
cid:73	O
)	O
k	O
(	O
cid:73	O
)	O
g	O
(	O
cid:73	O
)	O
dkriesel.com	O
10.3	O
training	O
is	O
closest	O
to	O
the	O
input	O
pattern	O
in	O
the	O
input	O
space	O
.	O
the	O
dimension	O
of	O
the	O
input	O
space	O
is	O
referred	O
to	O
as	O
n.	O
deﬁnition	O
10.3	O
(	O
topology	B
)	O
.	O
the	O
neu-	O
rons	O
are	O
interconnected	O
by	O
neighborhood	O
relationships	O
.	O
these	O
neighborhood	O
rela-	O
tionships	O
are	O
called	O
topology	B
.	O
the	O
train-	O
ing	O
of	O
a	O
som	O
is	O
highly	O
inﬂuenced	O
by	O
the	O
it	O
is	O
deﬁned	O
by	O
the	O
topology	B
topology	O
.	O
function	B
h	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
,	O
where	O
i	O
is	O
the	O
winner	O
neuron1	O
ist	O
,	O
k	O
the	O
neuron	O
to	O
be	O
adapted	O
(	O
which	O
will	O
be	O
discussed	O
later	O
)	O
and	O
t	O
the	O
timestep	O
.	O
the	O
dimension	O
of	O
the	O
topology	B
is	O
referred	O
to	O
as	O
g.	O
10.2	O
soms	O
always	O
activate	O
the	O
neuron	O
with	O
the	O
least	O
distance	O
to	O
an	O
input	O
pattern	O
like	O
many	O
other	O
neural	O
networks	O
,	O
the	O
som	O
has	O
to	O
be	O
trained	O
before	O
it	O
can	O
be	O
used	O
.	O
but	O
let	O
us	O
regard	O
the	O
very	O
simple	O
functionality	O
of	O
a	O
complete	O
self-organizing	O
map	O
before	O
training	O
,	O
since	O
there	O
are	O
many	O
analogies	O
to	O
the	O
training	O
.	O
functionality	O
consists	O
of	O
the	O
following	O
steps	O
:	O
input	O
of	O
an	O
arbitrary	O
value	O
p	O
of	O
the	O
input	O
space	O
rn	O
.	O
calculation	O
of	O
the	O
distance	O
between	O
ev-	O
ery	O
neuron	O
k	O
and	O
p	O
by	O
means	O
of	O
a	O
norm	O
,	O
i.e	O
.	O
calculation	O
of	O
||p	O
−	O
ck||	O
.	O
one	O
neuron	O
becomes	O
active	O
,	O
namely	O
such	O
neuron	O
i	O
with	O
the	O
shortest	O
1	O
we	O
will	O
learn	O
soon	O
what	O
a	O
winner	O
neuron	O
is	O
.	O
calculated	O
distance	O
to	O
the	O
input	O
.	O
all	O
other	O
neurons	O
remain	O
inactive.this	O
paradigm	O
of	O
activity	O
is	O
also	O
called	O
winner-takes-all	B
scheme	I
.	O
the	O
output	O
we	O
expect	O
due	O
to	O
the	O
input	O
of	O
a	O
som	O
shows	O
which	O
neuron	O
becomes	O
active	O
.	O
in	O
many	O
literature	O
citations	O
,	O
the	O
descrip-	O
tion	O
of	O
soms	O
is	O
more	O
formal	O
:	O
often	O
an	O
input	B
layer	I
is	O
described	O
that	O
is	O
completely	O
linked	O
towards	O
an	O
som	O
layer	B
.	O
then	O
the	O
in-	O
put	O
layer	B
(	O
n	O
neurons	O
)	O
forwards	O
all	O
inputs	O
to	O
the	O
som	O
layer	B
.	O
the	O
som	O
layer	B
is	O
later-	O
ally	O
linked	O
in	O
itself	O
so	O
that	O
a	O
winner	O
neuron	O
can	O
be	O
established	O
and	O
inhibit	O
the	O
other	O
neurons	O
.	O
i	O
think	O
that	O
this	O
explanation	O
of	O
a	O
som	O
is	O
not	O
very	O
descriptive	O
and	O
there-	O
fore	O
i	O
tried	O
to	O
provide	O
a	O
clearer	O
description	O
of	O
the	O
network	O
structure	O
.	O
now	O
the	O
question	O
is	O
which	O
neuron	O
is	O
ac-	O
tivated	O
by	O
which	O
input	O
–	O
and	O
the	O
answer	O
is	O
given	O
by	O
the	O
network	O
itself	O
during	O
train-	O
ing	O
.	O
10.3	O
training	O
[	O
training	O
makes	O
the	O
som	O
topology	B
cover	O
the	O
input	O
space	O
]	O
the	O
training	O
of	O
a	O
som	O
is	O
nearly	O
as	O
straightforward	O
as	O
the	O
func-	O
tionality	O
described	O
above	O
.	O
basically	O
,	O
it	O
is	O
structured	O
into	O
ﬁve	O
steps	O
,	O
which	O
partially	O
correspond	O
to	O
those	O
of	O
functionality	O
.	O
initialization	O
:	O
the	O
network	O
starts	O
with	O
random	O
neuron	O
centers	O
ck	O
∈	O
rn	O
from	O
the	O
input	O
space	O
.	O
creating	O
an	O
input	O
pattern	O
:	O
a	O
stimulus	B
,	O
i.e	O
.	O
a	O
point	O
p	O
,	O
is	O
selected	O
from	O
the	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
149	O
chapter	O
10	O
self-organizing	B
feature	I
maps	I
dkriesel.com	O
training	O
:	O
input	O
,	O
→	O
winner	O
i	O
,	O
change	O
in	O
position	O
i	O
and	O
neighbors	O
input	O
space	O
rn	O
.	O
now	O
this	O
stimulus	B
is	O
entered	O
into	O
the	O
network	O
.	O
distance	O
measurement	O
:	O
then	O
the	O
dis-	O
tance	O
||p−	O
ck||	O
is	O
determined	O
for	O
every	O
neuron	O
k	O
in	O
the	O
network	O
.	O
winner	O
takes	O
all	O
:	O
the	O
winner	O
neuron	O
i	O
is	O
determined	O
,	O
which	O
has	O
the	O
smallest	O
distance	O
to	O
p	O
,	O
i.e	O
.	O
which	O
fulﬁlls	O
the	O
condition	O
||p	O
−	O
ci||	O
≤	O
||p	O
−	O
ck||	O
∀	O
k	O
6=	O
i	O
.	O
you	O
can	O
see	O
that	O
from	O
several	O
win-	O
ner	O
neurons	O
one	O
can	O
be	O
selected	O
at	O
will	O
.	O
adapting	O
the	O
centers	O
:	O
the	O
neuron	O
cen-	O
ters	O
are	O
moved	O
within	O
the	O
input	O
space	O
according	O
to	O
the	O
rule2	O
∆ck	O
=	O
η	O
(	O
t	O
)	O
·	O
h	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
·	O
(	O
p	O
−	O
ck	O
)	O
,	O
where	O
the	O
values	O
∆ck	O
are	O
simply	O
added	O
to	O
the	O
existing	O
centers	O
.	O
the	O
last	O
factor	O
shows	O
that	O
the	O
change	O
in	O
position	O
of	O
the	O
neurons	O
k	O
is	O
propor-	O
tional	O
to	O
the	O
distance	O
to	O
the	O
input	O
pattern	B
p	O
and	O
,	O
as	O
usual	O
,	O
to	O
a	O
time-	O
dependent	O
learning	B
rate	I
η	O
(	O
t	O
)	O
.	O
the	O
above-mentioned	O
network	O
topology	O
ex-	O
erts	O
its	O
inﬂuence	O
by	O
means	O
of	O
the	O
func-	O
tion	O
h	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
,	O
which	O
will	O
be	O
discussed	O
in	O
the	O
following	O
.	O
2	O
note	O
:	O
in	O
many	O
sources	O
this	O
rule	O
is	O
written	O
ηh	O
(	O
p	O
−	O
ck	O
)	O
,	O
which	O
wrongly	O
leads	O
the	O
reader	O
to	O
believe	O
that	O
h	O
is	O
a	O
constant	O
.	O
this	O
problem	O
can	O
easily	O
be	O
solved	O
by	O
not	O
omitting	O
the	O
multiplication	O
dots	O
·	O
.	O
deﬁnition	O
10.4	O
(	O
som	O
learning	B
rule	O
)	O
.	O
a	O
som	O
is	O
trained	O
by	O
presenting	O
an	O
input	O
pat-	O
tern	O
and	O
determining	O
the	O
associated	O
win-	O
ner	O
neuron	O
.	O
the	O
winner	O
neuron	O
and	O
its	O
neighbor	O
neurons	O
,	O
which	O
are	O
deﬁned	O
by	O
the	O
topology	B
function	I
,	O
then	O
adapt	O
their	O
cen-	O
ters	O
according	O
to	O
the	O
rule	O
∆ck	O
=	O
η	O
(	O
t	O
)	O
·	O
h	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
·	O
(	O
p	O
−	O
ck	O
)	O
,	O
(	O
10.1	O
)	O
(	O
10.2	O
)	O
ck	O
(	O
t	O
+	O
1	O
)	O
=	O
ck	O
(	O
t	O
)	O
+	O
∆ck	O
(	O
t	O
)	O
.	O
10.3.1	O
the	O
topology	B
function	I
deﬁnes	O
,	O
how	O
a	O
learning	B
neuron	O
inﬂuences	O
its	O
neighbors	O
the	O
topology	B
function	I
h	O
is	O
not	O
deﬁned	O
on	O
the	O
input	O
space	O
but	O
on	O
the	O
grid	B
and	O
rep-	O
resents	O
the	O
neighborhood	O
relationships	O
be-	O
tween	O
the	O
neurons	O
,	O
i.e	O
.	O
the	O
topology	B
of	O
the	O
network	O
.	O
it	O
can	O
be	O
time-dependent	O
(	O
which	O
it	O
often	O
is	O
)	O
–	O
which	O
explains	O
the	O
parameter	O
t.	O
the	O
parameter	O
k	O
is	O
the	O
index	O
running	O
through	O
all	O
neurons	O
,	O
and	O
the	O
parameter	O
i	O
is	O
the	O
index	O
of	O
the	O
winner	O
neuron	O
.	O
in	O
principle	O
,	O
the	O
function	B
shall	O
take	O
a	O
large	O
value	O
if	O
k	O
is	O
the	O
neighbor	O
of	O
the	O
winner	O
neu-	O
ron	O
or	O
even	O
the	O
winner	O
neuron	O
itself	O
,	O
and	O
small	O
values	O
if	O
not	O
.	O
smore	O
precise	O
deﬁni-	O
tion	O
:	O
the	O
topology	B
function	I
must	O
be	O
uni-	O
modal	O
,	O
i.e	O
.	O
it	O
must	O
have	O
exactly	O
one	O
maxi-	O
mum	O
.	O
this	O
maximum	O
must	O
be	O
next	O
to	O
the	O
winner	O
neuron	O
i	O
,	O
for	O
which	O
the	O
distance	O
to	O
itself	O
certainly	O
is	O
0.	O
additionally	O
,	O
the	O
time-dependence	O
enables	O
us	O
,	O
for	O
example	O
,	O
to	O
reduce	O
the	O
neighbor-	O
hood	O
in	O
the	O
course	O
of	O
time	O
.	O
deﬁned	O
on	O
the	O
grid	B
only	O
1	O
maximum	O
for	O
the	O
winner	O
150	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
10.3	O
training	O
in	O
order	O
to	O
be	O
able	O
to	O
output	O
large	O
values	O
for	O
the	O
neighbors	O
of	O
i	O
and	O
small	O
values	O
for	O
non-neighbors	O
,	O
the	O
function	B
h	O
needs	O
some	O
kind	O
of	O
distance	O
notion	O
on	O
the	O
grid	B
because	O
from	O
somewhere	O
it	O
has	O
to	O
know	O
how	O
far	O
i	O
and	O
k	O
are	O
apart	O
from	O
each	O
other	O
on	O
the	O
grid	B
.	O
there	O
are	O
diﬀerent	O
methods	O
to	O
cal-	O
culate	O
this	O
distance	O
.	O
on	O
a	O
two-dimensional	O
grid	B
we	O
could	O
apply	O
,	O
for	O
instance	O
,	O
the	O
euclidean	O
distance	O
(	O
lower	O
part	O
of	O
ﬁg	O
.	O
10.2	O
)	O
or	O
on	O
a	O
one-dimensional	O
grid	B
we	O
could	O
simply	O
use	O
the	O
number	O
of	O
the	O
connections	O
between	O
the	O
neurons	O
i	O
and	O
k	O
(	O
upper	O
part	O
of	O
the	O
same	O
ﬁgure	O
)	O
.	O
deﬁnition	O
10.5	O
(	O
topology	B
function	I
)	O
.	O
the	O
topology	B
function	I
h	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
describes	O
the	O
neighborhood	O
relationships	O
in	O
the	O
topology	B
.	O
it	O
can	O
be	O
any	O
unimodal	O
func-	O
tion	O
that	O
reaches	O
its	O
maximum	O
when	O
i	O
=	O
k	O
gilt	O
.	O
time-dependence	O
is	O
optional	O
,	O
but	O
of-	O
ten	O
used	O
.	O
10.3.1.1	O
introduction	O
of	O
common	O
distance	O
and	O
topology	B
functions	O
a	O
common	O
distance	O
function	O
would	O
be	O
,	O
for	O
example	O
,	O
the	O
already	O
known	O
gaussian	O
bell	O
(	O
see	O
ﬁg	O
.	O
10.3	O
on	O
page	O
153	O
)	O
.	O
it	O
is	O
uni-	O
modal	O
with	O
a	O
maximum	O
close	O
to	O
0.	O
addi-	O
tionally	O
,	O
its	O
width	O
can	O
be	O
changed	O
by	O
ap-	O
plying	O
its	O
parameter	O
σ	O
,	O
which	O
can	O
be	O
used	O
to	O
realize	O
the	O
neighborhood	O
being	O
reduced	O
in	O
the	O
course	O
of	O
time	O
:	O
we	O
simply	O
relate	O
the	O
time-dependence	O
to	O
the	O
σ	O
and	O
the	O
result	O
is	O
σ	O
(	O
cid:73	O
)	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
i	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
i	O
/.-	O
,	O
(	O
)	O
*+	O
1	O
/	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
k	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
//.-	O
,	O
(	O
)	O
*+o	O
/.-	O
,	O
(	O
)	O
*+	O
8qqqqqq	O
2.23qqqqqqq	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
ko	O
//.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
/.-	O
,	O
(	O
)	O
*+	O
figure	O
10.2	O
:	O
example	O
distances	O
of	O
a	O
one-	O
dimensional	O
som	O
topology	B
(	O
above	O
)	O
and	O
a	O
two-	O
dimensional	O
som	O
topology	B
(	O
below	O
)	O
between	O
two	O
neurons	O
i	O
and	O
k.	O
in	O
the	O
lower	O
case	O
the	O
euclidean	O
distance	O
is	O
determined	O
(	O
in	O
two-dimensional	O
space	O
equivalent	O
to	O
the	O
pythagoream	O
theorem	O
)	O
.	O
in	O
the	O
upper	O
case	O
we	O
simply	O
count	O
the	O
discrete	B
path	O
length	O
between	O
i	O
and	O
k.	O
to	O
simplify	O
matters	O
i	O
required	O
a	O
ﬁxed	O
grid	B
edge	O
length	O
of	O
1	O
in	O
both	O
cases	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
151	O
o	O
o	O
/	O
o	O
	O
	O
x	O
x	O
8	O
o	O
o	O
/	O
o	O
/	O
chapter	O
10	O
self-organizing	B
feature	I
maps	I
dkriesel.com	O
a	O
monotonically	O
decreasing	O
σ	O
(	O
t	O
)	O
.	O
then	O
our	O
topology	B
function	I
could	O
look	O
like	O
this	O
:	O
typical	O
sizes	O
of	O
the	O
target	B
value	O
of	O
a	O
learn-	O
ing	O
rate	O
are	O
two	O
sizes	O
smaller	O
than	O
the	O
ini-	O
tial	O
value	O
,	O
e.g	O
(	O
cid:16	O
)	O
−	O
||gi−ck||2	O
2·σ	O
(	O
t	O
)	O
2	O
(	O
cid:17	O
)	O
h	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
=	O
e	O
,	O
(	O
10.3	O
)	O
0.01	O
<	O
η	O
<	O
0.6	O
where	O
gi	O
and	O
gk	O
represent	O
the	O
neuron	O
po-	O
sitions	O
on	O
the	O
grid	B
,	O
not	O
the	O
neuron	O
posi-	O
tions	O
in	O
the	O
input	O
space	O
,	O
which	O
would	O
be	O
referred	O
to	O
as	O
ci	O
and	O
ck	O
.	O
other	O
functions	O
that	O
can	O
be	O
used	O
in-	O
stead	O
of	O
the	O
gaussian	O
function	B
are	O
,	O
for	O
instance	O
,	O
the	O
cone	B
function	I
,	O
the	O
cylin-	O
der	O
function	B
or	O
the	O
mexican	O
hat	O
func-	O
tion	O
(	O
ﬁg	O
.	O
10.3	O
on	O
the	O
facing	O
page	O
)	O
.	O
here	O
,	O
the	O
mexican	O
hat	O
function	B
oﬀers	O
a	O
particu-	O
lar	O
biological	O
motivation	O
:	O
due	O
to	O
its	O
neg-	O
ative	O
digits	O
it	O
rejects	O
some	O
neurons	O
close	O
to	O
the	O
winner	O
neuron	O
,	O
a	O
behavior	O
that	O
has	O
already	O
been	O
observed	O
in	O
nature	O
.	O
this	O
can	O
cause	O
sharply	O
separated	O
map	O
areas	O
–	O
and	O
that	O
is	O
exactly	O
why	O
the	O
mexican	O
hat	O
func-	O
tion	O
has	O
been	O
suggested	O
by	O
teuvo	O
koho-	O
nen	O
himself	O
.	O
but	O
this	O
adjustment	O
charac-	O
teristic	O
is	O
not	O
necessary	O
for	O
the	O
functional-	O
ity	O
of	O
the	O
map	O
,	O
it	O
could	O
even	O
be	O
possible	O
that	O
the	O
map	O
would	O
diverge	O
,	O
i.e	O
.	O
it	O
could	O
virtually	O
explode	O
.	O
10.3.2	O
learning	B
rates	O
and	O
neighborhoods	O
can	O
decrease	O
monotonically	O
over	O
time	O
to	O
avoid	O
that	O
the	O
later	O
training	O
phases	O
forcefully	O
pull	O
the	O
entire	O
map	O
towards	O
a	O
new	O
pattern	B
,	O
the	O
soms	O
often	O
work	O
with	O
temporally	O
monotonically	O
decreasing	O
learning	B
rates	O
and	O
neighborhood	O
sizes	O
.	O
at	O
ﬁrst	O
,	O
let	O
us	O
talk	O
about	O
the	O
learning	B
rate	I
:	O
could	O
be	O
true	O
.	O
but	O
this	O
size	O
must	O
also	O
de-	O
pend	O
on	O
the	O
network	O
topology	O
or	O
the	O
size	O
of	O
the	O
neighborhood	O
.	O
as	O
we	O
have	O
already	O
seen	O
,	O
a	O
decreasing	O
neighborhood	O
size	O
can	O
be	O
realized	O
,	O
for	O
ex-	O
ample	O
,	O
by	O
means	O
of	O
a	O
time-dependent	O
,	O
monotonically	O
decreasing	O
σ	O
with	O
the	O
gaussin	O
bell	O
being	O
used	O
in	O
the	O
topology	B
function	I
.	O
the	O
advantage	O
of	O
a	O
decreasing	O
neighbor-	O
hood	O
size	O
is	O
that	O
in	O
the	O
beginning	O
a	O
moving	O
neuron	O
``	O
pulls	O
along	O
''	O
many	O
neurons	O
in	O
its	O
vicinity	O
,	O
i.e	O
.	O
the	O
randomly	O
initialized	O
net-	O
work	O
can	O
unfold	O
fast	O
and	O
properly	O
in	O
the	O
beginning	O
.	O
in	O
the	O
end	O
of	O
the	O
learning	B
pro-	O
cess	O
,	O
only	O
a	O
few	O
neurons	O
are	O
inﬂuenced	O
at	O
the	O
same	O
time	O
which	O
stiﬀens	O
the	O
network	O
as	O
a	O
whole	O
but	O
enables	O
a	O
good	O
``	O
ﬁne	O
tuning	O
''	O
of	O
the	O
individual	O
neurons	O
.	O
it	O
must	O
be	O
noted	O
that	O
h	O
·	O
η	O
≤	O
1	O
must	O
always	O
be	O
true	O
,	O
since	O
otherwise	O
the	O
neurons	O
would	O
constantly	O
miss	O
the	O
current	O
training	O
sample	O
.	O
but	O
enough	O
of	O
theory	O
–	O
let	O
us	O
take	O
a	O
look	O
at	O
a	O
som	O
in	O
action	O
!	O
152	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
10.3	O
training	O
figure	O
10.3	O
:	O
gaussian	O
bell	O
,	O
cone	B
function	I
,	O
cylinder	B
function	I
and	O
the	O
mexican	O
hat	O
function	B
sug-	O
gested	O
by	O
kohonen	O
as	O
examples	O
for	O
topology	B
functions	O
of	O
a	O
som..	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
153	O
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1−2−1.5−1−0.5	O
0	O
0.5	O
1	O
1.5	O
2h	O
(	O
r	O
)	O
rgaussian	O
in	O
1d	O
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1−4−2	O
0	O
2	O
4f	O
(	O
x	O
)	O
xcone	O
function	B
0	O
0.2	O
0.4	O
0.6	O
0.8	O
1−4−2	O
0	O
2	O
4f	O
(	O
x	O
)	O
xcylinder	O
funktion−1.5−1−0.5	O
0	O
0.5	O
1	O
1.5	O
2	O
2.5	O
3	O
3.5−3−2−1	O
0	O
1	O
2	O
3f	O
(	O
x	O
)	O
xmexican	O
hat	O
function	B
chapter	O
10	O
self-organizing	B
feature	I
maps	I
dkriesel.com	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
1	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
4	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
>	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
3	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
7	O
p	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
2	O
	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
6	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
5	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
1	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
2	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
3	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
4	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
5	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
6	O
?	O
>	O
=	O
<	O
89	O
:	O
;	O
7	O
figure	O
10.4	O
:	O
illustration	O
of	O
the	O
two-dimensional	O
input	O
space	O
(	O
left	O
)	O
and	O
the	O
one-dimensional	O
topolgy	O
space	O
(	O
right	O
)	O
of	O
a	O
self-organizing	B
map	I
.	O
neuron	O
3	O
is	O
the	O
winner	O
neuron	O
since	O
it	O
is	O
closest	O
to	O
p.	O
in	O
the	O
topology	B
,	O
the	O
neurons	O
2	O
and	O
4	O
are	O
the	O
neighbors	O
of	O
3.	O
the	O
arrows	O
mark	O
the	O
movement	O
of	O
the	O
winner	O
neuron	O
and	O
its	O
neighbors	O
towards	O
the	O
training	O
sample	O
p.	O
to	O
illustrate	O
the	O
one-dimensional	O
topology	B
of	O
the	O
network	O
,	O
it	O
is	O
plotted	O
into	O
the	O
input	O
space	O
by	O
the	O
dotted	O
line	O
.	O
the	O
arrows	O
mark	O
the	O
movement	O
of	O
the	O
winner	O
neuron	O
and	O
its	O
neighbors	O
towards	O
the	O
pattern	B
.	O
154	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
	O
	O
/	O
/	O
/	O
/	O
dkriesel.com	O
10.4	O
examples	O
10.4	O
examples	O
for	O
the	O
functionality	O
of	O
soms	O
let	O
us	O
begin	O
with	O
a	O
simple	O
,	O
mentally	O
com-	O
prehensible	O
example	O
.	O
in	O
this	O
example	O
,	O
we	O
use	O
a	O
two-dimensional	O
input	O
space	O
,	O
i.e	O
.	O
n	O
=	O
2	O
is	O
true	O
.	O
let	O
the	O
grid	B
structure	O
be	O
one-dimensional	O
(	O
g	O
=	O
1	O
)	O
.	O
furthermore	O
,	O
our	O
example	O
som	O
should	O
consist	O
of	O
7	O
neurons	O
and	O
the	O
learning	B
rate	I
should	O
be	O
η	O
=	O
0.5.	O
the	O
neighborhood	O
function	B
is	O
also	O
kept	O
simple	O
so	O
that	O
we	O
will	O
be	O
able	O
to	O
mentally	O
comprehend	O
the	O
network	O
:	O
	O
h	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
=	O
1	O
k	O
direct	O
neighbor	O
of	O
i	O
,	O
1	O
k	O
=	O
i	O
,	O
0	O
otherw	O
.	O
(	O
10.4	O
)	O
now	O
let	O
us	O
take	O
a	O
look	O
at	O
the	O
above-	O
mentioned	O
network	O
with	O
random	O
initializa-	O
tion	O
of	O
the	O
centers	O
(	O
ﬁg	O
.	O
10.4	O
on	O
the	O
preced-	O
ing	O
page	O
)	O
and	O
enter	O
a	O
training	O
sample	O
p.	O
obviously	O
,	O
in	O
our	O
example	O
the	O
input	O
pat-	O
tern	O
is	O
closest	O
to	O
neuron	O
3	O
,	O
i.e	O
.	O
this	O
is	O
the	O
winning	O
neuron	O
.	O
we	O
remember	O
soms	O
learning	B
rule	O
the	O
for	O
∆ck	O
=	O
η	O
(	O
t	O
)	O
·	O
h	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
·	O
(	O
p	O
−	O
ck	O
)	O
thus	O
,	O
the	O
factor	O
(	O
p−	O
ck	O
)	O
indicates	O
the	O
vector	O
of	O
the	O
neuron	O
k	O
to	O
the	O
pattern	B
p.	O
this	O
is	O
now	O
multiplied	O
by	O
diﬀerent	O
scalars	O
:	O
our	O
topology	B
function	I
h	O
indicates	O
that	O
only	O
the	O
winner	O
neuron	O
and	O
its	O
two	O
closest	O
neighbors	O
(	O
here	O
:	O
2	O
and	O
4	O
)	O
are	O
allowed	O
to	O
learn	O
by	O
returning	O
0	O
for	O
all	O
other	O
neurons	O
.	O
a	O
time-dependence	O
is	O
not	O
speciﬁed	O
.	O
thus	O
,	O
our	O
vector	O
(	O
p	O
−	O
ck	O
)	O
is	O
multiplied	O
by	O
either	O
1	O
or	O
0.	O
the	O
learning	B
rate	I
indicates	O
,	O
as	O
always	O
,	O
the	O
strength	O
of	O
learning	B
.	O
as	O
already	O
mentioned	O
,	O
η	O
=	O
0.5	O
,	O
i.	O
e.	O
all	O
in	O
all	O
,	O
the	O
result	O
is	O
that	O
the	O
winner	O
neuron	O
and	O
its	O
neighbors	O
(	O
here	O
:	O
2	O
,	O
3	O
and	O
4	O
)	O
ap-	O
proximate	O
the	O
pattern	B
p	O
half	O
the	O
way	O
(	O
in	O
the	O
ﬁgure	O
marked	O
by	O
arrows	O
)	O
.	O
although	O
the	O
center	O
of	O
neuron	O
7	O
–	O
seen	O
from	O
the	O
input	O
space	O
–	O
is	O
considerably	O
closer	O
to	O
the	O
input	O
pattern	O
p	O
than	O
neuron	O
2	O
,	O
neuron	O
2	O
is	O
learning	B
and	O
neuron	O
7	O
is	O
not	O
.	O
i	O
want	O
to	O
remind	O
that	O
the	O
network	O
topology	O
speciﬁes	O
which	O
neuron	O
is	O
allowed	O
to	O
learn	O
and	O
not	O
its	O
position	O
in	O
the	O
input	O
space	O
.	O
this	O
is	O
exactly	O
the	O
mechanism	O
by	O
which	O
a	O
topology	B
can	O
signiﬁcantly	O
cover	O
an	O
input	O
space	O
without	O
having	O
to	O
be	O
related	O
to	O
it	O
by	O
any	O
sort	O
.	O
topology	B
speciﬁes	O
,	O
who	O
will	O
learn	O
and	O
process	O
the	O
three	O
factors	O
from	O
the	O
back	O
:	O
learning	B
direction	O
:	O
remember	O
that	O
the	O
neuron	O
centers	O
ck	O
are	O
vectors	O
in	O
the	O
input	O
space	O
,	O
as	O
well	O
as	O
the	O
pattern	B
p.	O
after	O
the	O
adaptation	O
of	O
the	O
neurons	O
2	O
,	O
3	O
and	O
4	O
the	O
next	O
pattern	B
is	O
applied	O
,	O
and	O
so	O
on	O
.	O
another	O
example	O
of	O
how	O
such	O
a	O
one-	O
dimensional	O
som	O
can	O
develop	O
in	O
a	O
two-	O
dimensional	O
input	O
space	O
with	O
uniformly	O
distributed	O
input	B
patterns	I
in	O
the	O
course	O
of	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
155	O
chapter	O
10	O
self-organizing	B
feature	I
maps	I
dkriesel.com	O
time	O
can	O
be	O
seen	O
in	O
ﬁgure	O
10.5	O
on	O
the	O
fac-	O
ing	O
page	O
.	O
end	O
states	O
of	O
one-	O
and	O
two-dimensional	O
soms	O
with	O
diﬀerently	O
shaped	O
input	O
spaces	O
can	O
be	O
seen	O
in	O
ﬁgure	O
10.6	O
on	O
page	O
158.	O
as	O
we	O
can	O
see	O
,	O
not	O
every	O
input	O
space	O
can	O
be	O
neatly	O
covered	O
by	O
every	O
network	O
topol-	O
ogy	O
.	O
there	O
are	O
so	O
called	O
exposed	O
neurons	O
–	O
neurons	O
which	O
are	O
located	O
in	O
an	O
area	O
where	O
no	O
input	O
pattern	O
has	O
ever	O
been	O
oc-	O
curred	O
.	O
a	O
one-dimensional	O
topology	B
gen-	O
erally	O
produces	O
less	O
exposed	O
neurons	O
than	O
a	O
two-dimensional	O
one	O
:	O
for	O
instance	O
,	O
dur-	O
ing	O
training	O
on	O
circularly	O
arranged	O
input	B
patterns	I
it	O
is	O
nearly	O
impossible	O
with	O
a	O
two-	O
dimensional	O
squared	O
topology	O
to	O
avoid	O
the	O
exposed	O
neurons	O
in	O
the	O
center	O
of	O
the	O
cir-	O
cle	O
.	O
these	O
are	O
pulled	O
in	O
every	O
direction	O
during	O
the	O
training	O
so	O
that	O
they	O
ﬁnally	O
remain	O
in	O
the	O
center	O
.	O
but	O
this	O
does	O
not	O
make	O
the	O
one-dimensional	O
topology	B
an	O
op-	O
timal	O
topology	B
since	O
it	O
can	O
only	O
ﬁnd	O
less	O
complex	O
neighborhood	O
relationships	O
than	O
a	O
multi-dimensional	O
one	O
.	O
10.4.1	O
topological	O
defects	O
are	O
failures	O
in	O
som	O
unfolding	O
''	O
knot	O
''	O
in	O
map	O
during	O
the	O
unfolding	O
of	O
a	O
som	O
it	O
could	O
happen	O
that	O
a	O
topological	B
defect	I
(	O
ﬁg	O
.	O
10.7	O
)	O
occurs	O
,	O
i.e	O
.	O
the	O
som	O
does	O
not	O
unfold	O
correctly	O
.	O
a	O
topological	B
defect	I
can	O
be	O
described	O
at	O
best	O
by	O
means	O
of	O
the	O
word	O
''	O
knotting	O
''	O
.	O
figure	O
10.7	O
:	O
a	O
topological	B
defect	I
in	O
a	O
two-	O
dimensional	O
som	O
.	O
neighborhood	O
size	O
,	O
because	O
the	O
more	O
com-	O
plex	O
the	O
topology	B
is	O
(	O
or	O
the	O
more	O
neigh-	O
bors	O
each	O
neuron	O
has	O
,	O
respectively	O
,	O
since	O
a	O
three-dimensional	O
or	O
a	O
honeycombed	O
two-	O
dimensional	O
topology	B
could	O
also	O
be	O
gener-	O
ated	O
)	O
the	O
more	O
diﬃcult	O
it	O
is	O
for	O
a	O
randomly	O
initialized	O
map	O
to	O
unfold	O
.	O
10.5	O
it	O
is	O
possible	O
to	O
adjust	O
the	O
resolution	O
of	O
certain	O
areas	O
in	O
a	O
som	O
a	O
remedy	O
for	O
topological	O
defects	O
could	O
be	O
to	O
increase	O
the	O
initial	O
values	O
for	O
the	O
we	O
have	O
seen	O
that	O
a	O
som	O
is	O
trained	O
by	O
entering	O
input	B
patterns	I
of	O
the	O
input	O
space	O
156	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
10.5	O
adjustment	O
of	O
resolution	O
and	O
position-dependent	O
learning	B
rate	I
figure	O
10.5	O
:	O
behavior	O
of	O
a	O
som	O
with	O
one-dimensional	O
topology	B
(	O
g	O
=	O
1	O
)	O
after	O
the	O
input	O
of	O
0	O
,	O
100	O
,	O
300	O
,	O
500	O
,	O
5000	O
,	O
50000	O
,	O
70000	O
and	O
80000	O
randomly	O
distributed	O
input	B
patterns	I
p	O
∈	O
r2	O
.	O
during	O
the	O
training	O
η	O
decreased	O
from	O
1.0	O
to	O
0.1	O
,	O
the	O
σ	O
parameter	O
of	O
the	O
gauss	O
function	B
decreased	O
from	O
10.0	O
to	O
0.2.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
157	O
chapter	O
10	O
self-organizing	B
feature	I
maps	I
dkriesel.com	O
figure	O
10.6	O
:	O
end	O
states	O
of	O
one-dimensional	O
(	O
left	O
column	O
)	O
and	O
two-dimensional	O
(	O
right	O
column	O
)	O
soms	O
on	O
diﬀerent	O
input	O
spaces	O
.	O
200	O
neurons	O
were	O
used	O
for	O
the	O
one-dimensional	O
topology	B
,	O
10	O
×	O
10	O
neurons	O
for	O
the	O
two-dimensionsal	O
topology	B
and	O
80.000	O
input	B
patterns	I
for	O
all	O
maps	O
.	O
158	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
more	O
patterns	O
↓	O
higher	O
resolution	O
dkriesel.com	O
10.6	O
application	O
rn	O
one	O
after	O
another	O
,	O
again	O
and	O
again	O
so	O
that	O
the	O
som	O
will	O
be	O
aligned	O
with	O
these	O
patterns	O
and	O
map	O
them	O
.	O
it	O
could	O
happen	O
that	O
we	O
want	O
a	O
certain	O
subset	O
u	O
of	O
the	O
in-	O
put	O
space	O
to	O
be	O
mapped	O
more	O
precise	O
than	O
the	O
other	O
ones	O
.	O
this	O
problem	O
can	O
easily	O
be	O
solved	O
by	O
means	O
of	O
soms	O
:	O
during	O
the	O
training	O
dis-	O
proportionally	O
many	O
input	B
patterns	I
of	O
the	O
area	O
u	O
are	O
presented	O
to	O
the	O
som	O
.	O
if	O
the	O
number	O
of	O
training	O
patterns	O
of	O
u	O
⊂	O
rn	O
presented	O
to	O
the	O
som	O
exceeds	O
the	O
number	O
of	O
those	O
patterns	O
of	O
the	O
remaining	O
rn	O
\	O
u	O
,	O
then	O
more	O
neurons	O
will	O
group	O
there	O
while	O
the	O
remaining	O
neurons	O
are	O
sparsely	O
dis-	O
tributed	O
on	O
rn	O
\	O
u	O
(	O
ﬁg	O
.	O
10.8	O
on	O
the	O
next	O
page	O
)	O
.	O
as	O
you	O
can	O
see	O
in	O
the	O
illustration	O
,	O
the	O
edge	O
of	O
the	O
som	O
could	O
be	O
deformed	O
.	O
this	O
can	O
be	O
compensated	O
by	O
assigning	O
to	O
the	O
edge	O
of	O
the	O
input	O
space	O
a	O
slightly	O
higher	O
proba-	O
bility	O
of	O
being	O
hit	O
by	O
training	O
patterns	O
(	O
an	O
often	O
applied	O
approach	O
for	O
reaching	O
every	O
corner	O
with	O
the	O
soms	O
)	O
.	O
also	O
,	O
a	O
higher	O
learning	B
rate	I
is	O
often	O
used	O
for	O
edge	O
and	O
corner	O
neurons	O
,	O
since	O
they	O
are	O
only	O
pulled	O
into	O
the	O
center	O
by	O
the	O
topol-	O
ogy	O
.	O
this	O
also	O
results	O
in	O
a	O
signiﬁcantly	O
im-	O
proved	O
corner	O
coverage	O
.	O
10.6	O
application	O
of	O
soms	O
regarding	O
the	O
biologically	O
inspired	O
asso-	O
ciative	O
data	O
storage	O
,	O
there	O
are	O
many	O
ﬁelds	O
of	O
application	O
for	O
self-organizing	O
maps	O
and	O
their	O
variations	O
.	O
for	O
example	O
,	O
the	O
diﬀerent	O
phonemes	O
of	O
the	O
ﬁnnish	O
language	O
have	O
successfully	O
been	O
mapped	O
onto	O
a	O
som	O
with	O
a	O
two	O
dimen-	O
sional	O
discrete	B
grid	O
topology	B
and	O
therefore	O
neighborhoods	O
have	O
been	O
found	O
(	O
a	O
som	O
does	O
nothing	O
else	O
than	O
ﬁnding	O
neighbor-	O
hood	O
relationships	O
)	O
.	O
so	O
one	O
tries	O
once	O
more	O
to	O
break	O
down	O
a	O
high-dimensional	O
space	O
into	O
a	O
low-dimensional	O
space	O
(	O
the	O
topology	B
)	O
,	O
looks	O
if	O
some	O
structures	O
have	O
been	O
developed	O
–	O
et	O
voilà	O
:	O
clearly	O
deﬁned	O
areas	O
for	O
the	O
individual	O
phenomenons	O
are	O
formed	O
.	O
teuvo	O
kohonen	O
himself	O
made	O
the	O
ef-	O
fort	O
to	O
search	O
many	O
papers	O
mentioning	O
his	O
soms	O
in	O
their	O
keywords	O
.	O
in	O
this	O
large	O
in-	O
put	O
space	O
the	O
individual	O
papers	O
now	O
indi-	O
vidual	O
positions	O
,	O
depending	O
on	O
the	O
occur-	O
rence	O
of	O
keywords	O
.	O
then	O
kohonen	O
created	O
a	O
som	O
with	O
g	O
=	O
2	O
and	O
used	O
it	O
to	O
map	O
the	O
high-dimensional	O
``	O
paper	O
space	O
''	O
developed	O
by	O
him	O
.	O
thus	O
,	O
it	O
is	O
possible	O
to	O
enter	O
any	O
paper	O
into	O
the	O
completely	O
trained	O
som	O
and	O
look	O
which	O
neuron	O
in	O
the	O
som	O
is	O
activated	O
.	O
it	O
will	O
be	O
likely	O
to	O
discover	O
that	O
the	O
neigh-	O
bored	O
papers	O
in	O
the	O
topology	B
are	O
interest-	O
ing	O
,	O
too	O
.	O
this	O
type	O
of	O
brain-like	O
context-	O
based	O
search	O
also	O
works	O
with	O
many	O
other	O
input	O
spaces	O
.	O
it	O
is	O
to	O
be	O
noted	O
that	O
the	O
system	O
itself	O
similar	O
,	O
deﬁnes	O
what	O
is	O
neighbored	O
,	O
i.e	O
.	O
within	O
the	O
topology	B
–	O
and	O
that	O
’	O
s	O
why	O
it	O
is	O
so	O
interesting	O
.	O
this	O
example	O
shows	O
that	O
the	O
position	O
c	O
of	O
the	O
neurons	O
in	O
the	O
input	O
space	O
is	O
not	O
signif-	O
icant	O
.	O
it	O
is	O
rather	O
interesting	O
to	O
see	O
which	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
159	O
som	O
ﬁnds	O
similarities	O
chapter	O
10	O
self-organizing	B
feature	I
maps	I
dkriesel.com	O
figure	O
10.8	O
:	O
training	O
of	O
a	O
som	O
with	O
g	O
=	O
2	O
on	O
a	O
two-dimensional	O
input	O
space	O
.	O
on	O
the	O
left	O
side	O
,	O
the	O
chance	O
to	O
become	O
a	O
training	B
pattern	I
was	O
equal	O
for	O
each	O
coordinate	O
of	O
the	O
input	O
space	O
.	O
on	O
the	O
right	O
side	O
,	O
for	O
the	O
central	O
circle	O
in	O
the	O
input	O
space	O
,	O
this	O
chance	O
is	O
more	O
than	O
ten	O
times	O
larger	O
than	O
for	O
the	O
remaining	O
input	O
space	O
(	O
visible	O
in	O
the	O
larger	O
pattern	B
density	O
in	O
the	O
background	O
)	O
.	O
in	O
this	O
circle	O
the	O
neurons	O
are	O
obviously	O
more	O
crowded	O
and	O
the	O
remaining	O
area	O
is	O
covered	O
less	O
dense	O
but	O
in	O
both	O
cases	O
the	O
neurons	O
are	O
still	O
evenly	O
distributed	O
.	O
the	O
two	O
soms	O
were	O
trained	O
by	O
means	O
of	O
80.000	O
training	O
samples	O
and	O
decreasing	O
η	O
(	O
1	O
→	O
0.2	O
)	O
as	O
well	O
as	O
decreasing	O
σ	O
(	O
5	O
→	O
0.5	O
)	O
.	O
160	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
10.7	O
variations	O
neuron	O
is	O
activated	O
when	O
an	O
unknown	O
in-	O
put	O
pattern	B
is	O
entered	O
.	O
next	O
,	O
we	O
can	O
look	O
at	O
which	O
of	O
the	O
previous	O
inputs	O
this	O
neu-	O
ron	O
was	O
also	O
activated	O
–	O
and	O
will	O
imme-	O
diately	O
discover	O
a	O
group	O
of	O
very	O
similar	O
inputs	O
.	O
the	O
more	O
the	O
inputs	O
within	O
the	O
topology	B
are	O
diverging	O
,	O
the	O
less	O
things	O
they	O
have	O
in	O
common	O
.	O
virtually	O
,	O
the	O
topology	B
generates	O
a	O
map	O
of	O
the	O
input	O
characteris-	O
tics	O
–	O
reduced	O
to	O
descriptively	O
few	O
dimen-	O
sions	O
in	O
relation	O
to	O
the	O
input	B
dimension	I
.	O
therefore	O
,	O
the	O
topology	B
of	O
a	O
som	O
often	O
is	O
two-dimensional	O
so	O
that	O
it	O
can	O
be	O
easily	O
visualized	O
,	O
while	O
the	O
input	O
space	O
can	O
be	O
very	O
high-dimensional	O
.	O
10.6.1	O
soms	O
can	O
be	O
used	O
to	O
determine	O
centers	O
for	O
rbf	O
neurons	O
soms	O
arrange	O
themselves	O
exactly	O
towards	O
the	O
positions	O
of	O
the	O
outgoing	O
inputs	O
.	O
as	O
a	O
result	O
they	O
are	O
used	O
,	O
for	O
example	O
,	O
to	O
select	O
the	O
centers	O
of	O
an	O
rbf	O
network	O
.	O
we	O
have	O
already	O
been	O
introduced	O
to	O
the	O
paradigm	O
of	O
the	O
rbf	O
network	O
in	O
chapter	O
6.	O
as	O
we	O
have	O
already	O
seen	O
,	O
it	O
is	O
possible	O
to	O
control	O
which	O
areas	O
of	O
the	O
input	O
space	O
should	O
be	O
covered	O
with	O
higher	O
resolution	O
-	O
or	O
,	O
in	O
connection	B
with	O
rbf	O
networks	O
,	O
on	O
which	O
areas	O
of	O
our	O
function	B
should	O
the	O
rbf	O
network	O
work	O
with	O
more	O
neurons	O
,	O
i.e	O
.	O
work	O
more	O
exactly	O
.	O
as	O
a	O
further	O
useful	O
fea-	O
ture	O
of	O
the	O
combination	O
of	O
rbf	O
networks	O
with	O
soms	O
one	O
can	O
use	O
the	O
topology	B
ob-	O
tained	O
through	O
the	O
som	O
:	O
during	O
the	O
ﬁnal	O
training	O
of	O
a	O
rbf	O
neuron	O
it	O
can	O
be	O
used	O
to	O
inﬂuence	O
neighboring	O
rbf	O
neurons	O
in	O
diﬀerent	O
ways	O
.	O
for	O
this	O
,	O
many	O
neural	O
network	O
simulators	O
oﬀer	O
an	O
additional	O
so-called	O
som	O
layer	B
in	O
connection	B
with	O
the	O
simulation	O
of	O
rbf	O
networks	O
.	O
10.7	O
variations	O
of	O
soms	O
there	O
are	O
diﬀerent	O
variations	O
of	O
soms	O
for	O
diﬀerent	O
variations	O
of	O
representation	O
tasks	O
:	O
10.7.1	O
a	O
neural	O
gas	O
is	O
a	O
som	O
without	O
a	O
static	O
topology	B
the	O
neural	O
gas	O
is	O
a	O
variation	O
of	O
the	O
self-	O
organizing	O
maps	O
of	O
thomas	O
martinetz	O
[	O
mbs93	O
]	O
,	O
which	O
has	O
been	O
developed	O
from	O
the	O
diﬃculty	O
of	O
mapping	O
complex	O
input	O
information	O
that	O
partially	O
only	O
occur	O
in	O
the	O
subspaces	O
of	O
the	O
input	O
space	O
or	O
even	O
change	O
the	O
subspaces	O
(	O
ﬁg	O
.	O
10.9	O
on	O
the	O
fol-	O
lowing	O
page	O
)	O
.	O
the	O
idea	O
of	O
a	O
neural	O
gas	O
is	O
,	O
roughly	O
speak-	O
ing	O
,	O
to	O
realize	O
a	O
som	O
without	O
a	O
grid	B
struc-	O
ture	O
.	O
due	O
to	O
the	O
fact	O
that	O
they	O
are	O
de-	O
rived	O
from	O
the	O
soms	O
the	O
learning	B
steps	O
are	O
very	O
similar	O
to	O
the	O
som	O
learning	B
steps	O
,	O
but	O
they	O
include	O
an	O
additional	O
intermedi-	O
ate	O
step	O
:	O
.	O
again	O
,	O
random	O
initialization	O
of	O
ck	O
∈	O
rn	O
.	O
selection	O
and	O
presentation	O
of	O
a	O
pat-	O
tern	O
of	O
the	O
input	O
space	O
p	O
∈	O
rn	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
161	O
chapter	O
10	O
self-organizing	B
feature	I
maps	I
dkriesel.com	O
dynamic	O
neighborhood	O
figure	O
10.9	O
:	O
a	O
ﬁgure	O
ﬁlling	O
diﬀerent	O
subspaces	O
of	O
the	O
actual	O
input	O
space	O
of	O
diﬀerent	O
positions	O
therefore	O
can	O
hardly	O
be	O
ﬁlled	O
by	O
a	O
som	O
.	O
.	O
neuron	O
distance	O
measurement	O
.	O
identiﬁcation	O
of	O
the	O
winner	O
neuron	O
i	O
.	O
intermediate	O
step	O
:	O
generation	O
of	O
a	O
list	O
l	O
of	O
neurons	O
sorted	O
in	O
ascending	O
order	O
by	O
their	O
distance	O
to	O
the	O
winner	O
neu-	O
ron	O
.	O
thus	O
,	O
the	O
ﬁrst	O
neuron	O
in	O
the	O
list	O
l	O
is	O
the	O
neuron	O
that	O
is	O
closest	O
to	O
the	O
winner	O
neuron	O
.	O
.	O
changing	O
the	O
centers	O
by	O
means	O
of	O
the	O
known	O
rule	O
but	O
with	O
the	O
slightly	O
mod-	O
iﬁed	O
topology	B
function	I
hl	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
.	O
the	O
function	B
hl	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
,	O
which	O
is	O
slightly	O
modiﬁed	O
compared	O
with	O
the	O
original	O
func-	O
tion	O
h	O
(	O
i	O
,	O
k	O
,	O
t	O
)	O
,	O
now	O
regards	O
the	O
ﬁrst	O
el-	O
ements	O
of	O
the	O
list	O
as	O
the	O
neighborhood	O
of	O
the	O
winner	O
neuron	O
i.	O
the	O
direct	O
re-	O
sult	O
is	O
that	O
–	O
similar	O
to	O
the	O
free-ﬂoating	O
molecules	O
in	O
a	O
gas	O
–	O
the	O
neighborhood	O
rela-	O
tionships	O
between	O
the	O
neurons	O
can	O
change	O
anytime	O
,	O
and	O
the	O
number	O
of	O
neighbors	O
is	O
almost	O
arbitrary	O
,	O
too	O
.	O
the	O
distance	O
within	O
the	O
neighborhood	O
is	O
now	O
represented	O
by	O
the	O
distance	O
within	O
the	O
input	O
space	O
.	O
the	O
bulk	O
of	O
neurons	O
can	O
become	O
as	O
stiﬀ-	O
ened	O
as	O
a	O
som	O
by	O
means	O
of	O
a	O
constantly	O
decreasing	O
neighborhood	O
size	O
.	O
it	O
does	O
not	O
have	O
a	O
ﬁxed	O
dimension	O
but	O
it	O
can	O
take	O
the	O
dimension	O
that	O
is	O
locally	O
needed	O
at	O
the	O
mo-	O
ment	O
,	O
which	O
can	O
be	O
very	O
advantageous	O
.	O
a	O
disadvantage	O
could	O
be	O
that	O
there	O
is	O
no	O
ﬁxed	O
grid	B
forcing	O
the	O
input	O
space	O
to	O
become	O
regularly	O
covered	O
,	O
and	O
therefore	O
wholes	O
can	O
occur	O
in	O
the	O
cover	O
or	O
neurons	O
can	O
be	O
isolated	O
.	O
162	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
can	O
classify	O
complex	O
ﬁgure	O
dkriesel.com	O
10.7	O
variations	O
in	O
spite	O
of	O
all	O
practical	O
hints	O
,	O
it	O
is	O
as	O
al-	O
ways	O
the	O
user	O
’	O
s	O
responsibility	O
not	O
to	O
un-	O
derstand	O
this	O
text	O
as	O
a	O
catalog	O
for	O
easy	O
an-	O
swers	O
but	O
to	O
explore	O
all	O
advantages	O
and	O
disadvantages	O
himself	O
.	O
unlike	O
a	O
som	O
,	O
the	O
neighborhood	O
of	O
a	O
neu-	O
ral	O
gas	O
must	O
initially	O
refer	O
to	O
all	O
neurons	O
since	O
otherwise	O
some	O
outliers	O
of	O
the	O
ran-	O
dom	O
initialization	O
may	O
never	O
reach	O
the	O
re-	O
maining	O
group	O
.	O
to	O
forget	O
this	O
is	O
a	O
popular	O
error	O
during	O
the	O
implementation	O
of	O
a	O
neu-	O
ral	O
gas	O
.	O
with	O
a	O
neural	O
gas	O
it	O
is	O
possible	O
to	O
learn	O
a	O
kind	O
of	O
complex	O
input	O
such	O
as	O
in	O
ﬁg	O
.	O
10.9	O
on	O
the	O
preceding	O
page	O
since	O
we	O
are	O
not	O
bound	O
to	O
a	O
ﬁxed-dimensional	O
grid	B
.	O
but	O
some	O
computational	O
eﬀort	O
could	O
be	O
neces-	O
sary	O
for	O
the	O
permanent	O
sorting	O
of	O
the	O
list	O
(	O
here	O
,	O
it	O
could	O
be	O
eﬀective	O
to	O
store	O
the	O
list	O
in	O
an	O
ordered	O
data	O
structure	O
right	O
from	O
the	O
start	O
)	O
.	O
deﬁnition	O
10.6	O
(	O
neural	O
gas	O
)	O
.	O
a	O
neural	O
gas	O
diﬀers	O
from	O
a	O
som	O
by	O
a	O
completely	O
dy-	O
namic	O
neighborhood	O
function	B
.	O
with	O
every	O
learning	B
cycle	O
it	O
is	O
decided	O
anew	O
which	O
neu-	O
rons	O
are	O
the	O
neigborhood	O
neurons	O
of	O
the	O
winner	O
neuron	O
.	O
generally	O
,	O
the	O
criterion	O
for	O
this	O
decision	O
is	O
the	O
distance	O
between	O
the	O
neurosn	O
and	O
the	O
winner	O
neuron	O
in	O
the	O
input	O
space	O
.	O
10.7.2	O
a	O
multi-som	O
consists	O
of	O
several	O
separate	O
soms	O
in	O
order	O
to	O
present	O
another	O
variant	O
of	O
the	O
soms	O
,	O
i	O
want	O
to	O
formulate	O
an	O
extended	O
problem	O
:	O
what	O
do	O
we	O
do	O
with	O
input	O
pat-	O
terns	O
from	O
which	O
we	O
know	O
that	O
they	O
are	O
conﬁned	O
in	O
diﬀerent	O
(	O
maybe	O
disjoint	O
)	O
ar-	O
eas	O
?	O
here	O
,	O
the	O
idea	O
is	O
to	O
use	O
not	O
only	O
one	O
som	O
but	O
several	O
ones	O
:	O
a	O
multi-self-	O
organizing	O
map	O
,	O
shortly	O
referred	O
to	O
as	O
m-som	O
[	O
gke01b	O
,	O
gke01a	O
,	O
gs06	O
]	O
.	O
it	O
is	O
unnecessary	O
that	O
the	O
soms	O
have	O
the	O
same	O
topology	B
or	O
size	O
,	O
an	O
m-som	O
is	O
just	O
a	O
com-	O
bination	O
of	O
m	O
soms	O
.	O
this	O
learning	B
process	O
is	O
analog	O
to	O
that	O
of	O
the	O
soms	O
.	O
however	O
,	O
only	O
the	O
neurons	O
be-	O
longing	O
to	O
the	O
winner	O
som	O
of	O
each	O
train-	O
ing	O
step	O
are	O
adapted	O
.	O
thus	O
,	O
it	O
is	O
easy	O
to	O
represent	O
two	O
disjoint	O
clusters	B
of	O
data	O
by	O
means	O
of	O
two	O
soms	O
,	O
even	O
if	O
one	O
of	O
the	O
clusters	B
is	O
not	O
represented	O
in	O
every	O
dimen-	O
sion	O
of	O
the	O
input	O
space	O
rn	O
.	O
actually	O
,	O
the	O
individual	O
soms	O
exactly	O
reﬂect	O
these	O
clus-	O
ters	O
.	O
deﬁnition	O
10.7	O
(	O
multi-som	O
)	O
.	O
a	O
multi-	O
som	O
is	O
nothing	O
more	O
than	O
the	O
simultane-	O
ous	O
use	O
of	O
m	O
soms	O
.	O
10.7.3	O
a	O
multi-neural	B
gas	I
consists	O
of	O
several	O
separate	O
neural	O
gases	O
analogous	O
to	O
the	O
multi-som	O
,	O
we	O
also	O
have	O
a	O
set	O
of	O
m	O
neural	O
gases	O
:	O
a	O
multi-neural	B
gas	I
[	O
gs06	O
,	O
sg06	O
]	O
.	O
this	O
construct	O
be-	O
haves	O
analogous	O
to	O
neural	O
gas	O
and	O
m-som	O
:	O
again	O
,	O
only	O
the	O
neurons	O
of	O
the	O
winner	O
gas	O
are	O
adapted	O
.	O
the	O
reader	O
certainly	O
wonders	O
what	O
advan-	O
tage	O
is	O
there	O
to	O
use	O
a	O
multi-neural	B
gas	I
since	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
163	O
several	O
soms	O
several	O
gases	O
less	O
computa-	O
tional	O
eﬀort	O
chapter	O
10	O
self-organizing	B
feature	I
maps	I
dkriesel.com	O
an	O
individual	O
neural	O
gas	O
is	O
already	O
capa-	O
ble	O
to	O
divide	O
into	O
clusters	B
and	O
to	O
work	O
on	O
complex	O
input	B
patterns	I
with	O
changing	O
di-	O
mensions	O
.	O
basically	O
,	O
this	O
is	O
correct	O
,	O
but	O
a	O
multi-neural	B
gas	I
has	O
two	O
serious	O
advan-	O
tages	O
over	O
a	O
simple	O
neural	O
gas	O
.	O
1.	O
with	O
several	O
gases	O
,	O
we	O
can	O
directly	O
tell	O
which	O
neuron	O
belongs	O
to	O
which	O
gas	O
.	O
this	O
is	O
particularly	O
important	O
for	O
clustering	O
tasks	O
,	O
for	O
which	O
multi-	O
neural	O
gases	O
have	O
been	O
used	O
recently	O
.	O
simple	O
neural	O
gases	O
can	O
also	O
ﬁnd	O
and	O
cover	O
clusters	B
,	O
but	O
now	O
we	O
can	O
not	O
rec-	O
ognize	O
which	O
neuron	O
belongs	O
to	O
which	O
cluster	O
.	O
2.	O
a	O
lot	O
of	O
computational	O
eﬀort	O
is	O
saved	O
when	O
large	O
original	O
gases	O
are	O
divided	O
into	O
several	O
smaller	O
ones	O
since	O
(	O
as	O
al-	O
ready	O
mentioned	O
)	O
the	O
sorting	O
of	O
the	O
list	O
l	O
could	O
use	O
a	O
lot	O
of	O
computa-	O
tional	O
eﬀort	O
while	O
the	O
sorting	O
of	O
sev-	O
eral	O
smaller	O
lists	O
l1	O
,	O
l2	O
,	O
.	O
.	O
.	O
,	O
lm	O
is	O
less	O
time-consuming	O
–	O
even	O
if	O
these	O
lists	O
in	O
total	O
contain	O
the	O
same	O
number	O
of	O
neu-	O
rons	O
.	O
as	O
a	O
result	O
we	O
will	O
only	O
obtain	O
local	O
in-	O
stead	O
of	O
global	O
sortings	O
,	O
but	O
in	O
most	O
cases	O
these	O
local	O
sortings	O
are	O
suﬃcient	O
.	O
now	O
we	O
can	O
choose	O
between	O
two	O
extreme	O
cases	O
of	O
multi-neural	O
gases	O
:	O
one	O
extreme	O
case	O
is	O
the	O
ordinary	O
neural	O
gas	O
m	O
=	O
1	O
,	O
i.e	O
.	O
we	O
only	O
use	O
one	O
single	O
neural	O
gas	O
.	O
interest-	O
ing	O
enough	O
,	O
the	O
other	O
extreme	O
case	O
(	O
very	O
large	O
m	O
,	O
a	O
few	O
or	O
only	O
one	O
neuron	O
per	O
gas	O
)	O
behaves	O
analogously	O
to	O
the	O
k-means	O
clus-	O
tering	O
(	O
for	O
more	O
information	O
on	O
clustering	O
procedures	O
see	O
excursus	O
a	O
)	O
.	O
deﬁnition	O
10.8	O
(	O
multi-neural	B
gas	I
)	O
.	O
a	O
multi-neural	B
gas	I
is	O
nothing	O
more	O
than	O
the	O
simultaneous	O
use	O
of	O
m	O
neural	O
gases	O
.	O
10.7.4	O
growing	O
neural	O
gases	O
can	O
add	O
neurons	O
to	O
themselves	O
a	O
growing	B
neural	I
gas	I
is	O
a	O
variation	O
of	O
the	O
aforementioned	O
neural	O
gas	O
to	O
which	O
more	O
and	O
more	O
neurons	O
are	O
added	O
accord-	O
ing	O
to	O
certain	O
rules	O
.	O
thus	O
,	O
this	O
is	O
an	O
at-	O
tempt	O
to	O
work	O
against	O
the	O
isolation	O
of	O
neu-	O
rons	O
or	O
the	O
generation	O
of	O
larger	O
wholes	O
in	O
the	O
cover	O
.	O
here	O
,	O
this	O
subject	O
should	O
only	O
be	O
men-	O
tioned	O
but	O
not	O
discussed	O
.	O
to	O
build	O
a	O
growing	B
som	O
is	O
more	O
diﬃcult	O
because	O
new	O
neurons	O
have	O
to	O
be	O
integrated	O
in	O
the	O
neighborhood	O
.	O
exercises	O
exercise	O
17.	O
a	O
regular	O
,	O
two-dimensional	O
grid	B
shall	O
cover	O
a	O
two-dimensional	O
surface	O
as	O
``	O
well	O
''	O
as	O
possible	O
.	O
1.	O
which	O
grid	B
structure	O
would	O
suit	O
best	O
for	O
this	O
purpose	O
?	O
2.	O
which	O
criteria	O
did	O
you	O
use	O
for	O
``	O
well	O
''	O
and	O
``	O
best	O
''	O
?	O
the	O
very	O
imprecise	O
formulation	O
of	O
this	O
ex-	O
ercise	O
is	O
intentional	O
.	O
164	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
chapter	O
11	O
adaptive	B
resonance	I
theory	I
an	O
art	O
network	O
in	O
its	O
original	O
form	O
shall	O
classify	O
binary	O
input	O
vectors	O
,	O
i.e	O
.	O
to	O
assign	O
them	O
to	O
a	O
1-out-of-n	O
output	O
.	O
simultaneously	O
,	O
the	O
so	O
far	O
unclassiﬁed	O
patterns	O
shall	O
be	O
recognized	O
and	O
assigned	O
to	O
a	O
new	O
class	O
.	O
as	O
in	O
the	O
other	O
smaller	O
chapters	O
,	O
we	O
want	O
to	O
try	O
to	O
ﬁgure	O
out	O
the	O
basic	O
idea	O
of	O
the	O
adaptive	B
resonance	I
theory	I
(	O
abbre-	O
viated	O
:	O
art	O
)	O
without	O
discussing	O
its	O
the-	O
ory	O
profoundly	O
.	O
in	O
several	O
sections	O
we	O
have	O
already	O
men-	O
tioned	O
that	O
it	O
is	O
diﬃcult	O
to	O
use	O
neural	O
networks	O
for	O
the	O
learning	B
of	O
new	O
informa-	O
tion	O
in	O
addition	O
to	O
but	O
without	O
destroying	O
the	O
already	O
existing	O
information	O
.	O
this	O
cir-	O
cumstance	O
is	O
called	O
stability	B
/	I
plasticity	I
dilemma	I
.	O
in	O
1987	O
,	O
stephen	O
grossberg	O
and	O
gail	O
carpenter	O
published	O
the	O
ﬁrst	O
version	O
of	O
their	O
art	O
network	O
[	O
gro76	O
]	O
in	O
order	O
to	O
al-	O
leviate	O
this	O
problem	O
.	O
this	O
was	O
followed	O
by	O
a	O
whole	O
family	O
of	O
art	O
improvements	O
(	O
which	O
we	O
want	O
to	O
discuss	O
brieﬂy	O
,	O
too	O
)	O
.	O
it	O
is	O
the	O
idea	O
of	O
unsupervised	B
learning	I
,	O
whose	O
aim	O
is	O
the	O
(	O
initially	O
binary	O
)	O
pattern	B
recognition	I
,	O
or	O
more	O
precisely	O
the	O
catego-	O
rization	O
of	O
patterns	O
into	O
classes	O
.	O
but	O
addi-	O
tionally	O
an	O
art	O
network	O
shall	O
be	O
capable	O
to	O
ﬁnd	O
new	O
classes	O
.	O
11.1	O
task	O
and	O
structure	O
of	O
an	O
art	O
network	O
an	O
art	O
network	O
comprises	O
exactly	O
two	O
layers	O
:	O
the	O
input	B
layer	I
i	O
and	O
the	O
recog-	O
nition	O
layer	B
o	O
with	O
the	O
input	B
layer	I
be-	O
ing	O
completely	O
linked	O
towards	O
the	O
recog-	O
nition	O
layer	B
.	O
this	O
complete	O
link	O
induces	O
a	O
top-down	B
weight	O
matrix	O
w	O
that	O
con-	O
tains	O
the	O
weight	B
values	O
of	O
the	O
connections	O
between	O
each	O
neuron	O
in	O
the	O
input	B
layer	I
and	O
each	O
neuron	O
in	O
the	O
recognition	O
layer	B
(	O
ﬁg	O
.	O
11.1	O
on	O
the	O
following	O
page	O
)	O
.	O
simple	O
binary	O
patterns	O
are	O
entered	O
into	O
the	O
input	B
layer	I
and	O
transferred	O
to	O
the	O
recognition	O
layer	B
while	O
the	O
recognition	O
layer	B
shall	O
return	B
a	O
1-out-of-|o|	O
encoding	O
,	O
i.e	O
.	O
it	O
should	O
follow	O
the	O
winner-takes-all	O
pattern	O
recognition	O
165	O
chapter	O
11	O
adaptive	B
resonance	I
theory	I
dkriesel.com	O
i2	O
i3	O
i4	O
i1	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
gfed	O
@	O
abc	O
5kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk	O
)	O
ssssssssssssssssssssssssssssssssssssss	O
7ooooooooooooooooooooooooooooo	O
7ooooooooooooooooooooooooooooo	O
'ooooooooooooooooooooooooooooo	O
'ooooooooooooooooooooooooooooo	O
issssssssssssssssssssssssssssssssssssss	O
;	O
xxxxxxxxxxxxxxxxxxxxx	O
;	O
xxxxxxxxxxxxxxxxxxxxx	O
;	O
xxxxxxxxxxxxxxxxxxxxx	O
#	O
fffffffffffffffffffff	O
#	O
fffffffffffffffffffff	O
#	O
fffffffffffffffffffff	O
gooooooooooooooooooooooooooooo	O
gooooooooooooooooooooooooooooo	O
ukkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk	O
cfffffffffffffffffffff	O
cfffffffffffffffffffff	O
cfffffffffffffffffffff	O
e	O
e	O
e	O
e	O
44444444444444	O
44444444444444	O
44444444444444	O
44444444444444	O
wooooooooooooooooooooooooooooo	O
wooooooooooooooooooooooooooooo	O
y44444444444444	O
y44444444444444	O
y44444444444444	O
y44444444444444	O
{	O
xxxxxxxxxxxxxxxxxxxxx	O
{	O
xxxxxxxxxxxxxxxxxxxxx	O
{	O
xxxxxxxxxxxxxxxxxxxxx	O
	O
	O
	O
	O
gfed	O
@	O
abcω1	O
gfed	O
gfed	O
@	O
abcω2	O
gfed	O
@	O
abcω3	O
gfed	O
@	O
abcω4	O
gfed	O
@	O
abcω5	O
@	O
abcω6	O
figure	O
11.1	O
:	O
simpliﬁed	O
illustration	O
of	O
the	O
art	O
network	O
structure	O
.	O
top	O
:	O
the	O
input	B
layer	I
,	O
bottom	O
:	O
the	O
recognition	O
layer	B
.	O
in	O
this	O
illustration	O
the	O
lateral	O
inhibition	O
of	O
the	O
recognition	O
layer	B
and	O
the	O
control	O
neurons	O
are	O
omitted	O
.	O
scheme	O
.	O
for	O
instance	O
,	O
to	O
realize	O
this	O
1-	O
out-of-|o|	O
encoding	O
the	O
principle	O
of	O
lateral	O
inhibition	O
can	O
be	O
used	O
–	O
or	O
in	O
the	O
imple-	O
mentation	O
the	O
most	O
activated	O
neuron	O
can	O
be	O
searched	O
.	O
for	O
practical	O
reasons	O
an	O
if	O
query	O
would	O
suit	O
this	O
task	O
best	O
.	O
put	O
layer	B
causes	O
an	O
activity	O
within	O
the	O
recognition	O
layer	B
while	O
in	O
turn	O
in	O
the	O
recog-	O
nition	O
layer	B
every	O
activity	O
causes	O
an	O
activ-	O
ity	O
within	O
the	O
input	B
layer	I
.	O
layers	O
activate	O
one	O
another	O
11.1.1	O
resonance	B
takes	O
place	O
by	O
activities	O
being	O
tossed	O
and	O
turned	O
v	O
(	O
cid:73	O
)	O
but	O
there	O
also	O
exists	O
a	O
bottom-up	B
weight	O
matrix	O
v	O
,	O
which	O
propagates	O
the	O
activi-	O
ties	O
within	O
the	O
recognition	O
layer	B
back	O
into	O
the	O
input	B
layer	I
.	O
now	O
it	O
is	O
obvious	O
that	O
these	O
activities	O
are	O
bounced	O
forth	O
and	O
back	O
again	O
and	O
again	O
,	O
a	O
fact	O
that	O
leads	O
us	O
to	O
resonance	B
.	O
every	O
activity	O
within	O
the	O
in-	O
in	O
addition	O
to	O
the	O
two	O
mentioned	O
layers	O
,	O
in	O
an	O
art	O
network	O
also	O
exist	O
a	O
few	O
neu-	O
rons	O
that	O
exercise	O
control	O
functions	O
such	O
as	O
signal	O
enhancement	O
.	O
but	O
we	O
do	O
not	O
want	O
to	O
discuss	O
this	O
theory	O
further	O
since	O
here	O
only	O
the	O
basic	O
principle	O
of	O
the	O
art	O
net-	O
work	O
should	O
become	O
explicit	O
.	O
i	O
have	O
only	O
mentioned	O
it	O
to	O
explain	O
that	O
in	O
spite	O
of	O
the	O
recurrences	O
,	O
the	O
art	O
network	O
will	O
achieve	O
a	O
stable	O
state	B
after	O
an	O
input	O
.	O
166	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
	O
#	O
'	O
)	O
{	O
	O
	O
	O
	O
#	O
'	O
w	O
{	O
	O
	O
	O
	O
#	O
u	O
w	O
{	O
	O
	O
	O
	O
e	O
;	O
7	O
5	O
	O
	O
o	O
o	O
e	O
;	O
7	O
	O
	O
y	O
o	O
o	O
e	O
;	O
	O
	O
c	O
y	O
o	O
o	O
e	O
	O
	O
g	O
c	O
y	O
o	O
o	O
	O
	O
i	O
g	O
c	O
y	O
	O
	O
dkriesel.com	O
11.3	O
extensions	O
11.2	O
the	O
learning	B
process	O
of	O
an	O
art	O
network	O
is	O
divided	O
to	O
top-down	B
and	O
bottom-up	B
learning	O
the	O
trick	O
of	O
adaptive	B
resonance	I
theory	I
is	O
not	O
only	O
the	O
conﬁguration	O
of	O
the	O
art	O
net-	O
work	O
but	O
also	O
the	O
two-piece	O
learning	B
pro-	O
cedure	O
of	O
the	O
theory	O
:	O
on	O
the	O
one	O
hand	O
we	O
train	O
the	O
top-down	B
matrix	O
w	O
,	O
on	O
the	O
other	O
hand	O
we	O
train	O
the	O
bottom-up	B
matrix	O
v	O
(	O
ﬁg	O
.	O
11.2	O
on	O
the	O
next	O
page	O
)	O
.	O
11.2.1	O
pattern	B
input	O
and	O
top-down	B
learning	O
when	O
a	O
pattern	B
is	O
entered	O
into	O
the	O
net-	O
work	O
it	O
causes	O
-	O
as	O
already	O
mentioned	O
-	O
an	O
activation	B
at	O
the	O
output	O
neurons	O
and	O
the	O
strongest	O
neuron	O
wins	O
.	O
then	O
the	O
weights	O
of	O
the	O
matrix	O
w	O
going	O
towards	O
the	O
output	O
neuron	O
are	O
changed	O
such	O
that	O
the	O
output	O
of	O
the	O
strongest	O
neuron	O
ω	O
is	O
still	O
enhanced	O
,	O
i.e	O
.	O
the	O
class	O
aﬃliation	O
of	O
the	O
input	B
vector	I
to	O
the	O
class	O
of	O
the	O
output	O
neuron	O
ω	O
be-	O
comes	O
enhanced	O
.	O
11.2.2	O
resonance	B
and	O
bottom-up	B
learning	O
the	O
training	O
of	O
the	O
backward	O
weights	O
of	O
the	O
matrix	O
v	O
is	O
a	O
bit	O
tricky	O
:	O
only	O
the	O
weights	O
of	O
the	O
respective	O
winner	O
neuron	O
are	O
trained	O
towards	O
the	O
input	B
layer	I
and	O
our	O
current	O
input	O
pattern	O
is	O
used	O
as	O
teach-	O
ing	O
input	O
.	O
thus	O
,	O
the	O
network	O
is	O
trained	O
to	O
enhance	O
input	O
vectors	O
.	O
11.2.3	O
adding	O
an	O
output	O
neuron	O
of	O
course	O
,	O
it	O
could	O
happen	O
that	O
the	O
neu-	O
rons	O
are	O
nearly	O
equally	O
activated	O
or	O
that	O
several	O
neurons	O
are	O
activated	O
,	O
i.e	O
.	O
that	O
the	O
network	O
is	O
indecisive	O
.	O
in	O
this	O
case	O
,	O
the	O
mechanisms	O
of	O
the	O
control	O
neurons	O
acti-	O
vate	O
a	O
signal	O
that	O
adds	O
a	O
new	O
output	O
neu-	O
ron	O
.	O
then	O
the	O
current	O
pattern	B
is	O
assigned	O
to	O
this	O
output	O
neuron	O
and	O
the	O
weight	B
sets	O
of	O
the	O
new	O
neuron	O
are	O
trained	O
as	O
usual	O
.	O
thus	O
,	O
the	O
advantage	O
of	O
this	O
system	O
is	O
not	O
only	O
to	O
divide	O
inputs	O
into	O
classes	O
and	O
to	O
ﬁnd	O
new	O
classes	O
,	O
it	O
can	O
also	O
tell	O
us	O
after	O
the	O
activation	B
of	O
an	O
output	O
neuron	O
what	O
a	O
typical	O
representative	O
of	O
a	O
class	O
looks	O
like	O
-	O
which	O
is	O
a	O
signiﬁcant	O
feature	O
.	O
often	O
,	O
however	O
,	O
the	O
system	O
can	O
only	O
mod-	O
erately	O
distinguish	O
the	O
patterns	O
.	O
the	O
ques-	O
tion	O
is	O
when	O
a	O
new	O
neuron	O
is	O
permitted	O
to	O
become	O
active	O
and	O
when	O
it	O
should	O
learn	O
.	O
in	O
an	O
art	O
network	O
there	O
are	O
diﬀerent	O
ad-	O
ditional	O
control	O
neurons	O
which	O
answer	O
this	O
question	O
according	O
to	O
diﬀerent	O
mathemat-	O
ical	O
rules	O
and	O
which	O
are	O
responsible	O
for	O
in-	O
tercepting	O
special	O
cases	O
.	O
at	O
the	O
same	O
time	O
,	O
one	O
of	O
the	O
largest	O
ob-	O
jections	O
to	O
an	O
art	O
is	O
the	O
fact	O
that	O
an	O
art	O
network	O
uses	O
a	O
special	O
distinction	O
of	O
cases	O
,	O
similar	O
to	O
an	O
if	O
query	O
,	O
that	O
has	O
been	O
forced	O
into	O
the	O
mechanism	O
of	O
a	O
neural	O
net-	O
work	O
.	O
11.3	O
extensions	O
as	O
already	O
mentioned	O
above	O
,	O
the	O
art	O
net-	O
works	O
have	O
often	O
been	O
extended	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
167	O
winner	O
neuron	O
is	O
ampliﬁed	O
input	O
is	O
teach	O
.	O
inp	O
.	O
for	O
backward	O
weights	O
chapter	O
11	O
adaptive	B
resonance	I
theory	I
dkriesel.com	O
art-2	O
[	O
cg87	O
]	O
is	O
extended	O
to	O
continuous	B
inputs	O
and	O
additionally	O
oﬀers	O
(	O
in	O
an	O
ex-	O
tension	O
called	O
art-2a	O
)	O
enhancements	O
of	O
the	O
learning	B
speed	O
which	O
results	O
in	O
addi-	O
tional	O
control	O
neurons	O
and	O
layers	O
.	O
art-3	O
[	O
cg90	O
]	O
3	O
improves	O
the	O
learning	B
ability	O
of	O
art-2	O
by	O
adapting	O
additional	O
biological	O
processes	O
such	O
as	O
the	O
chemical	O
processes	O
within	O
the	O
synapses1	O
.	O
apart	O
from	O
the	O
described	O
ones	O
there	O
exist	O
many	O
other	O
extensions	O
.	O
figure	O
11.2	O
:	O
simpliﬁed	O
illustration	O
of	O
the	O
two-	O
piece	O
training	O
of	O
an	O
art	O
network	O
:	O
the	O
trained	O
weights	O
are	O
represented	O
by	O
solid	O
lines	O
.	O
let	O
us	O
as-	O
sume	O
that	O
a	O
pattern	B
has	O
been	O
entered	O
into	O
the	O
network	O
and	O
that	O
the	O
numbers	O
mark	O
the	O
outputs	O
.	O
top	O
:	O
we	O
can	O
see	O
that	O
ω2	O
is	O
the	O
winner	O
neu-	O
ron	O
.	O
middle	O
:	O
so	O
the	O
weights	O
are	O
trained	O
towards	O
the	O
winner	O
neuron	O
and	O
(	O
below	O
)	O
the	O
weights	O
of	O
the	O
winner	O
neuron	O
are	O
trained	O
towards	O
the	O
input	B
layer	I
.	O
1	O
because	O
of	O
the	O
frequent	O
extensions	O
of	O
the	O
adap-	O
tive	O
resonance	B
theory	O
wagging	O
tongues	O
already	O
call	O
them	O
``	O
art-n	O
networks	O
''	O
.	O
168	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
kapitel11adaptiveresonancetheorydkriesel.comgfed	O
@	O
abci1	O
''	O
''	O
gfed	O
@	O
abci2gfed	O
@	O
abci3gfed	O
@	O
abci4||gfed	O
@	O
abcω1yyooee	O
<	O
<	O
gfed	O
@	O
abcω2bbyyooee01gfed	O
@	O
abci1	O
''	O
''	O
ffffffffffffffffffffgfed	O
@	O
abci244444444444444gfed	O
@	O
abci3gfed	O
@	O
abci4||	O
gfed	O
@	O
abcω1yyooee	O
<	O
<	O
gfed	O
@	O
abcω2bbyyooee01gfed	O
@	O
abci1	O
''	O
''	O
gfed	O
@	O
abci2gfed	O
@	O
abci3gfed	O
@	O
abci4||gfed	O
@	O
abcω1yyooee	O
<	O
<	O
gfed	O
@	O
abcω2bbffffffffffffffffffffyy44444444444444ooee	O
01abbildung11.2	O
:	O
vereinfachtedarstellungdeszweigeteiltentrainingseinesart-netzes	O
:	O
diejeweilstrainiertengewichtesinddurchgezogendargestellt.nehmenwiran	O
,	O
einmusterwurdeindasnetzeingegebenunddiezahlenmarkierenausgaben.oben	O
:	O
wirwirsehen	O
,	O
istω2dasge-winnerneuron.mitte	O
:	O
alsowerdendiegewichtezumgewinnerneuronhintrainiertund	O
(	O
unten	O
)	O
diegewichtevomgewinnerneuronzureingangs-schichttrainiert.einerif-abfrage	O
,	O
diemanindenmecha-nismuseinesneuronalennetzesgepressthat.11.3erweiterungenwieschoneingangserw¨ahnt	O
,	O
wurdendieart-netzevielfacherweitert.art-2	O
[	O
cg87	O
]	O
isteineerweiterungaufkontinuierlicheeingabenundbietetzus¨atzlich	O
(	O
ineinerart-2agenanntenerweiterung	O
)	O
verbesserungenderlernge-schwindigkeit	O
,	O
waszus¨atzlichekontroll-neuroneundschichtenzurfolgehat.art-3	O
[	O
cg90	O
]	O
verbessertdielernf¨ahig-keitvonart-2	O
,	O
indemzus¨atzlichebiolo-gischevorg¨angewiez.b.diechemischenvorg¨angeinnerhalbdersynapsenadap-tiertwerden1.zus¨atzlichzudenbeschriebenenerweite-rungenexistierennochvielemehr.1durchdieh¨auﬁgenerweiterungenderadaptiveresonancetheorysprechenb¨osezungenbereitsvon	O
”	O
art-n-netzen	O
“	O
.168d.kriesel–einkleiner¨uberblick¨uberneuronalenetze	O
(	O
epsilon-de	O
)	O
part	O
iv	O
excursi	O
,	O
appendices	O
and	O
registers	O
169	O
appendix	O
a	O
excursus	O
:	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	O
learnable	O
ﬁelds	O
in	O
grimm	O
’	O
s	O
dictionary	O
the	O
extinct	O
german	O
word	O
``	O
kluster	O
''	O
is	O
described	O
by	O
``	O
was	O
dicht	O
und	O
dick	O
zusammensitzet	O
(	O
a	O
thick	O
and	O
dense	O
group	O
of	O
sth.	O
)	O
''	O
.	O
in	O
static	O
cluster	B
analysis	I
,	O
the	O
formation	O
of	O
groups	O
within	O
point	O
clouds	O
is	O
explored	O
.	O
introduction	O
of	O
some	O
procedures	O
,	O
comparison	O
of	O
their	O
advantages	O
and	O
disadvantages	O
.	O
discussion	O
of	O
an	O
adaptive	O
clustering	O
method	O
based	O
on	O
neural	O
networks	O
.	O
a	O
regional	O
and	O
online	O
learnable	O
ﬁeld	O
models	O
from	O
a	O
point	O
cloud	O
,	O
possibly	O
with	O
a	O
lot	O
of	O
points	O
,	O
a	O
comparatively	O
small	O
set	O
of	O
neurons	O
being	O
representative	O
for	O
the	O
point	O
cloud	O
.	O
as	O
already	O
mentioned	O
,	O
many	O
problems	O
can	O
be	O
traced	O
back	O
to	O
problems	O
in	O
cluster	B
analysis	I
.	O
therefore	O
,	O
it	O
is	O
necessary	O
to	O
re-	O
search	O
procedures	O
that	O
examine	O
whether	O
groups	O
(	O
so-called	O
clusters	B
)	O
exist	O
within	O
point	O
clouds	O
.	O
since	O
cluster	B
analysis	I
procedures	O
need	O
a	O
notion	O
of	O
distance	O
between	O
two	O
points	O
,	O
a	O
metric	B
must	O
be	O
deﬁned	O
on	O
the	O
space	O
where	O
these	O
points	O
are	O
situated	O
.	O
we	O
brieﬂy	O
want	O
to	O
specify	O
what	O
a	O
metric	B
is	O
.	O
deﬁnition	O
a.1	O
(	O
metric	B
)	O
.	O
a	O
relation	O
dist	O
(	O
x1	O
,	O
x2	O
)	O
deﬁned	O
for	O
two	O
objects	O
x1	O
,	O
x2	O
is	O
referred	O
to	O
as	O
metric	B
if	O
each	O
of	O
the	O
fol-	O
lowing	O
criteria	O
applies	O
:	O
1.	O
dist	O
(	O
x1	O
,	O
x2	O
)	O
=	O
0	O
if	O
and	O
only	O
if	O
x1	O
=	O
x2	O
,	O
2.	O
dist	O
(	O
x1	O
,	O
x2	O
)	O
=	O
dist	O
(	O
x2	O
,	O
x1	O
)	O
,	O
i.e	O
.	O
metry	O
,	O
sym-	O
≤	O
3.	O
dist	O
(	O
x1	O
,	O
x3	O
)	O
dist	O
(	O
x2	O
,	O
x3	O
)	O
,	O
i.e	O
.	O
inequality	O
holds	O
.	O
dist	O
(	O
x1	O
,	O
x2	O
)	O
+	O
the	O
triangle	O
colloquially	O
speaking	O
,	O
a	O
metric	B
is	O
a	O
tool	O
for	O
determining	O
distances	O
between	O
points	O
in	O
any	O
space	O
.	O
here	O
,	O
the	O
distances	O
have	O
to	O
be	O
symmetrical	O
,	O
and	O
the	O
distance	O
be-	O
tween	O
to	O
points	O
may	O
only	O
be	O
0	O
if	O
the	O
two	O
points	O
are	O
equal	O
.	O
additionally	O
,	O
the	O
trian-	O
gle	O
inequality	O
must	O
apply	O
.	O
metrics	O
are	O
provided	O
by	O
,	O
for	O
example	O
,	O
the	O
squared	B
distance	I
and	O
the	O
euclidean	O
distance	O
,	O
which	O
have	O
already	O
been	O
intro-	O
duced	O
.	O
based	O
on	O
such	O
metrics	O
we	O
can	O
de-	O
171	O
number	O
of	O
cluster	O
must	O
be	O
known	O
previously	O
appendix	O
a	O
excursus	O
:	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	O
learnable	O
ﬁeldsdkriesel.com	O
ﬁne	O
a	O
clustering	O
procedure	O
that	O
uses	O
a	O
met-	O
ric	O
as	O
distance	O
measure	O
.	O
7.	O
continue	O
with	O
4	O
until	O
the	O
assignments	O
are	O
no	O
longer	O
changed	O
.	O
now	O
we	O
want	O
to	O
introduce	O
and	O
brieﬂy	O
dis-	O
cuss	O
diﬀerent	O
clustering	O
procedures	O
.	O
a.1	O
k-means	B
clustering	I
allocates	O
data	O
to	O
a	O
predeﬁned	O
number	O
of	O
clusters	B
k-means	O
clustering	O
according	O
to	O
j.	O
macqueen	O
[	O
mac67	O
]	O
is	O
an	O
algorithm	B
that	O
is	O
often	O
used	O
because	O
of	O
its	O
low	O
computa-	O
tion	O
and	O
storage	O
complexity	O
and	O
which	O
is	O
regarded	O
as	O
``	O
inexpensive	O
and	O
good	O
''	O
.	O
the	O
operation	O
sequence	O
of	O
the	O
k-means	O
cluster-	O
ing	O
algorithm	B
is	O
the	O
following	O
:	O
1.	O
provide	O
data	O
to	O
be	O
examined	O
.	O
2.	O
deﬁne	O
k	O
,	O
which	O
is	O
the	O
number	O
of	O
clus-	O
ter	O
centers	O
.	O
3.	O
select	O
k	O
random	O
vectors	O
for	O
the	O
clus-	O
ter	O
centers	O
(	O
also	O
referred	O
to	O
as	O
code-	O
book	O
vectors	O
)	O
.	O
4.	O
assign	O
each	O
data	O
point	O
to	O
the	O
next	O
codebook	O
vector1	O
5.	O
compute	O
cluster	O
centers	O
for	O
all	O
clus-	O
ters	O
.	O
6.	O
set	O
codebook	O
vectors	O
to	O
new	O
cluster	O
centers	O
.	O
1	O
the	O
name	O
codebook	B
vector	I
was	O
created	O
because	O
the	O
often	O
used	O
name	O
cluster	O
vector	O
was	O
too	O
un-	O
clear	O
.	O
step	O
2	O
already	O
shows	O
one	O
of	O
the	O
great	O
ques-	O
tions	O
of	O
the	O
k-means	O
algorithm	O
:	O
the	O
num-	O
ber	O
k	O
of	O
the	O
cluster	O
centers	O
has	O
to	O
be	O
de-	O
termined	O
in	O
advance	O
.	O
this	O
can	O
not	O
be	O
done	O
by	O
the	O
algorithm	B
.	O
the	O
problem	O
is	O
that	O
it	O
is	O
not	O
necessarily	O
known	O
in	O
advance	O
how	O
k	O
can	O
be	O
determined	O
best	O
.	O
another	O
problem	O
is	O
that	O
the	O
procedure	O
can	O
become	O
quite	O
in-	O
stable	O
if	O
the	O
codebook	O
vectors	O
are	O
badly	O
initialized	O
.	O
but	O
since	O
this	O
is	O
random	O
,	O
it	O
is	O
often	O
useful	O
to	O
restart	O
the	O
procedure	O
.	O
this	O
has	O
the	O
advantage	O
of	O
not	O
requiring	O
much	O
computational	O
eﬀort	O
.	O
if	O
you	O
are	O
fully	O
aware	O
of	O
those	O
weaknesses	O
,	O
you	O
will	O
receive	O
quite	O
good	O
results	O
.	O
however	O
,	O
complex	O
structures	O
such	O
as	O
``	O
clus-	O
ters	O
in	O
clusters	B
''	O
can	O
not	O
be	O
recognized	O
.	O
if	O
k	O
is	O
high	O
,	O
the	O
outer	O
ring	O
of	O
the	O
construction	O
in	O
the	O
following	O
illustration	O
will	O
be	O
recog-	O
nized	O
as	O
many	O
single	O
clusters	O
.	O
if	O
k	O
is	O
low	O
,	O
the	O
ring	O
with	O
the	O
small	O
inner	O
clusters	B
will	O
be	O
recognized	O
as	O
one	O
cluster	O
.	O
for	O
an	O
illustration	O
see	O
the	O
upper	O
right	O
part	O
of	O
ﬁg	O
.	O
a.1	O
on	O
page	O
174.	O
a.2	O
k-nearest	B
neighboring	I
looks	O
for	O
the	O
k	O
nearest	O
neighbors	O
of	O
each	O
data	O
point	O
the	O
k-nearest	B
neighboring	I
procedure	O
[	O
ch67	O
]	O
connects	O
each	O
data	O
point	O
to	O
the	O
k	O
closest	O
neighbors	O
,	O
which	O
often	O
results	O
in	O
a	O
division	O
of	O
the	O
groups	O
.	O
then	O
such	O
a	O
group	O
172	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
clustering	O
radii	O
around	O
points	O
dkriesel.com	O
a.4	O
the	O
silhouette	O
coeﬃcient	O
builds	O
a	O
cluster	O
.	O
the	O
advantage	O
is	O
that	O
the	O
number	O
of	O
clusters	B
occurs	O
all	O
by	O
it-	O
self	O
.	O
the	O
disadvantage	O
is	O
that	O
a	O
large	O
stor-	O
age	O
and	O
computational	O
eﬀort	O
is	O
required	O
to	O
ﬁnd	O
the	O
next	O
neighbor	O
(	O
the	O
distances	O
be-	O
tween	O
all	O
data	O
points	O
must	O
be	O
computed	O
and	O
stored	O
)	O
.	O
clustering	O
next	O
points	O
there	O
are	O
some	O
special	O
cases	O
in	O
which	O
the	O
procedure	O
combines	O
data	O
points	O
belonging	O
to	O
diﬀerent	O
clusters	B
,	O
if	O
k	O
is	O
too	O
high	O
.	O
(	O
see	O
the	O
two	O
small	O
clusters	B
in	O
the	O
upper	O
right	O
of	O
the	O
illustration	O
)	O
.	O
clusters	B
consisting	O
of	O
only	O
one	O
single	O
data	O
point	O
are	O
basically	O
conncted	O
to	O
another	O
cluster	O
,	O
which	O
is	O
not	O
always	O
intentional	O
.	O
furthermore	O
,	O
it	O
is	O
not	O
mandatory	O
that	O
the	O
links	O
between	O
the	O
points	O
are	O
symmetric	O
.	O
but	O
this	O
procedure	O
allows	O
a	O
recognition	O
of	O
rings	O
and	O
therefore	O
of	O
``	O
clusters	B
in	O
clusters	B
''	O
,	O
which	O
is	O
a	O
clear	O
advantage	O
.	O
another	O
ad-	O
vantage	O
is	O
that	O
the	O
procedure	O
adaptively	O
responds	O
to	O
the	O
distances	O
in	O
and	O
between	O
the	O
clusters	B
.	O
for	O
an	O
illustration	O
see	O
the	O
lower	O
left	O
part	O
of	O
ﬁg	O
.	O
a.1	O
.	O
which	O
is	O
the	O
reason	O
for	O
the	O
name	O
epsilon-	O
nearest	O
neighboring	O
.	O
points	O
are	O
neig-	O
bors	O
if	O
they	O
are	O
at	O
most	O
ε	O
apart	O
from	O
each	O
other	O
.	O
here	O
,	O
the	O
storage	O
and	O
computa-	O
tional	O
eﬀort	O
is	O
obviously	O
very	O
high	O
,	O
which	O
is	O
a	O
disadvantage	O
.	O
but	O
note	O
that	O
there	O
are	O
some	O
special	O
cases	O
:	O
two	O
separate	O
clusters	B
can	O
easily	O
be	O
con-	O
nected	O
due	O
to	O
the	O
unfavorable	O
situation	B
of	O
a	O
single	O
data	O
point	O
.	O
this	O
can	O
also	O
happen	O
with	O
k-nearest	B
neighboring	I
,	O
but	O
it	O
would	O
be	O
more	O
diﬃcult	O
since	O
in	O
this	O
case	O
the	O
num-	O
ber	O
of	O
neighbors	O
per	O
point	O
is	O
limited	O
.	O
an	O
advantage	O
is	O
the	O
symmetric	O
nature	O
of	O
the	O
neighborhood	O
relationships	O
.	O
another	O
advantage	O
is	O
that	O
the	O
combination	O
of	O
min-	O
imal	O
clusters	B
due	O
to	O
a	O
ﬁxed	O
number	O
of	O
neighbors	O
is	O
avoided	O
.	O
on	O
the	O
other	O
hand	O
,	O
it	O
is	O
necessary	O
to	O
skill-	O
fully	O
initialize	O
ε	O
in	O
order	O
to	O
be	O
successful	O
,	O
i.e	O
.	O
smaller	O
than	O
half	O
the	O
smallest	O
distance	O
between	O
two	O
clusters	B
.	O
with	O
variable	O
clus-	O
ter	O
and	O
point	O
distances	O
within	O
clusters	B
this	O
can	O
possibly	O
be	O
a	O
problem	O
.	O
for	O
an	O
illustration	O
see	O
the	O
lower	O
right	O
part	O
of	O
ﬁg	O
.	O
a.1	O
.	O
a.3	O
ε-nearest	O
neighboring	O
looks	O
for	O
neighbors	O
within	O
the	O
radius	O
ε	O
for	O
each	O
data	O
point	O
a.4	O
the	O
silhouette	O
coeﬃcient	O
determines	O
how	O
accurate	O
a	O
given	O
clustering	O
is	O
another	O
approach	O
of	O
neighboring	O
:	O
here	O
,	O
the	O
neighborhood	O
detection	O
does	O
not	O
use	O
a	O
ﬁxed	O
number	O
k	O
of	O
neighbors	O
but	O
a	O
radius	O
ε	O
,	O
as	O
we	O
can	O
see	O
above	O
,	O
there	O
is	O
no	O
easy	O
an-	O
swer	O
for	O
clustering	O
problems	O
.	O
each	O
proce-	O
dure	O
described	O
has	O
very	O
speciﬁc	O
disadvan-	O
tages	O
.	O
in	O
this	O
respect	O
it	O
is	O
useful	O
to	O
have	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
173	O
appendix	O
a	O
excursus	O
:	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	O
learnable	O
ﬁeldsdkriesel.com	O
figure	O
a.1	O
:	O
top	O
left	O
:	O
our	O
set	O
of	O
points	O
.	O
we	O
will	O
use	O
this	O
set	O
to	O
explore	O
the	O
diﬀerent	O
clustering	O
methods	O
.	O
top	O
right	O
:	O
k-means	B
clustering	I
.	O
using	O
this	O
procedure	O
we	O
chose	O
k	O
=	O
6.	O
as	O
we	O
can	O
see	O
,	O
the	O
procedure	O
is	O
not	O
capable	O
to	O
recognize	O
``	O
clusters	B
in	O
clusters	B
''	O
(	O
bottom	O
left	O
of	O
the	O
illustration	O
)	O
.	O
long	O
``	O
lines	O
''	O
of	O
points	O
are	O
a	O
problem	O
,	O
too	O
:	O
they	O
would	O
be	O
recognized	O
as	O
many	O
small	O
clusters	B
(	O
if	O
k	O
is	O
suﬃciently	O
large	O
)	O
.	O
bottom	O
left	O
:	O
k-nearest	B
neighboring	I
.	O
if	O
k	O
is	O
selected	O
too	O
high	O
(	O
higher	O
than	O
the	O
number	O
of	O
points	O
in	O
the	O
smallest	O
cluster	O
)	O
,	O
this	O
will	O
result	O
in	O
cluster	O
combinations	O
shown	O
in	O
the	O
upper	O
right	O
of	O
the	O
illustration	O
.	O
bottom	O
right	O
:	O
ε-nearest	O
neighboring	O
.	O
this	O
procedure	O
will	O
cause	O
diﬃculties	O
if	O
ε	O
is	O
selected	O
larger	O
than	O
the	O
minimum	O
distance	O
between	O
two	O
clusters	B
(	O
see	O
upper	O
left	O
of	O
the	O
illustration	O
)	O
,	O
which	O
will	O
then	O
be	O
combined	O
.	O
174	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
a.5	O
regional	O
and	O
online	O
learnable	O
ﬁelds	O
a	O
criterion	O
to	O
decide	O
how	O
good	O
our	O
clus-	O
ter	O
division	O
is	O
.	O
this	O
possibility	O
is	O
oﬀered	O
by	O
the	O
silhouette	O
coeﬃcient	O
according	O
to	O
[	O
kau90	O
]	O
.	O
this	O
coeﬃcient	O
measures	O
how	O
well	O
the	O
clusters	B
are	O
delimited	O
from	O
each	O
other	O
and	O
indicates	O
if	O
points	O
may	O
be	O
as-	O
signed	O
to	O
the	O
wrong	O
clusters	B
.	O
apparently	O
,	O
the	O
whole	O
term	O
s	O
(	O
p	O
)	O
can	O
only	O
be	O
within	O
the	O
interval	O
[	O
−1	O
;	O
1	O
]	O
.	O
a	O
value	O
close	O
to	O
-1	O
indicates	O
a	O
bad	O
classiﬁcation	O
of	O
p.	O
the	O
silhouette	O
coeﬃcient	O
s	O
(	O
p	O
)	O
results	O
from	O
the	O
average	O
of	O
all	O
values	O
s	O
(	O
p	O
)	O
:	O
s	O
(	O
p	O
)	O
=	O
1	O
|p|	O
x	O
p∈p	O
s	O
(	O
p	O
)	O
.	O
(	O
a.4	O
)	O
as	O
above	O
the	O
total	O
quality	O
of	O
the	O
clus-	O
ter	O
division	O
is	O
expressed	O
by	O
the	O
interval	O
[	O
−1	O
;	O
1	O
]	O
.	O
as	O
diﬀerent	O
clustering	O
strategies	O
with	O
dif-	O
ferent	O
characteristics	O
have	O
been	O
presented	O
now	O
(	O
lots	O
of	O
further	O
material	O
is	O
presented	O
in	O
[	O
dhs01	O
]	O
)	O
,	O
as	O
well	O
as	O
a	O
measure	O
to	O
in-	O
dicate	O
the	O
quality	O
of	O
an	O
existing	O
arrange-	O
ment	O
of	O
given	O
data	O
into	O
clusters	B
,	O
i	O
want	O
to	O
introduce	O
a	O
clustering	O
method	O
based	O
on	O
an	O
unsupervised	B
learning	I
neural	O
net-	O
work	O
[	O
sge05	O
]	O
which	O
was	O
published	O
in	O
2005.	O
like	O
all	O
the	O
other	O
methods	O
this	O
one	O
may	O
not	O
be	O
perfect	O
but	O
it	O
eliminates	O
large	O
stan-	O
dard	O
weaknesses	O
of	O
the	O
known	O
clustering	O
methods	O
a.5	O
regional	O
and	O
online	O
learnable	O
ﬁelds	O
are	O
a	O
neural	O
clustering	O
strategy	O
the	O
paradigm	O
of	O
neural	O
networks	O
,	O
which	O
i	O
want	O
to	O
introduce	O
now	O
,	O
are	O
the	O
regional	O
and	O
online	O
learnable	O
ﬁelds	O
,	O
shortly	O
re-	O
ferred	O
to	O
as	O
rolfs	O
.	O
clustering	O
quality	O
is	O
measureable	O
let	O
p	O
be	O
a	O
point	O
cloud	O
and	O
p	O
a	O
point	O
in	O
p.	O
let	O
c	O
⊆	O
p	O
be	O
a	O
cluster	O
within	O
the	O
point	O
cloud	O
and	O
p	O
be	O
part	O
of	O
this	O
cluster	O
,	O
i.e	O
.	O
p	O
∈	O
c.	O
the	O
set	O
of	O
clusters	O
is	O
called	O
c.	O
summary	O
:	O
p	O
∈	O
c	O
⊆	O
p	O
applies	O
.	O
to	O
calculate	O
the	O
silhouette	O
coeﬃcient	O
,	O
we	O
initially	O
need	O
the	O
average	O
distance	O
between	O
point	O
p	O
and	O
all	O
its	O
cluster	O
neighbors	O
.	O
this	O
variable	O
is	O
referred	O
to	O
as	O
a	O
(	O
p	O
)	O
and	O
deﬁned	O
as	O
follows	O
:	O
a	O
(	O
p	O
)	O
=	O
1	O
|c|	O
−	O
1	O
x	O
q∈c	O
,	O
q6=p	O
dist	O
(	O
p	O
,	O
q	O
)	O
(	O
a.1	O
)	O
furthermore	O
,	O
let	O
b	O
(	O
p	O
)	O
be	O
the	O
average	O
dis-	O
tance	O
between	O
our	O
point	O
p	O
and	O
all	O
points	O
of	O
the	O
next	O
cluster	O
(	O
g	O
represents	O
all	O
clusters	B
except	O
for	O
c	O
)	O
:	O
b	O
(	O
p	O
)	O
=	O
min	O
g∈c	O
,	O
g6=c	O
1	O
|g|	O
dist	O
(	O
p	O
,	O
q	O
)	O
(	O
a.2	O
)	O
x	O
q∈g	O
the	O
point	O
p	O
is	O
classiﬁed	O
well	O
if	O
the	O
distance	O
to	O
the	O
center	O
of	O
the	O
own	O
cluster	O
is	O
minimal	O
and	O
the	O
distance	O
to	O
the	O
centers	O
of	O
the	O
other	O
clusters	B
is	O
maximal	O
.	O
in	O
this	O
case	O
,	O
the	O
fol-	O
lowing	O
term	O
provides	O
a	O
value	O
close	O
to	O
1	O
:	O
s	O
(	O
p	O
)	O
=	O
b	O
(	O
p	O
)	O
−	O
a	O
(	O
p	O
)	O
max	O
{	O
a	O
(	O
p	O
)	O
,	O
b	O
(	O
p	O
)	O
}	O
(	O
a.3	O
)	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
175	O
appendix	O
a	O
excursus	O
:	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	O
learnable	O
ﬁeldsdkriesel.com	O
k	O
(	O
cid:73	O
)	O
network	O
covers	O
point	O
cloud	O
a.5.1	O
rolfs	O
try	O
to	O
cover	O
data	O
with	O
neurons	O
roughly	O
speaking	O
,	O
the	O
regional	O
and	O
online	O
learnable	O
ﬁelds	O
are	O
a	O
set	O
k	O
of	O
neurons	O
which	O
try	O
to	O
cover	O
a	O
set	O
of	O
points	O
as	O
well	O
as	O
possible	O
by	O
means	O
of	O
their	O
distribution	O
in	O
the	O
input	O
space	O
.	O
for	O
this	O
,	O
neurons	O
are	O
added	O
,	O
moved	O
or	O
changed	O
in	O
their	O
size	O
dur-	O
ing	O
training	O
if	O
necessary	O
.	O
the	O
parameters	O
of	O
the	O
individual	O
neurons	O
will	O
be	O
discussed	O
later	O
.	O
deﬁnition	O
a.2	O
(	O
regional	O
and	O
online	O
learnable	O
ﬁeld	O
)	O
.	O
a	O
regional	O
and	O
on-	O
line	O
learnable	O
ﬁeld	O
(	O
abbreviated	O
rolf	O
or	O
rolf	O
network	O
)	O
is	O
a	O
set	O
k	O
of	O
neurons	O
that	O
are	O
trained	O
to	O
cover	O
a	O
certain	O
set	O
in	O
the	O
input	O
space	O
as	O
well	O
as	O
possible	O
.	O
figure	O
a.2	O
:	O
structure	O
of	O
a	O
rolf	O
neuron	O
.	O
a.5.1.1	O
rolf	O
neurons	O
feature	O
a	O
position	O
and	O
a	O
radius	O
in	O
the	O
input	O
space	O
c	O
(	O
cid:73	O
)	O
σ	O
(	O
cid:73	O
)	O
here	O
,	O
a	O
rolf	O
neuron	O
k	O
∈	O
k	O
has	O
two	O
parameters	O
:	O
similar	O
to	O
the	O
rbf	O
networks	O
,	O
it	O
has	O
a	O
center	O
ck	O
,	O
i.e	O
.	O
a	O
position	O
in	O
the	O
input	O
space	O
.	O
but	O
it	O
has	O
yet	O
another	O
parameter	O
:	O
the	O
ra-	O
dius	O
σ	O
,	O
which	O
deﬁnes	O
the	O
radius	O
of	O
the	O
per-	O
ceptive	O
surface	O
surrounding	O
the	O
neuron2	O
.	O
a	O
neuron	O
covers	O
the	O
part	O
of	O
the	O
input	O
space	O
that	O
is	O
situated	O
within	O
this	O
radius	O
.	O
neuron	O
represents	O
surface	O
ck	O
and	O
σk	O
are	O
locally	O
deﬁned	O
for	O
each	O
neu-	O
2	O
i	O
write	O
``	O
deﬁnes	O
''	O
and	O
not	O
``	O
is	O
''	O
because	O
the	O
actual	O
radius	O
is	O
speciﬁed	O
by	O
σ	O
·	O
ρ.	O
ron	O
.	O
this	O
particularly	O
means	O
that	O
the	O
neu-	O
rons	O
are	O
capable	O
to	O
cover	O
surfaces	O
of	O
diﬀer-	O
ent	O
sizes	O
.	O
the	O
radius	O
of	O
the	O
perceptive	O
surface	O
is	O
speciﬁed	O
by	O
r	O
=	O
ρ	O
·	O
σ	O
(	O
ﬁg	O
.	O
a.2	O
)	O
with	O
the	O
multiplier	O
ρ	O
being	O
globally	O
deﬁned	O
and	O
previously	O
speciﬁed	O
for	O
all	O
neurons	O
.	O
intu-	O
itively	O
,	O
the	O
reader	O
will	O
wonder	O
what	O
this	O
multiplicator	O
is	O
used	O
for	O
.	O
its	O
signiﬁcance	O
will	O
be	O
discussed	O
later	O
.	O
furthermore	O
,	O
the	O
following	O
has	O
to	O
be	O
observed	O
:	O
it	O
is	O
not	O
nec-	O
essary	O
for	O
the	O
perceptive	O
surface	O
of	O
the	O
dif-	O
ferent	O
neurons	O
to	O
be	O
of	O
the	O
same	O
size	O
.	O
deﬁnition	O
a.3	O
(	O
rolf	O
neuron	O
)	O
.	O
the	O
pa-	O
rameters	O
of	O
a	O
rolf	O
neuron	O
k	O
are	O
a	O
center	O
ck	O
and	O
a	O
radius	O
σk	O
.	O
deﬁnition	O
a.4	O
(	O
perceptive	O
surface	O
)	O
.	O
the	O
perceptive	O
surface	O
of	O
a	O
rolf	O
neuron	O
176	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
a.5	O
regional	O
and	O
online	O
learnable	O
ﬁelds	O
k	O
consists	O
of	O
all	O
points	O
within	O
the	O
radius	O
ρ	O
·	O
σ	O
in	O
the	O
input	O
space	O
.	O
a.5.2	O
a	O
rolf	O
learns	O
unsupervised	O
by	O
presenting	O
training	O
samples	O
online	O
like	O
many	O
other	O
paradigms	O
of	O
neural	O
net-	O
works	O
our	O
rolf	O
network	O
learns	O
by	O
receiv-	O
ing	O
many	O
training	O
samples	O
p	O
of	O
a	O
training	B
set	I
p.	O
the	O
learning	B
is	O
unsupervised	O
.	O
for	O
each	O
training	O
sample	O
p	O
entered	O
into	O
the	O
net-	O
work	O
two	O
cases	O
can	O
occur	O
:	O
1.	O
there	O
is	O
one	O
accepting	B
neuron	I
k	O
for	O
p	O
or	O
2.	O
there	O
is	O
no	O
accepting	B
neuron	I
at	O
all	O
.	O
if	O
in	O
the	O
ﬁrst	O
case	O
several	O
neurons	O
are	O
suit-	O
able	O
,	O
then	O
there	O
will	O
be	O
exactly	O
one	O
ac-	O
cepting	O
neuron	O
insofar	O
as	O
the	O
closest	O
neu-	O
ron	O
is	O
the	O
accepting	O
one	O
.	O
for	O
the	O
accepting	B
neuron	I
k	O
ck	O
and	O
σk	O
are	O
adapted	O
.	O
deﬁnition	O
a.5	O
(	O
accepting	B
neuron	I
)	O
.	O
the	O
criterion	O
for	O
a	O
rolf	O
neuron	O
k	O
to	O
be	O
an	O
accepting	B
neuron	I
of	O
a	O
point	O
p	O
is	O
that	O
the	O
point	O
p	O
must	O
be	O
located	O
within	O
the	O
percep-	O
tive	O
surface	O
of	O
k.	O
if	O
p	O
is	O
located	O
in	O
the	O
per-	O
ceptive	O
surfaces	O
of	O
several	O
neurons	O
,	O
then	O
the	O
closest	O
neuron	O
will	O
be	O
the	O
accepting	O
one	O
.	O
if	O
there	O
are	O
several	O
closest	O
neurons	O
,	O
one	O
can	O
be	O
chosen	O
randomly	O
.	O
a.5.2.1	O
both	O
positions	O
and	O
radii	O
are	O
adapted	O
throughout	O
learning	B
adapting	O
existing	O
neurons	O
let	O
us	O
assume	O
that	O
we	O
entered	O
a	O
training	O
sample	O
p	O
into	O
the	O
network	O
and	O
that	O
there	O
is	O
an	O
accepting	B
neuron	I
k.	O
then	O
the	O
radius	O
moves	O
towards	O
||p	O
−	O
ck||	O
(	O
i.e	O
.	O
towards	O
the	O
distance	O
between	O
p	O
and	O
ck	O
)	O
and	O
the	O
center	O
ck	O
towards	O
p.	O
additionally	O
,	O
let	O
us	O
deﬁne	O
the	O
two	O
learning	B
rates	O
ησ	O
and	O
ηc	O
for	O
radii	O
(	O
cid:74	O
)	O
ησ	O
,	O
ηc	O
and	O
centers	O
.	O
ck	O
(	O
t	O
+	O
1	O
)	O
=	O
ck	O
(	O
t	O
)	O
+	O
ηc	O
(	O
p	O
−	O
ck	O
(	O
t	O
)	O
)	O
σk	O
(	O
t	O
+	O
1	O
)	O
=	O
σk	O
(	O
t	O
)	O
+	O
ησ	O
(	O
||p	O
−	O
ck	O
(	O
t	O
)	O
||	O
−	O
σk	O
(	O
t	O
)	O
)	O
note	O
that	O
here	O
σk	O
is	O
a	O
scalar	O
while	O
ck	O
is	O
a	O
vector	O
in	O
the	O
input	O
space	O
.	O
deﬁnition	O
a.6	O
(	O
adapting	O
a	O
rolf	O
neu-	O
ron	O
)	O
.	O
a	O
neuron	O
k	O
accepted	O
by	O
a	O
point	O
p	O
is	O
adapted	O
according	O
to	O
the	O
following	O
rules	O
:	O
ck	O
(	O
t	O
+	O
1	O
)	O
=	O
ck	O
(	O
t	O
)	O
+	O
ηc	O
(	O
p	O
−	O
ck	O
(	O
t	O
)	O
)	O
(	O
a.5	O
)	O
σk	O
(	O
t	O
+	O
1	O
)	O
=	O
σk	O
(	O
t	O
)	O
+	O
ησ	O
(	O
||p	O
−	O
ck	O
(	O
t	O
)	O
||	O
−	O
σk	O
(	O
t	O
)	O
)	O
(	O
a.6	O
)	O
a.5.2.2	O
the	O
radius	O
multiplier	O
allows	O
neurons	O
to	O
be	O
able	O
not	O
only	O
to	O
shrink	O
now	O
we	O
can	O
understand	O
the	O
function	B
of	O
the	O
multiplier	O
ρ	O
:	O
due	O
to	O
this	O
multiplier	O
the	O
per-	O
(	O
cid:74	O
)	O
ρ	O
ceptive	O
surface	O
of	O
a	O
neuron	O
includes	O
more	O
than	O
only	O
all	O
points	O
surrounding	O
the	O
neu-	O
ron	O
in	O
the	O
radius	O
σ.	O
this	O
means	O
that	O
due	O
to	O
the	O
aforementioned	O
learning	B
rule	O
σ	O
can-	O
not	O
only	O
decrease	O
but	O
also	O
increase	O
.	O
deﬁnition	O
a.7	O
(	O
radius	O
multiplier	O
)	O
.	O
the	O
radius	O
multiplier	O
ρ	O
>	O
1	O
is	O
globally	O
deﬁned	O
and	O
expands	O
the	O
perceptive	O
surface	O
of	O
a	O
neuron	O
k	O
to	O
a	O
multiple	O
of	O
σk	O
.	O
so	O
it	O
is	O
en-	O
sured	O
that	O
the	O
radius	O
σk	O
can	O
not	O
only	O
de-	O
crease	O
but	O
also	O
increase	O
.	O
so	O
the	O
neurons	O
can	O
grow	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
177	O
appendix	O
a	O
excursus	O
:	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	O
learnable	O
ﬁeldsdkriesel.com	O
generally	O
,	O
the	O
radius	O
multiplier	O
is	O
set	O
to	O
values	O
in	O
the	O
lower	O
one-digit	O
range	O
,	O
such	O
as	O
2	O
or	O
3.	O
so	O
far	O
we	O
only	O
have	O
discussed	O
the	O
case	O
in	O
the	O
rolf	O
training	O
that	O
there	O
is	O
an	O
accept-	O
ing	O
neuron	O
for	O
the	O
training	O
sample	O
p.	O
a.5.2.3	O
as	O
required	O
,	O
new	O
neurons	O
are	O
generated	O
this	O
suggests	O
to	O
discuss	O
the	O
approach	O
for	O
the	O
case	O
that	O
there	O
is	O
no	O
accepting	O
neu-	O
ron	O
.	O
in	O
this	O
case	O
a	O
new	O
accepting	B
neuron	I
k	O
is	O
generated	O
for	O
our	O
training	O
sample	O
.	O
the	O
re-	O
sult	O
is	O
of	O
course	O
that	O
ck	O
and	O
σk	O
have	O
to	O
be	O
initialized	O
.	O
the	O
initialization	O
of	O
ck	O
can	O
be	O
understood	O
intuitively	O
:	O
the	O
center	O
of	O
the	O
new	O
neuron	O
is	O
simply	O
set	O
on	O
the	O
training	O
sample	O
,	O
i.e	O
.	O
ck	O
=	O
p.	O
we	O
generate	O
a	O
new	O
neuron	O
because	O
there	O
is	O
no	O
neuron	O
close	O
to	O
p	O
–	O
for	O
logical	O
reasons	O
,	O
we	O
place	O
the	O
neuron	O
exactly	O
on	O
p.	O
but	O
how	O
to	O
set	O
a	O
σ	O
when	O
a	O
new	O
neuron	O
is	O
generated	O
?	O
for	O
this	O
purpose	O
there	O
exist	O
diﬀerent	O
options	O
:	O
init-σ	O
:	O
we	O
always	O
select	O
a	O
predeﬁned	O
static	O
σ.	O
minimum	O
σ	O
:	O
we	O
take	O
a	O
look	O
at	O
the	O
σ	O
of	O
each	O
neuron	O
and	O
select	O
the	O
minimum	O
.	O
maximum	O
σ	O
:	O
we	O
take	O
a	O
look	O
at	O
the	O
σ	O
of	O
each	O
neuron	O
and	O
select	O
the	O
maximum	O
.	O
mean	O
σ	O
:	O
we	O
select	O
the	O
mean	O
σ	O
of	O
all	O
neu-	O
rons	O
.	O
currently	O
,	O
the	O
mean-σ	O
variant	O
is	O
the	O
fa-	O
vorite	O
one	O
although	O
the	O
learning	B
procedure	O
also	O
works	O
with	O
the	O
other	O
ones	O
.	O
in	O
the	O
minimum-σ	O
variant	O
the	O
neurons	O
tend	O
to	O
cover	O
less	O
of	O
the	O
surface	O
,	O
in	O
the	O
maximum-	O
σ	O
variant	O
they	O
tend	O
to	O
cover	O
more	O
of	O
the	O
surface	O
.	O
deﬁnition	O
a.8	O
(	O
generating	O
a	O
rolf	O
neu-	O
ron	O
)	O
.	O
if	O
a	O
new	O
rolf	O
neuron	O
k	O
is	O
gener-	O
ated	O
by	O
entering	O
a	O
training	O
sample	O
p	O
,	O
then	O
ck	O
is	O
intialized	O
with	O
p	O
and	O
σk	O
according	O
to	O
one	O
of	O
the	O
aforementioned	O
strategies	O
(	O
init-	O
σ	O
,	O
minimum-σ	O
,	O
maximum-σ	O
,	O
mean-σ	O
)	O
.	O
the	O
training	O
is	O
complete	O
when	O
after	O
re-	O
peated	O
randomly	O
permuted	O
pattern	B
presen-	O
tation	O
no	O
new	O
neuron	O
has	O
been	O
generated	O
in	O
an	O
epoch	B
and	O
the	O
positions	O
of	O
the	O
neu-	O
rons	O
barely	O
change	O
.	O
a.5.3	O
evaluating	O
a	O
rolf	O
the	O
result	O
of	O
the	O
training	O
algorithm	O
is	O
that	O
the	O
training	B
set	I
is	O
gradually	O
covered	O
well	O
and	O
precisely	O
by	O
the	O
rolf	O
neurons	O
and	O
that	O
a	O
high	O
concentration	O
of	O
points	O
on	O
a	O
spot	O
of	O
the	O
input	O
space	O
does	O
not	O
automati-	O
cally	O
generate	O
more	O
neurons	O
.	O
thus	O
,	O
a	O
pos-	O
sibly	O
very	O
large	O
point	O
cloud	O
is	O
reduced	O
to	O
very	O
few	O
representatives	O
(	O
based	O
on	O
the	O
in-	O
put	O
set	O
)	O
.	O
then	O
it	O
is	O
very	O
easy	O
to	O
deﬁne	O
the	O
num-	O
ber	O
of	O
clusters	B
:	O
two	O
neurons	O
are	O
(	O
accord-	O
ing	O
to	O
the	O
deﬁnition	O
of	O
the	O
rolf	O
)	O
con-	O
nected	O
when	O
their	O
perceptive	O
surfaces	O
over-	O
initialization	O
of	O
a	O
neurons	O
cluster	O
=	O
connected	O
neurons	O
178	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
a.5	O
regional	O
and	O
online	O
learnable	O
ﬁelds	O
some	O
kind	O
of	O
nearest	O
neighbor-	O
lap	O
(	O
i.e	O
.	O
ing	O
is	O
executed	O
with	O
the	O
variable	O
percep-	O
tive	O
surfaces	O
)	O
.	O
a	O
cluster	O
is	O
a	O
group	O
of	O
connected	O
neurons	O
or	O
a	O
group	O
of	O
points	O
of	O
the	O
input	O
space	O
covered	O
by	O
these	O
neurons	O
(	O
ﬁg	O
.	O
a.3	O
)	O
.	O
of	O
course	O
,	O
the	O
complete	O
rolf	O
network	O
can	O
be	O
evaluated	O
by	O
means	O
of	O
other	O
clus-	O
tering	O
methods	O
,	O
i.e	O
.	O
the	O
neurons	O
can	O
be	O
searched	O
for	O
clusters	B
.	O
particularly	O
with	O
clustering	O
methods	O
whose	O
storage	O
eﬀort	O
grows	O
quadratic	O
to	O
|p|	O
the	O
storage	O
eﬀort	O
can	O
be	O
reduced	O
dramatically	O
since	O
gener-	O
ally	O
there	O
are	O
considerably	O
less	O
rolf	O
neu-	O
rons	O
than	O
original	O
data	O
points	O
,	O
but	O
the	O
neurons	O
represent	O
the	O
data	O
points	O
quite	O
well	O
.	O
a.5.4	O
comparison	O
with	O
popular	O
clustering	O
methods	O
it	O
is	O
obvious	O
,	O
that	O
storing	O
the	O
neurons	O
rather	O
than	O
storing	O
the	O
input	O
points	O
takes	O
the	O
biggest	O
part	O
of	O
the	O
storage	O
eﬀort	O
of	O
the	O
rolfs	O
.	O
this	O
is	O
a	O
great	O
advantage	O
for	O
huge	O
point	O
clouds	O
with	O
a	O
lot	O
of	O
points	O
.	O
since	O
it	O
is	O
unnecessary	O
to	O
store	O
the	O
en-	O
tire	O
point	O
cloud	O
,	O
our	O
rolf	O
,	O
as	O
a	O
neural	O
clustering	O
method	O
,	O
has	O
the	O
capability	B
to	I
learn	I
online	O
,	O
which	O
is	O
deﬁnitely	O
a	O
great	O
ad-	O
vantage	O
.	O
furthermore	O
,	O
it	O
can	O
(	O
similar	O
to	O
ε	O
nearest	O
neighboring	O
or	O
k	O
nearest	O
neigh-	O
boring	O
)	O
distinguish	O
clusters	B
from	O
enclosed	O
clusters	B
–	O
but	O
due	O
to	O
the	O
online	O
presenta-	O
tion	O
of	O
the	O
data	O
without	O
a	O
quadratically	O
growing	B
storage	O
eﬀort	O
,	O
which	O
is	O
by	O
far	O
the	O
greatest	O
disadvantage	O
of	O
the	O
two	O
neighbor-	O
ing	O
methods	O
.	O
less	O
storage	O
eﬀort	O
!	O
recognize	O
''	O
cluster	O
in	O
clusters	B
''	O
figure	O
a.3	O
:	O
the	O
clustering	O
process	O
.	O
top	O
:	O
the	O
input	O
set	O
,	O
middle	O
:	O
the	O
input	O
space	O
covered	O
by	O
rolf	O
neurons	O
,	O
bottom	O
:	O
the	O
input	O
space	O
only	O
covered	O
by	O
the	O
neurons	O
(	O
representatives	O
)	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
179	O
appendix	O
a	O
excursus	O
:	O
cluster	B
analysis	I
and	O
regional	O
and	O
online	O
learnable	O
ﬁeldsdkriesel.com	O
additionally	O
,	O
the	O
issue	O
of	O
the	O
size	O
of	O
the	O
in-	O
dividual	O
clusters	B
proportional	O
to	O
their	O
dis-	O
tance	O
from	O
each	O
other	O
is	O
addressed	O
by	O
us-	O
ing	O
variable	O
perceptive	O
surfaces	O
-	O
which	O
is	O
also	O
not	O
always	O
the	O
case	O
for	O
the	O
two	O
men-	O
tioned	O
methods	O
.	O
the	O
rolf	O
compares	O
favorably	O
with	O
k-	O
means	O
clustering	O
,	O
as	O
well	O
:	O
firstly	O
,	O
it	O
is	O
un-	O
necessary	O
to	O
previously	O
know	O
the	O
number	O
of	O
clusters	B
and	O
,	O
secondly	O
,	O
k-means	O
cluster-	O
ing	O
recognizes	O
clusters	B
enclosed	O
by	O
other	O
clusters	B
as	O
separate	O
clusters	B
.	O
a.5.5	O
initializing	O
radii	O
,	O
learning	B
rates	O
and	O
multiplier	O
is	O
not	O
trivial	O
certainly	O
,	O
the	O
disadvantages	O
of	O
the	O
rolf	O
shall	O
not	O
be	O
concealed	O
:	O
it	O
is	O
not	O
always	O
easy	O
to	O
select	O
the	O
appropriate	O
initial	O
value	O
for	O
σ	O
and	O
ρ.	O
the	O
previous	O
knowledge	O
about	O
the	O
data	O
set	O
can	O
so	O
to	O
say	O
be	O
in-	O
cluded	O
in	O
ρ	O
and	O
the	O
initial	O
value	O
of	O
σ	O
of	O
the	O
rolf	O
:	O
fine-grained	O
data	O
clusters	B
should	O
use	O
a	O
small	O
ρ	O
and	O
a	O
small	O
σ	O
initial	O
value	O
.	O
but	O
the	O
smaller	O
the	O
ρ	O
the	O
smaller	O
,	O
the	O
chance	O
that	O
the	O
neurons	O
will	O
grow	O
if	O
neces-	O
sary	O
.	O
here	O
again	O
,	O
there	O
is	O
no	O
easy	O
answer	O
,	O
just	O
like	O
for	O
the	O
learning	B
rates	O
ηc	O
and	O
ησ	O
.	O
for	O
ρ	O
the	O
multipliers	O
in	O
the	O
lower	O
single-	O
digit	O
range	O
such	O
as	O
2	O
or	O
3	O
are	O
very	O
popu-	O
lar	O
.	O
ηc	O
and	O
ησ	O
successfully	O
work	O
with	O
val-	O
ues	O
about	O
0.005	O
to	O
0.1	O
,	O
variations	O
during	O
run-time	O
are	O
also	O
imaginable	O
for	O
this	O
type	O
of	O
network	O
.	O
initial	O
values	O
for	O
σ	O
generally	O
depend	O
on	O
the	O
cluster	O
and	O
data	O
distribu-	O
tion	O
(	O
i.e	O
.	O
they	O
often	O
have	O
to	O
be	O
tested	O
)	O
.	O
but	O
compared	O
to	O
wrong	O
initializations	O
–	O
at	O
least	O
with	O
the	O
mean-σ	O
strategy	O
–	O
they	O
are	O
relatively	O
robust	O
after	O
some	O
training	O
time	O
.	O
as	O
a	O
whole	O
,	O
the	O
rolf	O
is	O
on	O
a	O
par	O
with	O
the	O
other	O
clustering	O
methods	O
and	O
is	O
par-	O
ticularly	O
very	O
interesting	O
for	O
systems	O
with	O
low	O
storage	O
capacity	O
or	O
huge	O
data	O
sets	O
.	O
a.5.6	O
application	O
examples	O
a	O
ﬁrst	O
application	O
example	O
could	O
be	O
ﬁnd-	O
ing	O
color	O
clusters	B
in	O
rgb	O
images	O
.	O
another	O
ﬁeld	O
of	O
application	O
directly	O
described	O
in	O
the	O
rolf	O
publication	O
is	O
the	O
recognition	O
of	O
words	O
transferred	O
into	O
a	O
720-dimensional	O
feature	O
space	O
.	O
thus	O
,	O
we	O
can	O
see	O
that	O
rolfs	O
are	O
relatively	O
robust	O
against	O
higher	O
dimensions	O
.	O
further	O
applications	O
can	O
be	O
found	O
in	O
the	O
ﬁeld	O
of	O
analysis	O
of	O
attacks	O
on	O
network	O
systems	O
and	O
their	O
classiﬁcation	O
.	O
exercises	O
exercise	O
18.	O
determine	O
at	O
least	O
four	O
adaptation	O
steps	O
for	O
one	O
single	O
rolf	O
neu-	O
ron	O
k	O
if	O
the	O
four	O
patterns	O
stated	O
below	O
are	O
presented	O
one	O
after	O
another	O
in	O
the	O
in-	O
dicated	O
order	O
.	O
let	O
the	O
initial	O
values	O
for	O
the	O
rolf	O
neuron	O
be	O
ck	O
=	O
(	O
0.1	O
,	O
0.1	O
)	O
and	O
σk	O
=	O
1.	O
furthermore	O
,	O
let	O
ηc	O
=	O
0.5	O
and	O
ησ	O
=	O
0.	O
let	O
ρ	O
=	O
3.	O
p	O
=	O
{	O
(	O
0.1	O
,	O
0.1	O
)	O
;	O
=	O
(	O
0.9	O
,	O
0.1	O
)	O
;	O
=	O
(	O
0.1	O
,	O
0.9	O
)	O
;	O
=	O
(	O
0.9	O
,	O
0.9	O
)	O
}	O
.	O
180	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
appendix	O
b	O
excursus	O
:	O
neural	O
networks	O
used	O
for	O
prediction	O
discussion	O
of	O
an	O
application	O
of	O
neural	O
networks	O
:	O
a	O
look	O
ahead	O
into	O
the	O
future	O
of	O
time	B
series	I
.	O
after	O
discussing	O
the	O
diﬀerent	O
paradigms	O
of	O
neural	O
networks	O
it	O
is	O
now	O
useful	O
to	O
take	O
a	O
look	O
at	O
an	O
application	O
of	O
neural	O
networks	O
which	O
is	O
brought	O
up	O
often	O
and	O
(	O
as	O
we	O
will	O
see	O
)	O
is	O
also	O
used	O
for	O
fraud	O
:	O
the	O
applica-	O
tion	O
of	O
time	B
series	I
prediction	I
.	O
this	O
ex-	O
cursus	O
is	O
structured	O
into	O
the	O
description	O
of	O
time	B
series	I
and	O
estimations	O
about	O
the	O
re-	O
quirements	O
that	O
are	O
actually	O
needed	O
to	O
pre-	O
dict	O
the	O
values	O
of	O
a	O
time	B
series	I
.	O
finally	O
,	O
i	O
will	O
say	O
something	O
about	O
the	O
range	O
of	O
soft-	O
ware	O
which	O
should	O
predict	O
share	O
prices	O
or	O
other	O
economic	O
characteristics	O
by	O
means	O
of	O
neural	O
networks	O
or	O
other	O
procedures	O
.	O
b.1	O
about	O
time	B
series	I
a	O
time	B
series	I
is	O
a	O
series	O
of	O
values	O
dis-	O
cretized	O
in	O
time	O
.	O
for	O
example	O
,	O
daily	O
mea-	O
sured	O
temperature	O
values	O
or	O
other	O
meteo-	O
rological	O
data	O
of	O
a	O
speciﬁc	O
site	O
could	O
be	O
represented	O
by	O
a	O
time	B
series	I
.	O
share	O
price	O
values	O
also	O
represent	O
a	O
time	B
series	I
.	O
often	O
the	O
measurement	O
of	O
time	B
series	I
is	O
timely	O
equidistant	O
,	O
and	O
in	O
many	O
time	B
series	I
the	O
future	O
development	O
of	O
their	O
values	O
is	O
very	O
interesting	O
,	O
e.g	O
.	O
the	O
daily	O
weather	O
fore-	O
cast	O
.	O
this	O
chapter	O
should	O
not	O
be	O
a	O
detailed	O
description	O
but	O
rather	O
indicate	O
some	O
ap-	O
proaches	O
for	O
time	B
series	I
prediction	I
.	O
in	O
this	O
respect	O
i	O
will	O
again	O
try	O
to	O
avoid	O
formal	O
def-	O
initions	O
.	O
time	B
series	I
of	O
values	O
time	B
series	I
can	O
also	O
be	O
values	O
of	O
an	O
actu-	O
ally	O
continuous	B
function	O
read	O
in	O
a	O
certain	O
distance	O
of	O
time	O
∆t	O
(	O
ﬁg	O
.	O
b.1	O
on	O
the	O
next	O
(	O
cid:74	O
)	O
∆t	O
page	O
)	O
.	O
if	O
we	O
want	O
to	O
predict	O
a	O
time	B
series	I
,	O
we	O
will	O
look	O
for	O
a	O
neural	O
network	O
that	O
maps	O
the	O
previous	O
series	O
values	O
to	O
future	O
develop-	O
ments	O
of	O
the	O
time	B
series	I
,	O
i.e	O
.	O
if	O
we	O
know	O
longer	O
sections	O
of	O
the	O
time	B
series	I
,	O
we	O
will	O
181	O
appendix	O
b	O
excursus	O
:	O
neural	O
networks	O
used	O
for	O
prediction	O
dkriesel.com	O
have	O
enough	O
training	O
samples	O
.	O
of	O
course	O
,	O
these	O
are	O
not	O
examples	O
for	O
the	O
future	O
to	O
be	O
predicted	O
but	O
it	O
is	O
tried	O
to	O
generalize	O
and	O
to	O
extrapolate	O
the	O
past	O
by	O
means	O
of	O
the	O
said	O
samples	O
.	O
but	O
before	O
we	O
begin	O
to	O
predict	O
a	O
time	B
series	I
we	O
have	O
to	O
answer	O
some	O
questions	O
about	O
this	O
time	B
series	I
we	O
are	O
dealing	O
with	O
and	O
ensure	O
that	O
it	O
fulﬁlls	O
some	O
require-	O
ments	O
.	O
1.	O
do	O
we	O
have	O
any	O
evidence	O
which	O
sug-	O
gests	O
that	O
future	O
values	O
depend	O
in	O
any	O
way	O
on	O
the	O
past	O
values	O
of	O
the	O
time	O
se-	O
ries	O
?	O
does	O
the	O
past	O
of	O
a	O
time	B
series	I
include	O
information	O
about	O
its	O
future	O
?	O
2.	O
do	O
we	O
have	O
enough	O
past	O
values	O
of	O
the	O
time	B
series	I
that	O
can	O
be	O
used	O
as	O
train-	O
ing	O
patterns	O
?	O
3.	O
in	O
case	O
of	O
a	O
prediction	O
of	O
a	O
continuous	B
function	O
:	O
what	O
must	O
a	O
useful	O
∆t	O
look	O
like	O
?	O
now	O
these	O
questions	O
shall	O
be	O
explored	O
in	O
detail	O
.	O
how	O
much	O
information	O
about	O
the	O
future	O
is	O
included	O
in	O
the	O
past	O
values	O
of	O
a	O
time	O
se-	O
ries	O
?	O
this	O
is	O
the	O
most	O
important	O
question	O
to	O
be	O
answered	O
for	O
any	O
time	B
series	I
that	O
should	O
be	O
mapped	O
into	O
the	O
future	O
.	O
if	O
the	O
future	O
values	O
of	O
a	O
time	B
series	I
,	O
for	O
instance	O
,	O
do	O
not	O
depend	O
on	O
the	O
past	O
values	O
,	O
then	O
a	O
time	B
series	I
prediction	I
based	O
on	O
them	O
will	O
be	O
impossible	O
.	O
in	O
this	O
chapter	O
,	O
we	O
assume	O
systems	O
whose	O
future	O
values	O
can	O
be	O
deduced	O
from	O
their	O
states	O
–	O
the	O
deterministic	O
systems	O
.	O
this	O
figure	O
b.1	O
:	O
a	O
function	B
x	O
that	O
depends	O
on	O
the	O
time	O
is	O
sampled	O
at	O
discrete	B
time	O
steps	O
(	O
time	O
dis-	O
cretized	O
)	O
,	O
this	O
means	O
that	O
the	O
result	O
is	O
a	O
time	B
series	I
.	O
the	O
sampled	O
values	O
are	O
entered	O
into	O
a	O
neural	O
network	O
(	O
in	O
this	O
example	O
an	O
slp	O
)	O
which	O
shall	O
learn	O
to	O
predict	O
the	O
future	O
values	O
of	O
the	O
time	B
series	I
.	O
182	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
b.2	O
one-step-ahead	B
prediction	I
leads	O
us	O
to	O
the	O
question	O
of	O
what	O
a	O
system	O
state	B
is	O
.	O
b.2	O
one-step-ahead	B
prediction	I
a	O
system	O
state	B
completely	O
describes	O
a	O
sys-	O
tem	O
for	O
a	O
certain	O
point	O
of	O
time	O
.	O
the	O
future	O
of	O
a	O
deterministic	O
system	O
would	O
be	O
clearly	O
deﬁned	O
by	O
means	O
of	O
the	O
complete	O
descrip-	O
tion	O
of	O
its	O
current	O
state	B
.	O
the	O
problem	O
in	O
the	O
real	O
world	O
is	O
that	O
such	O
a	O
state	B
concept	O
includes	O
all	O
things	O
that	O
in-	O
ﬂuence	O
our	O
system	O
by	O
any	O
means	O
.	O
in	O
case	O
of	O
our	O
weather	O
forecast	O
for	O
a	O
spe-	O
ciﬁc	O
site	O
we	O
could	O
deﬁnitely	O
determine	O
the	O
temperature	O
,	O
the	O
atmospheric	O
pres-	O
sure	O
and	O
the	O
cloud	O
density	O
as	O
the	O
mete-	O
orological	O
state	B
of	O
the	O
place	O
at	O
a	O
time	O
t.	O
but	O
the	O
whole	O
state	B
would	O
include	O
signiﬁ-	O
cantly	O
more	O
information	O
.	O
here	O
,	O
the	O
world-	O
wide	O
phenomena	O
that	O
control	O
the	O
weather	O
would	O
be	O
interesting	O
as	O
well	O
as	O
small	O
local	O
pheonomena	O
such	O
as	O
the	O
cooling	O
system	O
of	O
the	O
local	O
power	O
plant	O
.	O
so	O
we	O
shall	O
note	O
that	O
the	O
system	O
state	B
is	O
de-	O
sirable	O
for	O
prediction	O
but	O
not	O
always	O
possi-	O
ble	O
to	O
obtain	O
.	O
often	O
only	O
fragments	O
of	O
the	O
current	O
states	O
can	O
be	O
acquired	O
,	O
e.g	O
.	O
for	O
a	O
weather	O
forecast	O
these	O
fragments	O
are	O
the	O
said	O
weather	O
data	O
.	O
however	O
,	O
we	O
can	O
partially	O
overcome	O
these	O
weaknesses	O
by	O
using	O
not	O
only	O
one	O
single	O
state	O
(	O
the	O
last	O
one	O
)	O
for	O
the	O
prediction	O
,	O
but	O
by	O
using	O
several	O
past	O
states	O
.	O
from	O
this	O
we	O
want	O
to	O
derive	O
our	O
ﬁrst	O
prediction	O
sys-	O
tem	O
:	O
predict	O
the	O
next	O
value	O
the	O
ﬁrst	O
attempt	O
to	O
predict	O
the	O
next	O
fu-	O
ture	O
value	O
of	O
a	O
time	B
series	I
out	O
of	O
past	O
val-	O
ues	O
is	O
called	O
one-step-ahead	B
prediction	I
(	O
ﬁg	O
.	O
b.2	O
on	O
the	O
following	O
page	O
)	O
.	O
such	O
a	O
predictor	O
system	O
receives	O
the	O
last	O
n	O
observed	O
state	B
parts	O
of	O
the	O
system	O
as	O
input	O
and	O
outputs	O
the	O
prediction	O
for	O
the	O
next	O
state	B
(	O
or	O
state	B
part	O
)	O
.	O
the	O
idea	O
of	O
a	O
state	O
space	O
with	O
predictable	O
states	O
is	O
called	O
state	B
space	I
forecasting	I
.	O
the	O
aim	O
of	O
the	O
predictor	O
is	O
to	O
realize	O
a	O
function	B
f	O
(	O
xt−n+1	O
,	O
.	O
.	O
.	O
,	O
xt−1	O
,	O
xt	O
)	O
=	O
˜xt+1	O
,	O
(	O
b.1	O
)	O
which	O
receives	O
exactly	O
n	O
past	O
values	O
in	O
or-	O
der	O
to	O
predict	O
the	O
future	O
value	O
.	O
predicted	O
values	O
shall	O
be	O
headed	O
by	O
a	O
tilde	O
(	O
e.g	O
.	O
˜x	O
)	O
(	O
cid:74	O
)	O
˜x	O
to	O
distinguish	O
them	O
from	O
the	O
actual	O
future	O
values	O
.	O
the	O
most	O
intuitive	O
and	O
simplest	O
approach	O
would	O
be	O
to	O
ﬁnd	O
a	O
linear	O
combination	O
˜xi+1	O
=	O
a0xi	O
+	O
a1xi−1	O
+	O
.	O
.	O
.	O
+	O
ajxi−j	O
(	O
b.2	O
)	O
that	O
approximately	O
fulﬁlls	O
our	O
tions	O
.	O
condi-	O
such	O
a	O
construction	O
is	O
called	O
digital	O
ﬁl-	O
ter	O
.	O
here	O
we	O
use	O
the	O
fact	O
that	O
time	B
series	I
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
183	O
appendix	O
b	O
excursus	O
:	O
neural	O
networks	O
used	O
for	O
prediction	O
dkriesel.com	O
xt−3	O
xt−2	O
xt−1	O
xt	O
˜xt+1	O
predictor	O
figure	O
b.2	O
:	O
representation	O
of	O
the	O
one-step-ahead	B
prediction	I
.	O
it	O
is	O
tried	O
to	O
calculate	O
the	O
future	O
value	O
from	O
a	O
series	O
of	O
past	O
values	O
.	O
the	O
predicting	O
element	O
(	O
in	O
this	O
case	O
a	O
neural	O
network	O
)	O
is	O
referred	O
to	O
as	O
predictor	O
.	O
usually	O
have	O
a	O
lot	O
of	O
past	O
values	O
so	O
that	O
we	O
can	O
set	O
up	O
a	O
series	O
of	O
equations1	O
:	O
means	O
of	O
the	O
delta	B
rule	I
provides	O
results	O
very	O
close	O
to	O
the	O
analytical	O
solution	O
.	O
xt	O
=	O
a0xt−1	O
+	O
.	O
.	O
.	O
+	O
ajxt−1−	O
(	O
n−1	O
)	O
xt−1	O
=	O
a0xt−2	O
+	O
.	O
.	O
.	O
+	O
ajxt−2−	O
(	O
n−1	O
)	O
...	O
(	O
b.3	O
)	O
xt−n	O
=	O
a0xt−n	O
+	O
.	O
.	O
.	O
+	O
ajxt−n−	O
(	O
n−1	O
)	O
thus	O
,	O
n	O
equations	O
could	O
be	O
found	O
for	O
n	O
un-	O
known	O
coeﬃcients	O
and	O
solve	O
them	O
(	O
if	O
pos-	O
sible	O
)	O
.	O
or	O
another	O
,	O
better	O
approach	O
:	O
we	O
could	O
use	O
m	O
>	O
n	O
equations	O
for	O
n	O
unknowns	O
in	O
such	O
a	O
way	O
that	O
the	O
sum	O
of	O
the	O
mean	O
squared	O
errors	O
of	O
the	O
already	O
known	O
pre-	O
diction	O
is	O
minimized	O
.	O
this	O
is	O
called	O
mov-	O
ing	O
average	O
procedure	O
.	O
but	O
this	O
linear	O
structure	O
corresponds	O
to	O
a	O
singlelayer	B
perceptron	I
with	O
a	O
linear	O
activa-	O
tion	O
function	B
which	O
has	O
been	O
trained	O
by	O
means	O
of	O
data	O
from	O
the	O
past	O
(	O
the	O
experi-	O
mental	O
setup	O
would	O
comply	O
with	O
ﬁg	O
.	O
b.1	O
on	O
page	O
182	O
)	O
.	O
in	O
fact	O
,	O
the	O
training	O
by	O
1	O
without	O
going	O
into	O
detail	O
,	O
i	O
want	O
to	O
remark	O
that	O
the	O
prediction	O
becomes	O
easier	O
the	O
more	O
past	O
values	O
of	O
the	O
time	B
series	I
are	O
available	O
.	O
i	O
would	O
like	O
to	O
ask	O
the	O
reader	O
to	O
read	O
up	O
on	O
the	O
nyquist-shannon	O
sampling	O
theorem	O
even	O
if	O
this	O
approach	O
often	O
provides	O
satis-	O
fying	O
results	O
,	O
we	O
have	O
seen	O
that	O
many	O
prob-	O
lems	O
can	O
not	O
be	O
solved	O
by	O
using	O
a	O
single-	O
layer	B
perceptron	O
.	O
additional	O
layers	O
with	O
linear	O
activation	O
function	B
are	O
useless	O
,	O
as	O
well	O
,	O
since	O
a	O
multilayer	B
perceptron	I
with	O
only	O
linear	O
activation	O
functions	O
can	O
be	O
re-	O
duced	O
to	O
a	O
singlelayer	B
perceptron	I
.	O
such	O
considerations	O
lead	O
to	O
a	O
non-linear	O
ap-	O
proach	O
.	O
the	O
multilayer	B
perceptron	I
and	O
non-linear	O
activation	B
functions	O
provide	O
a	O
universal	O
non-linear	O
function	B
approximator	I
,	O
i.e	O
.	O
we	O
can	O
use	O
an	O
n-|h|-1-mlp	O
for	O
n	O
n	O
inputs	O
out	O
of	O
the	O
past	O
.	O
an	O
rbf	O
network	O
could	O
also	O
be	O
used	O
.	O
but	O
remember	O
that	O
here	O
the	O
number	O
n	O
has	O
to	O
remain	O
low	O
since	O
in	O
rbf	O
networks	O
high	O
input	O
dimensions	O
are	O
very	O
complex	O
to	O
realize	O
.	O
so	O
if	O
we	O
want	O
to	O
include	O
many	O
past	O
values	O
,	O
a	O
multilayer	B
perceptron	I
will	O
require	O
considerably	O
less	O
computational	O
eﬀort	O
.	O
184	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
.	O
.	O
.	O
.	O
-	O
-	O
+	O
+	O
k	O
k	O
dkriesel.com	O
b.4	O
additional	O
optimization	O
approaches	O
for	O
prediction	O
b.3	O
two-step-ahead	B
prediction	I
b.4	O
additional	O
optimization	O
approaches	O
for	O
prediction	O
what	O
approaches	O
can	O
we	O
use	O
to	O
to	O
see	O
far-	O
ther	O
into	O
the	O
future	O
?	O
b.3.1	O
recursive	O
two-step-ahead	B
prediction	I
in	O
order	O
to	O
extend	O
the	O
prediction	O
to	O
,	O
for	O
in-	O
stance	O
,	O
two	O
time	O
steps	O
into	O
the	O
future	O
,	O
we	O
could	O
perform	O
two	O
one-step-ahead	O
predic-	O
tions	O
in	O
a	O
row	O
(	O
ﬁg	O
.	O
b.3	O
on	O
the	O
following	O
i.e	O
.	O
a	O
recursive	O
two-step-ahead	O
page	O
)	O
,	O
prediction	O
.	O
unfortunately	O
,	O
the	O
value	O
de-	O
termined	O
by	O
means	O
of	O
a	O
one-step-ahead	B
prediction	I
is	O
generally	O
imprecise	O
so	O
that	O
errors	O
can	O
be	O
built	O
up	O
,	O
and	O
the	O
more	O
pre-	O
dictions	O
are	O
performed	O
in	O
a	O
row	O
the	O
more	O
imprecise	O
becomes	O
the	O
result	O
.	O
b.3.2	O
direct	O
two-step-ahead	O
prediction	O
we	O
have	O
already	O
guessed	O
that	O
there	O
exists	O
a	O
better	O
approach	O
:	O
just	O
like	O
the	O
system	O
can	O
be	O
trained	O
to	O
predict	O
the	O
next	O
value	O
,	O
we	O
can	O
certainly	O
train	O
it	O
to	O
predict	O
the	O
next	O
but	O
one	O
value	O
.	O
this	O
means	O
we	O
di-	O
rectly	O
train	O
,	O
for	O
example	O
,	O
a	O
neural	O
network	O
to	O
look	O
two	O
time	O
steps	O
ahead	O
into	O
the	O
fu-	O
ture	O
,	O
which	O
is	O
referred	O
to	O
as	O
direct	O
two-	O
step-ahead	O
prediction	O
(	O
ﬁg	O
.	O
b.4	O
on	O
the	O
next	O
page	O
)	O
.	O
obviously	O
,	O
the	O
direct	O
two-step-	O
ahead	O
prediction	O
is	O
technically	O
identical	O
to	O
the	O
one-step-ahead	B
prediction	I
.	O
the	O
only	O
diﬀerence	O
is	O
the	O
training	O
.	O
the	O
possibility	O
to	O
predict	O
values	O
far	O
away	O
in	O
the	O
future	O
is	O
not	O
only	O
important	O
because	O
we	O
try	O
to	O
look	O
farther	O
ahead	O
into	O
the	O
fu-	O
ture	O
.	O
there	O
can	O
also	O
be	O
periodic	O
time	O
se-	O
ries	O
where	O
other	O
approaches	O
are	O
hardly	O
pos-	O
sible	O
:	O
if	O
a	O
lecture	O
begins	O
at	O
9	O
a.m.	O
every	O
thursday	O
,	O
it	O
is	O
not	O
very	O
useful	O
to	O
know	O
how	O
many	O
people	O
sat	O
in	O
the	O
lecture	O
room	O
on	O
monday	O
to	O
predict	O
the	O
number	O
of	O
lecture	O
participants	O
.	O
the	O
same	O
applies	O
,	O
for	O
ex-	O
ample	O
,	O
to	O
periodically	O
occurring	O
commuter	O
jams	O
.	O
b.4.1	O
changing	O
temporal	O
parameters	O
thus	O
,	O
it	O
can	O
be	O
useful	O
to	O
intentionally	O
leave	O
gaps	O
in	O
the	O
future	O
values	O
as	O
well	O
as	O
in	O
the	O
past	O
values	O
of	O
the	O
time	B
series	I
,	O
i.e	O
.	O
to	O
in-	O
troduce	O
the	O
parameter	O
∆t	O
which	O
indicates	O
which	O
past	O
value	O
is	O
used	O
for	O
prediction	O
.	O
technically	O
speaking	O
,	O
we	O
still	O
use	O
a	O
one-	O
step-ahead	O
prediction	O
only	O
that	O
we	O
extend	O
the	O
input	O
space	O
or	O
train	O
the	O
system	O
to	O
pre-	O
dict	O
values	O
lying	O
farther	O
away	O
.	O
it	O
is	O
also	O
possible	O
to	O
combine	O
diﬀerent	O
∆t	O
:	O
in	O
case	O
of	O
the	O
traﬃc	O
jam	O
prediction	O
for	O
a	O
monday	O
the	O
values	O
of	O
the	O
last	O
few	O
days	O
could	O
be	O
used	O
as	O
data	O
input	O
in	O
addition	O
to	O
the	O
values	O
of	O
the	O
previous	O
mondays	O
.	O
thus	O
,	O
we	O
use	O
the	O
last	O
values	O
of	O
several	O
periods	O
,	O
in	O
this	O
case	O
the	O
values	O
of	O
a	O
weekly	O
and	O
a	O
daily	O
period	B
.	O
we	O
could	O
also	O
include	O
an	O
an-	O
nual	O
period	B
in	O
the	O
form	O
of	O
the	O
beginning	O
of	O
the	O
holidays	O
(	O
for	O
sure	O
,	O
everyone	O
of	O
us	O
has	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
185	O
predict	O
future	O
values	O
direct	O
prediction	O
is	O
better	O
extent	O
input	O
period	O
appendix	O
b	O
excursus	O
:	O
neural	O
networks	O
used	O
for	O
prediction	O
dkriesel.com	O
predictor	O
xt−3	O
xt−2	O
xt−1	O
xt	O
˜xt+1	O
˜xt+2	O
predictor	O
figure	O
b.3	O
:	O
representation	O
of	O
the	O
two-step-ahead	B
prediction	I
.	O
attempt	O
to	O
predict	O
the	O
second	O
future	O
value	O
out	O
of	O
a	O
past	O
value	O
series	O
by	O
means	O
of	O
a	O
second	O
predictor	O
and	O
the	O
involvement	O
of	O
an	O
already	O
predicted	O
value	O
.	O
xt−3	O
xt−2	O
xt−1	O
xt	O
˜xt+1	O
˜xt+2	O
predictor	O
figure	O
b.4	O
:	O
representation	O
of	O
the	O
direct	O
two-step-ahead	O
prediction	O
.	O
here	O
,	O
the	O
second	O
time	O
step	O
is	O
predicted	O
directly	O
,	O
the	O
ﬁrst	O
one	O
is	O
omitted	O
.	O
technically	O
,	O
it	O
does	O
not	O
diﬀer	O
from	O
a	O
one-step-ahead	B
prediction	I
.	O
186	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
	O
	O
.	O
.	O
0	O
0	O
.	O
.	O
0	O
0	O
-	O
-	O
+	O
+	O
0	O
0	O
o	O
o	O
j	O
j	O
.	O
.	O
.	O
.	O
-	O
-	O
+	O
+	O
e	O
e	O
use	O
information	O
outside	O
of	O
time	B
series	I
dkriesel.com	O
b.5	O
remarks	O
on	O
the	O
prediction	O
of	O
share	O
prices	O
already	O
spent	O
a	O
lot	O
of	O
time	O
on	O
the	O
highway	O
because	O
he	O
forgot	O
the	O
beginning	O
of	O
the	O
hol-	O
idays	O
)	O
.	O
b.4.2	O
heterogeneous	B
prediction	O
another	O
prediction	O
approach	O
would	O
be	O
to	O
predict	O
the	O
future	O
values	O
of	O
a	O
single	O
time	O
series	O
out	O
of	O
several	O
time	B
series	I
,	O
if	O
it	O
is	O
assumed	O
that	O
the	O
additional	O
time	B
series	I
is	O
related	O
to	O
the	O
future	O
of	O
the	O
ﬁrst	O
one	O
(	O
heterogeneous	B
one-step-ahead	O
pre-	O
diction	O
,	O
ﬁg	O
.	O
b.5	O
on	O
the	O
following	O
page	O
)	O
.	O
if	O
we	O
want	O
to	O
predict	O
two	O
outputs	O
of	O
two	O
related	O
time	B
series	I
,	O
it	O
is	O
certainly	O
possible	O
to	O
perform	O
two	O
parallel	O
one-step-ahead	O
pre-	O
dictions	O
(	O
analytically	O
this	O
is	O
done	O
very	O
of-	O
ten	O
because	O
otherwise	O
the	O
equations	O
would	O
become	O
very	O
confusing	O
)	O
;	O
or	O
in	O
case	O
of	O
the	O
neural	O
networks	O
an	O
additional	O
output	O
neuron	O
is	O
attached	O
and	O
the	O
knowledge	O
of	O
both	O
time	B
series	I
is	O
used	O
for	O
both	O
outputs	O
(	O
ﬁg	O
.	O
b.6	O
on	O
the	O
next	O
page	O
)	O
.	O
you	O
’	O
ll	O
ﬁnd	O
more	O
and	O
more	O
general	O
material	O
on	O
time	B
series	I
in	O
[	O
wg94	O
]	O
.	O
b.5	O
remarks	O
on	O
the	O
prediction	O
of	O
share	O
prices	O
many	O
people	O
observe	O
the	O
changes	O
of	O
a	O
share	O
price	O
in	O
the	O
past	O
and	O
try	O
to	O
con-	O
clude	O
the	O
future	O
from	O
those	O
values	O
in	O
or-	O
der	O
to	O
beneﬁt	O
from	O
this	O
knowledge	O
.	O
share	O
prices	O
are	O
discontinuous	O
and	O
therefore	O
they	O
are	O
principally	O
diﬃcult	O
functions	O
.	O
further-	O
more	O
,	O
the	O
functions	O
can	O
only	O
be	O
used	O
for	O
discrete	B
values	O
–	O
often	O
,	O
for	O
example	O
,	O
in	O
a	O
daily	O
rhythm	O
(	O
including	O
the	O
maximum	O
and	O
minimum	O
values	O
per	O
day	O
,	O
if	O
we	O
are	O
lucky	O
)	O
with	O
the	O
daily	O
variations	O
certainly	O
being	O
eliminated	O
.	O
but	O
this	O
makes	O
the	O
whole	O
thing	O
even	O
more	O
diﬃcult	O
.	O
there	O
are	O
chartists	O
,	O
i.e	O
.	O
people	O
who	O
look	O
at	O
many	O
diagrams	O
and	O
decide	O
by	O
means	O
of	O
a	O
lot	O
of	O
background	O
knowledge	O
and	O
decade-long	O
experience	O
whether	O
the	O
equi-	O
ties	O
should	O
be	O
bought	O
or	O
not	O
(	O
and	O
often	O
they	O
are	O
very	O
successful	O
)	O
.	O
apart	O
from	O
the	O
share	O
prices	O
it	O
is	O
very	O
in-	O
teresting	O
to	O
predict	O
the	O
exchange	O
rates	O
of	O
currencies	O
:	O
if	O
we	O
exchange	O
100	O
euros	O
into	O
dollars	O
,	O
the	O
dollars	O
into	O
pounds	O
and	O
the	O
pounds	O
back	O
into	O
euros	O
it	O
could	O
be	O
pos-	O
sible	O
that	O
we	O
will	O
ﬁnally	O
receive	O
110	O
eu-	O
ros	O
.	O
but	O
once	O
found	O
out	O
,	O
we	O
would	O
do	O
this	O
more	O
often	O
and	O
thus	O
we	O
would	O
change	O
the	O
exchange	O
rates	O
into	O
a	O
state	B
in	O
which	O
such	O
an	O
increasing	O
circulation	O
would	O
no	O
longer	O
be	O
possible	O
(	O
otherwise	O
we	O
could	O
produce	O
money	O
by	O
generating	O
,	O
so	O
to	O
speak	O
,	O
a	O
ﬁnan-	O
cial	O
perpetual	O
motion	O
machine	O
.	O
at	O
the	O
stock	O
exchange	O
,	O
successful	O
stock	O
and	O
currency	O
brokers	O
raise	O
or	O
lower	O
their	O
thumbs	O
–	O
and	O
thereby	O
indicate	O
whether	O
in	O
their	O
opinion	O
a	O
share	O
price	O
or	O
an	O
exchange	O
rate	O
will	O
increase	O
or	O
decrease	O
.	O
mathemat-	O
ically	O
speaking	O
,	O
they	O
indicate	O
the	O
ﬁrst	O
bit	O
(	O
sign	O
)	O
of	O
the	O
ﬁrst	O
derivative	O
of	O
the	O
ex-	O
change	O
rate	O
.	O
in	O
that	O
way	O
excellent	O
world-	O
class	O
brokers	O
obtain	O
success	O
rates	O
of	O
about	O
70	O
%	O
.	O
in	O
great	O
britain	O
,	O
the	O
heterogeneous	B
one-	O
step-ahead	O
prediction	O
was	O
successfully	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
187	O
appendix	O
b	O
excursus	O
:	O
neural	O
networks	O
used	O
for	O
prediction	O
dkriesel.com	O
xt−3	O
xt−2	O
xt−1	O
xt	O
˜xt+1	O
predictor	O
yt−3	O
yt−2	O
yt−1	O
yt	O
figure	O
b.5	O
:	O
representation	O
of	O
the	O
heterogeneous	B
one-step-ahead	O
prediction	O
.	O
prediction	O
of	O
a	O
time	B
series	I
under	O
consideration	O
of	O
a	O
second	O
one	O
.	O
xt−3	O
xt−2	O
xt−1	O
xt	O
yt−3	O
yt−2	O
yt−1	O
yt	O
predictor	O
˜xt+1	O
˜yt+1	O
figure	O
b.6	O
:	O
heterogeneous	B
one-step-ahead	O
prediction	O
of	O
two	O
time	B
series	I
at	O
the	O
same	O
time	O
.	O
188	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
.	O
.	O
.	O
.	O
-	O
-	O
+	O
+	O
k	O
k	O
0	O
0	O
0	O
0	O
1	O
1	O
3	O
3	O
.	O
.	O
.	O
.	O
-	O
-	O
+	O
+	O
k	O
k	O
	O
	O
0	O
0	O
0	O
0	O
1	O
1	O
3	O
3	O
dkriesel.com	O
b.5	O
remarks	O
on	O
the	O
prediction	O
of	O
share	O
prices	O
again	O
and	O
again	O
some	O
software	O
appears	O
which	O
uses	O
scientiﬁc	O
key	O
words	O
such	O
as	O
”	O
neural	O
networks	O
”	O
to	O
purport	O
that	O
it	O
is	O
ca-	O
pable	O
to	O
predict	O
where	O
share	O
prices	O
are	O
go-	O
ing	O
.	O
do	O
not	O
buy	O
such	O
software	O
!	O
in	O
addi-	O
tion	O
to	O
the	O
aforementioned	O
scientiﬁc	O
exclu-	O
sions	O
there	O
is	O
one	O
simple	O
reason	O
for	O
this	O
:	O
if	O
these	O
tools	O
work	O
–	O
why	O
should	O
the	O
man-	O
ufacturer	O
sell	O
them	O
?	O
normally	O
,	O
useful	O
eco-	O
nomic	O
knowledge	O
is	O
kept	O
secret	O
.	O
if	O
we	O
knew	O
a	O
way	O
to	O
deﬁnitely	O
gain	O
wealth	O
by	O
means	O
of	O
shares	O
,	O
we	O
would	O
earn	O
our	O
millions	O
by	O
using	O
this	O
knowledge	O
instead	O
of	O
selling	O
it	O
for	O
30	O
euros	O
,	O
wouldn	O
’	O
t	O
we	O
?	O
used	O
to	O
increase	O
the	O
accuracy	O
of	O
such	O
pre-	O
dictions	O
to	O
76	O
%	O
:	O
in	O
addition	O
to	O
the	O
time	B
series	I
of	O
the	O
values	O
indicators	O
such	O
as	O
the	O
oil	O
price	O
in	O
rotterdam	O
or	O
the	O
us	O
national	O
debt	O
were	O
included	O
.	O
this	O
is	O
just	O
an	O
example	O
to	O
show	O
the	O
mag-	O
nitude	O
of	O
the	O
accuracy	O
of	O
stock-exchange	O
evaluations	O
,	O
since	O
we	O
are	O
still	O
talking	O
only	O
about	O
the	O
ﬁrst	O
bit	O
of	O
the	O
ﬁrst	O
derivation	O
!	O
we	O
still	O
do	O
not	O
know	O
how	O
strong	O
the	O
ex-	O
pected	O
increase	O
or	O
decrease	O
will	O
be	O
and	O
also	O
whether	O
the	O
eﬀort	O
will	O
pay	O
oﬀ	O
:	O
prob-	O
ably	O
,	O
one	O
wrong	O
prediction	O
could	O
nullify	O
the	O
proﬁt	O
of	O
one	O
hundred	O
correct	O
predic-	O
tions	O
.	O
how	O
can	O
neural	O
networks	O
be	O
used	O
to	O
pre-	O
dict	O
share	O
prices	O
?	O
intuitively	O
,	O
we	O
assume	O
that	O
future	O
share	O
prices	O
are	O
a	O
function	B
of	O
the	O
previous	O
share	O
values	O
.	O
but	O
this	O
assumption	O
is	O
wrong	O
:	O
share	O
prices	O
are	O
no	O
function	B
of	O
their	O
past	O
val-	O
ues	O
,	O
but	O
a	O
function	B
of	O
their	O
assumed	O
fu-	O
ture	O
value	O
.	O
we	O
do	O
not	O
buy	O
shares	O
be-	O
cause	O
their	O
values	O
have	O
been	O
increased	O
during	O
the	O
last	O
days	O
,	O
but	O
because	O
we	O
be-	O
lieve	O
that	O
they	O
will	O
futher	O
increase	O
tomor-	O
row	O
.	O
if	O
,	O
as	O
a	O
consequence	O
,	O
many	O
people	O
buy	O
a	O
share	O
,	O
they	O
will	O
boost	O
the	O
price	O
.	O
therefore	O
their	O
assumption	O
was	O
right	O
–	O
a	O
self-fulﬁlling	O
prophecy	O
has	O
been	O
gener-	O
ated	O
,	O
a	O
phenomenon	O
long	O
known	O
in	O
eco-	O
nomics	O
.	O
the	O
same	O
applies	O
the	O
other	O
way	O
around	O
:	O
we	O
sell	O
shares	O
because	O
we	O
believe	O
that	O
to-	O
morrow	O
the	O
prices	O
will	O
decrease	O
.	O
this	O
will	O
beat	O
down	O
the	O
prices	O
the	O
next	O
day	O
and	O
gen-	O
erally	O
even	O
more	O
the	O
day	O
after	O
the	O
next	O
.	O
share	O
price	O
function	B
of	O
assumed	O
future	O
value	O
!	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
189	O
appendix	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
what	O
if	O
there	O
were	O
no	O
training	O
samples	O
but	O
it	O
would	O
nevertheless	O
be	O
possible	O
to	O
evaluate	O
how	O
well	O
we	O
have	O
learned	O
to	O
solve	O
a	O
problem	O
?	O
let	O
us	O
examine	O
a	O
learning	B
paradigm	O
that	O
is	O
situated	O
between	O
supervised	O
and	O
unsupervised	B
learning	I
.	O
i	O
now	O
want	O
to	O
introduce	O
a	O
more	O
exotic	O
ap-	O
proach	O
of	O
learning	B
–	O
just	O
to	O
leave	O
the	O
usual	O
paths	O
.	O
we	O
know	O
learning	B
procedures	O
in	O
which	O
the	O
network	O
is	O
exactly	O
told	O
what	O
to	O
do	O
,	O
i.e	O
.	O
we	O
provide	O
exemplary	O
output	O
val-	O
ues	O
.	O
we	O
also	O
know	O
learning	B
procedures	O
like	O
those	O
of	O
the	O
self-organizing	O
maps	O
,	O
into	O
which	O
only	O
input	O
values	O
are	O
entered	O
.	O
now	O
we	O
want	O
to	O
explore	O
something	O
in-	O
between	O
:	O
the	O
learning	B
paradigm	O
of	O
rein-	O
forcement	O
learning	B
–	O
reinforcement	O
learn-	O
ing	O
according	O
to	O
sutton	O
and	O
barto	O
[	O
sb98	O
]	O
.	O
reinforcement	B
learning	I
in	O
itself	O
is	O
no	O
neu-	O
ral	O
network	O
but	O
only	O
one	O
of	O
the	O
three	O
learn-	O
ing	O
paradigms	O
already	O
mentioned	O
in	O
chap-	O
ter	O
4.	O
in	O
some	O
sources	O
it	O
is	O
counted	O
among	O
the	O
supervised	B
learning	I
procedures	O
since	O
a	O
feedback	O
is	O
given	O
.	O
due	O
to	O
its	O
very	O
rudimen-	O
tary	O
feedback	O
it	O
is	O
reasonable	O
to	O
separate	O
it	O
from	O
the	O
supervised	B
learning	I
procedures	O
–	O
apart	O
from	O
the	O
fact	O
that	O
there	O
are	O
no	O
training	O
samples	O
at	O
all	O
.	O
no	O
samples	O
but	O
feedback	O
from	O
cognitive	O
science	O
i.e	O
.	O
term	O
reinforcement	O
while	O
it	O
is	O
generally	O
known	O
that	O
pro-	O
cedures	O
such	O
as	O
backpropagation	B
can	O
not	O
work	O
in	O
the	O
human	O
brain	B
itself	O
,	O
reinforce-	O
ment	O
learning	B
is	O
usually	O
considered	O
as	O
be-	O
ing	O
biologically	O
more	O
motivated	O
.	O
learning	B
the	O
and	O
comes	O
psychology	O
and	O
it	O
describes	O
the	O
learning	B
system	O
of	O
carrot	O
and	O
stick	O
,	O
which	O
occurs	O
everywhere	O
in	O
nature	O
,	O
learning	B
by	O
means	O
of	O
good	O
or	O
bad	O
experience	O
,	O
reward	B
and	O
punishment	O
.	O
but	O
there	O
is	O
no	O
learning	B
aid	O
that	O
exactly	O
explains	O
what	O
we	O
have	O
to	O
do	O
:	O
we	O
only	O
receive	O
a	O
total	O
result	O
for	O
a	O
process	O
(	O
did	O
we	O
win	O
the	O
game	O
of	O
chess	O
or	O
not	O
?	O
and	O
how	O
sure	O
was	O
this	O
victory	O
?	O
)	O
,	O
but	O
no	O
results	O
for	O
the	O
individual	O
intermediate	O
steps	O
.	O
for	O
example	O
,	O
if	O
we	O
ride	O
our	O
bike	O
with	O
worn	O
tires	O
and	O
at	O
a	O
speed	O
of	O
exactly	O
21	O
,	O
5	O
km	O
h	O
through	O
a	O
turn	O
over	O
some	O
sand	O
with	O
a	O
grain	O
size	O
of	O
0.1mm	O
,	O
on	O
the	O
average	O
,	O
then	O
nobody	O
could	O
tell	O
us	O
exactly	O
which	O
han-	O
191	O
appendix	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
dkriesel.com	O
dlebar	O
angle	O
we	O
have	O
to	O
adjust	O
or	O
,	O
even	O
worse	O
,	O
how	O
strong	O
the	O
great	O
number	O
of	O
muscle	O
parts	O
in	O
our	O
arms	O
or	O
legs	O
have	O
to	O
contract	O
for	O
this	O
.	O
depending	O
on	O
whether	O
we	O
reach	O
the	O
end	O
of	O
the	O
curve	O
unharmed	O
or	O
not	O
,	O
we	O
soon	O
have	O
to	O
face	O
the	O
learning	B
expe-	O
rience	O
,	O
a	O
feedback	O
or	O
a	O
reward	B
,	O
be	O
it	O
good	O
or	O
bad	O
.	O
thus	O
,	O
the	O
reward	B
is	O
very	O
simple	O
-	O
but	O
on	O
the	O
other	O
hand	O
it	O
is	O
considerably	O
easier	O
to	O
obtain	O
.	O
if	O
we	O
now	O
have	O
tested	O
dif-	O
ferent	O
velocities	O
and	O
turning	O
angles	O
often	O
enough	O
and	O
received	O
some	O
rewards	O
,	O
we	O
will	O
get	O
a	O
feel	O
for	O
what	O
works	O
and	O
what	O
does	O
not	O
.	O
the	O
aim	O
of	O
reinforcement	B
learning	I
is	O
to	O
maintain	O
exactly	O
this	O
feeling	O
.	O
another	O
the	O
quasi-	O
impossibility	O
to	O
achieve	O
a	O
sort	O
of	O
cost	O
or	O
utility	O
function	B
is	O
a	O
tennis	O
player	O
who	O
tries	O
to	O
maximize	O
his	O
athletic	O
success	O
on	O
the	O
long	O
term	O
by	O
means	O
of	O
complex	O
movements	O
and	O
ballistic	O
trajectories	O
in	O
the	O
three-dimensional	O
space	O
including	O
the	O
wind	O
direction	O
,	O
the	O
importance	O
of	O
the	O
tournament	O
,	O
private	O
factors	O
and	O
many	O
more	O
.	O
to	O
get	O
straight	O
to	O
the	O
point	O
:	O
since	O
we	O
receive	O
only	O
little	O
feedback	O
,	O
reinforcement	B
learning	I
often	O
means	O
trial	O
and	O
error	O
–	O
and	O
therefore	O
it	O
is	O
very	O
slow	O
.	O
example	O
for	O
c.1	O
system	O
structure	O
now	O
we	O
want	O
to	O
brieﬂy	O
discuss	O
diﬀerent	O
sizes	O
and	O
components	O
of	O
the	O
system	O
.	O
we	O
will	O
deﬁne	O
them	O
more	O
precisely	O
in	O
the	O
fol-	O
lowing	O
sections	O
.	O
broadly	O
speaking	O
,	O
rein-	O
forcement	O
learning	B
represents	O
the	O
mutual	O
interaction	O
between	O
an	O
agent	B
and	O
an	O
envi-	O
ronmental	O
system	O
(	O
ﬁg	O
.	O
c.2	O
)	O
.	O
the	O
agent	B
shall	O
solve	O
some	O
problem	O
.	O
he	O
could	O
,	O
for	O
instance	O
,	O
be	O
an	O
autonomous	O
robot	O
that	O
shall	O
avoid	O
obstacles	O
.	O
the	O
agent	B
performs	O
some	O
actions	O
within	O
the	O
environment	B
and	O
in	O
return	B
receives	O
a	O
feed-	O
back	O
from	O
the	O
environment	B
,	O
which	O
in	O
the	O
following	O
is	O
called	O
reward	B
.	O
this	O
cycle	O
of	O
ac-	O
tion	O
and	O
reward	B
is	O
characteristic	O
for	O
rein-	O
forcement	O
learning	B
.	O
the	O
agent	B
inﬂuences	O
the	O
system	O
,	O
the	O
system	O
provides	O
a	O
reward	B
and	O
then	O
changes	O
.	O
the	O
reward	B
is	O
a	O
real	O
or	O
discrete	B
scalar	O
which	O
describes	O
,	O
as	O
mentioned	O
above	O
,	O
how	O
well	O
we	O
achieve	O
our	O
aim	O
,	O
but	O
it	O
does	O
not	O
give	O
any	O
guidance	O
how	O
we	O
can	O
achieve	O
it	O
.	O
the	O
aim	O
is	O
always	O
to	O
make	O
the	O
sum	O
of	O
rewards	O
as	O
high	O
as	O
possible	O
on	O
the	O
long	O
term	O
.	O
c.1.1	O
the	O
gridworld	B
as	O
a	O
learning	B
example	O
for	O
reinforcement	B
learning	I
i	O
would	O
like	O
to	O
use	O
the	O
so-called	O
gridworld	B
.	O
we	O
will	O
see	O
that	O
its	O
struc-	O
ture	O
is	O
very	O
simple	O
and	O
easy	O
to	O
ﬁgure	O
out	O
and	O
therefore	O
reinforcement	O
is	O
actually	O
not	O
necessary	O
.	O
however	O
,	O
it	O
is	O
very	O
suitable	O
for	O
representing	O
the	O
approach	O
of	O
reinforce-	O
ment	O
learning	B
.	O
now	O
let	O
us	O
exemplary	O
de-	O
ﬁne	O
the	O
individual	O
components	O
of	O
the	O
re-	O
inforcement	O
system	O
by	O
means	O
of	O
the	O
grid-	O
world	O
.	O
later	O
,	O
each	O
of	O
these	O
components	O
will	O
be	O
examined	O
more	O
exactly	O
.	O
environment	B
:	O
the	O
gridworld	B
(	O
ﬁg	O
.	O
c.1	O
on	O
the	O
facing	O
page	O
)	O
is	O
a	O
simple	O
,	O
discrete	B
simple	O
examplary	O
world	O
192	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
c.1	O
system	O
structure	O
world	O
in	O
two	O
dimensions	O
which	O
in	O
the	O
following	O
we	O
want	O
to	O
use	O
as	O
environ-	O
mental	O
system	O
.	O
agent	B
:	O
as	O
an	O
agent	B
we	O
use	O
a	O
simple	O
robot	O
being	O
situated	O
in	O
our	O
gridworld	B
.	O
state	O
space	O
:	O
as	O
we	O
can	O
see	O
,	O
our	O
gridworld	B
has	O
5	O
×	O
7	O
ﬁelds	O
with	O
6	O
ﬁelds	O
being	O
un-	O
accessible	O
.	O
therefore	O
,	O
our	O
agent	B
can	O
occupy	O
29	O
positions	O
in	O
the	O
grid	B
world	O
.	O
these	O
positions	O
are	O
regarded	O
as	O
states	O
for	O
the	O
agent	B
.	O
action	B
space	I
:	O
the	O
actions	O
are	O
still	O
miss-	O
ing	O
.	O
we	O
simply	O
deﬁne	O
that	O
the	O
robot	O
could	O
move	O
one	O
ﬁeld	O
up	O
or	O
down	O
,	O
to	O
the	O
right	O
or	O
to	O
the	O
left	O
(	O
as	O
long	O
as	O
there	O
is	O
no	O
obstacle	O
or	O
the	O
edge	O
of	O
our	O
gridworld	B
)	O
.	O
task	O
:	O
our	O
agent	B
’	O
s	O
task	O
is	O
to	O
leave	O
the	O
grid-	O
world	O
.	O
the	O
exit	O
is	O
located	O
on	O
the	O
right	O
of	O
the	O
light-colored	O
ﬁeld	O
.	O
non-determinism	O
:	O
the	O
two	O
obstacles	O
can	O
be	O
connected	O
by	O
a	O
``	O
door	O
''	O
.	O
when	O
the	O
door	O
is	O
closed	O
(	O
lower	O
part	O
of	O
the	O
illus-	O
tration	O
)	O
,	O
the	O
corresponding	O
ﬁeld	O
is	O
in-	O
accessible	O
.	O
the	O
position	O
of	O
the	O
door	O
can	O
not	O
change	O
during	O
a	O
cycle	O
but	O
only	O
between	O
the	O
cycles	O
.	O
we	O
now	O
have	O
created	O
a	O
small	O
world	O
that	O
will	O
accompany	O
us	O
through	O
the	O
following	O
learning	B
strategies	O
and	O
illustrate	O
them	O
.	O
c.1.2	O
agent	B
und	O
environment	B
our	O
aim	O
is	O
that	O
the	O
agent	B
learns	O
what	O
hap-	O
pens	O
by	O
means	O
of	O
the	O
reward	B
.	O
thus	O
,	O
it	O
×	O
×	O
figure	O
c.1	O
:	O
a	O
graphical	O
representation	O
of	O
our	O
gridworld	B
.	O
dark-colored	O
cells	O
are	O
obstacles	O
and	O
therefore	O
inaccessible	O
.	O
the	O
exit	O
is	O
located	O
on	O
the	O
right	O
side	O
of	O
the	O
light-colored	O
ﬁeld	O
.	O
the	O
symbol	O
×	O
marks	O
the	O
starting	O
position	O
of	O
our	O
agent	B
.	O
in	O
the	O
upper	O
part	O
of	O
our	O
ﬁgure	O
the	O
door	O
is	O
open	O
,	O
in	O
the	O
lower	O
part	O
it	O
is	O
closed	O
.	O
agent	B
reward	O
/	O
new	O
situation	B
action	O
environment	B
figure	O
c.2	O
:	O
the	O
agent	B
performs	O
some	O
actions	O
within	O
the	O
environment	B
and	O
in	O
return	B
receives	O
a	O
reward	B
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
193	O
_	O
_	O
?	O
?	O
agent	B
acts	O
in	O
environment	B
appendix	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
dkriesel.com	O
is	O
trained	O
over	O
,	O
of	O
and	O
by	O
means	O
of	O
a	O
dy-	O
namic	O
system	O
,	O
the	O
environment	B
,	O
in	O
order	O
to	O
reach	O
an	O
aim	O
.	O
but	O
what	O
does	O
learning	B
mean	O
in	O
this	O
context	O
?	O
the	O
agent	B
shall	O
learn	O
a	O
mapping	O
of	O
sit-	O
uations	O
to	O
actions	O
(	O
called	O
policy	B
)	O
,	O
i.e	O
.	O
it	O
shall	O
learn	O
what	O
to	O
do	O
in	O
which	O
situation	B
to	O
achieve	O
a	O
certain	O
(	O
given	O
)	O
aim	O
.	O
the	O
aim	O
is	O
simply	O
shown	O
to	O
the	O
agent	B
by	O
giving	O
an	O
award	O
for	O
the	O
achievement	O
.	O
such	O
an	O
award	O
must	O
not	O
be	O
mistaken	O
for	O
the	O
reward	B
–	O
on	O
the	O
agent	B
’	O
s	O
way	O
to	O
the	O
solution	O
it	O
may	O
sometimes	O
be	O
useful	O
to	O
receive	O
a	O
smaller	O
award	O
or	O
a	O
punishment	O
when	O
in	O
return	B
the	O
longterm	O
result	O
is	O
max-	O
imum	O
(	O
similar	O
to	O
the	O
situation	B
when	O
an	O
investor	O
just	O
sits	O
out	O
the	O
downturn	O
of	O
the	O
share	O
price	O
or	O
to	O
a	O
pawn	O
sacriﬁce	O
in	O
a	O
chess	O
game	O
)	O
.	O
so	O
,	O
if	O
the	O
agent	B
is	O
heading	O
into	O
the	O
right	O
direction	O
towards	O
the	O
target	B
,	O
it	O
receives	O
a	O
positive	O
reward	B
,	O
and	O
if	O
not	O
it	O
re-	O
ceives	O
no	O
reward	B
at	O
all	O
or	O
even	O
a	O
negative	O
reward	B
(	O
punishment	O
)	O
.	O
the	O
award	O
is	O
,	O
so	O
to	O
speak	O
,	O
the	O
ﬁnal	O
sum	O
of	O
all	O
rewards	O
–	O
which	O
is	O
also	O
called	O
return	B
.	O
after	O
having	O
colloquially	O
named	O
all	O
the	O
ba-	O
sic	O
components	O
,	O
we	O
want	O
to	O
discuss	O
more	O
precisely	O
which	O
components	O
can	O
be	O
used	O
to	O
make	O
up	O
our	O
abstract	O
reinforcement	O
learn-	O
ing	O
system	O
.	O
in	O
the	O
gridworld	B
:	O
in	O
the	O
gridworld	B
,	O
the	O
agent	B
is	O
a	O
simple	O
robot	O
that	O
should	O
ﬁnd	O
the	O
exit	O
of	O
the	O
gridworld	B
.	O
the	O
environment	B
is	O
the	O
gridworld	B
itself	O
,	O
which	O
is	O
a	O
discrete	B
gridworld	O
.	O
deﬁnition	O
c.1	O
(	O
agent	B
)	O
.	O
in	O
reinforce-	O
ment	O
learning	B
the	O
agent	B
can	O
be	O
formally	O
described	O
as	O
a	O
mapping	O
of	O
the	O
situation	B
space	I
s	O
into	O
the	O
action	B
space	I
a	O
(	O
st	O
)	O
.	O
the	O
meaning	O
of	O
situations	O
st	O
will	O
be	O
deﬁned	O
later	O
and	O
should	O
only	O
indicate	O
that	O
the	O
ac-	O
tion	O
space	O
depends	O
on	O
the	O
current	O
situa-	O
tion	O
.	O
agent	B
:	O
s	O
→	O
a	O
(	O
st	O
)	O
(	O
c.1	O
)	O
deﬁnition	O
c.2	O
(	O
environment	B
)	O
.	O
the	O
en-	O
vironment	O
represents	O
a	O
stochastic	O
map-	O
ping	O
of	O
an	O
action	O
a	O
in	O
the	O
current	O
situa-	O
tion	O
st	O
to	O
a	O
reward	B
rt	O
and	O
a	O
new	O
situation	B
st+1	O
.	O
environment	B
:	O
s	O
×	O
a	O
→	O
p	O
(	O
s	O
×	O
rt	O
)	O
(	O
c.2	O
)	O
c.1.3	O
states	O
,	O
situations	O
and	O
actions	O
as	O
already	O
mentioned	O
,	O
an	O
agent	B
can	O
be	O
in	O
diﬀerent	O
states	O
:	O
in	O
case	O
of	O
the	O
gridworld	B
,	O
for	O
example	O
,	O
it	O
can	O
be	O
in	O
diﬀerent	O
positions	O
(	O
here	O
we	O
get	O
a	O
two-dimensional	O
state	B
vec-	O
tor	O
)	O
.	O
for	O
an	O
agent	B
is	O
ist	O
not	O
always	O
possible	O
to	O
realize	O
all	O
information	O
about	O
its	O
current	O
state	B
so	O
that	O
we	O
have	O
to	O
introduce	O
the	O
term	O
situation	B
.	O
a	O
situation	B
is	O
a	O
state	B
from	O
the	O
agent	B
’	O
s	O
point	O
of	O
view	O
,	O
i.e	O
.	O
only	O
a	O
more	O
or	O
less	O
precise	O
approximation	O
of	O
a	O
state	B
.	O
therefore	O
,	O
situations	O
generally	O
do	O
not	O
al-	O
low	O
to	O
clearly	O
``	O
predict	O
''	O
successor	O
situa-	O
tions	O
–	O
even	O
with	O
a	O
completely	O
determin-	O
istic	O
system	O
this	O
may	O
not	O
be	O
applicable	O
.	O
if	O
we	O
knew	O
all	O
states	O
and	O
the	O
transitions	O
between	O
them	O
exactly	O
(	O
thus	O
,	O
the	O
complete	O
system	O
)	O
,	O
it	O
would	O
be	O
possible	O
to	O
plan	O
op-	O
timally	O
and	O
also	O
easy	O
to	O
ﬁnd	O
an	O
optimal	O
194	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
c.1	O
system	O
structure	O
policy	B
(	O
methods	O
are	O
provided	O
,	O
for	O
example	O
,	O
by	O
dynamic	O
programming	O
)	O
.	O
now	O
we	O
know	O
that	O
reinforcement	B
learning	I
is	O
an	O
interaction	O
between	O
the	O
agent	B
and	O
the	O
system	O
including	O
actions	O
at	O
and	O
sit-	O
uations	O
st.	O
the	O
agent	B
can	O
not	O
determine	O
by	O
itself	O
whether	O
the	O
current	O
situation	B
is	O
good	O
or	O
bad	O
:	O
this	O
is	O
exactly	O
the	O
reason	O
why	O
it	O
receives	O
the	O
said	O
reward	B
from	O
the	O
environment	B
.	O
in	O
the	O
gridworld	B
:	O
states	O
are	O
positions	O
where	O
the	O
agent	B
can	O
be	O
situated	O
.	O
sim-	O
ply	O
said	O
,	O
the	O
situations	O
equal	O
the	O
states	O
in	O
the	O
gridworld	B
.	O
possible	O
actions	O
would	O
be	O
to	O
move	O
towards	O
north	O
,	O
south	O
,	O
east	O
or	O
west	O
.	O
situation	B
and	O
action	O
can	O
be	O
vectorial	O
,	O
the	O
reward	B
is	O
always	O
a	O
scalar	O
(	O
in	O
an	O
extreme	O
case	O
even	O
only	O
a	O
binary	O
value	O
)	O
since	O
the	O
aim	O
of	O
reinforcement	B
learning	I
is	O
to	O
get	O
along	O
with	O
little	O
feedback	O
.	O
a	O
complex	O
vec-	O
torial	O
reward	B
would	O
equal	O
a	O
real	O
teaching	B
input	I
.	O
by	O
the	O
way	O
,	O
the	O
cost	O
function	B
should	O
be	O
minimized	O
,	O
which	O
would	O
not	O
be	O
possible	O
,	O
however	O
,	O
with	O
a	O
vectorial	O
reward	B
since	O
we	O
do	O
not	O
have	O
any	O
intuitive	O
order	O
relations	O
in	O
multi-dimensional	O
space	O
,	O
i.e	O
.	O
we	O
do	O
not	O
directly	O
know	O
what	O
is	O
better	O
or	O
worse	O
.	O
deﬁnition	O
c.3	O
(	O
state	B
)	O
.	O
within	O
its	O
en-	O
vironment	O
the	O
agent	B
is	O
in	O
a	O
state	B
.	O
states	O
contain	O
any	O
information	O
about	O
the	O
agent	B
within	O
the	O
environmental	O
system	O
.	O
thus	O
,	O
it	O
is	O
theoretically	O
possible	O
to	O
clearly	O
pre-	O
dict	O
a	O
successor	O
state	B
to	O
a	O
performed	O
ac-	O
tion	O
within	O
a	O
deterministic	O
system	O
out	O
of	O
this	O
godlike	O
state	B
knowledge	O
.	O
deﬁnition	O
c.4	O
(	O
situation	B
)	O
.	O
situations	O
st	O
(	O
here	O
at	O
time	O
t	O
)	O
of	O
a	O
situation	B
space	I
(	O
cid:74	O
)	O
st	O
s	O
are	O
the	O
agent	B
’	O
s	O
limited	O
,	O
approximate	O
(	O
cid:74	O
)	O
s	O
knowledge	O
about	O
its	O
state	B
.	O
this	O
approx-	O
imation	O
(	O
about	O
which	O
the	O
agent	B
can	O
not	O
even	O
know	O
how	O
good	O
it	O
is	O
)	O
makes	O
clear	O
pre-	O
dictions	O
impossible	O
.	O
deﬁnition	O
c.5	O
(	O
action	O
)	O
.	O
actions	O
at	O
can	O
(	O
cid:74	O
)	O
at	O
be	O
performed	O
by	O
the	O
agent	B
(	O
whereupon	O
it	O
could	O
be	O
possible	O
that	O
depending	O
on	O
the	O
situation	B
another	O
action	B
space	I
a	O
(	O
s	O
)	O
ex-	O
(	O
cid:74	O
)	O
a	O
(	O
s	O
)	O
ists	O
)	O
.	O
they	O
cause	O
state	B
transitions	O
and	O
therefore	O
a	O
new	O
situation	B
from	O
the	O
agent	B
’	O
s	O
point	O
of	O
view	O
.	O
c.1.4	O
reward	B
and	O
return	B
as	O
in	O
real	O
life	O
it	O
is	O
our	O
aim	O
to	O
receive	O
an	O
award	O
that	O
is	O
as	O
high	O
as	O
possible	O
,	O
i.e	O
.	O
to	O
maximize	O
the	O
sum	O
of	O
the	O
expected	O
re-	O
wards	O
r	O
,	O
called	O
return	B
r	O
,	O
on	O
the	O
long	O
term	O
.	O
for	O
ﬁnitely	O
many	O
time	O
steps1	O
the	O
rewards	O
can	O
simply	O
be	O
added	O
:	O
rt	O
=	O
rt+1	O
+	O
rt+2	O
+	O
.	O
.	O
.	O
∞x	O
x=1	O
=	O
rt+x	O
(	O
c.3	O
)	O
(	O
c.4	O
)	O
certainly	O
,	O
the	O
return	B
is	O
only	O
estimated	O
here	O
(	O
if	O
we	O
knew	O
all	O
rewards	O
and	O
therefore	O
the	O
return	B
completely	O
,	O
it	O
would	O
no	O
longer	O
be	O
necessary	O
to	O
learn	O
)	O
.	O
deﬁnition	O
c.6	O
(	O
reward	B
)	O
.	O
a	O
reward	B
rt	O
is	O
(	O
cid:74	O
)	O
rt	O
a	O
scalar	O
,	O
real	O
or	O
discrete	B
(	O
even	O
sometimes	O
only	O
binary	O
)	O
reward	B
or	O
punishment	O
which	O
1	O
in	O
practice	O
,	O
only	O
ﬁnitely	O
many	O
time	O
steps	O
will	O
be	O
possible	O
,	O
even	O
though	O
the	O
formulas	O
are	O
stated	O
with	O
an	O
inﬁnite	O
sum	O
in	O
the	O
ﬁrst	O
place	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
195	O
appendix	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
dkriesel.com	O
the	O
environmental	O
system	O
returns	O
to	O
the	O
agent	B
as	O
reaction	O
to	O
an	O
action	O
.	O
deﬁnition	O
c.7	O
(	O
return	B
)	O
.	O
the	O
return	B
rt	O
is	O
the	O
accumulation	O
of	O
all	O
received	O
rewards	O
until	O
time	O
t.	O
rt	O
(	O
cid:73	O
)	O
c.1.4.1	O
dealing	O
with	O
long	O
periods	O
of	O
time	O
however	O
,	O
not	O
every	O
problem	O
has	O
an	O
ex-	O
plicit	O
target	B
and	O
therefore	O
a	O
ﬁnite	O
sum	O
(	O
e.g	O
.	O
our	O
agent	B
can	O
be	O
a	O
robot	O
having	O
the	O
task	O
to	O
drive	O
around	O
again	O
and	O
again	O
and	O
to	O
avoid	O
obstacles	O
)	O
.	O
in	O
order	O
not	O
to	O
receive	O
a	O
diverging	O
sum	O
in	O
case	O
of	O
an	O
inﬁnite	O
series	O
of	O
reward	B
estimations	O
a	O
weakening	O
factor	O
0	O
<	O
γ	O
<	O
1	O
is	O
used	O
,	O
which	O
weakens	O
the	O
in-	O
ﬂuence	O
of	O
future	O
rewards	O
.	O
this	O
is	O
not	O
only	O
useful	O
if	O
there	O
exists	O
no	O
target	B
but	O
also	O
if	O
the	O
target	B
is	O
very	O
far	O
away	O
:	O
γ	O
(	O
cid:73	O
)	O
rt	O
=	O
rt+1	O
+	O
γ1rt+2	O
+	O
γ2rt+3	O
+	O
.	O
.	O
.	O
∞x	O
x=1	O
=	O
γx−1rt+x	O
(	O
c.5	O
)	O
(	O
c.6	O
)	O
the	O
farther	O
the	O
reward	B
is	O
away	O
,	O
the	O
smaller	O
is	O
the	O
inﬂuence	O
it	O
has	O
in	O
the	O
agent	B
’	O
s	O
deci-	O
sions	O
.	O
another	O
possibility	O
to	O
handle	O
the	O
return	B
sum	O
would	O
be	O
a	O
limited	O
time	B
horizon	I
τ	O
so	O
that	O
only	O
τ	O
many	O
following	O
rewards	O
rt+1	O
,	O
.	O
.	O
.	O
,	O
rt+τ	O
are	O
regarded	O
:	O
τ	O
(	O
cid:73	O
)	O
rt	O
=	O
rt+1	O
+	O
.	O
.	O
.	O
+	O
γτ−1rt+τ	O
τx	O
x=1	O
=	O
γx−1rt+x	O
(	O
c.7	O
)	O
(	O
c.8	O
)	O
the	O
thus	O
,	O
we	O
divide	O
into	O
episodes	O
.	O
usually	O
,	O
one	O
of	O
the	O
two	O
meth-	O
ods	O
is	O
used	O
to	O
limit	O
the	O
sum	O
,	O
if	O
not	O
both	O
methods	O
together	O
.	O
timeline	O
as	O
in	O
daily	O
living	O
we	O
try	O
to	O
approximate	O
our	O
current	O
situation	B
to	O
a	O
desired	O
state	B
.	O
since	O
it	O
is	O
not	O
mandatory	O
that	O
only	O
the	O
next	O
expected	O
reward	B
but	O
the	O
expected	O
to-	O
tal	O
sum	O
decides	O
what	O
the	O
agent	B
will	O
do	O
,	O
it	O
is	O
also	O
possible	O
to	O
perform	O
actions	O
that	O
,	O
on	O
short	O
notice	O
,	O
result	O
in	O
a	O
negative	O
reward	B
(	O
e.g	O
.	O
the	O
pawn	O
sacriﬁce	O
in	O
a	O
chess	O
game	O
)	O
but	O
will	O
pay	O
oﬀ	O
later	O
.	O
c.1.5	O
the	O
policy	B
after	O
having	O
considered	O
and	O
formalized	O
some	O
system	O
components	O
of	O
reinforcement	B
learning	I
the	O
actual	O
aim	O
is	O
still	O
to	O
be	O
dis-	O
cussed	O
:	O
during	O
reinforcement	B
learning	I
the	O
agent	B
learns	O
a	O
policy	B
π	O
:	O
s	O
→	O
p	O
(	O
a	O
)	O
,	O
thus	O
,	O
it	O
continuously	O
adjusts	O
a	O
mapping	O
of	O
the	O
situations	O
to	O
the	O
probabilities	O
p	O
(	O
a	O
)	O
,	O
with	O
which	O
any	O
action	O
a	O
is	O
performed	O
in	O
any	O
situation	B
s.	O
a	O
policy	B
can	O
be	O
deﬁned	O
as	O
a	O
strategy	O
to	O
select	O
actions	O
that	O
would	O
maximize	O
the	O
reward	B
in	O
the	O
long	O
term	O
.	O
in	O
the	O
gridworld	B
:	O
in	O
the	O
gridworld	B
the	O
pol-	O
icy	O
is	O
the	O
strategy	O
according	O
to	O
which	O
the	O
agent	B
tries	O
to	O
exit	O
the	O
gridworld	B
.	O
deﬁnition	O
c.8	O
(	O
policy	B
)	O
.	O
the	O
policy	B
π	O
s	O
a	O
mapping	O
of	O
situations	O
to	O
probabilities	O
(	O
cid:74	O
)	O
π	O
196	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
c.1	O
system	O
structure	O
to	O
perform	O
every	O
action	O
out	O
of	O
the	O
action	B
space	I
.	O
so	O
it	O
can	O
be	O
formalized	O
as	O
π	O
:	O
s	O
→	O
p	O
(	O
a	O
)	O
.	O
(	O
c.9	O
)	O
basically	O
,	O
we	O
distinguish	O
between	O
two	O
pol-	O
icy	O
paradigms	O
:	O
an	O
open	B
loop	I
policy	O
rep-	O
resents	O
an	O
open	O
control	O
chain	O
and	O
creates	O
out	O
of	O
an	O
initial	O
situation	B
s0	O
a	O
sequence	O
of	O
actions	O
a0	O
,	O
a1	O
,	O
.	O
.	O
.	O
with	O
ai	O
6=	O
ai	O
(	O
si	O
)	O
;	O
i	O
>	O
0.	O
thus	O
,	O
in	O
the	O
beginning	O
the	O
agent	B
develops	O
a	O
plan	O
and	O
consecutively	O
executes	O
it	O
to	O
the	O
end	O
without	O
considering	O
the	O
intermediate	O
situations	O
(	O
therefore	O
ai	O
6=	O
ai	O
(	O
si	O
)	O
,	O
actions	O
af-	O
ter	O
a0	O
do	O
not	O
depend	O
on	O
the	O
situations	O
)	O
.	O
in	O
the	O
gridworld	B
:	O
in	O
the	O
gridworld	B
,	O
an	O
open-loop	O
policy	B
would	O
provide	O
a	O
precise	O
direction	O
towards	O
the	O
exit	O
,	O
such	O
as	O
the	O
way	O
from	O
the	O
given	O
starting	O
position	O
to	O
(	O
in	O
ab-	O
breviations	O
of	O
the	O
directions	O
)	O
eeeen	O
.	O
so	O
an	O
open-loop	O
policy	B
is	O
a	O
sequence	O
of	O
actions	O
without	O
interim	O
feedback	O
.	O
a	O
se-	O
quence	O
of	O
actions	O
is	O
generated	O
out	O
of	O
a	O
starting	O
situation	B
.	O
if	O
the	O
system	O
is	O
known	O
well	O
and	O
truly	O
,	O
such	O
an	O
open-loop	O
policy	B
can	O
be	O
used	O
successfully	O
and	O
lead	O
to	O
use-	O
ful	O
results	O
.	O
but	O
,	O
for	O
example	O
,	O
to	O
know	O
the	O
chess	O
game	O
well	O
and	O
truly	O
it	O
would	O
be	O
nec-	O
essary	O
to	O
try	O
every	O
possible	O
move	O
,	O
which	O
would	O
be	O
very	O
time-consuming	O
.	O
thus	O
,	O
for	O
such	O
problems	O
we	O
have	O
to	O
ﬁnd	O
an	O
alterna-	O
tive	O
to	O
the	O
open-loop	O
policy	B
,	O
which	O
incorpo-	O
rates	O
the	O
current	O
situations	O
into	O
the	O
action	O
plan	O
:	O
a	O
closed	B
loop	I
policy	O
is	O
a	O
closed	B
loop	I
,	O
a	O
function	B
π	O
:	O
si	O
→	O
ai	O
with	O
ai	O
=	O
ai	O
(	O
si	O
)	O
,	O
in	O
a	O
manner	O
of	O
speaking	O
.	O
here	O
,	O
the	O
envi-	O
ronment	O
inﬂuences	O
our	O
action	O
or	O
the	O
agent	B
responds	O
to	O
the	O
input	O
of	O
the	O
environment	B
,	O
respectively	O
,	O
as	O
already	O
illustrated	O
in	O
ﬁg	O
.	O
c.2	O
.	O
a	O
closed-loop	O
policy	B
,	O
so	O
to	O
speak	O
,	O
is	O
a	O
reactive	O
plan	O
to	O
map	O
current	O
situations	O
to	O
actions	O
to	O
be	O
performed	O
.	O
in	O
the	O
gridworld	B
:	O
a	O
closed-loop	O
policy	B
would	O
be	O
responsive	O
to	O
the	O
current	O
posi-	O
tion	O
and	O
choose	O
the	O
direction	O
according	O
to	O
the	O
action	O
.	O
in	O
particular	O
,	O
when	O
an	O
obsta-	O
cle	O
appears	O
dynamically	O
,	O
such	O
a	O
policy	B
is	O
the	O
better	O
choice	O
.	O
when	O
selecting	O
the	O
actions	O
to	O
be	O
per-	O
formed	O
,	O
again	O
two	O
basic	O
strategies	O
can	O
be	O
examined	O
.	O
c.1.5.1	O
exploitation	O
vs.	O
exploration	O
as	O
in	O
real	O
life	O
,	O
during	O
reinforcement	O
learn-	O
ing	O
often	O
the	O
question	O
arises	O
whether	O
the	O
exisiting	O
knowledge	O
is	O
only	O
willfully	O
ex-	O
ploited	O
or	O
new	O
ways	O
are	O
also	O
explored	O
.	O
initially	O
,	O
we	O
want	O
to	O
discuss	O
the	O
two	O
ex-	O
tremes	O
:	O
a	O
greedy	B
policy	O
always	O
chooses	O
the	O
way	O
of	O
the	O
highest	O
reward	B
that	O
can	O
be	O
deter-	O
mined	O
in	O
advance	O
,	O
i.e	O
.	O
the	O
way	O
of	O
the	O
high-	O
est	O
known	O
reward	B
.	O
this	O
policy	B
represents	O
the	O
exploitation	B
approach	I
and	O
is	O
very	O
promising	O
when	O
the	O
used	O
system	O
is	O
already	O
known	O
.	O
in	O
contrast	O
to	O
the	O
exploitation	B
approach	I
it	O
is	O
the	O
aim	O
of	O
the	O
exploration	B
approach	I
to	O
explore	O
a	O
system	O
as	O
detailed	O
as	O
possible	O
so	O
that	O
also	O
such	O
paths	O
leading	O
to	O
the	O
tar-	O
get	O
can	O
be	O
found	O
which	O
may	O
be	O
not	O
very	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
197	O
research	O
or	O
safety	O
?	O
appendix	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
dkriesel.com	O
promising	O
at	O
ﬁrst	O
glance	O
but	O
are	O
in	O
fact	O
very	O
successful	O
.	O
let	O
us	O
assume	O
that	O
we	O
are	O
looking	O
for	O
the	O
way	O
to	O
a	O
restaurant	O
,	O
a	O
safe	O
policy	B
would	O
be	O
to	O
always	O
take	O
the	O
way	O
we	O
already	O
know	O
,	O
not	O
matter	O
how	O
unoptimal	O
and	O
long	O
it	O
may	O
be	O
,	O
and	O
not	O
to	O
try	O
to	O
explore	O
bet-	O
ter	O
ways	O
.	O
another	O
approach	O
would	O
be	O
to	O
explore	O
shorter	O
ways	O
every	O
now	O
and	O
then	O
,	O
even	O
at	O
the	O
risk	O
of	O
taking	O
a	O
long	O
time	O
and	O
being	O
unsuccessful	O
,	O
and	O
therefore	O
ﬁnally	O
having	O
to	O
take	O
the	O
original	O
way	O
and	O
arrive	O
too	O
late	O
at	O
the	O
restaurant	O
.	O
in	O
reality	O
,	O
often	O
a	O
combination	O
of	O
both	O
methods	O
is	O
applied	O
:	O
in	O
the	O
beginning	O
of	O
the	O
learning	B
process	O
it	O
is	O
researched	O
with	O
a	O
higher	O
probability	O
while	O
at	O
the	O
end	O
more	O
existing	O
knowledge	O
is	O
exploited	O
.	O
here	O
,	O
a	O
static	O
probability	O
distribution	O
is	O
also	O
pos-	O
sible	O
and	O
often	O
applied	O
.	O
in	O
the	O
gridworld	B
:	O
for	O
ﬁnding	O
the	O
way	O
in	O
the	O
gridworld	B
,	O
the	O
restaurant	O
example	O
ap-	O
plies	O
equally	O
.	O
c.2	O
learning	B
process	O
let	O
us	O
again	O
take	O
a	O
look	O
at	O
daily	O
life	O
.	O
ac-	O
tions	O
can	O
lead	O
us	O
from	O
one	O
situation	B
into	O
diﬀerent	O
subsituations	O
,	O
from	O
each	O
subsit-	O
uation	O
into	O
further	O
sub-subsituations	O
.	O
in	O
a	O
sense	O
,	O
we	O
get	O
a	O
situation	B
tree	I
where	O
links	O
between	O
the	O
nodes	O
must	O
be	O
consid-	O
ered	O
(	O
often	O
there	O
are	O
several	O
ways	O
to	O
reach	O
a	O
situation	B
–	O
so	O
the	O
tree	O
could	O
more	O
accu-	O
rately	O
be	O
referred	O
to	O
as	O
a	O
situation	B
graph	O
)	O
.	O
he	O
leaves	O
of	O
such	O
a	O
tree	O
are	O
the	O
end	O
situ-	O
ations	O
of	O
the	O
system	O
.	O
the	O
exploration	O
ap-	O
proach	O
would	O
search	O
the	O
tree	O
as	O
thoroughly	O
as	O
possible	O
and	O
become	O
acquainted	O
with	O
all	O
leaves	O
.	O
the	O
exploitation	B
approach	I
would	O
unerringly	O
go	O
to	O
the	O
best	O
known	O
leave	O
.	O
analogous	O
to	O
the	O
situation	B
tree	I
,	O
we	O
also	O
can	O
create	O
an	O
action	O
tree	O
.	O
here	O
,	O
the	O
re-	O
wards	O
for	O
the	O
actions	O
are	O
within	O
the	O
nodes	O
.	O
now	O
we	O
have	O
to	O
adapt	O
from	O
daily	O
life	O
how	O
we	O
learn	O
exactly	O
.	O
c.2.1	O
rewarding	O
strategies	O
interesting	O
and	O
very	O
important	O
is	O
the	O
ques-	O
tion	O
for	O
what	O
a	O
reward	B
and	O
what	O
kind	O
of	O
reward	B
is	O
awarded	O
since	O
the	O
design	O
of	O
the	O
reward	B
signiﬁcantly	O
controls	O
system	O
behav-	O
ior	O
.	O
as	O
we	O
have	O
seen	O
above	O
,	O
there	O
gener-	O
ally	O
are	O
(	O
again	O
as	O
in	O
daily	O
life	O
)	O
various	O
ac-	O
tions	O
that	O
can	O
be	O
performed	O
in	O
any	O
situa-	O
tion	O
.	O
there	O
are	O
diﬀerent	O
strategies	O
to	O
eval-	O
uate	O
the	O
selected	O
situations	O
and	O
to	O
learn	O
which	O
series	O
of	O
actions	O
would	O
lead	O
to	O
the	O
target	B
.	O
first	O
of	O
all	O
,	O
this	O
principle	O
should	O
be	O
explained	O
in	O
the	O
following	O
.	O
we	O
now	O
want	O
to	O
indicate	O
some	O
extreme	O
cases	O
as	O
design	O
examples	O
for	O
the	O
reward	B
:	O
a	O
rewarding	O
similar	O
to	O
the	O
rewarding	O
in	O
a	O
chess	O
game	O
is	O
referred	O
to	O
as	O
pure	B
delayed	I
reward	O
:	O
we	O
only	O
receive	O
the	O
reward	B
at	O
the	O
end	O
of	O
and	O
not	O
during	O
the	O
game	O
.	O
this	O
method	O
is	O
always	O
advantageous	O
when	O
we	O
ﬁnally	O
can	O
say	O
whether	O
we	O
were	O
succesful	O
or	O
not	O
,	O
but	O
the	O
interim	O
steps	O
do	O
not	O
allow	O
198	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
c.2	O
learning	B
process	O
an	O
estimation	O
of	O
our	O
situation	B
.	O
if	O
we	O
win	O
,	O
then	O
rt	O
=	O
0	O
∀t	O
<	O
τ	O
(	O
c.10	O
)	O
as	O
well	O
as	O
rτ	O
=	O
1.	O
if	O
we	O
lose	O
,	O
then	O
rτ	O
=	O
−1	O
.	O
with	O
this	O
rewarding	O
strategy	O
a	O
reward	B
is	O
only	O
returned	O
by	O
the	O
leaves	O
of	O
the	O
situation	B
tree	I
.	O
pure	B
negative	I
reward	O
:	O
here	O
,	O
rt	O
=	O
−1	O
∀t	O
<	O
τ	O
.	O
(	O
c.11	O
)	O
this	O
system	O
ﬁnds	O
the	O
most	O
rapid	O
way	O
to	O
reach	O
the	O
target	B
because	O
this	O
way	O
is	O
auto-	O
matically	O
the	O
most	O
favorable	O
one	O
in	O
respect	O
of	O
the	O
reward	B
.	O
the	O
agent	B
receives	O
punish-	O
ment	O
for	O
anything	O
it	O
does	O
–	O
even	O
if	O
it	O
does	O
nothing	O
.	O
as	O
a	O
result	O
it	O
is	O
the	O
most	O
inex-	O
pensive	O
method	O
for	O
the	O
agent	B
to	O
reach	O
the	O
target	B
fast	O
.	O
another	O
strategy	O
is	O
the	O
avoidance	O
strat-	O
egy	O
:	O
harmful	O
situations	O
are	O
avoided	O
.	O
here	O
,	O
rt	O
∈	O
{	O
0	O
,	O
−1	O
}	O
,	O
(	O
c.12	O
)	O
most	O
situations	O
do	O
not	O
receive	O
any	O
reward	B
,	O
only	O
a	O
few	O
of	O
them	O
receive	O
a	O
negative	O
re-	O
ward	O
.	O
the	O
agent	B
agent	O
will	O
avoid	O
getting	O
too	O
close	O
to	O
such	O
negative	O
situations	O
warning	O
:	O
rewarding	O
strategies	O
can	O
have	O
unexpected	O
consequences	O
.	O
a	O
robot	O
that	O
is	O
told	O
``	O
have	O
it	O
your	O
own	O
way	O
but	O
if	O
you	O
touch	O
an	O
obstacle	O
you	O
will	O
be	O
punished	O
''	O
will	O
sim-	O
ply	O
stand	O
still	O
.	O
if	O
standing	O
still	O
is	O
also	O
pun-	O
ished	O
,	O
it	O
will	O
drive	O
in	O
small	O
circles	O
.	O
recon-	O
sidering	O
this	O
,	O
we	O
will	O
understand	O
that	O
this	O
behavior	O
optimally	O
fulﬁlls	O
the	O
return	B
of	O
the	O
robot	O
but	O
unfortunately	O
was	O
not	O
intended	O
to	O
do	O
so	O
.	O
furthermore	O
,	O
we	O
can	O
show	O
that	O
especially	O
small	O
tasks	O
can	O
be	O
solved	O
better	O
by	O
means	O
of	O
negative	O
rewards	O
while	O
positive	O
,	O
more	O
diﬀerentiated	O
rewards	O
are	O
useful	O
for	O
large	O
,	O
complex	O
tasks	O
.	O
for	O
our	O
gridworld	B
we	O
want	O
to	O
apply	O
the	O
pure	B
negative	I
reward	O
strategy	O
:	O
the	O
robot	O
shall	O
ﬁnd	O
the	O
exit	O
as	O
fast	O
as	O
possible	O
.	O
c.2.2	O
the	O
state-value	B
function	I
evaluation	O
unlike	O
our	O
agent	B
we	O
have	O
a	O
godlike	O
view	O
state	B
of	O
our	O
gridworld	B
so	O
that	O
we	O
can	O
swiftly	O
de-	O
termine	O
which	O
robot	O
starting	O
position	O
can	O
provide	O
which	O
optimal	O
return	O
.	O
in	O
ﬁgure	O
c.3	O
on	O
the	O
next	O
page	O
these	O
opti-	O
mal	O
returns	O
are	O
applied	O
per	O
ﬁeld	O
.	O
in	O
the	O
gridworld	B
:	O
the	O
state-value	B
function	I
for	O
our	O
gridworld	B
exactly	O
represents	O
such	O
a	O
function	B
per	O
situation	B
(	O
=	O
position	O
)	O
with	O
the	O
diﬀerence	O
being	O
that	O
here	O
the	O
function	B
is	O
unknown	O
and	O
has	O
to	O
be	O
learned	O
.	O
thus	O
,	O
we	O
can	O
see	O
that	O
it	O
would	O
be	O
more	O
practical	O
for	O
the	O
robot	O
to	O
be	O
capable	O
to	O
evaluate	O
the	O
current	O
and	O
future	O
situations	O
.	O
so	O
let	O
us	O
take	O
a	O
look	O
at	O
another	O
system	O
component	O
of	O
reinforcement	B
learning	I
:	O
the	O
state-value	B
function	I
v	O
(	O
s	O
)	O
,	O
which	O
with	O
regard	O
to	O
a	O
policy	B
π	O
is	O
often	O
called	O
vπ	O
(	O
s	O
)	O
.	O
because	O
whether	O
a	O
situation	B
is	O
bad	O
often	O
depends	O
on	O
the	O
general	O
behavior	O
π	O
of	O
the	O
agent	B
.	O
a	O
situation	B
being	O
bad	O
under	O
a	O
policy	B
that	O
is	O
searching	O
risks	O
and	O
checking	O
out	O
limits	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
199	O
appendix	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
dkriesel.com	O
-6	O
-7	O
-6	O
-7	O
-8	O
-9	O
-10	O
-6	O
-7	O
-8	O
-9	O
-10	O
-11	O
-10	O
-5	O
-5	O
-6	O
-7	O
-8	O
-9	O
-5	O
-9	O
-10	O
-11	O
-10	O
-9	O
-4	O
-4	O
-5	O
-6	O
-7	O
-8	O
-3	O
-3	O
-7	O
-4	O
-3	O
-10	O
-11	O
-10	O
-9	O
-8	O
-7	O
-2	O
-1	O
-2	O
-3	O
-4	O
-5	O
-6	O
-2	O
-1	O
-2	O
-3	O
-4	O
-5	O
-6	O
figure	O
c.3	O
:	O
representation	O
of	O
each	O
optimal	O
re-	O
turn	O
per	O
ﬁeld	O
in	O
our	O
gridworld	B
by	O
means	O
of	O
pure	B
negative	I
reward	O
awarding	O
,	O
at	O
the	O
top	O
with	O
an	O
open	O
and	O
at	O
the	O
bottom	O
with	O
a	O
closed	O
door	O
.	O
would	O
be	O
,	O
for	O
instance	O
,	O
if	O
an	O
agent	B
on	O
a	O
bi-	O
cycle	O
turns	O
a	O
corner	O
and	O
the	O
front	O
wheel	O
begins	O
to	O
slide	O
out	O
.	O
and	O
due	O
to	O
its	O
dare-	O
devil	O
policy	B
the	O
agent	B
would	O
not	O
brake	O
in	O
this	O
situation	B
.	O
with	O
a	O
risk-aware	O
policy	B
the	O
same	O
situations	O
would	O
look	O
much	O
bet-	O
ter	O
,	O
thus	O
it	O
would	O
be	O
evaluated	O
higher	O
by	O
a	O
good	O
state-value	B
function	I
vπ	O
(	O
s	O
)	O
simply	O
returns	O
the	O
value	O
the	O
current	O
situation	B
s	O
has	O
for	O
the	O
agent	B
under	O
policy	B
π.	O
abstractly	O
speaking	O
,	O
according	O
to	O
the	O
above	O
deﬁnitions	O
,	O
the	O
value	O
of	O
the	O
state-	O
value	O
function	B
corresponds	O
to	O
the	O
return	B
rt	O
(	O
the	O
expected	O
value	O
)	O
of	O
a	O
situation	B
st.	O
vπ	O
(	O
s	O
)	O
(	O
cid:73	O
)	O
(	O
cid:74	O
)	O
v	O
∗	O
π	O
(	O
s	O
)	O
eπ	O
denotes	O
the	O
set	O
of	O
the	O
expected	O
returns	O
under	O
π	O
and	O
the	O
current	O
situation	B
st.	O
vπ	O
(	O
s	O
)	O
=	O
eπ	O
{	O
rt|s	O
=	O
st	O
}	O
deﬁnition	O
c.9	O
(	O
state-value	B
function	I
)	O
.	O
the	O
state-value	B
function	I
vπ	O
(	O
s	O
)	O
has	O
the	O
task	O
of	O
determining	O
the	O
value	O
of	O
situations	O
under	O
a	O
policy	B
,	O
i.e	O
.	O
to	O
answer	O
the	O
agent	B
’	O
s	O
question	O
of	O
whether	O
a	O
situation	B
s	O
is	O
good	O
or	O
bad	O
or	O
how	O
good	O
or	O
bad	O
it	O
is	O
.	O
for	O
this	O
purpose	O
it	O
returns	O
the	O
expectation	O
of	O
the	O
return	B
under	O
the	O
situation	B
:	O
vπ	O
(	O
s	O
)	O
=	O
eπ	O
{	O
rt|s	O
=	O
st	O
}	O
(	O
c.13	O
)	O
the	O
optimal	O
state-value	O
function	B
is	O
called	O
v	O
∗	O
π	O
(	O
s	O
)	O
.	O
unfortunaely	O
,	O
unlike	O
us	O
our	O
robot	O
does	O
not	O
have	O
a	O
godlike	O
view	O
of	O
its	O
environment	B
.	O
it	O
does	O
not	O
have	O
a	O
table	O
with	O
optimal	O
returns	O
like	O
the	O
one	O
shown	O
above	O
to	O
orient	O
itself	O
.	O
the	O
aim	O
of	O
reinforcement	B
learning	I
is	O
that	O
the	O
robot	O
generates	O
its	O
state-value	O
func-	O
tion	O
bit	O
by	O
bit	O
on	O
the	O
basis	B
of	O
the	O
returns	O
of	O
many	O
trials	O
and	O
approximates	O
the	O
optimal	O
state-value	O
function	B
v	O
∗	O
(	O
if	O
there	O
is	O
one	O
)	O
.	O
in	O
this	O
context	O
i	O
want	O
to	O
introduce	O
two	O
terms	O
closely	O
related	O
to	O
the	O
cycle	O
between	O
state-value	B
function	I
and	O
policy	B
:	O
c.2.2.1	O
policy	B
evaluation	O
policy	B
evaluation	O
is	O
the	O
approach	O
to	O
try	O
a	O
policy	B
a	O
few	O
times	O
,	O
to	O
provide	O
many	O
re-	O
wards	O
that	O
way	O
and	O
to	O
gradually	O
accumu-	O
late	O
a	O
state-value	B
function	I
by	O
means	O
of	O
these	O
rewards	O
.	O
200	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
c.2	O
learning	B
process	O
v	O
v	O
∗	O
π	O
π∗	O
figure	O
c.4	O
:	O
the	O
cycle	O
of	O
reinforcement	B
learning	I
which	O
ideally	O
leads	O
to	O
optimal	O
π∗	O
and	O
v	O
∗	O
.	O
c.2.2.2	O
policy	B
improvement	O
policy	B
improvement	O
means	O
to	O
improve	O
a	O
policy	B
itself	O
,	O
i.e	O
.	O
to	O
turn	O
it	O
into	O
a	O
new	O
and	O
better	O
one	O
.	O
in	O
order	O
to	O
improve	O
the	O
policy	B
we	O
have	O
to	O
aim	O
at	O
the	O
return	B
ﬁnally	O
having	O
a	O
larger	O
value	O
than	O
before	O
,	O
i.e	O
.	O
until	O
we	O
have	O
found	O
a	O
shorter	O
way	O
to	O
the	O
restaurant	O
and	O
have	O
walked	O
it	O
successfully	O
the	O
principle	O
of	O
reinforcement	B
learning	I
is	O
to	O
realize	O
an	O
interaction	O
.	O
it	O
is	O
tried	O
to	O
eval-	O
uate	O
how	O
good	O
a	O
policy	B
is	O
in	O
individual	O
situations	O
.	O
the	O
changed	O
state-value	O
func-	O
tion	O
provides	O
information	O
about	O
the	O
sys-	O
tem	O
with	O
which	O
we	O
again	O
improve	O
our	O
pol-	O
icy	O
.	O
these	O
two	O
values	O
lift	O
each	O
other	O
,	O
which	O
can	O
mathematically	O
be	O
proved	O
,	O
so	O
that	O
the	O
ﬁnal	O
result	O
is	O
an	O
optimal	O
policy	O
π∗	O
and	O
an	O
optimal	O
state-value	O
function	B
v	O
∗	O
(	O
ﬁg	O
.	O
c.4	O
)	O
.	O
this	O
cycle	O
sounds	O
simple	O
but	O
is	O
very	O
time-	O
consuming	O
.	O
at	O
ﬁrst	O
,	O
let	O
us	O
regard	O
a	O
simple	O
,	O
random	O
pol-	O
icy	O
by	O
which	O
our	O
robot	O
could	O
slowly	O
fulﬁll	O
and	O
improve	O
its	O
state-value	B
function	I
with-	O
out	O
any	O
previous	O
knowledge	O
.	O
c.2.3	O
monte	O
carlo	O
method	O
the	O
easiest	O
approach	O
to	O
accumulate	O
a	O
state-value	B
function	I
is	O
mere	O
trial	O
and	O
er-	O
ror	O
.	O
thus	O
,	O
we	O
select	O
a	O
randomly	O
behaving	O
policy	B
which	O
does	O
not	O
consider	O
the	O
accumu-	O
lated	O
state-value	B
function	I
for	O
its	O
random	O
decisions	O
.	O
it	O
can	O
be	O
proved	O
that	O
at	O
some	O
point	O
we	O
will	O
ﬁnd	O
the	O
exit	O
of	O
our	O
gridworld	B
by	O
chance	O
.	O
inspired	O
by	O
random-based	O
games	O
of	O
chance	O
this	O
approach	O
is	O
called	O
monte	O
carlo	O
method	O
.	O
if	O
we	O
additionally	O
assume	O
a	O
pure	B
negative	I
reward	O
,	O
it	O
is	O
obvious	O
that	O
we	O
can	O
receive	O
an	O
optimum	O
value	O
of	O
−6	O
for	O
our	O
starting	O
ﬁeld	O
in	O
the	O
state-value	B
function	I
.	O
depend-	O
ing	O
on	O
the	O
random	O
way	O
the	O
random	O
policy	B
takes	O
values	O
other	O
(	O
smaller	O
)	O
than	O
−6	O
can	O
occur	O
for	O
the	O
starting	O
ﬁeld	O
.	O
intuitively	O
,	O
we	O
want	O
to	O
memorize	O
only	O
the	O
better	O
value	O
for	O
one	O
state	B
(	O
i.e	O
.	O
one	O
ﬁeld	O
)	O
.	O
but	O
here	O
caution	O
is	O
advised	O
:	O
in	O
this	O
way	O
,	O
the	O
learning	B
proce-	O
dure	O
would	O
work	O
only	O
with	O
deterministic	O
systems	O
.	O
our	O
door	O
,	O
which	O
can	O
be	O
open	O
or	O
closed	O
during	O
a	O
cycle	O
,	O
would	O
produce	O
oscil-	O
lations	O
for	O
all	O
ﬁelds	O
and	O
such	O
oscillations	O
would	O
inﬂuence	O
their	O
shortest	O
way	O
to	O
the	O
target	B
.	O
with	O
the	O
monte	O
carlo	O
method	O
we	O
prefer	O
to	O
use	O
the	O
learning	B
rule2	O
v	O
(	O
st	O
)	O
new	O
=	O
v	O
(	O
st	O
)	O
alt	O
+	O
α	O
(	O
rt	O
−	O
v	O
(	O
st	O
)	O
alt	O
)	O
,	O
in	O
which	O
the	O
update	O
of	O
the	O
state-value	O
func-	O
tion	O
is	O
obviously	O
inﬂuenced	O
by	O
both	O
the	O
2	O
the	O
learning	B
rule	O
is	O
,	O
among	O
others	O
,	O
derived	O
by	O
means	O
of	O
the	O
bellman	O
equation	O
,	O
but	O
this	O
deriva-	O
tion	O
is	O
not	O
discussed	O
in	O
this	O
chapter	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
201	O
)	O
)	O
	O
	O
i	O
i	O
	O
	O
appendix	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
dkriesel.com	O
α	O
(	O
cid:73	O
)	O
old	O
state	B
value	O
and	O
the	O
received	O
return	B
(	O
α	O
is	O
the	O
learning	B
rate	I
)	O
.	O
thus	O
,	O
the	O
agent	B
gets	O
some	O
kind	O
of	O
memory	O
,	O
new	O
ﬁndings	O
always	O
change	O
the	O
situation	B
value	O
just	O
a	O
little	O
bit	O
.	O
an	O
exemplary	O
learning	B
step	O
is	O
shown	O
in	O
ﬁg	O
.	O
c.5	O
.	O
in	O
this	O
example	O
,	O
the	O
computation	O
of	O
the	O
state	B
value	O
was	O
applied	O
for	O
only	O
one	O
single	O
state	O
(	O
our	O
initial	O
state	B
)	O
.	O
it	O
should	O
be	O
ob-	O
vious	O
that	O
it	O
is	O
possible	O
(	O
and	O
often	O
done	O
)	O
to	O
train	O
the	O
values	O
for	O
the	O
states	O
visited	O
in-	O
between	O
(	O
in	O
case	O
of	O
the	O
gridworld	B
our	O
ways	O
to	O
the	O
target	B
)	O
at	O
the	O
same	O
time	O
.	O
the	O
result	O
of	O
such	O
a	O
calculation	O
related	O
to	O
our	O
exam-	O
ple	O
is	O
illustrated	O
in	O
ﬁg	O
.	O
c.6	O
on	O
the	O
facing	O
page	O
.	O
the	O
monte	O
carlo	O
method	O
seems	O
to	O
be	O
suboptimal	O
and	O
usually	O
it	O
is	O
signiﬁcantly	O
slower	O
than	O
the	O
following	O
methods	O
of	O
re-	O
inforcement	O
learning	B
.	O
but	O
this	O
method	O
is	O
the	O
only	O
one	O
for	O
which	O
it	O
can	O
be	O
mathemat-	O
ically	O
proved	O
that	O
it	O
works	O
and	O
therefore	O
it	O
is	O
very	O
useful	O
for	O
theoretical	O
considera-	O
tions	O
.	O
deﬁnition	O
c.10	O
(	O
monte	O
carlo	O
learning	B
)	O
.	O
actions	O
are	O
randomly	O
performed	O
regard-	O
less	O
of	O
the	O
state-value	B
function	I
and	O
in	O
the	O
long	O
term	O
an	O
expressive	O
state-value	O
func-	O
tion	O
is	O
accumulated	O
by	O
means	O
of	O
the	O
fol-	O
lowing	O
learning	B
rule	O
.	O
v	O
(	O
st	O
)	O
new	O
=	O
v	O
(	O
st	O
)	O
alt	O
+	O
α	O
(	O
rt	O
−	O
v	O
(	O
st	O
)	O
alt	O
)	O
,	O
c.2.4	O
temporal	O
diﬀerence	O
learning	B
most	O
of	O
the	O
learning	B
is	O
the	O
result	O
of	O
ex-	O
periences	O
;	O
e.g	O
.	O
walking	O
or	O
riding	O
a	O
bicycle	O
-6	O
-5	O
-4	O
-3	O
-1	O
-2	O
-14	O
-13	O
-12	O
-11	O
-10	O
-9	O
-8	O
-7	O
-1	O
-2	O
-3	O
-4	O
-5	O
-6	O
-10	O
figure	O
c.5	O
:	O
application	O
of	O
the	O
monte	O
carlo	O
learning	B
rule	O
with	O
a	O
learning	B
rate	I
of	O
α	O
=	O
0.5.	O
top	O
:	O
two	O
exemplary	O
ways	O
the	O
agent	B
randomly	O
selects	O
are	O
applied	O
(	O
one	O
with	O
an	O
open	O
and	O
one	O
with	O
a	O
closed	O
door	O
)	O
.	O
bottom	O
:	O
the	O
result	O
of	O
the	O
learning	B
rule	O
for	O
the	O
value	O
of	O
the	O
initial	O
state	B
con-	O
sidering	O
both	O
ways	O
.	O
due	O
to	O
the	O
fact	O
that	O
in	O
the	O
course	O
of	O
time	O
many	O
diﬀerent	O
ways	O
are	O
walked	O
given	O
a	O
random	O
policy	B
,	O
a	O
very	O
expressive	O
state-	O
value	O
function	B
is	O
obtained	O
.	O
202	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
c.2	O
learning	B
process	O
-10	O
-9	O
-8	O
-11	O
-10	O
-9	O
-8	O
-3	O
-7	O
-1	O
-2	O
-3	O
-4	O
-5	O
-6	O
figure	O
c.6	O
:	O
extension	O
of	O
the	O
learning	B
example	O
in	O
ﬁg	O
.	O
c.5	O
in	O
which	O
the	O
returns	O
for	O
intermedi-	O
ate	O
states	O
are	O
also	O
used	O
to	O
accumulate	O
the	O
state-	O
value	O
function	B
.	O
here	O
,	O
the	O
low	O
value	O
on	O
the	O
door	O
ﬁeld	O
can	O
be	O
seen	O
very	O
well	O
:	O
if	O
this	O
state	B
is	O
possi-	O
ble	O
,	O
it	O
must	O
be	O
very	O
positive	O
.	O
if	O
the	O
door	O
is	O
closed	O
,	O
this	O
state	B
is	O
impossible	O
.	O
evaluation	B
π	O
q	O
policy	B
improvement	O
figure	O
c.7	O
:	O
we	O
try	O
diﬀerent	O
actions	O
within	O
the	O
environment	B
and	O
as	O
a	O
result	O
we	O
learn	O
and	O
improve	O
the	O
policy	B
.	O
without	O
getting	O
injured	O
(	O
or	O
not	O
)	O
,	O
even	O
men-	O
tal	O
skills	O
like	O
mathematical	O
problem	O
solv-	O
ing	O
beneﬁt	O
a	O
lot	O
from	O
experience	O
and	O
sim-	O
ple	O
trial	O
and	O
error	O
.	O
thus	O
,	O
we	O
initialize	O
our	O
policy	B
with	O
arbitrary	O
values	O
–	O
we	O
try	O
,	O
learn	O
and	O
improve	O
the	O
policy	B
due	O
to	O
experience	O
(	O
ﬁg	O
.	O
c.7	O
)	O
.	O
in	O
contrast	O
to	O
the	O
monte	O
carlo	O
method	O
we	O
want	O
to	O
do	O
this	O
in	O
a	O
more	O
di-	O
rected	O
manner	O
.	O
just	O
as	O
we	O
learn	O
from	O
experience	O
to	O
re-	O
act	O
on	O
diﬀerent	O
situations	O
in	O
diﬀerent	O
ways	O
the	O
temporal	O
diﬀerence	O
learning	B
(	O
abbre-	O
viated	O
:	O
td	O
learning	B
)	O
,	O
does	O
the	O
same	O
by	O
training	O
vπ	O
(	O
s	O
)	O
(	O
i.e	O
.	O
the	O
agent	B
learns	O
to	O
esti-	O
mate	O
which	O
situations	O
are	O
worth	O
a	O
lot	O
and	O
which	O
are	O
not	O
)	O
.	O
again	O
the	O
current	O
situa-	O
tion	O
is	O
identiﬁed	O
with	O
st	O
,	O
the	O
following	O
sit-	O
uations	O
with	O
st+1	O
and	O
so	O
on	O
.	O
thus	O
,	O
the	O
learning	B
formula	O
for	O
the	O
state-value	O
func-	O
tion	O
vπ	O
(	O
st	O
)	O
is	O
v	O
(	O
st	O
)	O
new	O
=v	O
(	O
st	O
)	O
|	O
}	O
+	O
α	O
(	O
rt+1	O
+	O
γv	O
(	O
st+1	O
)	O
−	O
v	O
(	O
st	O
)	O
)	O
{	O
z	O
change	O
of	O
previous	O
value	O
we	O
can	O
see	O
that	O
the	O
change	O
in	O
value	O
of	O
the	O
current	O
situation	B
st	O
,	O
which	O
is	O
proportional	O
to	O
the	O
learning	B
rate	I
α	O
,	O
is	O
inﬂuenced	O
by	O
.	O
the	O
received	O
reward	B
rt+1	O
,	O
.	O
the	O
previous	O
return	B
weighted	O
with	O
a	O
factor	O
γ	O
of	O
the	O
following	O
situation	B
v	O
(	O
st+1	O
)	O
,	O
.	O
the	O
previous	O
value	O
of	O
the	O
situation	B
v	O
(	O
st	O
)	O
.	O
unlike	O
deﬁnition	O
c.11	O
(	O
temporal	O
diﬀerence	O
learning	B
)	O
.	O
the	O
monte	O
carlo	O
method	O
,	O
td	O
learning	B
looks	O
ahead	O
by	O
re-	O
garding	O
the	O
following	O
situation	B
st+1	O
.	O
thus	O
,	O
the	O
learning	B
rule	O
is	O
given	O
by	O
v	O
(	O
st	O
)	O
new	O
=v	O
(	O
st	O
)	O
(	O
c.14	O
)	O
|	O
}	O
+	O
α	O
(	O
rt+1	O
+	O
γv	O
(	O
st+1	O
)	O
−	O
v	O
(	O
st	O
)	O
)	O
.	O
{	O
z	O
change	O
of	O
previous	O
value	O
c.2.5	O
the	O
action-value	B
function	I
analogous	O
vπ	O
(	O
s	O
)	O
,	O
to	O
the	O
state-value	B
function	I
the	O
action-value	B
function	I
action	O
evaluation	B
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
203	O
!	O
!	O
a	O
a	O
appendix	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
dkriesel.com	O
0	O
×	O
+1	O
-1	O
c.2.6	O
q	O
learning	B
this	O
implies	O
qπ	O
(	O
s	O
,	O
a	O
)	O
as	O
learning	B
fomula	O
for	O
the	O
action-value	B
function	I
,	O
and	O
–	O
analo-	O
gously	O
to	O
td	O
learning	B
–	O
its	O
application	O
is	O
called	O
q	O
learning	B
:	O
figure	O
c.8	O
:	O
exemplary	O
values	O
of	O
an	O
action-	O
value	O
function	B
for	O
the	O
position	O
×	O
.	O
moving	O
right	O
,	O
one	O
remains	O
on	O
the	O
fastest	O
way	O
towards	O
the	O
tar-	O
get	O
,	O
moving	O
up	O
is	O
still	O
a	O
quite	O
fast	O
way	O
,	O
moving	O
down	O
is	O
not	O
a	O
good	O
way	O
at	O
all	O
(	O
provided	O
that	O
the	O
door	O
is	O
open	O
for	O
all	O
cases	O
)	O
.	O
qπ	O
(	O
s	O
,	O
a	O
)	O
is	O
another	O
system	O
component	O
of	O
qπ	O
(	O
s	O
,	O
a	O
)	O
(	O
cid:73	O
)	O
reinforcement	B
learning	I
,	O
which	O
evaluates	O
a	O
certain	O
action	O
a	O
under	O
a	O
certain	O
situation	B
s	O
and	O
the	O
policy	B
π.	O
in	O
the	O
gridworld	B
:	O
in	O
the	O
gridworld	B
,	O
the	O
action-value	B
function	I
tells	O
us	O
how	O
good	O
it	O
is	O
to	O
move	O
from	O
a	O
certain	O
ﬁeld	O
into	O
a	O
cer-	O
tain	O
direction	O
(	O
ﬁg	O
.	O
c.8	O
)	O
.	O
deﬁnition	O
c.12	O
(	O
action-value	B
function	I
)	O
.	O
like	O
the	O
state-value	B
function	I
,	O
the	O
action-	O
value	O
function	B
qπ	O
(	O
st	O
,	O
a	O
)	O
evaluates	O
certain	O
actions	O
on	O
the	O
basis	B
of	O
certain	O
situations	O
under	O
a	O
policy	B
.	O
the	O
optimal	O
action-value	O
function	B
is	O
called	O
q∗	O
π	O
(	O
st	O
,	O
a	O
)	O
.	O
π	O
(	O
s	O
,	O
a	O
)	O
(	O
cid:73	O
)	O
q∗	O
as	O
shown	O
in	O
ﬁg	O
.	O
c.9	O
,	O
the	O
actions	O
are	O
per-	O
formed	O
until	O
a	O
target	B
situation	O
(	O
here	O
re-	O
ferred	O
to	O
as	O
sτ	O
)	O
is	O
achieved	O
(	O
if	O
there	O
exists	O
a	O
target	B
situation	O
,	O
otherwise	O
the	O
actions	O
are	O
simply	O
performed	O
again	O
and	O
again	O
)	O
.	O
q	O
(	O
st	O
,	O
a	O
)	O
new	O
=q	O
(	O
st	O
,	O
a	O
)	O
+	O
α	O
(	O
rt+1	O
+	O
γ	O
max	O
q	O
(	O
st+1	O
,	O
a	O
)	O
−q	O
(	O
st	O
,	O
a	O
)	O
)	O
.	O
}	O
}	O
|	O
|	O
a	O
{	O
z	O
{	O
z	O
greedy	B
strategy	O
change	O
of	O
previous	O
value	O
again	O
we	O
break	O
down	O
the	O
change	O
of	O
the	O
current	O
action	O
value	O
(	O
proportional	O
to	O
the	O
learning	B
rate	I
α	O
)	O
under	O
the	O
current	O
situa-	O
tion	O
.	O
it	O
is	O
inﬂuenced	O
by	O
.	O
the	O
received	O
reward	B
rt+1	O
,	O
.	O
the	O
maximum	O
action	O
over	O
the	O
follow-	O
ing	O
actions	O
weighted	O
with	O
γ	O
(	O
here	O
,	O
a	O
greedy	B
strategy	O
is	O
applied	O
since	O
it	O
can	O
be	O
assumed	O
that	O
the	O
best	O
known	O
ac-	O
tion	O
is	O
selected	O
.	O
with	O
td	O
learning	B
,	O
on	O
the	O
other	O
hand	O
,	O
we	O
do	O
not	O
mind	O
to	O
always	O
get	O
into	O
the	O
best	O
known	O
next	O
situation	B
.	O
)	O
,	O
.	O
the	O
previous	O
value	O
of	O
the	O
action	O
under	O
our	O
situation	B
st	O
known	O
as	O
q	O
(	O
st	O
,	O
a	O
)	O
(	O
re-	O
member	O
that	O
this	O
is	O
also	O
weighted	O
by	O
means	O
of	O
α	O
)	O
.	O
usually	O
,	O
the	O
action-value	B
function	I
learns	O
considerably	O
faster	O
than	O
the	O
state-value	B
function	I
.	O
but	O
we	O
must	O
not	O
disregard	O
that	O
reinforcement	B
learning	I
is	O
generally	O
quite	O
slow	O
:	O
the	O
system	O
has	O
to	O
ﬁnd	O
out	O
itself	O
what	O
is	O
good	O
.	O
but	O
the	O
advantage	O
of	O
q	O
204	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
c.3	O
example	O
applications	O
gfed	O
@	O
abcs0	O
a0	O
r1	O
gfed	O
@	O
abcs1	O
direction	O
of	O
actions	O
···	O
gfed	O
@	O
abc	O
a1	O
aτ−2/	O
rτ−1	O
r2	O
direction	O
of	O
reward	B
sτ−1	O
onml	O
hijk	O
aτ−1	O
/	O
rτ	O
gfed	O
@	O
abcsτ	O
figure	O
c.9	O
:	O
actions	O
are	O
performed	O
until	O
the	O
desired	O
target	B
situation	O
is	O
achieved	O
.	O
attention	O
should	O
be	O
paid	O
to	O
numbering	O
:	O
rewards	O
are	O
numbered	O
beginning	O
with	O
1	O
,	O
actions	O
and	O
situations	O
beginning	O
with	O
0	O
(	O
this	O
has	O
simply	O
been	O
adopted	O
as	O
a	O
convention	O
)	O
.	O
q	O
(	O
st	O
,	O
a	O
)	O
new	O
=q	O
(	O
st	O
,	O
a	O
)	O
+	O
α	O
(	O
rt+1	O
+	O
γ	O
max	O
a	O
(	O
c.15	O
)	O
q	O
(	O
st+1	O
,	O
a	O
)	O
−	O
q	O
(	O
st	O
,	O
a	O
)	O
)	O
.	O
played	O
backgammon	O
knows	O
that	O
the	O
situ-	O
ation	O
space	O
is	O
huge	O
(	O
approx	O
.	O
1020	O
situa-	O
tions	O
)	O
.	O
as	O
a	O
result	O
,	O
the	O
state-value	O
func-	O
tions	O
can	O
not	O
be	O
computed	O
explicitly	O
(	O
par-	O
ticularly	O
in	O
the	O
late	O
eighties	O
when	O
td	O
gam-	O
mon	O
was	O
introduced	O
)	O
.	O
the	O
selected	O
re-	O
warding	O
strategy	O
was	O
the	O
pure	B
delayed	I
re-	O
ward	O
,	O
i.e	O
.	O
the	O
system	O
receives	O
the	O
reward	B
not	O
before	O
the	O
end	O
of	O
the	O
game	O
and	O
at	O
the	O
same	O
time	O
the	O
reward	B
is	O
the	O
return	B
.	O
then	O
the	O
system	O
was	O
allowed	O
to	O
practice	O
itself	O
(	O
initially	O
against	O
a	O
backgammon	O
program	O
,	O
then	O
against	O
an	O
entity	O
of	O
itself	O
)	O
.	O
the	O
result	O
was	O
that	O
it	O
achieved	O
the	O
highest	O
ranking	O
in	O
a	O
computer-backgammon	O
league	O
and	O
strik-	O
ingly	O
disproved	O
the	O
theory	O
that	O
a	O
computer	O
programm	O
is	O
not	O
capable	O
to	O
master	O
a	O
task	O
better	O
than	O
its	O
programmer	O
.	O
learning	B
is	O
:	O
π	O
can	O
be	O
initialized	O
arbitrar-	O
ily	O
,	O
and	O
by	O
means	O
of	O
q	O
learning	B
the	O
result	O
is	O
always	O
q∗	O
.	O
deﬁnition	O
c.13	O
(	O
q	O
learning	B
)	O
.	O
q	O
learn-	O
ing	O
trains	O
the	O
action-value	B
function	I
by	O
means	O
of	O
the	O
learning	B
rule	O
and	O
thus	O
ﬁnds	O
q∗	O
in	O
any	O
case	O
.	O
c.3	O
example	O
applications	O
c.3.1	O
td	O
gammon	O
c.3.2	O
the	O
car	O
in	O
the	O
pit	O
td	O
gammon	O
is	O
a	O
very	O
successful	O
backgammon	O
game	O
based	O
on	O
td	O
learn-	O
ing	O
invented	O
by	O
gerald	O
tesauro	O
.	O
the	O
situation	B
here	O
is	O
the	O
current	O
conﬁgura-	O
tion	O
of	O
the	O
board	O
.	O
anyone	O
who	O
has	O
ever	O
let	O
us	O
take	O
a	O
look	O
at	O
a	O
car	O
parking	O
on	O
a	O
one-dimensional	O
road	O
at	O
the	O
bottom	O
of	O
a	O
deep	O
pit	O
without	O
being	O
able	O
to	O
get	O
over	O
the	O
slope	O
on	O
both	O
sides	O
straight	O
away	O
by	O
means	O
of	O
its	O
engine	O
power	O
in	O
order	O
to	O
leave	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
205	O
/	O
/	O
(	O
(	O
/	O
/	O
k	O
k	O
/	O
k	O
k	O
/	O
k	O
k	O
l	O
l	O
h	O
h	O
appendix	O
c	O
excursus	O
:	O
reinforcement	B
learning	I
dkriesel.com	O
the	O
pit	O
.	O
trivially	O
,	O
the	O
executable	O
actions	O
here	O
are	O
the	O
possibilities	O
to	O
drive	O
forwards	O
and	O
backwards	O
.	O
the	O
intuitive	O
solution	O
we	O
think	O
of	O
immediately	O
is	O
to	O
move	O
backwards	O
,	O
to	O
gain	O
momentum	B
at	O
the	O
opposite	O
slope	O
and	O
oscillate	O
in	O
this	O
way	O
several	O
times	O
to	O
dash	O
out	O
of	O
the	O
pit	O
.	O
the	O
actions	O
of	O
a	O
reinforcement	B
learning	I
system	O
would	O
be	O
``	O
full	O
throttle	O
forward	O
''	O
,	O
''	O
full	O
reverse	O
''	O
and	O
``	O
doing	O
nothing	O
''	O
.	O
here	O
,	O
``	O
everything	O
costs	O
''	O
would	O
be	O
a	O
good	O
choice	O
for	O
awarding	O
the	O
reward	B
so	O
that	O
the	O
system	O
learns	O
fast	O
how	O
to	O
leave	O
the	O
pit	O
and	O
realizes	O
that	O
our	O
problem	O
can	O
not	O
be	O
solved	O
by	O
means	O
of	O
mere	O
forward	O
directed	O
engine	O
power	O
.	O
so	O
the	O
system	O
will	O
slowly	O
build	O
up	O
the	O
movement	O
.	O
the	O
policy	B
can	O
no	O
longer	O
be	O
stored	O
as	O
a	O
table	O
since	O
the	O
state	O
space	O
is	O
hard	O
to	O
dis-	O
cretize	O
.	O
as	O
policy	B
a	O
function	B
has	O
to	O
be	O
generated	O
.	O
c.3.3	O
the	O
pole	B
balancer	I
the	O
pole	B
balancer	I
was	O
developed	O
by	O
barto	O
,	O
sutton	O
and	O
anderson	O
.	O
let	O
be	O
given	O
a	O
situation	B
including	O
a	O
vehicle	O
that	O
is	O
capable	O
to	O
move	O
either	O
to	O
the	O
right	O
at	O
full	O
throttle	O
or	O
to	O
the	O
left	O
at	O
full	O
throt-	O
tle	O
(	O
bang	O
bang	O
control	O
)	O
.	O
only	O
these	O
two	O
actions	O
can	O
be	O
performed	O
,	O
standing	O
still	O
is	O
impossible	O
.	O
on	O
the	O
top	O
of	O
this	O
car	O
is	O
hinged	O
an	O
upright	O
pole	O
that	O
could	O
tip	O
over	O
to	O
both	O
sides	O
.	O
the	O
pole	O
is	O
built	O
in	O
such	O
a	O
way	O
that	O
it	O
always	O
tips	O
over	O
to	O
one	O
side	O
so	O
it	O
never	O
stands	O
still	O
(	O
let	O
us	O
assume	O
that	O
the	O
pole	O
is	O
rounded	O
at	O
the	O
lower	O
end	O
)	O
.	O
the	O
angle	O
of	O
the	O
pole	O
relative	O
to	O
the	O
verti-	O
cal	O
line	O
is	O
referred	O
to	O
as	O
α.	O
furthermore	O
,	O
the	O
vehicle	O
always	O
has	O
a	O
ﬁxed	O
position	O
x	O
an	O
our	O
one-dimensional	O
world	O
and	O
a	O
velocity	O
of	O
˙x	O
.	O
our	O
one-dimensional	O
world	O
is	O
lim-	O
ited	O
,	O
i.e	O
.	O
there	O
are	O
maximum	O
values	O
and	O
minimum	O
values	O
x	O
can	O
adopt	O
.	O
the	O
aim	O
of	O
our	O
system	O
is	O
to	O
learn	O
to	O
steer	O
the	O
car	O
in	O
such	O
a	O
way	O
that	O
it	O
can	O
balance	O
the	O
pole	O
,	O
to	O
prevent	O
the	O
pole	O
from	O
tipping	O
over	O
.	O
this	O
is	O
achieved	O
best	O
by	O
an	O
avoid-	O
ance	O
strategy	O
:	O
as	O
long	O
as	O
the	O
pole	O
is	O
bal-	O
anced	O
the	O
reward	B
is	O
0.	O
if	O
the	O
pole	O
tips	O
over	O
,	O
the	O
reward	B
is	O
-1.	O
interestingly	O
,	O
the	O
system	O
is	O
soon	O
capable	O
to	O
keep	O
the	O
pole	O
balanced	O
by	O
tilting	O
it	O
suf-	O
ﬁciently	O
fast	O
and	O
with	O
small	O
movements	O
.	O
at	O
this	O
the	O
system	O
mostly	O
is	O
in	O
the	O
cen-	O
ter	O
of	O
the	O
space	O
since	O
this	O
is	O
farthest	O
from	O
the	O
walls	O
which	O
it	O
understands	O
as	O
negative	O
(	O
if	O
it	O
touches	O
the	O
wall	O
,	O
the	O
pole	O
will	O
tip	O
over	O
)	O
.	O
c.3.3.1	O
swinging	O
up	O
an	O
inverted	O
pendulum	O
more	O
diﬃcult	O
for	O
the	O
system	O
is	O
the	O
fol-	O
lowing	O
initial	O
situation	B
:	O
the	O
pole	O
initially	O
hangs	O
down	O
,	O
has	O
to	O
be	O
swung	O
up	O
over	O
the	O
vehicle	O
and	O
ﬁnally	O
has	O
to	O
be	O
stabilized	O
.	O
in	O
the	O
literature	O
this	O
task	O
is	O
called	O
swing	B
up	I
an	I
inverted	I
pendulum	I
.	O
206	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
c.4	O
reinforcement	B
learning	I
in	O
connection	B
with	O
neural	O
networks	O
ment	O
learning	B
to	O
ﬁnd	O
a	O
strategy	O
in	O
order	O
to	O
exit	O
a	O
maze	O
as	O
fast	O
as	O
possible	O
.	O
.	O
what	O
could	O
an	O
appropriate	O
state-	O
value	O
function	B
look	O
like	O
?	O
.	O
how	O
would	O
you	O
generate	O
an	O
appropri-	O
ate	O
reward	B
?	O
assume	O
that	O
the	O
robot	O
is	O
capable	O
to	O
avoid	O
obstacles	O
and	O
at	O
any	O
time	O
knows	O
its	O
posi-	O
tion	O
(	O
x	O
,	O
y	O
)	O
and	O
orientation	O
φ.	O
exercise	O
20.	O
describe	O
the	O
function	B
of	O
the	O
two	O
components	O
ase	O
and	O
ace	O
as	O
they	O
have	O
been	O
proposed	O
by	O
barto	O
,	O
sut-	O
ton	O
and	O
anderson	O
to	O
control	O
the	O
pole	B
balancer	I
.	O
bibliography	O
:	O
[	O
bsa83	O
]	O
.	O
exercise	O
21.	O
indicate	O
several	O
``	O
classical	O
''	O
problems	O
of	O
informatics	O
which	O
could	O
be	O
solved	O
eﬃciently	O
by	O
means	O
of	O
reinforce-	O
ment	O
learning	B
.	O
please	O
give	O
reasons	O
for	O
your	O
answers	O
.	O
c.4	O
reinforcement	B
learning	I
in	O
connection	B
with	O
neural	O
networks	O
finally	O
,	O
the	O
reader	O
would	O
like	O
to	O
ask	O
why	O
a	O
text	O
on	O
``	O
neural	O
networks	O
''	O
includes	O
a	O
chap-	O
ter	O
about	O
reinforcement	B
learning	I
.	O
the	O
answer	O
is	O
very	O
simple	O
.	O
we	O
have	O
al-	O
ready	O
been	O
introduced	O
to	O
supervised	O
and	O
unsupervised	B
learning	I
procedures	O
.	O
al-	O
though	O
we	O
do	O
not	O
always	O
have	O
an	O
om-	O
niscient	O
teacher	O
who	O
makes	O
unsupervised	B
learning	I
possible	O
,	O
this	O
does	O
not	O
mean	O
that	O
we	O
do	O
not	O
receive	O
any	O
feedback	O
at	O
all	O
.	O
there	O
is	O
often	O
something	O
in	O
between	O
,	O
some	O
kind	O
of	O
criticism	O
or	O
school	O
mark	O
.	O
problems	O
like	O
this	O
can	O
be	O
solved	O
by	O
means	O
of	O
rein-	O
forcement	O
learning	B
.	O
but	O
not	O
every	O
problem	O
is	O
that	O
easily	O
solved	O
like	O
our	O
gridworld	B
:	O
in	O
our	O
backgammon	O
ex-	O
ample	O
we	O
have	O
approx	O
.	O
1020	O
situations	O
and	O
the	O
situation	B
tree	I
has	O
a	O
large	O
branching	O
fac-	O
tor	O
,	O
let	O
alone	O
other	O
games	O
.	O
here	O
,	O
the	O
tables	O
used	O
in	O
the	O
gridworld	B
can	O
no	O
longer	O
be	O
re-	O
alized	O
as	O
state-	O
and	O
action-value	O
functions	O
.	O
thus	O
,	O
we	O
have	O
to	O
ﬁnd	O
approximators	O
for	O
these	O
functions	O
.	O
and	O
which	O
learning	B
approximators	O
for	O
these	O
reinforcement	B
learning	I
components	O
come	O
immediately	O
into	O
our	O
mind	O
?	O
exactly	O
:	O
neural	O
networks	O
.	O
exercises	O
exercise	O
19.	O
a	O
robot	O
control	O
system	O
shall	O
be	O
persuaded	O
by	O
means	O
of	O
reinforce-	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
207	O
bibliography	O
[	O
and72	O
]	O
[	O
apz93	O
]	O
[	O
bsa83	O
]	O
[	O
cg87	O
]	O
[	O
cg88	O
]	O
[	O
cg90	O
]	O
[	O
ch67	O
]	O
[	O
cr00	O
]	O
[	O
cyb89	O
]	O
[	O
dhs01	O
]	O
james	O
a.	O
anderson	O
.	O
a	O
simple	O
neural	O
network	O
generating	O
an	O
interactive	O
memory	O
.	O
mathematical	O
biosciences	O
,	O
14:197–220	O
,	O
1972.	O
d.	O
anguita	O
,	O
g.	O
parodi	O
,	O
and	O
r.	O
zunino	O
.	O
speed	O
improvement	B
of	O
the	O
back-	O
propagation	O
on	O
current-generation	O
workstations	O
.	O
in	O
wcnn	O
’	O
93	O
,	O
portland	O
:	O
world	O
congress	O
on	O
neural	O
networks	O
,	O
july	O
11-15	O
,	O
1993	O
,	O
oregon	O
convention	O
center	O
,	O
portland	O
,	O
oregon	O
,	O
volume	O
1.	O
lawrence	O
erlbaum	O
,	O
1993.	O
a.	O
barto	O
,	O
r.	O
sutton	O
,	O
and	O
c.	O
anderson	O
.	O
neuron-like	O
adaptive	O
elements	O
that	O
can	O
solve	O
diﬃcult	O
learning	B
control	O
problems	O
.	O
ieee	O
transactions	O
on	O
systems	O
,	O
man	O
,	O
and	O
cybernetics	O
,	O
13	O
(	O
5	O
)	O
:834–846	O
,	O
september	O
1983.	O
g.	O
a.	O
carpenter	O
and	O
s.	O
grossberg	O
.	O
art2	O
:	O
self-organization	O
of	O
stable	O
cate-	O
gory	O
recognition	O
codes	O
for	O
analog	O
input	B
patterns	I
.	O
applied	O
optics	O
,	O
26:4919–	O
4930	O
,	O
1987.	O
m.a	O
.	O
cohen	O
and	O
s.	O
grossberg	O
.	O
absolute	O
stability	O
of	O
global	O
pattern	B
forma-	O
tion	O
and	O
parallel	O
memory	O
storage	O
by	O
competitive	O
neural	O
networks	O
.	O
com-	O
puter	O
society	O
press	O
technology	O
series	O
neural	O
networks	O
,	O
pages	O
70–81	O
,	O
1988.	O
g.	O
a.	O
carpenter	O
and	O
s.	O
grossberg	O
.	O
art	O
3	O
:	O
hierarchical	O
search	O
using	O
chemical	O
transmitters	O
in	O
self-organising	O
pattern	B
recognition	I
architectures	O
.	O
neural	O
networks	O
,	O
3	O
(	O
2	O
)	O
:129–152	O
,	O
1990.	O
t.	O
cover	O
and	O
p.	O
hart	O
.	O
nearest	O
neighbor	O
pattern	B
classiﬁcation	O
.	O
transactions	O
on	O
information	O
theory	O
,	O
13	O
(	O
1	O
)	O
:21–27	O
,	O
1967.	O
n.a	O
.	O
campbell	O
and	O
jb	O
reece	O
.	O
biologie	O
.	O
spektrum	O
.	O
akademischer	O
verlag	O
,	O
2000.	O
g.	O
cybenko	O
.	O
approximation	B
by	O
superpositions	O
of	O
a	O
sigmoidal	O
function	B
.	O
mathematics	O
of	O
control	O
,	O
signals	O
,	O
and	O
systems	O
(	O
mcss	O
)	O
,	O
2	O
(	O
4	O
)	O
:303–314	O
,	O
1989.	O
r.o	O
.	O
duda	O
,	O
p.e	O
.	O
hart	O
,	O
and	O
d.g	O
.	O
stork	O
.	O
pattern	B
classiﬁcation	O
.	O
wiley	O
new	O
york	O
,	O
2001.	O
ieee	O
209	O
bibliography	O
dkriesel.com	O
[	O
elm90	O
]	O
[	O
fah88	O
]	O
[	O
fmi83	O
]	O
[	O
fri94	O
]	O
jeﬀrey	O
l.	O
elman	O
.	O
finding	O
structure	O
in	O
time	O
.	O
cognitive	O
science	O
,	O
14	O
(	O
2	O
)	O
:179–	O
211	O
,	O
april	O
1990.	O
s.	O
e.	O
fahlman	O
.	O
an	O
empirical	O
sudy	O
of	O
learning	B
speed	O
in	O
back-propagation	O
networks	O
.	O
technical	O
report	O
cmu-cs-88-162	O
,	O
cmu	O
,	O
1988.	O
k.	O
fukushima	O
,	O
s.	O
miyake	O
,	O
and	O
t.	O
ito	O
.	O
neocognitron	O
:	O
a	O
neural	O
network	O
model	O
for	O
a	O
mechanism	O
of	O
visual	O
pattern	O
recognition	O
.	O
ieee	O
transactions	O
on	O
systems	O
,	O
man	O
,	O
and	O
cybernetics	O
,	O
13	O
(	O
5	O
)	O
:826–834	O
,	O
september/october	O
1983.	O
b.	O
fritzke	O
.	O
fast	O
learning	B
with	O
incremental	O
rbf	O
networks	O
.	O
neural	O
process-	O
ing	O
letters	O
,	O
1	O
(	O
1	O
)	O
:2–5	O
,	O
1994	O
.	O
[	O
gro76	O
]	O
[	O
gs06	O
]	O
[	O
heb49	O
]	O
[	O
gke01a	O
]	O
n.	O
goerke	O
,	O
f.	O
kintzler	O
,	O
and	O
r.	O
eckmiller	O
.	O
self	O
organized	O
classiﬁcation	O
of	O
chaotic	O
domains	O
from	O
a	O
nonlinearattractor	O
.	O
in	O
neural	O
networks	O
,	O
2001.	O
pro-	O
ceedings	O
.	O
ijcnn	O
’	O
01	O
.	O
international	O
joint	O
conference	O
on	O
,	O
volume	O
3	O
,	O
2001	O
.	O
[	O
gke01b	O
]	O
n.	O
goerke	O
,	O
f.	O
kintzler	O
,	O
and	O
r.	O
eckmiller	O
.	O
self	O
organized	O
partitioning	O
of	O
chaotic	O
attractors	O
for	O
control	O
.	O
lecture	O
notes	O
in	O
computer	O
science	O
,	O
pages	O
851–856	O
,	O
2001.	O
s.	O
grossberg	O
.	O
adaptive	O
pattern	O
classiﬁcation	O
and	O
universal	O
recoding	O
,	O
i	O
:	O
parallel	O
development	O
and	O
coding	O
of	O
neural	O
feature	O
detectors	O
.	O
biological	O
cybernetics	O
,	O
23:121–134	O
,	O
1976.	O
nils	O
goerke	O
and	O
alexandra	O
scherbart	O
.	O
classiﬁcation	O
using	O
multi-soms	O
and	O
multi-neural	B
gas	I
.	O
in	O
ijcnn	O
,	O
pages	O
3895–3902	O
,	O
2006.	O
donald	O
o.	O
hebb	O
.	O
the	O
organization	O
of	O
behavior	O
:	O
a	O
neuropsychological	O
theory	O
.	O
wiley	O
,	O
new	O
york	O
,	O
1949.	O
john	O
j.	O
hopﬁeld	O
.	O
neural	O
networks	O
and	O
physical	O
systems	O
with	O
emergent	O
col-	O
lective	O
computational	O
abilities	O
.	O
proc	O
.	O
of	O
the	O
national	O
academy	O
of	O
science	O
,	O
usa	O
,	O
79:2554–2558	O
,	O
1982.	O
jj	O
hopﬁeld	O
.	O
neurons	O
with	O
graded	O
response	O
have	O
collective	O
computational	O
properties	O
like	O
those	O
of	O
two-state	O
neurons	O
.	O
proceedings	O
of	O
the	O
national	O
academy	O
of	O
sciences	O
,	O
81	O
(	O
10	O
)	O
:3088–3092	O
,	O
1984.	O
jj	O
hopﬁeld	O
and	O
dw	O
tank	O
.	O
neural	O
computation	O
of	O
decisions	O
in	O
optimiza-	O
tion	O
problems	O
.	O
biological	O
cybernetics	O
,	O
52	O
(	O
3	O
)	O
:141–152	O
,	O
1985.	O
m.	O
i.	O
jordan	O
.	O
attractor	B
dynamics	O
and	O
parallelism	B
in	O
a	O
connectionist	O
se-	O
quential	O
machine	O
.	O
in	O
proceedings	O
of	O
the	O
eighth	O
conference	O
of	O
the	O
cognitive	O
science	O
society	O
,	O
pages	O
531–546	O
.	O
erlbaum	O
,	O
1986	O
.	O
[	O
hop82	O
]	O
[	O
hop84	O
]	O
[	O
ht85	O
]	O
[	O
jor86	O
]	O
210	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
bibliography	O
[	O
kau90	O
]	O
[	O
koh72	O
]	O
[	O
koh82	O
]	O
[	O
koh89	O
]	O
[	O
koh98	O
]	O
[	O
ksj00	O
]	O
l.	O
kaufman	O
.	O
finding	O
groups	O
in	O
data	O
:	O
an	O
introduction	O
to	O
cluster	B
analysis	I
.	O
in	O
finding	O
groups	O
in	O
data	O
:	O
an	O
introduction	O
to	O
cluster	B
analysis	I
.	O
wiley	O
,	O
new	O
york	O
,	O
1990.	O
t.	O
kohonen	O
.	O
correlation	O
matrix	O
memories	O
.	O
ieeetc	O
,	O
c-21:353–359	O
,	O
1972.	O
teuvo	O
kohonen	O
.	O
self-organized	O
formation	O
of	O
topologically	O
correct	O
feature	O
maps	O
.	O
biological	O
cybernetics	O
,	O
43:59–69	O
,	O
1982.	O
teuvo	O
kohonen	O
.	O
self-organization	O
and	O
associative	O
memory	O
.	O
springer-	O
verlag	O
,	O
berlin	O
,	O
third	O
edition	O
,	O
1989.	O
t.	O
kohonen	O
.	O
the	O
self-organizing	B
map	I
.	O
neurocomputing	O
,	O
21	O
(	O
1-3	O
)	O
:1–6	O
,	O
1998.	O
e.r	O
.	O
kandel	O
,	O
j.h	O
.	O
schwartz	O
,	O
and	O
t.m	O
.	O
jessell	O
.	O
principles	O
of	O
neural	O
science	O
.	O
appleton	O
&	O
lange	O
,	O
2000	O
.	O
[	O
lcds90	O
]	O
y.	O
le	O
cun	O
,	O
j.	O
s.	O
denker	O
,	O
and	O
s.	O
a.	O
solla	O
.	O
optimal	B
brain	I
damage	I
.	O
in	O
d.	O
touretzky	O
,	O
editor	O
,	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
2	O
,	O
pages	O
598–605	O
.	O
morgan	O
kaufmann	O
,	O
1990	O
.	O
[	O
mac67	O
]	O
[	O
mbs93	O
]	O
j.	O
macqueen	O
.	O
some	O
methods	O
for	O
classiﬁcation	O
and	O
analysis	O
of	O
multivariate	O
observations	O
.	O
in	O
proceedings	O
of	O
the	O
fifth	O
berkeley	O
symposium	O
on	O
mathe-	O
matics	O
,	O
statistics	O
and	O
probability	O
,	O
vol	O
.	O
1	O
,	O
pages	O
281–296	O
,	O
1967.	O
thomas	O
m.	O
martinetz	O
,	O
stanislav	O
g.	O
berkovich	O
,	O
and	O
klaus	O
j.	O
schulten	O
.	O
’	O
neural-gas	O
’	O
network	O
for	O
vector	O
quantization	B
and	O
its	O
application	O
to	O
time-	O
series	O
prediction	O
.	O
ieee	O
trans	O
.	O
on	O
neural	O
networks	O
,	O
4	O
(	O
4	O
)	O
:558–569	O
,	O
1993	O
.	O
[	O
mbw+10	O
]	O
k.d	O
.	O
micheva	O
,	O
b.	O
busse	O
,	O
n.c.	O
weiler	O
,	O
n.	O
o	O
’	O
rourke	O
,	O
and	O
s.j	O
.	O
smith	O
.	O
single-	O
synapse	B
analysis	O
of	O
a	O
diverse	O
synapse	B
population	O
:	O
proteomic	O
imaging	O
meth-	O
ods	O
and	O
markers	O
.	O
neuron	O
,	O
68	O
(	O
4	O
)	O
:639–653	O
,	O
2010	O
.	O
[	O
mp43	O
]	O
[	O
mp69	O
]	O
[	O
mr86	O
]	O
w.s	O
.	O
mcculloch	O
and	O
w.	O
pitts	O
.	O
a	O
logical	O
calculus	O
of	O
the	O
ideas	O
immanent	O
in	O
nervous	O
activity	O
.	O
bulletin	O
of	O
mathematical	O
biology	O
,	O
5	O
(	O
4	O
)	O
:115–133	O
,	O
1943.	O
m.	O
minsky	O
and	O
s.	O
papert	O
.	O
perceptrons	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
mass	O
,	O
1969.	O
j.	O
l.	O
mcclelland	O
and	O
d.	O
e.	O
rumelhart	O
.	O
parallel	O
distributed	O
processing	O
:	O
explorations	O
in	O
the	O
microstructure	O
of	O
cognition	O
,	O
volume	O
2.	O
mit	O
press	O
,	O
cambridge	O
,	O
1986.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
211	O
bibliography	O
[	O
par87	O
]	O
[	O
pg89	O
]	O
[	O
pin87	O
]	O
[	O
pm47	O
]	O
[	O
pre94	O
]	O
[	O
rb93	O
]	O
[	O
rd05	O
]	O
dkriesel.com	O
david	O
r.	O
parker	O
.	O
optimal	O
algorithms	O
for	O
adaptive	O
networks	O
:	O
second	O
or-	O
der	O
back	O
propagation	O
,	O
second	O
order	O
direct	O
propagation	O
,	O
and	O
second	O
order	O
hebbian	O
learning	B
.	O
in	O
maureen	O
caudill	O
and	O
charles	O
butler	O
,	O
editors	O
,	O
ieee	O
first	O
international	O
conference	O
on	O
neural	O
networks	O
(	O
icnn	O
’	O
87	O
)	O
,	O
volume	O
ii	O
,	O
pages	O
ii–593–ii–600	O
,	O
san	O
diego	O
,	O
ca	O
,	O
june	O
1987.	O
ieee	O
.	O
t.	O
poggio	O
and	O
f.	O
girosi	O
.	O
a	O
theory	O
of	O
networks	O
for	O
approximation	B
and	O
learning	B
.	O
mit	O
press	O
,	O
cambridge	O
mass.	O
,	O
1989.	O
f.	O
j.	O
pineda	O
.	O
generalization	B
of	O
back-propagation	O
to	O
recurrent	O
neural	O
net-	O
works	O
.	O
physical	O
review	O
letters	O
,	O
59:2229–2232	O
,	O
1987.	O
w.	O
pitts	O
and	O
w.s	O
.	O
mcculloch	O
.	O
how	O
we	O
know	O
universals	O
the	O
perception	O
of	O
auditory	O
and	O
visual	O
forms	O
.	O
bulletin	O
of	O
mathematical	O
biology	O
,	O
9	O
(	O
3	O
)	O
:127–147	O
,	O
1947.	O
l.	O
prechelt	O
.	O
proben1	O
:	O
a	O
set	O
of	O
neural	O
network	O
benchmark	O
problems	O
and	O
benchmarking	O
rules	O
.	O
technical	O
report	O
,	O
21:94	O
,	O
1994.	O
m.	O
riedmiller	O
and	O
h.	O
braun	O
.	O
a	O
direct	O
adaptive	O
method	O
for	O
faster	O
back-	O
propagation	O
learning	O
:	O
the	O
rprop	O
algorithm	B
.	O
in	O
neural	O
networks	O
,	O
1993.	O
,	O
ieee	O
international	O
conference	O
on	O
,	O
pages	O
586–591	O
.	O
ieee	O
,	O
1993.	O
g.	O
roth	O
and	O
u.	O
dicke	O
.	O
evolution	O
of	O
the	O
brain	B
and	O
intelligence	O
.	O
trends	O
in	O
cognitive	O
sciences	O
,	O
9	O
(	O
5	O
)	O
:250–257	O
,	O
2005	O
.	O
[	O
rhw86a	O
]	O
d.	O
rumelhart	O
,	O
g.	O
hinton	O
,	O
and	O
r.	O
williams	O
.	O
learning	B
representations	O
by	O
back-propagating	O
errors	O
.	O
nature	O
,	O
323:533–536	O
,	O
october	O
1986	O
.	O
[	O
rie94	O
]	O
[	O
ros58	O
]	O
[	O
rhw86b	O
]	O
david	O
e.	O
rumelhart	O
,	O
geoﬀrey	O
e.	O
hinton	O
,	O
and	O
r.	O
j.	O
williams	O
.	O
learning	B
internal	O
representations	O
by	O
error	O
propagation	O
.	O
in	O
d.	O
e.	O
rumelhart	O
,	O
j.	O
l.	O
mcclelland	O
,	O
and	O
the	O
pdp	O
research	O
group.	O
,	O
editors	O
,	O
parallel	O
distributed	O
pro-	O
cessing	O
:	O
explorations	O
in	O
the	O
microstructure	O
of	O
cognition	O
,	O
volume	O
1	O
:	O
foun-	O
dations	O
.	O
mit	O
press	O
,	O
1986.	O
m.	O
riedmiller	O
.	O
rprop	O
-	O
description	O
and	O
implementation	O
details	O
.	O
technical	O
report	O
,	O
university	O
of	O
karlsruhe	O
,	O
1994.	O
f.	O
rosenblatt	O
.	O
the	O
perceptron	B
:	O
a	O
probabilistic	O
model	O
for	O
information	O
storage	O
and	O
organization	O
in	O
the	O
brain	B
.	O
psychological	O
review	O
,	O
65:386–408	O
,	O
1958.	O
f.	O
rosenblatt	O
.	O
principles	O
of	O
neurodynamics	O
.	O
spartan	O
,	O
new	O
york	O
,	O
1962.	O
r.	O
s.	O
sutton	O
and	O
a.	O
g.	O
barto	O
.	O
reinforcement	B
learning	I
:	O
an	O
introduction	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
ma	O
,	O
1998	O
.	O
[	O
ros62	O
]	O
[	O
sb98	O
]	O
212	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O
dkriesel.com	O
bibliography	O
[	O
sg06	O
]	O
[	O
sge05	O
]	O
[	O
ste61	O
]	O
[	O
vdm73	O
]	O
[	O
was89	O
]	O
[	O
wer74	O
]	O
[	O
wer88	O
]	O
[	O
wg94	O
]	O
[	O
wh60	O
]	O
[	O
wid89	O
]	O
[	O
zel94	O
]	O
a.	O
scherbart	O
and	O
n.	O
goerke	O
.	O
unsupervised	O
system	O
for	O
discovering	O
patterns	O
in	O
time-series	O
,	O
2006.	O
rolf	O
schatten	O
,	O
nils	O
goerke	O
,	O
and	O
rolf	O
eckmiller	O
.	O
regional	O
and	O
online	O
learn-	O
able	O
ﬁelds	O
.	O
in	O
sameer	O
singh	O
,	O
maneesha	O
singh	O
,	O
chidanand	O
apté	O
,	O
and	O
petra	O
perner	O
,	O
editors	O
,	O
icapr	O
(	O
2	O
)	O
,	O
volume	O
3687	O
of	O
lecture	O
notes	O
in	O
computer	O
science	O
,	O
pages	O
74–83	O
.	O
springer	O
,	O
2005.	O
k.	O
steinbuch	O
.	O
die	O
lernmatrix	O
.	O
kybernetik	O
(	O
biological	O
cybernetics	O
)	O
,	O
1:36–45	O
,	O
1961.	O
c.	O
von	O
der	O
malsburg	O
.	O
self-organizing	O
of	O
orientation	O
sensitive	O
cells	O
in	O
striate	O
cortex	O
.	O
kybernetik	O
,	O
14:85–100	O
,	O
1973.	O
p.	O
d.	O
wasserman	O
.	O
neural	O
computing	O
theory	O
and	O
practice	O
.	O
new	O
york	O
:	O
van	O
nostrand	O
reinhold	O
,	O
1989.	O
p.	O
j.	O
werbos	O
.	O
beyond	O
regression	O
:	O
new	O
tools	O
for	O
prediction	O
and	O
analysis	O
in	O
the	O
behavioral	O
sciences	O
.	O
phd	O
thesis	O
,	O
harvard	O
university	O
,	O
1974.	O
p.	O
j.	O
werbos	O
.	O
backpropagation	B
:	O
past	O
and	O
future	O
.	O
in	O
proceedings	O
icnn-88	O
,	O
san	O
diego	O
,	O
pages	O
343–353	O
,	O
1988.	O
a.s.	O
weigend	O
and	O
n.a	O
.	O
gershenfeld	O
.	O
time	B
series	I
prediction	I
.	O
addison-	O
wesley	O
,	O
1994.	O
b.	O
widrow	O
and	O
m.	O
e.	O
hoﬀ	O
.	O
adaptive	O
switching	O
circuits	O
.	O
in	O
proceedings	O
wescon	O
,	O
pages	O
96–104	O
,	O
1960.	O
r.	O
widner	O
.	O
single-stage	O
logic	O
.	O
aiee	O
fall	O
general	O
meeting	O
,	O
1960.	O
wasser-	O
man	O
,	O
p.	O
neural	O
computing	O
,	O
theory	O
and	O
practice	O
,	O
van	O
nostrand	O
reinhold	O
,	O
1989.	O
andreas	O
zell	O
.	O
simulation	O
neuronaler	O
netze	O
.	O
addison-wesley	O
,	O
1994.	O
ger-	O
man	O
.	O
d.	O
kriesel	O
–	O
a	O
brief	O
introduction	O
to	O
neural	O
networks	O
(	O
zeta2-en	O
)	O