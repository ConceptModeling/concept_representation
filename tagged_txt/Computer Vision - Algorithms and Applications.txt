computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
richard	O
szeliski	O
september	O
3	O
,	O
2010	O
draft	O
c	O
(	O
cid:13	O
)	O
2010	O
springer	O
this	O
electronic	O
draft	O
is	O
for	O
non-commercial	O
personal	O
use	O
only	O
,	O
and	O
may	O
not	O
be	O
posted	O
or	O
re-distributed	O
in	O
any	O
form	O
.	O
please	O
refer	O
interested	O
readers	O
to	O
the	O
book	O
’	O
s	O
web	O
site	O
at	O
http	O
:	O
//szeliski.org/book/	O
.	O
this	O
book	O
is	O
dedicated	O
to	O
my	O
parents	O
,	O
zdzisław	O
and	O
jadwiga	O
,	O
and	O
my	O
family	O
,	O
lyn	O
,	O
anne	O
,	O
and	O
stephen	O
.	O
1	O
introduction	O
what	O
is	O
computer	O
vision	O
?	O
•	O
a	O
brief	O
history	O
•	O
book	O
overview	O
•	O
sample	O
syllabus	O
•	O
notation	O
2	O
image	B
formation	O
geometric	B
primitives	O
and	O
transformations	O
•	O
photometric	B
image	O
formation	O
•	O
the	O
digital	O
camera	O
3	O
image	B
processing	O
1	O
29	O
99	O
point	O
operators	O
•	O
linear	B
ﬁltering	O
•	O
more	O
neighborhood	B
operators	O
•	O
fourier	O
transforms	O
•	O
pyramids	O
and	O
wavelets	O
•	O
geometric	B
transformations	O
•	O
global	B
optimization	I
4	O
feature	B
detection	O
and	O
matching	B
205	O
points	B
and	O
patches	O
•	O
edges	O
•	O
lines	B
5	O
segmentation	B
mean	O
shift	O
and	O
mode	O
ﬁnding	O
•	O
normalized	B
cuts	I
•	O
active	B
contours	I
•	O
split	O
and	O
merge	O
•	O
graph	B
cuts	I
and	O
energy-based	B
methods	O
6	O
feature-based	B
alignment	O
2d	O
and	O
3d	O
feature-based	B
alignment	O
•	O
pose	O
estimation	B
•	O
geometric	B
intrinsic	O
calibration	B
7	O
structure	B
from	I
motion	I
267	O
309	O
343	O
triangulation	B
•	O
two-frame	B
structure	O
from	O
motion	B
•	O
factorization	B
•	O
bundle	B
adjustment	I
•	O
constrained	B
structure	O
and	O
motion	B
n^	O
8	O
dense	O
motion	O
estimation	B
translational	O
alignment	B
•	O
parametric	B
motion	O
•	O
spline-based	B
motion	O
•	O
optical	B
ﬂow	I
•	O
layered	B
motion	O
9	O
image	B
stitching	I
motion	O
models	O
•	O
global	B
alignment	I
•	O
compositing	B
381	O
427	O
10	O
computational	O
photography	O
467	O
photometric	B
calibration	O
•	O
high	B
dynamic	I
range	I
imaging	O
•	O
super-resolution	O
and	O
blur	B
removal	I
•	O
image	B
matting	O
and	O
compositing	B
•	O
texture	B
analysis	O
and	O
synthesis	O
11	O
stereo	B
correspondence	O
533	O
epipolar	B
geometry	I
•	O
sparse	B
correspondence	I
•	O
dense	B
correspondence	I
•	O
local	B
methods	I
•	O
global	B
optimization	I
•	O
multi-view	B
stereo	I
12	O
3d	O
reconstruction	O
577	O
shape	O
from	O
x	O
•	O
active	O
rangeﬁnding	O
•	O
surface	B
representations	O
•	O
point-based	B
representations	O
•	O
volumetric	B
representations	O
•	O
model-based	B
reconstruction	O
•	O
619	O
13	O
image-based	B
rendering	I
recovering	O
texture	B
maps	O
and	O
albedos	O
view	B
interpolation	I
•	O
layered	O
depth	O
images	O
•	O
light	O
ﬁelds	O
and	O
lumigraphs	O
•	O
environment	O
mattes	O
•	O
video-based	O
rendering	O
14	O
recognition	B
655	O
instance	B
recognition	O
•	O
category	O
recognition	O
•	O
object	O
detection	B
•	O
face	B
recognition	O
•	O
context	B
and	O
scene	B
understanding	I
•	O
recognition	B
databases	O
and	O
test	O
sets	O
preface	O
the	O
seeds	O
for	O
this	O
book	O
were	O
ﬁrst	O
planted	O
in	O
2001	O
when	O
steve	O
seitz	O
at	O
the	O
university	O
of	O
wash-	O
ington	O
invited	O
me	O
to	O
co-teach	O
a	O
course	O
called	O
“	O
computer	O
vision	O
for	O
computer	O
graphics	O
”	O
.	O
at	O
that	O
time	O
,	O
computer	O
vision	O
techniques	O
were	O
increasingly	O
being	O
used	O
in	O
computer	O
graphics	O
to	O
create	O
image-based	B
models	O
of	O
real-world	O
objects	O
,	O
to	O
create	O
visual	B
effects	I
,	O
and	O
to	O
merge	O
real-	O
world	O
imagery	O
using	O
computational	O
photography	O
techniques	O
.	O
our	O
decision	O
to	O
focus	B
on	O
the	O
applications	O
of	O
computer	O
vision	O
to	O
fun	O
problems	O
such	O
as	O
image	B
stitching	I
and	O
photo-based	O
3d	O
modeling	B
from	O
personal	O
photos	O
seemed	O
to	O
resonate	O
well	O
with	O
our	O
students	O
.	O
since	O
that	O
time	O
,	O
a	O
similar	O
syllabus	O
and	O
project-oriented	O
course	O
structure	O
has	O
been	O
used	O
to	O
teach	O
general	O
computer	O
vision	O
courses	O
both	O
at	O
the	O
university	O
of	O
washington	O
and	O
at	O
stanford	O
.	O
(	O
the	O
latter	O
was	O
a	O
course	O
i	O
co-taught	O
with	O
david	O
fleet	O
in	O
2003	O
.	O
)	O
similar	O
curricula	O
have	O
been	O
adopted	O
at	O
a	O
number	O
of	O
other	O
universities	O
and	O
also	O
incorporated	O
into	O
more	O
specialized	O
courses	O
on	O
computational	O
photography	O
.	O
(	O
for	O
ideas	O
on	O
how	O
to	O
use	O
this	O
book	O
in	O
your	O
own	O
course	O
,	O
please	O
see	O
table	O
1.1	O
in	O
section	O
1.4	O
.	O
)	O
this	O
book	O
also	O
reﬂects	O
my	O
20	O
years	O
’	O
experience	O
doing	O
computer	O
vision	O
research	O
in	O
corpo-	O
rate	O
research	O
labs	O
,	O
mostly	O
at	O
digital	O
equipment	O
corporation	O
’	O
s	O
cambridge	O
research	O
lab	O
and	O
at	O
microsoft	O
research	O
.	O
in	O
pursuing	O
my	O
work	O
,	O
i	O
have	O
mostly	O
focused	O
on	O
problems	O
and	O
solu-	O
tion	B
techniques	O
(	O
algorithms	O
)	O
that	O
have	O
practical	O
real-world	O
applications	O
and	O
that	O
work	O
well	O
in	O
practice	O
.	O
thus	O
,	O
this	O
book	O
has	O
more	O
emphasis	O
on	O
basic	O
techniques	O
that	O
work	O
under	O
real-world	O
conditions	O
and	O
less	O
on	O
more	O
esoteric	O
mathematics	O
that	O
has	O
intrinsic	B
elegance	O
but	O
less	O
practical	O
applicability	O
.	O
this	O
book	O
is	O
suitable	O
for	O
teaching	O
a	O
senior-level	O
undergraduate	O
course	O
in	O
computer	O
vision	O
to	O
students	O
in	O
both	O
computer	O
science	O
and	O
electrical	O
engineering	O
.	O
i	O
prefer	O
students	O
to	O
have	O
either	O
an	O
image	B
processing	O
or	O
a	O
computer	O
graphics	O
course	O
as	O
a	O
prerequisite	O
so	O
that	O
they	O
can	O
spend	O
less	O
time	O
learning	O
general	O
background	O
mathematics	O
and	O
more	O
time	O
studying	O
computer	O
vision	O
techniques	O
.	O
the	O
book	O
is	O
also	O
suitable	O
for	O
teaching	O
graduate-level	O
courses	O
in	O
computer	O
vision	O
(	O
by	O
delving	O
into	O
the	O
more	O
demanding	O
application	O
and	O
algorithmic	O
areas	O
)	O
and	O
as	O
a	O
gen-	O
eral	O
reference	O
to	O
fundamental	O
techniques	O
and	O
the	O
recent	O
research	O
literature	O
.	O
to	O
this	O
end	O
,	O
i	O
have	O
attempted	O
wherever	O
possible	O
to	O
at	O
least	O
cite	O
the	O
newest	O
research	O
in	O
each	O
sub-ﬁeld	O
,	O
even	O
if	O
the	O
viii	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
technical	O
details	O
are	O
too	O
complex	O
to	O
cover	O
in	O
the	O
book	O
itself	O
.	O
in	O
teaching	O
our	O
courses	O
,	O
we	O
have	O
found	O
it	O
useful	O
for	O
the	O
students	O
to	O
attempt	O
a	O
number	O
of	O
small	O
implementation	O
projects	O
,	O
which	O
often	O
build	O
on	O
one	O
another	O
,	O
in	O
order	B
to	O
get	O
them	O
used	O
to	O
working	O
with	O
real-world	O
images	O
and	O
the	O
challenges	O
that	O
these	O
present	O
.	O
the	O
students	O
are	O
then	O
asked	O
to	O
choose	O
an	O
individual	O
topic	O
for	O
each	O
of	O
their	O
small-group	O
,	O
ﬁnal	O
projects	O
.	O
(	O
sometimes	O
these	O
projects	O
even	O
turn	O
into	O
conference	O
papers	O
!	O
)	O
the	O
exercises	O
at	O
the	O
end	O
of	O
each	O
chapter	O
contain	O
numerous	O
suggestions	O
for	O
smaller	O
mid-term	O
projects	O
,	O
as	O
well	O
as	O
more	O
open-ended	O
problems	O
whose	O
solutions	O
are	O
still	O
active	O
research	O
topics	O
.	O
wherever	O
possible	O
,	O
i	O
encourage	O
students	O
to	O
try	O
their	O
algorithms	O
on	O
their	O
own	O
personal	O
photographs	O
,	O
since	O
this	O
better	O
motivates	O
them	O
,	O
often	O
leads	O
to	O
creative	O
variants	O
on	O
the	O
problems	O
,	O
and	O
better	O
acquaints	O
them	O
with	O
the	O
variety	O
and	O
complexity	O
of	O
real-world	O
imagery	O
.	O
in	O
formulating	O
and	O
solving	O
computer	O
vision	O
problems	O
,	O
i	O
have	O
often	O
found	O
it	O
useful	O
to	O
draw	O
inspiration	O
from	O
three	O
high-level	O
approaches	O
:	O
•	O
scientiﬁc	O
:	O
build	O
detailed	O
models	O
of	O
the	O
image	B
formation	O
process	O
and	O
develop	O
mathe-	O
matical	O
techniques	O
to	O
invert	O
these	O
in	O
order	B
to	O
recover	O
the	O
quantities	O
of	O
interest	O
(	O
where	O
necessary	O
,	O
making	O
simplifying	O
assumption	O
to	O
make	O
the	O
mathematics	O
more	O
tractable	O
)	O
.	O
•	O
statistical	O
:	O
use	O
probabilistic	B
models	I
to	O
quantify	O
the	O
prior	B
likelihood	O
of	O
your	O
unknowns	O
and	O
the	O
noisy	O
measurement	O
processes	O
that	O
produce	O
the	O
input	O
images	O
,	O
then	O
infer	O
the	O
best	O
possible	O
estimates	O
of	O
your	O
desired	O
quantities	O
and	O
analyze	O
their	O
resulting	O
uncertainties	O
.	O
the	O
inference	B
algorithms	O
used	O
are	O
often	O
closely	O
related	O
to	O
the	O
optimization	O
techniques	O
used	O
to	O
invert	O
the	O
(	O
scientiﬁc	O
)	O
image	B
formation	O
processes	O
.	O
•	O
engineering	O
:	O
develop	O
techniques	O
that	O
are	O
simple	O
to	O
describe	O
and	O
implement	O
but	O
that	O
are	O
also	O
known	O
to	O
work	O
well	O
in	O
practice	O
.	O
test	O
these	O
techniques	O
to	O
understand	O
their	O
limitation	O
and	O
failure	O
modes	O
,	O
as	O
well	O
as	O
their	O
expected	O
computational	O
costs	O
(	O
run-time	O
performance	O
)	O
.	O
these	O
three	O
approaches	O
build	O
on	O
each	O
other	O
and	O
are	O
used	O
throughout	O
the	O
book	O
.	O
my	O
personal	O
research	O
and	O
development	O
philosophy	O
(	O
and	O
hence	O
the	O
exercises	O
in	O
the	O
book	O
)	O
have	O
a	O
strong	O
emphasis	O
on	O
testing	O
algorithms	O
.	O
it	O
’	O
s	O
too	O
easy	O
in	O
computer	O
vision	O
to	O
develop	O
an	O
algorithm	B
that	O
does	O
something	O
plausible	O
on	O
a	O
few	O
images	O
rather	O
than	O
something	O
correct	O
.	O
the	O
best	O
way	O
to	O
validate	O
your	O
algorithms	O
is	O
to	O
use	O
a	O
three-part	O
strategy	B
.	O
first	O
,	O
test	O
your	O
algorithm	B
on	O
clean	O
synthetic	O
data	O
,	O
for	O
which	O
the	O
exact	O
results	O
are	O
known	O
.	O
second	O
,	O
add	O
noise	B
to	O
the	O
data	O
and	O
evaluate	O
how	O
the	O
performance	O
degrades	O
as	O
a	O
function	O
of	O
noise	B
level	O
.	O
finally	O
,	O
test	O
the	O
algorithm	B
on	O
real-world	O
data	O
,	O
preferably	O
drawn	O
from	O
a	O
wide	O
variety	O
of	O
sources	O
,	O
such	O
as	O
photos	O
found	O
on	O
the	O
web	O
.	O
only	O
then	O
can	O
you	O
truly	O
know	O
if	O
your	O
algorithm	B
can	O
deal	O
with	O
real-world	O
complexity	O
,	O
i.e.	O
,	O
images	O
that	O
do	O
not	O
ﬁt	O
some	O
simpliﬁed	O
model	O
or	O
assumptions	O
.	O
preface	O
ix	O
in	O
order	B
to	O
help	O
students	O
in	O
this	O
process	O
,	O
this	O
books	O
comes	O
with	O
a	O
large	O
amount	O
of	O
supple-	O
mentary	O
material	O
,	O
which	O
can	O
be	O
found	O
on	O
the	O
book	O
’	O
s	O
web	O
site	O
http	O
:	O
//szeliski.org/book	O
.	O
this	O
material	O
,	O
which	O
is	O
described	O
in	O
appendix	O
c	O
,	O
includes	O
:	O
•	O
pointers	O
to	O
commonly	O
used	O
data	B
sets	I
for	O
the	O
problems	O
,	O
which	O
can	O
be	O
found	O
on	O
the	O
web	O
•	O
pointers	O
to	O
software	O
libraries	O
,	O
which	O
can	O
help	O
students	O
get	O
started	O
with	O
basic	O
tasks	O
such	O
as	O
reading/writing	O
images	O
or	O
creating	O
and	O
manipulating	O
images	O
•	O
slide	O
sets	O
corresponding	O
to	O
the	O
material	O
covered	O
in	O
this	O
book	O
•	O
a	O
bibtex	O
bibliography	O
of	O
the	O
papers	O
cited	O
in	O
this	O
book	O
.	O
the	O
latter	O
two	O
resources	O
may	O
be	O
of	O
more	O
interest	O
to	O
instructors	O
and	O
researchers	O
publishing	O
new	O
papers	O
in	O
this	O
ﬁeld	O
,	O
but	O
they	O
will	O
probably	O
come	O
in	O
handy	O
even	O
with	O
regular	O
students	O
.	O
some	O
of	O
the	O
software	O
libraries	O
contain	O
implementations	O
of	O
a	O
wide	O
variety	O
of	O
computer	O
vision	O
algorithms	O
,	O
which	O
can	O
enable	O
you	O
to	O
tackle	O
more	O
ambitious	O
projects	O
(	O
with	O
your	O
instructor	O
’	O
s	O
consent	O
)	O
.	O
acknowledgements	O
i	O
would	O
like	O
to	O
gratefully	O
acknowledge	O
all	O
of	O
the	O
people	O
whose	O
passion	O
for	O
research	O
and	O
inquiry	O
as	O
well	O
as	O
encouragement	O
have	O
helped	O
me	O
write	O
this	O
book	O
.	O
steve	O
zucker	O
at	O
mcgill	O
university	O
ﬁrst	O
introduced	O
me	O
to	O
computer	O
vision	O
,	O
taught	O
all	O
of	O
his	O
students	O
to	O
question	O
and	O
debate	O
research	O
results	O
and	O
techniques	O
,	O
and	O
encouraged	O
me	O
to	O
pursue	O
a	O
graduate	O
career	O
in	O
this	O
area	O
.	O
takeo	O
kanade	O
and	O
geoff	O
hinton	O
,	O
my	O
ph	O
.	O
d.	O
thesis	O
advisors	O
at	O
carnegie	O
mellon	O
university	O
,	O
taught	O
me	O
the	O
fundamentals	O
of	O
good	O
research	O
,	O
writing	O
,	O
and	O
presentation	O
.	O
they	O
ﬁred	O
up	O
my	O
interest	O
in	O
visual	O
processing	O
,	O
3d	O
modeling	B
,	O
and	O
statistical	O
methods	O
,	O
while	O
larry	O
matthies	O
introduced	O
me	O
to	O
kalman	O
ﬁltering	O
and	O
stereo	B
matching	I
.	O
demetri	O
terzopoulos	O
was	O
my	O
mentor	O
at	O
my	O
ﬁrst	O
industrial	B
research	O
job	O
and	O
taught	O
me	O
the	O
ropes	O
of	O
successful	O
publishing	O
.	O
yvan	O
leclerc	O
and	O
pascal	O
fua	O
,	O
colleagues	O
from	O
my	O
brief	O
in-	O
terlude	O
at	O
sri	O
international	O
,	O
gave	O
me	O
new	O
perspectives	O
on	O
alternative	O
approaches	O
to	O
computer	O
vision	O
.	O
during	O
my	O
six	O
years	O
of	O
research	O
at	O
digital	O
equipment	O
corporation	O
’	O
s	O
cambridge	O
research	O
lab	O
,	O
i	O
was	O
fortunate	O
to	O
work	O
with	O
a	O
great	O
set	O
of	O
colleagues	O
,	O
including	O
ingrid	O
carlbom	O
,	O
gudrun	O
klinker	O
,	O
keith	O
waters	O
,	O
richard	O
weiss	O
,	O
st´ephane	O
lavall´ee	O
,	O
and	O
sing	O
bing	O
kang	O
,	O
as	O
well	O
as	O
to	O
supervise	O
the	O
ﬁrst	O
of	O
a	O
long	O
string	O
of	O
outstanding	O
summer	O
interns	O
,	O
including	O
david	O
tonnesen	O
,	O
sing	O
bing	O
kang	O
,	O
james	O
coughlan	O
,	O
and	O
harry	O
shum	O
.	O
this	O
is	O
also	O
where	O
i	O
began	O
my	O
long-term	O
collaboration	O
with	O
daniel	O
scharstein	O
,	O
now	O
at	O
middlebury	O
college	O
.	O
x	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
at	O
microsoft	O
research	O
,	O
i	O
’	O
ve	O
had	O
the	O
outstanding	O
fortune	O
to	O
work	O
with	O
some	O
of	O
the	O
world	O
’	O
s	O
best	O
researchers	O
in	O
computer	O
vision	O
and	O
computer	O
graphics	O
,	O
including	O
michael	O
cohen	O
,	O
hugues	O
hoppe	O
,	O
stephen	O
gortler	O
,	O
steve	O
shafer	O
,	O
matthew	O
turk	O
,	O
harry	O
shum	O
,	O
anandan	O
,	O
phil	O
torr	O
,	O
an-	O
tonio	O
criminisi	O
,	O
georg	O
petschnigg	O
,	O
kentaro	O
toyama	O
,	O
ramin	O
zabih	O
,	O
shai	O
avidan	O
,	O
sing	O
bing	O
kang	O
,	O
matt	O
uyttendaele	O
,	O
patrice	O
simard	O
,	O
larry	O
zitnick	O
,	O
richard	O
hartley	O
,	O
simon	O
winder	O
,	O
drew	O
steedly	O
,	O
chris	O
pal	O
,	O
nebojsa	O
jojic	O
,	O
patrick	O
baudisch	O
,	O
dani	O
lischinski	O
,	O
matthew	O
brown	O
,	O
simon	O
baker	O
,	O
michael	O
goesele	O
,	O
eric	O
stollnitz	O
,	O
david	O
nist´er	O
,	O
blaise	O
aguera	O
y	O
arcas	O
,	O
sudipta	O
sinha	O
,	O
johannes	O
kopf	O
,	O
neel	O
joshi	O
,	O
and	O
krishnan	O
ramnath	O
.	O
i	O
was	O
also	O
lucky	O
to	O
have	O
as	O
in-	O
terns	O
such	O
great	O
students	O
as	O
polina	O
golland	O
,	O
simon	O
baker	O
,	O
mei	O
han	O
,	O
arno	O
sch¨odl	O
,	O
ron	O
dror	O
,	O
ashley	O
eden	O
,	O
jinxiang	O
chai	O
,	O
rahul	O
swaminathan	O
,	O
yanghai	O
tsin	O
,	O
sam	O
hasinoff	O
,	O
anat	O
levin	O
,	O
matthew	O
brown	O
,	O
eric	O
bennett	O
,	O
vaibhav	O
vaish	O
,	O
jan-michael	O
frahm	O
,	O
james	O
diebel	O
,	O
ce	O
liu	O
,	O
josef	O
sivic	O
,	O
grant	O
schindler	O
,	O
colin	O
zheng	O
,	O
neel	O
joshi	O
,	O
sudipta	O
sinha	O
,	O
zeev	O
farbman	O
,	O
rahul	O
garg	O
,	O
tim	O
cho	O
,	O
yekeun	O
jeong	O
,	O
richard	O
roberts	O
,	O
varsha	O
hedau	O
,	O
and	O
dilip	O
krishnan	O
.	O
while	O
working	O
at	O
microsoft	O
,	O
i	O
’	O
ve	O
also	O
had	O
the	O
opportunity	O
to	O
collaborate	O
with	O
wonderful	O
colleagues	O
at	O
the	O
university	O
of	O
washington	O
,	O
where	O
i	O
hold	O
an	O
afﬁliate	O
professor	O
appointment	O
.	O
i	O
’	O
m	O
indebted	O
to	O
tony	O
derose	O
and	O
david	O
salesin	O
,	O
who	O
ﬁrst	O
encouraged	O
me	O
to	O
get	O
involved	O
with	O
the	O
research	O
going	O
on	O
at	O
uw	O
,	O
my	O
long-time	O
collaborators	O
brian	O
curless	O
,	O
steve	O
seitz	O
,	O
maneesh	O
agrawala	O
,	O
sameer	O
agarwal	O
,	O
and	O
yasu	O
furukawa	O
,	O
as	O
well	O
as	O
the	O
students	O
i	O
have	O
had	O
the	O
privilege	O
to	O
supervise	O
and	O
interact	O
with	O
,	O
including	O
fr´ederic	O
pighin	O
,	O
yung-yu	O
chuang	O
,	O
doug	O
zongker	O
,	O
colin	O
zheng	O
,	O
aseem	O
agarwala	O
,	O
dan	O
goldman	O
,	O
noah	O
snavely	O
,	O
rahul	O
garg	O
,	O
and	O
ryan	O
kaminsky	O
.	O
as	O
i	O
mentioned	O
at	O
the	O
beginning	O
of	O
this	O
preface	O
,	O
this	O
book	O
owes	O
its	O
inception	O
to	O
the	O
vision	O
course	O
that	O
steve	O
seitz	O
invited	O
me	O
to	O
co-teach	O
,	O
as	O
well	O
as	O
to	O
steve	O
’	O
s	O
encouragement	O
,	O
course	O
notes	O
,	O
and	O
editorial	O
input	O
.	O
i	O
’	O
m	O
also	O
grateful	O
to	O
the	O
many	O
other	O
computer	O
vision	O
researchers	O
who	O
have	O
given	O
me	O
so	O
many	O
constructive	O
suggestions	O
about	O
the	O
book	O
,	O
including	O
sing	O
bing	O
kang	O
,	O
who	O
was	O
my	O
infor-	O
mal	O
book	O
editor	O
,	O
vladimir	O
kolmogorov	O
,	O
who	O
contributed	O
appendix	O
b.5.5	O
on	O
linear	B
program-	O
ming	O
techniques	O
for	O
mrf	O
inference	B
,	O
daniel	O
scharstein	O
,	O
richard	O
hartley	O
,	O
simon	O
baker	O
,	O
noah	O
snavely	O
,	O
bill	O
freeman	O
,	O
svetlana	O
lazebnik	O
,	O
matthew	O
turk	O
,	O
jitendra	O
malik	O
,	O
alyosha	O
efros	O
,	O
michael	O
black	O
,	O
brian	O
curless	O
,	O
sameer	O
agarwal	O
,	O
li	O
zhang	O
,	O
deva	O
ramanan	O
,	O
olga	O
veksler	O
,	O
yuri	O
boykov	O
,	O
carsten	O
rother	O
,	O
phil	O
torr	O
,	O
bill	O
triggs	O
,	O
bruce	O
maxwell	O
,	O
jana	O
koˇseck´a	O
,	O
eero	O
si-	O
moncelli	O
,	O
aaron	O
hertzmann	O
,	O
antonio	O
torralba	O
,	O
tomaso	O
poggio	O
,	O
theo	O
pavlidis	O
,	O
baba	O
vemuri	O
,	O
nando	O
de	O
freitas	O
,	O
chuck	O
dyer	O
,	O
song	O
yi	O
,	O
falk	O
schubert	O
,	O
roman	O
pﬂugfelder	O
,	O
marshall	O
tap-	O
pen	O
,	O
james	O
coughlan	O
,	O
sammy	O
rogmans	O
,	O
klaus	O
strobel	O
,	O
shanmuganathan	O
,	O
andreas	O
siebert	O
,	O
yongjun	O
wu	O
,	O
fred	O
pighin	O
,	O
juan	O
cockburn	O
,	O
ronald	O
mallet	O
,	O
tim	O
soper	O
,	O
georgios	O
evangelidis	O
,	O
dwight	O
fowler	O
,	O
itzik	O
bayaz	O
,	O
daniel	O
o	O
’	O
connor	O
,	O
and	O
srikrishna	O
bhat	O
.	O
shena	O
deuchers	O
did	O
a	O
fantastic	O
job	O
copy-editing	O
the	O
book	O
and	O
suggesting	O
many	O
useful	O
improvements	O
and	O
wayne	O
wheeler	O
and	O
simon	O
rees	O
at	O
springer	O
were	O
most	O
helpful	O
throughout	O
the	O
whole	O
book	O
pub-	O
lishing	O
process	O
.	O
keith	O
price	O
’	O
s	O
annotated	O
computer	O
vision	O
bibliography	O
was	O
invaluable	O
in	O
preface	O
xi	O
tracking	O
down	O
references	B
and	O
ﬁnding	O
related	O
work	O
.	O
if	O
you	O
have	O
any	O
suggestions	O
for	O
improving	O
the	O
book	O
,	O
please	O
send	O
me	O
an	O
e-mail	O
,	O
as	O
i	O
would	O
like	O
to	O
keep	O
the	O
book	O
as	O
accurate	O
,	O
informative	O
,	O
and	O
timely	O
as	O
possible	O
.	O
lastly	O
,	O
this	O
book	O
would	O
not	O
have	O
been	O
possible	O
or	O
worthwhile	O
without	O
the	O
incredible	O
sup-	O
i	O
dedicate	O
this	O
book	O
to	O
my	O
parents	O
,	O
zdzisław	O
and	O
port	O
and	O
encouragement	O
of	O
my	O
family	O
.	O
jadwiga	O
,	O
whose	O
love	O
,	O
generosity	O
,	O
and	O
accomplishments	O
have	O
always	O
inspired	O
me	O
;	O
to	O
my	O
sis-	O
ter	O
basia	O
for	O
her	O
lifelong	O
friendship	O
;	O
and	O
especially	O
to	O
lyn	O
,	O
anne	O
,	O
and	O
stephen	O
,	O
whose	O
daily	O
encouragement	O
in	O
all	O
matters	O
(	O
including	O
this	O
book	O
project	O
)	O
makes	O
it	O
all	O
worthwhile	O
.	O
lake	O
wenatchee	O
august	O
,	O
2010	O
xii	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
contents	O
preface	O
contents	O
1	O
2	O
introduction	O
1.1	O
what	O
is	O
computer	O
vision	O
?	O
.	O
.	O
.	O
1.2	O
a	O
brief	O
history	O
.	O
.	O
.	O
.	O
1.3	O
book	O
overview	O
.	O
.	O
1.4	O
sample	O
syllabus	O
.	O
.	O
.	O
1.5	O
a	O
note	O
on	O
notation	O
.	O
1.6	O
additional	O
reading	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
2.1.1	O
geometric	B
primitives	O
.	O
.	O
2.1.2	O
2d	O
transformations	O
.	O
2.1.3	O
.	O
3d	O
transformations	O
.	O
3d	O
rotations	O
.	O
2.1.4	O
.	O
.	O
3d	O
to	O
2d	O
projections	B
.	O
2.1.5	O
2.1.6	O
lens	O
distortions	O
.	O
.	O
2.2	O
photometric	B
image	O
formation	O
.	O
.	O
image	B
formation	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
2.2.1	O
lighting	B
.	O
.	O
2.2.2	O
reﬂectance	B
and	O
shading	B
.	O
2.2.3	O
optics	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
2.3	O
the	O
digital	O
camera	O
.	O
.	O
sampling	B
and	O
aliasing	B
.	O
.	O
.	O
2.3.1	O
2.3.2	O
color	B
.	O
2.3.3	O
compression	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
vii	O
xiii	O
1	O
3	O
10	O
19	O
26	O
27	O
28	O
29	O
31	O
32	O
35	O
39	O
41	O
46	O
58	O
60	O
60	O
62	O
68	O
73	O
77	O
80	O
90	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
xiv	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
2.4	O
additional	O
reading	O
.	O
.	O
2.5	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3	O
image	B
processing	O
3.1	O
point	O
operators	O
3.2	O
linear	B
ﬁltering	O
.	O
.	O
.	O
.	O
3.3	O
more	O
neighborhood	B
operators	O
.	O
.	O
.	O
.	O
.	O
3.4	O
fourier	O
transforms	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
pixel	O
transforms	O
.	O
separable	B
ﬁltering	O
.	O
.	O
.	O
3.3.1	O
non-linear	B
ﬁltering	O
.	O
.	O
3.3.2	O
morphology	O
.	O
.	O
.	O
3.3.3	O
distance	O
transforms	O
.	O
3.3.4	O
connected	B
components	I
.	O
.	O
fourier	O
transform	B
pairs	O
.	O
.	O
.	O
.	O
.	O
.	O
3.1.1	O
.	O
.	O
3.1.2	O
color	B
transforms	O
.	O
.	O
.	O
3.1.3	O
compositing	B
and	O
matting	B
.	O
.	O
3.1.4	O
histogram	B
equalization	O
.	O
.	O
3.1.5	O
application	O
:	O
tonal	B
adjustment	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.2.1	O
.	O
.	O
3.2.2	O
examples	B
of	O
linear	B
ﬁltering	O
.	O
.	O
3.2.3	O
band-pass	B
and	O
steerable	B
ﬁlters	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.4.1	O
.	O
.	O
3.4.2	O
two-dimensional	B
fourier	O
transforms	O
.	O
.	O
3.4.3	O
wiener	O
ﬁltering	O
.	O
.	O
3.4.4	O
application	O
:	O
sharpening	O
,	O
blur	O
,	O
and	O
noise	B
removal	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.5.1	O
.	O
3.5.2	O
decimation	O
.	O
.	O
3.5.3	O
multi-resolution	O
representations	O
.	O
.	O
3.5.4	O
wavelets	O
.	O
3.5.5	O
application	O
:	O
image	B
blending	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.6.1	O
3.6.2	O
mesh-based	O
warping	O
.	O
.	O
3.6.3	O
application	O
:	O
feature-based	B
morphing	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.7.1	O
regularization	B
.	O
.	O
3.7.2	O
markov	O
random	O
ﬁelds	O
.	O
3.7.3	O
application	O
:	O
image	B
restoration	I
.	O
.	O
parametric	B
transformations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.5	O
pyramids	O
and	O
wavelets	O
.	O
.	O
.	O
interpolation	B
.	O
.	O
3.6	O
geometric	B
transformations	O
.	O
3.7	O
global	B
optimization	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
93	O
93	O
99	O
.	O
101	O
.	O
103	O
.	O
104	O
.	O
105	O
.	O
107	O
.	O
111	O
.	O
111	O
.	O
115	O
.	O
117	O
.	O
118	O
.	O
122	O
.	O
122	O
.	O
127	O
.	O
129	O
.	O
131	O
.	O
132	O
.	O
136	O
.	O
140	O
.	O
140	O
.	O
144	O
.	O
144	O
.	O
145	O
.	O
148	O
.	O
150	O
.	O
154	O
.	O
160	O
.	O
162	O
.	O
163	O
.	O
170	O
.	O
173	O
.	O
174	O
.	O
174	O
.	O
180	O
.	O
192	O
contents	O
3.8	O
additional	O
reading	O
.	O
.	O
3.9	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
4.2	O
edges	O
.	O
.	O
4.1	O
points	B
and	O
patches	O
.	O
4	O
feature	B
detection	O
and	O
matching	B
.	O
.	O
feature	B
detectors	O
.	O
.	O
feature	B
descriptors	O
.	O
.	O
feature	B
matching	O
.	O
feature	B
tracking	O
.	O
.	O
.	O
4.1.1	O
.	O
4.1.2	O
.	O
4.1.3	O
.	O
4.1.4	O
.	O
4.1.5	O
application	O
:	O
performance-driven	B
animation	I
.	O
.	O
.	O
.	O
4.2.1	O
edge	O
detection	O
.	O
4.2.2	O
edge	O
linking	O
.	O
.	O
.	O
4.2.3	O
application	O
:	O
edge	B
editing	I
and	O
enhancement	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
4.3	O
lines	B
.	O
4.3.1	O
.	O
4.3.2	O
hough	O
transforms	O
.	O
4.3.3	O
vanishing	B
points	I
.	O
.	O
4.3.4	O
application	O
:	O
rectangle	O
detection	B
.	O
.	O
.	O
.	O
.	O
.	O
successive	B
approximation	I
.	O
.	O
.	O
4.4	O
additional	O
reading	O
.	O
.	O
4.5	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5	O
segmentation	B
5.1	O
active	B
contours	I
.	O
.	O
snakes	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
scissors	O
.	O
.	O
.	O
.	O
5.1.1	O
.	O
.	O
5.1.2	O
dynamic	B
snakes	O
and	O
condensation	O
.	O
.	O
.	O
5.1.3	O
.	O
5.1.4	O
level	B
sets	I
.	O
.	O
.	O
5.1.5	O
application	O
:	O
contour	O
tracking	O
and	O
rotoscoping	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5.2.1	O
watershed	B
.	O
.	O
5.2.2	O
region	B
splitting	O
(	O
divisive	B
clustering	O
)	O
.	O
.	O
5.2.3	O
region	B
merging	O
(	O
agglomerative	B
clustering	O
)	O
5.2.4	O
graph-based	B
segmentation	O
.	O
.	O
.	O
.	O
5.2.5	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5.3.1	O
k-means	B
and	O
mixtures	O
of	O
gaussians	O
.	O
5.3.2	O
mean	B
shift	I
.	O
probabilistic	B
aggregation	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5.2	O
split	O
and	O
merge	O
.	O
5.3	O
mean	B
shift	I
and	O
mode	O
ﬁnding	O
.	O
xv	O
.	O
192	O
.	O
194	O
205	O
.	O
207	O
.	O
209	O
.	O
222	O
.	O
225	O
.	O
235	O
.	O
237	O
.	O
238	O
.	O
238	O
.	O
244	O
.	O
249	O
.	O
250	O
.	O
250	O
.	O
251	O
.	O
254	O
.	O
257	O
.	O
257	O
.	O
259	O
267	O
.	O
270	O
.	O
270	O
.	O
276	O
.	O
280	O
.	O
281	O
.	O
282	O
.	O
284	O
.	O
284	O
.	O
286	O
.	O
286	O
.	O
286	O
.	O
288	O
.	O
289	O
.	O
289	O
.	O
292	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
xvi	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5.4	O
normalized	B
cuts	I
.	O
5.5	O
graph	B
cuts	I
and	O
energy-based	B
methods	O
.	O
.	O
.	O
5.5.1	O
application	O
:	O
medical	B
image	I
segmentation	O
.	O
.	O
.	O
5.6	O
additional	O
reading	O
.	O
5.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6	O
feature-based	B
alignment	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6.1	O
6.2	O
pose	O
estimation	B
.	O
iterative	B
algorithms	O
.	O
3d	O
alignment	B
.	O
.	O
.	O
.	O
.	O
iterative	B
algorithms	O
.	O
.	O
2d	O
alignment	B
using	O
least	B
squares	I
.	O
.	O
.	O
.	O
2d	O
and	O
3d	O
feature-based	B
alignment	O
.	O
6.1.1	O
6.1.2	O
application	O
:	O
panography	B
.	O
.	O
6.1.3	O
.	O
.	O
6.1.4	O
robust	B
least	O
squares	O
and	O
ransac	O
.	O
.	O
6.1.5	O
.	O
.	O
.	O
.	O
.	O
6.3.1	O
calibration	B
patterns	O
.	O
.	O
6.3.2	O
vanishing	B
points	I
.	O
.	O
6.3.3	O
application	O
:	O
single	O
view	O
metrology	O
.	O
.	O
6.3.4	O
rotational	B
motion	I
.	O
6.3.5	O
radial	B
distortion	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6.2.1	O
linear	B
algorithms	O
.	O
.	O
6.2.2	O
6.2.3	O
application	O
:	O
augmented	B
reality	I
.	O
.	O
.	O
.	O
6.3	O
geometric	B
intrinsic	O
calibration	B
.	O
.	O
.	O
6.4	O
additional	O
reading	O
.	O
6.5	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7	O
structure	B
from	I
motion	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.1	O
triangulation	B
.	O
.	O
7.2	O
two-frame	B
structure	O
from	O
motion	B
.	O
7.2.1	O
7.2.2	O
.	O
7.2.3	O
application	O
:	O
view	B
morphing	I
.	O
.	O
.	O
.	O
projective	B
(	O
uncalibrated	O
)	O
reconstruction	O
.	O
self-calibration	B
.	O
.	O
.	O
.	O
perspective	B
and	O
projective	B
factorization	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.3.1	O
7.3.2	O
application	O
:	O
sparse	B
3d	O
model	O
extraction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.4.1	O
exploiting	O
sparsity	O
.	O
.	O
7.4.2	O
application	O
:	O
match	B
move	I
and	O
augmented	B
reality	I
.	O
7.4	O
bundle	B
adjustment	I
7.3	O
factorization	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
296	O
.	O
300	O
.	O
304	O
.	O
305	O
.	O
306	O
309	O
.	O
311	O
.	O
312	O
.	O
314	O
.	O
315	O
.	O
318	O
.	O
320	O
.	O
321	O
.	O
322	O
.	O
324	O
.	O
326	O
.	O
327	O
.	O
327	O
.	O
329	O
.	O
331	O
.	O
332	O
.	O
334	O
.	O
335	O
.	O
336	O
343	O
.	O
345	O
.	O
347	O
.	O
353	O
.	O
355	O
.	O
357	O
.	O
357	O
.	O
360	O
.	O
362	O
.	O
363	O
.	O
364	O
.	O
368	O
contents	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.4.3	O
uncertainty	B
and	O
ambiguities	O
.	O
7.4.4	O
application	O
:	O
reconstruction	O
from	O
internet	O
photos	O
.	O
.	O
.	O
.	O
.	O
.	O
7.5	O
constrained	B
structure	O
and	O
motion	B
.	O
.	O
.	O
.	O
.	O
.	O
plane-based	B
techniques	O
.	O
.	O
.	O
7.5.1	O
line-based	B
techniques	O
7.5.2	O
7.6	O
additional	O
reading	O
.	O
7.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8	O
dense	O
motion	O
estimation	B
8.1	O
translational	B
alignment	O
.	O
8.2	O
parametric	B
motion	O
.	O
8.3	O
spline-based	B
motion	O
.	O
8.4	O
optical	B
ﬂow	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
fourier-based	O
alignment	B
incremental	O
reﬁnement	O
.	O
.	O
.	O
8.1.1	O
hierarchical	B
motion	O
estimation	B
.	O
8.1.2	O
.	O
.	O
8.1.3	O
.	O
.	O
.	O
.	O
.	O
.	O
8.2.1	O
application	O
:	O
video	B
stabilization	I
.	O
8.2.2	O
learned	B
motion	O
models	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8.3.1	O
application	O
:	O
medical	B
image	I
registration	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8.5.1	O
application	O
:	O
frame	B
interpolation	I
.	O
.	O
8.5.2	O
transparent	B
layers	O
and	O
reﬂections	B
.	O
.	O
.	O
.	O
8.4.1	O
multi-frame	B
motion	O
estimation	B
.	O
8.4.2	O
application	O
:	O
video	B
denoising	I
.	O
8.4.3	O
application	O
:	O
de-interlacing	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8.5	O
layered	B
motion	O
.	O
8.6	O
additional	O
reading	O
.	O
8.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
xvii	O
.	O
370	O
.	O
371	O
.	O
374	O
.	O
374	O
.	O
376	O
.	O
377	O
.	O
377	O
381	O
.	O
384	O
.	O
387	O
.	O
388	O
.	O
392	O
.	O
398	O
.	O
401	O
.	O
403	O
.	O
404	O
.	O
408	O
.	O
409	O
.	O
413	O
.	O
414	O
.	O
415	O
.	O
415	O
.	O
418	O
.	O
419	O
.	O
421	O
.	O
422	O
427	O
.	O
430	O
.	O
431	O
.	O
432	O
.	O
433	O
.	O
435	O
.	O
436	O
.	O
438	O
.	O
441	O
.	O
441	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9	O
image	B
stitching	I
9.1	O
motion	B
models	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
planar	B
perspective	I
motion	I
.	O
.	O
.	O
.	O
9.1.1	O
.	O
9.1.2	O
application	O
:	O
whiteboard	B
and	I
document	I
scanning	I
.	O
.	O
.	O
.	O
9.1.3	O
rotational	O
panoramas	O
.	O
.	O
9.1.4	O
gap	B
closing	I
.	O
.	O
.	O
9.1.5	O
application	O
:	O
video	B
summarization	I
and	O
compression	B
.	O
.	O
9.1.6	O
cylindrical	B
and	O
spherical	B
coordinates	O
.	O
.	O
.	O
.	O
.	O
.	O
9.2.1	O
bundle	B
adjustment	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9.2	O
global	B
alignment	I
xviii	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
parallax	B
removal	I
9.3	O
compositing	B
.	O
.	O
.	O
9.2.2	O
9.2.3	O
recognizing	B
panoramas	I
.	O
9.2.4	O
direct	B
vs.	I
feature-based	I
alignment	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
pixel	B
selection	I
and	O
weighting	B
(	O
de-ghosting	B
)	O
.	O
.	O
.	O
.	O
.	O
.	O
9.3.1	O
choosing	O
a	O
compositing	B
surface	O
.	O
9.3.2	O
9.3.3	O
application	O
:	O
photomontage	O
.	O
9.3.4	O
blending	B
.	O
.	O
.	O
.	O
9.4	O
additional	O
reading	O
.	O
.	O
9.5	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
445	O
.	O
446	O
.	O
450	O
.	O
450	O
.	O
451	O
.	O
453	O
.	O
459	O
.	O
459	O
.	O
462	O
.	O
463	O
467	O
.	O
470	O
.	O
470	O
.	O
473	O
.	O
474	O
.	O
476	O
.	O
479	O
.	O
487	O
.	O
494	O
.	O
497	O
.	O
502	O
.	O
504	O
.	O
505	O
.	O
507	O
.	O
509	O
.	O
513	O
.	O
516	O
.	O
518	O
.	O
518	O
.	O
521	O
.	O
522	O
.	O
524	O
.	O
526	O
533	O
.	O
537	O
.	O
538	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10	O
computational	O
photography	O
10.1	O
photometric	B
calibration	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.3	O
super-resolution	O
and	O
blur	B
removal	I
10.2	O
high	B
dynamic	I
range	I
imaging	O
.	O
.	O
.	O
10.2.1	O
tone	B
mapping	I
.	O
.	O
10.2.2	O
application	O
:	O
flash	O
photography	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.3.1	O
color	B
image	O
demosaicing	B
.	O
10.3.2	O
application	O
:	O
colorization	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.1.1	O
radiometric	B
response	O
function	O
.	O
.	O
.	O
10.1.2	O
noise	B
level	O
estimation	B
.	O
.	O
10.1.3	O
vignetting	B
.	O
.	O
.	O
10.1.4	O
optical	B
blur	I
(	O
spatial	O
response	O
)	O
estimation	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.5.1	O
application	O
:	O
hole	B
ﬁlling	I
and	O
inpainting	B
.	O
.	O
10.5.2	O
application	O
:	O
non-photorealistic	B
rendering	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.4	O
image	B
matting	O
and	O
compositing	B
.	O
.	O
.	O
10.4.1	O
blue	B
screen	I
matting	O
.	O
.	O
.	O
10.4.2	O
natural	B
image	O
matting	B
.	O
.	O
.	O
10.4.3	O
optimization-based	B
matting	O
.	O
.	O
10.4.4	O
smoke	B
,	O
shadow	B
,	O
and	O
ﬂash	B
matting	O
.	O
.	O
10.4.5	O
video	B
matting	O
.	O
.	O
.	O
10.5	O
texture	B
analysis	O
and	O
synthesis	O
10.6	O
additional	O
reading	O
.	O
10.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11	O
stereo	B
correspondence	O
11.1	O
epipolar	B
geometry	I
.	O
.	O
11.1.1	O
rectiﬁcation	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
contents	O
11.4	O
local	B
methods	I
.	O
11.5	O
global	B
optimization	I
.	O
11.3	O
dense	B
correspondence	I
.	O
.	O
11.1.2	O
plane	B
sweep	I
.	O
.	O
11.2	O
sparse	B
correspondence	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.3.1	O
similarity	B
measures	O
.	O
.	O
.	O
.	O
11.2.1	O
3d	O
curves	O
and	O
proﬁles	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.4.1	O
sub-pixel	O
estimation	O
and	O
uncertainty	B
.	O
.	O
11.4.2	O
application	O
:	O
stereo-based	O
head	B
tracking	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.5.1	O
dynamic	B
programming	I
.	O
.	O
11.5.2	O
segmentation-based	B
techniques	O
.	O
11.5.3	O
application	O
:	O
z-keying	B
and	O
background	B
replacement	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.6.1	O
volumetric	B
and	O
3d	O
surface	B
reconstruction	I
.	O
.	O
11.6.2	O
shape	O
from	O
silhouettes	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.7	O
additional	O
reading	O
.	O
.	O
11.8	O
exercises	O
.	O
.	O
.	O
.	O
.	O
11.6	O
multi-view	B
stereo	I
.	O
.	O
.	O
12	O
3d	O
reconstruction	O
12.1	O
shape	O
from	O
x	O
.	O
12.2	O
active	O
rangeﬁnding	O
.	O
12.3	O
surface	B
representations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.2.1	O
range	O
data	O
merging	B
.	O
.	O
12.2.2	O
application	O
:	O
digital	B
heritage	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.1.1	O
shape	O
from	O
shading	B
and	O
photometric	B
stereo	I
.	O
.	O
12.1.2	O
shape	O
from	O
texture	B
.	O
12.1.3	O
shape	O
from	O
focus	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.5.1	O
implicit	O
surfaces	O
and	O
level	B
sets	I
.	O
.	O
.	O
.	O
.	O
12.6.1	O
architecture	B
.	O
.	O
.	O
12.6.2	O
heads	B
and	I
faces	I
.	O
.	O
12.6.3	O
application	O
:	O
facial	B
animation	I
.	O
.	O
12.6.4	O
whole	O
body	B
modeling	O
and	O
tracking	O
.	O
.	O
.	O
12.3.1	O
surface	B
interpolation	O
.	O
.	O
12.3.2	O
surface	B
simpliﬁcation	O
.	O
12.3.3	O
geometry	O
images	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.6	O
model-based	B
reconstruction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.4	O
point-based	B
representations	O
.	O
12.5	O
volumetric	B
representations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
xix	O
.	O
540	O
.	O
543	O
.	O
543	O
.	O
545	O
.	O
546	O
.	O
548	O
.	O
550	O
.	O
551	O
.	O
552	O
.	O
554	O
.	O
556	O
.	O
558	O
.	O
558	O
.	O
562	O
.	O
567	O
.	O
570	O
.	O
571	O
577	O
.	O
580	O
.	O
580	O
.	O
583	O
.	O
584	O
.	O
585	O
.	O
588	O
.	O
590	O
.	O
591	O
.	O
592	O
.	O
594	O
.	O
594	O
.	O
595	O
.	O
596	O
.	O
596	O
.	O
598	O
.	O
598	O
.	O
601	O
.	O
603	O
.	O
605	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
xx	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
12.7	O
recovering	O
texture	B
maps	O
and	O
albedos	O
.	O
.	O
12.7.1	O
estimating	O
brdfs	O
.	O
.	O
12.7.2	O
application	O
:	O
3d	O
photography	O
.	O
.	O
.	O
12.8	O
additional	O
reading	O
.	O
12.9	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13	O
image-based	B
rendering	I
13.1	O
view	B
interpolation	I
.	O
13.2	O
layered	O
depth	O
images	O
.	O
13.3	O
light	O
ﬁelds	O
and	O
lumigraphs	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13.1.1	O
view-dependent	B
texture	I
maps	I
13.1.2	O
application	O
:	O
photo	O
tourism	O
.	O
.	O
13.2.1	O
impostors	B
,	O
sprites	B
,	O
and	O
layers	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13.3.1	O
unstructured	B
lumigraph	O
.	O
13.3.2	O
surface	O
light	O
ﬁelds	O
.	O
.	O
.	O
13.3.3	O
application	O
:	O
concentric	O
mosaics	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13.4.1	O
higher-dimensional	O
light	O
ﬁelds	O
.	O
.	O
13.4.2	O
the	O
modeling	B
to	O
rendering	B
continuum	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13.5.1	O
video-based	O
animation	O
.	O
.	O
13.5.2	O
video	B
textures	I
.	O
.	O
13.5.3	O
application	O
:	O
animating	B
pictures	I
.	O
.	O
13.5.4	O
3d	O
video	B
.	O
.	O
.	O
13.5.5	O
application	O
:	O
video-based	B
walkthroughs	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13.4	O
environment	O
mattes	O
.	O
13.5	O
video-based	O
rendering	O
.	O
13.6	O
additional	O
reading	O
.	O
13.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
14	O
recognition	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.1	O
object	O
detection	B
.	O
.	O
.	O
14.1.1	O
face	B
detection	O
.	O
.	O
14.1.2	O
pedestrian	B
detection	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.2	O
face	B
recognition	O
.	O
.	O
14.2.1	O
eigenfaces	O
14.2.2	O
active	O
appearance	O
and	O
3d	O
shape	O
models	O
.	O
14.2.3	O
application	O
:	O
personal	O
photo	O
collections	O
.	O
.	O
.	O
.	O
14.3.1	O
geometric	B
alignment	I
.	O
14.3	O
instance	B
recognition	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
610	O
.	O
612	O
.	O
613	O
.	O
614	O
.	O
616	O
619	O
.	O
621	O
.	O
623	O
.	O
624	O
.	O
626	O
.	O
626	O
.	O
628	O
.	O
632	O
.	O
632	O
.	O
634	O
.	O
634	O
.	O
636	O
.	O
637	O
.	O
638	O
.	O
639	O
.	O
640	O
.	O
643	O
.	O
643	O
.	O
645	O
.	O
648	O
.	O
650	O
655	O
.	O
658	O
.	O
658	O
.	O
666	O
.	O
668	O
.	O
671	O
.	O
679	O
.	O
684	O
.	O
685	O
.	O
686	O
contents	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.3.2	O
large	O
databases	O
.	O
.	O
14.3.3	O
application	O
:	O
location	B
recognition	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.4	O
category	O
recognition	O
.	O
.	O
.	O
14.4.1	O
bag	B
of	I
words	I
.	O
.	O
.	O
.	O
14.4.2	O
part-based	B
models	O
14.4.3	O
recognition	B
with	O
segmentation	B
.	O
.	O
14.4.4	O
application	O
:	O
intelligent	B
photo	I
editing	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.5.1	O
learning	B
and	O
large	O
image	O
collections	O
14.5.2	O
application	O
:	O
image	B
search	I
.	O
.	O
.	O
14.6	O
recognition	B
databases	O
and	O
test	O
sets	O
.	O
14.7	O
additional	O
reading	O
.	O
.	O
.	O
.	O
.	O
.	O
14.8	O
exercises	O
14.5	O
context	B
and	O
scene	B
understanding	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
15	O
conclusion	O
a	O
linear	B
algebra	O
and	O
numerical	O
techniques	O
.	O
.	O
a.1	O
matrix	B
decompositions	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
a.2	O
linear	B
least	O
squares	O
.	O
.	O
a.1.1	O
singular	O
value	O
decomposition	O
.	O
a.1.2	O
eigenvalue	O
decomposition	O
.	O
.	O
.	O
.	O
a.1.3	O
qr	O
factorization	B
.	O
.	O
.	O
.	O
a.1.4	O
cholesky	O
factorization	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
a.2.1	O
total	B
least	O
squares	O
.	O
.	O
a.3	O
non-linear	B
least	O
squares	O
.	O
.	O
.	O
.	O
a.4	O
direct	B
sparse	O
matrix	O
techniques	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
a.4.1	O
variable	O
reordering	O
.	O
.	O
.	O
.	O
.	O
.	O
a.5.1	O
conjugate	B
gradient	I
.	O
a.5.2	O
preconditioning	O
.	O
a.5.3	O
multigrid	O
.	O
.	O
.	O
a.5	O
iterative	B
techniques	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
b	O
bayesian	O
modeling	B
and	O
inference	B
.	O
b.1	O
estimation	B
theory	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
b.1.1	O
likelihood	O
for	O
multivariate	O
gaussian	O
noise	B
b.2	O
maximum	O
likelihood	O
estimation	B
and	O
least	B
squares	I
.	O
.	O
b.3	O
robust	B
statistics	O
.	O
.	O
.	O
b.4	O
prior	B
models	O
and	O
bayesian	O
inference	B
.	O
b.5	O
markov	O
random	O
ﬁelds	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
xxi	O
.	O
687	O
.	O
693	O
.	O
696	O
.	O
697	O
.	O
701	O
.	O
704	O
.	O
709	O
.	O
712	O
.	O
714	O
.	O
717	O
.	O
718	O
.	O
722	O
.	O
725	O
731	O
735	O
.	O
736	O
.	O
736	O
.	O
737	O
.	O
740	O
.	O
741	O
.	O
742	O
.	O
744	O
.	O
746	O
.	O
747	O
.	O
748	O
.	O
748	O
.	O
749	O
.	O
751	O
.	O
753	O
755	O
.	O
757	O
.	O
757	O
.	O
759	O
.	O
760	O
.	O
762	O
.	O
763	O
xxii	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
b.5.1	O
gradient	B
descent	I
and	O
simulated	B
annealing	I
.	O
b.5.2	O
dynamic	B
programming	I
.	O
.	O
.	O
.	O
.	O
b.5.3	O
belief	B
propagation	I
.	O
.	O
.	O
b.5.4	O
graph	B
cuts	I
.	O
.	O
b.5.5	O
linear	O
programming	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
b.6	O
uncertainty	B
estimation	O
(	O
error	O
analysis	O
)	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
c	O
supplementary	O
material	O
.	O
.	O
.	O
c.1	O
data	B
sets	I
.	O
c.2	O
software	O
.	O
.	O
c.3	O
slides	O
and	O
lectures	O
c.4	O
bibliography	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
references	B
index	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
765	O
.	O
766	O
.	O
768	O
.	O
770	O
.	O
773	O
.	O
775	O
777	O
.	O
778	O
.	O
780	O
.	O
789	O
.	O
790	O
791	O
933	O
chapter	O
1	O
introduction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3	O
10	O
19	O
26	O
27	O
28	O
1.1	O
what	O
is	O
computer	O
vision	O
?	O
.	O
.	O
.	O
1.2	O
a	O
brief	O
history	O
.	O
.	O
.	O
1.3	O
book	O
overview	O
.	O
.	O
.	O
1.4	O
sample	O
syllabus	O
.	O
.	O
.	O
1.5	O
a	O
note	O
on	O
notation	O
.	O
1.6	O
additional	O
reading	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
figure	O
1.1	O
the	O
human	O
visual	O
system	O
has	O
no	O
problem	O
interpreting	O
the	O
subtle	O
variations	O
in	O
translucency	O
and	O
shading	B
in	O
this	O
photograph	O
and	O
correctly	O
segmenting	O
the	O
object	O
from	O
its	O
background	O
.	O
2	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
1.2	O
some	O
examples	B
of	O
computer	O
vision	O
algorithms	O
and	O
applications	O
.	O
(	O
a	O
)	O
structure	B
from	I
motion	I
algorithms	O
can	O
reconstruct	O
a	O
sparse	B
3d	O
point	O
model	O
of	O
a	O
large	O
complex	O
scene	O
from	O
hundreds	O
of	O
partially	O
overlapping	O
photographs	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
acm	O
.	O
(	O
b	O
)	O
stereo	B
matching	I
algorithms	O
can	O
build	O
a	O
detailed	O
3d	O
model	O
of	O
a	O
building	O
fac¸ade	O
from	O
hundreds	O
of	O
differently	O
exposed	O
photographs	O
taken	O
from	O
the	O
internet	O
(	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
ieee	O
.	O
(	O
c	O
)	O
person	O
tracking	O
algorithms	O
can	O
track	O
a	O
person	O
walking	O
in	O
front	O
of	O
a	O
cluttered	O
background	O
(	O
sidenbladh	O
,	O
black	O
,	O
and	O
fleet	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
springer	O
.	O
(	O
d	O
)	O
face	B
detection	O
algorithms	O
,	O
coupled	O
with	O
color-based	O
clothing	O
and	O
hair	O
detection	B
algorithms	O
,	O
can	O
locate	O
and	O
recognize	O
the	O
individuals	O
in	O
this	O
image	B
(	O
sivic	O
,	O
zitnick	O
,	O
and	O
szeliski	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
.	O
1.1	O
what	O
is	O
computer	O
vision	O
?	O
1.1	O
what	O
is	O
computer	O
vision	O
?	O
3	O
as	O
humans	O
,	O
we	O
perceive	O
the	O
three-dimensional	O
structure	O
of	O
the	O
world	O
around	O
us	O
with	O
apparent	O
ease	O
.	O
think	O
of	O
how	O
vivid	O
the	O
three-dimensional	O
percept	O
is	O
when	O
you	O
look	O
at	O
a	O
vase	O
of	O
ﬂowers	O
sitting	O
on	O
the	O
table	O
next	O
to	O
you	O
.	O
you	O
can	O
tell	O
the	O
shape	O
and	O
translucency	O
of	O
each	O
petal	O
through	O
the	O
subtle	O
patterns	B
of	O
light	O
and	O
shading	B
that	O
play	O
across	O
its	O
surface	B
and	O
effortlessly	O
segment	O
each	O
ﬂower	O
from	O
the	O
background	O
of	O
the	O
scene	O
(	O
figure	O
1.1	O
)	O
.	O
looking	O
at	O
a	O
framed	O
group	O
por-	O
trait	O
,	O
you	O
can	O
easily	O
count	O
(	O
and	O
name	O
)	O
all	O
of	O
the	O
people	O
in	O
the	O
picture	O
and	O
even	O
guess	O
at	O
their	O
emotions	O
from	O
their	O
facial	O
appearance	O
.	O
perceptual	O
psychologists	O
have	O
spent	O
decades	O
trying	O
to	O
understand	O
how	O
the	O
visual	O
system	O
works	O
and	O
,	O
even	O
though	O
they	O
can	O
devise	O
optical	O
illusions1	O
to	O
tease	O
apart	O
some	O
of	O
its	O
principles	O
(	O
figure	O
1.3	O
)	O
,	O
a	O
complete	O
solution	O
to	O
this	O
puzzle	O
remains	O
elusive	O
(	O
marr	O
1982	O
;	O
palmer	O
1999	O
;	O
livingstone	O
2008	O
)	O
.	O
researchers	O
in	O
computer	O
vision	O
have	O
been	O
developing	O
,	O
in	O
parallel	O
,	O
mathematical	O
tech-	O
niques	O
for	O
recovering	O
the	O
three-dimensional	O
shape	O
and	O
appearance	O
of	O
objects	O
in	O
imagery	O
.	O
we	O
now	O
have	O
reliable	O
techniques	O
for	O
accurately	O
computing	O
a	O
partial	O
3d	O
model	O
of	O
an	O
environment	O
from	O
thousands	O
of	O
partially	O
overlapping	O
photographs	O
(	O
figure	O
1.2a	O
)	O
.	O
given	O
a	O
large	O
enough	O
set	O
of	O
views	O
of	O
a	O
particular	O
object	O
or	O
fac¸ade	O
,	O
we	O
can	O
create	O
accurate	O
dense	O
3d	O
surface	B
mod-	O
els	O
using	O
stereo	O
matching	B
(	O
figure	O
1.2b	O
)	O
.	O
we	O
can	O
track	O
a	O
person	O
moving	O
against	O
a	O
complex	O
background	O
(	O
figure	O
1.2c	O
)	O
.	O
we	O
can	O
even	O
,	O
with	O
moderate	O
success	O
,	O
attempt	O
to	O
ﬁnd	O
and	O
name	O
all	O
of	O
the	O
people	O
in	O
a	O
photograph	O
using	O
a	O
combination	O
of	O
face	B
,	O
clothing	O
,	O
and	O
hair	O
detection	B
and	O
recognition	B
(	O
figure	O
1.2d	O
)	O
.	O
however	O
,	O
despite	O
all	O
of	O
these	O
advances	O
,	O
the	O
dream	O
of	O
having	O
a	O
computer	O
interpret	O
an	O
image	B
at	O
the	O
same	O
level	O
as	O
a	O
two-year	O
old	O
(	O
for	O
example	O
,	O
counting	O
all	O
of	O
the	O
animals	O
in	O
a	O
picture	O
)	O
remains	O
elusive	O
.	O
why	O
is	O
vision	O
so	O
difﬁcult	O
?	O
in	O
part	O
,	O
it	O
is	O
because	O
vision	O
is	O
an	O
inverse	B
problem	O
,	O
in	O
which	O
we	O
seek	O
to	O
recover	O
some	O
unknowns	O
given	O
insufﬁcient	O
information	O
to	O
fully	O
specify	O
the	O
solution	O
.	O
we	O
must	O
therefore	O
resort	O
to	O
physics-based	B
and	O
prob-	O
abilistic	O
models	O
to	O
disambiguate	O
between	O
potential	O
solutions	O
.	O
however	O
,	O
modeling	B
the	O
visual	O
world	O
in	O
all	O
of	O
its	O
rich	O
complexity	O
is	O
far	O
more	O
difﬁcult	O
than	O
,	O
say	O
,	O
modeling	B
the	O
vocal	O
tract	O
that	O
produces	O
spoken	O
sounds	O
.	O
the	O
forward	B
models	O
that	O
we	O
use	O
in	O
computer	O
vision	O
are	O
usually	O
developed	O
in	O
physics	O
(	O
ra-	O
diometry	O
,	O
optics	B
,	O
and	O
sensor	B
design	O
)	O
and	O
in	O
computer	O
graphics	O
.	O
both	O
of	O
these	O
ﬁelds	O
model	O
how	O
objects	O
move	O
and	O
animate	O
,	O
how	O
light	O
reﬂects	O
off	O
their	O
surfaces	O
,	O
is	O
scattered	O
by	O
the	O
at-	O
mosphere	O
,	O
refracted	O
through	O
camera	B
lenses	O
(	O
or	O
human	O
eyes	O
)	O
,	O
and	O
ﬁnally	O
projected	O
onto	O
a	O
ﬂat	O
(	O
or	O
curved	O
)	O
image	B
plane	O
.	O
while	O
computer	O
graphics	O
are	O
not	O
yet	O
perfect	O
(	O
no	O
fully	O
computer-	O
animated	O
movie	O
with	O
human	O
characters	O
has	O
yet	O
succeeded	O
at	O
crossing	O
the	O
uncanny	O
valley2	O
that	O
separates	O
real	O
humans	O
from	O
android	O
robots	O
and	O
computer-animated	O
humans	O
)	O
,	O
in	O
limited	O
1	O
http	O
:	O
//www.michaelbach.de/ot/sze	O
muelue	O
2	O
the	O
term	O
uncanny	O
valley	O
was	O
originally	O
coined	O
by	O
roboticist	O
masahiro	O
mori	O
as	O
applied	O
to	O
robotics	O
(	O
mori	O
1970	O
)	O
.	O
it	O
is	O
also	O
commonly	O
applied	O
to	O
computer-animated	O
ﬁlms	O
such	O
as	O
final	O
fantasy	O
and	O
polar	O
express	O
(	O
geller	O
2008	O
)	O
.	O
4	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
1.3	O
some	O
common	O
optical	O
illusions	O
and	O
what	O
they	O
might	O
tell	O
us	O
about	O
the	O
visual	O
sys-	O
tem	O
:	O
(	O
a	O
)	O
the	O
classic	O
m¨uller-lyer	O
illusion	O
,	O
where	O
the	O
length	O
of	O
the	O
two	O
horizontal	O
lines	B
appear	O
different	O
,	O
probably	O
due	O
to	O
the	O
imagined	O
perspective	B
effects	O
.	O
(	O
b	O
)	O
the	O
“	O
white	O
”	O
square	O
b	O
in	O
the	O
shadow	B
and	O
the	O
“	O
black	O
”	O
square	O
a	O
in	O
the	O
light	O
actually	O
have	O
the	O
same	O
absolute	O
intensity	O
value	O
.	O
the	O
percept	O
is	O
due	O
to	O
brightness	O
constancy	O
,	O
the	O
visual	O
system	O
’	O
s	O
attempt	O
to	O
discount	O
illumi-	O
nation	O
when	O
interpreting	O
colors	O
.	O
image	B
courtesy	O
of	O
ted	O
adelson	O
,	O
http	O
:	O
//web.mit.edu/persci/	O
people/adelson/checkershadow	O
illusion.html	O
.	O
(	O
c	O
)	O
a	O
variation	O
of	O
the	O
hermann	O
grid	O
illusion	O
,	O
courtesy	O
of	O
hany	O
farid	O
,	O
http	O
:	O
//www.cs.dartmouth.edu/∼farid/illusions/hermann.html	O
.	O
as	O
you	O
move	O
your	O
eyes	O
over	O
the	O
ﬁgure	O
,	O
gray	O
spots	O
appear	O
at	O
the	O
intersections	O
.	O
(	O
d	O
)	O
count	O
the	O
red	O
xs	O
in	O
the	O
left	O
half	O
of	O
the	O
ﬁgure	O
.	O
now	O
count	O
them	O
in	O
the	O
right	O
half	O
.	O
is	O
it	O
signiﬁcantly	O
harder	O
?	O
the	O
explanation	O
has	O
to	O
do	O
with	O
a	O
pop-out	O
effect	O
(	O
treisman	O
1985	O
)	O
,	O
which	O
tells	O
us	O
about	O
the	O
operations	O
of	O
parallel	O
perception	O
and	O
integration	O
pathways	O
in	O
the	O
brain	O
.	O
xxxxxxxoxoxoxxxxxxxxxxoxxxoxxxxxxxxoxxoxxoxxxxxxxxxoxooxxxxxxxxoxxoxxxxxxxxxxxoxxxoxxxxxxxxoxxoxxoxxxxxxxxoxxxoxxxxxxxxxxxooxxxxxxxxxxoxxxox	O
1.1	O
what	O
is	O
computer	O
vision	O
?	O
5	O
domains	O
,	O
such	O
as	O
rendering	B
a	O
still	O
scene	O
composed	O
of	O
everyday	O
objects	O
or	O
animating	O
extinct	O
creatures	O
such	O
as	O
dinosaurs	O
,	O
the	O
illusion	O
of	O
reality	O
is	O
perfect	O
.	O
in	O
computer	O
vision	O
,	O
we	O
are	O
trying	O
to	O
do	O
the	O
inverse	B
,	O
i.e.	O
,	O
to	O
describe	O
the	O
world	O
that	O
we	O
see	O
in	O
one	O
or	O
more	O
images	O
and	O
to	O
reconstruct	O
its	O
properties	B
,	O
such	O
as	O
shape	O
,	O
illumination	O
,	O
and	O
color	B
distributions	O
.	O
it	O
is	O
amazing	O
that	O
humans	O
and	O
animals	O
do	O
this	O
so	O
effortlessly	O
,	O
while	O
computer	O
vision	O
algorithms	O
are	O
so	O
error	O
prone	O
.	O
people	O
who	O
have	O
not	O
worked	O
in	O
the	O
ﬁeld	O
often	O
under-	O
estimate	O
the	O
difﬁculty	O
of	O
the	O
problem	O
.	O
(	O
colleagues	O
at	O
work	O
often	O
ask	O
me	O
for	O
software	O
to	O
ﬁnd	O
and	O
name	O
all	O
the	O
people	O
in	O
photos	O
,	O
so	O
they	O
can	O
get	O
on	O
with	O
the	O
more	O
“	O
interesting	O
”	O
work	O
.	O
)	O
this	O
misperception	O
that	O
vision	O
should	O
be	O
easy	O
dates	O
back	O
to	O
the	O
early	O
days	O
of	O
artiﬁcial	O
intelligence	O
(	O
see	O
section	O
1.2	O
)	O
,	O
when	O
it	O
was	O
initially	O
believed	O
that	O
the	O
cognitive	O
(	O
logic	O
proving	O
and	O
plan-	O
ning	O
)	O
parts	O
of	O
intelligence	O
were	O
intrinsically	O
more	O
difﬁcult	O
than	O
the	O
perceptual	O
components	O
(	O
boden	O
2006	O
)	O
.	O
the	O
good	O
news	O
is	O
that	O
computer	O
vision	O
is	O
being	O
used	O
today	O
in	O
a	O
wide	O
variety	O
of	O
real-world	O
applications	O
,	O
which	O
include	O
:	O
•	O
optical	O
character	O
recognition	B
(	O
ocr	O
)	O
:	O
reading	O
handwritten	O
postal	O
codes	O
on	O
letters	O
(	O
figure	O
1.4a	O
)	O
and	O
automatic	B
number	O
plate	O
recognition	B
(	O
anpr	O
)	O
;	O
•	O
machine	B
inspection	I
:	O
rapid	O
parts	O
inspection	O
for	O
quality	O
assurance	O
using	O
stereo	O
vision	O
with	O
specialized	O
illumination	O
to	O
measure	O
tolerances	O
on	O
aircraft	O
wings	O
or	O
auto	O
body	B
parts	O
(	O
figure	O
1.4b	O
)	O
or	O
looking	O
for	O
defects	O
in	O
steel	O
castings	O
using	O
x-ray	O
vision	O
;	O
•	O
retail	O
:	O
object	O
recognition	B
for	O
automated	B
checkout	O
lanes	O
(	O
figure	O
1.4c	O
)	O
;	O
•	O
3d	O
model	O
building	O
(	O
photogrammetry	B
)	O
:	O
fully	O
automated	B
construction	O
of	O
3d	O
models	O
from	O
aerial	O
photographs	O
used	O
in	O
systems	O
such	O
as	O
bing	O
maps	O
;	O
•	O
medical	B
imaging	I
:	O
registering	O
pre-operative	O
and	O
intra-operative	O
imagery	O
(	O
figure	O
1.4d	O
)	O
or	O
performing	O
long-term	O
studies	O
of	O
people	O
’	O
s	O
brain	O
morphology	O
as	O
they	O
age	O
;	O
•	O
automotive	B
safety	I
:	O
detecting	O
unexpected	O
obstacles	O
such	O
as	O
pedestrians	O
on	O
the	O
street	O
,	O
under	O
conditions	O
where	O
active	O
vision	O
techniques	O
such	O
as	O
radar	O
or	O
lidar	O
do	O
not	O
work	O
well	O
(	O
figure	O
1.4e	O
;	O
see	O
also	O
miller	O
,	O
campbell	O
,	O
huttenlocher	O
et	O
al	O
.	O
(	O
2008	O
)	O
;	O
montemerlo	O
,	O
becker	O
,	O
bhat	O
et	O
al	O
.	O
(	O
2008	O
)	O
;	O
urmson	O
,	O
anhalt	O
,	O
bagnell	O
et	O
al	O
.	O
(	O
2008	O
)	O
for	O
examples	O
of	O
fully	O
automated	B
driving	O
)	O
;	O
•	O
match	B
move	I
:	O
merging	B
computer-generated	O
imagery	O
(	O
cgi	O
)	O
with	O
live	O
action	O
footage	O
by	O
tracking	O
feature	B
points	O
in	O
the	O
source	O
video	B
to	O
estimate	O
the	O
3d	O
camera	B
motion	O
and	O
shape	O
of	O
the	O
environment	O
.	O
such	O
techniques	O
are	O
widely	O
used	O
in	O
hollywood	O
(	O
e.g.	O
,	O
in	O
movies	O
such	O
as	O
jurassic	O
park	O
)	O
(	O
roble	O
1999	O
;	O
roble	O
and	O
zafar	O
2009	O
)	O
;	O
they	O
also	O
require	O
the	O
use	O
of	O
precise	O
matting	B
to	O
insert	O
new	O
elements	O
between	O
foreground	O
and	O
background	O
elements	O
(	O
chuang	O
,	O
agarwala	O
,	O
curless	O
et	O
al	O
.	O
2002	O
)	O
.	O
6	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
e	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
(	O
f	O
)	O
figure	O
1.4	O
some	O
industrial	B
applications	O
of	O
computer	O
vision	O
:	O
(	O
a	O
)	O
optical	O
character	O
recognition	B
(	O
ocr	O
)	O
http	O
:	O
//yann.lecun.com/exdb/lenet/	O
;	O
(	O
b	O
)	O
mechanical	B
inspection	O
http	O
:	O
//www.cognitens	O
.	O
com/	O
;	O
(	O
c	O
)	O
retail	O
http	O
:	O
//www.evoretail.com/	O
;	O
(	O
d	O
)	O
medical	B
imaging	I
http	O
:	O
//www.clarontech.com/	O
;	O
(	O
e	O
)	O
automotive	B
safety	I
http	O
:	O
//www.mobileye.com/	O
;	O
(	O
f	O
)	O
surveillance	O
and	O
trafﬁc	O
monitoring	O
http	O
:	O
//www.honeywellvideo.com/	O
,	O
courtesy	O
of	O
honeywell	O
international	O
inc.	O
1.1	O
what	O
is	O
computer	O
vision	O
?	O
7	O
•	O
motion	B
capture	O
(	O
mocap	O
)	O
:	O
using	O
retro-reﬂective	O
markers	O
viewed	O
from	O
multiple	B
cam-	O
eras	O
or	O
other	O
vision-based	O
techniques	O
to	O
capture	O
actors	O
for	O
computer	O
animation	O
;	O
•	O
surveillance	O
:	O
monitoring	O
for	O
intruders	O
,	O
analyzing	O
highway	O
trafﬁc	O
(	O
figure	O
1.4f	O
)	O
,	O
and	O
monitoring	O
pools	O
for	O
drowning	O
victims	O
;	O
•	O
fingerprint	O
recognition	B
and	O
biometrics	B
:	O
for	O
automatic	O
access	O
authentication	O
as	O
well	O
as	O
forensic	O
applications	O
.	O
david	O
lowe	O
’	O
s	O
web	O
site	O
of	O
industrial	B
vision	O
applications	O
(	O
http	O
:	O
//www.cs.ubc.ca/spider/lowe/	O
vision.html	O
)	O
lists	O
many	O
other	O
interesting	O
industrial	B
applications	O
of	O
computer	O
vision	O
.	O
while	O
the	O
above	O
applications	O
are	O
all	O
extremely	O
important	O
,	O
they	O
mostly	O
pertain	O
to	O
fairly	O
specialized	O
kinds	O
of	O
imagery	O
and	O
narrow	O
domains	O
.	O
in	O
this	O
book	O
,	O
we	O
focus	B
more	O
on	O
broader	O
consumer-level	O
applications	O
,	O
such	O
as	O
fun	O
things	O
you	O
can	O
do	O
with	O
your	O
own	O
personal	O
photographs	O
and	O
video	B
.	O
these	O
include	O
:	O
•	O
stitching	O
:	O
turning	O
overlapping	O
photos	O
into	O
a	O
single	O
seamlessly	O
stitched	O
panorama	O
(	O
fig-	O
ure	O
1.5a	O
)	O
,	O
as	O
described	O
in	O
chapter	O
9	O
;	O
•	O
exposure	O
bracketing	O
:	O
merging	B
multiple	O
exposures	O
taken	O
under	O
challenging	O
lighting	B
conditions	O
(	O
strong	O
sunlight	O
and	O
shadows	O
)	O
into	O
a	O
single	O
perfectly	O
exposed	O
image	B
(	O
fig-	O
ure	O
1.5b	O
)	O
,	O
as	O
described	O
in	O
section	O
10.2	O
;	O
•	O
morphing	B
:	O
turning	O
a	O
picture	O
of	O
one	O
of	O
your	O
friends	O
into	O
another	O
,	O
using	O
a	O
seamless	O
morph	O
transition	O
(	O
figure	O
1.5c	O
)	O
;	O
•	O
3d	O
modeling	B
:	O
converting	O
one	O
or	O
more	O
snapshots	O
into	O
a	O
3d	O
model	O
of	O
the	O
object	O
or	O
person	O
you	O
are	O
photographing	O
(	O
figure	O
1.5d	O
)	O
,	O
as	O
described	O
in	O
section	O
12.6	O
•	O
video	B
match	O
move	O
and	O
stabilization	O
:	O
inserting	O
2d	O
pictures	O
or	O
3d	O
models	O
into	O
your	O
videos	O
by	O
automatically	O
tracking	O
nearby	O
reference	O
points	B
(	O
see	O
section	O
7.4.2	O
)	O
3	O
or	O
using	O
motion	O
estimates	O
to	O
remove	O
shake	O
from	O
your	O
videos	O
(	O
see	O
section	O
8.2.1	O
)	O
;	O
•	O
photo-based	O
walkthroughs	B
:	O
navigating	O
a	O
large	O
collection	O
of	O
photographs	O
,	O
such	O
as	O
the	O
interior	O
of	O
your	O
house	O
,	O
by	O
ﬂying	O
between	O
different	O
photos	O
in	O
3d	O
(	O
see	O
sections	O
13.1.2	O
and	O
13.5.5	O
)	O
•	O
face	B
detection	O
:	O
for	O
improved	O
camera	B
focusing	O
as	O
well	O
as	O
more	O
relevant	O
image	B
search-	O
ing	O
(	O
see	O
section	O
14.1.1	O
)	O
;	O
•	O
visual	O
authentication	O
:	O
automatically	O
logging	O
family	O
members	O
onto	O
your	O
home	O
com-	O
puter	O
as	O
they	O
sit	O
down	O
in	O
front	O
of	O
the	O
webcam	O
(	O
see	O
section	O
14.2	O
)	O
.	O
8	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
1.5	O
some	O
consumer	O
applications	O
of	O
computer	O
vision	O
:	O
(	O
a	O
)	O
image	B
stitching	I
:	O
merging	B
different	O
views	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
;	O
(	O
b	O
)	O
exposure	O
bracketing	O
:	O
merging	B
different	O
exposures	O
;	O
(	O
c	O
)	O
morphing	B
:	O
blending	B
between	O
two	O
photographs	O
(	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
morgan	O
kaufmann	O
;	O
(	O
d	O
)	O
turning	O
a	O
collection	O
of	O
photographs	O
into	O
a	O
3d	O
model	O
(	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
acm	O
.	O
1.1	O
what	O
is	O
computer	O
vision	O
?	O
9	O
the	O
great	O
thing	O
about	O
these	O
applications	O
is	O
that	O
they	O
are	O
already	O
familiar	O
to	O
most	O
students	O
;	O
they	O
are	O
,	O
at	O
least	O
,	O
technologies	O
that	O
students	O
can	O
immediately	O
appreciate	O
and	O
use	O
with	O
their	O
own	O
personal	O
media	O
.	O
since	O
computer	O
vision	O
is	O
a	O
challenging	O
topic	O
,	O
given	O
the	O
wide	O
range	O
of	O
mathematics	O
being	O
covered4	O
and	O
the	O
intrinsically	O
difﬁcult	O
nature	O
of	O
the	O
problems	O
being	O
solved	O
,	O
having	O
fun	O
and	O
relevant	O
problems	O
to	O
work	O
on	O
can	O
be	O
highly	O
motivating	O
and	O
inspiring	O
.	O
the	O
other	O
major	O
reason	O
why	O
this	O
book	O
has	O
a	O
strong	O
focus	B
on	O
applications	O
is	O
that	O
they	O
can	O
be	O
used	O
to	O
formulate	O
and	O
constrain	O
the	O
potentially	O
open-ended	O
problems	O
endemic	O
in	O
vision	O
.	O
for	O
example	O
,	O
if	O
someone	O
comes	O
to	O
me	O
and	O
asks	O
for	O
a	O
good	O
edge	O
detector	O
,	O
my	O
ﬁrst	O
question	O
is	O
usually	O
to	O
ask	O
why	O
?	O
what	O
kind	O
of	O
problem	O
are	O
they	O
trying	O
to	O
solve	O
and	O
why	O
do	O
they	O
believe	O
that	O
edge	O
detection	O
is	O
an	O
important	O
component	O
?	O
if	O
they	O
are	O
trying	O
to	O
locate	O
faces	B
,	O
i	O
usually	O
point	O
out	O
that	O
most	O
successful	O
face	B
detectors	O
use	O
a	O
combination	O
of	O
skin	O
color	B
detection	O
(	O
exer-	O
cise	O
2.8	O
)	O
and	O
simple	O
blob	O
features	O
section	O
14.1.1	O
;	O
they	O
do	O
not	O
rely	O
on	O
edge	O
detection	O
.	O
if	O
they	O
are	O
trying	O
to	O
match	O
door	O
and	O
window	O
edges	O
in	O
a	O
building	O
for	O
the	O
purpose	O
of	O
3d	O
reconstruction	O
,	O
i	O
tell	O
them	O
that	O
edges	O
are	O
a	O
ﬁne	O
idea	O
but	O
it	O
is	O
better	O
to	O
tune	O
the	O
edge	O
detector	O
for	O
long	O
edges	O
(	O
see	O
sections	O
3.2.3	O
and	O
4.2	O
)	O
and	O
link	O
them	O
together	O
into	O
straight	O
lines	B
with	O
common	O
vanishing	B
points	I
before	O
matching	B
(	O
see	O
section	O
4.3	O
)	O
.	O
thus	O
,	O
it	O
is	O
better	O
to	O
think	O
back	O
from	O
the	O
problem	O
at	O
hand	O
to	O
suitable	O
techniques	O
,	O
rather	O
than	O
to	O
grab	O
the	O
ﬁrst	O
technique	O
that	O
you	O
may	O
have	O
heard	O
of	O
.	O
this	O
kind	O
of	O
working	O
back	O
from	O
problems	O
to	O
solutions	O
is	O
typical	O
of	O
an	O
engineering	O
approach	O
to	O
the	O
study	O
of	O
vision	O
and	O
reﬂects	O
my	O
own	O
background	O
in	O
the	O
ﬁeld	O
.	O
first	O
,	O
i	O
come	O
up	O
with	O
a	O
detailed	O
problem	O
deﬁnition	O
and	O
decide	O
on	O
the	O
constraints	O
and	O
speciﬁcations	O
for	O
the	O
problem	O
.	O
then	O
,	O
i	O
try	O
to	O
ﬁnd	O
out	O
which	O
techniques	O
are	O
known	O
to	O
work	O
,	O
implement	O
a	O
few	O
of	O
these	O
,	O
evaluate	O
their	O
performance	O
,	O
and	O
ﬁnally	O
make	O
a	O
selection	O
.	O
in	O
order	B
for	O
this	O
process	O
to	O
work	O
,	O
it	O
is	O
important	O
to	O
have	O
realistic	O
test	O
data	O
,	O
both	O
synthetic	O
,	O
which	O
can	O
be	O
used	O
to	O
verify	O
correctness	O
and	O
analyze	O
noise	B
sensitivity	O
,	O
and	O
real-world	O
data	O
typical	O
of	O
the	O
way	O
the	O
system	O
will	O
ﬁnally	O
be	O
used	O
.	O
however	O
,	O
this	O
book	O
is	O
not	O
just	O
an	O
engineering	O
text	O
(	O
a	O
source	O
of	O
recipes	O
)	O
.	O
it	O
also	O
takes	O
a	O
scientiﬁc	O
approach	O
to	O
basic	O
vision	O
problems	O
.	O
here	O
,	O
i	O
try	O
to	O
come	O
up	O
with	O
the	O
best	O
possible	O
models	O
of	O
the	O
physics	O
of	O
the	O
system	O
at	O
hand	O
:	O
how	O
the	O
scene	O
is	O
created	O
,	O
how	O
light	O
interacts	O
with	O
the	O
scene	O
and	O
atmospheric	O
effects	O
,	O
and	O
how	O
the	O
sensors	O
work	O
,	O
including	O
sources	O
of	O
noise	B
and	O
uncertainty	B
.	O
the	O
task	O
is	O
then	O
to	O
try	O
to	O
invert	O
the	O
acquisition	O
process	O
to	O
come	O
up	O
with	O
the	O
best	O
possible	O
description	O
of	O
the	O
scene	O
.	O
the	O
book	O
often	O
uses	O
a	O
statistical	O
approach	O
to	O
formulating	O
and	O
solving	O
computer	O
vision	O
problems	O
.	O
where	O
appropriate	O
,	O
probability	O
distributions	O
are	O
used	O
to	O
model	O
the	O
scene	O
and	O
the	O
noisy	O
image	B
acquisition	O
process	O
.	O
the	O
association	O
of	O
prior	B
distributions	O
with	O
unknowns	O
is	O
often	O
3	O
for	O
a	O
fun	O
student	O
project	O
on	O
this	O
topic	O
,	O
see	O
the	O
“	O
photobook	O
”	O
project	O
at	O
http	O
:	O
//www.cc.gatech.edu/dvfx/videos/	O
dvfx2005.html	O
.	O
4	O
these	O
techniques	O
include	O
physics	O
,	O
euclidean	O
and	O
projective	B
geometry	O
,	O
statistics	O
,	O
and	O
optimization	O
.	O
they	O
make	O
computer	O
vision	O
a	O
fascinating	O
ﬁeld	O
to	O
study	O
and	O
a	O
great	O
way	O
to	O
learn	O
techniques	O
widely	O
applicable	O
in	O
other	O
ﬁelds	O
.	O
10	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
consider	O
a	O
robot	O
trying	O
to	O
estimate	O
the	O
distance	O
to	O
an	O
obstacle	O
:	O
called	O
bayesian	O
modeling	B
(	O
appendix	O
b	O
)	O
.	O
it	O
is	O
possible	O
to	O
associate	O
a	O
risk	O
or	O
loss	O
function	O
with	O
mis-estimating	O
the	O
answer	O
(	O
section	O
b.2	O
)	O
and	O
to	O
set	O
up	O
your	O
inference	B
algorithm	O
to	O
minimize	O
the	O
expected	O
risk	O
.	O
it	O
is	O
usually	O
safer	O
to	O
underestimate	O
than	O
to	O
overestimate	O
.	O
)	O
with	O
statistical	O
techniques	O
,	O
it	O
often	O
helps	O
to	O
gather	O
lots	O
of	O
training	O
data	O
from	O
which	O
to	O
learn	O
probabilistic	B
models	I
.	O
finally	O
,	O
statistical	O
approaches	O
enable	O
you	O
to	O
use	O
proven	O
inference	B
techniques	O
to	O
estimate	O
the	O
best	O
answer	O
(	O
or	O
distribution	O
of	O
answers	O
)	O
and	O
to	O
quantify	O
the	O
uncertainty	B
in	O
the	O
resulting	O
estimates	O
.	O
because	O
so	O
much	O
of	O
computer	O
vision	O
involves	O
the	O
solution	O
of	O
inverse	B
problems	O
or	O
the	O
esti-	O
mation	O
of	O
unknown	O
quantities	O
,	O
my	O
book	O
also	O
has	O
a	O
heavy	O
emphasis	O
on	O
algorithms	O
,	O
especially	O
those	O
that	O
are	O
known	O
to	O
work	O
well	O
in	O
practice	O
.	O
for	O
many	O
vision	O
problems	O
,	O
it	O
is	O
all	O
too	O
easy	O
to	O
come	O
up	O
with	O
a	O
mathematical	O
description	O
of	O
the	O
problem	O
that	O
either	O
does	O
not	O
match	O
realistic	O
real-world	O
conditions	O
or	O
does	O
not	O
lend	O
itself	O
to	O
the	O
stable	O
estimation	B
of	O
the	O
unknowns	O
.	O
what	O
we	O
need	O
are	O
algorithms	O
that	O
are	O
both	O
robust	B
to	O
noise	B
and	O
deviation	O
from	O
our	O
models	O
and	O
rea-	O
sonably	O
efﬁcient	O
in	O
terms	O
of	O
run-time	O
resources	O
and	O
space	O
.	O
in	O
this	O
book	O
,	O
i	O
go	O
into	O
these	O
issues	O
in	O
detail	O
,	O
using	O
bayesian	O
techniques	O
,	O
where	O
applicable	O
,	O
to	O
ensure	O
robustness	O
,	O
and	O
efﬁcient	O
search	O
,	O
minimization	O
,	O
and	O
linear	B
system	O
solving	O
algorithms	O
to	O
ensure	O
efﬁciency	B
.	O
most	O
of	O
the	O
algorithms	O
described	O
in	O
this	O
book	O
are	O
at	O
a	O
high	O
level	O
,	O
being	O
mostly	O
a	O
list	O
of	O
steps	O
that	O
have	O
to	O
be	O
ﬁlled	O
in	O
by	O
students	O
or	O
by	O
reading	O
more	O
detailed	O
descriptions	O
elsewhere	O
.	O
in	O
fact	O
,	O
many	O
of	O
the	O
algorithms	O
are	O
sketched	O
out	O
in	O
the	O
exercises	O
.	O
now	O
that	O
i	O
’	O
ve	O
described	O
the	O
goals	O
of	O
this	O
book	O
and	O
the	O
frameworks	O
that	O
i	O
use	O
,	O
i	O
devote	O
the	O
rest	O
of	O
this	O
chapter	O
to	O
two	O
additional	O
topics	O
.	O
section	O
1.2	O
is	O
a	O
brief	O
synopsis	O
of	O
the	O
history	O
of	O
computer	O
vision	O
.	O
it	O
can	O
easily	O
be	O
skipped	O
by	O
those	O
who	O
want	O
to	O
get	O
to	O
“	O
the	O
meat	O
”	O
of	O
the	O
new	O
material	O
in	O
this	O
book	O
and	O
do	O
not	O
care	O
as	O
much	O
about	O
who	O
invented	O
what	O
when	O
.	O
the	O
second	O
is	O
an	O
overview	O
of	O
the	O
book	O
’	O
s	O
contents	O
,	O
section	O
1.3	O
,	O
which	O
is	O
useful	O
reading	O
for	O
everyone	O
who	O
intends	O
to	O
make	O
a	O
study	O
of	O
this	O
topic	O
(	O
or	O
to	O
jump	O
in	O
partway	O
,	O
since	O
it	O
describes	O
chapter	O
inter-dependencies	O
)	O
.	O
this	O
outline	O
is	O
also	O
useful	O
for	O
instructors	O
looking	O
to	O
structure	O
one	O
or	O
more	O
courses	O
around	O
this	O
topic	O
,	O
as	O
it	O
provides	O
sample	O
curricula	O
based	O
on	O
the	O
book	O
’	O
s	O
contents	O
.	O
1.2	O
a	O
brief	O
history	O
in	O
this	O
section	O
,	O
i	O
provide	O
a	O
brief	O
personal	O
synopsis	O
of	O
the	O
main	O
developments	O
in	O
computer	O
vision	O
over	O
the	O
last	O
30	O
years	O
(	O
figure	O
1.6	O
)	O
;	O
at	O
least	O
,	O
those	O
that	O
i	O
ﬁnd	O
personally	O
interesting	O
and	O
which	O
appear	O
to	O
have	O
stood	O
the	O
test	O
of	O
time	O
.	O
readers	O
not	O
interested	O
in	O
the	O
provenance	O
of	O
various	O
ideas	O
and	O
the	O
evolution	B
of	O
this	O
ﬁeld	O
should	O
skip	O
ahead	O
to	O
the	O
book	O
overview	O
in	O
section	O
1.3	O
.	O
1.2	O
a	O
brief	O
history	O
11	O
figure	O
1.6	O
a	O
rough	O
timeline	O
of	O
some	O
of	O
the	O
most	O
active	O
topics	O
of	O
research	O
in	O
computer	O
vision	O
.	O
1970s	O
.	O
when	O
computer	O
vision	O
ﬁrst	O
started	O
out	O
in	O
the	O
early	O
1970s	O
,	O
it	O
was	O
viewed	O
as	O
the	O
visual	O
perception	O
component	O
of	O
an	O
ambitious	O
agenda	O
to	O
mimic	O
human	O
intelligence	O
and	O
to	O
endow	O
robots	O
with	O
intelligent	O
behavior	O
.	O
at	O
the	O
time	O
,	O
it	O
was	O
believed	O
by	O
some	O
of	O
the	O
early	O
pioneers	O
of	O
artiﬁcial	O
intelligence	O
and	O
robotics	O
(	O
at	O
places	O
such	O
as	O
mit	O
,	O
stanford	O
,	O
and	O
cmu	O
)	O
that	O
solving	O
the	O
“	O
visual	O
input	O
”	O
problem	O
would	O
be	O
an	O
easy	O
step	O
along	O
the	O
path	O
to	O
solving	O
more	O
difﬁcult	O
problems	O
such	O
as	O
higher-level	O
reasoning	O
and	O
planning	O
.	O
according	O
to	O
one	O
well-known	O
story	O
,	O
in	O
1966	O
,	O
marvin	O
minsky	O
at	O
mit	O
asked	O
his	O
undergraduate	O
student	O
gerald	O
jay	O
sussman	O
to	O
“	O
spend	O
the	O
summer	O
linking	B
a	O
camera	B
to	O
a	O
computer	O
and	O
getting	O
the	O
computer	O
to	O
describe	O
what	O
it	O
saw	O
”	O
(	O
boden	O
2006	O
,	O
p.	O
781	O
)	O
.5	O
we	O
now	O
know	O
that	O
the	O
problem	O
is	O
slightly	O
more	O
difﬁcult	O
than	O
that.6	O
what	O
distinguished	O
computer	O
vision	O
from	O
the	O
already	O
existing	O
ﬁeld	O
of	O
digital	O
image	O
pro-	O
cessing	O
(	O
rosenfeld	O
and	O
pfaltz	O
1966	O
;	O
rosenfeld	O
and	O
kak	O
1976	O
)	O
was	O
a	O
desire	O
to	O
recover	O
the	O
three-dimensional	O
structure	O
of	O
the	O
world	O
from	O
images	O
and	O
to	O
use	O
this	O
as	O
a	O
stepping	O
stone	O
to-	O
wards	O
full	O
scene	B
understanding	I
.	O
winston	O
(	O
1975	O
)	O
and	O
hanson	O
and	O
riseman	O
(	O
1978	O
)	O
provide	O
two	O
nice	O
collections	O
of	O
classic	O
papers	O
from	O
this	O
early	O
period	O
.	O
early	O
attempts	O
at	O
scene	B
understanding	I
involved	O
extracting	O
edges	O
and	O
then	O
inferring	O
the	O
3d	O
structure	O
of	O
an	O
object	O
or	O
a	O
“	O
blocks	O
world	O
”	O
from	O
the	O
topological	O
structure	O
of	O
the	O
2d	O
lines	B
(	O
roberts	O
1965	O
)	O
.	O
several	O
line	O
labeling	O
algorithms	O
(	O
figure	O
1.7a	O
)	O
were	O
developed	O
at	O
that	O
time	O
(	O
huffman	O
1971	O
;	O
clowes	O
1971	O
;	O
waltz	O
1975	O
;	O
rosenfeld	O
,	O
hummel	O
,	O
and	O
zucker	O
1976	O
;	O
kanade	O
1980	O
)	O
.	O
nalwa	O
(	O
1993	O
)	O
gives	O
a	O
nice	O
review	O
of	O
this	O
area	O
.	O
the	O
topic	O
of	O
edge	O
detection	O
was	O
also	O
5	O
boden	O
(	O
2006	O
)	O
cites	O
(	O
crevier	O
1993	O
)	O
as	O
the	O
original	O
source	O
.	O
the	O
actual	O
vision	O
memo	O
was	O
authored	O
by	O
seymour	O
papert	O
(	O
1966	O
)	O
and	O
involved	O
a	O
whole	O
cohort	O
of	O
students	O
.	O
6	O
to	O
see	O
how	O
far	O
robotic	O
vision	O
has	O
come	O
in	O
the	O
last	O
four	O
decades	O
,	O
have	O
a	O
look	O
at	O
the	O
towel-folding	O
robot	O
at	O
http	O
:	O
//rll.eecs.berkeley.edu/pr/icra10/	O
(	O
maitin-shepard	O
,	O
cusumano-towner	O
,	O
lei	O
et	O
al	O
.	O
2010	O
)	O
.	O
digital	O
image	O
processingblocks	O
world	O
,	O
line	O
labelinggeneralizedcylinders197generalized	O
cylinderspictorial	O
structuresstereo	O
correspondenceintrinsic	O
imagesoptical	O
flowstructure	O
from	O
motion70image	O
pyramidsscale-space	O
processingshape	O
from	O
shading	B
,	O
texture	B
,	O
and	O
focusphysically-based	O
modeling1980regularizationmarkov	O
random	O
fieldskalman	O
filters3d	O
range	O
data	O
processingprojective	O
invariantsfactorization1factorizationphysics-based	O
visiongraph	O
cutsparticle	O
filteringenergy-based	O
segmentationfacerecognitionanddetection1990face	O
recognition	B
and	O
detectionsubspace	O
methodsimage-based	O
modeling	B
and	O
renderingtexture	O
synthesis	O
and	O
inpaintingcomputational	O
photography2000feature-based	O
recognitionmrf	O
inference	B
algorithmscategory	O
recognitionlearning	O
12	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
figure	O
1.7	O
some	O
early	O
(	O
1970s	O
)	O
examples	B
of	O
computer	O
vision	O
algorithms	O
:	O
(	O
a	O
)	O
line	O
label-	O
ing	O
(	O
nalwa	O
1993	O
)	O
c	O
(	O
cid:13	O
)	O
1993	O
addison-wesley	O
,	O
(	O
b	O
)	O
pictorial	O
structures	O
(	O
fischler	O
and	O
elschlager	O
1973	O
)	O
c	O
(	O
cid:13	O
)	O
1973	O
ieee	O
,	O
(	O
c	O
)	O
articulated	O
body	B
model	O
(	O
marr	O
1982	O
)	O
c	O
(	O
cid:13	O
)	O
1982	O
david	O
marr	O
,	O
(	O
d	O
)	O
intrin-	O
sic	O
images	O
(	O
barrow	O
and	O
tenenbaum	O
1981	O
)	O
c	O
(	O
cid:13	O
)	O
1973	O
ieee	O
,	O
(	O
e	O
)	O
stereo	B
correspondence	O
(	O
marr	O
1982	O
)	O
c	O
(	O
cid:13	O
)	O
1982	O
david	O
marr	O
,	O
(	O
f	O
)	O
optical	B
ﬂow	I
(	O
nagel	O
and	O
enkelmann	O
1986	O
)	O
c	O
(	O
cid:13	O
)	O
1986	O
ieee	O
.	O
an	O
active	O
area	O
of	O
research	O
;	O
a	O
nice	O
survey	O
of	O
contemporaneous	O
work	O
can	O
be	O
found	O
in	O
(	O
davis	O
1975	O
)	O
.	O
three-dimensional	O
modeling	B
of	O
non-polyhedral	O
objects	O
was	O
also	O
being	O
studied	O
(	O
baum-	O
gart	O
1974	O
;	O
baker	O
1977	O
)	O
.	O
one	O
popular	O
approach	O
used	O
generalized	B
cylinders	O
,	O
i.e.	O
,	O
solids	O
of	O
revolution	O
and	O
swept	O
closed	O
curves	O
(	O
agin	O
and	O
binford	O
1976	O
;	O
nevatia	O
and	O
binford	O
1977	O
)	O
,	O
of-	O
ten	O
arranged	O
into	O
parts	O
relationships7	O
(	O
hinton	O
1977	O
;	O
marr	O
1982	O
)	O
(	O
figure	O
1.7c	O
)	O
.	O
fischler	O
and	O
elschlager	O
(	O
1973	O
)	O
called	O
such	O
elastic	O
arrangements	O
of	O
parts	O
pictorial	O
structures	O
(	O
figure	O
1.7b	O
)	O
.	O
this	O
is	O
currently	O
one	O
of	O
the	O
favored	O
approaches	O
being	O
used	O
in	O
object	O
recognition	B
(	O
see	O
sec-	O
tion	B
14.4	O
and	O
felzenszwalb	O
and	O
huttenlocher	O
2005	O
)	O
.	O
a	O
qualitative	O
approach	O
to	O
understanding	O
intensities	O
and	O
shading	B
variations	O
and	O
explaining	O
them	O
by	O
the	O
effects	O
of	O
image	B
formation	O
phenomena	O
,	O
such	O
as	O
surface	B
orientation	O
and	O
shadows	O
,	O
was	O
championed	O
by	O
barrow	O
and	O
tenenbaum	O
(	O
1981	O
)	O
in	O
their	O
paper	O
on	O
intrinsic	B
images	O
(	O
fig-	O
ure	O
1.7d	O
)	O
,	O
along	O
with	O
the	O
related	O
2	O
1/2	O
-d	O
sketch	O
ideas	O
of	O
marr	O
(	O
1982	O
)	O
.	O
this	O
approach	O
is	O
again	O
seeing	O
a	O
bit	O
of	O
a	O
revival	O
in	O
the	O
work	O
of	O
tappen	O
,	O
freeman	O
,	O
and	O
adelson	O
(	O
2005	O
)	O
.	O
more	O
quantitative	O
approaches	O
to	O
computer	O
vision	O
were	O
also	O
developed	O
at	O
the	O
time	O
,	O
in-	O
cluding	O
the	O
ﬁrst	O
of	O
many	O
feature-based	B
stereo	O
correspondence	B
algorithms	O
(	O
figure	O
1.7e	O
)	O
(	O
dev	O
7	O
in	O
robotics	O
and	O
computer	O
animation	O
,	O
these	O
linked-part	O
graphs	O
are	O
often	O
called	O
kinematic	O
chains	O
.	O
1.2	O
a	O
brief	O
history	O
13	O
1974	O
;	O
marr	O
and	O
poggio	O
1976	O
;	O
moravec	O
1977	O
;	O
marr	O
and	O
poggio	O
1979	O
;	O
mayhew	O
and	O
frisby	O
1981	O
;	O
baker	O
1982	O
;	O
barnard	O
and	O
fischler	O
1982	O
;	O
ohta	O
and	O
kanade	O
1985	O
;	O
grimson	O
1985	O
;	O
pol-	O
lard	O
,	O
mayhew	O
,	O
and	O
frisby	O
1985	O
;	O
prazdny	O
1985	O
)	O
and	O
intensity-based	B
optical	O
ﬂow	O
algorithms	O
(	O
figure	O
1.7f	O
)	O
(	O
horn	O
and	O
schunck	O
1981	O
;	O
huang	O
1981	O
;	O
lucas	O
and	O
kanade	O
1981	O
;	O
nagel	O
1986	O
)	O
.	O
the	O
early	O
work	O
in	O
simultaneously	O
recovering	O
3d	O
structure	O
and	O
camera	B
motion	O
(	O
see	O
chapter	O
7	O
)	O
also	O
began	O
around	O
this	O
time	O
(	O
ullman	O
1979	O
;	O
longuet-higgins	O
1981	O
)	O
.	O
a	O
lot	O
of	O
the	O
philosophy	O
of	O
how	O
vision	O
was	O
believed	O
to	O
work	O
at	O
the	O
time	O
is	O
summarized	O
in	O
david	O
marr	O
’	O
s	O
(	O
1982	O
)	O
book.8	O
in	O
particular	O
,	O
marr	O
introduced	O
his	O
notion	O
of	O
the	O
three	O
levels	O
of	O
description	O
of	O
a	O
(	O
visual	O
)	O
information	O
processing	O
system	O
.	O
these	O
three	O
levels	O
,	O
very	O
loosely	O
paraphrased	O
according	O
to	O
my	O
own	O
interpretation	O
,	O
are	O
:	O
•	O
computational	B
theory	I
:	O
what	O
is	O
the	O
goal	O
of	O
the	O
computation	O
(	O
task	O
)	O
and	O
what	O
are	O
the	O
constraints	O
that	O
are	O
known	O
or	O
can	O
be	O
brought	O
to	O
bear	O
on	O
the	O
problem	O
?	O
•	O
representations	B
and	I
algorithms	I
:	O
how	O
are	O
the	O
input	O
,	O
output	O
,	O
and	O
intermediate	O
infor-	O
mation	O
represented	O
and	O
which	O
algorithms	O
are	O
used	O
to	O
calculate	O
the	O
desired	O
result	O
?	O
•	O
hardware	B
implementation	I
:	O
how	O
are	O
the	O
representations	B
and	I
algorithms	I
mapped	O
onto	O
actual	O
hardware	O
,	O
e.g.	O
,	O
a	O
biological	O
vision	O
system	O
or	O
a	O
specialized	O
piece	O
of	O
silicon	O
?	O
con-	O
versely	O
,	O
how	O
can	O
hardware	O
constraints	O
be	O
used	O
to	O
guide	O
the	O
choice	O
of	O
representation	O
and	O
algorithm	B
?	O
with	O
the	O
increasing	O
use	O
of	O
graphics	O
chips	O
(	O
gpus	O
)	O
and	O
many-core	O
ar-	O
chitectures	O
for	O
computer	O
vision	O
(	O
see	O
section	O
c.2	O
)	O
,	O
this	O
question	O
is	O
again	O
becoming	O
quite	O
relevant	O
.	O
as	O
i	O
mentioned	O
earlier	O
in	O
this	O
introduction	O
,	O
it	O
is	O
my	O
conviction	O
that	O
a	O
careful	O
analysis	O
of	O
the	O
problem	O
speciﬁcation	O
and	O
known	O
constraints	O
from	O
image	B
formation	O
and	O
priors	O
(	O
the	O
scientiﬁc	O
and	O
statistical	O
approaches	O
)	O
must	O
be	O
married	O
with	O
efﬁcient	O
and	O
robust	B
algorithms	O
(	O
the	O
engineer-	O
ing	O
approach	O
)	O
to	O
design	O
successful	O
vision	O
algorithms	O
.	O
thus	O
,	O
it	O
seems	O
that	O
marr	O
’	O
s	O
philosophy	O
is	O
as	O
good	O
a	O
guide	O
to	O
framing	O
and	O
solving	O
problems	O
in	O
our	O
ﬁeld	O
today	O
as	O
it	O
was	O
25	O
years	O
ago	O
.	O
in	O
the	O
1980s	O
,	O
a	O
lot	O
of	O
attention	O
was	O
focused	O
on	O
more	O
sophisticated	O
mathematical	O
1980s	O
.	O
techniques	O
for	O
performing	O
quantitative	O
image	B
and	O
scene	O
analysis	O
.	O
image	B
pyramids	O
(	O
see	O
section	O
3.5	O
)	O
started	O
being	O
widely	O
used	O
to	O
perform	O
tasks	O
such	O
as	O
im-	O
age	O
blending	B
(	O
figure	O
1.8a	O
)	O
and	O
coarse-to-ﬁne	B
correspondence	O
search	O
(	O
rosenfeld	O
1980	O
;	O
burt	O
and	O
adelson	O
1983a	O
,	O
b	O
;	O
rosenfeld	O
1984	O
;	O
quam	O
1984	O
;	O
anandan	O
1989	O
)	O
.	O
continuous	O
versions	O
of	O
pyramids	O
using	O
the	O
concept	O
of	O
scale-space	O
processing	O
were	O
also	O
developed	O
(	O
witkin	O
1983	O
;	O
witkin	O
,	O
terzopoulos	O
,	O
and	O
kass	O
1986	O
;	O
lindeberg	O
1990	O
)	O
.	O
in	O
the	O
late	O
1980s	O
,	O
wavelets	O
(	O
see	O
sec-	O
tion	B
3.5.4	O
)	O
started	O
displacing	O
or	O
augmenting	O
regular	O
image	B
pyramids	O
in	O
some	O
applications	O
8	O
more	O
recent	O
developments	O
in	O
visual	O
perception	O
theory	O
are	O
covered	O
in	O
(	O
palmer	O
1999	O
;	O
livingstone	O
2008	O
)	O
.	O
14	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
figure	O
1.8	O
examples	B
of	O
computer	O
vision	O
algorithms	O
from	O
the	O
1980s	O
:	O
(	O
a	O
)	O
pyramid	B
blending	O
(	O
burt	O
and	O
adelson	O
1983b	O
)	O
c	O
(	O
cid:13	O
)	O
1983	O
acm	O
,	O
(	O
b	O
)	O
shape	O
from	O
shading	B
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
c	O
(	O
cid:13	O
)	O
1991	O
ieee	O
,	O
(	O
c	O
)	O
edge	O
detection	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
c	O
(	O
cid:13	O
)	O
1991	O
ieee	O
,	O
(	O
d	O
)	O
physically	B
based	I
models	O
(	O
terzopoulos	O
and	O
witkin	O
1988	O
)	O
c	O
(	O
cid:13	O
)	O
1988	O
ieee	O
,	O
(	O
e	O
)	O
regularization-	O
based	O
surface	B
reconstruction	I
(	O
terzopoulos	O
1988	O
)	O
c	O
(	O
cid:13	O
)	O
1988	O
ieee	O
,	O
(	O
f	O
)	O
range	O
data	O
acquisition	O
and	O
merging	B
(	O
banno	O
,	O
masuda	O
,	O
oishi	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
springer	O
.	O
(	O
adelson	O
,	O
simoncelli	O
,	O
and	O
hingorani	O
1987	O
;	O
mallat	O
1989	O
;	O
simoncelli	O
and	O
adelson	O
1990a	O
,	O
b	O
;	O
simoncelli	O
,	O
freeman	O
,	O
adelson	O
et	O
al	O
.	O
1992	O
)	O
.	O
the	O
use	O
of	O
stereo	B
as	O
a	O
quantitative	O
shape	O
cue	O
was	O
extended	O
by	O
a	O
wide	O
variety	O
of	O
shape-	O
from-x	O
techniques	O
,	O
including	O
shape	O
from	O
shading	B
(	O
figure	O
1.8b	O
)	O
(	O
see	O
section	O
12.1.1	O
and	O
horn	O
1975	O
;	O
pentland	O
1984	O
;	O
blake	O
,	O
zimmerman	O
,	O
and	O
knowles	O
1985	O
;	O
horn	O
and	O
brooks	O
1986	O
,	O
1989	O
)	O
,	O
photometric	B
stereo	I
(	O
see	O
section	O
12.1.1	O
and	O
woodham	O
1981	O
)	O
,	O
shape	O
from	O
texture	B
(	O
see	O
sec-	O
tion	B
12.1.2	O
and	O
witkin	O
1981	O
;	O
pentland	O
1984	O
;	O
malik	O
and	O
rosenholtz	O
1997	O
)	O
,	O
and	O
shape	O
from	O
focus	B
(	O
see	O
section	O
12.1.3	O
and	O
nayar	O
,	O
watanabe	O
,	O
and	O
noguchi	O
1995	O
)	O
.	O
horn	O
(	O
1986	O
)	O
has	O
a	O
nice	O
discussion	O
of	O
most	O
of	O
these	O
techniques	O
.	O
research	O
into	O
better	O
edge	O
and	O
contour	O
detection	B
(	O
figure	O
1.8c	O
)	O
(	O
see	O
section	O
4.2	O
)	O
was	O
also	O
active	O
during	O
this	O
period	O
(	O
canny	O
1986	O
;	O
nalwa	O
and	O
binford	O
1986	O
)	O
,	O
including	O
the	O
introduc-	O
tion	B
of	O
dynamically	O
evolving	O
contour	O
trackers	O
(	O
section	O
5.1.1	O
)	O
such	O
as	O
snakes	B
(	O
kass	O
,	O
witkin	O
,	O
and	O
terzopoulos	O
1988	O
)	O
,	O
as	O
well	O
as	O
three-dimensional	O
physically	B
based	I
models	O
(	O
figure	O
1.8d	O
)	O
(	O
terzopoulos	O
,	O
witkin	O
,	O
and	O
kass	O
1987	O
;	O
kass	O
,	O
witkin	O
,	O
and	O
terzopoulos	O
1988	O
;	O
terzopoulos	O
and	O
fleischer	O
1988	O
;	O
terzopoulos	O
,	O
witkin	O
,	O
and	O
kass	O
1988	O
)	O
.	O
researchers	O
noticed	O
that	O
a	O
lot	O
of	O
the	O
stereo	B
,	O
ﬂow	O
,	O
shape-from-x	O
,	O
and	O
edge	O
detection	O
al-	O
1.2	O
a	O
brief	O
history	O
15	O
gorithms	O
could	O
be	O
uniﬁed	O
,	O
or	O
at	O
least	O
described	O
,	O
using	O
the	O
same	O
mathematical	O
framework	O
if	O
they	O
were	O
posed	O
as	O
variational	O
optimization	O
problems	O
(	O
see	O
section	O
3.7	O
)	O
and	O
made	O
more	O
ro-	O
bust	O
(	O
well-posed	O
)	O
using	O
regularization	O
(	O
figure	O
1.8e	O
)	O
(	O
see	O
section	O
3.7.1	O
and	O
terzopoulos	O
1983	O
;	O
poggio	O
,	O
torre	O
,	O
and	O
koch	O
1985	O
;	O
terzopoulos	O
1986b	O
;	O
blake	O
and	O
zisserman	O
1987	O
;	O
bertero	O
,	O
pog-	O
gio	O
,	O
and	O
torre	O
1988	O
;	O
terzopoulos	O
1988	O
)	O
.	O
around	O
the	O
same	O
time	O
,	O
geman	O
and	O
geman	O
(	O
1984	O
)	O
pointed	O
out	O
that	O
such	O
problems	O
could	O
equally	O
well	O
be	O
formulated	O
using	O
discrete	O
markov	O
ran-	O
dom	O
field	O
(	O
mrf	O
)	O
models	O
(	O
see	O
section	O
3.7.2	O
)	O
,	O
which	O
enabled	O
the	O
use	O
of	O
better	O
(	O
global	B
)	O
search	O
and	O
optimization	O
algorithms	O
,	O
such	O
as	O
simulated	B
annealing	I
.	O
online	O
variants	O
of	O
mrf	O
algorithms	O
that	O
modeled	O
and	O
updated	O
uncertainties	O
using	O
the	O
kalman	O
ﬁlter	O
were	O
introduced	O
a	O
little	O
later	O
(	O
dickmanns	O
and	O
graefe	O
1988	O
;	O
matthies	O
,	O
kanade	O
,	O
and	O
szeliski	O
1989	O
;	O
szeliski	O
1989	O
)	O
.	O
attempts	O
were	O
also	O
made	O
to	O
map	O
both	O
regularized	O
and	O
mrf	O
algorithms	O
onto	O
parallel	O
hardware	O
(	O
poggio	O
and	O
koch	O
1985	O
;	O
poggio	O
,	O
little	O
,	O
gamble	O
et	O
al	O
.	O
1988	O
;	O
fischler	O
,	O
firschein	O
,	O
barnard	O
et	O
al	O
.	O
1989	O
)	O
.	O
the	O
book	O
by	O
fischler	O
and	O
firschein	O
(	O
1987	O
)	O
contains	O
a	O
nice	O
collection	O
of	O
articles	O
focusing	O
on	O
all	O
of	O
these	O
topics	O
(	O
stereo	B
,	O
ﬂow	O
,	O
regularization	B
,	O
mrfs	O
,	O
and	O
even	O
higher-level	O
vision	O
)	O
.	O
three-dimensional	O
range	O
data	O
processing	O
(	O
acquisition	O
,	O
merging	B
,	O
modeling	B
,	O
and	O
recogni-	O
tion	B
;	O
see	O
figure	O
1.8f	O
)	O
continued	O
being	O
actively	O
explored	O
during	O
this	O
decade	O
(	O
agin	O
and	O
binford	O
1976	O
;	O
besl	O
and	O
jain	O
1985	O
;	O
faugeras	O
and	O
hebert	O
1987	O
;	O
curless	O
and	O
levoy	O
1996	O
)	O
.	O
the	O
compi-	O
lation	O
by	O
kanade	O
(	O
1987	O
)	O
contains	O
a	O
lot	O
of	O
the	O
interesting	O
papers	O
in	O
this	O
area	O
.	O
1990s	O
.	O
while	O
a	O
lot	O
of	O
the	O
previously	O
mentioned	O
topics	O
continued	O
to	O
be	O
explored	O
,	O
a	O
few	O
of	O
them	O
became	O
signiﬁcantly	O
more	O
active	O
.	O
a	O
burst	O
of	O
activity	O
in	O
using	O
projective	O
invariants	O
for	B
recognition	I
(	O
mundy	O
and	O
zisserman	O
1992	O
)	O
evolved	O
into	O
a	O
concerted	O
effort	O
to	O
solve	O
the	O
structure	B
from	I
motion	I
problem	O
(	O
see	O
chap-	O
ter	O
7	O
)	O
.	O
a	O
lot	O
of	O
the	O
initial	O
activity	O
was	O
directed	O
at	O
projective	B
reconstructions	O
,	O
which	O
did	O
not	O
require	O
knowledge	O
of	O
camera	B
calibration	O
(	O
faugeras	O
1992	O
;	O
hartley	O
,	O
gupta	O
,	O
and	O
chang	O
1992	O
;	O
hartley	O
1994a	O
;	O
faugeras	O
and	O
luong	O
2001	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
simultaneously	O
,	O
fac-	O
torization	O
techniques	O
(	O
section	O
7.3	O
)	O
were	O
developed	O
to	O
solve	O
efﬁciently	O
problems	O
for	O
which	O
or-	O
thographic	O
camera	B
approximations	O
were	O
applicable	O
(	O
figure	O
1.9a	O
)	O
(	O
tomasi	O
and	O
kanade	O
1992	O
;	O
poelman	O
and	O
kanade	O
1997	O
;	O
anandan	O
and	O
irani	O
2002	O
)	O
and	O
then	O
later	O
extended	O
to	O
the	O
perspec-	O
tive	O
case	O
(	O
christy	O
and	O
horaud	O
1996	O
;	O
triggs	O
1996	O
)	O
.	O
eventually	O
,	O
the	O
ﬁeld	O
started	O
using	O
full	O
global	B
optimization	I
(	O
see	O
section	O
7.4	O
and	O
taylor	O
,	O
kriegman	O
,	O
and	O
anandan	O
1991	O
;	O
szeliski	O
and	O
kang	O
1994	O
;	O
azarbayejani	O
and	O
pentland	O
1995	O
)	O
,	O
which	O
was	O
later	O
recognized	O
as	O
being	O
the	O
same	O
as	O
the	O
bundle	B
adjustment	I
techniques	O
traditionally	O
used	O
in	O
photogrammetry	B
(	O
triggs	O
,	O
mclauch-	O
lan	O
,	O
hartley	O
et	O
al	O
.	O
1999	O
)	O
.	O
fully	O
automated	B
(	O
sparse	B
)	O
3d	O
modeling	B
systems	O
were	O
built	O
using	O
such	O
techniques	O
(	O
beardsley	O
,	O
torr	O
,	O
and	O
zisserman	O
1996	O
;	O
schaffalitzky	O
and	O
zisserman	O
2002	O
;	O
brown	O
and	O
lowe	O
2003	O
;	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
work	O
begun	O
in	O
the	O
1980s	O
on	O
using	O
detailed	O
measurements	O
of	O
color	B
and	O
intensity	O
combined	O
16	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
figure	O
1.9	O
examples	B
of	O
computer	O
vision	O
algorithms	O
from	O
the	O
1990s	O
:	O
(	O
a	O
)	O
factorization-based	O
structure	B
from	I
motion	I
(	O
tomasi	O
and	O
kanade	O
1992	O
)	O
c	O
(	O
cid:13	O
)	O
1992	O
springer	O
,	O
(	O
b	O
)	O
dense	O
stereo	O
match-	O
ing	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
,	O
(	O
c	O
)	O
multi-view	B
reconstruction	O
(	O
seitz	O
and	O
dyer	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
springer	O
,	O
(	O
d	O
)	O
face	B
tracking	O
(	O
matthews	O
,	O
xiao	O
,	O
and	O
baker	O
2007	O
)	O
,	O
(	O
e	O
)	O
image	B
segmenta-	O
tion	B
(	O
belongie	O
,	O
fowlkes	O
,	O
chung	O
et	O
al	O
.	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
springer	O
,	O
(	O
f	O
)	O
face	B
recognition	O
(	O
turk	O
and	O
pentland	O
1991a	O
)	O
.	O
with	O
accurate	O
physical	O
models	O
of	O
radiance	O
transport	O
and	O
color	B
image	O
formation	O
created	O
its	O
own	O
subﬁeld	O
known	O
as	O
physics-based	B
vision	O
.	O
a	O
good	O
survey	O
of	O
the	O
ﬁeld	O
can	O
be	O
found	O
in	O
the	O
three-	O
volume	O
collection	O
on	O
this	O
topic	O
(	O
wolff	O
,	O
shafer	O
,	O
and	O
healey	O
1992a	O
;	O
healey	O
and	O
shafer	O
1992	O
;	O
shafer	O
,	O
healey	O
,	O
and	O
wolff	O
1992	O
)	O
.	O
optical	B
ﬂow	I
methods	O
(	O
see	O
chapter	O
8	O
)	O
continued	O
to	O
be	O
improved	O
(	O
nagel	O
and	O
enkelmann	O
1986	O
;	O
bolles	O
,	O
baker	O
,	O
and	O
marimont	O
1987	O
;	O
horn	O
and	O
weldon	O
jr.	O
1988	O
;	O
anandan	O
1989	O
;	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
;	O
black	O
and	O
anandan	O
1996	O
;	O
bruhn	O
,	O
weickert	O
,	O
and	O
schn¨orr	O
2005	O
;	O
papenberg	O
,	O
bruhn	O
,	O
brox	O
et	O
al	O
.	O
2006	O
)	O
,	O
with	O
(	O
nagel	O
1986	O
;	O
barron	O
,	O
fleet	O
,	O
and	O
beauchemin	O
1994	O
;	O
baker	O
,	O
black	O
,	O
lewis	O
et	O
al	O
.	O
2007	O
)	O
being	O
good	O
surveys	B
.	O
similarly	O
,	O
a	O
lot	O
of	O
progress	O
was	O
made	O
on	O
dense	O
stereo	O
correspondence	B
algorithms	O
(	O
see	O
chapter	O
11	O
,	O
okutomi	O
and	O
kanade	O
(	O
1993	O
,	O
1994	O
)	O
;	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
(	O
1998	O
)	O
;	O
birchﬁeld	O
and	O
tomasi	O
(	O
1999	O
)	O
;	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
(	O
2001	O
)	O
,	O
and	O
the	O
survey	O
and	O
comparison	O
in	O
scharstein	O
and	O
szeliski	O
(	O
2002	O
)	O
)	O
,	O
with	O
the	O
biggest	O
breakthrough	O
being	O
perhaps	O
global	B
optimization	I
using	O
graph	B
cut	I
techniques	O
(	O
fig-	O
ure	O
1.9b	O
)	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
.	O
1.2	O
a	O
brief	O
history	O
17	O
multi-view	B
stereo	I
algorithms	O
(	O
figure	O
1.9c	O
)	O
that	O
produce	O
complete	O
3d	O
surfaces	O
(	O
see	O
sec-	O
tion	B
11.6	O
)	O
were	O
also	O
an	O
active	O
topic	O
of	O
research	O
(	O
seitz	O
and	O
dyer	O
1999	O
;	O
kutulakos	O
and	O
seitz	O
2000	O
)	O
that	O
continues	O
to	O
be	O
active	O
today	O
(	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
2006	O
)	O
.	O
techniques	O
for	O
producing	O
3d	O
volumetric	B
descriptions	O
from	O
binary	O
silhouettes	O
(	O
see	O
section	O
11.6.2	O
)	O
continued	O
to	O
be	O
developed	O
(	O
potmesil	O
1987	O
;	O
srivasan	O
,	O
liang	O
,	O
and	O
hackwood	O
1990	O
;	O
szeliski	O
1993	O
;	O
lau-	O
rentini	O
1994	O
)	O
,	O
along	O
with	O
techniques	O
based	O
on	O
tracking	O
and	O
reconstructing	O
smooth	O
occluding	O
contours	O
(	O
see	O
section	O
11.2.1	O
and	O
cipolla	O
and	O
blake	O
1992	O
;	O
vaillant	O
and	O
faugeras	O
1992	O
;	O
zheng	O
1994	O
;	O
boyer	O
and	O
berger	O
1997	O
;	O
szeliski	O
and	O
weiss	O
1998	O
;	O
cipolla	O
and	O
giblin	O
2000	O
)	O
.	O
tracking	O
algorithms	O
also	O
improved	O
a	O
lot	O
,	O
including	O
contour	O
tracking	O
using	O
active	O
contours	O
(	O
see	O
section	O
5.1	O
)	O
,	O
such	O
as	O
snakes	B
(	O
kass	O
,	O
witkin	O
,	O
and	O
terzopoulos	O
1988	O
)	O
,	O
particle	O
ﬁlters	O
(	O
blake	O
and	O
isard	O
1998	O
)	O
,	O
and	O
level	B
sets	I
(	O
malladi	O
,	O
sethian	O
,	O
and	O
vemuri	O
1995	O
)	O
,	O
as	O
well	O
as	O
intensity-based	B
(	O
direct	B
)	O
techniques	O
(	O
lucas	O
and	O
kanade	O
1981	O
;	O
shi	O
and	O
tomasi	O
1994	O
;	O
rehg	O
and	O
kanade	O
1994	O
)	O
,	O
often	O
applied	O
to	O
tracking	O
faces	B
(	O
figure	O
1.9d	O
)	O
(	O
lanitis	O
,	O
taylor	O
,	O
and	O
cootes	O
1997	O
;	O
matthews	O
and	O
baker	O
2004	O
;	O
matthews	O
,	O
xiao	O
,	O
and	O
baker	O
2007	O
)	O
and	O
whole	O
bodies	O
(	O
sidenbladh	O
,	O
black	O
,	O
and	O
fleet	O
2000	O
;	O
hilton	O
,	O
fua	O
,	O
and	O
ronfard	O
2006	O
;	O
moeslund	O
,	O
hilton	O
,	O
and	O
kr¨uger	O
2006	O
)	O
.	O
image	B
segmentation	O
(	O
see	O
chapter	O
5	O
)	O
(	O
figure	O
1.9e	O
)	O
,	O
a	O
topic	O
which	O
has	O
been	O
active	O
since	O
the	O
earliest	O
days	O
of	O
computer	O
vision	O
(	O
brice	O
and	O
fennema	O
1970	O
;	O
horowitz	O
and	O
pavlidis	O
1976	O
;	O
riseman	O
and	O
arbib	O
1977	O
;	O
rosenfeld	O
and	O
davis	O
1979	O
;	O
haralick	O
and	O
shapiro	O
1985	O
;	O
pavlidis	O
and	O
liow	O
1990	O
)	O
,	O
was	O
also	O
an	O
active	O
topic	O
of	O
research	O
,	O
producing	O
techniques	O
based	O
on	O
min-	O
imum	O
energy	O
(	O
mumford	O
and	O
shah	O
1989	O
)	O
and	O
minimum	O
description	O
length	O
(	O
leclerc	O
1989	O
)	O
,	O
normalized	B
cuts	I
(	O
shi	O
and	O
malik	O
2000	O
)	O
,	O
and	O
mean	B
shift	I
(	O
comaniciu	O
and	O
meer	O
2002	O
)	O
.	O
statistical	O
learning	B
techniques	O
started	O
appearing	O
,	O
ﬁrst	O
in	O
the	O
application	O
of	O
principal	O
com-	O
ponent	O
eigenface	B
analysis	O
to	O
face	B
recognition	O
(	O
figure	O
1.9f	O
)	O
(	O
see	O
section	O
14.2.1	O
and	O
turk	O
and	O
pentland	O
1991a	O
)	O
and	O
linear	B
dynamical	O
systems	O
for	O
curve	O
tracking	O
(	O
see	O
section	O
5.1.1	O
and	O
blake	O
and	O
isard	O
1998	O
)	O
.	O
perhaps	O
the	O
most	O
notable	O
development	O
in	O
computer	O
vision	O
during	O
this	O
decade	O
was	O
the	O
increased	O
interaction	O
with	O
computer	O
graphics	O
(	O
seitz	O
and	O
szeliski	O
1999	O
)	O
,	O
especially	O
in	O
the	O
cross-disciplinary	O
area	O
of	O
image-based	B
modeling	O
and	O
rendering	B
(	O
see	O
chapter	O
13	O
)	O
.	O
the	O
idea	O
of	O
manipulating	O
real-world	O
imagery	O
directly	O
to	O
create	O
new	O
animations	O
ﬁrst	O
came	O
to	O
prominence	O
with	O
image	O
morphing	B
techniques	O
(	O
figure1.5c	O
)	O
(	O
see	O
section	O
3.6.3	O
and	O
beier	O
and	O
neely	O
1992	O
)	O
and	O
was	O
later	O
applied	O
to	O
view	B
interpolation	I
(	O
chen	O
and	O
williams	O
1993	O
;	O
seitz	O
and	O
dyer	O
1996	O
)	O
,	O
panoramic	O
image	B
stitching	I
(	O
figure1.5a	O
)	O
(	O
see	O
chapter	O
9	O
and	O
mann	O
and	O
picard	O
1994	O
;	O
chen	O
1995	O
;	O
szeliski	O
1996	O
;	O
szeliski	O
and	O
shum	O
1997	O
;	O
szeliski	O
2006a	O
)	O
,	O
and	O
full	O
light-ﬁeld	O
rendering	B
(	O
figure	O
1.10a	O
)	O
(	O
see	O
section	O
13.3	O
and	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
;	O
levoy	O
and	O
hanrahan	O
1996	O
;	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
.	O
at	O
the	O
same	O
time	O
,	O
image-based	B
modeling	O
techniques	O
(	O
figure	O
1.10b	O
)	O
for	O
automatically	O
creating	O
realistic	O
3d	O
models	O
from	O
collections	O
of	O
images	O
were	O
also	O
being	O
introduced	O
(	O
beardsley	O
,	O
torr	O
,	O
and	O
zisserman	O
1996	O
;	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
1996	O
;	O
taylor	O
,	O
debevec	O
,	O
and	O
malik	O
1996	O
)	O
.	O
18	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
figure	O
1.10	O
recent	O
examples	B
of	O
computer	O
vision	O
algorithms	O
:	O
(	O
a	O
)	O
image-based	B
rendering	I
(	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
)	O
,	O
(	O
b	O
)	O
image-based	B
modeling	O
(	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
,	O
(	O
c	O
)	O
interactive	B
tone	O
mapping	O
(	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
2006a	O
)	O
(	O
d	O
)	O
texture	B
synthesis	O
(	O
efros	O
and	O
freeman	O
2001	O
)	O
,	O
(	O
e	O
)	O
feature-based	B
recognition	O
(	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2007	O
)	O
,	O
(	O
f	O
)	O
region-based	B
recognition	O
(	O
mori	O
,	O
ren	O
,	O
efros	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
ieee	O
.	O
2000s	O
.	O
this	O
past	O
decade	O
has	O
continued	O
to	O
see	O
a	O
deepening	O
interplay	O
between	O
the	O
vision	O
and	O
graphics	O
ﬁelds	O
.	O
in	O
particular	O
,	O
many	O
of	O
the	O
topics	O
introduced	O
under	O
the	O
rubric	O
of	O
image-based	B
rendering	I
,	O
such	O
as	O
image	B
stitching	I
(	O
see	O
chapter	O
9	O
)	O
,	O
light-ﬁeld	O
capture	O
and	O
rendering	B
(	O
see	O
section	O
13.3	O
)	O
,	O
and	O
high	B
dynamic	I
range	I
(	O
hdr	O
)	O
image	B
capture	O
through	O
exposure	O
bracketing	O
(	O
figure1.5b	O
)	O
(	O
see	O
section	O
10.2	O
and	O
mann	O
and	O
picard	O
1995	O
;	O
debevec	O
and	O
malik	O
1997	O
)	O
,	O
were	O
re-christened	O
as	O
computational	O
photography	O
(	O
see	O
chapter	O
10	O
)	O
to	O
acknowledge	O
the	O
increased	O
use	O
of	O
such	O
techniques	O
in	O
everyday	O
digital	O
photography	O
.	O
for	O
example	O
,	O
the	O
rapid	O
adoption	O
of	O
exposure	O
bracketing	O
to	O
create	O
high	B
dynamic	I
range	I
images	O
necessitated	O
the	O
development	O
of	O
tone	B
mapping	I
algorithms	O
(	O
figure	O
1.10c	O
)	O
(	O
see	O
section	O
10.2.1	O
)	O
to	O
convert	O
such	O
images	O
back	O
to	O
displayable	O
results	O
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
;	O
durand	O
and	O
dorsey	O
2002	O
;	O
rein-	O
hard	O
,	O
stark	O
,	O
shirley	O
et	O
al	O
.	O
2002	O
;	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
2006a	O
)	O
.	O
in	O
addition	O
to	O
merging	B
multiple	O
exposures	O
,	O
techniques	O
were	O
developed	O
to	O
merge	O
ﬂash	B
images	O
with	O
non-ﬂash	O
counterparts	O
(	O
eisemann	O
and	O
durand	O
2004	O
;	O
petschnigg	O
,	O
agrawala	O
,	O
hoppe	O
et	O
al	O
.	O
2004	O
)	O
and	O
to	O
interactively	O
or	O
automatically	O
select	O
different	O
regions	O
from	O
overlapping	O
images	O
(	O
agarwala	O
,	O
1.3	O
book	O
overview	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
.	O
19	O
texture	B
synthesis	O
(	O
figure	O
1.10d	O
)	O
(	O
see	O
section	O
10.5	O
)	O
,	O
quilting	O
(	O
efros	O
and	O
leung	O
1999	O
;	O
efros	O
and	O
freeman	O
2001	O
;	O
kwatra	O
,	O
sch¨odl	O
,	O
essa	O
et	O
al	O
.	O
2003	O
)	O
and	O
inpainting	B
(	O
bertalmio	O
,	O
sapiro	O
,	O
caselles	O
et	O
al	O
.	O
2000	O
;	O
bertalmio	O
,	O
vese	O
,	O
sapiro	O
et	O
al	O
.	O
2003	O
;	O
criminisi	O
,	O
p´erez	O
,	O
and	O
toyama	O
2004	O
)	O
are	O
additional	O
topics	O
that	O
can	O
be	O
classiﬁed	O
as	O
computational	O
photography	O
techniques	O
,	O
since	O
they	O
re-combine	O
input	O
image	B
samples	O
to	O
produce	O
new	O
photographs	O
.	O
a	O
second	O
notable	O
trend	O
during	O
this	O
past	O
decade	O
has	O
been	O
the	O
emergence	O
of	O
feature-based	B
techniques	O
(	O
combined	O
with	O
learning	O
)	O
for	O
object	O
recognition	B
(	O
see	O
section	O
14.3	O
and	O
ponce	O
,	O
hebert	O
,	O
schmid	O
et	O
al	O
.	O
2006	O
)	O
.	O
some	O
of	O
the	O
notable	O
papers	O
in	O
this	O
area	O
include	O
the	O
constellation	B
model	I
of	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
(	O
2007	O
)	O
(	O
figure	O
1.10e	O
)	O
and	O
the	O
pictorial	O
structures	O
of	O
felzenszwalb	O
and	O
huttenlocher	O
(	O
2005	O
)	O
.	O
feature-based	B
techniques	O
also	O
dominate	O
other	O
recognition	B
tasks	O
,	O
such	O
as	O
scene	O
recognition	O
(	O
zhang	O
,	O
marszalek	O
,	O
lazebnik	O
et	O
al	O
.	O
2007	O
)	O
and	O
panorama	O
and	O
location	B
recognition	I
(	O
brown	O
and	O
lowe	O
2007	O
;	O
schindler	O
,	O
brown	O
,	O
and	O
szeliski	O
2007	O
)	O
.	O
and	O
while	O
interest	O
point	O
(	O
patch-based	B
)	O
features	O
tend	O
to	O
dominate	O
current	O
research	O
,	O
some	O
groups	O
are	O
pursuing	O
recognition	B
based	O
on	O
contours	O
(	O
belongie	O
,	O
malik	O
,	O
and	O
puzicha	O
2002	O
)	O
and	O
region	B
segmentation	O
(	O
figure	O
1.10f	O
)	O
(	O
mori	O
,	O
ren	O
,	O
efros	O
et	O
al	O
.	O
2004	O
)	O
.	O
another	O
signiﬁcant	O
trend	O
from	O
this	O
past	O
decade	O
has	O
been	O
the	O
development	O
of	O
more	O
efﬁcient	O
algorithms	O
for	O
complex	O
global	B
optimization	I
problems	O
(	O
see	O
sections	O
3.7	O
and	O
b.5	O
and	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
;	O
blake	O
,	O
kohli	O
,	O
and	O
rother	O
2010	O
)	O
.	O
while	O
this	O
trend	O
began	O
with	O
work	O
on	O
graph	B
cuts	I
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
;	O
kohli	O
and	O
torr	O
2007	O
)	O
,	O
a	O
lot	O
of	O
progress	O
has	O
also	O
been	O
made	O
in	O
message	O
passing	O
algorithms	O
,	O
such	O
as	O
loopy	B
belief	I
propagation	I
(	O
lbp	O
)	O
(	O
yedidia	O
,	O
freeman	O
,	O
and	O
weiss	O
2001	O
;	O
kumar	O
and	O
torr	O
2006	O
)	O
.	O
the	O
ﬁnal	O
trend	O
,	O
which	O
now	O
dominates	O
a	O
lot	O
of	O
the	O
visual	O
recognition	O
research	O
in	O
our	O
com-	O
munity	O
,	O
is	O
the	O
application	O
of	O
sophisticated	O
machine	O
learning	O
techniques	O
to	O
computer	O
vision	O
problems	O
(	O
see	O
section	O
14.5.1	O
and	O
freeman	O
,	O
perona	O
,	O
and	O
sch¨olkopf	O
2008	O
)	O
.	O
this	O
trend	O
coin-	O
cides	O
with	O
the	O
increased	O
availability	O
of	O
immense	O
quantities	O
of	O
partially	O
labelled	O
data	O
on	O
the	O
internet	O
,	O
which	O
makes	O
it	O
more	O
feasible	O
to	O
learn	O
object	O
categories	O
without	O
the	O
use	O
of	O
careful	O
human	O
supervision	O
.	O
1.3	O
book	O
overview	O
in	O
the	O
ﬁnal	O
part	O
of	O
this	O
introduction	O
,	O
i	O
give	O
a	O
brief	O
tour	O
of	O
the	O
material	O
in	O
this	O
book	O
,	O
as	O
well	O
as	O
a	O
few	O
notes	O
on	O
notation	O
and	O
some	O
additional	O
general	O
references	B
.	O
since	O
computer	O
vision	O
is	O
such	O
a	O
broad	O
ﬁeld	O
,	O
it	O
is	O
possible	O
to	O
study	O
certain	O
aspects	O
of	O
it	O
,	O
e.g.	O
,	O
geometric	B
image	O
formation	O
and	O
3d	O
structure	O
recovery	O
,	O
without	O
engaging	O
other	O
parts	O
,	O
e.g.	O
,	O
the	O
modeling	B
of	O
reﬂectance	B
and	O
shading	B
.	O
some	O
of	O
the	O
chapters	O
in	O
this	O
book	O
are	O
only	O
loosely	O
coupled	O
with	O
others	O
,	O
and	O
it	O
is	O
not	O
strictly	O
necessary	O
to	O
read	O
all	O
of	O
the	O
material	O
in	O
sequence	O
.	O
20	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
1.11	O
relationship	O
between	O
images	O
,	O
geometry	O
,	O
and	O
photometry	O
,	O
as	O
well	O
as	O
a	O
taxonomy	B
of	O
the	O
topics	O
covered	O
in	O
this	O
book	O
.	O
topics	O
are	O
roughly	O
positioned	O
along	O
the	O
left–right	O
axis	O
depending	O
on	O
whether	O
they	O
are	O
more	O
closely	O
related	O
to	O
image-based	B
(	O
left	O
)	O
,	O
geometry-based	O
(	O
middle	O
)	O
or	O
appearance-based	O
(	O
right	O
)	O
representations	O
,	O
and	O
on	O
the	O
vertical	O
axis	O
by	O
increasing	O
level	O
of	O
abstraction	O
.	O
the	O
whole	O
ﬁgure	O
should	O
be	O
taken	O
with	O
a	O
large	O
grain	O
of	O
salt	O
,	O
as	O
there	O
are	O
many	O
additional	O
subtle	O
connections	O
between	O
topics	O
not	O
illustrated	O
here	O
.	O
images	O
(	O
2d	O
)	O
geometry	O
(	O
3d	O
)	O
shapephotometry	O
appearance+visiongraphicsimage	O
processing2.1	O
geometric	B
image	O
formation2.2	O
photometric	B
image	O
formation2.3	O
samplingand	O
aliasing3	O
image	B
processing4	O
feature	B
detection6	O
feature-based	B
alignment7	O
structure	O
from	O
motion8	O
motionestimation10	O
computational	O
photography11	O
stereo	B
correspondence12	O
3d	O
shape	O
recovery12	O
texture	B
recovery13	O
image-based	B
rendering14	O
recognition5	O
segmentation9stitching	O
1.3	O
book	O
overview	O
21	O
figure	O
1.11	O
shows	O
a	O
rough	O
layout	O
of	O
the	O
contents	O
of	O
this	O
book	O
.	O
since	O
computer	O
vision	O
involves	O
going	O
from	O
images	O
to	O
a	O
structural	O
description	O
of	O
the	O
scene	O
(	O
and	O
computer	O
graphics	O
the	O
converse	O
)	O
,	O
i	O
have	O
positioned	O
the	O
chapters	O
horizontally	O
in	O
terms	O
of	O
which	O
major	O
component	O
they	O
address	O
,	O
in	O
addition	O
to	O
vertically	O
according	O
to	O
their	O
dependence	O
.	O
going	O
from	O
left	O
to	O
right	O
,	O
we	O
see	O
the	O
major	O
column	O
headings	O
as	O
images	O
(	O
which	O
are	O
2d	O
in	O
nature	O
)	O
,	O
geometry	O
(	O
which	O
encompasses	O
3d	O
descriptions	O
)	O
,	O
and	O
photometry	O
(	O
which	O
encom-	O
passes	O
object	O
appearance	O
)	O
.	O
(	O
an	O
alternative	O
labeling	O
for	O
these	O
latter	O
two	O
could	O
also	O
be	O
shape	O
and	O
appearance—see	O
,	O
e.g.	O
,	O
chapter	O
13	O
and	O
kang	O
,	O
szeliski	O
,	O
and	O
anandan	O
(	O
2000	O
)	O
.	O
)	O
going	O
from	O
top	O
to	O
bottom	O
,	O
we	O
see	O
increasing	O
levels	O
of	O
modeling	B
and	O
abstraction	O
,	O
as	O
well	O
as	O
tech-	O
niques	O
that	O
build	O
on	O
previously	O
developed	O
algorithms	O
.	O
of	O
course	O
,	O
this	O
taxonomy	B
should	O
be	O
taken	O
with	O
a	O
large	O
grain	O
of	O
salt	O
,	O
as	O
the	O
processing	O
and	O
dependencies	O
in	O
this	O
diagram	O
are	O
not	O
strictly	O
sequential	O
and	O
subtle	O
additional	O
dependencies	O
and	O
relationships	O
also	O
exist	O
(	O
e.g.	O
,	O
some	O
recognition	B
techniques	O
make	O
use	O
of	O
3d	O
information	O
)	O
.	O
the	O
placement	O
of	O
topics	O
along	O
the	O
hor-	O
izontal	O
axis	O
should	O
also	O
be	O
taken	O
lightly	O
,	O
as	O
most	O
vision	O
algorithms	O
involve	O
mapping	O
between	O
at	O
least	O
two	O
different	O
representations.9	O
interspersed	O
throughout	O
the	O
book	O
are	O
sample	O
applications	O
,	O
which	O
relate	O
the	O
algorithms	O
and	O
mathematical	O
material	O
being	O
presented	O
in	O
various	O
chapters	O
to	O
useful	O
,	O
real-world	O
applica-	O
tions	O
.	O
many	O
of	O
these	O
applications	O
are	O
also	O
presented	O
in	O
the	O
exercises	O
sections	O
,	O
so	O
that	O
students	O
can	O
write	O
their	O
own	O
.	O
at	O
the	O
end	O
of	O
each	O
section	O
,	O
i	O
provide	O
a	O
set	O
of	O
exercises	O
that	O
the	O
students	O
can	O
use	O
to	O
imple-	O
ment	O
,	O
test	O
,	O
and	O
reﬁne	O
the	O
algorithms	O
and	O
techniques	O
presented	O
in	O
each	O
section	O
.	O
some	O
of	O
the	O
exercises	O
are	O
suitable	O
as	O
written	O
homework	O
assignments	O
,	O
others	O
as	O
shorter	O
one-week	O
projects	O
,	O
and	O
still	O
others	O
as	O
open-ended	O
research	O
problems	O
that	O
make	O
for	O
challenging	O
ﬁnal	O
projects	O
.	O
motivated	O
students	O
who	O
implement	O
a	O
reasonable	O
subset	O
of	O
these	O
exercises	O
will	O
,	O
by	O
the	O
end	O
of	O
the	O
book	O
,	O
have	O
a	O
computer	O
vision	O
software	O
library	O
that	O
can	O
be	O
used	O
for	O
a	O
variety	O
of	O
interesting	O
tasks	O
and	O
projects	O
.	O
as	O
a	O
reference	O
book	O
,	O
i	O
try	O
wherever	O
possible	O
to	O
discuss	O
which	O
techniques	O
and	O
algorithms	O
work	O
well	O
in	O
practice	O
,	O
as	O
well	O
as	O
providing	O
up-to-date	O
pointers	O
to	O
the	O
latest	O
research	O
results	O
in	O
the	O
areas	O
that	O
i	O
cover	O
.	O
the	O
exercises	O
can	O
be	O
used	O
to	O
build	O
up	O
your	O
own	O
personal	O
library	O
of	O
self-	O
tested	O
and	O
validated	O
vision	O
algorithms	O
,	O
which	O
is	O
more	O
worthwhile	O
in	O
the	O
long	O
term	O
(	O
assuming	O
you	O
have	O
the	O
time	O
)	O
than	O
simply	O
pulling	O
algorithms	O
out	O
of	O
a	O
library	O
whose	O
performance	O
you	O
do	O
not	O
really	O
understand	O
.	O
the	O
book	O
begins	O
in	O
chapter	O
2	O
with	O
a	O
review	O
of	O
the	O
image	B
formation	O
processes	O
that	O
create	O
the	O
images	O
that	O
we	O
see	O
and	O
capture	O
.	O
understanding	O
this	O
process	O
is	O
fundamental	O
if	O
you	O
want	O
to	O
take	O
a	O
scientiﬁc	O
(	O
model-based	B
)	O
approach	O
to	O
computer	O
vision	O
.	O
students	O
who	O
are	O
eager	O
to	O
just	O
start	O
implementing	O
algorithms	O
(	O
or	O
courses	O
that	O
have	O
limited	O
time	O
)	O
can	O
skip	O
ahead	O
to	O
the	O
9	O
for	O
an	O
interesting	O
comparison	O
with	O
what	O
is	O
known	O
about	O
the	O
human	O
visual	O
system	O
,	O
e.g.	O
,	O
the	O
largely	O
parallel	O
what	O
and	O
where	O
pathways	O
,	O
see	O
some	O
textbooks	B
on	O
human	O
perception	O
(	O
palmer	O
1999	O
;	O
livingstone	O
2008	O
)	O
.	O
22	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
2.	O
image	B
formation	O
3.	O
image	B
processing	O
4.	O
features	O
5.	O
segmentation	B
6-7.	O
structure	B
from	I
motion	I
8.	O
motion	B
9.	O
stitching	O
10.	O
computational	O
photography	O
11.	O
stereo	B
12	O
.	O
3d	O
shape	O
13.	O
image-based	B
rendering	I
14.	O
recognition	B
figure	O
1.12	O
a	O
pictorial	O
summary	O
of	O
the	O
chapter	O
contents	O
.	O
sources	O
:	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
(	O
2005	O
)	O
;	O
comaniciu	O
and	O
meer	O
(	O
2002	O
)	O
;	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
(	O
2006	O
)	O
;	O
nagel	O
and	O
enkelmann	O
(	O
1986	O
)	O
;	O
szeliski	O
and	O
shum	O
(	O
1997	O
)	O
;	O
debevec	O
and	O
malik	O
(	O
1997	O
)	O
;	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
(	O
1996	O
)	O
;	O
viola	O
and	O
jones	O
(	O
2004	O
)	O
—see	O
the	O
ﬁgures	O
in	O
the	O
respec-	O
tive	O
chapters	O
for	O
copyright	O
information	O
.	O
n^	O
1.3	O
book	O
overview	O
23	O
next	O
chapter	O
and	O
dip	O
into	O
this	O
material	O
later	O
.	O
in	O
chapter	O
2	O
,	O
we	O
break	O
down	O
image	B
formation	O
into	O
three	O
major	O
components	O
.	O
geometric	B
image	O
formation	O
(	O
section	O
2.1	O
)	O
deals	O
with	O
points	O
,	O
lines	B
,	O
and	O
planes	B
,	O
and	O
how	O
these	O
are	O
mapped	O
onto	O
images	O
using	O
projective	O
geometry	O
and	O
other	O
models	O
(	O
including	O
radial	B
lens	O
distortion	O
)	O
.	O
photometric	B
image	O
formation	O
(	O
section	O
2.2	O
)	O
covers	O
radiometry	O
,	O
which	O
describes	O
how	O
light	O
interacts	O
with	O
surfaces	O
in	O
the	O
world	O
,	O
and	O
optics	B
,	O
which	O
projects	O
light	O
onto	O
the	O
sensor	B
plane	O
.	O
finally	O
,	O
section	O
2.3	O
covers	O
how	O
sensors	O
work	O
,	O
including	O
topics	O
such	O
as	O
sampling	B
and	O
aliasing	B
,	O
color	B
sensing	O
,	O
and	O
in-camera	O
compression	B
.	O
chapter	O
3	O
covers	O
image	B
processing	O
,	O
which	O
is	O
needed	O
in	O
almost	O
all	O
computer	O
vision	O
appli-	O
cations	O
.	O
this	O
includes	O
topics	O
such	O
as	O
linear	B
and	O
non-linear	B
ﬁltering	O
(	O
section	O
3.3	O
)	O
,	O
the	O
fourier	O
transform	B
(	O
section	O
3.4	O
)	O
,	O
image	B
pyramids	O
and	O
wavelets	O
(	O
section	O
3.5	O
)	O
,	O
geometric	B
transforma-	O
tions	O
such	O
as	O
image	B
warping	O
(	O
section	O
3.6	O
)	O
,	O
and	O
global	B
optimization	I
techniques	O
such	O
as	O
regu-	O
larization	O
and	O
markov	O
random	O
fields	O
(	O
mrfs	O
)	O
(	O
section	O
3.7	O
)	O
.	O
while	O
most	O
of	O
this	O
material	O
is	O
covered	O
in	O
courses	O
and	O
textbooks	B
on	O
image	B
processing	O
,	O
the	O
use	O
of	O
optimization	O
techniques	O
is	O
more	O
typically	O
associated	O
with	O
computer	O
vision	O
(	O
although	O
mrfs	O
are	O
now	O
being	O
widely	O
used	O
in	O
image	B
processing	O
as	O
well	O
)	O
.	O
the	O
section	O
on	O
mrfs	O
is	O
also	O
the	O
ﬁrst	O
introduction	O
to	O
the	O
use	O
of	O
bayesian	O
inference	B
techniques	O
,	O
which	O
are	O
covered	O
at	O
a	O
more	O
abstract	O
level	O
in	O
appendix	O
b.	O
chapter	O
3	O
also	O
presents	O
applications	O
such	O
as	O
seamless	O
image	B
blending	O
and	O
image	B
restoration	I
.	O
in	O
chapter	O
4	O
,	O
we	O
cover	O
feature	B
detection	O
and	O
matching	B
.	O
a	O
lot	O
of	O
current	O
3d	O
reconstruction	O
and	O
recognition	B
techniques	O
are	O
built	O
on	O
extracting	O
and	O
matching	B
feature	O
points	B
(	O
section	O
4.1	O
)	O
,	O
so	O
this	O
is	O
a	O
fundamental	O
technique	O
required	O
by	O
many	O
subsequent	O
chapters	O
(	O
chapters	O
6	O
,	O
7	O
,	O
9	O
and	O
14	O
)	O
.	O
we	O
also	O
cover	O
edge	O
and	O
straight	O
line	O
detection	O
in	O
sections	O
4.2	O
and	O
4.3.	O
chapter	O
5	O
covers	O
region	B
segmentation	O
techniques	O
,	O
including	O
active	O
contour	O
detection	B
and	O
tracking	O
(	O
section	O
5.1	O
)	O
.	O
segmentation	B
techniques	O
include	O
top-down	O
(	O
split	O
)	O
and	O
bottom-up	O
(	O
merge	O
)	O
techniques	O
,	O
mean	B
shift	I
techniques	O
that	O
ﬁnd	O
modes	O
of	O
clusters	O
,	O
and	O
various	O
graph-	O
based	O
segmentation	B
approaches	O
.	O
all	O
of	O
these	O
techniques	O
are	O
essential	O
building	O
blocks	O
that	O
are	O
widely	O
used	O
in	O
a	O
variety	O
of	O
applications	O
,	O
including	O
performance-driven	B
animation	I
,	O
interactive	B
image	O
editing	O
,	O
and	O
recognition	B
.	O
in	O
chapter	O
6	O
,	O
we	O
cover	O
geometric	B
alignment	I
and	O
camera	B
calibration	O
.	O
we	O
introduce	O
the	O
basic	O
techniques	O
of	O
feature-based	B
alignment	O
in	O
section	O
6.1	O
and	O
show	O
how	O
this	O
problem	O
can	O
be	O
solved	O
using	O
either	O
linear	B
or	O
non-linear	B
least	O
squares	O
,	O
depending	O
on	O
the	O
motion	B
involved	O
.	O
we	O
also	O
introduce	O
additional	O
concepts	O
,	O
such	O
as	O
uncertainty	B
weighting	O
and	O
robust	B
regression	O
,	O
which	O
are	O
essential	O
to	O
making	O
real-world	O
systems	O
work	O
.	O
feature-based	B
alignment	O
is	O
then	O
used	O
as	O
a	O
building	O
block	O
for	O
3d	O
pose	O
estimation	B
(	O
extrinsic	B
calibration	O
)	O
in	O
section	O
6.2	O
and	O
camera	B
(	O
intrinsic	B
)	O
calibration	B
in	O
section	O
6.3.	O
chapter	O
6	O
also	O
describes	O
applications	O
of	O
these	O
techniques	O
to	O
photo	O
alignment	O
for	O
ﬂip-book	O
animations	O
,	O
3d	O
pose	O
estimation	B
from	O
a	O
hand-held	O
camera	B
,	O
and	O
single-view	O
reconstruction	O
of	O
building	O
models	O
.	O
chapter	O
7	O
covers	O
the	O
topic	O
of	O
structure	B
from	I
motion	I
,	O
which	O
involves	O
the	O
simultaneous	O
recovery	B
of	O
3d	O
camera	B
motion	O
and	O
3d	O
scene	O
structure	O
from	O
a	O
collection	O
of	O
tracked	O
2d	O
fea-	O
24	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
tures	O
.	O
this	O
chapter	O
begins	O
with	O
the	O
easier	O
problem	O
of	O
3d	O
point	O
triangulation	O
(	O
section	O
7.1	O
)	O
,	O
which	O
is	O
the	O
3d	O
reconstruction	O
of	O
points	B
from	O
matched	O
features	O
when	O
the	O
camera	B
positions	O
are	O
known	O
.	O
it	O
then	O
describes	O
two-frame	B
structure	O
from	O
motion	B
(	O
section	O
7.2	O
)	O
,	O
for	O
which	O
al-	O
gebraic	O
techniques	O
exist	O
,	O
as	O
well	O
as	O
robust	B
sampling	O
techniques	O
such	O
as	O
ransac	O
that	O
can	O
discount	O
erroneous	O
feature	B
matches	O
.	O
the	O
second	O
half	O
of	O
chapter	O
7	O
describes	O
techniques	O
for	O
multi-frame	O
structure	B
from	I
motion	I
,	O
including	O
factorization	B
(	O
section	O
7.3	O
)	O
,	O
bundle	B
adjustment	I
(	O
section	O
7.4	O
)	O
,	O
and	O
constrained	B
motion	O
and	O
structure	O
models	O
(	O
section	O
7.5	O
)	O
.	O
it	O
also	O
presents	O
applications	O
in	O
view	B
morphing	I
,	O
sparse	B
3d	O
model	O
construction	O
,	O
and	O
match	B
move	I
.	O
in	O
chapter	O
8	O
,	O
we	O
go	O
back	O
to	O
a	O
topic	O
that	O
deals	O
directly	O
with	O
image	O
intensities	O
(	O
as	O
op-	O
posed	O
to	O
feature	B
tracks	I
)	O
,	O
namely	O
dense	O
intensity-based	O
motion	B
estimation	I
(	O
optical	B
ﬂow	I
)	O
.	O
we	O
start	O
with	O
the	O
simplest	O
possible	O
motion	B
models	I
,	O
translational	B
motion	O
(	O
section	O
8.1	O
)	O
,	O
and	O
cover	O
topics	O
such	O
as	O
hierarchical	B
(	O
coarse-to-ﬁne	B
)	O
motion	B
estimation	I
,	O
fourier-based	O
techniques	O
,	O
and	O
iterative	B
reﬁnement	O
.	O
we	O
then	O
present	O
parametric	B
motion	O
models	O
,	O
which	O
can	O
be	O
used	O
to	O
com-	O
pensate	O
for	O
camera	O
rotation	O
and	O
zooming	O
,	O
as	O
well	O
as	O
afﬁne	B
or	O
planar	B
perspective	I
motion	I
(	O
sec-	O
tion	B
8.2	O
)	O
.	O
this	O
is	O
then	O
generalized	B
to	O
spline-based	B
motion	O
models	O
(	O
section	O
8.3	O
)	O
and	O
ﬁnally	O
to	O
general	O
per-pixel	O
optical	B
ﬂow	I
(	O
section	O
8.4	O
)	O
,	O
including	O
layered	B
and	O
learned	B
motion	O
models	O
(	O
section	O
8.5	O
)	O
.	O
applications	O
of	O
these	O
techniques	O
include	O
automated	B
morphing	O
,	O
frame	O
interpo-	O
lation	O
(	O
slow	O
motion	B
)	O
,	O
and	O
motion-based	O
user	O
interfaces	O
.	O
chapter	O
9	O
is	O
devoted	O
to	O
image	B
stitching	I
,	O
i.e.	O
,	O
the	O
construction	O
of	O
large	O
panoramas	O
and	O
com-	O
posites	O
.	O
while	O
stitching	O
is	O
just	O
one	O
example	O
of	O
computation	O
photography	O
(	O
see	O
chapter	O
10	O
)	O
,	O
there	O
is	O
enough	O
depth	O
here	O
to	O
warrant	O
a	O
separate	O
chapter	O
.	O
we	O
start	O
by	O
discussing	O
various	O
pos-	O
sible	O
motion	B
models	I
(	O
section	O
9.1	O
)	O
,	O
including	O
planar	O
motion	O
and	O
pure	O
camera	O
rotation	O
.	O
we	O
then	O
discuss	O
global	B
alignment	I
(	O
section	O
9.2	O
)	O
,	O
which	O
is	O
a	O
special	O
(	O
simpliﬁed	O
)	O
case	O
of	O
general	O
bundle	B
adjustment	I
,	O
and	O
then	O
present	O
panorama	O
recognition	B
,	O
i.e.	O
,	O
techniques	O
for	O
automatically	O
discovering	O
which	O
images	O
actually	O
form	O
overlapping	O
panoramas	O
.	O
finally	O
,	O
we	O
cover	O
the	O
topics	O
of	O
image	B
compositing	O
and	O
blending	B
(	O
section	O
9.3	O
)	O
,	O
which	O
involve	O
both	O
selecting	O
which	O
pixels	O
from	O
which	O
images	O
to	O
use	O
and	O
blending	B
them	O
together	O
so	O
as	O
to	O
disguise	O
exposure	O
differences	O
.	O
image	B
stitching	I
is	O
a	O
wonderful	O
application	O
that	O
ties	O
together	O
most	O
of	O
the	O
material	O
covered	O
in	O
earlier	O
parts	O
of	O
this	O
book	O
.	O
it	O
also	O
makes	O
for	O
a	O
good	O
mid-term	O
course	O
project	O
that	O
can	O
build	O
on	O
previously	O
developed	O
techniques	O
such	O
as	O
image	B
warping	O
and	O
feature	B
detection	O
and	O
match-	O
ing	O
.	O
chapter	O
9	O
also	O
presents	O
more	O
specialized	O
variants	O
of	O
stitching	O
such	O
as	O
whiteboard	B
and	I
document	I
scanning	I
,	O
video	B
summarization	I
,	O
panography	B
,	O
full	O
360◦	O
spherical	B
panoramas	O
,	O
and	O
interactive	B
photomontage	O
for	O
blending	O
repeated	O
action	O
shots	O
together	O
.	O
chapter	O
10	O
presents	O
additional	O
examples	B
of	O
computational	O
photography	O
,	O
which	O
is	O
the	O
pro-	O
cess	O
of	O
creating	O
new	O
images	O
from	O
one	O
or	O
more	O
input	O
photographs	O
,	O
often	O
based	O
on	O
the	O
careful	O
modeling	B
and	O
calibration	B
of	O
the	O
image	B
formation	O
process	O
(	O
section	O
10.1	O
)	O
.	O
computational	O
pho-	O
tography	O
techniques	O
include	O
merging	B
multiple	O
exposures	O
to	O
create	O
high	B
dynamic	I
range	I
images	O
(	O
section	O
10.2	O
)	O
,	O
increasing	O
image	B
resolution	O
through	O
blur	B
removal	I
and	O
super-resolution	O
(	O
sec-	O
1.3	O
book	O
overview	O
25	O
tion	B
10.3	O
)	O
,	O
and	O
image	B
editing	O
and	O
compositing	B
operations	O
(	O
section	O
10.4	O
)	O
.	O
we	O
also	O
cover	O
the	O
topics	O
of	O
texture	B
analysis	O
,	O
synthesis	O
and	O
inpainting	B
(	O
hole	B
ﬁlling	I
)	O
in	O
section	O
10.5	O
,	O
as	O
well	O
as	O
non-photorealistic	B
rendering	I
(	O
section	O
10.5.2	O
)	O
.	O
in	O
chapter	O
11	O
,	O
we	O
turn	O
to	O
the	O
issue	O
of	O
stereo	B
correspondence	O
,	O
which	O
can	O
be	O
thought	O
of	O
as	O
a	O
special	O
case	O
of	O
motion	B
estimation	I
where	O
the	O
camera	B
positions	O
are	O
already	O
known	O
(	O
sec-	O
tion	B
11.1	O
)	O
.	O
this	O
additional	O
knowledge	O
enables	O
stereo	B
algorithms	O
to	O
search	O
over	O
a	O
much	O
smaller	O
space	O
of	O
correspondences	O
and	O
,	O
in	O
many	O
cases	O
,	O
to	O
produce	O
dense	O
depth	O
estimates	O
that	O
can	O
be	O
converted	O
into	O
visible	O
surface	B
models	O
(	O
section	O
11.3	O
)	O
.	O
we	O
also	O
cover	O
multi-view	B
stereo	I
algorithms	O
that	O
build	O
a	O
true	O
3d	O
surface	B
representation	O
instead	O
of	O
just	O
a	O
single	O
depth	O
map	O
(	O
section	O
11.6	O
)	O
.	O
applications	O
of	O
stereo	B
matching	I
include	O
head	B
and	O
gaze	O
tracking	O
,	O
as	O
well	O
as	O
depth-based	O
background	B
replacement	I
(	O
z-keying	B
)	O
.	O
chapter	O
12	O
covers	O
additional	O
3d	O
shape	O
and	O
appearance	O
modeling	B
techniques	O
.	O
these	O
in-	O
clude	O
classic	O
shape-from-x	O
techniques	O
such	O
as	O
shape	O
from	O
shading	B
,	O
shape	O
from	O
texture	B
,	O
and	O
shape	O
from	O
focus	B
(	O
section	O
12.1	O
)	O
,	O
as	O
well	O
as	O
shape	O
from	O
smooth	O
occluding	O
contours	O
(	O
sec-	O
tion	B
11.2.1	O
)	O
and	O
silhouettes	B
(	O
section	O
12.5	O
)	O
.	O
an	O
alternative	O
to	O
all	O
of	O
these	O
passive	O
computer	O
vision	O
techniques	O
is	O
to	O
use	O
active	O
rangeﬁnding	O
(	O
section	O
12.2	O
)	O
,	O
i.e.	O
,	O
to	O
project	O
patterned	O
light	O
onto	O
scenes	O
and	O
recover	O
the	O
3d	O
geometry	O
through	O
triangulation	B
.	O
processing	O
all	O
of	O
these	O
3d	O
representations	O
often	O
involves	O
interpolating	O
or	O
simplifying	O
the	O
geometry	O
(	O
section	O
12.3	O
)	O
,	O
or	O
using	O
alternative	O
representations	O
such	O
as	O
surface	B
point	O
sets	O
(	O
section	O
12.4	O
)	O
.	O
the	O
collection	O
of	O
techniques	O
for	O
going	O
from	O
one	O
or	O
more	O
images	O
to	O
partial	O
or	O
full	O
3d	O
models	O
is	O
often	O
called	O
image-based	B
modeling	O
or	O
3d	O
photography	O
.	O
section	O
12.6	O
examines	O
three	O
more	O
specialized	O
application	O
areas	O
(	O
architecture	B
,	O
faces	B
,	O
and	O
human	O
bodies	O
)	O
,	O
which	O
can	O
use	O
model-based	B
reconstruction	O
to	O
ﬁt	O
parameterized	O
models	O
to	O
the	O
sensed	O
data	O
.	O
section	O
12.7	O
examines	O
the	O
topic	O
of	O
appearance	O
modeling	B
,	O
i.e.	O
,	O
techniques	O
for	O
estimating	O
the	O
texture	B
maps	O
,	O
albedos	O
,	O
or	O
even	O
sometimes	O
complete	O
bi-directional	O
reﬂectance	B
distribution	O
functions	O
(	O
brdfs	O
)	O
that	O
describe	O
the	O
appearance	O
of	O
3d	O
surfaces	O
.	O
in	O
chapter	O
13	O
,	O
we	O
discuss	O
the	O
large	O
number	O
of	O
image-based	B
rendering	I
techniques	O
that	O
have	O
been	O
developed	O
in	O
the	O
last	O
two	O
decades	O
,	O
including	O
simpler	O
techniques	O
such	O
as	O
view	O
in-	O
terpolation	O
(	O
section	O
13.1	O
)	O
,	O
layered	O
depth	O
images	O
(	O
section	O
13.2	O
)	O
,	O
and	O
sprites	B
and	O
layers	B
(	O
sec-	O
tion	B
13.2.1	O
)	O
,	O
as	O
well	O
as	O
the	O
more	O
general	O
framework	O
of	O
light	O
ﬁelds	O
and	O
lumigraphs	O
(	O
sec-	O
tion	B
13.3	O
)	O
and	O
higher-order	O
ﬁelds	O
such	O
as	O
environment	O
mattes	O
(	O
section	O
13.4	O
)	O
.	O
applications	O
of	O
these	O
techniques	O
include	O
navigating	O
3d	O
collections	O
of	O
photographs	O
using	O
photo	O
tourism	O
and	O
viewing	O
3d	O
models	O
as	O
object	O
movies	O
.	O
in	O
chapter	O
13	O
,	O
we	O
also	O
discuss	O
video-based	O
rendering	O
,	O
which	O
is	O
the	O
temporal	O
extension	O
of	O
image-based	B
rendering	I
.	O
the	O
topics	O
we	O
cover	O
include	O
video-based	O
animation	O
(	O
section	O
13.5.1	O
)	O
,	O
periodic	O
video	B
turned	O
into	O
video	B
textures	I
(	O
section	O
13.5.2	O
)	O
,	O
and	O
3d	O
video	B
constructed	O
from	O
multiple	B
video	O
streams	O
(	O
section	O
13.5.4	O
)	O
.	O
applications	O
of	O
these	O
techniques	O
include	O
video	B
de-	O
noising	O
,	O
morphing	B
,	O
and	O
tours	O
based	O
on	O
360◦	O
video	B
.	O
26	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
week	O
material	O
project	O
(	O
1	O
.	O
)	O
chapter	O
2	O
image	B
formation	O
2.	O
chapter	O
3	O
image	B
processing	O
3.	O
chapter	O
4	O
feature	B
detection	O
and	O
matching	B
4.	O
chapter	O
6	O
feature-based	B
alignment	O
5.	O
chapter	O
9	O
image	B
stitching	I
6.	O
chapter	O
8	O
dense	O
motion	O
estimation	B
7.	O
chapter	O
7	O
structure	B
from	I
motion	I
8.	O
chapter	O
14	O
recognition	B
(	O
9	O
.	O
)	O
chapter	O
10	O
computational	O
photography	O
10.	O
chapter	O
11	O
stereo	B
correspondence	O
(	O
11	O
.	O
)	O
chapter	O
12	O
3d	O
reconstruction	O
12.	O
chapter	O
13	O
image-based	B
rendering	I
13.	O
final	O
project	O
presentations	O
p1	O
p2	O
pp	O
fp	O
table	O
1.1	O
sample	O
syllabi	O
for	O
10-week	O
and	O
13-week	O
courses	O
.	O
the	O
weeks	O
in	O
parentheses	O
are	O
not	O
used	O
in	O
the	O
shorter	O
version	O
.	O
p1	O
and	O
p2	O
are	O
two	O
early-term	O
mini-projects	O
,	O
pp	O
is	O
when	O
the	O
(	O
student-selected	O
)	O
ﬁnal	O
project	O
proposals	O
are	O
due	O
,	O
and	O
fp	O
is	O
the	O
ﬁnal	O
project	O
presentations	O
.	O
chapter	O
14	O
describes	O
different	O
approaches	O
to	O
recognition	B
.	O
it	O
begins	O
with	O
techniques	O
for	O
detecting	O
and	O
recognizing	O
faces	O
(	O
sections	O
14.1	O
and	O
14.2	O
)	O
,	O
then	O
looks	O
at	O
techniques	O
for	O
ﬁnding	O
and	O
recognizing	O
particular	O
objects	O
(	O
instance	B
recognition	O
)	O
in	O
section	O
14.3.	O
next	O
,	O
we	O
cover	O
the	O
most	O
difﬁcult	O
variant	O
of	O
recognition	B
,	O
namely	O
the	O
recognition	B
of	O
broad	O
categories	O
,	O
such	O
as	O
cars	O
,	O
motorcycles	O
,	O
horses	O
and	O
other	O
animals	O
(	O
section	O
14.4	O
)	O
,	O
and	O
the	O
role	O
that	O
scene	O
context	O
plays	O
in	O
recognition	B
(	O
section	O
14.5	O
)	O
.	O
to	O
support	O
the	O
book	O
’	O
s	O
use	O
as	O
a	O
textbook	O
,	O
the	O
appendices	O
and	O
associated	O
web	O
site	O
contain	O
more	O
detailed	O
mathematical	O
topics	O
and	O
additional	O
material	O
.	O
appendix	O
a	O
covers	O
linear	B
algebra	O
and	O
numerical	O
techniques	O
,	O
including	O
matrix	O
algebra	O
,	O
least	B
squares	I
,	O
and	O
iterative	B
techniques	O
.	O
appendix	O
b	O
covers	O
bayesian	O
estimation	B
theory	O
,	O
including	O
maximum	O
likelihood	O
estimation	B
,	O
robust	B
statistics	O
,	O
markov	O
random	O
ﬁelds	O
,	O
and	O
uncertainty	B
modeling	I
.	O
appendix	O
c	O
describes	O
the	O
supplementary	O
material	O
available	O
to	O
complement	O
this	O
book	O
,	O
including	O
images	O
and	O
data	B
sets	I
,	O
pointers	O
to	O
software	O
,	O
course	O
slides	O
,	O
and	O
an	O
on-line	O
bibliography	O
.	O
1.4	O
sample	O
syllabus	O
teaching	O
all	O
of	O
the	O
material	O
covered	O
in	O
this	O
book	O
in	O
a	O
single	O
quarter	O
or	O
semester	O
course	O
is	O
a	O
herculean	O
task	O
and	O
likely	O
one	O
not	O
worth	O
attempting	O
.	O
it	O
is	O
better	O
to	O
simply	O
pick	O
and	O
choose	O
1.5	O
a	O
note	O
on	O
notation	O
27	O
topics	O
related	O
to	O
the	O
lecturer	O
’	O
s	O
preferred	O
emphasis	O
and	O
tailored	O
to	O
the	O
set	O
of	O
mini-projects	O
envisioned	O
for	O
the	O
students	O
.	O
steve	O
seitz	O
and	O
i	O
have	O
successfully	O
used	O
a	O
10-week	O
syllabus	O
similar	O
to	O
the	O
one	O
shown	O
in	O
table	O
1.1	O
(	O
omitting	O
the	O
parenthesized	O
weeks	O
)	O
as	O
both	O
an	O
undergraduate	O
and	O
a	O
graduate-level	O
course	O
in	O
computer	O
vision	O
.	O
the	O
undergraduate	O
course10	O
tends	O
to	O
go	O
lighter	O
on	O
the	O
mathematics	O
and	O
takes	O
more	O
time	O
reviewing	O
basics	O
,	O
while	O
the	O
graduate-level	O
course11	O
dives	O
more	O
deeply	O
into	O
techniques	O
and	O
assumes	O
the	O
students	O
already	O
have	O
a	O
decent	O
grounding	O
in	O
either	O
vision	O
or	O
related	O
mathematical	O
techniques	O
.	O
(	O
see	O
also	O
the	O
introduction	O
to	O
computer	O
vision	O
course	O
at	O
stanford,12	O
which	O
uses	O
a	O
similar	O
curriculum	O
.	O
)	O
related	O
courses	O
have	O
also	O
been	O
taught	O
on	O
the	O
topics	O
of	O
3d	O
photography13	O
and	O
computational	O
photography.14	O
when	O
steve	O
and	O
i	O
teach	O
the	O
course	O
,	O
we	O
prefer	O
to	O
give	O
the	O
students	O
several	O
small	O
program-	O
ming	O
projects	O
early	O
in	O
the	O
course	O
rather	O
than	O
focusing	O
on	O
written	O
homework	O
or	O
quizzes	O
.	O
with	O
a	O
suitable	O
choice	O
of	O
topics	O
,	O
it	O
is	O
possible	O
for	O
these	O
projects	O
to	O
build	O
on	O
each	O
other	O
.	O
for	O
exam-	O
ple	O
,	O
introducing	O
feature	B
matching	O
early	O
on	O
can	O
be	O
used	O
in	O
a	O
second	O
assignment	O
to	O
do	O
image	B
alignment	O
and	O
stitching	O
.	O
alternatively	O
,	O
direct	B
(	O
optical	B
ﬂow	I
)	O
techniques	O
can	O
be	O
used	O
to	O
do	O
the	O
alignment	B
and	O
more	O
focus	B
can	O
be	O
put	O
on	O
either	O
graph	B
cut	I
seam	O
selection	O
or	O
multi-resolution	O
blending	B
techniques	O
.	O
we	O
also	O
ask	O
the	O
students	O
to	O
propose	O
a	O
ﬁnal	O
project	O
(	O
we	O
provide	O
a	O
set	O
of	O
suggested	O
topics	O
for	O
those	O
who	O
need	O
ideas	O
)	O
by	O
the	O
middle	O
of	O
the	O
course	O
and	O
reserve	O
the	O
last	O
week	O
of	O
the	O
class	O
for	O
student	O
presentations	O
.	O
with	O
any	O
luck	O
,	O
some	O
of	O
these	O
ﬁnal	O
projects	O
can	O
actually	O
turn	O
into	O
conference	O
submissions	O
!	O
no	O
matter	O
how	O
you	O
decide	O
to	O
structure	O
the	O
course	O
or	O
how	O
you	O
choose	O
to	O
use	O
this	O
book	O
,	O
i	O
encourage	O
you	O
to	O
try	O
at	O
least	O
a	O
few	O
small	O
programming	O
tasks	O
to	O
get	O
a	O
good	O
feel	O
for	O
how	O
vision	O
techniques	O
work	O
,	O
and	O
when	O
they	O
do	O
not	O
.	O
better	O
yet	O
,	O
pick	O
topics	O
that	O
are	O
fun	O
and	O
can	O
be	O
used	O
on	O
your	O
own	O
photographs	O
,	O
and	O
try	O
to	O
push	O
your	O
creative	O
boundaries	O
to	O
come	O
up	O
with	O
surprising	O
results	O
.	O
1.5	O
a	O
note	O
on	O
notation	O
for	O
better	O
or	O
worse	O
,	O
the	O
notation	O
found	O
in	O
computer	O
vision	O
and	O
multi-view	B
geometry	O
textbooks	B
tends	O
to	O
vary	O
all	O
over	O
the	O
map	O
(	O
faugeras	O
1993	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
girod	O
,	O
greiner	O
,	O
and	O
niemann	O
2000	O
;	O
faugeras	O
and	O
luong	O
2001	O
;	O
forsyth	O
and	O
ponce	O
2003	O
)	O
.	O
in	O
this	O
book	O
,	O
i	O
use	O
the	O
convention	O
i	O
ﬁrst	O
learned	B
in	O
my	O
high	O
school	O
physics	O
class	O
(	O
and	O
later	O
multi-variate	O
10	O
http	O
:	O
//www.cs.washington.edu/education/courses/455/	O
11	O
http	O
:	O
//www.cs.washington.edu/education/courses/576/	O
12http	O
:	O
//vision.stanford.edu/teaching/cs223b/	O
13	O
http	O
:	O
//www.cs.washington.edu/education/courses/558/06sp/	O
14	O
http	O
:	O
//graphics.cs.cmu.edu/courses/15-463/	O
28	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
calculus	O
and	O
computer	O
graphics	O
courses	O
)	O
,	O
which	O
is	O
that	O
vectors	O
v	O
are	O
lower	O
case	O
bold	O
,	O
matrices	O
m	O
are	O
upper	O
case	O
bold	O
,	O
and	O
scalars	O
(	O
t	O
,	O
s	O
)	O
are	O
mixed	O
case	O
italic	O
.	O
unless	O
otherwise	O
noted	O
,	O
vectors	O
operate	O
as	O
column	O
vectors	O
,	O
i.e.	O
,	O
they	O
post-multiply	O
matrices	O
,	O
m	O
v	O
,	O
although	O
they	O
are	O
sometimes	O
written	O
as	O
comma-separated	O
parenthesized	O
lists	O
x	O
=	O
(	O
x	O
,	O
y	O
)	O
instead	O
of	O
bracketed	O
column	O
vectors	O
x	O
=	O
[	O
x	O
y	O
]	O
t	O
.	O
some	O
commonly	O
used	O
matrices	O
are	O
r	O
for	O
rotations	O
,	O
k	O
for	O
calibration	O
matrices	O
,	O
and	O
i	O
for	O
the	O
identity	O
matrix	O
.	O
homogeneous	B
coordinates	I
(	O
section	O
2.1	O
)	O
are	O
denoted	O
with	O
a	O
tilde	O
over	O
the	O
vector	O
,	O
e.g.	O
,	O
˜x	O
=	O
(	O
˜x	O
,	O
˜y	O
,	O
˜w	O
)	O
=	O
˜w	O
(	O
x	O
,	O
y	O
,	O
1	O
)	O
=	O
˜w¯x	O
in	O
p	O
2.	O
the	O
cross	O
product	O
operator	O
in	O
matrix	O
form	O
is	O
denoted	O
by	O
[	O
]	O
.	O
×	O
1.6	O
additional	O
reading	O
this	O
book	O
attempts	O
to	O
be	O
self-contained	O
,	O
so	O
that	O
students	O
can	O
implement	O
the	O
basic	O
assignments	O
and	O
algorithms	O
described	O
here	O
without	O
the	O
need	O
for	O
outside	O
references	B
.	O
however	O
,	O
it	O
does	O
pre-	O
suppose	O
a	O
general	O
familiarity	O
with	O
basic	O
concepts	O
in	O
linear	B
algebra	O
and	O
numerical	O
techniques	O
,	O
which	O
are	O
reviewed	O
in	O
appendix	O
a	O
,	O
and	O
image	B
processing	O
,	O
which	O
is	O
reviewed	O
in	O
chapter	O
3.	O
students	O
who	O
want	O
to	O
delve	O
more	O
deeply	O
into	O
these	O
topics	O
can	O
look	O
in	O
(	O
golub	O
and	O
van	O
loan	O
1996	O
)	O
for	O
matrix	O
algebra	O
and	O
(	O
strang	O
1988	O
)	O
for	O
linear	O
algebra	O
.	O
in	O
image	B
processing	O
,	O
there	O
are	O
a	O
number	O
of	O
popular	O
textbooks	B
,	O
including	O
(	O
crane	O
1997	O
;	O
gomes	O
and	O
velho	O
1997	O
;	O
j¨ahne	O
1997	O
;	O
pratt	O
2007	O
;	O
russ	O
2007	O
;	O
burger	O
and	O
burge	O
2008	O
;	O
gonzales	O
and	O
woods	O
2008	O
)	O
.	O
for	O
computer	O
graphics	O
,	O
popular	O
texts	O
include	O
(	O
foley	O
,	O
van	O
dam	O
,	O
feiner	O
et	O
al	O
.	O
1995	O
;	O
watt	O
1995	O
)	O
,	O
with	O
(	O
glassner	O
1995	O
)	O
providing	O
a	O
more	O
in-depth	O
look	O
at	O
image	B
formation	O
and	O
rendering	B
.	O
for	O
statistics	O
and	O
machine	O
learning	O
,	O
chris	O
bishop	O
’	O
s	O
(	O
2006	O
)	O
book	O
is	O
a	O
wonderful	O
and	O
comprehen-	O
sive	O
introduction	O
with	O
a	O
wealth	O
of	O
exercises	O
.	O
students	O
may	O
also	O
want	O
to	O
look	O
in	O
other	O
textbooks	B
on	O
computer	O
vision	O
for	O
material	O
that	O
we	O
do	O
not	O
cover	O
here	O
,	O
as	O
well	O
as	O
for	O
additional	O
project	O
ideas	O
(	O
ballard	O
and	O
brown	O
1982	O
;	O
faugeras	O
1993	O
;	O
nalwa	O
1993	O
;	O
trucco	O
and	O
verri	O
1998	O
;	O
forsyth	O
and	O
ponce	O
2003	O
)	O
.	O
there	O
is	O
,	O
however	O
,	O
no	O
substitute	O
for	O
reading	O
the	O
latest	O
research	O
literature	O
,	O
both	O
for	O
the	O
lat-	O
est	O
ideas	O
and	O
techniques	O
and	O
for	O
the	O
most	O
up-to-date	O
references	B
to	O
related	O
literature.15	O
in	O
this	O
book	O
,	O
i	O
have	O
attempted	O
to	O
cite	O
the	O
most	O
recent	O
work	O
in	O
each	O
ﬁeld	O
so	O
that	O
students	O
can	O
read	O
them	O
directly	O
and	O
use	O
them	O
as	O
inspiration	O
for	O
their	O
own	O
work	O
.	O
browsing	O
the	O
last	O
few	O
years	O
’	O
con-	O
ference	O
proceedings	O
from	O
the	O
major	O
vision	O
and	O
graphics	O
conferences	O
,	O
such	O
as	O
cvpr	O
,	O
eccv	O
,	O
iccv	O
,	O
and	O
siggraph	O
,	O
will	O
provide	O
a	O
wealth	O
of	O
new	O
ideas	O
.	O
the	O
tutorials	O
offered	O
at	O
these	O
conferences	O
,	O
for	O
which	O
slides	O
or	O
notes	O
are	O
often	O
available	O
on-line	O
,	O
are	O
also	O
an	O
invaluable	O
re-	O
source	O
.	O
15	O
for	O
a	O
comprehensive	O
bibliography	O
and	O
taxonomy	B
of	O
computer	O
vision	O
research	O
,	O
keith	O
price	O
’	O
s	O
annotated	O
com-	O
puter	O
vision	O
bibliography	O
http	O
:	O
//www.visionbib.com/bibliography/contents.html	O
is	O
an	O
invaluable	O
resource	O
.	O
chapter	O
2	O
image	B
formation	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
2.1.1	O
geometric	B
primitives	O
.	O
2.1.2	O
.	O
2d	O
transformations	O
.	O
.	O
2.1.3	O
3d	O
transformations	O
.	O
3d	O
rotations	O
.	O
2.1.4	O
.	O
.	O
2.1.5	O
3d	O
to	O
2d	O
projections	B
.	O
.	O
2.1.6	O
lens	O
distortions	O
.	O
2.2	O
photometric	B
image	O
formation	O
.	O
.	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
2.2.1	O
lighting	B
.	O
.	O
2.2.2	O
reﬂectance	B
and	O
shading	B
.	O
.	O
2.2.3	O
optics	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
2.3	O
the	O
digital	O
camera	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
sampling	B
and	O
aliasing	B
.	O
.	O
.	O
.	O
.	O
2.3.1	O
2.3.2	O
color	B
.	O
2.3.3	O
compression	B
.	O
.	O
.	O
2.4	O
additional	O
reading	O
.	O
2.5	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
31	O
32	O
35	O
39	O
41	O
46	O
58	O
60	O
60	O
62	O
68	O
73	O
77	O
80	O
90	O
93	O
93	O
30	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
2.1	O
a	O
few	O
components	O
of	O
the	O
image	B
formation	O
process	O
:	O
(	O
a	O
)	O
perspective	B
projection	O
;	O
(	O
b	O
)	O
light	O
scattering	O
when	O
hitting	O
a	O
surface	B
;	O
(	O
c	O
)	O
lens	O
optics	B
;	O
(	O
d	O
)	O
bayer	O
color	O
ﬁlter	O
array	O
.	O
n^zi=102mmf=	O
100mmzo=5mdgrgrbgbggrgrbgbg	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
31	O
before	O
we	O
can	O
intelligently	O
analyze	O
and	O
manipulate	O
images	O
,	O
we	O
need	O
to	O
establish	O
a	O
vocabulary	O
for	O
describing	O
the	O
geometry	O
of	O
a	O
scene	O
.	O
we	O
also	O
need	O
to	O
understand	O
the	O
image	B
formation	O
process	O
that	O
produced	O
a	O
particular	O
image	B
given	O
a	O
set	O
of	O
lighting	B
conditions	O
,	O
scene	O
geometry	O
,	O
surface	B
properties	O
,	O
and	O
camera	B
optics	O
.	O
in	O
this	O
chapter	O
,	O
we	O
present	O
a	O
simpliﬁed	O
model	O
of	O
such	O
an	O
image	B
formation	O
process	O
.	O
section	O
2.1	O
introduces	O
the	O
basic	O
geometric	B
primitives	O
used	O
throughout	O
the	O
book	O
(	O
points	B
,	O
lines	B
,	O
and	O
planes	B
)	O
and	O
the	O
geometric	B
transformations	O
that	O
project	O
these	O
3d	O
quantities	O
into	O
2d	O
image	B
features	O
(	O
figure	O
2.1a	O
)	O
.	O
section	O
2.2	O
describes	O
how	O
lighting	B
,	O
surface	B
properties	O
(	O
fig-	O
ure	O
2.1b	O
)	O
,	O
and	O
camera	B
optics	O
(	O
figure	O
2.1c	O
)	O
interact	O
in	O
order	B
to	O
produce	O
the	O
color	B
values	O
that	O
fall	O
onto	O
the	O
image	B
sensor	O
.	O
section	O
2.3	O
describes	O
how	O
continuous	O
color	B
images	O
are	O
turned	O
into	O
discrete	B
digital	O
samples	O
inside	O
the	O
image	B
sensor	O
(	O
figure	O
2.1d	O
)	O
and	O
how	O
to	O
avoid	O
(	O
or	O
at	O
least	O
characterize	O
)	O
sampling	B
deﬁciencies	O
,	O
such	O
as	O
aliasing	B
.	O
the	O
material	O
covered	O
in	O
this	O
chapter	O
is	O
but	O
a	O
brief	O
summary	O
of	O
a	O
very	O
rich	O
and	O
deep	O
set	O
of	O
topics	O
,	O
traditionally	O
covered	O
in	O
a	O
number	O
of	O
separate	O
ﬁelds	O
.	O
a	O
more	O
thorough	O
introduction	O
to	O
the	O
geometry	O
of	O
points	B
,	O
lines	B
,	O
planes	B
,	O
and	O
projections	B
can	O
be	O
found	O
in	O
textbooks	B
on	O
multi-view	B
geometry	O
(	O
hartley	O
and	O
zisserman	O
2004	O
;	O
faugeras	O
and	O
luong	O
2001	O
)	O
and	O
computer	O
graphics	O
(	O
foley	O
,	O
van	O
dam	O
,	O
feiner	O
et	O
al	O
.	O
1995	O
)	O
.	O
the	O
image	B
formation	O
(	O
synthesis	O
)	O
process	O
is	O
traditionally	O
taught	O
as	O
part	O
of	O
a	O
computer	O
graphics	O
curriculum	O
(	O
foley	O
,	O
van	O
dam	O
,	O
feiner	O
et	O
al	O
.	O
1995	O
;	O
glass-	O
ner	O
1995	O
;	O
watt	O
1995	O
;	O
shirley	O
2005	O
)	O
but	O
it	O
is	O
also	O
studied	O
in	O
physics-based	B
computer	O
vision	O
(	O
wolff	O
,	O
shafer	O
,	O
and	O
healey	O
1992a	O
)	O
.	O
the	O
behavior	O
of	O
camera	B
lens	O
systems	O
is	O
studied	O
in	O
optics	B
(	O
m¨oller	O
1988	O
;	O
hecht	O
2001	O
;	O
ray	O
2002	O
)	O
.	O
two	O
good	O
books	O
on	O
color	B
theory	O
are	O
(	O
wyszecki	O
and	O
stiles	O
2000	O
;	O
healey	O
and	O
shafer	O
1992	O
)	O
,	O
with	O
(	O
livingstone	O
2008	O
)	O
providing	O
a	O
more	O
fun	O
and	O
in-	O
formal	O
introduction	O
to	O
the	O
topic	O
of	O
color	B
perception	O
.	O
topics	O
relating	O
to	O
sampling	B
and	O
aliasing	B
are	O
covered	O
in	O
textbooks	B
on	O
signal	O
and	O
image	B
processing	O
(	O
crane	O
1997	O
;	O
j¨ahne	O
1997	O
;	O
oppen-	O
heim	O
and	O
schafer	O
1996	O
;	O
oppenheim	O
,	O
schafer	O
,	O
and	O
buck	O
1999	O
;	O
pratt	O
2007	O
;	O
russ	O
2007	O
;	O
burger	O
and	O
burge	O
2008	O
;	O
gonzales	O
and	O
woods	O
2008	O
)	O
.	O
a	O
note	O
to	O
students	O
:	O
if	O
you	O
have	O
already	O
studied	O
computer	O
graphics	O
,	O
you	O
may	O
want	O
to	O
skim	O
the	O
material	O
in	O
section	O
2.1	O
,	O
although	O
the	O
sections	O
on	O
projective	B
depth	O
and	O
object-centered	B
projection	O
near	O
the	O
end	O
of	O
section	O
2.1.5	O
may	O
be	O
new	O
to	O
you	O
.	O
similarly	O
,	O
physics	O
students	O
(	O
as	O
well	O
as	O
computer	O
graphics	O
students	O
)	O
will	O
mostly	O
be	O
familiar	O
with	O
section	O
2.2.	O
finally	O
,	O
students	O
with	O
a	O
good	O
background	O
in	O
image	B
processing	O
will	O
already	O
be	O
familiar	O
with	O
sampling	O
issues	O
(	O
section	O
2.3	O
)	O
as	O
well	O
as	O
some	O
of	O
the	O
material	O
in	O
chapter	O
3	O
.	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
in	O
this	O
section	O
,	O
we	O
introduce	O
the	O
basic	O
2d	O
and	O
3d	O
primitives	O
used	O
in	O
this	O
textbook	O
,	O
namely	O
points	B
,	O
lines	B
,	O
and	O
planes	B
.	O
we	O
also	O
describe	O
how	O
3d	O
features	O
are	O
projected	O
into	O
2d	O
features	O
.	O
32	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
more	O
detailed	O
descriptions	O
of	O
these	O
topics	O
(	O
along	O
with	O
a	O
gentler	O
and	O
more	O
intuitive	O
introduc-	O
tion	B
)	O
can	O
be	O
found	O
in	O
textbooks	B
on	O
multiple-view	O
geometry	O
(	O
hartley	O
and	O
zisserman	O
2004	O
;	O
faugeras	O
and	O
luong	O
2001	O
)	O
.	O
2.1.1	O
geometric	B
primitives	O
geometric	B
primitives	O
form	O
the	O
basic	O
building	O
blocks	O
used	O
to	O
describe	O
three-dimensional	O
shapes	O
.	O
in	O
this	O
section	O
,	O
we	O
introduce	O
points	B
,	O
lines	B
,	O
and	O
planes	B
.	O
later	O
sections	O
of	O
the	O
book	O
discuss	O
curves	O
(	O
sections	O
5.1	O
and	O
11.2	O
)	O
,	O
surfaces	O
(	O
section	O
12.3	O
)	O
,	O
and	O
volumes	O
(	O
section	O
12.5	O
)	O
.	O
2d	O
points	B
.	O
2d	O
points	B
(	O
pixel	O
coordinates	O
in	O
an	O
image	B
)	O
can	O
be	O
denoted	O
using	O
a	O
pair	O
of	O
values	O
,	O
x	O
=	O
(	O
x	O
,	O
y	O
)	O
∈	O
r2	O
,	O
or	O
alternatively	O
,	O
(	O
2.1	O
)	O
x	O
=	O
(	O
cid:34	O
)	O
x	O
y	O
(	O
cid:35	O
)	O
.	O
(	O
as	O
stated	O
in	O
the	O
introduction	O
,	O
we	O
use	O
the	O
(	O
x1	O
,	O
x2	O
,	O
.	O
.	O
.	O
)	O
notation	O
to	O
denote	O
column	O
vectors	O
.	O
)	O
2d	O
points	B
can	O
also	O
be	O
represented	O
using	O
homogeneous	O
coordinates	O
,	O
˜x	O
=	O
(	O
˜x	O
,	O
˜y	O
,	O
˜w	O
)	O
∈	O
p	O
2	O
,	O
where	O
vectors	O
that	O
differ	O
only	O
by	O
scale	O
are	O
considered	O
to	O
be	O
equivalent	O
.	O
p	O
2	O
=	O
r3	O
−	O
(	O
0	O
,	O
0	O
,	O
0	O
)	O
is	O
called	O
the	O
2d	O
projective	B
space	O
.	O
a	O
homogeneous	O
vector	O
˜x	O
can	O
be	O
converted	O
back	O
into	O
an	O
inhomogeneous	O
vector	O
x	O
by	O
dividing	O
through	O
by	O
the	O
last	O
element	O
˜w	O
,	O
i.e.	O
,	O
˜x	O
=	O
(	O
˜x	O
,	O
˜y	O
,	O
˜w	O
)	O
=	O
˜w	O
(	O
x	O
,	O
y	O
,	O
1	O
)	O
=	O
˜w¯x	O
,	O
(	O
2.2	O
)	O
where	O
¯x	O
=	O
(	O
x	O
,	O
y	O
,	O
1	O
)	O
is	O
the	O
augmented	O
vector	O
.	O
homogeneous	O
points	O
whose	O
last	O
element	O
is	O
˜w	O
=	O
0	O
are	O
called	O
ideal	O
points	B
or	O
points	B
at	O
inﬁnity	O
and	O
do	O
not	O
have	O
an	O
equivalent	O
inhomogeneous	O
representation	O
.	O
2d	O
lines	B
.	O
the	O
corresponding	O
line	O
equation	O
is	O
2d	O
lines	B
can	O
also	O
be	O
represented	O
using	O
homogeneous	O
coordinates	O
˜l	O
=	O
(	O
a	O
,	O
b	O
,	O
c	O
)	O
.	O
¯x	O
·	O
˜l	O
=	O
ax	O
+	O
by	O
+	O
c	O
=	O
0	O
.	O
(	O
2.3	O
)	O
we	O
can	O
normalize	O
the	O
line	O
equation	O
vector	O
so	O
that	O
l	O
=	O
(	O
ˆnx	O
,	O
ˆny	O
,	O
d	O
)	O
=	O
(	O
ˆn	O
,	O
d	O
)	O
with	O
(	O
cid:107	O
)	O
ˆn	O
(	O
cid:107	O
)	O
=	O
1.	O
in	O
this	O
case	O
,	O
ˆn	O
is	O
the	O
normal	B
vector	I
perpendicular	O
to	O
the	O
line	O
and	O
d	O
is	O
its	O
distance	O
to	O
the	O
origin	O
(	O
figure	O
2.2	O
)	O
.	O
(	O
the	O
one	O
exception	O
to	O
this	O
normalization	O
is	O
the	O
line	O
at	O
inﬁnity	O
˜l	O
=	O
(	O
0	O
,	O
0	O
,	O
1	O
)	O
,	O
which	O
includes	O
all	O
(	O
ideal	O
)	O
points	B
at	O
inﬁnity	O
.	O
)	O
we	O
can	O
also	O
express	O
ˆn	O
as	O
a	O
function	O
of	O
rotation	O
angle	O
θ	O
,	O
ˆn	O
=	O
(	O
ˆnx	O
,	O
ˆny	O
)	O
=	O
(	O
cos	O
θ	O
,	O
sin	O
θ	O
)	O
(	O
figure	O
2.2a	O
)	O
.	O
this	O
representation	O
is	O
commonly	O
used	O
in	O
the	O
hough	O
transform	B
line-ﬁnding	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
33	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
2.2	O
(	O
a	O
)	O
2d	O
line	O
equation	O
and	O
(	O
b	O
)	O
3d	O
plane	O
equation	O
,	O
expressed	O
in	O
terms	O
of	O
the	O
normal	O
ˆn	O
and	O
distance	O
to	O
the	O
origin	O
d.	O
algorithm	B
,	O
which	O
is	O
discussed	O
in	O
section	O
4.3.2.	O
the	O
combination	O
(	O
θ	O
,	O
d	O
)	O
is	O
also	O
known	O
as	O
polar	O
coordinates	O
.	O
when	O
using	O
homogeneous	O
coordinates	O
,	O
we	O
can	O
compute	O
the	O
intersection	O
of	O
two	O
lines	O
as	O
˜x	O
=	O
˜l1	O
×	O
˜l2	O
,	O
(	O
2.4	O
)	O
where	O
×	O
is	O
the	O
cross	O
product	O
operator	O
.	O
similarly	O
,	O
the	O
line	O
joining	O
two	O
points	O
can	O
be	O
written	O
as	O
(	O
2.5	O
)	O
˜l	O
=	O
˜x1	O
×	O
˜x2	O
.	O
when	O
trying	O
to	O
ﬁt	O
an	O
intersection	O
point	O
to	O
multiple	B
lines	O
or	O
,	O
conversely	O
,	O
a	O
line	O
to	O
multiple	B
points	O
,	O
least	B
squares	I
techniques	O
(	O
section	O
6.1.1	O
and	O
appendix	O
a.2	O
)	O
can	O
be	O
used	O
,	O
as	O
discussed	O
in	O
exercise	O
2.1	O
.	O
2d	O
conics	O
.	O
there	O
are	O
other	O
algebraic	O
curves	O
that	O
can	O
be	O
expressed	O
with	O
simple	O
polynomial	O
homogeneous	O
equations	O
.	O
for	O
example	O
,	O
the	O
conic	O
sections	O
(	O
so	O
called	O
because	O
they	O
arise	O
as	O
the	O
intersection	O
of	O
a	O
plane	O
and	O
a	O
3d	O
cone	O
)	O
can	O
be	O
written	O
using	O
a	O
quadric	O
equation	B
˜xt	O
q˜x	O
=	O
0	O
.	O
(	O
2.6	O
)	O
quadric	O
equations	B
play	O
useful	O
roles	O
in	O
the	O
study	O
of	O
multi-view	B
geometry	O
and	O
camera	B
calibra-	O
tion	B
(	O
hartley	O
and	O
zisserman	O
2004	O
;	O
faugeras	O
and	O
luong	O
2001	O
)	O
but	O
are	O
not	O
used	O
extensively	O
in	O
this	O
book	O
.	O
3d	O
points	B
.	O
point	O
coordinates	O
in	O
three	O
dimensions	O
can	O
be	O
written	O
using	O
inhomogeneous	O
co-	O
ordinates	O
x	O
=	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
∈	O
r3	O
or	O
homogeneous	B
coordinates	I
˜x	O
=	O
(	O
˜x	O
,	O
˜y	O
,	O
˜z	O
,	O
˜w	O
)	O
∈	O
p	O
3.	O
as	O
before	O
,	O
it	O
is	O
sometimes	O
useful	O
to	O
denote	O
a	O
3d	O
point	O
using	O
the	O
augmented	O
vector	O
¯x	O
=	O
(	O
x	O
,	O
y	O
,	O
z	O
,	O
1	O
)	O
with	O
˜x	O
=	O
˜w¯x	O
.	O
yxdθnl^zxdnmy^	O
34	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.3	O
3d	O
line	O
equation	O
,	O
r	O
=	O
(	O
1	O
−	O
λ	O
)	O
p	O
+	O
λq	O
.	O
3d	O
planes	B
.	O
3d	O
planes	B
can	O
also	O
be	O
represented	O
as	O
homogeneous	B
coordinates	I
˜m	O
=	O
(	O
a	O
,	O
b	O
,	O
c	O
,	O
d	O
)	O
with	O
a	O
corresponding	O
plane	O
equation	O
¯x	O
·	O
˜m	O
=	O
ax	O
+	O
by	O
+	O
cz	O
+	O
d	O
=	O
0	O
.	O
(	O
2.7	O
)	O
we	O
can	O
also	O
normalize	O
the	O
plane	O
equation	O
as	O
m	O
=	O
(	O
ˆnx	O
,	O
ˆny	O
,	O
ˆnz	O
,	O
d	O
)	O
=	O
(	O
ˆn	O
,	O
d	O
)	O
with	O
(	O
cid:107	O
)	O
ˆn	O
(	O
cid:107	O
)	O
=	O
1.	O
in	O
this	O
case	O
,	O
ˆn	O
is	O
the	O
normal	B
vector	I
perpendicular	O
to	O
the	O
plane	O
and	O
d	O
is	O
its	O
distance	O
to	O
the	O
origin	O
(	O
figure	O
2.2b	O
)	O
.	O
as	O
with	O
the	O
case	O
of	O
2d	O
lines	B
,	O
the	O
plane	O
at	O
inﬁnity	O
˜m	O
=	O
(	O
0	O
,	O
0	O
,	O
0	O
,	O
1	O
)	O
,	O
which	O
contains	O
all	O
the	O
points	B
at	O
inﬁnity	O
,	O
can	O
not	O
be	O
normalized	B
(	O
i.e.	O
,	O
it	O
does	O
not	O
have	O
a	O
unique	O
normal	O
or	O
a	O
ﬁnite	O
distance	O
)	O
.	O
we	O
can	O
express	O
ˆn	O
as	O
a	O
function	O
of	O
two	O
angles	O
(	O
θ	O
,	O
φ	O
)	O
,	O
ˆn	O
=	O
(	O
cos	O
θ	O
cos	O
φ	O
,	O
sin	O
θ	O
cos	O
φ	O
,	O
sin	O
φ	O
)	O
,	O
(	O
2.8	O
)	O
i.e.	O
,	O
using	O
spherical	O
coordinates	O
,	O
but	O
these	O
are	O
less	O
commonly	O
used	O
than	O
polar	O
coordinates	O
since	O
they	O
do	O
not	O
uniformly	O
sample	O
the	O
space	O
of	O
possible	O
normal	B
vectors	I
.	O
3d	O
lines	B
.	O
lines	B
in	O
3d	O
are	O
less	O
elegant	O
than	O
either	O
lines	B
in	O
2d	O
or	O
planes	B
in	O
3d	O
.	O
one	O
possible	O
representation	O
is	O
to	O
use	O
two	O
points	O
on	O
the	O
line	O
,	O
(	O
p	O
,	O
q	O
)	O
.	O
any	O
other	O
point	O
on	O
the	O
line	O
can	O
be	O
expressed	O
as	O
a	O
linear	B
combination	O
of	O
these	O
two	O
points	O
r	O
=	O
(	O
1	O
−	O
λ	O
)	O
p	O
+	O
λq	O
,	O
(	O
2.9	O
)	O
as	O
shown	O
in	O
figure	O
2.3.	O
if	O
we	O
restrict	O
0	O
≤	O
λ	O
≤	O
1	O
,	O
we	O
get	O
the	O
line	O
segment	O
joining	O
p	O
and	O
q.	O
if	O
we	O
use	O
homogeneous	B
coordinates	I
,	O
we	O
can	O
write	O
the	O
line	O
as	O
(	O
2.10	O
)	O
a	O
special	O
case	O
of	O
this	O
is	O
when	O
the	O
second	O
point	O
is	O
at	O
inﬁnity	O
,	O
i.e.	O
,	O
˜q	O
=	O
(	O
ˆdx	O
,	O
ˆdy	O
,	O
ˆdz	O
,	O
0	O
)	O
=	O
(	O
ˆd	O
,	O
0	O
)	O
.	O
here	O
,	O
we	O
see	O
that	O
ˆd	O
is	O
the	O
direction	O
of	O
the	O
line	O
.	O
we	O
can	O
then	O
re-write	O
the	O
inhomogeneous	O
3d	O
line	O
equation	O
as	O
˜r	O
=	O
µ˜p	O
+	O
λ˜q	O
.	O
r	O
=	O
p	O
+	O
λ	O
ˆd	O
.	O
(	O
2.11	O
)	O
zxλpqyr=	O
(	O
1-λ	O
)	O
p+λq	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
35	O
a	O
disadvantage	O
of	O
the	O
endpoint	O
representation	O
for	O
3d	O
lines	B
is	O
that	O
it	O
has	O
too	O
many	O
degrees	O
of	O
freedom	O
,	O
i.e.	O
,	O
six	O
(	O
three	O
for	O
each	O
endpoint	O
)	O
instead	O
of	O
the	O
four	O
degrees	O
that	O
a	O
3d	O
line	O
truly	O
has	O
.	O
however	O
,	O
if	O
we	O
ﬁx	O
the	O
two	O
points	O
on	O
the	O
line	O
to	O
lie	O
in	O
speciﬁc	O
planes	B
,	O
we	O
obtain	O
a	O
rep-	O
resentation	O
with	O
four	O
degrees	O
of	O
freedom	O
.	O
for	O
example	O
,	O
if	O
we	O
are	O
representing	O
nearly	O
vertical	O
lines	B
,	O
then	O
z	O
=	O
0	O
and	O
z	O
=	O
1	O
form	O
two	O
suitable	O
planes	B
,	O
i.e.	O
,	O
the	O
(	O
x	O
,	O
y	O
)	O
coordinates	O
in	O
both	O
planes	B
provide	O
the	O
four	O
coordinates	O
describing	O
the	O
line	O
.	O
this	O
kind	O
of	O
two-plane	O
parameteri-	O
zation	O
is	O
used	O
in	O
the	O
light	B
ﬁeld	I
and	O
lumigraph	O
image-based	B
rendering	I
systems	O
described	O
in	O
chapter	O
13	O
to	O
represent	O
the	O
collection	O
of	O
rays	O
seen	O
by	O
a	O
camera	B
as	O
it	O
moves	O
in	O
front	O
of	O
an	O
object	O
.	O
the	O
two-endpoint	O
representation	O
is	O
also	O
useful	O
for	O
representing	O
line	O
segments	O
,	O
even	O
when	O
their	O
exact	O
endpoints	O
can	O
not	O
be	O
seen	O
(	O
only	O
guessed	O
at	O
)	O
.	O
if	O
we	O
wish	O
to	O
represent	O
all	O
possible	O
lines	B
without	O
bias	O
towards	O
any	O
particular	O
orientation	O
,	O
we	O
can	O
use	O
pl¨ucker	O
coordinates	O
(	O
hartley	O
and	O
zisserman	O
2004	O
,	O
chapter	O
2	O
;	O
faugeras	O
and	O
luong	O
2001	O
,	O
chapter	O
3	O
)	O
.	O
these	O
coordinates	O
are	O
the	O
six	O
independent	O
non-zero	O
entries	O
in	O
the	O
4×4	O
skew	O
symmetric	O
matrix	O
(	O
2.12	O
)	O
l	O
=	O
˜p˜qt	O
−	O
˜q	O
˜pt	O
,	O
where	O
˜p	O
and	O
˜q	O
are	O
any	O
two	O
(	O
non-identical	O
)	O
points	B
on	O
the	O
line	O
.	O
this	O
representation	O
has	O
only	O
four	O
degrees	O
of	O
freedom	O
,	O
since	O
l	O
is	O
homogeneous	O
and	O
also	O
satisﬁes	O
det	O
(	O
l	O
)	O
=	O
0	O
,	O
which	O
results	O
in	O
a	O
quadratic	O
constraint	B
on	O
the	O
pl¨ucker	O
coordinates	O
.	O
in	O
practice	O
,	O
the	O
minimal	O
representation	O
is	O
not	O
essential	O
for	O
most	O
applications	O
.	O
an	O
ade-	O
quate	O
model	O
of	O
3d	O
lines	B
can	O
be	O
obtained	O
by	O
estimating	O
their	O
direction	O
(	O
which	O
may	O
be	O
known	O
ahead	O
of	O
time	O
,	O
e.g.	O
,	O
for	O
architecture	O
)	O
and	O
some	O
point	O
within	O
the	O
visible	O
portion	O
of	O
the	O
line	O
(	O
see	O
section	O
7.5.1	O
)	O
or	O
by	O
using	O
the	O
two	O
endpoints	O
,	O
since	O
lines	B
are	O
most	O
often	O
visible	O
as	O
ﬁnite	O
line	O
segments	O
.	O
however	O
,	O
if	O
you	O
are	O
interested	O
in	O
more	O
details	O
about	O
the	O
topic	O
of	O
minimal	O
line	O
parameterizations	O
,	O
f¨orstner	O
(	O
2005	O
)	O
discusses	O
various	O
ways	O
to	O
infer	O
and	O
model	O
3d	O
lines	B
in	O
projective	B
geometry	O
,	O
as	O
well	O
as	O
how	O
to	O
estimate	O
the	O
uncertainty	B
in	O
such	O
ﬁtted	O
models	O
.	O
3d	O
quadrics	O
.	O
the	O
3d	O
analog	O
of	O
a	O
conic	O
section	O
is	O
a	O
quadric	O
surface	B
¯xt	O
q¯x	O
=	O
0	O
(	O
2.13	O
)	O
(	O
hartley	O
and	O
zisserman	O
2004	O
,	O
chapter	O
2	O
)	O
.	O
again	O
,	O
while	O
quadric	O
surfaces	O
are	O
useful	O
in	O
the	O
study	O
of	O
multi-view	B
geometry	O
and	O
can	O
also	O
serve	O
as	O
useful	O
modeling	B
primitives	O
(	O
spheres	O
,	O
ellipsoids	O
,	O
cylinders	O
)	O
,	O
we	O
do	O
not	O
study	O
them	O
in	O
great	O
detail	O
in	O
this	O
book	O
.	O
2.1.2	O
2d	O
transformations	O
having	O
deﬁned	O
our	O
basic	O
primitives	O
,	O
we	O
can	O
now	O
turn	O
our	O
attention	O
to	O
how	O
they	O
can	O
be	O
trans-	O
formed	O
.	O
the	O
simplest	O
transformations	O
occur	O
in	O
the	O
2d	O
plane	O
and	O
are	O
illustrated	O
in	O
figure	O
2.4	O
.	O
36	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.4	O
basic	O
set	O
of	O
2d	O
planar	O
transformations	O
.	O
translation	B
.	O
2d	O
translations	O
can	O
be	O
written	O
as	O
x	O
(	O
cid:48	O
)	O
=	O
x	O
+	O
t	O
or	O
(	O
2.14	O
)	O
(	O
2.15	O
)	O
where	O
i	O
is	O
the	O
(	O
2	O
×	O
2	O
)	O
identity	O
matrix	O
or	O
x	O
(	O
cid:48	O
)	O
=	O
(	O
cid:104	O
)	O
i	O
¯x	O
(	O
cid:48	O
)	O
=	O
(	O
cid:34	O
)	O
i	O
0t	O
t	O
(	O
cid:105	O
)	O
¯x	O
1	O
(	O
cid:35	O
)	O
¯x	O
t	O
where	O
0	O
is	O
the	O
zero	O
vector	O
.	O
using	O
a	O
2	O
×	O
3	O
matrix	O
results	O
in	O
a	O
more	O
compact	O
notation	O
,	O
whereas	O
using	O
a	O
full-rank	O
3	O
×	O
3	O
matrix	O
(	O
which	O
can	O
be	O
obtained	O
from	O
the	O
2	O
×	O
3	O
matrix	O
by	O
appending	O
a	O
[	O
0t	O
1	O
]	O
row	O
)	O
makes	O
it	O
possible	O
to	O
chain	O
transformations	O
using	O
matrix	O
multiplication	B
.	O
note	O
that	O
in	O
any	O
equation	B
where	O
an	O
augmented	O
vector	O
such	O
as	O
¯x	O
appears	O
on	O
both	O
sides	O
,	O
it	O
can	O
always	O
be	O
replaced	O
with	O
a	O
full	O
homogeneous	O
vector	O
˜x	O
.	O
where	O
rotation	O
+	O
translation	B
.	O
this	O
transformation	O
is	O
also	O
known	O
as	O
2d	O
rigid	B
body	I
motion	O
or	O
the	O
2d	O
euclidean	O
transformation	O
(	O
since	O
euclidean	O
distances	O
are	O
preserved	O
)	O
.	O
it	O
can	O
be	O
written	O
as	O
x	O
(	O
cid:48	O
)	O
=	O
rx	O
+	O
t	O
or	O
x	O
(	O
cid:48	O
)	O
=	O
(	O
cid:104	O
)	O
r	O
t	O
(	O
cid:105	O
)	O
¯x	O
r	O
=	O
(	O
cid:34	O
)	O
cos	O
θ	O
−	O
sin	O
θ	O
cos	O
θ	O
(	O
cid:35	O
)	O
is	O
an	O
orthonormal	O
rotation	O
matrix	O
with	O
rrt	O
=	O
i	O
and	O
|r|	O
=	O
1.	O
scaled	B
rotation	I
.	O
also	O
known	O
as	O
the	O
similarity	B
transform	O
,	O
this	O
transformation	O
can	O
be	O
ex-	O
pressed	O
as	O
x	O
(	O
cid:48	O
)	O
=	O
srx	O
+	O
t	O
where	O
s	O
is	O
an	O
arbitrary	O
scale	O
factor	O
.	O
it	O
can	O
also	O
be	O
written	O
as	O
(	O
2.16	O
)	O
(	O
2.17	O
)	O
sin	O
θ	O
x	O
(	O
cid:48	O
)	O
=	O
(	O
cid:104	O
)	O
sr	O
t	O
(	O
cid:105	O
)	O
¯x	O
=	O
(	O
cid:34	O
)	O
a	O
−b	O
a	O
b	O
tx	O
ty	O
(	O
cid:35	O
)	O
¯x	O
,	O
(	O
2.18	O
)	O
where	O
we	O
no	O
longer	O
require	O
that	O
a2	O
+	O
b2	O
=	O
1.	O
the	O
similarity	B
transform	O
preserves	O
angles	O
between	O
lines	B
.	O
yxsimilarityeuclideanaffineprojectivetranslation	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
37	O
afﬁne	B
.	O
the	O
afﬁne	B
transformation	O
is	O
written	O
as	O
x	O
(	O
cid:48	O
)	O
=	O
a¯x	O
,	O
where	O
a	O
is	O
an	O
arbitrary	O
2	O
×	O
3	O
matrix	O
,	O
i.e.	O
,	O
x	O
(	O
cid:48	O
)	O
=	O
(	O
cid:34	O
)	O
a00	O
a01	O
a02	O
a10	O
a11	O
a12	O
(	O
cid:35	O
)	O
¯x	O
.	O
(	O
2.19	O
)	O
parallel	O
lines	B
remain	O
parallel	O
under	O
afﬁne	B
transformations	O
.	O
projective	B
.	O
this	O
transformation	O
,	O
also	O
known	O
as	O
a	O
perspective	B
transform	O
or	O
homography	B
,	O
operates	O
on	O
homogeneous	B
coordinates	I
,	O
˜x	O
(	O
cid:48	O
)	O
=	O
˜h	O
˜x	O
,	O
(	O
2.20	O
)	O
where	O
˜h	O
is	O
an	O
arbitrary	O
3	O
×	O
3	O
matrix	O
.	O
note	O
that	O
˜h	O
is	O
homogeneous	O
,	O
i.e.	O
,	O
it	O
is	O
only	O
deﬁned	O
up	O
to	O
a	O
scale	O
,	O
and	O
that	O
two	O
˜h	O
matrices	O
that	O
differ	O
only	O
by	O
scale	O
are	O
equivalent	O
.	O
the	O
resulting	O
homogeneous	O
coordinate	O
˜x	O
(	O
cid:48	O
)	O
must	O
be	O
normalized	B
in	O
order	B
to	O
obtain	O
an	O
inhomogeneous	O
result	O
x	O
,	O
i.e.	O
,	O
x	O
(	O
cid:48	O
)	O
=	O
h00x	O
+	O
h01y	O
+	O
h02	O
h20x	O
+	O
h21y	O
+	O
h22	O
and	O
y	O
(	O
cid:48	O
)	O
=	O
h10x	O
+	O
h11y	O
+	O
h12	O
h20x	O
+	O
h21y	O
+	O
h22	O
.	O
(	O
2.21	O
)	O
perspective	B
transformations	O
preserve	O
straight	O
lines	B
(	O
i.e.	O
,	O
they	O
remain	O
straight	O
after	O
the	O
trans-	O
formation	O
)	O
.	O
hierarchy	B
of	O
2d	O
transformations	O
.	O
the	O
preceding	O
set	O
of	O
transformations	O
are	O
illustrated	O
in	O
figure	O
2.4	O
and	O
summarized	O
in	O
table	O
2.1.	O
the	O
easiest	O
way	O
to	O
think	O
of	O
them	O
is	O
as	O
a	O
set	O
of	O
(	O
potentially	O
restricted	B
)	O
3	O
×	O
3	O
matrices	O
operating	O
on	O
2d	O
homogeneous	O
coordinate	O
vectors	O
.	O
hartley	O
and	O
zisserman	O
(	O
2004	O
)	O
contains	O
a	O
more	O
detailed	O
description	O
of	O
the	O
hierarchy	B
of	O
2d	O
planar	O
transformations	O
.	O
the	O
above	O
transformations	O
form	O
a	O
nested	O
set	O
of	O
groups	O
,	O
i.e.	O
,	O
they	O
are	O
closed	O
under	O
com-	O
position	O
and	O
have	O
an	O
inverse	B
that	O
is	O
a	O
member	O
of	O
the	O
same	O
group	O
.	O
(	O
this	O
will	O
be	O
important	O
later	O
when	O
applying	O
these	O
transformations	O
to	O
images	O
in	O
section	O
3.6	O
.	O
)	O
each	O
(	O
simpler	O
)	O
group	O
is	O
a	O
subset	O
of	O
the	O
more	O
complex	O
group	O
below	O
it	O
.	O
co-vectors	O
.	O
while	O
the	O
above	O
transformations	O
can	O
be	O
used	O
to	O
transform	B
points	O
in	O
a	O
2d	O
plane	O
,	O
can	O
they	O
also	O
be	O
used	O
directly	O
to	O
transform	B
a	O
line	O
equation	O
?	O
consider	O
the	O
homogeneous	O
equa-	O
tion	B
˜l	O
·	O
˜x	O
=	O
0.	O
if	O
we	O
transform	B
x	O
(	O
cid:48	O
)	O
=	O
˜hx	O
,	O
we	O
obtain	O
˜l	O
(	O
cid:48	O
)	O
·	O
˜x	O
(	O
cid:48	O
)	O
=	O
˜l	O
(	O
cid:48	O
)	O
t	O
˜h	O
˜x	O
=	O
(	O
˜h	O
t	O
˜l	O
(	O
cid:48	O
)	O
)	O
t	O
˜x	O
=	O
˜l	O
·	O
˜x	O
=	O
0	O
,	O
(	O
2.22	O
)	O
i.e.	O
,	O
˜l	O
(	O
cid:48	O
)	O
=	O
˜h−t	O
˜l	O
.	O
thus	O
,	O
the	O
action	O
of	O
a	O
projective	B
transformation	O
on	O
a	O
co-vector	O
such	O
as	O
a	O
2d	O
line	O
or	O
3d	O
normal	O
can	O
be	O
represented	O
by	O
the	O
transposed	O
inverse	B
of	O
the	O
matrix	O
,	O
which	O
is	O
equiv-	O
alent	O
to	O
the	O
adjoint	O
of	O
˜h	O
,	O
since	O
projective	B
transformation	O
matrices	O
are	O
homogeneous	O
.	O
jim	O
38	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
transformation	O
matrix	O
#	O
dof	O
preserves	O
icon	O
translation	B
rigid	O
(	O
euclidean	O
)	O
similarity	B
afﬁne	O
projective	B
(	O
cid:104	O
)	O
i	O
t	O
(	O
cid:105	O
)	O
2×3	O
(	O
cid:104	O
)	O
r	O
t	O
(	O
cid:105	O
)	O
2×3	O
(	O
cid:104	O
)	O
sr	O
t	O
(	O
cid:105	O
)	O
2×3	O
(	O
cid:104	O
)	O
a	O
(	O
cid:105	O
)	O
2×3	O
(	O
cid:104	O
)	O
˜h	O
(	O
cid:105	O
)	O
3×3	O
2	O
3	O
4	O
6	O
8	O
orientation	O
lengths	O
angles	O
	O
ss	O
ss	O
	O
	O
s	O
s	O
	O
	O
	O
straight	O
lines	B
``	O
parallelism	O
table	O
2.1	O
hierarchy	B
of	O
2d	O
coordinate	B
transformations	I
.	O
each	O
transformation	O
also	O
preserves	O
the	O
properties	B
listed	O
in	O
the	O
rows	O
below	O
it	O
,	O
i.e.	O
,	O
similarity	B
preserves	O
not	O
only	O
angles	O
but	O
also	O
parallelism	O
and	O
straight	O
lines	B
.	O
the	O
2×3	O
matrices	O
are	O
extended	O
with	O
a	O
third	O
[	O
0t	O
1	O
]	O
row	O
to	O
form	O
a	O
full	O
3	O
×	O
3	O
matrix	O
for	O
homogeneous	O
coordinate	O
transformations	O
.	O
blinn	O
(	O
1998	O
)	O
describes	O
(	O
in	O
chapters	O
9	O
and	O
10	O
)	O
the	O
ins	O
and	O
outs	O
of	O
notating	O
and	O
manipulating	O
co-vectors	O
.	O
while	O
the	O
above	O
transformations	O
are	O
the	O
ones	O
we	O
use	O
most	O
extensively	O
,	O
a	O
number	O
of	O
addi-	O
tional	O
transformations	O
are	O
sometimes	O
used	O
.	O
stretch/squash	O
.	O
this	O
transformation	O
changes	O
the	O
aspect	O
ratio	O
of	O
an	O
image	B
,	O
x	O
(	O
cid:48	O
)	O
=	O
sxx	O
+	O
tx	O
y	O
(	O
cid:48	O
)	O
=	O
syy	O
+	O
ty	O
,	O
and	O
is	O
a	O
restricted	B
form	O
of	O
an	O
afﬁne	B
transformation	O
.	O
unfortunately	O
,	O
it	O
does	O
not	O
nest	O
cleanly	O
with	O
the	O
groups	O
listed	O
in	O
table	O
2.1.	O
planar	O
surface	O
ﬂow	O
.	O
this	O
eight-parameter	O
transformation	O
(	O
horn	O
1986	O
;	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
;	O
girod	O
,	O
greiner	O
,	O
and	O
niemann	O
2000	O
)	O
,	O
x	O
(	O
cid:48	O
)	O
=	O
a0	O
+	O
a1x	O
+	O
a2y	O
+	O
a6x2	O
+	O
a7xy	O
y	O
(	O
cid:48	O
)	O
=	O
a3	O
+	O
a4x	O
+	O
a5y	O
+	O
a7x2	O
+	O
a6xy	O
,	O
arises	O
when	O
a	O
planar	O
surface	O
undergoes	O
a	O
small	O
3d	O
motion	B
.	O
it	O
can	O
thus	O
be	O
thought	O
of	O
as	O
a	O
small	O
motion	B
approximation	O
to	O
a	O
full	O
homography	B
.	O
its	O
main	O
attraction	O
is	O
that	O
it	O
is	O
linear	B
in	O
the	O
motion	B
parameters	O
,	O
ak	O
,	O
which	O
are	O
often	O
the	O
quantities	O
being	O
estimated	O
.	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
39	O
transformation	O
matrix	O
#	O
dof	O
preserves	O
icon	O
translation	B
rigid	O
(	O
euclidean	O
)	O
similarity	B
afﬁne	O
projective	B
(	O
cid:104	O
)	O
i	O
t	O
(	O
cid:105	O
)	O
3×4	O
(	O
cid:104	O
)	O
r	O
t	O
(	O
cid:105	O
)	O
3×4	O
(	O
cid:104	O
)	O
sr	O
t	O
(	O
cid:105	O
)	O
3×4	O
(	O
cid:104	O
)	O
a	O
(	O
cid:105	O
)	O
3×4	O
(	O
cid:104	O
)	O
˜h	O
(	O
cid:105	O
)	O
4×4	O
3	O
6	O
7	O
12	O
15	O
orientation	O
angles	O
lengths	O
	O
ss	O
ss	O
	O
	O
s	O
s	O
	O
	O
	O
straight	O
lines	B
``	O
parallelism	O
table	O
2.2	O
hierarchy	B
of	O
3d	O
coordinate	B
transformations	I
.	O
each	O
transformation	O
also	O
preserves	O
the	O
properties	B
listed	O
in	O
the	O
rows	O
below	O
it	O
,	O
i.e.	O
,	O
similarity	B
preserves	O
not	O
only	O
angles	O
but	O
also	O
parallelism	O
and	O
straight	O
lines	B
.	O
the	O
3	O
×	O
4	O
matrices	O
are	O
extended	O
with	O
a	O
fourth	O
[	O
0t	O
1	O
]	O
row	O
to	O
form	O
a	O
full	O
4	O
×	O
4	O
matrix	O
for	O
homogeneous	O
coordinate	O
transformations	O
.	O
the	O
mnemonic	O
icons	O
are	O
drawn	O
in	O
2d	O
but	O
are	O
meant	O
to	O
suggest	O
transformations	O
occurring	O
in	O
a	O
full	O
3d	O
cube	O
.	O
bilinear	B
interpolant	O
.	O
this	O
eight-parameter	O
transform	B
(	O
wolberg	O
1990	O
)	O
,	O
x	O
(	O
cid:48	O
)	O
=	O
a0	O
+	O
a1x	O
+	O
a2y	O
+	O
a6xy	O
y	O
(	O
cid:48	O
)	O
=	O
a3	O
+	O
a4x	O
+	O
a5y	O
+	O
a7xy	O
,	O
can	O
be	O
used	O
to	O
interpolate	O
the	O
deformation	O
due	O
to	O
the	O
motion	B
of	O
the	O
four	O
corner	O
points	B
of	O
a	O
square	O
.	O
(	O
in	O
fact	O
,	O
it	O
can	O
interpolate	O
the	O
motion	B
of	O
any	O
four	O
non-collinear	O
points	B
.	O
)	O
while	O
the	O
deformation	O
is	O
linear	B
in	O
the	O
motion	B
parameters	O
,	O
it	O
does	O
not	O
generally	O
preserve	O
straight	O
lines	B
(	O
only	O
lines	B
parallel	O
to	O
the	O
square	O
axes	O
)	O
.	O
however	O
,	O
it	O
is	O
often	O
quite	O
useful	O
,	O
e.g.	O
,	O
in	O
the	O
interpolation	B
of	O
sparse	B
grids	O
using	O
splines	O
(	O
section	O
8.3	O
)	O
.	O
2.1.3	O
3d	O
transformations	O
the	O
set	O
of	O
three-dimensional	O
coordinate	B
transformations	I
is	O
very	O
similar	O
to	O
that	O
available	O
for	O
2d	O
transformations	O
and	O
is	O
summarized	O
in	O
table	O
2.2.	O
as	O
in	O
2d	O
,	O
these	O
transformations	O
form	O
a	O
nested	O
set	O
of	O
groups	O
.	O
hartley	O
and	O
zisserman	O
(	O
2004	O
,	O
section	O
2.4	O
)	O
give	O
a	O
more	O
detailed	O
descrip-	O
tion	B
of	O
this	O
hierarchy	B
.	O
translation	B
.	O
3d	O
translations	O
can	O
be	O
written	O
as	O
x	O
(	O
cid:48	O
)	O
=	O
x	O
+	O
t	O
or	O
x	O
(	O
cid:48	O
)	O
=	O
(	O
cid:104	O
)	O
i	O
t	O
(	O
cid:105	O
)	O
¯x	O
(	O
2.23	O
)	O
40	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
where	O
i	O
is	O
the	O
(	O
3	O
×	O
3	O
)	O
identity	O
matrix	O
and	O
0	O
is	O
the	O
zero	O
vector	O
.	O
rotation	O
+	O
translation	B
.	O
also	O
known	O
as	O
3d	O
rigid	B
body	I
motion	O
or	O
the	O
3d	O
euclidean	O
trans-	O
formation	O
,	O
it	O
can	O
be	O
written	O
as	O
x	O
(	O
cid:48	O
)	O
=	O
rx	O
+	O
t	O
or	O
x	O
(	O
cid:48	O
)	O
=	O
(	O
cid:104	O
)	O
r	O
t	O
(	O
cid:105	O
)	O
¯x	O
(	O
2.24	O
)	O
where	O
r	O
is	O
a	O
3	O
×	O
3	O
orthonormal	O
rotation	O
matrix	O
with	O
rrt	O
=	O
i	O
and	O
|r|	O
=	O
1.	O
note	O
that	O
sometimes	O
it	O
is	O
more	O
convenient	O
to	O
describe	O
a	O
rigid	O
motion	O
using	O
x	O
(	O
cid:48	O
)	O
=	O
r	O
(	O
x	O
−	O
c	O
)	O
=	O
rx	O
−	O
rc	O
,	O
(	O
2.25	O
)	O
where	O
c	O
is	O
the	O
center	O
of	O
rotation	O
(	O
often	O
the	O
camera	B
center	O
)	O
.	O
compactly	O
parameterizing	O
a	O
3d	O
rotation	O
is	O
a	O
non-trivial	O
task	O
,	O
which	O
we	O
describe	O
in	O
more	O
detail	O
below	O
.	O
scaled	B
rotation	I
.	O
the	O
3d	O
similarity	B
transform	O
can	O
be	O
expressed	O
as	O
x	O
(	O
cid:48	O
)	O
=	O
srx	O
+	O
t	O
where	O
s	O
is	O
an	O
arbitrary	O
scale	O
factor	O
.	O
it	O
can	O
also	O
be	O
written	O
as	O
this	O
transformation	O
preserves	O
angles	O
between	O
lines	B
and	O
planes	B
.	O
x	O
(	O
cid:48	O
)	O
=	O
(	O
cid:104	O
)	O
sr	O
t	O
(	O
cid:105	O
)	O
¯x	O
.	O
(	O
2.26	O
)	O
afﬁne	B
.	O
the	O
afﬁne	B
transform	O
is	O
written	O
as	O
x	O
(	O
cid:48	O
)	O
=	O
a¯x	O
,	O
where	O
a	O
is	O
an	O
arbitrary	O
3	O
×	O
4	O
matrix	O
,	O
i.e.	O
,	O
x	O
(	O
cid:48	O
)	O
=	O
a00	O
a01	O
a02	O
a03	O
a10	O
a11	O
a12	O
a13	O
a20	O
a21	O
a22	O
a23	O
	O
¯x	O
.	O
parallel	O
lines	B
and	O
planes	B
remain	O
parallel	O
under	O
afﬁne	B
transformations	O
.	O
(	O
2.27	O
)	O
projective	B
.	O
this	O
transformation	O
,	O
variously	O
known	O
as	O
a	O
3d	O
perspective	B
transform	O
,	O
homogra-	O
phy	O
,	O
or	O
collineation	B
,	O
operates	O
on	O
homogeneous	B
coordinates	I
,	O
˜x	O
(	O
cid:48	O
)	O
=	O
˜h	O
˜x	O
,	O
(	O
2.28	O
)	O
where	O
˜h	O
is	O
an	O
arbitrary	O
4	O
×	O
4	O
homogeneous	O
matrix	O
.	O
as	O
in	O
2d	O
,	O
the	O
resulting	O
homogeneous	O
coordinate	O
˜x	O
(	O
cid:48	O
)	O
must	O
be	O
normalized	B
in	O
order	B
to	O
obtain	O
an	O
inhomogeneous	O
result	O
x.	O
perspective	B
transformations	O
preserve	O
straight	O
lines	B
(	O
i.e.	O
,	O
they	O
remain	O
straight	O
after	O
the	O
transformation	O
)	O
.	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
41	O
figure	O
2.5	O
rotation	O
around	O
an	O
axis	O
ˆn	O
by	O
an	O
angle	O
θ	O
.	O
2.1.4	O
3d	O
rotations	O
the	O
biggest	O
difference	B
between	O
2d	O
and	O
3d	O
coordinate	B
transformations	I
is	O
that	O
the	O
parameter-	O
ization	O
of	O
the	O
3d	O
rotation	O
matrix	O
r	O
is	O
not	O
as	O
straightforward	O
but	O
several	O
possibilities	O
exist	O
.	O
euler	O
angles	O
a	O
rotation	O
matrix	O
can	O
be	O
formed	O
as	O
the	O
product	O
of	O
three	O
rotations	O
around	O
three	O
cardinal	O
axes	O
,	O
e.g.	O
,	O
x	O
,	O
y	O
,	O
and	O
z	O
,	O
or	O
x	O
,	O
y	O
,	O
and	O
x.	O
this	O
is	O
generally	O
a	O
bad	O
idea	O
,	O
as	O
the	O
result	O
depends	O
on	O
the	O
order	B
in	O
which	O
the	O
transforms	O
are	O
applied	O
.	O
what	O
is	O
worse	O
,	O
it	O
is	O
not	O
always	O
possible	O
to	O
move	O
smoothly	O
in	O
the	O
parameter	O
space	O
,	O
i.e.	O
,	O
sometimes	O
one	O
or	O
more	O
of	O
the	O
euler	O
angles	O
change	O
dramatically	O
in	O
response	O
to	O
a	O
small	O
change	O
in	O
rotation.1	O
for	O
these	O
reasons	O
,	O
we	O
do	O
not	O
even	O
give	O
the	O
formula	O
for	O
euler	O
angles	O
in	O
this	O
book—interested	O
readers	O
can	O
look	O
in	O
other	O
textbooks	B
or	O
technical	O
reports	O
(	O
faugeras	O
1993	O
;	O
diebel	O
2006	O
)	O
.	O
note	O
that	O
,	O
in	O
some	O
applications	O
,	O
if	O
the	O
rotations	O
are	O
known	O
to	O
be	O
a	O
set	O
of	O
uni-axial	O
transforms	O
,	O
they	O
can	O
always	O
be	O
represented	O
using	O
an	O
explicit	O
set	O
of	O
rigid	O
transformations	O
.	O
axis/angle	B
(	O
exponential	B
twist	I
)	O
a	O
rotation	O
can	O
be	O
represented	O
by	O
a	O
rotation	O
axis	O
ˆn	O
and	O
an	O
angle	O
θ	O
,	O
or	O
equivalently	O
by	O
a	O
3d	O
vector	O
ω	O
=	O
θˆn	O
.	O
figure	O
2.5	O
shows	O
how	O
we	O
can	O
compute	O
the	O
equivalent	O
rotation	O
.	O
first	O
,	O
we	O
project	O
the	O
vector	O
v	O
onto	O
the	O
axis	O
ˆn	O
to	O
obtain	O
v	O
(	O
cid:107	O
)	O
=	O
ˆn	O
(	O
ˆn	O
·	O
v	O
)	O
=	O
(	O
ˆnˆnt	O
)	O
v	O
,	O
(	O
2.29	O
)	O
which	O
is	O
the	O
component	O
of	O
v	O
that	O
is	O
not	O
affected	O
by	O
the	O
rotation	O
.	O
next	O
,	O
we	O
compute	O
the	O
perpendicular	O
residual	O
of	O
v	O
from	O
ˆn	O
,	O
1	O
in	O
robotics	O
,	O
this	O
is	O
sometimes	O
referred	O
to	O
as	O
gimbal	O
lock	O
.	O
v⊥	O
=	O
v	O
−	O
v	O
(	O
cid:107	O
)	O
=	O
(	O
i	O
−	O
ˆnˆnt	O
)	O
v.	O
(	O
2.30	O
)	O
vv┴n^v×v║v××u┴uθ	O
[	O
ˆn	O
]	O
×	O
=	O
0	O
ˆnz	O
−ˆny	O
−ˆnz	O
0	O
ˆnx	O
ˆny	O
−ˆnx	O
0	O
	O
.	O
(	O
2.32	O
)	O
42	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
we	O
can	O
rotate	O
this	O
vector	O
by	O
90◦	O
using	O
the	O
cross	O
product	O
,	O
v×	O
=	O
ˆn	O
×	O
v	O
=	O
[	O
ˆn	O
]	O
×v	O
,	O
(	O
2.31	O
)	O
where	O
[	O
ˆn	O
]	O
×	O
is	O
the	O
matrix	O
form	O
of	O
the	O
cross	O
product	O
operator	O
with	O
the	O
vector	O
ˆn	O
=	O
(	O
ˆnx	O
,	O
ˆny	O
,	O
ˆnz	O
)	O
,	O
note	O
that	O
rotating	O
this	O
vector	O
by	O
another	O
90◦	O
is	O
equivalent	O
to	O
taking	O
the	O
cross	O
product	O
again	O
,	O
v××	O
=	O
ˆn	O
×	O
v×	O
=	O
[	O
ˆn	O
]	O
2	O
×	O
v	O
=	O
−v⊥	O
,	O
and	O
hence	O
v	O
(	O
cid:107	O
)	O
=	O
v	O
−	O
v⊥	O
=	O
v	O
+	O
v××	O
=	O
(	O
i	O
+	O
[	O
ˆn	O
]	O
2	O
×	O
)	O
v.	O
we	O
can	O
now	O
compute	O
the	O
in-plane	O
component	O
of	O
the	O
rotated	O
vector	O
u	O
as	O
u⊥	O
=	O
cos	O
θv⊥	O
+	O
sin	O
θv×	O
=	O
(	O
sin	O
θ	O
[	O
ˆn	O
]	O
×	O
−	O
cos	O
θ	O
[	O
ˆn	O
]	O
2	O
×	O
)	O
v.	O
putting	O
all	O
these	O
terms	O
together	O
,	O
we	O
obtain	O
the	O
ﬁnal	O
rotated	O
vector	O
as	O
u	O
=	O
u⊥	O
+	O
v	O
(	O
cid:107	O
)	O
=	O
(	O
i	O
+	O
sin	O
θ	O
[	O
ˆn	O
]	O
×	O
+	O
(	O
1	O
−	O
cos	O
θ	O
)	O
[	O
ˆn	O
]	O
2	O
×	O
)	O
v.	O
(	O
2.33	O
)	O
we	O
can	O
therefore	O
write	O
the	O
rotation	O
matrix	O
corresponding	O
to	O
a	O
rotation	O
by	O
θ	O
around	O
an	O
axis	O
ˆn	O
as	O
r	O
(	O
ˆn	O
,	O
θ	O
)	O
=	O
i	O
+	O
sin	O
θ	O
[	O
ˆn	O
]	O
×	O
+	O
(	O
1	O
−	O
cos	O
θ	O
)	O
[	O
ˆn	O
]	O
2	O
×	O
,	O
(	O
2.34	O
)	O
which	O
is	O
known	O
as	O
rodriguez	O
’	O
s	O
formula	O
(	O
ayache	O
1989	O
)	O
.	O
the	O
product	O
of	O
the	O
axis	O
ˆn	O
and	O
angle	O
θ	O
,	O
ω	O
=	O
θˆn	O
=	O
(	O
ωx	O
,	O
ωy	O
,	O
ωz	O
)	O
,	O
is	O
a	O
minimal	O
represen-	O
tation	O
for	O
a	O
3d	O
rotation	O
.	O
rotations	O
through	O
common	O
angles	O
such	O
as	O
multiples	O
of	O
90◦	O
can	O
be	O
represented	O
exactly	O
(	O
and	O
converted	O
to	O
exact	O
matrices	O
)	O
if	O
θ	O
is	O
stored	O
in	O
degrees	O
.	O
unfortunately	O
,	O
this	O
representation	O
is	O
not	O
unique	O
,	O
since	O
we	O
can	O
always	O
add	O
a	O
multiple	B
of	O
360◦	O
(	O
2π	O
radians	O
)	O
to	O
θ	O
and	O
get	O
the	O
same	O
rotation	O
matrix	O
.	O
as	O
well	O
,	O
(	O
ˆn	O
,	O
θ	O
)	O
and	O
(	O
−ˆn	O
,	O
−θ	O
)	O
represent	O
the	O
same	O
rotation	O
.	O
however	O
,	O
for	O
small	O
rotations	O
(	O
e.g.	O
,	O
corrections	O
to	O
rotations	O
)	O
,	O
this	O
is	O
an	O
excellent	O
choice	O
.	O
in	O
particular	O
,	O
for	O
small	O
(	O
inﬁnitesimal	O
or	O
instantaneous	O
)	O
rotations	O
and	O
θ	O
expressed	O
in	O
radians	O
,	O
rodriguez	O
’	O
s	O
formula	O
simpliﬁes	O
to	O
r	O
(	O
ω	O
)	O
≈	O
i	O
+	O
sin	O
θ	O
[	O
ˆn	O
]	O
×	O
≈	O
i	O
+	O
[	O
θˆn	O
]	O
×	O
=	O
1	O
ωz	O
−ωy	O
−ωz	O
1	O
ωx	O
ωy	O
−ωx	O
1	O
	O
,	O
(	O
2.35	O
)	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
43	O
which	O
gives	O
a	O
nice	O
linearized	O
relationship	O
between	O
the	O
rotation	O
parameters	O
ω	O
and	O
r.	O
we	O
can	O
also	O
write	O
r	O
(	O
ω	O
)	O
v	O
≈	O
v	O
+	O
ω	O
×	O
v	O
,	O
which	O
is	O
handy	O
when	O
we	O
want	O
to	O
compute	O
the	O
derivative	O
of	O
rv	O
with	O
respect	O
to	O
ω	O
,	O
∂rv	O
∂ωt	O
=	O
−	O
[	O
v	O
]	O
×	O
=	O
0	O
z	O
−y	O
0	O
−z	O
x	O
0	O
y	O
−x	O
	O
.	O
(	O
2.36	O
)	O
another	O
way	O
to	O
derive	O
a	O
rotation	O
through	O
a	O
ﬁnite	O
angle	O
is	O
called	O
the	O
exponential	B
twist	I
(	O
murray	O
,	O
li	O
,	O
and	O
sastry	O
1994	O
)	O
.	O
a	O
rotation	O
by	O
an	O
angle	O
θ	O
is	O
equivalent	O
to	O
k	O
rotations	O
through	O
θ/k	O
.	O
in	O
the	O
limit	O
as	O
k	O
→	O
∞	O
,	O
we	O
obtain	O
r	O
(	O
ˆn	O
,	O
θ	O
)	O
=	O
lim	O
k→∞	O
[	O
θˆn	O
]	O
×	O
)	O
k	O
=	O
exp	O
[	O
ω	O
]	O
×	O
.	O
(	O
2.37	O
)	O
(	O
i	O
+	O
1	O
k	O
if	O
we	O
expand	O
the	O
matrix	O
exponential	O
as	O
a	O
taylor	O
series	O
(	O
using	O
the	O
identity	O
[	O
ˆn	O
]	O
k+2	O
k	O
>	O
0	O
,	O
and	O
again	O
assuming	O
θ	O
is	O
in	O
radians	O
)	O
,	O
×	O
=	O
−	O
[	O
ˆn	O
]	O
k	O
×	O
,	O
exp	O
[	O
ω	O
]	O
×	O
=	O
i	O
+	O
θ	O
[	O
ˆn	O
]	O
×	O
+	O
θ2	O
2	O
[	O
ˆn	O
]	O
2	O
×	O
+	O
θ3	O
3	O
!	O
[	O
ˆn	O
]	O
3	O
×	O
θ3	O
3	O
!	O
+	O
···	O
)	O
[	O
ˆn	O
]	O
×	O
+	O
(	O
θ2	O
=	O
i	O
+	O
(	O
θ	O
−	O
2	O
−	O
=	O
i	O
+	O
sin	O
θ	O
[	O
ˆn	O
]	O
×	O
+	O
(	O
1	O
−	O
cos	O
θ	O
)	O
[	O
ˆn	O
]	O
2	O
×	O
,	O
+	O
···	O
θ3	O
4	O
!	O
+	O
···	O
)	O
[	O
ˆn	O
]	O
2	O
×	O
(	O
2.38	O
)	O
which	O
yields	O
the	O
familiar	O
rodriguez	O
’	O
s	O
formula	O
.	O
unit	O
quaternions	B
the	O
unit	O
quaternion	O
representation	O
is	O
closely	O
related	O
to	O
the	O
angle/axis	O
representation	O
.	O
a	O
unit	O
quaternion	O
is	O
a	O
unit	O
length	O
4-vector	O
whose	O
components	O
can	O
be	O
written	O
as	O
q	O
=	O
(	O
qx	O
,	O
qy	O
,	O
qz	O
,	O
qw	O
)	O
or	O
q	O
=	O
(	O
x	O
,	O
y	O
,	O
z	O
,	O
w	O
)	O
for	O
short	O
.	O
unit	O
quaternions	B
live	O
on	O
the	O
unit	O
sphere	O
(	O
cid:107	O
)	O
q	O
(	O
cid:107	O
)	O
=	O
1	O
and	O
antipodal	B
(	O
opposite	O
sign	O
)	O
quaternions	B
,	O
q	O
and	O
−q	O
,	O
represent	O
the	O
same	O
rotation	O
(	O
figure	O
2.6	O
)	O
.	O
other	O
than	O
this	O
ambiguity	O
(	O
dual	O
covering	O
)	O
,	O
the	O
unit	O
quaternion	O
representation	O
of	O
a	O
rotation	O
is	O
unique	O
.	O
furthermore	O
,	O
the	O
representation	O
is	O
continuous	O
,	O
i.e.	O
,	O
as	O
rotation	O
matrices	O
vary	O
continuously	O
,	O
one	O
can	O
ﬁnd	O
a	O
continuous	O
quaternion	O
representation	O
,	O
although	O
the	O
path	O
on	O
the	O
quaternion	O
sphere	O
may	O
wrap	O
all	O
the	O
way	O
around	O
before	O
returning	O
to	O
the	O
“	O
origin	O
”	O
qo	O
=	O
(	O
0	O
,	O
0	O
,	O
0	O
,	O
1	O
)	O
.	O
for	O
these	O
and	O
other	O
reasons	O
given	O
below	O
,	O
quaternions	B
are	O
a	O
very	O
popular	O
representation	O
for	O
pose	O
and	O
for	O
pose	O
interpolation	B
in	O
computer	O
graphics	O
(	O
shoemake	O
1985	O
)	O
.	O
quaternions	B
can	O
be	O
derived	O
from	O
the	O
axis/angle	B
representation	O
through	O
the	O
formula	O
q	O
=	O
(	O
v	O
,	O
w	O
)	O
=	O
(	O
sin	O
θ	O
2	O
ˆn	O
,	O
cos	O
θ	O
2	O
)	O
,	O
(	O
2.39	O
)	O
44	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.6	O
unit	O
quaternions	B
live	O
on	O
the	O
unit	O
sphere	O
(	O
cid:107	O
)	O
q	O
(	O
cid:107	O
)	O
=	O
1.	O
this	O
ﬁgure	O
shows	O
a	O
smooth	O
trajectory	O
through	O
the	O
three	O
quaternions	B
q0	O
,	O
q1	O
,	O
and	O
q2	O
.	O
the	O
antipodal	B
point	O
to	O
q2	O
,	O
namely	O
−q2	O
,	O
represents	O
the	O
same	O
rotation	O
as	O
q2	O
.	O
where	O
ˆn	O
and	O
θ	O
are	O
the	O
rotation	O
axis	O
and	O
angle	O
.	O
using	O
the	O
trigonometric	O
identities	O
sin	O
θ	O
=	O
2	O
sin	O
θ	O
2	O
,	O
rodriguez	O
’	O
s	O
formula	O
can	O
be	O
converted	O
to	O
2	O
cos	O
θ	O
2	O
and	O
(	O
1	O
−	O
cos	O
θ	O
)	O
=	O
2	O
sin2	O
θ	O
r	O
(	O
ˆn	O
,	O
θ	O
)	O
=	O
i	O
+	O
sin	O
θ	O
[	O
ˆn	O
]	O
×	O
+	O
(	O
1	O
−	O
cos	O
θ	O
)	O
[	O
ˆn	O
]	O
2	O
×	O
=	O
i	O
+	O
2w	O
[	O
v	O
]	O
×	O
+	O
2	O
[	O
v	O
]	O
2	O
×	O
.	O
(	O
2.40	O
)	O
this	O
suggests	O
a	O
quick	O
way	O
to	O
rotate	O
a	O
vector	O
v	O
by	O
a	O
quaternion	O
using	O
a	O
series	O
of	O
cross	O
products	O
,	O
scalings	O
,	O
and	O
additions	O
.	O
to	O
obtain	O
a	O
formula	O
for	O
r	O
(	O
q	O
)	O
as	O
a	O
function	O
of	O
(	O
x	O
,	O
y	O
,	O
z	O
,	O
w	O
)	O
,	O
recall	B
that	O
[	O
v	O
]	O
×	O
=	O
we	O
thus	O
obtain	O
0	O
−z	O
z	O
−y	O
y	O
0	O
−x	O
0	O
x	O
	O
and	O
[	O
v	O
]	O
2	O
×	O
=	O
−y2	O
−	O
z2	O
xy	O
xz	O
xy	O
−x2	O
−	O
z2	O
yz	O
xz	O
yz	O
−x2	O
−	O
y2	O
	O
.	O
(	O
2.41	O
)	O
r	O
(	O
q	O
)	O
=	O
1	O
−	O
2	O
(	O
y2	O
+	O
z2	O
)	O
2	O
(	O
xy	O
+	O
zw	O
)	O
2	O
(	O
xz	O
−	O
yw	O
)	O
2	O
(	O
xy	O
−	O
zw	O
)	O
1	O
−	O
2	O
(	O
x2	O
+	O
z2	O
)	O
2	O
(	O
yz	O
+	O
xw	O
)	O
2	O
(	O
xz	O
+	O
yw	O
)	O
2	O
(	O
yz	O
−	O
xw	O
)	O
1	O
−	O
2	O
(	O
x2	O
+	O
y2	O
)	O
	O
.	O
the	O
diagonal	O
terms	O
can	O
be	O
made	O
more	O
symmetrical	O
by	O
replacing	O
1	O
−	O
2	O
(	O
y2	O
+	O
z2	O
)	O
with	O
(	O
x2	O
+	O
w2	O
−	O
y2	O
−	O
z2	O
)	O
,	O
etc	O
.	O
the	O
nicest	O
aspect	O
of	O
unit	O
quaternions	B
is	O
that	O
there	O
is	O
a	O
simple	O
algebra	O
for	O
composing	O
rota-	O
tions	O
expressed	O
as	O
unit	O
quaternions	B
.	O
given	O
two	O
quaternions	O
q0	O
=	O
(	O
v0	O
,	O
w0	O
)	O
and	O
q1	O
=	O
(	O
v1	O
,	O
w1	O
)	O
,	O
the	O
quaternion	O
multiply	O
operator	O
is	O
deﬁned	O
as	O
q2	O
=	O
q0q1	O
=	O
(	O
v0	O
×	O
v1	O
+	O
w0v1	O
+	O
w1v0	O
,	O
w0w1	O
−	O
v0	O
·	O
v1	O
)	O
,	O
(	O
2.42	O
)	O
zxw║q║=1yq0q1q2-q2	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
45	O
with	O
the	O
property	O
that	O
r	O
(	O
q2	O
)	O
=	O
r	O
(	O
q0	O
)	O
r	O
(	O
q1	O
)	O
.	O
note	O
that	O
quaternion	O
multiplication	B
is	O
not	O
commutative	O
,	O
just	O
as	O
3d	O
rotations	O
and	O
matrix	O
multiplications	O
are	O
not	O
.	O
taking	O
the	O
inverse	B
of	O
a	O
quaternion	O
is	O
easy	O
:	O
just	O
ﬂip	O
the	O
sign	O
of	O
v	O
or	O
w	O
(	O
but	O
not	O
both	O
!	O
)	O
.	O
(	O
you	O
can	O
verify	O
this	O
has	O
the	O
desired	O
effect	O
of	O
transposing	O
the	O
r	O
matrix	O
in	O
(	O
2.41	O
)	O
.	O
)	O
thus	O
,	O
we	O
can	O
also	O
deﬁne	O
quaternion	O
division	O
as	O
q2	O
=	O
q0/q1	O
=	O
q0q−1	O
1	O
=	O
(	O
v0	O
×	O
v1	O
+	O
w0v1	O
−	O
w1v0	O
,	O
−w0w1	O
−	O
v0	O
·	O
v1	O
)	O
.	O
this	O
is	O
useful	O
when	O
the	O
incremental	B
rotation	O
between	O
two	O
rotations	O
is	O
desired	O
.	O
(	O
2.43	O
)	O
in	O
particular	O
,	O
if	O
we	O
want	O
to	O
determine	O
a	O
rotation	O
that	O
is	O
partway	O
between	O
two	O
given	O
rota-	O
tions	O
,	O
we	O
can	O
compute	O
the	O
incremental	B
rotation	O
,	O
take	O
a	O
fraction	O
of	O
the	O
angle	O
,	O
and	O
compute	O
the	O
new	O
rotation	O
.	O
this	O
procedure	O
is	O
called	O
spherical	B
linear	O
interpolation	B
or	O
slerp	O
for	O
short	O
(	O
shoe-	O
make	O
1985	O
)	O
and	O
is	O
given	O
in	O
algorithm	B
2.1.	O
note	O
that	O
shoemake	O
presents	O
two	O
formulas	O
other	O
than	O
the	O
one	O
given	O
here	O
.	O
the	O
ﬁrst	O
exponentiates	O
qr	O
by	O
alpha	O
before	O
multiplying	O
the	O
original	O
quaternion	O
,	O
while	O
the	O
second	O
treats	O
the	O
quaternions	B
as	O
4-vectors	O
on	O
a	O
sphere	O
and	O
uses	O
q2	O
=	O
qα	O
r	O
q0	O
,	O
q2	O
=	O
sin	O
(	O
1	O
−	O
α	O
)	O
θ	O
sin	O
θ	O
q0	O
+	O
sin	O
αθ	O
sin	O
θ	O
q1	O
,	O
(	O
2.44	O
)	O
(	O
2.45	O
)	O
where	O
θ	O
=	O
cos−1	O
(	O
q0	O
·	O
q1	O
)	O
and	O
the	O
dot	O
product	O
is	O
directly	O
between	O
the	O
quaternion	O
4-vectors	O
.	O
all	O
of	O
these	O
formulas	O
give	O
comparable	O
results	O
,	O
although	O
care	O
should	O
be	O
taken	O
when	O
q0	O
and	O
q1	O
are	O
close	O
together	O
,	O
which	O
is	O
why	O
i	O
prefer	O
to	O
use	O
an	O
arctangent	O
to	O
establish	O
the	O
rotation	O
angle	O
.	O
which	O
rotation	O
representation	O
is	O
better	O
?	O
the	O
choice	O
of	O
representation	O
for	O
3d	O
rotations	O
depends	O
partly	O
on	O
the	O
application	O
.	O
the	O
axis/angle	B
representation	O
is	O
minimal	O
,	O
and	O
hence	O
does	O
not	O
require	O
any	O
additional	O
con-	O
straints	O
on	O
the	O
parameters	B
(	O
no	O
need	O
to	O
re-normalize	O
after	O
each	O
update	O
)	O
.	O
if	O
the	O
angle	O
is	O
ex-	O
pressed	O
in	O
degrees	O
,	O
it	O
is	O
easier	O
to	O
understand	O
the	O
pose	O
(	O
say	O
,	O
90◦	O
twist	B
around	O
x-axis	O
)	O
,	O
and	O
also	O
easier	O
to	O
express	O
exact	O
rotations	O
.	O
when	O
the	O
angle	O
is	O
in	O
radians	O
,	O
the	O
derivatives	O
of	O
r	O
with	O
respect	O
to	O
ω	O
can	O
easily	O
be	O
computed	O
(	O
2.36	O
)	O
.	O
quaternions	B
,	O
on	O
the	O
other	O
hand	O
,	O
are	O
better	O
if	O
you	O
want	O
to	O
keep	O
track	O
of	O
a	O
smoothly	O
moving	O
camera	O
,	O
since	O
there	O
are	O
no	O
discontinuities	O
in	O
the	O
representation	O
.	O
it	O
is	O
also	O
easier	O
to	O
interpolate	O
between	O
rotations	O
and	O
to	O
chain	O
rigid	O
transformations	O
(	O
murray	O
,	O
li	O
,	O
and	O
sastry	O
1994	O
;	O
bregler	O
and	O
malik	O
1998	O
)	O
.	O
my	O
usual	O
preference	O
is	O
to	O
use	O
quaternions	B
,	O
but	O
to	O
update	O
their	O
estimates	O
using	O
an	O
incre-	O
mental	O
rotation	O
,	O
as	O
described	O
in	O
section	O
6.2.2	O
.	O
46	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
procedure	O
slerp	O
(	O
q0	O
,	O
q1	O
,	O
α	O
)	O
:	O
1.	O
qr	O
=	O
q1/q0	O
=	O
(	O
vr	O
,	O
wr	O
)	O
2.	O
if	O
wr	O
<	O
0	O
then	O
qr	O
←	O
−qr	O
3.	O
θr	O
=	O
2	O
tan−1	O
(	O
(	O
cid:107	O
)	O
vr	O
(	O
cid:107	O
)	O
/wr	O
)	O
4	O
.	O
ˆnr	O
=	O
n	O
(	O
vr	O
)	O
=	O
vr/	O
(	O
cid:107	O
)	O
vr	O
(	O
cid:107	O
)	O
5.	O
θα	O
=	O
α	O
θr	O
2	O
ˆnr	O
,	O
cos	O
θα	O
2	O
)	O
6.	O
qα	O
=	O
(	O
sin	O
θα	O
7.	O
return	O
q2	O
=	O
qαq0	O
algorithm	B
2.1	O
spherical	B
linear	O
interpolation	B
(	O
slerp	O
)	O
.	O
the	O
axis	O
and	O
total	B
angle	O
are	O
ﬁrst	O
com-	O
puted	O
from	O
the	O
quaternion	O
ratio	O
.	O
(	O
this	O
computation	O
can	O
be	O
lifted	O
outside	O
an	O
inner	O
loop	O
that	O
generates	O
a	O
set	O
of	O
interpolated	O
position	O
for	O
animation	O
.	O
)	O
an	O
incremental	B
quaternion	O
is	O
then	O
computed	O
and	O
multiplied	O
by	O
the	O
starting	O
rotation	O
quaternion	O
.	O
2.1.5	O
3d	O
to	O
2d	O
projections	B
now	O
that	O
we	O
know	O
how	O
to	O
represent	O
2d	O
and	O
3d	O
geometric	B
primitives	O
and	O
how	O
to	O
transform	B
them	O
spatially	O
,	O
we	O
need	O
to	O
specify	O
how	O
3d	O
primitives	O
are	O
projected	O
onto	O
the	O
image	B
plane	O
.	O
we	O
can	O
do	O
this	O
using	O
a	O
linear	B
3d	O
to	O
2d	O
projection	O
matrix	O
.	O
the	O
simplest	O
model	O
is	O
orthography	O
,	O
which	O
requires	O
no	O
division	O
to	O
get	O
the	O
ﬁnal	O
(	O
inhomogeneous	O
)	O
result	O
.	O
the	O
more	O
commonly	O
used	O
model	O
is	O
perspective	B
,	O
since	O
this	O
more	O
accurately	O
models	O
the	O
behavior	O
of	O
real	O
cameras	O
.	O
orthography	O
and	O
para-perspective	B
an	O
orthographic	B
projection	O
simply	O
drops	O
the	O
z	O
component	O
of	O
the	O
three-dimensional	O
coordi-	O
nate	O
p	O
to	O
obtain	O
the	O
2d	O
point	O
x	O
.	O
(	O
in	O
this	O
section	O
,	O
we	O
use	O
p	O
to	O
denote	O
3d	O
points	B
and	O
x	O
to	O
denote	O
2d	O
points	B
.	O
)	O
this	O
can	O
be	O
written	O
as	O
if	O
we	O
are	O
using	O
homogeneous	O
(	O
projective	B
)	O
coordinates	O
,	O
we	O
can	O
write	O
x	O
=	O
[	O
i	O
2×2|0	O
]	O
p.	O
˜x	O
=	O
1	O
0	O
0	O
0	O
0	O
1	O
0	O
0	O
0	O
0	O
0	O
1	O
	O
˜p	O
,	O
(	O
2.46	O
)	O
(	O
2.47	O
)	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
47	O
(	O
a	O
)	O
3d	O
view	O
(	O
b	O
)	O
orthography	O
(	O
c	O
)	O
scaled	O
orthography	O
(	O
d	O
)	O
para-perspective	B
(	O
e	O
)	O
perspective	B
(	O
f	O
)	O
object-centered	B
figure	O
2.7	O
commonly	O
used	O
projection	O
models	O
:	O
(	O
a	O
)	O
3d	O
view	O
of	O
world	O
,	O
(	O
b	O
)	O
orthography	O
,	O
(	O
c	O
)	O
scaled	O
orthography	O
,	O
(	O
d	O
)	O
para-perspective	B
,	O
(	O
e	O
)	O
perspective	B
,	O
(	O
f	O
)	O
object-centered	B
.	O
each	O
diagram	O
shows	O
a	O
top-down	O
view	O
of	O
the	O
projection	O
.	O
note	O
how	O
parallel	O
lines	B
on	O
the	O
ground	O
plane	O
and	O
box	O
sides	O
remain	O
parallel	O
in	O
the	O
non-perspective	O
projections	B
.	O
48	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
i.e.	O
,	O
we	O
drop	O
the	O
z	O
component	O
but	O
keep	O
the	O
w	O
component	O
.	O
orthography	O
is	O
an	O
approximate	O
model	O
for	O
long	O
focal	O
length	O
(	O
telephoto	O
)	O
lenses	O
and	O
objects	O
whose	O
depth	O
is	O
shallow	O
relative	O
to	O
their	O
distance	O
to	O
the	O
camera	B
(	O
sawhney	O
and	O
hanson	O
1991	O
)	O
.	O
it	O
is	O
exact	O
only	O
for	O
telecentric	O
lenses	O
(	O
baker	O
and	O
nayar	O
1999	O
,	O
2001	O
)	O
.	O
in	O
practice	O
,	O
world	O
coordinates	O
(	O
which	O
may	O
measure	O
dimensions	O
in	O
meters	O
)	O
need	O
to	O
be	O
scaled	O
to	O
ﬁt	O
onto	O
an	O
image	B
sensor	O
(	O
physically	O
measured	O
in	O
millimeters	O
,	O
but	O
ultimately	O
mea-	O
sured	O
in	O
pixels	O
)	O
.	O
for	O
this	O
reason	O
,	O
scaled	O
orthography	O
is	O
actually	O
more	O
commonly	O
used	O
,	O
x	O
=	O
[	O
si	O
2×2|0	O
]	O
p.	O
(	O
2.48	O
)	O
this	O
model	O
is	O
equivalent	O
to	O
ﬁrst	O
projecting	O
the	O
world	O
points	B
onto	O
a	O
local	B
fronto-parallel	O
image	B
plane	O
and	O
then	O
scaling	O
this	O
image	B
using	O
regular	O
perspective	B
projection	O
.	O
the	O
scaling	O
can	O
be	O
the	O
same	O
for	O
all	O
parts	O
of	O
the	O
scene	O
(	O
figure	O
2.7b	O
)	O
or	O
it	O
can	O
be	O
different	O
for	O
objects	O
that	O
are	O
being	O
modeled	O
independently	O
(	O
figure	O
2.7c	O
)	O
.	O
more	O
importantly	O
,	O
the	O
scaling	O
can	O
vary	O
from	O
frame	O
to	O
frame	O
when	O
estimating	O
structure	B
from	I
motion	I
,	O
which	O
can	O
better	O
model	O
the	O
scale	O
change	O
that	O
occurs	O
as	O
an	O
object	O
approaches	O
the	O
camera	B
.	O
scaled	O
orthography	O
is	O
a	O
popular	O
model	O
for	O
reconstructing	O
the	O
3d	O
shape	O
of	O
objects	O
far	O
away	O
from	O
the	O
camera	B
,	O
since	O
it	O
greatly	O
simpliﬁes	O
certain	O
computations	O
.	O
for	O
example	O
,	O
pose	O
(	O
camera	B
orientation	O
)	O
can	O
be	O
estimated	O
using	O
simple	O
least	B
squares	I
(	O
section	O
6.2.1	O
)	O
.	O
under	O
orthography	O
,	O
structure	O
and	O
motion	B
can	O
simultaneously	O
be	O
estimated	O
using	O
factorization	O
(	O
singular	O
value	O
de-	O
composition	O
)	O
,	O
as	O
discussed	O
in	O
section	O
7.3	O
(	O
tomasi	O
and	O
kanade	O
1992	O
)	O
.	O
a	O
closely	O
related	O
projection	O
model	O
is	O
para-perspective	B
(	O
aloimonos	O
1990	O
;	O
poelman	O
and	O
kanade	O
1997	O
)	O
.	O
in	O
this	O
model	O
,	O
object	O
points	B
are	O
again	O
ﬁrst	O
projected	O
onto	O
a	O
local	B
reference	O
parallel	O
to	O
the	O
image	B
plane	O
.	O
however	O
,	O
rather	O
than	O
being	O
projected	O
orthogonally	O
to	O
this	O
plane	O
,	O
they	O
are	O
projected	O
parallel	O
to	O
the	O
line	O
of	O
sight	O
to	O
the	O
object	O
center	O
(	O
figure	O
2.7d	O
)	O
.	O
this	O
is	O
followed	O
by	O
the	O
usual	O
projection	O
onto	O
the	O
ﬁnal	O
image	B
plane	O
,	O
which	O
again	O
amounts	O
to	O
a	O
scaling	O
.	O
the	O
combination	O
of	O
these	O
two	O
projections	O
is	O
therefore	O
afﬁne	B
and	O
can	O
be	O
written	O
as	O
˜x	O
=	O
	O
˜p	O
.	O
a00	O
a01	O
a02	O
a03	O
a10	O
a11	O
a12	O
a13	O
0	O
1	O
0	O
0	O
(	O
2.49	O
)	O
note	O
how	O
parallel	O
lines	B
in	O
3d	O
remain	O
parallel	O
after	O
projection	O
in	O
figure	O
2.7b–d	O
.	O
para-perspective	B
provides	O
a	O
more	O
accurate	O
projection	O
model	O
than	O
scaled	O
orthography	O
,	O
without	O
incurring	O
the	O
added	O
complexity	O
of	O
per-pixel	O
perspective	B
division	O
,	O
which	O
invalidates	O
traditional	O
factoriza-	O
tion	B
methods	O
(	O
poelman	O
and	O
kanade	O
1997	O
)	O
.	O
perspective	B
the	O
most	O
commonly	O
used	O
projection	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
is	O
true	O
3d	O
perspective	B
(	O
figure	O
2.7e	O
)	O
.	O
here	O
,	O
points	B
are	O
projected	O
onto	O
the	O
image	B
plane	O
by	O
dividing	O
them	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
by	O
their	O
z	O
component	O
.	O
using	O
inhomogeneous	O
coordinates	O
,	O
this	O
can	O
be	O
written	O
as	O
in	O
homogeneous	B
coordinates	I
,	O
the	O
projection	O
has	O
a	O
simple	O
linear	B
form	O
,	O
x/z	O
y/z	O
1	O
¯x	O
=	O
pz	O
(	O
p	O
)	O
=	O
˜x	O
=	O
1	O
0	O
0	O
0	O
0	O
1	O
0	O
0	O
0	O
0	O
1	O
0	O
	O
.	O
	O
˜p	O
,	O
49	O
(	O
2.50	O
)	O
(	O
2.51	O
)	O
i.e.	O
,	O
we	O
drop	O
the	O
w	O
component	O
of	O
p.	O
thus	O
,	O
after	O
projection	O
,	O
it	O
is	O
not	O
possible	O
to	O
recover	O
the	O
distance	O
of	O
the	O
3d	O
point	O
from	O
the	O
image	B
,	O
which	O
makes	O
sense	O
for	O
a	O
2d	O
imaging	O
sensor	B
.	O
a	O
form	O
often	O
seen	O
in	O
computer	O
graphics	O
systems	O
is	O
a	O
two-step	O
projection	O
that	O
ﬁrst	O
projects	O
3d	O
coordinates	O
into	O
normalized	B
device	O
coordinates	O
in	O
the	O
range	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
∈	O
[	O
−1	O
,	O
−1	O
]	O
×	O
[	O
−1	O
,	O
1	O
]	O
×	O
[	O
0	O
,	O
1	O
]	O
,	O
and	O
then	O
rescales	O
these	O
coordinates	O
to	O
integer	O
pixel	O
coordinates	O
using	O
a	O
view-	O
port	O
transformation	O
(	O
watt	O
1995	O
;	O
opengl-arb	O
1997	O
)	O
.	O
the	O
(	O
initial	O
)	O
perspective	B
projection	O
is	O
then	O
represented	O
using	O
a	O
4	O
×	O
4	O
matrix	O
˜p	O
,	O
(	O
2.52	O
)	O
	O
˜x	O
=	O
0	O
0	O
1	O
0	O
0	O
1	O
0	O
0	O
−zfar/zrange	O
0	O
0	O
1	O
0	O
0	O
znearzfar/zrange	O
0	O
where	O
znear	O
and	O
zfar	O
are	O
the	O
near	O
and	O
far	O
z	O
clipping	O
planes	B
and	O
zrange	O
=	O
zfar	O
−	O
znear	O
.	O
note	O
that	O
the	O
ﬁrst	O
two	O
rows	O
are	O
actually	O
scaled	O
by	O
the	O
focal	O
length	O
and	O
the	O
aspect	O
ratio	O
so	O
that	O
visible	O
rays	O
are	O
mapped	O
to	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
∈	O
[	O
−1	O
,	O
−1	O
]	O
2.	O
the	O
reason	O
for	O
keeping	O
the	O
third	O
row	O
,	O
rather	O
than	O
dropping	O
it	O
,	O
is	O
that	O
visibility	B
operations	O
,	O
such	O
as	O
z-buffering	O
,	O
require	O
a	O
depth	O
for	O
every	O
graphical	O
element	O
that	O
is	O
being	O
rendered	O
.	O
if	O
we	O
set	O
znear	O
=	O
1	O
,	O
zfar	O
→	O
∞	O
,	O
and	O
switch	O
the	O
sign	O
of	O
the	O
third	O
row	O
,	O
the	O
third	O
element	O
of	O
the	O
normalized	B
screen	O
vector	O
becomes	O
the	O
inverse	B
depth	O
,	O
i.e.	O
,	O
the	O
disparity	O
(	O
okutomi	O
and	O
kanade	O
1993	O
)	O
.	O
this	O
can	O
be	O
quite	O
convenient	O
in	O
many	O
cases	O
since	O
,	O
for	O
cameras	O
moving	O
around	O
outdoors	O
,	O
the	O
inverse	B
depth	O
to	O
the	O
camera	B
is	O
often	O
a	O
more	O
well-conditioned	O
parameterization	O
than	O
direct	B
3d	O
distance	O
.	O
while	O
a	O
regular	O
2d	O
image	B
sensor	O
has	O
no	O
way	O
of	O
measuring	O
distance	O
to	O
a	O
surface	B
point	O
,	O
range	O
sensors	O
(	O
section	O
12.2	O
)	O
and	O
stereo	B
matching	I
algorithms	O
(	O
chapter	O
11	O
)	O
can	O
compute	O
such	O
values	O
.	O
it	O
is	O
then	O
convenient	O
to	O
be	O
able	O
to	O
map	O
from	O
a	O
sensor-based	O
depth	O
or	O
disparity	O
value	O
d	O
directly	O
back	O
to	O
a	O
3d	O
location	O
using	O
the	O
inverse	B
of	O
a	O
4	O
×	O
4	O
matrix	O
(	O
section	O
2.1.5	O
)	O
.	O
we	O
can	O
do	O
this	O
if	O
we	O
represent	O
perspective	B
projection	O
using	O
a	O
full-rank	O
4	O
×	O
4	O
matrix	O
,	O
as	O
in	O
(	O
2.64	O
)	O
.	O
50	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.8	O
projection	O
of	O
a	O
3d	O
camera-centered	O
point	O
pc	O
onto	O
the	O
sensor	B
planes	O
at	O
location	O
p.	O
oc	O
is	O
the	O
camera	B
center	O
(	O
nodal	B
point	I
)	O
,	O
cs	O
is	O
the	O
3d	O
origin	O
of	O
the	O
sensor	B
plane	O
coordinate	O
system	O
,	O
and	O
sx	O
and	O
sy	O
are	O
the	O
pixel	O
spacings	O
.	O
camera	B
intrinsics	O
once	O
we	O
have	O
projected	O
a	O
3d	O
point	O
through	O
an	O
ideal	O
pinhole	O
using	O
a	O
projection	O
matrix	O
,	O
we	O
must	O
still	O
transform	B
the	O
resulting	O
coordinates	O
according	O
to	O
the	O
pixel	O
sensor	O
spacing	O
and	O
the	O
relative	O
position	O
of	O
the	O
sensor	B
plane	O
to	O
the	O
origin	O
.	O
figure	O
2.8	O
shows	O
an	O
illustration	O
of	O
the	O
geometry	O
involved	O
.	O
in	O
this	O
section	O
,	O
we	O
ﬁrst	O
present	O
a	O
mapping	O
from	O
2d	O
pixel	O
coordinates	O
to	O
3d	O
rays	O
using	O
a	O
sensor	B
homography	O
m	O
s	O
,	O
since	O
this	O
is	O
easier	O
to	O
explain	O
in	O
terms	O
of	O
physically	O
measurable	O
quantities	O
.	O
we	O
then	O
relate	O
these	O
quantities	O
to	O
the	O
more	O
commonly	O
used	O
camera	B
in-	O
trinsic	O
matrix	O
k	O
,	O
which	O
is	O
used	O
to	O
map	O
3d	O
camera-centered	O
points	B
pc	O
to	O
2d	O
pixel	O
coordinates	O
˜xs	O
.	O
image	B
sensors	O
return	O
pixel	O
values	O
indexed	O
by	O
integer	O
pixel	O
coordinates	O
(	O
xs	O
,	O
ys	O
)	O
,	O
often	O
with	O
the	O
coordinates	O
starting	O
at	O
the	O
upper-left	O
corner	O
of	O
the	O
image	B
and	O
moving	O
down	O
and	O
to	O
the	O
right	O
.	O
(	O
this	O
convention	O
is	O
not	O
obeyed	O
by	O
all	O
imaging	O
libraries	O
,	O
but	O
the	O
adjustment	O
for	O
other	O
coordinate	O
systems	O
is	O
straightforward	O
.	O
)	O
to	O
map	O
pixel	O
centers	O
to	O
3d	O
coordinates	O
,	O
we	O
ﬁrst	O
scale	O
the	O
(	O
xs	O
,	O
ys	O
)	O
values	O
by	O
the	O
pixel	O
spacings	O
(	O
sx	O
,	O
sy	O
)	O
(	O
sometimes	O
expressed	O
in	O
microns	O
for	O
solid-state	O
sensors	O
)	O
and	O
then	O
describe	O
the	O
orientation	O
of	O
the	O
sensor	B
array	O
relative	O
to	O
the	O
camera	B
projection	O
center	O
oc	O
with	O
an	O
origin	O
cs	O
and	O
a	O
3d	O
rotation	O
rs	O
(	O
figure	O
2.8	O
)	O
.	O
the	O
combined	O
2d	O
to	O
3d	O
projection	O
can	O
then	O
be	O
written	O
as	O
p	O
=	O
(	O
cid:104	O
)	O
rs	O
cs	O
(	O
cid:105	O
)	O
	O
the	O
ﬁrst	O
two	O
columns	O
of	O
the	O
3	O
×	O
3	O
matrix	O
m	O
s	O
are	O
the	O
3d	O
vectors	O
corresponding	O
to	O
unit	O
steps	O
in	O
the	O
image	B
pixel	O
array	O
along	O
the	O
xs	O
and	O
ys	O
directions	O
,	O
while	O
the	O
third	O
column	O
is	O
the	O
3d	O
image	B
array	O
origin	O
cs	O
.	O
sx	O
0	O
0	O
0	O
0	O
sy	O
0	O
0	O
0	O
0	O
0	O
1	O
xs	O
ys	O
1	O
	O
	O
=	O
m	O
s	O
¯xs	O
.	O
(	O
2.53	O
)	O
	O
zcxccsycxsyssxsypcpoc	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
51	O
the	O
matrix	O
m	O
s	O
is	O
parameterized	O
by	O
eight	O
unknowns	O
:	O
the	O
three	O
parameters	B
describing	O
the	O
rotation	O
rs	O
,	O
the	O
three	O
parameters	B
describing	O
the	O
translation	B
cs	O
,	O
and	O
the	O
two	O
scale	O
factors	O
(	O
sx	O
,	O
sy	O
)	O
.	O
note	O
that	O
we	O
ignore	O
here	O
the	O
possibility	O
of	O
skew	O
between	O
the	O
two	O
axes	O
on	O
the	O
image	B
plane	O
,	O
since	O
solid-state	O
manufacturing	O
techniques	O
render	O
this	O
negligible	O
.	O
in	O
practice	O
,	O
unless	O
we	O
have	O
accurate	O
external	O
knowledge	O
of	O
the	O
sensor	B
spacing	O
or	O
sensor	B
orientation	O
,	O
there	O
are	O
only	O
seven	O
degrees	O
of	O
freedom	O
,	O
since	O
the	O
distance	O
of	O
the	O
sensor	B
from	O
the	O
origin	O
can	O
not	O
be	O
teased	O
apart	O
from	O
the	O
sensor	B
spacing	O
,	O
based	O
on	O
external	O
image	B
measurement	O
alone	O
.	O
however	O
,	O
estimating	O
a	O
camera	B
model	O
m	O
s	O
with	O
the	O
required	O
seven	O
degrees	O
of	O
freedom	O
(	O
i.e.	O
,	O
where	O
the	O
ﬁrst	O
two	O
columns	O
are	O
orthogonal	O
after	O
an	O
appropriate	O
re-scaling	O
)	O
is	O
impractical	O
,	O
so	O
most	O
practitioners	O
assume	O
a	O
general	O
3	O
×	O
3	O
homogeneous	O
matrix	O
form	O
.	O
the	O
relationship	O
between	O
the	O
3d	O
pixel	O
center	O
p	O
and	O
the	O
3d	O
camera-centered	O
point	O
pc	O
is	O
given	O
by	O
an	O
unknown	O
scaling	O
s	O
,	O
p	O
=	O
spc	O
.	O
we	O
can	O
therefore	O
write	O
the	O
complete	O
projection	O
between	O
pc	O
and	O
a	O
homogeneous	O
version	O
of	O
the	O
pixel	O
address	O
˜xs	O
as	O
˜xs	O
=	O
αm−1	O
s	O
pc	O
=	O
kpc	O
.	O
(	O
2.54	O
)	O
the	O
3	O
×	O
3	O
matrix	O
k	O
is	O
called	O
the	O
calibration	B
matrix	I
and	O
describes	O
the	O
camera	B
intrinsics	O
(	O
as	O
opposed	O
to	O
the	O
camera	B
’	O
s	O
orientation	O
in	O
space	O
,	O
which	O
are	O
called	O
the	O
extrinsics	O
)	O
.	O
from	O
the	O
above	O
discussion	O
,	O
we	O
see	O
that	O
k	O
has	O
seven	O
degrees	O
of	O
freedom	O
in	O
theory	O
and	O
eight	O
degrees	O
of	O
freedom	O
(	O
the	O
full	O
dimensionality	O
of	O
a	O
3×	O
3	O
homogeneous	O
matrix	O
)	O
in	O
practice	O
.	O
why	O
,	O
then	O
,	O
do	O
most	O
textbooks	B
on	O
3d	O
computer	O
vision	O
and	O
multi-view	B
geometry	O
(	O
faugeras	O
1993	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
faugeras	O
and	O
luong	O
2001	O
)	O
treat	O
k	O
as	O
an	O
upper-triangular	O
matrix	O
with	O
ﬁve	O
degrees	O
of	O
freedom	O
?	O
while	O
this	O
is	O
usually	O
not	O
made	O
explicit	O
in	O
these	O
books	O
,	O
it	O
is	O
because	O
we	O
can	O
not	O
recover	O
the	O
full	O
k	O
matrix	O
based	O
on	O
external	O
measurement	O
alone	O
.	O
when	O
calibrating	O
a	O
camera	B
(	O
chap-	O
ter	O
6	O
)	O
based	O
on	O
external	O
3d	O
points	B
or	O
other	O
measurements	O
(	O
tsai	O
1987	O
)	O
,	O
we	O
end	O
up	O
estimating	O
the	O
intrinsic	B
(	O
k	O
)	O
and	O
extrinsic	B
(	O
r	O
,	O
t	O
)	O
camera	B
parameters	O
simultaneously	O
using	O
a	O
series	O
of	O
measurements	O
,	O
(	O
2.55	O
)	O
(	O
2.56	O
)	O
where	O
pw	O
are	O
known	O
3d	O
world	O
coordinates	O
and	O
˜xs	O
=	O
k	O
(	O
cid:104	O
)	O
r	O
t	O
(	O
cid:105	O
)	O
pw	O
=	O
p	O
pw	O
,	O
p	O
=	O
k	O
[	O
r|t	O
]	O
is	O
known	O
as	O
the	O
camera	B
matrix	O
.	O
inspecting	O
this	O
equation	B
,	O
we	O
see	O
that	O
we	O
can	O
post-multiply	O
1	O
,	O
and	O
still	O
end	O
up	O
with	O
a	O
valid	O
calibration	B
.	O
thus	O
,	O
it	O
k	O
by	O
r1	O
and	O
pre-multiply	O
[	O
r|t	O
]	O
by	O
rt	O
is	O
impossible	O
based	O
on	O
image	B
measurements	O
alone	O
to	O
know	O
the	O
true	O
orientation	O
of	O
the	O
sensor	B
and	O
the	O
true	O
camera	O
intrinsics	O
.	O
the	O
choice	O
of	O
an	O
upper-triangular	O
form	O
for	O
k	O
seems	O
to	O
be	O
conventional	O
.	O
given	O
a	O
full	O
3	O
×	O
4	O
camera	B
matrix	O
p	O
=	O
k	O
[	O
r|t	O
]	O
,	O
we	O
can	O
compute	O
an	O
upper-triangular	O
k	O
matrix	O
using	O
qr	O
52	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.9	O
simpliﬁed	O
camera	B
intrinsics	O
showing	O
the	O
focal	O
length	O
f	O
and	O
the	O
optical	O
center	O
(	O
cx	O
,	O
cy	O
)	O
.	O
the	O
image	B
width	O
and	O
height	O
are	O
w	O
and	O
h.	O
factorization	B
(	O
golub	O
and	O
van	O
loan	O
1996	O
)	O
.	O
(	O
note	O
the	O
unfortunate	O
clash	O
of	O
terminologies	O
:	O
in	O
matrix	O
algebra	O
textbooks	B
,	O
r	O
represents	O
an	O
upper-triangular	O
(	O
right	O
of	O
the	O
diagonal	O
)	O
matrix	O
;	O
in	O
computer	O
vision	O
,	O
r	O
is	O
an	O
orthogonal	O
rotation	O
.	O
)	O
there	O
are	O
several	O
ways	O
to	O
write	O
the	O
upper-triangular	O
form	O
of	O
k.	O
one	O
possibility	O
is	O
k	O
=	O
fx	O
0	O
0	O
s	O
fy	O
0	O
cx	O
cy	O
1	O
k	O
=	O
k	O
=	O
f	O
s	O
0	O
af	O
0	O
0	O
cx	O
cy	O
1	O
f	O
0	O
0	O
0	O
f	O
0	O
cx	O
cy	O
1	O
	O
,	O
	O
,	O
	O
.	O
(	O
2.57	O
)	O
(	O
2.58	O
)	O
(	O
2.59	O
)	O
which	O
uses	O
independent	O
focal	O
lengths	O
fx	O
and	O
fy	O
for	O
the	O
sensor	B
x	O
and	O
y	O
dimensions	O
.	O
the	O
entry	O
s	O
encodes	O
any	O
possible	O
skew	O
between	O
the	O
sensor	B
axes	O
due	O
to	O
the	O
sensor	B
not	O
being	O
mounted	O
perpendicular	O
to	O
the	O
optical	O
axis	O
and	O
(	O
cx	O
,	O
cy	O
)	O
denotes	O
the	O
optical	O
center	O
expressed	O
in	O
pixel	O
coordinates	O
.	O
another	O
possibility	O
is	O
where	O
the	O
aspect	O
ratio	O
a	O
has	O
been	O
made	O
explicit	O
and	O
a	O
common	O
focal	O
length	O
f	O
is	O
used	O
.	O
in	O
practice	O
,	O
for	O
many	O
applications	O
an	O
even	O
simpler	O
form	O
can	O
be	O
obtained	O
by	O
setting	O
a	O
=	O
1	O
and	O
s	O
=	O
0	O
,	O
often	O
,	O
setting	O
the	O
origin	O
at	O
roughly	O
the	O
center	O
of	O
the	O
image	B
,	O
e.g.	O
,	O
(	O
cx	O
,	O
cy	O
)	O
=	O
(	O
w/2	O
,	O
h/2	O
)	O
,	O
where	O
w	O
and	O
h	O
are	O
the	O
image	B
height	O
and	O
width	O
,	O
can	O
result	O
in	O
a	O
perfectly	O
usable	O
camera	B
model	O
with	O
a	O
single	O
unknown	O
,	O
i.e.	O
,	O
the	O
focal	O
length	O
f.	O
zcxc0ycxsysw-1h-1	O
(	O
cx	O
,	O
cy	O
)	O
0f	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
53	O
figure	O
2.10	O
central	O
projection	O
,	O
showing	O
the	O
relationship	O
between	O
the	O
3d	O
and	O
2d	O
coordi-	O
nates	O
,	O
p	O
and	O
x	O
,	O
as	O
well	O
as	O
the	O
relationship	O
between	O
the	O
focal	O
length	O
f	O
,	O
image	B
width	O
w	O
,	O
and	O
the	O
ﬁeld	O
of	O
view	O
θ.	O
figure	O
2.9	O
shows	O
how	O
these	O
quantities	O
can	O
be	O
visualized	O
as	O
part	O
of	O
a	O
simpliﬁed	O
imaging	O
model	O
.	O
note	O
that	O
now	O
we	O
have	O
placed	O
the	O
image	B
plane	O
in	O
front	O
of	O
the	O
nodal	B
point	I
(	O
projection	O
center	O
of	O
the	O
lens	O
)	O
.	O
the	O
sense	O
of	O
the	O
y	O
axis	O
has	O
also	O
been	O
ﬂipped	O
to	O
get	O
a	O
coordinate	O
system	O
compatible	O
with	O
the	O
way	O
that	O
most	O
imaging	O
libraries	O
treat	O
the	O
vertical	O
(	O
row	O
)	O
coordinate	O
.	O
cer-	O
tain	O
graphics	O
libraries	O
,	O
such	O
as	O
direct3d	O
,	O
use	O
a	O
left-handed	O
coordinate	O
system	O
,	O
which	O
can	O
lead	O
to	O
some	O
confusion	O
.	O
a	O
note	O
on	O
focal	O
lengths	O
the	O
issue	O
of	O
how	O
to	O
express	O
focal	O
lengths	O
is	O
one	O
that	O
often	O
causes	O
confusion	O
in	O
implementing	O
computer	O
vision	O
algorithms	O
and	O
discussing	O
their	O
results	O
.	O
this	O
is	O
because	O
the	O
focal	O
length	O
depends	O
on	O
the	O
units	O
used	O
to	O
measure	O
pixels	O
.	O
if	O
we	O
number	O
pixel	O
coordinates	O
using	O
integer	O
values	O
,	O
say	O
[	O
0	O
,	O
w	O
)	O
×	O
[	O
0	O
,	O
h	O
)	O
,	O
the	O
focal	O
length	O
f	O
and	O
camera	B
center	O
(	O
cx	O
,	O
cy	O
)	O
in	O
(	O
2.59	O
)	O
can	O
be	O
expressed	O
as	O
pixel	O
values	O
.	O
how	O
do	O
these	O
quan-	O
tities	O
relate	O
to	O
the	O
more	O
familiar	O
focal	O
lengths	O
used	O
by	O
photographers	O
?	O
figure	O
2.10	O
illustrates	O
the	O
relationship	O
between	O
the	O
focal	O
length	O
f	O
,	O
the	O
sensor	B
width	O
w	O
,	O
and	O
the	O
ﬁeld	O
of	O
view	O
θ	O
,	O
which	O
obey	O
the	O
formula	O
tan	O
θ	O
2	O
=	O
w	O
2f	O
or	O
f	O
=	O
w	O
2	O
(	O
cid:20	O
)	O
tan	O
θ	O
2	O
(	O
cid:21	O
)	O
−1	O
.	O
(	O
2.60	O
)	O
for	O
conventional	O
ﬁlm	O
cameras	O
,	O
w	O
=	O
35mm	O
,	O
and	O
hence	O
f	O
is	O
also	O
expressed	O
in	O
millimeters	O
.	O
since	O
we	O
work	O
with	O
digital	O
images	O
,	O
it	O
is	O
more	O
convenient	O
to	O
express	O
w	O
in	O
pixels	O
so	O
that	O
the	O
focal	O
length	O
f	O
can	O
be	O
used	O
directly	O
in	O
the	O
calibration	B
matrix	I
k	O
as	O
in	O
(	O
2.59	O
)	O
.	O
another	O
possibility	O
is	O
to	O
scale	O
the	O
pixel	O
coordinates	O
so	O
that	O
they	O
go	O
from	O
[	O
−1	O
,	O
1	O
)	O
along	O
the	O
longer	O
image	B
dimension	O
and	O
[	O
−a−1	O
,	O
a−1	O
)	O
along	O
the	O
shorter	O
axis	O
,	O
where	O
a	O
≥	O
1	O
is	O
the	O
image	B
aspect	O
ratio	O
(	O
as	O
opposed	O
to	O
the	O
sensor	B
cell	O
aspect	O
ratio	O
introduced	O
earlier	O
)	O
.	O
this	O
can	O
be	O
w/2fθ/2	O
(	O
x	O
,	O
y,1	O
)	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
z	O
54	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
accomplished	O
using	O
modiﬁed	O
normalized	B
device	O
coordinates	O
,	O
x	O
(	O
cid:48	O
)	O
s	O
=	O
(	O
2xs	O
−	O
w	O
)	O
/s	O
and	O
y	O
(	O
cid:48	O
)	O
s	O
=	O
(	O
2ys	O
−	O
h	O
)	O
/s	O
,	O
where	O
s	O
=	O
max	O
(	O
w	O
,	O
h	O
)	O
.	O
(	O
2.61	O
)	O
this	O
has	O
the	O
advantage	O
that	O
the	O
focal	O
length	O
f	O
and	O
optical	O
center	O
(	O
cx	O
,	O
cy	O
)	O
become	O
independent	O
of	O
the	O
image	B
resolution	O
,	O
which	O
can	O
be	O
useful	O
when	O
using	O
multi-resolution	O
,	O
image-processing	O
algorithms	O
,	O
such	O
as	O
image	B
pyramids	O
(	O
section	O
3.5	O
)	O
.2	O
the	O
use	O
of	O
s	O
instead	O
of	O
w	O
also	O
makes	O
the	O
focal	O
length	O
the	O
same	O
for	O
landscape	O
(	O
horizontal	O
)	O
and	O
portrait	O
(	O
vertical	O
)	O
pictures	O
,	O
as	O
is	O
the	O
case	O
in	O
35mm	O
photography	O
.	O
(	O
in	O
some	O
computer	O
graphics	O
textbooks	B
and	O
systems	O
,	O
normalized	B
device	O
coordinates	O
go	O
from	O
[	O
−1	O
,	O
1	O
]	O
×	O
[	O
−1	O
,	O
1	O
]	O
,	O
which	O
requires	O
the	O
use	O
of	O
two	O
different	O
focal	O
lengths	O
to	O
describe	O
the	O
camera	B
intrinsics	O
(	O
watt	O
1995	O
;	O
opengl-arb	O
1997	O
)	O
.	O
)	O
setting	O
s	O
=	O
w	O
=	O
2	O
in	O
(	O
2.60	O
)	O
,	O
we	O
obtain	O
the	O
simpler	O
(	O
unitless	O
)	O
relationship	O
f−1	O
=	O
tan	O
θ	O
2	O
.	O
(	O
2.62	O
)	O
the	O
conversion	O
between	O
the	O
various	O
focal	O
length	O
representations	O
is	O
straightforward	O
,	O
e.g.	O
,	O
to	O
go	O
from	O
a	O
unitless	O
f	O
to	O
one	O
expressed	O
in	O
pixels	O
,	O
multiply	O
by	O
w/2	O
,	O
while	O
to	O
convert	O
from	O
an	O
f	O
expressed	O
in	O
pixels	O
to	O
the	O
equivalent	O
35mm	O
focal	O
length	O
,	O
multiply	O
by	O
35/w	O
.	O
camera	B
matrix	O
now	O
that	O
we	O
have	O
shown	O
how	O
to	O
parameterize	O
the	O
calibration	B
matrix	I
k	O
,	O
we	O
can	O
put	O
the	O
camera	B
intrinsics	O
and	O
extrinsics	O
together	O
to	O
obtain	O
a	O
single	O
3	O
×	O
4	O
camera	B
matrix	O
(	O
2.63	O
)	O
it	O
is	O
sometimes	O
preferable	O
to	O
use	O
an	O
invertible	O
4	O
×	O
4	O
matrix	O
,	O
which	O
can	O
be	O
obtained	O
by	O
not	O
dropping	O
the	O
last	O
row	O
in	O
the	O
p	O
matrix	O
,	O
p	O
=	O
k	O
(	O
cid:104	O
)	O
r	O
t	O
(	O
cid:105	O
)	O
.	O
˜p	O
=	O
(	O
cid:34	O
)	O
k	O
0	O
1	O
(	O
cid:35	O
)	O
(	O
cid:34	O
)	O
r	O
t	O
1	O
(	O
cid:35	O
)	O
=	O
˜ke	O
,	O
0t	O
0t	O
(	O
2.64	O
)	O
where	O
e	O
is	O
a	O
3d	O
rigid-body	O
(	O
euclidean	O
)	O
transformation	O
and	O
˜k	O
is	O
the	O
full-rank	O
calibration	B
matrix	I
.	O
the	O
4	O
×	O
4	O
camera	B
matrix	O
˜p	O
can	O
be	O
used	O
to	O
map	O
directly	O
from	O
3d	O
world	O
coordinates	O
¯pw	O
=	O
(	O
xw	O
,	O
yw	O
,	O
zw	O
,	O
1	O
)	O
to	O
screen	O
coordinates	O
(	O
plus	O
disparity	O
)	O
,	O
xs	O
=	O
(	O
xs	O
,	O
ys	O
,	O
1	O
,	O
d	O
)	O
,	O
xs	O
∼	O
˜p	O
¯pw	O
,	O
(	O
2.65	O
)	O
where	O
∼	O
indicates	O
equality	O
up	O
to	O
scale	O
.	O
note	O
that	O
after	O
multiplication	B
by	O
˜p	O
,	O
the	O
vector	O
is	O
divided	O
by	O
the	O
third	O
element	O
of	O
the	O
vector	O
to	O
obtain	O
the	O
normalized	B
form	O
xs	O
=	O
(	O
xs	O
,	O
ys	O
,	O
1	O
,	O
d	O
)	O
.	O
2	O
to	O
make	O
the	O
conversion	O
truly	O
accurate	O
after	O
a	O
downsampling	O
step	O
in	O
a	O
pyramid	B
,	O
ﬂoating	O
point	O
values	O
of	O
w	O
and	O
h	O
would	O
have	O
to	O
be	O
maintained	O
since	O
they	O
can	O
become	O
non-integral	O
if	O
they	O
are	O
ever	O
odd	O
at	O
a	O
larger	O
resolution	O
in	O
the	O
pyramid	B
.	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
55	O
figure	O
2.11	O
regular	O
disparity	O
(	O
inverse	B
depth	O
)	O
and	O
projective	B
depth	O
(	O
parallax	O
from	O
a	O
reference	O
plane	O
)	O
.	O
plane	O
plus	O
parallax	O
(	O
projective	B
depth	O
)	O
in	O
general	O
,	O
when	O
using	O
the	O
4	O
×	O
4	O
matrix	O
˜p	O
,	O
we	O
have	O
the	O
freedom	O
to	O
remap	O
the	O
last	O
row	O
to	O
whatever	O
suits	O
our	O
purpose	O
(	O
rather	O
than	O
just	O
being	O
the	O
“	O
standard	O
”	O
interpretation	O
of	O
disparity	O
as	O
inverse	B
depth	O
)	O
.	O
let	O
us	O
re-write	O
the	O
last	O
row	O
of	O
˜p	O
as	O
p3	O
=	O
s3	O
[	O
ˆn0|c0	O
]	O
,	O
where	O
(	O
cid:107	O
)	O
ˆn0	O
(	O
cid:107	O
)	O
=	O
1.	O
we	O
then	O
have	O
the	O
equation	B
(	O
2.66	O
)	O
d	O
=	O
s3	O
z	O
(	O
ˆn0	O
·	O
pw	O
+	O
c0	O
)	O
,	O
where	O
z	O
=	O
p2	O
·	O
¯pw	O
=	O
rz	O
·	O
(	O
pw	O
−	O
c	O
)	O
is	O
the	O
distance	O
of	O
pw	O
from	O
the	O
camera	B
center	O
c	O
(	O
2.25	O
)	O
along	O
the	O
optical	O
axis	O
z	O
(	O
figure	O
2.11	O
)	O
.	O
thus	O
,	O
we	O
can	O
interpret	O
d	O
as	O
the	O
projective	B
disparity	O
or	O
projective	B
depth	O
of	O
a	O
3d	O
scene	O
point	O
pw	O
from	O
the	O
reference	O
plane	O
ˆn0	O
·	O
pw	O
+	O
c0	O
=	O
0	O
(	O
szeliski	O
and	O
coughlan	O
1997	O
;	O
szeliski	O
and	O
golland	O
1999	O
;	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
;	O
baker	O
,	O
szeliski	O
,	O
and	O
anandan	O
1998	O
)	O
.	O
(	O
the	O
projective	B
depth	O
is	O
also	O
sometimes	O
called	O
parallax	O
in	O
reconstruction	O
algorithms	O
that	O
use	O
the	O
term	O
plane	O
plus	O
parallax	O
(	O
kumar	O
,	O
anandan	O
,	O
and	O
hanna	O
1994	O
;	O
sawhney	O
1994	O
)	O
.	O
)	O
setting	O
ˆn0	O
=	O
0	O
and	O
c0	O
=	O
1	O
,	O
i.e.	O
,	O
putting	O
the	O
reference	O
plane	O
at	O
inﬁnity	O
,	O
results	O
in	O
the	O
more	O
standard	O
d	O
=	O
1/z	O
version	O
of	O
disparity	O
(	O
okutomi	O
and	O
kanade	O
1993	O
)	O
.	O
another	O
way	O
to	O
see	O
this	O
is	O
to	O
invert	O
the	O
˜p	O
matrix	O
so	O
that	O
we	O
can	O
map	O
pixels	O
plus	O
disparity	O
directly	O
back	O
to	O
3d	O
points	B
,	O
˜pw	O
=	O
˜p	O
−1	O
xs	O
.	O
(	O
2.67	O
)	O
in	O
general	O
,	O
we	O
can	O
choose	O
˜p	O
to	O
have	O
whatever	O
form	O
is	O
convenient	O
,	O
i.e.	O
,	O
to	O
sample	O
space	O
us-	O
ing	O
an	O
arbitrary	O
projection	O
.	O
this	O
can	O
come	O
in	O
particularly	O
handy	O
when	O
setting	O
up	O
multi-view	O
stereo	B
reconstruction	O
algorithms	O
,	O
since	O
it	O
allows	O
us	O
to	O
sweep	O
a	O
series	O
of	O
planes	B
(	O
section	O
11.1.2	O
)	O
through	O
space	O
with	O
a	O
variable	O
(	O
projective	B
)	O
sampling	B
that	O
best	O
matches	O
the	O
sensed	O
image	B
mo-	O
tions	O
(	O
collins	O
1996	O
;	O
szeliski	O
and	O
golland	O
1999	O
;	O
saito	O
and	O
kanade	O
1999	O
)	O
.	O
c	O
(	O
xs	O
,	O
ys	O
,	O
d	O
)	O
zimage	O
planed=1.0d=0.67d=0.5d	O
=	O
inverse	B
depth	O
(	O
xw	O
,	O
yw	O
,	O
zw	O
)	O
dzc	O
(	O
xs	O
,	O
ys	O
,	O
d	O
)	O
zimage	O
planed=0.5d=0d=-0.25d	O
=	O
projective	B
depth	O
(	O
xw	O
,	O
yw	O
,	O
zw	O
)	O
zplaneparallax	O
56	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
2.12	O
a	O
point	O
is	O
projected	O
into	O
two	O
images	O
:	O
(	O
a	O
)	O
relationship	O
between	O
the	O
3d	O
point	O
co-	O
ordinate	O
(	O
x	O
,	O
y	O
,	O
z	O
,	O
1	O
)	O
and	O
the	O
2d	O
projected	O
point	O
(	O
x	O
,	O
y	O
,	O
1	O
,	O
d	O
)	O
;	O
(	O
b	O
)	O
planar	O
homography	O
induced	O
by	O
points	O
all	O
lying	O
on	O
a	O
common	O
plane	O
ˆn0	O
·	O
p	O
+	O
c0	O
=	O
0.	O
mapping	O
from	O
one	O
camera	B
to	O
another	O
what	O
happens	O
when	O
we	O
take	O
two	O
images	O
of	O
a	O
3d	O
scene	O
from	O
different	O
camera	B
positions	O
or	O
orientations	O
(	O
figure	O
2.12a	O
)	O
?	O
using	O
the	O
full	O
rank	O
4	O
×	O
4	O
camera	B
matrix	O
˜p	O
=	O
˜ke	O
from	O
(	O
2.64	O
)	O
,	O
we	O
can	O
write	O
the	O
projection	O
from	O
world	O
to	O
screen	O
coordinates	O
as	O
˜x0	O
∼	O
˜k0e0p	O
=	O
˜p	O
0p	O
.	O
assuming	O
that	O
we	O
know	O
the	O
z-buffer	O
or	O
disparity	O
value	O
d0	O
for	O
a	O
pixel	O
in	O
one	O
image	B
,	O
we	O
can	O
compute	O
the	O
3d	O
point	O
location	O
p	O
using	O
(	O
2.68	O
)	O
(	O
2.69	O
)	O
(	O
2.70	O
)	O
p	O
∼	O
e−1	O
0	O
and	O
then	O
project	O
it	O
into	O
another	O
image	B
yielding	O
˜x1	O
∼	O
˜k1e1p	O
=	O
˜k1e1e−1	O
0	O
˜k−1	O
0	O
˜x0	O
˜k−1	O
0	O
˜x0	O
=	O
˜p	O
1	O
˜p	O
−1	O
0	O
˜x0	O
=	O
m	O
10	O
˜x0	O
.	O
unfortunately	O
,	O
we	O
do	O
not	O
usually	O
have	O
access	O
to	O
the	O
depth	O
coordinates	O
of	O
pixels	O
in	O
a	O
regular	O
photographic	O
image	B
.	O
however	O
,	O
for	O
a	O
planar	O
scene	O
,	O
as	O
discussed	O
above	O
in	O
(	O
2.66	O
)	O
,	O
we	O
can	O
replace	O
the	O
last	O
row	O
of	O
p	O
0	O
in	O
(	O
2.64	O
)	O
with	O
a	O
general	O
plane	O
equation	O
,	O
ˆn0	O
·	O
p	O
+	O
c0	O
that	O
maps	O
points	B
on	O
the	O
plane	O
to	O
d0	O
=	O
0	O
values	O
(	O
figure	O
2.12b	O
)	O
.	O
thus	O
,	O
if	O
we	O
set	O
d0	O
=	O
0	O
,	O
we	O
can	O
ignore	O
the	O
last	O
column	O
of	O
m	O
10	O
in	O
(	O
2.70	O
)	O
and	O
also	O
its	O
last	O
row	O
,	O
since	O
we	O
do	O
not	O
care	O
about	O
the	O
ﬁnal	O
z-buffer	O
depth	O
.	O
the	O
mapping	O
equation	B
(	O
2.70	O
)	O
thus	O
reduces	O
to	O
˜x1	O
∼	O
˜h	O
10	O
˜x0	O
,	O
(	O
2.71	O
)	O
where	O
˜h	O
10	O
is	O
a	O
general	O
3	O
×	O
3	O
homography	B
matrix	O
and	O
˜x1	O
and	O
˜x0	O
are	O
now	O
2d	O
homogeneous	B
coordinates	I
(	O
i.e.	O
,	O
3-vectors	O
)	O
(	O
szeliski	O
1996	O
)	O
.this	O
justiﬁes	O
the	O
use	O
of	O
the	O
8-parameter	O
homog-	O
raphy	O
as	O
a	O
general	O
alignment	B
model	O
for	O
mosaics	O
of	O
planar	O
scenes	O
(	O
mann	O
and	O
picard	O
1994	O
;	O
szeliski	O
1996	O
)	O
.	O
p=	O
(	O
x	O
,	O
y	O
,	O
z,1	O
)	O
x1=	O
(	O
x1	O
,	O
y1,1	O
,	O
d1	O
)	O
x0=	O
(	O
x0	O
,	O
y0,1	O
,	O
d0	O
)	O
~~m10n0·p+c0=	O
0x1=	O
(	O
x1	O
,	O
y1,1	O
)	O
x0=	O
(	O
x0	O
,	O
y0,1	O
)	O
~~h10^	O
.	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
57	O
the	O
other	O
special	O
case	O
where	O
we	O
do	O
not	O
need	O
to	O
know	O
depth	O
to	O
perform	O
inter-camera	O
mapping	O
is	O
when	O
the	O
camera	B
is	O
undergoing	O
pure	B
rotation	I
(	O
section	O
9.1.3	O
)	O
,	O
i.e.	O
,	O
when	O
t0	O
=	O
t1	O
.	O
in	O
this	O
case	O
,	O
we	O
can	O
write	O
˜x1	O
∼	O
k1r1r−1	O
0	O
k−1	O
0	O
˜x0	O
=	O
k1r10k−1	O
0	O
˜x0	O
,	O
(	O
2.72	O
)	O
which	O
again	O
can	O
be	O
represented	O
with	O
a	O
3	O
×	O
3	O
homography	B
.	O
if	O
we	O
assume	O
that	O
the	O
calibration	B
matrices	O
have	O
known	O
aspect	O
ratios	B
and	O
centers	O
of	O
projection	O
(	O
2.59	O
)	O
,	O
this	O
homography	B
can	O
be	O
parameterized	O
by	O
the	O
rotation	O
amount	O
and	O
the	O
two	O
unknown	O
focal	O
lengths	O
.	O
this	O
particular	O
formulation	O
is	O
commonly	O
used	O
in	O
image-stitching	O
applications	O
(	O
section	O
9.1.3	O
)	O
.	O
object-centered	B
projection	O
when	O
working	O
with	O
long	O
focal	O
length	O
lenses	O
,	O
it	O
often	O
becomes	O
difﬁcult	O
to	O
reliably	O
estimate	O
the	O
focal	O
length	O
from	O
image	B
measurements	O
alone	O
.	O
this	O
is	O
because	O
the	O
focal	O
length	O
and	O
the	O
distance	O
to	O
the	O
object	O
are	O
highly	O
correlated	O
and	O
it	O
becomes	O
difﬁcult	O
to	O
tease	O
these	O
two	O
effects	O
apart	O
.	O
for	O
example	O
,	O
the	O
change	O
in	O
scale	O
of	O
an	O
object	O
viewed	O
through	O
a	O
zoom	O
telephoto	O
lens	O
can	O
either	O
be	O
due	O
to	O
a	O
zoom	O
change	O
or	O
a	O
motion	B
towards	O
the	O
user	O
.	O
(	O
this	O
effect	O
was	O
put	O
to	O
dramatic	O
use	O
in	O
some	O
of	O
alfred	O
hitchcock	O
’	O
s	O
ﬁlm	O
vertigo	O
,	O
where	O
the	O
simultaneous	O
change	O
of	O
zoom	O
and	O
camera	B
motion	O
produces	O
a	O
disquieting	O
effect	O
.	O
)	O
this	O
ambiguity	O
becomes	O
clearer	O
if	O
we	O
write	O
out	O
the	O
projection	O
equation	B
corresponding	O
to	O
the	O
simple	O
calibration	B
matrix	I
k	O
(	O
2.59	O
)	O
,	O
xs	O
=	O
f	O
ys	O
=	O
f	O
rx	O
·	O
p	O
+	O
tx	O
rz	O
·	O
p	O
+	O
tz	O
ry	O
·	O
p	O
+	O
ty	O
rz	O
·	O
p	O
+	O
tz	O
+	O
cx	O
+	O
cy	O
,	O
(	O
2.73	O
)	O
(	O
2.74	O
)	O
where	O
rx	O
,	O
ry	O
,	O
and	O
rz	O
are	O
the	O
three	O
rows	O
of	O
r.	O
if	O
the	O
distance	O
to	O
the	O
object	O
center	O
tz	O
(	O
cid:29	O
)	O
(	O
cid:107	O
)	O
p	O
(	O
cid:107	O
)	O
(	O
the	O
size	O
of	O
the	O
object	O
)	O
,	O
the	O
denominator	O
is	O
approximately	O
tz	O
and	O
the	O
overall	O
scale	O
of	O
the	O
projected	O
object	O
depends	O
on	O
the	O
ratio	O
of	O
f	O
to	O
tz	O
.	O
it	O
therefore	O
becomes	O
difﬁcult	O
to	O
disentangle	O
these	O
two	O
quantities	O
.	O
to	O
see	O
this	O
more	O
clearly	O
,	O
let	O
ηz	O
=	O
t−1	O
z	O
equations	B
as	O
and	O
s	O
=	O
ηzf	O
.	O
we	O
can	O
then	O
re-write	O
the	O
above	O
xs	O
=	O
s	O
ys	O
=	O
s	O
rx	O
·	O
p	O
+	O
tx	O
1	O
+	O
ηzrz	O
·	O
p	O
ry	O
·	O
p	O
+	O
ty	O
1	O
+	O
ηzrz	O
·	O
p	O
+	O
cx	O
+	O
cy	O
(	O
2.75	O
)	O
(	O
2.76	O
)	O
(	O
szeliski	O
and	O
kang	O
1994	O
;	O
pighin	O
,	O
hecker	O
,	O
lischinski	O
et	O
al	O
.	O
1998	O
)	O
.	O
the	O
scale	O
of	O
the	O
projection	O
s	O
can	O
be	O
reliably	O
estimated	O
if	O
we	O
are	O
looking	O
at	O
a	O
known	O
object	O
(	O
i.e.	O
,	O
the	O
3d	O
coordinates	O
p	O
58	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
are	O
known	O
)	O
.	O
the	O
inverse	B
distance	O
ηz	O
is	O
now	O
mostly	O
decoupled	O
from	O
the	O
estimates	O
of	O
s	O
and	O
can	O
be	O
estimated	O
from	O
the	O
amount	O
of	O
foreshortening	O
as	O
the	O
object	O
rotates	O
.	O
furthermore	O
,	O
as	O
the	O
lens	O
becomes	O
longer	O
,	O
i.e.	O
,	O
the	O
projection	O
model	O
becomes	O
orthographic	B
,	O
there	O
is	O
no	O
need	O
to	O
replace	O
a	O
perspective	B
imaging	O
model	O
with	O
an	O
orthographic	B
one	O
,	O
since	O
the	O
same	O
equation	B
can	O
be	O
used	O
,	O
with	O
ηz	O
→	O
0	O
(	O
as	O
opposed	O
to	O
f	O
and	O
tz	O
both	O
going	O
to	O
inﬁnity	O
)	O
.	O
this	O
allows	O
us	O
to	O
form	O
a	O
natural	B
link	O
between	O
orthographic	B
reconstruction	O
techniques	O
such	O
as	O
factorization	B
and	O
their	O
projective/perspective	O
counterparts	O
(	O
section	O
7.3	O
)	O
.	O
2.1.6	O
lens	O
distortions	O
the	O
above	O
imaging	O
models	O
all	O
assume	O
that	O
cameras	O
obey	O
a	O
linear	B
projection	O
model	O
where	O
straight	O
lines	B
in	O
the	O
world	O
result	O
in	O
straight	O
lines	B
in	O
the	O
image	B
.	O
(	O
this	O
follows	O
as	O
a	O
natural	B
consequence	O
of	O
linear	B
matrix	O
operations	O
being	O
applied	O
to	O
homogeneous	B
coordinates	I
.	O
)	O
unfor-	O
tunately	O
,	O
many	O
wide-angle	O
lenses	O
have	O
noticeable	O
radial	B
distortion	I
,	O
which	O
manifests	O
itself	O
as	O
a	O
visible	O
curvature	O
in	O
the	O
projection	O
of	O
straight	O
lines	B
.	O
(	O
see	O
section	O
2.2.3	O
for	O
a	O
more	O
detailed	O
discussion	O
of	O
lens	O
optics	B
,	O
including	O
chromatic	B
aberration	I
.	O
)	O
unless	O
this	O
distortion	O
is	O
taken	O
into	O
account	O
,	O
it	O
becomes	O
impossible	O
to	O
create	O
highly	O
accurate	O
photorealistic	O
reconstructions	O
.	O
for	O
example	O
,	O
image	B
mosaics	O
constructed	O
without	O
taking	O
radial	B
distortion	I
into	O
account	O
will	O
often	O
exhibit	O
blurring	O
due	O
to	O
the	O
mis-registration	O
of	O
corresponding	O
features	O
before	O
pixel	O
blending	O
(	O
chapter	O
9	O
)	O
.	O
fortunately	O
,	O
compensating	O
for	O
radial	O
distortion	O
is	O
not	O
that	O
difﬁcult	O
in	O
practice	O
.	O
for	O
most	O
lenses	O
,	O
a	O
simple	O
quartic	O
model	O
of	O
distortion	O
can	O
produce	O
good	O
results	O
.	O
let	O
(	O
xc	O
,	O
yc	O
)	O
be	O
the	O
pixel	O
coordinates	O
obtained	O
after	O
perspective	B
division	O
but	O
before	O
scaling	O
by	O
focal	O
length	O
f	O
and	O
shifting	O
by	O
the	O
optical	O
center	O
(	O
cx	O
,	O
cy	O
)	O
,	O
i.e.	O
,	O
xc	O
=	O
yc	O
=	O
rx	O
·	O
p	O
+	O
tx	O
rz	O
·	O
p	O
+	O
tz	O
ry	O
·	O
p	O
+	O
ty	O
rz	O
·	O
p	O
+	O
tz	O
.	O
(	O
2.77	O
)	O
the	O
radial	B
distortion	I
model	O
says	O
that	O
coordinates	O
in	O
the	O
observed	O
images	O
are	O
displaced	O
away	O
(	O
barrel	B
distortion	O
)	O
or	O
towards	O
(	O
pincushion	B
distortion	O
)	O
the	O
image	B
center	O
by	O
an	O
amount	O
propor-	O
tional	O
to	O
their	O
radial	B
distance	O
(	O
figure	O
2.13a–b	O
)	O
.3	O
the	O
simplest	O
radial	B
distortion	I
models	O
use	O
low-order	O
polynomials	O
,	O
e.g.	O
,	O
ˆxc	O
=	O
xc	O
(	O
1	O
+	O
κ1r2	O
ˆyc	O
=	O
yc	O
(	O
1	O
+	O
κ1r2	O
c	O
+	O
κ2r4	O
c	O
)	O
c	O
)	O
,	O
c	O
+	O
κ2r4	O
(	O
2.78	O
)	O
3	O
anamorphic	O
lenses	O
,	O
which	O
are	O
widely	O
used	O
in	O
feature	B
ﬁlm	O
production	O
,	O
do	O
not	O
follow	O
this	O
radial	B
distortion	I
model	O
.	O
instead	O
,	O
they	O
can	O
be	O
thought	O
of	O
,	O
to	O
a	O
ﬁrst	O
approximation	O
,	O
as	O
inducing	O
different	O
vertical	O
and	O
horizontal	O
scalings	O
,	O
i.e.	O
,	O
non-square	O
pixels	O
.	O
2.1	O
geometric	B
primitives	O
and	O
transformations	O
59	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
2.13	O
radial	B
lens	O
distortions	O
:	O
(	O
a	O
)	O
barrel	B
,	O
(	O
b	O
)	O
pincushion	B
,	O
and	O
(	O
c	O
)	O
ﬁsheye	O
.	O
the	O
ﬁsheye	O
image	B
spans	O
almost	O
180◦	O
from	O
side-to-side	O
.	O
c	O
=	O
x2	O
c	O
+	O
y2	O
where	O
r2	O
radial	B
distortion	I
step	O
,	O
the	O
ﬁnal	O
pixel	O
coordinates	O
can	O
be	O
computed	O
using	O
c	O
and	O
κ1	O
and	O
κ2	O
are	O
called	O
the	O
radial	B
distortion	I
parameters.4	O
after	O
the	O
xs	O
=	O
f	O
x	O
(	O
cid:48	O
)	O
c	O
+	O
cx	O
ys	O
=	O
f	O
y	O
(	O
cid:48	O
)	O
c	O
+	O
cy	O
.	O
(	O
2.79	O
)	O
a	O
variety	O
of	O
techniques	O
can	O
be	O
used	O
to	O
estimate	O
the	O
radial	B
distortion	I
parameters	O
for	O
a	O
given	O
lens	O
,	O
as	O
discussed	O
in	O
section	O
6.3.5.	O
sometimes	O
the	O
above	O
simpliﬁed	O
model	O
does	O
not	O
model	O
the	O
true	O
distortions	O
produced	O
by	O
complex	O
lenses	O
accurately	O
enough	O
(	O
especially	O
at	O
very	O
wide	O
angles	O
)	O
.	O
a	O
more	O
complete	O
ana-	O
lytic	O
model	O
also	O
includes	O
tangential	B
distortions	O
and	O
decentering	B
distortions	O
(	O
slama	O
1980	O
)	O
,	O
but	O
these	O
distortions	O
are	O
not	O
covered	O
in	O
this	O
book	O
.	O
fisheye	O
lenses	O
(	O
figure	O
2.13c	O
)	O
require	O
a	O
model	O
that	O
differs	O
from	O
traditional	O
polynomial	O
models	O
of	O
radial	B
distortion	I
.	O
fisheye	O
lenses	O
behave	O
,	O
to	O
a	O
ﬁrst	O
approximation	O
,	O
as	O
equi-distance	O
projectors	O
of	O
angles	O
away	O
from	O
the	O
optical	O
axis	O
(	O
xiong	O
and	O
turkowski	O
1997	O
)	O
,	O
which	O
is	O
the	O
same	O
as	O
the	O
polar	O
projection	O
described	O
by	O
equations	O
(	O
9.22–9.24	O
)	O
.	O
xiong	O
and	O
turkowski	O
(	O
1997	O
)	O
describe	O
how	O
this	O
model	O
can	O
be	O
extended	O
with	O
the	O
addition	O
of	O
an	O
extra	O
quadratic	O
cor-	O
rection	O
in	O
φ	O
and	O
how	O
the	O
unknown	O
parameters	B
(	O
center	O
of	O
projection	O
,	O
scaling	O
factor	O
s	O
,	O
etc	O
.	O
)	O
can	O
be	O
estimated	O
from	O
a	O
set	O
of	O
overlapping	O
ﬁsheye	O
images	O
using	O
a	O
direct	B
(	O
intensity-based	B
)	O
non-linear	B
minimization	O
algorithm	B
.	O
for	O
even	O
larger	O
,	O
less	O
regular	O
distortions	O
,	O
a	O
parametric	B
distortion	O
model	O
using	O
splines	O
may	O
be	O
necessary	O
(	O
goshtasby	O
1989	O
)	O
.	O
if	O
the	O
lens	O
does	O
not	O
have	O
a	O
single	O
center	O
of	O
projection	O
,	O
it	O
4	O
sometimes	O
the	O
relationship	O
between	O
xc	O
and	O
ˆxc	O
is	O
expressed	O
the	O
other	O
way	O
around	O
,	O
i.e.	O
,	O
xc	O
=	O
ˆxc	O
(	O
1	O
+	O
κ1	O
ˆr2	O
c	O
+	O
c	O
)	O
.	O
this	O
is	O
convenient	O
if	O
we	O
map	O
image	B
pixels	O
into	O
(	O
warped	O
)	O
rays	O
by	O
dividing	O
through	O
by	O
f.	O
we	O
can	O
then	O
undistort	O
κ2	O
ˆr4	O
the	O
rays	O
and	O
have	O
true	O
3d	O
rays	O
in	O
space	O
.	O
60	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
may	O
become	O
necessary	O
to	O
model	O
the	O
3d	O
line	O
(	O
as	O
opposed	O
to	O
direction	O
)	O
corresponding	O
to	O
each	O
pixel	O
separately	O
(	O
gremban	O
,	O
thorpe	O
,	O
and	O
kanade	O
1988	O
;	O
champleboux	O
,	O
lavall´ee	O
,	O
sautot	O
et	O
al	O
.	O
1992	O
;	O
grossberg	O
and	O
nayar	O
2001	O
;	O
sturm	O
and	O
ramalingam	O
2004	O
;	O
tardif	O
,	O
sturm	O
,	O
trudeau	O
et	O
al	O
.	O
2009	O
)	O
.	O
some	O
of	O
these	O
techniques	O
are	O
described	O
in	O
more	O
detail	O
in	O
section	O
6.3.5	O
,	O
which	O
discusses	O
how	O
to	O
calibrate	O
lens	O
distortions	O
.	O
there	O
is	O
one	O
subtle	O
issue	O
associated	O
with	O
the	O
simple	O
radial	B
distortion	I
model	O
that	O
is	O
often	O
glossed	O
over	O
.	O
we	O
have	O
introduced	O
a	O
non-linearity	O
between	O
the	O
perspective	B
projection	O
and	O
ﬁnal	O
sensor	B
array	O
projection	O
steps	O
.	O
therefore	O
,	O
we	O
can	O
not	O
,	O
in	O
general	O
,	O
post-multiply	O
an	O
arbitrary	O
3×	O
3	O
matrix	O
k	O
with	O
a	O
rotation	O
to	O
put	O
it	O
into	O
upper-triangular	O
form	O
and	O
absorb	O
this	O
into	O
the	O
global	B
rotation	O
.	O
however	O
,	O
this	O
situation	O
is	O
not	O
as	O
bad	O
as	O
it	O
may	O
at	O
ﬁrst	O
appear	O
.	O
for	O
many	O
applications	O
,	O
keeping	O
the	O
simpliﬁed	O
diagonal	O
form	O
of	O
(	O
2.59	O
)	O
is	O
still	O
an	O
adequate	O
model	O
.	O
furthermore	O
,	O
if	O
we	O
correct	O
radial	B
and	O
other	O
distortions	O
to	O
an	O
accuracy	B
where	O
straight	O
lines	B
are	O
preserved	O
,	O
we	O
have	O
essentially	O
converted	O
the	O
sensor	B
back	O
into	O
a	O
linear	B
imager	O
and	O
the	O
previous	O
decomposition	O
still	O
applies	O
.	O
2.2	O
photometric	B
image	O
formation	O
in	O
modeling	B
the	O
image	B
formation	O
process	O
,	O
we	O
have	O
described	O
how	O
3d	O
geometric	B
features	O
in	O
the	O
world	O
are	O
projected	O
into	O
2d	O
features	O
in	O
an	O
image	B
.	O
however	O
,	O
images	O
are	O
not	O
composed	O
of	O
2d	O
features	O
.	O
instead	O
,	O
they	O
are	O
made	O
up	O
of	O
discrete	B
color	O
or	O
intensity	O
values	O
.	O
where	O
do	O
these	O
values	O
come	O
from	O
?	O
how	O
do	O
they	O
relate	O
to	O
the	O
lighting	B
in	O
the	O
environment	O
,	O
surface	B
properties	O
and	O
geometry	O
,	O
camera	B
optics	O
,	O
and	O
sensor	B
properties	O
(	O
figure	O
2.14	O
)	O
?	O
in	O
this	O
section	O
,	O
we	O
develop	O
a	O
set	O
of	O
models	O
to	O
describe	O
these	O
interactions	O
and	O
formulate	O
a	O
generative	O
process	O
of	O
image	B
formation	O
.	O
a	O
more	O
detailed	O
treatment	O
of	O
these	O
topics	O
can	O
be	O
found	O
in	O
other	O
textbooks	B
on	O
computer	O
graphics	O
and	O
image	B
synthesis	O
(	O
glassner	O
1995	O
;	O
weyrich	O
,	O
lawrence	O
,	O
lensch	O
et	O
al	O
.	O
2008	O
;	O
foley	O
,	O
van	O
dam	O
,	O
feiner	O
et	O
al	O
.	O
1995	O
;	O
watt	O
1995	O
;	O
cohen	O
and	O
wallace	O
1993	O
;	O
sillion	O
and	O
puech	O
1994	O
)	O
.	O
2.2.1	O
lighting	B
images	O
can	O
not	O
exist	O
without	O
light	O
.	O
to	O
produce	O
an	O
image	B
,	O
the	O
scene	O
must	O
be	O
illuminated	O
with	O
one	O
or	O
more	O
light	O
sources	O
.	O
(	O
certain	O
modalities	O
such	O
as	O
ﬂuorescent	O
microscopy	O
and	O
x-ray	O
tomography	O
do	O
not	O
ﬁt	O
this	O
model	O
,	O
but	O
we	O
do	O
not	O
deal	O
with	O
them	O
in	O
this	O
book	O
.	O
)	O
light	O
sources	O
can	O
generally	O
be	O
divided	O
into	O
point	O
and	O
area	O
light	O
sources	O
.	O
a	O
point	O
light	O
source	O
originates	O
at	O
a	O
single	O
location	O
in	O
space	O
(	O
e.g.	O
,	O
a	O
small	O
light	O
bulb	O
)	O
,	O
potentially	O
at	O
inﬁnity	O
(	O
e.g.	O
,	O
the	O
sun	O
)	O
.	O
(	O
note	O
that	O
for	O
some	O
applications	O
such	O
as	O
modeling	B
soft	O
shadows	O
(	O
penumbras	O
)	O
,	O
the	O
sun	O
may	O
have	O
to	O
be	O
treated	O
as	O
an	O
area	O
light	O
source	O
.	O
)	O
in	O
addition	O
to	O
its	O
location	O
,	O
a	O
point	O
light	O
source	O
has	O
an	O
intensity	O
and	O
a	O
color	B
spectrum	O
,	O
i.e.	O
,	O
a	O
distribution	O
over	O
2.2	O
photometric	B
image	O
formation	O
61	O
figure	O
2.14	O
a	O
simpliﬁed	O
model	O
of	O
photometric	B
image	O
formation	O
.	O
light	O
is	O
emitted	O
by	O
one	O
or	O
more	O
light	O
sources	O
and	O
is	O
then	O
reﬂected	O
from	O
an	O
object	O
’	O
s	O
surface	B
.	O
a	O
portion	O
of	O
this	O
light	O
is	O
directed	O
towards	O
the	O
camera	B
.	O
this	O
simpliﬁed	O
model	O
ignores	O
multiple	B
reﬂections	O
,	O
which	O
often	O
occur	O
in	O
real-world	O
scenes	O
.	O
wavelengths	O
l	O
(	O
λ	O
)	O
.	O
the	O
intensity	O
of	O
a	O
light	O
source	O
falls	O
off	O
with	O
the	O
square	O
of	O
the	O
distance	O
between	O
the	O
source	O
and	O
the	O
object	O
being	O
lit	O
,	O
because	O
the	O
same	O
light	O
is	O
being	O
spread	O
over	O
a	O
larger	O
(	O
spherical	B
)	O
area	O
.	O
a	O
light	O
source	O
may	O
also	O
have	O
a	O
directional	O
falloff	O
(	O
dependence	O
)	O
,	O
but	O
we	O
ignore	O
this	O
in	O
our	O
simpliﬁed	O
model	O
.	O
area	O
light	O
sources	O
are	O
more	O
complicated	O
.	O
a	O
simple	O
area	O
light	O
source	O
such	O
as	O
a	O
ﬂuorescent	O
ceiling	O
light	O
ﬁxture	O
with	O
a	O
diffuser	O
can	O
be	O
modeled	O
as	O
a	O
ﬁnite	O
rectangular	O
area	O
emitting	O
light	O
equally	O
in	O
all	O
directions	O
(	O
cohen	O
and	O
wallace	O
1993	O
;	O
sillion	O
and	O
puech	O
1994	O
;	O
glassner	O
1995	O
)	O
.	O
when	O
the	O
distribution	O
is	O
strongly	O
directional	O
,	O
a	O
four-dimensional	O
lightﬁeld	O
can	O
be	O
used	O
instead	O
(	O
ashdown	O
1993	O
)	O
.	O
a	O
more	O
complex	O
light	O
distribution	O
that	O
approximates	O
,	O
say	O
,	O
the	O
incident	O
illumination	O
on	O
an	O
object	O
sitting	O
in	O
an	O
outdoor	O
courtyard	O
,	O
can	O
often	O
be	O
represented	O
using	O
an	O
environment	O
map	O
(	O
greene	O
1986	O
)	O
(	O
originally	O
called	O
a	O
reﬂection	O
map	O
(	O
blinn	O
and	O
newell	O
1976	O
)	O
)	O
.	O
this	O
representa-	O
tion	B
maps	O
incident	O
light	O
directions	O
ˆv	O
to	O
color	B
values	O
(	O
or	O
wavelengths	O
,	O
λ	O
)	O
,	O
l	O
(	O
ˆv	O
;	O
λ	O
)	O
,	O
(	O
2.80	O
)	O
and	O
is	O
equivalent	O
to	O
assuming	O
that	O
all	O
light	O
sources	O
are	O
at	O
inﬁnity	O
.	O
environment	O
maps	O
can	O
be	O
represented	O
as	O
a	O
collection	O
of	O
cubical	O
faces	B
(	O
greene	O
1986	O
)	O
,	O
as	O
a	O
single	O
longitude–latitude	O
map	O
(	O
blinn	O
and	O
newell	O
1976	O
)	O
,	O
or	O
as	O
the	O
image	B
of	O
a	O
reﬂecting	O
sphere	O
(	O
watt	O
1995	O
)	O
.	O
a	O
convenient	O
way	O
to	O
get	O
a	O
rough	O
model	O
of	O
a	O
real-world	O
environment	O
map	O
is	O
to	O
take	O
an	O
image	B
of	O
a	O
reﬂective	O
mirrored	O
sphere	O
and	O
to	O
unwrap	O
this	O
image	B
onto	O
the	O
desired	O
environment	O
map	O
(	O
debevec	O
1998	O
)	O
.	O
watt	O
(	O
1995	O
)	O
gives	O
a	O
nice	O
discussion	O
of	O
environment	O
mapping	O
,	O
including	O
the	O
formulas	O
needed	O
to	O
map	O
directions	O
to	O
pixels	O
for	O
the	O
three	O
most	O
commonly	O
used	O
representations	O
.	O
n^surfacelight	O
sourceimage	O
planesensor	O
planeoptics	O
62	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
a	O
)	O
light	O
scatters	O
when	O
it	O
hits	O
a	O
surface	B
.	O
figure	O
2.15	O
(	O
b	O
)	O
the	O
bidirectional	O
reﬂectance	B
distribution	O
function	O
(	O
brdf	O
)	O
f	O
(	O
θi	O
,	O
φi	O
,	O
θr	O
,	O
φr	O
)	O
is	O
parameterized	O
by	O
the	O
angles	O
that	O
the	O
inci-	O
dent	O
,	O
ˆvi	O
,	O
and	O
reﬂected	O
,	O
ˆvr	O
,	O
light	O
ray	O
directions	O
make	O
with	O
the	O
local	B
surface	O
coordinate	O
frame	O
(	O
ˆdx	O
,	O
ˆdy	O
,	O
ˆn	O
)	O
.	O
2.2.2	O
reﬂectance	B
and	O
shading	B
when	O
light	O
hits	O
an	O
object	O
’	O
s	O
surface	B
,	O
it	O
is	O
scattered	O
and	O
reﬂected	O
(	O
figure	O
2.15a	O
)	O
.	O
many	O
different	O
models	O
have	O
been	O
developed	O
to	O
describe	O
this	O
interaction	O
.	O
in	O
this	O
section	O
,	O
we	O
ﬁrst	O
describe	O
the	O
most	O
general	O
form	O
,	O
the	O
bidirectional	O
reﬂectance	B
distribution	O
function	O
,	O
and	O
then	O
look	O
at	O
some	O
more	O
specialized	O
models	O
,	O
including	O
the	O
diffuse	B
,	O
specular	B
,	O
and	O
phong	O
shading	B
models	O
.	O
we	O
also	O
discuss	O
how	O
these	O
models	O
can	O
be	O
used	O
to	O
compute	O
the	O
global	B
illumination	I
corresponding	O
to	O
a	O
scene	O
.	O
the	O
bidirectional	O
reﬂectance	B
distribution	O
function	O
(	O
brdf	O
)	O
the	O
most	O
general	O
model	O
of	O
light	O
scattering	O
is	O
the	O
bidirectional	O
reﬂectance	B
distribution	O
func-	O
tion	B
(	O
brdf	O
)	O
.5	O
relative	O
to	O
some	O
local	B
coordinate	O
frame	O
on	O
the	O
surface	B
,	O
the	O
brdf	O
is	O
a	O
four-	O
dimensional	O
function	O
that	O
describes	O
how	O
much	O
of	O
each	O
wavelength	O
arriving	O
at	O
an	O
incident	O
direction	O
ˆvi	O
is	O
emitted	O
in	O
a	O
reﬂected	O
direction	O
ˆvr	O
(	O
figure	O
2.15b	O
)	O
.	O
the	O
function	O
can	O
be	O
written	O
in	O
terms	O
of	O
the	O
angles	O
of	O
the	O
incident	O
and	O
reﬂected	O
directions	O
relative	O
to	O
the	O
surface	B
frame	O
as	O
fr	O
(	O
θi	O
,	O
φi	O
,	O
θr	O
,	O
φr	O
;	O
λ	O
)	O
.	O
(	O
2.81	O
)	O
the	O
brdf	O
is	O
reciprocal	O
,	O
i.e.	O
,	O
because	O
of	O
the	O
physics	O
of	O
light	O
transport	O
,	O
you	O
can	O
interchange	O
the	O
roles	O
of	O
ˆvi	O
and	O
ˆvr	O
and	O
still	O
get	O
the	O
same	O
answer	O
(	O
this	O
is	O
sometimes	O
called	O
helmholtz	O
reciprocity	O
)	O
.	O
5	O
actually	O
,	O
even	O
more	O
general	O
models	O
of	O
light	O
transport	O
exist	O
,	O
including	O
some	O
that	O
model	O
spatial	O
variation	O
along	O
the	O
surface	B
,	O
sub-surface	O
scattering	O
,	O
and	O
atmospheric	O
effects—see	O
section	O
12.7.1—	O
(	O
dorsey	O
,	O
rushmeier	O
,	O
and	O
sillion	O
2007	O
;	O
weyrich	O
,	O
lawrence	O
,	O
lensch	O
et	O
al	O
.	O
2008	O
)	O
.	O
n^vidxn^vr^dy^θiφiφrθr^^	O
2.2	O
photometric	B
image	O
formation	O
63	O
most	O
surfaces	O
are	O
isotropic	B
,	O
i.e.	O
,	O
there	O
are	O
no	O
preferred	O
directions	O
on	O
the	O
surface	B
as	O
far	O
(	O
the	O
exceptions	O
are	O
anisotropic	B
surfaces	O
such	O
as	O
brushed	O
as	O
light	O
transport	O
is	O
concerned	O
.	O
(	O
scratched	O
)	O
aluminum	O
,	O
where	O
the	O
reﬂectance	B
depends	O
on	O
the	O
light	O
orientation	O
relative	O
to	O
the	O
direction	O
of	O
the	O
scratches	O
.	O
)	O
for	O
an	O
isotropic	B
material	O
,	O
we	O
can	O
simplify	O
the	O
brdf	O
to	O
fr	O
(	O
θi	O
,	O
θr	O
,	O
|φr	O
−	O
φi|	O
;	O
λ	O
)	O
or	O
fr	O
(	O
ˆvi	O
,	O
ˆvr	O
,	O
ˆn	O
;	O
λ	O
)	O
,	O
(	O
2.82	O
)	O
since	O
the	O
quantities	O
θi	O
,	O
θr	O
and	O
φr	O
−	O
φi	O
can	O
be	O
computed	O
from	O
the	O
directions	O
ˆvi	O
,	O
ˆvr	O
,	O
and	O
ˆn	O
.	O
to	O
calculate	O
the	O
amount	O
of	O
light	O
exiting	O
a	O
surface	B
point	O
p	O
in	O
a	O
direction	O
ˆvr	O
under	O
a	O
given	O
lighting	B
condition	O
,	O
we	O
integrate	O
the	O
product	O
of	O
the	O
incoming	O
light	O
li	O
(	O
ˆvi	O
;	O
λ	O
)	O
with	O
the	O
brdf	O
(	O
some	O
authors	O
call	O
this	O
step	O
a	O
convolution	O
)	O
.	O
taking	O
into	O
account	O
the	O
foreshortening	O
factor	O
cos+	O
θi	O
,	O
we	O
obtain	O
where	O
lr	O
(	O
ˆvr	O
;	O
λ	O
)	O
=	O
(	O
cid:90	O
)	O
li	O
(	O
ˆvi	O
;	O
λ	O
)	O
fr	O
(	O
ˆvi	O
,	O
ˆvr	O
,	O
ˆn	O
;	O
λ	O
)	O
cos+	O
θi	O
dˆvi	O
,	O
cos+	O
θi	O
=	O
max	O
(	O
0	O
,	O
cos	O
θi	O
)	O
.	O
(	O
2.83	O
)	O
(	O
2.84	O
)	O
if	O
the	O
light	O
sources	O
are	O
discrete	B
(	O
a	O
ﬁnite	O
number	O
of	O
point	O
light	O
sources	O
)	O
,	O
we	O
can	O
replace	O
the	O
integral	O
with	O
a	O
summation	O
,	O
lr	O
(	O
ˆvr	O
;	O
λ	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
li	O
(	O
λ	O
)	O
fr	O
(	O
ˆvi	O
,	O
ˆvr	O
,	O
ˆn	O
;	O
λ	O
)	O
cos+	O
θi	O
.	O
(	O
2.85	O
)	O
brdfs	O
for	O
a	O
given	O
surface	B
can	O
be	O
obtained	O
through	O
physical	O
modeling	B
(	O
torrance	O
and	O
sparrow	O
1967	O
;	O
cook	O
and	O
torrance	O
1982	O
;	O
glassner	O
1995	O
)	O
,	O
heuristic	O
modeling	B
(	O
phong	O
1975	O
)	O
,	O
or	O
through	O
empirical	O
observation	O
(	O
ward	O
1992	O
;	O
westin	O
,	O
arvo	O
,	O
and	O
torrance	O
1992	O
;	O
dana	O
,	O
van	O
gin-	O
neken	O
,	O
nayar	O
et	O
al	O
.	O
1999	O
;	O
dorsey	O
,	O
rushmeier	O
,	O
and	O
sillion	O
2007	O
;	O
weyrich	O
,	O
lawrence	O
,	O
lensch	O
et	O
al	O
.	O
2008	O
)	O
.6	O
typical	O
brdfs	O
can	O
often	O
be	O
split	O
into	O
their	O
diffuse	B
and	O
specular	B
components	O
,	O
as	O
described	O
below	O
.	O
diffuse	B
reﬂection	O
the	O
diffuse	B
component	O
(	O
also	O
known	O
as	O
lambertian	O
or	O
matte	O
reﬂection	O
)	O
scatters	O
light	O
uni-	O
formly	O
in	O
all	O
directions	O
and	O
is	O
the	O
phenomenon	O
we	O
most	O
normally	O
associate	O
with	O
shading	O
,	O
e.g.	O
,	O
the	O
smooth	O
(	O
non-shiny	O
)	O
variation	O
of	O
intensity	O
with	O
surface	O
normal	O
that	O
is	O
seen	O
when	O
ob-	O
serving	O
a	O
statue	O
(	O
figure	O
2.16	O
)	O
.	O
diffuse	B
reﬂection	O
also	O
often	O
imparts	O
a	O
strong	O
body	B
color	O
to	O
the	O
light	O
since	O
it	O
is	O
caused	O
by	O
selective	O
absorption	O
and	O
re-emission	O
of	O
light	O
inside	O
the	O
object	O
’	O
s	O
material	O
(	O
shafer	O
1985	O
;	O
glassner	O
1995	O
)	O
.	O
6	O
see	O
http	O
:	O
//www1.cs.columbia.edu/cave/software/curet/	O
for	O
a	O
database	O
of	O
some	O
empirically	O
sampled	O
brdfs	O
.	O
64	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.16	O
this	O
close-up	O
of	O
a	O
statue	O
shows	O
both	O
diffuse	B
(	O
smooth	O
shading	B
)	O
and	O
specular	B
(	O
shiny	O
highlight	O
)	O
reﬂection	O
,	O
as	O
well	O
as	O
darkening	O
in	O
the	O
grooves	O
and	O
creases	O
due	O
to	O
reduced	O
light	O
visibility	B
and	O
interreﬂections	O
.	O
(	O
photo	O
courtesy	O
of	O
the	O
caltech	O
vision	O
lab	O
,	O
http	O
:	O
//www	O
.	O
vision.caltech.edu/archive.html	O
.	O
)	O
while	O
light	O
is	O
scattered	O
uniformly	O
in	O
all	O
directions	O
,	O
i.e.	O
,	O
the	O
brdf	O
is	O
constant	O
,	O
fd	O
(	O
ˆvi	O
,	O
ˆvr	O
,	O
ˆn	O
;	O
λ	O
)	O
=	O
fd	O
(	O
λ	O
)	O
,	O
(	O
2.86	O
)	O
the	O
amount	O
of	O
light	O
depends	O
on	O
the	O
angle	O
between	O
the	O
incident	O
light	O
direction	O
and	O
the	O
surface	B
normal	O
θi	O
.	O
this	O
is	O
because	O
the	O
surface	B
area	O
exposed	O
to	O
a	O
given	O
amount	O
of	O
light	O
becomes	O
larger	O
at	O
oblique	O
angles	O
,	O
becoming	O
completely	O
self-shadowed	O
as	O
the	O
outgoing	O
surface	B
normal	O
points	B
away	O
from	O
the	O
light	O
(	O
figure	O
2.17a	O
)	O
.	O
(	O
think	O
about	O
how	O
you	O
orient	O
yourself	O
towards	O
the	O
sun	O
or	O
ﬁreplace	O
to	O
get	O
maximum	O
warmth	O
and	O
how	O
a	O
ﬂashlight	O
projected	O
obliquely	O
against	O
a	O
wall	O
is	O
less	O
bright	O
than	O
one	O
pointing	O
directly	O
at	O
it	O
.	O
)	O
the	O
shading	B
equation	O
for	O
diffuse	O
reﬂection	O
can	O
thus	O
be	O
written	O
as	O
ld	O
(	O
ˆvr	O
;	O
λ	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
where	O
specular	B
reﬂection	O
li	O
(	O
λ	O
)	O
fd	O
(	O
λ	O
)	O
[	O
ˆvi	O
·	O
ˆn	O
]	O
+	O
,	O
li	O
(	O
λ	O
)	O
fd	O
(	O
λ	O
)	O
cos+	O
θi	O
=	O
(	O
cid:88	O
)	O
i	O
[	O
ˆvi	O
·	O
ˆn	O
]	O
+	O
=	O
max	O
(	O
0	O
,	O
ˆvi	O
·	O
ˆn	O
)	O
.	O
(	O
2.87	O
)	O
(	O
2.88	O
)	O
the	O
second	O
major	O
component	O
of	O
a	O
typical	O
brdf	O
is	O
specular	B
(	O
gloss	O
or	O
highlight	O
)	O
reﬂection	O
,	O
which	O
depends	O
strongly	O
on	O
the	O
direction	O
of	O
the	O
outgoing	O
light	O
.	O
consider	O
light	O
reﬂecting	O
off	O
a	O
mirrored	O
surface	B
(	O
figure	O
2.17b	O
)	O
.	O
incident	O
light	O
rays	O
are	O
reﬂected	O
in	O
a	O
direction	O
that	O
is	O
rotated	O
by	O
180◦	O
around	O
the	O
surface	B
normal	O
ˆn	O
.	O
using	O
the	O
same	O
notation	O
as	O
in	O
equations	B
(	O
2.29–2.30	O
)	O
,	O
2.2	O
photometric	B
image	O
formation	O
65	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
2.17	O
(	O
a	O
)	O
the	O
diminution	O
of	O
returned	O
light	O
caused	O
by	O
foreshortening	O
depends	O
on	O
ˆvi·	O
ˆn	O
,	O
the	O
cosine	O
of	O
the	O
angle	O
between	O
the	O
incident	O
light	O
direction	O
ˆvi	O
and	O
the	O
surface	B
normal	O
ˆn	O
.	O
(	O
b	O
)	O
mirror	O
(	O
specular	B
)	O
reﬂection	O
:	O
the	O
incident	O
light	O
ray	O
direction	O
ˆvi	O
is	O
reﬂected	O
onto	O
the	O
specular	B
direction	O
ˆsi	O
around	O
the	O
surface	B
normal	O
ˆn	O
.	O
we	O
can	O
compute	O
the	O
specular	B
reﬂection	O
direction	O
ˆsi	O
as	O
ˆsi	O
=	O
v	O
(	O
cid:107	O
)	O
−	O
v⊥	O
=	O
(	O
2ˆnˆnt	O
−	O
i	O
)	O
vi	O
.	O
(	O
2.89	O
)	O
the	O
amount	O
of	O
light	O
reﬂected	O
in	O
a	O
given	O
direction	O
ˆvr	O
thus	O
depends	O
on	O
the	O
angle	O
θs	O
=	O
cos−1	O
(	O
ˆvr	O
·	O
ˆsi	O
)	O
between	O
the	O
view	O
direction	O
ˆvr	O
and	O
the	O
specular	B
direction	O
ˆsi	O
.	O
for	O
example	O
,	O
the	O
phong	O
(	O
1975	O
)	O
model	O
uses	O
a	O
power	O
of	O
the	O
cosine	O
of	O
the	O
angle	O
,	O
fs	O
(	O
θs	O
;	O
λ	O
)	O
=	O
ks	O
(	O
λ	O
)	O
coske	O
θs	O
,	O
while	O
the	O
torrance	O
and	O
sparrow	O
(	O
1967	O
)	O
micro-facet	O
model	O
uses	O
a	O
gaussian	O
,	O
fs	O
(	O
θs	O
;	O
λ	O
)	O
=	O
ks	O
(	O
λ	O
)	O
exp	O
(	O
−c2	O
sθ2	O
s	O
)	O
.	O
(	O
2.90	O
)	O
(	O
2.91	O
)	O
larger	O
exponents	O
ke	O
(	O
or	O
inverse	B
gaussian	O
widths	O
cs	O
)	O
correspond	O
to	O
more	O
specular	B
surfaces	O
with	O
distinct	O
highlights	O
,	O
while	O
smaller	O
exponents	O
better	O
model	O
materials	O
with	O
softer	O
gloss	O
.	O
phong	O
shading	B
phong	O
(	O
1975	O
)	O
combined	O
the	O
diffuse	B
and	O
specular	B
components	O
of	O
reﬂection	O
with	O
another	O
term	O
,	O
which	O
he	O
called	O
the	O
ambient	O
illumination	O
.	O
this	O
term	O
accounts	O
for	O
the	O
fact	O
that	O
objects	O
are	O
generally	O
illuminated	O
not	O
only	O
by	O
point	O
light	O
sources	O
but	O
also	O
by	O
a	O
general	O
diffuse	B
illumination	O
corresponding	O
to	O
inter-reﬂection	O
(	O
e.g.	O
,	O
the	O
walls	O
in	O
a	O
room	O
)	O
or	O
distant	O
sources	O
,	O
such	O
as	O
the	O
vi•n	O
=	O
1^	O
^0	O
<	O
vi•n	O
<	O
1^	O
^vi•n	O
<	O
0^	O
^vi•n	O
=	O
0^	O
^viv┴n^v║-v┴si180°v║^^	O
66	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
2.18	O
cross-section	O
through	O
a	O
phong	O
shading	B
model	O
brdf	O
for	O
a	O
ﬁxed	O
incident	O
illu-	O
mination	O
direction	O
:	O
(	O
a	O
)	O
component	O
values	O
as	O
a	O
function	O
of	O
angle	O
away	O
from	O
surface	B
normal	O
;	O
(	O
b	O
)	O
polar	O
plot	O
.	O
the	O
value	O
of	O
the	O
phong	O
exponent	O
ke	O
is	O
indicated	O
by	O
the	O
“	O
exp	O
”	O
labels	O
and	O
the	O
light	O
source	O
is	O
at	O
an	O
angle	O
of	O
30◦	O
away	O
from	O
the	O
normal	O
.	O
blue	O
sky	O
.	O
in	O
the	O
phong	O
model	O
,	O
the	O
ambient	O
term	O
does	O
not	O
depend	O
on	O
surface	B
orientation	O
,	O
but	O
depends	O
on	O
the	O
color	B
of	O
both	O
the	O
ambient	O
illumination	O
la	O
(	O
λ	O
)	O
and	O
the	O
object	O
ka	O
(	O
λ	O
)	O
,	O
fa	O
(	O
λ	O
)	O
=	O
ka	O
(	O
λ	O
)	O
la	O
(	O
λ	O
)	O
.	O
(	O
2.92	O
)	O
putting	O
all	O
of	O
these	O
terms	O
together	O
,	O
we	O
arrive	O
at	O
the	O
phong	O
shading	B
model	O
,	O
lr	O
(	O
ˆvr	O
;	O
λ	O
)	O
=	O
ka	O
(	O
λ	O
)	O
la	O
(	O
λ	O
)	O
+	O
kd	O
(	O
λ	O
)	O
(	O
cid:88	O
)	O
i	O
li	O
(	O
λ	O
)	O
(	O
ˆvr	O
·	O
ˆsi	O
)	O
ke	O
.	O
(	O
2.93	O
)	O
figure	O
2.18	O
shows	O
a	O
typical	O
set	O
of	O
phong	O
shading	B
model	O
components	O
as	O
a	O
function	O
of	O
the	O
angle	O
away	O
from	O
the	O
surface	B
normal	O
(	O
in	O
a	O
plane	O
containing	O
both	O
the	O
lighting	B
direction	O
and	O
the	O
viewer	O
)	O
.	O
li	O
(	O
λ	O
)	O
[	O
ˆvi	O
·	O
ˆn	O
]	O
+	O
+	O
ks	O
(	O
λ	O
)	O
(	O
cid:88	O
)	O
i	O
typically	O
,	O
the	O
ambient	O
and	O
diffuse	B
reﬂection	O
color	B
distributions	O
ka	O
(	O
λ	O
)	O
and	O
kd	O
(	O
λ	O
)	O
are	O
the	O
same	O
,	O
since	O
they	O
are	O
both	O
due	O
to	O
sub-surface	O
scattering	O
(	O
body	B
reﬂection	O
)	O
inside	O
the	O
surface	B
material	O
(	O
shafer	O
1985	O
)	O
.	O
the	O
specular	B
reﬂection	O
distribution	O
ks	O
(	O
λ	O
)	O
is	O
often	O
uniform	O
(	O
white	O
)	O
,	O
since	O
it	O
is	O
caused	O
by	O
interface	O
reﬂections	B
that	O
do	O
not	O
change	O
the	O
light	O
color	O
.	O
(	O
the	O
exception	O
to	O
this	O
are	O
metallic	O
materials	O
,	O
such	O
as	O
copper	O
,	O
as	O
opposed	O
to	O
the	O
more	O
common	O
dielectric	O
materials	O
,	O
such	O
as	O
plastics	O
.	O
)	O
the	O
ambient	O
illumination	O
la	O
(	O
λ	O
)	O
often	O
has	O
a	O
different	O
color	B
cast	O
from	O
the	O
direct	B
light	O
sources	O
li	O
(	O
λ	O
)	O
,	O
e.g.	O
,	O
it	O
may	O
be	O
blue	O
for	O
a	O
sunny	O
outdoor	O
scene	O
or	O
yellow	O
for	O
an	O
interior	O
lit	O
with	O
candles	O
or	O
incandescent	O
lights	O
.	O
(	O
the	O
presence	O
of	O
ambient	O
sky	O
illumination	O
in	O
shadowed	O
areas	O
is	O
what	O
often	O
causes	O
shadows	O
to	O
appear	O
bluer	O
than	O
the	O
corresponding	O
lit	O
portions	O
of	O
a	O
scene	O
)	O
.	O
note	O
also	O
that	O
the	O
diffuse	B
component	O
of	O
the	O
phong	O
model	O
(	O
or	O
of	O
any	O
shading	B
model	O
)	O
depends	O
on	O
the	O
angle	O
of	O
the	O
incoming	O
light	O
source	O
ˆvi	O
,	O
while	O
the	O
specular	B
component	O
depends	O
on	O
the	O
relative	O
angle	O
between	O
the	O
viewer	O
vr	O
and	O
the	O
specular	B
reﬂection	O
direction	O
ˆsi	O
(	O
which	O
itself	O
depends	O
on	O
the	O
incoming	O
light	O
direction	O
ˆvi	O
and	O
the	O
surface	B
normal	O
ˆn	O
)	O
.	O
0.00.10.20.30.40.5-90-80-70-60-50-40-30-20-100102030405060708090ambientdiffuseexp=10exp=100exp=10000.00.10.20.30.40.5-0.5-0.4-0.3-0.2-0.10.00.10.20.30.40.5ambientdiffuseexp=10exp=100exp=1000	O
2.2	O
photometric	B
image	O
formation	O
67	O
the	O
phong	O
shading	B
model	O
has	O
been	O
superseded	O
in	O
terms	O
of	O
physical	O
accuracy	B
by	O
a	O
number	O
of	O
more	O
recently	O
developed	O
models	O
in	O
computer	O
graphics	O
,	O
including	O
the	O
model	O
developed	O
by	O
cook	O
and	O
torrance	O
(	O
1982	O
)	O
based	O
on	O
the	O
original	O
micro-facet	O
model	O
of	O
torrance	O
and	O
sparrow	O
(	O
1967	O
)	O
.	O
until	O
recently	O
,	O
most	O
computer	O
graphics	O
hardware	O
implemented	O
the	O
phong	O
model	O
but	O
the	O
recent	O
advent	O
of	O
programmable	O
pixel	O
shaders	O
makes	O
the	O
use	O
of	O
more	O
complex	O
models	O
feasible	O
.	O
di-chromatic	B
reﬂection	O
model	O
the	O
torrance	O
and	O
sparrow	O
(	O
1967	O
)	O
model	O
of	O
reﬂection	O
also	O
forms	O
the	O
basis	O
of	O
shafer	O
’	O
s	O
(	O
1985	O
)	O
di-chromatic	B
reﬂection	O
model	O
,	O
which	O
states	O
that	O
the	O
apparent	O
color	B
of	O
a	O
uniform	O
material	O
lit	O
from	O
a	O
single	O
source	O
depends	O
on	O
the	O
sum	O
of	O
two	O
terms	O
,	O
lr	O
(	O
ˆvr	O
;	O
λ	O
)	O
=	O
li	O
(	O
ˆvr	O
,	O
ˆvi	O
,	O
ˆn	O
;	O
λ	O
)	O
+	O
lb	O
(	O
ˆvr	O
,	O
ˆvi	O
,	O
ˆn	O
;	O
λ	O
)	O
=	O
ci	O
(	O
λ	O
)	O
mi	O
(	O
ˆvr	O
,	O
ˆvi	O
,	O
ˆn	O
)	O
+	O
cb	O
(	O
λ	O
)	O
mb	O
(	O
ˆvr	O
,	O
ˆvi	O
,	O
ˆn	O
)	O
,	O
(	O
2.94	O
)	O
(	O
2.95	O
)	O
i.e.	O
,	O
the	O
radiance	O
of	O
the	O
light	O
reﬂected	O
at	O
the	O
interface	O
,	O
li	O
,	O
and	O
the	O
radiance	O
reﬂected	O
at	O
the	O
sur-	O
face	B
body	O
,	O
lb	O
.	O
each	O
of	O
these	O
,	O
in	O
turn	O
,	O
is	O
a	O
simple	O
product	O
between	O
a	O
relative	O
power	B
spectrum	I
c	O
(	O
λ	O
)	O
,	O
which	O
depends	O
only	O
on	O
wavelength	O
,	O
and	O
a	O
magnitude	O
m	O
(	O
ˆvr	O
,	O
ˆvi	O
,	O
ˆn	O
)	O
,	O
which	O
depends	O
only	O
on	O
geometry	O
.	O
(	O
this	O
model	O
can	O
easily	O
be	O
derived	O
from	O
a	O
generalized	B
version	O
of	O
phong	O
’	O
s	O
model	O
by	O
assuming	O
a	O
single	O
light	O
source	O
and	O
no	O
ambient	O
illumination	O
,	O
and	O
re-arranging	O
terms	O
.	O
)	O
the	O
di-chromatic	B
model	O
has	O
been	O
successfully	O
used	O
in	O
computer	O
vision	O
to	O
segment	O
specular	B
col-	O
ored	O
objects	O
with	O
large	O
variations	O
in	O
shading	B
(	O
klinker	O
1993	O
)	O
and	O
more	O
recently	O
has	O
inspired	O
local	B
two-color	O
models	O
for	O
applications	O
such	O
bayer	O
pattern	O
demosaicing	B
(	O
bennett	O
,	O
uytten-	O
daele	O
,	O
zitnick	O
et	O
al	O
.	O
2006	O
)	O
.	O
global	B
illumination	I
(	O
ray	O
tracing	O
and	O
radiosity	B
)	O
the	O
simple	O
shading	B
model	O
presented	O
thus	O
far	O
assumes	O
that	O
light	O
rays	O
leave	O
the	O
light	O
sources	O
,	O
bounce	O
off	O
surfaces	O
visible	O
to	O
the	O
camera	B
,	O
thereby	O
changing	O
in	O
intensity	O
or	O
color	B
,	O
and	O
arrive	O
at	O
the	O
camera	B
.	O
in	O
reality	O
,	O
light	O
sources	O
can	O
be	O
shadowed	O
by	O
occluders	O
and	O
rays	O
can	O
bounce	O
multiple	B
times	O
around	O
a	O
scene	O
while	O
making	O
their	O
trip	O
from	O
a	O
light	O
source	O
to	O
the	O
camera	B
.	O
two	O
methods	O
have	O
traditionally	O
been	O
used	O
to	O
model	O
such	O
effects	O
.	O
if	O
the	O
scene	O
is	O
mostly	O
specular	B
(	O
the	O
classic	O
example	O
being	O
scenes	O
made	O
of	O
glass	O
objects	O
and	O
mirrored	O
or	O
highly	O
pol-	O
ished	O
balls	O
)	O
,	O
the	O
preferred	O
approach	O
is	O
ray	O
tracing	O
or	O
path	O
tracing	O
(	O
glassner	O
1995	O
;	O
akenine-	O
m¨oller	O
and	O
haines	O
2002	O
;	O
shirley	O
2005	O
)	O
,	O
which	O
follows	O
individual	O
rays	O
from	O
the	O
camera	B
across	O
multiple	B
bounces	O
towards	O
the	O
light	O
sources	O
(	O
or	O
vice	O
versa	O
)	O
.	O
if	O
the	O
scene	O
is	O
composed	O
mostly	O
of	O
uniform	O
albedo	O
simple	O
geometry	O
illuminators	O
and	O
surfaces	O
,	O
radiosity	B
(	O
global	B
illumination	I
)	O
techniques	O
are	O
preferred	O
(	O
cohen	O
and	O
wallace	O
1993	O
;	O
sillion	O
and	O
puech	O
1994	O
;	O
glassner	O
1995	O
)	O
.	O
68	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
combinations	O
of	O
the	O
two	O
techniques	O
have	O
also	O
been	O
developed	O
(	O
wallace	O
,	O
cohen	O
,	O
and	O
green-	O
berg	O
1987	O
)	O
,	O
as	O
well	O
as	O
more	O
general	O
light	O
transport	O
techniques	O
for	O
simulating	O
effects	O
such	O
as	O
the	O
caustics	O
cast	O
by	O
rippling	O
water	O
.	O
the	O
basic	O
ray	O
tracing	O
algorithm	B
associates	O
a	O
light	O
ray	O
with	O
each	O
pixel	O
in	O
the	O
camera	B
im-	O
age	O
and	O
ﬁnds	O
its	O
intersection	O
with	O
the	O
nearest	O
surface	O
.	O
a	O
primary	O
contribution	O
can	O
then	O
be	O
computed	O
using	O
the	O
simple	O
shading	B
equations	O
presented	O
previously	O
(	O
e.g.	O
,	O
equation	B
(	O
2.93	O
)	O
)	O
for	O
all	O
light	O
sources	O
that	O
are	O
visible	O
for	O
that	O
surface	B
element	O
.	O
(	O
an	O
alternative	O
technique	O
for	O
computing	O
which	O
surfaces	O
are	O
illuminated	O
by	O
a	O
light	O
source	O
is	O
to	O
compute	O
a	O
shadow	B
map	O
,	O
or	O
shadow	B
buffer	O
,	O
i.e.	O
,	O
a	O
rendering	B
of	O
the	O
scene	O
from	O
the	O
light	O
source	O
’	O
s	O
perspective	B
,	O
and	O
then	O
compare	O
the	O
depth	O
of	O
pixels	O
being	O
rendered	O
with	O
the	O
map	O
(	O
williams	O
1983	O
;	O
akenine-m¨oller	O
and	O
haines	O
2002	O
)	O
.	O
)	O
additional	O
secondary	O
rays	O
can	O
then	O
be	O
cast	O
along	O
the	O
specular	B
direction	O
towards	O
other	O
objects	O
in	O
the	O
scene	O
,	O
keeping	O
track	O
of	O
any	O
attenuation	O
or	O
color	B
change	O
that	O
the	O
specular	B
reﬂection	O
induces	O
.	O
radiosity	B
works	O
by	O
associating	O
lightness	O
values	O
with	O
rectangular	O
surface	B
areas	O
in	O
the	O
scene	O
(	O
including	O
area	O
light	O
sources	O
)	O
.	O
the	O
amount	O
of	O
light	O
interchanged	O
between	O
any	O
two	O
(	O
mutually	O
visible	O
)	O
areas	O
in	O
the	O
scene	O
can	O
be	O
captured	O
as	O
a	O
form	O
factor	O
,	O
which	O
depends	O
on	O
their	O
relative	O
orientation	O
and	O
surface	B
reﬂectance	O
properties	B
,	O
as	O
well	O
as	O
the	O
1/r2	O
fall-off	O
as	O
light	O
is	O
distributed	O
over	O
a	O
larger	O
effective	O
sphere	O
the	O
further	O
away	O
it	O
is	O
(	O
cohen	O
and	O
wallace	O
1993	O
;	O
sillion	O
and	O
puech	O
1994	O
;	O
glassner	O
1995	O
)	O
.	O
a	O
large	O
linear	O
system	O
can	O
then	O
be	O
set	O
up	O
to	O
solve	O
for	O
the	O
ﬁnal	O
lightness	O
of	O
each	O
area	O
patch	O
,	O
using	O
the	O
light	O
sources	O
as	O
the	O
forcing	O
function	O
(	O
right	O
hand	O
side	O
)	O
.	O
once	O
the	O
system	O
has	O
been	O
solved	O
,	O
the	O
scene	O
can	O
be	O
rendered	O
from	O
any	O
desired	O
point	O
of	O
view	O
.	O
under	O
certain	O
circumstances	O
,	O
it	O
is	O
possible	O
to	O
recover	O
the	O
global	B
illumination	I
in	O
a	O
scene	O
from	O
photographs	O
using	O
computer	O
vision	O
techniques	O
(	O
yu	O
,	O
debevec	O
,	O
malik	O
et	O
al	O
.	O
1999	O
)	O
.	O
the	O
basic	O
radiosity	B
algorithm	O
does	O
not	O
take	O
into	O
account	O
certain	O
near	O
ﬁeld	O
effects	O
,	O
such	O
as	O
the	O
darkening	O
inside	O
corners	O
and	O
scratches	O
,	O
or	O
the	O
limited	O
ambient	O
illumination	O
caused	O
by	O
partial	O
shadowing	O
from	O
other	O
surfaces	O
.	O
such	O
effects	O
have	O
been	O
exploited	O
in	O
a	O
number	O
of	O
computer	O
vision	O
algorithms	O
(	O
nayar	O
,	O
ikeuchi	O
,	O
and	O
kanade	O
1991	O
;	O
langer	O
and	O
zucker	O
1994	O
)	O
.	O
while	O
all	O
of	O
these	O
global	B
illumination	I
effects	O
can	O
have	O
a	O
strong	O
effect	O
on	O
the	O
appearance	O
of	O
a	O
scene	O
,	O
and	O
hence	O
its	O
3d	O
interpretation	O
,	O
they	O
are	O
not	O
covered	O
in	O
more	O
detail	O
in	O
this	O
book	O
.	O
(	O
but	O
see	O
section	O
12.7.1	O
for	O
a	O
discussion	O
of	O
recovering	O
brdfs	O
from	O
real	O
scenes	O
and	O
objects	O
.	O
)	O
2.2.3	O
optics	B
once	O
the	O
light	O
from	O
a	O
scene	O
reaches	O
the	O
camera	B
,	O
it	O
must	O
still	O
pass	O
through	O
the	O
lens	O
before	O
reaching	O
the	O
sensor	B
(	O
analog	O
ﬁlm	O
or	O
digital	O
silicon	O
)	O
.	O
for	O
many	O
applications	O
,	O
it	O
sufﬁces	O
to	O
treat	O
the	O
lens	O
as	O
an	O
ideal	O
pinhole	O
that	O
simply	O
projects	O
all	O
rays	O
through	O
a	O
common	O
center	O
of	O
projection	O
(	O
figures	O
2.8	O
and	O
2.9	O
)	O
.	O
however	O
,	O
if	O
we	O
want	O
to	O
deal	O
with	O
issues	O
such	O
as	O
focus	B
,	O
exposure	O
,	O
vignetting	B
,	O
and	O
aber-	O
2.2	O
photometric	B
image	O
formation	O
69	O
figure	O
2.19	O
a	O
thin	B
lens	O
of	O
focal	O
length	O
f	O
focuses	O
the	O
light	O
from	O
a	O
plane	O
a	O
distance	O
zo	O
in	O
front	O
of	O
the	O
lens	O
at	O
a	O
distance	O
zi	O
behind	O
the	O
lens	O
,	O
where	O
1	O
f	O
.	O
if	O
the	O
focal	O
plane	O
(	O
vertical	O
zo	O
gray	O
line	O
next	O
to	O
c	O
)	O
is	O
moved	O
forward	B
,	O
the	O
images	O
are	O
no	O
longer	O
in	O
focus	B
and	O
the	O
circle	O
of	O
confusion	O
c	O
(	O
small	O
thick	O
line	O
segments	O
)	O
depends	O
on	O
the	O
distance	O
of	O
the	O
image	B
plane	O
motion	B
∆zi	O
relative	O
to	O
the	O
lens	O
aperture	O
diameter	O
d.	O
the	O
ﬁeld	O
of	O
view	O
(	O
f.o.v	O
.	O
)	O
depends	O
on	O
the	O
ratio	O
between	O
the	O
sensor	B
width	O
w	O
and	O
the	O
focal	O
length	O
f	O
(	O
or	O
,	O
more	O
precisely	O
,	O
the	O
focusing	O
distance	O
zi	O
,	O
which	O
is	O
usually	O
quite	O
close	O
to	O
f	O
)	O
.	O
+	O
1	O
zi	O
=	O
1	O
ration	O
,	O
we	O
need	O
to	O
develop	O
a	O
more	O
sophisticated	O
model	O
,	O
which	O
is	O
where	O
the	O
study	O
of	O
optics	B
comes	O
in	O
(	O
m¨oller	O
1988	O
;	O
hecht	O
2001	O
;	O
ray	O
2002	O
)	O
.	O
figure	O
2.19	O
shows	O
a	O
diagram	O
of	O
the	O
most	O
basic	O
lens	O
model	O
,	O
i.e.	O
,	O
the	O
thin	B
lens	O
composed	O
of	O
a	O
single	O
piece	O
of	O
glass	O
with	O
very	O
low	O
,	O
equal	O
curvature	O
on	O
both	O
sides	O
.	O
according	O
to	O
the	O
lens	O
law	O
(	O
which	O
can	O
be	O
derived	O
using	O
simple	O
geometric	B
arguments	O
on	O
light	O
ray	O
refraction	O
)	O
,	O
the	O
relationship	O
between	O
the	O
distance	O
to	O
an	O
object	O
zo	O
and	O
the	O
distance	O
behind	O
the	O
lens	O
at	O
which	O
a	O
focused	O
image	B
is	O
formed	O
zi	O
can	O
be	O
expressed	O
as	O
1	O
zi	O
(	O
2.96	O
)	O
1	O
zo	O
+	O
=	O
1	O
f	O
,	O
where	O
f	O
is	O
called	O
the	O
focal	O
length	O
of	O
the	O
lens	O
.	O
if	O
we	O
let	O
zo	O
→	O
∞	O
,	O
i.e.	O
,	O
we	O
adjust	O
the	O
lens	O
(	O
move	O
the	O
image	B
plane	O
)	O
so	O
that	O
objects	O
at	O
inﬁnity	O
are	O
in	O
focus	B
,	O
we	O
get	O
zi	O
=	O
f	O
,	O
which	O
is	O
why	O
we	O
can	O
think	O
of	O
a	O
lens	O
of	O
focal	O
length	O
f	O
as	O
being	O
equivalent	O
(	O
to	O
a	O
ﬁrst	O
approximation	O
)	O
to	O
a	O
pinhole	O
a	O
distance	O
f	O
from	O
the	O
focal	O
plane	O
(	O
figure	O
2.10	O
)	O
,	O
whose	O
ﬁeld	O
of	O
view	O
is	O
given	O
by	O
(	O
2.60	O
)	O
.	O
if	O
the	O
focal	O
plane	O
is	O
moved	O
away	O
from	O
its	O
proper	O
in-focus	O
setting	O
of	O
zi	O
(	O
e.g.	O
,	O
by	O
twisting	O
the	O
focus	B
ring	O
on	O
the	O
lens	O
)	O
,	O
objects	O
at	O
zo	O
are	O
no	O
longer	O
in	O
focus	B
,	O
as	O
shown	O
by	O
the	O
gray	O
plane	O
in	O
figure	O
2.19.	O
the	O
amount	O
of	O
mis-focus	O
is	O
measured	O
by	O
the	O
circle	O
of	O
confusion	O
c	O
(	O
shown	O
as	O
short	O
thick	O
blue	O
line	O
segments	O
on	O
the	O
gray	O
plane	O
)	O
.7	O
the	O
equation	B
for	O
the	O
circle	O
of	O
confusion	O
can	O
be	O
derived	O
using	O
similar	O
triangles	O
;	O
it	O
depends	O
on	O
the	O
distance	O
of	O
travel	O
in	O
the	O
focal	O
plane	O
∆zi	O
relative	O
to	O
the	O
original	O
focus	B
distance	O
zi	O
and	O
the	O
diameter	O
of	O
the	O
aperture	O
d	O
(	O
see	O
exercise	O
2.4	O
)	O
.	O
7	O
if	O
the	O
aperture	O
is	O
not	O
completely	O
circular	O
,	O
e.g.	O
,	O
if	O
it	O
is	O
caused	O
by	O
a	O
hexagonal	O
diaphragm	O
,	O
it	O
is	O
sometimes	O
possible	O
to	O
see	O
this	O
effect	O
in	O
the	O
actual	O
blur	O
function	O
(	O
levin	O
,	O
fergus	O
,	O
durand	O
et	O
al	O
.	O
2007	O
;	O
joshi	O
,	O
szeliski	O
,	O
and	O
kriegman	O
2008	O
)	O
or	O
in	O
the	O
“	O
glints	O
”	O
that	O
are	O
seen	O
when	O
shooting	O
into	O
the	O
sun	O
.	O
zi=102	O
mmf=	O
100	O
mmw=35mmzo=5	O
mf.o.v.cδzipd	O
70	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
2.20	O
regular	O
and	O
zoom	O
lens	O
depth	O
of	O
ﬁeld	O
indicators	O
.	O
the	O
allowable	O
depth	O
variation	O
in	O
the	O
scene	O
that	O
limits	O
the	O
circle	O
of	O
confusion	O
to	O
an	O
accept-	O
able	O
number	O
is	O
commonly	O
called	O
the	O
depth	O
of	O
ﬁeld	O
and	O
is	O
a	O
function	O
of	O
both	O
the	O
focus	B
distance	O
and	O
the	O
aperture	O
,	O
as	O
shown	O
diagrammatically	O
by	O
many	O
lens	O
markings	O
(	O
figure	O
2.20	O
)	O
.	O
since	O
this	O
depth	O
of	O
ﬁeld	O
depends	O
on	O
the	O
aperture	O
diameter	O
d	O
,	O
we	O
also	O
have	O
to	O
know	O
how	O
this	O
varies	O
with	O
the	O
commonly	O
displayed	O
f-number	O
,	O
which	O
is	O
usually	O
denoted	O
as	O
f	O
/	O
#	O
or	O
n	O
and	O
is	O
deﬁned	O
as	O
f	O
/	O
#	O
=	O
n	O
=	O
f	O
d	O
,	O
(	O
2.97	O
)	O
where	O
the	O
focal	O
length	O
f	O
and	O
the	O
aperture	O
diameter	O
d	O
are	O
measured	O
in	O
the	O
same	O
unit	O
(	O
say	O
,	O
millimeters	O
)	O
.	O
the	O
usual	O
way	O
to	O
write	O
the	O
f-number	O
is	O
to	O
replace	O
the	O
#	O
in	O
f	O
/	O
#	O
with	O
the	O
actual	O
number	O
,	O
i.e.	O
,	O
f	O
/1.4	O
,	O
f	O
/2	O
,	O
f	O
/2.8	O
,	O
.	O
.	O
.	O
,	O
f	O
/22	O
.	O
(	O
alternatively	O
,	O
we	O
can	O
say	O
n	O
=	O
1.4	O
,	O
etc	O
.	O
)	O
an	O
easy	O
way	O
to	O
interpret	O
these	O
numbers	O
is	O
to	O
notice	O
that	O
dividing	O
the	O
focal	O
length	O
by	O
the	O
f-number	O
gives	O
us	O
the	O
diameter	O
d	O
,	O
so	O
these	O
are	O
just	O
formulas	O
for	O
the	O
aperture	O
diameter.8	O
notice	O
that	O
the	O
usual	O
progression	O
for	O
f-numbers	O
is	O
in	O
full	O
stops	O
,	O
which	O
are	O
multiples	O
of	O
√2	O
,	O
since	O
this	O
corresponds	O
to	O
doubling	O
the	O
area	O
of	O
the	O
entrance	O
pupil	O
each	O
time	O
a	O
smaller	O
f-number	O
is	O
selected	O
.	O
(	O
this	O
doubling	O
is	O
also	O
called	O
changing	O
the	O
exposure	O
by	O
one	O
exposure	O
value	O
or	O
ev	O
.	O
it	O
has	O
the	O
same	O
effect	O
on	O
the	O
amount	O
of	O
light	O
reaching	O
the	O
sensor	B
as	O
doubling	O
the	O
exposure	O
duration	O
,	O
e.g.	O
,	O
from	O
1/125	O
to	O
1/250	O
,	O
see	O
exercise	O
2.5	O
.	O
)	O
now	O
that	O
you	O
know	O
how	O
to	O
convert	O
between	O
f-numbers	O
and	O
aperture	O
diameters	O
,	O
you	O
can	O
construct	O
your	O
own	O
plots	O
for	O
the	O
depth	O
of	O
ﬁeld	O
as	O
a	O
function	O
of	O
focal	O
length	O
f	O
,	O
circle	O
of	O
confusion	O
c	O
,	O
and	O
focus	B
distance	O
zo	O
,	O
as	O
explained	O
in	O
exercise	O
2.4	O
and	O
see	O
how	O
well	O
these	O
match	O
what	O
you	O
observe	O
on	O
actual	O
lenses	O
,	O
such	O
as	O
those	O
shown	O
in	O
figure	O
2.20.	O
of	O
course	O
,	O
real	O
lenses	O
are	O
not	O
inﬁnitely	O
thin	B
and	O
therefore	O
suffer	O
from	O
geometric	B
aber-	O
rations	O
,	O
unless	O
compound	B
elements	O
are	O
used	O
to	O
correct	O
for	O
them	O
.	O
the	O
classic	O
ﬁve	O
seidel	O
aberrations	O
,	O
which	O
arise	O
when	O
using	O
third-order	O
optics	B
,	O
include	O
spherical	B
aberration	O
,	O
coma	O
,	O
astigmatism	O
,	O
curvature	O
of	O
ﬁeld	O
,	O
and	O
distortion	O
(	O
m¨oller	O
1988	O
;	O
hecht	O
2001	O
;	O
ray	O
2002	O
)	O
.	O
8	O
this	O
also	O
explains	O
why	O
,	O
with	O
zoom	O
lenses	O
,	O
the	O
f-number	O
varies	O
with	O
the	O
current	O
zoom	O
(	O
focal	O
length	O
)	O
setting	O
.	O
2.2	O
photometric	B
image	O
formation	O
71	O
figure	O
2.21	O
in	O
a	O
lens	O
subject	O
to	O
chromatic	B
aberration	I
,	O
light	O
at	O
different	O
wavelengths	O
(	O
e.g.	O
,	O
the	O
red	O
and	O
blur	O
arrows	O
)	O
is	O
focused	O
with	O
a	O
different	O
focal	O
length	O
f	O
(	O
cid:48	O
)	O
and	O
hence	O
a	O
different	O
depth	O
z	O
(	O
cid:48	O
)	O
i	O
,	O
resulting	O
in	O
both	O
a	O
geometric	B
(	O
in-plane	O
)	O
displacement	O
and	O
a	O
loss	O
of	O
focus	B
.	O
chromatic	B
aberration	I
because	O
the	O
index	O
of	O
refraction	O
for	O
glass	O
varies	O
slightly	O
as	O
a	O
function	O
of	O
wavelength	O
,	O
sim-	O
ple	O
lenses	O
suffer	O
from	O
chromatic	B
aberration	I
,	O
which	O
is	O
the	O
tendency	O
for	O
light	O
of	O
different	O
colors	O
to	O
focus	B
at	O
slightly	O
different	O
distances	O
(	O
and	O
hence	O
also	O
with	O
slightly	O
different	O
mag-	O
niﬁcation	O
factors	O
)	O
,	O
as	O
shown	O
in	O
figure	O
2.21.	O
the	O
wavelength-dependent	O
magniﬁcation	O
fac-	O
tor	O
,	O
i.e.	O
,	O
the	O
transverse	O
chromatic	B
aberration	I
,	O
can	O
be	O
modeled	O
as	O
a	O
per-color	O
radial	B
distortion	I
(	O
section	O
2.1.6	O
)	O
and	O
,	O
hence	O
,	O
calibrated	O
using	O
the	O
techniques	O
described	O
in	O
section	O
6.3.5.	O
the	O
wavelength-dependent	O
blur	O
caused	O
by	O
longitudinal	O
chromatic	B
aberration	I
can	O
be	O
calibrated	O
using	O
techniques	O
described	O
in	O
section	O
10.1.4.	O
unfortunately	O
,	O
the	O
blur	O
induced	O
by	O
longitudinal	O
aberration	O
can	O
be	O
harder	O
to	O
undo	O
,	O
as	O
higher	O
frequencies	O
can	O
get	O
strongly	O
attenuated	O
and	O
hence	O
hard	O
to	O
recover	O
.	O
in	O
order	B
to	O
reduce	O
chromatic	O
and	O
other	O
kinds	O
of	O
aberrations	O
,	O
most	O
photographic	O
lenses	O
today	O
are	O
compound	B
lenses	O
made	O
of	O
different	O
glass	O
elements	O
(	O
with	O
different	O
coatings	O
)	O
.	O
such	O
lenses	O
can	O
no	O
longer	O
be	O
modeled	O
as	O
having	O
a	O
single	O
nodal	O
point	O
p	O
through	O
which	O
all	O
of	O
the	O
rays	O
must	O
pass	O
(	O
when	O
approximating	O
the	O
lens	O
with	O
a	O
pinhole	O
model	O
)	O
.	O
instead	O
,	O
these	O
lenses	O
have	O
both	O
a	O
front	O
nodal	B
point	I
,	O
through	O
which	O
the	O
rays	O
enter	O
the	O
lens	O
,	O
and	O
a	O
rear	O
nodal	B
point	I
,	O
through	O
which	O
they	O
leave	O
on	O
their	O
way	O
to	O
the	O
sensor	B
.	O
in	O
practice	O
,	O
only	O
the	O
location	O
of	O
the	O
front	O
nodal	B
point	I
is	O
of	O
interest	O
when	O
performing	O
careful	O
camera	B
calibration	O
,	O
e.g.	O
,	O
when	O
determining	O
the	O
point	O
around	O
which	O
to	O
rotate	O
to	O
capture	O
a	O
parallax-free	O
panorama	O
(	O
see	O
section	O
9.1.3	O
)	O
.	O
not	O
all	O
lenses	O
,	O
however	O
,	O
can	O
be	O
modeled	O
as	O
having	O
a	O
single	O
nodal	O
point	O
.	O
in	O
particular	O
,	O
very	O
wide-angle	O
lenses	O
such	O
as	O
ﬁsheye	O
lenses	O
(	O
section	O
2.1.6	O
)	O
and	O
certain	O
catadioptric	O
imaging	O
systems	O
consisting	O
of	O
lenses	O
and	O
curved	O
mirrors	O
(	O
baker	O
and	O
nayar	O
1999	O
)	O
do	O
not	O
have	O
a	O
single	O
point	O
through	O
which	O
all	O
of	O
the	O
acquired	O
light	O
rays	O
pass	O
.	O
in	O
such	O
cases	O
,	O
it	O
is	O
preferable	O
to	O
explicitly	O
construct	O
a	O
mapping	O
function	O
(	O
look-up	O
table	O
)	O
between	O
pixel	O
coordinates	O
and	O
3d	O
rays	O
in	O
space	O
(	O
gremban	O
,	O
thorpe	O
,	O
and	O
kanade	O
1988	O
;	O
champleboux	O
,	O
lavall´ee	O
,	O
sautot	O
et	O
al	O
.	O
zi	O
’	O
=103mmf	O
’	O
=	O
101mmzo=5mpdc	O
72	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.22	O
the	O
amount	O
of	O
light	O
hitting	O
a	O
pixel	O
of	O
surface	B
area	O
δi	O
depends	O
on	O
the	O
square	O
of	O
the	O
ratio	O
of	O
the	O
aperture	O
diameter	O
d	O
to	O
the	O
focal	O
length	O
f	O
,	O
as	O
well	O
as	O
the	O
fourth	O
power	O
of	O
the	O
off-axis	O
angle	O
α	O
cosine	O
,	O
cos4	O
α	O
.	O
1992	O
;	O
grossberg	O
and	O
nayar	O
2001	O
;	O
sturm	O
and	O
ramalingam	O
2004	O
;	O
tardif	O
,	O
sturm	O
,	O
trudeau	O
et	O
al	O
.	O
2009	O
)	O
,	O
as	O
mentioned	O
in	O
section	O
2.1.6.	O
vignetting	B
another	O
property	O
of	O
real-world	O
lenses	O
is	O
vignetting	B
,	O
which	O
is	O
the	O
tendency	O
for	O
the	O
brightness	O
of	O
the	O
image	B
to	O
fall	O
off	O
towards	O
the	O
edge	O
of	O
the	O
image	B
.	O
two	O
kinds	O
of	O
phenomena	O
usually	O
contribute	O
to	O
this	O
effect	O
(	O
ray	O
2002	O
)	O
.	O
the	O
ﬁrst	O
is	O
called	O
natural	B
vignetting	O
and	O
is	O
due	O
to	O
the	O
foreshortening	O
in	O
the	O
object	O
surface	B
,	O
projected	O
pixel	O
,	O
and	O
lens	O
aperture	O
,	O
as	O
shown	O
in	O
figure	O
2.22.	O
consider	O
the	O
light	O
leaving	O
the	O
object	O
surface	B
patch	O
of	O
size	O
δo	O
located	O
at	O
an	O
off-axis	O
angle	O
α.	O
because	O
this	O
patch	B
is	O
foreshortened	O
with	O
respect	O
to	O
the	O
camera	B
lens	O
,	O
the	O
amount	O
of	O
light	O
reaching	O
the	O
lens	O
is	O
reduced	O
by	O
a	O
factor	O
cos	O
α.	O
the	O
amount	O
of	O
light	O
reaching	O
the	O
lens	O
is	O
also	O
subject	O
to	O
the	O
usual	O
1/r2	O
fall-off	O
;	O
in	O
this	O
case	O
,	O
the	O
distance	O
ro	O
=	O
zo/	O
cos	O
α.	O
the	O
actual	O
area	O
of	O
the	O
aperture	O
through	O
which	O
the	O
light	O
passes	O
is	O
foreshortened	O
by	O
an	O
additional	O
factor	O
cos	O
α	O
,	O
i.e.	O
,	O
the	O
aperture	O
as	O
seen	O
from	O
point	O
o	O
is	O
an	O
ellipse	O
of	O
dimensions	O
d×	O
d	O
cos	O
α.	O
putting	O
all	O
of	O
these	O
factors	O
together	O
,	O
we	O
see	O
that	O
the	O
amount	O
of	O
light	O
leaving	O
o	O
and	O
passing	O
through	O
the	O
aperture	O
on	O
its	O
way	O
to	O
the	O
image	B
pixel	O
located	O
at	O
i	O
is	O
proportional	O
to	O
δo	O
cos	O
α	O
r2	O
o	O
π	O
(	O
cid:18	O
)	O
d	O
2	O
(	O
cid:19	O
)	O
2	O
cos	O
α	O
=	O
δo	O
π	O
4	O
d2	O
z2	O
o	O
cos4	O
α	O
.	O
(	O
2.98	O
)	O
since	O
triangles	O
∆op	O
q	O
and	O
∆ip	O
j	O
are	O
similar	O
,	O
the	O
projected	O
areas	O
of	O
of	O
the	O
object	O
surface	B
δo	O
and	O
image	B
pixel	O
δi	O
are	O
in	O
the	O
same	O
(	O
squared	O
)	O
ratio	O
as	O
zo	O
:	O
zi	O
,	O
putting	O
these	O
together	O
,	O
we	O
obtain	O
the	O
ﬁnal	O
relationship	O
between	O
the	O
amount	O
of	O
light	O
reaching	O
δo	O
δi	O
=	O
z2	O
o	O
z2	O
i	O
.	O
(	O
2.99	O
)	O
zi=102mmf=	O
100mmzo=5mδidδoαααpjioqro	O
2.3	O
the	O
digital	O
camera	O
73	O
pixel	O
i	O
and	O
the	O
aperture	O
diameter	O
d	O
,	O
the	O
focusing	O
distance	O
zi	O
≈	O
f	O
,	O
and	O
the	O
off-axis	O
angle	O
α	O
,	O
δo	O
π	O
4	O
d2	O
z2	O
o	O
cos4	O
α	O
=	O
δi	O
π	O
4	O
d2	O
z2	O
i	O
cos4	O
α	O
≈	O
δi	O
cos4	O
α	O
,	O
(	O
2.100	O
)	O
π	O
4	O
(	O
cid:18	O
)	O
d	O
f	O
(	O
cid:19	O
)	O
2	O
which	O
is	O
called	O
the	O
fundamental	O
radiometric	B
relation	O
between	O
the	O
scene	O
radiance	O
l	O
and	O
the	O
light	O
(	O
irradiance	O
)	O
e	O
reaching	O
the	O
pixel	O
sensor	O
,	O
e	O
=	O
l	O
π	O
4	O
(	O
cid:18	O
)	O
d	O
f	O
(	O
cid:19	O
)	O
2	O
cos4	O
α	O
,	O
(	O
2.101	O
)	O
(	O
horn	O
1986	O
;	O
nalwa	O
1993	O
;	O
hecht	O
2001	O
;	O
ray	O
2002	O
)	O
.	O
notice	O
in	O
this	O
equation	B
how	O
the	O
amount	O
of	O
light	O
depends	O
on	O
the	O
pixel	O
surface	O
area	O
(	O
which	O
is	O
why	O
the	O
smaller	O
sensors	O
in	O
point-and-shoot	O
cameras	O
are	O
so	O
much	O
noisier	O
than	O
digital	O
single	O
lens	O
reﬂex	O
(	O
slr	O
)	O
cameras	O
)	O
,	O
the	O
inverse	B
square	O
of	O
the	O
f-stop	O
n	O
=	O
f	O
/d	O
(	O
2.97	O
)	O
,	O
and	O
the	O
fourth	O
power	O
of	O
the	O
cos4	O
α	O
off-axis	O
fall-off	O
,	O
which	O
is	O
the	O
natural	B
vignetting	O
term	O
.	O
the	O
other	O
major	O
kind	O
of	O
vignetting	B
,	O
called	O
mechanical	B
vignetting	O
,	O
is	O
caused	O
by	O
the	O
internal	O
occlusion	O
of	O
rays	O
near	O
the	O
periphery	O
of	O
lens	O
elements	O
in	O
a	O
compound	B
lens	O
,	O
and	O
can	O
not	O
easily	O
be	O
described	O
mathematically	O
without	O
performing	O
a	O
full	O
ray-tracing	O
of	O
the	O
actual	O
lens	O
design.9	O
however	O
,	O
unlike	O
natural	B
vignetting	O
,	O
mechanical	B
vignetting	O
can	O
be	O
decreased	O
by	O
reducing	O
the	O
camera	B
aperture	O
(	O
increasing	O
the	O
f-number	O
)	O
.	O
it	O
can	O
also	O
be	O
calibrated	O
(	O
along	O
with	O
natural	O
vi-	O
gnetting	O
)	O
using	O
special	O
devices	O
such	O
as	O
integrating	O
spheres	O
,	O
uniformly	O
illuminated	O
targets	O
,	O
or	O
camera	B
rotation	O
,	O
as	O
discussed	O
in	O
section	O
10.1.3	O
.	O
2.3	O
the	O
digital	O
camera	O
after	O
starting	O
from	O
one	O
or	O
more	O
light	O
sources	O
,	O
reﬂecting	O
off	O
one	O
or	O
more	O
surfaces	O
in	O
the	O
world	O
,	O
and	O
passing	O
through	O
the	O
camera	B
’	O
s	O
optics	B
(	O
lenses	O
)	O
,	O
light	O
ﬁnally	O
reaches	O
the	O
imaging	O
sensor	B
.	O
how	O
are	O
the	O
photons	O
arriving	O
at	O
this	O
sensor	B
converted	O
into	O
the	O
digital	O
(	O
r	O
,	O
g	O
,	O
b	O
)	O
values	O
that	O
we	O
observe	O
when	O
we	O
look	O
at	O
a	O
digital	O
image	O
?	O
in	O
this	O
section	O
,	O
we	O
develop	O
a	O
simple	O
model	O
that	O
accounts	O
for	O
the	O
most	O
important	O
effects	O
such	O
as	O
exposure	O
(	O
gain	O
and	O
shutter	O
speed	O
)	O
,	O
non-	O
linear	B
mappings	O
,	O
sampling	B
and	O
aliasing	B
,	O
and	O
noise	B
.	O
figure	O
2.23	O
,	O
which	O
is	O
based	O
on	O
camera	B
models	O
developed	O
by	O
healey	O
and	O
kondepudy	O
(	O
1994	O
)	O
;	O
tsin	O
,	O
ramesh	O
,	O
and	O
kanade	O
(	O
2001	O
)	O
;	O
liu	O
,	O
szeliski	O
,	O
kang	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
shows	O
a	O
simple	O
version	O
of	O
the	O
processing	O
stages	O
that	O
occur	O
in	O
modern	O
digital	O
cameras	O
.	O
chakrabarti	O
,	O
scharstein	O
,	O
and	O
zickler	O
(	O
2009	O
)	O
developed	O
a	O
sophisti-	O
cated	O
24-parameter	O
model	O
that	O
is	O
an	O
even	O
better	O
match	O
to	O
the	O
processing	O
performed	O
in	O
today	O
’	O
s	O
cameras	O
.	O
9	O
there	O
are	O
some	O
empirical	O
models	O
that	O
work	O
well	O
in	O
practice	O
(	O
kang	O
and	O
weiss	O
2000	O
;	O
zheng	O
,	O
lin	O
,	O
and	O
kang	O
2006	O
)	O
.	O
74	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.23	O
image	B
sensing	O
pipeline	B
,	O
showing	O
the	O
various	O
sources	O
of	O
noise	B
as	O
well	O
as	O
typical	O
digital	O
post-processing	O
steps	O
.	O
light	O
falling	O
on	O
an	O
imaging	O
sensor	B
is	O
usually	O
picked	O
up	O
by	O
an	O
active	O
sensing	O
area	O
,	O
inte-	O
grated	O
for	O
the	O
duration	O
of	O
the	O
exposure	O
(	O
usually	O
expressed	O
as	O
the	O
shutter	O
speed	O
in	O
a	O
fraction	O
of	O
30	O
)	O
,	O
and	O
then	O
passed	O
to	O
a	O
set	O
of	O
sense	O
ampliﬁers	O
.	O
the	O
two	O
main	O
kinds	O
a	O
second	O
,	O
e.g.	O
,	O
1	O
of	O
sensor	B
used	O
in	O
digital	O
still	O
and	O
video	B
cameras	O
today	O
are	O
charge-coupled	O
device	O
(	O
ccd	O
)	O
and	O
complementary	O
metal	O
oxide	O
on	O
silicon	O
(	O
cmos	O
)	O
.	O
125	O
,	O
1	O
60	O
,	O
1	O
in	O
a	O
ccd	O
,	O
photons	O
are	O
accumulated	O
in	O
each	O
active	O
well	O
during	O
the	O
exposure	O
time	O
.	O
then	O
,	O
in	O
a	O
transfer	B
phase	O
,	O
the	O
charges	O
are	O
transferred	O
from	O
well	O
to	O
well	O
in	O
a	O
kind	O
of	O
“	O
bucket	O
brigade	O
”	O
until	O
they	O
are	O
deposited	O
at	O
the	O
sense	O
ampliﬁers	O
,	O
which	O
amplify	O
the	O
signal	O
and	O
pass	O
it	O
to	O
an	O
analog-to-digital	O
converter	O
(	O
adc	O
)	O
.10	O
older	O
ccd	O
sensors	O
were	O
prone	O
to	O
blooming	B
,	O
when	O
charges	O
from	O
one	O
over-exposed	O
pixel	O
spilled	O
into	O
adjacent	O
ones	O
,	O
but	O
most	O
newer	O
ccds	O
have	O
anti-blooming	O
technology	O
(	O
“	O
troughs	O
”	O
into	O
which	O
the	O
excess	O
charge	O
can	O
spill	O
)	O
.	O
in	O
cmos	O
,	O
the	O
photons	O
hitting	O
the	O
sensor	B
directly	O
affect	O
the	O
conductivity	O
(	O
or	O
gain	O
)	O
of	O
a	O
photodetector	O
,	O
which	O
can	O
be	O
selectively	O
gated	O
to	O
control	O
exposure	O
duration	O
,	O
and	O
locally	O
am-	O
pliﬁed	O
before	O
being	O
read	O
out	O
using	O
a	O
multiplexing	O
scheme	O
.	O
traditionally	O
,	O
ccd	O
sensors	O
outperformed	O
cmos	O
in	O
quality	O
sensitive	O
applications	O
,	O
such	O
as	O
digital	O
slrs	O
,	O
while	O
cmos	O
was	O
better	O
for	O
low-power	O
applications	O
,	O
but	O
today	O
cmos	O
is	O
used	O
in	O
most	O
digital	O
cameras	O
.	O
the	O
main	O
factors	O
affecting	O
the	O
performance	O
of	O
a	O
digital	O
image	O
sensor	B
are	O
the	O
shutter	O
speed	O
,	O
sampling	B
pitch	I
,	O
ﬁll	O
factor	O
,	O
chip	O
size	O
,	O
analog	O
gain	O
,	O
sensor	B
noise	O
,	O
and	O
the	O
resolution	O
(	O
and	O
quality	O
)	O
10	O
in	O
digital	O
still	O
cameras	O
,	O
a	O
complete	O
frame	O
is	O
captured	O
and	O
then	O
read	O
out	O
sequentially	O
at	O
once	O
.	O
however	O
,	O
if	O
video	B
is	O
being	O
captured	O
,	O
a	O
rolling	O
shutter	O
,	O
which	O
exposes	O
and	O
transfers	O
each	O
line	O
separately	O
,	O
is	O
often	O
used	O
.	O
in	O
older	O
video	B
cameras	O
,	O
the	O
even	O
ﬁelds	O
(	O
lines	B
)	O
were	O
scanned	O
ﬁrst	O
,	O
followed	O
by	O
the	O
odd	O
ﬁelds	O
,	O
in	O
a	O
process	O
that	O
is	O
called	O
interlacing	O
.	O
2.3	O
the	O
digital	O
camera	O
75	O
of	O
the	O
analog-to-digital	O
converter	O
.	O
many	O
of	O
the	O
actual	O
values	O
for	O
these	O
parameters	B
can	O
be	O
read	O
from	O
the	O
exif	O
tags	O
embedded	O
with	O
digital	O
images	O
.	O
while	O
others	O
can	O
be	O
obtained	O
from	O
the	O
camera	B
manufacturers	O
’	O
speciﬁcation	O
sheets	O
or	O
from	O
camera	B
review	O
or	O
calibration	B
web	O
sites.11	O
shutter	O
speed	O
.	O
the	O
shutter	O
speed	O
(	O
exposure	O
time	O
)	O
directly	O
controls	O
the	O
amount	O
of	O
light	O
reaching	O
the	O
sensor	B
and	O
,	O
hence	O
,	O
determines	O
if	O
images	O
are	O
under-	O
or	O
over-exposed	O
.	O
(	O
for	O
bright	O
scenes	O
,	O
where	O
a	O
large	O
aperture	O
or	O
slow	O
shutter	O
speed	O
are	O
desired	O
to	O
get	O
a	O
shallow	O
depth	O
of	O
ﬁeld	O
or	O
motion	B
blur	O
,	O
neutral	O
density	O
ﬁlters	O
are	O
sometimes	O
used	O
by	O
photographers	O
.	O
)	O
for	O
dynamic	O
scenes	O
,	O
the	O
shutter	O
speed	O
also	O
determines	O
the	O
amount	O
of	O
motion	B
blur	O
in	O
the	O
resulting	O
picture	O
.	O
usually	O
,	O
a	O
higher	O
shutter	O
speed	O
(	O
less	O
motion	B
blur	O
)	O
makes	O
subsequent	O
analysis	O
easier	O
(	O
see	O
sec-	O
tion	B
10.3	O
for	O
techniques	O
to	O
remove	O
such	O
blur	O
)	O
.	O
however	O
,	O
when	O
video	B
is	O
being	O
captured	O
for	O
display	O
,	O
some	O
motion	B
blur	O
may	O
be	O
desirable	O
to	O
avoid	O
stroboscopic	O
effects	O
.	O
sampling	B
pitch	I
.	O
the	O
sampling	B
pitch	I
is	O
the	O
physical	O
spacing	O
between	O
adjacent	O
sensor	B
cells	O
on	O
the	O
imaging	O
chip	O
.	O
a	O
sensor	B
with	O
a	O
smaller	O
sampling	B
pitch	I
has	O
a	O
higher	O
sampling	O
density	O
and	O
hence	O
provides	O
a	O
higher	O
resolution	O
(	O
in	O
terms	O
of	O
pixels	O
)	O
for	O
a	O
given	O
active	O
chip	O
area	O
.	O
however	O
,	O
a	O
smaller	O
pitch	O
also	O
means	O
that	O
each	O
sensor	B
has	O
a	O
smaller	O
area	O
and	O
can	O
not	O
accumulate	O
as	O
many	O
photons	O
;	O
this	O
makes	O
it	O
not	O
as	O
light	O
sensitive	O
and	O
more	O
prone	O
to	O
noise	B
.	O
fill	O
factor	O
.	O
the	O
ﬁll	O
factor	O
is	O
the	O
active	O
sensing	O
area	O
size	O
as	O
a	O
fraction	O
of	O
the	O
theoretically	O
available	O
sensing	O
area	O
(	O
the	O
product	O
of	O
the	O
horizontal	O
and	O
vertical	O
sampling	B
pitches	O
)	O
.	O
higher	O
ﬁll	O
factors	O
are	O
usually	O
preferable	O
,	O
as	O
they	O
result	O
in	O
more	O
light	O
capture	O
and	O
less	O
aliasing	B
(	O
see	O
section	O
2.3.1	O
)	O
.	O
however	O
,	O
this	O
must	O
be	O
balanced	O
with	O
the	O
need	O
to	O
place	O
additional	O
electronics	O
between	O
the	O
active	O
sense	O
areas	O
.	O
the	O
ﬁll	O
factor	O
of	O
a	O
camera	B
can	O
be	O
determined	O
empirically	O
using	O
a	O
photometric	B
camera	O
calibration	B
process	O
(	O
see	O
section	O
10.1.4	O
)	O
.	O
chip	O
size	O
.	O
video	B
and	O
point-and-shoot	O
cameras	O
have	O
traditionally	O
used	O
small	O
chip	O
areas	O
(	O
1	O
4-	O
2-inch	O
sensors12	O
)	O
,	O
while	O
digital	O
slr	O
cameras	O
try	O
to	O
come	O
closer	O
to	O
the	O
traditional	O
size	O
inch	O
to	O
1	O
of	O
a	O
35mm	O
ﬁlm	O
frame.13	O
when	O
overall	O
device	O
size	O
is	O
not	O
important	O
,	O
having	O
a	O
larger	O
chip	O
size	O
is	O
preferable	O
,	O
since	O
each	O
sensor	B
cell	O
can	O
be	O
more	O
photo-sensitive	O
.	O
(	O
for	O
compact	O
cameras	O
,	O
a	O
smaller	O
chip	O
means	O
that	O
all	O
of	O
the	O
optics	B
can	O
be	O
shrunk	O
down	O
proportionately	O
.	O
)	O
however	O
,	O
11	O
http	O
:	O
//www.clarkvision.com/imagedetail/digital.sensor.performance.summary/	O
.	O
12	O
these	O
numbers	O
refer	O
to	O
the	O
“	O
tube	O
diameter	O
”	O
of	O
the	O
old	O
vidicon	O
tubes	O
used	O
in	O
video	B
cameras	O
(	O
http	O
:	O
//www	O
.	O
dpreview.com/learn/	O
?	O
/glossary/camera	O
system/sensor	O
sizes	O
01.htm	O
)	O
.	O
the	O
1/2.5	O
”	O
sensor	B
on	O
the	O
canon	O
sd800	O
cam-	O
era	O
actually	O
measures	O
5.76mm	O
×	O
4.29mm	O
,	O
i.e.	O
,	O
a	O
sixth	O
of	O
the	O
size	O
(	O
on	O
side	O
)	O
of	O
a	O
35mm	O
full-frame	O
(	O
36mm	O
×	O
24mm	O
)	O
dslr	O
sensor	B
.	O
13	O
when	O
a	O
dslr	O
chip	O
does	O
not	O
ﬁll	O
the	O
35mm	O
full	O
frame	O
,	O
it	O
results	O
in	O
a	O
multiplier	O
effect	O
on	O
the	O
lens	O
focal	O
length	O
.	O
for	O
example	O
,	O
a	O
chip	O
that	O
is	O
only	O
0.6	O
the	O
dimension	O
of	O
a	O
35mm	O
frame	O
will	O
make	O
a	O
50mm	O
lens	O
image	B
the	O
same	O
angular	O
extent	O
as	O
a	O
50/0.6	O
=	O
50	O
×	O
1.6	O
=80mm	O
lens	O
,	O
as	O
demonstrated	O
in	O
(	O
2.60	O
)	O
.	O
76	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
larger	O
chips	O
are	O
more	O
expensive	O
to	O
produce	O
,	O
not	O
only	O
because	O
fewer	O
chips	O
can	O
be	O
packed	O
into	O
each	O
wafer	O
,	O
but	O
also	O
because	O
the	O
probability	O
of	O
a	O
chip	O
defect	O
goes	O
up	O
linearly	O
with	O
the	O
chip	O
area	O
.	O
analog	O
gain	O
.	O
before	O
analog-to-digital	O
conversion	O
,	O
the	O
sensed	O
signal	O
is	O
usually	O
boosted	O
by	O
a	O
sense	O
ampliﬁer	B
.	O
in	O
video	B
cameras	O
,	O
the	O
gain	O
on	O
these	O
ampliﬁers	O
was	O
traditionally	O
controlled	O
by	O
automatic	B
gain	O
control	O
(	O
agc	O
)	O
logic	O
,	O
which	O
would	O
adjust	O
these	O
values	O
to	O
obtain	O
a	O
good	O
overall	O
exposure	O
.	O
in	O
newer	O
digital	O
still	O
cameras	O
,	O
the	O
user	O
now	O
has	O
some	O
additional	O
control	O
over	O
this	O
gain	O
through	O
the	O
iso	O
setting	O
,	O
which	O
is	O
typically	O
expressed	O
in	O
iso	O
standard	O
units	O
such	O
as	O
100	O
,	O
200	O
,	O
or	O
400.	O
since	O
the	O
automated	B
exposure	O
control	O
in	O
most	O
cameras	O
also	O
adjusts	O
the	O
aperture	O
and	O
shutter	O
speed	O
,	O
setting	O
the	O
iso	O
manually	O
removes	O
one	O
degree	O
of	O
freedom	O
from	O
the	O
camera	B
’	O
s	O
control	O
,	O
just	O
as	O
manually	O
specifying	O
aperture	O
and	O
shutter	O
speed	O
does	O
.	O
in	O
theory	O
,	O
a	O
higher	O
gain	O
allows	O
the	O
camera	B
to	O
perform	O
better	O
under	O
low	O
light	O
conditions	O
(	O
less	O
motion	B
blur	O
due	O
to	O
long	O
exposure	O
times	O
when	O
the	O
aperture	O
is	O
already	O
maxed	O
out	O
)	O
.	O
in	O
practice	O
,	O
however	O
,	O
higher	O
iso	O
settings	O
usually	O
amplify	O
the	O
sensor	B
noise	O
.	O
sensor	B
noise	O
.	O
throughout	O
the	O
whole	O
sensing	O
process	O
,	O
noise	B
is	O
added	O
from	O
various	O
sources	O
,	O
which	O
may	O
include	O
ﬁxed	B
pattern	I
noise	O
,	O
dark	B
current	I
noise	O
,	O
shot	B
noise	I
,	O
ampliﬁer	B
noise	O
and	O
quantization	B
noise	O
(	O
healey	O
and	O
kondepudy	O
1994	O
;	O
tsin	O
,	O
ramesh	O
,	O
and	O
kanade	O
2001	O
)	O
.	O
the	O
ﬁnal	O
amount	O
of	O
noise	B
present	O
in	O
a	O
sampled	O
image	B
depends	O
on	O
all	O
of	O
these	O
quantities	O
,	O
as	O
well	O
as	O
the	O
incoming	O
light	O
(	O
controlled	O
by	O
the	O
scene	O
radiance	O
and	O
aperture	O
)	O
,	O
the	O
exposure	O
time	O
,	O
and	O
the	O
sensor	B
gain	O
.	O
also	O
,	O
for	O
low	O
light	O
conditions	O
where	O
the	O
noise	B
is	O
due	O
to	O
low	O
photon	O
counts	O
,	O
a	O
poisson	O
model	O
of	O
noise	B
may	O
be	O
more	O
appropriate	O
than	O
a	O
gaussian	O
model	O
.	O
as	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
10.1.1	O
,	O
liu	O
,	O
szeliski	O
,	O
kang	O
et	O
al	O
.	O
(	O
2008	O
)	O
use	O
this	O
model	O
,	O
along	O
with	O
an	O
empirical	O
database	O
of	O
camera	B
response	O
functions	O
(	O
crfs	O
)	O
obtained	O
by	O
grossberg	O
and	O
nayar	O
(	O
2004	O
)	O
,	O
to	O
estimate	O
the	O
noise	B
level	O
function	O
(	O
nlf	O
)	O
for	O
a	O
given	O
image	B
,	O
which	O
predicts	O
the	O
overall	O
noise	B
variance	O
at	O
a	O
given	O
pixel	O
as	O
a	O
function	O
of	O
its	O
brightness	O
(	O
a	O
separate	O
nlf	O
is	O
estimated	O
for	O
each	O
color	B
channel	O
)	O
.	O
an	O
alternative	O
approach	O
,	O
when	O
you	O
have	O
access	O
to	O
the	O
camera	B
before	O
taking	O
pictures	O
,	O
is	O
to	O
pre-calibrate	O
the	O
nlf	O
by	O
taking	O
repeated	O
shots	O
of	O
a	O
scene	O
containing	O
a	O
variety	O
of	O
colors	O
and	O
luminances	O
,	O
such	O
as	O
the	O
macbeth	O
color	B
chart	O
shown	O
in	O
figure	O
10.3b	O
(	O
mccamy	O
,	O
marcus	O
,	O
and	O
davidson	O
1976	O
)	O
.	O
(	O
when	O
estimating	O
the	O
variance	O
,	O
be	O
sure	O
to	O
throw	O
away	O
or	O
downweight	O
pixels	O
with	O
large	O
gradients	O
,	O
as	O
small	O
shifts	O
between	O
exposures	O
will	O
affect	O
the	O
sensed	O
values	O
at	O
such	O
pixels	O
.	O
)	O
unfortunately	O
,	O
the	O
pre-	O
calibration	B
process	O
may	O
have	O
to	O
be	O
repeated	O
for	O
different	O
exposure	O
times	O
and	O
gain	O
settings	O
because	O
of	O
the	O
complex	O
interactions	O
occurring	O
within	O
the	O
sensing	O
system	O
.	O
in	O
practice	O
,	O
most	O
computer	O
vision	O
algorithms	O
,	O
such	O
as	O
image	B
denoising	O
,	O
edge	O
detection	O
,	O
and	O
stereo	B
matching	I
,	O
all	O
beneﬁt	O
from	O
at	O
least	O
a	O
rudimentary	O
estimate	O
of	O
the	O
noise	B
level	O
.	O
barring	O
the	O
ability	O
to	O
pre-calibrate	O
the	O
camera	B
or	O
to	O
take	O
repeated	O
shots	O
of	O
the	O
same	O
scene	O
,	O
the	O
simplest	O
2.3	O
the	O
digital	O
camera	O
77	O
approach	O
is	O
to	O
look	O
for	O
regions	O
of	O
near-constant	O
value	O
and	O
to	O
estimate	O
the	O
noise	B
variance	O
in	O
such	O
regions	O
(	O
liu	O
,	O
szeliski	O
,	O
kang	O
et	O
al	O
.	O
2008	O
)	O
.	O
adc	O
resolution	O
.	O
the	O
ﬁnal	O
step	O
in	O
the	O
analog	O
processing	O
chain	O
occurring	O
within	O
an	O
imaging	O
sensor	B
is	O
the	O
analog	O
to	O
digital	O
conversion	O
(	O
adc	O
)	O
.	O
while	O
a	O
variety	O
of	O
techniques	O
can	O
be	O
used	O
to	O
implement	O
this	O
process	O
,	O
the	O
two	O
quantities	O
of	O
interest	O
are	O
the	O
resolution	O
of	O
this	O
process	O
(	O
how	O
many	O
bits	O
it	O
yields	O
)	O
and	O
its	O
noise	B
level	O
(	O
how	O
many	O
of	O
these	O
bits	O
are	O
useful	O
in	O
practice	O
)	O
.	O
for	O
most	O
cameras	O
,	O
the	O
number	O
of	O
bits	O
quoted	O
(	O
eight	O
bits	O
for	O
compressed	O
jpeg	O
images	O
and	O
a	O
nominal	O
16	O
bits	O
for	O
the	O
raw	O
formats	B
provided	O
by	O
some	O
dslrs	O
)	O
exceeds	O
the	O
actual	O
number	O
of	O
usable	O
bits	O
.	O
the	O
best	O
way	O
to	O
tell	O
is	O
to	O
simply	O
calibrate	O
the	O
noise	B
of	O
a	O
given	O
sensor	B
,	O
e.g.	O
,	O
by	O
taking	O
repeated	O
shots	O
of	O
the	O
same	O
scene	O
and	O
plotting	O
the	O
estimated	O
noise	B
as	O
a	O
function	O
of	O
brightness	O
(	O
exercise	O
2.6	O
)	O
.	O
digital	O
post-processing	O
.	O
once	O
the	O
irradiance	O
values	O
arriving	O
at	O
the	O
sensor	B
have	O
been	O
con-	O
verted	O
to	O
digital	O
bits	O
,	O
most	O
cameras	O
perform	O
a	O
variety	O
of	O
digital	O
signal	O
processing	O
(	O
dsp	O
)	O
operations	O
to	O
enhance	O
the	O
image	B
before	O
compressing	O
and	O
storing	O
the	O
pixel	O
values	O
.	O
these	O
in-	O
clude	O
color	O
ﬁlter	O
array	O
(	O
cfa	O
)	O
demosaicing	B
,	O
white	O
point	O
setting	O
,	O
and	O
mapping	O
of	O
the	O
luminance	O
values	O
through	O
a	O
gamma	B
function	O
to	O
increase	O
the	O
perceived	O
dynamic	B
range	O
of	O
the	O
signal	O
.	O
we	O
cover	O
these	O
topics	O
in	O
section	O
2.3.2	O
but	O
,	O
before	O
we	O
do	O
,	O
we	O
return	O
to	O
the	O
topic	O
of	O
aliasing	B
,	O
which	O
was	O
mentioned	O
in	O
connection	O
with	O
sensor	O
array	O
ﬁll	O
factors	O
.	O
2.3.1	O
sampling	B
and	O
aliasing	B
what	O
happens	O
when	O
a	O
ﬁeld	O
of	O
light	O
impinging	O
on	O
the	O
image	B
sensor	O
falls	O
onto	O
the	O
active	O
sense	O
areas	O
in	O
the	O
imaging	O
chip	O
?	O
the	O
photons	O
arriving	O
at	O
each	O
active	O
cell	O
are	O
integrated	O
and	O
then	O
digitized	O
.	O
however	O
,	O
if	O
the	O
ﬁll	O
factor	O
on	O
the	O
chip	O
is	O
small	O
and	O
the	O
signal	O
is	O
not	O
otherwise	O
band-limited	O
,	O
visually	O
unpleasing	O
aliasing	B
can	O
occur	O
.	O
to	O
explore	O
the	O
phenomenon	O
of	O
aliasing	B
,	O
let	O
us	O
ﬁrst	O
look	O
at	O
a	O
one-dimensional	O
signal	O
(	O
fig-	O
ure	O
2.24	O
)	O
,	O
in	O
which	O
we	O
have	O
two	O
sine	O
waves	O
,	O
one	O
at	O
a	O
frequency	O
of	O
f	O
=	O
3/4	O
and	O
the	O
other	O
at	O
f	O
=	O
5/4	O
.	O
if	O
we	O
sample	O
these	O
two	O
signals	O
at	O
a	O
frequency	O
of	O
f	O
=	O
2	O
,	O
we	O
see	O
that	O
they	O
produce	O
the	O
same	O
samples	O
(	O
shown	O
in	O
black	O
)	O
,	O
and	O
so	O
we	O
say	O
that	O
they	O
are	O
aliased.14	O
why	O
is	O
this	O
a	O
bad	O
effect	O
?	O
in	O
essence	O
,	O
we	O
can	O
no	O
longer	O
reconstruct	O
the	O
original	O
signal	O
,	O
since	O
we	O
do	O
not	O
know	O
which	O
of	O
the	O
two	O
original	O
frequencies	O
was	O
present	O
.	O
in	O
fact	O
,	O
shannon	O
’	O
s	O
sampling	B
theorem	O
shows	O
that	O
the	O
minimum	O
sampling	O
(	O
oppenheim	O
and	O
schafer	O
1996	O
;	O
oppenheim	O
,	O
schafer	O
,	O
and	O
buck	O
1999	O
)	O
rate	O
required	O
to	O
reconstruct	O
a	O
signal	O
14	O
an	O
alias	O
is	O
an	O
alternate	O
name	O
for	O
someone	O
,	O
so	O
the	O
sampled	O
signal	O
corresponds	O
to	O
two	O
different	O
aliases	O
.	O
78	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.24	O
aliasing	B
of	O
a	O
one-dimensional	O
signal	O
:	O
the	O
blue	O
sine	O
wave	O
at	O
f	O
=	O
3/4	O
and	O
the	O
red	O
sine	O
wave	O
at	O
f	O
=	O
5/4	O
have	O
the	O
same	O
digital	O
samples	O
,	O
when	O
sampled	O
at	O
f	O
=	O
2.	O
even	O
after	O
convolution	O
with	O
a	O
100	O
%	O
ﬁll	O
factor	O
box	O
ﬁlter	O
,	O
the	O
two	O
signals	O
,	O
while	O
no	O
longer	O
of	O
the	O
same	O
magnitude	O
,	O
are	O
still	O
aliased	O
in	O
the	O
sense	O
that	O
the	O
sampled	O
red	O
signal	O
looks	O
like	O
an	O
inverted	O
lower	O
magnitude	O
version	O
of	O
the	O
blue	O
signal	O
.	O
(	O
the	O
image	B
on	O
the	O
right	O
is	O
scaled	O
up	O
for	O
better	O
visibility	B
.	O
the	O
actual	O
sine	O
magnitudes	O
are	O
30	O
%	O
and	O
−18	O
%	O
of	O
their	O
original	O
values	O
.	O
)	O
from	O
its	O
instantaneous	O
samples	O
must	O
be	O
at	O
least	O
twice	O
the	O
highest	O
frequency,15	O
fs	O
≥	O
2fmax	O
.	O
(	O
2.102	O
)	O
the	O
maximum	O
frequency	O
in	O
a	O
signal	O
is	O
known	O
as	O
the	O
nyquist	O
frequency	O
and	O
the	O
inverse	B
of	O
the	O
minimum	O
sampling	O
frequency	O
rs	O
=	O
1/fs	O
is	O
known	O
as	O
the	O
nyquist	O
rate	O
.	O
however	O
,	O
you	O
may	O
ask	O
,	O
since	O
an	O
imaging	O
chip	O
actually	O
averages	O
the	O
light	B
ﬁeld	I
over	O
a	O
ﬁnite	O
area	O
,	O
are	O
the	O
results	O
on	O
point	O
sampling	O
still	O
applicable	O
?	O
averaging	O
over	O
the	O
sensor	B
area	O
does	O
tend	O
to	O
attenuate	O
some	O
of	O
the	O
higher	O
frequencies	O
.	O
however	O
,	O
even	O
if	O
the	O
ﬁll	O
factor	O
is	O
100	O
%	O
,	O
as	O
in	O
the	O
right	O
image	B
of	O
figure	O
2.24	O
,	O
frequencies	O
above	O
the	O
nyquist	O
limit	O
(	O
half	O
the	O
sampling	B
frequency	O
)	O
still	O
produce	O
an	O
aliased	O
signal	O
,	O
although	O
with	O
a	O
smaller	O
magnitude	O
than	O
the	O
corresponding	O
band-limited	O
signals	O
.	O
a	O
more	O
convincing	O
argument	O
as	O
to	O
why	O
aliasing	B
is	O
bad	O
can	O
be	O
seen	O
by	O
downsampling	O
a	O
signal	O
using	O
a	O
poor	O
quality	O
ﬁlter	O
such	O
as	O
a	O
box	O
(	O
square	O
)	O
ﬁlter	O
.	O
figure	O
2.25	O
shows	O
a	O
high-	O
frequency	O
chirp	O
image	B
(	O
so	O
called	O
because	O
the	O
frequencies	O
increase	O
over	O
time	O
)	O
,	O
along	O
with	O
the	O
results	O
of	O
sampling	B
it	O
with	O
a	O
25	O
%	O
ﬁll-factor	O
area	O
sensor	O
,	O
a	O
100	O
%	O
ﬁll-factor	O
sensor	B
,	O
and	O
a	O
high-	O
quality	O
9-tap	O
ﬁlter	O
.	O
additional	O
examples	B
of	O
downsampling	O
(	O
decimation	O
)	O
ﬁlters	O
can	O
be	O
found	O
in	O
section	O
3.5.2	O
and	O
figure	O
3.30.	O
the	O
best	O
way	O
to	O
predict	O
the	O
amount	O
of	O
aliasing	B
that	O
an	O
imaging	O
system	O
(	O
or	O
even	O
an	O
image	B
processing	O
algorithm	B
)	O
will	O
produce	O
is	O
to	O
estimate	O
the	O
point	B
spread	I
function	I
(	O
psf	O
)	O
,	O
which	O
represents	O
the	O
response	O
of	O
a	O
particular	O
pixel	O
sensor	O
to	O
an	O
ideal	O
point	O
light	O
source	O
.	O
the	O
psf	O
is	O
a	O
combination	O
(	O
convolution	O
)	O
of	O
the	O
blur	O
induced	O
by	O
the	O
optical	O
system	O
(	O
lens	O
)	O
and	O
the	O
ﬁnite	O
integration	O
area	O
of	O
a	O
chip	O
sensor.16	O
15	O
the	O
actual	O
theorem	O
states	O
that	O
fs	O
must	O
be	O
at	O
least	O
twice	O
the	O
signal	O
bandwidth	O
but	O
,	O
since	O
we	O
are	O
not	O
dealing	O
with	O
modulated	O
signals	O
such	O
as	O
radio	O
waves	O
during	O
image	B
capture	O
,	O
the	O
maximum	O
frequency	O
sufﬁces	O
.	O
16	O
imaging	O
chips	O
usually	O
interpose	O
an	O
optical	O
anti-aliasing	O
ﬁlter	O
just	O
before	O
the	O
imaging	O
chip	O
to	O
reduce	O
or	O
control	O
the	O
amount	O
of	O
aliasing	B
.	O
*f=	O
3/4f=	O
5/4=	O
2.3	O
the	O
digital	O
camera	O
79	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
2.25	O
aliasing	B
of	O
a	O
two-dimensional	B
signal	O
:	O
(	O
a	O
)	O
original	O
full-resolution	O
image	B
;	O
(	O
b	O
)	O
downsampled	O
4×	O
with	O
a	O
25	O
%	O
ﬁll	O
factor	O
box	O
ﬁlter	O
;	O
(	O
c	O
)	O
downsampled	O
4×	O
with	O
a	O
100	O
%	O
ﬁll	O
factor	O
box	O
ﬁlter	O
;	O
(	O
d	O
)	O
downsampled	O
4×	O
with	O
a	O
high-quality	O
9-tap	O
ﬁlter	O
.	O
notice	O
how	O
the	O
higher	O
frequencies	O
are	O
aliased	O
into	O
visible	O
frequencies	O
with	O
the	O
lower	O
quality	O
ﬁlters	O
,	O
while	O
the	O
9-tap	O
ﬁlter	O
completely	O
removes	O
these	O
higher	O
frequencies	O
.	O
if	O
we	O
know	O
the	O
blur	O
function	O
of	O
the	O
lens	O
and	O
the	O
ﬁll	O
factor	O
(	O
sensor	B
area	O
shape	O
and	O
spacing	O
)	O
for	O
the	O
imaging	O
chip	O
(	O
plus	O
,	O
optionally	O
,	O
the	O
response	O
of	O
the	O
anti-aliasing	O
ﬁlter	O
)	O
,	O
we	O
can	O
convolve	O
these	O
(	O
as	O
described	O
in	O
section	O
3.2	O
)	O
to	O
obtain	O
the	O
psf	O
.	O
figure	O
2.26a	O
shows	O
the	O
one-dimensional	O
cross-section	O
of	O
a	O
psf	O
for	O
a	O
lens	O
whose	O
blur	O
function	O
is	O
assumed	O
to	O
be	O
a	O
disc	O
of	O
a	O
radius	O
equal	O
to	O
the	O
pixel	O
spacing	O
s	O
plus	O
a	O
sensing	O
chip	O
whose	O
horizontal	O
ﬁll	O
factor	O
is	O
80	O
%	O
.	O
taking	O
the	O
fourier	O
transform	B
of	O
this	O
psf	O
(	O
section	O
3.4	O
)	O
,	O
we	O
obtain	O
the	O
modulation	O
transfer	B
function	O
(	O
mtf	O
)	O
,	O
from	O
which	O
we	O
can	O
estimate	O
the	O
amount	O
of	O
aliasing	B
as	O
the	O
area	O
of	O
the	O
fourier	O
magni-	O
tude	O
outside	O
the	O
f	O
≤	O
fs	O
nyquist	O
frequency.17	O
if	O
we	O
de-focus	O
the	O
lens	O
so	O
that	O
the	O
blur	O
function	O
has	O
a	O
radius	O
of	O
2s	O
(	O
figure	O
2.26c	O
)	O
,	O
we	O
see	O
that	O
the	O
amount	O
of	O
aliasing	B
decreases	O
signiﬁcantly	O
,	O
but	O
so	O
does	O
the	O
amount	O
of	O
image	B
detail	O
(	O
frequencies	O
closer	O
to	O
f	O
=	O
fs	O
)	O
.	O
under	O
laboratory	O
conditions	O
,	O
the	O
psf	O
can	O
be	O
estimated	O
(	O
to	O
pixel	O
precision	O
)	O
by	O
looking	O
at	O
a	O
point	O
light	O
source	O
such	O
as	O
a	O
pin	O
hole	O
in	O
a	O
black	O
piece	O
of	O
cardboard	O
lit	O
from	O
behind	O
.	O
however	O
,	O
this	O
psf	O
(	O
the	O
actual	O
image	B
of	O
the	O
pin	O
hole	O
)	O
is	O
only	O
accurate	O
to	O
a	O
pixel	O
resolution	O
and	O
,	O
while	O
it	O
can	O
model	O
larger	O
blur	O
(	O
such	O
as	O
blur	O
caused	O
by	O
defocus	O
)	O
,	O
it	O
can	O
not	O
model	O
the	O
sub-pixel	O
shape	O
of	O
the	O
psf	O
and	O
predict	O
the	O
amount	O
of	O
aliasing	B
.	O
an	O
alternative	O
technique	O
,	O
described	O
in	O
section	O
10.1.4	O
,	O
is	O
to	O
look	O
at	O
a	O
calibration	B
pattern	O
(	O
e.g.	O
,	O
one	O
consisting	O
of	O
slanted	O
step	O
edges	O
(	O
reichenbach	O
,	O
park	O
,	O
and	O
narayanswamy	O
1991	O
;	O
williams	O
and	O
burns	O
2001	O
;	O
joshi	O
,	O
szeliski	O
,	O
and	O
kriegman	O
2008	O
)	O
)	O
whose	O
ideal	O
appearance	O
can	O
be	O
re-synthesized	O
to	O
sub-pixel	O
precision	O
.	O
in	O
addition	O
to	O
occurring	O
during	O
image	B
acquisition	O
,	O
aliasing	B
can	O
also	O
be	O
introduced	O
in	O
var-	O
ious	O
image	B
processing	O
operations	O
,	O
such	O
as	O
resampling	O
,	O
upsampling	O
,	O
and	O
downsampling	O
.	O
sec-	O
tions	O
3.4	O
and	O
3.5.2	O
discuss	O
these	O
issues	O
and	O
show	O
how	O
careful	O
selection	O
of	O
ﬁlters	O
can	O
reduce	O
17	O
the	O
complex	O
fourier	O
transform	B
of	O
the	O
psf	O
is	O
actually	O
called	O
the	O
optical	O
transfer	O
function	O
(	O
otf	O
)	O
(	O
williams	O
1999	O
)	O
.	O
its	O
magnitude	O
is	O
called	O
the	O
modulation	O
transfer	B
function	O
(	O
mtf	O
)	O
and	O
its	O
phase	O
is	O
called	O
the	O
phase	O
transfer	O
function	O
(	O
ptf	O
)	O
.	O
80	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
2.26	O
sample	O
point	O
spread	O
functions	O
(	O
psf	O
)	O
:	O
the	O
diameter	O
of	O
the	O
blur	O
disc	O
(	O
blue	O
)	O
in	O
(	O
a	O
)	O
is	O
equal	O
to	O
half	O
the	O
pixel	O
spacing	O
,	O
while	O
the	O
diameter	O
in	O
(	O
c	O
)	O
is	O
twice	O
the	O
pixel	O
spacing	O
.	O
the	O
horizontal	O
ﬁll	O
factor	O
of	O
the	O
sensing	O
chip	O
is	O
80	O
%	O
and	O
is	O
shown	O
in	O
brown	O
.	O
the	O
convolution	O
of	O
these	O
two	O
kernels	O
gives	O
the	O
point	B
spread	I
function	I
,	O
shown	O
in	O
green	O
.	O
the	O
fourier	O
response	O
of	O
the	O
psf	O
(	O
the	O
mtf	O
)	O
is	O
plotted	O
in	O
(	O
b	O
)	O
and	O
(	O
d	O
)	O
.	O
the	O
area	O
above	O
the	O
nyquist	O
frequency	O
where	O
aliasing	B
occurs	O
is	O
shown	O
in	O
red	O
.	O
the	O
amount	O
of	O
aliasing	B
that	O
operations	O
inject	O
.	O
2.3.2	O
color	B
in	O
section	O
2.2	O
,	O
we	O
saw	O
how	O
lighting	B
and	O
surface	B
reﬂections	O
are	O
functions	O
of	O
wavelength	O
.	O
when	O
the	O
incoming	O
light	O
hits	O
the	O
imaging	O
sensor	B
,	O
light	O
from	O
different	O
parts	O
of	O
the	O
spectrum	O
is	O
somehow	O
integrated	O
into	O
the	O
discrete	B
red	O
,	O
green	O
,	O
and	O
blue	O
(	O
rgb	O
)	O
color	B
values	O
that	O
we	O
see	O
in	O
a	O
digital	O
image	O
.	O
how	O
does	O
this	O
process	O
work	O
and	O
how	O
can	O
we	O
analyze	O
and	O
manipulate	O
color	B
values	O
?	O
you	O
probably	O
recall	B
from	O
your	O
childhood	O
days	O
the	O
magical	O
process	O
of	O
mixing	O
paint	O
colors	O
to	O
obtain	O
new	O
ones	O
.	O
you	O
may	O
recall	B
that	O
blue+yellow	O
makes	O
green	O
,	O
red+blue	O
makes	O
purple	O
,	O
and	O
red+green	O
makes	O
brown	O
.	O
if	O
you	O
revisited	O
this	O
topic	O
at	O
a	O
later	O
age	O
,	O
you	O
may	O
have	O
learned	B
that	O
the	O
proper	O
subtractive	O
primaries	B
are	O
actually	O
cyan	O
(	O
a	O
light	O
blue-green	O
)	O
,	O
magenta	O
(	O
pink	O
)	O
,	O
and	O
yellow	O
(	O
figure	O
2.27b	O
)	O
,	O
although	O
black	O
is	O
also	O
often	O
used	O
in	O
four-color	O
printing	O
(	O
cmyk	O
)	O
.	O
(	O
if	O
you	O
ever	O
subsequently	O
took	O
any	O
painting	O
classes	O
,	O
you	O
learned	B
that	O
colors	O
can	O
have	O
even	O
0.00.20.40.60.81.0-1.4-1.2-1.0-0.8-0.6-0.4-0.20.00.20.40.60.81.01.21.40.00.20.40.60.81.0-2.0-1.5-1.0-0.50.00.51.01.52.00.00.20.40.60.81.0-1.4-1.2-1.0-0.8-0.6-0.4-0.20.00.20.40.60.81.01.21.40.00.20.40.60.81.0-2.0-1.5-1.0-0.50.00.51.01.52.0	O
2.3	O
the	O
digital	O
camera	O
81	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
2.27	O
primary	O
and	O
secondary	O
colors	O
:	O
(	O
a	O
)	O
additive	O
colors	O
red	O
,	O
green	O
,	O
and	O
blue	O
can	O
be	O
mixed	O
to	O
produce	O
cyan	O
,	O
magenta	O
,	O
yellow	O
,	O
and	O
white	O
;	O
(	O
b	O
)	O
subtractive	O
colors	O
cyan	O
,	O
magenta	O
,	O
and	O
yellow	O
can	O
be	O
mixed	O
to	O
produce	O
red	O
,	O
green	O
,	O
blue	O
,	O
and	O
black	O
.	O
more	O
fanciful	O
names	O
,	O
such	O
as	O
alizarin	O
crimson	O
,	O
cerulean	O
blue	O
,	O
and	O
chartreuse	O
.	O
)	O
the	O
subtractive	O
colors	O
are	O
called	O
subtractive	O
because	O
pigments	O
in	O
the	O
paint	O
absorb	O
certain	O
wavelengths	O
in	O
the	O
color	B
spectrum	O
.	O
later	O
on	O
,	O
you	O
may	O
have	O
learned	B
about	O
the	O
additive	O
primary	O
colors	O
(	O
red	O
,	O
green	O
,	O
and	O
blue	O
)	O
and	O
how	O
they	O
can	O
be	O
added	O
(	O
with	O
a	O
slide	O
projector	O
or	O
on	O
a	O
computer	O
monitor	O
)	O
to	O
produce	O
cyan	O
,	O
magenta	O
,	O
yellow	O
,	O
white	O
,	O
and	O
all	O
the	O
other	O
colors	O
we	O
typically	O
see	O
on	O
our	O
tv	O
sets	O
and	O
monitors	O
(	O
figure	O
2.27a	O
)	O
.	O
through	O
what	O
process	O
is	O
it	O
possible	O
for	O
two	O
different	O
colors	O
,	O
such	O
as	O
red	O
and	O
green	O
,	O
to	O
interact	O
to	O
produce	O
a	O
third	O
color	B
like	O
yellow	O
?	O
are	O
the	O
wavelengths	O
somehow	O
mixed	O
up	O
to	O
produce	O
a	O
new	O
wavelength	O
?	O
you	O
probably	O
know	O
that	O
the	O
correct	O
answer	O
has	O
nothing	O
to	O
do	O
with	O
physically	O
mixing	O
wavelengths	O
.	O
instead	O
,	O
the	O
existence	O
of	O
three	O
primaries	B
is	O
a	O
result	O
of	O
the	O
tri-stimulus	O
(	O
or	O
tri-	O
chromatic	O
)	O
nature	O
of	O
the	O
human	O
visual	O
system	O
,	O
since	O
we	O
have	O
three	O
different	O
kinds	O
of	O
cone	O
,	O
each	O
of	O
which	O
responds	O
selectively	O
to	O
a	O
different	O
portion	O
of	O
the	O
color	B
spectrum	O
(	O
glassner	O
1995	O
;	O
wyszecki	O
and	O
stiles	O
2000	O
;	O
fairchild	O
2005	O
;	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
2005	O
;	O
livingstone	O
2008	O
)	O
.18	O
note	O
that	O
for	O
machine	O
vision	O
applications	O
,	O
such	O
as	O
remote	O
sensing	O
and	O
terrain	O
clas-	O
siﬁcation	O
,	O
it	O
is	O
preferable	O
to	O
use	O
many	O
more	O
wavelengths	O
.	O
similarly	O
,	O
surveillance	O
applications	O
can	O
often	O
beneﬁt	O
from	O
sensing	O
in	O
the	O
near-infrared	O
(	O
nir	O
)	O
range	O
.	O
cie	O
rgb	O
and	O
xyz	O
to	O
test	O
and	O
quantify	O
the	O
tri-chromatic	O
theory	O
of	O
perception	O
,	O
we	O
can	O
attempt	O
to	O
reproduce	O
all	O
monochromatic	O
(	O
single	O
wavelength	O
)	O
colors	O
as	O
a	O
mixture	O
of	O
three	O
suitably	O
chosen	O
primaries	B
.	O
18	O
see	O
also	O
mark	O
fairchild	O
’	O
s	O
web	O
page	O
,	O
http	O
:	O
//www.cis.rit.edu/fairchild/whyiscolor/books	O
links.html	O
.	O
82	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
2.28	O
standard	O
cie	O
color	B
matching	O
functions	O
:	O
(	O
a	O
)	O
¯r	O
(	O
λ	O
)	O
,	O
¯g	O
(	O
λ	O
)	O
,	O
¯b	O
(	O
λ	O
)	O
color	B
spectra	O
obtained	O
from	O
matching	B
pure	O
colors	O
to	O
the	O
r=700.0nm	O
,	O
g=546.1nm	O
,	O
and	O
b=435.8nm	O
pri-	O
maries	O
;	O
(	O
b	O
)	O
¯x	O
(	O
λ	O
)	O
,	O
¯y	O
(	O
λ	O
)	O
,	O
¯z	O
(	O
λ	O
)	O
color	B
matching	O
functions	O
,	O
which	O
are	O
linear	B
combinations	O
of	O
the	O
(	O
¯r	O
(	O
λ	O
)	O
,	O
¯g	O
(	O
λ	O
)	O
,	O
¯b	O
(	O
λ	O
)	O
)	O
spectra	O
.	O
(	O
pure	O
wavelength	O
light	O
can	O
be	O
obtained	O
using	O
either	O
a	O
prism	O
or	O
specially	O
manufactured	O
color	B
ﬁlters	O
.	O
)	O
in	O
the	O
1930s	O
,	O
the	O
commission	O
internationale	O
d	O
’	O
eclairage	O
(	O
cie	O
)	O
standardized	O
the	O
rgb	O
representation	O
by	O
performing	O
such	O
color	B
matching	O
experiments	O
using	O
the	O
primary	O
colors	O
of	O
red	O
(	O
700.0nm	O
wavelength	O
)	O
,	O
green	O
(	O
546.1nm	O
)	O
,	O
and	O
blue	O
(	O
435.8nm	O
)	O
.	O
figure	O
2.28	O
shows	O
the	O
results	O
of	O
performing	O
these	O
experiments	O
with	O
a	O
standard	O
observer	O
,	O
i.e.	O
,	O
averaging	O
perceptual	O
results	O
over	O
a	O
large	O
number	O
of	O
subjects	O
.	O
you	O
will	O
notice	O
that	O
for	O
certain	O
pure	O
spectra	O
in	O
the	O
blue–green	O
range	O
,	O
a	O
negative	O
amount	O
of	O
red	O
light	O
has	O
to	O
be	O
added	O
,	O
i.e.	O
,	O
a	O
certain	O
amount	O
of	O
red	O
has	O
to	O
be	O
added	O
to	O
the	O
color	B
being	O
matched	O
in	O
order	B
to	O
get	O
a	O
color	B
match	O
.	O
these	O
results	O
also	O
provided	O
a	O
simple	O
explanation	O
for	O
the	O
existence	O
of	O
metamers	O
,	O
which	O
are	O
colors	O
with	O
different	O
spectra	O
that	O
are	O
perceptually	O
indistinguishable	O
.	O
note	O
that	O
two	O
fabrics	O
or	O
paint	O
colors	O
that	O
are	O
metamers	O
under	O
one	O
light	O
may	O
no	O
longer	O
be	O
so	O
under	O
different	O
lighting	B
.	O
because	O
of	O
the	O
problem	O
associated	O
with	O
mixing	O
negative	O
light	O
,	O
the	O
cie	O
also	O
developed	O
a	O
new	O
color	B
space	O
called	O
xyz	O
,	O
which	O
contains	O
all	O
of	O
the	O
pure	O
spectral	O
colors	O
within	O
its	O
positive	O
octant	O
.	O
(	O
it	O
also	O
maps	O
the	O
y	O
axis	O
to	O
the	O
luminance	O
,	O
i.e.	O
,	O
perceived	O
relative	O
brightness	O
,	O
and	O
maps	O
pure	O
white	O
to	O
a	O
diagonal	O
(	O
equal-valued	O
)	O
vector	O
.	O
)	O
the	O
transformation	O
from	O
rgb	O
to	O
xyz	O
is	O
given	O
by	O
x	O
y	O
z	O
	O
	O
=	O
1	O
0.17697	O
0.49	O
0.31	O
0.20	O
0.17697	O
0.81240	O
0.01063	O
0.00	O
0.01	O
0.99	O
	O
	O
r	O
g	O
b	O
	O
.	O
while	O
the	O
ofﬁcial	O
deﬁnition	O
of	O
the	O
cie	O
xyz	O
standard	O
has	O
the	O
matrix	O
normalized	O
so	O
that	O
the	O
y	O
value	O
corresponding	O
to	O
pure	O
red	O
is	O
1	O
,	O
a	O
more	O
commonly	O
used	O
form	O
is	O
to	O
omit	O
the	O
leading	O
(	O
2.103	O
)	O
-0.10.00.10.20.30.4360400440480520560600640680720760rgb0.00.20.40.60.81.01.21.41.61.82.0360400440480520560600640680720760xyz	O
2.3	O
the	O
digital	O
camera	O
83	O
figure	O
2.29	O
cie	O
chromaticity	O
diagram	O
,	O
showing	O
colors	O
and	O
their	O
corresponding	O
(	O
x	O
,	O
y	O
)	O
val-	O
ues	O
.	O
pure	O
spectral	O
colors	O
are	O
arranged	O
around	O
the	O
outside	O
of	O
the	O
curve	O
.	O
fraction	O
,	O
so	O
that	O
the	O
second	O
row	O
adds	O
up	O
to	O
one	O
,	O
i.e.	O
,	O
the	O
rgb	O
triplet	O
(	O
1	O
,	O
1	O
,	O
1	O
)	O
maps	O
to	O
a	O
y	O
value	O
of	O
1.	O
linearly	O
blending	B
the	O
(	O
¯r	O
(	O
λ	O
)	O
,	O
¯g	O
(	O
λ	O
)	O
,	O
¯b	O
(	O
λ	O
)	O
)	O
curves	O
in	O
figure	O
2.28a	O
according	O
to	O
(	O
2.103	O
)	O
,	O
we	O
obtain	O
the	O
resulting	O
(	O
¯x	O
(	O
λ	O
)	O
,	O
¯y	O
(	O
λ	O
)	O
,	O
¯z	O
(	O
λ	O
)	O
)	O
curves	O
shown	O
in	O
figure	O
2.28b	O
.	O
notice	O
how	O
all	O
three	O
spectra	O
(	O
color	B
matching	O
functions	O
)	O
now	O
have	O
only	O
positive	O
values	O
and	O
how	O
the	O
¯y	O
(	O
λ	O
)	O
curve	O
matches	O
that	O
of	O
the	O
luminance	O
perceived	O
by	O
humans	O
.	O
if	O
we	O
divide	O
the	O
xyz	O
values	O
by	O
the	O
sum	O
of	O
x+y+z	O
,	O
we	O
obtain	O
the	O
chromaticity	O
coordi-	O
nates	O
x	O
=	O
x	O
x	O
+	O
y	O
+	O
z	O
,	O
y	O
=	O
y	O
x	O
+	O
y	O
+	O
z	O
,	O
z	O
=	O
z	O
x	O
+	O
y	O
+	O
z	O
,	O
(	O
2.104	O
)	O
which	O
sum	O
up	O
to	O
1.	O
the	O
chromaticity	O
coordinates	O
discard	O
the	O
absolute	O
intensity	O
of	O
a	O
given	O
color	B
sample	O
and	O
just	O
represent	O
its	O
pure	O
color	O
.	O
if	O
we	O
sweep	O
the	O
monochromatic	O
color	B
λ	O
pa-	O
rameter	O
in	O
figure	O
2.28b	O
from	O
λ	O
=	O
380nm	O
to	O
λ	O
=	O
800nm	O
,	O
we	O
obtain	O
the	O
familiar	O
chromaticity	O
diagram	O
shown	O
in	O
figure	O
2.29.	O
this	O
ﬁgure	O
shows	O
the	O
(	O
x	O
,	O
y	O
)	O
value	O
for	O
every	O
color	B
value	O
per-	O
ceivable	O
by	O
most	O
humans	O
.	O
(	O
of	O
course	O
,	O
the	O
cmyk	O
reproduction	O
process	O
in	O
this	O
book	O
does	O
not	O
actually	O
span	O
the	O
whole	O
gamut	O
of	O
perceivable	O
colors	O
.	O
)	O
the	O
outer	O
curved	O
rim	O
represents	O
where	O
all	O
of	O
the	O
pure	O
monochromatic	O
color	B
values	O
map	O
in	O
(	O
x	O
,	O
y	O
)	O
space	O
,	O
while	O
the	O
lower	O
straight	O
line	O
,	O
which	O
connects	O
the	O
two	O
endpoints	O
,	O
is	O
known	O
as	O
the	O
purple	O
line	O
.	O
a	O
convenient	O
representation	O
for	O
color	O
values	O
,	O
when	O
we	O
want	O
to	O
tease	O
apart	O
luminance	O
and	O
chromaticity	O
,	O
is	O
therefore	O
yxy	O
(	O
luminance	O
plus	O
the	O
two	O
most	O
distinctive	O
chrominance	O
components	O
)	O
.	O
l*a*b*	O
color	B
space	O
while	O
the	O
xyz	O
color	B
space	O
has	O
many	O
convenient	O
properties	B
,	O
including	O
the	O
ability	O
to	O
separate	O
luminance	O
from	O
chrominance	O
,	O
it	O
does	O
not	O
actually	O
predict	O
how	O
well	O
humans	O
perceive	O
differ-	O
ences	O
in	O
color	B
or	O
luminance	O
.	O
84	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
because	O
the	O
response	O
of	O
the	O
human	O
visual	O
system	O
is	O
roughly	O
logarithmic	O
(	O
we	O
can	O
perceive	O
relative	O
luminance	O
differences	O
of	O
about	O
1	O
%	O
)	O
,	O
the	O
cie	O
deﬁned	O
a	O
non-linear	B
re-mapping	O
of	O
the	O
xyz	O
space	O
called	O
l*a*b*	O
(	O
also	O
sometimes	O
called	O
cielab	O
)	O
,	O
where	O
differences	O
in	O
luminance	O
or	O
chrominance	O
are	O
more	O
perceptually	O
uniform.19	O
the	O
l*	O
component	O
of	O
lightness	O
is	O
deﬁned	O
as	O
yn	O
(	O
cid:19	O
)	O
,	O
l∗	O
=	O
116f	O
(	O
cid:18	O
)	O
y	O
where	O
yn	O
is	O
the	O
luminance	O
value	O
for	O
nominal	O
white	O
(	O
fairchild	O
2005	O
)	O
and	O
f	O
(	O
t	O
)	O
=	O
(	O
cid:40	O
)	O
t1/3	O
t/	O
(	O
3δ2	O
)	O
+	O
2δ/3	O
t	O
>	O
δ3	O
else	O
,	O
(	O
2.105	O
)	O
(	O
2.106	O
)	O
is	O
a	O
ﬁnite-slope	O
approximation	O
to	O
the	O
cube	O
root	O
with	O
δ	O
=	O
6/29	O
.	O
the	O
resulting	O
0	O
.	O
.	O
.	O
100	O
scale	O
roughly	O
measures	O
equal	O
amounts	O
of	O
lightness	O
perceptibility	O
.	O
in	O
a	O
similar	O
fashion	O
,	O
the	O
a*	O
and	O
b*	O
components	O
are	O
deﬁned	O
as	O
a∗	O
=	O
500	O
(	O
cid:20	O
)	O
f	O
(	O
cid:18	O
)	O
x	O
xn	O
(	O
cid:19	O
)	O
−	O
f	O
(	O
cid:18	O
)	O
y	O
yn	O
(	O
cid:19	O
)	O
(	O
cid:21	O
)	O
and	O
b∗	O
=	O
200	O
(	O
cid:20	O
)	O
f	O
(	O
cid:18	O
)	O
y	O
yn	O
(	O
cid:19	O
)	O
−	O
f	O
(	O
cid:18	O
)	O
z	O
zn	O
(	O
cid:19	O
)	O
(	O
cid:21	O
)	O
,	O
(	O
2.107	O
)	O
where	O
again	O
,	O
(	O
xn	O
,	O
yn	O
,	O
zn	O
)	O
is	O
the	O
measured	O
white	O
point	O
.	O
figure	O
2.32i–k	O
show	O
the	O
l*a*b*	O
representation	O
for	O
a	O
sample	O
color	B
image	O
.	O
color	B
cameras	O
while	O
the	O
preceding	O
discussion	O
tells	O
us	O
how	O
we	O
can	O
uniquely	O
describe	O
the	O
perceived	O
tri-	O
stimulus	O
description	O
of	O
any	O
color	B
(	O
spectral	O
distribution	O
)	O
,	O
it	O
does	O
not	O
tell	O
us	O
how	O
rgb	O
still	O
and	O
video	B
cameras	O
actually	O
work	O
.	O
do	O
they	O
just	O
measure	O
the	O
amount	O
of	O
light	O
at	O
the	O
nominal	O
wavelengths	O
of	O
red	O
(	O
700.0nm	O
)	O
,	O
green	O
(	O
546.1nm	O
)	O
,	O
and	O
blue	O
(	O
435.8nm	O
)	O
?	O
do	O
color	B
monitors	O
just	O
emit	O
exactly	O
these	O
wavelengths	O
and	O
,	O
if	O
so	O
,	O
how	O
can	O
they	O
emit	O
negative	O
red	O
light	O
to	O
reproduce	O
colors	O
in	O
the	O
cyan	O
range	O
?	O
in	O
fact	O
,	O
the	O
design	O
of	O
rgb	O
video	B
cameras	O
has	O
historically	O
been	O
based	O
around	O
the	O
availabil-	O
ity	O
of	O
colored	O
phosphors	O
that	O
go	O
into	O
television	O
sets	O
.	O
when	O
standard-deﬁnition	O
color	B
television	O
was	O
invented	O
(	O
ntsc	O
)	O
,	O
a	O
mapping	O
was	O
deﬁned	O
between	O
the	O
rgb	O
values	O
that	O
would	O
drive	O
the	O
three	O
color	B
guns	O
in	O
the	O
cathode	O
ray	O
tube	O
(	O
crt	O
)	O
and	O
the	O
xyz	O
values	O
that	O
unambiguously	O
de-	O
ﬁne	O
perceived	O
color	B
(	O
this	O
standard	O
was	O
called	O
itu-r	O
bt.601	O
)	O
.	O
with	O
the	O
advent	O
of	O
hdtv	O
and	O
newer	O
monitors	O
,	O
a	O
new	O
standard	O
called	O
itu-r	O
bt.709	O
was	O
created	O
,	O
which	O
speciﬁes	O
the	O
xyz	O
19	O
another	O
perceptually	O
motivated	O
color	B
space	O
called	O
l*u*v*	O
was	O
developed	O
and	O
standardized	O
simultaneously	O
(	O
fairchild	O
2005	O
)	O
.	O
2.3	O
the	O
digital	O
camera	O
values	O
of	O
each	O
of	O
the	O
color	B
primaries	O
,	O
x	O
y	O
z	O
	O
	O
=	O
85	O
(	O
2.108	O
)	O
0.412453	O
0.357580	O
0.180423	O
0.212671	O
0.715160	O
0.072169	O
0.019334	O
0.119193	O
0.950227	O
	O
	O
r709	O
g709	O
b709	O
	O
.	O
in	O
practice	O
,	O
each	O
color	B
camera	O
integrates	O
light	O
according	O
to	O
the	O
spectral	O
response	O
function	O
of	O
its	O
red	O
,	O
green	O
,	O
and	O
blue	O
sensors	O
,	O
r	O
=	O
(	O
cid:90	O
)	O
l	O
(	O
λ	O
)	O
sr	O
(	O
λ	O
)	O
dλ	O
,	O
g	O
=	O
(	O
cid:90	O
)	O
l	O
(	O
λ	O
)	O
sg	O
(	O
λ	O
)	O
dλ	O
,	O
b	O
=	O
(	O
cid:90	O
)	O
l	O
(	O
λ	O
)	O
sb	O
(	O
λ	O
)	O
dλ	O
,	O
(	O
2.109	O
)	O
where	O
l	O
(	O
λ	O
)	O
is	O
the	O
incoming	O
spectrum	O
of	O
light	O
at	O
a	O
given	O
pixel	O
and	O
{	O
sr	O
(	O
λ	O
)	O
,	O
sg	O
(	O
λ	O
)	O
,	O
sb	O
(	O
λ	O
)	O
}	O
are	O
the	O
red	O
,	O
green	O
,	O
and	O
blue	O
spectral	O
sensitivities	O
of	O
the	O
corresponding	O
sensors	O
.	O
can	O
we	O
tell	O
what	O
spectral	O
sensitivities	O
the	O
cameras	O
actually	O
have	O
?	O
unless	O
the	O
camera	B
manufacturer	O
provides	O
us	O
with	O
this	O
data	O
or	O
we	O
observe	O
the	O
response	O
of	O
the	O
camera	B
to	O
a	O
whole	O
spectrum	O
of	O
monochromatic	O
lights	O
,	O
these	O
sensitivities	O
are	O
not	O
speciﬁed	O
by	O
a	O
standard	O
such	O
as	O
bt.709	O
.	O
instead	O
,	O
all	O
that	O
matters	O
is	O
that	O
the	O
tri-stimulus	O
values	O
for	O
a	O
given	O
color	B
produce	O
the	O
speciﬁed	O
rgb	O
values	O
.	O
the	O
manufacturer	O
is	O
free	O
to	O
use	O
sensors	O
with	O
sensitivities	O
that	O
do	O
not	O
match	O
the	O
standard	O
xyz	O
deﬁnitions	O
,	O
so	O
long	O
as	O
they	O
can	O
later	O
be	O
converted	O
(	O
through	O
a	O
linear	B
transform	O
)	O
to	O
the	O
standard	O
colors	O
.	O
similarly	O
,	O
while	O
tv	O
and	O
computer	O
monitors	O
are	O
supposed	O
to	O
produce	O
rgb	O
values	O
as	O
spec-	O
iﬁed	O
by	O
equation	O
(	O
2.108	O
)	O
,	O
there	O
is	O
no	O
reason	O
that	O
they	O
can	O
not	O
use	O
digital	O
logic	O
to	O
transform	B
the	O
incoming	O
rgb	O
values	O
into	O
different	O
signals	O
to	O
drive	O
each	O
of	O
the	O
color	B
channels	O
.	O
properly	O
cal-	O
ibrated	O
monitors	O
make	O
this	O
information	O
available	O
to	O
software	O
applications	O
that	O
perform	O
color	B
management	O
,	O
so	O
that	O
colors	O
in	O
real	O
life	O
,	O
on	O
the	O
screen	O
,	O
and	O
on	O
the	O
printer	O
all	O
match	O
as	O
closely	O
as	O
possible	O
.	O
color	O
ﬁlter	O
arrays	O
while	O
early	O
color	B
tv	O
cameras	O
used	O
three	O
vidicons	O
(	O
tubes	O
)	O
to	O
perform	O
their	O
sensing	O
and	O
later	O
cameras	O
used	O
three	O
separate	O
rgb	O
sensing	O
chips	O
,	O
most	O
of	O
today	O
’	O
s	O
digital	O
still	O
and	O
video	B
cam-	O
eras	O
cameras	O
use	O
a	O
color	O
ﬁlter	O
array	O
(	O
cfa	O
)	O
,	O
where	O
alternating	O
sensors	O
are	O
covered	O
by	O
different	O
colored	O
ﬁlters.20	O
20	O
a	O
newer	O
chip	O
design	O
by	O
foveon	O
(	O
http	O
:	O
//www.foveon.com	O
)	O
stacks	O
the	O
red	O
,	O
green	O
,	O
and	O
blue	O
sensors	O
beneath	O
each	O
other	O
,	O
but	O
it	O
has	O
not	O
yet	O
gained	O
widespread	O
adoption	O
.	O
86	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.30	O
bayer	O
rgb	O
pattern	O
:	O
(	O
a	O
)	O
color	O
ﬁlter	O
array	O
layout	O
;	O
(	O
b	O
)	O
interpolated	O
pixel	O
values	O
,	O
with	O
unknown	O
(	O
guessed	O
)	O
values	O
shown	O
as	O
lower	O
case	O
.	O
the	O
most	O
commonly	O
used	O
pattern	O
in	O
color	B
cameras	O
today	O
is	O
the	O
bayer	O
pattern	O
(	O
bayer	O
1976	O
)	O
,	O
which	O
places	O
green	O
ﬁlters	O
over	O
half	O
of	O
the	O
sensors	O
(	O
in	O
a	O
checkerboard	O
pattern	O
)	O
,	O
and	O
red	O
and	O
blue	O
ﬁlters	O
over	O
the	O
remaining	O
ones	O
(	O
figure	O
2.30	O
)	O
.	O
the	O
reason	O
that	O
there	O
are	O
twice	O
as	O
many	O
green	O
ﬁlters	O
as	O
red	O
and	O
blue	O
is	O
because	O
the	O
luminance	O
signal	O
is	O
mostly	O
determined	O
by	O
green	O
values	O
and	O
the	O
visual	O
system	O
is	O
much	O
more	O
sensitive	O
to	O
high	O
frequency	O
detail	O
in	O
luminance	O
than	O
in	O
chrominance	O
(	O
a	O
fact	O
that	O
is	O
exploited	O
in	O
color	B
image	O
compression—see	O
section	O
2.3.3	O
)	O
.	O
the	O
process	O
of	O
interpolating	O
the	O
missing	O
color	O
values	O
so	O
that	O
we	O
have	O
valid	O
rgb	O
values	O
for	O
all	O
the	O
pixels	O
is	O
known	O
as	O
demosaicing	B
and	O
is	O
covered	O
in	O
detail	O
in	O
section	O
10.3.1.	O
similarly	O
,	O
color	B
lcd	O
monitors	O
typically	O
use	O
alternating	O
stripes	O
of	O
red	O
,	O
green	O
,	O
and	O
blue	O
ﬁlters	O
placed	O
in	O
front	O
of	O
each	O
liquid	O
crystal	O
active	O
area	O
to	O
simulate	O
the	O
experience	O
of	O
a	O
full	O
color	B
display	O
.	O
as	O
before	O
,	O
because	O
the	O
visual	O
system	O
has	O
higher	O
resolution	O
(	O
acuity	O
)	O
in	O
luminance	O
than	O
chrominance	O
,	O
it	O
is	O
possible	O
to	O
digitally	O
pre-ﬁlter	O
rgb	O
(	O
and	O
monochrome	O
)	O
images	O
to	O
enhance	O
the	O
perception	O
of	O
crispness	O
(	O
betrisey	O
,	O
blinn	O
,	O
dresevic	O
et	O
al	O
.	O
2000	O
;	O
platt	O
2000	O
)	O
.	O
color	B
balance	I
before	O
encoding	O
the	O
sensed	O
rgb	O
values	O
,	O
most	O
cameras	O
perform	O
some	O
kind	O
of	O
color	B
balancing	O
operation	O
in	O
an	O
attempt	O
to	O
move	O
the	O
white	O
point	O
of	O
a	O
given	O
image	B
closer	O
to	O
pure	O
white	O
(	O
equal	O
rgb	O
values	O
)	O
.	O
if	O
the	O
color	B
system	O
and	O
the	O
illumination	O
are	O
the	O
same	O
(	O
the	O
bt.709	O
system	O
uses	O
the	O
daylight	O
illuminant	O
d65	O
as	O
its	O
reference	O
white	O
)	O
,	O
the	O
change	O
may	O
be	O
minimal	O
.	O
however	O
,	O
if	O
the	O
illuminant	O
is	O
strongly	O
colored	O
,	O
such	O
as	O
incandescent	O
indoor	O
lighting	B
(	O
which	O
generally	O
results	O
in	O
a	O
yellow	O
or	O
orange	O
hue	B
)	O
,	O
the	O
compensation	O
can	O
be	O
quite	O
signiﬁcant	O
.	O
a	O
simple	O
way	O
to	O
perform	O
color	B
correction	O
is	O
to	O
multiply	O
each	O
of	O
the	O
rgb	O
values	O
by	O
a	O
different	O
factor	O
(	O
i.e.	O
,	O
to	O
apply	O
a	O
diagonal	O
matrix	O
transform	O
to	O
the	O
rgb	O
color	B
space	O
)	O
.	O
more	O
complicated	O
transforms	O
,	O
which	O
are	O
sometimes	O
the	O
result	O
of	O
mapping	O
to	O
xyz	O
space	O
and	O
back	O
,	O
(	O
a	O
)	O
(	O
b	O
)	O
rgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbbgbggrgrgbgrgrbg	O
2.3	O
the	O
digital	O
camera	O
87	O
figure	O
2.31	O
gamma	B
compression	O
:	O
(	O
a	O
)	O
the	O
relationship	O
between	O
the	O
input	O
signal	O
luminance	O
y	O
and	O
the	O
transmitted	O
signal	O
y	O
(	O
cid:48	O
)	O
is	O
given	O
by	O
y	O
(	O
cid:48	O
)	O
=	O
y	O
1/γ	O
.	O
(	O
b	O
)	O
at	O
the	O
receiver	O
,	O
the	O
signal	O
y	O
(	O
cid:48	O
)	O
is	O
exponentiated	O
by	O
the	O
factor	O
γ	O
,	O
ˆy	O
=	O
y	O
(	O
cid:48	O
)	O
γ.	O
noise	B
introduced	O
during	O
transmission	O
is	O
squashed	O
in	O
the	O
dark	O
regions	O
,	O
which	O
corresponds	O
to	O
the	O
more	O
noise-sensitive	O
region	B
of	O
the	O
visual	O
system	O
.	O
actually	O
perform	O
a	O
color	B
twist	O
,	O
i.e.	O
,	O
they	O
use	O
a	O
general	O
3	O
×	O
3	O
color	B
transform	O
matrix.21	O
exer-	O
cise	O
2.9	O
has	O
you	O
explore	O
some	O
of	O
these	O
issues	O
.	O
gamma	B
in	O
the	O
early	O
days	O
of	O
black	O
and	O
white	O
television	O
,	O
the	O
phosphors	O
in	O
the	O
crt	O
used	O
to	O
display	O
the	O
tv	O
signal	O
responded	O
non-linearly	O
to	O
their	O
input	O
voltage	O
.	O
the	O
relationship	O
between	O
the	O
voltage	O
and	O
the	O
resulting	O
brightness	O
was	O
characterized	O
by	O
a	O
number	O
called	O
gamma	B
(	O
γ	O
)	O
,	O
since	O
the	O
formula	O
was	O
roughly	O
b	O
=	O
v	O
γ	O
,	O
(	O
2.110	O
)	O
with	O
a	O
γ	O
of	O
about	O
2.2.	O
to	O
compensate	O
for	O
this	O
effect	O
,	O
the	O
electronics	O
in	O
the	O
tv	O
camera	B
would	O
pre-map	O
the	O
sensed	O
luminance	O
y	O
through	O
an	O
inverse	B
gamma	O
,	O
y	O
(	O
cid:48	O
)	O
=	O
y	O
1	O
γ	O
,	O
(	O
2.111	O
)	O
with	O
a	O
typical	O
value	O
of	O
1	O
γ	O
=	O
0.45.	O
the	O
mapping	O
of	O
the	O
signal	O
through	O
this	O
non-linearity	O
before	O
transmission	O
had	O
a	O
beneﬁcial	O
side	O
effect	O
:	O
noise	B
added	O
during	O
transmission	O
(	O
remember	O
,	O
these	O
were	O
analog	O
days	O
!	O
)	O
would	O
be	O
reduced	O
(	O
after	O
applying	O
the	O
gamma	B
at	O
the	O
receiver	O
)	O
in	O
the	O
darker	O
regions	O
of	O
the	O
signal	O
where	O
it	O
was	O
more	O
visible	O
(	O
figure	O
2.31	O
)	O
.22	O
(	O
remember	O
that	O
our	O
visual	O
system	O
is	O
roughly	O
sensitive	O
to	O
relative	O
differences	O
in	O
luminance	O
.	O
)	O
21	O
those	O
of	O
you	O
old	O
enough	O
to	O
remember	O
the	O
early	O
days	O
of	O
color	B
television	O
will	O
naturally	O
think	O
of	O
the	O
hue	B
adjustment	O
knob	O
on	O
the	O
television	O
set	O
,	O
which	O
could	O
produce	O
truly	O
bizarre	O
results	O
.	O
22	O
a	O
related	O
technique	O
called	O
companding	O
was	O
the	O
basis	O
of	O
the	O
dolby	O
noise	B
reduction	O
systems	O
used	O
with	O
audio	O
tapes	O
.	O
yy	O
’	O
y	O
’	O
=	O
y1/γy	O
’	O
yy	O
=	O
y	O
’	O
γquantization	O
noisevisible	O
noise	B
88	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
when	O
color	B
television	O
was	O
invented	O
,	O
it	O
was	O
decided	O
to	O
separately	O
pass	O
the	O
red	O
,	O
green	O
,	O
and	O
blue	O
signals	O
through	O
the	O
same	O
gamma	B
non-linearity	O
before	O
combining	O
them	O
for	O
encoding	O
.	O
today	O
,	O
even	O
though	O
we	O
no	O
longer	O
have	O
analog	O
noise	B
in	O
our	O
transmission	O
systems	O
,	O
signals	O
are	O
still	O
quantized	O
during	O
compression	B
(	O
see	O
section	O
2.3.3	O
)	O
,	O
so	O
applying	O
inverse	B
gamma	O
to	O
sensed	O
values	O
is	O
still	O
useful	O
.	O
unfortunately	O
,	O
for	O
both	O
computer	O
vision	O
and	O
computer	O
graphics	O
,	O
the	O
presence	O
of	O
gamma	B
in	O
images	O
is	O
often	O
problematic	O
.	O
for	O
example	O
,	O
the	O
proper	O
simulation	O
of	O
radiometric	B
phenomena	O
such	O
as	O
shading	B
(	O
see	O
section	O
2.2	O
and	O
equation	B
(	O
2.87	O
)	O
)	O
occurs	O
in	O
a	O
linear	B
radiance	O
space	O
.	O
once	O
all	O
of	O
the	O
computations	O
have	O
been	O
performed	O
,	O
the	O
appropriate	O
gamma	B
should	O
be	O
applied	O
before	O
display	O
.	O
unfortunately	O
,	O
many	O
computer	O
graphics	O
systems	O
(	O
such	O
as	O
shading	B
models	O
)	O
operate	O
directly	O
on	O
rgb	O
values	O
and	O
display	O
these	O
values	O
directly	O
.	O
(	O
fortunately	O
,	O
newer	O
color	B
imaging	O
standards	O
such	O
as	O
the	O
16-bit	O
scrgb	O
use	O
a	O
linear	B
space	O
,	O
which	O
makes	O
this	O
less	O
of	O
a	O
problem	O
(	O
glassner	O
1995	O
)	O
.	O
)	O
in	O
computer	O
vision	O
,	O
the	O
situation	O
can	O
be	O
even	O
more	O
daunting	O
.	O
the	O
accurate	O
determination	O
of	O
surface	B
normals	O
,	O
using	O
a	O
technique	O
such	O
as	O
photometric	B
stereo	I
(	O
section	O
12.1.1	O
)	O
or	O
even	O
a	O
simpler	O
operation	O
such	O
as	O
accurate	O
image	B
deblurring	O
,	O
require	O
that	O
the	O
measurements	O
be	O
in	O
a	O
linear	B
space	O
of	O
intensities	O
.	O
therefore	O
,	O
it	O
is	O
imperative	O
when	O
performing	O
detailed	O
quantitative	O
computations	O
such	O
as	O
these	O
to	O
ﬁrst	O
undo	O
the	O
gamma	B
and	O
the	O
per-image	O
color	B
re-balancing	O
in	O
the	O
sensed	O
color	B
values	O
.	O
chakrabarti	O
,	O
scharstein	O
,	O
and	O
zickler	O
(	O
2009	O
)	O
develop	O
a	O
sophisti-	O
cated	O
24-parameter	O
model	O
that	O
is	O
a	O
good	O
match	O
to	O
the	O
processing	O
performed	O
by	O
today	O
’	O
s	O
digital	O
cameras	O
;	O
they	O
also	O
provide	O
a	O
database	O
of	O
color	B
images	O
you	O
can	O
use	O
for	O
your	O
own	O
testing.23	O
for	O
other	O
vision	O
applications	O
,	O
however	O
,	O
such	O
as	O
feature	B
detection	O
or	O
the	O
matching	B
of	O
sig-	O
nals	O
in	O
stereo	B
and	O
motion	B
estimation	I
,	O
this	O
linearization	O
step	O
is	O
often	O
not	O
necessary	O
.	O
in	O
fact	O
,	O
determining	O
whether	O
it	O
is	O
necessary	O
to	O
undo	O
gamma	B
can	O
take	O
some	O
careful	O
thinking	O
,	O
e.g.	O
,	O
in	O
the	O
case	O
of	O
compensating	O
for	O
exposure	O
variations	O
in	O
image	B
stitching	I
(	O
see	O
exercise	O
2.7	O
)	O
.	O
if	O
all	O
of	O
these	O
processing	O
steps	O
sound	O
confusing	O
to	O
model	O
,	O
they	O
are	O
.	O
exercise	O
2.10	O
has	O
you	O
try	O
to	O
tease	O
apart	O
some	O
of	O
these	O
phenomena	O
using	O
empirical	O
investigation	O
,	O
i.e.	O
,	O
taking	O
pictures	O
of	O
color	B
charts	O
and	O
comparing	O
the	O
raw	O
and	O
jpeg	O
compressed	O
color	O
values	O
.	O
other	O
color	B
spaces	O
while	O
rgb	O
and	O
xyz	O
are	O
the	O
primary	O
color	B
spaces	O
used	O
to	O
describe	O
the	O
spectral	O
content	O
(	O
and	O
hence	O
tri-stimulus	O
response	O
)	O
of	O
color	B
signals	O
,	O
a	O
variety	O
of	O
other	O
representations	O
have	O
been	O
developed	O
both	O
in	O
video	B
and	O
still	O
image	B
coding	O
and	O
in	O
computer	O
graphics	O
.	O
the	O
earliest	O
color	B
representation	O
developed	O
for	O
video	O
transmission	O
was	O
the	O
yiq	O
standard	O
developed	O
for	O
ntsc	O
video	B
in	O
north	O
america	O
and	O
the	O
closely	O
related	O
yuv	O
standard	O
developed	O
for	O
pal	O
in	O
europe	O
.	O
in	O
both	O
of	O
these	O
cases	O
,	O
it	O
was	O
desired	O
to	O
have	O
a	O
luma	O
channel	O
y	O
(	O
so	O
called	O
23	O
http	O
:	O
//vision.middlebury.edu/color/	O
.	O
2.3	O
the	O
digital	O
camera	O
89	O
since	O
it	O
only	O
roughly	O
mimics	O
true	O
luminance	O
)	O
that	O
would	O
be	O
comparable	O
to	O
the	O
regular	O
black-	O
and-white	O
tv	O
signal	O
,	O
along	O
with	O
two	O
lower	O
frequency	O
chroma	O
channels	O
.	O
in	O
both	O
systems	O
,	O
the	O
y	O
signal	O
(	O
or	O
more	O
appropriately	O
,	O
the	O
y	O
’	O
luma	O
signal	O
since	O
it	O
is	O
gamma	B
compressed	O
)	O
is	O
obtained	O
from	O
y	O
(	O
cid:48	O
)	O
601	O
=	O
0.299r	O
(	O
cid:48	O
)	O
+	O
0.587g	O
(	O
cid:48	O
)	O
+	O
0.114b	O
(	O
cid:48	O
)	O
,	O
(	O
2.112	O
)	O
where	O
r	O
’	O
g	O
’	O
b	O
’	O
is	O
the	O
triplet	O
of	O
gamma-compressed	O
color	B
components	O
.	O
when	O
using	O
the	O
newer	O
color	B
deﬁnitions	O
for	O
hdtv	O
in	O
bt.709	O
,	O
the	O
formula	O
is	O
y	O
(	O
cid:48	O
)	O
709	O
=	O
0.2125r	O
(	O
cid:48	O
)	O
+	O
0.7154g	O
(	O
cid:48	O
)	O
+	O
0.0721b	O
(	O
cid:48	O
)	O
.	O
(	O
2.113	O
)	O
the	O
uv	O
components	O
are	O
derived	O
from	O
scaled	O
versions	O
of	O
(	O
b	O
(	O
cid:48	O
)	O
−y	O
(	O
cid:48	O
)	O
)	O
and	O
(	O
r	O
(	O
cid:48	O
)	O
−y	O
(	O
cid:48	O
)	O
)	O
,	O
namely	O
,	O
(	O
2.114	O
)	O
u	O
=	O
0.492111	O
(	O
b	O
(	O
cid:48	O
)	O
−	O
y	O
(	O
cid:48	O
)	O
)	O
and	O
v	O
=	O
0.877283	O
(	O
r	O
(	O
cid:48	O
)	O
−	O
y	O
(	O
cid:48	O
)	O
)	O
,	O
in	O
whereas	O
the	O
iq	O
components	O
are	O
the	O
uv	O
components	O
rotated	O
through	O
an	O
angle	O
of	O
33◦	O
.	O
composite	O
(	O
ntsc	O
and	O
pal	O
)	O
video	B
,	O
the	O
chroma	O
signals	O
were	O
then	O
low-pass	B
ﬁltered	O
horizon-	O
tally	O
before	O
being	O
modulated	O
and	O
superimposed	O
on	O
top	O
of	O
the	O
y	O
’	O
luma	O
signal	O
.	O
backward	O
compatibility	O
was	O
achieved	O
by	O
having	O
older	O
black-and-white	O
tv	O
sets	O
effectively	O
ignore	O
the	O
high-frequency	O
chroma	O
signal	O
(	O
because	O
of	O
slow	O
electronics	O
)	O
or	O
,	O
at	O
worst	O
,	O
superimposing	O
it	O
as	O
a	O
high-frequency	O
pattern	O
on	O
top	O
of	O
the	O
main	O
signal	O
.	O
while	O
these	O
conversions	O
were	O
important	O
in	O
the	O
early	O
days	O
of	O
computer	O
vision	O
,	O
when	O
frame	O
grabbers	O
would	O
directly	O
digitize	O
the	O
composite	O
tv	O
signal	O
,	O
today	O
all	O
digital	O
video	O
and	O
still	O
image	B
compression	O
standards	O
are	O
based	O
on	O
the	O
newer	O
ycbcr	O
conversion	O
.	O
ycbcr	O
is	O
closely	O
related	O
to	O
yuv	O
(	O
the	O
cb	O
and	O
cr	O
signals	O
carry	O
the	O
blue	O
and	O
red	O
color	B
difference	O
signals	O
and	O
have	O
more	O
useful	O
mnemonics	O
than	O
uv	O
)	O
but	O
uses	O
different	O
scale	O
factors	O
to	O
ﬁt	O
within	O
the	O
eight-bit	O
range	O
available	O
with	O
digital	O
signals	O
.	O
for	O
video	O
,	O
the	O
y	O
’	O
signal	O
is	O
re-scaled	O
to	O
ﬁt	O
within	O
the	O
[	O
16	O
.	O
.	O
.	O
235	O
]	O
range	O
of	O
values	O
,	O
while	O
the	O
cb	O
and	O
cr	O
signals	O
are	O
scaled	O
to	O
ﬁt	O
within	O
[	O
16	O
.	O
.	O
.	O
240	O
]	O
(	O
gomes	O
and	O
velho	O
1997	O
;	O
fairchild	O
2005	O
)	O
.	O
for	O
still	O
images	O
,	O
the	O
jpeg	O
standard	O
uses	O
the	O
full	O
eight-bit	O
range	O
with	O
no	O
reserved	O
values	O
,	O
y	O
(	O
cid:48	O
)	O
cb	O
cr	O
	O
	O
=	O
0.299	O
0.587	O
−0.168736	O
−0.331264	O
0.5	O
0.114	O
0.5	O
−0.418688	O
−0.081312	O
	O
	O
r	O
(	O
cid:48	O
)	O
g	O
(	O
cid:48	O
)	O
b	O
(	O
cid:48	O
)	O
	O
+	O
0	O
128	O
128	O
	O
,	O
(	O
2.115	O
)	O
where	O
the	O
r	O
’	O
g	O
’	O
b	O
’	O
values	O
are	O
the	O
eight-bit	O
gamma-compressed	O
color	B
components	O
(	O
i.e.	O
,	O
the	O
actual	O
rgb	O
values	O
we	O
obtain	O
when	O
we	O
open	O
up	O
or	O
display	O
a	O
jpeg	O
image	B
)	O
.	O
for	O
most	O
appli-	O
cations	O
,	O
this	O
formula	O
is	O
not	O
that	O
important	O
,	O
since	O
your	O
image	B
reading	O
software	O
will	O
directly	O
90	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
provide	O
you	O
with	O
the	O
eight-bit	O
gamma-compressed	O
r	O
’	O
g	O
’	O
b	O
’	O
values	O
.	O
however	O
,	O
if	O
you	O
are	O
trying	O
to	O
do	O
careful	O
image	B
deblocking	O
(	O
exercise	O
3.30	O
)	O
,	O
this	O
information	O
may	O
be	O
useful	O
.	O
another	O
color	B
space	O
you	O
may	O
come	O
across	O
is	O
hue	B
,	O
saturation	O
,	O
value	O
(	O
hsv	O
)	O
,	O
which	O
is	O
a	O
pro-	O
jection	O
of	O
the	O
rgb	O
color	B
cube	O
onto	O
a	O
non-linear	B
chroma	O
angle	O
,	O
a	O
radial	B
saturation	O
percentage	O
,	O
and	O
a	O
luminance-inspired	O
value	O
.	O
in	O
more	O
detail	O
,	O
value	O
is	O
deﬁned	O
as	O
either	O
the	O
mean	O
or	O
maxi-	O
mum	O
color	B
value	O
,	O
saturation	O
is	O
deﬁned	O
as	O
scaled	O
distance	O
from	O
the	O
diagonal	O
,	O
and	O
hue	B
is	O
deﬁned	O
as	O
the	O
direction	O
around	O
a	O
color	B
wheel	O
(	O
the	O
exact	O
formulas	O
are	O
described	O
by	O
hall	O
(	O
1989	O
)	O
;	O
foley	O
,	O
van	O
dam	O
,	O
feiner	O
et	O
al	O
.	O
(	O
1995	O
)	O
)	O
.	O
such	O
a	O
decomposition	O
is	O
quite	O
natural	B
in	O
graphics	O
applications	O
such	O
as	O
color	B
picking	O
(	O
it	O
approximates	O
the	O
munsell	O
chart	O
for	O
color	O
description	O
)	O
.	O
figure	O
2.32l–	O
n	O
shows	O
an	O
hsv	O
representation	O
of	O
a	O
sample	O
color	B
image	O
,	O
where	O
saturation	O
is	O
encoded	O
using	O
a	O
gray	O
scale	O
(	O
saturated	O
=	O
darker	O
)	O
and	O
hue	B
is	O
depicted	O
as	O
a	O
color	B
.	O
if	O
you	O
want	O
your	O
computer	O
vision	O
algorithm	B
to	O
only	O
affect	O
the	O
value	O
(	O
luminance	O
)	O
of	O
an	O
image	B
and	O
not	O
its	O
saturation	O
or	O
hue	B
,	O
a	O
simpler	O
solution	O
is	O
to	O
use	O
either	O
the	O
y	O
xy	O
(	O
luminance	O
+	O
chromaticity	O
)	O
coordinates	O
deﬁned	O
in	O
(	O
2.104	O
)	O
or	O
the	O
even	O
simpler	O
color	B
ratios	O
,	O
r	O
=	O
r	O
r	O
+	O
g	O
+	O
b	O
,	O
g	O
=	O
g	O
r	O
+	O
g	O
+	O
b	O
,	O
b	O
=	O
b	O
r	O
+	O
g	O
+	O
b	O
(	O
2.116	O
)	O
(	O
figure	O
2.32e–h	O
)	O
.	O
after	O
manipulating	O
the	O
luma	O
(	O
2.112	O
)	O
,	O
e.g.	O
,	O
through	O
the	O
process	O
of	O
histogram	B
equalization	O
(	O
section	O
3.1.4	O
)	O
,	O
you	O
can	O
multiply	O
each	O
color	B
ratio	O
by	O
the	O
ratio	O
of	O
the	O
new	O
to	O
old	O
luma	O
to	O
obtain	O
an	O
adjusted	O
rgb	O
triplet	O
.	O
while	O
all	O
of	O
these	O
color	B
systems	O
may	O
sound	O
confusing	O
,	O
in	O
the	O
end	O
,	O
it	O
often	O
may	O
not	O
mat-	O
ter	O
that	O
much	O
which	O
one	O
you	O
use	O
.	O
poynton	O
,	O
in	O
his	O
color	B
faq	O
,	O
http	O
:	O
//www.poynton.com/	O
colorfaq.html	O
,	O
notes	O
that	O
the	O
perceptually	O
motivated	O
l*a*b*	O
system	O
is	O
qualitatively	O
similar	O
to	O
the	O
gamma-compressed	O
r	O
’	O
g	O
’	O
b	O
’	O
system	O
we	O
mostly	O
deal	O
with	O
,	O
since	O
both	O
have	O
a	O
fractional	O
power	O
scaling	O
(	O
which	O
approximates	O
a	O
logarithmic	O
response	O
)	O
between	O
the	O
actual	O
intensity	O
val-	O
ues	O
and	O
the	O
numbers	O
being	O
manipulated	O
.	O
as	O
in	O
all	O
cases	O
,	O
think	O
carefully	O
about	O
what	O
you	O
are	O
trying	O
to	O
accomplish	O
before	O
deciding	O
on	O
a	O
technique	O
to	O
use.24	O
2.3.3	O
compression	B
the	O
last	O
stage	O
in	O
a	O
camera	B
’	O
s	O
processing	O
pipeline	B
is	O
usually	O
some	O
form	O
of	O
image	B
compression	O
(	O
unless	O
you	O
are	O
using	O
a	O
lossless	O
compression	B
scheme	O
such	O
as	O
camera	B
raw	O
or	O
png	O
)	O
.	O
all	O
color	B
video	O
and	O
image	B
compression	O
algorithms	O
start	O
by	O
converting	O
the	O
signal	O
into	O
ycbcr	O
(	O
or	O
some	O
closely	O
related	O
variant	O
)	O
,	O
so	O
that	O
they	O
can	O
compress	O
the	O
luminance	O
signal	O
with	O
higher	O
ﬁdelity	O
than	O
the	O
chrominance	O
signal	O
.	O
(	O
recall	B
that	O
the	O
human	O
visual	O
system	O
has	O
poorer	O
24	O
if	O
you	O
are	O
at	O
a	O
loss	O
for	O
questions	O
at	O
a	O
conference	O
,	O
you	O
can	O
always	O
ask	O
why	O
the	O
speaker	O
did	O
not	O
use	O
a	O
perceptual	O
color	B
space	O
,	O
such	O
as	O
l*a*b*	O
.	O
conversely	O
,	O
if	O
they	O
did	O
use	O
l*a*b*	O
,	O
you	O
can	O
ask	O
if	O
they	O
have	O
any	O
concrete	O
evidence	O
that	O
this	O
works	O
better	O
than	O
regular	O
colors	O
.	O
2.3	O
the	O
digital	O
camera	O
91	O
(	O
a	O
)	O
rgb	O
(	O
b	O
)	O
r	O
(	O
c	O
)	O
g	O
(	O
d	O
)	O
b	O
(	O
e	O
)	O
rgb	O
(	O
f	O
)	O
r	O
(	O
g	O
)	O
g	O
(	O
h	O
)	O
b	O
(	O
i	O
)	O
l*	O
(	O
j	O
)	O
a*	O
(	O
k	O
)	O
b*	O
(	O
l	O
)	O
h	O
(	O
m	O
)	O
s	O
(	O
n	O
)	O
v	O
figure	O
2.32	O
color	B
space	O
transformations	O
:	O
(	O
a–d	O
)	O
rgb	O
;	O
(	O
e–h	O
)	O
rgb	O
.	O
(	O
i–k	O
)	O
l*a*b*	O
;	O
(	O
l–n	O
)	O
hsv	O
.	O
note	O
that	O
the	O
rgb	O
,	O
l*a*b*	O
,	O
and	O
hsv	O
values	O
are	O
all	O
re-scaled	O
to	O
ﬁt	O
the	O
dynamic	B
range	O
of	O
the	O
printed	O
page	O
.	O
frequency	O
response	O
to	O
color	B
than	O
to	O
luminance	O
changes	O
.	O
)	O
in	O
video	B
,	O
it	O
is	O
common	O
to	O
subsam-	O
ple	O
cb	O
and	O
cr	O
by	O
a	O
factor	O
of	O
two	O
horizontally	O
;	O
with	O
still	O
images	O
(	O
jpeg	O
)	O
,	O
the	O
subsampling	O
(	O
averaging	O
)	O
occurs	O
both	O
horizontally	O
and	O
vertically	O
.	O
once	O
the	O
luminance	O
and	O
chrominance	O
images	O
have	O
been	O
appropriately	O
subsampled	O
and	O
separated	O
into	O
individual	O
images	O
,	O
they	O
are	O
then	O
passed	O
to	O
a	O
block	O
transform	O
stage	O
.	O
the	O
most	O
common	O
technique	O
used	O
here	O
is	O
the	O
discrete	B
cosine	O
transform	B
(	O
dct	O
)	O
,	O
which	O
is	O
a	O
real-valued	O
variant	O
of	O
the	O
discrete	B
fourier	O
transform	B
(	O
dft	O
)	O
(	O
see	O
section	O
3.4.3	O
)	O
.	O
the	O
dct	O
is	O
a	O
reasonable	O
approximation	O
to	O
the	O
karhunen–lo`eve	O
or	O
eigenvalue	O
decomposition	O
of	O
natural	B
image	O
patches	O
,	O
i.e.	O
,	O
the	O
decomposition	O
that	O
simultaneously	O
packs	O
the	O
most	O
energy	O
into	O
the	O
ﬁrst	O
coefﬁcients	O
and	O
diagonalizes	O
the	O
joint	B
covariance	O
matrix	O
among	O
the	O
pixels	O
(	O
makes	O
transform	B
coefﬁcients	O
92	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
2.33	O
image	B
compressed	O
with	O
jpeg	O
at	O
three	O
quality	O
settings	O
.	O
note	O
how	O
the	O
amount	O
of	O
block	O
artifact	O
and	O
high-frequency	O
aliasing	B
(	O
“	O
mosquito	O
noise	B
”	O
)	O
increases	O
from	O
left	O
to	O
right	O
.	O
statistically	O
independent	O
)	O
.	O
both	O
mpeg	O
and	O
jpeg	O
use	O
8	O
×	O
8	O
dct	O
transforms	O
(	O
wallace	O
1991	O
;	O
le	O
gall	O
1991	O
)	O
,	O
although	O
newer	O
variants	O
use	O
smaller	O
4×4	O
blocks	O
or	O
alternative	O
transformations	O
,	O
such	O
as	O
wavelets	O
(	O
taubman	O
and	O
marcellin	O
2002	O
)	O
and	O
lapped	O
transforms	O
(	O
malvar	O
1990	O
,	O
1998	O
,	O
2000	O
)	O
are	O
now	O
used	O
.	O
after	O
transform	B
coding	O
,	O
the	O
coefﬁcient	O
values	O
are	O
quantized	O
into	O
a	O
set	O
of	O
small	O
integer	O
values	O
that	O
can	O
be	O
coded	O
using	O
a	O
variable	O
bit	O
length	O
scheme	O
such	O
as	O
a	O
huffman	O
code	O
or	O
an	O
arithmetic	O
code	O
(	O
wallace	O
1991	O
)	O
.	O
(	O
the	O
dc	O
(	O
lowest	O
frequency	O
)	O
coefﬁcients	O
are	O
also	O
adaptively	O
predicted	O
from	O
the	O
previous	O
block	O
’	O
s	O
dc	O
values	O
.	O
the	O
term	O
“	O
dc	O
”	O
comes	O
from	O
“	O
direct	B
current	O
”	O
,	O
i.e.	O
,	O
the	O
non-sinusoidal	O
or	O
non-alternating	O
part	O
of	O
a	O
signal	O
.	O
)	O
the	O
step	O
size	O
in	O
the	O
quantization	B
is	O
the	O
main	O
variable	O
controlled	O
by	O
the	O
quality	O
setting	O
on	O
the	O
jpeg	O
ﬁle	O
(	O
figure	O
2.33	O
)	O
.	O
with	O
video	O
,	O
it	O
is	O
also	O
usual	O
to	O
perform	O
block-based	O
motion	B
compensation	O
,	O
i.e.	O
,	O
to	O
encode	O
the	O
difference	B
between	O
each	O
block	O
and	O
a	O
predicted	O
set	O
of	O
pixel	O
values	O
obtained	O
from	O
a	O
shifted	O
block	O
in	O
the	O
previous	O
frame	O
.	O
(	O
the	O
exception	O
is	O
the	O
motion-jpeg	O
scheme	O
used	O
in	O
older	O
dv	O
camcorders	O
,	O
which	O
is	O
nothing	O
more	O
than	O
a	O
series	O
of	O
individually	O
jpeg	O
compressed	O
image	O
frames	O
.	O
)	O
while	O
basic	O
mpeg	O
uses	O
16	O
×	O
16	O
motion	B
compensation	O
blocks	O
with	O
integer	O
motion	B
values	O
(	O
le	O
gall	O
1991	O
)	O
,	O
newer	O
standards	O
use	O
adaptively	O
sized	O
block	O
,	O
sub-pixel	O
motions	O
,	O
and	O
the	O
ability	O
to	O
reference	O
blocks	O
from	O
older	O
frames	O
.	O
in	O
order	B
to	O
recover	O
more	O
gracefully	O
from	O
failures	O
and	O
to	O
allow	O
for	O
random	O
access	O
to	O
the	O
video	B
stream	O
,	O
predicted	O
p	O
frames	O
are	O
interleaved	O
among	O
independently	O
coded	O
i	O
frames	O
.	O
(	O
bi-directional	O
b	O
frames	O
are	O
also	O
sometimes	O
used	O
.	O
)	O
the	O
quality	O
of	O
a	O
compression	B
algorithm	O
is	O
usually	O
reported	O
using	O
its	O
peak	O
signal-to-noise	O
ratio	O
(	O
psnr	O
)	O
,	O
which	O
is	O
derived	O
from	O
the	O
average	O
mean	O
square	O
error	O
,	O
m	O
se	O
=	O
1	O
n	O
(	O
cid:88	O
)	O
x	O
(	O
cid:104	O
)	O
i	O
(	O
x	O
)	O
−	O
ˆi	O
(	O
x	O
)	O
(	O
cid:105	O
)	O
2	O
,	O
(	O
2.117	O
)	O
where	O
i	O
(	O
x	O
)	O
is	O
the	O
original	O
uncompressed	O
image	B
and	O
ˆi	O
(	O
x	O
)	O
is	O
its	O
compressed	O
counterpart	O
,	O
or	O
equivalently	O
,	O
the	O
root	O
mean	O
square	O
error	O
(	O
rms	O
error	O
)	O
,	O
which	O
is	O
deﬁned	O
as	O
rm	O
s	O
=	O
√m	O
se	O
.	O
(	O
2.118	O
)	O
2.4	O
additional	O
reading	O
the	O
psnr	O
is	O
deﬁned	O
as	O
p	O
sn	O
r	O
=	O
10	O
log10	O
i	O
2	O
max	O
m	O
se	O
=	O
20	O
log10	O
imax	O
rm	O
s	O
,	O
93	O
(	O
2.119	O
)	O
where	O
imax	O
is	O
the	O
maximum	O
signal	O
extent	O
,	O
e.g.	O
,	O
255	O
for	O
eight-bit	O
images	O
.	O
while	O
this	O
is	O
just	O
a	O
high-level	O
sketch	O
of	O
how	O
image	B
compression	O
works	O
,	O
it	O
is	O
useful	O
to	O
understand	O
so	O
that	O
the	O
artifacts	O
introduced	O
by	O
such	O
techniques	O
can	O
be	O
compensated	O
for	O
in	O
various	O
computer	O
vision	O
applications	O
.	O
2.4	O
additional	O
reading	O
as	O
we	O
mentioned	O
at	O
the	O
beginning	O
of	O
this	O
chapter	O
,	O
it	O
provides	O
but	O
a	O
brief	O
summary	O
of	O
a	O
very	O
rich	O
and	O
deep	O
set	O
of	O
topics	O
,	O
traditionally	O
covered	O
in	O
a	O
number	O
of	O
separate	O
ﬁelds	O
.	O
a	O
more	O
thorough	O
introduction	O
to	O
the	O
geometry	O
of	O
points	B
,	O
lines	B
,	O
planes	B
,	O
and	O
projections	B
can	O
be	O
found	O
in	O
textbooks	B
on	O
multi-view	B
geometry	O
(	O
hartley	O
and	O
zisserman	O
2004	O
;	O
faugeras	O
and	O
luong	O
2001	O
)	O
and	O
computer	O
graphics	O
(	O
foley	O
,	O
van	O
dam	O
,	O
feiner	O
et	O
al	O
.	O
1995	O
;	O
watt	O
1995	O
;	O
opengl-arb	O
1997	O
)	O
.	O
topics	O
covered	O
in	O
more	O
depth	O
include	O
higher-order	O
primitives	O
such	O
as	O
quadrics	O
,	O
conics	O
,	O
and	O
cubics	O
,	O
as	O
well	O
as	O
three-view	O
and	O
multi-view	B
geometry	O
.	O
the	O
image	B
formation	O
(	O
synthesis	O
)	O
process	O
is	O
traditionally	O
taught	O
as	O
part	O
of	O
a	O
computer	O
graphics	O
curriculum	O
(	O
foley	O
,	O
van	O
dam	O
,	O
feiner	O
et	O
al	O
.	O
1995	O
;	O
glassner	O
1995	O
;	O
watt	O
1995	O
;	O
shirley	O
2005	O
)	O
but	O
it	O
is	O
also	O
studied	O
in	O
physics-based	B
computer	O
vision	O
(	O
wolff	O
,	O
shafer	O
,	O
and	O
healey	O
1992a	O
)	O
.	O
the	O
behavior	O
of	O
camera	B
lens	O
systems	O
is	O
studied	O
in	O
optics	B
(	O
m¨oller	O
1988	O
;	O
hecht	O
2001	O
;	O
ray	O
2002	O
)	O
.	O
some	O
good	O
books	O
on	O
color	B
theory	O
have	O
been	O
written	O
by	O
healey	O
and	O
shafer	O
(	O
1992	O
)	O
;	O
wyszecki	O
and	O
stiles	O
(	O
2000	O
)	O
;	O
fairchild	O
(	O
2005	O
)	O
,	O
with	O
livingstone	O
(	O
2008	O
)	O
providing	O
a	O
more	O
fun	O
and	O
infor-	O
mal	O
introduction	O
to	O
the	O
topic	O
of	O
color	B
perception	O
.	O
mark	O
fairchild	O
’	O
s	O
page	O
of	O
color	B
books	O
and	O
links25	O
lists	O
many	O
other	O
sources	O
.	O
topics	O
relating	O
to	O
sampling	B
and	O
aliasing	B
are	O
covered	O
in	O
textbooks	B
on	O
signal	O
and	O
image	B
processing	O
(	O
crane	O
1997	O
;	O
j¨ahne	O
1997	O
;	O
oppenheim	O
and	O
schafer	O
1996	O
;	O
oppenheim	O
,	O
schafer	O
,	O
and	O
buck	O
1999	O
;	O
pratt	O
2007	O
;	O
russ	O
2007	O
;	O
burger	O
and	O
burge	O
2008	O
;	O
gonzales	O
and	O
woods	O
2008	O
)	O
.	O
2.5	O
exercises	O
a	O
note	O
to	O
students	O
:	O
this	O
chapter	O
is	O
relatively	O
light	O
on	O
exercises	O
since	O
it	O
contains	O
mostly	O
background	O
material	O
and	O
not	O
that	O
many	O
usable	O
techniques	O
.	O
if	O
you	O
really	O
want	O
to	O
understand	O
25	O
http	O
:	O
//www.cis.rit.edu/fairchild/whyiscolor/books	O
links.html	O
.	O
94	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
multi-view	B
geometry	O
in	O
a	O
thorough	O
way	O
,	O
i	O
encourage	O
you	O
to	O
read	O
and	O
do	O
the	O
exercises	O
provided	O
by	O
hartley	O
and	O
zisserman	O
(	O
2004	O
)	O
.	O
similarly	O
,	O
if	O
you	O
want	O
some	O
exercises	O
related	O
to	O
the	O
image	B
formation	O
process	O
,	O
glassner	O
’	O
s	O
(	O
1995	O
)	O
book	O
is	O
full	O
of	O
challenging	O
problems	O
.	O
ex	O
2.1	O
:	O
least	B
squares	I
intersection	O
point	O
and	O
line	O
ﬁtting—advanced	O
equation	B
(	O
2.4	O
)	O
shows	O
how	O
the	O
intersection	O
of	O
two	O
2d	O
lines	B
can	O
be	O
expressed	O
as	O
their	O
cross	O
product	O
,	O
assuming	O
the	O
lines	B
are	O
expressed	O
as	O
homogeneous	B
coordinates	I
.	O
1.	O
if	O
you	O
are	O
given	O
more	O
than	O
two	O
lines	O
and	O
want	O
to	O
ﬁnd	O
a	O
point	O
˜x	O
that	O
minimizes	O
the	O
sum	O
of	O
squared	O
distances	O
to	O
each	O
line	O
,	O
d	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
˜x	O
·	O
˜li	O
)	O
2	O
,	O
(	O
2.120	O
)	O
how	O
can	O
you	O
compute	O
this	O
quantity	O
?	O
(	O
hint	O
:	O
write	O
the	O
dot	O
product	O
as	O
˜xt	O
˜li	O
and	O
turn	O
the	O
squared	O
quantity	O
into	O
a	O
quadratic	O
form	O
,	O
˜xt	O
a˜x	O
.	O
)	O
2.	O
to	O
ﬁt	O
a	O
line	O
to	O
a	O
bunch	O
of	O
points	B
,	O
you	O
can	O
compute	O
the	O
centroid	O
(	O
mean	O
)	O
of	O
the	O
points	B
as	O
well	O
as	O
the	O
covariance	O
matrix	O
of	O
the	O
points	B
around	O
this	O
mean	O
.	O
show	O
that	O
the	O
line	O
passing	O
through	O
the	O
centroid	O
along	O
the	O
major	O
axis	O
of	O
the	O
covariance	O
ellipsoid	O
(	O
largest	O
eigenvector	O
)	O
minimizes	O
the	O
sum	O
of	O
squared	O
distances	O
to	O
the	O
points	B
.	O
3.	O
these	O
two	O
approaches	O
are	O
fundamentally	O
different	O
,	O
even	O
though	O
projective	B
duality	O
tells	O
us	O
that	O
points	B
and	O
lines	B
are	O
interchangeable	O
.	O
why	O
are	O
these	O
two	O
algorithms	O
so	O
appar-	O
ently	O
different	O
?	O
are	O
they	O
actually	O
minimizing	O
different	O
objectives	O
?	O
ex	O
2.2	O
:	O
2d	O
transform	B
editor	O
write	O
a	O
program	O
that	O
lets	O
you	O
interactively	O
create	O
a	O
set	O
of	O
rectangles	O
and	O
then	O
modify	O
their	O
“	O
pose	O
”	O
(	O
2d	O
transform	B
)	O
.	O
you	O
should	O
implement	O
the	O
following	O
steps	O
:	O
1.	O
open	O
an	O
empty	O
window	O
(	O
“	O
canvas	O
”	O
)	O
.	O
2.	O
shift	O
drag	O
(	O
rubber-band	O
)	O
to	O
create	O
a	O
new	O
rectangle	O
.	O
3.	O
select	O
the	O
deformation	O
mode	O
(	O
motion	B
model	O
)	O
:	O
translation	B
,	O
rigid	O
,	O
similarity	B
,	O
afﬁne	B
,	O
or	O
perspective	B
.	O
4.	O
drag	O
any	O
corner	O
of	O
the	O
outline	O
to	O
change	O
its	O
transformation	O
.	O
this	O
exercise	O
should	O
be	O
built	O
on	O
a	O
set	O
of	O
pixel	O
coordinate	O
and	O
transformation	O
classes	O
,	O
either	O
implemented	O
by	O
yourself	O
or	O
from	O
a	O
software	O
library	O
.	O
persistence	O
of	O
the	O
created	O
representation	O
(	O
save	O
and	O
load	O
)	O
should	O
also	O
be	O
supported	O
(	O
for	O
each	O
rectangle	O
,	O
save	O
its	O
transformation	O
)	O
.	O
2.5	O
exercises	O
95	O
ex	O
2.3	O
:	O
3d	O
viewer	O
write	O
a	O
simple	O
viewer	O
for	O
3d	O
points	B
,	O
lines	B
,	O
and	O
polygons	O
.	O
import	O
a	O
set	O
of	O
point	O
and	O
line	O
commands	O
(	O
primitives	O
)	O
as	O
well	O
as	O
a	O
viewing	O
transform	B
.	O
interactively	O
modify	O
the	O
object	O
or	O
camera	B
transform	O
.	O
this	O
viewer	O
can	O
be	O
an	O
extension	O
of	O
the	O
one	O
you	O
created	O
in	O
(	O
exercise	O
2.2	O
)	O
.	O
simply	O
replace	O
the	O
viewing	O
transformations	O
with	O
their	O
3d	O
equivalents	O
.	O
(	O
optional	O
)	O
add	O
a	O
z-buffer	O
to	O
do	O
hidden	O
surface	B
removal	O
for	O
polygons	O
.	O
(	O
optional	O
)	O
use	O
a	O
3d	O
drawing	O
package	O
and	O
just	O
write	O
the	O
viewer	O
control	O
.	O
ex	O
2.4	O
:	O
focus	B
distance	O
and	O
depth	O
of	O
ﬁeld	O
figure	O
out	O
how	O
the	O
focus	B
distance	O
and	O
depth	O
of	O
ﬁeld	O
indicators	O
on	O
a	O
lens	O
are	O
determined	O
.	O
1.	O
compute	O
and	O
plot	O
the	O
focus	B
distance	O
zo	O
as	O
a	O
function	O
of	O
the	O
distance	O
traveled	O
from	O
the	O
focal	O
length	O
∆zi	O
=	O
f	O
−	O
zi	O
for	O
a	O
lens	O
of	O
focal	O
length	O
f	O
(	O
say	O
,	O
100mm	O
)	O
.	O
does	O
this	O
explain	O
the	O
hyperbolic	O
progression	O
of	O
focus	B
distances	O
you	O
see	O
on	O
a	O
typical	O
lens	O
(	O
figure	O
2.20	O
)	O
?	O
2.	O
compute	O
the	O
depth	O
of	O
ﬁeld	O
(	O
minimum	O
and	O
maximum	O
focus	B
distances	O
)	O
for	O
a	O
given	O
focus	B
setting	O
zo	O
as	O
a	O
function	O
of	O
the	O
circle	O
of	O
confusion	O
diameter	O
c	O
(	O
make	O
it	O
a	O
fraction	O
of	O
the	O
sensor	B
width	O
)	O
,	O
the	O
focal	O
length	O
f	O
,	O
and	O
the	O
f-stop	O
number	O
n	O
(	O
which	O
relates	O
to	O
the	O
aperture	O
diameter	O
d	O
)	O
.	O
does	O
this	O
explain	O
the	O
usual	O
depth	O
of	O
ﬁeld	O
markings	O
on	O
a	O
lens	O
that	O
bracket	O
the	O
in-focus	O
marker	O
,	O
as	O
in	O
figure	O
2.20a	O
?	O
3.	O
now	O
consider	O
a	O
zoom	O
lens	O
with	O
a	O
varying	O
focal	O
length	O
f.	O
assume	O
that	O
as	O
you	O
zoom	O
,	O
the	O
lens	O
stays	O
in	O
focus	B
,	O
i.e.	O
,	O
the	O
distance	O
from	O
the	O
rear	O
nodal	B
point	I
to	O
the	O
sensor	B
plane	O
zi	O
adjusts	O
itself	O
automatically	O
for	O
a	O
ﬁxed	O
focus	O
distance	O
zo	O
.	O
how	O
do	O
the	O
depth	O
of	O
ﬁeld	O
indicators	O
vary	O
as	O
a	O
function	O
of	O
focal	O
length	O
?	O
can	O
you	O
reproduce	O
a	O
two-dimensional	B
plot	O
that	O
mimics	O
the	O
curved	O
depth	O
of	O
ﬁeld	O
lines	B
seen	O
on	O
the	O
lens	O
in	O
figure	O
2.20b	O
?	O
ex	O
2.5	O
:	O
f-numbers	O
and	O
shutter	O
speeds	O
list	O
the	O
common	O
f-numbers	O
and	O
shutter	O
speeds	O
that	O
your	O
camera	B
provides	O
.	O
on	O
older	O
model	O
slrs	O
,	O
they	O
are	O
visible	O
on	O
the	O
lens	O
and	O
shut-	O
ter	O
speed	O
dials	O
.	O
on	O
newer	O
cameras	O
,	O
you	O
have	O
to	O
look	O
at	O
the	O
electronic	O
viewﬁnder	O
(	O
or	O
lcd	O
screen/indicator	O
)	O
as	O
you	O
manually	O
adjust	O
exposures	O
.	O
1.	O
do	O
these	O
form	O
geometric	B
progressions	O
;	O
if	O
so	O
,	O
what	O
are	O
the	O
ratios	B
?	O
how	O
do	O
these	O
relate	O
to	O
exposure	O
values	O
(	O
evs	O
)	O
?	O
2.	O
if	O
your	O
camera	B
has	O
shutter	O
speeds	O
of	O
1	O
exactly	O
a	O
factor	O
of	O
two	O
apart	O
or	O
a	O
factor	O
of	O
125/60	O
=	O
2.083	O
apart	O
?	O
60	O
and	O
1	O
125	O
,	O
do	O
you	O
think	O
that	O
these	O
two	O
speeds	O
are	O
3.	O
how	O
accurate	O
do	O
you	O
think	O
these	O
numbers	O
are	O
?	O
can	O
you	O
devise	O
some	O
way	O
to	O
measure	O
exactly	O
how	O
the	O
aperture	O
affects	O
how	O
much	O
light	O
reaches	O
the	O
sensor	B
and	O
what	O
the	O
exact	O
exposure	O
times	O
actually	O
are	O
?	O
96	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ex	O
2.6	O
:	O
noise	B
level	O
calibration	B
estimate	O
the	O
amount	O
of	O
noise	B
in	O
your	O
camera	B
by	O
taking	O
re-	O
peated	O
shots	O
of	O
a	O
scene	O
with	O
the	O
camera	B
mounted	O
on	O
a	O
tripod	O
.	O
(	O
purchasing	O
a	O
remote	O
shutter	O
release	O
is	O
a	O
good	O
investment	O
if	O
you	O
own	O
a	O
dslr	O
.	O
)	O
alternatively	O
,	O
take	O
a	O
scene	O
with	O
constant	O
color	B
regions	O
(	O
such	O
as	O
a	O
color	B
checker	O
chart	O
)	O
and	O
estimate	O
the	O
variance	O
by	O
ﬁtting	O
a	O
smooth	O
function	O
to	O
each	O
color	B
region	O
and	O
then	O
taking	O
differences	O
from	O
the	O
predicted	O
function	O
.	O
1.	O
plot	O
your	O
estimated	O
variance	O
as	O
a	O
function	O
of	O
level	O
for	O
each	O
of	O
your	O
color	B
channels	O
separately	O
.	O
2.	O
change	O
the	O
iso	O
setting	O
on	O
your	O
camera	B
;	O
if	O
you	O
can	O
not	O
do	O
that	O
,	O
reduce	O
the	O
overall	O
light	O
in	O
your	O
scene	O
(	O
turn	O
off	O
lights	O
,	O
draw	O
the	O
curtains	O
,	O
wait	O
until	O
dusk	O
)	O
.	O
does	O
the	O
amount	O
of	O
noise	B
vary	O
a	O
lot	O
with	O
iso/gain	O
?	O
3.	O
compare	O
your	O
camera	B
to	O
another	O
one	O
at	O
a	O
different	O
price	O
point	O
or	O
year	O
of	O
make	O
.	O
is	O
there	O
evidence	O
to	O
suggest	O
that	O
“	O
you	O
get	O
what	O
you	O
pay	O
for	O
”	O
?	O
does	O
the	O
quality	O
of	O
digital	O
cameras	O
seem	O
to	O
be	O
improving	O
over	O
time	O
?	O
ex	O
2.7	O
:	O
gamma	B
correction	O
in	O
image	B
stitching	I
here	O
’	O
s	O
a	O
relatively	O
simple	O
puzzle	O
.	O
assume	O
you	O
are	O
given	O
two	O
images	O
that	O
are	O
part	O
of	O
a	O
panorama	O
that	O
you	O
want	O
to	O
stitch	O
(	O
see	O
chapter	O
9	O
)	O
.	O
the	O
two	O
images	O
were	O
taken	O
with	O
different	O
exposures	O
,	O
so	O
you	O
want	O
to	O
adjust	O
the	O
rgb	O
values	O
so	O
that	O
they	O
match	O
along	O
the	O
seam	O
line	O
.	O
is	O
it	O
necessary	O
to	O
undo	O
the	O
gamma	B
in	O
the	O
color	B
values	O
in	O
order	B
to	O
achieve	O
this	O
?	O
ex	O
2.8	O
:	O
skin	O
color	B
detection	O
devise	O
a	O
simple	O
skin	O
color	B
detector	O
(	O
forsyth	O
and	O
fleck	O
1999	O
;	O
jones	O
and	O
rehg	O
2001	O
;	O
vezhnevets	O
,	O
sazonov	O
,	O
and	O
andreeva	O
2003	O
;	O
kakumanu	O
,	O
makrogiannis	O
,	O
and	O
bourbakis	O
2007	O
)	O
based	O
on	O
chromaticity	O
or	O
other	O
color	B
properties	O
.	O
1.	O
take	O
a	O
variety	O
of	O
photographs	O
of	O
people	O
and	O
calculate	O
the	O
xy	O
chromaticity	O
values	O
for	O
each	O
pixel	O
.	O
2.	O
crop	O
the	O
photos	O
or	O
otherwise	O
indicate	O
with	O
a	O
painting	O
tool	O
which	O
pixels	O
are	O
likely	O
to	O
be	O
skin	O
(	O
e.g	O
.	O
face	B
and	O
arms	O
)	O
.	O
3.	O
calculate	O
a	O
color	B
(	O
chromaticity	O
)	O
distribution	O
for	O
these	O
pixels	O
.	O
you	O
can	O
use	O
something	O
as	O
simple	O
as	O
a	O
mean	O
and	O
covariance	O
measure	O
or	O
as	O
complicated	O
as	O
a	O
mean-shift	O
segmenta-	O
tion	B
algorithm	O
(	O
see	O
section	O
5.3.2	O
)	O
.	O
you	O
can	O
optionally	O
use	O
non-skin	O
pixels	O
to	O
model	O
the	O
background	O
distribution	O
.	O
4.	O
use	O
your	O
computed	O
distribution	O
to	O
ﬁnd	O
the	O
skin	O
regions	O
in	O
an	O
image	B
.	O
one	O
easy	O
way	O
to	O
visualize	O
this	O
is	O
to	O
paint	O
all	O
non-skin	O
pixels	O
a	O
given	O
color	B
,	O
such	O
as	O
white	O
or	O
black	O
.	O
5.	O
how	O
sensitive	O
is	O
your	O
algorithm	B
to	O
color	B
balance	I
(	O
scene	O
lighting	O
)	O
?	O
2.5	O
exercises	O
97	O
6.	O
does	O
a	O
simpler	O
chromaticity	O
measurement	O
,	O
such	O
as	O
a	O
color	B
ratio	O
(	O
2.116	O
)	O
,	O
work	O
just	O
as	O
well	O
?	O
ex	O
2.9	O
:	O
white	O
point	O
balancing—tricky	O
a	O
common	O
(	O
in-camera	O
or	O
post-processing	O
)	O
tech-	O
nique	O
for	O
performing	O
white	O
point	O
adjustment	O
is	O
to	O
take	O
a	O
picture	O
of	O
a	O
white	O
piece	O
of	O
paper	O
and	O
to	O
adjust	O
the	O
rgb	O
values	O
of	O
an	O
image	B
to	O
make	O
this	O
a	O
neutral	O
color	B
.	O
1.	O
describe	O
how	O
you	O
would	O
adjust	O
the	O
rgb	O
values	O
in	O
an	O
image	B
given	O
a	O
sample	O
“	O
white	O
color	B
”	O
of	O
(	O
rw	O
,	O
gw	O
,	O
bw	O
)	O
to	O
make	O
this	O
color	B
neutral	O
(	O
without	O
changing	O
the	O
exposure	O
too	O
much	O
)	O
.	O
2.	O
does	O
your	O
transformation	O
involve	O
a	O
simple	O
(	O
per-channel	O
)	O
scaling	O
of	O
the	O
rgb	O
values	O
or	O
do	O
you	O
need	O
a	O
full	O
3	O
×	O
3	O
color	B
twist	O
matrix	O
(	O
or	O
something	O
else	O
)	O
?	O
3.	O
convert	O
your	O
rgb	O
values	O
to	O
xyz	O
.	O
does	O
the	O
appropriate	O
correction	O
now	O
only	O
depend	O
on	O
the	O
xy	O
(	O
or	O
xy	O
)	O
values	O
?	O
if	O
so	O
,	O
when	O
you	O
convert	O
back	O
to	O
rgb	O
space	O
,	O
do	O
you	O
need	O
a	O
full	O
3	O
×	O
3	O
color	B
twist	O
matrix	O
to	O
achieve	O
the	O
same	O
effect	O
?	O
4.	O
if	O
you	O
used	O
pure	O
diagonal	O
scaling	O
in	O
the	O
direct	B
rgb	O
mode	O
but	O
end	O
up	O
with	O
a	O
twist	B
if	O
you	O
work	O
in	O
xyz	O
space	O
,	O
how	O
do	O
you	O
explain	O
this	O
apparent	O
dichotomy	O
?	O
which	O
approach	O
is	O
correct	O
?	O
(	O
or	O
is	O
it	O
possible	O
that	O
neither	O
approach	O
is	O
actually	O
correct	O
?	O
)	O
if	O
you	O
want	O
to	O
ﬁnd	O
out	O
what	O
your	O
camera	B
actually	O
does	O
,	O
continue	O
on	O
to	O
the	O
next	O
exercise	O
.	O
ex	O
2.10	O
:	O
in-camera	O
color	B
processing—challenging	O
if	O
your	O
camera	B
supports	O
a	O
raw	O
pixel	O
mode	O
,	O
take	O
a	O
pair	O
of	O
raw	O
and	O
jpeg	O
images	O
,	O
and	O
see	O
if	O
you	O
can	O
infer	O
what	O
the	O
camera	B
is	O
doing	O
when	O
it	O
converts	O
the	O
raw	O
pixel	O
values	O
to	O
the	O
ﬁnal	O
color-corrected	O
and	O
gamma-compressed	O
eight-bit	O
jpeg	O
pixel	O
values	O
.	O
1.	O
deduce	O
the	O
pattern	O
in	O
your	O
color	O
ﬁlter	O
array	O
from	O
the	O
correspondence	B
between	O
co-	O
located	O
raw	O
and	O
color-mapped	O
pixel	O
values	O
.	O
use	O
a	O
color	B
checker	O
chart	O
at	O
this	O
stage	O
if	O
it	O
makes	O
your	O
life	O
easier	O
.	O
you	O
may	O
ﬁnd	O
it	O
helpful	O
to	O
split	O
the	O
raw	O
image	B
into	O
four	O
separate	O
images	O
(	O
subsampling	O
even	O
and	O
odd	O
columns	O
and	O
rows	O
)	O
and	O
to	O
treat	O
each	O
of	O
these	O
new	O
images	O
as	O
a	O
“	O
virtual	O
”	O
sensor	B
.	O
2.	O
evaluate	O
the	O
quality	O
of	O
the	O
demosaicing	B
algorithm	O
by	O
taking	O
pictures	O
of	O
challenging	O
scenes	O
which	O
contain	O
strong	O
color	B
edges	O
(	O
such	O
as	O
those	O
shown	O
in	O
in	O
section	O
10.3.1	O
)	O
.	O
3.	O
if	O
you	O
can	O
take	O
the	O
same	O
exact	O
picture	O
after	O
changing	O
the	O
color	B
balance	I
values	O
in	O
your	O
camera	B
,	O
compare	O
how	O
these	O
settings	O
affect	O
this	O
processing	O
.	O
4.	O
compare	O
your	O
results	O
against	O
those	O
presented	O
by	O
chakrabarti	O
,	O
scharstein	O
,	O
and	O
zickler	O
(	O
2009	O
)	O
or	O
use	O
the	O
data	O
available	O
in	O
their	O
database	O
of	O
color	B
images.26	O
26	O
http	O
:	O
//vision.middlebury.edu/color/	O
.	O
98	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
chapter	O
3	O
image	B
processing	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.1	O
point	O
operators	O
.	O
3.2	O
linear	B
ﬁltering	O
.	O
.	O
separable	B
ﬁltering	O
.	O
.	O
.	O
.	O
.	O
.	O
3.1.1	O
pixel	O
transforms	O
.	O
.	O
3.1.2	O
color	B
transforms	O
.	O
.	O
3.1.3	O
compositing	B
and	O
matting	B
.	O
3.1.4	O
histogram	B
equalization	O
.	O
.	O
.	O
3.1.5	O
application	O
:	O
tonal	B
adjustment	I
.	O
.	O
3.2.1	O
3.2.2	O
examples	B
of	O
linear	B
ﬁltering	O
.	O
3.2.3	O
band-pass	B
and	O
steerable	B
ﬁlters	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.3.1	O
non-linear	B
ﬁltering	O
.	O
.	O
3.3.2	O
morphology	O
.	O
.	O
3.3.3	O
distance	O
transforms	O
.	O
.	O
3.3.4	O
connected	B
components	I
.	O
.	O
.	O
3.3	O
more	O
neighborhood	B
operators	O
.	O
.	O
.	O
.	O
.	O
fourier	O
transform	B
pairs	O
3.4	O
fourier	O
transforms	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.4.1	O
.	O
.	O
3.4.2	O
two-dimensional	B
fourier	O
transforms	O
.	O
3.4.3	O
wiener	O
ﬁltering	O
.	O
.	O
.	O
3.4.4	O
application	O
:	O
sharpening	O
,	O
blur	O
,	O
and	O
noise	B
removal	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.6.1	O
3.6.2	O
mesh-based	O
warping	O
.	O
.	O
3.6.3	O
application	O
:	O
feature-based	B
morphing	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.5.1	O
interpolation	B
.	O
3.5.2	O
decimation	O
.	O
.	O
3.5.3	O
multi-resolution	O
representations	O
.	O
.	O
3.5.4	O
wavelets	O
.	O
.	O
3.5.5	O
application	O
:	O
image	B
blending	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.7.1	O
regularization	B
.	O
3.7.2	O
markov	O
random	O
ﬁelds	O
.	O
.	O
3.7.3	O
application	O
:	O
image	B
restoration	I
.	O
.	O
.	O
.	O
parametric	B
transformations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
3.5	O
pyramids	O
and	O
wavelets	O
.	O
.	O
.	O
3.6	O
geometric	B
transformations	O
3.7	O
global	B
optimization	I
.	O
3.8	O
additional	O
reading	O
.	O
3.9	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
101	O
.	O
103	O
.	O
104	O
.	O
105	O
.	O
107	O
.	O
111	O
.	O
111	O
.	O
115	O
.	O
117	O
.	O
118	O
.	O
122	O
.	O
122	O
.	O
127	O
.	O
129	O
.	O
131	O
.	O
132	O
.	O
136	O
.	O
140	O
.	O
140	O
.	O
144	O
.	O
144	O
.	O
145	O
.	O
148	O
.	O
150	O
.	O
154	O
.	O
160	O
.	O
162	O
.	O
163	O
.	O
170	O
.	O
173	O
.	O
174	O
.	O
174	O
.	O
180	O
.	O
192	O
.	O
192	O
.	O
194	O
100	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
e	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
(	O
f	O
)	O
figure	O
3.1	O
some	O
common	O
image	B
processing	O
operations	O
:	O
(	O
a	O
)	O
original	O
image	B
;	O
(	O
b	O
)	O
increased	O
contrast	O
;	O
(	O
c	O
)	O
change	O
in	O
hue	B
;	O
(	O
d	O
)	O
“	O
posterized	O
”	O
(	O
quantized	O
colors	O
)	O
;	O
(	O
e	O
)	O
blurred	O
;	O
(	O
f	O
)	O
rotated	O
.	O
3.1	O
point	O
operators	O
101	O
now	O
that	O
we	O
have	O
seen	O
how	O
images	O
are	O
formed	O
through	O
the	O
interaction	O
of	O
3d	O
scene	O
elements	O
,	O
lighting	B
,	O
and	O
camera	B
optics	O
and	O
sensors	O
,	O
let	O
us	O
look	O
at	O
the	O
ﬁrst	O
stage	O
in	O
most	O
computer	O
vision	O
applications	O
,	O
namely	O
the	O
use	O
of	O
image	B
processing	O
to	O
preprocess	O
the	O
image	B
and	O
convert	O
it	O
into	O
a	O
form	O
suitable	O
for	O
further	O
analysis	O
.	O
examples	B
of	O
such	O
operations	O
include	O
exposure	O
correction	O
and	O
color	B
balancing	O
,	O
the	O
reduction	O
of	O
image	B
noise	O
,	O
increasing	O
sharpness	O
,	O
or	O
straightening	O
the	O
image	B
by	O
rotating	O
it	O
(	O
figure	O
3.1	O
)	O
.	O
while	O
some	O
may	O
consider	O
image	B
processing	O
to	O
be	O
outside	O
the	O
purview	O
of	O
computer	O
vision	O
,	O
most	O
computer	O
vision	O
applications	O
,	O
such	O
as	O
computational	O
photography	O
and	O
even	O
recognition	B
,	O
require	O
care	O
in	O
designing	O
the	O
image	B
processing	O
stages	O
in	O
order	B
to	O
achieve	O
acceptable	O
results	O
.	O
in	O
this	O
chapter	O
,	O
we	O
review	O
standard	O
image	O
processing	O
operators	O
that	O
map	O
pixel	O
values	O
from	O
one	O
image	B
to	O
another	O
.	O
image	B
processing	O
is	O
often	O
taught	O
in	O
electrical	O
engineering	O
departments	O
as	O
a	O
follow-on	O
course	O
to	O
an	O
introductory	O
course	O
in	O
signal	O
processing	O
(	O
oppenheim	O
and	O
schafer	O
1996	O
;	O
oppenheim	O
,	O
schafer	O
,	O
and	O
buck	O
1999	O
)	O
.	O
there	O
are	O
several	O
popular	O
textbooks	B
for	O
image	B
processing	O
(	O
crane	O
1997	O
;	O
gomes	O
and	O
velho	O
1997	O
;	O
j¨ahne	O
1997	O
;	O
pratt	O
2007	O
;	O
russ	O
2007	O
;	O
burger	O
and	O
burge	O
2008	O
;	O
gonzales	O
and	O
woods	O
2008	O
)	O
.	O
we	O
begin	O
this	O
chapter	O
with	O
the	O
simplest	O
kind	O
of	O
image	B
transforms	O
,	O
namely	O
those	O
that	O
manipulate	O
each	O
pixel	O
independently	O
of	O
its	O
neighbors	O
(	O
section	O
3.1	O
)	O
.	O
such	O
transforms	O
are	O
of-	O
ten	O
called	O
point	O
operators	O
or	O
point	O
processes	O
.	O
next	O
,	O
we	O
examine	O
neighborhood	B
(	O
area-based	O
)	O
operators	O
,	O
where	O
each	O
new	O
pixel	O
’	O
s	O
value	O
depends	O
on	O
a	O
small	O
number	O
of	O
neighboring	O
input	O
values	O
(	O
sections	O
3.2	O
and	O
3.3	O
)	O
.	O
a	O
convenient	O
tool	O
to	O
analyze	O
(	O
and	O
sometimes	O
accelerate	O
)	O
such	O
neighborhood	B
operations	O
is	O
the	O
fourier	O
transform	B
,	O
which	O
we	O
cover	O
in	O
section	O
3.4.	O
neighbor-	O
hood	O
operators	O
can	O
be	O
cascaded	B
to	O
form	O
image	B
pyramids	O
and	O
wavelets	O
,	O
which	O
are	O
useful	O
for	O
analyzing	O
images	O
at	O
a	O
variety	O
of	O
resolutions	O
(	O
scales	O
)	O
and	O
for	O
accelerating	O
certain	O
operations	O
(	O
section	O
3.5	O
)	O
.	O
another	O
important	O
class	O
of	O
global	B
operators	O
are	O
geometric	B
transformations	O
,	O
such	O
as	O
rotations	O
,	O
shears	O
,	O
and	O
perspective	B
deformations	O
(	O
section	O
3.6	O
)	O
.	O
finally	O
,	O
we	O
introduce	O
global	B
optimization	I
approaches	O
to	O
image	B
processing	O
,	O
which	O
involve	O
the	O
minimization	O
of	O
an	O
energy	O
functional	O
or	O
,	O
equivalently	O
,	O
optimal	O
estimation	B
using	O
bayesian	O
markov	O
random	O
ﬁeld	O
models	O
(	O
section	O
3.7	O
)	O
.	O
3.1	O
point	O
operators	O
the	O
simplest	O
kinds	O
of	O
image	B
processing	O
transforms	O
are	O
point	O
operators	O
,	O
where	O
each	O
output	O
pixel	O
’	O
s	O
value	O
depends	O
on	O
only	O
the	O
corresponding	O
input	O
pixel	O
value	O
(	O
plus	O
,	O
potentially	O
,	O
some	O
globally	O
collected	O
information	O
or	O
parameters	B
)	O
.	O
examples	B
of	O
such	O
operators	O
include	O
brightness	O
and	O
contrast	O
adjustments	O
(	O
figure	O
3.2	O
)	O
as	O
well	O
as	O
color	B
correction	O
and	O
transformations	O
.	O
in	O
the	O
image	B
processing	O
literature	O
,	O
such	O
operations	O
are	O
also	O
known	O
as	O
point	O
processes	O
(	O
crane	O
1997	O
)	O
.	O
we	O
begin	O
this	O
section	O
with	O
a	O
quick	O
review	O
of	O
simple	O
point	O
operators	O
such	O
as	O
brightness	O
102	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
e	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
(	O
f	O
)	O
figure	O
3.2	O
some	O
local	B
image	O
processing	O
operations	O
:	O
(	O
a	O
)	O
original	O
image	B
along	O
with	O
its	O
three	O
color	B
(	O
per-channel	O
)	O
histograms	O
;	O
(	O
b	O
)	O
brightness	O
increased	O
(	O
additive	O
offset	O
,	O
b	O
=	O
16	O
)	O
;	O
(	O
c	O
)	O
contrast	O
increased	O
(	O
multiplicative	O
gain	O
,	O
a	O
=	O
1.1	O
)	O
;	O
(	O
d	O
)	O
gamma	B
(	O
partially	O
)	O
linearized	O
(	O
γ	O
=	O
1.2	O
)	O
;	O
(	O
e	O
)	O
full	O
histogram	B
equalization	O
;	O
(	O
f	O
)	O
partial	O
histogram	B
equalization	O
.	O
3.1	O
point	O
operators	O
103	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
3.3	O
visualizing	O
image	B
data	O
:	O
(	O
a	O
)	O
original	O
image	B
;	O
(	O
b	O
)	O
cropped	O
portion	O
and	O
scanline	O
plot	O
using	O
an	O
image	B
inspection	O
tool	O
;	O
(	O
c	O
)	O
grid	O
of	O
numbers	O
;	O
(	O
d	O
)	O
surface	B
plot	O
.	O
for	O
ﬁgures	O
(	O
c	O
)	O
–	O
(	O
d	O
)	O
,	O
the	O
image	B
was	O
ﬁrst	O
converted	O
to	O
grayscale	O
.	O
scaling	O
and	O
image	B
addition	O
.	O
next	O
,	O
we	O
discuss	O
how	O
colors	O
in	O
images	O
can	O
be	O
manipulated	O
.	O
we	O
then	O
present	O
image	B
compositing	O
and	O
matting	B
operations	O
,	O
which	O
play	O
an	O
important	O
role	O
in	O
computational	O
photography	O
(	O
chapter	O
10	O
)	O
and	O
computer	O
graphics	O
applications	O
.	O
finally	O
,	O
we	O
describe	O
the	O
more	O
global	B
process	O
of	O
histogram	B
equalization	O
.	O
we	O
close	O
with	O
an	O
example	O
appli-	O
cation	O
that	O
manipulates	O
tonal	O
values	O
(	O
exposure	O
and	O
contrast	O
)	O
to	O
improve	O
image	B
appearance	O
.	O
3.1.1	O
pixel	O
transforms	O
a	O
general	O
image	B
processing	O
operator	O
is	O
a	O
function	O
that	O
takes	O
one	O
or	O
more	O
input	O
images	O
and	O
produces	O
an	O
output	O
image	B
.	O
in	O
the	O
continuous	O
domain	O
,	O
this	O
can	O
be	O
denoted	O
as	O
g	O
(	O
x	O
)	O
=	O
h	O
(	O
f	O
(	O
x	O
)	O
)	O
or	O
g	O
(	O
x	O
)	O
=	O
h	O
(	O
f0	O
(	O
x	O
)	O
,	O
.	O
.	O
.	O
,	O
fn	O
(	O
x	O
)	O
)	O
,	O
(	O
3.1	O
)	O
where	O
x	O
is	O
in	O
the	O
d-dimensional	O
domain	O
of	O
the	O
functions	O
(	O
usually	O
d	O
=	O
2	O
for	O
images	O
)	O
and	O
the	O
functions	O
f	O
and	O
g	O
operate	O
over	O
some	O
range	O
,	O
which	O
can	O
either	O
be	O
scalar	O
or	O
vector-valued	O
,	O
e.g.	O
,	O
for	O
color	O
images	O
or	O
2d	O
motion	B
.	O
for	O
discrete	O
(	O
sampled	O
)	O
images	O
,	O
the	O
domain	O
consists	O
of	O
a	O
ﬁnite	O
number	O
of	O
pixel	O
locations	O
,	O
x	O
=	O
(	O
i	O
,	O
j	O
)	O
,	O
and	O
we	O
can	O
write	O
g	O
(	O
i	O
,	O
j	O
)	O
=	O
h	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
)	O
.	O
(	O
3.2	O
)	O
figure	O
3.3	O
shows	O
how	O
an	O
image	B
can	O
be	O
represented	O
either	O
by	O
its	O
color	B
(	O
appearance	O
)	O
,	O
as	O
a	O
grid	O
of	O
numbers	O
,	O
or	O
as	O
a	O
two-dimensional	B
function	O
(	O
surface	B
plot	O
)	O
.	O
two	O
commonly	O
used	O
point	O
processes	O
are	O
multiplication	B
and	O
addition	O
with	O
a	O
constant	O
,	O
g	O
(	O
x	O
)	O
=	O
af	O
(	O
x	O
)	O
+	O
b	O
.	O
(	O
3.3	O
)	O
the	O
parameters	B
a	O
>	O
0	O
and	O
b	O
are	O
often	O
called	O
the	O
gain	O
and	O
bias	O
parameters	O
;	O
sometimes	O
these	O
parameters	B
are	O
said	O
to	O
control	O
contrast	O
and	O
brightness	O
,	O
respectively	O
(	O
figures	O
3.2b–c	O
)	O
.1	O
the	O
1	O
an	O
image	B
’	O
s	O
luminance	O
characteristics	O
can	O
also	O
be	O
summarized	O
by	O
its	O
key	O
(	O
average	O
luminanance	O
)	O
and	O
range	O
(	O
kopf	O
,	O
uyttendaele	O
,	O
deussen	O
et	O
al	O
.	O
2007	O
)	O
.	O
456098127132133137133466598123126128131133476596115119123135137476391107113122138134505980971101231331344953688397113128133505058708410211612650505258698610112013579111315s1s2s3s4s5s6s7s8s9s10s11s12s13s14s15s16020406080100120140160rangedomaindomain	O
104	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
bias	B
and	I
gain	I
parameters	O
can	O
also	O
be	O
spatially	O
varying	O
,	O
g	O
(	O
x	O
)	O
=	O
a	O
(	O
x	O
)	O
f	O
(	O
x	O
)	O
+	O
b	O
(	O
x	O
)	O
,	O
(	O
3.4	O
)	O
e.g.	O
,	O
when	O
simulating	O
the	O
graded	O
density	O
ﬁlter	O
used	O
by	O
photographers	O
to	O
selectively	O
darken	O
the	O
sky	O
or	O
when	O
modeling	B
vignetting	O
in	O
an	O
optical	O
system	O
.	O
multiplicative	O
gain	O
(	O
both	O
global	O
and	O
spatially	O
varying	O
)	O
is	O
a	O
linear	B
operation	O
,	O
since	O
it	O
obeys	O
the	O
superposition	B
principle	O
,	O
h	O
(	O
f0	O
+	O
f1	O
)	O
=	O
h	O
(	O
f0	O
)	O
+	O
h	O
(	O
f1	O
)	O
.	O
(	O
3.5	O
)	O
(	O
we	O
will	O
have	O
more	O
to	O
say	O
about	O
linear	B
shift	O
invariant	O
operators	O
in	O
section	O
3.2	O
.	O
)	O
operators	O
such	O
as	O
image	B
squaring	O
(	O
which	O
is	O
often	O
used	O
to	O
get	O
a	O
local	B
estimate	O
of	O
the	O
energy	O
in	O
a	O
band-	O
pass	O
ﬁltered	O
signal	O
,	O
see	O
section	O
3.5	O
)	O
are	O
not	O
linear	B
.	O
another	O
commonly	O
used	O
dyadic	O
(	O
two-input	O
)	O
operator	O
is	O
the	O
linear	B
blend	O
operator	O
,	O
g	O
(	O
x	O
)	O
=	O
(	O
1	O
−	O
α	O
)	O
f0	O
(	O
x	O
)	O
+	O
αf1	O
(	O
x	O
)	O
.	O
(	O
3.6	O
)	O
by	O
varying	O
α	O
from	O
0	O
→	O
1	O
,	O
this	O
operator	O
can	O
be	O
used	O
to	O
perform	O
a	O
temporal	O
cross-dissolve	O
between	O
two	O
images	O
or	O
videos	O
,	O
as	O
seen	O
in	O
slide	O
shows	O
and	O
ﬁlm	O
production	O
,	O
or	O
as	O
a	O
component	O
of	O
image	B
morphing	O
algorithms	O
(	O
section	O
3.6.3	O
)	O
.	O
one	O
highly	O
used	O
non-linear	B
transform	O
that	O
is	O
often	O
applied	O
to	O
images	O
before	O
further	O
pro-	O
cessing	O
is	O
gamma	B
correction	O
,	O
which	O
is	O
used	O
to	O
remove	O
the	O
non-linear	B
mapping	O
between	O
input	O
radiance	O
and	O
quantized	O
pixel	O
values	O
(	O
section	O
2.3.2	O
)	O
.	O
to	O
invert	O
the	O
gamma	B
mapping	O
applied	O
by	O
the	O
sensor	B
,	O
we	O
can	O
use	O
g	O
(	O
x	O
)	O
=	O
[	O
f	O
(	O
x	O
)	O
]	O
1/γ	O
,	O
(	O
3.7	O
)	O
where	O
a	O
gamma	B
value	O
of	O
γ	O
≈	O
2.2	O
is	O
a	O
reasonable	O
ﬁt	O
for	O
most	O
digital	O
cameras	O
.	O
3.1.2	O
color	B
transforms	O
while	O
color	B
images	O
can	O
be	O
treated	O
as	O
arbitrary	O
vector-valued	O
functions	O
or	O
collections	O
of	O
inde-	O
pendent	O
bands	O
,	O
it	O
usually	O
makes	O
sense	O
to	O
think	O
about	O
them	O
as	O
highly	O
correlated	O
signals	O
with	O
strong	O
connections	O
to	O
the	O
image	B
formation	O
process	O
(	O
section	O
2.2	O
)	O
,	O
sensor	B
design	O
(	O
section	O
2.3	O
)	O
,	O
and	O
human	O
perception	O
(	O
section	O
2.3.2	O
)	O
.	O
consider	O
,	O
for	O
example	O
,	O
brightening	O
a	O
picture	O
by	O
adding	O
a	O
constant	O
value	O
to	O
all	O
three	O
channels	O
,	O
as	O
shown	O
in	O
figure	O
3.2b	O
.	O
can	O
you	O
tell	O
if	O
this	O
achieves	O
the	O
desired	O
effect	O
of	O
making	O
the	O
image	B
look	O
brighter	O
?	O
can	O
you	O
see	O
any	O
undesirable	O
side-effects	O
or	O
artifacts	O
?	O
in	O
fact	O
,	O
adding	O
the	O
same	O
value	O
to	O
each	O
color	B
channel	O
not	O
only	O
increases	O
the	O
apparent	O
in-	O
tensity	O
of	O
each	O
pixel	O
,	O
it	O
can	O
also	O
affect	O
the	O
pixel	O
’	O
s	O
hue	B
and	O
saturation	O
.	O
how	O
can	O
we	O
deﬁne	O
and	O
manipulate	O
such	O
quantities	O
in	O
order	B
to	O
achieve	O
the	O
desired	O
perceptual	O
effects	O
?	O
3.1	O
point	O
operators	O
105	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
3.4	O
image	B
matting	O
and	O
compositing	B
(	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
source	O
image	B
;	O
(	O
b	O
)	O
extracted	O
foreground	O
object	O
f	O
;	O
(	O
c	O
)	O
alpha	B
matte	I
α	O
shown	O
in	O
grayscale	O
;	O
(	O
d	O
)	O
new	O
composite	O
c.	O
as	O
discussed	O
in	O
section	O
2.3.2	O
,	O
chromaticity	O
coordinates	O
(	O
2.104	O
)	O
or	O
even	O
simpler	O
color	B
ra-	O
tios	O
(	O
2.116	O
)	O
can	O
ﬁrst	O
be	O
computed	O
and	O
then	O
used	O
after	O
manipulating	O
(	O
e.g.	O
,	O
brightening	O
)	O
the	O
luminance	O
y	O
to	O
re-compute	O
a	O
valid	O
rgb	O
image	B
with	O
the	O
same	O
hue	B
and	O
saturation	O
.	O
figure	O
2.32g–i	O
shows	O
some	O
color	B
ratio	O
images	O
multiplied	O
by	O
the	O
middle	O
gray	O
value	O
for	O
better	O
visual-	O
ization	O
.	O
similarly	O
,	O
color	B
balancing	O
(	O
e.g.	O
,	O
to	O
compensate	O
for	O
incandescent	O
lighting	B
)	O
can	O
be	O
per-	O
formed	O
either	O
by	O
multiplying	O
each	O
channel	O
with	O
a	O
different	O
scale	O
factor	O
or	O
by	O
the	O
more	O
com-	O
plex	O
process	O
of	O
mapping	O
to	O
xyz	O
color	B
space	O
,	O
changing	O
the	O
nominal	O
white	O
point	O
,	O
and	O
mapping	O
back	O
to	O
rgb	O
,	O
which	O
can	O
be	O
written	O
down	O
using	O
a	O
linear	B
3	O
×	O
3	O
color	B
twist	O
transform	B
matrix	O
.	O
exercises	O
2.9	O
and	O
3.1	O
have	O
you	O
explore	O
some	O
of	O
these	O
issues	O
.	O
another	O
fun	O
project	O
,	O
best	O
attempted	O
after	O
you	O
have	O
mastered	O
the	O
rest	O
of	O
the	O
material	O
in	O
this	O
chapter	O
,	O
is	O
to	O
take	O
a	O
picture	O
with	O
a	O
rainbow	O
in	O
it	O
and	O
enhance	O
the	O
strength	O
of	O
the	O
rainbow	O
(	O
exercise	O
3.29	O
)	O
.	O
3.1.3	O
compositing	B
and	O
matting	B
in	O
many	O
photo	O
editing	O
and	O
visual	B
effects	I
applications	O
,	O
it	O
is	O
often	O
desirable	O
to	O
cut	O
a	O
foreground	O
object	O
out	O
of	O
one	O
scene	O
and	O
put	O
it	O
on	O
top	O
of	O
a	O
different	O
background	O
(	O
figure	O
3.4	O
)	O
.	O
the	O
process	O
of	O
extracting	O
the	O
object	O
from	O
the	O
original	O
image	B
is	O
often	O
called	O
matting	B
(	O
smith	O
and	O
blinn	O
1996	O
)	O
,	O
while	O
the	O
process	O
of	O
inserting	O
it	O
into	O
another	O
image	B
(	O
without	O
visible	O
artifacts	O
)	O
is	O
called	O
compositing	B
(	O
porter	O
and	O
duff	O
1984	O
;	O
blinn	O
1994a	O
)	O
.	O
the	O
intermediate	O
representation	O
used	O
for	O
the	O
foreground	O
object	O
between	O
these	O
two	O
stages	O
is	O
called	O
an	O
alpha-matted	O
color	B
image	O
(	O
figure	O
3.4b–c	O
)	O
.	O
in	O
addition	O
to	O
the	O
three	O
color	B
rgb	O
channels	O
,	O
an	O
alpha-matted	O
image	B
contains	O
a	O
fourth	O
alpha	O
channel	O
α	O
(	O
or	O
a	O
)	O
that	O
describes	O
the	O
relative	O
amount	O
of	O
opacity	B
or	O
fractional	O
coverage	O
at	O
each	O
pixel	O
(	O
figures	O
3.4c	O
and	O
3.5b	O
)	O
.	O
the	O
opacity	B
is	O
the	O
opposite	O
of	O
the	O
transparency	B
.	O
pixels	O
within	O
the	O
object	O
are	O
fully	O
opaque	O
(	O
α	O
=	O
1	O
)	O
,	O
while	O
pixels	O
fully	O
outside	O
the	O
object	O
are	O
transparent	B
(	O
α	O
=	O
0	O
)	O
.	O
pixels	O
on	O
the	O
boundary	O
of	O
the	O
object	O
vary	O
smoothly	O
between	O
these	O
two	O
extremes	O
,	O
which	O
hides	O
the	O
perceptual	O
visible	O
jaggies	O
106	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
×	O
(	O
1−	O
)	O
+	O
=	O
b	O
(	O
a	O
)	O
α	O
(	O
b	O
)	O
αf	O
(	O
c	O
)	O
c	O
(	O
d	O
)	O
figure	O
3.5	O
compositing	B
equation	O
c	O
=	O
(	O
1	O
−	O
α	O
)	O
b	O
+	O
αf	O
.	O
the	O
images	O
are	O
taken	O
from	O
a	O
close-up	O
of	O
the	O
region	B
of	O
the	O
hair	O
in	O
the	O
upper	O
right	O
part	O
of	O
the	O
lion	O
in	O
figure	O
3.4.	O
that	O
occur	O
if	O
only	O
binary	O
opacities	O
are	O
used	O
.	O
to	O
composite	O
a	O
new	O
(	O
or	O
foreground	O
)	O
image	B
on	O
top	O
of	O
an	O
old	O
(	O
background	O
)	O
image	B
,	O
the	O
over	B
operator	I
,	O
ﬁrst	O
proposed	O
by	O
porter	O
and	O
duff	O
(	O
1984	O
)	O
and	O
then	O
studied	O
extensively	O
by	O
blinn	O
(	O
1994a	O
;	O
1994b	O
)	O
,	O
is	O
used	O
,	O
(	O
3.8	O
)	O
this	O
operator	O
attenuates	O
the	O
inﬂuence	O
of	O
the	O
background	O
image	O
b	O
by	O
a	O
factor	O
(	O
1	O
−	O
α	O
)	O
and	O
then	O
adds	O
in	O
the	O
color	B
(	O
and	O
opacity	B
)	O
values	O
corresponding	O
to	O
the	O
foreground	O
layer	O
f	O
,	O
as	O
shown	O
in	O
figure	O
3.5.	O
c	O
=	O
(	O
1	O
−	O
α	O
)	O
b	O
+	O
αf	O
.	O
in	O
many	O
situations	O
,	O
it	O
is	O
convenient	O
to	O
represent	O
the	O
foreground	O
colors	O
in	O
pre-multiplied	B
form	O
,	O
i.e.	O
,	O
to	O
store	O
(	O
and	O
manipulate	O
)	O
the	O
αf	O
values	O
directly	O
.	O
as	O
blinn	O
(	O
1994b	O
)	O
shows	O
,	O
the	O
pre-multiplied	B
rgba	O
representation	O
is	O
preferred	O
for	O
several	O
reasons	O
,	O
including	O
the	O
ability	O
to	O
blur	O
or	O
resample	O
(	O
e.g.	O
,	O
rotate	O
)	O
alpha-matted	O
images	O
without	O
any	O
additional	O
complications	O
(	O
just	O
treating	O
each	O
rgba	O
band	O
independently	O
)	O
.	O
however	O
,	O
when	O
matting	B
using	O
local	B
color	O
consistency	O
(	O
ruzon	O
and	O
tomasi	O
2000	O
;	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
2001	O
)	O
,	O
the	O
pure	O
un-	O
multiplied	O
foreground	O
colors	O
f	O
are	O
used	O
,	O
since	O
these	O
remain	O
constant	O
(	O
or	O
vary	O
slowly	O
)	O
in	O
the	O
vicinity	O
of	O
the	O
object	O
edge	O
.	O
the	O
over	O
operation	O
is	O
not	O
the	O
only	O
kind	O
of	O
compositing	B
operation	O
that	O
can	O
be	O
used	O
.	O
porter	O
and	O
duff	O
(	O
1984	O
)	O
describe	O
a	O
number	O
of	O
additional	O
operations	O
that	O
can	O
be	O
useful	O
in	O
photo	O
editing	O
and	O
visual	B
effects	I
applications	O
.	O
in	O
this	O
book	O
,	O
we	O
concern	O
ourselves	O
with	O
only	O
one	O
additional	O
,	O
commonly	O
occurring	O
case	O
(	O
but	O
see	O
exercise	O
3.2	O
)	O
.	O
when	O
light	O
reﬂects	O
off	O
clean	O
transparent	B
glass	O
,	O
the	O
light	O
passing	O
through	O
the	O
glass	O
and	O
the	O
light	O
reﬂecting	O
off	O
the	O
glass	O
are	O
simply	O
added	O
together	O
(	O
figure	O
3.6	O
)	O
.	O
this	O
model	O
is	O
use-	O
ful	O
in	O
the	O
analysis	O
of	O
transparent	B
motion	O
(	O
black	O
and	O
anandan	O
1996	O
;	O
szeliski	O
,	O
avidan	O
,	O
and	O
anandan	O
2000	O
)	O
,	O
which	O
occurs	O
when	O
such	O
scenes	O
are	O
observed	O
from	O
a	O
moving	O
camera	O
(	O
see	O
section	O
8.5.2	O
)	O
.	O
the	O
actual	O
process	O
of	O
matting	B
,	O
i.e.	O
,	O
recovering	O
the	O
foreground	O
,	O
background	O
,	O
and	O
alpha	B
matte	I
values	O
from	O
one	O
or	O
more	O
images	O
,	O
has	O
a	O
rich	O
history	O
,	O
which	O
we	O
study	O
in	O
section	O
10.4	O
.	O
3.1	O
point	O
operators	O
107	O
figure	O
3.6	O
an	O
example	O
of	O
light	O
reﬂecting	O
off	O
the	O
transparent	B
glass	O
of	O
a	O
picture	O
frame	O
(	O
black	O
and	O
anandan	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
elsevier	O
.	O
you	O
can	O
clearly	O
see	O
the	O
woman	O
’	O
s	O
portrait	O
inside	O
the	O
picture	O
frame	O
superimposed	O
with	O
the	O
reﬂection	O
of	O
a	O
man	O
’	O
s	O
face	B
off	O
the	O
glass	O
.	O
smith	O
and	O
blinn	O
(	O
1996	O
)	O
have	O
a	O
nice	O
survey	O
of	O
traditional	O
blue-screen	O
matting	B
techniques	O
,	O
while	O
toyama	O
,	O
krumm	O
,	O
brumitt	O
et	O
al	O
.	O
(	O
1999	O
)	O
review	O
difference	B
matting	O
.	O
more	O
recently	O
,	O
there	O
has	O
been	O
a	O
lot	O
of	O
activity	O
in	O
computational	O
photography	O
relating	O
to	O
natural	B
image	O
matting	B
(	O
ruzon	O
and	O
tomasi	O
2000	O
;	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
2001	O
;	O
wang	O
and	O
cohen	O
2007a	O
)	O
,	O
which	O
attempts	O
to	O
extract	O
the	O
mattes	O
from	O
a	O
single	O
natural	O
image	B
(	O
figure	O
3.4a	O
)	O
or	O
from	O
ex-	O
tended	O
video	B
sequences	O
(	O
chuang	O
,	O
agarwala	O
,	O
curless	O
et	O
al	O
.	O
2002	O
)	O
.	O
all	O
of	O
these	O
techniques	O
are	O
described	O
in	O
more	O
detail	O
in	O
section	O
10.4	O
.	O
3.1.4	O
histogram	B
equalization	O
while	O
the	O
brightness	O
and	O
gain	O
controls	O
described	O
in	O
section	O
3.1.1	O
can	O
improve	O
the	O
appearance	O
of	O
an	O
image	B
,	O
how	O
can	O
we	O
automatically	O
determine	O
their	O
best	O
values	O
?	O
one	O
approach	O
might	O
be	O
to	O
look	O
at	O
the	O
darkest	O
and	O
brightest	O
pixel	O
values	O
in	O
an	O
image	B
and	O
map	O
them	O
to	O
pure	O
black	O
and	O
pure	O
white	O
.	O
another	O
approach	O
might	O
be	O
to	O
ﬁnd	O
the	O
average	O
value	O
in	O
the	O
image	B
,	O
push	O
it	O
towards	O
middle	O
gray	O
,	O
and	O
expand	O
the	O
range	O
so	O
that	O
it	O
more	O
closely	O
ﬁlls	O
the	O
displayable	O
values	O
(	O
kopf	O
,	O
uyttendaele	O
,	O
deussen	O
et	O
al	O
.	O
2007	O
)	O
.	O
how	O
can	O
we	O
visualize	O
the	O
set	O
of	O
lightness	O
values	O
in	O
an	O
image	B
in	O
order	B
to	O
test	O
some	O
of	O
these	O
heuristics	O
?	O
the	O
answer	O
is	O
to	O
plot	O
the	O
histogram	B
of	O
the	O
individual	O
color	B
channels	O
and	O
luminance	O
values	O
,	O
as	O
shown	O
in	O
figure	O
3.7b.2	O
from	O
this	O
distribution	O
,	O
we	O
can	O
compute	O
relevant	O
statistics	O
such	O
as	O
the	O
minimum	O
,	O
maximum	O
,	O
and	O
average	O
intensity	O
values	O
.	O
notice	O
that	O
the	O
image	B
in	O
figure	O
3.7a	O
has	O
both	O
an	O
excess	O
of	O
dark	O
values	O
and	O
light	O
values	O
,	O
but	O
that	O
the	O
mid-range	O
values	O
are	O
largely	O
under-populated	O
.	O
would	O
it	O
not	O
be	O
better	O
if	O
we	O
could	O
simultaneously	O
brighten	O
some	O
2	O
the	O
histogram	B
is	O
simply	O
the	O
count	O
of	O
the	O
number	O
of	O
pixels	O
at	O
each	O
gray	O
level	O
value	O
.	O
for	O
an	O
eight-bit	O
image	B
,	O
an	O
accumulation	O
table	O
with	O
256	O
entries	O
is	O
needed	O
.	O
for	O
higher	O
bit	O
depths	O
,	O
a	O
table	O
with	O
the	O
appropriate	O
number	O
of	O
entries	O
(	O
probably	O
fewer	O
than	O
the	O
full	O
number	O
of	O
gray	O
levels	O
)	O
should	O
be	O
used	O
.	O
108	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
figure	O
3.7	O
histogram	B
analysis	O
and	O
equalization	O
:	O
(	O
a	O
)	O
original	O
image	B
(	O
b	O
)	O
color	B
channel	O
and	O
in-	O
tensity	O
(	O
luminance	O
)	O
histograms	O
;	O
(	O
c	O
)	O
cumulative	O
distribution	O
functions	O
;	O
(	O
d	O
)	O
equalization	O
(	O
trans-	O
fer	O
)	O
functions	O
;	O
(	O
e	O
)	O
full	O
histogram	B
equalization	O
;	O
(	O
f	O
)	O
partial	O
histogram	B
equalization	O
.	O
dark	O
values	O
and	O
darken	O
some	O
light	O
values	O
,	O
while	O
still	O
using	O
the	O
full	O
extent	O
of	O
the	O
available	O
dynamic	B
range	O
?	O
can	O
you	O
think	O
of	O
a	O
mapping	O
that	O
might	O
do	O
this	O
?	O
one	O
popular	O
answer	O
to	O
this	O
question	O
is	O
to	O
perform	O
histogram	B
equalization	O
,	O
i.e.	O
,	O
to	O
ﬁnd	O
an	O
intensity	O
mapping	O
function	O
f	O
(	O
i	O
)	O
such	O
that	O
the	O
resulting	O
histogram	B
is	O
ﬂat	O
.	O
the	O
trick	O
to	O
ﬁnding	O
such	O
a	O
mapping	O
is	O
the	O
same	O
one	O
that	O
people	O
use	O
to	O
generate	O
random	O
samples	O
from	O
a	O
probability	O
density	O
function	O
,	O
which	O
is	O
to	O
ﬁrst	O
compute	O
the	O
cumulative	O
distribution	O
function	O
shown	O
in	O
figure	O
3.7c	O
.	O
think	O
of	O
the	O
original	O
histogram	B
h	O
(	O
i	O
)	O
as	O
the	O
distribution	O
of	O
grades	O
in	O
a	O
class	O
after	O
some	O
exam	O
.	O
how	O
can	O
we	O
map	O
a	O
particular	O
grade	O
to	O
its	O
corresponding	O
percentile	O
,	O
so	O
that	O
students	O
at	O
the	O
75	O
%	O
percentile	O
range	O
scored	O
better	O
than	O
3/4	O
of	O
their	O
classmates	O
?	O
the	O
answer	O
is	O
to	O
integrate	O
the	O
distribution	O
h	O
(	O
i	O
)	O
to	O
obtain	O
the	O
cumulative	O
distribution	O
c	O
(	O
i	O
)	O
,	O
c	O
(	O
i	O
)	O
=	O
1	O
n	O
h	O
(	O
i	O
)	O
=	O
c	O
(	O
i	O
−	O
1	O
)	O
+	O
1	O
n	O
h	O
(	O
i	O
)	O
,	O
(	O
3.9	O
)	O
i	O
(	O
cid:88	O
)	O
i=0	O
where	O
n	O
is	O
the	O
number	O
of	O
pixels	O
in	O
the	O
image	B
or	O
students	O
in	O
the	O
class	O
.	O
for	O
any	O
given	O
grade	O
or	O
intensity	O
,	O
we	O
can	O
look	O
up	O
its	O
corresponding	O
percentile	O
c	O
(	O
i	O
)	O
and	O
determine	O
the	O
ﬁnal	O
value	O
that	O
pixel	O
should	O
take	O
.	O
when	O
working	O
with	O
eight-bit	O
pixel	O
values	O
,	O
the	O
i	O
and	O
c	O
axes	O
are	O
rescaled	O
from	O
[	O
0	O
,	O
255	O
]	O
.	O
0100020003000400050006000050100150200250bgry050000100000150000200000250000300000350000050100150200250bgry050100150200250050100150200250bgry	O
3.1	O
point	O
operators	O
109	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
3.8	O
locally	B
adaptive	I
histogram	O
equalization	O
:	O
(	O
a	O
)	O
original	O
image	B
;	O
(	O
b	O
)	O
block	O
histogram	O
equalization	O
;	O
(	O
c	O
)	O
full	O
locally	B
adaptive	I
equalization	O
.	O
figure	O
3.7d	O
shows	O
the	O
result	O
of	O
applying	O
f	O
(	O
i	O
)	O
=	O
c	O
(	O
i	O
)	O
to	O
the	O
original	O
image	B
.	O
as	O
we	O
can	O
see	O
,	O
the	O
resulting	O
histogram	B
is	O
ﬂat	O
;	O
so	O
is	O
the	O
resulting	O
image	B
(	O
it	O
is	O
“	O
ﬂat	O
”	O
in	O
the	O
sense	O
of	O
a	O
lack	O
of	O
contrast	O
and	O
being	O
muddy	O
looking	O
)	O
.	O
one	O
way	O
to	O
compensate	O
for	O
this	O
is	O
to	O
only	O
partially	O
compensate	O
for	O
the	O
histogram	B
unevenness	O
,	O
e.g.	O
,	O
by	O
using	O
a	O
mapping	O
function	O
f	O
(	O
i	O
)	O
=	O
αc	O
(	O
i	O
)	O
+	O
(	O
1	O
−	O
α	O
)	O
i	O
,	O
which	O
is	O
a	O
linear	B
blend	O
between	O
the	O
cumulative	O
distribution	O
function	O
and	O
the	O
identity	O
transform	B
(	O
a	O
straight	O
line	O
)	O
.	O
as	O
you	O
can	O
see	O
in	O
figure	O
3.7e	O
,	O
the	O
resulting	O
image	B
maintains	O
more	O
of	O
its	O
original	O
grayscale	O
distribution	O
while	O
having	O
a	O
more	O
appealing	O
balance	B
.	O
another	O
potential	O
problem	O
with	O
histogram	O
equalization	O
(	O
or	O
,	O
in	O
general	O
,	O
image	B
brightening	O
)	O
is	O
that	O
noise	B
in	O
dark	O
regions	O
can	O
be	O
ampliﬁed	O
and	O
become	O
more	O
visible	O
.	O
exercise	O
3.6	O
suggests	O
some	O
possible	O
ways	O
to	O
mitigate	O
this	O
,	O
as	O
well	O
as	O
alternative	O
techniques	O
to	O
maintain	O
contrast	O
and	O
“	O
punch	O
”	O
in	O
the	O
original	O
images	O
(	O
larson	O
,	O
rushmeier	O
,	O
and	O
piatko	O
1997	O
;	O
stark	O
2000	O
)	O
.	O
locally	B
adaptive	I
histogram	O
equalization	O
while	O
global	B
histogram	O
equalization	O
can	O
be	O
useful	O
,	O
for	O
some	O
images	O
it	O
might	O
be	O
preferable	O
to	O
apply	O
different	O
kinds	O
of	O
equalization	O
in	O
different	O
regions	O
.	O
consider	O
for	O
example	O
the	O
image	B
in	O
figure	O
3.8a	O
,	O
which	O
has	O
a	O
wide	O
range	O
of	O
luminance	O
values	O
.	O
instead	O
of	O
computing	O
a	O
single	O
curve	O
,	O
what	O
if	O
we	O
were	O
to	O
subdivide	O
the	O
image	B
into	O
m	O
×	O
m	O
pixel	O
blocks	O
and	O
perform	O
separate	O
histogram	B
equalization	O
in	O
each	O
sub-block	O
?	O
as	O
you	O
can	O
see	O
in	O
figure	O
3.8b	O
,	O
the	O
resulting	O
image	B
exhibits	O
a	O
lot	O
of	O
blocking	O
artifacts	O
,	O
i.e.	O
,	O
intensity	O
discontinuities	O
at	O
block	O
boundaries	O
.	O
one	O
way	O
to	O
eliminate	O
blocking	O
artifacts	O
is	O
to	O
use	O
a	O
moving	O
window	O
,	O
i.e.	O
,	O
to	O
recompute	O
the	O
histogram	B
for	O
every	O
m	O
×	O
m	O
block	O
centered	O
at	O
each	O
pixel	O
.	O
this	O
process	O
can	O
be	O
quite	O
slow	O
(	O
m	O
2	O
operations	O
per	O
pixel	O
)	O
,	O
although	O
with	O
clever	O
programming	O
only	O
the	O
histogram	B
entries	O
corresponding	O
to	O
the	O
pixels	O
entering	O
and	O
leaving	O
the	O
block	O
(	O
in	O
a	O
raster	O
scan	O
across	O
the	O
image	B
)	O
need	O
to	O
be	O
updated	O
(	O
m	O
operations	O
per	O
pixel	O
)	O
.	O
note	O
that	O
this	O
operation	O
is	O
an	O
example	O
of	O
the	O
non-linear	B
neighborhood	O
operations	O
we	O
study	O
in	O
more	O
detail	O
in	O
section	O
3.3.1.	O
a	O
more	O
efﬁcient	O
approach	O
is	O
to	O
compute	O
non-overlapped	O
block-based	O
equalization	O
func-	O
tions	O
as	O
before	O
,	O
but	O
to	O
then	O
smoothly	O
interpolate	O
the	O
transfer	B
functions	O
as	O
we	O
move	O
between	O
110	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.9	O
local	B
histogram	O
interpolation	B
using	O
relative	O
(	O
s	O
,	O
t	O
)	O
coordinates	O
:	O
(	O
a	O
)	O
block-based	O
histograms	O
,	O
with	O
block	O
centers	O
shown	O
as	O
circles	O
;	O
(	O
b	O
)	O
corner-based	O
“	O
spline	B
”	O
histograms	O
.	O
pixels	O
are	O
located	O
on	O
grid	O
intersections	O
.	O
the	O
black	O
square	O
pixel	O
’	O
s	O
transfer	B
function	O
is	O
interpolated	O
from	O
the	O
four	O
adjacent	O
lookup	O
tables	O
(	O
gray	O
arrows	O
)	O
using	O
the	O
computed	O
(	O
s	O
,	O
t	O
)	O
values	O
.	O
block	O
boundaries	O
are	O
shown	O
as	O
dashed	O
lines	B
.	O
blocks	O
.	O
this	O
technique	O
is	O
known	O
as	O
adaptive	B
histogram	O
equalization	O
(	O
ahe	O
)	O
and	O
its	O
contrast-	O
limited	O
(	O
gain-limited	O
)	O
version	O
is	O
known	O
as	O
clahe	O
(	O
pizer	O
,	O
amburn	O
,	O
austin	O
et	O
al	O
.	O
1987	O
)	O
.3	O
the	O
weighting	B
function	O
for	O
a	O
given	O
pixel	O
(	O
i	O
,	O
j	O
)	O
can	O
be	O
computed	O
as	O
a	O
function	O
of	O
its	O
horizontal	O
and	O
vertical	O
position	O
(	O
s	O
,	O
t	O
)	O
within	O
a	O
block	O
,	O
as	O
shown	O
in	O
figure	O
3.9a	O
.	O
to	O
blend	O
the	O
four	O
lookup	O
functions	O
{	O
f00	O
,	O
.	O
.	O
.	O
,	O
f11	O
}	O
,	O
a	O
bilinear	B
blending	O
function	O
,	O
fs	O
,	O
t	O
(	O
i	O
)	O
=	O
(	O
1	O
−	O
s	O
)	O
(	O
1	O
−	O
t	O
)	O
f00	O
(	O
i	O
)	O
+	O
s	O
(	O
1	O
−	O
t	O
)	O
f10	O
(	O
i	O
)	O
+	O
(	O
1	O
−	O
s	O
)	O
tf01	O
(	O
i	O
)	O
+	O
stf11	O
(	O
i	O
)	O
(	O
3.10	O
)	O
can	O
be	O
used	O
.	O
(	O
see	O
section	O
3.5.2	O
for	O
higher-order	O
generalizations	O
of	O
such	O
spline	B
functions	O
.	O
)	O
note	O
that	O
instead	O
of	O
blending	B
the	O
four	O
lookup	O
tables	O
for	O
each	O
output	O
pixel	O
(	O
which	O
would	O
be	O
quite	O
slow	O
)	O
,	O
we	O
can	O
instead	O
blend	O
the	O
results	O
of	O
mapping	O
a	O
given	O
pixel	O
through	O
the	O
four	O
neigh-	O
boring	O
lookups	O
.	O
a	O
variant	O
on	O
this	O
algorithm	B
is	O
to	O
place	O
the	O
lookup	O
tables	O
at	O
the	O
corners	O
of	O
each	O
m	O
×	O
m	O
block	O
(	O
see	O
figure	O
3.9b	O
and	O
exercise	O
3.7	O
)	O
.	O
in	O
addition	O
to	O
blending	B
four	O
lookups	O
to	O
compute	O
the	O
ﬁnal	O
value	O
,	O
we	O
can	O
also	O
distribute	O
each	O
input	O
pixel	O
into	O
four	O
adjacent	O
lookup	O
tables	O
during	O
the	O
histogram	B
accumulation	O
phase	O
(	O
notice	O
that	O
the	O
gray	O
arrows	O
in	O
figure	O
3.9b	O
point	O
both	O
ways	O
)	O
,	O
i.e.	O
,	O
hk	O
,	O
l	O
(	O
i	O
(	O
i	O
,	O
j	O
)	O
)	O
+=	O
w	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
,	O
(	O
3.11	O
)	O
where	O
w	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
is	O
the	O
bilinear	B
weighting	O
function	O
between	O
pixel	O
(	O
i	O
,	O
j	O
)	O
and	O
lookup	O
table	O
(	O
k	O
,	O
l	O
)	O
.	O
this	O
is	O
an	O
example	O
of	O
soft	O
histogramming	O
,	O
which	O
is	O
used	O
in	O
a	O
variety	O
of	O
other	O
applica-	O
3this	O
algorithm	B
is	O
implemented	O
in	O
the	O
matlab	O
adapthist	O
function	O
.	O
tsts	O
3.2	O
linear	B
ﬁltering	O
111	O
tions	O
,	O
including	O
the	O
construction	O
of	O
sift	O
feature	B
descriptors	O
(	O
section	O
4.1.3	O
)	O
and	O
vocabulary	O
trees	O
(	O
section	O
14.3.2	O
)	O
.	O
3.1.5	O
application	O
:	O
tonal	B
adjustment	I
one	O
of	O
the	O
most	O
widely	O
used	O
applications	O
of	O
point-wise	O
image	B
processing	O
operators	O
is	O
the	O
manipulation	O
of	O
contrast	O
or	O
tone	O
in	O
photographs	O
,	O
to	O
make	O
them	O
look	O
either	O
more	O
attractive	O
or	O
more	O
interpretable	O
.	O
you	O
can	O
get	O
a	O
good	O
sense	O
of	O
the	O
range	O
of	O
operations	O
possible	O
by	O
opening	O
up	O
any	O
photo	O
manipulation	O
tool	O
and	O
trying	O
out	O
a	O
variety	O
of	O
contrast	O
,	O
brightness	O
,	O
and	O
color	B
manipulation	O
options	O
,	O
as	O
shown	O
in	O
figures	O
3.2	O
and	O
3.7.	O
exercises	O
3.1	O
,	O
3.5	O
,	O
and	O
3.6	O
have	O
you	O
implement	O
some	O
of	O
these	O
operations	O
,	O
in	O
order	B
to	O
become	O
familiar	O
with	O
basic	O
image	B
processing	O
operators	O
.	O
more	O
sophisticated	O
techniques	O
for	O
tonal	O
adjustment	O
(	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
2005	O
;	O
bae	O
,	O
paris	O
,	O
and	O
durand	O
2006	O
)	O
are	O
described	O
in	O
the	O
section	O
on	O
high	B
dynamic	I
range	I
tone	O
mapping	O
(	O
section	O
10.2.1	O
)	O
.	O
3.2	O
linear	B
ﬁltering	O
locally	B
adaptive	I
histogram	O
equalization	O
is	O
an	O
example	O
of	O
a	O
neighborhood	B
operator	O
or	O
local	B
operator	O
,	O
which	O
uses	O
a	O
collection	O
of	O
pixel	O
values	O
in	O
the	O
vicinity	O
of	O
a	O
given	O
pixel	O
to	O
deter-	O
mine	O
its	O
ﬁnal	O
output	O
value	O
(	O
figure	O
3.10	O
)	O
.	O
in	O
addition	O
to	O
performing	O
local	B
tone	O
adjustment	O
,	O
neighborhood	B
operators	O
can	O
be	O
used	O
to	O
ﬁlter	O
images	O
in	O
order	B
to	O
add	O
soft	O
blur	O
,	O
sharpen	O
de-	O
tails	O
,	O
accentuate	O
edges	O
,	O
or	O
remove	O
noise	B
(	O
figure	O
3.11b–d	O
)	O
.	O
in	O
this	O
section	O
,	O
we	O
look	O
at	O
linear	B
ﬁltering	O
operators	O
,	O
which	O
involve	O
weighted	B
combinations	O
of	O
pixels	O
in	O
small	O
neighborhoods	O
.	O
in	O
section	O
3.3	O
,	O
we	O
look	O
at	O
non-linear	B
operators	O
such	O
as	O
morphological	O
ﬁlters	O
and	O
distance	O
transforms	O
.	O
the	O
most	O
commonly	O
used	O
type	O
of	O
neighborhood	B
operator	O
is	O
a	O
linear	B
ﬁlter	O
,	O
in	O
which	O
an	O
output	O
pixel	O
’	O
s	O
value	O
is	O
determined	O
as	O
a	O
weighted	B
sum	O
of	O
input	O
pixel	O
values	O
(	O
figure	O
3.10	O
)	O
,	O
g	O
(	O
i	O
,	O
j	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
f	O
(	O
i	O
+	O
k	O
,	O
j	O
+	O
l	O
)	O
h	O
(	O
k	O
,	O
l	O
)	O
.	O
(	O
3.12	O
)	O
the	O
entries	O
in	O
the	O
weight	O
kernel	B
or	O
mask	B
h	O
(	O
k	O
,	O
l	O
)	O
are	O
often	O
called	O
the	O
ﬁlter	O
coefﬁcients	O
.	O
the	O
above	O
correlation	O
operator	O
can	O
be	O
more	O
compactly	O
notated	O
as	O
g	O
=	O
f	O
⊗	O
h.	O
(	O
3.13	O
)	O
a	O
common	O
variant	O
on	O
this	O
formula	O
is	O
g	O
(	O
i	O
,	O
j	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
f	O
(	O
i	O
−	O
k	O
,	O
j	O
−	O
l	O
)	O
h	O
(	O
k	O
,	O
l	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
f	O
(	O
k	O
,	O
l	O
)	O
h	O
(	O
i	O
−	O
k	O
,	O
j	O
−	O
l	O
)	O
,	O
(	O
3.14	O
)	O
112	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
3.10	O
neighborhood	B
ﬁltering	O
(	O
convolution	O
)	O
:	O
the	O
image	B
on	O
the	O
left	O
is	O
convolved	O
with	O
the	O
ﬁlter	O
in	O
the	O
middle	O
to	O
yield	O
the	O
image	B
on	O
the	O
right	O
.	O
the	O
light	O
blue	O
pixels	O
indicate	O
the	O
source	O
neighborhood	B
for	O
the	O
light	O
green	O
destination	O
pixel	O
.	O
where	O
the	O
sign	O
of	O
the	O
offsets	O
in	O
f	O
has	O
been	O
reversed	O
.	O
this	O
is	O
called	O
the	O
convolution	O
operator	O
,	O
g	O
=	O
f	O
∗	O
h	O
,	O
(	O
3.15	O
)	O
and	O
h	O
is	O
then	O
called	O
the	O
impulse	O
response	O
function.4	O
the	O
reason	O
for	O
this	O
name	O
is	O
that	O
the	O
kernel	B
function	O
,	O
h	O
,	O
convolved	O
with	O
an	O
impulse	O
signal	O
,	O
δ	O
(	O
i	O
,	O
j	O
)	O
(	O
an	O
image	B
that	O
is	O
0	O
everywhere	O
except	O
at	O
the	O
origin	O
)	O
reproduces	O
itself	O
,	O
h	O
∗	O
δ	O
=	O
h	O
,	O
whereas	O
correlation	O
produces	O
the	O
reﬂected	O
signal	O
.	O
(	O
try	O
this	O
yourself	O
to	O
verify	O
that	O
it	O
is	O
so	O
.	O
)	O
in	O
fact	O
,	O
equation	B
(	O
3.14	O
)	O
can	O
be	O
interpreted	O
as	O
the	O
superposition	B
(	O
addition	O
)	O
of	O
shifted	O
im-	O
pulse	O
response	O
functions	O
h	O
(	O
i−	O
k	O
,	O
j	O
−	O
l	O
)	O
multiplied	O
by	O
the	O
input	O
pixel	O
values	O
f	O
(	O
k	O
,	O
l	O
)	O
.	O
convolu-	O
tion	B
has	O
additional	O
nice	O
properties	B
,	O
e.g.	O
,	O
it	O
is	O
both	O
commutative	O
and	O
associative	O
.	O
as	O
well	O
,	O
the	O
fourier	O
transform	B
of	O
two	O
convolved	O
images	O
is	O
the	O
product	O
of	O
their	O
individual	O
fourier	O
trans-	O
forms	O
(	O
section	O
3.4	O
)	O
.	O
both	O
correlation	O
and	O
convolution	O
are	O
linear	B
shift-invariant	O
(	O
lsi	O
)	O
operators	O
,	O
which	O
obey	O
both	O
the	O
superposition	B
principle	O
(	O
3.5	O
)	O
,	O
h	O
◦	O
(	O
f0	O
+	O
f1	O
)	O
=	O
h	O
◦	O
f0	O
+	O
h	O
◦	O
f1	O
,	O
(	O
3.16	O
)	O
and	O
the	O
shift	O
invariance	O
principle	O
,	O
g	O
(	O
i	O
,	O
j	O
)	O
=	O
f	O
(	O
i	O
+	O
k	O
,	O
j	O
+	O
l	O
)	O
⇔	O
(	O
h	O
◦	O
g	O
)	O
(	O
i	O
,	O
j	O
)	O
=	O
(	O
h	O
◦	O
f	O
)	O
(	O
i	O
+	O
k	O
,	O
j	O
+	O
l	O
)	O
,	O
(	O
3.17	O
)	O
which	O
means	O
that	O
shifting	O
a	O
signal	O
commutes	O
with	O
applying	O
the	O
operator	O
(	O
◦	O
stands	O
for	O
the	O
lsi	O
operator	O
)	O
.	O
another	O
way	O
to	O
think	O
of	O
shift	O
invariance	O
is	O
that	O
the	O
operator	O
“	O
behaves	O
the	O
same	O
everywhere	O
”	O
.	O
4	O
the	O
continuous	O
version	O
of	O
convolution	O
can	O
be	O
written	O
as	O
g	O
(	O
x	O
)	O
=	O
(	O
cid:82	O
)	O
f	O
(	O
x	O
−	O
u	O
)	O
h	O
(	O
u	O
)	O
du	O
.	O
45609812713213313713346659812312612813113369951161251291324765961151191231351370.10.10.16892110120126132476391107113122138134*0.10.20.1=6686104114124132505980971101231331340.10.10.1627894108120129495368839711312813357698398112124505058708410211612653607185100114505052586986101120f	O
(	O
x	O
,	O
y	O
)	O
h	O
(	O
x	O
,	O
y	O
)	O
g	O
(	O
x	O
,	O
y	O
)	O
3.2	O
linear	B
ﬁltering	O
113	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
e	O
)	O
(	O
g	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
(	O
f	O
)	O
(	O
h	O
)	O
figure	O
3.11	O
some	O
neighborhood	B
operations	O
:	O
(	O
a	O
)	O
original	O
image	B
;	O
(	O
b	O
)	O
blurred	O
;	O
(	O
c	O
)	O
sharpened	O
;	O
(	O
d	O
)	O
smoothed	O
with	O
edge-preserving	O
ﬁlter	O
;	O
(	O
e	O
)	O
binary	O
image	O
;	O
(	O
f	O
)	O
dilated	O
;	O
(	O
g	O
)	O
distance	O
transform	O
;	O
(	O
h	O
)	O
connected	B
components	I
.	O
for	O
the	O
dilation	B
and	O
connected	B
components	I
,	O
black	O
(	O
ink	O
)	O
pixels	O
are	O
assumed	O
to	O
be	O
active	O
,	O
i.e.	O
,	O
to	O
have	O
a	O
value	O
of	O
1	O
in	O
equations	B
(	O
3.41–3.45	O
)	O
.	O
114	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
72	O
88	O
62	O
52	O
37	O
∗	O
1/4	O
1/2	O
1/4	O
⇔	O
1	O
4	O
	O
2	O
1	O
.	O
.	O
.	O
1	O
2	O
1	O
.	O
.	O
.	O
1	O
2	O
1	O
.	O
.	O
.	O
1	O
2	O
1	O
.	O
.	O
.	O
1	O
2	O
	O
	O
72	O
88	O
62	O
52	O
37	O
	O
figure	O
3.12	O
one-dimensional	O
signal	O
convolution	O
as	O
a	O
sparse	B
matrix-vector	O
multiply	O
,	O
g	O
=	O
hf	O
.	O
occasionally	O
,	O
a	O
shift-variant	O
version	O
of	O
correlation	O
or	O
convolution	O
may	O
be	O
used	O
,	O
e.g.	O
,	O
g	O
(	O
i	O
,	O
j	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
f	O
(	O
i	O
−	O
k	O
,	O
j	O
−	O
l	O
)	O
h	O
(	O
k	O
,	O
l	O
;	O
i	O
,	O
j	O
)	O
,	O
(	O
3.18	O
)	O
where	O
h	O
(	O
k	O
,	O
l	O
;	O
i	O
,	O
j	O
)	O
is	O
the	O
convolution	O
kernel	B
at	O
pixel	O
(	O
i	O
,	O
j	O
)	O
.	O
for	O
example	O
,	O
such	O
a	O
spatially	O
varying	O
kernel	O
can	O
be	O
used	O
to	O
model	O
blur	O
in	O
an	O
image	B
due	O
to	O
variable	O
depth-dependent	O
defocus	O
.	O
correlation	O
and	O
convolution	O
can	O
both	O
be	O
written	O
as	O
a	O
matrix-vector	O
multiply	O
,	O
if	O
we	O
ﬁrst	O
convert	O
the	O
two-dimensional	B
images	O
f	O
(	O
i	O
,	O
j	O
)	O
and	O
g	O
(	O
i	O
,	O
j	O
)	O
into	O
raster-ordered	O
vectors	O
f	O
and	O
g	O
,	O
g	O
=	O
hf	O
,	O
(	O
3.19	O
)	O
where	O
the	O
(	O
sparse	B
)	O
h	O
matrix	O
contains	O
the	O
convolution	O
kernels	O
.	O
figure	O
3.12	O
shows	O
how	O
a	O
one-dimensional	O
convolution	O
can	O
be	O
represented	O
in	O
matrix-vector	O
form	O
.	O
padding	O
(	O
border	O
effects	O
)	O
the	O
astute	O
reader	O
will	O
notice	O
that	O
the	O
matrix	O
multiply	O
shown	O
in	O
figure	O
3.12	O
suffers	O
from	O
boundary	O
effects	O
,	O
i.e.	O
,	O
the	O
results	O
of	O
ﬁltering	O
the	O
image	B
in	O
this	O
form	O
will	O
lead	O
to	O
a	O
darkening	O
of	O
the	O
corner	O
pixels	O
.	O
this	O
is	O
because	O
the	O
original	O
image	B
is	O
effectively	O
being	O
padded	O
with	O
0	O
values	O
wherever	O
the	O
convolution	O
kernel	B
extends	O
beyond	O
the	O
original	O
image	B
boundaries	O
.	O
to	O
compensate	O
for	O
this	O
,	O
a	O
number	O
of	O
alternative	O
padding	O
or	O
extension	O
modes	O
have	O
been	O
developed	O
(	O
figure	O
3.13	O
)	O
:	O
•	O
zero	O
:	O
set	O
all	O
pixels	O
outside	O
the	O
source	O
image	B
to	O
0	O
(	O
a	O
good	O
choice	O
for	O
alpha-matted	O
cutout	O
images	O
)	O
;	O
•	O
constant	O
(	O
border	O
color	B
)	O
:	O
set	O
all	O
pixels	O
outside	O
the	O
source	O
image	B
to	O
a	O
speciﬁed	O
border	O
value	O
;	O
•	O
clamp	O
(	O
replicate	O
or	O
clamp	O
to	O
edge	O
)	O
:	O
repeat	O
edge	O
pixels	O
indeﬁnitely	O
;	O
•	O
(	O
cyclic	O
)	O
wrap	O
(	O
repeat	O
or	O
tile	O
)	O
:	O
loop	O
“	O
around	O
”	O
the	O
image	B
in	O
a	O
“	O
toroidal	O
”	O
conﬁguration	O
;	O
3.2	O
linear	B
ﬁltering	O
115	O
zero	O
wrap	O
clamp	O
mirror	O
blurred	O
zero	O
normalized	O
zero	O
blurred	O
clamp	O
blurred	O
mirror	O
figure	O
3.13	O
border	O
padding	O
(	O
top	O
row	O
)	O
and	O
the	O
results	O
of	O
blurring	O
the	O
padded	O
image	B
(	O
bottom	O
row	O
)	O
.	O
the	O
normalized	B
zero	O
image	B
is	O
the	O
result	O
of	O
dividing	O
(	O
normalizing	B
)	O
the	O
blurred	O
zero-	O
padded	O
rgba	O
image	B
by	O
its	O
corresponding	O
soft	O
alpha	O
value	O
.	O
•	O
mirror	O
:	O
reﬂect	O
pixels	O
across	O
the	O
image	B
edge	O
;	O
•	O
extend	O
:	O
extend	O
the	O
signal	O
by	O
subtracting	O
the	O
mirrored	O
version	O
of	O
the	O
signal	O
from	O
the	O
edge	O
pixel	O
value	O
.	O
in	O
the	O
computer	O
graphics	O
literature	O
(	O
akenine-m¨oller	O
and	O
haines	O
2002	O
,	O
p.	O
124	O
)	O
,	O
these	O
mech-	O
anisms	O
are	O
known	O
as	O
the	O
wrapping	O
mode	O
(	O
opengl	O
)	O
or	O
texture	B
addressing	O
mode	O
(	O
direct3d	O
)	O
.	O
the	O
formulas	O
for	O
each	O
of	O
these	O
modes	O
are	O
left	O
to	O
the	O
reader	O
(	O
exercise	O
3.8	O
)	O
.	O
figure	O
3.13	O
shows	O
the	O
effects	O
of	O
padding	O
an	O
image	B
with	O
each	O
of	O
the	O
above	O
mechanisms	O
and	O
then	O
blurring	O
the	O
resulting	O
padded	O
image	B
.	O
as	O
you	O
can	O
see	O
,	O
zero	O
padding	O
darkens	O
the	O
edges	O
,	O
clamp	O
(	O
replication	O
)	O
padding	O
propagates	O
border	O
values	O
inward	O
,	O
mirror	O
(	O
reﬂection	O
)	O
padding	O
pre-	O
serves	O
colors	O
near	O
the	O
borders	O
.	O
extension	O
padding	O
(	O
not	O
shown	O
)	O
keeps	O
the	O
border	O
pixels	O
ﬁxed	O
(	O
during	O
blur	O
)	O
.	O
an	O
alternative	O
to	O
padding	O
is	O
to	O
blur	O
the	O
zero-padded	O
rgba	O
image	B
and	O
to	O
then	O
divide	O
the	O
resulting	O
image	B
by	O
its	O
alpha	O
value	O
to	O
remove	O
the	O
darkening	O
effect	O
.	O
the	O
results	O
can	O
be	O
quite	O
good	O
,	O
as	O
seen	O
in	O
the	O
normalized	B
zero	O
image	B
in	O
figure	O
3.13	O
.	O
3.2.1	O
separable	B
ﬁltering	O
the	O
process	O
of	O
performing	O
a	O
convolution	O
requires	O
k	O
2	O
(	O
multiply-add	O
)	O
operations	O
per	O
pixel	O
,	O
where	O
k	O
is	O
the	O
size	O
(	O
width	O
or	O
height	O
)	O
of	O
the	O
convolution	O
kernel	B
,	O
e.g.	O
,	O
the	O
box	O
ﬁlter	O
in	O
fig-	O
116	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
1	O
k2	O
1	O
1	O
...	O
1	O
1	O
1	O
...	O
1	O
···	O
···	O
1	O
···	O
1	O
1	O
...	O
1	O
1	O
16	O
1	O
2	O
1	O
2	O
4	O
2	O
1	O
2	O
1	O
1	O
256	O
4	O
6	O
4	O
1	O
1	O
4	O
16	O
24	O
16	O
4	O
6	O
24	O
36	O
24	O
6	O
4	O
16	O
24	O
16	O
4	O
1	O
1	O
4	O
6	O
4	O
1	O
8	O
−1	O
0	O
1	O
−2	O
0	O
2	O
−1	O
0	O
1	O
1	O
4	O
1	O
−2	O
−2	O
1	O
−2	O
1	O
4	O
−2	O
1	O
1	O
k	O
1	O
1	O
···	O
1	O
1	O
4	O
1	O
2	O
1	O
1	O
16	O
1	O
4	O
6	O
4	O
1	O
1	O
2	O
−1	O
0	O
1	O
1	O
2	O
1	O
−2	O
1	O
(	O
a	O
)	O
box	O
,	O
k	O
=	O
5	O
(	O
b	O
)	O
bilinear	B
(	O
c	O
)	O
“	O
gaussian	O
”	O
(	O
d	O
)	O
sobel	O
(	O
e	O
)	O
corner	O
figure	O
3.14	O
separable	B
linear	O
ﬁlters	O
:	O
for	O
each	O
image	B
(	O
a	O
)	O
–	O
(	O
e	O
)	O
,	O
we	O
show	O
the	O
2d	O
ﬁlter	O
kernel	B
(	O
top	O
)	O
,	O
the	O
corresponding	O
horizontal	O
1d	O
kernel	B
(	O
middle	O
)	O
,	O
and	O
the	O
ﬁltered	O
image	B
(	O
bottom	O
)	O
.	O
the	O
ﬁltered	O
sobel	O
and	O
corner	O
images	O
are	O
signed	B
,	O
scaled	O
up	O
by	O
2×	O
and	O
4×	O
,	O
respectively	O
,	O
and	O
added	O
to	O
a	O
gray	O
offset	O
before	O
display	O
.	O
ure	O
3.14a	O
.	O
in	O
many	O
cases	O
,	O
this	O
operation	O
can	O
be	O
signiﬁcantly	O
sped	O
up	O
by	O
ﬁrst	O
performing	O
a	O
one-dimensional	O
horizontal	O
convolution	O
followed	O
by	O
a	O
one-dimensional	O
vertical	O
convolution	O
(	O
which	O
requires	O
a	O
total	B
of	O
2k	O
operations	O
per	O
pixel	O
)	O
.	O
a	O
convolution	O
kernel	B
for	O
which	O
this	O
is	O
possible	O
is	O
said	O
to	O
be	O
separable	B
.	O
it	O
is	O
easy	O
to	O
show	O
that	O
the	O
two-dimensional	B
kernel	O
k	O
corresponding	O
to	O
successive	O
con-	O
volution	O
with	O
a	O
horizontal	O
kernel	B
h	O
and	O
a	O
vertical	O
kernel	B
v	O
is	O
the	O
outer	O
product	O
of	O
the	O
two	O
kernels	O
,	O
k	O
=	O
vht	O
(	O
3.20	O
)	O
(	O
see	O
figure	O
3.14	O
for	O
some	O
examples	B
)	O
.	O
because	O
of	O
the	O
increased	O
efﬁciency	B
,	O
the	O
design	O
of	O
convolution	O
kernels	O
for	O
computer	O
vision	O
applications	O
is	O
often	O
inﬂuenced	O
by	O
their	O
separability	O
.	O
how	O
can	O
we	O
tell	O
if	O
a	O
given	O
kernel	B
k	O
is	O
indeed	O
separable	B
?	O
this	O
can	O
often	O
be	O
done	O
by	O
inspection	O
or	O
by	O
looking	O
at	O
the	O
analytic	O
form	O
of	O
the	O
kernel	B
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
.	O
a	O
more	O
direct	B
method	O
is	O
to	O
treat	O
the	O
2d	O
kernel	B
as	O
a	O
2d	O
matrix	O
k	O
and	O
to	O
take	O
its	O
singular	O
value	O
decomposition	O
(	O
svd	O
)	O
,	O
σiuivt	O
i	O
(	O
3.21	O
)	O
k	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
see	O
appendix	O
a.1.1	O
for	O
the	O
deﬁnition	O
of	O
the	O
svd	O
)	O
.	O
if	O
only	O
the	O
ﬁrst	O
singular	O
value	O
σ0	O
is	O
non-zero	O
,	O
the	O
kernel	B
is	O
separable	B
and	O
√σ0u0	O
and	O
√σ0vt	O
0	O
provide	O
the	O
vertical	O
and	O
horizontal	O
3.2	O
linear	B
ﬁltering	O
117	O
kernels	O
(	O
perona	O
1995	O
)	O
.	O
for	O
example	O
,	O
the	O
laplacian	O
of	O
gaussian	O
kernel	B
(	O
3.26	O
and	O
4.23	O
)	O
can	O
be	O
implemented	O
as	O
the	O
sum	O
of	O
two	O
separable	O
ﬁlters	O
(	O
4.24	O
)	O
(	O
wiejak	O
,	O
buxton	O
,	O
and	O
buxton	O
1985	O
)	O
.	O
what	O
if	O
your	O
kernel	B
is	O
not	O
separable	B
and	O
yet	O
you	O
still	O
want	O
a	O
faster	O
way	O
to	O
implement	O
it	O
?	O
perona	O
(	O
1995	O
)	O
,	O
who	O
ﬁrst	O
made	O
the	O
link	O
between	O
kernel	B
separability	O
and	O
svd	O
,	O
suggests	O
using	O
more	O
terms	O
in	O
the	O
(	O
3.21	O
)	O
series	O
,	O
i.e.	O
,	O
summing	O
up	O
a	O
number	O
of	O
separable	B
convolutions	O
.	O
whether	O
this	O
is	O
worth	O
doing	O
or	O
not	O
depends	O
on	O
the	O
relative	O
sizes	O
of	O
k	O
and	O
the	O
number	O
of	O
sig-	O
niﬁcant	O
singular	O
values	O
,	O
as	O
well	O
as	O
other	O
considerations	O
,	O
such	O
as	O
cache	O
coherency	O
and	O
memory	O
locality	O
.	O
3.2.2	O
examples	B
of	O
linear	B
ﬁltering	O
now	O
that	O
we	O
have	O
described	O
the	O
process	O
for	O
performing	O
linear	B
ﬁltering	O
,	O
let	O
us	O
examine	O
a	O
number	O
of	O
frequently	O
used	O
ﬁlters	O
.	O
the	O
simplest	O
ﬁlter	O
to	O
implement	O
is	O
the	O
moving	B
average	I
or	O
box	O
ﬁlter	O
,	O
which	O
simply	O
averages	O
the	O
pixel	O
values	O
in	O
a	O
k	O
×	O
k	O
window	O
.	O
this	O
is	O
equivalent	O
to	O
convolving	O
the	O
image	B
with	O
a	O
kernel	B
of	O
all	O
ones	O
and	O
then	O
scaling	O
(	O
figure	O
3.14a	O
)	O
.	O
for	O
large	O
kernels	O
,	O
a	O
more	O
efﬁcient	O
implementation	O
is	O
to	O
slide	O
a	O
moving	O
window	O
across	O
each	O
scanline	O
(	O
in	O
a	O
separable	B
ﬁlter	O
)	O
while	O
adding	O
the	O
newest	O
pixel	O
and	O
subtracting	O
the	O
oldest	O
pixel	O
from	O
the	O
running	O
sum	O
.	O
this	O
is	O
related	O
to	O
the	O
concept	O
of	O
summed	O
area	O
tables	O
,	O
which	O
we	O
describe	O
shortly	O
.	O
a	O
smoother	O
image	B
can	O
be	O
obtained	O
by	O
separably	O
convolving	O
the	O
image	B
with	O
a	O
piecewise	O
linear	B
“	O
tent	O
”	O
function	O
(	O
also	O
known	O
as	O
a	O
bartlett	O
ﬁlter	O
)	O
.	O
figure	O
3.14b	O
shows	O
a	O
3	O
×	O
3	O
version	O
of	O
this	O
ﬁlter	O
,	O
which	O
is	O
called	O
the	O
bilinear	B
kernel	O
,	O
since	O
it	O
is	O
the	O
outer	O
product	O
of	O
two	O
linear	O
(	O
ﬁrst-order	O
)	O
splines	B
(	O
see	O
section	O
3.5.2	O
)	O
.	O
convolving	O
the	O
linear	B
tent	O
function	O
with	O
itself	O
yields	O
the	O
cubic	B
approximating	O
spline	B
,	O
which	O
is	O
called	O
the	O
“	O
gaussian	O
”	O
kernel	B
(	O
figure	O
3.14c	O
)	O
in	O
burt	O
and	O
adelson	O
’	O
s	O
(	O
1983a	O
)	O
lapla-	O
cian	O
pyramid	B
representation	O
(	O
section	O
3.5	O
)	O
.	O
note	O
that	O
approximate	O
gaussian	O
kernels	O
can	O
also	O
be	O
obtained	O
by	O
iterated	O
convolution	O
with	O
box	O
ﬁlters	O
(	O
wells	O
1986	O
)	O
.	O
in	O
applications	O
where	O
the	O
ﬁlters	O
really	O
need	O
to	O
be	O
rotationally	O
symmetric	O
,	O
carefully	O
tuned	O
versions	O
of	O
sampled	O
gaussians	O
should	O
be	O
used	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
(	O
exercise	O
3.10	O
)	O
.	O
the	O
kernels	O
we	O
just	O
discussed	O
are	O
all	O
examples	B
of	O
blurring	O
(	O
smoothing	B
)	O
or	O
low-pass	B
ker-	O
nels	O
(	O
since	O
they	O
pass	O
through	O
the	O
lower	O
frequencies	O
while	O
attenuating	O
higher	O
frequencies	O
)	O
.	O
how	O
good	O
are	O
they	O
at	O
doing	O
this	O
?	O
in	O
section	O
3.4	O
,	O
we	O
use	O
frequency-space	O
fourier	O
analysis	O
to	O
examine	O
the	O
exact	O
frequency	O
response	O
of	O
these	O
ﬁlters	O
.	O
we	O
also	O
introduce	O
the	O
sinc	B
(	O
(	O
sin	O
x	O
)	O
/x	O
)	O
ﬁlter	O
,	O
which	O
performs	O
ideal	O
low-pass	B
ﬁltering	O
.	O
in	O
practice	O
,	O
smoothing	B
kernels	O
are	O
often	O
used	O
to	O
reduce	O
high-frequency	O
noise	B
.	O
we	O
have	O
much	O
more	O
to	O
say	O
about	O
using	O
variants	O
on	O
smoothing	B
to	O
remove	O
noise	B
later	O
(	O
see	O
sections	O
3.3.1	O
,	O
3.4	O
,	O
and	O
3.7	O
)	O
.	O
surprisingly	O
,	O
smoothing	B
kernels	O
can	O
also	O
be	O
used	O
to	O
sharpen	O
images	O
using	O
a	O
process	O
called	O
118	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
unsharp	O
masking	O
.	O
since	O
blurring	O
the	O
image	B
reduces	O
high	O
frequencies	O
,	O
adding	O
some	O
of	O
the	O
difference	B
between	O
the	O
original	O
and	O
the	O
blurred	O
image	B
makes	O
it	O
sharper	O
,	O
gsharp	O
=	O
f	O
+	O
γ	O
(	O
f	O
−	O
hblur	O
∗	O
f	O
)	O
.	O
(	O
3.22	O
)	O
in	O
fact	O
,	O
before	O
the	O
advent	O
of	O
digital	O
photography	O
,	O
this	O
was	O
the	O
standard	O
way	O
to	O
sharpen	O
images	O
in	O
the	O
darkroom	O
:	O
create	O
a	O
blurred	O
(	O
“	O
positive	O
”	O
)	O
negative	O
from	O
the	O
original	O
negative	O
by	O
mis-	O
focusing	O
,	O
then	O
overlay	O
the	O
two	O
negatives	O
before	O
printing	O
the	O
ﬁnal	O
image	B
,	O
which	O
corresponds	O
to	O
this	O
is	O
no	O
longer	O
a	O
linear	B
ﬁlter	O
but	O
it	O
still	O
works	O
well	O
.	O
gunsharp	O
=	O
f	O
(	O
1	O
−	O
γhblur	O
∗	O
f	O
)	O
.	O
(	O
3.23	O
)	O
linear	B
ﬁltering	O
can	O
also	O
be	O
used	O
as	O
a	O
pre-processing	O
stage	O
to	O
edge	O
extraction	O
(	O
section	O
4.2	O
)	O
and	O
interest	O
point	O
detection	O
(	O
section	O
4.1	O
)	O
algorithms	O
.	O
figure	O
3.14d	O
shows	O
a	O
simple	O
3×	O
3	O
edge	O
extractor	O
called	O
the	O
sobel	O
operator	O
,	O
which	O
is	O
a	O
separable	B
combination	O
of	O
a	O
horizontal	O
central	O
difference	B
(	O
so	O
called	O
because	O
the	O
horizontal	O
derivative	O
is	O
centered	O
on	O
the	O
pixel	O
)	O
and	O
a	O
vertical	O
tent	O
ﬁlter	O
(	O
to	O
smooth	O
the	O
results	O
)	O
.	O
as	O
you	O
can	O
see	O
in	O
the	O
image	B
below	O
the	O
kernel	B
,	O
this	O
ﬁlter	O
effectively	O
emphasizes	O
horizontal	O
edges	O
.	O
the	O
simple	O
corner	O
detector	O
(	O
figure	O
3.14e	O
)	O
looks	O
for	O
simultaneous	O
horizontal	O
and	O
vertical	O
second	O
derivatives	O
.	O
as	O
you	O
can	O
see	O
however	O
,	O
it	O
responds	O
not	O
only	O
to	O
the	O
corners	O
of	O
the	O
square	O
,	O
but	O
also	O
along	O
diagonal	O
edges	O
.	O
better	O
corner	O
detectors	O
,	O
or	O
at	O
least	O
interest	O
point	O
detectors	O
that	O
are	O
more	O
rotationally	O
invariant	O
,	O
are	O
described	O
in	O
section	O
4.1	O
.	O
3.2.3	O
band-pass	B
and	O
steerable	B
ﬁlters	O
the	O
sobel	O
and	O
corner	O
operators	O
are	O
simple	O
examples	B
of	O
band-pass	B
and	O
oriented	B
ﬁlters	O
.	O
more	O
sophisticated	O
kernels	O
can	O
be	O
created	O
by	O
ﬁrst	O
smoothing	B
the	O
image	B
with	O
a	O
(	O
unit	O
area	O
)	O
gaussian	O
ﬁlter	O
,	O
and	O
then	O
taking	O
the	O
ﬁrst	O
or	O
second	O
derivatives	O
(	O
marr	O
1982	O
;	O
witkin	O
1983	O
;	O
freeman	O
and	O
adelson	O
1991	O
)	O
.	O
such	O
ﬁlters	O
are	O
known	O
collectively	O
as	O
band-pass	B
ﬁlters	O
,	O
since	O
they	O
ﬁlter	O
out	O
both	O
low	O
and	O
high	O
frequencies	O
.	O
the	O
(	O
undirected	O
)	O
second	O
derivative	O
of	O
a	O
two-dimensional	B
image	O
,	O
∇2f	O
=	O
∂2f	O
∂x2	O
+	O
∂2y	O
∂y2	O
,	O
(	O
3.25	O
)	O
is	O
known	O
as	O
the	O
laplacian	O
operator	O
.	O
blurring	O
an	O
image	B
with	O
a	O
gaussian	O
and	O
then	O
taking	O
its	O
laplacian	O
is	O
equivalent	O
to	O
convolving	O
directly	O
with	O
the	O
laplacian	O
of	O
gaussian	O
(	O
log	O
)	O
ﬁlter	O
,	O
∇2g	O
(	O
x	O
,	O
y	O
;	O
σ	O
)	O
=	O
(	O
cid:18	O
)	O
x2	O
+	O
y2	O
σ4	O
−	O
2	O
σ2	O
(	O
cid:19	O
)	O
g	O
(	O
x	O
,	O
y	O
;	O
σ	O
)	O
,	O
(	O
3.26	O
)	O
g	O
(	O
x	O
,	O
y	O
;	O
σ	O
)	O
=	O
1	O
2πσ2	O
e−	O
x2+y2	O
2σ2	O
,	O
(	O
3.24	O
)	O
3.2	O
linear	B
ﬁltering	O
119	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
3.15	O
second-order	O
steerable	B
ﬁlter	I
(	O
freeman	O
1992	O
)	O
c	O
(	O
cid:13	O
)	O
1992	O
ieee	O
:	O
(	O
a	O
)	O
original	O
image	B
of	O
einstein	O
;	O
(	O
b	O
)	O
orientation	O
map	O
computed	O
from	O
the	O
second-order	O
oriented	B
energy	O
;	O
(	O
c	O
)	O
original	O
image	B
with	O
oriented	B
structures	O
enhanced	O
.	O
which	O
has	O
certain	O
nice	O
scale-space	O
properties	B
(	O
witkin	O
1983	O
;	O
witkin	O
,	O
terzopoulos	O
,	O
and	O
kass	O
1986	O
)	O
.	O
the	O
ﬁve-point	O
laplacian	O
is	O
just	O
a	O
compact	O
approximation	O
to	O
this	O
more	O
sophisticated	O
ﬁlter	O
.	O
likewise	O
,	O
the	O
sobel	O
operator	O
is	O
a	O
simple	O
approximation	O
to	O
a	O
directional	O
or	O
oriented	B
ﬁlter	O
,	O
which	O
can	O
obtained	O
by	O
smoothing	O
with	O
a	O
gaussian	O
(	O
or	O
some	O
other	O
ﬁlter	O
)	O
and	O
then	O
taking	O
a	O
directional	B
derivative	I
∇ˆu	O
=	O
∂	O
∂	O
ˆu	O
,	O
which	O
is	O
obtained	O
by	O
taking	O
the	O
dot	O
product	O
between	O
the	O
gradient	O
ﬁeld	O
∇	O
and	O
a	O
unit	O
direction	O
ˆu	O
=	O
(	O
cos	O
θ	O
,	O
sin	O
θ	O
)	O
,	O
ˆu	O
·	O
∇	O
(	O
g	O
∗	O
f	O
)	O
=	O
∇ˆu	O
(	O
g	O
∗	O
f	O
)	O
=	O
(	O
∇ˆug	O
)	O
∗	O
f.	O
the	O
smoothed	O
directional	B
derivative	I
ﬁlter	O
,	O
gˆu	O
=	O
ugx	O
+	O
vgy	O
=	O
u	O
∂g	O
∂x	O
+	O
v	O
∂g	O
∂y	O
,	O
(	O
3.27	O
)	O
(	O
3.28	O
)	O
where	O
ˆu	O
=	O
(	O
u	O
,	O
v	O
)	O
,	O
is	O
an	O
example	O
of	O
a	O
steerable	B
ﬁlter	I
,	O
since	O
the	O
value	O
of	O
an	O
image	B
convolved	O
with	O
gˆu	O
can	O
be	O
computed	O
by	O
ﬁrst	O
convolving	O
with	O
the	O
pair	O
of	O
ﬁlters	O
(	O
gx	O
,	O
gy	O
)	O
and	O
then	O
steering	O
the	O
ﬁlter	O
(	O
potentially	O
locally	O
)	O
by	O
multiplying	O
this	O
gradient	O
ﬁeld	O
with	O
a	O
unit	O
vector	O
ˆu	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
.	O
the	O
advantage	O
of	O
this	O
approach	O
is	O
that	O
a	O
whole	O
family	O
of	O
ﬁlters	O
can	O
be	O
evaluated	O
with	O
very	O
little	O
cost	O
.	O
how	O
about	O
steering	O
a	O
directional	O
second	O
derivative	O
ﬁlter	O
∇ˆu	O
·	O
∇ˆugˆu	O
,	O
which	O
is	O
the	O
result	O
of	O
taking	O
a	O
(	O
smoothed	O
)	O
directional	B
derivative	I
and	O
then	O
taking	O
the	O
directional	B
derivative	I
again	O
?	O
for	O
example	O
,	O
gxx	O
is	O
the	O
second	O
directional	O
derivative	O
in	O
the	O
x	O
direction	O
.	O
at	O
ﬁrst	O
glance	O
,	O
it	O
would	O
appear	O
that	O
the	O
steering	O
trick	O
will	O
not	O
work	O
,	O
since	O
for	O
every	O
di-	O
rection	O
ˆu	O
,	O
we	O
need	O
to	O
compute	O
a	O
different	O
ﬁrst	O
directional	B
derivative	I
.	O
somewhat	O
surprisingly	O
,	O
freeman	O
and	O
adelson	O
(	O
1991	O
)	O
showed	O
that	O
,	O
for	O
directional	O
gaussian	O
derivatives	O
,	O
it	O
is	O
possible	O
120	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
3.16	O
fourth-order	O
steerable	B
ﬁlter	I
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
c	O
(	O
cid:13	O
)	O
1991	O
ieee	O
:	O
(	O
a	O
)	O
test	O
image	O
containing	O
bars	O
(	O
lines	B
)	O
and	O
step	O
edges	O
at	O
different	O
orientations	O
;	O
(	O
b	O
)	O
average	O
oriented	B
energy	O
;	O
(	O
c	O
)	O
dominant	O
orientation	O
;	O
(	O
d	O
)	O
oriented	B
energy	O
as	O
a	O
function	O
of	O
angle	O
(	O
polar	O
plot	O
)	O
.	O
to	O
steer	O
any	O
order	B
of	O
derivative	O
with	O
a	O
relatively	O
small	O
number	O
of	O
basis	O
functions	O
.	O
for	O
example	O
,	O
only	O
three	O
basis	O
functions	O
are	O
required	O
for	O
the	O
second-order	O
directional	B
derivative	I
,	O
gˆuˆu	O
=	O
u2gxx	O
+	O
2uvgxy	O
+	O
v2gyy	O
.	O
(	O
3.29	O
)	O
furthermore	O
,	O
each	O
of	O
the	O
basis	O
ﬁlters	O
,	O
while	O
not	O
itself	O
necessarily	O
separable	B
,	O
can	O
be	O
computed	O
using	O
a	O
linear	B
combination	O
of	O
a	O
small	O
number	O
of	O
separable	B
ﬁlters	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
.	O
this	O
remarkable	O
result	O
makes	O
it	O
possible	O
to	O
construct	O
directional	B
derivative	I
ﬁlters	O
of	O
in-	O
creasingly	O
greater	O
directional	O
selectivity	O
,	O
i.e.	O
,	O
ﬁlters	O
that	O
only	O
respond	O
to	O
edges	O
that	O
have	O
strong	O
local	B
consistency	O
in	O
orientation	O
(	O
figure	O
3.15	O
)	O
.	O
furthermore	O
,	O
higher	O
order	O
steerable	B
ﬁlters	O
can	O
respond	O
to	O
potentially	O
more	O
than	O
a	O
single	O
edge	O
orientation	O
at	O
a	O
given	O
location	O
,	O
and	O
they	O
can	O
respond	O
to	O
both	O
bar	O
edges	O
(	O
thin	B
lines	O
)	O
and	O
the	O
classic	O
step	O
edges	O
(	O
figure	O
3.16	O
)	O
.	O
in	O
order	B
to	O
do	O
this	O
,	O
however	O
,	O
full	O
hilbert	O
transform	B
pairs	O
need	O
to	O
be	O
used	O
for	O
second-order	O
and	O
higher	O
ﬁlters	O
,	O
as	O
described	O
in	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
.	O
steerable	B
ﬁlters	O
are	O
often	O
used	O
to	O
construct	O
both	O
feature	B
descriptors	O
(	O
section	O
4.1.3	O
)	O
and	O
edge	O
detectors	O
(	O
section	O
4.2	O
)	O
.	O
while	O
the	O
ﬁlters	O
developed	O
by	O
freeman	O
and	O
adelson	O
(	O
1991	O
)	O
are	O
best	O
suited	O
for	O
detecting	O
linear	B
(	O
edge-like	O
)	O
structures	O
,	O
more	O
recent	O
work	O
by	O
koethe	O
(	O
2003	O
)	O
shows	O
how	O
a	O
combined	O
2	O
×	O
2	O
boundary	O
tensor	O
can	O
be	O
used	O
to	O
encode	O
both	O
edge	O
and	O
junction	O
(	O
“	O
corner	O
”	O
)	O
features	O
.	O
exercise	O
3.12	O
has	O
you	O
implement	O
such	O
steerable	B
ﬁlters	O
and	O
apply	O
them	O
to	O
ﬁnding	O
both	O
edge	O
and	O
corner	O
features	O
.	O
summed	O
area	O
table	O
(	O
integral	O
image	B
)	O
if	O
an	O
image	B
is	O
going	O
to	O
be	O
repeatedly	O
convolved	O
with	O
different	O
box	O
ﬁlters	O
(	O
and	O
especially	O
ﬁlters	O
of	O
different	O
sizes	O
at	O
different	O
locations	O
)	O
,	O
you	O
can	O
precompute	O
the	O
summed	O
area	O
table	O
(	O
crow	O
3.2	O
linear	B
ﬁltering	O
121	O
figure	O
3.17	O
summed	O
area	O
tables	O
:	O
(	O
a	O
)	O
original	O
image	B
;	O
(	O
b	O
)	O
summed	O
area	O
table	O
;	O
(	O
c	O
)	O
computation	O
of	O
area	O
sum	O
.	O
each	O
value	O
in	O
the	O
summed	O
area	O
table	O
s	O
(	O
i	O
,	O
j	O
)	O
(	O
red	O
)	O
is	O
computed	O
recursively	O
from	O
its	O
three	O
adjacent	O
(	O
blue	O
)	O
neighbors	O
(	O
3.31	O
)	O
.	O
area	O
sums	O
s	O
(	O
green	O
)	O
are	O
computed	O
by	O
combining	O
the	O
four	O
values	O
at	O
the	O
rectangle	O
corners	O
(	O
purple	O
)	O
(	O
3.32	O
)	O
.	O
positive	O
values	O
are	O
shown	O
in	O
bold	O
and	O
negative	O
values	O
in	O
italics	O
.	O
1984	O
)	O
,	O
which	O
is	O
just	O
the	O
running	O
sum	O
of	O
all	O
the	O
pixel	O
values	O
from	O
the	O
origin	O
,	O
s	O
(	O
i	O
,	O
j	O
)	O
=	O
i	O
(	O
cid:88	O
)	O
k=0	O
j	O
(	O
cid:88	O
)	O
l=0	O
f	O
(	O
k	O
,	O
l	O
)	O
.	O
(	O
3.30	O
)	O
this	O
can	O
be	O
efﬁciently	O
computed	O
using	O
a	O
recursive	O
(	O
raster-scan	O
)	O
algorithm	B
,	O
s	O
(	O
i	O
,	O
j	O
)	O
=	O
s	O
(	O
i	O
−	O
1	O
,	O
j	O
)	O
+	O
s	O
(	O
i	O
,	O
j	O
−	O
1	O
)	O
−	O
s	O
(	O
i	O
−	O
1	O
,	O
j	O
−	O
1	O
)	O
+	O
f	O
(	O
i	O
,	O
j	O
)	O
.	O
(	O
3.31	O
)	O
the	O
image	B
s	O
(	O
i	O
,	O
j	O
)	O
is	O
also	O
often	O
called	O
an	O
integral	O
image	B
(	O
see	O
figure	O
3.17	O
)	O
and	O
can	O
actually	O
be	O
computed	O
using	O
only	O
two	O
additions	O
per	O
pixel	O
if	O
separate	O
row	O
sums	O
are	O
used	O
(	O
viola	O
and	O
jones	O
2004	O
)	O
.	O
to	O
ﬁnd	O
the	O
summed	O
area	O
(	O
integral	O
)	O
inside	O
a	O
rectangle	O
[	O
i0	O
,	O
i1	O
]	O
×	O
[	O
j0	O
,	O
j1	O
]	O
,	O
we	O
simply	O
combine	O
four	O
samples	O
from	O
the	O
summed	O
area	O
table	O
,	O
i1	O
(	O
cid:88	O
)	O
i=i0	O
j1	O
(	O
cid:88	O
)	O
j=j0	O
s	O
(	O
i0	O
.	O
.	O
.	O
i1	O
,	O
j0	O
.	O
.	O
.	O
j1	O
)	O
=	O
s	O
(	O
i1	O
,	O
j1	O
)	O
−	O
s	O
(	O
i1	O
,	O
j0	O
−	O
1	O
)	O
−	O
s	O
(	O
i0	O
−	O
1	O
,	O
j1	O
)	O
+	O
s	O
(	O
i0	O
−	O
1	O
,	O
j0	O
−	O
1	O
)	O
.	O
(	O
3.32	O
)	O
a	O
potential	O
disadvantage	O
of	O
summed	O
area	O
tables	O
is	O
that	O
they	O
require	O
log	O
m	O
+	O
log	O
n	O
extra	O
bits	O
in	O
the	O
accumulation	O
image	B
compared	O
to	O
the	O
original	O
image	B
,	O
where	O
m	O
and	O
n	O
are	O
the	O
image	B
width	O
and	O
height	O
.	O
extensions	O
of	O
summed	O
area	O
tables	O
can	O
also	O
be	O
used	O
to	O
approximate	O
other	O
convolution	O
kernels	O
(	O
wolberg	O
(	O
1990	O
,	O
section	O
6.5.2	O
)	O
contains	O
a	O
review	O
)	O
.	O
in	O
computer	O
vision	O
,	O
summed	O
area	O
tables	O
have	O
been	O
used	O
in	O
face	B
detection	O
(	O
viola	O
and	O
jones	O
2004	O
)	O
to	O
compute	O
simple	O
multi-scale	O
low-level	O
features	O
.	O
such	O
features	O
,	O
which	O
consist	O
of	O
adjacent	O
rectangles	O
of	O
positive	O
and	O
negative	O
values	O
,	O
are	O
also	O
known	O
as	O
boxlets	O
(	O
simard	O
,	O
bottou	O
,	O
327233512141735121417151344111924314111924315135191728384691728384643216132437486213243748622414815304459811530445981	O
(	O
a	O
)	O
s	O
=24	O
(	O
b	O
)	O
s	O
=28	O
(	O
c	O
)	O
s	O
=24	O
122	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
haffner	O
et	O
al	O
.	O
1998	O
)	O
.	O
in	O
principle	O
,	O
summed	O
area	O
tables	O
could	O
also	O
be	O
used	O
to	O
compute	O
the	O
sums	O
in	O
the	O
sum	O
of	O
squared	O
differences	O
(	O
ssd	O
)	O
stereo	B
and	O
motion	B
algorithms	O
(	O
section	O
11.4	O
)	O
.	O
in	O
practice	O
,	O
separable	B
moving	O
average	O
ﬁlters	O
are	O
usually	O
preferred	O
(	O
kanade	O
,	O
yoshida	O
,	O
oda	O
et	O
al	O
.	O
1996	O
)	O
,	O
unless	O
many	O
different	O
window	O
shapes	O
and	O
sizes	O
are	O
being	O
considered	O
(	O
veksler	O
2003	O
)	O
.	O
recursive	O
ﬁltering	O
the	O
incremental	B
formula	O
(	O
3.31	O
)	O
for	O
the	O
summed	O
area	O
is	O
an	O
example	O
of	O
a	O
recursive	O
ﬁlter	O
,	O
i.e.	O
,	O
one	O
whose	O
values	O
depends	O
on	O
previous	O
ﬁlter	O
outputs	O
.	O
in	O
the	O
signal	O
processing	O
literature	O
,	O
such	O
ﬁlters	O
are	O
known	O
as	O
inﬁnite	O
impulse	O
response	O
(	O
iir	O
)	O
,	O
since	O
the	O
output	O
of	O
the	O
ﬁlter	O
to	O
an	O
impulse	O
(	O
single	O
non-zero	O
value	O
)	O
goes	O
on	O
forever	O
.	O
for	O
example	O
,	O
for	O
a	O
summed	O
area	O
table	O
,	O
an	O
impulse	O
generates	O
an	O
inﬁnite	O
rectangle	O
of	O
1s	O
below	O
and	O
to	O
the	O
right	O
of	O
the	O
impulse	O
.	O
the	O
ﬁlters	O
we	O
have	O
previously	O
studied	O
in	O
this	O
chapter	O
,	O
which	O
involve	O
the	O
image	B
with	O
a	O
ﬁnite	O
extent	O
kernel	B
,	O
are	O
known	O
as	O
ﬁnite	O
impulse	O
response	O
(	O
fir	O
)	O
.	O
two-dimensional	B
iir	O
ﬁlters	O
and	O
recursive	O
formulas	O
are	O
sometimes	O
used	O
to	O
compute	O
quan-	O
tities	O
that	O
involve	O
large	O
area	O
interactions	O
,	O
such	O
as	O
two-dimensional	B
distance	O
functions	O
(	O
sec-	O
tion	B
3.3.3	O
)	O
and	O
connected	B
components	I
(	O
section	O
3.3.4	O
)	O
.	O
more	O
commonly	O
,	O
however	O
,	O
iir	O
ﬁlters	O
are	O
used	O
inside	O
one-dimensional	O
separable	B
ﬁltering	O
stages	O
to	O
compute	O
large-extent	O
smoothing	B
kernels	O
,	O
such	O
as	O
efﬁcient	O
approximations	O
to	O
gaus-	O
sians	O
and	O
edge	O
ﬁlters	O
(	O
deriche	O
1990	O
;	O
nielsen	O
,	O
florack	O
,	O
and	O
deriche	O
1997	O
)	O
.	O
pyramid-based	O
algorithms	O
(	O
section	O
3.5	O
)	O
can	O
also	O
be	O
used	O
to	O
perform	O
such	O
large-area	O
smoothing	B
computations	O
.	O
3.3	O
more	O
neighborhood	B
operators	O
as	O
we	O
have	O
just	O
seen	O
,	O
linear	B
ﬁlters	O
can	O
perform	O
a	O
wide	O
variety	O
of	O
image	B
transformations	O
.	O
however	O
non-linear	B
ﬁlters	O
,	O
such	O
as	O
edge-preserving	B
median	O
or	O
bilateral	B
ﬁlters	O
,	O
can	O
sometimes	O
perform	O
even	O
better	O
.	O
other	O
examples	B
of	O
neighborhood	B
operators	O
include	O
morphological	O
oper-	O
ators	O
that	O
operate	O
on	O
binary	O
images	O
,	O
as	O
well	O
as	O
semi-global	O
operators	O
that	O
compute	O
distance	O
transforms	O
and	O
ﬁnd	O
connected	B
components	I
in	O
binary	O
images	O
(	O
figure	O
3.11f–h	O
)	O
.	O
3.3.1	O
non-linear	B
ﬁltering	O
the	O
ﬁlters	O
we	O
have	O
looked	O
at	O
so	O
far	O
have	O
all	O
been	O
linear	B
,	O
i.e.	O
,	O
their	O
response	O
to	O
a	O
sum	O
of	O
two	O
signals	O
is	O
the	O
same	O
as	O
the	O
sum	O
of	O
the	O
individual	O
responses	O
.	O
this	O
is	O
equivalent	O
to	O
saying	O
that	O
each	O
output	O
pixel	O
is	O
a	O
weighted	B
summation	O
of	O
some	O
number	O
of	O
input	O
pixels	O
(	O
3.19	O
)	O
.	O
linear	B
ﬁlters	O
are	O
easier	O
to	O
compose	O
and	O
are	O
amenable	O
to	O
frequency	O
response	O
analysis	O
(	O
section	O
3.4	O
)	O
.	O
in	O
many	O
cases	O
,	O
however	O
,	O
better	O
performance	O
can	O
be	O
obtained	O
by	O
using	O
a	O
non-linear	B
com-	O
bination	O
of	O
neighboring	O
pixels	O
.	O
consider	O
for	O
example	O
the	O
image	B
in	O
figure	O
3.18e	O
,	O
where	O
the	O
3.3	O
more	O
neighborhood	B
operators	O
123	O
(	O
a	O
)	O
(	O
e	O
)	O
(	O
b	O
)	O
(	O
f	O
)	O
(	O
c	O
)	O
(	O
g	O
)	O
(	O
d	O
)	O
(	O
h	O
)	O
figure	O
3.18	O
median	B
and	O
bilateral	B
ﬁltering	O
:	O
(	O
a	O
)	O
original	O
image	B
with	O
gaussian	O
noise	B
;	O
(	O
b	O
)	O
gaus-	O
sian	O
ﬁltered	O
;	O
(	O
c	O
)	O
median	B
ﬁltered	O
;	O
(	O
d	O
)	O
bilaterally	O
ﬁltered	O
;	O
(	O
e	O
)	O
original	O
image	B
with	O
shot	B
noise	I
;	O
(	O
f	O
)	O
gaussian	O
ﬁltered	O
;	O
(	O
g	O
)	O
median	B
ﬁltered	O
;	O
(	O
h	O
)	O
bilaterally	O
ﬁltered	O
.	O
note	O
that	O
the	O
bilateral	B
ﬁlter	I
fails	O
to	O
remove	O
the	O
shot	B
noise	I
because	O
the	O
noisy	O
pixels	O
are	O
too	O
different	O
from	O
their	O
neighbors	O
.	O
figure	O
3.19	O
median	B
and	O
bilateral	B
ﬁltering	O
:	O
(	O
a	O
)	O
median	B
pixel	O
(	O
green	O
)	O
;	O
(	O
b	O
)	O
selected	O
α-trimmed	O
mean	O
pixels	O
;	O
(	O
c	O
)	O
domain	O
ﬁlter	O
(	O
numbers	O
along	O
edge	O
are	O
pixel	O
distances	O
)	O
;	O
(	O
d	O
)	O
range	O
ﬁlter	O
.	O
.21012121241212420.10.30.40.30.10.00.00.00.00.2213582135810.30.60.80.60.30.00.00.00.40.8137691376900.40.81.00.80.40.00.01.00.80.4348673486710.30.60.80.60.30.00.20.80.81.0457894578920.10.30.40.30.10.20.41.00.80.4	O
(	O
a	O
)	O
median	B
=4	O
(	O
b	O
)	O
α-mean=4.6	O
(	O
c	O
)	O
domain	O
filter	O
(	O
d	O
)	O
range	O
filter	O
124	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
noise	B
,	O
rather	O
than	O
being	O
gaussian	O
,	O
is	O
shot	B
noise	I
,	O
i.e.	O
,	O
it	O
occasionally	O
has	O
very	O
large	O
values	O
.	O
in	O
this	O
case	O
,	O
regular	O
blurring	O
with	O
a	O
gaussian	O
ﬁlter	O
fails	O
to	O
remove	O
the	O
noisy	O
pixels	O
and	O
instead	O
turns	O
them	O
into	O
softer	O
(	O
but	O
still	O
visible	O
)	O
spots	O
(	O
figure	O
3.18f	O
)	O
.	O
median	B
ﬁltering	O
a	O
better	O
ﬁlter	O
to	O
use	O
in	O
this	O
case	O
is	O
the	O
median	B
ﬁlter	O
,	O
which	O
selects	O
the	O
median	B
value	O
from	O
each	O
pixel	O
’	O
s	O
neighborhood	B
(	O
figure	O
3.19a	O
)	O
.	O
median	B
values	O
can	O
be	O
computed	O
in	O
expected	O
linear	B
time	O
using	O
a	O
randomized	O
select	O
algorithm	B
(	O
cormen	O
2001	O
)	O
and	O
incremental	B
variants	O
have	O
also	O
been	O
developed	O
by	O
tomasi	O
and	O
manduchi	O
(	O
1998	O
)	O
and	O
bovik	O
(	O
2000	O
,	O
section	O
3.2	O
)	O
.	O
since	O
the	O
shot	B
noise	I
value	O
usually	O
lies	O
well	O
outside	O
the	O
true	O
values	O
in	O
the	O
neighborhood	B
,	O
the	O
median	B
ﬁlter	O
is	O
able	O
to	O
ﬁlter	O
away	O
such	O
bad	O
pixels	O
(	O
figure	O
3.18c	O
)	O
.	O
one	O
downside	O
of	O
the	O
median	B
ﬁlter	O
,	O
in	O
addition	O
to	O
its	O
moderate	O
computational	O
cost	O
,	O
is	O
that	O
since	O
it	O
selects	O
only	O
one	O
input	O
pixel	O
value	O
to	O
replace	O
each	O
output	O
pixel	O
,	O
it	O
is	O
not	O
as	O
efﬁcient	O
at	O
averaging	O
away	O
regular	O
gaussian	O
noise	B
(	O
huber	O
1981	O
;	O
hampel	O
,	O
ronchetti	O
,	O
rousseeuw	O
et	O
al	O
.	O
1986	O
;	O
stewart	O
1999	O
)	O
.	O
a	O
better	O
choice	O
may	O
be	O
the	O
α-trimmed	O
mean	O
(	O
lee	O
and	O
redner	O
1990	O
)	O
(	O
crane	O
1997	O
,	O
p.	O
109	O
)	O
,	O
which	O
averages	O
together	O
all	O
of	O
the	O
pixels	O
except	O
for	O
the	O
α	O
fraction	O
that	O
are	O
the	O
smallest	O
and	O
the	O
largest	O
(	O
figure	O
3.19b	O
)	O
.	O
another	O
possibility	O
is	O
to	O
compute	O
a	O
weighted	B
median	O
,	O
in	O
which	O
each	O
pixel	O
is	O
used	O
a	O
num-	O
ber	O
of	O
times	O
depending	O
on	O
its	O
distance	O
from	O
the	O
center	O
.	O
this	O
turns	O
out	O
to	O
be	O
equivalent	O
to	O
minimizing	O
the	O
weighted	B
objective	O
function	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
w	O
(	O
k	O
,	O
l	O
)	O
|f	O
(	O
i	O
+	O
k	O
,	O
j	O
+	O
l	O
)	O
−	O
g	O
(	O
i	O
,	O
j	O
)	O
|p	O
,	O
(	O
3.33	O
)	O
where	O
g	O
(	O
i	O
,	O
j	O
)	O
is	O
the	O
desired	O
output	O
value	O
and	O
p	O
=	O
1	O
for	O
the	O
weighted	B
median	O
.	O
the	O
value	O
p	O
=	O
2	O
is	O
the	O
usual	O
weighted	B
mean	O
,	O
which	O
is	O
equivalent	O
to	O
correlation	O
(	O
3.12	O
)	O
after	O
normalizing	B
by	O
the	O
sum	O
of	O
the	O
weights	O
(	O
bovik	O
2000	O
,	O
section	O
3.2	O
)	O
(	O
haralick	O
and	O
shapiro	O
1992	O
,	O
section	O
7.2.6	O
)	O
.	O
the	O
weighted	B
mean	O
also	O
has	O
deep	O
connections	O
to	O
other	O
methods	O
in	O
robust	B
statistics	O
(	O
see	O
ap-	O
pendix	O
b.3	O
)	O
,	O
such	O
as	O
inﬂuence	O
functions	O
(	O
huber	O
1981	O
;	O
hampel	O
,	O
ronchetti	O
,	O
rousseeuw	O
et	O
al	O
.	O
1986	O
)	O
.	O
non-linear	B
smoothing	O
has	O
another	O
,	O
perhaps	O
even	O
more	O
important	O
property	O
,	O
especially	O
since	O
shot	B
noise	I
is	O
rare	O
in	O
today	O
’	O
s	O
cameras	O
.	O
such	O
ﬁltering	O
is	O
more	O
edge	O
preserving	O
,	O
i.e.	O
,	O
it	O
has	O
less	O
tendency	O
to	O
soften	O
edges	O
while	O
ﬁltering	O
away	O
high-frequency	O
noise	B
.	O
consider	O
the	O
noisy	O
image	B
in	O
figure	O
3.18a	O
.	O
in	O
order	B
to	O
remove	O
most	O
of	O
the	O
noise	B
,	O
the	O
gaussian	O
ﬁlter	O
is	O
forced	O
to	O
smooth	O
away	O
high-frequency	O
detail	O
,	O
which	O
is	O
most	O
noticeable	O
near	O
strong	O
edges	O
.	O
median	B
ﬁltering	O
does	O
better	O
but	O
,	O
as	O
mentioned	O
before	O
,	O
does	O
not	O
do	O
as	O
good	O
a	O
job	O
at	O
smoothing	B
away	O
from	O
discontinuities	O
.	O
see	O
(	O
tomasi	O
and	O
manduchi	O
1998	O
)	O
for	O
some	O
additional	O
references	B
to	O
edge-preserving	B
smoothing	O
techniques	O
.	O
3.3	O
more	O
neighborhood	B
operators	O
125	O
while	O
we	O
could	O
try	O
to	O
use	O
the	O
α-trimmed	O
mean	O
or	O
weighted	B
median	O
,	O
these	O
techniques	O
still	O
have	O
a	O
tendency	O
to	O
round	O
sharp	O
corners	O
,	O
since	O
the	O
majority	O
of	O
pixels	O
in	O
the	O
smoothing	B
area	O
come	O
from	O
the	O
background	O
distribution	O
.	O
bilateral	B
ﬁltering	O
what	O
if	O
we	O
were	O
to	O
combine	O
the	O
idea	O
of	O
a	O
weighted	B
ﬁlter	O
kernel	B
with	O
a	O
better	O
version	O
of	O
outlier	O
rejection	O
?	O
what	O
if	O
instead	O
of	O
rejecting	O
a	O
ﬁxed	O
percentage	O
α	O
,	O
we	O
simply	O
reject	O
(	O
in	O
a	O
soft	O
way	O
)	O
pixels	O
whose	O
values	O
differ	O
too	O
much	O
from	O
the	O
central	O
pixel	O
value	O
?	O
this	O
is	O
the	O
essential	O
idea	O
in	O
bilateral	B
ﬁltering	O
,	O
which	O
was	O
ﬁrst	O
popularized	O
in	O
the	O
computer	O
vision	O
community	O
by	O
tomasi	O
and	O
manduchi	O
(	O
1998	O
)	O
.	O
chen	O
,	O
paris	O
,	O
and	O
durand	O
(	O
2007	O
)	O
and	O
paris	O
,	O
kornprobst	O
,	O
tumblin	O
et	O
al	O
.	O
(	O
2008	O
)	O
cite	O
similar	O
earlier	O
work	O
(	O
aurich	O
and	O
weule	O
1995	O
;	O
smith	O
and	O
brady	O
1997	O
)	O
as	O
well	O
as	O
the	O
wealth	O
of	O
subsequent	O
applications	O
in	O
computer	O
vision	O
and	O
computational	O
photography	O
.	O
in	O
the	O
bilateral	B
ﬁlter	I
,	O
the	O
output	O
pixel	O
value	O
depends	O
on	O
a	O
weighted	B
combination	O
of	O
neigh-	O
boring	O
pixel	O
values	O
the	O
weighting	B
coefﬁcient	O
w	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
depends	O
on	O
the	O
product	O
of	O
a	O
domain	O
kernel	B
(	O
figure	O
3.19c	O
)	O
,	O
g	O
(	O
i	O
,	O
j	O
)	O
=	O
(	O
cid:80	O
)	O
k	O
,	O
l	O
f	O
(	O
k	O
,	O
l	O
)	O
w	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
(	O
cid:80	O
)	O
k	O
,	O
l	O
w	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
(	O
i	O
−	O
k	O
)	O
2	O
+	O
(	O
j	O
−	O
l	O
)	O
2	O
.	O
d	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
=	O
exp	O
(	O
cid:18	O
)	O
−	O
2σ2	O
d	O
(	O
cid:19	O
)	O
,	O
(	O
3.34	O
)	O
(	O
3.35	O
)	O
(	O
3.36	O
)	O
(	O
3.37	O
)	O
and	O
a	O
data-dependent	O
range	B
kernel	I
(	O
figure	O
3.19d	O
)	O
,	O
r	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
=	O
exp	O
(	O
cid:18	O
)	O
−	O
(	O
cid:107	O
)	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
f	O
(	O
k	O
,	O
l	O
)	O
(	O
cid:107	O
)	O
2	O
2σ2	O
r	O
(	O
cid:19	O
)	O
.	O
when	O
multiplied	O
together	O
,	O
these	O
yield	O
the	O
data-dependent	O
bilateral	B
weight	O
function	O
w	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
=	O
exp	O
(	O
cid:18	O
)	O
−	O
(	O
i	O
−	O
k	O
)	O
2	O
+	O
(	O
j	O
−	O
l	O
)	O
2	O
2σ2	O
d	O
−	O
(	O
cid:107	O
)	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
f	O
(	O
k	O
,	O
l	O
)	O
(	O
cid:107	O
)	O
2	O
2σ2	O
r	O
(	O
cid:19	O
)	O
.	O
figure	O
3.20	O
shows	O
an	O
example	O
of	O
the	O
bilateral	B
ﬁltering	O
of	O
a	O
noisy	O
step	O
edge	O
.	O
note	O
how	O
the	O
do-	O
main	O
kernel	B
is	O
the	O
usual	O
gaussian	O
,	O
the	O
range	B
kernel	I
measures	O
appearance	O
(	O
intensity	O
)	O
similarity	B
to	O
the	O
center	O
pixel	O
,	O
and	O
the	O
bilateral	B
ﬁlter	I
kernel	O
is	O
a	O
product	O
of	O
these	O
two	O
.	O
notice	O
that	O
the	O
range	O
ﬁlter	O
(	O
3.36	O
)	O
uses	O
the	O
vector	O
distance	O
between	O
the	O
center	O
and	O
the	O
neighboring	O
pixel	O
.	O
this	O
is	O
important	O
in	O
color	B
images	O
,	O
since	O
an	O
edge	O
in	O
any	O
one	O
of	O
the	O
color	B
bands	O
signals	O
a	O
change	O
in	O
material	O
and	O
hence	O
the	O
need	O
to	O
downweight	O
a	O
pixel	O
’	O
s	O
inﬂuence.5	O
5	O
tomasi	O
and	O
manduchi	O
(	O
1998	O
)	O
show	O
that	O
using	O
the	O
vector	O
distance	O
(	O
as	O
opposed	O
to	O
ﬁltering	O
each	O
color	B
band	O
separately	O
)	O
reduces	O
color	B
fringing	O
effects	O
.	O
they	O
also	O
recommend	O
taking	O
the	O
color	B
difference	O
in	O
the	O
more	O
perceptually	O
uniform	O
cielab	O
color	B
space	O
(	O
see	O
section	O
2.3.2	O
)	O
.	O
126	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
figure	O
3.20	O
bilateral	B
ﬁltering	O
(	O
durand	O
and	O
dorsey	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
acm	O
:	O
(	O
a	O
)	O
noisy	O
step	O
edge	O
input	O
;	O
(	O
b	O
)	O
domain	O
ﬁlter	O
(	O
gaussian	O
)	O
;	O
(	O
c	O
)	O
range	O
ﬁlter	O
(	O
similarity	B
to	O
center	O
pixel	O
value	O
)	O
;	O
(	O
d	O
)	O
bilateral	B
ﬁlter	I
;	O
(	O
e	O
)	O
ﬁltered	O
step	O
edge	O
output	O
;	O
(	O
f	O
)	O
3d	O
distance	O
between	O
pixels	O
.	O
since	O
bilateral	B
ﬁltering	O
is	O
quite	O
slow	O
compared	O
to	O
regular	O
separable	B
ﬁltering	O
,	O
a	O
number	O
of	O
acceleration	O
techniques	O
have	O
been	O
developed	O
(	O
durand	O
and	O
dorsey	O
2002	O
;	O
paris	O
and	O
durand	O
2006	O
;	O
chen	O
,	O
paris	O
,	O
and	O
durand	O
2007	O
;	O
paris	O
,	O
kornprobst	O
,	O
tumblin	O
et	O
al	O
.	O
2008	O
)	O
.	O
unfortunately	O
,	O
these	O
techniques	O
tend	O
to	O
use	O
more	O
memory	O
than	O
regular	O
ﬁltering	O
and	O
are	O
hence	O
not	O
directly	O
applicable	O
to	O
ﬁltering	O
full-color	O
images	O
.	O
iterated	O
adaptive	O
smoothing	B
and	O
anisotropic	B
diffusion	O
bilateral	B
(	O
and	O
other	O
)	O
ﬁlters	O
can	O
also	O
be	O
applied	O
in	O
an	O
iterative	B
fashion	O
,	O
especially	O
if	O
an	O
appear-	O
ance	O
more	O
like	O
a	O
“	O
cartoon	O
”	O
is	O
desired	O
(	O
tomasi	O
and	O
manduchi	O
1998	O
)	O
.	O
when	O
iterated	O
ﬁltering	O
is	O
applied	O
,	O
a	O
much	O
smaller	O
neighborhood	B
can	O
often	O
be	O
used	O
.	O
consider	O
,	O
for	O
example	O
,	O
using	O
only	O
the	O
four	O
nearest	O
neighbors	O
,	O
i.e.	O
,	O
restricting	O
|k−	O
i|	O
+|l−	O
j|	O
≤	O
1	O
in	O
(	O
3.34	O
)	O
.	O
observe	O
that	O
(	O
3.38	O
)	O
(	O
3.39	O
)	O
d	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
=	O
exp	O
(	O
cid:18	O
)	O
−	O
=	O
(	O
cid:40	O
)	O
1	O
,	O
(	O
i	O
−	O
k	O
)	O
2	O
+	O
(	O
j	O
−	O
l	O
)	O
2	O
2σ2	O
d	O
(	O
cid:19	O
)	O
λ	O
=	O
e−1/2σ2	O
d	O
,	O
|k	O
−	O
i|	O
+	O
|l	O
−	O
j|	O
=	O
0	O
,	O
|k	O
−	O
i|	O
+	O
|l	O
−	O
j|	O
=	O
1	O
.	O
3.3	O
more	O
neighborhood	B
operators	O
we	O
can	O
thus	O
re-write	O
(	O
3.34	O
)	O
as	O
f	O
(	O
t+1	O
)	O
(	O
i	O
,	O
j	O
)	O
=	O
127	O
(	O
3.40	O
)	O
f	O
(	O
t	O
)	O
(	O
i	O
,	O
j	O
)	O
+	O
η	O
(	O
cid:80	O
)	O
k	O
,	O
l	O
f	O
(	O
t	O
)	O
(	O
k	O
,	O
l	O
)	O
r	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
1	O
+	O
η	O
(	O
cid:80	O
)	O
k	O
,	O
l	O
r	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
1	O
+	O
ηr	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
η	O
=	O
f	O
(	O
t	O
)	O
(	O
i	O
,	O
j	O
)	O
+	O
r	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
[	O
f	O
(	O
t	O
)	O
(	O
k	O
,	O
l	O
)	O
−	O
f	O
(	O
t	O
)	O
(	O
i	O
,	O
j	O
)	O
]	O
,	O
where	O
r	O
=	O
(	O
cid:80	O
)	O
(	O
k	O
,	O
l	O
)	O
r	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
,	O
(	O
k	O
,	O
l	O
)	O
are	O
the	O
n4	O
neighbors	O
of	O
(	O
i	O
,	O
j	O
)	O
,	O
and	O
we	O
have	O
made	O
the	O
iterative	B
nature	O
of	O
the	O
ﬁltering	O
explicit	O
.	O
as	O
barash	O
(	O
2002	O
)	O
notes	O
,	O
(	O
3.40	O
)	O
is	O
the	O
same	O
as	O
the	O
discrete	B
anisotropic	O
diffusion	O
equation	B
ﬁrst	O
proposed	O
by	O
perona	O
and	O
malik	O
(	O
1990b	O
)	O
.6	O
since	O
its	O
original	O
introduction	O
,	O
anisotropic	B
dif-	O
fusion	O
has	O
been	O
extended	O
and	O
applied	O
to	O
a	O
wide	O
range	O
of	O
problems	O
(	O
nielsen	O
,	O
florack	O
,	O
and	O
de-	O
riche	O
1997	O
;	O
black	O
,	O
sapiro	O
,	O
marimont	O
et	O
al	O
.	O
1998	O
;	O
weickert	O
,	O
ter	O
haar	O
romeny	O
,	O
and	O
viergever	O
1998	O
;	O
weickert	O
1998	O
)	O
.	O
it	O
has	O
also	O
been	O
shown	O
to	O
be	O
closely	O
related	O
to	O
other	O
adaptive	B
smooth-	O
ing	O
techniques	O
(	O
saint-marc	O
,	O
chen	O
,	O
and	O
medioni	O
1991	O
;	O
barash	O
2002	O
;	O
barash	O
and	O
comaniciu	O
2004	O
)	O
as	O
well	O
as	O
bayesian	O
regularization	B
with	O
a	O
non-linear	B
smoothness	O
term	O
that	O
can	O
be	O
de-	O
rived	O
from	O
image	B
statistics	O
(	O
scharr	O
,	O
black	O
,	O
and	O
haussecker	O
2003	O
)	O
.	O
in	O
its	O
general	O
form	O
,	O
the	O
range	B
kernel	I
r	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
=	O
r	O
(	O
(	O
cid:107	O
)	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
f	O
(	O
k	O
,	O
l	O
)	O
(	O
cid:107	O
)	O
)	O
,	O
which	O
is	O
usually	O
called	O
the	O
gain	O
or	O
edge-stopping	O
function	O
,	O
or	O
diffusion	O
coefﬁcient	O
,	O
can	O
be	O
any	O
monotonically	O
increasing	O
function	O
with	O
r	O
(	O
cid:48	O
)	O
(	O
x	O
)	O
→	O
0	O
as	O
x	O
→	O
∞	O
.	O
black	O
,	O
sapiro	O
,	O
marimont	O
et	O
al	O
.	O
(	O
1998	O
)	O
show	O
how	O
anisotropic	B
diffusion	O
is	O
equivalent	O
to	O
minimizing	O
a	O
robust	B
penalty	O
function	O
on	O
the	O
image	B
gradients	O
,	O
which	O
we	O
discuss	O
in	O
sections	O
3.7.1	O
and	O
3.7.2	O
)	O
.	O
scharr	O
,	O
black	O
,	O
and	O
haussecker	O
(	O
2003	O
)	O
show	O
how	O
the	O
edge-stopping	O
function	O
can	O
be	O
derived	O
in	O
a	O
principled	O
manner	O
from	O
local	B
image	O
statistics	O
.	O
they	O
also	O
extend	O
the	O
diffusion	O
neighborhood	B
from	O
n4	O
to	O
n8	O
,	O
which	O
allows	O
them	O
to	O
create	O
a	O
diffusion	O
operator	O
that	O
is	O
both	O
rotationally	O
invariant	O
and	O
incorporates	O
information	O
about	O
the	O
eigenvalues	B
of	O
the	O
local	B
structure	O
tensor	O
.	O
note	O
that	O
,	O
without	O
a	O
bias	O
term	O
towards	O
the	O
original	O
image	B
,	O
anisotropic	B
diffusion	O
and	O
itera-	O
tive	O
adaptive	B
smoothing	O
converge	O
to	O
a	O
constant	O
image	B
.	O
unless	O
a	O
small	O
number	O
of	O
iterations	O
is	O
used	O
(	O
e.g.	O
,	O
for	O
speed	O
)	O
,	O
it	O
is	O
usually	O
preferable	O
to	O
formulate	O
the	O
smoothing	B
problem	O
as	O
a	O
joint	B
minimization	O
of	O
a	O
smoothness	B
term	O
and	O
a	O
data	O
ﬁdelity	O
term	O
,	O
as	O
discussed	O
in	O
sections	O
3.7.1	O
and	O
3.7.2	O
and	O
by	O
scharr	O
,	O
black	O
,	O
and	O
haussecker	O
(	O
2003	O
)	O
,	O
which	O
introduce	O
such	O
a	O
bias	O
in	O
a	O
principled	O
manner	O
.	O
3.3.2	O
morphology	O
while	O
non-linear	B
ﬁlters	O
are	O
often	O
used	O
to	O
enhance	O
grayscale	O
and	O
color	B
images	O
,	O
they	O
are	O
also	O
used	O
extensively	O
to	O
process	O
binary	O
images	O
.	O
such	O
images	O
often	O
occur	O
after	O
a	O
thresholding	B
6	O
the	O
1/	O
(	O
1	O
+	O
ηr	O
)	O
factor	O
is	O
not	O
present	O
in	O
anisotropic	B
diffusion	O
but	O
becomes	O
negligible	O
as	O
η	O
→	O
0	O
.	O
128	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
figure	O
3.21	O
binary	O
image	O
morphology	O
:	O
(	O
a	O
)	O
original	O
image	B
;	O
(	O
b	O
)	O
dilation	B
;	O
(	O
c	O
)	O
erosion	B
;	O
(	O
d	O
)	O
majority	O
;	O
(	O
e	O
)	O
opening	B
;	O
(	O
f	O
)	O
closing	B
.	O
the	O
structuring	O
element	O
for	O
all	O
examples	B
is	O
a	O
5	O
×	O
5	O
square	O
.	O
the	O
effects	O
of	O
majority	O
are	O
a	O
subtle	O
rounding	O
of	O
sharp	O
corners	O
.	O
opening	B
fails	O
to	O
eliminate	O
the	O
dot	O
,	O
since	O
it	O
is	O
not	O
wide	O
enough	O
.	O
operation	O
,	O
θ	O
(	O
f	O
,	O
t	O
)	O
=	O
(	O
cid:40	O
)	O
1	O
if	O
f	O
≥	O
t	O
,	O
0	O
else	O
,	O
(	O
3.41	O
)	O
e.g.	O
,	O
converting	O
a	O
scanned	O
grayscale	O
document	O
into	O
a	O
binary	O
image	O
for	O
further	O
processing	O
such	O
as	O
optical	O
character	O
recognition	B
.	O
the	O
most	O
common	O
binary	O
image	O
operations	O
are	O
called	O
morphological	O
operations	O
,	O
since	O
they	O
change	O
the	O
shape	O
of	O
the	O
underlying	O
binary	O
objects	O
(	O
ritter	O
and	O
wilson	O
2000	O
,	O
chapter	O
7	O
)	O
.	O
to	O
perform	O
such	O
an	O
operation	O
,	O
we	O
ﬁrst	O
convolve	O
the	O
binary	O
image	O
with	O
a	O
binary	O
structuring	O
element	O
and	O
then	O
select	O
a	O
binary	O
output	O
value	O
depending	O
on	O
the	O
thresholded	O
result	O
of	O
the	O
convolution	O
.	O
(	O
this	O
is	O
not	O
the	O
usual	O
way	O
in	O
which	O
these	O
operations	O
are	O
described	O
,	O
but	O
i	O
ﬁnd	O
it	O
a	O
nice	O
simple	O
way	O
to	O
unify	O
the	O
processes	O
.	O
)	O
the	O
structuring	O
element	O
can	O
be	O
any	O
shape	O
,	O
from	O
a	O
simple	O
3	O
×	O
3	O
box	O
ﬁlter	O
,	O
to	O
more	O
complicated	O
disc	O
structures	O
.	O
it	O
can	O
even	O
correspond	O
to	O
a	O
particular	O
shape	O
that	O
is	O
being	O
sought	O
for	O
in	O
the	O
image	B
.	O
figure	O
3.21	O
shows	O
a	O
close-up	O
of	O
the	O
convolution	O
of	O
a	O
binary	O
image	O
f	O
with	O
a	O
3	O
×	O
3	O
struc-	O
turing	O
element	O
s	O
and	O
the	O
resulting	O
images	O
for	O
the	O
operations	O
described	O
below	O
.	O
let	O
c	O
=	O
f	O
⊗	O
s	O
(	O
3.42	O
)	O
be	O
the	O
integer-valued	O
count	O
of	O
the	O
number	O
of	O
1s	O
inside	O
each	O
structuring	O
element	O
as	O
it	O
is	O
scanned	O
over	O
the	O
image	B
and	O
s	O
be	O
the	O
size	O
of	O
the	O
structuring	O
element	O
(	O
number	O
of	O
pixels	O
)	O
.	O
the	O
standard	O
operations	O
used	O
in	O
binary	O
morphology	O
include	O
:	O
•	O
dilation	B
:	O
dilate	O
(	O
f	O
,	O
s	O
)	O
=	O
θ	O
(	O
c	O
,	O
1	O
)	O
;	O
•	O
erosion	B
:	O
erode	O
(	O
f	O
,	O
s	O
)	O
=	O
θ	O
(	O
c	O
,	O
s	O
)	O
;	O
•	O
majority	O
:	O
maj	O
(	O
f	O
,	O
s	O
)	O
=	O
θ	O
(	O
c	O
,	O
s/2	O
)	O
;	O
•	O
opening	B
:	O
open	O
(	O
f	O
,	O
s	O
)	O
=	O
dilate	O
(	O
erode	O
(	O
f	O
,	O
s	O
)	O
,	O
s	O
)	O
;	O
3.3	O
more	O
neighborhood	B
operators	O
129	O
•	O
closing	B
:	O
close	O
(	O
f	O
,	O
s	O
)	O
=	O
erode	O
(	O
dilate	O
(	O
f	O
,	O
s	O
)	O
,	O
s	O
)	O
.	O
as	O
we	O
can	O
see	O
from	O
figure	O
3.21	O
,	O
dilation	B
grows	O
(	O
thickens	O
)	O
objects	O
consisting	O
of	O
1s	O
,	O
while	O
erosion	B
shrinks	O
(	O
thins	O
)	O
them	O
.	O
the	O
opening	B
and	O
closing	B
operations	O
tend	O
to	O
leave	O
large	O
regions	O
and	O
smooth	O
boundaries	O
unaffected	O
,	O
while	O
removing	O
small	O
objects	O
or	O
holes	O
and	O
smoothing	B
boundaries	O
.	O
while	O
we	O
will	O
not	O
use	O
mathematical	O
morphology	O
much	O
in	O
the	O
rest	O
of	O
this	O
book	O
,	O
it	O
is	O
a	O
handy	O
tool	O
to	O
have	O
around	O
whenever	O
you	O
need	O
to	O
clean	O
up	O
some	O
thresholded	O
images	O
.	O
you	O
can	O
ﬁnd	O
additional	O
details	O
on	O
morphology	O
in	O
other	O
textbooks	B
on	O
computer	O
vision	O
and	O
image	B
processing	O
(	O
haralick	O
and	O
shapiro	O
1992	O
,	O
section	O
5.2	O
)	O
(	O
bovik	O
2000	O
,	O
section	O
2.2	O
)	O
(	O
ritter	O
and	O
wilson	O
2000	O
,	O
section	O
7	O
)	O
as	O
well	O
as	O
articles	O
and	O
books	O
speciﬁcally	O
on	O
this	O
topic	O
(	O
serra	O
1982	O
;	O
serra	O
and	O
vincent	O
1992	O
;	O
yuille	O
,	O
vincent	O
,	O
and	O
geiger	O
1992	O
;	O
soille	O
2006	O
)	O
.	O
3.3.3	O
distance	O
transforms	O
the	O
distance	O
transform	O
is	O
useful	O
in	O
quickly	O
precomputing	O
the	O
distance	O
to	O
a	O
curve	O
or	O
set	O
of	O
points	B
using	O
a	O
two-pass	O
raster	O
algorithm	B
(	O
rosenfeld	O
and	O
pfaltz	O
1966	O
;	O
danielsson	O
1980	O
;	O
borge-	O
fors	O
1986	O
;	O
paglieroni	O
1992	O
;	O
breu	O
,	O
gil	O
,	O
kirkpatrick	O
et	O
al	O
.	O
1995	O
;	O
felzenszwalb	O
and	O
huttenlocher	O
2004a	O
;	O
fabbri	O
,	O
costa	O
,	O
torelli	O
et	O
al	O
.	O
2008	O
)	O
.	O
it	O
has	O
many	O
applications	O
,	O
including	O
level	B
sets	I
(	O
sec-	O
tion	B
5.1.4	O
)	O
,	O
fast	O
chamfer	O
matching	B
(	O
binary	O
image	O
alignment	B
)	O
(	O
huttenlocher	O
,	O
klanderman	O
,	O
and	O
rucklidge	O
1993	O
)	O
,	O
feathering	B
in	O
image	B
stitching	I
and	O
blending	B
(	O
section	O
9.3.2	O
)	O
,	O
and	O
nearest	O
point	O
alignment	B
(	O
section	O
12.2.1	O
)	O
.	O
the	O
distance	O
transform	O
d	O
(	O
i	O
,	O
j	O
)	O
of	O
a	O
binary	O
image	O
b	O
(	O
i	O
,	O
j	O
)	O
is	O
deﬁned	O
as	O
follows	O
.	O
let	O
d	O
(	O
k	O
,	O
l	O
)	O
be	O
some	O
distance	O
metric	O
between	O
pixel	O
offsets	O
.	O
two	O
commonly	O
used	O
metrics	O
include	O
the	O
city	O
block	O
or	O
manhattan	O
distance	O
and	O
the	O
euclidean	O
distance	O
the	O
distance	O
transform	O
is	O
then	O
deﬁned	O
as	O
d1	O
(	O
k	O
,	O
l	O
)	O
=	O
|k|	O
+	O
|l|	O
d2	O
(	O
k	O
,	O
l	O
)	O
=	O
(	O
cid:112	O
)	O
k2	O
+	O
l2	O
.	O
d	O
(	O
i	O
,	O
j	O
)	O
=	O
min	O
k	O
,	O
l	O
:	O
b	O
(	O
k	O
,	O
l	O
)	O
=0	O
d	O
(	O
i	O
−	O
k	O
,	O
j	O
−	O
l	O
)	O
,	O
(	O
3.43	O
)	O
(	O
3.44	O
)	O
(	O
3.45	O
)	O
i.e.	O
,	O
it	O
is	O
the	O
distance	O
to	O
the	O
nearest	O
background	O
pixel	O
whose	O
value	O
is	O
0.	O
the	O
d1	O
city	O
block	O
distance	O
transform	B
can	O
be	O
efﬁciently	O
computed	O
using	O
a	O
forward	B
and	O
backward	O
pass	O
of	O
a	O
simple	O
raster-scan	O
algorithm	B
,	O
as	O
shown	O
in	O
figure	O
3.22.	O
during	O
the	O
forward	B
pass	O
,	O
each	O
non-zero	O
pixel	O
in	O
b	O
is	O
replaced	O
by	O
the	O
minimum	O
of	O
1	O
+	O
the	O
distance	O
of	O
its	O
north	O
or	O
west	O
neighbor	O
.	O
during	O
the	O
backward	O
pass	O
,	O
the	O
same	O
occurs	O
,	O
except	O
that	O
the	O
minimum	O
is	O
both	O
over	O
the	O
current	O
value	O
d	O
and	O
1	O
+	O
the	O
distance	O
of	O
the	O
south	O
and	O
east	O
neighbors	O
(	O
figure	O
3.22	O
)	O
.	O
130	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
3.22	O
city	O
block	O
distance	O
transform	B
:	O
(	O
a	O
)	O
original	O
binary	O
image	O
;	O
(	O
b	O
)	O
top	O
to	O
bottom	O
(	O
forward	B
)	O
raster	O
sweep	O
:	O
green	O
values	O
are	O
used	O
to	O
compute	O
the	O
orange	O
value	O
;	O
(	O
c	O
)	O
bottom	O
to	O
top	O
(	O
backward	O
)	O
raster	O
sweep	O
:	O
green	O
values	O
are	O
merged	O
with	O
old	O
orange	O
value	O
;	O
(	O
d	O
)	O
ﬁnal	O
distance	O
transform	O
.	O
efﬁciently	O
computing	O
the	O
euclidean	O
distance	O
transform	O
is	O
more	O
complicated	O
.	O
here	O
,	O
just	O
keeping	O
the	O
minimum	O
scalar	O
distance	O
to	O
the	O
boundary	O
during	O
the	O
two	O
passes	O
is	O
not	O
sufﬁcient	O
.	O
instead	O
,	O
a	O
vector-valued	O
distance	O
consisting	O
of	O
both	O
the	O
x	O
and	O
y	O
coordinates	O
of	O
the	O
distance	O
to	O
the	O
boundary	O
must	O
be	O
kept	O
and	O
compared	O
using	O
the	O
squared	O
distance	O
(	O
hypotenuse	O
)	O
rule	O
.	O
as	O
well	O
,	O
larger	O
search	O
regions	O
need	O
to	O
be	O
used	O
to	O
obtain	O
reasonable	O
results	O
.	O
rather	O
than	O
explaining	O
the	O
algorithm	B
(	O
danielsson	O
1980	O
;	O
borgefors	O
1986	O
)	O
in	O
more	O
detail	O
,	O
we	O
leave	O
it	O
as	O
an	O
exercise	O
for	O
the	O
motivated	O
reader	O
(	O
exercise	O
3.13	O
)	O
.	O
figure	O
3.11g	O
shows	O
a	O
distance	O
transform	O
computed	O
from	O
a	O
binary	O
image	O
.	O
notice	O
how	O
the	O
values	O
grow	O
away	O
from	O
the	O
black	O
(	O
ink	O
)	O
regions	O
and	O
form	O
ridges	O
in	O
the	O
white	O
area	O
of	O
the	O
original	O
image	B
.	O
because	O
of	O
this	O
linear	B
growth	O
from	O
the	O
starting	O
boundary	O
pixels	O
,	O
the	O
distance	O
transform	O
is	O
also	O
sometimes	O
known	O
as	O
the	O
grassﬁre	O
transform	B
,	O
since	O
it	O
describes	O
the	O
time	O
at	O
which	O
a	O
ﬁre	O
starting	O
inside	O
the	O
black	O
region	B
would	O
consume	O
any	O
given	O
pixel	O
,	O
or	O
a	O
chamfer	O
,	O
because	O
it	O
resembles	O
similar	O
shapes	O
used	O
in	O
woodworking	O
and	O
industrial	B
design	O
.	O
the	O
ridges	O
in	O
the	O
distance	O
transform	O
become	O
the	O
skeleton	O
(	O
or	O
medial	O
axis	O
transform	B
(	O
mat	O
)	O
)	O
of	O
the	O
region	B
where	O
the	O
transform	B
is	O
computed	O
,	O
and	O
consist	O
of	O
pixels	O
that	O
are	O
of	O
equal	O
distance	O
to	O
two	O
(	O
or	O
more	O
)	O
boundaries	O
(	O
tek	O
and	O
kimia	O
2003	O
;	O
sebastian	O
and	O
kimia	O
2005	O
)	O
.	O
a	O
useful	O
extension	O
of	O
the	O
basic	O
distance	O
transform	O
is	O
the	O
signed	B
distance	O
transform	B
,	O
which	O
computes	O
distances	O
to	O
boundary	O
pixels	O
for	O
all	O
the	O
pixels	O
(	O
lavall´ee	O
and	O
szeliski	O
1995	O
)	O
.	O
the	O
simplest	O
way	O
to	O
create	O
this	O
is	O
to	O
compute	O
the	O
distance	O
transforms	O
for	O
both	O
the	O
original	O
bi-	O
nary	O
image	B
and	O
its	O
complement	O
and	O
to	O
negate	O
one	O
of	O
them	O
before	O
combining	O
.	O
because	O
such	O
distance	O
ﬁelds	O
tend	O
to	O
be	O
smooth	O
,	O
it	O
is	O
possible	O
to	O
store	O
them	O
more	O
compactly	O
(	O
with	O
mini-	O
mal	O
loss	O
in	O
relative	O
accuracy	B
)	O
using	O
a	O
spline	B
deﬁned	O
over	O
a	O
quadtree	B
or	O
octree	B
data	O
structure	O
(	O
lavall´ee	O
and	O
szeliski	O
1995	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
frisken	O
,	O
perry	O
,	O
rockwood	O
et	O
al	O
.	O
2000	O
)	O
.	O
such	O
precomputed	O
signed	B
distance	O
transforms	O
can	O
be	O
extremely	O
useful	O
in	O
efﬁciently	O
aligning	O
and	O
merging	B
2d	O
curves	O
and	O
3d	O
surfaces	O
(	O
huttenlocher	O
,	O
klanderman	O
,	O
and	O
rucklidge	O
.0000100000010000001000000100001110000112000011200001110001111100122310012231001222100111110012301221100122110011100001210000121000001000000100000010000000000000000000000000	O
3.3	O
more	O
neighborhood	B
operators	O
131	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
3.23	O
connected	O
component	O
computation	O
:	O
(	O
a	O
)	O
original	O
grayscale	O
image	B
;	O
(	O
b	O
)	O
horizontal	O
runs	O
(	O
nodes	O
)	O
connected	O
by	O
vertical	O
(	O
graph	O
)	O
edges	O
(	O
dashed	O
blue	O
)	O
—runs	O
are	O
pseudocolored	O
with	O
unique	O
colors	O
inherited	O
from	O
parent	O
nodes	O
;	O
(	O
c	O
)	O
re-coloring	O
after	O
merging	B
adjacent	O
segments	O
.	O
1993	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
curless	O
and	O
levoy	O
1996	O
)	O
,	O
especially	O
if	O
the	O
vectorial	O
version	O
of	O
the	O
distance	O
transform	O
,	O
i.e.	O
,	O
a	O
pointer	O
from	O
each	O
pixel	O
or	O
voxel	O
to	O
the	O
nearest	O
boundary	O
or	O
surface	B
element	O
,	O
is	O
stored	O
and	O
interpolated	O
.	O
signed	B
distance	O
ﬁelds	O
are	O
also	O
an	O
essential	O
com-	O
ponent	O
of	O
level	O
set	O
evolution	B
(	O
section	O
5.1.4	O
)	O
,	O
where	O
they	O
are	O
called	O
characteristic	O
functions	O
.	O
3.3.4	O
connected	B
components	I
another	O
useful	O
semi-global	O
image	O
operation	O
is	O
ﬁnding	O
connected	B
components	I
,	O
which	O
are	O
de-	O
ﬁned	O
as	O
regions	O
of	O
adjacent	O
pixels	O
that	O
have	O
the	O
same	O
input	O
value	O
(	O
or	O
label	O
)	O
.	O
(	O
in	O
the	O
remainder	O
of	O
this	O
section	O
,	O
consider	O
pixels	O
to	O
be	O
adjacent	O
if	O
they	O
are	O
immediate	O
n4	O
neighbors	O
and	O
they	O
have	O
the	O
same	O
input	O
value	O
.	O
)	O
connected	B
components	I
can	O
be	O
used	O
in	O
a	O
variety	O
of	O
applications	O
,	O
such	O
as	O
ﬁnding	O
individual	O
letters	O
in	O
a	O
scanned	O
document	O
or	O
ﬁnding	O
objects	O
(	O
say	O
,	O
cells	O
)	O
in	O
a	O
thresholded	O
image	B
and	O
computing	O
their	O
area	O
statistics	O
.	O
consider	O
the	O
grayscale	O
image	B
in	O
figure	O
3.23a	O
.	O
there	O
are	O
four	O
connected	B
components	I
in	O
this	O
ﬁgure	O
:	O
the	O
outermost	O
set	O
of	O
white	O
pixels	O
,	O
the	O
large	O
ring	O
of	O
gray	O
pixels	O
,	O
the	O
white	O
enclosed	O
region	B
,	O
and	O
the	O
single	O
gray	O
pixel	O
.	O
these	O
are	O
shown	O
pseudocolored	O
in	O
figure	O
3.23c	O
as	O
pink	O
,	O
green	O
,	O
blue	O
,	O
and	O
brown	O
.	O
to	O
compute	O
the	O
connected	B
components	I
of	O
an	O
image	B
,	O
we	O
ﬁrst	O
(	O
conceptually	O
)	O
split	O
the	O
image	B
into	O
horizontal	O
runs	O
of	O
adjacent	O
pixels	O
,	O
and	O
then	O
color	B
the	O
runs	O
with	O
unique	O
labels	O
,	O
re-using	O
the	O
labels	O
of	O
vertically	O
adjacent	O
runs	O
whenever	O
possible	O
.	O
in	O
a	O
second	O
phase	O
,	O
adjacent	O
runs	O
of	O
different	O
colors	O
are	O
then	O
merged	O
.	O
while	O
this	O
description	O
is	O
a	O
little	O
sketchy	O
,	O
it	O
should	O
be	O
enough	O
to	O
enable	O
a	O
motivated	O
stu-	O
dent	O
to	O
implement	O
this	O
algorithm	B
(	O
exercise	O
3.14	O
)	O
.	O
haralick	O
and	O
shapiro	O
(	O
1992	O
,	O
section	O
2.3	O
)	O
give	O
a	O
much	O
longer	O
description	O
of	O
various	O
connected	O
component	O
algorithms	O
,	O
including	O
ones	O
132	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
that	O
avoid	O
the	O
creation	O
of	O
a	O
potentially	O
large	O
re-coloring	O
(	O
equivalence	O
)	O
table	O
.	O
well-debugged	O
connected	O
component	O
algorithms	O
are	O
also	O
available	O
in	O
most	O
image	B
processing	O
libraries	O
.	O
once	O
a	O
binary	O
or	O
multi-valued	O
image	B
has	O
been	O
segmented	O
into	O
its	O
connected	B
components	I
,	O
it	O
is	O
often	O
useful	O
to	O
compute	O
the	O
area	O
statistics	O
for	O
each	O
individual	O
region	B
r.	O
such	O
statistics	O
include	O
:	O
•	O
the	O
area	O
(	O
number	O
of	O
pixels	O
)	O
;	O
•	O
the	O
perimeter	B
(	O
number	O
of	O
boundary	O
pixels	O
)	O
;	O
•	O
the	O
centroid	O
(	O
average	O
x	O
and	O
y	O
values	O
)	O
;	O
•	O
the	O
second	O
moments	O
,	O
m	O
=	O
(	O
cid:88	O
)	O
(	O
x	O
,	O
y	O
)	O
∈r	O
y	O
−	O
y	O
(	O
cid:35	O
)	O
(	O
cid:104	O
)	O
x	O
−	O
x	O
y	O
−	O
y	O
(	O
cid:105	O
)	O
,	O
(	O
cid:34	O
)	O
x	O
−	O
x	O
(	O
3.46	O
)	O
from	O
which	O
the	O
major	O
and	O
minor	O
axis	O
orientation	O
and	O
lengths	O
can	O
be	O
computed	O
using	O
eigenvalue	O
analysis.7	O
these	O
statistics	O
can	O
then	O
be	O
used	O
for	O
further	O
processing	O
,	O
e.g.	O
,	O
for	O
sorting	O
the	O
regions	O
by	O
the	O
area	O
size	O
(	O
to	O
consider	O
the	O
largest	O
regions	O
ﬁrst	O
)	O
or	O
for	O
preliminary	O
matching	B
of	O
regions	O
in	O
different	O
images	O
.	O
3.4	O
fourier	O
transforms	O
in	O
section	O
3.2	O
,	O
we	O
mentioned	O
that	O
fourier	O
analysis	O
could	O
be	O
used	O
to	O
analyze	O
the	O
frequency	O
characteristics	O
of	O
various	O
ﬁlters	O
.	O
in	O
this	O
section	O
,	O
we	O
explain	O
both	O
how	O
fourier	O
analysis	O
lets	O
us	O
determine	O
these	O
characteristics	O
(	O
or	O
equivalently	O
,	O
the	O
frequency	O
content	O
of	O
an	O
image	B
)	O
and	O
how	O
using	O
the	O
fast	O
fourier	O
transform	B
(	O
fft	O
)	O
lets	O
us	O
perform	O
large-kernel	O
convolutions	O
in	O
time	O
that	O
is	O
independent	O
of	O
the	O
kernel	B
’	O
s	O
size	O
.	O
more	O
comprehensive	O
introductions	O
to	O
fourier	O
transforms	O
are	O
provided	O
by	O
bracewell	O
(	O
1986	O
)	O
;	O
glassner	O
(	O
1995	O
)	O
;	O
oppenheim	O
and	O
schafer	O
(	O
1996	O
)	O
;	O
oppen-	O
heim	O
,	O
schafer	O
,	O
and	O
buck	O
(	O
1999	O
)	O
.	O
how	O
can	O
we	O
analyze	O
what	O
a	O
given	O
ﬁlter	O
does	O
to	O
high	O
,	O
medium	O
,	O
and	O
low	O
frequencies	O
?	O
the	O
answer	O
is	O
to	O
simply	O
pass	O
a	O
sinusoid	O
of	O
known	O
frequency	O
through	O
the	O
ﬁlter	O
and	O
to	O
observe	O
by	O
how	O
much	O
it	O
is	O
attenuated	O
.	O
let	O
s	O
(	O
x	O
)	O
=	O
sin	O
(	O
2πf	O
x	O
+	O
φi	O
)	O
=	O
sin	O
(	O
ωx	O
+	O
φi	O
)	O
(	O
3.47	O
)	O
7	O
moments	O
can	O
also	O
be	O
computed	O
using	O
green	O
’	O
s	O
theorem	O
applied	O
to	O
the	O
boundary	O
pixels	O
(	O
yang	O
and	O
albregtsen	O
1996	O
)	O
.	O
3.4	O
fourier	O
transforms	O
133	O
figure	O
3.24	O
the	O
fourier	O
transform	B
as	O
the	O
response	O
of	O
a	O
ﬁlter	O
h	O
(	O
x	O
)	O
to	O
an	O
input	O
sinusoid	O
s	O
(	O
x	O
)	O
=	O
ejωx	O
yielding	O
an	O
output	O
sinusoid	O
o	O
(	O
x	O
)	O
=	O
h	O
(	O
x	O
)	O
∗	O
s	O
(	O
x	O
)	O
=	O
aejωx+φ	O
.	O
be	O
the	O
input	O
sinusoid	O
whose	O
frequency	O
is	O
f	O
,	O
angular	O
frequency	O
is	O
ω	O
=	O
2πf	O
,	O
and	O
phase	O
is	O
φi	O
.	O
note	O
that	O
in	O
this	O
section	O
,	O
we	O
use	O
the	O
variables	O
x	O
and	O
y	O
to	O
denote	O
the	O
spatial	O
coordinates	O
of	O
an	O
image	B
,	O
rather	O
than	O
i	O
and	O
j	O
as	O
in	O
the	O
previous	O
sections	O
.	O
this	O
is	O
both	O
because	O
the	O
letters	O
i	O
and	O
j	O
are	O
used	O
for	O
the	O
imaginary	O
number	O
(	O
the	O
usage	O
depends	O
on	O
whether	O
you	O
are	O
reading	O
complex	O
variables	O
or	O
electrical	O
engineering	O
literature	O
)	O
and	O
because	O
it	O
is	O
clearer	O
how	O
to	O
distinguish	O
the	O
horizontal	O
(	O
x	O
)	O
and	O
vertical	O
(	O
y	O
)	O
components	O
in	O
frequency	O
space	O
.	O
in	O
this	O
section	O
,	O
we	O
use	O
the	O
letter	O
j	O
for	O
the	O
imaginary	O
number	O
,	O
since	O
that	O
is	O
the	O
form	O
more	O
commonly	O
found	O
in	O
the	O
signal	O
processing	O
literature	O
(	O
bracewell	O
1986	O
;	O
oppenheim	O
and	O
schafer	O
1996	O
;	O
oppenheim	O
,	O
schafer	O
,	O
and	O
buck	O
1999	O
)	O
.	O
if	O
we	O
convolve	O
the	O
sinusoidal	O
signal	O
s	O
(	O
x	O
)	O
with	O
a	O
ﬁlter	O
whose	O
impulse	O
response	O
is	O
h	O
(	O
x	O
)	O
,	O
we	O
get	O
another	O
sinusoid	O
of	O
the	O
same	O
frequency	O
but	O
different	O
magnitude	O
a	O
and	O
phase	O
φo	O
,	O
o	O
(	O
x	O
)	O
=	O
h	O
(	O
x	O
)	O
∗	O
s	O
(	O
x	O
)	O
=	O
a	O
sin	O
(	O
ωx	O
+	O
φo	O
)	O
,	O
(	O
3.48	O
)	O
as	O
shown	O
in	O
figure	O
3.24.	O
to	O
see	O
that	O
this	O
is	O
the	O
case	O
,	O
remember	O
that	O
a	O
convolution	O
can	O
be	O
expressed	O
as	O
a	O
weighted	B
summation	O
of	O
shifted	O
input	O
signals	O
(	O
3.14	O
)	O
and	O
that	O
the	O
summation	O
of	O
a	O
bunch	O
of	O
shifted	O
sinusoids	O
of	O
the	O
same	O
frequency	O
is	O
just	O
a	O
single	O
sinusoid	O
at	O
that	O
frequency.8	O
the	O
new	O
magnitude	O
a	O
is	O
called	O
the	O
gain	O
or	O
magnitude	O
of	O
the	O
ﬁlter	O
,	O
while	O
the	O
phase	O
difference	O
∆φ	O
=	O
φo	O
−	O
φi	O
is	O
called	O
the	O
shift	O
or	O
phase	O
.	O
in	O
fact	O
,	O
a	O
more	O
compact	O
notation	O
is	O
to	O
use	O
the	O
complex-valued	O
sinusoid	O
s	O
(	O
x	O
)	O
=	O
ejωx	O
=	O
cos	O
ωx	O
+	O
j	O
sin	O
ωx	O
.	O
in	O
that	O
case	O
,	O
we	O
can	O
simply	O
write	O
,	O
o	O
(	O
x	O
)	O
=	O
h	O
(	O
x	O
)	O
∗	O
s	O
(	O
x	O
)	O
=	O
aejωx+φ	O
.	O
8	O
if	O
h	O
is	O
a	O
general	O
(	O
non-linear	B
)	O
transform	B
,	O
additional	O
harmonic	O
frequencies	O
are	O
introduced	O
.	O
this	O
was	O
traditionally	O
the	O
bane	O
of	O
audiophiles	O
,	O
who	O
insisted	O
on	O
equipment	O
with	O
no	O
harmonic	O
distortion	O
.	O
now	O
that	O
digital	O
audio	O
has	O
intro-	O
duced	O
pure	O
distortion-free	O
sound	O
,	O
some	O
audiophiles	O
are	O
buying	O
retro	O
tube	O
ampliﬁers	O
or	O
digital	O
signal	O
processors	O
that	O
simulate	O
such	O
distortions	O
because	O
of	O
their	O
“	O
warmer	O
sound	O
”	O
.	O
(	O
3.49	O
)	O
(	O
3.50	O
)	O
s	O
(	O
x	O
)	O
o	O
(	O
x	O
)	O
h	O
(	O
x	O
)	O
soxxaφ	O
134	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
the	O
fourier	O
transform	B
is	O
simply	O
a	O
tabulation	O
of	O
the	O
magnitude	O
and	O
phase	O
response	O
at	O
each	O
frequency	O
,	O
h	O
(	O
ω	O
)	O
=	O
f	O
{	O
h	O
(	O
x	O
)	O
}	O
=	O
aejφ	O
,	O
(	O
3.51	O
)	O
i.e.	O
,	O
it	O
is	O
the	O
response	O
to	O
a	O
complex	O
sinusoid	O
of	O
frequency	O
ω	O
passed	O
through	O
the	O
ﬁlter	O
h	O
(	O
x	O
)	O
.	O
the	O
fourier	O
transform	B
pair	O
is	O
also	O
often	O
written	O
as	O
h	O
(	O
x	O
)	O
f↔	O
h	O
(	O
ω	O
)	O
.	O
(	O
3.52	O
)	O
unfortunately	O
,	O
(	O
3.51	O
)	O
does	O
not	O
give	O
an	O
actual	O
formula	O
for	O
computing	O
the	O
fourier	O
transform	B
.	O
instead	O
,	O
it	O
gives	O
a	O
recipe	O
,	O
i.e.	O
,	O
convolve	O
the	O
ﬁlter	O
with	O
a	O
sinusoid	O
,	O
observe	O
the	O
magnitude	O
and	O
phase	O
shift	O
,	O
repeat	O
.	O
fortunately	O
,	O
closed	O
form	O
equations	B
for	O
the	O
fourier	O
transform	B
exist	O
both	O
in	O
the	O
continuous	O
domain	O
,	O
h	O
(	O
ω	O
)	O
=	O
(	O
cid:90	O
)	O
∞	O
−∞	O
h	O
(	O
x	O
)	O
e−jωxdx	O
,	O
(	O
3.53	O
)	O
(	O
3.54	O
)	O
and	O
in	O
the	O
discrete	B
domain	O
,	O
h	O
(	O
k	O
)	O
=	O
1	O
n	O
n−1	O
(	O
cid:88	O
)	O
x=0	O
h	O
(	O
x	O
)	O
e−j	O
2πkx	O
n	O
,	O
where	O
n	O
is	O
the	O
length	O
of	O
the	O
signal	O
or	O
region	B
of	O
analysis	O
.	O
these	O
formulas	O
apply	O
both	O
to	O
ﬁlters	O
,	O
such	O
as	O
h	O
(	O
x	O
)	O
,	O
and	O
to	O
signals	O
or	O
images	O
,	O
such	O
as	O
s	O
(	O
x	O
)	O
or	O
g	O
(	O
x	O
)	O
.	O
the	O
discrete	B
form	O
of	O
the	O
fourier	O
transform	B
(	O
3.54	O
)	O
is	O
known	O
as	O
the	O
discrete	B
fourier	O
trans-	O
form	O
(	O
dft	O
)	O
.	O
note	O
that	O
while	O
(	O
3.54	O
)	O
can	O
be	O
evaluated	O
for	O
any	O
value	O
of	O
k	O
,	O
it	O
only	O
makes	O
sense	O
2	O
]	O
.	O
this	O
is	O
because	O
larger	O
values	O
of	O
k	O
alias	O
with	O
lower	O
for	O
values	O
in	O
the	O
range	O
k	O
∈	O
[	O
−	O
n	O
frequencies	O
and	O
hence	O
provide	O
no	O
additional	O
information	O
,	O
as	O
explained	O
in	O
the	O
discussion	O
on	O
aliasing	B
in	O
section	O
2.3.1	O
.	O
2	O
,	O
n	O
at	O
face	B
value	O
,	O
the	O
dft	O
takes	O
o	O
(	O
n	O
2	O
)	O
operations	O
(	O
multiply-adds	O
)	O
to	O
evaluate	O
.	O
fortunately	O
,	O
there	O
exists	O
a	O
faster	O
algorithm	B
called	O
the	O
fast	O
fourier	O
transform	B
(	O
fft	O
)	O
,	O
which	O
requires	O
only	O
o	O
(	O
n	O
log2	O
n	O
)	O
operations	O
(	O
bracewell	O
1986	O
;	O
oppenheim	O
,	O
schafer	O
,	O
and	O
buck	O
1999	O
)	O
.	O
we	O
do	O
not	O
explain	O
the	O
details	O
of	O
the	O
algorithm	B
here	O
,	O
except	O
to	O
say	O
that	O
it	O
involves	O
a	O
series	O
of	O
log2	O
n	O
stages	O
,	O
where	O
each	O
stage	O
performs	O
small	O
2×	O
2	O
transforms	O
(	O
matrix	O
multiplications	O
with	O
known	O
coefﬁcients	O
)	O
followed	O
by	O
some	O
semi-global	O
permutations	O
.	O
(	O
you	O
will	O
often	O
see	O
the	O
term	O
but-	O
terﬂy	O
applied	O
to	O
these	O
stages	O
because	O
of	O
the	O
pictorial	O
shape	O
of	O
the	O
signal	O
processing	O
graphs	O
involved	O
.	O
)	O
implementations	O
for	O
the	O
fft	O
can	O
be	O
found	O
in	O
most	O
numerical	O
and	O
signal	O
processing	O
libraries	O
.	O
now	O
that	O
we	O
have	O
deﬁned	O
the	O
fourier	O
transform	B
,	O
what	O
are	O
some	O
of	O
its	O
properties	B
and	O
how	O
can	O
they	O
be	O
used	O
?	O
table	O
3.1	O
lists	O
a	O
number	O
of	O
useful	O
properties	B
,	O
which	O
we	O
describe	O
in	O
a	O
little	O
more	O
detail	O
below	O
:	O
3.4	O
fourier	O
transforms	O
135	O
property	O
signal	O
transform	B
f1	O
(	O
ω	O
)	O
+	O
f2	O
(	O
ω	O
)	O
f	O
(	O
ω	O
)	O
e−jωx0	O
f	O
∗	O
(	O
ω	O
)	O
superposition	B
shift	O
reversal	O
convolution	O
correlation	O
multiplication	B
differentiation	O
domain	O
scaling	O
real	O
images	O
f1	O
(	O
x	O
)	O
+	O
f2	O
(	O
x	O
)	O
f	O
(	O
x	O
−	O
x0	O
)	O
f	O
(	O
−x	O
)	O
f	O
(	O
x	O
)	O
∗	O
h	O
(	O
x	O
)	O
f	O
(	O
x	O
)	O
⊗	O
h	O
(	O
x	O
)	O
f	O
(	O
x	O
)	O
h	O
(	O
x	O
)	O
f	O
(	O
cid:48	O
)	O
(	O
x	O
)	O
f	O
(	O
ax	O
)	O
f	O
(	O
ω	O
)	O
h	O
(	O
ω	O
)	O
f	O
(	O
ω	O
)	O
h∗	O
(	O
ω	O
)	O
f	O
(	O
ω	O
)	O
∗	O
h	O
(	O
ω	O
)	O
1/af	O
(	O
ω/a	O
)	O
f	O
(	O
x	O
)	O
=	O
f∗	O
(	O
x	O
)	O
⇔	O
f	O
(	O
ω	O
)	O
=	O
f	O
(	O
−ω	O
)	O
(	O
cid:80	O
)	O
ω	O
[	O
f	O
(	O
ω	O
)	O
]	O
2	O
jωf	O
(	O
ω	O
)	O
parseval	O
’	O
s	O
theorem	O
(	O
cid:80	O
)	O
x	O
[	O
f	O
(	O
x	O
)	O
]	O
2	O
=	O
table	O
3.1	O
some	O
useful	O
properties	B
of	O
fourier	O
transforms	O
.	O
the	O
original	O
transform	B
pair	O
is	O
f	O
(	O
ω	O
)	O
=	O
f	O
{	O
f	O
(	O
x	O
)	O
}	O
.	O
•	O
superposition	B
:	O
the	O
fourier	O
transform	B
of	O
a	O
sum	O
of	O
signals	O
is	O
the	O
sum	O
of	O
their	O
fourier	O
transforms	O
.	O
thus	O
,	O
the	O
fourier	O
transform	B
is	O
a	O
linear	B
operator	O
.	O
•	O
shift	O
:	O
the	O
fourier	O
transform	B
of	O
a	O
shifted	O
signal	O
is	O
the	O
transform	B
of	O
the	O
original	O
signal	O
multiplied	O
by	O
a	O
linear	B
phase	O
shift	O
(	O
complex	O
sinusoid	O
)	O
.	O
•	O
reversal	O
:	O
the	O
fourier	O
transform	B
of	O
a	O
reversed	O
signal	O
is	O
the	O
complex	O
conjugate	O
of	O
the	O
signal	O
’	O
s	O
transform	B
.	O
•	O
convolution	O
:	O
the	O
fourier	O
transform	B
of	O
a	O
pair	O
of	O
convolved	O
signals	O
is	O
the	O
product	O
of	O
their	O
transforms	O
.	O
•	O
correlation	O
:	O
the	O
fourier	O
transform	B
of	O
a	O
correlation	O
is	O
the	O
product	O
of	O
the	O
ﬁrst	O
transform	B
times	O
the	O
complex	O
conjugate	O
of	O
the	O
second	O
one	O
.	O
•	O
multiplication	B
:	O
the	O
fourier	O
transform	B
of	O
the	O
product	O
of	O
two	O
signals	O
is	O
the	O
convolution	O
of	O
their	O
transforms	O
.	O
•	O
differentiation	O
:	O
the	O
fourier	O
transform	B
of	O
the	O
derivative	O
of	O
a	O
signal	O
is	O
that	O
signal	O
’	O
s	O
transform	B
multiplied	O
by	O
the	O
frequency	O
.	O
in	O
other	O
words	O
,	O
differentiation	O
linearly	O
empha-	O
sizes	O
(	O
magniﬁes	O
)	O
higher	O
frequencies	O
.	O
•	O
domain	O
scaling	O
:	O
the	O
fourier	O
transform	B
of	O
a	O
stretched	O
signal	O
is	O
the	O
equivalently	O
com-	O
pressed	O
(	O
and	O
scaled	O
)	O
version	O
of	O
the	O
original	O
transform	B
and	O
vice	O
versa	O
.	O
136	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
•	O
real	O
images	O
:	O
the	O
fourier	O
transform	B
of	O
a	O
real-valued	O
signal	O
is	O
symmetric	O
around	O
the	O
origin	O
.	O
this	O
fact	O
can	O
be	O
used	O
to	O
save	O
space	O
and	O
to	O
double	O
the	O
speed	O
of	O
image	B
ffts	O
by	O
packing	O
alternating	O
scanlines	O
into	O
the	O
real	O
and	O
imaginary	O
parts	O
of	O
the	O
signal	O
being	O
transformed	O
.	O
•	O
parseval	O
’	O
s	O
theorem	O
:	O
the	O
energy	O
(	O
sum	O
of	O
squared	O
values	O
)	O
of	O
a	O
signal	O
is	O
the	O
same	O
as	O
the	O
energy	O
of	O
its	O
fourier	O
transform	B
.	O
all	O
of	O
these	O
properties	B
are	O
relatively	O
straightforward	O
to	O
prove	O
(	O
see	O
exercise	O
3.15	O
)	O
and	O
they	O
will	O
come	O
in	O
handy	O
later	O
in	O
the	O
book	O
,	O
e.g.	O
,	O
when	O
designing	O
optimum	O
wiener	O
ﬁlters	O
(	O
section	O
3.4.3	O
)	O
or	O
performing	O
fast	O
image	O
correlations	O
(	O
section	O
8.1.2	O
)	O
.	O
3.4.1	O
fourier	O
transform	B
pairs	O
now	O
that	O
we	O
have	O
these	O
properties	B
in	O
place	O
,	O
let	O
us	O
look	O
at	O
the	O
fourier	O
transform	B
pairs	O
of	O
some	O
commonly	O
occurring	O
ﬁlters	O
and	O
signals	O
,	O
as	O
listed	O
in	O
table	O
3.2.	O
in	O
more	O
detail	O
,	O
these	O
pairs	B
are	O
as	O
follows	O
:	O
•	O
impulse	O
:	O
the	O
impulse	O
response	O
has	O
a	O
constant	O
(	O
all	O
frequency	O
)	O
transform	B
.	O
•	O
shifted	O
impulse	O
:	O
the	O
shifted	O
impulse	O
has	O
unit	O
magnitude	O
and	O
linear	B
phase	O
.	O
•	O
box	O
ﬁlter	O
:	O
the	O
box	O
(	O
moving	B
average	I
)	O
ﬁlter	O
box	O
(	O
x	O
)	O
=	O
(	O
cid:40	O
)	O
1	O
if	O
|x|	O
≤	O
1	O
0	O
else	O
has	O
a	O
sinc	B
fourier	O
transform	B
,	O
sinc	B
(	O
ω	O
)	O
=	O
(	O
3.55	O
)	O
(	O
3.56	O
)	O
sin	O
ω	O
,	O
ω	O
which	O
has	O
an	O
inﬁnite	O
number	O
of	O
side	O
lobes	O
.	O
conversely	O
,	O
the	O
sinc	B
ﬁlter	O
is	O
an	O
ideal	O
low-	O
pass	O
ﬁlter	O
.	O
for	O
a	O
non-unit	O
box	O
,	O
the	O
width	O
of	O
the	O
box	O
a	O
and	O
the	O
spacing	O
of	O
the	O
zero	O
crossings	O
in	O
the	O
sinc	B
1/a	O
are	O
inversely	O
proportional	O
.	O
•	O
tent	O
:	O
the	O
piecewise	O
linear	B
tent	O
function	O
,	O
tent	O
(	O
x	O
)	O
=	O
max	O
(	O
0	O
,	O
1	O
−	O
|x|	O
)	O
,	O
has	O
a	O
sinc2	O
fourier	O
transform	B
.	O
•	O
gaussian	O
:	O
the	O
(	O
unit	O
area	O
)	O
gaussian	O
of	O
width	O
σ	O
,	O
1	O
√2πσ	O
g	O
(	O
x	O
;	O
σ	O
)	O
=	O
e−	O
x2	O
2σ2	O
,	O
has	O
a	O
(	O
unit	O
height	O
)	O
gaussian	O
of	O
width	O
σ−1	O
as	O
its	O
fourier	O
transform	B
.	O
(	O
3.57	O
)	O
(	O
3.58	O
)	O
3.4	O
fourier	O
transforms	O
137	O
name	O
impulse	O
shifted	O
impulse	O
box	O
ﬁlter	O
tent	O
gaussian	O
laplacian	O
of	O
gaussian	O
gabor	O
unsharp	B
mask	I
windowed	O
sinc	B
signal	O
transform	B
δ	O
(	O
x	O
)	O
δ	O
(	O
x	O
−	O
u	O
)	O
box	O
(	O
x/a	O
)	O
tent	O
(	O
x/a	O
)	O
g	O
(	O
x	O
;	O
σ	O
)	O
⇔	O
⇔	O
⇔	O
⇔	O
⇔	O
1	O
e−jωu	O
asinc	O
(	O
aω	O
)	O
asinc2	O
(	O
aω	O
)	O
√2π	O
σ	O
g	O
(	O
ω	O
;	O
σ−1	O
)	O
(	O
x2	O
σ4	O
−	O
1	O
√2π	O
σ	O
ω2g	O
(	O
ω	O
;	O
σ−1	O
)	O
σ2	O
)	O
g	O
(	O
x	O
;	O
σ	O
)	O
⇔	O
−	O
√2π	O
σ	O
g	O
(	O
ω	O
±	O
ω0	O
;	O
σ−1	O
)	O
cos	O
(	O
ω0x	O
)	O
g	O
(	O
x	O
;	O
σ	O
)	O
⇔	O
(	O
1	O
+	O
γ	O
)	O
δ	O
(	O
x	O
)	O
−	O
γg	O
(	O
x	O
;	O
σ	O
)	O
rcos	O
(	O
x/	O
(	O
aw	O
)	O
)	O
⇔	O
sinc	B
(	O
x/a	O
)	O
⇔	O
√2πγ	O
(	O
1	O
+	O
γ	O
)	O
−	O
σ	O
g	O
(	O
ω	O
;	O
σ−1	O
)	O
(	O
see	O
figure	O
3.29	O
)	O
table	O
3.2	O
some	O
useful	O
(	O
continuous	O
)	O
fourier	O
transform	B
pairs	O
:	O
the	O
dashed	O
line	O
in	O
the	O
fourier	O
transform	B
of	O
the	O
shifted	O
impulse	O
indicates	O
its	O
(	O
linear	B
)	O
phase	O
.	O
all	O
other	O
transforms	O
have	O
zero	O
phase	O
(	O
they	O
are	O
real-valued	O
)	O
.	O
note	O
that	O
the	O
ﬁgures	O
are	O
not	O
necessarily	O
drawn	O
to	O
scale	O
but	O
are	O
drawn	O
to	O
illustrate	O
the	O
general	O
shape	O
and	O
characteristics	O
of	O
the	O
ﬁlter	O
or	O
its	O
response	O
.	O
in	O
particular	O
,	O
the	O
laplacian	O
of	O
gaussian	O
is	O
drawn	O
inverted	O
because	O
it	O
resembles	O
more	O
a	O
“	O
mexican	O
hat	O
”	O
,	O
as	O
it	O
is	O
sometimes	O
called	O
.	O
-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000-0.50.00.51.01.5-1.0000-0.50000.00000.50001.0000-0.50.00.51.01.5-0.50000.00000.5000-0.50.00.51.0-1.0000-0.50000.00000.50001.0000-0.50.00.51.0-0.50000.00000.5000	O
138	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
•	O
laplacian	O
of	O
gaussian	O
:	O
the	O
second	O
derivative	O
of	O
a	O
gaussian	O
of	O
width	O
σ	O
,	O
log	O
(	O
x	O
;	O
σ	O
)	O
=	O
(	O
x2	O
σ4	O
−	O
1	O
σ2	O
)	O
g	O
(	O
x	O
;	O
σ	O
)	O
has	O
a	O
band-pass	B
response	O
of	O
√2π	O
σ	O
−	O
ω2g	O
(	O
ω	O
;	O
σ−1	O
)	O
(	O
3.59	O
)	O
(	O
3.60	O
)	O
as	O
its	O
fourier	O
transform	B
.	O
•	O
gabor	O
:	O
the	O
even	O
gabor	O
function	O
,	O
which	O
is	O
the	O
product	O
of	O
a	O
cosine	O
of	O
frequency	O
ω0	O
and	O
a	O
gaussian	O
of	O
width	O
σ	O
,	O
has	O
as	O
its	O
transform	B
the	O
sum	O
of	O
the	O
two	O
gaussians	O
of	O
width	O
σ−1	O
centered	O
at	O
ω	O
=	O
±ω0	O
.	O
the	O
odd	O
gabor	O
function	O
,	O
which	O
uses	O
a	O
sine	O
,	O
is	O
the	O
difference	B
of	O
two	O
such	O
gaussians	O
.	O
gabor	O
functions	O
are	O
often	O
used	O
for	O
oriented	O
and	O
band-pass	B
ﬁltering	O
,	O
since	O
they	O
can	O
be	O
more	O
frequency	O
selective	O
than	O
gaussian	O
derivatives	O
.	O
•	O
unsharp	B
mask	I
:	O
the	O
unsharp	B
mask	I
introduced	O
in	O
(	O
3.22	O
)	O
has	O
as	O
its	O
transform	B
a	O
unit	O
response	O
with	O
a	O
slight	O
boost	O
at	O
higher	O
frequencies	O
.	O
•	O
windowed	B
sinc	I
:	O
the	O
windowed	B
(	O
masked	O
)	O
sinc	B
function	O
shown	O
in	O
table	O
3.2	O
has	O
a	O
re-	O
sponse	O
function	O
that	O
approximates	O
an	O
ideal	O
low-pass	B
ﬁlter	O
better	O
and	O
better	O
as	O
additional	O
side	O
lobes	O
are	O
added	O
(	O
w	O
is	O
increased	O
)	O
.	O
figure	O
3.29	O
shows	O
the	O
shapes	O
of	O
these	O
such	O
ﬁl-	O
ters	O
along	O
with	O
their	O
fourier	O
transforms	O
.	O
for	O
these	O
examples	B
,	O
we	O
use	O
a	O
one-lobe	O
raised	O
cosine	O
,	O
rcos	O
(	O
x	O
)	O
=	O
(	O
1	O
+	O
cos	O
πx	O
)	O
box	O
(	O
x	O
)	O
,	O
(	O
3.61	O
)	O
1	O
2	O
also	O
known	O
as	O
the	O
hann	O
window	O
,	O
as	O
the	O
windowing	O
function	O
.	O
wolberg	O
(	O
1990	O
)	O
and	O
oppenheim	O
,	O
schafer	O
,	O
and	O
buck	O
(	O
1999	O
)	O
discuss	O
additional	O
windowing	O
functions	O
,	O
which	O
include	O
the	O
lanczos	O
window	O
,	O
the	O
positive	O
ﬁrst	O
lobe	O
of	O
a	O
sinc	B
function	O
.	O
we	O
can	O
also	O
compute	O
the	O
fourier	O
transforms	O
for	O
the	O
small	O
discrete	B
kernels	O
shown	O
in	O
fig-	O
ure	O
3.14	O
(	O
see	O
table	O
3.3	O
)	O
.	O
notice	O
how	O
the	O
moving	B
average	I
ﬁlters	O
do	O
not	O
uniformly	O
dampen	O
higher	O
frequencies	O
and	O
hence	O
can	O
lead	O
to	O
ringing	O
artifacts	O
.	O
the	O
binomial	B
ﬁlter	O
(	O
gomes	O
and	O
velho	O
1997	O
)	O
used	O
as	O
the	O
“	O
gaussian	O
”	O
in	O
burt	O
and	O
adelson	O
’	O
s	O
(	O
1983a	O
)	O
laplacian	O
pyramid	B
(	O
see	O
section	O
3.5	O
)	O
,	O
does	O
a	O
decent	O
job	O
of	O
separating	O
the	O
high	O
and	O
low	O
frequencies	O
,	O
but	O
still	O
leaves	O
a	O
fair	O
amount	O
of	O
high-frequency	O
detail	O
,	O
which	O
can	O
lead	O
to	O
aliasing	B
after	O
downsampling	O
.	O
the	O
sobel	O
edge	O
detector	O
at	O
ﬁrst	O
linearly	O
accentuates	O
frequencies	O
,	O
but	O
then	O
decays	O
at	O
higher	O
fre-	O
quencies	O
,	O
and	O
hence	O
has	O
trouble	O
detecting	O
ﬁne-scale	O
edges	O
,	O
e.g.	O
,	O
adjacent	O
black	O
and	O
white	O
columns	O
.	O
we	O
look	O
at	O
additional	O
examples	B
of	O
small	O
kernel	B
fourier	O
transforms	O
in	O
section	O
3.5.2	O
,	O
where	O
we	O
study	O
better	O
kernels	O
for	O
pre-ﬁltering	O
before	O
decimation	O
(	O
size	O
reduction	O
)	O
.	O
3.4	O
fourier	O
transforms	O
139	O
name	O
kernel	B
transform	O
plot	O
box-3	O
1	O
3	O
1	O
1	O
1	O
1	O
3	O
(	O
1	O
+	O
2	O
cos	O
ω	O
)	O
box-5	O
1	O
5	O
1	O
1	O
1	O
1	O
1	O
1	O
5	O
(	O
1	O
+	O
2	O
cos	O
ω	O
+	O
2	O
cos	O
2ω	O
)	O
linear	B
1	O
4	O
1	O
2	O
1	O
1	O
2	O
(	O
1	O
+	O
cos	O
ω	O
)	O
binomial	B
1	O
16	O
1	O
4	O
6	O
4	O
1	O
1	O
4	O
(	O
1	O
+	O
cos	O
ω	O
)	O
2	O
sobel	O
1	O
2	O
−1	O
0	O
1	O
sin	O
ω	O
corner	O
1	O
2	O
−1	O
2	O
−1	O
1	O
2	O
(	O
1	O
−	O
cos	O
ω	O
)	O
table	O
3.3	O
fourier	O
transforms	O
of	O
the	O
separable	B
kernels	O
shown	O
in	O
figure	O
3.14	O
.	O
-0.4-0.20.00.20.40.60.81.000.10.20.30.40.5-0.4-0.20.00.20.40.60.81.000.10.20.30.40.5-0.4-0.20.00.20.40.60.81.000.10.20.30.40.5-0.4-0.20.00.20.40.60.81.000.10.20.30.40.5-0.4-0.20.00.20.40.60.81.000.10.20.30.40.5-0.4-0.20.00.20.40.60.81.000.10.20.30.40.5	O
140	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
3.4.2	O
two-dimensional	B
fourier	O
transforms	O
the	O
formulas	O
and	O
insights	O
we	O
have	O
developed	O
for	O
one-dimensional	O
signals	O
and	O
their	O
trans-	O
forms	O
translate	O
directly	O
to	O
two-dimensional	B
images	O
.	O
here	O
,	O
instead	O
of	O
just	O
specifying	O
a	O
hor-	O
izontal	O
or	O
vertical	O
frequency	O
ωx	O
or	O
ωy	O
,	O
we	O
can	O
create	O
an	O
oriented	B
sinusoid	O
of	O
frequency	O
(	O
ωx	O
,	O
ωy	O
)	O
,	O
s	O
(	O
x	O
,	O
y	O
)	O
=	O
sin	O
(	O
ωxx	O
+	O
ωyy	O
)	O
.	O
(	O
3.62	O
)	O
the	O
corresponding	O
two-dimensional	B
fourier	O
transforms	O
are	O
then	O
h	O
(	O
ωx	O
,	O
ωy	O
)	O
=	O
(	O
cid:90	O
)	O
∞	O
−∞	O
(	O
cid:90	O
)	O
∞	O
−∞	O
h	O
(	O
x	O
,	O
y	O
)	O
e−j	O
(	O
ωxx+ωyy	O
)	O
dx	O
dy	O
,	O
(	O
3.63	O
)	O
and	O
in	O
the	O
discrete	B
domain	O
,	O
h	O
(	O
kx	O
,	O
ky	O
)	O
=	O
1	O
m	O
n	O
m−1	O
(	O
cid:88	O
)	O
x=0	O
n−1	O
(	O
cid:88	O
)	O
y=0	O
h	O
(	O
x	O
,	O
y	O
)	O
e−j2π	O
kxx+ky	O
y	O
m	O
n	O
,	O
(	O
3.64	O
)	O
where	O
m	O
and	O
n	O
are	O
the	O
width	O
and	O
height	O
of	O
the	O
image	B
.	O
all	O
of	O
the	O
fourier	O
transform	B
properties	O
from	O
table	O
3.1	O
carry	O
over	O
to	O
two	O
dimensions	O
if	O
we	O
replace	O
the	O
scalar	O
variables	O
x	O
,	O
ω	O
,	O
x0	O
and	O
a	O
with	O
their	O
2d	O
vector	O
counterparts	O
x	O
=	O
(	O
x	O
,	O
y	O
)	O
,	O
ω	O
=	O
(	O
ωx	O
,	O
ωy	O
)	O
,	O
x0	O
=	O
(	O
x0	O
,	O
y0	O
)	O
,	O
and	O
a	O
=	O
(	O
ax	O
,	O
ay	O
)	O
,	O
and	O
use	O
vector	O
inner	O
products	O
instead	O
of	O
multiplications	O
.	O
3.4.3	O
wiener	O
ﬁltering	O
while	O
the	O
fourier	O
transform	B
is	O
a	O
useful	O
tool	O
for	O
analyzing	O
the	O
frequency	O
characteristics	O
of	O
a	O
ﬁlter	O
kernel	B
or	O
image	B
,	O
it	O
can	O
also	O
be	O
used	O
to	O
analyze	O
the	O
frequency	O
spectrum	O
of	O
a	O
whole	O
class	O
of	O
images	O
.	O
a	O
simple	O
model	O
for	O
images	O
is	O
to	O
assume	O
that	O
they	O
are	O
random	O
noise	O
ﬁelds	O
whose	O
expected	O
magnitude	O
at	O
each	O
frequency	O
is	O
given	O
by	O
this	O
power	B
spectrum	I
ps	O
(	O
ωx	O
,	O
ωy	O
)	O
,	O
i.e.	O
,	O
(	O
cid:10	O
)	O
[	O
s	O
(	O
ωx	O
,	O
ωy	O
)	O
]	O
2	O
(	O
cid:11	O
)	O
=	O
ps	O
(	O
ωx	O
,	O
ωy	O
)	O
,	O
(	O
3.65	O
)	O
where	O
the	O
angle	O
brackets	O
(	O
cid:104	O
)	O
·	O
(	O
cid:105	O
)	O
denote	O
the	O
expected	O
(	O
mean	O
)	O
value	O
of	O
a	O
random	O
variable.9	O
to	O
generate	O
such	O
an	O
image	B
,	O
we	O
simply	O
create	O
a	O
random	O
gaussian	O
noise	B
image	O
s	O
(	O
ωx	O
,	O
ωy	O
)	O
where	O
each	O
“	O
pixel	O
”	O
is	O
a	O
zero-mean	O
gaussian10	O
of	O
variance	O
ps	O
(	O
ωx	O
,	O
ωy	O
)	O
and	O
then	O
take	O
its	O
inverse	B
fft	O
.	O
the	O
observation	O
that	O
signal	O
spectra	O
capture	O
a	O
ﬁrst-order	O
description	O
of	O
spatial	O
statistics	O
is	O
widely	O
used	O
in	O
signal	O
and	O
image	B
processing	O
.	O
in	O
particular	O
,	O
assuming	O
that	O
an	O
image	B
is	O
a	O
9	O
the	O
notation	O
e	O
[	O
·	O
]	O
is	O
also	O
commonly	O
used	O
.	O
10	O
we	O
set	O
the	O
dc	O
(	O
i.e.	O
,	O
constant	O
)	O
component	O
at	O
s	O
(	O
0	O
,	O
0	O
)	O
to	O
the	O
mean	O
grey	O
level	O
.	O
see	O
algorithm	O
c.1	O
in	O
appendix	O
c.2	O
for	O
code	O
to	O
generate	O
gaussian	O
noise	B
.	O
3.4	O
fourier	O
transforms	O
141	O
sample	O
from	O
a	O
correlated	O
gaussian	O
random	O
noise	O
ﬁeld	O
combined	O
with	O
a	O
statistical	O
model	O
of	O
the	O
measurement	O
process	O
yields	O
an	O
optimum	O
restoration	O
ﬁlter	O
known	O
as	O
the	O
wiener	O
ﬁlter.11	O
to	O
derive	O
the	O
wiener	O
ﬁlter	O
,	O
we	O
analyze	O
each	O
frequency	O
component	O
of	O
a	O
signal	O
’	O
s	O
fourier	O
transform	B
independently	O
.	O
the	O
noisy	O
image	B
formation	O
process	O
can	O
be	O
written	O
as	O
o	O
(	O
x	O
,	O
y	O
)	O
=	O
s	O
(	O
x	O
,	O
y	O
)	O
+	O
n	O
(	O
x	O
,	O
y	O
)	O
,	O
(	O
3.66	O
)	O
where	O
s	O
(	O
x	O
,	O
y	O
)	O
is	O
the	O
(	O
unknown	O
)	O
image	B
we	O
are	O
trying	O
to	O
recover	O
,	O
n	O
(	O
x	O
,	O
y	O
)	O
is	O
the	O
additive	O
noise	B
signal	O
,	O
and	O
o	O
(	O
x	O
,	O
y	O
)	O
is	O
the	O
observed	O
noisy	O
image	B
.	O
because	O
of	O
the	O
linearity	B
of	O
the	O
fourier	O
trans-	O
form	O
,	O
we	O
can	O
write	O
o	O
(	O
ωx	O
,	O
ωy	O
)	O
=	O
s	O
(	O
ωx	O
,	O
ωy	O
)	O
+	O
n	O
(	O
ωx	O
,	O
ωy	O
)	O
,	O
(	O
3.67	O
)	O
where	O
each	O
quantity	O
in	O
the	O
above	O
equation	B
is	O
the	O
fourier	O
transform	B
of	O
the	O
corresponding	O
image	B
.	O
at	O
each	O
frequency	O
(	O
ωx	O
,	O
ωy	O
)	O
,	O
we	O
know	O
from	O
our	O
image	B
spectrum	O
that	O
the	O
unknown	O
trans-	O
form	O
component	O
s	O
(	O
ωx	O
,	O
ωy	O
)	O
has	O
a	O
prior	B
distribution	I
which	O
is	O
a	O
zero-mean	O
gaussian	O
with	O
vari-	O
ance	O
ps	O
(	O
ωx	O
,	O
ωy	O
)	O
.	O
we	O
also	O
have	O
noisy	O
measurement	O
o	O
(	O
ωx	O
,	O
ωy	O
)	O
whose	O
variance	O
is	O
pn	O
(	O
ωx	O
,	O
ωy	O
)	O
,	O
i.e.	O
,	O
the	O
power	B
spectrum	I
of	O
the	O
noise	B
,	O
which	O
is	O
usually	O
assumed	O
to	O
be	O
constant	O
(	O
white	O
)	O
,	O
n.	O
pn	O
(	O
ωx	O
,	O
ωy	O
)	O
=	O
σ2	O
according	O
to	O
bayes	O
’	O
rule	O
(	O
appendix	O
b.4	O
)	O
,	O
the	O
posterior	O
estimate	O
of	O
s	O
can	O
be	O
written	O
as	O
p	O
(	O
s|o	O
)	O
=	O
p	O
(	O
o|s	O
)	O
p	O
(	O
s	O
)	O
p	O
(	O
o	O
)	O
,	O
(	O
3.68	O
)	O
where	O
p	O
(	O
o	O
)	O
=	O
(	O
cid:82	O
)	O
s	O
p	O
(	O
o|s	O
)	O
p	O
(	O
s	O
)	O
is	O
a	O
normalizing	B
constant	O
used	O
to	O
make	O
the	O
p	O
(	O
s|o	O
)	O
distribution	O
proper	O
(	O
integrate	O
to	O
1	O
)	O
.	O
the	O
prior	B
distribution	I
p	O
(	O
s	O
)	O
is	O
given	O
by	O
p	O
(	O
s	O
)	O
=	O
e−	O
(	O
s−µ	O
)	O
2	O
2ps	O
,	O
(	O
3.69	O
)	O
where	O
µ	O
is	O
the	O
expected	O
mean	O
at	O
that	O
frequency	O
(	O
0	O
everywhere	O
except	O
at	O
the	O
origin	O
)	O
and	O
the	O
measurement	O
distribution	O
p	O
(	O
o|s	O
)	O
is	O
given	O
by	O
p	O
(	O
s	O
)	O
=	O
e−	O
(	O
s−o	O
)	O
2	O
2pn	O
.	O
(	O
3.70	O
)	O
taking	O
the	O
negative	O
logarithm	O
of	O
both	O
sides	O
of	O
(	O
3.68	O
)	O
and	O
setting	O
µ	O
=	O
0	O
for	O
simplicity	O
,	O
we	O
get	O
−	O
log	O
p	O
(	O
s|o	O
)	O
=	O
−	O
log	O
p	O
(	O
o|s	O
)	O
−	O
log	O
p	O
(	O
s	O
)	O
+	O
c	O
n	O
(	O
s	O
−	O
o	O
)	O
2	O
+	O
1/2p	O
−1	O
=	O
1/2p	O
−1	O
s	O
s2	O
+	O
c	O
,	O
(	O
3.71	O
)	O
(	O
3.72	O
)	O
11	O
wiener	O
is	O
pronounced	O
“	O
veener	O
”	O
since	O
,	O
in	O
german	O
,	O
the	O
“	O
w	O
”	O
is	O
pronounced	O
“	O
v	O
”	O
.	O
remember	O
that	O
next	O
time	O
you	O
order	B
“	O
wiener	O
schnitzel	O
”	O
.	O
142	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.25	O
one-dimensional	O
wiener	O
ﬁlter	O
:	O
(	O
a	O
)	O
power	B
spectrum	I
of	O
signal	O
ps	O
(	O
f	O
)	O
,	O
noise	B
level	O
σ2	O
,	O
and	O
wiener	O
ﬁlter	O
transform	B
w	O
(	O
f	O
)	O
;	O
(	O
b	O
)	O
wiener	O
ﬁlter	O
spatial	O
kernel	B
.	O
which	O
is	O
the	O
negative	O
posterior	O
log	O
likelihood	O
.	O
the	O
minimum	O
of	O
this	O
quantity	O
is	O
easy	O
to	O
compute	O
,	O
sopt	O
=	O
the	O
quantity	O
p	O
−1	O
n	O
p	O
−1	O
n	O
+	O
p	O
−1	O
s	O
o	O
=	O
ps	O
ps	O
+	O
pn	O
o	O
=	O
w	O
(	O
ωx	O
,	O
ωy	O
)	O
=	O
1	O
1	O
+	O
σ2	O
n/ps	O
(	O
ωx	O
,	O
ωy	O
)	O
1	O
1	O
+	O
pn/ps	O
o	O
.	O
(	O
3.73	O
)	O
(	O
3.74	O
)	O
is	O
the	O
fourier	O
transform	B
of	O
the	O
optimum	O
wiener	O
ﬁlter	O
needed	O
to	O
remove	O
the	O
noise	B
from	O
an	O
image	B
whose	O
power	B
spectrum	I
is	O
ps	O
(	O
ωx	O
,	O
ωy	O
)	O
.	O
notice	O
that	O
this	O
ﬁlter	O
has	O
the	O
right	O
qualitative	O
properties	B
,	O
i.e.	O
,	O
for	O
low	O
frequencies	O
where	O
n	O
,	O
it	O
has	O
unit	O
gain	O
,	O
whereas	O
for	O
high	O
frequencies	O
,	O
it	O
attenuates	O
the	O
noise	B
by	O
a	O
factor	O
ps	O
(	O
cid:29	O
)	O
σ2	O
n.	O
figure	O
3.25	O
shows	O
the	O
one-dimensional	O
transform	B
w	O
(	O
f	O
)	O
and	O
the	O
corresponding	O
ﬁlter	O
ps/σ2	O
kernel	B
w	O
(	O
x	O
)	O
for	O
the	O
commonly	O
assumed	O
case	O
of	O
p	O
(	O
f	O
)	O
=	O
f−2	O
(	O
field	O
1987	O
)	O
.	O
exercise	O
3.16	O
has	O
you	O
compare	O
the	O
wiener	O
ﬁlter	O
as	O
a	O
denoising	O
algorithm	B
to	O
hand-tuned	O
gaussian	O
smoothing	B
.	O
the	O
methodology	O
given	O
above	O
for	O
deriving	O
the	O
wiener	O
ﬁlter	O
can	O
easily	O
be	O
extended	O
to	O
the	O
case	O
where	O
the	O
observed	O
image	B
is	O
a	O
noisy	O
blurred	O
version	O
of	O
the	O
original	O
image	B
,	O
o	O
(	O
x	O
,	O
y	O
)	O
=	O
b	O
(	O
x	O
,	O
y	O
)	O
∗	O
s	O
(	O
x	O
,	O
y	O
)	O
+	O
n	O
(	O
x	O
,	O
y	O
)	O
,	O
(	O
3.75	O
)	O
where	O
b	O
(	O
x	O
,	O
y	O
)	O
is	O
the	O
known	O
blur	O
kernel	O
.	O
rather	O
than	O
deriving	O
the	O
corresponding	O
wiener	O
ﬁl-	O
ter	O
,	O
we	O
leave	O
it	O
as	O
an	O
exercise	O
(	O
exercise	O
3.17	O
)	O
,	O
which	O
also	O
encourages	O
you	O
to	O
compare	O
your	O
de-blurring	O
results	O
with	O
unsharp	O
masking	O
and	O
na¨ıve	O
inverse	B
ﬁltering	O
.	O
more	O
sophisticated	O
al-	O
gorithms	O
for	O
blur	O
removal	O
are	O
discussed	O
in	O
sections	O
3.7	O
and	O
10.3.	O
discrete	B
cosine	O
transform	B
the	O
discrete	B
cosine	O
transform	B
(	O
dct	O
)	O
is	O
a	O
variant	O
of	O
the	O
fourier	O
transform	B
particularly	O
well-	O
suited	O
to	O
compressing	O
images	O
in	O
a	O
block-wise	O
fashion	O
.	O
the	O
one-dimensional	O
dct	O
is	O
com-	O
puted	O
by	O
taking	O
the	O
dot	O
product	O
of	O
each	O
n-wide	O
block	O
of	O
pixels	O
with	O
a	O
set	O
of	O
cosines	O
of	O
pnw	O
3.4	O
fourier	O
transforms	O
143	O
figure	O
3.26	O
discrete	B
cosine	O
transform	B
(	O
dct	O
)	O
basis	O
functions	O
:	O
the	O
ﬁrst	O
dc	O
(	O
i.e.	O
,	O
constant	O
)	O
basis	O
is	O
the	O
horizontal	O
blue	O
line	O
,	O
the	O
second	O
is	O
the	O
brown	O
half-cycle	O
waveform	O
,	O
etc	O
.	O
these	O
bases	O
are	O
widely	O
used	O
in	O
image	B
and	O
video	B
compression	I
standards	O
such	O
as	O
jpeg	O
.	O
cos	O
(	O
cid:18	O
)	O
π	O
n	O
(	O
i	O
+	O
1	O
2	O
)	O
k	O
(	O
cid:19	O
)	O
f	O
(	O
i	O
)	O
,	O
(	O
3.76	O
)	O
n−1	O
(	O
cid:88	O
)	O
i=0	O
different	O
frequencies	O
,	O
f	O
(	O
k	O
)	O
=	O
where	O
k	O
is	O
the	O
coefﬁcient	O
(	O
frequency	O
)	O
index	O
,	O
and	O
the	O
1/2-pixel	O
offset	O
is	O
used	O
to	O
make	O
the	O
basis	O
coefﬁcients	O
symmetric	O
(	O
wallace	O
1991	O
)	O
.	O
some	O
of	O
the	O
discrete	B
cosine	O
basis	O
functions	O
are	O
shown	O
in	O
figure	O
3.26.	O
as	O
you	O
can	O
see	O
,	O
the	O
ﬁrst	O
basis	O
function	O
(	O
the	O
straight	O
blue	O
line	O
)	O
encodes	O
the	O
average	O
dc	O
value	O
in	O
the	O
block	O
of	O
pixels	O
,	O
while	O
the	O
second	O
encodes	O
a	O
slightly	O
curvy	O
version	O
of	O
the	O
slope	O
.	O
in	O
turns	O
out	O
that	O
the	O
dct	O
is	O
a	O
good	O
approximation	O
to	O
the	O
optimal	O
karhunen–lo`eve	O
decom-	O
position	O
of	O
natural	B
image	O
statistics	O
over	O
small	O
patches	O
,	O
which	O
can	O
be	O
obtained	O
by	O
performing	O
a	O
principal	O
component	O
analysis	O
(	O
pca	O
)	O
of	O
images	O
,	O
as	O
described	O
in	O
section	O
14.2.1.	O
the	O
kl-	O
transform	B
de-correlates	O
the	O
signal	O
optimally	O
(	O
assuming	O
the	O
signal	O
is	O
described	O
by	O
its	O
spectrum	O
)	O
and	O
thus	O
,	O
theoretically	O
,	O
leads	O
to	O
optimal	O
compression	B
.	O
the	O
two-dimensional	B
version	O
of	O
the	O
dct	O
is	O
deﬁned	O
similarly	O
,	O
f	O
(	O
k	O
,	O
l	O
)	O
=	O
n−1	O
(	O
cid:88	O
)	O
i=0	O
n−1	O
(	O
cid:88	O
)	O
j=0	O
cos	O
(	O
cid:18	O
)	O
π	O
n	O
(	O
i	O
+	O
1	O
2	O
)	O
k	O
(	O
cid:19	O
)	O
cos	O
(	O
cid:18	O
)	O
π	O
n	O
(	O
j	O
+	O
1	O
2	O
)	O
l	O
(	O
cid:19	O
)	O
f	O
(	O
i	O
,	O
j	O
)	O
.	O
(	O
3.77	O
)	O
like	O
the	O
2d	O
fast	O
fourier	O
transform	B
,	O
the	O
2d	O
dct	O
can	O
be	O
implemented	O
separably	O
,	O
i.e.	O
,	O
ﬁrst	O
computing	O
the	O
dct	O
of	O
each	O
line	O
in	O
the	O
block	O
and	O
then	O
computing	O
the	O
dct	O
of	O
each	O
resulting	O
column	O
.	O
like	O
the	O
fft	O
,	O
each	O
of	O
the	O
dcts	O
can	O
also	O
be	O
computed	O
in	O
o	O
(	O
n	O
log	O
n	O
)	O
time	O
.	O
as	O
we	O
mentioned	O
in	O
section	O
2.3.3	O
,	O
the	O
dct	O
is	O
widely	O
used	O
in	O
today	O
’	O
s	O
image	B
and	O
video	B
compression	I
algorithms	O
,	O
although	O
it	O
is	O
slowly	O
being	O
supplanted	O
by	O
wavelet	O
algorithms	O
(	O
si-	O
moncelli	O
and	O
adelson	O
1990b	O
)	O
,	O
as	O
discussed	O
in	O
section	O
3.5.4	O
,	O
and	O
overlapped	O
variants	O
of	O
the	O
dct	O
(	O
malvar	O
1990	O
,	O
1998	O
,	O
2000	O
)	O
,	O
which	O
are	O
used	O
in	O
the	O
new	O
jpeg	O
xr	O
standard.12	O
these	O
12	O
http	O
:	O
//www.itu.int/rec/t-rec-t.832-200903-i/en	O
.	O
-1.00-0.75-0.50-0.250.000.250.500.751.000.000.250.500.751.00	O
144	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
newer	O
algorithms	O
suffer	O
less	O
from	O
the	O
blocking	O
artifacts	O
(	O
visible	O
edge-aligned	O
discontinuities	O
)	O
that	O
result	O
from	O
the	O
pixels	O
in	O
each	O
block	O
(	O
typically	O
8	O
×	O
8	O
)	O
being	O
transformed	O
and	O
quantized	O
independently	O
.	O
see	O
exercise	O
3.30	O
for	O
ideas	O
on	O
how	O
to	O
remove	O
blocking	O
artifacts	O
from	O
com-	O
pressed	O
jpeg	O
images	O
.	O
3.4.4	O
application	O
:	O
sharpening	O
,	O
blur	O
,	O
and	O
noise	B
removal	I
another	O
common	O
application	O
of	O
image	B
processing	O
is	O
the	O
enhancement	O
of	O
images	O
through	O
the	O
use	O
of	O
sharpening	O
and	O
noise	B
removal	I
operations	O
,	O
which	O
require	O
some	O
kind	O
of	O
neighborhood	B
processing	O
.	O
traditionally	O
,	O
these	O
kinds	O
of	O
operation	O
were	O
performed	O
using	O
linear	O
ﬁltering	O
(	O
see	O
sections	O
3.2	O
and	O
section	O
3.4.3	O
)	O
.	O
today	O
,	O
it	O
is	O
more	O
common	O
to	O
use	O
non-linear	B
ﬁlters	O
(	O
sec-	O
tion	B
3.3.1	O
)	O
,	O
such	O
as	O
the	O
weighted	B
median	O
or	O
bilateral	B
ﬁlter	I
(	O
3.34–3.37	O
)	O
,	O
anisotropic	B
diffusion	O
(	O
3.39–3.40	O
)	O
,	O
or	O
non-local	O
means	O
(	O
buades	O
,	O
coll	O
,	O
and	O
morel	O
2008	O
)	O
.	O
variational	O
methods	O
(	O
sec-	O
tion	B
3.7.1	O
)	O
,	O
especially	O
those	O
using	O
non-quadratic	O
(	O
robust	B
)	O
norms	O
such	O
as	O
the	O
l1	O
norm	O
(	O
which	O
is	O
called	O
total	B
variation	I
)	O
,	O
are	O
also	O
often	O
used	O
.	O
figure	O
3.19	O
shows	O
some	O
examples	B
of	O
linear	B
and	O
non-linear	B
ﬁlters	O
being	O
used	O
to	O
remove	O
noise	B
.	O
when	O
measuring	O
the	O
effectiveness	O
of	O
image	B
denoising	O
algorithms	O
,	O
it	O
is	O
common	O
to	O
report	O
the	O
results	O
as	O
a	O
peak	O
signal-to-noise	O
ratio	O
(	O
psnr	O
)	O
measurement	O
(	O
2.119	O
)	O
,	O
where	O
i	O
(	O
x	O
)	O
is	O
the	O
original	O
(	O
noise-free	O
)	O
image	B
and	O
ˆi	O
(	O
x	O
)	O
is	O
the	O
image	B
after	O
denoising	O
;	O
this	O
is	O
for	O
the	O
case	O
where	O
the	O
noisy	O
image	B
has	O
been	O
synthetically	O
generated	O
,	O
so	O
that	O
the	O
clean	O
image	B
is	O
known	O
.	O
a	O
better	O
way	O
to	O
measure	O
the	O
quality	O
is	O
to	O
use	O
a	O
perceptually	O
based	O
similarity	B
metric	O
,	O
such	O
as	O
the	O
structural	O
similarity	B
(	O
ssim	O
)	O
index	O
(	O
wang	O
,	O
bovik	O
,	O
sheikh	O
et	O
al	O
.	O
2004	O
;	O
wang	O
,	O
bovik	O
,	O
and	O
simoncelli	O
2005	O
)	O
.	O
exercises	O
3.11	O
,	O
3.16	O
,	O
3.17	O
,	O
3.21	O
,	O
and	O
3.28	O
have	O
you	O
implement	O
some	O
of	O
these	O
operations	O
and	O
compare	O
their	O
effectiveness	O
.	O
more	O
sophisticated	O
techniques	O
for	O
blur	O
removal	O
and	O
the	O
related	O
task	O
of	O
super-resolution	O
are	O
discussed	O
in	O
section	O
10.3	O
.	O
3.5	O
pyramids	O
and	O
wavelets	O
so	O
far	O
in	O
this	O
chapter	O
,	O
all	O
of	O
the	O
image	B
transformations	O
we	O
have	O
studied	O
produce	O
output	O
images	O
of	O
the	O
same	O
size	O
as	O
the	O
inputs	O
.	O
often	O
,	O
however	O
,	O
we	O
may	O
wish	O
to	O
change	O
the	O
resolution	O
of	O
an	O
image	B
before	O
proceeding	O
further	O
.	O
for	O
example	O
,	O
we	O
may	O
need	O
to	O
interpolate	O
a	O
small	O
image	B
to	O
make	O
its	O
resolution	O
match	O
that	O
of	O
the	O
output	O
printer	O
or	O
computer	O
screen	O
.	O
alternatively	O
,	O
we	O
may	O
want	O
to	O
reduce	O
the	O
size	O
of	O
an	O
image	B
to	O
speed	O
up	O
the	O
execution	O
of	O
an	O
algorithm	B
or	O
to	O
save	O
on	O
storage	O
space	O
or	O
transmission	O
time	O
.	O
sometimes	O
,	O
we	O
do	O
not	O
even	O
know	O
what	O
the	O
appropriate	O
resolution	O
for	O
the	O
image	B
should	O
be	O
.	O
consider	O
,	O
for	O
example	O
,	O
the	O
task	O
of	O
ﬁnding	O
a	O
face	B
in	O
an	O
image	B
(	O
section	O
14.1.1	O
)	O
.	O
since	O
we	O
do	O
not	O
know	O
the	O
scale	O
at	O
which	O
the	O
face	B
will	O
appear	O
,	O
we	O
need	O
to	O
generate	O
a	O
whole	O
pyramid	B
3.5	O
pyramids	O
and	O
wavelets	O
145	O
of	O
differently	O
sized	O
images	O
and	O
scan	O
each	O
one	O
for	O
possible	O
faces	B
.	O
(	O
biological	O
visual	O
systems	O
also	O
operate	O
on	O
a	O
hierarchy	B
of	O
scales	O
(	O
marr	O
1982	O
)	O
.	O
)	O
such	O
a	O
pyramid	B
can	O
also	O
be	O
very	O
helpful	O
in	O
accelerating	O
the	O
search	O
for	O
an	O
object	O
by	O
ﬁrst	O
ﬁnding	O
a	O
smaller	O
instance	B
of	O
that	O
object	O
at	O
a	O
coarser	O
level	O
of	O
the	O
pyramid	B
and	O
then	O
looking	O
for	O
the	O
full	O
resolution	O
object	O
only	O
in	O
the	O
vicinity	O
of	O
coarse-level	O
detections	O
(	O
section	O
8.1.1	O
)	O
.	O
finally	O
,	O
image	B
pyramids	O
are	O
extremely	O
useful	O
for	O
performing	O
multi-scale	O
editing	O
operations	O
such	O
as	O
blending	B
images	O
while	O
maintaining	O
details	O
.	O
in	O
this	O
section	O
,	O
we	O
ﬁrst	O
discuss	O
good	O
ﬁlters	O
for	O
changing	O
image	B
resolution	O
,	O
i.e.	O
,	O
upsampling	O
(	O
interpolation	B
,	O
section	O
3.5.1	O
)	O
and	O
downsampling	O
(	O
decimation	O
,	O
section	O
3.5.2	O
)	O
.	O
we	O
then	O
present	O
the	O
concept	O
of	O
multi-resolution	O
pyramids	O
,	O
which	O
can	O
be	O
used	O
to	O
create	O
a	O
complete	O
hierarchy	B
of	O
differently	O
sized	O
images	O
and	O
to	O
enable	O
a	O
variety	O
of	O
applications	O
(	O
section	O
3.5.3	O
)	O
.	O
a	O
closely	O
related	O
concept	O
is	O
that	O
of	O
wavelets	O
,	O
which	O
are	O
a	O
special	O
kind	O
of	O
pyramid	B
with	O
higher	O
frequency	O
selectivity	B
and	O
other	O
useful	O
properties	B
(	O
section	O
3.5.4	O
)	O
.	O
finally	O
,	O
we	O
present	O
a	O
useful	O
application	O
of	O
pyramids	O
,	O
namely	O
the	O
blending	B
of	O
different	O
images	O
in	O
a	O
way	O
that	O
hides	O
the	O
seams	O
between	O
the	O
image	B
boundaries	O
(	O
section	O
3.5.5	O
)	O
.	O
3.5.1	O
interpolation	B
in	O
order	B
to	O
interpolate	O
(	O
or	O
upsample	O
)	O
an	O
image	B
to	O
a	O
higher	O
resolution	O
,	O
we	O
need	O
to	O
select	O
some	O
interpolation	B
kernel	O
with	O
which	O
to	O
convolve	O
the	O
image	B
,	O
g	O
(	O
i	O
,	O
j	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
f	O
(	O
k	O
,	O
l	O
)	O
h	O
(	O
i	O
−	O
rk	O
,	O
j	O
−	O
rl	O
)	O
.	O
(	O
3.78	O
)	O
this	O
formula	O
is	O
related	O
to	O
the	O
discrete	B
convolution	O
formula	O
(	O
3.14	O
)	O
,	O
except	O
that	O
we	O
replace	O
k	O
and	O
l	O
in	O
h	O
(	O
)	O
with	O
rk	O
and	O
rl	O
,	O
where	O
r	O
is	O
the	O
upsampling	O
rate	O
.	O
figure	O
3.27a	O
shows	O
how	O
to	O
think	O
of	O
this	O
process	O
as	O
the	O
superposition	B
of	O
sample	O
weighted	B
interpolation	O
kernels	O
,	O
one	O
centered	O
at	O
each	O
input	O
sample	O
k.	O
an	O
alternative	O
mental	O
model	O
is	O
shown	O
in	O
figure	O
3.27b	O
,	O
where	O
the	O
kernel	B
is	O
centered	O
at	O
the	O
output	O
pixel	O
value	O
i	O
(	O
the	O
two	O
forms	O
are	O
equivalent	O
)	O
.	O
the	O
latter	O
form	O
is	O
sometimes	O
called	O
the	O
polyphase	O
ﬁlter	O
form	O
,	O
since	O
the	O
kernel	B
values	O
h	O
(	O
i	O
)	O
can	O
be	O
stored	O
as	O
r	O
separate	O
kernels	O
,	O
each	O
of	O
which	O
is	O
selected	O
for	O
convolution	O
with	O
the	O
input	O
samples	O
depending	O
on	O
the	O
phase	O
of	O
i	O
relative	O
to	O
the	O
upsampled	O
grid	O
.	O
what	O
kinds	O
of	O
kernel	B
make	O
good	O
interpolators	O
?	O
the	O
answer	O
depends	O
on	O
the	O
application	O
and	O
the	O
computation	O
time	O
involved	O
.	O
any	O
of	O
the	O
smoothing	B
kernels	O
shown	O
in	O
tables	O
3.2	O
and	O
3.3	O
can	O
be	O
used	O
after	O
appropriate	O
re-scaling.13	O
the	O
linear	B
interpolator	O
(	O
corresponding	O
to	O
the	O
tent	O
kernel	B
)	O
produces	O
interpolating	O
piecewise	O
linear	B
curves	O
,	O
which	O
result	O
in	O
unappealing	O
creases	O
when	O
applied	O
to	O
images	O
(	O
figure	O
3.28a	O
)	O
.	O
the	O
cubic	B
b-spline	O
,	O
whose	O
discrete	B
1/2-pixel	O
sam-	O
pling	O
appears	O
as	O
the	O
binomial	B
kernel	O
in	O
table	O
3.3	O
,	O
is	O
an	O
approximating	O
kernel	B
(	O
the	O
interpolated	O
13	O
the	O
smoothing	B
kernels	O
in	O
table	O
3.3	O
have	O
a	O
unit	O
area	O
.	O
to	O
turn	O
them	O
into	O
interpolating	O
kernels	O
,	O
we	O
simply	O
scale	O
them	O
up	O
by	O
the	O
interpolation	B
rate	O
r.	O
146	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.27	O
signal	O
interpolation	B
,	O
g	O
(	O
i	O
)	O
=	O
(	O
cid:80	O
)	O
k	O
f	O
(	O
k	O
)	O
h	O
(	O
i	O
−	O
rk	O
)	O
:	O
(	O
a	O
)	O
weighted	B
summation	O
of	O
input	O
values	O
;	O
(	O
b	O
)	O
polyphase	O
ﬁlter	O
interpretation	O
.	O
image	B
does	O
not	O
pass	O
through	O
the	O
input	O
data	O
points	O
)	O
that	O
produces	O
soft	O
images	O
with	O
reduced	O
high-frequency	O
detail	O
.	O
the	O
equation	B
for	O
the	O
cubic	B
b-spline	O
is	O
easiest	O
to	O
derive	O
by	O
convolving	O
the	O
tent	O
function	O
(	O
linear	B
b-spline	O
)	O
with	O
itself	O
.	O
while	O
most	O
graphics	O
cards	O
use	O
the	O
bilinear	B
kernel	O
(	O
optionally	O
combined	O
with	O
a	O
mip-	O
map—see	O
section	O
3.5.3	O
)	O
,	O
most	O
photo	O
editing	O
packages	O
use	O
bicubic	B
interpolation	O
.	O
the	O
cu-	O
bic	O
interpolant	O
is	O
a	O
c	O
1	O
(	O
derivative-continuous	O
)	O
piecewise-cubic	O
spline	B
(	O
the	O
term	O
“	O
spline	B
”	O
is	O
synonymous	O
with	O
“	O
piecewise-polynomial	O
”	O
)	O
14	O
whose	O
equation	B
is	O
1	O
−	O
(	O
a	O
+	O
3	O
)	O
x2	O
+	O
(	O
a	O
+	O
2	O
)	O
|x|3	O
a	O
(	O
|x|	O
−	O
1	O
)	O
(	O
|x|	O
−	O
2	O
)	O
2	O
0	O
if	O
|x|	O
<	O
1	O
if	O
1	O
≤	O
|x|	O
<	O
2	O
otherwise	O
,	O
(	O
3.79	O
)	O
h	O
(	O
x	O
)	O
=	O
where	O
a	O
speciﬁes	O
the	O
derivative	O
at	O
x	O
=	O
1	O
(	O
parker	O
,	O
kenyon	O
,	O
and	O
troxel	O
1983	O
)	O
.	O
the	O
value	O
of	O
a	O
is	O
often	O
set	O
to	O
−1	O
,	O
since	O
this	O
best	O
matches	O
the	O
frequency	O
characteristics	O
of	O
a	O
sinc	B
function	O
(	O
figure	O
3.29	O
)	O
.	O
it	O
also	O
introduces	O
a	O
small	O
amount	O
of	O
sharpening	O
,	O
which	O
can	O
be	O
visually	O
appeal-	O
ing	O
.	O
unfortunately	O
,	O
this	O
choice	O
does	O
not	O
linearly	O
interpolate	O
straight	O
lines	B
(	O
intensity	O
ramps	O
)	O
,	O
so	O
some	O
visible	O
ringing	O
may	O
occur	O
.	O
a	O
better	O
choice	O
for	O
large	O
amounts	O
of	O
interpolation	B
is	O
prob-	O
ably	O
a	O
=	O
−0.5	O
,	O
which	O
produces	O
a	O
quadratic	O
reproducing	O
spline	B
;	O
it	O
interpolates	O
linear	B
and	O
quadratic	O
functions	O
exactly	O
(	O
wolberg	O
1990	O
,	O
section	O
5.4.3	O
)	O
.	O
figure	O
3.29	O
shows	O
the	O
a	O
=	O
−1	O
and	O
a	O
=	O
−0.5	O
cubic	B
interpolating	O
kernel	B
along	O
with	O
their	O
fourier	O
transforms	O
;	O
figure	O
3.28b	O
and	O
c	O
shows	O
them	O
being	O
applied	O
to	O
two-dimensional	B
interpolation	O
.	O
splines	B
have	O
long	O
been	O
used	O
for	O
function	O
and	O
data	O
value	O
interpolation	B
because	O
of	O
the	O
abil-	O
ity	O
to	O
precisely	O
specify	O
derivatives	O
at	O
control	O
points	B
and	O
efﬁcient	O
incremental	B
algorithms	O
for	O
their	O
evaluation	B
(	O
bartels	O
,	O
beatty	O
,	O
and	O
barsky	O
1987	O
;	O
farin	O
1992	O
,	O
1996	O
)	O
.	O
splines	B
are	O
widely	O
used	O
in	O
geometric	B
modeling	O
and	O
computer-aided	O
design	O
(	O
cad	O
)	O
applications	O
,	O
although	O
they	O
have	O
14	O
the	O
term	O
“	O
spline	B
”	O
comes	O
from	O
the	O
draughtsman	O
’	O
s	O
workshop	O
,	O
where	O
it	O
was	O
the	O
name	O
of	O
a	O
ﬂexible	O
piece	O
of	O
wood	O
or	O
metal	O
used	O
to	O
draw	O
smooth	O
curves	O
.	O
f	O
(	O
k-1	O
)	O
f	O
(	O
k+1	O
)	O
f	O
(	O
k	O
)	O
g	O
(	O
i	O
)	O
r·	O
(	O
k-1	O
)	O
r·	O
(	O
k+1	O
)	O
rkif	O
(	O
k	O
)	O
h	O
(	O
i-rk	O
)	O
f	O
(	O
k-1	O
)	O
f	O
(	O
k+1	O
)	O
f	O
(	O
k	O
)	O
g	O
(	O
i	O
)	O
r·	O
(	O
k-1	O
)	O
r·	O
(	O
k+1	O
)	O
rkih	O
(	O
i-rk	O
)	O
3.5	O
pyramids	O
and	O
wavelets	O
147	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
3.28	O
two-dimensional	B
image	O
interpolation	B
:	O
(	O
a	O
)	O
bilinear	B
;	O
(	O
b	O
)	O
bicubic	B
(	O
a	O
=	O
−1	O
)	O
;	O
(	O
c	O
)	O
bicubic	B
(	O
a	O
=	O
−0.5	O
)	O
;	O
(	O
d	O
)	O
windowed	B
sinc	I
(	O
nine	O
taps	O
)	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.29	O
(	O
a	O
)	O
some	O
windowed	B
sinc	I
functions	O
and	O
(	O
b	O
)	O
their	O
log	O
fourier	O
transforms	O
:	O
raised-	O
cosine	O
windowed	B
sinc	I
in	O
blue	O
,	O
cubic	B
interpolators	O
(	O
a	O
=	O
−1	O
and	O
a	O
=	O
−0.5	O
)	O
in	O
green	O
and	O
purple	O
,	O
and	O
tent	O
function	O
in	O
brown	O
.	O
they	O
are	O
often	O
used	O
to	O
perform	O
high-accuracy	O
low-pass	B
ﬁltering	O
operations	O
.	O
-0.50.00.51.0-4-3-2-101234windowed-sinctentcubic	O
a=-0.5cubic	O
a=-1-200-180-160-140-120-100-80-60-40-200-0.50.00.5windowed-sinccubic	O
a=-0.5tentcubic	O
a=-1	O
148	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
started	O
being	O
displaced	O
by	O
subdivision	O
surfaces	O
(	O
zorin	O
,	O
schr¨oder	O
,	O
and	O
sweldens	O
1996	O
;	O
peters	O
and	O
reif	O
2008	O
)	O
.	O
in	O
computer	O
vision	O
,	O
splines	B
are	O
often	O
used	O
for	O
elastic	O
image	B
deformations	O
(	O
section	O
3.6.2	O
)	O
,	O
motion	B
estimation	I
(	O
section	O
8.3	O
)	O
,	O
and	O
surface	B
interpolation	O
(	O
section	O
12.3	O
)	O
.	O
in	O
fact	O
,	O
it	O
is	O
possible	O
to	O
carry	O
out	O
most	O
image	B
processing	O
operations	O
by	O
representing	O
images	O
as	O
splines	B
and	O
manipulating	O
them	O
in	O
a	O
multi-resolution	O
framework	O
(	O
unser	O
1999	O
)	O
.	O
the	O
highest	O
quality	O
interpolator	O
is	O
generally	O
believed	O
to	O
be	O
the	O
windowed	B
sinc	I
function	O
because	O
it	O
both	O
preserves	O
details	O
in	O
the	O
lower	O
resolution	O
image	B
and	O
avoids	O
aliasing	B
.	O
(	O
it	O
is	O
also	O
possible	O
to	O
construct	O
a	O
c	O
1	O
piecewise-cubic	O
approximation	O
to	O
the	O
windowed	B
sinc	I
by	O
matching	B
its	O
derivatives	O
at	O
zero	B
crossing	I
(	O
szeliski	O
and	O
ito	O
1986	O
)	O
.	O
)	O
however	O
,	O
some	O
people	O
object	O
to	O
the	O
excessive	O
ringing	O
that	O
can	O
be	O
introduced	O
by	O
the	O
windowed	B
sinc	I
and	O
to	O
the	O
repetitive	O
nature	O
of	O
the	O
ringing	O
frequencies	O
(	O
see	O
figure	O
3.28d	O
)	O
.	O
for	O
this	O
reason	O
,	O
some	O
photographers	O
prefer	O
to	O
repeatedly	O
interpolate	O
images	O
by	O
a	O
small	O
fractional	O
amount	O
(	O
this	O
tends	O
to	O
de-correlate	O
the	O
original	O
pixel	O
grid	O
with	O
the	O
ﬁnal	O
image	B
)	O
.	O
additional	O
possibilities	O
include	O
using	O
the	O
bilat-	O
eral	O
ﬁlter	O
as	O
an	O
interpolator	O
(	O
kopf	O
,	O
cohen	O
,	O
lischinski	O
et	O
al	O
.	O
2007	O
)	O
,	O
using	O
global	O
optimization	O
(	O
section	O
3.6	O
)	O
or	O
hallucinating	O
details	O
(	O
section	O
10.3	O
)	O
.	O
3.5.2	O
decimation	O
while	O
interpolation	B
can	O
be	O
used	O
to	O
increase	O
the	O
resolution	O
of	O
an	O
image	B
,	O
decimation	O
(	O
downsam-	O
pling	O
)	O
is	O
required	O
to	O
reduce	O
the	O
resolution.15	O
to	O
perform	O
decimation	O
,	O
we	O
ﬁrst	O
(	O
conceptually	O
)	O
convolve	O
the	O
image	B
with	O
a	O
low-pass	B
ﬁlter	O
(	O
to	O
avoid	O
aliasing	B
)	O
and	O
then	O
keep	O
every	O
rth	O
sample	O
.	O
in	O
practice	O
,	O
we	O
usually	O
only	O
evaluate	O
the	O
convolution	O
at	O
every	O
rth	O
sample	O
,	O
g	O
(	O
i	O
,	O
j	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
f	O
(	O
k	O
,	O
l	O
)	O
h	O
(	O
ri	O
−	O
k	O
,	O
rj	O
−	O
l	O
)	O
,	O
(	O
3.80	O
)	O
as	O
shown	O
in	O
figure	O
3.30.	O
note	O
that	O
the	O
smoothing	B
kernel	O
h	O
(	O
k	O
,	O
l	O
)	O
,	O
in	O
this	O
case	O
,	O
is	O
often	O
a	O
stretched	O
and	O
re-scaled	O
version	O
of	O
an	O
interpolation	B
kernel	O
.	O
alternatively	O
,	O
we	O
can	O
write	O
g	O
(	O
i	O
,	O
j	O
)	O
=	O
1	O
r	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
f	O
(	O
k	O
,	O
l	O
)	O
h	O
(	O
i	O
−	O
k/r	O
,	O
j	O
−	O
l/r	O
)	O
(	O
3.81	O
)	O
and	O
keep	O
the	O
same	O
kernel	B
h	O
(	O
k	O
,	O
l	O
)	O
for	O
both	O
interpolation	B
and	O
decimation	O
.	O
one	O
commonly	O
used	O
(	O
r	O
=	O
2	O
)	O
decimation	O
ﬁlter	O
is	O
the	O
binomial	B
ﬁlter	O
introduced	O
by	O
burt	O
and	O
adelson	O
(	O
1983a	O
)	O
.	O
as	O
shown	O
in	O
table	O
3.3	O
,	O
this	O
kernel	B
does	O
a	O
decent	O
job	O
of	O
separating	O
the	O
high	O
and	O
low	O
frequencies	O
,	O
but	O
still	O
leaves	O
a	O
fair	O
amount	O
of	O
high-frequency	O
detail	O
,	O
which	O
can	O
lead	O
to	O
aliasing	B
after	O
downsampling	O
.	O
however	O
,	O
for	O
applications	O
such	O
as	O
image	B
blending	O
(	O
discussed	O
later	O
in	O
this	O
section	O
)	O
,	O
this	O
aliasing	B
is	O
of	O
little	O
concern	O
.	O
15	O
the	O
term	O
“	O
decimation	O
”	O
has	O
a	O
gruesome	O
etymology	O
relating	O
to	O
the	O
practice	O
of	O
killing	O
every	O
tenth	O
soldier	O
in	O
it	O
is	O
generally	O
used	O
in	O
signal	O
processing	O
to	O
mean	O
any	O
downsampling	O
or	O
rate	O
a	O
roman	O
unit	O
guilty	O
of	O
cowardice	O
.	O
reduction	O
operation	O
.	O
3.5	O
pyramids	O
and	O
wavelets	O
149	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.30	O
signal	O
decimation	O
:	O
(	O
a	O
)	O
the	O
original	O
samples	O
are	O
(	O
b	O
)	O
convolved	O
with	O
a	O
low-pass	B
ﬁlter	O
before	O
being	O
downsampled	O
.	O
if	O
,	O
however	O
,	O
the	O
downsampled	O
images	O
will	O
be	O
displayed	O
directly	O
to	O
the	O
user	O
or	O
,	O
perhaps	O
,	O
blended	O
with	O
other	O
resolutions	O
(	O
as	O
in	O
mip-mapping	O
,	O
section	O
3.5.3	O
)	O
,	O
a	O
higher-quality	O
ﬁlter	O
is	O
desired	O
.	O
for	O
high	O
downsampling	O
rates	O
,	O
the	O
windowed	B
sinc	I
pre-ﬁlter	O
is	O
a	O
good	O
choice	O
(	O
fig-	O
ure	O
3.29	O
)	O
.	O
however	O
,	O
for	O
small	O
downsampling	O
rates	O
,	O
e.g.	O
,	O
r	O
=	O
2	O
,	O
more	O
careful	O
ﬁlter	O
design	O
is	O
required	O
.	O
table	O
3.4	O
shows	O
a	O
number	O
of	O
commonly	O
used	O
r	O
=	O
2	O
downsampling	O
ﬁlters	O
,	O
while	O
fig-	O
ure	O
3.31	O
shows	O
their	O
corresponding	O
frequency	O
responses	O
.	O
these	O
ﬁlters	O
include	O
:	O
•	O
the	O
linear	B
[	O
1	O
,	O
2	O
,	O
1	O
]	O
ﬁlter	O
gives	O
a	O
relatively	O
poor	O
response	O
;	O
•	O
the	O
binomial	B
[	O
1	O
,	O
4	O
,	O
6	O
,	O
4	O
,	O
1	O
]	O
ﬁlter	O
cuts	O
off	O
a	O
lot	O
of	O
frequencies	O
but	O
is	O
useful	O
for	O
computer	O
vision	O
analysis	O
pyramids	O
;	O
•	O
the	O
cubic	B
ﬁlters	O
from	O
(	O
3.79	O
)	O
;	O
the	O
a	O
=	O
−1	O
ﬁlter	O
has	O
a	O
sharper	O
fall-off	O
than	O
the	O
a	O
=	O
−0.5	O
ﬁlter	O
(	O
figure	O
3.31	O
)	O
;	O
0.50	O
0.25	O
|n|	O
linear	B
binomial	O
0.3750	O
0	O
0.2500	O
1	O
2	O
0.0625	O
3	O
4	O
cubic	B
a	O
=	O
−1	O
0.5000	O
0.3125	O
0.0000	O
-0.0625	O
cubic	B
a	O
=	O
−0.5	O
0.50000	O
0.28125	O
0.00000	O
-0.03125	O
windowed	B
sinc	I
0.4939	O
0.2684	O
0.0000	O
-0.0153	O
0.0000	O
qmf-9	O
0.5638	O
0.2932	O
-0.0519	O
-0.0431	O
0.0198	O
jpeg	O
2000	O
0.6029	O
0.2669	O
-0.0782	O
-0.0169	O
0.0267	O
table	O
3.4	O
filter	O
coefﬁcients	O
for	O
2×	O
decimation	O
.	O
these	O
ﬁlters	O
are	O
of	O
odd	O
length	O
,	O
are	O
sym-	O
metric	O
,	O
and	O
are	O
normalized	B
to	O
have	O
unit	O
dc	O
gain	O
(	O
sum	O
up	O
to	O
1	O
)	O
.	O
see	O
figure	O
3.31	O
for	O
their	O
associated	O
frequency	O
responses	O
.	O
150	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
3.31	O
frequency	O
response	O
for	O
some	O
2×	O
decimation	O
ﬁlters	O
.	O
the	O
cubic	B
a	O
=	O
−1	O
ﬁlter	O
has	O
the	O
sharpest	O
fall-off	O
but	O
also	O
a	O
bit	O
of	O
ringing	O
;	O
the	O
wavelet	O
analysis	O
ﬁlters	O
(	O
qmf-9	O
and	O
jpeg	O
2000	O
)	O
,	O
while	O
useful	O
for	O
compression	O
,	O
have	O
more	O
aliasing	B
.	O
•	O
a	O
cosine-windowed	O
sinc	B
function	O
(	O
table	O
3.2	O
)	O
;	O
•	O
the	O
qmf-9	O
ﬁlter	O
of	O
simoncelli	O
and	O
adelson	O
(	O
1990b	O
)	O
is	O
used	O
for	O
wavelet	O
denoising	O
and	O
aliases	O
a	O
fair	O
amount	O
(	O
note	O
that	O
the	O
original	O
ﬁlter	O
coefﬁcients	O
are	O
normalized	B
to	O
√2	O
gain	O
so	O
they	O
can	O
be	O
“	O
self-inverting	B
”	O
)	O
;	O
•	O
the	O
9/7	O
analysis	O
ﬁlter	O
from	O
jpeg	O
2000	O
(	O
taubman	O
and	O
marcellin	O
2002	O
)	O
.	O
please	O
see	O
the	O
original	O
papers	O
for	O
the	O
full-precision	O
values	O
of	O
some	O
of	O
these	O
coefﬁcients	O
.	O
3.5.3	O
multi-resolution	O
representations	O
now	O
that	O
we	O
have	O
described	O
interpolation	B
and	O
decimation	O
algorithms	O
,	O
we	O
can	O
build	O
a	O
complete	O
image	B
pyramid	O
(	O
figure	O
3.32	O
)	O
.	O
as	O
we	O
mentioned	O
before	O
,	O
pyramids	O
can	O
be	O
used	O
to	O
accelerate	O
coarse-to-ﬁne	B
search	O
algorithms	O
,	O
to	O
look	O
for	O
objects	O
or	O
patterns	B
at	O
different	O
scales	O
,	O
and	O
to	O
per-	O
form	O
multi-resolution	O
blending	B
operations	O
.	O
they	O
are	O
also	O
widely	O
used	O
in	O
computer	O
graphics	O
hardware	O
and	O
software	O
to	O
perform	O
fractional-level	O
decimation	O
using	O
the	O
mip-map	O
,	O
which	O
we	O
cover	O
in	O
section	O
3.6.	O
the	O
best	O
known	O
(	O
and	O
probably	O
most	O
widely	O
used	O
)	O
pyramid	B
in	O
computer	O
vision	O
is	O
burt	O
and	O
adelson	O
’	O
s	O
(	O
1983a	O
)	O
laplacian	O
pyramid	B
.	O
to	O
construct	O
the	O
pyramid	B
,	O
we	O
ﬁrst	O
blur	O
and	O
sub-	O
sample	O
the	O
original	O
image	B
by	O
a	O
factor	O
of	O
two	O
and	O
store	O
this	O
in	O
the	O
next	O
level	O
of	O
the	O
pyramid	B
(	O
figure	O
3.33	O
)	O
.	O
because	O
adjacent	O
levels	O
in	O
the	O
pyramid	B
are	O
related	O
by	O
a	O
sampling	B
rate	O
r	O
=	O
2	O
,	O
this	O
kind	O
of	O
pyramid	B
is	O
known	O
as	O
an	O
octave	B
pyramid	O
.	O
burt	O
and	O
adelson	O
originally	O
proposed	O
a	O
-0.200.20.40.60.8100.10.20.30.40.5linearbinomialcubic	O
a=-1cubic	O
a=-0.5wind	O
.	O
sincqmf-9jpeg	O
2000	O
3.5	O
pyramids	O
and	O
wavelets	O
151	O
figure	O
3.32	O
a	O
traditional	O
image	B
pyramid	O
:	O
each	O
level	O
has	O
half	O
the	O
resolution	O
(	O
width	O
and	O
height	O
)	O
,	O
and	O
hence	O
a	O
quarter	O
of	O
the	O
pixels	O
,	O
of	O
its	O
parent	O
level	O
.	O
ﬁve-tap	O
kernel	B
of	O
the	O
form	O
(	O
3.82	O
)	O
with	O
b	O
=	O
1/4	O
and	O
c	O
=	O
1/4−	O
a/2	O
.	O
in	O
practice	O
,	O
a	O
=	O
3/8	O
,	O
which	O
results	O
in	O
the	O
familiar	O
binomial	B
kernel	O
,	O
b	O
a	O
b	O
c	O
c	O
,	O
1	O
16	O
1	O
4	O
6	O
4	O
1	O
,	O
(	O
3.83	O
)	O
which	O
is	O
particularly	O
easy	O
to	O
implement	O
using	O
shifts	O
and	O
adds	O
.	O
(	O
this	O
was	O
important	O
in	O
the	O
days	O
when	O
multipliers	O
were	O
expensive	O
.	O
)	O
the	O
reason	O
they	O
call	O
their	O
resulting	O
pyramid	B
a	O
gaussian	O
pyramid	B
is	O
that	O
repeated	O
convolutions	O
of	O
the	O
binomial	B
kernel	O
converge	O
to	O
a	O
gaussian.16	O
to	O
compute	O
the	O
laplacian	O
pyramid	B
,	O
burt	O
and	O
adelson	O
ﬁrst	O
interpolate	O
a	O
lower	O
resolu-	O
tion	B
image	O
to	O
obtain	O
a	O
reconstructed	O
low-pass	B
version	O
of	O
the	O
original	O
image	B
(	O
figure	O
3.34b	O
)	O
.	O
they	O
then	O
subtract	O
this	O
low-pass	B
version	O
from	O
the	O
original	O
to	O
yield	O
the	O
band-pass	B
“	O
laplacian	O
”	O
image	B
,	O
which	O
can	O
be	O
stored	O
away	O
for	O
further	O
processing	O
.	O
the	O
resulting	O
pyramid	B
has	O
perfect	B
reconstruction	I
,	O
i.e.	O
,	O
the	O
laplacian	O
images	O
plus	O
the	O
base-level	O
gaussian	O
(	O
l2	O
in	O
figure	O
3.34b	O
)	O
are	O
sufﬁcient	O
to	O
exactly	O
reconstruct	O
the	O
original	O
image	B
.	O
figure	O
3.33	O
shows	O
the	O
same	O
com-	O
putation	O
in	O
one	O
dimension	O
as	O
a	O
signal	O
processing	O
diagram	O
,	O
which	O
completely	O
captures	O
the	O
computations	O
being	O
performed	O
during	O
the	O
analysis	O
and	O
re-synthesis	O
stages	O
.	O
burt	O
and	O
adelson	O
also	O
describe	O
a	O
variant	O
on	O
the	O
laplacian	O
pyramid	B
,	O
where	O
the	O
low-pass	B
image	O
is	O
taken	O
from	O
the	O
original	O
blurred	O
image	B
rather	O
than	O
the	O
reconstructed	O
pyramid	B
(	O
piping	O
the	O
output	O
of	O
the	O
l	O
box	O
directly	O
to	O
the	O
subtraction	O
in	O
figure	O
3.34b	O
)	O
.	O
this	O
variant	O
has	O
less	O
16	O
then	O
again	O
,	O
this	O
is	O
true	O
for	O
any	O
smoothing	B
kernel	O
(	O
wells	O
1986	O
)	O
.	O
finemediumcoarsel=	O
0l=	O
1l=	O
2	O
152	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.33	O
the	O
gaussian	O
pyramid	B
shown	O
as	O
a	O
signal	O
processing	O
diagram	O
:	O
the	O
(	O
a	O
)	O
analysis	O
and	O
(	O
b	O
)	O
re-synthesis	O
stages	O
are	O
shown	O
as	O
using	O
similar	O
computations	O
.	O
the	O
white	O
circles	O
in-	O
dicate	O
zero	O
values	O
inserted	O
by	O
the	O
↑	O
2	O
upsampling	O
operation	O
.	O
notice	O
how	O
the	O
reconstruction	O
ﬁlter	O
coefﬁcients	O
are	O
twice	O
the	O
analysis	O
coefﬁcients	O
.	O
the	O
computation	O
is	O
shown	O
as	O
ﬂowing	O
down	O
the	O
page	O
,	O
regardless	O
of	O
whether	O
we	O
are	O
going	O
from	O
coarse	O
to	O
ﬁne	O
or	O
vice	O
versa	O
.	O
aliasing	B
,	O
since	O
it	O
avoids	O
one	O
downsampling	O
and	O
upsampling	O
round-trip	O
,	O
but	O
it	O
is	O
not	O
self-	O
inverting	O
,	O
since	O
the	O
laplacian	O
images	O
are	O
no	O
longer	O
adequate	O
to	O
reproduce	O
the	O
original	O
image	B
.	O
as	O
with	O
the	O
gaussian	O
pyramid	B
,	O
the	O
term	O
laplacian	O
is	O
a	O
bit	O
of	O
a	O
misnomer	O
,	O
since	O
their	O
band-pass	B
images	O
are	O
really	O
differences	O
of	O
(	O
approximate	O
)	O
gaussians	O
,	O
or	O
dogs	O
,	O
dog	O
{	O
i	O
;	O
σ1	O
,	O
σ2	O
}	O
=	O
gσ1	O
∗	O
i	O
−	O
gσ2	O
∗	O
i	O
=	O
(	O
gσ1	O
−	O
gσ2	O
)	O
∗	O
i.	O
a	O
laplacian	O
of	O
gaussian	O
(	O
which	O
we	O
saw	O
in	O
(	O
3.26	O
)	O
)	O
is	O
actually	O
its	O
second	O
derivative	O
,	O
log	O
{	O
i	O
;	O
σ	O
}	O
=	O
∇2	O
(	O
gσ	O
∗	O
i	O
)	O
=	O
(	O
∇2gσ	O
)	O
∗	O
i	O
,	O
where	O
∇2	O
=	O
∂2	O
∂x2	O
+	O
∂2	O
∂y2	O
(	O
3.84	O
)	O
(	O
3.85	O
)	O
(	O
3.86	O
)	O
is	O
the	O
laplacian	O
(	O
operator	O
)	O
of	O
a	O
function	O
.	O
figure	O
3.35	O
shows	O
how	O
the	O
differences	O
of	O
gaussian	O
and	O
laplacians	O
of	O
gaussian	O
look	O
in	O
both	O
space	O
and	O
frequency	O
.	O
laplacians	O
of	O
gaussian	O
have	O
elegant	O
mathematical	O
properties	B
,	O
which	O
have	O
been	O
widely	O
studied	O
in	O
the	O
scale-space	O
community	O
(	O
witkin	O
1983	O
;	O
witkin	O
,	O
terzopoulos	O
,	O
and	O
kass	O
1986	O
;	O
lindeberg	O
1990	O
;	O
nielsen	O
,	O
florack	O
,	O
and	O
deriche	O
1997	O
)	O
and	O
can	O
be	O
used	O
for	O
a	O
variety	O
of	O
appli-	O
cations	O
including	O
edge	O
detection	O
(	O
marr	O
and	O
hildreth	O
1980	O
;	O
perona	O
and	O
malik	O
1990b	O
)	O
,	O
stereo	B
matching	I
(	O
witkin	O
,	O
terzopoulos	O
,	O
and	O
kass	O
1987	O
)	O
,	O
and	O
image	B
enhancement	O
(	O
nielsen	O
,	O
florack	O
,	O
and	O
deriche	O
1997	O
)	O
.	O
a	O
less	O
widely	O
used	O
variant	O
is	O
half-octave	B
pyramids	O
,	O
shown	O
in	O
figure	O
3.36a	O
.	O
these	O
were	O
ﬁrst	O
introduced	O
to	O
the	O
vision	O
community	O
by	O
crowley	O
and	O
stern	O
(	O
1984	O
)	O
,	O
who	O
call	O
them	O
dif-	O
ference	O
of	O
low-pass	B
(	O
dolp	O
)	O
transforms	O
.	O
because	O
of	O
the	O
small	O
scale	O
change	O
between	O
adja-	O
¼⅜¼161161¼⅜¼161161½¾½½¾½⅛⅛⅛⅛	O
3.5	O
pyramids	O
and	O
wavelets	O
153	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.34	O
the	O
laplacian	O
pyramid	B
:	O
(	O
a	O
)	O
the	O
conceptual	O
ﬂow	O
of	O
images	O
through	O
processing	O
stages	O
:	O
images	O
are	O
high-pass	O
and	O
low-pass	B
ﬁltered	O
,	O
and	O
the	O
low-pass	B
ﬁltered	O
images	O
are	O
pro-	O
cessed	O
in	O
the	O
next	O
stage	O
of	O
the	O
pyramid	B
.	O
during	O
reconstruction	O
,	O
the	O
interpolated	O
image	B
and	O
the	O
(	O
optionally	O
ﬁltered	O
)	O
high-pass	O
image	B
are	O
added	O
back	O
together	O
.	O
the	O
q	O
box	O
indicates	O
quantiza-	O
tion	B
or	O
some	O
other	O
pyramid	B
processing	O
,	O
e.g.	O
,	O
noise	B
removal	I
by	O
coring	O
(	O
setting	O
small	O
wavelet	O
values	O
to	O
0	O
)	O
.	O
(	O
b	O
)	O
the	O
actual	O
computation	O
of	O
the	O
high-pass	O
ﬁlter	O
involves	O
ﬁrst	O
interpolating	O
the	O
downsampled	O
low-pass	B
image	O
and	O
then	O
subtracting	O
it	O
.	O
this	O
results	O
in	O
perfect	B
reconstruction	I
when	O
q	O
is	O
the	O
identity	O
.	O
the	O
high-pass	O
(	O
or	O
band-pass	B
)	O
images	O
are	O
typically	O
called	O
laplacian	O
images	O
,	O
while	O
the	O
low-pass	B
images	O
are	O
called	O
gaussian	O
images	O
.	O
hl↓2h0hl↓2l1h1l2qfi↑2fi↑2qqh0l1h1l2iol↓2h0l1qi↑2h0l1i↑2–	O
154	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
space	O
:	O
frequency	O
:	O
−	O
−	O
=	O
=	O
low-pass	B
lower-pass	O
figure	O
3.35	O
the	O
difference	B
of	O
two	O
low-pass	O
ﬁlters	O
results	O
in	O
a	O
band-pass	B
ﬁlter	O
.	O
the	O
dashed	O
blue	O
lines	O
show	O
the	O
close	O
ﬁt	O
to	O
a	O
half-octave	B
laplacian	O
of	O
gaussian	O
.	O
cent	O
levels	O
,	O
the	O
authors	O
claim	O
that	O
coarse-to-ﬁne	B
algorithms	O
perform	O
better	O
.	O
in	O
the	O
image-	O
processing	O
community	O
,	O
half-octave	B
pyramids	O
combined	O
with	O
checkerboard	O
sampling	B
grids	O
are	O
known	O
as	O
quincunx	O
sampling	B
(	O
feilner	O
,	O
van	O
de	O
ville	O
,	O
and	O
unser	O
2005	O
)	O
.	O
in	O
detecting	O
multi-	O
scale	O
features	O
(	O
section	O
4.1.1	O
)	O
,	O
it	O
is	O
often	O
common	O
to	O
use	O
half-octave	B
or	O
even	O
quarter-octave	O
pyramids	O
(	O
lowe	O
2004	O
;	O
triggs	O
2004	O
)	O
.	O
however	O
,	O
in	O
this	O
case	O
,	O
the	O
subsampling	O
only	O
occurs	O
at	O
every	O
octave	B
level	O
,	O
i.e.	O
,	O
the	O
image	B
is	O
repeatedly	O
blurred	O
with	O
wider	O
gaussians	O
until	O
a	O
full	O
octave	B
of	O
resolution	O
change	O
has	O
been	O
achieved	O
(	O
figure	O
4.11	O
)	O
.	O
3.5.4	O
wavelets	O
while	O
pyramids	O
are	O
used	O
extensively	O
in	O
computer	O
vision	O
applications	O
,	O
some	O
people	O
use	O
wavelet	O
decompositions	O
as	O
an	O
alternative	O
.	O
wavelets	O
are	O
ﬁlters	O
that	O
localize	O
a	O
signal	O
in	O
both	O
space	O
and	O
frequency	O
(	O
like	O
the	O
gabor	O
ﬁlter	O
in	O
table	O
3.2	O
)	O
and	O
are	O
deﬁned	O
over	O
a	O
hierarchy	B
of	O
scales	O
.	O
wavelets	O
provide	O
a	O
smooth	O
way	O
to	O
decompose	O
a	O
signal	O
into	O
frequency	O
components	O
without	O
blocking	O
and	O
are	O
closely	O
related	O
to	O
pyramids	O
.	O
wavelets	O
were	O
originally	O
developed	O
in	O
the	O
applied	O
math	O
and	O
signal	O
processing	O
communi-	O
ties	O
and	O
were	O
introduced	O
to	O
the	O
computer	O
vision	O
community	O
by	O
mallat	O
(	O
1989	O
)	O
.	O
strang	O
(	O
1989	O
)	O
;	O
simoncelli	O
and	O
adelson	O
(	O
1990b	O
)	O
;	O
rioul	O
and	O
vetterli	O
(	O
1991	O
)	O
;	O
chui	O
(	O
1992	O
)	O
;	O
meyer	O
(	O
1993	O
)	O
all	O
provide	O
nice	O
introductions	O
to	O
the	O
subject	O
along	O
with	O
historical	O
reviews	O
,	O
while	O
chui	O
(	O
1992	O
)	O
pro-	O
vides	O
a	O
more	O
comprehensive	O
review	O
and	O
survey	O
of	O
applications	O
.	O
sweldens	O
(	O
1997	O
)	O
describes	O
the	O
more	O
recent	O
lifting	B
approach	O
to	O
wavelets	O
that	O
we	O
discuss	O
shortly	O
.	O
wavelets	O
are	O
widely	O
used	O
in	O
the	O
computer	O
graphics	O
community	O
to	O
perform	O
multi-resolution	O
geometric	B
processing	O
(	O
stollnitz	O
,	O
derose	O
,	O
and	O
salesin	O
1996	O
)	O
and	O
have	O
also	O
been	O
used	O
in	O
com-	O
puter	O
vision	O
for	O
similar	O
applications	O
(	O
szeliski	O
1990b	O
;	O
pentland	O
1994	O
;	O
gortler	O
and	O
cohen	O
1995	O
;	O
yaou	O
and	O
chang	O
1994	O
;	O
lai	O
and	O
vemuri	O
1997	O
;	O
szeliski	O
2006b	O
)	O
,	O
as	O
well	O
as	O
for	O
multi-scale	O
ori-	O
ented	O
ﬁltering	O
(	O
simoncelli	O
,	O
freeman	O
,	O
adelson	O
et	O
al	O
.	O
1992	O
)	O
and	O
denoising	O
(	O
portilla	O
,	O
strela	O
,	O
3.5	O
pyramids	O
and	O
wavelets	O
155	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.36	O
multiresolution	O
pyramids	O
:	O
(	O
a	O
)	O
pyramid	B
with	O
half-octave	B
(	O
quincunx	O
)	O
sampling	B
(	O
odd	O
levels	O
are	O
colored	O
gray	O
for	O
clarity	O
)	O
.	O
(	O
b	O
)	O
wavelet	O
pyramid—each	O
wavelet	O
level	O
stores	O
3/4	O
of	O
the	O
original	O
pixels	O
(	O
usually	O
the	O
horizontal	O
,	O
vertical	O
,	O
and	O
mixed	O
gradients	O
)	O
,	O
so	O
that	O
the	O
total	B
number	O
of	O
wavelet	O
coefﬁcients	O
and	O
original	O
pixels	O
is	O
the	O
same	O
.	O
wainwright	O
et	O
al	O
.	O
2003	O
)	O
.	O
since	O
both	O
image	B
pyramids	O
and	O
wavelets	O
decompose	O
an	O
image	B
into	O
multi-resolution	O
de-	O
scriptions	O
that	O
are	O
localized	O
in	O
both	O
space	O
and	O
frequency	O
,	O
how	O
do	O
they	O
differ	O
?	O
the	O
usual	O
answer	O
is	O
that	O
traditional	O
pyramids	O
are	O
overcomplete	B
,	O
i.e.	O
,	O
they	O
use	O
more	O
pixels	O
than	O
the	O
orig-	O
inal	O
image	B
to	O
represent	O
the	O
decomposition	O
,	O
whereas	O
wavelets	O
provide	O
a	O
tight	B
frame	I
,	O
i.e.	O
,	O
they	O
keep	O
the	O
size	O
of	O
the	O
decomposition	O
the	O
same	O
as	O
the	O
image	B
(	O
figure	O
3.36b	O
)	O
.	O
however	O
,	O
some	O
wavelet	O
families	O
are	O
,	O
in	O
fact	O
,	O
overcomplete	B
in	O
order	B
to	O
provide	O
better	O
shiftability	O
or	O
steering	O
in	O
orientation	O
(	O
simoncelli	O
,	O
freeman	O
,	O
adelson	O
et	O
al	O
.	O
1992	O
)	O
.	O
a	O
better	O
distinction	O
,	O
therefore	O
,	O
might	O
be	O
that	O
wavelets	O
are	O
more	O
orientation	O
selective	O
than	O
regular	O
band-pass	B
pyramids	O
.	O
how	O
are	O
two-dimensional	B
wavelets	O
constructed	O
?	O
figure	O
3.37a	O
shows	O
a	O
high-level	O
dia-	O
gram	O
of	O
one	O
stage	O
of	O
the	O
(	O
recursive	O
)	O
coarse-to-ﬁne	B
construction	O
(	O
analysis	O
)	O
pipeline	B
alongside	O
the	O
complementary	O
re-construction	O
(	O
synthesis	O
)	O
stage	O
.	O
in	O
this	O
diagram	O
,	O
the	O
high-pass	O
ﬁlter	O
followed	O
by	O
decimation	O
keeps	O
3/4	O
of	O
the	O
original	O
pixels	O
,	O
while	O
1/4	O
of	O
the	O
low-frequency	O
coef-	O
ﬁcients	O
are	O
passed	O
on	O
to	O
the	O
next	O
stage	O
for	O
further	O
analysis	O
.	O
in	O
practice	O
,	O
the	O
ﬁltering	O
is	O
usually	O
broken	O
down	O
into	O
two	O
separable	O
sub-stages	O
,	O
as	O
shown	O
in	O
figure	O
3.37b	O
.	O
the	O
resulting	O
three	O
wavelet	O
images	O
are	O
sometimes	O
called	O
the	O
high–high	O
(	O
hh	O
)	O
,	O
high–low	O
(	O
hl	O
)	O
,	O
and	O
low–high	O
(	O
lh	O
)	O
images	O
.	O
the	O
high–low	O
and	O
low–high	O
images	O
accentuate	O
the	O
horizontal	O
and	O
vertical	O
edges	O
and	O
gradients	O
,	O
while	O
the	O
high–high	O
image	B
contains	O
the	O
less	O
frequently	O
occurring	O
mixed	O
derivatives	O
.	O
how	O
are	O
the	O
high-pass	O
h	O
and	O
low-pass	B
l	O
ﬁlters	O
shown	O
in	O
figure	O
3.37b	O
chosen	O
and	O
how	O
can	O
the	O
corresponding	O
reconstruction	O
ﬁlters	O
i	O
and	O
f	O
be	O
computed	O
?	O
can	O
ﬁlters	O
be	O
designed	O
finemediumcoarsel=	O
0l=	O
1l=	O
2l=	O
3l=	O
4finemediumcoarsel=	O
0l=	O
1l=	O
2	O
156	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.37	O
two-dimensional	B
wavelet	O
decomposition	O
:	O
(	O
a	O
)	O
high-level	O
diagram	O
showing	O
the	O
low-pass	B
and	O
high-pass	O
transforms	O
as	O
single	O
boxes	O
;	O
(	O
b	O
)	O
separable	B
implementation	O
,	O
which	O
in-	O
volves	O
ﬁrst	O
performing	O
the	O
wavelet	O
transform	B
horizontally	O
and	O
then	O
vertically	O
.	O
the	O
i	O
and	O
f	O
boxes	O
are	O
the	O
interpolation	B
and	O
ﬁltering	O
boxes	O
required	O
to	O
re-synthesize	O
the	O
image	B
from	O
its	O
wavelet	O
components	O
.	O
that	O
all	O
have	O
ﬁnite	O
impulse	O
responses	O
?	O
this	O
topic	O
has	O
been	O
the	O
main	O
subject	O
of	O
study	O
in	O
the	O
wavelet	O
community	O
for	O
over	O
two	O
decades	O
.	O
the	O
answer	O
depends	O
largely	O
on	O
the	O
intended	O
ap-	O
plication	O
,	O
e.g.	O
,	O
whether	O
the	O
wavelets	O
are	O
being	O
used	O
for	O
compression	O
,	O
image	B
analysis	O
(	O
feature	B
ﬁnding	O
)	O
,	O
or	O
denoising	O
.	O
simoncelli	O
and	O
adelson	O
(	O
1990b	O
)	O
show	O
(	O
in	O
table	O
4.1	O
)	O
some	O
good	O
odd-	O
length	O
quadrature	O
mirror	O
ﬁlter	O
(	O
qmf	O
)	O
coefﬁcients	O
that	O
seem	O
to	O
work	O
well	O
in	O
practice	O
.	O
since	O
the	O
design	O
of	O
wavelet	O
ﬁlters	O
is	O
such	O
a	O
tricky	O
art	O
,	O
is	O
there	O
perhaps	O
a	O
better	O
way	O
?	O
in-	O
deed	O
,	O
a	O
simpler	O
procedure	O
is	O
to	O
split	O
the	O
signal	O
into	O
its	O
even	O
and	O
odd	O
components	O
and	O
then	O
perform	O
trivially	O
reversible	O
ﬁltering	O
operations	O
on	O
each	O
sequence	O
to	O
produce	O
what	O
are	O
called	O
lifted	O
wavelets	O
(	O
figures	O
3.38	O
and	O
3.39	O
)	O
.	O
sweldens	O
(	O
1996	O
)	O
gives	O
a	O
wonderfully	O
understandable	O
introduction	O
to	O
the	O
lifting	B
scheme	O
for	O
second-generation	O
wavelets	O
,	O
followed	O
by	O
a	O
comprehen-	O
sive	O
review	O
(	O
sweldens	O
1997	O
)	O
.	O
as	O
figure	O
3.38	O
demonstrates	O
,	O
rather	O
than	O
ﬁrst	O
ﬁltering	O
the	O
whole	O
input	O
sequence	O
(	O
image	B
)	O
hl↓2↓2l1qfi↑2↑2lh0hh0hl0lh0hh0hl0l1hh↓2hl1lh0hh0hl0hv↓2vlv↓2vlh↓2hhv↓2vlv↓2vl1lh0hh0hl0qqqfh↑2hfv↑2viv↑2vih↑2hfv↑2viv↑2v	O
3.5	O
pyramids	O
and	O
wavelets	O
157	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.38	O
one-dimensional	O
wavelet	O
transform	B
:	O
(	O
a	O
)	O
usual	O
high-pass	O
+	O
low-pass	B
ﬁlters	O
fol-	O
lowed	O
by	O
odd	O
(	O
↓	O
2o	O
)	O
and	O
even	O
(	O
↓	O
2e	O
)	O
downsampling	O
;	O
(	O
b	O
)	O
lifted	O
version	O
,	O
which	O
ﬁrst	O
selects	O
the	O
odd	O
and	O
even	O
subsequences	O
and	O
then	O
applies	O
a	O
low-pass	B
prediction	O
stage	O
l	O
and	O
a	O
high-pass	O
correction	O
stage	O
c	O
in	O
an	O
easily	O
reversible	O
manner	O
.	O
with	O
high-pass	O
and	O
low-pass	B
ﬁlters	O
and	O
then	O
keeping	O
the	O
odd	O
and	O
even	O
sub-sequences	O
,	O
the	O
lifting	B
scheme	O
ﬁrst	O
splits	O
the	O
sequence	O
into	O
its	O
even	O
and	O
odd	O
sub-components	O
.	O
filtering	O
the	O
even	O
sequence	O
with	O
a	O
low-pass	B
ﬁlter	O
l	O
and	O
subtracting	O
the	O
result	O
from	O
the	O
even	O
sequence	O
is	O
trivially	O
reversible	O
:	O
simply	O
perform	O
the	O
same	O
ﬁltering	O
and	O
then	O
add	O
the	O
result	O
back	O
in	O
.	O
furthermore	O
,	O
this	O
operation	O
can	O
be	O
performed	O
in	O
place	O
,	O
resulting	O
in	O
signiﬁcant	O
space	O
savings	O
.	O
the	O
same	O
applies	O
to	O
ﬁltering	O
the	O
even	O
sequence	O
with	O
the	O
correction	O
ﬁlter	O
c	O
,	O
which	O
is	O
used	O
to	O
ensure	O
that	O
the	O
even	O
sequence	O
is	O
low-pass	B
.	O
a	O
series	O
of	O
such	O
lifting	B
steps	O
can	O
be	O
used	O
to	O
create	O
more	O
complex	O
ﬁlter	O
responses	O
with	O
low	O
computational	O
cost	O
and	O
guaranteed	O
reversibility	O
.	O
this	O
process	O
can	O
perhaps	O
be	O
more	O
easily	O
understood	O
by	O
considering	O
the	O
signal	O
processing	O
diagram	O
in	O
figure	O
3.39.	O
during	O
analysis	O
,	O
the	O
average	O
of	O
the	O
even	O
values	O
is	O
subtracted	O
from	O
the	O
odd	O
value	O
to	O
obtain	O
a	O
high-pass	O
wavelet	O
coefﬁcient	O
.	O
however	O
,	O
the	O
even	O
samples	O
still	O
contain	O
an	O
aliased	O
sample	O
of	O
the	O
low-frequency	O
signal	O
.	O
to	O
compensate	O
for	O
this	O
,	O
a	O
small	O
amount	O
of	O
the	O
high-pass	O
wavelet	O
is	O
added	O
back	O
to	O
the	O
even	O
sequence	O
so	O
that	O
it	O
is	O
properly	O
low-pass	B
ﬁltered	O
.	O
(	O
it	O
is	O
easy	O
to	O
show	O
that	O
the	O
effective	O
low-pass	B
ﬁlter	O
is	O
[	O
−	O
1/8	O
,	O
1/4	O
,	O
3/4	O
,	O
1/4	O
,	O
−	O
1/8	O
]	O
,	O
which	O
is	O
in-	O
hl↓2e↓2ol1qfi↑2e↑2oh0l1h0q↓2o↓2elcl1h0l1h0↑2o↑2elc––	O
158	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.39	O
lifted	O
transform	B
shown	O
as	O
a	O
signal	O
processing	O
diagram	O
:	O
(	O
a	O
)	O
the	O
analysis	O
stage	O
ﬁrst	O
predicts	O
the	O
odd	O
value	O
from	O
its	O
even	O
neighbors	O
,	O
stores	O
the	O
difference	B
wavelet	O
,	O
and	O
then	O
compensates	O
the	O
coarser	O
even	O
value	O
by	O
adding	O
in	O
a	O
fraction	O
of	O
the	O
wavelet	O
.	O
(	O
b	O
)	O
the	O
synthesis	O
stage	O
simply	O
reverses	O
the	O
ﬂow	O
of	O
computation	O
and	O
the	O
signs	O
of	O
some	O
of	O
the	O
ﬁlters	O
and	O
op-	O
erations	O
.	O
the	O
light	O
blue	O
lines	B
show	O
what	O
happens	O
if	O
we	O
use	O
four	O
taps	O
for	O
the	O
prediction	O
and	O
correction	O
instead	O
of	O
just	O
two	O
.	O
deed	O
a	O
low-pass	B
ﬁlter	O
.	O
)	O
during	O
synthesis	O
,	O
the	O
same	O
operations	O
are	O
reversed	O
with	O
a	O
judicious	O
change	O
in	O
sign	O
.	O
of	O
course	O
,	O
we	O
need	O
not	O
restrict	O
ourselves	O
to	O
two-tap	O
ﬁlters	O
.	O
figure	O
3.39	O
shows	O
as	O
light	O
blue	O
arrows	O
additional	O
ﬁlter	O
coefﬁcients	O
that	O
could	O
optionally	O
be	O
added	O
to	O
the	O
lifting	B
scheme	O
without	O
affecting	O
its	O
reversibility	O
.	O
in	O
fact	O
,	O
the	O
low-pass	B
and	O
high-pass	O
ﬁltering	O
operations	O
can	O
be	O
interchanged	O
,	O
e.g.	O
,	O
we	O
could	O
use	O
a	O
ﬁve-tap	O
cubic	B
low-pass	O
ﬁlter	O
on	O
the	O
odd	O
sequence	O
(	O
plus	O
center	O
value	O
)	O
ﬁrst	O
,	O
followed	O
by	O
a	O
four-tap	O
cubic	B
low-pass	O
predictor	O
to	O
estimate	O
the	O
wavelet	O
,	O
although	O
i	O
have	O
not	O
seen	O
this	O
scheme	O
written	O
down	O
.	O
lifted	O
wavelets	O
are	O
called	O
second-generation	O
wavelets	O
because	O
they	O
can	O
easily	O
adapt	O
to	O
non-regular	O
sampling	B
topologies	O
,	O
e.g.	O
,	O
those	O
that	O
arise	O
in	O
computer	O
graphics	O
applications	O
such	O
as	O
multi-resolution	O
surface	B
manipulation	O
(	O
schr¨oder	O
and	O
sweldens	O
1995	O
)	O
.	O
it	O
also	O
turns	O
out	O
that	O
lifted	O
weighted	B
wavelets	O
,	O
i.e.	O
,	O
wavelets	O
whose	O
coefﬁcients	O
adapt	O
to	O
the	O
underlying	O
problem	O
being	O
solved	O
(	O
fattal	O
2009	O
)	O
,	O
can	O
be	O
extremely	O
effective	O
for	O
low-level	O
image	B
manipulation	O
tasks	O
and	O
also	O
for	O
preconditioning	O
the	O
kinds	O
of	O
sparse	B
linear	O
systems	O
that	O
arise	O
in	O
the	O
optimization-	O
based	O
approaches	O
to	O
vision	O
algorithms	O
that	O
we	O
discuss	O
in	O
section	O
3.7	O
(	O
szeliski	O
2006b	O
)	O
.	O
an	O
alternative	O
to	O
the	O
widely	O
used	O
“	O
separable	B
”	O
approach	O
to	O
wavelet	O
construction	O
,	O
which	O
de-	O
composes	O
each	O
level	O
into	O
horizontal	O
,	O
vertical	O
,	O
and	O
“	O
cross	O
”	O
sub-bands	O
,	O
is	O
to	O
use	O
a	O
representation	O
that	O
is	O
more	O
rotationally	O
symmetric	O
and	O
orientationally	O
selective	O
and	O
also	O
avoids	O
the	O
aliasing	B
inherent	O
in	O
sampling	B
signals	O
below	O
their	O
nyquist	O
frequency.17	O
simoncelli	O
,	O
freeman	O
,	O
adelson	O
et	O
al	O
.	O
(	O
1992	O
)	O
introduce	O
such	O
a	O
representation	O
,	O
which	O
they	O
call	O
a	O
pyramidal	O
radial	O
frequency	O
17	O
such	O
aliasing	B
can	O
often	O
be	O
seen	O
as	O
the	O
signal	O
content	O
moving	O
between	O
bands	O
as	O
the	O
original	O
signal	O
is	O
slowly	O
shifted	O
.	O
-½-½-½-½¼¼¼¼l0h0l1h1l2½½-¼-¼-¼-¼l0h0l1h1l2½½	O
3.5	O
pyramids	O
and	O
wavelets	O
159	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.40	O
steerable	B
shiftable	O
multiscale	O
transforms	O
(	O
simoncelli	O
,	O
freeman	O
,	O
adelson	O
et	O
al	O
.	O
1992	O
)	O
c	O
(	O
cid:13	O
)	O
1992	O
ieee	O
:	O
(	O
a	O
)	O
radial	B
multi-scale	O
frequency	O
domain	O
decomposition	O
;	O
(	O
b	O
)	O
original	O
image	B
;	O
(	O
c	O
)	O
a	O
set	O
of	O
four	O
steerable	B
ﬁlters	O
;	O
(	O
d	O
)	O
the	O
radial	B
multi-scale	O
wavelet	O
decomposition	O
.	O
implementation	O
of	O
shiftable	O
multi-scale	O
transforms	O
or	O
,	O
more	O
succinctly	O
,	O
steerable	B
pyramids	O
.	O
their	O
representation	O
is	O
not	O
only	O
overcomplete	B
(	O
which	O
eliminates	O
the	O
aliasing	B
problem	O
)	O
but	O
is	O
also	O
orientationally	O
selective	O
and	O
has	O
identical	O
analysis	O
and	O
synthesis	O
basis	O
functions	O
,	O
i.e.	O
,	O
it	O
is	O
self-inverting	B
,	O
just	O
like	O
“	O
regular	O
”	O
wavelets	O
.	O
as	O
a	O
result	O
,	O
this	O
makes	O
steerable	B
pyramids	O
a	O
much	O
more	O
useful	O
basis	O
for	O
the	O
structural	O
analysis	O
and	O
matching	B
tasks	O
commonly	O
used	O
in	O
computer	O
vision	O
.	O
figure	O
3.40a	O
shows	O
how	O
such	O
a	O
decomposition	O
looks	O
in	O
frequency	O
space	O
.	O
instead	O
of	O
re-	O
cursively	O
dividing	O
the	O
frequency	O
domain	O
into	O
2	O
×	O
2	O
squares	O
,	O
which	O
results	O
in	O
checkerboard	O
high	O
frequencies	O
,	O
radial	B
arcs	O
are	O
used	O
instead	O
.	O
figure	O
3.40b	O
illustrates	O
the	O
resulting	O
pyramid	B
sub-bands	O
.	O
even	O
through	O
the	O
representation	O
is	O
overcomplete	B
,	O
i.e.	O
,	O
there	O
are	O
more	O
wavelet	O
co-	O
efﬁcients	O
than	O
input	O
pixels	O
,	O
the	O
additional	O
frequency	O
and	O
orientation	O
selectivity	B
makes	O
this	O
representation	O
preferable	O
for	O
tasks	O
such	O
as	O
texture	B
analysis	O
and	O
synthesis	O
(	O
portilla	O
and	O
simon-	O
celli	O
2000	O
)	O
and	O
image	B
denoising	O
(	O
portilla	O
,	O
strela	O
,	O
wainwright	O
et	O
al	O
.	O
2003	O
;	O
lyu	O
and	O
simoncelli	O
2009	O
)	O
.	O
160	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
3.41	O
laplacian	O
pyramid	B
blending	O
(	O
burt	O
and	O
adelson	O
1983b	O
)	O
c	O
(	O
cid:13	O
)	O
1983	O
acm	O
:	O
(	O
a	O
)	O
orig-	O
inal	O
image	B
of	O
apple	O
,	O
(	O
b	O
)	O
original	O
image	B
of	O
orange	O
,	O
(	O
c	O
)	O
regular	O
splice	O
,	O
(	O
d	O
)	O
pyramid	B
blend	O
.	O
3.5.5	O
application	O
:	O
image	B
blending	O
one	O
of	O
the	O
most	O
engaging	O
and	O
fun	O
applications	O
of	O
the	O
laplacian	O
pyramid	B
presented	O
in	O
sec-	O
tion	B
3.5.3	O
is	O
the	O
creation	O
of	O
blended	O
composite	O
images	O
,	O
as	O
shown	O
in	O
figure	O
3.41	O
(	O
burt	O
and	O
adelson	O
1983b	O
)	O
.	O
while	O
splicing	O
the	O
apple	O
and	O
orange	O
images	O
together	O
along	O
the	O
midline	O
produces	O
a	O
noticeable	O
cut	O
,	O
splining	O
them	O
together	O
(	O
as	O
burt	O
and	O
adelson	O
(	O
1983b	O
)	O
called	O
their	O
procedure	O
)	O
creates	O
a	O
beautiful	O
illusion	O
of	O
a	O
truly	O
hybrid	O
fruit	O
.	O
the	O
key	O
to	O
their	O
approach	O
is	O
that	O
the	O
low-frequency	O
color	B
variations	O
between	O
the	O
red	O
apple	O
and	O
the	O
orange	O
are	O
smoothly	O
blended	O
,	O
while	O
the	O
higher-frequency	O
textures	O
on	O
each	O
fruit	O
are	O
blended	O
more	O
quickly	O
to	O
avoid	O
“	O
ghosting	O
”	O
effects	O
when	O
two	O
textures	O
are	O
overlaid	O
.	O
to	O
create	O
the	O
blended	O
image	B
,	O
each	O
source	O
image	B
is	O
ﬁrst	O
decomposed	O
into	O
its	O
own	O
lapla-	O
cian	O
pyramid	B
(	O
figure	O
3.42	O
,	O
left	O
and	O
middle	O
columns	O
)	O
.	O
each	O
band	O
is	O
then	O
multiplied	O
by	O
a	O
smooth	O
weighting	B
function	O
whose	O
extent	O
is	O
proportional	O
to	O
the	O
pyramid	B
level	O
.	O
the	O
simplest	O
and	O
most	O
general	O
way	O
to	O
create	O
these	O
weights	O
is	O
to	O
take	O
a	O
binary	O
mask	O
image	B
(	O
figure	O
3.43c	O
)	O
and	O
to	O
construct	O
a	O
gaussian	O
pyramid	B
from	O
this	O
mask	B
.	O
each	O
laplacian	O
pyramid	B
image	O
is	O
then	O
3.5	O
pyramids	O
and	O
wavelets	O
161	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
g	O
)	O
(	O
j	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
h	O
)	O
(	O
k	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
(	O
i	O
)	O
(	O
l	O
)	O
figure	O
3.42	O
laplacian	O
pyramid	B
blending	O
details	O
(	O
burt	O
and	O
adelson	O
1983b	O
)	O
c	O
(	O
cid:13	O
)	O
1983	O
acm	O
.	O
the	O
ﬁrst	O
three	O
rows	O
show	O
the	O
high	O
,	O
medium	O
,	O
and	O
low	O
frequency	O
parts	O
of	O
the	O
laplacian	O
pyramid	B
(	O
taken	O
from	O
levels	O
0	O
,	O
2	O
,	O
and	O
4	O
)	O
.	O
the	O
left	O
and	O
middle	O
columns	O
show	O
the	O
original	O
apple	O
and	O
orange	O
images	O
weighted	B
by	O
the	O
smooth	O
interpolation	B
functions	O
,	O
while	O
the	O
right	O
column	O
shows	O
the	O
averaged	O
contributions	O
.	O
162	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
3.43	O
laplacian	O
pyramid	B
blend	O
of	O
two	O
images	O
of	O
arbitrary	O
shape	O
(	O
burt	O
and	O
adelson	O
1983b	O
)	O
c	O
(	O
cid:13	O
)	O
1983	O
acm	O
:	O
(	O
a	O
)	O
ﬁrst	O
input	O
image	B
;	O
(	O
b	O
)	O
second	O
input	O
image	B
;	O
(	O
c	O
)	O
region	B
mask	O
;	O
(	O
d	O
)	O
blended	O
image	B
.	O
multiplied	O
by	O
its	O
corresponding	O
gaussian	O
mask	B
and	O
the	O
sum	O
of	O
these	O
two	O
weighted	O
pyramids	O
is	O
then	O
used	O
to	O
construct	O
the	O
ﬁnal	O
image	B
(	O
figure	O
3.42	O
,	O
right	O
column	O
)	O
.	O
figure	O
3.43	O
shows	O
that	O
this	O
process	O
can	O
be	O
applied	O
to	O
arbitrary	O
mask	B
images	O
with	O
sur-	O
prising	O
results	O
.	O
it	O
is	O
also	O
straightforward	O
to	O
extend	O
the	O
pyramid	B
blend	O
to	O
an	O
arbitrary	O
number	O
of	O
images	O
whose	O
pixel	O
provenance	O
is	O
indicated	O
by	O
an	O
integer-valued	O
label	O
image	B
(	O
see	O
exer-	O
cise	O
3.20	O
)	O
.	O
this	O
is	O
particularly	O
useful	O
in	O
image	B
stitching	I
and	O
compositing	B
applications	O
,	O
where	O
the	O
exposures	O
may	O
vary	O
between	O
different	O
images	O
,	O
as	O
described	O
in	O
section	O
9.3.4	O
.	O
3.6	O
geometric	B
transformations	O
in	O
the	O
previous	O
sections	O
,	O
we	O
saw	O
how	O
interpolation	B
and	O
decimation	O
could	O
be	O
used	O
to	O
change	O
the	O
resolution	O
of	O
an	O
image	B
.	O
in	O
this	O
section	O
,	O
we	O
look	O
at	O
how	O
to	O
perform	O
more	O
general	O
transfor-	O
mations	O
,	O
such	O
as	O
image	B
rotations	O
or	O
general	O
warps	O
.	O
in	O
contrast	O
to	O
the	O
point	O
processes	O
we	O
saw	O
in	O
section	O
3.1	O
,	O
where	O
the	O
function	O
applied	O
to	O
an	O
image	B
transforms	O
the	O
range	O
of	O
the	O
image	B
,	O
g	O
(	O
x	O
)	O
=	O
h	O
(	O
f	O
(	O
x	O
)	O
)	O
,	O
(	O
3.87	O
)	O
3.6	O
geometric	B
transformations	O
163	O
figure	O
3.44	O
image	B
warping	O
involves	O
modifying	O
the	O
domain	O
of	O
an	O
image	B
function	O
rather	O
than	O
its	O
range	O
.	O
figure	O
3.45	O
basic	O
set	O
of	O
2d	O
geometric	B
image	O
transformations	O
.	O
here	O
we	O
look	O
at	O
functions	O
that	O
transform	B
the	O
domain	O
,	O
g	O
(	O
x	O
)	O
=	O
f	O
(	O
h	O
(	O
x	O
)	O
)	O
(	O
3.88	O
)	O
(	O
see	O
figure	O
3.44	O
)	O
.	O
we	O
begin	O
by	O
studying	O
the	O
global	B
parametric	O
2d	O
transformation	O
ﬁrst	O
introduced	O
in	O
sec-	O
tion	B
2.1.2	O
.	O
(	O
such	O
a	O
transformation	O
is	O
called	O
parametric	B
because	O
it	O
is	O
controlled	O
by	O
a	O
small	O
number	O
of	O
parameters	B
.	O
)	O
we	O
then	O
turn	O
our	O
attention	O
to	O
more	O
local	B
general	O
deformations	O
such	O
as	O
those	O
deﬁned	O
on	O
meshes	O
(	O
section	O
3.6.2	O
)	O
.	O
finally	O
,	O
we	O
show	O
how	O
image	B
warps	O
can	O
be	O
combined	O
with	O
cross-dissolves	O
to	O
create	O
interesting	O
morphs	O
(	O
in-between	O
animations	O
)	O
in	O
section	O
3.6.3.	O
for	O
readers	O
interested	O
in	O
more	O
details	O
on	O
these	O
topics	O
,	O
there	O
is	O
an	O
excellent	O
survey	O
by	O
heck-	O
bert	O
(	O
1986	O
)	O
as	O
well	O
as	O
very	O
accessible	O
textbooks	B
by	O
wolberg	O
(	O
1990	O
)	O
,	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
(	O
1999	O
)	O
and	O
akenine-m¨oller	O
and	O
haines	O
(	O
2002	O
)	O
.	O
note	O
that	O
heckbert	O
’	O
s	O
survey	O
is	O
on	O
tex-	O
ture	O
mapping	O
,	O
which	O
is	O
how	O
the	O
computer	O
graphics	O
community	O
refers	O
to	O
the	O
topic	O
of	O
warping	O
images	O
onto	O
surfaces	O
.	O
3.6.1	O
parametric	B
transformations	O
parametric	B
transformations	O
apply	O
a	O
global	B
deformation	O
to	O
an	O
image	B
,	O
where	O
the	O
behavior	O
of	O
the	O
transformation	O
is	O
controlled	O
by	O
a	O
small	O
number	O
of	O
parameters	B
.	O
figure	O
3.45	O
shows	O
a	O
few	O
ex-	O
fxhffghghhgxfxgxyxsimilarityeuclideanaffineprojectivetranslation	O
164	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
transformation	O
matrix	O
#	O
dof	O
preserves	O
icon	O
translation	B
rigid	O
(	O
euclidean	O
)	O
similarity	B
afﬁne	O
projective	B
(	O
cid:104	O
)	O
i	O
t	O
(	O
cid:105	O
)	O
2×3	O
(	O
cid:104	O
)	O
r	O
t	O
(	O
cid:105	O
)	O
2×3	O
(	O
cid:104	O
)	O
sr	O
t	O
(	O
cid:105	O
)	O
2×3	O
(	O
cid:104	O
)	O
a	O
(	O
cid:105	O
)	O
2×3	O
(	O
cid:104	O
)	O
˜h	O
(	O
cid:105	O
)	O
3×3	O
2	O
3	O
4	O
6	O
8	O
orientation	O
lengths	O
angles	O
	O
ss	O
ss	O
	O
	O
s	O
s	O
	O
	O
	O
straight	O
lines	B
``	O
parallelism	O
table	O
3.5	O
hierarchy	B
of	O
2d	O
coordinate	B
transformations	I
.	O
each	O
transformation	O
also	O
preserves	O
the	O
properties	B
listed	O
in	O
the	O
rows	O
below	O
it	O
,	O
i.e.	O
,	O
similarity	B
preserves	O
not	O
only	O
angles	O
but	O
also	O
parallelism	O
and	O
straight	O
lines	B
.	O
the	O
2×3	O
matrices	O
are	O
extended	O
with	O
a	O
third	O
[	O
0t	O
1	O
]	O
row	O
to	O
form	O
a	O
full	O
3	O
×	O
3	O
matrix	O
for	O
homogeneous	O
coordinate	O
transformations	O
.	O
amples	O
of	O
such	O
transformations	O
,	O
which	O
are	O
based	O
on	O
the	O
2d	O
geometric	B
transformations	O
shown	O
in	O
figure	O
2.4.	O
the	O
formulas	O
for	O
these	O
transformations	O
were	O
originally	O
given	O
in	O
table	O
2.1	O
and	O
are	O
reproduced	O
here	O
in	O
table	O
3.5	O
for	O
ease	O
of	O
reference	O
.	O
in	O
general	O
,	O
given	O
a	O
transformation	O
speciﬁed	O
by	O
a	O
formula	O
x	O
(	O
cid:48	O
)	O
=	O
h	O
(	O
x	O
)	O
and	O
a	O
source	O
image	B
f	O
(	O
x	O
)	O
,	O
how	O
do	O
we	O
compute	O
the	O
values	O
of	O
the	O
pixels	O
in	O
the	O
new	O
image	B
g	O
(	O
x	O
)	O
,	O
as	O
given	O
in	O
(	O
3.88	O
)	O
?	O
think	O
about	O
this	O
for	O
a	O
minute	O
before	O
proceeding	O
and	O
see	O
if	O
you	O
can	O
ﬁgure	O
it	O
out	O
.	O
if	O
you	O
are	O
like	O
most	O
people	O
,	O
you	O
will	O
come	O
up	O
with	O
an	O
algorithm	B
that	O
looks	O
something	O
like	O
algorithm	B
3.1.	O
this	O
process	O
is	O
called	O
forward	B
warping	I
or	O
forward	B
mapping	O
and	O
is	O
shown	O
in	O
figure	O
3.46a	O
.	O
can	O
you	O
think	O
of	O
any	O
problems	O
with	O
this	O
approach	O
?	O
procedure	O
forwardwarp	O
(	O
f	O
,	O
h	O
,	O
out	O
g	O
)	O
:	O
for	O
every	O
pixel	O
x	O
in	O
f	O
(	O
x	O
)	O
1.	O
compute	O
the	O
destination	O
location	O
x	O
(	O
cid:48	O
)	O
=	O
h	O
(	O
x	O
)	O
.	O
2.	O
copy	O
the	O
pixel	O
f	O
(	O
x	O
)	O
to	O
g	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
.	O
algorithm	B
3.1	O
forward	B
warping	I
algorithm	O
for	O
transforming	O
an	O
image	B
f	O
(	O
x	O
)	O
into	O
an	O
image	B
g	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
through	O
the	O
parametric	B
transform	O
x	O
(	O
cid:48	O
)	O
=	O
h	O
(	O
x	O
)	O
.	O
3.6	O
geometric	B
transformations	O
165	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.46	O
forward	B
warping	I
algorithm	O
:	O
(	O
a	O
)	O
a	O
pixel	O
f	O
(	O
x	O
)	O
is	O
copied	O
to	O
its	O
corresponding	O
location	O
x	O
(	O
cid:48	O
)	O
=	O
h	O
(	O
x	O
)	O
in	O
image	B
g	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
;	O
(	O
b	O
)	O
detail	O
of	O
the	O
source	O
and	O
destination	O
pixel	O
locations	O
.	O
in	O
fact	O
,	O
this	O
approach	O
suffers	O
from	O
several	O
limitations	O
.	O
the	O
process	O
of	O
copying	O
a	O
pixel	O
f	O
(	O
x	O
)	O
to	O
a	O
location	O
x	O
(	O
cid:48	O
)	O
in	O
g	O
is	O
not	O
well	O
deﬁned	O
when	O
x	O
(	O
cid:48	O
)	O
has	O
a	O
non-integer	O
value	O
.	O
what	O
do	O
we	O
do	O
in	O
such	O
a	O
case	O
?	O
what	O
would	O
you	O
do	O
?	O
you	O
can	O
round	O
the	O
value	O
of	O
x	O
(	O
cid:48	O
)	O
to	O
the	O
nearest	O
integer	O
coordinate	O
and	O
copy	O
the	O
pixel	O
there	O
,	O
but	O
the	O
resulting	O
image	B
has	O
severe	O
aliasing	B
and	O
pixels	O
that	O
jump	O
around	O
a	O
lot	O
when	O
animating	O
the	O
transformation	O
.	O
you	O
can	O
also	O
“	O
distribute	O
”	O
the	O
value	O
among	O
its	O
four	O
nearest	O
neighbors	O
in	O
a	O
weighted	B
(	O
bilinear	B
)	O
fashion	O
,	O
keeping	O
track	O
of	O
the	O
per-pixel	O
weights	O
and	O
normalizing	B
at	O
the	O
end	O
.	O
this	O
technique	O
is	O
called	O
splatting	O
and	O
is	O
sometimes	O
used	O
for	O
volume	O
rendering	B
in	O
the	O
graphics	O
community	O
(	O
levoy	O
and	O
whitted	O
1985	O
;	O
levoy	O
1988	O
;	O
westover	O
1989	O
;	O
rusinkiewicz	O
and	O
levoy	O
2000	O
)	O
.	O
unfortunately	O
,	O
it	O
suffers	O
from	O
both	O
moderate	O
amounts	O
of	O
aliasing	B
and	O
a	O
fair	O
amount	O
of	O
blur	O
(	O
loss	O
of	O
high-resolution	O
detail	O
)	O
.	O
the	O
second	O
major	O
problem	O
with	O
forward	O
warping	O
is	O
the	O
appearance	O
of	O
cracks	O
and	O
holes	O
,	O
especially	O
when	O
magnifying	O
an	O
image	B
.	O
filling	O
such	O
holes	O
with	O
their	O
nearby	O
neighbors	O
can	O
lead	O
to	O
further	O
aliasing	B
and	O
blurring	O
.	O
what	O
can	O
we	O
do	O
instead	O
?	O
a	O
preferable	O
solution	O
is	O
to	O
use	O
inverse	B
warping	I
(	O
algorithm	B
3.2	O
)	O
,	O
where	O
each	O
pixel	O
in	O
the	O
destination	O
image	B
g	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
is	O
sampled	O
from	O
the	O
original	O
image	B
f	O
(	O
x	O
)	O
(	O
figure	O
3.47	O
)	O
.	O
how	O
does	O
this	O
differ	O
from	O
the	O
forward	B
warping	I
algorithm	O
?	O
for	O
one	O
thing	O
,	O
since	O
ˆh	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
is	O
(	O
presumably	O
)	O
deﬁned	O
for	O
all	O
pixels	O
in	O
g	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
,	O
we	O
no	O
longer	O
have	O
holes	O
.	O
more	O
importantly	O
,	O
resampling	O
an	O
image	B
at	O
non-integer	O
locations	O
is	O
a	O
well-studied	O
problem	O
(	O
general	O
image	B
inter-	O
polation	O
,	O
see	O
section	O
3.5.2	O
)	O
and	O
high-quality	O
ﬁlters	O
that	O
control	O
aliasing	B
can	O
be	O
used	O
.	O
where	O
does	O
the	O
function	O
ˆh	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
come	O
from	O
?	O
quite	O
often	O
,	O
it	O
can	O
simply	O
be	O
computed	O
as	O
the	O
inverse	B
of	O
h	O
(	O
x	O
)	O
.	O
in	O
fact	O
,	O
all	O
of	O
the	O
parametric	B
transforms	O
listed	O
in	O
table	O
3.5	O
have	O
closed	O
form	O
solutions	O
for	O
the	O
inverse	B
transform	O
:	O
simply	O
take	O
the	O
inverse	B
of	O
the	O
3	O
×	O
3	O
matrix	O
specifying	O
the	O
transform	B
.	O
in	O
other	O
cases	O
,	O
it	O
is	O
preferable	O
to	O
formulate	O
the	O
problem	O
of	O
image	B
warping	O
as	O
that	O
of	O
re-	O
sampling	B
a	O
source	O
image	B
f	O
(	O
x	O
)	O
given	O
a	O
mapping	O
x	O
=	O
ˆh	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
from	O
destination	O
pixels	O
x	O
(	O
cid:48	O
)	O
to	O
source	O
pixels	O
x.	O
for	O
example	O
,	O
in	O
optical	B
ﬂow	I
(	O
section	O
8.4	O
)	O
,	O
we	O
estimate	O
the	O
ﬂow	O
ﬁeld	O
as	O
the	O
f	O
(	O
x	O
)	O
g	O
(	O
x	O
’	O
)	O
xx	O
’	O
x	O
’	O
=h	O
(	O
x	O
)	O
f	O
(	O
x	O
)	O
g	O
(	O
x	O
’	O
)	O
xx	O
’	O
x	O
’	O
=h	O
(	O
x	O
)	O
166	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
procedure	O
inversewarp	O
(	O
f	O
,	O
h	O
,	O
out	O
g	O
)	O
:	O
for	O
every	O
pixel	O
x	O
(	O
cid:48	O
)	O
in	O
g	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
1.	O
compute	O
the	O
source	O
location	O
x	O
=	O
ˆh	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
2.	O
resample	O
f	O
(	O
x	O
)	O
at	O
location	O
x	O
and	O
copy	O
to	O
g	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
algorithm	B
3.2	O
inverse	B
warping	I
algorithm	O
for	O
creating	O
an	O
image	B
g	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
from	O
an	O
image	B
f	O
(	O
x	O
)	O
using	O
the	O
parametric	B
transform	O
x	O
(	O
cid:48	O
)	O
=	O
h	O
(	O
x	O
)	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.47	O
inverse	B
warping	I
algorithm	O
:	O
(	O
a	O
)	O
a	O
pixel	O
g	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
is	O
sampled	O
from	O
its	O
corresponding	O
location	O
x	O
=	O
ˆh	O
(	O
x	O
(	O
cid:48	O
)	O
)	O
in	O
image	B
f	O
(	O
x	O
)	O
;	O
(	O
b	O
)	O
detail	O
of	O
the	O
source	O
and	O
destination	O
pixel	O
locations	O
.	O
location	O
of	O
the	O
source	O
pixel	O
which	O
produced	O
the	O
current	O
pixel	O
whose	O
ﬂow	O
is	O
being	O
estimated	O
,	O
as	O
opposed	O
to	O
computing	O
the	O
destination	O
pixel	O
to	O
which	O
it	O
is	O
going	O
.	O
similarly	O
,	O
when	O
correcting	O
for	O
radial	O
distortion	O
(	O
section	O
2.1.6	O
)	O
,	O
we	O
calibrate	O
the	O
lens	O
by	O
computing	O
for	O
each	O
pixel	O
in	O
the	O
ﬁnal	O
(	O
undistorted	O
)	O
image	B
the	O
corresponding	O
pixel	O
location	O
in	O
the	O
original	O
(	O
distorted	O
)	O
image	B
.	O
what	O
kinds	O
of	O
interpolation	B
ﬁlter	O
are	O
suitable	O
for	O
the	O
resampling	O
process	O
?	O
any	O
of	O
the	O
ﬁl-	O
ters	O
we	O
studied	O
in	O
section	O
3.5.2	O
can	O
be	O
used	O
,	O
including	O
nearest	B
neighbor	I
,	O
bilinear	B
,	O
bicubic	B
,	O
and	O
windowed	B
sinc	I
functions	O
.	O
while	O
bilinear	B
is	O
often	O
used	O
for	O
speed	O
(	O
e.g.	O
,	O
inside	O
the	O
inner	O
loop	O
of	O
a	O
patch-tracking	O
algorithm	B
,	O
see	O
section	O
8.1.3	O
)	O
,	O
bicubic	B
,	O
and	O
windowed	B
sinc	I
are	O
preferable	O
where	O
visual	O
quality	O
is	O
important	O
.	O
to	O
compute	O
the	O
value	O
of	O
f	O
(	O
x	O
)	O
at	O
a	O
non-integer	O
location	O
x	O
,	O
we	O
simply	O
apply	O
our	O
usual	O
fir	O
resampling	O
ﬁlter	O
,	O
g	O
(	O
x	O
,	O
y	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
,	O
l	O
f	O
(	O
k	O
,	O
l	O
)	O
h	O
(	O
x	O
−	O
k	O
,	O
y	O
−	O
l	O
)	O
,	O
(	O
3.89	O
)	O
where	O
(	O
x	O
,	O
y	O
)	O
are	O
the	O
sub-pixel	O
coordinate	O
values	O
and	O
h	O
(	O
x	O
,	O
y	O
)	O
is	O
some	O
interpolating	O
or	O
smooth-	O
ing	O
kernel	B
.	O
recall	B
from	O
section	O
3.5.2	O
that	O
when	O
decimation	O
is	O
being	O
performed	O
,	O
the	O
smoothing	B
kernel	O
is	O
stretched	O
and	O
re-scaled	O
according	O
to	O
the	O
downsampling	O
rate	O
r.	O
unfortunately	O
,	O
for	O
a	O
general	O
(	O
non-zoom	O
)	O
image	B
transformation	O
,	O
the	O
resampling	O
rate	O
r	O
is	O
not	O
well	O
deﬁned	O
.	O
consider	O
a	O
transformation	O
that	O
stretches	O
the	O
x	O
dimensions	O
while	O
squashing	O
f	O
(	O
x	O
)	O
g	O
(	O
x	O
’	O
)	O
xx	O
’	O
x=h	O
(	O
x	O
’	O
)	O
^	O
f	O
(	O
x	O
)	O
g	O
(	O
x	O
’	O
)	O
xx	O
’	O
x=h	O
(	O
x	O
’	O
)	O
^	O
3.6	O
geometric	B
transformations	O
167	O
figure	O
3.48	O
anisotropic	B
texture	O
ﬁltering	O
:	O
(	O
a	O
)	O
jacobian	O
of	O
transform	B
a	O
and	O
the	O
induced	O
horizontal	O
and	O
vertical	O
resampling	O
rates	O
{	O
ax	O
(	O
cid:48	O
)	O
x	O
,	O
ax	O
(	O
cid:48	O
)	O
y	O
,	O
ay	O
(	O
cid:48	O
)	O
x	O
,	O
ay	O
(	O
cid:48	O
)	O
y	O
}	O
;	O
(	O
b	O
)	O
elliptical	O
footprint	O
of	O
an	O
ewa	O
smoothing	B
kernel	O
;	O
(	O
c	O
)	O
anisotropic	B
ﬁltering	I
using	O
multiple	B
samples	O
along	O
the	O
major	O
axis	O
.	O
image	B
pixels	O
lie	O
at	O
line	O
intersections	O
.	O
the	O
y	O
dimensions	O
.	O
the	O
resampling	O
kernel	B
should	O
be	O
performing	O
regular	O
interpolation	B
along	O
the	O
x	O
dimension	O
and	O
smoothing	B
(	O
to	O
anti-alias	O
the	O
blurred	O
image	B
)	O
in	O
the	O
y	O
direction	O
.	O
this	O
gets	O
even	O
more	O
complicated	O
for	O
the	O
case	O
of	O
general	O
afﬁne	B
or	O
perspective	B
transforms	O
.	O
what	O
can	O
we	O
do	O
?	O
fortunately	O
,	O
fourier	O
analysis	O
can	O
help	O
.	O
the	O
two-dimensional	B
general-	O
ization	O
of	O
the	O
one-dimensional	O
domain	O
scaling	O
law	O
given	O
in	O
table	O
3.1	O
is	O
g	O
(	O
ax	O
)	O
⇔	O
|a|−1g	O
(	O
a−t	O
f	O
)	O
.	O
(	O
3.90	O
)	O
for	O
all	O
of	O
the	O
transforms	O
in	O
table	O
3.5	O
except	O
perspective	B
,	O
the	O
matrix	O
a	O
is	O
already	O
deﬁned	O
.	O
for	O
perspective	O
transformations	O
,	O
the	O
matrix	O
a	O
is	O
the	O
linearized	O
derivative	O
of	O
the	O
perspective	B
transformation	O
(	O
figure	O
3.48a	O
)	O
,	O
i.e.	O
,	O
the	O
local	B
afﬁne	O
approximation	O
to	O
the	O
stretching	O
induced	O
by	O
the	O
projection	O
(	O
heckbert	O
1986	O
;	O
wolberg	O
1990	O
;	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
1999	O
;	O
akenine-	O
m¨oller	O
and	O
haines	O
2002	O
)	O
.	O
to	O
prevent	O
aliasing	B
,	O
we	O
need	O
to	O
pre-ﬁlter	O
the	O
image	B
f	O
(	O
x	O
)	O
with	O
a	O
ﬁlter	O
whose	O
frequency	O
response	O
is	O
the	O
projection	O
of	O
the	O
ﬁnal	O
desired	O
spectrum	O
through	O
the	O
a−t	O
transform	B
(	O
szeliski	O
,	O
winder	O
,	O
and	O
uyttendaele	O
2010	O
)	O
.	O
in	O
general	O
(	O
for	O
non-zoom	O
transforms	O
)	O
,	O
this	O
ﬁlter	O
is	O
non-	O
separable	B
and	O
hence	O
is	O
very	O
slow	O
to	O
compute	O
.	O
therefore	O
,	O
a	O
number	O
of	O
approximations	O
to	O
this	O
ﬁlter	O
are	O
used	O
in	O
practice	O
,	O
include	O
mip-mapping	O
,	O
elliptically	O
weighted	B
gaussian	O
averaging	O
,	O
and	O
anisotropic	B
ﬁltering	I
(	O
akenine-m¨oller	O
and	O
haines	O
2002	O
)	O
.	O
mip-mapping	O
mip-mapping	O
was	O
ﬁrst	O
proposed	O
by	O
williams	O
(	O
1983	O
)	O
as	O
a	O
means	O
to	O
rapidly	O
pre-ﬁlter	O
images	O
being	O
used	O
for	O
texture	O
mapping	O
in	O
computer	O
graphics	O
.	O
a	O
mip-map18	O
is	O
a	O
standard	O
image	O
18	O
the	O
term	O
‘	O
mip	O
’	O
stands	O
for	O
multi	O
in	O
parvo	O
,	O
meaning	O
‘	O
many	O
in	O
one	O
’	O
.	O
xyx	O
’	O
y	O
’	O
xyx	O
’	O
y	O
’	O
xyx	O
’	O
y	O
’	O
ay	O
’	O
yay	O
’	O
xax	O
’	O
xax	O
’	O
y	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
major	O
axisminor	O
axis	O
168	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
pyramid	B
(	O
figure	O
3.32	O
)	O
,	O
where	O
each	O
level	O
is	O
pre-ﬁltered	O
with	O
a	O
high-quality	O
ﬁlter	O
rather	O
than	O
a	O
poorer	O
quality	O
approximation	O
,	O
such	O
as	O
burt	O
and	O
adelson	O
’	O
s	O
(	O
1983b	O
)	O
ﬁve-tap	O
binomial	B
.	O
to	O
resample	O
an	O
image	B
from	O
a	O
mip-map	O
,	O
a	O
scalar	O
estimate	O
of	O
the	O
resampling	O
rate	O
r	O
is	O
ﬁrst	O
com-	O
puted	O
.	O
for	O
example	O
,	O
r	O
can	O
be	O
the	O
maximum	O
of	O
the	O
absolute	O
values	O
in	O
a	O
(	O
which	O
suppresses	O
aliasing	B
)	O
or	O
it	O
can	O
be	O
the	O
minimum	O
(	O
which	O
reduces	O
blurring	O
)	O
.	O
akenine-m¨oller	O
and	O
haines	O
(	O
2002	O
)	O
discuss	O
these	O
issues	O
in	O
more	O
detail	O
.	O
once	O
a	O
resampling	O
rate	O
has	O
been	O
speciﬁed	O
,	O
a	O
fractional	O
pyramid	B
level	O
is	O
computed	O
using	O
the	O
base	O
2	O
logarithm	O
,	O
l	O
=	O
log2	O
r.	O
(	O
3.91	O
)	O
one	O
simple	O
solution	O
is	O
to	O
resample	O
the	O
texture	B
from	O
the	O
next	O
higher	O
or	O
lower	O
pyramid	B
level	O
,	O
depending	O
on	O
whether	O
it	O
is	O
preferable	O
to	O
reduce	O
aliasing	B
or	O
blur	O
.	O
a	O
better	O
solution	O
is	O
to	O
re-	O
sample	O
both	O
images	O
and	O
blend	O
them	O
linearly	O
using	O
the	O
fractional	O
component	O
of	O
l.	O
since	O
most	O
mip-map	O
implementations	O
use	O
bilinear	B
resampling	O
within	O
each	O
level	O
,	O
this	O
approach	O
is	O
usu-	O
ally	O
called	O
trilinear	B
mip-mapping	O
.	O
computer	O
graphics	O
rendering	B
apis	O
,	O
such	O
as	O
opengl	O
and	O
direct3d	O
,	O
have	O
parameters	B
that	O
can	O
be	O
used	O
to	O
select	O
which	O
variant	O
of	O
mip-mapping	O
(	O
and	O
of	O
the	O
sampling	B
rate	O
r	O
computation	O
)	O
should	O
be	O
used	O
,	O
depending	O
on	O
the	O
desired	O
tradeoff	O
between	O
speed	O
and	O
quality	O
.	O
exercise	O
3.22	O
has	O
you	O
examine	O
some	O
of	O
these	O
tradeoffs	O
in	O
more	O
detail	O
.	O
elliptical	O
weighted	B
average	O
the	O
elliptical	O
weighted	B
average	O
(	O
ewa	O
)	O
ﬁlter	O
invented	O
by	O
greene	O
and	O
heckbert	O
(	O
1986	O
)	O
is	O
based	O
on	O
the	O
observation	O
that	O
the	O
afﬁne	B
mapping	O
x	O
=	O
ax	O
(	O
cid:48	O
)	O
deﬁnes	O
a	O
skewed	O
two-dimensional	B
coordinate	O
system	O
in	O
the	O
vicinity	O
of	O
each	O
source	O
pixel	O
x	O
(	O
figure	O
3.48a	O
)	O
.	O
for	O
every	O
destina-	O
tion	B
pixel	O
x	O
(	O
cid:48	O
)	O
,	O
the	O
ellipsoidal	O
projection	O
of	O
a	O
small	O
pixel	O
grid	O
in	O
x	O
(	O
cid:48	O
)	O
onto	O
x	O
is	O
computed	O
(	O
fig-	O
ure	O
3.48b	O
)	O
.	O
this	O
is	O
then	O
used	O
to	O
ﬁlter	O
the	O
source	O
image	B
g	O
(	O
x	O
)	O
with	O
a	O
gaussian	O
whose	O
inverse	B
covariance	O
matrix	O
is	O
this	O
ellipsoid	O
.	O
despite	O
its	O
reputation	O
as	O
a	O
high-quality	O
ﬁlter	O
(	O
akenine-m¨oller	O
and	O
haines	O
2002	O
)	O
,	O
we	O
have	O
found	O
in	O
our	O
work	O
(	O
szeliski	O
,	O
winder	O
,	O
and	O
uyttendaele	O
2010	O
)	O
that	O
because	O
a	O
gaussian	O
kernel	B
is	O
used	O
,	O
the	O
technique	O
suffers	O
simultaneously	O
from	O
both	O
blurring	O
and	O
aliasing	B
,	O
compared	O
to	O
higher-quality	O
ﬁlters	O
.	O
the	O
ewa	O
is	O
also	O
quite	O
slow	O
,	O
although	O
faster	O
variants	O
based	O
on	O
mip-	O
mapping	O
have	O
been	O
proposed	O
(	O
szeliski	O
,	O
winder	O
,	O
and	O
uyttendaele	O
(	O
2010	O
)	O
provide	O
some	O
addi-	O
tional	O
references	B
)	O
.	O
anisotropic	B
ﬁltering	I
an	O
alternative	O
approach	O
to	O
ﬁltering	O
oriented	B
textures	O
,	O
which	O
is	O
sometimes	O
implemented	O
in	O
graphics	O
hardware	O
(	O
gpus	O
)	O
,	O
is	O
to	O
use	O
anisotropic	B
ﬁltering	I
(	O
barkans	O
1997	O
;	O
akenine-m¨oller	O
and	O
haines	O
2002	O
)	O
.	O
in	O
this	O
approach	O
,	O
several	O
samples	O
at	O
different	O
resolutions	O
(	O
fractional	O
levels	O
in	O
the	O
mip-map	O
)	O
are	O
combined	O
along	O
the	O
major	O
axis	O
of	O
the	O
ewa	O
gaussian	O
(	O
figure	O
3.48c	O
)	O
.	O
3.6	O
geometric	B
transformations	O
169	O
figure	O
3.49	O
one-dimensional	O
signal	O
resampling	O
(	O
szeliski	O
,	O
winder	O
,	O
and	O
uyttendaele	O
2010	O
)	O
:	O
(	O
a	O
)	O
original	O
sampled	O
signal	O
f	O
(	O
i	O
)	O
;	O
(	O
b	O
)	O
interpolated	O
signal	O
g1	O
(	O
x	O
)	O
;	O
(	O
c	O
)	O
warped	O
signal	O
g2	O
(	O
x	O
)	O
;	O
(	O
d	O
)	O
ﬁltered	O
signal	O
g3	O
(	O
x	O
)	O
;	O
(	O
e	O
)	O
sampled	O
signal	O
f	O
(	O
cid:48	O
)	O
(	O
i	O
)	O
.	O
the	O
corresponding	O
spectra	O
are	O
shown	O
below	O
the	O
signals	O
,	O
with	O
the	O
aliased	O
portions	O
shown	O
in	O
red	O
.	O
multi-pass	B
transforms	O
the	O
optimal	O
approach	O
to	O
warping	O
images	O
without	O
excessive	O
blurring	O
or	O
aliasing	B
is	O
to	O
adap-	O
tively	O
pre-ﬁlter	O
the	O
source	O
image	B
at	O
each	O
pixel	O
using	O
an	O
ideal	O
low-pass	B
ﬁlter	O
,	O
i.e.	O
,	O
an	O
oriented	B
skewed	O
sinc	B
or	O
low-order	O
(	O
e.g.	O
,	O
cubic	B
)	O
approximation	O
(	O
figure	O
3.48a	O
)	O
.	O
figure	O
3.49	O
shows	O
how	O
this	O
works	O
in	O
one	O
dimension	O
.	O
the	O
signal	O
is	O
ﬁrst	O
(	O
theoretically	O
)	O
interpolated	O
to	O
a	O
continuous	O
waveform	O
,	O
(	O
ideally	O
)	O
low-pass	B
ﬁltered	O
to	O
below	O
the	O
new	O
nyquist	O
rate	O
,	O
and	O
then	O
re-sampled	O
to	O
the	O
ﬁnal	O
desired	O
resolution	O
.	O
in	O
practice	O
,	O
the	O
interpolation	B
and	O
decimation	O
steps	O
are	O
concate-	O
nated	O
into	O
a	O
single	O
polyphase	O
digital	O
ﬁltering	O
operation	O
(	O
szeliski	O
,	O
winder	O
,	O
and	O
uyttendaele	O
2010	O
)	O
.	O
for	O
parametric	O
transforms	O
,	O
the	O
oriented	B
two-dimensional	O
ﬁltering	O
and	O
resampling	O
opera-	O
tions	O
can	O
be	O
approximated	O
using	O
a	O
series	O
of	O
one-dimensional	O
resampling	O
and	O
shearing	O
trans-	O
forms	O
(	O
catmull	O
and	O
smith	O
1980	O
;	O
heckbert	O
1989	O
;	O
wolberg	O
1990	O
;	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
1999	O
;	O
szeliski	O
,	O
winder	O
,	O
and	O
uyttendaele	O
2010	O
)	O
.	O
the	O
advantage	O
of	O
using	O
a	O
series	O
of	O
one-	O
dimensional	O
transforms	O
is	O
that	O
they	O
are	O
much	O
more	O
efﬁcient	O
(	O
in	O
terms	O
of	O
basic	O
arithmetic	O
operations	O
)	O
than	O
large	O
,	O
non-separable	O
,	O
two-dimensional	B
ﬁlter	O
kernels	O
.	O
in	O
order	B
to	O
prevent	O
aliasing	B
,	O
however	O
,	O
it	O
may	O
be	O
necessary	O
to	O
upsample	O
in	O
the	O
opposite	O
di-	O
rection	O
before	O
applying	O
a	O
shearing	O
transformation	O
(	O
szeliski	O
,	O
winder	O
,	O
and	O
uyttendaele	O
2010	O
)	O
.	O
figure	O
3.50	O
shows	O
this	O
process	O
for	O
a	O
rotation	O
,	O
where	O
a	O
vertical	O
upsampling	O
stage	O
is	O
added	O
be-	O
fore	O
the	O
horizontal	O
shearing	O
(	O
and	O
upsampling	O
)	O
stage	O
.	O
the	O
upper	O
image	B
shows	O
the	O
appearance	O
of	O
the	O
letter	O
being	O
rotated	O
,	O
while	O
the	O
lower	O
image	B
shows	O
its	O
corresponding	O
fourier	O
transform	B
.	O
h2ifxxxif	O
’	O
g1g2g3ufug1ug2ug3uf	O
’	O
h1interpolate*	O
h1	O
(	O
x	O
)	O
warpax+tfilter*	O
h2	O
(	O
x	O
)	O
sample*	O
δ	O
(	O
x	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
(	O
h	O
)	O
(	O
i	O
)	O
(	O
j	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
170	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
3.50	O
four-pass	O
rotation	O
(	O
szeliski	O
,	O
winder	O
,	O
and	O
uyttendaele	O
2010	O
)	O
:	O
(	O
a	O
)	O
original	O
pixel	O
grid	O
,	O
image	B
,	O
and	O
its	O
fourier	O
transform	B
;	O
(	O
b	O
)	O
vertical	O
upsampling	O
;	O
(	O
c	O
)	O
horizontal	O
shear	O
and	O
up-	O
sampling	B
;	O
(	O
d	O
)	O
vertical	O
shear	O
and	O
downsampling	O
;	O
(	O
e	O
)	O
horizontal	O
downsampling	O
.	O
the	O
general	O
afﬁne	B
case	O
looks	O
similar	O
except	O
that	O
the	O
ﬁrst	O
two	O
stages	O
perform	O
general	O
resampling	O
.	O
3.6.2	O
mesh-based	O
warping	O
while	O
parametric	B
transforms	O
speciﬁed	O
by	O
a	O
small	O
number	O
of	O
global	B
parameters	O
have	O
many	O
uses	O
,	O
local	B
deformations	O
with	O
more	O
degrees	O
of	O
freedom	O
are	O
often	O
required	O
.	O
consider	O
,	O
for	O
example	O
,	O
changing	O
the	O
appearance	O
of	O
a	O
face	B
from	O
a	O
frown	O
to	O
a	O
smile	O
(	O
fig-	O
ure	O
3.51a	O
)	O
.	O
what	O
is	O
needed	O
in	O
this	O
case	O
is	O
to	O
curve	O
the	O
corners	O
of	O
the	O
mouth	O
upwards	O
while	O
leaving	O
the	O
rest	O
of	O
the	O
face	B
intact.19	O
to	O
perform	O
such	O
a	O
transformation	O
,	O
different	O
amounts	O
of	O
motion	B
are	O
required	O
in	O
different	O
parts	O
of	O
the	O
image	B
.	O
figure	O
3.51	O
shows	O
some	O
of	O
the	O
commonly	O
used	O
approaches	O
.	O
the	O
ﬁrst	O
approach	O
,	O
shown	O
in	O
figure	O
3.51a–b	O
,	O
is	O
to	O
specify	O
a	O
sparse	B
set	O
of	O
corresponding	O
points	B
.	O
the	O
displacement	O
of	O
these	O
points	B
can	O
then	O
be	O
interpolated	O
to	O
a	O
dense	O
displacement	O
ﬁeld	O
(	O
chapter	O
8	O
)	O
using	O
a	O
variety	O
of	O
techniques	O
(	O
nielson	O
1993	O
)	O
.	O
one	O
possibility	O
is	O
to	O
triangulate	O
the	O
set	O
of	O
points	B
in	O
one	O
image	B
(	O
de	O
berg	O
,	O
cheong	O
,	O
van	O
kreveld	O
et	O
al	O
.	O
2006	O
;	O
litwinowicz	O
and	O
williams	O
1994	O
;	O
buck	O
,	O
finkelstein	O
,	O
jacobs	O
et	O
al	O
.	O
2000	O
)	O
and	O
to	O
use	O
an	O
afﬁne	B
motion	O
model	O
(	O
table	O
3.5	O
)	O
,	O
speciﬁed	O
by	O
the	O
three	O
triangle	O
vertices	O
,	O
inside	O
each	O
triangle	O
.	O
if	O
the	O
destination	O
19	O
rowland	O
and	O
perrett	O
(	O
1995	O
)	O
;	O
pighin	O
,	O
hecker	O
,	O
lischinski	O
et	O
al	O
.	O
(	O
1998	O
)	O
;	O
blanz	O
and	O
vetter	O
(	O
1999	O
)	O
;	O
leyvand	O
,	O
cohen-	O
or	O
,	O
dror	O
et	O
al	O
.	O
(	O
2008	O
)	O
show	O
more	O
sophisticated	O
examples	B
of	O
changing	O
facial	O
expression	O
and	O
appearance	O
.	O
vertical	O
shear+	O
downsample	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
vertical	O
upsamplehorizontal	O
shear+	O
upsamplehorizontal	O
downsample	O
(	O
e	O
)	O
3.6	O
geometric	B
transformations	O
171	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
3.51	O
image	B
warping	O
alternatives	O
(	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
morgan	O
kaufmann	O
:	O
(	O
a	O
)	O
sparse	B
control	O
points	B
−→	O
deformation	O
grid	O
;	O
(	O
b	O
)	O
denser	O
set	O
of	O
control	O
point	O
correspondences	O
;	O
(	O
c	O
)	O
oriented	B
line	O
correspondences	O
;	O
(	O
d	O
)	O
uniform	O
quadrilateral	O
grid	O
.	O
image	B
is	O
triangulated	O
according	O
to	O
the	O
new	O
vertex	O
locations	O
,	O
an	O
inverse	B
warping	I
algorithm	O
(	O
figure	O
3.47	O
)	O
can	O
be	O
used	O
.	O
if	O
the	O
source	O
image	B
is	O
triangulated	O
and	O
used	O
as	O
a	O
texture	B
map	O
,	O
computer	O
graphics	O
rendering	B
algorithms	O
can	O
be	O
used	O
to	O
draw	O
the	O
new	O
image	B
(	O
but	O
care	O
must	O
be	O
taken	O
along	O
triangle	O
edges	O
to	O
avoid	O
potential	O
aliasing	B
)	O
.	O
alternative	O
methods	O
for	O
interpolating	O
a	O
sparse	B
set	O
of	O
displacements	O
include	O
moving	O
nearby	O
quadrilateral	O
mesh	O
vertices	O
,	O
as	O
shown	O
in	O
figure	O
3.51a	O
,	O
using	O
variational	O
(	O
energy	O
minimizing	O
)	O
interpolants	O
such	O
as	O
regularization	B
(	O
litwinowicz	O
and	O
williams	O
1994	O
)	O
,	O
see	O
section	O
3.7.1	O
,	O
or	O
using	O
locally	O
weighted	B
(	O
radial	B
basis	O
function	O
)	O
combinations	O
of	O
displacements	O
(	O
nielson	O
1993	O
)	O
.	O
(	O
see	O
(	O
section	O
12.3.1	O
)	O
for	O
additional	O
scattered	O
data	O
interpolation	O
techniques	O
.	O
)	O
if	O
quadrilateral	O
meshes	O
are	O
used	O
,	O
it	O
may	O
be	O
desirable	O
to	O
interpolate	O
displacements	O
down	O
to	O
individual	O
pixel	O
values	O
using	O
a	O
smooth	O
interpolant	O
such	O
as	O
a	O
quadratic	O
b-spline	O
(	O
farin	O
1996	O
;	O
lee	O
,	O
wolberg	O
,	O
chwa	O
et	O
al	O
.	O
1996	O
)	O
.20	O
in	O
some	O
cases	O
,	O
e.g.	O
,	O
if	O
a	O
dense	O
depth	O
map	O
has	O
been	O
estimated	O
for	O
an	O
image	B
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
,	O
we	O
only	O
know	O
the	O
forward	B
displacement	O
for	O
each	O
pixel	O
.	O
as	O
mentioned	O
before	O
,	O
drawing	O
source	O
pixels	O
at	O
their	O
destination	O
location	O
,	O
i.e.	O
,	O
forward	B
warping	I
(	O
figure	O
3.46	O
)	O
,	O
suffers	O
from	O
several	O
potential	O
problems	O
,	O
including	O
aliasing	B
and	O
the	O
appearance	O
of	O
small	O
cracks	O
.	O
an	O
alternative	O
technique	O
in	O
this	O
case	O
is	O
to	O
forward	B
warp	O
the	O
displacement	O
ﬁeld	O
(	O
or	O
depth	B
map	I
)	O
to	O
20	O
note	O
that	O
the	O
block-based	O
motion	B
models	I
used	O
by	O
many	O
video	B
compression	I
standards	O
(	O
le	O
gall	O
1991	O
)	O
can	O
be	O
thought	O
of	O
as	O
a	O
0th-order	O
(	O
piecewise-constant	O
)	O
displacement	O
ﬁeld	O
.	O
172	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
3.52	O
line-based	B
image	O
warping	O
(	O
beier	O
and	O
neely	O
1992	O
)	O
c	O
(	O
cid:13	O
)	O
1992	O
acm	O
:	O
(	O
a	O
)	O
distance	O
computation	O
and	O
position	O
transfer	B
;	O
(	O
b	O
)	O
rendering	B
algorithm	O
;	O
(	O
c	O
)	O
two	O
intermediate	O
warps	O
used	O
for	O
morphing	O
.	O
its	O
new	O
location	O
,	O
ﬁll	O
small	O
holes	O
in	O
the	O
resulting	O
map	O
,	O
and	O
then	O
use	O
inverse	B
warping	I
to	O
perform	O
the	O
resampling	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
.	O
the	O
reason	O
that	O
this	O
generally	O
works	O
better	O
than	O
forward	B
warping	I
is	O
that	O
displacement	O
ﬁelds	O
tend	O
to	O
be	O
much	O
smoother	O
than	O
images	O
,	O
so	O
the	O
aliasing	B
introduced	O
during	O
the	O
forward	B
warping	I
of	O
the	O
displacement	O
ﬁeld	O
is	O
much	O
less	O
noticeable	O
.	O
a	O
second	O
approach	O
to	O
specifying	O
displacements	O
for	O
local	O
deformations	O
is	O
to	O
use	O
corre-	O
sponding	O
oriented	B
line	O
segments	O
(	O
beier	O
and	O
neely	O
1992	O
)	O
,	O
as	O
shown	O
in	O
figures	O
3.51c	O
and	O
3.52.	O
pixels	O
along	O
each	O
line	O
segment	O
are	O
transferred	O
from	O
source	O
to	O
destination	O
exactly	O
as	O
speciﬁed	O
,	O
and	O
other	O
pixels	O
are	O
warped	O
using	O
a	O
smooth	O
interpolation	B
of	O
these	O
displacements	O
.	O
each	O
line	O
segment	O
correspondence	B
speciﬁes	O
a	O
translation	B
,	O
rotation	O
,	O
and	O
scaling	O
,	O
i.e.	O
,	O
a	O
similarity	B
trans-	O
form	O
(	O
table	O
3.5	O
)	O
,	O
for	O
pixels	O
in	O
its	O
vicinity	O
,	O
as	O
shown	O
in	O
figure	O
3.52a	O
.	O
line	O
segments	O
inﬂuence	O
the	O
overall	O
displacement	O
of	O
the	O
image	B
using	O
a	O
weighting	B
function	O
that	O
depends	O
on	O
the	O
mini-	O
mum	O
distance	O
to	O
the	O
line	O
segment	O
(	O
v	O
in	O
figure	O
3.52a	O
if	O
u	O
∈	O
[	O
0	O
,	O
1	O
]	O
,	O
else	O
the	O
shorter	O
of	O
the	O
two	O
distances	O
to	O
p	O
and	O
q	O
)	O
.	O
for	O
each	O
pixel	O
x	O
,	O
the	O
target	O
location	O
x	O
(	O
cid:48	O
)	O
for	O
each	O
line	O
correspondence	O
is	O
computed	O
along	O
with	O
a	O
weight	O
that	O
depends	O
on	O
the	O
distance	O
and	O
the	O
line	O
segment	O
length	O
(	O
figure	O
3.52b	O
)	O
.	O
the	O
weighted	B
average	O
of	O
all	O
target	O
locations	O
x	O
(	O
cid:48	O
)	O
i	O
then	O
becomes	O
the	O
ﬁnal	O
destination	O
location	O
.	O
note	O
that	O
while	O
beier	O
and	O
neely	O
describe	O
this	O
algorithm	B
as	O
a	O
forward	B
warp	O
,	O
an	O
equivalent	O
algorithm	B
can	O
be	O
written	O
by	O
sequencing	O
through	O
the	O
destination	O
pixels	O
.	O
the	O
resulting	O
warps	O
are	O
not	O
identical	O
because	O
line	O
lengths	O
or	O
distances	O
to	O
lines	B
may	O
be	O
different	O
.	O
exercise	O
3.23	O
has	O
you	O
implement	O
the	O
beier–neely	O
(	O
line-based	B
)	O
warp	O
and	O
compare	O
it	O
to	O
a	O
number	O
of	O
other	O
local	B
deformation	O
methods	O
.	O
yet	O
another	O
way	O
of	O
specifying	O
correspondences	O
in	O
order	B
to	O
create	O
image	B
warps	O
is	O
to	O
use	O
snakes	B
(	O
section	O
5.1.1	O
)	O
combined	O
with	O
b-splines	O
(	O
lee	O
,	O
wolberg	O
,	O
chwa	O
et	O
al	O
.	O
1996	O
)	O
.	O
this	O
tech-	O
nique	O
is	O
used	O
in	O
apple	O
’	O
s	O
shake	O
software	O
and	O
is	O
popular	O
in	O
the	O
medical	B
imaging	I
community	O
.	O
3.6	O
geometric	B
transformations	O
173	O
figure	O
3.53	O
image	B
morphing	O
(	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
morgan	O
kaufmann	O
.	O
top	O
row	O
:	O
if	O
the	O
two	O
images	O
are	O
just	O
blended	O
,	O
visible	O
ghosting	O
results	O
.	O
bottom	O
row	O
:	O
both	O
images	O
are	O
ﬁrst	O
warped	O
to	O
the	O
same	O
intermediate	O
location	O
(	O
e.g.	O
,	O
halfway	O
towards	O
the	O
other	O
image	B
)	O
and	O
the	O
resulting	O
warped	O
images	O
are	O
then	O
blended	O
resulting	O
in	O
a	O
seamless	O
morph	O
.	O
one	O
ﬁnal	O
possibility	O
for	O
specifying	O
displacement	O
ﬁelds	O
is	O
to	O
use	O
a	O
mesh	O
speciﬁcally	O
adapted	O
to	O
the	O
underlying	O
image	B
content	O
,	O
as	O
shown	O
in	O
figure	O
3.51d	O
.	O
specifying	O
such	O
meshes	O
by	O
hand	O
can	O
involve	O
a	O
fair	O
amount	O
of	O
work	O
;	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
(	O
1999	O
)	O
describe	O
an	O
interactive	B
system	O
for	O
doing	O
this	O
.	O
once	O
the	O
two	O
meshes	O
have	O
been	O
speciﬁed	O
,	O
intermediate	O
warps	O
can	O
be	O
generated	O
using	O
linear	O
interpolation	B
and	O
the	O
displacements	O
at	O
mesh	O
nodes	O
can	O
be	O
interpolated	O
using	O
splines	O
.	O
3.6.3	O
application	O
:	O
feature-based	B
morphing	O
while	O
warps	O
can	O
be	O
used	O
to	O
change	O
the	O
appearance	O
of	O
or	O
to	O
animate	O
a	O
single	O
image	O
,	O
even	O
more	O
powerful	O
effects	O
can	O
be	O
obtained	O
by	O
warping	O
and	O
blending	B
two	O
or	O
more	O
images	O
using	O
a	O
process	O
now	O
commonly	O
known	O
as	O
morphing	B
(	O
beier	O
and	O
neely	O
1992	O
;	O
lee	O
,	O
wolberg	O
,	O
chwa	O
et	O
al	O
.	O
1996	O
;	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
1999	O
)	O
.	O
figure	O
3.53	O
shows	O
the	O
essence	O
of	O
image	B
morphing	O
.	O
instead	O
of	O
simply	O
cross-dissolving	O
between	O
two	O
images	O
,	O
which	O
leads	O
to	O
ghosting	O
as	O
shown	O
in	O
the	O
top	O
row	O
,	O
each	O
image	B
is	O
warped	O
toward	O
the	O
other	O
image	B
before	O
blending	B
,	O
as	O
shown	O
in	O
the	O
bottom	O
row	O
.	O
if	O
the	O
correspondences	O
have	O
been	O
set	O
up	O
well	O
(	O
using	O
any	O
of	O
the	O
techniques	O
shown	O
in	O
figure	O
3.51	O
)	O
,	O
corresponding	O
features	O
are	O
aligned	O
and	O
no	O
ghosting	O
results	O
.	O
the	O
above	O
process	O
is	O
repeated	O
for	O
each	O
intermediate	O
frame	O
being	O
generated	O
during	O
a	O
174	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
morph	O
,	O
using	O
different	O
blends	O
(	O
and	O
amounts	O
of	O
deformation	O
)	O
at	O
each	O
interval	O
.	O
let	O
t	O
∈	O
[	O
0	O
,	O
1	O
]	O
be	O
the	O
time	O
parameter	O
that	O
describes	O
the	O
sequence	O
of	O
interpolated	O
frames	O
.	O
the	O
weighting	B
func-	O
tions	O
for	O
the	O
two	O
warped	O
images	O
in	O
the	O
blend	O
go	O
as	O
(	O
1	O
−	O
t	O
)	O
and	O
t.	O
conversely	O
,	O
the	O
amount	O
of	O
motion	B
that	O
image	B
0	O
undergoes	O
at	O
time	O
t	O
is	O
t	O
of	O
the	O
total	B
amount	O
of	O
motion	B
that	O
is	O
speciﬁed	O
by	O
the	O
correspondences	O
.	O
however	O
,	O
some	O
care	O
must	O
be	O
taken	O
in	O
deﬁning	O
what	O
it	O
means	O
to	O
par-	O
tially	O
warp	O
an	O
image	B
towards	O
a	O
destination	O
,	O
especially	O
if	O
the	O
desired	O
motion	B
is	O
far	O
from	O
linear	B
(	O
sederberg	O
,	O
gao	O
,	O
wang	O
et	O
al	O
.	O
1993	O
)	O
.	O
exercise	O
3.25	O
has	O
you	O
implement	O
a	O
morphing	B
algorithm	O
and	O
test	O
it	O
out	O
under	O
such	O
challenging	O
conditions	O
.	O
3.7	O
global	B
optimization	I
so	O
far	O
in	O
this	O
chapter	O
,	O
we	O
have	O
covered	O
a	O
large	O
number	O
of	O
image	B
processing	O
operators	O
that	O
take	O
as	O
input	O
one	O
or	O
more	O
images	O
and	O
produce	O
some	O
ﬁltered	O
or	O
transformed	O
version	O
of	O
these	O
images	O
.	O
in	O
many	O
applications	O
,	O
it	O
is	O
more	O
useful	O
to	O
ﬁrst	O
formulate	O
the	O
goals	O
of	O
the	O
desired	O
transformation	O
using	O
some	O
optimization	O
criterion	O
and	O
then	O
ﬁnd	O
or	O
infer	O
the	O
solution	O
that	O
best	O
meets	O
this	O
criterion	O
.	O
in	O
this	O
ﬁnal	O
section	O
,	O
we	O
present	O
two	O
different	O
(	O
but	O
closely	O
related	O
)	O
variants	O
on	O
this	O
idea	O
.	O
the	O
ﬁrst	O
,	O
which	O
is	O
often	O
called	O
regularization	B
or	O
variational	O
methods	O
(	O
section	O
3.7.1	O
)	O
,	O
con-	O
structs	O
a	O
continuous	O
global	B
energy	O
function	O
that	O
describes	O
the	O
desired	O
characteristics	O
of	O
the	O
solution	O
and	O
then	O
ﬁnds	O
a	O
minimum	O
energy	O
solution	O
using	O
sparse	O
linear	B
systems	O
or	O
related	O
iterative	B
techniques	O
.	O
the	O
second	O
formulates	O
the	O
problem	O
using	O
bayesian	O
statistics	O
,	O
model-	O
ing	O
both	O
the	O
noisy	O
measurement	O
process	O
that	O
produced	O
the	O
input	O
images	O
as	O
well	O
as	O
prior	B
assumptions	O
about	O
the	O
solution	O
space	O
,	O
which	O
are	O
often	O
encoded	O
using	O
a	O
markov	O
random	O
ﬁeld	O
(	O
section	O
3.7.2	O
)	O
.	O
examples	B
of	O
such	O
problems	O
include	O
surface	B
interpolation	O
from	O
scattered	O
data	O
(	O
figure	O
3.54	O
)	O
,	O
image	B
denoising	O
and	O
the	O
restoration	O
of	O
missing	O
regions	O
(	O
figure	O
3.57	O
)	O
,	O
and	O
the	O
segmentation	B
of	O
images	O
into	O
foreground	O
and	O
background	O
regions	O
(	O
figure	O
3.61	O
)	O
.	O
3.7.1	O
regularization	B
the	O
theory	O
of	O
regularization	B
was	O
ﬁrst	O
developed	O
by	O
statisticians	O
trying	O
to	O
ﬁt	O
models	O
to	O
data	O
that	O
severely	O
underconstrained	O
the	O
solution	O
space	O
(	O
tikhonov	O
and	O
arsenin	O
1977	O
;	O
engl	O
,	O
hanke	O
,	O
and	O
neubauer	O
1996	O
)	O
.	O
consider	O
,	O
for	O
example	O
,	O
ﬁnding	O
a	O
smooth	O
surface	B
that	O
passes	O
through	O
(	O
or	O
near	O
)	O
a	O
set	O
of	O
measured	O
data	O
points	O
(	O
figure	O
3.54	O
)	O
.	O
such	O
a	O
problem	O
is	O
described	O
as	O
ill-	O
posed	O
because	O
many	O
possible	O
surfaces	O
can	O
ﬁt	O
this	O
data	O
.	O
since	O
small	O
changes	O
in	O
the	O
input	O
can	O
sometimes	O
lead	O
to	O
large	O
changes	O
in	O
the	O
ﬁt	O
(	O
e.g.	O
,	O
if	O
we	O
use	O
polynomial	O
interpolation	B
)	O
,	O
such	O
problems	O
are	O
also	O
often	O
ill-conditioned	O
.	O
since	O
we	O
are	O
trying	O
to	O
recover	O
the	O
unknown	O
function	O
f	O
(	O
x	O
,	O
y	O
)	O
from	O
which	O
the	O
data	O
point	O
d	O
(	O
xi	O
,	O
yi	O
)	O
were	O
sampled	O
,	O
such	O
problems	O
are	O
also	O
often	O
called	O
3.7	O
global	B
optimization	I
175	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
3.54	O
a	O
simple	O
surface	B
interpolation	O
problem	O
:	O
(	O
a	O
)	O
nine	O
data	O
points	O
of	O
various	O
height	O
scattered	O
on	O
a	O
grid	O
;	O
(	O
b	O
)	O
second-order	O
,	O
controlled-continuity	O
,	O
thin-plate	O
spline	B
interpolator	O
,	O
with	O
a	O
tear	O
along	O
its	O
left	O
edge	O
and	O
a	O
crease	O
along	O
its	O
right	O
(	O
szeliski	O
1989	O
)	O
c	O
(	O
cid:13	O
)	O
1989	O
springer	O
.	O
inverse	B
problems	O
.	O
many	O
computer	O
vision	O
tasks	O
can	O
be	O
viewed	O
as	O
inverse	B
problems	O
,	O
since	O
we	O
are	O
trying	O
to	O
recover	O
a	O
full	O
description	O
of	O
the	O
3d	O
world	O
from	O
a	O
limited	O
set	O
of	O
images	O
.	O
in	O
order	B
to	O
quantify	O
what	O
it	O
means	O
to	O
ﬁnd	O
a	O
smooth	O
solution	O
,	O
we	O
can	O
deﬁne	O
a	O
norm	O
on	O
the	O
solution	O
space	O
.	O
for	O
one-dimensional	O
functions	O
f	O
(	O
x	O
)	O
,	O
we	O
can	O
integrate	O
the	O
squared	O
ﬁrst	O
derivative	O
of	O
the	O
function	O
,	O
or	O
perhaps	O
integrate	O
the	O
squared	O
second	O
derivative	O
,	O
e1	O
=	O
(	O
cid:90	O
)	O
f	O
2	O
e2	O
=	O
(	O
cid:90	O
)	O
f	O
2	O
x	O
(	O
x	O
)	O
dx	O
xx	O
(	O
x	O
)	O
dx	O
.	O
(	O
here	O
,	O
we	O
use	O
subscripts	O
to	O
denote	O
differentiation	O
.	O
)	O
such	O
energy	O
measures	O
are	O
examples	B
of	O
functionals	O
,	O
which	O
are	O
operators	O
that	O
map	O
functions	O
to	O
scalar	O
values	O
.	O
they	O
are	O
also	O
often	O
called	O
variational	O
methods	O
,	O
because	O
they	O
measure	O
the	O
variation	O
(	O
non-smoothness	O
)	O
in	O
a	O
function	O
.	O
in	O
two	O
dimensions	O
(	O
e.g.	O
,	O
for	O
images	O
,	O
ﬂow	O
ﬁelds	O
,	O
or	O
surfaces	O
)	O
,	O
the	O
corresponding	O
smooth-	O
(	O
3.92	O
)	O
(	O
3.93	O
)	O
(	O
3.94	O
)	O
(	O
3.95	O
)	O
ness	O
functionals	O
are	O
and	O
where	O
the	O
mixed	O
2f	O
2	O
1983	O
)	O
.	O
e1	O
=	O
(	O
cid:90	O
)	O
f	O
2	O
e2	O
=	O
(	O
cid:90	O
)	O
f	O
2	O
x	O
(	O
x	O
,	O
y	O
)	O
+	O
f	O
2	O
y	O
(	O
x	O
,	O
y	O
)	O
dx	O
dy	O
=	O
(	O
cid:90	O
)	O
(	O
cid:107	O
)	O
∇f	O
(	O
x	O
,	O
y	O
)	O
(	O
cid:107	O
)	O
2	O
dx	O
dy	O
xx	O
(	O
x	O
,	O
y	O
)	O
+	O
2f	O
2	O
xy	O
(	O
x	O
,	O
y	O
)	O
+	O
f	O
2	O
yy	O
(	O
x	O
,	O
y	O
)	O
dx	O
dy	O
,	O
xy	O
term	O
is	O
needed	O
to	O
make	O
the	O
measure	O
rotationally	O
invariant	O
(	O
grimson	O
the	O
ﬁrst	O
derivative	O
norm	O
is	O
often	O
called	O
the	O
membrane	O
,	O
since	O
interpolating	O
a	O
set	O
of	O
data	O
points	O
using	O
this	O
measure	O
results	O
in	O
a	O
tent-like	O
structure	O
.	O
(	O
in	O
fact	O
,	O
this	O
formula	O
is	O
a	O
small-	O
deﬂection	O
approximation	O
to	O
the	O
surface	B
area	O
,	O
which	O
is	O
what	O
soap	O
bubbles	O
minimize	O
.	O
)	O
the	O
for	O
a	O
problem	O
like	O
noise	B
removal	I
,	O
a	O
continuous	O
version	O
of	O
this	O
measure	O
can	O
be	O
used	O
,	O
[	O
f	O
(	O
xi	O
,	O
yi	O
)	O
−	O
di	O
]	O
2.	O
ed	O
=	O
(	O
cid:88	O
)	O
i	O
ed	O
=	O
(	O
cid:90	O
)	O
[	O
f	O
(	O
x	O
,	O
y	O
)	O
−	O
d	O
(	O
x	O
,	O
y	O
)	O
]	O
2	O
dx	O
dy	O
.	O
(	O
3.96	O
)	O
(	O
3.97	O
)	O
176	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
second-order	O
norm	O
is	O
called	O
the	O
thin-plate	O
spline	B
,	O
since	O
it	O
approximates	O
the	O
behavior	O
of	O
thin	B
plates	O
(	O
e.g.	O
,	O
ﬂexible	O
steel	O
)	O
under	O
small	O
deformations	O
.	O
a	O
blend	O
of	O
the	O
two	O
is	O
called	O
the	O
thin-	O
plate	O
spline	B
under	O
tension	O
;	O
versions	O
of	O
these	O
formulas	O
where	O
each	O
derivative	O
term	O
is	O
mul-	O
tiplied	O
by	O
a	O
local	B
weighting	O
function	O
are	O
called	O
controlled-continuity	O
splines	B
(	O
terzopoulos	O
1988	O
)	O
.	O
figure	O
3.54	O
shows	O
a	O
simple	O
example	O
of	O
a	O
controlled-continuity	O
interpolator	O
ﬁt	O
to	O
nine	O
scattered	O
data	O
points	O
.	O
in	O
practice	O
,	O
it	O
is	O
more	O
common	O
to	O
ﬁnd	O
ﬁrst-order	O
smoothness	B
terms	O
used	O
with	O
images	O
and	O
ﬂow	O
ﬁelds	O
(	O
section	O
8.4	O
)	O
and	O
second-order	O
smoothness	B
associated	O
with	O
surfaces	O
(	O
section	O
12.3.1	O
)	O
.	O
in	O
addition	O
to	O
the	O
smoothness	B
term	O
,	O
regularization	B
also	O
requires	O
a	O
data	O
term	O
(	O
or	O
data	O
penalty	O
)	O
.	O
for	O
scattered	O
data	O
interpolation	O
(	O
nielson	O
1993	O
)	O
,	O
the	O
data	O
term	O
measures	O
the	O
dis-	O
tance	O
between	O
the	O
function	O
f	O
(	O
x	O
,	O
y	O
)	O
and	O
a	O
set	O
of	O
data	O
points	O
di	O
=	O
d	O
(	O
xi	O
,	O
yi	O
)	O
,	O
to	O
obtain	O
a	O
global	B
energy	O
that	O
can	O
be	O
minimized	O
,	O
the	O
two	O
energy	O
terms	O
are	O
usually	O
added	O
together	O
,	O
e	O
=	O
ed	O
+	O
λes	O
,	O
(	O
3.98	O
)	O
where	O
es	O
is	O
the	O
smoothness	B
penalty	O
(	O
e1	O
,	O
e2	O
or	O
some	O
weighted	B
blend	O
)	O
and	O
λ	O
is	O
the	O
regulariza-	O
tion	B
parameter	O
,	O
which	O
controls	O
how	O
smooth	O
the	O
solution	O
should	O
be	O
.	O
in	O
order	B
to	O
ﬁnd	O
the	O
minimum	O
of	O
this	O
continuous	O
problem	O
,	O
the	O
function	O
f	O
(	O
x	O
,	O
y	O
)	O
is	O
usually	O
ﬁrst	O
discretized	O
on	O
a	O
regular	O
grid.21	O
the	O
most	O
principled	O
way	O
to	O
perform	O
this	O
discretization	O
is	O
to	O
use	O
ﬁnite	O
element	O
analysis	O
,	O
i.e.	O
,	O
to	O
approximate	O
the	O
function	O
with	O
a	O
piecewise	O
continuous	O
spline	B
,	O
and	O
then	O
perform	O
the	O
analytic	O
integration	O
(	O
bathe	O
2007	O
)	O
.	O
fortunately	O
,	O
for	O
both	O
the	O
ﬁrst-order	O
and	O
second-order	O
smoothness	B
functionals	O
,	O
the	O
judi-	O
cious	O
selection	O
of	O
appropriate	O
ﬁnite	O
elements	O
results	O
in	O
particularly	O
simple	O
discrete	B
forms	O
(	O
terzopoulos	O
1983	O
)	O
.	O
the	O
corresponding	O
discrete	B
smoothness	O
energy	O
functions	O
become	O
e1	O
=	O
(	O
cid:88	O
)	O
i	O
,	O
j	O
sx	O
(	O
i	O
,	O
j	O
)	O
[	O
f	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
−	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
gx	O
(	O
i	O
,	O
j	O
)	O
]	O
2	O
+	O
sy	O
(	O
i	O
,	O
j	O
)	O
[	O
f	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
−	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
gy	O
(	O
i	O
,	O
j	O
)	O
]	O
2	O
(	O
3.99	O
)	O
and	O
e2	O
=	O
h−2	O
(	O
cid:88	O
)	O
i	O
,	O
j	O
cx	O
(	O
i	O
,	O
j	O
)	O
[	O
f	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
−	O
2f	O
(	O
i	O
,	O
j	O
)	O
+	O
f	O
(	O
i	O
−	O
1	O
,	O
j	O
)	O
]	O
2	O
(	O
3.100	O
)	O
21	O
the	O
alternative	O
of	O
using	O
kernel	O
basis	O
functions	O
centered	O
on	O
the	O
data	O
points	O
(	O
boult	O
and	O
kender	O
1986	O
;	O
nielson	O
1993	O
)	O
is	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
12.3.1	O
.	O
3.7	O
global	B
optimization	I
177	O
+	O
2cm	O
(	O
i	O
,	O
j	O
)	O
[	O
f	O
(	O
i	O
+	O
1	O
,	O
j	O
+	O
1	O
)	O
−	O
f	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
−	O
f	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
+	O
f	O
(	O
i	O
,	O
j	O
)	O
]	O
2	O
+	O
cy	O
(	O
i	O
,	O
j	O
)	O
[	O
f	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
−	O
2f	O
(	O
i	O
,	O
j	O
)	O
+	O
f	O
(	O
i	O
,	O
j	O
−	O
1	O
)	O
]	O
2	O
,	O
where	O
h	O
is	O
the	O
size	O
of	O
the	O
ﬁnite	O
element	O
grid	O
.	O
the	O
h	O
factor	O
is	O
only	O
important	O
if	O
the	O
energy	O
is	O
being	O
discretized	O
at	O
a	O
variety	O
of	O
resolutions	O
,	O
as	O
in	O
coarse-to-ﬁne	B
or	O
multigrid	O
techniques	O
.	O
the	O
optional	O
smoothness	B
weights	O
sx	O
(	O
i	O
,	O
j	O
)	O
and	O
sy	O
(	O
i	O
,	O
j	O
)	O
control	O
the	O
location	O
of	O
horizon-	O
tal	O
and	O
vertical	O
tears	O
(	O
or	O
weaknesses	O
)	O
in	O
the	O
surface	B
.	O
for	O
other	O
problems	O
,	O
such	O
as	O
coloriza-	O
tion	B
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2004	O
)	O
and	O
interactive	B
tone	O
mapping	O
(	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
2006a	O
)	O
,	O
they	O
control	O
the	O
smoothness	B
in	O
the	O
interpolated	O
chroma	O
or	O
expo-	O
sure	O
ﬁeld	O
and	O
are	O
often	O
set	O
inversely	O
proportional	O
to	O
the	O
local	B
luminance	O
gradient	O
strength	O
.	O
for	O
second-order	O
problems	O
,	O
the	O
crease	O
variables	O
cx	O
(	O
i	O
,	O
j	O
)	O
,	O
cm	O
(	O
i	O
,	O
j	O
)	O
,	O
and	O
cy	O
(	O
i	O
,	O
j	O
)	O
control	O
the	O
locations	O
of	O
creases	O
in	O
the	O
surface	B
(	O
terzopoulos	O
1988	O
;	O
szeliski	O
1990a	O
)	O
.	O
the	O
data	O
values	O
gx	O
(	O
i	O
,	O
j	O
)	O
and	O
gy	O
(	O
i	O
,	O
j	O
)	O
are	O
gradient	O
data	O
terms	O
(	O
constraints	O
)	O
used	O
by	O
al-	O
gorithms	O
,	O
such	O
as	O
photometric	B
stereo	I
(	O
section	O
12.1.1	O
)	O
,	O
hdr	O
tone	B
mapping	I
(	O
section	O
10.2.1	O
)	O
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
)	O
,	O
poisson	O
blending	B
(	O
section	O
9.3.4	O
)	O
(	O
p´erez	O
,	O
gangnet	O
,	O
and	O
blake	O
2003	O
)	O
,	O
and	O
gradient-domain	O
blending	B
(	O
section	O
9.3.4	O
)	O
(	O
levin	O
,	O
zomet	O
,	O
peleg	O
et	O
al	O
.	O
2004	O
)	O
.	O
they	O
are	O
set	O
to	O
zero	O
when	O
just	O
discretizing	O
the	O
conventional	O
ﬁrst-order	O
smoothness	B
functional	O
(	O
3.94	O
)	O
.	O
the	O
two-dimensional	B
discrete	O
data	O
energy	O
is	O
written	O
as	O
ed	O
=	O
(	O
cid:88	O
)	O
i	O
,	O
j	O
w	O
(	O
i	O
,	O
j	O
)	O
[	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
d	O
(	O
i	O
,	O
j	O
)	O
]	O
2	O
,	O
(	O
3.101	O
)	O
where	O
the	O
local	B
weights	O
w	O
(	O
i	O
,	O
j	O
)	O
control	O
how	O
strongly	O
the	O
data	O
constraint	O
is	O
enforced	O
.	O
these	O
values	O
are	O
set	O
to	O
zero	O
where	O
there	O
is	O
no	O
data	O
and	O
can	O
be	O
set	O
to	O
the	O
inverse	B
variance	O
of	O
the	O
data	O
measurements	O
when	O
there	O
is	O
data	O
(	O
as	O
discussed	O
by	O
szeliski	O
(	O
1989	O
)	O
and	O
in	O
section	O
3.7.2	O
)	O
.	O
the	O
total	B
energy	O
of	O
the	O
discretized	O
problem	O
can	O
now	O
be	O
written	O
as	O
a	O
quadratic	O
form	O
e	O
=	O
ed	O
+	O
λes	O
=	O
xt	O
ax	O
−	O
2xt	O
b	O
+	O
c	O
,	O
where	O
x	O
=	O
[	O
f	O
(	O
0	O
,	O
0	O
)	O
.	O
.	O
.	O
f	O
(	O
m	O
−	O
1	O
,	O
n	O
−	O
1	O
)	O
]	O
is	O
called	O
the	O
state	O
vector.22	O
the	O
sparse	B
symmetric	O
positive-deﬁnite	O
matrix	O
a	O
is	O
called	O
the	O
hessian	O
since	O
it	O
encodes	O
the	O
second	O
derivative	O
of	O
the	O
energy	O
function.23	O
for	O
the	O
one-dimensional	O
,	O
ﬁrst-order	O
problem	O
,	O
a	O
is	O
tridiagonal	O
;	O
for	O
the	O
two-dimensional	B
,	O
ﬁrst-order	O
problem	O
,	O
it	O
is	O
multi-banded	O
with	O
ﬁve	O
non-	O
zero	O
entries	O
per	O
row	O
.	O
we	O
call	O
b	O
the	O
weighted	B
data	O
vector	O
.	O
minimizing	O
the	O
above	O
quadratic	O
form	O
is	O
equivalent	O
to	O
solving	O
the	O
sparse	B
linear	O
system	O
(	O
3.102	O
)	O
(	O
3.103	O
)	O
22	O
we	O
use	O
x	O
instead	O
of	O
f	O
because	O
this	O
is	O
the	O
more	O
common	O
form	O
in	O
the	O
numerical	O
analysis	O
literature	O
(	O
golub	O
and	O
ax	O
=	O
b	O
,	O
van	O
loan	O
1996	O
)	O
.	O
23	O
in	O
numerical	O
analysis	O
,	O
a	O
is	O
called	O
the	O
coefﬁcient	O
matrix	O
(	O
saad	O
2003	O
)	O
;	O
in	O
ﬁnite	O
element	O
analysis	O
(	O
bathe	O
2007	O
)	O
,	O
it	O
is	O
called	O
the	O
stiffness	B
matrix	I
.	O
178	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
3.55	O
graphical	O
model	O
interpretation	O
of	O
ﬁrst-order	O
regularization	B
.	O
the	O
white	O
circles	O
are	O
the	O
unknowns	O
f	O
(	O
i	O
,	O
j	O
)	O
while	O
the	O
dark	O
circles	O
are	O
the	O
input	O
data	O
d	O
(	O
i	O
,	O
j	O
)	O
.	O
in	O
the	O
resistive	O
grid	O
interpretation	O
,	O
the	O
d	O
and	O
f	O
values	O
encode	O
input	O
and	O
output	O
voltages	O
and	O
the	O
black	O
squares	O
denote	O
resistors	O
whose	O
conductance	O
is	O
set	O
to	O
sx	O
(	O
i	O
,	O
j	O
)	O
,	O
sy	O
(	O
i	O
,	O
j	O
)	O
,	O
and	O
w	O
(	O
i	O
,	O
j	O
)	O
.	O
in	O
the	O
spring-mass	O
system	O
analogy	O
,	O
the	O
circles	O
denote	O
elevations	O
and	O
the	O
black	O
squares	O
denote	O
springs	O
.	O
the	O
same	O
graphical	O
model	O
can	O
be	O
used	O
to	O
depict	O
a	O
ﬁrst-order	O
markov	O
random	O
ﬁeld	O
(	O
figure	O
3.56	O
)	O
.	O
which	O
can	O
be	O
done	O
using	O
a	O
variety	O
of	O
sparse	B
matrix	O
techniques	O
,	O
such	O
as	O
multigrid	O
(	O
briggs	O
,	O
henson	O
,	O
and	O
mccormick	O
2000	O
)	O
and	O
hierarchical	B
preconditioners	O
(	O
szeliski	O
2006b	O
)	O
,	O
as	O
de-	O
scribed	O
in	O
appendix	O
a.5	O
.	O
while	O
regularization	B
was	O
ﬁrst	O
introduced	O
to	O
the	O
vision	O
community	O
by	O
poggio	O
,	O
torre	O
,	O
and	O
koch	O
(	O
1985	O
)	O
and	O
terzopoulos	O
(	O
1986b	O
)	O
for	O
problems	O
such	O
as	O
surface	B
interpolation	O
,	O
it	O
was	O
quickly	O
adopted	O
by	O
other	O
vision	O
researchers	O
for	O
such	O
varied	O
problems	O
as	O
edge	O
detection	O
(	O
sec-	O
tion	B
4.2	O
)	O
,	O
optical	B
ﬂow	I
(	O
section	O
8.4	O
)	O
,	O
and	O
shape	O
from	O
shading	B
(	O
section	O
12.1	O
)	O
(	O
poggio	O
,	O
torre	O
,	O
and	O
koch	O
1985	O
;	O
horn	O
and	O
brooks	O
1986	O
;	O
terzopoulos	O
1986b	O
;	O
bertero	O
,	O
poggio	O
,	O
and	O
torre	O
1988	O
;	O
brox	O
,	O
bruhn	O
,	O
papenberg	O
et	O
al	O
.	O
2004	O
)	O
.	O
poggio	O
,	O
torre	O
,	O
and	O
koch	O
(	O
1985	O
)	O
also	O
showed	O
how	O
the	O
discrete	B
energy	O
deﬁned	O
by	O
equations	O
(	O
3.100–3.101	O
)	O
could	O
be	O
implemented	O
in	O
a	O
resistive	O
grid	O
,	O
as	O
shown	O
in	O
figure	O
3.55.	O
in	O
computational	O
photography	O
(	O
chapter	O
10	O
)	O
,	O
regularization	B
and	O
its	O
variants	O
are	O
commonly	O
used	O
to	O
solve	O
problems	O
such	O
as	O
high-dynamic	O
range	O
tone	O
mapping	O
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
;	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
2006a	O
)	O
,	O
pois-	O
son	O
and	O
gradient-domain	O
blending	B
(	O
p´erez	O
,	O
gangnet	O
,	O
and	O
blake	O
2003	O
;	O
levin	O
,	O
zomet	O
,	O
peleg	O
et	O
al	O
.	O
2004	O
;	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
,	O
colorization	B
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2004	O
)	O
,	O
and	O
natural	B
image	O
matting	B
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2008	O
)	O
.	O
robust	B
regularization	I
while	O
regularization	B
is	O
most	O
commonly	O
formulated	O
using	O
quadratic	O
(	O
l2	O
)	O
norms	O
(	O
compare	O
with	O
the	O
squared	O
derivatives	O
in	O
(	O
3.92–3.95	O
)	O
and	O
squared	O
differences	O
in	O
(	O
3.100–3.101	O
)	O
)	O
,	O
it	O
can	O
f	O
(	O
i	O
,	O
j	O
)	O
sx	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i	O
,	O
j+1	O
)	O
sy	O
(	O
i	O
,	O
j	O
)	O
w	O
(	O
i	O
,	O
j	O
)	O
d	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j+1	O
)	O
3.7	O
global	B
optimization	I
179	O
also	O
be	O
formulated	O
using	O
non-quadratic	O
robust	B
penalty	O
functions	O
(	O
appendix	O
b.3	O
)	O
.	O
for	O
exam-	O
ple	O
,	O
(	O
3.100	O
)	O
can	O
be	O
generalized	B
to	O
e1r	O
=	O
(	O
cid:88	O
)	O
i	O
,	O
j	O
sx	O
(	O
i	O
,	O
j	O
)	O
ρ	O
(	O
f	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
−	O
f	O
(	O
i	O
,	O
j	O
)	O
)	O
+	O
sy	O
(	O
i	O
,	O
j	O
)	O
ρ	O
(	O
f	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
−	O
f	O
(	O
i	O
,	O
j	O
)	O
)	O
,	O
(	O
3.104	O
)	O
where	O
ρ	O
(	O
x	O
)	O
is	O
some	O
monotonically	O
increasing	O
penalty	O
function	O
.	O
for	O
example	O
,	O
the	O
family	O
of	O
norms	O
ρ	O
(	O
x	O
)	O
=	O
|x|p	O
is	O
called	O
p-norms	O
.	O
when	O
p	O
<	O
2	O
,	O
the	O
resulting	O
smoothness	B
terms	O
become	O
more	O
piecewise	O
continuous	O
than	O
totally	O
smooth	O
,	O
which	O
can	O
better	O
model	O
the	O
discontinuous	O
nature	O
of	O
images	O
,	O
ﬂow	O
ﬁelds	O
,	O
and	O
3d	O
surfaces	O
.	O
an	O
early	O
example	O
of	O
robust	B
regularization	I
is	O
the	O
graduated	O
non-convexity	O
(	O
gnc	O
)	O
algo-	O
rithm	O
introduced	O
by	O
blake	O
and	O
zisserman	O
(	O
1987	O
)	O
.	O
here	O
,	O
the	O
norms	O
on	O
the	O
data	O
and	O
derivatives	O
are	O
clamped	O
to	O
a	O
maximum	O
value	O
ρ	O
(	O
x	O
)	O
=	O
min	O
(	O
x2	O
,	O
v	O
)	O
.	O
(	O
3.105	O
)	O
because	O
the	O
resulting	O
problem	O
is	O
highly	O
non-convex	O
(	O
it	O
has	O
many	O
local	B
minima	O
)	O
,	O
a	O
continua-	O
tion	B
method	O
is	O
proposed	O
,	O
where	O
a	O
quadratic	O
norm	O
(	O
which	O
is	O
convex	O
)	O
is	O
gradually	O
replaced	O
by	O
the	O
non-convex	O
robust	B
norm	O
(	O
allgower	O
and	O
georg	O
2003	O
)	O
.	O
(	O
around	O
the	O
same	O
time	O
,	O
terzopou-	O
los	O
(	O
1988	O
)	O
was	O
also	O
using	O
continuation	O
to	O
infer	O
the	O
tear	O
and	O
crease	O
variables	O
in	O
his	O
surface	B
interpolation	O
problems	O
.	O
)	O
today	O
,	O
it	O
is	O
more	O
common	O
to	O
use	O
the	O
l1	O
(	O
p	O
=	O
1	O
)	O
norm	O
,	O
which	O
is	O
often	O
called	O
total	B
variation	I
(	O
chan	O
,	O
osher	O
,	O
and	O
shen	O
2001	O
;	O
tschumperl´e	O
and	O
deriche	O
2005	O
;	O
tschumperl´e	O
2006	O
;	O
kaftory	O
,	O
schechner	O
,	O
and	O
zeevi	O
2007	O
)	O
.	O
other	O
norms	O
,	O
for	O
which	O
the	O
inﬂuence	O
(	O
derivative	O
)	O
more	O
quickly	O
decays	O
to	O
zero	O
,	O
are	O
presented	O
by	O
black	O
and	O
rangarajan	O
(	O
1996	O
)	O
;	O
black	O
,	O
sapiro	O
,	O
marimont	O
et	O
al	O
.	O
(	O
1998	O
)	O
and	O
discussed	O
in	O
appendix	O
b.3	O
.	O
even	O
more	O
recently	O
,	O
hyper-laplacian	O
norms	O
with	O
p	O
<	O
1	O
have	O
gained	O
popularity	O
,	O
based	O
on	O
the	O
observation	O
that	O
the	O
log-likelihood	O
distribution	O
of	O
image	B
derivatives	O
follows	O
a	O
p	O
≈	O
0.5	O
−	O
0.8	O
slope	O
and	O
is	O
therefore	O
a	O
hyper-laplacian	O
distribution	O
(	O
simoncelli	O
1999	O
;	O
levin	O
and	O
weiss	O
2007	O
;	O
weiss	O
and	O
freeman	O
2007	O
;	O
krishnan	O
and	O
fergus	O
2009	O
)	O
.	O
such	O
norms	O
have	O
an	O
even	O
stronger	O
tendency	O
to	O
prefer	O
large	O
discontinuities	O
over	O
small	O
ones	O
.	O
see	O
the	O
related	O
discussion	O
in	O
section	O
3.7.2	O
(	O
3.114	O
)	O
.	O
while	O
least	B
squares	I
regularized	O
problems	O
using	O
l2	O
norms	O
can	O
be	O
solved	O
using	O
linear	O
sys-	O
tems	O
,	O
other	O
p-norms	O
require	O
different	O
iterative	B
techniques	O
,	O
such	O
as	O
iteratively	B
reweighted	I
least	O
squares	O
(	O
irls	O
)	O
,	O
levenberg–marquardt	O
,	O
or	O
alternation	O
between	O
local	B
non-linear	O
subproblems	O
and	O
global	B
quadratic	O
regularization	B
(	O
krishnan	O
and	O
fergus	O
2009	O
)	O
.	O
such	O
techniques	O
are	O
dis-	O
cussed	O
in	O
section	O
6.1.3	O
and	O
appendices	O
a.3	O
and	O
b.3	O
.	O
180	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
3.7.2	O
markov	O
random	O
ﬁelds	O
as	O
we	O
have	O
just	O
seen	O
,	O
regularization	B
,	O
which	O
involves	O
the	O
minimization	O
of	O
energy	O
functionals	O
deﬁned	O
over	O
(	O
piecewise	O
)	O
continuous	O
functions	O
,	O
can	O
be	O
used	O
to	O
formulate	O
and	O
solve	O
a	O
variety	O
of	O
low-level	O
computer	O
vision	O
problems	O
.	O
an	O
alternative	O
technique	O
is	O
to	O
formulate	O
a	O
bayesian	O
model	O
,	O
which	O
separately	O
models	O
the	O
noisy	O
image	B
formation	O
(	O
measurement	O
)	O
process	O
,	O
as	O
well	O
as	O
assuming	O
a	O
statistical	O
prior	B
model	O
over	O
the	O
solution	O
space	O
.	O
in	O
this	O
section	O
,	O
we	O
look	O
at	O
priors	O
based	O
on	O
markov	O
random	O
ﬁelds	O
,	O
whose	O
log-likelihood	O
can	O
be	O
described	O
using	O
local	O
neighborhood	B
interaction	O
(	O
or	O
penalty	O
)	O
terms	O
(	O
kindermann	O
and	O
snell	O
1980	O
;	O
geman	O
and	O
geman	O
1984	O
;	O
marroquin	O
,	O
mitter	O
,	O
and	O
poggio	O
1987	O
;	O
li	O
1995	O
;	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
.	O
the	O
use	O
of	O
bayesian	O
modeling	B
has	O
several	O
potential	O
advantages	O
over	O
regularization	O
(	O
see	O
also	O
appendix	O
b	O
)	O
.	O
the	O
ability	O
to	O
model	O
measurement	O
processes	O
statistically	O
enables	O
us	O
to	O
extract	O
the	O
maximum	O
information	O
possible	O
from	O
each	O
measurement	O
,	O
rather	O
than	O
just	O
guessing	O
what	O
weighting	B
to	O
give	O
the	O
data	O
.	O
similarly	O
,	O
the	O
parameters	B
of	O
the	O
prior	B
distribution	I
can	O
often	O
be	O
learned	B
by	O
observing	O
samples	O
from	O
the	O
class	O
we	O
are	O
modeling	B
(	O
roth	O
and	O
black	O
2007a	O
;	O
tappen	O
2007	O
;	O
li	O
and	O
huttenlocher	O
2008	O
)	O
.	O
furthermore	O
,	O
because	O
our	O
model	O
is	O
probabilistic	B
,	O
it	O
is	O
possible	O
to	O
estimate	O
(	O
in	O
principle	O
)	O
complete	O
probability	O
distributions	O
over	O
the	O
unknowns	O
being	O
recovered	O
and	O
,	O
in	O
particular	O
,	O
to	O
model	O
the	O
uncertainty	B
in	O
the	O
solution	O
,	O
which	O
can	O
be	O
useful	O
in	O
latter	O
processing	O
stages	O
.	O
finally	O
,	O
markov	O
random	O
ﬁeld	O
models	O
can	O
be	O
deﬁned	O
over	O
discrete	O
variables	O
,	O
such	O
as	O
image	B
labels	O
(	O
where	O
the	O
variables	O
have	O
no	O
proper	O
ordering	O
)	O
,	O
for	O
which	O
regularization	B
does	O
not	O
apply	O
.	O
recall	B
from	O
(	O
3.68	O
)	O
in	O
section	O
3.4.3	O
(	O
or	O
see	O
appendix	O
b.4	O
)	O
that	O
,	O
according	O
to	O
bayes	O
’	O
rule	O
,	O
the	O
posterior	B
distribution	I
for	O
a	O
given	O
set	O
of	O
measurements	O
y	O
,	O
p	O
(	O
y|x	O
)	O
,	O
combined	O
with	O
a	O
prior	B
p	O
(	O
x	O
)	O
over	O
the	O
unknowns	O
x	O
,	O
is	O
given	O
by	O
p	O
(	O
x|y	O
)	O
=	O
p	O
(	O
y|x	O
)	O
p	O
(	O
x	O
)	O
p	O
(	O
y	O
)	O
,	O
(	O
3.106	O
)	O
where	O
p	O
(	O
y	O
)	O
=	O
(	O
cid:82	O
)	O
x	O
p	O
(	O
y|x	O
)	O
p	O
(	O
x	O
)	O
is	O
a	O
normalizing	B
constant	O
used	O
to	O
make	O
the	O
p	O
(	O
x|y	O
)	O
distribution	O
proper	O
(	O
integrate	O
to	O
1	O
)	O
.	O
taking	O
the	O
negative	O
logarithm	O
of	O
both	O
sides	O
of	O
(	O
3.106	O
)	O
,	O
we	O
get	O
−	O
log	O
p	O
(	O
x|y	O
)	O
=	O
−	O
log	O
p	O
(	O
y|x	O
)	O
−	O
log	O
p	O
(	O
x	O
)	O
+	O
c	O
,	O
(	O
3.107	O
)	O
which	O
is	O
the	O
negative	O
posterior	O
log	O
likelihood	O
.	O
to	O
ﬁnd	O
the	O
most	O
likely	O
(	O
maximum	O
a	O
posteriori	O
or	O
map	O
)	O
solution	O
x	O
given	O
some	O
measure-	O
ments	O
y	O
,	O
we	O
simply	O
minimize	O
this	O
negative	O
log	O
likelihood	O
,	O
which	O
can	O
also	O
be	O
thought	O
of	O
as	O
an	O
energy	O
,	O
e	O
(	O
x	O
,	O
y	O
)	O
=	O
ed	O
(	O
x	O
,	O
y	O
)	O
+	O
ep	O
(	O
x	O
)	O
.	O
(	O
3.108	O
)	O
(	O
we	O
drop	O
the	O
constant	O
c	O
because	O
its	O
value	O
does	O
not	O
matter	O
during	O
energy	O
minimization	O
.	O
)	O
the	O
ﬁrst	O
term	O
ed	O
(	O
x	O
,	O
y	O
)	O
is	O
the	O
data	O
energy	O
or	O
data	O
penalty	O
;	O
it	O
measures	O
the	O
negative	O
log	O
likelihood	O
3.7	O
global	B
optimization	I
181	O
that	O
the	O
data	O
were	O
observed	O
given	O
the	O
unknown	O
state	O
x.	O
the	O
second	O
term	O
ep	O
(	O
x	O
)	O
is	O
the	O
prior	B
energy	O
;	O
it	O
plays	O
a	O
role	O
analogous	O
to	O
the	O
smoothness	B
energy	O
in	O
regularization	B
.	O
note	O
that	O
the	O
map	O
estimate	O
may	O
not	O
always	O
be	O
desirable	O
,	O
since	O
it	O
selects	O
the	O
“	O
peak	O
”	O
in	O
the	O
posterior	O
dis-	O
tribution	O
rather	O
than	O
some	O
more	O
stable	O
statistic—see	O
the	O
discussion	O
in	O
appendix	O
b.2	O
and	O
by	O
levin	O
,	O
weiss	O
,	O
durand	O
et	O
al	O
.	O
(	O
2009	O
)	O
.	O
for	O
image	O
processing	O
applications	O
,	O
the	O
unknowns	O
x	O
are	O
the	O
set	O
of	O
output	O
pixels	O
and	O
the	O
data	O
are	O
(	O
in	O
the	O
simplest	O
case	O
)	O
the	O
input	O
pixels	O
x	O
=	O
[	O
f	O
(	O
0	O
,	O
0	O
)	O
.	O
.	O
.	O
f	O
(	O
m	O
−	O
1	O
,	O
n	O
−	O
1	O
)	O
]	O
,	O
y	O
=	O
[	O
d	O
(	O
0	O
,	O
0	O
)	O
.	O
.	O
.	O
d	O
(	O
m	O
−	O
1	O
,	O
n	O
−	O
1	O
)	O
]	O
as	O
shown	O
in	O
figure	O
3.56.	O
for	O
a	O
markov	O
random	O
ﬁeld	O
,	O
the	O
probability	O
p	O
(	O
x	O
)	O
is	O
a	O
gibbs	O
or	O
boltzmann	O
distribution	O
,	O
whose	O
negative	O
log	O
likelihood	O
(	O
according	O
to	O
the	O
hammersley–clifford	O
theorem	O
)	O
can	O
be	O
writ-	O
ten	O
as	O
a	O
sum	O
of	O
pairwise	O
interaction	O
potentials	O
,	O
ep	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
{	O
(	O
i	O
,	O
j	O
)	O
,	O
(	O
k	O
,	O
l	O
)	O
}	O
∈n	O
vi	O
,	O
j	O
,	O
k	O
,	O
l	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
,	O
f	O
(	O
k	O
,	O
l	O
)	O
)	O
,	O
(	O
3.109	O
)	O
where	O
n	O
(	O
i	O
,	O
j	O
)	O
denotes	O
the	O
neighbors	O
of	O
pixel	O
(	O
i	O
,	O
j	O
)	O
.	O
in	O
fact	O
,	O
the	O
general	O
version	O
of	O
the	O
theorem	O
says	O
that	O
the	O
energy	O
may	O
have	O
to	O
be	O
evaluated	O
over	O
a	O
larger	O
set	O
of	O
cliques	B
,	O
which	O
depend	O
on	O
the	O
order	B
of	O
the	O
markov	O
random	O
ﬁeld	O
(	O
kindermann	O
and	O
snell	O
1980	O
;	O
geman	O
and	O
geman	O
1984	O
;	O
bishop	O
2006	O
;	O
kohli	O
,	O
ladick´y	O
,	O
and	O
torr	O
2009	O
;	O
kohli	O
,	O
kumar	O
,	O
and	O
torr	O
2009	O
)	O
.	O
the	O
most	O
commonly	O
used	O
neighborhood	B
in	O
markov	O
random	O
ﬁeld	O
modeling	B
is	O
the	O
n4	O
neighborhood	B
,	O
where	O
each	O
pixel	O
in	O
the	O
ﬁeld	O
f	O
(	O
i	O
,	O
j	O
)	O
interacts	O
only	O
with	O
its	O
immediate	O
neigh-	O
bors	O
.	O
the	O
model	O
in	O
figure	O
3.56	O
,	O
which	O
we	O
previously	O
used	O
in	O
figure	O
3.55	O
to	O
illustrate	O
the	O
discrete	B
version	O
of	O
ﬁrst-order	O
regularization	B
,	O
shows	O
an	O
n4	O
mrf	O
.	O
the	O
sx	O
(	O
i	O
,	O
j	O
)	O
and	O
sy	O
(	O
i	O
,	O
j	O
)	O
black	O
boxes	O
denote	O
arbitrary	O
interaction	O
potentials	O
between	O
adjacent	O
nodes	O
in	O
the	O
random	O
ﬁeld	O
and	O
the	O
w	O
(	O
i	O
,	O
j	O
)	O
denote	O
the	O
data	O
penalty	O
functions	O
.	O
these	O
square	O
nodes	O
can	O
also	O
be	O
inter-	O
preted	O
as	O
factors	O
in	O
a	O
factor	O
graph	O
version	O
of	O
the	O
(	O
undirected	O
)	O
graphical	O
model	O
(	O
bishop	O
2006	O
)	O
,	O
which	O
is	O
another	O
name	O
for	O
interaction	O
potentials	O
.	O
(	O
strictly	O
speaking	O
,	O
the	O
factors	O
are	O
(	O
improper	O
)	O
probability	O
functions	O
whose	O
product	O
is	O
the	O
(	O
un-normalized	O
)	O
posterior	B
distribution	I
.	O
)	O
as	O
we	O
will	O
see	O
in	O
(	O
3.112–3.113	O
)	O
,	O
there	O
is	O
a	O
close	O
relationship	O
between	O
these	O
interaction	O
potentials	O
and	O
the	O
discretized	O
versions	O
of	O
regularized	O
image	B
restoration	I
problems	O
.	O
thus	O
,	O
to	O
a	O
ﬁrst	O
approximation	O
,	O
we	O
can	O
view	O
energy	O
minimization	O
being	O
performed	O
when	O
solving	O
a	O
regularized	O
problem	O
and	O
the	O
maximum	O
a	O
posteriori	O
inference	B
being	O
performed	O
in	O
an	O
mrf	O
as	O
equivalent	O
.	O
while	O
n4	O
neighborhoods	O
are	O
most	O
commonly	O
used	O
,	O
in	O
some	O
applications	O
n8	O
(	O
or	O
even	O
higher	O
order	O
)	O
neighborhoods	O
perform	O
better	O
at	O
tasks	O
such	O
as	O
image	B
segmentation	O
because	O
182	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
3.56	O
graphical	O
model	O
for	O
an	O
n4	O
neighborhood	B
markov	O
random	O
ﬁeld	O
.	O
(	O
the	O
blue	O
edges	O
are	O
added	O
for	O
an	O
n8	O
neighborhood	B
.	O
)	O
the	O
white	O
circles	O
are	O
the	O
unknowns	O
f	O
(	O
i	O
,	O
j	O
)	O
,	O
while	O
the	O
dark	O
circles	O
are	O
the	O
input	O
data	O
d	O
(	O
i	O
,	O
j	O
)	O
.	O
the	O
sx	O
(	O
i	O
,	O
j	O
)	O
and	O
sy	O
(	O
i	O
,	O
j	O
)	O
black	O
boxes	O
denote	O
arbi-	O
trary	O
interaction	O
potentials	O
between	O
adjacent	O
nodes	O
in	O
the	O
random	O
ﬁeld	O
,	O
and	O
the	O
w	O
(	O
i	O
,	O
j	O
)	O
denote	O
the	O
data	O
penalty	O
functions	O
.	O
the	O
same	O
graphical	O
model	O
can	O
be	O
used	O
to	O
depict	O
a	O
discrete	B
version	O
of	O
a	O
ﬁrst-order	O
regularization	B
problem	O
(	O
figure	O
3.55	O
)	O
.	O
they	O
can	O
better	O
model	O
discontinuities	O
at	O
different	O
orientations	O
(	O
boykov	O
and	O
kolmogorov	O
2003	O
;	O
rother	O
,	O
kohli	O
,	O
feng	O
et	O
al	O
.	O
2009	O
;	O
kohli	O
,	O
ladick´y	O
,	O
and	O
torr	O
2009	O
;	O
kohli	O
,	O
kumar	O
,	O
and	O
torr	O
2009	O
)	O
.	O
binary	O
mrfs	O
the	O
simplest	O
possible	O
example	O
of	O
a	O
markov	O
random	O
ﬁeld	O
is	O
a	O
binary	O
ﬁeld	O
.	O
examples	B
of	O
such	O
ﬁelds	O
include	O
1-bit	O
(	O
black	O
and	O
white	O
)	O
scanned	O
document	O
images	O
as	O
well	O
as	O
images	O
segmented	O
into	O
foreground	O
and	O
background	O
regions	O
.	O
to	O
denoise	O
a	O
scanned	O
image	B
,	O
we	O
set	O
the	O
data	O
penalty	O
to	O
reﬂect	O
the	O
agreement	O
between	O
the	O
scanned	O
and	O
ﬁnal	O
images	O
,	O
ed	O
(	O
i	O
,	O
j	O
)	O
=	O
wδ	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
,	O
d	O
(	O
i	O
,	O
j	O
)	O
)	O
(	O
3.110	O
)	O
and	O
the	O
smoothness	B
penalty	O
to	O
reﬂect	O
the	O
agreement	O
between	O
neighboring	O
pixels	O
ep	O
(	O
i	O
,	O
j	O
)	O
=	O
ex	O
(	O
i	O
,	O
j	O
)	O
+	O
ey	O
(	O
i	O
,	O
j	O
)	O
=	O
sδ	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
,	O
f	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
)	O
+	O
sδ	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
,	O
f	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
)	O
.	O
(	O
3.111	O
)	O
once	O
we	O
have	O
formulated	O
the	O
energy	O
,	O
how	O
do	O
we	O
minimize	O
it	O
?	O
the	O
simplest	O
approach	O
is	O
to	O
perform	O
gradient	B
descent	I
,	O
ﬂipping	O
one	O
state	O
at	O
a	O
time	O
if	O
it	O
produces	O
a	O
lower	O
energy	O
.	O
this	O
ap-	O
proach	O
is	O
known	O
as	O
contextual	O
classiﬁcation	O
(	O
kittler	O
and	O
f¨oglein	O
1984	O
)	O
,	O
iterated	B
conditional	I
modes	I
(	O
icm	O
)	O
(	O
besag	O
1986	O
)	O
,	O
or	O
highest	B
conﬁdence	I
ﬁrst	I
(	O
hcf	O
)	O
(	O
chou	O
and	O
brown	O
1990	O
)	O
if	O
the	O
pixel	O
with	O
the	O
largest	O
energy	O
decrease	O
is	O
selected	O
ﬁrst	O
.	O
unfortunately	O
,	O
these	O
downhill	O
methods	O
tend	O
to	O
get	O
easily	O
stuck	O
in	O
local	B
minima	O
.	O
an	O
al-	O
ternative	O
approach	O
is	O
to	O
add	O
some	O
randomness	O
to	O
the	O
process	O
,	O
which	O
is	O
known	O
as	O
stochastic	O
f	O
(	O
i	O
,	O
j	O
)	O
sx	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i	O
,	O
j+1	O
)	O
sy	O
(	O
i	O
,	O
j	O
)	O
w	O
(	O
i	O
,	O
j	O
)	O
d	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j+1	O
)	O
3.7	O
global	B
optimization	I
183	O
gradient	B
descent	I
(	O
metropolis	O
,	O
rosenbluth	O
,	O
rosenbluth	O
et	O
al	O
.	O
1953	O
;	O
geman	O
and	O
geman	O
1984	O
)	O
.	O
when	O
the	O
amount	O
of	O
noise	B
is	O
decreased	O
over	O
time	O
,	O
this	O
technique	O
is	O
known	O
as	O
simulated	O
an-	O
nealing	O
(	O
kirkpatrick	O
,	O
gelatt	O
,	O
and	O
vecchi	O
1983	O
;	O
carnevali	O
,	O
coletti	O
,	O
and	O
patarnello	O
1985	O
;	O
wol-	O
berg	O
and	O
pavlidis	O
1985	O
;	O
swendsen	O
and	O
wang	O
1987	O
)	O
and	O
was	O
ﬁrst	O
popularized	O
in	O
computer	O
vision	O
by	O
geman	O
and	O
geman	O
(	O
1984	O
)	O
and	O
later	O
applied	O
to	O
stereo	B
matching	I
by	O
barnard	O
(	O
1989	O
)	O
,	O
among	O
others	O
.	O
even	O
this	O
technique	O
,	O
however	O
,	O
does	O
not	O
perform	O
that	O
well	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
.	O
for	O
binary	O
images	O
,	O
a	O
much	O
better	O
technique	O
,	O
introduced	O
to	O
the	O
computer	O
vision	O
com-	O
munity	O
by	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
(	O
2001	O
)	O
is	O
to	O
re-formulate	O
the	O
energy	O
minimization	O
as	O
a	O
max-ﬂow/min-cut	O
graph	O
optimization	O
problem	O
(	O
greig	O
,	O
porteous	O
,	O
and	O
seheult	O
1989	O
)	O
.	O
this	O
technique	O
has	O
informally	O
come	O
to	O
be	O
known	O
as	O
graph	B
cuts	I
in	O
the	O
computer	O
vision	O
community	O
(	O
boykov	O
and	O
kolmogorov	O
2010	O
)	O
.	O
for	O
simple	O
energy	O
functions	O
,	O
e.g.	O
,	O
those	O
where	O
the	O
penalty	O
for	O
non-identical	O
neighboring	O
pixels	O
is	O
a	O
constant	O
,	O
this	O
algorithm	B
is	O
guaranteed	O
to	O
produce	O
the	O
global	B
minimum	O
.	O
kolmogorov	O
and	O
zabih	O
(	O
2004	O
)	O
formally	O
characterize	O
the	O
class	O
of	O
binary	O
energy	O
potentials	O
(	O
regularity	O
conditions	O
)	O
for	O
which	O
these	O
results	O
hold	O
,	O
while	O
newer	O
work	O
by	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
(	O
2008	O
)	O
and	O
rother	O
,	O
kolmogorov	O
,	O
lempitsky	O
et	O
al	O
.	O
(	O
2007	O
)	O
provide	O
good	O
algorithms	O
for	O
the	O
cases	O
when	O
they	O
do	O
not	O
.	O
in	O
addition	O
to	O
the	O
above	O
mentioned	O
techniques	O
,	O
a	O
number	O
of	O
other	O
optimization	O
approaches	O
have	O
been	O
developed	O
for	O
mrf	O
energy	O
minimization	O
,	O
such	O
as	O
(	O
loopy	O
)	O
belief	B
propagation	I
and	O
dynamic	B
programming	I
(	O
for	O
one-dimensional	O
problems	O
)	O
.	O
these	O
are	O
discussed	O
in	O
more	O
detail	O
in	O
appendix	O
b.5	O
as	O
well	O
as	O
the	O
comparative	O
survey	O
paper	O
by	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
ordinal-valued	O
mrfs	O
in	O
addition	O
to	O
binary	O
images	O
,	O
markov	O
random	O
ﬁelds	O
can	O
be	O
applied	O
to	O
ordinal-valued	O
labels	O
such	O
as	O
grayscale	O
images	O
or	O
depth	O
maps	O
.	O
the	O
term	O
”	O
ordinal	O
”	O
indicates	O
that	O
the	O
labels	O
have	O
an	O
implied	O
ordering	O
,	O
e.g.	O
,	O
that	O
higher	O
values	O
are	O
lighter	O
pixels	O
.	O
in	O
the	O
next	O
section	O
,	O
we	O
look	O
at	O
unordered	O
labels	O
,	O
such	O
as	O
source	O
image	B
labels	O
for	O
image	O
compositing	B
.	O
in	O
many	O
cases	O
,	O
it	O
is	O
common	O
to	O
extend	O
the	O
binary	O
data	O
and	O
smoothness	B
prior	O
terms	O
as	O
ed	O
(	O
i	O
,	O
j	O
)	O
=	O
w	O
(	O
i	O
,	O
j	O
)	O
ρd	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
d	O
(	O
i	O
,	O
j	O
)	O
)	O
(	O
3.112	O
)	O
and	O
ep	O
(	O
i	O
,	O
j	O
)	O
=	O
sx	O
(	O
i	O
,	O
j	O
)	O
ρp	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
f	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
)	O
+	O
sy	O
(	O
i	O
,	O
j	O
)	O
ρp	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
f	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
)	O
,	O
(	O
3.113	O
)	O
which	O
are	O
robust	B
generalizations	O
of	O
the	O
quadratic	O
penalty	O
terms	O
(	O
3.101	O
)	O
and	O
(	O
3.100	O
)	O
,	O
ﬁrst	O
introduced	O
in	O
(	O
3.105	O
)	O
.	O
as	O
before	O
,	O
the	O
w	O
(	O
i	O
,	O
j	O
)	O
,	O
sx	O
(	O
i	O
,	O
j	O
)	O
and	O
sy	O
(	O
i	O
,	O
j	O
)	O
weights	O
can	O
be	O
used	O
to	O
locally	O
control	O
the	O
data	O
weighting	O
and	O
the	O
horizontal	O
and	O
vertical	O
smoothness	B
.	O
instead	O
of	O
184	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
3.57	O
grayscale	O
image	B
denoising	O
and	O
inpainting	B
:	O
(	O
a	O
)	O
original	O
image	B
;	O
(	O
b	O
)	O
image	B
corrupted	O
by	O
noise	O
and	O
with	O
missing	O
data	O
(	O
black	O
bar	O
)	O
;	O
(	O
c	O
)	O
image	B
restored	O
using	O
loopy	O
be-	O
lief	O
propagation	O
;	O
(	O
d	O
)	O
image	B
restored	O
using	O
expansion	O
move	O
graph	B
cuts	I
.	O
images	O
are	O
from	O
http	O
:	O
//vision.middlebury.edu/mrf/results/	O
(	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
.	O
using	O
a	O
quadratic	O
penalty	O
,	O
however	O
,	O
a	O
general	O
monotonically	O
increasing	O
penalty	O
function	O
ρ	O
(	O
)	O
is	O
used	O
.	O
(	O
different	O
functions	O
can	O
be	O
used	O
for	O
the	O
data	O
and	O
smoothness	B
terms	O
.	O
)	O
for	O
example	O
,	O
ρp	O
can	O
be	O
a	O
hyper-laplacian	O
penalty	O
ρp	O
(	O
d	O
)	O
=	O
|d|p	O
,	O
p	O
<	O
1	O
,	O
(	O
3.114	O
)	O
which	O
better	O
encodes	O
the	O
distribution	O
of	O
gradients	O
(	O
mainly	O
edges	O
)	O
in	O
an	O
image	B
than	O
either	O
a	O
quadratic	O
or	O
linear	B
(	O
total	B
variation	I
)	O
penalty.24	O
levin	O
and	O
weiss	O
(	O
2007	O
)	O
use	O
such	O
a	O
penalty	O
to	O
separate	O
a	O
transmitted	O
and	O
reﬂected	O
image	B
(	O
figure	O
8.17	O
)	O
by	O
encouraging	O
gradients	O
to	O
lie	O
in	O
one	O
or	O
the	O
other	O
image	B
,	O
but	O
not	O
both	O
.	O
more	O
recently	O
,	O
levin	O
,	O
fergus	O
,	O
durand	O
et	O
al	O
.	O
(	O
2007	O
)	O
use	O
the	O
hyper-laplacian	O
as	O
a	O
prior	B
for	O
image	B
deconvolution	O
(	O
deblurring	O
)	O
and	O
krishnan	O
and	O
fergus	O
(	O
2009	O
)	O
develop	O
a	O
faster	O
algorithm	B
for	O
solving	O
such	O
problems	O
.	O
for	O
the	O
data	O
penalty	O
,	O
ρd	O
can	O
be	O
quadratic	O
(	O
to	O
model	O
gaussian	O
noise	B
)	O
or	O
the	O
log	O
of	O
a	O
contaminated	O
gaussian	O
(	O
appendix	O
b.3	O
)	O
.	O
when	O
ρp	O
is	O
a	O
quadratic	O
function	O
,	O
the	O
resulting	O
markov	O
random	O
ﬁeld	O
is	O
called	O
a	O
gaussian	O
markov	O
random	O
ﬁeld	O
(	O
gmrf	O
)	O
and	O
its	O
minimum	O
can	O
be	O
found	O
by	O
sparse	O
linear	B
system	O
solving	O
(	O
3.103	O
)	O
.	O
when	O
the	O
weighting	B
functions	O
are	O
uniform	O
,	O
the	O
gmrf	O
becomes	O
a	O
special	O
case	O
of	O
wiener	O
ﬁltering	O
(	O
section	O
3.4.3	O
)	O
.	O
allowing	O
the	O
weighting	B
functions	O
to	O
depend	O
on	O
the	O
input	O
image	B
(	O
a	O
special	O
kind	O
of	O
conditional	O
random	O
ﬁeld	O
,	O
which	O
we	O
describe	O
below	O
)	O
enables	O
quite	O
sophisticated	O
image	B
processing	O
algorithms	O
to	O
be	O
performed	O
,	O
including	O
colorization	B
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2004	O
)	O
,	O
interactive	B
tone	O
mapping	O
(	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
2006a	O
)	O
,	O
natural	B
image	O
matting	B
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2008	O
)	O
,	O
and	O
image	B
restoration	I
(	O
tappen	O
,	O
liu	O
,	O
freeman	O
et	O
al	O
.	O
2007	O
)	O
.	O
24	O
note	O
that	O
,	O
unlike	O
a	O
quadratic	O
penalty	O
,	O
the	O
sum	O
of	O
the	O
horizontal	O
and	O
vertical	O
derivative	O
p-norms	O
is	O
not	O
rotationally	O
invariant	O
.	O
a	O
better	O
approach	O
may	O
be	O
to	O
locally	O
estimate	O
the	O
gradient	O
direction	O
and	O
to	O
impose	O
different	O
norms	O
on	O
the	O
perpendicular	O
and	O
parallel	O
components	O
,	O
which	O
roth	O
and	O
black	O
(	O
2007b	O
)	O
call	O
a	O
steerable	B
random	O
ﬁeld	O
.	O
3.7	O
global	B
optimization	I
185	O
(	O
b	O
)	O
standard	O
move	O
(	O
a	O
)	O
initial	O
labeling	O
(	O
d	O
)	O
α-expansion	O
figure	O
3.58	O
multi-level	O
graph	O
optimization	O
from	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
initial	O
problem	O
conﬁguration	O
;	O
(	O
b	O
)	O
the	O
standard	O
move	O
only	O
changes	O
one	O
pixel	O
;	O
(	O
c	O
)	O
the	O
α-β-swap	O
optimally	O
exchanges	O
all	O
α	O
and	O
β-labeled	O
pixels	O
;	O
(	O
d	O
)	O
the	O
α-expansion	O
move	O
optimally	O
selects	O
among	O
current	O
pixel	O
values	O
and	O
the	O
α	O
label	O
.	O
(	O
c	O
)	O
α-β-swap	O
when	O
ρd	O
or	O
ρp	O
are	O
non-quadratic	O
functions	O
,	O
gradient	B
descent	I
techniques	O
such	O
as	O
non-	O
linear	B
least	O
squares	O
or	O
iteratively	O
re-weighted	O
least	B
squares	I
can	O
sometimes	O
be	O
used	O
(	O
ap-	O
pendix	O
a.3	O
)	O
.	O
however	O
,	O
if	O
the	O
search	O
space	O
has	O
lots	O
of	O
local	B
minima	O
,	O
as	O
is	O
the	O
case	O
for	O
stereo	O
matching	B
(	O
barnard	O
1989	O
;	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
,	O
more	O
sophisticated	O
techniques	O
are	O
required	O
.	O
the	O
extension	O
of	O
graph	B
cut	I
techniques	O
to	O
multi-valued	O
problems	O
was	O
ﬁrst	O
proposed	O
by	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
(	O
2001	O
)	O
.	O
in	O
their	O
paper	O
,	O
they	O
develop	O
two	O
different	O
algorithms	O
,	O
called	O
the	O
swap	O
move	O
and	O
the	O
expansion	B
move	I
,	O
which	O
iterate	O
among	O
a	O
series	O
of	O
binary	O
labeling	O
sub-problems	O
to	O
ﬁnd	O
a	O
good	O
solution	O
(	O
figure	O
3.58	O
)	O
.	O
note	O
that	O
a	O
global	B
solution	O
is	O
generally	O
not	O
achievable	O
,	O
as	O
the	O
problem	O
is	O
provably	O
np-hard	O
for	O
general	O
energy	O
functions	O
.	O
because	O
both	O
these	O
algorithms	O
use	O
a	O
binary	O
mrf	O
optimization	O
inside	O
their	O
inner	O
loop	O
,	O
they	O
are	O
subject	O
to	O
the	O
kind	O
of	O
constraints	O
on	O
the	O
energy	O
functions	O
that	O
occur	O
in	O
the	O
binary	O
labeling	O
case	O
(	O
kolmogorov	O
and	O
zabih	O
2004	O
)	O
.	O
appendix	O
b.5.4	O
discusses	O
these	O
algorithms	O
in	O
more	O
detail	O
,	O
along	O
with	O
some	O
more	O
recently	O
developed	O
approaches	O
to	O
this	O
problem	O
.	O
another	O
mrf	O
inference	B
technique	O
is	O
belief	B
propagation	I
(	O
bp	O
)	O
.	O
while	O
belief	B
propagation	I
was	O
originally	O
developed	O
for	O
inference	O
over	O
trees	O
,	O
where	O
it	O
is	O
exact	O
(	O
pearl	O
1988	O
)	O
,	O
it	O
has	O
more	O
recently	O
been	O
applied	O
to	O
graphs	O
with	O
loops	O
such	O
as	O
markov	O
random	O
ﬁelds	O
(	O
freeman	O
,	O
pasz-	O
tor	O
,	O
and	O
carmichael	O
2000	O
;	O
yedidia	O
,	O
freeman	O
,	O
and	O
weiss	O
2001	O
)	O
.	O
in	O
fact	O
,	O
some	O
of	O
the	O
better	O
performing	O
stereo-matching	O
algorithms	O
use	O
loopy	B
belief	I
propagation	I
(	O
lbp	O
)	O
to	O
perform	O
their	O
inference	B
(	O
sun	O
,	O
zheng	O
,	O
and	O
shum	O
2003	O
)	O
.	O
lbp	O
is	O
discussed	O
in	O
more	O
detail	O
in	O
appendix	O
b.5.3	O
as	O
well	O
as	O
the	O
comparative	O
survey	O
paper	O
on	O
mrf	O
optimization	O
(	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
.	O
figure	O
3.57	O
shows	O
an	O
example	O
of	O
image	B
denoising	O
and	O
inpainting	B
(	O
hole	B
ﬁlling	I
)	O
using	O
a	O
non-quadratic	O
energy	O
function	O
(	O
non-gaussian	O
mrf	O
)	O
.	O
the	O
original	O
image	B
has	O
been	O
corrupted	O
by	O
noise	O
and	O
a	O
portion	O
of	O
the	O
data	O
has	O
been	O
removed	O
(	O
the	O
black	O
bar	O
)	O
.	O
in	O
this	O
case	O
,	O
the	O
loopy	O
186	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
3.59	O
graphical	O
model	O
for	O
a	O
markov	O
random	O
ﬁeld	O
with	O
a	O
more	O
complex	O
measurement	O
model	O
.	O
the	O
additional	O
colored	O
edges	O
show	O
how	O
combinations	O
of	O
unknown	O
values	O
(	O
say	O
,	O
in	O
a	O
sharp	O
image	B
)	O
produce	O
the	O
measured	O
values	O
(	O
a	O
noisy	O
blurred	O
image	B
)	O
.	O
the	O
resulting	O
graphical	O
model	O
is	O
still	O
a	O
classic	O
mrf	O
and	O
is	O
just	O
as	O
easy	O
to	O
sample	O
from	O
,	O
but	O
some	O
inference	B
algorithms	O
(	O
e.g.	O
,	O
those	O
based	O
on	O
graph	B
cuts	I
)	O
may	O
not	O
be	O
applicable	O
because	O
of	O
the	O
increased	O
network	O
complexity	O
,	O
since	O
state	O
changes	O
during	O
the	O
inference	B
become	O
more	O
entangled	O
and	O
the	O
posterior	O
mrf	O
has	O
much	O
larger	O
cliques	B
.	O
belief	B
propagation	I
algorithm	O
computes	O
a	O
slightly	O
lower	O
energy	O
and	O
also	O
a	O
smoother	O
image	B
than	O
the	O
alpha-expansion	O
graph	B
cut	I
algorithm	O
.	O
of	O
course	O
,	O
the	O
above	O
formula	O
(	O
3.113	O
)	O
for	O
the	O
smoothness	B
term	O
ep	O
(	O
i	O
,	O
j	O
)	O
just	O
shows	O
the	O
simplest	O
case	O
.	O
in	O
more	O
recent	O
work	O
,	O
roth	O
and	O
black	O
(	O
2009	O
)	O
propose	O
a	O
field	O
of	O
experts	O
(	O
foe	O
)	O
model	O
,	O
which	O
sums	O
up	O
a	O
large	O
number	O
of	O
exponentiated	O
local	B
ﬁlter	O
outputs	O
to	O
arrive	O
at	O
the	O
smoothness	B
penalty	O
.	O
weiss	O
and	O
freeman	O
(	O
2007	O
)	O
analyze	O
this	O
approach	O
and	O
compare	O
it	O
to	O
the	O
simpler	O
hyper-laplacian	O
model	O
of	O
natural	B
image	O
statistics	O
.	O
lyu	O
and	O
simoncelli	O
(	O
2009	O
)	O
use	O
gaussian	O
scale	O
mixtures	O
(	O
gsms	O
)	O
to	O
construct	O
an	O
inhomogeneous	O
multi-scale	O
mrf	O
,	O
with	O
one	O
(	O
positive	O
exponential	O
)	O
gmrf	O
modulating	O
the	O
variance	O
(	O
amplitude	O
)	O
of	O
another	O
gaussian	O
mrf	O
.	O
it	O
is	O
also	O
possible	O
to	O
extend	O
the	O
measurement	O
model	O
to	O
make	O
the	O
sampled	O
(	O
noise-corrupted	O
)	O
input	O
pixels	O
correspond	O
to	O
blends	O
of	O
unknown	O
(	O
latent	O
)	O
image	B
pixels	O
,	O
as	O
in	O
figure	O
3.59.	O
this	O
is	O
the	O
commonly	O
occurring	O
case	O
when	O
trying	O
to	O
de-blur	O
an	O
image	B
.	O
while	O
this	O
kind	O
of	O
a	O
model	O
is	O
still	O
a	O
traditional	O
generative	O
markov	O
random	O
ﬁeld	O
,	O
ﬁnding	O
an	O
optimal	O
solution	O
can	O
be	O
difﬁcult	O
because	O
the	O
clique	O
sizes	O
get	O
larger	O
.	O
in	O
such	O
situations	O
,	O
gradient	B
descent	I
techniques	O
,	O
such	O
as	O
iteratively	B
reweighted	I
least	O
squares	O
,	O
can	O
be	O
used	O
(	O
joshi	O
,	O
zitnick	O
,	O
szeliski	O
et	O
al	O
.	O
2009	O
)	O
.	O
exercise	O
3.31	O
has	O
you	O
explore	O
some	O
of	O
these	O
issues	O
.	O
f	O
(	O
i	O
,	O
j	O
)	O
sx	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i	O
,	O
j+1	O
)	O
sy	O
(	O
i	O
,	O
j	O
)	O
w	O
(	O
i	O
,	O
j	O
)	O
d	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j+1	O
)	O
d	O
(	O
i	O
,	O
j+1	O
)	O
3.7	O
global	B
optimization	I
187	O
figure	O
3.60	O
an	O
unordered	O
label	O
mrf	O
(	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
strokes	O
in	O
each	O
of	O
the	O
source	O
images	O
on	O
the	O
left	O
are	O
used	O
as	O
constraints	O
on	O
an	O
mrf	O
optimization	O
,	O
which	O
is	O
solved	O
using	O
graph	O
cuts	O
.	O
the	O
resulting	O
multi-valued	O
label	O
ﬁeld	O
is	O
shown	O
as	O
a	O
color	B
overlay	O
in	O
the	O
middle	O
image	B
,	O
and	O
the	O
ﬁnal	O
composite	O
is	O
shown	O
on	O
the	O
right	O
.	O
unordered	O
labels	O
another	O
case	O
with	O
multi-valued	O
labels	O
where	O
markov	O
random	O
ﬁelds	O
are	O
often	O
applied	O
are	O
unordered	O
labels	O
,	O
i.e.	O
,	O
labels	O
where	O
there	O
is	O
no	O
semantic	O
meaning	O
to	O
the	O
numerical	O
difference	B
between	O
the	O
values	O
of	O
two	O
labels	O
.	O
for	O
example	O
,	O
if	O
we	O
are	O
classifying	O
terrain	O
from	O
aerial	O
imagery	O
,	O
it	O
makes	O
no	O
sense	O
to	O
take	O
the	O
numeric	O
difference	B
between	O
the	O
labels	O
assigned	O
to	O
forest	O
,	O
ﬁeld	O
,	O
water	O
,	O
and	O
pavement	O
.	O
in	O
fact	O
,	O
the	O
adjacencies	O
of	O
these	O
various	O
kinds	O
of	O
terrain	O
each	O
have	O
different	O
likelihoods	O
,	O
so	O
it	O
makes	O
more	O
sense	O
to	O
use	O
a	O
prior	B
of	O
the	O
form	O
ep	O
(	O
i	O
,	O
j	O
)	O
=	O
sx	O
(	O
i	O
,	O
j	O
)	O
v	O
(	O
l	O
(	O
i	O
,	O
j	O
)	O
,	O
l	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
)	O
+	O
sy	O
(	O
i	O
,	O
j	O
)	O
v	O
(	O
l	O
(	O
i	O
,	O
j	O
)	O
,	O
l	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
)	O
,	O
(	O
3.115	O
)	O
where	O
v	O
(	O
l0	O
,	O
l1	O
)	O
is	O
a	O
general	O
compatibility	O
or	O
potential	O
function	O
.	O
(	O
note	O
that	O
we	O
have	O
also	O
replaced	O
f	O
(	O
i	O
,	O
j	O
)	O
with	O
l	O
(	O
i	O
,	O
j	O
)	O
to	O
make	O
it	O
clearer	O
that	O
these	O
are	O
labels	O
rather	O
than	O
discrete	B
function	O
samples	O
.	O
)	O
an	O
alternative	O
way	O
to	O
write	O
this	O
prior	B
energy	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
;	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
is	O
ep	O
=	O
(	O
cid:88	O
)	O
(	O
p	O
,	O
q	O
)	O
∈n	O
vp	O
,	O
q	O
(	O
lp	O
,	O
lq	O
)	O
,	O
(	O
3.116	O
)	O
where	O
the	O
(	O
p	O
,	O
q	O
)	O
are	O
neighboring	O
pixels	O
and	O
a	O
spatially	O
varying	O
potential	O
function	O
vp	O
,	O
q	O
is	O
eval-	O
uated	O
for	O
each	O
neighboring	O
pair	O
.	O
an	O
important	O
application	O
of	O
unordered	O
mrf	O
labeling	O
is	O
seam	O
ﬁnding	O
in	O
image	B
composit-	O
ing	O
(	O
davis	O
1998	O
;	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
(	O
see	O
figure	O
3.60	O
,	O
which	O
is	O
explained	O
in	O
more	O
detail	O
in	O
section	O
9.3.2	O
)	O
.	O
here	O
,	O
the	O
compatibility	O
vp	O
,	O
q	O
(	O
lp	O
,	O
lq	O
)	O
measures	O
the	O
quality	O
of	O
the	O
visual	O
appearance	O
that	O
would	O
result	O
from	O
placing	O
a	O
pixel	O
p	O
from	O
image	B
lp	O
next	O
to	O
a	O
pixel	O
q	O
from	O
image	B
lq	O
.	O
as	O
with	O
most	O
mrfs	O
,	O
we	O
assume	O
that	O
vp	O
,	O
q	O
(	O
l	O
,	O
l	O
)	O
=	O
0	O
,	O
i.e.	O
,	O
it	O
is	O
per-	O
fectly	O
ﬁne	O
to	O
choose	O
contiguous	O
pixels	O
from	O
the	O
same	O
image	B
.	O
for	O
different	O
labels	O
,	O
however	O
,	O
188	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
3.61	O
image	B
segmentation	O
(	O
boykov	O
and	O
funka-lea	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
:	O
the	O
user	O
draws	O
a	O
few	O
red	O
strokes	O
in	O
the	O
foreground	O
object	O
and	O
a	O
few	O
blue	O
ones	O
in	O
the	O
background	O
.	O
the	O
system	O
computes	O
color	B
distributions	O
for	O
the	O
foreground	O
and	O
background	O
and	O
solves	O
a	O
binary	O
mrf	O
.	O
the	O
smoothness	B
weights	O
are	O
modulated	O
by	O
the	O
intensity	O
gradients	O
(	O
edges	O
)	O
,	O
which	O
makes	O
this	O
a	O
conditional	O
random	O
ﬁeld	O
(	O
crf	O
)	O
.	O
the	O
compatibility	O
vp	O
,	O
q	O
(	O
lp	O
,	O
lq	O
)	O
may	O
depend	O
on	O
the	O
values	O
of	O
the	O
underlying	O
pixels	O
ilp	O
(	O
p	O
)	O
and	O
ilq	O
(	O
q	O
)	O
.	O
consider	O
,	O
for	O
example	O
,	O
where	O
one	O
image	B
i0	O
is	O
all	O
sky	O
blue	O
,	O
i.e.	O
,	O
i0	O
(	O
p	O
)	O
=	O
i0	O
(	O
q	O
)	O
=	O
b	O
,	O
while	O
the	O
other	O
image	B
i1	O
has	O
a	O
transition	O
from	O
sky	O
blue	O
,	O
i1	O
(	O
p	O
)	O
=	O
b	O
,	O
to	O
forest	O
green	O
,	O
i1	O
(	O
q	O
)	O
=	O
g.	O
i0	O
:	O
:	O
i1	O
in	O
this	O
case	O
,	O
vp	O
,	O
q	O
(	O
1	O
,	O
0	O
)	O
=	O
0	O
(	O
the	O
colors	O
agree	O
)	O
,	O
while	O
vp	O
,	O
q	O
(	O
0	O
,	O
1	O
)	O
>	O
0	O
(	O
the	O
colors	O
disagree	O
)	O
.	O
conditional	O
random	O
ﬁelds	O
in	O
a	O
classic	O
bayesian	O
model	O
(	O
3.106–3.108	O
)	O
,	O
p	O
(	O
x|y	O
)	O
∝	O
p	O
(	O
y|x	O
)	O
p	O
(	O
x	O
)	O
,	O
(	O
3.117	O
)	O
the	O
prior	B
distribution	I
p	O
(	O
x	O
)	O
is	O
independent	O
of	O
the	O
observations	O
y.	O
sometimes	O
,	O
however	O
,	O
it	O
is	O
useful	O
to	O
modify	O
our	O
prior	B
assumptions	O
,	O
say	O
about	O
the	O
smoothness	B
of	O
the	O
ﬁeld	O
we	O
are	O
trying	O
to	O
estimate	O
,	O
in	O
response	O
to	O
the	O
sensed	O
data	O
.	O
whether	O
this	O
makes	O
sense	O
from	O
a	O
probability	O
viewpoint	O
is	O
something	O
we	O
discuss	O
once	O
we	O
have	O
explained	O
the	O
new	O
model	O
.	O
consider	O
the	O
interactive	B
image	O
segmentation	B
problem	O
shown	O
in	O
figure	O
3.61	O
(	O
boykov	O
and	O
funka-lea	O
2006	O
)	O
.	O
in	O
this	O
application	O
,	O
the	O
user	O
draws	O
foreground	O
(	O
red	O
)	O
and	O
background	O
(	O
blue	O
)	O
strokes	O
,	O
and	O
the	O
system	O
then	O
solves	O
a	O
binary	O
mrf	O
labeling	O
problem	O
to	O
estimate	O
the	O
extent	O
of	O
the	O
foreground	O
object	O
.	O
in	O
addition	O
to	O
minimizing	O
a	O
data	O
term	O
,	O
which	O
measures	O
the	O
pointwise	O
similarity	B
between	O
pixel	O
colors	O
and	O
the	O
inferred	O
region	B
distributions	O
(	O
section	O
5.5	O
)	O
,	O
the	O
mrf	O
pqpq	O
3.7	O
global	B
optimization	I
189	O
figure	O
3.62	O
graphical	O
model	O
for	O
a	O
conditional	O
random	O
ﬁeld	O
(	O
crf	O
)	O
.	O
the	O
additional	O
green	O
edges	O
show	O
how	O
combinations	O
of	O
sensed	O
data	O
inﬂuence	O
the	O
smoothness	B
in	O
the	O
underlying	O
mrf	O
prior	B
model	O
,	O
i.e.	O
,	O
sx	O
(	O
i	O
,	O
j	O
)	O
and	O
sy	O
(	O
i	O
,	O
j	O
)	O
in	O
(	O
3.113	O
)	O
depend	O
on	O
adjacent	O
d	O
(	O
i	O
,	O
j	O
)	O
values	O
.	O
these	O
additional	O
links	O
(	O
factors	O
)	O
enable	O
the	O
smoothness	B
to	O
depend	O
on	O
the	O
input	O
data	O
.	O
however	O
,	O
they	O
make	O
sampling	B
from	O
this	O
mrf	O
more	O
complex	O
.	O
is	O
modiﬁed	O
so	O
that	O
the	O
smoothness	B
terms	O
sx	O
(	O
x	O
,	O
y	O
)	O
and	O
sy	O
(	O
x	O
,	O
y	O
)	O
in	O
figure	O
3.56	O
and	O
(	O
3.113	O
)	O
depend	O
on	O
the	O
magnitude	O
of	O
the	O
gradient	O
between	O
adjacent	O
pixels.25	O
since	O
the	O
smoothness	B
term	O
now	O
depends	O
on	O
the	O
data	O
,	O
bayes	O
’	O
rule	O
(	O
3.117	O
)	O
no	O
longer	O
ap-	O
plies	O
.	O
instead	O
,	O
we	O
use	O
a	O
direct	B
model	O
for	O
the	O
posterior	B
distribution	I
p	O
(	O
x|y	O
)	O
,	O
whose	O
negative	O
log	O
likelihood	O
can	O
be	O
written	O
as	O
e	O
(	O
x|y	O
)	O
=	O
ed	O
(	O
x	O
,	O
y	O
)	O
+	O
es	O
(	O
x	O
,	O
y	O
)	O
vp	O
(	O
xp	O
,	O
y	O
)	O
+	O
(	O
cid:88	O
)	O
(	O
p	O
,	O
q	O
)	O
∈n	O
=	O
(	O
cid:88	O
)	O
p	O
vp	O
,	O
q	O
(	O
xp	O
,	O
xq	O
,	O
y	O
)	O
,	O
(	O
3.118	O
)	O
using	O
the	O
notation	O
introduced	O
in	O
(	O
3.116	O
)	O
.	O
the	O
resulting	O
probability	O
distribution	O
is	O
called	O
a	O
conditional	O
random	O
ﬁeld	O
(	O
crf	O
)	O
and	O
was	O
ﬁrst	O
introduced	O
to	O
the	O
computer	O
vision	O
ﬁeld	O
by	O
ku-	O
mar	O
and	O
hebert	O
(	O
2003	O
)	O
,	O
based	O
on	O
earlier	O
work	O
in	O
text	O
modeling	B
by	O
lafferty	O
,	O
mccallum	O
,	O
and	O
pereira	O
(	O
2001	O
)	O
.	O
figure	O
3.62	O
shows	O
a	O
graphical	O
model	O
where	O
the	O
smoothness	B
terms	O
depend	O
on	O
the	O
data	O
values	O
.	O
in	O
this	O
particular	O
model	O
,	O
each	O
smoothness	B
term	O
depends	O
only	O
on	O
its	O
adjacent	O
pair	O
of	O
data	O
values	O
,	O
i.e.	O
,	O
terms	O
are	O
of	O
the	O
form	O
vp	O
,	O
q	O
(	O
xp	O
,	O
xq	O
,	O
yp	O
,	O
yq	O
)	O
in	O
(	O
3.118	O
)	O
.	O
the	O
idea	O
of	O
modifying	O
smoothness	B
terms	O
in	O
response	O
to	O
input	O
data	O
is	O
not	O
new	O
.	O
for	O
ex-	O
ample	O
,	O
boykov	O
and	O
jolly	O
(	O
2001	O
)	O
used	O
this	O
idea	O
for	O
interactive	O
segmentation	B
,	O
as	O
shown	O
in	O
figure	O
3.61	O
,	O
and	O
it	O
is	O
now	O
widely	O
used	O
in	O
image	B
segmentation	O
(	O
section	O
5.5	O
)	O
(	O
blake	O
,	O
rother	O
,	O
25	O
an	O
alternative	O
formulation	O
that	O
also	O
uses	O
detected	O
edges	O
to	O
modulate	O
the	O
smoothness	B
of	O
a	O
depth	O
or	O
motion	B
ﬁeld	O
and	O
hence	O
to	O
integrate	O
multiple	B
lower	O
level	O
vision	O
modules	O
is	O
presented	O
by	O
poggio	O
,	O
gamble	O
,	O
and	O
little	O
(	O
1988	O
)	O
.	O
f	O
(	O
i	O
,	O
j	O
)	O
sx	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i	O
,	O
j+1	O
)	O
sy	O
(	O
i	O
,	O
j	O
)	O
w	O
(	O
i	O
,	O
j	O
)	O
d	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j+1	O
)	O
190	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
3.63	O
graphical	O
model	O
for	O
a	O
discriminative	O
random	O
ﬁeld	O
(	O
drf	O
)	O
.	O
the	O
additional	O
green	O
edges	O
show	O
how	O
combinations	O
of	O
sensed	O
data	O
,	O
e.g.	O
,	O
d	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
,	O
inﬂuence	O
the	O
data	O
term	O
for	O
f	O
(	O
i	O
,	O
j	O
)	O
.	O
the	O
generative	O
model	O
is	O
therefore	O
more	O
complex	O
,	O
i.e.	O
,	O
we	O
can	O
not	O
just	O
apply	O
a	O
simple	O
function	O
to	O
the	O
unknown	O
variables	O
and	O
add	O
noise	B
.	O
brown	O
et	O
al	O
.	O
2004	O
;	O
rother	O
,	O
kolmogorov	O
,	O
and	O
blake	O
2004	O
)	O
,	O
denoising	O
(	O
tappen	O
,	O
liu	O
,	O
freeman	O
et	O
al	O
.	O
2007	O
)	O
,	O
and	O
object	O
recognition	B
(	O
section	O
14.4.3	O
)	O
(	O
winn	O
and	O
shotton	O
2006	O
;	O
shotton	O
,	O
winn	O
,	O
rother	O
et	O
al	O
.	O
2009	O
)	O
.	O
in	O
stereo	B
matching	I
,	O
the	O
idea	O
of	O
encouraging	O
disparity	O
discontinuities	O
to	O
coincide	O
with	O
intensity	O
edges	O
goes	O
back	O
even	O
further	O
to	O
the	O
early	O
days	O
of	O
optimization	O
and	O
mrf-based	O
algorithms	O
(	O
poggio	O
,	O
gamble	O
,	O
and	O
little	O
1988	O
;	O
fua	O
1993	O
;	O
bobick	O
and	O
intille	O
1999	O
;	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
and	O
is	O
discussed	O
in	O
more	O
detail	O
in	O
(	O
section	O
11.5	O
)	O
.	O
in	O
addition	O
to	O
using	O
smoothness	O
terms	O
that	O
adapt	O
to	O
the	O
input	O
data	O
,	O
kumar	O
and	O
hebert	O
(	O
2003	O
)	O
also	O
compute	O
a	O
neighborhood	B
function	O
over	O
the	O
input	O
data	O
for	O
each	O
vp	O
(	O
xp	O
,	O
y	O
)	O
term	O
,	O
as	O
illustrated	O
in	O
figure	O
3.63	O
,	O
instead	O
of	O
using	O
the	O
classic	O
unary	O
mrf	O
data	O
term	O
vp	O
(	O
xp	O
,	O
yp	O
)	O
shown	O
in	O
figure	O
3.56.26	O
because	O
such	O
neighborhood	B
functions	O
can	O
be	O
thought	O
of	O
as	O
dis-	O
criminant	O
functions	O
(	O
a	O
term	O
widely	O
used	O
in	O
machine	O
learning	O
(	O
bishop	O
2006	O
)	O
)	O
,	O
they	O
call	O
the	O
resulting	O
graphical	O
model	O
a	O
discriminative	O
random	O
ﬁeld	O
(	O
drf	O
)	O
.	O
in	O
their	O
paper	O
,	O
kumar	O
and	O
hebert	O
(	O
2006	O
)	O
show	O
that	O
drfs	O
outperform	O
similar	O
crfs	O
on	O
a	O
number	O
of	O
applications	O
,	O
such	O
as	O
structure	O
detection	O
(	O
figure	O
3.64	O
)	O
and	O
binary	O
image	O
denoising	O
.	O
here	O
again	O
,	O
one	O
could	O
argue	O
that	O
previous	O
stereo	B
correspondence	O
algorithms	O
also	O
look	O
at	O
a	O
neighborhood	B
of	O
input	O
data	O
,	O
either	O
explicitly	O
,	O
because	O
they	O
compute	O
correlation	O
measures	O
(	O
criminisi	O
,	O
cross	O
,	O
blake	O
et	O
al	O
.	O
2006	O
)	O
as	O
data	O
terms	O
,	O
or	O
implicitly	O
,	O
because	O
even	O
pixel-wise	O
disparity	O
costs	O
look	O
at	O
several	O
pixels	O
in	O
either	O
the	O
left	O
or	O
right	O
image	B
(	O
barnard	O
1989	O
;	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
.	O
26	O
kumar	O
and	O
hebert	O
(	O
2006	O
)	O
call	O
the	O
unary	O
potentials	O
vp	O
(	O
xp	O
,	O
y	O
)	O
association	O
potentials	O
and	O
the	O
pairwise	O
potentials	O
vp	O
,	O
q	O
(	O
xp	O
,	O
yq	O
,	O
y	O
)	O
interaction	O
potentials	O
.	O
f	O
(	O
i	O
,	O
j	O
)	O
sx	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i	O
,	O
j+1	O
)	O
sy	O
(	O
i	O
,	O
j	O
)	O
w	O
(	O
i	O
,	O
j	O
)	O
d	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j+1	O
)	O
d	O
(	O
i	O
,	O
j+1	O
)	O
3.7	O
global	B
optimization	I
191	O
figure	O
3.64	O
structure	O
detection	O
results	O
using	O
an	O
mrf	O
(	O
left	O
)	O
and	O
a	O
drf	O
(	O
right	O
)	O
(	O
kumar	O
and	O
hebert	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
.	O
what	O
,	O
then	O
are	O
the	O
advantages	O
and	O
disadvantages	O
of	O
using	O
conditional	O
or	O
discriminative	O
random	O
ﬁelds	O
instead	O
of	O
mrfs	O
?	O
classic	O
bayesian	O
inference	B
(	O
mrf	O
)	O
assumes	O
that	O
the	O
prior	B
distribution	I
of	O
the	O
data	O
is	O
in-	O
dependent	O
of	O
the	O
measurements	O
.	O
this	O
makes	O
a	O
lot	O
of	O
sense	O
:	O
if	O
you	O
see	O
a	O
pair	O
of	O
sixes	O
when	O
you	O
ﬁrst	O
throw	O
a	O
pair	O
of	O
dice	O
,	O
it	O
would	O
be	O
unwise	O
to	O
assume	O
that	O
they	O
will	O
always	O
show	O
up	O
thereafter	O
.	O
however	O
,	O
if	O
after	O
playing	O
for	O
a	O
long	O
time	O
you	O
detect	O
a	O
statistically	O
signiﬁcant	O
bias	O
,	O
you	O
may	O
want	O
to	O
adjust	O
your	O
prior	B
.	O
what	O
crfs	O
do	O
,	O
in	O
essence	O
,	O
is	O
to	O
select	O
or	O
modify	O
the	O
prior	B
model	O
based	O
on	O
observed	O
data	O
.	O
this	O
can	O
be	O
viewed	O
as	O
making	O
a	O
partial	O
inference	B
over	O
addi-	O
tional	O
hidden	O
variables	O
or	O
correlations	O
between	O
the	O
unknowns	O
(	O
say	O
,	O
a	O
label	O
,	O
depth	O
,	O
or	O
clean	O
image	B
)	O
and	O
the	O
knowns	O
(	O
observed	O
images	O
)	O
.	O
in	O
some	O
cases	O
,	O
the	O
crf	O
approach	O
makes	O
a	O
lot	O
of	O
sense	O
and	O
is	O
,	O
in	O
fact	O
,	O
the	O
only	O
plausi-	O
ble	O
way	O
to	O
proceed	O
.	O
for	O
example	O
,	O
in	O
grayscale	O
image	B
colorization	O
(	O
section	O
10.3.2	O
)	O
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2004	O
)	O
,	O
the	O
best	O
way	O
to	O
transfer	B
the	O
continuity	O
information	O
from	O
the	O
input	O
grayscale	O
image	B
to	O
the	O
unknown	O
color	B
image	O
is	O
to	O
modify	O
local	B
smoothness	O
constraints	O
.	O
similarly	O
,	O
for	O
simultaneous	O
segmentation	B
and	O
recognition	B
(	O
winn	O
and	O
shotton	O
2006	O
;	O
shotton	O
,	O
winn	O
,	O
rother	O
et	O
al	O
.	O
2009	O
)	O
,	O
it	O
makes	O
a	O
lot	O
of	O
sense	O
to	O
permit	O
strong	O
color	B
edges	O
to	O
inﬂuence	O
the	O
semantic	O
image	B
label	O
continuities	O
.	O
in	O
other	O
cases	O
,	O
such	O
as	O
image	B
denoising	O
,	O
the	O
situation	O
is	O
more	O
subtle	O
.	O
using	O
a	O
non-	O
quadratic	O
(	O
robust	B
)	O
smoothness	B
term	O
as	O
in	O
(	O
3.113	O
)	O
plays	O
a	O
qualitatively	O
similar	O
role	O
to	O
setting	O
the	O
smoothness	B
based	O
on	O
local	B
gradient	O
information	O
in	O
a	O
gaussian	O
mrf	O
(	O
gmrf	O
)	O
(	O
tappen	O
,	O
liu	O
,	O
freeman	O
et	O
al	O
.	O
2007	O
)	O
.	O
(	O
in	O
more	O
recent	O
work	O
,	O
tanaka	O
and	O
okutomi	O
(	O
2008	O
)	O
use	O
a	O
larger	O
neighborhood	B
and	O
full	O
covariance	O
matrix	O
on	O
a	O
related	O
gaussian	O
mrf	O
.	O
)	O
the	O
advantage	O
of	O
gaus-	O
sian	O
mrfs	O
,	O
when	O
the	O
smoothness	B
can	O
be	O
correctly	O
inferred	O
,	O
is	O
that	O
the	O
resulting	O
quadratic	O
energy	O
can	O
be	O
minimized	O
in	O
a	O
single	O
step	O
.	O
however	O
,	O
for	O
situations	O
where	O
the	O
discontinuities	O
are	O
not	O
self-evident	O
in	O
the	O
input	O
data	O
,	O
such	O
as	O
for	O
piecewise-smooth	O
sparse	B
data	O
interpolation	B
(	O
blake	O
and	O
zisserman	O
1987	O
;	O
terzopoulos	O
1988	O
)	O
,	O
classic	O
robust	B
smoothness	O
energy	O
minimiza-	O
192	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
tion	B
may	O
be	O
preferable	O
.	O
thus	O
,	O
as	O
with	O
most	O
computer	O
vision	O
algorithms	O
,	O
a	O
careful	O
analysis	O
of	O
the	O
problem	O
at	O
hand	O
and	O
desired	O
robustness	O
and	O
computation	O
constraints	O
may	O
be	O
required	O
to	O
choose	O
the	O
best	O
technique	O
.	O
perhaps	O
the	O
biggest	O
advantage	O
of	O
crfs	O
and	O
drfs	O
,	O
as	O
argued	O
by	O
kumar	O
and	O
hebert	O
(	O
2006	O
)	O
,	O
tappen	O
,	O
liu	O
,	O
freeman	O
et	O
al	O
.	O
(	O
2007	O
)	O
and	O
blake	O
,	O
rother	O
,	O
brown	O
et	O
al	O
.	O
(	O
2004	O
)	O
,	O
is	O
that	O
learning	B
the	O
model	O
parameters	B
is	O
sometimes	O
easier	O
.	O
while	O
learning	B
parameters	I
in	O
mrfs	O
and	O
their	O
variants	O
is	O
not	O
a	O
topic	O
that	O
we	O
cover	O
in	O
this	O
book	O
,	O
interested	O
readers	O
can	O
ﬁnd	O
more	O
details	O
in	O
recently	O
published	O
articles	O
(	O
kumar	O
and	O
hebert	O
2006	O
;	O
roth	O
and	O
black	O
2007a	O
;	O
tappen	O
,	O
liu	O
,	O
freeman	O
et	O
al	O
.	O
2007	O
;	O
tappen	O
2007	O
;	O
li	O
and	O
huttenlocher	O
2008	O
)	O
.	O
3.7.3	O
application	O
:	O
image	B
restoration	I
in	O
section	O
3.4.4	O
,	O
we	O
saw	O
how	O
two-dimensional	B
linear	O
and	O
non-linear	B
ﬁlters	O
can	O
be	O
used	O
to	O
remove	O
noise	B
or	O
enhance	O
sharpness	O
in	O
images	O
.	O
sometimes	O
,	O
however	O
,	O
images	O
are	O
degraded	O
by	O
larger	O
problems	O
,	O
such	O
as	O
scratches	O
and	O
blotches	O
(	O
kokaram	O
2004	O
)	O
.	O
in	O
this	O
case	O
,	O
bayesian	O
meth-	O
ods	O
such	O
as	O
mrfs	O
,	O
which	O
can	O
model	O
spatially	O
varying	O
per-pixel	O
measurement	O
noise	B
,	O
can	O
be	O
used	O
instead	O
.	O
an	O
alternative	O
is	O
to	O
use	O
hole	B
ﬁlling	I
or	O
inpainting	B
techniques	O
(	O
bertalmio	O
,	O
sapiro	O
,	O
caselles	O
et	O
al	O
.	O
2000	O
;	O
bertalmio	O
,	O
vese	O
,	O
sapiro	O
et	O
al	O
.	O
2003	O
;	O
criminisi	O
,	O
p´erez	O
,	O
and	O
toyama	O
2004	O
)	O
,	O
as	O
discussed	O
in	O
sections	O
5.1.4	O
and	O
10.5.1.	O
figure	O
3.57	O
shows	O
an	O
example	O
of	O
image	B
denoising	O
and	O
inpainting	B
(	O
hole	B
ﬁlling	I
)	O
using	O
a	O
markov	O
random	O
ﬁeld	O
.	O
the	O
original	O
image	B
has	O
been	O
corrupted	O
by	O
noise	O
and	O
a	O
portion	O
of	O
the	O
data	O
has	O
been	O
removed	O
.	O
in	O
this	O
case	O
,	O
the	O
loopy	B
belief	I
propagation	I
algorithm	O
computes	O
a	O
slightly	O
lower	O
energy	O
and	O
also	O
a	O
smoother	O
image	B
than	O
the	O
alpha-expansion	O
graph	B
cut	I
algo-	O
rithm	O
.	O
3.8	O
additional	O
reading	O
if	O
you	O
are	O
interested	O
in	O
exploring	O
the	O
topic	O
of	O
image	B
processing	O
in	O
more	O
depth	O
,	O
some	O
popular	O
textbooks	B
have	O
been	O
written	O
by	O
lim	O
(	O
1990	O
)	O
;	O
crane	O
(	O
1997	O
)	O
;	O
gomes	O
and	O
velho	O
(	O
1997	O
)	O
;	O
j¨ahne	O
(	O
1997	O
)	O
;	O
pratt	O
(	O
2007	O
)	O
;	O
russ	O
(	O
2007	O
)	O
;	O
burger	O
and	O
burge	O
(	O
2008	O
)	O
;	O
gonzales	O
and	O
woods	O
(	O
2008	O
)	O
.	O
the	O
pre-eminent	O
conference	O
and	O
journal	O
in	O
this	O
ﬁeld	O
are	O
the	O
ieee	O
conference	O
on	O
image	B
pro-	O
cesssing	O
and	O
the	O
ieee	O
transactions	O
on	O
image	B
processing	O
.	O
for	O
image	O
compositing	B
operators	O
,	O
the	O
seminal	O
reference	O
is	O
by	O
porter	O
and	O
duff	O
(	O
1984	O
)	O
while	O
blinn	O
(	O
1994a	O
,	O
b	O
)	O
provides	O
a	O
more	O
detailed	O
tutorial	O
.	O
for	O
image	O
compositing	B
,	O
smith	O
and	O
blinn	O
(	O
1996	O
)	O
were	O
the	O
ﬁrst	O
to	O
bring	O
this	O
topic	O
to	O
the	O
attention	O
of	O
the	O
graphics	O
community	O
,	O
while	O
wang	O
and	O
cohen	O
(	O
2007a	O
)	O
provide	O
a	O
recent	O
in-depth	O
survey	O
.	O
in	O
the	O
realm	O
of	O
linear	B
ﬁltering	O
,	O
freeman	O
and	O
adelson	O
(	O
1991	O
)	O
provide	O
a	O
great	O
introduc-	O
tion	B
to	O
separable	B
and	O
steerable	B
oriented	O
band-pass	B
ﬁlters	O
,	O
while	O
perona	O
(	O
1995	O
)	O
shows	O
how	O
to	O
3.8	O
additional	O
reading	O
193	O
approximate	O
any	O
ﬁlter	O
as	O
a	O
sum	O
of	O
separable	B
components	O
.	O
the	O
literature	O
on	O
non-linear	B
ﬁltering	O
is	O
quite	O
wide	O
and	O
varied	O
;	O
it	O
includes	O
such	O
topics	O
as	O
bilateral	B
ﬁltering	O
(	O
tomasi	O
and	O
manduchi	O
1998	O
;	O
durand	O
and	O
dorsey	O
2002	O
;	O
paris	O
and	O
durand	O
2006	O
;	O
chen	O
,	O
paris	O
,	O
and	O
durand	O
2007	O
;	O
paris	O
,	O
kornprobst	O
,	O
tumblin	O
et	O
al	O
.	O
2008	O
)	O
,	O
related	O
itera-	O
tive	O
algorithms	O
(	O
saint-marc	O
,	O
chen	O
,	O
and	O
medioni	O
1991	O
;	O
nielsen	O
,	O
florack	O
,	O
and	O
deriche	O
1997	O
;	O
black	O
,	O
sapiro	O
,	O
marimont	O
et	O
al	O
.	O
1998	O
;	O
weickert	O
,	O
ter	O
haar	O
romeny	O
,	O
and	O
viergever	O
1998	O
;	O
weick-	O
ert	O
1998	O
;	O
barash	O
2002	O
;	O
scharr	O
,	O
black	O
,	O
and	O
haussecker	O
2003	O
;	O
barash	O
and	O
comaniciu	O
2004	O
)	O
,	O
and	O
variational	O
approaches	O
(	O
chan	O
,	O
osher	O
,	O
and	O
shen	O
2001	O
;	O
tschumperl´e	O
and	O
deriche	O
2005	O
;	O
tschumperl´e	O
2006	O
;	O
kaftory	O
,	O
schechner	O
,	O
and	O
zeevi	O
2007	O
)	O
.	O
good	O
references	B
to	O
image	B
morphology	O
include	O
(	O
haralick	O
and	O
shapiro	O
1992	O
,	O
section	O
5.2	O
;	O
bovik	O
2000	O
,	O
section	O
2.2	O
;	O
ritter	O
and	O
wilson	O
2000	O
,	O
section	O
7	O
;	O
serra	O
1982	O
;	O
serra	O
and	O
vincent	O
1992	O
;	O
yuille	O
,	O
vincent	O
,	O
and	O
geiger	O
1992	O
;	O
soille	O
2006	O
)	O
.	O
the	O
classic	O
papers	O
for	O
image	O
pyramids	O
and	O
pyramid	B
blending	O
are	O
by	O
burt	O
and	O
adelson	O
(	O
1983a	O
,	O
b	O
)	O
.	O
wavelets	O
were	O
ﬁrst	O
introduced	O
to	O
the	O
computer	O
vision	O
community	O
by	O
mallat	O
(	O
1989	O
)	O
and	O
good	O
tutorial	O
and	O
review	O
papers	O
and	O
books	O
are	O
available	O
(	O
strang	O
1989	O
;	O
simoncelli	O
and	O
adelson	O
1990b	O
;	O
rioul	O
and	O
vetterli	O
1991	O
;	O
chui	O
1992	O
;	O
meyer	O
1993	O
;	O
sweldens	O
1997	O
)	O
.	O
wavelets	O
are	O
widely	O
used	O
in	O
the	O
computer	O
graphics	O
community	O
to	O
perform	O
multi-resolution	O
geomet-	O
ric	O
processing	O
(	O
stollnitz	O
,	O
derose	O
,	O
and	O
salesin	O
1996	O
)	O
and	O
have	O
been	O
used	O
in	O
computer	O
vision	O
for	O
similar	O
applications	O
(	O
szeliski	O
1990b	O
;	O
pentland	O
1994	O
;	O
gortler	O
and	O
cohen	O
1995	O
;	O
yaou	O
and	O
chang	O
1994	O
;	O
lai	O
and	O
vemuri	O
1997	O
;	O
szeliski	O
2006b	O
)	O
,	O
as	O
well	O
as	O
for	O
multi-scale	O
oriented	B
ﬁlter-	O
ing	O
(	O
simoncelli	O
,	O
freeman	O
,	O
adelson	O
et	O
al	O
.	O
1992	O
)	O
and	O
denoising	O
(	O
portilla	O
,	O
strela	O
,	O
wainwright	O
et	O
al	O
.	O
2003	O
)	O
.	O
while	O
image	B
pyramids	O
(	O
section	O
3.5.3	O
)	O
are	O
usually	O
constructed	O
using	O
linear	O
ﬁltering	O
op-	O
erators	O
,	O
some	O
recent	O
work	O
has	O
started	O
investigating	O
non-linear	B
ﬁlters	O
,	O
since	O
these	O
can	O
better	O
preserve	O
details	O
and	O
other	O
salient	O
features	O
.	O
some	O
representative	O
papers	O
in	O
the	O
computer	O
vision	O
literature	O
are	O
by	O
gluckman	O
(	O
2006a	O
,	O
b	O
)	O
;	O
lyu	O
and	O
simoncelli	O
(	O
2008	O
)	O
and	O
in	O
computational	O
pho-	O
tography	O
by	O
bae	O
,	O
paris	O
,	O
and	O
durand	O
(	O
2006	O
)	O
;	O
farbman	O
,	O
fattal	O
,	O
lischinski	O
et	O
al	O
.	O
(	O
2008	O
)	O
;	O
fattal	O
(	O
2009	O
)	O
.	O
high-quality	O
algorithms	O
for	O
image	O
warping	O
and	O
resampling	O
are	O
covered	O
both	O
in	O
the	O
im-	O
age	O
processing	O
literature	O
(	O
wolberg	O
1990	O
;	O
dodgson	O
1992	O
;	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
1999	O
;	O
szeliski	O
,	O
winder	O
,	O
and	O
uyttendaele	O
2010	O
)	O
and	O
in	O
computer	O
graphics	O
(	O
williams	O
1983	O
;	O
heckbert	O
1986	O
;	O
barkans	O
1997	O
;	O
akenine-m¨oller	O
and	O
haines	O
2002	O
)	O
,	O
where	O
they	O
go	O
under	O
the	O
name	O
of	O
texture	B
mapping	O
.	O
combination	O
of	O
image	B
warping	O
and	O
image	B
blending	O
techniques	O
are	O
used	O
to	O
enable	O
morphing	B
between	O
images	O
,	O
which	O
is	O
covered	O
in	O
a	O
series	O
of	O
seminal	O
papers	O
and	O
books	O
(	O
beier	O
and	O
neely	O
1992	O
;	O
gomes	O
,	O
darsa	O
,	O
costa	O
et	O
al	O
.	O
1999	O
)	O
.	O
the	O
regularization	B
approach	O
to	O
computer	O
vision	O
problems	O
was	O
ﬁrst	O
introduced	O
to	O
the	O
vi-	O
sion	O
community	O
by	O
poggio	O
,	O
torre	O
,	O
and	O
koch	O
(	O
1985	O
)	O
and	O
terzopoulos	O
(	O
1986a	O
,	O
b	O
,	O
1988	O
)	O
and	O
continues	O
to	O
be	O
a	O
popular	O
framework	O
for	O
formulating	O
and	O
solving	O
low-level	O
vision	O
problems	O
194	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
ju	O
,	O
black	O
,	O
and	O
jepson	O
1996	O
;	O
nielsen	O
,	O
florack	O
,	O
and	O
deriche	O
1997	O
;	O
nordstr¨om	O
1990	O
;	O
brox	O
,	O
bruhn	O
,	O
papenberg	O
et	O
al	O
.	O
2004	O
;	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2008	O
)	O
.	O
more	O
detailed	O
mathe-	O
matical	O
treatment	O
and	O
additional	O
applications	O
can	O
be	O
found	O
in	O
the	O
applied	O
mathematics	O
and	O
statistics	O
literature	O
(	O
tikhonov	O
and	O
arsenin	O
1977	O
;	O
engl	O
,	O
hanke	O
,	O
and	O
neubauer	O
1996	O
)	O
.	O
the	O
literature	O
on	O
markov	O
random	O
ﬁelds	O
is	O
truly	O
immense	O
,	O
with	O
publications	O
in	O
related	O
ﬁelds	O
such	O
as	O
optimization	O
and	O
control	O
theory	O
of	O
which	O
few	O
vision	O
practitioners	O
are	O
even	O
aware	O
.	O
a	O
good	O
guide	O
to	O
the	O
latest	O
techniques	O
is	O
the	O
book	O
edited	O
by	O
blake	O
,	O
kohli	O
,	O
and	O
rother	O
(	O
2010	O
)	O
.	O
other	O
recent	O
articles	O
that	O
contain	O
nice	O
literature	O
reviews	O
or	O
experimental	O
compar-	O
isons	O
include	O
(	O
boykov	O
and	O
funka-lea	O
2006	O
;	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
;	O
kumar	O
,	O
veksler	O
,	O
and	O
torr	O
2010	O
)	O
.	O
the	O
seminal	O
paper	O
on	O
markov	O
random	O
ﬁelds	O
is	O
the	O
work	O
of	O
geman	O
and	O
geman	O
(	O
1984	O
)	O
,	O
who	O
introduced	O
this	O
formalism	O
to	O
computer	O
vision	O
researchers	O
and	O
also	O
introduced	O
the	O
no-	O
tion	B
of	O
line	O
processes	O
,	O
additional	O
binary	O
variables	O
that	O
control	O
whether	O
smoothness	B
penalties	O
are	O
enforced	O
or	O
not	O
.	O
black	O
and	O
rangarajan	O
(	O
1996	O
)	O
showed	O
how	O
independent	O
line	O
processes	O
could	O
be	O
replaced	O
with	O
robust	O
pairwise	O
potentials	O
;	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
(	O
2001	O
)	O
devel-	O
oped	O
iterative	B
binary	O
,	O
graph	B
cut	I
algorithms	O
for	O
optimizing	O
multi-label	O
mrfs	O
;	O
kolmogorov	O
and	O
zabih	O
(	O
2004	O
)	O
characterized	O
the	O
class	O
of	O
binary	O
energy	O
potentials	O
required	O
for	O
these	O
tech-	O
niques	O
to	O
work	O
;	O
and	O
freeman	O
,	O
pasztor	O
,	O
and	O
carmichael	O
(	O
2000	O
)	O
popularized	O
the	O
use	O
of	O
loopy	B
belief	I
propagation	I
for	O
mrf	O
inference	B
.	O
many	O
more	O
additional	O
references	B
can	O
be	O
found	O
in	O
sections	O
3.7.2	O
and	O
5.5	O
,	O
and	O
appendix	O
b.5	O
.	O
3.9	O
exercises	O
ex	O
3.1	O
:	O
color	B
balance	I
write	O
a	O
simple	O
application	O
to	O
change	O
the	O
color	B
balance	I
of	O
an	O
image	B
by	O
multiplying	O
each	O
color	B
value	O
by	O
a	O
different	O
user-speciﬁed	O
constant	O
.	O
if	O
you	O
want	O
to	O
get	O
fancy	O
,	O
you	O
can	O
make	O
this	O
application	O
interactive	B
,	O
with	O
sliders	O
.	O
1.	O
do	O
you	O
get	O
different	O
results	O
if	O
you	O
take	O
out	O
the	O
gamma	B
transformation	O
before	O
or	O
after	O
doing	O
the	O
multiplication	B
?	O
why	O
or	O
why	O
not	O
?	O
2.	O
take	O
the	O
same	O
picture	O
with	O
your	O
digital	O
camera	O
using	O
different	O
color	B
balance	I
settings	O
(	O
most	O
cameras	O
control	O
the	O
color	B
balance	I
from	O
one	O
of	O
the	O
menus	O
)	O
.	O
can	O
you	O
recover	O
what	O
the	O
color	B
balance	I
ratios	O
are	O
between	O
the	O
different	O
settings	O
?	O
you	O
may	O
need	O
to	O
put	O
your	O
camera	B
on	O
a	O
tripod	O
and	O
align	O
the	O
images	O
manually	O
or	O
automatically	O
to	O
make	O
this	O
work	O
.	O
alternatively	O
,	O
use	O
a	O
color	B
checker	O
chart	O
(	O
figure	O
10.3b	O
)	O
,	O
as	O
discussed	O
in	O
sections	O
2.3	O
and	O
10.1.1	O
.	O
3.	O
if	O
you	O
have	O
access	O
to	O
the	O
raw	O
image	B
for	O
the	O
camera	B
,	O
perform	O
the	O
demosaicing	B
yourself	O
(	O
section	O
10.3.1	O
)	O
or	O
downsample	O
the	O
image	B
resolution	O
to	O
get	O
a	O
“	O
true	O
”	O
rgb	O
image	B
.	O
does	O
3.9	O
exercises	O
195	O
your	O
camera	B
perform	O
a	O
simple	O
linear	B
mapping	O
between	O
raw	O
values	O
and	O
the	O
color-	O
balanced	O
values	O
in	O
a	O
jpeg	O
?	O
some	O
high-end	O
cameras	O
have	O
a	O
raw+jpeg	O
mode	O
,	O
which	O
makes	O
this	O
comparison	O
much	O
easier	O
.	O
4.	O
can	O
you	O
think	O
of	O
any	O
reason	O
why	O
you	O
might	O
want	O
to	O
perform	O
a	O
color	B
twist	O
(	O
sec-	O
tion	B
3.1.2	O
)	O
on	O
the	O
images	O
?	O
see	O
also	O
exercise	O
2.9	O
for	O
some	O
related	O
ideas	O
.	O
ex	O
3.2	O
:	O
compositing	B
and	O
reﬂections	B
section	O
3.1.3	O
describes	O
the	O
process	O
of	O
compositing	B
an	O
alpha-matted	O
image	B
on	O
top	O
of	O
another	O
.	O
answer	O
the	O
following	O
questions	O
and	O
optionally	O
validate	O
them	O
experimentally	O
:	O
1.	O
most	O
captured	O
images	O
have	O
gamma	B
correction	O
applied	O
to	O
them	O
.	O
does	O
this	O
invalidate	O
the	O
basic	O
compositing	B
equation	O
(	O
3.8	O
)	O
;	O
if	O
so	O
,	O
how	O
should	O
it	O
be	O
ﬁxed	O
?	O
2.	O
the	O
additive	O
(	O
pure	O
reﬂection	O
)	O
model	O
may	O
have	O
limitations	O
.	O
what	O
happens	O
if	O
the	O
glass	O
is	O
tinted	O
,	O
especially	O
to	O
a	O
non-gray	O
hue	B
?	O
how	O
about	O
if	O
the	O
glass	O
is	O
dirty	O
or	O
smudged	O
?	O
how	O
could	O
you	O
model	O
wavy	O
glass	O
or	O
other	O
kinds	O
of	O
refractive	O
objects	O
?	O
ex	O
3.3	O
:	O
blue	B
screen	I
matting	O
set	O
up	O
a	O
blue	O
or	O
green	O
background	O
,	O
e.g.	O
,	O
by	O
buying	O
a	O
large	O
piece	O
of	O
colored	O
posterboard	O
.	O
take	O
a	O
picture	O
of	O
the	O
empty	O
background	O
,	O
and	O
then	O
of	O
the	O
back-	O
ground	O
with	O
a	O
new	O
object	O
in	O
front	O
of	O
it	O
.	O
pull	O
the	O
matte	O
using	O
the	O
difference	B
between	O
each	O
colored	O
pixel	O
and	O
its	O
assumed	O
corresponding	O
background	O
pixel	O
,	O
using	O
one	O
of	O
the	O
techniques	O
described	O
in	O
section	O
3.1.3	O
)	O
or	O
by	O
smith	O
and	O
blinn	O
(	O
1996	O
)	O
.	O
ex	O
3.4	O
:	O
difference	B
keying	O
implement	O
a	O
difference	B
keying	O
algorithm	B
(	O
see	O
section	O
3.1.3	O
)	O
(	O
toyama	O
,	O
krumm	O
,	O
brumitt	O
et	O
al	O
.	O
1999	O
)	O
,	O
consisting	O
of	O
the	O
following	O
steps	O
:	O
1.	O
compute	O
the	O
mean	O
and	O
variance	O
(	O
or	O
median	B
and	O
robust	B
variance	O
)	O
at	O
each	O
pixel	O
in	O
an	O
“	O
empty	O
”	O
video	B
sequence	O
.	O
2.	O
for	O
each	O
new	O
frame	O
,	O
classify	O
each	O
pixel	O
as	O
foreground	O
or	O
background	O
(	O
set	O
the	O
back-	O
ground	O
pixels	O
to	O
rgba=0	O
)	O
.	O
3	O
.	O
(	O
optional	O
)	O
compute	O
the	O
alpha	O
channel	O
and	O
composite	O
over	O
a	O
new	O
background	O
.	O
4	O
.	O
(	O
optional	O
)	O
clean	O
up	O
the	O
image	B
using	O
morphology	O
(	O
section	O
3.3.1	O
)	O
,	O
label	O
the	O
connected	B
components	I
(	O
section	O
3.3.4	O
)	O
,	O
compute	O
their	O
centroids	O
,	O
and	O
track	O
them	O
from	O
frame	O
to	O
frame	O
.	O
use	O
this	O
to	O
build	O
a	O
“	O
people	O
counter	O
”	O
.	O
ex	O
3.5	O
:	O
photo	O
effects	O
write	O
a	O
variety	O
of	O
photo	O
enhancement	O
or	O
effects	O
ﬁlters	O
:	O
contrast	O
,	O
so-	O
larization	O
(	O
quantization	B
)	O
,	O
etc	O
.	O
which	O
ones	O
are	O
useful	O
(	O
perform	O
sensible	O
corrections	O
)	O
and	O
which	O
ones	O
are	O
more	O
creative	O
(	O
create	O
unusual	O
images	O
)	O
?	O
196	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ex	O
3.6	O
:	O
histogram	B
equalization	O
compute	O
the	O
gray	O
level	O
(	O
luminance	O
)	O
histogram	B
for	O
an	O
im-	O
age	O
and	O
equalize	O
it	O
so	O
that	O
the	O
tones	O
look	O
better	O
(	O
and	O
the	O
image	B
is	O
less	O
sensitive	O
to	O
exposure	O
settings	O
)	O
.	O
you	O
may	O
want	O
to	O
use	O
the	O
following	O
steps	O
:	O
1.	O
convert	O
the	O
color	B
image	O
to	O
luminance	O
(	O
section	O
3.1.2	O
)	O
.	O
2.	O
compute	O
the	O
histogram	B
,	O
the	O
cumulative	O
distribution	O
,	O
and	O
the	O
compensation	O
transfer	B
function	O
(	O
section	O
3.1.4	O
)	O
.	O
3	O
.	O
(	O
optional	O
)	O
try	O
to	O
increase	O
the	O
“	O
punch	O
”	O
in	O
the	O
image	B
by	O
ensuring	O
that	O
a	O
certain	O
fraction	O
of	O
pixels	O
(	O
say	O
,	O
5	O
%	O
)	O
are	O
mapped	O
to	O
pure	O
black	O
and	O
white	O
.	O
4	O
.	O
(	O
optional	O
)	O
limit	O
the	O
local	B
gain	O
f	O
(	O
cid:48	O
)	O
(	O
i	O
)	O
in	O
the	O
transfer	B
function	O
.	O
one	O
way	O
to	O
do	O
this	O
is	O
to	O
limit	O
f	O
(	O
i	O
)	O
<	O
γi	O
or	O
f	O
(	O
cid:48	O
)	O
(	O
i	O
)	O
<	O
γ	O
while	O
performing	O
the	O
accumulation	O
(	O
3.9	O
)	O
,	O
keeping	O
any	O
unaccumulated	O
values	O
“	O
in	O
reserve	O
”	O
.	O
(	O
i	O
’	O
ll	O
let	O
you	O
ﬁgure	O
out	O
the	O
exact	O
details	O
.	O
)	O
5.	O
compensate	O
the	O
luminance	O
channel	O
through	O
the	O
lookup	O
table	O
and	O
re-generate	O
the	O
color	B
image	O
using	O
color	O
ratios	B
(	O
2.116	O
)	O
.	O
6	O
.	O
(	O
optional	O
)	O
color	B
values	O
that	O
are	O
clipped	O
in	O
the	O
original	O
image	B
,	O
i.e.	O
,	O
have	O
one	O
or	O
more	O
saturated	O
color	B
channels	O
,	O
may	O
appear	O
unnatural	O
when	O
remapped	O
to	O
a	O
non-clipped	O
value	O
.	O
extend	O
your	O
algorithm	B
to	O
handle	O
this	O
case	O
in	O
some	O
useful	O
way	O
.	O
ex	O
3.7	O
:	O
local	B
histogram	O
equalization	O
compute	O
the	O
gray	O
level	O
(	O
luminance	O
)	O
histograms	O
for	O
each	O
patch	B
,	O
but	O
add	O
to	O
vertices	O
based	O
on	O
distance	O
(	O
a	O
spline	B
)	O
.	O
1.	O
build	O
on	O
exercise	O
3.6	O
(	O
luminance	O
computation	O
)	O
.	O
2.	O
distribute	O
values	O
(	O
counts	O
)	O
to	O
adjacent	O
vertices	O
(	O
bilinear	B
)	O
.	O
3.	O
convert	O
to	O
cdf	O
(	O
look-up	O
functions	O
)	O
.	O
4	O
.	O
(	O
optional	O
)	O
use	O
low-pass	B
ﬁltering	O
of	O
cdfs	O
.	O
5.	O
interpolate	O
adjacent	O
cdfs	O
for	O
ﬁnal	O
lookup	O
.	O
ex	O
3.8	O
:	O
padding	O
for	O
neighborhood	O
operations	O
write	O
down	O
the	O
formulas	O
for	O
computing	O
the	O
padded	O
pixel	O
values	O
˜f	O
(	O
i	O
,	O
j	O
)	O
as	O
a	O
function	O
of	O
the	O
original	O
pixel	O
values	O
f	O
(	O
k	O
,	O
l	O
)	O
and	O
the	O
image	B
width	O
and	O
height	O
(	O
m	O
,	O
n	O
)	O
for	O
each	O
of	O
the	O
padding	O
modes	O
shown	O
in	O
figure	O
3.13.	O
for	O
example	O
,	O
for	O
replication	O
(	O
clamping	O
)	O
,	O
˜f	O
(	O
i	O
,	O
j	O
)	O
=	O
f	O
(	O
k	O
,	O
l	O
)	O
,	O
k	O
=	O
max	O
(	O
0	O
,	O
min	O
(	O
m	O
−	O
1	O
,	O
i	O
)	O
)	O
,	O
l	O
=	O
max	O
(	O
0	O
,	O
min	O
(	O
n	O
−	O
1	O
,	O
j	O
)	O
)	O
,	O
(	O
hint	O
:	O
you	O
may	O
want	O
to	O
use	O
the	O
min	O
,	O
max	O
,	O
mod	O
,	O
and	O
absolute	O
value	O
operators	O
in	O
addition	O
to	O
the	O
regular	O
arithmetic	O
operators	O
.	O
)	O
3.9	O
exercises	O
197	O
•	O
describe	O
in	O
more	O
detail	O
the	O
advantages	O
and	O
disadvantages	O
of	O
these	O
various	O
modes	O
.	O
•	O
(	O
optional	O
)	O
check	O
what	O
your	O
graphics	O
card	O
does	O
by	O
drawing	O
a	O
texture-mapped	O
rectangle	O
where	O
the	O
texture	B
coordinates	O
lie	O
beyond	O
the	O
[	O
0.0	O
,	O
1.0	O
]	O
range	O
and	O
using	O
different	O
texture	B
clamping	O
modes	O
.	O
ex	O
3.9	O
:	O
separable	B
ﬁlters	O
implement	O
convolution	O
with	O
a	O
separable	B
kernel	O
.	O
the	O
input	O
should	O
be	O
a	O
grayscale	O
or	O
color	B
image	O
along	O
with	O
the	O
horizontal	O
and	O
vertical	O
kernels	O
.	O
make	O
sure	O
you	O
support	O
the	O
padding	O
mechanisms	O
developed	O
in	O
the	O
previous	O
exercise	O
.	O
you	O
will	O
need	O
this	O
functionality	O
for	O
some	O
of	O
the	O
later	O
exercises	O
.	O
if	O
you	O
already	O
have	O
access	O
to	O
separable	B
ﬁltering	O
in	O
an	O
image	B
processing	O
package	O
you	O
are	O
using	O
(	O
such	O
as	O
ipl	O
)	O
,	O
skip	O
this	O
exercise	O
.	O
•	O
(	O
optional	O
)	O
use	O
pietro	O
perona	O
’	O
s	O
(	O
1995	O
)	O
technique	O
to	O
approximate	O
convolution	O
as	O
a	O
sum	O
of	O
a	O
number	O
of	O
separable	B
kernels	O
.	O
let	O
the	O
user	O
specify	O
the	O
number	O
of	O
kernels	O
and	O
report	O
back	O
some	O
sensible	O
metric	O
of	O
the	O
approximation	O
ﬁdelity	O
.	O
ex	O
3.10	O
:	O
discrete	B
gaussian	O
ﬁlters	O
discuss	O
the	O
following	O
issues	O
with	O
implementing	O
a	O
dis-	O
crete	O
gaussian	O
ﬁlter	O
:	O
•	O
if	O
you	O
just	O
sample	O
the	O
equation	B
of	O
a	O
continuous	O
gaussian	O
ﬁlter	O
at	O
discrete	B
locations	O
,	O
will	O
you	O
get	O
the	O
desired	O
properties	B
,	O
e.g.	O
,	O
will	O
the	O
coefﬁcients	O
sum	O
up	O
to	O
0	O
?	O
similarly	O
,	O
if	O
you	O
sample	O
a	O
derivative	O
of	O
a	O
gaussian	O
,	O
do	O
the	O
samples	O
sum	O
up	O
to	O
0	O
or	O
have	O
vanishing	O
higher-order	O
moments	O
?	O
•	O
would	O
it	O
be	O
preferable	O
to	O
take	O
the	O
original	O
signal	O
,	O
interpolate	O
it	O
with	O
a	O
sinc	B
,	O
blur	O
with	O
a	O
continuous	O
gaussian	O
,	O
then	O
pre-ﬁlter	O
with	O
a	O
sinc	B
before	O
re-sampling	O
?	O
is	O
there	O
a	O
simpler	O
way	O
to	O
do	O
this	O
in	O
the	O
frequency	O
domain	O
?	O
•	O
would	O
it	O
make	O
more	O
sense	O
to	O
produce	O
a	O
gaussian	O
frequency	O
response	O
in	O
the	O
fourier	O
domain	O
and	O
to	O
then	O
take	O
an	O
inverse	B
fft	O
to	O
obtain	O
a	O
discrete	B
ﬁlter	O
?	O
•	O
how	O
does	O
truncation	O
of	O
the	O
ﬁlter	O
change	O
its	O
frequency	O
response	O
?	O
does	O
it	O
introduce	O
any	O
additional	O
artifacts	O
?	O
•	O
are	O
the	O
resulting	O
two-dimensional	B
ﬁlters	O
as	O
rotationally	O
invariant	O
as	O
their	O
continuous	O
analogs	O
?	O
is	O
there	O
some	O
way	O
to	O
improve	O
this	O
?	O
in	O
fact	O
,	O
can	O
any	O
2d	O
discrete	B
(	O
separable	B
or	O
non-separable	O
)	O
ﬁlter	O
be	O
truly	O
rotationally	O
invariant	O
?	O
ex	O
3.11	O
:	O
sharpening	O
,	O
blur	O
,	O
and	O
noise	B
removal	I
implement	O
some	O
softening	O
,	O
sharpening	O
,	O
and	O
non-linear	B
diffusion	O
(	O
selective	O
sharpening	O
or	O
noise	B
removal	I
)	O
ﬁlters	O
,	O
such	O
as	O
gaussian	O
,	O
median	B
,	O
and	O
bilateral	B
(	O
section	O
3.3.1	O
)	O
,	O
as	O
discussed	O
in	O
section	O
3.4.4.	O
take	O
blurry	O
or	O
noisy	O
images	O
(	O
shooting	O
in	O
low	O
light	O
is	O
a	O
good	O
way	O
to	O
get	O
both	O
)	O
and	O
try	O
to	O
improve	O
their	O
appearance	O
and	O
legibility	O
.	O
198	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ex	O
3.12	O
:	O
steerable	B
ﬁlters	O
implement	O
freeman	O
and	O
adelson	O
’	O
s	O
(	O
1991	O
)	O
steerable	B
ﬁlter	I
algo-	O
rithm	O
.	O
the	O
input	O
should	O
be	O
a	O
grayscale	O
or	O
color	B
image	O
and	O
the	O
output	O
should	O
be	O
a	O
multi-banded	O
◦	O
◦	O
image	B
consisting	O
of	O
g0	O
1	O
and	O
g90	O
.	O
the	O
coefﬁcients	O
for	O
the	O
ﬁlters	O
can	O
be	O
found	O
in	O
the	O
paper	O
1	O
by	O
freeman	O
and	O
adelson	O
(	O
1991	O
)	O
.	O
test	O
the	O
various	O
order	B
ﬁlters	O
on	O
a	O
number	O
of	O
images	O
of	O
your	O
choice	O
and	O
see	O
if	O
you	O
can	O
reliably	O
ﬁnd	O
corner	O
and	O
intersection	O
features	O
.	O
these	O
ﬁlters	O
will	O
be	O
quite	O
useful	O
later	O
to	O
detect	O
elongated	O
structures	O
,	O
such	O
as	O
lines	B
(	O
section	O
4.3	O
)	O
.	O
ex	O
3.13	O
:	O
distance	O
transform	O
implement	O
some	O
(	O
raster-scan	O
)	O
algorithms	O
for	O
city	O
block	O
and	O
euclidean	O
distance	O
transforms	O
.	O
can	O
you	O
do	O
it	O
without	O
peeking	O
at	O
the	O
literature	O
(	O
danielsson	O
1980	O
;	O
borgefors	O
1986	O
)	O
?	O
if	O
so	O
,	O
what	O
problems	O
did	O
you	O
come	O
across	O
and	O
resolve	O
?	O
later	O
on	O
,	O
you	O
can	O
use	O
the	O
distance	O
functions	O
you	O
compute	O
to	O
perform	O
feathering	B
during	O
image	B
stitching	I
(	O
section	O
9.3.2	O
)	O
.	O
ex	O
3.14	O
:	O
connected	B
components	I
implement	O
one	O
of	O
the	O
connected	O
component	O
algorithms	O
from	O
section	O
3.3.4	O
or	O
section	O
2.3	O
from	O
haralick	O
and	O
shapiro	O
’	O
s	O
book	O
(	O
1992	O
)	O
and	O
discuss	O
its	O
computational	O
complexity	O
.	O
•	O
threshold	O
or	O
quantize	O
an	O
image	B
to	O
obtain	O
a	O
variety	O
of	O
input	O
labels	O
and	O
then	O
compute	O
the	O
area	O
statistics	O
for	O
the	O
regions	O
that	O
you	O
ﬁnd	O
.	O
•	O
use	O
the	O
connected	B
components	I
that	O
you	O
have	O
found	O
to	O
track	O
or	O
match	O
regions	O
in	O
differ-	O
ent	O
images	O
or	O
video	B
frames	O
.	O
ex	O
3.15	O
:	O
fourier	O
transform	B
prove	O
the	O
properties	B
of	O
the	O
fourier	O
transform	B
listed	O
in	O
ta-	O
ble	O
3.1	O
and	O
derive	O
the	O
formulas	O
for	O
the	O
fourier	O
transforms	O
listed	O
in	O
tables	O
3.2	O
and	O
3.3.	O
these	O
exercises	O
are	O
very	O
useful	O
if	O
you	O
want	O
to	O
become	O
comfortable	O
working	O
with	O
fourier	O
transforms	O
,	O
which	O
is	O
a	O
very	O
useful	O
skill	O
when	O
analyzing	O
and	O
designing	O
the	O
behavior	O
and	O
efﬁciency	B
of	O
many	O
computer	O
vision	O
algorithms	O
.	O
ex	O
3.16	O
:	O
wiener	O
ﬁltering	O
estimate	O
the	O
frequency	O
spectrum	O
of	O
your	O
personal	O
photo	O
collec-	O
tion	B
and	O
use	O
it	O
to	O
perform	O
wiener	O
ﬁltering	O
on	O
a	O
few	O
images	O
with	O
varying	O
degrees	O
of	O
noise	B
.	O
1.	O
collect	O
a	O
few	O
hundred	O
of	O
your	O
images	O
by	O
re-scaling	O
them	O
to	O
ﬁt	O
within	O
a	O
512	O
×	O
512	O
window	O
and	O
cropping	O
them	O
.	O
2.	O
take	O
their	O
fourier	O
transforms	O
,	O
throw	O
away	O
the	O
phase	O
information	O
,	O
and	O
average	O
together	O
all	O
of	O
the	O
spectra	O
.	O
3.	O
pick	O
two	O
of	O
your	O
favorite	O
images	O
and	O
add	O
varying	O
amounts	O
of	O
gaussian	O
noise	B
,	O
σn	O
∈	O
{	O
1	O
,	O
2	O
,	O
5	O
,	O
10	O
,	O
20	O
}	O
gray	O
levels	O
.	O
3.9	O
exercises	O
199	O
4.	O
for	O
each	O
combination	O
of	O
image	B
and	O
noise	B
,	O
determine	O
by	O
eye	O
which	O
width	O
of	O
a	O
gaussian	O
blurring	O
ﬁlter	O
σs	O
gives	O
the	O
best	O
denoised	O
result	O
.	O
you	O
will	O
have	O
to	O
make	O
a	O
subjective	O
decision	O
between	O
sharpness	O
and	O
noise	B
.	O
5.	O
compute	O
the	O
wiener	O
ﬁltered	O
version	O
of	O
all	O
the	O
noised	O
images	O
and	O
compare	O
them	O
against	O
your	O
hand-tuned	O
gaussian-smoothed	O
images	O
.	O
6	O
.	O
(	O
optional	O
)	O
do	O
your	O
image	B
spectra	O
have	O
a	O
lot	O
of	O
energy	O
concentrated	O
along	O
the	O
horizontal	O
and	O
vertical	O
axes	O
(	O
fx	O
=	O
0	O
and	O
fy	O
=	O
0	O
)	O
?	O
can	O
you	O
think	O
of	O
an	O
explanation	O
for	O
this	O
?	O
does	O
rotating	O
your	O
image	B
samples	O
by	O
45◦	O
move	O
this	O
energy	O
to	O
the	O
diagonals	O
?	O
if	O
not	O
,	O
could	O
it	O
be	O
due	O
to	O
edge	O
effects	O
in	O
the	O
fourier	O
transform	B
?	O
can	O
you	O
suggest	O
some	O
techniques	O
for	O
reducing	O
such	O
effects	O
?	O
ex	O
3.17	O
:	O
deblurring	O
using	O
wiener	O
ﬁltering	O
use	O
wiener	O
ﬁltering	O
to	O
deblur	O
some	O
images	O
.	O
1.	O
modify	O
the	O
wiener	O
ﬁlter	O
derivation	O
(	O
3.66–3.74	O
)	O
to	O
incorporate	O
blur	O
(	O
3.75	O
)	O
.	O
2.	O
discuss	O
the	O
resulting	O
wiener	O
ﬁlter	O
in	O
terms	O
of	O
its	O
noise	B
suppression	O
and	O
frequency	O
boosting	B
characteristics	O
.	O
3.	O
assuming	O
that	O
the	O
blur	O
kernel	O
is	O
gaussian	O
and	O
the	O
image	B
spectrum	O
follows	O
an	O
inverse	B
frequency	O
law	O
,	O
compute	O
the	O
frequency	O
response	O
of	O
the	O
wiener	O
ﬁlter	O
,	O
and	O
compare	O
it	O
to	O
the	O
unsharp	B
mask	I
.	O
4.	O
synthetically	O
blur	O
two	O
of	O
your	O
sample	O
images	O
with	O
gaussian	O
blur	O
kernels	O
of	O
different	O
radii	O
,	O
add	O
noise	B
,	O
and	O
then	O
perform	O
wiener	O
ﬁltering	O
.	O
5.	O
repeat	O
the	O
above	O
experiment	O
with	O
a	O
“	O
pillbox	O
”	O
(	O
disc	O
)	O
blurring	O
kernel	B
,	O
which	O
is	O
charac-	O
teristic	O
of	O
a	O
ﬁnite	O
aperture	O
lens	O
(	O
section	O
2.2.3	O
)	O
.	O
compare	O
these	O
results	O
to	O
gaussian	O
blur	O
kernels	O
(	O
be	O
sure	O
to	O
inspect	O
your	O
frequency	O
plots	O
)	O
.	O
6.	O
it	O
has	O
been	O
suggested	O
that	O
regular	O
apertures	O
are	O
anathema	O
to	O
de-blurring	O
because	O
they	O
introduce	O
zeros	O
in	O
the	O
sensed	O
frequency	O
spectrum	O
(	O
veeraraghavan	O
,	O
raskar	O
,	O
agrawal	O
et	O
al	O
.	O
2007	O
)	O
.	O
show	O
that	O
this	O
is	O
indeed	O
an	O
issue	O
if	O
no	O
prior	B
model	O
is	O
assumed	O
for	O
the	O
signal	O
,	O
i.e.	O
,	O
p	O
−1	O
l1	O
.	O
if	O
a	O
reasonable	O
power	B
spectrum	I
is	O
assumed	O
,	O
is	O
this	O
still	O
a	O
problem	O
(	O
do	O
we	O
still	O
get	O
banding	O
or	O
ringing	O
artifacts	O
)	O
?	O
s	O
ex	O
3.18	O
:	O
high-quality	O
image	B
resampling	O
implement	O
several	O
of	O
the	O
low-pass	B
ﬁlters	O
pre-	O
sented	O
in	O
section	O
3.5.2	O
and	O
also	O
the	O
discussion	O
of	O
the	O
windowed	B
sinc	I
shown	O
in	O
table	O
3.2	O
and	O
figure	O
3.29.	O
feel	O
free	O
to	O
implement	O
other	O
ﬁlters	O
(	O
wolberg	O
1990	O
;	O
unser	O
1999	O
)	O
.	O
apply	O
your	O
ﬁlters	O
to	O
continuously	O
resize	O
an	O
image	B
,	O
both	O
magnifying	O
(	O
interpolating	O
)	O
and	O
minifying	O
(	O
decimating	O
)	O
it	O
;	O
compare	O
the	O
resulting	O
animations	O
for	O
several	O
ﬁlters	O
.	O
use	O
both	O
a	O
200	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
3.65	O
sample	O
images	O
for	O
testing	O
the	O
quality	O
of	O
resampling	O
algorithms	O
:	O
(	O
a	O
)	O
a	O
synthetic	O
chirp	O
;	O
(	O
b	O
)	O
and	O
(	O
c	O
)	O
some	O
high-frequency	O
images	O
from	O
the	O
image	B
compression	O
community	O
.	O
synthetic	O
chirp	O
image	B
(	O
figure	O
3.65a	O
)	O
and	O
natural	B
images	O
with	O
lots	O
of	O
high-frequency	O
detail	O
(	O
figure	O
3.65b-c	O
)	O
.27	O
you	O
may	O
ﬁnd	O
it	O
helpful	O
to	O
write	O
a	O
simple	O
visualization	O
program	O
that	O
continuously	O
plays	O
the	O
animations	O
for	O
two	O
or	O
more	O
ﬁlters	O
at	O
once	O
and	O
that	O
let	O
you	O
“	O
blink	O
”	O
between	O
different	O
results	O
.	O
discuss	O
the	O
merits	O
and	O
deﬁciencies	O
of	O
each	O
ﬁlter	O
,	O
as	O
well	O
as	O
its	O
tradeoff	O
between	O
speed	O
and	O
quality	O
.	O
ex	O
3.19	O
:	O
pyramids	O
construct	O
an	O
image	B
pyramid	O
.	O
the	O
inputs	O
should	O
be	O
a	O
grayscale	O
or	O
color	B
image	O
,	O
a	O
separable	B
ﬁlter	O
kernel	B
,	O
and	O
the	O
number	O
of	O
desired	O
levels	O
.	O
implement	O
at	O
least	O
the	O
following	O
kernels	O
:	O
•	O
2	O
×	O
2	O
block	O
ﬁltering	O
;	O
•	O
burt	O
and	O
adelson	O
’	O
s	O
binomial	B
kernel	O
1/16	O
(	O
1	O
,	O
4	O
,	O
6	O
,	O
4	O
,	O
1	O
)	O
(	O
burt	O
and	O
adelson	O
1983a	O
)	O
;	O
•	O
a	O
high-quality	O
seven-	O
or	O
nine-tap	O
ﬁlter	O
.	O
compare	O
the	O
visual	O
quality	O
of	O
the	O
various	O
decimation	O
ﬁlters	O
.	O
also	O
,	O
shift	O
your	O
input	O
image	B
by	O
1	O
to	O
4	O
pixels	O
and	O
compare	O
the	O
resulting	O
decimated	O
(	O
quarter	O
size	O
)	O
image	B
sequence	O
.	O
ex	O
3.20	O
:	O
pyramid	B
blending	O
write	O
a	O
program	O
that	O
takes	O
as	O
input	O
two	O
color	O
images	O
and	O
a	O
binary	O
mask	O
image	B
and	O
produces	O
the	O
laplacian	O
pyramid	B
blend	O
of	O
the	O
two	O
images	O
.	O
1.	O
construct	O
the	O
laplacian	O
pyramid	B
for	O
each	O
image	B
.	O
2.	O
construct	O
the	O
gaussian	O
pyramid	B
for	O
the	O
two	O
mask	O
images	O
(	O
the	O
input	O
image	B
and	O
its	O
complement	O
)	O
.	O
27	O
these	O
particular	O
images	O
are	O
available	O
on	O
the	O
book	O
’	O
s	O
web	O
site	O
.	O
3.9	O
exercises	O
201	O
3.	O
multiply	O
each	O
laplacian	O
image	B
by	O
its	O
corresponding	O
mask	B
and	O
sum	O
the	O
images	O
(	O
see	O
figure	O
3.43	O
)	O
.	O
4.	O
reconstruct	O
the	O
ﬁnal	O
image	B
from	O
the	O
blended	O
laplacian	O
pyramid	B
.	O
generalize	O
your	O
algorithm	B
to	O
input	O
n	O
images	O
and	O
a	O
label	O
image	B
with	O
values	O
1	O
.	O
.	O
.	O
n	O
(	O
the	O
value	O
0	O
can	O
be	O
reserved	O
for	O
“	O
no	O
input	O
”	O
)	O
.	O
discuss	O
whether	O
the	O
weighted	B
summation	O
stage	O
(	O
step	O
3	O
)	O
needs	O
to	O
keep	O
track	O
of	O
the	O
total	B
weight	O
for	O
renormalization	O
,	O
or	O
whether	O
the	O
math	O
just	O
works	O
out	O
.	O
use	O
your	O
algorithm	B
either	O
to	O
blend	O
two	O
differently	O
exposed	O
image	B
(	O
to	O
avoid	O
under-	O
and	O
over-exposed	O
regions	O
)	O
or	O
to	O
make	O
a	O
creative	O
blend	O
of	O
two	O
different	O
scenes	O
.	O
ex	O
3.21	O
:	O
wavelet	O
construction	O
and	O
applications	O
implement	O
one	O
of	O
the	O
wavelet	O
families	O
described	O
in	O
section	O
3.5.4	O
or	O
by	O
simoncelli	O
and	O
adelson	O
(	O
1990b	O
)	O
,	O
as	O
well	O
as	O
the	O
basic	O
lapla-	O
cian	O
pyramid	B
(	O
exercise	O
3.19	O
)	O
.	O
apply	O
the	O
resulting	O
representations	O
to	O
one	O
of	O
the	O
following	O
two	O
tasks	O
:	O
•	O
compression	B
:	O
compute	O
the	O
entropy	O
in	O
each	O
band	O
for	O
the	O
different	O
wavelet	O
implemen-	O
tations	O
,	O
assuming	O
a	O
given	O
quantization	B
level	O
(	O
say	O
,	O
1/4	O
gray	O
level	O
,	O
to	O
keep	O
the	O
rounding	O
error	O
acceptable	O
)	O
.	O
quantize	O
the	O
wavelet	O
coefﬁcients	O
and	O
reconstruct	O
the	O
original	O
im-	O
ages	O
.	O
which	O
technique	O
performs	O
better	O
?	O
(	O
see	O
(	O
simoncelli	O
and	O
adelson	O
1990b	O
)	O
or	O
any	O
of	O
the	O
multitude	O
of	O
wavelet	O
compression	B
papers	O
for	O
some	O
typical	O
results	O
.	O
)	O
•	O
denoising	O
.	O
after	O
computing	O
the	O
wavelets	O
,	O
suppress	O
small	O
values	O
using	O
coring	O
,	O
i.e.	O
,	O
set	O
small	O
values	O
to	O
zero	O
using	O
a	O
piecewise	O
linear	B
or	O
other	O
c	O
0	O
function	O
.	O
compare	O
the	O
results	O
of	O
your	O
denoising	O
using	O
different	O
wavelet	O
and	O
pyramid	B
representations	O
.	O
ex	O
3.22	O
:	O
parametric	B
image	O
warping	O
write	O
the	O
code	O
to	O
do	O
afﬁne	B
and	O
perspective	B
image	O
warps	O
(	O
optionally	O
bilinear	B
as	O
well	O
)	O
.	O
try	O
a	O
variety	O
of	O
interpolants	O
and	O
report	O
on	O
their	O
visual	O
quality	O
.	O
in	O
particular	O
,	O
discuss	O
the	O
following	O
:	O
•	O
in	O
a	O
mip-map	O
,	O
selecting	O
only	O
the	O
coarser	O
level	O
adjacent	O
to	O
the	O
computed	O
fractional	O
level	O
will	O
produce	O
a	O
blurrier	O
image	B
,	O
while	O
selecting	O
the	O
ﬁner	O
level	O
will	O
lead	O
to	O
aliasing	B
.	O
explain	O
why	O
this	O
is	O
so	O
and	O
discuss	O
whether	O
blending	B
an	O
aliased	O
and	O
a	O
blurred	O
image	B
(	O
tri-linear	O
mip-mapping	O
)	O
is	O
a	O
good	O
idea	O
.	O
•	O
when	O
the	O
ratio	O
of	O
the	O
horizontal	O
and	O
vertical	O
resampling	O
rates	O
becomes	O
very	O
different	O
(	O
anisotropic	B
)	O
,	O
the	O
mip-map	O
performs	O
even	O
worse	O
.	O
suggest	O
some	O
approaches	O
to	O
reduce	O
such	O
problems	O
.	O
ex	O
3.23	O
:	O
local	B
image	O
warping	O
open	O
an	O
image	B
and	O
deform	O
its	O
appearance	O
in	O
one	O
of	O
the	O
following	O
ways	O
:	O
202	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
1.	O
click	O
on	O
a	O
number	O
of	O
pixels	O
and	O
move	O
(	O
drag	O
)	O
them	O
to	O
new	O
locations	O
.	O
interpolate	O
the	O
resulting	O
sparse	B
displacement	O
ﬁeld	O
to	O
obtain	O
a	O
dense	O
motion	O
ﬁeld	O
(	O
sections	O
3.6.2	O
and	O
3.5.1	O
)	O
.	O
2.	O
draw	O
a	O
number	O
of	O
lines	B
in	O
the	O
image	B
.	O
move	O
the	O
endpoints	O
of	O
the	O
lines	B
to	O
specify	O
their	O
new	O
positions	O
and	O
use	O
the	O
beier–neely	O
interpolation	B
algorithm	O
(	O
beier	O
and	O
neely	O
1992	O
)	O
,	O
discussed	O
in	O
section	O
3.6.2	O
,	O
to	O
get	O
a	O
dense	O
motion	O
ﬁeld	O
.	O
3.	O
overlay	O
a	O
spline	B
control	O
grid	O
and	O
move	O
one	O
grid	O
point	O
at	O
a	O
time	O
(	O
optionally	O
select	O
the	O
level	O
of	O
the	O
deformation	O
)	O
.	O
4.	O
have	O
a	O
dense	O
per-pixel	O
ﬂow	O
ﬁeld	O
and	O
use	O
a	O
soft	O
“	O
paintbrush	O
”	O
to	O
design	O
a	O
horizontal	O
and	O
vertical	O
velocity	O
ﬁeld	O
.	O
5	O
.	O
(	O
optional	O
)	O
:	O
prove	O
whether	O
the	O
beier–neely	O
warp	O
does	O
or	O
does	O
not	O
reduce	O
to	O
a	O
sparse	B
point-based	O
deformation	O
as	O
the	O
line	O
segments	O
become	O
shorter	O
(	O
reduce	O
to	O
points	B
)	O
.	O
ex	O
3.24	O
:	O
forward	B
warping	I
given	O
a	O
displacement	O
ﬁeld	O
from	O
the	O
previous	O
exercise	O
,	O
write	O
a	O
forward	B
warping	I
algorithm	O
:	O
1.	O
write	O
a	O
forward	B
warper	O
using	O
splatting	O
,	O
either	O
nearest	B
neighbor	I
or	O
soft	O
accumulation	O
(	O
section	O
3.6.1	O
)	O
.	O
2.	O
write	O
a	O
two-pass	O
algorithm	B
,	O
which	O
forward	B
warps	O
the	O
displacement	O
ﬁeld	O
,	O
ﬁlls	O
in	O
small	O
holes	O
,	O
and	O
then	O
uses	O
inverse	B
warping	I
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
.	O
3.	O
compare	O
the	O
quality	O
of	O
these	O
two	O
algorithms	O
.	O
ex	O
3.25	O
:	O
feature-based	B
morphing	O
extend	O
the	O
warping	O
code	O
you	O
wrote	O
in	O
exercise	O
3.23	O
to	O
import	O
two	O
different	O
images	O
and	O
specify	O
correspondences	O
(	O
point	O
,	O
line	O
,	O
or	O
mesh-based	O
)	O
be-	O
tween	O
the	O
two	O
images	O
.	O
1.	O
create	O
a	O
morph	O
by	O
partially	O
warping	O
the	O
images	O
towards	O
each	O
other	O
and	O
cross-dissolving	O
(	O
section	O
3.6.3	O
)	O
.	O
2.	O
try	O
using	O
your	O
morphing	B
algorithm	O
to	O
perform	O
an	O
image	B
rotation	O
and	O
discuss	O
whether	O
it	O
behaves	O
the	O
way	O
you	O
want	O
it	O
to	O
.	O
ex	O
3.26	O
:	O
2d	O
image	B
editor	O
extend	O
the	O
program	O
you	O
wrote	O
in	O
exercise	O
2.2	O
to	O
import	O
images	O
and	O
let	O
you	O
create	O
a	O
“	O
collage	O
”	O
of	O
pictures	O
.	O
you	O
should	O
implement	O
the	O
following	O
steps	O
:	O
1.	O
open	O
up	O
a	O
new	O
image	B
(	O
in	O
a	O
separate	O
window	O
)	O
.	O
3.9	O
exercises	O
203	O
figure	O
3.66	O
there	O
is	O
a	O
faint	O
image	B
of	O
a	O
rainbow	O
visible	O
in	O
the	O
right	O
hand	O
side	O
of	O
this	O
picture	O
.	O
can	O
you	O
think	O
of	O
a	O
way	O
to	O
enhance	O
it	O
(	O
exercise	O
3.29	O
)	O
?	O
2.	O
shift	O
drag	O
(	O
rubber-band	O
)	O
to	O
crop	O
a	O
subregion	O
(	O
or	O
select	O
whole	O
image	B
)	O
.	O
3.	O
paste	O
into	O
the	O
current	O
canvas	O
.	O
4.	O
select	O
the	O
deformation	O
mode	O
(	O
motion	B
model	O
)	O
:	O
translation	B
,	O
rigid	O
,	O
similarity	B
,	O
afﬁne	B
,	O
or	O
perspective	B
.	O
5.	O
drag	O
any	O
corner	O
of	O
the	O
outline	O
to	O
change	O
its	O
transformation	O
.	O
6	O
.	O
(	O
optional	O
)	O
change	O
the	O
relative	O
ordering	O
of	O
the	O
images	O
and	O
which	O
image	B
is	O
currently	O
being	O
manipulated	O
.	O
the	O
user	O
should	O
see	O
the	O
composition	O
of	O
the	O
various	O
images	O
’	O
pieces	O
on	O
top	O
of	O
each	O
other	O
.	O
this	O
exercise	O
should	O
be	O
built	O
on	O
the	O
image	B
transformation	O
classes	O
supported	O
in	O
the	O
soft-	O
ware	O
library	O
.	O
persistence	O
of	O
the	O
created	O
representation	O
(	O
save	O
and	O
load	O
)	O
should	O
also	O
be	O
sup-	O
ported	O
(	O
for	O
each	O
image	B
,	O
save	O
its	O
transformation	O
)	O
.	O
ex	O
3.27	O
:	O
3d	O
texture-mapped	O
viewer	O
extend	O
the	O
viewer	O
you	O
created	O
in	O
exercise	O
2.3	O
to	O
in-	O
clude	O
texture-mapped	O
polygon	O
rendering	B
.	O
augment	O
each	O
polygon	O
with	O
(	O
u	O
,	O
v	O
,	O
w	O
)	O
coordinates	O
into	O
an	O
image	B
.	O
ex	O
3.28	O
:	O
image	B
denoising	O
implement	O
at	O
least	O
two	O
of	O
the	O
various	O
image	B
denoising	O
tech-	O
niques	O
described	O
in	O
this	O
chapter	O
and	O
compare	O
them	O
on	O
both	O
synthetically	O
noised	O
image	B
se-	O
quences	O
and	O
real-world	O
(	O
low-light	O
)	O
sequences	O
.	O
does	O
the	O
performance	O
of	O
the	O
algorithm	B
de-	O
pend	O
on	O
the	O
correct	O
choice	O
of	O
noise	B
level	O
estimate	O
?	O
can	O
you	O
draw	O
any	O
conclusions	O
as	O
to	O
which	O
techniques	O
work	O
better	O
?	O
204	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ex	O
3.29	O
:	O
rainbow	O
enhancer—challenging	O
take	O
a	O
picture	O
containing	O
a	O
rainbow	O
,	O
such	O
as	O
figure	O
3.66	O
,	O
and	O
enhance	O
the	O
strength	O
(	O
saturation	O
)	O
of	O
the	O
rainbow	O
.	O
1.	O
draw	O
an	O
arc	O
in	O
the	O
image	B
delineating	O
the	O
extent	O
of	O
the	O
rainbow	O
.	O
2.	O
fit	O
an	O
additive	O
rainbow	O
function	O
(	O
explain	O
why	O
it	O
is	O
additive	O
)	O
to	O
this	O
arc	O
(	O
it	O
is	O
best	O
to	O
work	O
with	O
linearized	O
pixel	O
values	O
)	O
,	O
using	O
the	O
spectrum	O
as	O
the	O
cross	O
section	O
,	O
and	O
estimating	O
the	O
width	O
of	O
the	O
arc	O
and	O
the	O
amount	O
of	O
color	B
being	O
added	O
.	O
this	O
is	O
the	O
trickiest	O
part	O
of	O
the	O
problem	O
,	O
as	O
you	O
need	O
to	O
tease	O
apart	O
the	O
(	O
low-frequency	O
)	O
rainbow	O
pattern	O
and	O
the	O
natural	B
image	O
hiding	O
behind	O
it	O
.	O
3.	O
amplify	O
the	O
rainbow	O
signal	O
and	O
add	O
it	O
back	O
into	O
the	O
image	B
,	O
re-applying	O
the	O
gamma	B
function	O
if	O
necessary	O
to	O
produce	O
the	O
ﬁnal	O
image	B
.	O
ex	O
3.30	O
:	O
image	B
deblocking—challenging	O
now	O
that	O
you	O
have	O
some	O
good	O
techniques	O
to	O
distinguish	O
signal	O
from	O
noise	B
,	O
develop	O
a	O
technique	O
to	O
remove	O
the	O
blocking	O
artifacts	O
that	O
occur	O
with	O
jpeg	O
at	O
high	O
compression	O
settings	O
(	O
section	O
2.3.3	O
)	O
.	O
your	O
technique	O
can	O
be	O
as	O
simple	O
as	O
looking	O
for	O
unexpected	O
edges	O
along	O
block	O
boundaries	O
,	O
to	O
looking	O
at	O
the	O
quantization	B
step	O
as	O
a	O
projection	O
of	O
a	O
convex	O
region	B
of	O
the	O
transform	B
coefﬁcient	O
space	O
onto	O
the	O
corresponding	O
quantized	O
values	O
.	O
1.	O
does	O
the	O
knowledge	O
of	O
the	O
compression	B
factor	O
,	O
which	O
is	O
available	O
in	O
the	O
jpeg	O
header	O
information	O
,	O
help	O
you	O
perform	O
better	O
deblocking	B
?	O
2.	O
because	O
the	O
quantization	B
occurs	O
in	O
the	O
dct	O
transformed	O
ycbcr	O
space	O
(	O
2.115	O
)	O
,	O
it	O
may	O
be	O
preferable	O
to	O
perform	O
the	O
analysis	O
in	O
this	O
space	O
.	O
on	O
the	O
other	O
hand	O
,	O
image	B
priors	O
make	O
more	O
sense	O
in	O
an	O
rgb	O
space	O
(	O
or	O
do	O
they	O
?	O
)	O
.	O
decide	O
how	O
you	O
will	O
approach	O
this	O
dichotomy	O
and	O
discuss	O
your	O
choice	O
.	O
3.	O
while	O
you	O
are	O
at	O
it	O
,	O
since	O
the	O
ycbcr	O
conversion	O
is	O
followed	O
by	O
a	O
chrominance	O
subsam-	O
pling	O
stage	O
(	O
before	O
the	O
dct	O
)	O
,	O
see	O
if	O
you	O
can	O
restore	O
some	O
of	O
the	O
lost	O
high-frequency	O
chrominance	O
signal	O
using	O
one	O
of	O
the	O
better	O
restoration	O
techniques	O
discussed	O
in	O
this	O
chapter	O
.	O
4.	O
if	O
your	O
camera	B
has	O
a	O
raw	O
+	O
jpeg	O
mode	O
,	O
how	O
close	O
can	O
you	O
come	O
to	O
the	O
noise-free	O
true	O
pixel	O
values	O
?	O
(	O
this	O
suggestion	O
may	O
not	O
be	O
that	O
useful	O
,	O
since	O
cameras	O
generally	O
use	O
reasonably	O
high	O
quality	O
settings	O
for	O
their	O
raw	O
+	O
jpeg	O
models	O
.	O
)	O
ex	O
3.31	O
:	O
inference	B
in	O
de-blurring—challenging	O
write	O
down	O
the	O
graphical	O
model	O
corre-	O
sponding	O
to	O
figure	O
3.59	O
for	O
a	O
non-blind	O
image	B
deblurring	O
problem	O
,	O
i.e.	O
,	O
one	O
where	O
the	O
blur	O
kernel	O
is	O
known	O
ahead	O
of	O
time	O
.	O
what	O
kind	O
of	O
efﬁcient	O
inference	B
(	O
optimization	O
)	O
algorithms	O
can	O
you	O
think	O
of	O
for	O
solving	O
such	O
problems	O
?	O
chapter	O
4	O
feature	B
detection	O
and	O
matching	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
4.2	O
edges	O
.	O
.	O
4.1	O
points	B
and	O
patches	O
.	O
.	O
.	O
feature	B
detectors	O
.	O
.	O
feature	B
descriptors	O
.	O
feature	B
matching	O
.	O
.	O
.	O
feature	B
tracking	O
.	O
.	O
.	O
4.1.1	O
.	O
4.1.2	O
.	O
4.1.3	O
4.1.4	O
.	O
4.1.5	O
application	O
:	O
performance-driven	B
animation	I
.	O
.	O
.	O
.	O
4.2.1	O
edge	O
detection	O
.	O
4.2.2	O
edge	O
linking	O
.	O
.	O
.	O
4.2.3	O
application	O
:	O
edge	B
editing	I
and	O
enhancement	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
4.3	O
lines	B
.	O
4.3.1	O
.	O
4.3.2	O
hough	O
transforms	O
.	O
4.3.3	O
vanishing	B
points	I
.	O
.	O
4.3.4	O
application	O
:	O
rectangle	O
detection	B
.	O
.	O
.	O
4.4	O
additional	O
reading	O
.	O
4.5	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
successive	B
approximation	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
207	O
.	O
209	O
.	O
222	O
.	O
225	O
.	O
235	O
.	O
237	O
.	O
238	O
.	O
238	O
.	O
244	O
.	O
249	O
.	O
250	O
.	O
250	O
.	O
251	O
.	O
254	O
.	O
257	O
.	O
257	O
.	O
259	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
206	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
4.1	O
a	O
variety	O
of	O
feature	B
detectors	O
and	O
descriptors	O
can	O
be	O
used	O
to	O
analyze	O
,	O
describe	O
and	O
match	O
images	O
:	O
(	O
a	O
)	O
point-like	O
interest	O
operators	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
;	O
(	O
b	O
)	O
region-like	O
interest	O
operators	O
(	O
matas	O
,	O
chum	O
,	O
urban	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
elsevier	O
;	O
(	O
c	O
)	O
edges	O
(	O
elder	O
and	O
goldberg	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
;	O
(	O
d	O
)	O
straight	O
lines	B
(	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
acm	O
.	O
4.1	O
points	B
and	O
patches	O
207	O
feature	B
detection	O
and	O
matching	B
are	O
an	O
essential	O
component	O
of	O
many	O
computer	O
vision	O
appli-	O
cations	O
.	O
consider	O
the	O
two	O
pairs	O
of	O
images	O
shown	O
in	O
figure	O
4.2.	O
for	O
the	O
ﬁrst	O
pair	O
,	O
we	O
may	O
wish	O
to	O
align	O
the	O
two	O
images	O
so	O
that	O
they	O
can	O
be	O
seamlessly	O
stitched	O
into	O
a	O
composite	O
mosaic	O
(	O
chapter	O
9	O
)	O
.	O
for	O
the	O
second	O
pair	O
,	O
we	O
may	O
wish	O
to	O
establish	O
a	O
dense	O
set	O
of	O
correspondences	O
so	O
that	O
a	O
3d	O
model	O
can	O
be	O
constructed	O
or	O
an	O
in-between	O
view	O
can	O
be	O
generated	O
(	O
chapter	O
11	O
)	O
.	O
in	O
either	O
case	O
,	O
what	O
kinds	O
of	O
features	O
should	O
you	O
detect	O
and	O
then	O
match	O
in	O
order	B
to	O
establish	O
such	O
an	O
alignment	B
or	O
set	O
of	O
correspondences	O
?	O
think	O
about	O
this	O
for	O
a	O
few	O
moments	O
before	O
reading	O
on	O
.	O
the	O
ﬁrst	O
kind	O
of	O
feature	B
that	O
you	O
may	O
notice	O
are	O
speciﬁc	O
locations	O
in	O
the	O
images	O
,	O
such	O
as	O
mountain	O
peaks	O
,	O
building	O
corners	O
,	O
doorways	O
,	O
or	O
interestingly	O
shaped	O
patches	O
of	O
snow	O
.	O
these	O
kinds	O
of	O
localized	O
feature	B
are	O
often	O
called	O
keypoint	O
features	O
or	O
interest	O
points	B
(	O
or	O
even	O
corners	O
)	O
and	O
are	O
often	O
described	O
by	O
the	O
appearance	O
of	O
patches	O
of	O
pixels	O
surrounding	O
the	O
point	O
location	O
(	O
section	O
4.1	O
)	O
.	O
another	O
class	O
of	O
important	O
features	O
are	O
edges	O
,	O
e.g.	O
,	O
the	O
proﬁle	B
of	O
mountains	O
against	O
the	O
sky	O
,	O
(	O
section	O
4.2	O
)	O
.	O
these	O
kinds	O
of	O
features	O
can	O
be	O
matched	O
based	O
on	O
their	O
orien-	O
tation	O
and	O
local	B
appearance	O
(	O
edge	O
proﬁles	O
)	O
and	O
can	O
also	O
be	O
good	O
indicators	O
of	O
object	O
bound-	O
aries	O
and	O
occlusion	O
events	O
in	O
image	B
sequences	O
.	O
edges	O
can	O
be	O
grouped	O
into	O
longer	O
curves	O
and	O
straight	O
line	O
segments	O
,	O
which	O
can	O
be	O
directly	O
matched	O
or	O
analyzed	O
to	O
ﬁnd	O
vanishing	B
points	I
and	O
hence	O
internal	O
and	O
external	O
camera	B
parameters	O
(	O
section	O
4.3	O
)	O
.	O
in	O
this	O
chapter	O
,	O
we	O
describe	O
some	O
practical	O
approaches	O
to	O
detecting	O
such	O
features	O
and	O
also	O
discuss	O
how	O
feature	B
correspondences	O
can	O
be	O
established	O
across	O
different	O
images	O
.	O
point	O
features	O
are	O
now	O
used	O
in	O
such	O
a	O
wide	O
variety	O
of	O
applications	O
that	O
it	O
is	O
good	O
practice	O
to	O
read	O
and	O
implement	O
some	O
of	O
the	O
algorithms	O
from	O
(	O
section	O
4.1	O
)	O
.	O
edges	O
and	O
lines	B
provide	O
information	O
that	O
is	O
complementary	O
to	O
both	O
keypoint	O
and	O
region-based	B
descriptors	O
and	O
are	O
well-suited	O
to	O
describing	O
object	O
boundaries	O
and	O
man-made	O
objects	O
.	O
these	O
alternative	O
descriptors	O
,	O
while	O
extremely	O
useful	O
,	O
can	O
be	O
skipped	O
in	O
a	O
short	O
introductory	O
course	O
.	O
4.1	O
points	B
and	O
patches	O
point	O
features	O
can	O
be	O
used	O
to	O
ﬁnd	O
a	O
sparse	B
set	O
of	O
corresponding	O
locations	O
in	O
different	O
im-	O
ages	O
,	O
often	O
as	O
a	O
pre-cursor	O
to	O
computing	O
camera	B
pose	O
(	O
chapter	O
7	O
)	O
,	O
which	O
is	O
a	O
prerequisite	O
for	O
computing	O
a	O
denser	O
set	O
of	O
correspondences	O
using	O
stereo	O
matching	B
(	O
chapter	O
11	O
)	O
.	O
such	O
corre-	O
spondences	O
can	O
also	O
be	O
used	O
to	O
align	O
different	O
images	O
,	O
e.g.	O
,	O
when	O
stitching	O
image	B
mosaics	O
or	O
performing	O
video	B
stabilization	I
(	O
chapter	O
9	O
)	O
.	O
they	O
are	O
also	O
used	O
extensively	O
to	O
perform	O
object	O
instance	B
and	O
category	O
recognition	O
(	O
sections	O
14.3	O
and	O
14.4	O
)	O
.	O
a	O
key	O
advantage	O
of	O
keypoints	O
is	O
that	O
they	O
permit	O
matching	B
even	O
in	O
the	O
presence	O
of	O
clutter	O
(	O
occlusion	O
)	O
and	O
large	B
scale	I
and	O
orientation	O
changes	O
.	O
feature-based	B
correspondence	O
techniques	O
have	O
been	O
used	O
since	O
the	O
early	O
days	O
of	O
stereo	B
208	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.2	O
two	O
pairs	O
of	O
images	O
to	O
be	O
matched	O
.	O
what	O
kinds	O
of	O
feature	B
might	O
one	O
use	O
to	O
establish	O
a	O
set	O
of	O
correspondences	O
between	O
these	O
images	O
?	O
matching	B
(	O
hannah	O
1974	O
;	O
moravec	O
1983	O
;	O
hannah	O
1988	O
)	O
and	O
have	O
more	O
recently	O
gained	O
pop-	O
ularity	O
for	O
image-stitching	O
applications	O
(	O
zoghlami	O
,	O
faugeras	O
,	O
and	O
deriche	O
1997	O
;	O
brown	O
and	O
lowe	O
2007	O
)	O
as	O
well	O
as	O
fully	O
automated	B
3d	O
modeling	B
(	O
beardsley	O
,	O
torr	O
,	O
and	O
zisserman	O
1996	O
;	O
schaffalitzky	O
and	O
zisserman	O
2002	O
;	O
brown	O
and	O
lowe	O
2003	O
;	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
there	O
are	O
two	O
main	O
approaches	O
to	O
ﬁnding	O
feature	B
points	O
and	O
their	O
correspondences	O
.	O
the	O
ﬁrst	O
is	O
to	O
ﬁnd	O
features	O
in	O
one	O
image	B
that	O
can	O
be	O
accurately	O
tracked	O
using	O
a	O
local	B
search	O
tech-	O
nique	O
,	O
such	O
as	O
correlation	O
or	O
least	B
squares	I
(	O
section	O
4.1.4	O
)	O
.	O
the	O
second	O
is	O
to	O
independently	O
detect	O
features	O
in	O
all	O
the	O
images	O
under	O
consideration	O
and	O
then	O
match	O
features	O
based	O
on	O
their	O
local	B
appearance	O
(	O
section	O
4.1.3	O
)	O
.	O
the	O
former	O
approach	O
is	O
more	O
suitable	O
when	O
images	O
are	O
taken	O
from	O
nearby	O
viewpoints	O
or	O
in	O
rapid	O
succession	O
(	O
e.g.	O
,	O
video	B
sequences	O
)	O
,	O
while	O
the	O
lat-	O
ter	O
is	O
more	O
suitable	O
when	O
a	O
large	O
amount	O
of	O
motion	B
or	O
appearance	O
change	O
is	O
expected	O
,	O
e.g.	O
,	O
in	O
stitching	O
together	O
panoramas	O
(	O
brown	O
and	O
lowe	O
2007	O
)	O
,	O
establishing	O
correspondences	O
in	O
wide	O
baseline	O
stereo	B
(	O
schaffalitzky	O
and	O
zisserman	O
2002	O
)	O
,	O
or	O
performing	O
object	O
recognition	B
(	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2007	O
)	O
.	O
in	O
this	O
section	O
,	O
we	O
split	O
the	O
keypoint	O
detection	B
and	O
matching	B
pipeline	O
into	O
four	O
separate	O
stages	O
.	O
during	O
the	O
feature	B
detection	O
(	O
extraction	O
)	O
stage	O
(	O
section	O
4.1.1	O
)	O
,	O
each	O
image	B
is	O
searched	O
for	O
locations	O
that	O
are	O
likely	O
to	O
match	O
well	O
in	O
other	O
images	O
.	O
at	O
the	O
feature	B
description	O
stage	O
(	O
section	O
4.1.2	O
)	O
,	O
each	O
region	B
around	O
detected	O
keypoint	O
locations	O
is	O
converted	O
into	O
a	O
more	O
com-	O
pact	O
and	O
stable	O
(	O
invariant	O
)	O
descriptor	O
that	O
can	O
be	O
matched	O
against	O
other	O
descriptors	O
.	O
the	O
4.1	O
points	B
and	O
patches	O
209	O
figure	O
4.3	O
image	B
pairs	O
with	O
extracted	O
patches	O
below	O
.	O
notice	O
how	O
some	O
patches	O
can	O
be	O
localized	O
or	O
matched	O
with	O
higher	O
accuracy	B
than	O
others	O
.	O
feature	B
matching	O
stage	O
(	O
section	O
4.1.3	O
)	O
efﬁciently	O
searches	O
for	O
likely	O
matching	B
candidates	O
in	O
other	O
images	O
.	O
the	O
feature	B
tracking	O
stage	O
(	O
section	O
4.1.4	O
)	O
is	O
an	O
alternative	O
to	O
the	O
third	O
stage	O
that	O
only	O
searches	O
a	O
small	O
neighborhood	B
around	O
each	O
detected	O
feature	B
and	O
is	O
therefore	O
more	O
suitable	O
for	O
video	O
processing	O
.	O
a	O
wonderful	O
example	O
of	O
all	O
of	O
these	O
stages	O
can	O
be	O
found	O
in	O
david	O
lowe	O
’	O
s	O
(	O
2004	O
)	O
paper	O
,	O
which	O
describes	O
the	O
development	O
and	O
reﬁnement	O
of	O
his	O
scale	O
invariant	O
feature	B
transform	O
(	O
sift	O
)	O
.	O
comprehensive	O
descriptions	O
of	O
alternative	O
techniques	O
can	O
be	O
found	O
in	O
a	O
series	O
of	O
survey	O
and	O
evaluation	B
papers	O
covering	O
both	O
feature	B
detection	O
(	O
schmid	O
,	O
mohr	O
,	O
and	O
bauck-	O
hage	O
2000	O
;	O
mikolajczyk	O
,	O
tuytelaars	O
,	O
schmid	O
et	O
al	O
.	O
2005	O
;	O
tuytelaars	O
and	O
mikolajczyk	O
2007	O
)	O
and	O
feature	B
descriptors	O
(	O
mikolajczyk	O
and	O
schmid	O
2005	O
)	O
.	O
shi	O
and	O
tomasi	O
(	O
1994	O
)	O
and	O
triggs	O
(	O
2004	O
)	O
also	O
provide	O
nice	O
reviews	O
of	O
feature	B
detection	O
techniques	O
.	O
4.1.1	O
feature	B
detectors	O
how	O
can	O
we	O
ﬁnd	O
image	B
locations	O
where	O
we	O
can	O
reliably	O
ﬁnd	O
correspondences	O
with	O
other	O
images	O
,	O
i.e.	O
,	O
what	O
are	O
good	O
features	O
to	O
track	O
(	O
shi	O
and	O
tomasi	O
1994	O
;	O
triggs	O
2004	O
)	O
?	O
look	O
again	O
at	O
the	O
image	B
pair	O
shown	O
in	O
figure	O
4.3	O
and	O
at	O
the	O
three	O
sample	O
patches	O
to	O
see	O
how	O
well	O
they	O
might	O
be	O
matched	O
or	O
tracked	O
.	O
as	O
you	O
may	O
notice	O
,	O
textureless	O
patches	O
are	O
nearly	O
impossible	O
to	O
localize	O
.	O
patches	O
with	O
large	O
contrast	O
changes	O
(	O
gradients	O
)	O
are	O
easier	O
to	O
localize	O
,	O
although	O
straight	O
line	O
segments	O
at	O
a	O
single	O
orientation	O
suffer	O
from	O
the	O
aperture	B
problem	I
(	O
horn	O
and	O
schunck	O
1981	O
;	O
lucas	O
and	O
kanade	O
1981	O
;	O
anandan	O
1989	O
)	O
,	O
i.e.	O
,	O
it	O
is	O
only	O
possible	O
to	O
align	O
the	O
patches	O
along	O
the	O
direction	O
normal	O
to	O
the	O
edge	O
direction	O
(	O
figure	O
4.4b	O
)	O
.	O
patches	O
with	O
210	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
4.4	O
aperture	O
problems	O
for	O
different	O
image	B
patches	O
:	O
(	O
a	O
)	O
stable	O
(	O
“	O
corner-like	O
”	O
)	O
ﬂow	O
;	O
(	O
b	O
)	O
classic	O
aperture	B
problem	I
(	O
barber-pole	O
illusion	O
)	O
;	O
(	O
c	O
)	O
textureless	O
region	B
.	O
the	O
two	O
images	O
i0	O
(	O
yellow	O
)	O
and	O
i1	O
(	O
red	O
)	O
are	O
overlaid	O
.	O
the	O
red	O
vector	O
u	O
indicates	O
the	O
displacement	O
between	O
the	O
patch	B
centers	O
and	O
the	O
w	O
(	O
xi	O
)	O
weighting	B
function	O
(	O
patch	B
window	O
)	O
is	O
shown	O
as	O
a	O
dark	O
circle	O
.	O
gradients	O
in	O
at	O
least	O
two	O
(	O
signiﬁcantly	O
)	O
different	O
orientations	O
are	O
the	O
easiest	O
to	O
localize	O
,	O
as	O
shown	O
schematically	O
in	O
figure	O
4.4a	O
.	O
these	O
intuitions	O
can	O
be	O
formalized	O
by	O
looking	O
at	O
the	O
simplest	O
possible	O
matching	B
criterion	O
for	O
comparing	O
two	O
image	O
patches	O
,	O
i.e.	O
,	O
their	O
(	O
weighted	B
)	O
summed	O
square	O
difference	O
,	O
ewssd	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
w	O
(	O
xi	O
)	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
,	O
(	O
4.1	O
)	O
where	O
i0	O
and	O
i1	O
are	O
the	O
two	O
images	O
being	O
compared	O
,	O
u	O
=	O
(	O
u	O
,	O
v	O
)	O
is	O
the	O
displacement	O
vector	O
,	O
w	O
(	O
x	O
)	O
is	O
a	O
spatially	O
varying	O
weighting	O
(	O
or	O
window	O
)	O
function	O
,	O
and	O
the	O
summation	O
i	O
is	O
over	O
all	O
the	O
pixels	O
in	O
the	O
patch	B
.	O
note	O
that	O
this	O
is	O
the	O
same	O
formulation	O
we	O
later	O
use	O
to	O
estimate	O
motion	B
between	O
complete	O
images	O
(	O
section	O
8.1	O
)	O
.	O
when	O
performing	O
feature	B
detection	O
,	O
we	O
do	O
not	O
know	O
which	O
other	O
image	B
locations	O
the	O
feature	B
will	O
end	O
up	O
being	O
matched	O
against	O
.	O
therefore	O
,	O
we	O
can	O
only	O
compute	O
how	O
stable	O
this	O
metric	O
is	O
with	O
respect	O
to	O
small	O
variations	O
in	O
position	O
∆u	O
by	O
comparing	O
an	O
image	B
patch	O
against	O
itself	O
,	O
which	O
is	O
known	O
as	O
an	O
auto-correlation	B
function	O
or	O
surface	B
eac	O
(	O
∆u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
w	O
(	O
xi	O
)	O
[	O
i0	O
(	O
xi	O
+	O
∆u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
(	O
4.2	O
)	O
(	O
figure	O
4.5	O
)	O
.1	O
note	O
how	O
the	O
auto-correlation	B
surface	O
for	O
the	O
textured	O
ﬂower	O
bed	O
(	O
figure	O
4.5b	O
and	O
the	O
red	O
cross	O
in	O
the	O
lower	O
right	O
quadrant	O
of	O
figure	O
4.5a	O
)	O
exhibits	O
a	O
strong	O
minimum	O
,	O
indicating	O
that	O
it	O
can	O
be	O
well	O
localized	O
.	O
the	O
correlation	O
surface	B
corresponding	O
to	O
the	O
roof	O
edge	O
(	O
figure	O
4.5c	O
)	O
has	O
a	O
strong	O
ambiguity	O
along	O
one	O
direction	O
,	O
while	O
the	O
correlation	O
surface	B
corresponding	O
to	O
the	O
cloud	O
region	B
(	O
figure	O
4.5d	O
)	O
has	O
no	O
stable	O
minimum	O
.	O
1	O
strictly	O
speaking	O
,	O
a	O
correlation	O
is	O
the	O
product	O
of	O
two	O
patches	O
(	O
3.12	O
)	O
;	O
i	O
’	O
m	O
using	O
the	O
term	O
here	O
in	O
a	O
more	O
qualitative	O
sense	O
.	O
the	O
weighted	B
sum	O
of	O
squared	O
differences	O
is	O
often	O
called	O
an	O
ssd	O
surface	B
(	O
section	O
8.1	O
)	O
.	O
xxixi+uui	O
4.1	O
points	B
and	O
patches	O
211	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
4.5	O
three	O
auto-correlation	B
surfaces	O
eac	O
(	O
∆u	O
)	O
shown	O
as	O
both	O
grayscale	O
images	O
and	O
surface	B
plots	O
:	O
(	O
a	O
)	O
the	O
original	O
image	B
is	O
marked	O
with	O
three	O
red	O
crosses	O
to	O
denote	O
where	O
the	O
auto-correlation	B
surfaces	O
were	O
computed	O
;	O
(	O
b	O
)	O
this	O
patch	B
is	O
from	O
the	O
ﬂower	O
bed	O
(	O
good	O
unique	O
minimum	O
)	O
;	O
(	O
c	O
)	O
this	O
patch	B
is	O
from	O
the	O
roof	O
edge	O
(	O
one-dimensional	O
aperture	B
problem	I
)	O
;	O
and	O
(	O
d	O
)	O
this	O
patch	B
is	O
from	O
the	O
cloud	O
(	O
no	O
good	O
peak	O
)	O
.	O
each	O
grid	O
point	O
in	O
ﬁgures	O
b–d	O
is	O
one	O
value	O
of	O
∆u	O
.	O
212	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
using	O
a	O
taylor	O
series	O
expansion	O
of	O
the	O
image	B
function	O
i0	O
(	O
xi	O
+∆u	O
)	O
≈	O
i0	O
(	O
xi	O
)	O
+∇i0	O
(	O
xi	O
)	O
·	O
∆u	O
(	O
lucas	O
and	O
kanade	O
1981	O
;	O
shi	O
and	O
tomasi	O
1994	O
)	O
,	O
we	O
can	O
approximate	O
the	O
auto-correlation	B
surface	O
as	O
eac	O
(	O
∆u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
≈	O
(	O
cid:88	O
)	O
i	O
=	O
(	O
cid:88	O
)	O
i	O
w	O
(	O
xi	O
)	O
[	O
i0	O
(	O
xi	O
+	O
∆u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
w	O
(	O
xi	O
)	O
[	O
i0	O
(	O
xi	O
)	O
+	O
∇i0	O
(	O
xi	O
)	O
·	O
∆u	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
w	O
(	O
xi	O
)	O
[	O
∇i0	O
(	O
xi	O
)	O
·	O
∆u	O
]	O
2	O
=	O
∆ut	O
a∆u	O
,	O
where	O
∇i0	O
(	O
xi	O
)	O
=	O
(	O
∂i0	O
∂x	O
,	O
∂i0	O
∂y	O
)	O
(	O
xi	O
)	O
(	O
4.3	O
)	O
(	O
4.4	O
)	O
(	O
4.5	O
)	O
(	O
4.6	O
)	O
(	O
4.7	O
)	O
(	O
4.8	O
)	O
is	O
the	O
image	B
gradient	O
at	O
xi	O
.	O
this	O
gradient	O
can	O
be	O
computed	O
using	O
a	O
variety	O
of	O
techniques	O
(	O
schmid	O
,	O
mohr	O
,	O
and	O
bauckhage	O
2000	O
)	O
.	O
the	O
classic	O
“	O
harris	O
”	O
detector	O
(	O
harris	O
and	O
stephens	O
1988	O
)	O
uses	O
a	O
[	O
-2	O
-1	O
0	O
1	O
2	O
]	O
ﬁlter	O
,	O
but	O
more	O
modern	O
variants	O
(	O
schmid	O
,	O
mohr	O
,	O
and	O
bauckhage	O
2000	O
;	O
triggs	O
2004	O
)	O
convolve	O
the	O
image	B
with	O
horizontal	O
and	O
vertical	O
derivatives	O
of	O
a	O
gaussian	O
(	O
typically	O
with	O
σ	O
=	O
1	O
)	O
.	O
the	O
auto-correlation	B
matrix	O
a	O
can	O
be	O
written	O
as	O
a	O
=	O
w	O
∗	O
(	O
cid:34	O
)	O
i	O
2	O
x	O
ixiy	O
y	O
(	O
cid:35	O
)	O
,	O
ixiy	O
i	O
2	O
where	O
we	O
have	O
replaced	O
the	O
weighted	B
summations	O
with	O
discrete	O
convolutions	O
with	O
the	O
weight-	O
ing	O
kernel	B
w.	O
this	O
matrix	O
can	O
be	O
interpreted	O
as	O
a	O
tensor	O
(	O
multiband	O
)	O
image	B
,	O
where	O
the	O
outer	O
products	O
of	O
the	O
gradients	O
∇i	O
are	O
convolved	O
with	O
a	O
weighting	B
function	O
w	O
to	O
provide	O
a	O
per-pixel	O
estimate	O
of	O
the	O
local	B
(	O
quadratic	O
)	O
shape	O
of	O
the	O
auto-correlation	B
function	O
.	O
as	O
ﬁrst	O
shown	O
by	O
anandan	O
(	O
1984	O
;	O
1989	O
)	O
and	O
further	O
discussed	O
in	O
section	O
8.1.3	O
and	O
(	O
8.44	O
)	O
,	O
the	O
inverse	B
of	O
the	O
matrix	O
a	O
provides	O
a	O
lower	O
bound	O
on	O
the	O
uncertainty	B
in	O
the	O
location	O
of	O
a	O
matching	B
patch	O
.	O
it	O
is	O
therefore	O
a	O
useful	O
indicator	O
of	O
which	O
patches	O
can	O
be	O
reliably	O
matched	O
.	O
the	O
easiest	O
way	O
to	O
visualize	O
and	O
reason	O
about	O
this	O
uncertainty	B
is	O
to	O
perform	O
an	O
eigenvalue	O
analysis	O
of	O
the	O
auto-correlation	B
matrix	O
a	O
,	O
which	O
produces	O
two	O
eigenvalues	O
(	O
λ0	O
,	O
λ1	O
)	O
and	O
two	O
eigenvector	O
directions	O
(	O
figure	O
4.6	O
)	O
.	O
since	O
the	O
larger	O
uncertainty	B
depends	O
on	O
the	O
smaller	O
eigen-	O
value	O
,	O
i.e.	O
,	O
λ−1/2	O
,	O
it	O
makes	O
sense	O
to	O
ﬁnd	O
maxima	O
in	O
the	O
smaller	O
eigenvalue	O
to	O
locate	O
good	O
features	O
to	O
track	O
(	O
shi	O
and	O
tomasi	O
1994	O
)	O
.	O
0	O
f¨orstner–harris	O
.	O
while	O
anandan	O
and	O
lucas	O
and	O
kanade	O
(	O
1981	O
)	O
were	O
the	O
ﬁrst	O
to	O
analyze	O
the	O
uncertainty	B
structure	O
of	O
the	O
auto-correlation	B
matrix	O
,	O
they	O
did	O
so	O
in	O
the	O
context	B
of	O
asso-	O
ciating	O
certainties	O
with	O
optic	O
ﬂow	O
measurements	O
.	O
f¨orstner	O
(	O
1986	O
)	O
and	O
harris	O
and	O
stephens	O
4.1	O
points	B
and	O
patches	O
213	O
figure	O
4.6	O
uncertainty	B
ellipse	O
corresponding	O
to	O
an	O
eigenvalue	O
analysis	O
of	O
the	O
auto-	O
correlation	O
matrix	O
a	O
.	O
(	O
1988	O
)	O
were	O
the	O
ﬁrst	O
to	O
propose	O
using	O
local	O
maxima	O
in	O
rotationally	O
invariant	O
scalar	O
measures	O
derived	O
from	O
the	O
auto-correlation	B
matrix	O
to	O
locate	O
keypoints	O
for	O
the	O
purpose	O
of	O
sparse	B
feature	O
matching	B
.	O
(	O
schmid	O
,	O
mohr	O
,	O
and	O
bauckhage	O
(	O
2000	O
)	O
;	O
triggs	O
(	O
2004	O
)	O
give	O
more	O
detailed	O
histori-	O
cal	O
reviews	O
of	O
feature	B
detection	O
algorithms	O
.	O
)	O
both	O
of	O
these	O
techniques	O
also	O
proposed	O
using	O
a	O
gaussian	O
weighting	B
window	O
instead	O
of	O
the	O
previously	O
used	O
square	O
patches	O
,	O
which	O
makes	O
the	O
detector	O
response	O
insensitive	O
to	O
in-plane	O
image	B
rotations	O
.	O
the	O
minimum	O
eigenvalue	O
λ0	O
(	O
shi	O
and	O
tomasi	O
1994	O
)	O
is	O
not	O
the	O
only	O
quantity	O
that	O
can	O
be	O
used	O
to	O
ﬁnd	O
keypoints	O
.	O
a	O
simpler	O
quantity	O
,	O
proposed	O
by	O
harris	O
and	O
stephens	O
(	O
1988	O
)	O
,	O
is	O
det	O
(	O
a	O
)	O
−	O
α	O
trace	O
(	O
a	O
)	O
2	O
=	O
λ0λ1	O
−	O
α	O
(	O
λ0	O
+	O
λ1	O
)	O
2	O
(	O
4.9	O
)	O
with	O
α	O
=	O
0.06.	O
unlike	O
eigenvalue	O
analysis	O
,	O
this	O
quantity	O
does	O
not	O
require	O
the	O
use	O
of	O
square	O
roots	O
and	O
yet	O
is	O
still	O
rotationally	O
invariant	O
and	O
also	O
downweights	O
edge-like	O
features	O
where	O
λ1	O
(	O
cid:29	O
)	O
λ0	O
.	O
triggs	O
(	O
2004	O
)	O
suggests	O
using	O
the	O
quantity	O
λ0	O
−	O
αλ1	O
(	O
4.10	O
)	O
(	O
say	O
,	O
with	O
α	O
=	O
0.05	O
)	O
,	O
which	O
also	O
reduces	O
the	O
response	O
at	O
1d	O
edges	O
,	O
where	O
aliasing	B
errors	O
sometimes	O
inﬂate	O
the	O
smaller	O
eigenvalue	O
.	O
he	O
also	O
shows	O
how	O
the	O
basic	O
2	O
×	O
2	O
hessian	O
can	O
be	O
extended	O
to	O
parametric	B
motions	O
to	O
detect	O
points	B
that	O
are	O
also	O
accurately	O
localizable	O
in	O
scale	O
and	O
rotation	O
.	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
(	O
2005	O
)	O
,	O
on	O
the	O
other	O
hand	O
,	O
use	O
the	O
harmonic	O
mean	O
,	O
det	O
a	O
tr	O
a	O
=	O
λ0λ1	O
λ0	O
+	O
λ1	O
,	O
(	O
4.11	O
)	O
which	O
is	O
a	O
smoother	O
function	O
in	O
the	O
region	B
where	O
λ0	O
≈	O
λ1	O
.	O
figure	O
4.7	O
shows	O
isocontours	O
of	O
the	O
various	O
interest	O
point	O
operators	O
,	O
from	O
which	O
we	O
can	O
see	O
how	O
the	O
two	O
eigenvalues	O
are	O
blended	O
to	O
determine	O
the	O
ﬁnal	O
interest	O
value	O
.	O
214	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.7	O
isocontours	O
of	O
popular	O
keypoint	O
detection	B
functions	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2004	O
)	O
.	O
each	O
detector	O
looks	O
for	O
points	O
where	O
the	O
eigenvalues	B
λ0	O
,	O
λ1	O
of	O
a	O
=	O
w	O
∗	O
∇i∇i	O
t	O
are	O
both	O
large	O
.	O
1.	O
compute	O
the	O
horizontal	O
and	O
vertical	O
derivatives	O
of	O
the	O
image	B
ix	O
and	O
iy	O
by	O
con-	O
volving	O
the	O
original	O
image	B
with	O
derivatives	O
of	O
gaussians	O
(	O
section	O
3.2.3	O
)	O
.	O
2.	O
compute	O
the	O
three	O
images	O
corresponding	O
to	O
the	O
outer	O
products	O
of	O
these	O
gradients	O
.	O
(	O
the	O
matrix	O
a	O
is	O
symmetric	O
,	O
so	O
only	O
three	O
entries	O
are	O
needed	O
.	O
)	O
3.	O
convolve	O
each	O
of	O
these	O
images	O
with	O
a	O
larger	O
gaussian	O
.	O
4.	O
compute	O
a	O
scalar	O
interest	O
measure	O
using	O
one	O
of	O
the	O
formulas	O
discussed	O
above	O
.	O
5.	O
find	O
local	B
maxima	O
above	O
a	O
certain	O
threshold	O
and	O
report	O
them	O
as	O
detected	O
feature	B
point	O
locations	O
.	O
algorithm	B
4.1	O
outline	O
of	O
a	O
basic	O
feature	B
detection	O
algorithm	B
.	O
4.1	O
points	B
and	O
patches	O
215	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
4.8	O
interest	O
operator	O
responses	O
:	O
(	O
a	O
)	O
sample	O
image	B
,	O
(	O
b	O
)	O
harris	O
response	O
,	O
and	O
(	O
c	O
)	O
dog	O
response	O
.	O
the	O
circle	O
sizes	O
and	O
colors	O
indicate	O
the	O
scale	O
at	O
which	O
each	O
interest	O
point	O
was	O
detected	O
.	O
notice	O
how	O
the	O
two	O
detectors	O
tend	O
to	O
respond	O
at	O
complementary	O
locations	O
.	O
the	O
steps	O
in	O
the	O
basic	O
auto-correlation-based	O
keypoint	O
detector	O
are	O
summarized	O
in	O
algo-	O
rithm	O
4.1.	O
figure	O
4.8	O
shows	O
the	O
resulting	O
interest	O
operator	O
responses	O
for	O
the	O
classic	O
harris	O
detector	O
as	O
well	O
as	O
the	O
difference	B
of	O
gaussian	O
(	O
dog	O
)	O
detector	O
discussed	O
below	O
.	O
adaptive	B
non-maximal	O
suppression	O
(	O
anms	O
)	O
.	O
while	O
most	O
feature	B
detectors	O
simply	O
look	O
for	O
local	O
maxima	O
in	O
the	O
interest	O
function	O
,	O
this	O
can	O
lead	O
to	O
an	O
uneven	O
distribution	O
of	O
feature	B
points	O
across	O
the	O
image	B
,	O
e.g.	O
,	O
points	B
will	O
be	O
denser	O
in	O
regions	O
of	O
higher	O
contrast	O
.	O
to	O
mitigate	O
this	O
problem	O
,	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
(	O
2005	O
)	O
only	O
detect	O
features	O
that	O
are	O
both	O
local	B
maxima	O
and	O
whose	O
response	O
value	O
is	O
signiﬁcantly	O
(	O
10	O
%	O
)	O
greater	O
than	O
that	O
of	O
all	O
of	O
its	O
neigh-	O
bors	O
within	O
a	O
radius	O
r	O
(	O
figure	O
4.9c–d	O
)	O
.	O
they	O
devise	O
an	O
efﬁcient	O
way	O
to	O
associate	O
suppression	O
radii	O
with	O
all	O
local	B
maxima	O
by	O
ﬁrst	O
sorting	O
them	O
by	O
their	O
response	O
strength	O
and	O
then	O
creating	O
a	O
second	O
list	O
sorted	O
by	O
decreasing	O
suppression	O
radius	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
.	O
figure	O
4.9	O
shows	O
a	O
qualitative	O
comparison	O
of	O
selecting	O
the	O
top	O
n	O
features	O
and	O
using	O
anms	O
.	O
measuring	O
repeatability	B
.	O
given	O
the	O
large	O
number	O
of	O
feature	B
detectors	O
that	O
have	O
been	O
de-	O
veloped	O
in	O
computer	O
vision	O
,	O
how	O
can	O
we	O
decide	O
which	O
ones	O
to	O
use	O
?	O
schmid	O
,	O
mohr	O
,	O
and	O
bauckhage	O
(	O
2000	O
)	O
were	O
the	O
ﬁrst	O
to	O
propose	O
measuring	O
the	O
repeatability	B
of	O
feature	B
detectors	O
,	O
which	O
they	O
deﬁne	O
as	O
the	O
frequency	O
with	O
which	O
keypoints	O
detected	O
in	O
one	O
image	B
are	O
found	O
within	O
	O
(	O
say	O
,	O
	O
=	O
1.5	O
)	O
pixels	O
of	O
the	O
corresponding	O
location	O
in	O
a	O
transformed	O
image	B
.	O
in	O
their	O
paper	O
,	O
they	O
transform	B
their	O
planar	O
images	O
by	O
applying	O
rotations	O
,	O
scale	O
changes	O
,	O
illumination	O
changes	O
,	O
viewpoint	O
changes	O
,	O
and	O
adding	O
noise	B
.	O
they	O
also	O
measure	O
the	O
information	O
content	O
available	O
at	O
each	O
detected	O
feature	B
point	O
,	O
which	O
they	O
deﬁne	O
as	O
the	O
entropy	O
of	O
a	O
set	O
of	O
rotation-	O
ally	O
invariant	O
local	B
grayscale	O
descriptors	O
.	O
among	O
the	O
techniques	O
they	O
survey	O
,	O
they	O
ﬁnd	O
that	O
the	O
improved	O
(	O
gaussian	O
derivative	O
)	O
version	O
of	O
the	O
harris	O
operator	O
with	O
σd	O
=	O
1	O
(	O
scale	O
of	O
the	O
derivative	O
gaussian	O
)	O
and	O
σi	O
=	O
2	O
(	O
scale	O
of	O
the	O
integration	O
gaussian	O
)	O
works	O
best	O
.	O
216	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
strongest	O
250	O
(	O
b	O
)	O
strongest	O
500	O
(	O
c	O
)	O
anms	O
250	O
,	O
r	O
=	O
24	O
(	O
d	O
)	O
anms	O
500	O
,	O
r	O
=	O
16	O
figure	O
4.9	O
adaptive	B
non-maximal	O
suppression	O
(	O
anms	O
)	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
:	O
the	O
upper	O
two	O
images	O
show	O
the	O
strongest	O
250	O
and	O
500	O
interest	O
points	B
,	O
while	O
the	O
lower	O
two	O
images	O
show	O
the	O
interest	O
points	B
selected	O
with	O
adaptive	O
non-maximal	O
sup-	O
pression	O
,	O
along	O
with	O
the	O
corresponding	O
suppression	O
radius	O
r.	O
note	O
how	O
the	O
latter	O
features	O
have	O
a	O
much	O
more	O
uniform	O
spatial	O
distribution	O
across	O
the	O
image	B
.	O
scale	B
invariance	I
in	O
many	O
situations	O
,	O
detecting	O
features	O
at	O
the	O
ﬁnest	O
stable	O
scale	O
possible	O
may	O
not	O
be	O
appro-	O
priate	O
.	O
for	O
example	O
,	O
when	O
matching	B
images	O
with	O
little	O
high	O
frequency	O
detail	O
(	O
e.g.	O
,	O
clouds	O
)	O
,	O
ﬁne-scale	O
features	O
may	O
not	O
exist	O
.	O
one	O
solution	O
to	O
the	O
problem	O
is	O
to	O
extract	O
features	O
at	O
a	O
variety	O
of	O
scales	O
,	O
e.g.	O
,	O
by	O
performing	O
the	O
same	O
operations	O
at	O
multiple	B
resolutions	O
in	O
a	O
pyramid	B
and	O
then	O
matching	B
features	O
at	O
the	O
same	O
level	O
.	O
this	O
kind	O
of	O
approach	O
is	O
suitable	O
when	O
the	O
images	O
being	O
matched	O
do	O
not	O
undergo	O
large	B
scale	I
changes	O
,	O
e.g.	O
,	O
when	O
matching	B
successive	O
aerial	O
images	O
taken	O
from	O
an	O
airplane	O
or	O
stitching	O
panoramas	O
taken	O
with	O
a	O
ﬁxed-focal-length	O
camera	B
.	O
figure	O
4.10	O
shows	O
the	O
output	O
of	O
one	O
such	O
approach	O
,	O
the	O
multi-scale	O
,	O
oriented	B
patch	O
detector	O
of	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
(	O
2005	O
)	O
,	O
for	O
which	O
responses	O
at	O
ﬁve	O
different	O
scales	O
are	O
shown	O
.	O
however	O
,	O
for	O
most	O
object	O
recognition	B
applications	O
,	O
the	O
scale	O
of	O
the	O
object	O
in	O
the	O
image	B
4.1	O
points	B
and	O
patches	O
217	O
figure	O
4.10	O
multi-scale	O
oriented	B
patches	O
(	O
mops	O
)	O
extracted	O
at	O
ﬁve	O
pyramid	B
levels	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
.	O
the	O
boxes	O
show	O
the	O
feature	B
orientation	O
and	O
the	O
region	B
from	O
which	O
the	O
descriptor	O
vectors	O
are	O
sampled	O
.	O
is	O
unknown	O
.	O
instead	O
of	O
extracting	O
features	O
at	O
many	O
different	O
scales	O
and	O
then	O
matching	B
all	O
of	O
them	O
,	O
it	O
is	O
more	O
efﬁcient	O
to	O
extract	O
features	O
that	O
are	O
stable	O
in	O
both	O
location	O
and	O
scale	O
(	O
lowe	O
2004	O
;	O
mikolajczyk	O
and	O
schmid	O
2004	O
)	O
.	O
early	O
investigations	O
into	O
scale	B
selection	I
were	O
performed	O
by	O
lindeberg	O
(	O
1993	O
;	O
1998b	O
)	O
,	O
who	O
ﬁrst	O
proposed	O
using	O
extrema	O
in	O
the	O
laplacian	O
of	O
gaussian	O
(	O
log	O
)	O
function	O
as	O
interest	O
point	O
locations	O
.	O
based	O
on	O
this	O
work	O
,	O
lowe	O
(	O
2004	O
)	O
proposed	O
computing	O
a	O
set	O
of	O
sub-octave	O
difference	B
of	O
gaussian	O
ﬁlters	O
(	O
figure	O
4.11a	O
)	O
,	O
looking	O
for	O
3d	O
(	O
space+scale	O
)	O
maxima	O
in	O
the	O
re-	O
sulting	O
structure	O
(	O
figure	O
4.11b	O
)	O
,	O
and	O
then	O
computing	O
a	O
sub-pixel	O
space+scale	O
location	O
using	O
a	O
quadratic	O
ﬁt	O
(	O
brown	O
and	O
lowe	O
2002	O
)	O
.	O
the	O
number	O
of	O
sub-octave	O
levels	O
was	O
determined	O
,	O
after	O
careful	O
empirical	O
investigation	O
,	O
to	O
be	O
three	O
,	O
which	O
corresponds	O
to	O
a	O
quarter-octave	O
pyramid	B
,	O
which	O
is	O
the	O
same	O
as	O
used	O
by	O
triggs	O
(	O
2004	O
)	O
.	O
as	O
with	O
the	O
harris	O
operator	O
,	O
pixels	O
where	O
there	O
is	O
strong	O
asymmetry	O
in	O
the	O
local	B
curvature	O
of	O
the	O
indicator	O
function	O
(	O
in	O
this	O
case	O
,	O
the	O
dog	O
)	O
are	O
rejected	O
.	O
this	O
is	O
implemented	O
by	O
ﬁrst	O
computing	O
the	O
local	B
hessian	O
of	O
the	O
difference	B
image	O
d	O
,	O
h	O
=	O
(	O
cid:34	O
)	O
dxx	O
dxy	O
dxy	O
dyy	O
(	O
cid:35	O
)	O
,	O
and	O
then	O
rejecting	O
keypoints	O
for	O
which	O
tr	O
(	O
h	O
)	O
2	O
det	O
(	O
h	O
)	O
>	O
10	O
.	O
(	O
4.12	O
)	O
(	O
4.13	O
)	O
218	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
4.11	O
scale-space	O
feature	B
detection	O
using	O
a	O
sub-octave	O
difference	B
of	O
gaussian	O
pyra-	O
mid	O
(	O
lowe	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
:	O
(	O
a	O
)	O
adjacent	O
levels	O
of	O
a	O
sub-octave	O
gaussian	O
pyramid	B
are	O
subtracted	O
to	O
produce	O
difference	B
of	O
gaussian	O
images	O
;	O
(	O
b	O
)	O
extrema	O
(	O
maxima	O
and	O
minima	O
)	O
in	O
the	O
resulting	O
3d	O
volume	O
are	O
detected	O
by	O
comparing	O
a	O
pixel	O
to	O
its	O
26	O
neighbors	O
.	O
while	O
lowe	O
’	O
s	O
scale	O
invariant	O
feature	B
transform	O
(	O
sift	O
)	O
performs	O
well	O
in	O
practice	O
,	O
it	O
is	O
not	O
based	O
on	O
the	O
same	O
theoretical	O
foundation	O
of	O
maximum	O
spatial	O
stability	O
as	O
the	O
auto-correlation-	O
based	O
detectors	O
.	O
(	O
in	O
fact	O
,	O
its	O
detection	B
locations	O
are	O
often	O
complementary	O
to	O
those	O
produced	O
by	O
such	O
techniques	O
and	O
can	O
therefore	O
be	O
used	O
in	O
conjunction	O
with	O
these	O
other	O
approaches	O
.	O
)	O
in	O
order	B
to	O
add	O
a	O
scale	B
selection	I
mechanism	O
to	O
the	O
harris	O
corner	O
detector	O
,	O
mikolajczyk	O
and	O
schmid	O
(	O
2004	O
)	O
evaluate	O
the	O
laplacian	O
of	O
gaussian	O
function	O
at	O
each	O
detected	O
harris	O
point	O
(	O
in	O
a	O
multi-scale	O
pyramid	B
)	O
and	O
keep	O
only	O
those	O
points	B
for	O
which	O
the	O
laplacian	O
is	O
extremal	O
(	O
larger	O
or	O
smaller	O
than	O
both	O
its	O
coarser	O
and	O
ﬁner-level	O
values	O
)	O
.	O
an	O
optional	O
iterative	B
reﬁnement	O
for	O
both	O
scale	O
and	O
position	O
is	O
also	O
proposed	O
and	O
evaluated	O
.	O
additional	O
examples	B
of	O
scale	O
invariant	O
region	B
detectors	O
are	O
discussed	O
by	O
mikolajczyk	O
,	O
tuytelaars	O
,	O
schmid	O
et	O
al	O
.	O
(	O
2005	O
)	O
;	O
tuytelaars	O
and	O
mikolajczyk	O
(	O
2007	O
)	O
.	O
rotational	O
invariance	O
and	O
orientation	O
estimation	B
in	O
addition	O
to	O
dealing	O
with	O
scale	O
changes	O
,	O
most	O
image	B
matching	O
and	O
object	O
recognition	B
algo-	O
rithms	O
need	O
to	O
deal	O
with	O
(	O
at	O
least	O
)	O
in-plane	O
image	B
rotation	O
.	O
one	O
way	O
to	O
deal	O
with	O
this	O
problem	O
is	O
to	O
design	O
descriptors	O
that	O
are	O
rotationally	O
invariant	O
(	O
schmid	O
and	O
mohr	O
1997	O
)	O
,	O
but	O
such	O
descriptors	O
have	O
poor	O
discriminability	O
,	O
i.e	O
.	O
they	O
map	O
different	O
looking	O
patches	O
to	O
the	O
same	O
descriptor	O
.	O
scale	O
(	O
first	O
octave	B
)	O
scale	O
(	O
nextoctave	O
)	O
gaussiandifference	O
ofgaussian	O
(	O
dog	O
)	O
.	O
.	O
.figure1	O
:	O
foreachoctaveofscalespace	O
,	O
theinitialimageisrepeatedlyconvolvedwithgaussianstoproducethesetofscalespaceimagesshownontheleft.adjacentgaussianimagesaresubtractedtoproducethedifference-of-gaussianimagesontheright.aftereachoctave	O
,	O
thegaussianimageisdown-sampledbyafactorof2	O
,	O
andtheprocessrepeated.inaddition	O
,	O
thedifference-of-gaussianfunctionprovidesacloseapproximationtothescale-normalizedlaplacianofgaussian	O
,	O
σ2∇2g	O
,	O
asstudiedbylindeberg	O
(	O
1994	O
)	O
.lindebergshowedthatthenormalizationofthelaplacianwiththefactorσ2isrequiredfortruescaleinvariance.indetailedexperimentalcomparisons	O
,	O
mikolajczyk	O
(	O
2002	O
)	O
foundthatthemaximaandminimaofσ2∇2gproducethemoststableimagefeaturescomparedtoarangeofotherpossibleimagefunctions	O
,	O
suchasthegradient	O
,	O
hessian	O
,	O
orharriscornerfunction.therelationshipbetweendandσ2∇2gcanbeunderstoodfromtheheatdiffusionequa-tion	O
(	O
parameterizedintermsofσratherthanthemoreusualt=σ2	O
)	O
:	O
∂g∂σ=σ∇2g.fromthis	O
,	O
weseethat∇2gcanbecomputedfromtheﬁnitedifferenceapproximationto∂g/∂σ	O
,	O
usingthedifferenceofnearbyscalesatkσandσ	O
:	O
σ∇2g=∂g∂σ≈g	O
(	O
x	O
,	O
y	O
,	O
kσ	O
)	O
−g	O
(	O
x	O
,	O
y	O
,	O
σ	O
)	O
kσ−σandtherefore	O
,	O
g	O
(	O
x	O
,	O
y	O
,	O
kσ	O
)	O
−g	O
(	O
x	O
,	O
y	O
,	O
σ	O
)	O
≈	O
(	O
k−1	O
)	O
σ2∇2g.thisshowsthatwhenthedifference-of-gaussianfunctionhasscalesdifferingbyacon-stantfactoritalreadyincorporatestheσ2scalenormalizationrequiredforthescale-invariant6scalefigure2	O
:	O
maximaandminimaofthedifference-of-gaussianimagesaredetectedbycomparingapixel	O
(	O
markedwithx	O
)	O
toits26neighborsin3x3regionsatthecurrentandadjacentscales	O
(	O
markedwithcircles	O
)	O
.laplacian.thefactor	O
(	O
k−1	O
)	O
intheequationisaconstantoverallscalesandthereforedoesnotinﬂuenceextremalocation.theapproximationerrorwillgotozeroaskgoesto1	O
,	O
butinpracticewehavefoundthattheapproximationhasalmostnoimpactonthestabilityofextremadetectionorlocalizationforevensigniﬁcantdifferencesinscale	O
,	O
suchask=√2.anefﬁcientapproachtoconstructionofd	O
(	O
x	O
,	O
y	O
,	O
σ	O
)	O
isshowninfigure1.theinitialimageisincrementallyconvolvedwithgaussianstoproduceimagesseparatedbyaconstantfactorkinscalespace	O
,	O
shownstackedintheleftcolumn.wechoosetodivideeachoctaveofscalespace	O
(	O
i.e.	O
,	O
doublingofσ	O
)	O
intoanintegernumber	O
,	O
s	O
,	O
ofintervals	O
,	O
sok=21/s.wemustproduces+3imagesinthestackofblurredimagesforeachoctave	O
,	O
sothatﬁnalextremadetectioncoversacompleteoctave.adjacentimagescalesaresubtractedtoproducethedifference-of-gaussianimagesshownontheright.onceacompleteoctavehasbeenprocessed	O
,	O
weresamplethegaussianimagethathastwicetheinitialvalueofσ	O
(	O
itwillbe2imagesfromthetopofthestack	O
)	O
bytakingeverysecondpixelineachrowandcolumn.theaccuracyofsamplingrelativetoσisnodifferentthanforthestartofthepreviousoctave	O
,	O
whilecomputationisgreatlyreduced.3.1localextremadetectioninordertodetectthelocalmaximaandminimaofd	O
(	O
x	O
,	O
y	O
,	O
σ	O
)	O
,	O
eachsamplepointiscomparedtoitseightneighborsinthecurrentimageandnineneighborsinthescaleaboveandbelow	O
(	O
seefigure2	O
)	O
.itisselectedonlyifitislargerthanalloftheseneighborsorsmallerthanallofthem.thecostofthischeckisreasonablylowduetothefactthatmostsamplepointswillbeeliminatedfollowingtheﬁrstfewchecks.animportantissueistodeterminethefrequencyofsamplingintheimageandscaledo-mainsthatisneededtoreliablydetecttheextrema.unfortunately	O
,	O
itturnsoutthatthereisnominimumspacingofsamplesthatwilldetectallextrema	O
,	O
astheextremacanbearbitrar-ilyclosetogether.thiscanbeseenbyconsideringawhitecircleonablackbackground	O
,	O
whichwillhaveasinglescalespacemaximumwherethecircularpositivecentralregionofthedifference-of-gaussianfunctionmatchesthesizeandlocationofthecircle.foraveryelongatedellipse	O
,	O
therewillbetwomaximaneareachendoftheellipse.asthelocationsofmaximaareacontinuousfunctionoftheimage	O
,	O
forsomeellipsewithintermediateelongationtherewillbeatransitionfromasinglemaximumtotwo	O
,	O
withthemaximaarbitrarilycloseto7	O
4.1	O
points	B
and	O
patches	O
219	O
figure	O
4.12	O
a	O
dominant	O
orientation	O
estimate	O
can	O
be	O
computed	O
by	O
creating	O
a	O
histogram	B
of	O
all	O
the	O
gradient	O
orientations	O
(	O
weighted	B
by	O
their	O
magnitudes	O
or	O
after	O
thresholding	B
out	O
small	O
gradients	O
)	O
and	O
then	O
ﬁnding	O
the	O
signiﬁcant	O
peaks	O
in	O
this	O
distribution	O
(	O
lowe	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
.	O
a	O
better	O
method	O
is	O
to	O
estimate	O
a	O
dominant	O
orientation	O
at	O
each	O
detected	O
keypoint	O
.	O
once	O
the	O
local	B
orientation	O
and	O
scale	O
of	O
a	O
keypoint	O
have	O
been	O
estimated	O
,	O
a	O
scaled	O
and	O
oriented	B
patch	O
around	O
the	O
detected	O
point	O
can	O
be	O
extracted	O
and	O
used	O
to	O
form	O
a	O
feature	B
descriptor	O
(	O
figures	O
4.10	O
and	O
4.17	O
)	O
.	O
the	O
simplest	O
possible	O
orientation	O
estimate	O
is	O
the	O
average	O
gradient	O
within	O
a	O
region	B
around	O
the	O
keypoint	O
.	O
if	O
a	O
gaussian	O
weighting	B
function	O
is	O
used	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
,	O
this	O
average	O
gradient	O
is	O
equivalent	O
to	O
a	O
ﬁrst-order	O
steerable	B
ﬁlter	I
(	O
section	O
3.2.3	O
)	O
,	O
i.e.	O
,	O
it	O
can	O
be	O
computed	O
using	O
an	O
image	B
convolution	O
with	O
the	O
horizontal	O
and	O
vertical	O
derivatives	O
of	O
gaus-	O
sian	O
ﬁlter	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
.	O
in	O
order	B
to	O
make	O
this	O
estimate	O
more	O
reliable	O
,	O
it	O
is	O
usually	O
preferable	O
to	O
use	O
a	O
larger	O
aggregation	O
window	O
(	O
gaussian	O
kernel	B
size	O
)	O
than	O
detection	B
window	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
.	O
the	O
orientations	O
of	O
the	O
square	O
boxes	O
shown	O
in	O
figure	O
4.10	O
were	O
computed	O
using	O
this	O
technique	O
.	O
sometimes	O
,	O
however	O
,	O
the	O
averaged	O
(	O
signed	B
)	O
gradient	O
in	O
a	O
region	B
can	O
be	O
small	O
and	O
therefore	O
an	O
unreliable	O
indicator	O
of	O
orientation	O
.	O
a	O
more	O
reliable	O
technique	O
is	O
to	O
look	O
at	O
the	O
histogram	B
of	O
orientations	O
computed	O
around	O
the	O
keypoint	O
.	O
lowe	O
(	O
2004	O
)	O
computes	O
a	O
36-bin	O
histogram	B
of	O
edge	O
orientations	O
weighted	B
by	O
both	O
gradient	O
magnitude	O
and	O
gaussian	O
distance	O
to	O
the	O
cen-	O
ter	O
,	O
ﬁnds	O
all	O
peaks	O
within	O
80	O
%	O
of	O
the	O
global	B
maximum	O
,	O
and	O
then	O
computes	O
a	O
more	O
accurate	O
orientation	O
estimate	O
using	O
a	O
three-bin	O
parabolic	O
ﬁt	O
(	O
figure	O
4.12	O
)	O
.	O
afﬁne	B
invariance	I
while	O
scale	O
and	O
rotation	B
invariance	I
are	O
highly	O
desirable	O
,	O
for	O
many	O
applications	O
such	O
as	O
wide	O
baseline	O
stereo	B
matching	I
(	O
pritchett	O
and	O
zisserman	O
1998	O
;	O
schaffalitzky	O
and	O
zisserman	O
2002	O
)	O
or	O
location	B
recognition	I
(	O
chum	O
,	O
philbin	O
,	O
sivic	O
et	O
al	O
.	O
2007	O
)	O
,	O
full	O
afﬁne	B
invariance	I
is	O
preferred	O
.	O
220	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.13	O
afﬁne	B
region	O
detectors	O
used	O
to	O
match	O
two	O
images	O
taken	O
from	O
dramatically	O
different	O
viewpoints	O
(	O
mikolajczyk	O
and	O
schmid	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
.	O
x0	O
→	O
a−1/2	O
x	O
(	O
cid:48	O
)	O
0	O
0	O
x	O
(	O
cid:48	O
)	O
0	O
→	O
rx	O
(	O
cid:48	O
)	O
1	O
1	O
a−1/2	O
x	O
(	O
cid:48	O
)	O
1	O
←	O
x1	O
figure	O
4.14	O
afﬁne	B
normalization	O
using	O
the	O
second	O
moment	O
matrices	O
,	O
as	O
described	O
by	O
miko-	O
lajczyk	O
,	O
tuytelaars	O
,	O
schmid	O
et	O
al	O
.	O
(	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
springer	O
.	O
after	O
image	B
coordinates	O
are	O
trans-	O
formed	O
using	O
the	O
matrices	O
a−1/2	O
,	O
they	O
are	O
related	O
by	O
a	O
pure	B
rotation	I
r	O
,	O
which	O
can	O
be	O
estimated	O
using	O
a	O
dominant	O
orientation	O
technique	O
.	O
and	O
a−1/2	O
0	O
1	O
afﬁne-invariant	O
detectors	O
not	O
only	O
respond	O
at	O
consistent	O
locations	O
after	O
scale	O
and	O
orientation	O
changes	O
,	O
they	O
also	O
respond	O
consistently	O
across	O
afﬁne	B
deformations	O
such	O
as	O
(	O
local	B
)	O
perspective	B
foreshortening	O
(	O
figure	O
4.13	O
)	O
.	O
in	O
fact	O
,	O
for	O
a	O
small	O
enough	O
patch	B
,	O
any	O
continuous	O
image	B
warping	O
can	O
be	O
well	O
approximated	O
by	O
an	O
afﬁne	B
deformation	O
.	O
to	O
introduce	O
afﬁne	B
invariance	I
,	O
several	O
authors	O
have	O
proposed	O
ﬁtting	O
an	O
ellipse	O
to	O
the	O
auto-	O
correlation	O
or	O
hessian	O
matrix	O
(	O
using	O
eigenvalue	O
analysis	O
)	O
and	O
then	O
using	O
the	O
principal	O
axes	O
and	O
ratios	B
of	O
this	O
ﬁt	O
as	O
the	O
afﬁne	B
coordinate	O
frame	O
(	O
lindeberg	O
and	O
garding	O
1997	O
;	O
baumberg	O
2000	O
;	O
mikolajczyk	O
and	O
schmid	O
2004	O
;	O
mikolajczyk	O
,	O
tuytelaars	O
,	O
schmid	O
et	O
al	O
.	O
2005	O
;	O
tuyte-	O
laars	O
and	O
mikolajczyk	O
2007	O
)	O
.	O
figure	O
4.14	O
shows	O
how	O
the	O
square	B
root	I
of	O
the	O
moment	O
matrix	O
can	O
be	O
used	O
to	O
transform	B
local	O
patches	O
into	O
a	O
frame	O
which	O
is	O
similar	O
up	O
to	O
rotation	O
.	O
another	O
important	O
afﬁne	B
invariant	O
region	B
detector	O
is	O
the	O
maximally	O
stable	O
extremal	O
region	B
(	O
mser	O
)	O
detector	O
developed	O
by	O
matas	O
,	O
chum	O
,	O
urban	O
et	O
al	O
.	O
(	O
2004	O
)	O
.	O
to	O
detect	O
msers	O
,	O
binary	O
regions	O
are	O
computed	O
by	O
thresholding	O
the	O
image	B
at	O
all	O
possible	O
gray	O
levels	O
(	O
the	O
technique	O
therefore	O
only	O
works	O
for	O
grayscale	O
images	O
)	O
.	O
this	O
operation	O
can	O
be	O
performed	O
efﬁciently	O
by	O
ﬁrst	O
sorting	O
all	O
pixels	O
by	O
gray	O
value	O
and	O
then	O
incrementally	O
adding	O
pixels	O
to	O
each	O
connected	O
component	O
as	O
the	O
threshold	O
is	O
changed	O
(	O
nist´er	O
and	O
stew´enius	O
2008	O
)	O
.	O
as	O
the	O
threshold	O
is	O
changed	O
,	O
the	O
area	O
of	O
each	O
component	O
(	O
region	B
)	O
is	O
monitored	O
;	O
regions	O
whose	O
rate	O
of	O
change	O
of	O
area	O
with	O
respect	O
to	O
the	O
threshold	O
is	O
minimal	O
are	O
deﬁned	O
as	O
maximally	O
stable	O
.	O
such	O
regions	O
4.1	O
points	B
and	O
patches	O
221	O
figure	O
4.15	O
maximally	O
stable	O
extremal	O
regions	O
(	O
msers	O
)	O
extracted	O
and	O
matched	O
from	O
a	O
number	O
of	O
images	O
(	O
matas	O
,	O
chum	O
,	O
urban	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
elsevier	O
.	O
figure	O
4.16	O
feature	B
matching	O
:	O
how	O
can	O
we	O
extract	O
local	B
descriptors	O
that	O
are	O
invariant	O
to	O
inter-image	O
variations	O
and	O
yet	O
still	O
discriminative	O
enough	O
to	O
establish	O
correct	O
correspon-	O
dences	O
?	O
are	O
therefore	O
invariant	O
to	O
both	O
afﬁne	B
geometric	O
and	O
photometric	B
(	O
linear	B
bias-gain	O
or	O
smooth	O
monotonic	O
)	O
transformations	O
(	O
figure	O
4.15	O
)	O
.	O
if	O
desired	O
,	O
an	O
afﬁne	B
coordinate	O
frame	O
can	O
be	O
ﬁt	O
to	O
each	O
detected	O
region	B
using	O
its	O
moment	O
matrix	O
.	O
the	O
area	O
of	O
feature	B
point	O
detectors	O
continues	O
to	O
be	O
very	O
active	O
,	O
with	O
papers	O
appearing	O
ev-	O
ery	O
year	O
at	O
major	O
computer	O
vision	O
conferences	O
(	O
xiao	O
and	O
shah	O
2003	O
;	O
koethe	O
2003	O
;	O
carneiro	O
and	O
jepson	O
2005	O
;	O
kenney	O
,	O
zuliani	O
,	O
and	O
manjunath	O
2005	O
;	O
bay	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
2006	O
;	O
platel	O
,	O
balmachnova	O
,	O
florack	O
et	O
al	O
.	O
2006	O
;	O
rosten	O
and	O
drummond	O
2006	O
)	O
.	O
mikolajczyk	O
,	O
tuyte-	O
laars	O
,	O
schmid	O
et	O
al	O
.	O
(	O
2005	O
)	O
survey	O
a	O
number	O
of	O
popular	O
afﬁne	B
region	O
detectors	O
and	O
provide	O
experimental	O
comparisons	O
of	O
their	O
invariance	O
to	O
common	O
image	B
transformations	O
such	O
as	O
scal-	O
ing	O
,	O
rotations	O
,	O
noise	B
,	O
and	O
blur	O
.	O
these	O
experimental	O
results	O
,	O
code	O
,	O
and	O
pointers	O
to	O
the	O
surveyed	O
papers	O
can	O
be	O
found	O
on	O
their	O
web	O
site	O
at	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/research/afﬁne/	O
.	O
of	O
course	O
,	O
keypoints	O
are	O
not	O
the	O
only	O
features	O
that	O
can	O
be	O
used	O
for	O
registering	O
images	O
.	O
zoghlami	O
,	O
faugeras	O
,	O
and	O
deriche	O
(	O
1997	O
)	O
use	O
line	O
segments	O
as	O
well	O
as	O
point-like	O
features	O
to	O
estimate	O
homographies	O
between	O
pairs	B
of	O
images	O
,	O
whereas	O
bartoli	O
,	O
coquerelle	O
,	O
and	O
sturm	O
(	O
2004	O
)	O
use	O
line	O
segments	O
with	O
local	O
correspondences	O
along	O
the	O
edges	O
to	O
extract	O
3d	O
structure	O
and	O
motion	B
.	O
tuytelaars	O
and	O
van	O
gool	O
(	O
2004	O
)	O
use	O
afﬁne	B
invariant	O
regions	O
to	O
detect	O
corre-	O
spondences	O
for	O
wide	O
baseline	O
stereo	B
matching	I
,	O
whereas	O
kadir	O
,	O
zisserman	O
,	O
and	O
brady	O
(	O
2004	O
)	O
detect	O
salient	O
regions	O
where	O
patch	B
entropy	O
and	O
its	O
rate	O
of	O
change	O
with	O
scale	O
are	O
locally	O
max-	O
imal	O
.	O
corso	O
and	O
hager	O
(	O
2005	O
)	O
use	O
a	O
related	O
technique	O
to	O
ﬁt	O
2d	O
oriented	B
gaussian	O
kernels	O
to	O
homogeneous	O
regions	O
.	O
more	O
details	O
on	O
techniques	O
for	O
ﬁnding	O
and	O
matching	B
curves	O
,	O
lines	B
,	O
and	O
regions	O
can	O
be	O
found	O
later	O
in	O
this	O
chapter	O
.	O
222	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.17	O
mops	O
descriptors	O
are	O
formed	O
using	O
an	O
8	O
×	O
8	O
sampling	B
of	O
bias	B
and	I
gain	I
nor-	O
malized	O
intensity	O
values	O
,	O
with	O
a	O
sample	O
spacing	O
of	O
ﬁve	O
pixels	O
relative	O
to	O
the	O
detection	B
scale	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
.	O
this	O
low	O
frequency	O
sampling	B
gives	O
the	O
features	O
some	O
robustness	O
to	O
interest	O
point	O
location	O
error	O
and	O
is	O
achieved	O
by	O
sampling	O
at	O
a	O
higher	O
pyramid	O
level	O
than	O
the	O
detection	B
scale	O
.	O
4.1.2	O
feature	B
descriptors	O
after	O
detecting	O
features	O
(	O
keypoints	O
)	O
,	O
we	O
must	O
match	O
them	O
,	O
i.e.	O
,	O
we	O
must	O
determine	O
which	O
features	O
come	O
from	O
corresponding	O
locations	O
in	O
different	O
images	O
.	O
in	O
some	O
situations	O
,	O
e.g.	O
,	O
for	O
video	O
sequences	O
(	O
shi	O
and	O
tomasi	O
1994	O
)	O
or	O
for	O
stereo	O
pairs	B
that	O
have	O
been	O
rectiﬁed	O
(	O
zhang	O
,	O
deriche	O
,	O
faugeras	O
et	O
al	O
.	O
1995	O
;	O
loop	O
and	O
zhang	O
1999	O
;	O
scharstein	O
and	O
szeliski	O
2002	O
)	O
,	O
the	O
lo-	O
cal	O
motion	B
around	O
each	O
feature	B
point	O
may	O
be	O
mostly	O
translational	B
.	O
in	O
this	O
case	O
,	O
simple	O
error	O
metrics	O
,	O
such	O
as	O
the	O
sum	O
of	O
squared	O
differences	O
or	O
normalized	B
cross-correlation	O
,	O
described	O
in	O
section	O
8.1	O
can	O
be	O
used	O
to	O
directly	O
compare	O
the	O
intensities	O
in	O
small	O
patches	O
around	O
each	O
feature	B
point	O
.	O
(	O
the	O
comparative	O
study	O
by	O
mikolajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
,	O
discussed	O
below	O
,	O
uses	O
cross-correlation	O
.	O
)	O
because	O
feature	B
points	O
may	O
not	O
be	O
exactly	O
located	O
,	O
a	O
more	O
accurate	O
matching	B
score	O
can	O
be	O
computed	O
by	O
performing	O
incremental	B
motion	O
reﬁnement	O
as	O
described	O
in	O
section	O
8.1.3	O
but	O
this	O
can	O
be	O
time	O
consuming	O
and	O
can	O
sometimes	O
even	O
decrease	O
perfor-	O
mance	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
.	O
in	O
most	O
cases	O
,	O
however	O
,	O
the	O
local	B
appearance	O
of	O
features	O
will	O
change	O
in	O
orientation	O
and	O
scale	O
,	O
and	O
sometimes	O
even	O
undergo	O
afﬁne	B
deformations	O
.	O
extracting	O
a	O
local	B
scale	O
,	O
orientation	O
,	O
or	O
afﬁne	B
frame	O
estimate	O
and	O
then	O
using	O
this	O
to	O
resample	O
the	O
patch	B
before	O
forming	O
the	O
feature	B
descriptor	O
is	O
thus	O
usually	O
preferable	O
(	O
figure	O
4.17	O
)	O
.	O
even	O
after	O
compensating	O
for	O
these	O
changes	O
,	O
the	O
local	B
appearance	O
of	O
image	B
patches	O
will	O
usually	O
still	O
vary	O
from	O
image	B
to	O
image	B
.	O
how	O
can	O
we	O
make	O
image	B
descriptors	O
more	O
invariant	O
to	O
such	O
changes	O
,	O
while	O
still	O
preserving	O
discriminability	O
between	O
different	O
(	O
non-corresponding	O
)	O
patches	O
(	O
figure	O
4.16	O
)	O
?	O
mikolajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
review	O
some	O
recently	O
developed	O
view-invariant	O
local	B
image	O
descriptors	O
and	O
experimentally	O
compare	O
their	O
performance	O
.	O
be-	O
low	O
,	O
we	O
describe	O
a	O
few	O
of	O
these	O
descriptors	O
in	O
more	O
detail	O
.	O
4.1	O
points	B
and	O
patches	O
223	O
bias	B
and	I
gain	I
normalization	I
(	O
mops	O
)	O
.	O
for	O
tasks	O
that	O
do	O
not	O
exhibit	O
large	O
amounts	O
of	O
fore-	O
shortening	O
,	O
such	O
as	O
image	B
stitching	I
,	O
simple	O
normalized	B
intensity	O
patches	O
perform	O
reasonably	O
well	O
and	O
are	O
simple	O
to	O
implement	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
(	O
figure	O
4.17	O
)	O
.	O
in	O
or-	O
der	O
to	O
compensate	O
for	O
slight	O
inaccuracies	O
in	O
the	O
feature	B
point	O
detector	O
(	O
location	O
,	O
orientation	O
,	O
and	O
scale	O
)	O
,	O
these	O
multi-scale	O
oriented	B
patches	O
(	O
mops	O
)	O
are	O
sampled	O
at	O
a	O
spacing	O
of	O
ﬁve	O
pixels	O
relative	O
to	O
the	O
detection	B
scale	O
,	O
using	O
a	O
coarser	O
level	O
of	O
the	O
image	B
pyramid	O
to	O
avoid	O
aliasing	B
.	O
to	O
compensate	O
for	O
afﬁne	O
photometric	B
variations	O
(	O
linear	B
exposure	O
changes	O
or	O
bias	B
and	I
gain	I
,	O
(	O
3.3	O
)	O
)	O
,	O
patch	B
intensities	O
are	O
re-scaled	O
so	O
that	O
their	O
mean	O
is	O
zero	O
and	O
their	O
variance	O
is	O
one	O
.	O
scale	O
invariant	O
feature	B
transform	O
(	O
sift	O
)	O
.	O
sift	O
features	O
are	O
formed	O
by	O
computing	O
the	O
gradient	O
at	O
each	O
pixel	O
in	O
a	O
16×16	O
window	O
around	O
the	O
detected	O
keypoint	O
,	O
using	O
the	O
appropriate	O
level	O
of	O
the	O
gaussian	O
pyramid	B
at	O
which	O
the	O
keypoint	O
was	O
detected	O
.	O
the	O
gradient	O
magnitudes	O
are	O
downweighted	O
by	O
a	O
gaussian	O
fall-off	O
function	O
(	O
shown	O
as	O
a	O
blue	O
circle	O
in	O
(	O
figure	O
4.18a	O
)	O
in	O
order	B
to	O
reduce	O
the	O
inﬂuence	O
of	O
gradients	O
far	O
from	O
the	O
center	O
,	O
as	O
these	O
are	O
more	O
affected	O
by	O
small	O
misregistrations	O
.	O
in	O
each	O
4	O
×	O
4	O
quadrant	O
,	O
a	O
gradient	O
orientation	O
histogram	B
is	O
formed	O
by	O
(	O
conceptually	O
)	O
adding	O
the	O
weighted	B
gradient	O
value	O
to	O
one	O
of	O
eight	O
orientation	O
histogram	B
bins	O
.	O
to	O
reduce	O
the	O
effects	O
of	O
location	O
and	O
dominant	O
orientation	O
misestimation	O
,	O
each	O
of	O
the	O
original	O
256	O
weighted	B
gradient	O
magnitudes	O
is	O
softly	O
added	O
to	O
2	O
×	O
2	O
×	O
2	O
histogram	B
bins	O
using	O
trilinear	O
interpolation	B
.	O
softly	O
distributing	O
values	O
to	O
adjacent	O
histogram	B
bins	O
is	O
generally	O
a	O
good	O
idea	O
in	O
any	O
appli-	O
cation	O
where	O
histograms	O
are	O
being	O
computed	O
,	O
e.g.	O
,	O
for	O
hough	O
transforms	O
(	O
section	O
4.3.2	O
)	O
or	O
local	B
histogram	O
equalization	O
(	O
section	O
3.1.4	O
)	O
.	O
the	O
resulting	O
128	O
non-negative	O
values	O
form	O
a	O
raw	O
version	O
of	O
the	O
sift	O
descriptor	O
vector	O
.	O
to	O
reduce	O
the	O
effects	O
of	O
contrast	O
or	O
gain	O
(	O
additive	O
variations	O
are	O
already	O
removed	O
by	O
the	O
gra-	O
dient	O
)	O
,	O
the	O
128-d	O
vector	O
is	O
normalized	B
to	O
unit	O
length	O
.	O
to	O
further	O
make	O
the	O
descriptor	O
robust	B
to	O
other	O
photometric	B
variations	O
,	O
values	O
are	O
clipped	O
to	O
0.2	O
and	O
the	O
resulting	O
vector	O
is	O
once	O
again	O
renormalized	O
to	O
unit	O
length	O
.	O
pca-sift	O
.	O
ke	O
and	O
sukthankar	O
(	O
2004	O
)	O
propose	O
a	O
simpler	O
way	O
to	O
compute	O
descriptors	O
in-	O
spired	O
by	O
sift	O
;	O
it	O
computes	O
the	O
x	O
and	O
y	O
(	O
gradient	O
)	O
derivatives	O
over	O
a	O
39	O
×	O
39	O
patch	B
and	O
then	O
reduces	O
the	O
resulting	O
3042-dimensional	O
vector	O
to	O
36	O
using	O
principal	O
component	O
analysis	O
(	O
pca	O
)	O
(	O
section	O
14.2.1	O
and	O
appendix	O
a.1.2	O
)	O
.	O
another	O
popular	O
variant	O
of	O
sift	O
is	O
surf	O
(	O
bay	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
2006	O
)	O
,	O
which	O
uses	O
box	O
ﬁlters	O
to	O
approximate	O
the	O
derivatives	O
and	O
integrals	O
used	O
in	O
sift	O
.	O
gradient	O
location-orientation	O
histogram	B
(	O
gloh	O
)	O
.	O
this	O
descriptor	O
,	O
developed	O
by	O
miko-	O
lajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
,	O
is	O
a	O
variant	O
on	O
sift	O
that	O
uses	O
a	O
log-polar	O
binning	O
structure	O
instead	O
of	O
the	O
four	O
quadrants	O
used	O
by	O
lowe	O
(	O
2004	O
)	O
(	O
figure	O
4.19	O
)	O
.	O
the	O
spatial	O
bins	O
are	O
of	O
radius	O
6	O
,	O
224	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
image	B
gradients	O
(	O
b	O
)	O
keypoint	O
descriptor	O
figure	O
4.18	O
a	O
schematic	O
representation	O
of	O
lowe	O
’	O
s	O
(	O
2004	O
)	O
scale	O
invariant	O
feature	B
transform	O
(	O
sift	O
)	O
:	O
(	O
a	O
)	O
gradient	O
orientations	O
and	O
magnitudes	O
are	O
computed	O
at	O
each	O
pixel	O
and	O
weighted	B
by	O
a	O
gaussian	O
fall-off	O
function	O
(	O
blue	O
circle	O
)	O
.	O
(	O
b	O
)	O
a	O
weighted	B
gradient	O
orientation	O
histogram	B
is	O
then	O
computed	O
in	O
each	O
subregion	O
,	O
using	O
trilinear	O
interpolation	B
.	O
while	O
this	O
ﬁgure	O
shows	O
an	O
8	O
×	O
8	O
pixel	O
patch	O
and	O
a	O
2	O
×	O
2	O
descriptor	O
array	O
,	O
lowe	O
’	O
s	O
actual	O
implementation	O
uses	O
16	O
×	O
16	O
patches	O
and	O
a	O
4	O
×	O
4	O
array	O
of	O
eight-bin	O
histograms	O
.	O
11	O
,	O
and	O
15	O
,	O
with	O
eight	O
angular	O
bins	O
(	O
except	O
for	O
the	O
central	O
region	B
)	O
,	O
for	O
a	O
total	B
of	O
17	O
spa-	O
tial	O
bins	O
and	O
16	O
orientation	O
bins	O
.	O
the	O
272-dimensional	O
histogram	B
is	O
then	O
projected	O
onto	O
a	O
128-dimensional	O
descriptor	O
using	O
pca	O
trained	O
on	O
a	O
large	O
database	O
.	O
in	O
their	O
evaluation	B
,	O
mikolajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
found	O
that	O
gloh	O
,	O
which	O
has	O
the	O
best	O
performance	O
overall	O
,	O
outperforms	O
sift	O
by	O
a	O
small	O
margin	O
.	O
steerable	B
ﬁlters	O
.	O
steerable	B
ﬁlters	O
(	O
section	O
3.2.3	O
)	O
are	O
combinations	O
of	O
derivative	O
of	O
gaus-	O
sian	O
ﬁlters	O
that	O
permit	O
the	O
rapid	O
computation	O
of	O
even	O
and	O
odd	O
(	O
symmetric	O
and	O
anti-symmetric	O
)	O
edge-like	O
and	O
corner-like	O
features	O
at	O
all	O
possible	O
orientations	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
.	O
because	O
they	O
use	O
reasonably	O
broad	O
gaussians	O
,	O
they	O
too	O
are	O
somewhat	O
insensitive	O
to	O
localiza-	O
tion	B
and	O
orientation	O
errors	O
.	O
performance	O
of	O
local	B
descriptors	O
.	O
among	O
the	O
local	B
descriptors	O
that	O
mikolajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
compared	O
,	O
they	O
found	O
that	O
gloh	O
performed	O
best	O
,	O
followed	O
closely	O
by	O
sift	O
(	O
see	O
fig-	O
ure	O
4.25	O
)	O
.	O
they	O
also	O
present	O
results	O
for	O
many	O
other	O
descriptors	O
not	O
covered	O
in	O
this	O
book	O
.	O
the	O
ﬁeld	O
of	O
feature	B
descriptors	O
continues	O
to	O
evolve	O
rapidly	O
,	O
with	O
some	O
of	O
the	O
newer	O
tech-	O
niques	O
looking	O
at	O
local	B
color	O
information	O
(	O
van	O
de	O
weijer	O
and	O
schmid	O
2006	O
;	O
abdel-hakim	O
and	O
farag	O
2006	O
)	O
.	O
winder	O
and	O
brown	O
(	O
2007	O
)	O
develop	O
a	O
multi-stage	O
framework	O
for	O
feature	O
descriptor	O
computation	O
that	O
subsumes	O
both	O
sift	O
and	O
gloh	O
(	O
figure	O
4.20a	O
)	O
and	O
also	O
allows	O
them	O
to	O
learn	O
optimal	O
parameters	B
for	O
newer	O
descriptors	O
that	O
outperform	O
previous	O
hand-tuned	O
4.1	O
points	B
and	O
patches	O
225	O
(	O
a	O
)	O
image	B
gradients	O
(	O
b	O
)	O
keypoint	O
descriptor	O
figure	O
4.19	O
the	O
gradient	O
location-orientation	O
histogram	B
(	O
gloh	O
)	O
descriptor	O
uses	O
log-polar	O
bins	O
instead	O
of	O
square	O
bins	O
to	O
compute	O
orientation	O
histograms	O
(	O
mikolajczyk	O
and	O
schmid	O
2005	O
)	O
.	O
descriptors	O
.	O
hua	O
,	O
brown	O
,	O
and	O
winder	O
(	O
2007	O
)	O
extend	O
this	O
work	O
by	O
learning	O
lower-dimensional	O
projections	B
of	O
higher-dimensional	O
descriptors	O
that	O
have	O
the	O
best	O
discriminative	O
power	O
.	O
both	O
of	O
these	O
papers	O
use	O
a	O
database	O
of	O
real-world	O
image	B
patches	O
(	O
figure	O
4.20b	O
)	O
obtained	O
by	O
sam-	O
pling	O
images	O
at	O
locations	O
that	O
were	O
reliably	O
matched	O
using	O
a	O
robust	B
structure-from-motion	O
algorithm	B
applied	O
to	O
internet	O
photo	O
collections	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
;	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2007	O
)	O
.	O
in	O
concurrent	O
work	O
,	O
tola	O
,	O
lepetit	O
,	O
and	O
fua	O
(	O
2010	O
)	O
developed	O
a	O
similar	O
daisy	O
descriptor	O
for	O
dense	O
stereo	B
matching	I
and	O
optimized	O
its	O
parameters	B
based	O
on	O
ground	O
truth	O
stereo	B
data	O
.	O
while	O
these	O
techniques	O
construct	O
feature	B
detectors	O
that	O
optimize	O
for	O
repeatability	O
across	O
all	O
object	O
classes	O
,	O
it	O
is	O
also	O
possible	O
to	O
develop	O
class-	O
or	O
instance-speciﬁc	O
feature	B
detectors	O
that	O
maximize	O
discriminability	O
from	O
other	O
classes	O
(	O
ferencz	O
,	O
learned-miller	O
,	O
and	O
malik	O
2008	O
)	O
.	O
4.1.3	O
feature	B
matching	O
once	O
we	O
have	O
extracted	O
features	O
and	O
their	O
descriptors	O
from	O
two	O
or	O
more	O
images	O
,	O
the	O
next	O
step	O
is	O
to	O
establish	O
some	O
preliminary	O
feature	B
matches	O
between	O
these	O
images	O
.	O
in	O
this	O
section	O
,	O
we	O
divide	O
this	O
problem	O
into	O
two	O
separate	O
components	O
.	O
the	O
ﬁrst	O
is	O
to	O
select	O
a	O
matching	B
strategy	O
,	O
which	O
determines	O
which	O
correspondences	O
are	O
passed	O
on	O
to	O
the	O
next	O
stage	O
for	O
further	O
process-	O
ing	O
.	O
the	O
second	O
is	O
to	O
devise	O
efﬁcient	O
data	O
structures	O
and	O
algorithms	O
to	O
perform	O
this	O
matching	B
as	O
quickly	O
as	O
possible	O
.	O
(	O
see	O
the	O
discussion	O
of	O
related	O
techniques	O
in	O
section	O
14.3.2	O
.	O
)	O
226	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
4.20	O
spatial	O
summation	O
blocks	O
for	O
sift	O
,	O
gloh	O
,	O
and	O
some	O
newly	O
developed	O
feature	B
descriptors	O
(	O
winder	O
and	O
brown	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
ieee	O
:	O
(	O
a	O
)	O
the	O
parameters	B
for	O
the	O
new	O
features	O
,	O
e.g.	O
,	O
their	O
gaussian	O
weights	O
,	O
are	O
learned	B
from	O
a	O
training	O
database	O
of	O
(	O
b	O
)	O
matched	O
real-world	O
image	B
patches	O
obtained	O
from	O
robust	B
structure	O
from	O
motion	B
applied	O
to	O
internet	O
photo	O
collec-	O
tions	O
(	O
hua	O
,	O
brown	O
,	O
and	O
winder	O
2007	O
)	O
.	O
matching	B
strategy	O
and	O
error	B
rates	I
determining	O
which	O
feature	B
matches	O
are	O
reasonable	O
to	O
process	O
further	O
depends	O
on	O
the	O
context	B
in	O
which	O
the	O
matching	B
is	O
being	O
performed	O
.	O
say	O
we	O
are	O
given	O
two	O
images	O
that	O
overlap	O
to	O
a	O
fair	O
amount	O
(	O
e.g.	O
,	O
for	O
image	O
stitching	O
,	O
as	O
in	O
figure	O
4.16	O
,	O
or	O
for	O
tracking	O
objects	O
in	O
a	O
video	B
)	O
.	O
we	O
know	O
that	O
most	O
features	O
in	O
one	O
image	B
are	O
likely	O
to	O
match	O
the	O
other	O
image	B
,	O
although	O
some	O
may	O
not	O
match	O
because	O
they	O
are	O
occluded	O
or	O
their	O
appearance	O
has	O
changed	O
too	O
much	O
.	O
on	O
the	O
other	O
hand	O
,	O
if	O
we	O
are	O
trying	O
to	O
recognize	O
how	O
many	O
known	O
objects	O
appear	O
in	O
a	O
clut-	O
tered	O
scene	O
(	O
figure	O
4.21	O
)	O
,	O
most	O
of	O
the	O
features	O
may	O
not	O
match	O
.	O
furthermore	O
,	O
a	O
large	O
number	O
of	O
potentially	O
matching	B
objects	O
must	O
be	O
searched	O
,	O
which	O
requires	O
more	O
efﬁcient	O
strategies	O
,	O
as	O
described	O
below	O
.	O
to	O
begin	O
with	O
,	O
we	O
assume	O
that	O
the	O
feature	B
descriptors	O
have	O
been	O
designed	O
so	O
that	O
eu-	O
clidean	O
(	O
vector	O
magnitude	O
)	O
distances	O
in	O
feature	B
space	O
can	O
be	O
directly	O
used	O
for	O
ranking	O
poten-	O
tial	O
matches	O
.	O
if	O
it	O
turns	O
out	O
that	O
certain	O
parameters	B
(	O
axes	O
)	O
in	O
a	O
descriptor	O
are	O
more	O
reliable	O
than	O
others	O
,	O
it	O
is	O
usually	O
preferable	O
to	O
re-scale	O
these	O
axes	O
ahead	O
of	O
time	O
,	O
e.g.	O
,	O
by	O
determin-	O
ing	O
how	O
much	O
they	O
vary	O
when	O
compared	O
against	O
other	O
known	O
good	O
matches	O
(	O
hua	O
,	O
brown	O
,	O
and	O
winder	O
2007	O
)	O
.	O
a	O
more	O
general	O
process	O
,	O
which	O
involves	O
transforming	O
feature	B
vectors	O
into	O
a	O
new	O
scaled	O
basis	O
,	O
is	O
called	O
whitening	O
and	O
is	O
discussed	O
in	O
more	O
detail	O
in	O
the	O
context	B
of	O
eigenface-based	O
face	B
recognition	O
(	O
section	O
14.2.1	O
)	O
.	O
given	O
a	O
euclidean	O
distance	O
metric	O
,	O
the	O
simplest	O
matching	B
strategy	O
is	O
to	O
set	O
a	O
threshold	O
(	O
maximum	O
distance	O
)	O
and	O
to	O
return	O
all	O
matches	O
from	O
other	O
images	O
within	O
this	O
threshold	O
.	O
set-	O
ting	O
the	O
threshold	O
too	O
high	O
results	O
in	O
too	O
many	O
false	O
positives	O
,	O
i.e.	O
,	O
incorrect	O
matches	O
being	O
returned	O
.	O
setting	O
the	O
threshold	O
too	O
low	O
results	O
in	O
too	O
many	O
false	O
negatives	O
,	O
i.e.	O
,	O
too	O
many	O
correct	O
matches	O
being	O
missed	O
(	O
figure	O
4.22	O
)	O
.	O
we	O
can	O
quantify	O
the	O
performance	O
of	O
a	O
matching	B
algorithm	O
at	O
a	O
particular	O
threshold	O
by	O
4.1	O
points	B
and	O
patches	O
227	O
figure	O
4.21	O
recognizing	O
objects	O
in	O
a	O
cluttered	O
scene	O
(	O
lowe	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
.	O
two	O
of	O
the	O
training	O
images	O
in	O
the	O
database	O
are	O
shown	O
on	O
the	O
left	O
.	O
these	O
are	O
matched	O
to	O
the	O
cluttered	O
scene	O
in	O
the	O
middle	O
using	O
sift	O
features	O
,	O
shown	O
as	O
small	O
squares	O
in	O
the	O
right	O
image	B
.	O
the	O
afﬁne	B
warp	O
of	O
each	O
recognized	O
database	O
image	B
onto	O
the	O
scene	O
is	O
shown	O
as	O
a	O
larger	O
parallelogram	O
in	O
the	O
right	O
image	B
.	O
figure	O
4.22	O
false	O
positives	O
and	O
negatives	O
:	O
the	O
black	O
digits	O
1	O
and	O
2	O
are	O
features	O
being	O
matched	O
against	O
a	O
database	O
of	O
features	O
in	O
other	O
images	O
.	O
at	O
the	O
current	O
threshold	O
setting	O
(	O
the	O
solid	O
circles	O
)	O
,	O
the	O
green	O
1	O
is	O
a	O
true	O
positive	O
(	O
good	O
match	O
)	O
,	O
the	O
blue	O
1	O
is	O
a	O
false	O
negative	O
(	O
failure	O
to	O
match	O
)	O
,	O
and	O
the	O
red	O
3	O
is	O
a	O
false	O
positive	O
(	O
incorrect	O
match	O
)	O
.	O
if	O
we	O
set	O
the	O
threshold	O
higher	O
(	O
the	O
dashed	O
circles	O
)	O
,	O
the	O
blue	O
1	O
becomes	O
a	O
true	O
positive	O
but	O
the	O
brown	O
4	O
becomes	O
an	O
additional	O
false	O
positive	O
.	O
112134	O
228	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
table	O
4.1	O
the	O
number	O
of	O
matches	O
correctly	O
and	O
incorrectly	O
estimated	O
by	O
a	O
feature	B
matching	O
algorithm	B
,	O
showing	O
the	O
number	O
of	O
true	O
positives	O
(	O
tp	O
)	O
,	O
false	O
positives	O
(	O
fp	O
)	O
,	O
false	O
negatives	O
(	O
fn	O
)	O
and	O
true	O
negatives	O
(	O
tn	O
)	O
.	O
the	O
columns	O
sum	O
up	O
to	O
the	O
actual	O
number	O
of	O
positives	O
(	O
p	O
)	O
and	O
negatives	O
(	O
n	O
)	O
,	O
while	O
the	O
rows	O
sum	O
up	O
to	O
the	O
predicted	O
number	O
of	O
positives	O
(	O
p	O
’	O
)	O
and	O
negatives	O
(	O
n	O
’	O
)	O
.	O
the	O
formulas	O
for	O
the	O
true	O
positive	O
rate	O
(	O
tpr	O
)	O
,	O
the	O
false	O
positive	O
rate	O
(	O
fpr	O
)	O
,	O
the	O
positive	O
predictive	O
value	O
(	O
ppv	O
)	O
,	O
and	O
the	O
accuracy	B
(	O
acc	O
)	O
are	O
given	O
in	O
the	O
text	O
.	O
ﬁrst	O
counting	O
the	O
number	O
of	O
true	O
and	O
false	O
matches	O
and	O
match	O
failures	O
,	O
using	O
the	O
following	O
deﬁnitions	O
(	O
fawcett	O
2006	O
)	O
:	O
•	O
tp	O
:	O
true	O
positives	O
,	O
i.e.	O
,	O
number	O
of	O
correct	O
matches	O
;	O
•	O
fn	O
:	O
false	O
negatives	O
,	O
matches	O
that	O
were	O
not	O
correctly	O
detected	O
;	O
•	O
fp	O
:	O
false	O
positives	O
,	O
proposed	O
matches	O
that	O
are	O
incorrect	O
;	O
•	O
tn	O
:	O
true	O
negatives	O
,	O
non-matches	O
that	O
were	O
correctly	O
rejected	O
.	O
table	O
4.1	O
shows	O
a	O
sample	O
confusion	O
matrix	O
(	O
contingency	O
table	O
)	O
containing	O
such	O
numbers	O
.	O
we	O
can	O
convert	O
these	O
numbers	O
into	O
unit	O
rates	O
by	O
deﬁning	O
the	O
following	O
quantities	O
(	O
fawcett	O
2006	O
)	O
:	O
•	O
true	O
positive	O
rate	O
(	O
tpr	O
)	O
,	O
•	O
false	O
positive	O
rate	O
(	O
fpr	O
)	O
,	O
tpr	O
=	O
tp	O
tp+fn	O
=	O
tp	O
p	O
;	O
fpr	O
=	O
fp	O
fp+tn	O
=	O
fp	O
n	O
;	O
•	O
positive	O
predictive	O
value	O
(	O
ppv	O
)	O
,	O
•	O
accuracy	B
(	O
acc	O
)	O
,	O
ppv	O
=	O
tp	O
tp+fp	O
=	O
tp	O
p	O
’	O
;	O
acc	O
=	O
tp+tn	O
p+n	O
.	O
(	O
4.14	O
)	O
(	O
4.15	O
)	O
(	O
4.16	O
)	O
(	O
4.17	O
)	O
predicted	O
matchestp	O
=18fp	O
=4p	O
'	O
=22ppv	O
=0.82predicted	O
non-matchesfn	O
=2tn	O
=76n	O
'	O
=78p	O
=20n	O
=80total	O
=100tpr	O
=0.90fpr	O
=0.05acc	O
=0.94true	O
matchestrue	O
non-matches	O
4.1	O
points	B
and	O
patches	O
229	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
4.23	O
roc	O
curve	O
and	O
its	O
related	O
rates	O
:	O
(	O
a	O
)	O
the	O
roc	O
curve	O
plots	O
the	O
true	O
positive	O
rate	O
against	O
the	O
false	O
positive	O
rate	O
for	O
a	O
particular	O
combination	O
of	O
feature	B
extraction	O
and	O
match-	O
ing	O
algorithms	O
.	O
ideally	O
,	O
the	O
true	O
positive	O
rate	O
should	O
be	O
close	O
to	O
1	O
,	O
while	O
the	O
false	O
positive	O
rate	O
is	O
close	O
to	O
0.	O
the	O
area	O
under	O
the	O
roc	O
curve	O
(	O
auc	O
)	O
is	O
often	O
used	O
as	O
a	O
single	O
(	O
scalar	O
)	O
measure	O
of	O
algorithm	B
performance	O
.	O
alternatively	O
,	O
the	O
equal	O
error	O
rate	O
is	O
sometimes	O
used	O
.	O
(	O
b	O
)	O
the	O
distribution	O
of	O
positives	O
(	O
matches	O
)	O
and	O
negatives	O
(	O
non-matches	O
)	O
as	O
a	O
function	O
of	O
inter-	O
feature	B
distance	O
d.	O
as	O
the	O
threshold	O
θ	O
is	O
increased	O
,	O
the	O
number	O
of	O
true	O
positives	O
(	O
tp	O
)	O
and	O
false	O
positives	O
(	O
fp	O
)	O
increases	O
.	O
in	O
the	O
information	O
retrieval	O
(	O
or	O
document	O
retrieval	O
)	O
literature	O
(	O
baeza-yates	O
and	O
ribeiro-	O
neto	O
1999	O
;	O
manning	O
,	O
raghavan	O
,	O
and	O
sch¨utze	O
2008	O
)	O
,	O
the	O
term	O
precision	B
(	O
how	O
many	O
returned	O
documents	O
are	O
relevant	O
)	O
is	O
used	O
instead	O
of	O
ppv	O
and	O
recall	B
(	O
what	O
fraction	O
of	O
relevant	O
docu-	O
ments	O
was	O
found	O
)	O
is	O
used	O
instead	O
of	O
tpr	O
.	O
any	O
particular	O
matching	B
strategy	O
(	O
at	O
a	O
particular	O
threshold	O
or	O
parameter	O
setting	O
)	O
can	O
be	O
rated	O
by	O
the	O
tpr	O
and	O
fpr	O
numbers	O
;	O
ideally	O
,	O
the	O
true	O
positive	O
rate	O
will	O
be	O
close	O
to	O
1	O
and	O
the	O
false	O
positive	O
rate	O
close	O
to	O
0.	O
as	O
we	O
vary	O
the	O
matching	B
threshold	O
,	O
we	O
obtain	O
a	O
family	O
of	O
such	O
points	B
,	O
which	O
are	O
collectively	O
known	O
as	O
the	O
receiver	O
operating	O
characteristic	O
(	O
roc	O
curve	O
)	O
(	O
fawcett	O
2006	O
)	O
(	O
figure	O
4.23a	O
)	O
.	O
the	O
closer	O
this	O
curve	O
lies	O
to	O
the	O
upper	O
left	O
corner	O
,	O
i.e.	O
,	O
the	O
larger	O
the	O
area	O
under	O
the	O
curve	O
(	O
auc	O
)	O
,	O
the	O
better	O
its	O
performance	O
.	O
figure	O
4.23b	O
shows	O
how	O
we	O
can	O
plot	O
the	O
number	O
of	O
matches	O
and	O
non-matches	O
as	O
a	O
function	O
of	O
inter-feature	O
distance	O
d.	O
these	O
curves	O
can	O
then	O
be	O
used	O
to	O
plot	O
an	O
roc	O
curve	O
(	O
exercise	O
4.3	O
)	O
.	O
the	O
roc	O
curve	O
can	O
also	O
be	O
used	O
to	O
calculate	O
the	O
mean	B
average	I
precision	I
,	O
which	O
is	O
the	O
average	O
precision	B
(	O
ppv	O
)	O
as	O
you	O
vary	O
the	O
threshold	O
to	O
select	O
the	O
best	O
results	O
,	O
then	O
the	O
two	O
top	O
results	O
,	O
etc	O
.	O
the	O
problem	O
with	O
using	O
a	O
ﬁxed	O
threshold	O
is	O
that	O
it	O
is	O
difﬁcult	O
to	O
set	O
;	O
the	O
useful	O
range	O
false	O
positive	O
ratetrue	O
positive	O
rate0.10.8011equal	O
error	O
raterandom	O
chancetpfpfntnθd	O
#	O
230	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.24	O
fixed	O
threshold	O
,	O
nearest	B
neighbor	I
,	O
and	O
nearest	B
neighbor	I
distance	O
ratio	O
matching	B
.	O
at	O
a	O
ﬁxed	O
distance	O
threshold	O
(	O
dashed	O
circles	O
)	O
,	O
descriptor	O
da	O
fails	O
to	O
match	O
db	O
and	O
dd	O
incorrectly	O
matches	O
dc	O
and	O
de	O
.	O
if	O
we	O
pick	O
the	O
nearest	B
neighbor	I
,	O
da	O
correctly	O
matches	O
db	O
but	O
dd	O
incorrectly	O
matches	O
dc	O
.	O
using	O
nearest	O
neighbor	O
distance	O
ratio	O
(	O
nndr	O
)	O
matching	B
,	O
the	O
small	O
nndr	O
d1/d2	O
correctly	O
matches	O
da	O
with	O
db	O
,	O
and	O
the	O
large	O
nndr	O
d	O
(	O
cid:48	O
)	O
1/d	O
(	O
cid:48	O
)	O
2	O
correctly	O
rejects	O
matches	O
for	O
dd	O
.	O
of	O
thresholds	O
can	O
vary	O
a	O
lot	O
as	O
we	O
move	O
to	O
different	O
parts	O
of	O
the	O
feature	B
space	O
(	O
lowe	O
2004	O
;	O
mikolajczyk	O
and	O
schmid	O
2005	O
)	O
.	O
a	O
better	O
strategy	B
in	O
such	O
cases	O
is	O
to	O
simply	O
match	O
the	O
nearest	B
neighbor	I
in	O
feature	B
space	O
.	O
since	O
some	O
features	O
may	O
have	O
no	O
matches	O
(	O
e.g.	O
,	O
they	O
may	O
be	O
part	O
of	O
background	O
clutter	O
in	O
object	O
recognition	B
or	O
they	O
may	O
be	O
occluded	O
in	O
the	O
other	O
image	B
)	O
,	O
a	O
threshold	O
is	O
still	O
used	O
to	O
reduce	O
the	O
number	O
of	O
false	O
positives	O
.	O
ideally	O
,	O
this	O
threshold	O
itself	O
will	O
adapt	O
to	O
different	O
regions	O
of	O
the	O
feature	B
space	O
.	O
if	O
sufﬁcient	O
training	O
data	O
is	O
available	O
(	O
hua	O
,	O
brown	O
,	O
and	O
winder	O
2007	O
)	O
,	O
it	O
is	O
sometimes	O
possible	O
to	O
learn	O
different	O
thresholds	O
for	O
different	O
features	O
.	O
often	O
,	O
however	O
,	O
we	O
are	O
simply	O
given	O
a	O
collection	O
of	O
images	O
to	O
match	O
,	O
e.g.	O
,	O
when	O
stitching	O
images	O
or	O
constructing	O
3d	O
models	O
from	O
unordered	O
photo	O
collections	O
(	O
brown	O
and	O
lowe	O
2007	O
,	O
2003	O
;	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
in	O
this	O
case	O
,	O
a	O
useful	O
heuristic	O
can	O
be	O
to	O
compare	O
the	O
nearest	B
neighbor	I
distance	O
to	O
that	O
of	O
the	O
second	O
nearest	O
neighbor	O
,	O
preferably	O
taken	O
from	O
an	O
image	B
that	O
is	O
known	O
not	O
to	O
match	O
the	O
target	O
(	O
e.g.	O
,	O
a	O
different	O
object	O
in	O
the	O
database	O
)	O
(	O
brown	O
and	O
lowe	O
2002	O
;	O
lowe	O
2004	O
)	O
.	O
we	O
can	O
deﬁne	O
this	O
nearest	B
neighbor	I
distance	O
ratio	O
(	O
mikolajczyk	O
and	O
schmid	O
2005	O
)	O
as	O
nndr	O
=	O
d1	O
d2	O
=	O
(	O
cid:107	O
)	O
da	O
−	O
db|	O
(	O
cid:107	O
)	O
da	O
−	O
dc|	O
,	O
(	O
4.18	O
)	O
where	O
d1	O
and	O
d2	O
are	O
the	O
nearest	O
and	O
second	O
nearest	O
neighbor	O
distances	O
,	O
da	O
is	O
the	O
target	O
descriptor	O
,	O
and	O
db	O
and	O
dc	O
are	O
its	O
closest	O
two	O
neighbors	O
(	O
figure	O
4.24	O
)	O
.	O
the	O
effects	O
of	O
using	O
these	O
three	O
different	O
matching	B
strategies	O
for	O
the	O
feature	B
descriptors	O
evaluated	O
by	O
mikolajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
are	O
shown	O
in	O
figure	O
4.25.	O
as	O
you	O
can	O
see	O
,	O
the	O
nearest	B
neighbor	I
and	O
nndr	O
strategies	O
produce	O
improved	O
roc	O
curves	O
.	O
dbdad1dddcd2ded1	O
’	O
d2	O
’	O
4.1	O
points	B
and	O
patches	O
231	O
figure	O
4.25	O
performance	O
of	O
the	O
feature	B
descriptors	O
evaluated	O
by	O
mikolajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
,	O
shown	O
for	O
three	O
matching	B
strategies	O
:	O
(	O
a	O
)	O
ﬁxed	O
threshold	O
;	O
(	O
b	O
)	O
nearest	B
neighbor	I
;	O
(	O
c	O
)	O
nearest	B
neighbor	I
distance	O
ratio	O
(	O
nndr	O
)	O
.	O
note	O
how	O
the	O
ordering	O
of	O
the	O
algo-	O
rithms	O
does	O
not	O
change	O
that	O
much	O
,	O
but	O
the	O
overall	O
performance	O
varies	O
signiﬁcantly	O
between	O
the	O
different	O
matching	B
strategies	O
.	O
mikolajczykandschmid	O
:	O
aperformanceevaluationoflocaldescriptors16in	O
(	O
cid:3	O
)	O
uenceoftheoverlaperroronthematchingresults.third	O
,	O
weevaluatetheperformancefordifferentdescriptordimensions.fourth	O
,	O
wecomparethedescriptorperformancefordifferentregiondetectorsandscenetypes.00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.911−precision	O
#	O
correct	O
/	O
3708gradient	O
momentscross	O
correlationsteerable	O
filterscomplex	O
filtersdifferential	O
invariantsglohsiftpca	O
−siftshape	O
contextspinhes−lap	O
gloh	O
(	O
a	O
)	O
00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.911−precision	O
#	O
correct	O
/	O
926gradient	O
momentscross	O
correlationsteerable	O
filterscomplex	O
filtersdifferential	O
invariantsglohsiftpca	O
−siftshape	O
contextspinhes−lap	O
gloh00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.911−precision	O
#	O
correct	O
/	O
926gradient	O
momentscross	O
correlationsteerable	O
filterscomplex	O
filtersdifferential	O
invariantsglohsiftpca	O
−siftshape	O
contextspinhes−lap	O
gloh	O
(	O
b	O
)	O
(	O
c	O
)	O
fig.4.comparisonofdifferentmatchingstrategies.descriptorscomputedonhessian-af	O
(	O
cid:2	O
)	O
neregionsforimagesfrom	O
(	O
cid:2	O
)	O
gure3	O
(	O
e	O
)	O
.	O
(	O
a	O
)	O
thresholdbasedmatching.	O
(	O
b	O
)	O
nearestneighbormatching	O
.	O
(	O
c	O
)	O
nearestneighbordistanceratiomatching.hes-lapglohistheglohdescriptorcomputedforhessian-laplaceregions	O
(	O
cf.sectioniv-a.4	O
)	O
.1	O
)	O
matchingstrategies	O
:	O
thede	O
(	O
cid:2	O
)	O
nitionofamatchdependsonthematchingstrategy.wecomparethreeofthem.inthecaseofthresholdbasedmatchingtworegionsarematchedifthedistancebetweentheirdescriptorsisbelowathreshold.adescriptorcanhaveseveralmatchesandseveralofthemmaybecorrect.inthecaseofnearestneighborbasedmatchingtworegionsfebruary23,2005draft	O
232	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.26	O
the	O
three	O
haar	O
wavelet	O
coefﬁcients	O
used	O
for	O
hashing	O
the	O
mops	O
descriptor	O
de-	O
vised	O
by	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
(	O
2005	O
)	O
are	O
computed	O
by	O
summing	O
each	O
8×8	O
normalized	B
patch	O
over	O
the	O
light	O
and	O
dark	O
gray	O
regions	O
and	O
taking	O
their	O
difference	B
.	O
efﬁcient	O
matching	B
once	O
we	O
have	O
decided	O
on	O
a	O
matching	B
strategy	O
,	O
we	O
still	O
need	O
to	O
search	O
efﬁciently	O
for	O
poten-	O
tial	O
candidates	O
.	O
the	O
simplest	O
way	O
to	O
ﬁnd	O
all	O
corresponding	O
feature	B
points	O
is	O
to	O
compare	O
all	O
features	O
against	O
all	O
other	O
features	O
in	O
each	O
pair	O
of	O
potentially	O
matching	B
images	O
.	O
unfortunately	O
,	O
this	O
is	O
quadratic	O
in	O
the	O
number	O
of	O
extracted	O
features	O
,	O
which	O
makes	O
it	O
impractical	O
for	O
most	O
applications	O
.	O
a	O
better	O
approach	O
is	O
to	O
devise	O
an	O
indexing	O
structure	O
,	O
such	O
as	O
a	O
multi-dimensional	O
search	O
tree	O
or	O
a	O
hash	O
table	O
,	O
to	O
rapidly	O
search	O
for	O
features	O
near	O
a	O
given	O
feature	B
.	O
such	O
indexing	O
struc-	O
tures	O
can	O
either	O
be	O
built	O
for	O
each	O
image	B
independently	O
(	O
which	O
is	O
useful	O
if	O
we	O
want	O
to	O
only	O
consider	O
certain	O
potential	O
matches	O
,	O
e.g.	O
,	O
searching	O
for	O
a	O
particular	O
object	O
)	O
or	O
globally	O
for	O
all	O
the	O
images	O
in	O
a	O
given	O
database	O
,	O
which	O
can	O
potentially	O
be	O
faster	O
,	O
since	O
it	O
removes	O
the	O
need	O
to	O
it-	O
erate	O
over	O
each	O
image	B
.	O
for	O
extremely	O
large	O
databases	O
(	O
millions	O
of	O
images	O
or	O
more	O
)	O
,	O
even	O
more	O
efﬁcient	O
structures	O
based	O
on	O
ideas	O
from	O
document	O
retrieval	O
(	O
e.g.	O
,	O
vocabulary	O
trees	O
,	O
(	O
nist´er	O
and	O
stew´enius	O
2006	O
)	O
)	O
can	O
be	O
used	O
(	O
section	O
14.3.2	O
)	O
.	O
one	O
of	O
the	O
simpler	O
techniques	O
to	O
implement	O
is	O
multi-dimensional	O
hashing	B
,	O
which	O
maps	O
descriptors	O
into	O
ﬁxed	O
size	O
buckets	O
based	O
on	O
some	O
function	O
applied	O
to	O
each	O
descriptor	O
vector	O
.	O
at	O
matching	B
time	O
,	O
each	O
new	O
feature	B
is	O
hashed	O
into	O
a	O
bucket	O
,	O
and	O
a	O
search	O
of	O
nearby	O
buckets	O
is	O
used	O
to	O
return	O
potential	O
candidates	O
,	O
which	O
can	O
then	O
be	O
sorted	O
or	O
graded	O
to	O
determine	O
which	O
are	O
valid	O
matches	O
.	O
a	O
simple	O
example	O
of	O
hashing	B
is	O
the	O
haar	O
wavelets	O
used	O
by	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
(	O
2005	O
)	O
in	O
their	O
mops	O
paper	O
.	O
during	O
the	O
matching	B
structure	O
construction	O
,	O
each	O
8	O
×	O
8	O
scaled	O
,	O
oriented	B
,	O
and	O
normalized	B
mops	O
patch	B
is	O
converted	O
into	O
a	O
three-element	O
index	O
by	O
perform-	O
ing	O
sums	O
over	O
different	O
quadrants	O
of	O
the	O
patch	B
(	O
figure	O
4.26	O
)	O
.	O
the	O
resulting	O
three	O
values	O
are	O
normalized	B
by	O
their	O
expected	O
standard	O
deviations	O
and	O
then	O
mapped	O
to	O
the	O
two	O
(	O
of	O
b	O
=	O
10	O
)	O
nearest	O
1d	O
bins	O
.	O
the	O
three-dimensional	O
indices	O
formed	O
by	O
concatenating	O
the	O
three	O
quantized	O
values	O
are	O
used	O
to	O
index	O
the	O
23	O
=	O
8	O
bins	O
where	O
the	O
feature	B
is	O
stored	O
(	O
added	O
)	O
.	O
at	O
query	O
time	O
,	O
only	O
the	O
primary	O
(	O
closest	O
)	O
indices	O
are	O
used	O
,	O
so	O
only	O
a	O
single	O
three-dimensional	O
bin	O
needs	O
to	O
4.1	O
points	B
and	O
patches	O
233	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
4.27	O
k-d	O
tree	O
and	O
best	O
bin	O
ﬁrst	O
(	O
bbf	O
)	O
search	O
(	O
beis	O
and	O
lowe	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
ieee	O
:	O
(	O
a	O
)	O
the	O
spatial	O
arrangement	O
of	O
the	O
axis-aligned	O
cutting	O
planes	B
is	O
shown	O
using	O
dashed	O
lines	B
.	O
individual	O
data	O
points	O
are	O
shown	O
as	O
small	O
diamonds	O
.	O
(	O
b	O
)	O
the	O
same	O
subdivision	O
can	O
be	O
repre-	O
sented	O
as	O
a	O
tree	O
,	O
where	O
each	O
interior	O
node	O
represents	O
an	O
axis-aligned	O
cutting	O
plane	O
(	O
e.g.	O
,	O
the	O
top	O
node	O
cuts	O
along	O
dimension	O
d1	O
at	O
value	O
.34	O
)	O
and	O
each	O
leaf	O
node	O
is	O
a	O
data	O
point	O
.	O
during	O
a	O
bbf	O
search	O
,	O
a	O
query	O
point	O
(	O
denoted	O
by	O
“	O
+	O
”	O
)	O
ﬁrst	O
looks	O
in	O
its	O
containing	O
bin	O
(	O
d	O
)	O
and	O
then	O
in	O
its	O
nearest	O
adjacent	O
bin	O
(	O
b	O
)	O
,	O
rather	O
than	O
its	O
closest	O
neighbor	O
in	O
the	O
tree	O
(	O
c	O
)	O
.	O
be	O
examined	O
.	O
the	O
coefﬁcients	O
in	O
the	O
bin	O
can	O
then	O
be	O
used	O
to	O
select	O
k	O
approximate	O
nearest	O
neighbors	O
for	O
further	O
processing	O
(	O
such	O
as	O
computing	O
the	O
nndr	O
)	O
.	O
a	O
more	O
complex	O
,	O
but	O
more	O
widely	O
applicable	O
,	O
version	O
of	O
hashing	B
is	O
called	O
locality	O
sen-	O
sitive	O
hashing	B
,	O
which	O
uses	O
unions	O
of	O
independently	O
computed	O
hashing	B
functions	O
to	O
index	O
the	O
features	O
(	O
gionis	O
,	O
indyk	O
,	O
and	O
motwani	O
1999	O
;	O
shakhnarovich	O
,	O
darrell	O
,	O
and	O
indyk	O
2006	O
)	O
.	O
shakhnarovich	O
,	O
viola	O
,	O
and	O
darrell	O
(	O
2003	O
)	O
extend	O
this	O
technique	O
to	O
be	O
more	O
sensitive	O
to	O
the	O
distribution	O
of	O
points	B
in	O
parameter	O
space	O
,	O
which	O
they	O
call	O
parameter-sensitive	O
hashing	B
.	O
even	O
more	O
recent	O
work	O
converts	O
high-dimensional	O
descriptor	O
vectors	O
into	O
binary	O
codes	O
that	O
can	O
be	O
compared	O
using	O
hamming	O
distances	O
(	O
torralba	O
,	O
weiss	O
,	O
and	O
fergus	O
2008	O
;	O
weiss	O
,	O
torralba	O
,	O
and	O
fergus	O
2008	O
)	O
or	O
that	O
can	O
accommodate	O
arbitrary	O
kernel	B
functions	O
(	O
kulis	O
and	O
grauman	O
2009	O
;	O
raginsky	O
and	O
lazebnik	O
2009	O
)	O
.	O
another	O
widely	O
used	O
class	O
of	O
indexing	O
structures	O
are	O
multi-dimensional	O
search	O
trees	O
.	O
the	O
best	O
known	O
of	O
these	O
are	O
k-d	B
trees	I
,	O
also	O
often	O
written	O
as	O
kd-trees	O
,	O
which	O
divide	O
the	O
multi-	O
dimensional	O
feature	B
space	O
along	O
alternating	O
axis-aligned	O
hyperplanes	O
,	O
choosing	O
the	O
threshold	O
along	O
each	O
axis	O
so	O
as	O
to	O
maximize	O
some	O
criterion	O
,	O
such	O
as	O
the	O
search	O
tree	O
balance	B
(	O
samet	O
1989	O
)	O
.	O
figure	O
4.27	O
shows	O
an	O
example	O
of	O
a	O
two-dimensional	B
k-d	O
tree	O
.	O
here	O
,	O
eight	O
different	O
data	O
points	O
a–h	O
are	O
shown	O
as	O
small	O
diamonds	O
arranged	O
on	O
a	O
two-dimensional	B
plane	O
.	O
the	O
k-d	O
tree	O
234	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
recursively	O
splits	O
this	O
plane	O
along	O
axis-aligned	O
(	O
horizontal	O
or	O
vertical	O
)	O
cutting	O
planes	B
.	O
each	O
split	O
can	O
be	O
denoted	O
using	O
the	O
dimension	O
number	O
and	O
split	O
value	O
(	O
figure	O
4.27b	O
)	O
.	O
the	O
splits	O
are	O
arranged	O
so	O
as	O
to	O
try	O
to	O
balance	B
the	O
tree	O
,	O
i.e.	O
,	O
to	O
keep	O
its	O
maximum	O
depth	O
as	O
small	O
as	O
possible	O
.	O
at	O
query	O
time	O
,	O
a	O
classic	O
k-d	O
tree	O
search	O
ﬁrst	O
locates	O
the	O
query	O
point	O
(	O
+	O
)	O
in	O
its	O
appropriate	O
bin	O
(	O
d	O
)	O
,	O
and	O
then	O
searches	O
nearby	O
leaves	O
in	O
the	O
tree	O
(	O
c	O
,	O
b	O
,	O
.	O
.	O
.	O
)	O
until	O
it	O
can	O
guarantee	O
that	O
the	O
nearest	B
neighbor	I
has	O
been	O
found	O
.	O
the	O
best	O
bin	O
ﬁrst	O
(	O
bbf	O
)	O
search	O
(	O
beis	O
and	O
lowe	O
1999	O
)	O
searches	O
bins	O
in	O
order	B
of	O
their	O
spatial	O
proximity	O
to	O
the	O
query	O
point	O
and	O
is	O
therefore	O
usually	O
more	O
efﬁcient	O
.	O
many	O
additional	O
data	O
structures	O
have	O
been	O
developed	O
over	O
the	O
years	O
for	O
solving	O
nearest	B
neighbor	I
problems	O
(	O
arya	O
,	O
mount	O
,	O
netanyahu	O
et	O
al	O
.	O
1998	O
;	O
liang	O
,	O
liu	O
,	O
xu	O
et	O
al	O
.	O
2001	O
;	O
hjalta-	O
son	O
and	O
samet	O
2003	O
)	O
.	O
for	O
example	O
,	O
nene	O
and	O
nayar	O
(	O
1997	O
)	O
developed	O
a	O
technique	O
they	O
call	O
slicing	O
that	O
uses	O
a	O
series	O
of	O
1d	O
binary	O
searches	O
on	O
the	O
point	O
list	O
sorted	O
along	O
different	O
dimen-	O
sions	O
to	O
efﬁciently	O
cull	O
down	O
a	O
list	O
of	O
candidate	O
points	B
that	O
lie	O
within	O
a	O
hypercube	O
of	O
the	O
query	O
point	O
.	O
grauman	O
and	O
darrell	O
(	O
2005	O
)	O
reweight	O
the	O
matches	O
at	O
different	O
levels	O
of	O
an	O
indexing	O
tree	O
,	O
which	O
allows	O
their	O
technique	O
to	O
be	O
less	O
sensitive	O
to	O
discretization	O
errors	O
in	O
the	O
tree	O
con-	O
struction	O
.	O
nist´er	O
and	O
stew´enius	O
(	O
2006	O
)	O
use	O
a	O
metric	O
tree	O
,	O
which	O
compares	O
feature	B
descriptors	O
to	O
a	O
small	O
number	O
of	O
prototypes	O
at	O
each	O
level	O
in	O
a	O
hierarchy	B
.	O
the	O
resulting	O
quantized	O
visual	B
words	I
can	O
then	O
be	O
used	O
with	O
classical	O
information	O
retrieval	O
(	O
document	O
relevance	O
)	O
techniques	O
to	O
quickly	O
winnow	O
down	O
a	O
set	O
of	O
potential	O
candidates	O
from	O
a	O
database	O
of	O
millions	O
of	O
images	O
(	O
section	O
14.3.2	O
)	O
.	O
muja	O
and	O
lowe	O
(	O
2009	O
)	O
compare	O
a	O
number	O
of	O
these	O
approaches	O
,	O
introduce	O
a	O
new	O
one	O
of	O
their	O
own	O
(	O
priority	O
search	O
on	O
hierarchical	B
k-means	O
trees	O
)	O
,	O
and	O
conclude	O
that	O
mul-	O
tiple	O
randomized	O
k-d	B
trees	I
often	O
provide	O
the	O
best	O
performance	O
.	O
despite	O
all	O
of	O
this	O
promising	O
work	O
,	O
the	O
rapid	O
computation	O
of	O
image	B
feature	O
correspondences	O
remains	O
a	O
challenging	O
open	O
research	O
problem	O
.	O
feature	B
match	O
veriﬁcation	B
and	O
densiﬁcation	B
once	O
we	O
have	O
some	O
hypothetical	O
(	O
putative	O
)	O
matches	O
,	O
we	O
can	O
often	O
use	O
geometric	B
alignment	I
(	O
section	O
6.1	O
)	O
to	O
verify	O
which	O
matches	O
are	O
inliers	B
and	O
which	O
ones	O
are	O
outliers	O
.	O
for	O
example	O
,	O
if	O
we	O
expect	O
the	O
whole	O
image	B
to	O
be	O
translated	O
or	O
rotated	O
in	O
the	O
matching	B
view	O
,	O
we	O
can	O
ﬁt	O
a	O
global	B
geometric	O
transform	B
and	O
keep	O
only	O
those	O
feature	B
matches	O
that	O
are	O
sufﬁciently	O
close	O
to	O
this	O
estimated	O
transformation	O
.	O
the	O
process	O
of	O
selecting	O
a	O
small	O
set	O
of	O
seed	O
matches	O
and	O
then	O
verifying	O
a	O
larger	O
set	O
is	O
often	O
called	O
random	O
sampling	O
or	O
ransac	O
(	O
section	O
6.1.4	O
)	O
.	O
once	O
an	O
initial	O
set	O
of	O
correspondences	O
has	O
been	O
established	O
,	O
some	O
systems	O
look	O
for	O
additional	O
matches	O
,	O
e.g.	O
,	O
by	O
looking	O
for	O
additional	O
correspondences	O
along	O
epipolar	O
lines	O
(	O
section	O
11.1	O
)	O
or	O
in	O
the	O
vicinity	O
of	O
estimated	O
locations	O
based	O
on	O
the	O
global	B
transform	O
.	O
these	O
topics	O
are	O
discussed	O
further	O
in	O
sections	O
6.1	O
,	O
11.2	O
,	O
and	O
14.3.1	O
.	O
4.1	O
points	B
and	O
patches	O
4.1.4	O
feature	B
tracking	O
235	O
an	O
alternative	O
to	O
independently	O
ﬁnding	O
features	O
in	O
all	O
candidate	O
images	O
and	O
then	O
matching	B
them	O
is	O
to	O
ﬁnd	O
a	O
set	O
of	O
likely	O
feature	B
locations	O
in	O
a	O
ﬁrst	O
image	B
and	O
to	O
then	O
search	O
for	O
their	O
corresponding	O
locations	O
in	O
subsequent	O
images	O
.	O
this	O
kind	O
of	O
detect	O
then	O
track	O
approach	O
is	O
more	O
widely	O
used	O
for	O
video	O
tracking	O
applications	O
,	O
where	O
the	O
expected	O
amount	O
of	O
motion	B
and	O
appearance	O
deformation	O
between	O
adjacent	O
frames	O
is	O
expected	O
to	O
be	O
small	O
.	O
the	O
process	O
of	O
selecting	O
good	O
features	O
to	O
track	O
is	O
closely	O
related	O
to	O
selecting	O
good	O
features	O
for	O
more	O
general	O
recognition	B
applications	O
.	O
in	O
practice	O
,	O
regions	O
containing	O
high	O
gradients	O
in	O
both	O
directions	O
,	O
i.e.	O
,	O
which	O
have	O
high	O
eigenvalues	O
in	O
the	O
auto-correlation	B
matrix	O
(	O
4.8	O
)	O
,	O
provide	O
stable	O
locations	O
at	O
which	O
to	O
ﬁnd	O
correspondences	O
(	O
shi	O
and	O
tomasi	O
1994	O
)	O
.	O
in	O
subsequent	O
frames	O
,	O
searching	O
for	O
locations	O
where	O
the	O
corresponding	O
patch	B
has	O
low	O
squared	O
difference	B
(	O
4.1	O
)	O
often	O
works	O
well	O
enough	O
.	O
however	O
,	O
if	O
the	O
images	O
are	O
undergo-	O
ing	O
brightness	O
change	O
,	O
explicitly	O
compensating	O
for	O
such	O
variations	O
(	O
8.9	O
)	O
or	O
using	O
normalized	O
cross-correlation	O
(	O
8.11	O
)	O
may	O
be	O
preferable	O
.	O
if	O
the	O
search	O
range	O
is	O
large	O
,	O
it	O
is	O
also	O
often	O
more	O
efﬁcient	O
to	O
use	O
a	O
hierarchical	B
search	O
strategy	B
,	O
which	O
uses	O
matches	O
in	O
lower-resolution	O
images	O
to	O
provide	O
better	O
initial	O
guesses	O
and	O
hence	O
speed	O
up	O
the	O
search	O
(	O
section	O
8.1.1	O
)	O
.	O
alternatives	O
to	O
this	O
strategy	B
involve	O
learning	B
what	O
the	O
appearance	O
of	O
the	O
patch	B
being	O
tracked	O
should	O
be	O
and	O
then	O
searching	O
for	O
it	O
in	O
the	O
vicinity	O
of	O
its	O
predicted	O
position	O
(	O
avidan	O
2001	O
;	O
jurie	O
and	O
dhome	O
2002	O
;	O
williams	O
,	O
blake	O
,	O
and	O
cipolla	O
2003	O
)	O
.	O
these	O
topics	O
are	O
all	O
covered	O
in	O
more	O
detail	O
in	O
section	O
8.1.3.	O
if	O
features	O
are	O
being	O
tracked	O
over	O
longer	O
image	B
sequences	O
,	O
their	O
appearance	O
can	O
undergo	O
larger	O
changes	O
.	O
you	O
then	O
have	O
to	O
decide	O
whether	O
to	O
continue	O
matching	B
against	O
the	O
originally	O
detected	O
patch	B
(	O
feature	B
)	O
or	O
to	O
re-sample	O
each	O
subsequent	O
frame	O
at	O
the	O
matching	B
location	O
.	O
the	O
former	O
strategy	B
is	O
prone	O
to	O
failure	O
as	O
the	O
original	O
patch	B
can	O
undergo	O
appearance	O
changes	O
such	O
as	O
foreshortening	O
.	O
the	O
latter	O
runs	O
the	O
risk	O
of	O
the	O
feature	B
drifting	O
from	O
its	O
original	O
location	O
to	O
some	O
other	O
location	O
in	O
the	O
image	B
(	O
shi	O
and	O
tomasi	O
1994	O
)	O
.	O
(	O
mathematically	O
,	O
small	O
mis-	O
registration	B
errors	O
compound	B
to	O
create	O
a	O
markov	O
random	O
walk	O
,	O
which	O
leads	O
to	O
larger	O
drift	O
over	O
time	O
.	O
)	O
a	O
preferable	O
solution	O
is	O
to	O
compare	O
the	O
original	O
patch	B
to	O
later	O
image	B
locations	O
using	O
an	O
afﬁne	B
motion	O
model	O
(	O
section	O
8.2	O
)	O
.	O
shi	O
and	O
tomasi	O
(	O
1994	O
)	O
ﬁrst	O
compare	O
patches	O
in	O
neigh-	O
boring	O
frames	O
using	O
a	O
translational	B
model	O
and	O
then	O
use	O
the	O
location	O
estimates	O
produced	O
by	O
this	O
step	O
to	O
initialize	O
an	O
afﬁne	B
registration	O
between	O
the	O
patch	B
in	O
the	O
current	O
frame	O
and	O
the	O
base	O
frame	O
where	O
a	O
feature	B
was	O
ﬁrst	O
detected	O
(	O
figure	O
4.28	O
)	O
.	O
in	O
their	O
system	O
,	O
features	O
are	O
only	O
detected	O
infrequently	O
,	O
i.e.	O
,	O
only	O
in	O
regions	O
where	O
tracking	O
has	O
failed	O
.	O
in	O
the	O
usual	O
case	O
,	O
an	O
area	O
around	O
the	O
current	O
predicted	O
location	O
of	O
the	O
feature	B
is	O
searched	O
with	O
an	O
incremental	B
reg-	O
istration	O
algorithm	B
(	O
section	O
8.1.3	O
)	O
.	O
the	O
resulting	O
tracker	O
is	O
often	O
called	O
the	O
kanade–lucas–	O
tomasi	O
(	O
klt	O
)	O
tracker	O
.	O
236	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.28	O
feature	B
tracking	O
using	O
an	O
afﬁne	B
motion	O
model	O
(	O
shi	O
and	O
tomasi	O
1994	O
)	O
c	O
(	O
cid:13	O
)	O
1994	O
ieee	O
,	O
top	O
row	O
:	O
image	B
patch	O
around	O
the	O
tracked	O
feature	B
location	O
.	O
bottom	O
row	O
:	O
image	B
patch	O
after	O
warping	O
back	O
toward	O
the	O
ﬁrst	O
frame	O
using	O
an	O
afﬁne	B
deformation	O
.	O
even	O
though	O
the	O
speed	O
sign	O
gets	O
larger	O
from	O
frame	O
to	O
frame	O
,	O
the	O
afﬁne	B
transformation	O
maintains	O
a	O
good	O
resemblance	O
between	O
the	O
original	O
and	O
subsequent	O
tracked	O
frames	O
.	O
since	O
their	O
original	O
work	O
on	O
feature	B
tracking	O
,	O
shi	O
and	O
tomasi	O
’	O
s	O
approach	O
has	O
generated	O
a	O
string	O
of	O
interesting	O
follow-on	O
papers	O
and	O
applications	O
.	O
beardsley	O
,	O
torr	O
,	O
and	O
zisserman	O
(	O
1996	O
)	O
use	O
extended	O
feature	B
tracking	O
combined	O
with	O
structure	O
from	O
motion	B
(	O
chapter	O
7	O
)	O
to	O
incremen-	O
tally	O
build	O
up	O
sparse	O
3d	O
models	O
from	O
video	B
sequences	O
.	O
kang	O
,	O
szeliski	O
,	O
and	O
shum	O
(	O
1997	O
)	O
tie	O
together	O
the	O
corners	O
of	O
adjacent	O
(	O
regularly	O
gridded	O
)	O
patches	O
to	O
provide	O
some	O
additional	O
stability	O
to	O
the	O
tracking	O
,	O
at	O
the	O
cost	O
of	O
poorer	O
handling	O
of	O
occlusions	O
.	O
tommasini	O
,	O
fusiello	O
,	O
trucco	O
et	O
al	O
.	O
(	O
1998	O
)	O
provide	O
a	O
better	O
spurious	O
match	O
rejection	O
criterion	O
for	O
the	O
basic	O
shi	O
and	O
tomasi	O
algorithm	B
,	O
collins	O
and	O
liu	O
(	O
2003	O
)	O
provide	O
improved	O
mechanisms	O
for	O
feature	O
selec-	O
tion	B
and	O
dealing	O
with	O
larger	O
appearance	O
changes	O
over	O
time	O
,	O
and	O
shaﬁque	O
and	O
shah	O
(	O
2005	O
)	O
develop	O
algorithms	O
for	O
feature	O
matching	B
(	O
data	O
association	O
)	O
for	O
videos	O
with	O
large	O
numbers	O
of	O
moving	O
objects	O
or	O
points	B
.	O
yilmaz	O
,	O
javed	O
,	O
and	O
shah	O
(	O
2006	O
)	O
and	O
lepetit	O
and	O
fua	O
(	O
2005	O
)	O
survey	O
the	O
larger	O
ﬁeld	O
of	O
object	O
tracking	O
,	O
which	O
includes	O
not	O
only	O
feature-based	B
techniques	O
but	O
also	O
alternative	O
techniques	O
based	O
on	O
contour	O
and	O
region	B
(	O
section	O
5.1	O
)	O
.	O
one	O
of	O
the	O
newest	O
developments	O
in	O
feature	B
tracking	O
is	O
the	O
use	O
of	O
learning	B
algorithms	O
to	O
build	O
special-purpose	O
recognizers	O
to	O
rapidly	O
search	O
for	O
matching	O
features	O
anywhere	O
in	O
an	O
image	B
(	O
lepetit	O
,	O
pilet	O
,	O
and	O
fua	O
2006	O
;	O
hinterstoisser	O
,	O
benhimane	O
,	O
navab	O
et	O
al	O
.	O
2008	O
;	O
rogez	O
,	O
rihan	O
,	O
ramalingam	O
et	O
al	O
.	O
2008	O
;	O
¨ozuysal	O
,	O
calonder	O
,	O
lepetit	O
et	O
al	O
.	O
2010	O
)	O
.2	O
by	O
taking	O
the	O
time	O
to	O
train	O
classiﬁers	O
on	O
sample	O
patches	O
and	O
their	O
afﬁne	B
deformations	O
,	O
extremely	O
fast	O
and	O
reliable	O
feature	B
detectors	O
can	O
be	O
constructed	O
,	O
which	O
enables	O
much	O
faster	O
motions	O
to	O
be	O
supported	O
(	O
figure	O
4.29	O
)	O
.	O
coupling	O
such	O
features	O
to	O
deformable	O
models	O
(	O
pilet	O
,	O
lepetit	O
,	O
and	O
fua	O
2008	O
)	O
or	O
structure-from-motion	O
algorithms	O
(	O
klein	O
and	O
murray	O
2008	O
)	O
can	O
result	O
in	O
even	O
higher	O
stability	O
.	O
2	O
see	O
also	O
my	O
previous	O
comment	O
on	O
earlier	O
work	O
in	O
learning-based	O
tracking	O
(	O
avidan	O
2001	O
;	O
jurie	O
and	O
dhome	O
2002	O
;	O
williams	O
,	O
blake	O
,	O
and	O
cipolla	O
2003	O
)	O
.	O
4.1	O
points	B
and	O
patches	O
237	O
figure	O
4.29	O
real-time	O
head	B
tracking	I
using	O
the	O
fast	O
trained	O
classiﬁers	O
of	O
lepetit	O
,	O
pilet	O
,	O
and	O
fua	O
(	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
ieee	O
.	O
4.1.5	O
application	O
:	O
performance-driven	B
animation	I
one	O
of	O
the	O
most	O
compelling	O
applications	O
of	O
fast	O
feature	O
tracking	O
is	O
performance-driven	O
an-	O
imation	O
,	O
i.e.	O
,	O
the	O
interactive	B
deformation	O
of	O
a	O
3d	O
graphics	O
model	O
based	O
on	O
tracking	O
a	O
user	O
’	O
s	O
motions	O
(	O
williams	O
1990	O
;	O
litwinowicz	O
and	O
williams	O
1994	O
;	O
lepetit	O
,	O
pilet	O
,	O
and	O
fua	O
2004	O
)	O
.	O
buck	O
,	O
finkelstein	O
,	O
jacobs	O
et	O
al	O
.	O
(	O
2000	O
)	O
present	O
a	O
system	O
that	O
tracks	O
a	O
user	O
’	O
s	O
facial	O
expres-	O
sions	O
and	O
head	B
motions	O
and	O
then	O
uses	O
them	O
to	O
morph	O
among	O
a	O
series	O
of	O
hand-drawn	O
sketches	O
.	O
an	O
animator	O
ﬁrst	O
extracts	O
the	O
eye	O
and	O
mouth	O
regions	O
of	O
each	O
sketch	O
and	O
draws	O
control	O
lines	B
over	O
each	O
image	B
(	O
figure	O
4.30a	O
)	O
.	O
at	O
run	O
time	O
,	O
a	O
face-tracking	O
system	O
(	O
toyama	O
1998	O
)	O
deter-	O
mines	O
the	O
current	O
location	O
of	O
these	O
features	O
(	O
figure	O
4.30b	O
)	O
.	O
the	O
animation	O
system	O
decides	O
which	O
input	O
images	O
to	O
morph	O
based	O
on	O
nearest	B
neighbor	I
feature	O
appearance	O
matching	B
and	O
triangular	O
barycentric	O
interpolation	B
.	O
it	O
also	O
computes	O
the	O
global	B
location	O
and	O
orientation	O
of	O
the	O
head	B
from	O
the	O
tracked	O
features	O
.	O
the	O
resulting	O
morphed	O
eye	O
and	O
mouth	O
regions	O
are	O
then	O
composited	O
back	O
into	O
the	O
overall	O
head	B
model	O
to	O
yield	O
a	O
frame	O
of	O
hand-drawn	O
animation	O
(	O
fig-	O
ure	O
4.30d	O
)	O
.	O
in	O
more	O
recent	O
work	O
,	O
barnes	O
,	O
jacobs	O
,	O
sanders	O
et	O
al	O
.	O
(	O
2008	O
)	O
watch	O
users	O
animate	O
paper	O
cutouts	O
on	O
a	O
desk	O
and	O
then	O
turn	O
the	O
resulting	O
motions	O
and	O
drawings	O
into	O
seamless	O
2d	O
anima-	O
tions	O
.	O
238	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
4.30	O
performance-driven	O
,	O
hand-drawn	O
animation	O
(	O
buck	O
,	O
finkelstein	O
,	O
jacobs	O
et	O
al	O
.	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
acm	O
:	O
(	O
a	O
)	O
eye	O
and	O
mouth	O
portions	O
of	O
hand-drawn	O
sketch	O
with	O
their	O
overlaid	O
control	O
lines	B
;	O
(	O
b	O
)	O
an	O
input	O
video	B
frame	O
with	O
the	O
tracked	O
features	O
overlaid	O
;	O
(	O
c	O
)	O
a	O
different	O
input	O
video	B
frame	O
along	O
with	O
its	O
(	O
d	O
)	O
corresponding	O
hand-drawn	O
animation	O
.	O
4.2	O
edges	O
while	O
interest	O
points	B
are	O
useful	O
for	O
ﬁnding	O
image	B
locations	O
that	O
can	O
be	O
accurately	O
matched	O
in	O
2d	O
,	O
edge	O
points	O
are	O
far	O
more	O
plentiful	O
and	O
often	O
carry	O
important	O
semantic	O
associations	O
.	O
for	O
example	O
,	O
the	O
boundaries	O
of	O
objects	O
,	O
which	O
also	O
correspond	O
to	O
occlusion	O
events	O
in	O
3d	O
,	O
are	O
usually	O
delineated	O
by	O
visible	O
contours	O
.	O
other	O
kinds	O
of	O
edges	O
correspond	O
to	O
shadow	B
boundaries	O
or	O
crease	O
edges	O
,	O
where	O
surface	B
orientation	O
changes	O
rapidly	O
.	O
isolated	O
edge	O
points	O
can	O
also	O
be	O
grouped	O
into	O
longer	O
curves	O
or	O
contours	O
,	O
as	O
well	O
as	O
straight	O
line	O
segments	O
(	O
section	O
4.3	O
)	O
.	O
it	O
is	O
interesting	O
that	O
even	O
young	O
children	O
have	O
no	O
difﬁculty	O
in	O
recognizing	O
familiar	O
objects	O
or	O
animals	O
from	O
such	O
simple	O
line	O
drawings	O
.	O
4.2.1	O
edge	O
detection	O
given	O
an	O
image	B
,	O
how	O
can	O
we	O
ﬁnd	O
the	O
salient	O
edges	O
?	O
consider	O
the	O
color	B
images	O
in	O
figure	O
4.31.	O
if	O
someone	O
asked	O
you	O
to	O
point	O
out	O
the	O
most	O
“	O
salient	O
”	O
or	O
“	O
strongest	O
”	O
edges	O
or	O
the	O
object	O
bound-	O
aries	O
(	O
martin	O
,	O
fowlkes	O
,	O
and	O
malik	O
2004	O
;	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
2010	O
)	O
,	O
which	O
ones	O
would	O
you	O
trace	O
?	O
how	O
closely	O
do	O
your	O
perceptions	O
match	O
the	O
edge	O
images	O
shown	O
in	O
fig-	O
ure	O
4.31	O
?	O
qualitatively	O
,	O
edges	O
occur	O
at	O
boundaries	O
between	O
regions	O
of	O
different	O
color	B
,	O
intensity	O
,	O
or	O
texture	B
.	O
unfortunately	O
,	O
segmenting	O
an	O
image	B
into	O
coherent	O
regions	O
is	O
a	O
difﬁcult	O
task	O
,	O
which	O
we	O
address	O
in	O
chapter	O
5.	O
often	O
,	O
it	O
is	O
preferable	O
to	O
detect	O
edges	O
using	O
only	O
purely	O
local	B
infor-	O
mation	O
.	O
under	O
such	O
conditions	O
,	O
a	O
reasonable	O
approach	O
is	O
to	O
deﬁne	O
an	O
edge	O
as	O
a	O
location	O
of	O
rapid	O
4.2	O
edges	O
239	O
figure	O
4.31	O
human	O
boundary	O
detection	B
(	O
martin	O
,	O
fowlkes	O
,	O
and	O
malik	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
ieee	O
.	O
the	O
darkness	O
of	O
the	O
edges	O
corresponds	O
to	O
how	O
many	O
human	O
subjects	O
marked	O
an	O
object	O
bound-	O
ary	O
at	O
that	O
location	O
.	O
intensity	O
variation.3	O
think	O
of	O
an	O
image	B
as	O
a	O
height	O
ﬁeld	O
.	O
on	O
such	O
a	O
surface	B
,	O
edges	O
occur	O
at	O
locations	O
of	O
steep	O
slopes	O
,	O
or	O
equivalently	O
,	O
in	O
regions	O
of	O
closely	O
packed	O
contour	O
lines	B
(	O
on	O
a	O
topographic	O
map	O
)	O
.	O
a	O
mathematical	O
way	O
to	O
deﬁne	O
the	O
slope	O
and	O
direction	O
of	O
a	O
surface	B
is	O
through	O
its	O
gradient	O
,	O
j	O
(	O
x	O
)	O
=	O
∇i	O
(	O
x	O
)	O
=	O
(	O
∂i	O
∂x	O
,	O
∂i	O
∂y	O
)	O
(	O
x	O
)	O
.	O
(	O
4.19	O
)	O
the	O
local	B
gradient	O
vector	O
j	O
points	B
in	O
the	O
direction	O
of	O
steepest	O
ascent	O
in	O
the	O
intensity	O
function	O
.	O
its	O
magnitude	O
is	O
an	O
indication	O
of	O
the	O
slope	O
or	O
strength	O
of	O
the	O
variation	O
,	O
while	O
its	O
orientation	O
points	B
in	O
a	O
direction	O
perpendicular	O
to	O
the	O
local	B
contour	O
.	O
unfortunately	O
,	O
taking	O
image	B
derivatives	O
accentuates	O
high	O
frequencies	O
and	O
hence	O
ampliﬁes	O
noise	B
,	O
since	O
the	O
proportion	O
of	O
noise	B
to	O
signal	O
is	O
larger	O
at	O
high	O
frequencies	O
.	O
it	O
is	O
therefore	O
prudent	O
to	O
smooth	O
the	O
image	B
with	O
a	O
low-pass	B
ﬁlter	O
prior	B
to	O
computing	O
the	O
gradient	O
.	O
because	O
we	O
would	O
like	O
the	O
response	O
of	O
our	O
edge	O
detector	O
to	O
be	O
independent	O
of	O
orientation	O
,	O
a	O
circularly	O
symmetric	O
smoothing	B
ﬁlter	O
is	O
desirable	O
.	O
as	O
we	O
saw	O
in	O
section	O
3.2	O
,	O
the	O
gaussian	O
is	O
the	O
only	O
separable	B
circularly	O
symmetric	O
ﬁlter	O
and	O
so	O
it	O
is	O
used	O
in	O
most	O
edge	O
detection	O
algorithms	O
.	O
canny	O
(	O
1986	O
)	O
discusses	O
alternative	O
ﬁlters	O
and	O
a	O
number	O
of	O
researcher	O
review	O
alternative	O
edge	O
detection	O
algorithms	O
and	O
compare	O
their	O
performance	O
(	O
davis	O
1975	O
;	O
nalwa	O
and	O
binford	O
1986	O
;	O
nalwa	O
1987	O
;	O
deriche	O
1987	O
;	O
freeman	O
and	O
adelson	O
1991	O
;	O
nalwa	O
1993	O
;	O
heath	O
,	O
sarkar	O
,	O
sanocki	O
et	O
al	O
.	O
1998	O
;	O
crane	O
1997	O
;	O
ritter	O
and	O
wilson	O
2000	O
;	O
bowyer	O
,	O
kranenburg	O
,	O
and	O
dougherty	O
2001	O
;	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
2010	O
)	O
.	O
because	O
differentiation	O
is	O
a	O
linear	B
operation	O
,	O
it	O
commutes	O
with	O
other	O
linear	B
ﬁltering	O
oper-	O
3	O
we	O
defer	O
the	O
topic	O
of	O
edge	O
detection	O
in	O
color	B
images	O
.	O
240	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ations	O
.	O
the	O
gradient	O
of	O
the	O
smoothed	O
image	B
can	O
therefore	O
be	O
written	O
as	O
j	O
σ	O
(	O
x	O
)	O
=	O
∇	O
[	O
gσ	O
(	O
x	O
)	O
∗	O
i	O
(	O
x	O
)	O
]	O
=	O
[	O
∇gσ	O
]	O
(	O
x	O
)	O
∗	O
i	O
(	O
x	O
)	O
,	O
(	O
4.20	O
)	O
i.e.	O
,	O
we	O
can	O
convolve	O
the	O
image	B
with	O
the	O
horizontal	O
and	O
vertical	O
derivatives	O
of	O
the	O
gaussian	O
kernel	B
function	O
,	O
∇gσ	O
(	O
x	O
)	O
=	O
(	O
∂gσ	O
∂x	O
,	O
∂gσ	O
∂y	O
)	O
(	O
x	O
)	O
=	O
[	O
−x	O
−	O
y	O
]	O
1	O
σ3	O
exp	O
(	O
cid:18	O
)	O
−	O
x2	O
+	O
y2	O
2σ2	O
(	O
cid:19	O
)	O
(	O
4.21	O
)	O
(	O
the	O
parameter	O
σ	O
indicates	O
the	O
width	O
of	O
the	O
gaussian	O
.	O
)	O
this	O
is	O
the	O
same	O
computation	O
that	O
is	O
performed	O
by	O
freeman	O
and	O
adelson	O
’	O
s	O
(	O
1991	O
)	O
ﬁrst-order	O
steerable	B
ﬁlter	I
,	O
which	O
we	O
already	O
covered	O
in	O
section	O
3.2.3.	O
for	O
many	O
applications	O
,	O
however	O
,	O
we	O
wish	O
to	O
thin	B
such	O
a	O
continuous	O
gradient	O
image	O
to	O
only	O
return	O
isolated	O
edges	O
,	O
i.e.	O
,	O
as	O
single	O
pixels	O
at	O
discrete	B
locations	O
along	O
the	O
edge	O
contours	O
.	O
this	O
can	O
be	O
achieved	O
by	O
looking	O
for	O
maxima	O
in	O
the	O
edge	O
strength	O
(	O
gradient	O
magnitude	O
)	O
in	O
a	O
direction	O
perpendicular	O
to	O
the	O
edge	O
orientation	O
,	O
i.e.	O
,	O
along	O
the	O
gradient	O
direction	O
.	O
finding	O
this	O
maximum	O
corresponds	O
to	O
taking	O
a	O
directional	B
derivative	I
of	O
the	O
strength	O
ﬁeld	O
in	O
the	O
direction	O
of	O
the	O
gradient	O
and	O
then	O
looking	O
for	O
zero	O
crossings	O
.	O
the	O
desired	O
directional	B
derivative	I
is	O
equivalent	O
to	O
the	O
dot	O
product	O
between	O
a	O
second	O
gradient	O
operator	O
and	O
the	O
results	O
of	O
the	O
ﬁrst	O
,	O
sσ	O
(	O
x	O
)	O
=	O
∇	O
·	O
j	O
σ	O
(	O
x	O
)	O
=	O
[	O
∇2gσ	O
]	O
(	O
x	O
)	O
∗	O
i	O
(	O
x	O
)	O
]	O
.	O
(	O
4.22	O
)	O
the	O
gradient	O
operator	O
dot	O
product	O
with	O
the	O
gradient	O
is	O
called	O
the	O
laplacian	O
.	O
the	O
convolution	O
kernel	B
(	O
4.23	O
)	O
∇2gσ	O
(	O
x	O
)	O
=	O
1	O
σ3	O
(	O
cid:18	O
)	O
2	O
−	O
x2	O
+	O
y2	O
2σ2	O
(	O
cid:19	O
)	O
exp	O
(	O
cid:18	O
)	O
−	O
x2	O
+	O
y2	O
2σ2	O
(	O
cid:19	O
)	O
is	O
therefore	O
called	O
the	O
laplacian	O
of	O
gaussian	O
(	O
log	O
)	O
kernel	B
(	O
marr	O
and	O
hildreth	O
1980	O
)	O
.	O
this	O
kernel	B
can	O
be	O
split	O
into	O
two	O
separable	O
parts	O
,	O
∇2gσ	O
(	O
x	O
)	O
=	O
1	O
σ3	O
(	O
cid:18	O
)	O
1	O
−	O
x2	O
2σ2	O
(	O
cid:19	O
)	O
gσ	O
(	O
x	O
)	O
gσ	O
(	O
y	O
)	O
+	O
1	O
σ3	O
(	O
cid:18	O
)	O
1	O
−	O
y2	O
2σ2	O
(	O
cid:19	O
)	O
gσ	O
(	O
y	O
)	O
gσ	O
(	O
x	O
)	O
(	O
4.24	O
)	O
(	O
wiejak	O
,	O
buxton	O
,	O
and	O
buxton	O
1985	O
)	O
,	O
which	O
allows	O
for	O
a	O
much	O
more	O
efﬁcient	O
implementation	O
using	O
separable	O
ﬁltering	O
(	O
section	O
3.2.1	O
)	O
.	O
in	O
practice	O
,	O
it	O
is	O
quite	O
common	O
to	O
replace	O
the	O
laplacian	O
of	O
gaussian	O
convolution	O
with	O
a	O
difference	B
of	O
gaussian	O
(	O
dog	O
)	O
computation	O
,	O
since	O
the	O
kernel	B
shapes	O
are	O
qualitatively	O
similar	O
(	O
figure	O
3.35	O
)	O
.	O
this	O
is	O
especially	O
convenient	O
if	O
a	O
“	O
laplacian	O
pyramid	B
”	O
(	O
section	O
3.5	O
)	O
has	O
already	O
been	O
computed.4	O
4	O
recall	B
that	O
burt	O
and	O
adelson	O
’	O
s	O
(	O
1983a	O
)	O
“	O
laplacian	O
pyramid	B
”	O
actually	O
computed	O
differences	O
of	O
gaussian-ﬁltered	O
levels	O
.	O
4.2	O
edges	O
241	O
in	O
fact	O
,	O
it	O
is	O
not	O
strictly	O
necessary	O
to	O
take	O
differences	O
between	O
adjacent	O
levels	O
when	O
com-	O
puting	O
the	O
edge	O
ﬁeld	O
.	O
think	O
about	O
what	O
a	O
zero	B
crossing	I
in	O
a	O
“	O
generalized	B
”	O
difference	B
of	O
gaussians	O
image	B
represents	O
.	O
the	O
ﬁner	O
(	O
smaller	O
kernel	B
)	O
gaussian	O
is	O
a	O
noise-reduced	O
version	O
of	O
the	O
original	O
image	B
.	O
the	O
coarser	O
(	O
larger	O
kernel	B
)	O
gaussian	O
is	O
an	O
estimate	O
of	O
the	O
average	O
in-	O
tensity	O
over	O
a	O
larger	O
region	B
.	O
thus	O
,	O
whenever	O
the	O
dog	O
image	B
changes	O
sign	O
,	O
this	O
corresponds	O
to	O
the	O
(	O
slightly	O
blurred	O
)	O
image	B
going	O
from	O
relatively	O
darker	O
to	O
relatively	O
lighter	O
,	O
as	O
compared	O
to	O
the	O
average	O
intensity	O
in	O
that	O
neighborhood	B
.	O
once	O
we	O
have	O
computed	O
the	O
sign	O
function	O
s	O
(	O
x	O
)	O
,	O
we	O
must	O
ﬁnd	O
its	O
zero	O
crossings	O
and	O
convert	O
these	O
into	O
edge	O
elements	O
(	O
edgels	O
)	O
.	O
an	O
easy	O
way	O
to	O
detect	O
and	O
represent	O
zero	O
crossings	O
is	O
to	O
look	O
for	O
adjacent	O
pixel	O
locations	O
xi	O
and	O
xj	O
where	O
the	O
sign	O
changes	O
value	O
,	O
i.e.	O
,	O
[	O
s	O
(	O
xi	O
)	O
>	O
0	O
]	O
(	O
cid:54	O
)	O
=	O
[	O
s	O
(	O
xj	O
)	O
>	O
0	O
]	O
.	O
the	O
sub-pixel	O
location	O
of	O
this	O
crossing	O
can	O
be	O
obtained	O
by	O
computing	O
the	O
“	O
x-intercept	O
”	O
of	O
the	O
“	O
line	O
”	O
connecting	O
s	O
(	O
xi	O
)	O
and	O
s	O
(	O
xj	O
)	O
,	O
xz	O
=	O
xis	O
(	O
xj	O
)	O
−	O
xjs	O
(	O
xi	O
)	O
s	O
(	O
xj	O
)	O
−	O
s	O
(	O
xi	O
)	O
.	O
(	O
4.25	O
)	O
the	O
orientation	O
and	O
strength	O
of	O
such	O
edgels	O
can	O
be	O
obtained	O
by	O
linearly	O
interpolating	O
the	O
gradient	O
values	O
computed	O
on	O
the	O
original	O
pixel	O
grid	O
.	O
an	O
alternative	O
edgel	O
representation	O
can	O
be	O
obtained	O
by	O
linking	O
adjacent	O
edgels	O
on	O
the	O
dual	O
grid	O
to	O
form	O
edgels	O
that	O
live	O
inside	O
each	O
square	O
formed	O
by	O
four	O
adjacent	O
pixels	O
in	O
the	O
original	O
pixel	O
grid.5	O
the	O
(	O
potential	O
)	O
advantage	O
of	O
this	O
representation	O
is	O
that	O
the	O
edgels	O
now	O
live	O
on	O
a	O
grid	O
offset	O
by	O
half	O
a	O
pixel	O
from	O
the	O
original	O
pixel	O
grid	O
and	O
are	O
thus	O
easier	O
to	O
store	O
and	O
access	O
.	O
as	O
before	O
,	O
the	O
orientations	O
and	O
strengths	O
of	O
the	O
edges	O
can	O
be	O
computed	O
by	O
interpolating	O
the	O
gradient	O
ﬁeld	O
or	O
estimating	O
these	O
values	O
from	O
the	O
difference	B
of	O
gaussian	O
image	B
(	O
see	O
exercise	O
4.7	O
)	O
.	O
in	O
applications	O
where	O
the	O
accuracy	B
of	O
the	O
edge	O
orientation	O
is	O
more	O
important	O
,	O
higher-order	O
steerable	B
ﬁlters	O
can	O
be	O
used	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
(	O
see	O
section	O
3.2.3	O
)	O
.	O
such	O
ﬁlters	O
are	O
more	O
selective	O
for	O
more	O
elongated	O
edges	O
and	O
also	O
have	O
the	O
possibility	O
of	O
better	O
modeling	B
curve	O
intersections	O
because	O
they	O
can	O
represent	O
multiple	B
orientations	O
at	O
the	O
same	O
pixel	O
(	O
figure	O
3.16	O
)	O
.	O
their	O
disadvantage	O
is	O
that	O
they	O
are	O
more	O
expensive	O
to	O
compute	O
and	O
the	O
directional	B
derivative	I
of	O
the	O
edge	O
strength	O
does	O
not	O
have	O
a	O
simple	O
closed	O
form	O
solution.6	O
242	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
figure	O
4.32	O
scale	B
selection	I
for	O
edge	O
detection	O
(	O
elder	O
and	O
zucker	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
ieee	O
:	O
(	O
a	O
)	O
original	O
image	B
;	O
(	O
b–c	O
)	O
canny/deriche	O
edge	O
detector	O
tuned	O
to	O
the	O
ﬁner	O
(	O
mannequin	O
)	O
and	O
coarser	O
(	O
shadow	B
)	O
scales	O
;	O
(	O
d	O
)	O
minimum	O
reliable	O
scale	O
for	O
gradient	O
estimation	O
;	O
(	O
e	O
)	O
minimum	O
reliable	O
scale	O
for	O
second	O
derivative	O
estimation	B
;	O
(	O
f	O
)	O
ﬁnal	O
detected	O
edges	O
.	O
scale	B
selection	I
and	O
blur	O
estimation	O
as	O
we	O
mentioned	O
before	O
,	O
the	O
derivative	O
,	O
laplacian	O
,	O
and	O
difference	B
of	O
gaussian	O
ﬁlters	O
(	O
4.20–	O
4.23	O
)	O
all	O
require	O
the	O
selection	O
of	O
a	O
spatial	O
scale	O
parameter	O
σ.	O
if	O
we	O
are	O
only	O
interested	O
in	O
detecting	O
sharp	O
edges	O
,	O
the	O
width	O
of	O
the	O
ﬁlter	O
can	O
be	O
determined	O
from	O
image	B
noise	O
characteris-	O
tics	O
(	O
canny	O
1986	O
;	O
elder	O
and	O
zucker	O
1998	O
)	O
.	O
however	O
,	O
if	O
we	O
want	O
to	O
detect	O
edges	O
that	O
occur	O
at	O
different	O
resolutions	O
(	O
figures	O
4.32b–c	O
)	O
,	O
a	O
scale-space	O
approach	O
that	O
detects	O
and	O
then	O
selects	O
edges	O
at	O
different	O
scales	O
may	O
be	O
necessary	O
(	O
witkin	O
1983	O
;	O
lindeberg	O
1994	O
,	O
1998a	O
;	O
nielsen	O
,	O
florack	O
,	O
and	O
deriche	O
1997	O
)	O
.	O
elder	O
and	O
zucker	O
(	O
1998	O
)	O
present	O
a	O
principled	O
approach	O
to	O
solving	O
this	O
problem	O
.	O
given	O
a	O
known	O
image	B
noise	O
level	O
,	O
their	O
technique	O
computes	O
,	O
for	O
every	O
pixel	O
,	O
the	O
minimum	O
scale	O
at	O
which	O
an	O
edge	O
can	O
be	O
reliably	O
detected	O
(	O
figure	O
4.32d	O
)	O
.	O
their	O
approach	O
ﬁrst	O
computes	O
5	O
this	O
algorithm	B
is	O
a	O
2d	O
version	O
of	O
the	O
3d	O
marching	B
cubes	I
isosurface	O
extraction	O
algorithm	B
(	O
lorensen	O
and	O
cline	O
1987	O
)	O
.	O
6	O
in	O
fact	O
,	O
the	O
edge	O
orientation	O
can	O
have	O
a	O
180◦	O
ambiguity	O
for	O
“	O
bar	O
edges	O
”	O
,	O
which	O
makes	O
the	O
computation	O
of	O
zero	O
crossings	O
in	O
the	O
derivative	O
more	O
tricky	O
.	O
4.2	O
edges	O
243	O
gradients	O
densely	O
over	O
an	O
image	B
by	O
selecting	O
among	O
gradient	O
estimates	O
computed	O
at	O
different	O
scales	O
,	O
based	O
on	O
their	O
gradient	O
magnitudes	O
.	O
it	O
then	O
performs	O
a	O
similar	O
estimate	O
of	O
minimum	O
scale	O
for	O
directed	O
second	O
derivatives	O
and	O
uses	O
zero	O
crossings	O
of	O
this	O
latter	O
quantity	O
to	O
robustly	O
select	O
edges	O
(	O
figures	O
4.32e–f	O
)	O
.	O
as	O
an	O
optional	O
ﬁnal	O
step	O
,	O
the	O
blur	O
width	O
of	O
each	O
edge	O
can	O
be	O
computed	O
from	O
the	O
distance	O
between	O
extrema	O
in	O
the	O
second	O
derivative	O
response	O
minus	O
the	O
width	O
of	O
the	O
gaussian	O
ﬁlter	O
.	O
color	B
edge	O
detection	B
while	O
most	O
edge	O
detection	O
techniques	O
have	O
been	O
developed	O
for	O
grayscale	O
images	O
,	O
color	B
im-	O
ages	O
can	O
provide	O
additional	O
information	O
.	O
for	O
example	O
,	O
noticeable	O
edges	O
between	O
iso-luminant	O
colors	O
(	O
colors	O
that	O
have	O
the	O
same	O
luminance	O
)	O
are	O
useful	O
cues	O
but	O
fail	O
to	O
be	O
detected	O
by	O
grayscale	O
edge	O
operators	O
.	O
one	O
simple	O
approach	O
is	O
to	O
combine	O
the	O
outputs	O
of	O
grayscale	O
detectors	O
run	O
on	O
each	O
color	B
band	O
separately.7	O
however	O
,	O
some	O
care	O
must	O
be	O
taken	O
.	O
for	O
example	O
,	O
if	O
we	O
simply	O
sum	O
up	O
the	O
gradients	O
in	O
each	O
of	O
the	O
color	B
bands	O
,	O
the	O
signed	B
gradients	O
may	O
actually	O
cancel	O
each	O
other	O
!	O
(	O
consider	O
,	O
for	O
example	O
a	O
pure	O
red-to-green	O
edge	O
.	O
)	O
we	O
could	O
also	O
detect	O
edges	O
independently	O
in	O
each	O
band	O
and	O
then	O
take	O
the	O
union	O
of	O
these	O
,	O
but	O
this	O
might	O
lead	O
to	O
thickened	O
or	O
doubled	O
edges	O
that	O
are	O
hard	O
to	O
link	O
.	O
a	O
better	O
approach	O
is	O
to	O
compute	O
the	O
oriented	B
energy	O
in	O
each	O
band	O
(	O
morrone	O
and	O
burr	O
1988	O
;	O
perona	O
and	O
malik	O
1990a	O
)	O
,	O
e.g.	O
,	O
using	O
a	O
second-order	O
steerable	B
ﬁlter	I
(	O
section	O
3.2.3	O
)	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
,	O
and	O
then	O
sum	O
up	O
the	O
orientation-weighted	O
energies	O
and	O
ﬁnd	O
their	O
joint	B
best	O
orientation	O
.	O
unfortunately	O
,	O
the	O
directional	B
derivative	I
of	O
this	O
energy	O
may	O
not	O
have	O
a	O
closed	O
form	O
solution	O
(	O
as	O
in	O
the	O
case	O
of	O
signed	B
ﬁrst-order	O
steerable	B
ﬁlters	O
)	O
,	O
so	O
a	O
simple	O
zero	O
crossing-based	O
strategy	B
can	O
not	O
be	O
used	O
.	O
however	O
,	O
the	O
technique	O
described	O
by	O
elder	O
and	O
zucker	O
(	O
1998	O
)	O
can	O
be	O
used	O
to	O
compute	O
these	O
zero	O
crossings	O
numerically	O
instead	O
.	O
an	O
alternative	O
approach	O
is	O
to	O
estimate	O
local	B
color	O
statistics	O
in	O
regions	O
around	O
each	O
pixel	O
(	O
ruzon	O
and	O
tomasi	O
2001	O
;	O
martin	O
,	O
fowlkes	O
,	O
and	O
malik	O
2004	O
)	O
.	O
this	O
has	O
the	O
advantage	O
that	O
more	O
sophisticated	O
techniques	O
(	O
e.g.	O
,	O
3d	O
color	B
histograms	O
)	O
can	O
be	O
used	O
to	O
compare	O
regional	O
statistics	O
and	O
that	O
additional	O
measures	O
,	O
such	O
as	O
texture	B
,	O
can	O
also	O
be	O
considered	O
.	O
figure	O
4.33	O
shows	O
the	O
output	O
of	O
such	O
detectors	O
.	O
of	O
course	O
,	O
many	O
other	O
approaches	O
have	O
been	O
developed	O
for	O
detecting	O
color	B
edges	O
,	O
dating	O
back	O
to	O
early	O
work	O
by	O
nevatia	O
(	O
1977	O
)	O
.	O
ruzon	O
and	O
tomasi	O
(	O
2001	O
)	O
and	O
gevers	O
,	O
van	O
de	O
weijer	O
,	O
and	O
stokman	O
(	O
2006	O
)	O
provide	O
good	O
reviews	O
of	O
these	O
approaches	O
,	O
which	O
include	O
ideas	O
such	O
as	O
fusing	O
outputs	O
from	O
multiple	B
channels	O
,	O
using	O
multidimensional	O
gradients	O
,	O
and	O
vector-based	O
7	O
instead	O
of	O
using	O
the	O
raw	O
rgb	O
space	O
,	O
a	O
more	O
perceptually	O
uniform	O
color	B
space	O
such	O
as	O
l*a*b*	O
(	O
see	O
section	O
2.3.2	O
)	O
can	O
be	O
used	O
instead	O
.	O
when	O
trying	O
to	O
match	O
human	O
performance	O
(	O
martin	O
,	O
fowlkes	O
,	O
and	O
malik	O
2004	O
)	O
,	O
this	O
makes	O
sense	O
.	O
however	O
,	O
in	O
terms	O
of	O
the	O
physics	O
of	O
the	O
underlying	O
image	B
formation	O
and	O
sensing	O
,	O
it	O
may	O
be	O
a	O
questionable	O
strategy	B
.	O
244	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
methods	O
.	O
combining	O
edge	O
feature	O
cues	O
if	O
the	O
goal	O
of	O
edge	O
detection	O
is	O
to	O
match	O
human	O
boundary	B
detection	I
performance	O
(	O
bowyer	O
,	O
kranenburg	O
,	O
and	O
dougherty	O
2001	O
;	O
martin	O
,	O
fowlkes	O
,	O
and	O
malik	O
2004	O
;	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
2010	O
)	O
,	O
as	O
opposed	O
to	O
simply	O
ﬁnding	O
stable	O
features	O
for	O
matching	O
,	O
even	O
better	O
detectors	O
can	O
be	O
constructed	O
by	O
combining	O
multiple	B
low-level	O
cues	O
such	O
as	O
brightness	O
,	O
color	B
,	O
and	O
tex-	O
ture	O
.	O
martin	O
,	O
fowlkes	O
,	O
and	O
malik	O
(	O
2004	O
)	O
describe	O
a	O
system	O
that	O
combines	O
brightness	O
,	O
color	B
,	O
and	O
texture	B
edges	O
to	O
produce	O
state-of-the-art	O
performance	O
on	O
a	O
database	O
of	O
hand-segmented	O
natu-	O
ral	O
color	B
images	O
(	O
martin	O
,	O
fowlkes	O
,	O
tal	O
et	O
al	O
.	O
2001	O
)	O
.	O
first	O
,	O
they	O
construct	O
and	O
train8	O
separate	O
oriented	B
half-disc	O
detectors	O
for	O
measuring	O
signiﬁcant	O
differences	O
in	O
brightness	O
(	O
luminance	O
)	O
,	O
color	B
(	O
a*	O
and	O
b*	O
channels	O
,	O
summed	O
responses	O
)	O
,	O
and	O
texture	B
(	O
un-normalized	O
ﬁlter	O
bank	O
re-	O
sponses	O
from	O
the	O
work	O
of	O
malik	O
,	O
belongie	O
,	O
leung	O
et	O
al	O
.	O
(	O
2001	O
)	O
)	O
.	O
some	O
of	O
the	O
responses	O
are	O
then	O
sharpened	O
using	O
a	O
soft	O
non-maximal	O
suppression	O
technique	O
.	O
finally	O
,	O
the	O
outputs	O
of	O
the	O
three	O
detectors	O
are	O
combined	O
using	O
a	O
variety	O
of	O
machine-learning	O
techniques	O
,	O
from	O
which	O
logistic	O
regression	O
is	O
found	O
to	O
have	O
the	O
best	O
tradeoff	O
between	O
speed	O
,	O
space	O
and	O
accuracy	B
.	O
the	O
resulting	O
system	O
(	O
see	O
figure	O
4.33	O
for	O
some	O
examples	B
)	O
is	O
shown	O
to	O
outperform	O
previously	O
developed	O
techniques	O
.	O
maire	O
,	O
arbelaez	O
,	O
fowlkes	O
et	O
al	O
.	O
(	O
2008	O
)	O
improve	O
on	O
these	O
results	O
by	O
combining	O
the	O
detector	O
based	O
on	O
local	B
appearance	O
with	O
a	O
spectral	O
(	O
segmentation-based	B
)	O
de-	O
in	O
more	O
recent	O
work	O
,	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
tector	O
(	O
belongie	O
and	O
malik	O
1998	O
)	O
.	O
(	O
2010	O
)	O
build	O
a	O
hierarchical	B
segmentation	O
on	O
top	O
of	O
this	O
edge	O
detector	O
using	O
a	O
variant	O
of	O
the	O
watershed	B
algorithm	O
.	O
4.2.2	O
edge	O
linking	O
while	O
isolated	O
edges	O
can	O
be	O
useful	O
for	O
a	O
variety	O
of	O
applications	O
,	O
such	O
as	O
line	O
detection	O
(	O
sec-	O
tion	B
4.3	O
)	O
and	O
sparse	B
stereo	O
matching	B
(	O
section	O
11.2	O
)	O
,	O
they	O
become	O
even	O
more	O
useful	O
when	O
linked	O
into	O
continuous	O
contours	O
.	O
if	O
the	O
edges	O
have	O
been	O
detected	O
using	O
zero	O
crossings	O
of	O
some	O
function	O
,	O
linking	B
them	O
up	O
is	O
straightforward	O
,	O
since	O
adjacent	O
edgels	O
share	O
common	O
endpoints	O
.	O
linking	B
the	O
edgels	O
into	O
chains	O
involves	O
picking	O
up	O
an	O
unlinked	O
edgel	O
and	O
following	O
its	O
neighbors	O
in	O
both	O
directions	O
.	O
either	O
a	O
sorted	O
list	O
of	O
edgels	O
(	O
sorted	O
ﬁrst	O
by	O
x	O
coordinates	O
and	O
then	O
by	O
y	O
coordinates	O
,	O
for	O
example	O
)	O
or	O
a	O
2d	O
array	O
can	O
be	O
used	O
to	O
accelerate	O
the	O
neighbor	O
ﬁnding	O
.	O
if	O
edges	O
were	O
not	O
detected	O
using	O
zero	O
crossings	O
,	O
ﬁnding	O
the	O
continuation	O
of	O
an	O
edgel	O
can	O
be	O
tricky	O
.	O
in	O
this	O
case	O
,	O
comparing	O
the	O
orientation	O
(	O
and	O
,	O
optionally	O
,	O
phase	O
)	O
of	O
adjacent	O
edgels	O
can	O
be	O
used	O
for	O
8	O
the	O
training	O
uses	O
200	O
labeled	O
images	O
and	O
testing	O
is	O
performed	O
on	O
a	O
different	O
set	O
of	O
100	O
images	O
.	O
4.2	O
edges	O
245	O
figure	O
4.33	O
combined	O
brightness	O
,	O
color	B
,	O
texture	B
boundary	O
detector	O
(	O
martin	O
,	O
fowlkes	O
,	O
and	O
malik	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
ieee	O
.	O
successive	O
rows	O
show	O
the	O
outputs	O
of	O
the	O
brightness	O
gradient	O
(	O
bg	O
)	O
,	O
color	B
gradient	O
(	O
cg	O
)	O
,	O
texture	B
gradient	O
(	O
tg	O
)	O
,	O
and	O
combined	O
(	O
bg+cg+tg	O
)	O
detectors	O
.	O
the	O
ﬁnal	O
row	O
shows	O
human-labeled	O
boundaries	O
derived	O
from	O
a	O
database	O
of	O
hand-segmented	O
images	O
(	O
martin	O
,	O
fowlkes	O
,	O
tal	O
et	O
al	O
.	O
2001	O
)	O
.	O
246	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.34	O
chain	B
code	I
representation	O
of	O
a	O
grid-aligned	O
linked	O
edge	O
chain	O
.	O
the	O
code	O
is	O
represented	O
as	O
a	O
series	O
of	O
direction	O
codes	O
,	O
e.g	O
,	O
0	O
1	O
0	O
7	O
6	O
5	O
,	O
which	O
can	O
further	O
be	O
compressed	O
using	O
predictive	O
and	O
run-length	O
coding	O
.	O
disambiguation	O
.	O
ideas	O
from	O
connected	O
component	O
computation	O
can	O
also	O
sometimes	O
be	O
used	O
to	O
make	O
the	O
edge	O
linking	O
process	O
even	O
faster	O
(	O
see	O
exercise	O
4.8	O
)	O
.	O
once	O
the	O
edgels	O
have	O
been	O
linked	O
into	O
chains	O
,	O
we	O
can	O
apply	O
an	O
optional	O
thresholding	B
with	O
hysteresis	B
to	O
remove	O
low-strength	O
contour	O
segments	O
(	O
canny	O
1986	O
)	O
.	O
the	O
basic	O
idea	O
of	O
hysteresis	B
is	O
to	O
set	O
two	O
different	O
thresholds	O
and	O
allow	O
a	O
curve	O
being	O
tracked	O
above	O
the	O
higher	O
threshold	O
to	O
dip	O
in	O
strength	O
down	O
to	O
the	O
lower	O
threshold	O
.	O
linked	O
edgel	O
lists	O
can	O
be	O
encoded	O
more	O
compactly	O
using	O
a	O
variety	O
of	O
alternative	O
repre-	O
sentations	O
.	O
a	O
chain	B
code	I
encodes	O
a	O
list	O
of	O
connected	O
points	O
lying	O
on	O
an	O
n8	O
grid	O
using	O
a	O
three-bit	O
code	O
corresponding	O
to	O
the	O
eight	O
cardinal	O
directions	O
(	O
n	O
,	O
ne	O
,	O
e	O
,	O
se	O
,	O
s	O
,	O
sw	O
,	O
w	O
,	O
nw	O
)	O
between	O
a	O
point	O
and	O
its	O
successor	O
(	O
figure	O
4.34	O
)	O
.	O
while	O
this	O
representation	O
is	O
more	O
compact	O
than	O
the	O
original	O
edgel	O
list	O
(	O
especially	O
if	O
predictive	O
variable-length	O
coding	O
is	O
used	O
)	O
,	O
it	O
is	O
not	O
very	O
suitable	O
for	O
further	O
processing	O
.	O
a	O
more	O
useful	O
representation	O
is	O
the	O
arc	B
length	I
parameterization	I
of	O
a	O
contour	O
,	O
x	O
(	O
s	O
)	O
,	O
where	O
s	O
denotes	O
the	O
arc	O
length	O
along	O
a	O
curve	O
.	O
consider	O
the	O
linked	O
set	O
of	O
edgels	O
shown	O
in	O
fig-	O
ure	O
4.35a	O
.	O
we	O
start	O
at	O
one	O
point	O
(	O
the	O
dot	O
at	O
(	O
1.0	O
,	O
0.5	O
)	O
in	O
figure	O
4.35a	O
)	O
and	O
plot	O
it	O
at	O
coordinate	O
s	O
=	O
0	O
(	O
figure	O
4.35b	O
)	O
.	O
the	O
next	O
point	O
at	O
(	O
2.0	O
,	O
0.5	O
)	O
gets	O
plotted	O
at	O
s	O
=	O
1	O
,	O
and	O
the	O
next	O
point	O
at	O
(	O
2.5	O
,	O
1.0	O
)	O
gets	O
plotted	O
at	O
s	O
=	O
1.7071	O
,	O
i.e.	O
,	O
we	O
increment	O
s	O
by	O
the	O
length	O
of	O
each	O
edge	O
seg-	O
ment	O
.	O
the	O
resulting	O
plot	O
can	O
be	O
resampled	O
on	O
a	O
regular	O
(	O
say	O
,	O
integral	O
)	O
s	O
grid	O
before	O
further	O
processing	O
.	O
the	O
advantage	O
of	O
the	O
arc-length	O
parameterization	O
is	O
that	O
it	O
makes	O
matching	B
and	O
processing	O
(	O
e.g.	O
,	O
smoothing	B
)	O
operations	O
much	O
easier	O
.	O
consider	O
the	O
two	O
curves	O
describing	O
similar	O
shapes	O
shown	O
in	O
figure	O
4.36.	O
to	O
compare	O
the	O
curves	O
,	O
we	O
ﬁrst	O
subtract	O
the	O
average	O
values	O
x0	O
=	O
(	O
cid:82	O
)	O
s	O
x	O
(	O
s	O
)	O
from	O
each	O
descriptor	O
.	O
next	O
,	O
we	O
rescale	O
each	O
descriptor	O
so	O
that	O
s	O
goes	O
from	O
0	O
to	O
1	O
instead	O
of	O
0	O
to	O
s	O
,	O
i.e.	O
,	O
we	O
divide	O
x	O
(	O
s	O
)	O
by	O
s.	O
finally	O
,	O
we	O
take	O
the	O
fourier	O
transform	B
of	O
each	O
n	O
0n	O
0w6ne	O
1	O
7nwsw	O
5	O
4.2	O
edges	O
247	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
4.35	O
arc-length	O
parameterization	O
of	O
a	O
contour	O
:	O
(	O
a	O
)	O
discrete	B
points	O
along	O
the	O
contour	O
are	O
ﬁrst	O
transcribed	O
as	O
(	O
b	O
)	O
(	O
x	O
,	O
y	O
)	O
pairs	B
along	O
the	O
arc	O
length	O
s.	O
this	O
curve	O
can	O
then	O
be	O
regularly	O
re-sampled	O
or	O
converted	O
into	O
alternative	O
(	O
e.g.	O
,	O
fourier	O
)	O
representations	O
.	O
figure	O
4.36	O
matching	B
two	O
contours	O
using	O
their	O
arc-length	O
parameterization	O
.	O
if	O
both	O
curves	O
are	O
normalized	B
to	O
unit	O
length	O
,	O
s	O
∈	O
[	O
0	O
,	O
1	O
]	O
and	O
centered	O
around	O
their	O
centroid	O
x0	O
,	O
they	O
will	O
have	O
the	O
same	O
descriptor	O
up	O
to	O
an	O
overall	O
“	O
temporal	O
”	O
shift	O
(	O
due	O
to	O
different	O
starting	O
points	B
for	O
s	O
=	O
0	O
)	O
and	O
a	O
phase	O
(	O
x-y	O
)	O
shift	O
(	O
due	O
to	O
rotation	O
)	O
.	O
0123401234xy0123401234567891011s.xytx	O
(	O
s	O
)	O
κs=0=1x0s=0=1x0	O
248	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
4.37	O
curve	O
smoothing	B
with	O
a	O
gaussian	O
kernel	B
(	O
lowe	O
1988	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
ieee	O
:	O
(	O
a	O
)	O
with-	O
out	O
a	O
shrinkage	O
correction	O
term	O
;	O
(	O
b	O
)	O
with	O
a	O
shrinkage	O
correction	O
term	O
.	O
figure	O
4.38	O
changing	O
the	O
character	O
of	O
a	O
curve	O
without	O
affecting	O
its	O
sweep	O
(	O
finkelstein	O
and	O
salesin	O
1994	O
)	O
c	O
(	O
cid:13	O
)	O
1994	O
acm	O
:	O
higher	O
frequency	O
wavelets	O
can	O
be	O
replaced	O
with	O
exemplars	O
from	O
a	O
style	O
library	O
to	O
effect	O
different	O
local	B
appearances	O
.	O
normalized	B
descriptor	O
,	O
treating	O
each	O
x	O
=	O
(	O
x	O
,	O
y	O
)	O
value	O
as	O
a	O
complex	O
number	O
.	O
if	O
the	O
original	O
curves	O
are	O
the	O
same	O
(	O
up	O
to	O
an	O
unknown	O
scale	O
and	O
rotation	O
)	O
,	O
the	O
resulting	O
fourier	O
transforms	O
should	O
differ	O
only	O
by	O
a	O
scale	O
change	O
in	O
magnitude	O
plus	O
a	O
constant	O
complex	O
phase	O
shift	O
,	O
due	O
to	O
rotation	O
,	O
and	O
a	O
linear	B
phase	O
shift	O
in	O
the	O
domain	O
,	O
due	O
to	O
different	O
starting	O
points	B
for	O
s	O
(	O
see	O
exercise	O
4.9	O
)	O
.	O
arc-length	O
parameterization	O
can	O
also	O
be	O
used	O
to	O
smooth	O
curves	O
in	O
order	B
to	O
remove	O
digiti-	O
zation	O
noise	B
.	O
however	O
,	O
if	O
we	O
just	O
apply	O
a	O
regular	O
smoothing	B
ﬁlter	O
,	O
the	O
curve	O
tends	O
to	O
shrink	O
on	O
itself	O
(	O
figure	O
4.37a	O
)	O
.	O
lowe	O
(	O
1989	O
)	O
and	O
taubin	O
(	O
1995	O
)	O
describe	O
techniques	O
that	O
compensate	O
for	O
this	O
shrinkage	O
by	O
adding	O
an	O
offset	O
term	O
based	O
on	O
second	O
derivative	O
estimates	O
or	O
a	O
larger	O
smoothing	B
kernel	O
(	O
figure	O
4.37b	O
)	O
.	O
an	O
alternative	O
approach	O
,	O
based	O
on	O
selectively	O
modifying	O
different	O
frequencies	O
in	O
a	O
wavelet	O
decomposition	O
,	O
is	O
presented	O
by	O
finkelstein	O
and	O
salesin	O
(	O
1994	O
)	O
.	O
in	O
addition	O
to	O
controlling	O
shrinkage	O
without	O
affecting	O
its	O
“	O
sweep	O
”	O
,	O
wavelets	O
allow	O
the	O
“	O
character	O
”	O
of	O
a	O
curve	O
to	O
be	O
interactively	O
modiﬁed	O
,	O
as	O
shown	O
in	O
figure	O
4.38.	O
the	O
evolution	B
of	O
curves	O
as	O
they	O
are	O
smoothed	O
and	O
simpliﬁed	O
is	O
related	O
to	O
“	O
grassﬁre	O
”	O
(	O
dis-	O
4.2	O
edges	O
249	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
figure	O
4.39	O
image	B
editing	O
in	O
the	O
contour	O
domain	O
(	O
elder	O
and	O
goldberg	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
and	O
(	O
d	O
)	O
original	O
images	O
;	O
(	O
b	O
)	O
and	O
(	O
e	O
)	O
extracted	O
edges	O
(	O
edges	O
to	O
be	O
deleted	O
are	O
marked	O
in	O
white	O
)	O
;	O
(	O
c	O
)	O
and	O
(	O
f	O
)	O
reconstructed	O
edited	O
images	O
.	O
tance	O
)	O
transforms	O
and	O
region	B
skeletons	O
(	O
section	O
3.3.3	O
)	O
(	O
tek	O
and	O
kimia	O
2003	O
)	O
,	O
and	O
can	O
be	O
used	O
to	O
recognize	O
objects	O
based	O
on	O
their	O
contour	O
shape	O
(	O
sebastian	O
and	O
kimia	O
2005	O
)	O
.	O
more	O
local	B
de-	O
scriptors	O
of	O
curve	O
shape	O
such	O
as	O
shape	O
contexts	O
(	O
belongie	O
,	O
malik	O
,	O
and	O
puzicha	O
2002	O
)	O
can	O
also	O
be	O
used	O
for	B
recognition	I
and	O
are	O
potentially	O
more	O
robust	B
to	O
missing	O
parts	O
due	O
to	O
occlusions	O
.	O
the	O
ﬁeld	O
of	O
contour	O
detection	B
and	O
linking	B
continues	O
to	O
evolve	O
rapidly	O
and	O
now	O
includes	O
techniques	O
for	O
global	O
contour	O
grouping	O
,	O
boundary	O
completion	O
,	O
and	O
junction	O
detection	B
(	O
maire	O
,	O
arbelaez	O
,	O
fowlkes	O
et	O
al	O
.	O
2008	O
)	O
,	O
as	O
well	O
as	O
grouping	O
contours	O
into	O
likely	O
regions	O
(	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
2010	O
)	O
and	O
wide-baseline	O
correspondence	B
(	O
meltzer	O
and	O
soatto	O
2008	O
)	O
.	O
4.2.3	O
application	O
:	O
edge	B
editing	I
and	O
enhancement	O
while	O
edges	O
can	O
serve	O
as	O
components	O
for	O
object	O
recognition	B
or	O
features	O
for	O
matching	O
,	O
they	O
can	O
also	O
be	O
used	O
directly	O
for	O
image	O
editing	O
.	O
in	O
fact	O
,	O
if	O
the	O
edge	O
magnitude	O
and	O
blur	O
estimate	O
are	O
kept	O
along	O
with	O
each	O
edge	O
,	O
a	O
visually	O
similar	O
image	B
can	O
be	O
reconstructed	O
from	O
this	O
information	O
(	O
elder	O
1999	O
)	O
.	O
based	O
on	O
this	O
princi-	O
ple	O
,	O
elder	O
and	O
goldberg	O
(	O
2001	O
)	O
propose	O
a	O
system	O
for	O
“	O
image	B
editing	O
in	O
the	O
contour	O
domain	O
”	O
.	O
their	O
system	O
allows	O
users	O
to	O
selectively	O
remove	O
edges	O
corresponding	O
to	O
unwanted	O
features	O
such	O
as	O
specularities	B
,	O
shadows	O
,	O
or	O
distracting	O
visual	O
elements	O
.	O
after	O
reconstructing	O
the	O
image	B
from	O
the	O
remaining	O
edges	O
,	O
the	O
undesirable	O
visual	O
features	O
have	O
been	O
removed	O
(	O
figure	O
4.39	O
)	O
.	O
250	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.40	O
approximating	O
a	O
curve	O
(	O
shown	O
in	O
black	O
)	O
as	O
a	O
polyline	O
or	O
b-spline	O
:	O
(	O
a	O
)	O
original	O
curve	O
and	O
a	O
polyline	O
approximation	O
shown	O
in	O
red	O
;	O
(	O
b	O
)	O
successive	B
approximation	I
by	O
recursively	O
ﬁnding	O
points	B
furthest	O
away	O
from	O
the	O
current	O
approximation	O
;	O
(	O
c	O
)	O
smooth	O
interpolating	O
spline	B
,	O
shown	O
in	O
dark	O
blue	O
,	O
ﬁt	O
to	O
the	O
polyline	O
vertices	O
.	O
another	O
potential	O
application	O
is	O
to	O
enhance	O
perceptually	O
salient	O
edges	O
while	O
simplifying	O
the	O
underlying	O
image	B
to	O
produce	O
a	O
cartoon-like	O
or	O
“	O
pen-and-ink	O
”	O
stylized	O
image	B
(	O
decarlo	O
and	O
santella	O
2002	O
)	O
.	O
this	O
application	O
is	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
10.5.2	O
.	O
4.3	O
lines	B
while	O
edges	O
and	O
general	O
curves	O
are	O
suitable	O
for	O
describing	O
the	O
contours	O
of	O
natural	B
objects	O
,	O
the	O
man-made	O
world	O
is	O
full	O
of	O
straight	O
lines	B
.	O
detecting	O
and	O
matching	B
these	O
lines	B
can	O
be	O
useful	O
in	O
a	O
variety	O
of	O
applications	O
,	O
including	O
architectural	O
modeling	B
,	O
pose	O
estimation	B
in	O
urban	O
environments	O
,	O
and	O
the	O
analysis	O
of	O
printed	O
document	O
layouts	O
.	O
in	O
this	O
section	O
,	O
we	O
present	O
some	O
techniques	O
for	O
extracting	O
piecewise	O
linear	B
descriptions	O
from	O
the	O
curves	O
computed	O
in	O
the	O
previous	O
section	O
.	O
we	O
begin	O
with	O
some	O
algorithms	O
for	O
approx-	O
imating	O
a	O
curve	O
as	O
a	O
piecewise-linear	O
polyline	O
.	O
we	O
then	O
describe	O
the	O
hough	O
transform	B
,	O
which	O
can	O
be	O
used	O
to	O
group	O
edgels	O
into	O
line	O
segments	O
even	O
across	O
gaps	O
and	O
occlusions	O
.	O
finally	O
,	O
we	O
describe	O
how	O
3d	O
lines	B
with	O
common	O
vanishing	B
points	I
can	O
be	O
grouped	O
together	O
.	O
these	O
van-	O
ishing	O
points	B
can	O
be	O
used	O
to	O
calibrate	O
a	O
camera	B
and	O
to	O
determine	O
its	O
orientation	O
relative	O
to	O
a	O
rectahedral	O
scene	O
,	O
as	O
described	O
in	O
section	O
6.3.2	O
.	O
4.3.1	O
successive	B
approximation	I
as	O
we	O
saw	O
in	O
section	O
4.2.2	O
,	O
describing	O
a	O
curve	O
as	O
a	O
series	O
of	O
2d	O
locations	O
xi	O
=	O
x	O
(	O
si	O
)	O
provides	O
a	O
general	O
representation	O
suitable	O
for	O
matching	O
and	O
further	O
processing	O
.	O
in	O
many	O
applications	O
,	O
however	O
,	O
it	O
is	O
preferable	O
to	O
approximate	O
such	O
a	O
curve	O
with	O
a	O
simpler	O
representation	O
,	O
e.g.	O
,	O
as	O
a	O
piecewise-linear	O
polyline	O
or	O
as	O
a	O
b-spline	O
curve	O
(	O
farin	O
1996	O
)	O
,	O
as	O
shown	O
in	O
figure	O
4.40.	O
many	O
techniques	O
have	O
been	O
developed	O
over	O
the	O
years	O
to	O
perform	O
this	O
approximation	O
,	O
which	O
is	O
also	O
known	O
as	O
line	O
simpliﬁcation	O
.	O
one	O
of	O
the	O
oldest	O
,	O
and	O
simplest	O
,	O
is	O
the	O
one	O
proposed	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
4.3	O
lines	B
251	O
figure	O
4.41	O
original	O
hough	O
transform	B
:	O
(	O
a	O
)	O
each	O
point	O
votes	O
for	O
a	O
complete	O
family	O
of	O
poten-	O
tial	O
lines	B
ri	O
(	O
θ	O
)	O
=	O
xi	O
cos	O
θ	O
+	O
yi	O
sin	O
θ	O
;	O
(	O
b	O
)	O
each	O
pencil	O
of	O
lines	B
sweeps	O
out	O
a	O
sinusoid	O
in	O
(	O
r	O
,	O
θ	O
)	O
;	O
their	O
intersection	O
provides	O
the	O
desired	O
line	O
equation	O
.	O
by	O
ramer	O
(	O
1972	O
)	O
and	O
douglas	O
and	O
peucker	O
(	O
1973	O
)	O
,	O
who	O
recursively	O
subdivide	O
the	O
curve	O
at	O
the	O
point	O
furthest	O
away	O
from	O
the	O
line	O
joining	O
the	O
two	O
endpoints	O
(	O
or	O
the	O
current	O
coarse	O
polyline	O
approximation	O
)	O
,	O
as	O
shown	O
in	O
figure	O
4.40.	O
hershberger	O
and	O
snoeyink	O
(	O
1992	O
)	O
provide	O
a	O
more	O
efﬁcient	O
implementation	O
and	O
also	O
cite	O
some	O
of	O
the	O
other	O
related	O
work	O
in	O
this	O
area	O
.	O
once	O
the	O
line	O
simpliﬁcation	O
has	O
been	O
computed	O
,	O
it	O
can	O
be	O
used	O
to	O
approximate	O
the	O
orig-	O
inal	O
curve	O
.	O
if	O
a	O
smoother	O
representation	O
or	O
visualization	O
is	O
desired	O
,	O
either	O
approximating	O
or	O
interpolating	O
splines	B
or	O
curves	O
can	O
be	O
used	O
(	O
sections	O
3.5.1	O
and	O
5.1.1	O
)	O
(	O
szeliski	O
and	O
ito	O
1986	O
;	O
bartels	O
,	O
beatty	O
,	O
and	O
barsky	O
1987	O
;	O
farin	O
1996	O
)	O
,	O
as	O
shown	O
in	O
figure	O
4.40c	O
.	O
4.3.2	O
hough	O
transforms	O
while	O
curve	O
approximation	O
with	O
polylines	O
can	O
often	O
lead	O
to	O
successful	O
line	O
extraction	O
,	O
lines	B
in	O
the	O
real	O
world	O
are	O
sometimes	O
broken	O
up	O
into	O
disconnected	O
components	O
or	O
made	O
up	O
of	O
many	O
collinear	O
line	O
segments	O
.	O
in	O
many	O
cases	O
,	O
it	O
is	O
desirable	O
to	O
group	O
such	O
collinear	O
segments	O
into	O
extended	O
lines	B
.	O
at	O
a	O
further	O
processing	O
stage	O
(	O
described	O
in	O
section	O
4.3.3	O
)	O
,	O
we	O
can	O
then	O
group	O
such	O
lines	B
into	O
collections	O
with	O
common	O
vanishing	B
points	I
.	O
the	O
hough	O
transform	B
,	O
named	O
after	O
its	O
original	O
inventor	O
(	O
hough	O
1962	O
)	O
,	O
is	O
a	O
well-known	O
technique	O
for	O
having	O
edges	O
“	O
vote	O
”	O
for	O
plausible	O
line	O
locations	O
(	O
duda	O
and	O
hart	O
1972	O
;	O
ballard	O
1981	O
;	O
illingworth	O
and	O
kittler	O
1988	O
)	O
.	O
in	O
its	O
original	O
formulation	O
(	O
figure	O
4.41	O
)	O
,	O
each	O
edge	O
point	O
votes	O
for	O
all	O
possible	O
lines	B
passing	O
through	O
it	O
,	O
and	O
lines	B
corresponding	O
to	O
high	O
accumulator	O
or	O
bin	O
values	O
are	O
examined	O
for	O
potential	O
line	O
ﬁts.9	O
unless	O
the	O
points	B
on	O
a	O
line	O
are	O
truly	O
punctate	O
,	O
a	O
better	O
approach	O
(	O
in	O
my	O
experience	O
)	O
is	O
to	O
use	O
the	O
local	B
orientation	O
information	O
at	O
each	O
edgel	O
to	O
vote	O
for	O
a	O
single	O
accumulator	O
cell	O
(	O
figure	O
4.42	O
)	O
,	O
as	O
described	O
below	O
.	O
a	O
hybrid	O
strategy	B
,	O
9	O
the	O
hough	O
transform	B
can	O
also	O
be	O
generalized	B
to	O
look	O
for	O
other	O
geometric	B
features	O
such	O
as	O
circles	O
(	O
ballard	O
1981	O
)	O
,	O
but	O
we	O
do	O
not	O
cover	O
such	O
extensions	O
in	O
this	O
book	O
.	O
θiriθ	O
(	O
xi	O
,	O
yi	O
)	O
03600rmaxr-rmaxxy	O
(	O
a	O
)	O
(	O
b	O
)	O
252	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.42	O
oriented	B
hough	O
transform	B
:	O
(	O
a	O
)	O
an	O
edgel	O
re-parameterized	O
in	O
polar	O
(	O
r	O
,	O
θ	O
)	O
coor-	O
dinates	O
,	O
with	O
ˆni	O
=	O
(	O
cos	O
θi	O
,	O
sin	O
θi	O
)	O
and	O
ri	O
=	O
ˆni	O
·	O
xi	O
;	O
(	O
b	O
)	O
(	O
r	O
,	O
θ	O
)	O
accumulator	O
array	O
,	O
showing	O
the	O
votes	O
for	O
the	O
three	O
edgels	O
marked	O
in	O
red	O
,	O
green	O
,	O
and	O
blue	O
.	O
figure	O
4.43	O
2d	O
line	O
equation	O
expressed	O
in	O
terms	O
of	O
the	O
normal	O
ˆn	O
and	O
distance	O
to	O
the	O
origin	O
d.	O
where	O
each	O
edgel	O
votes	O
for	O
a	O
number	O
of	O
possible	O
orientation	O
or	O
location	O
pairs	O
centered	O
around	O
the	O
estimate	O
orientation	O
,	O
may	O
be	O
desirable	O
in	O
some	O
cases	O
.	O
before	O
we	O
can	O
vote	O
for	O
line	O
hypotheses	O
,	O
we	O
must	O
ﬁrst	O
choose	O
a	O
suitable	O
representation	O
.	O
figure	O
4.43	O
(	O
copied	O
from	O
figure	O
2.2a	O
)	O
shows	O
the	O
normal-distance	O
(	O
ˆn	O
,	O
d	O
)	O
parameterization	O
for	O
a	O
line	O
.	O
since	O
lines	B
are	O
made	O
up	O
of	O
edge	O
segments	O
,	O
we	O
adopt	O
the	O
convention	O
that	O
the	O
line	O
normal	O
ˆn	O
points	B
in	O
the	O
same	O
direction	O
(	O
i.e.	O
,	O
has	O
the	O
same	O
sign	O
)	O
as	O
the	O
image	B
gradient	O
j	O
(	O
x	O
)	O
=	O
∇i	O
(	O
x	O
)	O
(	O
4.19	O
)	O
.	O
to	O
obtain	O
a	O
minimal	O
two-parameter	O
representation	O
for	O
lines	O
,	O
we	O
convert	O
the	O
normal	B
vector	I
into	O
an	O
angle	O
θ	O
=	O
tan−1	O
ny/nx	O
,	O
(	O
4.26	O
)	O
as	O
shown	O
in	O
figure	O
4.43.	O
the	O
range	O
of	O
possible	O
(	O
θ	O
,	O
d	O
)	O
values	O
is	O
[	O
−180◦	O
,	O
180◦	O
]	O
×	O
[	O
−√2	O
,	O
√2	O
]	O
,	O
assuming	O
that	O
we	O
are	O
using	O
normalized	O
pixel	O
coordinates	O
(	O
2.61	O
)	O
that	O
lie	O
in	O
[	O
−1	O
,	O
1	O
]	O
.	O
the	O
number	O
of	O
bins	O
to	O
use	O
along	O
each	O
axis	O
depends	O
on	O
the	O
accuracy	B
of	O
the	O
position	O
and	O
orientation	O
estimate	O
available	O
at	O
each	O
edgel	O
and	O
the	O
expected	O
line	O
density	O
,	O
and	O
is	O
best	O
set	O
experimentally	O
with	O
some	O
test	O
runs	O
on	O
sample	O
imagery	O
.	O
given	O
the	O
line	O
parameterization	O
,	O
the	O
hough	O
transform	B
proceeds	O
as	O
shown	O
in	O
algorithm	B
4.2.	O
θiriθ	O
(	O
xi	O
,	O
yi	O
)	O
03600rmaxr-rmaxxy	O
(	O
a	O
)	O
(	O
b	O
)	O
yxdθnl^	O
4.3	O
lines	B
253	O
procedure	O
hough	O
(	O
{	O
(	O
x	O
,	O
y	O
,	O
θ	O
)	O
}	O
)	O
:	O
1.	O
clear	O
the	O
accumulator	O
array	O
.	O
2.	O
for	O
each	O
detected	O
edgel	O
at	O
location	O
(	O
x	O
,	O
y	O
)	O
and	O
orientation	O
θ	O
=	O
tan−1	O
ny/nx	O
,	O
compute	O
the	O
value	O
of	O
d	O
=	O
x	O
nx	O
+	O
y	O
ny	O
and	O
increment	O
the	O
accumulator	O
corresponding	O
to	O
(	O
θ	O
,	O
d	O
)	O
.	O
3.	O
find	O
the	O
peaks	O
in	O
the	O
accumulator	O
corresponding	O
to	O
lines	B
.	O
4.	O
optionally	O
re-ﬁt	O
the	O
lines	B
to	O
the	O
constituent	O
edgels	O
.	O
algorithm	B
4.2	O
outline	O
of	O
a	O
hough	O
transform	B
algorithm	O
based	O
on	O
oriented	B
edge	O
segments	O
.	O
note	O
that	O
the	O
original	O
formulation	O
of	O
the	O
hough	O
transform	B
,	O
which	O
assumed	O
no	O
knowledge	O
of	O
the	O
edgel	O
orientation	O
θ	O
,	O
has	O
an	O
additional	O
loop	O
inside	O
step	O
2	O
that	O
iterates	O
over	O
all	O
possible	O
values	O
of	O
θ	O
and	O
increments	O
a	O
whole	O
series	O
of	O
accumulators	O
.	O
there	O
are	O
a	O
lot	O
of	O
details	O
in	O
getting	O
the	O
hough	O
transform	B
to	O
work	O
well	O
,	O
but	O
these	O
are	O
best	O
worked	O
out	O
by	O
writing	O
an	O
implementation	O
and	O
testing	O
it	O
out	O
on	O
sample	O
data	O
.	O
exercise	O
4.12	O
describes	O
some	O
of	O
these	O
steps	O
in	O
more	O
detail	O
,	O
including	O
using	O
edge	O
segment	O
lengths	O
or	O
strengths	O
during	O
the	O
voting	O
process	O
,	O
keeping	O
a	O
list	O
of	O
constituent	O
edgels	O
in	O
the	O
accumulator	O
array	O
for	O
easier	O
post-processing	O
,	O
and	O
optionally	O
combining	O
edges	O
of	O
different	O
“	O
polarity	O
”	O
into	O
the	O
same	O
line	O
segments	O
.	O
an	O
alternative	O
to	O
the	O
2d	O
polar	O
(	O
θ	O
,	O
d	O
)	O
representation	O
for	O
lines	O
is	O
to	O
use	O
the	O
full	O
3d	O
m	O
=	O
(	O
ˆn	O
,	O
d	O
)	O
line	O
equation	O
,	O
projected	O
onto	O
the	O
unit	O
sphere	O
.	O
while	O
the	O
sphere	O
can	O
be	O
parameterized	O
using	O
spherical	O
coordinates	O
(	O
2.8	O
)	O
,	O
ˆm	O
=	O
(	O
cos	O
θ	O
cos	O
φ	O
,	O
sin	O
θ	O
cos	O
φ	O
,	O
sin	O
φ	O
)	O
,	O
(	O
4.27	O
)	O
this	O
does	O
not	O
uniformly	O
sample	O
the	O
sphere	O
and	O
still	O
requires	O
the	O
use	O
of	O
trigonometry	O
.	O
an	O
alternative	O
representation	O
can	O
be	O
obtained	O
by	O
using	O
a	O
cube	B
map	I
,	O
i.e.	O
,	O
projecting	O
m	O
onto	O
the	O
face	B
of	O
a	O
unit	O
cube	O
(	O
figure	O
4.44a	O
)	O
.	O
to	O
compute	O
the	O
cube	B
map	I
coordinate	O
of	O
a	O
3d	O
vector	O
m	O
,	O
ﬁrst	O
ﬁnd	O
the	O
largest	O
(	O
absolute	O
value	O
)	O
component	O
of	O
m	O
,	O
i.e.	O
,	O
m	O
=	O
±	O
max	O
(	O
|nx|	O
,	O
|ny|	O
,	O
|d|	O
)	O
,	O
and	O
use	O
this	O
to	O
select	O
one	O
of	O
the	O
six	O
cube	O
faces	O
.	O
divide	O
the	O
remaining	O
two	O
coordinates	O
by	O
m	O
and	O
use	O
these	O
as	O
indices	O
into	O
the	O
cube	O
face	O
.	O
while	O
this	O
avoids	O
the	O
use	O
of	O
trigonometry	O
,	O
it	O
does	O
require	O
some	O
decision	O
logic	O
.	O
one	O
advantage	O
of	O
using	O
the	O
cube	B
map	I
,	O
ﬁrst	O
pointed	O
out	O
by	O
tuytelaars	O
,	O
van	O
gool	O
,	O
and	O
proesmans	O
(	O
1997	O
)	O
,	O
is	O
that	O
all	O
of	O
the	O
lines	B
passing	O
through	O
a	O
point	O
correspond	O
to	O
line	O
segments	O
254	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
⇒	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
4.44	O
cube	B
map	I
representation	O
for	O
line	O
equations	B
and	O
vanishing	B
points	I
:	O
(	O
a	O
)	O
a	O
cube	B
map	I
surrounding	O
the	O
unit	O
sphere	O
;	O
(	O
b	O
)	O
projecting	O
the	O
half-cube	O
onto	O
three	O
subspaces	O
(	O
tuytelaars	O
,	O
van	O
gool	O
,	O
and	O
proesmans	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
ieee	O
.	O
on	O
the	O
cube	O
faces	O
,	O
which	O
is	O
useful	O
if	O
the	O
original	O
(	O
full	O
voting	O
)	O
variant	O
of	O
the	O
hough	O
transform	B
is	O
being	O
used	O
.	O
in	O
their	O
work	O
,	O
they	O
represent	O
the	O
line	O
equation	O
as	O
ax	O
+	O
b	O
+	O
y	O
=	O
0	O
,	O
which	O
does	O
not	O
treat	O
the	O
x	O
and	O
y	O
axes	O
symmetrically	O
.	O
note	O
that	O
if	O
we	O
restrict	O
d	O
≥	O
0	O
by	O
ignoring	O
the	O
polarity	O
of	O
the	O
edge	O
orientation	O
(	O
gradient	O
sign	O
)	O
,	O
we	O
can	O
use	O
a	O
half-cube	O
instead	O
,	O
which	O
can	O
be	O
represented	O
using	O
only	O
three	O
cube	O
faces	O
,	O
as	O
shown	O
in	O
figure	O
4.44b	O
(	O
tuytelaars	O
,	O
van	O
gool	O
,	O
and	O
proesmans	O
1997	O
)	O
.	O
ransac-based	O
line	O
detection	O
.	O
another	O
alternative	O
to	O
the	O
hough	O
transform	B
is	O
the	O
ran-	O
dom	O
sample	O
consensus	O
(	O
ransac	O
)	O
algorithm	B
described	O
in	O
more	O
detail	O
in	O
section	O
6.1.4.	O
in	O
brief	O
,	O
ransac	O
randomly	O
chooses	O
pairs	B
of	O
edgels	O
to	O
form	O
a	O
line	O
hypothesis	O
and	O
then	O
tests	O
how	O
many	O
other	O
edgels	O
fall	O
onto	O
this	O
line	O
.	O
(	O
if	O
the	O
edge	O
orientations	O
are	O
accurate	O
enough	O
,	O
a	O
single	O
edgel	O
can	O
produce	O
this	O
hypothesis	O
.	O
)	O
lines	B
with	O
sufﬁciently	O
large	O
numbers	O
of	O
inliers	B
(	O
matching	B
edgels	O
)	O
are	O
then	O
selected	O
as	O
the	O
desired	O
line	O
segments	O
.	O
an	O
advantage	O
of	O
ransac	O
is	O
that	O
no	O
accumulator	O
array	O
is	O
needed	O
and	O
so	O
the	O
algorithm	B
can	O
be	O
more	O
space	O
efﬁcient	O
and	O
potentially	O
less	O
prone	O
to	O
the	O
choice	O
of	O
bin	O
size	O
.	O
the	O
disadvantage	O
is	O
that	O
many	O
more	O
hypotheses	O
may	O
need	O
to	O
be	O
generated	O
and	O
tested	O
than	O
those	O
obtained	O
by	O
ﬁnding	O
peaks	O
in	O
the	O
accumulator	O
array	O
.	O
in	O
general	O
,	O
there	O
is	O
no	O
clear	O
consensus	O
on	O
which	O
line	O
estimation	O
technique	O
performs	O
best	O
.	O
it	O
is	O
therefore	O
a	O
good	O
idea	O
to	O
think	O
carefully	O
about	O
the	O
problem	O
at	O
hand	O
and	O
to	O
implement	O
several	O
approaches	O
(	O
successive	B
approximation	I
,	O
hough	O
,	O
and	O
ransac	O
)	O
to	O
determine	O
the	O
one	O
that	O
works	O
best	O
for	O
your	O
application	O
.	O
4.3.3	O
vanishing	B
points	I
in	O
many	O
scenes	O
,	O
structurally	O
important	O
lines	B
have	O
the	O
same	O
vanishing	O
point	O
because	O
they	O
are	O
parallel	O
in	O
3d	O
.	O
examples	B
of	O
such	O
lines	B
are	O
horizontal	O
and	O
vertical	O
building	O
edges	O
,	O
zebra	O
cross-	O
ings	O
,	O
railway	O
tracks	O
,	O
the	O
edges	O
of	O
furniture	O
such	O
as	O
tables	O
and	O
dressers	O
,	O
and	O
of	O
course	O
,	O
the	O
ubiquitous	O
calibration	B
pattern	O
(	O
figure	O
4.45	O
)	O
.	O
finding	O
the	O
vanishing	B
points	I
common	O
to	O
such	O
4.3	O
lines	B
255	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
4.45	O
real-world	O
vanishing	B
points	I
:	O
(	O
a	O
)	O
architecture	B
(	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
2008	O
)	O
,	O
(	O
b	O
)	O
furniture	O
(	O
miˇcuˇs`ık	O
,	O
wildenauer	O
,	O
and	O
koˇseck´a	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
,	O
and	O
(	O
c	O
)	O
cali-	O
bration	O
patterns	B
(	O
zhang	O
2000	O
)	O
.	O
line	O
sets	O
can	O
help	O
reﬁne	O
their	O
position	O
in	O
the	O
image	B
and	O
,	O
in	O
certain	O
cases	O
,	O
help	O
determine	O
the	O
intrinsic	B
and	O
extrinsic	B
orientation	O
of	O
the	O
camera	B
(	O
section	O
6.3.2	O
)	O
.	O
over	O
the	O
years	O
,	O
a	O
large	O
number	O
of	O
techniques	O
have	O
been	O
developed	O
for	O
ﬁnding	O
vanishing	B
points	I
,	O
including	O
(	O
quan	O
and	O
mohr	O
1989	O
;	O
collins	O
and	O
weiss	O
1990	O
;	O
brillaut-o	O
’	O
mahoney	O
1991	O
;	O
mclean	O
and	O
kotturi	O
1995	O
;	O
becker	O
and	O
bove	O
1995	O
;	O
shufelt	O
1999	O
;	O
tuytelaars	O
,	O
van	O
gool	O
,	O
and	O
proesmans	O
1997	O
;	O
schaffalitzky	O
and	O
zisserman	O
2000	O
;	O
antone	O
and	O
teller	O
2002	O
;	O
rother	O
2002	O
;	O
koˇseck´a	O
and	O
zhang	O
2005	O
;	O
pﬂugfelder	O
2008	O
;	O
tardif	O
2009	O
)	O
—see	O
some	O
of	O
the	O
more	O
recent	O
pa-	O
pers	O
for	O
additional	O
references	B
.	O
in	O
this	O
section	O
,	O
we	O
present	O
a	O
simple	O
hough	O
technique	O
based	O
on	O
having	O
line	O
pairs	O
vote	O
for	O
potential	O
vanishing	O
point	O
locations	O
,	O
followed	O
by	O
a	O
robust	B
least	O
squares	O
ﬁtting	O
stage	O
.	O
for	O
alternative	O
approaches	O
,	O
please	O
see	O
some	O
of	O
the	O
more	O
recent	O
papers	O
listed	O
above	O
.	O
the	O
ﬁrst	O
stage	O
in	O
my	O
vanishing	O
point	O
detection	B
algorithm	O
uses	O
a	O
hough	O
transform	B
to	O
accu-	O
mulate	O
votes	O
for	O
likely	O
vanishing	O
point	O
candidates	O
.	O
as	O
with	O
line	O
ﬁtting	O
,	O
one	O
possible	O
approach	O
is	O
to	O
have	O
each	O
line	O
vote	O
for	O
all	O
possible	O
vanishing	O
point	O
directions	O
,	O
either	O
using	O
a	O
cube	B
map	I
(	O
tuytelaars	O
,	O
van	O
gool	O
,	O
and	O
proesmans	O
1997	O
;	O
antone	O
and	O
teller	O
2002	O
)	O
or	O
a	O
gaussian	O
sphere	O
(	O
collins	O
and	O
weiss	O
1990	O
)	O
,	O
optionally	O
using	O
knowledge	O
about	O
the	O
uncertainty	B
in	O
the	O
vanish-	O
ing	O
point	O
location	O
to	O
perform	O
a	O
weighted	B
vote	O
(	O
collins	O
and	O
weiss	O
1990	O
;	O
brillaut-o	O
’	O
mahoney	O
1991	O
;	O
shufelt	O
1999	O
)	O
.	O
my	O
preferred	O
approach	O
is	O
to	O
use	O
pairs	B
of	O
detected	O
line	O
segments	O
to	O
form	O
candidate	O
vanishing	O
point	O
locations	O
.	O
let	O
ˆmi	O
and	O
ˆmj	O
be	O
the	O
(	O
unit	O
norm	O
)	O
line	O
equations	O
for	O
a	O
pair	O
of	O
line	O
segments	O
and	O
li	O
and	O
lj	O
be	O
their	O
corresponding	O
segment	O
lengths	O
.	O
the	O
location	O
of	O
the	O
corresponding	O
vanishing	O
point	O
hypothesis	O
can	O
be	O
computed	O
as	O
and	O
the	O
corresponding	O
weight	O
set	O
to	O
vij	O
=	O
ˆmi	O
×	O
ˆmj	O
wij	O
=	O
(	O
cid:107	O
)	O
vij	O
(	O
cid:107	O
)	O
lilj	O
.	O
(	O
4.28	O
)	O
(	O
4.29	O
)	O
256	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
4.46	O
triple	O
product	O
of	O
the	O
line	O
segments	O
endpoints	O
pi0	O
and	O
pi1	O
and	O
the	O
vanishing	O
point	O
v.	O
the	O
area	O
a	O
is	O
proportional	O
to	O
the	O
perpendicular	O
distance	O
d1	O
and	O
the	O
distance	O
between	O
the	O
other	O
endpoint	O
pi0	O
and	O
the	O
vanishing	O
point	O
.	O
this	O
has	O
the	O
desirable	O
effect	O
of	O
downweighting	O
(	O
near-	O
)	O
collinear	O
line	O
segments	O
and	O
short	O
line	O
segments	O
.	O
the	O
hough	O
space	O
itself	O
can	O
either	O
be	O
represented	O
using	O
spherical	O
coordinates	O
(	O
4.27	O
)	O
or	O
as	O
a	O
cube	B
map	I
(	O
figure	O
4.44a	O
)	O
.	O
once	O
the	O
hough	O
accumulator	O
space	O
has	O
been	O
populated	O
,	O
peaks	O
can	O
be	O
detected	O
in	O
a	O
manner	O
similar	O
to	O
that	O
previously	O
discussed	O
for	O
line	O
detection	B
.	O
given	O
a	O
set	O
of	O
candidate	O
line	O
segments	O
that	O
voted	O
for	O
a	O
vanishing	O
point	O
,	O
which	O
can	O
optionally	O
be	O
kept	O
as	O
a	O
list	O
at	O
each	O
hough	O
accu-	O
mulator	O
cell	O
,	O
i	O
then	O
use	O
a	O
robust	B
least	O
squares	O
ﬁt	O
to	O
estimate	O
a	O
more	O
accurate	O
location	O
for	O
each	O
vanishing	O
point	O
.	O
consider	O
the	O
relationship	O
between	O
the	O
two	O
line	O
segment	O
endpoints	O
{	O
pi0	O
,	O
pi1	O
}	O
and	O
the	O
van-	O
ishing	O
point	O
v	O
,	O
as	O
shown	O
in	O
figure	O
4.46.	O
the	O
area	O
a	O
of	O
the	O
triangle	O
given	O
by	O
these	O
three	O
points	B
,	O
which	O
is	O
the	O
magnitude	O
of	O
their	O
triple	O
product	O
ai	O
=	O
|	O
(	O
pi0	O
×	O
pi1	O
)	O
·	O
v|	O
,	O
(	O
4.30	O
)	O
is	O
proportional	O
to	O
the	O
perpendicular	O
distance	O
d1	O
between	O
each	O
endpoint	O
and	O
the	O
line	O
through	O
v	O
and	O
the	O
other	O
endpoint	O
,	O
as	O
well	O
as	O
the	O
distance	O
between	O
pi0	O
and	O
v.	O
assuming	O
that	O
the	O
accuracy	B
of	O
a	O
ﬁtted	O
line	O
segment	O
is	O
proportional	O
to	O
its	O
endpoint	O
accuracy	B
(	O
exercise	O
4.13	O
)	O
,	O
this	O
therefore	O
serves	O
as	O
an	O
optimal	O
metric	O
for	O
how	O
well	O
a	O
vanishing	O
point	O
ﬁts	O
a	O
set	O
of	O
extracted	O
lines	B
(	O
leibowitz	O
(	O
2001	O
,	O
section	O
3.6.1	O
)	O
and	O
pﬂugfelder	O
(	O
2008	O
,	O
section	O
2.1.1.3	O
)	O
)	O
.	O
a	O
robustiﬁed	O
least	B
squares	I
estimate	O
(	O
appendix	O
b.3	O
)	O
for	O
the	O
vanishing	O
point	O
can	O
therefore	O
be	O
written	O
as	O
wi	O
(	O
ai	O
)	O
mimt	O
i	O
(	O
cid:33	O
)	O
v	O
=	O
vt	O
m	O
v	O
,	O
(	O
4.31	O
)	O
e	O
=	O
(	O
cid:88	O
)	O
i	O
ρ	O
(	O
ai	O
)	O
=	O
vt	O
(	O
cid:32	O
)	O
(	O
cid:88	O
)	O
i	O
where	O
mi	O
=	O
pi0	O
×	O
pi1	O
is	O
the	O
segment	O
line	O
equation	O
weighted	B
by	O
its	O
length	O
li	O
,	O
and	O
wi	O
=	O
ρ	O
(	O
cid:48	O
)	O
(	O
ai	O
)	O
/ai	O
is	O
the	O
inﬂuence	O
of	O
each	O
robustiﬁed	O
(	O
reweighted	O
)	O
measurement	O
on	O
the	O
ﬁnal	O
error	O
(	O
appendix	O
b.3	O
)	O
.	O
notice	O
how	O
this	O
metric	O
is	O
closely	O
related	O
to	O
the	O
original	O
formula	O
for	O
the	O
pair-	O
wise	O
weighted	B
hough	O
transform	B
accumulation	O
step	O
.	O
the	O
ﬁnal	O
desired	O
value	O
for	O
v	O
is	O
computed	O
as	O
the	O
least	O
eigenvector	O
of	O
m.	O
pi1pi0vmi^d1a	O
4.4	O
additional	O
reading	O
257	O
while	O
the	O
technique	O
described	O
above	O
proceeds	O
in	O
two	O
discrete	O
stages	O
,	O
better	O
results	O
may	O
be	O
obtained	O
by	O
alternating	O
between	O
assigning	O
lines	B
to	O
vanishing	B
points	I
and	O
reﬁtting	O
the	O
van-	O
ishing	O
point	O
locations	O
(	O
antone	O
and	O
teller	O
2002	O
;	O
koˇseck´a	O
and	O
zhang	O
2005	O
;	O
pﬂugfelder	O
2008	O
)	O
.	O
the	O
results	O
of	O
detecting	O
individual	O
vanishing	B
points	I
can	O
also	O
be	O
made	O
more	O
robust	B
by	O
simulta-	O
neously	O
searching	O
for	O
pairs	O
or	O
triplets	O
of	O
mutually	O
orthogonal	O
vanishing	O
points	B
(	O
shufelt	O
1999	O
;	O
antone	O
and	O
teller	O
2002	O
;	O
rother	O
2002	O
;	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
2008	O
)	O
.	O
some	O
results	O
of	O
such	O
vanishing	O
point	O
detection	B
algorithms	O
can	O
be	O
seen	O
in	O
figure	O
4.45	O
.	O
4.3.4	O
application	O
:	O
rectangle	O
detection	B
once	O
sets	O
of	O
mutually	O
orthogonal	O
vanishing	O
points	B
have	O
been	O
detected	O
,	O
it	O
now	O
becomes	O
pos-	O
sible	O
to	O
search	O
for	O
3d	O
rectangular	O
structures	O
in	O
the	O
image	B
(	O
figure	O
4.47	O
)	O
.	O
over	O
the	O
last	O
decade	O
,	O
a	O
variety	O
of	O
techniques	O
have	O
been	O
developed	O
to	O
ﬁnd	O
such	O
rectangles	O
,	O
primarily	O
focused	O
on	O
architectural	O
scenes	O
(	O
koˇseck´a	O
and	O
zhang	O
2005	O
;	O
han	O
and	O
zhu	O
2005	O
;	O
shaw	O
and	O
barnes	O
2006	O
;	O
miˇcuˇs`ık	O
,	O
wildenauer	O
,	O
and	O
koˇseck´a	O
2008	O
;	O
schindler	O
,	O
krishnamurthy	O
,	O
lublinerman	O
et	O
al	O
.	O
2008	O
)	O
.	O
after	O
detecting	O
orthogonal	O
vanishing	O
directions	O
,	O
koˇseck´a	O
and	O
zhang	O
(	O
2005	O
)	O
reﬁne	O
the	O
ﬁtted	O
line	O
equations	O
,	O
search	O
for	O
corners	O
near	O
line	O
intersections	O
,	O
and	O
then	O
verify	O
rectangle	O
hy-	O
potheses	O
by	O
rectifying	O
the	O
corresponding	O
patches	O
and	O
looking	O
for	O
a	O
preponderance	O
of	O
hori-	O
zontal	O
and	O
vertical	O
edges	O
(	O
figures	O
4.47a–b	O
)	O
.	O
in	O
follow-on	O
work	O
,	O
miˇcuˇs`ık	O
,	O
wildenauer	O
,	O
and	O
koˇseck´a	O
(	O
2008	O
)	O
use	O
a	O
markov	O
random	O
ﬁeld	O
(	O
mrf	O
)	O
to	O
disambiguate	O
between	O
potentially	O
over-	O
lapping	O
rectangle	O
hypotheses	O
.	O
they	O
also	O
use	O
a	O
plane	B
sweep	I
algorithm	O
to	O
match	O
rectangles	O
between	O
different	O
views	O
(	O
figures	O
4.47d–f	O
)	O
.	O
a	O
different	O
approach	O
is	O
proposed	O
by	O
han	O
and	O
zhu	O
(	O
2005	O
)	O
,	O
who	O
use	O
a	O
grammar	O
of	O
potential	O
rectangle	O
shapes	O
and	O
nesting	O
structures	O
(	O
between	O
rectangles	O
and	O
vanishing	B
points	I
)	O
to	O
infer	O
the	O
most	O
likely	O
assignment	O
of	O
line	O
segments	O
to	O
rectangles	O
(	O
figure	O
4.47c	O
)	O
.	O
4.4	O
additional	O
reading	O
one	O
of	O
the	O
seminal	O
papers	O
on	O
feature	B
detection	O
,	O
description	O
,	O
and	O
matching	B
is	O
by	O
lowe	O
(	O
2004	O
)	O
.	O
comprehensive	O
surveys	B
and	O
evaluations	O
of	O
such	O
techniques	O
have	O
been	O
made	O
by	O
schmid	O
,	O
mohr	O
,	O
and	O
bauckhage	O
(	O
2000	O
)	O
;	O
mikolajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
;	O
mikolajczyk	O
,	O
tuytelaars	O
,	O
schmid	O
et	O
al	O
.	O
(	O
2005	O
)	O
;	O
tuytelaars	O
and	O
mikolajczyk	O
(	O
2007	O
)	O
while	O
shi	O
and	O
tomasi	O
(	O
1994	O
)	O
and	O
triggs	O
(	O
2004	O
)	O
also	O
provide	O
nice	O
reviews	O
.	O
in	O
the	O
area	O
of	O
feature	B
detectors	O
(	O
mikolajczyk	O
,	O
tuytelaars	O
,	O
schmid	O
et	O
al	O
.	O
2005	O
)	O
,	O
in	O
addition	O
to	O
such	O
classic	O
approaches	O
as	O
f¨orstner–harris	O
(	O
f¨orstner	O
1986	O
;	O
harris	O
and	O
stephens	O
1988	O
)	O
and	O
difference	B
of	O
gaussians	O
(	O
lindeberg	O
1993	O
,	O
1998b	O
;	O
lowe	O
2004	O
)	O
,	O
maximally	O
stable	O
extremal	O
re-	O
gions	O
(	O
msers	O
)	O
are	O
widely	O
used	O
for	O
applications	O
that	O
require	O
afﬁne	B
invariance	I
(	O
matas	O
,	O
chum	O
,	O
258	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
figure	O
4.47	O
rectangle	O
detection	B
:	O
(	O
a	O
)	O
indoor	O
corridor	O
and	O
(	O
b	O
)	O
building	O
exterior	O
with	O
grouped	O
facades	O
(	O
koˇseck´a	O
and	O
zhang	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
elsevier	O
;	O
(	O
c	O
)	O
grammar-based	O
recognition	B
(	O
han	O
and	O
zhu	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
;	O
(	O
d–f	O
)	O
rectangle	O
matching	B
using	O
a	O
plane	B
sweep	I
algorithm	O
(	O
miˇcuˇs`ık	O
,	O
wildenauer	O
,	O
and	O
koˇseck´a	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
.	O
urban	O
et	O
al	O
.	O
2004	O
;	O
nist´er	O
and	O
stew´enius	O
2008	O
)	O
.	O
more	O
recent	O
interest	O
point	O
detectors	O
are	O
discussed	O
by	O
xiao	O
and	O
shah	O
(	O
2003	O
)	O
;	O
koethe	O
(	O
2003	O
)	O
;	O
carneiro	O
and	O
jepson	O
(	O
2005	O
)	O
;	O
kenney	O
,	O
zuliani	O
,	O
and	O
manjunath	O
(	O
2005	O
)	O
;	O
bay	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
(	O
2006	O
)	O
;	O
platel	O
,	O
balmachnova	O
,	O
florack	O
et	O
al	O
.	O
(	O
2006	O
)	O
;	O
rosten	O
and	O
drummond	O
(	O
2006	O
)	O
,	O
as	O
well	O
as	O
techniques	O
based	O
on	O
line	O
matching	O
(	O
zoghlami	O
,	O
faugeras	O
,	O
and	O
deriche	O
1997	O
;	O
bartoli	O
,	O
coquerelle	O
,	O
and	O
sturm	O
2004	O
)	O
and	O
region	B
detection	O
(	O
kadir	O
,	O
zisserman	O
,	O
and	O
brady	O
2004	O
;	O
matas	O
,	O
chum	O
,	O
urban	O
et	O
al	O
.	O
2004	O
;	O
tuyte-	O
laars	O
and	O
van	O
gool	O
2004	O
;	O
corso	O
and	O
hager	O
2005	O
)	O
.	O
a	O
variety	O
of	O
local	O
feature	O
descriptors	O
(	O
and	O
matching	B
heuristics	O
)	O
are	O
surveyed	O
and	O
com-	O
pared	O
by	O
mikolajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
.	O
more	O
recent	O
publications	O
in	O
this	O
area	O
include	O
those	O
by	O
van	O
de	O
weijer	O
and	O
schmid	O
(	O
2006	O
)	O
;	O
abdel-hakim	O
and	O
farag	O
(	O
2006	O
)	O
;	O
winder	O
and	O
brown	O
(	O
2007	O
)	O
;	O
hua	O
,	O
brown	O
,	O
and	O
winder	O
(	O
2007	O
)	O
.	O
techniques	O
for	O
efﬁciently	O
matching	B
features	O
include	O
k-d	B
trees	I
(	O
beis	O
and	O
lowe	O
1999	O
;	O
lowe	O
2004	O
;	O
muja	O
and	O
lowe	O
2009	O
)	O
,	O
pyramid	B
match-	O
ing	O
kernels	O
(	O
grauman	O
and	O
darrell	O
2005	O
)	O
,	O
metric	O
(	O
vocabulary	O
)	O
trees	O
(	O
nist´er	O
and	O
stew´enius	O
2006	O
)	O
,	O
and	O
a	O
variety	O
of	O
multi-dimensional	O
hashing	B
techniques	O
(	O
shakhnarovich	O
,	O
viola	O
,	O
and	O
darrell	O
2003	O
;	O
torralba	O
,	O
weiss	O
,	O
and	O
fergus	O
2008	O
;	O
weiss	O
,	O
torralba	O
,	O
and	O
fergus	O
2008	O
;	O
kulis	O
and	O
4.5	O
exercises	O
259	O
grauman	O
2009	O
;	O
raginsky	O
and	O
lazebnik	O
2009	O
)	O
.	O
the	O
classic	O
reference	O
on	O
feature	B
detection	O
and	O
tracking	O
is	O
(	O
shi	O
and	O
tomasi	O
1994	O
)	O
.	O
more	O
recent	O
work	O
in	O
this	O
ﬁeld	O
has	O
focused	O
on	O
learning	B
better	O
matching	B
functions	O
for	O
speciﬁc	O
features	O
(	O
avidan	O
2001	O
;	O
jurie	O
and	O
dhome	O
2002	O
;	O
williams	O
,	O
blake	O
,	O
and	O
cipolla	O
2003	O
;	O
lepetit	O
and	O
fua	O
2005	O
;	O
lepetit	O
,	O
pilet	O
,	O
and	O
fua	O
2006	O
;	O
hinterstoisser	O
,	O
benhimane	O
,	O
navab	O
et	O
al	O
.	O
2008	O
;	O
rogez	O
,	O
rihan	O
,	O
ramalingam	O
et	O
al	O
.	O
2008	O
;	O
¨ozuysal	O
,	O
calonder	O
,	O
lepetit	O
et	O
al	O
.	O
2010	O
)	O
.	O
a	O
highly	O
cited	O
and	O
widely	O
used	O
edge	O
detector	O
is	O
the	O
one	O
developed	O
by	O
canny	O
(	O
1986	O
)	O
.	O
alternative	O
edge	O
detectors	O
as	O
well	O
as	O
experimental	O
comparisons	O
can	O
be	O
found	O
in	O
publica-	O
tions	O
by	O
nalwa	O
and	O
binford	O
(	O
1986	O
)	O
;	O
nalwa	O
(	O
1987	O
)	O
;	O
deriche	O
(	O
1987	O
)	O
;	O
freeman	O
and	O
adelson	O
(	O
1991	O
)	O
;	O
nalwa	O
(	O
1993	O
)	O
;	O
heath	O
,	O
sarkar	O
,	O
sanocki	O
et	O
al	O
.	O
(	O
1998	O
)	O
;	O
crane	O
(	O
1997	O
)	O
;	O
ritter	O
and	O
wilson	O
(	O
2000	O
)	O
;	O
bowyer	O
,	O
kranenburg	O
,	O
and	O
dougherty	O
(	O
2001	O
)	O
;	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
(	O
2010	O
)	O
.	O
the	O
topic	O
of	O
scale	B
selection	I
in	O
edge	O
detection	O
is	O
nicely	O
treated	O
by	O
elder	O
and	O
zucker	O
(	O
1998	O
)	O
,	O
while	O
approaches	O
to	O
color	B
and	O
texture	B
edge	O
detection	B
can	O
be	O
found	O
in	O
(	O
ruzon	O
and	O
tomasi	O
2001	O
;	O
martin	O
,	O
fowlkes	O
,	O
and	O
malik	O
2004	O
;	O
gevers	O
,	O
van	O
de	O
weijer	O
,	O
and	O
stokman	O
2006	O
)	O
.	O
edge	O
detectors	O
have	O
also	O
recently	O
been	O
combined	O
with	O
region	O
segmentation	B
techniques	O
to	O
further	O
improve	O
the	O
detection	B
of	O
semantically	O
salient	O
boundaries	O
(	O
maire	O
,	O
arbelaez	O
,	O
fowlkes	O
et	O
al	O
.	O
2008	O
;	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
2010	O
)	O
.	O
edges	O
linked	O
into	O
contours	O
can	O
be	O
smoothed	O
and	O
manipulated	O
for	O
artistic	O
effect	O
(	O
lowe	O
1989	O
;	O
finkelstein	O
and	O
salesin	O
1994	O
;	O
taubin	O
1995	O
)	O
and	O
used	O
for	B
recognition	I
(	O
belongie	O
,	O
malik	O
,	O
and	O
puzicha	O
2002	O
;	O
tek	O
and	O
kimia	O
2003	O
;	O
sebastian	O
and	O
kimia	O
2005	O
)	O
.	O
an	O
early	O
,	O
well-regarded	O
paper	O
on	O
straight	O
line	O
extraction	O
in	O
images	O
was	O
written	O
by	O
burns	O
,	O
hanson	O
,	O
and	O
riseman	O
(	O
1986	O
)	O
.	O
more	O
recent	O
techniques	O
often	O
combine	O
line	O
detection	O
with	O
van-	O
ishing	O
point	O
detection	O
(	O
quan	O
and	O
mohr	O
1989	O
;	O
collins	O
and	O
weiss	O
1990	O
;	O
brillaut-o	O
’	O
mahoney	O
1991	O
;	O
mclean	O
and	O
kotturi	O
1995	O
;	O
becker	O
and	O
bove	O
1995	O
;	O
shufelt	O
1999	O
;	O
tuytelaars	O
,	O
van	O
gool	O
,	O
and	O
proesmans	O
1997	O
;	O
schaffalitzky	O
and	O
zisserman	O
2000	O
;	O
antone	O
and	O
teller	O
2002	O
;	O
rother	O
2002	O
;	O
koˇseck´a	O
and	O
zhang	O
2005	O
;	O
pﬂugfelder	O
2008	O
;	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
2008	O
;	O
tardif	O
2009	O
)	O
.	O
4.5	O
exercises	O
ex	O
4.1	O
:	O
interest	O
point	O
detector	O
their	O
performance	O
(	O
with	O
your	O
own	O
or	O
with	O
a	O
classmate	O
’	O
s	O
detector	O
)	O
.	O
implement	O
one	O
or	O
more	O
keypoint	O
detectors	O
and	O
compare	O
possible	O
detectors	O
:	O
•	O
laplacian	O
or	O
difference	B
of	O
gaussian	O
;	O
•	O
f¨orstner–harris	O
hessian	O
(	O
try	O
different	O
formula	O
variants	O
given	O
in	O
(	O
4.9–4.11	O
)	O
)	O
;	O
260	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
•	O
oriented/steerable	O
ﬁlter	O
,	O
looking	O
for	O
either	O
second-order	O
high	O
second	O
response	O
or	O
two	O
edges	O
in	O
a	O
window	O
(	O
koethe	O
2003	O
)	O
,	O
as	O
discussed	O
in	O
section	O
4.1.1.	O
other	O
detectors	O
are	O
described	O
by	O
mikolajczyk	O
,	O
tuytelaars	O
,	O
schmid	O
et	O
al	O
.	O
(	O
2005	O
)	O
;	O
tuytelaars	O
and	O
mikolajczyk	O
(	O
2007	O
)	O
.	O
additional	O
optional	O
steps	O
could	O
include	O
:	O
1.	O
compute	O
the	O
detections	O
on	O
a	O
sub-octave	O
pyramid	B
and	O
ﬁnd	O
3d	O
maxima	O
.	O
2.	O
find	O
local	B
orientation	O
estimates	O
using	O
steerable	O
ﬁlter	O
responses	O
or	O
a	O
gradient	O
histogram-	O
ming	O
method	O
.	O
3.	O
implement	O
non-maximal	O
suppression	O
,	O
such	O
as	O
the	O
adaptive	B
technique	O
of	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
(	O
2005	O
)	O
.	O
4.	O
vary	O
the	O
window	O
shape	O
and	O
size	O
(	O
pre-ﬁlter	O
and	O
aggregation	O
)	O
.	O
to	O
test	O
for	O
repeatability	B
,	O
download	O
the	O
code	O
from	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/research/	O
afﬁne/	O
(	O
mikolajczyk	O
,	O
tuytelaars	O
,	O
schmid	O
et	O
al	O
.	O
2005	O
;	O
tuytelaars	O
and	O
mikolajczyk	O
2007	O
)	O
or	O
simply	O
rotate	O
or	O
shear	O
your	O
own	O
test	B
images	I
.	O
(	O
pick	O
a	O
domain	O
you	O
may	O
want	O
to	O
use	O
later	O
,	O
e.g.	O
,	O
for	O
outdoor	O
stitching	O
.	O
)	O
be	O
sure	O
to	O
measure	O
and	O
report	O
the	O
stability	O
of	O
your	O
scale	O
and	O
orientation	O
estimates	O
.	O
ex	O
4.2	O
:	O
interest	O
point	O
descriptor	O
implement	O
one	O
or	O
more	O
descriptors	O
(	O
steered	O
to	O
local	B
scale	O
and	O
orientation	O
)	O
and	O
compare	O
their	O
performance	O
(	O
with	O
your	O
own	O
or	O
with	O
a	O
classmate	O
’	O
s	O
detec-	O
tor	O
)	O
.	O
some	O
possible	O
descriptors	O
include	O
•	O
contrast-normalized	O
patches	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
;	O
•	O
sift	O
(	O
lowe	O
2004	O
)	O
;	O
•	O
gloh	O
(	O
mikolajczyk	O
and	O
schmid	O
2005	O
)	O
;	O
•	O
daisy	O
(	O
winder	O
and	O
brown	O
2007	O
;	O
tola	O
,	O
lepetit	O
,	O
and	O
fua	O
2010	O
)	O
.	O
other	O
detectors	O
are	O
described	O
by	O
mikolajczyk	O
and	O
schmid	O
(	O
2005	O
)	O
.	O
ex	O
4.3	O
:	O
roc	O
curve	O
computation	O
given	O
a	O
pair	O
of	O
curves	O
(	O
histograms	O
)	O
plotting	O
the	O
number	O
of	O
matching	B
and	O
non-matching	O
features	O
as	O
a	O
function	O
of	O
euclidean	O
distance	O
d	O
as	O
shown	O
in	O
figure	O
4.23b	O
,	O
derive	O
an	O
algorithm	B
for	O
plotting	O
a	O
roc	O
curve	O
(	O
figure	O
4.23a	O
)	O
.	O
in	O
particular	O
,	O
let	O
t	O
(	O
d	O
)	O
be	O
the	O
distribution	O
of	O
true	O
matches	O
and	O
f	O
(	O
d	O
)	O
be	O
the	O
distribution	O
of	O
(	O
false	O
)	O
non-matches	O
.	O
write	O
down	O
the	O
equations	B
for	O
the	O
roc	O
,	O
i.e.	O
,	O
tpr	O
(	O
fpr	O
)	O
,	O
and	O
the	O
auc	O
.	O
(	O
hint	O
:	O
plot	O
the	O
cumulative	O
distributions	O
t	O
(	O
d	O
)	O
=	O
(	O
cid:82	O
)	O
t	O
(	O
d	O
)	O
and	O
f	O
(	O
d	O
)	O
=	O
(	O
cid:82	O
)	O
f	O
(	O
d	O
)	O
and	O
see	O
if	O
these	O
help	O
you	O
derive	O
the	O
tpr	O
and	O
fpr	O
at	O
a	O
given	O
threshold	O
θ	O
.	O
)	O
4.5	O
exercises	O
261	O
ex	O
4.4	O
:	O
feature	B
matcher	O
after	O
extracting	O
features	O
from	O
a	O
collection	O
of	O
overlapping	O
or	O
dis-	O
torted	O
images,10	O
match	O
them	O
up	O
by	O
their	O
descriptors	O
either	O
using	O
nearest	O
neighbor	O
matching	B
or	O
a	O
more	O
efﬁcient	O
matching	B
strategy	O
such	O
as	O
a	O
k-d	O
tree	O
.	O
see	O
whether	O
you	O
can	O
improve	O
the	O
accuracy	B
of	O
your	O
matches	O
using	O
techniques	O
such	O
as	O
the	O
nearest	B
neighbor	I
distance	O
ratio	O
.	O
ex	O
4.5	O
:	O
feature	B
tracker	O
instead	O
of	O
ﬁnding	O
feature	B
points	O
independently	O
in	O
multiple	B
images	O
and	O
then	O
matching	B
them	O
,	O
ﬁnd	O
features	O
in	O
the	O
ﬁrst	O
image	B
of	O
a	O
video	B
or	O
image	B
sequence	O
and	O
then	O
re-locate	O
the	O
corresponding	O
points	B
in	O
the	O
next	O
frames	O
using	O
either	O
search	O
and	O
gradient	B
descent	I
(	O
shi	O
and	O
tomasi	O
1994	O
)	O
or	O
learned	B
feature	O
detectors	O
(	O
lepetit	O
,	O
pilet	O
,	O
and	O
fua	O
2006	O
;	O
fossati	O
,	O
dimitrijevic	O
,	O
lepetit	O
et	O
al	O
.	O
2007	O
)	O
.	O
when	O
the	O
number	O
of	O
tracked	O
points	B
drops	O
below	O
a	O
threshold	O
or	O
new	O
regions	O
in	O
the	O
image	B
become	O
visible	O
,	O
ﬁnd	O
additional	O
points	B
to	O
track	O
.	O
(	O
optional	O
)	O
winnow	O
out	O
incorrect	O
matches	O
by	O
estimating	O
a	O
homography	B
(	O
6.19–6.23	O
)	O
or	O
fundamental	O
matrix	O
(	O
section	O
7.2.1	O
)	O
.	O
(	O
optional	O
)	O
reﬁne	O
the	O
accuracy	B
of	O
your	O
matches	O
using	O
the	O
iterative	B
registration	O
algorithm	B
described	O
in	O
section	O
8.2	O
and	O
exercise	O
8.2.	O
ex	O
4.6	O
:	O
facial	B
feature	I
tracker	O
apply	O
your	O
feature	B
tracker	O
to	O
tracking	O
points	B
on	O
a	O
person	O
’	O
s	O
face	B
,	O
either	O
manually	O
initialized	O
to	O
interesting	O
locations	O
such	O
as	O
eye	O
corners	O
or	O
automatically	O
initialized	O
at	O
interest	O
points	B
.	O
(	O
optional	O
)	O
match	O
features	O
between	O
two	O
people	O
and	O
use	O
these	O
features	O
to	O
perform	O
image	B
morphing	O
(	O
exercise	O
3.25	O
)	O
.	O
ex	O
4.7	O
:	O
edge	O
detector	O
mance	O
to	O
that	O
of	O
your	O
classmates	O
’	O
detectors	O
or	O
code	O
downloaded	O
from	O
the	O
internet	O
.	O
implement	O
an	O
edge	O
detector	O
of	O
your	O
choice	O
.	O
compare	O
its	O
perfor-	O
a	O
simple	O
but	O
well-performing	O
sub-pixel	O
edge	O
detector	O
can	O
be	O
created	O
as	O
follows	O
:	O
1.	O
blur	O
the	O
input	O
image	B
a	O
little	O
,	O
bσ	O
(	O
x	O
)	O
=	O
gσ	O
(	O
x	O
)	O
∗	O
i	O
(	O
x	O
)	O
.	O
2.	O
construct	O
a	O
gaussian	O
pyramid	B
(	O
exercise	O
3.19	O
)	O
,	O
p	O
=	O
pyramid	B
{	O
bσ	O
(	O
x	O
)	O
}	O
3.	O
subtract	O
an	O
interpolated	O
coarser-level	O
pyramid	B
image	O
from	O
the	O
original	O
resolution	O
blurred	O
image	B
,	O
10	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/research/afﬁne/	O
.	O
s	O
(	O
x	O
)	O
=	O
bσ	O
(	O
x	O
)	O
−	O
p.interpolatedlevel	O
(	O
l	O
)	O
.	O
262	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
struct	O
sedgel	O
{	O
float	O
e	O
[	O
2	O
]	O
[	O
2	O
]	O
;	O
float	O
x	O
,	O
y	O
;	O
float	O
n_x	O
,	O
n_y	O
;	O
float	O
theta	O
;	O
float	O
length	O
;	O
float	O
strength	O
;	O
//	O
edgel	O
endpoints	O
(	O
zero	B
crossing	I
)	O
//	O
sub-pixel	O
edge	O
position	O
(	O
midpoint	O
)	O
//	O
orientation	O
,	O
as	O
normal	B
vector	I
//	O
orientation	O
,	O
as	O
angle	O
(	O
degrees	O
)	O
//	O
length	O
of	O
edgel	O
//	O
strength	O
of	O
edgel	O
(	O
gradient	O
magnitude	O
)	O
}	O
;	O
struct	O
sline	O
:	O
public	O
sedgel	O
{	O
float	O
line_length	O
;	O
//	O
length	O
of	O
line	O
(	O
est	O
.	O
from	O
ellipsoid	O
)	O
float	O
sigma	O
;	O
float	O
r	O
;	O
//	O
estimated	O
std	O
.	O
dev	O
.	O
of	O
edgel	O
noise	O
//	O
line	O
equation	O
:	O
x	O
*	O
n_y	O
-	O
y	O
*	O
n_x	O
=	O
r	O
}	O
;	O
figure	O
4.48	O
a	O
potential	O
c++	O
structure	O
for	O
edgel	O
and	O
line	O
elements	O
.	O
4.	O
for	O
each	O
quad	O
of	O
pixels	O
,	O
{	O
(	O
i	O
,	O
j	O
)	O
,	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
,	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
,	O
(	O
i	O
+	O
1	O
,	O
j	O
+	O
1	O
)	O
}	O
,	O
count	O
the	O
number	O
of	O
zero	O
crossings	O
along	O
the	O
four	O
edges	O
.	O
5.	O
when	O
there	O
are	O
exactly	O
two	O
zero	O
crossings	O
,	O
compute	O
their	O
locations	O
using	O
(	O
4.25	O
)	O
and	O
store	O
these	O
edgel	O
endpoints	O
along	O
with	O
the	O
midpoint	O
in	O
the	O
edgel	O
structure	O
(	O
figure	O
4.48	O
)	O
.	O
6.	O
for	O
each	O
edgel	O
,	O
compute	O
the	O
local	B
gradient	O
by	O
taking	O
the	O
horizontal	O
and	O
vertical	O
differ-	O
ences	O
between	O
the	O
values	O
of	O
s	O
along	O
the	O
zero	B
crossing	I
edges	O
.	O
7.	O
store	O
the	O
magnitude	O
of	O
this	O
gradient	O
as	O
the	O
edge	O
strength	O
and	O
either	O
its	O
orientation	O
or	O
that	O
of	O
the	O
segment	O
joining	O
the	O
edgel	O
endpoints	O
as	O
the	O
edge	O
orientation	O
.	O
8.	O
add	O
the	O
edgel	O
to	O
a	O
list	O
of	O
edgels	O
or	O
store	O
it	O
in	O
a	O
2d	O
array	O
of	O
edgels	O
(	O
addressed	O
by	O
pixel	O
coordinates	O
)	O
.	O
figure	O
4.48	O
shows	O
a	O
possible	O
representation	O
for	O
each	O
computed	O
edgel	O
.	O
ex	O
4.8	O
:	O
edge	O
linking	O
and	O
thresholding	B
link	O
up	O
the	O
edges	O
computed	O
in	O
the	O
previous	O
exer-	O
cise	O
into	O
chains	O
and	O
optionally	O
perform	O
thresholding	B
with	O
hysteresis	B
.	O
the	O
steps	O
may	O
include	O
:	O
1.	O
store	O
the	O
edgels	O
either	O
in	O
a	O
2d	O
array	O
(	O
say	O
,	O
an	O
integer	O
image	B
with	O
indices	O
into	O
the	O
edgel	O
list	O
)	O
or	O
pre-sort	O
the	O
edgel	O
list	O
ﬁrst	O
by	O
(	O
integer	O
)	O
x	O
coordinates	O
and	O
then	O
y	O
coordinates	O
,	O
for	O
faster	O
neighbor	O
ﬁnding	O
.	O
4.5	O
exercises	O
263	O
2.	O
pick	O
up	O
an	O
edgel	O
from	O
the	O
list	O
of	O
unlinked	O
edgels	O
and	O
ﬁnd	O
its	O
neighbors	O
in	O
both	O
direc-	O
tions	O
until	O
no	O
neighbor	O
is	O
found	O
or	O
a	O
closed	O
contour	O
is	O
obtained	O
.	O
flag	O
edgels	O
as	O
linked	O
as	O
you	O
visit	O
them	O
and	O
push	O
them	O
onto	O
your	O
list	O
of	O
linked	O
edgels	O
.	O
3.	O
alternatively	O
,	O
generalize	O
a	O
previously	O
developed	O
connected	O
component	O
algorithm	B
(	O
ex-	O
ercise	O
3.14	O
)	O
to	O
perform	O
the	O
linking	B
in	O
just	O
two	O
raster	O
passes	O
.	O
4	O
.	O
(	O
optional	O
)	O
perform	O
hysteresis-based	O
thresholding	B
(	O
canny	O
1986	O
)	O
.	O
use	O
two	O
thresholds	O
”	O
hi	O
”	O
and	O
”	O
lo	O
”	O
for	O
the	O
edge	O
strength	O
.	O
a	O
candidate	O
edgel	O
is	O
considered	O
an	O
edge	O
if	O
either	O
its	O
strength	O
is	O
above	O
the	O
”	O
hi	O
”	O
threshold	O
or	O
its	O
strength	O
is	O
above	O
the	O
”	O
lo	O
”	O
threshold	O
and	O
it	O
is	O
(	O
recursively	O
)	O
connected	O
to	O
a	O
previously	O
detected	O
edge	O
.	O
5	O
.	O
(	O
optional	O
)	O
link	O
together	O
contours	O
that	O
have	O
small	O
gaps	O
but	O
whose	O
endpoints	O
have	O
sim-	O
ilar	O
orientations	O
.	O
6	O
.	O
(	O
optional	O
)	O
find	O
junctions	O
between	O
adjacent	O
contours	O
,	O
e.g.	O
,	O
using	O
some	O
of	O
the	O
ideas	O
(	O
or	O
references	B
)	O
from	O
maire	O
,	O
arbelaez	O
,	O
fowlkes	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
ex	O
4.9	O
:	O
contour	O
matching	B
convert	O
a	O
closed	O
contour	O
(	O
linked	O
edgel	O
list	O
)	O
into	O
its	O
arc-length	O
parameterization	O
and	O
use	O
this	O
to	O
match	O
object	O
outlines	O
.	O
the	O
steps	O
may	O
include	O
:	O
1.	O
walk	O
along	O
the	O
contour	O
and	O
create	O
a	O
list	O
of	O
(	O
xi	O
,	O
yi	O
,	O
si	O
)	O
triplets	O
,	O
using	O
the	O
arc-length	O
formula	O
si+1	O
=	O
si	O
+	O
(	O
cid:107	O
)	O
xi+1	O
−	O
xi	O
(	O
cid:107	O
)	O
.	O
(	O
4.32	O
)	O
2.	O
resample	O
this	O
list	O
onto	O
a	O
regular	O
set	O
of	O
(	O
xj	O
,	O
yj	O
,	O
j	O
)	O
samples	O
using	O
linear	O
interpolation	B
of	O
each	O
segment	O
.	O
3.	O
compute	O
the	O
average	O
values	O
of	O
x	O
and	O
y	O
,	O
i.e.	O
,	O
x	O
and	O
y	O
and	O
subtract	O
them	O
from	O
your	O
sampled	O
curve	O
points	B
.	O
4.	O
resample	O
the	O
original	O
(	O
xi	O
,	O
yi	O
,	O
si	O
)	O
piecewise-linear	O
function	O
onto	O
a	O
length-independent	O
set	O
of	O
samples	O
,	O
say	O
j	O
∈	O
[	O
0	O
,	O
1023	O
]	O
.	O
(	O
using	O
a	O
length	O
which	O
is	O
a	O
power	O
of	O
two	O
makes	O
subsequent	O
fourier	O
transforms	O
more	O
convenient	O
.	O
)	O
5.	O
compute	O
the	O
fourier	O
transform	B
of	O
the	O
curve	O
,	O
treating	O
each	O
(	O
x	O
,	O
y	O
)	O
pair	O
as	O
a	O
complex	O
number	O
.	O
6.	O
to	O
compare	O
two	O
curves	O
,	O
ﬁt	O
a	O
linear	B
equation	O
to	O
the	O
phase	O
difference	O
between	O
the	O
two	O
curves	O
.	O
(	O
careful	O
:	O
phase	O
wraps	O
around	O
at	O
360◦	O
.	O
also	O
,	O
you	O
may	O
wish	O
to	O
weight	O
samples	O
by	O
their	O
fourier	O
spectrum	O
magnitude—see	O
section	O
8.1.2	O
.	O
)	O
264	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
7	O
.	O
(	O
optional	O
)	O
prove	O
that	O
the	O
constant	O
phase	O
component	O
corresponds	O
to	O
the	O
temporal	O
shift	O
in	O
s	O
,	O
while	O
the	O
linear	B
component	O
corresponds	O
to	O
rotation	O
.	O
of	O
course	O
,	O
feel	O
free	O
to	O
try	O
any	O
other	O
curve	O
descriptor	O
and	O
matching	B
technique	O
from	O
the	O
com-	O
puter	O
vision	O
literature	O
(	O
tek	O
and	O
kimia	O
2003	O
;	O
sebastian	O
and	O
kimia	O
2005	O
)	O
.	O
ex	O
4.10	O
:	O
jigsaw	O
puzzle	O
solver—challenging	O
write	O
a	O
program	O
to	O
automatically	O
solve	O
a	O
jig-	O
saw	O
puzzle	O
from	O
a	O
set	O
of	O
scanned	O
puzzle	O
pieces	O
.	O
your	O
software	O
may	O
include	O
the	O
following	O
components	O
:	O
1.	O
scan	O
the	O
pieces	O
(	O
either	O
face	B
up	O
or	O
face	B
down	O
)	O
on	O
a	O
ﬂatbed	O
scanner	O
with	O
a	O
distinctively	O
colored	O
background	O
.	O
2	O
.	O
(	O
optional	O
)	O
scan	O
in	O
the	O
box	O
top	O
to	O
use	O
as	O
a	O
low-resolution	O
reference	O
image	B
.	O
3.	O
use	O
color-based	O
thresholding	B
to	O
isolate	O
the	O
pieces	O
.	O
4.	O
extract	O
the	O
contour	O
of	O
each	O
piece	O
using	O
edge	O
ﬁnding	O
and	O
linking	B
.	O
5	O
.	O
(	O
optional	O
)	O
re-represent	O
each	O
contour	O
using	O
an	O
arc-length	O
or	O
some	O
other	O
re-parameterization	O
.	O
break	O
up	O
the	O
contours	O
into	O
meaningful	O
matchable	O
pieces	O
.	O
(	O
is	O
this	O
hard	O
?	O
)	O
6	O
.	O
(	O
optional	O
)	O
associate	O
color	B
values	O
with	O
each	O
contour	O
to	O
help	O
in	O
the	O
matching	B
.	O
7	O
.	O
(	O
optional	O
)	O
match	O
pieces	O
to	O
the	O
reference	O
image	B
using	O
some	O
rotationally	O
invariant	O
fea-	O
ture	O
descriptors	O
.	O
8.	O
solve	O
a	O
global	B
optimization	I
or	O
(	O
backtracking	O
)	O
search	O
problem	O
to	O
snap	O
pieces	O
together	O
and	O
place	O
them	O
in	O
the	O
correct	O
location	O
relative	O
to	O
the	O
reference	O
image	B
.	O
9.	O
test	O
your	O
algorithm	B
on	O
a	O
succession	O
of	O
more	O
difﬁcult	O
puzzles	O
and	O
compare	O
your	O
results	O
with	O
those	O
of	O
others	O
.	O
ex	O
4.11	O
:	O
successive	B
approximation	I
line	O
detector	O
(	O
section	O
4.3.1	O
)	O
(	O
ramer	O
1972	O
;	O
douglas	O
and	O
peucker	O
1973	O
)	O
to	O
convert	O
a	O
hand-drawn	O
curve	O
(	O
or	O
linked	O
edge	O
image	O
)	O
into	O
a	O
small	O
set	O
of	O
polylines	O
.	O
implement	O
a	O
line	O
simpliﬁcation	O
algorithm	B
(	O
optional	O
)	O
re-render	O
this	O
curve	O
using	O
either	O
an	O
approximating	O
or	O
interpolating	O
spline	B
or	O
bezier	O
curve	O
(	O
szeliski	O
and	O
ito	O
1986	O
;	O
bartels	O
,	O
beatty	O
,	O
and	O
barsky	O
1987	O
;	O
farin	O
1996	O
)	O
.	O
ex	O
4.12	O
:	O
hough	O
transform	B
line	O
detector	O
in	O
images	O
:	O
implement	O
a	O
hough	O
transform	B
for	O
ﬁnding	O
lines	B
4.5	O
exercises	O
265	O
1.	O
create	O
an	O
accumulator	O
array	O
of	O
the	O
appropriate	O
user-speciﬁed	O
size	O
and	O
clear	O
it	O
.	O
the	O
user	O
can	O
specify	O
the	O
spacing	O
in	O
degrees	O
between	O
orientation	O
bins	O
and	O
in	O
pixels	O
between	O
dis-	O
tance	O
bins	O
.	O
the	O
array	O
can	O
be	O
allocated	O
as	O
integer	O
(	O
for	O
simple	O
counts	O
)	O
,	O
ﬂoating	O
point	O
(	O
for	O
weighted	O
counts	O
)	O
,	O
or	O
as	O
an	O
array	O
of	O
vectors	O
for	O
keeping	O
back	O
pointers	O
to	O
the	O
constituent	O
edges	O
.	O
2.	O
for	O
each	O
detected	O
edgel	O
at	O
location	O
(	O
x	O
,	O
y	O
)	O
and	O
orientation	O
θ	O
=	O
tan−1	O
ny/nx	O
,	O
compute	O
the	O
value	O
of	O
d	O
=	O
xnx	O
+	O
yny	O
(	O
4.33	O
)	O
and	O
increment	O
the	O
accumulator	O
corresponding	O
to	O
(	O
θ	O
,	O
d	O
)	O
.	O
(	O
optional	O
)	O
weight	O
the	O
vote	O
of	O
each	O
edge	O
by	O
its	O
length	O
(	O
see	O
exercise	O
4.7	O
)	O
or	O
the	O
strength	O
of	O
its	O
gradient	O
.	O
3	O
.	O
(	O
optional	O
)	O
smooth	O
the	O
scalar	O
accumulator	O
array	O
by	O
adding	O
in	O
values	O
from	O
its	O
immediate	O
neighbors	O
.	O
this	O
can	O
help	O
counteract	O
the	O
discretization	O
effect	O
of	O
voting	O
for	O
only	O
a	O
single	O
bin—see	O
exercise	O
3.7	O
.	O
4.	O
find	O
the	O
largest	O
peaks	O
(	O
local	B
maxima	O
)	O
in	O
the	O
accumulator	O
corresponding	O
to	O
lines	B
.	O
5	O
.	O
(	O
optional	O
)	O
for	O
each	O
peak	O
,	O
re-ﬁt	O
the	O
lines	B
to	O
the	O
constituent	O
edgels	O
,	O
using	O
total	O
least	B
squares	I
(	O
appendix	O
a.2	O
)	O
.	O
use	O
the	O
original	O
edgel	O
lengths	O
or	O
strength	O
weights	O
to	O
weight	O
the	O
least	B
squares	I
ﬁt	O
,	O
as	O
well	O
as	O
the	O
agreement	O
between	O
the	O
hypothesized	O
line	O
orienta-	O
tion	B
and	O
the	O
edgel	O
orientation	O
.	O
determine	O
whether	O
these	O
heuristics	O
help	O
increase	O
the	O
accuracy	B
of	O
the	O
ﬁt	O
.	O
6.	O
after	O
ﬁtting	O
each	O
peak	O
,	O
zero-out	O
or	O
eliminate	O
that	O
peak	O
and	O
its	O
adjacent	O
bins	O
in	O
the	O
array	O
,	O
and	O
move	O
on	O
to	O
the	O
next	O
largest	O
peak	O
.	O
test	O
out	O
your	O
hough	O
transform	B
on	O
a	O
variety	O
of	O
images	O
taken	O
indoors	O
and	O
outdoors	O
,	O
as	O
well	O
as	O
checkerboard	O
calibration	B
patterns	O
.	O
for	O
checkerboard	O
patterns	B
,	O
you	O
can	O
modify	O
your	O
hough	O
transform	B
by	O
collapsing	O
antipodal	B
bins	O
(	O
θ	O
±	O
180◦	O
,	O
−d	O
)	O
with	O
(	O
θ	O
,	O
d	O
)	O
to	O
ﬁnd	O
lines	B
that	O
do	O
not	O
care	O
about	O
polarity	O
changes	O
.	O
can	O
you	O
think	O
of	O
examples	B
in	O
real-world	O
images	O
where	O
this	O
might	O
be	O
desirable	O
as	O
well	O
?	O
ex	O
4.13	O
:	O
line	O
ﬁtting	O
uncertainty	B
estimate	O
the	O
uncertainty	B
(	O
covariance	O
)	O
in	O
your	O
line	O
ﬁt	O
us-	O
ing	O
uncertainty	B
analysis	O
.	O
1.	O
after	O
determining	O
which	O
edgels	O
belong	O
to	O
the	O
line	O
segment	O
(	O
using	O
either	O
successive	B
approximation	I
or	O
hough	O
transform	B
)	O
,	O
re-ﬁt	O
the	O
line	O
segment	O
using	O
total	O
least	B
squares	I
(	O
van	O
huffel	O
and	O
vandewalle	O
1991	O
;	O
van	O
huffel	O
and	O
lemmerling	O
2002	O
)	O
,	O
i.e.	O
,	O
ﬁnd	O
the	O
mean	O
or	O
centroid	O
of	O
the	O
edgels	O
and	O
then	O
use	O
eigenvalue	O
analysis	O
to	O
ﬁnd	O
the	O
dominant	O
orientation	O
.	O
266	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
2.	O
compute	O
the	O
perpendicular	O
errors	O
(	O
deviations	O
)	O
to	O
the	O
line	O
and	O
robustly	O
estimate	O
the	O
variance	O
of	O
the	O
ﬁtting	O
noise	B
using	O
an	O
estimator	O
such	O
as	O
mad	O
(	O
appendix	O
b.3	O
)	O
.	O
3	O
.	O
(	O
optional	O
)	O
re-ﬁt	O
the	O
line	O
parameters	O
by	O
throwing	O
away	O
outliers	O
or	O
using	O
a	O
robust	B
norm	O
or	O
inﬂuence	O
function	O
.	O
4.	O
estimate	O
the	O
error	O
in	O
the	O
perpendicular	O
location	O
of	O
the	O
line	O
segment	O
and	O
its	O
orientation	O
.	O
ex	O
4.14	O
:	O
vanishing	B
points	I
compute	O
the	O
vanishing	B
points	I
in	O
an	O
image	B
using	O
one	O
of	O
the	O
tech-	O
niques	O
described	O
in	O
section	O
4.3.3	O
and	O
optionally	O
reﬁne	O
the	O
original	O
line	O
equations	O
associated	O
with	O
each	O
vanishing	O
point	O
.	O
your	O
results	O
can	O
be	O
used	O
later	O
to	O
track	O
a	O
target	O
(	O
exercise	O
6.5	O
)	O
or	O
reconstruct	O
architecture	B
(	O
section	O
12.6.1	O
)	O
.	O
ex	O
4.15	O
:	O
vanishing	O
point	O
uncertainty	B
perform	O
an	O
uncertainty	B
analysis	O
on	O
your	O
estimated	O
vanishing	B
points	I
.	O
you	O
will	O
need	O
to	O
decide	O
how	O
to	O
represent	O
your	O
vanishing	O
point	O
,	O
e.g.	O
,	O
homo-	O
geneous	O
coordinates	O
on	O
a	O
sphere	O
,	O
to	O
handle	O
vanishing	B
points	I
near	O
inﬁnity	O
.	O
see	O
the	O
discussion	O
of	O
bingham	O
distributions	O
by	O
collins	O
and	O
weiss	O
(	O
1990	O
)	O
for	O
some	O
ideas	O
.	O
chapter	O
5	O
segmentation	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5.2	O
split	O
and	O
merge	O
.	O
5.1	O
active	B
contours	I
.	O
.	O
snakes	B
scissors	O
.	O
.	O
.	O
.	O
5.1.1	O
.	O
.	O
5.1.2	O
dynamic	B
snakes	O
and	O
condensation	O
.	O
.	O
.	O
5.1.3	O
.	O
5.1.4	O
level	B
sets	I
.	O
.	O
.	O
5.1.5	O
application	O
:	O
contour	O
tracking	O
and	O
rotoscoping	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5.2.1	O
watershed	B
.	O
.	O
5.2.2	O
region	B
splitting	O
(	O
divisive	B
clustering	O
)	O
.	O
.	O
5.2.3	O
region	B
merging	O
(	O
agglomerative	B
clustering	O
)	O
5.2.4	O
graph-based	B
segmentation	O
.	O
.	O
.	O
.	O
5.2.5	O
.	O
.	O
.	O
.	O
.	O
.	O
probabilistic	B
aggregation	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5.3	O
mean	B
shift	I
and	O
mode	O
ﬁnding	O
.	O
.	O
.	O
.	O
5.3.1	O
k-means	B
and	O
mixtures	O
of	O
gaussians	O
.	O
.	O
5.3.2	O
mean	B
shift	I
.	O
.	O
5.4	O
normalized	B
cuts	I
.	O
.	O
5.5	O
graph	B
cuts	I
and	O
energy-based	B
methods	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5.5.1	O
application	O
:	O
medical	B
image	I
segmentation	O
.	O
.	O
.	O
5.6	O
additional	O
reading	O
.	O
5.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
270	O
.	O
270	O
.	O
276	O
.	O
280	O
.	O
281	O
.	O
282	O
.	O
284	O
.	O
284	O
.	O
286	O
.	O
286	O
.	O
286	O
.	O
288	O
.	O
289	O
.	O
289	O
.	O
292	O
.	O
296	O
.	O
300	O
.	O
304	O
.	O
305	O
.	O
306	O
268	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
e	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
(	O
f	O
)	O
figure	O
5.1	O
some	O
popular	O
image	B
segmentation	O
techniques	O
:	O
(	O
a	O
)	O
active	B
contours	I
(	O
isard	O
and	O
blake	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
springer	O
;	O
(	O
b	O
)	O
level	B
sets	I
(	O
cremers	O
,	O
rousson	O
,	O
and	O
deriche	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
springer	O
;	O
(	O
c	O
)	O
graph-based	B
merging	O
(	O
felzenszwalb	O
and	O
huttenlocher	O
2004b	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
;	O
(	O
d	O
)	O
mean	B
shift	I
(	O
comaniciu	O
and	O
meer	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
ieee	O
;	O
(	O
e	O
)	O
texture	B
and	O
interven-	O
ing	O
contour-based	B
normalized	O
cuts	O
(	O
malik	O
,	O
belongie	O
,	O
leung	O
et	O
al	O
.	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
springer	O
;	O
(	O
f	O
)	O
binary	O
mrf	O
solved	O
using	O
graph	O
cuts	O
(	O
boykov	O
and	O
funka-lea	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
.	O
5	O
segmentation	B
269	O
image	B
segmentation	O
is	O
the	O
task	O
of	O
ﬁnding	O
groups	O
of	O
pixels	O
that	O
“	O
go	O
together	O
”	O
.	O
in	O
statistics	O
,	O
this	O
problem	O
is	O
known	O
as	O
cluster	B
analysis	I
and	O
is	O
a	O
widely	O
studied	O
area	O
with	O
hundreds	O
of	O
different	O
algorithms	O
(	O
jain	O
and	O
dubes	O
1988	O
;	O
kaufman	O
and	O
rousseeuw	O
1990	O
;	O
jain	O
,	O
duin	O
,	O
and	O
mao	O
2000	O
;	O
jain	O
,	O
topchy	O
,	O
law	O
et	O
al	O
.	O
2004	O
)	O
.	O
in	O
computer	O
vision	O
,	O
image	B
segmentation	O
is	O
one	O
of	O
the	O
oldest	O
and	O
most	O
widely	O
studied	O
prob-	O
lems	O
(	O
brice	O
and	O
fennema	O
1970	O
;	O
pavlidis	O
1977	O
;	O
riseman	O
and	O
arbib	O
1977	O
;	O
ohlander	O
,	O
price	O
,	O
and	O
reddy	O
1978	O
;	O
rosenfeld	O
and	O
davis	O
1979	O
;	O
haralick	O
and	O
shapiro	O
1985	O
)	O
.	O
early	O
techniques	O
tend	O
to	O
use	O
region	B
splitting	O
or	O
merging	B
(	O
brice	O
and	O
fennema	O
1970	O
;	O
horowitz	O
and	O
pavlidis	O
1976	O
;	O
ohlander	O
,	O
price	O
,	O
and	O
reddy	O
1978	O
;	O
pavlidis	O
and	O
liow	O
1990	O
)	O
,	O
which	O
correspond	O
to	O
divisive	B
and	O
agglomerative	B
algorithms	O
in	O
the	O
clustering	O
literature	O
(	O
jain	O
,	O
topchy	O
,	O
law	O
et	O
al	O
.	O
2004	O
)	O
.	O
more	O
recent	O
algorithms	O
often	O
optimize	O
some	O
global	B
criterion	O
,	O
such	O
as	O
intra-region	O
consistency	O
and	O
inter-region	O
boundary	O
lengths	O
or	O
dissimilarity	O
(	O
leclerc	O
1989	O
;	O
mumford	O
and	O
shah	O
1989	O
;	O
shi	O
and	O
malik	O
2000	O
;	O
comaniciu	O
and	O
meer	O
2002	O
;	O
felzenszwalb	O
and	O
huttenlocher	O
2004b	O
;	O
cremers	O
,	O
rousson	O
,	O
and	O
deriche	O
2007	O
)	O
.	O
we	O
have	O
already	O
seen	O
examples	B
of	O
image	B
segmentation	O
in	O
sections	O
3.3.2	O
and	O
3.7.2.	O
in	O
this	O
chapter	O
,	O
we	O
review	O
some	O
additional	O
techniques	O
that	O
have	O
been	O
developed	O
for	O
image	O
seg-	O
mentation	O
.	O
these	O
include	O
algorithms	O
based	O
on	O
active	B
contours	I
(	O
section	O
5.1	O
)	O
and	O
level	B
sets	I
(	O
section	O
5.1.4	O
)	O
,	O
region	B
splitting	O
and	O
merging	B
(	O
section	O
5.2	O
)	O
,	O
mean	B
shift	I
(	O
mode	O
ﬁnding	O
)	O
(	O
sec-	O
tion	B
5.3	O
)	O
,	O
normalized	B
cuts	I
(	O
splitting	B
based	O
on	O
pixel	O
similarity	O
metrics	O
)	O
(	O
section	O
5.4	O
)	O
,	O
and	O
bi-	O
nary	O
markov	O
random	O
ﬁelds	O
solved	O
using	O
graph	O
cuts	O
(	O
section	O
5.5	O
)	O
.	O
figure	O
5.1	O
shows	O
some	O
examples	B
of	O
these	O
techniques	O
applied	O
to	O
different	O
images	O
.	O
since	O
the	O
literature	O
on	O
image	B
segmentation	O
is	O
so	O
vast	O
,	O
a	O
good	O
way	O
to	O
get	O
a	O
handle	O
on	O
some	O
of	O
the	O
better	O
performing	O
algorithms	O
is	O
to	O
look	O
at	O
experimental	O
comparisons	O
on	O
human-labeled	O
databases	O
(	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
2010	O
)	O
.	O
the	O
best	O
known	O
of	O
these	O
is	O
the	O
berkeley	O
segmentation	B
dataset	O
and	O
benchmark1	O
(	O
martin	O
,	O
fowlkes	O
,	O
tal	O
et	O
al	O
.	O
2001	O
)	O
,	O
which	O
consists	O
of	O
1000	O
images	O
from	O
a	O
corel	O
image	B
dataset	O
that	O
were	O
hand-labeled	O
by	O
30	O
human	O
subjects	O
.	O
many	O
of	O
the	O
more	O
recent	O
image	B
segmentation	O
algorithms	O
report	O
comparative	O
results	O
on	O
this	O
database	O
.	O
for	O
example	O
,	O
unnikrishnan	O
,	O
pantofaru	O
,	O
and	O
hebert	O
(	O
2007	O
)	O
propose	O
new	O
metrics	O
for	O
comparing	O
such	O
algorithms	O
.	O
estrada	O
and	O
jepson	O
(	O
2009	O
)	O
compare	O
four	O
well-known	O
seg-	O
mentation	O
algorithms	O
on	O
the	O
berkeley	O
data	O
set	O
and	O
conclude	O
that	O
while	O
their	O
own	O
se-mincut	O
algorithm	B
(	O
estrada	O
,	O
jepson	O
,	O
and	O
chennubhotla	O
2004	O
)	O
algorithm	B
outperforms	O
the	O
others	O
by	O
a	O
small	O
margin	O
,	O
there	O
still	O
exists	O
a	O
wide	O
gap	O
between	O
automated	B
and	O
human	O
segmentation	O
per-	O
formance.2	O
a	O
new	O
database	O
of	O
foreground	O
and	O
background	O
segmentations	O
,	O
used	O
by	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
(	O
2007	O
)	O
,	O
is	O
also	O
available.3	O
1	O
http	O
:	O
//www.eecs.berkeley.edu/research/projects/cs/vision/grouping/segbench/	O
2	O
an	O
interesting	O
observation	O
about	O
their	O
roc	O
plots	O
is	O
that	O
automated	B
techniques	O
cluster	O
tightly	O
along	O
similar	O
curves	O
,	O
but	O
human	O
performance	O
is	O
all	O
over	O
the	O
map	O
.	O
3	O
http	O
:	O
//www.wisdom.weizmann.ac.il/∼vision/seg	O
evaluation	B
db/index.html	O
270	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
5.1	O
active	B
contours	I
while	O
lines	B
,	O
vanishing	B
points	I
,	O
and	O
rectangles	O
are	O
commonplace	O
in	O
the	O
man-made	O
world	O
,	O
curves	O
corresponding	O
to	O
object	O
boundaries	O
are	O
even	O
more	O
common	O
,	O
especially	O
in	O
the	O
natural	B
environment	O
.	O
in	O
this	O
section	O
,	O
we	O
describe	O
three	O
related	O
approaches	O
to	O
locating	O
such	O
boundary	O
curves	O
in	O
images	O
.	O
the	O
ﬁrst	O
,	O
originally	O
called	O
snakes	B
by	O
its	O
inventors	O
(	O
kass	O
,	O
witkin	O
,	O
and	O
terzopoulos	O
1988	O
)	O
(	O
section	O
5.1.1	O
)	O
,	O
is	O
an	O
energy-minimizing	O
,	O
two-dimensional	B
spline	O
curve	O
that	O
evolves	O
(	O
moves	O
)	O
towards	O
image	B
features	O
such	O
as	O
strong	O
edges	O
.	O
the	O
second	O
,	O
intelligent	B
scissors	I
(	O
mortensen	O
and	O
barrett	O
1995	O
)	O
(	O
section	O
5.1.3	O
)	O
,	O
allow	O
the	O
user	O
to	O
sketch	O
in	O
real	O
time	O
a	O
curve	O
that	O
clings	O
to	O
object	O
boundaries	O
.	O
finally	O
,	O
level	O
set	O
techniques	O
(	O
section	O
5.1.4	O
)	O
evolve	O
the	O
curve	O
as	O
the	O
zero-	O
set	O
of	O
a	O
characteristic	O
function	O
,	O
which	O
allows	O
them	O
to	O
easily	O
change	O
topology	O
and	O
incorporate	O
region-based	B
statistics	O
.	O
all	O
three	O
of	O
these	O
are	O
examples	B
of	O
active	B
contours	I
(	O
blake	O
and	O
isard	O
1998	O
;	O
mortensen	O
1999	O
)	O
,	O
since	O
these	O
boundary	O
detectors	O
iteratively	O
move	O
towards	O
their	O
ﬁnal	O
solution	O
under	O
the	O
combination	O
of	O
image	B
and	O
optional	O
user-guidance	O
forces	O
.	O
5.1.1	O
snakes	B
snakes	O
are	O
a	O
two-dimensional	B
generalization	O
of	O
the	O
1d	O
energy-minimizing	O
splines	B
ﬁrst	O
intro-	O
duced	O
in	O
section	O
3.7.1	O
,	O
eint	O
=	O
(	O
cid:90	O
)	O
α	O
(	O
s	O
)	O
(	O
cid:107	O
)	O
f	O
s	O
(	O
s	O
)	O
(	O
cid:107	O
)	O
2	O
+	O
β	O
(	O
s	O
)	O
(	O
cid:107	O
)	O
f	O
ss	O
(	O
s	O
)	O
(	O
cid:107	O
)	O
2	O
ds	O
,	O
(	O
5.1	O
)	O
where	O
s	O
is	O
the	O
arc-length	O
along	O
the	O
curve	O
f	O
(	O
s	O
)	O
=	O
(	O
x	O
(	O
s	O
)	O
,	O
y	O
(	O
s	O
)	O
)	O
and	O
α	O
(	O
s	O
)	O
and	O
β	O
(	O
s	O
)	O
are	O
ﬁrst-	O
and	O
second-order	O
continuity	O
weighting	B
functions	O
analogous	O
to	O
the	O
s	O
(	O
x	O
,	O
y	O
)	O
and	O
c	O
(	O
x	O
,	O
y	O
)	O
terms	O
introduced	O
in	O
(	O
3.100–3.101	O
)	O
.	O
we	O
can	O
discretize	O
this	O
energy	O
by	O
sampling	O
the	O
initial	O
curve	O
position	O
evenly	O
along	O
its	O
length	O
(	O
figure	O
4.35	O
)	O
to	O
obtain	O
eint	O
=	O
(	O
cid:88	O
)	O
i	O
α	O
(	O
i	O
)	O
(	O
cid:107	O
)	O
f	O
(	O
i	O
+	O
1	O
)	O
−	O
f	O
(	O
i	O
)	O
(	O
cid:107	O
)	O
2/h2	O
(	O
5.2	O
)	O
+	O
β	O
(	O
i	O
)	O
(	O
cid:107	O
)	O
f	O
(	O
i	O
+	O
1	O
)	O
−	O
2f	O
(	O
i	O
)	O
+	O
f	O
(	O
i	O
−	O
1	O
)	O
(	O
cid:107	O
)	O
2/h4	O
,	O
where	O
h	O
is	O
the	O
step	O
size	O
,	O
which	O
can	O
be	O
neglected	O
if	O
we	O
resample	O
the	O
curve	O
along	O
its	O
arc-length	O
after	O
each	O
iteration	O
.	O
in	O
addition	O
to	O
this	O
internal	O
spline	O
energy	O
,	O
a	O
snake	O
simultaneously	O
minimizes	O
external	O
image-based	B
and	O
constraint-based	O
potentials	O
.	O
the	O
image-based	B
potentials	O
are	O
the	O
sum	O
of	O
sev-	O
eral	O
terms	O
eimage	O
=	O
wlineeline	O
+	O
wedgeeedge	O
+	O
wtermeterm	O
,	O
(	O
5.3	O
)	O
5.1	O
active	B
contours	I
271	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
5.2	O
snakes	B
(	O
kass	O
,	O
witkin	O
,	O
and	O
terzopoulos	O
1988	O
)	O
c	O
(	O
cid:13	O
)	O
1988	O
springer	O
:	O
(	O
a	O
)	O
the	O
“	O
snake	O
pit	O
”	O
for	O
interactively	O
controlling	O
shape	O
;	O
(	O
b	O
)	O
lip	O
tracking	O
.	O
where	O
the	O
line	O
term	O
attracts	O
the	O
snake	O
to	O
dark	O
ridges	O
,	O
the	O
edge	O
term	O
attracts	O
it	O
to	O
strong	O
gradi-	O
ents	O
(	O
edges	O
)	O
,	O
and	O
the	O
term	O
term	O
attracts	O
it	O
to	O
line	O
terminations	O
.	O
in	O
practice	O
,	O
most	O
systems	O
only	O
use	O
the	O
edge	O
term	O
,	O
which	O
can	O
either	O
be	O
directly	O
proportional	O
to	O
the	O
image	B
gradients	O
,	O
−	O
(	O
cid:107	O
)	O
∇i	O
(	O
f	O
(	O
i	O
)	O
)	O
(	O
cid:107	O
)	O
2	O
,	O
−|	O
(	O
gσ	O
∗	O
∇2i	O
)	O
(	O
f	O
(	O
i	O
)	O
)	O
|2	O
.	O
(	O
5.4	O
)	O
(	O
5.5	O
)	O
or	O
to	O
a	O
smoothed	O
version	O
of	O
the	O
image	B
laplacian	O
,	O
eedge	O
=	O
(	O
cid:88	O
)	O
i	O
eedge	O
=	O
(	O
cid:88	O
)	O
i	O
people	O
also	O
sometimes	O
extract	O
edges	O
and	O
then	O
use	O
a	O
distance	O
map	O
to	O
the	O
edges	O
as	O
an	O
alternative	O
to	O
these	O
two	O
originally	O
proposed	O
potentials	O
.	O
in	O
interactive	B
applications	O
,	O
a	O
variety	O
of	O
user-placed	O
constraints	O
can	O
also	O
be	O
added	O
,	O
e.g.	O
,	O
attractive	O
(	O
spring	O
)	O
forces	O
towards	O
anchor	O
points	B
d	O
(	O
i	O
)	O
,	O
espring	O
=	O
ki	O
(	O
cid:107	O
)	O
f	O
(	O
i	O
)	O
−	O
d	O
(	O
i	O
)	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
5.6	O
)	O
as	O
well	O
as	O
repulsive	O
1/r	O
(	O
“	O
volcano	O
”	O
)	O
forces	O
(	O
figure	O
5.2a	O
)	O
.	O
as	O
the	O
snakes	B
evolve	O
by	O
minimiz-	O
ing	O
their	O
energy	O
,	O
they	O
often	O
“	O
wiggle	O
”	O
and	O
“	O
slither	O
”	O
,	O
which	O
accounts	O
for	O
their	O
popular	O
name	O
.	O
figure	O
5.2b	O
shows	O
snakes	B
being	O
used	O
to	O
track	O
a	O
person	O
’	O
s	O
lips	O
.	O
because	O
regular	O
snakes	B
have	O
a	O
tendency	O
to	O
shrink	O
(	O
exercise	O
5.1	O
)	O
,	O
it	O
is	O
usually	O
better	O
to	O
initialize	O
them	O
by	O
drawing	O
the	O
snake	O
outside	O
the	O
object	O
of	O
interest	O
to	O
be	O
tracked	O
.	O
alterna-	O
tively	O
,	O
an	O
expansion	O
ballooning	O
force	O
can	O
be	O
added	O
to	O
the	O
dynamics	O
(	O
cohen	O
and	O
cohen	O
1993	O
)	O
,	O
essentially	O
moving	O
each	O
point	O
outwards	O
along	O
its	O
normal	O
.	O
to	O
efﬁciently	O
solve	O
the	O
sparse	B
linear	O
system	O
arising	O
from	O
snake	O
energy	O
minimization	O
,	O
a	O
sparse	B
direct	O
solver	O
(	O
appendix	O
a.4	O
)	O
can	O
be	O
used	O
,	O
since	O
the	O
linear	B
system	O
is	O
essentially	O
penta-	O
diagonal.4	O
snake	O
evolution	B
is	O
usually	O
implemented	O
as	O
an	O
alternation	O
between	O
this	O
linear	B
sys-	O
4	O
a	O
closed	O
snake	O
has	O
a	O
toeplitz	O
matrix	O
form	O
,	O
which	O
can	O
still	O
be	O
factored	O
and	O
solved	O
in	O
o	O
(	O
n	O
)	O
time	O
.	O
272	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
5.3	O
elastic	O
net	O
:	O
the	O
open	O
squares	O
indicate	O
the	O
cities	O
and	O
the	O
closed	O
squares	O
linked	O
by	O
straight	O
line	O
segments	O
are	O
the	O
tour	O
points	B
.	O
the	O
blue	O
circles	O
indicate	O
the	O
approximate	O
extent	O
of	O
the	O
attraction	O
force	O
of	O
each	O
city	O
,	O
which	O
is	O
reduced	O
over	O
time	O
.	O
under	O
the	O
bayesian	O
interpretation	O
of	O
the	O
elastic	O
net	O
,	O
the	O
blue	O
circles	O
correspond	O
to	O
one	O
standard	O
deviation	O
of	O
the	O
circular	O
gaussian	O
that	O
generates	O
each	O
city	O
from	O
some	O
unknown	O
tour	O
point	O
.	O
tem	O
solution	O
and	O
the	O
linearization	O
of	O
non-linear	B
constraints	O
such	O
as	O
edge	O
energy	O
.	O
a	O
more	O
direct	B
way	O
to	O
ﬁnd	O
a	O
global	B
energy	O
minimum	O
is	O
to	O
use	O
dynamic	B
programming	I
(	O
amini	O
,	O
weymouth	O
,	O
and	O
jain	O
1990	O
;	O
williams	O
and	O
shah	O
1992	O
)	O
,	O
but	O
this	O
is	O
not	O
often	O
used	O
in	O
practice	O
,	O
since	O
it	O
has	O
been	O
superseded	O
by	O
even	O
more	O
efﬁcient	O
or	O
interactive	B
algorithms	O
such	O
as	O
intelligent	B
scissors	I
(	O
section	O
5.1.3	O
)	O
and	O
grabcut	O
(	O
section	O
5.5	O
)	O
.	O
elastic	O
nets	O
and	O
slippery	O
springs	O
an	O
interesting	O
variant	O
on	O
snakes	B
,	O
ﬁrst	O
proposed	O
by	O
durbin	O
and	O
willshaw	O
(	O
1987	O
)	O
and	O
later	O
re-formulated	O
in	O
an	O
energy-minimizing	O
framework	O
by	O
durbin	O
,	O
szeliski	O
,	O
and	O
yuille	O
(	O
1989	O
)	O
,	O
is	O
the	O
elastic	O
net	O
formulation	O
of	O
the	O
traveling	O
salesman	O
problem	O
(	O
tsp	O
)	O
.	O
recall	B
that	O
in	O
a	O
tsp	O
,	O
the	O
salesman	O
must	O
visit	O
each	O
city	O
once	O
while	O
minimizing	O
the	O
total	B
distance	O
traversed	O
.	O
a	O
snake	O
that	O
is	O
constrained	B
to	O
pass	O
through	O
each	O
city	O
could	O
solve	O
this	O
problem	O
(	O
without	O
any	O
optimality	O
guarantees	O
)	O
but	O
it	O
is	O
impossible	O
to	O
tell	O
ahead	O
of	O
time	O
which	O
snake	O
control	O
point	O
should	O
be	O
associated	O
with	O
each	O
city	O
.	O
instead	O
of	O
having	O
a	O
ﬁxed	O
constraint	O
between	O
snake	O
nodes	O
and	O
cities	O
,	O
as	O
in	O
(	O
5.6	O
)	O
,	O
a	O
city	O
is	O
assumed	O
to	O
pass	O
near	O
some	O
point	O
along	O
the	O
tour	O
(	O
figure	O
5.3	O
)	O
.	O
in	O
a	O
probabilistic	B
interpretation	O
,	O
each	O
city	O
is	O
generated	O
as	O
a	O
mixture	O
of	O
gaussians	O
centered	O
at	O
each	O
tour	O
point	O
,	O
p	O
(	O
d	O
(	O
j	O
)	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
pij	O
with	O
pij	O
=	O
e−d2	O
ij	O
/	O
(	O
2σ2	O
)	O
where	O
σ	O
is	O
the	O
standard	O
deviation	O
of	O
the	O
gaussian	O
and	O
dij	O
=	O
(	O
cid:107	O
)	O
f	O
(	O
i	O
)	O
−	O
d	O
(	O
j	O
)	O
(	O
cid:107	O
)	O
(	O
5.7	O
)	O
(	O
5.8	O
)	O
5.1	O
active	B
contours	I
273	O
is	O
the	O
euclidean	O
distance	O
between	O
a	O
tour	O
point	O
f	O
(	O
i	O
)	O
and	O
a	O
city	O
location	O
d	O
(	O
j	O
)	O
.	O
the	O
correspond-	O
ing	O
data	O
ﬁtting	O
energy	O
(	O
negative	O
log	O
likelihood	O
)	O
is	O
eslippery	O
=	O
−	O
(	O
cid:88	O
)	O
j	O
log	O
p	O
(	O
d	O
(	O
j	O
)	O
)	O
=	O
−	O
(	O
cid:88	O
)	O
j	O
log	O
(	O
cid:104	O
)	O
(	O
cid:88	O
)	O
e−	O
(	O
cid:107	O
)	O
f	O
(	O
i	O
)	O
−d	O
(	O
j	O
)	O
(	O
cid:107	O
)	O
2/2σ2	O
(	O
cid:105	O
)	O
.	O
(	O
5.9	O
)	O
this	O
energy	O
derives	O
its	O
name	O
from	O
the	O
fact	O
that	O
,	O
unlike	O
a	O
regular	O
spring	O
,	O
which	O
couples	O
a	O
given	O
snake	O
point	O
to	O
a	O
given	O
constraint	B
(	O
5.6	O
)	O
,	O
this	O
alternative	O
energy	O
deﬁnes	O
a	O
slippery	B
spring	I
that	O
allows	O
the	O
association	O
between	O
constraints	O
(	O
cities	O
)	O
and	O
curve	O
(	O
tour	O
)	O
points	B
to	O
evolve	O
over	O
time	O
(	O
szeliski	O
1989	O
)	O
.	O
note	O
that	O
this	O
is	O
a	O
soft	O
variant	O
of	O
the	O
popular	O
iterated	O
closest	O
point	O
data	O
constraint	B
that	O
is	O
often	O
used	O
in	O
ﬁtting	O
or	O
aligning	O
surfaces	O
to	O
data	O
points	O
or	O
to	O
each	O
other	O
(	O
section	O
12.2.1	O
)	O
(	O
besl	O
and	O
mckay	O
1992	O
;	O
zhang	O
1994	O
)	O
.	O
to	O
compute	O
a	O
good	O
solution	O
to	O
the	O
tsp	O
,	O
the	O
slippery	B
spring	I
data	O
association	O
energy	O
is	O
combined	O
with	O
a	O
regular	O
ﬁrst-order	O
internal	O
smoothness	O
energy	O
(	O
5.3	O
)	O
to	O
deﬁne	O
the	O
cost	O
of	O
a	O
tour	O
.	O
the	O
tour	O
f	O
(	O
s	O
)	O
is	O
initialized	O
as	O
a	O
small	O
circle	O
around	O
the	O
mean	O
of	O
the	O
city	O
points	B
and	O
σ	O
is	O
progressively	O
lowered	O
(	O
figure	O
5.3	O
)	O
.	O
for	O
large	O
σ	O
values	O
,	O
the	O
tour	O
tries	O
to	O
stay	O
near	O
the	O
centroid	O
of	O
the	O
points	B
but	O
as	O
σ	O
decreases	O
each	O
city	O
pulls	O
more	O
and	O
more	O
strongly	O
on	O
its	O
closest	O
tour	O
points	B
(	O
durbin	O
,	O
szeliski	O
,	O
and	O
yuille	O
1989	O
)	O
.	O
in	O
the	O
limit	O
as	O
σ	O
→	O
0	O
,	O
each	O
city	O
is	O
guaranteed	O
to	O
capture	O
at	O
least	O
one	O
tour	O
point	O
and	O
the	O
tours	O
between	O
subsequent	O
cites	O
become	O
straight	O
lines	B
.	O
splines	B
and	O
shape	B
priors	I
while	O
snakes	B
can	O
be	O
very	O
good	O
at	O
capturing	O
the	O
ﬁne	O
and	O
irregular	O
detail	O
in	O
many	O
real-world	O
contours	O
,	O
they	O
sometimes	O
exhibit	O
too	O
many	O
degrees	O
of	O
freedom	O
,	O
making	O
it	O
more	O
likely	O
that	O
they	O
can	O
get	O
trapped	O
in	O
local	B
minima	O
during	O
their	O
evolution	B
.	O
one	O
solution	O
to	O
this	O
problem	O
is	O
to	O
control	O
the	O
snake	O
with	O
fewer	O
degrees	O
of	O
freedom	O
through	O
the	O
use	O
of	O
b-spline	O
approximations	O
(	O
menet	O
,	O
saint-marc	O
,	O
and	O
medioni	O
1990b	O
,	O
a	O
;	O
cipolla	O
and	O
blake	O
1990	O
)	O
.	O
the	O
resulting	O
b-snake	O
can	O
be	O
written	O
as	O
f	O
(	O
s	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
bk	O
(	O
s	O
)	O
xk	O
f	O
=	O
bx	O
or	O
in	O
discrete	B
form	O
as	O
with	O
f	O
=	O
f	O
t	O
(	O
0	O
)	O
...	O
f	O
t	O
(	O
n	O
)	O
	O
,	O
b	O
=	O
b0	O
(	O
s0	O
)	O
...	O
b0	O
(	O
sn	O
)	O
.	O
.	O
.	O
bk	O
(	O
s0	O
)	O
...	O
.	O
.	O
.	O
bk	O
(	O
sn	O
)	O
...	O
	O
,	O
and	O
x	O
=	O
xt	O
(	O
0	O
)	O
...	O
xt	O
(	O
k	O
)	O
(	O
5.10	O
)	O
(	O
5.11	O
)	O
	O
.	O
(	O
5.12	O
)	O
274	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
5.4	O
point	O
distribution	O
model	O
for	O
a	O
set	O
of	O
resistors	O
(	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
)	O
c	O
(	O
cid:13	O
)	O
1995	O
elsevier	O
:	O
(	O
a	O
)	O
set	O
of	O
input	O
resistor	O
shapes	O
;	O
(	O
b	O
)	O
assignment	O
of	O
control	O
points	B
to	O
the	O
boundary	O
;	O
(	O
c	O
)	O
distribution	O
(	O
scatter	O
plot	O
)	O
of	O
point	O
locations	O
;	O
(	O
d	O
)	O
ﬁrst	O
(	O
largest	O
)	O
mode	O
of	O
variation	O
in	O
the	O
ensemble	O
shapes	O
.	O
if	O
the	O
object	O
being	O
tracked	O
or	O
recognized	O
has	O
large	O
variations	O
in	O
location	O
,	O
scale	O
,	O
or	O
ori-	O
entation	O
,	O
these	O
can	O
be	O
modeled	O
as	O
an	O
additional	O
transformation	O
on	O
the	O
control	O
points	B
,	O
e.g.	O
,	O
x	O
(	O
cid:48	O
)	O
k	O
=	O
srxk	O
+	O
t	O
(	O
2.18	O
)	O
,	O
which	O
can	O
be	O
estimated	O
at	O
the	O
same	O
time	O
as	O
the	O
values	O
of	O
the	O
control	O
points	B
.	O
alternatively	O
,	O
separate	O
detection	B
and	O
alignment	B
stages	O
can	O
be	O
run	O
to	O
ﬁrst	O
localize	O
and	O
orient	O
the	O
objects	O
of	O
interest	O
(	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
)	O
.	O
in	O
a	O
b-snake	O
,	O
because	O
the	O
snake	O
is	O
controlled	O
by	O
fewer	O
degrees	O
of	O
freedom	O
,	O
there	O
is	O
less	O
need	O
for	O
the	O
internal	O
smoothness	O
forces	O
used	O
with	O
the	O
original	O
snakes	B
,	O
although	O
these	O
can	O
still	O
be	O
derived	O
and	O
implemented	O
using	O
ﬁnite	O
element	O
analysis	O
,	O
i.e.	O
,	O
taking	O
derivatives	O
and	O
integrals	O
of	O
the	O
b-spline	O
basis	O
functions	O
(	O
terzopoulos	O
1983	O
;	O
bathe	O
2007	O
)	O
.	O
in	O
practice	O
,	O
it	O
is	O
more	O
common	O
to	O
estimate	O
a	O
set	O
of	O
shape	B
priors	I
on	O
the	O
typical	O
distribution	O
of	O
the	O
control	O
points	B
{	O
xk	O
}	O
(	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
)	O
.	O
consider	O
the	O
set	O
of	O
resistor	O
if	O
we	O
describe	O
each	O
contour	O
with	O
the	O
set	O
of	O
control	O
points	B
shapes	O
shown	O
in	O
figure	O
5.4a	O
.	O
shown	O
in	O
figure	O
5.4b	O
,	O
we	O
can	O
plot	O
the	O
distribution	O
of	O
each	O
point	O
in	O
a	O
scatter	O
plot	O
,	O
as	O
shown	O
in	O
figure	O
5.4c	O
.	O
one	O
potential	O
way	O
of	O
describing	O
this	O
distribution	O
would	O
be	O
by	O
the	O
location	O
¯xk	O
and	O
2d	O
covariance	O
ck	O
of	O
each	O
individual	O
point	O
xk	O
.	O
these	O
could	O
then	O
be	O
turned	O
into	O
a	O
quadratic	O
penalty	O
(	O
prior	B
energy	O
)	O
on	O
the	O
point	O
location	O
,	O
eloc	O
(	O
xk	O
)	O
=	O
1	O
2	O
(	O
xk	O
−	O
¯xk	O
)	O
t	O
c−1	O
k	O
(	O
xk	O
−	O
¯xk	O
)	O
.	O
(	O
5.13	O
)	O
in	O
practice	O
,	O
however	O
,	O
the	O
variation	O
in	O
point	O
locations	O
is	O
usually	O
highly	O
correlated	O
.	O
a	O
preferable	O
approach	O
is	O
to	O
estimate	O
the	O
joint	B
covariance	O
of	O
all	O
the	O
points	B
simultaneously	O
.	O
first	O
,	O
concatenate	O
all	O
of	O
the	O
point	O
locations	O
{	O
xk	O
}	O
into	O
a	O
single	O
vector	O
x	O
,	O
e.g.	O
,	O
by	O
interleaving	O
the	O
x	O
and	O
y	O
locations	O
of	O
each	O
point	O
.	O
the	O
distribution	O
of	O
these	O
vectors	O
across	O
all	O
training	O
5.1	O
active	B
contours	I
275	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
5.5	O
active	O
shape	O
model	O
(	O
asm	O
)	O
:	O
(	O
a	O
)	O
the	O
effect	O
of	O
varying	O
the	O
ﬁrst	O
four	O
shape	O
param-	O
eters	O
for	O
a	O
set	O
of	O
faces	B
(	O
cootes	O
,	O
taylor	O
,	O
lanitis	O
et	O
al	O
.	O
1993	O
)	O
c	O
(	O
cid:13	O
)	O
1993	O
ieee	O
;	O
(	O
b	O
)	O
searching	O
for	O
the	O
strongest	O
gradient	O
along	O
the	O
normal	O
to	O
each	O
control	O
point	O
(	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
)	O
c	O
(	O
cid:13	O
)	O
1995	O
elsevier	O
.	O
examples	B
(	O
figure	O
5.4a	O
)	O
can	O
be	O
described	O
with	O
a	O
mean	O
¯x	O
and	O
a	O
covariance	O
c	O
=	O
1	O
p	O
(	O
cid:88	O
)	O
p	O
(	O
xp	O
−	O
¯x	O
)	O
(	O
xp	O
−	O
¯x	O
)	O
t	O
,	O
(	O
5.14	O
)	O
where	O
xp	O
are	O
the	O
p	O
training	O
examples	B
.	O
using	O
eigenvalue	O
analysis	O
(	O
appendix	O
a.1.2	O
)	O
,	O
which	O
is	O
also	O
known	O
as	O
principal	O
component	O
analysis	O
(	O
pca	O
)	O
(	O
appendix	O
b.1.1	O
)	O
,	O
the	O
covariance	O
matrix	O
can	O
be	O
written	O
as	O
,	O
c	O
=	O
φ	O
diag	O
(	O
λ0	O
.	O
.	O
.	O
λk−1	O
)	O
φt	O
.	O
(	O
5.15	O
)	O
in	O
most	O
cases	O
,	O
the	O
likely	O
appearance	O
of	O
the	O
points	B
can	O
be	O
modeled	O
using	O
only	O
a	O
few	O
eigen-	O
vectors	O
with	O
the	O
largest	O
eigenvalues	B
.	O
the	O
resulting	O
point	O
distribution	O
model	O
(	O
cootes	O
,	O
taylor	O
,	O
lanitis	O
et	O
al	O
.	O
1993	O
;	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
)	O
can	O
be	O
written	O
as	O
x	O
=	O
¯x	O
+	O
ˆφ	O
b	O
,	O
(	O
5.16	O
)	O
where	O
b	O
is	O
an	O
m	O
(	O
cid:28	O
)	O
k	O
element	O
shape	O
parameter	O
vector	O
and	O
ˆφ	O
are	O
the	O
ﬁrst	O
m	O
columns	O
of	O
φ.	O
to	O
constrain	O
the	O
shape	O
parameters	O
to	O
reasonable	O
values	O
,	O
we	O
can	O
use	O
a	O
quadratic	O
penalty	O
of	O
the	O
form	O
alternatively	O
,	O
the	O
range	O
of	O
allowable	O
bm	O
values	O
can	O
be	O
limited	O
to	O
some	O
range	O
,	O
e.g.	O
,	O
|bm|	O
≤	O
3√λm	O
(	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
)	O
.	O
alternative	O
approaches	O
for	O
deriving	O
a	O
set	O
of	O
shape	O
vectors	O
are	O
reviewed	O
by	O
isard	O
and	O
blake	O
(	O
1998	O
)	O
.	O
eshape	O
=	O
m/2λm	O
.	O
b2	O
(	O
5.17	O
)	O
1	O
2	O
bt	O
diag	O
(	O
λ0	O
.	O
.	O
.	O
λm−1	O
)	O
b	O
=	O
(	O
cid:88	O
)	O
m	O
276	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
varying	O
the	O
individual	O
shape	O
parameters	O
bm	O
over	O
the	O
range	O
−2√λm	O
≤	O
2√λm	O
can	O
give	O
a	O
good	O
indication	O
of	O
the	O
expected	O
variation	O
in	O
appearance	O
,	O
as	O
shown	O
in	O
figure	O
5.4d	O
.	O
another	O
example	O
,	O
this	O
time	O
related	O
to	O
face	B
contours	O
,	O
is	O
shown	O
in	O
figure	O
5.5a	O
.	O
in	O
order	B
to	O
align	O
a	O
point	O
distribution	O
model	O
with	O
an	O
image	B
,	O
each	O
control	O
point	O
searches	O
in	O
a	O
direction	O
normal	O
to	O
the	O
contour	O
to	O
ﬁnd	O
the	O
most	O
likely	O
corresponding	O
image	B
edge	O
point	O
(	O
figure	O
5.5b	O
)	O
.	O
these	O
individual	O
measurements	O
can	O
be	O
combined	O
with	O
priors	O
on	O
the	O
shape	O
parameters	O
(	O
and	O
,	O
if	O
desired	O
,	O
position	O
,	O
scale	O
,	O
and	O
orientation	O
parameters	B
)	O
to	O
estimate	O
a	O
new	O
set	O
of	O
parameters	B
.	O
the	O
resulting	O
active	O
shape	O
model	O
(	O
asm	O
)	O
can	O
be	O
iteratively	O
minimized	O
to	O
ﬁt	O
images	O
to	O
non-rigidly	O
deforming	O
objects	O
such	O
as	O
medical	O
images	O
or	O
body	B
parts	O
such	O
as	O
hands	O
(	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
)	O
.	O
the	O
asm	O
can	O
also	O
be	O
combined	O
with	O
a	O
pca	O
analysis	O
of	O
the	O
underlying	O
gray-level	O
distribution	O
to	O
create	O
an	O
active	B
appearance	I
model	I
(	O
aam	O
)	O
(	O
cootes	O
,	O
edwards	O
,	O
and	O
taylor	O
2001	O
)	O
,	O
which	O
we	O
discuss	O
in	O
more	O
detail	O
in	O
section	O
14.2.2	O
.	O
5.1.2	O
dynamic	B
snakes	O
and	O
condensation	O
in	O
many	O
applications	O
of	O
active	B
contours	I
,	O
the	O
object	O
of	O
interest	O
is	O
being	O
tracked	O
from	O
frame	O
to	O
frame	O
as	O
it	O
deforms	O
and	O
evolves	O
.	O
in	O
this	O
case	O
,	O
it	O
makes	O
sense	O
to	O
use	O
estimates	O
from	O
the	O
previous	O
frame	O
to	O
predict	O
and	O
constrain	O
the	O
new	O
estimates	O
.	O
one	O
way	O
to	O
do	O
this	O
is	O
to	O
use	O
kalman	O
ﬁltering	O
,	O
which	O
results	O
in	O
a	O
formulation	O
called	O
kalman	O
snakes	B
(	O
terzopoulos	O
and	O
szeliski	O
1992	O
;	O
blake	O
,	O
curwen	O
,	O
and	O
zisserman	O
1993	O
)	O
.	O
the	O
kalman	O
ﬁlter	O
is	O
based	O
on	O
a	O
linear	B
dynamic	O
model	O
of	O
shape	O
parameter	O
evolution	B
,	O
xt	O
=	O
axt−1	O
+	O
wt	O
,	O
(	O
5.18	O
)	O
where	O
xt	O
and	O
xt−1	O
are	O
the	O
current	O
and	O
previous	O
state	O
variables	O
,	O
a	O
is	O
the	O
linear	B
transition	O
matrix	O
,	O
and	O
w	O
is	O
a	O
noise	B
(	O
perturbation	O
)	O
vector	O
,	O
which	O
is	O
often	O
modeled	O
as	O
a	O
gaussian	O
(	O
gelb	O
1974	O
)	O
.	O
the	O
matrices	O
a	O
and	O
the	O
noise	B
covariance	O
can	O
be	O
learned	B
ahead	O
of	O
time	O
by	O
observing	O
typical	O
sequences	O
of	O
the	O
object	O
being	O
tracked	O
(	O
blake	O
and	O
isard	O
1998	O
)	O
.	O
the	O
qualitative	O
behavior	O
of	O
the	O
kalman	O
ﬁlter	O
can	O
be	O
seen	O
in	O
figure	O
5.6a	O
.	O
the	O
linear	B
dy-	O
namic	O
model	O
causes	O
a	O
deterministic	O
change	O
(	O
drift	O
)	O
in	O
the	O
previous	O
estimate	O
,	O
while	O
the	O
process	O
noise	B
(	O
perturbation	O
)	O
causes	O
a	O
stochastic	O
diffusion	O
that	O
increases	O
the	O
system	O
entropy	O
(	O
lack	O
of	O
certainty	O
)	O
.	O
new	O
measurements	O
from	O
the	O
current	O
frame	O
restore	O
some	O
of	O
the	O
certainty	O
(	O
peaked-	O
ness	O
)	O
in	O
the	O
updated	O
estimate	O
.	O
in	O
many	O
situations	O
,	O
however	O
,	O
such	O
as	O
when	O
tracking	O
in	O
clutter	O
,	O
a	O
better	O
estimate	O
for	O
the	O
contour	O
can	O
be	O
obtained	O
if	O
we	O
remove	O
the	O
assumptions	O
that	O
the	O
distribution	O
are	O
gaussian	O
,	O
which	O
is	O
what	O
the	O
kalman	O
ﬁlter	O
requires	O
.	O
in	O
this	O
case	O
,	O
a	O
general	O
multi-modal	O
distribution	O
is	O
propagated	O
,	O
as	O
shown	O
in	O
figure	O
5.6b	O
.	O
in	O
order	B
to	O
model	O
such	O
multi-modal	O
distributions	O
,	O
isard	O
and	O
blake	O
(	O
1998	O
)	O
introduced	O
the	O
use	O
of	O
particle	B
ﬁltering	I
to	O
the	O
computer	O
vision	O
community.5	O
5	O
alternatives	O
to	O
modeling	B
multi-modal	O
distributions	O
include	O
mixtures	O
of	O
gaussians	O
(	O
bishop	O
2006	O
)	O
and	O
multiple	B
5.1	O
active	B
contours	I
277	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
5.6	O
probability	O
density	O
propagation	O
(	O
isard	O
and	O
blake	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
springer	O
.	O
at	O
the	O
beginning	O
of	O
each	O
estimation	B
step	O
,	O
the	O
probability	O
density	O
is	O
updated	O
according	O
to	O
the	O
linear	B
dynamic	O
model	O
(	O
deterministic	O
drift	O
)	O
and	O
its	O
certainty	O
is	O
reduced	O
due	O
to	O
process	O
noise	B
(	O
stochastic	O
diffusion	O
)	O
.	O
new	O
measurements	O
introduce	O
additional	O
information	O
that	O
helps	O
reﬁne	O
the	O
current	O
estimate	O
.	O
(	O
a	O
)	O
the	O
kalman	O
ﬁlter	O
models	O
the	O
distributions	O
as	O
uni-modal	O
,	O
i.e.	O
,	O
using	O
a	O
mean	O
and	O
covariance	O
.	O
(	O
b	O
)	O
some	O
applications	O
require	O
more	O
general	O
multi-modal	O
distributions	O
.	O
278	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
5.7	O
factored	O
sampling	B
using	O
particle	O
ﬁlter	O
in	O
the	O
condensation	O
algorithm	B
(	O
is-	O
ard	O
and	O
blake	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
springer	O
:	O
(	O
a	O
)	O
each	O
density	O
distribution	O
is	O
represented	O
using	O
a	O
superposition	B
of	O
weighted	B
particles	O
;	O
(	O
b	O
)	O
the	O
drift-diffusion-measurement	O
cycle	O
implemented	O
using	O
random	O
sampling	B
,	O
perturbation	O
,	O
and	O
re-weighting	O
stages	O
.	O
5.1	O
active	B
contours	I
279	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
5.8	O
head	B
tracking	I
using	O
condensation	O
(	O
isard	O
and	O
blake	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
springer	O
:	O
(	O
a	O
)	O
sample	O
set	O
representation	O
of	O
head	B
estimate	O
distribution	O
;	O
(	O
b	O
)	O
multiple	B
measure-	O
ments	O
at	O
each	O
control	O
vertex	O
location	O
;	O
(	O
c	O
)	O
multi-hypothesis	O
tracking	O
over	O
time	O
.	O
particle	B
ﬁltering	I
techniques	O
represent	O
a	O
probability	O
distribution	O
using	O
a	O
collection	O
of	O
weighted	B
point	O
samples	O
(	O
figure	O
5.7a	O
)	O
(	O
andrieu	O
,	O
de	O
freitas	O
,	O
doucet	O
et	O
al	O
.	O
2003	O
;	O
bishop	O
2006	O
;	O
koller	O
and	O
friedman	O
2009	O
)	O
.	O
to	O
update	O
the	O
locations	O
of	O
the	O
samples	O
according	O
to	O
the	O
linear	B
dy-	O
namics	O
(	O
deterministic	O
drift	O
)	O
,	O
the	O
centers	O
of	O
the	O
samples	O
are	O
updated	O
according	O
to	O
(	O
5.18	O
)	O
and	O
multiple	B
samples	O
are	O
generated	O
for	O
each	O
point	O
(	O
figure	O
5.7b	O
)	O
.	O
these	O
are	O
then	O
perturbed	O
to	O
account	O
for	O
the	O
stochastic	O
diffusion	O
,	O
i.e.	O
,	O
their	O
locations	O
are	O
moved	O
by	O
random	O
vectors	O
taken	O
from	O
the	O
distribution	O
of	O
w.6	O
finally	O
,	O
the	O
weights	O
of	O
these	O
samples	O
are	O
multiplied	O
by	O
the	O
mea-	O
surement	O
probability	O
density	O
,	O
i.e.	O
,	O
we	O
take	O
each	O
sample	O
and	O
measure	O
its	O
likelihood	O
given	O
the	O
current	O
(	O
new	O
)	O
measurements	O
.	O
because	O
the	O
point	O
samples	O
represent	O
and	O
propagate	O
conditional	O
estimates	O
of	O
the	O
multi-modal	O
density	O
,	O
isard	O
and	O
blake	O
(	O
1998	O
)	O
dubbed	O
their	O
algorithm	B
condi-	O
tional	O
density	O
propagation	O
or	O
condensation	O
.	O
figure	O
5.8a	O
shows	O
what	O
a	O
factored	O
sample	O
of	O
a	O
head	B
tracker	O
might	O
look	O
like	O
,	O
drawing	O
a	O
red	O
b-spline	O
contour	O
for	O
each	O
of	O
(	O
a	O
subset	O
of	O
)	O
the	O
particles	O
being	O
tracked	O
.	O
figure	O
5.8b	O
shows	O
why	O
the	O
measurement	O
density	O
itself	O
is	O
often	O
multi-modal	O
:	O
the	O
locations	O
of	O
the	O
edges	O
perpendicular	O
to	O
the	O
spline	B
curve	O
can	O
have	O
multiple	B
local	O
maxima	O
due	O
to	O
background	O
clutter	O
.	O
finally	O
,	O
figure	O
5.8c	O
shows	O
the	O
temporal	O
evolution	B
of	O
the	O
conditional	O
density	O
(	O
x	O
coordinate	O
of	O
the	O
head	B
and	O
shoulder	O
tracker	O
centroid	O
)	O
as	O
it	O
tracks	O
several	O
people	O
over	O
time	O
.	O
hypothesis	O
tracking	O
(	O
bar-shalom	O
and	O
fortmann	O
1988	O
;	O
cham	O
and	O
rehg	O
1999	O
)	O
.	O
6	O
note	O
that	O
because	O
of	O
the	O
structure	O
of	O
these	O
steps	O
,	O
non-linear	B
dynamics	O
and	O
non-gaussian	O
noise	B
can	O
be	O
used	O
.	O
280	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
5.9	O
intelligent	B
scissors	I
:	O
(	O
a	O
)	O
as	O
the	O
mouse	O
traces	O
the	O
white	O
path	O
,	O
the	O
scissors	O
follow	O
the	O
orange	O
path	O
along	O
the	O
object	O
boundary	O
(	O
the	O
green	O
curves	O
show	O
intermediate	O
positions	O
)	O
(	O
mortensen	O
and	O
barrett	O
1995	O
)	O
c	O
(	O
cid:13	O
)	O
1995	O
acm	O
;	O
(	O
b	O
)	O
regular	O
scissors	O
can	O
sometimes	O
jump	O
to	O
a	O
stronger	O
(	O
incorrect	O
)	O
boundary	O
;	O
(	O
c	O
)	O
after	O
training	O
to	O
the	O
previous	O
segment	O
,	O
similar	O
edge	O
proﬁles	O
are	O
preferred	O
(	O
mortensen	O
and	O
barrett	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1995	O
elsevier	O
.	O
5.1.3	O
scissors	O
active	B
contours	I
allow	O
a	O
user	O
to	O
roughly	O
specify	O
a	O
boundary	O
of	O
interest	O
and	O
have	O
the	O
system	O
evolve	O
the	O
contour	O
towards	O
a	O
more	O
accurate	O
location	O
as	O
well	O
as	O
track	O
it	O
over	O
time	O
.	O
the	O
results	O
of	O
this	O
curve	O
evolution	B
,	O
however	O
,	O
may	O
be	O
unpredictable	O
and	O
may	O
require	O
additional	O
user-based	O
hints	O
to	O
achieve	O
the	O
desired	O
result	O
.	O
an	O
alternative	O
approach	O
is	O
to	O
have	O
the	O
system	O
optimize	O
the	O
contour	O
in	O
real	O
time	O
as	O
the	O
user	O
is	O
drawing	O
(	O
mortensen	O
1999	O
)	O
.	O
the	O
intelligent	B
scissors	I
system	O
developed	O
by	O
mortensen	O
and	O
barrett	O
(	O
1995	O
)	O
does	O
just	O
that	O
.	O
as	O
the	O
user	O
draws	O
a	O
rough	O
outline	O
(	O
the	O
white	O
curve	O
in	O
figure	O
5.9a	O
)	O
,	O
the	O
system	O
computes	O
and	O
draws	O
a	O
better	O
curve	O
that	O
clings	O
to	O
high-contrast	O
edges	O
(	O
the	O
orange	O
curve	O
)	O
.	O
to	O
compute	O
the	O
optimal	O
curve	O
path	O
(	O
live-wire	O
)	O
,	O
the	O
image	B
is	O
ﬁrst	O
pre-processed	O
to	O
associate	O
low	O
costs	O
with	O
edges	O
(	O
links	O
between	O
neighboring	O
horizontal	O
,	O
vertical	O
,	O
and	O
diagonal	O
,	O
i.e.	O
,	O
n8	O
neighbors	O
)	O
that	O
are	O
likely	O
to	O
be	O
boundary	O
elements	O
.	O
their	O
system	O
uses	O
a	O
combination	O
of	O
zero-	O
crossing	O
,	O
gradient	O
magnitudes	O
,	O
and	O
gradient	O
orientations	O
to	O
compute	O
these	O
costs	O
.	O
next	O
,	O
as	O
the	O
user	O
traces	O
a	O
rough	O
curve	O
,	O
the	O
system	O
continuously	O
recomputes	O
the	O
lowest-	O
cost	O
path	O
between	O
the	O
starting	O
seed	O
point	O
and	O
the	O
current	O
mouse	O
location	O
using	O
dijkstra	O
’	O
s	O
al-	O
gorithm	O
,	O
a	O
breadth-ﬁrst	O
dynamic	B
programming	I
algorithm	O
that	O
terminates	O
at	O
the	O
current	O
target	O
location	O
.	O
in	O
order	B
to	O
keep	O
the	O
system	O
from	O
jumping	O
around	O
unpredictably	O
,	O
the	O
system	O
will	O
“	O
freeze	O
”	O
the	O
curve	O
to	O
date	O
(	O
reset	O
the	O
seed	O
point	O
)	O
after	O
a	O
period	O
of	O
inactivity	O
.	O
to	O
prevent	O
the	O
live	O
wire	O
from	O
jumping	O
onto	O
adjacent	O
higher-contrast	O
contours	O
,	O
the	O
system	O
also	O
“	O
learns	O
”	O
the	O
intensity	O
5.1	O
active	B
contours	I
281	O
figure	O
5.10	O
level	O
set	O
evolution	B
for	O
a	O
geodesic	B
active	I
contour	I
.	O
the	O
embedding	O
function	O
φ	O
is	O
updated	O
based	O
on	O
the	O
curvature	O
of	O
the	O
underlying	O
surface	B
modulated	O
by	O
the	O
edge/speed	O
function	O
g	O
(	O
i	O
)	O
,	O
as	O
well	O
as	O
the	O
gradient	O
of	O
g	O
(	O
i	O
)	O
,	O
thereby	O
attracting	O
it	O
to	O
strong	O
edges	O
.	O
proﬁle	B
under	O
the	O
current	O
optimized	O
curve	O
,	O
and	O
uses	O
this	O
to	O
preferentially	O
keep	O
the	O
wire	O
moving	O
along	O
the	O
same	O
(	O
or	O
a	O
similar	O
looking	O
)	O
boundary	O
(	O
figure	O
5.9b–c	O
)	O
.	O
several	O
extensions	O
have	O
been	O
proposed	O
to	O
the	O
basic	O
algorithm	B
,	O
which	O
works	O
remarkably	O
well	O
even	O
in	O
its	O
original	O
form	O
.	O
mortensen	O
and	O
barrett	O
(	O
1999	O
)	O
use	O
tobogganing	B
,	O
which	O
is	O
a	O
simple	O
form	O
of	O
watershed	B
region	O
segmentation	B
,	O
to	O
pre-segment	O
the	O
image	B
into	O
regions	O
whose	O
boundaries	O
become	O
candidates	O
for	O
optimized	O
curve	O
paths	O
.	O
the	O
resulting	O
region	B
boundaries	O
are	O
turned	O
into	O
a	O
much	O
smaller	O
graph	O
,	O
where	O
nodes	O
are	O
located	O
wherever	O
three	O
or	O
four	O
regions	O
meet	O
.	O
the	O
dijkstra	O
algorithm	B
is	O
then	O
run	O
on	O
this	O
reduced	O
graph	O
,	O
resulting	O
in	O
much	O
faster	O
(	O
and	O
often	O
more	O
stable	O
)	O
performance	O
.	O
another	O
extension	O
to	O
intelligent	B
scissors	I
is	O
to	O
use	O
a	O
proba-	O
bilistic	O
framework	O
that	O
takes	O
into	O
account	O
the	O
current	O
trajectory	O
of	O
the	O
boundary	O
,	O
resulting	O
in	O
a	O
system	O
called	O
jetstream	O
(	O
p´erez	O
,	O
blake	O
,	O
and	O
gangnet	O
2001	O
)	O
.	O
instead	O
of	O
re-computing	O
an	O
optimal	O
curve	O
at	O
each	O
time	O
instant	O
,	O
a	O
simpler	O
system	O
can	O
be	O
developed	O
by	O
simply	O
“	O
snapping	O
”	O
the	O
current	O
mouse	O
position	O
to	O
the	O
nearest	O
likely	O
boundary	O
point	O
(	O
gleicher	O
1995	O
)	O
.	O
applications	O
of	O
these	O
boundary	O
extraction	O
techniques	O
to	O
image	B
cutting	O
and	O
pasting	O
are	O
presented	O
in	O
section	O
10.4	O
.	O
5.1.4	O
level	B
sets	I
a	O
limitation	O
of	O
active	B
contours	I
based	O
on	O
parametric	B
curves	O
of	O
the	O
form	O
f	O
(	O
s	O
)	O
,	O
e.g.	O
,	O
snakes	B
,	O
b-	O
snakes	B
,	O
and	O
condensation	O
,	O
is	O
that	O
it	O
is	O
challenging	O
to	O
change	O
the	O
topology	O
of	O
the	O
curve	O
as	O
it	O
evolves	O
.	O
(	O
mcinerney	O
and	O
terzopoulos	O
(	O
1999	O
,	O
2000	O
)	O
describe	O
one	O
approach	O
to	O
doing	O
this	O
.	O
)	O
furthermore	O
,	O
if	O
the	O
shape	O
changes	O
dramatically	O
,	O
curve	O
reparameterization	O
may	O
also	O
be	O
required	O
.	O
an	O
alternative	O
representation	O
for	O
such	O
closed	O
contours	O
is	O
to	O
use	O
a	O
level	O
set	O
,	O
where	O
the	O
zero-	O
crossing	O
(	O
s	O
)	O
of	O
a	O
characteristic	O
(	O
or	O
signed	B
distance	O
(	O
section	O
3.3.3	O
)	O
)	O
function	O
deﬁne	O
the	O
curve	O
.	O
-1+1ϕ	O
=	O
0ϕ∆g	O
(	O
i	O
)	O
282	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
level	B
sets	I
evolve	O
to	O
ﬁt	O
and	O
track	O
objects	O
of	O
interest	O
by	O
modifying	O
the	O
underlying	O
embedding	O
function	O
(	O
another	O
name	O
for	O
this	O
2d	O
function	O
)	O
φ	O
(	O
x	O
,	O
y	O
)	O
instead	O
of	O
the	O
curve	O
f	O
(	O
s	O
)	O
(	O
malladi	O
,	O
sethian	O
,	O
and	O
vemuri	O
1995	O
;	O
sethian	O
1999	O
;	O
sapiro	O
2001	O
;	O
osher	O
and	O
paragios	O
2003	O
)	O
.	O
to	O
reduce	O
the	O
amount	O
of	O
computation	O
required	O
,	O
only	O
a	O
small	O
strip	O
(	O
frontier	O
)	O
around	O
the	O
locations	O
of	O
the	O
current	O
zero-crossing	O
needs	O
to	O
updated	O
at	O
each	O
step	O
,	O
which	O
results	O
in	O
what	O
are	O
called	O
fast	O
marching	O
methods	O
(	O
sethian	O
1999	O
)	O
.	O
an	O
example	O
of	O
an	O
evolution	B
equation	O
is	O
the	O
geodesic	B
active	I
contour	I
proposed	O
by	O
caselles	O
,	O
kimmel	O
,	O
and	O
sapiro	O
(	O
1997	O
)	O
and	O
yezzi	O
,	O
kichenassamy	O
,	O
kumar	O
et	O
al	O
.	O
(	O
1997	O
)	O
,	O
dφ	O
dt	O
|∇φ|	O
(	O
cid:19	O
)	O
=	O
|∇φ|div	O
(	O
cid:18	O
)	O
g	O
(	O
i	O
)	O
∇φ	O
=	O
g	O
(	O
i	O
)	O
|∇φ|div	O
(	O
cid:18	O
)	O
∇φ	O
|∇φ|	O
(	O
cid:19	O
)	O
+	O
∇g	O
(	O
i	O
)	O
·	O
∇φ	O
,	O
(	O
5.19	O
)	O
where	O
g	O
(	O
i	O
)	O
is	O
a	O
generalized	B
version	O
of	O
the	O
snake	O
edge	O
potential	O
(	O
5.5	O
)	O
.	O
to	O
get	O
an	O
intuitive	O
sense	O
of	O
the	O
curve	O
’	O
s	O
behavior	O
,	O
assume	O
that	O
the	O
embedding	O
function	O
φ	O
is	O
a	O
signed	B
distance	O
function	O
away	O
from	O
the	O
curve	O
(	O
figure	O
5.10	O
)	O
,	O
in	O
which	O
case	O
|φ|	O
=	O
1.	O
the	O
ﬁrst	O
term	O
in	O
equation	B
(	O
5.19	O
)	O
moves	O
the	O
curve	O
in	O
the	O
direction	O
of	O
its	O
curvature	O
,	O
i.e.	O
,	O
it	O
acts	O
to	O
straighten	O
the	O
curve	O
,	O
under	O
the	O
inﬂuence	O
of	O
the	O
modulation	O
function	O
g	O
(	O
i	O
)	O
.	O
the	O
second	O
term	O
moves	O
the	O
curve	O
down	O
the	O
gradient	O
of	O
g	O
(	O
i	O
)	O
,	O
encouraging	O
the	O
curve	O
to	O
migrate	O
towards	O
minima	O
of	O
g	O
(	O
i	O
)	O
.	O
while	O
this	O
level-set	O
formulation	O
can	O
readily	O
change	O
topology	O
,	O
it	O
is	O
still	O
susceptible	O
to	O
lo-	O
cal	O
minima	O
,	O
since	O
it	O
is	O
based	O
on	O
local	B
measurements	O
such	O
as	O
image	B
gradients	O
.	O
an	O
alternative	O
approach	O
is	O
to	O
re-cast	O
the	O
problem	O
in	O
a	O
segmentation	B
framework	O
,	O
where	O
the	O
energy	O
measures	O
the	O
consistency	O
of	O
the	O
image	B
statistics	O
(	O
e.g.	O
,	O
color	B
,	O
texture	B
,	O
motion	B
)	O
inside	O
and	O
outside	O
the	O
seg-	O
mented	O
regions	O
(	O
cremers	O
,	O
rousson	O
,	O
and	O
deriche	O
2007	O
;	O
rousson	O
and	O
paragios	O
2008	O
;	O
houhou	O
,	O
thiran	O
,	O
and	O
bresson	O
2008	O
)	O
.	O
these	O
approaches	O
build	O
on	O
earlier	O
energy-based	B
segmentation	O
frameworks	O
introduced	O
by	O
leclerc	O
(	O
1989	O
)	O
,	O
mumford	O
and	O
shah	O
(	O
1989	O
)	O
,	O
and	O
chan	O
and	O
vese	O
(	O
1992	O
)	O
,	O
which	O
are	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
5.5.	O
examples	B
of	O
such	O
level-set	O
seg-	O
mentations	O
are	O
shown	O
in	O
figure	O
5.11	O
,	O
which	O
shows	O
the	O
evolution	B
of	O
the	O
level	B
sets	I
from	O
a	O
series	O
of	O
distributed	O
circles	O
towards	O
the	O
ﬁnal	O
binary	O
segmentation	O
.	O
for	O
more	O
information	O
on	O
level	B
sets	I
and	O
their	O
applications	O
,	O
please	O
see	O
the	O
collection	O
of	O
papers	O
edited	O
by	O
osher	O
and	O
paragios	O
(	O
2003	O
)	O
as	O
well	O
as	O
the	O
series	O
of	O
workshops	O
on	O
variational	O
and	O
level	O
set	O
methods	O
in	O
computer	O
vision	O
(	O
paragios	O
,	O
faugeras	O
,	O
chan	O
et	O
al	O
.	O
2005	O
)	O
and	O
special	O
issues	O
on	O
scale	O
space	O
and	O
variational	O
methods	O
in	O
computer	O
vision	O
(	O
paragios	O
and	O
sgallari	O
2009	O
)	O
.	O
5.1.5	O
application	O
:	O
contour	O
tracking	O
and	O
rotoscoping	B
active	O
contours	O
can	O
be	O
used	O
in	O
a	O
wide	O
variety	O
of	O
object-tracking	O
applications	O
(	O
blake	O
and	O
isard	O
1998	O
;	O
yilmaz	O
,	O
javed	O
,	O
and	O
shah	O
2006	O
)	O
.	O
for	O
example	O
,	O
they	O
can	O
be	O
used	O
to	O
track	O
facial	O
features	O
5.1	O
active	B
contours	I
283	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
5.11	O
level	O
set	O
segmentation	B
(	O
cremers	O
,	O
rousson	O
,	O
and	O
deriche	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
springer	O
:	O
(	O
a	O
)	O
grayscale	O
image	B
segmentation	O
and	O
(	O
b	O
)	O
color	B
image	O
segmentation	B
.	O
uni-variate	O
and	O
multi-variate	O
gaussians	O
are	O
used	O
to	O
model	O
the	O
foreground	O
and	O
background	O
pixel	O
dis-	O
tributions	O
.	O
the	O
initial	O
circles	O
evolve	O
towards	O
an	O
accurate	O
segmentation	B
of	O
foreground	O
and	O
background	O
,	O
adapting	O
their	O
topology	O
as	O
they	O
evolve	O
.	O
for	O
performance-driven	O
animation	O
(	O
terzopoulos	O
and	O
waters	O
1990	O
;	O
lee	O
,	O
terzopoulos	O
,	O
and	O
wa-	O
ters	O
1995	O
;	O
parke	O
and	O
waters	O
1996	O
;	O
bregler	O
,	O
covell	O
,	O
and	O
slaney	O
1997	O
)	O
(	O
figure	O
5.2b	O
)	O
.	O
they	O
can	O
also	O
be	O
used	O
to	O
track	O
heads	O
and	O
people	O
,	O
as	O
shown	O
in	O
figure	O
5.8	O
,	O
as	O
well	O
as	O
moving	O
vehicles	O
(	O
paragios	O
and	O
deriche	O
2000	O
)	O
.	O
additional	O
applications	O
include	O
medical	B
image	I
segmentation	O
,	O
where	O
contours	O
can	O
be	O
tracked	O
from	O
slice	O
to	O
slice	O
in	O
computerized	O
tomography	O
(	O
3d	O
medical	O
imagery	O
)	O
(	O
cootes	O
and	O
taylor	O
2001	O
)	O
or	O
over	O
time	O
,	O
as	O
in	O
ultrasound	O
scans	O
.	O
an	O
interesting	O
application	O
that	O
is	O
closer	O
to	O
computer	O
animation	O
and	O
visual	B
effects	I
is	O
ro-	O
toscoping	O
,	O
which	O
uses	O
the	O
tracked	O
contours	O
to	O
deform	O
a	O
set	O
of	O
hand-drawn	O
animations	O
(	O
or	O
to	O
modify	O
or	O
replace	O
the	O
original	O
video	B
frames	O
)	O
.7	O
agarwala	O
,	O
hertzmann	O
,	O
seitz	O
et	O
al	O
.	O
(	O
2004	O
)	O
present	O
a	O
system	O
based	O
on	O
tracking	O
hand-drawn	O
b-spline	O
contours	O
drawn	O
at	O
selected	O
keyframes	O
,	O
using	O
a	O
combination	O
of	O
geometric	B
and	O
appearance-based	O
criteria	O
(	O
figure	O
5.12	O
)	O
.	O
they	O
also	O
pro-	O
vide	O
an	O
excellent	O
review	O
of	O
previous	O
rotoscoping	B
and	O
image-based	B
,	O
contour-tracking	O
systems	O
.	O
7	O
the	O
term	O
comes	O
from	O
a	O
device	O
(	O
a	O
rotoscope	O
)	O
that	O
projected	O
frames	O
of	O
a	O
live-action	O
ﬁlm	O
underneath	O
an	O
acetate	O
so	O
that	O
artists	O
could	O
draw	O
animations	O
directly	O
over	O
the	O
actors	O
’	O
shapes	O
.	O
284	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
5.12	O
keyframe-based	O
rotoscoping	B
(	O
agarwala	O
,	O
hertzmann	O
,	O
seitz	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
(	O
a	O
)	O
original	O
frames	O
;	O
(	O
b	O
)	O
rotoscoped	O
contours	O
;	O
(	O
c	O
)	O
re-colored	O
blouse	O
;	O
(	O
d	O
)	O
rotoscoped	O
hand-drawn	O
animation	O
.	O
additional	O
applications	O
of	O
rotoscoping	B
(	O
object	O
contour	O
detection	B
and	O
segmentation	B
)	O
,	O
such	O
as	O
cutting	O
and	O
pasting	O
objects	O
from	O
one	O
photograph	O
into	O
another	O
,	O
are	O
presented	O
in	O
section	O
10.4	O
.	O
5.2	O
split	O
and	O
merge	O
as	O
mentioned	O
in	O
the	O
introduction	O
to	O
this	O
chapter	O
,	O
the	O
simplest	O
possible	O
technique	O
for	O
seg-	O
menting	O
a	O
grayscale	O
image	B
is	O
to	O
select	O
a	O
threshold	O
and	O
then	O
compute	O
connected	B
components	I
(	O
section	O
3.3.2	O
)	O
.	O
unfortunately	O
,	O
a	O
single	O
threshold	O
is	O
rarely	O
sufﬁcient	O
for	O
the	O
whole	O
image	B
because	O
of	O
lighting	B
and	O
intra-object	O
statistical	O
variations	O
.	O
in	O
this	O
section	O
,	O
we	O
describe	O
a	O
number	O
of	O
algorithms	O
that	O
proceed	O
either	O
by	O
recursively	O
splitting	B
the	O
whole	O
image	B
into	O
pieces	O
based	O
on	O
region	B
statistics	O
or	O
,	O
conversely	O
,	O
merging	B
pixels	O
and	O
regions	O
together	O
in	O
a	O
hierarchical	B
fashion	O
.	O
it	O
is	O
also	O
possible	O
to	O
combine	O
both	O
splitting	B
and	O
merging	B
by	O
starting	O
with	O
a	O
medium-grain	O
segmentation	B
(	O
in	O
a	O
quadtree	B
representation	O
)	O
and	O
then	O
allowing	O
both	O
merging	B
and	O
splitting	B
operations	O
(	O
horowitz	O
and	O
pavlidis	O
1976	O
;	O
pavlidis	O
and	O
liow	O
1990	O
)	O
.	O
5.2.1	O
watershed	B
a	O
technique	O
related	O
to	O
thresholding	B
,	O
since	O
it	O
operates	O
on	O
a	O
grayscale	O
image	B
,	O
is	O
watershed	B
com-	O
putation	O
(	O
vincent	O
and	O
soille	O
1991	O
)	O
.	O
this	O
technique	O
segments	O
an	O
image	B
into	O
several	O
catchment	O
basins	B
,	O
which	O
are	O
the	O
regions	O
of	O
an	O
image	B
(	O
interpreted	O
as	O
a	O
height	O
ﬁeld	O
or	O
landscape	O
)	O
where	O
5.2	O
split	O
and	O
merge	O
285	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
5.13	O
locally	O
constrained	O
watershed	B
segmentation	O
(	O
beare	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
ieee	O
:	O
(	O
a	O
)	O
original	O
confocal	O
microscopy	O
image	B
with	O
marked	O
seeds	O
(	O
line	O
segments	O
)	O
;	O
(	O
b	O
)	O
standard	O
water-	O
shed	O
segmentation	B
;	O
(	O
c	O
)	O
locally	O
constrained	O
watershed	B
segmentation	O
.	O
rain	O
would	O
ﬂow	O
into	O
the	O
same	O
lake	O
.	O
an	O
efﬁcient	O
way	O
to	O
compute	O
such	O
regions	O
is	O
to	O
start	O
ﬂood-	O
ing	O
the	O
landscape	O
at	O
all	O
of	O
the	O
local	B
minima	O
and	O
to	O
label	O
ridges	O
wherever	O
differently	O
evolving	O
components	O
meet	O
.	O
the	O
whole	O
algorithm	B
can	O
be	O
implemented	O
using	O
a	O
priority	O
queue	O
of	O
pixels	O
and	O
breadth-ﬁrst	O
search	O
(	O
vincent	O
and	O
soille	O
1991	O
)	O
.8	O
since	O
images	O
rarely	O
have	O
dark	O
regions	O
separated	O
by	O
lighter	O
ridges	O
,	O
watershed	B
segmen-	O
tation	O
is	O
usually	O
applied	O
to	O
a	O
smoothed	O
version	O
of	O
the	O
gradient	O
magnitude	O
image	B
,	O
which	O
also	O
makes	O
it	O
usable	O
with	O
color	O
images	O
.	O
as	O
an	O
alternative	O
,	O
the	O
maximum	O
oriented	B
energy	O
in	O
a	O
steer-	O
able	O
ﬁlter	O
(	O
3.28–3.29	O
)	O
(	O
freeman	O
and	O
adelson	O
1991	O
)	O
can	O
be	O
used	O
as	O
the	O
basis	O
of	O
the	O
oriented	B
watershed	O
transform	B
developed	O
by	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
(	O
2010	O
)	O
.	O
such	O
techniques	O
end	O
up	O
ﬁnding	O
smooth	O
regions	O
separated	O
by	O
visible	O
(	O
higher	O
gradient	O
)	O
boundaries	O
.	O
since	O
such	O
boundaries	O
are	O
what	O
active	B
contours	I
usually	O
follow	O
,	O
active	O
contour	O
algorithms	O
(	O
mortensen	O
and	O
barrett	O
1999	O
;	O
li	O
,	O
sun	O
,	O
tang	O
et	O
al	O
.	O
2004	O
)	O
often	O
precompute	O
such	O
a	O
segmentation	B
using	O
either	O
the	O
watershed	B
or	O
the	O
related	O
tobogganing	B
technique	O
(	O
section	O
5.1.3	O
)	O
.	O
unfortunately	O
,	O
watershed	B
segmentation	O
associates	O
a	O
unique	O
region	B
with	O
each	O
local	B
mini-	O
mum	O
,	O
which	O
can	O
lead	O
to	O
over-segmentation	O
.	O
watershed	B
segmentation	O
is	O
therefore	O
often	O
used	O
as	O
part	O
of	O
an	O
interactive	B
system	O
,	O
where	O
the	O
user	O
ﬁrst	O
marks	O
seed	O
locations	O
(	O
with	O
a	O
click	O
or	O
a	O
short	O
stroke	O
)	O
that	O
correspond	O
to	O
the	O
centers	O
of	O
different	O
desired	O
components	O
.	O
figure	O
5.13	O
shows	O
the	O
results	O
of	O
running	O
the	O
watershed	B
algorithm	O
with	O
some	O
manually	O
placed	O
markers	O
on	O
a	O
confocal	O
microscopy	O
image	B
.	O
it	O
also	O
shows	O
the	O
result	O
for	O
an	O
improved	O
version	O
of	O
watershed	B
that	O
uses	O
local	B
morphology	O
to	O
smooth	O
out	O
and	O
optimize	O
the	O
boundaries	O
separating	O
the	O
regions	O
(	O
beare	O
2006	O
)	O
.	O
8	O
a	O
related	O
algorithm	B
can	O
be	O
used	O
to	O
compute	O
maximally	O
stable	O
extremal	O
regions	O
(	O
msers	O
)	O
efﬁciently	O
(	O
sec-	O
tion	B
4.1.1	O
)	O
(	O
nist´er	O
and	O
stew´enius	O
2008	O
)	O
.	O
286	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
5.2.2	O
region	B
splitting	O
(	O
divisive	B
clustering	O
)	O
splitting	B
the	O
image	B
into	O
successively	O
ﬁner	O
regions	O
is	O
one	O
of	O
the	O
oldest	O
techniques	O
in	O
computer	O
vision	O
.	O
ohlander	O
,	O
price	O
,	O
and	O
reddy	O
(	O
1978	O
)	O
present	O
such	O
a	O
technique	O
,	O
which	O
ﬁrst	O
computes	O
a	O
histogram	B
for	O
the	O
whole	O
image	B
and	O
then	O
ﬁnds	O
a	O
threshold	O
that	O
best	O
separates	O
the	O
large	O
peaks	O
in	O
the	O
histogram	B
.	O
this	O
process	O
is	O
repeated	O
until	O
regions	O
are	O
either	O
fairly	O
uniform	O
or	O
below	O
a	O
certain	O
size	O
.	O
more	O
recent	O
splitting	B
algorithms	O
often	O
optimize	O
some	O
metric	O
of	O
intra-region	O
similarity	B
and	O
inter-region	O
dissimilarity	O
.	O
these	O
are	O
covered	O
in	O
sections	O
5.4	O
and	O
5.5	O
.	O
5.2.3	O
region	B
merging	O
(	O
agglomerative	B
clustering	O
)	O
region	B
merging	O
techniques	O
also	O
date	O
back	O
to	O
the	O
beginnings	O
of	O
computer	O
vision	O
.	O
brice	O
and	O
fennema	O
(	O
1970	O
)	O
use	O
a	O
dual	O
grid	O
for	O
representing	O
boundaries	O
between	O
pixels	O
and	O
merge	O
re-	O
gions	O
based	O
on	O
their	O
relative	O
boundary	O
lengths	O
and	O
the	O
strength	O
of	O
the	O
visible	O
edges	O
at	O
these	O
boundaries	O
.	O
in	O
data	O
clustering	O
,	O
algorithms	O
can	O
link	O
clusters	O
together	O
based	O
on	O
the	O
distance	O
between	O
their	O
closest	O
points	B
(	O
single-link	O
clustering	O
)	O
,	O
their	O
farthest	O
points	B
(	O
complete-link	O
clustering	O
)	O
,	O
or	O
something	O
in	O
between	O
(	O
jain	O
,	O
topchy	O
,	O
law	O
et	O
al	O
.	O
2004	O
)	O
.	O
kamvar	O
,	O
klein	O
,	O
and	O
manning	O
(	O
2002	O
)	O
provide	O
a	O
probabilistic	B
interpretation	O
of	O
these	O
algorithms	O
and	O
show	O
how	O
additional	O
models	O
can	O
be	O
incorporated	O
within	O
this	O
framework	O
.	O
a	O
very	O
simple	O
version	O
of	O
pixel-based	O
merging	B
combines	O
adjacent	O
regions	O
whose	O
average	O
color	B
difference	O
is	O
below	O
a	O
threshold	O
or	O
whose	O
regions	O
are	O
too	O
small	O
.	O
segmenting	O
the	O
image	B
into	O
such	O
superpixels	O
(	O
mori	O
,	O
ren	O
,	O
efros	O
et	O
al	O
.	O
2004	O
)	O
,	O
which	O
are	O
not	O
semantically	O
meaningful	O
,	O
can	O
be	O
a	O
useful	O
pre-processing	O
stage	O
to	O
make	O
higher-level	O
algorithms	O
such	O
as	O
stereo	B
matching	I
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
;	O
taguchi	O
,	O
wilburn	O
,	O
and	O
zitnick	O
2008	O
)	O
,	O
optic	O
ﬂow	O
(	O
zitnick	O
,	O
jojic	O
,	O
and	O
kang	O
2005	O
;	O
brox	O
,	O
bregler	O
,	O
and	O
malik	O
2009	O
)	O
,	O
and	O
recognition	B
(	O
mori	O
,	O
ren	O
,	O
efros	O
et	O
al	O
.	O
2004	O
;	O
mori	O
2005	O
;	O
gu	O
,	O
lim	O
,	O
arbelaez	O
et	O
al	O
.	O
2009	O
;	O
lim	O
,	O
arbel´aez	O
,	O
gu	O
et	O
al	O
.	O
2009	O
)	O
both	O
faster	O
and	O
more	O
robust	B
.	O
5.2.4	O
graph-based	B
segmentation	O
while	O
many	O
merging	B
algorithms	O
simply	O
apply	O
a	O
ﬁxed	O
rule	O
that	O
groups	O
pixels	O
and	O
regions	O
together	O
,	O
felzenszwalb	O
and	O
huttenlocher	O
(	O
2004b	O
)	O
present	O
a	O
merging	B
algorithm	O
that	O
uses	O
rel-	O
ative	O
dissimilarities	O
between	O
regions	O
to	O
determine	O
which	O
ones	O
should	O
be	O
merged	O
;	O
it	O
produces	O
an	O
algorithm	B
that	O
provably	O
optimizes	O
a	O
global	B
grouping	O
metric	O
.	O
they	O
start	O
with	O
a	O
pixel-to-	O
pixel	O
dissimilarity	O
measure	O
w	O
(	O
e	O
)	O
that	O
measures	O
,	O
for	O
example	O
,	O
intensity	O
differences	O
between	O
n8	O
neighbors	O
.	O
(	O
alternatively	O
,	O
they	O
can	O
use	O
the	O
joint	B
feature	I
space	I
distances	O
(	O
5.42	O
)	O
introduced	O
by	O
comaniciu	O
and	O
meer	O
(	O
2002	O
)	O
,	O
which	O
we	O
discuss	O
in	O
section	O
5.3.2	O
.	O
)	O
5.2	O
split	O
and	O
merge	O
287	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
5.14	O
graph-based	B
merging	O
segmentation	B
(	O
felzenszwalb	O
and	O
huttenlocher	O
2004b	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
:	O
(	O
a	O
)	O
input	O
grayscale	O
image	B
that	O
is	O
successfully	O
segmented	O
into	O
three	O
regions	O
even	O
though	O
the	O
variation	O
inside	O
the	O
smaller	O
rectangle	O
is	O
larger	O
than	O
the	O
variation	O
across	O
the	O
middle	O
edge	O
;	O
(	O
b	O
)	O
input	O
grayscale	O
image	B
;	O
(	O
c	O
)	O
resulting	O
segmentation	B
using	O
an	O
n8	O
pixel	O
neigh-	O
borhood	O
.	O
for	O
any	O
region	B
r	O
,	O
its	O
internal	O
difference	O
is	O
deﬁned	O
as	O
the	O
largest	O
edge	O
weight	O
in	O
the	O
re-	O
gion	O
’	O
s	O
minimum	O
spanning	O
tree	O
,	O
int	O
(	O
r	O
)	O
=	O
min	O
e∈m	O
st	O
(	O
r	O
)	O
w	O
(	O
e	O
)	O
.	O
(	O
5.20	O
)	O
for	O
any	O
two	O
adjacent	O
regions	O
with	O
at	O
least	O
one	O
edge	O
connecting	O
their	O
vertices	O
,	O
the	O
difference	B
between	O
these	O
regions	O
is	O
deﬁned	O
as	O
the	O
minimum	O
weight	O
edge	O
connecting	O
the	O
two	O
regions	O
,	O
dif	O
(	O
r1	O
,	O
r2	O
)	O
=	O
min	O
e=	O
(	O
v1	O
,	O
v2	O
)	O
|v1∈r1	O
,	O
v2∈r2	O
w	O
(	O
e	O
)	O
.	O
(	O
5.21	O
)	O
their	O
algorithm	B
merges	O
any	O
two	O
adjacent	O
regions	O
whose	O
difference	B
is	O
smaller	O
than	O
the	O
mini-	O
mum	O
internal	O
difference	O
of	O
these	O
two	O
regions	O
,	O
mint	O
(	O
r1	O
,	O
r2	O
)	O
=	O
min	O
(	O
int	O
(	O
r1	O
)	O
+	O
τ	O
(	O
r1	O
)	O
,	O
int	O
(	O
r2	O
)	O
+	O
τ	O
(	O
r2	O
)	O
)	O
,	O
(	O
5.22	O
)	O
where	O
τ	O
(	O
r	O
)	O
is	O
a	O
heuristic	O
region	B
penalty	O
that	O
felzenszwalb	O
and	O
huttenlocher	O
(	O
2004b	O
)	O
set	O
to	O
k/|r|	O
,	O
but	O
which	O
can	O
be	O
set	O
to	O
any	O
application-speciﬁc	O
measure	O
of	O
region	B
goodness	O
.	O
by	O
merging	O
regions	O
in	O
decreasing	O
order	B
of	O
the	O
edges	O
separating	O
them	O
(	O
which	O
can	O
be	O
efﬁ-	O
ciently	O
evaluated	O
using	O
a	O
variant	O
of	O
kruskal	O
’	O
s	O
minimum	O
spanning	O
tree	O
algorithm	B
)	O
,	O
they	O
prov-	O
ably	O
produce	O
segmentations	O
that	O
are	O
neither	O
too	O
ﬁne	O
(	O
there	O
exist	O
regions	O
that	O
could	O
have	O
been	O
merged	O
)	O
nor	O
too	O
coarse	O
(	O
there	O
are	O
regions	O
that	O
could	O
be	O
split	O
without	O
being	O
mergeable	O
)	O
.	O
for	O
ﬁxed-size	O
pixel	O
neighborhoods	O
,	O
the	O
running	O
time	O
for	O
this	O
algorithm	B
is	O
o	O
(	O
n	O
log	O
n	O
)	O
,	O
where	O
n	O
is	O
the	O
number	O
of	O
image	B
pixels	O
,	O
which	O
makes	O
it	O
one	O
of	O
the	O
fastest	O
segmentation	B
algorithms	O
(	O
paris	O
and	O
durand	O
2007	O
)	O
.	O
figure	O
5.14	O
shows	O
two	O
examples	O
of	O
images	O
segmented	O
using	O
their	O
technique	O
.	O
288	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
5.15	O
coarse	O
to	O
ﬁne	O
node	O
aggregation	O
in	O
segmentation	B
by	O
weighted	O
aggregation	O
(	O
swa	O
)	O
(	O
sharon	O
,	O
galun	O
,	O
sharon	O
et	O
al	O
.	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
macmillan	O
publishers	O
ltd	O
[	O
nature	O
]	O
:	O
(	O
a	O
)	O
original	O
gray-level	O
pixel	O
grid	O
;	O
(	O
b	O
)	O
inter-pixel	O
couplings	O
,	O
where	O
thicker	O
lines	B
indicate	O
stronger	O
couplings	O
;	O
(	O
c	O
)	O
after	O
one	O
level	O
of	O
coarsening	O
,	O
where	O
each	O
original	O
pixel	O
is	O
strongly	O
coupled	O
to	O
one	O
of	O
the	O
coarse-level	O
nodes	O
;	O
(	O
d	O
)	O
after	O
two	O
levels	O
of	O
coarsening	O
.	O
5.2.5	O
probabilistic	B
aggregation	I
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
(	O
2007	O
)	O
develop	O
a	O
probabilistic	B
merging	O
algorithm	B
based	O
on	O
two	O
cues	O
,	O
namely	O
gray-level	O
similarity	B
and	O
texture	B
similarity	O
.	O
the	O
gray-level	O
similarity	B
between	O
regions	O
ri	O
and	O
rj	O
is	O
based	O
on	O
the	O
minimal	O
external	O
difference	B
from	O
other	O
neighboring	O
regions	O
,	O
local	B
=	O
min	O
(	O
∆+	O
σ+	O
i	O
,	O
∆+	O
j	O
)	O
,	O
(	O
5.23	O
)	O
where	O
∆+	O
and	O
rk	O
.	O
this	O
is	O
compared	O
to	O
the	O
average	O
intensity	O
difference	B
,	O
i	O
=	O
mink	O
|∆ik|	O
and	O
∆ik	O
is	O
the	O
difference	B
in	O
average	O
intensities	O
between	O
regions	O
ri	O
σ−local	O
=	O
∆−i	O
+	O
∆−j	O
2	O
,	O
(	O
5.24	O
)	O
where	O
∆−i	O
=	O
(	O
cid:80	O
)	O
k	O
(	O
τik∆ik	O
)	O
/	O
(	O
cid:80	O
)	O
k	O
(	O
τik	O
)	O
and	O
τik	O
is	O
the	O
boundary	O
length	O
between	O
regions	O
ri	O
and	O
rk	O
.	O
the	O
texture	B
similarity	O
is	O
deﬁned	O
using	O
relative	O
differences	O
between	O
histogram	B
bins	O
of	O
simple	O
oriented	B
sobel	O
ﬁlter	O
responses	O
.	O
the	O
pairwise	O
statistics	O
σ+	O
local	B
and	O
σ−local	O
are	O
used	O
to	O
compute	O
the	O
likelihoods	O
pij	O
that	O
two	O
regions	O
should	O
be	O
merged	O
.	O
(	O
see	O
the	O
paper	O
by	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
(	O
2007	O
)	O
for	O
more	O
details	O
.	O
)	O
merging	B
proceeds	O
in	O
a	O
hierarchical	B
fashion	O
inspired	O
by	O
algebraic	O
multigrid	O
techniques	O
(	O
brandt	O
1986	O
;	O
briggs	O
,	O
henson	O
,	O
and	O
mccormick	O
2000	O
)	O
and	O
previously	O
used	O
by	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
(	O
2007	O
)	O
in	O
their	O
segmentation	B
by	O
weighted	O
aggregation	O
(	O
swa	O
)	O
algorithm	B
(	O
sharon	O
,	O
galun	O
,	O
sharon	O
et	O
al	O
.	O
2006	O
)	O
,	O
which	O
we	O
discuss	O
in	O
section	O
5.4.	O
a	O
subset	O
of	O
the	O
nodes	O
c	O
⊂	O
v	O
that	O
are	O
(	O
collectively	O
)	O
strongly	O
coupled	O
to	O
all	O
of	O
the	O
original	O
nodes	O
(	O
regions	O
)	O
are	O
used	O
to	O
deﬁne	O
the	O
problem	O
at	O
a	O
coarser	O
scale	O
(	O
figure	O
5.15	O
)	O
,	O
where	O
strong	O
coupling	O
is	O
deﬁned	O
as	O
(	O
cid:80	O
)	O
j∈c	O
pij	O
(	O
cid:80	O
)	O
j∈v	O
pij	O
>	O
φ	O
,	O
(	O
5.25	O
)	O
5.3	O
mean	B
shift	I
and	O
mode	O
ﬁnding	O
289	O
with	O
φ	O
usually	O
set	O
to	O
0.2.	O
the	O
intensity	O
and	O
texture	B
similarity	O
statistics	O
for	O
the	O
coarser	O
nodes	O
are	O
recursively	O
computed	O
using	O
weighted	O
averaging	O
,	O
where	O
the	O
relative	O
strengths	O
(	O
couplings	O
)	O
between	O
coarse-	O
and	O
ﬁne-level	O
nodes	O
are	O
based	O
on	O
their	O
merge	O
probabilities	O
pij	O
.	O
this	O
allows	O
the	O
algorithm	B
to	O
run	O
in	O
essentially	O
o	O
(	O
n	O
)	O
time	O
,	O
using	O
the	O
same	O
kind	O
of	O
hierarchical	B
aggrega-	O
tion	B
operations	O
that	O
are	O
used	O
in	O
pyramid-based	O
ﬁltering	O
or	O
preconditioning	O
algorithms	O
.	O
after	O
a	O
segmentation	B
has	O
been	O
identiﬁed	O
at	O
a	O
coarser	O
level	O
,	O
the	O
exact	O
memberships	O
of	O
each	O
pixel	O
are	O
computed	O
by	O
propagating	O
coarse-level	O
assignments	O
to	O
their	O
ﬁner-level	O
“	O
children	O
”	O
(	O
sharon	O
,	O
galun	O
,	O
sharon	O
et	O
al	O
.	O
2006	O
;	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
2007	O
)	O
.	O
figure	O
5.22	O
shows	O
the	O
segmen-	O
tations	O
produced	O
by	O
this	O
algorithm	B
compared	O
to	O
other	O
popular	O
segmentation	B
algorithms	O
.	O
5.3	O
mean	B
shift	I
and	O
mode	O
ﬁnding	O
mean-shift	O
and	O
mode	O
ﬁnding	O
techniques	O
,	O
such	O
as	O
k-means	B
and	O
mixtures	O
of	O
gaussians	O
,	O
model	O
the	O
feature	B
vectors	O
associated	O
with	O
each	O
pixel	O
(	O
e.g.	O
,	O
color	B
and	O
position	O
)	O
as	O
samples	O
from	O
an	O
unknown	O
probability	O
density	O
function	O
and	O
then	O
try	O
to	O
ﬁnd	O
clusters	O
(	O
modes	O
)	O
in	O
this	O
distribution	O
.	O
consider	O
the	O
color	B
image	O
shown	O
in	O
figure	O
5.16a	O
.	O
how	O
would	O
you	O
segment	O
this	O
image	B
based	O
on	O
color	B
alone	O
?	O
figure	O
5.16b	O
shows	O
the	O
distribution	O
of	O
pixels	O
in	O
l*u*v*	O
space	O
,	O
which	O
is	O
equivalent	O
to	O
what	O
a	O
vision	O
algorithm	B
that	O
ignores	O
spatial	O
location	O
would	O
see	O
.	O
to	O
make	O
the	O
visualization	O
simpler	O
,	O
let	O
us	O
only	O
consider	O
the	O
l*u*	O
coordinates	O
,	O
as	O
shown	O
in	O
figure	O
5.16c	O
.	O
how	O
many	O
obvious	O
(	O
elongated	O
)	O
clusters	O
do	O
you	O
see	O
?	O
how	O
would	O
you	O
go	O
about	O
ﬁnding	O
these	O
clusters	O
?	O
the	O
k-means	B
and	O
mixtures	O
of	O
gaussians	O
techniques	O
use	O
a	O
parametric	B
model	O
of	O
the	O
den-	O
sity	O
function	O
to	O
answer	O
this	O
question	O
,	O
i.e.	O
,	O
they	O
assume	O
the	O
density	O
is	O
the	O
superposition	B
of	O
a	O
small	O
number	O
of	O
simpler	O
distributions	O
(	O
e.g.	O
,	O
gaussians	O
)	O
whose	O
locations	O
(	O
centers	O
)	O
and	O
shape	O
(	O
covariance	O
)	O
can	O
be	O
estimated	O
.	O
mean	B
shift	I
,	O
on	O
the	O
other	O
hand	O
,	O
smoothes	O
the	O
distribution	O
and	O
ﬁnds	O
its	O
peaks	O
as	O
well	O
as	O
the	O
regions	O
of	O
feature	B
space	O
that	O
correspond	O
to	O
each	O
peak	O
.	O
since	O
a	O
complete	O
density	O
is	O
being	O
modeled	O
,	O
this	O
approach	O
is	O
called	O
non-parametric	B
(	O
bishop	O
2006	O
)	O
.	O
let	O
us	O
look	O
at	O
these	O
techniques	O
in	O
more	O
detail	O
.	O
5.3.1	O
k-means	B
and	O
mixtures	O
of	O
gaussians	O
while	O
k-means	B
implicitly	O
models	O
the	O
probability	O
density	O
as	O
a	O
superposition	B
of	O
spherically	O
symmetric	O
distributions	O
,	O
it	O
does	O
not	O
require	O
any	O
probabilistic	B
reasoning	O
or	O
modeling	B
(	O
bishop	O
2006	O
)	O
.	O
instead	O
,	O
the	O
algorithm	B
is	O
given	O
the	O
number	O
of	O
clusters	O
k	O
it	O
is	O
supposed	O
to	O
ﬁnd	O
;	O
it	O
then	O
iteratively	O
updates	O
the	O
cluster	O
center	O
location	O
based	O
on	O
the	O
samples	O
that	O
are	O
closest	O
to	O
each	O
center	O
.	O
the	O
algorithm	B
can	O
be	O
initialized	O
by	O
randomly	O
sampling	B
k	O
centers	O
from	O
the	O
input	O
feature	B
vectors	O
.	O
techniques	O
have	O
also	O
been	O
developed	O
for	O
splitting	O
or	O
merging	B
cluster	O
centers	O
290	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
5.16	O
mean-shift	O
image	B
segmentation	O
(	O
comaniciu	O
and	O
meer	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
ieee	O
:	O
(	O
a	O
)	O
input	O
color	B
image	O
;	O
(	O
b	O
)	O
pixels	O
plotted	O
in	O
l*u*v*	O
space	O
;	O
(	O
c	O
)	O
l*u*	O
space	O
distribution	O
;	O
(	O
d	O
)	O
clustered	O
results	O
after	O
159	O
mean-shift	O
procedures	O
;	O
(	O
e	O
)	O
corresponding	O
trajectories	O
with	O
peaks	O
marked	O
as	O
red	O
dots	O
.	O
5.3	O
mean	B
shift	I
and	O
mode	O
ﬁnding	O
291	O
based	O
on	O
their	O
statistics	O
,	O
and	O
for	O
accelerating	O
the	O
process	O
of	O
ﬁnding	O
the	O
nearest	O
mean	O
center	O
(	O
bishop	O
2006	O
)	O
.	O
in	O
mixtures	O
of	O
gaussians	O
,	O
each	O
cluster	O
center	O
is	O
augmented	O
by	O
a	O
covariance	O
matrix	O
whose	O
values	O
are	O
re-estimated	O
from	O
the	O
corresponding	O
samples	O
.	O
instead	O
of	O
using	O
nearest	O
neighbors	O
to	O
associate	O
input	O
samples	O
with	O
cluster	O
centers	O
,	O
a	O
mahalanobis	O
distance	O
(	O
appendix	O
b.1.1	O
)	O
is	O
used	O
:	O
d	O
(	O
xi	O
,	O
µk	O
;	O
σk	O
)	O
=	O
(	O
cid:107	O
)	O
xi	O
−	O
µk	O
(	O
cid:107	O
)	O
σ−1	O
k	O
=	O
(	O
xi	O
−	O
µk	O
)	O
t	O
σ−1	O
k	O
(	O
xi	O
−	O
µk	O
)	O
(	O
5.26	O
)	O
where	O
xi	O
are	O
the	O
input	O
samples	O
,	O
µk	O
are	O
the	O
cluster	O
centers	O
,	O
and	O
σk	O
are	O
their	O
covariance	O
es-	O
timates	O
.	O
samples	O
can	O
be	O
associated	O
with	O
the	O
nearest	O
cluster	O
center	O
(	O
a	O
hard	O
assignment	O
of	O
membership	O
)	O
or	O
can	O
be	O
softly	O
assigned	O
to	O
several	O
nearby	O
clusters	O
.	O
this	O
latter	O
,	O
more	O
commonly	O
used	O
,	O
approach	O
corresponds	O
to	O
iteratively	O
re-estimating	O
the	O
parameters	B
for	O
a	O
mixture	O
of	O
gaussians	O
density	O
function	O
,	O
p	O
(	O
x|	O
{	O
πk	O
,	O
µk	O
,	O
σk	O
}	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
πk	O
n	O
(	O
x|µk	O
,	O
σk	O
)	O
,	O
(	O
5.27	O
)	O
where	O
πk	O
are	O
the	O
mixing	O
coefﬁcients	O
,	O
µk	O
and	O
σk	O
are	O
the	O
gaussian	O
means	O
and	O
covariances	O
,	O
and	O
1	O
|σk|	O
is	O
the	O
normal	O
(	O
gaussian	O
)	O
distribution	O
(	O
bishop	O
2006	O
)	O
.	O
n	O
(	O
x|µk	O
,	O
σk	O
)	O
=	O
e−d	O
(	O
x	O
,	O
µk	O
;	O
σk	O
)	O
(	O
5.28	O
)	O
to	O
iteratively	O
compute	O
(	O
a	O
local	B
)	O
maximum	O
likely	O
estimate	O
for	O
the	O
unknown	O
mixture	O
pa-	O
rameters	O
{	O
πk	O
,	O
µk	O
,	O
σk	O
}	O
,	O
the	O
expectation	O
maximization	O
(	O
em	O
)	O
algorithm	B
(	O
dempster	O
,	O
laird	O
,	O
and	O
rubin	O
1977	O
)	O
proceeds	O
in	O
two	O
alternating	O
stages	O
:	O
1.	O
the	O
expectation	O
stage	O
(	O
e	O
step	O
)	O
estimates	O
the	O
responsibilities	O
zik	O
=	O
1	O
zi	O
πk	O
n	O
(	O
x|µk	O
,	O
σk	O
)	O
with	O
(	O
cid:88	O
)	O
k	O
zik	O
=	O
1	O
,	O
(	O
5.29	O
)	O
which	O
are	O
the	O
estimates	O
of	O
how	O
likely	O
a	O
sample	O
xi	O
was	O
generated	O
from	O
the	O
kth	O
gaussian	O
cluster	O
.	O
2.	O
the	O
maximization	O
stage	O
(	O
m	O
step	O
)	O
updates	O
the	O
parameter	O
values	O
µk	O
=	O
σk	O
=	O
1	O
nk	O
(	O
cid:88	O
)	O
i	O
nk	O
(	O
cid:88	O
)	O
i	O
1	O
πk	O
=	O
nk	O
n	O
,	O
zikxi	O
,	O
zik	O
(	O
xi	O
−	O
µk	O
)	O
(	O
xi	O
−	O
µk	O
)	O
t	O
,	O
(	O
5.30	O
)	O
(	O
5.31	O
)	O
(	O
5.32	O
)	O
292	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
where	O
nk	O
=	O
(	O
cid:88	O
)	O
i	O
zik	O
.	O
(	O
5.33	O
)	O
is	O
an	O
estimate	O
of	O
the	O
number	O
of	O
sample	O
points	B
assigned	O
to	O
each	O
cluster	O
.	O
bishop	O
(	O
2006	O
)	O
has	O
a	O
wonderful	O
exposition	O
of	O
both	O
mixture	O
of	O
gaussians	O
estimation	B
and	O
the	O
more	O
general	O
topic	O
of	O
expectation	O
maximization	O
.	O
in	O
the	O
context	B
of	O
image	B
segmentation	O
,	O
ma	O
,	O
derksen	O
,	O
hong	O
et	O
al	O
.	O
(	O
2007	O
)	O
present	O
a	O
nice	O
review	O
of	O
segmentation	B
using	O
mixtures	O
of	O
gaussians	O
and	O
develop	O
their	O
own	O
extension	O
based	O
on	O
minimum	O
description	O
length	O
(	O
mdl	O
)	O
coding	O
,	O
which	O
they	O
show	O
produces	O
good	O
results	O
on	O
the	O
berkeley	O
segmentation	B
database	O
.	O
5.3.2	O
mean	B
shift	I
while	O
k-means	B
and	O
mixtures	O
of	O
gaussians	O
use	O
a	O
parametric	B
form	O
to	O
model	O
the	O
probability	O
den-	O
sity	O
function	O
being	O
segmented	O
,	O
mean	B
shift	I
implicitly	O
models	O
this	O
distribution	O
using	O
a	O
smooth	O
continuous	O
non-parametric	B
model	O
.	O
the	O
key	O
to	O
mean	B
shift	I
is	O
a	O
technique	O
for	O
efﬁciently	O
ﬁnd-	O
ing	O
peaks	O
in	O
this	O
high-dimensional	O
data	O
distribution	O
without	O
ever	O
computing	O
the	O
complete	O
function	O
explicitly	O
(	O
fukunaga	O
and	O
hostetler	O
1975	O
;	O
cheng	O
1995	O
;	O
comaniciu	O
and	O
meer	O
2002	O
)	O
.	O
consider	O
once	O
again	O
the	O
data	O
points	O
shown	O
in	O
figure	O
5.16c	O
,	O
which	O
can	O
be	O
thought	O
of	O
as	O
having	O
been	O
drawn	O
from	O
some	O
probability	O
density	O
function	O
.	O
if	O
we	O
could	O
compute	O
this	O
density	O
function	O
,	O
as	O
visualized	O
in	O
figure	O
5.16e	O
,	O
we	O
could	O
ﬁnd	O
its	O
major	O
peaks	O
(	O
modes	O
)	O
and	O
identify	O
regions	O
of	O
the	O
input	O
space	O
that	O
climb	O
to	O
the	O
same	O
peak	O
as	O
being	O
part	O
of	O
the	O
same	O
region	B
.	O
this	O
is	O
the	O
inverse	B
of	O
the	O
watershed	B
algorithm	O
described	O
in	O
section	O
5.2.1	O
,	O
which	O
climbs	O
downhill	O
to	O
ﬁnd	O
basins	B
of	O
attraction	O
.	O
the	O
ﬁrst	O
question	O
,	O
then	O
,	O
is	O
how	O
to	O
estimate	O
the	O
density	O
function	O
given	O
a	O
sparse	B
set	O
of	O
samples	O
.	O
one	O
of	O
the	O
simplest	O
approaches	O
is	O
to	O
just	O
smooth	O
the	O
data	O
,	O
e.g.	O
,	O
by	O
convolving	O
it	O
with	O
a	O
ﬁxed	O
kernel	O
of	O
width	O
h	O
,	O
f	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
k	O
(	O
x	O
−	O
xi	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
k	O
(	O
cid:18	O
)	O
(	O
cid:107	O
)	O
x	O
−	O
xi	O
(	O
cid:107	O
)	O
2	O
h2	O
(	O
cid:19	O
)	O
,	O
(	O
5.34	O
)	O
where	O
xi	O
are	O
the	O
input	O
samples	O
and	O
k	O
(	O
r	O
)	O
is	O
the	O
kernel	B
function	O
(	O
or	O
parzen	O
window	O
)	O
.9	O
this	O
approach	O
is	O
known	O
as	O
kernel	B
density	O
estimation	B
or	O
the	O
parzen	O
window	O
technique	O
(	O
duda	O
,	O
hart	O
,	O
and	O
stork	O
2001	O
,	O
section	O
4.3	O
;	O
bishop	O
2006	O
,	O
section	O
2.5.1	O
)	O
.	O
once	O
we	O
have	O
computed	O
f	O
(	O
x	O
)	O
,	O
as	O
shown	O
in	O
figures	O
5.16e	O
and	O
5.17	O
,	O
we	O
can	O
ﬁnd	O
its	O
local	B
maxima	O
using	O
gradient	O
ascent	O
or	O
some	O
other	O
optimization	O
technique	O
.	O
9	O
in	O
this	O
simpliﬁed	O
formula	O
,	O
a	O
euclidean	O
metric	O
is	O
used	O
.	O
we	O
discuss	O
a	O
little	O
later	O
(	O
5.42	O
)	O
how	O
to	O
generalize	O
this	O
to	O
non-uniform	O
(	O
scaled	O
or	O
oriented	B
)	O
metrics	O
.	O
note	O
also	O
that	O
this	O
distribution	O
may	O
not	O
be	O
proper	O
,	O
i.e.	O
,	O
integrate	O
to	O
1.	O
since	O
we	O
are	O
looking	O
for	O
maxima	O
in	O
the	O
density	O
,	O
this	O
does	O
not	O
matter	O
.	O
5.3	O
mean	B
shift	I
and	O
mode	O
ﬁnding	O
293	O
figure	O
5.17	O
one-dimensional	O
visualization	O
of	O
the	O
kernel	B
density	O
estimate	O
,	O
its	O
derivative	O
,	O
and	O
a	O
mean	B
shift	I
.	O
the	O
kernel	B
density	O
estimate	O
f	O
(	O
x	O
)	O
is	O
obtained	O
by	O
convolving	O
the	O
sparse	B
set	O
of	O
input	O
samples	O
xi	O
with	O
the	O
kernel	B
function	O
k	O
(	O
x	O
)	O
.	O
the	O
derivative	O
of	O
this	O
function	O
,	O
f	O
(	O
cid:48	O
)	O
(	O
x	O
)	O
,	O
can	O
be	O
obtained	O
by	O
convolving	O
the	O
inputs	O
with	O
the	O
derivative	O
kernel	B
g	O
(	O
x	O
)	O
.	O
estimating	O
the	O
local	B
displacement	O
vectors	O
around	O
a	O
current	O
estimate	O
xk	O
results	O
in	O
the	O
mean-shift	O
vector	O
m	O
(	O
xk	O
)	O
,	O
which	O
,	O
in	O
a	O
multi-dimensional	O
setting	O
,	O
point	O
in	O
the	O
same	O
direction	O
as	O
the	O
function	O
gradient	O
∇f	O
(	O
xk	O
)	O
.	O
the	O
red	O
dots	O
indicate	O
local	B
maxima	O
in	O
f	O
(	O
x	O
)	O
to	O
which	O
the	O
mean	O
shifts	O
converge	O
.	O
the	O
problem	O
with	O
this	O
“	O
brute	O
force	O
”	O
approach	O
is	O
that	O
,	O
for	O
higher	O
dimensions	O
,	O
it	O
becomes	O
computationally	O
prohibitive	O
to	O
evaluate	O
f	O
(	O
x	O
)	O
over	O
the	O
complete	O
search	O
space.10	O
instead	O
,	O
mean	B
shift	I
uses	O
a	O
variant	O
of	O
what	O
is	O
known	O
in	O
the	O
optimization	O
literature	O
as	O
multiple	B
restart	O
gradient	B
descent	I
.	O
starting	O
at	O
some	O
guess	O
for	O
a	O
local	B
maximum	O
,	O
yk	O
,	O
which	O
can	O
be	O
a	O
random	O
input	O
data	O
point	O
xi	O
,	O
mean	B
shift	I
computes	O
the	O
gradient	O
of	O
the	O
density	O
estimate	O
f	O
(	O
x	O
)	O
at	O
yk	O
and	O
takes	O
an	O
uphill	O
step	O
in	O
that	O
direction	O
(	O
figure	O
5.17	O
)	O
.	O
the	O
gradient	O
of	O
f	O
(	O
x	O
)	O
is	O
given	O
by	O
∇f	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
xi	O
−	O
x	O
)	O
g	O
(	O
x	O
−	O
xi	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
g	O
(	O
r	O
)	O
=	O
−k	O
(	O
cid:48	O
)	O
(	O
r	O
)	O
,	O
where	O
(	O
xi	O
−	O
x	O
)	O
g	O
(	O
cid:18	O
)	O
(	O
cid:107	O
)	O
x	O
−	O
xi	O
(	O
cid:107	O
)	O
2	O
h2	O
(	O
cid:19	O
)	O
,	O
(	O
5.35	O
)	O
(	O
5.36	O
)	O
and	O
k	O
(	O
cid:48	O
)	O
(	O
r	O
)	O
is	O
the	O
ﬁrst	O
derivative	O
of	O
k	O
(	O
r	O
)	O
.	O
we	O
can	O
re-write	O
the	O
gradient	O
of	O
the	O
density	O
function	O
as	O
where	O
the	O
vector	O
g	O
(	O
x	O
−	O
xi	O
)	O
(	O
cid:35	O
)	O
m	O
(	O
x	O
)	O
,	O
∇f	O
(	O
x	O
)	O
=	O
(	O
cid:34	O
)	O
(	O
cid:88	O
)	O
i	O
m	O
(	O
x	O
)	O
=	O
(	O
cid:80	O
)	O
i	O
xig	O
(	O
x	O
−	O
xi	O
)	O
(	O
cid:80	O
)	O
i	O
g	O
(	O
x	O
−	O
xi	O
)	O
−	O
x	O
(	O
5.37	O
)	O
(	O
5.38	O
)	O
is	O
called	O
the	O
mean	B
shift	I
,	O
since	O
it	O
is	O
the	O
difference	B
between	O
the	O
weighted	B
mean	O
of	O
the	O
neighbors	O
xi	O
around	O
x	O
and	O
the	O
current	O
value	O
of	O
x	O
.	O
10	O
even	O
for	O
one	O
dimension	O
,	O
if	O
the	O
space	O
is	O
extremely	O
sparse	B
,	O
it	O
may	O
be	O
inefﬁcient	O
.	O
xf	O
(	O
x	O
)	O
xik	O
(	O
x	O
)	O
g	O
(	O
x	O
)	O
f	O
'	O
(	O
xk	O
)	O
xkm	O
(	O
xk	O
)	O
294	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
in	O
the	O
mean-shift	O
procedure	O
,	O
the	O
current	O
estimate	O
of	O
the	O
mode	O
yk	O
at	O
iteration	O
k	O
is	O
replaced	O
by	O
its	O
locally	O
weighted	O
mean	O
,	O
yk+1	O
=	O
yk	O
+	O
m	O
(	O
yk	O
)	O
=	O
(	O
cid:80	O
)	O
i	O
xig	O
(	O
yk	O
−	O
xi	O
)	O
(	O
cid:80	O
)	O
i	O
g	O
(	O
yk	O
−	O
xi	O
)	O
.	O
comaniciu	O
and	O
meer	O
(	O
2002	O
)	O
prove	O
that	O
this	O
algorithm	B
converges	O
to	O
a	O
local	B
maximum	O
of	O
f	O
(	O
x	O
)	O
under	O
reasonably	O
weak	O
conditions	O
on	O
the	O
kernel	B
k	O
(	O
r	O
)	O
,	O
i.e.	O
,	O
that	O
it	O
is	O
monotonically	O
decreasing	O
.	O
this	O
convergence	O
is	O
not	O
guaranteed	O
for	O
regular	O
gradient	B
descent	I
unless	O
appropriate	O
step	O
size	O
control	O
is	O
used	O
.	O
the	O
two	O
kernels	O
that	O
comaniciu	O
and	O
meer	O
(	O
2002	O
)	O
studied	O
are	O
the	O
epanechnikov	O
kernel	B
,	O
(	O
5.39	O
)	O
(	O
5.40	O
)	O
(	O
5.41	O
)	O
which	O
is	O
a	O
radial	B
generalization	O
of	O
a	O
bilinear	B
kernel	O
,	O
and	O
the	O
gaussian	O
(	O
normal	O
)	O
kernel	B
,	O
ke	O
(	O
r	O
)	O
=	O
max	O
(	O
0	O
,	O
1	O
−	O
r	O
)	O
,	O
2	O
r	O
(	O
cid:19	O
)	O
.	O
kn	O
(	O
r	O
)	O
=	O
exp	O
(	O
cid:18	O
)	O
−	O
1	O
the	O
corresponding	O
derivative	O
kernels	O
g	O
(	O
r	O
)	O
are	O
a	O
unit	O
ball	O
and	O
another	O
gaussian	O
,	O
respectively	O
.	O
using	O
the	O
epanechnikov	O
kernel	B
converges	O
in	O
a	O
ﬁnite	O
number	O
of	O
steps	O
,	O
while	O
the	O
gaussian	O
kernel	B
has	O
a	O
smoother	O
trajectory	O
(	O
and	O
produces	O
better	O
results	O
)	O
,	O
but	O
converges	O
very	O
slowly	O
near	O
a	O
mode	O
(	O
exercise	O
5.5	O
)	O
.	O
the	O
simplest	O
way	O
to	O
apply	O
mean	B
shift	I
is	O
to	O
start	O
a	O
separate	O
mean-shift	O
mode	O
estimate	O
y	O
at	O
every	O
input	O
point	O
xi	O
and	O
to	O
iterate	O
for	O
a	O
ﬁxed	O
number	O
of	O
steps	O
or	O
until	O
the	O
mean-shift	O
magnitude	O
is	O
below	O
a	O
threshold	O
.	O
a	O
faster	O
approach	O
is	O
to	O
randomly	O
subsample	O
the	O
input	O
points	B
xi	O
and	O
to	O
keep	O
track	O
of	O
each	O
point	O
’	O
s	O
temporal	O
evolution	B
.	O
the	O
remaining	O
points	B
can	O
then	O
be	O
classiﬁed	O
based	O
on	O
the	O
nearest	O
evolution	O
path	O
(	O
comaniciu	O
and	O
meer	O
2002	O
)	O
.	O
paris	O
and	O
durand	O
(	O
2007	O
)	O
review	O
a	O
number	O
of	O
other	O
more	O
efﬁcient	O
implementations	O
of	O
mean	B
shift	I
,	O
including	O
their	O
own	O
approach	O
,	O
which	O
is	O
based	O
on	O
using	O
an	O
efﬁcient	O
low-resolution	O
estimate	O
of	O
the	O
complete	O
multi-dimensional	O
space	O
of	O
f	O
(	O
x	O
)	O
along	O
with	O
its	O
stationary	O
points	B
.	O
the	O
color-based	O
segmentation	B
shown	O
in	O
figure	O
5.16	O
only	O
looks	O
at	O
pixel	O
colors	O
when	O
deter-	O
mining	O
the	O
best	O
clustering	O
.	O
it	O
may	O
therefore	O
cluster	O
together	O
small	O
isolated	O
pixels	O
that	O
happen	O
to	O
have	O
the	O
same	O
color	B
,	O
which	O
may	O
not	O
correspond	O
to	O
a	O
semantically	O
meaningful	O
segmentation	B
of	O
the	O
image	B
.	O
better	O
results	O
can	O
usually	O
be	O
obtained	O
by	O
clustering	O
in	O
the	O
joint	B
domain	O
of	O
color	B
and	O
lo-	O
cation	O
.	O
in	O
this	O
approach	O
,	O
the	O
spatial	O
coordinates	O
of	O
the	O
image	B
xs	O
=	O
(	O
x	O
,	O
y	O
)	O
,	O
which	O
are	O
called	O
the	O
spatial	O
domain	O
,	O
are	O
concatenated	O
with	O
the	O
color	B
values	O
xr	O
,	O
which	O
are	O
known	O
as	O
the	O
range	O
domain	O
,	O
and	O
mean-shift	O
clustering	O
is	O
applied	O
in	O
this	O
ﬁve-dimensional	O
space	O
xj	O
.	O
since	O
location	O
and	O
color	B
may	O
have	O
different	O
scales	O
,	O
the	O
kernels	O
are	O
adjusted	O
accordingly	O
,	O
i.e.	O
,	O
we	O
use	O
a	O
kernel	B
of	O
the	O
form	O
k	O
(	O
xj	O
)	O
=	O
k	O
(	O
cid:18	O
)	O
(	O
cid:107	O
)	O
xr	O
(	O
cid:107	O
)	O
2	O
r	O
(	O
cid:19	O
)	O
k	O
(	O
cid:18	O
)	O
(	O
cid:107	O
)	O
xs	O
(	O
cid:107	O
)	O
2	O
s	O
(	O
cid:19	O
)	O
,	O
h2	O
h2	O
(	O
5.42	O
)	O
5.3	O
mean	B
shift	I
and	O
mode	O
ﬁnding	O
295	O
figure	O
5.18	O
mean-shift	O
color	B
image	O
segmentation	B
with	O
parameters	B
(	O
hs	O
,	O
hr	O
,	O
m	O
)	O
=	O
(	O
16	O
,	O
19	O
,	O
40	O
)	O
(	O
comaniciu	O
and	O
meer	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
ieee	O
.	O
where	O
separate	O
parameters	B
hs	O
and	O
hr	O
are	O
used	O
to	O
control	O
the	O
spatial	O
and	O
range	O
bandwidths	O
of	O
the	O
ﬁlter	O
kernels	O
.	O
figure	O
5.18	O
shows	O
an	O
example	O
of	O
mean-shift	O
clustering	O
in	O
the	O
joint	B
domain	O
,	O
with	O
parameters	O
(	O
hs	O
,	O
hr	O
,	O
m	O
)	O
=	O
(	O
16	O
,	O
19	O
,	O
40	O
)	O
,	O
where	O
spatial	O
regions	O
containing	O
less	O
than	O
m	O
pixels	O
are	O
eliminated	O
.	O
the	O
form	O
of	O
the	O
joint	B
domain	O
ﬁlter	O
kernel	B
(	O
5.42	O
)	O
is	O
reminiscent	O
of	O
the	O
bilateral	B
ﬁlter	I
kernel	O
(	O
3.34–3.37	O
)	O
discussed	O
in	O
section	O
3.3.1.	O
the	O
difference	B
between	O
mean	B
shift	I
and	O
bilateral	B
ﬁl-	O
tering	O
,	O
however	O
,	O
is	O
that	O
in	O
mean	B
shift	I
the	O
spatial	O
coordinates	O
of	O
each	O
pixel	O
are	O
adjusted	O
along	O
with	O
its	O
color	B
values	O
,	O
so	O
that	O
the	O
pixel	O
migrates	O
more	O
quickly	O
towards	O
other	O
pixels	O
with	O
similar	O
colors	O
,	O
and	O
can	O
therefore	O
later	O
be	O
used	O
for	O
clustering	O
and	O
segmentation	B
.	O
determining	O
the	O
best	O
bandwidth	O
parameters	O
h	O
to	O
use	O
with	O
mean	O
shift	O
remains	O
something	O
of	O
an	O
art	O
,	O
although	O
a	O
number	O
of	O
approaches	O
have	O
been	O
explored	O
.	O
these	O
include	O
optimizing	O
the	O
bias–variance	O
tradeoff	O
,	O
looking	O
for	O
parameter	O
ranges	O
where	O
the	O
number	O
of	O
clusters	O
varies	O
slowly	O
,	O
optimizing	O
some	O
external	O
clustering	O
criterion	O
,	O
or	O
using	O
top-down	O
(	O
application	O
domain	O
)	O
knowledge	O
(	O
comaniciu	O
and	O
meer	O
2003	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
change	O
the	O
orientation	O
of	O
the	O
kernel	B
in	O
joint	B
parameter	O
space	O
for	O
applications	O
such	O
as	O
spatio-temporal	O
(	O
video	B
)	O
segmentations	O
(	O
wang	O
,	O
thiesson	O
,	O
xu	O
et	O
al	O
.	O
2004	O
)	O
.	O
mean	B
shift	I
has	O
been	O
applied	O
to	O
a	O
number	O
of	O
different	O
problems	O
in	O
computer	O
vision	O
,	O
includ-	O
ing	O
face	B
tracking	O
,	O
2d	O
shape	O
extraction	O
,	O
and	O
texture	B
segmentation	O
(	O
comaniciu	O
and	O
meer	O
2002	O
)	O
,	O
and	O
more	O
recently	O
in	O
stereo	B
matching	I
(	O
chapter	O
11	O
)	O
(	O
wei	O
and	O
quan	O
2004	O
)	O
,	O
non-photorealistic	B
rendering	I
(	O
section	O
10.5.2	O
)	O
(	O
decarlo	O
and	O
santella	O
2002	O
)	O
,	O
and	O
video	B
editing	O
(	O
section	O
10.4.5	O
)	O
(	O
wang	O
,	O
bhat	O
,	O
colburn	O
et	O
al	O
.	O
2005	O
)	O
.	O
paris	O
and	O
durand	O
(	O
2007	O
)	O
provide	O
a	O
nice	O
review	O
of	O
such	O
applications	O
,	O
as	O
well	O
as	O
techniques	O
for	O
more	O
efﬁciently	O
solving	O
the	O
mean-shift	O
equations	B
and	O
producing	O
hierarchical	B
segmentations	O
.	O
296	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
a	O
a	O
assoc	O
(	O
a	O
,	O
a	O
)	O
cut	O
(	O
b	O
,	O
a	O
)	O
b	O
sum	O
assoc	O
(	O
a	O
,	O
v	O
)	O
b	O
sum	O
cut	O
(	O
a	O
,	O
b	O
)	O
assoc	O
(	O
a	O
,	O
v	O
)	O
assoc	O
(	O
b	O
,	O
b	O
)	O
assoc	O
(	O
b	O
,	O
v	O
)	O
assoc	O
(	O
b	O
,	O
v	O
)	O
(	O
b	O
)	O
(	O
a	O
)	O
figure	O
5.19	O
sample	O
weighted	B
graph	O
and	O
its	O
normalized	B
cut	O
:	O
(	O
a	O
)	O
a	O
small	O
sample	O
graph	O
and	O
its	O
smallest	O
normalized	B
cut	O
;	O
(	O
b	O
)	O
tabular	O
form	O
of	O
the	O
associations	O
and	O
cuts	O
for	O
this	O
graph	O
.	O
the	O
assoc	O
and	O
cut	O
entries	O
are	O
computed	O
as	O
area	O
sums	O
of	O
the	O
associated	O
weight	O
matrix	O
w	O
(	O
fig-	O
ure	O
5.20	O
)	O
.	O
normalizing	B
the	O
table	O
entries	O
by	O
the	O
row	O
or	O
column	O
sums	O
produces	O
normalized	B
associations	O
and	O
cuts	O
n	O
assoc	O
and	O
n	O
cut	O
.	O
5.4	O
normalized	B
cuts	I
while	O
bottom-up	O
merging	B
techniques	O
aggregate	O
regions	O
into	O
coherent	O
wholes	O
and	O
mean-shift	O
techniques	O
try	O
to	O
ﬁnd	O
clusters	O
of	O
similar	O
pixels	O
using	O
mode	O
ﬁnding	O
,	O
the	O
normalized	B
cuts	I
technique	O
introduced	O
by	O
shi	O
and	O
malik	O
(	O
2000	O
)	O
examines	O
the	O
afﬁnities	B
(	O
similarities	O
)	O
between	O
nearby	O
pixels	O
and	O
tries	O
to	O
separate	O
groups	O
that	O
are	O
connected	O
by	O
weak	O
afﬁnities	O
.	O
consider	O
the	O
simple	O
graph	O
shown	O
in	O
figure	O
5.19a	O
.	O
the	O
pixels	O
in	O
group	O
a	O
are	O
all	O
strongly	O
connected	O
with	O
high	O
afﬁnities	O
,	O
shown	O
as	O
thick	O
red	O
lines	B
,	O
as	O
are	O
the	O
pixels	O
in	O
group	O
b.	O
the	O
connections	O
between	O
these	O
two	O
groups	O
,	O
shown	O
as	O
thinner	O
blue	O
lines	O
,	O
are	O
much	O
weaker	O
.	O
a	O
normalized	B
cut	O
between	O
the	O
two	O
groups	O
,	O
shown	O
as	O
a	O
dashed	O
line	O
,	O
separates	O
them	O
into	O
two	O
clusters	O
.	O
the	O
cut	O
between	O
two	O
groups	O
a	O
and	O
b	O
is	O
deﬁned	O
as	O
the	O
sum	O
of	O
all	O
the	O
weights	O
being	O
cut	O
,	O
cut	O
(	O
a	O
,	O
b	O
)	O
=	O
(	O
cid:88	O
)	O
i∈a	O
,	O
j∈b	O
wij	O
,	O
(	O
5.43	O
)	O
where	O
the	O
weights	O
between	O
two	O
pixels	O
(	O
or	O
regions	O
)	O
i	O
and	O
j	O
measure	O
their	O
similarity	B
.	O
using	O
a	O
minimum	O
cut	O
as	O
a	O
segmentation	B
criterion	O
,	O
however	O
,	O
does	O
not	O
result	O
in	O
reasonable	O
clusters	O
,	O
since	O
the	O
smallest	O
cuts	O
usually	O
involve	O
isolating	O
a	O
single	O
pixel	O
.	O
a	O
better	O
measure	O
of	O
segmentation	B
is	O
the	O
normalized	B
cut	O
,	O
which	O
is	O
deﬁned	O
as	O
ncut	O
(	O
a	O
,	O
b	O
)	O
=	O
cut	O
(	O
a	O
,	O
b	O
)	O
assoc	O
(	O
a	O
,	O
v	O
)	O
+	O
cut	O
(	O
a	O
,	O
b	O
)	O
assoc	O
(	O
b	O
,	O
v	O
)	O
,	O
(	O
5.44	O
)	O
where	O
assoc	O
(	O
a	O
,	O
a	O
)	O
=	O
(	O
cid:80	O
)	O
i∈a	O
,	O
j∈a	O
wij	O
is	O
the	O
association	O
(	O
sum	O
of	O
all	O
the	O
weights	O
)	O
within	O
a	O
cluster	O
and	O
assoc	O
(	O
a	O
,	O
v	O
)	O
=	O
assoc	O
(	O
a	O
,	O
a	O
)	O
+	O
cut	O
(	O
a	O
,	O
b	O
)	O
is	O
the	O
sum	O
of	O
all	O
the	O
weights	O
associated	O
aaaabbb	O
5.4	O
normalized	B
cuts	I
297	O
with	O
nodes	O
in	O
a.	O
figure	O
5.19b	O
shows	O
how	O
the	O
cuts	O
and	O
associations	O
can	O
be	O
thought	O
of	O
as	O
area	O
sums	O
in	O
the	O
weight	O
matrix	O
w	O
=	O
[	O
wij	O
]	O
,	O
where	O
the	O
entries	O
of	O
the	O
matrix	O
have	O
been	O
arranged	O
so	O
that	O
the	O
nodes	O
in	O
a	O
come	O
ﬁrst	O
and	O
the	O
nodes	O
in	O
b	O
come	O
second	O
.	O
figure	O
5.20	O
shows	O
an	O
actual	O
weight	O
matrix	O
for	O
which	O
these	O
area	O
sums	O
can	O
be	O
computed	O
.	O
dividing	O
each	O
of	O
these	O
areas	O
by	O
the	O
corresponding	O
row	O
sum	O
(	O
the	O
rightmost	O
column	O
of	O
figure	O
5.19b	O
)	O
results	O
in	O
the	O
normalized	B
cut	O
and	O
association	O
values	O
.	O
these	O
normalized	B
values	O
better	O
reﬂect	O
the	O
ﬁtness	O
of	O
a	O
particular	O
segmentation	B
,	O
since	O
they	O
look	O
for	O
collections	O
of	O
edges	O
that	O
are	O
weak	O
relative	O
to	O
all	O
of	O
the	O
edges	O
both	O
inside	O
and	O
emanating	O
from	O
a	O
particular	O
region	B
.	O
unfortunately	O
,	O
computing	O
the	O
optimal	O
normalized	B
cut	O
is	O
np-complete	O
.	O
instead	O
,	O
shi	O
and	O
malik	O
(	O
2000	O
)	O
suggest	O
computing	O
a	O
real-valued	O
assignment	O
of	O
nodes	O
to	O
groups	O
.	O
let	O
x	O
be	O
the	O
indicator	O
vector	O
where	O
xi	O
=	O
+1	O
iff	O
i	O
∈	O
a	O
and	O
xi	O
=	O
−1	O
iff	O
i	O
∈	O
b.	O
let	O
d	O
=	O
w	O
1	O
be	O
the	O
row	O
sums	O
of	O
the	O
symmetric	O
matrix	O
w	O
and	O
d	O
=	O
diag	O
(	O
d	O
)	O
be	O
the	O
corresponding	O
diagonal	O
matrix	O
.	O
shi	O
and	O
malik	O
(	O
2000	O
)	O
show	O
that	O
minimizing	O
the	O
normalized	B
cut	O
over	O
all	O
possible	O
indicator	O
vectors	O
x	O
is	O
equivalent	O
to	O
minimizing	O
min	O
y	O
yt	O
(	O
d	O
−	O
w	O
)	O
y	O
yt	O
dy	O
,	O
(	O
5.45	O
)	O
where	O
y	O
=	O
(	O
(	O
1+	O
x	O
)	O
−	O
b	O
(	O
1−	O
x	O
)	O
)	O
/2	O
is	O
a	O
vector	O
consisting	O
of	O
all	O
1s	O
and	O
−bs	O
such	O
that	O
y·	O
d	O
=	O
0.	O
minimizing	O
this	O
rayleigh	O
quotient	O
is	O
equivalent	O
to	O
solving	O
the	O
generalized	B
eigenvalue	O
system	O
which	O
can	O
be	O
turned	O
into	O
a	O
regular	O
eigenvalue	O
problem	O
(	O
d	O
−	O
w	O
)	O
y	O
=	O
λdy	O
,	O
(	O
i	O
−	O
n	O
)	O
z	O
=	O
λz	O
,	O
(	O
5.46	O
)	O
(	O
5.47	O
)	O
where	O
n	O
=	O
d−1/2w	O
d−1/2	O
is	O
the	O
normalized	B
afﬁnity	O
matrix	O
(	O
weiss	O
1999	O
)	O
and	O
z	O
=	O
d1/2y	O
.	O
because	O
these	O
eigenvectors	O
can	O
be	O
interpreted	O
as	O
the	O
large	O
modes	O
of	O
vibration	O
in	O
a	O
spring-mass	O
system	O
,	O
normalized	B
cuts	I
is	O
an	O
example	O
of	O
a	O
spectral	O
method	O
for	O
image	O
segmen-	O
tation	O
.	O
extending	O
an	O
idea	O
originally	O
proposed	O
by	O
scott	O
and	O
longuet-higgins	O
(	O
1990	O
)	O
,	O
weiss	O
(	O
1999	O
)	O
suggests	O
normalizing	B
the	O
afﬁnity	O
matrix	O
and	O
then	O
using	O
the	O
top	O
k	O
eigenvectors	O
to	O
reconstitute	O
a	O
q	O
matrix	O
.	O
other	O
papers	O
have	O
extended	O
the	O
basic	O
normalized	B
cuts	I
framework	O
by	O
modifying	O
the	O
afﬁnity	O
matrix	O
in	O
different	O
ways	O
,	O
ﬁnding	O
better	O
discrete	B
solutions	O
to	O
the	O
minimization	O
prob-	O
lem	O
,	O
or	O
applying	O
multi-scale	O
techniques	O
(	O
meil˘a	O
and	O
shi	O
2000	O
,	O
2001	O
;	O
ng	O
,	O
jordan	O
,	O
and	O
weiss	O
2001	O
;	O
yu	O
and	O
shi	O
2003	O
;	O
cour	O
,	O
b´en´ezit	O
,	O
and	O
shi	O
2005	O
;	O
tolliver	O
and	O
miller	O
2006	O
)	O
.	O
figure	O
5.20b	O
shows	O
the	O
second	O
smallest	O
(	O
real-valued	O
)	O
eigenvector	O
corresponding	O
to	O
the	O
weight	O
matrix	O
shown	O
in	O
figure	O
5.20a	O
.	O
(	O
here	O
,	O
the	O
rows	O
have	O
been	O
permuted	O
to	O
separate	O
the	O
two	O
groups	O
of	O
variables	O
that	O
belong	O
to	O
the	O
different	O
components	O
of	O
this	O
eigenvector	O
.	O
)	O
af-	O
ter	O
this	O
real-valued	O
vector	O
is	O
computed	O
,	O
the	O
variables	O
corresponding	O
to	O
positive	O
and	O
negative	O
298	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
5.20	O
sample	O
weight	O
table	O
and	O
its	O
second	O
smallest	O
eigenvector	O
(	O
shi	O
and	O
malik	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
ieee	O
:	O
(	O
a	O
)	O
sample	O
32	O
×	O
32	O
weight	O
matrix	O
w	O
;	O
(	O
b	O
)	O
eigenvector	O
corresponding	O
to	O
the	O
second	O
smallest	O
eigenvalue	O
of	O
the	O
generalized	B
eigenvalue	O
problem	O
(	O
d	O
−	O
w	O
)	O
y	O
=	O
λdy	O
.	O
eigenvector	O
values	O
are	O
associated	O
with	O
the	O
two	O
cut	O
components	O
.	O
this	O
process	O
can	O
be	O
further	O
repeated	O
to	O
hierarchically	O
subdivide	O
an	O
image	B
,	O
as	O
shown	O
in	O
figure	O
5.21.	O
the	O
original	O
algorithm	B
proposed	O
by	O
shi	O
and	O
malik	O
(	O
2000	O
)	O
used	O
spatial	O
position	O
and	O
image	B
feature	O
differences	O
to	O
compute	O
the	O
pixel-wise	O
afﬁnities	B
,	O
wij	O
=	O
exp	O
(	O
cid:18	O
)	O
−	O
(	O
cid:107	O
)	O
f	O
i	O
−	O
f	O
j	O
(	O
cid:107	O
)	O
2	O
σ2	O
f	O
−	O
(	O
cid:107	O
)	O
xi	O
−	O
xj	O
(	O
cid:107	O
)	O
2	O
σ2	O
s	O
(	O
cid:19	O
)	O
,	O
(	O
5.48	O
)	O
for	O
pixels	O
within	O
a	O
radius	O
(	O
cid:107	O
)	O
xi	O
−	O
xj	O
(	O
cid:107	O
)	O
<	O
r	O
,	O
where	O
f	O
is	O
a	O
feature	B
vector	O
that	O
consists	O
of	O
intensi-	O
ties	O
,	O
colors	O
,	O
or	O
oriented	B
ﬁlter	O
histograms	O
.	O
(	O
note	O
how	O
(	O
5.48	O
)	O
is	O
the	O
negative	O
exponential	O
of	O
the	O
joint	B
feature	I
space	I
distance	O
(	O
5.42	O
)	O
.	O
)	O
in	O
subsequent	O
work	O
,	O
malik	O
,	O
belongie	O
,	O
leung	O
et	O
al	O
.	O
(	O
2001	O
)	O
look	O
for	O
intervening	O
contours	O
between	O
pixels	O
i	O
and	O
j	O
and	O
deﬁne	O
an	O
intervening	B
contour	I
weight	O
ij	O
=	O
1	O
−	O
max	O
wic	O
x∈lij	O
pcon	O
(	O
x	O
)	O
,	O
(	O
5.49	O
)	O
where	O
lij	O
is	O
the	O
image	B
line	O
joining	O
pixels	O
i	O
and	O
j	O
and	O
pcon	O
(	O
x	O
)	O
is	O
the	O
probability	O
of	O
an	O
inter-	O
vening	O
contour	O
perpendicular	O
to	O
this	O
line	O
,	O
which	O
is	O
deﬁned	O
as	O
the	O
negative	O
exponential	O
of	O
the	O
oriented	B
energy	O
in	O
the	O
perpendicular	O
direction	O
.	O
they	O
multiply	O
these	O
weights	O
with	O
a	O
texton-	O
based	O
texture	B
similarity	O
metric	O
and	O
use	O
an	O
initial	O
over-segmentation	O
based	O
purely	O
on	O
local	B
pixel-wise	O
features	O
to	O
re-estimate	O
intervening	O
contours	O
and	O
texture	B
statistics	O
in	O
a	O
region-based	B
manner	O
.	O
figure	O
5.22	O
shows	O
the	O
results	O
of	O
running	O
this	O
improved	O
algorithm	B
on	O
a	O
number	O
of	O
test	B
images	I
.	O
because	O
it	O
requires	O
the	O
solution	O
of	O
large	O
sparse	O
eigenvalue	O
problems	O
,	O
normalized	B
cuts	I
can	O
be	O
quite	O
slow	O
.	O
sharon	O
,	O
galun	O
,	O
sharon	O
et	O
al	O
.	O
(	O
2006	O
)	O
present	O
a	O
way	O
to	O
accelerate	O
the	O
com-	O
putation	O
of	O
the	O
normalized	B
cuts	I
using	O
an	O
approach	O
inspired	O
by	O
algebraic	O
multigrid	O
(	O
brandt	O
5.4	O
normalized	B
cuts	I
299	O
figure	O
5.21	O
normalized	B
cuts	I
segmentation	O
(	O
shi	O
and	O
malik	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
ieee	O
:	O
the	O
input	O
image	B
and	O
the	O
components	O
returned	O
by	O
the	O
normalized	B
cuts	I
algorithm	O
.	O
figure	O
5.22	O
comparative	O
segmentation	B
results	O
(	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
ieee	O
.	O
“	O
our	O
method	O
”	O
refers	O
to	O
the	O
probabilistic	B
bottom-up	O
merging	B
algorithm	O
developed	O
by	O
alpert	O
et	O
al	O
.	O
300	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
1986	O
;	O
briggs	O
,	O
henson	O
,	O
and	O
mccormick	O
2000	O
)	O
.	O
to	O
coarsen	O
the	O
original	O
problem	O
,	O
they	O
select	O
a	O
smaller	O
number	O
of	O
variables	O
such	O
that	O
the	O
remaining	O
ﬁne-level	O
variables	O
are	O
strongly	O
cou-	O
pled	O
to	O
at	O
least	O
one	O
coarse-level	O
variable	O
.	O
figure	O
5.15	O
shows	O
this	O
process	O
schematically	O
,	O
while	O
(	O
5.25	O
)	O
gives	O
the	O
deﬁnition	O
for	O
strong	O
coupling	O
except	O
that	O
,	O
in	O
this	O
case	O
,	O
the	O
original	O
weights	O
wij	O
in	O
the	O
normalized	B
cut	O
are	O
used	O
instead	O
of	O
merge	O
probabilities	O
pij	O
.	O
once	O
a	O
set	O
of	O
coarse	O
variables	O
has	O
been	O
selected	O
,	O
an	O
inter-level	O
interpolation	B
matrix	O
with	O
elements	O
similar	O
to	O
the	O
left	O
hand	O
side	O
of	O
(	O
5.25	O
)	O
is	O
used	O
to	O
deﬁne	O
a	O
reduced	O
version	O
of	O
the	O
nor-	O
malized	O
cuts	O
problem	O
.	O
in	O
addition	O
to	O
computing	O
the	O
weight	O
matrix	O
using	O
interpolation-based	O
coarsening	O
,	O
additional	O
region	B
statistics	O
are	O
used	O
to	O
modulate	O
the	O
weights	O
.	O
after	O
a	O
normalized	B
cut	O
has	O
been	O
computed	O
at	O
the	O
coarsest	O
level	O
of	O
analysis	O
,	O
the	O
membership	O
values	O
of	O
ﬁner-level	O
nodes	O
are	O
computed	O
by	O
interpolating	O
parent	O
values	O
and	O
mapping	O
values	O
within	O
	O
=	O
0.1	O
of	O
0	O
and	O
1	O
to	O
pure	O
boolean	O
values	O
.	O
an	O
example	O
of	O
the	O
segmentation	B
produced	O
by	O
weighted	O
aggregation	O
(	O
swa	O
)	O
is	O
shown	O
in	O
figure	O
5.22	O
,	O
along	O
with	O
the	O
most	O
recent	O
probabilistic	B
bottom-up	O
merging	B
algorithm	O
by	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
(	O
2007	O
)	O
,	O
which	O
was	O
described	O
in	O
section	O
5.2.	O
in	O
even	O
more	O
recent	O
work	O
,	O
wang	O
and	O
oliensis	O
(	O
2010	O
)	O
show	O
how	O
to	O
estimate	O
statistics	O
over	O
segmentations	O
(	O
e.g.	O
,	O
mean	O
region	O
size	O
)	O
directly	O
from	O
the	O
afﬁnity	O
graph	O
.	O
they	O
use	O
this	O
to	O
produce	O
segmentations	O
that	O
are	O
more	O
central	O
with	O
respect	O
to	O
other	O
possible	O
segmentations	O
.	O
5.5	O
graph	B
cuts	I
and	O
energy-based	B
methods	O
a	O
common	O
theme	O
in	O
image	B
segmentation	O
algorithms	O
is	O
the	O
desire	O
to	O
group	O
pixels	O
that	O
have	O
similar	O
appearance	O
(	O
statistics	O
)	O
and	O
to	O
have	O
the	O
boundaries	O
between	O
pixels	O
in	O
different	O
regions	O
be	O
of	O
short	O
length	O
and	O
across	O
visible	O
discontinuities	O
.	O
if	O
we	O
restrict	O
the	O
boundary	O
measurements	O
to	O
be	O
between	O
immediate	O
neighbors	O
and	O
compute	O
region	B
membership	O
statistics	O
by	O
summing	O
over	O
pixels	O
,	O
we	O
can	O
formulate	O
this	O
as	O
a	O
classic	O
pixel-based	O
energy	O
function	O
using	O
either	O
a	O
variational	O
formulation	O
(	O
regularization	B
,	O
see	O
section	O
3.7.1	O
)	O
or	O
as	O
a	O
binary	O
markov	O
random	O
ﬁeld	O
(	O
section	O
3.7.2	O
)	O
.	O
examples	B
of	O
the	O
continuous	O
approach	O
include	O
(	O
mumford	O
and	O
shah	O
1989	O
;	O
chan	O
and	O
vese	O
1992	O
;	O
zhu	O
and	O
yuille	O
1996	O
;	O
tabb	O
and	O
ahuja	O
1997	O
)	O
along	O
with	O
the	O
level	O
set	O
approaches	O
dis-	O
cussed	O
in	O
section	O
5.1.4.	O
an	O
early	O
example	O
of	O
a	O
discrete	B
labeling	O
problem	O
that	O
combines	O
both	O
region-based	B
and	O
boundary-based	O
energy	O
terms	O
is	O
the	O
work	O
of	O
leclerc	O
(	O
1989	O
)	O
,	O
who	O
used	O
minimum	O
description	O
length	O
(	O
mdl	O
)	O
coding	O
to	O
derive	O
the	O
energy	O
function	O
being	O
minimized	O
.	O
boykov	O
and	O
funka-lea	O
(	O
2006	O
)	O
present	O
a	O
wonderful	O
survey	O
of	O
various	O
energy-based	B
tech-	O
niques	O
for	O
binary	O
object	O
segmentation	B
,	O
some	O
of	O
which	O
we	O
discuss	O
below	O
.	O
as	O
we	O
saw	O
in	O
section	O
3.7.2	O
,	O
the	O
energy	O
corresponding	O
to	O
a	O
segmentation	B
problem	O
can	O
be	O
5.5	O
graph	B
cuts	I
and	O
energy-based	B
methods	O
written	O
(	O
c.f	O
.	O
equations	B
(	O
3.100	O
)	O
and	O
(	O
3.108–3.113	O
)	O
)	O
as	O
where	O
the	O
region	B
term	O
e	O
(	O
f	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
,	O
j	O
er	O
(	O
i	O
,	O
j	O
)	O
+	O
eb	O
(	O
i	O
,	O
j	O
)	O
,	O
er	O
(	O
i	O
,	O
j	O
)	O
=	O
es	O
(	O
i	O
(	O
i	O
,	O
j	O
)	O
;	O
r	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
)	O
)	O
301	O
(	O
5.50	O
)	O
(	O
5.51	O
)	O
is	O
the	O
negative	O
log	O
likelihood	O
that	O
pixel	O
intensity	O
(	O
or	O
color	B
)	O
i	O
(	O
i	O
,	O
j	O
)	O
is	O
consistent	O
with	O
the	O
statis-	O
tics	O
of	O
region	B
r	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
)	O
and	O
the	O
boundary	O
term	O
eb	O
(	O
i	O
,	O
j	O
)	O
=	O
sx	O
(	O
i	O
,	O
j	O
)	O
δ	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
f	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
)	O
+	O
sy	O
(	O
i	O
,	O
j	O
)	O
δ	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
f	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
)	O
(	O
5.52	O
)	O
measures	O
the	O
inconsistency	O
between	O
n4	O
neighbors	O
modulated	O
by	O
local	O
horizontal	O
and	O
vertical	O
smoothness	B
terms	O
sx	O
(	O
i	O
,	O
j	O
)	O
and	O
sy	O
(	O
i	O
,	O
j	O
)	O
.	O
region	B
statistics	O
can	O
be	O
something	O
as	O
simple	O
as	O
the	O
mean	O
gray	O
level	O
or	O
color	B
(	O
leclerc	O
1989	O
)	O
,	O
in	O
which	O
case	O
es	O
(	O
i	O
;	O
µk	O
)	O
=	O
(	O
cid:107	O
)	O
i	O
−	O
µk	O
(	O
cid:107	O
)	O
2	O
.	O
(	O
5.53	O
)	O
alternatively	O
,	O
they	O
can	O
be	O
more	O
complex	O
,	O
such	O
as	O
region	B
intensity	O
histograms	O
(	O
boykov	O
and	O
jolly	O
2001	O
)	O
or	O
color	B
gaussian	O
mixture	O
models	O
(	O
rother	O
,	O
kolmogorov	O
,	O
and	O
blake	O
2004	O
)	O
.	O
for	O
smoothness	O
(	O
boundary	O
)	O
terms	O
,	O
it	O
is	O
common	O
to	O
make	O
the	O
strength	O
of	O
the	O
smoothness	B
sx	O
(	O
i	O
,	O
j	O
)	O
inversely	O
proportional	O
to	O
the	O
local	B
edge	O
strength	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
.	O
originally	O
,	O
energy-based	B
segmentation	O
problems	O
were	O
optimized	O
using	O
iterative	O
gradient	B
descent	I
techniques	O
,	O
which	O
were	O
slow	O
and	O
prone	O
to	O
getting	O
trapped	O
in	O
local	B
minima	O
.	O
boykov	O
and	O
jolly	O
(	O
2001	O
)	O
were	O
the	O
ﬁrst	O
to	O
apply	O
the	O
binary	O
mrf	O
optimization	O
algorithm	B
developed	O
by	O
greig	O
,	O
porteous	O
,	O
and	O
seheult	O
(	O
1989	O
)	O
to	O
binary	O
object	O
segmentation	B
.	O
in	O
this	O
approach	O
,	O
the	O
user	O
ﬁrst	O
delineates	O
pixels	O
in	O
the	O
background	O
and	O
foreground	O
regions	O
using	O
a	O
few	O
strokes	O
of	O
an	O
image	B
brush	O
(	O
figure	O
3.61	O
)	O
.	O
these	O
pixels	O
then	O
become	O
the	O
seeds	O
that	O
tie	O
nodes	O
in	O
the	O
s–t	O
graph	O
to	O
the	O
source	O
and	O
sink	O
labels	O
s	O
and	O
t	O
(	O
figure	O
5.23a	O
)	O
.	O
seed	O
pixels	O
can	O
also	O
be	O
used	O
to	O
estimate	O
foreground	O
and	O
background	O
region	O
statistics	O
(	O
intensity	O
or	O
color	B
histograms	O
)	O
.	O
the	O
capacities	O
of	O
the	O
other	O
edges	O
in	O
the	O
graph	O
are	O
derived	O
from	O
the	O
region	B
and	O
boundary	O
energy	O
terms	O
,	O
i.e.	O
,	O
pixels	O
that	O
are	O
more	O
compatible	O
with	O
the	O
foreground	O
or	O
background	O
region	O
get	O
stronger	O
connections	O
to	O
the	O
respective	O
source	O
or	O
sink	O
;	O
adjacent	O
pixels	O
with	O
greater	O
smooth-	O
ness	O
also	O
get	O
stronger	O
links	O
.	O
once	O
the	O
minimum-cut/maximum-ﬂow	O
problem	O
has	O
been	O
solved	O
using	O
a	O
polynomial	O
time	O
algorithm	O
(	O
goldberg	O
and	O
tarjan	O
1988	O
;	O
boykov	O
and	O
kolmogorov	O
2004	O
)	O
,	O
pixels	O
on	O
either	O
side	O
of	O
the	O
computed	O
cut	O
are	O
labeled	O
according	O
to	O
the	O
source	O
or	O
sink	O
to	O
which	O
they	O
remain	O
connected	O
(	O
figure	O
5.23b	O
)	O
.	O
while	O
graph	B
cuts	I
is	O
just	O
one	O
of	O
several	O
known	O
techniques	O
for	O
mrf	O
energy	O
minimization	O
(	O
appendix	O
b.5.4	O
)	O
,	O
it	O
is	O
still	O
the	O
one	O
most	O
commonly	O
used	O
for	O
solving	O
binary	O
mrf	O
problems	O
.	O
302	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
5.23	O
graph	B
cuts	I
for	O
region	B
segmentation	O
(	O
boykov	O
and	O
jolly	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
the	O
energy	O
function	O
is	O
encoded	O
as	O
a	O
maximum	O
ﬂow	O
problem	O
;	O
(	O
b	O
)	O
the	O
minimum	O
cut	O
determines	O
the	O
region	B
boundary	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
5.24	O
grabcut	O
image	B
segmentation	O
(	O
rother	O
,	O
kolmogorov	O
,	O
and	O
blake	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
(	O
a	O
)	O
the	O
user	O
draws	O
a	O
bounding	O
box	O
in	O
red	O
;	O
(	O
b	O
)	O
the	O
algorithm	B
guesses	O
color	B
distributions	O
for	O
the	O
object	O
and	O
background	O
and	O
performs	O
a	O
binary	O
segmentation	O
;	O
(	O
c	O
)	O
the	O
process	O
is	O
repeated	O
with	O
better	O
region	B
statistics	O
.	O
the	O
basic	O
binary	O
segmentation	O
algorithm	B
of	O
boykov	O
and	O
jolly	O
(	O
2001	O
)	O
has	O
been	O
extended	O
in	O
a	O
number	O
of	O
directions	O
.	O
the	O
grabcut	O
system	O
of	O
rother	O
,	O
kolmogorov	O
,	O
and	O
blake	O
(	O
2004	O
)	O
iteratively	O
re-estimates	O
the	O
region	B
statistics	O
,	O
which	O
are	O
modeled	O
as	O
a	O
mixtures	O
of	O
gaussians	O
in	O
color	B
space	O
.	O
this	O
allows	O
their	O
system	O
to	O
operate	O
given	O
minimal	O
user	O
input	O
,	O
such	O
as	O
a	O
single	O
bounding	O
box	O
(	O
figure	O
5.24a	O
)	O
—the	O
background	O
color	O
model	O
is	O
initialized	O
from	O
a	O
strip	O
of	O
pixels	O
around	O
the	O
box	O
outline	O
.	O
(	O
the	O
foreground	O
color	B
model	I
is	O
initialized	O
from	O
the	O
interior	O
pixels	O
,	O
but	O
quickly	O
converges	O
to	O
a	O
better	O
estimate	O
of	O
the	O
object	O
.	O
)	O
the	O
user	O
can	O
also	O
place	O
additional	O
strokes	O
to	O
reﬁne	O
the	O
segmentation	B
as	O
the	O
solution	O
progresses	O
.	O
in	O
more	O
recent	O
work	O
,	O
cui	O
,	O
yang	O
,	O
wen	O
et	O
al	O
.	O
(	O
2008	O
)	O
use	O
color	B
and	O
edge	O
models	O
derived	O
from	O
previous	O
segmentations	O
of	O
similar	O
objects	O
to	O
improve	O
the	O
local	B
models	O
used	O
in	O
grabcut	O
.	O
another	O
major	O
extension	O
to	O
the	O
original	O
binary	O
segmentation	O
formulation	O
is	O
the	O
addition	O
of	O
objectterminal	O
terminalbackground	O
pqrwvstbackground	O
object	O
terminalterminalpqrwvstcut	O
5.5	O
graph	B
cuts	I
and	O
energy-based	B
methods	O
303	O
figure	O
5.25	O
segmentation	B
with	O
a	O
directed	O
graph	O
cut	O
(	O
boykov	O
and	O
funka-lea	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
:	O
(	O
a	O
)	O
directed	O
graph	O
;	O
(	O
b	O
)	O
image	B
with	O
seed	O
points	O
;	O
(	O
c	O
)	O
the	O
undirected	O
graph	O
incorrectly	O
continues	O
the	O
boundary	O
along	O
the	O
bright	O
object	O
;	O
(	O
d	O
)	O
the	O
directed	O
graph	O
correctly	O
segments	O
the	O
light	O
gray	O
region	B
from	O
its	O
darker	O
surround	O
.	O
directed	B
edges	I
,	O
which	O
allows	O
boundary	O
regions	O
to	O
be	O
oriented	B
,	O
e.g.	O
,	O
to	O
prefer	O
light	O
to	O
dark	O
tran-	O
sitions	O
or	O
vice	O
versa	O
(	O
kolmogorov	O
and	O
boykov	O
2005	O
)	O
.	O
figure	O
5.25	O
shows	O
an	O
example	O
where	O
the	O
directed	O
graph	O
cut	O
correctly	O
segments	O
the	O
light	O
gray	O
liver	O
from	O
its	O
dark	O
gray	O
surround	O
.	O
the	O
same	O
approach	O
can	O
be	O
used	O
to	O
measure	O
the	O
ﬂux	B
exiting	O
a	O
region	B
,	O
i.e.	O
,	O
the	O
signed	B
gradient	O
pro-	O
jected	O
normal	O
to	O
the	O
region	B
boundary	O
.	O
combining	O
oriented	B
graphs	O
with	O
larger	O
neighborhoods	O
enables	O
approximating	O
continuous	O
problems	O
such	O
as	O
those	O
traditionally	O
solved	O
using	O
level	O
sets	O
in	O
the	O
globally	O
optimal	O
graph	B
cut	I
framework	O
(	O
boykov	O
and	O
kolmogorov	O
2003	O
;	O
kolmogorov	O
and	O
boykov	O
2005	O
)	O
.	O
even	O
more	O
recent	O
developments	O
in	O
graph	O
cut-based	O
segmentation	B
techniques	O
include	O
the	O
addition	O
of	O
connectivity	O
priors	O
to	O
force	O
the	O
foreground	O
to	O
be	O
in	O
a	O
single	O
piece	O
(	O
vicente	O
,	O
kol-	O
mogorov	O
,	O
and	O
rother	O
2008	O
)	O
and	O
shape	B
priors	I
to	O
use	O
knowledge	O
about	O
an	O
object	O
’	O
s	O
shape	O
during	O
the	O
segmentation	B
process	O
(	O
lempitsky	O
and	O
boykov	O
2007	O
;	O
lempitsky	O
,	O
blake	O
,	O
and	O
rother	O
2008	O
)	O
.	O
while	O
optimizing	O
the	O
binary	O
mrf	O
energy	O
(	O
5.50	O
)	O
requires	O
the	O
use	O
of	O
combinatorial	O
op-	O
timization	O
techniques	O
,	O
such	O
as	O
maximum	O
ﬂow	O
,	O
an	O
approximate	O
solution	O
can	O
be	O
obtained	O
by	O
converting	O
the	O
binary	O
energy	O
terms	O
into	O
quadratic	O
energy	O
terms	O
deﬁned	O
over	O
a	O
continuous	O
[	O
0	O
,	O
1	O
]	O
random	O
ﬁeld	O
,	O
which	O
then	O
becomes	O
a	O
classical	O
membrane-based	O
regularization	B
problem	O
(	O
3.100–3.102	O
)	O
.	O
the	O
resulting	O
quadratic	O
energy	O
function	O
can	O
then	O
be	O
solved	O
using	O
standard	O
linear	B
system	O
solvers	O
(	O
3.102–3.103	O
)	O
,	O
although	O
if	O
speed	O
is	O
an	O
issue	O
,	O
you	O
should	O
use	O
multigrid	O
or	O
one	O
of	O
its	O
variants	O
(	O
appendix	O
a.5	O
)	O
.	O
once	O
the	O
continuous	O
solution	O
has	O
been	O
computed	O
,	O
it	O
can	O
be	O
thresholded	O
at	O
0.5	O
to	O
yield	O
a	O
binary	O
segmentation	O
.	O
the	O
[	O
0	O
,	O
1	O
]	O
continuous	O
optimization	O
problem	O
can	O
also	O
be	O
interpreted	O
as	O
computing	O
the	O
prob-	O
122boykovandfunka-leafigure7.segmentationviacutsonadirectedgraph.comparetheresultsonanundirectedgraph	O
(	O
c	O
)	O
withtheresultsonadirectedgraphin	O
(	O
d	O
)	O
.assumenowthatanoptimalsegmentationisalreadycomputedforsomeinitialsetofseeds.auseraddsanew	O
“	O
object	O
”	O
seedtopixelpthatwasnotpreviouslyassignedanyseed.weneedtochangethecostsfortwot-linksatpt-linkinitialcostnewcost	O
{	O
p	O
,	O
s	O
}	O
λrp	O
(	O
“	O
bkg	O
”	O
)	O
k	O
{	O
p	O
,	O
t	O
}	O
λrp	O
(	O
“	O
obj	O
”	O
)	O
0andthencomputethemaximumﬂow	O
(	O
minimumcut	O
)	O
onthenewgraph.infact	O
,	O
wecanstartfromtheﬂowfoundattheendofinitialcomputation.theonlyproblemisthatreassignmentofedgeweightsasabovereducescapacitiesofsomeedges.ifthereisaﬂowthroughsuchanedgethenwemaybreaktheﬂowconsistency.increasinganedgecapacity	O
,	O
ontheotherhand	O
,	O
isneveraproblem.then	O
,	O
wecansolvetheproblemasfollows.toaccommodatethenew	O
“	O
object	O
”	O
seedatpixelpweincreasethet-linksweightsaccordingtothetablet-linkinitialcostaddnewcost	O
{	O
p	O
,	O
s	O
}	O
λrp	O
(	O
“	O
bkg	O
”	O
)	O
k+λrp	O
(	O
“	O
obj	O
”	O
)	O
k+cp	O
{	O
p	O
,	O
t	O
}	O
λrp	O
(	O
“	O
obj	O
”	O
)	O
λrp	O
(	O
“	O
bkg	O
”	O
)	O
cpthesenewcostsareconsistentwiththeedgeweighttableforpixelsinosincetheextraconstantcpatbotht-linksofapixeldoesnotchangetheoptimalcut.13then	O
,	O
amaximumﬂow	O
(	O
minimumcut	O
)	O
onanewgraphcanbeefﬁcientlyobtainedstartingfromtheprevi-ousﬂowwithoutrecomputingthewholesolutionfromscratch.notethatthesametrickcanbedonetoadjustthesegmentationwhenanew	O
“	O
background	O
”	O
seedisaddedorwhenaseedisdeleted.onehastoﬁguretherightamountsthathavetobeaddedtothecostsoftwot-linksatthecorrespondingpixel.thenewcostsshouldbeconsistentwiththeedgeweighttableplusorminusthesameconstant.2.7.usingdirectededgesforsimplicity	O
,	O
wepreviouslyconcentratedonthecaseofundirectedgraphsasinfig.3.infact	O
,	O
themajorityofs-tcutalgorithmsfromcombinatorialoptimizationcanbeappliedtodirectedgraphsaswell.figure7	O
(	O
a	O
)	O
givesoneexampleofsuchagraphwhereeachpairofneighboringnodesisconnectedbytwodirectededges	O
(	O
p	O
,	O
q	O
)	O
and	O
(	O
q	O
,	O
p	O
)	O
withdistinctweightsw	O
(	O
p	O
,	O
q	O
)	O
andw	O
(	O
q	O
,	O
p	O
)	O
.ifacutseparatestwoneighboringnodespandqsothatpisconnectedtothesourcewhileqisconnectedtothesinkthenthecostofthecutincludesw	O
(	O
p	O
,	O
q	O
)	O
whilew	O
(	O
q	O
,	O
p	O
)	O
isignored.viseversa	O
,	O
ifqisconnectedtothesourceandptothesinkthenthecostofthecutincludesonlyw	O
(	O
q	O
,	O
p	O
)	O
.incertaincasesonecantakeadvantageofsuchdi-rectedcoststoobtainmoreaccurateobjectboundaries.forexample	O
,	O
comparetwosegmentationsinfig.7	O
(	O
c	O
,	O
d	O
)	O
obtainedonamedicalimagein	O
(	O
b	O
)	O
usingthesamesetofconstraints.arelativelybrightobjectofinterestontheright	O
(	O
liver	O
)	O
isseparatedfromasmallbrightblobon	O
304	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ability	O
at	O
each	O
pixel	O
that	O
a	O
random	B
walker	I
starting	O
at	O
that	O
pixel	O
ends	O
up	O
at	O
one	O
of	O
the	O
labeled	O
seed	O
pixels	O
,	O
which	O
is	O
also	O
equivalent	O
to	O
computing	O
the	O
potential	O
in	O
a	O
resistive	O
grid	O
where	O
the	O
resistors	O
are	O
equal	O
to	O
the	O
edge	O
weights	O
(	O
grady	O
2006	O
;	O
sinop	O
and	O
grady	O
2007	O
)	O
.	O
k-way	O
seg-	O
mentations	O
can	O
also	O
be	O
computed	O
by	O
iterating	O
through	O
the	O
seed	O
labels	O
,	O
using	O
a	O
binary	O
problem	O
with	O
one	O
label	O
set	O
to	O
1	O
and	O
all	O
the	O
others	O
set	O
to	O
0	O
to	O
compute	O
the	O
relative	O
membership	O
proba-	O
bilities	O
for	O
each	O
pixel	O
.	O
in	O
follow-on	O
work	O
,	O
grady	O
and	O
ali	O
(	O
2008	O
)	O
use	O
a	O
precomputation	O
of	O
the	O
eigenvectors	O
of	O
the	O
linear	B
system	O
to	O
make	O
the	O
solution	O
with	O
a	O
novel	O
set	O
of	O
seeds	O
faster	O
,	O
which	O
is	O
related	O
to	O
the	O
laplacian	O
matting	B
problem	O
presented	O
in	O
section	O
10.4.3	O
(	O
levin	O
,	O
acha	O
,	O
and	O
lischinski	O
2008	O
)	O
.	O
couprie	O
,	O
grady	O
,	O
najman	O
et	O
al	O
.	O
(	O
2009	O
)	O
relate	O
the	O
random	B
walker	I
to	O
water-	O
sheds	O
and	O
other	O
segmentation	B
techniques	O
.	O
singaraju	O
,	O
grady	O
,	O
and	O
vidal	O
(	O
2008	O
)	O
add	O
directed-	O
edge	O
constraints	O
in	O
order	B
to	O
support	O
ﬂux	O
,	O
which	O
makes	O
the	O
energy	O
piecewise	O
quadratic	O
and	O
hence	O
not	O
solvable	O
as	O
a	O
single	O
linear	O
system	O
.	O
the	O
random	B
walker	I
algorithm	O
can	O
also	O
be	O
used	O
to	O
solve	O
the	O
mumford–shah	O
segmentation	B
problem	O
(	O
grady	O
and	O
alvino	O
2008	O
)	O
and	O
to	O
com-	O
pute	O
fast	O
multigrid	O
solutions	O
(	O
grady	O
2008	O
)	O
.	O
a	O
nice	O
review	O
of	O
these	O
techniques	O
is	O
given	O
by	O
singaraju	O
,	O
grady	O
,	O
sinop	O
et	O
al	O
.	O
(	O
2010	O
)	O
.	O
an	O
even	O
faster	O
way	O
to	O
compute	O
a	O
continuous	O
[	O
0	O
,	O
1	O
]	O
approximate	O
segmentation	B
is	O
to	O
com-	O
pute	O
weighted	B
geodesic	O
distances	O
between	O
the	O
0	O
and	O
1	O
seed	O
regions	O
(	O
bai	O
and	O
sapiro	O
2009	O
)	O
,	O
which	O
can	O
also	O
be	O
used	O
to	O
estimate	O
soft	O
alpha	O
mattes	O
(	O
section	O
10.4.3	O
)	O
.	O
a	O
related	O
approach	O
by	O
criminisi	O
,	O
sharp	O
,	O
and	O
blake	O
(	O
2008	O
)	O
can	O
be	O
used	O
to	O
ﬁnd	O
fast	O
approximate	O
solutions	O
to	O
general	O
binary	O
markov	O
random	O
ﬁeld	O
optimization	O
problems	O
.	O
5.5.1	O
application	O
:	O
medical	B
image	I
segmentation	O
one	O
of	O
the	O
most	O
promising	O
applications	O
of	O
image	B
segmentation	O
is	O
in	O
the	O
medical	B
imaging	I
domain	O
,	O
where	O
it	O
can	O
be	O
used	O
to	O
segment	O
anatomical	O
tissues	O
for	O
later	O
quantitative	O
analysis	O
.	O
figure	O
5.25	O
shows	O
a	O
binary	O
graph	O
cut	O
with	O
directed	O
edges	O
being	O
used	O
to	O
segment	O
the	O
liver	O
tis-	O
sue	O
(	O
light	O
gray	O
)	O
from	O
its	O
surrounding	O
bone	O
(	O
white	O
)	O
and	O
muscle	O
(	O
dark	O
gray	O
)	O
tissue	O
.	O
figure	O
5.26	O
shows	O
the	O
segmentation	B
of	O
bones	O
in	O
a	O
256	O
×	O
256	O
×	O
119	O
computed	O
x-ray	O
tomography	O
(	O
ct	O
)	O
volume	O
.	O
without	O
the	O
powerful	O
optimization	O
techniques	O
available	O
in	O
today	O
’	O
s	O
image	B
segmen-	O
tation	O
algorithms	O
,	O
such	O
processing	O
used	O
to	O
require	O
much	O
more	O
laborious	O
manual	O
tracing	O
of	O
individual	O
x-ray	O
slices	O
.	O
the	O
ﬁelds	O
of	O
medical	B
image	I
segmentation	O
(	O
mcinerney	O
and	O
terzopoulos	O
1996	O
)	O
and	O
med-	O
ical	O
image	B
registration	I
(	O
kybic	O
and	O
unser	O
2003	O
)	O
(	O
section	O
8.3.1	O
)	O
are	O
rich	O
research	O
ﬁelds	O
with	O
their	O
own	O
specialized	O
conferences	O
,	O
such	O
as	O
medical	B
imaging	I
computing	O
and	O
computer	O
as-	O
sisted	O
intervention	O
(	O
miccai	O
)	O
,11	O
and	O
journals	O
,	O
such	O
as	O
medical	B
image	I
analysis	O
and	O
ieee	O
transactions	O
on	O
medical	B
imaging	I
.	O
these	O
can	O
be	O
great	O
sources	O
of	O
references	B
and	O
ideas	O
for	O
research	O
in	O
this	O
area	O
.	O
11http	O
:	O
//www.miccai.org/	O
.	O
5.6	O
additional	O
reading	O
305	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
5.26	O
3d	O
volumetric	B
medical	O
image	B
segmentation	O
using	O
graph	O
cuts	O
(	O
boykov	O
and	O
funka-lea	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
:	O
(	O
a	O
)	O
computed	O
tomography	O
(	O
ct	O
)	O
slice	O
with	O
some	O
seeds	O
;	O
(	O
b	O
)	O
recovered	O
3d	O
volumetric	B
bone	O
model	O
(	O
on	O
a	O
256	O
×	O
256	O
×	O
119	O
voxel	O
grid	O
)	O
.	O
5.6	O
additional	O
reading	O
the	O
topic	O
of	O
image	B
segmentation	O
is	O
closely	O
related	O
to	O
clustering	O
techniques	O
,	O
which	O
are	O
treated	O
in	O
a	O
number	O
of	O
monographs	O
and	O
review	O
articles	O
(	O
jain	O
and	O
dubes	O
1988	O
;	O
kaufman	O
and	O
rousseeuw	O
1990	O
;	O
jain	O
,	O
duin	O
,	O
and	O
mao	O
2000	O
;	O
jain	O
,	O
topchy	O
,	O
law	O
et	O
al	O
.	O
2004	O
)	O
.	O
some	O
early	O
segmentation	B
techniques	O
include	O
those	O
describerd	O
by	O
brice	O
and	O
fennema	O
(	O
1970	O
)	O
;	O
pavlidis	O
(	O
1977	O
)	O
;	O
riseman	O
and	O
arbib	O
(	O
1977	O
)	O
;	O
ohlander	O
,	O
price	O
,	O
and	O
reddy	O
(	O
1978	O
)	O
;	O
rosenfeld	O
and	O
davis	O
(	O
1979	O
)	O
;	O
haralick	O
and	O
shapiro	O
(	O
1985	O
)	O
,	O
while	O
examples	B
of	O
newer	O
techniques	O
are	O
developed	O
by	O
leclerc	O
(	O
1989	O
)	O
;	O
mumford	O
and	O
shah	O
(	O
1989	O
)	O
;	O
shi	O
and	O
malik	O
(	O
2000	O
)	O
;	O
felzenszwalb	O
and	O
huttenlocher	O
(	O
2004b	O
)	O
.	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
(	O
2010	O
)	O
provide	O
a	O
good	O
review	O
of	O
automatic	B
segmentation	O
techniques	O
and	O
also	O
compare	O
their	O
performance	O
on	O
the	O
berkeley	O
segmentation	B
dataset	O
and	O
benchmark	O
(	O
martin	O
,	O
fowlkes	O
,	O
tal	O
et	O
al	O
.	O
2001	O
)	O
.12	O
additional	O
comparison	O
papers	O
and	O
databases	O
include	O
those	O
by	O
unnikrishnan	O
,	O
pantofaru	O
,	O
and	O
hebert	O
(	O
2007	O
)	O
;	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
(	O
2007	O
)	O
;	O
estrada	O
and	O
jepson	O
(	O
2009	O
)	O
.	O
the	O
topic	O
of	O
active	B
contours	I
has	O
a	O
long	O
history	O
,	O
beginning	O
with	O
the	O
seminal	O
work	O
on	O
snakes	B
and	O
other	O
energy-minimizing	O
variational	O
methods	O
(	O
kass	O
,	O
witkin	O
,	O
and	O
terzopoulos	O
1988	O
;	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
;	O
blake	O
and	O
isard	O
1998	O
)	O
,	O
continuing	O
through	O
tech-	O
niques	O
such	O
as	O
intelligent	B
scissors	I
(	O
mortensen	O
and	O
barrett	O
1995	O
,	O
1999	O
;	O
p´erez	O
,	O
blake	O
,	O
and	O
gangnet	O
2001	O
)	O
,	O
and	O
culminating	O
in	O
level	B
sets	I
(	O
malladi	O
,	O
sethian	O
,	O
and	O
vemuri	O
1995	O
;	O
caselles	O
,	O
kimmel	O
,	O
and	O
sapiro	O
1997	O
;	O
sethian	O
1999	O
;	O
paragios	O
and	O
deriche	O
2000	O
;	O
sapiro	O
2001	O
;	O
osher	O
and	O
paragios	O
2003	O
;	O
paragios	O
,	O
faugeras	O
,	O
chan	O
et	O
al	O
.	O
2005	O
;	O
cremers	O
,	O
rousson	O
,	O
and	O
deriche	O
2007	O
;	O
rousson	O
and	O
paragios	O
2008	O
;	O
paragios	O
and	O
sgallari	O
2009	O
)	O
,	O
which	O
are	O
currently	O
the	O
most	O
widely	O
12	O
http	O
:	O
//www.eecs.berkeley.edu/research/projects/cs/vision/grouping/segbench/	O
.	O
306	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
used	O
active	O
contour	O
methods	O
.	O
techniques	O
for	O
segmenting	O
images	O
based	O
on	O
local	B
pixel	O
similarities	O
combined	O
with	O
ag-	O
gregation	O
or	O
splitting	B
methods	O
include	O
watersheds	O
(	O
vincent	O
and	O
soille	O
1991	O
;	O
beare	O
2006	O
;	O
arbel´aez	O
,	O
maire	O
,	O
fowlkes	O
et	O
al	O
.	O
2010	O
)	O
,	O
region	B
splitting	O
(	O
ohlander	O
,	O
price	O
,	O
and	O
reddy	O
1978	O
)	O
,	O
region	B
merging	O
(	O
brice	O
and	O
fennema	O
1970	O
;	O
pavlidis	O
and	O
liow	O
1990	O
;	O
jain	O
,	O
topchy	O
,	O
law	O
et	O
al	O
.	O
2004	O
)	O
,	O
as	O
well	O
as	O
graph-based	B
and	O
probabilistic	B
multi-scale	O
approaches	O
(	O
felzenszwalb	O
and	O
huttenlocher	O
2004b	O
;	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
2007	O
)	O
.	O
mean-shift	O
algorithms	O
,	O
which	O
ﬁnd	O
modes	O
(	O
peaks	O
)	O
in	O
a	O
density	O
function	O
representation	O
of	O
the	O
pixels	O
,	O
are	O
presented	O
by	O
comaniciu	O
and	O
meer	O
(	O
2002	O
)	O
;	O
paris	O
and	O
durand	O
(	O
2007	O
)	O
.	O
parametric	B
mixtures	O
of	O
gaussians	O
can	O
also	O
be	O
used	O
to	O
represent	O
and	O
segment	O
such	O
pixel	O
densities	O
(	O
bishop	O
2006	O
;	O
ma	O
,	O
derksen	O
,	O
hong	O
et	O
al	O
.	O
2007	O
)	O
.	O
the	O
seminal	O
work	O
on	O
spectral	O
(	O
eigenvalue	O
)	O
methods	O
for	O
image	O
segmentation	B
is	O
the	O
nor-	O
malized	O
cut	O
algorithm	B
of	O
shi	O
and	O
malik	O
(	O
2000	O
)	O
.	O
related	O
work	O
includes	O
that	O
by	O
weiss	O
(	O
1999	O
)	O
;	O
meil˘a	O
and	O
shi	O
(	O
2000	O
,	O
2001	O
)	O
;	O
malik	O
,	O
belongie	O
,	O
leung	O
et	O
al	O
.	O
(	O
2001	O
)	O
;	O
ng	O
,	O
jordan	O
,	O
and	O
weiss	O
(	O
2001	O
)	O
;	O
yu	O
and	O
shi	O
(	O
2003	O
)	O
;	O
cour	O
,	O
b´en´ezit	O
,	O
and	O
shi	O
(	O
2005	O
)	O
;	O
sharon	O
,	O
galun	O
,	O
sharon	O
et	O
al	O
.	O
(	O
2006	O
)	O
;	O
tolliver	O
and	O
miller	O
(	O
2006	O
)	O
;	O
wang	O
and	O
oliensis	O
(	O
2010	O
)	O
.	O
continuous-energy-based	O
(	O
variational	O
)	O
approaches	O
to	O
interactive	B
segmentation	O
include	O
leclerc	O
(	O
1989	O
)	O
;	O
mumford	O
and	O
shah	O
(	O
1989	O
)	O
;	O
chan	O
and	O
vese	O
(	O
1992	O
)	O
;	O
zhu	O
and	O
yuille	O
(	O
1996	O
)	O
;	O
tabb	O
and	O
ahuja	O
(	O
1997	O
)	O
.	O
discrete	B
variants	O
of	O
such	O
problems	O
are	O
usually	O
optimized	O
using	O
binary	O
graph	B
cuts	I
or	O
other	O
combinatorial	O
energy	O
minimization	O
methods	O
(	O
boykov	O
and	O
jolly	O
2001	O
;	O
boykov	O
and	O
kolmogorov	O
2003	O
;	O
rother	O
,	O
kolmogorov	O
,	O
and	O
blake	O
2004	O
;	O
kolmogorov	O
and	O
boykov	O
2005	O
;	O
cui	O
,	O
yang	O
,	O
wen	O
et	O
al	O
.	O
2008	O
;	O
vicente	O
,	O
kolmogorov	O
,	O
and	O
rother	O
2008	O
;	O
lempitsky	O
and	O
boykov	O
2007	O
;	O
lempitsky	O
,	O
blake	O
,	O
and	O
rother	O
2008	O
)	O
,	O
although	O
continuous	O
optimization	O
techniques	O
fol-	O
lowed	O
by	O
thresholding	O
can	O
also	O
be	O
used	O
(	O
grady	O
2006	O
;	O
grady	O
and	O
ali	O
2008	O
;	O
singaraju	O
,	O
grady	O
,	O
and	O
vidal	O
2008	O
;	O
criminisi	O
,	O
sharp	O
,	O
and	O
blake	O
2008	O
;	O
grady	O
2008	O
;	O
bai	O
and	O
sapiro	O
2009	O
;	O
cou-	O
prie	O
,	O
grady	O
,	O
najman	O
et	O
al	O
.	O
2009	O
)	O
.	O
boykov	O
and	O
funka-lea	O
(	O
2006	O
)	O
present	O
a	O
good	O
survey	O
of	O
various	O
energy-based	B
techniques	O
for	O
binary	O
object	O
segmentation	B
.	O
5.7	O
exercises	O
ex	O
5.1	O
:	O
snake	O
evolution	B
prove	O
that	O
,	O
in	O
the	O
absence	O
of	O
external	O
forces	O
,	O
a	O
snake	O
will	O
always	O
shrink	O
to	O
a	O
small	O
circle	O
and	O
eventually	O
a	O
single	O
point	O
,	O
regardless	O
of	O
whether	O
ﬁrst-	O
or	O
second-	O
order	B
smoothness	O
(	O
or	O
some	O
combination	O
)	O
is	O
used	O
.	O
(	O
hint	O
:	O
if	O
you	O
can	O
show	O
that	O
the	O
evolution	B
of	O
the	O
x	O
(	O
s	O
)	O
and	O
y	O
(	O
s	O
)	O
components	O
are	O
indepen-	O
dent	O
,	O
you	O
can	O
analyze	O
the	O
1d	O
case	O
more	O
easily	O
.	O
)	O
ex	O
5.2	O
:	O
snake	O
tracker	O
implement	O
a	O
snake-based	O
contour	O
tracker	O
:	O
5.7	O
exercises	O
307	O
1.	O
decide	O
whether	O
to	O
use	O
a	O
large	O
number	O
of	O
contour	O
points	B
or	O
a	O
smaller	O
number	O
interpo-	O
lated	O
with	O
a	O
b-spline	O
.	O
2.	O
deﬁne	O
your	O
internal	O
smoothness	O
energy	O
function	O
and	O
decide	O
what	O
image-based	B
attrac-	O
tive	O
forces	O
to	O
use	O
.	O
3.	O
at	O
each	O
iteration	O
,	O
set	O
up	O
the	O
banded	O
linear	B
system	O
of	O
equations	B
(	O
quadratic	O
energy	O
func-	O
tion	B
)	O
and	O
solve	O
it	O
using	O
banded	O
cholesky	O
factorization	B
(	O
appendix	O
a.4	O
)	O
.	O
ex	O
5.3	O
:	O
intelligent	B
scissors	I
implement	O
the	O
intelligent	B
scissors	I
(	O
live-wire	O
)	O
interactive	B
seg-	O
mentation	O
algorithm	B
(	O
mortensen	O
and	O
barrett	O
1995	O
)	O
and	O
design	O
a	O
graphical	O
user	O
interface	O
(	O
gui	O
)	O
to	O
let	O
you	O
draw	O
such	O
curves	O
over	O
an	O
image	B
and	O
use	O
them	O
for	O
segmentation	O
.	O
ex	O
5.4	O
:	O
region	B
segmentation	O
implement	O
one	O
of	O
the	O
region	B
segmentation	O
algorithms	O
de-	O
scribed	O
in	O
this	O
chapter	O
.	O
some	O
popular	O
segmentation	B
algorithms	O
include	O
:	O
•	O
k-means	B
(	O
section	O
5.3.1	O
)	O
;	O
•	O
mixtures	O
of	O
gaussians	O
(	O
section	O
5.3.1	O
)	O
;	O
•	O
mean	B
shift	I
(	O
section	O
5.3.2	O
)	O
and	O
exercise	O
5.5	O
;	O
•	O
normalized	B
cuts	I
(	O
section	O
5.4	O
)	O
;	O
•	O
similarity	B
graph-based	O
segmentation	B
(	O
section	O
5.2.4	O
)	O
;	O
•	O
binary	O
markov	O
random	O
ﬁelds	O
solved	O
using	O
graph	O
cuts	O
(	O
section	O
5.5	O
)	O
.	O
apply	O
your	O
region	B
segmentation	O
to	O
a	O
video	B
sequence	O
and	O
use	O
it	O
to	O
track	O
moving	O
regions	O
from	O
frame	O
to	O
frame	O
.	O
alternatively	O
,	O
test	O
out	O
your	O
segmentation	B
algorithm	O
on	O
the	O
berkeley	O
segmentation	B
database	O
(	O
martin	O
,	O
fowlkes	O
,	O
tal	O
et	O
al	O
.	O
2001	O
)	O
.	O
ex	O
5.5	O
:	O
mean	B
shift	I
develop	O
a	O
mean-shift	O
segmentation	B
algorithm	O
for	O
color	O
images	O
(	O
co-	O
maniciu	O
and	O
meer	O
2002	O
)	O
.	O
1.	O
convert	O
your	O
image	B
to	O
l*a*b*	O
space	O
,	O
or	O
keep	O
the	O
original	O
rgb	O
colors	O
,	O
and	O
augment	O
them	O
with	O
the	O
pixel	O
(	O
x	O
,	O
y	O
)	O
locations	O
.	O
2.	O
for	O
every	O
pixel	O
(	O
l	O
,	O
a	O
,	O
b	O
,	O
x	O
,	O
y	O
)	O
,	O
compute	O
the	O
weighted	B
mean	O
of	O
its	O
neighbors	O
using	O
either	O
a	O
unit	O
ball	O
(	O
epanechnikov	O
kernel	B
)	O
or	O
ﬁnite-radius	O
gaussian	O
,	O
or	O
some	O
other	O
kernel	B
of	O
your	O
choosing	O
.	O
weight	O
the	O
color	B
and	O
spatial	O
scales	O
differently	O
,	O
e.g.	O
,	O
using	O
values	O
of	O
(	O
hs	O
,	O
hr	O
,	O
m	O
)	O
=	O
(	O
16	O
,	O
19	O
,	O
40	O
)	O
as	O
shown	O
in	O
figure	O
5.18	O
.	O
308	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
3.	O
replace	O
the	O
current	O
value	O
with	O
this	O
weighted	B
mean	O
and	O
iterate	O
until	O
either	O
the	O
motion	B
is	O
below	O
a	O
threshold	O
or	O
a	O
ﬁnite	O
number	O
of	O
steps	O
has	O
been	O
taken	O
.	O
4.	O
cluster	O
all	O
ﬁnal	O
values	O
(	O
modes	O
)	O
that	O
are	O
within	O
a	O
threshold	O
,	O
i.e.	O
,	O
ﬁnd	O
the	O
connected	B
components	I
.	O
since	O
each	O
pixel	O
is	O
associated	O
with	O
a	O
ﬁnal	O
mean-shift	O
(	O
mode	O
)	O
value	O
,	O
this	O
results	O
in	O
an	O
image	B
segmentation	O
,	O
i.e.	O
,	O
each	O
pixel	O
is	O
labeled	O
with	O
its	O
ﬁnal	O
component	O
.	O
5	O
.	O
(	O
optional	O
)	O
use	O
a	O
random	O
subset	O
of	O
the	O
pixels	O
as	O
starting	O
points	B
and	O
ﬁnd	O
which	O
com-	O
ponent	O
each	O
unlabeled	O
pixel	O
belongs	O
to	O
,	O
either	O
by	O
ﬁnding	O
its	O
nearest	B
neighbor	I
or	O
by	O
iterating	O
the	O
mean	B
shift	I
until	O
it	O
ﬁnds	O
a	O
neighboring	O
track	O
of	O
mean-shift	O
values	O
.	O
describe	O
the	O
data	O
structures	O
you	O
use	O
to	O
make	O
this	O
efﬁcient	O
.	O
6	O
.	O
(	O
optional	O
)	O
mean	B
shift	I
divides	O
the	O
kernel	B
density	O
function	O
estimate	O
by	O
the	O
local	B
weight-	O
ing	O
to	O
obtain	O
a	O
step	O
size	O
that	O
is	O
guaranteed	O
to	O
converge	O
but	O
may	O
be	O
slow	O
.	O
use	O
an	O
alter-	O
native	O
step	O
size	O
estimation	B
algorithm	O
from	O
the	O
optimization	O
literature	O
to	O
see	O
if	O
you	O
can	O
make	O
the	O
algorithm	B
converge	O
faster	O
.	O
chapter	O
6	O
feature-based	B
alignment	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6.1	O
6.2	O
pose	O
estimation	B
.	O
.	O
.	O
3d	O
alignment	B
.	O
.	O
.	O
.	O
.	O
iterative	B
algorithms	O
.	O
iterative	B
algorithms	O
.	O
.	O
2d	O
alignment	B
using	O
least	B
squares	I
.	O
.	O
.	O
.	O
2d	O
and	O
3d	O
feature-based	B
alignment	O
.	O
6.1.1	O
6.1.2	O
application	O
:	O
panography	B
.	O
.	O
6.1.3	O
.	O
.	O
6.1.4	O
robust	B
least	O
squares	O
and	O
ransac	O
.	O
6.1.5	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6.3.1	O
calibration	B
patterns	O
.	O
.	O
6.3.2	O
vanishing	B
points	I
.	O
6.3.3	O
application	O
:	O
single	O
view	O
metrology	O
.	O
.	O
6.3.4	O
rotational	B
motion	I
.	O
.	O
.	O
6.3.5	O
radial	B
distortion	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6.2.1	O
linear	B
algorithms	O
.	O
6.2.2	O
.	O
6.2.3	O
application	O
:	O
augmented	B
reality	I
.	O
.	O
.	O
.	O
6.3	O
geometric	B
intrinsic	O
calibration	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6.4	O
additional	O
reading	O
.	O
.	O
6.5	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
311	O
.	O
312	O
.	O
314	O
.	O
315	O
.	O
318	O
.	O
320	O
.	O
321	O
.	O
322	O
.	O
324	O
.	O
326	O
.	O
327	O
.	O
327	O
.	O
329	O
.	O
331	O
.	O
332	O
.	O
334	O
.	O
335	O
.	O
336	O
310	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
6.1	O
geometric	B
alignment	I
and	O
calibration	B
:	O
(	O
a	O
)	O
geometric	B
alignment	I
of	O
2d	O
images	O
for	O
stitching	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
;	O
(	O
b	O
)	O
a	O
two-dimensional	B
calibration	O
target	O
(	O
zhang	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
ieee	O
;	O
(	O
c	O
)	O
calibration	B
from	O
vanishing	B
points	I
;	O
(	O
d	O
)	O
scene	O
with	O
easy-to-	O
ﬁnd	O
lines	B
and	O
vanishing	O
directions	O
(	O
criminisi	O
,	O
reid	O
,	O
and	O
zisserman	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
springer	O
.	O
x1x0x2x1x0x2c	O
6.1	O
2d	O
and	O
3d	O
feature-based	B
alignment	O
311	O
figure	O
6.2	O
basic	O
set	O
of	O
2d	O
planar	O
transformations	O
once	O
we	O
have	O
extracted	O
features	O
from	O
images	O
,	O
the	O
next	O
stage	O
in	O
many	O
vision	O
algorithms	O
is	O
to	O
match	O
these	O
features	O
across	O
different	O
images	O
(	O
section	O
4.1.3	O
)	O
.	O
an	O
important	O
component	O
of	O
this	O
matching	B
is	O
to	O
verify	O
whether	O
the	O
set	O
of	O
matching	B
features	O
is	O
geometrically	O
consistent	O
,	O
e.g.	O
,	O
whether	O
the	O
feature	B
displacements	O
can	O
be	O
described	O
by	O
a	O
simple	O
2d	O
or	O
3d	O
geometric	B
transformation	O
.	O
the	O
computed	O
motions	O
can	O
then	O
be	O
used	O
in	O
other	O
applications	O
such	O
as	O
image	B
stitching	I
(	O
chapter	O
9	O
)	O
or	O
augmented	B
reality	I
(	O
section	O
6.2.3	O
)	O
.	O
in	O
this	O
chapter	O
,	O
we	O
look	O
at	O
the	O
topic	O
of	O
geometric	B
image	O
registration	B
,	O
i.e.	O
,	O
the	O
computation	O
of	O
2d	O
and	O
3d	O
transformations	O
that	O
map	O
features	O
in	O
one	O
image	B
to	O
another	O
(	O
section	O
6.1	O
)	O
.	O
one	O
special	O
case	O
of	O
this	O
problem	O
is	O
pose	O
estimation	B
,	O
which	O
is	O
determining	O
a	O
camera	B
’	O
s	O
position	O
relative	O
to	O
a	O
known	O
3d	O
object	O
or	O
scene	O
(	O
section	O
6.2	O
)	O
.	O
another	O
case	O
is	O
the	O
computation	O
of	O
a	O
camera	B
’	O
s	O
intrinsic	B
calibration	O
,	O
which	O
consists	O
of	O
the	O
internal	O
parameters	O
such	O
as	O
focal	O
length	O
and	O
radial	B
distortion	I
(	O
section	O
6.3	O
)	O
.	O
in	O
chapter	O
7	O
,	O
we	O
look	O
at	O
the	O
related	O
problems	O
of	O
how	O
to	O
estimate	O
3d	O
point	O
structure	O
from	O
2d	O
matches	O
(	O
triangulation	B
)	O
and	O
how	O
to	O
simultaneously	O
estimate	O
3d	O
geometry	O
and	O
camera	B
motion	O
(	O
structure	B
from	I
motion	I
)	O
.	O
6.1	O
2d	O
and	O
3d	O
feature-based	B
alignment	O
feature-based	B
alignment	O
is	O
the	O
problem	O
of	O
estimating	O
the	O
motion	B
between	O
two	O
or	O
more	O
sets	O
of	O
matched	O
2d	O
or	O
3d	O
points	B
.	O
in	O
this	O
section	O
,	O
we	O
restrict	O
ourselves	O
to	O
global	B
parametric	O
trans-	O
formations	O
,	O
such	O
as	O
those	O
described	O
in	O
section	O
2.1.2	O
and	O
shown	O
in	O
table	O
2.1	O
and	O
figure	O
6.2	O
,	O
or	O
higher	O
order	O
transformation	O
for	O
curved	O
surfaces	O
(	O
shashua	O
and	O
toelg	O
1997	O
;	O
can	O
,	O
stewart	O
,	O
roysam	O
et	O
al	O
.	O
2002	O
)	O
.	O
applications	O
to	O
non-rigid	B
or	O
elastic	O
deformations	O
(	O
bookstein	O
1989	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
torresani	O
,	O
hertzmann	O
,	O
and	O
bregler	O
2008	O
)	O
are	O
examined	O
in	O
sec-	O
tions	O
8.3	O
and	O
12.6.4.	O
yxsimilarityeuclideanaffineprojectivetranslation	O
312	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
transform	B
matrix	O
parameters	B
p	O
jacobian	O
j	O
translation	B
euclidean	O
similarity	B
afﬁne	O
projective	B
tx	O
tx	O
b	O
sθ	O
cθ	O
0	O
1	O
(	O
cid:34	O
)	O
1	O
0	O
tx	O
ty	O
(	O
cid:35	O
)	O
ty	O
(	O
cid:35	O
)	O
(	O
cid:34	O
)	O
cθ	O
−sθ	O
(	O
cid:34	O
)	O
1	O
+	O
a	O
−b	O
1	O
+	O
a	O
ty	O
(	O
cid:35	O
)	O
(	O
cid:34	O
)	O
1	O
+	O
a00	O
ty	O
(	O
cid:35	O
)	O
	O
	O
h02	O
1	O
+	O
h11	O
h12	O
1	O
1	O
+	O
h00	O
1	O
+	O
a11	O
h10	O
h20	O
h01	O
h21	O
a01	O
a10	O
tx	O
(	O
tx	O
,	O
ty	O
)	O
(	O
tx	O
,	O
ty	O
,	O
θ	O
)	O
(	O
tx	O
,	O
ty	O
,	O
a	O
,	O
b	O
)	O
(	O
tx	O
,	O
ty	O
,	O
a00	O
,	O
a01	O
,	O
a10	O
,	O
a11	O
)	O
0	O
0	O
(	O
cid:34	O
)	O
1	O
(	O
cid:34	O
)	O
1	O
(	O
cid:34	O
)	O
1	O
(	O
cid:34	O
)	O
1	O
0	O
0	O
0	O
1	O
(	O
cid:35	O
)	O
cθx	O
−	O
sθy	O
(	O
cid:35	O
)	O
0	O
−sθx	O
−	O
cθy	O
1	O
x	O
(	O
cid:35	O
)	O
0	O
x	O
−y	O
1	O
0	O
x	O
y	O
(	O
cid:35	O
)	O
0	O
x	O
y	O
1	O
0	O
0	O
0	O
y	O
(	O
h00	O
,	O
h01	O
,	O
.	O
.	O
.	O
,	O
h21	O
)	O
(	O
see	O
section	O
6.1.3	O
)	O
table	O
6.1	O
jacobians	O
of	O
the	O
2d	O
coordinate	B
transformations	I
x	O
(	O
cid:48	O
)	O
=	O
f	O
(	O
x	O
;	O
p	O
)	O
shown	O
in	O
table	O
2.1	O
,	O
where	O
we	O
have	O
re-parameterized	O
the	O
motions	O
so	O
that	O
they	O
are	O
identity	O
for	O
p	O
=	O
0	O
.	O
6.1.1	O
2d	O
alignment	B
using	O
least	B
squares	I
given	O
a	O
set	O
of	O
matched	O
feature	B
points	O
{	O
(	O
xi	O
,	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
}	O
and	O
a	O
planar	O
parametric	O
transformation1	O
of	O
the	O
form	O
x	O
(	O
cid:48	O
)	O
=	O
f	O
(	O
x	O
;	O
p	O
)	O
,	O
(	O
6.1	O
)	O
how	O
can	O
we	O
produce	O
the	O
best	O
estimate	O
of	O
the	O
motion	B
parameters	O
p	O
?	O
the	O
usual	O
way	O
to	O
do	O
this	O
is	O
to	O
use	O
least	B
squares	I
,	O
i.e.	O
,	O
to	O
minimize	O
the	O
sum	O
of	O
squared	O
residuals	O
where	O
els	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
2	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
f	O
(	O
xi	O
;	O
p	O
)	O
−	O
x	O
(	O
cid:48	O
)	O
i	O
(	O
cid:107	O
)	O
2	O
,	O
ri	O
=	O
f	O
(	O
xi	O
;	O
p	O
)	O
−	O
x	O
(	O
cid:48	O
)	O
i	O
=	O
ˆx	O
(	O
cid:48	O
)	O
i	O
−	O
˜x	O
(	O
cid:48	O
)	O
i	O
(	O
6.2	O
)	O
(	O
6.3	O
)	O
is	O
the	O
residual	O
between	O
the	O
measured	O
location	O
ˆx	O
(	O
cid:48	O
)	O
i	O
and	O
its	O
corresponding	O
current	O
predicted	O
location	O
˜x	O
(	O
cid:48	O
)	O
i	O
=	O
f	O
(	O
xi	O
;	O
p	O
)	O
.	O
(	O
see	O
appendix	O
a.2	O
for	O
more	O
on	O
least	B
squares	I
and	O
appendix	O
b.2	O
for	O
a	O
statistical	O
justiﬁcation	O
.	O
)	O
1	O
for	O
examples	O
of	O
non-planar	O
parametric	B
models	O
,	O
such	O
as	O
quadrics	O
,	O
see	O
the	O
work	O
of	O
shashua	O
and	O
toelg	O
(	O
1997	O
)	O
;	O
shashua	O
and	O
wexler	O
(	O
2001	O
)	O
.	O
6.1	O
2d	O
and	O
3d	O
feature-based	B
alignment	O
313	O
many	O
of	O
the	O
motion	B
models	I
presented	O
in	O
section	O
2.1.2	O
and	O
table	O
2.1	O
,	O
i.e.	O
,	O
translation	B
,	O
similarity	B
,	O
and	O
afﬁne	B
,	O
have	O
a	O
linear	B
relationship	O
between	O
the	O
amount	O
of	O
motion	B
∆x	O
=	O
x	O
(	O
cid:48	O
)	O
−	O
x	O
and	O
the	O
unknown	O
parameters	B
p	O
,	O
∆x	O
=	O
x	O
(	O
cid:48	O
)	O
−	O
x	O
=	O
j	O
(	O
x	O
)	O
p	O
,	O
(	O
6.4	O
)	O
where	O
j	O
=	O
∂f	O
/∂p	O
is	O
the	O
jacobian	O
of	O
the	O
transformation	O
f	O
with	O
respect	O
to	O
the	O
motion	B
param-	O
eters	O
p	O
(	O
see	O
table	O
6.1	O
)	O
.	O
in	O
this	O
case	O
,	O
a	O
simple	O
linear	B
regression	O
(	O
linear	B
least	O
squares	O
problem	O
)	O
can	O
be	O
formulated	O
as	O
ells	O
=	O
(	O
cid:88	O
)	O
i	O
=	O
pt	O
(	O
cid:34	O
)	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
j	O
(	O
xi	O
)	O
p	O
−	O
∆xi	O
(	O
cid:107	O
)	O
2	O
j	O
t	O
(	O
xi	O
)	O
j	O
(	O
xi	O
)	O
(	O
cid:35	O
)	O
p	O
−	O
2pt	O
(	O
cid:34	O
)	O
(	O
cid:88	O
)	O
i	O
=	O
pt	O
ap	O
−	O
2pt	O
b	O
+	O
c.	O
(	O
6.5	O
)	O
j	O
t	O
(	O
xi	O
)	O
∆xi	O
(	O
cid:35	O
)	O
+	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
∆xi	O
(	O
cid:107	O
)	O
2	O
(	O
6.6	O
)	O
(	O
6.7	O
)	O
the	O
minimum	O
can	O
be	O
found	O
by	O
solving	O
the	O
symmetric	O
positive	O
deﬁnite	O
(	O
spd	O
)	O
system	O
of	O
nor-	O
mal	O
equations2	O
where	O
ap	O
=	O
b	O
,	O
a	O
=	O
(	O
cid:88	O
)	O
i	O
j	O
t	O
(	O
xi	O
)	O
j	O
(	O
xi	O
)	O
(	O
6.8	O
)	O
(	O
6.9	O
)	O
is	O
called	O
the	O
hessian	O
and	O
b	O
=	O
(	O
cid:80	O
)	O
i	O
j	O
t	O
(	O
xi	O
)	O
∆xi	O
.	O
for	O
the	O
case	O
of	O
pure	B
translation	I
,	O
the	O
result-	O
ing	O
equations	B
have	O
a	O
particularly	O
simple	O
form	O
,	O
i.e.	O
,	O
the	O
translation	B
is	O
the	O
average	O
translation	B
between	O
corresponding	O
points	B
or	O
,	O
equivalently	O
,	O
the	O
translation	B
of	O
the	O
point	O
centroids	O
.	O
uncertainty	B
weighting	O
.	O
the	O
above	O
least	B
squares	I
formulation	O
assumes	O
that	O
all	O
feature	B
points	O
are	O
matched	O
with	O
the	O
same	O
accuracy	B
.	O
this	O
is	O
often	O
not	O
the	O
case	O
,	O
since	O
certain	O
points	B
may	O
fall	O
into	O
more	O
textured	O
regions	O
than	O
others	O
.	O
if	O
we	O
associate	O
a	O
scalar	O
variance	O
estimate	O
σ2	O
i	O
with	O
each	O
correspondence	B
,	O
we	O
can	O
minimize	O
the	O
weighted	B
least	O
squares	O
problem	O
instead,3	O
ewls	O
=	O
(	O
cid:88	O
)	O
i	O
σ−2	O
i	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
2	O
.	O
(	O
6.10	O
)	O
as	O
shown	O
in	O
section	O
8.1.3	O
,	O
a	O
covariance	O
estimate	O
for	O
patch-based	O
matching	B
can	O
be	O
obtained	O
by	O
multiplying	O
the	O
inverse	B
of	O
the	O
patch	B
hessian	O
ai	O
(	O
8.55	O
)	O
with	O
the	O
per-pixel	O
noise	B
covariance	O
2	O
for	O
poorly	O
conditioned	O
problems	O
,	O
it	O
is	O
better	O
to	O
use	O
qr	O
decomposition	O
on	O
the	O
set	O
of	O
linear	B
equations	O
j	O
(	O
xi	O
)	O
p	O
=	O
∆xi	O
instead	O
of	O
the	O
normal	O
equations	O
(	O
bj¨orck	O
1996	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
)	O
.	O
however	O
,	O
such	O
conditions	O
rarely	O
arise	O
in	O
image	B
registration	I
.	O
3	O
problems	O
where	O
each	O
measurement	O
can	O
have	O
a	O
different	O
variance	O
or	O
certainty	O
are	O
called	O
heteroscedastic	B
models	O
.	O
314	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
6.3	O
a	O
simple	O
panograph	O
consisting	O
of	O
three	O
images	O
automatically	O
aligned	O
with	O
a	O
translational	B
model	O
and	O
then	O
averaged	O
together	O
.	O
n	O
(	O
8.44	O
)	O
.	O
weighting	B
each	O
squared	O
residual	O
by	O
its	O
inverse	B
covariance	O
σ−1	O
σ2	O
is	O
called	O
the	O
information	O
matrix	O
)	O
,	O
we	O
obtain	O
i	O
=	O
σ−2	O
n	O
ai	O
(	O
which	O
ecwls	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
2	O
−1	O
σ	O
i	O
=	O
(	O
cid:88	O
)	O
i	O
i	O
σ−1	O
rt	O
i	O
ri	O
=	O
(	O
cid:88	O
)	O
i	O
σ−2	O
n	O
rt	O
i	O
airi	O
.	O
(	O
6.11	O
)	O
6.1.2	O
application	O
:	O
panography	B
one	O
of	O
the	O
simplest	O
(	O
and	O
most	O
fun	O
)	O
applications	O
of	O
image	B
alignment	O
is	O
a	O
special	O
form	O
of	O
image	B
stitching	I
called	O
panography	B
.	O
in	O
a	O
panograph	O
,	O
images	O
are	O
translated	O
and	O
optionally	O
rotated	O
and	O
scaled	O
before	O
being	O
blended	O
with	O
simple	O
averaging	O
(	O
figure	O
6.3	O
)	O
.	O
this	O
process	O
mimics	O
the	O
photographic	O
collages	O
created	O
by	O
artist	O
david	O
hockney	O
,	O
although	O
his	O
compositions	O
use	O
an	O
opaque	O
overlay	O
model	O
,	O
being	O
created	O
out	O
of	O
regular	O
photographs	O
.	O
in	O
most	O
of	O
the	O
examples	B
seen	O
on	O
the	O
web	O
,	O
the	O
images	O
are	O
aligned	O
by	O
hand	O
for	O
best	O
artistic	O
effect.4	O
however	O
,	O
it	O
is	O
also	O
possible	O
to	O
use	O
feature	B
matching	O
and	O
alignment	B
techniques	O
to	O
perform	O
the	O
registration	B
automatically	O
(	O
nomura	O
,	O
zhang	O
,	O
and	O
nayar	O
2007	O
;	O
zelnik-manor	O
and	O
perona	O
2007	O
)	O
.	O
consider	O
a	O
simple	O
translational	B
model	O
.	O
we	O
want	O
all	O
the	O
corresponding	O
features	O
in	O
different	O
images	O
to	O
line	O
up	O
as	O
best	O
as	O
possible	O
.	O
let	O
tj	O
be	O
the	O
location	O
of	O
the	O
jth	O
image	B
coordinate	O
frame	O
in	O
the	O
global	B
composite	O
frame	O
and	O
xij	O
be	O
the	O
location	O
of	O
the	O
ith	O
matched	O
feature	B
in	O
the	O
jth	O
image	B
.	O
in	O
order	B
to	O
align	O
the	O
images	O
,	O
we	O
wish	O
to	O
minimize	O
the	O
least	B
squares	I
error	O
epls	O
=	O
(	O
cid:88	O
)	O
ij	O
(	O
cid:107	O
)	O
(	O
tj	O
+	O
xij	O
)	O
−	O
xi	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
6.12	O
)	O
4	O
http	O
:	O
//www.ﬂickr.com/groups/panography/	O
.	O
6.1	O
2d	O
and	O
3d	O
feature-based	B
alignment	O
315	O
where	O
xi	O
is	O
the	O
consensus	O
(	O
average	O
)	O
position	O
of	O
feature	B
i	O
in	O
the	O
global	B
coordinate	O
frame	O
.	O
(	O
an	O
alternative	O
approach	O
is	O
to	O
register	O
each	O
pair	O
of	O
overlapping	O
images	O
separately	O
and	O
then	O
compute	O
a	O
consensus	O
location	O
for	O
each	O
frame—see	O
exercise	O
6.2	O
.	O
)	O
the	O
above	O
least	B
squares	I
problem	O
is	O
indeterminate	O
(	O
you	O
can	O
add	O
a	O
constant	O
offset	O
to	O
all	O
the	O
frame	O
and	O
point	O
locations	O
tj	O
and	O
xi	O
)	O
.	O
to	O
ﬁx	O
this	O
,	O
either	O
pick	O
one	O
frame	O
as	O
being	O
at	O
the	O
origin	O
or	O
add	O
a	O
constraint	B
to	O
make	O
the	O
average	O
frame	O
offsets	O
be	O
0.	O
the	O
formulas	O
for	O
adding	O
rotation	O
and	O
scale	O
transformations	O
are	O
straightforward	O
and	O
are	O
left	O
as	O
an	O
exercise	O
(	O
exercise	O
6.2	O
)	O
.	O
see	O
if	O
you	O
can	O
create	O
some	O
collages	O
that	O
you	O
would	O
be	O
happy	O
to	O
share	O
with	O
others	O
on	O
the	O
web	O
.	O
6.1.3	O
iterative	B
algorithms	O
while	O
linear	B
least	O
squares	O
is	O
the	O
simplest	O
method	O
for	O
estimating	O
parameters	B
,	O
most	O
problems	O
in	O
computer	O
vision	O
do	O
not	O
have	O
a	O
simple	O
linear	B
relationship	O
between	O
the	O
measurements	O
and	O
the	O
unknowns	O
.	O
in	O
this	O
case	O
,	O
the	O
resulting	O
problem	O
is	O
called	O
non-linear	B
least	O
squares	O
or	O
non-linear	B
regression	O
.	O
consider	O
,	O
for	O
example	O
,	O
the	O
problem	O
of	O
estimating	O
a	O
rigid	O
euclidean	O
2d	O
transformation	O
(	O
translation	B
plus	O
rotation	O
)	O
between	O
two	O
sets	O
of	O
points	B
.	O
if	O
we	O
parameterize	O
this	O
transformation	O
by	O
the	O
translation	B
amount	O
(	O
tx	O
,	O
ty	O
)	O
and	O
the	O
rotation	O
angle	O
θ	O
,	O
as	O
in	O
table	O
2.1	O
,	O
the	O
jacobian	O
of	O
this	O
transformation	O
,	O
given	O
in	O
table	O
6.1	O
,	O
depends	O
on	O
the	O
current	O
value	O
of	O
θ.	O
notice	O
how	O
in	O
table	O
6.1	O
,	O
we	O
have	O
re-parameterized	O
the	O
motion	B
matrices	O
so	O
that	O
they	O
are	O
always	O
the	O
identity	O
at	O
the	O
origin	O
p	O
=	O
0	O
,	O
which	O
makes	O
it	O
easier	O
to	O
initialize	O
the	O
motion	B
parameters	O
.	O
to	O
minimize	O
the	O
non-linear	B
least	O
squares	O
problem	O
,	O
we	O
iteratively	O
ﬁnd	O
an	O
update	O
∆p	O
to	O
the	O
current	O
parameter	O
estimate	O
p	O
by	O
minimizing	O
(	O
cid:107	O
)	O
f	O
(	O
xi	O
;	O
p	O
+	O
∆p	O
)	O
−	O
x	O
(	O
cid:48	O
)	O
i	O
(	O
cid:107	O
)	O
2	O
(	O
cid:107	O
)	O
j	O
(	O
xi	O
;	O
p	O
)	O
∆p	O
−	O
ri	O
(	O
cid:107	O
)	O
2	O
enls	O
(	O
∆p	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
≈	O
(	O
cid:88	O
)	O
i	O
=	O
∆pt	O
(	O
cid:34	O
)	O
(	O
cid:88	O
)	O
i	O
j	O
t	O
j	O
(	O
cid:35	O
)	O
∆p	O
−	O
2∆pt	O
(	O
cid:34	O
)	O
(	O
cid:88	O
)	O
i	O
j	O
t	O
ri	O
(	O
cid:35	O
)	O
+	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
2	O
=	O
∆pt	O
a∆p	O
−	O
2∆pt	O
b	O
+	O
c	O
,	O
(	O
6.13	O
)	O
(	O
6.14	O
)	O
(	O
6.15	O
)	O
(	O
6.16	O
)	O
(	O
6.17	O
)	O
where	O
the	O
“	O
hessian	O
”	O
5	O
a	O
is	O
the	O
same	O
as	O
equation	B
(	O
6.9	O
)	O
and	O
the	O
right	O
hand	O
side	O
vector	O
b	O
=	O
(	O
cid:88	O
)	O
i	O
j	O
t	O
(	O
xi	O
)	O
ri	O
5	O
the	O
“	O
hessian	O
”	O
a	O
is	O
not	O
the	O
true	O
hessian	O
(	O
second	O
derivative	O
)	O
of	O
the	O
non-linear	B
least	O
squares	O
problem	O
(	O
6.13	O
)	O
.	O
instead	O
,	O
it	O
is	O
the	O
approximate	O
hessian	O
,	O
which	O
neglects	O
second	O
(	O
and	O
higher	O
)	O
order	B
derivatives	O
of	O
f	O
(	O
xi	O
;	O
p	O
+	O
∆p	O
)	O
.	O
316	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
is	O
now	O
a	O
jacobian-weighted	O
sum	O
of	O
residual	O
vectors	O
.	O
this	O
makes	O
intuitive	O
sense	O
,	O
as	O
the	O
pa-	O
rameters	O
are	O
pulled	O
in	O
the	O
direction	O
of	O
the	O
prediction	O
error	O
with	O
a	O
strength	O
proportional	O
to	O
the	O
jacobian	O
.	O
once	O
a	O
and	O
b	O
have	O
been	O
computed	O
,	O
we	O
solve	O
for	O
∆p	O
using	O
(	O
a	O
+	O
λdiag	O
(	O
a	O
)	O
)	O
∆p	O
=	O
b	O
,	O
(	O
6.18	O
)	O
and	O
update	O
the	O
parameter	O
vector	O
p	O
←	O
p	O
+	O
∆p	O
accordingly	O
.	O
the	O
parameter	O
λ	O
is	O
an	O
addi-	O
tional	O
damping	O
parameter	O
used	O
to	O
ensure	O
that	O
the	O
system	O
takes	O
a	O
“	O
downhill	O
”	O
step	O
in	O
energy	O
(	O
squared	O
error	O
)	O
and	O
is	O
an	O
essential	O
component	O
of	O
the	O
levenberg–marquardt	O
algorithm	B
(	O
de-	O
scribed	O
in	O
more	O
detail	O
in	O
appendix	O
a.3	O
)	O
.	O
in	O
many	O
applications	O
,	O
it	O
can	O
be	O
set	O
to	O
0	O
if	O
the	O
system	O
is	O
successfully	O
converging	O
.	O
for	O
the	O
case	O
of	O
our	O
2d	O
translation+rotation	O
,	O
we	O
end	O
up	O
with	O
a	O
3×3	O
set	O
of	O
normal	O
equations	O
in	O
the	O
unknowns	O
(	O
δtx	O
,	O
δty	O
,	O
δθ	O
)	O
.	O
an	O
initial	O
guess	O
for	O
(	O
tx	O
,	O
ty	O
,	O
θ	O
)	O
can	O
be	O
obtained	O
by	O
ﬁtting	O
a	O
four-parameter	O
similarity	B
transform	O
in	O
(	O
tx	O
,	O
ty	O
,	O
c	O
,	O
s	O
)	O
and	O
then	O
setting	O
θ	O
=	O
tan−1	O
(	O
s/c	O
)	O
.	O
an	O
alternative	O
approach	O
is	O
to	O
estimate	O
the	O
translation	B
parameters	O
using	O
the	O
centroids	O
of	O
the	O
2d	O
points	B
and	O
to	O
then	O
estimate	O
the	O
rotation	O
angle	O
using	O
polar	O
coordinates	O
(	O
exercise	O
6.3	O
)	O
.	O
for	O
the	O
other	O
2d	O
motion	B
models	I
,	O
the	O
derivatives	O
in	O
table	O
6.1	O
are	O
all	O
fairly	O
straightforward	O
,	O
except	O
for	O
the	O
projective	B
2d	O
motion	B
(	O
homography	B
)	O
,	O
which	O
arises	O
in	O
image-stitching	O
applica-	O
tions	O
(	O
chapter	O
9	O
)	O
.	O
these	O
equations	B
can	O
be	O
re-written	O
from	O
(	O
2.21	O
)	O
in	O
their	O
new	O
parametric	B
form	O
as	O
x	O
(	O
cid:48	O
)	O
=	O
(	O
1	O
+	O
h00	O
)	O
x	O
+	O
h01y	O
+	O
h02	O
h20x	O
+	O
h21y	O
+	O
1	O
and	O
y	O
(	O
cid:48	O
)	O
=	O
h10x	O
+	O
(	O
1	O
+	O
h11	O
)	O
y	O
+	O
h12	O
h20x	O
+	O
h21y	O
+	O
1	O
the	O
jacobian	O
is	O
therefore	O
j	O
=	O
∂f	O
∂p	O
=	O
1	O
d	O
(	O
cid:34	O
)	O
x	O
y	O
0	O
0	O
0	O
1	O
0	O
0	O
x	O
y	O
0	O
−x	O
(	O
cid:48	O
)	O
x	O
−x	O
(	O
cid:48	O
)	O
y	O
1	O
−y	O
(	O
cid:48	O
)	O
x	O
−y	O
(	O
cid:48	O
)	O
y	O
(	O
cid:35	O
)	O
,	O
.	O
(	O
6.19	O
)	O
(	O
6.20	O
)	O
where	O
d	O
=	O
h20x	O
+	O
h21y	O
+	O
1	O
is	O
the	O
denominator	O
in	O
(	O
6.19	O
)	O
,	O
which	O
depends	O
on	O
the	O
current	O
parameter	O
settings	O
(	O
as	O
do	O
x	O
(	O
cid:48	O
)	O
and	O
y	O
(	O
cid:48	O
)	O
)	O
.	O
an	O
initial	O
guess	O
for	O
the	O
eight	O
unknowns	O
{	O
h00	O
,	O
h01	O
,	O
.	O
.	O
.	O
,	O
h21	O
}	O
can	O
be	O
obtained	O
by	O
multiply-	O
ing	O
both	O
sides	O
of	O
the	O
equations	B
in	O
(	O
6.19	O
)	O
through	O
by	O
the	O
denominator	O
,	O
which	O
yields	O
the	O
linear	B
set	O
of	O
equations	B
,	O
(	O
cid:34	O
)	O
ˆx	O
(	O
cid:48	O
)	O
−	O
x	O
ˆy	O
(	O
cid:48	O
)	O
−	O
y	O
(	O
cid:35	O
)	O
=	O
(	O
cid:34	O
)	O
x	O
y	O
0	O
0	O
0	O
1	O
0	O
0	O
x	O
y	O
0	O
−ˆx	O
(	O
cid:48	O
)	O
x	O
−ˆx	O
(	O
cid:48	O
)	O
y	O
1	O
−ˆy	O
(	O
cid:48	O
)	O
x	O
−ˆy	O
(	O
cid:48	O
)	O
y	O
(	O
cid:35	O
)	O
	O
h00	O
...	O
h21	O
	O
.	O
(	O
6.21	O
)	O
however	O
,	O
this	O
is	O
not	O
optimal	O
from	O
a	O
statistical	O
point	O
of	O
view	O
,	O
since	O
the	O
denominator	O
d	O
,	O
which	O
was	O
used	O
to	O
multiply	O
each	O
equation	B
,	O
can	O
vary	O
quite	O
a	O
bit	O
from	O
point	O
to	O
point.6	O
6	O
hartley	O
and	O
zisserman	O
(	O
2004	O
)	O
call	O
this	O
strategy	B
of	O
forming	O
linear	B
equations	O
from	O
rational	O
equations	B
the	O
direct	B
6.1	O
2d	O
and	O
3d	O
feature-based	B
alignment	O
317	O
one	O
way	O
to	O
compensate	O
for	O
this	O
is	O
to	O
reweight	O
each	O
equation	B
by	O
the	O
inverse	B
of	O
the	O
current	O
estimate	O
of	O
the	O
denominator	O
,	O
d	O
,	O
1	O
d	O
(	O
cid:34	O
)	O
ˆx	O
(	O
cid:48	O
)	O
−	O
x	O
ˆy	O
(	O
cid:48	O
)	O
−	O
y	O
(	O
cid:35	O
)	O
=	O
1	O
d	O
(	O
cid:34	O
)	O
x	O
y	O
0	O
0	O
0	O
1	O
0	O
0	O
x	O
y	O
0	O
−ˆx	O
(	O
cid:48	O
)	O
x	O
−ˆx	O
(	O
cid:48	O
)	O
y	O
1	O
−ˆy	O
(	O
cid:48	O
)	O
x	O
−ˆy	O
(	O
cid:48	O
)	O
y	O
(	O
cid:35	O
)	O
	O
h00	O
...	O
h21	O
	O
.	O
(	O
6.22	O
)	O
while	O
this	O
may	O
at	O
ﬁrst	O
seem	O
to	O
be	O
the	O
exact	O
same	O
set	O
of	O
equations	B
as	O
(	O
6.21	O
)	O
,	O
because	O
least	B
squares	I
is	O
being	O
used	O
to	O
solve	O
the	O
over-determined	O
set	O
of	O
equations	B
,	O
the	O
weightings	O
do	O
matter	O
and	O
produce	O
a	O
different	O
set	O
of	O
normal	O
equations	O
that	O
performs	O
better	O
in	O
practice	O
.	O
the	O
most	O
principled	O
way	O
to	O
do	O
the	O
estimation	B
,	O
however	O
,	O
is	O
to	O
directly	O
minimize	O
the	O
squared	O
residual	O
equations	B
(	O
6.13	O
)	O
using	O
the	O
gauss–newton	O
approximation	O
,	O
i.e.	O
,	O
performing	O
a	O
ﬁrst-	O
order	B
taylor	O
series	O
expansion	O
in	O
p	O
,	O
as	O
shown	O
in	O
(	O
6.14	O
)	O
,	O
which	O
yields	O
the	O
set	O
of	O
equations	B
(	O
cid:34	O
)	O
ˆx	O
(	O
cid:48	O
)	O
−	O
˜x	O
(	O
cid:48	O
)	O
ˆy	O
(	O
cid:48	O
)	O
−	O
˜y	O
(	O
cid:48	O
)	O
(	O
cid:35	O
)	O
=	O
1	O
d	O
(	O
cid:34	O
)	O
x	O
y	O
0	O
0	O
0	O
1	O
0	O
0	O
x	O
y	O
0	O
−˜x	O
(	O
cid:48	O
)	O
x	O
−˜x	O
(	O
cid:48	O
)	O
y	O
1	O
−˜y	O
(	O
cid:48	O
)	O
x	O
−˜y	O
(	O
cid:48	O
)	O
y	O
(	O
cid:35	O
)	O
	O
∆h00	O
...	O
∆h21	O
	O
.	O
(	O
6.23	O
)	O
while	O
these	O
look	O
similar	O
to	O
(	O
6.22	O
)	O
,	O
they	O
differ	O
in	O
two	O
important	O
respects	O
.	O
first	O
,	O
the	O
left	O
hand	O
side	O
consists	O
of	O
unweighted	O
prediction	O
errors	O
rather	O
than	O
point	O
displacements	O
and	O
the	O
solution	O
vector	O
is	O
a	O
perturbation	O
to	O
the	O
parameter	O
vector	O
p.	O
second	O
,	O
the	O
quantities	O
inside	O
j	O
involve	O
predicted	O
feature	B
locations	O
(	O
˜x	O
(	O
cid:48	O
)	O
,	O
˜y	O
(	O
cid:48	O
)	O
)	O
instead	O
of	O
sensed	O
feature	B
locations	O
(	O
ˆx	O
(	O
cid:48	O
)	O
,	O
ˆy	O
(	O
cid:48	O
)	O
)	O
.	O
both	O
of	O
these	O
differences	O
are	O
subtle	O
and	O
yet	O
they	O
lead	O
to	O
an	O
algorithm	B
that	O
,	O
when	O
combined	O
with	O
proper	O
checking	O
for	O
downhill	O
steps	O
(	O
as	O
in	O
the	O
levenberg–marquardt	O
algorithm	B
)	O
,	O
will	O
converge	O
to	O
a	O
local	B
minimum	O
.	O
note	O
that	O
iterating	O
equations	B
(	O
6.22	O
)	O
is	O
not	O
guaranteed	O
to	O
converge	O
,	O
since	O
it	O
is	O
not	O
minimizing	O
a	O
well-deﬁned	O
energy	O
function	O
.	O
equation	B
(	O
6.23	O
)	O
is	O
analogous	O
to	O
the	O
additive	O
algorithm	B
for	O
direct	B
intensity-based	O
regis-	O
tration	O
(	O
section	O
8.2	O
)	O
,	O
since	O
the	O
change	O
to	O
the	O
full	O
transformation	O
is	O
being	O
computed	O
.	O
if	O
we	O
prepend	O
an	O
incremental	B
homography	O
to	O
the	O
current	O
homography	B
instead	O
,	O
i.e.	O
,	O
we	O
use	O
a	O
com-	O
positional	O
algorithm	B
(	O
described	O
in	O
section	O
8.2	O
)	O
,	O
we	O
get	O
d	O
=	O
1	O
(	O
since	O
p	O
=	O
0	O
)	O
and	O
the	O
above	O
formula	O
simpliﬁes	O
to	O
ˆy	O
(	O
cid:48	O
)	O
−	O
y	O
(	O
cid:35	O
)	O
=	O
(	O
cid:34	O
)	O
x	O
y	O
(	O
cid:34	O
)	O
ˆx	O
(	O
cid:48	O
)	O
−	O
x	O
0	O
0	O
0	O
1	O
0	O
0	O
x	O
y	O
0	O
−x2	O
−xy	O
1	O
−xy	O
−y2	O
(	O
cid:35	O
)	O
	O
∆h00	O
...	O
∆h21	O
	O
,	O
(	O
6.24	O
)	O
where	O
we	O
have	O
replaced	O
(	O
˜x	O
(	O
cid:48	O
)	O
,	O
˜y	O
(	O
cid:48	O
)	O
)	O
with	O
(	O
x	O
,	O
y	O
)	O
for	O
conciseness	O
.	O
(	O
notice	O
how	O
this	O
results	O
in	O
the	O
same	O
jacobian	O
as	O
(	O
8.63	O
)	O
.	O
)	O
linear	B
transform	O
,	O
but	O
that	O
term	O
is	O
more	O
commonly	O
associated	O
with	O
pose	O
estimation	B
(	O
section	O
6.2	O
)	O
.	O
note	O
also	O
that	O
our	O
deﬁnition	O
of	O
the	O
hij	O
parameters	B
differs	O
from	O
that	O
used	O
in	O
their	O
book	O
,	O
since	O
we	O
deﬁne	O
hii	O
to	O
be	O
the	O
difference	B
from	O
unity	O
and	O
we	O
do	O
not	O
leave	O
h22	O
as	O
a	O
free	O
parameter	O
,	O
which	O
means	O
that	O
we	O
can	O
not	O
handle	O
certain	O
extreme	O
homographies	O
.	O
318	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
6.1.4	O
robust	B
least	O
squares	O
and	O
ransac	O
while	O
regular	O
least	B
squares	I
is	O
the	O
method	O
of	O
choice	O
for	O
measurements	O
where	O
the	O
noise	B
follows	O
a	O
normal	O
(	O
gaussian	O
)	O
distribution	O
,	O
more	O
robust	B
versions	O
of	O
least	B
squares	I
are	O
required	O
when	O
there	O
are	O
outliers	O
among	O
the	O
correspondences	O
(	O
as	O
there	O
almost	O
always	O
are	O
)	O
.	O
in	O
this	O
case	O
,	O
it	O
is	O
preferable	O
to	O
use	O
an	O
m-estimator	O
(	O
huber	O
1981	O
;	O
hampel	O
,	O
ronchetti	O
,	O
rousseeuw	O
et	O
al	O
.	O
1986	O
;	O
black	O
and	O
rangarajan	O
1996	O
;	O
stewart	O
1999	O
)	O
,	O
which	O
involves	O
applying	O
a	O
robust	B
penalty	O
function	O
ρ	O
(	O
r	O
)	O
to	O
the	O
residuals	O
erls	O
(	O
∆p	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
ρ	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
(	O
6.25	O
)	O
(	O
6.26	O
)	O
instead	O
of	O
squaring	O
them	O
.	O
we	O
can	O
take	O
the	O
derivative	O
of	O
this	O
function	O
with	O
respect	O
to	O
p	O
and	O
set	O
it	O
to	O
0	O
,	O
ψ	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
∂	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
∂p	O
(	O
cid:88	O
)	O
i	O
=	O
(	O
cid:88	O
)	O
i	O
ψ	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
rt	O
i	O
∂ri	O
∂p	O
=	O
0	O
,	O
where	O
ψ	O
(	O
r	O
)	O
=	O
ρ	O
(	O
cid:48	O
)	O
(	O
r	O
)	O
is	O
the	O
derivative	O
of	O
ρ	O
and	O
is	O
called	O
the	O
inﬂuence	O
function	O
.	O
if	O
we	O
introduce	O
a	O
weight	O
function	O
,	O
w	O
(	O
r	O
)	O
=	O
ψ	O
(	O
r	O
)	O
/r	O
,	O
we	O
observe	O
that	O
ﬁnding	O
the	O
stationary	O
point	O
of	O
(	O
6.25	O
)	O
using	O
(	O
6.26	O
)	O
is	O
equivalent	O
to	O
minimizing	O
the	O
iteratively	B
reweighted	I
least	O
squares	O
(	O
irls	O
)	O
problem	O
eirls	O
=	O
(	O
cid:88	O
)	O
i	O
w	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
6.27	O
)	O
where	O
the	O
w	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
play	O
the	O
same	O
local	B
weighting	O
role	O
as	O
σ−2	O
in	O
(	O
6.10	O
)	O
.	O
the	O
irls	O
algo-	O
rithm	O
alternates	O
between	O
computing	O
the	O
inﬂuence	O
functions	O
w	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
and	O
solving	O
the	O
result-	O
ing	O
weighted	B
least	O
squares	O
problem	O
(	O
with	O
ﬁxed	O
w	O
values	O
)	O
.	O
other	O
incremental	B
robust	O
least	B
squares	I
algorithms	O
can	O
be	O
found	O
in	O
the	O
work	O
of	O
sawhney	O
and	O
ayer	O
(	O
1996	O
)	O
;	O
black	O
and	O
anan-	O
dan	O
(	O
1996	O
)	O
;	O
black	O
and	O
rangarajan	O
(	O
1996	O
)	O
;	O
baker	O
,	O
gross	O
,	O
ishikawa	O
et	O
al	O
.	O
(	O
2003	O
)	O
and	O
textbooks	B
and	O
tutorials	O
on	O
robust	B
statistics	O
(	O
huber	O
1981	O
;	O
hampel	O
,	O
ronchetti	O
,	O
rousseeuw	O
et	O
al	O
.	O
1986	O
;	O
rousseeuw	O
and	O
leroy	O
1987	O
;	O
stewart	O
1999	O
)	O
.	O
i	O
while	O
m-estimators	O
can	O
deﬁnitely	O
help	O
reduce	O
the	O
inﬂuence	O
of	O
outliers	O
,	O
in	O
some	O
cases	O
,	O
starting	O
with	O
too	O
many	O
outliers	O
will	O
prevent	O
irls	O
(	O
or	O
other	O
gradient	B
descent	I
algorithms	O
)	O
from	O
converging	O
to	O
the	O
global	B
optimum	O
.	O
a	O
better	O
approach	O
is	O
often	O
to	O
ﬁnd	O
a	O
starting	O
set	O
of	O
inlier	O
correspondences	O
,	O
i.e.	O
,	O
points	B
that	O
are	O
consistent	O
with	O
a	O
dominant	O
motion	B
estimate.7	O
two	O
widely	O
used	O
approaches	O
to	O
this	O
problem	O
are	O
called	O
random	O
sample	O
consensus	O
,	O
or	O
ransac	O
for	O
short	O
(	O
fischler	O
and	O
bolles	O
1981	O
)	O
,	O
and	O
least	O
median	O
of	O
squares	O
(	O
lms	O
)	O
(	O
rousseeuw	O
1984	O
)	O
.	O
both	O
techniques	O
start	O
by	O
selecting	O
(	O
at	O
random	O
)	O
a	O
subset	O
of	O
k	O
correspondences	O
,	O
which	O
is	O
7	O
for	O
pixel-based	O
alignment	B
methods	O
(	O
section	O
8.1.1	O
)	O
,	O
hierarchical	B
(	O
coarse-to-ﬁne	B
)	O
techniques	O
are	O
often	O
used	O
to	O
lock	O
onto	O
the	O
dominant	O
motion	B
in	O
a	O
scene	O
.	O
6.1	O
2d	O
and	O
3d	O
feature-based	B
alignment	O
319	O
then	O
used	O
to	O
compute	O
an	O
initial	O
estimate	O
for	O
p.	O
the	O
residuals	O
of	O
the	O
full	O
set	O
of	O
correspondences	O
are	O
then	O
computed	O
as	O
(	O
6.28	O
)	O
where	O
˜x	O
(	O
cid:48	O
)	O
i	O
are	O
the	O
estimated	O
(	O
mapped	O
)	O
locations	O
and	O
ˆx	O
(	O
cid:48	O
)	O
i	O
are	O
the	O
sensed	O
(	O
detected	O
)	O
feature	B
point	O
locations	O
.	O
ri	O
=	O
˜x	O
(	O
cid:48	O
)	O
i	O
(	O
xi	O
;	O
p	O
)	O
−	O
ˆx	O
(	O
cid:48	O
)	O
i	O
,	O
the	O
ransac	O
technique	O
then	O
counts	O
the	O
number	O
of	O
inliers	B
that	O
are	O
within	O
	O
of	O
their	O
pre-	O
dicted	O
location	O
,	O
i.e.	O
,	O
whose	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
≤	O
	O
.	O
(	O
the	O
	O
value	O
is	O
application	O
dependent	O
but	O
is	O
often	O
around	O
1–3	O
pixels	O
.	O
)	O
least	O
median	O
of	O
squares	O
ﬁnds	O
the	O
median	B
value	O
of	O
the	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
2	O
values	O
.	O
the	O
random	O
selection	O
process	O
is	O
repeated	O
s	O
times	O
and	O
the	O
sample	O
set	O
with	O
the	O
largest	O
number	O
of	O
inliers	B
(	O
or	O
with	O
the	O
smallest	O
median	B
residual	O
)	O
is	O
kept	O
as	O
the	O
ﬁnal	O
solution	O
.	O
either	O
the	O
initial	O
parameter	O
guess	O
p	O
or	O
the	O
full	O
set	O
of	O
computed	O
inliers	B
is	O
then	O
passed	O
on	O
to	O
the	O
next	O
data	O
ﬁtting	O
stage	O
.	O
when	O
the	O
number	O
of	O
measurements	O
is	O
quite	O
large	O
,	O
it	O
may	O
be	O
preferable	O
to	O
only	O
score	O
a	O
subset	O
of	O
the	O
measurements	O
in	O
an	O
initial	O
round	O
that	O
selects	O
the	O
most	O
plausible	O
hypotheses	O
for	O
additional	O
scoring	O
and	O
selection	O
.	O
this	O
modiﬁcation	O
of	O
ransac	O
,	O
which	O
can	O
signiﬁcantly	O
speed	O
up	O
its	O
performance	O
,	O
is	O
called	O
preemptive	B
ransac	O
(	O
nist´er	O
2003	O
)	O
.	O
in	O
another	O
variant	O
on	O
ransac	O
called	O
prosac	O
(	O
progressive	O
sample	O
consensus	O
)	O
,	O
random	O
samples	O
are	O
ini-	O
tially	O
added	O
from	O
the	O
most	O
“	O
conﬁdent	O
”	O
matches	O
,	O
thereby	O
speeding	O
up	O
the	O
process	O
of	O
ﬁnding	O
a	O
(	O
statistically	O
)	O
likely	O
good	O
set	O
of	O
inliers	B
(	O
chum	O
and	O
matas	O
2005	O
)	O
.	O
to	O
ensure	O
that	O
the	O
random	O
sampling	O
has	O
a	O
good	O
chance	O
of	O
ﬁnding	O
a	O
true	O
set	O
of	O
inliers	B
,	O
a	O
sufﬁcient	O
number	O
of	O
trials	O
s	O
must	O
be	O
tried	O
.	O
let	O
p	O
be	O
the	O
probability	O
that	O
any	O
given	O
correspon-	O
dence	O
is	O
valid	O
and	O
p	O
be	O
the	O
total	B
probability	O
of	O
success	O
after	O
s	O
trials	O
.	O
the	O
likelihood	O
in	O
one	O
trial	O
that	O
all	O
k	O
random	O
samples	O
are	O
inliers	B
is	O
pk	O
.	O
therefore	O
,	O
the	O
likelihood	O
that	O
s	O
such	O
trials	O
will	O
all	O
fail	O
is	O
and	O
the	O
required	O
minimum	O
number	O
of	O
trials	O
is	O
1	O
−	O
p	O
=	O
(	O
1	O
−	O
pk	O
)	O
s	O
(	O
6.29	O
)	O
(	O
6.30	O
)	O
s	O
=	O
log	O
(	O
1	O
−	O
p	O
)	O
log	O
(	O
1	O
−	O
pk	O
)	O
.	O
stewart	O
(	O
1999	O
)	O
gives	O
examples	B
of	O
the	O
required	O
number	O
of	O
trials	O
s	O
to	O
attain	O
a	O
99	O
%	O
proba-	O
bility	O
of	O
success	O
.	O
as	O
you	O
can	O
see	O
from	O
table	O
6.2	O
,	O
the	O
number	O
of	O
trials	O
grows	O
quickly	O
with	O
the	O
number	O
of	O
sample	O
points	B
used	O
.	O
this	O
provides	O
a	O
strong	O
incentive	O
to	O
use	O
the	O
minimum	O
number	O
of	O
sample	O
points	B
k	O
possible	O
for	O
any	O
given	O
trial	O
,	O
which	O
is	O
how	O
ransac	O
is	O
normally	O
used	O
in	O
practice	O
.	O
uncertainty	B
modeling	I
in	O
addition	O
to	O
robustly	O
computing	O
a	O
good	O
alignment	B
,	O
some	O
applications	O
require	O
the	O
compu-	O
tation	O
of	O
uncertainty	B
(	O
see	O
appendix	O
b.6	O
)	O
.	O
for	O
linear	O
problems	O
,	O
this	O
estimate	O
can	O
be	O
obtained	O
320	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
k	O
3	O
6	O
6	O
p	O
0.5	O
0.6	O
0.5	O
s	O
35	O
97	O
293	O
table	O
6.2	O
number	O
of	O
trials	O
s	O
to	O
attain	O
a	O
99	O
%	O
probability	O
of	O
success	O
(	O
stewart	O
1999	O
)	O
.	O
by	O
inverting	O
the	O
hessian	O
matrix	O
(	O
6.9	O
)	O
and	O
multiplying	O
it	O
by	O
the	O
feature	B
position	O
noise	B
(	O
if	O
these	O
have	O
not	O
already	O
been	O
used	O
to	O
weight	O
the	O
individual	O
measurements	O
,	O
as	O
in	O
equations	B
(	O
6.10	O
)	O
and	O
6.11	O
)	O
)	O
.	O
in	O
statistics	O
,	O
the	O
hessian	O
,	O
which	O
is	O
the	O
inverse	B
covariance	O
,	O
is	O
sometimes	O
called	O
the	O
(	O
fisher	O
)	O
information	O
matrix	O
(	O
appendix	O
b.1.1	O
)	O
.	O
when	O
the	O
problem	O
involves	O
non-linear	B
least	O
squares	O
,	O
the	O
inverse	B
of	O
the	O
hessian	O
matrix	O
provides	O
the	O
cramer–rao	O
lower	O
bound	O
on	O
the	O
covariance	O
matrix	O
,	O
i.e.	O
,	O
it	O
provides	O
the	O
minimum	O
amount	O
of	O
covariance	O
in	O
a	O
given	O
solution	O
,	O
which	O
can	O
actually	O
have	O
a	O
wider	O
spread	O
(	O
“	O
longer	O
tails	O
”	O
)	O
if	O
the	O
energy	O
ﬂattens	O
out	O
away	O
from	O
the	O
local	B
minimum	O
where	O
the	O
optimal	O
solution	O
is	O
found	O
.	O
6.1.5	O
3d	O
alignment	B
instead	O
of	O
aligning	O
2d	O
sets	O
of	O
image	B
features	O
,	O
many	O
computer	O
vision	O
applications	O
require	O
the	O
alignment	B
of	O
3d	O
points	B
.	O
in	O
the	O
case	O
where	O
the	O
3d	O
transformations	O
are	O
linear	B
in	O
the	O
motion	B
parameters	O
,	O
e.g.	O
,	O
for	O
translation	O
,	O
similarity	B
,	O
and	O
afﬁne	B
,	O
regular	O
least	B
squares	I
(	O
6.5	O
)	O
can	O
be	O
used	O
.	O
the	O
case	O
of	O
rigid	O
(	O
euclidean	O
)	O
motion	B
,	O
er3d	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
x	O
(	O
cid:48	O
)	O
i	O
−	O
rxi	O
−	O
t	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
6.31	O
)	O
which	O
arises	O
more	O
frequently	O
and	O
is	O
often	O
called	O
the	O
absolute	B
orientation	I
problem	O
(	O
horn	O
1987	O
)	O
,	O
requires	O
slightly	O
different	O
techniques	O
.	O
if	O
only	O
scalar	O
weightings	O
are	O
being	O
used	O
(	O
as	O
opposed	O
to	O
full	O
3d	O
per-point	O
anisotropic	B
covariance	O
estimates	O
)	O
,	O
the	O
weighted	B
centroids	O
of	O
the	O
two	O
point	O
clouds	O
c	O
and	O
c	O
(	O
cid:48	O
)	O
can	O
be	O
used	O
to	O
estimate	O
the	O
translation	B
t	O
=	O
c	O
(	O
cid:48	O
)	O
−	O
rc.8	O
we	O
are	O
then	O
left	O
with	O
the	O
problem	O
of	O
estimating	O
the	O
rotation	O
between	O
two	O
sets	O
of	O
points	B
{	O
ˆxi	O
=	O
xi	O
−	O
c	O
}	O
and	O
{	O
ˆx	O
(	O
cid:48	O
)	O
i	O
=	O
x	O
(	O
cid:48	O
)	O
i	O
−	O
c	O
(	O
cid:48	O
)	O
}	O
that	O
are	O
both	O
centered	O
at	O
the	O
origin	O
.	O
one	O
commonly	O
used	O
technique	O
is	O
called	O
the	O
orthogonal	O
procrustes	O
algorithm	B
(	O
golub	O
and	O
van	O
loan	O
1996	O
,	O
p.	O
601	O
)	O
and	O
involves	O
computing	O
the	O
singular	O
value	O
decomposition	O
(	O
svd	O
)	O
of	O
8	O
when	O
full	O
covariances	O
are	O
used	O
,	O
they	O
are	O
transformed	O
by	O
the	O
rotation	O
and	O
so	O
a	O
closed-form	O
solution	O
for	O
transla-	O
tion	B
is	O
not	O
possible	O
.	O
6.2	O
pose	O
estimation	B
the	O
3	O
×	O
3	O
correlation	O
matrix	O
c	O
=	O
(	O
cid:88	O
)	O
i	O
ˆx	O
(	O
cid:48	O
)	O
ˆxt	O
=	O
uσv	O
t	O
.	O
321	O
(	O
6.32	O
)	O
the	O
rotation	O
matrix	O
is	O
then	O
obtained	O
as	O
r	O
=	O
u	O
v	O
t	O
.	O
(	O
verify	O
this	O
for	O
yourself	O
when	O
ˆx	O
(	O
cid:48	O
)	O
=	O
rˆx	O
.	O
)	O
another	O
technique	O
is	O
the	O
absolute	B
orientation	I
algorithm	O
(	O
horn	O
1987	O
)	O
for	O
estimating	O
the	O
unit	O
quaternion	O
corresponding	O
to	O
the	O
rotation	O
matrix	O
r	O
,	O
which	O
involves	O
forming	O
a	O
4×4	O
matrix	O
from	O
the	O
entries	O
in	O
c	O
and	O
then	O
ﬁnding	O
the	O
eigenvector	O
associated	O
with	O
its	O
largest	O
positive	O
eigenvalue	O
.	O
lorusso	O
,	O
eggert	O
,	O
and	O
fisher	O
(	O
1995	O
)	O
experimentally	O
compare	O
these	O
two	O
techniques	O
to	O
two	O
additional	O
techniques	O
proposed	O
in	O
the	O
literature	O
,	O
but	O
ﬁnd	O
that	O
the	O
difference	B
in	O
accuracy	B
is	O
negligible	O
(	O
well	O
below	O
the	O
effects	O
of	O
measurement	O
noise	B
)	O
.	O
in	O
situations	O
where	O
these	O
closed-form	O
algorithms	O
are	O
not	O
applicable	O
,	O
e.g.	O
,	O
when	O
full	O
3d	O
covariances	O
are	O
being	O
used	O
or	O
when	O
the	O
3d	O
alignment	B
is	O
part	O
of	O
some	O
larger	O
optimization	O
,	O
the	O
incremental	B
rotation	O
update	O
introduced	O
in	O
section	O
2.1.4	O
(	O
2.35–2.36	O
)	O
,	O
which	O
is	O
parameterized	O
by	O
an	O
instantaneous	O
rotation	O
vector	O
ω	O
,	O
can	O
be	O
used	O
(	O
see	O
section	O
9.1.3	O
for	O
an	O
application	O
to	O
image	B
stitching	I
.	O
)	O
in	O
some	O
situations	O
,	O
e.g.	O
,	O
when	O
merging	B
range	O
data	O
maps	O
,	O
the	O
correspondence	B
between	O
data	O
points	O
is	O
not	O
known	O
a	O
priori	O
.	O
in	O
this	O
case	O
,	O
iterative	B
algorithms	O
that	O
start	O
by	O
matching	O
nearby	O
points	B
and	O
then	O
update	O
the	O
most	O
likely	O
correspondence	B
can	O
be	O
used	O
(	O
besl	O
and	O
mckay	O
1992	O
;	O
zhang	O
1994	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
gold	O
,	O
rangarajan	O
,	O
lu	O
et	O
al	O
.	O
1998	O
;	O
david	O
,	O
dementhon	O
,	O
duraiswami	O
et	O
al	O
.	O
2004	O
;	O
li	O
and	O
hartley	O
2007	O
;	O
enqvist	O
,	O
josephson	O
,	O
and	O
kahl	O
2009	O
)	O
.	O
these	O
techniques	O
are	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
12.2.1	O
.	O
6.2	O
pose	O
estimation	B
a	O
particular	O
instance	B
of	O
feature-based	B
alignment	O
,	O
which	O
occurs	O
very	O
often	O
,	O
is	O
estimating	O
an	O
object	O
’	O
s	O
3d	O
pose	O
from	O
a	O
set	O
of	O
2d	O
point	O
projections	O
.	O
this	O
pose	O
estimation	B
problem	O
is	O
also	O
known	O
as	O
extrinsic	B
calibration	O
,	O
as	O
opposed	O
to	O
the	O
intrinsic	B
calibration	O
of	O
internal	O
camera	O
pa-	O
rameters	O
such	O
as	O
focal	O
length	O
,	O
which	O
we	O
discuss	O
in	O
section	O
6.3.	O
the	O
problem	O
of	O
recovering	O
pose	O
from	O
three	O
correspondences	O
,	O
which	O
is	O
the	O
minimal	O
amount	O
of	O
information	O
necessary	O
,	O
is	O
known	O
as	O
the	O
perspective-3-point-problem	O
(	O
p3p	O
)	O
,	O
with	O
extensions	O
to	O
larger	O
numbers	O
of	O
points	B
collectively	O
known	O
as	O
pnp	O
(	O
haralick	O
,	O
lee	O
,	O
ottenberg	O
et	O
al	O
.	O
1994	O
;	O
quan	O
and	O
lan	O
1999	O
;	O
moreno-noguer	O
,	O
lepetit	O
,	O
and	O
fua	O
2007	O
)	O
.	O
in	O
this	O
section	O
,	O
we	O
look	O
at	O
some	O
of	O
the	O
techniques	O
that	O
have	O
been	O
developed	O
to	O
solve	O
such	O
problems	O
,	O
starting	O
with	O
the	O
direct	B
linear	O
transform	B
(	O
dlt	O
)	O
,	O
which	O
recovers	O
a	O
3×	O
4	O
camera	B
ma-	O
trix	O
,	O
followed	O
by	O
other	O
“	O
linear	B
”	O
algorithms	O
,	O
and	O
then	O
looking	O
at	O
statistically	O
optimal	O
iterative	B
algorithms	O
.	O
322	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
6.2.1	O
linear	B
algorithms	O
the	O
simplest	O
way	O
to	O
recover	O
the	O
pose	O
of	O
the	O
camera	B
is	O
to	O
form	O
a	O
set	O
of	O
linear	B
equations	O
analo-	O
gous	O
to	O
those	O
used	O
for	O
2d	O
motion	B
estimation	I
(	O
6.19	O
)	O
from	O
the	O
camera	B
matrix	O
form	O
of	O
perspec-	O
tive	O
projection	O
(	O
2.55–2.56	O
)	O
,	O
xi	O
=	O
p00xi	O
+	O
p01yi	O
+	O
p02zi	O
+	O
p03	O
p20xi	O
+	O
p21yi	O
+	O
p22zi	O
+	O
p23	O
yi	O
=	O
p10xi	O
+	O
p11yi	O
+	O
p12zi	O
+	O
p13	O
p20xi	O
+	O
p21yi	O
+	O
p22zi	O
+	O
p23	O
,	O
(	O
6.33	O
)	O
(	O
6.34	O
)	O
where	O
(	O
xi	O
,	O
yi	O
)	O
are	O
the	O
measured	O
2d	O
feature	B
locations	O
and	O
(	O
xi	O
,	O
yi	O
,	O
zi	O
)	O
are	O
the	O
known	O
3d	O
feature	B
locations	O
(	O
figure	O
6.4	O
)	O
.	O
as	O
with	O
(	O
6.21	O
)	O
,	O
this	O
system	O
of	O
equations	B
can	O
be	O
solved	O
in	O
a	O
linear	B
fashion	O
for	O
the	O
unknowns	O
in	O
the	O
camera	B
matrix	O
p	O
by	O
multiplying	O
the	O
denominator	O
on	O
both	O
sides	O
of	O
the	O
equation.9	O
the	O
resulting	O
algorithm	B
is	O
called	O
the	O
direct	B
linear	O
transform	B
(	O
dlt	O
)	O
and	O
is	O
commonly	O
attributed	O
to	O
sutherland	O
(	O
1974	O
)	O
.	O
(	O
for	O
a	O
more	O
in-depth	O
discussion	O
,	O
refer	O
to	O
the	O
work	O
of	O
hartley	O
and	O
zisserman	O
(	O
2004	O
)	O
.	O
)	O
in	O
order	B
to	O
compute	O
the	O
12	O
(	O
or	O
11	O
)	O
unknowns	O
in	O
p	O
,	O
at	O
least	O
six	O
correspondences	O
between	O
3d	O
and	O
2d	O
locations	O
must	O
be	O
known	O
.	O
as	O
with	O
the	O
case	O
of	O
estimating	O
homographies	O
(	O
6.21–6.23	O
)	O
,	O
more	O
accurate	O
results	O
for	O
the	O
entries	O
in	O
p	O
can	O
be	O
obtained	O
by	O
directly	O
minimizing	O
the	O
set	O
of	O
equations	B
(	O
6.33–6.34	O
)	O
using	O
non-linear	O
least	B
squares	I
with	O
a	O
small	O
number	O
of	O
iterations	O
.	O
once	O
the	O
entries	O
in	O
p	O
have	O
been	O
recovered	O
,	O
it	O
is	O
possible	O
to	O
recover	O
both	O
the	O
intrinsic	B
calibration	O
matrix	O
k	O
and	O
the	O
rigid	O
transformation	O
(	O
r	O
,	O
t	O
)	O
by	O
observing	O
from	O
equation	B
(	O
2.56	O
)	O
that	O
p	O
=	O
k	O
[	O
r|t	O
]	O
.	O
(	O
6.35	O
)	O
since	O
k	O
is	O
by	O
convention	O
upper-triangular	O
(	O
see	O
the	O
discussion	O
in	O
section	O
2.1.5	O
)	O
,	O
both	O
k	O
and	O
r	O
can	O
be	O
obtained	O
from	O
the	O
front	O
3	O
×	O
3	O
sub-matrix	O
of	O
p	O
using	O
rq	O
factorization	B
(	O
golub	O
and	O
van	O
loan	O
1996	O
)	O
.10	O
in	O
most	O
applications	O
,	O
however	O
,	O
we	O
have	O
some	O
prior	B
knowledge	O
about	O
the	O
intrinsic	B
cali-	O
bration	O
matrix	O
k	O
,	O
e.g.	O
,	O
that	O
the	O
pixels	O
are	O
square	O
,	O
the	O
skew	O
is	O
very	O
small	O
,	O
and	O
the	O
optical	O
center	O
is	O
near	O
the	O
center	O
of	O
the	O
image	B
(	O
2.57–2.59	O
)	O
.	O
such	O
constraints	O
can	O
be	O
incorporated	O
into	O
a	O
non-linear	B
minimization	O
of	O
the	O
parameters	B
in	O
k	O
and	O
(	O
r	O
,	O
t	O
)	O
,	O
as	O
described	O
in	O
section	O
6.2.2.	O
in	O
the	O
case	O
where	O
the	O
camera	B
is	O
already	O
calibrated	O
,	O
i.e.	O
,	O
the	O
matrix	O
k	O
is	O
known	O
(	O
sec-	O
tion	B
6.3	O
)	O
,	O
we	O
can	O
perform	O
pose	O
estimation	B
using	O
as	O
few	O
as	O
three	O
points	B
(	O
fischler	O
and	O
bolles	O
1981	O
;	O
haralick	O
,	O
lee	O
,	O
ottenberg	O
et	O
al	O
.	O
1994	O
;	O
quan	O
and	O
lan	O
1999	O
)	O
.	O
the	O
basic	O
observation	O
that	O
these	O
linear	B
pnp	O
(	O
perspective	B
n-point	O
)	O
algorithms	O
employ	O
is	O
that	O
the	O
visual	O
angle	O
between	O
any	O
9	O
because	O
p	O
is	O
unknown	O
up	O
to	O
a	O
scale	O
,	O
we	O
can	O
either	O
ﬁx	O
one	O
of	O
the	O
entries	O
,	O
e.g.	O
,	O
p23	O
=	O
1	O
,	O
or	O
ﬁnd	O
the	O
smallest	O
singular	O
vector	O
of	O
the	O
set	O
of	O
linear	B
equations	O
.	O
10	O
note	O
the	O
unfortunate	O
clash	O
of	O
terminologies	O
:	O
in	O
matrix	O
algebra	O
textbooks	B
,	O
r	O
represents	O
an	O
upper-triangular	O
matrix	O
;	O
in	O
computer	O
vision	O
,	O
r	O
is	O
an	O
orthogonal	O
rotation	O
.	O
6.2	O
pose	O
estimation	B
323	O
figure	O
6.4	O
pose	O
estimation	B
by	O
the	O
direct	B
linear	O
transform	B
and	O
by	O
measuring	O
visual	O
angles	O
and	O
distances	O
between	O
pairs	B
of	O
points	B
.	O
pair	O
of	O
2d	O
points	B
ˆxi	O
and	O
ˆxj	O
must	O
be	O
the	O
same	O
as	O
the	O
angle	O
between	O
their	O
corresponding	O
3d	O
points	B
pi	O
and	O
pj	O
(	O
figure	O
6.4	O
)	O
.	O
given	O
a	O
set	O
of	O
corresponding	O
2d	O
and	O
3d	O
points	B
{	O
(	O
ˆxi	O
,	O
pi	O
)	O
}	O
,	O
where	O
the	O
ˆxi	O
are	O
unit	O
directions	O
obtained	O
by	O
transforming	O
2d	O
pixel	O
measurements	O
xi	O
to	O
unit	O
norm	O
3d	O
directions	O
ˆxi	O
through	O
the	O
inverse	B
calibration	O
matrix	O
k	O
,	O
ˆxi	O
=	O
n	O
(	O
k−1xi	O
)	O
=	O
k−1xi/	O
(	O
cid:107	O
)	O
k−1xi	O
(	O
cid:107	O
)	O
,	O
the	O
unknowns	O
are	O
the	O
distances	O
di	O
from	O
the	O
camera	B
origin	O
c	O
to	O
the	O
3d	O
points	B
pi	O
,	O
where	O
(	O
figure	O
6.4	O
)	O
.	O
the	O
cosine	O
law	O
for	O
triangle	O
∆	O
(	O
c	O
,	O
pi	O
,	O
pj	O
)	O
gives	O
us	O
pi	O
=	O
di	O
ˆxi	O
+	O
c	O
fij	O
(	O
di	O
,	O
dj	O
)	O
=	O
d2	O
i	O
+	O
d2	O
j	O
−	O
2didjcij	O
−	O
d2	O
ij	O
=	O
0	O
,	O
where	O
and	O
cij	O
=	O
cos	O
θij	O
=	O
ˆxi	O
·	O
ˆxj	O
ij	O
=	O
(	O
cid:107	O
)	O
pi	O
−	O
pj	O
(	O
cid:107	O
)	O
2.	O
d2	O
(	O
6.36	O
)	O
(	O
6.37	O
)	O
(	O
6.38	O
)	O
(	O
6.39	O
)	O
(	O
6.40	O
)	O
we	O
can	O
take	O
any	O
triplet	O
of	O
constraints	O
(	O
fij	O
,	O
fik	O
,	O
fjk	O
)	O
and	O
eliminate	O
the	O
dj	O
and	O
dk	O
using	O
sylvester	O
resultants	O
(	O
cox	O
,	O
little	O
,	O
and	O
o	O
’	O
shea	O
2007	O
)	O
to	O
obtain	O
a	O
quartic	O
equation	B
in	O
d2	O
i	O
,	O
gijk	O
(	O
d2	O
i	O
)	O
=	O
a4d8	O
i	O
+	O
a3d6	O
i	O
+	O
a2d4	O
i	O
+	O
a1d2	O
i	O
+	O
a0	O
=	O
0	O
.	O
(	O
6.41	O
)	O
given	O
ﬁve	O
or	O
more	O
correspondences	O
,	O
we	O
can	O
generate	O
(	O
n−1	O
)	O
(	O
n−2	O
)	O
estimate	O
(	O
using	O
svd	O
)	O
for	O
the	O
values	O
of	O
(	O
d8	O
triplets	O
to	O
obtain	O
a	O
linear	B
i	O
)	O
(	O
quan	O
and	O
lan	O
1999	O
)	O
.	O
estimates	O
for	O
i	O
,	O
d2	O
i	O
,	O
d6	O
i	O
,	O
d4	O
2	O
pi=	O
(	O
xi	O
,	O
yi	O
,	O
zi	O
,	O
wi	O
)	O
xipjdijdidjxjθijc	O
324	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
i	O
can	O
computed	O
as	O
ratios	B
of	O
successive	O
d2n+2	O
d2	O
obtain	O
a	O
ﬁnal	O
estimate	O
of	O
d2	O
i	O
(	O
and	O
hence	O
di	O
)	O
.	O
/d2n	O
i	O
estimates	O
and	O
these	O
can	O
be	O
averaged	O
to	O
i	O
once	O
the	O
individual	O
estimates	O
of	O
the	O
di	O
distances	O
have	O
been	O
computed	O
,	O
we	O
can	O
generate	O
a	O
3d	O
structure	O
consisting	O
of	O
the	O
scaled	O
point	O
directions	O
di	O
ˆxi	O
,	O
which	O
can	O
then	O
be	O
aligned	O
with	O
the	O
3d	O
point	O
cloud	O
{	O
pi	O
}	O
using	O
absolute	O
orientation	O
(	O
section	O
6.1.5	O
)	O
to	O
obtained	O
the	O
desired	O
pose	O
estimate	O
.	O
quan	O
and	O
lan	O
(	O
1999	O
)	O
give	O
accuracy	B
results	O
for	O
this	O
and	O
other	O
techniques	O
,	O
which	O
use	O
fewer	O
points	B
but	O
require	O
more	O
complicated	O
algebraic	O
manipulations	O
.	O
the	O
paper	O
by	O
moreno-noguer	O
,	O
lepetit	O
,	O
and	O
fua	O
(	O
2007	O
)	O
reviews	O
more	O
recent	O
alternatives	O
and	O
also	O
gives	O
a	O
lower	O
complexity	O
algorithm	B
that	O
typically	O
produces	O
more	O
accurate	O
results	O
.	O
unfortunately	O
,	O
because	O
minimal	O
pnp	O
solutions	O
can	O
be	O
quite	O
noise	B
sensitive	O
and	O
also	O
suffer	O
from	O
bas-relief	O
ambiguities	O
(	O
e.g.	O
,	O
depth	O
reversals	O
)	O
(	O
section	O
7.4.3	O
)	O
,	O
it	O
is	O
often	O
preferable	O
to	O
use	O
the	O
linear	B
six-point	O
algorithm	B
to	O
guess	O
an	O
initial	O
pose	O
and	O
then	O
optimize	O
this	O
estimate	O
using	O
the	O
iterative	B
technique	O
described	O
in	O
section	O
6.2.2.	O
an	O
alternative	O
pose	O
estimation	B
algorithm	O
involves	O
starting	O
with	O
a	O
scaled	O
orthographic	O
pro-	O
jection	O
model	O
and	O
then	O
iteratively	O
reﬁning	O
this	O
initial	O
estimate	O
using	O
a	O
more	O
accurate	O
perspec-	O
tive	O
projection	O
model	O
(	O
dementhon	O
and	O
davis	O
1995	O
)	O
.	O
the	O
attraction	O
of	O
this	O
model	O
,	O
as	O
stated	O
in	O
the	O
paper	O
’	O
s	O
title	O
,	O
is	O
that	O
it	O
can	O
be	O
implemented	O
“	O
in	O
25	O
lines	B
of	O
[	O
mathematica	O
]	O
code	O
”	O
.	O
6.2.2	O
iterative	B
algorithms	O
the	O
most	O
accurate	O
(	O
and	O
ﬂexible	O
)	O
way	O
to	O
estimate	O
pose	O
is	O
to	O
directly	O
minimize	O
the	O
squared	O
(	O
or	O
robust	B
)	O
reprojection	O
error	O
for	O
the	O
2d	O
points	B
as	O
a	O
function	O
of	O
the	O
unknown	O
pose	O
parameters	B
in	O
(	O
r	O
,	O
t	O
)	O
and	O
optionally	O
k	O
using	O
non-linear	O
least	B
squares	I
(	O
tsai	O
1987	O
;	O
bogart	O
1991	O
;	O
gleicher	O
and	O
witkin	O
1992	O
)	O
.	O
we	O
can	O
write	O
the	O
projection	O
equations	B
as	O
xi	O
=	O
f	O
(	O
pi	O
;	O
r	O
,	O
t	O
,	O
k	O
)	O
and	O
iteratively	O
minimize	O
the	O
robustiﬁed	O
linearized	O
reprojection	O
errors	O
enlp	O
=	O
(	O
cid:88	O
)	O
i	O
ρ	O
(	O
cid:18	O
)	O
∂f	O
∂r	O
∆r	O
+	O
∂f	O
∂t	O
∆t	O
+	O
∂f	O
∂k	O
∆k	O
−	O
ri	O
(	O
cid:19	O
)	O
,	O
(	O
6.42	O
)	O
(	O
6.43	O
)	O
where	O
ri	O
=	O
˜xi	O
−	O
ˆxi	O
is	O
the	O
current	O
residual	O
vector	O
(	O
2d	O
error	O
in	O
predicted	O
position	O
)	O
and	O
the	O
partial	O
derivatives	O
are	O
with	O
respect	O
to	O
the	O
unknown	O
pose	O
parameters	B
(	O
rotation	O
,	O
translation	B
,	O
and	O
optionally	O
calibration	B
)	O
.	O
note	O
that	O
if	O
full	O
2d	O
covariance	O
estimates	O
are	O
available	O
for	O
the	O
2d	O
feature	B
locations	O
,	O
the	O
above	O
squared	O
norm	O
can	O
be	O
weighted	B
by	O
the	O
inverse	B
point	O
covariance	O
matrix	O
,	O
as	O
in	O
equation	B
(	O
6.11	O
)	O
.	O
an	O
easier	O
to	O
understand	O
(	O
and	O
implement	O
)	O
version	O
of	O
the	O
above	O
non-linear	B
regression	O
prob-	O
lem	O
can	O
be	O
constructed	O
by	O
re-writing	O
the	O
projection	O
equations	B
as	O
a	O
concatenation	O
of	O
simpler	O
steps	O
,	O
each	O
of	O
which	O
transforms	O
a	O
4d	O
homogeneous	O
coordinate	O
pi	O
by	O
a	O
simple	O
transformation	O
6.2	O
pose	O
estimation	B
325	O
figure	O
6.5	O
a	O
set	O
of	O
chained	O
transforms	O
for	O
projecting	O
a	O
3d	O
point	O
pi	O
to	O
a	O
2d	O
measurement	O
xi	O
through	O
a	O
series	O
of	O
transformations	O
f	O
(	O
k	O
)	O
,	O
each	O
of	O
which	O
is	O
controlled	O
by	O
its	O
own	O
set	O
of	O
param-	O
eters	O
.	O
the	O
dashed	O
lines	B
indicate	O
the	O
ﬂow	O
of	O
information	O
as	O
partial	O
derivatives	O
are	O
computed	O
during	O
a	O
backward	O
pass	O
.	O
such	O
as	O
translation	B
,	O
rotation	O
,	O
or	O
perspective	B
division	O
(	O
figure	O
6.5	O
)	O
.	O
the	O
resulting	O
projection	O
equations	B
can	O
be	O
written	O
as	O
y	O
(	O
1	O
)	O
=	O
f	O
t	O
(	O
pi	O
;	O
cj	O
)	O
=	O
pi	O
−	O
cj	O
,	O
y	O
(	O
2	O
)	O
=	O
f	O
r	O
(	O
y	O
(	O
1	O
)	O
;	O
qj	O
)	O
=	O
r	O
(	O
qj	O
)	O
y	O
(	O
1	O
)	O
,	O
y	O
(	O
3	O
)	O
=	O
f	O
p	O
(	O
y	O
(	O
2	O
)	O
)	O
=	O
y	O
(	O
2	O
)	O
z	O
(	O
2	O
)	O
,	O
xi	O
=	O
f	O
c	O
(	O
y	O
(	O
3	O
)	O
;	O
k	O
)	O
=	O
k	O
(	O
k	O
)	O
y	O
(	O
3	O
)	O
.	O
(	O
6.44	O
)	O
(	O
6.45	O
)	O
(	O
6.46	O
)	O
(	O
6.47	O
)	O
note	O
that	O
in	O
these	O
equations	B
,	O
we	O
have	O
indexed	O
the	O
camera	B
centers	O
cj	O
and	O
camera	B
rotation	O
quaternions	B
qj	O
by	O
an	O
index	O
j	O
,	O
in	O
case	O
more	O
than	O
one	O
pose	O
of	O
the	O
calibration	B
object	O
is	O
being	O
used	O
(	O
see	O
also	O
section	O
7.4	O
.	O
)	O
we	O
are	O
also	O
using	O
the	O
camera	B
center	O
cj	O
instead	O
of	O
the	O
world	O
translation	B
tj	O
,	O
since	O
this	O
is	O
a	O
more	O
natural	B
parameter	O
to	O
estimate	O
.	O
the	O
advantage	O
of	O
this	O
chained	O
set	O
of	O
transformations	O
is	O
that	O
each	O
one	O
has	O
a	O
simple	O
partial	O
derivative	O
with	O
respect	O
both	O
to	O
its	O
parameters	B
and	O
to	O
its	O
input	O
.	O
thus	O
,	O
once	O
the	O
predicted	O
value	O
of	O
˜xi	O
has	O
been	O
computed	O
based	O
on	O
the	O
3d	O
point	O
location	O
pi	O
and	O
the	O
current	O
values	O
of	O
the	O
pose	O
parameters	B
(	O
cj	O
,	O
qj	O
,	O
k	O
)	O
,	O
we	O
can	O
obtain	O
all	O
of	O
the	O
required	O
partial	O
derivatives	O
using	O
the	O
chain	O
rule	O
(	O
6.48	O
)	O
∂ri	O
∂p	O
(	O
k	O
)	O
=	O
∂ri	O
∂y	O
(	O
k	O
)	O
∂y	O
(	O
k	O
)	O
∂p	O
(	O
k	O
)	O
,	O
where	O
p	O
(	O
k	O
)	O
indicates	O
one	O
of	O
the	O
parameter	O
vectors	O
that	O
is	O
being	O
optimized	O
.	O
(	O
this	O
same	O
“	O
trick	O
”	O
is	O
used	O
in	O
neural	B
networks	I
as	O
part	O
of	O
the	O
backpropagation	O
algorithm	B
(	O
bishop	O
2006	O
)	O
.	O
)	O
the	O
one	O
special	O
case	O
in	O
this	O
formulation	O
that	O
can	O
be	O
considerably	O
simpliﬁed	O
is	O
the	O
compu-	O
tation	O
of	O
the	O
rotation	O
update	O
.	O
instead	O
of	O
directly	O
computing	O
the	O
derivatives	O
of	O
the	O
3×3	O
rotation	O
matrix	O
r	O
(	O
q	O
)	O
as	O
a	O
function	O
of	O
the	O
unit	O
quaternion	O
entries	O
,	O
you	O
can	O
prepend	O
the	O
incremental	B
ro-	O
tation	O
matrix	O
∆r	O
(	O
ω	O
)	O
given	O
in	O
equation	B
(	O
2.35	O
)	O
to	O
the	O
current	O
rotation	O
matrix	O
and	O
compute	O
the	O
fc	O
(	O
x	O
)	O
=	O
kxkfp	O
(	O
x	O
)	O
=	O
p/zfr	O
(	O
x	O
)	O
=	O
rxqjft	O
(	O
x	O
)	O
=	O
x-ccjpixiy	O
(	O
1	O
)	O
y	O
(	O
2	O
)	O
y	O
(	O
3	O
)	O
326	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
6.6	O
the	O
videomouse	O
can	O
sense	O
six	O
degrees	O
of	O
freedom	O
relative	O
to	O
a	O
specially	O
printed	O
mouse	O
pad	O
using	O
its	O
embedded	O
camera	B
(	O
hinckley	O
,	O
sinclair	O
,	O
hanson	O
et	O
al	O
.	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
acm	O
:	O
(	O
a	O
)	O
top	O
view	O
of	O
the	O
mouse	O
;	O
(	O
b	O
)	O
view	O
of	O
the	O
mouse	O
showing	O
the	O
curved	O
base	O
for	O
rocking	O
;	O
(	O
c	O
)	O
moving	O
the	O
mouse	O
pad	O
with	O
the	O
other	O
hand	O
extends	O
the	O
interaction	O
capabilities	O
;	O
(	O
d	O
)	O
the	O
resulting	O
movement	O
seen	O
on	O
the	O
screen	O
.	O
partial	O
derivative	O
of	O
the	O
transform	B
with	O
respect	O
to	O
these	O
parameters	B
,	O
which	O
results	O
in	O
a	O
simple	O
cross	O
product	O
of	O
the	O
backward	O
chaining	O
partial	O
derivative	O
and	O
the	O
outgoing	O
3d	O
vector	O
(	O
2.36	O
)	O
.	O
6.2.3	O
application	O
:	O
augmented	B
reality	I
a	O
widely	O
used	O
application	O
of	O
pose	O
estimation	B
is	O
augmented	B
reality	I
,	O
where	O
virtual	O
3d	O
images	O
or	O
annotations	O
are	O
superimposed	O
on	O
top	O
of	O
a	O
live	O
video	B
feed	O
,	O
either	O
through	O
the	O
use	O
of	O
see-	O
through	O
glasses	O
(	O
a	O
head-mounted	O
display	O
)	O
or	O
on	O
a	O
regular	O
computer	O
or	O
mobile	O
device	O
screen	O
(	O
azuma	O
,	O
baillot	O
,	O
behringer	O
et	O
al	O
.	O
2001	O
;	O
haller	O
,	O
billinghurst	O
,	O
and	O
thomas	O
2007	O
)	O
.	O
in	O
some	O
applications	O
,	O
a	O
special	O
pattern	O
printed	O
on	O
cards	O
or	O
in	O
a	O
book	O
is	O
tracked	O
to	O
perform	O
the	O
aug-	O
mentation	O
(	O
kato	O
,	O
billinghurst	O
,	O
poupyrev	O
et	O
al	O
.	O
2000	O
;	O
billinghurst	O
,	O
kato	O
,	O
and	O
poupyrev	O
2001	O
)	O
.	O
for	O
a	O
desktop	O
application	O
,	O
a	O
grid	O
of	O
dots	O
printed	O
on	O
a	O
mouse	O
pad	O
can	O
be	O
tracked	O
by	O
a	O
camera	B
embedded	O
in	O
an	O
augmented	O
mouse	O
to	O
give	O
the	O
user	O
control	O
of	O
a	O
full	O
six	O
degrees	O
of	O
freedom	O
over	O
their	O
position	O
and	O
orientation	O
in	O
a	O
3d	O
space	O
(	O
hinckley	O
,	O
sinclair	O
,	O
hanson	O
et	O
al	O
.	O
1999	O
)	O
,	O
as	O
shown	O
in	O
figure	O
6.6.	O
sometimes	O
,	O
the	O
scene	O
itself	O
provides	O
a	O
convenient	O
object	O
to	O
track	O
,	O
such	O
as	O
the	O
rectangle	O
deﬁning	O
a	O
desktop	O
used	O
in	O
through-the-lens	O
camera	B
control	O
(	O
gleicher	O
and	O
witkin	O
1992	O
)	O
.	O
in	O
outdoor	O
locations	O
,	O
such	O
as	O
ﬁlm	O
sets	O
,	O
it	O
is	O
more	O
common	O
to	O
place	O
special	O
markers	O
such	O
as	O
brightly	O
colored	O
balls	O
in	O
the	O
scene	O
to	O
make	O
it	O
easier	O
to	O
ﬁnd	O
and	O
track	O
them	O
(	O
bogart	O
1991	O
)	O
.	O
in	O
older	O
applications	O
,	O
surveying	O
techniques	O
were	O
used	O
to	O
determine	O
the	O
locations	O
of	O
these	O
balls	O
before	O
ﬁlming	O
.	O
today	O
,	O
it	O
is	O
more	O
common	O
to	O
apply	O
structure-from-motion	O
directly	O
to	O
the	O
ﬁlm	O
footage	O
itself	O
(	O
section	O
7.4.2	O
)	O
.	O
rapid	O
pose	O
estimation	B
is	O
also	O
central	O
to	O
tracking	O
the	O
position	O
and	O
orientation	O
of	O
the	O
hand-	O
held	O
remote	O
controls	O
used	O
in	O
nintendo	O
’	O
s	O
wii	O
game	O
systems	O
.	O
a	O
high-speed	O
camera	B
embedded	O
in	O
the	O
remote	O
control	O
is	O
used	O
to	O
track	O
the	O
locations	O
of	O
the	O
infrared	O
(	O
ir	O
)	O
leds	O
in	O
the	O
bar	O
that	O
6.3	O
geometric	B
intrinsic	O
calibration	B
327	O
is	O
mounted	O
on	O
the	O
tv	O
monitor	O
.	O
pose	O
estimation	B
is	O
then	O
used	O
to	O
infer	O
the	O
remote	O
control	O
’	O
s	O
location	O
and	O
orientation	O
at	O
very	O
high	O
frame	O
rates	O
.	O
the	O
wii	O
system	O
can	O
be	O
extended	O
to	O
a	O
variety	O
of	O
other	O
user	O
interaction	O
applications	O
by	O
mounting	O
the	O
bar	O
on	O
a	O
hand-held	O
device	O
,	O
as	O
described	O
by	O
johnny	O
lee.11	O
exercises	O
6.4	O
and	O
6.5	O
have	O
you	O
implement	O
two	O
different	O
tracking	O
and	O
pose	O
estimation	B
sys-	O
tems	O
for	O
augmented-reality	O
applications	O
.	O
the	O
ﬁrst	O
system	O
tracks	O
the	O
outline	O
of	O
a	O
rectangular	O
object	O
,	O
such	O
as	O
a	O
book	O
cover	O
or	O
magazine	O
page	O
,	O
and	O
the	O
second	O
has	O
you	O
track	O
the	O
pose	O
of	O
a	O
hand-held	O
rubik	O
’	O
s	O
cube	O
.	O
6.3	O
geometric	B
intrinsic	O
calibration	B
as	O
described	O
above	O
in	O
equations	B
(	O
6.42–6.43	O
)	O
,	O
the	O
computation	O
of	O
the	O
internal	O
(	O
intrinsic	B
)	O
cam-	O
era	O
calibration	B
parameters	O
can	O
occur	O
simultaneously	O
with	O
the	O
estimation	B
of	O
the	O
(	O
extrinsic	B
)	O
pose	O
of	O
the	O
camera	B
with	O
respect	O
to	O
a	O
known	O
calibration	B
target	O
.	O
this	O
,	O
indeed	O
,	O
is	O
the	O
“	O
classic	O
”	O
approach	O
to	O
camera	B
calibration	O
used	O
in	O
both	O
the	O
photogrammetry	B
(	O
slama	O
1980	O
)	O
and	O
the	O
com-	O
puter	O
vision	O
(	O
tsai	O
1987	O
)	O
communities	O
.	O
in	O
this	O
section	O
,	O
we	O
look	O
at	O
alternative	O
formulations	O
(	O
which	O
may	O
not	O
involve	O
the	O
full	O
solution	O
of	O
a	O
non-linear	B
regression	O
problem	O
)	O
,	O
the	O
use	O
of	O
alter-	O
native	O
calibration	B
targets	O
,	O
and	O
the	O
estimation	B
of	O
the	O
non-linear	B
part	O
of	O
camera	B
optics	O
such	O
as	O
radial	B
distortion.12	O
6.3.1	O
calibration	B
patterns	O
the	O
use	O
of	O
a	O
calibration	B
pattern	O
or	O
set	O
of	O
markers	O
is	O
one	O
of	O
the	O
more	O
reliable	O
ways	O
to	O
estimate	O
a	O
camera	B
’	O
s	O
intrinsic	B
parameters	O
.	O
in	O
photogrammetry	B
,	O
it	O
is	O
common	O
to	O
set	O
up	O
a	O
camera	B
in	O
a	O
large	O
ﬁeld	O
looking	O
at	O
distant	O
calibration	B
targets	O
whose	O
exact	O
location	O
has	O
been	O
precomputed	O
using	O
surveying	O
equipment	O
(	O
slama	O
1980	O
;	O
atkinson	O
1996	O
;	O
kraus	O
1997	O
)	O
.	O
in	O
this	O
case	O
,	O
the	O
trans-	O
lational	O
component	O
of	O
the	O
pose	O
becomes	O
irrelevant	O
and	O
only	O
the	O
camera	B
rotation	O
and	O
intrinsic	B
parameters	O
need	O
to	O
be	O
recovered	O
.	O
if	O
a	O
smaller	O
calibration	B
rig	O
needs	O
to	O
be	O
used	O
,	O
e.g.	O
,	O
for	O
indoor	O
robotics	O
applications	O
or	O
for	O
mobile	O
robots	O
that	O
carry	O
their	O
own	O
calibration	B
target	O
,	O
it	O
is	O
best	O
if	O
the	O
calibration	B
object	O
can	O
span	O
as	O
much	O
of	O
the	O
workspace	O
as	O
possible	O
(	O
figure	O
6.8a	O
)	O
,	O
as	O
planar	O
targets	O
often	O
fail	O
to	O
accurately	O
predict	O
the	O
components	O
of	O
the	O
pose	O
that	O
lie	O
far	O
away	O
from	O
the	O
plane	O
.	O
a	O
good	O
way	O
to	O
determine	O
if	O
the	O
calibration	B
has	O
been	O
successfully	O
performed	O
is	O
to	O
estimate	O
the	O
covariance	O
in	O
the	O
param-	O
eters	O
(	O
section	O
6.1.4	O
)	O
and	O
then	O
project	O
3d	O
points	B
from	O
various	O
points	B
in	O
the	O
workspace	O
into	O
the	O
image	B
in	O
order	B
to	O
estimate	O
their	O
2d	O
positional	O
uncertainty	B
.	O
11	O
http	O
:	O
//johnnylee.net/projects/wii/	O
.	O
12	O
in	O
some	O
applications	O
,	O
you	O
can	O
use	O
the	O
exif	O
tags	O
associated	O
with	O
a	O
jpeg	O
image	B
to	O
obtain	O
a	O
rough	O
estimate	O
of	O
a	O
camera	B
’	O
s	O
focal	O
length	O
but	O
this	O
technique	O
should	O
be	O
used	O
with	O
caution	O
as	O
the	O
results	O
are	O
often	O
inaccurate	O
.	O
328	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
6.7	O
calibrating	O
a	O
lens	O
by	O
drawing	O
straight	O
lines	B
on	O
cardboard	O
(	O
debevec	O
,	O
wenger	O
,	O
tchou	O
et	O
al	O
.	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
acm	O
:	O
(	O
a	O
)	O
an	O
image	B
taken	O
by	O
the	O
video	B
camera	O
showing	O
a	O
hand	O
holding	O
a	O
metal	O
ruler	O
whose	O
right	O
edge	O
appears	O
vertical	O
in	O
the	O
image	B
;	O
(	O
b	O
)	O
the	O
set	O
of	O
lines	B
drawn	O
on	O
the	O
cardboard	O
converging	O
on	O
the	O
front	O
nodal	B
point	I
(	O
center	O
of	O
projection	O
)	O
of	O
the	O
lens	O
and	O
indicating	O
the	O
horizontal	O
ﬁeld	O
of	O
view	O
.	O
an	O
alternative	O
method	O
for	O
estimating	O
the	O
focal	O
length	O
and	O
center	O
of	O
projection	O
of	O
a	O
lens	O
is	O
to	O
place	O
the	O
camera	B
on	O
a	O
large	O
ﬂat	O
piece	O
of	O
cardboard	O
and	O
use	O
a	O
long	O
metal	O
ruler	O
to	O
draw	O
lines	B
on	O
the	O
cardboard	O
that	O
appear	O
vertical	O
in	O
the	O
image	B
,	O
as	O
shown	O
in	O
figure	O
6.7a	O
(	O
debevec	O
,	O
wenger	O
,	O
tchou	O
et	O
al	O
.	O
2002	O
)	O
.	O
such	O
lines	B
lie	O
on	O
planes	B
that	O
are	O
parallel	O
to	O
the	O
vertical	O
axis	O
of	O
the	O
camera	B
sensor	O
and	O
also	O
pass	O
through	O
the	O
lens	O
’	O
front	O
nodal	B
point	I
.	O
the	O
location	O
of	O
the	O
nodal	B
point	I
(	O
projected	O
vertically	O
onto	O
the	O
cardboard	O
plane	O
)	O
and	O
the	O
horizontal	O
ﬁeld	O
of	O
view	O
(	O
deter-	O
mined	O
from	O
lines	B
that	O
graze	O
the	O
left	O
and	O
right	O
edges	O
of	O
the	O
visible	O
image	B
)	O
can	O
be	O
recovered	O
by	O
intersecting	O
these	O
lines	B
and	O
measuring	O
their	O
angular	O
extent	O
(	O
figure	O
6.7b	O
)	O
.	O
if	O
no	O
calibration	B
pattern	O
is	O
available	O
,	O
it	O
is	O
also	O
possible	O
to	O
perform	O
calibration	B
simulta-	O
neously	O
with	O
structure	O
and	O
pose	O
recovery	B
(	O
sections	O
6.3.4	O
and	O
7.4	O
)	O
,	O
which	O
is	O
known	O
as	O
self-	O
calibration	B
(	O
faugeras	O
,	O
luong	O
,	O
and	O
maybank	O
1992	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
2010	O
)	O
.	O
however	O
,	O
such	O
an	O
approach	O
requires	O
a	O
large	O
amount	O
of	O
imagery	O
to	O
be	O
accurate	O
.	O
planar	O
calibration	O
patterns	B
when	O
a	O
ﬁnite	O
workspace	O
is	O
being	O
used	O
and	O
accurate	O
machining	O
and	O
motion	B
control	O
platforms	O
are	O
available	O
,	O
a	O
good	O
way	O
to	O
perform	O
calibration	B
is	O
to	O
move	O
a	O
planar	O
calibration	O
target	O
in	O
a	O
controlled	O
fashion	O
through	O
the	O
workspace	O
volume	O
.	O
this	O
approach	O
is	O
sometimes	O
called	O
the	O
n-	O
planes	B
calibration	O
approach	O
(	O
gremban	O
,	O
thorpe	O
,	O
and	O
kanade	O
1988	O
;	O
champleboux	O
,	O
lavall´ee	O
,	O
szeliski	O
et	O
al	O
.	O
1992	O
;	O
grossberg	O
and	O
nayar	O
2001	O
)	O
and	O
has	O
the	O
advantage	O
that	O
each	O
camera	B
pixel	O
can	O
be	O
mapped	O
to	O
a	O
unique	O
3d	O
ray	O
in	O
space	O
,	O
which	O
takes	O
care	O
of	O
both	O
linear	B
effects	O
modeled	O
6.3	O
geometric	B
intrinsic	O
calibration	B
329	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
6.8	O
calibration	B
patterns	O
:	O
(	O
a	O
)	O
a	O
three-dimensional	O
target	O
(	O
quan	O
and	O
lan	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
ieee	O
;	O
(	O
b	O
)	O
a	O
two-dimensional	B
target	O
(	O
zhang	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
ieee	O
.	O
note	O
that	O
radial	B
distortion	I
needs	O
to	O
be	O
removed	O
from	O
such	O
images	O
before	O
the	O
feature	B
points	O
can	O
be	O
used	O
for	O
calibration	O
.	O
by	O
the	O
calibration	B
matrix	I
k	O
and	O
non-linear	B
effects	O
such	O
as	O
radial	B
distortion	I
(	O
section	O
6.3.5	O
)	O
.	O
a	O
less	O
cumbersome	O
but	O
also	O
less	O
accurate	O
calibration	B
can	O
be	O
obtained	O
by	O
waving	O
a	O
pla-	O
nar	O
calibration	B
pattern	O
in	O
front	O
of	O
a	O
camera	B
(	O
figure	O
6.8b	O
)	O
.	O
in	O
this	O
case	O
,	O
the	O
pattern	O
’	O
s	O
pose	O
has	O
(	O
in	O
principle	O
)	O
to	O
be	O
recovered	O
in	O
conjunction	O
with	O
the	O
intrinsics	O
.	O
in	O
this	O
technique	O
,	O
each	O
input	O
image	B
is	O
used	O
to	O
compute	O
a	O
separate	O
homography	B
(	O
6.19–6.23	O
)	O
˜h	O
mapping	O
the	O
plane	O
’	O
s	O
calibration	B
points	O
(	O
xi	O
,	O
yi	O
,	O
0	O
)	O
into	O
image	B
coordinates	O
(	O
xi	O
,	O
yi	O
)	O
,	O
(	O
6.49	O
)	O
xi	O
=	O
xi	O
yi	O
1	O
	O
∼	O
k	O
(	O
cid:104	O
)	O
r0	O
r1	O
t	O
(	O
cid:105	O
)	O
	O
xi	O
yi	O
1	O
	O
∼	O
˜hpi	O
,	O
where	O
the	O
ri	O
are	O
the	O
ﬁrst	O
two	O
columns	O
of	O
r	O
and	O
∼	O
indicates	O
equality	O
up	O
to	O
scale	O
.	O
from	O
these	O
,	O
zhang	O
(	O
2000	O
)	O
shows	O
how	O
to	O
form	O
linear	B
constraints	O
on	O
the	O
nine	O
entries	O
in	O
the	O
b	O
=	O
k−t	O
k−1	O
matrix	O
,	O
from	O
which	O
the	O
calibration	B
matrix	I
k	O
can	O
be	O
recovered	O
using	O
a	O
matrix	O
square	O
root	O
and	O
inversion	O
.	O
(	O
the	O
matrix	O
b	O
is	O
known	O
as	O
the	O
image	B
of	O
the	O
absolute	O
conic	O
(	O
iac	O
)	O
in	O
projective	B
geometry	O
and	O
is	O
commonly	O
used	O
for	O
camera	O
calibration	B
(	O
hartley	O
and	O
zisserman	O
2004	O
,	O
section	O
7.5	O
)	O
.	O
)	O
if	O
only	O
the	O
focal	O
length	O
is	O
being	O
recovered	O
,	O
the	O
even	O
simpler	O
approach	O
of	O
using	O
vanishing	O
points	B
can	O
be	O
used	O
instead	O
.	O
6.3.2	O
vanishing	B
points	I
a	O
common	O
case	O
for	O
calibration	O
that	O
occurs	O
often	O
in	O
practice	O
is	O
when	O
the	O
camera	B
is	O
looking	O
at	O
a	O
man-made	O
scene	O
with	O
strong	O
extended	O
rectahedral	O
objects	O
such	O
as	O
boxes	O
or	O
room	O
walls	O
.	O
in	O
this	O
case	O
,	O
we	O
can	O
intersect	O
the	O
2d	O
lines	B
corresponding	O
to	O
3d	O
parallel	O
lines	B
to	O
compute	O
their	O
vanishing	B
points	I
,	O
as	O
described	O
in	O
section	O
4.3.3	O
,	O
and	O
use	O
these	O
to	O
determine	O
the	O
intrinsic	B
and	O
extrinsic	B
calibration	O
parameters	B
(	O
caprile	O
and	O
torre	O
1990	O
;	O
becker	O
and	O
bove	O
1995	O
;	O
liebowitz	O
330	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
6.9	O
calibration	B
from	O
vanishing	B
points	I
:	O
(	O
a	O
)	O
any	O
pair	O
of	O
ﬁnite	O
vanishing	B
points	I
(	O
ˆxi	O
,	O
ˆxj	O
)	O
can	O
be	O
used	O
to	O
estimate	O
the	O
focal	O
length	O
;	O
(	O
b	O
)	O
the	O
orthocenter	O
of	O
the	O
vanishing	O
point	O
triangle	O
gives	O
the	O
optical	O
center	O
of	O
the	O
image	B
c.	O
and	O
zisserman	O
1998	O
;	O
cipolla	O
,	O
drummond	O
,	O
and	O
robertson	O
1999	O
;	O
antone	O
and	O
teller	O
2002	O
;	O
criminisi	O
,	O
reid	O
,	O
and	O
zisserman	O
2000	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
pﬂugfelder	O
2008	O
)	O
.	O
let	O
us	O
assume	O
that	O
we	O
have	O
detected	O
two	O
or	O
more	O
orthogonal	O
vanishing	O
points	B
,	O
all	O
of	O
which	O
are	O
ﬁnite	O
,	O
i.e.	O
,	O
they	O
are	O
not	O
obtained	O
from	O
lines	B
that	O
appear	O
to	O
be	O
parallel	O
in	O
the	O
image	B
plane	O
(	O
figure	O
6.9a	O
)	O
.	O
let	O
us	O
also	O
assume	O
a	O
simpliﬁed	O
form	O
for	O
the	O
calibration	B
matrix	I
k	O
where	O
only	O
the	O
focal	O
length	O
is	O
unknown	O
(	O
2.59	O
)	O
.	O
(	O
it	O
is	O
often	O
safe	O
for	O
rough	O
3d	O
modeling	B
to	O
assume	O
that	O
the	O
optical	O
center	O
is	O
at	O
the	O
center	O
of	O
the	O
image	B
,	O
that	O
the	O
aspect	O
ratio	O
is	O
1	O
,	O
and	O
that	O
there	O
is	O
no	O
skew	O
.	O
)	O
in	O
this	O
case	O
,	O
the	O
projection	O
equation	B
for	O
the	O
vanishing	B
points	I
can	O
be	O
written	O
as	O
	O
∼	O
rpi	O
=	O
ri	O
,	O
(	O
6.50	O
)	O
ˆxi	O
=	O
xi	O
−	O
cx	O
yi	O
−	O
cy	O
f	O
where	O
pi	O
corresponds	O
to	O
one	O
of	O
the	O
cardinal	O
directions	O
(	O
1	O
,	O
0	O
,	O
0	O
)	O
,	O
(	O
0	O
,	O
1	O
,	O
0	O
)	O
,	O
or	O
(	O
0	O
,	O
0	O
,	O
1	O
)	O
,	O
and	O
ri	O
is	O
the	O
ith	O
column	O
of	O
the	O
rotation	O
matrix	O
r.	O
from	O
the	O
orthogonality	O
between	O
columns	O
of	O
the	O
rotation	O
matrix	O
,	O
we	O
have	O
ri	O
·	O
rj	O
∼	O
(	O
xi	O
−	O
cx	O
)	O
(	O
xj	O
−	O
cy	O
)	O
+	O
(	O
yi	O
−	O
cy	O
)	O
(	O
yj	O
−	O
cy	O
)	O
+	O
f	O
2	O
=	O
0	O
(	O
6.51	O
)	O
from	O
which	O
we	O
can	O
obtain	O
an	O
estimate	O
for	O
f	O
2.	O
note	O
that	O
the	O
accuracy	B
of	O
this	O
estimate	O
increases	O
as	O
the	O
vanishing	B
points	I
move	O
closer	O
to	O
the	O
center	O
of	O
the	O
image	B
.	O
in	O
other	O
words	O
,	O
it	O
is	O
best	O
to	O
tilt	O
the	O
calibration	B
pattern	O
a	O
decent	O
amount	O
around	O
the	O
45◦	O
axis	O
,	O
as	O
in	O
figure	O
6.9a	O
.	O
once	O
the	O
focal	O
length	O
f	O
has	O
been	O
determined	O
,	O
the	O
individual	O
columns	O
of	O
r	O
can	O
be	O
estimated	O
by	O
normalizing	O
the	O
left	O
hand	O
side	O
of	O
(	O
6.50	O
)	O
and	O
taking	O
cross	O
products	O
.	O
alternatively	O
,	O
an	O
svd	O
of	O
the	O
initial	O
r	O
estimate	O
,	O
which	O
is	O
a	O
variant	O
on	O
orthogonal	O
procrustes	O
(	O
6.32	O
)	O
,	O
can	O
be	O
used	O
.	O
if	O
all	O
three	O
vanishing	B
points	I
are	O
visible	O
and	O
ﬁnite	O
in	O
the	O
same	O
image	B
,	O
it	O
is	O
also	O
possible	O
to	O
estimate	O
the	O
optical	O
center	O
as	O
the	O
orthocenter	O
of	O
the	O
triangle	O
formed	O
by	O
the	O
three	O
vanishing	B
points	I
(	O
caprile	O
and	O
torre	O
1990	O
;	O
hartley	O
and	O
zisserman	O
2004	O
,	O
section	O
7.6	O
)	O
(	O
figure	O
6.9b	O
)	O
.	O
x1x0x2x1x0x2c	O
6.3	O
geometric	B
intrinsic	O
calibration	B
331	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
6.10	O
single	O
view	O
metrology	O
(	O
criminisi	O
,	O
reid	O
,	O
and	O
zisserman	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
springer	O
:	O
(	O
a	O
)	O
input	O
image	B
showing	O
the	O
three	O
coordinate	O
axes	O
computed	O
from	O
the	O
two	O
hori-	O
zontal	O
vanishing	B
points	I
(	O
which	O
can	O
be	O
determined	O
from	O
the	O
sidings	O
on	O
the	O
shed	O
)	O
;	O
(	O
b	O
)	O
a	O
new	O
view	O
of	O
the	O
3d	O
reconstruction	O
.	O
in	O
practice	O
,	O
however	O
,	O
it	O
is	O
more	O
accurate	O
to	O
re-estimate	O
any	O
unknown	O
intrinsic	B
calibration	O
parameters	B
using	O
non-linear	B
least	O
squares	O
(	O
6.42	O
)	O
.	O
6.3.3	O
application	O
:	O
single	O
view	O
metrology	O
a	O
fun	O
application	O
of	O
vanishing	O
point	O
estimation	B
and	O
camera	B
calibration	O
is	O
the	O
single	O
view	O
metrology	O
system	O
developed	O
by	O
criminisi	O
,	O
reid	O
,	O
and	O
zisserman	O
(	O
2000	O
)	O
.	O
their	O
system	O
allows	O
people	O
to	O
interactively	O
measure	O
heights	O
and	O
other	O
dimensions	O
as	O
well	O
as	O
to	O
build	O
piecewise-	O
planar	O
3d	O
models	O
,	O
as	O
shown	O
in	O
figure	O
6.10.	O
the	O
ﬁrst	O
step	O
in	O
their	O
system	O
is	O
to	O
identify	O
two	O
orthogonal	O
vanishing	B
points	I
on	O
the	O
ground	O
plane	O
and	O
the	O
vanishing	O
point	O
for	O
the	O
vertical	O
direction	O
,	O
which	O
can	O
be	O
done	O
by	O
drawing	O
some	O
parallel	O
sets	O
of	O
lines	B
in	O
the	O
image	B
.	O
(	O
alternatively	O
,	O
automated	B
techniques	O
such	O
as	O
those	O
dis-	O
cussed	O
in	O
section	O
4.3.3	O
or	O
by	O
schaffalitzky	O
and	O
zisserman	O
(	O
2000	O
)	O
could	O
be	O
used	O
.	O
)	O
the	O
user	O
then	O
marks	O
a	O
few	O
dimensions	O
in	O
the	O
image	B
,	O
such	O
as	O
the	O
height	O
of	O
a	O
reference	O
object	O
,	O
and	O
the	O
system	O
can	O
automatically	O
compute	O
the	O
height	O
of	O
another	O
object	O
.	O
walls	O
and	O
other	O
planar	O
impostors	O
(	O
geometry	O
)	O
can	O
also	O
be	O
sketched	O
and	O
reconstructed	O
.	O
in	O
the	O
formulation	O
originally	O
developed	O
by	O
criminisi	O
,	O
reid	O
,	O
and	O
zisserman	O
(	O
2000	O
)	O
,	O
the	O
system	O
produces	O
an	O
afﬁne	B
reconstruction	O
,	O
i.e.	O
,	O
one	O
that	O
is	O
only	O
known	O
up	O
to	O
a	O
set	O
of	O
indepen-	O
dent	O
scaling	O
factors	O
along	O
each	O
axis	O
.	O
a	O
potentially	O
more	O
useful	O
system	O
can	O
be	O
constructed	O
by	O
assuming	O
that	O
the	O
camera	B
is	O
calibrated	O
up	O
to	O
an	O
unknown	O
focal	O
length	O
,	O
which	O
can	O
be	O
recov-	O
ered	O
from	O
orthogonal	O
(	O
ﬁnite	O
)	O
vanishing	O
directions	O
,	O
as	O
we	O
just	O
described	O
in	O
section	O
6.3.2.	O
once	O
this	O
is	O
done	O
,	O
the	O
user	O
can	O
indicate	O
an	O
origin	O
on	O
the	O
ground	O
plane	O
and	O
another	O
point	O
a	O
known	O
distance	O
away	O
.	O
from	O
this	O
,	O
points	B
on	O
the	O
ground	O
plane	O
can	O
be	O
directly	O
projected	O
into	O
3d	O
and	O
332	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
6.11	O
four	O
images	O
taken	O
with	O
a	O
hand-held	O
camera	B
registered	O
using	O
a	O
3d	O
rotation	O
motion	O
model	O
,	O
which	O
can	O
be	O
used	O
to	O
estimate	O
the	O
focal	O
length	O
of	O
the	O
camera	B
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
acm	O
.	O
points	B
above	O
the	O
ground	O
plane	O
,	O
when	O
paired	O
with	O
their	O
ground	O
plane	O
projections	O
,	O
can	O
also	O
be	O
recovered	O
.	O
a	O
fully	O
metric	O
reconstruction	O
of	O
the	O
scene	O
then	O
becomes	O
possible	O
.	O
exercise	O
6.9	O
has	O
you	O
implement	O
such	O
a	O
system	O
and	O
then	O
use	O
it	O
to	O
model	O
some	O
simple	O
3d	O
scenes	O
.	O
section	O
12.6.1	O
describes	O
other	O
,	O
potentially	O
multi-view	B
,	O
approaches	O
to	O
architectural	O
reconstruction	O
,	O
including	O
an	O
interactive	B
piecewise-planar	O
modeling	B
system	O
that	O
uses	O
vanishing	B
points	I
to	O
establish	O
3d	O
line	O
directions	O
and	O
plane	O
normals	O
(	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
2008	O
)	O
.	O
6.3.4	O
rotational	B
motion	I
when	O
no	O
calibration	B
targets	O
or	O
known	O
structures	O
are	O
available	O
but	O
you	O
can	O
rotate	O
the	O
camera	B
around	O
its	O
front	O
nodal	B
point	I
(	O
or	O
,	O
equivalently	O
,	O
work	O
in	O
a	O
large	O
open	O
environment	O
where	O
all	O
ob-	O
jects	O
are	O
distant	O
)	O
,	O
the	O
camera	B
can	O
be	O
calibrated	O
from	O
a	O
set	O
of	O
overlapping	O
images	O
by	O
assuming	O
that	O
it	O
is	O
undergoing	O
pure	O
rotational	O
motion	B
,	O
as	O
shown	O
in	O
figure	O
6.11	O
(	O
stein	O
1995	O
;	O
hartley	O
1997b	O
;	O
hartley	O
,	O
hayman	O
,	O
de	O
agapito	O
et	O
al	O
.	O
2000	O
;	O
de	O
agapito	O
,	O
hayman	O
,	O
and	O
reid	O
2001	O
;	O
kang	O
and	O
weiss	O
1999	O
;	O
shum	O
and	O
szeliski	O
2000	O
;	O
frahm	O
and	O
koch	O
2003	O
)	O
.	O
when	O
a	O
full	O
360◦	O
mo-	O
tion	B
is	O
used	O
to	O
perform	O
this	O
calibration	B
,	O
a	O
very	O
accurate	O
estimate	O
of	O
the	O
focal	O
length	O
f	O
can	O
be	O
obtained	O
,	O
as	O
the	O
accuracy	B
in	O
this	O
estimate	O
is	O
proportional	O
to	O
the	O
total	B
number	O
of	O
pixels	O
in	O
the	O
resulting	O
cylindrical	B
panorama	O
(	O
section	O
9.1.6	O
)	O
(	O
stein	O
1995	O
;	O
shum	O
and	O
szeliski	O
2000	O
)	O
.	O
to	O
use	O
this	O
technique	O
,	O
we	O
ﬁrst	O
compute	O
the	O
homographies	O
˜h	O
ij	O
between	O
all	O
overlapping	O
pairs	B
of	O
images	O
,	O
as	O
explained	O
in	O
equations	B
(	O
6.19–6.23	O
)	O
.	O
then	O
,	O
we	O
use	O
the	O
observation	O
,	O
ﬁrst	O
made	O
in	O
equation	B
(	O
2.72	O
)	O
and	O
explored	O
in	O
more	O
detail	O
in	O
section	O
9.1.3	O
(	O
9.5	O
)	O
,	O
that	O
each	O
homog-	O
raphy	O
is	O
related	O
to	O
the	O
inter-camera	O
rotation	O
rij	O
through	O
the	O
(	O
unknown	O
)	O
calibration	B
matrices	O
6.3	O
geometric	B
intrinsic	O
calibration	B
ki	O
and	O
kj	O
,	O
˜h	O
ij	O
=	O
kirir−1	O
j	O
k−1	O
j	O
=	O
kirijk−1	O
j	O
333	O
(	O
6.52	O
)	O
.	O
the	O
simplest	O
way	O
to	O
obtain	O
the	O
calibration	B
is	O
to	O
use	O
the	O
simpliﬁed	O
form	O
of	O
the	O
calibra-	O
tion	B
matrix	O
(	O
2.59	O
)	O
,	O
where	O
we	O
assume	O
that	O
the	O
pixels	O
are	O
square	O
and	O
the	O
optical	O
center	O
lies	O
at	O
the	O
center	O
of	O
the	O
image	B
,	O
i.e.	O
,	O
kk	O
=	O
diag	O
(	O
fk	O
,	O
fk	O
,	O
1	O
)	O
.	O
(	O
we	O
number	O
the	O
pixel	O
coordinates	O
ac-	O
cordingly	O
,	O
i.e.	O
,	O
place	O
pixel	O
(	O
x	O
,	O
y	O
)	O
=	O
(	O
0	O
,	O
0	O
)	O
at	O
the	O
center	O
of	O
the	O
image	B
.	O
)	O
we	O
can	O
then	O
rewrite	O
equation	B
(	O
6.52	O
)	O
as	O
r10	O
∼	O
k−1	O
1	O
˜h	O
10k0	O
∼	O
h00	O
h10	O
f1h20	O
h01	O
h11	O
f1h21	O
f−1	O
0	O
h02	O
f−1	O
0	O
h12	O
f−1	O
0	O
f1h22	O
	O
,	O
(	O
6.53	O
)	O
where	O
hij	O
are	O
the	O
elements	O
of	O
˜h	O
10.	O
using	O
the	O
orthonormality	O
properties	B
of	O
the	O
rotation	O
matrix	O
r10	O
and	O
the	O
fact	O
that	O
the	O
right	O
hand	O
side	O
of	O
(	O
6.53	O
)	O
is	O
known	O
only	O
up	O
to	O
a	O
scale	O
,	O
we	O
obtain	O
00	O
+	O
h2	O
h2	O
01	O
+	O
f−2	O
0	O
h2	O
02	O
=	O
h2	O
10	O
+	O
h2	O
11	O
+	O
f−2	O
0	O
h2	O
12	O
and	O
from	O
this	O
,	O
we	O
can	O
compute	O
estimates	O
for	O
f0	O
of	O
h00h10	O
+	O
h01h11	O
+	O
f−2	O
0	O
h02h12	O
=	O
0	O
.	O
0	O
=	O
f	O
2	O
or	O
02	O
h2	O
12	O
−	O
h2	O
00	O
+	O
h2	O
01	O
−	O
h2	O
h2	O
h02h12	O
10	O
−	O
h2	O
11	O
0	O
=	O
−	O
f	O
2	O
h00h10	O
+	O
h01h11	O
if	O
h2	O
00	O
+	O
h2	O
01	O
(	O
cid:54	O
)	O
=	O
h2	O
10	O
+	O
h2	O
11	O
if	O
h00h10	O
(	O
cid:54	O
)	O
=	O
−h01h11	O
.	O
(	O
6.54	O
)	O
(	O
6.55	O
)	O
(	O
6.56	O
)	O
(	O
6.57	O
)	O
(	O
note	O
that	O
the	O
equations	B
originally	O
given	O
by	O
szeliski	O
and	O
shum	O
(	O
1997	O
)	O
are	O
erroneous	O
;	O
the	O
correct	O
equations	B
are	O
given	O
by	O
shum	O
and	O
szeliski	O
(	O
2000	O
)	O
.	O
)	O
if	O
neither	O
of	O
these	O
conditions	O
holds	O
,	O
we	O
can	O
also	O
take	O
the	O
dot	O
products	O
between	O
the	O
ﬁrst	O
(	O
or	O
second	O
)	O
row	O
and	O
the	O
third	O
one	O
.	O
similar	O
results	O
can	O
be	O
obtained	O
for	O
f1	O
as	O
well	O
,	O
by	O
analyzing	O
the	O
columns	O
of	O
˜h	O
10.	O
if	O
the	O
focal	O
length	O
is	O
the	O
same	O
for	O
both	O
images	O
,	O
we	O
can	O
take	O
the	O
geometric	B
mean	O
of	O
f0	O
and	O
f1	O
as	O
the	O
estimated	O
focal	O
length	O
f	O
=	O
√f1f0	O
.	O
when	O
multiple	B
estimates	O
of	O
f	O
are	O
available	O
,	O
e.g.	O
,	O
from	O
different	O
homographies	O
,	O
the	O
median	B
value	O
can	O
be	O
used	O
as	O
the	O
ﬁnal	O
estimate	O
.	O
a	O
more	O
general	O
(	O
upper-triangular	O
)	O
estimate	O
of	O
k	O
can	O
be	O
obtained	O
in	O
the	O
case	O
of	O
a	O
ﬁxed-	O
parameter	O
camera	B
ki	O
=	O
k	O
using	O
the	O
technique	O
of	O
hartley	O
(	O
1997b	O
)	O
.	O
observe	O
from	O
(	O
6.52	O
)	O
that	O
rij	O
∼	O
k−1	O
˜h	O
ijk	O
and	O
r−t	O
ij	O
we	O
obtain	O
k−1	O
˜h	O
ijk	O
∼	O
kt	O
˜h−t	O
ij	O
∼	O
kt	O
˜h−t	O
ij	O
k−t	O
,	O
from	O
which	O
we	O
get	O
ij	O
k−t	O
.	O
equating	O
rij	O
=	O
r−t	O
˜h	O
ij	O
(	O
kkt	O
)	O
∼	O
(	O
kkt	O
)	O
˜h−t	O
ij	O
.	O
(	O
6.58	O
)	O
334	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
this	O
provides	O
us	O
with	O
some	O
homogeneous	O
linear	O
constraints	O
on	O
the	O
entries	O
in	O
a	O
=	O
kkt	O
,	O
which	O
is	O
known	O
as	O
the	O
dual	O
of	O
the	O
image	B
of	O
the	O
absolute	O
conic	O
(	O
hartley	O
1997b	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
(	O
recall	B
that	O
when	O
we	O
estimate	O
a	O
homography	B
,	O
we	O
can	O
only	O
recover	O
it	O
up	O
to	O
an	O
unknown	O
scale	O
.	O
)	O
given	O
a	O
sufﬁcient	O
number	O
of	O
independent	O
homography	B
estimates	O
˜h	O
ij	O
,	O
we	O
can	O
recover	O
a	O
(	O
up	O
to	O
a	O
scale	O
)	O
using	O
either	O
svd	O
or	O
eigenvalue	O
analysis	O
and	O
then	O
recover	O
k	O
through	O
cholesky	O
decomposition	O
(	O
appendix	O
a.1.4	O
)	O
.	O
extensions	O
to	O
the	O
cases	O
of	O
temporally	O
varying	O
calibration	B
parameters	O
and	O
non-stationary	O
cameras	O
are	O
discussed	O
by	O
hartley	O
,	O
hayman	O
,	O
de	O
agapito	O
et	O
al	O
.	O
(	O
2000	O
)	O
and	O
de	O
agapito	O
,	O
hayman	O
,	O
and	O
reid	O
(	O
2001	O
)	O
.	O
the	O
quality	O
of	O
the	O
intrinsic	B
camera	O
parameters	B
can	O
be	O
greatly	O
increased	O
by	O
constructing	O
a	O
full	O
360◦	O
panorama	O
,	O
since	O
mis-estimating	O
the	O
focal	O
length	O
will	O
result	O
in	O
a	O
gap	O
(	O
or	O
excessive	O
overlap	O
)	O
when	O
the	O
ﬁrst	O
image	B
in	O
the	O
sequence	O
is	O
stitched	O
to	O
itself	O
(	O
figure	O
9.5	O
)	O
.	O
the	O
resulting	O
mis-alignment	O
can	O
be	O
used	O
to	O
improve	O
the	O
estimate	O
of	O
the	O
focal	O
length	O
and	O
to	O
re-adjust	O
the	O
rotation	O
estimates	O
,	O
as	O
described	O
in	O
section	O
9.1.4.	O
rotating	O
the	O
camera	B
by	O
90◦	O
around	O
its	O
optic	O
axis	O
and	O
re-shooting	O
the	O
panorama	O
is	O
a	O
good	O
way	O
to	O
check	O
for	O
aspect	O
ratio	O
and	O
skew	O
pixel	O
problems	O
,	O
as	O
is	O
generating	O
a	O
full	O
hemi-spherical	O
panorama	O
when	O
there	O
is	O
sufﬁcient	O
texture	B
.	O
ultimately	O
,	O
however	O
,	O
the	O
most	O
accurate	O
estimate	O
of	O
the	O
calibration	B
parameters	O
(	O
including	O
radial	B
distortion	I
)	O
can	O
be	O
obtained	O
using	O
a	O
full	O
simultaneous	O
non-linear	B
minimization	O
of	O
the	O
intrinsic	B
and	O
extrinsic	B
(	O
rotation	O
)	O
parameters	B
,	O
as	O
described	O
in	O
section	O
9.2	O
.	O
6.3.5	O
radial	B
distortion	I
when	O
images	O
are	O
taken	O
with	O
wide-angle	O
lenses	O
,	O
it	O
is	O
often	O
necessary	O
to	O
model	O
lens	O
distor-	O
tions	O
such	O
as	O
radial	B
distortion	I
.	O
as	O
discussed	O
in	O
section	O
2.1.6	O
,	O
the	O
radial	B
distortion	I
model	O
says	O
that	O
coordinates	O
in	O
the	O
observed	O
images	O
are	O
displaced	O
away	O
from	O
(	O
barrel	B
distortion	O
)	O
or	O
towards	O
(	O
pincushion	B
distortion	O
)	O
the	O
image	B
center	O
by	O
an	O
amount	O
proportional	O
to	O
their	O
radial	B
distance	O
(	O
figure	O
2.13a–b	O
)	O
.	O
the	O
simplest	O
radial	B
distortion	I
models	O
use	O
low-order	O
polynomials	O
(	O
c.f	O
.	O
equation	B
(	O
2.78	O
)	O
)	O
,	O
ˆx	O
=	O
x	O
(	O
1	O
+	O
κ1r2	O
+	O
κ2r4	O
)	O
ˆy	O
=	O
y	O
(	O
1	O
+	O
κ1r2	O
+	O
κ2r4	O
)	O
,	O
(	O
6.59	O
)	O
where	O
r2	O
=	O
x2	O
+	O
y2	O
and	O
κ1	O
and	O
κ2	O
are	O
called	O
the	O
radial	B
distortion	I
parameters	O
(	O
brown	O
1971	O
;	O
slama	O
1980	O
)	O
.13	O
a	O
variety	O
of	O
techniques	O
can	O
be	O
used	O
to	O
estimate	O
the	O
radial	B
distortion	I
parameters	O
for	O
a	O
given	O
lens.14	O
one	O
of	O
the	O
simplest	O
and	O
most	O
useful	O
is	O
to	O
take	O
an	O
image	B
of	O
a	O
scene	O
with	O
a	O
lot	O
13	O
sometimes	O
the	O
relationship	O
between	O
x	O
and	O
ˆx	O
is	O
expressed	O
the	O
other	O
way	O
around	O
,	O
i.e.	O
,	O
using	O
primed	O
(	O
ﬁnal	O
)	O
coordinates	O
on	O
the	O
right-hand	O
side	O
,	O
x	O
=	O
ˆx	O
(	O
1	O
+	O
κ1	O
ˆr2	O
+	O
κ2	O
ˆr4	O
)	O
.	O
this	O
is	O
convenient	O
if	O
we	O
map	O
image	B
pixels	O
into	O
(	O
warped	O
)	O
rays	O
and	O
then	O
undistort	O
the	O
rays	O
to	O
obtain	O
3d	O
rays	O
in	O
space	O
,	O
i.e.	O
,	O
if	O
we	O
are	O
using	O
inverse	O
warping	O
.	O
14	O
some	O
of	O
today	O
’	O
s	O
digital	O
cameras	O
are	O
starting	O
to	O
remove	O
radial	B
distortion	I
using	O
software	O
in	O
the	O
camera	B
itself	O
.	O
6.4	O
additional	O
reading	O
335	O
of	O
straight	O
lines	B
,	O
especially	O
lines	B
aligned	O
with	O
and	O
near	O
the	O
edges	O
of	O
the	O
image	B
.	O
the	O
radial	B
distortion	I
parameters	O
can	O
then	O
be	O
adjusted	O
until	O
all	O
of	O
the	O
lines	B
in	O
the	O
image	B
are	O
straight	O
,	O
which	O
is	O
commonly	O
called	O
the	O
plumb-line	B
method	I
(	O
brown	O
1971	O
;	O
kang	O
2001	O
;	O
el-melegy	O
and	O
farag	O
2003	O
)	O
.	O
exercise	O
6.10	O
gives	O
some	O
more	O
details	O
on	O
how	O
to	O
implement	O
such	O
a	O
technique	O
.	O
another	O
approach	O
is	O
to	O
use	O
several	O
overlapping	O
images	O
and	O
to	O
combine	O
the	O
estimation	B
of	O
the	O
radial	B
distortion	I
parameters	O
with	O
the	O
image	B
alignment	O
process	O
,	O
i.e.	O
,	O
by	O
extending	O
the	O
pipeline	B
used	O
for	O
stitching	O
in	O
section	O
9.2.1.	O
sawhney	O
and	O
kumar	O
(	O
1999	O
)	O
use	O
a	O
hierarchy	B
of	O
motion	B
models	I
(	O
translation	B
,	O
afﬁne	B
,	O
projective	B
)	O
in	O
a	O
coarse-to-ﬁne	B
strategy	O
coupled	O
with	O
a	O
quadratic	O
radial	B
distortion	I
correction	O
term	O
.	O
they	O
use	O
direct	B
(	O
intensity-based	B
)	O
minimiza-	O
tion	B
to	O
compute	O
the	O
alignment	B
.	O
stein	O
(	O
1997	O
)	O
uses	O
a	O
feature-based	B
approach	O
combined	O
with	O
a	O
general	O
3d	O
motion	B
model	O
(	O
and	O
quadratic	O
radial	B
distortion	I
)	O
,	O
which	O
requires	O
more	O
matches	O
than	O
a	O
parallax-free	O
rotational	O
panorama	O
but	O
is	O
potentially	O
more	O
general	O
.	O
more	O
recent	O
ap-	O
proaches	O
sometimes	O
simultaneously	O
compute	O
both	O
the	O
unknown	O
intrinsic	B
parameters	O
and	O
the	O
radial	B
distortion	I
coefﬁcients	O
,	O
which	O
may	O
include	O
higher-order	O
terms	O
or	O
more	O
complex	O
rational	O
or	O
non-parametric	B
forms	O
(	O
claus	O
and	O
fitzgibbon	O
2005	O
;	O
sturm	O
2005	O
;	O
thirthala	O
and	O
pollefeys	O
2005	O
;	O
barreto	O
and	O
daniilidis	O
2005	O
;	O
hartley	O
and	O
kang	O
2005	O
;	O
steele	O
and	O
jaynes	O
2006	O
;	O
tardif	O
,	O
sturm	O
,	O
trudeau	O
et	O
al	O
.	O
2009	O
)	O
.	O
when	O
a	O
known	O
calibration	B
target	O
is	O
being	O
used	O
(	O
figure	O
6.8	O
)	O
,	O
the	O
radial	B
distortion	I
estima-	O
tion	B
can	O
be	O
folded	O
into	O
the	O
estimation	B
of	O
the	O
other	O
intrinsic	B
and	O
extrinsic	B
parameters	O
(	O
zhang	O
2000	O
;	O
hartley	O
and	O
kang	O
2007	O
;	O
tardif	O
,	O
sturm	O
,	O
trudeau	O
et	O
al	O
.	O
2009	O
)	O
.	O
this	O
can	O
be	O
viewed	O
as	O
adding	O
another	O
stage	O
to	O
the	O
general	O
non-linear	B
minimization	O
pipeline	B
shown	O
in	O
figure	O
6.5	O
between	O
the	O
intrinsic	B
parameter	O
multiplication	B
box	O
f	O
c	O
and	O
the	O
perspective	B
division	O
box	O
f	O
p.	O
(	O
see	O
exercise	O
6.11	O
on	O
more	O
details	O
for	O
the	O
case	O
of	O
a	O
planar	O
calibration	O
target	O
.	O
)	O
of	O
course	O
,	O
as	O
discussed	O
in	O
section	O
2.1.6	O
,	O
more	O
general	O
models	O
of	O
lens	O
distortion	O
,	O
such	O
as	O
ﬁsheye	O
and	O
non-central	O
projection	O
,	O
may	O
sometimes	O
be	O
required	O
.	O
while	O
the	O
parameterization	O
of	O
such	O
lenses	O
may	O
be	O
more	O
complicated	O
(	O
section	O
2.1.6	O
)	O
,	O
the	O
general	O
approach	O
of	O
either	O
us-	O
ing	O
calibration	B
rigs	O
with	O
known	O
3d	O
positions	O
or	O
self-calibration	B
through	O
the	O
use	O
of	O
multiple	B
overlapping	O
images	O
of	O
a	O
scene	O
can	O
both	O
be	O
used	O
(	O
hartley	O
and	O
kang	O
2007	O
;	O
tardif	O
,	O
sturm	O
,	O
and	O
roy	O
2007	O
)	O
.	O
the	O
same	O
techniques	O
used	O
to	O
calibrate	O
for	O
radial	O
distortion	O
can	O
also	O
be	O
used	O
to	O
reduce	O
the	O
amount	O
of	O
chromatic	B
aberration	I
by	O
separately	O
calibrating	O
each	O
color	B
channel	O
and	O
then	O
warping	O
the	O
channels	O
to	O
put	O
them	O
back	O
into	O
alignment	B
(	O
exercise	O
6.12	O
)	O
.	O
6.4	O
additional	O
reading	O
hartley	O
and	O
zisserman	O
(	O
2004	O
)	O
provide	O
a	O
wonderful	O
introduction	O
to	O
the	O
topics	O
of	O
feature-based	B
alignment	O
and	O
optimal	O
motion	B
estimation	I
,	O
as	O
well	O
as	O
an	O
in-depth	O
discussion	O
of	O
camera	B
cali-	O
bration	O
and	O
pose	O
estimation	B
techniques	O
.	O
336	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
techniques	O
for	O
robust	O
estimation	B
are	O
discussed	O
in	O
more	O
detail	O
in	O
appendix	O
b.3	O
and	O
in	O
monographs	O
and	O
review	O
articles	O
on	O
this	O
topic	O
(	O
huber	O
1981	O
;	O
hampel	O
,	O
ronchetti	O
,	O
rousseeuw	O
et	O
al	O
.	O
1986	O
;	O
rousseeuw	O
and	O
leroy	O
1987	O
;	O
black	O
and	O
rangarajan	O
1996	O
;	O
stewart	O
1999	O
)	O
.	O
the	O
most	O
commonly	O
used	O
robust	B
initialization	O
technique	O
in	O
computer	O
vision	O
is	O
random	O
sample	O
con-	O
sensus	O
(	O
ransac	O
)	O
(	O
fischler	O
and	O
bolles	O
1981	O
)	O
,	O
which	O
has	O
spawned	O
a	O
series	O
of	O
more	O
efﬁcient	O
variants	O
(	O
nist´er	O
2003	O
;	O
chum	O
and	O
matas	O
2005	O
)	O
.	O
the	O
topic	O
of	O
registering	O
3d	O
point	O
data	O
sets	O
is	O
called	O
absolute	B
orientation	I
(	O
horn	O
1987	O
)	O
and	O
3d	O
pose	O
estimation	B
(	O
lorusso	O
,	O
eggert	O
,	O
and	O
fisher	O
1995	O
)	O
.	O
a	O
variety	O
of	O
techniques	O
has	O
been	O
developed	O
for	O
simultaneously	O
computing	O
3d	O
point	O
correspondences	O
and	O
their	O
corresponding	O
rigid	O
transformations	O
(	O
besl	O
and	O
mckay	O
1992	O
;	O
zhang	O
1994	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
gold	O
,	O
rangarajan	O
,	O
lu	O
et	O
al	O
.	O
1998	O
;	O
david	O
,	O
dementhon	O
,	O
duraiswami	O
et	O
al	O
.	O
2004	O
;	O
li	O
and	O
hartley	O
2007	O
;	O
enqvist	O
,	O
josephson	O
,	O
and	O
kahl	O
2009	O
)	O
.	O
camera	B
calibration	O
was	O
ﬁrst	O
studied	O
in	O
photogrammetry	B
(	O
brown	O
1971	O
;	O
slama	O
1980	O
;	O
atkin-	O
son	O
1996	O
;	O
kraus	O
1997	O
)	O
but	O
it	O
has	O
also	O
been	O
widely	O
studied	O
in	O
computer	O
vision	O
(	O
tsai	O
1987	O
;	O
gremban	O
,	O
thorpe	O
,	O
and	O
kanade	O
1988	O
;	O
champleboux	O
,	O
lavall´ee	O
,	O
szeliski	O
et	O
al	O
.	O
1992	O
;	O
zhang	O
2000	O
;	O
grossberg	O
and	O
nayar	O
2001	O
)	O
.	O
vanishing	B
points	I
observed	O
either	O
from	O
rectahedral	O
cali-	O
bration	O
objects	O
or	O
man-made	O
architecture	B
are	O
often	O
used	O
to	O
perform	O
rudimentary	O
calibration	B
(	O
caprile	O
and	O
torre	O
1990	O
;	O
becker	O
and	O
bove	O
1995	O
;	O
liebowitz	O
and	O
zisserman	O
1998	O
;	O
cipolla	O
,	O
drummond	O
,	O
and	O
robertson	O
1999	O
;	O
antone	O
and	O
teller	O
2002	O
;	O
criminisi	O
,	O
reid	O
,	O
and	O
zisserman	O
2000	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
pﬂugfelder	O
2008	O
)	O
.	O
performing	O
camera	B
calibration	O
without	O
using	O
known	O
targets	O
is	O
known	O
as	O
self-calibration	B
and	O
is	O
discussed	O
in	O
textbooks	B
and	O
surveys	B
on	O
structure	B
from	I
motion	I
(	O
faugeras	O
,	O
luong	O
,	O
and	O
maybank	O
1992	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
2010	O
)	O
.	O
one	O
popular	O
subset	O
of	O
such	O
techniques	O
uses	O
pure	O
rotational	O
motion	B
(	O
stein	O
1995	O
;	O
hartley	O
1997b	O
;	O
hartley	O
,	O
hayman	O
,	O
de	O
agapito	O
et	O
al	O
.	O
2000	O
;	O
de	O
agapito	O
,	O
hayman	O
,	O
and	O
reid	O
2001	O
;	O
kang	O
and	O
weiss	O
1999	O
;	O
shum	O
and	O
szeliski	O
2000	O
;	O
frahm	O
and	O
koch	O
2003	O
)	O
.	O
6.5	O
exercises	O
ex	O
6.1	O
:	O
feature-based	B
image	O
alignment	B
for	O
ﬂip-book	O
animations	O
take	O
a	O
set	O
of	O
photos	O
of	O
an	O
action	O
scene	O
or	O
portrait	O
(	O
preferably	O
in	O
motor-drive—continuous	O
shooting—mode	O
)	O
and	O
align	O
them	O
to	O
make	O
a	O
composite	O
or	O
ﬂip-book	O
animation	O
.	O
1.	O
extract	O
features	O
and	O
feature	B
descriptors	O
using	O
some	O
of	O
the	O
techniques	O
described	O
in	O
sec-	O
tions	O
4.1.1–4.1.2	O
.	O
2.	O
match	O
your	O
features	O
using	O
nearest	O
neighbor	O
matching	B
with	O
a	O
nearest	B
neighbor	I
distance	O
ratio	O
test	O
(	O
4.18	O
)	O
.	O
6.5	O
exercises	O
337	O
3.	O
compute	O
an	O
optimal	O
2d	O
translation	B
and	O
rotation	O
between	O
the	O
ﬁrst	O
image	B
and	O
all	O
subse-	O
quent	O
images	O
,	O
using	O
least	O
squares	O
(	O
section	O
6.1.1	O
)	O
with	O
optional	O
ransac	O
for	O
robustness	O
(	O
section	O
6.1.4	O
)	O
.	O
4.	O
resample	O
all	O
of	O
the	O
images	O
onto	O
the	O
ﬁrst	O
image	B
’	O
s	O
coordinate	O
frame	O
(	O
section	O
3.6.1	O
)	O
using	O
either	O
bilinear	B
or	O
bicubic	B
resampling	O
and	O
optionally	O
crop	O
them	O
to	O
their	O
common	O
area	O
.	O
5.	O
convert	O
the	O
resulting	O
images	O
into	O
an	O
animated	O
gif	O
(	O
using	O
software	O
available	O
from	O
the	O
web	O
)	O
or	O
optionally	O
implement	O
cross-dissolves	O
to	O
turn	O
them	O
into	O
a	O
“	O
slo-mo	O
”	O
video	B
.	O
6	O
.	O
(	O
optional	O
)	O
combine	O
this	O
technique	O
with	O
feature-based	O
(	O
exercise	O
3.25	O
)	O
morphing	B
.	O
ex	O
6.2	O
:	O
panography	B
create	O
the	O
kind	O
of	O
panograph	O
discussed	O
in	O
section	O
6.1.2	O
and	O
com-	O
monly	O
found	O
on	O
the	O
web	O
.	O
1.	O
take	O
a	O
series	O
of	O
interesting	O
overlapping	O
photos	O
.	O
2.	O
use	O
the	O
feature	B
detector	O
,	O
descriptor	O
,	O
and	O
matcher	O
developed	O
in	O
exercises	O
4.1–4.4	O
(	O
or	O
existing	O
software	O
)	O
to	O
match	O
features	O
among	O
the	O
images	O
.	O
3.	O
turn	O
each	O
connected	O
component	O
of	O
matching	B
features	O
into	O
a	O
track	O
,	O
i.e.	O
,	O
assign	O
a	O
unique	O
index	O
i	O
to	O
each	O
track	O
,	O
discarding	O
any	O
tracks	O
that	O
are	O
inconsistent	O
(	O
contain	O
two	O
different	O
features	O
in	O
the	O
same	O
image	B
)	O
.	O
4.	O
compute	O
a	O
global	B
translation	O
for	O
each	O
image	B
using	O
equation	B
(	O
6.12	O
)	O
.	O
5.	O
since	O
your	O
matches	O
probably	O
contain	O
errors	O
,	O
turn	O
the	O
above	O
least	O
square	O
metric	O
into	O
a	O
robust	B
metric	O
(	O
6.25	O
)	O
and	O
re-solve	O
your	O
system	O
using	O
iteratively	O
reweighted	O
least	B
squares	I
.	O
6.	O
compute	O
the	O
size	O
of	O
the	O
resulting	O
composite	O
canvas	O
and	O
resample	O
each	O
image	B
into	O
its	O
ﬁnal	O
position	O
on	O
the	O
canvas	O
.	O
(	O
keeping	O
track	O
of	O
bounding	O
boxes	O
will	O
make	O
this	O
more	O
efﬁcient	O
.	O
)	O
7.	O
average	O
all	O
of	O
the	O
images	O
,	O
or	O
choose	O
some	O
kind	O
of	O
ordering	O
and	O
implement	O
translucent	O
over	O
compositing	O
(	O
3.8	O
)	O
.	O
8	O
.	O
(	O
optional	O
)	O
extend	O
your	O
parametric	B
motion	O
model	O
to	O
include	O
rotations	B
and	I
scale	I
,	O
i.e.	O
,	O
the	O
similarity	B
transform	O
given	O
in	O
table	O
6.1.	O
discuss	O
how	O
you	O
could	O
handle	O
the	O
case	O
of	O
translations	O
and	O
rotations	O
only	O
(	O
no	O
scale	O
)	O
.	O
9	O
.	O
(	O
optional	O
)	O
write	O
a	O
simple	O
tool	O
to	O
let	O
the	O
user	O
adjust	O
the	O
ordering	O
and	O
opacity	B
,	O
and	O
add	O
or	O
remove	O
images	O
.	O
338	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
10	O
.	O
(	O
optional	O
)	O
write	O
down	O
a	O
different	O
least	B
squares	I
problem	O
that	O
involves	O
pairwise	O
match-	O
ing	O
of	O
images	O
.	O
discuss	O
why	O
this	O
might	O
be	O
better	O
or	O
worse	O
than	O
the	O
global	B
matching	O
formula	O
given	O
in	O
(	O
6.12	O
)	O
.	O
ex	O
6.3	O
:	O
2d	O
rigid/euclidean	O
matching	B
several	O
alternative	O
approaches	O
are	O
given	O
in	O
section	O
6.1.3	O
for	O
estimating	O
a	O
2d	O
rigid	O
(	O
euclidean	O
)	O
alignment	B
.	O
1.	O
implement	O
the	O
various	O
alternatives	O
and	O
compare	O
their	O
accuracy	B
on	O
synthetic	O
data	O
,	O
i.e.	O
,	O
random	O
2d	O
point	O
clouds	O
with	O
noisy	O
feature	B
positions	O
.	O
2.	O
one	O
approach	O
is	O
to	O
estimate	O
the	O
translations	O
from	O
the	O
centroids	O
and	O
then	O
estimate	O
ro-	O
tation	O
in	O
polar	O
coordinates	O
.	O
do	O
you	O
need	O
to	O
weight	O
the	O
angles	O
obtained	O
from	O
a	O
polar	O
decomposition	O
in	O
some	O
way	O
to	O
get	O
the	O
statistically	O
correct	O
estimate	O
?	O
3.	O
how	O
can	O
you	O
modify	O
your	O
techniques	O
to	O
take	O
into	O
account	O
either	O
scalar	O
(	O
6.10	O
)	O
or	O
full	O
two-dimensional	B
point	O
covariance	O
weightings	O
(	O
6.11	O
)	O
?	O
do	O
all	O
of	O
the	O
previously	O
devel-	O
oped	O
“	O
shortcuts	O
”	O
still	O
work	O
or	O
does	O
full	O
weighting	B
require	O
iterative	B
optimization	O
?	O
ex	O
6.4	O
:	O
2d	O
match	O
move/augmented	O
reality	O
replace	O
a	O
picture	O
in	O
a	O
magazine	O
or	O
a	O
book	O
with	O
a	O
different	O
image	B
or	O
video	B
.	O
1.	O
with	O
a	O
webcam	O
,	O
take	O
a	O
picture	O
of	O
a	O
magazine	O
or	O
book	O
page	O
.	O
2.	O
outline	O
a	O
ﬁgure	O
or	O
picture	O
on	O
the	O
page	O
with	O
a	O
rectangle	O
,	O
i.e.	O
,	O
draw	O
over	O
the	O
four	O
sides	O
as	O
they	O
appear	O
in	O
the	O
image	B
.	O
3.	O
match	O
features	O
in	O
this	O
area	O
with	O
each	O
new	O
image	B
frame	O
.	O
4.	O
replace	O
the	O
original	O
image	B
with	O
an	O
“	O
advertising	O
”	O
insert	O
,	O
warping	O
the	O
new	O
image	B
with	O
the	O
appropriate	O
homography	B
.	O
5.	O
try	O
your	O
approach	O
on	O
a	O
clip	O
from	O
a	O
sporting	O
event	O
(	O
e.g.	O
,	O
indoor	O
or	O
outdoor	O
soccer	O
)	O
to	O
implement	O
a	O
billboard	O
replacement	O
.	O
ex	O
6.5	O
:	O
3d	O
joystick	O
track	O
a	O
rubik	O
’	O
s	O
cube	O
to	O
implement	O
a	O
3d	O
joystick/mouse	O
control	O
.	O
1.	O
get	O
out	O
an	O
old	O
rubik	O
’	O
s	O
cube	O
(	O
or	O
get	O
one	O
from	O
your	O
parents	O
)	O
.	O
2.	O
write	O
a	O
program	O
to	O
detect	O
the	O
center	O
of	O
each	O
colored	O
square	O
.	O
3.	O
group	O
these	O
centers	O
into	O
lines	B
and	O
then	O
ﬁnd	O
the	O
vanishing	B
points	I
for	O
each	O
face	B
.	O
4.	O
estimate	O
the	O
rotation	O
angle	O
and	O
focal	O
length	O
from	O
the	O
vanishing	B
points	I
.	O
6.5	O
exercises	O
339	O
5.	O
estimate	O
the	O
full	O
3d	O
pose	O
(	O
including	O
translation	B
)	O
by	O
ﬁnding	O
one	O
or	O
more	O
3×3	O
grids	O
and	O
recovering	O
the	O
plane	O
’	O
s	O
full	O
equation	B
from	O
this	O
known	O
homography	B
using	O
the	O
technique	O
developed	O
by	O
zhang	O
(	O
2000	O
)	O
.	O
6.	O
alternatively	O
,	O
since	O
you	O
already	O
know	O
the	O
rotation	O
,	O
simply	O
estimate	O
the	O
unknown	O
trans-	O
lation	O
from	O
the	O
known	O
3d	O
corner	O
points	B
on	O
the	O
cube	O
and	O
their	O
measured	O
2d	O
locations	O
using	O
either	O
linear	B
or	O
non-linear	B
least	O
squares	O
.	O
7.	O
use	O
the	O
3d	O
rotation	O
and	O
position	O
to	O
control	O
a	O
vrml	O
or	O
3d	O
game	O
viewer	O
.	O
ex	O
6.6	O
:	O
rotation-based	O
calibration	B
take	O
an	O
outdoor	O
or	O
indoor	O
sequence	O
from	O
a	O
rotating	O
camera	B
with	O
very	O
little	O
parallax	O
and	O
use	O
it	O
to	O
calibrate	O
the	O
focal	O
length	O
of	O
your	O
camera	B
using	O
the	O
techniques	O
described	O
in	O
section	O
6.3.4	O
or	O
sections	O
9.1.3–9.2.1	O
.	O
1.	O
take	O
out	O
any	O
radial	B
distortion	I
in	O
the	O
images	O
using	O
one	O
of	O
the	O
techniques	O
from	O
exer-	O
cises	O
6.10–6.11	O
or	O
using	O
parameters	O
supplied	O
for	O
a	O
given	O
camera	B
by	O
your	O
instructor	O
.	O
2.	O
detect	O
and	O
match	O
feature	O
points	B
across	O
neighboring	O
frames	O
and	O
chain	O
them	O
into	O
feature	B
tracks	I
.	O
3.	O
compute	O
homographies	O
between	O
overlapping	O
frames	O
and	O
use	O
equations	B
(	O
6.56–6.57	O
)	O
to	O
get	O
an	O
estimate	O
of	O
the	O
focal	O
length	O
.	O
4.	O
compute	O
a	O
full	O
360◦	O
panorama	O
and	O
update	O
your	O
focal	O
length	O
estimate	O
to	O
close	O
the	O
gap	O
(	O
section	O
9.1.4	O
)	O
.	O
5	O
.	O
(	O
optional	O
)	O
perform	O
a	O
complete	O
bundle	B
adjustment	I
in	O
the	O
rotation	O
matrices	O
and	O
focal	O
length	O
to	O
obtain	O
the	O
highest	O
quality	O
estimate	O
(	O
section	O
9.2.1	O
)	O
.	O
ex	O
6.7	O
:	O
target-based	O
calibration	B
use	O
a	O
three-dimensional	O
target	O
to	O
calibrate	O
your	O
camera	B
.	O
1.	O
construct	O
a	O
three-dimensional	O
calibration	B
pattern	O
with	O
known	O
3d	O
locations	O
.	O
it	O
is	O
not	O
easy	O
to	O
get	O
high	O
accuracy	O
unless	O
you	O
use	O
a	O
machine	O
shop	O
,	O
but	O
you	O
can	O
get	O
close	O
using	O
heavy	O
plywood	O
and	O
printed	O
patterns	B
.	O
2.	O
find	O
the	O
corners	O
,	O
e.g	O
,	O
using	O
a	O
line	O
ﬁnder	O
and	O
intersecting	O
the	O
lines	B
.	O
3.	O
implement	O
one	O
of	O
the	O
iterative	B
calibration	O
and	O
pose	O
estimation	B
algorithms	O
described	O
in	O
tsai	O
(	O
1987	O
)	O
;	O
bogart	O
(	O
1991	O
)	O
;	O
gleicher	O
and	O
witkin	O
(	O
1992	O
)	O
or	O
the	O
system	O
described	O
in	O
section	O
6.2.2	O
.	O
4.	O
take	O
many	O
pictures	O
at	O
different	O
distances	O
and	O
orientations	O
relative	O
to	O
the	O
calibration	B
target	O
and	O
report	O
on	O
both	O
your	O
re-projection	O
errors	O
and	O
accuracy	B
.	O
(	O
to	O
do	O
the	O
latter	O
,	O
you	O
may	O
need	O
to	O
use	O
simulated	O
data	O
.	O
)	O
340	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ex	O
6.8	O
:	O
calibration	B
accuracy	O
compare	O
the	O
three	O
calibration	B
techniques	O
(	O
plane-based	B
,	O
rotation-	O
based	O
,	O
and	O
3d-target-based	O
)	O
.	O
one	O
approach	O
is	O
to	O
have	O
a	O
different	O
student	O
implement	O
each	O
one	O
and	O
to	O
compare	O
the	O
results	O
.	O
another	O
approach	O
is	O
to	O
use	O
synthetic	O
data	O
,	O
potentially	O
re-using	O
the	O
software	O
you	O
developed	O
for	O
exercise	O
2.3.	O
the	O
advantage	O
of	O
using	O
synthetic	O
data	O
is	O
that	O
you	O
know	O
the	O
ground	O
truth	O
for	O
the	O
calibration	B
and	O
pose	O
parameters	B
,	O
you	O
can	O
easily	O
run	O
lots	O
of	O
experiments	O
,	O
and	O
you	O
can	O
synthetically	O
vary	O
the	O
noise	B
in	O
your	O
measurements	O
.	O
here	O
are	O
some	O
possible	O
guidelines	O
for	O
constructing	O
your	O
test	O
sets	O
:	O
1.	O
assume	O
a	O
medium-wide	O
focal	O
length	O
(	O
say	O
,	O
50◦	O
ﬁeld	O
of	O
view	O
)	O
.	O
2.	O
for	O
the	O
plane-based	B
technique	O
,	O
generate	O
a	O
2d	O
grid	O
target	O
and	O
project	O
it	O
at	O
different	O
inclinations	O
.	O
3.	O
for	O
a	O
3d	O
target	O
,	O
create	O
an	O
inner	O
cube	O
corner	O
and	O
position	O
it	O
so	O
that	O
it	O
ﬁlls	O
most	O
of	O
ﬁeld	O
of	O
view	O
.	O
4.	O
for	O
the	O
rotation	O
technique	O
,	O
scatter	O
points	B
uniformly	O
on	O
a	O
sphere	O
until	O
you	O
get	O
a	O
similar	O
number	O
of	O
points	B
as	O
for	O
other	O
techniques	O
.	O
before	O
comparing	O
your	O
techniques	O
,	O
predict	O
which	O
one	O
will	O
be	O
the	O
most	O
accurate	O
(	O
normalize	O
your	O
results	O
by	O
the	O
square	B
root	I
of	O
the	O
number	O
of	O
points	B
used	O
)	O
.	O
add	O
varying	O
amounts	O
of	O
noise	B
to	O
your	O
measurements	O
and	O
describe	O
the	O
noise	B
sensitivity	O
of	O
your	O
various	O
techniques	O
.	O
ex	O
6.9	O
:	O
single	O
view	O
metrology	O
implement	O
a	O
system	O
to	O
measure	O
dimensions	O
and	O
reconstruct	O
a	O
3d	O
model	O
from	O
a	O
single	O
image	O
of	O
a	O
man-made	O
scene	O
using	O
visible	O
vanishing	O
directions	O
(	O
sec-	O
tion	B
6.3.3	O
)	O
(	O
criminisi	O
,	O
reid	O
,	O
and	O
zisserman	O
2000	O
)	O
.	O
1.	O
find	O
the	O
three	O
orthogonal	O
vanishing	O
points	B
from	O
parallel	O
lines	B
and	O
use	O
them	O
to	O
establish	O
the	O
three	O
coordinate	O
axes	O
(	O
rotation	O
matrix	O
r	O
of	O
the	O
camera	B
relative	O
to	O
the	O
scene	O
)	O
.	O
if	O
two	O
of	O
the	O
vanishing	B
points	I
are	O
ﬁnite	O
(	O
not	O
at	O
inﬁnity	O
)	O
,	O
use	O
them	O
to	O
compute	O
the	O
focal	O
length	O
,	O
assuming	O
a	O
known	O
optical	O
center	O
.	O
otherwise	O
,	O
ﬁnd	O
some	O
other	O
way	O
to	O
calibrate	O
your	O
camera	B
;	O
you	O
could	O
use	O
some	O
of	O
the	O
techniques	O
described	O
by	O
schaffalitzky	O
and	O
zisserman	O
(	O
2000	O
)	O
.	O
2.	O
click	O
on	O
a	O
ground	O
plane	O
point	O
to	O
establish	O
your	O
origin	O
and	O
click	O
on	O
a	O
point	O
a	O
known	O
distance	O
away	O
to	O
establish	O
the	O
scene	O
scale	O
.	O
this	O
lets	O
you	O
compute	O
the	O
translation	B
t	O
between	O
the	O
camera	B
and	O
the	O
scene	O
.	O
as	O
an	O
alternative	O
,	O
click	O
on	O
a	O
pair	O
of	O
points	B
,	O
one	O
on	O
the	O
ground	O
plane	O
and	O
one	O
above	O
it	O
,	O
and	O
use	O
the	O
known	O
height	O
to	O
establish	O
the	O
scene	O
scale	O
.	O
6.5	O
exercises	O
341	O
3.	O
write	O
a	O
user	O
interface	O
that	O
lets	O
you	O
click	O
on	O
ground	O
plane	O
points	O
to	O
recover	O
their	O
3d	O
locations	O
.	O
(	O
hint	O
:	O
you	O
already	O
know	O
the	O
camera	B
matrix	O
,	O
so	O
knowledge	O
of	O
a	O
point	O
’	O
s	O
z	O
value	O
is	O
sufﬁcient	O
to	O
recover	O
its	O
3d	O
location	O
.	O
)	O
click	O
on	O
pairs	B
of	O
points	B
(	O
one	O
on	O
the	O
ground	O
plane	O
,	O
one	O
above	O
it	O
)	O
to	O
measure	O
vertical	O
heights	O
.	O
4.	O
extend	O
your	O
system	O
to	O
let	O
you	O
draw	O
quadrilaterals	O
in	O
the	O
scene	O
that	O
correspond	O
to	O
axis-	O
aligned	O
rectangles	O
in	O
the	O
world	O
,	O
using	O
some	O
of	O
the	O
techniques	O
described	O
by	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
export	O
your	O
3d	O
rectangles	O
to	O
a	O
vrml	O
or	O
ply15	O
ﬁle	O
.	O
5	O
.	O
(	O
optional	O
)	O
warp	O
the	O
pixels	O
enclosed	O
by	O
the	O
quadrilateral	O
using	O
the	O
correct	O
homography	B
to	O
produce	O
a	O
texture	B
map	O
for	O
each	O
planar	O
polygon	O
.	O
ex	O
6.10	O
:	O
radial	B
distortion	I
with	O
plumb	O
lines	B
mine	O
the	O
radial	B
distortion	I
parameters	O
.	O
implement	O
a	O
plumb-line	O
algorithm	O
to	O
deter-	O
1.	O
take	O
some	O
images	O
of	O
scenes	O
with	O
lots	O
of	O
straight	O
lines	B
,	O
e.g.	O
,	O
hallways	O
in	O
your	O
home	O
or	O
ofﬁce	O
,	O
and	O
try	O
to	O
get	O
some	O
of	O
the	O
lines	B
as	O
close	O
to	O
the	O
edges	O
of	O
the	O
image	B
as	O
possible	O
.	O
2.	O
extract	O
the	O
edges	O
and	O
link	O
them	O
into	O
curves	O
,	O
as	O
described	O
in	O
section	O
4.2.2	O
and	O
exer-	O
cise	O
4.8	O
.	O
3.	O
fit	O
quadratic	O
or	O
elliptic	O
curves	O
to	O
the	O
linked	O
edges	O
using	O
a	O
generalization	O
of	O
the	O
suc-	O
cessive	O
line	O
approximation	O
algorithm	B
described	O
in	O
section	O
4.3.1	O
and	O
exercise	O
4.11	O
and	O
keep	O
the	O
curves	O
that	O
ﬁt	O
this	O
form	O
well	O
.	O
4.	O
for	O
each	O
curved	O
segment	O
,	O
ﬁt	O
a	O
straight	O
line	O
and	O
minimize	O
the	O
perpendicular	O
distance	O
between	O
the	O
curve	O
and	O
the	O
line	O
while	O
adjusting	O
the	O
radial	B
distortion	I
parameters	O
.	O
5.	O
alternate	O
between	O
re-ﬁtting	O
the	O
straight	O
line	O
and	O
adjusting	O
the	O
radial	B
distortion	I
param-	O
eters	O
until	O
convergence	O
.	O
ex	O
6.11	O
:	O
radial	B
distortion	I
with	O
a	O
calibration	B
target	O
use	O
a	O
grid	O
calibration	B
target	O
to	O
de-	O
termine	O
the	O
radial	B
distortion	I
parameters	O
.	O
1.	O
print	O
out	O
a	O
planar	O
calibration	O
target	O
,	O
mount	O
it	O
on	O
a	O
stiff	O
board	O
,	O
and	O
get	O
it	O
to	O
ﬁll	O
your	O
ﬁeld	O
of	O
view	O
.	O
2.	O
detect	O
the	O
squares	O
,	O
lines	B
,	O
or	O
dots	O
in	O
your	O
calibration	B
target	O
.	O
3.	O
estimate	O
the	O
homography	B
mapping	O
the	O
target	O
to	O
the	O
camera	B
from	O
the	O
central	O
portion	O
of	O
the	O
image	B
that	O
does	O
not	O
have	O
any	O
radial	B
distortion	I
.	O
15	O
http	O
:	O
//meshlab.sf.net	O
.	O
342	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
4.	O
predict	O
the	O
positions	O
of	O
the	O
remaining	O
targets	O
and	O
use	O
the	O
differences	O
between	O
the	O
ob-	O
served	O
and	O
predicted	O
positions	O
to	O
estimate	O
the	O
radial	B
distortion	I
.	O
5	O
.	O
(	O
optional	O
)	O
fit	O
a	O
general	O
spline	B
model	O
(	O
for	O
severe	O
distortion	O
)	O
instead	O
of	O
the	O
quartic	O
dis-	O
tortion	O
model	O
.	O
6	O
.	O
(	O
optional	O
)	O
extend	O
your	O
technique	O
to	O
calibrate	O
a	O
ﬁsheye	O
lens	O
.	O
ex	O
6.12	O
:	O
chromatic	B
aberration	I
use	O
the	O
radial	B
distortion	I
estimates	O
for	O
each	O
color	B
channel	O
computed	O
in	O
the	O
previous	O
exercise	O
to	O
clean	O
up	O
wide-angle	O
lens	O
images	O
by	O
warping	O
all	O
of	O
the	O
channels	O
into	O
alignment	B
.	O
(	O
optional	O
)	O
straighten	O
out	O
the	O
images	O
at	O
the	O
same	O
time	O
.	O
can	O
you	O
think	O
of	O
any	O
reasons	O
why	O
this	O
warping	O
strategy	B
may	O
not	O
always	O
work	O
?	O
chapter	O
7	O
structure	B
from	I
motion	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.1	O
triangulation	B
.	O
.	O
7.2	O
two-frame	B
structure	O
from	O
motion	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.3	O
factorization	B
.	O
7.4	O
bundle	B
adjustment	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.2.1	O
7.2.2	O
.	O
7.2.3	O
application	O
:	O
view	B
morphing	I
.	O
.	O
.	O
.	O
projective	B
(	O
uncalibrated	O
)	O
reconstruction	O
.	O
.	O
self-calibration	B
.	O
.	O
.	O
perspective	B
and	O
projective	B
factorization	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.3.1	O
.	O
7.3.2	O
application	O
:	O
sparse	B
3d	O
model	O
extraction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.4.1	O
exploiting	O
sparsity	O
.	O
.	O
7.4.2	O
application	O
:	O
match	B
move	I
and	O
augmented	B
reality	I
.	O
7.4.3	O
uncertainty	B
and	O
ambiguities	O
.	O
.	O
7.4.4	O
application	O
:	O
reconstruction	O
from	O
internet	O
photos	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7.5.1	O
line-based	B
techniques	O
7.5.2	O
7.5	O
constrained	B
structure	O
and	O
motion	B
.	O
.	O
.	O
.	O
.	O
.	O
plane-based	B
techniques	O
.	O
.	O
.	O
7.6	O
additional	O
reading	O
.	O
.	O
7.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
345	O
.	O
347	O
.	O
353	O
.	O
355	O
.	O
357	O
.	O
357	O
.	O
360	O
.	O
362	O
.	O
363	O
.	O
364	O
.	O
368	O
.	O
370	O
.	O
371	O
.	O
374	O
.	O
374	O
.	O
376	O
.	O
377	O
.	O
377	O
344	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
(	O
h	O
)	O
(	O
i	O
)	O
(	O
j	O
)	O
(	O
k	O
)	O
(	O
l	O
)	O
(	O
m	O
)	O
(	O
n	O
)	O
figure	O
7.1	O
structure	B
from	I
motion	I
systems	O
:	O
(	O
a–d	O
)	O
orthographic	B
factorization	O
(	O
tomasi	O
and	O
kanade	O
1992	O
)	O
c	O
(	O
cid:13	O
)	O
1992	O
springer	O
;	O
(	O
e–f	O
)	O
line	O
matching	O
(	O
schmid	O
and	O
zisserman	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
ieee	O
;	O
(	O
g–k	O
)	O
incremental	B
structure	O
from	O
motion	B
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
;	O
(	O
l	O
)	O
3d	O
reconstruction	O
of	O
trafalgar	O
square	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
;	O
(	O
m	O
)	O
3d	O
reconstruction	O
of	O
the	O
great	O
wall	O
of	O
china	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
;	O
(	O
n	O
)	O
3d	O
reconstruction	O
of	O
the	O
old	O
town	O
square	O
,	O
prague	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
acm	O
.	O
7.1	O
triangulation	B
345	O
in	O
the	O
previous	O
chapter	O
,	O
we	O
saw	O
how	O
2d	O
and	O
3d	O
point	O
sets	O
could	O
be	O
aligned	O
and	O
how	O
such	O
alignments	O
could	O
be	O
used	O
to	O
estimate	O
both	O
a	O
camera	B
’	O
s	O
pose	O
and	O
its	O
internal	O
calibration	O
parame-	O
ters	O
.	O
in	O
this	O
chapter	O
,	O
we	O
look	O
at	O
the	O
converse	O
problem	O
of	O
estimating	O
the	O
locations	O
of	O
3d	O
points	B
from	O
multiple	B
images	O
given	O
only	O
a	O
sparse	B
set	O
of	O
correspondences	O
between	O
image	B
features	O
.	O
while	O
this	O
process	O
often	O
involves	O
simultaneously	O
estimating	O
both	O
3d	O
geometry	O
(	O
structure	O
)	O
and	O
camera	B
pose	O
(	O
motion	B
)	O
,	O
it	O
is	O
commonly	O
known	O
as	O
structure	B
from	I
motion	I
(	O
ullman	O
1979	O
)	O
.	O
the	O
topics	O
of	O
projective	B
geometry	O
and	O
structure	B
from	I
motion	I
are	O
extremely	O
rich	O
and	O
some	O
excellent	O
textbooks	B
and	O
surveys	B
have	O
been	O
written	O
on	O
them	O
(	O
faugeras	O
and	O
luong	O
2001	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
2010	O
)	O
.	O
this	O
chapter	O
skips	O
over	O
a	O
lot	O
of	O
the	O
richer	O
material	O
available	O
in	O
these	O
books	O
,	O
such	O
as	O
the	O
trifocal	O
tensor	O
and	O
al-	O
gebraic	O
techniques	O
for	O
full	O
self-calibration	B
,	O
and	O
concentrates	O
instead	O
on	O
the	O
basics	O
that	O
we	O
have	O
found	O
useful	O
in	O
large-scale	O
,	O
image-based	B
reconstruction	O
problems	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
we	O
begin	O
with	O
a	O
brief	O
discussion	O
of	O
triangulation	B
(	O
section	O
7.1	O
)	O
,	O
which	O
is	O
the	O
problem	O
of	O
estimating	O
a	O
point	O
’	O
s	O
3d	O
location	O
when	O
it	O
is	O
seen	O
from	O
multiple	B
cameras	O
.	O
next	O
,	O
we	O
look	O
at	O
the	O
two-frame	B
structure	O
from	O
motion	B
problem	O
(	O
section	O
7.2	O
)	O
,	O
which	O
involves	O
the	O
determination	O
of	O
the	O
epipolar	B
geometry	I
between	O
two	O
cameras	O
and	O
which	O
can	O
also	O
be	O
used	O
to	O
recover	O
certain	O
information	O
about	O
the	O
camera	B
intrinsics	O
using	O
self-calibration	O
(	O
section	O
7.2.2	O
)	O
.	O
section	O
7.3	O
looks	O
at	O
factorization	B
approaches	O
to	O
simultaneously	O
estimating	O
structure	O
and	O
motion	B
from	O
large	O
numbers	O
of	O
point	O
tracks	O
using	O
orthographic	O
approximations	O
to	O
the	O
projection	O
model	O
.	O
we	O
then	O
develop	O
a	O
more	O
general	O
and	O
useful	O
approach	O
to	O
structure	B
from	I
motion	I
,	O
namely	O
the	O
simultaneous	O
bundle	B
adjustment	I
of	O
all	O
the	O
camera	B
and	O
3d	O
structure	O
parameters	O
(	O
section	O
7.4	O
)	O
.	O
we	O
also	O
look	O
at	O
special	O
cases	O
that	O
arise	O
when	O
there	O
are	O
higher-level	O
structures	O
,	O
such	O
as	O
lines	B
and	O
planes	B
,	O
in	O
the	O
scene	O
(	O
section	O
7.5	O
)	O
.	O
7.1	O
triangulation	B
the	O
problem	O
of	O
determining	O
a	O
point	O
’	O
s	O
3d	O
position	O
from	O
a	O
set	O
of	O
corresponding	O
image	B
locations	O
and	O
known	O
camera	B
positions	O
is	O
known	O
as	O
triangulation	B
.	O
this	O
problem	O
is	O
the	O
converse	O
of	O
the	O
pose	O
estimation	B
problem	O
we	O
studied	O
in	O
section	O
6.2.	O
one	O
of	O
the	O
simplest	O
ways	O
to	O
solve	O
this	O
problem	O
is	O
to	O
ﬁnd	O
the	O
3d	O
point	O
p	O
that	O
lies	O
closest	O
to	O
all	O
of	O
the	O
3d	O
rays	O
corresponding	O
to	O
the	O
2d	O
matching	B
feature	O
locations	O
{	O
xj	O
}	O
observed	O
by	O
cam-	O
eras	O
{	O
p	O
j	O
=	O
kj	O
[	O
rj|tj	O
]	O
}	O
,	O
where	O
tj	O
=	O
−rjcj	O
and	O
cj	O
is	O
the	O
jth	O
camera	B
center	O
(	O
2.55–2.56	O
)	O
.	O
as	O
you	O
can	O
see	O
in	O
figure	O
7.2	O
,	O
these	O
rays	O
originate	O
at	O
cj	O
in	O
a	O
direction	O
ˆvj	O
=	O
n	O
(	O
r−1	O
j	O
xj	O
)	O
.	O
the	O
nearest	O
point	O
to	O
p	O
on	O
this	O
ray	O
,	O
which	O
we	O
denote	O
as	O
qj	O
,	O
minimizes	O
the	O
distance	O
j	O
k−1	O
(	O
cid:107	O
)	O
cj	O
+	O
dj	O
ˆvj	O
−	O
p	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
7.1	O
)	O
346	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
7.2	O
3d	O
point	O
triangulation	O
by	O
ﬁnding	O
the	O
point	O
p	O
that	O
lies	O
nearest	O
to	O
all	O
of	O
the	O
optical	O
rays	O
cj	O
+	O
dj	O
ˆvj	O
.	O
which	O
has	O
a	O
minimum	O
at	O
dj	O
=	O
ˆvj	O
·	O
(	O
p	O
−	O
cj	O
)	O
.	O
hence	O
,	O
qj	O
=	O
cj	O
+	O
(	O
ˆvj	O
ˆvt	O
j	O
)	O
(	O
p	O
−	O
cj	O
)	O
=	O
cj	O
+	O
(	O
p	O
−	O
cj	O
)	O
(	O
cid:107	O
)	O
,	O
in	O
the	O
notation	O
of	O
equation	B
(	O
2.29	O
)	O
,	O
and	O
the	O
squared	O
distance	O
between	O
p	O
and	O
qj	O
is	O
j	O
=	O
(	O
cid:107	O
)	O
(	O
i	O
−	O
ˆvj	O
ˆvt	O
r2	O
j	O
)	O
(	O
p	O
−	O
cj	O
)	O
(	O
cid:107	O
)	O
2	O
=	O
(	O
cid:107	O
)	O
(	O
p	O
−	O
cj	O
)	O
⊥	O
(	O
cid:107	O
)	O
2	O
.	O
(	O
7.2	O
)	O
(	O
7.3	O
)	O
the	O
optimal	O
value	O
for	O
p	O
,	O
which	O
lies	O
closest	O
to	O
all	O
of	O
the	O
rays	O
,	O
can	O
be	O
computed	O
as	O
a	O
regular	O
least	B
squares	I
problem	O
by	O
summing	O
over	O
all	O
the	O
r2	O
j	O
and	O
ﬁnding	O
the	O
optimal	O
value	O
of	O
p	O
,	O
p	O
=	O
(	O
cid:88	O
)	O
j	O
j	O
)	O
	O
−1	O
(	O
cid:88	O
)	O
j	O
j	O
)	O
cj	O
.	O
(	O
i	O
−	O
ˆvj	O
ˆvt	O
(	O
i	O
−	O
ˆvj	O
ˆvt	O
(	O
7.4	O
)	O
an	O
alternative	O
formulation	O
,	O
which	O
is	O
more	O
statistically	O
optimal	O
and	O
which	O
can	O
produce	O
signiﬁcantly	O
better	O
estimates	O
if	O
some	O
of	O
the	O
cameras	O
are	O
closer	O
to	O
the	O
3d	O
point	O
than	O
others	O
,	O
is	O
to	O
minimize	O
the	O
residual	O
in	O
the	O
measurement	O
equations	B
00	O
x	O
+	O
p	O
(	O
j	O
)	O
xj	O
=	O
p	O
(	O
j	O
)	O
20	O
x	O
+	O
p	O
(	O
j	O
)	O
p	O
(	O
j	O
)	O
10	O
x	O
+	O
p	O
(	O
j	O
)	O
yj	O
=	O
p	O
(	O
j	O
)	O
p	O
(	O
j	O
)	O
20	O
x	O
+	O
p	O
(	O
j	O
)	O
01	O
y	O
+	O
p	O
(	O
j	O
)	O
21	O
y	O
+	O
p	O
(	O
j	O
)	O
11	O
y	O
+	O
p	O
(	O
j	O
)	O
21	O
y	O
+	O
p	O
(	O
j	O
)	O
02	O
z	O
+	O
p	O
(	O
j	O
)	O
22	O
z	O
+	O
p	O
(	O
j	O
)	O
12	O
z	O
+	O
p	O
(	O
j	O
)	O
22	O
z	O
+	O
p	O
(	O
j	O
)	O
03	O
w	O
23	O
w	O
13	O
w	O
23	O
w	O
(	O
7.5	O
)	O
(	O
7.6	O
)	O
,	O
where	O
(	O
xj	O
,	O
yj	O
)	O
are	O
the	O
measured	O
2d	O
feature	B
locations	O
and	O
{	O
p	O
(	O
j	O
)	O
in	O
camera	B
matrix	O
p	O
j	O
(	O
sutherland	O
1974	O
)	O
.	O
23	O
}	O
are	O
the	O
known	O
entries	O
as	O
with	O
equations	O
(	O
6.21	O
,	O
6.33	O
,	O
and	O
6.34	O
)	O
,	O
this	O
set	O
of	O
non-linear	B
equations	O
can	O
be	O
converted	O
into	O
a	O
linear	B
least	O
squares	O
problem	O
by	O
multiplying	O
both	O
sides	O
of	O
the	O
denominator	O
.	O
note	O
that	O
if	O
00	O
.	O
.	O
.	O
p	O
(	O
j	O
)	O
px1x0r0c0c1r1v0v1d0d1q0^^q1	O
7.2	O
two-frame	B
structure	O
from	O
motion	B
347	O
we	O
use	O
homogeneous	B
coordinates	I
p	O
=	O
(	O
x	O
,	O
y	O
,	O
z	O
,	O
w	O
)	O
,	O
the	O
resulting	O
set	O
of	O
equations	B
is	O
homo-	O
geneous	O
and	O
is	O
best	O
solved	O
as	O
a	O
singular	O
value	O
decomposition	O
(	O
svd	O
)	O
or	O
eigenvalue	O
problem	O
(	O
looking	O
for	O
the	O
smallest	O
singular	O
vector	O
or	O
eigenvector	O
)	O
.	O
if	O
we	O
set	O
w	O
=	O
1	O
,	O
we	O
can	O
use	O
regular	O
linear	B
least	O
squares	O
,	O
but	O
the	O
resulting	O
system	O
may	O
be	O
singular	O
or	O
poorly	O
conditioned	O
,	O
i.e.	O
,	O
if	O
all	O
of	O
the	O
viewing	O
rays	O
are	O
parallel	O
,	O
as	O
occurs	O
for	O
points	O
far	O
away	O
from	O
the	O
camera	B
.	O
for	O
this	O
reason	O
,	O
it	O
is	O
generally	O
preferable	O
to	O
parameterize	O
3d	O
points	B
using	O
homogeneous	B
coordinates	I
,	O
especially	O
if	O
we	O
know	O
that	O
there	O
are	O
likely	O
to	O
be	O
points	B
at	O
greatly	O
varying	O
dis-	O
tances	O
from	O
the	O
cameras	O
.	O
of	O
course	O
,	O
minimizing	O
the	O
set	O
of	O
observations	O
(	O
7.5–7.6	O
)	O
using	O
non-	O
linear	B
least	O
squares	O
,	O
as	O
described	O
in	O
(	O
6.14	O
and	O
6.23	O
)	O
,	O
is	O
preferable	O
to	O
using	O
linear	O
least	B
squares	I
,	O
regardless	O
of	O
the	O
representation	O
chosen	O
.	O
for	O
the	O
case	O
of	O
two	O
observations	O
,	O
it	O
turns	O
out	O
that	O
the	O
location	O
of	O
the	O
point	O
p	O
that	O
exactly	O
minimizes	O
the	O
true	O
reprojection	O
error	O
(	O
7.5–7.6	O
)	O
can	O
be	O
computed	O
using	O
the	O
solution	O
of	O
degree	O
six	O
equations	B
(	O
hartley	O
and	O
sturm	O
1997	O
)	O
.	O
another	O
problem	O
to	O
watch	O
out	O
for	O
with	O
triangulation	B
is	O
the	O
issue	O
of	O
chirality	O
,	O
i.e.	O
,	O
ensuring	O
that	O
the	O
reconstructed	O
points	B
lie	O
in	O
front	O
of	O
all	O
the	O
cameras	O
(	O
hartley	O
1998	O
)	O
.	O
while	O
this	O
can	O
not	O
always	O
be	O
guaranteed	O
,	O
a	O
useful	O
heuristic	O
is	O
to	O
take	O
the	O
points	B
that	O
lie	O
behind	O
the	O
cameras	O
because	O
their	O
rays	O
are	O
diverging	O
(	O
imagine	O
figure	O
7.2	O
where	O
the	O
rays	O
were	O
pointing	O
away	O
from	O
each	O
other	O
)	O
and	O
to	O
place	O
them	O
on	O
the	O
plane	O
at	O
inﬁnity	O
by	O
setting	O
their	O
w	O
values	O
to	O
0	O
.	O
7.2	O
two-frame	B
structure	O
from	O
motion	B
so	O
far	O
in	O
our	O
study	O
of	O
3d	O
reconstruction	O
,	O
we	O
have	O
always	O
assumed	O
that	O
either	O
the	O
3d	O
point	O
positions	O
or	O
the	O
3d	O
camera	B
poses	O
are	O
known	O
in	O
advance	O
.	O
in	O
this	O
section	O
,	O
we	O
take	O
our	O
ﬁrst	O
look	O
at	O
structure	B
from	I
motion	I
,	O
which	O
is	O
the	O
simultaneous	O
recovery	B
of	O
3d	O
structure	O
and	O
pose	O
from	O
image	B
correspondences	O
.	O
consider	O
figure	O
7.3	O
,	O
which	O
shows	O
a	O
3d	O
point	O
p	O
being	O
viewed	O
from	O
two	O
cameras	O
whose	O
relative	O
position	O
can	O
be	O
encoded	O
by	O
a	O
rotation	O
r	O
and	O
a	O
translation	B
t.	O
since	O
we	O
do	O
not	O
know	O
anything	O
about	O
the	O
camera	B
positions	O
,	O
without	O
loss	O
of	O
generality	O
,	O
we	O
can	O
set	O
the	O
ﬁrst	O
camera	B
at	O
the	O
origin	O
c0	O
=	O
0	O
and	O
at	O
a	O
canonical	O
orientation	O
r0	O
=	O
i.	O
now	O
notice	O
that	O
the	O
observed	O
location	O
of	O
point	O
p	O
in	O
the	O
ﬁrst	O
image	B
,	O
p0	O
=	O
d0	O
ˆx0	O
is	O
mapped	O
into	O
the	O
second	O
image	O
by	O
the	O
transformation	O
d1	O
ˆx1	O
=	O
p1	O
=	O
rp0	O
+	O
t	O
=	O
r	O
(	O
d0	O
ˆx0	O
)	O
+	O
t	O
,	O
(	O
7.7	O
)	O
where	O
ˆxj	O
=	O
k−1	O
sides	O
with	O
t	O
in	O
order	B
to	O
annihilate	O
it	O
on	O
the	O
right	O
hand	O
side	O
yields1	O
j	O
xj	O
are	O
the	O
(	O
local	B
)	O
ray	O
direction	O
vectors	O
.	O
taking	O
the	O
cross	O
product	O
of	O
both	O
1	O
the	O
cross-product	O
operator	O
[	O
]	O
×	O
was	O
introduced	O
in	O
(	O
2.32	O
)	O
.	O
d1	O
[	O
t	O
]	O
×	O
ˆx1	O
=	O
d0	O
[	O
t	O
]	O
×rˆx0	O
.	O
(	O
7.8	O
)	O
348	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
7.3	O
epipolar	B
geometry	I
:	O
the	O
vectors	O
t	O
=	O
c1	O
−	O
c0	O
,	O
p	O
−	O
c0	O
and	O
p	O
−	O
c1	O
are	O
co-planar	O
and	O
deﬁne	O
the	O
basic	O
epipolar	O
constraint	O
expressed	O
in	O
terms	O
of	O
the	O
pixel	O
measurements	O
x0	O
and	O
x1	O
.	O
taking	O
the	O
dot	O
product	O
of	O
both	O
sides	O
with	O
ˆx1	O
yields	O
d0	O
ˆxt	O
1	O
(	O
[	O
t	O
]	O
×r	O
)	O
ˆx0	O
=	O
d1	O
ˆxt	O
1	O
[	O
t	O
]	O
×	O
ˆx1	O
=	O
0	O
,	O
(	O
7.9	O
)	O
since	O
the	O
right	O
hand	O
side	O
is	O
a	O
triple	O
product	O
with	O
two	O
identical	O
entries	O
.	O
(	O
another	O
way	O
to	O
say	O
this	O
is	O
that	O
the	O
cross	O
product	O
matrix	O
[	O
t	O
]	O
×	O
is	O
skew	O
symmetric	O
and	O
returns	O
0	O
when	O
pre-	O
and	O
post-multiplied	O
by	O
the	O
same	O
vector	O
.	O
)	O
we	O
therefore	O
arrive	O
at	O
the	O
basic	O
epipolar	O
constraint	O
ˆxt	O
1	O
e	O
ˆx0	O
=	O
0	O
,	O
where	O
e	O
=	O
[	O
t	O
]	O
×r	O
is	O
called	O
the	O
essential	O
matrix	O
(	O
longuet-higgins	O
1981	O
)	O
.	O
(	O
7.10	O
)	O
(	O
7.11	O
)	O
an	O
alternative	O
way	O
to	O
derive	O
the	O
epipolar	O
constraint	O
is	O
to	O
notice	O
that	O
in	O
order	B
for	O
the	O
cam-	O
eras	O
to	O
be	O
oriented	B
so	O
that	O
the	O
rays	O
ˆx0	O
and	O
ˆx1	O
intersect	O
in	O
3d	O
at	O
point	O
p	O
,	O
the	O
vectors	O
connecting	O
the	O
two	O
camera	O
centers	O
c1	O
−	O
c0	O
=	O
−r−1	O
1	O
t	O
and	O
the	O
rays	O
corresponding	O
to	O
pixels	O
x0	O
and	O
x1	O
,	O
namely	O
r−1	O
j	O
ˆxj	O
,	O
must	O
be	O
co-planar	O
.	O
this	O
requires	O
that	O
the	O
triple	O
product	O
(	O
ˆx0	O
,	O
r−1	O
ˆx1	O
,	O
−r−1t	O
)	O
=	O
(	O
rˆx0	O
,	O
ˆx1	O
,	O
−t	O
)	O
=	O
ˆx1	O
·	O
(	O
t	O
×	O
rˆx0	O
)	O
=	O
ˆxt	O
notice	O
that	O
the	O
essential	O
matrix	O
e	O
maps	O
a	O
point	O
ˆx0	O
in	O
image	B
0	O
into	O
a	O
line	O
l1	O
=	O
e	O
ˆx0	O
in	O
image	B
1	O
,	O
since	O
ˆxt	O
1	O
l1	O
=	O
0	O
(	O
figure	O
7.3	O
)	O
.	O
all	O
such	O
lines	B
must	O
pass	O
through	O
the	O
second	O
epipole	O
e1	O
,	O
which	O
is	O
therefore	O
deﬁned	O
as	O
the	O
left	O
singular	O
vector	O
of	O
e	O
with	O
a	O
0	O
singular	O
value	O
,	O
or	O
,	O
equivalently	O
,	O
the	O
projection	O
of	O
the	O
vector	O
t	O
into	O
image	B
1.	O
the	O
dual	O
(	O
transpose	O
)	O
of	O
these	O
1	O
(	O
[	O
t	O
]	O
×r	O
)	O
ˆx0	O
=	O
0	O
.	O
(	O
7.12	O
)	O
epipolar	O
planep∞p	O
(	O
r	O
,	O
t	O
)	O
c0c1epipolarlinesx0e0e1x1l1l0	O
7.2	O
two-frame	B
structure	O
from	O
motion	B
349	O
relationships	O
gives	O
us	O
the	O
epipolar	O
line	O
in	O
the	O
ﬁrst	O
image	B
as	O
l0	O
=	O
et	O
ˆx1	O
and	O
e0	O
as	O
the	O
zero-	O
value	O
right	O
singular	O
vector	O
of	O
e.	O
given	O
this	O
fundamental	O
relationship	O
(	O
7.10	O
)	O
,	O
how	O
can	O
we	O
use	O
it	O
to	O
recover	O
the	O
camera	B
motion	O
encoded	O
in	O
the	O
essential	O
matrix	O
e	O
?	O
if	O
we	O
have	O
n	O
corresponding	O
measurements	O
{	O
(	O
xi0	O
,	O
xi1	O
)	O
}	O
,	O
we	O
can	O
form	O
n	O
homogeneous	O
equations	O
in	O
the	O
nine	O
elements	O
of	O
e	O
=	O
{	O
e00	O
.	O
.	O
.	O
e22	O
}	O
,	O
xi0xi1e00	O
+	O
yi0xi1e01	O
+	O
xi1e02	O
+	O
xi0yi1e00	O
+	O
yi0yi1e11	O
+	O
yi1e12	O
+	O
xi0e20	O
+	O
yi0e21	O
+	O
e22	O
=	O
0	O
where	O
xij	O
=	O
(	O
xij	O
,	O
yij	O
,	O
1	O
)	O
.	O
this	O
can	O
be	O
written	O
more	O
compactly	O
as	O
[	O
xi1	O
xt	O
i0	O
]	O
⊗	O
e	O
=	O
zi	O
⊗	O
e	O
=	O
zi	O
·	O
f	O
=	O
0	O
,	O
(	O
7.13	O
)	O
(	O
7.14	O
)	O
where	O
⊗	O
indicates	O
an	O
element-wise	O
multiplication	B
and	O
summation	O
of	O
matrix	O
elements	O
,	O
and	O
zi	O
i0	O
and	O
e	O
matrices.2	O
given	O
n	O
≥	O
8	O
and	O
f	O
are	O
the	O
rasterized	O
(	O
vector	O
)	O
forms	O
of	O
the	O
zi	O
=	O
ˆxi1	O
ˆxt	O
such	O
equations	B
,	O
we	O
can	O
compute	O
an	O
estimate	O
(	O
up	O
to	O
scale	O
)	O
for	O
the	O
entries	O
in	O
e	O
using	O
an	O
svd	O
.	O
in	O
the	O
presence	O
of	O
noisy	O
measurements	O
,	O
how	O
close	O
is	O
this	O
estimate	O
to	O
being	O
statistically	O
optimal	O
?	O
if	O
you	O
look	O
at	O
the	O
entries	O
in	O
(	O
7.13	O
)	O
,	O
you	O
can	O
see	O
that	O
some	O
entries	O
are	O
the	O
products	O
of	O
image	B
measurements	O
such	O
as	O
xi0yi1	O
and	O
others	O
are	O
direct	B
image	O
measurements	O
(	O
or	O
even	O
the	O
identity	O
)	O
.	O
if	O
the	O
measurements	O
have	O
comparable	O
noise	B
,	O
the	O
terms	O
that	O
are	O
products	O
of	O
measurements	O
have	O
their	O
noise	B
ampliﬁed	O
by	O
the	O
other	O
element	O
in	O
the	O
product	O
,	O
which	O
can	O
lead	O
to	O
very	O
poor	O
scaling	O
,	O
e.g.	O
,	O
an	O
inordinately	O
large	O
inﬂuence	O
of	O
points	B
with	O
large	O
coordinates	O
(	O
far	O
away	O
from	O
the	O
image	B
center	O
)	O
.	O
in	O
order	B
to	O
counteract	O
this	O
trend	O
,	O
hartley	O
(	O
1997a	O
)	O
suggests	O
that	O
the	O
point	O
coordinates	O
should	O
be	O
translated	O
and	O
scaled	O
so	O
that	O
their	O
centroid	O
lies	O
at	O
the	O
origin	O
and	O
their	O
variance	O
is	O
unity	O
,	O
i.e.	O
,	O
˜xi	O
=	O
s	O
(	O
xi	O
−	O
µx	O
)	O
˜yi	O
=	O
s	O
(	O
xi	O
−	O
µy	O
)	O
i	O
+	O
(	O
cid:80	O
)	O
i	O
˜y2	O
(	O
7.15	O
)	O
(	O
7.16	O
)	O
such	O
that	O
(	O
cid:80	O
)	O
i	O
˜xi	O
=	O
(	O
cid:80	O
)	O
i	O
˜yi	O
=	O
0	O
and	O
(	O
cid:80	O
)	O
i	O
˜x2	O
once	O
the	O
essential	O
matrix	O
˜e	O
has	O
been	O
computed	O
from	O
the	O
transformed	O
coordinates	O
{	O
(	O
˜xi0	O
,	O
˜xi1	O
)	O
}	O
,	O
where	O
˜xij	O
=	O
t	O
j	O
ˆxij	O
,	O
the	O
original	O
essential	O
matrix	O
e	O
can	O
be	O
recovered	O
as	O
i	O
=	O
2n	O
,	O
where	O
n	O
is	O
the	O
number	O
of	O
points.3	O
e	O
=	O
t	O
1	O
˜et	O
0	O
.	O
(	O
7.17	O
)	O
2	O
we	O
use	O
f	O
instead	O
of	O
e	O
to	O
denote	O
the	O
rasterized	O
form	O
of	O
e	O
to	O
avoid	O
confusion	O
with	O
the	O
epipoles	O
ej	O
.	O
3	O
more	O
precisely	O
,	O
hartley	O
(	O
1997a	O
)	O
suggests	O
scaling	O
the	O
points	B
“	O
so	O
that	O
the	O
average	O
distance	O
from	O
the	O
origin	O
is	O
equal	O
√	O
2	O
”	O
but	O
the	O
heuristic	O
of	O
unit	O
variance	O
is	O
faster	O
to	O
compute	O
(	O
does	O
not	O
require	O
per-point	O
square	O
roots	O
)	O
and	O
should	O
to	O
yield	O
comparable	O
improvements	O
.	O
350	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
in	O
his	O
paper	O
,	O
hartley	O
(	O
1997a	O
)	O
compares	O
the	O
improvement	O
due	O
to	O
his	O
re-normalization	B
strategy	O
to	O
alternative	O
distance	O
measures	O
proposed	O
by	O
others	O
such	O
as	O
zhang	O
(	O
1998a	O
,	O
b	O
)	O
and	O
concludes	O
that	O
his	O
simple	O
re-normalization	B
in	O
most	O
cases	O
is	O
as	O
effective	O
as	O
(	O
or	O
better	O
than	O
)	O
alternative	O
techniques	O
.	O
torr	O
and	O
fitzgibbon	O
(	O
2004	O
)	O
recommend	O
a	O
variant	O
on	O
this	O
algorithm	B
where	O
the	O
norm	O
of	O
the	O
upper	O
2	O
×	O
2	O
sub-matrix	O
of	O
e	O
is	O
set	O
to	O
1	O
and	O
show	O
that	O
it	O
has	O
even	O
better	O
stability	O
with	O
respect	O
to	O
2d	O
coordinate	B
transformations	I
.	O
once	O
an	O
estimate	O
for	O
the	O
essential	O
matrix	O
e	O
has	O
been	O
recovered	O
,	O
the	O
direction	O
of	O
the	O
trans-	O
lation	O
vector	O
t	O
can	O
be	O
estimated	O
.	O
note	O
that	O
the	O
absolute	O
distance	O
between	O
the	O
two	O
cameras	O
can	O
never	O
be	O
recovered	O
from	O
pure	O
image	O
measurements	O
alone	O
,	O
regardless	O
of	O
how	O
many	O
cameras	O
or	O
points	B
are	O
used	O
.	O
knowledge	O
about	O
absolute	O
camera	O
and	O
point	O
positions	O
or	O
distances	O
,	O
of-	O
ten	O
called	O
ground	O
control	O
points	B
in	O
photogrammetry	B
,	O
is	O
always	O
required	O
to	O
establish	O
the	O
ﬁnal	O
scale	O
,	O
position	O
,	O
and	O
orientation	O
.	O
to	O
estimate	O
this	O
direction	O
ˆt	O
,	O
observe	O
that	O
under	O
ideal	O
noise-free	O
conditions	O
,	O
the	O
essential	O
e	O
=	O
0.	O
this	O
singularity	O
shows	O
up	O
as	O
a	O
singular	O
value	O
of	O
0	O
when	O
t	O
matrix	O
e	O
is	O
singular	O
,	O
i.e.	O
,	O
ˆt	O
an	O
svd	O
of	O
e	O
is	O
performed	O
,	O
	O
	O
vt	O
0	O
vt	O
1	O
vt	O
2	O
	O
(	O
7.18	O
)	O
e	O
=	O
[	O
ˆt	O
]	O
×r	O
=	O
uσv	O
t	O
=	O
(	O
cid:104	O
)	O
u0	O
u1	O
ˆt	O
(	O
cid:105	O
)	O
	O
1	O
1	O
0	O
when	O
e	O
is	O
computed	O
from	O
noisy	O
measurements	O
,	O
the	O
singular	O
vector	O
associated	O
with	O
the	O
small-	O
est	O
singular	O
value	O
gives	O
us	O
ˆt	O
.	O
(	O
the	O
other	O
two	O
singular	O
values	O
should	O
be	O
similar	O
but	O
are	O
not	O
,	O
in	O
general	O
,	O
equal	O
to	O
1	O
because	O
e	O
is	O
only	O
computed	O
up	O
to	O
an	O
unknown	O
scale	O
.	O
)	O
because	O
e	O
is	O
rank-deﬁcient	B
,	O
it	O
turns	O
out	O
that	O
we	O
actually	O
only	O
need	O
seven	O
correspondences	O
of	O
the	O
form	O
of	O
equation	B
(	O
7.14	O
)	O
instead	O
of	O
eight	O
to	O
estimate	O
this	O
matrix	O
(	O
hartley	O
1994a	O
;	O
torr	O
and	O
murray	O
1997	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
(	O
the	O
advantage	O
of	O
using	O
fewer	O
correspondences	O
inside	O
a	O
ransac	O
robust	B
ﬁtting	O
stage	O
is	O
that	O
fewer	O
random	O
samples	O
need	O
to	O
be	O
generated	O
.	O
)	O
from	O
this	O
set	O
of	O
seven	O
homogeneous	O
equations	O
(	O
which	O
we	O
can	O
stack	O
into	O
a	O
7	O
×	O
9	O
matrix	O
for	O
svd	O
analysis	O
)	O
,	O
we	O
can	O
ﬁnd	O
two	O
independent	O
vectors	O
,	O
say	O
f	O
0	O
and	O
f	O
1	O
such	O
that	O
zi	O
·	O
f	O
j	O
=	O
0.	O
these	O
two	O
vectors	O
can	O
be	O
converted	O
back	O
into	O
3	O
×	O
3	O
matrices	O
e0	O
and	O
e1	O
,	O
which	O
span	O
the	O
solution	O
space	O
for	O
(	O
7.19	O
)	O
e	O
=	O
αe0	O
+	O
(	O
1	O
−	O
α	O
)	O
e1	O
.	O
to	O
ﬁnd	O
the	O
correct	O
value	O
of	O
α	O
,	O
we	O
observe	O
that	O
e	O
has	O
a	O
zero	O
determinant	O
,	O
since	O
it	O
is	O
rank	O
deﬁcient	O
,	O
and	O
hence	O
det|αe0	O
+	O
(	O
1	O
−	O
α	O
)	O
e1|	O
=	O
0	O
.	O
(	O
7.20	O
)	O
this	O
gives	O
us	O
a	O
cubic	B
equation	O
in	O
α	O
,	O
which	O
has	O
either	O
one	O
or	O
three	O
solutions	O
(	O
roots	O
)	O
.	O
substitut-	O
ing	O
these	O
values	O
into	O
(	O
7.19	O
)	O
to	O
obtain	O
e	O
,	O
we	O
can	O
test	O
this	O
essential	O
matrix	O
against	O
other	O
unused	O
feature	B
correspondences	O
to	O
select	O
the	O
correct	O
one	O
.	O
7.2	O
two-frame	B
structure	O
from	O
motion	B
351	O
once	O
ˆt	O
has	O
been	O
recovered	O
,	O
how	O
can	O
we	O
estimate	O
the	O
corresponding	O
rotation	O
matrix	O
r	O
?	O
recall	B
that	O
the	O
cross-product	O
operator	O
[	O
ˆt	O
]	O
×	O
(	O
2.32	O
)	O
projects	O
a	O
vector	O
onto	O
a	O
set	O
of	O
orthogonal	O
basis	O
vectors	O
that	O
include	O
ˆt	O
,	O
zeros	O
out	O
the	O
ˆt	O
component	O
,	O
and	O
rotates	O
the	O
other	O
two	O
by	O
90◦	O
,	O
[	O
ˆt	O
]	O
×	O
=	O
szr90◦	O
st	O
=	O
(	O
cid:104	O
)	O
s0	O
s1	O
ˆt	O
(	O
cid:105	O
)	O
	O
1	O
1	O
0	O
where	O
ˆt	O
=	O
s0	O
×	O
s1	O
.	O
from	O
equations	B
(	O
7.18	O
and	O
7.21	O
)	O
,	O
we	O
get	O
0	O
−1	O
0	O
1	O
	O
	O
e	O
=	O
[	O
ˆt	O
]	O
×r	O
=	O
szr90◦	O
st	O
r	O
=	O
uσv	O
t	O
,	O
	O
	O
st	O
0	O
st	O
1	O
t	O
ˆt	O
	O
,	O
1	O
(	O
7.21	O
)	O
(	O
7.22	O
)	O
from	O
which	O
we	O
can	O
conclude	O
that	O
s	O
=	O
u.	O
recall	B
that	O
for	O
a	O
noise-free	O
essential	O
matrix	O
,	O
(	O
σ	O
=	O
z	O
)	O
,	O
and	O
hence	O
r90◦	O
u	O
t	O
r	O
=	O
v	O
t	O
(	O
7.23	O
)	O
and	O
(	O
7.24	O
)	O
unfortunately	O
,	O
we	O
only	O
know	O
both	O
e	O
and	O
ˆt	O
up	O
to	O
a	O
sign	O
.	O
furthermore	O
,	O
the	O
matrices	O
u	O
and	O
v	O
are	O
not	O
guaranteed	O
to	O
be	O
rotations	O
(	O
you	O
can	O
ﬂip	O
both	O
their	O
signs	O
and	O
still	O
get	O
a	O
valid	O
svd	O
)	O
.	O
for	O
this	O
reason	O
,	O
we	O
have	O
to	O
generate	O
all	O
four	O
possible	O
rotation	O
matrices	O
r	O
=	O
u	O
rt	O
90◦	O
v	O
t	O
.	O
r	O
=	O
±u	O
rt	O
±90◦	O
v	O
t	O
(	O
7.25	O
)	O
and	O
keep	O
the	O
two	O
whose	O
determinant	O
|r|	O
=	O
1.	O
to	O
disambiguate	O
between	O
the	O
remaining	O
pair	O
of	O
potential	O
rotations	O
,	O
which	O
form	O
a	O
twisted	B
pair	I
(	O
hartley	O
and	O
zisserman	O
2004	O
,	O
p.	O
240	O
)	O
,	O
we	O
need	O
to	O
pair	O
them	O
with	O
both	O
possible	O
signs	O
of	O
the	O
translation	B
direction	O
±ˆt	O
and	O
select	O
the	O
combination	O
for	O
which	O
the	O
largest	O
number	O
of	O
points	B
is	O
seen	O
in	O
front	O
of	O
both	O
cameras.4	O
the	O
property	O
that	O
points	B
must	O
lie	O
in	O
front	O
of	O
the	O
camera	B
,	O
i.e.	O
,	O
at	O
a	O
positive	O
distance	O
along	O
the	O
viewing	O
rays	O
emanating	O
from	O
the	O
camera	B
,	O
is	O
known	O
as	O
chirality	O
(	O
hartley	O
1998	O
)	O
.	O
in	O
addition	O
to	O
determining	O
the	O
signs	O
of	O
the	O
rotation	O
and	O
translation	B
,	O
as	O
described	O
above	O
,	O
the	O
chirality	O
(	O
sign	O
of	O
the	O
distances	O
)	O
of	O
the	O
points	B
in	O
a	O
reconstruction	O
can	O
be	O
used	O
inside	O
a	O
ransac	O
procedure	O
(	O
along	O
with	O
the	O
reprojection	O
errors	O
)	O
to	O
distinguish	O
between	O
likely	O
and	O
unlikely	O
conﬁgurations.5	O
chirality	O
can	O
also	O
be	O
used	O
to	O
transform	B
projective	O
reconstructions	O
(	O
sections	O
7.2.1	O
and	O
7.2.2	O
)	O
into	O
quasi-afﬁne	O
reconstructions	O
(	O
hartley	O
1998	O
)	O
.	O
the	O
normalized	B
“	O
eight-point	B
algorithm	I
”	O
(	O
hartley	O
1997a	O
)	O
described	O
above	O
is	O
not	O
the	O
only	O
way	O
to	O
estimate	O
the	O
camera	B
motion	O
from	O
correspondences	O
.	O
variants	O
include	O
using	O
seven	O
points	B
4	O
in	O
the	O
noise-free	O
case	O
,	O
a	O
single	O
point	O
sufﬁces	O
.	O
it	O
is	O
safer	O
,	O
however	O
,	O
to	O
test	O
all	O
or	O
a	O
sufﬁcient	O
subset	O
of	O
points	B
,	O
downweighting	O
the	O
ones	O
that	O
lie	O
close	O
to	O
the	O
plane	O
at	O
inﬁnity	O
,	O
for	O
which	O
it	O
is	O
easy	O
to	O
get	O
depth	O
reversals	O
.	O
5	O
note	O
that	O
as	O
points	B
get	O
further	O
away	O
from	O
a	O
camera	B
,	O
i.e.	O
,	O
closer	O
toward	O
the	O
plane	O
at	O
inﬁnity	O
,	O
errors	O
in	O
chirality	O
become	O
more	O
likely	O
.	O
352	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
7.4	O
pure	O
translational	O
camera	B
motion	O
results	O
in	O
visual	O
motion	O
where	O
all	O
the	O
points	B
move	O
towards	O
(	O
or	O
away	O
from	O
)	O
a	O
common	O
focus	B
of	O
expansion	O
(	O
foe	O
)	O
e.	O
they	O
therefore	O
satisfy	O
the	O
triple	O
product	O
condition	O
(	O
x0	O
,	O
x1	O
,	O
e	O
)	O
=	O
e	O
·	O
(	O
x0	O
×	O
x1	O
)	O
=	O
0.	O
while	O
enforcing	O
the	O
rank	O
two	O
constraint	O
in	O
e	O
(	O
7.19–7.20	O
)	O
and	O
a	O
ﬁve-point	O
algorithm	B
that	O
requires	O
ﬁnding	O
the	O
roots	O
of	O
a	O
10th	O
degree	O
polynomial	O
(	O
nist´er	O
2004	O
)	O
.	O
since	O
such	O
algorithms	O
use	O
fewer	O
points	B
to	O
compute	O
their	O
estimates	O
,	O
they	O
are	O
less	O
sensitive	O
to	O
outliers	O
when	O
used	O
as	O
part	O
of	O
a	O
random	O
sampling	O
(	O
ransac	O
)	O
strategy	B
.	O
pure	B
translation	I
(	O
known	O
rotation	O
)	O
in	O
the	O
case	O
where	O
we	O
know	O
the	O
rotation	O
,	O
we	O
can	O
pre-rotate	O
the	O
points	B
in	O
the	O
second	O
image	O
to	O
match	O
the	O
viewing	O
direction	O
of	O
the	O
ﬁrst	O
.	O
the	O
resulting	O
set	O
of	O
3d	O
points	B
all	O
move	O
towards	O
(	O
or	O
away	O
from	O
)	O
the	O
focus	B
of	O
expansion	O
(	O
foe	O
)	O
,	O
as	O
shown	O
in	O
figure	O
7.4.6	O
the	O
resulting	O
essential	O
matrix	O
e	O
is	O
(	O
in	O
the	O
noise-free	O
case	O
)	O
skew	O
symmetric	O
and	O
so	O
can	O
be	O
estimated	O
more	O
directly	O
by	O
setting	O
eij	O
=	O
−eji	O
and	O
eii	O
=	O
0	O
in	O
(	O
7.13	O
)	O
.	O
two	O
points	O
with	O
non-zero	O
parallax	O
now	O
sufﬁce	O
to	O
estimate	O
the	O
foe	O
.	O
a	O
more	O
direct	B
derivation	O
of	O
the	O
foe	O
estimate	O
can	O
be	O
obtained	O
by	O
minimizing	O
the	O
triple	O
product	O
(	O
(	O
xi0	O
×	O
xi1	O
)	O
·	O
e	O
)	O
2	O
,	O
which	O
is	O
equivalent	O
to	O
ﬁnding	O
the	O
null	O
space	O
for	O
the	O
set	O
of	O
equations	B
(	O
cid:88	O
)	O
i	O
(	O
xi0	O
,	O
xi1	O
,	O
e	O
)	O
2	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
yi0	O
−	O
yi1	O
)	O
e0	O
+	O
(	O
xi1	O
−	O
xi0	O
)	O
e1	O
+	O
(	O
xi0yi1	O
−	O
yi0xi1	O
)	O
e2	O
=	O
0	O
.	O
(	O
7.26	O
)	O
(	O
7.27	O
)	O
note	O
that	O
,	O
as	O
in	O
the	O
eight-point	B
algorithm	I
,	O
it	O
is	O
advisable	O
to	O
normalize	O
the	O
2d	O
points	B
to	O
have	O
unit	O
variance	O
before	O
computing	O
this	O
estimate	O
.	O
in	O
situations	O
where	O
a	O
large	O
number	O
of	O
points	B
at	O
inﬁnity	O
are	O
available	O
,	O
e.g.	O
,	O
when	O
shooting	O
outdoor	O
scenes	O
or	O
when	O
the	O
camera	B
motion	O
is	O
small	O
compared	O
to	O
distant	O
objects	O
,	O
this	O
suggests	O
an	O
alternative	O
ransac	O
strategy	B
for	O
estimating	O
the	O
camera	B
motion	O
.	O
first	O
,	O
pick	O
a	O
pair	O
of	O
points	B
to	O
estimate	O
a	O
rotation	O
,	O
hoping	O
that	O
both	O
of	O
the	O
points	B
lie	O
at	O
inﬁnity	O
(	O
very	O
far	O
from	O
the	O
6	O
fans	O
of	O
star	O
trek	O
and	O
star	O
wars	O
will	O
recognize	O
this	O
as	O
the	O
“	O
jump	O
to	O
hyperdrive	O
”	O
visual	O
effect	O
.	O
exi0xi1	O
7.2	O
two-frame	B
structure	O
from	O
motion	B
353	O
camera	B
)	O
.	O
then	O
,	O
compute	O
the	O
foe	O
and	O
check	O
whether	O
the	O
residual	O
error	O
is	O
small	O
(	O
indicating	O
agreement	O
with	O
this	O
rotation	O
hypothesis	O
)	O
and	O
whether	O
the	O
motions	O
towards	O
or	O
away	O
from	O
the	O
epipole	O
(	O
foe	O
)	O
are	O
all	O
in	O
the	O
same	O
direction	O
(	O
ignoring	O
very	O
small	O
motions	O
,	O
which	O
may	O
be	O
noise-contaminated	O
)	O
.	O
pure	B
rotation	I
the	O
case	O
of	O
pure	B
rotation	I
results	O
in	O
a	O
degenerate	O
estimate	O
of	O
the	O
essential	O
matrix	O
e	O
and	O
of	O
the	O
translation	B
direction	O
ˆt	O
.	O
consider	O
ﬁrst	O
the	O
case	O
of	O
the	O
rotation	O
matrix	O
being	O
known	O
.	O
the	O
estimates	O
for	O
the	O
foe	O
will	O
be	O
degenerate	O
,	O
since	O
xi0	O
≈	O
xi1	O
,	O
and	O
hence	O
(	O
7.27	O
)	O
,	O
is	O
degenerate	O
.	O
a	O
similar	O
argument	O
shows	O
that	O
the	O
equations	B
for	O
the	O
essential	O
matrix	O
(	O
7.13	O
)	O
are	O
also	O
rank-	O
deﬁcient	O
.	O
this	O
suggests	O
that	O
it	O
might	O
be	O
prudent	O
before	O
computing	O
a	O
full	O
essential	O
matrix	O
to	O
ﬁrst	O
compute	O
a	O
rotation	O
estimate	O
r	O
using	O
(	O
6.32	O
)	O
,	O
potentially	O
with	O
just	O
a	O
small	O
number	O
of	O
points	B
,	O
and	O
then	O
compute	O
the	O
residuals	O
after	O
rotating	O
the	O
points	B
before	O
proceeding	O
with	O
a	O
full	O
e	O
computation	O
.	O
7.2.1	O
projective	B
(	O
uncalibrated	O
)	O
reconstruction	O
in	O
many	O
cases	O
,	O
such	O
as	O
when	O
trying	O
to	O
build	O
a	O
3d	O
model	O
from	O
internet	O
or	O
legacy	O
photos	O
taken	O
by	O
unknown	O
cameras	O
without	O
any	O
exif	O
tags	O
,	O
we	O
do	O
not	O
know	O
ahead	O
of	O
time	O
the	O
intrinsic	B
calibration	O
parameters	B
associated	O
with	O
the	O
input	O
images	O
.	O
in	O
such	O
situations	O
,	O
we	O
can	O
still	O
esti-	O
mate	O
a	O
two-frame	B
reconstruction	O
,	O
although	O
the	O
true	O
metric	O
structure	O
may	O
not	O
be	O
available	O
,	O
e.g.	O
,	O
orthogonal	O
lines	O
or	O
planes	B
in	O
the	O
world	O
may	O
not	O
end	O
up	O
being	O
reconstructed	O
as	O
orthogonal	O
.	O
consider	O
the	O
derivations	O
we	O
used	O
to	O
estimate	O
the	O
essential	O
matrix	O
e	O
(	O
7.10–7.12	O
)	O
.	O
in	O
the	O
uncalibrated	O
case	O
,	O
we	O
do	O
not	O
know	O
the	O
calibration	B
matrices	O
kj	O
,	O
so	O
we	O
can	O
not	O
use	O
the	O
normal-	O
ized	O
ray	O
directions	O
ˆxj	O
=	O
k−1	O
j	O
xj	O
.	O
instead	O
,	O
we	O
have	O
access	O
only	O
to	O
the	O
image	B
coordinates	O
xj	O
,	O
and	O
so	O
the	O
essential	O
matrix	O
(	O
7.10	O
)	O
becomes	O
ˆxt	O
1	O
e	O
ˆx1	O
=	O
xt	O
1	O
f	O
x0	O
=	O
0	O
,	O
1	O
k−t	O
1	O
ek−1	O
0	O
x0	O
=	O
xt	O
where	O
f	O
=	O
k−t	O
1	O
ek−1	O
0	O
=	O
[	O
e	O
]	O
×	O
˜h	O
(	O
7.28	O
)	O
(	O
7.29	O
)	O
is	O
called	O
the	O
fundamental	O
matrix	O
(	O
faugeras	O
1992	O
;	O
hartley	O
,	O
gupta	O
,	O
and	O
chang	O
1992	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
like	O
the	O
essential	O
matrix	O
,	O
the	O
fundamental	O
matrix	O
is	O
(	O
in	O
principle	O
)	O
rank	O
two	O
,	O
f	O
=	O
[	O
e	O
]	O
×	O
˜h	O
=	O
uσv	O
t	O
=	O
(	O
cid:104	O
)	O
u0	O
u1	O
e1	O
(	O
cid:105	O
)	O
	O
σ0	O
σ1	O
0	O
	O
	O
vt	O
0	O
vt	O
1	O
et	O
0	O
	O
.	O
(	O
7.30	O
)	O
354	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
its	O
smallest	O
left	O
singular	O
vector	O
indicates	O
the	O
epipole	O
e1	O
in	O
the	O
image	B
1	O
and	O
its	O
smallest	O
right	O
singular	O
vector	O
is	O
e0	O
(	O
figure	O
7.3	O
)	O
.	O
the	O
homography	B
˜h	O
in	O
(	O
7.29	O
)	O
,	O
which	O
in	O
principle	O
should	O
equal	O
˜h	O
=	O
k−t	O
1	O
rk−1	O
0	O
,	O
(	O
7.31	O
)	O
can	O
not	O
be	O
uniquely	O
recovered	O
from	O
f	O
,	O
since	O
any	O
homography	B
of	O
the	O
form	O
˜h	O
(	O
cid:48	O
)	O
=	O
˜h	O
+	O
evt	O
results	O
in	O
the	O
same	O
f	O
matrix	O
.	O
(	O
note	O
that	O
[	O
e	O
]	O
×	O
annihilates	O
any	O
multiple	B
of	O
e.	O
)	O
any	O
one	O
of	O
these	O
valid	O
homographies	O
˜h	O
maps	O
some	O
plane	O
in	O
the	O
scene	O
from	O
one	O
image	B
to	O
the	O
other	O
.	O
it	O
is	O
not	O
possible	O
to	O
tell	O
in	O
advance	O
which	O
one	O
it	O
is	O
without	O
either	O
selecting	O
four	O
or	O
more	O
co-planar	O
correspondences	O
to	O
compute	O
˜h	O
as	O
part	O
of	O
the	O
f	O
estimation	B
process	O
(	O
in	O
a	O
manner	O
analogous	O
to	O
guessing	O
a	O
rotation	O
for	O
e	O
)	O
or	O
mapping	O
all	O
points	B
in	O
one	O
image	B
through	O
˜h	O
and	O
seeing	O
which	O
ones	O
line	O
up	O
with	O
their	O
corresponding	O
locations	O
in	O
the	O
other.7	O
in	O
order	B
to	O
create	O
a	O
projective	B
reconstruction	O
of	O
the	O
scene	O
,	O
we	O
can	O
pick	O
any	O
valid	O
homog-	O
raphy	O
˜h	O
that	O
satisﬁes	O
equation	B
(	O
7.29	O
)	O
.	O
for	O
example	O
,	O
following	O
a	O
technique	O
analogous	O
to	O
equations	B
(	O
7.18–7.24	O
)	O
,	O
we	O
get	O
f	O
=	O
[	O
e	O
]	O
×	O
˜h	O
=	O
szr90◦	O
st	O
˜h	O
=	O
uσv	O
t	O
and	O
hence	O
˜h	O
=	O
u	O
rt	O
90◦	O
ˆσv	O
t	O
,	O
(	O
7.32	O
)	O
(	O
7.33	O
)	O
where	O
ˆσ	O
is	O
the	O
singular	O
value	O
matrix	O
with	O
the	O
smallest	O
value	O
replaced	O
by	O
a	O
reasonable	O
alter-	O
native	O
(	O
say	O
,	O
the	O
middle	O
value	O
)	O
.8	O
we	O
can	O
then	O
form	O
a	O
pair	O
of	O
camera	B
matrices	O
p	O
0	O
=	O
[	O
i|0	O
]	O
and	O
p	O
0	O
=	O
[	O
˜h|e	O
]	O
,	O
(	O
7.34	O
)	O
from	O
which	O
a	O
projective	B
reconstruction	O
of	O
the	O
scene	O
can	O
be	O
computed	O
using	O
triangulation	O
(	O
section	O
7.1	O
)	O
.	O
while	O
the	O
projective	B
reconstruction	O
may	O
not	O
be	O
useful	O
in	O
practice	O
,	O
it	O
can	O
often	O
be	O
upgraded	O
to	O
an	O
afﬁne	B
or	O
metric	O
reconstruction	O
,	O
as	O
detailed	O
below	O
.	O
even	O
without	O
this	O
step	O
,	O
however	O
,	O
the	O
fundamental	O
matrix	O
f	O
can	O
be	O
very	O
useful	O
in	O
ﬁnding	O
additional	O
correspondences	O
,	O
as	O
they	O
must	O
all	O
lie	O
on	O
corresponding	O
epipolar	O
lines	O
,	O
i.e.	O
,	O
any	O
feature	B
x0	O
in	O
image	B
0	O
must	O
have	O
its	O
correspondence	B
lying	O
on	O
the	O
associated	O
epipolar	O
line	O
l1	O
=	O
f	O
x0	O
in	O
image	B
1	O
,	O
assuming	O
that	O
the	O
point	O
motions	O
are	O
due	O
to	O
a	O
rigid	O
transformation	O
.	O
7	O
this	O
process	O
is	O
sometimes	O
referred	O
to	O
as	O
plane	O
plus	O
parallax	O
(	O
section	O
2.1.5	O
)	O
(	O
kumar	O
,	O
anandan	O
,	O
and	O
hanna	O
1994	O
;	O
sawhney	O
1994	O
)	O
.	O
8	O
hartley	O
and	O
zisserman	O
(	O
2004	O
,	O
p.	O
237	O
)	O
recommend	O
using	O
˜h	O
=	O
[	O
e	O
]	O
×f	O
(	O
luong	O
and	O
vi´eville	O
1996	O
)	O
,	O
which	O
places	O
the	O
camera	B
on	O
the	O
plane	O
at	O
inﬁnity	O
.	O
7.2	O
two-frame	B
structure	O
from	O
motion	B
355	O
7.2.2	O
self-calibration	B
the	O
results	O
of	O
structure	B
from	I
motion	I
computation	O
are	O
much	O
more	O
useful	O
(	O
and	O
intelligible	O
)	O
if	O
a	O
metric	O
reconstruction	O
is	O
obtained	O
,	O
i.e.	O
,	O
one	O
in	O
which	O
parallel	O
lines	B
are	O
parallel	O
,	O
orthogonal	O
walls	O
are	O
at	O
right	O
angles	O
,	O
and	O
the	O
reconstructed	O
model	O
is	O
a	O
scaled	O
version	O
of	O
reality	O
.	O
over	O
the	O
years	O
,	O
a	O
large	O
number	O
of	O
self-calibration	B
(	O
or	O
auto-calibration	O
)	O
techniques	O
have	O
been	O
de-	O
veloped	O
for	O
converting	O
a	O
projective	B
reconstruction	O
into	O
a	O
metric	O
one	O
,	O
which	O
is	O
equivalent	O
to	O
recovering	O
the	O
unknown	O
calibration	B
matrices	O
kj	O
associated	O
with	O
each	O
image	B
(	O
hartley	O
and	O
zisserman	O
2004	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
2010	O
)	O
.	O
in	O
situations	O
where	O
certain	O
additional	O
information	O
is	O
known	O
about	O
the	O
scene	O
,	O
different	O
methods	O
may	O
be	O
employed	O
.	O
for	O
example	O
,	O
if	O
there	O
are	O
parallel	O
lines	B
in	O
the	O
scene	O
(	O
usually	O
,	O
having	O
several	O
lines	B
converge	O
on	O
the	O
same	O
vanishing	O
point	O
is	O
good	O
evidence	O
)	O
,	O
three	O
or	O
more	O
vanishing	B
points	I
,	O
which	O
are	O
the	O
images	O
of	O
points	B
at	O
inﬁnity	O
,	O
can	O
be	O
used	O
to	O
establish	O
the	O
ho-	O
mography	O
for	O
the	O
plane	O
at	O
inﬁnity	O
,	O
from	O
which	O
focal	O
lengths	O
and	O
rotations	O
can	O
be	O
recovered	O
.	O
if	O
two	O
or	O
more	O
ﬁnite	O
orthogonal	O
vanishing	O
points	B
have	O
been	O
observed	O
,	O
the	O
single-image	O
cali-	O
bration	O
method	O
based	O
on	O
vanishing	B
points	I
(	O
section	O
6.3.2	O
)	O
can	O
be	O
used	O
instead	O
.	O
in	O
the	O
absence	O
of	O
such	O
external	O
information	O
,	O
it	O
is	O
not	O
possible	O
to	O
recover	O
a	O
fully	O
parameter-	O
ized	O
independent	O
calibration	B
matrix	I
kj	O
for	O
each	O
image	B
from	O
correspondences	O
alone	O
.	O
to	O
see	O
this	O
,	O
consider	O
the	O
set	O
of	O
all	O
camera	B
matrices	O
p	O
j	O
=	O
kj	O
[	O
rj|tj	O
]	O
projecting	O
world	O
coordinates	O
pi	O
=	O
(	O
xi	O
,	O
yi	O
,	O
zi	O
,	O
wi	O
)	O
into	O
screen	O
coordinates	O
xij	O
∼	O
p	O
jpi	O
.	O
now	O
consider	O
transforming	O
the	O
3d	O
scene	O
{	O
pi	O
}	O
through	O
an	O
arbitrary	O
4×	O
4	O
projective	B
transformation	O
˜h	O
,	O
yielding	O
a	O
new	O
model	O
consisting	O
of	O
points	B
p	O
(	O
cid:48	O
)	O
i	O
=	O
˜hpi	O
.	O
post-multiplying	O
each	O
p	O
j	O
matrix	O
by	O
˜h−1	O
still	O
produces	O
the	O
same	O
screen	O
coordinates	O
and	O
a	O
new	O
set	O
calibration	B
matrices	O
can	O
be	O
computed	O
by	O
applying	O
rq	O
decomposition	O
to	O
the	O
new	O
camera	B
matrix	O
p	O
(	O
cid:48	O
)	O
j	O
=	O
p	O
j	O
˜h−1	O
.	O
for	O
this	O
reason	O
,	O
all	O
self-calibration	B
methods	O
assume	O
some	O
restricted	B
form	O
of	O
the	O
calibration	B
matrix	I
,	O
either	O
by	O
setting	O
or	O
equating	O
some	O
of	O
their	O
elements	O
or	O
by	O
assuming	O
that	O
they	O
do	O
not	O
vary	O
over	O
time	O
.	O
while	O
most	O
of	O
the	O
techniques	O
discussed	O
by	O
hartley	O
and	O
zisserman	O
(	O
2004	O
)	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
(	O
2010	O
)	O
require	O
three	O
or	O
more	O
frames	O
,	O
in	O
this	O
section	O
we	O
present	O
a	O
simple	O
technique	O
that	O
can	O
recover	O
the	O
focal	O
lengths	O
(	O
f0	O
,	O
f1	O
)	O
of	O
both	O
images	O
from	O
the	O
fundamental	O
matrix	O
f	O
in	O
a	O
two-frame	B
reconstruction	O
(	O
hartley	O
and	O
zisserman	O
2004	O
,	O
p.	O
456	O
)	O
.	O
to	O
accomplish	O
this	O
,	O
we	O
assume	O
that	O
the	O
camera	B
has	O
zero	O
skew	O
,	O
a	O
known	O
aspect	O
ratio	O
(	O
usu-	O
ally	O
set	O
to	O
1	O
)	O
,	O
and	O
a	O
known	O
optical	O
center	O
,	O
as	O
in	O
equation	B
(	O
2.59	O
)	O
.	O
how	O
reasonable	O
is	O
this	O
assumption	O
in	O
practice	O
?	O
the	O
answer	O
,	O
as	O
with	O
many	O
questions	O
,	O
is	O
“	O
it	O
depends	O
”	O
.	O
if	O
absolute	O
metric	O
accuracy	B
is	O
required	O
,	O
as	O
in	O
photogrammetry	B
applications	O
,	O
it	O
is	O
imperative	O
to	O
pre-calibrate	O
the	O
cameras	O
using	O
one	O
of	O
the	O
techniques	O
from	O
section	O
6.3	O
and	O
to	O
use	O
ground	O
control	O
points	B
to	O
pin	O
down	O
the	O
reconstruction	O
.	O
if	O
instead	O
,	O
we	O
simply	O
wish	O
to	O
reconstruct	O
the	O
world	O
for	O
visualization	O
or	O
image-based	B
rendering	I
applications	O
,	O
as	O
in	O
the	O
photo	O
tourism	O
system	O
of	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
(	O
2006	O
)	O
,	O
this	O
assumption	O
is	O
quite	O
reasonable	O
in	O
practice	O
.	O
356	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
most	O
cameras	O
today	O
have	O
square	O
pixels	O
and	O
an	O
optical	O
center	O
near	O
the	O
middle	O
of	O
the	O
image	B
,	O
and	O
are	O
much	O
more	O
likely	O
to	O
deviate	O
from	O
a	O
simple	O
camera	B
model	O
due	O
to	O
radial	B
distortion	I
(	O
section	O
6.3.5	O
)	O
,	O
which	O
should	O
be	O
compensated	O
for	O
whenever	O
possible	O
.	O
the	O
biggest	O
problems	O
occur	O
when	O
images	O
have	O
been	O
cropped	O
off-center	O
,	O
in	O
which	O
case	O
the	O
optical	O
center	O
will	O
no	O
longer	O
be	O
in	O
the	O
middle	O
,	O
or	O
when	O
perspective	B
pictures	O
have	O
been	O
taken	O
of	O
a	O
different	O
picture	O
,	O
in	O
which	O
case	O
a	O
general	O
camera	B
matrix	O
becomes	O
necessary.9	O
given	O
these	O
caveats	O
,	O
the	O
two-frame	B
focal	O
length	O
estimation	B
algorithm	O
based	O
on	O
the	O
kruppa	O
equations	B
developed	O
by	O
hartley	O
and	O
zisserman	O
(	O
2004	O
,	O
p.	O
456	O
)	O
proceeds	O
as	O
follows	O
.	O
take	O
the	O
left	O
and	O
right	O
singular	O
vectors	O
{	O
u0	O
,	O
u1	O
,	O
v0	O
,	O
v1	O
}	O
of	O
the	O
fundamental	O
matrix	O
f	O
(	O
7.30	O
)	O
and	O
their	O
associated	O
singular	O
values	O
{	O
σ0	O
,	O
σ1	O
)	O
and	O
form	O
the	O
following	O
set	O
of	O
equations	B
:	O
ut	O
1	O
d0u1	O
σ2	O
0vt	O
0	O
d1v0	O
=	O
−	O
ut	O
0	O
d0u1	O
σ0σ1vt	O
0	O
d1v1	O
=	O
ut	O
0	O
d0u0	O
σ2	O
1vt	O
1	O
d1v1	O
,	O
where	O
the	O
two	O
matrices	O
(	O
7.35	O
)	O
(	O
7.36	O
)	O
dj	O
=	O
kjkt	O
j	O
=	O
diag	O
(	O
f	O
2	O
j	O
,	O
f	O
2	O
j	O
,	O
1	O
)	O
=	O
f	O
2	O
j	O
f	O
2	O
j	O
1	O
	O
encode	O
the	O
unknown	O
focal	O
lengths	O
.	O
for	O
simplicity	O
,	O
let	O
us	O
rewrite	O
each	O
of	O
the	O
numerators	O
and	O
denominators	O
in	O
(	O
7.35	O
)	O
as	O
eij0	O
(	O
f	O
2	O
eij1	O
(	O
f	O
2	O
0	O
)	O
=	O
ut	O
1	O
)	O
=	O
σiσjvt	O
i	O
d0uj	O
=	O
aij	O
+	O
bijf	O
2	O
0	O
,	O
i	O
d1vj	O
=	O
cij	O
+	O
dijf	O
2	O
1	O
.	O
(	O
7.37	O
)	O
(	O
7.38	O
)	O
notice	O
that	O
each	O
of	O
these	O
is	O
afﬁne	B
(	O
linear	B
plus	O
constant	O
)	O
in	O
either	O
f	O
2	O
can	O
cross-multiply	O
these	O
equations	B
to	O
obtain	O
quadratic	O
equations	B
in	O
f	O
2	O
be	O
solved	O
.	O
(	O
see	O
also	O
the	O
work	O
by	O
bougnoux	O
(	O
1998	O
)	O
for	O
some	O
alternative	O
formulations	O
.	O
)	O
1	O
.	O
hence	O
,	O
we	O
0	O
or	O
f	O
2	O
j	O
,	O
which	O
can	O
readily	O
an	O
alternative	O
solution	O
technique	O
is	O
to	O
observe	O
that	O
we	O
have	O
a	O
set	O
of	O
three	O
equations	B
related	O
by	O
an	O
unknown	O
scalar	O
λ	O
,	O
i.e.	O
,	O
eij0	O
(	O
f	O
2	O
0	O
)	O
=	O
λeij1	O
(	O
f	O
2	O
1	O
)	O
(	O
7.39	O
)	O
1	O
,	O
λ	O
)	O
and	O
hence	O
(	O
f0	O
,	O
f1	O
)	O
.	O
(	O
richard	O
hartley	O
,	O
personal	O
communication	O
,	O
july	O
2009	O
)	O
.	O
these	O
can	O
readily	O
be	O
solved	O
to	O
yield	O
(	O
f	O
2	O
0	O
,	O
λf	O
2	O
how	O
well	O
does	O
this	O
approach	O
work	O
in	O
practice	O
?	O
there	O
are	O
certain	O
degenerate	O
conﬁgura-	O
tions	O
,	O
such	O
as	O
when	O
there	O
is	O
no	O
rotation	O
or	O
when	O
the	O
optical	O
axes	O
intersect	O
,	O
when	O
it	O
does	O
not	O
work	O
at	O
all	O
.	O
(	O
in	O
such	O
a	O
situation	O
,	O
you	O
can	O
vary	O
the	O
focal	O
lengths	O
of	O
the	O
cameras	O
and	O
obtain	O
9	O
in	O
photo	O
tourism	O
,	O
our	O
system	O
registered	O
photographs	O
of	O
an	O
information	O
sign	O
outside	O
notre	O
dame	O
with	O
real	O
pictures	O
of	O
the	O
cathedral	O
.	O
7.3	O
factorization	B
357	O
a	O
deeper	O
or	O
shallower	O
reconstruction	O
,	O
which	O
is	O
an	O
example	O
of	O
a	O
bas-relief	B
ambiguity	I
(	O
sec-	O
tion	B
7.4.3	O
)	O
.	O
)	O
hartley	O
and	O
zisserman	O
(	O
2004	O
)	O
recommend	O
using	O
techniques	O
based	O
on	O
three	O
or	O
more	O
frames	O
.	O
however	O
,	O
if	O
you	O
ﬁnd	O
two	O
images	O
for	O
which	O
the	O
estimates	O
of	O
(	O
f	O
2	O
1	O
,	O
λ	O
)	O
are	O
well	O
conditioned	O
,	O
they	O
can	O
be	O
used	O
to	O
initialize	O
a	O
more	O
complete	O
bundle	B
adjustment	I
of	O
all	O
the	O
parameters	B
(	O
section	O
7.4	O
)	O
.	O
an	O
alternative	O
,	O
which	O
is	O
often	O
used	O
in	O
systems	O
such	O
as	O
photo	O
tourism	O
,	O
is	O
to	O
use	O
camera	B
exif	O
tags	O
or	O
generic	O
default	O
values	O
to	O
initialize	O
focal	O
length	O
esti-	O
mates	O
and	O
reﬁne	O
them	O
as	O
part	O
of	O
bundle	B
adjustment	I
.	O
0	O
,	O
λf	O
2	O
7.2.3	O
application	O
:	O
view	B
morphing	I
an	O
interesting	O
application	O
of	O
basic	O
two-frame	B
structure	O
from	O
motion	B
is	O
view	B
morphing	I
(	O
also	O
known	O
as	O
view	B
interpolation	I
,	O
see	O
section	O
13.1	O
)	O
,	O
which	O
can	O
be	O
used	O
to	O
generate	O
a	O
smooth	O
3d	O
animation	O
from	O
one	O
view	O
of	O
a	O
3d	O
scene	O
to	O
another	O
(	O
chen	O
and	O
williams	O
1993	O
;	O
seitz	O
and	O
dyer	O
1996	O
)	O
.	O
to	O
create	O
such	O
a	O
transition	O
,	O
you	O
must	O
ﬁrst	O
smoothly	O
interpolate	O
the	O
camera	B
matrices	O
,	O
i.e.	O
,	O
the	O
camera	B
positions	O
,	O
orientations	O
,	O
and	O
focal	O
lengths	O
.	O
while	O
simple	O
linear	B
interpolation	O
can	O
be	O
used	O
(	O
representing	O
rotations	O
as	O
quaternions	B
(	O
section	O
2.1.4	O
)	O
)	O
,	O
a	O
more	O
pleasing	O
effect	O
is	O
obtained	O
by	O
easing	O
in	O
and	O
easing	O
out	O
the	O
camera	B
parameters	O
,	O
e.g.	O
,	O
using	O
a	O
raised	O
cosine	O
,	O
as	O
well	O
as	O
moving	O
the	O
camera	B
along	O
a	O
more	O
circular	O
trajectory	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
to	O
generate	O
in-between	O
frames	O
,	O
either	O
a	O
full	O
set	O
of	O
3d	O
correspondences	O
needs	O
to	O
be	O
es-	O
tablished	O
(	O
section	O
11.3	O
)	O
or	O
3d	O
models	O
(	O
proxies	O
)	O
must	O
be	O
created	O
for	O
each	O
reference	O
view	O
.	O
section	O
13.1	O
describes	O
several	O
widely	O
used	O
approaches	O
to	O
this	O
problem	O
.	O
one	O
of	O
the	O
simplest	O
is	O
to	O
just	O
triangulate	O
the	O
set	O
of	O
matched	O
feature	B
points	O
in	O
each	O
image	B
,	O
e.g.	O
,	O
using	O
delaunay	O
triangulation	B
.	O
as	O
the	O
3d	O
points	B
are	O
re-projected	O
into	O
their	O
intermediate	O
views	O
,	O
pixels	O
can	O
be	O
mapped	O
from	O
their	O
original	O
source	O
images	O
to	O
their	O
new	O
views	O
using	O
afﬁne	O
or	O
projective	B
map-	O
ping	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
.	O
the	O
ﬁnal	O
image	B
is	O
then	O
composited	O
using	O
a	O
linear	B
blend	O
of	O
the	O
two	O
reference	O
images	O
,	O
as	O
with	O
usual	O
morphing	B
(	O
section	O
3.6.3	O
)	O
.	O
7.3	O
factorization	B
when	O
processing	O
video	B
sequences	O
,	O
we	O
often	O
get	O
extended	O
feature	B
tracks	I
(	O
section	O
4.1.4	O
)	O
from	O
which	O
it	O
is	O
possible	O
to	O
recover	O
the	O
structure	O
and	O
motion	B
using	O
a	O
process	O
called	O
factorization	B
.	O
consider	O
the	O
tracks	O
generated	O
by	O
a	O
rotating	O
ping	O
pong	O
ball	O
,	O
which	O
has	O
been	O
marked	O
with	O
dots	O
to	O
make	O
its	O
shape	O
and	O
motion	B
more	O
discernable	O
(	O
figure	O
7.5	O
)	O
.	O
we	O
can	O
readily	O
see	O
from	O
the	O
shape	O
of	O
the	O
tracks	O
that	O
the	O
moving	O
object	O
must	O
be	O
a	O
sphere	O
,	O
but	O
how	O
can	O
we	O
infer	O
this	O
mathematically	O
?	O
it	O
turns	O
out	O
that	O
,	O
under	O
orthography	O
or	O
related	O
models	O
we	O
discuss	O
below	O
,	O
the	O
shape	O
and	O
motion	B
can	O
be	O
recovered	O
simultaneously	O
using	O
a	O
singular	O
value	O
decomposition	O
(	O
tomasi	O
and	O
358	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
7.5	O
3d	O
reconstruction	O
of	O
a	O
rotating	O
ping	O
pong	O
ball	O
using	O
factorization	O
(	O
tomasi	O
and	O
kanade	O
1992	O
)	O
c	O
(	O
cid:13	O
)	O
1992	O
springer	O
:	O
(	O
a	O
)	O
sample	O
image	B
with	O
tracked	O
features	O
overlaid	O
;	O
(	O
b	O
)	O
sub-	O
sampled	O
feature	B
motion	O
stream	O
;	O
(	O
c	O
)	O
two	O
views	O
of	O
the	O
reconstructed	O
3d	O
model	O
.	O
kanade	O
1992	O
)	O
.	O
consider	O
the	O
orthographic	B
and	O
weak	O
perspective	O
projection	O
models	O
introduced	O
in	O
equations	B
(	O
2.47–2.49	O
)	O
.	O
since	O
the	O
last	O
row	O
is	O
always	O
[	O
0	O
0	O
0	O
1	O
]	O
,	O
there	O
is	O
no	O
perspective	B
division	O
and	O
we	O
can	O
write	O
(	O
7.40	O
)	O
where	O
xji	O
is	O
the	O
location	O
of	O
the	O
ith	O
point	O
in	O
the	O
jth	O
frame	O
,	O
˜p	O
j	O
is	O
the	O
upper	O
2	O
×	O
4	O
portion	O
of	O
the	O
projection	O
matrix	O
p	O
j	O
,	O
and	O
¯pi	O
=	O
(	O
xi	O
,	O
yi	O
,	O
zi	O
,	O
1	O
)	O
is	O
the	O
augmented	O
3d	O
point	O
position.10	O
let	O
us	O
assume	O
(	O
for	O
now	O
)	O
that	O
every	O
point	O
i	O
is	O
visible	O
in	O
every	O
frame	O
j.	O
we	O
can	O
take	O
the	O
xji	O
=	O
˜p	O
j	O
¯pi	O
,	O
centroid	O
(	O
average	O
)	O
of	O
the	O
projected	O
point	O
locations	O
xji	O
in	O
frame	O
j	O
,	O
¯xj	O
=	O
1	O
n	O
(	O
cid:88	O
)	O
i	O
xji	O
=	O
˜p	O
j	O
1	O
n	O
(	O
cid:88	O
)	O
i	O
¯pi	O
=	O
˜p	O
j¯c	O
,	O
(	O
7.41	O
)	O
where	O
¯c	O
=	O
(	O
¯x	O
,	O
¯y	O
,	O
¯z	O
,	O
1	O
)	O
is	O
the	O
augmented	O
3d	O
centroid	O
of	O
the	O
point	O
cloud	O
.	O
since	O
world	O
coordinate	O
frames	O
in	O
structure	B
from	I
motion	I
are	O
always	O
arbitrary	O
,	O
i.e.	O
,	O
we	O
can	O
not	O
recover	O
true	O
3d	O
locations	O
without	O
ground	O
control	O
points	B
(	O
known	O
measurements	O
)	O
,	O
we	O
can	O
place	O
the	O
origin	O
of	O
the	O
world	O
at	O
the	O
centroid	O
of	O
the	O
points	B
,	O
i.e	O
,	O
¯x	O
=	O
¯y	O
=	O
¯z	O
=	O
0	O
,	O
so	O
that	O
¯c	O
=	O
(	O
0	O
,	O
0	O
,	O
0	O
,	O
1	O
)	O
.	O
we	O
see	O
from	O
this	O
that	O
the	O
centroid	O
of	O
the	O
2d	O
points	B
in	O
each	O
frame	O
¯xj	O
directly	O
gives	O
us	O
the	O
last	O
element	O
of	O
˜p	O
j.	O
let	O
˜xji	O
=	O
xji	O
−	O
¯xj	O
be	O
the	O
2d	O
point	O
locations	O
after	O
their	O
image	B
centroid	O
has	O
been	O
sub-	O
tracted	O
.	O
we	O
can	O
now	O
write	O
˜xji	O
=	O
m	O
jpi	O
,	O
(	O
7.42	O
)	O
10	O
in	O
this	O
section	O
,	O
we	O
index	O
the	O
2d	O
point	O
positions	O
as	O
xji	O
instead	O
of	O
xij	O
,	O
since	O
this	O
is	O
the	O
convention	O
adopted	O
by	O
factorization	O
papers	O
(	O
tomasi	O
and	O
kanade	O
1992	O
)	O
and	O
is	O
consistent	O
with	O
the	O
factorization	B
given	O
in	O
(	O
7.43	O
)	O
.	O
7.3	O
factorization	B
359	O
where	O
m	O
j	O
is	O
the	O
upper	O
2	O
×	O
3	O
portion	O
of	O
the	O
projection	O
matrix	O
p	O
j	O
and	O
pi	O
=	O
(	O
xi	O
,	O
yi	O
,	O
zi	O
)	O
.	O
we	O
can	O
concatenate	O
all	O
of	O
these	O
measurement	O
equations	B
into	O
one	O
large	O
matrix	O
=	O
	O
m	O
1	O
...	O
m	O
j	O
...	O
m	O
m	O
	O
	O
(	O
cid:104	O
)	O
p1	O
···	O
pi	O
···	O
pn	O
(	O
cid:105	O
)	O
=	O
ˆm	O
ˆs	O
.	O
(	O
7.43	O
)	O
ˆx	O
=	O
	O
···	O
˜x1n	O
˜x11	O
···	O
˜x1i	O
...	O
...	O
...	O
···	O
˜xjn	O
˜xj1	O
···	O
˜xji	O
...	O
...	O
...	O
˜xm	O
1	O
···	O
˜xm	O
i	O
···	O
˜xm	O
n	O
ˆx	O
is	O
called	O
the	O
measurement	O
matrix	O
and	O
ˆm	O
and	O
(	O
ˆs	O
are	O
the	O
motion	B
)	O
and	O
structure	O
matrices	O
,	O
respectively	O
(	O
tomasi	O
and	O
kanade	O
1992	O
)	O
.	O
because	O
the	O
motion	B
matrix	O
ˆm	O
is	O
2m	O
×	O
3	O
and	O
the	O
structure	O
matrix	O
ˆs	O
is	O
3	O
×	O
n	O
,	O
an	O
svd	O
applied	O
to	O
ˆx	O
has	O
only	O
three	O
non-zero	O
singular	O
values	O
.	O
in	O
the	O
case	O
where	O
the	O
measurements	O
in	O
ˆx	O
are	O
noisy	O
,	O
svd	O
returns	O
the	O
rank-three	O
factorization	B
of	O
ˆx	O
that	O
is	O
the	O
closest	O
to	O
ˆx	O
in	O
a	O
least	B
squares	I
sense	O
(	O
tomasi	O
and	O
kanade	O
1992	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
it	O
would	O
be	O
nice	O
if	O
the	O
svd	O
of	O
ˆx	O
=	O
uσv	O
t	O
directly	O
returned	O
the	O
matrices	O
ˆm	O
and	O
ˆs	O
,	O
but	O
it	O
does	O
not	O
.	O
instead	O
,	O
we	O
can	O
write	O
the	O
relationship	O
ˆx	O
=	O
uσv	O
t	O
=	O
[	O
u	O
q	O
]	O
[	O
q−1σv	O
t	O
]	O
(	O
7.44	O
)	O
and	O
set	O
ˆm	O
=	O
u	O
q	O
and	O
ˆs	O
=	O
q−1σv	O
t	O
.11	O
how	O
can	O
we	O
recover	O
the	O
values	O
of	O
the	O
3×	O
3	O
matrix	O
q	O
?	O
this	O
depends	O
on	O
the	O
motion	B
model	O
being	O
used	O
.	O
in	O
the	O
case	O
of	O
orthographic	B
projection	O
(	O
2.47	O
)	O
,	O
the	O
entries	O
in	O
m	O
j	O
are	O
the	O
ﬁrst	O
two	O
rows	O
of	O
rotation	O
matrices	O
rj	O
,	O
so	O
we	O
have	O
mj0	O
·	O
mj0	O
=	O
u2jqqt	O
ut	O
2j	O
mj0	O
·	O
mj1	O
=	O
u2jqqt	O
ut	O
mj1	O
·	O
mj1	O
=	O
u2j+1qqt	O
ut	O
=	O
1	O
,	O
=	O
0	O
,	O
2j+1	O
=	O
1	O
,	O
2j+1	O
(	O
7.45	O
)	O
where	O
uk	O
are	O
the	O
3	O
×	O
1	O
rows	O
of	O
the	O
matrix	O
u.	O
this	O
gives	O
us	O
a	O
large	O
set	O
of	O
equations	B
for	O
the	O
entries	O
in	O
the	O
matrix	O
qqt	O
,	O
from	O
which	O
the	O
matrix	O
q	O
can	O
be	O
recovered	O
using	O
a	O
matrix	O
square	O
root	O
(	O
appendix	O
a.1.4	O
)	O
.	O
if	O
we	O
have	O
scaled	O
orthography	O
(	O
2.48	O
)	O
,	O
i.e.	O
,	O
m	O
j	O
=	O
sjrj	O
,	O
the	O
ﬁrst	O
and	O
third	O
equations	B
are	O
equal	O
to	O
sj	O
and	O
can	O
be	O
set	O
equal	O
to	O
each	O
other	O
.	O
note	O
that	O
even	O
once	O
q	O
has	O
been	O
recovered	O
,	O
there	O
still	O
exists	O
a	O
bas-relief	B
ambiguity	I
,	O
i.e.	O
,	O
we	O
can	O
never	O
be	O
sure	O
if	O
the	O
object	O
is	O
rotating	O
left	O
to	O
right	O
or	O
if	O
its	O
depth	O
reversed	O
version	O
is	O
moving	O
the	O
other	O
way	O
.	O
(	O
this	O
can	O
be	O
seen	O
in	O
the	O
classic	O
rotating	O
necker	O
cube	O
visual	O
illusion	O
.	O
)	O
11	O
tomasi	O
and	O
kanade	O
(	O
1992	O
)	O
ﬁrst	O
take	O
the	O
square	B
root	I
of	O
σ	O
and	O
distribute	O
this	O
to	O
u	O
and	O
v	O
,	O
but	O
there	O
is	O
no	O
particular	O
reason	O
to	O
do	O
this	O
.	O
360	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
additional	O
cues	O
,	O
such	O
as	O
the	O
appearance	O
and	O
disappearance	O
of	O
points	B
,	O
or	O
perspective	B
effects	O
,	O
both	O
of	O
which	O
are	O
discussed	O
below	O
,	O
can	O
be	O
used	O
to	O
remove	O
this	O
ambiguity	O
.	O
for	O
motion	O
models	O
other	O
than	O
pure	O
orthography	O
,	O
e.g.	O
,	O
for	O
scaled	O
orthography	O
or	O
para-	O
perspective	B
,	O
the	O
approach	O
above	O
must	O
be	O
extended	O
in	O
the	O
appropriate	O
manner	O
.	O
such	O
tech-	O
niques	O
are	O
relatively	O
straightforward	O
to	O
derive	O
from	O
ﬁrst	O
principles	O
;	O
more	O
details	O
can	O
be	O
found	O
in	O
papers	O
that	O
extend	O
the	O
basic	O
factorization	B
approach	O
to	O
these	O
more	O
ﬂexible	O
models	O
(	O
poel-	O
man	O
and	O
kanade	O
1997	O
)	O
.	O
additional	O
extensions	O
of	O
the	O
original	O
factorization	B
algorithm	O
include	O
multi-body	O
rigid	O
motion	O
(	O
costeira	O
and	O
kanade	O
1995	O
)	O
,	O
sequential	O
updates	O
to	O
the	O
factorization	B
(	O
morita	O
and	O
kanade	O
1997	O
)	O
,	O
the	O
addition	O
of	O
lines	B
and	O
planes	B
(	O
morris	O
and	O
kanade	O
1998	O
)	O
,	O
and	O
re-scaling	O
the	O
measurements	O
to	O
incorporate	O
individual	O
location	O
uncertainties	O
(	O
anandan	O
and	O
irani	O
2002	O
)	O
.	O
a	O
disadvantage	O
of	O
factorization	B
approaches	O
is	O
that	O
they	O
require	O
a	O
complete	O
set	O
of	O
tracks	O
,	O
i.e.	O
,	O
each	O
point	O
must	O
be	O
visible	O
in	O
each	O
frame	O
,	O
in	O
order	B
for	O
the	O
factorization	B
approach	O
to	O
work	O
.	O
tomasi	O
and	O
kanade	O
(	O
1992	O
)	O
deal	O
with	O
this	O
problem	O
by	O
ﬁrst	O
applying	O
factorization	B
to	O
smaller	O
denser	O
subsets	O
and	O
then	O
using	O
known	O
camera	B
(	O
motion	B
)	O
or	O
point	O
(	O
structure	O
)	O
estimates	O
to	O
hallu-	O
cinate	O
additional	O
missing	O
values	O
,	O
which	O
allows	O
them	O
to	O
incrementally	O
incorporate	O
more	O
fea-	O
tures	O
and	O
cameras	O
.	O
huynh	O
,	O
hartley	O
,	O
and	O
heyden	O
(	O
2003	O
)	O
extend	O
this	O
approach	O
to	O
view	O
missing	O
data	O
as	O
special	O
cases	O
of	O
outliers	O
.	O
buchanan	O
and	O
fitzgibbon	O
(	O
2005	O
)	O
develop	O
fast	O
iterative	O
al-	O
gorithms	O
for	O
performing	O
large	O
matrix	O
factorizations	O
with	O
missing	O
data	O
.	O
the	O
general	O
topic	O
of	O
principal	O
component	O
analysis	O
(	O
pca	O
)	O
with	O
missing	O
data	O
also	O
appears	O
in	O
other	O
computer	O
vision	O
problems	O
(	O
shum	O
,	O
ikeuchi	O
,	O
and	O
reddy	O
1995	O
;	O
de	O
la	O
torre	O
and	O
black	O
2003	O
;	O
gross	O
,	O
matthews	O
,	O
and	O
baker	O
2006	O
;	O
torresani	O
,	O
hertzmann	O
,	O
and	O
bregler	O
2008	O
;	O
vidal	O
,	O
ma	O
,	O
and	O
sastry	O
2010	O
)	O
.	O
7.3.1	O
perspective	B
and	O
projective	B
factorization	I
another	O
disadvantage	O
of	O
regular	O
factorization	B
is	O
that	O
it	O
can	O
not	O
deal	O
with	O
perspective	O
cameras	O
.	O
one	O
way	O
to	O
get	O
around	O
this	O
problem	O
is	O
to	O
perform	O
an	O
initial	O
afﬁne	B
(	O
e.g.	O
,	O
orthographic	B
)	O
recon-	O
struction	O
and	O
to	O
then	O
correct	O
for	O
the	O
perspective	B
effects	O
in	O
an	O
iterative	B
manner	O
(	O
christy	O
and	O
horaud	O
1996	O
)	O
.	O
observe	O
that	O
the	O
object-centered	B
projection	O
model	O
(	O
2.76	O
)	O
rxj	O
·	O
pi	O
+	O
txj	O
1	O
+	O
ηjrzj	O
·	O
pi	O
ryj	O
·	O
pi	O
+	O
tyj	O
1	O
+	O
ηjrzj	O
·	O
pi	O
xji	O
=	O
sj	O
yji	O
=	O
sj	O
(	O
7.46	O
)	O
(	O
7.47	O
)	O
differs	O
from	O
the	O
scaled	O
orthographic	O
projection	O
model	O
(	O
7.40	O
)	O
by	O
the	O
inclusion	O
of	O
the	O
denomi-	O
nator	O
terms	O
(	O
1	O
+	O
ηjrzj	O
·	O
pi	O
)	O
.12	O
12	O
assuming	O
that	O
the	O
optical	O
center	O
(	O
cx	O
,	O
cy	O
)	O
lies	O
at	O
(	O
0	O
,	O
0	O
)	O
and	O
that	O
pixels	O
are	O
square	O
.	O
7.3	O
factorization	B
361	O
if	O
we	O
knew	O
the	O
correct	O
values	O
of	O
ηj	O
=	O
t−1	O
zj	O
and	O
the	O
structure	O
and	O
motion	B
parameters	O
rj	O
and	O
pi	O
,	O
we	O
could	O
cross-multiply	O
the	O
left	O
hand	O
side	O
(	O
visible	O
point	O
measurements	O
xji	O
and	O
yji	O
)	O
by	O
the	O
denominator	O
and	O
get	O
corrected	O
values	O
,	O
for	O
which	O
the	O
bilinear	B
projection	O
model	O
(	O
7.40	O
)	O
is	O
exact	O
.	O
in	O
practice	O
,	O
after	O
an	O
initial	O
reconstruction	O
,	O
the	O
values	O
of	O
ηj	O
can	O
be	O
estimated	O
independently	O
for	O
each	O
frame	O
by	O
comparing	O
reconstructed	O
and	O
sensed	O
point	O
positions	O
.	O
(	O
the	O
third	O
row	O
of	O
the	O
rotation	O
matrix	O
rzj	O
is	O
always	O
available	O
as	O
the	O
cross-product	O
of	O
the	O
ﬁrst	O
two	O
rows	O
.	O
)	O
note	O
that	O
since	O
the	O
ηj	O
are	O
determined	O
from	O
the	O
image	B
measurements	O
,	O
the	O
cameras	O
do	O
not	O
have	O
to	O
be	O
pre-calibrated	O
,	O
i.e.	O
,	O
their	O
focal	O
lengths	O
can	O
be	O
recovered	O
from	O
fj	O
=	O
sj/ηj	O
.	O
once	O
the	O
ηj	O
have	O
been	O
estimated	O
,	O
the	O
feature	B
locations	O
can	O
then	O
be	O
corrected	O
before	O
apply-	O
ing	O
another	O
round	O
of	O
factorization	B
.	O
note	O
that	O
because	O
of	O
the	O
initial	O
depth	O
reversal	O
ambiguity	O
,	O
both	O
reconstructions	O
have	O
to	O
be	O
tried	O
while	O
calculating	O
ηj	O
.	O
(	O
the	O
incorrect	O
reconstruction	O
will	O
result	O
in	O
a	O
negative	O
ηj	O
,	O
which	O
is	O
not	O
physically	O
meaningful	O
.	O
)	O
christy	O
and	O
horaud	O
(	O
1996	O
)	O
report	O
that	O
their	O
algorithm	B
usually	O
converges	O
in	O
three	O
to	O
ﬁve	O
iterations	O
,	O
with	O
the	O
majority	O
of	O
the	O
time	O
spent	O
in	O
the	O
svd	O
computation	O
.	O
an	O
alternative	O
approach	O
,	O
which	O
does	O
not	O
assume	O
partially	O
calibrated	O
cameras	O
(	O
known	O
op-	O
tical	O
center	O
,	O
square	O
pixels	O
,	O
and	O
zero	O
skew	O
)	O
is	O
to	O
perform	O
a	O
fully	O
projective	B
factorization	I
(	O
sturm	O
and	O
triggs	O
1996	O
;	O
triggs	O
1996	O
)	O
.	O
in	O
this	O
case	O
,	O
the	O
inclusion	O
of	O
the	O
third	O
row	O
of	O
the	O
camera	B
matrix	O
in	O
(	O
7.40	O
)	O
is	O
equivalent	O
to	O
multiplying	O
each	O
reconstructed	O
measurement	O
xji	O
=	O
m	O
jpi	O
by	O
its	O
inverse	B
(	O
projective	B
)	O
depth	O
ηji	O
=	O
d−1	O
ji	O
=	O
1/	O
(	O
p	O
j2pi	O
)	O
or	O
,	O
equivalently	O
,	O
multiplying	O
each	O
measured	O
position	O
by	O
its	O
projective	B
depth	O
dji	O
,	O
=	O
ˆm	O
ˆs	O
.	O
(	O
7.48	O
)	O
in	O
the	O
original	O
paper	O
by	O
sturm	O
and	O
triggs	O
(	O
1996	O
)	O
,	O
the	O
projective	B
depths	O
dji	O
are	O
obtained	O
from	O
two-frame	B
reconstructions	O
,	O
while	O
in	O
later	O
work	O
(	O
triggs	O
1996	O
;	O
oliensis	O
and	O
hartley	O
2007	O
)	O
,	O
they	O
are	O
initialized	O
to	O
dji	O
=	O
1	O
and	O
updated	O
after	O
each	O
iteration	O
.	O
oliensis	O
and	O
hartley	O
(	O
2007	O
)	O
present	O
an	O
update	O
formula	O
that	O
is	O
guaranteed	O
to	O
converge	O
to	O
a	O
ﬁxed	O
point	O
.	O
none	O
of	O
these	O
authors	O
suggest	O
actually	O
estimating	O
the	O
third	O
row	O
of	O
p	O
j	O
as	O
part	O
of	O
the	O
projective	B
depth	O
computations	O
.	O
in	O
any	O
case	O
,	O
it	O
is	O
unclear	O
when	O
a	O
fully	O
projective	B
reconstruction	O
would	O
be	O
preferable	O
to	O
a	O
partially	O
calibrated	O
one	O
,	O
especially	O
if	O
they	O
are	O
being	O
used	O
to	O
initialize	O
a	O
full	O
bundle	B
adjustment	I
of	O
all	O
the	O
parameters	B
.	O
one	O
of	O
the	O
attractions	O
of	O
factorization	B
methods	O
is	O
that	O
they	O
provide	O
a	O
“	O
closed	O
form	O
”	O
(	O
some-	O
times	O
called	O
a	O
“	O
linear	B
”	O
)	O
method	O
to	O
initialize	O
iterative	B
techniques	O
such	O
as	O
bundle	B
adjustment	I
.	O
an	O
alternative	O
initialization	B
technique	O
is	O
to	O
estimate	O
the	O
homographies	O
corresponding	O
to	O
some	O
ˆx	O
=	O
	O
d11	O
˜x11	O
...	O
dj1	O
˜xj1	O
...	O
···	O
d1i	O
˜x1i	O
...	O
···	O
dji	O
˜xji	O
...	O
···	O
d1n	O
˜x1n	O
...	O
···	O
djn	O
˜xjn	O
...	O
dm	O
1	O
˜xm	O
1	O
···	O
dm	O
i	O
˜xm	O
i	O
···	O
dm	O
n	O
˜xm	O
n	O
	O
362	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
7.6	O
3d	O
teacup	O
model	O
reconstructed	O
from	O
a	O
240-frame	O
video	B
sequence	O
(	O
tomasi	O
and	O
kanade	O
1992	O
)	O
c	O
(	O
cid:13	O
)	O
1992	O
springer	O
:	O
(	O
a	O
)	O
ﬁrst	O
frame	O
of	O
video	B
;	O
(	O
b	O
)	O
last	O
frame	O
of	O
video	B
;	O
(	O
c	O
)	O
side	O
view	O
of	O
3d	O
model	O
;	O
(	O
d	O
)	O
top	O
view	O
of	O
3d	O
model	O
.	O
common	O
plane	O
seen	O
by	O
all	O
the	O
cameras	O
(	O
rother	O
and	O
carlsson	O
2002	O
)	O
.	O
in	O
a	O
calibrated	O
camera	B
setting	O
,	O
this	O
can	O
correspond	O
to	O
estimating	O
consistent	O
rotations	O
for	O
all	O
of	O
the	O
cameras	O
,	O
for	O
ex-	O
ample	O
,	O
using	O
matched	O
vanishing	B
points	I
(	O
antone	O
and	O
teller	O
2002	O
)	O
.	O
once	O
these	O
have	O
been	O
recovered	O
,	O
the	O
camera	B
positions	O
can	O
then	O
be	O
obtained	O
by	O
solving	O
a	O
linear	B
system	O
(	O
antone	O
and	O
teller	O
2002	O
;	O
rother	O
and	O
carlsson	O
2002	O
;	O
rother	O
2003	O
)	O
.	O
7.3.2	O
application	O
:	O
sparse	B
3d	O
model	O
extraction	O
once	O
a	O
multi-view	B
3d	O
reconstruction	O
of	O
the	O
scene	O
has	O
been	O
estimated	O
,	O
it	O
then	O
becomes	O
possi-	O
ble	O
to	O
create	O
a	O
texture-mapped	O
3d	O
model	O
of	O
the	O
object	O
and	O
to	O
look	O
at	O
it	O
from	O
new	O
directions	O
.	O
the	O
ﬁrst	O
step	O
is	O
to	O
create	O
a	O
denser	O
3d	O
model	O
than	O
the	O
sparse	B
point	O
cloud	O
that	O
structure	B
from	I
motion	I
produces	O
.	O
one	O
alternative	O
is	O
to	O
run	O
dense	O
multi-view	O
stereo	B
(	O
sections	O
11.3–	O
11.6	O
)	O
.	O
alternatively	O
,	O
a	O
simpler	O
technique	O
such	O
as	O
3d	O
triangulation	B
can	O
be	O
used	O
,	O
as	O
shown	O
in	O
figure	O
7.6	O
,	O
in	O
which	O
207	O
reconstructed	O
3d	O
points	B
are	O
triangulated	O
to	O
produce	O
a	O
surface	B
mesh	O
.	O
in	O
order	B
to	O
create	O
a	O
more	O
realistic	O
model	O
,	O
a	O
texture	B
map	O
can	O
be	O
extracted	O
for	O
each	O
trian-	O
gle	O
face	B
.	O
the	O
equations	B
to	O
map	O
points	B
on	O
the	O
surface	B
of	O
a	O
3d	O
triangle	O
to	O
a	O
2d	O
image	B
are	O
straightforward	O
:	O
just	O
pass	O
the	O
local	B
2d	O
coordinates	O
on	O
the	O
triangle	O
through	O
the	O
3	O
×	O
4	O
camera	B
projection	O
matrix	O
to	O
obtain	O
a	O
3	O
×	O
3	O
homography	B
(	O
planar	O
perspective	O
projection	O
)	O
.	O
when	O
mul-	O
tiple	O
source	O
images	O
are	O
available	O
,	O
as	O
is	O
usually	O
the	O
case	O
in	O
multi-view	B
reconstruction	O
,	O
either	O
the	O
closest	O
and	O
most	O
fronto-parallel	O
image	B
can	O
be	O
used	O
or	O
multiple	B
images	O
can	O
be	O
blended	O
in	O
to	O
deal	O
with	O
view-dependent	O
foreshortening	O
(	O
wang	O
,	O
kang	O
,	O
szeliski	O
et	O
al	O
.	O
2001	O
)	O
or	O
to	O
obtain	O
super-resolved	O
results	O
(	O
goldluecke	O
and	O
cremers	O
2009	O
)	O
another	O
alternative	O
is	O
to	O
create	O
a	O
sep-	O
arate	O
texture	B
map	O
from	O
each	O
reference	O
camera	B
and	O
to	O
blend	O
between	O
them	O
during	O
rendering	B
,	O
which	O
is	O
known	O
as	O
view-dependent	O
texture	O
mapping	O
(	O
section	O
13.1.1	O
)	O
(	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
1996	O
;	O
debevec	O
,	O
yu	O
,	O
and	O
borshukov	O
1998	O
)	O
.	O
7.4	O
bundle	B
adjustment	I
363	O
figure	O
7.7	O
a	O
set	O
of	O
chained	O
transforms	O
for	O
projecting	O
a	O
3d	O
point	O
pi	O
into	O
a	O
2d	O
measure-	O
ment	O
xij	O
through	O
a	O
series	O
of	O
transformations	O
f	O
(	O
k	O
)	O
,	O
each	O
of	O
which	O
is	O
controlled	O
by	O
its	O
own	O
set	O
of	O
parameters	B
.	O
the	O
dashed	O
lines	B
indicate	O
the	O
ﬂow	O
of	O
information	O
as	O
partial	O
derivatives	O
are	O
computed	O
during	O
a	O
backward	O
pass	O
.	O
the	O
formula	O
for	O
the	O
radial	B
distortion	I
function	O
is	O
f	O
rd	O
(	O
x	O
)	O
=	O
(	O
1	O
+	O
κ1r2	O
+	O
κ2r4	O
)	O
x	O
.	O
7.4	O
bundle	B
adjustment	I
as	O
we	O
have	O
mentioned	O
several	O
times	O
before	O
,	O
the	O
most	O
accurate	O
way	O
to	O
recover	O
structure	O
and	O
motion	B
is	O
to	O
perform	O
robust	B
non-linear	O
minimization	O
of	O
the	O
measurement	O
(	O
re-projection	O
)	O
er-	O
rors	O
,	O
which	O
is	O
commonly	O
known	O
in	O
the	O
photogrammetry	B
(	O
and	O
now	O
computer	O
vision	O
)	O
commu-	O
nities	O
as	O
bundle	O
adjustment.13	O
triggs	O
,	O
mclauchlan	O
,	O
hartley	O
et	O
al	O
.	O
(	O
1999	O
)	O
provide	O
an	O
excellent	O
overview	O
of	O
this	O
topic	O
,	O
including	O
its	O
historical	O
development	O
,	O
pointers	O
to	O
the	O
photogrammetry	B
literature	O
(	O
slama	O
1980	O
;	O
atkinson	O
1996	O
;	O
kraus	O
1997	O
)	O
,	O
and	O
subtle	O
issues	O
with	O
gauge	O
ambigu-	O
ities	O
.	O
the	O
topic	O
is	O
also	O
treated	O
in	O
depth	O
in	O
textbooks	B
and	O
surveys	B
on	O
multi-view	B
geometry	O
(	O
faugeras	O
and	O
luong	O
2001	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
2010	O
)	O
.	O
we	O
have	O
already	O
introduced	O
the	O
elements	O
of	O
bundle	B
adjustment	I
in	O
our	O
discussion	O
on	O
iter-	O
ative	O
pose	O
estimation	B
(	O
section	O
6.2.2	O
)	O
,	O
i.e.	O
,	O
equations	B
(	O
6.42–6.48	O
)	O
and	O
figure	O
6.5.	O
the	O
biggest	O
difference	B
between	O
these	O
formulas	O
and	O
full	O
bundle	B
adjustment	I
is	O
that	O
our	O
feature	B
location	O
mea-	O
surements	O
xij	O
now	O
depend	O
not	O
only	O
on	O
the	O
point	O
(	O
track	O
index	O
)	O
i	O
but	O
also	O
on	O
the	O
camera	B
pose	O
index	O
j	O
,	O
xij	O
=	O
f	O
(	O
pi	O
,	O
rj	O
,	O
cj	O
,	O
kj	O
)	O
,	O
(	O
7.49	O
)	O
and	O
that	O
the	O
3d	O
point	O
positions	O
pi	O
are	O
also	O
being	O
simultaneously	O
updated	O
.	O
in	O
addition	O
,	O
it	O
is	O
common	O
to	O
add	O
a	O
stage	O
for	O
radial	O
distortion	O
parameter	O
estimation	B
(	O
2.78	O
)	O
,	O
f	O
rd	O
(	O
x	O
)	O
=	O
(	O
1	O
+	O
κ1r2	O
+	O
κ2r4	O
)	O
x	O
,	O
(	O
7.50	O
)	O
if	O
the	O
cameras	O
being	O
used	O
have	O
not	O
been	O
pre-calibrated	O
,	O
as	O
shown	O
in	O
figure	O
7.7	O
.	O
13	O
the	O
term	O
”	O
bundle	O
”	O
refers	O
to	O
the	O
bundles	O
of	O
rays	O
connecting	O
camera	B
centers	O
to	O
3d	O
points	B
and	O
the	O
term	O
”	O
adjust-	O
ment	O
”	O
refers	O
to	O
the	O
iterative	B
minimization	O
of	O
re-projection	O
error	O
.	O
alternative	O
terms	O
for	O
this	O
in	O
the	O
vision	O
community	O
include	O
optimal	O
motion	B
estimation	I
(	O
weng	O
,	O
ahuja	O
,	O
and	O
huang	O
1993	O
)	O
and	O
non-linear	B
least	O
squares	O
(	O
appendix	O
a.3	O
)	O
(	O
taylor	O
,	O
kriegman	O
,	O
and	O
anandan	O
1991	O
;	O
szeliski	O
and	O
kang	O
1994	O
)	O
.	O
fc	O
(	O
x	O
)	O
=	O
kxfjfp	O
(	O
x	O
)	O
=	O
p/zfr	O
(	O
x	O
)	O
=	O
rjxqjft	O
(	O
x	O
)	O
=	O
x-cjcjpiy	O
(	O
1	O
)	O
y	O
(	O
2	O
)	O
y	O
(	O
4	O
)	O
frd	O
(	O
x	O
)	O
=	O
...	O
y	O
(	O
3	O
)	O
κjρ	O
(	O
||x-xij||σ	O
)	O
eijσijxij~xij^^	O
364	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
while	O
most	O
of	O
the	O
boxes	O
(	O
transforms	O
)	O
in	O
figure	O
7.7	O
have	O
previously	O
been	O
explained	O
(	O
6.47	O
)	O
,	O
the	O
leftmost	O
box	O
has	O
not	O
.	O
this	O
box	O
performs	O
a	O
robust	B
comparison	O
of	O
the	O
predicted	O
and	O
mea-	O
sured	O
2d	O
locations	O
ˆxij	O
and	O
˜xij	O
after	O
re-scaling	O
by	O
the	O
measurement	O
noise	B
covariance	O
σij	O
.	O
in	O
more	O
detail	O
,	O
this	O
operation	O
can	O
be	O
written	O
as	O
rij	O
=	O
˜xij	O
−	O
ˆxij	O
,	O
ijς−1	O
ij	O
=	O
rt	O
s2	O
ij	O
rij	O
,	O
eij	O
=	O
ˆρ	O
(	O
s2	O
ij	O
)	O
,	O
(	O
7.51	O
)	O
(	O
7.52	O
)	O
(	O
7.53	O
)	O
where	O
ˆρ	O
(	O
r2	O
)	O
=	O
ρ	O
(	O
r	O
)	O
.	O
the	O
corresponding	O
jacobians	O
(	O
partial	O
derivatives	O
)	O
can	O
be	O
written	O
as	O
∂eij	O
∂s2	O
ij	O
∂s2	O
ij	O
∂	O
˜xij	O
=	O
ˆρ	O
(	O
cid:48	O
)	O
(	O
s2	O
ij	O
)	O
,	O
=	O
σ−1	O
ij	O
rij	O
.	O
(	O
7.54	O
)	O
(	O
7.55	O
)	O
the	O
advantage	O
of	O
the	O
chained	O
representation	O
introduced	O
above	O
is	O
that	O
it	O
not	O
only	O
makes	O
the	O
computations	O
of	O
the	O
partial	O
derivatives	O
and	O
jacobians	O
simpler	O
but	O
it	O
can	O
also	O
be	O
adapted	O
to	O
any	O
camera	B
conﬁguration	O
.	O
consider	O
for	O
example	O
a	O
pair	O
of	O
cameras	O
mounted	O
on	O
a	O
robot	O
that	O
is	O
moving	O
around	O
in	O
the	O
world	O
,	O
as	O
shown	O
in	O
figure	O
7.8a	O
.	O
by	O
replacing	O
the	O
rightmost	O
two	O
transformations	O
in	O
figure	O
7.7	O
with	O
the	O
transformations	O
shown	O
in	O
figure	O
7.8b	O
,	O
we	O
can	O
simultaneously	O
recover	O
the	O
position	O
of	O
the	O
robot	O
at	O
each	O
time	O
and	O
the	O
calibration	B
of	O
each	O
camera	B
with	O
respect	O
to	O
the	O
rig	O
,	O
in	O
addition	O
to	O
the	O
3d	O
structure	O
of	O
the	O
world	O
.	O
7.4.1	O
exploiting	O
sparsity	O
large	O
bundle	O
adjustment	O
problems	O
,	O
such	O
as	O
those	O
involving	O
reconstructing	O
3d	O
scenes	O
from	O
thousands	O
of	O
internet	O
photographs	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2008b	O
;	O
agarwal	O
,	O
snavely	O
,	O
simon	O
et	O
al	O
.	O
2009	O
;	O
agarwal	O
,	O
furukawa	O
,	O
snavely	O
et	O
al	O
.	O
2010	O
;	O
snavely	O
,	O
simon	O
,	O
goesele	O
et	O
al	O
.	O
2010	O
)	O
,	O
can	O
require	O
solving	O
non-linear	B
least	O
squares	O
problems	O
with	O
millions	O
of	O
measurements	O
(	O
feature	B
matches	O
)	O
and	O
tens	O
of	O
thousands	O
of	O
unknown	O
parameters	B
(	O
3d	O
point	O
positions	O
and	O
cam-	O
era	O
poses	O
)	O
.	O
unless	O
some	O
care	O
is	O
taken	O
,	O
these	O
kinds	O
of	O
problem	O
can	O
become	O
intractable	O
,	O
since	O
the	O
(	O
direct	B
)	O
solution	O
of	O
dense	O
least	O
squares	O
problems	O
is	O
cubic	B
in	O
the	O
number	O
of	O
unknowns	O
.	O
fortunately	O
,	O
structure	B
from	I
motion	I
is	O
a	O
bipartite	O
problem	O
in	O
structure	O
and	O
motion	B
.	O
each	O
feature	B
point	O
xij	O
in	O
a	O
given	O
image	B
depends	O
on	O
one	O
3d	O
point	O
position	O
pi	O
and	O
one	O
3d	O
camera	B
pose	O
(	O
rj	O
,	O
cj	O
)	O
.	O
this	O
is	O
illustrated	O
in	O
figure	O
7.9a	O
,	O
where	O
each	O
circle	O
(	O
1–9	O
)	O
indicates	O
a	O
3d	O
point	O
,	O
each	O
square	O
(	O
a–d	O
)	O
indicates	O
a	O
camera	B
,	O
and	O
lines	B
(	O
edges	O
)	O
indicate	O
which	O
points	B
are	O
visible	O
in	O
which	O
cameras	O
(	O
2d	O
features	O
)	O
.	O
if	O
the	O
values	O
for	O
all	O
the	O
points	B
are	O
known	O
or	O
ﬁxed	O
,	O
the	O
equations	B
for	O
all	O
the	O
cameras	O
become	O
independent	O
,	O
and	O
vice	O
versa	O
.	O
7.4	O
bundle	B
adjustment	I
365	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
7.8	O
a	O
camera	B
rig	O
and	O
its	O
associated	O
transform	B
chain	O
.	O
(	O
a	O
)	O
as	O
the	O
mobile	O
rig	O
(	O
robot	O
)	O
moves	O
around	O
in	O
the	O
world	O
,	O
its	O
pose	O
with	O
respect	O
to	O
the	O
world	O
at	O
time	O
t	O
is	O
captured	O
by	O
(	O
rr	O
t	O
)	O
.	O
t	O
,	O
cr	O
j	O
)	O
.	O
(	O
b	O
)	O
a	O
3d	O
point	O
with	O
world	O
each	O
camera	B
’	O
s	O
pose	O
with	O
respect	O
to	O
the	O
rig	O
is	O
captured	O
by	O
(	O
rc	O
j	O
,	O
cc	O
coordinates	O
pw	O
i	O
,	O
and	O
then	O
through	O
the	O
rest	O
of	O
the	O
i	O
camera-speciﬁc	O
chain	O
,	O
as	O
shown	O
in	O
figure	O
7.7.	O
is	O
ﬁrst	O
transformed	O
into	O
rig	O
coordinates	O
pr	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
7.9	O
(	O
a	O
)	O
bipartite	O
graph	O
for	O
a	O
toy	O
structure	B
from	I
motion	I
problem	O
and	O
(	O
b	O
)	O
its	O
associated	O
jacobian	O
j	O
and	O
(	O
c	O
)	O
hessian	O
a.	O
numbers	O
indicate	O
3d	O
points	B
and	O
letters	O
indicate	O
cameras	O
.	O
the	O
dashed	O
arcs	O
and	O
light	O
blue	O
squares	O
indicate	O
the	O
ﬁll-in	O
that	O
occurs	O
when	O
the	O
structure	O
(	O
point	O
)	O
variables	O
are	O
eliminated	O
.	O
piwpir	O
(	O
rtr	O
,	O
ctr	O
)	O
(	O
rjc	O
,	O
cjc	O
)	O
yxfr	O
(	O
x	O
)	O
=	O
rjcxqjcft	O
(	O
x	O
)	O
=	O
x-cjccjcy	O
(	O
1	O
)	O
y	O
(	O
2	O
)	O
fr	O
(	O
x	O
)	O
=	O
rtrxqtrft	O
(	O
x	O
)	O
=	O
x-ctrctrpiwy	O
(	O
0	O
)	O
pir…abcd123456789123456789abcd1a1b2a2b3a3b4a4b4c5b5c6b6c7c7d8c8d9c9d123456789abcd123456789abcd	O
366	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
if	O
we	O
order	B
the	O
structure	O
variables	O
before	O
the	O
motion	B
variables	O
in	O
the	O
hessian	O
matrix	O
a	O
(	O
and	O
hence	O
also	O
the	O
right	O
hand	O
side	O
vector	O
b	O
)	O
,	O
we	O
obtain	O
a	O
structure	O
for	O
the	O
hessian	O
shown	O
in	O
figure	O
7.9c.14	O
when	O
such	O
a	O
system	O
is	O
solved	O
using	O
sparse	O
cholesky	O
factorization	B
(	O
see	O
ap-	O
pendix	O
a.4	O
)	O
(	O
bj¨orck	O
1996	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
)	O
,	O
the	O
ﬁll-in	O
occurs	O
in	O
the	O
smaller	O
motion	B
hessian	O
acc	O
(	O
szeliski	O
and	O
kang	O
1994	O
;	O
triggs	O
,	O
mclauchlan	O
,	O
hartley	O
et	O
al	O
.	O
1999	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
lourakis	O
and	O
argyros	O
2009	O
;	O
engels	O
,	O
stew´enius	O
,	O
and	O
nist´er	O
2006	O
)	O
.	O
some	O
re-	O
cent	O
papers	O
by	O
(	O
byr¨od	O
and	O
øastr¨om	O
2009	O
)	O
,	O
jeong	O
,	O
nist´er	O
,	O
steedly	O
et	O
al	O
.	O
(	O
2010	O
)	O
and	O
(	O
agarwal	O
,	O
snavely	O
,	O
seitz	O
et	O
al	O
.	O
2010	O
)	O
explore	O
the	O
use	O
of	O
iterative	B
(	O
conjugate	B
gradient	I
)	O
techniques	O
for	O
the	O
solution	O
of	O
bundle	B
adjustment	I
problems	O
.	O
in	O
more	O
detail	O
,	O
the	O
reduced	B
motion	I
hessian	O
is	O
computed	O
using	O
the	O
schur	O
complement	O
,	O
a	O
(	O
cid:48	O
)	O
cc	O
=	O
acc	O
−	O
at	O
pca−1	O
pp	O
apc	O
,	O
(	O
7.56	O
)	O
where	O
app	O
is	O
the	O
point	O
(	O
structure	O
)	O
hessian	O
(	O
the	O
top	O
left	O
block	O
of	O
figure	O
7.9c	O
)	O
,	O
apc	O
is	O
the	O
point-camera	O
hessian	O
(	O
the	O
top	O
right	O
block	O
)	O
,	O
and	O
acc	O
and	O
a	O
(	O
cid:48	O
)	O
cc	O
are	O
the	O
motion	B
hessians	O
before	O
and	O
after	O
the	O
point	O
variable	O
elimination	O
(	O
the	O
bottom	O
right	O
block	O
of	O
figure	O
7.9c	O
)	O
.	O
notice	O
that	O
a	O
(	O
cid:48	O
)	O
cc	O
has	O
a	O
non-zero	O
entry	O
between	O
two	O
cameras	O
if	O
they	O
see	O
any	O
3d	O
point	O
in	O
common	O
.	O
this	O
is	O
indicated	O
with	O
dashed	O
arcs	O
in	O
figure	O
7.9a	O
and	O
light	O
blue	O
squares	O
in	O
figure	O
7.9c	O
.	O
whenever	O
there	O
are	O
global	B
parameters	O
present	O
in	O
the	O
reconstruction	B
algorithm	I
,	O
such	O
as	O
camera	B
intrinsics	O
that	O
are	O
common	O
to	O
all	O
of	O
the	O
cameras	O
,	O
or	O
camera	B
rig	O
calibration	B
parameters	O
such	O
as	O
those	O
shown	O
in	O
figure	O
7.8	O
,	O
they	O
should	O
be	O
ordered	O
last	O
(	O
placed	O
along	O
the	O
right	O
and	O
bottom	O
edges	O
of	O
a	O
)	O
in	O
order	B
to	O
reduce	O
ﬁll-in	O
.	O
engels	O
,	O
stew´enius	O
,	O
and	O
nist´er	O
(	O
2006	O
)	O
provide	O
a	O
nice	O
recipe	O
for	O
sparse	O
bundle	B
adjustment	I
,	O
including	O
all	O
the	O
steps	O
needed	O
to	O
initialize	O
the	O
iterations	O
,	O
as	O
well	O
as	O
typical	O
computation	O
times	O
for	O
a	O
system	O
that	O
uses	O
a	O
ﬁxed	O
number	O
of	O
backward-looking	O
frames	O
in	O
a	O
real-time	O
setting	O
.	O
they	O
also	O
recommend	O
using	O
homogeneous	O
coordinates	O
for	O
the	O
structure	O
parameters	O
pi	O
,	O
which	O
is	O
a	O
good	O
idea	O
,	O
since	O
it	O
avoids	O
numerical	O
instabilities	O
for	O
points	O
near	O
inﬁnity	O
.	O
bundle	B
adjustment	I
is	O
now	O
the	O
standard	O
method	O
of	O
choice	O
for	O
most	O
structure-from-motion	O
problems	O
and	O
is	O
commonly	O
applied	O
to	O
problems	O
with	O
hundreds	O
of	O
weakly	O
calibrated	O
images	O
and	O
tens	O
of	O
thousands	O
of	O
points	B
,	O
e.g.	O
,	O
in	O
systems	O
such	O
as	O
photosynth	O
.	O
(	O
much	O
larger	O
prob-	O
lems	O
are	O
commonly	O
solved	O
in	O
photogrammetry	B
and	O
aerial	O
imagery	O
,	O
but	O
these	O
are	O
usually	O
care-	O
fully	O
calibrated	O
and	O
make	O
use	O
of	O
surveyed	O
ground	O
control	O
points	B
.	O
)	O
however	O
,	O
as	O
the	O
problems	O
become	O
larger	O
,	O
it	O
becomes	O
impractical	O
to	O
re-solve	O
full	O
bundle	B
adjustment	I
problems	O
at	O
each	O
iteration	O
.	O
one	O
approach	O
to	O
dealing	O
with	O
this	O
problem	O
is	O
to	O
use	O
an	O
incremental	B
algorithm	O
,	O
where	O
new	O
cameras	O
are	O
added	O
over	O
time	O
.	O
(	O
this	O
makes	O
particular	O
sense	O
if	O
the	O
data	O
is	O
being	O
acquired	O
from	O
14	O
this	O
ordering	O
is	O
preferable	O
when	O
there	O
are	O
fewer	O
cameras	O
than	O
3d	O
points	B
,	O
which	O
is	O
the	O
usual	O
case	O
.	O
the	O
exception	O
is	O
when	O
we	O
are	O
tracking	O
a	O
small	O
number	O
of	O
points	B
through	O
many	O
video	B
frames	O
,	O
in	O
which	O
case	O
this	O
ordering	O
should	O
be	O
reversed	O
.	O
7.4	O
bundle	B
adjustment	I
367	O
a	O
video	B
camera	O
or	O
moving	O
vehicle	O
(	O
nist´er	O
,	O
naroditsky	O
,	O
and	O
bergen	O
2006	O
;	O
pollefeys	O
,	O
nist´er	O
,	O
frahm	O
et	O
al	O
.	O
2008	O
)	O
.	O
)	O
a	O
kalman	O
ﬁlter	O
can	O
be	O
used	O
to	O
incrementally	O
update	O
estimates	O
as	O
new	O
information	O
is	O
acquired	O
.	O
unfortunately	O
,	O
such	O
sequential	O
updating	O
is	O
only	O
statistically	O
optimal	O
for	O
linear	O
least	B
squares	I
problems	O
.	O
for	O
non-linear	O
problems	O
such	O
as	O
structure	B
from	I
motion	I
,	O
an	O
extended	O
kalman	O
ﬁlter	O
,	O
which	O
linearizes	O
measurement	O
and	O
update	O
equations	O
around	O
the	O
current	O
estimate	O
,	O
needs	O
to	O
be	O
used	O
(	O
gelb	O
1974	O
;	O
vi´eville	O
and	O
faugeras	O
1990	O
)	O
.	O
to	O
overcome	O
this	O
limitation	O
,	O
several	O
passes	O
can	O
be	O
made	O
through	O
the	O
data	O
(	O
azarbayejani	O
and	O
pentland	O
1995	O
)	O
.	O
because	O
points	B
disappear	O
from	O
view	O
(	O
and	O
old	O
cameras	O
become	O
irrelevant	O
)	O
,	O
a	O
variable	O
state	O
dimension	O
ﬁlter	O
(	O
vsdf	O
)	O
can	O
be	O
used	O
to	O
adjust	O
the	O
set	O
of	O
state	O
variables	O
over	O
time	O
,	O
for	O
example	O
,	O
by	O
keeping	O
only	O
cameras	O
and	O
point	O
tracks	O
seen	O
in	O
the	O
last	O
k	O
frames	O
(	O
mclauchlan	O
2000	O
)	O
.	O
a	O
more	O
ﬂexible	O
approach	O
to	O
using	O
a	O
ﬁxed	O
number	O
of	O
frames	O
is	O
to	O
propagate	O
corrections	O
backwards	O
through	O
points	B
and	O
cameras	O
until	O
the	O
changes	O
on	O
parameters	B
are	O
below	O
a	O
threshold	O
(	O
steedly	O
and	O
essa	O
2001	O
)	O
.	O
variants	O
of	O
these	O
techniques	O
,	O
including	O
methods	O
that	O
use	O
a	O
ﬁxed	O
window	O
for	O
bundle	O
adjustment	O
(	O
engels	O
,	O
stew´enius	O
,	O
and	O
nist´er	O
2006	O
)	O
or	O
select	O
keyframes	O
for	O
doing	O
full	O
bundle	B
adjustment	I
(	O
klein	O
and	O
murray	O
2008	O
)	O
are	O
now	O
commonly	O
used	O
in	O
real-time	O
tracking	O
and	O
augmented-reality	O
applica-	O
tions	O
,	O
as	O
discussed	O
in	O
section	O
7.4.2.	O
when	O
maximum	O
accuracy	B
is	O
required	O
,	O
it	O
is	O
still	O
preferable	O
to	O
perform	O
a	O
full	O
bundle	O
ad-	O
justment	O
over	O
all	O
the	O
frames	O
.	O
in	O
order	B
to	O
control	O
the	O
resulting	O
computational	O
complexity	O
,	O
one	O
approach	O
is	O
to	O
lock	O
together	O
subsets	O
of	O
frames	O
into	O
locally	O
rigid	O
conﬁgurations	O
and	O
to	O
optimize	O
the	O
relative	O
positions	O
of	O
these	O
cluster	O
(	O
steedly	O
,	O
essa	O
,	O
and	O
dellaert	O
2003	O
)	O
.	O
a	O
different	O
approach	O
is	O
to	O
select	O
a	O
smaller	O
number	O
of	O
frames	O
to	O
form	O
a	O
skeletal	B
set	I
that	O
still	O
spans	O
the	O
whole	O
dataset	O
and	O
produces	O
reconstructions	O
of	O
comparable	O
accuracy	B
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2008b	O
)	O
.	O
we	O
describe	O
this	O
latter	O
technique	O
in	O
more	O
detail	O
in	O
section	O
7.4.4	O
,	O
where	O
we	O
discuss	O
applica-	O
tions	O
of	O
structure	B
from	I
motion	I
to	O
large	O
image	O
sets	O
.	O
while	O
bundle	B
adjustment	I
and	O
other	O
robust	B
non-linear	O
least	B
squares	I
techniques	O
are	O
the	O
methods	O
of	O
choice	O
for	O
most	O
structure-from-motion	O
problems	O
,	O
they	O
suffer	O
from	O
initialization	B
problems	O
,	O
i.e.	O
,	O
they	O
can	O
get	O
stuck	O
in	O
local	B
energy	O
minima	O
if	O
not	O
started	O
sufﬁciently	O
close	O
to	O
the	O
global	B
optimum	O
.	O
many	O
systems	O
try	O
to	O
mitigate	O
this	O
by	O
being	O
conservative	O
in	O
what	O
reconstruction	O
they	O
perform	O
early	O
on	O
and	O
which	O
cameras	O
and	O
points	B
they	O
add	O
to	O
the	O
solution	O
(	O
section	O
7.4.4	O
)	O
.	O
an	O
alternative	O
,	O
however	O
,	O
is	O
to	O
re-formulate	O
the	O
problem	O
using	O
a	O
norm	O
that	O
supports	O
the	O
computation	O
of	O
global	B
optima	O
.	O
kahl	O
and	O
hartley	O
(	O
2008	O
)	O
describe	O
techniques	O
for	O
using	O
l∞	O
norms	O
in	O
geometric	B
recon-	O
struction	O
problems	O
.	O
the	O
advantage	O
of	O
such	O
norms	O
is	O
that	O
globally	O
optimal	O
solutions	O
can	O
be	O
efﬁciently	O
computed	O
using	O
second-order	O
cone	O
programming	O
(	O
socp	O
)	O
.	O
the	O
disadvantage	O
is	O
that	O
l∞	O
norms	O
are	O
particularly	O
sensitive	O
to	O
outliers	O
and	O
so	O
must	O
be	O
combined	O
with	O
good	O
outlier	O
rejection	O
techniques	O
before	O
they	O
can	O
be	O
used	O
.	O
368	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
7.4.2	O
application	O
:	O
match	B
move	I
and	O
augmented	B
reality	I
one	O
of	O
the	O
neatest	O
applications	O
of	O
structure	B
from	I
motion	I
is	O
to	O
estimate	O
the	O
3d	O
motion	B
of	O
a	O
video	B
or	O
ﬁlm	O
camera	B
,	O
along	O
with	O
the	O
geometry	O
of	O
a	O
3d	O
scene	O
,	O
in	O
order	B
to	O
superimpose	O
3d	O
graphics	O
or	O
computer-generated	O
images	O
(	O
cgi	O
)	O
on	O
the	O
scene	O
.	O
in	O
the	O
visual	B
effects	I
industry	O
,	O
this	O
is	O
known	O
as	O
the	O
match	B
move	I
problem	O
(	O
roble	O
1999	O
)	O
,	O
since	O
the	O
motion	B
of	O
the	O
synthetic	O
3d	O
camera	B
used	O
to	O
render	O
the	O
graphics	O
must	O
be	O
matched	O
to	O
that	O
of	O
the	O
real-world	O
camera	B
.	O
for	O
very	O
small	O
motions	O
,	O
or	O
motions	O
involving	O
pure	O
camera	O
rotations	O
,	O
one	O
or	O
two	O
tracked	O
points	B
can	O
sufﬁce	O
to	O
compute	O
the	O
necessary	O
visual	O
motion	O
.	O
for	O
planar	O
surfaces	O
moving	O
in	O
3d	O
,	O
four	O
points	B
are	O
needed	O
to	O
compute	O
the	O
homography	B
,	O
which	O
can	O
then	O
be	O
used	O
to	O
insert	O
planar	O
overlays	O
,	O
e.g.	O
,	O
to	O
replace	O
the	O
contents	O
of	O
advertising	O
billboards	O
during	O
sporting	O
events	O
.	O
the	O
general	O
version	O
of	O
this	O
problem	O
requires	O
the	O
estimation	B
of	O
the	O
full	O
3d	O
camera	B
pose	O
along	O
with	O
the	O
focal	O
length	O
(	O
zoom	O
)	O
of	O
the	O
lens	O
and	O
potentially	O
its	O
radial	B
distortion	I
parameters	O
(	O
roble	O
1999	O
)	O
.	O
when	O
the	O
3d	O
structure	O
of	O
the	O
scene	O
is	O
known	O
ahead	O
of	O
time	O
,	O
pose	O
estima-	O
tion	B
techniques	O
such	O
as	O
view	O
correlation	O
(	O
bogart	O
1991	O
)	O
or	O
through-the-lens	O
camera	B
control	O
(	O
gleicher	O
and	O
witkin	O
1992	O
)	O
can	O
be	O
used	O
,	O
as	O
described	O
in	O
section	O
6.2.3.	O
for	O
more	O
complex	O
scenes	O
,	O
it	O
is	O
usually	O
preferable	O
to	O
recover	O
the	O
3d	O
structure	O
simultane-	O
ously	O
with	O
the	O
camera	B
motion	O
using	O
structure-from-motion	O
techniques	O
.	O
the	O
trick	O
with	O
using	O
such	O
techniques	O
is	O
that	O
in	O
order	B
to	O
prevent	O
any	O
visible	O
jitter	O
between	O
the	O
synthetic	O
graph-	O
ics	O
and	O
the	O
actual	O
scene	O
,	O
features	O
must	O
be	O
tracked	O
to	O
very	O
high	O
accuracy	O
and	O
ample	O
feature	B
tracks	I
must	O
be	O
available	O
in	O
the	O
vicinity	O
of	O
the	O
insertion	O
location	O
.	O
some	O
of	O
today	O
’	O
s	O
best	O
known	O
match	B
move	I
software	O
packages	O
,	O
such	O
as	O
the	O
boujou	O
package	O
from	O
2d3,15	O
which	O
won	O
an	O
emmy	O
award	O
in	O
2002	O
,	O
originated	O
in	O
structure-from-motion	O
research	O
in	O
the	O
computer	O
vision	O
commu-	O
nity	O
(	O
fitzgibbon	O
and	O
zisserman	O
1998	O
)	O
.	O
closely	O
related	O
to	O
the	O
match	B
move	I
problem	O
is	O
robotics	O
navigation	O
,	O
where	O
a	O
robot	O
must	O
es-	O
timate	O
its	O
location	O
relative	O
to	O
its	O
environment	O
,	O
while	O
simultaneously	O
avoiding	O
any	O
dangerous	O
obstacles	O
.	O
this	O
problem	O
is	O
often	O
known	O
as	O
simultaneous	O
localization	B
and	I
mapping	I
(	O
slam	O
)	O
(	O
thrun	O
,	O
burgard	O
,	O
and	O
fox	O
2005	O
)	O
or	O
visual	O
odometry	O
(	O
levin	O
and	O
szeliski	O
2004	O
;	O
nist´er	O
,	O
nar-	O
oditsky	O
,	O
and	O
bergen	O
2006	O
;	O
maimone	O
,	O
cheng	O
,	O
and	O
matthies	O
2007	O
)	O
.	O
early	O
versions	O
of	O
such	O
algorithms	O
used	O
range-sensing	O
techniques	O
,	O
such	O
as	O
ultrasound	O
,	O
laser	O
range	O
ﬁnders	O
,	O
or	O
stereo	B
matching	I
,	O
to	O
estimate	O
local	B
3d	O
geometry	O
,	O
which	O
could	O
then	O
be	O
fused	O
into	O
a	O
3d	O
model	O
.	O
newer	O
techniques	O
can	O
perform	O
the	O
same	O
task	O
based	O
purely	O
on	O
visual	O
feature	O
tracking	O
,	O
sometimes	O
not	O
even	O
requiring	O
a	O
stereo	B
camera	O
rig	O
(	O
davison	O
,	O
reid	O
,	O
molton	O
et	O
al	O
.	O
2007	O
)	O
.	O
another	O
closely	O
related	O
application	O
is	O
augmented	B
reality	I
,	O
where	O
3d	O
objects	O
are	O
inserted	O
into	O
a	O
video	B
feed	O
in	O
real	O
time	O
,	O
often	O
to	O
annotate	O
or	O
help	O
users	O
understand	O
a	O
scene	O
(	O
azuma	O
,	O
baillot	O
,	O
behringer	O
et	O
al	O
.	O
2001	O
)	O
.	O
while	O
traditional	O
systems	O
require	O
prior	B
knowledge	O
about	O
the	O
scene	O
or	O
object	O
being	O
visually	O
tracked	O
(	O
rosten	O
and	O
drummond	O
2005	O
)	O
,	O
newer	O
systems	O
can	O
15	O
http	O
:	O
//www.2d3.com/	O
.	O
7.4	O
bundle	B
adjustment	I
369	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
7.10	O
3d	O
augmented	B
reality	I
:	O
(	O
a	O
)	O
darth	O
vader	O
and	O
a	O
horde	O
of	O
ewoks	O
battle	O
it	O
out	O
on	O
a	O
table-top	O
recovered	O
using	O
real-time	O
,	O
keyframe-based	O
structure	B
from	I
motion	I
(	O
klein	O
and	O
murray	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
ieee	O
;	O
(	O
b	O
)	O
a	O
virtual	O
teapot	O
is	O
ﬁxed	O
to	O
the	O
top	O
of	O
a	O
real-world	O
coffee	O
cup	O
,	O
whose	O
pose	O
is	O
re-recognized	O
at	O
each	O
time	O
frame	O
(	O
gordon	O
and	O
lowe	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
springer	O
.	O
simultaneously	O
build	O
up	O
a	O
model	O
of	O
the	O
3d	O
environment	O
and	O
then	O
track	O
it	O
,	O
so	O
that	O
graphics	O
can	O
be	O
superimposed	O
.	O
klein	O
and	O
murray	O
(	O
2007	O
)	O
describe	O
a	O
parallel	O
tracking	O
and	O
mapping	O
(	O
ptam	O
)	O
system	O
,	O
which	O
simultaneously	O
applies	O
full	O
bundle	B
adjustment	I
to	O
keyframes	O
selected	O
from	O
a	O
video	B
stream	O
,	O
while	O
performing	O
robust	B
real-time	O
pose	O
estimation	B
on	O
intermediate	O
frames	O
.	O
fig-	O
ure	O
7.10a	O
shows	O
an	O
example	O
of	O
their	O
system	O
in	O
use	O
.	O
once	O
an	O
initial	O
3d	O
scene	O
has	O
been	O
reconstructed	O
,	O
a	O
dominant	O
plane	O
is	O
estimated	O
(	O
in	O
this	O
case	O
,	O
the	O
table-top	O
)	O
and	O
3d	O
animated	O
characters	O
are	O
virtually	O
inserted	O
.	O
klein	O
and	O
murray	O
(	O
2008	O
)	O
extend	O
their	O
previous	O
system	O
to	O
handle	O
even	O
faster	O
camera	B
motion	O
by	O
adding	O
edge	O
features	O
,	O
which	O
can	O
still	O
be	O
detected	O
even	O
when	O
interest	O
points	B
become	O
too	O
blurred	O
.	O
they	O
also	O
use	O
a	O
direct	B
(	O
intensity-based	B
)	O
rotation	O
estimation	O
algorithm	B
for	O
even	O
faster	O
motions	O
.	O
instead	O
of	O
modeling	B
the	O
whole	O
scene	O
as	O
one	O
rigid	O
reference	O
frame	O
,	O
gordon	O
and	O
lowe	O
(	O
2006	O
)	O
ﬁrst	O
build	O
a	O
3d	O
model	O
of	O
an	O
individual	O
object	O
using	O
feature	O
matching	B
and	O
structure	B
from	I
motion	I
.	O
once	O
the	O
system	O
has	O
been	O
initialized	O
,	O
for	O
every	O
new	O
frame	O
,	O
they	O
ﬁnd	O
the	O
object	O
and	O
its	O
pose	O
using	O
a	O
3d	O
instance	B
recognition	O
algorithm	B
,	O
and	O
then	O
superimpose	O
a	O
graphical	O
object	O
onto	O
that	O
model	O
,	O
as	O
shown	O
in	O
figure	O
7.10b	O
.	O
while	O
reliably	O
tracking	O
such	O
objects	O
and	O
environments	O
is	O
now	O
a	O
well-solved	O
problem	O
,	O
determining	O
which	O
pixels	O
should	O
be	O
occluded	O
by	O
foreground	O
scene	O
elements	O
still	O
remains	O
an	O
open	O
problem	O
(	O
chuang	O
,	O
agarwala	O
,	O
curless	O
et	O
al	O
.	O
2002	O
;	O
wang	O
and	O
cohen	O
2007a	O
)	O
.	O
370	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
7.4.3	O
uncertainty	B
and	O
ambiguities	O
because	O
structure	B
from	I
motion	I
involves	O
the	O
estimation	B
of	O
so	O
many	O
highly	O
coupled	O
parameters	B
,	O
often	O
with	O
no	O
known	O
“	O
ground	O
truth	O
”	O
components	O
,	O
the	O
estimates	O
produced	O
by	O
structure	O
from	O
motion	B
algorithms	O
can	O
often	O
exhibit	O
large	O
amounts	O
of	O
uncertainty	B
(	O
szeliski	O
and	O
kang	O
1997	O
)	O
.	O
an	O
example	O
of	O
this	O
is	O
the	O
classic	O
bas-relief	B
ambiguity	I
,	O
which	O
makes	O
it	O
hard	O
to	O
simultaneously	O
estimate	O
the	O
3d	O
depth	O
of	O
a	O
scene	O
and	O
the	O
amount	O
of	O
camera	B
motion	O
(	O
oliensis	O
2005	O
)	O
.16	O
as	O
mentioned	O
before	O
,	O
a	O
unique	O
coordinate	O
frame	O
and	O
scale	O
for	O
a	O
reconstructed	O
scene	O
can-	O
not	O
be	O
recovered	O
from	O
monocular	O
visual	O
measurements	O
alone	O
.	O
(	O
when	O
a	O
stereo	B
rig	O
is	O
used	O
,	O
the	O
scale	O
can	O
be	O
recovered	O
if	O
we	O
know	O
the	O
distance	O
(	O
baseline	O
)	O
between	O
the	O
cameras	O
.	O
)	O
this	O
seven-degree-of-freedom	O
gauge	O
ambiguity	O
makes	O
it	O
tricky	O
to	O
compute	O
the	O
covariance	O
matrix	O
associated	O
with	O
a	O
3d	O
reconstruction	O
(	O
triggs	O
,	O
mclauchlan	O
,	O
hartley	O
et	O
al	O
.	O
1999	O
;	O
kanatani	O
and	O
morris	O
2001	O
)	O
.	O
a	O
simple	O
way	O
to	O
compute	O
a	O
covariance	O
matrix	O
that	O
ignores	O
the	O
gauge	O
freedom	O
(	O
indeterminacy	O
)	O
is	O
to	O
throw	O
away	O
the	O
seven	O
smallest	O
eigenvalues	B
of	O
the	O
information	O
matrix	O
(	O
in-	O
verse	O
covariance	O
)	O
,	O
whose	O
values	O
are	O
equivalent	O
to	O
the	O
problem	O
hessian	O
a	O
up	O
to	O
noise	B
scaling	O
(	O
see	O
section	O
6.1.4	O
and	O
appendix	O
b.6	O
)	O
.	O
after	O
we	O
do	O
this	O
,	O
the	O
resulting	O
matrix	O
can	O
be	O
inverted	O
to	O
obtain	O
an	O
estimate	O
of	O
the	O
parameter	O
covariance	O
.	O
szeliski	O
and	O
kang	O
(	O
1997	O
)	O
use	O
this	O
approach	O
to	O
visualize	O
the	O
largest	O
directions	O
of	O
variation	O
in	O
typical	O
structure	B
from	I
motion	I
problems	O
.	O
not	O
surprisingly	O
,	O
they	O
ﬁnd	O
that	O
(	O
ignoring	O
the	O
gauge	O
freedoms	O
)	O
,	O
the	O
greatest	O
uncertainties	O
for	O
problems	O
such	O
as	O
observing	O
an	O
object	O
from	O
a	O
small	O
number	O
of	O
nearby	O
viewpoints	O
are	O
in	O
the	O
depths	O
of	O
the	O
3d	O
structure	O
relative	O
to	O
the	O
extent	O
of	O
the	O
camera	B
motion.17	O
it	O
is	O
also	O
possible	O
to	O
estimate	O
local	B
or	O
marginal	O
uncertainties	O
for	O
individual	O
parameters	B
,	O
which	O
corresponds	O
simply	O
to	O
taking	O
block	O
sub-matrices	O
from	O
the	O
full	O
covariance	O
matrix	O
.	O
un-	O
der	O
certain	O
conditions	O
,	O
such	O
as	O
when	O
the	O
camera	B
poses	O
are	O
relatively	O
certain	O
compared	O
to	O
3d	O
point	O
locations	O
,	O
such	O
uncertainty	B
estimates	O
can	O
be	O
meaningful	O
.	O
however	O
,	O
in	O
many	O
cases	O
,	O
indi-	O
vidual	O
uncertainty	B
measures	O
can	O
mask	B
the	O
extent	O
to	O
which	O
reconstruction	O
errors	O
are	O
correlated	O
,	O
which	O
is	O
why	O
looking	O
at	O
the	O
ﬁrst	O
few	O
modes	O
of	O
greatest	O
joint	B
variation	O
can	O
be	O
helpful	O
.	O
the	O
other	O
way	O
in	O
which	O
gauge	O
ambiguities	O
affect	O
structure	B
from	I
motion	I
and	O
,	O
in	O
particular	O
,	O
bundle	B
adjustment	I
is	O
that	O
they	O
make	O
the	O
system	O
hessian	O
matrix	O
a	O
rank-deﬁcient	B
and	O
hence	O
impossible	O
to	O
invert	O
.	O
a	O
number	O
of	O
techniques	O
have	O
been	O
proposed	O
to	O
mitigate	O
this	O
problem	O
(	O
triggs	O
,	O
mclauchlan	O
,	O
hartley	O
et	O
al	O
.	O
1999	O
;	O
bartoli	O
2003	O
)	O
.	O
in	O
practice	O
,	O
however	O
,	O
it	O
appears	O
that	O
simply	O
adding	O
a	O
small	O
amount	O
of	O
the	O
hessian	O
diagonal	O
λdiag	O
(	O
a	O
)	O
to	O
the	O
hessian	O
a	O
itself	O
,	O
as	O
is	O
done	O
in	O
the	O
levenberg–marquardt	O
non-linear	B
least	O
squares	O
algorithm	B
(	O
appendix	O
a.3	O
)	O
,	O
usually	O
16	O
bas-relief	O
refers	O
to	O
a	O
kind	O
of	O
sculpture	O
in	O
which	O
objects	O
,	O
often	O
on	O
ornamental	O
friezes	O
,	O
are	O
sculpted	O
with	O
less	O
depth	O
than	O
they	O
actually	O
occupy	O
.	O
when	O
lit	O
from	O
above	O
by	O
sunlight	O
,	O
they	O
appear	O
to	O
have	O
true	O
3d	O
depth	O
because	O
of	O
the	O
ambiguity	O
between	O
relative	O
depth	O
and	O
the	O
angle	O
of	O
the	O
illuminant	O
(	O
section	O
12.1.1	O
)	O
.	O
17	O
a	O
good	O
way	O
to	O
minimize	O
the	O
amount	O
of	O
such	O
ambiguities	O
is	O
to	O
use	O
wide	O
ﬁeld	O
of	O
view	O
cameras	O
(	O
antone	O
and	O
teller	O
2002	O
;	O
levin	O
and	O
szeliski	O
2006	O
)	O
.	O
7.4	O
bundle	B
adjustment	I
works	O
well	O
.	O
371	O
7.4.4	O
application	O
:	O
reconstruction	O
from	O
internet	O
photos	O
the	O
most	O
widely	O
used	O
application	O
of	O
structure	B
from	I
motion	I
is	O
in	O
the	O
reconstruction	O
of	O
3d	O
objects	O
and	O
scenes	O
from	O
video	B
sequences	O
and	O
collections	O
of	O
images	O
(	O
pollefeys	O
and	O
van	O
gool	O
2002	O
)	O
.	O
the	O
last	O
decade	O
has	O
seen	O
an	O
explosion	O
of	O
techniques	O
for	O
performing	O
this	O
task	O
auto-	O
matically	O
without	O
the	O
need	O
for	O
any	O
manual	O
correspondence	B
or	O
pre-surveyed	O
ground	O
control	O
points	B
.	O
a	O
lot	O
of	O
these	O
techniques	O
assume	O
that	O
the	O
scene	O
is	O
taken	O
with	O
the	O
same	O
camera	B
and	O
hence	O
the	O
images	O
all	O
have	O
the	O
same	O
intrinsics	O
(	O
fitzgibbon	O
and	O
zisserman	O
1998	O
;	O
koch	O
,	O
polle-	O
feys	O
,	O
and	O
van	O
gool	O
2000	O
;	O
schaffalitzky	O
and	O
zisserman	O
2002	O
;	O
tuytelaars	O
and	O
van	O
gool	O
2004	O
;	O
pollefeys	O
,	O
nist´er	O
,	O
frahm	O
et	O
al	O
.	O
2008	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
2010	O
)	O
.	O
many	O
of	O
these	O
techniques	O
take	O
the	O
results	O
of	O
the	O
sparse	B
feature	O
matching	B
and	O
structure	B
from	I
motion	I
computation	O
and	O
then	O
compute	O
dense	O
3d	O
surface	B
models	O
using	O
multi-view	O
stereo	B
techniques	O
(	O
section	O
11.6	O
)	O
(	O
koch	O
,	O
pollefeys	O
,	O
and	O
van	O
gool	O
2000	O
;	O
pollefeys	O
and	O
van	O
gool	O
2002	O
;	O
pollefeys	O
,	O
nist´er	O
,	O
frahm	O
et	O
al	O
.	O
2008	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
2010	O
)	O
.	O
the	O
latest	O
innovation	O
in	O
this	O
space	O
has	O
been	O
the	O
application	O
of	O
structure	B
from	I
motion	I
and	O
multi-view	B
stereo	I
techniques	O
to	O
thousands	O
of	O
images	O
taken	O
from	O
the	O
internet	O
,	O
where	O
very	O
little	O
is	O
known	O
about	O
the	O
cameras	O
taking	O
the	O
photographs	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2008a	O
)	O
.	O
be-	O
fore	O
the	O
structure	B
from	I
motion	I
computation	O
can	O
begin	O
,	O
it	O
is	O
ﬁrst	O
necessary	O
to	O
establish	O
sparse	B
correspondences	O
between	O
different	O
pairs	B
of	O
images	O
and	O
to	O
then	O
link	O
such	O
correspondences	O
into	O
feature	B
tracks	I
,	O
which	O
associate	O
individual	O
2d	O
image	B
features	O
with	O
global	O
3d	O
points	B
.	O
because	O
the	O
o	O
(	O
n	O
2	O
)	O
comparison	O
of	O
all	O
pairs	B
of	O
images	O
can	O
be	O
very	O
slow	O
,	O
a	O
number	O
of	O
techniques	O
have	O
been	O
developed	O
in	O
the	O
recognition	B
community	O
to	O
make	O
this	O
process	O
faster	O
(	O
section	O
14.3.2	O
)	O
(	O
nist´er	O
and	O
stew´enius	O
2006	O
;	O
philbin	O
,	O
chum	O
,	O
sivic	O
et	O
al	O
.	O
2008	O
;	O
li	O
,	O
wu	O
,	O
zach	O
et	O
al	O
.	O
2008	O
;	O
chum	O
,	O
philbin	O
,	O
and	O
zisserman	O
2008	O
;	O
chum	O
and	O
matas	O
2010	O
)	O
.	O
to	O
begin	O
the	O
reconstruction	O
process	O
,	O
it	O
is	O
important	O
to	O
to	O
select	O
a	O
good	O
pair	O
of	O
images	O
,	O
where	O
there	O
are	O
both	O
a	O
large	O
number	O
of	O
consistent	O
matches	O
(	O
to	O
lower	O
the	O
likelihood	O
of	O
in-	O
correct	O
correspondences	O
)	O
and	O
a	O
signiﬁcant	O
amount	O
of	O
out-of-plane	O
parallax,18	O
to	O
ensure	O
that	O
a	O
stable	O
reconstruction	O
can	O
be	O
obtained	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
the	O
exif	O
tags	O
associated	O
with	O
the	O
photographs	O
can	O
be	O
used	O
to	O
get	O
good	O
initial	O
estimates	O
for	O
camera	O
focal	O
lengths	O
,	O
although	O
this	O
is	O
not	O
always	O
strictly	O
necessary	O
,	O
since	O
these	O
parameters	B
are	O
re-adjusted	O
as	O
part	O
of	O
the	O
bundle	B
adjustment	I
process	O
.	O
once	O
an	O
initial	O
pair	O
has	O
been	O
reconstructed	O
,	O
the	O
pose	O
of	O
cameras	O
that	O
see	O
a	O
sufﬁcient	O
num-	O
ber	O
of	O
the	O
resulting	O
3d	O
points	B
can	O
be	O
estimated	O
(	O
section	O
6.2	O
)	O
and	O
the	O
complete	O
set	O
of	O
cameras	O
and	O
feature	B
correspondences	O
can	O
be	O
used	O
to	O
perform	O
another	O
round	O
of	O
bundle	B
adjustment	I
.	O
fig-	O
18	O
a	O
simple	O
way	O
to	O
compute	O
this	O
is	O
to	O
robustly	O
ﬁt	O
a	O
homography	B
to	O
the	O
correspondences	O
and	O
measure	O
reprojection	O
errors	O
.	O
372	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
7.11	O
incremental	B
structure	O
from	O
motion	B
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
acm	O
:	O
starting	O
with	O
an	O
initial	O
two-frame	B
reconstruction	O
of	O
trevi	O
fountain	O
,	O
batches	O
of	O
images	O
are	O
added	O
using	O
pose	O
estimation	B
,	O
and	O
their	O
positions	O
(	O
along	O
with	O
the	O
3d	O
model	O
)	O
are	O
reﬁned	O
using	O
bundle	O
adjustment	O
.	O
ure	O
7.11	O
shows	O
the	O
progression	O
of	O
the	O
incremental	B
bundle	O
adjustment	O
algorithm	B
,	O
where	O
sets	O
of	O
cameras	O
are	O
added	O
after	O
each	O
successive	O
round	O
of	O
bundle	B
adjustment	I
,	O
while	O
figure	O
7.12	O
shows	O
some	O
additional	O
results	O
.	O
an	O
alternative	O
to	O
this	O
kind	O
of	O
seed	B
and	I
grow	I
approach	O
is	O
to	O
ﬁrst	O
re-	O
construct	O
triplets	O
of	O
images	O
and	O
then	O
hierarchically	O
merge	O
triplets	O
into	O
larger	O
collections	O
,	O
as	O
described	O
by	O
fitzgibbon	O
and	O
zisserman	O
(	O
1998	O
)	O
.	O
unfortunately	O
,	O
as	O
the	O
incremental	B
structure	O
from	O
motion	B
algorithm	O
continues	O
to	O
add	O
more	O
cameras	O
and	O
points	B
,	O
it	O
can	O
become	O
extremely	O
slow	O
.	O
the	O
direct	B
solution	O
of	O
a	O
dense	O
system	O
of	O
o	O
(	O
n	O
)	O
equations	B
for	O
the	O
camera	B
pose	O
updates	O
can	O
take	O
o	O
(	O
n	O
3	O
)	O
time	O
;	O
while	O
structure	B
from	I
motion	I
problems	O
are	O
rarely	O
dense	O
,	O
scenes	O
such	O
as	O
city	O
squares	O
have	O
a	O
high	O
percentage	O
of	O
cameras	O
that	O
see	O
points	O
in	O
common	O
.	O
re-running	O
the	O
bundle	B
adjustment	I
algorithm	O
after	O
every	O
few	O
camera	B
additions	O
results	O
in	O
a	O
quartic	O
scaling	O
of	O
the	O
run	O
time	O
with	O
the	O
number	O
of	O
images	O
in	O
the	O
dataset	O
.	O
one	O
approach	O
to	O
solving	O
this	O
problem	O
is	O
to	O
select	O
a	O
smaller	O
number	O
of	O
images	O
for	O
the	O
original	O
scene	O
reconstruction	O
and	O
to	O
fold	O
in	O
the	O
remaining	O
images	O
at	O
the	O
very	O
end	O
.	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
(	O
2008b	O
)	O
develop	O
an	O
algorithm	B
for	O
computing	O
such	O
a	O
skele-	O
tal	O
set	O
of	O
images	O
,	O
which	O
is	O
guaranteed	O
to	O
produce	O
a	O
reconstruction	O
whose	O
error	O
is	O
within	O
a	O
bounded	O
factor	O
of	O
the	O
optimal	O
reconstruction	O
accuracy	O
.	O
their	O
algorithm	B
ﬁrst	O
evaluates	O
all	O
pairwise	O
uncertainties	O
(	O
position	O
covariances	O
)	O
between	O
overlapping	O
images	O
and	O
then	O
chains	O
them	O
together	O
to	O
estimate	O
a	O
lower	O
bound	O
for	O
the	O
relative	O
uncertainty	B
of	O
any	O
distant	O
pair	O
.	O
the	O
skeletal	B
set	I
is	O
constructed	O
so	O
that	O
the	O
maximal	O
uncertainty	B
between	O
any	O
pair	O
grows	O
by	O
no	O
more	O
than	O
a	O
constant	O
factor	O
.	O
figure	O
7.13	O
shows	O
an	O
example	O
of	O
the	O
skeletal	B
set	I
computed	O
for	O
784	O
images	O
of	O
the	O
pantheon	O
in	O
rome	O
.	O
as	O
you	O
can	O
see	O
,	O
even	O
though	O
the	O
skeletal	B
set	I
contains	O
just	O
a	O
fraction	O
of	O
the	O
original	O
images	O
,	O
the	O
shapes	O
of	O
the	O
skeletal	B
set	I
and	O
full	O
bundle	O
adjusted	O
reconstructions	O
are	O
virtually	O
indistinguishable	O
.	O
the	O
ability	O
to	O
automatically	O
reconstruct	O
3d	O
models	O
from	O
large	O
,	O
unstructured	B
image	O
col-	O
lections	O
has	O
opened	O
a	O
wide	O
variety	O
of	O
additional	O
applications	O
,	O
including	O
the	O
ability	O
to	O
automat-	O
7.4	O
bundle	B
adjustment	I
373	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
7.12	O
3d	O
reconstructions	O
produced	O
by	O
the	O
incremental	B
structure	O
from	O
motion	B
algo-	O
rithm	O
developed	O
by	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
(	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
acm	O
:	O
(	O
a	O
)	O
cameras	O
and	O
point	O
cloud	O
from	O
trafalgar	O
square	O
;	O
(	O
b	O
)	O
cameras	O
and	O
points	B
overlaid	O
on	O
an	O
image	B
from	O
the	O
great	O
wall	O
of	O
china	O
;	O
(	O
c	O
)	O
overhead	O
view	O
of	O
a	O
reconstruction	O
of	O
the	O
old	O
town	O
square	O
in	O
prague	O
registered	O
to	O
an	O
aerial	O
photograph	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
7.13	O
large	B
scale	I
structure	O
from	O
motion	B
using	O
skeletal	O
sets	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2008b	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
:	O
(	O
a	O
)	O
original	O
match	O
graph	O
for	O
784	O
images	O
;	O
(	O
b	O
)	O
skeletal	B
set	I
containing	O
101	O
images	O
;	O
(	O
c	O
)	O
top-down	O
view	O
of	O
scene	O
(	O
pantheon	O
)	O
reconstructed	O
from	O
the	O
skele-	O
tal	O
set	O
;	O
(	O
d	O
)	O
reconstruction	O
after	O
adding	O
in	O
the	O
remaining	O
images	O
using	O
pose	O
estimation	B
;	O
(	O
e	O
)	O
ﬁnal	O
bundle	O
adjusted	O
reconstruction	O
,	O
which	O
is	O
almost	O
identical	O
.	O
374	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ically	O
ﬁnd	O
and	O
label	O
locations	O
and	O
regions	O
of	O
interest	O
(	O
simon	O
,	O
snavely	O
,	O
and	O
seitz	O
2007	O
;	O
simon	O
and	O
seitz	O
2008	O
;	O
gammeter	O
,	O
bossard	O
,	O
quack	O
et	O
al	O
.	O
2009	O
)	O
and	O
to	O
cluster	O
large	O
image	B
collections	O
so	O
that	O
they	O
can	O
be	O
automatically	O
labeled	O
(	O
li	O
,	O
wu	O
,	O
zach	O
et	O
al	O
.	O
2008	O
;	O
quack	O
,	O
leibe	O
,	O
and	O
van	O
gool	O
2008	O
)	O
.	O
some	O
of	O
these	O
application	O
are	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
13.1.2	O
.	O
7.5	O
constrained	B
structure	O
and	O
motion	B
the	O
most	O
general	O
algorithms	O
for	O
structure	O
from	O
motion	B
make	O
no	O
prior	B
assumptions	O
about	O
the	O
objects	O
or	O
scenes	O
that	O
they	O
are	O
reconstructing	O
.	O
in	O
many	O
cases	O
,	O
however	O
,	O
the	O
scene	O
contains	O
higher-level	O
geometric	B
primitives	O
,	O
such	O
as	O
lines	B
and	O
planes	B
.	O
these	O
can	O
provide	O
information	O
complementary	O
to	O
interest	O
points	B
and	O
also	O
serve	O
as	O
useful	O
building	O
blocks	O
for	O
3d	O
modeling	B
and	O
visualization	O
.	O
furthermore	O
,	O
these	O
primitives	O
are	O
often	O
arranged	O
in	O
particular	O
relationships	O
,	O
i.e.	O
,	O
many	O
lines	B
and	O
planes	B
are	O
either	O
parallel	O
or	O
orthogonal	O
to	O
each	O
other	O
.	O
this	O
is	O
particularly	O
true	O
of	O
architectural	O
scenes	O
and	O
models	O
,	O
which	O
we	O
study	O
in	O
more	O
detail	O
in	O
section	O
12.6.1.	O
sometimes	O
,	O
instead	O
of	O
exploiting	O
regularity	O
in	O
the	O
scene	O
structure	O
,	O
it	O
is	O
possible	O
to	O
take	O
advantage	O
of	O
a	O
constrained	B
motion	O
model	O
.	O
for	O
example	O
,	O
if	O
the	O
object	O
of	O
interest	O
is	O
rotating	O
on	O
a	O
turntable	O
(	O
szeliski	O
1991b	O
)	O
,	O
i.e.	O
,	O
around	O
a	O
ﬁxed	O
but	O
unknown	O
axis	O
,	O
specialized	O
techniques	O
can	O
be	O
used	O
to	O
recover	O
this	O
motion	B
(	O
fitzgibbon	O
,	O
cross	O
,	O
and	O
zisserman	O
1998	O
)	O
.	O
in	O
other	O
situa-	O
tions	O
,	O
the	O
camera	B
itself	O
may	O
be	O
moving	O
in	O
a	O
ﬁxed	O
arc	O
around	O
some	O
center	O
of	O
rotation	O
(	O
shum	O
and	O
he	O
1999	O
)	O
.	O
specialized	O
capture	O
setups	O
,	O
such	O
as	O
mobile	O
stereo	B
camera	O
rigs	O
or	O
moving	O
ve-	O
hicles	O
equipped	O
with	O
multiple	O
ﬁxed	O
cameras	O
,	O
can	O
also	O
take	O
advantage	O
of	O
the	O
knowledge	O
that	O
individual	O
cameras	O
are	O
(	O
mostly	O
)	O
ﬁxed	O
with	O
respect	O
to	O
the	O
capture	O
rig	O
,	O
as	O
shown	O
in	O
figure	O
7.8.19	O
7.5.1	O
line-based	B
techniques	O
it	O
is	O
well	O
known	O
that	O
pairwise	O
epipolar	B
geometry	I
can	O
not	O
be	O
recovered	O
from	O
line	O
matches	O
alone	O
,	O
even	O
if	O
the	O
cameras	O
are	O
calibrated	O
.	O
to	O
see	O
this	O
,	O
think	O
of	O
projecting	O
the	O
set	O
of	O
lines	B
in	O
each	O
image	B
into	O
a	O
set	O
of	O
3d	O
planes	B
in	O
space	O
.	O
you	O
can	O
move	O
the	O
two	O
cameras	O
around	O
into	O
any	O
conﬁguration	O
you	O
like	O
and	O
still	O
obtain	O
a	O
valid	O
reconstruction	O
for	O
3d	O
lines	B
.	O
when	O
lines	B
are	O
visible	O
in	O
three	O
or	O
more	O
views	O
,	O
the	O
trifocal	O
tensor	O
can	O
be	O
used	O
to	O
transfer	B
lines	O
from	O
one	O
pair	O
of	O
images	O
to	O
another	O
(	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
the	O
trifocal	O
tensor	O
can	O
also	O
be	O
computed	O
on	O
the	O
basis	O
of	O
line	O
matches	O
alone	O
.	O
schmid	O
and	O
zisserman	O
(	O
1997	O
)	O
describe	O
a	O
widely	O
used	O
technique	O
for	O
matching	O
2d	O
lines	B
based	O
on	O
the	O
average	O
of	O
15	O
×	O
15	O
pixel	O
correlation	O
scores	O
evaluated	O
at	O
all	O
pixels	O
along	O
their	O
19	O
because	O
of	O
mechanical	B
compliance	O
and	O
jitter	O
,	O
it	O
may	O
be	O
prudent	O
to	O
allow	O
for	O
a	O
small	O
amount	O
of	O
individual	O
camera	B
rotation	O
around	O
a	O
nominal	O
position	O
.	O
7.5	O
constrained	B
structure	O
and	O
motion	B
375	O
figure	O
7.14	O
two	O
images	O
of	O
a	O
toy	O
house	O
along	O
with	O
their	O
matched	O
3d	O
line	O
segments	O
(	O
schmid	O
and	O
zisserman	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
springer	O
.	O
common	O
line	O
segment	O
intersection.20	O
in	O
their	O
system	O
,	O
the	O
epipolar	B
geometry	I
is	O
assumed	O
to	O
be	O
known	O
,	O
e.g.	O
,	O
computed	O
from	O
point	O
matches	O
.	O
for	O
wide	O
baselines	O
,	O
all	O
possible	O
homographies	O
corresponding	O
to	O
planes	B
passing	O
through	O
the	O
3d	O
line	O
are	O
used	O
to	O
warp	O
pixels	O
and	O
the	O
maximum	O
correlation	O
score	O
is	O
used	O
.	O
for	O
triplets	O
of	O
images	O
,	O
the	O
trifocal	O
tensor	O
is	O
used	O
to	O
verify	O
that	O
the	O
lines	B
are	O
in	O
geometric	B
correspondence	O
before	O
evaluating	O
the	O
correlations	O
between	O
line	O
segments	O
.	O
figure	O
7.14	O
shows	O
the	O
results	O
of	O
using	O
their	O
system	O
.	O
bartoli	O
and	O
sturm	O
(	O
2003	O
)	O
describe	O
a	O
complete	O
system	O
for	O
extending	O
three	O
view	O
relations	O
(	O
trifocal	O
tensors	O
)	O
computed	O
from	O
manual	O
line	O
correspondences	O
to	O
a	O
full	O
bundle	B
adjustment	I
of	O
all	O
the	O
line	O
and	O
camera	B
parameters	O
.	O
the	O
key	O
to	O
their	O
approach	O
is	O
to	O
use	O
the	O
pl¨ucker	O
coor-	O
dinates	O
(	O
2.12	O
)	O
to	O
parameterize	O
lines	B
and	O
to	O
directly	O
minimize	O
reprojection	O
errors	O
.	O
it	O
is	O
also	O
possible	O
to	O
represent	O
3d	O
line	O
segments	O
by	O
their	O
endpoints	O
and	O
to	O
measure	O
either	O
the	O
reprojec-	O
tion	B
error	O
perpendicular	O
to	O
the	O
detected	O
2d	O
line	O
segments	O
in	O
each	O
image	B
or	O
the	O
2d	O
errors	O
using	O
an	O
elongated	O
uncertainty	B
ellipse	O
aligned	O
with	O
the	O
line	O
segment	O
direction	O
(	O
szeliski	O
and	O
kang	O
1994	O
)	O
.	O
instead	O
of	O
reconstructing	O
3d	O
lines	B
,	O
bay	O
,	O
ferrari	O
,	O
and	O
van	O
gool	O
(	O
2005	O
)	O
use	O
ransac	O
to	O
group	O
lines	B
into	O
likely	O
coplanar	O
subsets	O
.	O
four	O
lines	B
are	O
chosen	O
at	O
random	O
to	O
compute	O
a	O
homog-	O
raphy	O
,	O
which	O
is	O
then	O
veriﬁed	O
for	O
these	O
and	O
other	O
plausible	O
line	O
segment	O
matches	O
by	O
evaluating	O
color	B
histogram-based	O
correlation	O
scores	O
.	O
the	O
2d	O
intersection	O
points	B
of	O
lines	B
belonging	O
to	O
the	O
same	O
plane	O
are	O
then	O
used	O
as	O
virtual	O
measurements	O
to	O
estimate	O
the	O
epipolar	B
geometry	I
,	O
which	O
is	O
more	O
accurate	O
than	O
using	O
the	O
homographies	O
directly	O
.	O
an	O
alternative	O
to	O
grouping	O
lines	B
into	O
coplanar	O
subsets	O
is	O
to	O
group	O
lines	B
by	O
parallelism	O
.	O
whenever	O
three	O
or	O
more	O
2d	O
lines	B
share	O
a	O
common	O
vanishing	O
point	O
,	O
there	O
is	O
a	O
good	O
likelihood	O
that	O
they	O
are	O
parallel	O
in	O
3d	O
.	O
by	O
ﬁnding	O
multiple	B
vanishing	O
points	B
in	O
an	O
image	B
(	O
section	O
4.3.3	O
)	O
and	O
establishing	O
correspondences	O
between	O
such	O
vanishing	B
points	I
in	O
different	O
images	O
,	O
the	O
rel-	O
ative	O
rotations	O
between	O
the	O
various	O
images	O
(	O
and	O
often	O
the	O
camera	B
intrinsics	O
)	O
can	O
be	O
directly	O
estimated	O
(	O
section	O
6.3.2	O
)	O
.	O
20	O
because	O
lines	B
often	O
occur	O
at	O
depth	O
or	O
orientation	O
discontinuities	O
,	O
it	O
may	O
be	O
preferable	O
to	O
compute	O
correlation	O
scores	O
(	O
or	O
to	O
match	O
color	O
histograms	O
(	O
bay	O
,	O
ferrari	O
,	O
and	O
van	O
gool	O
2005	O
)	O
)	O
separately	O
on	O
each	O
side	O
of	O
the	O
line	O
.	O
376	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
shum	O
,	O
han	O
,	O
and	O
szeliski	O
(	O
1998	O
)	O
describe	O
a	O
3d	O
modeling	B
system	O
which	O
ﬁrst	O
constructs	O
calibrated	O
panoramas	O
from	O
multiple	B
images	O
(	O
section	O
7.4	O
)	O
and	O
then	O
has	O
the	O
user	O
draw	O
vertical	O
and	O
horizontal	O
lines	B
in	O
the	O
image	B
to	O
demarcate	O
the	O
boundaries	O
of	O
planar	O
regions	O
.	O
the	O
lines	B
are	O
initially	O
used	O
to	O
establish	O
an	O
absolute	O
rotation	O
for	O
each	O
panorama	O
and	O
are	O
later	O
used	O
(	O
along	O
with	O
the	O
inferred	O
vertices	O
and	O
planes	B
)	O
to	O
infer	O
a	O
3d	O
structure	O
,	O
which	O
can	O
be	O
recovered	O
up	O
to	O
scale	O
from	O
one	O
or	O
more	O
images	O
(	O
figure	O
12.15	O
)	O
.	O
a	O
fully	O
automated	B
approach	O
to	O
line-based	B
structure	O
from	O
motion	B
is	O
presented	O
vy	O
werner	O
and	O
zisserman	O
(	O
2002	O
)	O
.	O
in	O
their	O
system	O
,	O
they	O
ﬁrst	O
ﬁnd	O
lines	B
and	O
group	O
them	O
by	O
common	O
van-	O
ishing	O
points	B
in	O
each	O
image	B
(	O
section	O
4.3.3	O
)	O
.	O
the	O
vanishing	B
points	I
are	O
then	O
used	O
to	O
calibrate	O
the	O
camera	B
,	O
i.e.	O
,	O
to	O
performa	O
a	O
“	O
metric	O
upgrade	O
”	O
(	O
section	O
6.3.2	O
)	O
.	O
lines	B
corresponding	O
to	O
common	O
vanishing	B
points	I
are	O
then	O
matched	O
using	O
both	O
appearance	O
(	O
schmid	O
and	O
zisserman	O
1997	O
)	O
and	O
trifocal	O
tensors	O
.	O
the	O
resulting	O
set	O
of	O
3d	O
lines	B
,	O
color	B
coded	O
by	O
common	O
vanishing	O
directions	O
(	O
3d	O
orientations	O
)	O
is	O
shown	O
in	O
figure	O
12.16a	O
.	O
these	O
lines	B
are	O
then	O
used	O
to	O
infer	O
planes	B
and	O
a	O
block-structured	O
model	O
for	O
the	O
scene	O
,	O
as	O
described	O
in	O
more	O
detail	O
in	O
section	O
12.6.1	O
.	O
7.5.2	O
plane-based	B
techniques	O
in	O
scenes	O
that	O
are	O
rich	O
in	O
planar	O
structures	O
,	O
e.g.	O
,	O
in	O
architecture	B
and	O
certain	O
kinds	O
of	O
manu-	O
factured	O
objects	O
such	O
as	O
furniture	O
,	O
it	O
is	O
possible	O
to	O
directly	O
estimate	O
homographies	O
between	O
different	O
planes	B
,	O
using	O
either	O
feature-based	B
or	O
intensity-based	B
methods	O
.	O
in	O
principle	O
,	O
this	O
in-	O
formation	O
can	O
be	O
used	O
to	O
simultaneously	O
infer	O
the	O
camera	B
poses	O
and	O
the	O
plane	O
equations	O
,	O
i.e.	O
,	O
to	O
compute	O
plane-based	B
structure	O
from	O
motion	B
.	O
luong	O
and	O
faugeras	O
(	O
1996	O
)	O
show	O
how	O
a	O
fundamental	O
matrix	O
can	O
be	O
directly	O
computed	O
from	O
two	O
or	O
more	O
homographies	O
using	O
algebraic	O
manipulations	O
and	O
least	B
squares	I
.	O
unfortu-	O
nately	O
,	O
this	O
approach	O
often	O
performs	O
poorly	O
,	O
since	O
the	O
algebraic	O
errors	O
do	O
not	O
correspond	O
to	O
meaningful	O
reprojection	O
errors	O
(	O
szeliski	O
and	O
torr	O
1998	O
)	O
.	O
a	O
better	O
approach	O
is	O
to	O
hallucinate	O
virtual	O
point	O
correspondences	O
within	O
the	O
areas	O
from	O
which	O
each	O
homography	B
was	O
computed	O
and	O
to	O
feed	O
them	O
into	O
a	O
standard	O
structure	O
from	O
mo-	O
tion	B
algorithm	O
(	O
szeliski	O
and	O
torr	O
1998	O
)	O
.	O
an	O
even	O
better	O
approach	O
is	O
to	O
use	O
full	O
bundle	O
adjust-	O
ment	O
with	O
explicit	O
plane	O
equations	O
,	O
as	O
well	O
as	O
additional	O
constraints	O
to	O
force	O
reconstructed	O
co-planar	O
features	O
to	O
lie	O
exactly	O
on	O
their	O
corresponding	O
planes	B
.	O
(	O
a	O
principled	O
way	O
to	O
do	O
this	O
is	O
to	O
establish	O
a	O
coordinate	O
frame	O
for	O
each	O
plane	O
,	O
e.g.	O
,	O
at	O
one	O
of	O
the	O
feature	B
points	O
,	O
and	O
to	O
use	O
2d	O
in-plane	O
parameterizations	O
for	O
the	O
other	O
points	B
.	O
)	O
the	O
system	O
developed	O
by	O
shum	O
,	O
han	O
,	O
and	O
szeliski	O
(	O
1998	O
)	O
shows	O
an	O
example	O
of	O
such	O
an	O
approach	O
,	O
where	O
the	O
directions	O
of	O
lines	B
and	O
normals	O
for	O
planes	O
in	O
the	O
scene	O
are	O
pre-speciﬁed	O
by	O
the	O
user	O
.	O
7.6	O
additional	O
reading	O
7.6	O
additional	O
reading	O
377	O
the	O
topic	O
of	O
structure	B
from	I
motion	I
is	O
extensively	O
covered	O
in	O
books	O
and	O
review	O
articles	O
on	O
multi-view	B
geometry	O
(	O
faugeras	O
and	O
luong	O
2001	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
2010	O
)	O
.	O
for	O
two-frame	O
reconstruction	O
,	O
hartley	O
(	O
1997a	O
)	O
wrote	O
a	O
highly	O
cited	O
paper	O
on	O
the	O
“	O
eight-point	B
algorithm	I
”	O
for	O
computing	O
an	O
essential	O
or	O
fundamental	O
ma-	O
trix	O
with	O
reasonable	O
point	O
normalization	O
.	O
when	O
the	O
cameras	O
are	O
calibrated	O
,	O
the	O
ﬁve-point	O
algorithm	B
of	O
nist´er	O
(	O
2004	O
)	O
can	O
be	O
used	O
in	O
conjunction	O
with	O
ransac	O
to	O
obtain	O
initial	O
recon-	O
structions	O
from	O
the	O
minimum	O
number	O
of	O
points	B
.	O
when	O
the	O
cameras	O
are	O
uncalibrated	O
,	O
various	O
self-calibration	B
techniques	O
can	O
be	O
found	O
in	O
work	O
by	O
hartley	O
and	O
zisserman	O
(	O
2004	O
)	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
(	O
2010	O
)	O
—i	O
only	O
brieﬂy	O
mention	O
one	O
of	O
the	O
simplest	O
techniques	O
,	O
the	O
kruppa	O
equations	B
(	O
7.35	O
)	O
.	O
in	O
applications	O
where	O
points	B
are	O
being	O
tracked	O
from	O
frame	O
to	O
frame	O
,	O
factorization	B
tech-	O
niques	O
,	O
based	O
on	O
either	O
orthographic	B
camera	O
models	O
(	O
tomasi	O
and	O
kanade	O
1992	O
;	O
poelman	O
and	O
kanade	O
1997	O
;	O
costeira	O
and	O
kanade	O
1995	O
;	O
morita	O
and	O
kanade	O
1997	O
;	O
morris	O
and	O
kanade	O
1998	O
;	O
anandan	O
and	O
irani	O
2002	O
)	O
or	O
projective	B
extensions	O
(	O
christy	O
and	O
horaud	O
1996	O
;	O
sturm	O
and	O
triggs	O
1996	O
;	O
triggs	O
1996	O
;	O
oliensis	O
and	O
hartley	O
2007	O
)	O
,	O
can	O
be	O
used	O
.	O
triggs	O
,	O
mclauchlan	O
,	O
hartley	O
et	O
al	O
.	O
(	O
1999	O
)	O
provide	O
a	O
good	O
tutorial	O
and	O
survey	O
on	O
bundle	B
adjustment	I
,	O
while	O
lourakis	O
and	O
argyros	O
(	O
2009	O
)	O
and	O
engels	O
,	O
stew´enius	O
,	O
and	O
nist´er	O
(	O
2006	O
)	O
provide	O
tips	O
on	O
implementation	O
and	O
effective	O
practices	O
.	O
bundle	B
adjustment	I
is	O
also	O
covered	O
in	O
textbooks	B
and	O
surveys	B
on	O
multi-view	B
geometry	O
(	O
faugeras	O
and	O
luong	O
2001	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
2010	O
)	O
.	O
techniques	O
for	O
handling	O
larger	O
problems	O
are	O
described	O
by	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
(	O
2008b	O
)	O
;	O
agarwal	O
,	O
snavely	O
,	O
simon	O
et	O
al	O
.	O
(	O
2009	O
)	O
;	O
jeong	O
,	O
nist´er	O
,	O
steedly	O
et	O
al	O
.	O
(	O
2010	O
)	O
;	O
agarwal	O
,	O
snavely	O
,	O
seitz	O
et	O
al	O
.	O
(	O
2010	O
)	O
.	O
while	O
bundle	B
adjustment	I
is	O
often	O
called	O
as	O
an	O
inner	O
loop	O
inside	O
incremental	B
reconstruction	O
algorithms	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
,	O
hierarchical	B
(	O
fitzgibbon	O
and	O
zisserman	O
1998	O
;	O
farenzena	O
,	O
fusiello	O
,	O
and	O
gherardi	O
2009	O
)	O
and	O
global	B
(	O
rother	O
and	O
carlsson	O
2002	O
;	O
martinec	O
and	O
pajdla	O
2007	O
)	O
approaches	O
for	O
initialization	O
are	O
also	O
possible	O
and	O
perhaps	O
even	O
preferable	O
.	O
as	O
structure	B
from	I
motion	I
starts	O
being	O
applied	O
to	O
dynamic	B
scenes	O
,	O
the	O
topic	O
of	O
non-rigid	B
structure	O
from	O
motion	B
(	O
torresani	O
,	O
hertzmann	O
,	O
and	O
bregler	O
2008	O
)	O
,	O
which	O
we	O
do	O
not	O
cover	O
in	O
this	O
book	O
,	O
will	O
become	O
more	O
important	O
.	O
7.7	O
exercises	O
ex	O
7.1	O
:	O
triangulation	B
use	O
the	O
calibration	B
pattern	O
you	O
built	O
and	O
tested	O
in	O
exercise	O
6.7	O
to	O
test	O
your	O
triangulation	B
accuracy	O
.	O
as	O
an	O
alternative	O
,	O
generate	O
synthetic	O
3d	O
points	B
and	O
cameras	O
and	O
add	O
noise	B
to	O
the	O
2d	O
point	O
measurements	O
.	O
378	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
1.	O
assume	O
that	O
you	O
know	O
the	O
camera	B
pose	O
,	O
i.e.	O
,	O
the	O
camera	B
matrices	O
.	O
use	O
the	O
3d	O
distance	O
to	O
rays	O
(	O
7.4	O
)	O
or	O
linearized	O
versions	O
of	O
equations	B
(	O
7.5–7.6	O
)	O
to	O
compute	O
an	O
initial	O
set	O
of	O
3d	O
locations	O
.	O
compare	O
these	O
to	O
your	O
known	O
ground	O
truth	O
locations	O
.	O
2.	O
use	O
iterative	B
non-linear	O
minimization	O
to	O
improve	O
your	O
initial	O
estimates	O
and	O
report	O
on	O
the	O
improvement	O
in	O
accuracy	B
.	O
3	O
.	O
(	O
optional	O
)	O
use	O
the	O
technique	O
described	O
by	O
hartley	O
and	O
sturm	O
(	O
1997	O
)	O
to	O
perform	O
two-	O
frame	O
triangulation	O
.	O
4.	O
see	O
if	O
any	O
of	O
the	O
failure	O
modes	O
reported	O
by	O
hartley	O
and	O
sturm	O
(	O
1997	O
)	O
or	O
hartley	O
(	O
1998	O
)	O
occur	O
in	O
practice	O
.	O
ex	O
7.2	O
:	O
essential	O
and	O
fundamental	O
matrix	O
implement	O
the	O
two-frame	B
e	O
and	O
f	O
matrix	O
es-	O
timation	O
techniques	O
presented	O
in	O
section	O
7.2	O
,	O
with	O
suitable	O
re-scaling	O
for	O
better	O
noise	B
immu-	O
nity	O
.	O
1.	O
use	O
the	O
data	O
from	O
exercise	O
7.1	O
to	O
validate	O
your	O
algorithms	O
and	O
to	O
report	O
on	O
their	O
accu-	O
racy	O
.	O
2	O
.	O
(	O
optional	O
)	O
implement	O
one	O
of	O
the	O
improved	O
f	O
or	O
e	O
estimation	B
algorithms	O
,	O
e.g.	O
,	O
us-	O
ing	O
renormalization	O
(	O
zhang	O
1998b	O
;	O
torr	O
and	O
fitzgibbon	O
2004	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
,	O
ransac	O
(	O
torr	O
and	O
murray	O
1997	O
)	O
,	O
least	O
media	O
squares	O
(	O
lms	O
)	O
,	O
or	O
the	O
ﬁve-point	O
algorithm	B
developed	O
by	O
nist´er	O
(	O
2004	O
)	O
.	O
ex	O
7.3	O
:	O
view	B
morphing	I
and	O
interpolation	B
implement	O
automatic	B
view	O
morphing	B
,	O
i.e.	O
,	O
com-	O
pute	O
two-frame	B
structure	O
from	O
motion	B
and	O
then	O
use	O
these	O
results	O
to	O
generate	O
a	O
smooth	O
anima-	O
tion	B
from	O
one	O
image	B
to	O
the	O
next	O
(	O
section	O
7.2.3	O
)	O
.	O
1.	O
decide	O
how	O
to	O
represent	O
your	O
3d	O
scene	O
,	O
e.g.	O
,	O
compute	O
a	O
delaunay	O
triangulation	B
of	O
the	O
matched	O
point	O
and	O
decide	O
what	O
to	O
do	O
with	O
the	O
triangles	O
near	O
the	O
border	O
.	O
(	O
hint	O
:	O
try	O
ﬁtting	O
a	O
plane	O
to	O
the	O
scene	O
,	O
e.g.	O
,	O
behind	O
most	O
of	O
the	O
points	B
.	O
)	O
2.	O
compute	O
your	O
in-between	O
camera	B
positions	O
and	O
orientations	O
.	O
3.	O
warp	O
each	O
triangle	O
to	O
its	O
new	O
location	O
,	O
preferably	O
using	O
the	O
correct	O
perspective	B
projec-	O
tion	B
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
.	O
4	O
.	O
(	O
optional	O
)	O
if	O
you	O
have	O
a	O
denser	O
3d	O
model	O
(	O
e.g.	O
,	O
from	O
stereo	B
)	O
,	O
decide	O
what	O
to	O
do	O
at	O
the	O
“	O
cracks	O
”	O
.	O
5	O
.	O
(	O
optional	O
)	O
for	O
a	O
non-rigid	B
scene	O
,	O
e.g.	O
,	O
two	O
pictures	O
of	O
a	O
face	B
with	O
different	O
expressions	O
,	O
not	O
all	O
of	O
your	O
matched	O
points	B
will	O
obey	O
the	O
epipolar	B
geometry	I
.	O
decide	O
how	O
to	O
handle	O
them	O
to	O
achieve	O
the	O
best	O
effect	O
.	O
7.7	O
exercises	O
379	O
ex	O
7.4	O
:	O
factorization	B
implement	O
the	O
factorization	B
algorithm	O
described	O
in	O
section	O
7.3	O
us-	O
ing	O
point	O
tracks	O
you	O
computed	O
in	O
exercise	O
4.5	O
.	O
1	O
.	O
(	O
optional	O
)	O
implement	O
uncertainty	B
rescaling	O
(	O
anandan	O
and	O
irani	O
2002	O
)	O
and	O
comment	O
on	O
whether	O
this	O
improves	O
your	O
results	O
.	O
2	O
.	O
(	O
optional	O
)	O
implement	O
one	O
of	O
the	O
perspective	B
improvements	O
to	O
factorization	B
discussed	O
in	O
section	O
7.3.1	O
(	O
christy	O
and	O
horaud	O
1996	O
;	O
sturm	O
and	O
triggs	O
1996	O
;	O
triggs	O
1996	O
)	O
.	O
does	O
this	O
produce	O
signiﬁcantly	O
lower	O
reprojection	O
errors	O
?	O
can	O
you	O
upgrade	O
this	O
reconstruc-	O
tion	B
to	O
a	O
metric	O
one	O
?	O
ex	O
7.5	O
:	O
bundle	O
adjuster	O
it	O
really	O
is	O
not	O
.	O
implement	O
a	O
full	O
bundle	O
adjuster	O
.	O
this	O
may	O
sound	O
daunting	O
,	O
but	O
1.	O
devise	O
the	O
internal	O
data	O
structures	O
and	O
external	O
ﬁle	O
representations	O
to	O
hold	O
your	O
camera	B
parameters	O
(	O
position	O
,	O
orientation	O
,	O
and	O
focal	O
length	O
)	O
,	O
3d	O
point	O
locations	O
(	O
euclidean	O
or	O
homogeneous	O
)	O
,	O
and	O
2d	O
point	O
tracks	O
(	O
frame	O
and	O
point	O
identiﬁer	O
as	O
well	O
as	O
2d	O
locations	O
)	O
.	O
2.	O
use	O
some	O
other	O
technique	O
,	O
such	O
as	O
factorization	B
,	O
to	O
initialize	O
the	O
3d	O
point	O
and	O
camera	B
locations	O
from	O
your	O
2d	O
tracks	O
(	O
e.g.	O
,	O
a	O
subset	O
of	O
points	B
that	O
appears	O
in	O
all	O
frames	O
)	O
.	O
3.	O
implement	O
the	O
code	O
corresponding	O
to	O
the	O
forward	B
transformations	O
in	O
figure	O
7.7	O
,	O
i.e.	O
,	O
for	O
each	O
2d	O
point	O
measurement	O
,	O
take	O
the	O
corresponding	O
3d	O
point	O
,	O
map	O
it	O
through	O
the	O
camera	B
transformations	O
(	O
including	O
perspective	B
projection	O
and	O
focal	O
length	O
scaling	O
)	O
,	O
and	O
compare	O
it	O
to	O
the	O
2d	O
point	O
measurement	O
to	O
get	O
a	O
residual	O
error	O
.	O
4.	O
take	O
the	O
residual	O
error	O
and	O
compute	O
its	O
derivatives	O
with	O
respect	O
to	O
all	O
the	O
unknown	O
motion	B
and	O
structure	O
parameters	O
,	O
using	O
backward	O
chaining	O
,	O
as	O
shown	O
,	O
e.g.	O
,	O
in	O
figure	O
7.7	O
and	O
equation	B
(	O
6.47	O
)	O
.	O
this	O
gives	O
you	O
the	O
sparse	B
jacobian	O
j	O
used	O
in	O
equations	B
(	O
6.13–	O
6.17	O
)	O
and	O
equation	B
(	O
6.43	O
)	O
.	O
5.	O
use	O
a	O
sparse	B
least	O
squares	O
or	O
linear	B
system	O
solver	O
,	O
e.g.	O
,	O
matlab	O
,	O
sparsesuite	O
,	O
or	O
sparskit	O
(	O
see	O
appendix	O
a.4	O
and	O
a.5	O
)	O
,	O
to	O
solve	O
the	O
corresponding	O
linearized	O
system	O
,	O
adding	O
a	O
small	O
amount	O
of	O
diagonal	O
preconditioning	O
,	O
as	O
in	O
levenberg–marquardt	O
.	O
6.	O
update	O
your	O
parameters	B
,	O
make	O
sure	O
your	O
rotation	O
matrices	O
are	O
still	O
orthonormal	O
(	O
e.g.	O
,	O
by	O
re-computing	O
them	O
from	O
your	O
quaternions	B
)	O
,	O
and	O
continue	O
iterating	O
while	O
monitoring	O
your	O
residual	O
error	O
.	O
7	O
.	O
(	O
optional	O
)	O
use	O
the	O
“	O
schur	O
complement	O
trick	O
”	O
(	O
7.56	O
)	O
to	O
reduce	O
the	O
size	O
of	O
the	O
system	O
being	O
solved	O
(	O
triggs	O
,	O
mclauchlan	O
,	O
hartley	O
et	O
al	O
.	O
1999	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
lourakis	O
and	O
argyros	O
2009	O
;	O
engels	O
,	O
stew´enius	O
,	O
and	O
nist´er	O
2006	O
)	O
.	O
380	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
8	O
.	O
(	O
optional	O
)	O
implement	O
your	O
own	O
iterative	B
sparse	O
solver	O
,	O
e.g.	O
,	O
conjugate	B
gradient	I
,	O
and	O
compare	O
its	O
performance	O
to	O
a	O
direct	B
method	O
.	O
9	O
.	O
(	O
optional	O
)	O
make	O
your	O
bundle	O
adjuster	O
robust	B
to	O
outliers	O
,	O
or	O
try	O
adding	O
some	O
of	O
the	O
other	O
improvements	O
discussed	O
in	O
(	O
engels	O
,	O
stew´enius	O
,	O
and	O
nist´er	O
2006	O
)	O
.	O
can	O
you	O
think	O
of	O
any	O
other	O
ways	O
to	O
make	O
your	O
algorithm	B
even	O
faster	O
or	O
more	O
robust	B
?	O
ex	O
7.6	O
:	O
match	B
move	I
and	O
augmented	B
reality	I
use	O
the	O
results	O
of	O
the	O
previous	O
exercise	O
to	O
superimpose	O
a	O
rendered	O
3d	O
model	O
on	O
top	O
of	O
video	B
.	O
see	O
section	O
7.4.2	O
for	O
more	O
details	O
and	O
ideas	O
.	O
check	O
for	O
how	O
“	O
locked	O
down	O
”	O
the	O
objects	O
are	O
.	O
ex	O
7.7	O
:	O
line-based	B
reconstruction	O
augment	O
the	O
previously	O
developed	O
bundle	O
adjuster	O
to	O
include	O
lines	B
,	O
possibly	O
with	O
known	O
3d	O
orientations	O
.	O
optionally	O
,	O
use	O
co-planar	O
sets	O
of	O
points	B
and	O
lines	B
to	O
hypothesize	O
planes	B
and	O
to	O
enforce	O
co-planarity	O
(	O
schaffalitzky	O
and	O
zisserman	O
2002	O
;	O
robertson	O
and	O
cipolla	O
2002	O
)	O
ex	O
7.8	O
:	O
flexible	O
bundle	O
adjuster	O
design	O
a	O
bundle	O
adjuster	O
that	O
allows	O
for	O
arbitrary	O
chains	O
of	O
transformations	O
and	O
prior	B
knowledge	O
about	O
the	O
unknowns	O
,	O
as	O
suggested	O
in	O
figures	O
7.7–7.8	O
.	O
ex	O
7.9	O
:	O
unordered	O
image	B
matching	O
compute	O
the	O
camera	B
pose	O
and	O
3d	O
structure	O
of	O
a	O
scene	O
from	O
an	O
arbitrary	O
collection	O
of	O
photographs	O
(	O
brown	O
and	O
lowe	O
2003	O
;	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
chapter	O
8	O
dense	O
motion	O
estimation	B
8.1	O
translational	B
alignment	O
.	O
8.2	O
parametric	B
motion	O
.	O
8.3	O
spline-based	B
motion	O
.	O
8.4	O
optical	B
ﬂow	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
fourier-based	O
alignment	B
incremental	O
reﬁnement	O
.	O
.	O
.	O
8.1.1	O
hierarchical	B
motion	O
estimation	B
.	O
8.1.2	O
.	O
.	O
8.1.3	O
.	O
.	O
.	O
.	O
.	O
.	O
8.2.1	O
application	O
:	O
video	B
stabilization	I
.	O
.	O
8.2.2	O
learned	B
motion	O
models	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8.3.1	O
application	O
:	O
medical	B
image	I
registration	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8.5.1	O
application	O
:	O
frame	B
interpolation	I
.	O
.	O
8.5.2	O
transparent	B
layers	O
and	O
reﬂections	B
.	O
.	O
.	O
.	O
8.4.1	O
multi-frame	B
motion	O
estimation	B
.	O
8.4.2	O
application	O
:	O
video	B
denoising	I
.	O
8.4.3	O
application	O
:	O
de-interlacing	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
384	O
.	O
387	O
.	O
388	O
.	O
392	O
.	O
398	O
.	O
401	O
.	O
403	O
.	O
404	O
.	O
408	O
.	O
409	O
.	O
413	O
.	O
414	O
.	O
415	O
.	O
415	O
.	O
418	O
.	O
419	O
.	O
421	O
.	O
422	O
8.5	O
layered	B
motion	O
.	O
8.6	O
additional	O
reading	O
.	O
.	O
8.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
382	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
e	O
)	O
(	O
b	O
)	O
ﬂow	O
initial	O
layers	B
ﬁnal	O
layers	B
layers	O
with	O
pixel	O
assignments	O
and	O
ﬂow	O
(	O
d	O
)	O
(	O
f	O
)	O
figure	O
8.1	O
motion	B
estimation	I
:	O
(	O
a–b	O
)	O
regularization-based	O
optical	B
ﬂow	I
(	O
nagel	O
and	O
enkel-	O
mann	O
1986	O
)	O
c	O
(	O
cid:13	O
)	O
1986	O
ieee	O
;	O
(	O
c–d	O
)	O
layered	B
motion	O
estimation	B
(	O
wang	O
and	O
adelson	O
1994	O
)	O
c	O
(	O
cid:13	O
)	O
1994	O
ieee	O
;	O
(	O
e–f	O
)	O
sample	O
image	B
and	O
ground	O
truth	O
ﬂow	O
from	O
evaluation	B
database	O
(	O
baker	O
,	O
black	O
,	O
lewis	O
et	O
al	O
.	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
ieee	O
.	O
8	O
dense	O
motion	O
estimation	B
383	O
algorithms	O
for	O
aligning	O
images	O
and	O
estimating	O
motion	B
in	O
video	B
sequences	O
are	O
among	O
the	O
most	O
widely	O
used	O
in	O
computer	O
vision	O
.	O
for	O
example	O
,	O
frame-rate	O
image	B
alignment	O
is	O
widely	O
used	O
in	O
camcorders	O
and	O
digital	O
cameras	O
to	O
implement	O
their	O
image	B
stabilization	O
(	O
is	O
)	O
feature	B
.	O
an	O
early	O
example	O
of	O
a	O
widely	O
used	O
image	B
registration	I
algorithm	O
is	O
the	O
patch-based	B
trans-	O
lational	O
alignment	B
(	O
optical	B
ﬂow	I
)	O
technique	O
developed	O
by	O
lucas	O
and	O
kanade	O
(	O
1981	O
)	O
.	O
variants	O
of	O
this	O
algorithm	B
are	O
used	O
in	O
almost	O
all	O
motion-compensated	O
video	B
compression	I
schemes	O
such	O
as	O
mpeg	O
and	O
h.263	O
(	O
le	O
gall	O
1991	O
)	O
.	O
similar	O
parametric	B
motion	O
estimation	B
algorithms	O
have	O
found	O
a	O
wide	O
variety	O
of	O
applications	O
,	O
including	O
video	B
summarization	I
(	O
teodosio	O
and	O
bender	O
1993	O
;	O
irani	O
and	O
anandan	O
1998	O
)	O
,	O
video	B
stabilization	I
(	O
hansen	O
,	O
anandan	O
,	O
dana	O
et	O
al	O
.	O
1994	O
;	O
srinivasan	O
,	O
chellappa	O
,	O
veeraraghavan	O
et	O
al	O
.	O
2005	O
;	O
matsushita	O
,	O
ofek	O
,	O
ge	O
et	O
al	O
.	O
2006	O
)	O
,	O
and	O
video	B
compression	I
(	O
irani	O
,	O
hsu	O
,	O
and	O
anandan	O
1995	O
;	O
lee	O
,	O
ge	O
chen	O
,	O
lung	O
bruce	O
lin	O
et	O
al	O
.	O
1997	O
)	O
.	O
more	O
sophisticated	O
image	B
registration	I
algorithms	O
have	O
also	O
been	O
developed	O
for	O
medical	O
imaging	O
and	O
remote	O
sensing	O
.	O
image	B
registration	I
techniques	O
are	O
surveyed	O
by	O
brown	O
(	O
1992	O
)	O
,	O
zitov	O
’	O
aa	O
and	O
flusser	O
(	O
2003	O
)	O
,	O
goshtasby	O
(	O
2005	O
)	O
,	O
and	O
szeliski	O
(	O
2006a	O
)	O
.	O
to	O
estimate	O
the	O
motion	B
between	O
two	O
or	O
more	O
images	O
,	O
a	O
suitable	O
error	O
metric	O
must	O
ﬁrst	O
be	O
chosen	O
to	O
compare	O
the	O
images	O
(	O
section	O
8.1	O
)	O
.	O
once	O
this	O
has	O
been	O
established	O
,	O
a	O
suitable	O
search	O
technique	O
must	O
be	O
devised	O
.	O
the	O
simplest	O
technique	O
is	O
to	O
exhaustively	O
try	O
all	O
possible	O
alignments	O
,	O
i.e.	O
,	O
to	O
do	O
a	O
full	O
search	O
.	O
in	O
practice	O
,	O
this	O
may	O
be	O
too	O
slow	O
,	O
so	O
hierarchical	B
coarse-	O
to-ﬁne	O
techniques	O
(	O
section	O
8.1.1	O
)	O
based	O
on	O
image	B
pyramids	O
are	O
normally	O
used	O
.	O
alternatively	O
,	O
fourier	O
transforms	O
(	O
section	O
8.1.2	O
)	O
can	O
be	O
used	O
to	O
speed	O
up	O
the	O
computation	O
.	O
to	O
get	O
sub-pixel	O
precision	O
in	O
the	O
alignment	B
,	O
incremental	B
methods	O
(	O
section	O
8.1.3	O
)	O
based	O
on	O
a	O
taylor	O
series	O
expansion	O
of	O
the	O
image	B
function	O
are	O
often	O
used	O
.	O
these	O
can	O
also	O
be	O
applied	O
to	O
parametric	B
motion	O
models	O
(	O
section	O
8.2	O
)	O
,	O
which	O
model	O
global	B
image	O
transformations	O
such	O
as	O
rotation	O
or	O
shearing	O
.	O
motion	B
estimation	I
can	O
be	O
made	O
more	O
reliable	O
by	O
learning	O
the	O
typi-	O
cal	O
dynamics	O
or	O
motion	B
statistics	O
of	O
the	O
scenes	O
or	O
objects	O
being	O
tracked	O
,	O
e.g.	O
,	O
the	O
natural	B
gait	O
of	O
walking	O
people	O
(	O
section	O
8.2.2	O
)	O
.	O
for	O
more	O
complex	O
motions	O
,	O
piecewise	O
parametric	B
spline	O
motion	B
models	I
(	O
section	O
8.3	O
)	O
can	O
be	O
used	O
.	O
in	O
the	O
presence	O
of	O
multiple	B
independent	O
(	O
and	O
per-	O
haps	O
non-rigid	B
)	O
motions	O
,	O
general-purpose	O
optical	B
ﬂow	I
(	O
or	O
optic	O
ﬂow	O
)	O
techniques	O
need	O
to	O
be	O
used	O
(	O
section	O
8.4	O
)	O
.	O
for	O
even	O
more	O
complex	O
motions	O
that	O
include	O
a	O
lot	O
of	O
occlusions	O
,	O
layered	B
motion	O
models	O
(	O
section	O
8.5	O
)	O
,	O
which	O
decompose	O
the	O
scene	O
into	O
coherently	O
moving	O
layers	O
,	O
can	O
work	O
well	O
.	O
in	O
this	O
chapter	O
,	O
we	O
describe	O
each	O
of	O
these	O
techniques	O
in	O
more	O
detail	O
.	O
additional	O
details	O
can	O
be	O
found	O
in	O
review	O
and	O
comparative	O
evaluation	B
papers	O
on	O
motion	B
estimation	I
(	O
barron	O
,	O
fleet	O
,	O
and	O
beauchemin	O
1994	O
;	O
mitiche	O
and	O
bouthemy	O
1996	O
;	O
stiller	O
and	O
konrad	O
1999	O
;	O
szeliski	O
2006a	O
;	O
baker	O
,	O
black	O
,	O
lewis	O
et	O
al	O
.	O
2007	O
)	O
.	O
384	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
8.1	O
translational	B
alignment	O
the	O
simplest	O
way	O
to	O
establish	O
an	O
alignment	B
between	O
two	O
images	O
or	O
image	B
patches	O
is	O
to	O
shift	O
one	O
image	B
relative	O
to	O
the	O
other	O
.	O
given	O
a	O
template	O
image	B
i0	O
(	O
x	O
)	O
sampled	O
at	O
discrete	B
pixel	O
locations	O
{	O
xi	O
=	O
(	O
xi	O
,	O
yi	O
)	O
}	O
,	O
we	O
wish	O
to	O
ﬁnd	O
where	O
it	O
is	O
located	O
in	O
image	B
i1	O
(	O
x	O
)	O
.	O
a	O
least	B
squares	I
solution	O
to	O
this	O
problem	O
is	O
to	O
ﬁnd	O
the	O
minimum	O
of	O
the	O
sum	O
of	O
squared	O
differences	O
(	O
ssd	O
)	O
function	O
essd	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
=	O
(	O
cid:88	O
)	O
i	O
e2	O
i	O
,	O
(	O
8.1	O
)	O
where	O
u	O
=	O
(	O
u	O
,	O
v	O
)	O
is	O
the	O
displacement	O
and	O
ei	O
=	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
is	O
called	O
the	O
residual	O
error	O
(	O
or	O
the	O
displaced	O
frame	O
difference	O
in	O
the	O
video	B
coding	O
literature	O
)	O
.1	O
(	O
we	O
ignore	O
for	O
the	O
moment	O
the	O
possibility	O
that	O
parts	O
of	O
i0	O
may	O
lie	O
outside	O
the	O
boundaries	O
of	O
i1	O
or	O
be	O
otherwise	O
not	O
visible	O
.	O
)	O
the	O
assumption	O
that	O
corresponding	O
pixel	O
values	O
remain	O
the	O
same	O
in	O
the	O
two	O
images	O
is	O
often	O
called	O
the	O
brightness	O
constancy	O
constraint.2	O
in	O
general	O
,	O
the	O
displacement	O
u	O
can	O
be	O
fractional	O
,	O
so	O
a	O
suitable	O
interpolation	B
function	O
must	O
be	O
applied	O
to	O
image	B
i1	O
(	O
x	O
)	O
.	O
in	O
practice	O
,	O
a	O
bilinear	B
interpolant	O
is	O
often	O
used	O
but	O
bicubic	B
inter-	O
polation	O
can	O
yield	O
slightly	O
better	O
results	O
(	O
szeliski	O
and	O
scharstein	O
2004	O
)	O
.	O
color	B
images	O
can	O
be	O
processed	O
by	O
summing	O
differences	O
across	O
all	O
three	O
color	B
channels	O
,	O
although	O
it	O
is	O
also	O
possible	O
to	O
ﬁrst	O
transform	B
the	O
images	O
into	O
a	O
different	O
color	B
space	O
or	O
to	O
only	O
use	O
the	O
luminance	O
(	O
which	O
is	O
often	O
done	O
in	O
video	B
encoders	O
)	O
.	O
robust	B
error	O
metrics	O
.	O
we	O
can	O
make	O
the	O
above	O
error	O
metric	O
more	O
robust	B
to	O
outliers	O
by	O
re-	O
placing	O
the	O
squared	O
error	O
terms	O
with	O
a	O
robust	B
function	O
ρ	O
(	O
ei	O
)	O
(	O
huber	O
1981	O
;	O
hampel	O
,	O
ronchetti	O
,	O
rousseeuw	O
et	O
al	O
.	O
1986	O
;	O
black	O
and	O
anandan	O
1996	O
;	O
stewart	O
1999	O
)	O
to	O
obtain	O
esrd	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
ρ	O
(	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
ρ	O
(	O
ei	O
)	O
.	O
(	O
8.2	O
)	O
the	O
robust	B
norm	O
ρ	O
(	O
e	O
)	O
is	O
a	O
function	O
that	O
grows	O
less	O
quickly	O
than	O
the	O
quadratic	O
penalty	O
associ-	O
ated	O
with	O
least	O
squares	O
.	O
one	O
such	O
function	O
,	O
sometimes	O
used	O
in	O
motion	B
estimation	I
for	O
video	B
coding	O
because	O
of	O
its	O
speed	O
,	O
is	O
the	O
sum	O
of	O
absolute	O
differences	O
(	O
sad	O
)	O
metric3	O
or	O
l1	O
norm	O
,	O
i.e.	O
,	O
esad	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
|i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
|	O
=	O
(	O
cid:88	O
)	O
i	O
|ei|	O
.	O
(	O
8.3	O
)	O
1	O
the	O
usual	O
justiﬁcation	O
for	O
using	O
least	B
squares	I
is	O
that	O
it	O
is	O
the	O
optimal	O
estimate	O
with	O
respect	O
to	O
gaussian	O
noise	B
.	O
see	O
the	O
discussion	O
below	O
on	O
robust	B
error	O
metrics	O
as	O
well	O
as	O
appendix	O
b.3	O
.	O
2	O
brightness	O
constancy	O
(	O
horn	O
1974	O
)	O
is	O
the	O
tendency	O
for	O
objects	O
to	O
maintain	O
their	O
perceived	O
brightness	O
under	O
varying	O
illumination	O
conditions	O
.	O
3	O
in	O
video	B
compression	I
,	O
e.g.	O
,	O
the	O
h.264	O
standard	O
(	O
http	O
:	O
//www.itu.int/rec/t-rec-h.264	O
)	O
,	O
the	O
sum	O
of	O
absolute	O
trans-	O
formed	O
differences	O
(	O
satd	O
)	O
,	O
which	O
measures	O
the	O
differences	O
in	O
a	O
frequency	O
transform	B
space	O
,	O
e.g.	O
,	O
using	O
a	O
hadamard	O
transform	B
,	O
is	O
often	O
used	O
since	O
it	O
more	O
accurately	O
predicts	O
quality	O
(	O
richardson	O
2003	O
)	O
.	O
8.1	O
translational	B
alignment	O
385	O
however	O
,	O
since	O
this	O
function	O
is	O
not	O
differentiable	O
at	O
the	O
origin	O
,	O
it	O
is	O
not	O
well	O
suited	O
to	O
gradient-	O
descent	O
approaches	O
such	O
as	O
the	O
ones	O
presented	O
in	O
section	O
8.1.3.	O
instead	O
,	O
a	O
smoothly	O
varying	O
function	O
that	O
is	O
quadratic	O
for	O
small	O
values	O
but	O
grows	O
more	O
slowly	O
away	O
from	O
the	O
origin	O
is	O
often	O
used	O
.	O
black	O
and	O
rangarajan	O
(	O
1996	O
)	O
discuss	O
a	O
variety	O
of	O
such	O
functions	O
,	O
including	O
the	O
geman–mcclure	O
function	O
,	O
ρgm	O
(	O
x	O
)	O
=	O
x2	O
1	O
+	O
x2/a2	O
,	O
(	O
8.4	O
)	O
where	O
a	O
is	O
a	O
constant	O
that	O
can	O
be	O
thought	O
of	O
as	O
an	O
outlier	O
threshold	O
.	O
an	O
appropriate	O
value	O
for	O
the	O
threshold	O
can	O
itself	O
be	O
derived	O
using	O
robust	O
statistics	O
(	O
huber	O
1981	O
;	O
hampel	O
,	O
ronchetti	O
,	O
rousseeuw	O
et	O
al	O
.	O
1986	O
;	O
rousseeuw	O
and	O
leroy	O
1987	O
)	O
,	O
e.g.	O
,	O
by	O
computing	O
the	O
median	B
absolute	O
deviation	O
,	O
m	O
ad	O
=	O
medi|ei|	O
,	O
and	O
multiplying	O
it	O
by	O
1.4	O
to	O
obtain	O
a	O
robust	B
estimate	O
of	O
the	O
standard	O
deviation	O
of	O
the	O
inlier	O
noise	B
process	O
(	O
stewart	O
1999	O
)	O
.	O
spatially	O
varying	O
weights	O
.	O
the	O
error	O
metrics	O
above	O
ignore	O
that	O
fact	O
that	O
for	O
a	O
given	O
align-	O
ment	O
,	O
some	O
of	O
the	O
pixels	O
being	O
compared	O
may	O
lie	O
outside	O
the	O
original	O
image	B
boundaries	O
.	O
furthermore	O
,	O
we	O
may	O
want	O
to	O
partially	O
or	O
completely	O
downweight	O
the	O
contributions	O
of	O
cer-	O
tain	O
pixels	O
.	O
for	O
example	O
,	O
we	O
may	O
want	O
to	O
selectively	O
“	O
erase	O
”	O
some	O
parts	O
of	O
an	O
image	B
from	O
consideration	O
when	O
stitching	O
a	O
mosaic	O
where	O
unwanted	O
foreground	O
objects	O
have	O
been	O
cut	O
out	O
.	O
for	O
applications	O
such	O
as	O
background	O
stabilization	O
,	O
we	O
may	O
want	O
to	O
downweight	O
the	O
middle	O
part	O
of	O
the	O
image	B
,	O
which	O
often	O
contains	O
independently	O
moving	O
objects	O
being	O
tracked	O
by	O
the	O
camera	B
.	O
all	O
of	O
these	O
tasks	O
can	O
be	O
accomplished	O
by	O
associating	O
a	O
spatially	O
varying	O
per-pixel	O
weight	O
value	O
with	O
each	O
of	O
the	O
two	O
images	O
being	O
matched	O
.	O
the	O
error	O
metric	O
then	O
becomes	O
the	O
weighted	B
(	O
or	O
windowed	B
)	O
ssd	O
function	O
,	O
ewssd	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
w0	O
(	O
xi	O
)	O
w1	O
(	O
xi	O
+	O
u	O
)	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
,	O
(	O
8.5	O
)	O
where	O
the	O
weighting	B
functions	O
w0	O
and	O
w1	O
are	O
zero	O
outside	O
the	O
image	B
boundaries	O
.	O
if	O
a	O
large	O
range	O
of	O
potential	O
motions	O
is	O
allowed	O
,	O
the	O
above	O
metric	O
can	O
have	O
a	O
bias	O
towards	O
smaller	O
overlap	O
solutions	O
.	O
to	O
counteract	O
this	O
bias	O
,	O
the	O
windowed	B
ssd	O
score	O
can	O
be	O
divided	O
by	O
the	O
overlap	O
area	O
w0	O
(	O
xi	O
)	O
w1	O
(	O
xi	O
+	O
u	O
)	O
(	O
8.6	O
)	O
to	O
compute	O
a	O
per-pixel	O
(	O
or	O
mean	O
)	O
squared	O
pixel	O
error	O
ewssd/a	O
.	O
the	O
square	B
root	I
of	O
this	O
quantity	O
is	O
the	O
root	O
mean	O
square	O
intensity	O
error	O
often	O
reported	O
in	O
comparative	O
studies	O
.	O
rm	O
s	O
=	O
(	O
cid:112	O
)	O
ewssd/a	O
(	O
8.7	O
)	O
a	O
=	O
(	O
cid:88	O
)	O
i	O
386	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
bias	B
and	I
gain	I
(	O
exposure	O
differences	O
)	O
.	O
often	O
,	O
the	O
two	O
images	O
being	O
aligned	O
were	O
not	O
taken	O
with	O
the	O
same	O
exposure	O
.	O
a	O
simple	O
model	O
of	O
linear	B
(	O
afﬁne	B
)	O
intensity	O
variation	O
between	O
the	O
two	O
images	O
is	O
the	O
bias	B
and	I
gain	I
model	O
,	O
i1	O
(	O
x	O
+	O
u	O
)	O
=	O
(	O
1	O
+	O
α	O
)	O
i0	O
(	O
x	O
)	O
+	O
β	O
,	O
(	O
8.8	O
)	O
where	O
β	O
is	O
the	O
bias	O
and	O
α	O
is	O
the	O
gain	O
(	O
lucas	O
and	O
kanade	O
1981	O
;	O
gennert	O
1988	O
;	O
fuh	O
and	O
maragos	O
1991	O
;	O
baker	O
,	O
gross	O
,	O
and	O
matthews	O
2003	O
;	O
evangelidis	O
and	O
psarakis	O
2008	O
)	O
.	O
the	O
least	B
squares	I
formulation	O
then	O
becomes	O
ebg	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
(	O
1	O
+	O
α	O
)	O
i0	O
(	O
xi	O
)	O
−	O
β	O
]	O
2	O
=	O
(	O
cid:88	O
)	O
i	O
[	O
αi0	O
(	O
xi	O
)	O
+	O
β	O
−	O
ei	O
]	O
2	O
.	O
(	O
8.9	O
)	O
rather	O
than	O
taking	O
a	O
simple	O
squared	O
difference	B
between	O
corresponding	O
patches	O
,	O
it	O
becomes	O
necessary	O
to	O
perform	O
a	O
linear	B
regression	O
(	O
appendix	O
a.2	O
)	O
,	O
which	O
is	O
somewhat	O
more	O
costly	O
.	O
note	O
that	O
for	O
color	O
images	O
,	O
it	O
may	O
be	O
necessary	O
to	O
estimate	O
a	O
different	O
bias	B
and	I
gain	I
for	O
each	O
color	B
channel	O
to	O
compensate	O
for	O
the	O
automatic	B
color	O
correction	O
performed	O
by	O
some	O
digital	O
cameras	O
(	O
section	O
2.3.2	O
)	O
.	O
bias	B
and	I
gain	I
compensation	O
is	O
also	O
used	O
in	O
video	B
codecs	O
,	O
where	O
it	O
is	O
known	O
as	O
weighted	B
prediction	O
(	O
richardson	O
2003	O
)	O
.	O
a	O
more	O
general	O
(	O
spatially	O
varying	O
,	O
non-parametric	B
)	O
model	O
of	O
intensity	O
variation	O
,	O
which	O
is	O
computed	O
as	O
part	O
of	O
the	O
registration	B
process	O
,	O
is	O
used	O
in	O
(	O
negahdaripour	O
1998	O
;	O
jia	O
and	O
tang	O
2003	O
;	O
seitz	O
and	O
baker	O
2009	O
)	O
.	O
this	O
can	O
be	O
useful	O
for	O
dealing	O
with	O
local	O
variations	O
such	O
as	O
the	O
vignetting	B
caused	O
by	O
wide-angle	O
lenses	O
,	O
wide	O
apertures	O
,	O
or	O
lens	O
housings	O
.	O
it	O
is	O
also	O
pos-	O
sible	O
to	O
pre-process	O
the	O
images	O
before	O
comparing	O
their	O
values	O
,	O
e.g.	O
,	O
using	O
band-pass	O
ﬁltered	O
images	O
(	O
anandan	O
1989	O
;	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
)	O
,	O
gradients	O
(	O
scharstein	O
1994	O
;	O
papenberg	O
,	O
bruhn	O
,	O
brox	O
et	O
al	O
.	O
2006	O
)	O
,	O
or	O
using	O
other	O
local	B
transformations	O
such	O
as	O
histograms	O
or	O
rank	O
transforms	O
(	O
cox	O
,	O
roy	O
,	O
and	O
hingorani	O
1995	O
;	O
zabih	O
and	O
woodﬁll	O
1994	O
)	O
,	O
or	O
to	O
max-	O
imize	O
mutual	O
information	O
(	O
viola	O
and	O
wells	O
iii	O
1997	O
;	O
kim	O
,	O
kolmogorov	O
,	O
and	O
zabih	O
2003	O
)	O
.	O
hirschm¨uller	O
and	O
scharstein	O
(	O
2009	O
)	O
compare	O
a	O
number	O
of	O
these	O
approaches	O
and	O
report	O
on	O
their	O
relative	O
performance	O
in	O
scenes	O
with	O
exposure	O
differences	O
.	O
correlation	O
.	O
an	O
alternative	O
to	O
taking	O
intensity	O
differences	O
is	O
to	O
perform	O
correlation	O
,	O
i.e.	O
,	O
to	O
maximize	O
the	O
product	O
(	O
or	O
cross-correlation	O
)	O
of	O
the	O
two	O
aligned	O
images	O
,	O
ecc	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
i0	O
(	O
xi	O
)	O
i1	O
(	O
xi	O
+	O
u	O
)	O
.	O
(	O
8.10	O
)	O
at	O
ﬁrst	O
glance	O
,	O
this	O
may	O
appear	O
to	O
make	O
bias	B
and	I
gain	I
modeling	O
unnecessary	O
,	O
since	O
the	O
images	O
will	O
prefer	O
to	O
line	O
up	O
regardless	O
of	O
their	O
relative	O
scales	O
and	O
offsets	O
.	O
however	O
,	O
this	O
is	O
actually	O
not	O
true	O
.	O
if	O
a	O
very	O
bright	O
patch	B
exists	O
in	O
i1	O
(	O
x	O
)	O
,	O
the	O
maximum	O
product	O
may	O
actually	O
lie	O
in	O
that	O
area	O
.	O
8.1	O
translational	B
alignment	O
for	O
this	O
reason	O
,	O
normalized	B
cross-correlation	O
is	O
more	O
commonly	O
used	O
,	O
encc	O
(	O
u	O
)	O
=	O
(	O
cid:80	O
)	O
i	O
[	O
i0	O
(	O
xi	O
)	O
−	O
i0	O
]	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i1	O
]	O
(	O
cid:113	O
)	O
(	O
cid:80	O
)	O
i	O
[	O
i0	O
(	O
xi	O
)	O
−	O
i0	O
]	O
2	O
(	O
cid:113	O
)	O
(	O
cid:80	O
)	O
i	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i1	O
]	O
2	O
,	O
where	O
i0	O
=	O
i1	O
=	O
i0	O
(	O
xi	O
)	O
and	O
i1	O
(	O
xi	O
+	O
u	O
)	O
1	O
n	O
(	O
cid:88	O
)	O
i	O
n	O
(	O
cid:88	O
)	O
i	O
1	O
387	O
(	O
8.11	O
)	O
(	O
8.12	O
)	O
(	O
8.13	O
)	O
are	O
the	O
mean	O
images	O
of	O
the	O
corresponding	O
patches	O
and	O
n	O
is	O
the	O
number	O
of	O
pixels	O
in	O
the	O
patch	B
.	O
the	O
normalized	B
cross-correlation	O
score	O
is	O
always	O
guaranteed	O
to	O
be	O
in	O
the	O
range	O
[	O
−1	O
,	O
1	O
]	O
,	O
which	O
makes	O
it	O
easier	O
to	O
handle	O
in	O
some	O
higher-level	O
applications	O
,	O
such	O
as	O
deciding	O
which	O
patches	O
truly	O
match	O
.	O
normalized	B
correlation	O
works	O
well	O
when	O
matching	B
images	O
taken	O
with	O
different	O
exposures	O
,	O
e.g.	O
,	O
when	O
creating	O
high	B
dynamic	I
range	I
images	O
(	O
section	O
10.2	O
)	O
.	O
note	O
,	O
however	O
,	O
that	O
the	O
ncc	O
score	O
is	O
undeﬁned	O
if	O
either	O
of	O
the	O
two	O
patches	O
has	O
zero	O
variance	O
(	O
and	O
,	O
in	O
fact	O
,	O
its	O
performance	O
degrades	O
for	O
noisy	O
low-contrast	O
regions	O
)	O
.	O
a	O
variant	O
on	O
ncc	O
,	O
which	O
is	O
related	O
to	O
the	O
bias–gain	O
regression	O
implicit	O
in	O
the	O
matching	B
score	O
(	O
8.9	O
)	O
,	O
is	O
the	O
normalized	B
ssd	O
score	O
enssd	O
(	O
u	O
)	O
=	O
1	O
2	O
(	O
cid:80	O
)	O
i	O
(	O
cid:2	O
)	O
[	O
i0	O
(	O
xi	O
)	O
−	O
i0	O
]	O
−	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i1	O
]	O
(	O
cid:3	O
)	O
2	O
(	O
cid:113	O
)	O
(	O
cid:80	O
)	O
i	O
[	O
i0	O
(	O
xi	O
)	O
−	O
i0	O
]	O
2	O
+	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i1	O
]	O
2	O
(	O
8.14	O
)	O
recently	O
proposed	O
by	O
criminisi	O
,	O
shotton	O
,	O
blake	O
et	O
al	O
.	O
(	O
2007	O
)	O
.	O
in	O
their	O
experiments	O
,	O
they	O
ﬁnd	O
that	O
it	O
produces	O
comparable	O
results	O
to	O
ncc	O
,	O
but	O
is	O
more	O
efﬁcient	O
when	O
applied	O
to	O
a	O
large	O
number	O
of	O
overlapping	O
patches	O
using	O
a	O
moving	B
average	I
technique	O
(	O
section	O
3.2.2	O
)	O
.	O
8.1.1	O
hierarchical	B
motion	O
estimation	B
now	O
that	O
we	O
have	O
a	O
well-deﬁned	O
alignment	B
cost	O
function	O
to	O
optimize	O
,	O
how	O
can	O
we	O
ﬁnd	O
its	O
minimum	O
?	O
the	O
simplest	O
solution	O
is	O
to	O
do	O
a	O
full	O
search	O
over	O
some	O
range	O
of	O
shifts	O
,	O
using	O
ei-	O
ther	O
integer	O
or	O
sub-pixel	O
steps	O
.	O
this	O
is	O
often	O
the	O
approach	O
used	O
for	O
block	O
matching	B
in	O
motion	B
compensated	I
video	O
compression	B
,	O
where	O
a	O
range	O
of	O
possible	O
motions	O
(	O
say	O
,	O
±16	O
pixels	O
)	O
is	O
ex-	O
plored.4	O
to	O
accelerate	O
this	O
search	O
process	O
,	O
hierarchical	B
motion	O
estimation	B
is	O
often	O
used	O
:	O
an	O
image	B
pyramid	O
(	O
section	O
3.5	O
)	O
is	O
constructed	O
and	O
a	O
search	O
over	O
a	O
smaller	O
number	O
of	O
discrete	B
pixels	O
4	O
in	O
stereo	B
matching	I
(	O
section	O
11.1.2	O
)	O
,	O
an	O
explicit	O
search	O
over	O
all	O
possible	O
disparities	O
(	O
i.e.	O
,	O
a	O
plane	B
sweep	I
)	O
is	O
almost	O
always	O
performed	O
,	O
since	O
the	O
number	O
of	O
search	O
hypotheses	O
is	O
much	O
smaller	O
due	O
to	O
the	O
1d	O
nature	O
of	O
the	O
potential	O
displacements	O
.	O
388	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
corresponding	O
to	O
the	O
same	O
range	O
of	O
motion	B
)	O
is	O
ﬁrst	O
performed	O
at	O
coarser	O
levels	O
(	O
quam	O
1984	O
;	O
anandan	O
1989	O
;	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
)	O
.	O
the	O
motion	B
estimate	O
from	O
one	O
level	O
of	O
the	O
pyramid	B
is	O
then	O
used	O
to	O
initialize	O
a	O
smaller	O
local	B
search	O
at	O
the	O
next	O
ﬁner	O
level	O
.	O
al-	O
ternatively	O
,	O
several	O
seeds	O
(	O
good	O
solutions	O
)	O
from	O
the	O
coarse	O
level	O
can	O
be	O
used	O
to	O
initialize	O
the	O
ﬁne-level	O
search	O
.	O
while	O
this	O
is	O
not	O
guaranteed	O
to	O
produce	O
the	O
same	O
result	O
as	O
a	O
full	O
search	O
,	O
it	O
usually	O
works	O
almost	O
as	O
well	O
and	O
is	O
much	O
faster	O
.	O
more	O
formally	O
,	O
let	O
k	O
(	O
xj	O
)	O
←	O
˜i	O
(	O
l−1	O
)	O
i	O
(	O
l	O
)	O
k	O
(	O
2xj	O
)	O
(	O
8.15	O
)	O
be	O
the	O
decimated	O
image	B
at	O
level	O
l	O
obtained	O
by	O
subsampling	O
(	O
downsampling	O
)	O
a	O
smoothed	O
ver-	O
sion	O
of	O
the	O
image	B
at	O
level	O
l−1	O
.	O
see	O
section	O
3.5	O
for	O
how	O
to	O
perform	O
the	O
required	O
downsampling	O
(	O
pyramid	B
construction	O
)	O
without	O
introducing	O
too	O
much	O
aliasing	B
.	O
at	O
the	O
coarsest	O
level	O
,	O
we	O
search	O
for	O
the	O
best	O
displacement	O
u	O
(	O
l	O
)	O
that	O
minimizes	O
the	O
dif-	O
ference	O
between	O
images	O
i	O
(	O
l	O
)	O
1	O
.	O
this	O
is	O
usually	O
done	O
using	O
a	O
full	O
search	O
over	O
some	O
0	O
range	O
of	O
displacements	O
u	O
(	O
l	O
)	O
∈	O
2−l	O
[	O
−s	O
,	O
s	O
]	O
2	O
,	O
where	O
s	O
is	O
the	O
desired	O
search	O
range	O
at	O
the	O
ﬁnest	O
(	O
original	O
)	O
resolution	O
level	O
,	O
optionally	O
followed	O
by	O
the	O
incremental	B
reﬁnement	I
step	O
described	O
in	O
section	O
8.1.3.	O
and	O
i	O
(	O
l	O
)	O
once	O
a	O
suitable	O
motion	B
vector	O
has	O
been	O
estimated	O
,	O
it	O
is	O
used	O
to	O
predict	O
a	O
likely	O
displace-	O
ment	O
ˆu	O
(	O
l−1	O
)	O
←	O
2u	O
(	O
l	O
)	O
(	O
8.16	O
)	O
for	O
the	O
next	O
ﬁner	O
level.5	O
the	O
search	O
over	O
displacements	O
is	O
then	O
repeated	O
at	O
the	O
ﬁner	O
level	O
over	O
a	O
much	O
narrower	O
range	O
of	O
displacements	O
,	O
say	O
ˆu	O
(	O
l−1	O
)	O
±	O
1	O
,	O
again	O
optionally	O
combined	O
with	O
an	O
incremental	B
reﬁnement	I
step	O
(	O
anandan	O
1989	O
)	O
.	O
alternatively	O
,	O
one	O
of	O
the	O
images	O
can	O
be	O
warped	O
(	O
resampled	O
)	O
by	O
the	O
current	O
motion	B
estimate	O
,	O
in	O
which	O
case	O
only	O
small	O
incremental	B
motions	O
need	O
to	O
be	O
computed	O
at	O
the	O
ﬁner	O
level	O
.	O
a	O
nice	O
description	O
of	O
the	O
whole	O
process	O
,	O
extended	O
to	O
parametric	B
motion	O
estimation	B
(	O
section	O
8.2	O
)	O
,	O
is	O
provided	O
by	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
(	O
1992	O
)	O
.	O
8.1.2	O
fourier-based	O
alignment	B
when	O
the	O
search	O
range	O
corresponds	O
to	O
a	O
signiﬁcant	O
fraction	O
of	O
the	O
larger	O
image	B
(	O
as	O
is	O
the	O
case	O
in	O
image	B
stitching	I
,	O
see	O
chapter	O
9	O
)	O
,	O
the	O
hierarchical	B
approach	O
may	O
not	O
work	O
that	O
well	O
,	O
since	O
it	O
is	O
often	O
not	O
possible	O
to	O
coarsen	O
the	O
representation	O
too	O
much	O
before	O
signiﬁcant	O
features	O
are	O
blurred	O
away	O
.	O
in	O
this	O
case	O
,	O
a	O
fourier-based	O
approach	O
may	O
be	O
preferable	O
.	O
5	O
this	O
doubling	O
of	O
displacements	O
is	O
only	O
necessary	O
if	O
displacements	O
are	O
deﬁned	O
in	O
integer	O
pixel	O
coordinates	O
,	O
which	O
is	O
the	O
usual	O
case	O
in	O
the	O
literature	O
(	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
)	O
.	O
if	O
normalized	B
device	O
coordinates	O
(	O
section	O
2.1.5	O
)	O
are	O
used	O
instead	O
,	O
the	O
displacements	O
(	O
and	O
search	O
ranges	O
)	O
need	O
not	O
change	O
from	O
level	O
to	O
level	O
,	O
although	O
the	O
step	O
sizes	O
will	O
need	O
to	O
be	O
adjusted	O
,	O
to	O
keep	O
search	O
steps	O
of	O
roughly	O
one	O
pixel	O
.	O
8.1	O
translational	B
alignment	O
389	O
fourier-based	O
alignment	B
relies	O
on	O
the	O
fact	O
that	O
the	O
fourier	O
transform	B
of	O
a	O
shifted	O
signal	O
has	O
the	O
same	O
magnitude	O
as	O
the	O
original	O
signal	O
but	O
a	O
linearly	O
varying	O
phase	O
(	O
section	O
3.4	O
)	O
,	O
i.e.	O
,	O
f	O
{	O
i1	O
(	O
x	O
+	O
u	O
)	O
}	O
=	O
f	O
{	O
i1	O
(	O
x	O
)	O
}	O
e−ju·ω	O
=	O
i1	O
(	O
ω	O
)	O
e−ju·ω	O
,	O
(	O
8.17	O
)	O
where	O
ω	O
is	O
the	O
vector-valued	O
angular	O
frequency	O
of	O
the	O
fourier	O
transform	B
and	O
we	O
use	O
cal-	O
ligraphic	O
notation	O
i1	O
(	O
ω	O
)	O
=	O
f	O
{	O
i1	O
(	O
x	O
)	O
}	O
to	O
denote	O
the	O
fourier	O
transform	B
of	O
a	O
signal	O
(	O
sec-	O
tion	B
3.4	O
)	O
.	O
another	O
useful	O
property	O
of	O
fourier	O
transforms	O
is	O
that	O
convolution	O
in	O
the	O
spatial	O
domain	O
corresponds	O
to	O
multiplication	B
in	O
the	O
fourier	O
domain	O
(	O
section	O
3.4	O
)	O
.6	O
thus	O
,	O
the	O
fourier	O
trans-	O
form	O
of	O
the	O
cross-correlation	O
function	O
ecc	O
can	O
be	O
written	O
as	O
f	O
{	O
ecc	O
(	O
u	O
)	O
}	O
=	O
f	O
(	O
cid:40	O
)	O
(	O
cid:88	O
)	O
i	O
where	O
i0	O
(	O
xi	O
)	O
i1	O
(	O
xi	O
+	O
u	O
)	O
(	O
cid:41	O
)	O
=	O
f	O
{	O
i0	O
(	O
u	O
)	O
¯∗i1	O
(	O
u	O
)	O
}	O
=	O
i0	O
(	O
ω	O
)	O
i∗1	O
(	O
ω	O
)	O
,	O
f	O
(	O
u	O
)	O
¯∗g	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
f	O
(	O
xi	O
)	O
g	O
(	O
xi	O
+	O
u	O
)	O
(	O
8.18	O
)	O
(	O
8.19	O
)	O
is	O
the	O
correlation	O
function	O
,	O
i.e.	O
,	O
the	O
convolution	O
of	O
one	O
signal	O
with	O
the	O
reverse	O
of	O
the	O
other	O
,	O
and	O
i∗1	O
(	O
ω	O
)	O
is	O
the	O
complex	O
conjugate	O
of	O
i1	O
(	O
ω	O
)	O
.	O
this	O
is	O
because	O
convolution	O
is	O
deﬁned	O
as	O
the	O
summation	O
of	O
one	O
signal	O
with	O
the	O
reverse	O
of	O
the	O
other	O
(	O
section	O
3.4	O
)	O
.	O
thus	O
,	O
to	O
efﬁciently	O
evaluate	O
ecc	O
over	O
the	O
range	O
of	O
all	O
possible	O
values	O
of	O
u	O
,	O
we	O
take	O
the	O
fourier	O
transforms	O
of	O
both	O
images	O
i0	O
(	O
x	O
)	O
and	O
i1	O
(	O
x	O
)	O
,	O
multiply	O
both	O
transforms	O
together	O
(	O
after	O
conjugating	O
the	O
second	O
one	O
)	O
,	O
and	O
take	O
the	O
inverse	B
transform	O
of	O
the	O
result	O
.	O
the	O
fast	O
fourier	O
transform	B
algorithm	O
can	O
compute	O
the	O
transform	B
of	O
an	O
n	O
×	O
m	O
image	B
in	O
o	O
(	O
n	O
m	O
log	O
n	O
m	O
)	O
operations	O
(	O
bracewell	O
1986	O
)	O
.	O
this	O
can	O
be	O
signiﬁcantly	O
faster	O
than	O
the	O
o	O
(	O
n	O
2m	O
2	O
)	O
operations	O
required	O
to	O
do	O
a	O
full	O
search	O
when	O
the	O
full	O
range	O
of	O
image	B
overlaps	O
is	O
considered	O
.	O
while	O
fourier-based	O
convolution	O
is	O
often	O
used	O
to	O
accelerate	O
the	O
computation	O
of	O
image	B
correlations	O
,	O
it	O
can	O
also	O
be	O
used	O
to	O
accelerate	O
the	O
sum	O
of	O
squared	O
differences	O
function	O
(	O
and	O
its	O
variants	O
)	O
.	O
consider	O
the	O
ssd	O
formula	O
given	O
in	O
(	O
8.1	O
)	O
.	O
its	O
fourier	O
transform	B
can	O
be	O
written	O
as	O
f	O
{	O
essd	O
(	O
u	O
)	O
}	O
=	O
f	O
(	O
cid:40	O
)	O
(	O
cid:88	O
)	O
i	O
=	O
δ	O
(	O
ω	O
)	O
(	O
cid:88	O
)	O
i	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
(	O
cid:41	O
)	O
[	O
i	O
2	O
0	O
(	O
xi	O
)	O
+	O
i	O
2	O
1	O
(	O
xi	O
)	O
]	O
−	O
2i0	O
(	O
ω	O
)	O
i∗1	O
(	O
ω	O
)	O
.	O
(	O
8.20	O
)	O
thus	O
,	O
the	O
ssd	O
function	O
can	O
be	O
computed	O
by	O
taking	O
twice	O
the	O
correlation	O
function	O
and	O
sub-	O
tracting	O
it	O
from	O
the	O
sum	O
of	O
the	O
energies	O
in	O
the	O
two	O
images	O
.	O
6	O
in	O
fact	O
,	O
the	O
fourier	O
shift	O
property	O
(	O
8.17	O
)	O
derives	O
from	O
the	O
convolution	O
theorem	O
by	O
observing	O
that	O
shifting	O
is	O
equivalent	O
to	O
convolution	O
with	O
a	O
displaced	O
delta	O
function	O
δ	O
(	O
x	O
−	O
u	O
)	O
.	O
390	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
windowed	B
correlation	O
.	O
unfortunately	O
,	O
the	O
fourier	O
convolution	O
theorem	O
only	O
applies	O
when	O
the	O
summation	O
over	O
xi	O
is	O
performed	O
over	O
all	O
the	O
pixels	O
in	O
both	O
images	O
,	O
using	O
a	O
circular	O
shift	O
of	O
the	O
image	B
when	O
accessing	O
pixels	O
outside	O
the	O
original	O
boundaries	O
.	O
while	O
this	O
is	O
acceptable	O
for	O
small	O
shifts	O
and	O
comparably	O
sized	O
images	O
,	O
it	O
makes	O
no	O
sense	O
when	O
the	O
images	O
overlap	O
by	O
a	O
small	O
amount	O
or	O
one	O
image	B
is	O
a	O
small	O
subset	O
of	O
the	O
other	O
.	O
in	O
that	O
case	O
,	O
the	O
cross-correlation	O
function	O
should	O
be	O
replaced	O
with	O
a	O
windowed	B
(	O
weighted	B
)	O
cross-correlation	O
function	O
,	O
ewcc	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
w0	O
(	O
xi	O
)	O
i0	O
(	O
xi	O
)	O
w1	O
(	O
xi	O
+	O
u	O
)	O
i1	O
(	O
xi	O
+	O
u	O
)	O
,	O
=	O
[	O
w0	O
(	O
x	O
)	O
i0	O
(	O
x	O
)	O
]	O
¯∗	O
[	O
w1	O
(	O
x	O
)	O
i1	O
(	O
x	O
)	O
]	O
(	O
8.21	O
)	O
(	O
8.22	O
)	O
where	O
the	O
weighting	B
functions	O
w0	O
and	O
w1	O
are	O
zero	O
outside	O
the	O
valid	O
ranges	O
of	O
the	O
images	O
and	O
both	O
images	O
are	O
padded	O
so	O
that	O
circular	O
shifts	O
return	O
0	O
values	O
outside	O
the	O
original	O
image	B
boundaries	O
.	O
an	O
even	O
more	O
interesting	O
case	O
is	O
the	O
computation	O
of	O
the	O
weighted	B
ssd	O
function	O
intro-	O
duced	O
in	O
equation	B
(	O
8.5	O
)	O
,	O
ewssd	O
(	O
u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
w0	O
(	O
xi	O
)	O
w1	O
(	O
xi	O
+	O
u	O
)	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
.	O
(	O
8.23	O
)	O
expanding	O
this	O
as	O
a	O
sum	O
of	O
correlations	O
and	O
deriving	O
the	O
appropriate	O
set	O
of	O
fourier	O
transforms	O
is	O
left	O
for	O
exercise	O
8.1.	O
the	O
same	O
kind	O
of	O
derivation	O
can	O
also	O
be	O
applied	O
to	O
the	O
bias–gain	O
corrected	O
sum	O
of	O
squared	O
difference	B
function	O
ebg	O
(	O
8.9	O
)	O
.	O
again	O
,	O
fourier	O
transforms	O
can	O
be	O
used	O
to	O
efﬁciently	O
compute	O
all	O
the	O
correlations	O
needed	O
to	O
perform	O
the	O
linear	B
regression	O
in	O
the	O
bias	B
and	I
gain	I
parameters	O
in	O
order	B
to	O
estimate	O
the	O
exposure-compensated	O
difference	B
for	O
each	O
potential	O
shift	O
(	O
exercise	O
8.1	O
)	O
.	O
phase	B
correlation	I
.	O
a	O
variant	O
of	O
regular	O
correlation	O
(	O
8.18	O
)	O
that	O
is	O
sometimes	O
used	O
for	O
motion	O
estimation	B
is	O
phase	B
correlation	I
(	O
kuglin	O
and	O
hines	O
1975	O
;	O
brown	O
1992	O
)	O
.	O
here	O
,	O
the	O
spectrum	O
of	O
the	O
two	O
signals	O
being	O
matched	O
is	O
whitened	O
by	O
dividing	O
each	O
per-frequency	O
product	O
in	O
(	O
8.18	O
)	O
by	O
the	O
magnitudes	O
of	O
the	O
fourier	O
transforms	O
,	O
f	O
{	O
epc	O
(	O
u	O
)	O
}	O
=	O
i0	O
(	O
ω	O
)	O
i∗1	O
(	O
ω	O
)	O
(	O
cid:107	O
)	O
i0	O
(	O
ω	O
)	O
(	O
cid:107	O
)	O
(	O
cid:107	O
)	O
i1	O
(	O
ω	O
)	O
(	O
cid:107	O
)	O
(	O
8.24	O
)	O
before	O
taking	O
the	O
ﬁnal	O
inverse	B
fourier	O
transform	B
.	O
in	O
the	O
case	O
of	O
noiseless	O
signals	O
with	O
perfect	O
(	O
cyclic	O
)	O
shift	O
,	O
we	O
have	O
i1	O
(	O
x	O
+	O
u	O
)	O
=	O
i0	O
(	O
x	O
)	O
and	O
hence	O
,	O
from	O
equation	B
(	O
8.17	O
)	O
,	O
we	O
obtain	O
f	O
{	O
i1	O
(	O
x	O
+	O
u	O
)	O
}	O
=	O
i1	O
(	O
ω	O
)	O
e−2πju·ω	O
=	O
i0	O
(	O
ω	O
)	O
and	O
f	O
{	O
epc	O
(	O
u	O
)	O
}	O
=	O
e−2πju·ω	O
.	O
(	O
8.25	O
)	O
8.1	O
translational	B
alignment	O
391	O
the	O
output	O
of	O
phase	B
correlation	I
(	O
under	O
ideal	O
conditions	O
)	O
is	O
therefore	O
a	O
single	O
spike	O
(	O
impulse	O
)	O
located	O
at	O
the	O
correct	O
value	O
of	O
u	O
,	O
which	O
(	O
in	O
principle	O
)	O
makes	O
it	O
easier	O
to	O
ﬁnd	O
the	O
correct	O
estimate	O
.	O
phase	B
correlation	I
has	O
a	O
reputation	O
in	O
some	O
quarters	O
of	O
outperforming	O
regular	O
correlation	O
,	O
but	O
this	O
behavior	O
depends	O
on	O
the	O
characteristics	O
of	O
the	O
signals	O
and	O
noise	B
.	O
if	O
the	O
original	O
images	O
are	O
contaminated	O
by	O
noise	O
in	O
a	O
narrow	O
frequency	O
band	O
(	O
e.g.	O
,	O
low-frequency	O
noise	B
or	O
peaked	O
frequency	O
“	O
hum	O
”	O
)	O
,	O
the	O
whitening	O
process	O
effectively	O
de-emphasizes	O
the	O
noise	B
in	O
these	O
regions	O
.	O
however	O
,	O
if	O
the	O
original	O
signals	O
have	O
very	O
low	O
signal-to-noise	O
ratio	O
at	O
some	O
frequencies	O
(	O
say	O
,	O
two	O
blurry	O
or	O
low-textured	O
images	O
with	O
lots	O
of	O
high-frequency	O
noise	B
)	O
,	O
the	O
whitening	O
process	O
can	O
actually	O
decrease	O
performance	O
(	O
see	O
exercise	O
8.1	O
)	O
.	O
recently	O
,	O
gradient	O
cross-correlation	O
has	O
emerged	O
as	O
a	O
promising	O
alternative	O
to	O
phase	O
cor-	O
relation	O
(	O
argyriou	O
and	O
vlachos	O
2003	O
)	O
,	O
although	O
further	O
systematic	O
studies	O
are	O
probably	O
war-	O
ranted	O
.	O
phase	B
correlation	I
has	O
also	O
been	O
studied	O
by	O
fleet	O
and	O
jepson	O
(	O
1990	O
)	O
as	O
a	O
method	O
for	O
estimating	O
general	O
optical	B
ﬂow	I
and	O
stereo	B
disparity	O
.	O
rotations	B
and	I
scale	I
.	O
while	O
fourier-based	O
alignment	B
is	O
mostly	O
used	O
to	O
estimate	O
transla-	O
tional	O
shifts	O
between	O
images	O
,	O
it	O
can	O
,	O
under	O
certain	O
limited	O
conditions	O
,	O
also	O
be	O
used	O
to	O
estimate	O
in-plane	O
rotations	O
and	O
scales	O
.	O
consider	O
two	O
images	O
that	O
are	O
related	O
purely	O
by	O
rotation	O
,	O
i.e.	O
,	O
i1	O
(	O
ˆrx	O
)	O
=	O
i0	O
(	O
x	O
)	O
.	O
(	O
8.26	O
)	O
if	O
we	O
re-sample	O
the	O
images	O
into	O
polar	O
coordinates	O
,	O
˜i0	O
(	O
r	O
,	O
θ	O
)	O
=	O
i0	O
(	O
r	O
cos	O
θ	O
,	O
r	O
sin	O
θ	O
)	O
and	O
˜i1	O
(	O
r	O
,	O
θ	O
)	O
=	O
i1	O
(	O
r	O
cos	O
θ	O
,	O
r	O
sin	O
θ	O
)	O
,	O
(	O
8.27	O
)	O
we	O
obtain	O
˜i1	O
(	O
r	O
,	O
θ	O
+	O
ˆθ	O
)	O
=	O
˜i0	O
(	O
r	O
,	O
θ	O
)	O
.	O
(	O
8.28	O
)	O
the	O
desired	O
rotation	O
can	O
then	O
be	O
estimated	O
using	O
a	O
fast	O
fourier	O
transform	B
(	O
fft	O
)	O
shift-based	O
technique	O
.	O
if	O
the	O
two	O
images	O
are	O
also	O
related	O
by	O
a	O
scale	O
,	O
i1	O
(	O
eˆs	O
ˆrx	O
)	O
=	O
i0	O
(	O
x	O
)	O
,	O
(	O
8.29	O
)	O
we	O
can	O
re-sample	O
into	O
log-polar	O
coordinates	O
,	O
˜i0	O
(	O
s	O
,	O
θ	O
)	O
=	O
i0	O
(	O
es	O
cos	O
θ	O
,	O
es	O
sin	O
θ	O
)	O
and	O
˜i1	O
(	O
s	O
,	O
θ	O
)	O
=	O
i1	O
(	O
es	O
cos	O
θ	O
,	O
es	O
sin	O
θ	O
)	O
,	O
(	O
8.30	O
)	O
to	O
obtain	O
˜i1	O
(	O
s	O
+	O
ˆs	O
,	O
θ	O
+	O
ˆθ	O
)	O
=	O
i0	O
(	O
s	O
,	O
θ	O
)	O
.	O
(	O
8.31	O
)	O
392	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
8.2	O
taylor	O
series	O
approximation	O
of	O
a	O
function	O
and	O
the	O
incremental	B
computation	O
of	O
the	O
optical	B
ﬂow	I
correction	O
amount	O
.	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
is	O
the	O
image	B
gradient	O
at	O
(	O
xi	O
+	O
u	O
)	O
and	O
ei	O
is	O
the	O
current	O
intensity	O
difference	B
.	O
in	O
this	O
case	O
,	O
care	O
must	O
be	O
taken	O
to	O
choose	O
a	O
suitable	O
range	O
of	O
s	O
values	O
that	O
reasonably	O
samples	O
the	O
original	O
image	B
.	O
for	O
images	O
that	O
are	O
also	O
translated	O
by	O
a	O
small	O
amount	O
,	O
i1	O
(	O
eˆs	O
ˆrx	O
+	O
t	O
)	O
=	O
i0	O
(	O
x	O
)	O
,	O
(	O
8.32	O
)	O
de	O
castro	O
and	O
morandi	O
(	O
1987	O
)	O
propose	O
an	O
ingenious	O
solution	O
that	O
uses	O
several	O
steps	O
to	O
esti-	O
mate	O
the	O
unknown	O
parameters	B
.	O
first	O
,	O
both	O
images	O
are	O
converted	O
to	O
the	O
fourier	O
domain	O
and	O
only	O
the	O
magnitudes	O
of	O
the	O
transformed	O
images	O
are	O
retained	O
.	O
in	O
principle	O
,	O
the	O
fourier	O
mag-	O
nitude	O
images	O
are	O
insensitive	O
to	O
translations	O
in	O
the	O
image	B
plane	O
(	O
although	O
the	O
usual	O
caveats	O
about	O
border	O
effects	O
apply	O
)	O
.	O
next	O
,	O
the	O
two	O
magnitude	O
images	O
are	O
aligned	O
in	O
rotation	O
and	O
scale	O
using	O
the	O
polar	O
or	O
log-polar	O
representations	O
.	O
once	O
rotation	O
and	O
scale	O
are	O
estimated	O
,	O
one	O
of	O
the	O
images	O
can	O
be	O
de-rotated	O
and	O
scaled	O
and	O
a	O
regular	O
translational	B
algorithm	O
can	O
be	O
applied	O
to	O
estimate	O
the	O
translational	B
shift	O
.	O
unfortunately	O
,	O
this	O
trick	O
only	O
applies	O
when	O
the	O
images	O
have	O
large	O
overlap	O
(	O
small	O
transla-	O
tional	O
motion	B
)	O
.	O
for	O
more	O
general	O
motion	B
of	O
patches	O
or	O
images	O
,	O
the	O
parametric	B
motion	O
estima-	O
tor	O
described	O
in	O
section	O
8.2	O
or	O
the	O
feature-based	B
approaches	O
described	O
in	O
section	O
6.1	O
need	O
to	O
be	O
used	O
.	O
8.1.3	O
incremental	B
reﬁnement	I
the	O
techniques	O
described	O
up	O
till	O
now	O
can	O
estimate	O
alignment	B
to	O
the	O
nearest	O
pixel	O
(	O
or	O
poten-	O
tially	O
fractional	O
pixel	O
if	O
smaller	O
search	O
steps	O
are	O
used	O
)	O
.	O
in	O
general	O
,	O
image	B
stabilization	O
and	O
stitching	O
applications	O
require	O
much	O
higher	O
accuracies	O
to	O
obtain	O
acceptable	O
results	O
.	O
to	O
obtain	O
better	O
sub-pixel	O
estimates	O
,	O
we	O
can	O
use	O
one	O
of	O
several	O
techniques	O
described	O
by	O
tian	O
and	O
huhns	O
(	O
1986	O
)	O
.	O
one	O
possibility	O
is	O
to	O
evaluate	O
several	O
discrete	B
(	O
integer	O
or	O
fractional	O
)	O
values	O
of	O
(	O
u	O
,	O
v	O
)	O
around	O
the	O
best	O
value	O
found	O
so	O
far	O
and	O
to	O
interpolate	O
the	O
matching	B
score	O
to	O
ﬁnd	O
an	O
analytic	O
minimum	O
.	O
ixeiδui0	O
(	O
xi	O
)	O
i1	O
(	O
xi+u	O
)	O
j1	O
(	O
xi+u	O
)	O
i0i1xi	O
8.1	O
translational	B
alignment	O
393	O
a	O
more	O
commonly	O
used	O
approach	O
,	O
ﬁrst	O
proposed	O
by	O
lucas	O
and	O
kanade	O
(	O
1981	O
)	O
,	O
is	O
to	O
perform	O
gradient	B
descent	I
on	O
the	O
ssd	O
energy	O
function	O
(	O
8.1	O
)	O
,	O
using	O
a	O
taylor	O
series	O
expansion	O
of	O
the	O
image	B
function	O
(	O
figure	O
8.2	O
)	O
,	O
elk−ssd	O
(	O
u	O
+	O
∆u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
≈	O
(	O
cid:88	O
)	O
i	O
=	O
(	O
cid:88	O
)	O
i	O
[	O
i1	O
(	O
xi	O
+	O
u	O
+	O
∆u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
[	O
i1	O
(	O
xi	O
+	O
u	O
)	O
+	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
∆u	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
[	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
∆u	O
+	O
ei	O
]	O
2	O
,	O
where	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
=	O
∇i1	O
(	O
xi	O
+	O
u	O
)	O
=	O
(	O
∂i1	O
∂x	O
,	O
∂i1	O
∂y	O
)	O
(	O
xi	O
+	O
u	O
)	O
is	O
the	O
image	B
gradient	O
or	O
jacobian	O
at	O
(	O
xi	O
+	O
u	O
)	O
and	O
ei	O
=	O
i1	O
(	O
xi	O
+	O
u	O
)	O
−	O
i0	O
(	O
xi	O
)	O
,	O
(	O
8.33	O
)	O
(	O
8.34	O
)	O
(	O
8.35	O
)	O
(	O
8.36	O
)	O
(	O
8.37	O
)	O
ﬁrst	O
introduced	O
in	O
(	O
8.1	O
)	O
,	O
is	O
the	O
current	O
intensity	O
error.7	O
the	O
gradient	O
at	O
a	O
particular	O
sub-pixel	O
location	O
(	O
xi	O
+	O
u	O
)	O
can	O
be	O
computed	O
using	O
a	O
variety	O
of	O
techniques	O
,	O
the	O
simplest	O
of	O
which	O
is	O
to	O
simply	O
take	O
the	O
horizontal	O
and	O
vertical	O
differences	O
between	O
pixels	O
x	O
and	O
x	O
+	O
(	O
1	O
,	O
0	O
)	O
or	O
x	O
+	O
(	O
0	O
,	O
1	O
)	O
.	O
more	O
sophisticated	O
derivatives	O
can	O
sometimes	O
lead	O
to	O
noticeable	O
performance	O
improvements	O
.	O
the	O
linearized	O
form	O
of	O
the	O
incremental	B
update	O
to	O
the	O
ssd	O
error	O
(	O
8.35	O
)	O
is	O
often	O
called	O
the	O
optical	B
ﬂow	I
constraint	O
or	O
brightness	O
constancy	O
constraint	B
equation	O
ixu	O
+	O
iyv	O
+	O
it	O
=	O
0	O
,	O
(	O
8.38	O
)	O
where	O
the	O
subscripts	O
in	O
ix	O
and	O
iy	O
denote	O
spatial	O
derivatives	O
,	O
and	O
it	O
is	O
called	O
the	O
temporal	O
derivative	O
,	O
which	O
makes	O
sense	O
if	O
we	O
are	O
computing	O
instantaneous	O
velocity	O
in	O
a	O
video	B
se-	O
quence	O
.	O
when	O
squared	O
and	O
summed	O
or	O
integrated	O
over	O
a	O
region	B
,	O
it	O
can	O
be	O
used	O
to	O
compute	O
optic	O
ﬂow	O
(	O
horn	O
and	O
schunck	O
1981	O
)	O
.	O
the	O
above	O
least	B
squares	I
problem	O
(	O
8.35	O
)	O
can	O
be	O
minimized	O
by	O
solving	O
the	O
associated	O
nor-	O
mal	O
equations	B
(	O
appendix	O
a.2	O
)	O
,	O
where	O
a∆u	O
=	O
b	O
a	O
=	O
(	O
cid:88	O
)	O
i	O
j	O
t	O
1	O
(	O
xi	O
+	O
u	O
)	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
(	O
8.39	O
)	O
(	O
8.40	O
)	O
7	O
we	O
follow	O
the	O
convention	O
,	O
commonly	O
used	O
in	O
robotics	O
and	O
by	O
baker	O
and	O
matthews	O
(	O
2004	O
)	O
,	O
that	O
derivatives	O
with	O
respect	O
to	O
(	O
column	O
)	O
vectors	O
result	O
in	O
row	O
vectors	O
,	O
so	O
that	O
fewer	O
transposes	O
are	O
needed	O
in	O
the	O
formulas	O
.	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
b	O
=	O
−	O
(	O
cid:88	O
)	O
i	O
eij	O
t	O
1	O
(	O
xi	O
+	O
u	O
)	O
(	O
8.41	O
)	O
394	O
and	O
are	O
called	O
the	O
(	O
gauss–newton	O
approximation	O
of	O
the	O
)	O
hessian	O
and	O
gradient-weighted	O
residual	O
vector	O
,	O
respectively.8	O
these	O
matrices	O
are	O
also	O
often	O
written	O
as	O
a	O
=	O
(	O
cid:34	O
)	O
(	O
cid:80	O
)	O
i	O
2	O
x	O
(	O
cid:80	O
)	O
ixiy	O
(	O
cid:80	O
)	O
ixiy	O
(	O
cid:80	O
)	O
i	O
2	O
y	O
(	O
cid:35	O
)	O
and	O
b	O
=	O
−	O
(	O
cid:34	O
)	O
(	O
cid:80	O
)	O
ixit	O
(	O
cid:80	O
)	O
iyit	O
(	O
cid:35	O
)	O
.	O
(	O
8.42	O
)	O
the	O
gradients	O
required	O
for	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
can	O
be	O
evaluated	O
at	O
the	O
same	O
time	O
as	O
the	O
image	B
warps	O
required	O
to	O
estimate	O
i1	O
(	O
xi	O
+	O
u	O
)	O
(	O
section	O
3.6.1	O
(	O
3.89	O
)	O
)	O
and	O
,	O
in	O
fact	O
,	O
are	O
often	O
computed	O
as	O
a	O
side-product	O
of	O
image	B
interpolation	O
.	O
if	O
efﬁciency	B
is	O
a	O
concern	O
,	O
these	O
gradients	O
can	O
be	O
replaced	O
by	O
the	O
gradients	O
in	O
the	O
template	O
image	B
,	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
≈	O
j	O
0	O
(	O
xi	O
)	O
,	O
(	O
8.43	O
)	O
since	O
near	O
the	O
correct	O
alignment	B
,	O
the	O
template	O
and	O
displaced	O
target	O
images	O
should	O
look	O
sim-	O
ilar	O
.	O
this	O
has	O
the	O
advantage	O
of	O
allowing	O
the	O
pre-computation	O
of	O
the	O
hessian	O
and	O
jacobian	O
images	O
,	O
which	O
can	O
result	O
in	O
signiﬁcant	O
computational	O
savings	O
(	O
hager	O
and	O
belhumeur	O
1998	O
;	O
baker	O
and	O
matthews	O
2004	O
)	O
.	O
a	O
further	O
reduction	O
in	O
computation	O
can	O
be	O
obtained	O
by	O
writing	O
the	O
warped	O
image	B
i1	O
(	O
xi	O
+	O
u	O
)	O
used	O
to	O
compute	O
ei	O
in	O
(	O
8.37	O
)	O
as	O
a	O
convolution	O
of	O
a	O
sub-pixel	O
interpolation	O
ﬁlter	O
with	O
the	O
discrete	B
samples	O
in	O
i1	O
(	O
peleg	O
and	O
rav-acha	O
2006	O
)	O
.	O
precomput-	O
ing	O
the	O
inner	O
product	O
between	O
the	O
gradient	O
ﬁeld	O
and	O
shifted	O
version	O
of	O
i1	O
allows	O
the	O
iterative	B
re-computation	O
of	O
ei	O
to	O
be	O
performed	O
in	O
constant	O
time	O
(	O
independent	O
of	O
the	O
number	O
of	O
pixels	O
)	O
.	O
the	O
effectiveness	O
of	O
the	O
above	O
incremental	B
update	O
rule	O
relies	O
on	O
the	O
quality	O
of	O
the	O
taylor	O
series	O
approximation	O
.	O
when	O
far	O
away	O
from	O
the	O
true	O
displacement	O
(	O
say	O
,	O
1–2	O
pixels	O
)	O
,	O
several	O
iterations	O
may	O
be	O
needed	O
.	O
it	O
is	O
possible	O
,	O
however	O
,	O
to	O
estimate	O
a	O
value	O
for	O
j	O
1	O
using	O
a	O
least	B
squares	I
ﬁt	O
to	O
a	O
series	O
of	O
larger	O
displacements	O
in	O
order	B
to	O
increase	O
the	O
range	O
of	O
convergence	O
(	O
jurie	O
and	O
dhome	O
2002	O
)	O
or	O
to	O
“	O
learn	O
”	O
a	O
special-purpose	O
recognizer	O
for	O
a	O
given	O
patch	B
(	O
avi-	O
dan	O
2001	O
;	O
williams	O
,	O
blake	O
,	O
and	O
cipolla	O
2003	O
;	O
lepetit	O
,	O
pilet	O
,	O
and	O
fua	O
2006	O
;	O
hinterstoisser	O
,	O
benhimane	O
,	O
navab	O
et	O
al	O
.	O
2008	O
;	O
¨ozuysal	O
,	O
calonder	O
,	O
lepetit	O
et	O
al	O
.	O
2010	O
)	O
as	O
discussed	O
in	O
sec-	O
tion	B
4.1.4.	O
a	O
commonly	O
used	O
stopping	O
criterion	O
for	O
incremental	O
updating	O
is	O
to	O
monitor	O
the	O
magnitude	O
of	O
the	O
displacement	O
correction	O
(	O
cid:107	O
)	O
u	O
(	O
cid:107	O
)	O
and	O
to	O
stop	O
when	O
it	O
drops	O
below	O
a	O
certain	O
threshold	O
(	O
say	O
,	O
1/10	O
of	O
a	O
pixel	O
)	O
.	O
for	O
larger	O
motions	O
,	O
it	O
is	O
usual	O
to	O
combine	O
the	O
incremental	B
update	O
rule	O
with	O
a	O
hierarchical	B
coarse-to-ﬁne	O
search	O
strategy	B
,	O
as	O
described	O
in	O
section	O
8.1.1	O
.	O
8	O
the	O
true	O
hessian	O
is	O
the	O
full	O
second	O
derivative	O
of	O
the	O
error	O
function	O
e	O
,	O
which	O
may	O
not	O
be	O
positive	O
deﬁnite—see	O
section	O
6.1.3	O
and	O
appendix	O
a.3	O
.	O
8.1	O
translational	B
alignment	O
395	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
8.3	O
aperture	O
problems	O
for	O
different	O
image	B
regions	O
,	O
denoted	O
by	O
the	O
orange	O
and	O
red	O
l-shaped	O
structures	O
,	O
overlaid	O
in	O
the	O
same	O
image	B
to	O
make	O
it	O
easier	O
to	O
diagram	O
the	O
ﬂow	O
.	O
(	O
a	O
)	O
a	O
window	O
w	O
(	O
xi	O
)	O
centered	O
at	O
xi	O
(	O
black	O
circle	O
)	O
can	O
uniquely	O
be	O
matched	O
to	O
its	O
corresponding	O
structure	O
at	O
xi	O
+	O
u	O
in	O
the	O
second	O
(	O
red	O
)	O
image	B
.	O
(	O
b	O
)	O
a	O
window	O
centered	O
on	O
the	O
edge	O
exhibits	O
the	O
classic	O
aperture	B
problem	I
,	O
since	O
it	O
can	O
be	O
matched	O
to	O
a	O
1d	O
family	O
of	O
possible	O
locations	O
.	O
(	O
c	O
)	O
in	O
a	O
completely	O
textureless	O
region	B
,	O
the	O
matches	O
become	O
totally	O
unconstrained	O
.	O
conditioning	O
and	O
aperture	O
problems	O
.	O
sometimes	O
,	O
the	O
inversion	O
of	O
the	O
linear	B
system	O
(	O
8.39	O
)	O
can	O
be	O
poorly	O
conditioned	O
because	O
of	O
lack	O
of	O
two-dimensional	B
texture	O
in	O
the	O
patch	B
being	O
aligned	O
.	O
a	O
commonly	O
occurring	O
example	O
of	O
this	O
is	O
the	O
aperture	B
problem	I
,	O
ﬁrst	O
identiﬁed	O
in	O
some	O
of	O
the	O
early	O
papers	O
on	O
optical	B
ﬂow	I
(	O
horn	O
and	O
schunck	O
1981	O
)	O
and	O
then	O
studied	O
more	O
ex-	O
tensively	O
by	O
anandan	O
(	O
1989	O
)	O
.	O
consider	O
an	O
image	B
patch	O
that	O
consists	O
of	O
a	O
slanted	O
edge	O
moving	O
to	O
the	O
right	O
(	O
figure	O
8.3	O
)	O
.	O
only	O
the	O
normal	O
component	O
of	O
the	O
velocity	O
(	O
displacement	O
)	O
can	O
be	O
reliably	O
recovered	O
in	O
this	O
case	O
.	O
this	O
manifests	O
itself	O
in	O
(	O
8.39	O
)	O
as	O
a	O
rank-deﬁcient	B
matrix	O
a	O
,	O
i.e.	O
,	O
one	O
whose	O
smaller	O
eigenvalue	O
is	O
very	O
close	O
to	O
zero.9	O
when	O
equation	B
(	O
8.39	O
)	O
is	O
solved	O
,	O
the	O
component	O
of	O
the	O
displacement	O
along	O
the	O
edge	O
is	O
very	O
poorly	O
conditioned	O
and	O
can	O
result	O
in	O
wild	O
guesses	O
under	O
small	O
noise	B
perturbations	O
.	O
one	O
way	O
to	O
mitigate	O
this	O
problem	O
is	O
to	O
add	O
a	O
prior	B
(	O
soft	O
constraint	O
)	O
on	O
the	O
expected	O
range	O
of	O
motions	O
(	O
simoncelli	O
,	O
adelson	O
,	O
and	O
heeger	O
1991	O
;	O
baker	O
,	O
gross	O
,	O
and	O
matthews	O
2004	O
;	O
govindu	O
2006	O
)	O
.	O
this	O
can	O
be	O
accomplished	O
by	O
adding	O
a	O
small	O
value	O
to	O
the	O
diagonal	O
of	O
a	O
,	O
which	O
essentially	O
biases	O
the	O
solution	O
towards	O
smaller	O
∆u	O
values	O
that	O
still	O
(	O
mostly	O
)	O
minimize	O
the	O
squared	O
error	O
.	O
however	O
,	O
the	O
pure	O
gaussian	O
model	O
assumed	O
when	O
using	O
a	O
simple	O
(	O
ﬁxed	O
)	O
quadratic	O
prior	B
,	O
as	O
in	O
(	O
simoncelli	O
,	O
adelson	O
,	O
and	O
heeger	O
1991	O
)	O
,	O
does	O
not	O
always	O
hold	O
in	O
practice	O
,	O
e.g.	O
,	O
because	O
of	O
aliasing	B
along	O
strong	O
edges	O
(	O
triggs	O
2004	O
)	O
.	O
for	O
this	O
reason	O
,	O
it	O
may	O
be	O
prudent	O
to	O
add	O
some	O
small	O
fraction	O
(	O
say	O
,	O
5	O
%	O
)	O
of	O
the	O
larger	O
eigenvalue	O
to	O
the	O
smaller	O
one	O
before	O
doing	O
the	O
matrix	O
inversion	O
.	O
9the	O
matrix	O
a	O
is	O
by	O
construction	O
always	O
guaranteed	O
to	O
be	O
symmetric	O
positive	O
semi-deﬁnite	O
,	O
i.e.	O
,	O
it	O
has	O
real	O
non-negative	O
eigenvalues	B
.	O
xxixi+uui	O
396	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
8.4	O
ssd	O
surfaces	O
corresponding	O
to	O
three	O
locations	O
(	O
red	O
crosses	O
)	O
in	O
an	O
image	B
:	O
(	O
a	O
)	O
highly	O
textured	O
area	O
,	O
strong	O
minimum	O
,	O
low	O
uncertainty	B
;	O
(	O
b	O
)	O
strong	O
edge	O
,	O
aperture	O
prob-	O
lem	O
,	O
high	O
uncertainty	O
in	O
one	O
direction	O
;	O
(	O
c	O
)	O
weak	O
texture	O
,	O
no	O
clear	O
minimum	O
,	O
large	O
uncertainty	O
.	O
8.1	O
translational	B
alignment	O
397	O
uncertainty	B
modeling	I
.	O
the	O
reliability	O
of	O
a	O
particular	O
patch-based	B
motion	O
estimate	O
can	O
be	O
captured	O
more	O
formally	O
with	O
an	O
uncertainty	B
model	O
.	O
the	O
simplest	O
such	O
model	O
is	O
a	O
covariance	O
matrix	O
,	O
which	O
captures	O
the	O
expected	O
variance	O
in	O
the	O
motion	B
estimate	O
in	O
all	O
possible	O
directions	O
.	O
as	O
discussed	O
in	O
section	O
6.1.4	O
and	O
appendix	O
b.6	O
,	O
under	O
small	O
amounts	O
of	O
additive	O
gaussian	O
noise	B
,	O
it	O
can	O
be	O
shown	O
that	O
the	O
covariance	O
matrix	O
σu	O
is	O
proportional	O
to	O
the	O
inverse	B
of	O
the	O
hessian	O
a	O
,	O
σu	O
=	O
σ2	O
na−1	O
,	O
(	O
8.44	O
)	O
n	O
is	O
the	O
variance	O
of	O
the	O
additive	O
gaussian	O
noise	B
(	O
anandan	O
1989	O
;	O
matthies	O
,	O
kanade	O
,	O
where	O
σ2	O
and	O
szeliski	O
1989	O
;	O
szeliski	O
1989	O
)	O
.	O
for	O
larger	O
amounts	O
of	O
noise	B
,	O
the	O
linearization	O
performed	O
by	O
the	O
lucas–kanade	O
algorithm	B
in	O
(	O
8.35	O
)	O
is	O
only	O
approximate	O
,	O
so	O
the	O
above	O
quantity	O
becomes	O
a	O
cramer–rao	O
lower	O
bound	O
on	O
the	O
true	O
covariance	O
.	O
thus	O
,	O
the	O
minimum	O
and	O
maximum	O
eigenvalues	B
of	O
the	O
hessian	O
a	O
can	O
now	O
be	O
interpreted	O
as	O
the	O
(	O
scaled	O
)	O
inverse	B
variances	O
in	O
the	O
least-certain	O
and	O
most-certain	O
directions	O
of	O
motion	B
.	O
(	O
a	O
more	O
detailed	O
analysis	O
using	O
a	O
more	O
realistic	O
model	O
of	O
image	B
noise	O
is	O
given	O
by	O
steele	O
and	O
jaynes	O
(	O
2005	O
)	O
.	O
)	O
figure	O
8.4	O
shows	O
the	O
local	B
ssd	O
surfaces	O
for	O
three	O
different	O
pixel	O
locations	O
in	O
an	O
image	B
.	O
as	O
you	O
can	O
see	O
,	O
the	O
surface	B
has	O
a	O
clear	O
minimum	O
in	O
the	O
highly	O
textured	O
region	B
and	O
suffers	O
from	O
the	O
aperture	B
problem	I
near	O
the	O
strong	O
edge	O
.	O
bias	B
and	I
gain	I
,	O
weighting	B
,	O
and	O
robust	B
error	O
metrics	O
.	O
the	O
lucas–kanade	O
update	B
rule	I
can	O
also	O
be	O
applied	O
to	O
the	O
bias–gain	O
equation	B
(	O
8.9	O
)	O
to	O
obtain	O
elk−bg	O
(	O
u	O
+	O
∆u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
[	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
∆u	O
+	O
ei	O
−	O
αi0	O
(	O
xi	O
)	O
−	O
β	O
]	O
2	O
(	O
8.45	O
)	O
(	O
lucas	O
and	O
kanade	O
1981	O
;	O
gennert	O
1988	O
;	O
fuh	O
and	O
maragos	O
1991	O
;	O
baker	O
,	O
gross	O
,	O
and	O
matthews	O
2003	O
)	O
.	O
the	O
resulting	O
4	O
×	O
4	O
system	O
of	O
equations	B
can	O
be	O
solved	O
to	O
simultaneously	O
estimate	O
the	O
translational	B
displacement	O
update	O
∆u	O
and	O
the	O
bias	B
and	I
gain	I
parameters	O
β	O
and	O
α.	O
a	O
similar	O
formulation	O
can	O
be	O
derived	O
for	O
images	O
(	O
templates	O
)	O
that	O
have	O
a	O
linear	B
appearance	I
variation	I
,	O
i1	O
(	O
x	O
+	O
u	O
)	O
≈	O
i0	O
(	O
x	O
)	O
+	O
(	O
cid:88	O
)	O
j	O
λjbj	O
(	O
x	O
)	O
,	O
(	O
8.46	O
)	O
where	O
the	O
bj	O
(	O
x	O
)	O
are	O
the	O
basis	O
images	O
and	O
the	O
λj	O
are	O
the	O
unknown	O
coefﬁcients	O
(	O
hager	O
and	O
belhumeur	O
1998	O
;	O
baker	O
,	O
gross	O
,	O
ishikawa	O
et	O
al	O
.	O
2003	O
;	O
baker	O
,	O
gross	O
,	O
and	O
matthews	O
2003	O
)	O
.	O
potential	O
linear	O
appearance	O
variations	O
include	O
illumination	O
changes	O
(	O
hager	O
and	O
belhumeur	O
1998	O
)	O
and	O
small	O
non-rigid	B
deformations	O
(	O
black	O
and	O
jepson	O
1998	O
)	O
.	O
a	O
weighted	B
(	O
windowed	B
)	O
version	O
of	O
the	O
lucas–kanade	O
algorithm	B
is	O
also	O
possible	O
:	O
elk−wssd	O
(	O
u	O
+	O
∆u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
w0	O
(	O
xi	O
)	O
w1	O
(	O
xi	O
+	O
u	O
)	O
[	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
∆u	O
+	O
ei	O
]	O
2	O
.	O
(	O
8.47	O
)	O
398	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
note	O
that	O
here	O
,	O
in	O
deriving	O
the	O
lucas–kanade	O
update	O
from	O
the	O
original	O
weighted	B
ssd	O
function	O
(	O
8.5	O
)	O
,	O
we	O
have	O
neglected	O
taking	O
the	O
derivative	O
of	O
the	O
w1	O
(	O
xi	O
+	O
u	O
)	O
weighting	B
function	O
with	O
respect	O
to	O
u	O
,	O
which	O
is	O
usually	O
acceptable	O
in	O
practice	O
,	O
especially	O
if	O
the	O
weighting	B
function	O
is	O
a	O
binary	O
mask	O
with	O
relatively	O
few	O
transitions	O
.	O
baker	O
,	O
gross	O
,	O
ishikawa	O
et	O
al	O
.	O
(	O
2003	O
)	O
only	O
use	O
the	O
w0	O
(	O
x	O
)	O
term	O
,	O
which	O
is	O
reasonable	O
if	O
the	O
two	O
images	O
have	O
the	O
same	O
extent	O
and	O
no	O
(	O
independent	O
)	O
cutouts	O
in	O
the	O
overlap	O
region	B
.	O
they	O
also	O
discuss	O
the	O
idea	O
of	O
making	O
the	O
weighting	B
proportional	O
to	O
∇i	O
(	O
x	O
)	O
,	O
which	O
helps	O
for	O
very	O
noisy	O
images	O
,	O
where	O
the	O
gradient	O
itself	O
is	O
noisy	O
.	O
similar	O
observations	O
,	O
formulated	O
in	O
terms	O
of	O
total	B
least	O
squares	O
(	O
van	O
huffel	O
and	O
vandewalle	O
1991	O
;	O
van	O
huffel	O
and	O
lemmerling	O
2002	O
)	O
,	O
have	O
been	O
made	O
by	O
other	O
researchers	O
studying	O
optical	B
ﬂow	I
(	O
weber	O
and	O
malik	O
1995	O
;	O
bab-	O
hadiashar	O
and	O
suter	O
1998b	O
;	O
m¨uhlich	O
and	O
mester	O
1998	O
)	O
.	O
lastly	O
,	O
baker	O
,	O
gross	O
,	O
ishikawa	O
et	O
al	O
.	O
(	O
2003	O
)	O
show	O
how	O
evaluating	O
equation	B
(	O
8.47	O
)	O
at	O
just	O
the	O
most	O
reliable	O
(	O
highest	O
gradient	O
)	O
pixels	O
does	O
not	O
signiﬁcantly	O
reduce	O
performance	O
for	O
large	O
enough	O
images	O
,	O
even	O
if	O
only	O
5–10	O
%	O
of	O
the	O
pixels	O
are	O
used	O
.	O
(	O
this	O
idea	O
was	O
originally	O
proposed	O
by	O
dellaert	O
and	O
collins	O
(	O
1999	O
)	O
,	O
who	O
used	O
a	O
more	O
sophisticated	O
selection	O
criterion	O
.	O
)	O
the	O
lucas–kanade	O
incremental	B
reﬁnement	I
step	O
can	O
also	O
be	O
applied	O
to	O
the	O
robust	B
error	O
metric	O
introduced	O
in	O
section	O
8.1	O
,	O
elk−srd	O
(	O
u	O
+	O
∆u	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
ρ	O
(	O
j	O
1	O
(	O
xi	O
+	O
u	O
)	O
∆u	O
+	O
ei	O
)	O
,	O
(	O
8.48	O
)	O
which	O
can	O
be	O
solved	O
using	O
the	O
iteratively	B
reweighted	I
least	O
squares	O
technique	O
described	O
in	O
section	O
6.1.4	O
.	O
8.2	O
parametric	B
motion	O
many	O
image	B
alignment	O
tasks	O
,	O
for	O
example	O
image	B
stitching	I
with	O
handheld	O
cameras	O
,	O
require	O
the	O
use	O
of	O
more	O
sophisticated	O
motion	B
models	I
,	O
as	O
described	O
in	O
section	O
2.1.2.	O
since	O
these	O
models	O
,	O
e.g.	O
,	O
afﬁne	B
deformations	O
,	O
typically	O
have	O
more	O
parameters	B
than	O
pure	B
translation	I
,	O
a	O
full	O
search	O
over	O
the	O
possible	O
range	O
of	O
values	O
is	O
impractical	O
.	O
instead	O
,	O
the	O
incremental	B
lucas–	O
kanade	O
algorithm	B
can	O
be	O
generalized	B
to	O
parametric	B
motion	O
models	O
and	O
used	O
in	O
conjunction	O
with	O
a	O
hierarchical	B
search	O
algorithm	B
(	O
lucas	O
and	O
kanade	O
1981	O
;	O
rehg	O
and	O
witkin	O
1991	O
;	O
fuh	O
and	O
maragos	O
1991	O
;	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
;	O
shashua	O
and	O
toelg	O
1997	O
;	O
shashua	O
and	O
wexler	O
2001	O
;	O
baker	O
and	O
matthews	O
2004	O
)	O
.	O
for	O
parametric	O
motion	B
,	O
instead	O
of	O
using	O
a	O
single	O
constant	O
translation	B
vector	O
u	O
,	O
we	O
use	O
a	O
spatially	O
varying	O
motion	O
ﬁeld	O
or	O
correspondence	B
map	O
,	O
x	O
(	O
cid:48	O
)	O
(	O
x	O
;	O
p	O
)	O
,	O
parameterized	O
by	O
a	O
low-	O
dimensional	O
vector	O
p	O
,	O
where	O
x	O
(	O
cid:48	O
)	O
can	O
be	O
any	O
of	O
the	O
motion	B
models	I
presented	O
in	O
section	O
2.1.2	O
.	O
8.2	O
parametric	B
motion	O
the	O
parametric	B
incremental	O
motion	B
update	O
rule	O
now	O
becomes	O
elk−pm	O
(	O
p	O
+	O
∆p	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
≈	O
(	O
cid:88	O
)	O
i	O
=	O
(	O
cid:88	O
)	O
i	O
[	O
i1	O
(	O
x	O
(	O
cid:48	O
)	O
(	O
xi	O
;	O
p	O
+	O
∆p	O
)	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
[	O
i1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
+	O
j	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
∆p	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
[	O
j	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
∆p	O
+	O
ei	O
]	O
2	O
,	O
where	O
the	O
jacobian	O
is	O
now	O
j	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
=	O
∂i1	O
∂p	O
=	O
∇i1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
∂x	O
(	O
cid:48	O
)	O
∂p	O
(	O
xi	O
)	O
,	O
399	O
(	O
8.49	O
)	O
(	O
8.50	O
)	O
(	O
8.51	O
)	O
(	O
8.52	O
)	O
i.e.	O
,	O
the	O
product	O
of	O
the	O
image	B
gradient	O
∇i1	O
with	O
the	O
jacobian	O
of	O
the	O
correspondence	B
ﬁeld	O
,	O
j	O
x	O
(	O
cid:48	O
)	O
=	O
∂x	O
(	O
cid:48	O
)	O
/∂p	O
.	O
the	O
motion	B
jacobians	O
j	O
x	O
(	O
cid:48	O
)	O
for	O
the	O
2d	O
planar	O
transformations	O
introduced	O
in	O
section	O
2.1.2	O
and	O
table	O
2.1	O
are	O
given	O
in	O
table	O
6.1.	O
note	O
how	O
we	O
have	O
re-parameterized	O
the	O
motion	B
matrices	O
so	O
that	O
they	O
are	O
always	O
the	O
identity	O
at	O
the	O
origin	O
p	O
=	O
0.	O
this	O
becomes	O
useful	O
later	O
,	O
when	O
we	O
talk	O
about	O
the	O
compositional	B
and	O
inverse	B
compositional	O
algorithms	O
.	O
(	O
it	O
also	O
makes	O
it	O
easier	O
to	O
impose	O
priors	O
on	O
the	O
motions	O
.	O
)	O
for	O
parametric	O
motion	B
,	O
the	O
(	O
gauss–newton	O
)	O
hessian	O
and	O
gradient-weighted	O
residual	O
vec-	O
tor	O
become	O
and	O
a	O
=	O
(	O
cid:88	O
)	O
i	O
x	O
(	O
cid:48	O
)	O
(	O
xi	O
)	O
[	O
∇i	O
t	O
j	O
t	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
∇i1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
]	O
j	O
x	O
(	O
cid:48	O
)	O
(	O
xi	O
)	O
b	O
=	O
−	O
(	O
cid:88	O
)	O
i	O
x	O
(	O
cid:48	O
)	O
(	O
xi	O
)	O
[	O
ei∇i	O
t	O
j	O
t	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
]	O
.	O
(	O
8.53	O
)	O
(	O
8.54	O
)	O
note	O
how	O
the	O
expressions	O
inside	O
the	O
square	O
brackets	O
are	O
the	O
same	O
ones	O
evaluated	O
for	O
the	O
simpler	O
translational	B
motion	O
case	O
(	O
8.40–8.41	O
)	O
.	O
patch-based	B
approximation	O
.	O
the	O
computation	O
of	O
the	O
hessian	O
and	O
residual	O
vectors	O
for	O
parametric	O
motion	B
can	O
be	O
signiﬁcantly	O
more	O
expensive	O
than	O
for	O
the	O
translational	B
case	O
.	O
for	O
parametric	O
motion	B
with	O
n	O
parameters	B
and	O
n	O
pixels	O
,	O
the	O
accumulation	O
of	O
a	O
and	O
b	O
takes	O
o	O
(	O
n2n	O
)	O
operations	O
(	O
baker	O
and	O
matthews	O
2004	O
)	O
.	O
one	O
way	O
to	O
reduce	O
this	O
by	O
a	O
signiﬁcant	O
amount	O
is	O
to	O
divide	O
the	O
image	B
up	O
into	O
smaller	O
sub-blocks	O
(	O
patches	O
)	O
pj	O
and	O
to	O
only	O
accumulate	O
the	O
simpler	O
2	O
×	O
2	O
quantities	O
inside	O
the	O
square	O
brackets	O
at	O
the	O
pixel	O
level	O
(	O
shum	O
and	O
szeliski	O
2000	O
)	O
,	O
aj	O
=	O
(	O
cid:88	O
)	O
i∈pj	O
bj	O
=	O
(	O
cid:88	O
)	O
i∈pj	O
∇i	O
t	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
∇i1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
ei∇i	O
t	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
.	O
(	O
8.55	O
)	O
(	O
8.56	O
)	O
400	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
the	O
full	O
hessian	O
and	O
residual	O
can	O
then	O
be	O
approximated	O
as	O
a	O
≈	O
(	O
cid:88	O
)	O
j	O
and	O
j	O
t	O
x	O
(	O
cid:48	O
)	O
(	O
ˆxj	O
)	O
[	O
(	O
cid:88	O
)	O
i∈pj	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
∇i1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
]	O
j	O
x	O
(	O
cid:48	O
)	O
(	O
ˆxj	O
)	O
=	O
(	O
cid:88	O
)	O
j	O
∇i	O
t	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
]	O
=	O
−	O
(	O
cid:88	O
)	O
j	O
x	O
(	O
cid:48	O
)	O
(	O
ˆxj	O
)	O
[	O
(	O
cid:88	O
)	O
i∈pj	O
b	O
≈	O
−	O
(	O
cid:88	O
)	O
j	O
ei∇i	O
t	O
j	O
t	O
j	O
t	O
x	O
(	O
cid:48	O
)	O
(	O
ˆxj	O
)	O
ajj	O
x	O
(	O
cid:48	O
)	O
(	O
ˆxj	O
)	O
(	O
8.57	O
)	O
j	O
t	O
x	O
(	O
cid:48	O
)	O
(	O
ˆxj	O
)	O
bj	O
,	O
(	O
8.58	O
)	O
where	O
ˆxj	O
is	O
the	O
center	O
of	O
each	O
patch	B
pj	O
(	O
shum	O
and	O
szeliski	O
2000	O
)	O
.	O
this	O
is	O
equivalent	O
to	O
replacing	O
the	O
true	O
motion	O
jacobian	O
with	O
a	O
piecewise-constant	O
approximation	O
.	O
in	O
practice	O
,	O
this	O
works	O
quite	O
well	O
.	O
the	O
relationship	O
of	O
this	O
approximation	O
to	O
feature-based	B
registration	O
is	O
discussed	O
in	O
section	O
9.2.4.	O
compositional	B
approach	O
.	O
for	O
a	O
complex	O
parametric	B
motion	O
such	O
as	O
a	O
homography	B
,	O
the	O
computation	O
of	O
the	O
motion	B
jacobian	O
becomes	O
complicated	O
and	O
may	O
involve	O
a	O
per-pixel	O
divi-	O
sion	O
.	O
szeliski	O
and	O
shum	O
(	O
1997	O
)	O
observed	O
that	O
this	O
can	O
be	O
simpliﬁed	O
by	O
ﬁrst	O
warping	O
the	O
target	O
image	B
i1	O
according	O
to	O
the	O
current	O
motion	B
estimate	O
x	O
(	O
cid:48	O
)	O
(	O
x	O
;	O
p	O
)	O
,	O
˜i1	O
(	O
x	O
)	O
=	O
i1	O
(	O
x	O
(	O
cid:48	O
)	O
(	O
x	O
;	O
p	O
)	O
)	O
,	O
and	O
then	O
comparing	O
this	O
warped	O
image	B
against	O
the	O
template	O
i0	O
(	O
x	O
)	O
,	O
(	O
8.59	O
)	O
(	O
8.60	O
)	O
(	O
8.61	O
)	O
(	O
8.62	O
)	O
elk−ss	O
(	O
∆p	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
≈	O
(	O
cid:88	O
)	O
i	O
=	O
(	O
cid:88	O
)	O
i	O
[	O
˜i1	O
(	O
˜x	O
(	O
xi	O
;	O
∆p	O
)	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
[	O
˜j1	O
(	O
xi	O
)	O
∆p	O
+	O
ei	O
]	O
2	O
[	O
∇˜i1	O
(	O
xi	O
)	O
j	O
˜x	O
(	O
xi	O
)	O
∆p	O
+	O
ei	O
]	O
2.	O
note	O
that	O
since	O
the	O
two	O
images	O
are	O
assumed	O
to	O
be	O
fairly	O
similar	O
,	O
only	O
an	O
incremental	B
para-	O
metric	O
motion	B
is	O
required	O
,	O
i.e.	O
,	O
the	O
incremental	B
motion	O
can	O
be	O
evaluated	O
around	O
p	O
=	O
0	O
,	O
which	O
can	O
lead	O
to	O
considerable	O
simpliﬁcations	O
.	O
for	O
example	O
,	O
the	O
jacobian	O
of	O
the	O
planar	O
projective	O
transform	B
(	O
6.19	O
)	O
now	O
becomes	O
j	O
˜x	O
=	O
∂	O
˜x	O
∂p	O
(	O
cid:12	O
)	O
(	O
cid:12	O
)	O
(	O
cid:12	O
)	O
(	O
cid:12	O
)	O
p=0	O
=	O
(	O
cid:34	O
)	O
x	O
y	O
0	O
0	O
0	O
1	O
0	O
0	O
x	O
y	O
0	O
−x2	O
−xy	O
1	O
−xy	O
−y2	O
(	O
cid:35	O
)	O
.	O
(	O
8.63	O
)	O
once	O
the	O
incremental	B
motion	O
˜x	O
has	O
been	O
computed	O
,	O
it	O
can	O
be	O
prepended	O
to	O
the	O
previously	O
estimated	O
motion	B
,	O
which	O
is	O
easy	O
to	O
do	O
for	O
motions	O
represented	O
with	O
transformation	O
matrices	O
,	O
such	O
as	O
those	O
given	O
in	O
tables	O
2.1	O
and	O
6.1.	O
baker	O
and	O
matthews	O
(	O
2004	O
)	O
call	O
this	O
the	O
forward	B
compositional	O
algorithm	B
,	O
since	O
the	O
target	O
image	B
is	O
being	O
re-warped	O
and	O
the	O
ﬁnal	O
motion	B
esti-	O
mates	O
are	O
being	O
composed	O
.	O
8.2	O
parametric	B
motion	O
401	O
if	O
the	O
appearance	O
of	O
the	O
warped	O
and	O
template	O
images	O
is	O
similar	O
enough	O
,	O
we	O
can	O
replace	O
the	O
gradient	O
of	O
˜i1	O
(	O
x	O
)	O
with	O
the	O
gradient	O
of	O
i0	O
(	O
x	O
)	O
,	O
as	O
suggested	O
previously	O
(	O
8.43	O
)	O
.	O
this	O
has	O
po-	O
tentially	O
a	O
big	O
advantage	O
in	O
that	O
it	O
allows	O
the	O
pre-computation	O
(	O
and	O
inversion	O
)	O
of	O
the	O
hessian	O
matrix	O
a	O
given	O
in	O
equation	B
(	O
8.53	O
)	O
.	O
the	O
residual	O
vector	O
b	O
(	O
8.54	O
)	O
can	O
also	O
be	O
partially	O
precom-	O
puted	O
,	O
i.e.	O
,	O
the	O
steepest	O
descent	O
images	O
∇i0	O
(	O
x	O
)	O
j	O
˜x	O
(	O
x	O
)	O
can	O
precomputed	O
and	O
stored	O
for	O
later	O
multiplication	B
with	O
the	O
e	O
(	O
x	O
)	O
=	O
˜i1	O
(	O
x	O
)	O
−	O
i0	O
(	O
x	O
)	O
error	O
images	O
(	O
baker	O
and	O
matthews	O
2004	O
)	O
.	O
this	O
idea	O
was	O
ﬁrst	O
suggested	O
by	O
hager	O
and	O
belhumeur	O
(	O
1998	O
)	O
in	O
what	O
baker	O
and	O
matthews	O
(	O
2004	O
)	O
call	O
a	O
inverse	B
additive	O
scheme	O
.	O
baker	O
and	O
matthews	O
(	O
2004	O
)	O
introduce	O
one	O
more	O
variant	O
they	O
call	O
the	O
inverse	B
composi-	O
tional	O
algorithm	B
.	O
rather	O
than	O
(	O
conceptually	O
)	O
re-warping	O
the	O
warped	O
target	O
image	B
˜i1	O
(	O
x	O
)	O
,	O
they	O
instead	O
warp	O
the	O
template	O
image	B
i0	O
(	O
x	O
)	O
and	O
minimize	O
elk−bm	O
(	O
∆p	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
≈	O
(	O
cid:88	O
)	O
i	O
[	O
˜i1	O
(	O
xi	O
)	O
−	O
i0	O
(	O
˜x	O
(	O
xi	O
;	O
∆p	O
)	O
)	O
]	O
2	O
[	O
∇i0	O
(	O
xi	O
)	O
j	O
˜x	O
(	O
xi	O
)	O
∆p	O
−	O
ei	O
]	O
2	O
.	O
(	O
8.64	O
)	O
(	O
8.65	O
)	O
this	O
is	O
identical	O
to	O
the	O
forward	B
warped	O
algorithm	B
(	O
8.62	O
)	O
with	O
the	O
gradients	O
∇˜i1	O
(	O
x	O
)	O
replaced	O
by	O
the	O
gradients	O
∇i0	O
(	O
x	O
)	O
,	O
except	O
for	O
the	O
sign	O
of	O
ei	O
.	O
the	O
resulting	O
update	O
∆p	O
is	O
the	O
negative	O
of	O
the	O
one	O
computed	O
by	O
the	O
modiﬁed	O
equation	B
(	O
8.62	O
)	O
and	O
hence	O
the	O
inverse	B
of	O
the	O
incremental	B
transformation	O
must	O
be	O
prepended	O
to	O
the	O
current	O
transform	B
.	O
because	O
the	O
inverse	B
composi-	O
tional	O
algorithm	B
has	O
the	O
potential	O
of	O
pre-computing	O
the	O
inverse	B
hessian	O
and	O
the	O
steepest	O
de-	O
scent	O
images	O
,	O
this	O
makes	O
it	O
the	O
preferred	O
approach	O
of	O
those	O
surveyed	O
by	O
baker	O
and	O
matthews	O
(	O
2004	O
)	O
.	O
figure	O
8.5	O
(	O
baker	O
,	O
gross	O
,	O
ishikawa	O
et	O
al	O
.	O
2003	O
)	O
beautifully	O
shows	O
all	O
of	O
the	O
steps	O
required	O
to	O
implement	O
the	O
inverse	B
compositional	O
algorithm	B
.	O
baker	O
and	O
matthews	O
(	O
2004	O
)	O
also	O
discuss	O
the	O
advantage	O
of	O
using	O
gauss–newton	O
iteration	O
(	O
i.e.	O
,	O
the	O
ﬁrst-order	O
expansion	O
of	O
the	O
least	B
squares	I
,	O
as	O
above	O
)	O
compared	O
to	O
other	O
approaches	O
such	O
as	O
steepest	O
descent	O
and	O
levenberg–marquardt	O
.	O
subsequent	O
parts	O
of	O
the	O
series	O
(	O
baker	O
,	O
gross	O
,	O
ishikawa	O
et	O
al	O
.	O
2003	O
;	O
baker	O
,	O
gross	O
,	O
and	O
matthews	O
2003	O
,	O
2004	O
)	O
discuss	O
more	O
advanced	O
topics	O
such	O
as	O
per-pixel	O
weighting	B
,	O
pixel	B
selection	I
for	O
efﬁciency	B
,	O
a	O
more	O
in-depth	O
discussion	O
of	O
robust	B
metrics	O
and	O
algorithms	O
,	O
linear	O
appearance	O
variations	O
,	O
and	O
priors	O
on	O
parameters	B
.	O
they	O
make	O
for	O
invaluable	O
reading	O
for	O
anyone	O
interested	O
in	O
implementing	O
a	O
highly	O
tuned	O
imple-	O
mentation	O
of	O
incremental	B
image	O
registration	B
.	O
evangelidis	O
and	O
psarakis	O
(	O
2008	O
)	O
provide	O
some	O
detailed	O
experimental	O
evaluations	O
of	O
these	O
and	O
other	O
related	O
approaches	O
.	O
8.2.1	O
application	O
:	O
video	B
stabilization	I
video	O
stabilization	O
is	O
one	O
of	O
the	O
most	O
widely	O
used	O
applications	O
of	O
parametric	B
motion	O
esti-	O
mation	O
(	O
hansen	O
,	O
anandan	O
,	O
dana	O
et	O
al	O
.	O
1994	O
;	O
irani	O
,	O
rousso	O
,	O
and	O
peleg	O
1997	O
;	O
morimoto	O
and	O
402	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
8.5	O
a	O
schematic	O
overview	O
of	O
the	O
inverse	B
compositional	O
algorithm	B
(	O
copied	O
,	O
with	O
permission	O
,	O
from	O
(	O
baker	O
,	O
gross	O
,	O
ishikawa	O
et	O
al	O
.	O
2003	O
)	O
)	O
.	O
steps	O
3–6	O
(	O
light-colored	O
arrows	O
)	O
are	O
performed	O
once	O
as	O
a	O
pre-computation	O
.	O
the	O
main	O
algorithm	B
simply	O
consists	O
of	O
iterating	O
:	O
image	B
warping	O
(	O
step	O
1	O
)	O
,	O
image	B
differencing	O
(	O
step	O
2	O
)	O
,	O
image	B
dot	O
products	O
(	O
step	O
7	O
)	O
,	O
multiplication	B
with	O
the	O
inverse	B
of	O
the	O
hessian	O
(	O
step	O
8	O
)	O
,	O
and	O
the	O
update	O
to	O
the	O
warp	O
(	O
step	O
9	O
)	O
.	O
all	O
of	O
these	O
steps	O
can	O
be	O
performed	O
efﬁciently	O
.	O
8.2	O
parametric	B
motion	O
403	O
chellappa	O
1997	O
;	O
srinivasan	O
,	O
chellappa	O
,	O
veeraraghavan	O
et	O
al	O
.	O
2005	O
)	O
.	O
algorithms	O
for	O
stabiliza-	O
tion	B
run	O
inside	O
both	O
hardware	O
devices	O
,	O
such	O
as	O
camcorders	O
and	O
still	O
cameras	O
,	O
and	O
software	O
packages	O
for	O
improving	O
the	O
visual	O
quality	O
of	O
shaky	O
videos	O
.	O
in	O
their	O
paper	O
on	O
full-frame	O
video	B
stabilization	I
,	O
matsushita	O
,	O
ofek	O
,	O
ge	O
et	O
al	O
.	O
(	O
2006	O
)	O
give	O
a	O
nice	O
overview	O
of	O
the	O
three	O
major	O
stages	O
of	O
stabilization	O
,	O
namely	O
motion	B
estimation	I
,	O
motion	B
smoothing	O
,	O
and	O
image	B
warping	O
.	O
motion	B
estimation	I
algorithms	O
often	O
use	O
a	O
similarity	B
trans-	O
form	O
to	O
handle	O
camera	B
translations	O
,	O
rotations	O
,	O
and	O
zooming	O
.	O
the	O
tricky	O
part	O
is	O
getting	O
these	O
algorithms	O
to	O
lock	O
onto	O
the	O
background	O
motion	O
,	O
which	O
is	O
a	O
result	O
of	O
the	O
camera	B
movement	O
,	O
without	O
getting	O
distracted	O
by	O
independent	O
moving	O
foreground	O
objects	O
.	O
motion	B
smoothing	O
al-	O
gorithms	O
recover	O
the	O
low-frequency	O
(	O
slowly	O
varying	O
)	O
part	O
of	O
the	O
motion	B
and	O
then	O
estimate	O
the	O
high-frequency	O
shake	O
component	O
that	O
needs	O
to	O
be	O
removed	O
.	O
finally	O
,	O
image	B
warping	O
algo-	O
rithms	O
apply	O
the	O
high-frequency	O
correction	O
to	O
render	O
the	O
original	O
frames	O
as	O
if	O
the	O
camera	B
had	O
undergone	O
only	O
the	O
smooth	O
motion	B
.	O
the	O
resulting	O
stabilization	O
algorithms	O
can	O
greatly	O
improve	O
the	O
appearance	O
of	O
shaky	O
videos	O
but	O
they	O
often	O
still	O
contain	O
visual	O
artifacts	O
.	O
for	O
example	O
,	O
image	B
warping	O
can	O
result	O
in	O
missing	O
borders	O
around	O
the	O
image	B
,	O
which	O
must	O
be	O
cropped	O
,	O
ﬁlled	O
using	O
information	O
from	O
other	O
frames	O
,	O
or	O
hallucinated	O
using	O
inpainting	O
techniques	O
(	O
section	O
10.5.1	O
)	O
.	O
furthermore	O
,	O
video	B
frames	O
cap-	O
tured	O
during	O
fast	O
motion	O
are	O
often	O
blurry	O
.	O
their	O
appearance	O
can	O
be	O
improved	O
either	O
using	O
deblurring	O
techniques	O
(	O
section	O
10.3	O
)	O
or	O
stealing	O
sharper	O
pixels	O
from	O
other	O
frames	O
with	O
less	O
motion	B
or	O
better	O
focus	B
(	O
matsushita	O
,	O
ofek	O
,	O
ge	O
et	O
al	O
.	O
2006	O
)	O
.	O
exercise	O
8.3	O
has	O
you	O
implement	O
and	O
test	O
some	O
of	O
these	O
ideas	O
.	O
in	O
situations	O
where	O
the	O
camera	B
is	O
translating	O
a	O
lot	O
in	O
3d	O
,	O
e.g.	O
,	O
when	O
the	O
videographer	O
is	O
walking	O
,	O
an	O
even	O
better	O
approach	O
is	O
to	O
compute	O
a	O
full	O
structure	B
from	I
motion	I
reconstruction	O
of	O
the	O
camera	B
motion	O
and	O
3d	O
scene	O
.	O
a	O
smooth	O
3d	O
camera	B
path	O
can	O
then	O
be	O
computed	O
and	O
the	O
original	O
video	B
re-rendered	O
using	O
view	O
interpolation	B
with	O
the	O
interpolated	O
3d	O
point	O
cloud	O
serving	O
as	O
the	O
proxy	O
geometry	O
while	O
preserving	O
salient	O
features	O
(	O
liu	O
,	O
gleicher	O
,	O
jin	O
et	O
al	O
.	O
2009	O
)	O
.	O
if	O
you	O
have	O
access	O
to	O
a	O
camera	B
array	O
instead	O
of	O
a	O
single	O
video	O
camera	B
,	O
you	O
can	O
do	O
even	O
better	O
using	O
a	O
light	B
ﬁeld	I
rendering	O
approach	O
(	O
section	O
13.3	O
)	O
(	O
smith	O
,	O
zhang	O
,	O
jin	O
et	O
al	O
.	O
2009	O
)	O
.	O
8.2.2	O
learned	B
motion	O
models	O
an	O
alternative	O
to	O
parameterizing	O
the	O
motion	B
ﬁeld	O
with	O
a	O
geometric	B
deformation	O
such	O
as	O
an	O
afﬁne	B
transform	O
is	O
to	O
learn	O
a	O
set	O
of	O
basis	O
functions	O
tailored	O
to	O
a	O
particular	O
application	O
(	O
black	O
,	O
yacoob	O
,	O
jepson	O
et	O
al	O
.	O
1997	O
)	O
.	O
first	O
,	O
a	O
set	O
of	O
dense	O
motion	O
ﬁelds	O
(	O
section	O
8.4	O
)	O
is	O
computed	O
from	O
a	O
set	O
of	O
training	O
videos	O
.	O
next	O
,	O
singular	O
value	O
decomposition	O
(	O
svd	O
)	O
is	O
applied	O
to	O
the	O
stack	O
of	O
motion	B
ﬁelds	O
ut	O
(	O
x	O
)	O
to	O
compute	O
the	O
ﬁrst	O
few	O
singular	O
vectors	O
vk	O
(	O
x	O
)	O
.	O
finally	O
,	O
for	O
a	O
new	O
test	O
sequence	O
,	O
a	O
novel	O
ﬂow	O
ﬁeld	O
is	O
computed	O
using	O
a	O
coarse-to-ﬁne	B
algorithm	O
that	O
estimates	O
the	O
404	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
8.6	O
learned	B
parameterized	O
motion	B
ﬁelds	O
for	O
a	O
walking	O
sequence	O
(	O
black	O
,	O
yacoob	O
,	O
jepson	O
et	O
al	O
.	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
ieee	O
:	O
(	O
a	O
)	O
learned	B
basis	O
ﬂow	O
ﬁelds	O
;	O
(	O
b	O
)	O
plots	O
of	O
motion	B
coefﬁcients	O
over	O
time	O
and	O
corresponding	O
estimated	O
motion	B
ﬁelds	O
.	O
unknown	O
coefﬁcient	O
ak	O
in	O
the	O
parameterized	O
ﬂow	O
ﬁeld	O
u	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
akvk	O
(	O
x	O
)	O
.	O
(	O
8.66	O
)	O
figure	O
8.6a	O
shows	O
a	O
set	O
of	O
basis	O
ﬁelds	O
learned	B
by	O
observing	O
videos	O
of	O
walking	O
motions	O
.	O
figure	O
8.6b	O
shows	O
the	O
temporal	O
evolution	B
of	O
the	O
basis	O
coefﬁcients	O
as	O
well	O
as	O
a	O
few	O
of	O
the	O
recovered	O
parametric	B
motion	O
ﬁelds	O
.	O
note	O
that	O
similar	O
ideas	O
can	O
also	O
be	O
applied	O
to	O
feature	B
tracks	I
(	O
torresani	O
,	O
hertzmann	O
,	O
and	O
bregler	O
2008	O
)	O
,	O
which	O
is	O
a	O
topic	O
we	O
discuss	O
in	O
more	O
detail	O
in	O
sections	O
4.1.4	O
and	O
12.6.4	O
.	O
8.3	O
spline-based	B
motion	O
while	O
parametric	B
motion	O
models	O
are	O
useful	O
in	O
a	O
wide	O
variety	O
of	O
applications	O
(	O
such	O
as	O
video	B
stabilization	I
and	O
mapping	O
onto	O
planar	O
surfaces	O
)	O
,	O
most	O
image	B
motion	O
is	O
too	O
complicated	O
to	O
be	O
captured	O
by	O
such	O
low-dimensional	O
models	O
.	O
traditionally	O
,	O
optical	B
ﬂow	I
algorithms	O
(	O
section	O
8.4	O
)	O
compute	O
an	O
independent	O
motion	B
esti-	O
mate	O
for	O
each	O
pixel	O
,	O
i.e.	O
,	O
the	O
number	O
of	O
ﬂow	O
vectors	O
computed	O
is	O
equal	O
to	O
the	O
number	O
of	O
input	O
pixels	O
.	O
the	O
general	O
optical	B
ﬂow	I
analog	O
to	O
equation	B
(	O
8.1	O
)	O
can	O
thus	O
be	O
written	O
as	O
essd−of	O
(	O
{	O
ui	O
}	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
[	O
i1	O
(	O
xi	O
+	O
ui	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
.	O
(	O
8.67	O
)	O
8.3	O
spline-based	B
motion	O
405	O
figure	O
8.7	O
spline	B
motion	O
ﬁeld	O
:	O
the	O
displacement	O
vectors	O
ui	O
=	O
(	O
ui	O
,	O
vi	O
)	O
are	O
shown	O
as	O
pluses	O
(	O
+	O
)	O
and	O
are	O
controlled	O
by	O
the	O
smaller	O
number	O
of	O
control	O
vertices	O
ˆuj	O
=	O
(	O
ˆui	O
,	O
ˆvj	O
)	O
,	O
which	O
are	O
shown	O
as	O
circles	O
(	O
◦	O
)	O
.	O
notice	O
how	O
in	O
the	O
above	O
equation	B
,	O
the	O
number	O
of	O
variables	O
{	O
ui	O
}	O
is	O
twice	O
the	O
number	O
of	O
measurements	O
,	O
so	O
the	O
problem	O
is	O
underconstrained	O
.	O
the	O
two	O
classic	O
approaches	O
to	O
this	O
problem	O
,	O
which	O
we	O
study	O
in	O
section	O
8.4	O
,	O
are	O
to	O
perform	O
the	O
summation	O
over	O
overlapping	O
regions	O
(	O
the	O
patch-based	B
or	O
window-based	B
approach	O
)	O
or	O
to	O
add	O
smoothness	B
terms	O
on	O
the	O
{	O
ui	O
}	O
ﬁeld	O
using	O
regularization	O
or	O
markov	O
random	O
ﬁelds	O
(	O
sec-	O
tion	B
3.7	O
)	O
.	O
in	O
this	O
section	O
,	O
we	O
describe	O
an	O
alternative	O
approach	O
that	O
lies	O
somewhere	O
between	O
general	O
optical	B
ﬂow	I
(	O
independent	O
ﬂow	O
at	O
each	O
pixel	O
)	O
and	O
parametric	B
ﬂow	O
(	O
a	O
small	O
number	O
of	O
global	B
parameters	O
)	O
.	O
the	O
approach	O
is	O
to	O
represent	O
the	O
motion	B
ﬁeld	O
as	O
a	O
two-dimensional	B
spline	O
controlled	O
by	O
a	O
smaller	O
number	O
of	O
control	O
vertices	O
{	O
ˆuj	O
}	O
(	O
figure	O
8.7	O
)	O
,	O
ˆujwi	O
,	O
j	O
,	O
(	O
8.68	O
)	O
ui	O
=	O
(	O
cid:88	O
)	O
j	O
ˆujbj	O
(	O
xi	O
)	O
=	O
(	O
cid:88	O
)	O
j	O
where	O
the	O
bj	O
(	O
xi	O
)	O
are	O
called	O
the	O
basis	O
functions	O
and	O
are	O
only	O
non-zero	O
over	O
a	O
small	O
ﬁnite	O
sup-	O
port	O
interval	O
(	O
szeliski	O
and	O
coughlan	O
1997	O
)	O
.	O
we	O
call	O
the	O
wij	O
=	O
bj	O
(	O
xi	O
)	O
weights	O
to	O
emphasize	O
that	O
the	O
{	O
ui	O
}	O
are	O
known	O
linear	B
combinations	O
of	O
the	O
{	O
ˆuj	O
}	O
.	O
some	O
commonly	O
used	O
spline	B
basis	O
functions	O
are	O
shown	O
in	O
figure	O
8.8.	O
substituting	O
the	O
formula	O
for	O
the	O
individual	O
per-pixel	O
ﬂow	O
vectors	O
ui	O
(	O
8.68	O
)	O
into	O
the	O
ssd	O
error	O
metric	O
(	O
8.67	O
)	O
yields	O
a	O
parametric	B
motion	O
formula	O
similar	O
to	O
equation	B
(	O
8.50	O
)	O
.	O
the	O
biggest	O
difference	B
is	O
that	O
the	O
jacobian	O
j	O
1	O
(	O
x	O
(	O
cid:48	O
)	O
i	O
)	O
(	O
8.52	O
)	O
now	O
consists	O
of	O
the	O
sparse	B
entries	O
in	O
the	O
weight	O
matrix	O
w	O
=	O
[	O
wij	O
]	O
.	O
in	O
situations	O
where	O
we	O
know	O
something	O
more	O
about	O
the	O
motion	B
ﬁeld	O
,	O
e.g.	O
,	O
when	O
the	O
mo-	O
tion	B
is	O
due	O
to	O
a	O
camera	B
moving	O
in	O
a	O
static	O
scene	O
,	O
we	O
can	O
use	O
more	O
specialized	O
motion	B
models	I
.	O
for	O
example	O
,	O
the	O
plane	O
plus	O
parallax	O
model	O
(	O
section	O
2.1.5	O
)	O
can	O
be	O
naturally	O
combined	O
with	O
a	O
spline-based	B
motion	O
representation	O
,	O
where	O
the	O
in-plane	O
motion	B
is	O
represented	O
by	O
a	O
homog-	O
raphy	O
(	O
6.19	O
)	O
and	O
the	O
out-of-plane	O
parallax	O
d	O
is	O
represented	O
by	O
a	O
scalar	O
variable	O
at	O
each	O
spline	B
406	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
8.8	O
sample	O
spline	B
basis	O
functions	O
(	O
szeliski	O
and	O
coughlan	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
springer	O
.	O
the	O
block	O
(	O
constant	O
)	O
interpolator/basis	O
corresponds	O
to	O
block-based	O
motion	B
estimation	I
(	O
le	O
gall	O
1991	O
)	O
.	O
see	O
section	O
3.5.1	O
for	O
more	O
details	O
on	O
spline	B
functions	O
.	O
8.3	O
spline-based	B
motion	O
407	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
8.9	O
quadtree	B
spline-based	I
motion	O
estimation	B
(	O
szeliski	O
and	O
shum	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
ieee	O
:	O
(	O
a	O
)	O
quadtree	B
spline	O
representation	O
,	O
(	O
b	O
)	O
which	O
can	O
lead	O
to	O
cracks	O
,	O
unless	O
the	O
white	O
nodes	O
are	O
constrained	B
to	O
depend	O
on	O
their	O
parents	O
;	O
(	O
c	O
)	O
deformed	O
quadtree	B
spline	O
mesh	O
overlaid	O
on	O
grayscale	O
image	B
;	O
(	O
d	O
)	O
ﬂow	O
ﬁeld	O
visualized	O
as	O
a	O
needle	O
diagram	O
.	O
control	O
point	O
(	O
szeliski	O
and	O
kang	O
1995	O
;	O
szeliski	O
and	O
coughlan	O
1997	O
)	O
.	O
in	O
many	O
cases	O
,	O
the	O
small	O
number	O
of	O
spline	B
vertices	O
results	O
in	O
a	O
motion	B
estimation	I
problem	O
that	O
is	O
well	O
conditioned	O
.	O
however	O
,	O
if	O
large	O
textureless	O
regions	O
(	O
or	O
elongated	O
edges	O
subject	O
to	O
the	O
aperture	B
problem	I
)	O
persist	O
across	O
several	O
spline	B
patches	O
,	O
it	O
may	O
be	O
necessary	O
to	O
add	O
a	O
regularization	B
term	O
to	O
make	O
the	O
problem	O
well	O
posed	O
(	O
section	O
3.7.1	O
)	O
.	O
the	O
simplest	O
way	O
to	O
do	O
this	O
is	O
to	O
directly	O
add	O
squared	O
difference	B
penalties	O
between	O
adjacent	O
vertices	O
in	O
the	O
spline	B
control	O
mesh	O
{	O
ˆuj	O
}	O
,	O
as	O
in	O
(	O
3.100	O
)	O
.	O
if	O
a	O
multi-resolution	O
(	O
coarse-to-ﬁne	B
)	O
strategy	B
is	O
being	O
used	O
,	O
it	O
is	O
important	O
to	O
re-scale	O
these	O
smoothness	B
terms	O
while	O
going	O
from	O
level	O
to	O
level	O
.	O
the	O
linear	B
system	O
corresponding	O
to	O
the	O
spline-based	B
motion	O
estimator	O
is	O
sparse	B
and	O
regu-	O
lar	O
.	O
because	O
it	O
is	O
usually	O
of	O
moderate	O
size	O
,	O
it	O
can	O
often	O
be	O
solved	O
using	O
direct	O
techniques	O
such	O
as	O
cholesky	O
decomposition	O
(	O
appendix	O
a.4	O
)	O
.	O
alternatively	O
,	O
if	O
the	O
problem	O
becomes	O
too	O
large	O
and	O
subject	O
to	O
excessive	O
ﬁll-in	O
,	O
iterative	B
techniques	O
such	O
as	O
hierarchically	O
preconditioned	B
con-	O
jugate	O
gradient	O
(	O
szeliski	O
1990b	O
,	O
2006b	O
)	O
can	O
be	O
used	O
instead	O
(	O
appendix	O
a.5	O
)	O
.	O
because	O
of	O
its	O
robustness	O
,	O
spline-based	B
motion	O
estimation	B
has	O
been	O
used	O
for	O
a	O
number	O
of	O
applications	O
,	O
including	O
visual	B
effects	I
(	O
roble	O
1999	O
)	O
and	O
medical	B
image	I
registration	O
(	O
sec-	O
tion	B
8.3.1	O
)	O
(	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
kybic	O
and	O
unser	O
2003	O
)	O
.	O
one	O
disadvantage	O
of	O
the	O
basic	O
technique	O
,	O
however	O
,	O
is	O
that	O
the	O
model	O
does	O
a	O
poor	O
job	O
near	O
motion	B
discontinuities	O
,	O
unless	O
an	O
excessive	O
number	O
of	O
nodes	O
is	O
used	O
.	O
to	O
remedy	O
this	O
situation	O
,	O
szeliski	O
and	O
shum	O
(	O
1996	O
)	O
propose	O
using	O
a	O
quadtree	B
representation	O
embedded	O
in	O
the	O
spline	B
control	O
grid	O
(	O
figure	O
8.9a	O
)	O
.	O
large	O
cells	O
are	O
used	O
to	O
present	O
regions	O
of	O
smooth	O
motion	B
,	O
while	O
smaller	O
cells	O
are	O
added	O
in	O
regions	O
of	O
motion	B
discontinuities	O
(	O
figure	O
8.9c	O
)	O
.	O
to	O
estimate	O
the	O
motion	B
,	O
a	O
coarse-to-ﬁne	B
strategy	O
is	O
used	O
.	O
starting	O
with	O
a	O
regular	O
spline	B
imposed	O
over	O
a	O
lower-resolution	O
image	B
,	O
an	O
initial	O
motion	B
estimate	O
is	O
obtained	O
.	O
spline	B
patches	O
where	O
the	O
motion	B
is	O
inconsistent	O
,	O
i.e.	O
,	O
the	O
squared	O
residual	O
(	O
8.67	O
)	O
is	O
above	O
a	O
threshold	O
,	O
are	O
subdivided	O
into	O
smaller	O
patches	O
.	O
in	O
order	B
to	O
avoid	O
cracks	O
in	O
the	O
resulting	O
motion	B
ﬁeld	O
(	O
fig-	O
408	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
8.10	O
elastic	O
brain	O
registration	B
(	O
kybic	O
and	O
unser	O
2003	O
)	O
c	O
(	O
cid:13	O
)	O
2003	O
ieee	O
:	O
(	O
a	O
)	O
original	O
brain	O
atlas	O
and	O
patient	O
mri	O
images	O
overlaid	O
in	O
red–green	O
;	O
(	O
b	O
)	O
after	O
elastic	O
registration	O
with	O
eight	O
user-speciﬁed	O
landmarks	O
(	O
not	O
shown	O
)	O
;	O
(	O
c	O
)	O
a	O
cubic	B
b-spline	O
deformation	O
ﬁeld	O
,	O
shown	O
as	O
a	O
deformed	O
grid	O
.	O
ure	O
8.9b	O
)	O
,	O
the	O
values	O
of	O
certain	O
nodes	O
in	O
the	O
reﬁned	O
mesh	O
,	O
i.e.	O
,	O
those	O
adjacent	O
to	O
larger	O
cells	O
,	O
need	O
to	O
be	O
restricted	B
so	O
that	O
they	O
depend	O
on	O
their	O
parent	O
values	O
.	O
this	O
is	O
most	O
easily	O
accom-	O
plished	O
using	O
a	O
hierarchical	B
basis	O
representation	O
for	O
the	O
quadtree	B
spline	O
(	O
szeliski	O
1990b	O
)	O
and	O
selectively	O
setting	O
some	O
of	O
the	O
hierarchical	B
basis	O
functions	O
to	O
0	O
,	O
as	O
described	O
in	O
(	O
szeliski	O
and	O
shum	O
1996	O
)	O
.	O
8.3.1	O
application	O
:	O
medical	B
image	I
registration	O
because	O
they	O
excel	O
at	O
representing	O
smooth	O
elastic	O
deformation	O
ﬁelds	O
,	O
spline-based	B
motion	O
models	O
have	O
found	O
widespread	O
use	O
in	O
medical	B
image	I
registration	O
(	O
bajcsy	O
and	O
kovacic	O
1989	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
christensen	O
,	O
joshi	O
,	O
and	O
miller	O
1997	O
)	O
.10	O
registration	B
techniques	O
can	O
be	O
used	O
both	O
to	O
track	O
an	O
individual	O
patient	O
’	O
s	O
development	O
or	O
progress	O
over	O
time	O
(	O
a	O
lon-	O
gitudinal	O
study	O
)	O
or	O
to	O
match	O
different	O
patient	O
images	O
together	O
to	O
ﬁnd	O
commonalities	O
and	O
de-	O
tect	O
variations	O
or	O
pathologies	O
(	O
cross-sectional	O
studies	O
)	O
.	O
when	O
different	O
imaging	O
modalities	O
are	O
being	O
registered	O
,	O
e.g.	O
,	O
computed	O
tomography	O
(	O
ct	O
)	O
scans	O
and	O
magnetic	O
resonance	O
images	O
(	O
mri	O
)	O
,	O
mutual	O
information	O
measures	O
of	O
similarity	B
are	O
often	O
necessary	O
(	O
viola	O
and	O
wells	O
iii	O
1997	O
;	O
maes	O
,	O
collignon	O
,	O
vandermeulen	O
et	O
al	O
.	O
1997	O
)	O
.	O
kybic	O
and	O
unser	O
(	O
2003	O
)	O
provide	O
a	O
nice	O
literature	O
review	O
and	O
describe	O
a	O
complete	O
working	O
system	O
based	O
on	O
representing	O
both	O
the	O
images	O
and	O
the	O
deformation	O
ﬁelds	O
as	O
multi-resolution	O
splines	B
.	O
figure	O
8.10	O
shows	O
an	O
example	O
of	O
the	O
kybic	O
and	O
unser	O
system	O
being	O
used	O
to	O
register	O
a	O
patient	O
’	O
s	O
brain	O
mri	O
with	O
a	O
labeled	O
brain	O
atlas	O
image	B
.	O
the	O
system	O
can	O
be	O
run	O
in	O
a	O
fully	O
auto-	O
10	O
in	O
computer	O
graphics	O
,	O
such	O
elastic	O
volumetric	O
deformation	O
are	O
known	O
as	O
free-form	O
deformations	O
(	O
sederberg	O
and	O
parry	O
1986	O
;	O
coquillart	O
1990	O
;	O
celniker	O
and	O
gossard	O
1991	O
)	O
.	O
8.4	O
optical	B
ﬂow	I
409	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
8.11	O
octree	B
spline-based	O
image	B
registration	I
of	O
two	O
vertebral	O
surface	B
models	O
(	O
szeliski	O
and	O
lavall´ee	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
springer	O
:	O
(	O
a	O
)	O
after	O
initial	O
rigid	O
alignment	O
;	O
(	O
b	O
)	O
after	O
elastic	O
align-	O
ment	O
;	O
(	O
c	O
)	O
a	O
cross-section	O
through	O
the	O
adapted	O
octree	B
spline	O
deformation	O
ﬁeld	O
.	O
matic	O
mode	O
but	O
more	O
accurate	O
results	O
can	O
be	O
obtained	O
by	O
locating	O
a	O
few	O
key	O
landmarks	O
.	O
more	O
recent	O
papers	O
on	O
deformable	O
medical	B
image	I
registration	O
,	O
including	O
performance	O
evaluations	O
,	O
include	O
(	O
klein	O
,	O
staring	O
,	O
and	O
pluim	O
2007	O
;	O
glocker	O
,	O
komodakis	O
,	O
tziritas	O
et	O
al	O
.	O
2008	O
)	O
.	O
as	O
with	O
other	O
applications	O
,	O
regular	O
volumetric	B
splines	O
can	O
be	O
enhanced	O
using	O
selective	O
reﬁnement	O
.	O
in	O
the	O
case	O
of	O
3d	O
volumetric	B
image	O
or	O
surface	B
registration	O
,	O
these	O
are	O
known	O
as	O
octree	B
splines	O
(	O
szeliski	O
and	O
lavall´ee	O
1996	O
)	O
and	O
have	O
been	O
used	O
to	O
register	O
medical	O
surface	O
models	O
such	O
as	O
vertebrae	O
and	O
faces	B
from	O
different	O
patients	O
(	O
figure	O
8.11	O
)	O
.	O
8.4	O
optical	B
ﬂow	I
the	O
most	O
general	O
(	O
and	O
challenging	O
)	O
version	O
of	O
motion	B
estimation	I
is	O
to	O
compute	O
an	O
indepen-	O
dent	O
estimate	O
of	O
motion	B
at	O
each	O
pixel	O
,	O
which	O
is	O
generally	O
known	O
as	O
optical	O
(	O
or	O
optic	O
)	O
ﬂow	O
.	O
as	O
we	O
mentioned	O
in	O
the	O
previous	O
section	O
,	O
this	O
generally	O
involves	O
minimizing	O
the	O
brightness	O
or	O
color	B
difference	O
between	O
corresponding	O
pixels	O
summed	O
over	O
the	O
image	B
,	O
[	O
i1	O
(	O
xi	O
+	O
ui	O
)	O
−	O
i0	O
(	O
xi	O
)	O
]	O
2	O
.	O
(	O
8.69	O
)	O
essd−of	O
(	O
{	O
ui	O
}	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
since	O
the	O
number	O
of	O
variables	O
{	O
ui	O
}	O
is	O
twice	O
the	O
number	O
of	O
measurements	O
,	O
the	O
problem	O
is	O
underconstrained	O
.	O
the	O
two	O
classic	O
approaches	O
to	O
this	O
problem	O
are	O
to	O
perform	O
the	O
summa-	O
tion	B
locally	O
over	O
overlapping	O
regions	O
(	O
the	O
patch-based	B
or	O
window-based	B
approach	O
)	O
or	O
to	O
add	O
smoothness	B
terms	O
on	O
the	O
{	O
ui	O
}	O
ﬁeld	O
using	O
regularization	O
or	O
markov	O
random	O
ﬁelds	O
(	O
sec-	O
tion	B
3.7	O
)	O
and	O
to	O
search	O
for	O
a	O
global	B
minimum	O
.	O
the	O
patch-based	B
approach	O
usually	O
involves	O
using	O
a	O
taylor	O
series	O
expansion	O
of	O
the	O
dis-	O
placed	O
image	B
function	O
(	O
8.35	O
)	O
in	O
order	B
to	O
obtain	O
sub-pixel	O
estimates	O
(	O
lucas	O
and	O
kanade	O
1981	O
)	O
.	O
410	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
anandan	O
(	O
1989	O
)	O
shows	O
how	O
a	O
series	O
of	O
local	B
discrete	O
search	O
steps	O
can	O
be	O
interleaved	O
with	O
lucas–kanade	O
incremental	B
reﬁnement	I
steps	O
in	O
a	O
coarse-to-ﬁne	B
pyramid	O
scheme	O
,	O
which	O
al-	O
lows	O
the	O
estimation	B
of	O
large	O
motions	O
,	O
as	O
described	O
in	O
section	O
8.1.1.	O
he	O
also	O
analyzes	O
how	O
the	O
uncertainty	B
in	O
local	B
motion	O
estimates	O
is	O
related	O
to	O
the	O
eigenvalues	B
of	O
the	O
local	B
hessian	O
matrix	O
ai	O
(	O
8.44	O
)	O
,	O
as	O
shown	O
in	O
figures	O
8.3–8.4	O
.	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
(	O
1992	O
)	O
develop	O
a	O
uniﬁed	O
framework	O
for	O
describing	O
both	O
parametric	B
(	O
section	O
8.2	O
)	O
and	O
patch-based	B
optic	O
ﬂow	O
algorithms	O
and	O
provide	O
a	O
nice	O
introduc-	O
tion	B
to	O
this	O
topic	O
.	O
after	O
each	O
iteration	O
of	O
optic	O
ﬂow	O
estimation	B
in	O
a	O
coarse-to-ﬁne	B
pyramid	O
,	O
they	O
re-warp	O
one	O
of	O
the	O
images	O
so	O
that	O
only	O
incremental	B
ﬂow	O
estimates	O
are	O
computed	O
(	O
sec-	O
tion	B
8.1.1	O
)	O
.	O
when	O
overlapping	O
patches	O
are	O
used	O
,	O
an	O
efﬁcient	O
implementation	O
is	O
to	O
ﬁrst	O
com-	O
pute	O
the	O
outer	O
products	O
of	O
the	O
gradients	O
and	O
intensity	O
errors	O
(	O
8.40–8.41	O
)	O
at	O
every	O
pixel	O
and	O
then	O
perform	O
the	O
overlapping	O
window	O
sums	O
using	O
a	O
moving	B
average	I
ﬁlter.11	O
instead	O
of	O
solving	O
for	O
each	O
motion	B
(	O
or	O
motion	B
update	O
)	O
independently	O
,	O
horn	O
and	O
schunck	O
(	O
1981	O
)	O
develop	O
a	O
regularization-based	O
framework	O
where	O
(	O
8.69	O
)	O
is	O
simultaneously	O
minimized	O
over	O
all	O
ﬂow	O
vectors	O
{	O
ui	O
}	O
.	O
in	O
order	B
to	O
constrain	O
the	O
problem	O
,	O
smoothness	B
constraints	O
,	O
i.e.	O
,	O
squared	O
penalties	O
on	O
ﬂow	O
derivatives	O
,	O
are	O
added	O
to	O
the	O
basic	O
per-pixel	O
error	O
metric	O
.	O
because	O
the	O
technique	O
was	O
originally	O
developed	O
for	O
small	O
motions	O
in	O
a	O
variational	O
(	O
continuous	O
func-	O
tion	B
)	O
framework	O
,	O
the	O
linearized	O
brightness	O
constancy	O
constraint	B
corresponding	O
to	O
(	O
8.35	O
)	O
,	O
i.e.	O
,	O
(	O
8.38	O
)	O
,	O
is	O
more	O
commonly	O
written	O
as	O
an	O
analytic	O
integral	O
ehs	O
=	O
(	O
cid:90	O
)	O
(	O
ixu	O
+	O
iyv	O
+	O
it	O
)	O
2	O
dx	O
dy	O
,	O
(	O
8.70	O
)	O
where	O
(	O
ix	O
,	O
iy	O
)	O
=	O
∇i1	O
=	O
j	O
1	O
and	O
it	O
=	O
ei	O
is	O
the	O
temporal	O
derivative	O
,	O
i.e.	O
,	O
the	O
brightness	O
change	O
between	O
images	O
.	O
the	O
horn	O
and	O
schunck	O
model	O
can	O
also	O
be	O
viewed	O
as	O
the	O
limiting	O
case	O
of	O
spline-based	B
motion	O
estimation	B
as	O
the	O
splines	B
become	O
1x1	O
pixel	O
patches	O
.	O
it	O
is	O
also	O
possible	O
to	O
combine	O
ideas	O
from	O
local	B
and	O
global	B
ﬂow	O
estimation	B
into	O
a	O
single	O
framework	O
by	O
using	O
a	O
locally	O
aggregated	O
(	O
as	O
opposed	O
to	O
single-pixel	O
)	O
hessian	O
as	O
the	O
bright-	O
ness	O
constancy	O
term	O
(	O
bruhn	O
,	O
weickert	O
,	O
and	O
schn¨orr	O
2005	O
)	O
.	O
consider	O
the	O
discrete	B
analog	O
(	O
8.35	O
)	O
to	O
the	O
analytic	O
global	B
energy	O
(	O
8.70	O
)	O
,	O
ehsd	O
=	O
(	O
cid:88	O
)	O
i	O
i	O
[	O
j	O
ij	O
t	O
ut	O
i	O
]	O
ui	O
+	O
2eij	O
t	O
i	O
ui	O
+	O
e2	O
i	O
.	O
(	O
8.71	O
)	O
if	O
we	O
replace	O
the	O
per-pixel	O
(	O
rank	O
1	O
)	O
hessians	O
ai	O
=	O
[	O
j	O
ij	O
t	O
i	O
]	O
and	O
residuals	O
bi	O
=	O
j	O
iei	O
with	O
area-	O
aggregated	O
versions	O
(	O
8.40–8.41	O
)	O
,	O
we	O
obtain	O
a	O
global	B
minimization	O
algorithm	B
where	O
region-	O
based	O
brightness	O
constraints	O
are	O
used	O
.	O
another	O
extension	O
to	O
the	O
basic	O
optic	O
ﬂow	O
model	O
is	O
to	O
use	O
a	O
combination	O
of	O
global	B
(	O
para-	O
metric	O
)	O
and	O
local	B
motion	O
models	O
.	O
for	O
example	O
,	O
if	O
we	O
know	O
that	O
the	O
motion	B
is	O
due	O
to	O
a	O
camera	B
11other	O
smoothing	B
or	O
aggregation	O
ﬁlters	O
can	O
also	O
be	O
used	O
at	O
this	O
stage	O
(	O
bruhn	O
,	O
weickert	O
,	O
and	O
schn¨orr	O
2005	O
)	O
.	O
8.4	O
optical	B
ﬂow	I
411	O
moving	O
in	O
a	O
static	O
scene	O
(	O
rigid	O
motion	O
)	O
,	O
we	O
can	O
re-formulate	O
the	O
problem	O
as	O
the	O
estimation	B
of	O
a	O
per-pixel	O
depth	O
along	O
with	O
the	O
parameters	B
of	O
the	O
global	B
camera	O
motion	B
(	O
adiv	O
1989	O
;	O
hanna	O
1991	O
;	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
;	O
szeliski	O
and	O
coughlan	O
1997	O
;	O
nir	O
,	O
bruckstein	O
,	O
and	O
kimmel	O
2008	O
;	O
wedel	O
,	O
cremers	O
,	O
pock	O
et	O
al	O
.	O
2009	O
)	O
.	O
such	O
techniques	O
are	O
closely	O
related	O
to	O
stereo	B
matching	I
(	O
chapter	O
11	O
)	O
.	O
alternatively	O
,	O
we	O
can	O
estimate	O
either	O
per-image	O
or	O
per-segment	O
afﬁne	B
motion	O
models	O
combined	O
with	O
per-pixel	O
residual	O
corrections	O
(	O
black	O
and	O
jepson	O
1996	O
;	O
ju	O
,	O
black	O
,	O
and	O
jepson	O
1996	O
;	O
chang	O
,	O
tekalp	O
,	O
and	O
sezan	O
1997	O
;	O
m´emin	O
and	O
p´erez	O
2002	O
)	O
.	O
we	O
revisit	O
this	O
topic	O
in	O
section	O
8.5.	O
of	O
course	O
,	O
image	B
brightness	O
may	O
not	O
always	O
be	O
an	O
appropriate	O
metric	O
for	O
measuring	O
ap-	O
pearance	O
consistency	O
,	O
e.g.	O
,	O
when	O
the	O
lighting	B
in	O
an	O
image	B
is	O
varying	O
.	O
as	O
discussed	O
in	O
sec-	O
tion	B
8.1	O
,	O
matching	B
gradients	O
,	O
ﬁltered	O
images	O
,	O
or	O
other	O
metrics	O
such	O
as	O
image	B
hessians	O
(	O
sec-	O
ond	O
derivative	O
measures	O
)	O
may	O
be	O
more	O
appropriate	O
.	O
it	O
is	O
also	O
possible	O
to	O
locally	O
compute	O
the	O
phase	O
of	O
steerable	B
ﬁlters	O
in	O
the	O
image	B
,	O
which	O
is	O
insensitive	O
to	O
both	O
bias	B
and	I
gain	I
transforma-	O
tions	O
(	O
fleet	O
and	O
jepson	O
1990	O
)	O
.	O
papenberg	O
,	O
bruhn	O
,	O
brox	O
et	O
al	O
.	O
(	O
2006	O
)	O
review	O
and	O
explore	O
such	O
constraints	O
and	O
also	O
provide	O
a	O
detailed	O
analysis	O
and	O
justiﬁcation	O
for	O
iteratively	O
re-warping	O
images	O
during	O
incremental	B
ﬂow	O
computation	O
.	O
because	O
the	O
brightness	O
constancy	O
constraint	B
is	O
evaluated	O
at	O
each	O
pixel	O
independently	O
,	O
rather	O
than	O
being	O
summed	O
over	O
patches	O
where	O
the	O
constant	O
ﬂow	O
assumption	O
may	O
be	O
violated	O
,	O
global	B
optimization	I
approaches	O
tend	O
to	O
perform	O
better	O
near	O
motion	B
discontinuities	O
.	O
this	O
is	O
especially	O
true	O
if	O
robust	B
metrics	O
are	O
used	O
in	O
the	O
smoothness	B
constraint	O
(	O
black	O
and	O
anandan	O
1996	O
;	O
bab-hadiashar	O
and	O
suter	O
1998a	O
)	O
.12	O
one	O
popular	O
choice	O
for	O
robust	O
metrics	O
in	O
the	O
l1	O
norm	O
,	O
also	O
known	O
as	O
total	B
variation	I
(	O
tv	O
)	O
,	O
which	O
results	O
in	O
a	O
convex	O
energy	O
whose	O
global	B
minimum	O
can	O
be	O
found	O
(	O
bruhn	O
,	O
weickert	O
,	O
and	O
schn¨orr	O
2005	O
;	O
papenberg	O
,	O
bruhn	O
,	O
brox	O
et	O
al	O
.	O
2006	O
)	O
.	O
anisotropic	B
smoothness	I
priors	O
,	O
which	O
apply	O
a	O
different	O
smoothness	B
in	O
the	O
direc-	O
tions	O
parallel	O
and	O
perpendicular	O
to	O
the	O
image	B
gradient	O
,	O
are	O
another	O
popular	O
choice	O
(	O
nagel	O
and	O
enkelmann	O
1986	O
;	O
sun	O
,	O
roth	O
,	O
lewis	O
et	O
al	O
.	O
2008	O
;	O
werlberger	O
,	O
trobin	O
,	O
pock	O
et	O
al	O
.	O
2009	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
learn	O
a	O
set	O
of	O
better	O
smoothness	B
constraints	O
(	O
derivative	O
ﬁlters	O
and	O
robust	B
functions	O
)	O
from	O
a	O
set	O
of	O
paired	O
ﬂow	O
and	O
intensity	O
images	O
(	O
sun	O
,	O
roth	O
,	O
lewis	O
et	O
al	O
.	O
2008	O
)	O
.	O
ad-	O
ditional	O
details	O
on	O
some	O
of	O
these	O
techniques	O
are	O
given	O
by	O
baker	O
,	O
black	O
,	O
lewis	O
et	O
al	O
.	O
(	O
2007	O
)	O
and	O
baker	O
,	O
scharstein	O
,	O
lewis	O
et	O
al	O
.	O
(	O
2009	O
)	O
.	O
because	O
of	O
the	O
large	O
,	O
two-dimensional	B
search	O
space	O
in	O
estimating	O
ﬂow	O
,	O
most	O
algorithms	O
use	O
variations	O
of	O
gradient	B
descent	I
and	O
coarse-to-ﬁne	B
continuation	O
methods	O
to	O
minimize	O
the	O
global	B
energy	O
function	O
.	O
this	O
contrasts	O
starkly	O
with	O
stereo	O
matching	B
(	O
which	O
is	O
an	O
“	O
easier	O
”	O
one-dimensional	O
disparity	O
estimation	B
problem	O
)	O
,	O
where	O
combinatorial	O
optimization	O
techniques	O
have	O
been	O
the	O
method	O
of	O
choice	O
for	O
the	O
last	O
decade	O
.	O
fortunately	O
,	O
combinatorial	O
optimization	O
methods	O
based	O
on	O
markov	O
random	O
ﬁelds	O
are	O
be-	O
12	O
robust	B
brightness	O
metrics	O
(	O
section	O
8.1	O
,	O
(	O
8.2	O
)	O
)	O
can	O
also	O
help	O
improve	O
the	O
performance	O
of	O
window-based	B
ap-	O
proaches	O
(	O
black	O
and	O
anandan	O
1996	O
)	O
.	O
412	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
8.12	O
evaluation	B
of	O
the	O
results	O
of	O
24	O
optical	B
ﬂow	I
algorithms	O
,	O
october	O
2009	O
,	O
http	O
:	O
//vision.middlebury.edu/ﬂow/	O
,	O
(	O
baker	O
,	O
scharstein	O
,	O
lewis	O
et	O
al	O
.	O
2009	O
)	O
.	O
by	O
moving	O
the	O
mouse	O
pointer	O
over	O
an	O
underlined	O
performance	O
score	O
,	O
the	O
user	O
can	O
interactively	O
view	O
the	O
correspond-	O
ing	O
ﬂow	O
and	O
error	O
maps	O
.	O
clicking	O
on	O
a	O
score	O
toggles	O
between	O
the	O
computed	O
and	O
ground	O
truth	O
ﬂows	O
.	O
next	O
to	O
each	O
score	O
,	O
the	O
corresponding	O
rank	O
in	O
the	O
current	O
column	O
is	O
indicated	O
by	O
a	O
smaller	O
blue	O
number	O
.	O
the	O
minimum	O
(	O
best	O
)	O
score	O
in	O
each	O
column	O
is	O
shown	O
in	O
boldface	O
.	O
the	O
table	O
is	O
sorted	O
by	O
the	O
average	O
rank	O
(	O
computed	O
over	O
all	O
24	O
columns	O
,	O
three	O
region	B
masks	O
for	O
each	O
of	O
the	O
eight	O
sequences	O
)	O
.	O
the	O
average	O
rank	O
serves	O
as	O
an	O
approximate	O
measure	O
of	O
performance	O
under	O
the	O
selected	O
metric/statistic	O
.	O
8.4	O
optical	B
ﬂow	I
413	O
ginning	O
to	O
appear	O
and	O
tend	O
to	O
be	O
among	O
the	O
better-performing	O
methods	O
on	O
the	O
recently	O
re-	O
leased	O
optical	B
ﬂow	I
database	O
(	O
baker	O
,	O
black	O
,	O
lewis	O
et	O
al	O
.	O
2007	O
)	O
.13	O
examples	B
of	O
such	O
techniques	O
include	O
the	O
one	O
developed	O
by	O
glocker	O
,	O
paragios	O
,	O
komodakis	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
who	O
use	O
a	O
coarse-to-ﬁne	B
strategy	O
with	O
per-pixel	O
2d	O
uncertainty	B
estimates	O
,	O
which	O
are	O
then	O
used	O
to	O
guide	O
the	O
reﬁnement	O
and	O
search	O
at	O
the	O
next	O
ﬁner	O
level	O
.	O
instead	O
of	O
using	O
gra-	O
dient	O
descent	O
to	O
reﬁne	O
the	O
ﬂow	O
estimates	O
,	O
a	O
combinatorial	O
search	O
over	O
discrete	O
displacement	O
labels	O
(	O
which	O
is	O
able	O
to	O
ﬁnd	O
better	O
energy	O
minima	O
)	O
is	O
performed	O
using	O
their	O
fast-pd	O
algorithm	B
(	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
2008	O
)	O
.	O
lempitsky	O
,	O
roth	O
,	O
and	O
rother	O
.	O
(	O
2008	O
)	O
use	O
fusion	O
moves	O
(	O
lempitsky	O
,	O
rother	O
,	O
and	O
blake	O
2007	O
)	O
over	O
proposals	O
generated	O
from	O
basic	O
ﬂow	O
algorithms	O
(	O
horn	O
and	O
schunck	O
1981	O
;	O
lucas	O
and	O
kanade	O
1981	O
)	O
to	O
ﬁnd	O
good	O
solutions	O
.	O
the	O
basic	O
idea	O
behind	O
fusion	O
moves	O
is	O
to	O
replace	O
portions	O
of	O
the	O
current	O
best	O
estimate	O
with	O
hypotheses	O
generated	O
by	O
more	O
basic	O
techniques	O
(	O
or	O
their	O
shifted	O
versions	O
)	O
and	O
to	O
alternate	O
them	O
with	O
local	O
gradient	B
descent	I
for	O
better	O
energy	O
minimization	O
.	O
the	O
ﬁeld	O
of	O
accurate	O
motion	B
estimation	I
continues	O
to	O
evolve	O
at	O
a	O
rapid	O
pace	O
,	O
with	O
signif-	O
icant	O
advances	O
in	O
performance	O
occurring	O
every	O
year	O
.	O
the	O
optical	B
ﬂow	I
evaluation	O
web	O
site	O
(	O
http	O
:	O
//vision.middlebury.edu/ﬂow/	O
)	O
is	O
a	O
good	O
source	O
of	O
pointers	O
to	O
high-performing	O
recently	O
developed	O
algorithms	O
(	O
figure	O
8.12	O
)	O
.	O
8.4.1	O
multi-frame	B
motion	O
estimation	B
so	O
far	O
,	O
we	O
have	O
looked	O
at	O
motion	B
estimation	I
as	O
a	O
two-frame	B
problem	O
,	O
where	O
the	O
goal	O
is	O
to	O
compute	O
a	O
motion	B
ﬁeld	O
that	O
aligns	O
pixels	O
from	O
one	O
image	B
with	O
those	O
in	O
another	O
.	O
in	O
practice	O
,	O
motion	B
estimation	I
is	O
usually	O
applied	O
to	O
video	B
,	O
where	O
a	O
whole	O
sequence	O
of	O
frames	O
is	O
available	O
to	O
perform	O
this	O
task	O
.	O
one	O
classic	O
approach	O
to	O
multi-frame	B
motion	O
is	O
to	O
ﬁlter	O
the	O
spatio-temporal	O
volume	O
using	O
oriented	O
or	O
steerable	B
ﬁlters	O
(	O
heeger	O
1988	O
)	O
,	O
in	O
a	O
manner	O
analogous	O
to	O
oriented	B
edge	O
detec-	O
tion	B
(	O
section	O
3.2.3	O
)	O
.	O
figure	O
8.13	O
shows	O
two	O
frames	O
from	O
the	O
commonly	O
used	O
ﬂower	O
garden	O
sequence	O
,	O
as	O
well	O
as	O
a	O
horizontal	O
slice	O
through	O
the	O
spatio-temporal	O
volume	O
,	O
i.e.	O
,	O
the	O
3d	O
vol-	O
ume	O
created	O
by	O
stacking	O
all	O
of	O
the	O
video	B
frames	O
together	O
.	O
because	O
the	O
pixel	O
motion	O
is	O
mostly	O
horizontal	O
,	O
the	O
slopes	O
of	O
individual	O
(	O
textured	O
)	O
pixel	O
tracks	O
,	O
which	O
correspond	O
to	O
their	O
horizon-	O
tal	O
velocities	O
,	O
can	O
clearly	O
be	O
seen	O
.	O
spatio-temporal	O
ﬁltering	O
uses	O
a	O
3d	O
volume	O
around	O
each	O
pixel	O
to	O
determine	O
the	O
best	O
orientation	O
in	O
space–time	O
,	O
which	O
corresponds	O
directly	O
to	O
a	O
pixel	O
’	O
s	O
velocity	O
.	O
unfortunately	O
,	O
in	O
order	B
to	O
obtain	O
reasonably	O
accurate	O
velocity	O
estimates	O
everywhere	O
in	O
an	O
image	B
,	O
spatio-temporal	O
ﬁlters	O
have	O
moderately	O
large	O
extents	O
,	O
which	O
severely	O
degrades	O
the	O
quality	O
of	O
their	O
estimates	O
near	O
motion	B
discontinuities	O
.	O
(	O
this	O
same	O
problem	O
is	O
endemic	O
in	O
13	O
http	O
:	O
//vision.middlebury.edu/ﬂow/	O
.	O
414	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
8.13	O
slice	O
through	O
a	O
spatio-temporal	O
volume	O
(	O
szeliski	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
ieee	O
:	O
(	O
a–b	O
)	O
two	O
frames	O
from	O
the	O
ﬂower	O
garden	O
sequence	O
;	O
(	O
c	O
)	O
a	O
horizontal	O
slice	O
through	O
the	O
complete	O
spatio-temporal	O
volume	O
,	O
with	O
the	O
arrows	O
indicating	O
locations	O
of	O
potential	O
key	O
frames	O
where	O
ﬂow	O
is	O
estimated	O
.	O
note	O
that	O
the	O
colors	O
for	O
the	O
ﬂower	O
garden	O
sequence	O
are	O
incorrect	O
;	O
the	O
correct	O
colors	O
(	O
yellow	O
ﬂowers	O
)	O
are	O
shown	O
in	O
figure	O
8.15	O
.	O
2d	O
window-based	B
motion	O
estimators	O
.	O
)	O
an	O
alternative	O
to	O
full	O
spatio-temporal	O
ﬁltering	O
is	O
to	O
estimate	O
more	O
local	B
spatio-temporal	O
derivatives	O
and	O
use	O
them	O
inside	O
a	O
global	B
optimization	I
framework	O
to	O
ﬁll	O
in	O
textureless	O
regions	O
(	O
bruhn	O
,	O
weickert	O
,	O
and	O
schn¨orr	O
2005	O
;	O
govindu	O
2006	O
)	O
.	O
another	O
alternative	O
is	O
to	O
simultaneously	O
estimate	O
multiple	B
motion	O
estimates	O
,	O
while	O
also	O
optionally	O
reasoning	O
about	O
occlusion	O
relationships	O
(	O
szeliski	O
1999	O
)	O
.	O
figure	O
8.13c	O
shows	O
schemat-	O
ically	O
one	O
potential	O
approach	O
to	O
this	O
problem	O
.	O
the	O
horizontal	O
arrows	O
show	O
the	O
locations	O
of	O
keyframes	O
s	O
where	O
motion	B
is	O
estimated	O
,	O
while	O
other	O
slices	O
indicate	O
video	B
frames	O
t	O
whose	O
colors	O
are	O
matched	O
with	O
those	O
predicted	O
by	O
interpolating	O
between	O
the	O
keyframes	O
.	O
motion	B
es-	O
timation	O
can	O
be	O
cast	O
as	O
a	O
global	B
energy	O
minimization	O
problem	O
that	O
simultaneously	O
minimizes	O
brightness	O
compatibility	O
and	O
ﬂow	O
compatibility	O
terms	O
between	O
keyframes	O
and	O
other	O
frames	O
,	O
in	O
addition	O
to	O
using	O
robust	O
smoothness	B
terms	O
.	O
the	O
multi-view	B
framework	O
is	O
potentially	O
even	O
more	O
appropriate	O
for	O
rigid	O
scene	O
motion	O
(	O
multi-view	B
stereo	I
)	O
(	O
section	O
11.6	O
)	O
,	O
where	O
the	O
unknowns	O
at	O
each	O
pixel	O
are	O
disparities	O
and	O
occlusion	O
relationships	O
can	O
be	O
determined	O
directly	O
from	O
pixel	O
depths	O
(	O
szeliski	O
1999	O
;	O
kol-	O
mogorov	O
and	O
zabih	O
2002	O
)	O
.	O
however	O
,	O
it	O
may	O
also	O
be	O
applicable	O
to	O
general	O
motion	B
,	O
with	O
the	O
addition	O
of	O
models	O
for	O
object	O
accelerations	O
and	O
occlusion	O
relationships	O
.	O
8.4.2	O
application	O
:	O
video	B
denoising	I
video	O
denoising	O
is	O
the	O
process	O
of	O
removing	O
noise	B
and	O
other	O
artifacts	O
such	O
as	O
scratches	O
from	O
ﬁlm	O
and	O
video	B
(	O
kokaram	O
2004	O
)	O
.	O
unlike	O
single	O
image	O
denoising	O
,	O
where	O
the	O
only	O
information	O
available	O
is	O
in	O
the	O
current	O
picture	O
,	O
video	B
denoisers	O
can	O
average	O
or	O
borrow	O
information	O
from	O
adjacent	O
frames	O
.	O
however	O
,	O
in	O
order	B
to	O
do	O
this	O
without	O
introducing	O
blur	O
or	O
jitter	O
(	O
irregular	O
motion	B
)	O
,	O
they	O
need	O
accurate	O
per-pixel	O
motion	B
estimates	O
.	O
exercise	O
8.7	O
lists	O
some	O
of	O
the	O
steps	O
required	O
,	O
which	O
include	O
the	O
ability	O
to	O
determine	O
if	O
the	O
8.5	O
layered	B
motion	O
415	O
current	O
motion	B
estimate	O
is	O
accurate	O
enough	O
to	O
permit	O
averaging	O
with	O
other	O
frames	O
.	O
gai	O
and	O
kang	O
(	O
2009	O
)	O
describe	O
their	O
recently	O
developed	O
restoration	O
process	O
,	O
which	O
involves	O
a	O
series	O
of	O
additional	O
steps	O
to	O
deal	O
with	O
the	O
special	O
characteristics	O
of	O
vintage	O
ﬁlm	O
.	O
8.4.3	O
application	O
:	O
de-interlacing	B
another	O
commonly	O
used	O
application	O
of	O
per-pixel	O
motion	B
estimation	I
is	O
video	B
de-interlacing	O
,	O
which	O
is	O
the	O
process	O
of	O
converting	O
a	O
video	B
taken	O
with	O
alternating	O
ﬁelds	O
of	O
even	O
and	O
odd	O
lines	B
to	O
a	O
non-interlaced	O
signal	O
that	O
contains	O
both	O
ﬁelds	O
in	O
each	O
frame	O
(	O
de	O
haan	O
and	O
bellers	O
1998	O
)	O
.	O
two	O
simple	O
de-interlacing	B
techniques	O
are	O
bob	O
,	O
which	O
copies	O
the	O
line	O
above	O
or	O
below	O
the	O
missing	O
line	O
from	O
the	O
same	O
ﬁeld	O
,	O
and	O
weave	O
,	O
which	O
copies	O
the	O
corresponding	O
line	O
from	O
the	O
ﬁeld	O
before	O
or	O
after	O
.	O
the	O
names	O
come	O
from	O
the	O
visual	O
artifacts	O
generated	O
by	O
these	O
two	O
simple	O
techniques	O
:	O
bob	O
introduces	O
an	O
up-and-down	O
bobbing	O
motion	B
along	O
strong	O
horizontal	O
lines	B
;	O
weave	O
can	O
lead	O
to	O
a	O
“	O
zippering	O
”	O
effect	O
along	O
horizontally	O
translating	O
edges	O
.	O
replacing	O
these	O
copy	O
operators	O
with	O
averages	O
can	O
help	O
but	O
does	O
not	O
completely	O
remove	O
these	O
artifacts	O
.	O
a	O
wide	O
variety	O
of	O
improved	O
techniques	O
have	O
been	O
developed	O
for	O
this	O
process	O
,	O
which	O
is	O
often	O
embedded	O
in	O
specialized	O
dsp	O
chips	O
found	O
inside	O
video	B
digitization	O
boards	O
in	O
computers	O
(	O
since	O
broadcast	O
video	B
is	O
often	O
interlaced	O
,	O
while	O
computer	O
monitors	O
are	O
not	O
)	O
.	O
a	O
large	O
class	O
of	O
these	O
techniques	O
estimates	O
local	B
per-pixel	O
motions	O
and	O
interpolates	O
the	O
missing	B
data	I
from	O
the	O
information	O
available	O
in	O
spatially	O
and	O
temporally	O
adjacent	O
ﬁelds	O
.	O
dai	O
,	O
baker	O
,	O
and	O
kang	O
(	O
2009	O
)	O
review	O
this	O
literature	O
and	O
propose	O
their	O
own	O
algorithm	B
,	O
which	O
selects	O
among	O
seven	O
different	O
interpolation	B
functions	O
at	O
each	O
pixel	O
using	O
an	O
mrf	O
framework	O
.	O
8.5	O
layered	B
motion	O
in	O
many	O
situation	O
,	O
visual	O
motion	O
is	O
caused	O
by	O
the	O
movement	O
of	O
a	O
small	O
number	O
of	O
objects	O
at	O
different	O
depths	O
in	O
the	O
scene	O
.	O
in	O
such	O
situations	O
,	O
the	O
pixel	O
motions	O
can	O
be	O
described	O
more	O
succinctly	O
(	O
and	O
estimated	O
more	O
reliably	O
)	O
if	O
pixels	O
are	O
grouped	O
into	O
appropriate	O
objects	O
or	O
layers	B
(	O
wang	O
and	O
adelson	O
1994	O
)	O
.	O
figure	O
8.14	O
shows	O
this	O
approach	O
schematically	O
.	O
the	O
motion	B
in	O
this	O
sequence	O
is	O
caused	O
by	O
the	O
translational	B
motion	O
of	O
the	O
checkered	O
background	O
and	O
the	O
rotation	O
of	O
the	O
foreground	O
hand	O
.	O
the	O
complete	O
motion	B
sequence	O
can	O
be	O
reconstructed	O
from	O
the	O
appearance	O
of	O
the	O
foreground	O
and	O
background	O
elements	O
,	O
which	O
can	O
be	O
represented	O
as	O
alpha-matted	O
images	O
(	O
sprites	B
or	O
video	B
objects	O
)	O
and	O
the	O
parametric	B
motion	O
corresponding	O
to	O
each	O
layer	O
.	O
displacing	O
and	O
compositing	B
these	O
layers	B
in	O
back	O
to	O
front	O
order	B
(	O
section	O
3.1.3	O
)	O
recreates	O
the	O
original	O
video	B
sequence	O
.	O
layered	B
motion	O
representations	O
not	O
only	O
lead	O
to	O
compact	O
representations	O
(	O
wang	O
and	O
adelson	O
1994	O
;	O
lee	O
,	O
ge	O
chen	O
,	O
lung	O
bruce	O
lin	O
et	O
al	O
.	O
1997	O
)	O
,	O
but	O
they	O
also	O
exploit	O
the	O
infor-	O
mation	O
available	O
in	O
multiple	B
video	O
frames	O
,	O
as	O
well	O
as	O
accurately	O
modeling	B
the	O
appearance	O
of	O
416	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
intensity	O
map	O
alpha	O
map	O
velocity	O
map	O
intensity	O
map	O
alpha	O
map	O
velocity	O
map	O
frame	O
1	O
frame	O
2	O
frame	O
3	O
figure	O
8.14	O
layered	B
motion	O
estimation	B
framework	O
(	O
wang	O
and	O
adelson	O
1994	O
)	O
c	O
(	O
cid:13	O
)	O
1994	O
ieee	O
:	O
the	O
top	O
two	O
rows	O
describe	O
the	O
two	O
layers	O
,	O
each	O
of	O
which	O
consists	O
of	O
an	O
intensity	O
(	O
color	B
)	O
image	B
,	O
an	O
alpha	O
mask	O
(	O
black=transparent	O
)	O
,	O
and	O
a	O
parametric	B
motion	O
ﬁeld	O
.	O
the	O
layers	B
are	O
com-	O
posited	O
with	O
different	O
amounts	O
of	O
motion	B
to	O
recreate	O
the	O
video	B
sequence	O
.	O
pixels	O
near	O
motion	B
discontinuities	O
.	O
this	O
makes	O
them	O
particularly	O
suited	O
as	O
a	O
representation	O
for	O
image-based	O
rendering	B
(	O
section	O
13.2.1	O
)	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
;	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
as	O
well	O
as	O
object-level	O
video	B
editing	O
.	O
to	O
compute	O
a	O
layered	B
representation	O
of	O
a	O
video	B
sequence	O
,	O
wang	O
and	O
adelson	O
(	O
1994	O
)	O
ﬁrst	O
estimate	O
afﬁne	B
motion	O
models	O
over	O
a	O
collection	O
of	O
non-overlapping	O
patches	O
and	O
then	O
cluster	O
these	O
estimates	O
using	O
k-means	O
.	O
they	O
then	O
alternate	O
between	O
assigning	O
pixels	O
to	O
layers	B
and	O
recomputing	O
motion	B
estimates	O
for	O
each	O
layer	O
using	O
the	O
assigned	O
pixels	O
,	O
using	O
a	O
technique	O
ﬁrst	O
proposed	O
by	O
darrell	O
and	O
pentland	O
(	O
1991	O
)	O
.	O
once	O
the	O
parametric	B
motions	O
and	O
pixel-wise	O
layer	O
assignments	O
have	O
been	O
computed	O
for	O
each	O
frame	O
independently	O
,	O
layers	B
are	O
constructed	O
by	O
warping	O
and	O
merging	B
the	O
various	O
layer	O
pieces	O
from	O
all	O
of	O
the	O
frames	O
together	O
.	O
median	B
ﬁltering	O
is	O
used	O
to	O
produce	O
sharp	O
composite	O
layers	B
that	O
are	O
robust	B
to	O
small	O
intensity	O
variations	O
,	O
as	O
well	O
as	O
to	O
infer	O
occlusion	O
relationships	O
between	O
the	O
layers	B
.	O
figure	O
8.15	O
shows	O
the	O
results	O
of	O
this	O
process	O
on	O
the	O
ﬂower	O
garden	O
sequence	O
.	O
you	O
can	O
see	O
both	O
the	O
initial	O
and	O
ﬁnal	O
layer	O
assignments	O
for	O
one	O
of	O
the	O
frames	O
,	O
as	O
well	O
as	O
the	O
composite	O
ﬂow	O
and	O
the	O
alpha-matted	O
layers	B
with	O
their	O
corresponding	O
ﬂow	O
vectors	O
overlaid	O
.	O
in	O
follow-on	O
work	O
,	O
weiss	O
and	O
adelson	O
(	O
1996	O
)	O
use	O
a	O
formal	O
probabilistic	B
mixture	O
model	O
to	O
infer	O
both	O
the	O
optimal	O
number	O
of	O
layers	B
and	O
the	O
per-pixel	O
layer	O
assignments	O
.	O
weiss	O
(	O
1997	O
)	O
8.5	O
layered	B
motion	O
417	O
ﬂow	O
initial	O
layers	B
ﬁnal	O
layers	B
color	O
image	B
(	O
input	O
frame	O
)	O
layers	B
with	O
pixel	O
assignments	O
and	O
ﬂow	O
figure	O
8.15	O
layered	B
motion	O
estimation	B
results	O
(	O
wang	O
and	O
adelson	O
1994	O
)	O
c	O
(	O
cid:13	O
)	O
1994	O
ieee	O
.	O
further	O
generalizes	O
this	O
approach	O
by	O
replacing	O
the	O
per-layer	O
afﬁne	B
motion	O
models	O
with	O
smooth	O
regularized	O
per-pixel	O
motion	B
estimates	O
,	O
which	O
allows	O
the	O
system	O
to	O
better	O
handle	O
curved	O
and	O
undulating	O
layers	B
,	O
such	O
as	O
those	O
seen	O
in	O
most	O
real-world	O
sequences	O
.	O
the	O
above	O
approaches	O
,	O
however	O
,	O
still	O
make	O
a	O
distinction	O
between	O
estimating	O
the	O
motions	O
and	O
layer	O
assignments	O
and	O
then	O
later	O
estimating	O
the	O
layer	O
colors	O
.	O
in	O
the	O
system	O
described	O
by	O
baker	O
,	O
szeliski	O
,	O
and	O
anandan	O
(	O
1998	O
)	O
,	O
the	O
generative	O
model	O
illustrated	O
in	O
figure	O
8.14	O
is	O
gen-	O
eralized	O
to	O
account	O
for	O
real-world	O
rigid	O
motion	O
scenes	O
.	O
the	O
motion	B
of	O
each	O
frame	O
is	O
described	O
using	O
a	O
3d	O
camera	B
model	O
and	O
the	O
motion	B
of	O
each	O
layer	O
is	O
described	O
using	O
a	O
3d	O
plane	O
equation	O
plus	O
per-pixel	O
residual	O
depth	O
offsets	O
(	O
the	O
plane	O
plus	O
parallax	O
representation	O
(	O
section	O
2.1.5	O
)	O
)	O
.	O
the	O
initial	O
layer	O
estimation	B
proceeds	O
in	O
a	O
manner	O
similar	O
to	O
that	O
of	O
wang	O
and	O
adelson	O
(	O
1994	O
)	O
,	O
except	O
that	O
rigid	O
planar	O
motions	O
(	O
homographies	O
)	O
are	O
used	O
instead	O
of	O
afﬁne	B
motion	O
models	O
.	O
the	O
ﬁnal	O
model	O
reﬁnement	O
,	O
however	O
,	O
jointly	O
re-optimizes	O
the	O
layer	O
pixel	O
color	O
and	O
opacity	B
values	O
ll	O
and	O
the	O
3d	O
depth	O
,	O
plane	O
,	O
and	O
motion	B
parameters	O
zl	O
,	O
nl	O
,	O
and	O
p	O
t	O
by	O
minimizing	O
the	O
discrepancy	O
between	O
the	O
re-synthesized	O
and	O
observed	O
motion	B
sequences	O
(	O
baker	O
,	O
szeliski	O
,	O
and	O
anandan	O
1998	O
)	O
.	O
figure	O
8.16	O
shows	O
the	O
ﬁnal	O
results	O
obtained	O
with	O
this	O
algorithm	B
.	O
as	O
you	O
can	O
see	O
,	O
the	O
motion	B
boundaries	O
and	O
layer	O
assignments	O
are	O
much	O
crisper	O
than	O
those	O
in	O
figure	O
8.15.	O
because	O
of	O
the	O
per-pixel	O
depth	O
offsets	O
,	O
the	O
individual	O
layer	O
color	B
values	O
are	O
also	O
sharper	O
than	O
those	O
obtained	O
with	O
afﬁne	O
or	O
planar	O
motion	O
models	O
.	O
while	O
the	O
original	O
system	O
of	O
baker	O
,	O
szeliski	O
,	O
and	O
anandan	O
(	O
1998	O
)	O
required	O
a	O
rough	O
initial	O
assignment	O
of	O
pixels	O
to	O
layers	B
,	O
torr	O
,	O
szeliski	O
,	O
and	O
anandan	O
(	O
2001	O
)	O
describe	O
automated	B
bayesian	O
techniques	O
for	O
initializing	O
this	O
system	O
and	O
determining	O
the	O
optimal	O
number	O
of	O
layers	B
.	O
layered	B
motion	O
estimation	B
continues	O
to	O
be	O
an	O
active	O
area	O
of	O
research	O
.	O
representative	O
pa-	O
pers	O
in	O
this	O
area	O
include	O
(	O
sawhney	O
and	O
ayer	O
1996	O
;	O
jojic	O
and	O
frey	O
2001	O
;	O
xiao	O
and	O
shah	O
2005	O
;	O
kumar	O
,	O
torr	O
,	O
and	O
zisserman	O
2008	O
;	O
thayananthan	O
,	O
iwasaki	O
,	O
and	O
cipolla	O
2008	O
;	O
schoenemann	O
and	O
cremers	O
2008	O
)	O
.	O
418	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
8.16	O
layered	B
stereo	O
reconstruction	O
(	O
baker	O
,	O
szeliski	O
,	O
and	O
anandan	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
ieee	O
:	O
(	O
a	O
)	O
ﬁrst	O
and	O
(	O
b	O
)	O
last	O
input	O
images	O
;	O
(	O
c	O
)	O
initial	O
segmentation	B
into	O
six	O
layers	B
;	O
(	O
d	O
)	O
and	O
(	O
e	O
)	O
the	O
six	O
layer	O
sprites	B
;	O
(	O
f	O
)	O
depth	B
map	I
for	O
planar	O
sprites	O
(	O
darker	O
denotes	O
closer	O
)	O
;	O
front	O
layer	O
(	O
g	O
)	O
before	O
and	O
(	O
h	O
)	O
after	O
residual	O
depth	O
estimation	O
.	O
note	O
that	O
the	O
colors	O
for	O
the	O
ﬂower	O
garden	O
sequence	O
are	O
incorrect	O
;	O
the	O
correct	O
colors	O
(	O
yellow	O
ﬂowers	O
)	O
are	O
shown	O
in	O
figure	O
8.15.	O
o	O
of	O
course	O
,	O
layers	B
are	O
not	O
the	O
only	O
way	O
to	O
introduce	O
segmentation	B
into	O
motion	B
estimation	I
.	O
a	O
large	O
number	O
of	O
algorithms	O
have	O
been	O
developed	O
that	O
alternate	O
between	O
estimating	O
optic	O
ﬂow	O
vectors	O
and	O
segmenting	O
them	O
into	O
coherent	O
regions	O
(	O
black	O
and	O
jepson	O
1996	O
;	O
ju	O
,	O
black	O
,	O
and	O
jepson	O
1996	O
;	O
chang	O
,	O
tekalp	O
,	O
and	O
sezan	O
1997	O
;	O
m´emin	O
and	O
p´erez	O
2002	O
;	O
cremers	O
and	O
soatto	O
2005	O
)	O
.	O
some	O
of	O
the	O
more	O
recent	O
techniques	O
rely	O
on	O
ﬁrst	O
segmenting	O
the	O
input	O
color	B
images	O
and	O
then	O
estimating	O
per-segment	O
motions	O
that	O
produce	O
a	O
coherent	O
motion	B
ﬁeld	O
while	O
also	O
modeling	B
occlusions	O
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
;	O
zitnick	O
,	O
jojic	O
,	O
and	O
kang	O
2005	O
;	O
stein	O
,	O
hoiem	O
,	O
and	O
hebert	O
2007	O
;	O
thayananthan	O
,	O
iwasaki	O
,	O
and	O
cipolla	O
2008	O
)	O
.	O
8.5.1	O
application	O
:	O
frame	B
interpolation	I
frame	O
interpolation	B
is	O
another	O
widely	O
used	O
application	O
of	O
motion	B
estimation	I
,	O
often	O
imple-	O
mented	O
in	O
the	O
same	O
circuitry	O
as	O
de-interlacing	B
hardware	O
required	O
to	O
match	O
an	O
incoming	O
video	B
8.5	O
layered	B
motion	O
419	O
to	O
a	O
monitor	O
’	O
s	O
actual	O
refresh	O
rate	O
.	O
as	O
with	O
de-interlacing	O
,	O
information	O
from	O
novel	O
in-between	O
frames	O
needs	O
to	O
be	O
interpolated	O
from	O
preceding	O
and	O
subsequent	O
frames	O
.	O
the	O
best	O
results	O
can	O
be	O
obtained	O
if	O
an	O
accurate	O
motion	B
estimate	O
can	O
be	O
computed	O
at	O
each	O
unknown	O
pixel	O
’	O
s	O
lo-	O
cation	O
.	O
however	O
,	O
in	O
addition	O
to	O
computing	O
the	O
motion	B
,	O
occlusion	O
information	O
is	O
critical	O
to	O
prevent	O
colors	O
from	O
being	O
contaminated	O
by	O
moving	O
foreground	O
objects	O
that	O
might	O
obscure	O
a	O
particular	O
pixel	O
in	O
a	O
preceding	O
or	O
subsequent	O
frame	O
.	O
in	O
a	O
little	O
more	O
detail	O
,	O
consider	O
figure	O
8.13c	O
and	O
assume	O
that	O
the	O
arrows	O
denote	O
keyframes	O
between	O
which	O
we	O
wish	O
to	O
interpolate	O
additional	O
images	O
.	O
the	O
orientations	O
of	O
the	O
streaks	O
in	O
this	O
ﬁgure	O
encode	O
the	O
velocities	O
of	O
individual	O
pixels	O
.	O
if	O
the	O
same	O
motion	B
estimate	O
u0	O
is	O
obtained	O
at	O
location	O
x0	O
in	O
image	B
i0	O
as	O
is	O
obtained	O
at	O
location	O
x0	O
+	O
u0	O
in	O
image	B
i1	O
,	O
the	O
ﬂow	O
vectors	O
are	O
said	O
to	O
be	O
consistent	O
.	O
this	O
motion	B
estimate	O
can	O
be	O
transferred	O
to	O
location	O
x0	O
+	O
tu0	O
in	O
the	O
image	B
it	O
being	O
generated	O
,	O
where	O
t	O
∈	O
(	O
0	O
,	O
1	O
)	O
is	O
the	O
time	O
of	O
interpolation	O
.	O
the	O
ﬁnal	O
color	B
value	O
at	O
pixel	O
x0	O
+	O
tu0	O
can	O
be	O
computed	O
as	O
a	O
linear	B
blend	O
,	O
it	O
(	O
x0	O
+	O
tu0	O
)	O
=	O
(	O
1	O
−	O
t	O
)	O
i0	O
(	O
x0	O
)	O
+	O
ti1	O
(	O
x0	O
+	O
u0	O
)	O
.	O
(	O
8.72	O
)	O
if	O
,	O
however	O
,	O
the	O
motion	B
vectors	O
are	O
different	O
at	O
corresponding	O
locations	O
,	O
some	O
method	O
must	O
be	O
used	O
to	O
determine	O
which	O
is	O
correct	O
and	O
which	O
image	B
contains	O
colors	O
that	O
are	O
occluded	O
.	O
the	O
actual	O
reasoning	O
is	O
even	O
more	O
subtle	O
than	O
this	O
.	O
one	O
example	O
of	O
such	O
an	O
interpolation	B
algorithm	O
,	O
based	O
on	O
earlier	O
work	O
in	O
depth	B
map	I
interpolation	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
;	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
which	O
is	O
the	O
one	O
used	O
in	O
the	O
ﬂow	O
evaluation	B
paper	O
of	O
baker	O
,	O
black	O
,	O
lewis	O
et	O
al	O
.	O
(	O
2007	O
)	O
;	O
baker	O
,	O
scharstein	O
,	O
lewis	O
et	O
al	O
.	O
(	O
2009	O
)	O
.	O
an	O
even	O
higher-	O
quality	O
frame	B
interpolation	I
algorithm	O
,	O
which	O
uses	O
gradient-based	O
reconstruction	O
,	O
is	O
presented	O
by	O
mahajan	O
,	O
huang	O
,	O
matusik	O
et	O
al	O
.	O
(	O
2009	O
)	O
.	O
8.5.2	O
transparent	B
layers	O
and	O
reﬂections	B
a	O
special	O
case	O
of	O
layered	B
motion	O
that	O
occurs	O
quite	O
often	O
is	O
transparent	B
motion	O
,	O
which	O
is	O
usu-	O
ally	O
caused	O
by	O
reﬂections	O
seen	O
in	O
windows	O
and	O
picture	O
frames	O
(	O
figures	O
8.17	O
and	O
8.18	O
)	O
.	O
some	O
of	O
the	O
early	O
work	O
in	O
this	O
area	O
handles	O
transparent	B
motion	O
by	O
either	O
just	O
estimating	O
the	O
component	O
motions	O
(	O
shizawa	O
and	O
mase	O
1991	O
;	O
bergen	O
,	O
burt	O
,	O
hingorani	O
et	O
al	O
.	O
1992	O
;	O
darrell	O
and	O
simoncelli	O
1993	O
;	O
irani	O
,	O
rousso	O
,	O
and	O
peleg	O
1994	O
)	O
or	O
by	O
assigning	O
individual	O
pixels	O
to	O
competing	O
motion	B
layers	O
(	O
darrell	O
and	O
pentland	O
1995	O
;	O
black	O
and	O
anandan	O
1996	O
;	O
ju	O
,	O
black	O
,	O
and	O
jepson	O
1996	O
)	O
,	O
which	O
is	O
appropriate	O
for	O
scenes	O
partially	O
seen	O
through	O
a	O
ﬁne	O
occluder	O
(	O
e.g.	O
,	O
foliage	O
)	O
.	O
however	O
,	O
to	O
accurately	O
separate	O
truly	O
transparent	B
layers	O
,	O
a	O
better	O
model	O
for	O
motion	O
due	O
to	O
reﬂections	B
is	O
required	O
.	O
because	O
of	O
the	O
way	O
that	O
light	O
is	O
both	O
reﬂected	O
from	O
and	O
transmitted	O
through	O
a	O
glass	O
surface	B
,	O
the	O
correct	O
model	O
for	O
reﬂections	O
is	O
an	O
additive	O
one	O
,	O
where	O
each	O
moving	O
layer	O
contributes	O
some	O
intensity	O
to	O
the	O
ﬁnal	O
image	B
(	O
szeliski	O
,	O
avidan	O
,	O
and	O
anandan	O
2000	O
)	O
.	O
420	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
8.17	O
light	O
reﬂecting	O
off	O
the	O
transparent	B
glass	O
of	O
a	O
picture	O
frame	O
:	O
(	O
a	O
)	O
ﬁrst	O
image	B
from	O
the	O
input	O
sequence	O
;	O
(	O
b	O
)	O
dominant	O
motion	B
layer	O
min-composite	O
;	O
(	O
c	O
)	O
secondary	O
motion	B
residual	O
layer	O
max-composite	O
;	O
(	O
d–e	O
)	O
ﬁnal	O
estimated	O
picture	O
and	O
reﬂection	O
layers	B
the	O
original	O
images	O
are	O
from	O
black	O
and	O
anandan	O
(	O
1996	O
)	O
,	O
while	O
the	O
separated	O
layers	B
are	O
from	O
szeliski	O
,	O
avidan	O
,	O
and	O
anandan	O
(	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
ieee	O
.	O
if	O
the	O
motions	O
of	O
the	O
individual	O
layers	B
are	O
known	O
,	O
the	O
recovery	B
of	O
the	O
individual	O
layers	B
is	O
a	O
simple	O
constrained	B
least	O
squares	O
problem	O
,	O
with	O
the	O
individual	O
layer	O
images	O
are	O
constrained	B
to	O
be	O
positive	O
.	O
however	O
,	O
this	O
problem	O
can	O
suffer	O
from	O
extended	O
low-frequency	O
ambiguities	O
,	O
especially	O
if	O
either	O
of	O
the	O
layers	B
lacks	O
dark	O
(	O
black	O
)	O
pixels	O
or	O
the	O
motion	B
is	O
uni-directional	O
.	O
in	O
their	O
paper	O
,	O
szeliski	O
,	O
avidan	O
,	O
and	O
anandan	O
(	O
2000	O
)	O
show	O
that	O
the	O
simultaneous	O
estimation	B
of	O
the	O
motions	O
and	O
layer	O
values	O
can	O
be	O
obtained	O
by	O
alternating	O
between	O
robustly	O
computing	O
the	O
motion	B
layers	O
and	O
then	O
making	O
conservative	O
(	O
upper-	O
or	O
lower-bound	O
)	O
estimates	O
of	O
the	O
layer	O
intensities	O
.	O
the	O
ﬁnal	O
motion	B
and	O
layer	O
estimates	O
can	O
then	O
be	O
polished	O
using	O
gradient	O
descent	O
on	O
a	O
joint	B
constrained	O
least	B
squares	I
formulation	O
similar	O
to	O
(	O
baker	O
,	O
szeliski	O
,	O
and	O
anandan	O
1998	O
)	O
,	O
where	O
the	O
over	O
compositing	O
operator	O
is	O
replaced	O
with	O
addition	O
.	O
figures	O
8.17	O
and	O
8.18	O
show	O
the	O
results	O
of	O
applying	O
these	O
techniques	O
to	O
two	O
different	O
pic-	O
ture	O
frames	O
with	O
reﬂections	O
.	O
notice	O
how	O
,	O
in	O
the	O
second	O
sequence	O
,	O
the	O
amount	O
of	O
reﬂected	O
light	O
is	O
quite	O
low	O
compared	O
to	O
the	O
transmitted	O
light	O
(	O
the	O
picture	O
of	O
the	O
girl	O
)	O
and	O
yet	O
the	O
algorithm	B
is	O
still	O
able	O
to	O
recover	O
both	O
layers	B
.	O
unfortunately	O
,	O
the	O
simple	O
parametric	B
motion	O
models	O
used	O
in	O
(	O
szeliski	O
,	O
avidan	O
,	O
and	O
anan-	O
dan	O
2000	O
)	O
are	O
only	O
valid	O
for	O
planar	O
reﬂectors	O
and	O
scenes	O
with	O
shallow	O
depth	O
.	O
the	O
extension	O
of	O
these	O
techniques	O
to	O
curved	O
reﬂectors	O
and	O
scenes	O
with	O
signiﬁcant	O
depth	O
has	O
also	O
been	O
studied	O
8.6	O
additional	O
reading	O
421	O
figure	O
8.18	O
transparent	B
motion	O
separation	O
(	O
szeliski	O
,	O
avidan	O
,	O
and	O
anandan	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
ieee	O
:	O
(	O
a	O
)	O
ﬁrst	O
image	B
from	O
input	O
sequence	O
;	O
(	O
b	O
)	O
dominant	O
motion	B
layer	O
min-composite	O
;	O
(	O
c	O
)	O
sec-	O
ondary	O
motion	B
residual	O
layer	O
max-composite	O
;	O
(	O
d–e	O
)	O
ﬁnal	O
estimated	O
picture	O
and	O
reﬂection	O
lay-	O
ers	O
.	O
note	O
that	O
the	O
reﬂected	O
layers	B
in	O
(	O
c	O
)	O
and	O
(	O
e	O
)	O
are	O
doubled	O
in	O
intensity	O
to	O
better	O
show	O
their	O
structure	O
.	O
(	O
swaminathan	O
,	O
kang	O
,	O
szeliski	O
et	O
al	O
.	O
2002	O
;	O
criminisi	O
,	O
kang	O
,	O
swaminathan	O
et	O
al	O
.	O
2005	O
)	O
,	O
as	O
has	O
the	O
extension	O
to	O
scenes	O
with	O
more	O
complex	O
3d	O
depth	O
(	O
tsin	O
,	O
kang	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
8.6	O
additional	O
reading	O
some	O
of	O
the	O
earliest	O
algorithms	O
for	O
motion	O
estimation	B
were	O
developed	O
for	O
motion-compen-	O
sated	O
video	B
coding	O
(	O
netravali	O
and	O
robbins	O
1979	O
)	O
and	O
such	O
techniques	O
continue	O
to	O
be	O
used	O
in	O
modern	O
coding	O
standards	O
such	O
as	O
mpeg	O
,	O
h.263	O
,	O
and	O
h.264	O
(	O
le	O
gall	O
1991	O
;	O
richardson	O
2003	O
)	O
.14	O
in	O
computer	O
vision	O
,	O
this	O
ﬁeld	O
was	O
originally	O
called	O
image	B
sequence	O
analysis	O
(	O
huang	O
1981	O
)	O
.	O
some	O
of	O
the	O
early	O
seminal	O
papers	O
include	O
the	O
variational	O
approaches	O
developed	O
by	O
horn	O
and	O
schunck	O
(	O
1981	O
)	O
and	O
nagel	O
and	O
enkelmann	O
(	O
1986	O
)	O
,	O
and	O
the	O
patch-based	B
translational	O
alignment	B
technique	O
developed	O
by	O
lucas	O
and	O
kanade	O
(	O
1981	O
)	O
.	O
hierarchical	B
(	O
coarse-to-ﬁne	B
)	O
versions	O
of	O
such	O
algorithms	O
were	O
developed	O
by	O
quam	O
(	O
1984	O
)	O
,	O
anandan	O
(	O
1989	O
)	O
,	O
and	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
(	O
1992	O
)	O
,	O
although	O
they	O
have	O
also	O
long	O
been	O
used	O
in	O
motion	B
estimation	I
for	O
video	B
coding	O
.	O
translational	B
motion	O
models	O
were	O
generalized	B
to	O
afﬁne	B
motion	O
by	O
rehg	O
and	O
witkin	O
(	O
1991	O
)	O
,	O
fuh	O
and	O
maragos	O
(	O
1991	O
)	O
,	O
and	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
(	O
1992	O
)	O
and	O
to	O
quadric	O
refer-	O
ence	O
surfaces	O
by	O
shashua	O
and	O
toelg	O
(	O
1997	O
)	O
and	O
shashua	O
and	O
wexler	O
(	O
2001	O
)	O
—see	O
baker	O
and	O
matthews	O
(	O
2004	O
)	O
for	O
a	O
nice	O
review	O
.	O
such	O
parametric	B
motion	O
estimation	B
algorithms	O
have	O
found	O
widespread	O
application	O
in	O
video	B
summarization	I
(	O
teodosio	O
and	O
bender	O
1993	O
;	O
irani	O
and	O
anan-	O
dan	O
1998	O
)	O
,	O
video	B
stabilization	I
(	O
hansen	O
,	O
anandan	O
,	O
dana	O
et	O
al	O
.	O
1994	O
;	O
srinivasan	O
,	O
chellappa	O
,	O
14	O
http	O
:	O
//www.itu.int/rec/t-rec-h.264	O
.	O
422	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
veeraraghavan	O
et	O
al	O
.	O
2005	O
;	O
matsushita	O
,	O
ofek	O
,	O
ge	O
et	O
al	O
.	O
2006	O
)	O
,	O
and	O
video	B
compression	I
(	O
irani	O
,	O
hsu	O
,	O
and	O
anandan	O
1995	O
;	O
lee	O
,	O
ge	O
chen	O
,	O
lung	O
bruce	O
lin	O
et	O
al	O
.	O
1997	O
)	O
.	O
surveys	B
of	O
parametric	B
image	O
registration	B
include	O
those	O
by	O
brown	O
(	O
1992	O
)	O
,	O
zitov	O
’	O
aa	O
and	O
flusser	O
(	O
2003	O
)	O
,	O
goshtasby	O
(	O
2005	O
)	O
,	O
and	O
szeliski	O
(	O
2006a	O
)	O
.	O
good	O
general	O
surveys	B
and	O
comparisons	O
of	O
optic	O
ﬂow	O
algorithms	O
include	O
those	O
by	O
ag-	O
garwal	O
and	O
nandhakumar	O
(	O
1988	O
)	O
,	O
barron	O
,	O
fleet	O
,	O
and	O
beauchemin	O
(	O
1994	O
)	O
,	O
otte	O
and	O
nagel	O
(	O
1994	O
)	O
,	O
mitiche	O
and	O
bouthemy	O
(	O
1996	O
)	O
,	O
stiller	O
and	O
konrad	O
(	O
1999	O
)	O
,	O
mccane	O
,	O
novins	O
,	O
cran-	O
nitch	O
et	O
al	O
.	O
(	O
2001	O
)	O
,	O
szeliski	O
(	O
2006a	O
)	O
,	O
and	O
baker	O
,	O
black	O
,	O
lewis	O
et	O
al	O
.	O
(	O
2007	O
)	O
.	O
the	O
topic	O
of	O
matching	B
primitives	O
,	O
i.e.	O
,	O
pre-transforming	O
images	O
using	O
ﬁltering	O
or	O
other	O
techniques	O
before	O
matching	B
,	O
is	O
treated	O
in	O
a	O
number	O
of	O
papers	O
(	O
anandan	O
1989	O
;	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
;	O
scharstein	O
1994	O
;	O
zabih	O
and	O
woodﬁll	O
1994	O
;	O
cox	O
,	O
roy	O
,	O
and	O
hingorani	O
1995	O
;	O
viola	O
and	O
wells	O
iii	O
1997	O
;	O
negahdaripour	O
1998	O
;	O
kim	O
,	O
kolmogorov	O
,	O
and	O
zabih	O
2003	O
;	O
jia	O
and	O
tang	O
2003	O
;	O
papenberg	O
,	O
bruhn	O
,	O
brox	O
et	O
al	O
.	O
2006	O
;	O
seitz	O
and	O
baker	O
2009	O
)	O
.	O
hirschm¨uller	O
and	O
scharstein	O
(	O
2009	O
)	O
compare	O
a	O
number	O
of	O
these	O
approaches	O
and	O
report	O
on	O
their	O
relative	O
performance	O
in	O
scenes	O
with	O
exposure	O
differences	O
.	O
the	O
publication	O
of	O
a	O
new	O
benchmark	O
for	O
evaluating	O
optical	B
ﬂow	I
algorithms	O
(	O
baker	O
,	O
black	O
,	O
lewis	O
et	O
al	O
.	O
2007	O
)	O
has	O
led	O
to	O
rapid	O
advances	O
in	O
the	O
quality	O
of	O
estimation	B
algorithms	O
,	O
to	O
the	O
point	O
where	O
new	O
datasets	O
may	O
soon	O
become	O
necessary	O
.	O
according	O
to	O
their	O
updated	O
techni-	O
cal	O
report	O
(	O
baker	O
,	O
scharstein	O
,	O
lewis	O
et	O
al	O
.	O
2009	O
)	O
,	O
most	O
of	O
the	O
best	O
performing	O
algorithms	O
use	O
robust	B
data	O
and	O
smoothness	B
norms	O
(	O
often	O
l1	O
tv	O
)	O
and	O
continuous	O
variational	O
optimization	O
techniques	O
,	O
although	O
some	O
techniques	O
use	O
discrete	B
optimization	O
or	O
segmentations	O
(	O
papen-	O
berg	O
,	O
bruhn	O
,	O
brox	O
et	O
al	O
.	O
2006	O
;	O
trobin	O
,	O
pock	O
,	O
cremers	O
et	O
al	O
.	O
2008	O
;	O
xu	O
,	O
chen	O
,	O
and	O
jia	O
2008	O
;	O
lempitsky	O
,	O
roth	O
,	O
and	O
rother	O
.	O
2008	O
;	O
werlberger	O
,	O
trobin	O
,	O
pock	O
et	O
al	O
.	O
2009	O
;	O
lei	O
and	O
yang	O
2009	O
;	O
wedel	O
,	O
cremers	O
,	O
pock	O
et	O
al	O
.	O
2009	O
)	O
.	O
8.7	O
exercises	O
ex	O
8.1	O
:	O
correlation	O
implement	O
and	O
compare	O
the	O
performance	O
of	O
the	O
following	O
correlation	O
algorithms	O
:	O
•	O
sum	O
of	O
squared	O
differences	O
(	O
8.1	O
)	O
•	O
sum	O
of	O
robust	B
differences	O
(	O
8.2	O
)	O
•	O
sum	O
of	O
absolute	O
differences	O
(	O
8.3	O
)	O
•	O
bias–gain	O
compensated	O
squared	O
differences	O
(	O
8.9	O
)	O
•	O
normalized	B
cross-correlation	O
(	O
8.11	O
)	O
8.7	O
exercises	O
423	O
•	O
windowed	B
versions	O
of	O
the	O
above	O
(	O
8.22–8.23	O
)	O
•	O
fourier-based	O
implementations	O
of	O
the	O
above	O
measures	O
(	O
8.18–8.20	O
)	O
•	O
phase	B
correlation	I
(	O
8.24	O
)	O
•	O
gradient	O
cross-correlation	O
(	O
argyriou	O
and	O
vlachos	O
2003	O
)	O
.	O
compare	O
a	O
few	O
of	O
your	O
algorithms	O
on	O
different	O
motion	B
sequences	O
with	O
different	O
amounts	O
of	O
noise	B
,	O
exposure	O
variation	O
,	O
occlusion	O
,	O
and	O
frequency	O
variations	O
(	O
e.g.	O
,	O
high-frequency	O
textures	O
,	O
such	O
as	O
sand	O
or	O
cloth	O
,	O
and	O
low-frequency	O
images	O
,	O
such	O
as	O
clouds	O
or	O
motion-blurred	O
video	B
)	O
.	O
some	O
datasets	O
with	O
illumination	O
variation	O
and	O
ground	O
truth	O
correspondences	O
(	O
horizontal	O
mo-	O
tion	B
)	O
can	O
be	O
found	O
at	O
http	O
:	O
//vision.middlebury.edu/stereo/data/	O
(	O
the	O
2005	O
and	O
2006	O
datasets	O
)	O
.	O
some	O
additional	O
ideas	O
,	O
variants	O
,	O
and	O
questions	O
:	O
1.	O
when	O
do	O
you	O
think	O
that	O
phase	B
correlation	I
will	O
outperform	O
regular	O
correlation	O
or	O
ssd	O
?	O
can	O
you	O
show	O
this	O
experimentally	O
or	O
justify	O
it	O
analytically	O
?	O
2.	O
for	O
the	O
fourier-based	O
masked	O
or	O
windowed	B
correlation	O
and	O
sum	O
of	O
squared	O
differences	O
,	O
the	O
results	O
should	O
be	O
the	O
same	O
as	O
the	O
direct	B
implementations	O
.	O
note	O
that	O
you	O
will	O
have	O
to	O
expand	O
(	O
8.5	O
)	O
into	O
a	O
sum	O
of	O
pairwise	O
correlations	O
,	O
just	O
as	O
in	O
(	O
8.22	O
)	O
.	O
(	O
this	O
is	O
part	O
of	O
the	O
exercise	O
.	O
)	O
3.	O
for	O
the	O
bias–gain	O
corrected	O
variant	O
of	O
squared	O
differences	O
(	O
8.9	O
)	O
,	O
you	O
will	O
also	O
have	O
to	O
expand	O
the	O
terms	O
to	O
end	O
up	O
with	O
a	O
3	O
×	O
3	O
(	O
least	B
squares	I
)	O
system	O
of	O
equations	B
.	O
if	O
implementing	O
the	O
fast	O
fourier	O
transform	B
version	O
,	O
you	O
will	O
need	O
to	O
ﬁgure	O
out	O
how	O
all	O
of	O
these	O
entries	O
can	O
be	O
evaluated	O
in	O
the	O
fourier	O
domain	O
.	O
4	O
.	O
(	O
optional	O
)	O
implement	O
some	O
of	O
the	O
additional	O
techniques	O
studied	O
by	O
hirschm¨uller	O
and	O
scharstein	O
(	O
2009	O
)	O
and	O
see	O
if	O
your	O
results	O
agree	O
with	O
theirs	O
.	O
ex	O
8.2	O
:	O
afﬁne	B
registration	O
implement	O
a	O
coarse-to-ﬁne	B
direct	O
method	O
for	O
afﬁne	O
and	O
pro-	O
jective	O
image	B
alignment	O
.	O
1.	O
does	O
it	O
help	O
to	O
use	O
lower-order	O
(	O
simpler	O
)	O
models	O
at	O
coarser	O
levels	O
of	O
the	O
pyramid	B
(	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
)	O
?	O
2	O
.	O
(	O
optional	O
)	O
implement	O
patch-based	B
acceleration	O
(	O
shum	O
and	O
szeliski	O
2000	O
;	O
baker	O
and	O
matthews	O
2004	O
)	O
.	O
3.	O
see	O
the	O
baker	O
and	O
matthews	O
(	O
2004	O
)	O
survey	O
for	O
more	O
comparisons	O
and	O
ideas	O
.	O
ex	O
8.3	O
:	O
stabilization	O
write	O
a	O
program	O
to	O
stabilize	O
an	O
input	O
video	B
sequence	O
.	O
you	O
should	O
implement	O
the	O
following	O
steps	O
,	O
as	O
described	O
in	O
section	O
8.2.1	O
:	O
424	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
1.	O
compute	O
the	O
translation	B
(	O
and	O
,	O
optionally	O
,	O
rotation	O
)	O
between	O
successive	O
frames	O
with	O
ro-	O
bust	O
outlier	O
rejection	O
.	O
2.	O
perform	O
temporal	O
high-pass	O
ﬁltering	O
on	O
the	O
motion	B
parameters	O
to	O
remove	O
the	O
low-	O
frequency	O
component	O
(	O
smooth	O
the	O
motion	B
)	O
.	O
3.	O
compensate	O
for	O
the	O
high-frequency	O
motion	B
,	O
zooming	O
in	O
slightly	O
(	O
a	O
user-speciﬁed	O
amount	O
)	O
to	O
avoid	O
missing	O
edge	O
pixels	O
.	O
4	O
.	O
(	O
optional	O
)	O
do	O
not	O
zoom	O
in	O
,	O
but	O
instead	O
borrow	O
pixels	O
from	O
previous	O
or	O
subsequent	O
frames	O
to	O
ﬁll	O
in	O
.	O
5	O
.	O
(	O
optional	O
)	O
compensate	O
for	O
images	O
that	O
are	O
blurry	O
because	O
of	O
fast	O
motion	O
by	O
“	O
stealing	O
”	O
higher	O
frequencies	O
from	O
adjacent	O
frames	O
.	O
ex	O
8.4	O
:	O
optical	B
ﬂow	I
compute	O
optical	B
ﬂow	I
(	O
spline-based	B
or	O
per-pixel	O
)	O
between	O
two	O
im-	O
ages	O
,	O
using	O
one	O
or	O
more	O
of	O
the	O
techniques	O
described	O
in	O
this	O
chapter	O
.	O
1.	O
test	O
your	O
algorithms	O
on	O
the	O
motion	B
sequences	O
available	O
at	O
http	O
:	O
//vision.middlebury	O
.	O
edu/ﬂow/	O
or	O
http	O
:	O
//people.csail.mit.edu/celiu/motionannotation/	O
and	O
compare	O
your	O
re-	O
sults	O
(	O
visually	O
)	O
to	O
those	O
available	O
on	O
these	O
web	O
sites	O
.	O
if	O
you	O
think	O
your	O
algorithm	B
is	O
competitive	O
with	O
the	O
best	O
,	O
consider	O
submitting	O
it	O
for	O
formal	O
evaluation	B
.	O
2.	O
visualize	O
the	O
quality	O
of	O
your	O
results	O
by	O
generating	O
in-between	O
images	O
using	O
frame	O
in-	O
terpolation	O
(	O
exercise	O
8.5	O
)	O
.	O
3.	O
what	O
can	O
you	O
say	O
about	O
the	O
relative	O
efﬁciency	B
(	O
speed	O
)	O
of	O
your	O
approach	O
?	O
ex	O
8.5	O
:	O
automated	B
morphing	O
/	O
frame	B
interpolation	I
write	O
a	O
program	O
to	O
automatically	O
morph	O
between	O
pairs	B
of	O
images	O
.	O
implement	O
the	O
following	O
steps	O
,	O
as	O
sketched	O
out	O
in	O
section	O
8.5.1	O
and	O
by	O
baker	O
,	O
scharstein	O
,	O
lewis	O
et	O
al	O
.	O
(	O
2009	O
)	O
:	O
1.	O
compute	O
the	O
ﬂow	O
both	O
ways	O
(	O
previous	O
exercise	O
)	O
.	O
consider	O
using	O
a	O
multi-frame	B
(	O
n	O
>	O
2	O
)	O
technique	O
to	O
better	O
deal	O
with	O
occluded	O
regions	O
.	O
2.	O
for	O
each	O
intermediate	O
(	O
morphed	O
)	O
image	B
,	O
compute	O
a	O
set	O
of	O
ﬂow	O
vectors	O
and	O
which	O
im-	O
ages	O
should	O
be	O
used	O
in	O
the	O
ﬁnal	O
composition	O
.	O
3.	O
blend	O
(	O
cross-dissolve	O
)	O
the	O
images	O
and	O
view	O
with	O
a	O
sequence	O
viewer	O
.	O
try	O
this	O
out	O
on	O
images	O
of	O
your	O
friends	O
and	O
colleagues	O
and	O
see	O
what	O
kinds	O
of	O
morphs	O
you	O
get	O
.	O
alternatively	O
,	O
take	O
a	O
video	B
sequence	O
and	O
do	O
a	O
high-quality	O
slow-motion	O
effect	O
.	O
compare	O
your	O
algorithm	B
with	O
simple	O
cross-fading	O
.	O
8.7	O
exercises	O
425	O
ex	O
8.6	O
:	O
motion-based	O
user	O
interaction	O
write	O
a	O
program	O
to	O
compute	O
a	O
low-resolution	O
mo-	O
tion	B
ﬁeld	O
in	O
order	B
to	O
interactively	O
control	O
a	O
simple	O
application	O
(	O
cutler	O
and	O
turk	O
1998	O
)	O
.	O
for	O
example	O
:	O
1.	O
downsample	O
each	O
image	B
using	O
a	O
pyramid	B
and	O
compute	O
the	O
optical	B
ﬂow	I
(	O
spline-based	B
or	O
pixel-based	O
)	O
from	O
the	O
previous	O
frame	O
.	O
2.	O
segment	O
each	O
training	O
video	B
sequence	O
into	O
different	O
“	O
actions	O
”	O
(	O
e.g.	O
,	O
hand	O
moving	O
in-	O
wards	O
,	O
moving	O
up	O
,	O
no	O
motion	B
)	O
and	O
“	O
learn	O
”	O
the	O
velocity	O
ﬁelds	O
associated	O
with	O
each	O
one	O
.	O
(	O
you	O
can	O
simply	O
ﬁnd	O
the	O
mean	O
and	O
variance	O
for	O
each	O
motion	B
ﬁeld	O
or	O
use	O
something	O
more	O
sophisticated	O
,	O
such	O
as	O
a	O
support	O
vector	O
machine	O
(	O
svm	O
)	O
.	O
)	O
3.	O
write	O
a	O
recognizer	O
that	O
ﬁnds	O
successive	O
actions	O
of	O
approximately	O
the	O
right	O
duration	O
and	O
hook	O
it	O
up	O
to	O
an	O
interactive	B
application	O
(	O
e.g.	O
,	O
a	O
sound	O
generator	O
or	O
a	O
computer	O
game	O
)	O
.	O
4.	O
ask	O
your	O
friends	O
to	O
test	O
it	O
out	O
.	O
ex	O
8.7	O
:	O
video	B
denoising	I
implement	O
the	O
algorithm	B
sketched	O
in	O
application	O
8.4.2.	O
your	O
al-	O
gorithm	O
should	O
contain	O
the	O
following	O
steps	O
:	O
1.	O
compute	O
accurate	O
per-pixel	O
ﬂow	O
.	O
2.	O
determine	O
which	O
pixels	O
in	O
the	O
reference	O
image	B
have	O
good	O
matches	O
with	O
other	O
frames	O
.	O
3.	O
either	O
average	O
all	O
of	O
the	O
matched	O
pixels	O
or	O
choose	O
the	O
sharpest	O
image	B
,	O
if	O
trying	O
to	O
compensate	O
for	O
blur	O
.	O
don	O
’	O
t	O
forget	O
to	O
use	O
regular	O
single-frame	O
denoising	O
techniques	O
as	O
part	O
of	O
your	O
solution	O
,	O
(	O
see	O
section	O
3.4.4	O
,	O
section	O
3.7.3	O
,	O
and	O
exercise	O
3.11	O
)	O
.	O
4.	O
devise	O
a	O
fall-back	O
strategy	B
for	O
areas	O
where	O
you	O
don	O
’	O
t	O
think	O
the	O
ﬂow	O
estimates	O
are	O
accu-	O
rate	O
enough	O
.	O
ex	O
8.8	O
:	O
motion	B
segmentation	O
write	O
a	O
program	O
to	O
segment	O
an	O
image	B
into	O
separately	O
mov-	O
ing	O
regions	O
or	O
to	O
reliably	O
ﬁnd	O
motion	B
boundaries	O
.	O
use	O
the	O
human-assisted	O
motion	B
segmentation	O
database	O
at	O
http	O
:	O
//people.csail.mit.edu/celiu/	O
motionannotation/	O
as	O
some	O
of	O
your	O
test	O
data	O
.	O
ex	O
8.9	O
:	O
layered	B
motion	O
estimation	B
decompose	O
into	O
separate	O
layers	B
(	O
section	O
8.5	O
)	O
a	O
video	B
sequence	O
of	O
a	O
scene	O
taken	O
with	O
a	O
moving	O
camera	O
:	O
1.	O
find	O
the	O
set	O
of	O
dominant	O
(	O
afﬁne	B
or	O
planar	O
perspective	O
)	O
motions	O
,	O
either	O
by	O
computing	O
them	O
in	O
blocks	O
or	O
ﬁnding	O
a	O
robust	B
estimate	O
and	O
then	O
iteratively	O
re-ﬁtting	O
outliers	O
.	O
2.	O
determine	O
which	O
pixels	O
go	O
with	O
each	O
motion	B
.	O
426	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
3.	O
construct	O
the	O
layers	B
by	O
blending	B
pixels	O
from	O
different	O
frames	O
.	O
4	O
.	O
(	O
optional	O
)	O
add	O
per-pixel	O
residual	O
ﬂows	O
or	O
depths	O
.	O
5	O
.	O
(	O
optional	O
)	O
reﬁne	O
your	O
estimates	O
using	O
an	O
iterative	B
global	O
optimization	O
technique	O
.	O
6	O
.	O
(	O
optional	O
)	O
write	O
an	O
interactive	B
renderer	O
to	O
generate	O
in-between	O
frames	O
or	O
view	O
the	O
scene	O
from	O
different	O
viewpoints	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
.	O
7	O
.	O
(	O
optional	O
)	O
construct	O
an	O
unwrap	O
mosaic	O
from	O
a	O
more	O
complex	O
scene	O
and	O
use	O
this	O
to	O
do	O
some	O
video	B
editing	O
(	O
rav-acha	O
,	O
kohli	O
,	O
fitzgibbon	O
et	O
al	O
.	O
2008	O
)	O
.	O
ex	O
8.10	O
:	O
transparent	B
motion	O
and	O
reﬂection	O
estimation	B
take	O
a	O
video	B
sequence	O
looking	O
through	O
a	O
window	O
(	O
or	O
picture	O
frame	O
)	O
and	O
see	O
if	O
you	O
can	O
remove	O
the	O
reﬂection	O
in	O
order	B
to	O
better	O
see	O
what	O
is	O
inside	O
.	O
the	O
steps	O
are	O
described	O
in	O
section	O
8.5.2	O
and	O
by	O
szeliski	O
,	O
avidan	O
,	O
and	O
anandan	O
(	O
2000	O
)	O
.	O
alternative	O
approaches	O
can	O
be	O
found	O
in	O
work	O
by	O
shizawa	O
and	O
mase	O
(	O
1991	O
)	O
,	O
bergen	O
,	O
burt	O
,	O
hingorani	O
et	O
al	O
.	O
(	O
1992	O
)	O
,	O
darrell	O
and	O
simoncelli	O
(	O
1993	O
)	O
,	O
darrell	O
and	O
pentland	O
(	O
1995	O
)	O
,	O
irani	O
,	O
rousso	O
,	O
and	O
peleg	O
(	O
1994	O
)	O
,	O
black	O
and	O
anandan	O
(	O
1996	O
)	O
,	O
and	O
ju	O
,	O
black	O
,	O
and	O
jepson	O
(	O
1996	O
)	O
.	O
chapter	O
9	O
image	B
stitching	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9.1	O
motion	B
models	I
9.2	O
global	B
alignment	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
planar	B
perspective	I
motion	I
.	O
.	O
.	O
.	O
9.1.1	O
.	O
9.1.2	O
application	O
:	O
whiteboard	B
and	I
document	I
scanning	I
.	O
.	O
.	O
.	O
9.1.3	O
rotational	O
panoramas	O
.	O
9.1.4	O
gap	B
closing	I
.	O
.	O
.	O
.	O
9.1.5	O
application	O
:	O
video	B
summarization	I
and	O
compression	B
.	O
.	O
9.1.6	O
cylindrical	B
and	O
spherical	B
coordinates	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9.2.1	O
bundle	B
adjustment	I
.	O
.	O
.	O
9.2.2	O
.	O
.	O
.	O
9.2.3	O
recognizing	B
panoramas	I
.	O
.	O
9.2.4	O
direct	B
vs.	I
feature-based	I
alignment	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
pixel	B
selection	I
and	O
weighting	B
(	O
de-ghosting	B
)	O
.	O
.	O
.	O
.	O
.	O
parallax	B
removal	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9.3	O
compositing	B
.	O
.	O
9.3.1	O
choosing	O
a	O
compositing	B
surface	O
.	O
9.3.2	O
9.3.3	O
application	O
:	O
photomontage	O
9.3.4	O
blending	B
.	O
.	O
.	O
.	O
.	O
9.4	O
additional	O
reading	O
.	O
9.5	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
430	O
.	O
431	O
.	O
432	O
.	O
433	O
.	O
435	O
.	O
436	O
.	O
438	O
.	O
441	O
.	O
441	O
.	O
445	O
.	O
446	O
.	O
450	O
.	O
450	O
.	O
451	O
.	O
453	O
.	O
459	O
.	O
459	O
.	O
462	O
.	O
463	O
428	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
9.1	O
image	B
stitching	I
:	O
(	O
a	O
)	O
portion	O
of	O
a	O
cylindrical	B
panorama	O
and	O
(	O
b	O
)	O
a	O
spherical	B
panorama	O
constructed	O
from	O
54	O
photographs	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
;	O
(	O
c	O
)	O
a	O
multi-image	O
panorama	O
automatically	O
assembled	O
from	O
an	O
unordered	O
photo	O
collection	O
;	O
a	O
multi-	O
image	B
stitch	O
(	O
d	O
)	O
without	O
and	O
(	O
e	O
)	O
with	O
moving	O
object	O
removal	O
(	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
.	O
9	O
image	B
stitching	I
429	O
algorithms	O
for	O
aligning	O
images	O
and	O
stitching	O
them	O
into	O
seamless	O
photo-mosaics	O
are	O
among	O
the	O
oldest	O
and	O
most	O
widely	O
used	O
in	O
computer	O
vision	O
(	O
milgram	O
1975	O
;	O
peleg	O
1981	O
)	O
.	O
image	B
stitching	I
algorithms	O
create	O
the	O
high-resolution	O
photo-mosaics	O
used	O
to	O
produce	O
today	O
’	O
s	O
digital	O
maps	O
and	O
satellite	O
photos	O
.	O
they	O
also	O
come	O
bundled	O
with	O
most	O
digital	O
cameras	O
and	O
can	O
be	O
used	O
to	O
create	O
beautiful	O
ultra	O
wide-angle	O
panoramas	O
.	O
image	B
stitching	I
originated	O
in	O
the	O
photogrammetry	B
community	O
,	O
where	O
more	O
manually	O
in-	O
tensive	O
methods	O
based	O
on	O
surveyed	O
ground	O
control	O
points	B
or	O
manually	O
registered	O
tie	O
points	B
have	O
long	O
been	O
used	O
to	O
register	O
aerial	O
photos	O
into	O
large-scale	O
photo-mosaics	O
(	O
slama	O
1980	O
)	O
.	O
one	O
of	O
the	O
key	O
advances	O
in	O
this	O
community	O
was	O
the	O
development	O
of	O
bundle	B
adjustment	I
al-	O
gorithms	O
(	O
section	O
7.4	O
)	O
,	O
which	O
could	O
simultaneously	O
solve	O
for	O
the	O
locations	O
of	O
all	O
of	O
the	O
cam-	O
era	O
positions	O
,	O
thus	O
yielding	O
globally	O
consistent	O
solutions	O
(	O
triggs	O
,	O
mclauchlan	O
,	O
hartley	O
et	O
al	O
.	O
1999	O
)	O
.	O
another	O
recurring	O
problem	O
in	O
creating	O
photo-mosaics	O
is	O
the	O
elimination	O
of	O
visible	O
seams	O
,	O
for	O
which	O
a	O
variety	O
of	O
techniques	O
have	O
been	O
developed	O
over	O
the	O
years	O
(	O
milgram	O
1975	O
,	O
1977	O
;	O
peleg	O
1981	O
;	O
davis	O
1998	O
;	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
in	O
ﬁlm	O
photography	O
,	O
special	O
cameras	O
were	O
developed	O
in	O
the	O
1990s	O
to	O
take	O
ultra-wide-	O
angle	O
panoramas	O
,	O
often	O
by	O
exposing	O
the	O
ﬁlm	O
through	O
a	O
vertical	O
slit	O
as	O
the	O
camera	B
rotated	O
on	O
its	O
axis	O
(	O
meehan	O
1990	O
)	O
.	O
in	O
the	O
mid-1990s	O
,	O
image	B
alignment	O
techniques	O
started	O
being	O
applied	O
to	O
the	O
construction	O
of	O
wide-angle	O
seamless	O
panoramas	O
from	O
regular	O
hand-held	O
cameras	O
(	O
mann	O
and	O
picard	O
1994	O
;	O
chen	O
1995	O
;	O
szeliski	O
1996	O
)	O
.	O
more	O
recent	O
work	O
in	O
this	O
area	O
has	O
addressed	O
the	O
need	O
to	O
compute	O
globally	O
consistent	O
alignments	O
(	O
szeliski	O
and	O
shum	O
1997	O
;	O
sawhney	O
and	O
kumar	O
1999	O
;	O
shum	O
and	O
szeliski	O
2000	O
)	O
,	O
to	O
remove	O
“	O
ghosts	O
”	O
due	O
to	O
parallax	O
and	O
object	O
move-	O
ment	O
(	O
davis	O
1998	O
;	O
shum	O
and	O
szeliski	O
2000	O
;	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
2001	O
;	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
,	O
and	O
to	O
deal	O
with	O
varying	O
exposures	O
(	O
mann	O
and	O
picard	O
1994	O
;	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
2001	O
;	O
levin	O
,	O
zomet	O
,	O
peleg	O
et	O
al	O
.	O
2004	O
;	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
;	O
eden	O
,	O
uyttendaele	O
,	O
and	O
szeliski	O
2006	O
;	O
kopf	O
,	O
uyttendaele	O
,	O
deussen	O
et	O
al	O
.	O
2007	O
)	O
.1	O
these	O
techniques	O
have	O
spawned	O
a	O
large	O
number	O
of	O
commercial	O
stitching	O
products	O
(	O
chen	O
1995	O
;	O
sawhney	O
,	O
kumar	O
,	O
gendel	O
et	O
al	O
.	O
1998	O
)	O
,	O
of	O
which	O
reviews	O
and	O
comparisons	O
can	O
be	O
found	O
on	O
the	O
web.2	O
while	O
most	O
of	O
the	O
earlier	O
techniques	O
worked	O
by	O
directly	O
minimizing	O
pixel-to-pixel	O
dis-	O
similarities	O
,	O
more	O
recent	O
algorithms	O
usually	O
extract	O
a	O
sparse	B
set	O
of	O
features	O
and	O
match	O
them	O
to	O
each	O
other	O
,	O
as	O
described	O
in	O
chapter	O
4.	O
such	O
feature-based	B
approaches	O
to	O
image	B
stitching	I
have	O
the	O
advantage	O
of	O
being	O
more	O
robust	B
against	O
scene	O
movement	O
and	O
are	O
potentially	O
faster	O
,	O
if	O
implemented	O
the	O
right	O
way	O
.	O
their	O
biggest	O
advantage	O
,	O
however	O
,	O
is	O
the	O
ability	O
to	O
“	O
recognize	O
panoramas	O
”	O
,	O
i.e.	O
,	O
to	O
automatically	O
discover	O
the	O
adjacency	O
(	O
overlap	O
)	O
relationships	O
among	O
an	O
unordered	O
set	O
of	O
images	O
,	O
which	O
makes	O
them	O
ideally	O
suited	O
for	O
fully	O
automated	B
stitching	O
of	O
1	O
a	O
collection	O
of	O
some	O
of	O
these	O
papers	O
was	O
compiled	O
by	O
benosman	O
and	O
kang	O
(	O
2001	O
)	O
and	O
they	O
are	O
surveyed	O
by	O
szeliski	O
(	O
2006a	O
)	O
.	O
2	O
the	O
photosynth	O
web	O
site	O
,	O
http	O
:	O
//photosynth.net	O
,	O
allows	O
people	O
to	O
create	O
and	O
upload	O
panoramas	O
for	O
free	O
.	O
430	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
panoramas	O
taken	O
by	O
casual	O
users	O
(	O
brown	O
and	O
lowe	O
2007	O
)	O
.	O
what	O
,	O
then	O
,	O
are	O
the	O
essential	O
problems	O
in	O
image	B
stitching	I
?	O
as	O
with	O
image	O
alignment	B
,	O
we	O
must	O
ﬁrst	O
determine	O
the	O
appropriate	O
mathematical	O
model	O
relating	O
pixel	O
coordinates	O
in	O
one	O
im-	O
age	O
to	O
pixel	O
coordinates	O
in	O
another	O
;	O
section	O
9.1	O
reviews	O
the	O
basic	O
models	O
we	O
have	O
studied	O
and	O
presents	O
some	O
new	O
motion	B
models	I
related	O
speciﬁcally	O
to	O
panoramic	O
image	B
stitching	I
.	O
next	O
,	O
we	O
must	O
somehow	O
estimate	O
the	O
correct	O
alignments	O
relating	O
various	O
pairs	B
(	O
or	O
collections	O
)	O
of	O
images	O
.	O
chapter	O
4	O
discussed	O
how	O
distinctive	O
features	O
can	O
be	O
found	O
in	O
each	O
image	B
and	O
then	O
efﬁciently	O
matched	O
to	O
rapidly	O
establish	O
correspondences	O
between	O
pairs	B
of	O
images	O
.	O
chapter	O
8	O
discussed	O
how	O
direct	B
pixel-to-pixel	O
comparisons	O
combined	O
with	O
gradient	O
descent	O
(	O
and	O
other	O
optimization	O
techniques	O
)	O
can	O
also	O
be	O
used	O
to	O
estimate	O
these	O
parameters	B
.	O
when	O
multiple	B
im-	O
ages	O
exist	O
in	O
a	O
panorama	O
,	O
bundle	B
adjustment	I
(	O
section	O
7.4	O
)	O
can	O
be	O
used	O
to	O
compute	O
a	O
globally	O
consistent	O
set	O
of	O
alignments	O
and	O
to	O
efﬁciently	O
discover	O
which	O
images	O
overlap	O
one	O
another	O
.	O
in	O
section	O
9.2	O
,	O
we	O
look	O
at	O
how	O
each	O
of	O
these	O
previously	O
developed	O
techniques	O
can	O
be	O
modiﬁed	O
to	O
take	O
advantage	O
of	O
the	O
imaging	O
setups	O
commonly	O
used	O
to	O
create	O
panoramas	O
.	O
once	O
we	O
have	O
aligned	O
the	O
images	O
,	O
we	O
must	O
choose	O
a	O
ﬁnal	O
compositing	B
surface	O
for	O
warping	O
the	O
aligned	O
images	O
(	O
section	O
9.3.1	O
)	O
.	O
we	O
also	O
need	O
algorithms	O
to	O
seamlessly	O
cut	O
and	O
blend	O
over-	O
lapping	O
images	O
,	O
even	O
in	O
the	O
presence	O
of	O
parallax	O
,	O
lens	O
distortion	O
,	O
scene	O
motion	O
,	O
and	O
exposure	O
differences	O
(	O
section	O
9.3.2–9.3.4	O
)	O
.	O
9.1	O
motion	B
models	I
before	O
we	O
can	O
register	O
and	O
align	O
images	O
,	O
we	O
need	O
to	O
establish	O
the	O
mathematical	O
relationships	O
that	O
map	O
pixel	O
coordinates	O
from	O
one	O
image	B
to	O
another	O
.	O
a	O
variety	O
of	O
such	O
parametric	B
motion	O
models	O
are	O
possible	O
,	O
from	O
simple	O
2d	O
transforms	O
,	O
to	O
planar	O
perspective	O
models	O
,	O
3d	O
camera	B
rotations	O
,	O
lens	O
distortions	O
,	O
and	O
mapping	O
to	O
non-planar	O
(	O
e.g.	O
,	O
cylindrical	B
)	O
surfaces	O
.	O
we	O
already	O
covered	O
several	O
of	O
these	O
models	O
in	O
sections	O
2.1	O
and	O
6.1.	O
in	O
particular	O
,	O
we	O
saw	O
in	O
section	O
2.1.5	O
how	O
the	O
parametric	B
motion	O
describing	O
the	O
deformation	O
of	O
a	O
planar	O
surfaced	O
as	O
viewed	O
from	O
different	O
positions	O
can	O
be	O
described	O
with	O
an	O
eight-parameter	O
homography	B
(	O
2.71	O
)	O
(	O
mann	O
and	O
picard	O
1994	O
;	O
szeliski	O
1996	O
)	O
.	O
we	O
also	O
saw	O
how	O
a	O
camera	B
undergoing	O
a	O
pure	B
rotation	I
induces	O
a	O
different	O
kind	O
of	O
homography	B
(	O
2.72	O
)	O
.	O
in	O
this	O
section	O
,	O
we	O
review	O
both	O
of	O
these	O
models	O
and	O
show	O
how	O
they	O
can	O
be	O
applied	O
to	O
dif-	O
ferent	O
stitching	O
situations	O
.	O
we	O
also	O
introduce	O
spherical	B
and	O
cylindrical	B
compositing	O
surfaces	O
and	O
show	O
how	O
,	O
under	O
favorable	O
circumstances	O
,	O
they	O
can	O
be	O
used	O
to	O
perform	O
alignment	B
using	O
pure	O
translations	O
(	O
section	O
9.1.6	O
)	O
.	O
deciding	O
which	O
alignment	B
model	O
is	O
most	O
appropriate	O
for	O
a	O
given	O
situation	O
or	O
set	O
of	O
data	O
is	O
a	O
model	O
selection	O
problem	O
(	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
torr	O
2002	O
;	O
bishop	O
2006	O
;	O
robert	O
2007	O
)	O
,	O
an	O
important	O
topic	O
we	O
do	O
not	O
cover	O
in	O
this	O
book	O
.	O
9.1	O
motion	B
models	I
431	O
(	O
a	O
)	O
translation	B
[	O
2	O
dof	O
]	O
(	O
b	O
)	O
afﬁne	B
[	O
6	O
dof	O
]	O
(	O
c	O
)	O
perspective	B
[	O
8	O
dof	O
]	O
(	O
d	O
)	O
3d	O
rotation	O
[	O
3+	O
dof	O
]	O
figure	O
9.2	O
two-dimensional	B
motion	O
models	O
and	O
how	O
they	O
can	O
be	O
used	O
for	O
image	O
stitching	O
.	O
9.1.1	O
planar	B
perspective	I
motion	I
the	O
simplest	O
possible	O
motion	B
model	O
to	O
use	O
when	O
aligning	O
images	O
is	O
to	O
simply	O
translate	O
and	O
rotate	O
them	O
in	O
2d	O
(	O
figure	O
9.2a	O
)	O
.	O
this	O
is	O
exactly	O
the	O
same	O
kind	O
of	O
motion	B
that	O
you	O
would	O
use	O
if	O
you	O
had	O
overlapping	O
photographic	O
prints	O
.	O
it	O
is	O
also	O
the	O
kind	O
of	O
technique	O
favored	O
by	O
david	O
hockney	O
to	O
create	O
the	O
collages	O
that	O
he	O
calls	O
joiners	O
(	O
zelnik-manor	O
and	O
perona	O
2007	O
;	O
nomura	O
,	O
zhang	O
,	O
and	O
nayar	O
2007	O
)	O
.	O
creating	O
such	O
collages	O
,	O
which	O
show	O
visible	O
seams	O
and	O
inconsistencies	O
that	O
add	O
to	O
the	O
artistic	O
effect	O
,	O
is	O
popular	O
on	O
web	O
sites	O
such	O
as	O
flickr	O
,	O
where	O
they	O
more	O
commonly	O
go	O
under	O
the	O
name	O
panography	B
(	O
section	O
6.1.2	O
)	O
.	O
translation	B
and	O
rotation	O
are	O
also	O
usually	O
adequate	O
motion	B
models	I
to	O
compensate	O
for	O
small	O
camera	B
motions	O
in	O
applications	O
such	O
as	O
photo	O
and	O
video	B
stabilization	I
and	O
merging	B
(	O
exercise	O
6.1	O
and	O
section	O
8.2.1	O
)	O
.	O
in	O
section	O
6.1.3	O
,	O
we	O
saw	O
how	O
the	O
mapping	O
between	O
two	O
cameras	O
viewing	O
a	O
common	O
plane	O
can	O
be	O
described	O
using	O
a	O
3×3	O
homography	B
(	O
2.71	O
)	O
.	O
consider	O
the	O
matrix	O
m	O
10	O
that	O
arises	O
when	O
mapping	O
a	O
pixel	O
in	O
one	O
image	B
to	O
a	O
3d	O
point	O
and	O
then	O
back	O
onto	O
a	O
second	O
image	O
,	O
˜x1	O
∼	O
˜p	O
1	O
˜p	O
−1	O
0	O
˜x0	O
=	O
m	O
10	O
˜x0	O
.	O
(	O
9.1	O
)	O
when	O
the	O
last	O
row	O
of	O
the	O
p	O
0	O
matrix	O
is	O
replaced	O
with	O
a	O
plane	O
equation	O
ˆn0·p+c0	O
and	O
points	B
are	O
assumed	O
to	O
lie	O
on	O
this	O
plane	O
,	O
i.e.	O
,	O
their	O
disparity	O
is	O
d0	O
=	O
0	O
,	O
we	O
can	O
ignore	O
the	O
last	O
column	O
of	O
m	O
10	O
and	O
also	O
its	O
last	O
row	O
,	O
since	O
we	O
do	O
not	O
care	O
about	O
the	O
ﬁnal	O
z-buffer	O
depth	O
.	O
the	O
resulting	O
homography	B
matrix	O
˜h	O
10	O
(	O
the	O
upper	O
left	O
3	O
×	O
3	O
sub-matrix	O
of	O
m	O
10	O
)	O
describes	O
the	O
mapping	O
between	O
pixels	O
in	O
the	O
two	O
images	O
,	O
˜x1	O
∼	O
˜h	O
10	O
˜x0	O
.	O
(	O
9.2	O
)	O
this	O
observation	O
formed	O
the	O
basis	O
of	O
some	O
of	O
the	O
earliest	O
automated	B
image	O
stitching	O
al-	O
gorithms	O
(	O
mann	O
and	O
picard	O
1994	O
;	O
szeliski	O
1994	O
,	O
1996	O
)	O
.	O
because	O
reliable	O
feature	B
matching	O
techniques	O
had	O
not	O
yet	O
been	O
developed	O
,	O
these	O
algorithms	O
used	O
direct	B
pixel	O
value	O
matching	B
,	O
i.e.	O
,	O
direct	B
parametric	O
motion	B
estimation	I
,	O
as	O
described	O
in	O
section	O
8.2	O
and	O
equations	B
(	O
6.19–6.20	O
)	O
.	O
432	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
more	O
recent	O
stitching	O
algorithms	O
ﬁrst	O
extract	O
features	O
and	O
then	O
match	O
them	O
up	O
,	O
often	O
using	O
robust	O
techniques	O
such	O
as	O
ransac	O
(	O
section	O
6.1.4	O
)	O
to	O
compute	O
a	O
good	O
set	O
of	O
inliers	B
.	O
the	O
ﬁnal	O
computation	O
of	O
the	O
homography	B
(	O
9.2	O
)	O
,	O
i.e.	O
,	O
the	O
solution	O
of	O
the	O
least	B
squares	I
ﬁtting	O
problem	O
given	O
pairs	B
of	O
corresponding	O
features	O
,	O
x1	O
=	O
(	O
1	O
+	O
h00	O
)	O
x0	O
+	O
h01y0	O
+	O
h02	O
h20x0	O
+	O
h21y0	O
+	O
1	O
and	O
y1	O
=	O
h10x0	O
+	O
(	O
1	O
+	O
h11	O
)	O
y0	O
+	O
h12	O
h20x0	O
+	O
h21y0	O
+	O
1	O
,	O
(	O
9.3	O
)	O
uses	O
iterative	B
least	O
squares	O
,	O
as	O
described	O
in	O
section	O
6.1.3	O
and	O
equations	B
(	O
6.21–6.23	O
)	O
.	O
9.1.2	O
application	O
:	O
whiteboard	B
and	I
document	I
scanning	I
the	O
simplest	O
image-stitching	O
application	O
is	O
to	O
stitch	O
together	O
a	O
number	O
of	O
image	B
scans	O
taken	O
on	O
a	O
ﬂatbed	O
scanner	O
.	O
say	O
you	O
have	O
a	O
large	O
map	O
,	O
or	O
a	O
piece	O
of	O
child	O
’	O
s	O
artwork	O
,	O
that	O
is	O
too	O
large	O
to	O
ﬁt	O
on	O
your	O
scanner	O
.	O
simply	O
take	O
multiple	B
scans	O
of	O
the	O
document	O
,	O
making	O
sure	O
to	O
overlap	O
the	O
scans	O
by	O
a	O
large	O
enough	O
amount	O
to	O
ensure	O
that	O
there	O
are	O
enough	O
common	O
features	O
.	O
next	O
,	O
take	O
successive	O
pairs	O
of	O
images	O
that	O
you	O
know	O
overlap	O
,	O
extract	O
features	O
,	O
match	O
them	O
up	O
,	O
and	O
estimate	O
the	O
2d	O
rigid	O
transform	O
(	O
2.16	O
)	O
,	O
xk+1	O
=	O
rkxk	O
+	O
tk	O
,	O
(	O
9.4	O
)	O
that	O
best	O
matches	O
the	O
features	O
,	O
using	O
two-point	O
ransac	O
,	O
if	O
necessary	O
,	O
to	O
ﬁnd	O
a	O
good	O
set	O
of	O
inliers	B
.	O
then	O
,	O
on	O
a	O
ﬁnal	O
compositing	B
surface	O
(	O
aligned	O
with	O
the	O
ﬁrst	O
scan	O
,	O
for	O
example	O
)	O
,	O
resample	O
your	O
images	O
(	O
section	O
3.6.1	O
)	O
and	O
average	O
them	O
together	O
.	O
can	O
you	O
see	O
any	O
potential	O
problems	O
with	O
this	O
scheme	O
?	O
one	O
complication	O
is	O
that	O
a	O
2d	O
rigid	O
transformation	O
is	O
non-linear	B
in	O
the	O
rotation	O
angle	O
θ	O
,	O
so	O
you	O
will	O
have	O
to	O
either	O
use	O
non-linear	B
least	O
squares	O
or	O
constrain	O
r	O
to	O
be	O
orthonormal	O
,	O
as	O
described	O
in	O
section	O
6.1.3.	O
a	O
bigger	O
problem	O
lies	O
in	O
the	O
pairwise	O
alignment	B
process	O
.	O
as	O
you	O
align	O
more	O
and	O
more	O
pairs	B
,	O
the	O
solution	O
may	O
drift	O
so	O
that	O
it	O
is	O
no	O
longer	O
globally	O
consistent	O
.	O
in	O
this	O
case	O
,	O
a	O
global	B
op-	O
timization	O
procedure	O
,	O
as	O
described	O
in	O
section	O
9.2	O
,	O
may	O
be	O
required	O
.	O
such	O
global	B
optimization	I
often	O
requires	O
a	O
large	O
system	O
of	O
non-linear	B
equations	O
to	O
be	O
solved	O
,	O
although	O
in	O
some	O
cases	O
,	O
such	O
as	O
linearized	O
homographies	O
(	O
section	O
9.1.3	O
)	O
or	O
similarity	B
transforms	O
(	O
section	O
6.1.2	O
)	O
,	O
reg-	O
ular	O
least	B
squares	I
may	O
be	O
an	O
option	O
.	O
a	O
slightly	O
more	O
complex	O
scenario	O
is	O
when	O
you	O
take	O
multiple	B
overlapping	O
handheld	O
pic-	O
tures	O
of	O
a	O
whiteboard	O
or	O
other	O
large	O
planar	O
object	O
(	O
he	O
and	O
zhang	O
2005	O
;	O
zhang	O
and	O
he	O
2007	O
)	O
.	O
here	O
,	O
the	O
natural	B
motion	O
model	O
to	O
use	O
is	O
a	O
homography	B
,	O
although	O
a	O
more	O
complex	O
model	O
that	O
estimates	O
the	O
3d	O
rigid	O
motion	O
relative	O
to	O
the	O
plane	O
(	O
plus	O
the	O
focal	O
length	O
,	O
if	O
unknown	O
)	O
,	O
could	O
in	O
principle	O
be	O
used	O
.	O
9.1	O
motion	B
models	I
433	O
figure	O
9.3	O
pure	O
3d	O
camera	B
rotation	O
.	O
the	O
form	O
of	O
the	O
homography	B
(	O
mapping	O
)	O
is	O
particularly	O
simple	O
and	O
depends	O
only	O
on	O
the	O
3d	O
rotation	O
matrix	O
and	O
focal	O
lengths	O
.	O
9.1.3	O
rotational	O
panoramas	O
the	O
most	O
typical	O
case	O
for	O
panoramic	O
image	B
stitching	I
is	O
when	O
the	O
camera	B
undergoes	O
a	O
pure	O
ro-	O
tation	O
.	O
think	O
of	O
standing	O
at	O
the	O
rim	O
of	O
the	O
grand	O
canyon	O
.	O
relative	O
to	O
the	O
distant	O
geometry	O
in	O
the	O
scene	O
,	O
as	O
you	O
snap	O
away	O
,	O
the	O
camera	B
is	O
undergoing	O
a	O
pure	B
rotation	I
,	O
which	O
is	O
equivalent	O
to	O
assuming	O
that	O
all	O
points	B
are	O
very	O
far	O
from	O
the	O
camera	B
,	O
i.e.	O
,	O
on	O
the	O
plane	O
at	O
inﬁnity	O
(	O
figure	O
9.3	O
)	O
.	O
setting	O
t0	O
=	O
t1	O
=	O
0	O
,	O
we	O
get	O
the	O
simpliﬁed	O
3	O
×	O
3	O
homography	B
˜h	O
10	O
=	O
k1r1r−1	O
0	O
k−1	O
0	O
=	O
k1r10k−1	O
0	O
,	O
where	O
kk	O
=	O
diag	O
(	O
fk	O
,	O
fk	O
,	O
1	O
)	O
is	O
the	O
simpliﬁed	O
camera	B
intrinsic	O
matrix	O
(	O
2.59	O
)	O
,	O
assuming	O
that	O
cx	O
=	O
cy	O
=	O
0	O
,	O
i.e.	O
,	O
we	O
are	O
indexing	O
the	O
pixels	O
starting	O
from	O
the	O
optical	O
center	O
(	O
szeliski	O
1996	O
)	O
.	O
this	O
can	O
also	O
be	O
re-written	O
as	O
x1	O
y1	O
1	O
	O
	O
∼	O
f1	O
f1	O
f−1	O
0	O
f−1	O
0	O
1	O
	O
	O
x0	O
y0	O
1	O
	O
1	O
	O
r10	O
	O
∼	O
r10	O
	O
x1	O
y1	O
f1	O
x0	O
y0	O
f0	O
	O
,	O
(	O
9.5	O
)	O
(	O
9.6	O
)	O
(	O
9.7	O
)	O
or	O
which	O
reveals	O
the	O
simplicity	O
of	O
the	O
mapping	O
equations	B
and	O
makes	O
all	O
of	O
the	O
motion	B
parameters	O
explicit	O
.	O
thus	O
,	O
instead	O
of	O
the	O
general	O
eight-parameter	O
homography	B
relating	O
a	O
pair	O
of	O
images	O
,	O
we	O
get	O
the	O
three-	O
,	O
four-	O
,	O
or	O
ﬁve-parameter	O
3d	O
rotation	O
motion	O
models	O
corresponding	O
to	O
the	O
cases	O
where	O
the	O
focal	O
length	O
f	O
is	O
known	O
,	O
ﬁxed	O
,	O
or	O
variable	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
.3	O
es-	O
timating	O
the	O
3d	O
rotation	O
matrix	O
(	O
and	O
,	O
optionally	O
,	O
focal	O
length	O
)	O
associated	O
with	O
each	O
image	B
is	O
3	O
an	O
initial	O
estimate	O
of	O
the	O
focal	O
lengths	O
can	O
be	O
obtained	O
using	O
the	O
intrinsic	B
calibration	O
techniques	O
described	O
in	O
section	O
6.3.4	O
or	O
from	O
exif	O
tags	O
.	O
π∞	O
:	O
(	O
0,0,0,1	O
)	O
·p=	O
0r10x1=	O
(	O
x1	O
,	O
y1	O
,	O
f1	O
)	O
~x0=	O
(	O
x0	O
,	O
y0	O
,	O
f0	O
)	O
~	O
434	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
intrinsically	O
more	O
stable	O
than	O
estimating	O
a	O
homography	B
with	O
a	O
full	O
eight	O
degrees	O
of	O
freedom	O
,	O
which	O
makes	O
this	O
the	O
method	O
of	O
choice	O
for	O
large-scale	O
image	B
stitching	I
algorithms	O
(	O
szeliski	O
and	O
shum	O
1997	O
;	O
shum	O
and	O
szeliski	O
2000	O
;	O
brown	O
and	O
lowe	O
2007	O
)	O
.	O
given	O
this	O
representation	O
,	O
how	O
do	O
we	O
update	O
the	O
rotation	O
matrices	O
to	O
best	O
align	O
two	O
over-	O
lapping	O
images	O
?	O
given	O
a	O
current	O
estimate	O
for	O
the	O
homography	B
˜h	O
10	O
in	O
(	O
9.5	O
)	O
,	O
the	O
best	O
way	O
to	O
update	O
r10	O
is	O
to	O
prepend	O
an	O
incremental	B
rotation	O
matrix	O
r	O
(	O
ω	O
)	O
to	O
the	O
current	O
estimate	O
r10	O
(	O
szeliski	O
and	O
shum	O
1997	O
;	O
shum	O
and	O
szeliski	O
2000	O
)	O
,	O
˜h	O
(	O
ω	O
)	O
=	O
k1r	O
(	O
ω	O
)	O
r10k−1	O
0	O
=	O
[	O
k1r	O
(	O
ω	O
)	O
k−1	O
1	O
]	O
[	O
k1r10k−1	O
0	O
]	O
=	O
d	O
˜h	O
10	O
.	O
(	O
9.8	O
)	O
note	O
that	O
here	O
we	O
have	O
written	O
the	O
update	B
rule	I
in	O
the	O
compositional	B
form	O
,	O
where	O
the	O
in-	O
cremental	O
update	O
d	O
is	O
prepended	O
to	O
the	O
current	O
homography	B
˜h	O
10.	O
using	O
the	O
small-angle	O
approximation	O
to	O
r	O
(	O
ω	O
)	O
given	O
in	O
(	O
2.35	O
)	O
,	O
we	O
can	O
write	O
the	O
incremental	B
update	O
matrix	O
as	O
d	O
=	O
k1r	O
(	O
ω	O
)	O
k−1	O
1	O
≈	O
k1	O
(	O
i	O
+	O
[	O
ω	O
]	O
×	O
)	O
k−1	O
1	O
=	O
1	O
ωz	O
−ωz	O
1	O
−ωy/f1	O
ωx/f1	O
f1ωy	O
−f1ωx	O
1	O
	O
.	O
(	O
9.9	O
)	O
notice	O
how	O
there	O
is	O
now	O
a	O
nice	O
one-to-one	O
correspondence	B
between	O
the	O
entries	O
in	O
the	O
d	O
matrix	O
and	O
the	O
h00	O
,	O
.	O
.	O
.	O
,	O
h21	O
parameters	B
used	O
in	O
table	O
6.1	O
and	O
equation	B
(	O
6.19	O
)	O
,	O
i.e.	O
,	O
(	O
h00	O
,	O
h01	O
,	O
h02	O
,	O
h00	O
,	O
h11	O
,	O
h12	O
,	O
h20	O
,	O
h21	O
)	O
=	O
(	O
0	O
,	O
−ωz	O
,	O
f1ωy	O
,	O
ωz	O
,	O
0	O
,	O
−f1ωx	O
,	O
−ωy/f1	O
,	O
ωx/f1	O
)	O
.	O
(	O
9.10	O
)	O
we	O
can	O
therefore	O
apply	O
the	O
chain	O
rule	O
to	O
equations	B
(	O
6.24	O
and	O
9.10	O
)	O
to	O
obtain	O
(	O
cid:34	O
)	O
ˆx	O
(	O
cid:48	O
)	O
−	O
x	O
ˆy	O
(	O
cid:48	O
)	O
−	O
y	O
(	O
cid:35	O
)	O
=	O
(	O
cid:34	O
)	O
−xy/f1	O
−	O
(	O
f1	O
+	O
y2/f1	O
)	O
f1	O
+	O
x2/f1	O
−y	O
xy/f1	O
x	O
(	O
cid:35	O
)	O
	O
ωx	O
ωy	O
ωz	O
	O
,	O
(	O
9.11	O
)	O
which	O
give	O
us	O
the	O
linearized	O
update	O
equations	O
needed	O
to	O
estimate	O
ω	O
=	O
(	O
ωx	O
,	O
ωy	O
,	O
ωz	O
)	O
.4	O
notice	O
that	O
this	O
update	B
rule	I
depends	O
on	O
the	O
focal	O
length	O
f1	O
of	O
the	O
target	O
view	O
and	O
is	O
independent	O
of	O
the	O
focal	O
length	O
f0	O
of	O
the	O
template	O
view	O
.	O
this	O
is	O
because	O
the	O
compositional	B
algorithm	O
essentially	O
makes	O
small	O
perturbations	O
to	O
the	O
target	O
.	O
once	O
the	O
incremental	B
rotation	O
vector	O
ω	O
has	O
been	O
computed	O
,	O
the	O
r1	O
rotation	O
matrix	O
can	O
be	O
updated	O
using	O
r1	O
←	O
r	O
(	O
ω	O
)	O
r1	O
.	O
the	O
formulas	O
for	O
updating	O
the	O
focal	O
length	O
estimates	O
are	O
a	O
little	O
more	O
involved	O
and	O
are	O
given	O
in	O
(	O
shum	O
and	O
szeliski	O
2000	O
)	O
.	O
we	O
will	O
not	O
repeat	O
them	O
here	O
,	O
since	O
an	O
alternative	O
up-	O
date	O
rule	O
,	O
based	O
on	O
minimizing	O
the	O
difference	B
between	O
back-projected	O
3d	O
rays	O
,	O
is	O
given	O
in	O
section	O
9.2.1.	O
figure	O
9.4	O
shows	O
the	O
alignment	B
of	O
four	O
images	O
under	O
the	O
3d	O
rotation	O
motion	O
model	O
.	O
4	O
this	O
is	O
the	O
same	O
as	O
the	O
rotational	O
component	O
of	O
instantaneous	O
rigid	O
ﬂow	O
(	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
)	O
and	O
the	O
update	O
equations	O
given	O
by	O
szeliski	O
and	O
shum	O
(	O
1997	O
)	O
and	O
shum	O
and	O
szeliski	O
(	O
2000	O
)	O
.	O
9.1	O
motion	B
models	I
435	O
figure	O
9.4	O
four	O
images	O
taken	O
with	O
a	O
hand-held	O
camera	B
registered	O
using	O
a	O
3d	O
rotation	O
mo-	O
tion	B
model	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
.	O
notice	O
how	O
the	O
homographies	O
,	O
rather	O
than	O
being	O
arbitrary	O
,	O
have	O
a	O
well-deﬁned	O
keystone	O
shape	O
whose	O
width	O
increases	O
away	O
from	O
the	O
origin	O
.	O
9.1.4	O
gap	B
closing	I
the	O
techniques	O
presented	O
in	O
this	O
section	O
can	O
be	O
used	O
to	O
estimate	O
a	O
series	O
of	O
rotation	O
matrices	O
and	O
focal	O
lengths	O
,	O
which	O
can	O
be	O
chained	O
together	O
to	O
create	O
large	O
panoramas	O
.	O
unfortunately	O
,	O
because	O
of	O
accumulated	O
errors	O
,	O
this	O
approach	O
will	O
rarely	O
produce	O
a	O
closed	O
360◦	O
panorama	O
.	O
instead	O
,	O
there	O
will	O
invariably	O
be	O
either	O
a	O
gap	O
or	O
an	O
overlap	O
(	O
figure	O
9.5	O
)	O
.	O
we	O
can	O
solve	O
this	O
problem	O
by	O
matching	O
the	O
ﬁrst	O
image	B
in	O
the	O
sequence	O
with	O
the	O
last	O
one	O
.	O
the	O
difference	B
between	O
the	O
two	O
rotation	O
matrix	O
estimates	O
associated	O
with	O
the	O
repeated	O
ﬁrst	O
indicates	O
the	O
amount	O
of	O
misregistration	O
.	O
this	O
error	O
can	O
be	O
distributed	O
evenly	O
across	O
the	O
whole	O
sequence	O
by	O
taking	O
the	O
quotient	O
of	O
the	O
two	O
quaternions	O
associated	O
with	O
these	O
rotations	O
and	O
dividing	O
this	O
“	O
error	O
quaternion	O
”	O
by	O
the	O
number	O
of	O
images	O
in	O
the	O
sequence	O
(	O
assuming	O
relatively	O
constant	O
inter-frame	O
rotations	O
)	O
.	O
we	O
can	O
also	O
update	O
the	O
estimated	O
focal	O
length	O
based	O
on	O
the	O
amount	O
of	O
misregistration	O
.	O
to	O
do	O
this	O
,	O
we	O
ﬁrst	O
convert	O
the	O
error	O
quaternion	O
into	O
a	O
gap	O
angle	O
,	O
θg	O
and	O
then	O
update	O
the	O
focal	O
length	O
using	O
the	O
equation	B
f	O
(	O
cid:48	O
)	O
=	O
f	O
(	O
1	O
−	O
θg/360◦	O
)	O
.	O
figure	O
9.5a	O
shows	O
the	O
end	O
of	O
registered	O
image	B
sequence	O
and	O
the	O
ﬁrst	O
image	B
.	O
there	O
is	O
a	O
big	O
gap	O
between	O
the	O
last	O
image	B
and	O
the	O
ﬁrst	O
which	O
are	O
in	O
fact	O
the	O
same	O
image	B
.	O
the	O
gap	O
is	O
32◦	O
because	O
the	O
wrong	O
estimate	O
of	O
focal	O
length	O
(	O
f	O
=	O
510	O
)	O
was	O
used	O
.	O
figure	O
9.5b	O
shows	O
the	O
registration	B
after	O
closing	B
the	O
gap	O
with	O
the	O
correct	O
focal	O
length	O
(	O
f	O
=	O
468	O
)	O
.	O
notice	O
that	O
both	O
mosaics	O
show	O
very	O
little	O
visual	O
misregistration	O
(	O
except	O
at	O
the	O
gap	O
)	O
,	O
yet	O
figure	O
9.5a	O
has	O
been	O
computed	O
using	O
a	O
focal	O
length	O
that	O
has	O
9	O
%	O
error	O
.	O
related	O
approaches	O
have	O
been	O
developed	O
by	O
hartley	O
(	O
1994b	O
)	O
,	O
mcmillan	O
and	O
bishop	O
(	O
1995	O
)	O
,	O
stein	O
(	O
1995	O
)	O
,	O
and	O
kang	O
and	O
weiss	O
(	O
1997	O
)	O
to	O
solve	O
the	O
focal	O
length	O
estimation	B
problem	O
using	O
pure	O
panning	O
motion	B
and	O
cylindrical	B
images	O
.	O
436	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
9.5	O
gap	B
closing	I
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
:	O
(	O
a	O
)	O
a	O
gap	O
is	O
visible	O
when	O
the	O
focal	O
length	O
is	O
wrong	O
(	O
f	O
=	O
510	O
)	O
.	O
(	O
b	O
)	O
no	O
gap	O
is	O
visible	O
for	O
the	O
correct	O
focal	O
length	O
(	O
f	O
=	O
468	O
)	O
.	O
unfortunately	O
,	O
this	O
particular	O
gap-closing	O
heuristic	O
only	O
works	O
for	O
the	O
kind	O
of	O
“	O
one-dimensional	O
”	O
panorama	O
where	O
the	O
camera	B
is	O
continuously	O
turning	O
in	O
the	O
same	O
direction	O
.	O
in	O
section	O
9.2	O
,	O
we	O
describe	O
a	O
different	O
approach	O
to	O
removing	O
gaps	O
and	O
overlaps	O
that	O
works	O
for	O
arbitrary	O
camera	B
motions	O
.	O
9.1.5	O
application	O
:	O
video	B
summarization	I
and	O
compression	B
an	O
interesting	O
application	O
of	O
image	B
stitching	I
is	O
the	O
ability	O
to	O
summarize	O
and	O
compress	O
videos	O
taken	O
with	O
a	O
panning	O
camera	B
.	O
this	O
application	O
was	O
ﬁrst	O
suggested	O
by	O
teodosio	O
and	O
bender	O
(	O
1993	O
)	O
,	O
who	O
called	O
their	O
mosaic-based	O
summaries	O
salient	O
stills	O
.	O
these	O
ideas	O
were	O
then	O
ex-	O
tended	O
by	O
irani	O
,	O
hsu	O
,	O
and	O
anandan	O
(	O
1995	O
)	O
,	O
kumar	O
,	O
anandan	O
,	O
irani	O
et	O
al	O
.	O
(	O
1995	O
)	O
,	O
and	O
irani	O
and	O
anandan	O
(	O
1998	O
)	O
to	O
additional	O
applications	O
,	O
such	O
as	O
video	B
compression	I
and	O
video	B
indexing	O
.	O
while	O
these	O
early	O
approaches	O
used	O
afﬁne	B
motion	O
models	O
and	O
were	O
therefore	O
restricted	B
to	O
long	O
focal	O
lengths	O
,	O
the	O
techniques	O
were	O
generalized	B
by	O
lee	O
,	O
ge	O
chen	O
,	O
lung	O
bruce	O
lin	O
et	O
al	O
.	O
(	O
1997	O
)	O
to	O
full	O
eight-parameter	O
homographies	O
and	O
incorporated	O
into	O
the	O
mpeg-4	O
video	B
compression	I
standard	O
,	O
where	O
the	O
stitched	O
background	O
layers	O
were	O
called	O
video	B
sprites	O
(	O
figure	O
9.6	O
)	O
.	O
while	O
video	B
stitching	O
is	O
in	O
many	O
ways	O
a	O
straightforward	O
generalization	O
of	O
multiple-image	O
stitching	O
(	O
steedly	O
,	O
pal	O
,	O
and	O
szeliski	O
2005	O
;	O
baudisch	O
,	O
tan	O
,	O
steedly	O
et	O
al	O
.	O
2006	O
)	O
,	O
the	O
potential	O
presence	O
of	O
large	O
amounts	O
of	O
independent	O
motion	B
,	O
camera	B
zoom	O
,	O
and	O
the	O
desire	O
to	O
visualize	O
dynamic	B
events	O
impose	O
additional	O
challenges	O
.	O
for	O
example	O
,	O
moving	O
foreground	O
objects	O
can	O
often	O
be	O
removed	O
using	O
median	O
ﬁltering	O
.	O
alternatively	O
,	O
foreground	O
objects	O
can	O
be	O
extracted	O
into	O
a	O
separate	O
layer	O
(	O
sawhney	O
and	O
ayer	O
1996	O
)	O
and	O
later	O
composited	O
back	O
into	O
the	O
stitched	O
panoramas	O
,	O
sometimes	O
as	O
multiple	B
instances	O
to	O
give	O
the	O
impressions	O
of	O
a	O
“	O
chronophotograph	O
”	O
9.1	O
motion	B
models	I
+	O
+	O
+···	O
+	O
437	O
=	O
figure	O
9.6	O
video	B
stitching	O
the	O
background	O
scene	O
to	O
create	O
a	O
single	O
sprite	O
image	B
that	O
can	O
be	O
transmitted	O
and	O
used	O
to	O
re-create	O
the	O
background	O
in	O
each	O
frame	O
(	O
lee	O
,	O
ge	O
chen	O
,	O
lung	O
bruce	O
lin	O
et	O
al	O
.	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
ieee	O
.	O
(	O
massey	O
and	O
bender	O
1996	O
)	O
and	O
sometimes	O
as	O
video	B
overlays	O
(	O
irani	O
and	O
anandan	O
1998	O
)	O
.	O
videos	O
can	O
also	O
be	O
used	O
to	O
create	O
animated	O
panoramic	O
video	B
textures	I
(	O
section	O
13.5.2	O
)	O
,	O
in	O
which	O
different	O
portions	O
of	O
a	O
panoramic	O
scene	O
are	O
animated	O
with	O
independently	O
moving	O
video	O
loops	O
(	O
agarwala	O
,	O
zheng	O
,	O
pal	O
et	O
al	O
.	O
2005	O
;	O
rav-acha	O
,	O
pritch	O
,	O
lischinski	O
et	O
al	O
.	O
2005	O
)	O
,	O
or	O
to	O
shine	O
“	O
video	B
ﬂashlights	O
”	O
onto	O
a	O
composite	O
mosaic	O
of	O
a	O
scene	O
(	O
sawhney	O
,	O
arpa	O
,	O
kumar	O
et	O
al	O
.	O
2002	O
)	O
.	O
video	B
can	O
also	O
provide	O
an	O
interesting	O
source	O
of	O
content	O
for	O
creating	O
panoramas	O
taken	O
from	O
moving	O
cameras	O
.	O
while	O
this	O
invalidates	O
the	O
usual	O
assumption	O
of	O
a	O
single	O
point	O
of	O
view	O
(	O
opti-	O
cal	O
center	O
)	O
,	O
interesting	O
results	O
can	O
still	O
be	O
obtained	O
.	O
for	O
example	O
,	O
the	O
videobrush	O
system	O
of	O
sawhney	O
,	O
kumar	O
,	O
gendel	O
et	O
al	O
.	O
(	O
1998	O
)	O
uses	O
thin	B
strips	O
taken	O
from	O
the	O
center	O
of	O
the	O
image	B
to	O
create	O
a	O
panorama	O
taken	O
from	O
a	O
horizontally	O
moving	O
camera	O
.	O
this	O
idea	O
can	O
be	O
generalized	B
to	O
other	O
camera	B
motions	O
and	O
compositing	B
surfaces	O
using	O
the	O
concept	O
of	O
mosaics	O
on	O
adap-	O
tive	O
manifold	O
(	O
peleg	O
,	O
rousso	O
,	O
rav-acha	O
et	O
al	O
.	O
2000	O
)	O
,	O
and	O
also	O
used	O
to	O
generate	O
panoramic	O
stereograms	O
(	O
peleg	O
,	O
ben-ezra	O
,	O
and	O
pritch	O
2001	O
)	O
.	O
related	O
ideas	O
have	O
been	O
used	O
to	O
create	O
panoramic	O
matte	O
paintings	O
for	O
multi-plane	O
cel	O
animation	O
(	O
wood	O
,	O
finkelstein	O
,	O
hughes	O
et	O
al	O
.	O
1997	O
)	O
,	O
for	O
creating	O
stitched	O
images	O
of	O
scenes	O
with	O
parallax	O
(	O
kumar	O
,	O
anandan	O
,	O
irani	O
et	O
al	O
.	O
1995	O
)	O
,	O
and	O
as	O
3d	O
representations	O
of	O
more	O
complex	O
scenes	O
using	O
multiple-center-of-projection	O
images	O
(	O
rademacher	O
and	O
bishop	O
1998	O
)	O
and	O
multi-perspective	O
panoramas	O
(	O
rom´an	O
,	O
garg	O
,	O
and	O
levoy	O
2004	O
;	O
rom´an	O
and	O
lensch	O
2006	O
;	O
agarwala	O
,	O
agrawala	O
,	O
cohen	O
et	O
al	O
.	O
2006	O
)	O
.	O
another	O
interesting	O
variant	O
on	O
video-based	O
panoramas	O
are	O
concentric	O
mosaics	O
(	O
section	O
13.3.3	O
)	O
(	O
shum	O
and	O
he	O
1999	O
)	O
.	O
here	O
,	O
rather	O
than	O
trying	O
to	O
produce	O
a	O
single	O
panoramic	O
image	B
,	O
the	O
com-	O
plete	O
original	O
video	B
is	O
kept	O
and	O
used	O
to	O
re-synthesize	O
views	O
(	O
from	O
different	O
camera	B
origins	O
)	O
using	O
ray	O
remapping	O
(	O
light	B
ﬁeld	I
rendering	O
)	O
,	O
thus	O
endowing	O
the	O
panorama	O
with	O
a	O
sense	O
of	O
3d	O
438	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
9.7	O
projection	O
from	O
3d	O
to	O
(	O
a	O
)	O
cylindrical	B
and	O
(	O
b	O
)	O
spherical	B
coordinates	O
.	O
depth	O
.	O
the	O
same	O
data	O
set	O
can	O
also	O
be	O
used	O
to	O
explicitly	O
reconstruct	O
the	O
depth	O
using	O
multi-	O
baseline	O
stereo	B
(	O
peleg	O
,	O
ben-ezra	O
,	O
and	O
pritch	O
2001	O
;	O
li	O
,	O
shum	O
,	O
tang	O
et	O
al	O
.	O
2004	O
;	O
zheng	O
,	O
kang	O
,	O
cohen	O
et	O
al	O
.	O
2007	O
)	O
.	O
9.1.6	O
cylindrical	B
and	O
spherical	B
coordinates	O
an	O
alternative	O
to	O
using	O
homographies	O
or	O
3d	O
motions	O
to	O
align	O
images	O
is	O
to	O
ﬁrst	O
warp	O
the	O
images	O
into	O
cylindrical	B
coordinates	O
and	O
then	O
use	O
a	O
pure	O
translational	O
model	O
to	O
align	O
them	O
(	O
chen	O
1995	O
;	O
szeliski	O
1996	O
)	O
.	O
unfortunately	O
,	O
this	O
only	O
works	O
if	O
the	O
images	O
are	O
all	O
taken	O
with	O
a	O
level	O
camera	O
or	O
with	O
a	O
known	O
tilt	O
angle	O
.	O
assume	O
for	O
now	O
that	O
the	O
camera	B
is	O
in	O
its	O
canonical	O
position	O
,	O
i.e.	O
,	O
its	O
rotation	O
matrix	O
is	O
the	O
identity	O
,	O
r	O
=	O
i	O
,	O
so	O
that	O
the	O
optical	O
axis	O
is	O
aligned	O
with	O
the	O
z	O
axis	O
and	O
the	O
y	O
axis	O
is	O
aligned	O
vertically	O
.	O
the	O
3d	O
ray	O
corresponding	O
to	O
an	O
(	O
x	O
,	O
y	O
)	O
pixel	O
is	O
therefore	O
(	O
x	O
,	O
y	O
,	O
f	O
)	O
.	O
we	O
wish	O
to	O
project	O
this	O
image	B
onto	O
a	O
cylindrical	B
surface	O
of	O
unit	O
radius	O
(	O
szeliski	O
1996	O
)	O
.	O
points	B
on	O
this	O
surface	B
are	O
parameterized	O
by	O
an	O
angle	O
θ	O
and	O
a	O
height	O
h	O
,	O
with	O
the	O
3d	O
cylindrical	B
coordinates	O
corresponding	O
to	O
(	O
θ	O
,	O
h	O
)	O
given	O
by	O
(	O
sin	O
θ	O
,	O
h	O
,	O
cos	O
θ	O
)	O
∝	O
(	O
x	O
,	O
y	O
,	O
f	O
)	O
,	O
(	O
9.12	O
)	O
as	O
shown	O
in	O
figure	O
9.7a	O
.	O
from	O
this	O
correspondence	B
,	O
we	O
can	O
compute	O
the	O
formula	O
for	O
the	O
warped	O
or	O
mapped	O
coordinates	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
,	O
x	O
(	O
cid:48	O
)	O
=	O
sθ	O
=	O
s	O
tan−1	O
x	O
f	O
(	O
9.13	O
)	O
,	O
y	O
(	O
cid:48	O
)	O
=	O
sh	O
=	O
s	O
,	O
(	O
9.14	O
)	O
y	O
(	O
cid:112	O
)	O
x2	O
+	O
f	O
2	O
where	O
s	O
is	O
an	O
arbitrary	O
scaling	O
factor	O
(	O
sometimes	O
called	O
the	O
radius	O
of	O
the	O
cylinder	O
)	O
that	O
can	O
be	O
set	O
to	O
s	O
=	O
f	O
to	O
minimize	O
the	O
distortion	O
(	O
scaling	O
)	O
near	O
the	O
center	O
of	O
the	O
image.5	O
the	O
inverse	B
of	O
5	O
the	O
scale	O
can	O
also	O
be	O
set	O
to	O
a	O
larger	O
or	O
smaller	O
value	O
for	O
the	O
ﬁnal	O
compositing	B
surface	O
,	O
depending	O
on	O
the	O
desired	O
output	O
panorama	O
resolution—see	O
section	O
9.3.	O
p=	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
x=	O
(	O
sinθ	O
,	O
h	O
,	O
cosθ	O
)	O
θhxyp=	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
x=	O
(	O
sinθ	O
cosφ	O
,	O
sinφ	O
,	O
cosθcosφ	O
)	O
θφxy	O
9.1	O
motion	B
models	I
this	O
mapping	O
equation	B
is	O
given	O
by	O
439	O
(	O
9.15	O
)	O
(	O
9.16	O
)	O
y	O
(	O
cid:48	O
)	O
s	O
sec	O
x	O
(	O
cid:48	O
)	O
s	O
.	O
x	O
=	O
f	O
tan	O
θ	O
=	O
f	O
tan	O
x	O
(	O
cid:48	O
)	O
s	O
y	O
=	O
h	O
(	O
cid:112	O
)	O
x2	O
+	O
f	O
2	O
=	O
y	O
(	O
cid:48	O
)	O
s	O
,	O
f	O
(	O
cid:113	O
)	O
1	O
+	O
tan2	O
x	O
(	O
cid:48	O
)	O
/s	O
=	O
f	O
images	O
can	O
also	O
be	O
projected	O
onto	O
a	O
spherical	B
surface	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
,	O
which	O
is	O
useful	O
if	O
the	O
ﬁnal	O
panorama	O
includes	O
a	O
full	O
sphere	O
or	O
hemisphere	O
of	O
views	O
,	O
instead	O
of	O
just	O
a	O
cylindrical	B
strip	O
.	O
in	O
this	O
case	O
,	O
the	O
sphere	O
is	O
parameterized	O
by	O
two	O
angles	O
(	O
θ	O
,	O
φ	O
)	O
,	O
with	O
3d	O
spherical	B
coordinates	O
given	O
by	O
(	O
sin	O
θ	O
cos	O
φ	O
,	O
sin	O
φ	O
,	O
cos	O
θ	O
cos	O
φ	O
)	O
∝	O
(	O
x	O
,	O
y	O
,	O
f	O
)	O
,	O
(	O
9.17	O
)	O
as	O
shown	O
in	O
figure	O
9.7b.6	O
the	O
correspondence	B
between	O
coordinates	O
is	O
now	O
given	O
by	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
:	O
(	O
9.18	O
)	O
(	O
9.19	O
)	O
(	O
9.20	O
)	O
(	O
9.21	O
)	O
sec	O
x	O
(	O
cid:48	O
)	O
s	O
.	O
x	O
(	O
cid:48	O
)	O
=	O
sθ	O
=	O
s	O
tan−1	O
x	O
f	O
,	O
y	O
(	O
cid:48	O
)	O
=	O
sφ	O
=	O
s	O
tan−1	O
,	O
y	O
(	O
cid:112	O
)	O
x2	O
+	O
f	O
2	O
while	O
the	O
inverse	B
is	O
given	O
by	O
x	O
=	O
f	O
tan	O
θ	O
=	O
f	O
tan	O
x	O
(	O
cid:48	O
)	O
s	O
,	O
y	O
=	O
(	O
cid:112	O
)	O
x2	O
+	O
f	O
2	O
tan	O
φ	O
=	O
tan	O
y	O
(	O
cid:48	O
)	O
s	O
f	O
(	O
cid:113	O
)	O
1	O
+	O
tan2	O
x	O
(	O
cid:48	O
)	O
/s	O
=	O
f	O
tan	O
y	O
(	O
cid:48	O
)	O
s	O
note	O
that	O
it	O
may	O
be	O
simpler	O
to	O
generate	O
a	O
scaled	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
direction	O
from	O
equation	B
(	O
9.17	O
)	O
followed	O
by	O
a	O
perspective	B
division	O
by	O
z	O
and	O
a	O
scaling	O
by	O
f.	O
cylindrical	B
image	O
stitching	O
algorithms	O
are	O
most	O
commonly	O
used	O
when	O
the	O
camera	B
is	O
known	O
to	O
be	O
level	O
and	O
only	O
rotating	O
around	O
its	O
vertical	O
axis	O
(	O
chen	O
1995	O
)	O
.	O
under	O
these	O
condi-	O
tions	O
,	O
images	O
at	O
different	O
rotations	O
are	O
related	O
by	O
a	O
pure	O
horizontal	O
translation.7	O
this	O
makes	O
it	O
attractive	O
as	O
an	O
initial	O
class	O
project	O
in	O
an	O
introductory	O
computer	O
vision	O
course	O
,	O
since	O
the	O
full	O
complexity	O
of	O
the	O
perspective	B
alignment	O
algorithm	B
(	O
sections	O
6.1	O
,	O
8.2	O
,	O
and	O
9.1.3	O
)	O
can	O
be	O
avoided	O
.	O
figure	O
9.8	O
shows	O
how	O
two	O
cylindrically	O
warped	O
images	O
from	O
a	O
leveled	O
rotational	O
panorama	O
are	O
related	O
by	O
a	O
pure	B
translation	I
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
.	O
professional	O
panoramic	O
photographers	O
often	O
use	O
pan-tilt	O
heads	O
that	O
make	O
it	O
easy	O
to	O
control	O
the	O
tilt	O
and	O
to	O
stop	O
at	O
speciﬁc	O
detents	O
in	O
the	O
rotation	O
angle	O
.	O
motorized	O
rotation	O
heads	O
are	O
also	O
6	O
note	O
that	O
these	O
are	O
not	O
the	O
usual	O
spherical	B
coordinates	O
,	O
ﬁrst	O
presented	O
in	O
equation	B
(	O
2.8	O
)	O
.	O
here	O
,	O
the	O
y	O
axis	O
points	B
at	O
the	O
north	O
pole	O
instead	O
of	O
the	O
z	O
axis	O
,	O
since	O
we	O
are	O
used	O
to	O
viewing	O
images	O
taken	O
horizontally	O
,	O
i.e.	O
,	O
with	O
the	O
y	O
axis	O
pointing	O
in	O
the	O
direction	O
of	O
the	O
gravity	O
vector	O
.	O
7small	O
vertical	O
tilts	O
can	O
sometimes	O
be	O
compensated	O
for	O
with	O
vertical	O
translations	O
.	O
440	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
9.8	O
a	O
cylindrical	B
panorama	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
:	O
(	O
a	O
)	O
two	O
cylin-	O
drically	O
warped	O
images	O
related	O
by	O
a	O
horizontal	O
translation	B
;	O
(	O
b	O
)	O
part	O
of	O
a	O
cylindrical	B
panorama	O
composited	O
from	O
a	O
sequence	O
of	O
images	O
.	O
figure	O
9.9	O
a	O
spherical	B
panorama	O
constructed	O
from	O
54	O
photographs	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
.	O
sometimes	O
used	O
for	O
the	O
acquisition	O
of	O
larger	O
panoramas	O
(	O
kopf	O
,	O
uyttendaele	O
,	O
deussen	O
et	O
al	O
.	O
2007	O
)	O
.8	O
not	O
only	O
do	O
they	O
ensure	O
a	O
uniform	O
coverage	O
of	O
the	O
visual	O
ﬁeld	O
with	O
a	O
desired	O
amount	O
of	O
image	B
overlap	O
but	O
they	O
also	O
make	O
it	O
possible	O
to	O
stitch	O
the	O
images	O
using	O
cylindrical	O
or	O
spherical	B
coordinates	O
and	O
pure	O
translations	O
.	O
in	O
this	O
case	O
,	O
pixel	O
coordinates	O
(	O
x	O
,	O
y	O
,	O
f	O
)	O
must	O
ﬁrst	O
be	O
rotated	O
using	O
the	O
known	O
tilt	O
and	O
panning	O
angles	O
before	O
being	O
projected	O
into	O
cylindrical	B
or	O
spherical	B
coordinates	O
(	O
chen	O
1995	O
)	O
.	O
having	O
a	O
roughly	O
known	O
panning	O
angle	O
also	O
makes	O
it	O
easier	O
to	O
compute	O
the	O
alignment	B
,	O
since	O
the	O
rough	O
relative	O
positioning	O
of	O
all	O
the	O
input	O
images	O
is	O
known	O
ahead	O
of	O
time	O
,	O
enabling	O
a	O
reduced	O
search	O
range	O
for	O
alignment	B
.	O
figure	O
9.9	O
shows	O
a	O
full	O
3d	O
rotational	O
panorama	O
unwrapped	O
onto	O
the	O
surface	B
of	O
a	O
sphere	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
.	O
one	O
ﬁnal	O
coordinate	O
mapping	O
worth	O
mentioning	O
is	O
the	O
polar	O
mapping	O
,	O
where	O
the	O
north	O
8see	O
also	O
http	O
:	O
//gigapan.org	O
.	O
9.2	O
global	B
alignment	I
pole	O
lies	O
along	O
the	O
optical	O
axis	O
rather	O
than	O
the	O
vertical	O
axis	O
,	O
(	O
cos	O
θ	O
sin	O
φ	O
,	O
sin	O
θ	O
sin	O
φ	O
,	O
cos	O
φ	O
)	O
=	O
s	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
.	O
in	O
this	O
case	O
,	O
the	O
mapping	O
equations	B
become	O
x	O
(	O
cid:48	O
)	O
=	O
sφ	O
cos	O
θ	O
=	O
s	O
y	O
(	O
cid:48	O
)	O
=	O
sφ	O
sin	O
θ	O
=	O
s	O
x	O
r	O
y	O
r	O
tan−1	O
r	O
z	O
tan−1	O
r	O
z	O
,	O
,	O
441	O
(	O
9.22	O
)	O
(	O
9.23	O
)	O
(	O
9.24	O
)	O
where	O
r	O
=	O
(	O
cid:112	O
)	O
x2	O
+	O
y2	O
is	O
the	O
radial	B
distance	O
in	O
the	O
(	O
x	O
,	O
y	O
)	O
plane	O
and	O
sφ	O
plays	O
a	O
similar	O
role	O
in	O
the	O
(	O
x	O
(	O
cid:48	O
)	O
,	O
y	O
(	O
cid:48	O
)	O
)	O
plane	O
.	O
this	O
mapping	O
provides	O
an	O
attractive	O
visualization	O
surface	B
for	O
certain	O
kinds	O
of	O
wide-angle	O
panoramas	O
and	O
is	O
also	O
a	O
good	O
model	O
for	O
the	O
distortion	O
induced	O
by	O
ﬁsheye	O
lenses	O
,	O
as	O
discussed	O
in	O
section	O
2.1.6.	O
note	O
how	O
for	O
small	O
values	O
of	O
(	O
x	O
,	O
y	O
)	O
,	O
the	O
mapping	O
equations	B
reduce	O
to	O
x	O
(	O
cid:48	O
)	O
≈	O
sx/z	O
,	O
which	O
suggests	O
that	O
s	O
plays	O
a	O
role	O
similar	O
to	O
the	O
focal	O
length	O
f.	O
9.2	O
global	B
alignment	I
so	O
far	O
,	O
we	O
have	O
discussed	O
how	O
to	O
register	O
pairs	B
of	O
images	O
using	O
a	O
variety	O
of	O
motion	B
models	I
.	O
in	O
most	O
applications	O
,	O
we	O
are	O
given	O
more	O
than	O
a	O
single	O
pair	O
of	O
images	O
to	O
register	O
.	O
the	O
goal	O
is	O
then	O
to	O
ﬁnd	O
a	O
globally	O
consistent	O
set	O
of	O
alignment	B
parameters	O
that	O
minimize	O
the	O
mis-registration	O
between	O
all	O
pairs	B
of	O
images	O
(	O
szeliski	O
and	O
shum	O
1997	O
;	O
shum	O
and	O
szeliski	O
2000	O
;	O
sawhney	O
and	O
kumar	O
1999	O
;	O
coorg	O
and	O
teller	O
2000	O
)	O
.	O
in	O
this	O
section	O
,	O
we	O
extend	O
the	O
pairwise	O
matching	B
criteria	O
(	O
6.2	O
,	O
8.1	O
,	O
and	O
8.50	O
)	O
to	O
a	O
global	B
energy	O
function	O
that	O
involves	O
all	O
of	O
the	O
per-image	O
pose	O
parameters	B
(	O
section	O
9.2.1	O
)	O
.	O
once	O
we	O
have	O
computed	O
the	O
global	B
alignment	I
,	O
we	O
often	O
need	O
to	O
perform	O
local	B
adjustments	O
,	O
such	O
as	O
parallax	B
removal	I
,	O
to	O
reduce	O
double	O
images	O
and	O
blurring	O
due	O
to	O
local	B
mis-registrations	O
(	O
section	O
9.2.2	O
)	O
.	O
finally	O
,	O
if	O
we	O
are	O
given	O
an	O
unordered	O
set	O
of	O
images	O
to	O
register	O
,	O
we	O
need	O
to	O
discover	O
which	O
images	O
go	O
together	O
to	O
form	O
one	O
or	O
more	O
panoramas	O
.	O
this	O
process	O
of	O
panorama	O
recognition	B
is	O
described	O
in	O
section	O
9.2.3	O
.	O
9.2.1	O
bundle	B
adjustment	I
one	O
way	O
to	O
register	O
a	O
large	O
number	O
of	O
images	O
is	O
to	O
add	O
new	O
images	O
to	O
the	O
panorama	O
one	O
at	O
a	O
time	O
,	O
aligning	O
the	O
most	O
recent	O
image	B
with	O
the	O
previous	O
ones	O
already	O
in	O
the	O
collection	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
and	O
discovering	O
,	O
if	O
necessary	O
,	O
which	O
images	O
it	O
overlaps	O
(	O
sawhney	O
and	O
kumar	O
1999	O
)	O
.	O
in	O
the	O
case	O
of	O
360◦	O
panoramas	O
,	O
accumulated	O
error	O
may	O
lead	O
to	O
the	O
presence	O
of	O
a	O
gap	O
(	O
or	O
excessive	O
overlap	O
)	O
between	O
the	O
two	O
ends	O
of	O
the	O
panorama	O
,	O
which	O
can	O
be	O
ﬁxed	O
442	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
by	O
stretching	O
the	O
alignment	B
of	O
all	O
the	O
images	O
using	O
a	O
process	O
called	O
gap	B
closing	I
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
.	O
however	O
,	O
a	O
better	O
alternative	O
is	O
to	O
simultaneously	O
align	O
all	O
the	O
images	O
using	O
a	O
least-squares	O
framework	O
to	O
correctly	O
distribute	O
any	O
mis-registration	O
errors	O
.	O
the	O
process	O
of	O
simultaneously	O
adjusting	O
pose	O
parameters	B
for	O
a	O
large	O
collection	O
of	O
overlap-	O
ping	O
images	O
is	O
called	O
bundle	B
adjustment	I
in	O
the	O
photogrammetry	B
community	O
(	O
triggs	O
,	O
mclauch-	O
lan	O
,	O
hartley	O
et	O
al	O
.	O
1999	O
)	O
.	O
in	O
computer	O
vision	O
,	O
it	O
was	O
ﬁrst	O
applied	O
to	O
the	O
general	O
structure	B
from	I
motion	I
problem	O
(	O
szeliski	O
and	O
kang	O
1994	O
)	O
and	O
then	O
later	O
specialized	O
for	O
panoramic	O
image	B
stitching	I
(	O
shum	O
and	O
szeliski	O
2000	O
;	O
sawhney	O
and	O
kumar	O
1999	O
;	O
coorg	O
and	O
teller	O
2000	O
)	O
.	O
in	O
this	O
section	O
,	O
we	O
formulate	O
the	O
problem	O
of	O
global	B
alignment	I
using	O
a	O
feature-based	B
ap-	O
proach	O
,	O
since	O
this	O
results	O
in	O
a	O
simpler	O
system	O
.	O
an	O
equivalent	O
direct	B
approach	O
can	O
be	O
obtained	O
either	O
by	O
dividing	O
images	O
into	O
patches	O
and	O
creating	O
a	O
virtual	O
feature	O
correspondence	B
for	O
each	O
one	O
(	O
as	O
discussed	O
in	O
section	O
9.2.4	O
and	O
by	O
shum	O
and	O
szeliski	O
(	O
2000	O
)	O
)	O
or	O
by	O
replacing	O
the	O
per-feature	O
error	O
metrics	O
with	O
per-pixel	O
metrics	O
.	O
consider	O
the	O
feature-based	B
alignment	O
problem	O
given	O
in	O
equation	B
(	O
6.2	O
)	O
,	O
i.e.	O
,	O
epairwise−ls	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
2	O
=	O
(	O
cid:107	O
)	O
˜x	O
(	O
cid:48	O
)	O
i	O
(	O
xi	O
;	O
p	O
)	O
−	O
ˆx	O
(	O
cid:48	O
)	O
i	O
(	O
cid:107	O
)	O
2	O
.	O
(	O
9.25	O
)	O
for	O
multi-image	O
alignment	B
,	O
instead	O
of	O
having	O
a	O
single	O
collection	O
of	O
pairwise	O
feature	B
corre-	O
spondences	O
,	O
{	O
(	O
xi	O
,	O
ˆx	O
(	O
cid:48	O
)	O
i	O
)	O
}	O
,	O
we	O
have	O
a	O
collection	O
of	O
n	O
features	O
,	O
with	O
the	O
location	O
of	O
the	O
ith	O
feature	B
point	O
in	O
the	O
jth	O
image	B
denoted	O
by	O
xij	O
and	O
its	O
scalar	O
conﬁdence	O
(	O
i.e.	O
,	O
inverse	B
variance	O
)	O
denoted	O
by	O
cij.9	O
each	O
image	B
also	O
has	O
some	O
associated	O
pose	O
parameters	B
.	O
in	O
this	O
section	O
,	O
we	O
assume	O
that	O
this	O
pose	O
consists	O
of	O
a	O
rotation	O
matrix	O
rj	O
and	O
a	O
focal	O
length	O
fj	O
,	O
although	O
formulations	O
in	O
terms	O
of	O
homographies	O
are	O
also	O
possible	O
(	O
szeliski	O
and	O
shum	O
1997	O
;	O
sawhney	O
and	O
kumar	O
1999	O
)	O
.	O
the	O
equation	B
mapping	O
a	O
3d	O
point	O
xi	O
into	O
a	O
point	O
xij	O
in	O
frame	O
j	O
can	O
be	O
re-written	O
from	O
equations	B
(	O
2.68	O
)	O
and	O
(	O
9.5	O
)	O
as	O
j	O
˜xij	O
,	O
˜xij	O
∼	O
kjrjxi	O
and	O
xi	O
∼	O
r−1	O
j	O
k−1	O
(	O
9.26	O
)	O
where	O
kj	O
=	O
diag	O
(	O
fj	O
,	O
fj	O
,	O
1	O
)	O
is	O
the	O
simpliﬁed	O
form	O
of	O
the	O
calibration	B
matrix	I
.	O
the	O
motion	B
mapping	O
a	O
point	O
xij	O
from	O
frame	O
j	O
into	O
a	O
point	O
xik	O
in	O
frame	O
k	O
is	O
similarly	O
given	O
by	O
˜xik	O
∼	O
˜h	O
kj	O
˜xij	O
=	O
kkrkr−1	O
(	O
9.27	O
)	O
given	O
an	O
initial	O
set	O
of	O
{	O
(	O
rj	O
,	O
fj	O
)	O
}	O
estimates	O
obtained	O
from	O
chaining	O
pairwise	O
alignments	O
,	O
how	O
do	O
we	O
reﬁne	O
these	O
estimates	O
?	O
one	O
approach	O
is	O
to	O
directly	O
extend	O
the	O
pairwise	O
energy	O
epairwise−ls	O
(	O
9.25	O
)	O
to	O
a	O
multiview	O
j	O
k−1	O
j	O
˜xij	O
.	O
formulation	O
,	O
eall−pairs−2d	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:88	O
)	O
jk	O
cijcik	O
(	O
cid:107	O
)	O
˜xik	O
(	O
ˆxij	O
;	O
rj	O
,	O
fj	O
,	O
rk	O
,	O
fk	O
)	O
−	O
ˆxik	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
9.28	O
)	O
9	O
features	O
that	O
are	O
not	O
seen	O
in	O
image	B
j	O
have	O
cij	O
=	O
0.	O
we	O
can	O
also	O
use	O
2	O
×	O
2	O
inverse	B
covariance	O
matrices	O
σ−1	O
in	O
ij	O
place	O
of	O
cij	O
,	O
as	O
shown	O
in	O
equation	B
(	O
6.11	O
)	O
.	O
9.2	O
global	B
alignment	I
443	O
where	O
the	O
˜xik	O
function	O
is	O
the	O
predicted	O
location	O
of	O
feature	B
i	O
in	O
frame	O
k	O
given	O
by	O
(	O
9.27	O
)	O
,	O
ˆxij	O
is	O
the	O
observed	O
location	O
,	O
and	O
the	O
“	O
2d	O
”	O
in	O
the	O
subscript	O
indicates	O
that	O
an	O
image-plane	O
error	O
is	O
being	O
minimized	O
(	O
shum	O
and	O
szeliski	O
2000	O
)	O
.	O
note	O
that	O
since	O
˜xik	O
depends	O
on	O
the	O
ˆxij	O
observed	O
value	O
,	O
we	O
actually	O
have	O
an	O
errors-in-variable	O
problem	O
,	O
which	O
in	O
principle	O
requires	O
more	O
sophisticated	O
techniques	O
than	O
least	B
squares	I
to	O
solve	O
(	O
van	O
huffel	O
and	O
lemmerling	O
2002	O
;	O
matei	O
and	O
meer	O
2006	O
)	O
.	O
however	O
,	O
in	O
practice	O
,	O
if	O
we	O
have	O
enough	O
features	O
,	O
we	O
can	O
directly	O
minimize	O
the	O
above	O
quantity	O
using	O
regular	O
non-linear	B
least	O
squares	O
and	O
obtain	O
an	O
accurate	O
multi-frame	B
alignment	O
.	O
while	O
this	O
approach	O
works	O
well	O
in	O
practice	O
,	O
it	O
suffers	O
from	O
two	O
potential	O
disadvantages	O
.	O
first	O
,	O
since	O
a	O
summation	O
is	O
taken	O
over	O
all	O
pairs	B
with	O
corresponding	O
features	O
,	O
features	O
that	O
are	O
observed	O
many	O
times	O
are	O
overweighted	O
in	O
the	O
ﬁnal	O
solution	O
.	O
(	O
in	O
effect	O
,	O
a	O
feature	B
observed	O
m	O
2	O
(	O
cid:1	O
)	O
times	O
instead	O
of	O
m	O
times	O
.	O
)	O
second	O
,	O
the	O
derivatives	O
of	O
˜xik	O
with	O
respect	O
times	O
gets	O
counted	O
(	O
cid:0	O
)	O
m	O
to	O
the	O
{	O
(	O
rj	O
,	O
fj	O
)	O
}	O
are	O
a	O
little	O
cumbersome	O
,	O
although	O
using	O
the	O
incremental	B
correction	O
to	O
rj	O
introduced	O
in	O
section	O
9.1.3	O
makes	O
this	O
more	O
tractable	O
.	O
an	O
alternative	O
way	O
to	O
formulate	O
the	O
optimization	O
is	O
to	O
use	O
true	O
bundle	O
adjustment	O
,	O
i.e.	O
,	O
to	O
solve	O
not	O
only	O
for	O
the	O
pose	O
parameters	B
{	O
(	O
rj	O
,	O
fj	O
)	O
}	O
but	O
also	O
for	O
the	O
3d	O
point	O
positions	O
{	O
xi	O
}	O
,	O
(	O
9.29	O
)	O
eba−2d	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:88	O
)	O
j	O
cij	O
(	O
cid:107	O
)	O
˜xij	O
(	O
xi	O
;	O
rj	O
,	O
fj	O
)	O
−	O
ˆxij	O
(	O
cid:107	O
)	O
2	O
,	O
where	O
˜xij	O
(	O
xi	O
;	O
rj	O
,	O
fj	O
)	O
is	O
given	O
by	O
(	O
9.26	O
)	O
.	O
the	O
disadvantage	O
of	O
full	O
bundle	B
adjustment	I
is	O
that	O
there	O
are	O
more	O
variables	O
to	O
solve	O
for	O
,	O
so	O
each	O
iteration	O
and	O
also	O
the	O
overall	O
convergence	O
may	O
be	O
slower	O
.	O
(	O
imagine	O
how	O
the	O
3d	O
points	B
need	O
to	O
“	O
shift	O
”	O
each	O
time	O
some	O
rotation	O
matrices	O
are	O
updated	O
.	O
)	O
however	O
,	O
the	O
computational	O
complexity	O
of	O
each	O
linearized	O
gauss–newton	O
step	O
can	O
be	O
reduced	O
using	O
sparse	B
matrix	O
techniques	O
(	O
section	O
7.4.1	O
)	O
(	O
szeliski	O
and	O
kang	O
1994	O
;	O
triggs	O
,	O
mclauchlan	O
,	O
hartley	O
et	O
al	O
.	O
1999	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
an	O
alternative	O
formulation	O
is	O
to	O
minimize	O
the	O
error	O
in	O
3d	O
projected	O
ray	O
directions	O
(	O
shum	O
and	O
szeliski	O
2000	O
)	O
,	O
i.e.	O
,	O
eba−3d	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:88	O
)	O
j	O
cij	O
(	O
cid:107	O
)	O
˜xi	O
(	O
ˆxij	O
;	O
rj	O
,	O
fj	O
)	O
−	O
xi	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
9.30	O
)	O
where	O
˜xi	O
(	O
xij	O
;	O
rj	O
,	O
fj	O
)	O
is	O
given	O
by	O
the	O
second	O
half	O
of	O
(	O
9.26	O
)	O
.	O
this	O
has	O
no	O
particular	O
advantage	O
over	O
(	O
9.29	O
)	O
.	O
in	O
fact	O
,	O
since	O
errors	O
are	O
being	O
minimized	O
in	O
3d	O
ray	B
space	I
,	O
there	O
is	O
a	O
bias	O
towards	O
estimating	O
longer	O
focal	O
lengths	O
,	O
since	O
the	O
angles	O
between	O
rays	O
become	O
smaller	O
as	O
f	O
increases	O
.	O
however	O
,	O
if	O
we	O
eliminate	O
the	O
3d	O
rays	O
xi	O
,	O
we	O
can	O
derive	O
a	O
pairwise	O
energy	O
formulated	O
in	O
3d	O
ray	B
space	I
(	O
shum	O
and	O
szeliski	O
2000	O
)	O
,	O
eall−pairs−3d	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:88	O
)	O
jk	O
cijcik	O
(	O
cid:107	O
)	O
˜xi	O
(	O
ˆxij	O
;	O
rj	O
,	O
fj	O
)	O
−	O
˜xi	O
(	O
ˆxik	O
;	O
rk	O
,	O
fk	O
)	O
(	O
cid:107	O
)	O
2	O
.	O
(	O
9.31	O
)	O
444	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
this	O
results	O
in	O
the	O
simplest	O
set	O
of	O
update	O
equations	O
(	O
shum	O
and	O
szeliski	O
2000	O
)	O
,	O
since	O
the	O
fk	O
can	O
be	O
folded	O
into	O
the	O
creation	O
of	O
the	O
homogeneous	O
coordinate	O
vector	O
as	O
in	O
equation	B
(	O
9.7	O
)	O
.	O
thus	O
,	O
even	O
though	O
this	O
formula	O
over-weights	O
features	O
that	O
occur	O
more	O
frequently	O
,	O
it	O
is	O
the	O
method	O
used	O
by	O
shum	O
and	O
szeliski	O
(	O
2000	O
)	O
and	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
(	O
2005	O
)	O
.	O
in	O
order	B
to	O
reduce	O
the	O
bias	O
towards	O
longer	O
focal	O
lengths	O
,	O
we	O
multiply	O
each	O
residual	O
(	O
3d	O
error	O
)	O
by	O
(	O
cid:112	O
)	O
fjfk	O
,	O
which	O
is	O
similar	O
to	O
projecting	O
the	O
3d	O
rays	O
into	O
a	O
“	O
virtual	O
camera	O
”	O
of	O
intermediate	O
focal	O
length	O
.	O
up	B
vector	I
selection	I
.	O
as	O
mentioned	O
above	O
,	O
there	O
exists	O
a	O
global	B
ambiguity	O
in	O
the	O
pose	O
of	O
the	O
3d	O
cameras	O
computed	O
by	O
the	O
above	O
methods	O
.	O
while	O
this	O
may	O
not	O
appear	O
to	O
matter	O
,	O
people	O
prefer	O
that	O
the	O
ﬁnal	O
stitched	O
image	B
is	O
“	O
upright	O
”	O
rather	O
than	O
twisted	O
or	O
tilted	O
.	O
more	O
concretely	O
,	O
people	O
are	O
used	O
to	O
seeing	O
photographs	O
displayed	O
so	O
that	O
the	O
vertical	O
(	O
gravity	O
)	O
axis	O
points	B
straight	O
up	O
in	O
the	O
image	B
.	O
consider	O
how	O
you	O
usually	O
shoot	O
photographs	O
:	O
while	O
you	O
may	O
pan	O
and	O
tilt	O
the	O
camera	B
any	O
which	O
way	O
,	O
you	O
usually	O
keep	O
the	O
horizontal	O
edge	O
of	O
your	O
camera	B
(	O
its	O
x-axis	O
)	O
parallel	O
to	O
the	O
ground	O
plane	O
(	O
perpendicular	O
to	O
the	O
world	O
gravity	O
direction	O
)	O
.	O
mathematically	O
,	O
this	O
constraint	B
on	O
the	O
rotation	O
matrices	O
can	O
be	O
expressed	O
as	O
follows	O
.	O
re-	O
call	O
from	O
equation	B
(	O
9.26	O
)	O
that	O
the	O
3d	O
to	O
2d	O
projection	O
is	O
given	O
by	O
˜xik	O
∼	O
kkrkxi	O
.	O
(	O
9.32	O
)	O
we	O
wish	O
to	O
post-multiply	O
each	O
rotation	O
matrix	O
rk	O
by	O
a	O
global	B
rotation	O
rg	O
such	O
that	O
the	O
pro-	O
jection	O
of	O
the	O
global	B
y-axis	O
,	O
ˆ	O
=	O
(	O
0	O
,	O
1	O
,	O
0	O
)	O
is	O
perpendicular	O
to	O
the	O
image	B
x-axis	O
,	O
ˆı	O
=	O
(	O
1	O
,	O
0	O
,	O
0	O
)	O
.10	O
this	O
constraint	B
can	O
be	O
written	O
as	O
ˆıt	O
rkrgˆ	O
=	O
0	O
(	O
9.33	O
)	O
(	O
note	O
that	O
the	O
scaling	O
by	O
the	O
calibration	B
matrix	I
is	O
irrelevant	O
here	O
)	O
.	O
this	O
is	O
equivalent	O
to	O
re-	O
quiring	O
that	O
the	O
ﬁrst	O
row	O
of	O
rk	O
,	O
rk0	O
=	O
ˆıt	O
rk	O
be	O
perpendicular	O
to	O
the	O
second	O
column	O
of	O
rg	O
,	O
rg1	O
=	O
rgˆ	O
.	O
this	O
set	O
of	O
constraints	O
(	O
one	O
per	O
input	O
image	B
)	O
can	O
be	O
written	O
as	O
a	O
least	B
squares	I
problem	O
,	O
thus	O
,	O
rg1	O
is	O
the	O
smallest	O
eigenvector	O
of	O
the	O
scatter	O
or	O
moment	O
matrix	O
spanned	O
by	O
the	O
indi-	O
vidual	O
camera	B
rotation	O
x-vectors	O
,	O
which	O
should	O
generally	O
be	O
of	O
the	O
form	O
(	O
c	O
,	O
0	O
,	O
s	O
)	O
when	O
the	O
cameras	O
are	O
upright	O
.	O
to	O
fully	O
specify	O
the	O
rg	O
global	B
rotation	O
,	O
we	O
need	O
to	O
specify	O
one	O
additional	O
constraint	B
.	O
this	O
is	O
related	O
to	O
the	O
view	O
selection	O
problem	O
discussed	O
in	O
section	O
9.3.1.	O
one	O
simple	O
heuristic	O
is	O
to	O
10	O
note	O
that	O
here	O
we	O
use	O
the	O
convention	O
common	O
in	O
computer	O
graphics	O
that	O
the	O
vertical	O
world	O
axis	O
corresponds	O
to	O
y.	O
this	O
is	O
a	O
natural	B
choice	O
if	O
we	O
wish	O
the	O
rotation	O
matrix	O
associated	O
with	O
a	O
“	O
regular	O
”	O
image	B
taken	O
horizontally	O
to	O
be	O
the	O
identity	O
,	O
rather	O
than	O
a	O
90◦	O
rotation	O
around	O
the	O
x-axis	O
.	O
rg1	O
=	O
arg	O
min	O
(	O
rt	O
rk0	O
)	O
2	O
=	O
arg	O
min	O
r	O
r	O
(	O
cid:88	O
)	O
k	O
rt	O
(	O
cid:34	O
)	O
(	O
cid:88	O
)	O
k	O
rk0rt	O
k0	O
(	O
cid:35	O
)	O
r.	O
(	O
9.34	O
)	O
9.2	O
global	B
alignment	I
445	O
t	O
ˆk	O
rk	O
to	O
be	O
close	O
to	O
the	O
world	O
z-axis	O
,	O
rg2	O
=	O
rgˆk	O
.	O
we	O
can	O
therefore	O
compute	O
the	O
full	O
rotation	O
matrix	O
rg	O
in	O
three	O
steps	O
:	O
prefer	O
the	O
average	O
z-axis	O
of	O
the	O
individual	O
rotation	O
matrices	O
,	O
k	O
=	O
(	O
cid:80	O
)	O
k	O
1.	O
rg1	O
=	O
min	O
eigenvector	O
(	O
(	O
cid:80	O
)	O
k	O
rk0rt	O
2.	O
rg0	O
=	O
n	O
(	O
(	O
(	O
cid:80	O
)	O
k	O
rk2	O
)	O
×	O
rg1	O
)	O
;	O
3.	O
rg2	O
=	O
rg0	O
×	O
rg1	O
,	O
where	O
n	O
(	O
v	O
)	O
=	O
v/	O
(	O
cid:107	O
)	O
v	O
(	O
cid:107	O
)	O
normalizes	O
a	O
vector	O
v.	O
9.2.2	O
parallax	B
removal	I
k0	O
)	O
;	O
once	O
we	O
have	O
optimized	O
the	O
global	B
orientations	O
and	O
focal	O
lengths	O
of	O
our	O
cameras	O
,	O
we	O
may	O
ﬁnd	O
that	O
the	O
images	O
are	O
still	O
not	O
perfectly	O
aligned	O
,	O
i.e.	O
,	O
the	O
resulting	O
stitched	O
image	B
looks	O
blurry	O
or	O
ghosted	O
in	O
some	O
places	O
.	O
this	O
can	O
be	O
caused	O
by	O
a	O
variety	O
of	O
factors	O
,	O
including	O
unmodeled	O
radial	B
distortion	I
,	O
3d	O
parallax	O
(	O
failure	O
to	O
rotate	O
the	O
camera	B
around	O
its	O
optical	O
center	O
)	O
,	O
small	O
scene	O
motions	O
such	O
as	O
waving	O
tree	O
branches	O
,	O
and	O
large-scale	O
scene	O
motions	O
such	O
as	O
people	O
moving	O
in	O
and	O
out	O
of	O
pictures	O
.	O
each	O
of	O
these	O
problems	O
can	O
be	O
treated	O
with	O
a	O
different	O
approach	O
.	O
radial	B
distortion	I
can	O
be	O
estimated	O
(	O
potentially	O
ahead	O
of	O
time	O
)	O
using	O
one	O
of	O
the	O
techniques	O
discussed	O
in	O
section	O
2.1.6.	O
for	O
example	O
,	O
the	O
plumb-line	B
method	I
(	O
brown	O
1971	O
;	O
kang	O
2001	O
;	O
el-melegy	O
and	O
farag	O
2003	O
)	O
adjusts	O
radial	B
distortion	I
parameters	O
until	O
slightly	O
curved	O
lines	B
become	O
straight	O
,	O
while	O
mosaic-	O
based	O
approaches	O
adjust	O
them	O
until	O
mis-registration	O
is	O
reduced	O
in	O
image	B
overlap	O
areas	O
(	O
stein	O
1997	O
;	O
sawhney	O
and	O
kumar	O
1999	O
)	O
.	O
3d	O
parallax	O
can	O
be	O
handled	O
by	O
doing	O
a	O
full	O
3d	O
bundle	B
adjustment	I
,	O
i.e.	O
,	O
by	O
replacing	O
the	O
projection	O
equation	B
(	O
9.26	O
)	O
used	O
in	O
equation	B
(	O
9.29	O
)	O
with	O
equation	O
(	O
2.68	O
)	O
,	O
which	O
models	O
cam-	O
era	O
translations	O
.	O
the	O
3d	O
positions	O
of	O
the	O
matched	O
feature	B
points	O
and	O
cameras	O
can	O
then	O
be	O
si-	O
multaneously	O
recovered	O
,	O
although	O
this	O
can	O
be	O
signiﬁcantly	O
more	O
expensive	O
than	O
parallax-free	O
image	B
registration	I
.	O
once	O
the	O
3d	O
structure	O
has	O
been	O
recovered	O
,	O
the	O
scene	O
could	O
(	O
in	O
theory	O
)	O
be	O
projected	O
to	O
a	O
single	O
(	O
central	O
)	O
viewpoint	O
that	O
contains	O
no	O
parallax	O
.	O
however	O
,	O
in	O
order	B
to	O
do	O
this	O
,	O
dense	O
stereo	O
correspondence	B
needs	O
to	O
be	O
performed	O
(	O
section	O
11.3	O
)	O
(	O
li	O
,	O
shum	O
,	O
tang	O
et	O
al	O
.	O
2004	O
;	O
zheng	O
,	O
kang	O
,	O
cohen	O
et	O
al	O
.	O
2007	O
)	O
,	O
which	O
may	O
not	O
be	O
possible	O
if	O
the	O
images	O
contain	O
only	O
partial	O
overlap	O
.	O
in	O
that	O
case	O
,	O
it	O
may	O
be	O
necessary	O
to	O
correct	O
for	O
parallax	O
only	O
in	O
the	O
overlap	O
areas	O
,	O
which	O
can	O
be	O
accomplished	O
using	O
a	O
multi-perspective	O
plane	B
sweep	I
(	O
mpps	O
)	O
algorithm	B
(	O
kang	O
,	O
szeliski	O
,	O
and	O
uyttendaele	O
2004	O
;	O
uyttendaele	O
,	O
criminisi	O
,	O
kang	O
et	O
al	O
.	O
2004	O
)	O
.	O
when	O
the	O
motion	B
in	O
the	O
scene	O
is	O
very	O
large	O
,	O
i.e.	O
,	O
when	O
objects	O
appear	O
and	O
disappear	O
com-	O
pletely	O
,	O
a	O
sensible	O
solution	O
is	O
to	O
simply	O
select	O
pixels	O
from	O
only	O
one	O
image	B
at	O
a	O
time	O
as	O
the	O
source	O
for	O
the	O
ﬁnal	O
composite	O
(	O
milgram	O
1977	O
;	O
davis	O
1998	O
;	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
446	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
et	O
al	O
.	O
2004	O
)	O
,	O
as	O
discussed	O
in	O
section	O
9.3.2.	O
however	O
,	O
when	O
the	O
motion	B
is	O
reasonably	O
small	O
(	O
on	O
the	O
order	B
of	O
a	O
few	O
pixels	O
)	O
,	O
general	O
2d	O
motion	B
estimation	I
(	O
optical	B
ﬂow	I
)	O
can	O
be	O
used	O
to	O
perform	O
an	O
appropriate	O
correction	O
before	O
blending	B
using	O
a	O
process	O
called	O
local	B
alignment	O
(	O
shum	O
and	O
szeliski	O
2000	O
;	O
kang	O
,	O
uyttendaele	O
,	O
winder	O
et	O
al	O
.	O
2003	O
)	O
.	O
this	O
same	O
process	O
can	O
also	O
be	O
used	O
to	O
compensate	O
for	O
radial	O
distortion	O
and	O
3d	O
parallax	O
,	O
although	O
it	O
uses	O
a	O
weaker	O
motion	B
model	O
than	O
explicitly	O
modeling	B
the	O
source	O
of	O
error	O
and	O
may	O
,	O
therefore	O
,	O
fail	O
more	O
often	O
or	O
introduce	O
unwanted	O
distortions	O
.	O
the	O
local	B
alignment	O
technique	O
introduced	O
by	O
shum	O
and	O
szeliski	O
(	O
2000	O
)	O
starts	O
with	O
the	O
global	B
bundle	O
adjustment	O
(	O
9.31	O
)	O
used	O
to	O
optimize	O
the	O
camera	B
poses	O
.	O
once	O
these	O
have	O
been	O
estimated	O
,	O
the	O
desired	O
location	O
of	O
a	O
3d	O
point	O
xi	O
can	O
be	O
estimated	O
as	O
the	O
average	O
of	O
the	O
back-	O
projected	O
3d	O
locations	O
,	O
¯xi	O
∼	O
(	O
cid:88	O
)	O
j	O
cij	O
˜xi	O
(	O
ˆxij	O
;	O
rj	O
,	O
fj	O
)	O
(	O
cid:44	O
)	O
(	O
cid:88	O
)	O
j	O
cij	O
,	O
(	O
9.35	O
)	O
which	O
can	O
be	O
projected	O
into	O
each	O
image	B
j	O
to	O
obtain	O
a	O
target	O
location	O
¯xij	O
.	O
the	O
difference	B
between	O
the	O
target	O
locations	O
¯xij	O
and	O
the	O
original	O
features	O
xij	O
provide	O
a	O
set	O
of	O
local	B
motion	O
estimates	O
uij	O
=	O
¯xij	O
−	O
xij	O
,	O
(	O
9.36	O
)	O
which	O
can	O
be	O
interpolated	O
to	O
form	O
a	O
dense	O
correction	O
ﬁeld	O
uj	O
(	O
xj	O
)	O
.	O
in	O
their	O
system	O
,	O
shum	O
and	O
szeliski	O
(	O
2000	O
)	O
use	O
an	O
inverse	B
warping	I
algorithm	O
where	O
the	O
sparse	B
−uij	O
values	O
are	O
placed	O
at	O
the	O
new	O
target	O
locations	O
¯xij	O
,	O
interpolated	O
using	O
bilinear	O
kernel	B
functions	O
(	O
nielson	O
1993	O
)	O
and	O
then	O
added	O
to	O
the	O
original	O
pixel	O
coordinates	O
when	O
computing	O
the	O
warped	O
(	O
corrected	O
)	O
image	B
.	O
in	O
order	B
to	O
get	O
a	O
reasonably	O
dense	O
set	O
of	O
features	O
to	O
interpolate	O
,	O
shum	O
and	O
szeliski	O
(	O
2000	O
)	O
place	O
a	O
feature	B
point	O
at	O
the	O
center	O
of	O
each	O
patch	B
(	O
the	O
patch	B
size	O
controls	O
the	O
smoothness	B
in	O
the	O
local	B
alignment	O
stage	O
)	O
,	O
rather	O
than	O
relying	O
of	O
features	O
extracted	O
using	O
an	O
interest	O
operator	O
(	O
figure	O
9.10	O
)	O
.	O
an	O
alternative	O
approach	O
to	O
motion-based	O
de-ghosting	B
was	O
proposed	O
by	O
kang	O
,	O
uytten-	O
daele	O
,	O
winder	O
et	O
al	O
.	O
(	O
2003	O
)	O
,	O
who	O
estimate	O
dense	O
optical	O
ﬂow	O
between	O
each	O
input	O
image	B
and	O
a	O
central	O
reference	O
image	B
.	O
the	O
accuracy	B
of	O
the	O
ﬂow	O
vector	O
is	O
checked	O
using	O
a	O
photo-consistency	O
measure	O
before	O
a	O
given	O
warped	O
pixel	O
is	O
considered	O
valid	O
and	O
is	O
used	O
to	O
compute	O
a	O
high	O
dy-	O
namic	O
range	O
radiance	O
estimate	O
,	O
which	O
is	O
the	O
goal	O
of	O
their	O
overall	O
algorithm	B
.	O
the	O
requirement	O
for	O
a	O
reference	O
image	B
makes	O
their	O
approach	O
less	O
applicable	O
to	O
general	O
image	B
mosaicing	O
,	O
al-	O
though	O
an	O
extension	O
to	O
this	O
case	O
could	O
certainly	O
be	O
envisaged	O
.	O
9.2.3	O
recognizing	B
panoramas	I
the	O
ﬁnal	O
piece	O
needed	O
to	O
perform	O
fully	O
automated	B
image	O
stitching	O
is	O
a	O
technique	O
to	O
recognize	O
which	O
images	O
actually	O
go	O
together	O
,	O
which	O
brown	O
and	O
lowe	O
(	O
2007	O
)	O
call	O
recognizing	O
panora-	O
9.2	O
global	B
alignment	I
447	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
9.10	O
deghosting	O
a	O
mosaic	O
with	O
motion	O
parallax	O
(	O
shum	O
and	O
szeliski	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
ieee	O
:	O
(	O
a	O
)	O
composite	O
with	O
parallax	O
;	O
(	O
b	O
)	O
after	O
a	O
single	O
deghosting	O
step	O
(	O
patch	B
size	O
32	O
)	O
;	O
(	O
c	O
)	O
after	O
multiple	B
steps	O
(	O
sizes	O
32	O
,	O
16	O
and	O
8	O
)	O
.	O
mas	O
.	O
if	O
the	O
user	O
takes	O
images	O
in	O
sequence	O
so	O
that	O
each	O
image	B
overlaps	O
its	O
predecessor	O
and	O
also	O
speciﬁes	O
the	O
ﬁrst	O
and	O
last	O
images	O
to	O
be	O
stitched	O
,	O
bundle	B
adjustment	I
combined	O
with	O
the	O
process	O
of	O
topology	O
inference	B
can	O
be	O
used	O
to	O
automatically	O
assemble	O
a	O
panorama	O
(	O
sawhney	O
and	O
kumar	O
1999	O
)	O
.	O
however	O
,	O
users	O
often	O
jump	O
around	O
when	O
taking	O
panoramas	O
,	O
e.g.	O
,	O
they	O
may	O
start	O
a	O
new	O
row	O
on	O
top	O
of	O
a	O
previous	O
one	O
,	O
jump	O
back	O
to	O
take	O
a	O
repeat	O
shot	O
,	O
or	O
create	O
360◦	O
panoramas	O
where	O
end-to-end	O
overlaps	O
need	O
to	O
be	O
discovered	O
.	O
furthermore	O
,	O
the	O
ability	O
to	O
discover	O
multiple	B
panoramas	O
taken	O
by	O
a	O
user	O
over	O
an	O
extended	O
period	O
of	O
time	O
can	O
be	O
a	O
big	O
convenience	O
.	O
to	O
recognize	O
panoramas	O
,	O
brown	O
and	O
lowe	O
(	O
2007	O
)	O
ﬁrst	O
ﬁnd	O
all	O
pairwise	O
image	B
overlaps	O
using	O
a	O
feature-based	B
method	O
and	O
then	O
ﬁnd	O
connected	B
components	I
in	O
the	O
overlap	O
graph	O
to	O
“	O
recognize	O
”	O
individual	O
panoramas	O
(	O
figure	O
9.11	O
)	O
.	O
the	O
feature-based	B
matching	O
stage	O
ﬁrst	O
ex-	O
tracts	O
scale	O
invariant	O
feature	B
transform	O
(	O
sift	O
)	O
feature	B
locations	O
and	O
feature	B
descriptors	O
(	O
lowe	O
2004	O
)	O
from	O
all	O
the	O
input	O
images	O
and	O
places	O
them	O
in	O
an	O
indexing	O
structure	O
,	O
as	O
described	O
in	O
sec-	O
tion	B
4.1.3.	O
for	O
each	O
image	B
pair	O
under	O
consideration	O
,	O
the	O
nearest	O
matching	O
neighbor	O
is	O
found	O
for	O
each	O
feature	B
in	O
the	O
ﬁrst	O
image	B
,	O
using	O
the	O
indexing	O
structure	O
to	O
rapidly	O
ﬁnd	O
candidates	O
and	O
then	O
comparing	O
feature	B
descriptors	O
to	O
ﬁnd	O
the	O
best	O
match	O
.	O
ransac	O
is	O
used	O
to	O
ﬁnd	O
a	O
set	O
of	O
in-	O
lier	O
matches	O
;	O
pairs	B
of	O
matches	O
are	O
used	O
to	O
hypothesize	O
similarity	B
motion	O
models	O
that	O
are	O
then	O
used	O
to	O
count	O
the	O
number	O
of	O
inliers	B
.	O
(	O
a	O
more	O
recent	O
ransac	O
algorithm	B
tailored	O
speciﬁcally	O
for	O
rotational	O
panoramas	O
is	O
described	O
by	O
brown	O
,	O
hartley	O
,	O
and	O
nist´er	O
(	O
2007	O
)	O
.	O
)	O
in	O
practice	O
,	O
the	O
most	O
difﬁcult	O
part	O
of	O
getting	O
a	O
fully	O
automated	B
stitching	O
algorithm	B
to	O
work	O
is	O
deciding	O
which	O
pairs	B
of	O
images	O
actually	O
correspond	O
to	O
the	O
same	O
parts	O
of	O
the	O
scene	O
.	O
repeated	O
structures	O
such	O
as	O
windows	O
(	O
figure	O
9.12	O
)	O
can	O
lead	O
to	O
false	O
matches	O
when	O
using	O
a	O
feature-based	B
approach	O
.	O
one	O
way	O
to	O
mitigate	O
this	O
problem	O
is	O
to	O
perform	O
a	O
direct	B
pixel-	O
based	O
comparison	O
between	O
the	O
registered	O
images	O
to	O
determine	O
if	O
they	O
actually	O
are	O
different	O
views	O
of	O
the	O
same	O
scene	O
.	O
unfortunately	O
,	O
this	O
heuristic	O
may	O
fail	O
if	O
there	O
are	O
moving	O
objects	O
in	O
the	O
scene	O
(	O
figure	O
9.13	O
)	O
.	O
while	O
there	O
is	O
no	O
magic	O
bullet	O
for	O
this	O
problem	O
,	O
short	O
of	O
full	O
scene	B
understanding	I
,	O
further	O
improvements	O
can	O
likely	O
be	O
made	O
by	O
applying	O
domain-speciﬁc	O
448	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
9.11	O
recognizing	B
panoramas	I
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
,	O
ﬁgures	O
cour-	O
tesy	O
of	O
matthew	O
brown	O
:	O
(	O
a	O
)	O
input	O
images	O
with	O
pairwise	O
matches	O
;	O
(	O
b	O
)	O
images	O
grouped	O
into	O
connected	B
components	I
(	O
panoramas	O
)	O
;	O
(	O
c	O
)	O
individual	O
panoramas	O
registered	O
and	O
blended	O
into	O
stitched	O
composites	O
.	O
9.2	O
global	B
alignment	I
449	O
figure	O
9.12	O
matching	B
errors	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2004	O
)	O
:	O
accidental	O
matching	B
of	O
several	O
features	O
can	O
lead	O
to	O
matches	O
between	O
pairs	B
of	O
images	O
that	O
do	O
not	O
actually	O
overlap	O
.	O
figure	O
9.13	O
validation	O
of	O
image	B
matches	O
by	O
direct	O
pixel	O
error	O
comparison	O
can	O
fail	O
when	O
the	O
scene	O
contains	O
moving	O
objects	O
(	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
.	O
450	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
heuristics	O
,	O
such	O
as	O
priors	O
on	O
typical	O
camera	B
motions	O
as	O
well	O
as	O
machine	O
learning	O
techniques	O
applied	O
to	O
the	O
problem	O
of	O
match	O
validation	O
.	O
9.2.4	O
direct	B
vs.	I
feature-based	I
alignment	O
given	O
that	O
there	O
exist	O
these	O
two	O
approaches	O
to	O
aligning	O
images	O
,	O
which	O
is	O
preferable	O
?	O
early	O
feature-based	B
methods	O
would	O
get	O
confused	O
in	O
regions	O
that	O
were	O
either	O
too	O
textured	O
or	O
not	O
textured	O
enough	O
.	O
the	O
features	O
would	O
often	O
be	O
distributed	O
unevenly	O
over	O
the	O
images	O
,	O
thereby	O
failing	O
to	O
match	O
image	O
pairs	B
that	O
should	O
have	O
been	O
aligned	O
.	O
furthermore	O
,	O
establishing	O
correspondences	O
relied	O
on	O
simple	O
cross-correlation	O
between	O
patches	O
surrounding	O
the	O
feature	B
points	O
,	O
which	O
did	O
not	O
work	O
well	O
when	O
the	O
images	O
were	O
rotated	O
or	O
had	O
foreshortening	O
due	O
to	O
homographies	O
.	O
today	O
,	O
feature	B
detection	O
and	O
matching	B
schemes	O
are	O
remarkably	O
robust	B
and	O
can	O
even	O
be	O
used	O
for	O
known	O
object	O
recognition	B
from	O
widely	O
separated	O
views	O
(	O
lowe	O
2004	O
)	O
.	O
features	O
not	O
only	O
respond	O
to	O
regions	O
of	O
high	O
“	O
cornerness	O
”	O
(	O
f¨orstner	O
1986	O
;	O
harris	O
and	O
stephens	O
1988	O
)	O
but	O
also	O
to	O
“	O
blob-like	O
”	O
regions	O
(	O
lowe	O
2004	O
)	O
,	O
and	O
uniform	O
areas	O
(	O
matas	O
,	O
chum	O
,	O
urban	O
et	O
al	O
.	O
2004	O
;	O
tuytelaars	O
and	O
van	O
gool	O
2004	O
)	O
.	O
furthermore	O
,	O
because	O
they	O
operate	O
in	O
scale-space	O
and	O
use	O
a	O
dominant	O
orientation	O
(	O
or	O
orientation	O
invariant	O
descriptors	O
)	O
,	O
they	O
can	O
match	O
images	O
that	O
differ	O
in	O
scale	O
,	O
orientation	O
,	O
and	O
even	O
foreshortening	O
.	O
our	O
own	O
experience	O
in	O
working	O
with	O
feature-	O
based	O
approaches	O
is	O
that	O
if	O
the	O
features	O
are	O
well	O
distributed	O
over	O
the	O
image	B
and	O
the	O
descriptors	O
reasonably	O
designed	O
for	O
repeatability	O
,	O
enough	O
correspondences	O
to	O
permit	O
image	B
stitching	I
can	O
usually	O
be	O
found	O
(	O
brown	O
,	O
szeliski	O
,	O
and	O
winder	O
2005	O
)	O
.	O
the	O
biggest	O
disadvantage	O
of	O
direct	B
pixel-based	O
alignment	B
techniques	O
is	O
that	O
they	O
have	O
a	O
limited	O
range	O
of	O
convergence	O
.	O
even	O
though	O
they	O
can	O
be	O
used	O
in	O
a	O
hierarchical	B
(	O
coarse-to-	O
ﬁne	O
)	O
estimation	B
framework	O
,	O
in	O
practice	O
it	O
is	O
hard	O
to	O
use	O
more	O
than	O
two	O
or	O
three	O
levels	O
of	O
a	O
pyramid	B
before	O
important	O
details	O
start	O
to	O
be	O
blurred	O
away.11	O
for	O
matching	O
sequential	O
frames	O
in	O
a	O
video	B
,	O
direct	B
approaches	O
can	O
usually	O
be	O
made	O
to	O
work	O
.	O
however	O
,	O
for	O
matching	O
partially	O
overlapping	O
images	O
in	O
photo-based	O
panoramas	O
or	O
for	O
image	O
collections	O
where	O
the	O
contrast	O
or	O
content	O
varies	O
too	O
much	O
,	O
they	O
fail	O
too	O
often	O
to	O
be	O
useful	O
and	O
feature-based	B
approaches	O
are	O
therefore	O
preferred	O
.	O
9.3	O
compositing	B
once	O
we	O
have	O
registered	O
all	O
of	O
the	O
input	O
images	O
with	O
respect	O
to	O
each	O
other	O
,	O
we	O
need	O
to	O
decide	O
how	O
to	O
produce	O
the	O
ﬁnal	O
stitched	O
mosaic	O
image	B
.	O
this	O
involves	O
selecting	O
a	O
ﬁnal	O
compositing	B
surface	O
(	O
ﬂat	O
,	O
cylindrical	B
,	O
spherical	B
,	O
etc	O
.	O
)	O
and	O
view	O
(	O
reference	O
image	B
)	O
.	O
it	O
also	O
involves	O
selecting	O
11	O
fourier-based	O
correlation	O
(	O
szeliski	O
1996	O
;	O
szeliski	O
and	O
shum	O
1997	O
)	O
can	O
extend	O
this	O
range	O
but	O
requires	O
cylindrical	B
images	O
or	O
motion	B
prediction	O
to	O
be	O
useful	O
.	O
9.3	O
compositing	B
451	O
which	O
pixels	O
contribute	O
to	O
the	O
ﬁnal	O
composite	O
and	O
how	O
to	O
optimally	O
blend	O
these	O
pixels	O
to	O
minimize	O
visible	O
seams	O
,	O
blur	O
,	O
and	O
ghosting	O
.	O
in	O
this	O
section	O
,	O
we	O
review	O
techniques	O
that	O
address	O
these	O
problems	O
,	O
namely	O
compositing	B
surface	O
parameterization	O
,	O
pixel	O
and	O
seam	B
selection	I
,	O
blending	B
,	O
and	O
exposure	B
compensation	I
.	O
my	O
emphasis	O
is	O
on	O
fully	O
automated	B
approaches	O
to	O
the	O
problem	O
.	O
since	O
the	O
creation	O
of	O
high-	O
quality	O
panoramas	O
and	O
composites	O
is	O
as	O
much	O
an	O
artistic	O
endeavor	O
as	O
a	O
computational	O
one	O
,	O
various	O
interactive	B
tools	O
have	O
been	O
developed	O
to	O
assist	O
this	O
process	O
(	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
;	O
li	O
,	O
sun	O
,	O
tang	O
et	O
al	O
.	O
2004	O
;	O
rother	O
,	O
kolmogorov	O
,	O
and	O
blake	O
2004	O
)	O
.	O
some	O
of	O
these	O
are	O
covered	O
in	O
more	O
detail	O
in	O
section	O
10.4	O
.	O
9.3.1	O
choosing	O
a	O
compositing	B
surface	O
the	O
ﬁrst	O
choice	O
to	O
be	O
made	O
is	O
how	O
to	O
represent	O
the	O
ﬁnal	O
image	B
.	O
if	O
only	O
a	O
few	O
images	O
are	O
stitched	O
together	O
,	O
a	O
natural	B
approach	O
is	O
to	O
select	O
one	O
of	O
the	O
images	O
as	O
the	O
reference	O
and	O
to	O
then	O
warp	O
all	O
of	O
the	O
other	O
images	O
into	O
its	O
reference	O
coordinate	O
system	O
.	O
the	O
resulting	O
com-	O
posite	O
is	O
sometimes	O
called	O
a	O
ﬂat	O
panorama	O
,	O
since	O
the	O
projection	O
onto	O
the	O
ﬁnal	O
surface	B
is	O
still	O
a	O
perspective	B
projection	O
,	O
and	O
hence	O
straight	O
lines	B
remain	O
straight	O
(	O
which	O
is	O
often	O
a	O
desirable	O
attribute	O
)	O
.12	O
for	O
larger	O
ﬁelds	O
of	O
view	O
,	O
however	O
,	O
we	O
can	O
not	O
maintain	O
a	O
ﬂat	O
representation	O
without	O
ex-	O
cessively	O
stretching	O
pixels	O
near	O
the	O
border	O
of	O
the	O
image	B
.	O
(	O
in	O
practice	O
,	O
ﬂat	O
panoramas	O
start	O
to	O
look	O
severely	O
distorted	O
once	O
the	O
ﬁeld	O
of	O
view	O
exceeds	O
90◦	O
or	O
so	O
.	O
)	O
the	O
usual	O
choice	O
for	O
compositing	O
larger	O
panoramas	O
is	O
to	O
use	O
a	O
cylindrical	B
(	O
chen	O
1995	O
;	O
szeliski	O
1996	O
)	O
or	O
spherical	B
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
projection	O
,	O
as	O
described	O
in	O
section	O
9.1.6.	O
in	O
fact	O
,	O
any	O
surface	B
used	O
for	O
environment	O
mapping	O
in	O
computer	O
graphics	O
can	O
be	O
used	O
,	O
including	O
a	O
cube	B
map	I
,	O
which	O
represents	O
the	O
full	O
viewing	O
sphere	O
with	O
the	O
six	O
square	O
faces	O
of	O
a	O
cube	O
(	O
greene	O
1986	O
;	O
szeliski	O
and	O
shum	O
1997	O
)	O
.	O
cartographers	O
have	O
also	O
developed	O
a	O
number	O
of	O
alternative	O
methods	O
for	O
representing	O
the	O
globe	O
(	O
bugayevskiy	O
and	O
snyder	O
1995	O
)	O
.	O
the	O
choice	O
of	O
parameterization	O
is	O
somewhat	O
application	O
dependent	O
and	O
involves	O
a	O
trade-	O
off	O
between	O
keeping	O
the	O
local	B
appearance	O
undistorted	O
(	O
e.g.	O
,	O
keeping	O
straight	O
lines	B
straight	O
)	O
and	O
providing	O
a	O
reasonably	O
uniform	O
sampling	B
of	O
the	O
environment	O
.	O
automatically	O
making	O
this	O
selection	O
and	O
smoothly	O
transitioning	O
between	O
representations	O
based	O
on	O
the	O
extent	O
of	O
the	O
panorama	O
is	O
an	O
active	O
area	O
of	O
current	O
research	O
(	O
kopf	O
,	O
uyttendaele	O
,	O
deussen	O
et	O
al	O
.	O
2007	O
)	O
.	O
an	O
interesting	O
recent	O
development	O
in	O
panoramic	O
photography	O
has	O
been	O
the	O
use	O
of	O
stereo-	O
graphic	O
projections	B
looking	O
down	O
at	O
the	O
ground	O
(	O
in	O
an	O
outdoor	O
scene	O
)	O
to	O
create	O
“	O
little	O
planet	O
”	O
renderings.13	O
12	O
recently	O
,	O
some	O
techniques	O
have	O
been	O
developed	O
to	O
straighten	O
curved	O
lines	B
in	O
cylindrical	B
and	O
spherical	B
panora-	O
mas	O
(	O
carroll	O
,	O
agrawala	O
,	O
and	O
agarwala	O
2009	O
;	O
kopf	O
,	O
lischinski	O
,	O
deussen	O
et	O
al	O
.	O
2009	O
)	O
.	O
13	O
these	O
are	O
inspired	O
by	O
the	O
little	O
prince	O
by	O
antoine	O
de	O
saint-exupery	O
.	O
go	O
to	O
http	O
:	O
//www.ﬂickr.com	O
and	O
search	O
452	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
view	O
selection	O
.	O
once	O
we	O
have	O
chosen	O
the	O
output	O
parameterization	O
,	O
we	O
still	O
need	O
to	O
deter-	O
mine	O
which	O
part	O
of	O
the	O
scene	O
will	O
be	O
centered	O
in	O
the	O
ﬁnal	O
view	O
.	O
as	O
mentioned	O
above	O
,	O
for	O
a	O
ﬂat	O
composite	O
,	O
we	O
can	O
choose	O
one	O
of	O
the	O
images	O
as	O
a	O
reference	O
.	O
often	O
,	O
a	O
reasonable	O
choice	O
is	O
the	O
one	O
that	O
is	O
geometrically	O
most	O
central	O
.	O
for	O
example	O
,	O
for	O
rotational	O
panoramas	O
represented	O
as	O
a	O
collection	O
of	O
3d	O
rotation	O
matrices	O
,	O
we	O
can	O
choose	O
the	O
image	B
whose	O
z-axis	O
is	O
closest	O
to	O
the	O
average	O
z-axis	O
(	O
assuming	O
a	O
reasonable	O
ﬁeld	O
of	O
view	O
)	O
.	O
alternatively	O
,	O
we	O
can	O
use	O
the	O
average	O
z-axis	O
(	O
or	O
quaternion	O
,	O
but	O
this	O
is	O
trickier	O
)	O
to	O
deﬁne	O
the	O
reference	O
rotation	O
matrix	O
.	O
for	O
larger	O
,	O
e.g.	O
,	O
cylindrical	B
or	O
spherical	B
,	O
panoramas	O
,	O
we	O
can	O
use	O
the	O
same	O
heuristic	O
if	O
a	O
subset	O
of	O
the	O
viewing	O
sphere	O
has	O
been	O
imaged	O
.	O
in	O
the	O
case	O
of	O
full	O
360◦	O
panoramas	O
,	O
a	O
better	O
choice	O
might	O
be	O
to	O
choose	O
the	O
middle	O
image	B
from	O
the	O
sequence	O
of	O
inputs	O
,	O
or	O
sometimes	O
the	O
ﬁrst	O
image	B
,	O
assuming	O
this	O
contains	O
the	O
object	O
of	O
greatest	O
interest	O
.	O
in	O
all	O
of	O
these	O
cases	O
,	O
having	O
the	O
user	O
control	O
the	O
ﬁnal	O
view	O
is	O
often	O
highly	O
desirable	O
.	O
if	O
the	O
“	O
up	O
vector	O
”	O
computation	O
de-	O
scribed	O
in	O
section	O
9.2.1	O
is	O
working	O
correctly	O
,	O
this	O
can	O
be	O
as	O
simple	O
as	O
panning	O
over	O
the	O
image	B
or	O
setting	O
a	O
vertical	O
“	O
center	O
line	O
”	O
for	O
the	O
ﬁnal	O
panorama	O
.	O
coordinate	B
transformations	I
.	O
after	O
selecting	O
the	O
parameterization	O
and	O
reference	O
view	O
,	O
we	O
still	O
need	O
to	O
compute	O
the	O
mappings	O
between	O
the	O
input	O
and	O
output	O
pixels	O
coordinates	O
.	O
if	O
the	O
ﬁnal	O
compositing	B
surface	O
is	O
ﬂat	O
(	O
e.g.	O
,	O
a	O
single	O
plane	O
or	O
the	O
face	B
of	O
a	O
cube	B
map	I
)	O
and	O
the	O
input	O
images	O
have	O
no	O
radial	B
distortion	I
,	O
the	O
coordinate	O
transformation	O
is	O
the	O
simple	O
homography	B
described	O
by	O
(	O
9.5	O
)	O
.	O
this	O
kind	O
of	O
warping	O
can	O
be	O
performed	O
in	O
graphics	O
hardware	O
by	O
appropriately	O
setting	O
texture	B
mapping	O
coordinates	O
and	O
rendering	B
a	O
single	O
quadrilateral	O
.	O
if	O
the	O
ﬁnal	O
composite	O
surface	B
has	O
some	O
other	O
analytic	O
form	O
(	O
e.g.	O
,	O
cylindrical	B
or	O
spherical	B
)	O
,	O
we	O
need	O
to	O
convert	O
every	O
pixel	O
in	O
the	O
ﬁnal	O
panorama	O
into	O
a	O
viewing	O
ray	O
(	O
3d	O
point	O
)	O
and	O
then	O
map	O
it	O
back	O
into	O
each	O
image	B
according	O
to	O
the	O
projection	O
(	O
and	O
optionally	O
radial	B
distortion	I
)	O
equations	B
.	O
this	O
process	O
can	O
be	O
made	O
more	O
efﬁcient	O
by	O
precomputing	O
some	O
lookup	O
tables	O
,	O
e.g.	O
,	O
the	O
partial	O
trigonometric	O
functions	O
needed	O
to	O
map	O
cylindrical	B
or	O
spherical	B
coordinates	O
to	O
3d	O
coordinates	O
or	O
the	O
radial	B
distortion	I
ﬁeld	O
at	O
each	O
pixel	O
.	O
it	O
is	O
also	O
possible	O
to	O
accelerate	O
this	O
process	O
by	O
computing	O
exact	O
pixel	O
mappings	O
on	O
a	O
coarser	O
grid	O
and	O
then	O
interpolating	O
these	O
values	O
.	O
when	O
the	O
ﬁnal	O
compositing	B
surface	O
is	O
a	O
texture-mapped	O
polyhedron	O
,	O
a	O
slightly	O
more	O
so-	O
phisticated	O
algorithm	B
must	O
be	O
used	O
.	O
not	O
only	O
do	O
the	O
3d	O
and	O
texture	B
map	O
coordinates	O
have	O
to	O
be	O
properly	O
handled	O
,	O
but	O
a	O
small	O
amount	O
of	O
overdraw	O
outside	O
the	O
triangle	O
footprints	O
in	O
the	O
tex-	O
ture	O
map	O
is	O
necessary	O
,	O
to	O
ensure	O
that	O
the	O
texture	B
pixels	O
being	O
interpolated	O
during	O
3d	O
rendering	B
have	O
valid	O
values	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
.	O
sampling	B
issues	O
.	O
while	O
the	O
above	O
computations	O
can	O
yield	O
the	O
correct	O
(	O
fractional	O
)	O
pixel	O
addresses	O
in	O
each	O
input	O
image	B
,	O
we	O
still	O
need	O
to	O
pay	O
attention	O
to	O
sampling	B
issues	O
.	O
for	O
example	O
,	O
for	O
“	O
little	O
planet	O
projection	O
”	O
.	O
9.3	O
compositing	B
453	O
if	O
the	O
ﬁnal	O
panorama	O
has	O
a	O
lower	O
resolution	O
than	O
the	O
input	O
images	O
,	O
pre-ﬁltering	O
the	O
input	O
images	O
is	O
necessary	O
to	O
avoid	O
aliasing	B
.	O
these	O
issues	O
have	O
been	O
extensively	O
studied	O
in	O
both	O
the	O
image	B
processing	O
and	O
computer	O
graphics	O
communities	O
.	O
the	O
basic	O
problem	O
is	O
to	O
compute	O
the	O
appropriate	O
pre-ﬁlter	O
,	O
which	O
depends	O
on	O
the	O
distance	O
(	O
and	O
arrangement	O
)	O
between	O
neighboring	O
samples	O
in	O
a	O
source	O
image	B
.	O
as	O
discussed	O
in	O
sections	O
3.5.2	O
and	O
3.6.1	O
,	O
various	O
approximate	O
solutions	O
,	O
such	O
as	O
mip	O
mapping	O
(	O
williams	O
1983	O
)	O
or	O
elliptically	O
weighted	B
gaussian	O
averaging	O
(	O
greene	O
and	O
heckbert	O
1986	O
)	O
have	O
been	O
developed	O
in	O
the	O
graphics	O
community	O
.	O
for	O
highest	O
visual	O
quality	O
,	O
a	O
higher	O
order	O
(	O
e.g.	O
,	O
cubic	B
)	O
interpolator	O
combined	O
with	O
a	O
spatially	O
adaptive	O
pre-	O
ﬁlter	O
may	O
be	O
necessary	O
(	O
wang	O
,	O
kang	O
,	O
szeliski	O
et	O
al	O
.	O
2001	O
)	O
.	O
under	O
certain	O
conditions	O
,	O
it	O
may	O
also	O
be	O
possible	O
to	O
produce	O
images	O
with	O
a	O
higher	O
resolution	O
than	O
the	O
input	O
images	O
using	O
the	O
process	O
of	O
super-resolution	O
(	O
section	O
10.3	O
)	O
.	O
9.3.2	O
pixel	B
selection	I
and	O
weighting	B
(	O
de-ghosting	B
)	O
once	O
the	O
source	O
pixels	O
have	O
been	O
mapped	O
onto	O
the	O
ﬁnal	O
composite	O
surface	B
,	O
we	O
must	O
still	O
decide	O
how	O
to	O
blend	O
them	O
in	O
order	B
to	O
create	O
an	O
attractive-looking	O
panorama	O
.	O
if	O
all	O
of	O
the	O
images	O
are	O
in	O
perfect	O
registration	O
and	O
identically	O
exposed	O
,	O
this	O
is	O
an	O
easy	O
problem	O
,	O
i.e.	O
,	O
any	O
pixel	O
or	O
combination	O
will	O
do	O
.	O
however	O
,	O
for	O
real	O
images	O
,	O
visible	O
seams	O
(	O
due	O
to	O
exposure	O
differences	O
)	O
,	O
blurring	O
(	O
due	O
to	O
mis-registration	O
)	O
,	O
or	O
ghosting	O
(	O
due	O
to	O
moving	O
objects	O
)	O
can	O
occur	O
.	O
creating	O
clean	O
,	O
pleasing-looking	O
panoramas	O
involves	O
both	O
deciding	O
which	O
pixels	O
to	O
use	O
and	O
how	O
to	O
weight	O
or	O
blend	O
them	O
.	O
the	O
distinction	O
between	O
these	O
two	O
stages	O
is	O
a	O
little	O
ﬂuid	O
,	O
since	O
per-pixel	O
weighting	B
can	O
be	O
thought	O
of	O
as	O
a	O
combination	O
of	O
selection	O
and	O
blending	B
.	O
in	O
this	O
section	O
,	O
we	O
discuss	O
spatially	O
varying	O
weighting	O
,	O
pixel	B
selection	I
(	O
seam	O
placement	O
)	O
,	O
and	O
then	O
more	O
sophisticated	O
blending	B
.	O
feathering	B
and	O
center-weighting	O
.	O
the	O
simplest	O
way	O
to	O
create	O
a	O
ﬁnal	O
composite	O
is	O
to	O
sim-	O
ply	O
take	O
an	O
average	O
value	O
at	O
each	O
pixel	O
,	O
c	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
wk	O
(	O
x	O
)	O
˜ik	O
(	O
x	O
)	O
(	O
cid:44	O
)	O
(	O
cid:88	O
)	O
k	O
wk	O
(	O
x	O
)	O
,	O
(	O
9.37	O
)	O
where	O
˜ik	O
(	O
x	O
)	O
are	O
the	O
warped	O
(	O
re-sampled	O
)	O
images	O
and	O
wk	O
(	O
x	O
)	O
is	O
1	O
at	O
valid	O
pixels	O
and	O
0	O
else-	O
where	O
.	O
on	O
computer	O
graphics	O
hardware	O
,	O
this	O
kind	O
of	O
summation	O
can	O
be	O
performed	O
in	O
an	O
accumulation	O
buffer	O
(	O
using	O
the	O
a	O
channel	O
as	O
the	O
weight	O
)	O
.	O
simple	O
averaging	O
usually	O
does	O
not	O
work	O
very	O
well	O
,	O
since	O
exposure	O
differences	O
,	O
mis-	O
registrations	O
,	O
and	O
scene	O
movement	O
are	O
all	O
very	O
visible	O
(	O
figure	O
9.14a	O
)	O
.	O
if	O
rapidly	O
moving	O
objects	O
are	O
the	O
only	O
problem	O
,	O
taking	O
a	O
median	B
ﬁlter	O
(	O
which	O
is	O
a	O
kind	O
of	O
pixel	B
selection	I
opera-	O
tor	O
)	O
can	O
often	O
be	O
used	O
to	O
remove	O
them	O
(	O
figure	O
9.14b	O
)	O
(	O
irani	O
and	O
anandan	O
1998	O
)	O
.	O
conversely	O
,	O
center-weighting	O
(	O
discussed	O
below	O
)	O
and	O
minimum	O
likelihood	O
selection	O
(	O
agarwala	O
,	O
dontcheva	O
,	O
454	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
e	O
)	O
(	O
g	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
(	O
f	O
)	O
(	O
h	O
)	O
figure	O
9.14	O
final	O
composites	O
computed	O
by	O
a	O
variety	O
of	O
algorithms	O
(	O
szeliski	O
2006a	O
)	O
:	O
(	O
a	O
)	O
average	O
,	O
(	O
b	O
)	O
median	B
,	O
(	O
c	O
)	O
feathered	O
average	O
,	O
(	O
d	O
)	O
p-norm	O
p	O
=	O
10	O
,	O
(	O
e	O
)	O
voronoi	O
,	O
(	O
f	O
)	O
weighted	B
rod	O
vertex	O
cover	O
with	O
feathering	O
,	O
(	O
g	O
)	O
graph	B
cut	I
seams	O
with	O
poisson	O
blending	B
and	O
(	O
h	O
)	O
with	O
pyramid	O
blending	B
.	O
9.3	O
compositing	B
455	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
can	O
sometimes	O
be	O
used	O
to	O
retain	O
multiple	B
copies	O
of	O
a	O
moving	O
object	O
(	O
figure	O
9.17	O
)	O
.	O
a	O
better	O
approach	O
to	O
averaging	O
is	O
to	O
weight	O
pixels	O
near	O
the	O
center	O
of	O
the	O
image	B
more	O
heavily	O
and	O
to	O
down-weight	O
pixels	O
near	O
the	O
edges	O
.	O
when	O
an	O
image	B
has	O
some	O
cutout	O
regions	O
,	O
down-weighting	O
pixels	O
near	O
the	O
edges	O
of	O
both	O
cutouts	O
and	O
the	O
image	B
is	O
preferable	O
.	O
this	O
can	O
be	O
done	O
by	O
computing	O
a	O
distance	O
map	O
or	O
grassﬁre	O
transform	B
,	O
wk	O
(	O
x	O
)	O
=	O
arg	O
min	O
y	O
{	O
(	O
cid:107	O
)	O
y	O
(	O
cid:107	O
)	O
|	O
˜ik	O
(	O
x	O
+	O
y	O
)	O
is	O
invalid	O
}	O
,	O
(	O
9.38	O
)	O
where	O
each	O
valid	O
pixel	O
is	O
tagged	O
with	O
its	O
euclidean	O
distance	O
to	O
the	O
nearest	O
invalid	O
pixel	O
(	O
sec-	O
tion	B
3.3.3	O
)	O
.	O
the	O
euclidean	O
distance	O
map	O
can	O
be	O
efﬁciently	O
computed	O
using	O
a	O
two-pass	O
raster	O
algorithm	B
(	O
danielsson	O
1980	O
;	O
borgefors	O
1986	O
)	O
.	O
weighted	B
averaging	O
with	O
a	O
distance	O
map	O
is	O
often	O
called	O
feathering	B
(	O
szeliski	O
and	O
shum	O
1997	O
;	O
chen	O
and	O
klette	O
1999	O
;	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
2001	O
)	O
and	O
does	O
a	O
reasonable	O
job	O
of	O
blending	B
over	O
exposure	O
differences	O
.	O
however	O
,	O
blurring	O
and	O
ghosting	O
can	O
still	O
be	O
problems	O
(	O
figure	O
9.14c	O
)	O
.	O
note	O
that	O
weighted	B
averaging	O
is	O
not	O
the	O
same	O
as	O
compositing	B
the	O
individual	O
images	O
with	O
the	O
classic	O
over	O
operation	O
(	O
porter	O
and	O
duff	O
1984	O
;	O
blinn	O
1994a	O
)	O
,	O
even	O
when	O
using	O
the	O
weight	O
values	O
(	O
normalized	B
to	O
sum	O
up	O
to	O
one	O
)	O
as	O
alpha	O
(	O
translucency	O
)	O
channels	O
.	O
this	O
is	O
because	O
the	O
over	O
operation	O
attenuates	O
the	O
values	O
from	O
more	O
distant	O
surfaces	O
and	O
,	O
hence	O
,	O
is	O
not	O
equivalent	O
to	O
a	O
direct	B
sum	O
.	O
one	O
way	O
to	O
improve	O
feathering	B
is	O
to	O
raise	O
the	O
distance	O
map	O
values	O
to	O
some	O
large	O
power	O
,	O
i.e.	O
,	O
to	O
use	O
wp	O
k	O
(	O
x	O
)	O
in	O
equation	B
(	O
9.37	O
)	O
.	O
the	O
weighted	B
averages	O
then	O
become	O
dominated	O
by	O
the	O
larger	O
values	O
,	O
i.e.	O
,	O
they	O
act	O
somewhat	O
like	O
a	O
p-norm	O
.	O
the	O
resulting	O
composite	O
can	O
often	O
provide	O
a	O
reasonable	O
tradeoff	O
between	O
visible	O
exposure	O
differences	O
and	O
blur	O
(	O
figure	O
9.14d	O
)	O
.	O
in	O
the	O
limit	O
as	O
p	O
→	O
∞	O
,	O
only	O
the	O
pixel	O
with	O
the	O
maximum	O
weight	O
is	O
selected	O
,	O
where	O
c	O
(	O
x	O
)	O
=	O
˜il	O
(	O
x	O
)	O
(	O
x	O
)	O
,	O
l	O
=	O
arg	O
max	O
k	O
wk	O
(	O
x	O
)	O
(	O
9.39	O
)	O
(	O
9.40	O
)	O
is	O
the	O
label	O
assignment	O
or	O
pixel	B
selection	I
function	O
that	O
selects	O
which	O
image	B
to	O
use	O
at	O
each	O
pixel	O
.	O
this	O
hard	O
pixel	B
selection	I
process	O
produces	O
a	O
visibility	B
mask-sensitive	O
variant	O
of	O
the	O
fa-	O
miliar	O
voronoi	O
diagram	O
,	O
which	O
assigns	O
each	O
pixel	O
to	O
the	O
nearest	O
image	O
center	O
in	O
the	O
set	O
(	O
wood	O
,	O
finkelstein	O
,	O
hughes	O
et	O
al	O
.	O
1997	O
;	O
peleg	O
,	O
rousso	O
,	O
rav-acha	O
et	O
al	O
.	O
2000	O
)	O
.	O
the	O
resulting	O
com-	O
posite	O
,	O
while	O
useful	O
for	O
artistic	O
guidance	O
and	O
in	O
high-overlap	O
panoramas	O
(	O
manifold	O
mosaics	O
)	O
tends	O
to	O
have	O
very	O
hard	O
edges	O
with	O
noticeable	O
seams	O
when	O
the	O
exposures	O
vary	O
(	O
figure	O
9.14e	O
)	O
.	O
xiong	O
and	O
turkowski	O
(	O
1998	O
)	O
use	O
this	O
voronoi	O
idea	O
(	O
local	B
maximum	O
of	O
the	O
grassﬁre	O
trans-	O
form	O
)	O
to	O
select	O
seams	O
for	O
laplacian	O
pyramid	B
blending	O
(	O
which	O
is	O
discussed	O
below	O
)	O
.	O
however	O
,	O
456	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
9.15	O
computation	O
of	O
regions	O
of	O
difference	B
(	O
rods	O
)	O
(	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
three	O
overlapping	O
images	O
with	O
a	O
moving	O
face	O
;	O
(	O
b	O
)	O
corresponding	O
rods	O
;	O
(	O
c	O
)	O
graph	O
of	O
coincident	O
rods	O
.	O
since	O
the	O
seam	B
selection	I
is	O
performed	O
sequentially	O
as	O
new	O
images	O
are	O
added	O
in	O
,	O
some	O
artifacts	O
can	O
occur	O
.	O
optimal	O
seam	B
selection	I
.	O
computing	O
the	O
voronoi	O
diagram	O
is	O
one	O
way	O
to	O
select	O
the	O
seams	O
between	O
regions	O
where	O
different	O
images	O
contribute	O
to	O
the	O
ﬁnal	O
composite	O
.	O
however	O
,	O
voronoi	O
images	O
totally	O
ignore	O
the	O
local	B
image	O
structure	O
underlying	O
the	O
seam	O
.	O
a	O
better	O
approach	O
is	O
to	O
place	O
the	O
seams	O
in	O
regions	O
where	O
the	O
images	O
agree	O
,	O
so	O
that	O
tran-	O
sitions	O
from	O
one	O
source	O
to	O
another	O
are	O
not	O
visible	O
.	O
in	O
this	O
way	O
,	O
the	O
algorithm	B
avoids	O
“	O
cutting	O
through	O
”	O
moving	O
objects	O
where	O
a	O
seam	O
would	O
look	O
unnatural	O
(	O
davis	O
1998	O
)	O
.	O
for	O
a	O
pair	O
of	O
images	O
,	O
this	O
process	O
can	O
be	O
formulated	O
as	O
a	O
simple	O
dynamic	B
program	O
starting	O
from	O
one	O
edge	O
of	O
the	O
overlap	O
region	B
and	O
ending	O
at	O
the	O
other	O
(	O
milgram	O
1975	O
,	O
1977	O
;	O
davis	O
1998	O
;	O
efros	O
and	O
freeman	O
2001	O
)	O
.	O
when	O
multiple	B
images	O
are	O
being	O
composited	O
,	O
the	O
dynamic	B
program	O
idea	O
does	O
not	O
readily	O
generalize	O
.	O
(	O
for	O
square	O
texture	B
tiles	O
being	O
composited	O
sequentially	O
,	O
efros	O
and	O
freeman	O
(	O
2001	O
)	O
run	O
a	O
dynamic	B
program	O
along	O
each	O
of	O
the	O
four	O
tile	O
sides	O
.	O
)	O
to	O
overcome	O
this	O
problem	O
,	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
(	O
2001	O
)	O
observed	O
that	O
,	O
for	O
well-registered	O
images	O
,	O
moving	O
objects	O
produce	O
the	O
most	O
visible	O
artifacts	O
,	O
namely	O
translu-	O
cent	O
looking	O
ghosts	O
.	O
their	O
system	O
therefore	O
decides	O
which	O
objects	O
to	O
keep	O
and	O
which	O
ones	O
to	O
erase	O
.	O
first	O
,	O
the	O
algorithm	B
compares	O
all	O
overlapping	O
input	O
image	B
pairs	O
to	O
determine	O
re-	O
gions	O
of	O
difference	B
(	O
rods	O
)	O
where	O
the	O
images	O
disagree	O
.	O
next	O
,	O
a	O
graph	O
is	O
constructed	O
with	O
the	O
rods	O
as	O
vertices	O
and	O
edges	O
representing	O
rod	O
pairs	B
that	O
overlap	O
in	O
the	O
ﬁnal	O
composite	O
(	O
fig-	O
ure	O
9.15	O
)	O
.	O
since	O
the	O
presence	O
of	O
an	O
edge	O
indicates	O
an	O
area	O
of	O
disagreement	O
,	O
vertices	O
(	O
regions	O
)	O
must	O
be	O
removed	O
from	O
the	O
ﬁnal	O
composite	O
until	O
no	O
edge	O
spans	O
a	O
pair	O
of	O
remaining	O
vertices	O
.	O
the	O
smallest	O
such	O
set	O
can	O
be	O
computed	O
using	O
a	O
vertex	O
cover	O
algorithm	B
.	O
since	O
several	O
such	O
covers	O
may	O
exist	O
,	O
a	O
weighted	B
vertex	O
cover	O
is	O
used	O
instead	O
,	O
where	O
the	O
vertex	O
weights	O
are	O
com-	O
puted	O
by	O
summing	O
the	O
feather	O
weights	O
in	O
the	O
rod	O
(	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
2001	O
)	O
.	O
the	O
algorithm	B
therefore	O
prefers	O
removing	O
regions	O
that	O
are	O
near	O
the	O
edge	O
of	O
the	O
image	B
,	O
which	O
reduces	O
the	O
likelihood	O
that	O
partially	O
visible	O
objects	O
will	O
appear	O
in	O
the	O
ﬁnal	O
composite	O
.	O
(	O
it	O
is	O
9.3	O
compositing	B
457	O
figure	O
9.16	O
photomontage	O
(	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
.	O
from	O
a	O
set	O
of	O
ﬁve	O
source	O
images	O
(	O
of	O
which	O
four	O
are	O
shown	O
on	O
the	O
left	O
)	O
,	O
photomontage	O
quickly	O
creates	O
a	O
composite	O
family	O
portrait	O
in	O
which	O
everyone	O
is	O
smiling	O
and	O
looking	O
at	O
the	O
camera	B
(	O
right	O
)	O
.	O
users	O
simply	O
ﬂip	O
through	O
the	O
stack	O
and	O
coarsely	O
draw	O
strokes	O
using	O
the	O
designated	O
source	O
image	B
objective	O
over	O
the	O
people	O
they	O
wish	O
to	O
add	O
to	O
the	O
composite	O
.	O
the	O
user-applied	O
strokes	O
and	O
computed	O
regions	O
(	O
middle	O
)	O
are	O
color-coded	O
by	O
the	O
borders	O
of	O
the	O
source	O
images	O
on	O
the	O
left	O
.	O
also	O
possible	O
to	O
infer	O
which	O
object	O
in	O
a	O
region	B
of	O
difference	B
is	O
the	O
foreground	O
object	O
by	O
the	O
“	O
edginess	O
”	O
(	O
pixel	O
differences	O
)	O
across	O
the	O
rod	O
boundary	O
,	O
which	O
should	O
be	O
higher	O
when	O
an	O
object	O
is	O
present	O
(	O
herley	O
2005	O
)	O
.	O
)	O
once	O
the	O
desired	O
excess	O
regions	O
of	O
difference	B
have	O
been	O
removed	O
,	O
the	O
ﬁnal	O
composite	O
can	O
be	O
created	O
by	O
feathering	O
(	O
figure	O
9.14f	O
)	O
.	O
a	O
different	O
approach	O
to	O
pixel	B
selection	I
and	O
seam	O
placement	O
is	O
described	O
by	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
.	O
their	O
system	O
computes	O
the	O
label	O
assignment	O
that	O
opti-	O
mizes	O
the	O
sum	O
of	O
two	O
objective	O
functions	O
.	O
the	O
ﬁrst	O
is	O
a	O
per-pixel	O
image	B
objective	O
that	O
deter-	O
mines	O
which	O
pixels	O
are	O
likely	O
to	O
produce	O
good	O
composites	O
,	O
cd	O
=	O
(	O
cid:88	O
)	O
x	O
d	O
(	O
x	O
,	O
l	O
(	O
x	O
)	O
)	O
,	O
(	O
9.41	O
)	O
where	O
d	O
(	O
x	O
,	O
l	O
)	O
is	O
the	O
data	O
penalty	O
associated	O
with	O
choosing	O
image	B
l	O
at	O
pixel	O
x.	O
in	O
their	O
system	O
,	O
users	O
can	O
select	O
which	O
pixels	O
to	O
use	O
by	O
“	O
painting	O
”	O
over	O
an	O
image	B
with	O
the	O
desired	O
object	O
or	O
appearance	O
,	O
which	O
sets	O
d	O
(	O
x	O
,	O
l	O
)	O
to	O
a	O
large	O
value	O
for	O
all	O
labels	O
l	O
other	O
than	O
the	O
one	O
selected	O
by	O
the	O
user	O
(	O
figure	O
9.16	O
)	O
.	O
alternatively	O
,	O
automated	B
selection	O
criteria	O
can	O
be	O
used	O
,	O
such	O
as	O
maximum	O
likelihood	O
,	O
which	O
prefers	O
pixels	O
that	O
occur	O
repeatedly	O
in	O
the	O
background	O
(	O
for	O
object	O
removal	O
)	O
,	O
or	O
minimum	O
likelihood	O
for	O
objects	O
that	O
occur	O
infrequently	O
,	O
i.e.	O
,	O
for	O
moving	O
object	O
retention	O
.	O
using	O
a	O
more	O
traditional	O
center-weighted	O
data	O
term	O
tends	O
to	O
favor	O
objects	O
that	O
are	O
centered	O
in	O
the	O
input	O
images	O
(	O
figure	O
9.17	O
)	O
.	O
the	O
second	O
term	O
is	O
a	O
seam	O
objective	O
that	O
penalizes	O
differences	O
in	O
labelings	O
between	O
adja-	O
cent	O
images	O
,	O
cs	O
=	O
(	O
cid:88	O
)	O
(	O
x	O
,	O
y	O
)	O
∈n	O
s	O
(	O
x	O
,	O
y	O
,	O
l	O
(	O
x	O
)	O
,	O
l	O
(	O
y	O
)	O
)	O
,	O
(	O
9.42	O
)	O
458	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
9.17	O
set	O
of	O
ﬁve	O
photos	O
tracking	O
a	O
snowboarder	O
’	O
s	O
jump	O
stitched	O
together	O
into	O
a	O
seam-	O
less	O
composite	O
.	O
because	O
the	O
algorithm	B
prefers	O
pixels	O
near	O
the	O
center	O
of	O
the	O
image	B
,	O
multiple	B
copies	O
of	O
the	O
boarder	O
are	O
retained	O
.	O
where	O
s	O
(	O
x	O
,	O
y	O
,	O
lx	O
,	O
ly	O
)	O
is	O
the	O
image-dependent	O
interaction	O
penalty	O
or	O
seam	O
cost	O
of	O
placing	O
a	O
seam	O
between	O
pixels	O
x	O
and	O
y	O
,	O
and	O
n	O
is	O
the	O
set	O
of	O
n4	O
neighboring	O
pixels	O
.	O
for	O
example	O
,	O
the	O
simple	O
color-based	O
seam	O
penalty	O
used	O
in	O
(	O
kwatra	O
,	O
sch¨odl	O
,	O
essa	O
et	O
al	O
.	O
2003	O
;	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
can	O
be	O
written	O
as	O
s	O
(	O
x	O
,	O
y	O
,	O
lx	O
,	O
ly	O
)	O
=	O
(	O
cid:107	O
)	O
˜ilx	O
(	O
x	O
)	O
−	O
˜ily	O
(	O
x	O
)	O
(	O
cid:107	O
)	O
+	O
(	O
cid:107	O
)	O
˜ilx	O
(	O
y	O
)	O
−	O
˜ily	O
(	O
y	O
)	O
(	O
cid:107	O
)	O
.	O
(	O
9.43	O
)	O
more	O
sophisticated	O
seam	O
penalties	O
can	O
also	O
look	O
at	O
image	B
gradients	O
or	O
the	O
presence	O
of	O
image	B
edges	O
(	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
.	O
seam	O
penalties	O
are	O
widely	O
used	O
in	O
other	O
computer	O
vision	O
applications	O
such	O
as	O
stereo	B
matching	I
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
to	O
give	O
the	O
labeling	O
function	O
its	O
coherence	O
or	O
smoothness	B
.	O
an	O
alternative	O
approach	O
,	O
which	O
places	O
seams	O
along	O
strong	O
consistent	O
edges	O
in	O
overlapping	O
images	O
using	O
a	O
watershed	B
computation	O
is	O
described	O
by	O
soille	O
(	O
2006	O
)	O
.	O
the	O
sum	O
of	O
these	O
two	O
objective	O
functions	O
gives	O
rise	O
to	O
a	O
markov	O
random	O
ﬁeld	O
(	O
mrf	O
)	O
,	O
for	O
which	O
good	O
optimization	O
algorithms	O
are	O
described	O
in	O
sections	O
3.7.2	O
and	O
5.5	O
and	O
ap-	O
pendix	O
b.5	O
.	O
for	O
label	O
computations	O
of	O
this	O
kind	O
,	O
the	O
α-expansion	O
algorithm	B
developed	O
by	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
(	O
2001	O
)	O
works	O
particularly	O
well	O
(	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
.	O
for	O
the	O
result	O
shown	O
in	O
figure	O
9.14g	O
,	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
use	O
a	O
large	O
data	O
penalty	O
for	O
invalid	O
pixels	O
and	O
0	O
for	O
valid	O
pixels	O
.	O
notice	O
how	O
the	O
seam	O
placement	O
algorithm	B
avoids	O
regions	O
of	O
difference	B
,	O
including	O
those	O
that	O
border	O
the	O
image	B
and	O
that	O
might	O
result	O
in	O
objects	O
being	O
cut	O
off	O
.	O
graph	B
cuts	I
(	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
2004	O
)	O
and	O
9.3	O
compositing	B
459	O
vertex	O
cover	O
(	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
2001	O
)	O
often	O
produce	O
similar	O
looking	O
results	O
,	O
although	O
the	O
former	O
is	O
signiﬁcantly	O
slower	O
since	O
it	O
optimizes	O
over	O
all	O
pixels	O
,	O
while	O
the	O
latter	O
is	O
more	O
sensitive	O
to	O
the	O
thresholds	O
used	O
to	O
determine	O
regions	O
of	O
difference	B
.	O
9.3.3	O
application	O
:	O
photomontage	O
while	O
image	B
stitching	I
is	O
normally	O
used	O
to	O
composite	O
partially	O
overlapping	O
photographs	O
,	O
it	O
can	O
also	O
be	O
used	O
to	O
composite	O
repeated	O
shots	O
of	O
a	O
scene	O
taken	O
with	O
the	O
aim	O
of	O
obtaining	O
the	O
best	O
possible	O
composition	O
and	O
appearance	O
of	O
each	O
element	O
.	O
figure	O
9.16	O
shows	O
the	O
photomontage	O
system	O
developed	O
by	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
,	O
where	O
users	O
draw	O
strokes	O
over	O
a	O
set	O
of	O
pre-aligned	O
images	O
to	O
indicate	O
which	O
re-	O
gions	O
they	O
wish	O
to	O
keep	O
from	O
each	O
image	B
.	O
once	O
the	O
system	O
solves	O
the	O
resulting	O
multi-label	O
graph	B
cut	I
(	O
9.41–9.42	O
)	O
,	O
the	O
various	O
pieces	O
taken	O
from	O
each	O
source	O
photo	O
are	O
blended	O
together	O
using	O
a	O
variant	O
of	O
poisson	O
image	B
blending	O
(	O
9.44–9.46	O
)	O
.	O
their	O
system	O
can	O
also	O
be	O
used	O
to	O
au-	O
tomatically	O
composite	O
an	O
all-focus	O
image	B
from	O
a	O
series	O
of	O
bracketed	O
focus	B
images	O
(	O
hasinoff	O
,	O
kutulakos	O
,	O
durand	O
et	O
al	O
.	O
2009	O
)	O
or	O
to	O
remove	O
wires	O
and	O
other	O
unwanted	O
elements	O
from	O
sets	O
of	O
photographs	O
.	O
exercise	O
9.10	O
has	O
you	O
implement	O
this	O
system	O
and	O
try	O
out	O
some	O
of	O
its	O
variants	O
.	O
9.3.4	O
blending	B
once	O
the	O
seams	O
between	O
images	O
have	O
been	O
determined	O
and	O
unwanted	O
objects	O
removed	O
,	O
we	O
still	O
need	O
to	O
blend	O
the	O
images	O
to	O
compensate	O
for	O
exposure	O
differences	O
and	O
other	O
mis-alignments	O
.	O
the	O
spatially	O
varying	O
weighting	O
(	O
feathering	B
)	O
previously	O
discussed	O
can	O
often	O
be	O
used	O
to	O
accom-	O
plish	O
this	O
.	O
however	O
,	O
it	O
is	O
difﬁcult	O
in	O
practice	O
to	O
achieve	O
a	O
pleasing	O
balance	B
between	O
smoothing	B
out	O
low-frequency	O
exposure	O
variations	O
and	O
retaining	O
sharp	O
enough	O
transitions	O
to	O
prevent	O
blur-	O
ring	O
(	O
although	O
using	O
a	O
high	O
exponent	O
in	O
feathering	B
can	O
help	O
)	O
.	O
laplacian	O
pyramid	B
blending	O
.	O
an	O
attractive	O
solution	O
to	O
this	O
problem	O
is	O
the	O
laplacian	O
pyra-	O
mid	O
blending	B
technique	O
developed	O
by	O
burt	O
and	O
adelson	O
(	O
1983b	O
)	O
,	O
which	O
we	O
discussed	O
in	O
sec-	O
tion	B
3.5.5.	O
instead	O
of	O
using	O
a	O
single	O
transition	O
width	O
,	O
a	O
frequency-adaptive	O
width	O
is	O
used	O
by	O
creating	O
a	O
band-pass	B
(	O
laplacian	O
)	O
pyramid	B
and	O
making	O
the	O
transition	O
widths	O
within	O
each	O
level	O
a	O
function	O
of	O
the	O
level	O
,	O
i.e.	O
,	O
the	O
same	O
width	O
in	O
pixels	O
.	O
in	O
practice	O
,	O
a	O
small	O
number	O
of	O
levels	O
,	O
i.e.	O
,	O
as	O
few	O
as	O
two	O
(	O
brown	O
and	O
lowe	O
2007	O
)	O
,	O
may	O
be	O
adequate	O
to	O
compensate	O
for	O
differences	O
in	O
exposure	O
.	O
the	O
result	O
of	O
applying	O
this	O
pyramid	B
blending	O
is	O
shown	O
in	O
figure	O
9.14h	O
.	O
gradient	B
domain	I
blending	O
.	O
an	O
alternative	O
approach	O
to	O
multi-band	O
image	B
blending	O
is	O
to	O
perform	O
the	O
operations	O
in	O
the	O
gradient	B
domain	I
.	O
reconstructing	O
images	O
from	O
their	O
gradient	O
ﬁelds	O
has	O
a	O
long	O
history	O
in	O
computer	O
vision	O
(	O
horn	O
1986	O
)	O
,	O
starting	O
originally	O
with	O
work	O
in	O
460	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
9.18	O
poisson	O
image	B
editing	O
(	O
p´erez	O
,	O
gangnet	O
,	O
and	O
blake	O
2003	O
)	O
c	O
(	O
cid:13	O
)	O
2003	O
acm	O
:	O
(	O
a	O
)	O
the	O
dog	O
and	O
the	O
two	O
children	O
are	O
chosen	O
as	O
source	O
images	O
to	O
be	O
pasted	O
into	O
the	O
destination	O
swimming	O
pool	O
.	O
(	O
b	O
)	O
simple	O
pasting	O
fails	O
to	O
match	O
the	O
colors	O
at	O
the	O
boundaries	O
,	O
whereas	O
(	O
c	O
)	O
poisson	O
image	B
blending	O
masks	O
these	O
differences	O
.	O
brightness	O
constancy	O
(	O
horn	O
1974	O
)	O
,	O
shape	O
from	O
shading	B
(	O
horn	O
and	O
brooks	O
1989	O
)	O
,	O
and	O
photo-	O
metric	O
stereo	B
(	O
woodham	O
1981	O
)	O
.	O
more	O
recently	O
,	O
related	O
ideas	O
have	O
been	O
used	O
for	O
reconstruct-	O
ing	O
images	O
from	O
their	O
edges	O
(	O
elder	O
and	O
goldberg	O
2001	O
)	O
,	O
removing	O
shadows	O
from	O
images	O
(	O
weiss	O
2001	O
)	O
,	O
separating	O
reﬂections	B
from	O
a	O
single	O
image	O
(	O
levin	O
,	O
zomet	O
,	O
and	O
weiss	O
2004	O
;	O
levin	O
and	O
weiss	O
2007	O
)	O
,	O
and	O
tone	B
mapping	I
high	O
dynamic	B
range	O
images	O
by	O
reducing	O
the	O
mag-	O
nitude	O
of	O
image	B
edges	O
(	O
gradients	O
)	O
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
)	O
.	O
p´erez	O
,	O
gangnet	O
,	O
and	O
blake	O
(	O
2003	O
)	O
show	O
how	O
gradient	B
domain	I
reconstruction	O
can	O
be	O
used	O
to	O
do	O
seamless	O
object	O
insertion	O
in	O
image	B
editing	O
applications	O
(	O
figure	O
9.18	O
)	O
.	O
rather	O
than	O
copy-	O
ing	O
pixels	O
,	O
the	O
gradients	O
of	O
the	O
new	O
image	B
fragment	O
are	O
copied	O
instead	O
.	O
the	O
actual	O
pixel	O
values	O
for	O
the	O
copied	O
area	O
are	O
then	O
computed	O
by	O
solving	O
a	O
poisson	O
equation	B
that	O
locally	O
matches	O
the	O
gradients	O
while	O
obeying	O
the	O
ﬁxed	O
dirichlet	O
(	O
exact	O
matching	B
)	O
conditions	O
at	O
the	O
seam	O
bound-	O
ary	O
.	O
p´erez	O
,	O
gangnet	O
,	O
and	O
blake	O
(	O
2003	O
)	O
show	O
that	O
this	O
is	O
equivalent	O
to	O
computing	O
an	O
additive	O
membrane	O
interpolant	O
of	O
the	O
mismatch	O
between	O
the	O
source	O
and	O
destination	O
images	O
along	O
the	O
boundary.14	O
in	O
earlier	O
work	O
,	O
peleg	O
(	O
1981	O
)	O
also	O
proposed	O
adding	O
a	O
smooth	O
function	O
to	O
enforce	O
consistency	O
along	O
the	O
seam	O
curve	O
.	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
extended	O
this	O
idea	O
to	O
a	O
multi-source	O
formu-	O
lation	O
,	O
where	O
it	O
no	O
longer	O
makes	O
sense	O
to	O
talk	O
of	O
a	O
destination	O
image	B
whose	O
exact	O
pixel	O
values	O
must	O
be	O
matched	O
at	O
the	O
seam	O
.	O
instead	O
,	O
each	O
source	O
image	B
contributes	O
its	O
own	O
gradient	O
ﬁeld	O
and	O
the	O
poisson	O
equation	B
is	O
solved	O
using	O
neumann	O
boundary	O
conditions	O
,	O
i.e.	O
,	O
dropping	O
any	O
equations	B
that	O
involve	O
pixels	O
outside	O
the	O
boundary	O
of	O
the	O
image	B
.	O
14	O
the	O
membrane	O
interpolant	O
is	O
known	O
to	O
have	O
nicer	O
interpolation	B
properties	O
for	O
arbitrary-shaped	O
constraints	O
than	O
frequency-domain	O
interpolants	O
(	O
nielson	O
1993	O
)	O
.	O
9.3	O
compositing	B
461	O
rather	O
than	O
solving	O
the	O
poisson	O
partial	O
differential	O
equations	B
,	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
directly	O
minimize	O
a	O
variational	O
problem	O
,	O
c	O
(	O
x	O
)	O
(	O
cid:107	O
)	O
∇c	O
(	O
x	O
)	O
−	O
∇˜il	O
(	O
x	O
)	O
(	O
x	O
)	O
(	O
cid:107	O
)	O
2.	O
min	O
the	O
discretized	O
form	O
of	O
this	O
equation	B
is	O
a	O
set	O
of	O
gradient	O
constraint	O
equations	B
(	O
9.44	O
)	O
(	O
9.45	O
)	O
(	O
9.46	O
)	O
c	O
(	O
x	O
+	O
ˆı	O
)	O
−	O
c	O
(	O
x	O
)	O
=	O
˜il	O
(	O
x	O
)	O
(	O
x	O
+	O
ˆı	O
)	O
−	O
˜il	O
(	O
x	O
)	O
(	O
x	O
)	O
and	O
c	O
(	O
x	O
+	O
ˆ	O
)	O
−	O
c	O
(	O
x	O
)	O
=	O
˜il	O
(	O
x	O
)	O
(	O
x	O
+	O
ˆ	O
)	O
−	O
˜il	O
(	O
x	O
)	O
(	O
x	O
)	O
,	O
where	O
ˆı	O
=	O
(	O
1	O
,	O
0	O
)	O
and	O
ˆ	O
=	O
(	O
0	O
,	O
1	O
)	O
are	O
unit	O
vectors	O
in	O
the	O
x	O
and	O
y	O
directions.15	O
they	O
then	O
solve	O
the	O
associated	O
sparse	B
least	O
squares	O
problem	O
.	O
since	O
this	O
system	O
of	O
equations	B
is	O
only	O
deﬁned	O
up	O
to	O
an	O
additive	O
constraint	B
,	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
ask	O
the	O
user	O
to	O
select	O
the	O
value	O
of	O
one	O
pixel	O
.	O
in	O
practice	O
,	O
a	O
better	O
choice	O
might	O
be	O
to	O
weakly	O
bias	O
the	O
solution	O
towards	O
reproducing	O
the	O
original	O
color	B
values	O
.	O
in	O
order	B
to	O
accelerate	O
the	O
solution	O
of	O
this	O
sparse	B
linear	O
system	O
,	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
(	O
2002	O
)	O
use	O
multigrid	O
,	O
whereas	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
use	O
hierarchical	B
basis	O
preconditioned	B
conjugate	O
gradient	B
descent	I
(	O
szeliski	O
1990b	O
,	O
2006b	O
)	O
(	O
ap-	O
pendix	O
a.5	O
)	O
.	O
in	O
subsequent	O
work	O
,	O
agarwala	O
(	O
2007	O
)	O
shows	O
how	O
using	O
a	O
quadtree	B
represen-	O
tation	O
for	O
the	O
solution	O
can	O
further	O
accelerate	O
the	O
computation	O
with	O
minimal	O
loss	O
in	O
accuracy	B
,	O
while	O
szeliski	O
,	O
uyttendaele	O
,	O
and	O
steedly	O
(	O
2008	O
)	O
show	O
how	O
representing	O
the	O
per-image	O
offset	O
ﬁelds	O
using	O
even	O
coarser	O
splines	B
is	O
even	O
faster	O
.	O
this	O
latter	O
work	O
also	O
argues	O
that	O
blending	B
in	O
the	O
log	O
domain	O
,	O
i.e.	O
,	O
using	O
multiplicative	O
rather	O
than	O
additive	O
offsets	O
,	O
is	O
preferable	O
,	O
as	O
it	O
more	O
closely	O
matches	O
texture	B
contrasts	O
across	O
seam	O
boundaries	O
.	O
the	O
resulting	O
seam	O
blending	O
works	O
very	O
well	O
in	O
practice	O
(	O
figure	O
9.14h	O
)	O
,	O
although	O
care	O
must	O
be	O
taken	O
when	O
copying	O
large	O
gradient	O
values	O
near	O
seams	O
so	O
that	O
a	O
“	O
double	O
edge	O
”	O
is	O
not	O
introduced	O
.	O
copying	O
gradients	O
directly	O
from	O
the	O
source	O
images	O
after	O
seam	O
placement	O
is	O
just	O
one	O
ap-	O
proach	O
to	O
gradient	B
domain	I
blending	O
.	O
the	O
paper	O
by	O
levin	O
,	O
zomet	O
,	O
peleg	O
et	O
al	O
.	O
(	O
2004	O
)	O
examines	O
several	O
different	O
variants	O
of	O
this	O
approach	O
,	O
which	O
they	O
call	O
gradient-domain	O
image	B
stitching	I
(	O
gist	B
)	O
.	O
the	O
techniques	O
they	O
examine	O
include	O
feathering	B
(	O
blending	B
)	O
the	O
gradients	O
from	O
the	O
source	O
images	O
,	O
as	O
well	O
as	O
using	O
an	O
l1	O
norm	O
in	O
performing	O
the	O
reconstruction	O
of	O
the	O
image	B
from	O
the	O
gradient	O
ﬁeld	O
,	O
rather	O
than	O
using	O
an	O
l2	O
norm	O
as	O
in	O
equation	B
(	O
9.44	O
)	O
.	O
their	O
preferred	O
technique	O
is	O
the	O
l1	O
optimization	O
of	O
a	O
feathered	O
(	O
blended	O
)	O
cost	O
function	O
on	O
the	O
original	O
image	B
gradients	O
(	O
which	O
they	O
call	O
gist1-l1	O
)	O
.	O
since	O
l1	O
optimization	O
using	O
linear	O
programming	O
can	O
be	O
slow	O
,	O
they	O
develop	O
a	O
faster	O
iterative	B
median-based	O
algorithm	B
in	O
a	O
multigrid	O
framework	O
.	O
visual	O
comparisons	O
between	O
their	O
preferred	O
approach	O
and	O
what	O
they	O
call	O
optimal	O
seam	O
on	O
the	O
gradients	O
(	O
which	O
is	O
equivalent	O
to	O
the	O
approach	O
of	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
)	O
show	O
similar	O
results	O
,	O
while	O
signiﬁcantly	O
improving	O
on	O
pyramid	B
blending	O
and	O
feather-	O
ing	O
algorithms	O
.	O
15	O
at	O
seam	O
locations	O
,	O
the	O
right	O
hand	O
side	O
is	O
replaced	O
by	O
the	O
average	O
of	O
the	O
gradients	O
in	O
the	O
two	O
source	O
images	O
.	O
462	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
exposure	B
compensation	I
.	O
pyramid	B
and	O
gradient	B
domain	I
blending	O
can	O
do	O
a	O
good	O
job	O
of	O
compensating	O
for	O
moderate	O
amounts	O
of	O
exposure	O
differences	O
between	O
images	O
.	O
however	O
,	O
when	O
the	O
exposure	O
differences	O
become	O
large	O
,	O
alternative	O
approaches	O
may	O
be	O
necessary	O
.	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
(	O
2001	O
)	O
iteratively	O
estimate	O
a	O
local	B
correction	O
between	O
each	O
source	O
image	B
and	O
a	O
blended	O
composite	O
.	O
first	O
,	O
a	O
block-based	O
quadratic	O
transfer	B
function	O
is	O
ﬁt	O
between	O
each	O
source	O
image	B
and	O
an	O
initial	O
feathered	O
composite	O
.	O
next	O
,	O
transfer	B
functions	O
are	O
averaged	O
with	O
their	O
neighbors	O
to	O
get	O
a	O
smoother	O
mapping	O
and	O
per-pixel	O
transfer	B
functions	O
are	O
computed	O
by	O
splining	O
(	O
interpolating	O
)	O
between	O
neighboring	O
block	O
values	O
.	O
once	O
each	O
source	O
image	B
has	O
been	O
smoothly	O
adjusted	O
,	O
a	O
new	O
feathered	O
composite	O
is	O
computed	O
and	O
the	O
process	O
is	O
repeated	O
(	O
typically	O
three	O
times	O
)	O
.	O
the	O
results	O
shown	O
by	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
(	O
2001	O
)	O
demonstrate	O
that	O
this	O
does	O
a	O
better	O
job	O
of	O
exposure	B
compensation	I
than	O
simple	O
feathering	B
and	O
can	O
handle	O
local	B
variations	O
in	O
exposure	O
due	O
to	O
effects	O
such	O
as	O
lens	O
vignetting	B
.	O
ultimately	O
,	O
however	O
,	O
the	O
most	O
principled	O
way	O
to	O
deal	O
with	O
exposure	O
differences	O
is	O
to	O
stitch	O
images	O
in	O
the	O
radiance	O
domain	O
,	O
i.e.	O
,	O
to	O
convert	O
each	O
image	B
into	O
a	O
radiance	O
image	B
using	O
its	O
exposure	O
value	O
and	O
then	O
create	O
a	O
stitched	O
,	O
high	B
dynamic	I
range	I
image	O
,	O
as	O
discussed	O
in	O
sec-	O
tion	B
10.2	O
(	O
eden	O
,	O
uyttendaele	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
9.4	O
additional	O
reading	O
the	O
literature	O
on	O
image	B
stitching	I
dates	O
back	O
to	O
work	O
in	O
the	O
photogrammetry	B
community	O
in	O
the	O
1970s	O
(	O
milgram	O
1975	O
,	O
1977	O
;	O
slama	O
1980	O
)	O
.	O
in	O
computer	O
vision	O
,	O
papers	O
started	O
appearing	O
in	O
the	O
early	O
1980s	O
(	O
peleg	O
1981	O
)	O
,	O
while	O
the	O
development	O
of	O
fully	O
automated	B
techniques	O
came	O
about	O
a	O
decade	O
later	O
(	O
mann	O
and	O
picard	O
1994	O
;	O
chen	O
1995	O
;	O
szeliski	O
1996	O
;	O
szeliski	O
and	O
shum	O
1997	O
;	O
sawhney	O
and	O
kumar	O
1999	O
;	O
shum	O
and	O
szeliski	O
2000	O
)	O
.	O
those	O
techniques	O
used	O
direct	B
pixel-based	O
alignment	B
but	O
feature-based	B
approaches	O
are	O
now	O
the	O
norm	O
(	O
zoghlami	O
,	O
faugeras	O
,	O
and	O
deriche	O
1997	O
;	O
capel	O
and	O
zisserman	O
1998	O
;	O
cham	O
and	O
cipolla	O
1998	O
;	O
badra	O
,	O
qumsieh	O
,	O
and	O
dudek	O
1998	O
;	O
mclauchlan	O
and	O
jaenicke	O
2002	O
;	O
brown	O
and	O
lowe	O
2007	O
)	O
.	O
a	O
collection	O
of	O
some	O
of	O
these	O
papers	O
can	O
be	O
found	O
in	O
the	O
book	O
by	O
benosman	O
and	O
kang	O
(	O
2001	O
)	O
.	O
szeliski	O
(	O
2006a	O
)	O
provides	O
a	O
comprehensive	O
survey	O
of	O
image	B
stitching	I
,	O
on	O
which	O
the	O
material	O
in	O
this	O
chapter	O
is	O
based	O
.	O
high-quality	O
techniques	O
for	O
optimal	O
seam	O
ﬁnding	O
and	O
blending	B
are	O
another	O
important	O
component	O
of	O
image	B
stitching	I
systems	O
.	O
important	O
developments	O
in	O
this	O
ﬁeld	O
include	O
work	O
by	O
milgram	O
(	O
1977	O
)	O
,	O
burt	O
and	O
adelson	O
(	O
1983b	O
)	O
,	O
davis	O
(	O
1998	O
)	O
,	O
uyttendaele	O
,	O
eden	O
,	O
and	O
szeliski	O
(	O
2001	O
)	O
,	O
p´erez	O
,	O
gangnet	O
,	O
and	O
blake	O
(	O
2003	O
)	O
,	O
levin	O
,	O
zomet	O
,	O
peleg	O
et	O
al	O
.	O
(	O
2004	O
)	O
,	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
,	O
eden	O
,	O
uyttendaele	O
,	O
and	O
szeliski	O
(	O
2006	O
)	O
,	O
and	O
kopf	O
,	O
uyt-	O
tendaele	O
,	O
deussen	O
et	O
al	O
.	O
(	O
2007	O
)	O
.	O
in	O
addition	O
to	O
the	O
merging	B
of	O
multiple	B
overlapping	O
photographs	O
taken	O
for	O
aerial	O
or	O
ter-	O
9.5	O
exercises	O
463	O
restrial	O
panoramic	O
image	B
creation	O
,	O
stitching	O
techniques	O
can	O
be	O
used	O
for	O
automated	O
white-	O
board	O
scanning	O
(	O
he	O
and	O
zhang	O
2005	O
;	O
zhang	O
and	O
he	O
2007	O
)	O
,	O
scanning	O
with	O
a	O
mouse	O
(	O
nakao	O
,	O
kashitani	O
,	O
and	O
kaneyoshi	O
1998	O
)	O
,	O
and	O
retinal	O
image	B
mosaics	O
(	O
can	O
,	O
stewart	O
,	O
roysam	O
et	O
al	O
.	O
2002	O
)	O
.	O
they	O
can	O
also	O
be	O
applied	O
to	O
video	B
sequences	O
(	O
teodosio	O
and	O
bender	O
1993	O
;	O
irani	O
,	O
hsu	O
,	O
and	O
anandan	O
1995	O
;	O
kumar	O
,	O
anandan	O
,	O
irani	O
et	O
al	O
.	O
1995	O
;	O
sawhney	O
and	O
ayer	O
1996	O
;	O
massey	O
and	O
bender	O
1996	O
;	O
irani	O
and	O
anandan	O
1998	O
;	O
sawhney	O
,	O
arpa	O
,	O
kumar	O
et	O
al	O
.	O
2002	O
;	O
agarwala	O
,	O
zheng	O
,	O
pal	O
et	O
al	O
.	O
2005	O
;	O
rav-acha	O
,	O
pritch	O
,	O
lischinski	O
et	O
al	O
.	O
2005	O
;	O
steedly	O
,	O
pal	O
,	O
and	O
szeliski	O
2005	O
;	O
baudisch	O
,	O
tan	O
,	O
steedly	O
et	O
al	O
.	O
2006	O
)	O
and	O
can	O
even	O
be	O
used	O
for	O
video	O
compression	B
(	O
lee	O
,	O
ge	O
chen	O
,	O
lung	O
bruce	O
lin	O
et	O
al	O
.	O
1997	O
)	O
.	O
9.5	O
exercises	O
ex	O
9.1	O
:	O
direct	B
pixel-based	O
alignment	B
take	O
a	O
pair	O
of	O
images	O
,	O
compute	O
a	O
coarse-to-ﬁne	B
afﬁne	O
alignment	B
(	O
exercise	O
8.2	O
)	O
and	O
then	O
blend	O
them	O
using	O
either	O
averaging	O
(	O
exercise	O
6.2	O
)	O
or	O
a	O
lapla-	O
cian	O
pyramid	B
(	O
exercise	O
3.20	O
)	O
.	O
extend	O
your	O
motion	B
model	O
from	O
afﬁne	B
to	O
perspective	B
(	O
homog-	O
raphy	O
)	O
to	O
better	O
deal	O
with	O
rotational	O
mosaics	O
and	O
planar	O
surfaces	O
seen	O
under	O
arbitrary	O
motion	B
.	O
ex	O
9.2	O
:	O
featured-based	O
stitching	O
extend	O
your	O
feature-based	B
alignment	O
technique	O
from	O
ex-	O
ercise	O
6.2	O
to	O
use	O
a	O
full	O
perspective	B
model	O
and	O
then	O
blend	O
the	O
resulting	O
mosaic	O
using	O
either	O
averaging	O
or	O
more	O
sophisticated	O
distance-based	O
feathering	B
(	O
exercise	O
9.9	O
)	O
.	O
ex	O
9.3	O
:	O
cylindrical	B
strip	O
panoramas	O
to	O
generate	O
cylindrical	B
or	O
spherical	B
panoramas	O
from	O
a	O
horizontally	O
panning	O
(	O
rotating	O
)	O
camera	B
,	O
it	O
is	O
best	O
to	O
use	O
a	O
tripod	O
.	O
set	O
your	O
camera	B
up	O
to	O
take	O
a	O
series	O
of	O
50	O
%	O
overlapped	O
photos	O
and	O
then	O
use	O
the	O
following	O
steps	O
to	O
create	O
your	O
panorama	O
:	O
1.	O
estimate	O
the	O
amount	O
of	O
radial	B
distortion	I
by	O
taking	O
some	O
pictures	O
with	O
lots	O
of	O
long	O
straight	O
lines	B
near	O
the	O
edges	O
of	O
the	O
image	B
and	O
then	O
using	O
the	O
plumb-line	B
method	I
from	O
exercise	O
6.10	O
.	O
2.	O
compute	O
the	O
focal	O
length	O
either	O
by	O
using	O
a	O
ruler	O
and	O
paper	O
,	O
as	O
in	O
figure	O
6.7	O
(	O
debevec	O
,	O
wenger	O
,	O
tchou	O
et	O
al	O
.	O
2002	O
)	O
or	O
by	O
rotating	O
your	O
camera	B
on	O
the	O
tripod	O
,	O
overlapping	O
the	O
images	O
by	O
exactly	O
0	O
%	O
and	O
counting	O
the	O
number	O
of	O
images	O
it	O
takes	O
to	O
make	O
a	O
360◦	O
panorama	O
.	O
3.	O
convert	O
each	O
of	O
your	O
images	O
to	O
cylindrical	B
coordinates	O
using	O
(	O
9.12–9.16	O
)	O
.	O
4.	O
line	O
up	O
the	O
images	O
with	O
a	O
translational	B
motion	O
model	O
using	O
either	O
a	O
direct	B
pixel-based	O
technique	O
,	O
such	O
as	O
coarse-to-ﬁne	B
incremental	O
or	O
an	O
fft	O
,	O
or	O
a	O
feature-based	B
technique	O
.	O
5	O
.	O
(	O
optional	O
)	O
if	O
doing	O
a	O
complete	O
360◦	O
panorama	O
,	O
align	O
the	O
ﬁrst	O
and	O
last	O
images	O
.	O
compute	O
the	O
amount	O
of	O
accumulated	O
vertical	O
mis-registration	O
and	O
re-distribute	O
this	O
among	O
the	O
images	O
.	O
464	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
6.	O
blend	O
the	O
resulting	O
images	O
using	O
feathering	O
or	O
some	O
other	O
technique	O
.	O
ex	O
9.4	O
:	O
coarse	O
alignment	B
use	O
fft	O
or	O
phase	B
correlation	I
(	O
section	O
8.1.2	O
)	O
to	O
estimate	O
the	O
initial	O
alignment	B
between	O
successive	O
images	O
.	O
how	O
well	O
does	O
this	O
work	O
?	O
over	O
what	O
range	O
of	O
overlaps	O
?	O
if	O
it	O
does	O
not	O
work	O
,	O
does	O
aligning	O
sub-sections	O
(	O
e.g.	O
,	O
quarters	O
)	O
do	O
better	O
?	O
ex	O
9.5	O
:	O
automated	B
mosaicing	O
use	O
feature-based	B
alignment	O
with	O
four-point	O
ransac	O
for	O
homographies	O
(	O
section	O
6.1.3	O
,	O
equations	B
(	O
6.19–6.23	O
)	O
)	O
or	O
three-point	O
ransac	O
for	O
rotational	O
motions	O
(	O
brown	O
,	O
hartley	O
,	O
and	O
nist´er	O
2007	O
)	O
to	O
match	O
up	O
all	O
pairs	B
of	O
overlapping	O
images	O
.	O
merge	O
these	O
pairwise	O
estimates	O
together	O
by	O
ﬁnding	O
a	O
spanning	O
tree	O
of	O
pairwise	O
relations	O
.	O
visualize	O
the	O
resulting	O
global	B
alignment	I
,	O
e.g.	O
,	O
by	O
displaying	O
a	O
blend	O
of	O
each	O
image	B
with	O
all	O
other	O
images	O
that	O
overlap	O
it	O
.	O
for	O
greater	O
robustness	O
,	O
try	O
multiple	B
spanning	O
trees	O
(	O
perhaps	O
randomly	O
sampled	O
based	O
on	O
the	O
conﬁdence	O
in	O
pairwise	O
alignments	O
)	O
to	O
see	O
if	O
you	O
can	O
recover	O
from	O
bad	O
pairwise	O
matches	O
(	O
zach	O
,	O
klopschitz	O
,	O
and	O
pollefeys	O
2010	O
)	O
.	O
as	O
a	O
measure	O
of	O
ﬁtness	O
,	O
count	O
how	O
many	O
pairwise	O
estimates	O
are	O
consistent	O
with	O
the	O
global	B
alignment	I
.	O
ex	O
9.6	O
:	O
global	B
optimization	I
use	O
the	O
initialization	B
from	O
the	O
previous	O
algorithm	B
to	O
perform	O
a	O
full	O
bundle	B
adjustment	I
over	O
all	O
of	O
the	O
camera	B
rotations	O
and	O
focal	O
lengths	O
,	O
as	O
described	O
in	O
section	O
7.4	O
and	O
by	O
shum	O
and	O
szeliski	O
(	O
2000	O
)	O
.	O
optionally	O
,	O
estimate	O
radial	B
distortion	I
parame-	O
ters	O
as	O
well	O
or	O
support	O
ﬁsheye	O
lenses	O
(	O
section	O
2.1.6	O
)	O
.	O
as	O
in	O
the	O
previous	O
exercise	O
,	O
visualize	O
the	O
quality	O
of	O
your	O
registration	B
by	O
creating	O
compos-	O
ites	O
of	O
each	O
input	O
image	B
with	O
its	O
neighbors	O
,	O
optionally	O
blinking	O
between	O
the	O
original	O
image	B
and	O
the	O
composite	O
to	O
better	O
see	O
mis-alignment	O
artifacts	O
.	O
ex	O
9.7	O
:	O
de-ghosting	B
use	O
the	O
results	O
of	O
the	O
previous	O
bundle	B
adjustment	I
to	O
predict	O
the	O
loca-	O
tion	B
of	O
each	O
feature	B
in	O
a	O
consensus	O
geometry	O
.	O
use	O
the	O
difference	B
between	O
the	O
predicted	O
and	O
actual	O
feature	B
locations	O
to	O
correct	O
for	O
small	O
mis-registrations	O
,	O
as	O
described	O
in	O
section	O
9.2.2	O
(	O
shum	O
and	O
szeliski	O
2000	O
)	O
.	O
ex	O
9.8	O
:	O
compositing	B
surface	O
choose	O
a	O
compositing	B
surface	O
(	O
section	O
9.3.1	O
)	O
,	O
e.g.	O
,	O
a	O
single	O
reference	O
image	B
extended	O
to	O
a	O
larger	O
plane	O
,	O
a	O
sphere	O
represented	O
using	O
cylindrical	O
or	O
spherical	B
coordinates	O
,	O
a	O
stereographic	O
“	O
little	O
planet	O
”	O
projection	O
,	O
or	O
a	O
cube	B
map	I
.	O
project	O
all	O
of	O
your	O
images	O
onto	O
this	O
surface	B
and	O
blend	O
them	O
with	O
equal	O
weighting	B
,	O
for	O
now	O
(	O
just	O
to	O
see	O
where	O
the	O
original	O
image	B
seams	O
are	O
)	O
.	O
ex	O
9.9	O
:	O
feathering	B
and	O
blending	B
compute	O
a	O
feather	O
(	O
distance	O
)	O
map	O
for	O
each	O
warped	O
source	O
image	B
and	O
use	O
these	O
maps	O
to	O
blend	O
the	O
warped	O
images	O
.	O
alternatively	O
,	O
use	O
laplacian	O
pyramid	B
blending	O
(	O
exercise	O
3.20	O
)	O
or	O
gradient	B
domain	I
blend-	O
ing	O
.	O
9.5	O
exercises	O
465	O
ex	O
9.10	O
:	O
photomontage	O
and	O
object	O
removal	O
users	O
can	O
indicate	O
desired	O
or	O
unwanted	O
regions	O
in	O
pre-registered	O
images	O
using	O
strokes	O
or	O
other	O
primitives	O
(	O
such	O
as	O
bounding	O
boxes	O
)	O
.	O
implement	O
a	O
“	O
photomontage	O
”	O
system	O
in	O
which	O
(	O
optional	O
)	O
devise	O
an	O
automatic	B
moving	O
objects	O
remover	O
(	O
or	O
“	O
keeper	O
”	O
)	O
by	O
analyzing	O
which	O
inconsistent	O
regions	O
are	O
more	O
or	O
less	O
typical	O
given	O
some	O
consensus	O
(	O
e.g.	O
,	O
median	B
ﬁltering	O
)	O
of	O
the	O
aligned	O
images	O
.	O
figure	O
9.17	O
shows	O
an	O
example	O
where	O
the	O
moving	O
object	O
was	O
kept	O
.	O
try	O
to	O
make	O
this	O
work	O
for	O
sequences	O
with	O
large	O
amounts	O
of	O
overlaps	O
and	O
consider	O
averaging	O
the	O
images	O
to	O
make	O
the	O
moving	O
object	O
look	O
more	O
ghosted	O
.	O
466	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
chapter	O
10	O
computational	O
photography	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.2.1	O
tone	B
mapping	I
.	O
.	O
10.2.2	O
application	O
:	O
flash	O
photography	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.3.1	O
color	B
image	O
demosaicing	B
.	O
10.3.2	O
application	O
:	O
colorization	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.1	O
photometric	B
calibration	O
.	O
10.3	O
super-resolution	O
and	O
blur	B
removal	I
10.2	O
high	B
dynamic	I
range	I
imaging	O
.	O
.	O
.	O
.	O
.	O
10.1.1	O
radiometric	B
response	O
function	O
.	O
.	O
10.1.2	O
noise	B
level	O
estimation	B
.	O
.	O
10.1.3	O
vignetting	B
.	O
.	O
.	O
.	O
10.1.4	O
optical	B
blur	I
(	O
spatial	O
response	O
)	O
estimation	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.5.1	O
application	O
:	O
hole	B
ﬁlling	I
and	O
inpainting	B
.	O
.	O
10.5.2	O
application	O
:	O
non-photorealistic	B
rendering	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10.4	O
image	B
matting	O
and	O
compositing	B
.	O
.	O
.	O
.	O
10.4.1	O
blue	B
screen	I
matting	O
.	O
.	O
10.4.2	O
natural	B
image	O
matting	B
.	O
.	O
10.4.3	O
optimization-based	B
matting	O
.	O
.	O
10.4.4	O
smoke	B
,	O
shadow	B
,	O
and	O
ﬂash	B
matting	O
.	O
10.4.5	O
video	B
matting	O
.	O
.	O
.	O
.	O
10.5	O
texture	B
analysis	O
and	O
synthesis	O
10.6	O
additional	O
reading	O
.	O
.	O
10.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
470	O
.	O
470	O
.	O
.	O
.	O
473	O
.	O
474	O
.	O
.	O
476	O
.	O
.	O
.	O
479	O
.	O
487	O
.	O
.	O
494	O
.	O
.	O
497	O
.	O
.	O
.	O
502	O
.	O
504	O
.	O
.	O
505	O
.	O
.	O
.	O
507	O
.	O
509	O
.	O
.	O
513	O
.	O
.	O
516	O
.	O
.	O
.	O
518	O
.	O
518	O
.	O
.	O
521	O
.	O
.	O
522	O
.	O
.	O
.	O
524	O
.	O
526	O
.	O
468	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
10.1	O
computational	O
photography	O
:	O
(	O
a	O
)	O
merging	B
multiple	O
exposures	O
to	O
create	O
high	B
dynamic	I
range	I
images	O
(	O
debevec	O
and	O
malik	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
;	O
(	O
b	O
)	O
merging	B
ﬂash	O
and	O
non-	O
ﬂash	B
photographs	O
;	O
(	O
petschnigg	O
,	O
agrawala	O
,	O
hoppe	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
;	O
(	O
c	O
)	O
image	B
mat-	O
ting	O
and	O
compositing	B
;	O
(	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
;	O
(	O
d	O
)	O
hole	B
ﬁlling	I
with	O
inpainting	B
(	O
criminisi	O
,	O
p´erez	O
,	O
and	O
toyama	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
ieee	O
.	O
10	O
computational	O
photography	O
469	O
stitching	O
multiple	B
images	O
into	O
wide	O
ﬁeld	O
of	O
view	O
panoramas	O
,	O
which	O
we	O
covered	O
in	O
chapter	O
9	O
,	O
allows	O
us	O
create	O
photographs	O
that	O
could	O
not	O
be	O
captured	O
with	O
a	O
regular	O
camera	B
.	O
this	O
is	O
just	O
one	O
instance	B
of	O
computational	O
photography	O
,	O
where	O
image	B
analysis	O
and	O
processing	O
algorithms	O
are	O
applied	O
to	O
one	O
or	O
more	O
photographs	O
to	O
create	O
images	O
that	O
go	O
beyond	O
the	O
capabilities	O
of	O
traditional	O
imaging	O
systems	O
.	O
some	O
of	O
these	O
techniques	O
are	O
now	O
being	O
incorporated	O
directly	O
into	O
digital	O
still	O
cameras	O
.	O
for	O
example	O
,	O
some	O
of	O
the	O
newer	O
digital	O
still	O
cameras	O
have	O
sweep	O
panorama	O
modes	O
and	O
take	O
multiple	B
shots	O
in	O
low-light	O
conditions	O
to	O
reduce	O
image	B
noise	O
.	O
in	O
this	O
chapter	O
,	O
we	O
cover	O
a	O
number	O
of	O
additional	O
computational	O
photography	O
algorithms	O
.	O
we	O
begin	O
with	O
a	O
review	O
of	O
photometric	B
image	O
calibration	B
(	O
section	O
10.1	O
)	O
,	O
i.e.	O
,	O
the	O
measurement	O
of	O
camera	B
and	O
lens	O
responses	O
,	O
which	O
is	O
a	O
prerequisite	O
for	O
many	O
of	O
the	O
algorithms	O
we	O
describe	O
later	O
.	O
we	O
then	O
discuss	O
high	B
dynamic	I
range	I
imaging	O
(	O
section	O
10.2	O
)	O
,	O
which	O
captures	O
the	O
full	O
range	O
of	O
brightness	O
in	O
a	O
scene	O
through	O
the	O
use	O
of	O
multiple	B
exposures	O
(	O
figure	O
10.1a	O
)	O
.	O
we	O
also	O
discuss	O
tone	B
mapping	I
operators	O
,	O
which	O
map	O
rich	O
images	O
back	O
into	O
regular	O
display	O
devices	O
,	O
such	O
as	O
screens	O
and	O
printers	O
,	O
as	O
well	O
as	O
algorithms	O
that	O
merge	O
ﬂash	O
and	O
regular	O
images	O
to	O
obtain	O
better	O
exposures	O
(	O
figure	O
10.1b	O
)	O
.	O
next	O
,	O
we	O
discuss	O
how	O
the	O
resolution	O
of	O
images	O
can	O
be	O
improved	O
either	O
by	O
merging	O
mul-	O
tiple	O
photographs	O
together	O
or	O
using	O
sophisticated	O
image	B
priors	O
(	O
section	O
10.3	O
)	O
.	O
this	O
includes	O
algorithms	O
for	O
extracting	O
full-color	O
images	O
from	O
the	O
patterned	O
bayer	O
mosaics	O
present	O
in	O
most	O
cameras	O
.	O
in	O
section	O
10.4	O
,	O
we	O
discuss	O
algorithms	O
for	O
cutting	O
pieces	O
of	O
images	O
from	O
one	O
photograph	O
and	O
pasting	O
them	O
into	O
others	O
(	O
figure	O
10.1c	O
)	O
.	O
in	O
section	O
10.5	O
,	O
we	O
describe	O
how	O
to	O
generate	O
novel	O
textures	O
from	O
real-world	O
samples	O
for	O
applications	O
such	O
as	O
ﬁlling	O
holes	O
in	O
images	O
(	O
fig-	O
ure	O
10.1d	O
)	O
.	O
we	O
close	O
with	O
a	O
brief	O
overview	O
of	O
non-photorealistic	B
rendering	I
(	O
section	O
10.5.2	O
)	O
,	O
which	O
can	O
turn	O
regular	O
photographs	O
into	O
artistic	O
renderings	O
that	O
resemble	O
traditional	O
drawings	O
and	O
paintings	O
.	O
one	O
topic	O
that	O
we	O
do	O
not	O
cover	O
extensively	O
in	O
this	O
book	O
is	O
novel	O
computational	O
sensors	O
,	O
optics	B
,	O
and	O
cameras	O
.	O
a	O
nice	O
survey	O
can	O
be	O
found	O
in	O
an	O
article	O
by	O
nayar	O
(	O
2006	O
)	O
,	O
a	O
recently	O
published	O
book	O
by	O
raskar	O
and	O
tumblin	O
(	O
2010	O
)	O
,	O
and	O
more	O
recent	O
research	O
papers	O
(	O
levin	O
,	O
fergus	O
,	O
durand	O
et	O
al	O
.	O
2007	O
)	O
.	O
some	O
related	O
discussion	O
can	O
also	O
be	O
found	O
in	O
sections	O
10.2	O
and	O
13.3.	O
a	O
good	O
general-audience	O
introduction	O
to	O
computational	O
photography	O
can	O
be	O
found	O
in	O
the	O
article	O
by	O
hayes	O
(	O
2008	O
)	O
as	O
well	O
as	O
survey	O
papers	O
by	O
nayar	O
(	O
2006	O
)	O
,	O
cohen	O
and	O
szeliski	O
(	O
2006	O
)	O
,	O
levoy	O
(	O
2006	O
)	O
,	O
and	O
debevec	O
(	O
2006	O
)	O
.1	O
raskar	O
and	O
tumblin	O
(	O
2010	O
)	O
give	O
extensive	O
coverage	O
of	O
topics	O
in	O
this	O
area	O
,	O
with	O
particular	O
emphasis	O
on	O
computational	O
cameras	O
and	O
sensors	O
.	O
the	O
sub-ﬁeld	O
of	O
high	B
dynamic	I
range	I
imaging	O
has	O
its	O
own	O
book	O
discussing	O
research	O
in	O
this	O
area	O
(	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
2005	O
)	O
,	O
as	O
well	O
as	O
a	O
wonderful	O
book	O
aimed	O
more	O
at	O
profes-	O
1	O
see	O
also	O
the	O
two	O
special	O
issue	O
journals	O
edited	O
by	O
bimber	O
(	O
2006	O
)	O
and	O
durand	O
and	O
szeliski	O
(	O
2007	O
)	O
.	O
470	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
sional	O
photographers	O
(	O
freeman	O
2008	O
)	O
.2	O
a	O
good	O
survey	O
of	O
image	B
matting	O
is	O
provided	O
by	O
wang	O
and	O
cohen	O
(	O
2007a	O
)	O
.	O
there	O
are	O
also	O
several	O
courses	O
on	O
computational	O
photography	O
where	O
the	O
instructors	O
have	O
provided	O
extensive	O
on-line	O
materials	O
,	O
e.g.	O
,	O
fr´edo	O
durand	O
’	O
s	O
computation	O
photography	O
course	O
at	O
mit,3	O
alyosha	O
efros	O
’	O
class	O
at	O
carnegie	O
mellon,4	O
marc	O
levoy	O
’	O
s	O
class	O
at	O
stanford,5	O
and	O
a	O
series	O
of	O
siggraph	O
courses	O
on	O
computational	O
photography.6	O
10.1	O
photometric	B
calibration	O
before	O
we	O
can	O
successfully	O
merge	O
multiple	B
photographs	O
,	O
we	O
need	O
to	O
characterize	O
the	O
func-	O
tions	O
that	O
map	O
incoming	O
irradiance	O
into	O
pixel	O
values	O
and	O
also	O
the	O
amounts	O
of	O
noise	B
present	O
in	O
each	O
image	B
.	O
in	O
this	O
section	O
,	O
we	O
examine	O
three	O
components	O
of	O
the	O
imaging	O
pipeline	B
(	O
fig-	O
ure	O
10.2	O
)	O
that	O
affect	O
this	O
mapping	O
.	O
the	O
ﬁrst	O
is	O
the	O
radiometric	B
response	O
function	O
(	O
mitsunaga	O
and	O
nayar	O
1999	O
)	O
,	O
which	O
maps	O
photons	O
arriving	O
at	O
the	O
lens	O
into	O
digital	O
values	O
stored	O
in	O
the	O
image	B
ﬁle	O
(	O
section	O
10.1.1	O
)	O
.	O
the	O
second	O
is	O
vignetting	B
,	O
which	O
darkens	O
pixel	O
values	O
near	O
the	O
periphery	O
of	O
images	O
,	O
especially	O
at	O
large	O
apertures	O
(	O
section	O
10.1.3	O
)	O
.	O
the	O
third	O
is	O
the	O
point	B
spread	I
function	I
,	O
which	O
characterizes	O
the	O
blur	O
induced	O
by	O
the	O
lens	O
,	O
anti-aliasing	O
ﬁlters	O
,	O
and	O
ﬁnite	O
sensor	B
areas	O
(	O
section	O
10.1.4	O
)	O
.7	O
the	O
material	O
in	O
this	O
section	O
builds	O
on	O
the	O
image	B
formation	O
processes	O
described	O
in	O
sections	O
2.2.3	O
and	O
2.3.3	O
,	O
so	O
if	O
it	O
has	O
been	O
a	O
while	O
since	O
you	O
looked	O
at	O
those	O
sections	O
,	O
please	O
go	O
back	O
and	O
review	O
them	O
.	O
10.1.1	O
radiometric	B
response	O
function	O
as	O
we	O
can	O
see	O
in	O
figure	O
10.2	O
,	O
a	O
number	O
of	O
factors	O
affect	O
how	O
the	O
intensity	O
of	O
light	O
arriving	O
at	O
the	O
lens	O
ends	O
up	O
being	O
mapped	O
into	O
stored	O
digital	O
values	O
.	O
let	O
us	O
ignore	O
for	O
now	O
any	O
non-	O
uniform	O
attenuation	O
that	O
may	O
occur	O
inside	O
the	O
lens	O
,	O
which	O
we	O
cover	O
in	O
section	O
10.1.3.	O
the	O
ﬁrst	O
factors	O
to	O
affect	O
this	O
mapping	O
are	O
the	O
aperture	O
and	O
shutter	O
speed	O
(	O
section	O
2.3	O
)	O
,	O
which	O
can	O
be	O
modeled	O
as	O
global	B
multipliers	O
on	O
the	O
incoming	O
light	O
,	O
most	O
conveniently	O
mea-	O
sured	O
in	O
exposure	O
values	O
(	O
log2	O
brightness	O
ratios	B
)	O
.	O
next	O
,	O
the	O
analog	O
to	O
digital	O
(	O
a/d	O
)	O
converter	O
on	O
the	O
sensing	O
chip	O
applies	O
an	O
electronic	O
gain	O
,	O
usually	O
controlled	O
by	O
the	O
iso	O
setting	O
on	O
your	O
camera	B
.	O
while	O
in	O
theory	O
this	O
gain	O
is	O
linear	B
,	O
as	O
with	O
any	O
electronics	O
non-linearities	O
may	O
be	O
2	O
gulbins	O
and	O
gulbins	O
(	O
2009	O
)	O
discuss	O
related	O
photographic	O
techniques	O
.	O
3	O
mit	O
6.815/6.865	O
,	O
http	O
:	O
//stellar.mit.edu/s/course/6/sp08/6.815/materials.html	O
.	O
4	O
cmu	O
15-463	O
,	O
http	O
:	O
//graphics.cs.cmu.edu/courses/15-463/	O
.	O
5	O
stanford	O
cs	O
448a	O
,	O
http	O
:	O
//graphics.stanford.edu/courses/cs448a-10/	O
.	O
6	O
http	O
:	O
//web.media.mit.edu/∼raskar/photo/	O
.	O
7	O
additional	O
photometric	B
camera	O
and	O
lens	O
effects	O
include	O
sensor	B
glare	O
,	O
blooming	B
,	O
and	O
chromatic	B
aberration	I
,	O
which	O
can	O
also	O
be	O
thought	O
of	O
as	O
a	O
spectrally	O
varying	O
form	O
of	O
geometric	B
aberration	O
(	O
section	O
2.2.3	O
)	O
.	O
10.1	O
photometric	B
calibration	O
471	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
10.2	O
image	B
sensing	O
pipeline	B
:	O
(	O
a	O
)	O
block	O
diagram	O
showing	O
the	O
various	O
sources	O
of	O
noise	B
as	O
well	O
as	O
the	O
typical	O
digital	O
post-processing	O
steps	O
;	O
(	O
b	O
)	O
equivalent	O
signal	O
transforms	O
,	O
including	O
convolution	O
,	O
gain	O
,	O
and	O
noise	B
injection	O
.	O
the	O
abbreviations	O
are	O
:	O
rd	O
=	O
radial	B
distortion	I
,	O
aa	O
=	O
anti-aliasing	O
ﬁlter	O
,	O
cfa	O
=	O
color	O
ﬁlter	O
array	O
,	O
q1	O
and	O
q2	O
=	O
quantization	B
noise	O
.	O
sceneradiancedsprawsensor	O
chipcamera	O
bodyopticsaperturesensor	O
(	O
ccd/cmos	O
)	O
adcdemosaic	O
(	O
sharpen	O
)	O
white	O
balancegamma/curvecompressshuttergain	O
(	O
iso	O
)	O
jpegadcrawdspsensor	O
chipcamera	O
bodyscene	O
radianceopticsaperturesensor	O
(	O
ccd/cmos	O
)	O
demosaic	O
(	O
sharpen	O
)	O
white	O
balancegamma/curvecompressshuttergain	O
(	O
iso	O
)	O
jpegblur	O
kern	O
.	O
&	O
rdf-stop	O
&	O
vignetteexposure	O
taa	O
cfanoiseiso	O
gainq1	O
?	O
?	O
rgb	O
gainq2gamma	O
&	O
s-curve	O
472	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
10.3	O
radiometric	B
response	O
calibration	B
:	O
(	O
a	O
)	O
typical	O
camera	B
response	O
function	O
,	O
show-	O
ing	O
the	O
mapping	O
between	O
incoming	O
log	O
irradiance	O
(	O
exposure	O
)	O
and	O
output	O
eight-bit	O
pixel	O
val-	O
ues	O
,	O
for	O
one	O
color	B
channel	O
(	O
debevec	O
and	O
malik	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
;	O
(	O
b	O
)	O
color	B
checker	O
chart	O
.	O
present	O
(	O
either	O
unintentionally	O
or	O
by	O
design	O
)	O
.	O
ignoring	O
,	O
for	O
now	O
,	O
photon	O
noise	B
,	O
on-chip	O
noise	B
,	O
ampliﬁer	B
noise	O
,	O
and	O
quantization	B
noise	O
,	O
which	O
we	O
discuss	O
shortly	O
,	O
you	O
can	O
often	O
assume	O
that	O
the	O
mapping	O
between	O
incoming	O
light	O
and	O
the	O
values	O
stored	O
in	O
a	O
raw	O
camera	B
ﬁle	O
(	O
if	O
your	O
camera	B
supports	O
this	O
)	O
is	O
roughly	O
linear	B
.	O
if	O
images	O
are	O
being	O
stored	O
in	O
the	O
more	O
common	O
jpeg	O
format	O
,	O
the	O
camera	B
’	O
s	O
digital	O
signal	O
processor	O
(	O
dsp	O
)	O
next	O
performs	O
bayer	O
pattern	O
demosaicing	B
(	O
sections	O
2.3.2	O
and	O
10.3.1	O
)	O
,	O
which	O
is	O
a	O
mostly	O
linear	B
(	O
but	O
often	O
non-stationary	O
)	O
process	O
.	O
some	O
sharpening	O
is	O
also	O
often	O
applied	O
at	O
this	O
stage	O
.	O
next	O
,	O
the	O
color	B
values	O
are	O
multiplied	O
by	O
different	O
constants	O
(	O
or	O
sometimes	O
a	O
3	O
×	O
3	O
color	B
twist	O
matrix	O
)	O
to	O
perform	O
color	B
balancing	O
,	O
i.e.	O
,	O
to	O
move	O
the	O
white	O
point	O
closer	O
to	O
pure	O
white	O
.	O
finally	O
,	O
a	O
standard	O
gamma	O
is	O
applied	O
to	O
the	O
intensities	O
in	O
each	O
color	B
channel	O
and	O
the	O
colors	O
are	O
converted	O
into	O
ycbcr	O
format	O
before	O
being	O
transformed	O
by	O
a	O
dct	O
,	O
quantized	O
,	O
and	O
then	O
compressed	O
into	O
the	O
jpeg	O
format	O
(	O
section	O
2.3.3	O
)	O
.	O
figure	O
10.2	O
shows	O
all	O
of	O
these	O
steps	O
in	O
pictorial	O
form	O
.	O
given	O
the	O
complexity	O
of	O
all	O
of	O
this	O
processing	O
,	O
it	O
is	O
difﬁcult	O
to	O
model	O
the	O
camera	B
response	O
function	O
(	O
figure	O
10.3a	O
)	O
,	O
i.e.	O
,	O
the	O
mapping	O
between	O
incoming	O
irradiance	O
and	O
digital	O
rgb	O
val-	O
ues	O
,	O
from	O
ﬁrst	O
principles	O
.	O
a	O
more	O
practical	O
approach	O
is	O
to	O
calibrate	O
the	O
camera	B
by	O
measuring	O
correspondences	O
between	O
incoming	O
light	O
and	O
ﬁnal	O
values	O
.	O
the	O
most	O
accurate	O
,	O
but	O
most	O
expensive	O
,	O
approach	O
is	O
to	O
use	O
an	O
integrating	O
sphere	O
,	O
which	O
is	O
a	O
large	O
(	O
typically	O
1m	O
diameter	O
)	O
sphere	O
carefully	O
painted	O
on	O
the	O
inside	O
with	O
white	O
matte	O
paint	O
.	O
an	O
accurately	O
calibrated	O
light	O
at	O
the	O
top	O
controls	O
the	O
amount	O
of	O
radiance	O
inside	O
the	O
sphere	O
(	O
which	O
is	O
constant	O
everywhere	O
because	O
of	O
the	O
sphere	O
’	O
s	O
radiometry	O
)	O
and	O
a	O
small	O
opening	B
at	O
the	O
side	O
allows	O
for	O
a	O
camera/lens	O
combination	O
to	O
be	O
mounted	O
.	O
by	O
slowly	O
varying	O
the	O
current	O
going	O
into	O
the	O
light	O
,	O
an	O
accurate	O
correspondence	B
can	O
be	O
established	O
between	O
incoming	O
radiance	O
and	O
10.1	O
photometric	B
calibration	O
473	O
measured	O
pixel	O
values	O
.	O
the	O
vignetting	B
and	O
noise	B
characteristics	O
of	O
the	O
camera	B
can	O
also	O
be	O
simultaneously	O
determined	O
.	O
a	O
more	O
practical	O
alternative	O
is	O
to	O
use	O
a	O
calibration	B
chart	O
(	O
figure	O
10.3b	O
)	O
such	O
as	O
the	O
mac-	O
beth	O
or	O
munsell	O
colorchecker	O
chart.8	O
the	O
biggest	O
problem	O
with	O
this	O
approach	O
is	O
to	O
ensure	O
uniform	O
lighting	B
.	O
one	O
approach	O
is	O
to	O
use	O
a	O
large	O
dark	O
room	O
with	O
a	O
high-quality	O
light	O
source	O
far	O
away	O
from	O
(	O
and	O
perpendicular	O
to	O
)	O
the	O
chart	O
.	O
another	O
is	O
to	O
place	O
the	O
chart	O
outdoors	O
away	O
from	O
any	O
shadows	O
.	O
(	O
the	O
results	O
will	O
differ	O
under	O
these	O
two	O
conditions	O
,	O
because	O
the	O
color	B
of	O
the	O
illuminant	O
will	O
be	O
different	O
)	O
.	O
the	O
easiest	O
approach	O
is	O
probably	O
to	O
take	O
multiple	B
exposures	O
of	O
the	O
same	O
scene	O
while	O
the	O
camera	B
is	O
on	O
a	O
tripod	O
and	O
to	O
recover	O
the	O
response	O
function	O
by	O
simultaneously	O
estimating	O
the	O
incoming	O
irradiance	O
at	O
each	O
pixel	O
and	O
the	O
response	O
curve	O
(	O
mann	O
and	O
picard	O
1995	O
;	O
debevec	O
and	O
malik	O
1997	O
;	O
mitsunaga	O
and	O
nayar	O
1999	O
)	O
.	O
this	O
approach	O
is	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
10.2	O
on	O
high	B
dynamic	I
range	I
imaging	O
.	O
if	O
all	O
else	O
fails	O
,	O
i.e.	O
,	O
you	O
just	O
have	O
one	O
or	O
more	O
unrelated	O
photos	O
,	O
you	O
can	O
use	O
an	O
interna-	O
tional	O
color	B
consortium	O
(	O
icc	O
)	O
proﬁle	B
for	O
the	O
camera	B
(	O
fairchild	O
2005	O
)	O
.9	O
even	O
more	O
simply	O
,	O
you	O
can	O
just	O
assume	O
that	O
the	O
response	O
is	O
linear	B
if	O
they	O
are	O
raw	O
ﬁles	O
and	O
that	O
the	O
images	O
have	O
a	O
γ	O
=	O
2.2	O
non-linearity	O
(	O
plus	O
clipping	O
)	O
applied	O
to	O
each	O
rgb	O
channel	O
if	O
they	O
are	O
jpeg	O
images	O
.	O
10.1.2	O
noise	B
level	O
estimation	B
in	O
addition	O
to	O
knowing	O
the	O
camera	B
response	O
function	O
,	O
it	O
is	O
also	O
often	O
important	O
to	O
know	O
the	O
amount	O
of	O
noise	B
being	O
injected	O
under	O
a	O
particular	O
camera	B
setting	O
(	O
e.g.	O
,	O
iso/gain	O
level	O
)	O
.	O
the	O
simplest	O
characterization	O
of	O
noise	B
is	O
a	O
single	O
standard	O
deviation	O
,	O
usually	O
measured	O
in	O
gray	O
levels	O
,	O
independent	O
of	O
pixel	O
value	O
.	O
a	O
more	O
accurate	O
model	O
can	O
be	O
obtained	O
by	O
estimating	O
the	O
noise	B
level	O
as	O
a	O
function	O
of	O
pixel	O
value	O
(	O
figure	O
10.4	O
)	O
,	O
which	O
is	O
known	O
as	O
the	O
noise	B
level	O
function	O
(	O
liu	O
,	O
szeliski	O
,	O
kang	O
et	O
al	O
.	O
2008	O
)	O
.	O
as	O
with	O
the	O
camera	B
response	O
function	O
,	O
the	O
simplest	O
way	O
to	O
estimate	O
these	O
quantities	O
is	O
in	O
the	O
lab	O
,	O
using	O
either	O
an	O
integrating	O
sphere	O
or	O
a	O
calibration	B
chart	O
.	O
the	O
noise	B
can	O
be	O
estimated	O
either	O
at	O
each	O
pixel	O
independently	O
,	O
by	O
taking	O
repeated	O
exposures	O
and	O
computing	O
the	O
temporal	O
variance	O
in	O
the	O
measurements	O
(	O
healey	O
and	O
kondepudy	O
1994	O
)	O
,	O
or	O
over	O
regions	O
,	O
by	O
assuming	O
that	O
pixel	O
values	O
should	O
all	O
be	O
the	O
same	O
within	O
some	O
region	B
(	O
e.g.	O
,	O
inside	O
a	O
color	B
checker	O
square	O
)	O
and	O
computing	O
a	O
spatial	O
variance	O
.	O
this	O
approach	O
can	O
be	O
generalized	B
to	O
photos	O
where	O
there	O
are	O
regions	O
of	O
constant	O
or	O
slowly	O
varying	O
intensity	O
(	O
liu	O
,	O
szeliski	O
,	O
kang	O
et	O
al	O
.	O
2008	O
)	O
.	O
first	O
,	O
segment	O
the	O
image	B
into	O
such	O
regions	O
and	O
ﬁt	O
a	O
constant	O
or	O
linear	B
function	O
inside	O
each	O
region	B
.	O
next	O
,	O
measure	O
the	O
(	O
spatial	O
)	O
standard	O
deviation	O
of	O
the	O
differences	O
between	O
the	O
noisy	O
input	O
pixels	O
and	O
the	O
smooth	O
ﬁtted	O
function	O
8	O
http	O
:	O
//www.xrite.com	O
.	O
9	O
see	O
also	O
the	O
icc	O
information	O
on	O
proﬁles	B
,	O
http	O
:	O
//www.color.org/info	O
proﬁles2.xalter	O
.	O
474	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.4	O
noise	B
level	O
function	O
estimates	O
obtained	O
from	O
a	O
single	O
color	O
photograph	O
(	O
liu	O
,	O
szeliski	O
,	O
kang	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
.	O
the	O
colored	O
curves	O
are	O
the	O
estimated	O
nlf	O
ﬁt	O
as	O
the	O
probabilistic	B
lower	O
envelope	O
of	O
the	O
measured	O
deviations	O
between	O
the	O
noisy	O
piecewise-smooth	O
images	O
.	O
the	O
ground	O
truth	O
nlfs	O
obtained	O
by	O
averaging	O
29	O
images	O
are	O
shown	O
in	O
gray	O
.	O
away	O
from	O
large	O
gradients	O
and	O
region	B
boundaries	O
.	O
plot	O
these	O
as	O
a	O
function	O
of	O
output	O
level	O
for	O
each	O
color	B
channel	O
,	O
as	O
shown	O
in	O
figure	O
10.4.	O
finally	O
,	O
ﬁt	O
a	O
lower	O
envelope	O
to	O
this	O
distribution	O
in	O
order	B
to	O
ignore	O
pixels	O
or	O
deviations	O
that	O
are	O
outliers	O
.	O
a	O
fully	O
bayesian	O
approach	O
to	O
this	O
problem	O
that	O
models	O
the	O
statistical	O
distribution	O
of	O
each	O
quantity	O
is	O
presented	O
by	O
(	O
liu	O
,	O
szeliski	O
,	O
kang	O
et	O
al	O
.	O
2008	O
)	O
.	O
a	O
simpler	O
approach	O
,	O
which	O
should	O
produce	O
useful	O
results	O
in	O
most	O
cases	O
,	O
is	O
to	O
ﬁt	O
a	O
low-dimensional	O
function	O
(	O
e.g.	O
,	O
positive	O
valued	O
b-spline	O
)	O
to	O
the	O
lower	O
envelope	O
(	O
see	O
exercise	O
10.2	O
)	O
.	O
in	O
more	O
recent	O
work	O
,	O
matsushita	O
and	O
lin	O
(	O
2007	O
)	O
present	O
a	O
technique	O
for	O
simultaneously	O
estimating	O
a	O
camera	B
’	O
s	O
response	O
and	O
noise	B
level	O
functions	O
based	O
on	O
skew	O
(	O
asymmetries	O
)	O
in	O
level-dependent	O
noise	B
distributions	O
.	O
their	O
paper	O
also	O
contains	O
extensive	O
references	B
to	O
previ-	O
ous	O
work	O
in	O
these	O
areas	O
.	O
10.1.3	O
vignetting	B
a	O
common	O
problem	O
with	O
using	O
wide-angle	O
and	O
wide-aperture	O
lenses	O
is	O
that	O
the	O
image	B
tends	O
to	O
darken	O
in	O
the	O
corners	O
(	O
figure	O
10.5a	O
)	O
.	O
this	O
problem	O
is	O
generally	O
known	O
as	O
vignetting	B
and	O
comes	O
in	O
several	O
different	O
forms	O
,	O
including	O
natural	B
,	O
optical	O
,	O
and	O
mechanical	B
vignetting	O
(	O
sec-	O
tion	B
2.2.3	O
)	O
(	O
ray	O
2002	O
)	O
.	O
as	O
with	O
radiometric	O
response	O
function	O
calibration	B
,	O
the	O
most	O
accurate	O
way	O
to	O
calibrate	O
vignetting	B
is	O
to	O
use	O
an	O
integrating	O
sphere	O
or	O
a	O
picture	O
of	O
a	O
uniformly	O
colored	O
and	O
illuminated	O
blank	O
wall	O
.	O
an	O
alternative	O
approach	O
is	O
to	O
stitch	O
a	O
panoramic	O
scene	O
and	O
to	O
assume	O
that	O
the	O
true	O
radiance	O
at	O
each	O
pixel	O
comes	O
from	O
the	O
central	O
portion	O
of	O
each	O
input	O
image	B
.	O
this	O
is	O
easier	O
to	O
do	O
if	O
the	O
radiometric	B
response	O
function	O
is	O
already	O
known	O
(	O
e.g.	O
,	O
by	O
shooting	O
in	O
raw	O
mode	O
)	O
and	O
if	O
the	O
exposure	O
is	O
kept	O
constant	O
.	O
if	O
the	O
response	O
function	O
,	O
image	B
exposures	O
,	O
and	O
vignetting	B
function	O
are	O
unknown	O
,	O
they	O
can	O
still	O
be	O
recovered	O
by	O
optimizing	O
a	O
large	O
least	O
squares	O
ﬁtting	O
10.1	O
photometric	B
calibration	O
475	O
figure	O
10.5	O
single	O
image	O
vignetting	B
correction	O
(	O
zheng	O
,	O
yu	O
,	O
kang	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
:	O
(	O
a	O
)	O
original	O
image	B
with	O
strong	O
visible	O
vignetting	B
;	O
(	O
b	O
)	O
vignetting	B
compensation	O
as	O
de-	O
scribed	O
by	O
zheng	O
,	O
zhou	O
,	O
georgescu	O
et	O
al	O
.	O
(	O
2006	O
)	O
;	O
(	O
c–d	O
)	O
vignetting	B
compensation	O
as	O
described	O
by	O
zheng	O
,	O
yu	O
,	O
kang	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
10.6	O
simultaneous	O
estimation	B
of	O
vignetting	B
,	O
exposure	O
,	O
and	O
radiometric	B
response	O
(	O
goldman	O
2011	O
)	O
c	O
(	O
cid:13	O
)	O
2011	O
ieee	O
:	O
(	O
a	O
)	O
original	O
average	O
of	O
the	O
input	O
images	O
;	O
(	O
b	O
)	O
after	O
compen-	O
sating	O
for	O
vignetting	O
;	O
(	O
c	O
)	O
using	O
gradient	O
domain	O
blending	B
only	O
(	O
note	O
the	O
remaining	O
mottled	O
look	O
)	O
;	O
(	O
d	O
)	O
after	O
both	O
vignetting	B
compensation	O
and	O
blending	B
.	O
problem	O
(	O
litvinov	O
and	O
schechner	O
2005	O
;	O
goldman	O
2011	O
)	O
.	O
figure	O
10.6	O
shows	O
an	O
example	O
of	O
simultaneously	O
estimating	O
the	O
vignetting	B
,	O
exposure	O
,	O
and	O
radiometric	B
response	O
function	O
from	O
a	O
set	O
of	O
overlapping	O
photographs	O
(	O
goldman	O
2011	O
)	O
.	O
note	O
that	O
unless	O
vignetting	B
is	O
modeled	O
and	O
compensated	O
,	O
regular	O
gradient-domain	O
image	B
blending	O
(	O
section	O
9.3.4	O
)	O
will	O
not	O
create	O
an	O
attractive	O
image	B
.	O
if	O
only	O
a	O
single	O
image	O
is	O
available	O
,	O
vignetting	B
can	O
be	O
estimated	O
by	O
looking	O
for	O
slow	O
con-	O
sistent	O
intensity	O
variations	O
in	O
the	O
radial	B
direction	O
.	O
the	O
original	O
algorithm	B
proposed	O
by	O
zheng	O
,	O
lin	O
,	O
and	O
kang	O
(	O
2006	O
)	O
ﬁrst	O
pre-segmented	O
the	O
image	B
into	O
smoothly	O
varying	O
regions	O
and	O
then	O
performed	O
an	O
analysis	O
inside	O
each	O
region	B
.	O
instead	O
of	O
pre-segmenting	O
the	O
image	B
,	O
zheng	O
,	O
yu	O
,	O
kang	O
et	O
al	O
.	O
(	O
2008	O
)	O
compute	O
the	O
radial	B
gradients	O
at	O
all	O
the	O
pixels	O
and	O
use	O
the	O
asymmetry	O
in	O
this	O
distribution	O
(	O
since	O
gradients	O
away	O
from	O
the	O
center	O
are	O
,	O
on	O
average	O
,	O
slightly	O
negative	O
)	O
to	O
476	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
estimate	O
the	O
vignetting	B
.	O
figure	O
10.5	O
shows	O
the	O
results	O
of	O
applying	O
each	O
of	O
these	O
algorithms	O
to	O
an	O
image	B
with	O
a	O
large	O
amount	O
of	O
vignetting	B
.	O
exercise	O
10.3	O
has	O
you	O
implement	O
some	O
of	O
the	O
above	O
techniques	O
.	O
10.1.4	O
optical	B
blur	I
(	O
spatial	O
response	O
)	O
estimation	B
one	O
ﬁnal	O
characteristic	O
of	O
imaging	O
systems	O
that	O
you	O
should	O
calibrate	O
is	O
the	O
spatial	O
response	O
function	O
,	O
which	O
encodes	O
the	O
optical	B
blur	I
that	O
gets	O
convolved	O
with	O
the	O
incoming	O
image	B
to	O
pro-	O
duce	O
the	O
point-sampled	O
image	B
.	O
the	O
shape	O
of	O
the	O
convolution	O
kernel	B
,	O
which	O
is	O
also	O
known	O
as	O
point	B
spread	I
function	I
(	O
psf	O
)	O
or	O
optical	O
transfer	O
function	O
,	O
depends	O
on	O
several	O
factors	O
,	O
including	O
lens	O
blur	O
and	O
radial	B
distortion	I
(	O
section	O
2.2.3	O
)	O
,	O
anti-aliasing	O
ﬁlters	O
in	O
front	O
of	O
the	O
sensor	B
,	O
and	O
the	O
shape	O
and	O
extent	O
of	O
each	O
active	O
pixel	O
area	O
(	O
section	O
2.3	O
)	O
(	O
figure	O
10.2	O
)	O
.	O
a	O
good	O
estimate	O
of	O
this	O
function	O
is	O
required	O
for	O
applications	O
such	O
as	O
multi-image	O
super-resolution	O
and	O
de-blurring	O
(	O
section	O
10.3	O
)	O
.	O
in	O
theory	O
,	O
one	O
could	O
estimate	O
the	O
psf	O
by	O
simply	O
observing	O
an	O
inﬁnitely	O
small	O
point	O
light	O
source	O
everywhere	O
in	O
the	O
image	B
.	O
creating	O
an	O
array	O
of	O
samples	O
by	O
drilling	O
through	O
a	O
dark	O
plate	O
and	O
backlighting	O
with	O
a	O
very	O
bright	O
light	O
source	O
is	O
difﬁcult	O
in	O
practice	O
.	O
a	O
more	O
practical	O
approach	O
is	O
to	O
observe	O
an	O
image	B
composed	O
of	O
long	O
straight	O
lines	B
or	O
bars	O
,	O
since	O
these	O
can	O
be	O
ﬁtted	O
to	O
arbitrary	O
precision	B
.	O
because	O
the	O
location	O
of	O
a	O
horizontal	O
or	O
vertical	O
edge	O
can	O
be	O
aliased	O
during	O
acquisition	O
,	O
slightly	O
slanted	O
edges	O
are	O
preferred	O
.	O
the	O
proﬁle	B
and	O
locations	O
of	O
such	O
edges	O
can	O
be	O
estimated	O
to	O
sub-pixel	O
precision	O
,	O
which	O
makes	O
it	O
possible	O
to	O
estimate	O
the	O
psf	O
at	O
sub-pixel	O
resolutions	O
(	O
reichenbach	O
,	O
park	O
,	O
and	O
narayanswamy	O
1991	O
;	O
burns	O
and	O
williams	O
1999	O
;	O
williams	O
and	O
burns	O
2001	O
;	O
goesele	O
,	O
fuchs	O
,	O
and	O
seidel	O
2003	O
)	O
.	O
the	O
thesis	O
by	O
murphy	O
(	O
2005	O
)	O
contains	O
a	O
nice	O
survey	O
of	O
all	O
aspects	O
of	O
camera	B
calibration	O
,	O
including	O
the	O
spatial	O
frequency	O
response	O
(	O
sfr	O
)	O
,	O
spatial	O
uniformity	O
,	O
tone	O
reproduction	O
,	O
color	B
reproduction	O
,	O
noise	B
,	O
dynamic	B
range	O
,	O
color	B
channel	O
registration	B
,	O
and	O
depth	O
of	O
ﬁeld	O
.	O
it	O
also	O
includes	O
a	O
description	O
of	O
a	O
slant-edge	O
calibration	B
algorithm	O
called	O
sfrmat2	O
.	O
the	O
slant-edge	O
technique	O
can	O
be	O
used	O
to	O
recover	O
a	O
1d	O
projection	O
of	O
the	O
2d	O
psf	O
,	O
e.g.	O
,	O
slightly	O
vertical	O
edges	O
are	O
used	O
to	O
recover	O
the	O
horizontal	O
line	O
spread	O
function	O
(	O
lsf	O
)	O
(	O
williams	O
1999	O
)	O
.	O
the	O
lsf	O
is	O
then	O
often	O
converted	O
into	O
the	O
fourier	O
domain	O
and	O
its	O
magnitude	O
plotted	O
as	O
a	O
one-dimensional	O
modulation	O
transfer	B
function	O
(	O
mtf	O
)	O
,	O
which	O
indicates	O
which	O
image	B
frequen-	O
cies	O
are	O
lost	O
(	O
blurred	O
)	O
and	O
aliased	O
during	O
the	O
acquisition	O
process	O
(	O
section	O
2.3.1	O
)	O
.	O
for	O
most	O
computational	O
photography	O
applications	O
,	O
it	O
is	O
preferable	O
to	O
directly	O
estimate	O
the	O
full	O
2d	O
psf	O
,	O
since	O
it	O
can	O
be	O
hard	O
to	O
recover	O
from	O
its	O
projections	B
(	O
williams	O
1999	O
)	O
.	O
figure	O
10.7	O
shows	O
a	O
pattern	O
containing	O
edges	O
at	O
all	O
orientations	O
,	O
which	O
can	O
be	O
used	O
to	O
directly	O
recover	O
a	O
two-dimensional	B
psf	O
.	O
first	O
,	O
corners	O
in	O
the	O
pattern	O
are	O
located	O
by	O
extracting	O
edges	O
in	O
the	O
sensed	O
image	B
,	O
linking	B
them	O
,	O
and	O
ﬁnding	O
the	O
intersections	O
of	O
the	O
circular	O
arcs	O
.	O
next	O
,	O
the	O
ideal	O
pattern	O
,	O
whose	O
analytic	O
form	O
is	O
known	O
,	O
is	O
warped	O
(	O
using	O
a	O
homography	B
)	O
to	O
10.1	O
photometric	B
calibration	O
477	O
figure	O
10.7	O
calibration	B
pattern	O
with	O
edges	O
equally	O
distributed	O
at	O
all	O
orientations	O
that	O
can	O
be	O
used	O
for	O
psf	O
and	O
radial	B
distortion	I
estimation	O
(	O
joshi	O
,	O
szeliski	O
,	O
and	O
kriegman	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
.	O
a	O
portion	O
of	O
an	O
actual	O
sensed	O
image	B
is	O
shown	O
in	O
the	O
middle	O
and	O
a	O
close-up	O
of	O
the	O
ideal	O
pattern	O
is	O
on	O
the	O
right	O
.	O
ﬁt	O
the	O
central	O
portion	O
of	O
the	O
input	O
image	B
and	O
its	O
intensities	O
are	O
adjusted	O
to	O
ﬁt	O
the	O
ones	O
in	O
the	O
sensed	O
image	B
.	O
if	O
desired	O
,	O
the	O
pattern	O
can	O
be	O
rendered	O
at	O
a	O
higher	O
resolution	O
than	O
the	O
input	O
image	B
,	O
which	O
enables	O
the	O
estimation	B
of	O
the	O
psf	O
to	O
sub-pixel	O
resolution	O
(	O
figure	O
10.8a	O
)	O
.	O
finally	O
a	O
large	O
linear	O
least	B
squares	I
system	O
is	O
solved	O
to	O
recover	O
the	O
unknown	O
psf	O
kernel	B
k	O
,	O
k	O
=	O
arg	O
min	O
k	O
(	O
cid:107	O
)	O
b	O
−	O
d	O
(	O
i	O
∗	O
k	O
)	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
10.1	O
)	O
where	O
b	O
is	O
the	O
sensed	O
(	O
blurred	O
)	O
image	B
,	O
i	O
is	O
the	O
predicted	O
(	O
sharp	O
)	O
image	B
,	O
and	O
d	O
is	O
an	O
optional	O
downsampling	O
operator	O
that	O
matches	O
the	O
resolution	O
of	O
the	O
ideal	O
and	O
sensed	O
images	O
(	O
joshi	O
,	O
szeliski	O
,	O
and	O
kriegman	O
2008	O
)	O
.	O
in	O
terms	O
of	O
the	O
notation	O
(	O
3.75	O
)	O
introduced	O
in	O
section	O
3.4.3	O
,	O
this	O
could	O
also	O
be	O
written	O
as	O
b	O
=	O
arg	O
min	O
b	O
(	O
cid:107	O
)	O
o	O
−	O
d	O
(	O
s	O
∗	O
b	O
)	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
10.2	O
)	O
where	O
o	O
is	O
the	O
observed	O
image	B
,	O
s	O
is	O
the	O
sharp	O
image	B
,	O
and	O
b	O
is	O
the	O
blur	O
kernel	O
.	O
if	O
the	O
process	O
of	O
estimating	O
the	O
psf	O
is	O
done	O
locally	O
in	O
overlapping	O
patches	O
of	O
the	O
image	B
,	O
it	O
can	O
also	O
be	O
used	O
to	O
estimate	O
the	O
radial	B
distortion	I
and	O
chromatic	B
aberration	I
induced	O
by	O
the	O
lens	O
(	O
figure	O
10.8b	O
)	O
.	O
because	O
the	O
homography	B
mapping	O
the	O
ideal	O
target	O
to	O
the	O
sensed	O
image	B
is	O
estimated	O
in	O
the	O
central	O
(	O
undistorted	O
)	O
part	O
of	O
the	O
image	B
,	O
any	O
(	O
per-channel	O
)	O
shifts	O
induced	O
by	O
the	O
optics	B
manifest	O
themselves	O
as	O
a	O
displacement	O
in	O
the	O
psf	O
centers.10	O
compensating	O
for	O
these	O
shifts	O
eliminates	O
both	O
the	O
achromatic	O
radial	B
distortion	I
and	O
the	O
inter-channel	O
shifts	O
that	O
result	O
in	O
visible	O
chromatic	B
aberration	I
.	O
the	O
color-dependent	O
blurring	O
caused	O
by	O
chromatic	O
aberration	O
(	O
figure	O
2.21	O
)	O
can	O
also	O
be	O
removed	O
using	O
the	O
de-blurring	O
techniques	O
discussed	O
in	O
10	O
this	O
process	O
confounds	O
the	O
distinction	O
between	O
geometric	B
and	O
photometric	B
calibration	O
.	O
in	O
principle	O
,	O
any	O
ge-	O
ometric	O
distortion	O
could	O
be	O
modeled	O
by	O
spatially	O
varying	O
displaced	O
psfs	O
.	O
in	O
practice	O
,	O
it	O
is	O
easier	O
to	O
fold	O
any	O
large	O
shifts	O
into	O
the	O
geometric	B
correction	O
component	O
.	O
478	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
10.8	O
point	B
spread	I
function	I
estimation	O
using	O
a	O
calibration	B
target	O
(	O
joshi	O
,	O
szeliski	O
,	O
and	O
kriegman	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
.	O
(	O
a	O
)	O
sub-pixel	O
psfs	O
at	O
successively	O
higher	O
resolutions	O
(	O
note	O
the	O
interaction	O
between	O
the	O
square	O
sensing	O
area	O
and	O
the	O
circular	O
lens	O
blur	O
)	O
.	O
(	O
b	O
)	O
the	O
radial	B
distortion	I
and	O
chromatic	B
aberration	I
can	O
also	O
be	O
estimated	O
and	O
removed	O
.	O
(	O
c	O
)	O
psf	O
for	O
a	O
mis-	O
focused	O
(	O
blurred	O
)	O
lens	O
showing	O
some	O
diffraction	O
and	O
vignetting	B
effects	O
in	O
the	O
corners	O
.	O
section	O
10.3.	O
figure	O
10.8b	O
shows	O
how	O
the	O
radial	B
distortion	I
and	O
chromatic	B
aberration	I
manifest	O
themselves	O
as	O
elongated	O
and	O
displaced	O
psfs	O
,	O
along	O
with	O
the	O
result	O
of	O
removing	O
these	O
effects	O
in	O
a	O
region	B
of	O
the	O
calibration	B
target	O
.	O
the	O
local	B
2d	O
psf	O
estimation	B
technique	O
can	O
also	O
be	O
used	O
to	O
estimate	O
vignetting	B
.	O
fig-	O
ure	O
10.8c	O
shows	O
how	O
the	O
mechanical	B
vignetting	O
manifests	O
itself	O
as	O
clipping	O
of	O
the	O
psf	O
in	O
the	O
corners	O
of	O
the	O
image	B
.	O
in	O
order	B
for	O
the	O
overall	O
dimming	O
associated	O
with	O
vignetting	O
to	O
be	O
prop-	O
erly	O
captured	O
,	O
the	O
modiﬁed	O
intensities	O
of	O
the	O
ideal	O
pattern	O
need	O
to	O
be	O
extrapolated	O
from	O
the	O
center	O
,	O
which	O
is	O
best	O
done	O
with	O
a	O
uniformly	O
illuminated	O
target	O
.	O
when	O
working	O
with	O
raw	O
bayer-pattern	O
images	O
,	O
the	O
correct	O
way	O
to	O
estimate	O
the	O
psf	O
is	O
to	O
only	O
evaluate	O
the	O
least	B
squares	I
terms	O
in	O
(	O
10.1	O
)	O
at	O
sensed	O
pixel	O
values	O
,	O
while	O
interpolating	O
the	O
ideal	O
image	B
to	O
all	O
values	O
.	O
for	O
jpeg	O
images	O
,	O
you	O
should	O
linearize	O
your	O
intensities	O
ﬁrst	O
,	O
e.g.	O
,	O
remove	O
the	O
gamma	B
and	O
any	O
other	O
non-linearities	O
in	O
your	O
estimated	O
radiometric	B
response	O
function	O
.	O
what	O
if	O
you	O
have	O
an	O
image	B
that	O
was	O
taken	O
with	O
an	O
uncalibrated	O
camera	B
?	O
can	O
you	O
still	O
recover	O
the	O
psf	O
an	O
use	O
it	O
to	O
correct	O
the	O
image	B
?	O
in	O
fact	O
,	O
with	O
a	O
slight	O
modiﬁcation	O
,	O
the	O
previous	O
algorithms	O
still	O
work	O
.	O
instead	O
of	O
assuming	O
a	O
known	O
calibration	B
image	O
,	O
you	O
can	O
detect	O
strong	O
elongated	O
edges	O
and	O
ﬁt	O
ideal	O
step	O
edges	O
in	O
such	O
regions	O
(	O
figure	O
10.9b	O
)	O
,	O
resulting	O
in	O
the	O
sharp	O
image	B
shown	O
−2−1012−2−10	O
1	O
2	O
−2−1012−2−10	O
1	O
2	O
−2−1012−2−10	O
1	O
2	O
−2−1012−2−10	O
1	O
2	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
479	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
10.9	O
estimating	O
the	O
psf	O
without	O
using	O
a	O
calibration	B
pattern	O
(	O
joshi	O
,	O
szeliski	O
,	O
and	O
kriegman	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
:	O
(	O
a	O
)	O
input	O
image	B
with	O
blue	O
cross-section	O
(	O
proﬁle	B
)	O
location	O
,	O
(	O
b	O
)	O
proﬁle	B
of	O
sensed	O
and	O
predicted	O
step	O
edges	O
,	O
(	O
c–d	O
)	O
locations	O
and	O
values	O
of	O
the	O
predicted	O
colors	O
near	O
the	O
edge	O
locations	O
.	O
in	O
figure	O
10.9d	O
.	O
for	O
every	O
pixel	O
that	O
is	O
surrounded	O
by	O
a	O
complete	O
set	O
of	O
valid	O
estimated	O
neighbors	O
(	O
green	O
pixels	O
in	O
figure	O
10.9c	O
)	O
,	O
apply	O
the	O
least	B
squares	I
formula	O
(	O
10.1	O
)	O
to	O
estimate	O
the	O
kernel	B
k.	O
the	O
resulting	O
locally	O
estimated	O
psfs	O
can	O
be	O
used	O
to	O
correct	O
for	O
chromatic	O
aberration	O
(	O
since	O
the	O
relative	O
displacements	O
between	O
per-channel	O
psfs	O
can	O
be	O
computed	O
)	O
,	O
as	O
shown	O
by	O
joshi	O
,	O
szeliski	O
,	O
and	O
kriegman	O
(	O
2008	O
)	O
.	O
exercise	O
10.4	O
provides	O
some	O
more	O
detailed	O
instructions	O
for	O
implementing	O
and	O
testing	O
edge-based	B
psf	O
estimation	B
algorithms	O
.	O
an	O
alternative	O
approach	O
,	O
which	O
does	O
not	O
require	O
the	O
explicit	O
detection	B
of	O
edges	O
but	O
uses	O
image	B
statistics	O
(	O
gradient	O
distributions	O
)	O
instead	O
,	O
is	O
pre-	O
sented	O
by	O
fergus	O
,	O
singh	O
,	O
hertzmann	O
et	O
al	O
.	O
(	O
2006	O
)	O
.	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
as	O
we	O
mentioned	O
earlier	O
in	O
this	O
chapter	O
,	O
registered	O
images	O
taken	O
at	O
different	O
exposures	O
can	O
be	O
used	O
to	O
calibrate	O
the	O
radiometric	B
response	O
function	O
of	O
a	O
camera	B
.	O
more	O
importantly	O
,	O
they	O
can	O
help	O
you	O
create	O
well-exposed	O
photographs	O
under	O
challenging	O
conditions	O
,	O
such	O
as	O
brightly	O
lit	O
minmaxrrvalid	O
regionminmaxrrvalid	O
regionminmaxrrvalid	O
regionminmaxrrvalid	O
region	B
480	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.10	O
sample	O
indoor	O
image	B
where	O
the	O
areas	O
outside	O
the	O
window	O
are	O
overexposed	O
and	O
inside	O
the	O
room	O
are	O
too	O
dark	O
.	O
1	O
1,500	O
25,000	O
400,000	O
2,000,000	O
figure	O
10.11	O
relative	O
brightness	O
of	O
different	O
scenes	O
,	O
ranging	O
from	O
1	O
inside	O
a	O
dark	O
room	O
lit	O
by	O
a	O
monitor	O
to	O
2,000,000	O
looking	O
at	O
the	O
sun	O
.	O
photos	O
courtesy	O
of	O
paul	O
debevec	O
.	O
scenes	O
where	O
any	O
single	O
exposure	O
contains	O
saturated	O
(	O
overexposed	O
)	O
and	O
dark	O
(	O
underexposed	O
)	O
regions	O
(	O
figure	O
10.10	O
)	O
.	O
this	O
problem	O
is	O
quite	O
common	O
,	O
because	O
the	O
natural	B
world	O
contains	O
a	O
range	O
of	O
radiance	O
values	O
that	O
is	O
far	O
greater	O
than	O
can	O
be	O
captured	O
with	O
any	O
photographic	O
sensor	B
or	O
ﬁlm	O
(	O
figure	O
10.11	O
)	O
.	O
taking	O
a	O
set	O
of	O
bracketed	O
exposures	O
(	O
exposures	O
taken	O
by	O
a	O
camera	B
in	O
automatic	B
exposure	O
bracketing	O
(	O
aeb	O
)	O
mode	O
to	O
deliberately	O
under-	O
and	O
over-expose	O
the	O
image	B
)	O
gives	O
you	O
the	O
material	O
from	O
which	O
to	O
create	O
a	O
properly	O
exposed	O
photograph	O
,	O
as	O
shown	O
in	O
figure	O
10.12	O
(	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
2005	O
;	O
freeman	O
2008	O
;	O
gulbins	O
and	O
gulbins	O
2009	O
;	O
hasinoff	O
,	O
durand	O
,	O
and	O
freeman	O
2010	O
)	O
.	O
while	O
it	O
is	O
possible	O
to	O
combine	O
pixels	O
from	O
different	O
exposures	O
directly	O
into	O
a	O
ﬁnal	O
com-	O
+	O
+	O
⇒	O
figure	O
10.12	O
a	O
bracketed	O
set	O
of	O
shots	O
(	O
using	O
the	O
camera	B
’	O
s	O
automatic	B
exposure	O
bracketing	O
(	O
aeb	O
)	O
mode	O
)	O
and	O
the	O
resulting	O
high	B
dynamic	I
range	I
(	O
hdr	O
)	O
composite	O
.	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
481	O
posite	O
(	O
burt	O
and	O
kolczynski	O
1993	O
;	O
mertens	O
,	O
kautz	O
,	O
and	O
reeth	O
2007	O
)	O
,	O
this	O
approach	O
runs	O
the	O
risk	O
of	O
creating	O
contrast	O
reversals	O
and	O
halos	B
.	O
instead	O
,	O
the	O
more	O
common	O
approach	O
is	O
to	O
pro-	O
ceed	O
in	O
three	O
stages	O
:	O
1.	O
estimate	O
the	O
radiometric	B
response	O
function	O
from	O
the	O
aligned	O
images	O
.	O
2.	O
estimate	O
a	O
radiance	O
map	O
by	O
selecting	O
or	O
blending	B
pixels	O
from	O
different	O
exposures	O
.	O
3.	O
tone	O
map	O
the	O
resulting	O
high	B
dynamic	I
range	I
(	O
hdr	O
)	O
image	B
back	O
into	O
a	O
displayable	O
gamut	O
.	O
the	O
idea	O
behind	O
estimating	O
the	O
radiometric	B
response	O
function	O
is	O
relatively	O
straightforward	O
(	O
mann	O
and	O
picard	O
1995	O
;	O
debevec	O
and	O
malik	O
1997	O
;	O
mitsunaga	O
and	O
nayar	O
1999	O
;	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
2005	O
)	O
.	O
suppose	O
you	O
take	O
three	O
sets	O
of	O
images	O
at	O
different	O
exposures	O
(	O
shutter	O
speeds	O
)	O
,	O
say	O
at	O
±2	O
exposure	O
values.11	O
if	O
we	O
were	O
able	O
to	O
determine	O
the	O
irradiance	O
(	O
exposure	O
)	O
ei	O
at	O
each	O
pixel	O
(	O
2.101	O
)	O
,	O
we	O
could	O
plot	O
it	O
against	O
the	O
measured	O
pixel	O
value	O
zij	O
for	O
each	O
exposure	O
time	O
tj	O
,	O
as	O
shown	O
in	O
figure	O
10.13.	O
unfortunately	O
,	O
we	O
do	O
not	O
know	O
the	O
irradiance	O
values	O
ei	O
,	O
so	O
these	O
have	O
to	O
be	O
estimated	O
at	O
the	O
same	O
time	O
as	O
the	O
radiometric	B
response	O
function	O
f	O
,	O
which	O
can	O
be	O
written	O
(	O
debevec	O
and	O
malik	O
1997	O
)	O
as	O
zij	O
=	O
f	O
(	O
ei	O
tj	O
)	O
,	O
(	O
10.3	O
)	O
where	O
tj	O
is	O
the	O
exposure	O
time	O
for	O
the	O
jth	O
image	B
.	O
the	O
inverse	B
response	O
curve	O
f−1	O
is	O
given	O
by	O
f−1	O
(	O
zij	O
)	O
=	O
ei	O
tj	O
.	O
(	O
10.4	O
)	O
taking	O
logarithms	O
of	O
both	O
sides	O
(	O
base	O
2	O
is	O
convenient	O
,	O
as	O
we	O
can	O
now	O
measure	O
quantities	O
in	O
evs	O
)	O
,	O
we	O
obtain	O
g	O
(	O
zij	O
)	O
=	O
log	O
f−1	O
(	O
zij	O
)	O
=	O
log	O
ei	O
+	O
log	O
tj	O
,	O
(	O
10.5	O
)	O
where	O
g	O
=	O
log	O
f−1	O
(	O
which	O
maps	O
pixel	O
values	O
zij	O
into	O
log	O
irradiance	O
)	O
is	O
the	O
curve	O
we	O
are	O
estimating	O
(	O
figure	O
10.13	O
turned	O
on	O
its	O
side	O
)	O
.	O
debevec	O
and	O
malik	O
(	O
1997	O
)	O
assume	O
that	O
the	O
exposure	O
times	O
tj	O
are	O
known	O
.	O
(	O
recall	B
that	O
these	O
can	O
be	O
obtained	O
from	O
a	O
camera	B
’	O
s	O
exif	O
tags	O
,	O
but	O
that	O
they	O
actually	O
follow	O
a	O
power	O
of	O
2	O
progression	O
.	O
.	O
.	O
,	O
1/128	O
,	O
1/64	O
,	O
1/32	O
,	O
1/16	O
,	O
1/8	O
,	O
.	O
.	O
.	O
instead	O
of	O
the	O
marked	O
.	O
.	O
.	O
,	O
1/125	O
,	O
1/60	O
,	O
1/30	O
,	O
1/15	O
,	O
1/8	O
,	O
.	O
.	O
.	O
values—see	O
exercise	O
2.5	O
.	O
)	O
the	O
unknowns	O
are	O
therefore	O
the	O
per-pixel	O
exposures	O
ei	O
and	O
the	O
response	O
values	O
gk	O
=	O
g	O
(	O
k	O
)	O
,	O
where	O
g	O
can	O
be	O
discretized	O
according	O
to	O
the	O
256	O
pixel	O
values	O
commonly	O
observed	O
in	O
eight-bit	O
images	O
.	O
(	O
the	O
response	O
curves	O
are	O
calibrated	O
separately	O
for	O
each	O
color	B
channel	O
.	O
)	O
11	O
changing	O
the	O
shutter	O
speed	O
is	O
preferable	O
to	O
changing	O
the	O
aperture	O
,	O
as	O
the	O
latter	O
can	O
modify	O
the	O
vignetting	B
and	O
focus	B
.	O
using	O
±2	O
“	O
f-stops	O
”	O
(	O
technically	O
,	O
exposure	O
values	O
,	O
or	O
evs	O
,	O
since	O
f-stops	O
refer	O
to	O
apertures	O
)	O
is	O
usually	O
the	O
right	O
compromise	O
between	O
capturing	O
a	O
good	O
dynamic	B
range	O
and	O
having	O
properly	O
exposed	O
pixels	O
everywhere	O
.	O
482	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.13	O
radiometric	B
calibration	O
using	O
multiple	O
exposures	O
(	O
debevec	O
and	O
malik	O
1997	O
)	O
.	O
corresponding	O
pixel	O
values	O
are	O
plotted	O
as	O
functions	O
of	O
log	O
exposures	O
(	O
irradiance	O
)	O
.	O
the	O
curves	O
on	O
the	O
left	O
are	O
shifted	O
to	O
account	O
for	O
each	O
pixel	O
’	O
s	O
unknown	O
radiance	O
until	O
they	O
all	O
line	O
up	O
into	O
a	O
single	O
smooth	O
curve	O
.	O
in	O
order	B
to	O
make	O
the	O
response	O
curve	O
smooth	O
,	O
debevec	O
and	O
malik	O
(	O
1997	O
)	O
add	O
a	O
second-	O
order	B
smoothness	O
constraint	B
λ	O
(	O
cid:88	O
)	O
k	O
g	O
(	O
cid:48	O
)	O
(	O
cid:48	O
)	O
(	O
k	O
)	O
2	O
=	O
λ	O
(	O
cid:88	O
)	O
[	O
g	O
(	O
k	O
−	O
1	O
)	O
−	O
2g	O
(	O
k	O
)	O
+	O
g	O
(	O
k	O
+	O
1	O
)	O
]	O
2	O
,	O
(	O
10.6	O
)	O
which	O
is	O
similar	O
to	O
the	O
one	O
used	O
in	O
snakes	B
(	O
5.3	O
)	O
.	O
since	O
pixel	O
values	O
are	O
more	O
reliable	O
in	O
the	O
middle	O
of	O
their	O
range	O
(	O
and	O
the	O
g	O
function	O
becomes	O
singular	O
near	O
saturation	O
values	O
)	O
,	O
they	O
also	O
add	O
a	O
weighting	B
(	O
hat	O
)	O
function	O
w	O
(	O
k	O
)	O
that	O
decays	O
to	O
zero	O
at	O
both	O
ends	O
of	O
the	O
pixel	O
value	O
range	O
,	O
w	O
(	O
z	O
)	O
=	O
(	O
cid:40	O
)	O
z	O
−	O
zmin	O
zmax	O
−	O
z	O
z	O
≤	O
(	O
zmin	O
+	O
zmax	O
)	O
/2	O
z	O
>	O
(	O
zmin	O
+	O
zmax	O
)	O
/2	O
.	O
(	O
10.7	O
)	O
putting	O
all	O
of	O
these	O
terms	O
together	O
,	O
they	O
obtain	O
a	O
least	B
squares	I
problem	O
in	O
the	O
unknowns	O
{	O
gk	O
}	O
and	O
{	O
ei	O
}	O
,	O
e	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:88	O
)	O
j	O
w	O
(	O
zi	O
,	O
j	O
)	O
[	O
g	O
(	O
zi	O
,	O
j	O
)	O
−	O
log	O
ei	O
−	O
log	O
tj	O
]	O
2	O
+	O
λ	O
(	O
cid:88	O
)	O
k	O
w	O
(	O
k	O
)	O
g	O
(	O
cid:48	O
)	O
(	O
cid:48	O
)	O
(	O
k	O
)	O
2	O
.	O
(	O
10.8	O
)	O
(	O
in	O
order	B
to	O
remove	O
the	O
overall	O
shift	O
ambiguity	O
in	O
the	O
response	O
curve	O
and	O
irradiance	O
values	O
,	O
the	O
middle	O
of	O
the	O
response	O
curve	O
is	O
set	O
to	O
0	O
.	O
)	O
debevec	O
and	O
malik	O
(	O
1997	O
)	O
show	O
how	O
this	O
can	O
be	O
implemented	O
in	O
21	O
lines	B
of	O
matlab	O
code	O
,	O
which	O
partially	O
accounts	O
for	O
the	O
popularity	O
of	O
their	O
technique	O
.	O
while	O
debevec	O
and	O
malik	O
(	O
1997	O
)	O
assume	O
that	O
the	O
exposure	O
times	O
tj	O
are	O
known	O
exactly	O
,	O
there	O
is	O
no	O
reason	O
why	O
these	O
additional	O
variables	O
can	O
not	O
be	O
thrown	O
into	O
the	O
least	B
squares	I
problem	O
,	O
constraining	O
their	O
ﬁnal	O
estimated	O
values	O
to	O
lie	O
close	O
to	O
their	O
nominal	O
values	O
ˆtj	O
with	O
an	O
extra	O
term	O
η	O
(	O
cid:80	O
)	O
j	O
(	O
tj	O
−	O
ˆtj	O
)	O
2.	O
log	O
exposurepixel	O
value312log	O
exposurepixel	O
value	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
483	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
10.14	O
recovered	O
response	O
function	O
and	O
radiance	O
image	B
for	O
a	O
real	O
digital	O
camera	O
(	O
dcs460	O
)	O
(	O
debevec	O
and	O
malik	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
.	O
figure	O
10.14	O
shows	O
the	O
recovered	O
radiometric	B
response	O
function	O
for	O
a	O
digital	O
camera	O
along	O
with	O
select	O
(	O
relative	O
)	O
radiance	O
values	O
in	O
the	O
overall	O
radiance	O
map	O
.	O
figure	O
10.15	O
shows	O
the	O
bracketed	O
input	O
images	O
captured	O
on	O
color	B
ﬁlm	O
and	O
the	O
corresponding	O
radiance	O
map	O
.	O
while	O
debevec	O
and	O
malik	O
(	O
1997	O
)	O
use	O
a	O
general	O
second-order	O
smooth	O
curve	O
g	O
to	O
parame-	O
terize	O
their	O
response	O
curve	O
,	O
mann	O
and	O
picard	O
(	O
1995	O
)	O
use	O
a	O
three-parameter	O
function	O
f	O
(	O
e	O
)	O
=	O
α	O
+	O
βeγ	O
,	O
(	O
10.9	O
)	O
while	O
mitsunaga	O
and	O
nayar	O
(	O
1999	O
)	O
use	O
a	O
low-order	O
(	O
n	O
≤	O
10	O
)	O
polynomial	O
for	O
the	O
inverse	B
response	O
function	O
g.	O
pal	O
,	O
szeliski	O
,	O
uyttendaele	O
et	O
al	O
.	O
(	O
2004	O
)	O
derive	O
a	O
bayesian	O
model	O
that	O
estimates	O
an	O
independent	O
smooth	O
response	O
function	O
for	O
each	O
image	B
,	O
which	O
can	O
better	O
model	O
the	O
more	O
sophisticated	O
(	O
and	O
hence	O
less	O
predictable	O
)	O
automatic	B
contrast	O
and	O
tone	O
adjustment	O
performed	O
in	O
today	O
’	O
s	O
digital	O
cameras	O
.	O
once	O
the	O
response	O
function	O
has	O
been	O
estimated	O
,	O
the	O
second	O
step	O
in	O
creating	O
high	B
dynamic	I
range	I
photographs	O
is	O
to	O
merge	O
the	O
input	O
images	O
into	O
a	O
composite	O
radiance	O
map	O
.	O
if	O
the	O
re-	O
sponse	O
function	O
and	O
images	O
were	O
known	O
exactly	O
,	O
i.e.	O
,	O
if	O
they	O
were	O
noise	B
free	O
,	O
you	O
could	O
use	O
any	O
non-saturated	O
pixel	O
value	O
to	O
estimate	O
the	O
corresponding	O
radiance	O
by	O
mapping	O
it	O
through	O
the	O
inverse	B
response	O
curve	O
e	O
=	O
g	O
(	O
z	O
)	O
.	O
unfortunately	O
,	O
pixels	O
are	O
noisy	O
,	O
especially	O
under	O
low-light	O
conditions	O
when	O
fewer	O
photons	O
arrive	O
at	O
the	O
sensor	B
.	O
to	O
compensate	O
for	O
this	O
,	O
mann	O
and	O
picard	O
(	O
1995	O
)	O
use	O
the	O
derivative	O
of	O
the	O
response	O
function	O
as	O
a	O
weight	O
in	O
determining	O
the	O
ﬁnal	O
radiance	O
estimate	O
,	O
since	O
“	O
ﬂatter	O
”	O
regions	O
of	O
the	O
curve	O
tell	O
us	O
less	O
about	O
the	O
incoming	O
irradiance	O
.	O
debevec	O
and	O
malik	O
(	O
1997	O
)	O
use	O
a	O
hat	O
function	O
(	O
10.7	O
)	O
which	O
accentuates	O
mid-tone	O
pixels	O
while	O
avoiding	O
saturated	O
values	O
.	O
mitsunaga	O
and	O
nayar	O
(	O
1999	O
)	O
show	O
that	O
in	O
order	B
to	O
maximize	O
the	O
signal-to-noise	O
ratio	O
(	O
snr	O
)	O
,	O
484	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.15	O
bracketed	O
set	O
of	O
exposures	O
captured	O
with	O
a	O
ﬁlm	O
camera	B
and	O
the	O
resulting	O
radiance	O
image	B
displayed	O
in	O
pseudocolor	O
(	O
debevec	O
and	O
malik	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
10.16	O
merging	B
multiple	O
exposures	O
to	O
create	O
a	O
high	B
dynamic	I
range	I
composite	O
(	O
kang	O
,	O
uyttendaele	O
,	O
winder	O
et	O
al	O
.	O
2003	O
)	O
:	O
(	O
a–c	O
)	O
three	O
different	O
exposures	O
;	O
(	O
d	O
)	O
merging	B
the	O
exposures	O
using	O
classic	O
algorithms	O
(	O
note	O
the	O
ghosting	O
due	O
to	O
the	O
horse	O
’	O
s	O
head	B
movement	O
)	O
;	O
(	O
e	O
)	O
merging	B
the	O
exposures	O
with	O
motion	O
compensation	O
.	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
485	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
10.17	O
hdr	O
merging	B
with	O
large	O
amounts	O
of	O
motion	B
(	O
eden	O
,	O
uyttendaele	O
,	O
and	O
szeliski	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
ieee	O
:	O
(	O
a	O
)	O
registered	O
bracketed	O
input	O
images	O
;	O
(	O
b	O
)	O
results	O
after	O
the	O
ﬁrst	O
pass	O
of	O
image	B
selection	O
:	O
reference	O
labels	O
,	O
image	B
,	O
and	O
tone-mapped	O
image	B
;	O
(	O
c	O
)	O
results	O
after	O
the	O
second	O
pass	O
of	O
image	B
selection	O
:	O
ﬁnal	O
labels	O
,	O
compressed	O
hdr	O
image	B
,	O
and	O
tone-mapped	O
image	B
the	O
weighting	B
function	O
must	O
emphasize	O
both	O
higher	O
pixel	O
values	O
and	O
larger	O
gradients	O
in	O
the	O
transfer	B
function	O
,	O
i.e.	O
,	O
w	O
(	O
z	O
)	O
=	O
g	O
(	O
z	O
)	O
/g	O
(	O
cid:48	O
)	O
(	O
z	O
)	O
,	O
(	O
10.10	O
)	O
where	O
the	O
weights	O
w	O
are	O
used	O
to	O
form	O
the	O
ﬁnal	O
irradiance	O
estimate	O
log	O
ei	O
=	O
(	O
cid:80	O
)	O
j	O
w	O
(	O
zij	O
)	O
[	O
g	O
(	O
zij	O
)	O
−	O
log	O
tj	O
]	O
(	O
cid:80	O
)	O
j	O
w	O
(	O
zij	O
)	O
.	O
(	O
10.11	O
)	O
exercise	O
10.1	O
has	O
you	O
implement	O
one	O
of	O
the	O
radiometric	B
response	O
function	O
calibration	B
tech-	O
niques	O
and	O
then	O
use	O
it	O
to	O
create	O
radiance	O
maps	O
.	O
under	O
real-world	O
conditions	O
,	O
casually	O
acquired	O
images	O
may	O
not	O
be	O
perfectly	O
registered	O
and	O
may	O
contain	O
moving	O
objects	O
.	O
ward	O
(	O
2003	O
)	O
uses	O
a	O
global	B
(	O
parametric	B
)	O
transform	B
to	O
align	O
the	O
input	O
images	O
,	O
while	O
kang	O
,	O
uyttendaele	O
,	O
winder	O
et	O
al	O
.	O
(	O
2003	O
)	O
present	O
an	O
algorithm	B
that	O
combines	O
global	B
registration	O
with	O
local	O
motion	B
estimation	I
(	O
optical	B
ﬂow	I
)	O
to	O
accurately	O
align	O
the	O
images	O
before	O
blending	B
their	O
radiance	O
estimates	O
(	O
figure	O
10.16	O
)	O
.	O
since	O
the	O
images	O
may	O
486	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.18	O
fuji	O
superccd	O
high	B
dynamic	I
range	I
image	O
sensor	B
.	O
the	O
paired	O
large	O
and	O
small	O
active	O
areas	O
provide	O
two	O
different	O
effective	O
exposures	O
.	O
have	O
widely	O
different	O
exposures	O
,	O
care	O
must	O
be	O
taken	O
when	O
estimating	O
the	O
motions	O
,	O
which	O
must	O
themselves	O
be	O
checked	O
for	O
consistency	O
to	O
avoid	O
the	O
creation	O
of	O
ghosts	O
and	O
object	O
fragments	O
.	O
even	O
this	O
approach	O
,	O
however	O
,	O
may	O
not	O
work	O
when	O
the	O
camera	B
is	O
simultaneously	O
undergo-	O
ing	O
large	O
panning	O
motions	O
and	O
exposure	O
changes	O
,	O
which	O
is	O
a	O
common	O
occurrence	O
in	O
casually	O
acquired	O
panoramas	O
.	O
under	O
such	O
conditions	O
,	O
different	O
parts	O
of	O
the	O
image	B
may	O
be	O
seen	O
at	O
one	O
or	O
more	O
exposures	O
.	O
devising	O
a	O
method	O
to	O
blend	O
all	O
of	O
these	O
different	O
sources	O
while	O
avoid-	O
ing	O
sharp	O
transitions	O
and	O
dealing	O
with	O
scene	O
motion	B
is	O
a	O
challenging	O
problem	O
.	O
one	O
approach	O
is	O
to	O
ﬁrst	O
ﬁnd	O
a	O
consensus	O
mosaic	O
and	O
to	O
then	O
selectively	O
compute	O
radiances	O
in	O
under-	O
and	O
over-exposed	O
regions	O
(	O
eden	O
,	O
uyttendaele	O
,	O
and	O
szeliski	O
2006	O
)	O
,	O
as	O
shown	O
in	O
figure	O
10.17.	O
recently	O
,	O
some	O
cameras	O
,	O
such	O
as	O
the	O
sony	O
α550	O
and	O
pentax	O
k-7	O
,	O
have	O
started	O
integrating	O
multiple	B
exposure	O
merging	B
and	O
tone	B
mapping	I
directly	O
into	O
the	O
camera	B
body	O
.	O
in	O
the	O
future	O
,	O
the	O
need	O
to	O
compute	O
high	B
dynamic	I
range	I
images	O
from	O
multiple	B
exposures	O
may	O
be	O
eliminated	O
by	O
advances	O
in	O
camera	B
sensor	O
technology	O
(	O
figure	O
10.18	O
)	O
(	O
yang	O
,	O
el	O
gamal	O
,	O
fowler	O
et	O
al	O
.	O
1999	O
;	O
nayar	O
and	O
mitsunaga	O
2000	O
;	O
nayar	O
and	O
branzoi	O
2003	O
;	O
kang	O
,	O
uyttendaele	O
,	O
winder	O
et	O
al	O
.	O
2003	O
;	O
narasimhan	O
and	O
nayar	O
2005	O
;	O
tumblin	O
,	O
agrawal	O
,	O
and	O
raskar	O
2005	O
)	O
.	O
however	O
,	O
the	O
need	O
to	O
blend	O
such	O
images	O
and	O
to	O
tone	O
map	O
them	O
to	O
lower-gamut	O
displays	O
is	O
likely	O
to	O
remain	O
.	O
hdr	O
image	B
formats	O
.	O
before	O
we	O
discuss	O
techniques	O
for	O
mapping	O
hdr	O
images	O
back	O
to	O
a	O
displayable	O
gamut	O
,	O
we	O
should	O
discuss	O
the	O
commonly	O
used	O
formats	B
for	O
storing	O
hdr	O
images	O
.	O
if	O
storage	O
space	O
is	O
not	O
an	O
issue	O
,	O
storing	O
each	O
of	O
the	O
r	O
,	O
g	O
,	O
and	O
b	O
values	O
as	O
a	O
32-bit	O
ieee	O
ﬂoat	O
is	O
the	O
best	O
solution	O
.	O
the	O
commonly	O
used	O
portable	O
pixmap	O
(	O
.ppm	O
)	O
format	O
,	O
which	O
supports	O
both	O
uncompressed	O
ascii	O
and	O
raw	O
binary	O
encodings	O
of	O
values	O
,	O
can	O
be	O
extended	O
to	O
a	O
portable	O
floatmap	O
(	O
.pfm	O
)	O
format	O
by	O
modifying	O
the	O
header	O
.	O
tiff	O
also	O
supports	O
full	O
ﬂoating	O
point	O
values	O
.	O
a	O
more	O
compact	O
representation	O
is	O
the	O
radiance	O
format	O
(	O
.pic	O
,	O
.hdr	O
)	O
(	O
ward	O
1994	O
)	O
,	O
which	O
uses	O
a	O
single	O
common	O
exponent	O
and	O
per-channel	O
mantissas	O
(	O
10.19b	O
)	O
.	O
an	O
intermediate	O
encod-	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
487	O
figure	O
10.19	O
hdr	O
image	B
encoding	O
formats	B
:	O
(	O
a	O
)	O
portable	O
pixmap	O
(	O
.ppm	O
)	O
;	O
(	O
b	O
)	O
radiance	O
(	O
.pic	O
,	O
.hdr	O
)	O
;	O
(	O
c	O
)	O
openexr	O
(	O
.exr	O
)	O
.	O
ing	O
,	O
openexr	O
from	O
ilm,12	O
uses	O
16-bit	O
ﬂoats	O
for	O
each	O
channel	O
(	O
10.19c	O
)	O
,	O
which	O
is	O
a	O
format	O
supported	O
natively	O
on	O
most	O
modern	O
gpus	O
.	O
ward	O
(	O
2004	O
)	O
describes	O
these	O
and	O
other	O
data	O
for-	O
mats	O
such	O
as	O
logluv	O
(	O
larson	O
1998	O
)	O
in	O
more	O
detail	O
,	O
as	O
do	O
the	O
books	O
by	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
(	O
2005	O
)	O
and	O
freeman	O
(	O
2008	O
)	O
.	O
an	O
even	O
more	O
recent	O
hdr	O
image	B
format	O
is	O
the	O
jpeg	O
xr	O
standard.13	O
10.2.1	O
tone	B
mapping	I
once	O
a	O
radiance	O
map	O
has	O
been	O
computed	O
,	O
it	O
is	O
usually	O
necessary	O
to	O
display	O
it	O
on	O
a	O
lower	O
gamut	O
(	O
i.e.	O
,	O
eight-bit	O
)	O
screen	O
or	O
printer	O
.	O
a	O
variety	O
of	O
tone	B
mapping	I
techniques	O
has	O
been	O
developed	O
for	O
this	O
purpose	O
,	O
which	O
involve	O
either	O
computing	O
spatially	O
varying	O
transfer	O
functions	O
or	O
reducing	O
image	B
gradients	O
to	O
ﬁt	O
the	O
available	O
dynamic	B
range	O
(	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
2005	O
)	O
.	O
the	O
simplest	O
way	O
to	O
compress	O
a	O
high	B
dynamic	I
range	I
radiance	O
image	B
into	O
a	O
low	O
dynamic	B
range	O
gamut	O
is	O
to	O
use	O
a	O
global	B
transfer	O
curve	O
(	O
larson	O
,	O
rushmeier	O
,	O
and	O
piatko	O
1997	O
)	O
.	O
fig-	O
ure	O
10.20	O
shows	O
one	O
such	O
example	O
,	O
where	O
a	O
gamma	B
curve	O
is	O
used	O
to	O
map	O
an	O
hdr	O
image	B
back	O
12	O
http	O
:	O
//www.openexr.net/	O
.	O
13	O
http	O
:	O
//www.itu.int/rec/t-rec-t.832-200903-i/en	O
.	O
96	O
bits	O
/	O
pixelsignexponentmantissa	O
(	O
a	O
)	O
32	O
bits	O
/	O
pixelredgreenblueexponent	O
(	O
b	O
)	O
48	O
bits	O
/	O
pixelsignexponentmantissa	O
(	O
c	O
)	O
488	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
10.20	O
global	B
tone	O
mapping	O
:	O
(	O
a	O
)	O
input	O
hdr	O
image	B
,	O
linearly	O
mapped	O
;	O
(	O
b	O
)	O
gamma	B
applied	O
to	O
each	O
color	B
channel	O
independently	O
;	O
(	O
c	O
)	O
gamma	B
applied	O
to	O
intensity	O
(	O
colors	O
are	O
less	O
washed	O
out	O
)	O
.	O
original	O
hdr	O
image	B
courtesy	O
of	O
paul	O
debevec	O
,	O
http	O
:	O
//ict.debevec.org/	O
∼debevec/research/hdr/	O
.	O
processed	O
images	O
courtesy	O
of	O
fr´edo	O
durand	O
,	O
mit	O
6.815/6.865	O
course	O
on	O
computational	O
photography	O
.	O
into	O
a	O
displayable	O
gamut	O
.	O
if	O
gamma	B
is	O
applied	O
separately	O
to	O
each	O
channel	O
(	O
figure	O
10.20b	O
)	O
,	O
the	O
colors	O
become	O
muted	O
(	O
less	O
saturated	O
)	O
,	O
since	O
higher-valued	O
color	B
channels	O
contribute	O
less	O
(	O
pro-	O
portionately	O
)	O
to	O
the	O
ﬁnal	O
color	B
.	O
splitting	B
the	O
image	B
up	O
into	O
its	O
luminance	O
and	O
chrominance	O
(	O
say	O
,	O
l*a*b*	O
)	O
components	O
(	O
section	O
2.3.2	O
)	O
,	O
applying	O
the	O
global	B
mapping	O
to	O
the	O
luminance	O
channel	O
,	O
and	O
then	O
reconstituting	O
a	O
color	B
image	O
works	O
better	O
(	O
figure	O
10.20c	O
)	O
.	O
unfortunately	O
,	O
when	O
the	O
image	B
has	O
a	O
really	O
wide	O
range	O
of	O
exposures	O
,	O
this	O
global	B
approach	O
still	O
fails	O
to	O
preserve	O
details	O
in	O
regions	O
with	O
widely	O
varying	O
exposures	O
.	O
what	O
is	O
needed	O
,	O
in-	O
stead	O
,	O
is	O
something	O
akin	O
to	O
the	O
dodging	O
and	O
burning	O
performed	O
by	O
photographers	O
in	O
the	O
dark-	O
room	O
.	O
mathematically	O
,	O
this	O
is	O
similar	O
to	O
dividing	O
each	O
pixel	O
by	O
the	O
average	O
brightness	O
in	O
a	O
region	B
around	O
that	O
pixel	O
.	O
figure	O
10.21	O
shows	O
how	O
this	O
process	O
works	O
.	O
as	O
before	O
,	O
the	O
image	B
is	O
split	O
into	O
its	O
lumi-	O
nance	O
and	O
chrominance	O
channels	O
.	O
the	O
log	O
luminance	O
image	B
h	O
(	O
x	O
,	O
y	O
)	O
=	O
log	O
l	O
(	O
x	O
,	O
y	O
)	O
is	O
then	O
low-pass	B
ﬁltered	O
to	O
produce	O
a	O
base	O
layer	O
and	O
a	O
high-pass	O
detail	O
layer	O
hl	O
(	O
x	O
,	O
y	O
)	O
=	O
b	O
(	O
x	O
,	O
y	O
)	O
∗	O
h	O
(	O
x	O
,	O
y	O
)	O
,	O
hh	O
(	O
x	O
,	O
y	O
)	O
=	O
h	O
(	O
x	O
,	O
y	O
)	O
−	O
hl	O
(	O
x	O
,	O
y	O
)	O
.	O
(	O
10.12	O
)	O
(	O
10.13	O
)	O
(	O
10.14	O
)	O
the	O
base	O
layer	O
is	O
then	O
contrast	O
reduced	O
by	O
scaling	O
to	O
the	O
desired	O
log-luminance	O
range	O
,	O
h	O
(	O
cid:48	O
)	O
h	O
(	O
x	O
,	O
y	O
)	O
=	O
s	O
hh	O
(	O
x	O
,	O
y	O
)	O
(	O
10.15	O
)	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
and	O
added	O
to	O
the	O
detail	O
layer	O
to	O
produce	O
the	O
new	O
log-luminance	O
image	B
i	O
(	O
x	O
,	O
y	O
)	O
=	O
h	O
(	O
cid:48	O
)	O
h	O
(	O
x	O
,	O
y	O
)	O
+	O
hl	O
(	O
x	O
,	O
y	O
)	O
,	O
489	O
(	O
10.16	O
)	O
which	O
can	O
then	O
be	O
exponentiated	O
to	O
produce	O
the	O
tone-mapped	O
(	O
compressed	O
)	O
luminance	O
im-	O
age	O
.	O
note	O
that	O
this	O
process	O
is	O
equivalent	O
to	O
dividing	O
each	O
luminance	O
value	O
by	O
(	O
a	O
monotonic	O
mapping	O
of	O
)	O
the	O
average	O
log-luminance	O
value	O
in	O
a	O
region	B
around	O
that	O
pixel	O
.	O
figure	O
10.21	O
shows	O
the	O
low-pass	B
and	O
high-pass	O
log	O
luminance	O
image	B
and	O
the	O
resulting	O
tone-mapped	O
color	B
image	O
.	O
note	O
how	O
the	O
detail	O
layer	O
has	O
visible	O
halos	B
around	O
the	O
high-	O
contrast	O
edges	O
,	O
which	O
are	O
visible	O
in	O
the	O
ﬁnal	O
tone-mapped	O
image	B
.	O
this	O
is	O
because	O
linear	B
ﬁltering	O
,	O
which	O
is	O
not	O
edge	O
preserving	O
,	O
produces	O
halos	B
in	O
the	O
detail	O
layer	O
(	O
figure	O
10.23	O
)	O
.	O
the	O
solution	O
to	O
this	O
problem	O
is	O
to	O
use	O
an	O
edge-preserving	B
ﬁlter	O
to	O
create	O
the	O
base	O
layer	O
.	O
du-	O
rand	O
and	O
dorsey	O
(	O
2002	O
)	O
study	O
a	O
number	O
of	O
such	O
edge-preserving	B
ﬁlters	O
,	O
including	O
anisotropic	B
and	O
robust	B
anisotropic	O
diffusion	O
,	O
and	O
select	O
bilateral	B
ﬁltering	O
(	O
section	O
3.3.1	O
)	O
as	O
their	O
edge-	O
preserving	O
ﬁlter	O
.	O
(	O
a	O
more	O
recent	O
paper	O
by	O
farbman	O
,	O
fattal	O
,	O
lischinski	O
et	O
al	O
.	O
(	O
2008	O
)	O
argues	O
in	O
favor	O
of	O
using	O
a	O
weighted	B
least	O
squares	O
(	O
wlf	O
)	O
ﬁlter	O
as	O
an	O
alternative	O
to	O
the	O
bilateral	B
ﬁlter	I
and	O
paris	O
,	O
kornprobst	O
,	O
tumblin	O
et	O
al	O
.	O
(	O
2008	O
)	O
reviews	O
bilateral	B
ﬁltering	O
and	O
its	O
applications	O
in	O
computer	O
vision	O
and	O
computational	O
photography	O
.	O
)	O
figure	O
10.22	O
shows	O
how	O
replacing	O
the	O
linear	B
low-pass	O
ﬁlter	O
with	O
a	O
bilateral	B
ﬁlter	I
produces	O
tone-mapped	O
images	O
with	O
no	O
visible	O
ha-	O
los	O
.	O
figure	O
10.24	O
summarizes	O
the	O
complete	O
information	O
ﬂow	O
in	O
this	O
process	O
,	O
starting	O
with	O
the	O
decomposition	O
into	O
log	O
luminance	O
and	O
chrominance	O
images	O
,	O
bilateral	B
ﬁltering	O
,	O
contrast	O
reduction	O
,	O
and	O
re-composition	O
into	O
the	O
ﬁnal	O
output	O
image	B
.	O
an	O
alternative	O
to	O
compressing	O
the	O
base	O
layer	O
is	O
to	O
compress	O
its	O
derivatives	O
,	O
i.e.	O
,	O
the	O
gra-	O
dient	O
of	O
the	O
log-luminance	O
image	B
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
)	O
.	O
figure	O
10.25	O
illus-	O
trates	O
this	O
process	O
.	O
the	O
log-luminance	O
image	B
is	O
differentiated	O
to	O
obtain	O
a	O
gradient	O
image	O
this	O
gradient	O
image	O
is	O
then	O
attenuated	O
by	O
a	O
spatially	O
varying	O
attenuation	O
function	O
φ	O
(	O
x	O
,	O
y	O
)	O
,	O
h	O
(	O
cid:48	O
)	O
(	O
x	O
,	O
y	O
)	O
=	O
∇h	O
(	O
x	O
,	O
y	O
)	O
.	O
(	O
10.17	O
)	O
g	O
(	O
x	O
,	O
y	O
)	O
=	O
h	O
(	O
cid:48	O
)	O
(	O
x	O
,	O
y	O
)	O
φ	O
(	O
x	O
,	O
y	O
)	O
.	O
(	O
10.18	O
)	O
the	O
attenuation	O
function	O
i	O
(	O
x	O
,	O
y	O
)	O
is	O
designed	O
to	O
attenuate	O
large-scale	O
brightness	O
changes	O
(	O
fig-	O
ure	O
10.26a	O
)	O
and	O
is	O
designed	O
to	O
take	O
into	O
account	O
gradients	O
at	O
different	O
spatial	O
scales	O
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
)	O
.	O
after	O
attenuation	O
,	O
the	O
resulting	O
gradient	O
ﬁeld	O
is	O
re-integrated	O
by	O
solving	O
a	O
ﬁrst-order	O
vari-	O
ational	O
(	O
least	B
squares	I
)	O
problem	O
,	O
min	O
(	O
cid:90	O
)	O
(	O
cid:90	O
)	O
(	O
cid:107	O
)	O
∇i	O
(	O
x	O
,	O
y	O
)	O
−	O
g	O
(	O
x	O
,	O
y	O
)	O
(	O
cid:107	O
)	O
2dx	O
dy	O
(	O
10.19	O
)	O
490	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
10.21	O
local	B
tone	O
mapping	O
using	O
linear	O
ﬁlters	O
:	O
(	O
a	O
)	O
low-pass	B
and	O
high-pass	O
ﬁltered	O
log	O
luminance	O
images	O
and	O
color	B
(	O
chrominance	O
)	O
image	B
;	O
(	O
b	O
)	O
resulting	O
tone-mapped	O
image	B
(	O
after	O
at-	O
tenuating	O
the	O
low-pass	B
log	O
luminance	O
image	B
)	O
shows	O
visible	O
halos	B
around	O
the	O
trees	O
.	O
processed	O
images	O
courtesy	O
of	O
fr´edo	O
durand	O
,	O
mit	O
6.815/6.865	O
course	O
on	O
computational	O
photography	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
10.22	O
local	B
tone	O
mapping	O
using	O
bilateral	O
ﬁlter	O
(	O
durand	O
and	O
dorsey	O
2002	O
)	O
:	O
(	O
a	O
)	O
low-	O
pass	O
and	O
high-pass	O
bilateral	B
ﬁltered	O
log	O
luminance	O
images	O
and	O
color	B
(	O
chrominance	O
)	O
image	B
;	O
(	O
b	O
)	O
resulting	O
tone-mapped	O
image	B
(	O
after	O
attenuating	O
the	O
low-pass	B
log	O
luminance	O
image	B
)	O
shows	O
no	O
halos	B
.	O
processed	O
images	O
courtesy	O
of	O
fr´edo	O
durand	O
,	O
mit	O
6.815/6.865	O
course	O
on	O
compu-	O
tational	O
photography	O
.	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
491	O
figure	O
10.23	O
gaussian	O
vs.	O
bilateral	B
ﬁltering	O
(	O
petschnigg	O
,	O
agrawala	O
,	O
hoppe	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
a	O
gaussian	O
low-pass	B
ﬁlter	O
blurs	O
across	O
all	O
edges	O
and	O
therefore	O
creates	O
strong	O
peaks	O
and	O
valleys	O
in	O
the	O
detail	O
image	B
that	O
cause	O
halos	B
.	O
the	O
bilateral	B
ﬁlter	I
does	O
not	O
smooth	O
across	O
strong	O
edges	O
and	O
thereby	O
reduces	O
halos	B
while	O
still	O
capturing	O
detail	O
.	O
figure	O
10.24	O
local	B
tone	O
mapping	O
using	O
bilateral	O
ﬁlter	O
(	O
durand	O
and	O
dorsey	O
2002	O
)	O
:	O
sum-	O
mary	O
of	O
algorithm	B
workﬂow	O
.	O
images	O
courtesy	O
of	O
fr´edo	O
durand	O
,	O
mit	O
6.815/6.865	O
course	O
on	O
computational	O
photography	O
.	O
492	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.25	O
gradient	B
domain	I
tone	O
mapping	O
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
acm	O
.	O
the	O
original	O
image	B
with	O
a	O
dynamic	B
range	O
of	O
2415:1	O
is	O
ﬁrst	O
converted	O
into	O
the	O
log	O
domain	O
,	O
h	O
(	O
x	O
)	O
,	O
and	O
its	O
gradients	O
are	O
computed	O
,	O
h	O
(	O
cid:48	O
)	O
(	O
x	O
)	O
.	O
these	O
are	O
attenuated	O
(	O
compressed	O
)	O
based	O
on	O
local	B
contrast	O
,	O
g	O
(	O
x	O
)	O
,	O
and	O
integrated	O
to	O
produce	O
the	O
new	O
logarithmic	O
exposure	O
image	O
i	O
(	O
x	O
)	O
,	O
which	O
is	O
exponentiated	O
to	O
produce	O
the	O
ﬁnal	O
intensity	O
image	B
,	O
whose	O
dynamic	B
range	O
is	O
7.5:1.	O
to	O
obtain	O
the	O
compressed	O
log-luminance	O
image	B
i	O
(	O
x	O
,	O
y	O
)	O
.	O
this	O
least	B
squares	I
problem	O
is	O
the	O
same	O
that	O
was	O
used	O
for	O
poisson	O
blending	B
(	O
section	O
9.3.4	O
)	O
and	O
was	O
ﬁrst	O
introduced	O
in	O
our	O
study	O
of	O
regularization	B
(	O
section	O
3.7.1	O
,	O
3.100	O
)	O
.	O
it	O
can	O
efﬁciently	O
be	O
solved	O
using	O
techniques	O
such	O
as	O
multigrid	O
and	O
hierarchical	B
basis	O
preconditioning	O
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
;	O
szeliski	O
2006b	O
;	O
farbman	O
,	O
fattal	O
,	O
lischinski	O
et	O
al	O
.	O
2008	O
)	O
.	O
once	O
the	O
new	O
luminance	O
image	B
has	O
been	O
computed	O
,	O
it	O
is	O
combined	O
with	O
the	O
original	O
color	B
image	O
using	O
cout	O
=	O
(	O
cid:18	O
)	O
cin	O
lin	O
(	O
cid:19	O
)	O
s	O
lout	O
,	O
(	O
10.20	O
)	O
where	O
c	O
=	O
(	O
r	O
,	O
g	O
,	O
b	O
)	O
and	O
lin	O
and	O
lout	O
are	O
the	O
original	O
and	O
compressed	O
luminance	O
images	O
.	O
the	O
exponent	O
s	O
controls	O
the	O
saturation	O
of	O
the	O
colors	O
and	O
is	O
typically	O
in	O
the	O
range	O
s	O
∈	O
[	O
0.4	O
,	O
0.6	O
]	O
.	O
figure	O
10.26b	O
shows	O
the	O
ﬁnal	O
tone-mapped	O
color	B
image	O
,	O
which	O
shows	O
no	O
visible	O
halos	B
despite	O
the	O
extremely	O
large	O
variation	O
in	O
input	O
radiance	O
values	O
.	O
yet	O
another	O
alternative	O
to	O
these	O
two	O
approaches	O
is	O
to	O
perform	O
the	O
local	B
dodging	O
and	O
burn-	O
ing	O
using	O
a	O
locally	O
scale-selective	O
operator	O
(	O
reinhard	O
,	O
stark	O
,	O
shirley	O
et	O
al	O
.	O
2002	O
)	O
.	O
figure	O
10.27	O
shows	O
how	O
such	O
a	O
scale	B
selection	I
operator	O
can	O
determine	O
a	O
radius	O
(	O
scale	O
)	O
that	O
only	O
includes	O
logexpdiffint.compress2500:17.5:1h	O
(	O
x	O
)	O
i	O
(	O
x	O
)	O
h	O
’	O
(	O
x	O
)	O
g	O
(	O
x	O
)	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
493	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
10.26	O
gradient	B
domain	I
tone	O
mapping	O
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
acm	O
:	O
(	O
a	O
)	O
attenuation	O
map	O
,	O
with	O
darker	O
values	O
corresponding	O
to	O
more	O
attenuation	O
;	O
(	O
b	O
)	O
ﬁnal	O
tone-mapped	O
image	B
.	O
similar	O
color	B
values	O
within	O
the	O
inner	O
circle	O
while	O
avoiding	O
much	O
brighter	O
values	O
in	O
the	O
sur-	O
rounding	O
circle	O
.	O
in	O
practice	O
,	O
a	O
difference	B
of	O
gaussians	O
normalized	B
by	O
the	O
inner	O
gaussian	O
response	O
is	O
evaluated	O
over	O
a	O
range	O
of	O
scales	O
,	O
and	O
the	O
largest	O
scale	O
whose	O
metric	O
is	O
below	O
a	O
threshold	O
is	O
selected	O
(	O
reinhard	O
,	O
stark	O
,	O
shirley	O
et	O
al	O
.	O
2002	O
)	O
.	O
what	O
all	O
of	O
these	O
techniques	O
have	O
in	O
common	O
is	O
that	O
they	O
adaptively	O
attenuate	O
or	O
brighten	O
different	O
regions	O
of	O
the	O
image	B
so	O
that	O
they	O
can	O
be	O
displayed	O
in	O
a	O
limited	O
gamut	O
without	O
loss	O
of	O
contrast	O
.	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
(	O
2006b	O
)	O
introduce	O
an	O
interactive	B
technique	O
that	O
performs	O
this	O
operation	O
by	O
interpolating	O
a	O
set	O
of	O
sparse	B
user-drawn	O
adjustments	O
(	O
strokes	O
and	O
associated	O
exposure	O
value	O
corrections	O
)	O
to	O
a	O
piecewise-continuous	O
exposure	O
correction	O
map	O
(	O
figure	O
10.28	O
)	O
.	O
the	O
interpolation	B
is	O
performed	O
by	O
minimizing	O
a	O
locally	O
weighted	O
least	O
square	O
(	O
wls	O
)	O
variational	O
problem	O
,	O
min	O
(	O
cid:90	O
)	O
(	O
cid:90	O
)	O
wd	O
(	O
x	O
,	O
y	O
)	O
(	O
cid:107	O
)	O
f	O
(	O
x	O
,	O
y	O
)	O
−	O
g	O
(	O
x	O
,	O
y	O
)	O
(	O
cid:107	O
)	O
2dx	O
dy	O
+	O
λ	O
(	O
cid:90	O
)	O
(	O
cid:90	O
)	O
ws	O
(	O
x	O
,	O
y	O
)	O
(	O
cid:107	O
)	O
∇f	O
(	O
x	O
,	O
y	O
)	O
(	O
cid:107	O
)	O
2dx	O
dy	O
,	O
(	O
10.21	O
)	O
where	O
g	O
(	O
x	O
,	O
y	O
)	O
and	O
f	O
(	O
x	O
,	O
y	O
)	O
are	O
the	O
input	O
and	O
output	O
log	O
exposure	O
(	O
attenuation	O
)	O
maps	O
(	O
fig-	O
ure	O
10.28	O
)	O
.	O
the	O
data	O
weighting	O
term	O
wd	O
(	O
x	O
,	O
y	O
)	O
is	O
1	O
at	O
stroke	O
locations	O
and	O
0	O
elsewhere	O
.	O
the	O
smoothness	B
weighting	O
term	O
ws	O
(	O
x	O
,	O
y	O
)	O
is	O
inversely	O
proportional	O
to	O
the	O
log-luminance	O
gradient	O
,	O
1	O
(	O
cid:107	O
)	O
∇h	O
(	O
cid:107	O
)	O
α	O
+	O
	O
and	O
hence	O
encourages	O
the	O
f	O
(	O
x	O
,	O
y	O
)	O
map	O
to	O
be	O
smoother	O
in	O
low-gradient	O
areas	O
than	O
along	O
high-	O
gradient	O
discontinuities.14	O
the	O
same	O
approach	O
can	O
also	O
be	O
used	O
for	O
fully	O
automated	B
tone	O
map-	O
14	O
in	O
practice	O
,	O
the	O
x	O
and	O
y	O
discrete	B
derivatives	O
are	O
weighted	B
separately	O
(	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
ws	O
=	O
(	O
10.22	O
)	O
494	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.27	O
scale	B
selection	I
for	O
tone	B
mapping	I
(	O
reinhard	O
,	O
stark	O
,	O
shirley	O
et	O
al	O
.	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
acm	O
.	O
ping	O
by	O
setting	O
target	O
exposure	O
values	O
at	O
each	O
pixel	O
and	O
allowing	O
the	O
weighted	B
least	O
squares	O
to	O
convert	O
these	O
into	O
piecewise	O
smooth	O
adjustment	O
maps	O
.	O
the	O
weighted	B
least	O
squares	O
algorithm	B
,	O
which	O
was	O
originally	O
developed	O
for	O
image	O
coloriza-	O
tion	B
applications	O
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2004	O
)	O
,	O
has	O
recently	O
been	O
applied	O
to	O
general	O
edge-preserving	B
smoothing	O
in	O
applications	O
such	O
as	O
contrast	O
enhancement	O
(	O
bae	O
,	O
paris	O
,	O
and	O
durand	O
2006	O
)	O
and	O
tone	B
mapping	I
(	O
farbman	O
,	O
fattal	O
,	O
lischinski	O
et	O
al	O
.	O
2008	O
)	O
where	O
the	O
bilateral	B
ﬁltering	O
was	O
previously	O
used	O
.	O
it	O
can	O
also	O
be	O
used	O
to	O
perform	O
hdr	O
merging	B
and	O
tone	B
mapping	I
simultaneously	O
(	O
raman	O
and	O
chaudhuri	O
2007	O
,	O
2009	O
)	O
.	O
given	O
the	O
wide	O
range	O
of	O
locally	B
adaptive	I
tone	O
mapping	O
algorithms	O
that	O
have	O
been	O
devel-	O
oped	O
,	O
which	O
ones	O
should	O
be	O
used	O
in	O
practice	O
?	O
freeman	O
(	O
2008	O
)	O
provides	O
a	O
great	O
discussion	O
of	O
commercially	O
available	O
algorithms	O
,	O
their	O
artifacts	O
,	O
and	O
the	O
parameters	B
that	O
can	O
be	O
used	O
to	O
control	O
them	O
.	O
he	O
also	O
has	O
a	O
wealth	O
of	O
tips	O
for	O
hdr	O
photography	O
and	O
workﬂow	O
.	O
i	O
highly	O
rec-	O
ommend	O
his	O
book	O
for	O
anyone	O
contemplating	O
additional	O
research	O
(	O
or	O
personal	O
photography	O
)	O
in	O
this	O
area	O
.	O
10.2.2	O
application	O
:	O
flash	O
photography	O
while	O
high	B
dynamic	I
range	I
imaging	O
combines	O
images	O
of	O
a	O
scene	O
taken	O
at	O
different	O
exposures	O
,	O
it	O
is	O
also	O
possible	O
to	O
combine	O
ﬂash	B
and	I
non-ﬂash	I
images	O
to	O
achieve	O
better	O
exposure	O
and	O
color	B
balance	I
and	O
to	O
reduce	O
noise	B
(	O
eisemann	O
and	O
durand	O
2004	O
;	O
petschnigg	O
,	O
agrawala	O
,	O
hoppe	O
et	O
al	O
.	O
2004	O
)	O
.	O
the	O
problem	O
with	O
ﬂash	O
images	O
is	O
that	O
the	O
color	B
is	O
often	O
unnatural	O
(	O
it	O
fails	O
to	O
capture	O
the	O
ambient	O
illumination	O
)	O
,	O
there	O
may	O
be	O
strong	O
shadows	O
or	O
specularities	B
,	O
and	O
there	O
is	O
a	O
radial	B
falloff	O
in	O
brightness	O
away	O
from	O
the	O
camera	B
(	O
figures	O
10.1b	O
and	O
10.29a	O
)	O
.	O
non-ﬂash	O
photos	O
2006b	O
)	O
.	O
their	O
default	O
parameter	O
settings	O
are	O
λ	O
=	O
0.2	O
,	O
α	O
=	O
1	O
,	O
and	O
	O
=	O
0.0001	O
.	O
10.2	O
high	B
dynamic	I
range	I
imaging	O
495	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
10.28	O
interactive	B
local	O
tone	B
mapping	I
(	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
2006b	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
acm	O
:	O
(	O
a	O
)	O
user-drawn	O
strokes	O
with	O
associated	O
exposure	O
values	O
g	O
(	O
x	O
,	O
y	O
)	O
(	O
b	O
)	O
correspond-	O
ing	O
piecewise-smooth	O
exposure	O
adjustment	O
map	O
f	O
(	O
x	O
,	O
y	O
)	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
10.29	O
detail	O
transfer	B
in	O
ﬂash/no-ﬂash	O
photography	O
(	O
petschnigg	O
,	O
agrawala	O
,	O
hoppe	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
(	O
a	O
)	O
details	O
of	O
input	O
ambient	O
a	O
and	O
ﬂash	B
f	O
images	O
;	O
(	O
b	O
)	O
joint	B
bilaterally	O
ﬁltered	O
no-ﬂash	O
image	B
anr	O
;	O
(	O
c	O
)	O
detail	O
layer	O
f	O
detail	O
computed	O
from	O
the	O
ﬂash	B
image	O
f	O
;	O
(	O
d	O
)	O
ﬁnal	O
merged	O
image	B
afinal	O
.	O
496	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
taken	O
under	O
low	O
light	O
conditions	O
often	O
suffer	O
from	O
excessive	O
noise	B
(	O
because	O
of	O
the	O
high	O
iso	O
gains	O
and	O
low	O
photon	O
counts	O
)	O
and	O
blur	O
(	O
due	O
to	O
longer	O
exposures	O
)	O
.	O
is	O
there	O
some	O
way	O
to	O
combine	O
a	O
non-ﬂash	O
photo	O
taken	O
just	O
before	O
the	O
ﬂash	B
goes	O
off	O
with	O
the	O
ﬂash	B
photo	O
to	O
produce	O
an	O
image	B
with	O
good	O
color	B
values	O
,	O
sharpness	O
,	O
and	O
low	O
noise	B
?	O
15	O
petschnigg	O
,	O
agrawala	O
,	O
hoppe	O
et	O
al	O
.	O
(	O
2004	O
)	O
approach	O
this	O
problem	O
by	O
ﬁrst	O
ﬁltering	O
the	O
no-	O
ﬂash	B
(	O
ambient	O
)	O
image	B
a	O
with	O
a	O
variant	O
of	O
the	O
bilateral	B
ﬁlter	I
called	O
the	O
joint	B
bilateral	O
ﬁlter16	O
in	O
which	O
the	O
range	B
kernel	I
(	O
3.36	O
)	O
r	O
(	O
i	O
,	O
j	O
,	O
k	O
,	O
l	O
)	O
=	O
exp	O
(	O
cid:18	O
)	O
−	O
(	O
cid:107	O
)	O
f	O
(	O
i	O
,	O
j	O
)	O
−	O
f	O
(	O
k	O
,	O
l	O
)	O
(	O
cid:107	O
)	O
2	O
2σ2	O
r	O
(	O
cid:19	O
)	O
(	O
10.23	O
)	O
is	O
evaluated	O
on	O
the	O
ﬂash	B
image	O
f	O
instead	O
of	O
the	O
ambient	O
image	B
a	O
,	O
since	O
the	O
ﬂash	B
image	O
is	O
less	O
noisy	O
and	O
hence	O
has	O
more	O
reliable	O
edges	O
(	O
figure	O
10.29b	O
)	O
.	O
because	O
the	O
contents	O
of	O
the	O
ﬂash	B
image	O
can	O
be	O
unreliable	O
inside	O
and	O
at	O
the	O
boundaries	O
of	O
shadows	O
and	O
specularities	B
,	O
these	O
are	O
detected	O
and	O
a	O
regular	O
bilaterally	O
ﬁltered	O
image	B
abase	O
is	O
used	O
instead	O
(	O
figure	O
10.30	O
)	O
.	O
the	O
second	O
stage	O
of	O
their	O
algorithm	B
computes	O
a	O
ﬂash	B
detail	O
image	B
f	O
detail	O
=	O
f	O
+	O
	O
f	O
base	O
+	O
	O
,	O
(	O
10.24	O
)	O
where	O
f	O
base	O
is	O
a	O
bilaterally	O
ﬁltered	O
version	O
of	O
the	O
ﬂash	B
image	O
f	O
and	O
	O
=	O
0.02.	O
this	O
detail	O
im-	O
age	O
(	O
figure	O
10.29c	O
)	O
encodes	O
details	O
that	O
may	O
have	O
been	O
ﬁltered	O
away	O
from	O
the	O
noise-reduced	O
no-ﬂash	O
image	B
anr	O
,	O
as	O
well	O
as	O
additional	O
details	O
created	O
by	O
the	O
ﬂash	B
camera	O
,	O
which	O
often	O
add	O
crispness	O
.	O
the	O
detail	O
image	B
is	O
used	O
to	O
modulate	O
the	O
noise-reduced	O
ambient	O
image	B
anr	O
to	O
produce	O
the	O
ﬁnal	O
results	O
afinal	O
=	O
(	O
1	O
−	O
m	O
)	O
anrf	O
detail	O
+	O
m	O
abase	O
(	O
10.25	O
)	O
shown	O
in	O
figures	O
10.1b	O
and	O
10.29d	O
.	O
eisemann	O
and	O
durand	O
(	O
2004	O
)	O
present	O
an	O
alternative	O
algorithm	B
that	O
shares	O
some	O
of	O
the	O
same	O
basic	O
concepts	O
.	O
both	O
papers	O
are	O
well	O
worth	O
reading	O
and	O
contrasting	O
(	O
exercise	O
10.6	O
)	O
.	O
flash	O
images	O
can	O
also	O
be	O
used	O
for	O
a	O
variety	O
of	O
additional	O
applications	O
such	O
as	O
extracting	O
more	O
reliable	O
foreground	O
mattes	O
of	O
objects	O
(	O
raskar	O
,	O
tan	O
,	O
feris	O
et	O
al	O
.	O
2004	O
;	O
sun	O
,	O
li	O
,	O
kang	O
et	O
al	O
.	O
2006	O
)	O
.	O
flash	O
photography	O
is	O
just	O
one	O
instance	B
of	O
the	O
more	O
general	O
topic	O
of	O
active	B
illumination	I
,	O
which	O
is	O
discussed	O
in	O
more	O
detail	O
by	O
raskar	O
and	O
tumblin	O
(	O
2010	O
)	O
.	O
15	O
in	O
fact	O
,	O
the	O
discontinued	O
fujifilm	O
finepix	O
f40fd	O
camera	B
takes	O
a	O
pair	O
of	O
ﬂash	O
and	O
no	O
ﬂash	B
images	O
in	O
quick	O
succession	O
;	O
however	O
,	O
it	O
only	O
lets	O
you	O
decide	O
to	O
keep	O
one	O
of	O
them	O
.	O
16	O
eisemann	O
and	O
durand	O
(	O
2004	O
)	O
call	O
this	O
the	O
cross	O
bilateral	B
ﬁlter	I
.	O
10.3	O
super-resolution	O
and	O
blur	B
removal	I
497	O
figure	O
10.30	O
flash/no-ﬂash	O
photography	O
algorithm	B
(	O
petschnigg	O
,	O
agrawala	O
,	O
hoppe	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
.	O
the	O
ambient	O
(	O
no-ﬂash	O
)	O
image	B
a	O
is	O
ﬁltered	O
with	O
a	O
regular	O
bilateral	B
ﬁlter	I
to	O
produce	O
abase	O
,	O
which	O
is	O
used	O
in	O
shadow	B
and	O
specularity	O
regions	O
,	O
and	O
a	O
joint	B
bilaterally	O
ﬁltered	O
noise	B
reduced	O
image	B
anr	O
.	O
the	O
ﬂash	B
image	O
f	O
is	O
bilaterally	O
ﬁltered	O
to	O
produce	O
a	O
base	O
image	B
f	O
base	O
and	O
a	O
detail	O
(	O
ratio	O
)	O
image	B
f	O
detail	O
,	O
which	O
is	O
used	O
to	O
modulate	O
the	O
de-	O
noised	O
ambient	O
image	B
.	O
the	O
shadow/specularity	O
mask	B
m	O
is	O
computed	O
by	O
comparing	O
linearized	O
versions	O
of	O
the	O
ﬂash	O
and	O
no-ﬂash	O
images	O
.	O
10.3	O
super-resolution	O
and	O
blur	B
removal	I
while	O
high	B
dynamic	I
range	I
imaging	O
enables	O
us	O
to	O
obtain	O
an	O
image	B
with	O
a	O
larger	O
dynamic	B
range	O
than	O
a	O
single	O
regular	O
image	B
,	O
super-resolution	O
enables	O
us	O
to	O
create	O
images	O
with	O
higher	O
spatial	O
resolution	O
and	O
less	O
noise	B
than	O
regular	O
camera	B
images	O
(	O
chaudhuri	O
2001	O
;	O
park	O
,	O
park	O
,	O
and	O
kang	O
2003	O
;	O
capel	O
and	O
zisserman	O
2003	O
;	O
capel	O
2004	O
;	O
van	O
ouwerkerk	O
2006	O
)	O
.	O
most	O
com-	O
monly	O
,	O
super-resolution	O
refers	O
to	O
the	O
process	O
of	O
aligning	O
and	O
combining	O
several	O
input	O
images	O
to	O
produce	O
such	O
high-resolution	O
composites	O
(	O
irani	O
and	O
peleg	O
1991	O
;	O
cheeseman	O
,	O
kanefsky	O
,	O
hanson	O
et	O
al	O
.	O
1993	O
;	O
pickup	O
,	O
capel	O
,	O
roberts	O
et	O
al	O
.	O
2009	O
)	O
.	O
however	O
,	O
some	O
newer	O
techniques	O
can	O
super-resolve	O
a	O
single	O
image	O
(	O
freeman	O
,	O
jones	O
,	O
and	O
pasztor	O
2002	O
;	O
baker	O
and	O
kanade	O
2002	O
;	O
fattal	O
2007	O
)	O
and	O
are	O
hence	O
closely	O
related	O
to	O
techniques	O
for	O
removing	O
blur	O
(	O
sections	O
3.4.3	O
and	O
3.4.4	O
)	O
.	O
the	O
most	O
principled	O
way	O
to	O
formulate	O
the	O
super-resolution	O
problem	O
is	O
to	O
write	O
down	O
the	O
stochastic	O
image	O
formation	O
equations	B
and	O
image	B
priors	O
and	O
to	O
then	O
use	O
bayesian	O
inference	B
to	O
recover	O
the	O
super-resolved	O
(	O
original	O
)	O
sharp	O
image	B
.	O
we	O
can	O
do	O
this	O
by	O
generalizing	O
the	O
image	B
498	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
formation	O
equations	B
(	O
3.75	O
)	O
used	O
for	O
image	O
deblurring	O
(	O
section	O
3.4.3	O
)	O
,	O
which	O
we	O
also	O
used	O
in	O
(	O
10.2	O
)	O
for	O
blur	O
kernel	B
(	O
psf	O
)	O
estimation	B
(	O
section	O
10.1.4	O
)	O
.	O
in	O
this	O
case	O
,	O
we	O
have	O
several	O
ob-	O
served	O
images	O
{	O
ok	O
(	O
x	O
)	O
}	O
,	O
as	O
well	O
as	O
an	O
image	B
warping	O
function	O
ˆhk	O
(	O
x	O
)	O
for	O
each	O
observed	O
image	B
(	O
figure	O
3.47	O
)	O
.	O
combining	O
all	O
of	O
these	O
elements	O
,	O
we	O
get	O
the	O
(	O
noisy	O
)	O
observation	O
equations17	O
ok	O
(	O
x	O
)	O
=	O
d	O
{	O
b	O
(	O
x	O
)	O
∗	O
s	O
(	O
ˆhk	O
(	O
x	O
)	O
)	O
}	O
+	O
nk	O
(	O
x	O
)	O
,	O
(	O
10.26	O
)	O
where	O
d	O
is	O
the	O
downsampling	O
operator	O
,	O
which	O
operates	O
after	O
the	O
super-resolved	O
(	O
sharp	O
)	O
warped	O
image	B
s	O
(	O
ˆhk	O
(	O
x	O
)	O
)	O
has	O
been	O
convolved	O
with	O
the	O
blur	O
kernel	O
b	O
(	O
x	O
)	O
.	O
the	O
above	O
image	B
formation	O
equations	B
lead	O
to	O
the	O
following	O
least	B
squares	I
problem	O
,	O
(	O
cid:107	O
)	O
ok	O
(	O
x	O
)	O
−	O
d	O
{	O
bk	O
(	O
x	O
)	O
∗	O
s	O
(	O
ˆhk	O
(	O
x	O
)	O
)	O
}	O
(	O
cid:107	O
)	O
2	O
.	O
(	O
10.27	O
)	O
(	O
cid:88	O
)	O
k	O
in	O
most	O
super-resolution	O
algorithms	O
,	O
the	O
alignment	B
(	O
warping	O
)	O
ˆhk	O
is	O
estimated	O
using	O
one	O
of	O
the	O
input	O
frames	O
as	O
the	O
reference	O
frame	O
;	O
either	O
feature-based	B
(	O
section	O
6.1.3	O
)	O
or	O
direct	B
(	O
image-	O
based	O
)	O
(	O
section	O
8.2	O
)	O
parametric	B
alignment	O
techniques	O
can	O
be	O
used	O
.	O
(	O
a	O
few	O
algorithms	O
,	O
such	O
as	O
those	O
described	O
by	O
schultz	O
and	O
stevenson	O
(	O
1996	O
)	O
or	O
capel	O
(	O
2004	O
)	O
use	O
dense	O
(	O
per-pixel	O
ﬂow	O
)	O
estimates	O
.	O
)	O
a	O
better	O
approach	O
is	O
to	O
re-compute	O
the	O
alignment	B
by	O
directly	O
minimizing	O
(	O
10.27	O
)	O
once	O
an	O
initial	O
estimate	O
of	O
s	O
(	O
x	O
)	O
has	O
been	O
computed	O
(	O
hardie	O
,	O
barnard	O
,	O
and	O
armstrong	O
1997	O
)	O
or	O
to	O
marginalize	O
out	O
the	O
motion	B
parameters	O
altogether	O
(	O
pickup	O
,	O
capel	O
,	O
roberts	O
et	O
al	O
.	O
2007	O
)	O
—see	O
also	O
the	O
work	O
of	O
protter	O
and	O
elad	O
(	O
2009	O
)	O
for	O
some	O
related	O
video	B
super-resolution	O
work	O
.	O
the	O
point	B
spread	I
function	I
(	O
blur	O
kernel	O
)	O
bk	O
is	O
either	O
inferred	O
from	O
knowledge	O
of	O
the	O
image	B
formation	O
process	O
(	O
e.g.	O
,	O
the	O
amount	O
of	O
motion	B
or	O
defocus	O
blur	O
and	O
the	O
camera	B
sensor	O
optics	B
)	O
or	O
calibrated	O
from	O
a	O
test	O
image	O
or	O
the	O
observed	O
images	O
{	O
ok	O
}	O
using	O
one	O
of	O
the	O
techniques	O
described	O
in	O
section	O
10.1.4.	O
the	O
problem	O
of	O
simultaneously	O
inferring	O
the	O
blur	O
kernel	O
and	O
the	O
sharp	O
image	B
is	O
known	O
as	O
blind	O
image	B
deconvolution	O
(	O
kundur	O
and	O
hatzinakos	O
1996	O
;	O
levin	O
2006	O
)	O
.18	O
given	O
an	O
estimate	O
of	O
ˆhk	O
and	O
bk	O
(	O
x	O
)	O
,	O
(	O
10.27	O
)	O
can	O
be	O
re-written	O
using	O
matrix/vector	O
notation	O
as	O
a	O
large	O
sparse	O
least	B
squares	I
problem	O
in	O
the	O
unknown	O
values	O
of	O
the	O
super-resolved	O
pixels	O
s	O
,	O
(	O
cid:88	O
)	O
k	O
(	O
cid:107	O
)	O
ok	O
−	O
dbkw	O
ks	O
(	O
cid:107	O
)	O
2	O
.	O
(	O
10.28	O
)	O
17	O
it	O
is	O
also	O
possible	O
to	O
add	O
an	O
unknown	O
bias–gain	O
term	O
to	O
each	O
observation	O
(	O
capel	O
2004	O
)	O
,	O
as	O
was	O
done	O
for	O
motion	O
estimation	B
in	O
(	O
8.8	O
)	O
.	O
18	O
notice	O
that	O
there	O
is	O
a	O
chicken-and-egg	O
problem	O
if	O
both	O
the	O
blur	O
kernel	O
and	O
the	O
super-resolved	O
image	B
are	O
un-	O
known	O
.	O
this	O
can	O
be	O
“	O
broken	O
”	O
either	O
using	O
structural	O
assumptions	O
about	O
the	O
sharp	O
image	B
,	O
e.g.	O
,	O
the	O
presence	O
of	O
edges	O
(	O
joshi	O
,	O
szeliski	O
,	O
and	O
kriegman	O
2008	O
)	O
or	O
prior	B
models	O
for	O
the	O
image	B
,	O
such	O
as	O
edge	O
sparsity	O
(	O
fergus	O
,	O
singh	O
,	O
hertzmann	O
et	O
al	O
.	O
2006	O
)	O
.	O
10.3	O
super-resolution	O
and	O
blur	B
removal	I
499	O
(	O
recall	B
from	O
(	O
3.89	O
)	O
that	O
once	O
the	O
warping	O
function	O
ˆhk	O
is	O
known	O
,	O
values	O
of	O
s	O
(	O
ˆhk	O
(	O
x	O
)	O
)	O
depend	O
linearly	O
on	O
those	O
in	O
s	O
(	O
x	O
)	O
.	O
)	O
an	O
efﬁcient	O
way	O
to	O
solve	O
this	O
least	B
squares	I
problem	O
is	O
to	O
use	O
preconditioned	B
conjugate	O
gradient	B
descent	I
(	O
capel	O
2004	O
)	O
,	O
although	O
some	O
earlier	O
algorithms	O
,	O
such	O
as	O
the	O
one	O
developed	O
by	O
irani	O
and	O
peleg	O
(	O
1991	O
)	O
,	O
used	O
regular	O
gradient	B
descent	I
(	O
also	O
known	O
as	O
iterative	B
back	O
projection	O
(	O
ibp	O
)	O
,	O
in	O
the	O
computed	O
tomography	O
literature	O
)	O
.	O
the	O
above	O
formulation	O
assumes	O
that	O
warping	O
can	O
be	O
expressed	O
as	O
a	O
simple	O
(	O
sinc	B
or	O
bicu-	O
bic	O
)	O
interpolated	O
resampling	O
of	O
the	O
super-resolved	O
sharp	O
image	B
,	O
followed	O
by	O
a	O
stationary	O
(	O
spatially	O
invariant	O
)	O
blurring	O
(	O
psf	O
)	O
and	O
area	O
integration	O
process	O
.	O
however	O
,	O
if	O
the	O
surface	B
is	O
severely	O
foreshortened	O
,	O
we	O
have	O
to	O
take	O
into	O
account	O
the	O
spatially	O
varying	O
ﬁltering	O
that	O
occurs	O
during	O
the	O
image	B
warping	O
(	O
section	O
3.6.1	O
)	O
,	O
before	O
we	O
can	O
then	O
model	O
the	O
psf	O
induced	O
by	O
the	O
optics	B
and	O
camera	B
sensor	O
(	O
wang	O
,	O
kang	O
,	O
szeliski	O
et	O
al	O
.	O
2001	O
;	O
capel	O
2004	O
)	O
.	O
how	O
well	O
does	O
this	O
least	B
squares	I
(	O
mle	O
)	O
approach	O
to	O
super-resolution	O
work	O
?	O
in	O
practice	O
,	O
this	O
depends	O
a	O
lot	O
on	O
the	O
amount	O
of	O
blur	O
and	O
aliasing	B
in	O
the	O
camera	B
optics	O
,	O
as	O
well	O
as	O
the	O
accu-	O
racy	O
in	O
the	O
motion	B
and	O
psf	O
estimates	O
(	O
baker	O
and	O
kanade	O
2002	O
;	O
jiang	O
,	O
wong	O
,	O
and	O
bao	O
2003	O
;	O
capel	O
2004	O
)	O
.	O
less	O
blurring	O
and	O
more	O
aliasing	B
means	O
that	O
there	O
is	O
more	O
(	O
aliased	O
)	O
high	O
fre-	O
quency	O
information	O
available	O
to	O
be	O
recovered	O
.	O
however	O
,	O
because	O
the	O
least	B
squares	I
(	O
maximum	O
likelihood	O
)	O
formulation	O
uses	O
no	O
image	B
prior	O
,	O
a	O
lot	O
of	O
high-frequency	O
noise	B
can	O
be	O
introduced	O
into	O
the	O
solution	O
(	O
figure	O
10.31c	O
)	O
.	O
for	O
this	O
reason	O
,	O
most	O
super-resolution	O
algorithms	O
assume	O
some	O
form	O
of	O
image	B
prior	O
.	O
the	O
simplest	O
of	O
these	O
is	O
to	O
place	O
a	O
penalty	O
on	O
the	O
image	B
derivatives	O
similar	O
to	O
equations	B
(	O
3.105	O
and	O
3.113	O
)	O
,	O
e.g.	O
,	O
(	O
cid:88	O
)	O
(	O
i	O
,	O
j	O
)	O
ρp	O
(	O
s	O
(	O
i	O
,	O
j	O
)	O
−	O
s	O
(	O
i	O
+	O
1	O
,	O
j	O
)	O
)	O
+	O
ρp	O
(	O
s	O
(	O
i	O
,	O
j	O
)	O
−	O
s	O
(	O
i	O
,	O
j	O
+	O
1	O
)	O
)	O
.	O
(	O
10.29	O
)	O
as	O
discussed	O
in	O
section	O
3.7.2	O
,	O
when	O
ρp	O
is	O
quadratic	O
,	O
this	O
is	O
a	O
form	O
of	O
tikhonov	O
regulariza-	O
tion	B
(	O
section	O
3.7.1	O
)	O
,	O
and	O
the	O
overall	O
problem	O
is	O
still	O
linear	B
least	O
squares	O
.	O
the	O
resulting	O
prior	B
image	O
model	O
is	O
a	O
gaussian	O
markov	O
random	O
ﬁeld	O
(	O
gmrf	O
)	O
,	O
which	O
can	O
be	O
extended	O
to	O
other	O
(	O
e.g.	O
,	O
diagonal	O
)	O
differences	O
,	O
as	O
in	O
(	O
capel	O
2004	O
)	O
(	O
figure	O
10.31	O
)	O
.	O
unfortunately	O
,	O
gmrfs	O
tend	O
to	O
produce	O
solutions	O
with	O
visible	O
ripples	O
,	O
which	O
can	O
also	O
be	O
interpreted	O
as	O
increased	O
noise	B
sensitivity	O
in	O
middle	O
frequencies	O
(	O
exercise	O
3.17	O
)	O
.	O
a	O
bet-	O
ter	O
image	B
prior	O
is	O
a	O
robust	B
prior	O
that	O
encourages	O
piecewise	O
continuous	O
solutions	O
(	O
black	O
and	O
rangarajan	O
1996	O
)	O
,	O
see	O
appendix	O
b.3	O
.	O
examples	B
of	O
such	O
priors	O
include	O
the	O
huber	O
potential	O
(	O
schultz	O
and	O
stevenson	O
1996	O
;	O
capel	O
and	O
zisserman	O
2003	O
)	O
,	O
which	O
is	O
a	O
blend	O
of	O
a	O
gaussian	O
with	O
a	O
longer-tailed	O
laplacian	O
,	O
and	O
the	O
even	O
sparser	O
(	O
heavier-tailed	O
)	O
hyper-laplacians	O
used	O
by	O
levin	O
,	O
fergus	O
,	O
durand	O
et	O
al	O
.	O
(	O
2007	O
)	O
and	O
krishnan	O
and	O
fergus	O
(	O
2009	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
learn	O
the	O
parameters	B
for	O
such	O
priors	O
using	O
cross-validation	O
(	O
capel	O
2004	O
;	O
pickup	O
2007	O
)	O
.	O
while	O
sparse	B
(	O
robust	B
)	O
derivative	O
priors	O
can	O
reduce	O
rippling	O
effects	O
and	O
increase	O
edge	O
sharpness	O
,	O
they	O
can	O
not	O
hallucinate	O
higher-frequency	O
texture	B
or	O
details	O
.	O
to	O
do	O
this	O
,	O
a	O
train-	O
500	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
e	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
(	O
f	O
)	O
figure	O
10.31	O
super-resolution	O
results	O
using	O
a	O
variety	O
of	O
image	B
priors	O
(	O
capel	O
2001	O
)	O
:	O
(	O
a	O
)	O
low-	O
res	O
roi	O
(	O
bicubic	B
3×	O
zoom	O
)	O
;	O
(	O
b	O
)	O
average	O
image	B
;	O
(	O
c	O
)	O
mle	O
@	O
1.25×	O
pixel-zoom	O
;	O
(	O
d	O
)	O
simple	O
(	O
cid:107	O
)	O
x	O
(	O
cid:107	O
)	O
2	O
prior	B
(	O
λ	O
=	O
0.004	O
)	O
;	O
(	O
e	O
)	O
gmrf	O
(	O
λ	O
=	O
0.003	O
)	O
;	O
(	O
f	O
)	O
hmrf	O
(	O
λ	O
=	O
0.01	O
,	O
α	O
=	O
0.04	O
)	O
.	O
10	O
images	O
are	O
used	O
as	O
input	O
and	O
a	O
3×	O
super-resolved	O
image	B
is	O
produced	O
in	O
each	O
case	O
,	O
except	O
for	O
the	O
mle	O
result	O
in	O
(	O
c	O
)	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
10.32	O
example-based	B
super-resolution	O
:	O
(	O
a	O
)	O
original	O
32	O
×	O
32	O
low-resolution	O
image	B
;	O
(	O
b	O
)	O
example-based	B
super-resolved	O
256	O
×	O
256	O
image	B
(	O
freeman	O
,	O
jones	O
,	O
and	O
pasztor	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
ieee	O
;	O
(	O
c	O
)	O
upsampling	O
via	O
imposed	O
edge	O
statistics	O
(	O
fattal	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
acm	O
.	O
10.3	O
super-resolution	O
and	O
blur	B
removal	I
501	O
ing	O
set	O
of	O
sample	O
images	O
can	O
be	O
used	O
to	O
ﬁnd	O
plausible	O
mappings	O
between	O
low-frequency	O
originals	O
and	O
the	O
missing	O
higher	O
frequencies	O
.	O
inspired	O
by	O
some	O
of	O
the	O
example-based	B
texture	O
synthesis	O
algorithms	O
we	O
discuss	O
in	O
section	O
10.5	O
,	O
the	O
example-based	B
super-resolution	O
algo-	O
rithm	O
developed	O
by	O
freeman	O
,	O
jones	O
,	O
and	O
pasztor	O
(	O
2002	O
)	O
uses	O
training	O
images	O
to	O
learn	O
the	O
mapping	O
between	O
local	B
texture	O
patches	O
and	O
missing	O
higher-frequency	O
details	O
.	O
to	O
ensure	O
that	O
overlapping	O
patches	O
are	O
similar	O
in	O
appearance	O
,	O
a	O
markov	O
random	O
ﬁeld	O
is	O
used	O
and	O
optimized	O
using	O
either	O
belief	B
propagation	I
(	O
freeman	O
,	O
pasztor	O
,	O
and	O
carmichael	O
2000	O
)	O
or	O
a	O
raster-scan	O
de-	O
terministic	O
variant	O
(	O
freeman	O
,	O
jones	O
,	O
and	O
pasztor	O
2002	O
)	O
.	O
figure	O
10.32	O
shows	O
the	O
results	O
of	O
hallucinating	O
missing	O
details	O
using	O
this	O
approach	O
and	O
compares	O
these	O
results	O
to	O
a	O
more	O
recent	O
algorithm	B
by	O
fattal	O
(	O
2007	O
)	O
.	O
this	O
latter	O
algorithm	B
learns	O
to	O
predict	O
oriented	B
gradient	O
magni-	O
tudes	O
in	O
the	O
ﬁner	O
resolution	O
image	B
based	O
on	O
a	O
pixel	O
’	O
s	O
location	O
relative	O
to	O
the	O
nearest	O
detected	O
edge	O
along	O
with	O
the	O
corresponding	O
edge	O
statistics	O
(	O
magnitude	O
and	O
width	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
combine	O
sparse	B
(	O
robust	B
)	O
derivative	O
priors	O
with	O
example-based	O
super-resolution	O
,	O
as	O
shown	O
by	O
tappen	O
,	O
russell	O
,	O
and	O
freeman	O
(	O
2003	O
)	O
.	O
an	O
alternative	O
(	O
but	O
closely	O
related	O
)	O
form	O
of	O
hallucination	B
is	O
to	O
recognize	O
the	O
parts	O
of	O
a	O
training	O
database	O
of	O
images	O
to	O
which	O
a	O
low-resolution	O
pixel	O
might	O
correspond	O
.	O
in	O
their	O
work	O
,	O
baker	O
and	O
kanade	O
(	O
2002	O
)	O
use	O
local	B
derivative-of-gaussian	O
ﬁlter	O
responses	O
as	O
features	O
and	O
then	O
match	O
parent	O
structure	O
vectors	O
in	O
a	O
manner	O
similar	O
to	O
de	O
bonet	O
(	O
1997	O
)	O
.19	O
the	O
high-	O
frequency	O
gradient	O
at	O
each	O
recognized	O
training	O
image	B
location	O
is	O
then	O
used	O
as	O
a	O
constraint	B
on	O
the	O
super-resolved	O
image	B
,	O
along	O
with	O
the	O
usual	O
reconstruction	O
(	O
prediction	O
)	O
equation	B
(	O
10.27	O
)	O
.	O
figure	O
10.33	O
shows	O
the	O
result	O
of	O
hallucinating	O
higher-resolution	O
faces	B
from	O
lower-resolution	O
inputs	O
;	O
baker	O
and	O
kanade	O
(	O
2002	O
)	O
also	O
show	O
examples	B
of	O
super-resolving	O
known-font	O
text	O
.	O
exercise	O
10.7	O
gives	O
more	O
details	O
on	O
how	O
to	O
implement	O
and	O
test	O
one	O
or	O
more	O
of	O
these	O
super-	O
resolution	O
techniques	O
.	O
under	O
favorable	O
conditions	O
,	O
super-resolution	O
and	O
related	O
upsampling	O
techniques	O
can	O
in-	O
crease	O
the	O
resolution	O
of	O
a	O
well-photographed	O
image	B
or	O
image	B
collection	O
.	O
when	O
the	O
input	O
images	O
are	O
blurry	O
to	O
start	O
with	O
,	O
the	O
best	O
one	O
can	O
often	O
hope	O
for	O
is	O
to	O
reduce	O
the	O
amount	O
of	O
blur	O
.	O
this	O
problem	O
is	O
closely	O
related	O
super-resolution	O
,	O
with	O
the	O
biggest	O
differences	O
being	O
that	O
the	O
blur	O
kernel	O
b	O
is	O
usually	O
much	O
larger	O
and	O
the	O
downsampling	O
factor	O
d	O
is	O
unity	O
.	O
a	O
large	O
literature	O
on	O
image	B
deblurring	O
exists	O
;	O
some	O
of	O
the	O
more	O
recent	O
publications	O
with	O
nice	O
literature	O
reviews	O
include	O
those	O
by	O
fergus	O
,	O
singh	O
,	O
hertzmann	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
yuan	O
,	O
sun	O
,	O
quan	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
and	O
joshi	O
,	O
zitnick	O
,	O
szeliski	O
et	O
al	O
.	O
(	O
2009	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
reduce	O
blur	O
by	O
combining	O
sharp	O
(	O
but	O
noisy	O
)	O
images	O
with	O
blurrier	O
(	O
but	O
cleaner	O
)	O
images	O
(	O
yuan	O
,	O
sun	O
,	O
quan	O
et	O
al	O
.	O
2007	O
)	O
,	O
take	O
lots	O
of	O
quick	O
exposures20	O
(	O
hasinoff	O
and	O
kutulakos	O
2008	O
;	O
hasinoff	O
,	O
kutulakos	O
,	O
durand	O
et	O
al	O
.	O
2009	O
;	O
hasinoff	O
,	O
durand	O
,	O
and	O
freeman	O
2010	O
)	O
,	O
or	O
use	O
coded	O
aperture	O
techniques	O
to	O
simultaneously	O
19	O
for	O
face	O
super-resolution	O
,	O
where	O
all	O
the	O
images	O
are	O
pre-aligned	O
,	O
only	O
corresponding	O
pixels	O
in	O
different	O
images	O
are	O
examined	O
.	O
20	O
the	O
sony	O
dsc-wx1	O
takes	O
multiple	B
shots	O
to	O
produce	O
better	O
low-light	O
photos	O
.	O
502	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.33	O
recognition-based	O
super-resolution	O
(	O
baker	O
and	O
kanade	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
ieee	O
.	O
the	O
hallucinated	O
column	O
shows	O
the	O
results	O
of	O
the	O
recognition-based	O
algorithm	B
compared	O
to	O
the	O
regularization-based	O
approach	O
of	O
hardie	O
,	O
barnard	O
,	O
and	O
armstrong	O
(	O
1997	O
)	O
.	O
estimate	O
depth	O
and	O
reduce	O
blur	O
(	O
levin	O
,	O
fergus	O
,	O
durand	O
et	O
al	O
.	O
2007	O
;	O
zhou	O
,	O
lin	O
,	O
and	O
nayar	O
2009	O
)	O
.	O
10.3.1	O
color	B
image	O
demosaicing	B
a	O
special	O
case	O
of	O
super-resolution	O
,	O
which	O
is	O
used	O
daily	O
in	O
most	O
digital	O
still	O
cameras	O
,	O
is	O
the	O
process	O
of	O
demosaicing	B
samples	O
from	O
a	O
color	O
ﬁlter	O
array	O
(	O
cfa	O
)	O
into	O
a	O
full-color	O
rgb	O
image	B
.	O
figure	O
10.34	O
shows	O
the	O
most	O
commonly	O
used	O
cfa	O
known	O
as	O
the	O
bayer	O
pattern	O
,	O
which	O
has	O
twice	O
as	O
many	O
green	O
(	O
g	O
)	O
sensors	O
as	O
red	O
and	O
blue	O
sensors	O
.	O
the	O
process	O
of	O
going	O
from	O
the	O
known	O
cfa	O
pixels	O
values	O
to	O
the	O
full	O
rgb	O
image	B
is	O
quite	O
challenging	O
.	O
unlike	O
regular	O
super-resolution	O
,	O
where	O
small	O
errors	O
in	O
guessing	O
unknown	O
values	O
usually	O
show	O
up	O
as	O
blur	O
or	O
aliasing	B
,	O
demosaicing	B
artifacts	O
often	O
produce	O
spurious	O
colors	O
or	O
high-frequency	O
patterned	O
zippering	O
,	O
which	O
are	O
quite	O
visible	O
to	O
the	O
eye	O
(	O
figure	O
10.35b	O
)	O
.	O
over	O
the	O
years	O
,	O
a	O
variety	O
of	O
techniques	O
have	O
been	O
developed	O
for	O
image	O
demosaicing	B
(	O
kim-	O
mel	O
1999	O
)	O
.	O
bennett	O
,	O
uyttendaele	O
,	O
zitnick	O
et	O
al	O
.	O
(	O
2006	O
)	O
present	O
a	O
recently	O
developed	O
algorithm	B
along	O
with	O
some	O
good	O
references	B
,	O
while	O
longere	O
,	O
delahunt	O
,	O
zhang	O
et	O
al	O
.	O
(	O
2002	O
)	O
and	O
tappen	O
,	O
russell	O
,	O
and	O
freeman	O
(	O
2003	O
)	O
compare	O
some	O
previously	O
developed	O
techniques	O
using	O
percep-	O
tually	O
motivated	O
metrics	O
.	O
to	O
reduce	O
the	O
zippering	O
effect	O
,	O
most	O
techniques	O
use	O
the	O
edge	O
or	O
10.3	O
super-resolution	O
and	O
blur	B
removal	I
503	O
figure	O
10.34	O
bayer	O
rgb	O
pattern	O
:	O
(	O
a	O
)	O
color	O
ﬁlter	O
array	O
layout	O
;	O
(	O
b	O
)	O
interpolated	O
pixel	O
values	O
,	O
with	O
unknown	O
(	O
guessed	O
)	O
values	O
shown	O
as	O
lower	O
case	O
.	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
10.35	O
cfa	O
demosaicing	B
results	O
(	O
bennett	O
,	O
uyttendaele	O
,	O
zitnick	O
et	O
al	O
.	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
:	O
(	O
a	O
)	O
original	O
full-resolution	O
image	B
(	O
a	O
color	B
subsampled	O
version	O
is	O
used	O
as	O
the	O
input	O
to	O
the	O
algorithms	O
)	O
;	O
(	O
b	O
)	O
bilinear	B
interpolation	O
results	O
,	O
showing	O
color	B
fringing	O
near	O
the	O
tip	O
of	O
the	O
blue	O
crayon	O
and	O
zippering	O
near	O
its	O
left	O
(	O
vertical	O
)	O
edge	O
;	O
(	O
c	O
)	O
the	O
high-quality	O
linear	B
interpolation	O
results	O
of	O
malvar	O
,	O
he	O
,	O
and	O
cutler	O
(	O
2004	O
)	O
(	O
note	O
the	O
strong	O
halo/checkerboard	O
artifacts	O
on	O
the	O
yellow	O
crayon	O
)	O
;	O
(	O
d	O
)	O
using	O
the	O
local	B
two-color	O
prior	B
of	O
bennett	O
,	O
uyttendaele	O
,	O
zitnick	O
et	O
al	O
.	O
(	O
2006	O
)	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
rgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbrgbbgbggrgrgbgrgrbg	O
504	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.36	O
two-color	O
model	O
computed	O
from	O
a	O
collection	O
of	O
local	B
5	O
×	O
5	O
neighborhoods	O
(	O
bennett	O
,	O
uyttendaele	O
,	O
zitnick	O
et	O
al	O
.	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
.	O
after	O
two-means	O
clustering	O
and	O
reprojection	O
along	O
the	O
line	O
joining	O
the	O
two	O
dominant	O
colors	O
(	O
red	O
dots	O
)	O
,	O
the	O
majority	O
of	O
the	O
pixels	O
fall	O
near	O
the	O
ﬁtted	O
line	O
.	O
the	O
distribution	O
along	O
the	O
line	O
,	O
projected	O
along	O
the	O
rgb	O
axes	O
,	O
is	O
peaked	O
at	O
0	O
and	O
1	O
,	O
the	O
two	O
dominant	O
colors	O
.	O
gradient	O
information	O
from	O
the	O
green	O
channel	O
,	O
which	O
is	O
more	O
reliable	O
because	O
it	O
is	O
sampled	O
more	O
densely	O
,	O
to	O
infer	O
plausible	O
values	O
for	O
the	O
red	O
and	O
blue	O
channels	O
,	O
which	O
are	O
more	O
sparsely	O
sampled	O
.	O
to	O
reduce	O
color	B
fringing	O
,	O
some	O
techniques	O
perform	O
a	O
color	B
space	O
analysis	O
,	O
e.g.	O
,	O
using	O
median	O
ﬁltering	O
on	O
color	B
opponent	O
channels	O
(	O
longere	O
,	O
delahunt	O
,	O
zhang	O
et	O
al	O
.	O
2002	O
)	O
.	O
the	O
approach	O
of	O
bennett	O
,	O
uyttendaele	O
,	O
zitnick	O
et	O
al	O
.	O
(	O
2006	O
)	O
locally	O
forms	O
a	O
two-color	O
model	O
from	O
an	O
initial	O
demosaicing	B
result	O
,	O
using	O
a	O
moving	O
5	O
×	O
5	O
window	O
to	O
ﬁnd	O
the	O
two	O
dominant	O
colors	O
(	O
figure	O
10.36	O
)	O
.21	O
once	O
the	O
local	B
color	O
model	O
has	O
been	O
estimated	O
at	O
each	O
pixel	O
,	O
a	O
bayesian	O
approach	O
is	O
then	O
used	O
to	O
encourage	O
pixel	O
values	O
to	O
lie	O
along	O
each	O
color	B
line	O
and	O
to	O
cluster	O
around	O
the	O
dominant	O
color	B
values	O
,	O
which	O
reduces	O
halos	B
(	O
figure	O
10.35d	O
)	O
.	O
the	O
bayesian	O
approach	O
also	O
supports	O
the	O
simultaneous	O
application	O
of	O
demosaicing	B
and	O
super-resolution	O
,	O
i.e.	O
,	O
multiple	B
cfa	O
inputs	O
can	O
be	O
merged	O
into	O
a	O
higher-quality	O
full-color	O
image	B
,	O
which	O
becomes	O
more	O
important	O
as	O
additional	O
processing	O
becomes	O
incorporated	O
into	O
today	O
’	O
s	O
cameras	O
.	O
10.3.2	O
application	O
:	O
colorization	B
although	O
not	O
strictly	O
an	O
example	O
of	O
super-resolution	O
,	O
the	O
process	O
of	O
colorization	B
,	O
i.e.	O
,	O
manu-	O
ally	O
adding	O
colors	O
to	O
a	O
“	O
black	O
and	O
white	O
”	O
(	O
grayscale	O
)	O
image	B
,	O
is	O
another	O
example	O
of	O
a	O
sparse	B
interpolation	O
problem	O
.	O
in	O
most	O
applications	O
of	O
colorization	B
,	O
the	O
user	O
draws	O
some	O
scribbles	O
in-	O
dicating	O
the	O
desired	O
colors	O
in	O
certain	O
regions	O
(	O
figure	O
10.37a	O
)	O
and	O
the	O
system	O
interpolates	O
the	O
21	O
previous	O
work	O
on	O
locally	O
linear	O
color	B
models	O
(	O
klinker	O
,	O
shafer	O
,	O
and	O
kanade	O
1990	O
;	O
omer	O
and	O
werman	O
2004	O
)	O
focuses	O
on	O
color	B
and	O
illumination	O
variation	O
within	O
a	O
single	O
material	O
,	O
whereas	O
bennett	O
,	O
uyttendaele	O
,	O
zitnick	O
et	O
al	O
.	O
(	O
2006	O
)	O
use	O
the	O
two-color	O
model	O
to	O
describe	O
variations	O
across	O
color	B
(	O
material	O
)	O
edges	O
.	O
10.4	O
image	B
matting	O
and	O
compositing	B
505	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
10.37	O
colorization	B
using	O
optimization	O
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
(	O
a	O
)	O
grayscale	O
image	B
some	O
color	B
scribbles	O
overlaid	O
;	O
(	O
b	O
)	O
resulting	O
colorized	O
image	B
;	O
(	O
c	O
)	O
original	O
color	B
image	O
from	O
which	O
the	O
grayscale	O
image	B
and	O
the	O
chrominance	O
values	O
for	O
the	O
scribbles	O
were	O
derived	O
.	O
original	O
photograph	O
by	O
rotem	O
weiss	O
.	O
speciﬁed	O
chrominance	O
(	O
u	O
,	O
v	O
)	O
values	O
to	O
the	O
whole	O
image	B
,	O
which	O
are	O
then	O
re-combined	O
with	O
the	O
input	O
luminance	O
channel	O
to	O
produce	O
a	O
ﬁnal	O
colorized	O
image	B
,	O
as	O
shown	O
in	O
figure	O
10.37b	O
.	O
in	O
the	O
system	O
developed	O
by	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
(	O
2004	O
)	O
,	O
the	O
interpolation	B
is	O
performed	O
us-	O
ing	O
locally	O
weighted	O
regularization	B
(	O
3.100	O
)	O
,	O
where	O
the	O
local	B
smoothness	O
weights	O
are	O
inversely	O
proportional	O
to	O
luminance	O
gradients	O
.	O
this	O
approach	O
to	O
locally	O
weighted	O
regularization	B
has	O
inspired	O
later	O
algorithms	O
for	O
high	O
dynamic	B
range	O
tone	B
mapping	I
(	O
lischinski	O
,	O
farbman	O
,	O
uyt-	O
tendaele	O
et	O
al	O
.	O
2006a	O
)	O
,	O
see	O
section	O
10.2.1	O
,	O
as	O
well	O
as	O
other	O
applications	O
of	O
the	O
weighted	B
least	O
squares	O
(	O
wls	O
)	O
formulation	O
(	O
farbman	O
,	O
fattal	O
,	O
lischinski	O
et	O
al	O
.	O
2008	O
)	O
.	O
an	O
alternative	O
approach	O
to	O
performing	O
the	O
sparse	B
chrominance	O
interpolation	B
based	O
on	O
geodesic	O
(	O
edge-aware	O
)	O
distance	O
functions	O
has	O
been	O
developed	O
by	O
yatziv	O
and	O
sapiro	O
(	O
2006	O
)	O
.	O
10.4	O
image	B
matting	O
and	O
compositing	B
image	O
matting	B
and	O
compositing	B
is	O
the	O
process	O
of	O
cutting	O
a	O
foreground	O
object	O
out	O
of	O
one	O
image	B
and	O
pasting	O
it	O
against	O
a	O
new	O
background	O
(	O
smith	O
and	O
blinn	O
1996	O
;	O
wang	O
and	O
cohen	O
2007a	O
)	O
.	O
it	O
is	O
commonly	O
used	O
in	O
television	O
and	O
ﬁlm	O
production	O
to	O
composite	O
a	O
live	O
actor	O
in	O
front	O
of	O
computer-generated	O
imagery	O
such	O
as	O
weather	O
maps	O
or	O
3d	O
virtual	O
characters	O
and	O
scenery	O
(	O
wright	O
2006	O
;	O
brinkmann	O
2008	O
)	O
.	O
we	O
have	O
already	O
seen	O
a	O
number	O
of	O
tools	O
for	O
interactively	O
segmenting	O
objects	O
in	O
an	O
image	B
,	O
including	O
snakes	B
(	O
section	O
5.1.1	O
)	O
,	O
scissors	O
(	O
section	O
5.1.3	O
)	O
,	O
and	O
grabcut	O
segmentation	B
(	O
sec-	O
tion	B
5.5	O
)	O
.	O
while	O
these	O
techniques	O
can	O
generate	O
reasonable	O
pixel-accurate	O
segmentations	O
,	O
they	O
fail	O
to	O
capture	O
the	O
subtle	O
interplay	O
of	O
foreground	O
and	O
background	O
colors	O
at	O
mixed	O
pixels	O
along	O
the	O
boundary	O
(	O
szeliski	O
and	O
golland	O
1999	O
)	O
(	O
figure	O
10.38a	O
)	O
.	O
in	O
order	B
to	O
successfully	O
copy	O
a	O
foreground	O
object	O
from	O
one	O
image	B
to	O
another	O
without	O
506	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.38	O
softening	O
a	O
hard	O
segmentation	B
boundary	O
(	O
border	O
matting	B
)	O
(	O
rother	O
,	O
kol-	O
mogorov	O
,	O
and	O
blake	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
(	O
a	O
)	O
the	O
region	B
surrounding	O
a	O
segmentation	B
bound-	O
ary	O
where	O
pixels	O
of	O
mixed	O
foreground	O
and	O
background	O
colors	O
are	O
visible	O
;	O
(	O
b	O
)	O
pixel	O
values	O
along	O
the	O
boundary	O
are	O
used	O
to	O
compute	O
a	O
soft	O
alpha	O
matte	O
;	O
(	O
c	O
)	O
at	O
each	O
point	O
along	O
the	O
curve	O
t	O
,	O
a	O
displacement	O
∆	O
and	O
a	O
width	O
σ	O
are	O
estimated	O
.	O
visible	O
discretization	O
artifacts	O
,	O
we	O
need	O
to	O
pull	O
a	O
matte	O
,	O
i.e.	O
,	O
to	O
estimate	O
a	O
soft	O
opacity	O
channel	O
α	O
and	O
the	O
uncontaminated	O
foreground	O
colors	O
f	O
from	O
the	O
input	O
composite	O
image	B
c.	O
recall	B
from	O
section	O
3.1.3	O
(	O
figure	O
3.4	O
)	O
that	O
the	O
compositing	B
equation	O
(	O
3.8	O
)	O
can	O
be	O
written	O
as	O
c	O
=	O
(	O
1	O
−	O
α	O
)	O
b	O
+	O
αf	O
.	O
(	O
10.30	O
)	O
this	O
operator	O
attenuates	O
the	O
inﬂuence	O
of	O
the	O
background	O
image	O
b	O
by	O
a	O
factor	O
(	O
1	O
−	O
α	O
)	O
and	O
then	O
adds	O
in	O
the	O
(	O
partial	O
)	O
color	B
values	O
corresponding	O
to	O
the	O
foreground	O
element	O
f	O
.	O
while	O
the	O
compositing	B
operation	O
is	O
easy	O
to	O
implement	O
,	O
the	O
reverse	O
matting	B
operation	O
of	O
estimating	O
f	O
,	O
α	O
,	O
and	O
b	O
given	O
an	O
input	O
image	B
c	O
is	O
much	O
more	O
challenging	O
(	O
figure	O
10.39	O
)	O
.	O
to	O
see	O
why	O
,	O
observe	O
that	O
while	O
the	O
composite	O
pixel	O
color	O
c	O
provides	O
three	O
measurements	O
,	O
the	O
f	O
,	O
α	O
,	O
and	O
b	O
unknowns	O
have	O
a	O
total	B
of	O
seven	O
degrees	O
of	O
freedom	O
.	O
devising	O
techniques	O
to	O
estimate	O
these	O
unknowns	O
despite	O
the	O
underconstrained	O
nature	O
of	O
the	O
problem	O
is	O
the	O
essence	O
of	O
image	B
matting	O
.	O
in	O
this	O
section	O
,	O
we	O
review	O
a	O
number	O
of	O
image	B
matting	O
techniques	O
.	O
we	O
begin	O
with	O
blue	O
screen	O
matting	B
,	O
which	O
assumes	O
that	O
the	O
background	O
is	O
a	O
constant	O
known	O
color	B
,	O
and	O
discuss	O
its	O
variants	O
,	O
two-screen	O
matting	B
(	O
when	O
multiple	B
backgrounds	O
can	O
be	O
used	O
)	O
and	O
difference	B
matting	O
(	O
where	O
the	O
known	O
background	O
is	O
arbitrary	O
)	O
.	O
we	O
then	O
discuss	O
local	B
variants	O
of	O
natural	B
image	O
matting	B
,	O
where	O
both	O
the	O
foreground	O
and	O
background	O
are	O
unknown	O
.	O
in	O
these	O
applications	O
,	O
it	O
is	O
usual	O
to	O
ﬁrst	O
specify	O
a	O
trimap	B
,	O
i.e.	O
,	O
a	O
three-way	O
labeling	O
of	O
the	O
image	B
into	O
foreground	O
,	O
back-	O
ground	O
,	O
and	O
unknown	O
regions	O
(	O
figure	O
10.39b	O
)	O
.	O
next	O
,	O
we	O
present	O
some	O
global	B
optimization	I
approaches	O
to	O
natural	B
image	O
matting	B
.	O
finally	O
,	O
we	O
discuss	O
variants	O
on	O
the	O
matting	B
problem	O
,	O
including	O
shadow	B
matting	O
,	O
ﬂash	B
matting	O
,	O
and	O
environment	O
matting	O
.	O
10.4	O
image	B
matting	O
and	O
compositing	B
507	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
10.39	O
natural	B
image	O
matting	B
(	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
input	O
image	B
with	O
a	O
“	O
natural	B
”	O
(	O
non-constant	O
)	O
background	O
;	O
(	O
b	O
)	O
hand-drawn	O
trimap—gray	O
indicates	O
unknown	O
regions	O
;	O
(	O
c	O
)	O
extracted	O
alpha	O
map	O
;	O
(	O
d	O
)	O
extracted	O
(	O
premultiplied	O
)	O
foreground	O
colors	O
;	O
(	O
e	O
)	O
composite	O
over	O
a	O
new	O
background	O
.	O
10.4.1	O
blue	B
screen	I
matting	O
blue	B
screen	I
matting	O
involves	O
ﬁlming	O
an	O
actor	O
(	O
or	O
object	O
)	O
in	O
front	O
of	O
a	O
constant	O
colored	O
back-	O
ground	O
.	O
while	O
originally	O
bright	O
blue	O
was	O
the	O
preferred	O
color	B
,	O
bright	O
green	O
is	O
now	O
more	O
com-	O
monly	O
used	O
(	O
wright	O
2006	O
;	O
brinkmann	O
2008	O
)	O
.	O
smith	O
and	O
blinn	O
(	O
1996	O
)	O
discuss	O
a	O
number	O
of	O
techniques	O
for	O
blue	O
screen	O
matting	B
,	O
which	O
are	O
mostly	O
described	O
in	O
patents	O
rather	O
than	O
in	O
the	O
open	O
research	O
literature	O
.	O
early	O
techniques	O
used	O
linear	B
combination	O
of	O
object	O
color	B
channels	O
with	O
user-tuned	O
parameters	B
to	O
estimate	O
the	O
opacity	B
α.	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
(	O
2001	O
)	O
describe	O
a	O
newer	O
technique	O
called	O
mishima	O
’	O
s	O
al-	O
gorithm	O
,	O
which	O
involves	O
ﬁtting	O
two	O
polyhedral	O
surfaces	O
(	O
centered	O
at	O
the	O
mean	O
background	O
color	B
)	O
,	O
separating	O
the	O
foreground	O
and	O
background	O
color	O
distributions	O
and	O
then	O
measuring	O
the	O
relative	O
distance	O
of	O
a	O
novel	O
color	B
to	O
these	O
surfaces	O
to	O
estimate	O
α	O
(	O
figure	O
10.41e	O
)	O
.	O
while	O
this	O
technique	O
works	O
well	O
in	O
many	O
studio	O
settings	O
,	O
it	O
can	O
still	O
suffer	O
from	O
blue	O
spill	O
,	O
where	O
translu-	O
cent	O
pixels	O
around	O
the	O
edges	O
of	O
an	O
object	O
acquire	O
some	O
of	O
the	O
background	O
blue	O
coloration	O
(	O
figure	O
10.40	O
)	O
.	O
two-screen	O
matting	B
.	O
in	O
their	O
paper	O
,	O
smith	O
and	O
blinn	O
(	O
1996	O
)	O
also	O
introduce	O
an	O
algorithm	B
called	O
triangulation	B
matting	O
that	O
uses	O
more	O
than	O
one	O
known	O
background	O
color	O
to	O
over-constrain	O
the	O
equations	B
required	O
to	O
estimate	O
the	O
opacity	B
α	O
and	O
foreground	O
color	B
f	O
.	O
508	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.40	O
blue-screen	O
matting	B
results	O
(	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
.	O
mishima	O
’	O
s	O
method	O
produces	O
visible	O
blue	O
spill	O
(	O
color	B
fringing	O
in	O
the	O
hair	O
)	O
,	O
while	O
chuang	O
’	O
s	O
bayesian	O
matting	B
approach	O
produces	O
accurate	O
results	O
.	O
for	O
example	O
,	O
consider	O
in	O
the	O
compositing	B
equation	O
(	O
10.30	O
)	O
setting	O
the	O
background	O
color	O
to	O
black	O
,	O
i.e.	O
,	O
b	O
=	O
0.	O
the	O
resulting	O
composite	O
image	B
c	O
is	O
therefore	O
equal	O
to	O
αf	O
.	O
replacing	O
the	O
background	O
color	O
with	O
a	O
different	O
known	O
non-zero	O
value	O
b	O
now	O
results	O
in	O
c	O
−	O
αf	O
=	O
(	O
1	O
−	O
α	O
)	O
b	O
,	O
(	O
10.31	O
)	O
which	O
is	O
an	O
overconstrained	O
set	O
of	O
(	O
color	B
)	O
equations	B
for	O
estimating	O
α.	O
in	O
practice	O
,	O
b	O
should	O
be	O
chosen	O
so	O
as	O
not	O
to	O
saturate	O
c	O
and	O
,	O
for	O
best	O
accuracy	B
,	O
several	O
values	O
of	O
b	O
should	O
be	O
used	O
.	O
it	O
is	O
also	O
important	O
that	O
colors	O
be	O
linearized	O
before	O
processing	O
,	O
which	O
is	O
the	O
case	O
for	O
all	O
image	B
matting	O
algorithms	O
.	O
papers	O
that	O
generate	O
ground	O
truth	O
alpha	O
mattes	O
for	O
evaluation	O
purposes	O
normally	O
use	O
these	O
techniques	O
to	O
obtain	O
accurate	O
matte	O
estimates	O
(	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
2001	O
;	O
wang	O
and	O
cohen	O
2007b	O
;	O
levin	O
,	O
acha	O
,	O
and	O
lischinski	O
2008	O
;	O
rhemann	O
,	O
rother	O
,	O
rav-acha	O
et	O
al	O
.	O
2008	O
;	O
rhemann	O
,	O
rother	O
,	O
wang	O
et	O
al	O
.	O
2009	O
)	O
.22	O
exercise	O
10.8	O
has	O
you	O
do	O
this	O
as	O
well	O
.	O
22	O
see	O
the	O
alpha	O
matting	O
evaluation	B
web	O
site	O
at	O
http	O
:	O
//alphamatting.com/	O
.	O
10.4	O
image	B
matting	O
and	O
compositing	B
509	O
difference	B
matting	O
.	O
a	O
related	O
approach	O
when	O
the	O
background	O
is	O
irregular	O
but	O
known	O
is	O
called	O
difference	B
matting	O
(	O
wright	O
2006	O
;	O
brinkmann	O
2008	O
)	O
.	O
it	O
is	O
most	O
commonly	O
used	O
when	O
the	O
actor	O
or	O
object	O
is	O
ﬁlmed	O
against	O
a	O
static	O
background	O
,	O
e.g.	O
,	O
for	O
ofﬁce	O
videoconferencing	O
,	O
person	O
tracking	O
applications	O
(	O
toyama	O
,	O
krumm	O
,	O
brumitt	O
et	O
al	O
.	O
1999	O
)	O
,	O
or	O
to	O
produce	O
silhou-	O
ettes	O
for	O
volumetric	O
3d	O
reconstruction	O
techniques	O
(	O
section	O
11.6.2	O
)	O
(	O
szeliski	O
1993	O
;	O
seitz	O
and	O
dyer	O
1997	O
;	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
2006	O
)	O
.	O
it	O
can	O
also	O
be	O
used	O
with	O
a	O
panning	O
camera	B
where	O
the	O
background	O
is	O
composited	O
from	O
frames	O
where	O
the	O
foreground	O
has	O
been	O
removed	O
using	O
a	O
garbage	O
matte	O
(	O
section	O
10.4.5	O
)	O
(	O
chuang	O
,	O
agarwala	O
,	O
curless	O
et	O
al	O
.	O
2002	O
)	O
.	O
another	O
recent	O
application	O
is	O
the	O
detection	B
of	O
visual	O
continuity	O
errors	O
in	O
ﬁlms	O
,	O
i.e.	O
,	O
differences	O
in	O
the	O
background	O
when	O
a	O
shot	O
is	O
re-taken	O
at	O
later	O
time	O
(	O
pickup	O
and	O
zisserman	O
2009	O
)	O
.	O
in	O
the	O
case	O
where	O
the	O
foreground	O
and	O
background	O
motions	O
can	O
both	O
be	O
speciﬁed	O
with	O
parametric	O
transforms	O
,	O
high-quality	O
mattes	O
can	O
be	O
extracted	O
using	O
a	O
generalization	O
of	O
triangu-	O
lation	O
matting	B
(	O
wexler	O
,	O
fitzgibbon	O
,	O
and	O
zisserman	O
2002	O
)	O
.	O
when	O
frames	O
need	O
to	O
be	O
processed	O
independently	O
,	O
however	O
,	O
the	O
results	O
are	O
often	O
of	O
poor	O
quality	O
(	O
figure	O
10.42	O
)	O
.	O
in	O
such	O
cases	O
,	O
using	O
a	O
pair	O
of	O
stereo	B
cameras	O
as	O
input	O
can	O
dramatically	O
improve	O
the	O
quality	O
of	O
the	O
results	O
(	O
criminisi	O
,	O
cross	O
,	O
blake	O
et	O
al	O
.	O
2006	O
;	O
yin	O
,	O
criminisi	O
,	O
winn	O
et	O
al	O
.	O
2007	O
)	O
.	O
10.4.2	O
natural	B
image	O
matting	B
the	O
most	O
general	O
version	O
of	O
image	B
matting	O
is	O
when	O
nothing	O
is	O
known	O
about	O
the	O
background	O
except	O
,	O
perhaps	O
,	O
for	O
a	O
rough	O
segmentation	B
of	O
the	O
scene	O
into	O
foreground	O
,	O
background	O
,	O
and	O
unknown	O
regions	O
,	O
which	O
is	O
known	O
as	O
the	O
trimap	B
(	O
figure	O
10.39b	O
)	O
.	O
some	O
recent	O
techniques	O
,	O
however	O
,	O
relax	O
this	O
requirement	O
and	O
allow	O
the	O
user	O
to	O
just	O
draw	O
a	O
few	O
strokes	O
or	O
scribbles	O
in	O
the	O
image	B
,	O
see	O
figures	O
10.45	O
and	O
10.46	O
(	O
wang	O
and	O
cohen	O
2005	O
;	O
wang	O
,	O
agrawala	O
,	O
and	O
cohen	O
2007	O
;	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2008	O
;	O
rhemann	O
,	O
rother	O
,	O
rav-acha	O
et	O
al	O
.	O
2008	O
;	O
rhemann	O
,	O
rother	O
,	O
and	O
gelautz	O
2008	O
)	O
.	O
fully	O
automated	B
single	O
image	B
matting	O
results	O
have	O
also	O
been	O
reported	O
(	O
levin	O
,	O
acha	O
,	O
and	O
lischinski	O
2008	O
;	O
singaraju	O
,	O
rother	O
,	O
and	O
rhemann	O
2009	O
)	O
.	O
the	O
survey	O
paper	O
by	O
wang	O
and	O
cohen	O
(	O
2007a	O
)	O
has	O
detailed	O
descriptions	O
and	O
comparisons	O
of	O
all	O
of	O
these	O
techniques	O
,	O
a	O
selection	O
of	O
which	O
are	O
described	O
brieﬂy	O
below	O
.	O
a	O
relatively	O
simple	O
algorithm	B
for	O
performing	O
natural	B
image	O
matting	B
is	O
knockout	O
,	O
as	O
de-	O
scribed	O
by	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
(	O
2001	O
)	O
and	O
illustrated	O
in	O
figure	O
10.41f	O
.	O
in	O
this	O
algorithm	B
,	O
the	O
nearest	O
known	O
foreground	O
and	O
background	O
pixels	O
(	O
in	O
image	B
space	O
)	O
are	O
deter-	O
mined	O
and	O
then	O
blended	O
with	O
neighboring	O
known	O
pixels	O
to	O
produce	O
a	O
per-pixel	O
foreground	O
f	O
and	O
background	O
b	O
color	B
estimate	O
.	O
the	O
background	O
color	O
is	O
then	O
adjusted	O
so	O
that	O
the	O
measured	O
color	B
c	O
lies	O
on	O
the	O
line	O
between	O
f	O
and	O
b.	O
finally	O
,	O
opacity	B
α	O
is	O
estimated	O
on	O
a	O
per-channel	O
basis	O
,	O
and	O
the	O
three	O
estimates	O
are	O
combined	O
based	O
on	O
per-channel	O
color	B
differences	O
.	O
(	O
this	O
is	O
an	O
approximation	O
to	O
the	O
least	B
squares	I
solution	O
for	O
α	O
.	O
)	O
figure	O
10.42	O
shows	O
that	O
knockout	O
has	O
problems	O
when	O
the	O
background	O
consists	O
of	O
more	O
than	O
one	O
dominant	O
local	B
color	O
.	O
510	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
mishima	O
knockout	O
ruzon–tomasi	O
bayesian	O
figure	O
10.41	O
image	B
matting	O
algorithms	O
(	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
.	O
mishima	O
’	O
s	O
algorithm	B
models	O
global	B
foreground	O
and	O
background	O
color	O
distribution	O
as	O
polyhedral	O
surfaces	O
centered	O
around	O
the	O
mean	O
background	O
(	O
blue	O
)	O
color	B
.	O
knockout	O
uses	O
a	O
lo-	O
cal	O
color	B
estimate	O
of	O
foreground	O
and	O
background	O
for	O
each	O
pixel	O
and	O
computes	O
α	O
along	O
each	O
color	B
axis	O
.	O
ruzon	O
and	O
tomasi	O
’	O
s	O
algorithm	B
locally	O
models	O
foreground	O
and	O
background	O
colors	O
and	O
variances	O
.	O
chuang	O
et	O
al.	O
’	O
s	O
bayesian	O
matting	B
approach	O
computes	O
a	O
map	O
estimate	O
of	O
(	O
frac-	O
tional	O
)	O
foreground	O
color	B
and	O
opacity	B
given	O
the	O
local	B
foreground	O
and	O
background	O
distributions	O
.	O
more	O
accurate	O
matting	B
results	O
can	O
be	O
obtained	O
if	O
we	O
treat	O
the	O
foreground	O
and	O
background	O
colors	O
as	O
distributions	O
sampled	O
over	O
some	O
region	B
(	O
figure	O
10.41g–h	O
)	O
.	O
ruzon	O
and	O
tomasi	O
(	O
2000	O
)	O
model	O
local	B
color	O
distributions	O
as	O
mixtures	O
of	O
(	O
uncorrelated	O
)	O
gaussians	O
and	O
compute	O
these	O
models	O
in	O
strips	O
.	O
they	O
then	O
ﬁnd	O
the	O
pairing	O
of	O
mixture	O
components	O
f	O
and	O
b	O
that	O
best	O
describes	O
the	O
observed	O
color	B
c	O
,	O
compute	O
the	O
α	O
as	O
the	O
relative	O
distance	O
between	O
these	O
means	O
,	O
and	O
adjust	O
the	O
estimates	O
of	O
f	O
and	O
b	O
so	O
they	O
are	O
collinear	O
with	O
c.	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
(	O
2001	O
)	O
and	O
hillman	O
,	O
hannah	O
,	O
and	O
renshaw	O
(	O
2001	O
)	O
use	O
full	O
3	O
×	O
3	O
color	B
covariance	O
matrices	O
to	O
model	O
mixtures	O
of	O
correlated	O
gaussians	O
,	O
and	O
compute	O
estimates	O
independently	O
for	O
each	O
pixel	O
.	O
matte	O
extraction	O
proceeds	O
in	O
strips	O
starting	O
from	O
known	O
color	B
values	O
growing	O
into	O
the	O
unknown	O
regions	O
,	O
so	O
that	O
recently	O
computed	O
f	O
and	O
b	O
colors	O
can	O
be	O
used	O
in	O
later	O
stages	O
.	O
to	O
estimate	O
the	O
most	O
likely	O
value	O
of	O
an	O
unknown	O
pixel	O
’	O
s	O
opacity	B
and	O
(	O
unmixed	O
)	O
foreground	O
and	O
background	O
colors	O
,	O
chuang	O
et	O
al	O
.	O
use	O
a	O
fully	O
bayesian	O
formulation	O
that	O
maximizes	O
p	O
(	O
f	O
,	O
b	O
,	O
α|c	O
)	O
=	O
p	O
(	O
c|f	O
,	O
b	O
,	O
α	O
)	O
p	O
(	O
f	O
)	O
p	O
(	O
b	O
)	O
p	O
(	O
α	O
)	O
/p	O
(	O
c	O
)	O
.	O
(	O
10.32	O
)	O
10.4	O
image	B
matting	O
and	O
compositing	B
511	O
figure	O
10.42	O
natural	B
image	O
matting	B
results	O
(	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
.	O
difference	B
matting	O
and	O
knockout	O
both	O
perform	O
poorly	O
on	O
this	O
kind	O
of	O
background	O
,	O
while	O
the	O
more	O
recent	O
natural	B
image	O
matting	B
techniques	O
perform	O
well	O
.	O
chuang	O
et	O
al.	O
’	O
s	O
results	O
are	O
slightly	O
smoother	O
and	O
closer	O
to	O
the	O
ground	O
truth	O
.	O
512	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
this	O
is	O
equivalent	O
to	O
minimizing	O
the	O
negative	O
log	O
likelihood	O
l	O
(	O
f	O
,	O
b	O
,	O
α|c	O
)	O
=	O
l	O
(	O
c|f	O
,	O
b	O
,	O
α	O
)	O
+	O
l	O
(	O
f	O
)	O
+	O
l	O
(	O
b	O
)	O
+	O
l	O
(	O
α	O
)	O
(	O
10.33	O
)	O
(	O
dropping	O
the	O
l	O
(	O
c	O
)	O
term	O
since	O
it	O
is	O
constant	O
)	O
.	O
let	O
us	O
examine	O
each	O
of	O
these	O
terms	O
in	O
turn	O
.	O
the	O
ﬁrst	O
,	O
l	O
(	O
c|f	O
,	O
b	O
,	O
α	O
)	O
,	O
is	O
the	O
likelihood	O
that	O
pixel	O
color	O
c	O
was	O
observed	O
given	O
values	O
for	O
the	O
unknowns	O
(	O
f	O
,	O
b	O
,	O
α	O
)	O
.	O
if	O
we	O
assume	O
gaussian	O
noise	B
in	O
our	O
observation	O
with	O
variance	O
σ2	O
c	O
,	O
this	O
negative	O
log	O
likelihood	O
(	O
data	O
term	O
)	O
is	O
l	O
(	O
c	O
)	O
=	O
1/2	O
(	O
cid:107	O
)	O
c	O
−	O
[	O
αf	O
+	O
(	O
1	O
−	O
α	O
)	O
b	O
]	O
(	O
cid:107	O
)	O
2/σ2	O
c	O
,	O
(	O
10.34	O
)	O
as	O
illustrated	O
in	O
figure	O
10.41h	O
.	O
the	O
second	O
term	O
,	O
l	O
(	O
f	O
)	O
,	O
corresponds	O
to	O
the	O
likelihood	O
that	O
a	O
particular	O
foreground	O
color	B
f	O
comes	O
from	O
the	O
mixture	O
of	O
gaussians	O
distribution	O
.	O
after	O
partitioning	O
the	O
sample	O
foreground	O
colors	O
into	O
clusters	O
,	O
a	O
weighted	B
mean	O
and	O
covariance	O
is	O
computed	O
,	O
where	O
the	O
weights	O
are	O
proportional	O
to	O
a	O
given	O
foreground	O
pixel	O
’	O
s	O
opacity	B
and	O
distance	O
from	O
the	O
unknown	O
pixel	O
.	O
the	O
negative	O
log	O
likelihood	O
for	O
each	O
cluster	O
is	O
thus	O
given	O
by	O
l	O
(	O
f	O
)	O
=	O
(	O
f	O
−	O
f	O
)	O
t	O
σ−1	O
f	O
(	O
f	O
−	O
f	O
)	O
.	O
(	O
10.35	O
)	O
a	O
similar	O
method	O
is	O
used	O
to	O
estimate	O
unknown	O
background	O
color	O
distributions	O
.	O
if	O
the	O
back-	O
ground	O
is	O
already	O
known	O
,	O
i.e.	O
,	O
for	O
blue	O
screen	O
or	O
difference	B
matting	O
applications	O
,	O
its	O
measured	O
color	B
value	O
and	O
variance	O
are	O
used	O
instead	O
.	O
an	O
alternative	O
to	O
modeling	B
the	O
foreground	O
and	O
background	O
color	O
distributions	O
as	O
mixtures	O
of	O
gaussians	O
is	O
to	O
keep	O
around	O
the	O
original	O
color	B
samples	O
and	O
to	O
compute	O
the	O
most	O
likely	O
pairings	O
that	O
explain	O
the	O
observed	O
color	B
c	O
(	O
wang	O
and	O
cohen	O
2005	O
,	O
2007b	O
)	O
.	O
these	O
techniques	O
are	O
described	O
in	O
more	O
detail	O
in	O
(	O
wang	O
and	O
cohen	O
2007a	O
)	O
.	O
in	O
their	O
bayesian	O
matting	B
paper	O
,	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
(	O
2001	O
)	O
assume	O
a	O
constant	O
(	O
non-informative	O
)	O
distribution	O
for	O
l	O
(	O
α	O
)	O
.	O
more	O
recent	O
papers	O
assume	O
this	O
distribution	O
to	O
be	O
more	O
peaked	O
around	O
0	O
and	O
1	O
,	O
or	O
sometimes	O
use	O
markov	O
random	O
ﬁelds	O
(	O
mrfs	O
)	O
to	O
deﬁne	O
a	O
global	B
correlated	O
prior	B
on	O
p	O
(	O
α	O
)	O
(	O
wang	O
and	O
cohen	O
2007a	O
)	O
.	O
to	O
compute	O
the	O
most	O
likely	O
estimates	O
for	O
(	O
f	O
,	O
b	O
,	O
α	O
)	O
,	O
the	O
bayesian	O
matting	B
algorithm	O
alter-	O
nates	O
between	O
computing	O
(	O
f	O
,	O
b	O
)	O
and	O
α	O
,	O
since	O
each	O
of	O
these	O
problems	O
is	O
quadratic	O
and	O
hence	O
can	O
be	O
solved	O
as	O
a	O
small	O
linear	B
system	O
.	O
when	O
several	O
color	B
clusters	O
are	O
estimated	O
,	O
the	O
most	O
likely	O
pairing	O
of	O
foreground	O
and	O
background	O
color	O
clusters	O
is	O
used	O
.	O
bayesian	O
image	B
matting	O
produces	O
results	O
that	O
improve	O
on	O
the	O
original	O
natural	B
image	O
mat-	O
ting	O
algorithm	B
by	O
ruzon	O
and	O
tomasi	O
(	O
2000	O
)	O
,	O
as	O
can	O
be	O
seen	O
in	O
figure	O
10.42.	O
however	O
,	O
com-	O
pared	O
to	O
more	O
recent	O
techniques	O
(	O
wang	O
and	O
cohen	O
2007a	O
)	O
,	O
its	O
performance	O
is	O
not	O
as	O
good	O
for	O
complex	O
background	O
or	O
inaccurate	O
trimaps	O
(	O
figure	O
10.44	O
)	O
.	O
10.4	O
image	B
matting	O
and	O
compositing	B
513	O
10.4.3	O
optimization-based	B
matting	O
an	O
alternative	O
to	O
estimating	O
each	O
pixel	O
’	O
s	O
opacity	B
and	O
foreground	O
color	B
independently	O
is	O
to	O
use	O
global	B
optimization	I
to	O
compute	O
a	O
matte	O
that	O
takes	O
into	O
account	O
correlations	O
between	O
neigh-	O
boring	O
α	O
values	O
.	O
two	O
examples	O
of	O
this	O
are	O
border	O
matting	B
in	O
the	O
grabcut	O
interactive	B
segmen-	O
tation	O
system	O
(	O
rother	O
,	O
kolmogorov	O
,	O
and	O
blake	O
2004	O
)	O
and	O
poisson	O
matting	B
(	O
sun	O
,	O
jia	O
,	O
tang	O
et	O
al	O
.	O
2004	O
)	O
.	O
border	O
matting	B
ﬁrst	O
dilates	O
the	O
region	B
around	O
the	O
binary	O
segmentation	O
produced	O
by	O
grab-	O
cut	O
(	O
section	O
5.5	O
)	O
and	O
then	O
solves	O
for	O
a	O
sub-pixel	O
boundary	O
location	O
∆	O
and	O
a	O
blur	O
width	O
σ	O
for	O
every	O
point	O
along	O
the	O
boundary	O
(	O
figure	O
10.38	O
)	O
.	O
smoothness	B
in	O
these	O
parameters	B
along	O
the	O
boundary	O
is	O
enforced	O
using	O
regularization	O
and	O
the	O
optimization	O
is	O
performed	O
using	O
dynamic	O
programming	O
.	O
while	O
this	O
technique	O
can	O
obtain	O
good	O
results	O
for	O
smooth	O
boundaries	O
,	O
such	O
as	O
a	O
person	O
’	O
s	O
face	B
,	O
it	O
has	O
difﬁculty	O
with	O
ﬁne	O
details	O
,	O
such	O
as	O
hair	O
.	O
poisson	O
matting	B
(	O
sun	O
,	O
jia	O
,	O
tang	O
et	O
al	O
.	O
2004	O
)	O
assumes	O
a	O
known	O
foreground	O
and	O
background	O
color	O
for	O
each	O
pixel	O
in	O
the	O
trimap	B
(	O
as	O
with	O
bayesian	O
matting	B
)	O
.	O
however	O
,	O
instead	O
of	O
indepen-	O
dently	O
estimating	O
each	O
α	O
value	O
,	O
it	O
assumes	O
that	O
the	O
gradient	O
of	O
the	O
alpha	B
matte	I
and	O
the	O
gradient	O
of	O
the	O
color	B
image	O
are	O
related	O
by	O
∇α	O
=	O
f	O
−	O
b	O
(	O
cid:107	O
)	O
f	O
−	O
b	O
(	O
cid:107	O
)	O
2	O
·	O
∇c	O
,	O
(	O
10.36	O
)	O
which	O
can	O
be	O
derived	O
by	O
taking	O
gradients	O
of	O
both	O
sides	O
of	O
(	O
10.30	O
)	O
and	O
assuming	O
that	O
the	O
foreground	O
and	O
background	O
vary	O
slowly	O
.	O
the	O
per-pixel	O
gradient	O
estimates	O
are	O
then	O
integrated	O
into	O
a	O
continuous	O
α	O
(	O
x	O
)	O
ﬁeld	O
using	O
the	O
regularization	B
(	O
least	B
squares	I
)	O
technique	O
ﬁrst	O
described	O
in	O
section	O
3.7.1	O
(	O
3.100	O
)	O
and	O
subsequently	O
used	O
in	O
poisson	O
blending	B
(	O
section	O
9.3.4	O
,	O
9.44	O
)	O
and	O
gradient-based	O
dynamic	B
range	O
compression	B
mapping	O
(	O
section	O
10.2.1	O
,	O
10.19	O
)	O
.	O
this	O
technique	O
works	O
well	O
when	O
good	O
foreground	O
and	O
background	O
color	O
estimates	O
are	O
available	O
and	O
these	O
colors	O
vary	O
slowly	O
.	O
instead	O
of	O
computing	O
per-pixel	O
foreground	O
and	O
background	O
colors	O
,	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
(	O
2008	O
)	O
assume	O
only	O
that	O
these	O
color	B
distribution	O
can	O
locally	O
be	O
well	O
approximated	O
as	O
mixtures	O
of	O
two	O
colors	O
,	O
which	O
is	O
known	O
as	O
the	O
color	B
line	O
model	O
(	O
figure	O
10.43a–c	O
)	O
.	O
under	O
this	O
assumption	O
,	O
a	O
closed-form	O
estimate	O
for	O
α	O
at	O
each	O
pixel	O
i	O
in	O
a	O
(	O
say	O
,	O
3×	O
3	O
)	O
window	O
wk	O
is	O
given	O
by	O
(	O
10.37	O
)	O
αi	O
=	O
ak	O
·	O
(	O
ci	O
−	O
b0	O
)	O
=	O
ak	O
·	O
c	O
+	O
bk	O
,	O
where	O
ci	O
is	O
the	O
pixel	O
color	O
treated	O
as	O
a	O
three-vector	O
,	O
b0	O
is	O
any	O
pixel	O
along	O
the	O
background	O
color	O
line	O
,	O
and	O
ak	O
is	O
the	O
vector	O
joining	O
the	O
two	O
closest	O
points	B
on	O
the	O
foreground	O
and	O
back-	O
ground	O
color	B
lines	O
,	O
as	O
shown	O
in	O
figure	O
10.43c	O
.	O
(	O
note	O
that	O
the	O
geometric	B
derivation	O
shown	O
in	O
this	O
ﬁgure	O
is	O
an	O
alternative	O
to	O
the	O
algebraic	O
derivation	O
presented	O
by	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
(	O
2008	O
)	O
.	O
)	O
minimizing	O
the	O
deviations	O
of	O
the	O
alpha	O
values	O
αi	O
from	O
their	O
respective	O
color	B
514	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.43	O
color	B
line	O
matting	B
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2008	O
)	O
:	O
(	O
a	O
)	O
local	B
3	O
×	O
3	O
patch	B
of	O
colors	O
;	O
(	O
b	O
)	O
potential	O
assignment	O
of	O
α	O
values	O
;	O
(	O
c	O
)	O
foreground	O
and	O
background	O
color	O
lines	B
,	O
the	O
vector	O
ak	O
joining	O
their	O
closest	O
points	B
of	O
intersection	O
,	O
and	O
the	O
family	O
of	O
parallel	O
planes	B
of	O
constant	O
α	O
values	O
,	O
αi	O
=	O
ak	O
·	O
(	O
ci	O
−	O
b0	O
)	O
;	O
(	O
d	O
)	O
a	O
scatter	O
plot	O
of	O
sample	O
colors	O
and	O
the	O
deviations	O
from	O
the	O
mean	O
µk	O
for	O
two	O
sample	O
colors	O
ci	O
and	O
cj	O
.	O
line	O
models	O
(	O
10.37	O
)	O
over	O
all	O
overlapping	O
windows	O
wk	O
in	O
the	O
image	B
gives	O
rise	O
to	O
the	O
cost	O
eα	O
=	O
(	O
cid:88	O
)	O
k	O
(	O
cid:32	O
)	O
(	O
cid:88	O
)	O
i∈wk	O
(	O
αi	O
−	O
ak	O
·	O
ci	O
−	O
bk	O
)	O
2	O
+	O
	O
(	O
cid:107	O
)	O
ak	O
(	O
cid:107	O
)	O
(	O
cid:33	O
)	O
,	O
(	O
10.38	O
)	O
where	O
the	O
	O
term	O
is	O
used	O
to	O
regularize	O
the	O
value	O
of	O
ak	O
in	O
the	O
case	O
where	O
the	O
two	O
color	O
distri-	O
butions	O
overlap	O
(	O
i.e.	O
,	O
in	O
constant	O
α	O
regions	O
)	O
.	O
because	O
this	O
formula	O
is	O
quadratic	O
in	O
the	O
unknowns	O
{	O
(	O
ak	O
,	O
bk	O
)	O
}	O
,	O
they	O
can	O
be	O
eliminated	O
inside	O
each	O
window	O
wk	O
,	O
leading	O
to	O
a	O
ﬁnal	O
energy	O
where	O
the	O
entries	O
in	O
the	O
l	O
matrix	O
are	O
given	O
by	O
eα	O
=	O
αt	O
lα	O
,	O
lij	O
=	O
(	O
cid:88	O
)	O
k	O
:	O
i∈wk∧j∈wk	O
(	O
cid:18	O
)	O
δij	O
−	O
1	O
m	O
(	O
cid:16	O
)	O
1	O
+	O
(	O
c	O
i	O
−	O
µk	O
)	O
t	O
ˆσ−1	O
k	O
(	O
cj	O
−	O
µk	O
)	O
(	O
cid:17	O
)	O
(	O
cid:19	O
)	O
,	O
(	O
10.39	O
)	O
(	O
10.40	O
)	O
where	O
m	O
=	O
|wk|	O
is	O
the	O
number	O
of	O
pixels	O
in	O
each	O
(	O
overlapping	O
)	O
window	O
,	O
µk	O
is	O
the	O
mean	O
color	O
of	O
the	O
pixels	O
in	O
window	O
wk	O
,	O
and	O
ˆσk	O
is	O
the	O
3	O
×	O
3	O
covariance	O
of	O
the	O
pixel	O
colors	O
plus	O
/mi	O
.	O
figure	O
10.43d	O
shows	O
the	O
intuition	O
behind	O
the	O
entries	O
in	O
this	O
afﬁnity	O
matrix	O
,	O
which	O
is	O
called	O
the	O
matting	B
laplacian	O
.	O
note	O
how	O
when	O
two	O
pixels	O
ci	O
and	O
cj	O
in	O
wk	O
point	O
in	O
opposite	O
direc-	O
tions	O
away	O
from	O
the	O
mean	O
µk	O
,	O
their	O
weighted	B
dot	O
product	O
is	O
close	O
to	O
−1	O
,	O
and	O
so	O
their	O
afﬁnity	O
becomes	O
close	O
to	O
0.	O
pixels	O
close	O
to	O
each	O
other	O
in	O
color	B
space	O
(	O
and	O
hence	O
with	O
similar	O
expected	O
α	O
values	O
)	O
will	O
have	O
afﬁnities	B
close	O
to	O
−2/m	O
.	O
minimizing	O
the	O
quadratic	O
energy	O
(	O
10.39	O
)	O
constrained	B
by	O
the	O
known	O
values	O
of	O
α	O
=	O
{	O
0	O
,	O
1	O
}	O
at	O
scribbles	O
only	O
requires	O
the	O
solution	O
of	O
a	O
sparse	B
set	O
of	O
linear	B
equations	O
,	O
which	O
is	O
why	O
the	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
akα=0α=0.5α=1b0ci	O
(	O
d	O
)	O
ciμkσkcj	O
10.4	O
image	B
matting	O
and	O
compositing	B
515	O
figure	O
10.44	O
comparative	O
matting	B
results	O
for	O
a	O
medium	O
accuracy	B
trimap	O
.	O
wang	O
and	O
cohen	O
(	O
2007a	O
)	O
describe	O
the	O
individual	O
techniques	O
being	O
compared	O
.	O
authors	O
call	O
their	O
technique	O
a	O
closed-form	O
solution	O
to	O
natural	B
image	O
matting	B
.	O
once	O
α	O
has	O
been	O
computed	O
,	O
the	O
foreground	O
and	O
background	O
colors	O
are	O
estimated	O
using	O
a	O
least	B
squares	I
minimization	O
of	O
the	O
compositing	B
equation	O
(	O
10.30	O
)	O
regularized	O
with	O
a	O
spatially	O
varying	O
ﬁrst-	O
order	B
smoothness	O
,	O
(	O
10.41	O
)	O
(	O
cid:107	O
)	O
ci	O
−	O
[	O
α	O
+	O
fi	O
+	O
(	O
1	O
−	O
αi	O
)	O
bi	O
]	O
(	O
cid:107	O
)	O
2	O
+	O
λ|∇αi|	O
(	O
(	O
cid:107	O
)	O
∇fi	O
(	O
cid:107	O
)	O
2	O
+	O
(	O
cid:107	O
)	O
∇bi	O
(	O
cid:107	O
)	O
2	O
)	O
,	O
eb	O
,	O
f	O
=	O
(	O
cid:88	O
)	O
i	O
where	O
the	O
|∇αi|	O
weight	O
is	O
applied	O
separately	O
for	O
the	O
x	O
and	O
y	O
components	O
of	O
the	O
f	O
and	O
b	O
derivatives	O
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2008	O
)	O
.	O
laplacian	O
(	O
closed-form	O
)	O
matting	B
is	O
just	O
one	O
of	O
many	O
optimization-based	B
techniques	O
sur-	O
veyed	O
and	O
compared	O
by	O
wang	O
and	O
cohen	O
(	O
2007a	O
)	O
.	O
some	O
of	O
these	O
techniques	O
use	O
alternative	O
formulations	O
for	O
the	O
afﬁnities	B
or	O
smoothness	B
terms	O
on	O
the	O
α	O
matte	O
,	O
alternative	O
estimation	B
techniques	O
such	O
as	O
belief	B
propagation	I
,	O
or	O
alternative	O
representations	O
(	O
e.g.	O
,	O
local	B
histograms	O
)	O
for	O
modeling	O
local	B
foreground	O
and	O
background	O
color	O
distributions	O
(	O
wang	O
and	O
cohen	O
2005	O
,	O
2007b	O
,	O
c	O
)	O
.	O
some	O
of	O
these	O
techniques	O
also	O
provide	O
real-time	O
results	O
as	O
the	O
user	O
draws	O
a	O
contour	O
line	O
or	O
sparse	B
set	O
of	O
scribbles	O
(	O
wang	O
,	O
agrawala	O
,	O
and	O
cohen	O
2007	O
;	O
rhemann	O
,	O
rother	O
,	O
rav-	O
acha	O
et	O
al	O
.	O
2008	O
)	O
or	O
even	O
pre-segment	O
the	O
image	B
into	O
a	O
small	O
number	O
of	O
mattes	O
that	O
the	O
user	O
can	O
select	O
with	O
simple	O
clicks	O
(	O
levin	O
,	O
acha	O
,	O
and	O
lischinski	O
2008	O
)	O
.	O
figure	O
10.44	O
shows	O
the	O
results	O
of	O
running	O
a	O
number	O
of	O
the	O
surveyed	O
algorithms	O
on	O
a	O
region	B
of	O
toy	O
animal	O
fur	O
where	O
a	O
trimap	B
has	O
been	O
speciﬁed	O
,	O
while	O
figure	O
10.45	O
shows	O
results	O
for	O
techniques	O
that	O
can	O
produce	O
mattes	O
with	O
only	O
a	O
few	O
scribbles	O
as	O
input	O
.	O
figure	O
10.46	O
shows	O
a	O
result	O
for	O
an	O
even	O
more	O
recent	O
algorithm	B
(	O
rhemann	O
,	O
rother	O
,	O
rav-acha	O
et	O
al	O
.	O
2008	O
)	O
that	O
claims	O
to	O
outperform	O
all	O
of	O
the	O
techniques	O
surveyed	O
by	O
wang	O
and	O
cohen	O
(	O
2007a	O
)	O
.	O
pasting	O
.	O
once	O
a	O
matte	O
has	O
been	O
pulled	O
from	O
an	O
image	B
,	O
it	O
is	O
usually	O
composited	O
directly	O
over	O
the	O
new	O
background	O
,	O
unless	O
the	O
seams	O
between	O
the	O
cutout	O
and	O
background	O
regions	O
are	O
516	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.45	O
comparative	O
matting	B
results	O
with	O
scribble-based	O
inputs	O
.	O
wang	O
and	O
cohen	O
(	O
2007a	O
)	O
describe	O
the	O
individual	O
techniques	O
being	O
compared	O
.	O
figure	O
10.46	O
stroke-based	O
segmentation	B
result	O
(	O
rhemann	O
,	O
rother	O
,	O
rav-acha	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
.	O
to	O
be	O
hidden	O
,	O
in	O
which	O
case	O
poisson	O
blending	B
(	O
p´erez	O
,	O
gangnet	O
,	O
and	O
blake	O
2003	O
)	O
can	O
be	O
used	O
(	O
section	O
9.3.4	O
)	O
.	O
in	O
the	O
latter	O
case	O
,	O
it	O
is	O
helpful	O
if	O
the	O
matte	O
boundary	O
passes	O
through	O
regions	O
that	O
either	O
have	O
little	O
texture	B
or	O
look	O
similar	O
in	O
the	O
old	O
and	O
new	O
images	O
.	O
papers	O
by	O
jia	O
,	O
sun	O
,	O
tang	O
et	O
al	O
.	O
(	O
2006	O
)	O
and	O
wang	O
and	O
cohen	O
(	O
2007c	O
)	O
explain	O
how	O
to	O
do	O
this	O
.	O
10.4.4	O
smoke	B
,	O
shadow	B
,	O
and	O
ﬂash	B
matting	O
in	O
addition	O
to	O
matting	B
out	O
solid	O
objects	O
with	O
fractional	O
boundaries	O
,	O
it	O
is	O
also	O
possible	O
to	O
matte	O
out	O
translucent	O
media	O
such	O
as	O
smoke	B
(	O
chuang	O
,	O
agarwala	O
,	O
curless	O
et	O
al	O
.	O
2002	O
)	O
.	O
starting	O
with	O
a	O
video	B
sequence	O
,	O
each	O
pixel	O
is	O
modeled	O
as	O
a	O
linear	B
combination	O
of	O
its	O
(	O
unknown	O
)	O
background	O
color	O
and	O
a	O
constant	O
foreground	O
(	O
smoke	B
)	O
color	B
that	O
is	O
common	O
to	O
all	O
pixels	O
.	O
voting	O
in	O
color	B
10.4	O
image	B
matting	O
and	O
compositing	B
517	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
10.47	O
smoke	B
matting	O
(	O
chuang	O
,	O
agarwala	O
,	O
curless	O
et	O
al	O
.	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
acm	O
:	O
(	O
a	O
)	O
input	O
video	B
frame	O
;	O
(	O
b	O
)	O
after	O
removing	O
the	O
foreground	O
object	O
;	O
(	O
c	O
)	O
estimated	O
alpha	B
matte	I
;	O
(	O
d	O
)	O
insertion	O
of	O
new	O
objects	O
into	O
the	O
background	O
.	O
figure	O
10.48	O
shadow	B
matting	O
(	O
chuang	O
,	O
goldman	O
,	O
curless	O
et	O
al	O
.	O
2003	O
)	O
c	O
(	O
cid:13	O
)	O
2003	O
acm	O
.	O
in-	O
stead	O
of	O
simply	O
darkening	O
the	O
new	O
scene	O
with	O
the	O
shadow	B
(	O
c	O
)	O
,	O
shadow	B
matting	O
correctly	O
dims	O
the	O
lit	O
scene	O
with	O
the	O
new	O
shadow	B
and	O
drapes	O
the	O
shadow	B
over	O
3d	O
geometry	O
(	O
d	O
)	O
.	O
space	O
is	O
used	O
to	O
estimate	O
this	O
foreground	O
color	B
and	O
the	O
distance	O
along	O
each	O
color	B
line	O
is	O
used	O
to	O
estimate	O
the	O
per-pixel	O
temporally	O
varying	O
alpha	O
(	O
figure	O
10.47	O
)	O
.	O
extracting	O
and	O
re-inserting	O
shadows	O
is	O
also	O
possible	O
using	O
a	O
related	O
technique	O
(	O
chuang	O
,	O
goldman	O
,	O
curless	O
et	O
al	O
.	O
2003	O
)	O
.	O
here	O
,	O
instead	O
of	O
assuming	O
a	O
constant	O
foreground	O
color	B
,	O
each	O
pixel	O
is	O
assumed	O
to	O
vary	O
between	O
its	O
fully	O
lit	O
and	O
fully	O
shadowed	O
colors	O
,	O
which	O
can	O
be	O
esti-	O
mated	O
by	O
taking	O
(	O
robust	B
)	O
minimum	O
and	O
maximum	O
values	O
over	O
time	O
as	O
a	O
shadow	B
passes	O
over	O
the	O
scene	O
(	O
exercise	O
10.9	O
)	O
.	O
the	O
resulting	O
fractional	O
shadow	B
matte	O
can	O
be	O
used	O
to	O
re-project	O
the	O
shadow	B
into	O
a	O
new	O
scene	O
.	O
if	O
the	O
destination	O
scene	O
has	O
a	O
non-planar	O
geometry	O
,	O
it	O
can	O
be	O
scanned	O
by	O
waving	O
a	O
straight	O
stick	O
shadow	B
across	O
the	O
scene	O
.	O
the	O
new	O
shadow	B
matte	O
can	O
then	O
be	O
warped	O
with	O
the	O
computed	O
deformation	O
ﬁeld	O
to	O
have	O
it	O
drape	O
correctly	O
over	O
the	O
new	O
scene	O
(	O
figure	O
10.48	O
)	O
.	O
the	O
quality	O
and	O
reliability	O
of	O
matting	B
algorithms	O
can	O
also	O
be	O
enhanced	O
using	O
more	O
sophis-	O
ticated	O
acquisition	O
systems	O
.	O
for	O
example	O
,	O
taking	O
a	O
ﬂash	B
and	I
non-ﬂash	I
image	O
pair	O
supports	O
the	O
reliable	O
extraction	O
of	O
foreground	O
mattes	O
,	O
which	O
show	O
up	O
as	O
regions	O
of	O
large	O
illumination	O
change	O
between	O
the	O
two	O
images	O
(	O
sun	O
,	O
li	O
,	O
kang	O
et	O
al	O
.	O
2006	O
)	O
.	O
taking	O
simultaneous	O
video	B
streams	O
focused	O
at	O
different	O
distances	O
(	O
mcguire	O
,	O
matusik	O
,	O
pﬁster	O
et	O
al	O
.	O
2005	O
)	O
or	O
using	O
multi-	O
camera	B
arrays	O
(	O
joshi	O
,	O
matusik	O
,	O
and	O
avidan	O
2006	O
)	O
are	O
also	O
good	O
approaches	O
to	O
producing	O
518	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
high-quality	O
mattes	O
.	O
these	O
techniques	O
are	O
described	O
in	O
more	O
detail	O
in	O
(	O
wang	O
and	O
cohen	O
2007a	O
)	O
.	O
lastly	O
,	O
photographing	O
a	O
refractive	O
object	O
in	O
front	O
of	O
a	O
number	O
of	O
patterned	O
backgrounds	O
allows	O
the	O
object	O
to	O
be	O
placed	O
in	O
novel	O
3d	O
environments	O
.	O
these	O
environment	O
matting	O
tech-	O
niques	O
(	O
zongker	O
,	O
werner	O
,	O
curless	O
et	O
al	O
.	O
1999	O
;	O
chuang	O
,	O
zongker	O
,	O
hindorff	O
et	O
al	O
.	O
2000	O
)	O
are	O
discussed	O
in	O
section	O
13.4	O
.	O
10.4.5	O
video	B
matting	O
while	O
regular	O
single-frame	O
matting	B
techniques	O
such	O
as	O
blue	O
or	O
green	O
screen	O
matting	B
(	O
smith	O
and	O
blinn	O
1996	O
;	O
wright	O
2006	O
;	O
brinkmann	O
2008	O
)	O
can	O
be	O
applied	O
to	O
video	B
sequences	O
,	O
the	O
pres-	O
ence	O
of	O
moving	O
objects	O
can	O
sometimes	O
make	O
the	O
matting	B
process	O
easier	O
,	O
as	O
portions	O
of	O
the	O
background	O
may	O
get	O
revealed	O
in	O
preceding	O
or	O
subsequent	O
frames	O
.	O
chuang	O
,	O
agarwala	O
,	O
curless	O
et	O
al	O
.	O
(	O
2002	O
)	O
describe	O
a	O
nice	O
approach	O
to	O
this	O
video	B
matting	O
problem	O
,	O
where	O
foreground	O
objects	O
are	O
ﬁrst	O
removed	O
using	O
a	O
conservative	O
garbage	O
matte	O
and	O
the	O
resulting	O
background	O
plates	O
are	O
aligned	O
and	O
composited	O
to	O
yield	O
a	O
high-quality	O
back-	O
ground	O
estimate	O
.	O
they	O
also	O
describe	O
how	O
trimaps	O
drawn	O
at	O
sparse	B
keyframes	O
can	O
be	O
inter-	O
polated	O
to	O
in-between	O
frames	O
using	O
bi-direction	O
optic	O
ﬂow	O
.	O
alternative	O
approaches	O
to	O
video	B
matting	O
,	O
such	O
as	O
rotoscoping	B
,	O
which	O
involves	O
drawing	O
and	O
tracking	O
curves	O
in	O
video	B
sequences	O
(	O
agarwala	O
,	O
hertzmann	O
,	O
seitz	O
et	O
al	O
.	O
2004	O
)	O
,	O
are	O
discussed	O
in	O
the	O
matting	B
survey	O
paper	O
by	O
wang	O
and	O
cohen	O
(	O
2007a	O
)	O
.	O
10.5	O
texture	B
analysis	O
and	O
synthesis	O
while	O
texture	B
analysis	O
and	O
synthesis	O
may	O
not	O
at	O
ﬁrst	O
seem	O
like	O
computational	O
photography	O
techniques	O
,	O
they	O
are	O
,	O
in	O
fact	O
,	O
widely	O
used	O
to	O
repair	O
defects	O
,	O
such	O
as	O
small	O
holes	O
,	O
in	O
images	O
or	O
to	O
create	O
non-photorealistic	O
painterly	O
renderings	O
from	O
regular	O
photographs	O
.	O
the	O
problem	O
of	O
texture	B
synthesis	O
can	O
be	O
formulated	O
as	O
follows	O
:	O
given	O
a	O
small	O
sample	O
of	O
a	O
“	O
texture	B
”	O
(	O
figure	O
10.49a	O
)	O
,	O
generate	O
a	O
larger	O
similar-looking	O
image	B
(	O
figure	O
10.49b	O
)	O
.	O
as	O
you	O
can	O
imagine	O
,	O
for	O
certain	O
sample	O
textures	O
,	O
this	O
problem	O
can	O
be	O
quite	O
challenging	O
.	O
traditional	O
approaches	O
to	O
texture	B
analysis	O
and	O
synthesis	O
try	O
to	O
match	O
the	O
spectrum	O
of	O
the	O
source	O
image	B
while	O
generating	O
shaped	O
noise	B
.	O
matching	B
the	O
frequency	O
characteristics	O
,	O
which	O
is	O
equivalent	O
to	O
matching	B
spatial	O
correlations	O
,	O
is	O
in	O
itself	O
not	O
sufﬁcient	O
.	O
the	O
distributions	O
of	O
the	O
responses	O
at	O
different	O
frequencies	O
must	O
also	O
match	O
.	O
heeger	O
and	O
bergen	O
(	O
1995	O
)	O
develop	O
an	O
algorithm	B
that	O
alternates	O
between	O
matching	B
the	O
histograms	O
of	O
multi-scale	O
(	O
steerable	B
pyramid	O
)	O
responses	O
and	O
matching	B
the	O
ﬁnal	O
image	B
histogram	O
.	O
portilla	O
and	O
simoncelli	O
(	O
2000	O
)	O
improve	O
on	O
this	O
technique	O
by	O
also	O
matching	B
pairwise	O
statistics	O
across	O
scale	O
and	O
orientations	O
.	O
de	O
bonet	O
(	O
1997	O
)	O
uses	O
a	O
coarse-to-ﬁne	B
strategy	O
to	O
ﬁnd	O
locations	O
in	O
the	O
source	O
texture	B
with	O
a	O
similar	O
10.5	O
texture	B
analysis	O
and	O
synthesis	O
519	O
radishes	O
(	O
a	O
)	O
lots	O
more	O
radishes	O
(	O
b	O
)	O
rocks	O
yogurt	O
(	O
c	O
)	O
figure	O
10.49	O
texture	B
synthesis	O
:	O
(	O
a	O
)	O
given	O
a	O
small	O
patch	B
of	O
texture	B
,	O
the	O
task	O
is	O
to	O
synthesize	O
(	O
b	O
)	O
a	O
similar-looking	O
larger	O
patch	B
;	O
(	O
c	O
)	O
other	O
semi-structured	O
textures	O
that	O
are	O
challenging	O
to	O
synthesize	O
.	O
(	O
images	O
courtesy	O
of	O
alyosha	O
efros	O
.	O
)	O
parent	O
structure	O
,	O
i.e.	O
,	O
similar	O
multi-scale	O
oriented	B
ﬁlter	O
responses	O
,	O
and	O
then	O
randomly	O
chooses	O
one	O
of	O
these	O
matching	B
locations	O
as	O
the	O
current	O
sample	O
value	O
.	O
more	O
recent	O
texture	B
synthesis	O
algorithms	O
sequentially	O
generate	O
texture	B
pixels	O
by	O
looking	O
for	O
neighborhoods	O
in	O
the	O
source	O
texture	B
that	O
are	O
similar	O
to	O
the	O
currently	O
synthesized	O
image	B
(	O
efros	O
and	O
leung	O
1999	O
)	O
.	O
consider	O
the	O
(	O
as	O
yet	O
)	O
unknown	O
pixel	O
p	O
in	O
the	O
partially	O
constructed	O
texture	B
on	O
the	O
left	O
side	O
of	O
figure	O
10.50.	O
since	O
some	O
of	O
its	O
neighboring	O
pixels	O
have	O
been	O
already	O
been	O
synthesized	O
,	O
we	O
can	O
look	O
for	O
similar	O
partial	O
neighborhoods	O
in	O
the	O
sample	O
texture	B
image	O
on	O
the	O
right	O
and	O
randomly	O
select	O
one	O
of	O
these	O
as	O
the	O
new	O
value	O
of	O
p.	O
this	O
process	O
can	O
be	O
repeated	O
down	O
the	O
new	O
image	B
either	O
in	O
a	O
raster	O
fashion	O
or	O
by	O
scanning	O
around	O
the	O
periphery	O
(	O
“	O
onion	O
peeling	O
”	O
)	O
when	O
ﬁlling	O
holes	O
,	O
as	O
discussed	O
in	O
(	O
section	O
10.5.1	O
)	O
.	O
in	O
their	O
actual	O
implementation	O
,	O
efros	O
and	O
leung	O
(	O
1999	O
)	O
ﬁnd	O
the	O
most	O
similar	O
neighborhood	B
and	O
then	O
include	O
all	O
other	O
neighborhoods	O
within	O
a	O
d	O
=	O
(	O
1	O
+	O
	O
)	O
distance	O
,	O
with	O
	O
=	O
0.1.	O
they	O
also	O
optionally	O
weight	O
the	O
random	O
pixel	O
selections	O
by	O
the	O
similarity	B
metric	O
d.	O
to	O
accelerate	O
this	O
process	O
and	O
improve	O
its	O
visual	O
quality	O
,	O
wei	O
and	O
levoy	O
(	O
2000	O
)	O
extend	O
this	O
technique	O
using	O
a	O
coarse-to-ﬁne	B
generation	O
process	O
,	O
where	O
coarser	O
levels	O
of	O
the	O
pyramid	B
,	O
which	O
have	O
already	O
been	O
synthesized	O
,	O
are	O
also	O
considered	O
during	O
the	O
matching	B
(	O
de	O
bonet	O
1997	O
)	O
.	O
to	O
accelerate	O
the	O
nearest	B
neighbor	I
ﬁnding	O
,	O
tree-structured	O
vector	O
quantization	B
is	O
used	O
.	O
efros	O
and	O
freeman	O
(	O
2001	O
)	O
propose	O
an	O
alternative	O
acceleration	O
and	O
visual	O
quality	O
improve-	O
520	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
10.50	O
texture	B
synthesis	O
using	O
non-parametric	O
sampling	B
(	O
efros	O
and	O
leung	O
1999	O
)	O
.	O
the	O
value	O
of	O
the	O
newest	O
pixel	O
p	O
is	O
randomly	O
chosen	O
from	O
similar	O
local	B
(	O
partial	O
)	O
patches	O
in	O
the	O
source	O
texture	B
(	O
input	O
image	B
)	O
.	O
(	O
figure	O
courtesy	O
of	O
alyosha	O
efros	O
.	O
)	O
figure	O
10.51	O
texture	B
synthesis	O
by	O
image	O
quilting	O
(	O
efros	O
and	O
freeman	O
2001	O
)	O
.	O
instead	O
of	O
generating	O
a	O
single	O
pixel	O
at	O
a	O
time	O
,	O
larger	O
blocks	O
are	O
copied	O
from	O
the	O
source	O
texture	B
.	O
the	O
tran-	O
sitions	O
in	O
the	O
overlap	O
regions	O
between	O
the	O
selected	O
blocks	O
are	O
then	O
optimized	O
using	O
dynamic	O
programming	O
.	O
(	O
figure	O
courtesy	O
of	O
alyosha	O
efros	O
.	O
)	O
ment	O
technique	O
.	O
instead	O
of	O
synthesizing	O
a	O
single	O
pixel	O
at	O
a	O
time	O
,	O
overlapping	O
square	O
blocks	O
are	O
selected	O
using	O
similarity	O
with	O
previously	O
synthesized	O
regions	O
(	O
figure	O
10.51	O
)	O
.	O
once	O
the	O
appropriate	O
blocks	O
have	O
been	O
selected	O
,	O
the	O
seam	O
between	O
newly	O
overlapping	O
blocks	O
is	O
deter-	O
mined	O
using	O
dynamic	O
programming	O
.	O
(	O
full	O
graph	B
cut	I
seam	O
selection	O
is	O
not	O
required	O
,	O
since	O
only	O
one	O
seam	O
location	O
per	O
row	O
is	O
needed	O
for	O
a	O
vertical	O
boundary	O
.	O
)	O
because	O
this	O
process	O
involves	O
selecting	O
small	O
patches	O
and	O
them	O
stitching	O
them	O
together	O
,	O
efros	O
and	O
freeman	O
(	O
2001	O
)	O
call	O
their	O
system	O
image	B
quilting	I
.	O
komodakis	O
and	O
tziritas	O
(	O
2007b	O
)	O
present	O
an	O
mrf-based	O
version	O
of	O
this	O
block	O
synthesis	O
algorithm	B
that	O
uses	O
a	O
new	O
,	O
efﬁcient	O
version	O
of	O
loopy	B
belief	I
propagation	I
they	O
call	O
“	O
priority-bp	O
”	O
.	O
ppnon-parametricsamplinginput	O
imageoutput	O
imageppinput	O
imagenon-parametricsamplingbboutput	O
imageb1b2minimal	O
errorboundary	O
cut	O
10.5	O
texture	B
analysis	O
and	O
synthesis	O
521	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
10.52	O
image	B
inpainting	O
(	O
hole	B
ﬁlling	I
)	O
:	O
(	O
a–b	O
)	O
propagation	O
along	O
isophote	O
directions	O
(	O
bertalmio	O
,	O
sapiro	O
,	O
caselles	O
et	O
al	O
.	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
acm	O
;	O
(	O
c–d	O
)	O
exemplar-based	O
inpainting	B
with	O
conﬁdence-based	O
ﬁlling	O
order	B
(	O
criminisi	O
,	O
p´erez	O
,	O
and	O
toyama	O
2004	O
)	O
.	O
10.5.1	O
application	O
:	O
hole	B
ﬁlling	I
and	O
inpainting	B
filling	O
holes	O
left	O
behind	O
when	O
objects	O
or	O
defects	O
are	O
excised	O
from	O
photographs	O
,	O
which	O
is	O
known	O
as	O
inpainting	B
,	O
is	O
one	O
of	O
the	O
most	O
common	O
applications	O
of	O
texture	B
synthesis	O
.	O
such	O
techniques	O
are	O
used	O
not	O
only	O
to	O
remove	O
unwanted	O
people	O
or	O
interlopers	O
from	O
photographs	O
(	O
king	O
1997	O
)	O
but	O
also	O
to	O
ﬁx	O
small	O
defects	O
in	O
old	O
photos	O
and	O
movies	O
(	O
scratch	B
removal	I
)	O
or	O
to	O
remove	O
wires	O
holding	O
props	O
or	O
actors	O
in	O
mid-air	O
during	O
ﬁlming	O
(	O
wire	O
removal	O
)	O
.	O
bertalmio	O
,	O
sapiro	O
,	O
caselles	O
et	O
al	O
.	O
(	O
2000	O
)	O
solve	O
the	O
problem	O
by	O
propagating	O
pixel	O
values	O
along	O
isophote	O
(	O
constant-value	O
)	O
directions	O
interleaved	O
with	O
some	O
anisotropic	B
diffusion	O
steps	O
(	O
figure	O
10.52a–	O
b	O
)	O
.	O
telea	O
(	O
2004	O
)	O
develops	O
a	O
faster	O
technique	O
that	O
uses	O
the	O
fast	B
marching	I
method	I
from	O
level	B
sets	I
(	O
section	O
5.1.4	O
)	O
.	O
however	O
,	O
these	O
techniques	O
will	O
not	O
hallucinate	O
texture	B
in	O
the	O
missing	O
regions	O
.	O
bertalmio	O
,	O
vese	O
,	O
sapiro	O
et	O
al	O
.	O
(	O
2003	O
)	O
augment	O
their	O
earlier	O
technique	O
by	O
adding	O
synthetic	O
texture	B
to	O
the	O
inﬁlled	O
regions	O
.	O
the	O
example-based	B
(	O
non-parametric	B
)	O
texture	B
generation	O
techniques	O
discussed	O
in	O
the	O
pre-	O
vious	O
section	O
can	O
also	O
be	O
used	O
by	O
ﬁlling	O
the	O
holes	O
from	O
the	O
outside	O
in	O
(	O
the	O
“	O
onion-peel	O
”	O
or-	O
dering	O
)	O
.	O
however	O
,	O
this	O
approach	O
may	O
fail	O
to	O
propagate	O
strong	O
oriented	B
structures	O
.	O
criminisi	O
,	O
p´erez	O
,	O
and	O
toyama	O
(	O
2004	O
)	O
use	O
exemplar-based	O
texture	B
synthesis	O
where	O
the	O
order	B
of	O
synthesis	O
is	O
determined	O
by	O
the	O
strength	O
of	O
the	O
gradient	O
along	O
the	O
region	B
boundary	O
(	O
figures	O
10.1d	O
and	O
10.52c–d	O
)	O
.	O
sun	O
,	O
yuan	O
,	O
jia	O
et	O
al	O
.	O
(	O
2004	O
)	O
present	O
a	O
related	O
approach	O
where	O
the	O
user	O
draws	O
in-	O
teractive	O
lines	B
to	O
indicate	O
where	O
structures	O
should	O
be	O
preferentially	O
propagated	O
.	O
additional	O
techniques	O
related	O
to	O
these	O
approaches	O
include	O
those	O
developed	O
by	O
drori	O
,	O
cohen-or	O
,	O
and	O
yeshurun	O
(	O
2003	O
)	O
,	O
kwatra	O
,	O
sch¨odl	O
,	O
essa	O
et	O
al	O
.	O
(	O
2003	O
)	O
,	O
kwatra	O
,	O
essa	O
,	O
bobick	O
et	O
al	O
.	O
(	O
2005	O
)	O
,	O
wilczkowiak	O
,	O
brostow	O
,	O
tordoff	O
et	O
al	O
.	O
(	O
2005	O
)	O
,	O
komodakis	O
and	O
tziritas	O
(	O
2007b	O
)	O
,	O
and	O
wexler	O
,	O
shechtman	O
,	O
and	O
irani	O
(	O
2007	O
)	O
.	O
most	O
hole	B
ﬁlling	I
algorithms	O
borrow	O
small	O
pieces	O
of	O
the	O
original	O
image	B
to	O
ﬁll	O
in	O
the	O
holes	O
.	O
when	O
a	O
large	O
database	O
of	O
source	O
images	O
is	O
available	O
,	O
e.g.	O
,	O
when	O
images	O
are	O
taken	O
from	O
a	O
522	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
10.53	O
texture	B
transfer	O
(	O
efros	O
and	O
freeman	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
acm	O
:	O
(	O
a	O
)	O
reference	O
(	O
tar-	O
get	O
)	O
image	B
;	O
(	O
b	O
)	O
source	O
texture	B
;	O
(	O
c	O
)	O
image	B
(	O
partially	O
)	O
rendered	O
using	O
the	O
texture	B
.	O
photo	O
sharing	O
site	O
or	O
the	O
internet	O
,	O
it	O
is	O
sometimes	O
possible	O
to	O
copy	O
a	O
single	O
contiguous	O
image	B
region	O
to	O
ﬁll	O
the	O
hole	O
.	O
hays	O
and	O
efros	O
(	O
2007	O
)	O
present	O
such	O
a	O
technique	O
,	O
which	O
uses	O
image	B
context	O
and	O
boundary	O
compatibility	O
to	O
select	O
the	O
source	O
image	B
,	O
which	O
is	O
then	O
blended	O
with	O
the	O
original	O
(	O
holey	O
)	O
image	B
using	O
graph	B
cuts	I
and	O
poisson	O
blending	B
.	O
this	O
technique	O
is	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
14.4.4	O
and	O
figure	O
14.46	O
.	O
10.5.2	O
application	O
:	O
non-photorealistic	B
rendering	I
two	O
more	O
applications	O
of	O
the	O
exemplar-based	O
texture	B
synthesis	O
ideas	O
are	O
texture	B
transfer	O
(	O
efros	O
and	O
freeman	O
2001	O
)	O
and	O
image	B
analogies	O
(	O
hertzmann	O
,	O
jacobs	O
,	O
oliver	O
et	O
al	O
.	O
2001	O
)	O
,	O
which	O
are	O
both	O
examples	B
of	O
non-photorealistic	B
rendering	I
(	O
gooch	O
and	O
gooch	O
2001	O
)	O
.	O
in	O
addition	O
to	O
using	O
a	O
source	O
texture	B
image	O
,	O
texture	B
transfer	O
also	O
takes	O
a	O
reference	O
(	O
or	O
target	O
)	O
image	B
,	O
and	O
tries	O
to	O
match	O
certain	O
characteristics	O
of	O
the	O
target	O
image	B
with	O
the	O
newly	O
synthesized	O
image	B
.	O
for	O
example	O
,	O
the	O
new	O
image	B
being	O
rendered	O
in	O
figure	O
10.53c	O
not	O
only	O
tries	O
to	O
satisfy	O
the	O
usual	O
similarity	B
constraints	O
with	O
the	O
source	O
texture	B
in	O
figure	O
10.53b	O
,	O
but	O
it	O
also	O
tries	O
to	O
match	O
the	O
luminance	O
characteristics	O
of	O
the	O
reference	O
image	B
.	O
efros	O
and	O
freeman	O
(	O
2001	O
)	O
mention	O
that	O
blurred	O
image	B
intensities	O
or	O
local	B
image	O
orientation	O
angles	O
are	O
alternative	O
quantities	O
that	O
could	O
be	O
matched	O
.	O
hertzmann	O
,	O
jacobs	O
,	O
oliver	O
et	O
al	O
.	O
(	O
2001	O
)	O
formulate	O
the	O
following	O
problem	O
:	O
given	O
a	O
pair	O
of	O
images	O
a	O
and	O
a	O
(	O
cid:48	O
)	O
(	O
the	O
unﬁltered	O
and	O
ﬁltered	O
source	O
images	O
,	O
re-	O
spectively	O
)	O
,	O
along	O
with	O
some	O
additional	O
unﬁltered	O
target	O
image	B
b	O
,	O
synthesize	O
a	O
new	O
ﬁltered	O
target	O
image	B
b	O
(	O
cid:48	O
)	O
such	O
that	O
a	O
:	O
a	O
(	O
cid:48	O
)	O
:	O
:	O
b	O
:	O
b	O
(	O
cid:48	O
)	O
.	O
10.5	O
texture	B
analysis	O
and	O
synthesis	O
523	O
a	O
a	O
(	O
cid:48	O
)	O
b	O
b	O
(	O
cid:48	O
)	O
figure	O
10.54	O
image	B
analogies	O
(	O
hertzmann	O
,	O
jacobs	O
,	O
oliver	O
et	O
al	O
.	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
acm	O
.	O
given	O
an	O
example	O
pair	O
of	O
a	O
source	O
image	B
a	O
and	O
its	O
rendered	O
(	O
ﬁltered	O
)	O
version	O
a	O
(	O
cid:48	O
)	O
,	O
generate	O
the	O
rendered	O
version	O
b	O
(	O
cid:48	O
)	O
from	O
another	O
unﬁltered	O
source	O
image	B
b.	O
instead	O
of	O
having	O
the	O
user	O
program	O
a	O
certain	O
non-photorealistic	B
rendering	I
effect	O
,	O
it	O
is	O
sufﬁcient	O
to	O
supply	O
the	O
system	O
with	O
examples	O
of	O
before	O
and	O
after	O
images	O
,	O
and	O
let	O
the	O
system	O
synthesize	O
the	O
novel	O
image	B
using	O
exemplar-based	O
synthesis	O
,	O
as	O
shown	O
in	O
figure	O
10.54.	O
the	O
algorithm	B
used	O
to	O
solve	O
image	B
analogies	O
proceeds	O
in	O
a	O
manner	O
analogous	O
to	O
the	O
tex-	O
ture	O
synthesis	O
algorithms	O
of	O
(	O
efros	O
and	O
leung	O
1999	O
;	O
wei	O
and	O
levoy	O
2000	O
)	O
.	O
once	O
gaus-	O
sian	O
pyramids	O
have	O
been	O
computed	O
for	O
all	O
of	O
the	O
source	O
and	O
reference	O
images	O
,	O
the	O
algorithm	B
looks	O
for	O
neighborhoods	O
in	O
the	O
source	O
ﬁltered	O
pyramids	O
generated	O
from	O
a	O
(	O
cid:48	O
)	O
that	O
are	O
simi-	O
lar	O
to	O
the	O
partially	O
constructed	O
neighborhood	B
in	O
b	O
(	O
cid:48	O
)	O
,	O
while	O
at	O
the	O
same	O
time	O
having	O
similar	O
multi-resolution	O
appearances	O
at	O
corresponding	O
locations	O
in	O
a	O
and	O
b.	O
as	O
with	O
texture	O
trans-	O
fer	O
,	O
appearance	O
characteristics	O
can	O
include	O
not	O
only	O
(	O
blurred	O
)	O
color	B
or	O
luminance	O
values	O
but	O
also	O
orientations	O
.	O
this	O
general	O
framework	O
allows	O
image	B
analogies	O
to	O
be	O
applied	O
to	O
a	O
variety	O
of	O
rendering	B
tasks	O
.	O
in	O
addition	O
to	O
exemplar-based	O
non-photorealistic	B
rendering	I
,	O
image	B
analogies	O
can	O
be	O
used	O
for	O
traditional	O
texture	B
synthesis	O
,	O
super-resolution	O
,	O
and	O
texture	B
transfer	O
(	O
using	O
the	O
same	O
textured	O
image	B
for	O
both	O
a	O
and	O
a	O
(	O
cid:48	O
)	O
)	O
.	O
if	O
only	O
the	O
ﬁltered	O
(	O
rendered	O
)	O
image	B
a	O
(	O
cid:48	O
)	O
is	O
available	O
,	O
as	O
is	O
the	O
case	O
with	O
paintings	O
,	O
the	O
missing	O
reference	O
image	B
a	O
can	O
be	O
hallucinated	O
using	O
a	O
smart	O
(	O
edge	O
preserving	O
)	O
blur	O
operator	O
.	O
finally	O
,	O
it	O
is	O
possible	O
to	O
train	O
a	O
system	O
to	O
perform	O
texture-by-	O
numbers	O
by	O
manually	O
painting	O
over	O
a	O
natural	B
image	O
with	O
pseudocolors	O
corresponding	O
to	O
pix-	O
els	O
’	O
semantic	O
meanings	O
,	O
e.g.	O
,	O
water	O
,	O
trees	O
,	O
and	O
grass	O
(	O
figure	O
10.55a–b	O
)	O
.	O
the	O
resulting	O
system	O
can	O
then	O
convert	O
a	O
novel	O
sketch	O
into	O
a	O
fully	O
rendered	O
synthetic	O
photograph	O
(	O
figure	O
10.55c–d	O
)	O
.	O
in	O
more	O
recent	O
work	O
,	O
cheng	O
,	O
vishwanathan	O
,	O
and	O
zhang	O
(	O
2008	O
)	O
add	O
ideas	O
from	O
image	B
quilting	I
(	O
efros	O
and	O
freeman	O
2001	O
)	O
and	O
mrf	O
inference	B
(	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
2008	O
)	O
to	O
the	O
basic	O
image	B
analogies	O
algorithm	B
,	O
while	O
ramanarayanan	O
and	O
bala	O
(	O
2007	O
)	O
recast	O
this	O
pro-	O
cess	O
as	O
energy	O
minimization	O
,	O
which	O
means	O
it	O
can	O
also	O
be	O
viewed	O
as	O
a	O
conditional	O
random	O
ﬁeld	O
(	O
section	O
3.7.2	O
)	O
,	O
and	O
devise	O
an	O
efﬁcient	O
algorithm	B
to	O
ﬁnd	O
a	O
good	O
minimum	O
.	O
more	O
traditional	O
ﬁltering	O
and	O
feature	B
detection	O
techniques	O
can	O
also	O
be	O
used	O
for	O
non-	O
524	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
original	O
a	O
(	O
cid:48	O
)	O
painted	O
a	O
novel	O
textured	O
b	O
(	O
cid:48	O
)	O
figure	O
10.55	O
texture-by-numbers	O
(	O
hertzmann	O
,	O
jacobs	O
,	O
oliver	O
et	O
al	O
.	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
acm	O
.	O
given	O
a	O
textured	O
image	B
a	O
(	O
cid:48	O
)	O
and	O
a	O
hand-labeled	O
(	O
painted	O
)	O
version	O
a	O
,	O
synthesize	O
a	O
new	O
image	B
b	O
(	O
cid:48	O
)	O
given	O
just	O
the	O
painted	O
version	O
b.	O
novel	O
painted	O
b	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
10.56	O
non-photorealistic	O
abstraction	O
of	O
photographs	O
:	O
(	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
acm	O
and	O
(	O
b	O
)	O
farbman	O
,	O
fattal	O
,	O
lischinski	O
et	O
al	O
.	O
(	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
acm	O
.	O
(	O
a	O
)	O
decarlo	O
and	O
santella	O
photorealistic	O
rendering.23	O
for	O
example	O
,	O
pen-and-ink	O
illustration	O
(	O
winkenbach	O
and	O
salesin	O
1994	O
)	O
and	O
painterly	O
rendering	B
techniques	O
(	O
litwinowicz	O
1997	O
)	O
use	O
local	B
color	O
,	O
intensity	O
,	O
and	O
orientation	O
estimates	O
as	O
an	O
input	O
to	O
their	O
procedural	O
rendering	B
algorithms	O
.	O
techniques	O
for	O
stylizing	O
and	O
simplifying	O
photographs	O
and	O
video	B
(	O
decarlo	O
and	O
santella	O
2002	O
;	O
winnem¨oller	O
,	O
olsen	O
,	O
and	O
gooch	O
2006	O
;	O
farbman	O
,	O
fattal	O
,	O
lischinski	O
et	O
al	O
.	O
2008	O
)	O
,	O
as	O
in	O
figure	O
10.56	O
,	O
use	O
combinations	O
of	O
edge-preserving	B
blurring	O
(	O
section	O
3.3.1	O
)	O
and	O
edge	O
detection	O
and	O
enhance-	O
ment	O
(	O
section	O
4.2.3	O
)	O
.	O
10.6	O
additional	O
reading	O
a	O
good	O
overview	O
of	O
computational	O
photography	O
can	O
be	O
found	O
in	O
the	O
book	O
by	O
raskar	O
and	O
tumblin	O
(	O
2010	O
)	O
,	O
survey	O
articles	O
by	O
nayar	O
(	O
2006	O
)	O
,	O
cohen	O
and	O
szeliski	O
(	O
2006	O
)	O
,	O
levoy	O
(	O
2006	O
)	O
,	O
23	O
for	O
a	O
good	O
selection	O
of	O
papers	O
,	O
see	O
the	O
symposia	O
on	O
non-photorealistic	O
animation	O
and	O
rendering	B
(	O
npar	O
)	O
at	O
http	O
:	O
//www.npar.org/	O
.	O
10.6	O
additional	O
reading	O
525	O
debevec	O
(	O
2006	O
)	O
,	O
and	O
hayes	O
(	O
2008	O
)	O
,	O
as	O
well	O
as	O
two	O
special	O
journal	O
issues	O
edited	O
by	O
bimber	O
(	O
2006	O
)	O
and	O
durand	O
and	O
szeliski	O
(	O
2007	O
)	O
.	O
notes	O
from	O
the	O
courses	O
on	O
computational	O
photog-	O
raphy	O
mentioned	O
at	O
the	O
beginning	O
of	O
this	O
chapter	O
are	O
another	O
great	O
source	O
of	O
material	O
and	O
references.24	O
the	O
sub-ﬁeld	O
of	O
high	B
dynamic	I
range	I
imaging	O
has	O
its	O
own	O
book	O
discussing	O
research	O
in	O
this	O
area	O
(	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
2005	O
)	O
,	O
as	O
well	O
as	O
some	O
books	O
describing	O
related	O
pho-	O
tographic	O
techniques	O
(	O
freeman	O
2008	O
;	O
gulbins	O
and	O
gulbins	O
2009	O
)	O
.	O
algorithms	O
for	O
calibrating	O
the	O
radiometric	B
response	O
function	O
of	O
a	O
camera	B
can	O
be	O
found	O
in	O
articles	O
by	O
mann	O
and	O
picard	O
(	O
1995	O
)	O
,	O
debevec	O
and	O
malik	O
(	O
1997	O
)	O
,	O
and	O
mitsunaga	O
and	O
nayar	O
(	O
1999	O
)	O
.	O
the	O
subject	O
of	O
tone	B
mapping	I
is	O
treated	O
extensively	O
in	O
(	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
2005	O
)	O
.	O
representative	O
papers	O
from	O
the	O
large	O
volume	O
of	O
literature	O
on	O
this	O
topic	O
include	O
those	O
by	O
tumblin	O
and	O
rushmeier	O
(	O
1993	O
)	O
,	O
larson	O
,	O
rushmeier	O
,	O
and	O
piatko	O
(	O
1997	O
)	O
,	O
pattanaik	O
,	O
ferw-	O
erda	O
,	O
fairchild	O
et	O
al	O
.	O
(	O
1998	O
)	O
,	O
tumblin	O
and	O
turk	O
(	O
1999	O
)	O
,	O
durand	O
and	O
dorsey	O
(	O
2002	O
)	O
,	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
(	O
2002	O
)	O
,	O
reinhard	O
,	O
stark	O
,	O
shirley	O
et	O
al	O
.	O
(	O
2002	O
)	O
,	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
(	O
2006b	O
)	O
,	O
and	O
farbman	O
,	O
fattal	O
,	O
lischinski	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
the	O
literature	O
on	O
super-resolution	O
is	O
quite	O
extensive	O
(	O
chaudhuri	O
2001	O
;	O
park	O
,	O
park	O
,	O
and	O
kang	O
2003	O
;	O
capel	O
and	O
zisserman	O
2003	O
;	O
capel	O
2004	O
;	O
van	O
ouwerkerk	O
2006	O
)	O
.	O
the	O
term	O
super-	O
resolution	O
usually	O
describes	O
techniques	O
for	O
aligning	O
and	O
merging	B
multiple	O
images	O
to	O
produce	O
higher-resolution	O
composites	O
(	O
keren	O
,	O
peleg	O
,	O
and	O
brada	O
1988	O
;	O
irani	O
and	O
peleg	O
1991	O
;	O
cheese-	O
man	O
,	O
kanefsky	O
,	O
hanson	O
et	O
al	O
.	O
1993	O
;	O
mann	O
and	O
picard	O
1994	O
;	O
chiang	O
and	O
boult	O
1996	O
;	O
bascle	O
,	O
blake	O
,	O
and	O
zisserman	O
1996	O
;	O
capel	O
and	O
zisserman	O
1998	O
;	O
smelyanskiy	O
,	O
cheeseman	O
,	O
maluf	O
et	O
al	O
.	O
2000	O
;	O
capel	O
and	O
zisserman	O
2000	O
;	O
pickup	O
,	O
capel	O
,	O
roberts	O
et	O
al	O
.	O
2009	O
;	O
gulbins	O
and	O
gul-	O
bins	O
2009	O
)	O
.	O
however	O
,	O
single-image	O
super-resolution	O
techniques	O
have	O
also	O
been	O
developed	O
(	O
freeman	O
,	O
jones	O
,	O
and	O
pasztor	O
2002	O
;	O
baker	O
and	O
kanade	O
2002	O
;	O
fattal	O
2007	O
)	O
.	O
a	O
good	O
survey	O
on	O
image	B
matting	O
is	O
given	O
by	O
wang	O
and	O
cohen	O
(	O
2007a	O
)	O
.	O
representative	O
papers	O
,	O
which	O
include	O
extensive	O
comparisons	O
with	O
previous	O
work	O
,	O
include	O
those	O
by	O
chuang	O
,	O
curless	O
,	O
salesin	O
et	O
al	O
.	O
(	O
2001	O
)	O
,	O
wang	O
and	O
cohen	O
(	O
2007b	O
)	O
,	O
levin	O
,	O
acha	O
,	O
and	O
lischinski	O
(	O
2008	O
)	O
,	O
rhemann	O
,	O
rother	O
,	O
rav-acha	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
and	O
rhemann	O
,	O
rother	O
,	O
wang	O
et	O
al	O
.	O
(	O
2009	O
)	O
.	O
the	O
literature	O
on	O
texture	B
synthesis	O
and	O
hole	B
ﬁlling	I
includes	O
traditional	O
approaches	O
to	O
tex-	O
ture	O
synthesis	O
,	O
which	O
try	O
to	O
match	O
image	O
statistics	O
between	O
source	O
and	O
destination	O
images	O
(	O
heeger	O
and	O
bergen	O
1995	O
;	O
de	O
bonet	O
1997	O
;	O
portilla	O
and	O
simoncelli	O
2000	O
)	O
,	O
as	O
well	O
as	O
newer	O
approaches	O
,	O
which	O
search	O
for	O
matching	O
neighborhoods	O
or	O
patches	O
inside	O
the	O
source	O
sample	O
(	O
efros	O
and	O
leung	O
1999	O
;	O
wei	O
and	O
levoy	O
2000	O
;	O
efros	O
and	O
freeman	O
2001	O
)	O
.	O
in	O
a	O
similar	O
vein	O
,	O
traditional	O
approaches	O
to	O
hole	B
ﬁlling	I
involve	O
the	O
solution	O
of	O
local	B
variational	O
(	O
smooth	O
continu-	O
ation	O
)	O
problems	O
(	O
bertalmio	O
,	O
sapiro	O
,	O
caselles	O
et	O
al	O
.	O
2000	O
;	O
bertalmio	O
,	O
vese	O
,	O
sapiro	O
et	O
al	O
.	O
2003	O
;	O
24	O
mit	O
6.815/6.865	O
,	O
http	O
:	O
//stellar.mit.edu/s/course/6/sp08/6.815/materials.html	O
,	O
cmu	O
15-463	O
,	O
http	O
:	O
//graphics.cs	O
.	O
cmu.edu/courses/15-463/2008	O
fall/	O
,	O
stanford	O
cs	O
448a	O
,	O
http	O
:	O
//graphics.stanford.edu/courses/cs448a-08-spring/	O
,	O
and	O
siggraph	O
courses	O
,	O
http	O
:	O
//web.media.mit.edu/∼raskar/photo/	O
.	O
526	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
telea	O
2004	O
)	O
.	O
more	O
recent	O
techniques	O
use	O
data-driven	O
texture	B
synthesis	O
approaches	O
(	O
drori	O
,	O
cohen-or	O
,	O
and	O
yeshurun	O
2003	O
;	O
kwatra	O
,	O
sch¨odl	O
,	O
essa	O
et	O
al	O
.	O
2003	O
;	O
criminisi	O
,	O
p´erez	O
,	O
and	O
toyama	O
2004	O
;	O
sun	O
,	O
yuan	O
,	O
jia	O
et	O
al	O
.	O
2004	O
;	O
kwatra	O
,	O
essa	O
,	O
bobick	O
et	O
al	O
.	O
2005	O
;	O
wilczkowiak	O
,	O
brostow	O
,	O
tordoff	O
et	O
al	O
.	O
2005	O
;	O
komodakis	O
and	O
tziritas	O
2007b	O
;	O
wexler	O
,	O
shechtman	O
,	O
and	O
irani	O
2007	O
)	O
.	O
10.7	O
exercises	O
ex	O
10.1	O
:	O
radiometric	B
calibration	O
implement	O
one	O
of	O
the	O
multi-exposure	O
radiometric	B
cali-	O
bration	O
algorithms	O
described	O
in	O
section	O
10.2	O
(	O
debevec	O
and	O
malik	O
1997	O
;	O
mitsunaga	O
and	O
nayar	O
1999	O
;	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
2005	O
)	O
.	O
this	O
calibration	B
will	O
be	O
useful	O
in	O
a	O
number	O
of	O
different	O
applications	O
,	O
such	O
as	O
stitching	O
images	O
or	O
stereo	B
matching	I
with	O
different	O
exposures	O
and	O
shape	O
from	O
shading	B
.	O
1.	O
take	O
a	O
series	O
of	O
bracketed	O
images	O
with	O
your	O
camera	B
on	O
a	O
tripod	O
.	O
if	O
your	O
camera	B
has	O
an	O
automatic	B
exposure	O
bracketing	O
(	O
aeb	O
)	O
mode	O
,	O
taking	O
three	O
images	O
may	O
be	O
sufﬁcient	O
to	O
calibrate	O
most	O
of	O
your	O
camera	B
’	O
s	O
dynamic	B
range	O
,	O
especially	O
if	O
your	O
scene	O
has	O
a	O
lot	O
of	O
bright	O
and	O
dark	O
regions	O
.	O
(	O
shooting	O
outdoors	O
or	O
through	O
a	O
window	O
on	O
a	O
sunny	O
day	O
is	O
best	O
.	O
)	O
2.	O
if	O
your	O
images	O
are	O
not	O
taken	O
on	O
a	O
tripod	O
,	O
ﬁrst	O
perform	O
a	O
global	B
alignment	I
(	O
similarity	B
transform	O
)	O
.	O
3.	O
estimate	O
the	O
radiometric	B
response	O
function	O
using	O
one	O
of	O
the	O
techniques	O
cited	O
above	O
.	O
4.	O
estimate	O
the	O
high	B
dynamic	I
range	I
radiance	O
image	B
by	O
selecting	O
or	O
blending	B
pixels	O
from	O
different	O
exposures	O
(	O
debevec	O
and	O
malik	O
1997	O
;	O
mitsunaga	O
and	O
nayar	O
1999	O
;	O
eden	O
,	O
uyt-	O
tendaele	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
5.	O
repeat	O
your	O
calibration	B
experiments	O
under	O
different	O
conditions	O
,	O
e.g.	O
,	O
indoors	O
under	O
in-	O
candescent	O
light	O
,	O
to	O
get	O
a	O
sense	O
for	O
the	O
range	O
of	O
color	B
balancing	O
effects	O
that	O
your	O
camera	B
imposes	O
.	O
6.	O
if	O
your	O
camera	B
supports	O
raw	O
and	O
jpeg	O
mode	O
,	O
calibrate	O
both	O
sets	O
of	O
images	O
simulta-	O
neously	O
and	O
to	O
each	O
other	O
(	O
the	O
radiance	O
at	O
each	O
pixel	O
will	O
correspond	O
)	O
.	O
see	O
if	O
you	O
can	O
come	O
up	O
with	O
a	O
model	O
for	O
what	O
your	O
camera	B
does	O
,	O
e.g.	O
,	O
whether	O
it	O
treats	O
color	B
balance	I
as	O
a	O
diagonal	O
or	O
full	O
3	O
×	O
3	O
matrix	O
multiply	O
,	O
whether	O
it	O
uses	O
non-linearities	O
in	O
addition	O
to	O
gamma	B
,	O
whether	O
it	O
sharpens	O
the	O
image	B
while	O
“	O
developing	O
”	O
the	O
jpeg	O
image	B
,	O
etc	O
.	O
7.	O
develop	O
an	O
interactive	B
viewer	O
to	O
change	O
the	O
exposure	O
of	O
an	O
image	B
based	O
on	O
the	O
average	O
exposure	O
of	O
a	O
region	B
around	O
the	O
mouse	O
.	O
(	O
one	O
variant	O
is	O
to	O
show	O
the	O
adjusted	O
image	B
10.7	O
exercises	O
527	O
inside	O
a	O
window	O
around	O
the	O
mouse	O
.	O
another	O
is	O
to	O
adjust	O
the	O
complete	O
image	B
based	O
on	O
the	O
mouse	O
position	O
.	O
)	O
8.	O
implement	O
a	O
tone	B
mapping	I
operator	O
(	O
exercise	O
10.5	O
)	O
and	O
use	O
this	O
to	O
map	O
your	O
radiance	O
image	B
to	O
a	O
displayable	O
gamut	O
.	O
ex	O
10.2	O
:	O
noise	B
level	O
function	O
determine	O
your	O
camera	B
’	O
s	O
noise	B
level	O
function	O
using	O
either	O
multiple	B
shots	O
or	O
by	O
analyzing	O
smooth	O
regions	O
.	O
1.	O
set	O
up	O
your	O
camera	B
on	O
a	O
tripod	O
looking	O
at	O
a	O
calibration	B
target	O
or	O
a	O
static	O
scene	O
with	O
a	O
good	O
variation	O
in	O
input	O
levels	O
and	O
colors	O
.	O
(	O
check	O
your	O
camera	B
’	O
s	O
histogram	B
to	O
ensure	O
that	O
all	O
values	O
are	O
being	O
sampled	O
.	O
)	O
2.	O
take	O
repeated	O
images	O
of	O
the	O
same	O
scene	O
(	O
ideally	O
with	O
a	O
remote	O
shutter	O
release	O
)	O
and	O
average	O
them	O
to	O
compute	O
the	O
variance	O
at	O
each	O
pixel	O
.	O
discarding	O
pixels	O
near	O
high	O
gra-	O
dients	O
(	O
which	O
are	O
affected	O
by	O
camera	O
motion	B
)	O
,	O
plot	O
for	O
each	O
color	B
channel	O
the	O
standard	O
deviation	O
at	O
each	O
pixel	O
as	O
a	O
function	O
of	O
its	O
output	O
value	O
.	O
3.	O
fit	O
a	O
lower	O
envelope	O
to	O
these	O
measurements	O
and	O
use	O
this	O
as	O
your	O
noise	B
level	O
function	O
.	O
how	O
much	O
variation	O
do	O
you	O
see	O
in	O
the	O
noise	B
as	O
a	O
function	O
of	O
input	O
level	O
?	O
how	O
much	O
of	O
this	O
is	O
signiﬁcant	O
,	O
i.e.	O
,	O
away	O
from	O
ﬂat	O
regions	O
in	O
your	O
camera	B
response	O
function	O
where	O
you	O
do	O
not	O
want	O
to	O
be	O
sampling	B
anyway	O
?	O
4	O
.	O
(	O
optional	O
)	O
using	O
the	O
same	O
images	O
,	O
develop	O
a	O
technique	O
that	O
segments	O
the	O
image	B
into	O
near-constant	O
regions	O
(	O
liu	O
,	O
szeliski	O
,	O
kang	O
et	O
al	O
.	O
2008	O
)	O
.	O
(	O
this	O
is	O
easier	O
if	O
you	O
are	O
pho-	O
tographing	O
a	O
calibration	B
chart	O
.	O
)	O
compute	O
the	O
deviations	O
for	O
each	O
region	B
from	O
a	O
single	O
image	O
and	O
use	O
them	O
to	O
estimate	O
the	O
nlf	O
.	O
how	O
does	O
this	O
compare	O
to	O
the	O
multi-image	O
technique	O
,	O
and	O
how	O
stable	O
are	O
your	O
estimates	O
from	O
image	B
to	O
image	B
?	O
ex	O
10.3	O
:	O
vignetting	B
estimate	O
the	O
amount	O
of	O
vignetting	B
in	O
some	O
of	O
your	O
lenses	O
using	O
one	O
of	O
the	O
following	O
three	O
techniques	O
(	O
or	O
devise	O
one	O
of	O
your	O
choosing	O
)	O
:	O
1.	O
take	O
an	O
image	B
of	O
a	O
large	O
uniform	O
intensity	O
region	B
(	O
well-illuminated	O
wall	O
or	O
blue	O
sky—	O
but	O
be	O
careful	O
of	O
brightness	O
gradients	O
)	O
and	O
ﬁt	O
a	O
radial	B
polynomial	O
curve	O
to	O
estimate	O
the	O
vignetting	B
.	O
2.	O
construct	O
a	O
center-weighted	O
panorama	O
and	O
compare	O
these	O
pixel	O
values	O
to	O
the	O
input	O
im-	O
age	O
values	O
to	O
estimate	O
the	O
vignetting	B
function	O
.	O
weight	O
pixels	O
in	O
slowly	O
varying	O
regions	O
more	O
highly	O
,	O
as	O
small	O
misalignments	O
will	O
give	O
large	O
errors	O
at	O
high	O
gradients	O
.	O
option-	O
ally	O
estimate	O
the	O
radiometric	B
response	O
function	O
as	O
well	O
(	O
litvinov	O
and	O
schechner	O
2005	O
;	O
goldman	O
2011	O
)	O
.	O
528	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
3.	O
analyze	O
the	O
radial	B
gradients	O
(	O
especially	O
in	O
low-gradient	O
regions	O
)	O
and	O
ﬁt	O
the	O
robust	B
means	O
of	O
these	O
gradients	O
to	O
the	O
derivative	O
of	O
the	O
vignetting	B
function	O
,	O
as	O
described	O
by	O
zheng	O
,	O
yu	O
,	O
kang	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
for	O
the	O
parametric	B
form	O
of	O
your	O
vignetting	B
function	O
,	O
you	O
can	O
either	O
use	O
a	O
simple	O
radial	B
func-	O
tion	B
,	O
e.g.	O
,	O
f	O
(	O
r	O
)	O
=	O
1	O
+	O
α1r	O
+	O
α2r2	O
+	O
···	O
(	O
10.42	O
)	O
or	O
one	O
of	O
the	O
specialized	O
equations	B
developed	O
by	O
kang	O
and	O
weiss	O
(	O
2000	O
)	O
and	O
zheng	O
,	O
lin	O
,	O
and	O
kang	O
(	O
2006	O
)	O
.	O
in	O
all	O
of	O
these	O
cases	O
,	O
be	O
sure	O
that	O
you	O
are	O
using	O
linearized	O
intensity	O
measurements	O
,	O
by	O
using	O
either	O
raw	O
images	O
or	O
images	O
linearized	O
through	O
a	O
radiometric	B
response	O
function	O
,	O
or	O
at	O
least	O
images	O
where	O
the	O
gamma	B
curve	O
has	O
been	O
removed	O
.	O
(	O
optional	O
)	O
what	O
happens	O
if	O
you	O
forget	O
to	O
undo	O
the	O
gamma	B
before	O
ﬁtting	O
a	O
(	O
multiplicative	O
)	O
vignetting	B
function	O
?	O
ex	O
10.4	O
:	O
optical	B
blur	I
(	O
psf	O
)	O
estimation	B
compute	O
the	O
optical	O
psf	O
either	O
using	O
a	O
known	O
target	O
(	O
figure	O
10.7	O
)	O
or	O
by	O
detecting	O
and	O
ﬁtting	O
step	O
edges	O
(	O
section	O
10.1.4	O
)	O
(	O
joshi	O
,	O
szeliski	O
,	O
and	O
kriegman	O
2008	O
)	O
.	O
1.	O
detect	O
strong	O
edges	O
to	O
sub-pixel	O
precision	O
.	O
2.	O
fit	O
a	O
local	B
proﬁle	O
to	O
each	O
oriented	B
edge	O
and	O
ﬁll	O
these	O
pixels	O
into	O
an	O
ideal	O
target	O
image	B
,	O
either	O
at	O
image	B
resolution	O
or	O
at	O
a	O
higher	O
resolution	O
(	O
figure	O
10.9c–d	O
)	O
.	O
3.	O
use	O
least	B
squares	I
(	O
10.1	O
)	O
at	O
valid	O
pixels	O
to	O
estimate	O
the	O
psf	O
kernel	B
k	O
,	O
either	O
globally	O
or	O
in	O
locally	O
overlapping	O
sub-regions	O
of	O
the	O
image	B
.	O
4.	O
visualize	O
the	O
recovered	O
psfs	O
and	O
use	O
them	O
to	O
remove	O
chromatic	B
aberration	I
or	O
de-blur	O
the	O
image	B
.	O
ex	O
10.5	O
:	O
tone	B
mapping	I
implement	O
one	O
of	O
the	O
tone	B
mapping	I
algorithms	O
discussed	O
in	O
sec-	O
tion	B
10.2.1	O
(	O
durand	O
and	O
dorsey	O
2002	O
;	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
;	O
reinhard	O
,	O
stark	O
,	O
shirley	O
et	O
al	O
.	O
2002	O
;	O
lischinski	O
,	O
farbman	O
,	O
uyttendaele	O
et	O
al	O
.	O
2006b	O
)	O
or	O
any	O
of	O
the	O
numer-	O
ous	O
additional	O
algorithms	O
discussed	O
by	O
reinhard	O
,	O
ward	O
,	O
pattanaik	O
et	O
al	O
.	O
(	O
2005	O
)	O
and	O
http	O
:	O
//stellar.mit.edu/s/course/6/sp08/6.815/materials.html	O
.	O
(	O
optional	O
)	O
compare	O
your	O
algorithm	B
to	O
local	B
histogram	O
equalization	O
(	O
section	O
3.1.4	O
)	O
.	O
ex	O
10.6	O
:	O
flash	O
enhancement	O
develop	O
an	O
algorithm	B
to	O
combine	O
ﬂash	B
and	I
non-ﬂash	I
pho-	O
tographs	O
to	O
best	O
effect	O
.	O
you	O
can	O
use	O
ideas	O
from	O
eisemann	O
and	O
durand	O
(	O
2004	O
)	O
and	O
petschnigg	O
,	O
agrawala	O
,	O
hoppe	O
et	O
al	O
.	O
(	O
2004	O
)	O
or	O
anything	O
else	O
you	O
think	O
might	O
work	O
well	O
.	O
10.7	O
exercises	O
529	O
ex	O
10.7	O
:	O
super-resolution	O
implement	O
one	O
or	O
more	O
super-resolution	O
algorithms	O
and	O
com-	O
pare	O
their	O
performance	O
.	O
1.	O
take	O
a	O
set	O
of	O
photographs	O
of	O
the	O
same	O
scene	O
using	O
a	O
hand-held	O
camera	B
(	O
to	O
ensure	O
that	O
there	O
is	O
some	O
jitter	O
between	O
the	O
photographs	O
)	O
.	O
2.	O
determine	O
the	O
psf	O
for	O
the	O
images	O
you	O
are	O
trying	O
to	O
super-resolve	O
using	O
one	O
of	O
the	O
techniques	O
in	O
exercise	O
10.4	O
.	O
3.	O
alternatively	O
,	O
simulate	O
a	O
collection	O
of	O
lower-resolution	O
images	O
by	O
taking	O
a	O
high-quality	O
photograph	O
(	O
avoid	O
those	O
with	O
compression	O
artifacts	O
)	O
and	O
applying	O
your	O
own	O
pre-ﬁlter	O
kernel	B
and	O
downsampling	O
.	O
4.	O
estimate	O
the	O
relative	O
motion	B
between	O
the	O
images	O
using	O
a	O
parametric	B
translation	O
and	O
rotation	O
motion	O
estimation	B
algorithm	O
(	O
sections	O
6.1.3	O
or	O
8.2	O
)	O
.	O
5.	O
implement	O
a	O
basic	O
least	B
squares	I
super-resolution	O
algorithm	B
by	O
minimizing	O
the	O
differ-	O
ence	O
between	O
the	O
observed	O
and	O
downsampled	O
images	O
(	O
10.27–10.28	O
)	O
.	O
6.	O
add	O
in	O
a	O
gradient	O
image	O
prior	B
,	O
either	O
as	O
another	O
least	B
squares	I
term	O
or	O
as	O
a	O
robust	B
term	O
that	O
can	O
be	O
minimized	O
using	O
iteratively	O
reweighted	O
least	B
squares	I
(	O
appendix	O
a.3	O
)	O
.	O
7	O
.	O
(	O
optional	O
)	O
implement	O
one	O
of	O
the	O
example-based	B
super-resolution	O
techniques	O
,	O
where	O
matching	B
against	O
a	O
set	O
of	O
exemplar	O
images	O
is	O
used	O
either	O
to	O
infer	O
higher-frequency	O
information	O
to	O
be	O
added	O
to	O
the	O
reconstruction	O
(	O
freeman	O
,	O
jones	O
,	O
and	O
pasztor	O
2002	O
)	O
or	O
higher-frequency	O
gradients	O
to	O
be	O
matched	O
in	O
the	O
super-resolved	O
image	B
(	O
baker	O
and	O
kanade	O
2002	O
)	O
.	O
8	O
.	O
(	O
optional	O
)	O
use	O
local	B
edge	O
statistic	O
information	O
to	O
improve	O
the	O
quality	O
of	O
the	O
super-	O
resolved	O
image	B
(	O
fattal	O
2007	O
)	O
.	O
ex	O
10.8	O
:	O
image	B
matting	O
develop	O
an	O
algorithm	B
for	O
pulling	O
a	O
foreground	O
matte	O
from	O
natural	B
images	O
,	O
as	O
described	O
in	O
section	O
10.4	O
.	O
1.	O
make	O
sure	O
that	O
the	O
images	O
you	O
are	O
taking	O
are	O
linearized	O
(	O
exercise	O
10.1	O
and	O
section	O
10.1	O
)	O
and	O
that	O
your	O
camera	B
exposure	O
is	O
ﬁxed	O
(	O
full	O
manual	O
mode	O
)	O
,	O
at	O
least	O
when	O
taking	O
multi-	O
ple	O
shots	O
of	O
the	O
same	O
scene	O
.	O
2.	O
to	O
acquire	O
ground	O
truth	O
data	O
,	O
place	O
your	O
object	O
in	O
front	O
of	O
a	O
computer	O
monitor	O
and	O
display	O
a	O
variety	O
of	O
solid	O
background	O
colors	O
as	O
well	O
as	O
some	O
natural	B
imagery	O
.	O
3.	O
remove	O
your	O
object	O
and	O
re-display	O
the	O
same	O
images	O
to	O
acquire	O
known	O
background	O
colors	O
.	O
530	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
4.	O
use	O
triangulation	B
matting	O
(	O
smith	O
and	O
blinn	O
1996	O
)	O
to	O
estimate	O
the	O
ground	O
truth	O
opacities	O
α	O
and	O
pre-multiplied	B
foreground	O
colors	O
αf	O
for	O
your	O
objects	O
.	O
5.	O
implement	O
one	O
or	O
more	O
of	O
the	O
natural	B
image	O
matting	B
algorithms	O
described	O
in	O
sec-	O
tion	B
10.4	O
and	O
compare	O
your	O
results	O
to	O
the	O
ground	O
truth	O
values	O
you	O
computed	O
.	O
alter-	O
natively	O
,	O
use	O
the	O
matting	B
test	O
images	O
published	O
on	O
http	O
:	O
//alphamatting.com/	O
.	O
6	O
.	O
(	O
optional	O
)	O
run	O
your	O
algorithms	O
on	O
other	O
images	O
taken	O
with	O
the	O
same	O
calibrated	O
camera	B
(	O
or	O
other	O
images	O
you	O
ﬁnd	O
interesting	O
)	O
.	O
ex	O
10.9	O
:	O
smoke	B
and	O
shadow	B
matting	O
extract	O
smoke	B
or	O
shadow	B
mattes	O
from	O
one	O
scene	O
and	O
insert	O
them	O
into	O
another	O
(	O
chuang	O
,	O
agarwala	O
,	O
curless	O
et	O
al	O
.	O
2002	O
;	O
chuang	O
,	O
goldman	O
,	O
curless	O
et	O
al	O
.	O
2003	O
)	O
.	O
1.	O
take	O
a	O
still	O
or	O
video	B
sequence	O
of	O
images	O
with	O
and	O
without	O
some	O
intermittent	O
smoke	B
and	O
shadows	O
.	O
(	O
remember	O
to	O
linearize	O
your	O
images	O
before	O
proceeding	O
with	O
any	O
computa-	O
tions	O
.	O
)	O
2.	O
for	O
each	O
pixel	O
,	O
ﬁt	O
a	O
line	O
to	O
the	O
observed	O
color	B
values	O
.	O
3.	O
if	O
performing	O
smoke	B
matting	O
,	O
robustly	O
compute	O
the	O
intersection	O
of	O
these	O
lines	B
to	O
obtain	O
the	O
smoke	B
color	O
estimate	O
.	O
then	O
,	O
estimate	O
the	O
background	O
color	O
as	O
the	O
other	O
extremum	O
(	O
unless	O
you	O
already	O
took	O
a	O
smoke-free	O
background	O
image	O
)	O
.	O
if	O
performing	O
shadow	B
matting	O
,	O
compute	O
robust	B
shadow	O
(	O
minimum	O
)	O
and	O
lit	O
(	O
maximum	O
)	O
values	O
for	O
each	O
pixel	O
.	O
4.	O
extract	O
the	O
smoke	B
or	O
shadow	B
mattes	O
from	O
each	O
frame	O
as	O
the	O
fraction	O
between	O
these	O
two	O
values	O
(	O
background	O
and	O
smoke	B
or	O
shadowed	O
and	O
lit	O
)	O
.	O
5.	O
scan	O
a	O
new	O
(	O
destination	O
)	O
scene	O
or	O
modify	O
the	O
original	O
background	O
with	O
an	O
image	B
editor	O
.	O
6.	O
re-insert	O
the	O
smoke	B
or	O
shadow	B
matte	O
,	O
along	O
with	O
any	O
other	O
foreground	O
objects	O
you	O
may	O
have	O
extracted	O
.	O
7	O
.	O
(	O
optional	O
)	O
using	O
a	O
series	O
of	O
cast	O
stick	O
shadows	O
,	O
estimate	O
the	O
deformation	O
ﬁeld	O
for	O
the	O
destination	O
scene	O
in	O
order	B
to	O
correctly	O
warp	O
(	O
drape	O
)	O
the	O
shadows	O
across	O
the	O
new	O
ge-	O
ometry	O
.	O
(	O
this	O
is	O
related	O
to	O
the	O
shadow	B
scanning	O
technique	O
developed	O
by	O
bouguet	O
and	O
perona	O
(	O
1999	O
)	O
and	O
implemented	O
in	O
exercise	O
12.2	O
.	O
)	O
8	O
.	O
(	O
optional	O
)	O
chuang	O
,	O
goldman	O
,	O
curless	O
et	O
al	O
.	O
(	O
2003	O
)	O
only	O
demonstrated	O
their	O
technique	O
for	O
planar	O
source	O
geometries	O
.	O
can	O
you	O
extend	O
their	O
technique	O
to	O
capture	O
shadows	O
ac-	O
quired	O
from	O
an	O
irregular	O
source	O
geometry	O
?	O
10.7	O
exercises	O
531	O
9	O
.	O
(	O
optional	O
)	O
can	O
you	O
change	O
the	O
direction	O
of	O
the	O
shadow	B
,	O
i.e.	O
,	O
simulate	O
the	O
effect	O
of	O
changing	O
the	O
light	O
source	O
direction	O
?	O
ex	O
10.10	O
:	O
texture	B
synthesis	O
rithms	O
presented	O
in	O
section	O
10.5.	O
here	O
is	O
one	O
possible	O
procedure	O
:	O
implement	O
one	O
of	O
the	O
texture	B
synthesis	O
or	O
hole	B
ﬁlling	I
algo-	O
1.	O
implement	O
the	O
basic	O
efros	O
and	O
leung	O
(	O
1999	O
)	O
algorithm	B
,	O
i.e.	O
,	O
starting	O
from	O
the	O
outside	O
(	O
for	O
hole	O
ﬁlling	O
)	O
or	O
in	O
raster	O
order	B
(	O
for	O
texture	O
synthesis	O
)	O
,	O
search	O
for	O
a	O
similar	O
neighbor-	O
hood	O
in	O
the	O
source	O
texture	B
image	O
,	O
and	O
copy	O
that	O
pixel	O
.	O
2.	O
add	O
in	O
the	O
wei	O
and	O
levoy	O
(	O
2000	O
)	O
extension	O
of	O
generating	O
the	O
pixels	O
in	O
a	O
coarse-to-ﬁne	B
fashion	O
,	O
i.e.	O
,	O
generate	O
a	O
lower-resolution	O
synthetic	O
texture	B
(	O
or	O
ﬁlled	O
image	B
)	O
,	O
and	O
use	O
this	O
as	O
a	O
guide	O
for	O
matching	O
regions	O
in	O
the	O
ﬁner	O
resolution	O
version	O
.	O
3.	O
add	O
in	O
the	O
criminisi	O
,	O
p´erez	O
,	O
and	O
toyama	O
(	O
2004	O
)	O
idea	O
of	O
prioritizing	O
pixels	O
to	O
be	O
ﬁlled	O
by	O
some	O
function	O
of	O
the	O
local	B
structure	O
(	O
gradient	O
or	O
orientation	O
strength	O
)	O
.	O
4.	O
extend	O
any	O
of	O
the	O
above	O
algorithms	O
by	O
selecting	O
sub-blocks	O
in	O
the	O
source	O
texture	B
and	O
using	O
optimization	O
to	O
determine	O
the	O
seam	O
between	O
the	O
new	O
block	O
and	O
the	O
existing	O
image	B
that	O
it	O
overlaps	O
(	O
efros	O
and	O
freeman	O
2001	O
)	O
.	O
5	O
.	O
(	O
optional	O
)	O
implement	O
one	O
of	O
the	O
isophote	O
(	O
smooth	O
continuation	O
)	O
inpainting	B
algorithms	O
(	O
bertalmio	O
,	O
sapiro	O
,	O
caselles	O
et	O
al	O
.	O
2000	O
;	O
telea	O
2004	O
)	O
.	O
6	O
.	O
(	O
optional	O
)	O
add	O
the	O
ability	O
to	O
supply	O
a	O
target	O
(	O
reference	O
)	O
image	B
(	O
efros	O
and	O
freeman	O
2001	O
)	O
or	O
to	O
provide	O
sample	O
ﬁltered	O
or	O
unﬁltered	O
(	O
reference	O
and	O
rendered	O
)	O
images	O
(	O
hertz-	O
mann	O
,	O
jacobs	O
,	O
oliver	O
et	O
al	O
.	O
2001	O
)	O
,	O
see	O
section	O
10.5.2.	O
ex	O
10.11	O
:	O
colorization	B
implement	O
the	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
(	O
2004	O
)	O
colorization	B
al-	O
gorithm	O
that	O
is	O
sketched	O
out	O
in	O
section	O
10.3.2	O
and	O
figure	O
10.37.	O
find	O
some	O
historic	O
monochrome	O
photographs	O
and	O
some	O
modern	O
color	B
ones	O
.	O
write	O
an	O
interactive	B
tool	O
that	O
lets	O
you	O
“	O
pick	O
”	O
col-	O
ors	O
from	O
a	O
modern	O
photo	O
and	O
paint	O
over	O
the	O
old	O
one	O
.	O
tune	O
the	O
algorithm	B
parameters	O
to	O
give	O
you	O
good	O
results	O
.	O
are	O
you	O
pleased	O
with	O
the	O
results	O
?	O
can	O
you	O
think	O
of	O
ways	O
to	O
make	O
them	O
look	O
more	O
“	O
antique	O
”	O
,	O
e.g.	O
,	O
with	O
softer	O
(	O
less	O
saturated	O
and	O
edgy	O
)	O
colors	O
?	O
532	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
chapter	O
11	O
stereo	B
correspondence	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.1	O
epipolar	B
geometry	I
.	O
.	O
.	O
.	O
11.2	O
sparse	B
correspondence	I
.	O
.	O
.	O
.	O
.	O
11.2.1	O
3d	O
curves	O
and	O
proﬁles	B
.	O
.	O
.	O
.	O
.	O
11.3.1	O
similarity	B
measures	O
.	O
.	O
11.3	O
dense	B
correspondence	I
11.4	O
local	B
methods	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.1.1	O
rectiﬁcation	B
.	O
11.1.2	O
plane	B
sweep	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.4.1	O
sub-pixel	O
estimation	O
and	O
uncertainty	B
.	O
.	O
11.4.2	O
application	O
:	O
stereo-based	O
head	B
tracking	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.5.1	O
dynamic	B
programming	I
.	O
.	O
.	O
11.5.2	O
segmentation-based	B
techniques	O
11.5.3	O
application	O
:	O
z-keying	B
and	O
background	B
replacement	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.6.1	O
volumetric	B
and	O
3d	O
surface	B
reconstruction	I
.	O
11.6.2	O
shape	O
from	O
silhouettes	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.5	O
global	B
optimization	I
.	O
11.6	O
multi-view	B
stereo	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11.7	O
additional	O
reading	O
.	O
11.8	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
537	O
.	O
538	O
.	O
540	O
.	O
543	O
.	O
543	O
.	O
545	O
.	O
546	O
.	O
548	O
.	O
550	O
.	O
551	O
.	O
552	O
.	O
554	O
.	O
556	O
.	O
558	O
.	O
558	O
.	O
562	O
.	O
567	O
.	O
570	O
.	O
571	O
534	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
(	O
h	O
)	O
figure	O
11.1	O
stereo	B
reconstruction	O
techniques	O
can	O
convert	O
(	O
a–b	O
)	O
a	O
pair	O
of	O
images	O
into	O
(	O
c	O
)	O
a	O
depth	B
map	I
(	O
http	O
:	O
//vision.middlebury.edu/stereo/data/scenes2003/	O
)	O
or	O
(	O
d–e	O
)	O
a	O
sequence	O
of	O
images	O
into	O
(	O
f	O
)	O
a	O
3d	O
model	O
(	O
http	O
:	O
//vision.middlebury.edu/mview/data/	O
)	O
.	O
(	O
g	O
)	O
an	O
analytical	O
stereo	B
plotter	O
,	O
courtesy	O
of	O
kenney	O
aerial	O
mapping	O
,	O
inc.	O
,	O
can	O
generate	O
(	O
h	O
)	O
contour	O
plots	O
.	O
11	O
stereo	B
correspondence	O
535	O
stereo	B
matching	I
is	O
the	O
process	O
of	O
taking	O
two	O
or	O
more	O
images	O
and	O
estimating	O
a	O
3d	O
model	O
of	O
the	O
scene	O
by	O
ﬁnding	O
matching	B
pixels	O
in	O
the	O
images	O
and	O
converting	O
their	O
2d	O
positions	O
into	O
3d	O
depths	O
.	O
in	O
chapters	O
6–7	O
,	O
we	O
described	O
techniques	O
for	O
recovering	O
camera	B
positions	O
and	O
building	O
sparse	B
3d	O
models	O
of	O
scenes	O
or	O
objects	O
.	O
in	O
this	O
chapter	O
,	O
we	O
address	O
the	O
question	O
of	O
how	O
to	O
build	O
a	O
more	O
complete	O
3d	O
model	O
,	O
e.g.	O
,	O
a	O
sparse	B
or	O
dense	O
depth	O
map	O
that	O
assigns	O
relative	O
depths	O
to	O
pixels	O
in	O
the	O
input	O
images	O
.	O
we	O
also	O
look	O
at	O
the	O
topic	O
of	O
multi-view	B
stereo	I
algorithms	O
that	O
produce	O
complete	O
3d	O
volumetric	B
or	O
surface-based	O
object	O
models	O
.	O
why	O
are	O
people	O
interested	O
in	O
stereo	B
matching	I
?	O
from	O
the	O
earliest	O
inquiries	O
into	O
visual	O
per-	O
ception	O
,	O
it	O
was	O
known	O
that	O
we	O
perceive	O
depth	O
based	O
on	O
the	O
differences	O
in	O
appearance	O
between	O
the	O
left	O
and	O
right	O
eye.1	O
as	O
a	O
simple	O
experiment	O
,	O
hold	O
your	O
ﬁnger	O
vertically	O
in	O
front	O
of	O
your	O
eyes	O
and	O
close	O
each	O
eye	O
alternately	O
.	O
you	O
will	O
notice	O
that	O
the	O
ﬁnger	O
jumps	O
left	O
and	O
right	O
relative	O
to	O
the	O
background	O
of	O
the	O
scene	O
.	O
the	O
same	O
phenomenon	O
is	O
visible	O
in	O
the	O
image	B
pair	O
shown	O
in	O
figure	O
11.1a–b	O
,	O
in	O
which	O
the	O
foreground	O
objects	O
shift	O
left	O
and	O
right	O
relative	O
to	O
the	O
background	O
.	O
as	O
we	O
will	O
shortly	O
see	O
,	O
under	O
simple	O
imaging	O
conﬁgurations	O
(	O
both	O
eyes	O
or	O
cameras	O
look-	O
ing	O
straight	O
ahead	O
)	O
,	O
the	O
amount	O
of	O
horizontal	O
motion	B
or	O
disparity	O
is	O
inversely	O
proportional	O
to	O
the	O
distance	O
from	O
the	O
observer	O
.	O
while	O
the	O
basic	O
physics	O
and	O
geometry	O
relating	O
visual	O
disparity	O
to	O
scene	O
structure	O
are	O
well	O
understood	O
(	O
section	O
11.1	O
)	O
,	O
automatically	O
measuring	O
this	O
disparity	O
by	O
establishing	O
dense	O
and	O
accurate	O
inter-image	O
correspondences	O
is	O
a	O
challenging	O
task	O
.	O
the	O
earliest	O
stereo	B
matching	I
algorithms	O
were	O
developed	O
in	O
the	O
ﬁeld	O
of	O
photogrammetry	B
for	O
automatically	O
constructing	O
topographic	O
elevation	O
maps	O
from	O
overlapping	O
aerial	O
images	O
.	O
prior	B
to	O
this	O
,	O
operators	O
would	O
use	O
photogrammetric	O
stereo	B
plotters	O
,	O
which	O
displayed	O
shifted	O
versions	O
of	O
such	O
images	O
to	O
each	O
eye	O
and	O
allowed	O
the	O
operator	O
to	O
ﬂoat	O
a	O
dot	O
cursor	O
around	O
con-	O
stant	O
elevation	O
contours	O
(	O
figure	O
11.1g	O
)	O
.	O
the	O
development	O
of	O
fully	O
automated	B
stereo	O
matching	B
algorithms	O
was	O
a	O
major	O
advance	O
in	O
this	O
ﬁeld	O
,	O
enabling	O
much	O
more	O
rapid	O
and	O
less	O
expensive	O
processing	O
of	O
aerial	O
imagery	O
(	O
hannah	O
1974	O
;	O
hsieh	O
,	O
mckeown	O
,	O
and	O
perlant	O
1992	O
)	O
.	O
in	O
computer	O
vision	O
,	O
the	O
topic	O
of	O
stereo	B
matching	I
has	O
been	O
one	O
of	O
the	O
most	O
widely	O
stud-	O
ied	O
and	O
fundamental	O
problems	O
(	O
marr	O
and	O
poggio	O
1976	O
;	O
barnard	O
and	O
fischler	O
1982	O
;	O
dhond	O
and	O
aggarwal	O
1989	O
;	O
scharstein	O
and	O
szeliski	O
2002	O
;	O
brown	O
,	O
burschka	O
,	O
and	O
hager	O
2003	O
;	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
2006	O
)	O
,	O
and	O
continues	O
to	O
be	O
one	O
of	O
the	O
most	O
active	O
research	O
areas	O
.	O
while	O
photogrammetric	O
matching	B
concentrated	O
mainly	O
on	O
aerial	O
imagery	O
,	O
computer	O
vision	O
applica-	O
tions	O
include	O
modeling	B
the	O
human	O
visual	O
system	O
(	O
marr	O
1982	O
)	O
,	O
robotic	O
navigation	O
and	O
manip-	O
ulation	O
(	O
moravec	O
1983	O
;	O
konolige	O
1997	O
;	O
thrun	O
,	O
montemerlo	O
,	O
dahlkamp	O
et	O
al	O
.	O
2006	O
)	O
,	O
as	O
well	O
as	O
view	B
interpolation	I
and	O
image-based	B
rendering	I
(	O
figure	O
11.2a–d	O
)	O
,	O
3d	O
model	O
building	O
(	O
fig-	O
ure	O
11.2e–f	O
and	O
h–j	O
)	O
,	O
and	O
mixing	O
live	O
action	O
with	O
computer-generated	O
imagery	O
(	O
figure	O
11.2g	O
)	O
.	O
in	O
this	O
chapter	O
,	O
we	O
describe	O
the	O
fundamental	O
principles	O
behind	O
stereo	B
matching	I
,	O
following	O
1	O
the	O
word	O
stereo	B
comes	O
from	O
the	O
greek	O
for	O
solid	O
;	O
stereo	B
vision	O
is	O
how	O
we	O
perceive	O
solid	O
shape	O
(	O
koenderink	O
1990	O
)	O
.	O
536	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
(	O
h	O
)	O
(	O
i	O
)	O
(	O
j	O
)	O
figure	O
11.2	O
applications	O
of	O
stereo	B
vision	O
:	O
(	O
a	O
)	O
input	O
image	B
,	O
(	O
b	O
)	O
computed	O
depth	B
map	I
,	O
and	O
(	O
c	O
)	O
new	O
view	O
generation	O
from	O
multi-view	B
stereo	I
(	O
matthies	O
,	O
kanade	O
,	O
and	O
szeliski	O
1989	O
)	O
c	O
(	O
cid:13	O
)	O
1989	O
springer	O
;	O
(	O
d	O
)	O
view	B
morphing	I
between	O
two	O
images	O
(	O
seitz	O
and	O
dyer	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
;	O
(	O
e–f	O
)	O
3d	O
face	B
modeling	I
(	O
images	O
courtesy	O
of	O
fr´ed´eric	O
devernay	O
)	O
;	O
(	O
g	O
)	O
z-keying	B
live	O
and	O
computer-	O
generated	O
imagery	O
(	O
kanade	O
,	O
yoshida	O
,	O
oda	O
et	O
al	O
.	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
ieee	O
;	O
(	O
h–j	O
)	O
building	O
3d	O
surface	B
models	O
from	O
multiple	B
video	O
streams	O
in	O
virtualized	O
reality	O
(	O
kanade	O
,	O
rander	O
,	O
and	O
narayanan	O
1997	O
)	O
.	O
11.1	O
epipolar	B
geometry	I
537	O
the	O
general	O
taxonomy	B
proposed	O
by	O
scharstein	O
and	O
szeliski	O
(	O
2002	O
)	O
.	O
we	O
begin	O
in	O
section	O
11.1	O
with	O
a	O
review	O
of	O
the	O
geometry	O
of	O
stereo	B
image	O
matching	B
,	O
i.e.	O
,	O
how	O
to	O
compute	O
for	O
a	O
given	O
pixel	O
in	O
one	O
image	B
the	O
range	O
of	O
possible	O
locations	O
the	O
pixel	O
might	O
appear	O
at	O
in	O
the	O
other	O
image	B
,	O
i.e.	O
,	O
its	O
epipolar	O
line	O
.	O
we	O
describe	O
how	O
to	O
pre-warp	O
images	O
so	O
that	O
corresponding	O
epipolar	O
lines	O
are	O
coincident	O
(	O
rectiﬁcation	B
)	O
.	O
we	O
also	O
describe	O
a	O
general	O
resampling	O
algorithm	B
called	O
plane	B
sweep	I
that	O
can	O
be	O
used	O
to	O
perform	O
multi-image	O
stereo	B
matching	I
with	O
arbitrary	O
camera	B
conﬁgurations	O
.	O
next	O
,	O
we	O
brieﬂy	O
survey	O
techniques	O
for	O
the	O
sparse	B
stereo	O
matching	B
of	O
interest	O
points	B
and	O
edge-like	O
features	O
(	O
section	O
11.2	O
)	O
.	O
we	O
then	O
turn	O
to	O
the	O
main	O
topic	O
of	O
this	O
chapter	O
,	O
namely	O
the	O
estimation	B
of	O
a	O
dense	O
set	O
of	O
pixel-wise	O
correspondences	O
in	O
the	O
form	O
of	O
a	O
disparity	O
map	O
(	O
fig-	O
ure	O
11.1c	O
)	O
.	O
this	O
involves	O
ﬁrst	O
selecting	O
a	O
pixel	O
matching	O
criterion	O
(	O
section	O
11.3	O
)	O
and	O
then	O
using	O
either	O
local	B
area-based	O
aggregation	O
(	O
section	O
11.4	O
)	O
or	O
global	B
optimization	I
(	O
section	O
11.5	O
)	O
to	O
help	O
disambiguate	O
potential	O
matches	O
.	O
in	O
section	O
11.6	O
,	O
we	O
discuss	O
multi-view	B
stereo	I
meth-	O
ods	O
that	O
aim	O
to	O
reconstruct	O
a	O
complete	O
3d	O
model	O
instead	O
of	O
just	O
a	O
single	O
disparity	O
image	B
(	O
figure	O
11.1d–f	O
)	O
.	O
11.1	O
epipolar	B
geometry	I
given	O
a	O
pixel	O
in	O
one	O
image	B
,	O
how	O
can	O
we	O
compute	O
its	O
correspondence	B
in	O
the	O
other	O
image	B
?	O
in	O
chapter	O
8	O
,	O
we	O
saw	O
that	O
a	O
variety	O
of	O
search	O
techniques	O
can	O
be	O
used	O
to	O
match	O
pixels	O
based	O
on	O
their	O
local	B
appearance	O
as	O
well	O
as	O
the	O
motions	O
of	O
neighboring	O
pixels	O
.	O
in	O
the	O
case	O
of	O
stereo	B
matching	I
,	O
however	O
,	O
we	O
have	O
some	O
additional	O
information	O
available	O
,	O
namely	O
the	O
positions	O
and	O
calibration	B
data	O
for	O
the	O
cameras	O
that	O
took	O
the	O
pictures	O
of	O
the	O
same	O
static	O
scene	O
(	O
section	O
7.2	O
)	O
.	O
how	O
can	O
we	O
exploit	O
this	O
information	O
to	O
reduce	O
the	O
number	O
of	O
potential	O
correspondences	O
,	O
and	O
hence	O
both	O
speed	O
up	O
the	O
matching	B
and	O
increase	O
its	O
reliability	O
?	O
figure	O
11.3a	O
shows	O
how	O
a	O
pixel	O
in	O
one	O
image	B
x0	O
projects	O
to	O
an	O
epipolar	O
line	O
segment	O
in	O
the	O
other	O
image	B
.	O
the	O
segment	O
is	O
bounded	O
at	O
one	O
end	O
by	O
the	O
projection	O
of	O
the	O
original	O
viewing	O
ray	O
at	O
inﬁnity	O
p	O
and	O
at	O
the	O
other	O
end	O
by	O
the	O
projection	O
of	O
the	O
original	O
camera	B
center	O
c0	O
into	O
the	O
second	O
camera	O
,	O
which	O
is	O
known	O
as	O
the	O
epipole	O
e1	O
.	O
if	O
we	O
project	O
the	O
epipolar	O
line	O
in	O
the	O
second	O
image	O
back	O
into	O
the	O
ﬁrst	O
,	O
we	O
get	O
another	O
line	O
(	O
segment	O
)	O
,	O
this	O
time	O
bounded	O
by	O
the	O
other	O
corresponding	O
epipole	O
e0	O
.	O
extending	O
both	O
line	O
segments	O
to	O
inﬁnity	O
,	O
we	O
get	O
a	O
pair	O
of	O
corresponding	O
epipolar	O
lines	O
(	O
figure	O
11.3b	O
)	O
,	O
which	O
are	O
the	O
intersection	O
of	O
the	O
two	O
image	O
planes	B
with	O
the	O
epipolar	O
plane	O
that	O
passes	O
through	O
both	O
camera	B
centers	O
c0	O
and	O
c1	O
as	O
well	O
as	O
the	O
point	O
of	O
interest	O
p	O
(	O
faugeras	O
and	O
luong	O
2001	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
∞	O
538	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
11.3	O
epipolar	B
geometry	I
:	O
(	O
a	O
)	O
epipolar	O
line	O
segment	O
corresponding	O
to	O
one	O
ray	O
;	O
(	O
b	O
)	O
corresponding	O
set	O
of	O
epipolar	O
lines	O
and	O
their	O
epipolar	O
plane	O
.	O
11.1.1	O
rectiﬁcation	B
as	O
we	O
saw	O
in	O
section	O
7.2	O
,	O
the	O
epipolar	B
geometry	I
for	O
a	O
pair	O
of	O
cameras	O
is	O
implicit	O
in	O
the	O
relative	O
pose	O
and	O
calibrations	O
of	O
the	O
cameras	O
,	O
and	O
can	O
easily	O
be	O
computed	O
from	O
seven	O
or	O
more	O
point	O
matches	O
using	O
the	O
fundamental	O
matrix	O
(	O
or	O
ﬁve	O
or	O
more	O
points	B
for	O
the	O
calibrated	O
essential	O
matrix	O
)	O
(	O
zhang	O
1998a	O
,	O
b	O
;	O
faugeras	O
and	O
luong	O
2001	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
once	O
this	O
geometry	O
has	O
been	O
computed	O
,	O
we	O
can	O
use	O
the	O
epipolar	O
line	O
corresponding	O
to	O
a	O
pixel	O
in	O
one	O
image	B
to	O
constrain	O
the	O
search	O
for	O
corresponding	O
pixels	O
in	O
the	O
other	O
image	B
.	O
one	O
way	O
to	O
do	O
this	O
is	O
to	O
use	O
a	O
general	O
correspondence	B
algorithm	O
,	O
such	O
as	O
optical	B
ﬂow	I
(	O
section	O
8.4	O
)	O
,	O
but	O
to	O
only	O
consider	O
locations	O
along	O
the	O
epipolar	O
line	O
(	O
or	O
to	O
project	O
any	O
ﬂow	O
vectors	O
that	O
fall	O
off	O
back	O
onto	O
the	O
line	O
)	O
.	O
a	O
more	O
efﬁcient	O
algorithm	B
can	O
be	O
obtained	O
by	O
ﬁrst	O
rectifying	O
(	O
i.e	O
,	O
warping	O
)	O
the	O
input	O
images	O
so	O
that	O
corresponding	O
horizontal	O
scanlines	O
are	O
epipolar	O
lines	O
(	O
loop	O
and	O
zhang	O
1999	O
;	O
faugeras	O
and	O
luong	O
2001	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.2	O
afterwards	O
,	O
it	O
is	O
possible	O
to	O
match	O
horizontal	O
scanlines	O
independently	O
or	O
to	O
shift	O
images	O
horizontally	O
while	O
computing	O
matching	B
scores	O
(	O
figure	O
11.4	O
)	O
.	O
a	O
simple	O
way	O
to	O
rectify	O
the	O
two	O
images	O
is	O
to	O
ﬁrst	O
rotate	O
both	O
cameras	O
so	O
that	O
they	O
are	O
looking	O
perpendicular	O
to	O
the	O
line	O
joining	O
the	O
camera	B
centers	O
c0	O
and	O
c1	O
.	O
since	O
there	O
is	O
a	O
de-	O
gree	O
of	O
freedom	O
in	O
the	O
tilt	O
,	O
the	O
smallest	O
rotations	O
that	O
achieve	O
this	O
should	O
be	O
used	O
.	O
next	O
,	O
to	O
determine	O
the	O
desired	O
twist	B
around	O
the	O
optical	O
axes	O
,	O
make	O
the	O
up	O
vector	O
(	O
the	O
camera	B
y	O
axis	O
)	O
2	O
this	O
makes	O
most	O
sense	O
if	O
the	O
cameras	O
are	O
next	O
to	O
each	O
other	O
,	O
although	O
by	O
rotating	O
the	O
cameras	O
,	O
rectiﬁcation	B
can	O
be	O
performed	O
on	O
any	O
pair	O
that	O
is	O
not	O
verged	O
too	O
much	O
or	O
has	O
too	O
much	O
of	O
a	O
scale	O
change	O
.	O
in	O
those	O
latter	O
cases	O
,	O
using	O
plane	O
sweep	O
(	O
below	O
)	O
or	O
hypothesizing	O
small	O
planar	O
patch	O
locations	O
in	O
3d	O
(	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2007	O
)	O
may	O
be	O
preferable	O
.	O
px1x0	O
(	O
r	O
,	O
t	O
)	O
p∞e1e0c0c1	O
epipolar	O
planep∞p	O
(	O
r	O
,	O
t	O
)	O
c0c1epipolarlinesx0e0e1x1l1l0	O
11.1	O
epipolar	B
geometry	I
539	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
11.4	O
the	O
multi-stage	O
stereo	B
rectiﬁcation	O
algorithm	B
of	O
loop	O
and	O
zhang	O
(	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
ieee	O
.	O
(	O
a	O
)	O
original	O
image	B
pair	O
overlaid	O
with	O
several	O
epipolar	O
lines	O
;	O
(	O
b	O
)	O
images	O
trans-	O
formed	O
so	O
that	O
epipolar	O
lines	O
are	O
parallel	O
;	O
(	O
c	O
)	O
images	O
rectiﬁed	O
so	O
that	O
epipolar	O
lines	O
are	O
hori-	O
zontal	O
and	O
in	O
vertial	O
correspondence	B
;	O
(	O
d	O
)	O
ﬁnal	O
rectiﬁcation	B
that	O
minimizes	O
horizontal	O
distor-	O
tions	O
.	O
perpendicular	O
to	O
the	O
camera	B
center	O
line	O
.	O
this	O
ensures	O
that	O
corresponding	O
epipolar	O
lines	O
are	O
horizontal	O
and	O
that	O
the	O
disparity	O
for	O
points	O
at	O
inﬁnity	O
is	O
0.	O
finally	O
,	O
re-scale	O
the	O
images	O
,	O
if	O
nec-	O
essary	O
,	O
to	O
account	O
for	O
different	O
focal	O
lengths	O
,	O
magnifying	O
the	O
smaller	O
image	B
to	O
avoid	O
aliasing	B
.	O
(	O
the	O
full	O
details	O
of	O
this	O
procedure	O
can	O
be	O
found	O
in	O
fusiello	O
,	O
trucco	O
,	O
and	O
verri	O
(	O
2000	O
)	O
and	O
ex-	O
ercise	O
11.1	O
.	O
)	O
note	O
that	O
in	O
general	O
,	O
it	O
is	O
not	O
possible	O
to	O
rectify	O
an	O
arbitrary	O
collection	O
of	O
images	O
simultaneously	O
unless	O
their	O
optical	O
centers	O
are	O
collinear	O
,	O
although	O
rotating	O
the	O
cameras	O
so	O
that	O
they	O
all	O
point	O
in	O
the	O
same	O
direction	O
reduces	O
the	O
inter-camera	O
pixel	O
movements	O
to	O
scalings	O
and	O
translations	O
.	O
the	O
resulting	O
standard	B
rectiﬁed	I
geometry	I
is	O
employed	O
in	O
a	O
lot	O
of	O
stereo	B
camera	O
setups	O
and	O
stereo	B
algorithms	O
,	O
and	O
leads	O
to	O
a	O
very	O
simple	O
inverse	B
relationship	O
between	O
3d	O
depths	O
z	O
and	O
disparities	O
d	O
,	O
d	O
=	O
f	O
b	O
z	O
,	O
where	O
f	O
is	O
the	O
focal	O
length	O
(	O
measured	O
in	O
pixels	O
)	O
,	O
b	O
is	O
the	O
baseline	O
,	O
and	O
x	O
(	O
cid:48	O
)	O
=	O
x	O
+	O
d	O
(	O
x	O
,	O
y	O
)	O
,	O
y	O
(	O
cid:48	O
)	O
=	O
y	O
(	O
11.1	O
)	O
(	O
11.2	O
)	O
describes	O
the	O
relationship	O
between	O
corresponding	O
pixel	O
coordinates	O
in	O
the	O
left	O
and	O
right	O
im-	O
ages	O
(	O
bolles	O
,	O
baker	O
,	O
and	O
marimont	O
1987	O
;	O
okutomi	O
and	O
kanade	O
1993	O
;	O
scharstein	O
and	O
szeliski	O
540	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
11.5	O
slices	O
through	O
a	O
typical	O
disparity	O
space	O
image	O
(	O
dsi	O
)	O
(	O
scharstein	O
and	O
szeliski	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
springer	O
:	O
(	O
a	O
)	O
original	O
color	B
image	O
;	O
(	O
b	O
)	O
ground	O
truth	O
disparities	O
;	O
(	O
c–e	O
)	O
three	O
(	O
x	O
,	O
y	O
)	O
slices	O
for	O
d	O
=	O
10	O
,	O
16	O
,	O
21	O
;	O
(	O
f	O
)	O
an	O
(	O
x	O
,	O
d	O
)	O
slice	O
for	O
y	O
=	O
151	O
(	O
the	O
dashed	O
line	O
in	O
(	O
b	O
)	O
)	O
.	O
various	O
dark	O
(	O
matching	B
)	O
regions	O
are	O
visible	O
in	O
(	O
c–e	O
)	O
,	O
e.g.	O
,	O
the	O
bookshelves	O
,	O
table	O
and	O
cans	O
,	O
and	O
head	B
statue	O
,	O
and	O
three	O
disparity	O
levels	O
can	O
be	O
seen	O
as	O
horizontal	O
lines	B
in	O
(	O
f	O
)	O
.	O
the	O
dark	O
bands	O
in	O
the	O
dsis	O
indicate	O
regions	O
that	O
match	O
at	O
this	O
disparity	O
.	O
(	O
smaller	O
dark	O
regions	O
are	O
often	O
the	O
result	O
of	O
textureless	O
regions	O
.	O
)	O
additional	O
examples	B
of	O
dsis	O
are	O
discussed	O
by	O
bobick	O
and	O
intille	O
(	O
1999	O
)	O
.	O
2002	O
)	O
.3	O
the	O
task	O
of	O
extracting	O
depth	O
from	O
a	O
set	O
of	O
images	O
then	O
becomes	O
one	O
of	O
estimating	O
the	O
disparity	O
map	O
d	O
(	O
x	O
,	O
y	O
)	O
.	O
after	O
rectiﬁcation	B
,	O
we	O
can	O
easily	O
compare	O
the	O
similarity	B
of	O
pixels	O
at	O
corresponding	O
lo-	O
cations	O
(	O
x	O
,	O
y	O
)	O
and	O
(	O
x	O
(	O
cid:48	O
)	O
,	O
y	O
(	O
cid:48	O
)	O
)	O
=	O
(	O
x	O
+	O
d	O
,	O
y	O
)	O
and	O
store	O
them	O
in	O
a	O
disparity	O
space	O
image	O
(	O
dsi	O
)	O
c	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
for	O
further	O
processing	O
(	O
figure	O
11.5	O
)	O
.	O
the	O
concept	O
of	O
the	O
disparity	O
space	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
dates	O
back	O
to	O
early	O
work	O
in	O
stereo	B
matching	I
(	O
marr	O
and	O
poggio	O
1976	O
)	O
,	O
while	O
the	O
concept	O
of	O
a	O
disparity	O
space	O
image	O
(	O
volume	O
)	O
is	O
generally	O
associated	O
with	O
yang	O
,	O
yuille	O
,	O
and	O
lu	O
(	O
1993	O
)	O
and	O
intille	O
and	O
bobick	O
(	O
1994	O
)	O
.	O
11.1.2	O
plane	B
sweep	I
an	O
alternative	O
to	O
pre-rectifying	O
the	O
images	O
before	O
matching	B
is	O
to	O
sweep	O
a	O
set	O
of	O
planes	B
through	O
the	O
scene	O
and	O
to	O
measure	O
the	O
photoconsistency	B
of	O
different	O
images	O
as	O
they	O
are	O
re-projected	O
onto	O
these	O
planes	B
(	O
figure	O
11.6	O
)	O
.	O
this	O
process	O
is	O
commonly	O
known	O
as	O
the	O
plane	B
sweep	I
algo-	O
rithm	O
(	O
collins	O
1996	O
;	O
szeliski	O
and	O
golland	O
1999	O
;	O
saito	O
and	O
kanade	O
1999	O
)	O
.	O
as	O
we	O
saw	O
in	O
section	O
2.1.5	O
,	O
where	O
we	O
introduced	O
projective	B
depth	O
(	O
also	O
known	O
as	O
plane	O
plus	O
parallax	O
(	O
kumar	O
,	O
anandan	O
,	O
and	O
hanna	O
1994	O
;	O
sawhney	O
1994	O
;	O
szeliski	O
and	O
coughlan	O
3	O
the	O
term	O
disparity	O
was	O
ﬁrst	O
introduced	O
in	O
the	O
human	O
vision	O
literature	O
to	O
describe	O
the	O
difference	B
in	O
location	O
of	O
corresponding	O
features	O
seen	O
by	O
the	O
left	O
and	O
right	O
eyes	O
(	O
marr	O
1982	O
)	O
.	O
horizontal	O
disparity	O
is	O
the	O
most	O
commonly	O
studied	O
phenomenon	O
,	O
but	O
vertical	O
disparity	O
is	O
possible	O
if	O
the	O
eyes	O
are	O
verged	O
.	O
11.1	O
epipolar	B
geometry	I
541	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
11.6	O
sweeping	O
a	O
set	O
of	O
planes	B
through	O
a	O
scene	O
(	O
szeliski	O
and	O
golland	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
springer	O
:	O
(	O
a	O
)	O
the	O
set	O
of	O
planes	B
seen	O
from	O
a	O
virtual	O
camera	O
induces	O
a	O
set	O
of	O
homographies	O
in	O
any	O
other	O
source	O
(	O
input	O
)	O
camera	B
image	O
.	O
(	O
b	O
)	O
the	O
warped	O
images	O
from	O
all	O
the	O
other	O
cameras	O
can	O
be	O
stacked	O
into	O
a	O
generalized	B
disparity	O
space	O
volume	O
˜i	O
(	O
x	O
,	O
y	O
,	O
d	O
,	O
k	O
)	O
indexed	O
by	O
pixel	O
location	O
(	O
x	O
,	O
y	O
)	O
,	O
disparity	O
d	O
,	O
and	O
camera	B
k.	O
1997	O
)	O
)	O
,	O
the	O
last	O
row	O
of	O
a	O
full-rank	O
4	O
×	O
4	O
projection	O
matrix	O
˜p	O
can	O
be	O
set	O
to	O
an	O
arbitrary	O
plane	O
equation	O
p3	O
=	O
s3	O
[	O
ˆn0|c0	O
]	O
.	O
the	O
resulting	O
four-dimensional	O
projective	B
transform	O
(	O
collineation	B
)	O
(	O
2.68	O
)	O
maps	O
3d	O
world	O
points	B
p	O
=	O
(	O
x	O
,	O
y	O
,	O
z	O
,	O
1	O
)	O
into	O
screen	O
coordinates	O
xs	O
=	O
(	O
xs	O
,	O
ys	O
,	O
1	O
,	O
d	O
)	O
,	O
where	O
the	O
projective	B
depth	O
(	O
or	O
parallax	O
)	O
d	O
(	O
2.66	O
)	O
is	O
0	O
on	O
the	O
reference	O
plane	O
(	O
figure	O
2.11	O
)	O
.	O
sweeping	O
d	O
through	O
a	O
series	O
of	O
disparity	O
hypotheses	O
,	O
as	O
shown	O
in	O
figure	O
11.6a	O
,	O
corre-	O
sponds	O
to	O
mapping	O
each	O
input	O
image	B
into	O
the	O
virtual	O
camera	O
˜p	O
deﬁning	O
the	O
disparity	O
space	O
through	O
a	O
series	O
of	O
homographies	O
(	O
2.68–2.71	O
)	O
,	O
˜xk	O
∼	O
˜p	O
k	O
˜p	O
−1	O
xs	O
=	O
˜h	O
k	O
˜x	O
+	O
tkd	O
=	O
(	O
˜h	O
k	O
+	O
tk	O
[	O
0	O
0	O
d	O
]	O
)	O
˜x	O
,	O
(	O
11.3	O
)	O
as	O
shown	O
in	O
figure	O
2.12b	O
,	O
where	O
˜xk	O
and	O
˜x	O
are	O
the	O
homogeneous	O
pixel	O
coordinates	O
in	O
the	O
source	O
and	O
virtual	O
(	O
reference	O
)	O
images	O
(	O
szeliski	O
and	O
golland	O
1999	O
)	O
.	O
the	O
members	O
of	O
the	O
fam-	O
ily	O
of	O
homographies	O
˜h	O
k	O
(	O
d	O
)	O
=	O
˜h	O
k	O
+	O
tk	O
[	O
0	O
0	O
d	O
]	O
,	O
which	O
are	O
parametererized	O
by	O
the	O
addition	O
of	O
a	O
rank-1	O
matrix	O
,	O
are	O
related	O
to	O
each	O
other	O
through	O
a	O
planar	O
homology	O
(	O
hartley	O
and	O
zisserman	O
2004	O
,	O
a5.2	O
)	O
.	O
the	O
choice	O
of	O
virtual	O
camera	O
and	O
parameterization	O
is	O
application	O
dependent	O
and	O
is	O
what	O
gives	O
this	O
framework	O
a	O
lot	O
of	O
its	O
ﬂexibility	O
.	O
in	O
many	O
applications	O
,	O
one	O
of	O
the	O
input	O
cameras	O
(	O
the	O
reference	O
camera	B
)	O
is	O
used	O
,	O
thus	O
computing	O
a	O
depth	B
map	I
that	O
is	O
registered	O
with	O
one	O
of	O
the	O
input	O
images	O
and	O
which	O
can	O
later	O
be	O
used	O
for	O
image-based	O
rendering	B
(	O
sections	O
13.1	O
and	O
13.2	O
)	O
.	O
in	O
other	O
applications	O
,	O
such	O
as	O
view	B
interpolation	I
for	O
gaze	B
correction	I
in	O
video-conferencing	O
virtual	O
cameradxyinput	O
image	B
kuvhomography	O
:	O
u	O
=	O
h	O
x	O
xykdk	O
542	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
section	O
11.4.2	O
)	O
(	O
ott	O
,	O
lewis	O
,	O
and	O
cox	O
1993	O
;	O
criminisi	O
,	O
shotton	O
,	O
blake	O
et	O
al	O
.	O
2003	O
)	O
,	O
a	O
camera	B
centrally	O
located	O
between	O
the	O
two	O
input	O
cameras	O
is	O
preferable	O
,	O
since	O
it	O
provides	O
the	O
needed	O
per-pixel	O
disparities	O
to	O
hallucinate	O
the	O
virtual	O
middle	O
image	B
.	O
the	O
choice	O
of	O
disparity	O
sampling	B
,	O
i.e.	O
,	O
the	O
setting	O
of	O
the	O
zero	O
parallax	O
plane	O
and	O
the	O
scaling	O
of	O
integer	O
disparities	O
,	O
is	O
also	O
application	O
dependent	O
,	O
and	O
is	O
usually	O
set	O
to	O
bracket	O
the	O
range	O
of	O
interest	O
,	O
i.e.	O
,	O
the	O
working	O
volume	O
,	O
while	O
scaling	O
disparities	O
to	O
sample	O
the	O
image	B
in	O
pixel	O
(	O
or	O
sub-pixel	O
)	O
shifts	O
.	O
for	O
example	O
,	O
when	O
using	O
stereo	O
vision	O
for	O
obstacle	O
avoidance	O
in	O
robot	O
navigation	O
,	O
it	O
is	O
most	O
convenient	O
to	O
set	O
up	O
disparity	O
to	O
measure	O
per-pixel	O
elevation	O
above	O
the	O
ground	O
(	O
ivanchenko	O
,	O
shen	O
,	O
and	O
coughlan	O
2009	O
)	O
.	O
as	O
each	O
input	O
image	B
is	O
warped	O
onto	O
the	O
current	O
planes	B
parameterized	O
by	O
disparity	O
d	O
,	O
it	O
can	O
be	O
stacked	O
into	O
a	O
generalized	B
disparity	O
space	O
image	O
˜i	O
(	O
x	O
,	O
y	O
,	O
d	O
,	O
k	O
)	O
for	O
further	O
processing	O
(	O
figure	O
11.6b	O
)	O
(	O
szeliski	O
and	O
golland	O
1999	O
)	O
.	O
in	O
most	O
stereo	B
algorithms	O
,	O
the	O
photoconsistency	B
(	O
e.g.	O
,	O
sum	O
of	O
squared	O
or	O
robust	B
differences	O
)	O
with	O
respect	O
to	O
the	O
reference	O
image	B
ir	O
is	O
calculated	O
and	O
stored	O
in	O
the	O
dsi	O
c	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
ρ	O
(	O
˜i	O
(	O
x	O
,	O
y	O
,	O
d	O
,	O
k	O
)	O
−	O
ir	O
(	O
x	O
,	O
y	O
)	O
)	O
.	O
(	O
11.4	O
)	O
however	O
,	O
it	O
is	O
also	O
possible	O
to	O
compute	O
alternative	O
statistics	O
such	O
as	O
robust	B
variance	O
,	O
focus	B
,	O
or	O
entropy	O
(	O
section	O
11.3.1	O
)	O
(	O
vaish	O
,	O
szeliski	O
,	O
zitnick	O
et	O
al	O
.	O
2006	O
)	O
or	O
to	O
use	O
this	O
representation	O
to	O
reason	O
about	O
occlusions	O
(	O
szeliski	O
and	O
golland	O
1999	O
;	O
kang	O
and	O
szeliski	O
2004	O
)	O
.	O
the	O
gen-	O
eralized	O
dsi	O
will	O
come	O
in	O
particularly	O
handy	O
when	O
we	O
come	O
back	O
to	O
the	O
topic	O
of	O
multi-view	B
stereo	I
in	O
section	O
11.6.	O
of	O
course	O
,	O
planes	B
are	O
not	O
the	O
only	O
surfaces	O
that	O
can	O
be	O
used	O
to	O
deﬁne	O
a	O
3d	O
sweep	O
through	O
the	O
space	O
of	O
interest	O
.	O
cylindrical	B
surfaces	O
,	O
especially	O
when	O
coupled	O
with	O
panoramic	O
photog-	O
raphy	O
(	O
chapter	O
9	O
)	O
,	O
are	O
often	O
used	O
(	O
ishiguro	O
,	O
yamamoto	O
,	O
and	O
tsuji	O
1992	O
;	O
kang	O
and	O
szeliski	O
1997	O
;	O
shum	O
and	O
szeliski	O
1999	O
;	O
li	O
,	O
shum	O
,	O
tang	O
et	O
al	O
.	O
2004	O
;	O
zheng	O
,	O
kang	O
,	O
cohen	O
et	O
al	O
.	O
2007	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
deﬁne	O
other	O
manifold	O
topologies	O
,	O
e.g.	O
,	O
ones	O
where	O
the	O
camera	B
rotates	O
around	O
a	O
ﬁxed	O
axis	O
(	O
seitz	O
2001	O
)	O
.	O
once	O
the	O
dsi	O
has	O
been	O
computed	O
,	O
the	O
next	O
step	O
in	O
most	O
stereo	B
correspondence	O
algorithms	O
is	O
to	O
produce	O
a	O
univalued	O
function	O
in	O
disparity	O
space	O
d	O
(	O
x	O
,	O
y	O
)	O
that	O
best	O
describes	O
the	O
shape	O
of	O
the	O
surfaces	O
in	O
the	O
scene	O
.	O
this	O
can	O
be	O
viewed	O
as	O
ﬁnding	O
a	O
surface	B
embedded	O
in	O
the	O
disparity	O
space	O
image	O
that	O
has	O
some	O
optimality	O
property	O
,	O
such	O
as	O
lowest	O
cost	O
and	O
best	O
(	O
piecewise	O
)	O
smoothness	B
(	O
yang	O
,	O
yuille	O
,	O
and	O
lu	O
1993	O
)	O
.	O
figure	O
11.5	O
shows	O
examples	B
of	O
slices	O
through	O
a	O
typical	O
dsi	O
.	O
more	O
ﬁgures	O
of	O
this	O
kind	O
can	O
be	O
found	O
in	O
the	O
paper	O
by	O
bobick	O
and	O
intille	O
(	O
1999	O
)	O
.	O
11.2	O
sparse	B
correspondence	I
11.2	O
sparse	B
correspondence	I
543	O
early	O
stereo	B
matching	I
algorithms	O
were	O
feature-based	B
,	O
i.e.	O
,	O
they	O
ﬁrst	O
extracted	O
a	O
set	O
of	O
poten-	O
tially	O
matchable	O
image	B
locations	O
,	O
using	O
either	O
interest	O
operators	O
or	O
edge	O
detectors	O
,	O
and	O
then	O
searched	O
for	O
corresponding	O
locations	O
in	O
other	O
images	O
using	O
a	O
patch-based	B
metric	O
(	O
hannah	O
1974	O
;	O
marr	O
and	O
poggio	O
1979	O
;	O
mayhew	O
and	O
frisby	O
1980	O
;	O
baker	O
and	O
binford	O
1981	O
;	O
arnold	O
1983	O
;	O
grimson	O
1985	O
;	O
ohta	O
and	O
kanade	O
1985	O
;	O
bolles	O
,	O
baker	O
,	O
and	O
marimont	O
1987	O
;	O
matthies	O
,	O
kanade	O
,	O
and	O
szeliski	O
1989	O
;	O
hsieh	O
,	O
mckeown	O
,	O
and	O
perlant	O
1992	O
;	O
bolles	O
,	O
baker	O
,	O
and	O
hannah	O
1993	O
)	O
.	O
this	O
limitation	O
to	O
sparse	B
correspondences	O
was	O
partially	O
due	O
to	O
computational	O
resource	O
limitations	O
,	O
but	O
was	O
also	O
driven	O
by	O
a	O
desire	O
to	O
limit	O
the	O
answers	O
produced	O
by	O
stereo	O
algorithms	O
to	O
matches	O
with	O
high	O
certainty	O
.	O
in	O
some	O
applications	O
,	O
there	O
was	O
also	O
a	O
desire	O
to	O
match	O
scenes	O
with	O
potentially	O
very	O
different	O
illuminations	O
,	O
where	O
edges	O
might	O
be	O
the	O
only	O
stable	O
features	O
(	O
collins	O
1996	O
)	O
.	O
such	O
sparse	B
3d	O
reconstructions	O
could	O
later	O
be	O
interpolated	O
using	O
surface	O
ﬁt-	O
ting	O
algorithms	O
such	O
as	O
those	O
discussed	O
in	O
sections	O
3.7.1	O
and	O
12.3.1.	O
more	O
recent	O
work	O
in	O
this	O
area	O
has	O
focused	O
on	O
ﬁrst	O
extracting	O
highly	O
reliable	O
features	O
and	O
then	O
using	O
these	O
as	O
seeds	O
to	O
grow	O
additional	O
matches	O
(	O
zhang	O
and	O
shan	O
2000	O
;	O
lhuillier	O
and	O
quan	O
2002	O
)	O
.	O
similar	O
approaches	O
have	O
also	O
been	O
extended	O
to	O
wide	O
baseline	O
multi-view	B
stereo	I
problems	O
and	O
combined	O
with	O
3d	O
surface	B
reconstruction	I
(	O
lhuillier	O
and	O
quan	O
2005	O
;	O
strecha	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
2003	O
;	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2007	O
)	O
or	O
free-space	O
reasoning	O
(	O
taylor	O
2003	O
)	O
,	O
as	O
described	O
in	O
more	O
detail	O
in	O
section	O
11.6	O
.	O
11.2.1	O
3d	O
curves	O
and	O
proﬁles	B
another	O
example	O
of	O
sparse	B
correspondence	I
is	O
the	O
matching	B
of	O
proﬁle	B
curves	O
(	O
or	O
occluding	O
contours	O
)	O
,	O
which	O
occur	O
at	O
the	O
boundaries	O
of	O
objects	O
(	O
figure	O
11.7	O
)	O
and	O
at	O
interior	O
self	O
occlu-	O
sions	O
,	O
where	O
the	O
surface	B
curves	O
away	O
from	O
the	O
camera	B
viewpoint	O
.	O
the	O
difﬁculty	O
in	O
matching	B
proﬁle	O
curves	O
is	O
that	O
in	O
general	O
,	O
the	O
locations	O
of	O
proﬁle	B
curves	O
vary	O
as	O
a	O
function	O
of	O
camera	B
viewpoint	O
.	O
therefore	O
,	O
matching	B
curves	O
directly	O
in	O
two	O
images	O
and	O
then	O
triangulating	O
these	O
matches	O
can	O
lead	O
to	O
erroneous	O
shape	O
measurements	O
.	O
fortunately	O
,	O
if	O
three	O
or	O
more	O
closely	O
spaced	O
frames	O
are	O
available	O
,	O
it	O
is	O
possible	O
to	O
ﬁt	O
a	O
local	B
circular	O
arc	O
to	O
the	O
locations	O
of	O
corresponding	O
edgels	O
(	O
figure	O
11.7a	O
)	O
and	O
therefore	O
obtain	O
semi-dense	O
curved	O
surface	B
meshes	O
directly	O
from	O
the	O
matches	O
(	O
figures	O
11.7c	O
and	O
g	O
)	O
.	O
another	O
advantage	O
of	O
match-	O
ing	O
such	O
curves	O
is	O
that	O
they	O
can	O
be	O
used	O
to	O
reconstruct	O
surface	B
shape	O
for	O
untextured	O
surfaces	O
,	O
so	O
long	O
as	O
there	O
is	O
a	O
visible	O
difference	B
between	O
foreground	O
and	O
background	O
colors	O
.	O
over	O
the	O
years	O
,	O
a	O
number	O
of	O
different	O
techniques	O
have	O
been	O
developed	O
for	O
reconstructing	O
surface	B
shape	O
from	O
proﬁle	B
curves	O
(	O
giblin	O
and	O
weiss	O
1987	O
;	O
cipolla	O
and	O
blake	O
1992	O
;	O
vaillant	O
and	O
faugeras	O
1992	O
;	O
zheng	O
1994	O
;	O
boyer	O
and	O
berger	O
1997	O
;	O
szeliski	O
and	O
weiss	O
1998	O
)	O
.	O
cipolla	O
and	O
giblin	O
(	O
2000	O
)	O
describe	O
many	O
of	O
these	O
techniques	O
,	O
as	O
well	O
as	O
related	O
topics	O
such	O
as	O
in-	O
544	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
figure	O
11.7	O
surface	B
reconstruction	I
from	O
occluding	O
contours	O
(	O
szeliski	O
and	O
weiss	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
springer	O
:	O
(	O
a	O
)	O
circular	O
arc	O
ﬁtting	O
in	O
the	O
epipolar	O
plane	O
;	O
(	O
b	O
)	O
synthetic	O
example	O
of	O
an	O
el-	O
lipsoid	O
with	O
a	O
truncated	O
side	O
and	O
elliptic	O
surface	B
markings	O
;	O
(	O
c	O
)	O
partially	O
reconstructed	O
surface	B
mesh	O
seen	O
from	O
an	O
oblique	O
and	O
top-down	O
view	O
;	O
(	O
d	O
)	O
real-world	O
image	B
sequence	O
of	O
a	O
soda	O
can	O
on	O
a	O
turntable	O
;	O
(	O
e	O
)	O
extracted	O
edges	O
;	O
(	O
f	O
)	O
partially	O
reconstructed	O
proﬁle	B
curves	O
;	O
(	O
g	O
)	O
partially	O
re-	O
constructed	O
surface	B
mesh	O
.	O
(	O
partial	O
reconstructions	O
are	O
shown	O
so	O
as	O
not	O
to	O
clutter	O
the	O
images	O
.	O
)	O
ferring	O
camera	B
motion	O
from	O
proﬁle	B
curve	O
sequences	O
.	O
below	O
,	O
we	O
summarize	O
the	O
approach	O
developed	O
by	O
szeliski	O
and	O
weiss	O
(	O
1998	O
)	O
,	O
which	O
assumes	O
a	O
discrete	B
set	O
of	O
images	O
,	O
rather	O
than	O
formulating	O
the	O
problem	O
in	O
a	O
continuous	O
differential	O
framework	O
.	O
let	O
us	O
assume	O
that	O
the	O
camera	B
is	O
moving	O
smoothly	O
enough	O
that	O
the	O
local	B
epipolar	O
geometry	O
varies	O
slowly	O
,	O
i.e.	O
,	O
the	O
epipolar	O
planes	O
induced	O
by	O
the	O
successive	O
camera	O
centers	O
and	O
an	O
edgel	O
under	O
consideration	O
are	O
nearly	O
co-planar	O
.	O
the	O
ﬁrst	O
step	O
in	O
the	O
processing	O
pipeline	B
is	O
to	O
extract	O
and	O
link	O
edges	O
in	O
each	O
of	O
the	O
input	O
images	O
(	O
figures	O
11.7b	O
and	O
e	O
)	O
.	O
next	O
,	O
edgels	O
in	O
successive	O
images	O
are	O
matched	O
using	O
pairwise	O
epipolar	B
geometry	I
,	O
proximity	O
and	O
(	O
optionally	O
)	O
appearance	O
.	O
this	O
provides	O
a	O
linked	O
set	O
of	O
edges	O
in	O
the	O
spatio-temporal	O
volume	O
,	O
which	O
is	O
sometimes	O
called	O
the	O
weaving	O
wall	O
(	O
baker	O
1989	O
)	O
.	O
to	O
reconstruct	O
the	O
3d	O
location	O
of	O
an	O
individual	O
edgel	O
,	O
along	O
with	O
its	O
local	B
in-plane	O
normal	O
and	O
curvature	O
,	O
we	O
project	O
the	O
viewing	O
rays	O
corresponding	O
to	O
its	O
neighbors	O
onto	O
the	O
instanta-	O
neous	O
epipolar	O
plane	O
deﬁned	O
by	O
the	O
camera	B
center	O
,	O
the	O
viewing	O
ray	O
,	O
and	O
the	O
camera	B
velocity	O
,	O
as	O
shown	O
in	O
figure	O
11.7a	O
.	O
we	O
then	O
ﬁt	O
an	O
osculating	O
circle	O
to	O
the	O
projected	O
lines	B
,	O
parameteriz-	O
11.3	O
dense	B
correspondence	I
ing	O
the	O
circle	O
by	O
its	O
centerpoint	O
c	O
=	O
(	O
xc	O
,	O
yc	O
)	O
and	O
radius	O
r	O
,	O
cixc	O
+	O
siyc	O
+	O
r	O
=	O
di	O
,	O
545	O
(	O
11.5	O
)	O
where	O
ci	O
=	O
ˆti	O
·	O
ˆt0	O
and	O
si	O
=	O
−ˆti	O
·	O
ˆn0	O
are	O
the	O
cosine	O
and	O
sine	O
of	O
the	O
angle	O
between	O
viewing	O
ray	O
i	O
and	O
the	O
central	O
viewing	O
ray	O
0	O
,	O
and	O
di	O
=	O
(	O
qi	O
−	O
q0	O
)	O
·	O
ˆn0	O
is	O
the	O
perpendicular	O
distance	O
between	O
viewing	O
ray	O
i	O
and	O
the	O
local	B
origin	O
q0	O
,	O
which	O
is	O
a	O
point	O
chosen	O
on	O
the	O
central	O
viewing	O
ray	O
close	O
to	O
the	O
line	O
intersections	O
(	O
szeliski	O
and	O
weiss	O
1998	O
)	O
.	O
the	O
resulting	O
set	O
of	O
linear	B
equations	O
can	O
be	O
solved	O
using	O
least	O
squares	O
,	O
and	O
the	O
quality	O
of	O
the	O
solution	O
(	O
residual	O
error	O
)	O
can	O
be	O
used	O
to	O
check	O
for	O
erroneous	O
correspondences	O
.	O
the	O
resulting	O
set	O
of	O
3d	O
points	B
,	O
along	O
with	O
their	O
spatial	O
(	O
in-image	O
)	O
and	O
temporal	O
(	O
between-	O
image	B
)	O
neighbors	O
,	O
form	O
a	O
3d	O
surface	B
mesh	O
with	O
local	O
normal	O
and	O
curvature	O
estimates	O
(	O
fig-	O
ures	O
11.7c	O
and	O
g	O
)	O
.	O
note	O
that	O
whenever	O
a	O
curve	O
is	O
due	O
to	O
a	O
surface	B
marking	O
or	O
a	O
sharp	O
crease	O
edge	O
,	O
rather	O
than	O
a	O
smooth	O
surface	B
proﬁle	O
curve	O
,	O
this	O
shows	O
up	O
as	O
a	O
0	O
or	O
small	O
radius	O
of	O
curva-	O
ture	O
.	O
such	O
curves	O
result	O
in	O
isolated	O
3d	O
space	O
curves	O
,	O
rather	O
than	O
elements	O
of	O
smooth	O
surface	B
meshes	O
,	O
but	O
can	O
still	O
be	O
incorporated	O
into	O
the	O
3d	O
surface	B
model	O
during	O
a	O
later	O
stage	O
of	O
surface	B
interpolation	O
(	O
section	O
12.3.1	O
)	O
.	O
11.3	O
dense	B
correspondence	I
while	O
sparse	B
matching	O
algorithms	O
are	O
still	O
occasionally	O
used	O
,	O
most	O
stereo	B
matching	I
algo-	O
rithms	O
today	O
focus	B
on	O
dense	B
correspondence	I
,	O
since	O
this	O
is	O
required	O
for	O
applications	O
such	O
as	O
image-based	B
rendering	I
or	O
modeling	B
.	O
this	O
problem	O
is	O
more	O
challenging	O
than	O
sparse	B
corre-	O
spondence	O
,	O
since	O
inferring	O
depth	O
values	O
in	O
textureless	O
regions	O
requires	O
a	O
certain	O
amount	O
of	O
guesswork	O
.	O
(	O
think	O
of	O
a	O
solid	O
colored	O
background	O
seen	O
through	O
a	O
picket	O
fence	O
.	O
what	O
depth	O
should	O
it	O
be	O
?	O
)	O
in	O
this	O
section	O
,	O
we	O
review	O
the	O
taxonomy	B
and	O
categorization	O
scheme	O
for	O
dense	O
correspon-	O
dence	O
algorithms	O
ﬁrst	O
proposed	O
by	O
scharstein	O
and	O
szeliski	O
(	O
2002	O
)	O
.	O
the	O
taxonomy	B
consists	O
of	O
a	O
set	O
of	O
algorithmic	O
“	O
building	O
blocks	O
”	O
from	O
which	O
a	O
large	O
set	O
of	O
algorithms	O
can	O
be	O
con-	O
structed	O
.	O
it	O
is	O
based	O
on	O
the	O
observation	O
that	O
stereo	B
algorithms	O
generally	O
perform	O
some	O
subset	O
of	O
the	O
following	O
four	O
steps	O
:	O
1.	O
matching	B
cost	O
computation	O
;	O
2.	O
cost	O
(	O
support	O
)	O
aggregation	O
;	O
3.	O
disparity	O
computation	O
and	O
optimization	O
;	O
and	O
4.	O
disparity	O
reﬁnement	O
.	O
546	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
for	O
example	O
,	O
local	B
(	O
window-based	B
)	O
algorithms	O
(	O
section	O
11.4	O
)	O
,	O
where	O
the	O
disparity	O
com-	O
putation	O
at	O
a	O
given	O
point	O
depends	O
only	O
on	O
intensity	O
values	O
within	O
a	O
ﬁnite	O
window	O
,	O
usually	O
make	O
implicit	O
smoothness	B
assumptions	O
by	O
aggregating	O
support	O
.	O
some	O
of	O
these	O
algorithms	O
can	O
cleanly	O
be	O
broken	O
down	O
into	O
steps	O
1	O
,	O
2	O
,	O
3.	O
for	O
example	O
,	O
the	O
traditional	O
sum-of-squared-	O
differences	O
(	O
ssd	O
)	O
algorithm	B
can	O
be	O
described	O
as	O
:	O
1.	O
the	O
matching	B
cost	O
is	O
the	O
squared	O
difference	B
of	O
intensity	O
values	O
at	O
a	O
given	O
disparity	O
.	O
2.	O
aggregation	O
is	O
done	O
by	O
summing	O
the	O
matching	B
cost	O
over	O
square	O
windows	O
with	O
constant	O
disparity	O
.	O
3.	O
disparities	O
are	O
computed	O
by	O
selecting	O
the	O
minimal	O
(	O
winning	O
)	O
aggregated	O
value	O
at	O
each	O
pixel	O
.	O
some	O
local	B
algorithms	O
,	O
however	O
,	O
combine	O
steps	O
1	O
and	O
2	O
and	O
use	O
a	O
matching	B
cost	O
that	O
is	O
based	O
on	O
a	O
support	B
region	I
,	O
e.g	O
.	O
normalized	B
cross-correlation	O
(	O
hannah	O
1974	O
;	O
bolles	O
,	O
baker	O
,	O
and	O
han-	O
nah	O
1993	O
)	O
and	O
the	O
rank	O
transform	B
(	O
zabih	O
and	O
woodﬁll	O
1994	O
)	O
and	O
other	O
ordinal	O
measures	O
(	O
bhat	O
and	O
nayar	O
1998	O
)	O
.	O
(	O
this	O
can	O
also	O
be	O
viewed	O
as	O
a	O
preprocessing	O
step	O
;	O
see	O
(	O
section	O
11.3.1	O
)	O
.	O
)	O
global	B
algorithms	O
,	O
on	O
the	O
other	O
hand	O
,	O
make	O
explicit	O
smoothness	B
assumptions	O
and	O
then	O
solve	O
a	O
a	O
global	B
optimization	I
problem	O
(	O
section	O
11.5	O
)	O
.	O
such	O
algorithms	O
typically	O
do	O
not	O
per-	O
form	O
an	O
aggregation	O
step	O
,	O
but	O
rather	O
seek	O
a	O
disparity	O
assignment	O
(	O
step	O
3	O
)	O
that	O
minimizes	O
a	O
global	B
cost	O
function	O
that	O
consists	O
of	O
data	O
(	O
step	O
1	O
)	O
terms	O
and	O
smoothness	B
terms	O
.	O
the	O
main	O
dis-	O
tinctions	O
among	O
these	O
algorithms	O
is	O
the	O
minimization	O
procedure	O
used	O
,	O
e.g.	O
,	O
simulated	O
anneal-	O
ing	O
(	O
marroquin	O
,	O
mitter	O
,	O
and	O
poggio	O
1987	O
;	O
barnard	O
1989	O
)	O
,	O
probabilistic	B
(	O
mean-ﬁeld	O
)	O
diffusion	O
(	O
scharstein	O
and	O
szeliski	O
1998	O
)	O
,	O
expectation	O
maximization	O
(	O
em	O
)	O
(	O
birchﬁeld	O
,	O
natarajan	O
,	O
and	O
tomasi	O
2007	O
)	O
,	O
graph	B
cuts	I
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
,	O
or	O
loopy	B
belief	I
propagation	I
(	O
sun	O
,	O
zheng	O
,	O
and	O
shum	O
2003	O
)	O
,	O
to	O
name	O
just	O
a	O
few	O
.	O
in	O
between	O
these	O
two	O
broad	O
classes	O
are	O
certain	O
iterative	B
algorithms	O
that	O
do	O
not	O
explicitly	O
specify	O
a	O
global	B
function	O
to	O
be	O
minimized	O
,	O
but	O
whose	O
behavior	O
mimics	O
closely	O
that	O
of	O
iterative	B
optimization	O
algorithms	O
(	O
marr	O
and	O
poggio	O
1976	O
;	O
zitnick	O
and	O
kanade	O
2000	O
)	O
.	O
hierarchical	B
(	O
coarse-to-ﬁne	B
)	O
algorithms	O
resemble	O
such	O
iterative	B
algorithms	O
,	O
but	O
typically	O
operate	O
on	O
an	O
image	B
pyramid	O
where	O
results	O
from	O
coarser	O
levels	O
are	O
used	O
to	O
constrain	O
a	O
more	O
local	B
search	O
at	O
ﬁner	O
levels	O
(	O
witkin	O
,	O
terzopoulos	O
,	O
and	O
kass	O
1987	O
;	O
quam	O
1984	O
;	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
)	O
.	O
11.3.1	O
similarity	B
measures	O
the	O
ﬁrst	O
component	O
of	O
any	O
dense	O
stereo	O
matching	B
algorithm	O
is	O
a	O
similarity	B
measure	I
that	O
compares	O
pixel	O
values	O
in	O
order	B
to	O
determine	O
how	O
likely	O
they	O
are	O
to	O
be	O
in	O
correspondence	B
.	O
in	O
this	O
section	O
,	O
we	O
brieﬂy	O
review	O
the	O
similarity	B
measures	O
introduced	O
in	O
section	O
8.1	O
and	O
mention	O
a	O
11.3	O
dense	B
correspondence	I
547	O
few	O
others	O
that	O
have	O
been	O
developed	O
speciﬁcally	O
for	O
stereo	O
matching	B
(	O
scharstein	O
and	O
szeliski	O
2002	O
;	O
hirschm¨uller	O
and	O
scharstein	O
2009	O
)	O
.	O
the	O
most	O
common	O
pixel-based	O
matching	B
costs	O
include	O
sums	O
of	O
squared	O
intensity	O
differ-	O
ences	O
(	O
ssd	O
)	O
(	O
hannah	O
1974	O
)	O
and	O
absolute	O
intensity	O
differences	O
(	O
sad	O
)	O
(	O
kanade	O
1994	O
)	O
.	O
in	O
the	O
video	B
processing	O
community	O
,	O
these	O
matching	B
criteria	O
are	O
referred	O
to	O
as	O
the	O
mean-squared	O
error	O
(	O
mse	O
)	O
and	O
mean	O
absolute	O
difference	B
(	O
mad	O
)	O
measures	O
;	O
the	O
term	O
displaced	O
frame	O
dif-	O
ference	O
is	O
also	O
often	O
used	O
(	O
tekalp	O
1995	O
)	O
.	O
more	O
recently	O
,	O
robust	B
measures	O
(	O
8.2	O
)	O
,	O
including	O
truncated	O
quadratics	O
and	O
contaminated	O
gaussians	O
,	O
have	O
been	O
proposed	O
(	O
black	O
and	O
anandan	O
1996	O
;	O
black	O
and	O
rangarajan	O
1996	O
;	O
scharstein	O
and	O
szeliski	O
1998	O
)	O
.	O
these	O
measures	O
are	O
useful	O
because	O
they	O
limit	O
the	O
inﬂuence	O
of	O
mismatches	O
during	O
aggregation	O
.	O
vaish	O
,	O
szeliski	O
,	O
zitnick	O
et	O
al	O
.	O
(	O
2006	O
)	O
compare	O
a	O
number	O
of	O
such	O
robust	B
measures	O
,	O
including	O
a	O
new	O
one	O
based	O
on	O
the	O
entropy	O
of	O
the	O
pixel	O
values	O
at	O
a	O
particular	O
disparity	O
hypothesis	O
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
,	O
which	O
is	O
particularly	O
useful	O
in	O
multi-view	B
stereo	I
.	O
other	O
traditional	O
matching	B
costs	O
include	O
normalized	B
cross-correlation	O
(	O
8.11	O
)	O
(	O
hannah	O
1974	O
;	O
bolles	O
,	O
baker	O
,	O
and	O
hannah	O
1993	O
;	O
evangelidis	O
and	O
psarakis	O
2008	O
)	O
,	O
which	O
behaves	O
similarly	O
to	O
sum-of-squared-differences	O
(	O
ssd	O
)	O
,	O
and	O
binary	O
matching	O
costs	O
(	O
i.e.	O
,	O
match	O
or	O
no	O
match	O
)	O
(	O
marr	O
and	O
poggio	O
1976	O
)	O
,	O
based	O
on	O
binary	O
features	O
such	O
as	O
edges	O
(	O
baker	O
and	O
binford	O
1981	O
;	O
grimson	O
1985	O
)	O
or	O
the	O
sign	O
of	O
the	O
laplacian	O
(	O
nishihara	O
1984	O
)	O
.	O
because	O
of	O
their	O
poor	O
discriminability	O
,	O
simple	O
binary	O
matching	O
costs	O
are	O
no	O
longer	O
used	O
in	O
dense	O
stereo	O
matching	B
.	O
some	O
costs	O
are	O
insensitive	O
to	O
differences	O
in	O
camera	B
gain	O
or	O
bias	O
,	O
for	O
example	O
gradient-	O
based	O
measures	O
(	O
seitz	O
1989	O
;	O
scharstein	O
1994	O
)	O
,	O
phase	O
and	O
ﬁlter-bank	O
responses	O
(	O
marr	O
and	O
poggio	O
1979	O
;	O
kass	O
1988	O
;	O
jenkin	O
,	O
jepson	O
,	O
and	O
tsotsos	O
1991	O
;	O
jones	O
and	O
malik	O
1992	O
)	O
,	O
ﬁlters	O
that	O
remove	O
regular	O
or	O
robust	B
(	O
bilaterally	O
ﬁltered	O
)	O
means	O
(	O
ansar	O
,	O
castano	O
,	O
and	O
matthies	O
2004	O
;	O
hirschm¨uller	O
and	O
scharstein	O
2009	O
)	O
,	O
dense	O
feature	O
descriptor	O
(	O
tola	O
,	O
lepetit	O
,	O
and	O
fua	O
2010	O
)	O
,	O
and	O
non-parametric	B
measures	O
such	O
as	O
rank	O
and	O
census	O
transforms	O
(	O
zabih	O
and	O
woodﬁll	O
1994	O
)	O
,	O
ordinal	O
measures	O
(	O
bhat	O
and	O
nayar	O
1998	O
)	O
,	O
or	O
entropy	O
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
;	O
zitnick	O
and	O
kang	O
2007	O
)	O
.	O
the	O
census	O
transform	B
,	O
which	O
converts	O
each	O
pixel	O
inside	O
a	O
moving	O
window	O
into	O
a	O
bit	O
vector	O
representing	O
which	O
neighbors	O
are	O
above	O
or	O
below	O
the	O
central	O
pixel	O
,	O
was	O
found	O
by	O
hirschm¨uller	O
and	O
scharstein	O
(	O
2009	O
)	O
to	O
be	O
quite	O
robust	B
against	O
large-scale	O
,	O
non-	O
stationary	O
exposure	O
and	O
illumination	O
changes	O
.	O
it	O
is	O
also	O
possible	O
to	O
correct	O
for	O
differing	O
global	B
camera	O
characteristics	O
by	O
performing	O
a	O
preprocessing	O
or	O
iterative	B
reﬁnement	O
step	O
that	O
estimates	O
inter-image	O
bias–gain	O
variations	O
using	O
global	O
regression	O
(	O
gennert	O
1988	O
)	O
,	O
histogram	B
equalization	O
(	O
cox	O
,	O
roy	O
,	O
and	O
hingorani	O
1995	O
)	O
,	O
or	O
mutual	O
information	O
(	O
kim	O
,	O
kolmogorov	O
,	O
and	O
zabih	O
2003	O
;	O
hirschm¨uller	O
2008	O
)	O
.	O
lo-	O
cal	O
,	O
smoothly	O
varying	O
compensation	O
ﬁelds	O
have	O
also	O
been	O
proposed	O
(	O
strecha	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
2003	O
;	O
zhang	O
,	O
mcmillan	O
,	O
and	O
yu	O
2006	O
)	O
.	O
in	O
order	B
to	O
compensate	O
for	O
sampling	O
issues	O
,	O
i.e.	O
,	O
dramatically	O
different	O
pixel	O
values	O
in	O
548	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
high-frequency	O
areas	O
,	O
birchﬁeld	O
and	O
tomasi	O
(	O
1998	O
)	O
proposed	O
a	O
matching	B
cost	O
that	O
is	O
less	O
sen-	O
sitive	O
to	O
shifts	O
in	O
image	B
sampling	O
.	O
rather	O
than	O
just	O
comparing	O
pixel	O
values	O
shifted	O
by	O
integral	O
amounts	O
(	O
which	O
may	O
miss	O
a	O
valid	O
match	O
)	O
,	O
they	O
compare	O
each	O
pixel	O
in	O
the	O
reference	O
image	B
against	O
a	O
linearly	O
interpolated	O
function	O
of	O
the	O
other	O
image	B
.	O
more	O
detailed	O
studies	O
of	O
these	O
and	O
additional	O
matching	B
costs	O
are	O
explored	O
in	O
(	O
szeliski	O
and	O
scharstein	O
2004	O
;	O
hirschm¨uller	O
and	O
scharstein	O
2009	O
)	O
.	O
in	O
particular	O
,	O
if	O
you	O
expect	O
there	O
to	O
be	O
signiﬁcant	O
exposure	O
or	O
appear-	O
ance	O
variation	O
between	O
images	O
that	O
you	O
are	O
matching	B
,	O
some	O
of	O
the	O
more	O
robust	B
measures	O
that	O
performed	O
well	O
in	O
the	O
evaluation	B
by	O
hirschm¨uller	O
and	O
scharstein	O
(	O
2009	O
)	O
,	O
such	O
as	O
the	O
census	O
transform	B
(	O
zabih	O
and	O
woodﬁll	O
1994	O
)	O
,	O
ordinal	O
measures	O
(	O
bhat	O
and	O
nayar	O
1998	O
)	O
,	O
bi-	O
lateral	O
subtraction	O
(	O
ansar	O
,	O
castano	O
,	O
and	O
matthies	O
2004	O
)	O
,	O
or	O
hierarchical	B
mutual	O
information	O
(	O
hirschm¨uller	O
2008	O
)	O
,	O
should	O
be	O
used	O
.	O
11.4	O
local	B
methods	I
local	O
and	O
window-based	B
methods	O
aggregate	O
the	O
matching	B
cost	O
by	O
summing	O
or	O
averaging	O
over	O
a	O
support	B
region	I
in	O
the	O
dsi	O
c	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
.4	O
a	O
support	B
region	I
can	O
be	O
either	O
two-dimensional	B
at	O
a	O
ﬁxed	O
disparity	O
(	O
favoring	O
fronto-parallel	O
surfaces	O
)	O
,	O
or	O
three-dimensional	O
in	O
x-y-d	O
space	O
(	O
supporting	O
slanted	O
surfaces	O
)	O
.	O
two-dimensional	B
evidence	O
aggregation	O
has	O
been	O
implemented	O
using	O
square	O
windows	O
or	O
gaussian	O
convolution	O
(	O
traditional	O
)	O
,	O
multiple	B
windows	O
anchored	O
at	O
different	O
points	B
,	O
i.e.	O
,	O
shiftable	O
windows	O
(	O
arnold	O
1983	O
;	O
fusiello	O
,	O
roberto	O
,	O
and	O
trucco	O
1997	O
;	O
bobick	O
and	O
intille	O
1999	O
)	O
,	O
windows	O
with	O
adaptive	O
sizes	O
(	O
okutomi	O
and	O
kanade	O
1992	O
;	O
kanade	O
and	O
okutomi	O
1994	O
;	O
kang	O
,	O
szeliski	O
,	O
and	O
chai	O
2001	O
;	O
veksler	O
2001	O
,	O
2003	O
)	O
,	O
windows	O
based	O
on	O
connected	B
components	I
of	O
constant	O
disparity	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
1998	O
)	O
,	O
or	O
the	O
re-	O
sults	O
of	O
color-based	O
segmentation	B
(	O
yoon	O
and	O
kweon	O
2006	O
;	O
tombari	O
,	O
mattoccia	O
,	O
di	O
stefano	O
et	O
al	O
.	O
2008	O
)	O
.	O
three-dimensional	O
support	O
functions	O
that	O
have	O
been	O
proposed	O
include	O
limited	O
disparity	O
difference	B
(	O
grimson	O
1985	O
)	O
,	O
limited	O
disparity	O
gradient	O
(	O
pollard	O
,	O
mayhew	O
,	O
and	O
frisby	O
1985	O
)	O
,	O
prazdny	O
’	O
s	O
coherence	O
principle	O
(	O
prazdny	O
1985	O
)	O
,	O
and	O
the	O
more	O
recent	O
work	O
(	O
which	O
in-	O
cludes	O
visibility	B
and	O
occlusion	O
reasoning	O
)	O
by	O
zitnick	O
and	O
kanade	O
(	O
2000	O
)	O
.	O
aggregation	O
with	O
a	O
ﬁxed	O
support	O
region	B
can	O
be	O
performed	O
using	O
2d	O
or	O
3d	O
convolution	O
,	O
c	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
=	O
w	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
∗	O
c0	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
,	O
(	O
11.6	O
)	O
or	O
,	O
in	O
the	O
case	O
of	O
rectangular	O
windows	O
,	O
using	O
efﬁcient	O
moving	B
average	I
box-ﬁlters	O
(	O
sec-	O
tion	B
3.2.2	O
)	O
(	O
kanade	O
,	O
yoshida	O
,	O
oda	O
et	O
al	O
.	O
1996	O
;	O
kimura	O
,	O
shinbo	O
,	O
yamaguchi	O
et	O
al	O
.	O
1999	O
)	O
.	O
shiftable	O
windows	O
can	O
also	O
be	O
implemented	O
efﬁciently	O
using	O
a	O
separable	B
sliding	O
min-ﬁlter	O
(	O
figure	O
11.8	O
)	O
(	O
scharstein	O
and	O
szeliski	O
2002	O
,	O
section	O
4.2	O
)	O
.	O
selecting	O
among	O
windows	O
of	O
dif-	O
ferent	O
shapes	O
and	O
sizes	O
can	O
be	O
performed	O
more	O
efﬁciently	O
by	O
ﬁrst	O
computing	O
a	O
summed	O
area	O
4	O
for	O
two	O
recent	O
surveys	B
and	O
comparisons	O
of	O
such	O
techniques	O
,	O
please	O
see	O
the	O
work	O
of	O
gong	O
,	O
yang	O
,	O
wang	O
et	O
al	O
.	O
(	O
2007	O
)	O
and	O
tombari	O
,	O
mattoccia	O
,	O
di	O
stefano	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
11.4	O
local	B
methods	I
549	O
figure	O
11.8	O
shiftable	B
window	I
(	O
scharstein	O
and	O
szeliski	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
springer	O
.	O
the	O
effect	O
of	O
trying	O
all	O
3	O
×	O
3	O
shifted	O
windows	O
around	O
the	O
black	O
pixel	O
is	O
the	O
same	O
as	O
taking	O
the	O
minimum	O
matching	O
score	O
across	O
all	O
centered	O
(	O
non-shifted	O
)	O
windows	O
in	O
the	O
same	O
neighborhood	B
.	O
(	O
for	O
clarity	O
,	O
only	O
three	O
of	O
the	O
neighboring	O
shifted	O
windows	O
are	O
shown	O
here	O
.	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
11.9	O
aggregation	O
window	O
sizes	O
and	O
weights	O
adapted	O
to	O
image	B
content	O
(	O
tombari	O
,	O
mattoccia	O
,	O
di	O
stefano	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
:	O
(	O
a	O
)	O
original	O
image	B
with	O
selected	O
evaluation	B
points	O
;	O
(	O
b	O
)	O
variable	O
windows	O
(	O
veksler	O
2003	O
)	O
;	O
(	O
c	O
)	O
adaptive	B
weights	O
(	O
yoon	O
and	O
kweon	O
2006	O
)	O
;	O
(	O
d	O
)	O
segmentation-based	B
(	O
tombari	O
,	O
mattoccia	O
,	O
and	O
di	O
stefano	O
2007	O
)	O
.	O
notice	O
how	O
the	O
adaptive	B
weights	O
and	O
segmentation-based	B
techniques	O
adapt	O
their	O
support	O
to	O
similarly	O
colored	O
pixels	O
.	O
table	O
(	O
section	O
3.2.3	O
,	O
3.30–3.32	O
)	O
(	O
veksler	O
2003	O
)	O
.	O
selecting	O
the	O
right	O
window	O
is	O
important	O
,	O
since	O
windows	O
must	O
be	O
large	O
enough	O
to	O
contain	O
sufﬁcient	O
texture	B
and	O
yet	O
small	O
enough	O
so	O
that	O
they	O
do	O
not	O
straddle	O
depth	O
discontinuities	O
(	O
figure	O
11.9	O
)	O
.	O
an	O
alternative	O
method	O
for	O
ag-	O
gregation	O
is	O
iterative	B
diffusion	O
,	O
i.e.	O
,	O
repeatedly	O
adding	O
to	O
each	O
pixel	O
’	O
s	O
cost	O
the	O
weighted	B
values	O
of	O
its	O
neighboring	O
pixels	O
’	O
costs	O
(	O
szeliski	O
and	O
hinton	O
1985	O
;	O
shah	O
1993	O
;	O
scharstein	O
and	O
szeliski	O
1998	O
)	O
.	O
of	O
the	O
local	B
aggregation	O
methods	O
compared	O
by	O
gong	O
,	O
yang	O
,	O
wang	O
et	O
al	O
.	O
(	O
2007	O
)	O
and	O
tombari	O
,	O
mattoccia	O
,	O
di	O
stefano	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
the	O
fast	O
variable	O
window	O
approach	O
of	O
vek-	O
sler	O
(	O
2003	O
)	O
and	O
the	O
locally	O
weighting	O
approach	O
developed	O
by	O
yoon	O
and	O
kweon	O
(	O
2006	O
)	O
con-	O
sistently	O
stood	O
out	O
as	O
having	O
the	O
best	O
tradeoff	O
between	O
performance	O
and	O
speed.5	O
the	O
local	B
weighting	O
technique	O
,	O
in	O
particular	O
,	O
is	O
interesting	O
because	O
,	O
instead	O
of	O
using	O
square	O
windows	O
with	O
uniform	O
weighting	B
,	O
each	O
pixel	O
within	O
an	O
aggregation	O
window	O
inﬂuences	O
the	O
ﬁnal	O
match-	O
5	O
more	O
recent	O
and	O
extensive	O
results	O
from	O
tombari	O
,	O
mattoccia	O
,	O
di	O
stefano	O
et	O
al	O
.	O
(	O
2008	O
)	O
can	O
be	O
found	O
at	O
http	O
:	O
//www.vision.deis.unibo.it/spe/spehome.aspx	O
.	O
550	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ing	O
cost	O
based	O
on	O
its	O
color	B
similarity	I
and	O
spatial	O
distance	O
,	O
just	O
as	O
in	O
bilinear	B
ﬁltering	O
(	O
fig-	O
ure	O
11.9c	O
)	O
.	O
(	O
in	O
fact	O
,	O
their	O
aggregation	O
step	O
is	O
closely	O
related	O
to	O
doing	O
a	O
joint	B
bilateral	O
ﬁlter	O
on	O
the	O
color/disparity	O
image	B
,	O
except	O
that	O
it	O
is	O
done	O
symmetrically	O
in	O
both	O
reference	O
and	O
target	O
images	O
.	O
)	O
the	O
segmentation-based	B
aggregation	O
method	O
of	O
tombari	O
,	O
mattoccia	O
,	O
and	O
di	O
stefano	O
(	O
2007	O
)	O
did	O
even	O
better	O
,	O
although	O
a	O
fast	O
implementation	O
of	O
this	O
algorithm	B
does	O
not	O
yet	O
exist	O
.	O
in	O
local	B
methods	I
,	O
the	O
emphasis	O
is	O
on	O
the	O
matching	B
cost	O
computation	O
and	O
cost	O
aggregation	O
steps	O
.	O
computing	O
the	O
ﬁnal	O
disparities	O
is	O
trivial	O
:	O
simply	O
choose	O
at	O
each	O
pixel	O
the	O
disparity	O
associated	O
with	O
the	O
minimum	O
cost	O
value	O
.	O
thus	O
,	O
these	O
methods	O
perform	O
a	O
local	B
“	O
winner-	O
take-all	O
”	O
(	O
wta	O
)	O
optimization	O
at	O
each	O
pixel	O
.	O
a	O
limitation	O
of	O
this	O
approach	O
(	O
and	O
many	O
other	O
correspondence	B
algorithms	O
)	O
is	O
that	O
uniqueness	O
of	O
matches	O
is	O
only	O
enforced	O
for	O
one	O
image	B
(	O
the	O
reference	O
image	B
)	O
,	O
while	O
points	B
in	O
the	O
other	O
image	B
might	O
match	O
multiple	O
points	B
,	O
unless	O
cross-checking	O
and	O
subsequent	O
hole	B
ﬁlling	I
is	O
used	O
(	O
fua	O
1993	O
;	O
hirschm¨uller	O
and	O
scharstein	O
2009	O
)	O
.	O
11.4.1	O
sub-pixel	O
estimation	O
and	O
uncertainty	B
most	O
stereo	B
correspondence	O
algorithms	O
compute	O
a	O
set	O
of	O
disparity	O
estimates	O
in	O
some	O
dis-	O
cretized	O
space	O
,	O
e.g.	O
,	O
for	O
integer	O
disparities	O
(	O
exceptions	O
include	O
continuous	O
optimization	O
tech-	O
niques	O
such	O
as	O
optical	B
ﬂow	I
(	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
)	O
or	O
splines	B
(	O
szeliski	O
and	O
coughlan	O
1997	O
)	O
)	O
.	O
for	O
applications	O
such	O
as	O
robot	O
navigation	O
or	O
people	O
tracking	O
,	O
these	O
may	O
be	O
perfectly	O
adequate	O
.	O
however	O
for	O
image-based	O
rendering	B
,	O
such	O
quantized	O
maps	O
lead	O
to	O
very	O
unappealing	O
view	O
synthesis	O
results	O
,	O
i.e.	O
,	O
the	O
scene	O
appears	O
to	O
be	O
made	O
up	O
of	O
many	O
thin	B
shear-	O
ing	O
layers	B
.	O
to	O
remedy	O
this	O
situation	O
,	O
many	O
algorithms	O
apply	O
a	O
sub-pixel	B
reﬁnement	I
stage	O
after	O
the	O
initial	O
discrete	B
correspondence	O
stage	O
.	O
(	O
an	O
alternative	O
is	O
to	O
simply	O
start	O
with	O
more	O
discrete	B
disparity	O
levels	O
(	O
szeliski	O
and	O
scharstein	O
2004	O
)	O
.	O
)	O
sub-pixel	O
disparity	O
estimates	O
can	O
be	O
computed	O
in	O
a	O
variety	O
of	O
ways	O
,	O
including	O
iterative	B
gradient	O
descent	O
and	O
ﬁtting	O
a	O
curve	O
to	O
the	O
matching	B
costs	O
at	O
discrete	B
disparity	O
levels	O
(	O
ryan	O
,	O
gray	O
,	O
and	O
hunt	O
1980	O
;	O
lucas	O
and	O
kanade	O
1981	O
;	O
tian	O
and	O
huhns	O
1986	O
;	O
matthies	O
,	O
kanade	O
,	O
and	O
szeliski	O
1989	O
;	O
kanade	O
and	O
okutomi	O
1994	O
)	O
.	O
this	O
provides	O
an	O
easy	O
way	O
to	O
increase	O
the	O
resolution	O
of	O
a	O
stereo	B
algorithm	O
with	O
little	O
additional	O
computation	O
.	O
however	O
,	O
to	O
work	O
well	O
,	O
the	O
intensities	O
being	O
matched	O
must	O
vary	O
smoothly	O
,	O
and	O
the	O
regions	O
over	O
which	O
these	O
estimates	O
are	O
computed	O
must	O
be	O
on	O
the	O
same	O
(	O
correct	O
)	O
surface	B
.	O
recently	O
,	O
some	O
questions	O
have	O
been	O
raised	O
about	O
the	O
advisability	O
of	O
ﬁtting	O
correlation	O
curves	O
to	O
integer-sampled	O
matching	B
costs	O
(	O
shimizu	O
and	O
okutomi	O
2001	O
)	O
.	O
this	O
situation	O
may	O
even	O
be	O
worse	O
when	O
sampling-insensitive	O
dissimilarity	O
measures	O
are	O
used	O
(	O
birchﬁeld	O
and	O
tomasi	O
1998	O
)	O
.	O
these	O
issues	O
are	O
explored	O
in	O
more	O
depth	O
by	O
szeliski	O
and	O
scharstein	O
(	O
2004	O
)	O
.	O
besides	O
sub-pixel	O
computations	O
,	O
there	O
are	O
other	O
ways	O
of	O
post-processing	O
the	O
computed	O
disparities	O
.	O
occluded	O
areas	O
can	O
be	O
detected	O
using	O
cross-checking	O
,	O
i.e.	O
,	O
comparing	O
left-to-	O
11.4	O
local	B
methods	I
551	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
11.10	O
uncertainty	B
in	O
stereo	B
depth	O
estimation	B
(	O
szeliski	O
1991b	O
)	O
:	O
(	O
a	O
)	O
input	O
image	B
;	O
(	O
b	O
)	O
estimated	O
depth	B
map	I
(	O
blue	O
is	O
closer	O
)	O
;	O
(	O
c	O
)	O
estimated	O
conﬁdence	O
(	O
red	O
is	O
higher	O
)	O
.	O
as	O
you	O
can	O
see	O
,	O
more	O
textured	O
areas	O
have	O
higher	O
conﬁdence	O
.	O
right	O
and	O
right-to-left	O
disparity	O
maps	O
(	O
fua	O
1993	O
)	O
.	O
a	O
median	B
ﬁlter	O
can	O
be	O
applied	O
to	O
clean	O
up	O
spurious	O
mismatches	O
,	O
and	O
holes	O
due	O
to	O
occlusion	O
can	O
be	O
ﬁlled	O
by	O
surface	O
ﬁtting	O
or	O
by	O
distributing	O
neighboring	O
disparity	O
estimates	O
(	O
birchﬁeld	O
and	O
tomasi	O
1999	O
;	O
scharstein	O
1999	O
;	O
hirschm¨uller	O
and	O
scharstein	O
2009	O
)	O
.	O
another	O
kind	O
of	O
post-processing	O
,	O
which	O
can	O
be	O
useful	O
in	O
later	O
processing	O
stages	O
,	O
is	O
to	O
asso-	O
ciate	O
conﬁdences	O
with	O
per-pixel	O
depth	O
estimates	O
(	O
figure	O
11.10	O
)	O
,	O
which	O
can	O
be	O
done	O
by	O
looking	O
at	O
the	O
curvature	O
of	O
the	O
correlation	O
surface	B
,	O
i.e.	O
,	O
how	O
strong	O
the	O
minimum	O
in	O
the	O
dsi	O
image	B
is	O
at	O
the	O
winning	O
disparity	O
.	O
matthies	O
,	O
kanade	O
,	O
and	O
szeliski	O
(	O
1989	O
)	O
show	O
that	O
under	O
the	O
assump-	O
tion	B
of	O
small	O
noise	B
,	O
photometrically	O
calibrated	O
images	O
,	O
and	O
densely	O
sampled	O
disparities	O
,	O
the	O
variance	O
of	O
a	O
local	B
depth	O
estimate	O
can	O
be	O
estimated	O
as	O
v	O
ar	O
(	O
d	O
)	O
=	O
σ2	O
i	O
a	O
,	O
(	O
11.7	O
)	O
where	O
a	O
is	O
the	O
curvature	O
of	O
the	O
dsi	O
as	O
a	O
function	O
of	O
d	O
,	O
which	O
can	O
be	O
measured	O
using	O
a	O
local	B
parabolic	O
ﬁt	O
or	O
by	O
squaring	O
all	O
the	O
horizontal	O
gradients	O
in	O
the	O
window	O
,	O
and	O
σ2	O
i	O
is	O
the	O
vari-	O
ance	O
of	O
the	O
image	B
noise	O
,	O
which	O
can	O
be	O
estimated	O
from	O
the	O
minimum	O
ssd	O
score	O
.	O
(	O
see	O
also	O
section	O
6.1.4	O
,	O
(	O
8.44	O
)	O
,	O
and	O
appendix	O
b.6	O
.	O
)	O
11.4.2	O
application	O
:	O
stereo-based	O
head	B
tracking	I
a	O
common	O
application	O
of	O
real-time	O
stereo	B
algorithms	O
is	O
for	O
tracking	O
the	O
position	O
of	O
a	O
user	O
interacting	O
with	O
a	O
computer	O
or	O
game	O
system	O
.	O
the	O
use	O
of	O
stereo	B
can	O
dramatically	O
improve	O
the	O
reliability	O
of	O
such	O
a	O
system	O
compared	O
to	O
trying	O
to	O
use	O
monocular	O
color	B
and	O
intensity	O
information	O
(	O
darrell	O
,	O
gordon	O
,	O
harville	O
et	O
al	O
.	O
2000	O
)	O
.	O
once	O
recovered	O
,	O
this	O
information	O
can	O
be	O
used	O
in	O
a	O
variety	O
of	O
applications	O
,	O
including	O
controlling	O
a	O
virtual	O
environment	O
or	O
game	O
,	O
552	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
correcting	O
the	O
apparent	O
gaze	O
during	O
video	B
conferencing	O
,	O
and	O
background	B
replacement	I
.	O
we	O
discuss	O
the	O
ﬁrst	O
two	O
applications	O
below	O
and	O
defer	O
the	O
discussion	O
of	O
background	B
replacement	I
to	O
section	O
11.5.3.	O
the	O
use	O
of	O
head	B
tracking	I
to	O
control	O
a	O
user	O
’	O
s	O
virtual	O
viewpoint	O
while	O
viewing	O
a	O
3d	O
object	O
or	O
environment	O
on	O
a	O
computer	O
monitor	O
is	O
sometimes	O
called	O
ﬁsh	O
tank	O
virtual	O
reality	O
,	O
since	O
the	O
user	O
is	O
observing	O
a	O
3d	O
world	O
as	O
if	O
it	O
were	O
contained	O
inside	O
a	O
ﬁsh	O
tank	O
(	O
ware	O
,	O
arthur	O
,	O
and	O
booth	O
1993	O
)	O
.	O
early	O
versions	O
of	O
these	O
systems	O
used	O
mechanical	B
head	O
tracking	O
devices	O
and	O
stereo	B
glasses	O
.	O
today	O
,	O
such	O
systems	O
can	O
be	O
controlled	O
using	O
stereo-based	O
head	B
tracking	I
and	O
stereo	B
glasses	O
can	O
be	O
replaced	O
with	O
autostereoscopic	O
displays	O
.	O
head	B
tracking	I
can	O
also	O
be	O
used	O
to	O
construct	O
a	O
“	O
virtual	O
mirror	O
”	O
,	O
where	O
the	O
user	O
’	O
s	O
head	B
can	O
be	O
modiﬁed	O
in	O
real-time	O
using	O
a	O
variety	O
of	O
visual	B
effects	I
(	O
darrell	O
,	O
baker	O
,	O
crow	O
et	O
al	O
.	O
1997	O
)	O
.	O
another	O
application	O
of	O
stereo	B
head	O
tracking	O
and	O
3d	O
reconstruction	O
is	O
in	O
gaze	B
correction	I
(	O
ott	O
,	O
lewis	O
,	O
and	O
cox	O
1993	O
)	O
.	O
when	O
a	O
user	O
participates	O
in	O
a	O
desktop	O
video-conference	O
or	O
video	B
chat	O
,	O
the	O
camera	B
is	O
usually	O
placed	O
on	O
top	O
of	O
the	O
monitor	O
.	O
since	O
the	O
person	O
is	O
gazing	O
at	O
a	O
window	O
somewhere	O
on	O
the	O
screen	O
,	O
it	O
appears	O
as	O
if	O
they	O
are	O
looking	O
down	O
and	O
away	O
from	O
the	O
other	O
participants	O
,	O
instead	O
of	O
straight	O
at	O
them	O
.	O
replacing	O
the	O
single	O
camera	O
with	O
two	O
or	O
more	O
cameras	O
enables	O
a	O
virtual	O
view	O
to	O
be	O
constructed	O
right	O
at	O
the	O
position	O
where	O
they	O
are	O
looking	O
resulting	O
in	O
virtual	O
eye	O
contact	O
.	O
real-time	O
stereo	B
matching	I
is	O
used	O
to	O
construct	O
an	O
accurate	O
3d	O
head	B
model	O
and	O
view	B
interpolation	I
(	O
section	O
13.1	O
)	O
is	O
used	O
to	O
synthesize	O
the	O
novel	O
in-between	O
view	O
(	O
criminisi	O
,	O
shotton	O
,	O
blake	O
et	O
al	O
.	O
2003	O
)	O
.	O
11.5	O
global	B
optimization	I
global	O
stereo	B
matching	I
methods	O
perform	O
some	O
optimization	O
or	O
iteration	O
steps	O
after	O
the	O
dis-	O
parity	O
computation	O
phase	O
and	O
often	O
skip	O
the	O
aggregation	O
step	O
altogether	O
,	O
because	O
the	O
global	B
smoothness	O
constraints	O
perform	O
a	O
similar	O
function	O
.	O
many	O
global	B
methods	O
are	O
formulated	O
in	O
an	O
energy-minimization	O
framework	O
,	O
where	O
,	O
as	O
we	O
saw	O
in	O
sections	O
3.7	O
(	O
3.100–3.102	O
)	O
and	O
8.4	O
,	O
the	O
objective	O
is	O
to	O
ﬁnd	O
a	O
solution	O
d	O
that	O
minimizes	O
a	O
global	B
energy	O
,	O
e	O
(	O
d	O
)	O
=	O
ed	O
(	O
d	O
)	O
+	O
λes	O
(	O
d	O
)	O
.	O
(	O
11.8	O
)	O
the	O
data	O
term	O
,	O
ed	O
(	O
d	O
)	O
,	O
measures	O
how	O
well	O
the	O
disparity	O
function	O
d	O
agrees	O
with	O
the	O
input	O
image	B
pair	O
.	O
using	O
our	O
previously	O
deﬁned	O
disparity	O
space	O
image	O
,	O
we	O
deﬁne	O
this	O
energy	O
as	O
ed	O
(	O
d	O
)	O
=	O
(	O
cid:88	O
)	O
(	O
x	O
,	O
y	O
)	O
c	O
(	O
x	O
,	O
y	O
,	O
d	O
(	O
x	O
,	O
y	O
)	O
)	O
,	O
(	O
11.9	O
)	O
where	O
c	O
is	O
the	O
(	O
initial	O
or	O
aggregated	O
)	O
matching	B
cost	O
dsi	O
.	O
the	O
smoothness	B
term	O
es	O
(	O
d	O
)	O
encodes	O
the	O
smoothness	B
assumptions	O
made	O
by	O
the	O
algorithm	B
.	O
to	O
make	O
the	O
optimization	O
computationally	O
tractable	O
,	O
the	O
smoothness	B
term	O
is	O
often	O
restricted	B
11.5	O
global	B
optimization	I
553	O
to	O
measuring	O
only	O
the	O
differences	O
between	O
neighboring	O
pixels	O
’	O
disparities	O
,	O
es	O
(	O
d	O
)	O
=	O
(	O
cid:88	O
)	O
(	O
x	O
,	O
y	O
)	O
ρ	O
(	O
d	O
(	O
x	O
,	O
y	O
)	O
−	O
d	O
(	O
x	O
+	O
1	O
,	O
y	O
)	O
)	O
+	O
ρ	O
(	O
d	O
(	O
x	O
,	O
y	O
)	O
−	O
d	O
(	O
x	O
,	O
y	O
+	O
1	O
)	O
)	O
,	O
(	O
11.10	O
)	O
where	O
ρ	O
is	O
some	O
monotonically	O
increasing	O
function	O
of	O
disparity	O
difference	B
.	O
it	O
is	O
also	O
possi-	O
ble	O
to	O
use	O
larger	O
neighborhoods	O
,	O
such	O
as	O
n8	O
,	O
which	O
can	O
lead	O
to	O
better	O
boundaries	O
(	O
boykov	O
and	O
kolmogorov	O
2003	O
)	O
,	O
or	O
to	O
use	O
second-order	O
smoothness	B
terms	O
(	O
woodford	O
,	O
reid	O
,	O
torr	O
et	O
al	O
.	O
2008	O
)	O
,	O
but	O
such	O
terms	O
require	O
more	O
complex	O
optimization	O
techniques	O
.	O
an	O
alternative	O
to	O
smoothness	B
functionals	O
is	O
to	O
use	O
a	O
lower-dimensional	O
representation	O
such	O
as	O
splines	B
(	O
szeliski	O
and	O
coughlan	O
1997	O
)	O
.	O
in	O
standard	O
regularization	O
(	O
section	O
3.7.1	O
)	O
,	O
ρ	O
is	O
a	O
quadratic	O
function	O
,	O
which	O
makes	O
d	O
smooth	O
everywhere	O
and	O
may	O
lead	O
to	O
poor	O
results	O
at	O
object	O
boundaries	O
.	O
energy	O
functions	O
that	O
do	O
not	O
have	O
this	O
problem	O
are	O
called	O
discontinuity-preserving	O
and	O
are	O
based	O
on	O
robust	B
ρ	O
functions	O
(	O
terzopoulos	O
1986b	O
;	O
black	O
and	O
rangarajan	O
1996	O
)	O
.	O
the	O
seminal	O
paper	O
by	O
geman	O
and	O
ge-	O
man	O
(	O
1984	O
)	O
gave	O
a	O
bayesian	O
interpretation	O
of	O
these	O
kinds	O
of	O
energy	O
functions	O
and	O
proposed	O
a	O
discontinuity-preserving	O
energy	O
function	O
based	O
on	O
markov	O
random	O
ﬁelds	O
(	O
mrfs	O
)	O
and	O
addi-	O
tional	O
line	O
processes	O
,	O
which	O
are	O
additional	O
binary	O
variables	O
that	O
control	O
whether	O
smoothness	B
penalties	O
are	O
enforced	O
or	O
not	O
.	O
black	O
and	O
rangarajan	O
(	O
1996	O
)	O
show	O
how	O
independent	O
line	O
pro-	O
cess	O
variables	O
can	O
be	O
replaced	O
by	O
robust	O
pairwise	O
disparity	O
terms	O
.	O
the	O
terms	O
in	O
es	O
can	O
also	O
be	O
made	O
to	O
depend	O
on	O
the	O
intensity	O
differences	O
,	O
e.g.	O
,	O
ρd	O
(	O
d	O
(	O
x	O
,	O
y	O
)	O
−	O
d	O
(	O
x	O
+	O
1	O
,	O
y	O
)	O
)	O
·	O
ρi	O
(	O
(	O
cid:107	O
)	O
i	O
(	O
x	O
,	O
y	O
)	O
−	O
i	O
(	O
x	O
+	O
1	O
,	O
y	O
)	O
(	O
cid:107	O
)	O
)	O
,	O
(	O
11.11	O
)	O
where	O
ρi	O
is	O
some	O
monotonically	O
decreasing	O
function	O
of	O
intensity	O
differences	O
that	O
lowers	O
smoothness	B
costs	O
at	O
high-intensity	O
gradients	O
.	O
this	O
idea	O
(	O
gamble	O
and	O
poggio	O
1987	O
;	O
fua	O
1993	O
;	O
bobick	O
and	O
intille	O
1999	O
;	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
encourages	O
disparity	O
discontinu-	O
ities	O
to	O
coincide	O
with	O
intensity	O
or	O
color	B
edges	O
and	O
appears	O
to	O
account	O
for	O
some	O
of	O
the	O
good	O
performance	O
of	O
global	B
optimization	I
approaches	O
.	O
while	O
most	O
researchers	O
set	O
these	O
functions	O
heuristically	O
,	O
scharstein	O
and	O
pal	O
(	O
2007	O
)	O
show	O
how	O
the	O
free	O
parameters	B
in	O
such	O
conditional	O
random	O
ﬁelds	O
(	O
section	O
3.7.2	O
,	O
(	O
3.118	O
)	O
)	O
can	O
be	O
learned	B
from	O
ground	O
truth	O
disparity	O
maps	O
.	O
once	O
the	O
global	B
energy	O
has	O
been	O
deﬁned	O
,	O
a	O
variety	O
of	O
algorithms	O
can	O
be	O
used	O
to	O
ﬁnd	O
a	O
(	O
local	B
)	O
minimum	O
.	O
traditional	O
approaches	O
associated	O
with	O
regularization	O
and	O
markov	O
random	O
ﬁelds	O
include	O
continuation	O
(	O
blake	O
and	O
zisserman	O
1987	O
)	O
,	O
simulated	B
annealing	I
(	O
geman	O
and	O
geman	O
1984	O
;	O
marroquin	O
,	O
mitter	O
,	O
and	O
poggio	O
1987	O
;	O
barnard	O
1989	O
)	O
,	O
highest	B
conﬁdence	I
ﬁrst	I
(	O
chou	O
and	O
brown	O
1990	O
)	O
,	O
and	O
mean-ﬁeld	O
annealing	O
(	O
geiger	O
and	O
girosi	O
1991	O
)	O
.	O
more	O
recently	O
,	O
max-ﬂow	O
and	O
graph	B
cut	I
methods	O
have	O
been	O
proposed	O
to	O
solve	O
a	O
special	O
class	O
of	O
global	B
optimization	I
problems	O
(	O
roy	O
and	O
cox	O
1998	O
;	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
;	O
ishikawa	O
2003	O
)	O
.	O
such	O
methods	O
are	O
more	O
efﬁcient	O
than	O
simulated	B
annealing	I
and	O
have	O
produced	O
good	O
results	O
,	O
as	O
have	O
techniques	O
based	O
on	O
loopy	B
belief	I
propagation	I
(	O
sun	O
,	O
zheng	O
,	O
and	O
shum	O
554	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
2003	O
;	O
tappen	O
and	O
freeman	O
2003	O
)	O
.	O
appendix	O
b.5	O
and	O
a	O
recent	O
survey	O
paper	O
on	O
mrf	O
inference	B
(	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
discuss	O
and	O
compare	O
such	O
techniques	O
in	O
more	O
detail	O
.	O
while	O
global	B
optimization	I
techniques	O
currently	O
produce	O
the	O
best	O
stereo	B
matching	I
results	O
,	O
there	O
are	O
some	O
alternative	O
approaches	O
worth	O
studying	O
.	O
cooperative	B
algorithms	I
.	O
cooperative	B
algorithms	I
,	O
inspired	O
by	O
computational	O
models	O
of	O
hu-	O
man	O
stereo	B
vision	O
,	O
were	O
among	O
the	O
earliest	O
methods	O
proposed	O
for	O
disparity	O
computation	O
(	O
dev	O
1974	O
;	O
marr	O
and	O
poggio	O
1976	O
;	O
marroquin	O
1983	O
;	O
szeliski	O
and	O
hinton	O
1985	O
;	O
zitnick	O
and	O
kanade	O
2000	O
)	O
.	O
such	O
algorithms	O
iteratively	O
update	O
disparity	O
estimates	O
using	O
non-linear	O
operations	O
that	O
result	O
in	O
an	O
overall	O
behavior	O
similar	O
to	O
global	B
optimization	I
algorithms	O
.	O
in	O
fact	O
,	O
for	O
some	O
of	O
these	O
algorithms	O
,	O
it	O
is	O
possible	O
to	O
explicitly	O
state	O
a	O
global	B
function	O
that	O
is	O
being	O
minimized	O
(	O
scharstein	O
and	O
szeliski	O
1998	O
)	O
.	O
coarse-to-ﬁne	B
and	O
incremental	B
warping	O
.	O
most	O
of	O
today	O
’	O
s	O
best	O
algorithms	O
ﬁrst	O
enumer-	O
ate	O
all	O
possible	O
matches	O
at	O
all	O
possible	O
disparities	O
and	O
then	O
select	O
the	O
best	O
set	O
of	O
matches	O
in	O
some	O
way	O
.	O
faster	O
approaches	O
can	O
sometimes	O
be	O
obtained	O
using	O
methods	O
inspired	O
by	O
classic	O
(	O
inﬁnitesimal	O
)	O
optical	B
ﬂow	I
computation	O
.	O
here	O
,	O
images	O
are	O
successively	O
warped	O
and	O
disparity	O
estimates	O
incrementally	O
updated	O
until	O
a	O
satisfactory	O
registration	B
is	O
achieved	O
.	O
these	O
techniques	O
are	O
most	O
often	O
implemented	O
within	O
a	O
coarse-to-ﬁne	B
hierarchical	O
reﬁnement	O
framework	O
(	O
quam	O
1984	O
;	O
bergen	O
,	O
anandan	O
,	O
hanna	O
et	O
al	O
.	O
1992	O
;	O
barron	O
,	O
fleet	O
,	O
and	O
beauchemin	O
1994	O
;	O
szeliski	O
and	O
coughlan	O
1997	O
)	O
.	O
11.5.1	O
dynamic	B
programming	I
a	O
different	O
class	O
of	O
global	B
optimization	I
algorithm	O
is	O
based	O
on	O
dynamic	B
programming	I
.	O
while	O
the	O
2d	O
optimization	O
of	O
equation	B
(	O
11.8	O
)	O
can	O
be	O
shown	O
to	O
be	O
np-hard	O
for	O
common	O
classes	O
of	O
smoothness	B
functions	O
(	O
veksler	O
1999	O
)	O
,	O
dynamic	B
programming	I
can	O
ﬁnd	O
the	O
global	B
mini-	O
mum	O
for	O
independent	O
scanlines	O
in	O
polynomial	O
time	O
.	O
dynamic	B
programming	I
was	O
ﬁrst	O
used	O
for	O
stereo	O
vision	O
in	O
sparse	B
,	O
edge-based	B
methods	O
(	O
baker	O
and	O
binford	O
1981	O
;	O
ohta	O
and	O
kanade	O
1985	O
)	O
.	O
more	O
recent	O
approaches	O
have	O
focused	O
on	O
the	O
dense	O
(	O
intensity-based	B
)	O
scanline	O
match-	O
ing	O
problem	O
(	O
belhumeur	O
1996	O
;	O
geiger	O
,	O
ladendorf	O
,	O
and	O
yuille	O
1992	O
;	O
cox	O
,	O
hingorani	O
,	O
rao	O
et	O
al	O
.	O
1996	O
;	O
bobick	O
and	O
intille	O
1999	O
;	O
birchﬁeld	O
and	O
tomasi	O
1999	O
)	O
.	O
these	O
approaches	O
work	O
by	O
computing	O
the	O
minimum-cost	O
path	O
through	O
the	O
matrix	O
of	O
all	O
pairwise	O
matching	B
costs	O
between	O
two	O
corresponding	O
scanlines	O
,	O
i.e.	O
,	O
through	O
a	O
horizontal	O
slice	O
of	O
the	O
dsi	O
.	O
partial	O
occlusion	O
is	O
handled	O
explicitly	O
by	O
assigning	O
a	O
group	O
of	O
pixels	O
in	O
one	O
image	B
to	O
a	O
single	O
pixel	O
in	O
the	O
other	O
image	B
.	O
figure	O
11.11	O
schematically	O
shows	O
how	O
dp	O
works	O
,	O
while	O
figure	O
11.5f	O
shows	O
a	O
real	O
dsi	O
slice	O
over	O
which	O
the	O
dp	O
is	O
applied	O
.	O
11.5	O
global	B
optimization	I
555	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
11.11	O
stereo	B
matching	I
using	O
dynamic	B
programming	I
,	O
as	O
illustrated	O
by	O
(	O
a	O
)	O
scharstein	O
and	O
szeliski	O
(	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
springer	O
and	O
(	O
b	O
)	O
kolmogorov	O
,	O
criminisi	O
,	O
blake	O
et	O
al	O
.	O
(	O
2006	O
)	O
.	O
c	O
(	O
cid:13	O
)	O
2006	O
ieee	O
.	O
for	O
each	O
pair	O
of	O
corresponding	O
scanlines	O
,	O
a	O
minimizing	O
path	O
through	O
the	O
matrix	O
of	O
all	O
pairwise	O
matching	B
costs	O
(	O
dsi	O
)	O
is	O
selected	O
.	O
lowercase	O
letters	O
(	O
a–k	O
)	O
symbolize	O
the	O
inten-	O
sities	O
along	O
each	O
scanline	O
.	O
uppercase	O
letters	O
represent	O
the	O
selected	O
path	O
through	O
the	O
matrix	O
.	O
matches	O
are	O
indicated	O
by	O
m	O
,	O
while	O
partially	O
occluded	O
points	B
(	O
which	O
have	O
a	O
ﬁxed	O
cost	O
)	O
are	O
indicated	O
by	O
l	O
or	O
r	O
,	O
corresponding	O
to	O
points	B
only	O
visible	O
in	O
the	O
left	O
or	O
right	O
images	O
,	O
respec-	O
tively	O
.	O
usually	O
,	O
only	O
a	O
limited	O
disparity	O
range	O
is	O
considered	O
(	O
0–4	O
in	O
the	O
ﬁgure	O
,	O
indicated	O
by	O
the	O
non-shaded	O
squares	O
)	O
.	O
the	O
representation	O
in	O
(	O
a	O
)	O
allows	O
for	O
diagonal	O
moves	O
while	O
the	O
rep-	O
resentation	O
in	O
(	O
b	O
)	O
does	O
not	O
.	O
note	O
that	O
these	O
diagrams	O
,	O
which	O
use	O
the	O
cyclopean	O
representation	O
of	O
depth	O
,	O
i.e.	O
,	O
depth	O
relative	O
to	O
a	O
camera	B
between	O
the	O
two	O
input	O
cameras	O
,	O
show	O
an	O
“	O
unskewed	O
”	O
x-d	O
slice	O
through	O
the	O
dsi	O
.	O
to	O
implement	O
dynamic	B
programming	I
for	O
a	O
scanline	O
y	O
,	O
each	O
entry	O
(	O
state	O
)	O
in	O
a	O
2d	O
cost	O
matrix	O
d	O
(	O
m	O
,	O
n	O
)	O
is	O
computed	O
by	O
combining	O
its	O
dsi	O
value	O
c	O
(	O
cid:48	O
)	O
(	O
m	O
,	O
n	O
)	O
=	O
c	O
(	O
m	O
+	O
n	O
,	O
m	O
−	O
n	O
,	O
y	O
)	O
(	O
11.12	O
)	O
with	O
one	O
of	O
its	O
predecessor	O
cost	O
values	O
.	O
using	O
the	O
representation	O
shown	O
in	O
figure	O
11.11a	O
,	O
which	O
allows	O
for	O
“	O
diagonal	O
”	O
moves	O
,	O
the	O
aggregated	O
match	O
costs	O
can	O
be	O
recursively	O
computed	O
as	O
d	O
(	O
m	O
,	O
n	O
,	O
m	O
)	O
=	O
min	O
(	O
d	O
(	O
m−1	O
,	O
n−1	O
,	O
m	O
)	O
,	O
d	O
(	O
m−1	O
,	O
n	O
,	O
l	O
)	O
,	O
d	O
(	O
m−1	O
,	O
n−1	O
,	O
r	O
)	O
)	O
+	O
c	O
(	O
cid:48	O
)	O
(	O
m	O
,	O
n	O
)	O
(	O
11.13	O
)	O
d	O
(	O
m	O
,	O
n	O
,	O
l	O
)	O
=	O
min	O
(	O
d	O
(	O
m−1	O
,	O
n−1	O
,	O
m	O
)	O
,	O
d	O
(	O
m−1	O
,	O
n	O
,	O
l	O
)	O
)	O
+	O
o	O
d	O
(	O
m	O
,	O
n	O
,	O
r	O
)	O
=	O
min	O
(	O
d	O
(	O
m	O
,	O
n−1	O
,	O
m	O
)	O
,	O
d	O
(	O
m	O
,	O
n−1	O
,	O
r	O
)	O
)	O
+	O
o	O
,	O
where	O
o	O
is	O
a	O
per-pixel	O
occlusion	O
cost	O
.	O
the	O
aggregation	O
rules	O
corresponding	O
to	O
figure	O
11.11b	O
are	O
given	O
by	O
kolmogorov	O
,	O
criminisi	O
,	O
blake	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
who	O
also	O
use	O
a	O
two-state	O
foreground–	O
background	O
model	O
for	O
bi-layer	O
segmentation	B
.	O
cdefgkaleft	O
scanlineiright	O
scanlineacfgjkhbmlrrrmllmmm5kd1232810m12340leftn1234rightcyclopeandisparity64fig.3.stereomatch-space.notationconventionsforleftandrightepipolarlineswithpixelcoordinatesm	O
,	O
n	O
,	O
cyclopeancoordinateskandstereodisparityd=m−n.hypotheticalmatchingpathshowndashed	O
(	O
cf.	O
[	O
11	O
]	O
,	O
[	O
9	O
]	O
)	O
.iv.layereddynamicprogramming	O
(	O
ldp	O
)	O
themodelusedinldp	O
,	O
asmentionedearlier	O
,	O
isthegeneralstereocrfmodel	O
(	O
8	O
)	O
withenergye	O
(	O
z	O
,	O
x	O
,	O
d	O
;	O
θ	O
)	O
fromsectionii	O
,	O
butwithallverticalconstraintsremoved.alloptimiza-tionthereforetakesplaceindependently	O
,	O
withinindividualscanlines.inthisone-dimensionalsituation	O
,	O
thegibbsenergyspeci	O
(	O
cid:2	O
)	O
cationisequivalenttospecifyingahiddenmarkovmodel	O
(	O
hmm	O
)	O
on	O
(	O
x	O
,	O
d	O
)	O
alongeachscanline.asusualforanhmm	O
,	O
thepriorenergyv	O
(	O
herealsoswitchedsoftlybycontrast	O
)	O
isexpressedasamarkovchainoverxk	O
,	O
dkgivenxk−1	O
,	O
dk−1.observationlikelihoods	O
,	O
umforstereoanducforcolour	O
,	O
areexpressedasemissioncosts	O
,	O
asisstandardforanhmm.inthissectionwe	O
(	O
cid:2	O
)	O
rstsetoutthenotationforthehmmonascanline	O
,	O
andthengivedetailsofhowthevariousenergiesarerepresentedinthemodel	O
,	O
all	O
(	O
cid:2	O
)	O
nallysummarisedinastate-transitiondiagramforthehmm.a.optimalmatchingpathalongascanlineleftpixelslmandrightpixelsrn	O
,	O
onagivenscanlineoflengthnspixels	O
,	O
areorderedbyanyparticularmatchingpath	O
(	O
(	O
cid:2	O
)	O
gure3	O
)	O
,	O
giving2ncyclopeanpixelsz=	O
{	O
zk	O
,	O
k=1	O
,	O
...	O
,2ns	O
}	O
,	O
wherek=m+n.thek-axisistheso-calledcyclopean1coordinateaxis.conventionallyindpstereomatchingthe	O
(	O
cid:147	O
)	O
orderingconstraint	O
(	O
cid:148	O
)	O
[	O
26	O
]	O
,	O
[	O
8	O
]	O
isimposed	O
,	O
andthismeansthateachmovein	O
(	O
cid:2	O
)	O
gure3isallowedonlyinthepositive	O
(	O
north-to-east	O
)	O
quadrantofthediagram.stereodisparityalongthecyclopeanepipolarlineisd=	O
{	O
dk	O
,	O
k=1	O
,	O
...	O
,2ns−1	O
}	O
wheredk=m−n.stepwiserestrictionforldp	O
:	O
previousmatchingalgo-rithms	O
,	O
e.g.	O
[	O
9	O
]	O
,	O
[	O
27	O
]	O
,	O
haveallowedmultipleand/ordiago-nalmovesonthestereomatchingpaths	O
(	O
(	O
cid:2	O
)	O
g3	O
)	O
.heretheproblemdifferssigni	O
(	O
cid:2	O
)	O
cantly.in	O
[	O
9	O
]	O
,	O
[	O
27	O
]	O
diagonalmovesare1cyclopeanheremeansmid-waybetweenleftandrightinputcameras.alwaysmatched	O
,	O
andhorizontal/verticalonesareunmatched.howeverthenatureofthestereomatchingproblemdemandsthathorizontal/verticalmovesshouldcomebothinmatchedandunmatchedforms.	O
(	O
matchedhorizontal/verticalmovesareneededtorepresentthedeviationofavisiblesurfacefromfronto-parallel	O
)	O
.thisraisesaconsistencyrequirementbetweenmatchedmovetypes	O
:	O
apathconsistingofasequenceofdiagonalmovesisexactlyequivalenttoacorrespondingpathinwhichhorizontalandverticalmovesalternatestrictly.theprobabilitiesofthetwopathsshouldthereforebeidentical.thisismosteasilyachievedsimplybyoutlawingexplicit	O
,	O
diagonalmatchedmoves	O
,	O
forcingthemtobeexpressedinsteadasahorizontal/verticalpair.thisrestriction	O
,	O
illustratedin	O
(	O
cid:2	O
)	O
gure3	O
,	O
ensuresaconsistentprobabilisticinterpretationofthesequencematchingproblem.furthermore	O
,	O
thestepwiserestrictionhastheaddedvirtuethateachelementlmandrnis	O
(	O
cid:147	O
)	O
explained	O
(	O
cid:148	O
)	O
onceandonlyonce.thisisbecauseahorizontalstepin	O
(	O
cid:2	O
)	O
gure3visitsanewlm	O
,	O
whichisthereby	O
(	O
cid:147	O
)	O
explained	O
(	O
cid:148	O
)	O
butstayswiththeoldrn.conversely	O
,	O
averticalstepvisitsanewrn.thuseachlmandeachrnappearsonceandonlyonceasazkinap	O
(	O
zk|	O
...	O
)	O
term	O
,	O
inthejointlikelihoodqkp	O
(	O
zk|xk	O
,	O
dk	O
,	O
z1	O
,	O
...	O
,	O
zk−1	O
)	O
forthescanline.thismakesforaconsistentde	O
(	O
cid:2	O
)	O
nitionofthelikelihood.b.ldp	O
:	O
stereowithocclusionandlayersthethreepossiblestatesxk∈	O
{	O
f	O
,	O
b	O
,	O
o	O
}	O
aredoubledup	O
,	O
forconvenience	O
,	O
tore	O
(	O
cid:3	O
)	O
ecttheexistenceofleftandrightvariants	O
,	O
respectivelythehorizontalandverticalmovesin	O
(	O
cid:2	O
)	O
gure3.thisgivesatotalof6possiblestates	O
:	O
xk∈	O
{	O
l-match-f	O
,	O
r-match-f	O
,	O
l-match-b	O
,	O
r-match-b	O
,	O
l-occ	O
,	O
r-occ	O
}	O
.thehmmforthegibbsmodelisthenre	O
(	O
cid:3	O
)	O
ectedinthestate-spacediagramof	O
(	O
cid:2	O
)	O
gure4	O
,	O
whichrepresentsmarkovchaintransitionsk−1→k	O
,	O
intermsofcosts	O
(	O
ieenergyincrements	O
)	O
onarcs	O
,	O
andthesecapturethecontrast-modi	O
(	O
cid:2	O
)	O
edpriorenergyv.observationlikelihoodenergiesarerepresentedbythecostsumkanduckonnodes.	O
[	O
notethatleft-occludingandright-occludingstatescannotdirectlyintercommunicate	O
,	O
re	O
(	O
cid:3	O
)	O
ectingconstraintsofstereogeometry.	O
]	O
priorandcontrast	O
:	O
transitionenergiesbetweenoccludingandforegroundstatesrepresentthecomponentf	O
(	O
...	O
)	O
ofthepriorenergyv	O
(	O
17	O
)	O
,	O
andincorporatethesoftcontrastswitchv∗de	O
(	O
cid:2	O
)	O
nedearlier	O
(	O
16	O
)	O
.	O
(	O
inthiscyclopeansetting	O
,	O
v∗mustbecomputedfromcontrastintheleftortherightimage	O
,	O
accordingtowhetherthestateisleft-foregroundorright-foreground	O
.	O
)	O
themodelhasanumberofparameters	O
{	O
af	O
,	O
ab	O
,	O
ao	O
,	O
bf	O
,	O
bb	O
,	O
bo	O
,	O
cf	O
,	O
cb	O
}	O
.itmightseemproblematicthatsomanyparametersneedtobeset	O
,	O
butinfacttheycanbelearnedfromlabeledtrainingframesasfollows	O
:	O
bo=log	O
(	O
2wo	O
)	O
bf=log	O
(	O
wf	O
)	O
bb=log	O
(	O
wb	O
)	O
(	O
18	O
)	O
wherewo	O
,	O
wfandwbarethemeanwidthsofoccluded	O
,	O
foregroundandbackgroundregionsrespectively.thisfollowssimplyfromthefactthat2exp−b0istheprobabilityofescapefromanoccludedstate	O
,	O
andsoon.thenconsiderationofviewinggeometrytogetherwithanassumptionabouttypical	O
556	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
problems	O
with	O
dynamic	O
programming	O
stereo	B
include	O
the	O
selection	O
of	O
the	O
right	O
cost	O
for	O
occluded	O
pixels	O
and	O
the	O
difﬁculty	O
of	O
enforcing	O
inter-scanline	O
consistency	O
,	O
although	O
several	O
methods	O
propose	O
ways	O
of	O
addressing	O
the	O
latter	O
(	O
ohta	O
and	O
kanade	O
1985	O
;	O
belhumeur	O
1996	O
;	O
cox	O
,	O
hingorani	O
,	O
rao	O
et	O
al	O
.	O
1996	O
;	O
bobick	O
and	O
intille	O
1999	O
;	O
birchﬁeld	O
and	O
tomasi	O
1999	O
;	O
kolmogorov	O
,	O
criminisi	O
,	O
blake	O
et	O
al	O
.	O
2006	O
)	O
.	O
another	O
problem	O
is	O
that	O
the	O
dynamic	B
program-	O
ming	O
approach	O
requires	O
enforcing	O
the	O
monotonicity	B
or	O
ordering	B
constraint	I
(	O
yuille	O
and	O
poggio	O
1984	O
)	O
.	O
this	O
constraint	B
requires	O
that	O
the	O
relative	O
ordering	O
of	O
pixels	O
on	O
a	O
scanline	O
remain	O
the	O
same	O
between	O
the	O
two	O
views	O
,	O
which	O
may	O
not	O
be	O
the	O
case	O
in	O
scenes	O
containing	O
narrow	O
fore-	O
ground	O
objects	O
.	O
an	O
alternative	O
to	O
traditional	O
dynamic	B
programming	I
,	O
introduced	O
by	O
scharstein	O
and	O
szeliski	O
(	O
2002	O
)	O
,	O
is	O
to	O
neglect	O
the	O
vertical	O
smoothness	B
constraints	O
in	O
(	O
11.10	O
)	O
and	O
simply	O
optimize	O
in-	O
dependent	O
scanlines	O
in	O
the	O
global	B
energy	O
function	O
(	O
11.8	O
)	O
,	O
which	O
can	O
easily	O
be	O
done	O
using	O
a	O
recursive	O
algorithm	B
,	O
d	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
=	O
c	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
+	O
min	O
d	O
(	O
cid:48	O
)	O
{	O
d	O
(	O
x	O
−	O
1	O
,	O
y	O
,	O
d	O
(	O
cid:48	O
)	O
)	O
+	O
ρd	O
(	O
d	O
−	O
d	O
(	O
cid:48	O
)	O
)	O
}	O
.	O
(	O
11.14	O
)	O
the	O
advantage	O
of	O
this	O
scanline	B
optimization	I
algorithm	O
is	O
that	O
it	O
computes	O
the	O
same	O
represen-	O
tation	O
and	O
minimizes	O
a	O
reduced	O
version	O
of	O
the	O
same	O
energy	O
function	O
as	O
the	O
full	O
2d	O
energy	O
function	O
(	O
11.8	O
)	O
.	O
unfortunately	O
,	O
it	O
still	O
suffers	O
from	O
the	O
same	O
streaking	O
artifacts	O
as	O
dynamic	B
programming	I
.	O
a	O
much	O
better	O
approach	O
is	O
to	O
evaluate	O
the	O
cumulative	O
cost	O
function	O
(	O
11.14	O
)	O
from	O
multiple	B
directions	O
,	O
e.g	O
,	O
from	O
the	O
eight	O
cardinal	O
directions	O
,	O
n	O
,	O
e	O
,	O
w	O
,	O
s	O
,	O
ne	O
,	O
se	O
,	O
sw	O
,	O
nw	O
(	O
hirschm¨uller	O
2008	O
)	O
.	O
the	O
resulting	O
semi-global	B
optimization	I
performs	O
quite	O
well	O
and	O
is	O
extremely	O
efﬁcient	O
to	O
implement	O
.	O
even	O
though	O
dynamic	B
programming	I
and	O
scanline	B
optimization	I
algorithms	O
do	O
not	O
gen-	O
erally	O
produce	O
the	O
most	O
accurate	O
stereo	B
reconstructions	O
,	O
when	O
combined	O
with	O
sophisticated	O
aggregation	O
strategies	O
,	O
they	O
can	O
produce	O
very	O
fast	O
and	O
high-quality	O
results	O
.	O
11.5.2	O
segmentation-based	B
techniques	O
while	O
most	O
stereo	B
matching	I
algorithms	O
perform	O
their	O
computations	O
on	O
a	O
per-pixel	O
basis	O
,	O
some	O
of	O
the	O
more	O
recent	O
techniques	O
ﬁrst	O
segment	O
the	O
images	O
into	O
regions	O
and	O
then	O
try	O
to	O
label	O
each	O
region	B
with	O
a	O
disparity	O
.	O
for	O
example	O
,	O
tao	O
,	O
sawhney	O
,	O
and	O
kumar	O
(	O
2001	O
)	O
segment	O
the	O
reference	O
image	B
,	O
estimate	O
per-pixel	O
disparities	O
using	O
a	O
local	B
technique	O
,	O
and	O
then	O
do	O
local	B
plane	O
ﬁts	O
inside	O
each	O
segment	O
before	O
applying	O
smoothness	B
constraints	O
between	O
neighboring	O
segments	O
.	O
zitnick	O
,	O
kang	O
,	O
uyt-	O
tendaele	O
et	O
al	O
.	O
(	O
2004	O
)	O
and	O
zitnick	O
and	O
kang	O
(	O
2007	O
)	O
use	O
over-segmentation	O
to	O
mitigate	O
initial	O
bad	O
segmentations	O
.	O
after	O
a	O
set	O
of	O
initial	O
cost	O
values	O
for	O
each	O
segment	O
has	O
been	O
stored	O
into	O
a	O
disparity	O
space	O
distribution	O
(	O
dsd	O
)	O
,	O
iterative	B
relaxation	O
(	O
or	O
loopy	B
belief	I
propagation	I
,	O
in	O
the	O
11.5	O
global	B
optimization	I
557	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
11.12	O
segmentation-based	B
stereo	O
matching	B
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
(	O
a	O
)	O
input	O
color	B
image	O
;	O
(	O
b	O
)	O
color-based	O
segmentation	B
;	O
(	O
c	O
)	O
initial	O
disparity	O
es-	O
timates	O
;	O
(	O
d	O
)	O
ﬁnal	O
piecewise-smoothed	O
disparities	O
;	O
(	O
e	O
)	O
mrf	O
neighborhood	B
deﬁned	O
over	O
the	O
segments	O
in	O
the	O
disparity	O
space	O
distribution	O
(	O
zitnick	O
and	O
kang	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
springer	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
11.13	O
stereo	B
matching	I
with	O
adaptive	B
over-segmentation	O
and	O
matting	B
(	O
taguchi	O
,	O
wilburn	O
,	O
and	O
zitnick	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
:	O
(	O
a	O
)	O
segment	O
boundaries	O
are	O
reﬁned	O
during	O
the	O
optimization	O
,	O
leading	O
to	O
more	O
accurate	O
results	O
(	O
e.g.	O
,	O
the	O
thin	B
green	O
leaf	O
in	O
the	O
bottom	O
row	O
)	O
;	O
(	O
b	O
)	O
alpha	O
mattes	O
are	O
extracted	O
at	O
segment	O
boundaries	O
,	O
which	O
leads	O
to	O
visually	O
better	O
compositing	B
results	O
(	O
middle	O
column	O
)	O
.	O
more	O
recent	O
work	O
of	O
zitnick	O
and	O
kang	O
(	O
2007	O
)	O
)	O
is	O
used	O
to	O
adjust	O
the	O
disparity	O
estimates	O
for	O
each	O
segment	O
,	O
as	O
shown	O
in	O
figure	O
11.12.	O
taguchi	O
,	O
wilburn	O
,	O
and	O
zitnick	O
(	O
2008	O
)	O
reﬁne	O
the	O
segment	O
shapes	O
as	O
part	O
of	O
the	O
optimization	O
process	O
,	O
which	O
leads	O
to	O
much	O
improved	O
results	O
,	O
as	O
shown	O
in	O
figure	O
11.13.	O
even	O
more	O
accurate	O
results	O
are	O
obtained	O
by	O
klaus	O
,	O
sormann	O
,	O
and	O
karner	O
(	O
2006	O
)	O
,	O
who	O
ﬁrst	O
segment	O
the	O
reference	O
image	B
using	O
mean	B
shift	I
,	O
run	O
a	O
small	O
(	O
3	O
×	O
3	O
)	O
sad	O
plus	O
gradient	O
sad	O
(	O
weighted	B
by	O
cross-checking	O
)	O
to	O
get	O
initial	O
disparity	O
estimates	O
,	O
ﬁt	O
local	B
planes	O
,	O
re-ﬁt	O
with	O
global	O
planes	B
,	O
and	O
then	O
run	O
a	O
ﬁnal	O
mrf	O
on	O
plane	O
assignments	O
with	O
loopy	O
belief	B
propagation	I
.	O
when	O
the	O
algorithm	B
was	O
ﬁrst	O
introduced	O
in	O
2006	O
,	O
it	O
was	O
the	O
top	O
ranked	O
algorithm	B
on	O
the	O
evaluation	B
site	O
at	O
http	O
:	O
//vision.middlebury.edu/stereo	O
;	O
in	O
early	O
2010	O
,	O
it	O
still	O
had	O
the	O
top	O
rank	O
on	O
the	O
new	O
evaluation	B
datasets	O
.	O
the	O
highest	O
ranked	O
algorithm	B
,	O
by	O
wang	O
and	O
zheng	O
(	O
2008	O
)	O
,	O
follows	O
a	O
similar	O
approach	O
of	O
segmenting	O
the	O
image	B
,	O
doing	O
local	B
plane	O
ﬁts	O
,	O
and	O
then	O
performing	O
cooperative	O
optimization	O
558	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
of	O
neighboring	O
plane	O
ﬁt	O
parameters	B
.	O
another	O
highly	O
ranked	O
algorithm	B
,	O
by	O
yang	O
,	O
wang	O
,	O
yang	O
et	O
al	O
.	O
(	O
2009	O
)	O
,	O
uses	O
the	O
color	B
correlation	O
approach	O
of	O
yoon	O
and	O
kweon	O
(	O
2006	O
)	O
and	O
hierarchical	B
belief	O
propagation	O
to	O
obtain	O
an	O
initial	O
set	O
of	O
disparity	O
estimates	O
.	O
after	O
left–right	O
consistency	O
checking	O
to	O
detect	O
occluded	O
pixels	O
,	O
the	O
data	O
terms	O
for	O
low-conﬁdence	O
and	O
occluded	O
pixels	O
are	O
recomputed	O
using	O
segmentation-based	O
plane	O
ﬁts	O
and	O
one	O
or	O
more	O
rounds	O
of	O
hierarchical	B
belief	O
propagation	O
are	O
used	O
to	O
obtain	O
the	O
ﬁnal	O
disparity	O
estimates	O
.	O
another	O
important	O
ability	O
of	O
segmentation-based	B
stereo	O
algorithms	O
,	O
which	O
they	O
share	O
with	O
algorithms	O
that	O
use	O
explicit	O
layers	B
(	O
baker	O
,	O
szeliski	O
,	O
and	O
anandan	O
1998	O
;	O
szeliski	O
and	O
golland	O
1999	O
)	O
or	O
boundary	O
extraction	O
(	O
hasinoff	O
,	O
kang	O
,	O
and	O
szeliski	O
2006	O
)	O
,	O
is	O
the	O
ability	O
to	O
extract	O
fractional	O
pixel	O
alpha	O
mattes	O
at	O
depth	O
discontinuities	O
(	O
bleyer	O
,	O
gelautz	O
,	O
rother	O
et	O
al	O
.	O
2009	O
)	O
.	O
this	O
ability	O
is	O
crucial	O
when	O
attempting	O
to	O
create	O
virtual	O
view	O
interpolation	B
without	O
clinging	O
boundary	O
or	O
tearing	O
artifacts	O
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
and	O
also	O
to	O
seamlessly	O
insert	O
virtual	O
objects	O
(	O
taguchi	O
,	O
wilburn	O
,	O
and	O
zitnick	O
2008	O
)	O
,	O
as	O
shown	O
in	O
figure	O
11.13b	O
.	O
since	O
new	O
stereo	B
matching	I
algorithms	O
continue	O
to	O
be	O
introduced	O
every	O
year	O
,	O
it	O
is	O
a	O
good	O
idea	O
to	O
periodically	O
check	O
the	O
middlebury	O
evaluation	B
site	O
at	O
http	O
:	O
//vision.middlebury.edu/	O
stereo	B
for	O
a	O
listing	O
of	O
the	O
most	O
recent	O
algorithms	O
to	O
be	O
evaluated	O
.	O
11.5.3	O
application	O
:	O
z-keying	B
and	O
background	B
replacement	I
another	O
application	O
of	O
real-time	O
stereo	B
matching	I
is	O
z-keying	B
,	O
which	O
is	O
the	O
process	O
of	O
seg-	O
menting	O
a	O
foreground	O
actor	O
from	O
the	O
background	O
using	O
depth	O
information	O
,	O
usually	O
for	O
the	O
purpose	O
of	O
replacing	O
the	O
background	O
with	O
some	O
computer-generated	O
imagery	O
,	O
as	O
shown	O
in	O
figure	O
11.2g	O
.	O
originally	O
,	O
z-keying	B
systems	O
required	O
expensive	O
custom-built	O
hardware	O
to	O
produce	O
the	O
desired	O
depth	O
maps	O
in	O
real	O
time	O
and	O
were	O
,	O
therefore	O
,	O
restricted	B
to	O
broadcast	O
studio	O
applica-	O
tions	O
(	O
kanade	O
,	O
yoshida	O
,	O
oda	O
et	O
al	O
.	O
1996	O
;	O
iddan	O
and	O
yahav	O
2001	O
)	O
.	O
off-line	O
systems	O
were	O
also	O
developed	O
for	O
estimating	O
3d	O
multi-viewpoint	O
geometry	O
from	O
video	B
streams	O
(	O
section	O
13.5.4	O
)	O
(	O
kanade	O
,	O
rander	O
,	O
and	O
narayanan	O
1997	O
;	O
carranza	O
,	O
theobalt	O
,	O
magnor	O
et	O
al	O
.	O
2003	O
;	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
;	O
vedula	O
,	O
baker	O
,	O
and	O
kanade	O
2005	O
)	O
.	O
recent	O
advances	O
in	O
highly	O
accurate	O
real-time	O
stereo	B
matching	I
,	O
however	O
,	O
now	O
make	O
it	O
possible	O
to	O
perform	O
z-keying	B
on	O
regular	O
pcs	O
,	O
enabling	O
desktop	O
videoconferencing	O
applications	O
such	O
as	O
those	O
shown	O
in	O
fig-	O
ure	O
11.14	O
(	O
kolmogorov	O
,	O
criminisi	O
,	O
blake	O
et	O
al	O
.	O
2006	O
)	O
.	O
11.6	O
multi-view	B
stereo	I
while	O
matching	B
pairs	O
of	O
images	O
is	O
a	O
useful	O
way	O
of	O
obtaining	O
depth	O
information	O
,	O
matching	B
more	O
images	O
can	O
lead	O
to	O
even	O
better	O
results	O
.	O
in	O
this	O
section	O
,	O
we	O
review	O
not	O
only	O
techniques	O
for	O
11.6	O
multi-view	B
stereo	I
559	O
figure	O
11.14	O
background	B
replacement	I
using	O
z-keying	B
with	O
a	O
bi-layer	O
segmentation	B
algo-	O
rithm	O
(	O
kolmogorov	O
,	O
criminisi	O
,	O
blake	O
et	O
al	O
.	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
ieee	O
.	O
creating	O
complete	O
3d	O
object	O
models	O
,	O
but	O
also	O
simpler	O
techniques	O
for	O
improving	O
the	O
quality	O
of	O
depth	O
maps	O
using	O
multiple	O
source	O
images	O
.	O
as	O
we	O
saw	O
in	O
our	O
discussion	O
of	O
plane	B
sweep	I
(	O
section	O
11.1.2	O
)	O
,	O
it	O
is	O
possible	O
to	O
resample	O
all	O
neighboring	O
k	O
images	O
at	O
each	O
disparity	O
hypothesis	O
d	O
into	O
a	O
generalized	B
disparity	O
space	O
volume	O
˜i	O
(	O
x	O
,	O
y	O
,	O
d	O
,	O
k	O
)	O
.	O
the	O
simplest	O
way	O
to	O
take	O
advantage	O
of	O
these	O
additional	O
images	O
is	O
to	O
sum	O
up	O
their	O
differences	O
from	O
the	O
reference	O
image	B
ir	O
as	O
in	O
(	O
11.4	O
)	O
,	O
c	O
(	O
x	O
,	O
y	O
,	O
d	O
)	O
=	O
(	O
cid:88	O
)	O
k	O
ρ	O
(	O
˜i	O
(	O
x	O
,	O
y	O
,	O
d	O
,	O
k	O
)	O
−	O
ir	O
(	O
x	O
,	O
y	O
)	O
)	O
.	O
(	O
11.15	O
)	O
this	O
is	O
the	O
basis	O
of	O
the	O
well-known	O
sum	O
of	O
summed-squared-difference	O
(	O
sssd	O
)	O
and	O
ssad	O
approaches	O
(	O
okutomi	O
and	O
kanade	O
1993	O
;	O
kang	O
,	O
webb	O
,	O
zitnick	O
et	O
al	O
.	O
1995	O
)	O
,	O
which	O
can	O
be	O
ex-	O
tended	O
to	O
reason	O
about	O
likely	O
patterns	B
of	O
occlusion	O
(	O
nakamura	O
,	O
matsuura	O
,	O
satoh	O
et	O
al	O
.	O
1996	O
)	O
.	O
more	O
recent	O
work	O
by	O
gallup	O
,	O
frahm	O
,	O
mordohai	O
et	O
al	O
.	O
(	O
2008	O
)	O
show	O
how	O
to	O
adapt	O
the	O
base-	O
lines	B
used	O
to	O
the	O
expected	O
depth	O
in	O
order	B
to	O
get	O
the	O
best	O
tradeoff	O
between	O
geometric	B
accuracy	O
(	O
wide	O
baseline	O
)	O
and	O
robustness	O
to	O
occlusion	O
(	O
narrow	O
baseline	O
)	O
.	O
alternative	O
multi-view	B
cost	O
metrics	O
include	O
measures	O
such	O
as	O
synthetic	O
focus	B
sharpness	O
and	O
the	O
entropy	O
of	O
the	O
pixel	O
color	O
distribution	O
(	O
vaish	O
,	O
szeliski	O
,	O
zitnick	O
et	O
al	O
.	O
2006	O
)	O
.	O
a	O
useful	O
way	O
to	O
visualize	O
the	O
multi-frame	B
stereo	O
estimation	B
problem	O
is	O
to	O
examine	O
the	O
epipolar	B
plane	I
image	I
(	O
epi	O
)	O
formed	O
by	O
stacking	O
corresponding	O
scanlines	O
from	O
all	O
the	O
images	O
,	O
as	O
shown	O
in	O
figures	O
8.13c	O
and	O
11.15	O
(	O
bolles	O
,	O
baker	O
,	O
and	O
marimont	O
1987	O
;	O
baker	O
and	O
bolles	O
1989	O
;	O
baker	O
1989	O
)	O
.	O
as	O
you	O
can	O
see	O
in	O
figure	O
11.15	O
,	O
as	O
a	O
camera	B
translates	O
horizontally	O
(	O
in	O
a	O
standard	O
horizontally	O
rectiﬁed	O
geometry	O
)	O
,	O
objects	O
at	O
different	O
depths	O
move	O
sideways	O
at	O
a	O
rate	O
inversely	O
proportional	O
to	O
their	O
depth	O
(	O
11.1	O
)	O
.6	O
foreground	O
objects	O
occlude	O
background	O
objects	O
,	O
which	O
can	O
be	O
seen	O
as	O
epi-strips	O
(	O
criminisi	O
,	O
kang	O
,	O
swaminathan	O
et	O
al	O
.	O
2005	O
)	O
occluding	O
other	O
6	O
the	O
four-dimensional	O
generalization	O
of	O
the	O
epi	O
is	O
the	O
light	B
ﬁeld	I
,	O
which	O
we	O
study	O
in	O
section	O
13.3.	O
in	O
principle	O
,	O
560	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
11.15	O
epipolar	B
plane	I
image	I
(	O
epi	O
)	O
(	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
and	O
a	O
schematic	O
epi	O
(	O
kang	O
,	O
szeliski	O
,	O
and	O
chai	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
.	O
(	O
a	O
)	O
the	O
lumigraph	O
(	O
light	B
ﬁeld	I
)	O
(	O
section	O
13.3	O
)	O
is	O
the	O
4d	O
space	O
of	O
all	O
light	O
rays	O
passing	O
through	O
a	O
volume	O
of	O
space	O
.	O
taking	O
a	O
2d	O
slice	O
results	O
in	O
all	O
of	O
the	O
light	O
rays	O
embedded	O
in	O
a	O
plane	O
and	O
is	O
equivalent	O
to	O
a	O
scanline	O
taken	O
from	O
a	O
stacked	O
epi	O
volume	O
.	O
objects	O
at	O
different	O
depths	O
move	O
sideways	O
with	O
velocities	O
(	O
slopes	O
)	O
proportional	O
to	O
their	O
inverse	B
depth	O
.	O
occlusion	O
(	O
and	O
translucency	O
)	O
effects	O
can	O
easily	O
be	O
seen	O
in	O
this	O
representation	O
.	O
(	O
b	O
)	O
the	O
epi	O
corresponding	O
to	O
figure	O
11.16	O
showing	O
the	O
three	O
images	O
(	O
middle	O
,	O
left	O
,	O
and	O
right	O
)	O
as	O
slices	O
through	O
the	O
epi	O
volume	O
.	O
the	O
spatially	O
and	O
temporally	O
shifted	O
window	O
around	O
the	O
black	O
pixel	O
is	O
indicated	O
by	O
the	O
rectangle	O
,	O
showing	O
the	O
right	O
image	B
is	O
not	O
being	O
used	O
in	O
matching	B
.	O
strips	O
in	O
the	O
epi	O
.	O
if	O
we	O
are	O
given	O
a	O
dense	O
enough	O
set	O
of	O
images	O
,	O
we	O
can	O
ﬁnd	O
such	O
strips	O
and	O
reason	O
about	O
their	O
relationships	O
in	O
order	B
to	O
both	O
reconstruct	O
the	O
3d	O
scene	O
and	O
make	O
inferences	O
about	O
translucent	O
objects	O
(	O
tsin	O
,	O
kang	O
,	O
and	O
szeliski	O
2006	O
)	O
and	O
specular	B
reﬂections	O
(	O
swami-	O
nathan	O
,	O
kang	O
,	O
szeliski	O
et	O
al	O
.	O
2002	O
;	O
criminisi	O
,	O
kang	O
,	O
swaminathan	O
et	O
al	O
.	O
2005	O
)	O
.	O
alternatively	O
,	O
we	O
can	O
treat	O
the	O
series	O
of	O
images	O
as	O
a	O
set	O
of	O
sequential	O
observations	O
and	O
merge	O
them	O
using	O
kalman	O
ﬁltering	O
(	O
matthies	O
,	O
kanade	O
,	O
and	O
szeliski	O
1989	O
)	O
or	O
maximum	O
likelihood	O
inference	B
(	O
cox	O
1994	O
)	O
.	O
when	O
fewer	O
images	O
are	O
available	O
,	O
it	O
becomes	O
necessary	O
to	O
fall	O
back	O
on	O
aggregation	O
tech-	O
niques	O
such	O
as	O
sliding	O
windows	O
or	O
global	B
optimization	I
.	O
with	O
additional	O
input	O
images	O
,	O
how-	O
ever	O
,	O
the	O
likelihood	O
of	O
occlusions	O
increases	O
.	O
it	O
is	O
therefore	O
prudent	O
to	O
adjust	O
not	O
only	O
the	O
best	O
window	O
locations	O
using	O
a	O
shiftable	B
window	I
approach	O
,	O
as	O
shown	O
in	O
figure	O
11.16a	O
,	O
but	O
also	O
to	O
optionally	O
select	O
a	O
subset	O
of	O
neighboring	O
frames	O
in	O
order	B
to	O
discount	O
those	O
images	O
where	O
the	O
region	B
of	O
interest	O
is	O
occluded	O
,	O
as	O
shown	O
in	O
figure	O
11.16b	O
(	O
kang	O
,	O
szeliski	O
,	O
and	O
chai	O
2001	O
)	O
.	O
there	O
is	O
enough	O
information	O
in	O
a	O
light	B
ﬁeld	I
to	O
recover	O
both	O
the	O
shape	O
and	O
the	O
brdf	O
of	O
objects	O
(	O
soatto	O
,	O
yezzi	O
,	O
and	O
jin	O
2003	O
)	O
,	O
although	O
relatively	O
little	O
progress	O
has	O
been	O
made	O
to	O
date	O
on	O
this	O
topic	O
.	O
aedcbleftmiddlerightfxt	O
11.6	O
multi-view	B
stereo	I
561	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
11.16	O
spatio-temporally	O
shiftable	O
windows	O
(	O
kang	O
,	O
szeliski	O
,	O
and	O
chai	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
a	O
simple	O
three-image	O
sequence	O
(	O
the	O
middle	O
image	B
is	O
the	O
reference	O
image	B
)	O
,	O
which	O
has	O
a	O
moving	O
frontal	O
gray	O
square	O
(	O
marked	O
f	O
)	O
and	O
a	O
stationary	O
background	O
.	O
regions	O
b	O
,	O
c	O
,	O
d	O
,	O
and	O
e	O
are	O
partially	O
occluded	O
.	O
(	O
a	O
)	O
a	O
regular	O
ssd	O
algorithm	B
will	O
make	O
mistakes	O
when	O
matching	B
pixels	O
in	O
these	O
regions	O
(	O
e.g	O
.	O
the	O
window	O
centered	O
on	O
the	O
black	O
pixel	O
in	O
region	B
b	O
)	O
and	O
in	O
windows	O
straddling	O
depth	O
discontinuities	O
(	O
the	O
window	O
centered	O
on	O
the	O
white	O
pixel	O
in	O
region	B
f	O
)	O
.	O
(	O
b	O
)	O
shiftable	O
windows	O
help	O
mitigate	O
the	O
problems	O
in	O
partially	O
occluded	O
regions	O
and	O
near	O
depth	O
discontinuities	O
.	O
the	O
shifted	O
window	O
centered	O
on	O
the	O
white	O
pixel	O
in	O
region	B
f	O
matches	O
correctly	O
in	O
all	O
frames	O
.	O
the	O
shifted	O
window	O
centered	O
on	O
the	O
black	O
pixel	O
in	O
region	B
b	O
matches	O
correctly	O
in	O
the	O
left	O
image	B
,	O
but	O
requires	O
temporal	O
selection	O
to	O
disable	O
matching	B
the	O
right	O
image	B
.	O
figure	O
11.15b	O
shows	O
an	O
epi	O
corresponding	O
to	O
this	O
sequence	O
and	O
describes	O
in	O
more	O
detail	O
how	O
temporal	O
selection	O
works	O
.	O
figure11.15b	O
shows	O
how	O
such	O
spatio-temporal	O
selection	O
or	O
shifting	O
of	O
windows	O
corresponds	O
to	O
selecting	O
the	O
most	O
likely	O
un-occluded	O
volumetric	B
region	O
in	O
the	O
epipolar	B
plane	I
image	I
vol-	O
ume	O
.	O
the	O
results	O
of	O
applying	O
these	O
techniques	O
to	O
the	O
multi-frame	B
ﬂower	O
garden	O
image	B
sequence	O
are	O
shown	O
in	O
figure	O
11.17	O
,	O
which	O
compares	O
the	O
results	O
of	O
using	O
regular	O
(	O
non-shifted	O
)	O
sssd	O
with	O
spatially	O
shifted	O
windows	O
and	O
full	O
spatio-temporal	O
window	O
selection	O
.	O
(	O
the	O
task	O
of	O
applying	O
stereo	B
to	O
a	O
rigid	O
scene	O
ﬁlmed	O
with	O
a	O
moving	O
camera	O
is	O
sometimes	O
called	O
motion	B
stereo	O
)	O
.	O
similar	O
improvements	O
from	O
using	O
spatio-temporal	O
selection	O
are	O
reported	O
by	O
(	O
kang	O
and	O
szeliski	O
2004	O
)	O
and	O
are	O
evident	O
even	O
when	O
local	B
measurements	O
are	O
combined	O
with	O
global	O
optimization	O
.	O
while	O
computing	O
a	O
depth	B
map	I
from	O
multiple	B
inputs	O
outperforms	O
pairwise	O
stereo	B
match-	O
ing	O
,	O
even	O
more	O
dramatic	O
improvements	O
can	O
be	O
obtained	O
by	O
estimating	O
multiple	B
depth	O
maps	O
simultaneously	O
(	O
szeliski	O
1999	O
;	O
kang	O
and	O
szeliski	O
2004	O
)	O
.	O
the	O
existence	O
of	O
multiple	B
depth	O
maps	O
enables	O
more	O
accurate	O
reasoning	O
about	O
occlusions	O
,	O
as	O
regions	O
which	O
are	O
occluded	O
in	O
one	O
image	B
may	O
be	O
visible	O
(	O
and	O
matchable	O
)	O
in	O
others	O
.	O
the	O
multi-view	B
reconstruction	O
problem	O
can	O
be	O
formulated	O
as	O
the	O
simultaneous	O
estimation	B
of	O
depth	O
maps	O
at	O
key	O
frames	O
(	O
figure	O
8.13c	O
)	O
while	O
maximizing	O
not	O
only	O
photoconsistency	B
and	O
piecewise	O
disparity	O
smoothness	B
but	O
also	O
the	O
consistency	O
between	O
disparity	O
estimates	O
at	O
different	O
frames	O
.	O
while	O
szeliski	O
(	O
1999	O
)	O
and	O
kang	O
abcdefabcdefabcdefleftmiddlerightabcdefabcdefabcdefleftmiddleright	O
562	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
11.17	O
local	B
(	O
5	O
×	O
5	O
window-based	B
)	O
matching	B
results	O
(	O
kang	O
,	O
szeliski	O
,	O
and	O
chai	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
window	O
that	O
is	O
not	O
spatially	O
perturbed	O
(	O
centered	O
)	O
;	O
(	O
b	O
)	O
spatially	O
perturbed	O
window	O
;	O
(	O
c	O
)	O
using	O
the	O
best	O
ﬁve	O
of	O
10	O
neighboring	O
frames	O
;	O
(	O
d	O
)	O
using	O
the	O
better	O
half	O
sequence	O
.	O
notice	O
how	O
the	O
results	O
near	O
the	O
tree	O
trunk	O
are	O
improved	O
using	O
temporal	O
selection	O
.	O
and	O
szeliski	O
(	O
2004	O
)	O
use	O
soft	O
(	O
penalty-based	O
)	O
constraints	O
to	O
encourage	O
multiple	B
disparity	O
maps	O
to	O
be	O
consistent	O
,	O
kolmogorov	O
and	O
zabih	O
(	O
2002	O
)	O
show	O
how	O
such	O
consistency	O
measures	O
can	O
be	O
encoded	O
as	O
hard	O
constraints	O
,	O
which	O
guarantee	O
that	O
the	O
multiple	B
depth	O
maps	O
are	O
not	O
only	O
similar	O
but	O
actually	O
identical	O
in	O
overlapping	O
regions	O
.	O
newer	O
algorithms	O
that	O
simultaneously	O
estimate	O
multiple	B
disparity	O
maps	O
include	O
papers	O
by	O
maitre	O
,	O
shinagawa	O
,	O
and	O
do	O
(	O
2008	O
)	O
and	O
zhang	O
,	O
jia	O
,	O
wong	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
a	O
closely	O
related	O
topic	O
to	O
multi-frame	B
stereo	O
estimation	B
is	O
scene	O
ﬂow	O
,	O
in	O
which	O
multiple	B
cameras	O
are	O
used	O
to	O
capture	O
a	O
dynamic	B
scene	O
.	O
the	O
task	O
is	O
then	O
to	O
simultaneously	O
recover	O
the	O
3d	O
shape	O
of	O
the	O
object	O
at	O
every	O
instant	O
in	O
time	O
and	O
to	O
estimate	O
the	O
full	O
3d	O
motion	B
of	O
every	O
surface	B
point	O
between	O
frames	O
.	O
representative	O
papers	O
in	O
this	O
area	O
include	O
those	O
by	O
vedula	O
,	O
baker	O
,	O
rander	O
et	O
al	O
.	O
(	O
2005	O
)	O
,	O
zhang	O
and	O
kambhamettu	O
(	O
2003	O
)	O
,	O
pons	O
,	O
keriven	O
,	O
and	O
faugeras	O
(	O
2007	O
)	O
,	O
huguet	O
and	O
devernay	O
(	O
2007	O
)	O
,	O
and	O
wedel	O
,	O
rabe	O
,	O
vaudrey	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
figure	O
11.18a	O
shows	O
an	O
image	B
of	O
the	O
3d	O
scene	O
ﬂow	O
for	O
the	O
tango	O
dancer	O
shown	O
in	O
figure	O
11.2h–j	O
,	O
while	O
figure	O
11.18b	O
shows	O
3d	O
scene	O
ﬂows	O
captured	O
from	O
a	O
moving	O
vehicle	O
for	O
the	O
purpose	O
of	O
obstacle	O
avoidance	O
.	O
in	O
addition	O
to	O
supporting	O
mensuration	O
and	O
safety	O
applications	O
,	O
scene	O
ﬂow	O
can	O
be	O
used	O
to	O
support	O
both	O
spatial	O
and	O
temporal	O
view	B
interpolation	I
(	O
section	O
13.5.4	O
)	O
,	O
as	O
demonstrated	O
by	O
vedula	O
,	O
baker	O
,	O
and	O
kanade	O
(	O
2005	O
)	O
.	O
11.6.1	O
volumetric	B
and	O
3d	O
surface	B
reconstruction	I
according	O
to	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
(	O
2006	O
)	O
:	O
the	O
goal	O
of	O
multi-view	B
stereo	I
is	O
to	O
reconstruct	O
a	O
complete	O
3d	O
object	O
model	O
from	O
a	O
collection	O
of	O
images	O
taken	O
from	O
known	O
camera	B
viewpoints	O
.	O
the	O
most	O
challenging	O
but	O
potentially	O
most	O
useful	O
variant	O
of	O
multi-view	B
stereo	I
reconstruc-	O
tion	B
is	O
to	O
create	O
globally	O
consistent	O
3d	O
models	O
.	O
this	O
topic	O
has	O
a	O
long	O
history	O
in	O
computer	O
vision	O
,	O
starting	O
with	O
surface	O
mesh	O
reconstruction	O
techniques	O
such	O
as	O
the	O
one	O
developed	O
by	O
11.6	O
multi-view	B
stereo	I
563	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
11.18	O
three-dimensional	O
scene	O
ﬂow	O
:	O
(	O
a	O
)	O
computed	O
from	O
a	O
multi-camera	O
dome	O
sur-	O
rounding	O
the	O
dancer	O
shown	O
in	O
figure	O
11.2h–j	O
(	O
vedula	O
,	O
baker	O
,	O
rander	O
et	O
al	O
.	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
;	O
(	O
b	O
)	O
computed	O
from	O
stereo	B
cameras	O
mounted	O
on	O
a	O
moving	O
vehicle	O
(	O
wedel	O
,	O
rabe	O
,	O
vau-	O
drey	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
springer	O
.	O
fua	O
and	O
leclerc	O
(	O
1995	O
)	O
(	O
figure	O
11.19a	O
)	O
.	O
a	O
variety	O
of	O
approaches	O
and	O
representations	O
have	O
been	O
used	O
to	O
solve	O
this	O
problem	O
,	O
including	O
3d	O
voxel	O
representations	O
(	O
seitz	O
and	O
dyer	O
1999	O
;	O
szeliski	O
and	O
golland	O
1999	O
;	O
de	O
bonet	O
and	O
viola	O
1999	O
;	O
kutulakos	O
and	O
seitz	O
2000	O
;	O
eisert	O
,	O
stein-	O
bach	O
,	O
and	O
girod	O
2000	O
;	O
slabaugh	O
,	O
culbertson	O
,	O
slabaugh	O
et	O
al	O
.	O
2004	O
;	O
sinha	O
and	O
pollefeys	O
2005	O
;	O
vogiatzis	O
,	O
hernandez	O
,	O
torr	O
et	O
al	O
.	O
2007	O
;	O
hiep	O
,	O
keriven	O
,	O
pons	O
et	O
al	O
.	O
2009	O
)	O
,	O
level	B
sets	I
(	O
faugeras	O
and	O
keriven	O
1998	O
;	O
pons	O
,	O
keriven	O
,	O
and	O
faugeras	O
2007	O
)	O
,	O
polygonal	O
meshes	O
(	O
fua	O
and	O
leclerc	O
1995	O
;	O
narayanan	O
,	O
rander	O
,	O
and	O
kanade	O
1998	O
;	O
hernandez	O
and	O
schmitt	O
2004	O
;	O
furukawa	O
and	O
ponce	O
2009	O
)	O
,	O
and	O
multiple	B
depth	O
maps	O
(	O
kolmogorov	O
and	O
zabih	O
2002	O
)	O
.	O
figure	O
11.19	O
shows	O
representative	O
examples	B
of	O
3d	O
object	O
models	O
reconstructed	O
using	O
some	O
of	O
these	O
techniques	O
.	O
in	O
order	B
to	O
organize	O
and	O
compare	O
all	O
these	O
techniques	O
,	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
(	O
2006	O
)	O
developed	O
a	O
six-point	O
taxonomy	B
that	O
can	O
help	O
classify	O
algorithms	O
according	O
to	O
the	O
scene	O
rep-	O
resentation	O
,	O
photoconsistency	B
measure	O
,	O
visibility	B
model	O
,	O
shape	B
priors	I
,	O
reconstruction	O
algo-	O
rithm	O
,	O
and	O
initialization	B
requirements	I
they	O
use	O
.	O
below	O
,	O
we	O
summarize	O
some	O
of	O
these	O
choices	O
and	O
list	O
a	O
few	O
representative	O
papers	O
.	O
for	O
more	O
details	O
,	O
please	O
consult	O
the	O
full	O
survey	O
paper	O
(	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
2006	O
)	O
and	O
the	O
evaluation	B
web	O
site	O
,	O
http	O
:	O
//vision.middlebury.edu/	O
mview/	O
,	O
which	O
contains	O
pointers	O
to	O
even	O
more	O
recent	O
papers	O
and	O
results	O
.	O
scene	B
representation	I
.	O
one	O
of	O
the	O
more	O
popular	O
3d	O
representations	O
is	O
a	O
uniform	O
grid	O
of	O
3d	O
voxels,7	O
which	O
can	O
be	O
reconstructed	O
using	O
a	O
variety	O
of	O
carving	O
(	O
seitz	O
and	O
dyer	O
1999	O
;	O
kutu-	O
lakos	O
and	O
seitz	O
2000	O
)	O
or	O
optimization	O
(	O
sinha	O
and	O
pollefeys	O
2005	O
;	O
vogiatzis	O
,	O
hernandez	O
,	O
torr	O
et	O
al	O
.	O
2007	O
;	O
hiep	O
,	O
keriven	O
,	O
pons	O
et	O
al	O
.	O
2009	O
)	O
techniques	O
.	O
level	O
set	O
techniques	O
(	O
section	O
5.1.4	O
)	O
also	O
operate	O
on	O
a	O
uniform	O
grid	O
but	O
,	O
instead	O
of	O
representing	O
a	O
binary	O
occupancy	O
map	O
,	O
they	O
represent	O
the	O
signed	B
distance	O
to	O
the	O
surface	B
(	O
faugeras	O
and	O
keriven	O
1998	O
;	O
pons	O
,	O
keriven	O
,	O
and	O
faugeras	O
2007	O
)	O
,	O
which	O
can	O
encode	O
a	O
ﬁner	O
level	O
of	O
detail	O
.	O
polygonal	O
meshes	O
are	O
another	O
pop-	O
7	O
for	O
outdoor	O
scenes	O
that	O
go	O
to	O
inﬁnity	O
,	O
a	O
non-uniform	O
gridding	O
of	O
space	O
may	O
be	O
preferable	O
(	O
slabaugh	O
,	O
culbertson	O
,	O
slabaugh	O
et	O
al	O
.	O
2004	O
)	O
.	O
eﬃcientdensesceneflowfromsparseordensestereodataandreaswedel1,2	O
,	O
clemensrabe1	O
,	O
tobivaudrey3	O
,	O
thomasbrox4	O
,	O
uwefranke1	O
,	O
anddanielcremers21daimlergroupresearchfirstname.lastname	O
@	O
daimler.com2universityofbonndcremers	O
@	O
cs.uni-bonn.de3universityofaucklandt.vaudrey	O
@	O
auckland.ac.nz4universityofdresdenbrox	O
@	O
inf.tu-dresden.deabstract.thispaperpresentsatechniqueforestimatingthethree-dimensionalvelocityvectorﬁeldthatdescribesthemotionofeachvisiblescenepoint	O
(	O
sceneﬂow	O
)	O
.thetechniquepresentedusestwocon-secutiveimagepairsfromastereosequence.themaincontributionistodecouplethepositionandvelocityestimationsteps	O
,	O
andtoestimatedensevelocitiesusingavariationalapproach.weenforcethesceneﬂowtoyieldconsistentdisplacementvectorsintheleftandrightimages.thedecouplingstrategyhastwomainadvantages	O
:	O
firstly	O
,	O
weareindepen-dentinchoosingadisparityestimationtechnique	O
,	O
whichcanyieldeithersparseordensecorrespondences	O
,	O
andsecondly	O
,	O
wecanachieveframeratesof5fpsonstandardconsumerhardware.theapproachprovidesdensevelocityestimateswithaccurateresultsatdistancesupto50me-ters.1introductionaveryimportantfeaturetoextractfromamovingsceneisthevelocityofvisibleobjects.inthescopeofthehumannervesystemsuchperceptionofmotionisreferredtoaskinaesthesia.themotionin3dspaceiscalledsceneﬂowandcanbedescribedbyathree-dimensionalvelocityﬁeld.fig.1.sceneﬂowexample.despitesimilardistancefromtheviewer	O
,	O
themovingcar	O
(	O
red	O
)	O
canbeclearlydistinguishedfromtheparkedvehicles	O
(	O
green	O
)	O
.d.forsyth	O
,	O
p.torr	O
,	O
anda.zisserman	O
(	O
eds	O
.	O
)	O
:	O
eccv2008	O
,	O
parti	O
,	O
lncs5302	O
,	O
pp.739–751,2008.c	O
(	O
cid:2	O
)	O
springer-verlagberlinheidelberg2008	O
564	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
(	O
h	O
)	O
figure	O
11.19	O
multi-view	B
stereo	I
algorithms	O
:	O
(	O
a	O
)	O
surface-based	O
stereo	B
(	O
fua	O
and	O
leclerc	O
1995	O
)	O
;	O
(	O
b	O
)	O
voxel	B
coloring	I
(	O
seitz	O
and	O
dyer	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
springer	O
;	O
(	O
c	O
)	O
depth	B
map	I
merg-	O
ing	O
(	O
narayanan	O
,	O
rander	O
,	O
and	O
kanade	O
1998	O
)	O
;	O
(	O
d	O
)	O
level	O
set	O
evolution	B
(	O
faugeras	O
and	O
keriven	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
ieee	O
;	O
(	O
e	O
)	O
silhouette	O
and	O
stereo	B
fusion	O
(	O
hernandez	O
and	O
schmitt	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
elsevier	O
;	O
(	O
f	O
)	O
multi-view	B
image	O
matching	B
(	O
pons	O
,	O
keriven	O
,	O
and	O
faugeras	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
;	O
(	O
g	O
)	O
volumetric	B
graph	O
cut	O
(	O
vogiatzis	O
,	O
torr	O
,	O
and	O
cipolla	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
;	O
(	O
h	O
)	O
carved	O
visual	O
hulls	O
(	O
furukawa	O
and	O
ponce	O
2009	O
)	O
c	O
(	O
cid:13	O
)	O
2009	O
springer	O
.	O
ular	O
representation	O
(	O
fua	O
and	O
leclerc	O
1995	O
;	O
narayanan	O
,	O
rander	O
,	O
and	O
kanade	O
1998	O
;	O
isidoro	O
and	O
sclaroff	O
2003	O
;	O
hernandez	O
and	O
schmitt	O
2004	O
;	O
furukawa	O
and	O
ponce	O
2009	O
;	O
hiep	O
,	O
keriven	O
,	O
pons	O
et	O
al	O
.	O
2009	O
)	O
.	O
meshes	O
are	O
the	O
standard	O
representation	O
used	O
in	O
computer	O
graphics	O
and	O
also	O
readily	O
support	O
the	O
computation	O
of	O
visibility	B
and	O
occlusions	O
.	O
finally	O
,	O
as	O
we	O
discussed	O
in	O
the	O
previous	O
section	O
,	O
multiple	B
depth	O
maps	O
can	O
also	O
be	O
used	O
(	O
szeliski	O
1999	O
;	O
kolmogorov	O
and	O
zabih	O
2002	O
;	O
kang	O
and	O
szeliski	O
2004	O
)	O
.	O
many	O
algorithms	O
also	O
use	O
more	O
than	O
a	O
single	O
represen-	O
tation	O
,	O
e.g.	O
,	O
they	O
may	O
start	O
by	O
computing	O
multiple	B
depth	O
maps	O
and	O
then	O
merge	O
them	O
into	O
a	O
3d	O
object	O
model	O
(	O
narayanan	O
,	O
rander	O
,	O
and	O
kanade	O
1998	O
;	O
furukawa	O
and	O
ponce	O
2009	O
;	O
goesele	O
,	O
curless	O
,	O
and	O
seitz	O
2006	O
;	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2007	O
;	O
furukawa	O
,	O
curless	O
,	O
seitz	O
et	O
al	O
.	O
2010	O
)	O
.	O
11.6	O
multi-view	B
stereo	I
565	O
photoconsistency	B
measure	O
.	O
as	O
we	O
discussed	O
in	O
(	O
section	O
11.3.1	O
)	O
,	O
a	O
variety	O
of	O
similarity	B
measures	O
can	O
be	O
used	O
to	O
compare	O
pixel	O
values	O
in	O
different	O
images	O
,	O
including	O
measures	O
that	O
try	O
to	O
discount	O
illumination	O
effects	O
or	O
be	O
less	O
sensitive	O
to	O
outliers	O
.	O
in	O
multi-view	B
stereo	I
,	O
algo-	O
rithms	O
have	O
a	O
choice	O
of	O
computing	O
these	O
measures	O
directly	O
on	O
the	O
surface	B
of	O
the	O
model	O
,	O
i.e.	O
,	O
in	O
scene	O
space	O
,	O
or	O
projecting	O
pixel	O
values	O
from	O
one	O
image	B
(	O
or	O
from	O
a	O
textured	O
model	O
)	O
back	O
into	O
another	O
image	B
,	O
i.e.	O
,	O
in	O
image	B
space	O
.	O
(	O
the	O
latter	O
corresponds	O
more	O
closely	O
to	O
a	O
bayesian	O
ap-	O
proach	O
,	O
since	O
input	O
images	O
are	O
noisy	O
measurements	O
of	O
the	O
colored	O
3d	O
model	O
.	O
)	O
the	O
geometry	O
of	O
the	O
object	O
,	O
i.e.	O
,	O
its	O
distance	O
to	O
each	O
camera	B
and	O
its	O
local	B
surface	O
normal	O
,	O
when	O
available	O
,	O
can	O
be	O
used	O
to	O
adjust	O
the	O
matching	B
windows	O
used	O
in	O
the	O
computation	O
to	O
account	O
for	O
foreshortening	O
and	O
scale	O
change	O
(	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2007	O
)	O
.	O
visibility	B
model	O
.	O
a	O
big	O
advantage	O
that	O
multi-view	B
stereo	I
algorithms	O
have	O
over	O
single-depth-	O
map	O
approaches	O
is	O
their	O
ability	O
to	O
reason	O
in	O
a	O
principled	O
manner	O
about	O
visibility	B
and	O
occlu-	O
sions	O
.	O
techniques	O
that	O
use	O
the	O
current	O
state	O
of	O
the	O
3d	O
model	O
to	O
predict	O
which	O
surface	B
pixels	O
are	O
visible	O
in	O
each	O
image	B
(	O
kutulakos	O
and	O
seitz	O
2000	O
;	O
faugeras	O
and	O
keriven	O
1998	O
;	O
vogiatzis	O
,	O
hernandez	O
,	O
torr	O
et	O
al	O
.	O
2007	O
;	O
hiep	O
,	O
keriven	O
,	O
pons	O
et	O
al	O
.	O
2009	O
)	O
are	O
classiﬁed	O
as	O
using	O
geometric	O
visibility	B
models	O
in	O
the	O
taxonomy	B
of	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
(	O
2006	O
)	O
.	O
techniques	O
that	O
se-	O
lect	O
a	O
neighboring	O
subset	O
of	O
image	B
to	O
match	O
are	O
called	O
quasi-geometric	O
(	O
narayanan	O
,	O
rander	O
,	O
and	O
kanade	O
1998	O
;	O
kang	O
and	O
szeliski	O
2004	O
;	O
hernandez	O
and	O
schmitt	O
2004	O
)	O
,	O
while	O
techniques	O
that	O
use	O
traditional	O
robust	B
similarity	O
measures	O
are	O
called	O
outlier-based	O
.	O
while	O
full	O
geometric	B
reasoning	O
is	O
the	O
most	O
principled	O
and	O
accurate	O
approach	O
,	O
it	O
can	O
be	O
very	O
slow	O
to	O
evaluate	O
and	O
depends	O
on	O
the	O
evolving	O
quality	O
of	O
the	O
current	O
surface	B
estimate	O
to	O
predict	O
visibility	B
,	O
which	O
can	O
be	O
a	O
bit	O
of	O
a	O
chicken-and-egg	O
problem	O
,	O
unless	O
conservative	O
assumptions	O
are	O
used	O
,	O
as	O
they	O
are	O
by	O
kutulakos	O
and	O
seitz	O
(	O
2000	O
)	O
.	O
shape	B
priors	I
.	O
because	O
stereo	B
matching	I
is	O
often	O
underconstrained	O
,	O
especially	O
in	O
texture-	O
less	O
regions	O
,	O
most	O
matching	B
algorithms	O
adopt	O
(	O
either	O
explicitly	O
or	O
implicitly	O
)	O
some	O
form	O
of	O
prior	B
model	O
for	O
the	O
expected	O
shape	O
.	O
many	O
of	O
the	O
techniques	O
that	O
rely	O
on	O
optimization	O
use	O
a	O
3d	O
smoothness	B
or	O
area-based	O
photoconsistency	B
constraint	O
,	O
which	O
,	O
because	O
of	O
the	O
natural	B
ten-	O
dency	O
of	O
smooth	O
surfaces	O
to	O
shrink	O
inwards	O
,	O
often	O
results	O
in	O
a	O
minimal	O
surface	B
prior	O
(	O
faugeras	O
and	O
keriven	O
1998	O
;	O
sinha	O
and	O
pollefeys	O
2005	O
;	O
vogiatzis	O
,	O
hernandez	O
,	O
torr	O
et	O
al	O
.	O
2007	O
)	O
.	O
ap-	O
proaches	O
that	O
carve	O
away	O
the	O
volume	O
of	O
space	O
often	O
stop	O
once	O
a	O
photoconsistent	O
solution	O
is	O
found	O
(	O
seitz	O
and	O
dyer	O
1999	O
;	O
kutulakos	O
and	O
seitz	O
2000	O
)	O
,	O
which	O
corresponds	O
to	O
a	O
maximal	O
sur-	O
face	B
bias	O
,	O
i.e.	O
,	O
these	O
techniques	O
tend	O
to	O
over-estimate	O
the	O
true	O
shape	O
.	O
finally	O
,	O
multiple	B
depth	O
map	O
approaches	O
often	O
adopt	O
traditional	O
image-based	B
smoothness	O
(	O
regularization	B
)	O
constraints	O
.	O
reconstruction	B
algorithm	I
.	O
the	O
details	O
of	O
how	O
the	O
actual	O
reconstruction	B
algorithm	I
pro-	O
ceeds	O
is	O
where	O
the	O
largest	O
variety—and	O
greatest	O
innovation—in	O
multi-view	B
stereo	I
algorithms	O
566	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
can	O
be	O
found	O
.	O
some	O
approaches	O
use	O
global	B
optimization	I
deﬁned	O
over	O
a	O
three-dimensional	O
photoconsis-	O
tency	O
volume	O
to	O
recover	O
a	O
complete	O
surface	B
.	O
approaches	O
based	O
on	O
graph	B
cuts	I
use	O
polynomial	O
complexity	O
binary	O
segmentation	O
algorithms	O
to	O
recover	O
the	O
object	O
model	O
deﬁned	O
on	O
the	O
voxel	O
grid	O
(	O
sinha	O
and	O
pollefeys	O
2005	O
;	O
vogiatzis	O
,	O
hernandez	O
,	O
torr	O
et	O
al	O
.	O
2007	O
;	O
hiep	O
,	O
keriven	O
,	O
pons	O
et	O
al	O
.	O
2009	O
)	O
.	O
level	O
set	O
approaches	O
use	O
a	O
continuous	O
surface	B
evolution	O
to	O
ﬁnd	O
a	O
good	O
mini-	O
mum	O
in	O
the	O
conﬁguration	O
space	O
of	O
potential	O
surfaces	O
and	O
therefore	O
require	O
a	O
reasonably	O
good	O
initialization	B
(	O
faugeras	O
and	O
keriven	O
1998	O
;	O
pons	O
,	O
keriven	O
,	O
and	O
faugeras	O
2007	O
)	O
.	O
in	O
order	B
for	O
the	O
photoconsistency	B
volume	O
to	O
be	O
meaningful	O
,	O
matching	B
costs	O
need	O
to	O
be	O
computed	O
in	O
some	O
robust	B
fashion	O
,	O
e.g.	O
,	O
using	O
sets	O
of	O
limited	O
views	O
or	O
by	O
aggregating	O
multiple	B
depth	O
maps	O
.	O
an	O
alternative	O
approach	O
to	O
global	B
optimization	I
is	O
to	O
sweep	O
through	O
the	O
3d	O
volume	O
while	O
computing	O
both	O
photoconsistency	B
and	O
visibility	B
simultaneously	O
.	O
the	O
voxel	B
coloring	I
algorithm	O
of	O
seitz	O
and	O
dyer	O
(	O
1999	O
)	O
performs	O
a	O
front-to-back	O
plane	B
sweep	I
.	O
on	O
every	O
plane	O
,	O
any	O
voxels	O
that	O
are	O
sufﬁciently	O
photoconsistent	O
are	O
labeled	O
as	O
part	O
of	O
the	O
object	O
.	O
the	O
corresponding	O
pixels	O
in	O
the	O
source	O
images	O
can	O
then	O
be	O
“	O
erased	O
”	O
,	O
since	O
they	O
are	O
already	O
accounted	O
for	O
,	O
and	O
therefore	O
do	O
not	O
contribute	O
to	O
further	O
photoconsistency	B
computations	O
.	O
(	O
a	O
similar	O
approach	O
,	O
albeit	O
without	O
the	O
front-to-back	O
sweep	O
order	B
,	O
is	O
used	O
by	O
szeliski	O
and	O
golland	O
(	O
1999	O
)	O
.	O
)	O
the	O
resulting	O
3d	O
volume	O
,	O
under	O
noise-	O
and	O
resampling-free	O
conditions	O
,	O
is	O
guaranteed	O
to	O
produce	O
both	O
a	O
photoconsistent	O
3d	O
model	O
and	O
to	O
enclose	O
whatever	O
true	O
3d	O
object	O
model	O
generated	O
the	O
images	O
.	O
unfortunately	O
,	O
voxel	B
coloring	I
is	O
only	O
guaranteed	O
to	O
work	O
if	O
all	O
of	O
the	O
cameras	O
lie	O
on	O
the	O
same	O
side	O
of	O
the	O
sweep	O
planes	B
,	O
which	O
is	O
not	O
possible	O
in	O
general	O
ring	O
conﬁgurations	O
of	O
cameras	O
.	O
kutulakos	O
and	O
seitz	O
(	O
2000	O
)	O
generalize	O
voxel	B
coloring	I
to	O
space	B
carving	I
,	O
where	O
subsets	O
of	O
cameras	O
that	O
satisfy	O
the	O
voxel	B
coloring	I
constraint	O
are	O
iteratively	O
selected	O
and	O
the	O
3d	O
voxel	O
grid	O
is	O
alternately	O
carved	O
away	O
along	O
different	O
axes	O
.	O
another	O
popular	O
approach	O
to	O
multi-view	B
stereo	I
is	O
to	O
ﬁrst	O
independently	O
compute	O
multiple	B
depth	O
maps	O
and	O
then	O
merge	O
these	O
partial	O
maps	O
into	O
a	O
complete	O
3d	O
model	O
.	O
approaches	O
to	O
depth	B
map	I
merging	O
,	O
which	O
are	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
12.2.1	O
,	O
include	O
signed	B
distance	O
functions	O
(	O
curless	O
and	O
levoy	O
1996	O
)	O
,	O
used	O
by	O
goesele	O
,	O
curless	O
,	O
and	O
seitz	O
(	O
2006	O
)	O
,	O
and	O
poisson	O
surface	B
reconstruction	I
(	O
kazhdan	O
,	O
bolitho	O
,	O
and	O
hoppe	O
2006	O
)	O
,	O
used	O
by	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
(	O
2007	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
reconstruct	O
sparser	O
representations	O
,	O
such	O
as	O
3d	O
points	B
and	O
lines	B
,	O
and	O
to	O
interpolate	O
them	O
to	O
full	O
3d	O
surfaces	O
(	O
section	O
12.3.1	O
)	O
(	O
taylor	O
2003	O
)	O
.	O
initialization	B
requirements	I
.	O
one	O
ﬁnal	O
element	O
discussed	O
by	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
(	O
2006	O
)	O
is	O
the	O
varying	O
degrees	O
of	O
initialization	B
required	O
by	O
different	O
algorithms	O
.	O
because	O
some	O
algorithms	O
reﬁne	O
or	O
evolve	O
a	O
rough	O
3d	O
model	O
,	O
they	O
require	O
a	O
reasonably	O
accurate	O
(	O
or	O
over-	O
complete	O
)	O
initial	O
model	O
,	O
which	O
can	O
often	O
be	O
obtained	O
by	O
reconstructing	O
a	O
volume	O
from	O
object	O
11.6	O
multi-view	B
stereo	I
567	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
figure	O
11.20	O
the	O
multi-view	B
stereo	I
data	O
sets	O
captured	O
by	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
(	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
.	O
only	O
(	O
a	O
)	O
and	O
(	O
b	O
)	O
are	O
currently	O
used	O
for	O
evaluation	O
.	O
silhouettes	B
,	O
as	O
discussed	O
in	O
section	O
11.6.2.	O
however	O
,	O
if	O
the	O
algorithm	B
performs	O
a	O
global	B
op-	O
timization	O
(	O
kolev	O
,	O
klodt	O
,	O
brox	O
et	O
al	O
.	O
2009	O
;	O
kolev	O
and	O
cremers	O
2009	O
)	O
,	O
this	O
dependence	O
on	O
initialization	B
is	O
not	O
an	O
issue	O
.	O
empirical	O
evaluation	B
.	O
in	O
order	B
to	O
evaluate	O
the	O
large	O
number	O
of	O
design	O
alternatives	O
in	O
multi-	O
view	O
stereo	O
,	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
(	O
2006	O
)	O
collected	O
a	O
dataset	O
of	O
calibrated	O
images	O
using	O
a	O
spherical	B
gantry	O
.	O
a	O
representative	O
image	B
from	O
each	O
of	O
the	O
six	O
datasets	O
is	O
shown	O
in	O
fig-	O
ure	O
11.20	O
,	O
although	O
only	O
the	O
ﬁrst	O
two	O
datasets	O
have	O
as	O
yet	O
been	O
fully	O
processed	O
and	O
used	O
for	O
evaluation	O
.	O
figure	O
11.21	O
shows	O
the	O
results	O
of	O
running	O
seven	O
different	O
algorithms	O
on	O
the	O
tem-	O
ple	O
dataset	O
.	O
as	O
you	O
can	O
see	O
,	O
most	O
of	O
the	O
techniques	O
do	O
an	O
impressive	O
job	O
of	O
capturing	O
the	O
ﬁne	O
details	O
in	O
the	O
columns	O
,	O
although	O
it	O
is	O
also	O
clear	O
that	O
the	O
techniques	O
employ	O
differing	O
amounts	O
of	O
smoothing	B
to	O
achieve	O
these	O
results	O
.	O
since	O
the	O
publication	O
of	O
the	O
survey	O
by	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
the	O
ﬁeld	O
of	O
multi-view	B
stereo	I
has	O
continued	O
to	O
advance	O
at	O
a	O
rapid	O
pace	O
(	O
strecha	O
,	O
fransens	O
,	O
and	O
van	O
gool	O
2006	O
;	O
hernandez	O
,	O
vogiatzis	O
,	O
and	O
cipolla	O
2007	O
;	O
habbecke	O
and	O
kobbelt	O
2007	O
;	O
furukawa	O
and	O
ponce	O
2007	O
;	O
vogiatzis	O
,	O
hernandez	O
,	O
torr	O
et	O
al	O
.	O
2007	O
;	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2007	O
;	O
sinha	O
,	O
mordohai	O
,	O
and	O
pollefeys	O
2007	O
;	O
gargallo	O
,	O
prados	O
,	O
and	O
sturm	O
2007	O
;	O
merrell	O
,	O
ak-	O
barzadeh	O
,	O
wang	O
et	O
al	O
.	O
2007	O
;	O
zach	O
,	O
pock	O
,	O
and	O
bischof	O
2007b	O
;	O
furukawa	O
and	O
ponce	O
2008	O
;	O
hornung	O
,	O
zeng	O
,	O
and	O
kobbelt	O
2008	O
;	O
bradley	O
,	O
boubekeur	O
,	O
and	O
heidrich	O
2008	O
;	O
zach	O
2008	O
;	O
campbell	O
,	O
vogiatzis	O
,	O
hern´andez	O
et	O
al	O
.	O
2008	O
;	O
kolev	O
,	O
klodt	O
,	O
brox	O
et	O
al	O
.	O
2009	O
;	O
hiep	O
,	O
keriven	O
,	O
pons	O
et	O
al	O
.	O
2009	O
;	O
furukawa	O
,	O
curless	O
,	O
seitz	O
et	O
al	O
.	O
2010	O
)	O
.	O
the	O
multi-view	B
stereo	I
evaluation	O
site	O
,	O
http	O
:	O
//vision.middlebury.edu/mview/	O
,	O
provides	O
quantitative	O
results	O
for	O
these	O
algorithms	O
along	O
with	O
pointers	O
to	O
where	O
to	O
ﬁnd	O
these	O
papers	O
.	O
11.6.2	O
shape	O
from	O
silhouettes	B
in	O
many	O
situations	O
,	O
performing	O
a	O
foreground–background	O
segmentation	B
of	O
the	O
object	O
of	O
in-	O
terest	O
is	O
a	O
good	O
way	O
to	O
initialize	O
or	O
ﬁt	O
a	O
3d	O
model	O
(	O
grauman	O
,	O
shakhnarovich	O
,	O
and	O
darrell	O
568	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
11.21	O
reconstruction	O
results	O
(	O
details	O
)	O
for	O
seven	O
algorithms	O
(	O
hernandez	O
and	O
schmitt	O
2004	O
;	O
furukawa	O
and	O
ponce	O
2009	O
;	O
pons	O
,	O
keriven	O
,	O
and	O
faugeras	O
2005	O
;	O
goesele	O
,	O
curless	O
,	O
and	O
seitz	O
2006	O
;	O
vogiatzis	O
,	O
torr	O
,	O
and	O
cipolla	O
2005	O
;	O
tran	O
and	O
davis	O
2002	O
;	O
kolmogorov	O
and	O
zabih	O
2002	O
)	O
evaluated	O
by	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
(	O
2006	O
)	O
on	O
the	O
47-image	O
temple	O
ring	O
dataset	O
.	O
the	O
numbers	O
underneath	O
each	O
detail	O
image	B
are	O
the	O
accuracy	B
of	O
each	O
of	O
these	O
techniques	O
mea-	O
sured	O
in	O
millimeters	O
.	O
2003	O
;	O
vlasic	O
,	O
baran	O
,	O
matusik	O
et	O
al	O
.	O
2008	O
)	O
or	O
to	O
impose	O
a	O
convex	O
set	O
of	O
constraints	O
on	O
multi-	O
view	O
stereo	O
(	O
kolev	O
and	O
cremers	O
2008	O
)	O
.	O
over	O
the	O
years	O
,	O
a	O
number	O
of	O
techniques	O
have	O
been	O
developed	O
to	O
reconstruct	O
a	O
3d	O
volumetric	B
model	O
from	O
the	O
intersection	O
of	O
the	O
binary	O
silhou-	O
ettes	O
projected	O
into	O
3d	O
.	O
the	O
resulting	O
model	O
is	O
called	O
a	O
visual	B
hull	I
(	O
or	O
sometimes	O
a	O
line	O
hull	O
)	O
,	O
analogous	O
with	O
the	O
convex	O
hull	O
of	O
a	O
set	O
of	O
points	B
,	O
since	O
the	O
volume	O
is	O
maximal	O
with	O
respect	O
to	O
the	O
visual	O
silhouettes	O
and	O
surface	B
elements	O
are	O
tangent	O
to	O
the	O
viewing	O
rays	O
(	O
lines	B
)	O
along	O
the	O
silhouette	O
boundaries	O
(	O
laurentini	O
1994	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
carve	O
away	O
a	O
more	O
accu-	O
rate	O
reconstruction	O
using	O
multi-view	B
stereo	I
(	O
sinha	O
and	O
pollefeys	O
2005	O
)	O
or	O
by	O
analyzing	O
cast	O
shadows	O
(	O
savarese	O
,	O
andreetto	O
,	O
rushmeier	O
et	O
al	O
.	O
2007	O
)	O
.	O
some	O
techniques	O
ﬁrst	O
approximate	O
each	O
silhouette	O
with	O
a	O
polygonal	O
representation	O
and	O
then	O
intersect	O
the	O
resulting	O
faceted	O
conical	O
regions	O
in	O
three-space	O
to	O
produce	O
polyhedral	O
mod-	O
els	O
(	O
baumgart	O
1974	O
;	O
martin	O
and	O
aggarwal	O
1983	O
;	O
matusik	O
,	O
buehler	O
,	O
and	O
mcmillan	O
2001	O
)	O
,	O
which	O
can	O
later	O
be	O
reﬁned	O
using	O
triangular	O
splines	B
(	O
sullivan	O
and	O
ponce	O
1998	O
)	O
.	O
other	O
ap-	O
proaches	O
use	O
voxel-based	O
representations	O
,	O
usually	O
encoded	O
as	O
octrees	O
(	O
samet	O
1989	O
)	O
,	O
because	O
of	O
the	O
resulting	O
space–time	O
efﬁciency	B
.	O
figures	O
11.22a–b	O
show	O
an	O
example	O
of	O
a	O
3d	O
octree	B
model	O
and	O
its	O
associated	O
colored	O
tree	O
,	O
where	O
black	O
nodes	O
are	O
interior	O
to	O
the	O
model	O
,	O
white	O
11.6	O
multi-view	B
stereo	I
569	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
11.22	O
volumetric	B
octree	O
reconstruction	O
from	O
binary	O
silhouettes	O
(	O
szeliski	O
1993	O
)	O
c	O
(	O
cid:13	O
)	O
1993	O
elsevier	O
:	O
(	O
a	O
)	O
octree	B
representation	O
and	O
its	O
corresponding	O
(	O
b	O
)	O
tree	O
structure	O
;	O
(	O
c	O
)	O
input	O
image	B
of	O
an	O
object	O
on	O
a	O
turntable	O
;	O
(	O
d	O
)	O
computed	O
3d	O
volumetric	B
octree	O
model	O
.	O
nodes	O
are	O
exterior	O
,	O
and	O
gray	O
nodes	O
are	O
of	O
mixed	O
occupancy	O
.	O
examples	B
of	O
octree-based	O
re-	O
construction	O
approaches	O
include	O
those	O
by	O
potmesil	O
(	O
1987	O
)	O
,	O
noborio	O
,	O
fukada	O
,	O
and	O
arimoto	O
(	O
1988	O
)	O
,	O
srivasan	O
,	O
liang	O
,	O
and	O
hackwood	O
(	O
1990	O
)	O
,	O
and	O
szeliski	O
(	O
1993	O
)	O
.	O
the	O
approach	O
of	O
szeliski	O
(	O
1993	O
)	O
ﬁrst	O
converts	O
each	O
binary	O
silhouette	O
into	O
a	O
one-sided	O
variant	O
of	O
a	O
distance	O
map	O
,	O
where	O
each	O
pixel	O
in	O
the	O
map	O
indicates	O
the	O
largest	O
square	O
that	O
is	O
completely	O
inside	O
(	O
or	O
outside	O
)	O
the	O
silhouette	O
.	O
this	O
makes	O
it	O
fast	O
to	O
project	O
an	O
octree	B
cell	O
into	O
the	O
silhouette	O
to	O
conﬁrm	O
whether	O
it	O
is	O
completely	O
inside	O
or	O
outside	O
the	O
object	O
,	O
so	O
that	O
it	O
can	O
be	O
colored	O
black	O
,	O
white	O
,	O
or	O
left	O
as	O
gray	O
(	O
mixed	O
)	O
for	O
further	O
reﬁnement	O
on	O
a	O
smaller	O
grid	O
.	O
the	O
octree	B
construction	O
algorithm	B
proceeds	O
in	O
a	O
coarse-to-ﬁne	B
manner	O
,	O
ﬁrst	O
building	O
an	O
octree	B
at	O
a	O
relatively	O
coarse	O
resolution	O
,	O
and	O
then	O
reﬁning	O
it	O
by	O
revisiting	O
and	O
subdividing	O
all	O
the	O
input	O
images	O
for	O
the	O
gray	O
(	O
mixed	O
)	O
cells	O
whose	O
occupancy	O
has	O
not	O
yet	O
been	O
determined	O
.	O
figure	O
11.22d	O
shows	O
the	O
resulting	O
octree	B
model	O
computed	O
from	O
a	O
coffee	O
cup	O
rotating	O
on	O
a	O
turntable	O
.	O
more	O
recent	O
work	O
on	O
visual	B
hull	I
computation	O
borrows	O
ideas	O
from	O
image-based	B
rendering	I
,	O
and	O
is	O
hence	O
called	O
an	O
image-based	B
visual	O
hull	O
(	O
matusik	O
,	O
buehler	O
,	O
raskar	O
et	O
al	O
.	O
2000	O
)	O
.	O
instead	O
of	O
precomputing	O
a	O
global	B
3d	O
model	O
,	O
an	O
image-based	B
visual	O
hull	O
is	O
recomputed	O
for	O
each	O
new	O
570	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
viewpoint	O
,	O
by	O
successively	O
intersecting	O
viewing	O
ray	O
segments	O
with	O
the	O
binary	O
silhouettes	O
in	O
each	O
image	B
.	O
this	O
not	O
only	O
leads	O
to	O
a	O
fast	O
computation	O
algorithm	B
but	O
also	O
enables	O
fast	O
texturing	O
of	O
the	O
recovered	O
model	O
with	O
color	O
values	O
from	O
the	O
input	O
images	O
.	O
this	O
approach	O
can	O
also	O
be	O
combined	O
with	O
high-quality	O
deformable	O
templates	O
to	O
capture	O
and	O
re-animate	O
whole	O
body	B
motion	O
(	O
vlasic	O
,	O
baran	O
,	O
matusik	O
et	O
al	O
.	O
2008	O
)	O
.	O
11.7	O
additional	O
reading	O
the	O
ﬁeld	O
of	O
stereo	B
correspondence	O
and	O
depth	O
estimation	O
is	O
one	O
of	O
the	O
oldest	O
and	O
most	O
widely	O
studied	O
topics	O
in	O
computer	O
vision	O
.	O
a	O
number	O
of	O
good	O
surveys	B
have	O
been	O
written	O
over	O
the	O
years	O
(	O
marr	O
and	O
poggio	O
1976	O
;	O
barnard	O
and	O
fischler	O
1982	O
;	O
dhond	O
and	O
aggarwal	O
1989	O
;	O
scharstein	O
and	O
szeliski	O
2002	O
;	O
brown	O
,	O
burschka	O
,	O
and	O
hager	O
2003	O
;	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
2006	O
)	O
and	O
they	O
can	O
serve	O
as	O
good	O
guides	O
to	O
this	O
extensive	O
literature	O
.	O
because	O
of	O
computational	O
limitations	O
and	O
the	O
desire	O
to	O
ﬁnd	O
appearance-invariant	O
cor-	O
respondences	O
,	O
early	O
algorithms	O
often	O
focused	O
on	O
ﬁnding	O
sparse	B
correspondences	O
(	O
hannah	O
1974	O
;	O
marr	O
and	O
poggio	O
1979	O
;	O
mayhew	O
and	O
frisby	O
1980	O
;	O
baker	O
and	O
binford	O
1981	O
;	O
arnold	O
1983	O
;	O
grimson	O
1985	O
;	O
ohta	O
and	O
kanade	O
1985	O
;	O
bolles	O
,	O
baker	O
,	O
and	O
marimont	O
1987	O
;	O
matthies	O
,	O
kanade	O
,	O
and	O
szeliski	O
1989	O
;	O
hsieh	O
,	O
mckeown	O
,	O
and	O
perlant	O
1992	O
;	O
bolles	O
,	O
baker	O
,	O
and	O
hannah	O
1993	O
)	O
.	O
the	O
topic	O
of	O
computing	O
epipolar	B
geometry	I
and	O
pre-rectifying	O
images	O
is	O
covered	O
in	O
sec-	O
tions	O
7.2	O
and	O
11.1	O
and	O
is	O
also	O
treated	O
in	O
textbooks	B
on	O
multi-view	B
geometry	O
(	O
faugeras	O
and	O
luong	O
2001	O
;	O
hartley	O
and	O
zisserman	O
2004	O
)	O
and	O
articles	O
speciﬁcally	O
on	O
this	O
topic	O
(	O
torr	O
and	O
murray	O
1997	O
;	O
zhang	O
1998a	O
,	O
b	O
)	O
.	O
the	O
concepts	O
of	O
the	O
disparity	O
space	O
and	O
disparity	O
space	O
im-	O
age	O
are	O
often	O
associated	O
with	O
the	O
seminal	O
work	O
by	O
marr	O
(	O
1982	O
)	O
and	O
the	O
papers	O
of	O
yang	O
,	O
yuille	O
,	O
and	O
lu	O
(	O
1993	O
)	O
and	O
intille	O
and	O
bobick	O
(	O
1994	O
)	O
.	O
the	O
plane	B
sweep	I
algorithm	O
was	O
ﬁrst	O
popular-	O
ized	O
by	O
collins	O
(	O
1996	O
)	O
and	O
then	O
generalized	B
to	O
a	O
full	O
arbitrary	O
projective	B
setting	O
by	O
szeliski	O
and	O
golland	O
(	O
1999	O
)	O
and	O
saito	O
and	O
kanade	O
(	O
1999	O
)	O
.	O
plane	O
sweeps	O
can	O
also	O
be	O
formulated	O
using	O
cylindrical	O
surfaces	O
(	O
ishiguro	O
,	O
yamamoto	O
,	O
and	O
tsuji	O
1992	O
;	O
kang	O
and	O
szeliski	O
1997	O
;	O
shum	O
and	O
szeliski	O
1999	O
;	O
li	O
,	O
shum	O
,	O
tang	O
et	O
al	O
.	O
2004	O
;	O
zheng	O
,	O
kang	O
,	O
cohen	O
et	O
al	O
.	O
2007	O
)	O
or	O
even	O
more	O
general	O
topologies	O
(	O
seitz	O
2001	O
)	O
.	O
once	O
the	O
topology	O
for	O
the	O
cost	O
volume	O
or	O
dsi	O
has	O
been	O
set	O
up	O
,	O
we	O
need	O
to	O
compute	O
the	O
actual	O
photoconsistency	B
measures	O
for	O
each	O
pixel	O
and	O
potential	O
depth	O
.	O
a	O
wide	O
range	O
of	O
such	O
measures	O
have	O
been	O
proposed	O
,	O
as	O
discussed	O
in	O
section	O
11.3.1.	O
some	O
of	O
these	O
are	O
compared	O
in	O
recent	O
surveys	B
and	O
evaluations	O
of	O
matching	B
costs	O
(	O
scharstein	O
and	O
szeliski	O
2002	O
;	O
hirschm¨uller	O
and	O
scharstein	O
2009	O
)	O
.	O
to	O
compute	O
an	O
actual	O
depth	B
map	I
from	O
these	O
costs	O
,	O
some	O
form	O
of	O
optimization	O
or	O
selection	O
criterion	O
must	O
be	O
used	O
.	O
the	O
simplest	O
of	O
these	O
are	O
sliding	O
windows	O
of	O
various	O
kinds	O
,	O
which	O
11.8	O
exercises	O
571	O
are	O
discussed	O
in	O
section	O
11.4	O
and	O
surveyed	O
by	O
gong	O
,	O
yang	O
,	O
wang	O
et	O
al	O
.	O
(	O
2007	O
)	O
and	O
tombari	O
,	O
mattoccia	O
,	O
di	O
stefano	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
more	O
commonly	O
,	O
global	B
optimization	I
frameworks	O
are	O
used	O
to	O
compute	O
the	O
best	O
disparity	O
ﬁeld	O
,	O
as	O
described	O
in	O
section	O
11.5.	O
these	O
techniques	O
include	O
dynamic	B
programming	I
and	O
truly	O
global	B
optimization	I
algorithms	O
,	O
such	O
as	O
graph	B
cuts	I
and	O
loopy	B
belief	I
propagation	I
.	O
because	O
the	O
literature	O
on	O
this	O
is	O
so	O
extensive	O
,	O
it	O
is	O
described	O
in	O
more	O
detail	O
in	O
section	O
11.5.	O
a	O
good	O
place	O
to	O
ﬁnd	O
pointers	O
to	O
the	O
latest	O
results	O
in	O
this	O
ﬁeld	O
is	O
the	O
middlebury	O
stereo	B
vision	O
page	O
at	O
http	O
:	O
//vision.middlebury.edu/stereo	O
.	O
algorithms	O
for	O
multi-view	O
stereo	B
typically	O
fall	O
into	O
two	O
categories	O
.	O
the	O
ﬁrst	O
include	O
al-	O
gorithms	O
that	O
compute	O
traditional	O
depth	O
maps	O
using	O
several	O
images	O
for	O
computing	O
photocon-	O
sistency	O
measures	O
(	O
okutomi	O
and	O
kanade	O
1993	O
;	O
kang	O
,	O
webb	O
,	O
zitnick	O
et	O
al	O
.	O
1995	O
;	O
nakamura	O
,	O
matsuura	O
,	O
satoh	O
et	O
al	O
.	O
1996	O
;	O
szeliski	O
and	O
golland	O
1999	O
;	O
kang	O
,	O
szeliski	O
,	O
and	O
chai	O
2001	O
;	O
vaish	O
,	O
szeliski	O
,	O
zitnick	O
et	O
al	O
.	O
2006	O
;	O
gallup	O
,	O
frahm	O
,	O
mordohai	O
et	O
al	O
.	O
2008	O
)	O
.	O
optionally	O
,	O
some	O
of	O
these	O
techniques	O
compute	O
multiple	B
depth	O
maps	O
and	O
use	O
additional	O
constraints	O
to	O
encourage	O
the	O
different	O
depth	O
maps	O
to	O
be	O
consistent	O
(	O
szeliski	O
1999	O
;	O
kolmogorov	O
and	O
zabih	O
2002	O
;	O
kang	O
and	O
szeliski	O
2004	O
;	O
maitre	O
,	O
shinagawa	O
,	O
and	O
do	O
2008	O
;	O
zhang	O
,	O
jia	O
,	O
wong	O
et	O
al	O
.	O
2008	O
)	O
.	O
the	O
second	O
category	O
consists	O
of	O
papers	O
that	O
compute	O
true	O
3d	O
volumetric	B
or	O
surface-based	O
object	O
models	O
.	O
again	O
,	O
because	O
of	O
the	O
large	O
number	O
of	O
papers	O
published	O
on	O
this	O
topic	O
,	O
rather	O
than	O
citing	O
them	O
here	O
,	O
we	O
refer	O
you	O
to	O
the	O
material	O
in	O
section	O
11.6.1	O
,	O
the	O
survey	O
by	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
and	O
the	O
on-line	O
evaluation	B
web	O
site	O
at	O
http	O
:	O
//vision.middlebury	O
.	O
edu/mview/	O
.	O
11.8	O
exercises	O
ex	O
11.1	O
:	O
stereo	B
pair	O
rectiﬁcation	B
implement	O
the	O
following	O
simple	O
algorithm	B
(	O
section	O
11.1.1	O
)	O
:	O
1.	O
rotate	O
both	O
cameras	O
so	O
that	O
they	O
are	O
looking	O
perpendicular	O
to	O
the	O
line	O
joining	O
the	O
two	O
camera	O
centers	O
c0	O
and	O
c1	O
.	O
the	O
smallest	O
rotation	O
can	O
be	O
computed	O
from	O
the	O
cross	O
prod-	O
uct	O
between	O
the	O
original	O
and	O
desired	O
optical	O
axes	O
.	O
2.	O
twist	B
the	O
optical	O
axes	O
so	O
that	O
the	O
horizontal	O
axis	O
of	O
each	O
camera	B
looks	O
in	O
the	O
direction	O
of	O
the	O
other	O
camera	B
.	O
(	O
again	O
,	O
the	O
cross	O
product	O
between	O
the	O
current	O
x-axis	O
after	O
the	O
ﬁrst	O
rotation	O
and	O
the	O
line	O
joining	O
the	O
cameras	O
gives	O
the	O
rotation	O
.	O
)	O
3.	O
if	O
needed	O
,	O
scale	O
up	O
the	O
smaller	O
(	O
less	O
detailed	O
)	O
image	B
so	O
that	O
it	O
has	O
the	O
same	O
resolution	O
(	O
and	O
hence	O
line-to-line	O
correspondence	B
)	O
as	O
the	O
other	O
image	B
.	O
now	O
compare	O
your	O
results	O
to	O
the	O
algorithm	B
proposed	O
by	O
loop	O
and	O
zhang	O
(	O
1999	O
)	O
.	O
can	O
you	O
think	O
of	O
situations	O
where	O
their	O
approach	O
may	O
be	O
preferable	O
?	O
572	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ex	O
11.2	O
:	O
rigid	O
direct	O
alignment	B
modify	O
your	O
spline-based	B
or	O
optical	B
ﬂow	I
motion	O
estima-	O
tor	O
from	O
exercise	O
8.4	O
to	O
use	O
epipolar	B
geometry	I
,	O
i.e	O
.	O
to	O
only	O
estimate	O
disparity	O
.	O
(	O
optional	O
)	O
extend	O
your	O
algorithm	B
to	O
simultaneously	O
estimate	O
the	O
epipolar	B
geometry	I
(	O
with-	O
out	O
ﬁrst	O
using	O
point	O
correspondences	O
)	O
by	O
estimating	O
a	O
base	O
homography	B
corresponding	O
to	O
a	O
reference	O
plane	O
for	O
the	O
dominant	O
motion	B
and	O
then	O
an	O
epipole	O
for	O
the	O
residual	O
parallax	O
(	O
mo-	O
tion	B
)	O
.	O
ex	O
11.3	O
:	O
shape	O
from	O
proﬁles	B
reconstruct	O
a	O
surface	B
model	O
from	O
a	O
series	O
of	O
edge	O
images	O
(	O
section	O
11.2.1	O
)	O
.	O
1.	O
extract	O
edges	O
and	O
link	O
them	O
(	O
exercises	O
4.7–4.8	O
)	O
.	O
2.	O
based	O
on	O
previously	O
computed	O
epipolar	B
geometry	I
,	O
match	O
up	O
edges	O
in	O
triplets	O
(	O
or	O
longer	O
sets	O
)	O
of	O
images	O
.	O
3.	O
reconstruct	O
the	O
3d	O
locations	O
of	O
the	O
curves	O
using	O
osculating	O
circles	O
(	O
11.5	O
)	O
.	O
4.	O
render	O
the	O
resulting	O
3d	O
surface	B
model	O
as	O
a	O
sparse	B
mesh	O
,	O
i.e.	O
,	O
drawing	O
the	O
reconstructed	O
3d	O
proﬁle	B
curves	O
and	O
links	O
between	O
3d	O
points	B
in	O
neighboring	O
images	O
with	O
similar	O
osculating	O
circles	O
.	O
ex	O
11.4	O
:	O
plane	B
sweep	I
implement	O
a	O
plane	B
sweep	I
algorithm	O
(	O
section	O
11.1.2	O
)	O
.	O
if	O
the	O
images	O
are	O
already	O
pre-rectiﬁed	O
,	O
this	O
consists	O
simply	O
of	O
shifting	O
images	O
relative	O
to	O
each	O
other	O
and	O
comparing	O
pixels	O
.	O
if	O
the	O
images	O
are	O
not	O
pre-rectiﬁed	O
,	O
compute	O
the	O
homography	B
that	O
resamples	O
the	O
target	O
image	B
into	O
the	O
reference	O
image	B
’	O
s	O
coordinate	O
system	O
for	O
each	O
plane	O
.	O
evaluate	O
a	O
subset	O
of	O
the	O
following	O
similarity	B
measures	O
(	O
section	O
11.3.1	O
)	O
and	O
compare	O
their	O
performance	O
by	O
visualizing	O
the	O
disparity	O
space	O
image	O
(	O
dsi	O
)	O
,	O
which	O
should	O
be	O
dark	O
for	O
pixels	O
at	O
correct	O
depths	O
:	O
•	O
squared	O
difference	B
(	O
sd	O
)	O
;	O
•	O
absolute	O
difference	O
(	O
ad	O
)	O
;	O
•	O
truncated	O
or	O
robust	B
measures	O
;	O
•	O
gradient	O
differences	O
;	O
•	O
rank	O
or	O
census	O
transform	B
(	O
the	O
latter	O
usually	O
performs	O
better	O
)	O
;	O
•	O
mutual	O
information	O
from	O
a	O
pre-computed	O
joint	B
density	O
function	O
.	O
consider	O
using	O
the	O
birchﬁeld	O
and	O
tomasi	O
(	O
1998	O
)	O
technique	O
of	O
comparing	O
ranges	O
between	O
neighboring	O
pixels	O
(	O
different	O
shifted	O
or	O
warped	O
images	O
)	O
.	O
also	O
,	O
try	O
pre-compensating	O
images	O
for	O
bias	O
or	O
gain	O
variations	O
using	O
one	O
or	O
more	O
of	O
the	O
techniques	O
discussed	O
in	O
section	O
11.3.1	O
.	O
11.8	O
exercises	O
573	O
ex	O
11.5	O
:	O
aggregation	O
and	O
window-based	B
stereo	O
implement	O
one	O
or	O
more	O
of	O
the	O
matching	B
cost	O
aggregation	O
strategies	O
described	O
in	O
section	O
11.4	O
:	O
•	O
convolution	O
with	O
a	O
box	O
or	O
gaussian	O
kernel	B
;	O
•	O
shifting	O
window	O
locations	O
by	O
applying	O
a	O
min	O
ﬁlter	O
(	O
scharstein	O
and	O
szeliski	O
2002	O
)	O
;	O
•	O
picking	O
a	O
window	O
that	O
maximizes	O
some	O
match-reliability	O
metric	O
(	O
veksler	O
2001	O
,	O
2003	O
)	O
;	O
•	O
weighting	B
pixels	O
by	O
their	O
similarity	B
to	O
the	O
central	O
pixel	O
(	O
yoon	O
and	O
kweon	O
2006	O
)	O
.	O
once	O
you	O
have	O
aggregated	O
the	O
costs	O
in	O
the	O
dsi	O
,	O
pick	O
the	O
winner	O
at	O
each	O
pixel	O
(	O
winner-take-	O
all	O
)	O
,	O
and	O
then	O
optionally	O
perform	O
one	O
or	O
more	O
of	O
the	O
following	O
post-processing	O
steps	O
:	O
1.	O
compute	O
matches	O
both	O
ways	O
and	O
pick	O
only	O
the	O
reliable	O
matches	O
(	O
draw	O
the	O
others	O
in	O
another	O
color	B
)	O
;	O
2.	O
tag	O
matches	O
that	O
are	O
unsure	O
(	O
whose	O
conﬁdence	O
is	O
too	O
low	O
)	O
;	O
3.	O
ﬁll	O
in	O
the	O
matches	O
that	O
are	O
unsure	O
from	O
neighboring	O
values	O
;	O
4.	O
reﬁne	O
your	O
matches	O
to	O
sub-pixel	O
disparity	O
by	O
either	O
ﬁtting	O
a	O
parabola	O
to	O
the	O
dsi	O
values	O
around	O
the	O
winner	O
or	O
by	O
using	O
an	O
iteration	O
of	O
lukas–kanade	O
.	O
ex	O
11.6	O
:	O
optimization-based	B
stereo	O
compute	O
the	O
disparity	O
space	O
image	O
(	O
dsi	O
)	O
volume	O
us-	O
ing	O
one	O
of	O
the	O
techniques	O
you	O
implemented	O
in	O
exercise	O
11.4	O
and	O
then	O
implement	O
one	O
(	O
or	O
more	O
)	O
of	O
the	O
global	B
optimization	I
techniques	O
described	O
in	O
section	O
11.5	O
to	O
compute	O
the	O
depth	B
map	I
.	O
potential	O
choices	O
include	O
:	O
•	O
dynamic	B
programming	I
or	O
scanline	B
optimization	I
(	O
relatively	O
easy	O
)	O
;	O
•	O
semi-global	B
optimization	I
(	O
hirschm¨uller	O
2008	O
)	O
,	O
which	O
is	O
a	O
simple	O
extension	O
of	O
scanline	B
optimization	I
and	O
performs	O
well	O
;	O
•	O
graph	B
cuts	I
using	O
alpha	O
expansions	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
,	O
for	O
which	O
you	O
will	O
need	O
to	O
ﬁnd	O
a	O
max-ﬂow	O
or	O
min-cut	O
algorithm	B
(	O
http	O
:	O
//vision.middlebury.edu/stereo	O
)	O
;	O
•	O
loopy	B
belief	I
propagation	I
(	O
appendix	O
b.5.3	O
)	O
.	O
evaluate	O
your	O
algorithm	B
by	O
running	O
it	O
on	O
the	O
middlebury	O
stereo	B
data	O
sets	O
.	O
how	O
well	O
does	O
your	O
algorithm	B
do	O
against	O
local	B
aggregation	O
(	O
yoon	O
and	O
kweon	O
2006	O
)	O
?	O
can	O
you	O
think	O
of	O
some	O
extensions	O
or	O
modiﬁcations	O
to	O
make	O
it	O
even	O
better	O
?	O
574	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ex	O
11.7	O
:	O
view	B
interpolation	I
,	O
revisited	O
compute	O
a	O
dense	O
depth	O
map	O
using	O
one	O
of	O
the	O
tech-	O
niques	O
you	O
developed	O
above	O
and	O
use	O
it	O
(	O
or	O
,	O
better	O
yet	O
,	O
a	O
depth	B
map	I
for	O
each	O
source	O
image	B
)	O
to	O
generate	O
smooth	O
in-between	O
views	O
from	O
a	O
stereo	B
data	O
set	O
.	O
compare	O
your	O
results	O
against	O
using	O
the	O
ground	O
truth	O
depth	O
data	O
(	O
if	O
available	O
)	O
.	O
what	O
kinds	O
of	O
artifacts	O
do	O
you	O
see	O
?	O
can	O
you	O
think	O
of	O
ways	O
to	O
reduce	O
them	O
?	O
more	O
details	O
on	O
implementing	O
such	O
algorithms	O
can	O
be	O
found	O
in	O
section	O
13.1	O
and	O
exercises	O
13.1–13.4	O
.	O
ex	O
11.8	O
:	O
multi-frame	B
stereo	O
extend	O
one	O
of	O
your	O
previous	O
techniques	O
to	O
use	O
multiple	B
input	O
frames	O
(	O
section	O
11.6	O
)	O
and	O
try	O
to	O
improve	O
the	O
results	O
you	O
obtained	O
with	O
just	O
two	O
views	O
.	O
if	O
helpful	O
,	O
try	O
using	O
temporal	O
selection	O
(	O
kang	O
and	O
szeliski	O
2004	O
)	O
to	O
deal	O
with	O
the	O
increased	O
number	O
of	O
occlusions	O
in	O
multi-frame	B
data	O
sets	O
.	O
you	O
can	O
also	O
try	O
to	O
simultaneously	O
estimate	O
multiple	B
depth	O
maps	O
and	O
make	O
them	O
consis-	O
tent	O
(	O
kolmogorov	O
and	O
zabih	O
2002	O
;	O
kang	O
and	O
szeliski	O
2004	O
)	O
.	O
test	O
your	O
algorithms	O
out	O
on	O
some	O
standard	O
multi-view	O
data	B
sets	I
.	O
ex	O
11.9	O
:	O
volumetric	B
stereo	O
implement	O
voxel	B
coloring	I
(	O
seitz	O
and	O
dyer	O
1999	O
)	O
as	O
a	O
simple	O
extension	O
to	O
the	O
plane	B
sweep	I
algorithm	O
you	O
implemented	O
in	O
exercise	O
11.4	O
.	O
1.	O
instead	O
of	O
computing	O
the	O
complete	O
dsi	O
all	O
at	O
once	O
,	O
evaluate	O
each	O
plane	O
one	O
at	O
a	O
time	O
from	O
front	O
to	O
back	O
.	O
2.	O
tag	O
every	O
voxel	O
whose	O
photoconsistency	B
is	O
below	O
a	O
certain	O
threshold	O
as	O
being	O
part	O
of	O
the	O
object	O
and	O
remember	O
its	O
average	O
(	O
or	O
robust	B
)	O
color	B
(	O
seitz	O
and	O
dyer	O
1999	O
;	O
eisert	O
,	O
steinbach	O
,	O
and	O
girod	O
2000	O
;	O
kutulakos	O
2000	O
;	O
slabaugh	O
,	O
culbertson	O
,	O
slabaugh	O
et	O
al	O
.	O
2004	O
)	O
.	O
3.	O
erase	O
the	O
input	O
pixels	O
corresponding	O
to	O
tagged	O
voxels	O
in	O
the	O
input	O
images	O
,	O
e.g.	O
,	O
by	O
setting	O
their	O
alpha	O
value	O
to	O
0	O
(	O
or	O
to	O
some	O
reduced	O
number	O
,	O
depending	O
on	O
occupancy	O
)	O
.	O
4.	O
as	O
you	O
evaluate	O
the	O
next	O
plane	O
,	O
use	O
the	O
source	O
image	B
alpha	O
values	O
to	O
modify	O
your	O
photoconsistency	B
score	O
,	O
e.g.	O
,	O
only	O
consider	O
pixels	O
that	O
have	O
full	O
alpha	O
or	O
weight	O
pixels	O
by	O
their	O
alpha	O
values	O
.	O
5.	O
if	O
the	O
cameras	O
are	O
not	O
all	O
on	O
the	O
same	O
side	O
of	O
your	O
plane	O
sweeps	O
,	O
use	O
space	B
carving	I
(	O
kutulakos	O
and	O
seitz	O
2000	O
)	O
to	O
cycle	O
through	O
different	O
subsets	O
of	O
source	O
images	O
while	O
carving	O
away	O
the	O
volume	O
from	O
different	O
directions	O
.	O
ex	O
11.10	O
:	O
depth	B
map	I
merging	O
use	O
the	O
technique	O
you	O
developed	O
for	O
multi-frame	O
stereo	B
in	O
exercise	O
11.8	O
or	O
a	O
different	O
technique	O
,	O
such	O
as	O
the	O
one	O
described	O
by	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
(	O
2007	O
)	O
,	O
to	O
compute	O
a	O
depth	B
map	I
for	O
every	O
input	O
image	B
.	O
11.8	O
exercises	O
575	O
merge	O
these	O
depth	O
maps	O
into	O
a	O
coherent	O
3d	O
model	O
,	O
e.g.	O
,	O
using	O
poisson	O
surface	B
reconstruc-	O
tion	B
(	O
kazhdan	O
,	O
bolitho	O
,	O
and	O
hoppe	O
2006	O
)	O
.	O
ex	O
11.11	O
:	O
shape	O
from	O
silhouettes	B
build	O
a	O
silhouette-based	O
volume	O
reconstruction	O
algo-	O
rithm	O
(	O
section	O
11.6.2	O
)	O
.	O
use	O
an	O
octree	B
or	O
some	O
other	O
representation	O
of	O
your	O
choosing	O
.	O
576	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
chapter	O
12	O
3d	O
reconstruction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.1	O
shape	O
from	O
x	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.2	O
active	O
rangeﬁnding	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.2.1	O
range	O
data	O
merging	B
.	O
12.2.2	O
application	O
:	O
digital	B
heritage	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.3.1	O
surface	B
interpolation	O
.	O
.	O
12.3.2	O
surface	B
simpliﬁcation	O
.	O
.	O
12.3.3	O
geometry	O
images	O
.	O
.	O
.	O
.	O
12.4	O
point-based	B
representations	O
.	O
12.5	O
volumetric	B
representations	O
.	O
12.3	O
surface	B
representations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.1.1	O
shape	O
from	O
shading	B
and	O
photometric	B
stereo	I
.	O
12.1.2	O
shape	O
from	O
texture	B
.	O
.	O
.	O
.	O
12.1.3	O
shape	O
from	O
focus	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.5.1	O
implicit	O
surfaces	O
and	O
level	B
sets	I
.	O
.	O
.	O
.	O
.	O
12.6.1	O
architecture	B
.	O
.	O
.	O
.	O
12.6.2	O
heads	B
and	I
faces	I
.	O
12.6.3	O
application	O
:	O
facial	B
animation	I
.	O
.	O
12.6.4	O
whole	O
body	B
modeling	O
and	O
tracking	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.7.1	O
estimating	O
brdfs	O
.	O
.	O
12.7.2	O
application	O
:	O
3d	O
photography	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.6	O
model-based	B
reconstruction	O
.	O
.	O
.	O
.	O
.	O
12.7	O
recovering	O
texture	B
maps	O
and	O
albedos	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12.8	O
additional	O
reading	O
.	O
12.9	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
580	O
.	O
580	O
.	O
583	O
.	O
584	O
.	O
585	O
.	O
588	O
.	O
590	O
.	O
591	O
.	O
592	O
.	O
594	O
.	O
594	O
.	O
595	O
.	O
596	O
.	O
596	O
.	O
598	O
.	O
598	O
.	O
601	O
.	O
603	O
.	O
605	O
.	O
610	O
.	O
612	O
.	O
613	O
.	O
614	O
.	O
616	O
578	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
g	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
h	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
(	O
i	O
)	O
figure	O
12.1	O
3d	O
shape	O
acquisition	O
and	O
modeling	B
techniques	O
:	O
(	O
a	O
)	O
shaded	O
image	B
(	O
zhang	O
,	O
tsai	O
,	O
cryer	O
et	O
al	O
.	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
ieee	O
;	O
(	O
b	O
)	O
texture	B
gradient	O
(	O
garding	O
1992	O
)	O
c	O
(	O
cid:13	O
)	O
1992	O
springer	O
;	O
(	O
c	O
)	O
real-time	O
depth	O
from	O
focus	B
(	O
nayar	O
,	O
watanabe	O
,	O
and	O
noguchi	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
ieee	O
;	O
(	O
d	O
)	O
scanning	O
a	O
scene	O
with	O
a	O
stick	O
shadow	B
(	O
bouguet	O
and	O
perona	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
springer	O
;	O
(	O
e	O
)	O
merging	B
range	O
maps	O
into	O
a	O
3d	O
model	O
(	O
curless	O
and	O
levoy	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
;	O
(	O
f	O
)	O
point-based	B
surface	O
modeling	B
(	O
pauly	O
,	O
keiser	O
,	O
kobbelt	O
et	O
al	O
.	O
2003	O
)	O
c	O
(	O
cid:13	O
)	O
2003	O
acm	O
;	O
(	O
g	O
)	O
automated	B
modeling	O
of	O
a	O
3d	O
building	O
using	O
lines	O
and	O
planes	B
(	O
werner	O
and	O
zisserman	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
springer	O
;	O
(	O
h	O
)	O
3d	O
face	B
model	O
from	O
spacetime	B
stereo	I
(	O
zhang	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
;	O
(	O
i	O
)	O
person	O
tracking	O
(	O
sigal	O
,	O
bhatia	O
,	O
roth	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
ieee	O
.	O
12	O
3d	O
reconstruction	O
579	O
as	O
we	O
saw	O
in	O
the	O
previous	O
chapter	O
,	O
a	O
variety	O
of	O
stereo	B
matching	I
techniques	O
have	O
been	O
de-	O
veloped	O
to	O
reconstruct	O
high	O
quality	O
3d	O
models	O
from	O
two	O
or	O
more	O
images	O
.	O
however	O
,	O
stereo	B
is	O
just	O
one	O
of	O
the	O
many	O
potential	O
cues	O
that	O
can	O
be	O
used	O
to	O
infer	O
shape	O
from	O
images	O
.	O
in	O
this	O
chapter	O
,	O
we	O
investigate	O
a	O
number	O
of	O
such	O
techniques	O
,	O
which	O
include	O
not	O
only	O
visual	O
cues	O
such	O
as	O
shading	B
and	O
focus	B
,	O
but	O
also	O
techniques	O
for	O
merging	O
multiple	B
range	O
or	O
depth	O
images	O
into	O
3d	O
models	O
,	O
as	O
well	O
as	O
techniques	O
for	O
reconstructing	O
specialized	O
models	O
,	O
such	O
as	O
heads	O
,	O
bodies	O
,	O
or	O
architecture	B
.	O
among	O
the	O
various	O
cues	O
that	O
can	O
be	O
used	O
to	O
infer	O
shape	O
,	O
the	O
shading	B
on	O
a	O
surface	B
(	O
fig-	O
ure	O
12.1a	O
)	O
can	O
provide	O
a	O
lot	O
of	O
information	O
about	O
local	B
surface	O
orientations	O
and	O
hence	O
overall	O
surface	B
shape	O
(	O
section	O
12.1.1	O
)	O
.	O
this	O
approach	O
becomes	O
even	O
more	O
powerful	O
when	O
lights	O
shining	O
from	O
different	O
directions	O
can	O
be	O
turned	O
on	O
and	O
off	O
separately	O
(	O
photometric	B
stereo	I
)	O
.	O
texture	B
gradients	O
(	O
figure	O
12.1b	O
)	O
,	O
i.e.	O
,	O
the	O
foreshortening	O
of	O
regular	O
patterns	B
as	O
the	O
surface	B
slants	O
or	O
bends	O
away	O
from	O
the	O
camera	B
,	O
can	O
provide	O
similar	O
cues	O
on	O
local	B
surface	O
orientation	O
(	O
section	O
12.1.2	O
)	O
.	O
focus	B
is	O
another	O
powerful	O
cue	O
to	O
scene	O
depth	O
,	O
especially	O
when	O
two	O
or	O
more	O
images	O
with	O
different	O
focus	B
settings	O
are	O
used	O
(	O
section	O
12.1.3	O
)	O
.	O
3d	O
shape	O
can	O
also	O
be	O
estimated	O
using	O
active	O
illumination	O
techniques	O
such	O
as	O
light	O
stripes	O
(	O
figure	O
12.1d	O
)	O
or	O
time	B
of	I
ﬂight	I
range	O
ﬁnders	O
(	O
section	O
12.2	O
)	O
.	O
the	O
partial	O
surface	B
models	O
obtained	O
using	O
such	O
techniques	O
(	O
or	O
passive	O
image-based	B
stereo	O
)	O
can	O
then	O
be	O
merged	O
into	O
more	O
coherent	O
3d	O
surface	B
models	O
(	O
figure	O
12.1e	O
)	O
,	O
as	O
discussed	O
in	O
section	O
12.2.1.	O
such	O
techniques	O
have	O
been	O
used	O
to	O
construct	O
highly	O
detailed	O
and	O
accurate	O
models	O
of	O
cultural	O
heritage	O
such	O
as	O
historic	O
sites	O
(	O
section	O
12.2.2	O
)	O
.	O
the	O
resulting	O
surface	B
models	O
can	O
then	O
be	O
simpliﬁed	O
to	O
support	O
viewing	O
at	O
different	O
resolutions	O
and	O
streaming	O
across	O
the	O
web	O
(	O
section	O
12.3.2	O
)	O
.	O
an	O
alternative	O
to	O
working	O
with	O
continuous	O
surfaces	O
is	O
to	O
represent	O
3d	O
surfaces	O
as	O
dense	O
collections	O
of	O
3d	O
oriented	B
points	O
(	O
section	O
12.4	O
)	O
or	O
as	O
volumetric	B
primitives	O
(	O
section	O
12.5	O
)	O
.	O
3d	O
modeling	B
can	O
be	O
more	O
efﬁcient	O
and	O
effective	O
if	O
we	O
know	O
something	O
about	O
the	O
objects	O
we	O
are	O
trying	O
to	O
reconstruct	O
.	O
in	O
section	O
12.6	O
,	O
we	O
look	O
at	O
three	O
specialized	O
but	O
commonly	O
occurring	O
examples	B
,	O
namely	O
architecture	B
(	O
figure	O
12.1g	O
)	O
,	O
heads	B
and	I
faces	I
(	O
figure	O
12.1h	O
)	O
,	O
and	O
whole	O
bodies	O
(	O
figure	O
12.1i	O
)	O
.	O
in	O
addition	O
to	O
modeling	B
people	O
,	O
we	O
also	O
discuss	O
techniques	O
for	O
tracking	O
them	O
.	O
the	O
last	O
stage	O
of	O
shape	O
and	O
appearance	O
modeling	B
is	O
to	O
extract	O
some	O
textures	O
to	O
paint	O
onto	O
our	O
3d	O
models	O
(	O
section	O
12.7	O
)	O
.	O
some	O
techniques	O
go	O
beyond	O
this	O
and	O
actually	O
estimate	O
full	O
brdfs	O
(	O
section	O
12.7.1	O
)	O
.	O
because	O
there	O
exists	O
such	O
a	O
large	O
variety	O
of	O
techniques	O
to	O
perform	O
3d	O
modeling	B
,	O
this	O
chapter	O
does	O
not	O
go	O
into	O
detail	O
on	O
any	O
one	O
of	O
these	O
.	O
readers	O
are	O
encouraged	O
to	O
ﬁnd	O
more	O
information	O
in	O
the	O
cited	O
references	B
or	O
more	O
specialized	O
publications	O
and	O
conferences	O
de-	O
voted	O
to	O
these	O
topics	O
,	O
e.g.	O
,	O
the	O
international	O
symposium	O
on	O
3d	O
data	O
processing	O
,	O
visualiza-	O
tion	B
,	O
and	O
transmission	O
(	O
3dpvt	O
)	O
,	O
the	O
international	O
conference	O
on	O
3d	O
digital	O
imaging	O
and	O
modeling	B
(	O
3dim	O
)	O
,	O
the	O
international	O
conference	O
on	O
automatic	B
face	O
and	O
gesture	O
recognition	B
580	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
fg	O
)	O
,	O
the	O
ieee	O
workshop	O
on	O
analysis	O
and	O
modeling	B
of	O
faces	B
and	O
gestures	O
,	O
and	O
the	O
interna-	O
tional	O
workshop	O
on	O
tracking	O
humans	O
for	O
the	O
evaluation	B
of	O
their	O
motion	B
in	O
image	B
sequences	O
(	O
themis	O
)	O
.	O
12.1	O
shape	O
from	O
x	O
in	O
addition	O
to	O
binocular	O
disparity	O
,	O
shading	B
,	O
texture	B
,	O
and	O
focus	B
all	O
play	O
a	O
role	O
in	O
how	O
we	O
per-	O
ceive	O
shape	O
.	O
the	O
study	O
of	O
how	O
shape	O
can	O
be	O
inferred	O
from	O
such	O
cues	O
is	O
sometimes	O
called	O
shape	O
from	O
x	O
,	O
since	O
the	O
individual	O
instances	O
are	O
called	O
shape	O
from	O
shading	B
,	O
shape	O
from	O
tex-	O
ture	O
,	O
and	O
shape	O
from	O
focus.1	O
in	O
this	O
section	O
,	O
we	O
look	O
at	O
these	O
three	O
cues	O
and	O
how	O
they	O
can	O
be	O
used	O
to	O
reconstruct	O
3d	O
geometry	O
.	O
a	O
good	O
overview	O
of	O
all	O
these	O
topics	O
can	O
be	O
found	O
in	O
the	O
collection	O
of	O
papers	O
on	O
physics-based	B
shape	O
inference	B
edited	O
by	O
wolff	O
,	O
shafer	O
,	O
and	O
healey	O
(	O
1992b	O
)	O
.	O
12.1.1	O
shape	O
from	O
shading	B
and	O
photometric	B
stereo	I
when	O
you	O
look	O
at	O
images	O
of	O
smooth	O
shaded	O
objects	O
,	O
such	O
as	O
the	O
ones	O
shown	O
in	O
figure	O
12.2	O
,	O
you	O
can	O
clearly	O
see	O
the	O
shape	O
of	O
the	O
object	O
from	O
just	O
the	O
shading	B
variation	O
.	O
how	O
is	O
this	O
possible	O
?	O
the	O
answer	O
is	O
that	O
as	O
the	O
surface	B
normal	O
changes	O
across	O
the	O
object	O
,	O
the	O
apparent	O
brightness	O
changes	O
as	O
a	O
function	O
of	O
the	O
angle	O
between	O
the	O
local	B
surface	O
orientation	O
and	O
the	O
incident	O
illumination	O
,	O
as	O
shown	O
in	O
figure	O
2.15	O
(	O
section	O
2.2.2	O
)	O
.	O
the	O
problem	O
of	O
recovering	O
the	O
shape	O
of	O
a	O
surface	B
from	O
this	O
intensity	O
variation	O
is	O
known	O
as	O
shape	O
from	O
shading	B
and	O
is	O
one	O
of	O
the	O
classic	O
problems	O
in	O
computer	O
vision	O
(	O
horn	O
1975	O
)	O
.	O
the	O
collection	O
of	O
papers	O
edited	O
by	O
horn	O
and	O
brooks	O
(	O
1989	O
)	O
is	O
a	O
great	O
source	O
of	O
information	O
on	O
this	O
topic	O
,	O
especially	O
the	O
chapter	O
on	O
variational	O
approaches	O
.	O
the	O
survey	O
by	O
zhang	O
,	O
tsai	O
,	O
cryer	O
et	O
al	O
.	O
(	O
1999	O
)	O
not	O
only	O
reviews	O
more	O
recent	O
techniques	O
,	O
but	O
also	O
provides	O
some	O
comparative	O
results	O
.	O
most	O
shape	O
from	O
shading	B
algorithms	O
assume	O
that	O
the	O
surface	B
under	O
consideration	O
is	O
of	O
a	O
uniform	O
albedo	O
and	O
reﬂectance	B
,	O
and	O
that	O
the	O
light	O
source	O
directions	O
are	O
either	O
known	O
or	O
can	O
be	O
calibrated	O
by	O
the	O
use	O
of	O
a	O
reference	O
object	O
.	O
under	O
the	O
assumptions	O
of	O
distant	O
light	O
sources	O
and	O
observer	O
,	O
the	O
variation	O
in	O
intensity	O
(	O
irradiance	O
equation	B
)	O
become	O
purely	O
a	O
function	O
of	O
the	O
local	B
surface	O
orientation	O
,	O
i	O
(	O
x	O
,	O
y	O
)	O
=	O
r	O
(	O
p	O
(	O
x	O
,	O
y	O
)	O
,	O
q	O
(	O
x	O
,	O
y	O
)	O
)	O
,	O
(	O
12.1	O
)	O
where	O
(	O
p	O
,	O
q	O
)	O
=	O
(	O
zx	O
,	O
zy	O
)	O
are	O
the	O
depth	B
map	I
derivatives	O
and	O
r	O
(	O
p	O
,	O
q	O
)	O
is	O
called	O
the	O
reﬂectance	B
map	O
.	O
for	O
example	O
,	O
a	O
diffuse	B
(	O
lambertian	O
)	O
surface	B
has	O
a	O
reﬂectance	B
map	O
that	O
is	O
the	O
(	O
non-	O
1	O
we	O
have	O
already	O
seen	O
examples	B
of	O
shape	O
from	O
stereo	B
,	O
shape	O
from	O
proﬁles	B
,	O
and	O
shape	O
from	O
silhouettes	B
in	O
chap-	O
ter	O
11	O
.	O
12.1	O
shape	O
from	O
x	O
581	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
(	O
h	O
)	O
figure	O
12.2	O
synthetic	O
shape	O
from	O
shading	B
(	O
zhang	O
,	O
tsai	O
,	O
cryer	O
et	O
al	O
.	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
ieee	O
:	O
shaded	O
images	O
,	O
(	O
a–b	O
)	O
with	O
light	O
from	O
in	O
front	O
(	O
0	O
,	O
0	O
,	O
1	O
)	O
and	O
(	O
c–d	O
)	O
with	O
light	O
the	O
front	O
right	O
(	O
1	O
,	O
0	O
,	O
1	O
)	O
;	O
(	O
e–f	O
)	O
corresponding	O
shape	O
from	O
shading	B
reconstructions	O
using	O
the	O
technique	O
of	O
tsai	O
and	O
shah	O
(	O
1994	O
)	O
.	O
negative	O
)	O
dot	O
product	O
(	O
2.88	O
)	O
between	O
the	O
surface	B
normal	O
ˆn	O
=	O
(	O
p	O
,	O
q	O
,	O
1	O
)	O
/	O
(	O
cid:112	O
)	O
1	O
+	O
p2	O
+	O
q2	O
and	O
the	O
light	O
source	O
direction	O
v	O
=	O
(	O
vx	O
,	O
vy	O
,	O
vz	O
)	O
,	O
r	O
(	O
p	O
,	O
q	O
)	O
=	O
max	O
(	O
cid:32	O
)	O
0	O
,	O
ρ	O
pvx	O
+	O
qvy	O
+	O
vz	O
(	O
cid:112	O
)	O
1	O
+	O
p2	O
+	O
q2	O
(	O
cid:33	O
)	O
,	O
where	O
ρ	O
is	O
the	O
surface	B
reﬂectance	O
factor	O
(	O
albedo	O
)	O
.	O
(	O
12.2	O
)	O
in	O
principle	O
,	O
equations	B
(	O
12.1–12.2	O
)	O
can	O
be	O
used	O
to	O
estimate	O
(	O
p	O
,	O
q	O
)	O
using	O
non-linear	O
least	B
squares	I
or	O
some	O
other	O
method	O
.	O
unfortunately	O
,	O
unless	O
additional	O
constraints	O
are	O
imposed	O
,	O
there	O
are	O
more	O
unknowns	O
per	O
pixel	O
(	O
p	O
,	O
q	O
)	O
than	O
there	O
are	O
measurements	O
(	O
i	O
)	O
.	O
one	O
commonly	O
used	O
constraint	B
is	O
the	O
smoothness	B
constraint	O
,	O
es	O
=	O
(	O
cid:90	O
)	O
p2	O
x	O
+	O
p2	O
y	O
+	O
q2	O
x	O
+	O
q2	O
y	O
dx	O
dy	O
=	O
(	O
cid:90	O
)	O
(	O
cid:107	O
)	O
∇p	O
(	O
cid:107	O
)	O
2	O
+	O
(	O
cid:107	O
)	O
∇q	O
(	O
cid:107	O
)	O
2	O
dx	O
dy	O
,	O
which	O
we	O
already	O
saw	O
in	O
section	O
3.7.1	O
(	O
3.94	O
)	O
.	O
the	O
other	O
is	O
the	O
integrability	O
constraint	B
,	O
ei	O
=	O
(	O
cid:90	O
)	O
(	O
py	O
−	O
qx	O
)	O
2	O
dx	O
dy	O
,	O
(	O
12.3	O
)	O
(	O
12.4	O
)	O
582	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
which	O
arises	O
naturally	O
,	O
since	O
for	O
a	O
valid	O
depth	B
map	I
z	O
(	O
x	O
,	O
y	O
)	O
with	O
(	O
p	O
,	O
q	O
)	O
=	O
(	O
zx	O
,	O
zy	O
)	O
,	O
we	O
have	O
py	O
=	O
zxy	O
=	O
zyx	O
=	O
qx	O
.	O
instead	O
of	O
ﬁrst	O
recovering	O
the	O
orientation	O
ﬁelds	O
(	O
p	O
,	O
q	O
)	O
and	O
integrating	O
them	O
to	O
obtain	O
a	O
surface	B
,	O
it	O
is	O
also	O
possible	O
to	O
directly	O
minimize	O
the	O
discrepancy	O
in	O
the	O
image	B
formation	O
equa-	O
tion	B
(	O
12.1	O
)	O
while	O
ﬁnding	O
the	O
optimal	O
depth	B
map	I
z	O
(	O
x	O
,	O
y	O
)	O
(	O
horn	O
1990	O
)	O
.	O
unfortunately	O
,	O
shape	O
from	O
shading	B
is	O
susceptible	O
to	O
local	B
minima	O
in	O
the	O
search	O
space	O
and	O
,	O
like	O
other	O
variational	O
problems	O
that	O
involve	O
the	O
simultaneous	O
estimation	B
of	O
many	O
variables	O
,	O
can	O
also	O
suffer	O
from	O
slow	O
convergence	O
.	O
using	O
multi-resolution	O
techniques	O
(	O
szeliski	O
1991a	O
)	O
can	O
help	O
accelerate	O
the	O
convergence	O
,	O
while	O
using	O
more	O
sophisticated	O
optimization	O
techniques	O
(	O
dupuis	O
and	O
olien-	O
sis	O
1994	O
)	O
can	O
help	O
avoid	O
local	B
minima	O
.	O
in	O
practice	O
,	O
surfaces	O
other	O
than	O
plaster	O
casts	O
are	O
rarely	O
of	O
a	O
single	O
uniform	O
albedo	O
.	O
shape	O
from	O
shading	B
therefore	O
needs	O
to	O
be	O
combined	O
with	O
some	O
other	O
technique	O
or	O
extended	O
in	O
some	O
way	O
to	O
make	O
it	O
useful	O
.	O
one	O
way	O
to	O
do	O
this	O
is	O
to	O
combine	O
it	O
with	O
stereo	O
matching	B
(	O
fua	O
and	O
leclerc	O
1995	O
)	O
or	O
known	O
texture	B
(	O
surface	B
patterns	O
)	O
(	O
white	O
and	O
forsyth	O
2006	O
)	O
.	O
the	O
stereo	B
and	O
texture	B
components	O
provide	O
information	O
in	O
textured	O
regions	O
,	O
while	O
shape	O
from	O
shading	B
helps	O
ﬁll	O
in	O
the	O
information	O
across	O
uniformly	O
colored	O
regions	O
and	O
also	O
provides	O
ﬁner	O
information	O
about	O
surface	B
shape	O
.	O
photometric	B
stereo	I
.	O
another	O
way	O
to	O
make	O
shape	O
from	O
shading	B
more	O
reliable	O
is	O
to	O
use	O
mul-	O
tiple	O
light	O
sources	O
that	O
can	O
be	O
selectively	O
turned	O
on	O
and	O
off	O
.	O
this	O
technique	O
is	O
called	O
photo-	O
metric	O
stereo	B
,	O
since	O
the	O
light	O
sources	O
play	O
a	O
role	O
analogous	O
to	O
the	O
cameras	O
located	O
at	O
different	O
locations	O
in	O
traditional	O
stereo	B
(	O
woodham	O
1981	O
)	O
.2	O
for	O
each	O
light	O
source	O
,	O
we	O
have	O
a	O
differ-	O
ent	O
reﬂectance	B
map	O
,	O
r1	O
(	O
p	O
,	O
q	O
)	O
,	O
r2	O
(	O
p	O
,	O
q	O
)	O
,	O
etc	O
.	O
given	O
the	O
corresponding	O
intensities	O
i1	O
,	O
i2	O
,	O
etc	O
.	O
at	O
a	O
pixel	O
,	O
we	O
can	O
in	O
principle	O
recover	O
both	O
an	O
unknown	O
albedo	O
ρ	O
and	O
a	O
surface	B
orientation	O
estimate	O
(	O
p	O
,	O
q	O
)	O
.	O
for	O
diffuse	O
surfaces	O
(	O
12.2	O
)	O
,	O
if	O
we	O
parameterize	O
the	O
local	B
orientation	O
by	O
ˆn	O
,	O
we	O
get	O
(	O
for	O
non-shadowed	O
pixels	O
)	O
a	O
set	O
of	O
linear	B
equations	O
of	O
the	O
form	O
ik	O
=	O
ρˆn	O
·	O
vk	O
,	O
(	O
12.5	O
)	O
from	O
which	O
we	O
can	O
recover	O
ρˆn	O
using	O
linear	O
least	B
squares	I
.	O
these	O
equations	B
are	O
well	O
condi-	O
tioned	O
as	O
long	O
as	O
the	O
(	O
three	O
or	O
more	O
)	O
vectors	O
vk	O
are	O
linearly	O
independent	O
,	O
i.e.	O
,	O
they	O
are	O
not	O
along	O
the	O
same	O
azimuth	O
(	O
direction	O
away	O
from	O
the	O
viewer	O
)	O
.	O
once	O
the	O
surface	B
normals	O
or	O
gradients	O
have	O
been	O
recovered	O
at	O
each	O
pixel	O
,	O
they	O
can	O
be	O
integrated	O
into	O
a	O
depth	B
map	I
using	O
a	O
variant	O
of	O
regularized	O
surface	B
ﬁtting	O
(	O
3.100	O
)	O
.	O
(	O
nehab	O
,	O
rusinkiewicz	O
,	O
davis	O
et	O
al	O
.	O
(	O
2005	O
)	O
and	O
harker	O
and	O
o	O
’	O
leary	O
(	O
2008	O
)	O
have	O
produced	O
some	O
recent	O
work	O
in	O
this	O
area	O
.	O
)	O
2	O
an	O
alternative	O
to	O
turning	O
lights	O
on-and-off	O
is	O
to	O
use	O
three	O
colored	O
lights	O
(	O
woodham	O
1994	O
;	O
hernandez	O
,	O
vogiatzis	O
,	O
brostow	O
et	O
al	O
.	O
2007	O
;	O
hernandez	O
and	O
vogiatzis	O
2010	O
)	O
.	O
12.1	O
shape	O
from	O
x	O
583	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
12.3	O
synthetic	O
shape	O
from	O
texture	B
(	O
garding	O
1992	O
)	O
c	O
(	O
cid:13	O
)	O
1992	O
springer	O
:	O
(	O
a	O
)	O
regular	O
texture	B
wrapped	O
onto	O
a	O
curved	O
surface	B
and	O
(	O
b	O
)	O
the	O
corresponding	O
surface	B
normal	O
estimates	O
.	O
shape	O
from	O
mirror	O
reﬂections	B
(	O
savarese	O
,	O
chen	O
,	O
and	O
perona	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
springer	O
:	O
(	O
c	O
)	O
a	O
regular	O
pattern	O
reﬂecting	O
off	O
a	O
curved	O
mirror	O
gives	O
rise	O
to	O
(	O
d	O
)	O
curved	O
lines	B
,	O
from	O
which	O
3d	O
point	O
locations	O
and	O
normals	O
can	O
be	O
inferred	O
.	O
when	O
surfaces	O
are	O
specular	B
,	O
more	O
than	O
three	O
light	O
directions	O
may	O
be	O
required	O
.	O
in	O
fact	O
,	O
the	O
irradiance	O
equation	B
given	O
in	O
(	O
12.1	O
)	O
not	O
only	O
requires	O
that	O
the	O
light	O
sources	O
and	O
camera	B
be	O
distant	O
from	O
the	O
surface	B
,	O
it	O
also	O
neglects	O
inter-reﬂections	O
,	O
which	O
can	O
be	O
a	O
signiﬁcant	O
source	O
of	O
the	O
shading	B
observed	O
on	O
object	O
surfaces	O
,	O
e.g.	O
,	O
the	O
darkening	O
seen	O
inside	O
concave	O
structures	O
such	O
as	O
grooves	O
and	O
crevasses	O
(	O
nayar	O
,	O
ikeuchi	O
,	O
and	O
kanade	O
1991	O
)	O
.	O
12.1.2	O
shape	O
from	O
texture	B
the	O
variation	O
in	O
foreshortening	O
observed	O
in	O
regular	O
textures	O
can	O
also	O
provide	O
useful	O
informa-	O
tion	B
about	O
local	B
surface	O
orientation	O
.	O
figure	O
12.3	O
shows	O
an	O
example	O
of	O
such	O
a	O
pattern	O
,	O
along	O
with	O
the	O
estimated	O
local	B
surface	O
orientations	O
.	O
shape	O
from	O
texture	B
algorithms	O
require	O
a	O
number	O
of	O
processing	O
steps	O
,	O
including	O
the	O
extraction	O
of	O
repeated	O
patterns	B
or	O
the	O
measurement	O
of	O
local	B
frequencies	O
in	O
order	B
to	O
compute	O
local	B
afﬁne	O
deformations	O
,	O
and	O
a	O
subsequent	O
stage	O
to	O
infer	O
lo-	O
cal	O
surface	B
orientation	O
.	O
details	O
on	O
these	O
various	O
stages	O
can	O
be	O
found	O
in	O
the	O
research	O
literature	O
(	O
witkin	O
1981	O
;	O
ikeuchi	O
1981	O
;	O
blostein	O
and	O
ahuja	O
1987	O
;	O
garding	O
1992	O
;	O
malik	O
and	O
rosenholtz	O
1997	O
;	O
lobay	O
and	O
forsyth	O
2006	O
)	O
.	O
when	O
the	O
original	O
pattern	O
is	O
regular	O
,	O
it	O
is	O
possible	O
to	O
ﬁt	O
a	O
regular	O
but	O
slightly	O
deformed	O
grid	O
to	O
the	O
image	B
and	O
use	O
this	O
grid	O
for	O
a	O
variety	O
of	O
image	B
replacement	O
or	O
analysis	O
tasks	O
(	O
liu	O
,	O
collins	O
,	O
and	O
tsin	O
2004	O
;	O
liu	O
,	O
lin	O
,	O
and	O
hays	O
2004	O
;	O
hays	O
,	O
leordeanu	O
,	O
efros	O
et	O
al	O
.	O
2006	O
;	O
lin	O
,	O
hays	O
,	O
wu	O
et	O
al	O
.	O
2006	O
;	O
park	O
,	O
brocklehurst	O
,	O
collins	O
et	O
al	O
.	O
2009	O
)	O
.	O
this	O
process	O
becomes	O
even	O
easier	O
if	O
specially	O
printed	O
textured	O
cloth	O
patterns	B
are	O
used	O
(	O
white	O
and	O
forsyth	O
2006	O
;	O
white	O
,	O
crane	O
,	O
and	O
forsyth	O
2007	O
)	O
.	O
the	O
deformations	O
induced	O
in	O
a	O
regular	O
pattern	O
when	O
it	O
is	O
viewed	O
in	O
the	O
reﬂection	O
of	O
a	O
curved	O
mirror	O
,	O
as	O
shown	O
in	O
figure	O
12.3c–d	O
,	O
can	O
be	O
used	O
to	O
recover	O
the	O
shape	O
of	O
the	O
surface	B
estimate	O
tangent	O
planesscene	O
pattern	O
(	O
b	O
)	O
(	O
c	O
)	O
camerascenemirror	O
surface	B
c	O
(	O
a	O
)	O
estimate	O
tangent	O
planesscene	O
pattern	O
(	O
b	O
)	O
(	O
c	O
)	O
camerascenemirror	O
surface	B
c	O
(	O
a	O
)	O
estimate	O
tangent	O
planesscene	O
pattern	O
(	O
b	O
)	O
(	O
c	O
)	O
camerascenemirror	O
surface	B
c	O
(	O
a	O
)	O
584	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
a	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
figure	O
12.4	O
real	O
time	O
depth	O
from	O
defocus	O
(	O
nayar	O
,	O
watanabe	O
,	O
and	O
noguchi	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
ieee	O
:	O
(	O
a	O
)	O
the	O
real-time	O
focus	B
range	O
sensor	B
,	O
which	O
includes	O
a	O
half-silvered	O
mirror	O
between	O
the	O
two	O
telecentric	O
lenses	O
(	O
lower	O
right	O
)	O
,	O
a	O
prism	O
that	O
splits	O
the	O
image	B
into	O
two	O
ccd	O
sensors	O
(	O
lower	O
left	O
)	O
,	O
and	O
an	O
edged	O
checkerboard	O
pattern	O
illuminated	O
by	O
a	O
xenon	O
lamp	O
(	O
top	O
)	O
;	O
(	O
b–c	O
)	O
input	O
video	B
frames	O
from	O
the	O
two	O
cameras	O
along	O
with	O
(	O
d	O
)	O
the	O
corresponding	O
depth	B
map	I
;	O
(	O
e–f	O
)	O
two	O
frames	O
(	O
you	O
can	O
see	O
the	O
texture	B
if	O
you	O
zoom	O
in	O
)	O
and	O
(	O
g	O
)	O
the	O
corresponding	O
3d	O
mesh	O
model	O
.	O
(	O
savarese	O
,	O
chen	O
,	O
and	O
perona	O
2005	O
;	O
rozenfeld	O
,	O
shimshoni	O
,	O
and	O
lindenbaum	O
2007	O
)	O
.	O
it	O
is	O
is	O
also	O
possible	O
to	O
infer	O
local	B
shape	O
information	O
from	O
specular	B
ﬂow	O
,	O
i.e.	O
,	O
the	O
motion	B
of	O
specu-	O
larities	O
when	O
viewed	O
from	O
a	O
moving	O
camera	O
(	O
oren	O
and	O
nayar	O
1997	O
;	O
zisserman	O
,	O
giblin	O
,	O
and	O
blake	O
1989	O
;	O
swaminathan	O
,	O
kang	O
,	O
szeliski	O
et	O
al	O
.	O
2002	O
)	O
.	O
12.1.3	O
shape	O
from	O
focus	B
a	O
strong	O
cue	O
for	O
object	O
depth	O
is	O
the	O
amount	O
of	O
blur	O
,	O
which	O
increases	O
as	O
the	O
object	O
’	O
s	O
surface	B
moves	O
away	O
from	O
the	O
camera	B
’	O
s	O
focusing	O
distance	O
.	O
as	O
shown	O
in	O
figure	O
2.19	O
,	O
moving	O
the	O
object	O
surface	B
away	O
from	O
the	O
focus	B
plane	O
increases	O
the	O
circle	O
of	O
confusion	O
,	O
according	O
to	O
a	O
formula	O
that	O
is	O
easy	O
to	O
establish	O
using	O
similar	O
triangles	O
(	O
exercise	O
2.4	O
)	O
.	O
a	O
number	O
of	O
techniques	O
have	O
been	O
developed	O
to	O
estimate	O
depth	O
from	O
the	O
amount	O
of	O
de-	O
focus	B
(	O
depth	O
from	O
defocus	O
)	O
(	O
pentland	O
1987	O
;	O
nayar	O
and	O
nakagawa	O
1994	O
;	O
nayar	O
,	O
watanabe	O
,	O
and	O
noguchi	O
1996	O
;	O
watanabe	O
and	O
nayar	O
1998	O
;	O
chaudhuri	O
and	O
rajagopalan	O
1999	O
;	O
favaro	O
and	O
soatto	O
2006	O
)	O
.	O
in	O
order	B
to	O
make	O
such	O
a	O
technique	O
practical	O
,	O
a	O
number	O
issues	O
need	O
to	O
be	O
addressed	O
:	O
•	O
the	O
amount	O
of	O
blur	O
increase	O
in	O
both	O
directions	O
as	O
you	O
move	O
away	O
from	O
the	O
focus	B
plane	O
.	O
therefore	O
,	O
it	O
is	O
necessary	O
to	O
use	O
two	O
or	O
more	O
images	O
captured	O
with	O
different	O
focus	B
12.2	O
active	O
rangeﬁnding	O
585	O
figure	O
12.5	O
range	O
data	O
scanning	O
(	O
curless	O
and	O
levoy	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
:	O
(	O
a	O
)	O
a	O
laser	O
dot	O
on	O
a	O
surface	B
is	O
imaged	O
by	O
a	O
ccd	O
sensor	B
;	O
(	O
b	O
)	O
a	O
laser	O
stripe	O
(	O
sheet	O
)	O
is	O
imaged	O
by	O
the	O
sensor	B
(	O
the	O
deformation	O
of	O
the	O
stripe	O
encodes	O
the	O
distance	O
to	O
the	O
object	O
)	O
;	O
(	O
c	O
)	O
the	O
resulting	O
set	O
of	O
3d	O
points	B
are	O
turned	O
into	O
(	O
d	O
)	O
a	O
triangulated	O
mesh	O
.	O
distance	O
settings	O
(	O
pentland	O
1987	O
;	O
nayar	O
,	O
watanabe	O
,	O
and	O
noguchi	O
1996	O
)	O
or	O
to	O
translate	O
the	O
object	O
in	O
depth	O
and	O
look	O
for	O
the	O
point	O
of	O
maximum	O
sharpness	O
(	O
nayar	O
and	O
nakagawa	O
1994	O
)	O
.	O
•	O
the	O
magniﬁcation	O
of	O
the	O
object	O
can	O
vary	O
as	O
the	O
focus	B
distance	O
is	O
changed	O
or	O
the	O
object	O
is	O
moved	O
.	O
this	O
can	O
be	O
modeled	O
either	O
explicitly	O
(	O
making	O
correspondence	B
more	O
difﬁcult	O
)	O
or	O
using	O
telecentric	O
optics	B
,	O
which	O
approximate	O
an	O
orthographic	B
camera	O
and	O
require	O
an	O
aperture	O
in	O
front	O
of	O
the	O
lens	O
(	O
nayar	O
,	O
watanabe	O
,	O
and	O
noguchi	O
1996	O
)	O
.	O
•	O
the	O
amount	O
of	O
defocus	O
must	O
be	O
reliably	O
estimated	O
.	O
a	O
simple	O
approach	O
is	O
to	O
average	O
the	O
squared	O
gradient	O
in	O
a	O
region	B
but	O
this	O
suffers	O
from	O
several	O
problems	O
,	O
including	O
the	O
image	B
magniﬁcation	O
problem	O
mentioned	O
above	O
.	O
a	O
better	O
solution	O
is	O
to	O
use	O
carefully	O
designed	O
rational	O
ﬁlters	O
(	O
watanabe	O
and	O
nayar	O
1998	O
)	O
.	O
figure	O
12.4	O
shows	O
an	O
example	O
of	O
a	O
real-time	O
depth	O
from	O
defocus	O
sensor	B
,	O
which	O
employs	O
two	O
imaging	O
chips	O
at	O
slightly	O
different	O
depths	O
sharing	O
a	O
common	O
optical	O
path	O
,	O
as	O
well	O
as	O
an	O
active	B
illumination	I
system	O
that	O
projects	O
a	O
checkerboard	O
pattern	O
from	O
the	O
same	O
direction	O
.	O
as	O
you	O
can	O
see	O
in	O
figure	O
12.4b–g	O
,	O
the	O
system	O
produces	O
high-accuracy	O
real-time	O
depth	O
maps	O
for	O
both	O
static	O
and	O
dynamic	B
scenes	O
.	O
12.2	O
active	O
rangeﬁnding	O
as	O
we	O
have	O
seen	O
in	O
the	O
previous	O
section	O
,	O
actively	O
lighting	B
a	O
scene	O
,	O
whether	O
for	O
the	O
purpose	O
of	O
estimating	O
normals	O
using	O
photometric	O
stereo	B
or	O
for	O
adding	O
artiﬁcial	O
texture	B
for	O
shape	O
from	O
defocus	O
,	O
can	O
greatly	O
improve	O
the	O
performance	O
of	O
vision	O
systems	O
.	O
this	O
kind	O
of	O
active	O
illu-	O
mination	O
has	O
been	O
used	O
from	O
the	O
earliest	O
days	O
of	O
machine	O
vision	O
to	O
construct	O
highly	O
reliable	O
surfaceccdlaser	O
(	O
a	O
)	O
direction	O
of	O
travelobjectccdccd	O
image	B
planelasercylindrical	O
lenslaser	O
sheetσzσx	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
586	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
12.6	O
shape	O
scanning	O
using	O
cast	O
shadows	O
(	O
bouguet	O
and	O
perona	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
springer	O
:	O
(	O
a	O
)	O
camera	B
setup	O
with	O
a	O
point	O
light	O
source	O
(	O
a	O
desk	O
lamp	O
without	O
its	O
reﬂector	O
)	O
,	O
a	O
hand-held	O
stick	O
casting	O
a	O
shadow	B
,	O
and	O
(	O
b	O
)	O
the	O
objects	O
being	O
scanned	O
in	O
front	O
of	O
two	O
planar	O
backgrounds	O
.	O
(	O
c	O
)	O
real-time	O
depth	B
map	I
using	O
a	O
pulsed	O
illumination	O
system	O
(	O
iddan	O
and	O
yahav	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
spie	O
.	O
sensors	O
for	O
estimating	O
3d	O
depth	O
images	O
using	O
a	O
variety	O
of	O
rangeﬁnding	O
(	O
or	O
range	O
sensing	O
)	O
techniques	O
(	O
besl	O
1989	O
;	O
curless	O
1999	O
;	O
hebert	O
2000	O
)	O
.	O
one	O
of	O
the	O
most	O
popular	O
active	B
illumination	I
sensors	O
is	O
a	O
laser	O
or	O
light	B
stripe	I
sensor	O
,	O
which	O
sweeps	O
a	O
plane	O
of	O
light	O
across	O
the	O
scene	O
or	O
object	O
while	O
observing	O
it	O
from	O
an	O
offset	O
viewpoint	O
,	O
as	O
shown	O
in	O
figure	O
12.5b	O
(	O
rioux	O
and	O
bird	O
1993	O
;	O
curless	O
and	O
levoy	O
1995	O
)	O
.	O
as	O
the	O
stripe	O
falls	O
across	O
the	O
object	O
,	O
it	O
deforms	O
its	O
shape	O
according	O
to	O
the	O
shape	O
of	O
the	O
surface	B
it	O
is	O
illuminating	O
.	O
it	O
is	O
then	O
a	O
simple	O
matter	O
of	O
using	O
optical	O
triangulation	B
to	O
estimate	O
the	O
3d	O
locations	O
of	O
all	O
the	O
points	B
seen	O
in	O
a	O
particular	O
stripe	O
.	O
in	O
more	O
detail	O
,	O
knowledge	O
of	O
the	O
3d	O
plane	O
equation	O
of	O
the	O
light	B
stripe	I
allows	O
us	O
to	O
infer	O
the	O
3d	O
location	O
corresponding	O
to	O
each	O
illuminated	O
pixel	O
,	O
as	O
pre-	O
viously	O
discussed	O
in	O
(	O
2.70–2.71	O
)	O
.	O
the	O
accuracy	B
of	O
light	O
striping	O
techniques	O
can	O
be	O
improved	O
by	O
ﬁnding	O
the	O
exact	O
temporal	O
peak	O
in	O
illumination	O
for	O
each	O
pixel	O
(	O
curless	O
and	O
levoy	O
1995	O
)	O
.	O
the	O
ﬁnal	O
accuracy	B
of	O
a	O
scanner	O
can	O
be	O
determined	O
using	O
slant	O
edge	O
modulation	O
techniques	O
,	O
i.e.	O
,	O
by	O
imaging	O
sharp	O
creases	O
in	O
a	O
calibration	B
object	O
(	O
goesele	O
,	O
fuchs	O
,	O
and	O
seidel	O
2003	O
)	O
.	O
an	O
interesting	O
variant	O
on	O
light	B
stripe	I
rangeﬁnding	O
is	O
presented	O
by	O
bouguet	O
and	O
perona	O
(	O
1999	O
)	O
.	O
instead	O
of	O
projecting	O
a	O
light	B
stripe	I
,	O
they	O
simply	O
wave	O
a	O
stick	O
casting	O
a	O
shadow	B
over	O
a	O
scene	O
or	O
object	O
illuminated	O
by	O
a	O
point	O
light	O
source	O
such	O
as	O
a	O
lamp	O
or	O
the	O
sun	O
(	O
figure	O
12.6a	O
)	O
.	O
as	O
the	O
shadow	B
falls	O
across	O
two	O
background	O
planes	B
whose	O
orientation	O
relative	O
to	O
the	O
cam-	O
era	O
is	O
known	O
(	O
or	O
inferred	O
during	O
pre-calibration	O
)	O
,	O
the	O
plane	O
equation	O
for	O
each	O
stripe	O
can	O
be	O
inferred	O
from	O
the	O
two	O
projected	O
lines	B
,	O
whose	O
3d	O
equations	B
are	O
known	O
(	O
figure	O
12.6b	O
)	O
.	O
the	O
deformation	O
of	O
the	O
shadow	B
as	O
it	O
crosses	O
the	O
object	O
being	O
scanned	O
then	O
reveals	O
its	O
3d	O
shape	O
,	O
as	O
with	O
regular	O
light	B
stripe	I
rangeﬁnding	O
(	O
exercise	O
12.2	O
)	O
.	O
this	O
technique	O
can	O
also	O
be	O
used	O
to	O
estimate	O
the	O
3d	O
geometry	O
of	O
a	O
background	O
scene	O
and	O
how	O
its	O
appearance	O
varies	O
as	O
it	O
moves	O
into	O
shadow	B
,	O
in	O
order	B
to	O
cast	O
new	O
shadows	O
onto	O
the	O
scene	O
(	O
chuang	O
,	O
goldman	O
,	O
curless	O
et	O
al	O
.	O
12.2	O
active	O
rangeﬁnding	O
2003	O
)	O
(	O
section	O
10.4.3	O
)	O
.	O
587	O
the	O
time	O
it	O
takes	O
to	O
scan	O
an	O
object	O
using	O
a	O
light	B
stripe	I
technique	O
is	O
proportional	O
to	O
the	O
number	O
of	O
depth	O
planes	O
used	O
,	O
which	O
is	O
usually	O
comparable	O
to	O
the	O
number	O
of	O
pixels	O
across	O
an	O
image	B
.	O
a	O
much	O
faster	O
scanner	O
can	O
be	O
constructed	O
by	O
turning	O
different	O
projector	O
pixels	O
on	O
and	O
off	O
in	O
a	O
structured	O
manner	O
,	O
e.g.	O
,	O
using	O
a	O
binary	O
or	O
gray	O
code	O
(	O
besl	O
1989	O
)	O
.	O
for	O
example	O
,	O
let	O
us	O
assume	O
that	O
the	O
lcd	O
projector	O
we	O
are	O
using	O
has	O
1024	O
columns	O
of	O
pixels	O
.	O
taking	O
the	O
10-bit	O
binary	O
code	O
corresponding	O
to	O
each	O
column	O
’	O
s	O
address	O
(	O
0	O
.	O
.	O
.	O
1023	O
)	O
,	O
we	O
project	O
the	O
ﬁrst	O
bit	O
,	O
then	O
the	O
second	O
,	O
etc	O
.	O
after	O
10	O
projections	B
(	O
e.g.	O
,	O
a	O
third	O
of	O
a	O
second	O
for	O
a	O
synchronized	O
30hz	O
camera-projector	O
system	O
)	O
,	O
each	O
pixel	O
in	O
the	O
camera	B
knows	O
which	O
of	O
the	O
1024	O
columns	O
of	O
projector	O
light	O
it	O
is	O
seeing	O
.	O
a	O
similar	O
approach	O
can	O
also	O
be	O
used	O
to	O
estimate	O
the	O
refractive	O
properties	B
of	O
an	O
object	O
by	O
placing	O
a	O
monitor	O
behind	O
the	O
object	O
(	O
zongker	O
,	O
werner	O
,	O
curless	O
et	O
al	O
.	O
1999	O
;	O
chuang	O
,	O
zongker	O
,	O
hindorff	O
et	O
al	O
.	O
2000	O
)	O
(	O
section	O
13.4	O
)	O
.	O
very	O
fast	O
scanners	O
can	O
also	O
be	O
constructed	O
with	O
a	O
single	O
laser	O
beam	O
,	O
i.e.	O
,	O
a	O
real-time	O
ﬂying	O
spot	O
optical	O
triangulation	O
scanner	O
(	O
rioux	O
,	O
bechthold	O
,	O
taylor	O
et	O
al	O
.	O
1987	O
)	O
.	O
if	O
even	O
faster	O
,	O
i.e.	O
,	O
frame-rate	O
,	O
scanning	O
is	O
required	O
,	O
we	O
can	O
project	O
a	O
single	O
textured	O
pat-	O
tern	O
into	O
the	O
scene	O
.	O
proesmans	O
,	O
van	O
gool	O
,	O
and	O
defoort	O
(	O
1998	O
)	O
describe	O
a	O
system	O
where	O
a	O
checkerboard	O
grid	O
is	O
projected	O
onto	O
an	O
object	O
(	O
e.g.	O
,	O
a	O
person	O
’	O
s	O
face	B
)	O
and	O
the	O
deformation	O
of	O
the	O
grid	O
is	O
used	O
to	O
infer	O
3d	O
shape	O
.	O
unfortunately	O
,	O
such	O
a	O
technique	O
only	O
works	O
if	O
the	O
surface	B
is	O
continuous	O
enough	O
to	O
link	O
all	O
of	O
the	O
grid	O
points	B
.	O
a	O
much	O
better	O
system	O
can	O
be	O
constructed	O
using	O
high-speed	O
custom	O
illumination	O
and	O
sens-	O
ing	O
hardware	O
.	O
iddan	O
and	O
yahav	O
(	O
2001	O
)	O
describe	O
the	O
construction	O
of	O
their	O
3dv	O
zcam	O
video-	O
rate	O
depth	O
sensing	O
camera	B
,	O
which	O
projects	O
a	O
pulsed	O
plane	O
of	O
light	O
onto	O
the	O
scene	O
and	O
then	O
integrates	O
the	O
returning	O
light	O
for	O
a	O
short	O
interval	O
,	O
essentially	O
obtaining	O
time-of-ﬂight	O
mea-	O
surement	O
for	O
the	O
distance	O
to	O
individual	O
pixels	O
in	O
the	O
scene	O
.	O
a	O
good	O
description	O
of	O
earlier	O
time-of-ﬂight	O
systems	O
,	O
including	O
amplitude	O
and	O
frequency	O
modulation	O
schemes	O
for	O
lidar	O
,	O
can	O
be	O
found	O
in	O
(	O
besl	O
1989	O
)	O
.	O
instead	O
of	O
using	O
a	O
single	O
camera	O
,	O
it	O
is	O
also	O
possible	O
to	O
construct	O
an	O
active	B
illumination	I
range	O
sensor	B
using	O
stereo	B
imaging	O
setups	O
.	O
the	O
simplest	O
way	O
to	O
do	O
this	O
is	O
to	O
just	O
project	O
ran-	O
dom	O
stripe	O
patterns	B
onto	O
the	O
scene	O
to	O
create	O
synthetic	O
texture	B
,	O
which	O
helps	O
match	O
textureless	O
surfaces	O
(	O
kang	O
,	O
webb	O
,	O
zitnick	O
et	O
al	O
.	O
1995	O
)	O
.	O
projecting	O
a	O
known	O
series	O
of	O
stripes	O
,	O
just	O
as	O
in	O
coded	B
pattern	I
single-camera	O
rangeﬁnding	O
,	O
makes	O
the	O
correspondence	B
between	O
pixels	O
unam-	O
biguous	O
and	O
allows	O
for	O
the	O
recovery	B
of	O
depth	O
estimates	O
at	O
pixels	O
only	O
seen	O
in	O
a	O
single	O
camera	O
(	O
scharstein	O
and	O
szeliski	O
2003	O
)	O
.	O
this	O
technique	O
has	O
been	O
used	O
to	O
produce	O
large	O
numbers	O
of	O
highly	O
accurate	O
registered	O
multi-image	O
stereo	B
pairs	O
and	O
depth	O
maps	O
for	O
the	O
purpose	O
of	O
eval-	O
uating	O
stereo	B
correspondence	O
algorithms	O
(	O
scharstein	O
and	O
szeliski	O
2002	O
;	O
hirschm¨uller	O
and	O
scharstein	O
2009	O
)	O
and	O
learning	B
depth	O
map	O
priors	O
and	O
parameters	B
(	O
scharstein	O
and	O
pal	O
2007	O
)	O
.	O
while	O
projecting	O
multiple	B
patterns	O
usually	O
requires	O
the	O
scene	O
or	O
object	O
to	O
remain	O
still	O
,	O
ad-	O
ditional	O
processing	O
can	O
enable	O
the	O
production	O
of	O
real-time	O
depth	O
maps	O
for	O
dynamic	O
scenes	O
.	O
588	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
12.7	O
real-time	O
dense	O
3d	O
face	B
capture	O
using	O
spacetime	O
stereo	B
(	O
zhang	O
,	O
snavely	O
,	O
cur-	O
less	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
(	O
a	O
)	O
set	O
of	O
ﬁve	O
consecutive	O
video	B
frames	O
from	O
one	O
of	O
two	O
stereo	O
cameras	O
(	O
every	O
ﬁfth	O
frame	O
is	O
free	O
of	O
stripe	O
patterns	B
,	O
in	O
order	B
to	O
extract	O
texture	B
)	O
;	O
(	O
b	O
)	O
resulting	O
high-quality	O
3d	O
surface	B
model	O
(	O
depth	B
map	I
visualized	O
as	O
a	O
shaded	O
rendering	B
)	O
.	O
the	O
basic	O
idea	O
(	O
davis	O
,	O
ramamoorthi	O
,	O
and	O
rusinkiewicz	O
2003	O
;	O
zhang	O
,	O
curless	O
,	O
and	O
seitz	O
2003	O
)	O
is	O
to	O
assume	O
that	O
depth	O
is	O
nearly	O
constant	O
within	O
a	O
3d	O
space–time	O
window	O
around	O
each	O
pixel	O
and	O
to	O
use	O
the	O
3d	O
window	O
for	O
matching	O
and	O
reconstruction	O
.	O
depending	O
on	O
the	O
surface	B
shape	O
and	O
motion	B
,	O
this	O
assumption	O
may	O
be	O
error-prone	O
,	O
as	O
shown	O
in	O
(	O
davis	O
,	O
nahab	O
,	O
ramamoorthi	O
et	O
al	O
.	O
2005	O
)	O
.	O
to	O
model	O
shapes	O
more	O
accurately	O
,	O
zhang	O
,	O
curless	O
,	O
and	O
seitz	O
(	O
2003	O
)	O
model	O
the	O
linear	B
disparity	O
variation	O
within	O
the	O
space–time	O
window	O
and	O
show	O
that	O
bet-	O
ter	O
results	O
can	O
be	O
obtained	O
by	O
globally	O
optimizing	O
disparity	O
and	O
disparity	O
gradient	O
estimates	O
over	O
video	O
volumes	O
(	O
zhang	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2004	O
)	O
.	O
figure	O
12.7	O
shows	O
the	O
results	O
of	O
applying	O
this	O
system	O
to	O
a	O
person	O
’	O
s	O
face	B
;	O
the	O
frame-rate	O
3d	O
surface	B
model	O
can	O
then	O
be	O
used	O
for	O
further	O
model-based	B
ﬁtting	O
and	O
computer	O
graphics	O
manipulation	O
(	O
section	O
12.6.2	O
)	O
.	O
12.2.1	O
range	O
data	O
merging	B
while	O
individual	O
range	O
images	O
can	O
be	O
useful	O
for	O
applications	O
such	O
as	O
real-time	O
z-keying	B
or	O
fa-	O
cial	O
motion	B
capture	O
,	O
they	O
are	O
often	O
used	O
as	O
building	O
blocks	O
for	O
more	O
complete	O
3d	O
object	O
mod-	O
eling	O
.	O
in	O
such	O
applications	O
,	O
the	O
next	O
two	O
steps	O
in	O
processing	O
are	O
the	O
registration	B
(	O
alignment	B
)	O
of	O
partial	O
3d	O
surface	B
models	O
and	O
their	O
integration	O
into	O
coherent	O
3d	O
surfaces	O
(	O
curless	O
1999	O
)	O
.	O
if	O
desired	O
,	O
this	O
can	O
be	O
followed	O
by	O
a	O
model	O
ﬁtting	O
stage	O
using	O
either	O
parametric	B
representations	O
such	O
as	O
generalized	B
cylinders	O
(	O
agin	O
and	O
binford	O
1976	O
;	O
nevatia	O
and	O
binford	O
1977	O
;	O
marr	O
and	O
nishihara	O
1978	O
;	O
brooks	O
1981	O
)	O
,	O
superquadrics	O
(	O
pentland	O
1986	O
;	O
solina	O
and	O
bajcsy	O
1990	O
;	O
ter-	O
zopoulos	O
and	O
metaxas	O
1991	O
)	O
,	O
or	O
non-parametric	B
models	O
such	O
as	O
triangular	O
meshes	O
(	O
boissonat	O
1984	O
)	O
or	O
physically-based	O
models	O
(	O
terzopoulos	O
,	O
witkin	O
,	O
and	O
kass	O
1988	O
;	O
delingette	O
,	O
hebert	O
,	O
and	O
ikeuichi	O
1992	O
;	O
terzopoulos	O
and	O
metaxas	O
1991	O
;	O
mcinerney	O
and	O
terzopoulos	O
1993	O
;	O
ter-	O
zopoulos	O
1999	O
)	O
.	O
a	O
number	O
of	O
techniques	O
have	O
also	O
been	O
developed	O
for	O
segmenting	O
range	O
images	O
into	O
simpler	O
constituent	O
surfaces	O
(	O
hoover	O
,	O
jean-baptiste	O
,	O
jiang	O
et	O
al	O
.	O
1996	O
)	O
.	O
the	O
most	O
widely	O
used	O
3d	O
registration	B
technique	O
is	O
the	O
iterated	O
closest	O
point	O
(	O
icp	O
)	O
algo-	O
12.2	O
active	O
rangeﬁnding	O
589	O
rithm	O
,	O
which	O
alternates	O
between	O
ﬁnding	O
the	O
closest	O
point	O
matches	O
between	O
the	O
two	O
surfaces	O
being	O
aligned	O
and	O
then	O
solving	O
a	O
3d	O
absolute	B
orientation	I
problem	O
(	O
section	O
6.1.5	O
,	O
(	O
6.31–6.32	O
)	O
(	O
besl	O
and	O
mckay	O
1992	O
;	O
chen	O
and	O
medioni	O
1992	O
;	O
zhang	O
1994	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
gold	O
,	O
rangarajan	O
,	O
lu	O
et	O
al	O
.	O
1998	O
;	O
david	O
,	O
dementhon	O
,	O
duraiswami	O
et	O
al	O
.	O
2004	O
;	O
li	O
and	O
hart-	O
ley	O
2007	O
;	O
enqvist	O
,	O
josephson	O
,	O
and	O
kahl	O
2009	O
)	O
.3	O
since	O
the	O
two	O
surfaces	O
being	O
aligned	O
usually	O
only	O
have	O
partial	O
overlap	O
and	O
may	O
also	O
have	O
outliers	O
,	O
robust	B
matching	O
criteria	O
(	O
section	O
6.1.4	O
and	O
appendix	O
b.3	O
)	O
are	O
typically	O
used	O
.	O
in	O
order	B
to	O
speed	O
up	O
the	O
determination	O
of	O
the	O
closest	O
point	O
,	O
and	O
also	O
to	O
make	O
the	O
distance-to-surface	O
computation	O
more	O
accurate	O
,	O
one	O
of	O
the	O
two	O
point	O
sets	O
(	O
e.g.	O
,	O
the	O
current	O
merged	O
model	O
)	O
can	O
be	O
converted	O
into	O
a	O
signed	B
distance	O
function	O
,	O
optionally	O
represented	O
using	O
an	O
octree	B
spline	O
for	O
compactness	O
(	O
lavall´ee	O
and	O
szeliski	O
1995	O
)	O
.	O
variants	O
on	O
the	O
basic	O
icp	O
algorithm	B
can	O
be	O
used	O
to	O
register	O
3d	O
point	O
sets	O
under	O
non-rigid	B
de-	O
formations	O
,	O
e.g.	O
,	O
for	O
medical	O
applications	O
(	O
feldmar	O
and	O
ayache	O
1996	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
)	O
.	O
color	B
values	O
associated	O
with	O
the	O
points	B
or	O
range	O
measurements	O
can	O
also	O
be	O
used	O
as	O
part	O
of	O
the	O
registration	B
process	O
to	O
improve	O
robustness	O
(	O
johnson	O
and	O
kang	O
1997	O
;	O
pulli	O
1999	O
)	O
.	O
unfortunately	O
,	O
the	O
icp	O
algorithm	B
and	O
its	O
variants	O
can	O
only	O
ﬁnd	O
a	O
locally	O
optimal	O
alignment	B
between	O
3d	O
surfaces	O
.	O
if	O
this	O
is	O
not	O
known	O
a	O
priori	O
,	O
more	O
global	B
correspondence	O
or	O
search	O
techniques	O
,	O
based	O
on	O
local	B
descriptors	O
invariant	O
to	O
3d	O
rigid	O
transformations	O
,	O
need	O
to	O
be	O
used	O
.	O
an	O
example	O
of	O
such	O
a	O
descriptor	O
is	O
the	O
spin	O
image	B
,	O
which	O
is	O
a	O
local	B
circular	O
projection	O
of	O
a	O
3d	O
surface	B
patch	O
around	O
the	O
local	B
normal	O
axis	O
(	O
johnson	O
and	O
hebert	O
1999	O
)	O
.	O
another	O
(	O
earlier	O
)	O
example	O
is	O
the	O
splash	O
representation	O
introduced	O
by	O
stein	O
and	O
medioni	O
(	O
1992	O
)	O
.	O
once	O
two	O
or	O
more	O
3d	O
surfaces	O
have	O
been	O
aligned	O
,	O
they	O
can	O
be	O
merged	O
into	O
a	O
single	O
model	O
.	O
one	O
approach	O
is	O
to	O
represent	O
each	O
surface	B
using	O
a	O
triangulated	O
mesh	O
and	O
combine	O
these	O
meshes	O
using	O
a	O
process	O
that	O
is	O
sometimes	O
called	O
zippering	O
(	O
soucy	O
and	O
laurendeau	O
1992	O
;	O
turk	O
and	O
levoy	O
1994	O
)	O
.	O
another	O
,	O
now	O
more	O
widely	O
used	O
,	O
approach	O
is	O
to	O
compute	O
a	O
signed	B
distance	O
function	O
that	O
ﬁts	O
all	O
of	O
the	O
3d	O
data	O
points	O
(	O
hoppe	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1992	O
;	O
curless	O
and	O
levoy	O
1996	O
;	O
hilton	O
,	O
stoddart	O
,	O
illingworth	O
et	O
al	O
.	O
1996	O
;	O
wheeler	O
,	O
sato	O
,	O
and	O
ikeuchi	O
1998	O
)	O
.	O
figure	O
12.8	O
shows	O
one	O
such	O
approach	O
,	O
the	O
volumetric	B
range	O
image	B
processing	O
(	O
vrip	O
)	O
technique	O
developed	O
by	O
curless	O
and	O
levoy	O
(	O
1996	O
)	O
,	O
which	O
ﬁrst	O
computes	O
a	O
weighted	B
signed	O
distance	O
function	O
from	O
each	O
range	O
image	O
and	O
then	O
merges	O
them	O
using	O
a	O
weighted	B
averaging	O
process	O
.	O
to	O
make	O
the	O
representation	O
more	O
compact	O
,	O
run-length	O
coding	O
is	O
used	O
to	O
encode	O
the	O
empty	O
,	O
seen	O
,	O
and	O
varying	O
(	O
signed	B
distance	O
)	O
voxels	O
,	O
and	O
only	O
the	O
signed	B
distance	O
values	O
near	O
each	O
surface	B
are	O
stored.4	O
once	O
the	O
merged	O
signed	B
distance	O
function	O
has	O
been	O
computed	O
,	O
a	O
zero-crossing	O
surface	B
extraction	O
algorithm	B
,	O
such	O
as	O
marching	B
cubes	I
(	O
lorensen	O
and	O
cline	O
1987	O
)	O
,	O
can	O
be	O
used	O
to	O
recover	O
a	O
meshed	O
surface	B
model	O
.	O
figure	O
12.9	O
shows	O
an	O
example	O
of	O
the	O
3	O
some	O
techniques	O
,	O
such	O
as	O
the	O
one	O
developed	O
by	O
chen	O
and	O
medioni	O
(	O
1992	O
)	O
,	O
use	O
local	B
surface	O
tangent	O
planes	B
to	O
make	O
this	O
computation	O
more	O
accurate	O
and	O
to	O
accelerate	O
convergence	O
.	O
4	O
an	O
alternative	O
,	O
even	O
more	O
compact	O
,	O
representation	O
could	O
be	O
to	O
use	O
octrees	O
(	O
lavall´ee	O
and	O
szeliski	O
1995	O
)	O
.	O
590	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
12.8	O
range	O
data	O
merging	B
(	O
curless	O
and	O
levoy	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
:	O
(	O
a	O
)	O
two	O
signed	O
distance	O
functions	O
(	O
top	O
left	O
)	O
are	O
merged	O
with	O
their	O
(	O
weights	O
)	O
bottom	O
left	O
to	O
produce	O
a	O
com-	O
bined	O
set	O
of	O
functions	O
(	O
right	O
column	O
)	O
from	O
which	O
an	O
isosurface	O
can	O
be	O
extracted	O
(	O
green	O
dashed	O
line	O
)	O
;	O
(	O
b	O
)	O
the	O
signed	B
distance	O
functions	O
are	O
combined	O
with	O
empty	O
and	O
unseen	O
space	O
labels	O
to	O
ﬁll	O
holes	O
in	O
the	O
isosurface	O
.	O
complete	O
range	O
data	O
merging	B
and	O
isosurface	O
extraction	O
pipeline	B
.	O
volumetric	B
range	O
data	O
merging	O
techniques	O
based	O
on	O
signed	B
distance	O
or	O
characteristic	O
(	O
inside–outside	O
)	O
functions	O
are	O
also	O
widely	O
used	O
to	O
extract	O
smooth	O
well-behaved	O
surfaces	O
from	O
oriented	B
or	O
unoriented	O
sets	O
of	O
points	B
(	O
hoppe	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1992	O
;	O
ohtake	O
,	O
belyaev	O
,	O
alexa	O
et	O
al	O
.	O
2003	O
;	O
kazhdan	O
,	O
bolitho	O
,	O
and	O
hoppe	O
2006	O
;	O
lempitsky	O
and	O
boykov	O
2007	O
;	O
zach	O
,	O
pock	O
,	O
and	O
bischof	O
2007b	O
;	O
zach	O
2008	O
)	O
,	O
as	O
discussed	O
in	O
more	O
detail	O
in	O
section	O
12.5.1	O
.	O
12.2.2	O
application	O
:	O
digital	B
heritage	I
active	O
rangeﬁnding	O
technologies	O
,	O
combined	O
with	O
surface	O
modeling	B
and	O
appearance	O
model-	O
ing	O
techniques	O
(	O
section	O
12.7	O
)	O
,	O
are	O
widely	O
used	O
in	O
the	O
ﬁelds	O
of	O
archeological	O
and	O
historical	O
preservation	O
,	O
which	O
often	O
also	O
goes	O
under	O
the	O
name	O
digital	B
heritage	I
(	O
macdonald	O
2006	O
)	O
.	O
in	O
such	O
applications	O
,	O
detailed	O
3d	O
models	O
of	O
cultural	O
objects	O
are	O
acquired	O
and	O
later	O
used	O
for	O
ap-	O
plications	O
such	O
as	O
analysis	O
,	O
preservation	O
,	O
restoration	O
,	O
and	O
the	O
production	O
of	O
duplicate	O
artwork	O
(	O
rioux	O
and	O
bird	O
1993	O
)	O
.	O
a	O
more	O
recent	O
example	O
of	O
such	O
an	O
endeavor	O
is	O
the	O
digital	O
michelangelo	O
project	O
of	O
levoy	O
,	O
pulli	O
,	O
curless	O
et	O
al	O
.	O
(	O
2000	O
)	O
,	O
which	O
used	O
cyberware	O
laser	O
stripe	O
scanners	O
and	O
high-quality	O
digital	O
slr	O
cameras	O
mounted	O
on	O
a	O
large	O
gantry	O
to	O
obtain	O
detailed	O
scans	O
of	O
michelangelo	O
’	O
s	O
david	O
and	O
other	O
sculptures	O
in	O
florence	O
.	O
the	O
project	O
also	O
took	O
scans	O
of	O
the	O
forma	O
urbis	O
romae	O
,	O
an	O
ancient	O
stone	O
map	O
of	O
rome	O
that	O
had	O
shattered	O
into	O
pieces	O
,	O
for	O
which	O
new	O
matches	O
were	O
obtained	O
using	O
digital	O
techniques	O
.	O
the	O
whole	O
process	O
,	O
from	O
initial	O
planning	O
,	O
to	O
software	O
12.3	O
surface	B
representations	O
591	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
12.9	O
reconstruction	O
and	O
hardcopy	O
of	O
the	O
“	O
happy	O
buddha	O
”	O
statuette	O
(	O
curless	O
and	O
levoy	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
:	O
(	O
a	O
)	O
photograph	O
of	O
the	O
original	O
statue	O
after	O
spray	O
painting	O
with	O
matte	O
gray	O
;	O
(	O
b	O
)	O
partial	O
range	O
scan	O
;	O
(	O
c	O
)	O
merged	O
range	O
scans	O
;	O
(	O
d	O
)	O
colored	O
rendering	B
of	O
the	O
recon-	O
structed	O
model	O
;	O
(	O
e	O
)	O
hardcopy	O
of	O
the	O
model	O
constructed	O
using	O
stereolithography	O
.	O
development	O
,	O
acquisition	O
,	O
and	O
post-processing	O
,	O
took	O
several	O
years	O
(	O
and	O
many	O
volunteers	O
)	O
,	O
and	O
produced	O
a	O
wealth	O
of	O
3d	O
shape	O
and	O
appearance	O
modeling	B
techniques	O
as	O
a	O
result	O
.	O
even	O
larger-scale	O
projects	O
are	O
now	O
being	O
attempted	O
,	O
for	O
example	O
,	O
the	O
scanning	O
of	O
com-	O
plete	O
temple	O
sites	O
such	O
as	O
angkor-thom	O
(	O
ikeuchi	O
and	O
sato	O
2001	O
;	O
ikeuchi	O
and	O
miyazaki	O
2007	O
;	O
banno	O
,	O
masuda	O
,	O
oishi	O
et	O
al	O
.	O
2008	O
)	O
.	O
figure	O
12.10	O
shows	O
details	O
from	O
this	O
project	O
,	O
including	O
a	O
sample	O
photograph	O
,	O
a	O
detailed	O
3d	O
(	O
sculptural	O
)	O
head	B
model	O
scanned	O
from	O
ground	O
level	O
,	O
and	O
an	O
aerial	O
overview	O
of	O
the	O
ﬁnal	O
merged	O
3d	O
site	O
model	O
,	O
which	O
was	O
acquired	O
using	O
a	O
balloon	O
.	O
12.3	O
surface	B
representations	O
in	O
previous	O
sections	O
,	O
we	O
have	O
seen	O
different	O
representations	O
being	O
used	O
to	O
integrate	O
3d	O
range	O
scans	O
.	O
we	O
now	O
look	O
at	O
several	O
of	O
these	O
representations	O
in	O
more	O
detail	O
.	O
explicit	O
surface	B
representations	O
,	O
such	O
as	O
triangle	O
meshes	O
,	O
splines	B
(	O
farin	O
1992	O
,	O
1996	O
)	O
,	O
and	O
subdivision	O
sur-	O
faces	B
(	O
stollnitz	O
,	O
derose	O
,	O
and	O
salesin	O
1996	O
;	O
zorin	O
,	O
schr¨oder	O
,	O
and	O
sweldens	O
1996	O
;	O
warren	O
and	O
weimer	O
2001	O
;	O
peters	O
and	O
reif	O
2008	O
)	O
,	O
enable	O
not	O
only	O
the	O
creation	O
of	O
highly	O
detailed	O
models	O
but	O
also	O
processing	O
operations	O
,	O
such	O
as	O
interpolation	B
(	O
section	O
12.3.1	O
)	O
,	O
fairing	O
or	O
smoothing	B
,	O
and	O
decimation	O
and	O
simpliﬁcation	B
(	O
section	O
12.3.2	O
)	O
.	O
we	O
also	O
examine	O
discrete	B
point-based	O
representations	O
(	O
section	O
12.4	O
)	O
and	O
volumetric	B
representations	O
(	O
section	O
12.5	O
)	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
592	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
12.10	O
laser	O
range	O
modeling	O
of	O
the	O
bayon	O
temple	O
at	O
angkor-thom	O
(	O
banno	O
,	O
masuda	O
,	O
oishi	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
springer	O
:	O
(	O
a	O
)	O
sample	O
photograph	O
from	O
the	O
site	O
;	O
(	O
b	O
)	O
a	O
detailed	O
head	B
model	O
scanned	O
from	O
the	O
ground	O
;	O
(	O
c	O
)	O
ﬁnal	O
merged	O
3d	O
model	O
of	O
the	O
temple	O
scanned	O
using	O
a	O
laser	O
range	O
sensor	O
mounted	O
on	O
a	O
balloon	O
.	O
12.3.1	O
surface	B
interpolation	O
one	O
of	O
the	O
most	O
common	O
operations	O
on	O
surfaces	O
is	O
their	O
reconstruction	O
from	O
a	O
set	O
of	O
sparse	B
data	O
constraints	O
,	O
i.e	O
.	O
scattered	O
data	O
interpolation	O
.	O
when	O
formulating	O
such	O
problems	O
,	O
surfaces	O
may	O
be	O
parameterized	O
as	O
height	O
ﬁelds	O
f	O
(	O
x	O
)	O
,	O
as	O
3d	O
parametric	B
surfaces	O
f	O
(	O
x	O
)	O
,	O
or	O
as	O
non-	O
parametric	B
models	O
such	O
as	O
collections	O
of	O
triangles	O
.	O
in	O
the	O
section	O
on	O
image	B
processing	O
,	O
we	O
saw	O
how	O
two-dimensional	B
function	O
interpolation	B
and	O
approximation	O
problems	O
{	O
di	O
}	O
→	O
f	O
(	O
x	O
)	O
could	O
be	O
cast	O
as	O
energy	O
minimization	O
problems	O
using	O
regularization	O
(	O
section	O
3.7.1	O
(	O
3.94–3.98	O
)	O
.5	O
such	O
problems	O
can	O
also	O
specify	O
the	O
locations	O
of	O
discontinuities	O
in	O
the	O
surface	B
as	O
well	O
as	O
local	B
orientation	O
constraints	O
(	O
terzopoulos	O
1986b	O
;	O
zhang	O
,	O
dugas-phocion	O
,	O
samson	O
et	O
al	O
.	O
2002	O
)	O
.	O
one	O
approach	O
to	O
solving	O
such	O
problems	O
is	O
to	O
discretize	O
both	O
the	O
surface	B
and	O
the	O
energy	O
on	O
a	O
discrete	B
grid	O
or	O
mesh	O
using	O
ﬁnite	O
element	O
analysis	O
(	O
3.100–3.102	O
)	O
(	O
terzopoulos	O
1986b	O
)	O
.	O
such	O
problems	O
can	O
then	O
be	O
solved	O
using	O
sparse	O
system	O
solving	O
techniques	O
,	O
such	O
as	O
multigrid	O
(	O
briggs	O
,	O
henson	O
,	O
and	O
mccormick	O
2000	O
)	O
or	O
hierarchically	O
preconditioned	B
conjugate	O
gradient	O
(	O
szeliski	O
2006b	O
)	O
.	O
the	O
surface	B
can	O
also	O
be	O
represented	O
using	O
a	O
hierarchical	B
combination	O
of	O
multilevel	B
b-splines	O
(	O
lee	O
,	O
wolberg	O
,	O
and	O
shin	O
1996	O
)	O
.	O
an	O
alternative	O
approach	O
is	O
to	O
use	O
radial	B
basis	O
(	O
or	O
kernel	B
)	O
functions	O
(	O
boult	O
and	O
kender	O
1986	O
;	O
nielson	O
1993	O
)	O
.	O
to	O
interpolate	O
a	O
ﬁeld	O
f	O
(	O
x	O
)	O
through	O
(	O
or	O
near	O
)	O
a	O
number	O
of	O
data	O
values	O
di	O
located	O
at	O
xi	O
,	O
the	O
radial	B
basis	O
function	O
approach	O
uses	O
f	O
(	O
x	O
)	O
=	O
(	O
cid:80	O
)	O
i	O
wi	O
(	O
x	O
)	O
di	O
(	O
cid:80	O
)	O
i	O
wi	O
(	O
x	O
)	O
,	O
(	O
12.6	O
)	O
5	O
the	O
difference	B
between	O
interpolation	B
and	O
approximation	O
is	O
that	O
the	O
former	O
requires	O
the	O
surface	B
or	O
function	O
to	O
pass	O
through	O
the	O
data	O
while	O
the	O
latter	O
allows	O
the	O
function	O
to	O
pass	O
near	O
the	O
data	O
,	O
and	O
can	O
therefore	O
be	O
used	O
for	O
surface	O
smoothing	B
as	O
well	O
.	O
12.3	O
surface	B
representations	O
where	O
the	O
weights	O
,	O
wi	O
(	O
x	O
)	O
=	O
k	O
(	O
(	O
cid:107	O
)	O
x	O
−	O
xi	O
(	O
cid:107	O
)	O
)	O
,	O
593	O
(	O
12.7	O
)	O
are	O
computed	O
using	O
a	O
radial	B
basis	O
(	O
spherically	O
symmetrical	O
)	O
function	O
k	O
(	O
r	O
)	O
.	O
if	O
we	O
want	O
the	O
function	O
f	O
(	O
x	O
)	O
to	O
exactly	O
interpolate	O
the	O
data	O
points	O
,	O
the	O
kernel	B
functions	O
must	O
either	O
be	O
singular	O
at	O
the	O
origin	O
,	O
limr→0	O
k	O
(	O
r	O
)	O
→	O
∞	O
(	O
nielson	O
1993	O
)	O
,	O
or	O
a	O
dense	O
linear	O
system	O
must	O
be	O
solved	O
to	O
determine	O
the	O
magnitude	O
associated	O
with	O
each	O
basis	O
function	O
(	O
boult	O
and	O
kender	O
1986	O
)	O
.	O
it	O
turns	O
out	O
that	O
,	O
for	O
certain	O
regularized	O
problems	O
,	O
e.g.	O
,	O
(	O
3.94–3.96	O
)	O
,	O
there	O
exist	O
radial	B
basis	O
functions	O
(	O
kernels	O
)	O
that	O
give	O
the	O
same	O
results	O
as	O
a	O
full	O
analytical	O
solution	O
(	O
boult	O
and	O
kender	O
1986	O
)	O
.	O
unfortunately	O
,	O
because	O
the	O
dense	O
system	O
solving	O
is	O
cubic	B
in	O
the	O
number	O
of	O
data	O
points	O
,	O
basis	O
function	O
approaches	O
can	O
only	O
be	O
used	O
for	O
small	O
problems	O
such	O
as	O
feature-based	B
image	O
morphing	B
(	O
beier	O
and	O
neely	O
1992	O
)	O
.	O
when	O
a	O
three-dimensional	O
parametric	B
surface	O
is	O
being	O
modeled	O
,	O
the	O
vector-valued	O
func-	O
tion	B
f	O
in	O
(	O
12.6	O
)	O
or	O
(	O
3.94–3.102	O
)	O
encodes	O
3d	O
coordinates	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
on	O
the	O
surface	B
and	O
the	O
domain	O
x	O
=	O
(	O
s	O
,	O
t	O
)	O
encodes	O
the	O
surface	B
parameterization	O
.	O
one	O
example	O
of	O
such	O
surfaces	O
are	O
symmetry-seeking	B
parametric	O
models	O
,	O
which	O
are	O
elastically	O
deformable	O
versions	O
of	O
general-	O
ized	O
cylinders6	O
(	O
terzopoulos	O
,	O
witkin	O
,	O
and	O
kass	O
1987	O
)	O
.	O
in	O
these	O
models	O
,	O
s	O
is	O
the	O
parameter	O
along	O
the	O
spine	O
of	O
the	O
deformable	O
tube	O
and	O
t	O
is	O
the	O
parameter	O
around	O
the	O
tube	O
.	O
a	O
variety	O
of	O
smoothness	B
and	O
radial	B
symmetry	O
forces	O
are	O
used	O
to	O
constrain	O
the	O
model	O
while	O
it	O
is	O
ﬁtted	O
to	O
image-based	B
silhouette	O
curves	O
.	O
it	O
is	O
also	O
possible	O
to	O
deﬁne	O
non-parametric	B
surface	O
models	O
such	O
as	O
general	O
triangulated	O
meshes	O
and	O
to	O
equip	O
such	O
meshes	O
(	O
using	O
ﬁnite	O
element	O
analysis	O
)	O
with	O
both	O
internal	O
smooth-	O
ness	O
metrics	O
and	O
external	O
data	O
ﬁtting	O
metrics	O
(	O
sander	O
and	O
zucker	O
1990	O
;	O
fua	O
and	O
sander	O
1992	O
;	O
delingette	O
,	O
hebert	O
,	O
and	O
ikeuichi	O
1992	O
;	O
mcinerney	O
and	O
terzopoulos	O
1993	O
)	O
.	O
while	O
most	O
of	O
these	O
approaches	O
assume	O
a	O
standard	O
elastic	O
deformation	O
model	O
,	O
which	O
uses	O
quadratic	O
inter-	O
nal	O
smoothness	B
terms	O
,	O
it	O
is	O
also	O
possible	O
to	O
use	O
sub-linear	O
energy	O
models	O
in	O
order	B
to	O
better	O
preserve	O
surface	B
creases	O
(	O
diebel	O
,	O
thrun	O
,	O
and	O
br¨unig	O
2006	O
)	O
.	O
triangle	O
meshes	O
can	O
also	O
be	O
aug-	O
mented	O
with	O
either	O
spline	B
elements	O
(	O
sullivan	O
and	O
ponce	O
1998	O
)	O
or	O
subdivision	O
surfaces	O
(	O
stoll-	O
nitz	O
,	O
derose	O
,	O
and	O
salesin	O
1996	O
;	O
zorin	O
,	O
schr¨oder	O
,	O
and	O
sweldens	O
1996	O
;	O
warren	O
and	O
weimer	O
2001	O
;	O
peters	O
and	O
reif	O
2008	O
)	O
to	O
produce	O
surfaces	O
with	O
better	O
smoothness	B
control	O
.	O
both	O
parametric	B
and	O
non-parametric	B
surface	O
models	O
assume	O
that	O
the	O
topology	O
of	O
the	O
sur-	O
face	B
is	O
known	O
and	O
ﬁxed	O
ahead	O
of	O
time	O
.	O
for	O
more	O
ﬂexible	O
surface	B
modeling	O
,	O
we	O
can	O
either	O
rep-	O
resent	O
the	O
surface	B
as	O
a	O
collection	O
of	O
oriented	B
points	O
(	O
section	O
12.4	O
)	O
or	O
use	O
3d	O
implicit	O
functions	O
(	O
section	O
12.5.1	O
)	O
,	O
which	O
can	O
also	O
be	O
combined	O
with	O
elastic	O
3d	O
surface	B
models	O
(	O
mcinerney	O
and	O
terzopoulos	O
1993	O
)	O
.	O
6	O
a	O
generalized	B
cylinder	O
(	O
brooks	O
1981	O
)	O
is	O
a	O
solid	O
of	O
revolution	O
,	O
i.e.	O
,	O
the	O
result	O
of	O
rotating	O
a	O
(	O
usually	O
smooth	O
)	O
curve	O
around	O
an	O
axis	O
.	O
it	O
can	O
also	O
be	O
generated	O
by	O
sweeping	O
a	O
slowly	O
varying	O
circular	O
cross-section	O
along	O
the	O
axis	O
.	O
(	O
these	O
two	O
interpretations	O
are	O
equivalent	O
.	O
)	O
594	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
12.11	O
progressive	O
mesh	O
representation	O
of	O
an	O
airplane	O
model	O
(	O
hoppe	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
:	O
(	O
a	O
)	O
base	O
mesh	O
m	O
0	O
(	O
150	O
faces	B
)	O
;	O
(	O
b	O
)	O
mesh	O
m	O
175	O
(	O
500	O
faces	B
)	O
;	O
(	O
c	O
)	O
mesh	O
m	O
425	O
(	O
1000	O
faces	B
)	O
;	O
(	O
d	O
)	O
original	O
mesh	O
m	O
=	O
m	O
n	O
(	O
13,546	O
faces	B
)	O
.	O
12.3.2	O
surface	B
simpliﬁcation	O
once	O
a	O
triangle	B
mesh	I
has	O
been	O
created	O
from	O
3d	O
data	O
,	O
it	O
is	O
often	O
desirable	O
to	O
create	O
a	O
hierarchy	B
of	O
mesh	O
models	O
,	O
for	O
example	O
,	O
to	O
control	O
the	O
displayed	O
level	O
of	O
detail	O
(	O
lod	O
)	O
in	O
a	O
computer	O
graphics	O
application	O
.	O
(	O
in	O
essence	O
,	O
this	O
is	O
a	O
3d	O
analog	O
to	O
image	B
pyramids	O
(	O
section	O
3.5	O
)	O
.	O
)	O
one	O
approach	O
to	O
doing	O
this	O
is	O
to	O
approximate	O
a	O
given	O
mesh	O
with	O
one	O
that	O
has	O
subdivision	O
connec-	O
tivity	O
,	O
over	O
which	O
a	O
set	O
of	O
triangular	O
wavelet	O
coefﬁcients	O
can	O
then	O
be	O
computed	O
(	O
eck	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1995	O
)	O
.	O
a	O
more	O
continuous	O
approach	O
is	O
to	O
use	O
sequential	O
edge	O
collapse	O
opera-	O
tions	O
to	O
go	O
from	O
the	O
original	O
ﬁne-resolution	O
mesh	O
to	O
a	O
coarse	O
base-level	O
mesh	O
(	O
hoppe	O
1996	O
)	O
.	O
the	O
resulting	O
progressive	O
mesh	O
(	O
pm	O
)	O
representation	O
can	O
be	O
used	O
to	O
render	O
the	O
3d	O
model	O
at	O
arbitrary	O
levels	O
of	O
detail	O
,	O
as	O
shown	O
in	O
figure	O
12.11	O
.	O
12.3.3	O
geometry	O
images	O
while	O
multi-resolution	O
surface	B
representations	O
such	O
as	O
(	O
eck	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1995	O
;	O
hoppe	O
1996	O
)	O
support	O
level	O
of	O
detail	O
operations	O
,	O
they	O
still	O
consist	O
of	O
an	O
irregular	O
collection	O
of	O
triangles	O
,	O
which	O
makes	O
them	O
more	O
difﬁcult	O
to	O
compress	O
and	O
store	O
in	O
a	O
cache-efﬁcient	O
manner.7	O
to	O
make	O
the	O
triangulation	B
completely	O
regular	O
(	O
uniform	O
and	O
gridded	O
)	O
,	O
gu	O
,	O
gortler	O
,	O
and	O
hoppe	O
(	O
2002	O
)	O
describe	O
how	O
to	O
create	O
geometry	O
images	O
by	O
cutting	O
surface	B
meshes	O
along	O
well-	O
chosen	O
lines	B
and	O
“	O
ﬂattening	O
”	O
the	O
resulting	O
representation	O
into	O
a	O
square	O
.	O
figure	O
12.12a	O
shows	O
the	O
resulting	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
values	O
of	O
the	O
surface	B
mesh	O
mapped	O
over	O
the	O
unit	O
square	O
,	O
while	O
fig-	O
ure	O
12.12b	O
shows	O
the	O
associated	O
(	O
nx	O
,	O
ny	O
,	O
nz	O
)	O
normal	O
map	O
,	O
i.e.	O
,	O
the	O
surface	B
normals	O
associ-	O
ated	O
with	O
each	O
mesh	O
vertex	O
,	O
which	O
can	O
be	O
used	O
to	O
compensate	O
for	O
loss	O
in	O
visual	O
ﬁdelity	O
if	O
the	O
original	O
geometry	O
image	B
is	O
heavily	O
compressed	O
.	O
7	O
subdivision	O
triangulations	O
,	O
such	O
as	O
those	O
in	O
(	O
eck	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1995	O
)	O
,	O
are	O
semi-regular	O
,	O
i.e.	O
,	O
regular	O
(	O
ordered	O
and	O
nested	O
)	O
within	O
each	O
subdivided	O
base	O
triangle	O
.	O
12.4	O
point-based	B
representations	O
595	O
+	O
=⇒	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
(	O
a	O
)	O
(	O
nx	O
,	O
ny	O
,	O
nz	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
12.12	O
geometry	O
images	O
(	O
gu	O
,	O
gortler	O
,	O
and	O
hoppe	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
acm	O
:	O
(	O
a	O
)	O
the	O
257×	O
257	O
geometry	O
image	B
deﬁnes	O
a	O
mesh	O
over	O
the	O
surface	B
;	O
(	O
b	O
)	O
the	O
512	O
×	O
512	O
normal	O
map	O
deﬁnes	O
vertex	O
normals	O
;	O
(	O
c	O
)	O
ﬁnal	O
lit	O
3d	O
model	O
.	O
12.4	O
point-based	B
representations	O
as	O
we	O
mentioned	O
previously	O
,	O
triangle-based	O
surface	B
models	O
assume	O
that	O
the	O
topology	O
(	O
and	O
often	O
the	O
rough	O
shape	O
)	O
of	O
the	O
3d	O
model	O
is	O
known	O
ahead	O
of	O
time	O
.	O
while	O
it	O
is	O
possible	O
to	O
re-mesh	O
a	O
model	O
as	O
it	O
is	O
being	O
deformed	O
or	O
ﬁtted	O
,	O
a	O
simpler	O
solution	O
is	O
to	O
dispense	O
with	O
an	O
explicit	O
triangle	B
mesh	I
altogether	O
and	O
to	O
have	O
triangle	O
vertices	O
behave	O
as	O
oriented	B
points	O
,	O
or	O
particles	O
,	O
or	O
surface	B
elements	O
(	O
surfels	O
)	O
(	O
szeliski	O
and	O
tonnesen	O
1992	O
)	O
.	O
in	O
order	B
to	O
endow	O
the	O
resulting	O
particle	O
system	O
with	O
internal	O
smoothness	B
constraints	O
,	O
pair-	O
wise	O
interaction	O
potentials	O
can	O
be	O
deﬁned	O
that	O
approximate	O
the	O
equivalent	O
elastic	O
bending	O
energies	O
that	O
would	O
be	O
obtained	O
using	O
local	O
ﬁnite-element	O
analysis.8	O
instead	O
of	O
deﬁning	O
the	O
ﬁnite	O
element	O
neighborhood	B
for	O
each	O
particle	O
(	O
vertex	O
)	O
ahead	O
of	O
time	O
,	O
a	O
soft	O
inﬂuence	O
function	O
is	O
used	O
to	O
couple	O
nearby	O
particles	O
.	O
the	O
resulting	O
3d	O
model	O
can	O
change	O
both	O
topology	O
and	O
par-	O
ticle	O
density	O
as	O
it	O
evolves	O
and	O
can	O
therefore	O
be	O
used	O
to	O
interpolate	O
partial	O
3d	O
data	O
with	O
holes	O
(	O
szeliski	O
,	O
tonnesen	O
,	O
and	O
terzopoulos	O
1993b	O
)	O
.	O
discontinuities	O
in	O
both	O
the	O
surface	B
orientation	O
and	O
crease	O
curves	O
can	O
also	O
be	O
modeled	O
(	O
szeliski	O
,	O
tonnesen	O
,	O
and	O
terzopoulos	O
1993a	O
)	O
.	O
to	O
render	O
the	O
particle	O
system	O
as	O
a	O
continuous	O
surface	B
,	O
local	B
dynamic	O
triangulation	B
heuris-	O
tics	O
(	O
szeliski	O
and	O
tonnesen	O
1992	O
)	O
or	O
direct	B
surface	O
element	O
splatting	O
(	O
pﬁster	O
,	O
zwicker	O
,	O
van	O
baar	O
et	O
al	O
.	O
2000	O
)	O
can	O
be	O
used	O
.	O
another	O
alternative	O
is	O
to	O
ﬁrst	O
convert	O
the	O
point	O
cloud	O
into	O
an	O
implicit	O
signed	B
distance	O
or	O
inside–outside	O
function	O
,	O
using	O
either	O
minimum	O
signed	O
distances	O
to	O
the	O
oriented	B
points	O
(	O
hoppe	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1992	O
)	O
or	O
by	O
interpolating	O
a	O
charac-	O
teristic	O
(	O
inside–outside	O
)	O
function	O
using	O
radial	O
basis	O
functions	O
(	O
turk	O
and	O
o	O
’	O
brien	O
2002	O
;	O
dinh	O
,	O
turk	O
,	O
and	O
slabaugh	O
2002	O
)	O
.	O
even	O
greater	O
precision	B
over	O
the	O
implicit	O
function	O
ﬁtting	O
,	O
including	O
the	O
ability	O
to	O
handle	O
irregular	O
point	O
densities	O
,	O
can	O
be	O
obtained	O
by	O
computing	O
a	O
moving	O
least	O
8	O
as	O
mentioned	O
before	O
,	O
an	O
alternative	O
is	O
to	O
use	O
sub-linear	O
interaction	O
potentials	O
,	O
which	O
encourage	O
the	O
preservation	O
of	O
surface	B
creases	O
(	O
diebel	O
,	O
thrun	O
,	O
and	O
br¨unig	O
2006	O
)	O
.	O
596	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
12.13	O
point-based	B
surface	O
modeling	B
with	O
moving	O
least	O
squares	O
(	O
mls	O
)	O
(	O
pauly	O
,	O
keiser	O
,	O
kobbelt	O
et	O
al	O
.	O
2003	O
)	O
c	O
(	O
cid:13	O
)	O
2003	O
acm	O
:	O
(	O
a	O
)	O
a	O
set	O
of	O
points	B
(	O
black	O
dots	O
)	O
is	O
turned	O
into	O
an	O
implicit	O
inside–outside	O
function	O
(	O
black	O
curve	O
)	O
;	O
(	O
b	O
)	O
the	O
signed	B
distance	O
to	O
the	O
nearest	O
oriented	O
point	O
can	O
serve	O
as	O
an	O
approximation	O
to	O
the	O
inside–outside	O
distance	O
;	O
(	O
c	O
)	O
a	O
set	O
of	O
oriented	B
points	O
with	O
variable	O
sampling	B
density	O
representing	O
a	O
3d	O
surface	B
(	O
head	B
model	O
)	O
;	O
(	O
d	O
)	O
local	B
estimate	O
of	O
sampling	B
density	O
,	O
which	O
is	O
used	O
in	O
the	O
moving	O
least	O
squares	O
;	O
(	O
e	O
)	O
reconstructed	O
continuous	O
3d	O
surface	B
.	O
squares	O
(	O
mls	O
)	O
estimate	O
of	O
the	O
signed	B
distance	O
function	O
(	O
alexa	O
,	O
behr	O
,	O
cohen-or	O
et	O
al	O
.	O
2003	O
;	O
pauly	O
,	O
keiser	O
,	O
kobbelt	O
et	O
al	O
.	O
2003	O
)	O
,	O
as	O
shown	O
in	O
figure	O
12.13.	O
further	O
improvements	O
can	O
be	O
obtained	O
using	O
local	O
sphere	O
ﬁtting	O
(	O
guennebaud	O
and	O
gross	O
2007	O
)	O
,	O
faster	O
and	O
more	O
accu-	O
rate	O
re-sampling	O
(	O
guennebaud	O
,	O
germann	O
,	O
and	O
gross	O
2008	O
)	O
,	O
and	O
kernel	B
regression	O
to	O
better	O
tolerate	O
outliers	O
(	O
oztireli	O
,	O
guennebaud	O
,	O
and	O
gross	O
2008	O
)	O
.	O
12.5	O
volumetric	B
representations	O
a	O
third	O
alternative	O
for	O
modeling	O
3d	O
surfaces	O
is	O
to	O
construct	O
3d	O
volumetric	B
inside–outside	O
functions	O
.	O
we	O
already	O
saw	O
examples	B
of	O
this	O
in	O
section	O
11.6.1	O
,	O
where	O
we	O
looked	O
at	O
voxel	O
color-	O
ing	O
(	O
seitz	O
and	O
dyer	O
1999	O
)	O
,	O
space	B
carving	I
(	O
kutulakos	O
and	O
seitz	O
2000	O
)	O
,	O
and	O
level	O
set	O
(	O
faugeras	O
and	O
keriven	O
1998	O
;	O
pons	O
,	O
keriven	O
,	O
and	O
faugeras	O
2007	O
)	O
techniques	O
for	O
stereo	O
matching	B
,	O
and	O
section	O
11.6.2	O
,	O
where	O
we	O
discussed	O
using	O
binary	O
silhouette	O
images	O
to	O
reconstruct	O
volumes	O
.	O
in	O
this	O
section	O
,	O
we	O
look	O
at	O
continuous	O
implicit	O
(	O
inside–outside	O
)	O
functions	O
to	O
represent	O
3d	O
shape	O
.	O
12.5.1	O
implicit	O
surfaces	O
and	O
level	B
sets	I
while	O
polyhedral	O
and	O
voxel-based	O
representations	O
can	O
represent	O
three-dimensional	O
shapes	O
to	O
an	O
arbitrary	O
precision	B
,	O
they	O
lack	O
some	O
of	O
the	O
intrinsic	B
smoothness	O
properties	B
available	O
with	O
continuous	O
implicit	O
surfaces	O
,	O
which	O
use	O
an	O
indicator	O
function	O
(	O
characteristic	O
function	O
)	O
f	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
to	O
indicate	O
which	O
3d	O
points	B
are	O
inside	O
f	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
<	O
0	O
or	O
outside	O
f	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
>	O
0	O
12.5	O
volumetric	B
representations	O
597	O
the	O
object	O
.	O
an	O
early	O
example	O
of	O
using	O
implicit	O
functions	O
to	O
model	O
3d	O
objects	O
in	O
computer	O
vision	O
are	O
superquadrics	O
,	O
which	O
are	O
a	O
generalization	O
of	O
quadric	O
(	O
e.g.	O
,	O
ellipsoidal	O
)	O
parametric	B
volumetric	O
models	O
,	O
f	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
=	O
(	O
cid:32	O
)	O
(	O
cid:18	O
)	O
x	O
a1	O
(	O
cid:19	O
)	O
2/2	O
a2	O
(	O
cid:19	O
)	O
2/2	O
(	O
cid:33	O
)	O
2/1	O
+	O
(	O
cid:18	O
)	O
y	O
+	O
(	O
cid:18	O
)	O
x	O
a1	O
(	O
cid:19	O
)	O
2/1	O
−	O
1	O
=	O
0	O
(	O
12.8	O
)	O
(	O
pentland	O
1986	O
;	O
solina	O
and	O
bajcsy	O
1990	O
;	O
waithe	O
and	O
ferrie	O
1991	O
;	O
leonardis	O
,	O
jakliˇc	O
,	O
and	O
solina	O
1997	O
)	O
.	O
the	O
values	O
of	O
(	O
a1	O
,	O
a2	O
,	O
a3	O
)	O
control	O
the	O
extent	O
of	O
model	O
along	O
each	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
axis	O
,	O
while	O
the	O
values	O
of	O
(	O
1	O
,	O
2	O
)	O
control	O
how	O
“	O
square	O
”	O
it	O
is	O
.	O
to	O
model	O
a	O
wider	O
variety	O
of	O
shapes	O
,	O
superquadrics	O
are	O
usually	O
combined	O
with	O
either	O
rigid	O
or	O
non-rigid	B
deformations	O
(	O
terzopoulos	O
and	O
metaxas	O
1991	O
;	O
metaxas	O
and	O
terzopoulos	O
2002	O
)	O
.	O
superquadric	O
models	O
can	O
either	O
be	O
ﬁt	O
to	O
range	O
data	O
or	O
used	O
directly	O
for	O
stereo	O
matching	B
.	O
a	O
different	O
kind	O
of	O
implicit	O
shape	O
model	O
can	O
be	O
constructed	O
by	O
deﬁning	O
a	O
signed	B
distance	O
function	O
over	O
a	O
regular	O
three-dimensional	O
grid	O
,	O
optionally	O
using	O
an	O
octree	B
spline	O
to	O
represent	O
this	O
function	O
more	O
coarsely	O
away	O
from	O
its	O
surface	B
(	O
zero-set	O
)	O
(	O
lavall´ee	O
and	O
szeliski	O
1995	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
frisken	O
,	O
perry	O
,	O
rockwood	O
et	O
al	O
.	O
2000	O
;	O
ohtake	O
,	O
belyaev	O
,	O
alexa	O
et	O
al	O
.	O
2003	O
)	O
.	O
we	O
have	O
already	O
seen	O
examples	B
of	O
signed	B
distance	O
functions	O
being	O
used	O
to	O
represent	O
distance	O
transforms	O
(	O
section	O
3.3.3	O
)	O
,	O
level	B
sets	I
for	O
2d	O
contour	O
ﬁtting	O
and	O
tracking	O
(	O
section	O
5.1.4	O
)	O
,	O
volumetric	B
stereo	O
(	O
section	O
11.6.1	O
)	O
,	O
range	O
data	O
merging	B
(	O
section	O
12.2.1	O
)	O
,	O
and	O
point-based	B
modeling	O
(	O
section	O
12.4	O
)	O
.	O
the	O
advantage	O
of	O
representing	O
such	O
functions	O
directly	O
on	O
a	O
grid	O
is	O
that	O
it	O
is	O
quick	O
and	O
easy	O
to	O
look	O
up	O
distance	O
function	O
values	O
for	O
any	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
location	O
and	O
also	O
easy	O
to	O
extract	O
the	O
isosurface	O
using	O
the	O
marching	B
cubes	I
algorithm	O
(	O
lorensen	O
and	O
cline	O
1987	O
)	O
.	O
the	O
work	O
of	O
ohtake	O
,	O
belyaev	O
,	O
alexa	O
et	O
al	O
.	O
(	O
2003	O
)	O
is	O
particularly	O
notable	O
since	O
it	O
allows	O
for	O
several	O
distance	O
functions	O
to	O
be	O
used	O
simultaneously	O
and	O
then	O
combined	O
locally	O
to	O
produce	O
sharp	O
features	O
such	O
as	O
creases	O
.	O
poisson	O
surface	B
reconstruction	I
(	O
kazhdan	O
,	O
bolitho	O
,	O
and	O
hoppe	O
2006	O
)	O
uses	O
a	O
closely	O
related	O
volumetric	B
function	O
,	O
namely	O
a	O
smoothed	O
0/1	O
inside–outside	O
(	O
characteristic	O
)	O
function	O
,	O
which	O
can	O
be	O
thought	O
of	O
as	O
a	O
clipped	O
signed	B
distance	O
function	O
.	O
the	O
gradients	O
for	O
this	O
function	O
are	O
set	O
to	O
lie	O
along	O
oriented	B
surface	O
normals	O
near	O
known	O
surface	B
points	O
and	O
0	O
elsewhere	O
.	O
the	O
function	O
itself	O
is	O
represented	O
using	O
a	O
quadratic	O
tensor-product	O
b-spline	O
over	O
an	O
octree	B
,	O
which	O
provides	O
a	O
compact	O
representation	O
with	O
larger	O
cells	O
away	O
from	O
the	O
surface	B
or	O
in	O
regions	O
of	O
lower	O
point	O
density	O
,	O
and	O
also	O
admits	O
the	O
efﬁcient	O
solution	O
of	O
the	O
related	O
poisson	O
equations	B
(	O
3.100–3.102	O
)	O
,	O
see	O
section	O
9.3.4	O
(	O
p´erez	O
,	O
gangnet	O
,	O
and	O
blake	O
2003	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
replace	O
the	O
quadratic	O
penalties	O
used	O
in	O
the	O
poisson	O
equations	B
with	O
l1	O
(	O
total	B
variation	I
)	O
constraints	O
and	O
still	O
obtain	O
a	O
convex	O
optimization	O
problem	O
,	O
which	O
can	O
be	O
solved	O
using	O
either	O
continuous	O
(	O
zach	O
,	O
pock	O
,	O
and	O
bischof	O
2007b	O
;	O
zach	O
2008	O
)	O
or	O
discrete	B
graph	O
cut	O
(	O
lempitsky	O
and	O
boykov	O
2007	O
)	O
techniques	O
.	O
598	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
signed	B
distance	O
functions	O
also	O
play	O
an	O
integral	O
role	O
in	O
level-set	O
evolution	B
equations	O
(	O
(	O
sec-	O
tions	O
5.1.4	O
and	O
11.6.1	O
)	O
,	O
where	O
the	O
values	O
of	O
distance	O
transforms	O
on	O
the	O
mesh	O
are	O
updated	O
as	O
the	O
surface	B
evolves	O
to	O
ﬁt	O
multi-view	B
stereo	I
photoconsistency	O
measures	O
(	O
faugeras	O
and	O
keriven	O
1998	O
)	O
.	O
12.6	O
model-based	B
reconstruction	O
when	O
we	O
know	O
something	O
ahead	O
of	O
time	O
about	O
the	O
objects	O
we	O
are	O
trying	O
to	O
model	O
,	O
we	O
can	O
construct	O
more	O
detailed	O
and	O
reliable	O
3d	O
models	O
using	O
specialized	O
techniques	O
and	O
representa-	O
tions	O
.	O
for	O
example	O
,	O
architecture	B
is	O
usually	O
made	O
up	O
of	O
large	O
planar	O
regions	O
and	O
other	O
para-	O
metric	O
forms	O
(	O
such	O
as	O
surfaces	O
of	O
revolution	O
)	O
,	O
usually	O
oriented	B
perpendicular	O
to	O
gravity	O
and	O
to	O
each	O
other	O
(	O
section	O
12.6.1	O
)	O
.	O
heads	B
and	I
faces	I
can	O
be	O
represented	O
using	O
low-dimensional	O
,	O
non-rigid	B
shape	O
models	O
,	O
since	O
the	O
variability	O
in	O
shape	O
and	O
appearance	O
of	O
human	O
faces	O
,	O
while	O
extremely	O
large	O
,	O
is	O
still	O
bounded	O
(	O
section	O
12.6.2	O
)	O
.	O
human	O
bodies	O
or	O
parts	O
,	O
such	O
as	O
hands	O
,	O
form	O
highly	O
articulated	O
structures	O
,	O
which	O
can	O
be	O
represented	O
using	O
kinematic	O
chains	O
of	O
piecewise	O
rigid	O
skeletal	O
elements	O
linked	O
by	O
joints	O
(	O
section	O
12.6.4	O
)	O
.	O
in	O
this	O
section	O
,	O
we	O
highlight	O
some	O
of	O
the	O
main	O
ideas	O
,	O
representations	O
,	O
and	O
modeling	B
algo-	O
rithms	O
used	O
for	O
these	O
three	O
cases	O
.	O
additional	O
details	O
and	O
references	B
can	O
be	O
found	O
in	O
special-	O
ized	O
conferences	O
and	O
workshops	O
devoted	O
to	O
these	O
topics	O
,	O
e.g.	O
,	O
the	O
international	O
symposium	O
on	O
3d	O
data	O
processing	O
,	O
visualization	O
,	O
and	O
transmission	O
(	O
3dpvt	O
)	O
,	O
the	O
international	O
conference	O
on	O
3d	O
digital	O
imaging	O
and	O
modeling	B
(	O
3dim	O
)	O
,	O
the	O
international	O
conference	O
on	O
automatic	B
face	O
and	O
gesture	O
recognition	B
(	O
fg	O
)	O
,	O
the	O
ieee	O
workshop	O
on	O
analysis	O
and	O
modeling	B
of	O
faces	B
and	O
gestures	O
,	O
and	O
the	O
international	O
workshop	O
on	O
tracking	O
humans	O
for	O
the	O
evaluation	B
of	O
their	O
motion	B
in	O
image	B
sequences	O
(	O
themis	O
)	O
.	O
12.6.1	O
architecture	B
architectural	O
modeling	B
,	O
especially	O
from	O
aerial	O
photography	O
,	O
has	O
been	O
one	O
of	O
the	O
longest	O
stud-	O
ied	O
problems	O
in	O
both	O
photogrammetry	B
and	O
computer	O
vision	O
(	O
walker	O
and	O
herman	O
1988	O
)	O
.	O
re-	O
cently	O
,	O
the	O
development	O
of	O
reliable	O
image-based	B
modeling	O
techniques	O
,	O
as	O
well	O
as	O
the	O
preva-	O
lence	O
of	O
digital	O
cameras	O
and	O
3d	O
computer	O
games	O
,	O
has	O
spurred	O
renewed	O
interest	O
in	O
this	O
area	O
.	O
the	O
work	O
by	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
(	O
1996	O
)	O
was	O
one	O
of	O
the	O
earliest	O
hybrid	O
geometry-	O
and	O
image-based	B
modeling	O
and	O
rendering	B
systems	O
.	O
their	O
fac¸ade	O
system	O
combines	O
an	O
inter-	O
active	O
image-guided	O
geometric	B
modeling	O
tool	O
with	O
model-based	O
(	O
local	B
plane	O
plus	O
parallax	O
)	O
stereo	B
matching	I
and	O
view-dependent	O
texture	O
mapping	O
.	O
during	O
the	O
interactive	B
photogrammet-	O
ric	O
modeling	B
phase	O
,	O
the	O
user	O
selects	O
block	O
elements	O
and	O
aligns	O
their	O
edges	O
with	O
visible	O
edges	O
in	O
the	O
input	O
images	O
(	O
figure	O
12.14a	O
)	O
.	O
the	O
system	O
then	O
automatically	O
computes	O
the	O
dimensions	O
and	O
locations	O
of	O
the	O
blocks	O
along	O
with	O
the	O
camera	B
positions	O
using	O
constrained	O
optimization	O
12.6	O
model-based	B
reconstruction	O
599	O
figure	O
12.14	O
interactive	B
architectural	O
modeling	B
using	O
the	O
fac¸ade	O
system	O
(	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
:	O
(	O
a	O
)	O
input	O
image	B
with	O
user-drawn	O
edges	O
shown	O
in	O
green	O
;	O
(	O
b	O
)	O
shaded	O
3d	O
solid	O
model	O
;	O
(	O
c	O
)	O
geometric	B
primitives	O
overlaid	O
onto	O
the	O
input	O
image	B
;	O
(	O
d	O
)	O
ﬁnal	O
view-dependent	B
,	O
texture-mapped	O
3d	O
model	O
.	O
(	O
figure	O
12.14b–c	O
)	O
.	O
this	O
approach	O
is	O
intrinsically	O
more	O
reliable	O
than	O
general	O
feature-based	B
structure	O
from	O
motion	B
,	O
because	O
it	O
exploits	O
the	O
strong	O
geometry	O
available	O
in	O
the	O
block	O
primi-	O
tives	O
.	O
related	O
work	O
by	O
becker	O
and	O
bove	O
(	O
1995	O
)	O
,	O
horry	O
,	O
anjyo	O
,	O
and	O
arai	O
(	O
1997	O
)	O
,	O
and	O
crimin-	O
isi	O
,	O
reid	O
,	O
and	O
zisserman	O
(	O
2000	O
)	O
exploits	O
similar	O
information	O
available	O
from	O
vanishing	B
points	I
.	O
in	O
the	O
interactive	B
,	O
image-based	B
modeling	O
system	O
of	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
vanishing	O
point	O
directions	O
are	O
used	O
to	O
guide	O
the	O
user	O
drawing	O
of	O
polygons	O
,	O
which	O
are	O
then	O
automatically	O
ﬁtted	O
to	O
sparse	B
3d	O
points	B
recovered	O
using	O
structure	O
from	O
motion	B
.	O
once	O
the	O
rough	O
geometry	O
has	O
been	O
estimated	O
,	O
more	O
detailed	O
offset	O
maps	O
can	O
be	O
com-	O
puted	O
for	O
each	O
planar	O
face	O
using	O
a	O
local	B
plane	O
sweep	O
,	O
which	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
(	O
1996	O
)	O
call	O
model-based	B
stereo	O
.	O
finally	O
,	O
during	O
rendering	B
,	O
images	O
from	O
different	O
viewpoints	O
are	O
warped	O
and	O
blended	O
together	O
as	O
the	O
camera	B
moves	O
around	O
the	O
scene	O
,	O
using	O
a	O
process	O
(	O
re-	O
lated	O
to	O
light	B
ﬁeld	I
and	O
lumigraph	O
rendering	B
,	O
see	O
section	O
13.3	O
)	O
called	O
view-dependent	O
texture	O
mapping	O
(	O
figure	O
12.14d	O
)	O
.	O
for	O
interior	O
modeling	B
,	O
instead	O
of	O
working	O
with	O
single	O
pictures	O
,	O
it	O
is	O
more	O
useful	O
to	O
work	O
with	O
panoramas	O
,	O
since	O
you	O
can	O
see	O
larger	O
extents	O
of	O
walls	O
and	O
other	O
structures	O
.	O
the	O
3d	O
mod-	O
eling	O
system	O
developed	O
by	O
shum	O
,	O
han	O
,	O
and	O
szeliski	O
(	O
1998	O
)	O
ﬁrst	O
constructs	O
calibrated	O
panora-	O
mas	O
from	O
multiple	B
images	O
(	O
section	O
7.4	O
)	O
and	O
then	O
has	O
the	O
user	O
draw	O
vertical	O
and	O
horizontal	O
lines	B
in	O
the	O
image	B
to	O
demarcate	O
the	O
boundaries	O
of	O
planar	O
regions	O
.	O
the	O
lines	B
are	O
initially	O
used	O
to	O
establish	O
an	O
absolute	O
rotation	O
for	O
each	O
panorama	O
and	O
are	O
later	O
used	O
(	O
along	O
with	O
the	O
inferred	O
vertices	O
and	O
planes	B
)	O
to	O
optimize	O
the	O
3d	O
structure	O
,	O
which	O
can	O
be	O
recovered	O
up	O
to	O
scale	O
from	O
one	O
or	O
more	O
images	O
(	O
figure	O
12.15	O
)	O
.	O
360◦	O
high	B
dynamic	I
range	I
panoramas	O
can	O
also	O
be	O
used	O
for	O
outdoor	O
modeling	B
,	O
since	O
they	O
provide	O
highly	O
reliable	O
estimates	O
of	O
relative	O
camera	B
orientations	O
as	O
well	O
as	O
vanishing	O
point	O
directions	O
(	O
antone	O
and	O
teller	O
2002	O
;	O
teller	O
,	O
antone	O
,	O
bodnar	O
et	O
al	O
.	O
600	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
12.15	O
interactive	B
3d	O
modeling	B
from	O
panoramas	O
(	O
shum	O
,	O
han	O
,	O
and	O
szeliski	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
ieee	O
:	O
(	O
a	O
)	O
wide-angle	O
view	O
of	O
a	O
panorama	O
with	O
user-drawn	O
vertical	O
and	O
horizontal	O
(	O
axis-aligned	O
)	O
lines	B
;	O
(	O
b	O
)	O
single-view	O
reconstruction	O
of	O
the	O
corridors	O
.	O
2003	O
)	O
.	O
while	O
earlier	O
image-based	B
modeling	O
systems	O
required	O
some	O
user	O
authoring	O
,	O
werner	O
and	O
zisserman	O
(	O
2002	O
)	O
present	O
a	O
fully	O
automated	B
line-based	O
reconstruction	O
system	O
.	O
as	O
described	O
in	O
section	O
7.5.1	O
,	O
they	O
ﬁrst	O
detect	O
lines	B
and	O
vanishing	B
points	I
and	O
use	O
them	O
to	O
calibrate	O
the	O
camera	B
;	O
then	O
they	O
establish	O
line	O
correspondences	O
using	O
both	O
appearance	O
matching	B
and	O
tri-	O
focal	O
tensors	O
,	O
which	O
enables	O
them	O
to	O
reconstruct	O
families	O
of	O
3d	O
line	O
segments	O
,	O
as	O
shown	O
in	O
figure	O
12.16a	O
.	O
they	O
then	O
generate	O
plane	O
hypotheses	O
,	O
using	O
both	O
co-planar	O
3d	O
lines	B
and	O
a	O
plane	B
sweep	I
(	O
section	O
11.1.2	O
)	O
based	O
on	O
cross-correlation	O
scores	O
evaluated	O
at	O
interest	O
points	B
.	O
intersections	O
of	O
planes	B
are	O
used	O
to	O
determine	O
the	O
extent	O
of	O
each	O
plane	O
,	O
i.e.	O
,	O
an	O
initial	O
coarse	O
ge-	O
ometry	O
,	O
which	O
is	O
then	O
reﬁned	O
with	O
the	O
addition	O
of	O
rectangular	O
or	O
wedge-shaped	O
indentations	O
and	O
extrusions	O
(	O
figure	O
12.16c	O
)	O
.	O
note	O
that	O
when	O
top-down	O
maps	O
of	O
the	O
buildings	O
being	O
mod-	O
eled	O
are	O
available	O
,	O
these	O
can	O
be	O
used	O
to	O
further	O
constrain	O
the	O
3d	O
modeling	B
process	O
(	O
robertson	O
and	O
cipolla	O
2002	O
,	O
2009	O
)	O
.	O
the	O
idea	O
of	O
using	O
matched	O
3d	O
lines	B
for	O
estimating	O
vanishing	O
point	O
directions	O
and	O
dominant	O
planes	B
continues	O
to	O
be	O
used	O
in	O
a	O
number	O
of	O
recent	O
fully	O
automated	B
image-based	O
architectural	O
modeling	B
systems	O
(	O
zebedin	O
,	O
bauer	O
,	O
karner	O
et	O
al	O
.	O
2008	O
;	O
miˇcuˇs´ık	O
and	O
koˇseck´a	O
2009	O
;	O
furukawa	O
,	O
curless	O
,	O
seitz	O
et	O
al	O
.	O
2009b	O
;	O
sinha	O
,	O
steedly	O
,	O
and	O
szeliski	O
2009	O
)	O
.	O
another	O
common	O
characteristic	O
of	O
architecture	B
is	O
the	O
repeated	O
use	O
of	O
primitives	O
such	O
as	O
windows	O
,	O
doors	O
,	O
and	O
colonnades	O
.	O
architectural	O
modeling	B
systems	O
can	O
be	O
designed	O
to	O
search	O
for	O
such	O
repeated	O
elements	O
and	O
to	O
use	O
them	O
as	O
part	O
of	O
the	O
structure	O
inference	O
process	O
(	O
dick	O
,	O
torr	O
,	O
and	O
cipolla	O
2004	O
;	O
mueller	O
,	O
zeng	O
,	O
wonka	O
et	O
al	O
.	O
2007	O
;	O
schindler	O
,	O
krishnamurthy	O
,	O
lublin-	O
erman	O
et	O
al	O
.	O
2008	O
;	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
2008	O
)	O
.	O
the	O
combination	O
of	O
all	O
these	O
techniques	O
now	O
makes	O
it	O
possible	O
to	O
reconstruct	O
the	O
structure	O
of	O
large	O
3d	O
scenes	O
(	O
zhu	O
and	O
kanade	O
2008	O
)	O
.	O
for	O
example	O
,	O
the	O
urbanscan	O
system	O
of	O
polle-	O
feys	O
,	O
nist´er	O
,	O
frahm	O
et	O
al	O
.	O
(	O
2008	O
)	O
reconstructs	O
texture-mapped	O
3d	O
models	O
of	O
city	O
streets	O
from	O
videos	O
acquired	O
with	O
a	O
gps-equipped	O
vehicle	O
.	O
to	O
obtain	O
real-time	O
performance	O
,	O
they	O
use	O
both	O
optimized	O
on-line	O
structure-from-motion	O
algorithms	O
,	O
as	O
well	O
as	O
gpu	O
implementations	O
12.6	O
model-based	B
reconstruction	O
601	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
12.16	O
automated	B
architectural	O
reconstruction	O
using	O
3d	O
lines	B
and	O
planes	B
(	O
werner	O
and	O
zisserman	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
springer	O
:	O
(	O
a	O
)	O
reconstructed	O
3d	O
lines	B
,	O
color	B
coded	O
by	O
their	O
van-	O
ishing	O
directions	O
;	O
(	O
b	O
)	O
wire-frame	O
model	O
superimposed	O
onto	O
an	O
input	O
image	B
;	O
(	O
c	O
)	O
triangulated	O
piecewise-planar	O
model	O
with	O
windows	O
;	O
(	O
d	O
)	O
ﬁnal	O
texture-mapped	O
model	O
.	O
of	O
plane-sweep	O
stereo	B
aligned	O
to	O
dominant	O
planes	B
and	O
depth	B
map	I
fusion	O
.	O
cornelis	O
,	O
leibe	O
,	O
cornelis	O
et	O
al	O
.	O
(	O
2008	O
)	O
present	O
a	O
related	O
system	O
that	O
also	O
uses	O
plane-sweep	O
stereo	B
(	O
aligned	O
to	O
vertical	O
building	O
fac¸ades	O
)	O
combined	O
with	O
object	O
recognition	B
and	O
segmentation	B
for	O
vehicles	O
.	O
miˇcuˇs´ık	O
and	O
koˇseck´a	O
(	O
2009	O
)	O
build	O
on	O
these	O
results	O
using	O
omni-directional	O
images	O
and	O
super-	O
pixel-based	O
stereo	B
matching	I
along	O
dominant	O
plane	O
orientations	O
.	O
reconstruction	O
directly	O
from	O
active	O
range	O
scanning	O
data	O
combined	O
with	O
color	O
imagery	O
that	O
has	O
been	O
compensated	O
for	O
ex-	O
posure	O
and	O
lighting	B
variations	O
is	O
also	O
possible	O
(	O
chen	O
and	O
chen	O
2008	O
;	O
stamos	O
,	O
liu	O
,	O
chen	O
et	O
al	O
.	O
2008	O
;	O
troccoli	O
and	O
allen	O
2008	O
)	O
.	O
12.6.2	O
heads	B
and	I
faces	I
another	O
area	O
in	O
which	O
specialized	O
shape	O
and	O
appearance	O
models	O
are	O
extremely	O
helpful	O
is	O
in	O
the	O
modeling	B
of	O
heads	B
and	I
faces	I
.	O
even	O
though	O
the	O
appearance	O
of	O
people	O
seems	O
at	O
ﬁrst	O
glance	O
to	O
be	O
inﬁnitely	O
variable	O
,	O
the	O
actual	O
shape	O
of	O
a	O
person	O
’	O
s	O
head	B
and	O
face	B
can	O
be	O
described	O
rea-	O
sonably	O
well	O
using	O
a	O
few	O
dozen	O
parameters	B
(	O
pighin	O
,	O
hecker	O
,	O
lischinski	O
et	O
al	O
.	O
1998	O
;	O
guenter	O
,	O
grimm	O
,	O
wood	O
et	O
al	O
.	O
1998	O
;	O
decarlo	O
,	O
metaxas	O
,	O
and	O
stone	O
1998	O
;	O
blanz	O
and	O
vetter	O
1999	O
;	O
shan	O
,	O
liu	O
,	O
and	O
zhang	O
2001	O
)	O
.	O
figure	O
12.17	O
shows	O
an	O
example	O
of	O
an	O
image-based	B
modeling	O
system	O
,	O
where	O
user-speciﬁed	O
keypoints	O
in	O
several	O
images	O
are	O
used	O
to	O
ﬁt	O
a	O
generic	O
head	B
model	O
to	O
a	O
person	O
’	O
s	O
face	B
.	O
as	O
you	O
can	O
see	O
in	O
figure	O
12.17c	O
,	O
after	O
specifying	O
just	O
over	O
100	O
keypoints	O
,	O
the	O
shape	O
of	O
the	O
face	B
has	O
become	O
quite	O
adapted	O
and	O
recognizable	O
.	O
extracting	O
a	O
texture	B
map	O
from	O
the	O
original	O
images	O
and	O
then	O
applying	O
it	O
to	O
the	O
head	B
model	O
results	O
in	O
an	O
animatable	O
model	O
with	O
striking	O
visual	O
ﬁdelity	O
(	O
figure	O
12.18a	O
)	O
.	O
a	O
more	O
powerful	O
system	O
can	O
be	O
built	O
by	O
applying	O
principal	O
component	O
analysis	O
(	O
pca	O
)	O
to	O
a	O
collection	O
of	O
3d	O
scanned	O
faces	B
,	O
which	O
is	O
a	O
topic	O
we	O
discuss	O
in	O
section	O
12.6.3.	O
as	O
you	O
can	O
see	O
in	O
figure	O
12.19	O
,	O
it	O
is	O
then	O
possible	O
to	O
ﬁt	O
morphable	O
3d	O
models	O
to	O
single	O
images	O
and	O
to	O
602	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
b	O
)	O
figure	O
12.17	O
3d	O
model	O
ﬁtting	O
to	O
a	O
collection	O
of	O
images	O
:	O
(	O
pighin	O
,	O
hecker	O
,	O
lischinski	O
et	O
al	O
.	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
acm	O
:	O
(	O
a	O
)	O
set	O
of	O
ﬁve	O
input	O
images	O
along	O
with	O
user-selected	O
keypoints	O
;	O
(	O
b	O
)	O
the	O
complete	O
set	O
of	O
keypoints	O
and	O
curves	O
;	O
(	O
c	O
)	O
three	O
meshes—the	O
original	O
,	O
adapted	O
after	O
13	O
keypoints	O
,	O
and	O
after	O
an	O
additional	O
99	O
keypoints	O
;	O
(	O
d	O
)	O
the	O
partition	O
of	O
the	O
image	B
into	O
separately	O
animatable	O
regions	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
12.18	O
head	B
and	O
expression	O
tracking	O
and	O
re-animation	O
using	O
deformable	O
3d	O
models	O
.	O
(	O
a	O
)	O
models	O
ﬁt	O
directly	O
to	O
ﬁve	O
input	O
video	B
streams	O
(	O
pighin	O
,	O
szeliski	O
,	O
and	O
salesin	O
2002	O
)	O
c	O
(	O
cid:13	O
)	O
2002	O
springer	O
:	O
the	O
bottom	O
row	O
shows	O
the	O
results	O
of	O
re-animating	O
a	O
synthetic	O
texture-mapped	O
3d	O
model	O
with	O
pose	O
and	O
expression	O
parameters	B
ﬁtted	O
to	O
the	O
input	O
images	O
in	O
the	O
top	O
row	O
.	O
(	O
b	O
)	O
models	O
ﬁt	O
to	O
frame-rate	O
spacetime	B
stereo	I
surface	O
models	O
(	O
zhang	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
the	O
top	O
row	O
shows	O
the	O
input	O
images	O
with	O
synthetic	O
green	O
markers	O
overlaid	O
,	O
while	O
the	O
bottom	O
row	O
shows	O
the	O
ﬁtted	O
3d	O
surface	B
model	O
.	O
12.6	O
model-based	B
reconstruction	O
603	O
use	O
such	O
models	O
for	O
a	O
variety	O
of	O
animation	O
and	O
visual	B
effects	I
(	O
blanz	O
and	O
vetter	O
1999	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
design	O
stereo	B
matching	I
algorithms	O
that	O
optimize	O
directly	O
for	O
the	O
head	B
model	O
parameters	B
(	O
shan	O
,	O
liu	O
,	O
and	O
zhang	O
2001	O
;	O
kang	O
and	O
jones	O
2002	O
)	O
or	O
to	O
use	O
the	O
output	O
of	O
real-	O
time	O
stereo	O
with	O
active	O
illumination	O
(	O
zhang	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2004	O
)	O
(	O
figures	O
12.7	O
and	O
12.18b	O
)	O
.	O
as	O
the	O
sophistication	O
of	O
3d	O
facial	O
capture	O
systems	O
evolves	O
,	O
so	O
does	O
the	O
detail	O
and	O
realism	O
in	O
the	O
reconstructed	O
models	O
.	O
newer	O
systems	O
can	O
capture	O
(	O
in	O
real-time	O
)	O
not	O
only	O
surface	B
details	O
such	O
as	O
wrinkles	O
and	O
creases	O
,	O
but	O
also	O
accurate	O
models	O
of	O
skin	O
reﬂection	O
,	O
translucency	O
,	O
and	O
sub-surface	O
scattering	O
(	O
weyrich	O
,	O
matusik	O
,	O
pﬁster	O
et	O
al	O
.	O
2006	O
;	O
golovinskiy	O
,	O
matusik	O
,	O
ster	O
et	O
al	O
.	O
2006	O
;	O
bickel	O
,	O
botsch	O
,	O
angst	O
et	O
al	O
.	O
2007	O
;	O
igarashi	O
,	O
nishino	O
,	O
and	O
nayar	O
2007	O
)	O
.	O
once	O
a	O
3d	O
head	B
model	O
has	O
been	O
constructed	O
,	O
it	O
can	O
be	O
used	O
in	O
a	O
variety	O
of	O
applications	O
,	O
such	O
as	O
head	B
tracking	I
(	O
toyama	O
1998	O
;	O
lepetit	O
,	O
pilet	O
,	O
and	O
fua	O
2004	O
;	O
matthews	O
,	O
xiao	O
,	O
and	O
baker	O
2007	O
)	O
,	O
as	O
shown	O
in	O
figures	O
4.29	O
and	O
14.24	O
,	O
and	O
face	B
transfer	O
,	O
i.e.	O
,	O
replacing	O
one	O
person	O
’	O
s	O
face	B
with	O
another	O
in	O
a	O
video	B
(	O
bregler	O
,	O
covell	O
,	O
and	O
slaney	O
1997	O
;	O
vlasic	O
,	O
brand	O
,	O
pﬁster	O
et	O
al	O
.	O
2005	O
)	O
.	O
additional	O
applications	O
include	O
face	B
beautiﬁcation	O
by	O
warping	O
face	B
images	O
toward	O
a	O
more	O
attractive	O
“	O
standard	O
”	O
(	O
leyvand	O
,	O
cohen-or	O
,	O
dror	O
et	O
al	O
.	O
2008	O
)	O
,	O
face	B
de-identiﬁcation	O
for	O
privacy	O
protection	O
(	O
gross	O
,	O
sweeney	O
,	O
de	O
la	O
torre	O
et	O
al	O
.	O
2008	O
)	O
,	O
and	O
face	B
swapping	O
(	O
bitouk	O
,	O
kumar	O
,	O
dhillon	O
et	O
al	O
.	O
2008	O
)	O
.	O
12.6.3	O
application	O
:	O
facial	B
animation	I
perhaps	O
the	O
most	O
widely	O
used	O
application	O
of	O
3d	O
head	B
modeling	O
is	O
facial	B
animation	I
.	O
once	O
a	O
parameterized	O
3d	O
model	O
of	O
shape	O
and	O
appearance	O
(	O
surface	B
texture	O
)	O
has	O
been	O
constructed	O
,	O
it	O
can	O
be	O
used	O
directly	O
to	O
track	O
a	O
person	O
’	O
s	O
facial	O
motions	O
(	O
figure	O
12.18a	O
)	O
and	O
to	O
animate	O
a	O
different	O
character	O
with	O
these	O
same	O
motions	O
and	O
expressions	O
(	O
pighin	O
,	O
szeliski	O
,	O
and	O
salesin	O
2002	O
)	O
.	O
an	O
improved	O
version	O
of	O
such	O
a	O
system	O
can	O
be	O
constructed	O
by	O
ﬁrst	O
applying	O
principal	O
com-	O
ponent	O
analysis	O
(	O
pca	O
)	O
to	O
the	O
space	O
of	O
possible	O
head	B
shapes	O
and	O
facial	O
appearances	O
.	O
blanz	O
and	O
vetter	O
(	O
1999	O
)	O
describe	O
a	O
system	O
where	O
they	O
ﬁrst	O
capture	O
a	O
set	O
of	O
200	O
colored	O
range	O
scans	O
of	O
faces	B
(	O
figure	O
12.19a	O
)	O
,	O
which	O
can	O
be	O
represented	O
as	O
a	O
large	O
collection	O
of	O
(	O
x	O
,	O
y	O
,	O
z	O
,	O
r	O
,	O
g	O
,	O
b	O
)	O
samples	O
(	O
vertices	O
)	O
.9	O
in	O
order	B
for	O
3d	O
morphing	B
to	O
be	O
meaningful	O
,	O
corresponding	O
vertices	O
in	O
different	O
people	O
’	O
s	O
scans	O
must	O
ﬁrst	O
be	O
put	O
into	O
correspondence	B
(	O
pighin	O
,	O
hecker	O
,	O
lischinski	O
et	O
al	O
.	O
1998	O
)	O
.	O
once	O
this	O
is	O
done	O
,	O
pca	O
can	O
be	O
applied	O
to	O
more	O
naturally	O
parameterize	O
the	O
3d	O
mor-	O
phable	O
model	O
.	O
the	O
ﬂexibility	O
of	O
this	O
model	O
can	O
be	O
increased	O
by	O
performing	O
separate	O
analyses	O
in	O
different	O
subregions	O
,	O
such	O
as	O
the	O
eyes	O
,	O
nose	O
,	O
and	O
mouth	O
,	O
just	O
as	O
in	O
modular	O
eigenspaces	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
.	O
9	O
a	O
cylindrical	B
coordinate	O
system	O
provides	O
a	O
natural	B
two-dimensional	O
embedding	O
for	O
this	O
collection	O
,	O
but	O
such	O
an	O
embedding	O
is	O
not	O
necessary	O
to	O
perform	O
pca	O
.	O
604	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
12.19	O
3d	O
morphable	O
face	B
model	O
(	O
blanz	O
and	O
vetter	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
acm	O
:	O
(	O
a	O
)	O
orig-	O
inal	O
3d	O
face	B
model	O
with	O
the	O
addition	O
of	O
shape	O
and	O
texture	B
variations	O
in	O
speciﬁc	O
directions	O
:	O
deviation	O
from	O
the	O
mean	O
(	O
caricature	O
)	O
,	O
gender	O
,	O
expression	O
,	O
weight	O
,	O
and	O
nose	O
shape	O
;	O
(	O
b	O
)	O
a	O
3d	O
morphable	O
model	O
is	O
ﬁt	O
to	O
a	O
single	O
image	O
,	O
after	O
which	O
its	O
weight	O
or	O
expression	O
can	O
be	O
manip-	O
ulated	O
;	O
(	O
c	O
)	O
another	O
example	O
of	O
a	O
3d	O
reconstruction	O
along	O
with	O
a	O
different	O
set	O
of	O
3d	O
manipula-	O
tions	O
such	O
as	O
lighting	B
and	O
pose	O
change	O
.	O
12.6	O
model-based	B
reconstruction	O
605	O
after	O
computing	O
a	O
subspace	O
representation	O
,	O
different	O
directions	O
in	O
this	O
space	O
can	O
be	O
as-	O
sociated	O
with	O
different	O
characteristics	O
such	O
as	O
gender	O
,	O
facial	O
expressions	O
,	O
or	O
facial	O
features	O
(	O
figure	O
12.19a	O
)	O
.	O
as	O
in	O
the	O
work	O
of	O
rowland	O
and	O
perrett	O
(	O
1995	O
)	O
,	O
faces	B
can	O
be	O
turned	O
into	O
caricatures	O
by	O
exaggerating	O
their	O
displacement	O
from	O
the	O
mean	O
image	O
.	O
3d	O
morphable	O
models	O
can	O
be	O
ﬁtted	O
to	O
a	O
single	O
image	O
using	O
gradient	O
descent	O
on	O
the	O
error	O
between	O
the	O
input	O
image	B
and	O
the	O
re-synthesized	O
model	O
image	B
,	O
after	O
an	O
initial	O
manual	O
place-	O
ment	O
of	O
the	O
model	O
in	O
an	O
approximately	O
correct	O
pose	O
,	O
scale	O
,	O
and	O
location	O
(	O
figures	O
12.19b–c	O
)	O
.	O
the	O
efﬁciency	B
of	O
this	O
ﬁtting	O
process	O
can	O
be	O
increased	O
using	O
inverse	O
compositional	B
image	O
alignment	B
(	O
8.64–8.65	O
)	O
,	O
as	O
described	O
by	O
romdhani	O
and	O
vetter	O
(	O
2003	O
)	O
.	O
the	O
resulting	O
texture-mapped	O
3d	O
model	O
can	O
then	O
be	O
modiﬁed	O
to	O
produce	O
a	O
variety	O
of	O
vi-	O
sual	O
effects	O
,	O
including	O
changing	O
a	O
person	O
’	O
s	O
weight	O
or	O
expression	O
,	O
or	O
three-dimensional	O
effects	O
such	O
as	O
re-lighting	O
or	O
3d	O
video-based	O
animation	O
(	O
section	O
13.5.1	O
)	O
.	O
such	O
models	O
can	O
also	O
be	O
used	O
for	O
video	O
compression	B
,	O
e.g.	O
,	O
by	O
only	O
transmitting	O
a	O
small	O
number	O
of	O
facial	O
expression	O
and	O
pose	O
parameters	B
to	O
drive	O
a	O
synthetic	O
avatar	O
(	O
eisert	O
,	O
wiegand	O
,	O
and	O
girod	O
2000	O
;	O
gao	O
,	O
chen	O
,	O
wang	O
et	O
al	O
.	O
2003	O
)	O
.	O
3d	O
facial	B
animation	I
is	O
often	O
matched	O
to	O
the	O
performance	O
of	O
an	O
actor	O
,	O
in	O
what	O
is	O
known	O
as	O
performance-driven	B
animation	I
(	O
section	O
4.1.5	O
)	O
(	O
williams	O
1990	O
)	O
.	O
traditional	O
performance-	O
driven	O
animation	O
systems	O
use	O
marker-based	O
motion	B
capture	O
(	O
ma	O
,	O
jones	O
,	O
chiang	O
et	O
al	O
.	O
2008	O
)	O
,	O
while	O
some	O
newer	O
systems	O
use	O
video	B
footage	O
to	O
control	O
the	O
animation	O
(	O
buck	O
,	O
finkelstein	O
,	O
jacobs	O
et	O
al	O
.	O
2000	O
;	O
pighin	O
,	O
szeliski	O
,	O
and	O
salesin	O
2002	O
;	O
zhang	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2004	O
;	O
vlasic	O
,	O
brand	O
,	O
pﬁster	O
et	O
al	O
.	O
2005	O
)	O
.	O
an	O
example	O
of	O
the	O
latter	O
approach	O
is	O
the	O
system	O
developed	O
for	O
the	O
ﬁlm	O
benjamin	O
button	O
,	O
in	O
which	O
digital	O
domain	O
used	O
the	O
contour	O
system	O
from	O
mova10	O
to	O
capture	O
actor	O
brad	O
pitt	O
’	O
s	O
facial	O
motions	O
and	O
expressions	O
(	O
roble	O
and	O
zafar	O
2009	O
)	O
.	O
contour	O
uses	O
a	O
combina-	O
tion	B
of	O
phosphorescent	O
paint	O
and	O
multiple	B
high-resolution	O
video	B
cameras	O
to	O
capture	O
real-time	O
3d	O
range	O
scans	O
of	O
the	O
actor	O
.	O
these	O
3d	O
models	O
were	O
then	O
translated	O
into	O
facial	O
action	O
cod-	O
ing	O
system	O
(	O
facs	O
)	O
shape	O
and	O
expression	O
parameters	B
(	O
ekman	O
and	O
friesen	O
1978	O
)	O
to	O
drive	O
a	O
different	O
(	O
older	O
)	O
synthetically	O
animated	O
computer-generated	O
imagery	O
(	O
cgi	O
)	O
character	O
.	O
12.6.4	O
whole	O
body	B
modeling	O
and	O
tracking	O
the	O
topics	O
of	O
tracking	O
humans	O
,	O
modeling	B
their	O
shape	O
and	O
appearance	O
,	O
and	O
recognizing	O
their	O
activities	O
,	O
are	O
some	O
of	O
the	O
most	O
actively	O
studied	O
areas	O
of	O
computer	O
vision	O
.	O
annual	O
confer-	O
ences11	O
and	O
special	O
journal	O
issues	O
(	O
hilton	O
,	O
fua	O
,	O
and	O
ronfard	O
2006	O
)	O
are	O
devoted	O
to	O
this	O
sub-	O
ject	O
,	O
and	O
two	O
recent	O
surveys	B
(	O
forsyth	O
,	O
arikan	O
,	O
ikemoto	O
et	O
al	O
.	O
2006	O
;	O
moeslund	O
,	O
hilton	O
,	O
and	O
10	O
http	O
:	O
//www.mova.com	O
.	O
11	O
international	O
conference	O
on	O
automatic	B
face	O
and	O
gesture	O
recognition	B
(	O
fg	O
)	O
,	O
ieee	O
workshop	O
on	O
analysis	O
and	O
modeling	B
of	O
faces	B
and	O
gestures	O
,	O
and	O
international	O
workshop	O
on	O
tracking	O
humans	O
for	O
the	O
evaluation	B
of	O
their	O
motion	B
in	O
image	B
sequences	O
(	O
themis	O
)	O
.	O
606	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
kr¨uger	O
2006	O
)	O
each	O
list	O
over	O
400	O
papers	O
devoted	O
to	O
these	O
topics.12	O
the	O
humaneva	O
database	O
of	O
articulated	O
human	O
motions13	O
contains	O
multi-view	B
video	O
sequences	O
of	O
human	O
actions	O
along	O
with	O
corresponding	O
motion	B
capture	O
data	O
,	O
evaluation	B
code	O
,	O
and	O
a	O
reference	O
3d	O
tracker	O
based	O
on	O
particle	B
ﬁltering	I
.	O
the	O
companion	O
paper	O
by	O
sigal	O
,	O
balan	O
,	O
and	O
black	O
(	O
2010	O
)	O
not	O
only	O
describes	O
the	O
database	O
and	O
evaluation	B
but	O
also	O
has	O
a	O
nice	O
survey	O
of	O
important	O
work	O
in	O
this	O
ﬁeld	O
.	O
given	O
the	O
breadth	O
of	O
this	O
area	O
,	O
it	O
is	O
difﬁcult	O
to	O
categorize	O
all	O
of	O
this	O
research	O
,	O
especially	O
since	O
different	O
techniques	O
usually	O
build	O
on	O
each	O
other	O
.	O
moeslund	O
,	O
hilton	O
,	O
and	O
kr¨uger	O
(	O
2006	O
)	O
divide	O
their	O
survey	O
into	O
initialization	B
,	O
tracking	O
(	O
which	O
includes	O
background	O
modeling	O
and	O
segmentation	B
)	O
,	O
pose	O
estimation	B
,	O
and	O
action	O
(	O
activity	O
)	O
recognition	B
.	O
forsyth	O
,	O
arikan	O
,	O
ikemoto	O
et	O
al	O
.	O
(	O
2006	O
)	O
divide	O
their	O
survey	O
into	O
sections	O
on	O
tracking	O
(	O
background	B
subtraction	I
,	O
deformable	O
templates	O
,	O
ﬂow	O
,	O
and	O
probabilistic	B
models	I
)	O
,	O
recovering	O
3d	O
pose	O
from	O
2d	O
observations	O
,	O
and	O
data	O
association	O
and	O
body	B
parts	O
.	O
they	O
also	O
include	O
a	O
section	O
on	O
motion	B
synthesis	O
,	O
which	O
is	O
more	O
widely	O
studied	O
in	O
computer	O
graphics	O
(	O
arikan	O
and	O
forsyth	O
2002	O
;	O
kovar	O
,	O
gleicher	O
,	O
and	O
pighin	O
2002	O
;	O
lee	O
,	O
chai	O
,	O
reitsma	O
et	O
al	O
.	O
2002	O
;	O
li	O
,	O
wang	O
,	O
and	O
shum	O
2002	O
;	O
pullen	O
and	O
bregler	O
2002	O
)	O
,	O
see	O
section	O
13.5.2.	O
another	O
potential	O
taxonomy	B
for	O
work	O
in	O
this	O
ﬁeld	O
would	O
be	O
along	O
the	O
lines	B
of	O
whether	O
2d	O
or	O
3d	O
(	O
or	O
multi-view	B
)	O
images	O
are	O
used	O
as	O
input	O
and	O
whether	O
2d	O
or	O
3d	O
kinematic	B
models	I
are	O
used	O
.	O
in	O
this	O
section	O
,	O
we	O
brieﬂy	O
review	O
some	O
of	O
the	O
more	O
seminal	O
and	O
widely	O
cited	O
papers	O
in	O
the	O
areas	O
of	O
background	B
subtraction	I
,	O
initialization	B
and	O
detection	B
,	O
tracking	O
with	O
ﬂow	O
,	O
3d	O
kinematic	B
models	I
,	O
probabilistic	B
models	I
,	O
adaptive	B
shape	I
modeling	I
,	O
and	O
activity	B
recognition	I
.	O
we	O
refer	O
the	O
reader	O
to	O
the	O
previously	O
mentioned	O
surveys	B
for	O
other	O
topics	O
and	O
more	O
details	O
.	O
background	B
subtraction	I
.	O
one	O
of	O
the	O
ﬁrst	O
steps	O
in	O
many	O
(	O
but	O
certainly	O
not	O
all	O
)	O
human	O
track-	O
ing	O
systems	O
is	O
to	O
model	O
the	O
background	O
in	O
order	B
to	O
extract	O
the	O
moving	O
foreground	O
objects	O
(	O
silhouettes	B
)	O
corresponding	O
to	O
people	O
.	O
toyama	O
,	O
krumm	O
,	O
brumitt	O
et	O
al	O
.	O
(	O
1999	O
)	O
review	O
several	O
difference	B
matting	O
and	O
background	O
maintenance	O
(	O
modeling	B
)	O
techniques	O
and	O
provide	O
a	O
good	O
introduction	O
to	O
this	O
topic	O
.	O
stauffer	O
and	O
grimson	O
(	O
1999	O
)	O
describe	O
some	O
techniques	O
based	O
on	O
mixture	O
models	O
,	O
while	O
sidenbladh	O
and	O
black	O
(	O
2003	O
)	O
develop	O
a	O
more	O
comprehensive	O
treat-	O
ment	O
,	O
which	O
models	O
not	O
only	O
the	O
background	O
image	O
statistics	O
but	O
also	O
the	O
appearance	O
of	O
the	O
foreground	O
objects	O
,	O
e.g.	O
,	O
their	O
edge	O
and	O
motion	B
(	O
frame	O
difference	O
)	O
statistics	O
.	O
once	O
silhouettes	B
have	O
been	O
extracted	O
from	O
one	O
or	O
more	O
cameras	O
,	O
they	O
can	O
then	O
be	O
mod-	O
eled	O
using	O
deformable	O
templates	O
or	O
other	O
contour	O
models	O
(	O
baumberg	O
and	O
hogg	O
1996	O
;	O
wren	O
,	O
azarbayejani	O
,	O
darrell	O
et	O
al	O
.	O
1997	O
)	O
.	O
tracking	O
such	O
silhouettes	B
over	O
time	O
supports	O
the	O
analysis	O
of	O
multiple	B
people	O
moving	O
around	O
a	O
scene	O
,	O
including	O
building	O
shape	O
and	O
appearance	O
models	O
12	O
older	O
surveys	B
include	O
those	O
by	O
gavrila	O
(	O
1999	O
)	O
and	O
moeslund	O
and	O
granum	O
(	O
2001	O
)	O
.	O
some	O
surveys	B
on	O
gesture	O
recognition	B
,	O
which	O
we	O
do	O
not	O
cover	O
in	O
this	O
book	O
,	O
include	O
those	O
by	O
pavlovi´c	O
,	O
sharma	O
,	O
and	O
huang	O
(	O
1997	O
)	O
and	O
yang	O
,	O
ahuja	O
,	O
and	O
tabb	O
(	O
2002	O
)	O
.	O
13	O
http	O
:	O
//vision.cs.brown.edu/humaneva/	O
.	O
12.6	O
model-based	B
reconstruction	O
607	O
and	O
detecting	O
if	O
they	O
are	O
carrying	O
objects	O
(	O
haritaoglu	O
,	O
harwood	O
,	O
and	O
davis	O
2000	O
;	O
mittal	O
and	O
davis	O
2003	O
;	O
dimitrijevic	O
,	O
lepetit	O
,	O
and	O
fua	O
2006	O
)	O
.	O
initialization	B
and	O
detection	B
.	O
in	O
order	B
to	O
track	O
people	O
in	O
a	O
fully	O
automated	B
manner	O
,	O
it	O
is	O
necessary	O
to	O
ﬁrst	O
detect	O
(	O
or	O
re-acquire	O
)	O
their	O
presence	O
in	O
individual	O
video	B
frames	O
.	O
this	O
topic	O
is	O
closely	O
related	O
to	O
pedestrian	B
detection	O
,	O
which	O
is	O
often	O
considered	O
as	O
a	O
kind	O
of	O
object	O
recog-	O
nition	O
(	O
mori	O
,	O
ren	O
,	O
efros	O
et	O
al	O
.	O
2004	O
;	O
felzenszwalb	O
and	O
huttenlocher	O
2005	O
;	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
2008	O
)	O
,	O
and	O
is	O
therefore	O
treated	O
in	O
more	O
depth	O
in	O
section	O
14.1.2.	O
additional	O
techniques	O
for	O
initializing	O
3d	O
trackers	O
based	O
on	O
2d	O
images	O
include	O
those	O
described	O
by	O
howe	O
,	O
leventon	O
,	O
and	O
freeman	O
(	O
2000	O
)	O
,	O
rosales	O
and	O
sclaroff	O
(	O
2000	O
)	O
,	O
shakhnarovich	O
,	O
viola	O
,	O
and	O
darrell	O
(	O
2003	O
)	O
,	O
sminchisescu	O
,	O
kanaujia	O
,	O
li	O
et	O
al	O
.	O
(	O
2005	O
)	O
,	O
agarwal	O
and	O
triggs	O
(	O
2006	O
)	O
,	O
lee	O
and	O
cohen	O
(	O
2006	O
)	O
,	O
sigal	O
and	O
black	O
(	O
2006	O
)	O
,	O
and	O
stenger	O
,	O
thayananthan	O
,	O
torr	O
et	O
al	O
.	O
(	O
2006	O
)	O
.	O
single-frame	O
human	O
detection	O
and	O
pose	O
estimation	B
algorithms	O
can	O
sometimes	O
be	O
used	O
by	O
themselves	O
to	O
perform	O
tracking	O
(	O
ramanan	O
,	O
forsyth	O
,	O
and	O
zisserman	O
2005	O
;	O
rogez	O
,	O
rihan	O
,	O
ra-	O
malingam	O
et	O
al	O
.	O
2008	O
;	O
bourdev	O
and	O
malik	O
2009	O
)	O
,	O
as	O
described	O
in	O
section	O
4.1.4.	O
more	O
often	O
,	O
however	O
,	O
they	O
are	O
combined	O
with	O
frame-to-frame	O
tracking	O
techniques	O
to	O
provide	O
better	O
relia-	O
bility	O
(	O
fossati	O
,	O
dimitrijevic	O
,	O
lepetit	O
et	O
al	O
.	O
2007	O
;	O
andriluka	O
,	O
roth	O
,	O
and	O
schiele	O
2008	O
;	O
ferrari	O
,	O
marin-jimenez	O
,	O
and	O
zisserman	O
2008	O
)	O
.	O
tracking	O
with	O
ﬂow	O
.	O
the	O
tracking	O
of	O
people	O
and	O
their	O
pose	O
from	O
frame	O
to	O
frame	O
can	O
be	O
en-	O
hanced	O
by	O
computing	O
optic	O
ﬂow	O
or	O
matching	B
the	O
appearance	O
of	O
their	O
limbs	O
from	O
one	O
frame	O
to	O
another	O
.	O
for	O
example	O
,	O
the	O
cardboard	O
people	O
model	O
of	O
ju	O
,	O
black	O
,	O
and	O
yacoob	O
(	O
1996	O
)	O
mod-	O
els	O
the	O
appearance	O
of	O
each	O
leg	O
portion	O
(	O
upper	O
and	O
lower	O
)	O
as	O
a	O
moving	O
rectangle	O
,	O
and	O
uses	O
optic	O
ﬂow	O
to	O
estimate	O
their	O
location	O
in	O
each	O
subsequent	O
frame	O
.	O
cham	O
and	O
rehg	O
(	O
1999	O
)	O
and	O
sidenbladh	O
,	O
black	O
,	O
and	O
fleet	O
(	O
2000	O
)	O
track	O
limbs	O
using	O
optical	O
ﬂow	O
and	O
templates	O
,	O
along	O
with	O
techniques	O
for	O
dealing	O
with	O
multiple	O
hypotheses	O
and	O
uncertainty	B
.	O
bregler	O
,	O
malik	O
,	O
and	O
pullen	O
(	O
2004	O
)	O
use	O
a	O
full	O
3d	O
model	O
of	O
limb	O
and	O
body	B
motion	O
,	O
as	O
described	O
below	O
.	O
it	O
is	O
also	O
possible	O
to	O
match	O
the	O
estimated	O
motion	B
ﬁeld	O
itself	O
to	O
some	O
prototypes	O
in	O
order	B
to	O
identify	O
the	O
particular	O
phase	O
of	O
a	O
running	O
motion	B
or	O
to	O
match	O
two	O
low-resolution	O
video	B
portions	O
in	O
order	B
to	O
perform	O
video	B
replacement	O
(	O
efros	O
,	O
berg	O
,	O
mori	O
et	O
al	O
.	O
2003	O
)	O
.	O
3d	O
kinematic	B
models	I
.	O
the	O
effectiveness	O
of	O
human	O
modeling	O
and	O
tracking	O
can	O
be	O
greatly	O
enhanced	O
using	O
a	O
more	O
accurate	O
3d	O
model	O
of	O
a	O
person	O
’	O
s	O
shape	O
and	O
motion	B
.	O
underlying	O
such	O
representations	O
,	O
which	O
are	O
ubiquitous	O
in	O
3d	O
computer	O
animation	O
in	O
games	O
and	O
special	O
effects	O
,	O
is	O
a	O
kinematic	O
model	O
or	O
kinematic	O
chain	O
,	O
which	O
speciﬁes	O
the	O
length	O
of	O
each	O
limb	O
in	O
a	O
skeleton	O
as	O
well	O
as	O
the	O
2d	O
or	O
3d	O
rotation	O
angles	O
between	O
the	O
limbs	O
or	O
segments	O
(	O
figure	O
12.20a–b	O
)	O
.	O
inferring	O
the	O
values	O
of	O
the	O
joint	B
angles	O
from	O
the	O
locations	O
of	O
the	O
visible	O
surface	B
points	O
is	O
called	O
inverse	B
kinematics	O
(	O
ik	O
)	O
and	O
is	O
widely	O
studied	O
in	O
computer	O
graphics	O
.	O
608	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
12.20	O
tracking	O
3d	O
human	B
motion	I
:	O
(	O
a	O
)	O
kinematic	O
chain	O
model	O
for	O
a	O
human	O
hand	O
(	O
rehg	O
,	O
morris	O
,	O
and	O
kanade	O
2003	O
)	O
c	O
(	O
cid:13	O
)	O
2003	O
,	O
reprinted	O
by	O
permission	O
of	O
sage	O
;	O
(	O
b	O
)	O
tracking	O
a	O
kinematic	O
chain	O
blob	O
model	O
in	O
a	O
video	B
sequence	O
(	O
bregler	O
,	O
malik	O
,	O
and	O
pullen	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
;	O
(	O
c–d	O
)	O
probabilistic	B
loose-limbed	O
collection	O
of	O
body	B
parts	O
(	O
sigal	O
,	O
bhatia	O
,	O
roth	O
et	O
al	O
.	O
2004	O
)	O
figure	O
12.20a	O
shows	O
the	O
kinematic	O
model	O
for	O
a	O
human	O
hand	O
used	O
by	O
rehg	O
,	O
morris	O
,	O
and	O
kanade	O
(	O
2003	O
)	O
to	O
track	O
hand	O
motion	B
in	O
a	O
video	B
.	O
as	O
you	O
can	O
see	O
,	O
the	O
attachment	O
points	B
between	O
the	O
ﬁngers	O
and	O
the	O
thumb	O
have	O
two	O
degrees	O
of	O
freedom	O
,	O
while	O
the	O
ﬁnger	O
joints	O
themselves	O
have	O
only	O
one	O
.	O
using	O
this	O
kind	O
of	O
model	O
can	O
greatly	O
enhance	O
the	O
ability	O
of	O
an	O
edge-based	B
tracker	O
to	O
cope	O
with	O
rapid	O
motion	B
,	O
ambiguities	O
in	O
3d	O
pose	O
,	O
and	O
partial	O
occlusions	O
.	O
kinematic	O
chain	O
models	O
are	O
even	O
more	O
widely	O
used	O
for	O
whole	O
body	B
modeling	O
and	O
tracking	O
(	O
o	O
’	O
rourke	O
and	O
badler	O
1980	O
;	O
hogg	O
1983	O
;	O
rohr	O
1994	O
)	O
.	O
one	O
popular	O
approach	O
is	O
to	O
associate	O
an	O
ellipsoid	O
or	O
superquadric	O
with	O
each	O
rigid	O
limb	O
in	O
the	O
kinematic	O
model	O
,	O
as	O
shown	O
in	O
fig-	O
ure	O
12.20b	O
.	O
this	O
model	O
can	O
then	O
be	O
ﬁtted	O
to	O
each	O
frame	O
in	O
one	O
or	O
more	O
video	B
streams	O
either	O
by	O
matching	O
silhouettes	B
extracted	O
from	O
known	O
backgrounds	O
or	O
by	O
matching	O
and	O
tracking	O
the	O
locations	O
of	O
occluding	O
edges	O
(	O
gavrila	O
and	O
davis	O
1996	O
;	O
kakadiaris	O
and	O
metaxas	O
2000	O
;	O
bre-	O
gler	O
,	O
malik	O
,	O
and	O
pullen	O
2004	O
;	O
kehl	O
and	O
van	O
gool	O
2006	O
)	O
.	O
note	O
that	O
some	O
techniques	O
use	O
2d	O
models	O
coupled	O
to	O
2d	O
measurements	O
,	O
some	O
use	O
3d	O
measurements	O
(	O
range	O
data	O
or	O
multi-view	B
video	O
)	O
with	O
3d	O
models	O
,	O
and	O
some	O
use	O
monocular	O
video	B
to	O
infer	O
and	O
track	O
3d	O
models	O
directly	O
.	O
it	O
is	O
also	O
possible	O
to	O
use	O
temporal	O
models	O
to	O
improve	O
the	O
tracking	O
of	O
periodic	O
motions	O
,	O
such	O
as	O
walking	O
,	O
by	O
analyzing	O
the	O
joint	B
angles	O
as	O
functions	O
of	O
time	O
(	O
polana	O
and	O
nelson	O
1997	O
;	O
seitz	O
and	O
dyer	O
1997	O
;	O
cutler	O
and	O
davis	O
2000	O
)	O
.	O
the	O
generality	O
and	O
applicability	O
of	O
such	O
tech-	O
niques	O
can	O
be	O
improved	O
by	O
learning	O
typical	O
motion	B
patterns	O
using	O
principal	O
component	O
anal-	O
ysis	O
(	O
sidenbladh	O
,	O
black	O
,	O
and	O
fleet	O
2000	O
;	O
urtasun	O
,	O
fleet	O
,	O
and	O
fua	O
2006	O
)	O
.	O
probabilistic	B
models	I
.	O
because	O
tracking	O
can	O
be	O
such	O
a	O
difﬁcult	O
task	O
,	O
sophisticated	O
proba-	O
bilistic	O
inference	B
techniques	O
are	O
often	O
used	O
to	O
estimate	O
the	O
likely	O
states	O
of	O
the	O
person	O
being	O
tracked	O
.	O
one	O
popular	O
approach	O
,	O
called	O
particle	B
ﬁltering	I
(	O
isard	O
and	O
blake	O
1998	O
)	O
,	O
was	O
origi-	O
nally	O
developed	O
for	O
tracking	O
the	O
outlines	O
of	O
people	O
and	O
hands	O
,	O
as	O
described	O
in	O
section	O
5.1.2	O
12.6	O
model-based	B
reconstruction	O
609	O
figure	O
12.21	O
estimating	O
human	O
shape	O
and	O
pose	O
from	O
a	O
single	O
image	O
using	O
a	O
parametric	B
3d	O
model	O
(	O
guan	O
,	O
weiss	O
,	O
bˇalan	O
et	O
al	O
.	O
2009	O
)	O
c	O
(	O
cid:13	O
)	O
2009	O
ieee	O
.	O
(	O
figures	O
5.6–5.8	O
)	O
.	O
it	O
was	O
subsequently	O
applied	O
to	O
whole-body	O
tracking	O
(	O
deutscher	O
,	O
blake	O
,	O
and	O
reid	O
2000	O
;	O
sidenbladh	O
,	O
black	O
,	O
and	O
fleet	O
2000	O
;	O
deutscher	O
and	O
reid	O
2005	O
)	O
and	O
continues	O
to	O
be	O
used	O
in	O
modern	O
trackers	O
(	O
ong	O
,	O
micilotta	O
,	O
bowden	O
et	O
al	O
.	O
2006	O
)	O
.	O
alternative	O
approaches	O
to	O
handling	O
the	O
uncertainty	B
inherent	O
in	O
tracking	O
include	O
multiple	B
hypothesis	I
tracking	O
(	O
cham	O
and	O
rehg	O
1999	O
)	O
and	O
inﬂated	O
covariances	O
(	O
sminchisescu	O
and	O
triggs	O
2001	O
)	O
.	O
figure	O
12.20c–d	O
shows	O
an	O
example	O
of	O
a	O
sophisticated	O
spatio-temporal	O
probabilistic	B
graph-	O
ical	O
model	O
called	O
loose-limbed	O
people	O
,	O
which	O
models	O
not	O
only	O
the	O
geometric	B
relationship	O
be-	O
tween	O
various	O
limbs	O
,	O
but	O
also	O
their	O
likely	O
temporal	O
dynamics	O
(	O
sigal	O
,	O
bhatia	O
,	O
roth	O
et	O
al	O
.	O
2004	O
)	O
.	O
the	O
conditional	O
probabilities	O
relating	O
various	O
limbs	O
and	O
time	O
instances	O
are	O
learned	B
from	O
train-	O
ing	O
data	O
,	O
and	O
particle	B
ﬁltering	I
is	O
used	O
to	O
perform	O
the	O
ﬁnal	O
pose	O
inference	B
.	O
adaptive	B
shape	I
modeling	I
.	O
another	O
essential	O
component	O
of	O
whole	O
body	B
modeling	O
and	O
tracking	O
is	O
the	O
ﬁtting	O
of	O
parameterized	O
shape	O
models	O
to	O
visual	O
data	O
.	O
as	O
we	O
saw	O
in	O
sec-	O
tion	B
12.6.3	O
(	O
figure	O
12.19	O
)	O
,	O
the	O
availability	O
of	O
large	O
numbers	O
of	O
registered	O
3d	O
range	O
scans	O
can	O
be	O
used	O
to	O
create	O
morphable	O
models	O
of	O
shape	O
and	O
appearance	O
(	O
allen	O
,	O
curless	O
,	O
and	O
popovi´c	O
2003	O
)	O
.	O
building	O
on	O
this	O
work	O
,	O
anguelov	O
,	O
srinivasan	O
,	O
koller	O
et	O
al	O
.	O
(	O
2005	O
)	O
develop	O
a	O
sophis-	O
ticated	O
system	O
called	O
scape	O
(	O
shape	O
completion	O
and	O
animation	O
for	O
people	O
)	O
,	O
which	O
ﬁrst	O
610	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
acquires	O
a	O
large	O
number	O
of	O
range	O
scans	O
of	O
different	O
people	O
and	O
of	O
one	O
person	O
in	O
different	O
poses	O
,	O
and	O
then	O
registers	O
these	O
scans	O
using	O
semi-automated	O
marker	O
placement	O
.	O
the	O
registered	O
datasets	O
are	O
used	O
to	O
model	O
the	O
variation	O
in	O
shape	O
as	O
a	O
function	O
of	O
personal	O
characteristics	O
and	O
skeletal	O
pose	O
,	O
e.g.	O
,	O
the	O
bulging	O
of	O
muscles	O
as	O
certain	O
joints	O
are	O
ﬂexed	O
(	O
figure	O
12.21	O
,	O
top	O
row	O
)	O
.	O
the	O
resulting	O
system	O
can	O
then	O
be	O
used	O
for	O
shape	O
completion	O
,	O
i.e.	O
,	O
the	O
recovery	B
of	O
a	O
full	O
3d	O
mesh	O
model	O
from	O
a	O
small	O
number	O
of	O
captured	O
markers	O
,	O
by	O
ﬁnding	O
the	O
best	O
model	O
parameters	B
in	O
both	O
shape	O
and	O
pose	O
space	O
that	O
ﬁt	O
the	O
measured	O
data	O
.	O
because	O
it	O
is	O
constructed	O
completely	O
from	O
scans	O
of	O
people	O
in	O
close-ﬁtting	O
clothing	O
and	O
uses	O
a	O
parametric	B
shape	O
model	O
,	O
the	O
scape	O
system	O
can	O
not	O
cope	O
with	O
people	O
wearing	O
loose-	O
ﬁtting	O
clothing	O
.	O
b˘alan	O
and	O
black	O
(	O
2008	O
)	O
overcome	O
this	O
limitation	O
by	O
estimating	O
the	O
body	B
shape	O
that	O
ﬁts	O
within	O
the	O
visual	B
hull	I
of	O
the	O
same	O
person	O
observed	O
in	O
multiple	B
poses	O
,	O
while	O
vlasic	O
,	O
baran	O
,	O
matusik	O
et	O
al	O
.	O
(	O
2008	O
)	O
adapt	O
an	O
initial	O
surface	B
mesh	O
ﬁtted	O
with	O
a	O
parametric	B
shape	O
model	O
to	O
better	O
match	O
the	O
visual	B
hull	I
.	O
while	O
the	O
preceding	O
body	B
ﬁtting	O
and	O
pose	O
estimation	B
systems	O
use	O
multiple	B
views	O
to	O
esti-	O
mate	O
body	B
shape	O
,	O
even	O
more	O
recent	O
work	O
by	O
guan	O
,	O
weiss	O
,	O
bˇalan	O
et	O
al	O
.	O
(	O
2009	O
)	O
can	O
ﬁt	O
a	O
human	O
shape	O
and	O
pose	O
model	O
to	O
a	O
single	O
image	O
of	O
a	O
person	O
on	O
a	O
natural	B
background	O
.	O
manual	O
ini-	O
tialization	O
is	O
used	O
to	O
estimate	O
a	O
rough	O
pose	O
(	O
skeleton	O
)	O
and	O
height	O
model	O
,	O
and	O
this	O
is	O
then	O
used	O
to	O
segment	O
the	O
person	O
’	O
s	O
outline	O
using	O
the	O
grab	O
cut	O
segmentation	B
algorithm	O
(	O
section	O
5.5	O
)	O
.	O
the	O
shape	O
and	O
pose	O
estimate	O
are	O
then	O
reﬁned	O
using	O
a	O
combination	O
of	O
silhouette	O
edge	O
cues	O
and	O
shading	B
information	O
(	O
figure	O
12.21	O
)	O
.	O
the	O
resulting	O
3d	O
model	O
can	O
be	O
used	O
to	O
create	O
novel	O
animations	O
.	O
activity	B
recognition	I
.	O
the	O
ﬁnal	O
widely	O
studied	O
topic	O
in	O
human	O
modeling	O
is	O
motion	B
,	O
activity	O
,	O
and	O
action	O
recognition	B
(	O
bobick	O
1997	O
;	O
hu	O
,	O
tan	O
,	O
wang	O
et	O
al	O
.	O
2004	O
;	O
hilton	O
,	O
fua	O
,	O
and	O
ronfard	O
2006	O
)	O
.	O
examples	B
of	O
actions	O
that	O
are	O
commonly	O
recognized	O
include	O
walking	O
and	O
running	O
,	O
jumping	O
,	O
dancing	O
,	O
picking	O
up	O
objects	O
,	O
sitting	O
down	O
and	O
standing	O
up	O
,	O
and	O
waving	O
.	O
recent	O
representative	O
papers	O
on	O
these	O
topics	O
have	O
been	O
written	O
by	O
robertson	O
and	O
reid	O
(	O
2006	O
)	O
,	O
smin-	O
chisescu	O
,	O
kanaujia	O
,	O
and	O
metaxas	O
(	O
2006	O
)	O
,	O
weinland	O
,	O
ronfard	O
,	O
and	O
boyer	O
(	O
2006	O
)	O
,	O
yilmaz	O
and	O
shah	O
(	O
2006	O
)	O
,	O
and	O
gorelick	O
,	O
blank	O
,	O
shechtman	O
et	O
al	O
.	O
(	O
2007	O
)	O
.	O
12.7	O
recovering	O
texture	B
maps	O
and	O
albedos	O
after	O
a	O
3d	O
model	O
of	O
an	O
object	O
or	O
person	O
has	O
been	O
acquired	O
,	O
the	O
ﬁnal	O
step	O
in	O
modeling	B
is	O
usually	O
to	O
recover	O
a	O
texture	B
map	O
to	O
describe	O
the	O
object	O
’	O
s	O
surface	B
appearance	O
.	O
this	O
ﬁrst	O
requires	O
establishing	O
a	O
parameterization	O
for	O
the	O
(	O
u	O
,	O
v	O
)	O
texture	B
coordinates	O
as	O
a	O
function	O
of	O
3d	O
surface	B
position	O
.	O
one	O
simple	O
way	O
to	O
do	O
this	O
is	O
to	O
associate	O
a	O
separate	O
texture	B
map	O
with	O
each	O
triangle	O
(	O
or	O
pair	O
of	O
triangles	O
)	O
.	O
more	O
space-efﬁcient	O
techniques	O
involve	O
unwrapping	O
the	O
surface	B
onto	O
12.7	O
recovering	O
texture	B
maps	O
and	O
albedos	O
611	O
one	O
or	O
more	O
maps	O
,	O
e.g.	O
,	O
using	O
a	O
subdivision	O
mesh	O
(	O
section	O
12.3.2	O
)	O
(	O
eck	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1995	O
)	O
or	O
a	O
geometry	O
image	B
(	O
section	O
12.3.3	O
)	O
(	O
gu	O
,	O
gortler	O
,	O
and	O
hoppe	O
2002	O
)	O
.	O
once	O
the	O
(	O
u	O
,	O
v	O
)	O
coordinates	O
for	O
each	O
triangle	O
have	O
been	O
ﬁxed	O
,	O
the	O
perspective	B
projec-	O
tion	B
equations	O
mapping	O
from	O
texture	B
(	O
u	O
,	O
v	O
)	O
to	O
an	O
image	B
j	O
’	O
s	O
pixel	O
(	O
uj	O
,	O
vj	O
)	O
coordinates	O
can	O
be	O
obtained	O
by	O
concatenating	O
the	O
afﬁne	B
(	O
u	O
,	O
v	O
)	O
→	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
mapping	O
with	O
the	O
perspective	B
ho-	O
mography	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
→	O
(	O
uj	O
,	O
vj	O
)	O
(	O
szeliski	O
and	O
shum	O
1997	O
)	O
.	O
the	O
color	B
values	O
for	O
the	O
(	O
u	O
,	O
v	O
)	O
texture	B
map	O
can	O
then	O
be	O
re-sampled	O
and	O
stored	O
,	O
or	O
the	O
original	O
image	B
can	O
itself	O
be	O
used	O
as	O
the	O
texture	B
source	O
using	O
projective	O
texture	B
mapping	O
(	O
opengl-arb	O
1997	O
)	O
.	O
the	O
situation	O
becomes	O
more	O
involved	O
when	O
more	O
than	O
one	O
source	O
image	B
is	O
available	O
for	O
appearance	O
recovery	B
,	O
which	O
is	O
the	O
usual	O
case	O
.	O
one	O
possibility	O
is	O
to	O
use	O
a	O
view-dependent	O
texture	O
map	O
(	O
section	O
13.1.1	O
)	O
,	O
in	O
which	O
a	O
different	O
source	O
image	B
(	O
or	O
combination	O
of	O
source	O
images	O
)	O
is	O
used	O
for	O
each	O
polygonal	O
face	B
based	O
on	O
the	O
angles	O
between	O
the	O
virtual	O
camera	O
,	O
the	O
surface	B
normals	O
,	O
and	O
the	O
source	O
images	O
(	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
1996	O
;	O
pighin	O
,	O
hecker	O
,	O
lischinski	O
et	O
al	O
.	O
1998	O
)	O
.	O
an	O
alternative	O
approach	O
is	O
to	O
estimate	O
a	O
complete	O
surface	O
light	O
field	O
for	O
each	O
surface	B
point	O
(	O
wood	O
,	O
azuma	O
,	O
aldinger	O
et	O
al	O
.	O
2000	O
)	O
,	O
as	O
described	O
in	O
section	O
13.3.2.	O
in	O
some	O
situations	O
,	O
e.g.	O
,	O
when	O
using	O
models	O
in	O
traditional	O
3d	O
games	O
,	O
it	O
is	O
preferable	O
to	O
merge	O
all	O
of	O
the	O
source	O
images	O
into	O
a	O
single	O
coherent	O
texture	B
map	O
during	O
pre-processing	O
.	O
ideally	O
,	O
each	O
surface	B
triangle	O
should	O
select	O
the	O
source	O
image	B
where	O
it	O
is	O
seen	O
most	O
directly	O
(	O
perpendicular	O
to	O
its	O
normal	O
)	O
and	O
at	O
the	O
resolution	O
best	O
matching	B
the	O
texture	B
map	O
resolution.14	O
this	O
can	O
be	O
posed	O
as	O
a	O
graph	B
cut	I
optimization	O
problem	O
,	O
where	O
the	O
smoothness	B
term	O
encour-	O
ages	O
adjacent	O
triangles	O
to	O
use	O
similar	O
source	O
images	O
,	O
followed	O
by	O
blending	O
to	O
compensate	O
for	O
exposure	O
differences	O
(	O
lempitsky	O
and	O
ivanov	O
2007	O
;	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
2008	O
)	O
.	O
even	O
better	O
results	O
can	O
be	O
obtained	O
by	O
explicitly	O
modeling	B
geometric	O
and	O
photometric	B
mis-	O
alignments	O
between	O
the	O
source	O
images	O
(	O
shum	O
and	O
szeliski	O
2000	O
;	O
gal	O
,	O
wexler	O
,	O
ofek	O
et	O
al	O
.	O
2010	O
)	O
.	O
these	O
kinds	O
of	O
approaches	O
produce	O
good	O
results	O
when	O
the	O
lighting	B
stays	O
ﬁxed	O
with	O
respect	O
to	O
the	O
object	O
,	O
i.e.	O
,	O
when	O
the	O
camera	B
moves	O
around	O
the	O
object	O
or	O
space	O
.	O
when	O
the	O
lighting	B
is	O
strongly	O
directional	O
,	O
however	O
,	O
and	O
the	O
object	O
is	O
being	O
moved	O
relative	O
to	O
this	O
lighting	B
,	O
strong	O
shading	B
effects	O
or	O
specularities	B
may	O
be	O
present	O
,	O
which	O
will	O
interfere	O
with	O
the	O
reliable	O
recov-	O
ery	O
of	O
a	O
texture	B
(	O
albedo	O
)	O
map	O
.	O
in	O
this	O
case	O
,	O
it	O
is	O
preferable	O
to	O
explicitly	O
undo	O
the	O
shading	B
effects	O
(	O
section	O
12.1	O
)	O
by	O
modeling	O
the	O
light	O
source	O
directions	O
and	O
estimating	O
the	O
surface	B
re-	O
ﬂectance	O
properties	B
while	O
recovering	O
the	O
texture	B
map	O
(	O
sato	O
and	O
ikeuchi	O
1996	O
;	O
sato	O
,	O
wheeler	O
,	O
and	O
ikeuchi	O
1997	O
;	O
yu	O
and	O
malik	O
1998	O
;	O
yu	O
,	O
debevec	O
,	O
malik	O
et	O
al	O
.	O
1999	O
)	O
.	O
figure	O
12.22	O
shows	O
the	O
results	O
of	O
one	O
such	O
approach	O
,	O
where	O
the	O
specularities	B
are	O
ﬁrst	O
removed	O
while	O
estimat-	O
ing	O
the	O
matte	O
reﬂectance	B
component	O
(	O
albedo	O
)	O
and	O
then	O
later	O
re-introduced	O
by	O
estimating	O
the	O
specular	B
component	O
ks	O
in	O
a	O
torrance–sparrow	O
reﬂection	O
model	O
(	O
2.91	O
)	O
.	O
14	O
when	O
surfaces	O
are	O
seen	O
at	O
oblique	O
viewing	O
angles	O
,	O
it	O
may	O
be	O
necessary	O
to	O
blend	O
different	O
images	O
together	O
to	O
obtain	O
the	O
best	O
resolution	O
(	O
wang	O
,	O
kang	O
,	O
szeliski	O
et	O
al	O
.	O
2001	O
)	O
.	O
612	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
12.22	O
estimating	O
the	O
diffuse	B
albedo	O
and	O
reﬂectance	B
parameters	O
for	O
a	O
scanned	O
3d	O
model	O
(	O
sato	O
,	O
wheeler	O
,	O
and	O
ikeuchi	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
:	O
(	O
a	O
)	O
set	O
of	O
input	O
images	O
projected	O
onto	O
the	O
model	O
;	O
(	O
b	O
)	O
the	O
complete	O
diffuse	B
reﬂection	O
(	O
albedo	O
)	O
model	O
;	O
(	O
c	O
)	O
rendering	B
from	O
the	O
reﬂectance	B
model	O
including	O
the	O
specular	B
component	O
.	O
12.7.1	O
estimating	O
brdfs	O
a	O
more	O
ambitious	O
approach	O
to	O
the	O
problem	O
of	O
view-dependent	B
appearance	O
modeling	B
is	O
to	O
estimate	O
a	O
general	O
bidirectional	O
reﬂectance	B
distribution	O
function	O
(	O
brdf	O
)	O
for	O
each	O
point	O
on	O
an	O
object	O
’	O
s	O
surface	B
.	O
dana	O
,	O
van	O
ginneken	O
,	O
nayar	O
et	O
al	O
.	O
(	O
1999	O
)	O
,	O
jensen	O
,	O
marschner	O
,	O
levoy	O
et	O
al	O
.	O
(	O
2001	O
)	O
,	O
and	O
lensch	O
,	O
kautz	O
,	O
goesele	O
et	O
al	O
.	O
(	O
2003	O
)	O
present	O
different	O
techniques	O
for	O
estimating	O
such	O
functions	O
,	O
while	O
dorsey	O
,	O
rushmeier	O
,	O
and	O
sillion	O
(	O
2007	O
)	O
and	O
weyrich	O
,	O
lawrence	O
,	O
lensch	O
et	O
al	O
.	O
(	O
2008	O
)	O
present	O
more	O
recent	O
surveys	B
of	O
the	O
topics	O
of	O
brdf	O
modeling	B
,	O
recovery	B
,	O
and	O
rendering	B
.	O
as	O
we	O
saw	O
in	O
section	O
2.2.2	O
(	O
2.81	O
)	O
,	O
the	O
brdf	O
can	O
be	O
written	O
as	O
fr	O
(	O
θi	O
,	O
φi	O
,	O
θr	O
,	O
φr	O
;	O
λ	O
)	O
,	O
(	O
12.9	O
)	O
where	O
(	O
θi	O
,	O
φi	O
)	O
and	O
(	O
θr	O
,	O
φr	O
)	O
are	O
the	O
angles	O
the	O
incident	O
ˆvi	O
and	O
reﬂected	O
ˆvr	O
light	O
ray	O
directions	O
make	O
with	O
the	O
local	B
surface	O
coordinate	O
frame	O
(	O
ˆdx	O
,	O
ˆdy	O
,	O
ˆn	O
)	O
shown	O
in	O
figure	O
2.15.	O
when	O
mod-	O
eling	O
the	O
appearance	O
of	O
an	O
object	O
,	O
as	O
opposed	O
to	O
the	O
appearance	O
of	O
a	O
patch	B
of	O
material	O
,	O
we	O
need	O
to	O
estimate	O
this	O
function	O
at	O
every	O
point	O
(	O
x	O
,	O
y	O
)	O
on	O
the	O
object	O
’	O
s	O
surface	B
,	O
which	O
gives	O
us	O
the	O
spatially	O
varying	O
brdf	O
,	O
or	O
svbrdf	O
(	O
weyrich	O
,	O
lawrence	O
,	O
lensch	O
et	O
al	O
.	O
2008	O
)	O
,	O
fv	O
(	O
x	O
,	O
y	O
,	O
θi	O
,	O
φi	O
,	O
θr	O
,	O
φr	O
;	O
λ	O
)	O
.	O
(	O
12.10	O
)	O
if	O
sub-surface	O
scattering	O
effects	O
are	O
being	O
modeled	O
,	O
such	O
as	O
the	O
long-range	O
transmission	O
of	O
light	O
through	O
materials	O
such	O
as	O
alabaster	O
,	O
the	O
eight-dimensional	O
bidirectional	O
scattering-	O
surface	B
reﬂectance-distribution	O
function	O
(	O
bssrdf	O
)	O
is	O
used	O
instead	O
,	O
fe	O
(	O
xi	O
,	O
yi	O
,	O
θi	O
,	O
φi	O
,	O
xe	O
,	O
ye	O
,	O
θe	O
,	O
φe	O
;	O
λ	O
)	O
,	O
(	O
12.11	O
)	O
where	O
the	O
e	O
subscript	O
now	O
represents	O
the	O
emitted	O
rather	O
than	O
the	O
reﬂected	O
light	O
directions	O
.	O
12.7	O
recovering	O
texture	B
maps	O
and	O
albedos	O
613	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
12.23	O
image-based	B
reconstruction	O
of	O
appearance	O
and	O
detailed	O
geometry	O
(	O
lensch	O
,	O
kautz	O
,	O
goesele	O
et	O
al	O
.	O
2003	O
)	O
c	O
(	O
cid:13	O
)	O
2003	O
acm	O
.	O
(	O
a	O
)	O
appearance	O
models	O
(	O
brdfs	O
)	O
are	O
re-estimated	O
using	O
divisive	O
clustering	O
.	O
(	O
b	O
)	O
in	O
order	B
to	O
model	O
detailed	O
spatially	O
varying	O
appearance	O
,	O
each	O
lumitexel	O
is	O
projected	O
onto	O
the	O
basis	O
formed	O
by	O
the	O
clustered	O
materials	O
.	O
weyrich	O
,	O
lawrence	O
,	O
lensch	O
et	O
al	O
.	O
(	O
2008	O
)	O
provide	O
a	O
nice	O
survey	O
of	O
these	O
and	O
related	O
topics	O
,	O
including	O
basic	O
photometry	O
,	O
brdf	O
models	O
,	O
traditional	O
brdf	O
acquisition	O
using	O
gonio	O
reﬂec-	O
tometry	O
(	O
the	O
precise	O
measurement	O
of	O
visual	O
angles	O
and	O
reﬂectances	O
)	O
,	O
multiplexed	O
illumination	O
(	O
schechner	O
,	O
nayar	O
,	O
and	O
belhumeur	O
2009	O
)	O
,	O
skin	O
modeling	B
(	O
debevec	O
,	O
hawkins	O
,	O
tchou	O
et	O
al	O
.	O
2000	O
;	O
weyrich	O
,	O
matusik	O
,	O
pﬁster	O
et	O
al	O
.	O
2006	O
)	O
,	O
and	O
image-based	B
acquisition	O
techniques	O
,	O
which	O
simultaneously	O
recover	O
an	O
object	O
’	O
s	O
3d	O
shape	O
and	O
reﬂectometry	O
from	O
multiple	B
photographs	O
.	O
a	O
nice	O
example	O
of	O
this	O
latter	O
approach	O
is	O
the	O
system	O
developed	O
by	O
lensch	O
,	O
kautz	O
,	O
goesele	O
et	O
al	O
.	O
(	O
2003	O
)	O
,	O
who	O
estimate	O
locally	O
varying	O
brdfs	O
and	O
reﬁne	O
their	O
shape	O
models	O
using	O
local	O
estimates	O
of	O
surface	B
normals	O
.	O
to	O
build	O
up	O
their	O
models	O
,	O
they	O
ﬁrst	O
associate	O
a	O
lumitexels	O
,	O
which	O
contains	O
a	O
3d	O
position	O
,	O
a	O
surface	B
normal	O
,	O
and	O
a	O
set	O
of	O
sparse	B
radiance	O
samples	O
,	O
with	O
each	O
surface	B
point	O
.	O
next	O
,	O
they	O
cluster	O
such	O
lumitexels	O
into	O
materials	O
that	O
share	O
common	O
properties	B
,	O
using	O
a	O
lafortune	O
reﬂectance	B
model	O
(	O
lafortune	O
,	O
foo	O
,	O
torrance	O
et	O
al	O
.	O
1997	O
)	O
and	O
a	O
divisive	B
clustering	O
approach	O
(	O
figure	O
12.23a	O
)	O
.	O
finally	O
,	O
in	O
order	B
to	O
model	O
detailed	O
spatially	O
varying	O
appearance	O
,	O
each	O
lumitexel	O
(	O
surface	B
point	O
)	O
is	O
projected	O
onto	O
the	O
basis	O
of	O
clustered	O
appearance	O
models	O
(	O
figure	O
12.23b	O
)	O
.	O
while	O
most	O
of	O
the	O
techniques	O
discussed	O
in	O
this	O
section	O
require	O
large	O
numbers	O
of	O
views	O
to	O
estimate	O
surface	B
properties	O
,	O
a	O
challenging	O
future	O
direction	O
will	O
be	O
to	O
take	O
these	O
techniques	O
out	O
of	O
the	O
lab	O
and	O
into	O
the	O
real	O
world	O
,	O
and	O
to	O
combine	O
them	O
with	O
regular	O
and	O
internet	O
photo	O
image-based	O
modeling	B
approaches	O
.	O
12.7.2	O
application	O
:	O
3d	O
photography	O
the	O
techniques	O
described	O
in	O
this	O
chapter	O
for	O
building	O
complete	O
3d	O
models	O
from	O
multiple	B
im-	O
ages	O
and	O
then	O
recovering	O
their	O
surface	B
appearance	O
have	O
opened	O
up	O
a	O
whole	O
new	O
range	O
of	O
applications	O
that	O
often	O
go	O
under	O
the	O
name	O
3d	O
photography	O
.	O
pollefeys	O
and	O
van	O
gool	O
(	O
2002	O
)	O
provide	O
a	O
nice	O
introduction	O
to	O
this	O
ﬁeld	O
,	O
including	O
the	O
processing	O
steps	O
of	O
feature	B
matching	O
,	O
614	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
structure	B
from	I
motion	I
recovery,15	O
dense	O
depth	O
map	O
estimation	B
,	O
3d	O
model	O
building	O
,	O
and	O
tex-	O
ture	O
map	O
recovery	B
.	O
a	O
complete	O
web-based	O
system	O
for	O
automatically	O
performing	O
all	O
of	O
these	O
tasks	O
,	O
called	O
arc3d	O
,	O
is	O
described	O
by	O
vergauwen	O
and	O
van	O
gool	O
(	O
2006	O
)	O
and	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
(	O
2010	O
)	O
.	O
the	O
latter	O
paper	O
provides	O
not	O
only	O
an	O
in-depth	O
survey	O
of	O
this	O
whole	O
ﬁeld	O
but	O
also	O
a	O
detailed	O
description	O
of	O
their	O
complete	O
end-to-end	O
system	O
.	O
an	O
alternative	O
to	O
such	O
fully	O
automated	B
systems	O
is	O
to	O
put	O
the	O
user	O
in	O
the	O
loop	O
in	O
what	O
is	O
sometimes	O
called	O
interactive	B
computer	O
vision	O
.	O
van	O
den	O
hengel	O
,	O
dick	O
,	O
thormhlen	O
et	O
al	O
.	O
(	O
2007	O
)	O
describe	O
their	O
videotrace	O
system	O
,	O
which	O
performs	O
automated	B
point	O
tracking	O
and	O
3d	O
structure	O
recovery	O
from	O
video	B
and	O
then	O
lets	O
the	O
user	O
draw	O
triangles	O
and	O
surfaces	O
on	O
top	O
of	O
the	O
resulting	O
point	O
cloud	O
,	O
as	O
well	O
as	O
interactively	O
adjusting	O
the	O
locations	O
of	O
model	O
vertices	O
.	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
(	O
2008	O
)	O
describe	O
a	O
related	O
system	O
that	O
uses	O
matched	O
vanishing	B
points	I
in	O
multiple	B
images	O
(	O
figure	O
4.45	O
)	O
to	O
infer	O
3d	O
line	O
orientations	O
and	O
plane	O
normals	O
.	O
these	O
are	O
then	O
used	O
to	O
guide	O
the	O
user	O
drawing	O
axis-aligned	O
planes	B
,	O
which	O
are	O
automatically	O
ﬁtted	O
to	O
the	O
recovered	O
3d	O
point	O
cloud	O
.	O
fully	O
automated	B
variants	O
on	O
these	O
ideas	O
are	O
described	O
by	O
zebedin	O
,	O
bauer	O
,	O
karner	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
furukawa	O
,	O
curless	O
,	O
seitz	O
et	O
al	O
.	O
(	O
2009a	O
)	O
,	O
furukawa	O
,	O
curless	O
,	O
seitz	O
et	O
al	O
.	O
(	O
2009b	O
)	O
,	O
miˇcuˇs´ık	O
and	O
koˇseck´a	O
(	O
2009	O
)	O
,	O
and	O
sinha	O
,	O
steedly	O
,	O
and	O
szeliski	O
(	O
2009	O
)	O
.	O
as	O
the	O
sophistication	O
and	O
reliability	O
of	O
these	O
techniques	O
continues	O
to	O
improve	O
,	O
we	O
can	O
ex-	O
pect	O
to	O
see	O
even	O
more	O
user-friendly	O
applications	O
for	O
photorealistic	O
3d	O
modeling	B
from	O
images	O
(	O
exercise	O
12.8	O
)	O
.	O
12.8	O
additional	O
reading	O
shape	O
from	O
shading	B
is	O
one	O
of	O
the	O
classic	O
problems	O
in	O
computer	O
vision	O
(	O
horn	O
1975	O
)	O
.	O
some	O
representative	O
papers	O
in	O
this	O
area	O
include	O
those	O
by	O
horn	O
(	O
1977	O
)	O
,	O
ikeuchi	O
and	O
horn	O
(	O
1981	O
)	O
,	O
pentland	O
(	O
1984	O
)	O
,	O
horn	O
and	O
brooks	O
(	O
1986	O
)	O
,	O
horn	O
(	O
1990	O
)	O
,	O
szeliski	O
(	O
1991a	O
)	O
,	O
mancini	O
and	O
wolff	O
(	O
1992	O
)	O
,	O
dupuis	O
and	O
oliensis	O
(	O
1994	O
)	O
,	O
and	O
fua	O
and	O
leclerc	O
(	O
1995	O
)	O
.	O
the	O
collection	O
of	O
papers	O
edited	O
by	O
horn	O
and	O
brooks	O
(	O
1989	O
)	O
is	O
a	O
great	O
source	O
of	O
information	O
on	O
this	O
topic	O
,	O
especially	O
the	O
chapter	O
on	O
variational	O
approaches	O
.	O
the	O
survey	O
by	O
zhang	O
,	O
tsai	O
,	O
cryer	O
et	O
al	O
.	O
(	O
1999	O
)	O
not	O
only	O
reviews	O
more	O
recent	O
techniques	O
but	O
also	O
provides	O
some	O
comparative	O
results	O
.	O
woodham	O
(	O
1981	O
)	O
wrote	O
the	O
seminal	O
paper	O
of	O
photometric	B
stereo	I
.	O
shape	O
from	O
texture	B
techniques	O
include	O
those	O
by	O
witkin	O
(	O
1981	O
)	O
,	O
ikeuchi	O
(	O
1981	O
)	O
,	O
blostein	O
and	O
ahuja	O
(	O
1987	O
)	O
,	O
gard-	O
ing	O
(	O
1992	O
)	O
,	O
malik	O
and	O
rosenholtz	O
(	O
1997	O
)	O
,	O
liu	O
,	O
collins	O
,	O
and	O
tsin	O
(	O
2004	O
)	O
,	O
liu	O
,	O
lin	O
,	O
and	O
hays	O
(	O
2004	O
)	O
,	O
hays	O
,	O
leordeanu	O
,	O
efros	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
lin	O
,	O
hays	O
,	O
wu	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
lobay	O
and	O
forsyth	O
(	O
2006	O
)	O
,	O
white	O
and	O
forsyth	O
(	O
2006	O
)	O
,	O
white	O
,	O
crane	O
,	O
and	O
forsyth	O
(	O
2007	O
)	O
,	O
and	O
park	O
,	O
brockle-	O
hurst	O
,	O
collins	O
et	O
al	O
.	O
(	O
2009	O
)	O
.	O
good	O
papers	O
and	O
books	O
on	O
depth	O
from	O
defocus	O
have	O
been	O
written	O
by	O
pentland	O
(	O
1987	O
)	O
,	O
nayar	O
and	O
nakagawa	O
(	O
1994	O
)	O
,	O
nayar	O
,	O
watanabe	O
,	O
and	O
noguchi	O
(	O
1996	O
)	O
,	O
15	O
these	O
earlier	O
steps	O
are	O
also	O
discussed	O
in	O
section	O
7.4.4	O
.	O
12.8	O
additional	O
reading	O
615	O
watanabe	O
and	O
nayar	O
(	O
1998	O
)	O
,	O
chaudhuri	O
and	O
rajagopalan	O
(	O
1999	O
)	O
,	O
and	O
favaro	O
and	O
soatto	O
(	O
2006	O
)	O
.	O
additional	O
techniques	O
for	O
recovering	O
shape	O
from	O
various	O
kinds	O
of	O
illumination	O
ef-	O
fects	O
,	O
including	O
inter-reﬂections	O
(	O
nayar	O
,	O
ikeuchi	O
,	O
and	O
kanade	O
1991	O
)	O
,	O
are	O
discussed	O
in	O
the	O
book	O
on	O
shape	O
recovery	O
edited	O
by	O
wolff	O
,	O
shafer	O
,	O
and	O
healey	O
(	O
1992b	O
)	O
.	O
active	O
rangeﬁnding	O
systems	O
,	O
which	O
use	O
laser	O
or	O
natural	B
light	O
illumination	O
projected	O
into	O
the	O
scene	O
,	O
have	O
been	O
described	O
by	O
besl	O
(	O
1989	O
)	O
,	O
rioux	O
and	O
bird	O
(	O
1993	O
)	O
,	O
kang	O
,	O
webb	O
,	O
zit-	O
nick	O
et	O
al	O
.	O
(	O
1995	O
)	O
,	O
curless	O
and	O
levoy	O
(	O
1995	O
)	O
,	O
curless	O
and	O
levoy	O
(	O
1996	O
)	O
,	O
proesmans	O
,	O
van	O
gool	O
,	O
and	O
defoort	O
(	O
1998	O
)	O
,	O
bouguet	O
and	O
perona	O
(	O
1999	O
)	O
,	O
curless	O
(	O
1999	O
)	O
,	O
hebert	O
(	O
2000	O
)	O
,	O
id-	O
dan	O
and	O
yahav	O
(	O
2001	O
)	O
,	O
goesele	O
,	O
fuchs	O
,	O
and	O
seidel	O
(	O
2003	O
)	O
,	O
scharstein	O
and	O
szeliski	O
(	O
2003	O
)	O
,	O
davis	O
,	O
ramamoorthi	O
,	O
and	O
rusinkiewicz	O
(	O
2003	O
)	O
,	O
zhang	O
,	O
curless	O
,	O
and	O
seitz	O
(	O
2003	O
)	O
,	O
zhang	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
(	O
2004	O
)	O
,	O
and	O
moons	O
,	O
van	O
gool	O
,	O
and	O
vergauwen	O
(	O
2010	O
)	O
.	O
individual	O
range	O
scans	O
can	O
be	O
aligned	O
using	O
3d	O
correspondence	B
and	O
distance	O
optimization	O
techniques	O
such	O
as	O
iterated	O
closest	O
points	B
and	O
its	O
variants	O
(	O
besl	O
and	O
mckay	O
1992	O
;	O
zhang	O
1994	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
johnson	O
and	O
kang	O
1997	O
;	O
gold	O
,	O
rangarajan	O
,	O
lu	O
et	O
al	O
.	O
1998	O
;	O
johnson	O
and	O
hebert	O
1999	O
;	O
pulli	O
1999	O
;	O
david	O
,	O
dementhon	O
,	O
duraiswami	O
et	O
al	O
.	O
2004	O
;	O
li	O
and	O
hartley	O
2007	O
;	O
enqvist	O
,	O
josephson	O
,	O
and	O
kahl	O
2009	O
)	O
.	O
once	O
they	O
have	O
been	O
aligned	O
,	O
range	O
scans	O
can	O
be	O
merged	O
using	O
techniques	O
that	O
model	O
the	O
signed	B
distance	O
of	O
surfaces	O
to	O
volumetric	B
sam-	O
ple	O
points	B
(	O
hoppe	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1992	O
;	O
curless	O
and	O
levoy	O
1996	O
;	O
hilton	O
,	O
stoddart	O
,	O
illingworth	O
et	O
al	O
.	O
1996	O
;	O
wheeler	O
,	O
sato	O
,	O
and	O
ikeuchi	O
1998	O
;	O
kazhdan	O
,	O
bolitho	O
,	O
and	O
hoppe	O
2006	O
;	O
lempitsky	O
and	O
boykov	O
2007	O
;	O
zach	O
,	O
pock	O
,	O
and	O
bischof	O
2007b	O
;	O
zach	O
2008	O
)	O
.	O
once	O
constructed	O
,	O
3d	O
surfaces	O
can	O
be	O
modeled	O
and	O
manipulated	O
using	O
a	O
variety	O
of	O
three-	O
dimensional	O
representations	O
,	O
which	O
include	O
triangle	O
meshes	O
(	O
eck	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1995	O
;	O
hoppe	O
1996	O
)	O
,	O
splines	B
(	O
farin	O
1992	O
,	O
1996	O
;	O
lee	O
,	O
wolberg	O
,	O
and	O
shin	O
1996	O
)	O
,	O
subdivision	O
surfaces	O
(	O
stollnitz	O
,	O
derose	O
,	O
and	O
salesin	O
1996	O
;	O
zorin	O
,	O
schr¨oder	O
,	O
and	O
sweldens	O
1996	O
;	O
warren	O
and	O
weimer	O
2001	O
;	O
peters	O
and	O
reif	O
2008	O
)	O
,	O
and	O
geometry	O
images	O
(	O
gu	O
,	O
gortler	O
,	O
and	O
hoppe	O
2002	O
)	O
.	O
alternatively	O
,	O
they	O
can	O
be	O
represented	O
as	O
collections	O
of	O
point	O
samples	O
with	O
local	O
ori-	O
entation	O
estimates	O
(	O
hoppe	O
,	O
derose	O
,	O
duchamp	O
et	O
al	O
.	O
1992	O
;	O
szeliski	O
and	O
tonnesen	O
1992	O
;	O
turk	O
and	O
o	O
’	O
brien	O
2002	O
;	O
pﬁster	O
,	O
zwicker	O
,	O
van	O
baar	O
et	O
al	O
.	O
2000	O
;	O
alexa	O
,	O
behr	O
,	O
cohen-or	O
et	O
al	O
.	O
2003	O
;	O
pauly	O
,	O
keiser	O
,	O
kobbelt	O
et	O
al	O
.	O
2003	O
;	O
diebel	O
,	O
thrun	O
,	O
and	O
br¨unig	O
2006	O
;	O
guennebaud	O
and	O
gross	O
2007	O
;	O
guennebaud	O
,	O
germann	O
,	O
and	O
gross	O
2008	O
;	O
oztireli	O
,	O
guennebaud	O
,	O
and	O
gross	O
2008	O
)	O
.	O
they	O
can	O
also	O
be	O
modeled	O
using	O
implicit	O
inside–outside	O
characteristic	O
or	O
signed	B
distance	O
functions	O
sampled	O
on	O
regular	O
or	O
irregular	O
(	O
octree	B
)	O
volumetric	B
grids	O
(	O
lavall´ee	O
and	O
szeliski	O
1995	O
;	O
szeliski	O
and	O
lavall´ee	O
1996	O
;	O
frisken	O
,	O
perry	O
,	O
rockwood	O
et	O
al	O
.	O
2000	O
;	O
dinh	O
,	O
turk	O
,	O
and	O
slabaugh	O
2002	O
;	O
kazhdan	O
,	O
bolitho	O
,	O
and	O
hoppe	O
2006	O
;	O
lempitsky	O
and	O
boykov	O
2007	O
;	O
zach	O
,	O
pock	O
,	O
and	O
bischof	O
2007b	O
;	O
zach	O
2008	O
)	O
.	O
the	O
literature	O
on	O
model-based	B
3d	O
reconstruction	O
is	O
extensive	O
.	O
for	O
modeling	O
architecture	B
and	O
urban	O
scenes	O
,	O
both	O
interactive	B
and	O
fully	O
automated	B
systems	O
have	O
been	O
developed	O
.	O
a	O
special	O
journal	O
issue	O
devoted	O
to	O
the	O
reconstruction	O
of	O
large-scale	O
3d	O
scenes	O
(	O
zhu	O
and	O
kanade	O
616	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
2008	O
)	O
is	O
a	O
good	O
source	O
of	O
references	B
and	O
robertson	O
and	O
cipolla	O
(	O
2009	O
)	O
give	O
a	O
nice	O
description	O
of	O
a	O
complete	O
system	O
.	O
lots	O
of	O
additional	O
references	B
can	O
be	O
found	O
in	O
section	O
12.6.1.	O
face	B
and	O
whole	O
body	B
modeling	O
and	O
tracking	O
is	O
a	O
very	O
active	O
sub-ﬁeld	O
of	O
computer	O
vision	O
,	O
with	O
its	O
own	O
conferences	O
and	O
workshops	O
,	O
e.g.	O
,	O
the	O
international	O
conference	O
on	O
automatic	B
face	O
and	O
gesture	O
recognition	B
(	O
fg	O
)	O
,	O
the	O
ieee	O
workshop	O
on	O
analysis	O
and	O
modeling	B
of	O
faces	B
and	O
gestures	O
,	O
and	O
the	O
international	O
workshop	O
on	O
tracking	O
humans	O
for	O
the	O
evaluation	B
of	O
their	O
motion	B
in	O
image	B
sequences	O
(	O
themis	O
)	O
.	O
recent	O
survey	O
articles	O
on	O
the	O
topic	O
of	O
whole	O
body	B
modeling	O
and	O
tracking	O
include	O
those	O
by	O
forsyth	O
,	O
arikan	O
,	O
ikemoto	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
moeslund	O
,	O
hilton	O
,	O
and	O
kr¨uger	O
(	O
2006	O
)	O
,	O
and	O
sigal	O
,	O
balan	O
,	O
and	O
black	O
(	O
2010	O
)	O
.	O
12.9	O
exercises	O
ex	O
12.1	O
:	O
shape	O
from	O
focus	B
grab	O
a	O
series	O
of	O
focused	O
images	O
with	O
a	O
digital	O
slr	O
set	O
to	O
man-	O
ual	O
focus	B
(	O
or	O
get	O
one	O
that	O
allows	O
for	O
programmatic	O
focus	B
control	O
)	O
and	O
recover	O
the	O
depth	O
of	O
an	O
object	O
.	O
1.	O
take	O
some	O
calibration	B
images	O
,	O
e.g.	O
,	O
of	O
a	O
checkerboard	O
,	O
so	O
you	O
can	O
compute	O
a	O
mapping	O
between	O
the	O
amount	O
of	O
defocus	O
and	O
the	O
focus	B
setting	O
.	O
2.	O
try	O
both	O
a	O
fronto-parallel	O
planar	O
target	O
and	O
one	O
which	O
is	O
slanted	O
so	O
that	O
it	O
covers	O
the	O
working	O
range	O
of	O
the	O
sensor	B
.	O
which	O
one	O
works	O
better	O
?	O
3.	O
now	O
put	O
a	O
real	O
object	O
in	O
the	O
scene	O
and	O
perform	O
a	O
similar	O
focus	B
sweep	O
.	O
4.	O
for	O
each	O
pixel	O
,	O
compute	O
the	O
local	B
sharpness	O
and	O
ﬁt	O
a	O
parabolic	O
curve	O
over	O
focus	O
settings	O
to	O
ﬁnd	O
the	O
most	O
in-focus	O
setting	O
.	O
5.	O
map	O
these	O
focus	B
settings	O
to	O
depth	O
and	O
compare	O
your	O
result	O
to	O
ground	O
truth	O
.	O
if	O
you	O
are	O
using	O
a	O
known	O
simple	O
object	O
,	O
such	O
as	O
sphere	O
or	O
cylinder	O
(	O
a	O
ball	O
or	O
a	O
soda	O
can	O
)	O
,	O
it	O
’	O
s	O
easy	O
to	O
measure	O
its	O
true	O
shape	O
.	O
6	O
.	O
(	O
optional	O
)	O
see	O
if	O
you	O
can	O
recover	O
the	O
depth	B
map	I
from	O
just	O
two	O
or	O
three	O
focus	B
settings	O
.	O
7	O
.	O
(	O
optional	O
)	O
use	O
an	O
lcd	O
projector	O
to	O
project	O
artiﬁcial	O
texture	B
onto	O
the	O
scene	O
.	O
use	O
a	O
pair	O
of	O
cameras	O
to	O
compare	O
the	O
accuracy	B
of	O
your	O
shape	O
from	O
focus	B
and	O
shape	O
from	O
stereo	B
techniques	O
.	O
8	O
.	O
(	O
optional	O
)	O
create	O
an	O
all-in-focus	O
image	B
using	O
the	O
technique	O
of	O
agarwala	O
,	O
dontcheva	O
,	O
agrawala	O
et	O
al	O
.	O
(	O
2004	O
)	O
.	O
ex	O
12.2	O
:	O
shadow	B
striping	O
implement	O
the	O
handheld	O
shadow	B
striping	O
system	O
of	O
bouguet	O
and	O
perona	O
(	O
1999	O
)	O
.	O
the	O
basic	O
steps	O
include	O
the	O
following	O
.	O
12.9	O
exercises	O
617	O
1.	O
set	O
up	O
two	O
background	O
planes	O
behind	O
the	O
object	O
of	O
interest	O
and	O
calculate	O
their	O
orienta-	O
tion	B
relative	O
to	O
the	O
viewer	O
,	O
e.g.	O
,	O
with	O
ﬁducial	O
marks	O
.	O
2.	O
cast	O
a	O
moving	O
shadow	O
with	O
a	O
stick	O
across	O
the	O
scene	O
;	O
record	O
the	O
video	B
or	O
capture	O
the	O
data	O
with	O
a	O
webcam	O
.	O
3.	O
estimate	O
each	O
light	O
plane	O
equation	B
from	O
the	O
projections	B
of	O
the	O
cast	O
shadow	B
against	O
the	O
two	O
backgrounds	O
.	O
4.	O
triangulate	O
to	O
the	O
remaining	O
points	B
on	O
each	O
curve	O
to	O
get	O
a	O
3d	O
stripe	O
and	O
display	O
the	O
stripes	O
using	O
a	O
3d	O
graphics	O
engine	O
.	O
5	O
.	O
(	O
optional	O
)	O
remove	O
the	O
requirement	O
for	O
a	O
known	O
second	O
(	O
vertical	O
)	O
plane	O
and	O
infer	O
its	O
location	O
(	O
or	O
that	O
of	O
the	O
light	O
source	O
)	O
using	O
the	O
techniques	O
described	O
by	O
bouguet	O
and	O
perona	O
(	O
1999	O
)	O
.	O
the	O
techniques	O
from	O
exercise	O
10.9	O
may	O
also	O
be	O
helpful	O
here	O
.	O
ex	O
12.3	O
:	O
range	O
data	O
registration	B
register	O
two	O
or	O
more	O
3d	O
datasets	O
using	O
either	O
iterated	O
closest	O
points	B
(	O
icp	O
)	O
(	O
besl	O
and	O
mckay	O
1992	O
;	O
zhang	O
1994	O
;	O
gold	O
,	O
rangarajan	O
,	O
lu	O
et	O
al	O
.	O
1998	O
)	O
or	O
octree	B
signed	O
distance	O
ﬁelds	O
(	O
szeliski	O
and	O
lavall´ee	O
1996	O
)	O
(	O
section	O
12.2.1	O
)	O
.	O
apply	O
your	O
technique	O
to	O
narrow-baseline	O
stereo	B
pairs	O
,	O
e.g.	O
,	O
obtained	O
by	O
moving	O
a	O
cam-	O
era	O
around	O
an	O
object	O
,	O
using	O
structure	O
from	O
motion	B
to	O
recover	O
the	O
camera	B
poses	O
,	O
and	O
using	O
a	O
standard	O
stereo	O
matching	B
algorithm	O
.	O
ex	O
12.4	O
:	O
range	O
data	O
merging	B
merge	O
the	O
datasets	O
that	O
you	O
registered	O
in	O
the	O
previous	O
exer-	O
cise	O
using	O
signed	O
distance	O
ﬁelds	O
(	O
curless	O
and	O
levoy	O
1996	O
;	O
hilton	O
,	O
stoddart	O
,	O
illingworth	O
et	O
al	O
.	O
1996	O
)	O
.	O
you	O
can	O
optionally	O
use	O
an	O
octree	B
to	O
represent	O
and	O
compress	O
this	O
ﬁeld	O
if	O
you	O
already	O
implemented	O
it	O
in	O
the	O
previous	O
registration	B
step	O
.	O
extract	O
a	O
meshed	O
surface	B
model	O
from	O
the	O
signed	B
distance	O
ﬁeld	O
using	O
marching	O
cubes	O
and	O
display	O
the	O
resulting	O
model	O
.	O
ex	O
12.5	O
:	O
surface	B
simpliﬁcation	O
use	O
progressive	O
meshes	O
(	O
hoppe	O
1996	O
)	O
or	O
some	O
other	O
tech-	O
nique	O
from	O
section	O
12.3.2	O
to	O
create	O
a	O
hierarchical	B
simpliﬁcation	O
of	O
your	O
surface	B
model	O
.	O
ex	O
12.6	O
:	O
architectural	O
modeler	O
build	O
a	O
3d	O
interior	O
or	O
exterior	O
model	O
of	O
some	O
architec-	O
tural	O
structure	O
,	O
such	O
as	O
your	O
house	O
,	O
from	O
a	O
series	O
of	O
handheld	O
wide-angle	O
photographs	O
.	O
1.	O
extract	O
lines	B
and	O
vanishing	B
points	I
(	O
exercises	O
4.11–4.15	O
)	O
to	O
estimate	O
the	O
dominant	O
di-	O
rections	O
in	O
each	O
image	B
.	O
2.	O
use	O
structure	B
from	I
motion	I
to	O
recover	O
all	O
of	O
the	O
camera	B
poses	O
and	O
match	O
up	O
the	O
vanish-	O
ing	O
points	B
.	O
618	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
3.	O
let	O
the	O
user	O
sketch	O
the	O
locations	O
of	O
the	O
walls	O
by	O
drawing	O
lines	B
corresponding	O
to	O
wall	O
bottoms	O
,	O
tops	O
,	O
and	O
horizontal	O
extents	O
onto	O
the	O
images	O
(	O
sinha	O
,	O
steedly	O
,	O
szeliski	O
et	O
al	O
.	O
2008	O
)	O
—see	O
also	O
exercise	O
6.9.	O
do	O
something	O
similar	O
for	O
openings	O
(	O
doors	O
and	O
windows	O
)	O
and	O
simple	O
furniture	O
(	O
tables	O
and	O
countertops	O
)	O
.	O
4.	O
convert	O
the	O
resulting	O
polygonal	O
meshes	O
into	O
a	O
3d	O
model	O
(	O
e.g.	O
,	O
vrml	O
)	O
and	O
optionally	O
texture-map	O
these	O
surfaces	O
from	O
the	O
images	O
.	O
ex	O
12.7	O
:	O
body	B
tracker	O
download	O
the	O
video	B
sequences	O
from	O
the	O
humaneva	O
web	O
site.16	O
either	O
implement	O
a	O
human	B
motion	I
tracker	O
from	O
scratch	O
or	O
extend	O
the	O
code	O
on	O
that	O
web	O
site	O
(	O
sigal	O
,	O
balan	O
,	O
and	O
black	O
2010	O
)	O
in	O
some	O
interesting	O
way	O
.	O
ex	O
12.8	O
:	O
3d	O
photography	O
combine	O
all	O
of	O
your	O
previously	O
developed	O
techniques	O
to	O
pro-	O
duce	O
a	O
system	O
that	O
takes	O
a	O
series	O
of	O
photographs	O
or	O
a	O
video	B
and	O
constructs	O
a	O
photorealistic	O
texture-mapped	O
3d	O
model	O
.	O
16	O
http	O
:	O
//vision.cs.brown.edu/humaneva/	O
.	O
chapter	O
13	O
image-based	B
rendering	I
13.1	O
view	B
interpolation	I
.	O
13.2	O
layered	O
depth	O
images	O
.	O
13.3	O
light	O
ﬁelds	O
and	O
lumigraphs	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13.1.1	O
view-dependent	B
texture	I
maps	I
13.1.2	O
application	O
:	O
photo	O
tourism	O
.	O
.	O
13.2.1	O
impostors	B
,	O
sprites	B
,	O
and	O
layers	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13.3.1	O
unstructured	B
lumigraph	O
.	O
13.3.2	O
surface	O
light	O
ﬁelds	O
.	O
.	O
.	O
13.3.3	O
application	O
:	O
concentric	O
mosaics	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13.4.1	O
higher-dimensional	O
light	O
ﬁelds	O
.	O
.	O
13.4.2	O
the	O
modeling	B
to	O
rendering	B
continuum	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13.5.1	O
video-based	O
animation	O
.	O
.	O
13.5.2	O
video	B
textures	I
.	O
.	O
13.5.3	O
application	O
:	O
animating	B
pictures	I
.	O
.	O
.	O
13.5.4	O
3d	O
video	B
.	O
.	O
13.5.5	O
application	O
:	O
video-based	B
walkthroughs	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
621	O
.	O
623	O
.	O
624	O
.	O
626	O
.	O
626	O
.	O
628	O
.	O
632	O
.	O
632	O
.	O
634	O
.	O
634	O
.	O
636	O
.	O
637	O
.	O
638	O
.	O
639	O
.	O
640	O
.	O
643	O
.	O
643	O
.	O
645	O
.	O
648	O
.	O
650	O
13.6	O
additional	O
reading	O
.	O
13.7	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
13.4	O
environment	O
mattes	O
.	O
.	O
.	O
.	O
.	O
.	O
13.5	O
video-based	O
rendering	O
.	O
620	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
g	O
)	O
(	O
h	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
(	O
i	O
)	O
figure	O
13.1	O
image-based	B
and	O
video-based	O
rendering	O
:	O
(	O
a	O
)	O
a	O
3d	O
view	O
of	O
a	O
photo	O
tourism	O
re-	O
construction	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
acm	O
;	O
(	O
b	O
)	O
a	O
slice	O
through	O
a	O
4d	O
light	B
ﬁeld	I
(	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
;	O
(	O
c	O
)	O
sprites	B
with	O
depth	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
acm	O
;	O
(	O
d	O
)	O
surface	B
light	I
ﬁeld	I
(	O
wood	O
,	O
azuma	O
,	O
aldinger	O
et	O
al	O
.	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
acm	O
;	O
(	O
e	O
)	O
environment	B
matte	I
in	O
front	O
of	O
a	O
novel	O
background	O
(	O
zongker	O
,	O
werner	O
,	O
curless	O
et	O
al	O
.	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
acm	O
;	O
(	O
f	O
)	O
real-time	O
video	B
environment	O
matte	O
(	O
chuang	O
,	O
zongker	O
,	O
hindorff	O
et	O
al	O
.	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
acm	O
;	O
(	O
g	O
)	O
video	B
rewrite	O
used	O
to	O
re-animate	O
old	O
video	B
(	O
bregler	O
,	O
covell	O
,	O
and	O
slaney	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
;	O
(	O
h	O
)	O
video	B
texture	I
of	O
a	O
candle	O
ﬂame	O
(	O
sch¨odl	O
,	O
szeliski	O
,	O
salesin	O
et	O
al	O
.	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
acm	O
;	O
(	O
i	O
)	O
video	B
view	O
interpolation	B
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
.	O
13.1	O
view	B
interpolation	I
621	O
over	O
the	O
last	O
two	O
decades	O
,	O
image-based	B
rendering	I
has	O
emerged	O
as	O
one	O
of	O
the	O
most	O
exciting	O
applications	O
of	O
computer	O
vision	O
(	O
kang	O
,	O
li	O
,	O
tong	O
et	O
al	O
.	O
2006	O
;	O
shum	O
,	O
chan	O
,	O
and	O
kang	O
2007	O
)	O
.	O
in	O
image-based	B
rendering	I
,	O
3d	O
reconstruction	O
techniques	O
from	O
computer	O
vision	O
are	O
combined	O
with	O
computer	O
graphics	O
rendering	B
techniques	O
that	O
use	O
multiple	B
views	O
of	O
a	O
scene	O
to	O
create	O
inter-	O
active	O
photo-realistic	O
experiences	O
,	O
such	O
as	O
the	O
photo	O
tourism	O
system	O
shown	O
in	O
figure	O
13.1a	O
.	O
commercial	O
versions	O
of	O
such	O
systems	O
include	O
immersive	O
street-level	O
navigation	O
in	O
on-line	O
mapping	O
systems1	O
and	O
the	O
creation	O
of	O
3d	O
photosynths2	O
from	O
large	O
collections	O
of	O
casually	O
acquired	O
photographs	O
.	O
in	O
this	O
chapter	O
,	O
we	O
explore	O
a	O
variety	O
of	O
image-based	B
rendering	I
techniques	O
,	O
such	O
as	O
those	O
illustrated	O
in	O
figure	O
13.1.	O
we	O
begin	O
with	O
view	O
interpolation	B
(	O
section	O
13.1	O
)	O
,	O
which	O
creates	O
a	O
seamless	O
transition	O
between	O
a	O
pair	O
of	O
reference	O
images	O
using	O
one	O
or	O
more	O
pre-computed	O
depth	O
maps	O
.	O
closely	O
related	O
to	O
this	O
idea	O
are	O
view-dependent	B
texture	I
maps	I
(	O
section	O
13.1.1	O
)	O
,	O
which	O
blend	O
multiple	B
texture	O
maps	O
on	O
a	O
3d	O
model	O
’	O
s	O
surface	B
.	O
the	O
representations	O
used	O
for	O
both	O
the	O
color	B
imagery	O
and	O
the	O
3d	O
geometry	O
in	O
view	B
interpolation	I
include	O
a	O
number	O
of	O
clever	O
variants	O
such	O
as	O
layered	O
depth	O
images	O
(	O
section	O
13.2	O
)	O
and	O
sprites	B
with	O
depth	O
(	O
section	O
13.2.1	O
)	O
.	O
we	O
continue	O
our	O
exploration	O
of	O
image-based	B
rendering	I
with	O
the	O
light	B
ﬁeld	I
and	O
lumigraph	O
four-dimensional	O
representations	O
of	O
a	O
scene	O
’	O
s	O
appearance	O
(	O
section	O
13.3	O
)	O
,	O
which	O
can	O
be	O
used	O
to	O
render	O
the	O
scene	O
from	O
any	O
arbitrary	O
viewpoint	O
.	O
variants	O
on	O
these	O
representations	O
include	O
the	O
unstructured	B
lumigraph	O
(	O
section	O
13.3.1	O
)	O
,	O
surface	O
light	O
ﬁelds	O
(	O
section	O
13.3.2	O
)	O
,	O
concentric	O
mosaics	O
(	O
section	O
13.3.3	O
)	O
,	O
and	O
environment	O
mattes	O
(	O
section	O
13.4	O
)	O
.	O
the	O
last	O
part	O
of	O
this	O
chapter	O
explores	O
the	O
topic	O
of	O
video-based	O
rendering	O
,	O
which	O
uses	O
one	O
or	O
more	O
videos	O
in	O
order	B
to	O
create	O
novel	O
video-based	O
experiences	O
(	O
section	O
13.5	O
)	O
.	O
the	O
topics	O
we	O
cover	O
include	O
video-based	O
facial	O
animation	O
(	O
section	O
13.5.1	O
)	O
,	O
as	O
well	O
as	O
video	B
textures	I
(	O
section	O
13.5.2	O
)	O
,	O
in	O
which	O
short	O
video	B
clips	O
can	O
be	O
seamlessly	O
looped	O
to	O
create	O
dynamic	B
real-	O
time	O
video-based	O
renderings	O
of	O
a	O
scene	O
.	O
we	O
close	O
with	O
a	O
discussion	O
of	O
3d	O
videos	O
created	O
from	O
multiple	B
video	O
streams	O
(	O
section	O
13.5.4	O
)	O
,	O
as	O
well	O
as	O
video-based	B
walkthroughs	I
of	O
environments	O
(	O
section	O
13.5.5	O
)	O
,	O
which	O
have	O
found	O
widespread	O
application	O
in	O
immersive	O
outdoor	O
mapping	O
and	O
driving	O
direction	O
systems	O
.	O
13.1	O
view	B
interpolation	I
while	O
the	O
term	O
image-based	B
rendering	I
ﬁrst	O
appeared	O
in	O
the	O
papers	O
by	O
chen	O
(	O
1995	O
)	O
and	O
mcmillan	O
and	O
bishop	O
(	O
1995	O
)	O
,	O
the	O
work	O
on	O
view	B
interpolation	I
by	O
chen	O
and	O
williams	O
(	O
1993	O
)	O
is	O
considered	O
as	O
the	O
seminal	O
paper	O
in	O
the	O
ﬁeld	O
.	O
in	O
view	B
interpolation	I
,	O
pairs	B
of	O
rendered	O
color	B
images	O
are	O
combined	O
with	O
their	O
pre-computed	O
depth	O
maps	O
to	O
generate	O
interpolated	O
views	O
that	O
1	O
http	O
:	O
//maps.bing.com	O
and	O
http	O
:	O
//maps.google.com	O
.	O
2	O
http	O
:	O
//photosynth.net	O
.	O
622	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
13.2	O
view	B
interpolation	I
(	O
chen	O
and	O
williams	O
1993	O
)	O
c	O
(	O
cid:13	O
)	O
1993	O
acm	O
:	O
(	O
a	O
)	O
holes	O
from	O
one	O
source	O
image	B
(	O
shown	O
in	O
blue	O
)	O
;	O
(	O
b	O
)	O
holes	O
after	O
combining	O
two	O
widely	O
spaced	O
images	O
;	O
(	O
c	O
)	O
holes	O
after	O
combining	O
two	O
closely	O
spaced	O
images	O
;	O
(	O
d	O
)	O
after	O
interpolation	B
(	O
hole	B
ﬁlling	I
)	O
.	O
mimic	O
what	O
a	O
virtual	O
camera	O
would	O
see	O
in	O
between	O
the	O
two	O
reference	O
views	O
.	O
view	B
interpolation	I
combines	O
two	O
ideas	O
that	O
were	O
previously	O
used	O
in	O
computer	O
vision	O
and	O
computer	O
graphics	O
.	O
the	O
ﬁrst	O
is	O
the	O
idea	O
of	O
pairing	O
a	O
recovered	O
depth	B
map	I
with	O
the	O
refer-	O
ence	O
image	B
used	O
in	O
its	O
computation	O
and	O
then	O
using	O
the	O
resulting	O
texture-mapped	O
3d	O
model	O
to	O
generate	O
novel	O
views	O
(	O
figure	O
11.1	O
)	O
.	O
the	O
second	O
is	O
the	O
idea	O
of	O
morphing	B
(	O
section	O
3.6.3	O
)	O
(	O
figure	O
3.53	O
)	O
,	O
where	O
correspondences	O
between	O
pairs	B
of	O
images	O
are	O
used	O
to	O
warp	O
each	O
refer-	O
ence	O
image	B
to	O
an	O
in-between	O
location	O
while	O
simultaneously	O
cross-dissolving	O
between	O
the	O
two	O
warped	O
images	O
.	O
figure	O
13.2	O
illustrates	O
this	O
process	O
in	O
more	O
detail	O
.	O
first	O
,	O
both	O
source	O
images	O
are	O
warped	O
to	O
the	O
novel	O
view	O
,	O
using	O
both	O
the	O
knowledge	O
of	O
the	O
reference	O
and	O
virtual	O
3d	O
camera	B
pose	O
along	O
with	O
each	O
image	B
’	O
s	O
depth	B
map	I
(	O
2.68–2.70	O
)	O
.	O
in	O
the	O
paper	O
by	O
chen	O
and	O
williams	O
(	O
1993	O
)	O
,	O
a	O
forward	B
warping	I
algorithm	O
(	O
algorithm	B
3.1	O
and	O
figure	O
3.46	O
)	O
is	O
used	O
.	O
the	O
depth	O
maps	O
are	O
represented	O
as	O
quadtrees	O
for	O
both	O
space	O
and	O
rendering	B
time	O
efﬁciency	B
(	O
samet	O
1989	O
)	O
.	O
during	O
the	O
forward	B
warping	I
process	O
,	O
multiple	B
pixels	O
(	O
which	O
occlude	O
one	O
another	O
)	O
may	O
land	O
on	O
the	O
same	O
destination	O
pixel	O
.	O
to	O
resolve	O
this	O
conﬂict	O
,	O
either	O
a	O
z-buffer	O
depth	O
value	O
can	O
be	O
associated	O
with	O
each	O
destination	O
pixel	O
or	O
the	O
images	O
can	O
be	O
warped	O
in	O
back-to-front	O
order	B
,	O
which	O
can	O
be	O
computed	O
based	O
on	O
the	O
knowledge	O
of	O
epipolar	B
geometry	I
(	O
chen	O
and	O
williams	O
1993	O
;	O
laveau	O
and	O
faugeras	O
1994	O
;	O
mcmillan	O
and	O
bishop	O
1995	O
)	O
.	O
once	O
the	O
two	O
reference	O
images	O
have	O
been	O
warped	O
to	O
the	O
novel	O
view	O
(	O
figure	O
13.2a–b	O
)	O
,	O
they	O
can	O
be	O
merged	O
to	O
create	O
a	O
coherent	O
composite	O
(	O
figure	O
13.2c	O
)	O
.	O
whenever	O
one	O
of	O
the	O
images	O
has	O
a	O
hole	O
(	O
illustrated	O
as	O
a	O
cyan	O
pixel	O
)	O
,	O
the	O
other	O
image	B
is	O
used	O
as	O
the	O
ﬁnal	O
value	O
.	O
when	O
both	O
images	O
have	O
pixels	O
to	O
contribute	O
,	O
these	O
can	O
be	O
blended	O
as	O
in	O
usual	O
morphing	B
,	O
i.e.	O
,	O
according	O
to	O
the	O
relative	O
distances	O
between	O
the	O
virtual	O
and	O
source	O
cameras	O
.	O
note	O
that	O
if	O
the	O
two	O
images	O
have	O
very	O
different	O
exposures	O
,	O
which	O
can	O
happen	O
when	O
performing	O
view	B
interpolation	I
on	O
real	O
images	O
,	O
the	O
hole-ﬁlled	O
regions	O
and	O
the	O
blended	O
regions	O
will	O
have	O
different	O
exposures	O
,	O
leading	O
13.1	O
view	B
interpolation	I
to	O
subtle	O
artifacts	O
.	O
623	O
the	O
ﬁnal	O
step	O
in	O
view	B
interpolation	I
(	O
figure	O
13.2d	O
)	O
is	O
to	O
ﬁll	O
any	O
remaining	O
holes	O
or	O
cracks	O
due	O
to	O
the	O
forward	B
warping	I
process	O
or	O
lack	O
of	O
source	O
data	O
(	O
scene	O
visibility	O
)	O
.	O
this	O
can	O
be	O
done	O
by	O
copying	O
pixels	O
from	O
the	O
further	O
pixels	O
adjacent	O
to	O
the	O
hole	O
.	O
(	O
otherwise	O
,	O
foreground	O
objects	O
are	O
subject	O
to	O
a	O
“	O
fattening	O
effect	O
”	O
.	O
)	O
the	O
above	O
process	O
works	O
well	O
for	O
rigid	O
scenes	O
,	O
although	O
its	O
visual	O
quality	O
(	O
lack	O
of	O
alias-	O
ing	O
)	O
can	O
be	O
improved	O
using	O
a	O
two-pass	O
,	O
forward–backward	O
algorithm	B
(	O
section	O
13.2.1	O
)	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
or	O
full	O
3d	O
rendering	B
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
.	O
in	O
the	O
case	O
where	O
the	O
two	O
reference	O
images	O
are	O
views	O
of	O
a	O
non-rigid	B
scene	O
,	O
e.g.	O
,	O
a	O
person	O
smiling	O
in	O
one	O
image	B
and	O
frowning	O
in	O
the	O
other	O
,	O
view	B
morphing	I
,	O
which	O
combines	O
ideas	O
from	O
view	B
interpolation	I
with	O
regular	O
morphing	B
,	O
can	O
be	O
used	O
(	O
seitz	O
and	O
dyer	O
1996	O
)	O
.	O
while	O
the	O
original	O
view	B
interpolation	I
paper	O
describes	O
how	O
to	O
generate	O
novel	O
views	O
based	O
on	O
similar	O
pre-computed	O
(	O
linear	B
perspective	O
)	O
images	O
,	O
the	O
plenoptic	O
modeling	B
paper	O
of	O
mcmil-	O
lan	O
and	O
bishop	O
(	O
1995	O
)	O
argues	O
that	O
cylindrical	B
images	O
should	O
be	O
used	O
to	O
store	O
the	O
pre-computed	O
rendering	B
or	O
real-world	O
images	O
.	O
(	O
chen	O
1995	O
)	O
also	O
propose	O
using	O
environment	O
maps	O
(	O
cylin-	O
drical	O
,	O
cubic	B
,	O
or	O
spherical	B
)	O
as	O
source	O
images	O
for	O
view	O
interpolation	B
.	O
13.1.1	O
view-dependent	B
texture	I
maps	I
view-dependent	O
texture	B
maps	O
(	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
1996	O
)	O
are	O
closely	O
related	O
to	O
view	B
interpolation	I
.	O
instead	O
of	O
associating	O
a	O
separate	O
depth	B
map	I
with	O
each	O
input	O
image	B
,	O
a	O
single	O
3d	O
model	O
is	O
created	O
for	O
the	O
scene	O
,	O
but	O
different	O
images	O
are	O
used	O
as	O
texture	B
map	O
sources	O
depending	O
on	O
the	O
virtual	O
camera	O
’	O
s	O
current	O
position	O
(	O
figure	O
13.3a	O
)	O
.3	O
in	O
more	O
detail	O
,	O
given	O
a	O
new	O
virtual	O
camera	O
position	O
,	O
the	O
similarity	B
of	O
this	O
camera	B
’	O
s	O
view	O
of	O
each	O
polygon	O
(	O
or	O
pixel	O
)	O
is	O
compared	O
to	O
that	O
of	O
potential	O
source	O
images	O
.	O
the	O
images	O
are	O
then	O
blended	O
using	O
a	O
weighting	B
that	O
is	O
inversely	O
proportional	O
to	O
the	O
angles	O
αi	O
between	O
the	O
virtual	O
view	O
and	O
the	O
source	O
views	O
(	O
figure	O
13.3a	O
)	O
.	O
even	O
though	O
the	O
geometric	B
model	O
can	O
be	O
fairly	O
coarse	O
(	O
figure	O
13.3b	O
)	O
,	O
blending	B
between	O
different	O
views	O
gives	O
a	O
strong	O
sense	O
of	O
more	O
detailed	O
geometry	O
because	O
of	O
the	O
parallax	O
(	O
visual	O
motion	O
)	O
between	O
corresponding	O
pixels	O
.	O
while	O
the	O
original	O
paper	O
performs	O
the	O
weighted	B
blend	O
computation	O
separately	O
at	O
each	O
pixel	O
or	O
coarsened	O
polygon	O
face	B
,	O
follow-on	O
work	O
by	O
debevec	O
,	O
yu	O
,	O
and	O
borshukov	O
(	O
1998	O
)	O
presents	O
a	O
more	O
efﬁ-	O
cient	O
implementation	O
based	O
on	O
precomputing	O
contributions	O
for	O
various	O
portions	O
of	O
viewing	O
space	O
and	O
then	O
using	O
projective	O
texture	B
mapping	O
(	O
opengl-arb	O
1997	O
)	O
.	O
the	O
idea	O
of	O
view-dependent	O
texture	O
mapping	O
has	O
been	O
used	O
in	O
a	O
large	O
number	O
of	O
sub-	O
sequent	O
image-based	B
rendering	I
systems	O
,	O
including	O
facial	O
modeling	O
and	O
animation	O
(	O
pighin	O
,	O
3	O
the	O
term	O
image-based	B
modeling	O
,	O
which	O
is	O
now	O
commonly	O
used	O
to	O
describe	O
the	O
creation	O
of	O
texture-mapped	O
3d	O
models	O
from	O
multiple	B
images	O
,	O
appears	O
to	O
have	O
ﬁrst	O
been	O
used	O
by	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
(	O
1996	O
)	O
,	O
who	O
also	O
used	O
the	O
term	O
photogrammetric	O
modeling	B
to	O
describe	O
the	O
same	O
process	O
.	O
624	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
13.3	O
view-dependent	O
texture	O
mapping	O
(	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
.	O
(	O
a	O
)	O
the	O
weighting	B
given	O
to	O
each	O
input	O
view	O
depends	O
on	O
the	O
relative	O
angles	O
between	O
the	O
novel	O
(	O
virtual	O
)	O
view	O
and	O
the	O
original	O
views	O
;	O
(	O
b	O
)	O
simpliﬁed	O
3d	O
model	O
geometry	O
;	O
(	O
c	O
)	O
with	O
view-	O
dependent	O
texture	B
mapping	O
,	O
the	O
geometry	O
appears	O
to	O
have	O
more	O
detail	O
(	O
recessed	O
windows	O
)	O
.	O
hecker	O
,	O
lischinski	O
et	O
al	O
.	O
1998	O
)	O
and	O
3d	O
scanning	O
and	O
visualization	O
(	O
pulli	O
,	O
abi-rached	O
,	O
duchamp	O
et	O
al	O
.	O
1998	O
)	O
.	O
closely	O
related	O
to	O
view-dependent	O
texture	O
mapping	O
is	O
the	O
idea	O
of	O
blending	B
be-	O
tween	O
light	O
rays	O
in	O
4d	O
space	O
,	O
which	O
forms	O
the	O
basis	O
of	O
the	O
lumigraph	O
and	O
unstructured	B
lu-	O
migraph	O
systems	O
(	O
section	O
13.3	O
)	O
(	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
;	O
buehler	O
,	O
bosse	O
,	O
mcmillan	O
et	O
al	O
.	O
2001	O
)	O
.	O
in	O
order	B
to	O
provide	O
even	O
more	O
realism	O
in	O
their	O
fac¸ade	O
system	O
,	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
(	O
1996	O
)	O
also	O
include	O
a	O
model-based	B
stereo	O
component	O
,	O
which	O
optionally	O
computes	O
an	O
offset	O
(	O
parallax	O
)	O
map	O
for	O
each	O
coarse	O
planar	O
facet	O
of	O
their	O
3d	O
model	O
.	O
they	O
call	O
the	O
resulting	O
analysis	O
and	O
rendering	B
system	O
a	O
hybrid	O
geometry-	O
and	O
image-based	B
approach	O
,	O
since	O
it	O
uses	O
traditional	O
3d	O
geometric	B
modeling	O
to	O
create	O
the	O
global	B
3d	O
model	O
,	O
but	O
then	O
uses	O
local	B
depth	O
offsets	O
,	O
along	O
with	O
view	O
interpolation	B
,	O
to	O
add	O
visual	O
realism	O
.	O
13.1.2	O
application	O
:	O
photo	O
tourism	O
while	O
view	B
interpolation	I
was	O
originally	O
developed	O
to	O
accelerate	O
the	O
rendering	B
of	O
3d	O
scenes	O
on	O
low-powered	O
processors	O
and	O
systems	O
without	O
graphics	O
acceleration	O
,	O
it	O
turns	O
out	O
that	O
it	O
can	O
be	O
applied	O
directly	O
to	O
large	O
collections	O
of	O
casually	O
acquired	O
photographs	O
.	O
the	O
photo	O
tourism	O
system	O
developed	O
by	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
(	O
2006	O
)	O
uses	O
structure	B
from	I
motion	I
to	O
compute	O
the	O
3d	O
locations	O
and	O
poses	O
of	O
all	O
the	O
cameras	O
taking	O
the	O
images	O
,	O
along	O
with	O
a	O
sparse	B
3d	O
point-cloud	O
model	O
of	O
the	O
scene	O
(	O
section	O
7.4.4	O
,	O
figure	O
7.11	O
)	O
.	O
to	O
perform	O
an	O
image-based	B
exploration	O
of	O
the	O
resulting	O
sea	O
of	O
images	O
(	O
aliaga	O
,	O
funkhouser	O
,	O
yanovsky	O
et	O
al	O
.	O
2003	O
)	O
,	O
photo	O
tourism	O
ﬁrst	O
associates	O
a	O
3d	O
proxy	O
with	O
each	O
image	B
.	O
while	O
a	O
triangulated	O
mesh	O
obtained	O
from	O
the	O
point	O
cloud	O
can	O
sometimes	O
form	O
a	O
suitable	O
proxy	O
,	O
e.g.	O
,	O
for	O
outdoor	O
terrain	O
models	O
,	O
a	O
simple	O
dominant	O
plane	O
ﬁt	O
to	O
the	O
3d	O
points	B
visible	O
in	O
each	O
image	B
13.1	O
view	B
interpolation	I
625	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
13.4	O
photo	O
tourism	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
:	O
c	O
(	O
cid:13	O
)	O
2006	O
acm	O
:	O
(	O
a	O
)	O
a	O
3d	O
overview	O
of	O
the	O
scene	O
,	O
with	O
translucent	O
washes	O
and	O
lines	B
painted	O
onto	O
the	O
planar	O
impostors	O
;	O
(	O
b	O
)	O
once	O
the	O
user	O
has	O
selected	O
a	O
region	B
of	O
interest	O
,	O
a	O
set	O
of	O
related	O
thumbnails	O
is	O
displayed	O
along	O
the	O
bottom	O
;	O
(	O
c	O
)	O
planar	O
proxy	O
selection	O
for	O
optimal	O
stabilization	O
(	O
snavely	O
,	O
garg	O
,	O
seitz	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
acm	O
.	O
often	O
performs	O
better	O
,	O
because	O
it	O
does	O
not	O
contain	O
any	O
erroneous	O
segments	O
or	O
connections	O
that	O
pop	O
out	O
as	O
artifacts	O
.	O
as	O
automated	B
3d	O
modeling	B
techniques	O
continue	O
to	O
improve	O
,	O
however	O
,	O
the	O
pendulum	O
may	O
swing	O
back	O
to	O
more	O
detailed	O
3d	O
geometry	O
(	O
goesele	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2007	O
;	O
sinha	O
,	O
steedly	O
,	O
and	O
szeliski	O
2009	O
)	O
.	O
the	O
resulting	O
image-based	B
navigation	O
system	O
lets	O
users	O
move	O
from	O
photo	O
to	O
photo	O
,	O
ei-	O
ther	O
by	O
selecting	O
cameras	O
from	O
a	O
top-down	O
view	O
of	O
the	O
scene	O
(	O
figure	O
13.4a	O
)	O
or	O
by	O
selecting	O
regions	O
of	O
interest	O
in	O
an	O
image	B
,	O
navigating	O
to	O
nearby	O
views	O
,	O
or	O
selecting	O
related	O
thumbnails	O
(	O
figure	O
13.4b	O
)	O
.	O
to	O
create	O
a	O
background	O
for	O
the	O
3d	O
scene	O
,	O
e.g.	O
,	O
when	O
being	O
viewed	O
from	O
above	O
,	O
non-photorealistic	O
techniques	O
(	O
section	O
10.5.2	O
)	O
,	O
such	O
as	O
translucent	O
color	B
washes	O
or	O
highlighted	O
3d	O
line	O
segments	O
,	O
can	O
be	O
used	O
(	O
figure	O
13.4a	O
)	O
.	O
the	O
system	O
can	O
also	O
be	O
used	O
to	O
annotate	O
regions	O
of	O
images	O
and	O
to	O
automatically	O
propagate	O
such	O
annotations	O
to	O
other	O
pho-	O
tographs	O
.	O
the	O
3d	O
planar	O
proxies	O
used	O
in	O
photo	O
tourism	O
and	O
the	O
related	O
photosynth	O
system	O
from	O
microsoft	O
result	O
in	O
non-photorealistic	O
transitions	O
reminiscent	O
of	O
visual	B
effects	I
such	O
as	O
“	O
page	O
ﬂips	O
”	O
.	O
selecting	O
a	O
stable	O
3d	O
axis	O
for	O
all	O
the	O
planes	B
can	O
reduce	O
the	O
amount	O
of	O
swimming	O
and	O
enhance	O
the	O
perception	O
of	O
3d	O
(	O
figure	O
13.4c	O
)	O
(	O
snavely	O
,	O
garg	O
,	O
seitz	O
et	O
al	O
.	O
2008	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
automatically	O
detect	O
objects	O
in	O
the	O
scene	O
that	O
are	O
seen	O
from	O
multiple	B
views	O
and	O
create	O
“	O
orbits	O
”	O
of	O
viewpoints	O
around	O
such	O
objects	O
.	O
furthermore	O
,	O
nearby	O
images	O
in	O
both	O
3d	O
position	O
and	O
viewing	O
direction	O
can	O
be	O
linked	O
to	O
create	O
“	O
virtual	O
paths	O
”	O
,	O
which	O
can	O
then	O
be	O
used	O
to	O
navigate	O
between	O
arbitrary	O
pairs	B
of	O
images	O
,	O
such	O
as	O
those	O
you	O
might	O
take	O
yourself	O
while	O
walking	O
around	O
a	O
popular	O
tourist	O
site	O
(	O
snavely	O
,	O
garg	O
,	O
seitz	O
et	O
al	O
.	O
2008	O
)	O
.	O
the	O
spatial	O
matching	B
of	O
image	B
features	O
and	O
regions	O
performed	O
by	O
photo	O
tourism	O
can	O
also	O
be	O
used	O
to	O
infer	O
more	O
information	O
from	O
large	O
image	O
collections	O
.	O
for	O
example	O
,	O
simon	O
,	O
snavely	O
,	O
and	O
seitz	O
(	O
2007	O
)	O
show	O
how	O
the	O
match	O
graph	O
between	O
images	O
of	O
popular	O
tourist	O
sites	O
626	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
can	O
be	O
used	O
to	O
ﬁnd	O
the	O
most	O
iconic	O
(	O
commonly	O
photographed	O
)	O
objects	O
in	O
the	O
collection	O
,	O
along	O
with	O
their	O
related	O
tags	O
.	O
in	O
follow-on	O
work	O
,	O
simon	O
and	O
seitz	O
(	O
2008	O
)	O
show	O
how	O
such	O
tags	O
can	O
be	O
propagated	O
to	O
sub-regions	O
of	O
each	O
image	B
,	O
using	O
an	O
analysis	O
of	O
which	O
3d	O
points	B
appear	O
in	O
the	O
central	O
portions	O
of	O
photographs	O
.	O
extensions	O
of	O
these	O
techniques	O
to	O
all	O
of	O
the	O
world	O
’	O
s	O
images	O
,	O
including	O
the	O
use	O
of	O
gps	O
tags	O
where	O
available	O
,	O
have	O
been	O
investigated	O
as	O
well	O
(	O
li	O
,	O
wu	O
,	O
zach	O
et	O
al	O
.	O
2008	O
;	O
quack	O
,	O
leibe	O
,	O
and	O
van	O
gool	O
2008	O
;	O
crandall	O
,	O
backstrom	O
,	O
huttenlocher	O
et	O
al	O
.	O
2009	O
;	O
li	O
,	O
crandall	O
,	O
and	O
huttenlocher	O
2009	O
;	O
zheng	O
,	O
zhao	O
,	O
song	O
et	O
al	O
.	O
2009	O
)	O
.	O
13.2	O
layered	O
depth	O
images	O
traditional	O
view	B
interpolation	I
techniques	O
associate	O
a	O
single	O
depth	O
map	O
with	O
each	O
source	O
or	O
reference	O
image	B
.	O
unfortunately	O
,	O
when	O
such	O
a	O
depth	B
map	I
is	O
warped	O
to	O
a	O
novel	O
view	O
,	O
holes	O
and	O
cracks	O
inevitably	O
appear	O
behind	O
the	O
foreground	O
objects	O
.	O
one	O
way	O
to	O
alleviate	O
this	O
problem	O
is	O
to	O
keep	O
several	O
depth	O
and	O
color	B
values	O
(	O
depth	O
pixels	O
)	O
at	O
every	O
pixel	O
in	O
a	O
reference	O
image	B
(	O
or	O
,	O
at	O
least	O
for	O
pixels	O
near	O
foreground–background	O
transitions	O
)	O
(	O
figure	O
13.5	O
)	O
.	O
the	O
resulting	O
data	O
structure	O
,	O
which	O
is	O
called	O
a	O
layered	B
depth	I
image	I
(	O
ldi	O
)	O
,	O
can	O
be	O
used	O
to	O
render	O
new	O
views	O
using	O
a	O
back-to-front	O
forward	B
warping	I
(	O
splatting	O
)	O
algorithm	B
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
.	O
13.2.1	O
impostors	B
,	O
sprites	B
,	O
and	O
layers	B
an	O
alternative	O
to	O
keeping	O
lists	O
of	O
color-depth	O
values	O
at	O
each	O
pixel	O
,	O
as	O
is	O
done	O
in	O
the	O
ldi	O
,	O
is	O
to	O
organize	O
objects	O
into	O
different	O
layers	B
or	O
sprites	B
.	O
the	O
term	O
sprite	O
originates	O
in	O
the	O
computer	O
game	O
industry	O
,	O
where	O
it	O
is	O
used	O
to	O
designate	O
ﬂat	O
animated	O
characters	O
in	O
games	O
such	O
as	O
pac-	O
man	O
or	O
mario	O
bros.	O
when	O
put	O
into	O
a	O
3d	O
setting	O
,	O
such	O
objects	O
are	O
often	O
called	O
impostors	B
,	O
because	O
they	O
use	O
a	O
piece	O
of	O
ﬂat	O
,	O
alpha-matted	O
geometry	O
to	O
represent	O
simpliﬁed	O
versions	O
of	O
3d	O
objects	O
that	O
are	O
far	O
away	O
from	O
the	O
camera	B
(	O
shade	O
,	O
lischinski	O
,	O
salesin	O
et	O
al	O
.	O
1996	O
;	O
lengyel	O
and	O
snyder	O
1997	O
;	O
torborg	O
and	O
kajiya	O
1996	O
)	O
.	O
in	O
computer	O
vision	O
,	O
such	O
representations	O
are	O
usually	O
called	O
layers	B
(	O
wang	O
and	O
adelson	O
1994	O
;	O
baker	O
,	O
szeliski	O
,	O
and	O
anandan	O
1998	O
;	O
torr	O
,	O
szeliski	O
,	O
and	O
anandan	O
1999	O
;	O
birchﬁeld	O
,	O
natarajan	O
,	O
and	O
tomasi	O
2007	O
)	O
.	O
section	O
8.5.2	O
discusses	O
the	O
topics	O
of	O
transparent	B
layers	O
and	O
reﬂections	B
,	O
which	O
occur	O
on	O
specular	B
and	O
transparent	B
surfaces	O
such	O
as	O
glass	O
.	O
while	O
ﬂat	O
layers	B
can	O
often	O
serve	O
as	O
an	O
adequate	O
representation	O
of	O
geometry	O
and	O
appear-	O
ance	O
for	O
far-away	O
objects	O
,	O
better	O
geometric	B
ﬁdelity	O
can	O
be	O
achieved	O
by	O
also	O
modeling	B
the	O
per-pixel	O
offsets	O
relative	O
to	O
a	O
base	O
plane	O
,	O
as	O
shown	O
in	O
figures	O
13.5	O
and	O
13.6a–b	O
.	O
such	O
repre-	O
sentations	O
are	O
called	O
plane	O
plus	O
parallax	O
in	O
the	O
computer	O
vision	O
literature	O
(	O
kumar	O
,	O
anandan	O
,	O
and	O
hanna	O
1994	O
;	O
sawhney	O
1994	O
;	O
szeliski	O
and	O
coughlan	O
1997	O
;	O
baker	O
,	O
szeliski	O
,	O
and	O
anandan	O
1998	O
)	O
,	O
as	O
discussed	O
in	O
section	O
8.5	O
(	O
figure	O
8.16	O
)	O
.	O
in	O
addition	O
to	O
fully	O
automated	B
stereo	O
tech-	O
niques	O
,	O
it	O
is	O
also	O
possible	O
to	O
paint	O
in	O
depth	O
layers	O
(	O
kang	O
1998	O
;	O
oh	O
,	O
chen	O
,	O
dorsey	O
et	O
al	O
.	O
2001	O
;	O
13.2	O
layered	O
depth	O
images	O
627	O
figure	O
13.5	O
a	O
variety	O
of	O
image-based	B
rendering	I
primitives	O
,	O
which	O
can	O
be	O
used	O
depending	O
on	O
the	O
distance	O
between	O
the	O
camera	B
and	O
the	O
object	O
of	O
interest	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
acm	O
.	O
closer	O
objects	O
may	O
require	O
more	O
detailed	O
polygonal	O
representations	O
,	O
while	O
mid-level	O
objects	O
can	O
use	O
a	O
layered	B
depth	I
image	I
(	O
ldi	O
)	O
,	O
and	O
far-away	O
objects	O
can	O
use	O
sprites	B
(	O
potentially	O
with	B
depth	I
)	O
and	O
environment	O
maps	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
13.6	O
sprites	B
with	O
depth	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
acm	O
:	O
(	O
a	O
)	O
alpha-	O
matted	O
color	B
sprite	O
;	O
(	O
b	O
)	O
corresponding	O
relative	O
depth	O
or	O
parallax	O
;	O
(	O
c	O
)	O
rendering	B
without	O
relative	O
depth	O
;	O
(	O
d	O
)	O
rendering	B
with	O
depth	O
(	O
note	O
the	O
curved	O
object	O
boundaries	O
)	O
.	O
628	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
shum	O
,	O
sun	O
,	O
yamazaki	O
et	O
al	O
.	O
2004	O
)	O
or	O
to	O
infer	O
their	O
3d	O
structure	O
from	O
monocular	O
image	B
cues	O
(	O
section	O
14.4.4	O
)	O
(	O
hoiem	O
,	O
efros	O
,	O
and	O
hebert	O
2005b	O
;	O
saxena	O
,	O
sun	O
,	O
and	O
ng	O
2009	O
)	O
.	O
how	O
can	O
we	O
render	O
a	O
sprite	O
with	B
depth	I
from	O
a	O
novel	O
viewpoint	O
?	O
one	O
possibility	O
,	O
as	O
with	O
a	O
regular	O
depth	B
map	I
,	O
is	O
to	O
just	O
forward	B
warp	O
each	O
pixel	O
to	O
its	O
new	O
location	O
,	O
which	O
can	O
cause	O
aliasing	B
and	O
cracks	O
.	O
a	O
better	O
way	O
,	O
which	O
we	O
already	O
mentioned	O
in	O
section	O
3.6.2	O
,	O
is	O
to	O
ﬁrst	O
warp	O
the	O
depth	O
(	O
or	O
(	O
u	O
,	O
v	O
)	O
displacement	O
)	O
map	O
to	O
the	O
novel	O
view	O
,	O
ﬁll	O
in	O
the	O
cracks	O
,	O
and	O
then	O
use	O
higher-quality	O
inverse	B
warping	I
to	O
resample	O
the	O
color	B
image	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
.	O
figure	O
13.6d	O
shows	O
the	O
results	O
of	O
applying	O
such	O
a	O
two-pass	O
rendering	B
algorithm	O
.	O
from	O
this	O
still	O
image	B
,	O
you	O
can	O
appreciate	O
that	O
the	O
foreground	O
sprites	B
look	O
more	O
rounded	O
;	O
however	O
,	O
to	O
fully	O
appreciate	O
the	O
improvement	O
in	O
realism	O
,	O
you	O
would	O
have	O
to	O
look	O
at	O
the	O
actual	O
animated	O
sequence	O
.	O
sprites	B
with	O
depth	O
can	O
also	O
be	O
rendered	O
using	O
conventional	O
graphics	O
hardware	O
,	O
as	O
de-	O
scribed	O
in	O
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
.	O
rogmans	O
,	O
lu	O
,	O
bekaert	O
et	O
al	O
.	O
(	O
2009	O
)	O
describe	O
gpu	O
implementations	O
of	O
both	O
real-time	O
stereo	B
matching	I
and	O
real-time	O
forward	B
and	O
inverse	B
rendering	O
algorithms	O
.	O
13.3	O
light	O
ﬁelds	O
and	O
lumigraphs	O
while	O
image-based	B
rendering	I
approaches	O
can	O
synthesize	O
scene	O
renderings	O
from	O
novel	O
view-	O
points	B
,	O
they	O
raise	O
the	O
following	O
more	O
general	O
question	O
:	O
is	O
is	O
possible	O
to	O
capture	O
and	O
render	O
the	O
appearance	O
of	O
a	O
scene	O
from	O
all	O
possible	O
viewpoints	O
and	O
,	O
if	O
so	O
,	O
what	O
is	O
the	O
complexity	O
of	O
the	O
resulting	O
structure	O
?	O
let	O
us	O
assume	O
that	O
we	O
are	O
looking	O
at	O
a	O
static	O
scene	O
,	O
i.e.	O
,	O
one	O
where	O
the	O
objects	O
and	O
illu-	O
minants	O
are	O
ﬁxed	O
,	O
and	O
only	O
the	O
observer	O
is	O
moving	O
around	O
.	O
under	O
these	O
conditions	O
,	O
we	O
can	O
describe	O
each	O
image	B
by	O
the	O
location	O
and	O
orientation	O
of	O
the	O
virtual	O
camera	O
(	O
6	O
dof	O
)	O
as	O
well	O
as	O
its	O
intrinsics	O
(	O
e.g.	O
,	O
its	O
focal	O
length	O
)	O
.	O
however	O
,	O
if	O
we	O
capture	O
a	O
two-dimensional	B
spherical	O
im-	O
age	O
around	O
each	O
possible	O
camera	B
location	O
,	O
we	O
can	O
re-render	O
any	O
view	O
from	O
this	O
information.4	O
thus	O
,	O
taking	O
the	O
cross-product	O
of	O
the	O
three-dimensional	O
space	O
of	O
camera	B
positions	O
with	O
the	O
2d	O
space	O
of	O
spherical	B
images	O
,	O
we	O
obtain	O
the	O
5d	O
plenoptic	O
function	O
of	O
adelson	O
and	O
bergen	O
(	O
1991	O
)	O
,	O
which	O
forms	O
the	O
basis	O
of	O
the	O
image-based	B
rendering	I
system	O
of	O
mcmillan	O
and	O
bishop	O
(	O
1995	O
)	O
.	O
notice	O
,	O
however	O
,	O
that	O
when	O
there	O
is	O
no	O
light	O
dispersion	O
in	O
the	O
scene	O
,	O
i.e.	O
,	O
no	O
smoke	B
or	O
fog	O
,	O
all	O
the	O
coincident	O
rays	O
along	O
a	O
portion	O
of	O
free	O
space	O
(	O
between	O
solid	O
or	O
refractive	O
objects	O
)	O
have	O
the	O
same	O
color	B
value	O
.	O
under	O
these	O
conditions	O
,	O
we	O
can	O
reduce	O
the	O
5d	O
plenoptic	O
function	O
to	O
4	O
since	O
we	O
are	O
counting	O
dimensions	O
,	O
we	O
ignore	O
for	O
now	O
any	O
sampling	B
or	O
resolution	O
issues	O
.	O
13.3	O
light	O
ﬁelds	O
and	O
lumigraphs	O
629	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
13.7	O
the	O
lumigraph	O
(	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
:	O
(	O
a	O
)	O
a	O
ray	O
is	O
represented	O
by	O
its	O
4d	O
two-plane	O
parameters	B
(	O
s	O
,	O
t	O
)	O
and	O
(	O
u	O
,	O
v	O
)	O
;	O
(	O
b	O
)	O
a	O
slice	O
through	O
the	O
3d	O
light	B
ﬁeld	I
subset	O
(	O
u	O
,	O
v	O
,	O
s	O
)	O
.	O
the	O
4d	O
light	B
ﬁeld	I
of	O
all	O
possible	O
rays	O
(	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
;	O
levoy	O
and	O
hanrahan	O
1996	O
;	O
levoy	O
2006	O
)	O
.5	O
to	O
make	O
the	O
parameterization	O
of	O
this	O
4d	O
function	O
simpler	O
,	O
let	O
us	O
put	O
two	O
planes	O
in	O
the	O
3d	O
scene	O
roughly	O
bounding	O
the	O
area	O
of	O
interest	O
,	O
as	O
shown	O
in	O
figure	O
13.7a	O
.	O
any	O
light	O
ray	O
terminating	O
at	O
a	O
camera	B
that	O
lives	O
in	O
front	O
of	O
the	O
st	O
plane	O
(	O
assuming	O
that	O
this	O
space	O
is	O
empty	O
)	O
passes	O
through	O
the	O
two	O
planes	O
at	O
(	O
s	O
,	O
t	O
)	O
and	O
(	O
u	O
,	O
v	O
)	O
and	O
can	O
be	O
described	O
by	O
its	O
4d	O
coordinate	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
.	O
this	O
diagram	O
(	O
and	O
parameterization	O
)	O
can	O
be	O
interpreted	O
as	O
describing	O
a	O
family	O
of	O
cameras	O
living	O
on	O
the	O
st	O
plane	O
with	O
their	O
image	B
planes	O
being	O
the	O
uv	O
plane	O
.	O
the	O
uv	O
plane	O
can	O
be	O
placed	O
at	O
inﬁnity	O
,	O
which	O
corresponds	O
to	O
all	O
the	O
virtual	O
cameras	O
looking	O
in	O
the	O
same	O
direction	O
.	O
in	O
practice	O
,	O
if	O
the	O
planes	B
are	O
of	O
ﬁnite	O
extent	O
,	O
the	O
ﬁnite	O
light	B
slab	I
l	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
can	O
be	O
used	O
to	O
generate	O
any	O
synthetic	O
view	O
that	O
a	O
camera	B
would	O
see	O
through	O
a	O
(	O
ﬁnite	O
)	O
viewport	O
in	O
the	O
st	O
plane	O
with	O
a	O
view	O
frustum	O
that	O
wholly	O
intersects	O
the	O
far	O
uv	O
plane	O
.	O
to	O
enable	O
the	O
camera	B
to	O
move	O
all	O
the	O
way	O
around	O
an	O
object	O
,	O
the	O
3d	O
space	O
surrounding	O
the	O
object	O
can	O
be	O
split	O
into	O
multiple	B
domains	O
,	O
each	O
with	O
its	O
own	O
light	B
slab	I
parameterization	O
.	O
conversely	O
,	O
if	O
the	O
camera	B
is	O
moving	O
inside	O
a	O
bounded	O
volume	O
of	O
free	O
space	O
looking	O
outward	O
,	O
multiple	B
cube	O
faces	B
surrounding	O
the	O
camera	B
can	O
be	O
used	O
as	O
(	O
s	O
,	O
t	O
)	O
planes	B
.	O
5	O
levoy	O
and	O
hanrahan	O
(	O
1996	O
)	O
borrowed	O
the	O
term	O
light	B
ﬁeld	I
from	O
a	O
paper	O
by	O
gershun	O
(	O
1939	O
)	O
.	O
another	O
name	O
for	O
this	O
representation	O
is	O
the	O
photic	O
ﬁeld	O
(	O
moon	O
and	O
spencer	O
1981	O
)	O
.	O
stuv	O
(	O
s	O
,	O
t	O
)	O
(	O
u	O
,	O
v	O
)	O
camera	B
centerimage	O
plane	O
pixel	O
630	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
13.8	O
depth	O
compensation	O
in	O
the	O
lumigraph	O
(	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
)	O
c	O
(	O
cid:13	O
)	O
1996	O
acm	O
.	O
to	O
resample	O
the	O
(	O
s	O
,	O
u	O
)	O
dashed	O
light	O
ray	O
,	O
the	O
u	O
parameter	O
corresponding	O
to	O
each	O
discrete	B
si	O
camera	B
location	O
is	O
modiﬁed	O
according	O
to	O
the	O
out-of-plane	O
depth	O
z	O
to	O
yield	O
new	O
coordinates	O
u	O
and	O
u	O
(	O
cid:48	O
)	O
;	O
in	O
(	O
u	O
,	O
s	O
)	O
ray	B
space	I
,	O
the	O
original	O
sample	O
(	O
(	O
cid:52	O
)	O
)	O
is	O
resampled	O
from	O
the	O
(	O
si	O
,	O
u	O
(	O
cid:48	O
)	O
)	O
and	O
(	O
si+1	O
,	O
u	O
(	O
cid:48	O
)	O
(	O
cid:48	O
)	O
)	O
samples	O
,	O
which	O
are	O
themselves	O
linear	B
blends	O
of	O
their	O
adjacent	O
(	O
◦	O
)	O
samples	O
.	O
thinking	O
about	O
4d	O
spaces	O
is	O
difﬁcult	O
,	O
so	O
let	O
us	O
drop	O
our	O
visualization	O
by	O
one	O
dimension	O
.	O
if	O
we	O
ﬁx	O
the	O
row	O
value	O
t	O
and	O
constrain	O
our	O
camera	B
to	O
move	O
along	O
the	O
s	O
axis	O
while	O
looking	O
at	O
the	O
uv	O
plane	O
,	O
we	O
can	O
stack	O
all	O
of	O
the	O
stabilized	O
images	O
the	O
camera	B
sees	O
to	O
get	O
the	O
(	O
u	O
,	O
v	O
,	O
s	O
)	O
epipolar	O
volume	O
,	O
which	O
we	O
discussed	O
in	O
section	O
11.6.	O
a	O
“	O
horizontal	O
”	O
cross-section	O
through	O
this	O
volume	O
is	O
the	O
well-known	O
epipolar	B
plane	I
image	I
(	O
bolles	O
,	O
baker	O
,	O
and	O
marimont	O
1987	O
)	O
,	O
which	O
is	O
the	O
us	O
slice	O
shown	O
in	O
figure	O
13.7b	O
.	O
as	O
you	O
can	O
see	O
in	O
this	O
slice	O
,	O
each	O
color	B
pixel	O
moves	O
along	O
a	O
linear	B
track	O
whose	O
slope	O
is	O
related	O
to	O
its	O
depth	O
(	O
parallax	O
)	O
from	O
the	O
uv	O
plane	O
.	O
(	O
pixels	O
exactly	O
on	O
the	O
uv	O
plane	O
appear	O
“	O
vertical	O
”	O
,	O
i.e.	O
,	O
they	O
do	O
not	O
move	O
as	O
the	O
camera	B
moves	O
along	O
s.	O
)	O
furthermore	O
,	O
pixel	O
tracks	O
occlude	O
one	O
another	O
as	O
their	O
corresponding	O
3d	O
surface	B
elements	O
occlude	O
.	O
translucent	O
pixels	O
,	O
however	O
,	O
composite	O
over	O
background	O
pixels	O
(	O
section	O
3.1.3	O
,	O
(	O
3.8	O
)	O
)	O
rather	O
than	O
occluding	O
them	O
.	O
thus	O
,	O
we	O
can	O
think	O
of	O
adjacent	O
pixels	O
sharing	O
a	O
similar	O
planar	O
geometry	O
as	O
epi	O
strips	O
or	O
epi	O
tubes	O
(	O
criminisi	O
,	O
kang	O
,	O
swaminathan	O
et	O
al	O
.	O
2005	O
)	O
.	O
the	O
equations	B
mapping	O
from	O
pixels	O
(	O
x	O
,	O
y	O
)	O
in	O
a	O
virtual	O
camera	O
and	O
the	O
corresponding	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
coordinates	O
are	O
relatively	O
straightforward	O
to	O
derive	O
and	O
are	O
sketched	O
out	O
in	O
ex-	O
ercise	O
13.7.	O
it	O
is	O
also	O
possible	O
to	O
show	O
that	O
the	O
set	O
of	O
pixels	O
corresponding	O
to	O
a	O
regular	O
ortho-	O
graphic	O
or	O
perspective	B
camera	O
,	O
i.e.	O
,	O
one	O
that	O
has	O
a	O
linear	B
projective	O
relationship	O
between	O
3d	O
points	B
and	O
(	O
x	O
,	O
y	O
)	O
pixels	O
(	O
2.63	O
)	O
,	O
lie	O
along	O
a	O
two-dimensional	B
hyperplane	O
in	O
the	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
light	B
ﬁeld	I
(	O
exercise	O
13.7	O
)	O
.	O
13.3	O
light	O
ﬁelds	O
and	O
lumigraphs	O
631	O
while	O
a	O
light	B
ﬁeld	I
can	O
be	O
used	O
to	O
render	O
a	O
complex	O
3d	O
scene	O
from	O
novel	O
viewpoints	O
,	O
a	O
much	O
better	O
rendering	B
(	O
with	O
less	O
ghosting	O
)	O
can	O
be	O
obtained	O
if	O
something	O
is	O
known	O
about	O
its	O
3d	O
geometry	O
.	O
the	O
lumigraph	O
system	O
of	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
(	O
1996	O
)	O
extends	O
the	O
basic	O
light	B
ﬁeld	I
rendering	O
approach	O
by	O
taking	O
into	O
account	O
the	O
3d	O
location	O
of	O
surface	B
points	O
corresponding	O
to	O
each	O
3d	O
ray	O
.	O
consider	O
the	O
ray	O
(	O
s	O
,	O
u	O
)	O
corresponding	O
to	O
the	O
dashed	O
line	O
in	O
figure	O
13.8	O
,	O
which	O
intersects	O
the	O
object	O
’	O
s	O
surface	B
at	O
a	O
distance	O
z	O
from	O
the	O
uv	O
plane	O
.	O
when	O
we	O
look	O
up	O
the	O
pixel	O
’	O
s	O
color	B
in	O
camera	B
si	O
(	O
assuming	O
that	O
the	O
light	B
ﬁeld	I
is	O
discretely	O
sampled	O
on	O
a	O
regular	O
4d	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
grid	O
)	O
,	O
the	O
actual	O
pixel	O
coordinate	O
is	O
u	O
(	O
cid:48	O
)	O
,	O
instead	O
of	O
the	O
original	O
u	O
value	O
speciﬁed	O
by	O
the	O
(	O
s	O
,	O
u	O
)	O
ray	O
.	O
similarly	O
,	O
for	O
camera	O
si+1	O
(	O
where	O
si	O
≤	O
s	O
≤	O
si+1	O
)	O
,	O
pixel	O
address	O
u	O
(	O
cid:48	O
)	O
(	O
cid:48	O
)	O
is	O
used	O
.	O
thus	O
,	O
instead	O
of	O
using	O
quadri-linear	O
interpolation	B
of	O
the	O
nearest	O
sampled	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
values	O
around	O
a	O
given	O
ray	O
to	O
determine	O
its	O
color	B
,	O
the	O
(	O
u	O
,	O
v	O
)	O
values	O
are	O
modiﬁed	O
for	O
each	O
discrete	B
(	O
si	O
,	O
ti	O
)	O
camera	B
.	O
figure	O
13.8	O
also	O
shows	O
the	O
same	O
reasoning	O
in	O
ray	B
space	I
.	O
here	O
,	O
the	O
original	O
continuous-	O
valued	O
(	O
s	O
,	O
u	O
)	O
ray	O
is	O
represented	O
by	O
a	O
triangle	O
and	O
the	O
nearby	O
sampled	O
discrete	B
values	O
are	O
shown	O
as	O
circles	O
.	O
instead	O
of	O
just	O
blending	B
the	O
four	O
nearest	O
samples	O
,	O
as	O
would	O
be	O
indicated	O
by	O
the	O
vertical	O
and	O
horizontal	O
dashed	O
lines	B
,	O
the	O
modiﬁed	O
(	O
si	O
,	O
u	O
(	O
cid:48	O
)	O
)	O
and	O
(	O
si+1	O
,	O
u	O
(	O
cid:48	O
)	O
(	O
cid:48	O
)	O
)	O
values	O
are	O
sampled	O
instead	O
and	O
their	O
values	O
are	O
then	O
blended	O
.	O
the	O
resulting	O
rendering	B
system	O
produces	O
images	O
of	O
much	O
better	O
quality	O
than	O
a	O
proxy-free	O
light	B
ﬁeld	I
and	O
is	O
the	O
method	O
of	O
choice	O
whenever	O
3d	O
geometry	O
can	O
be	O
inferred	O
.	O
in	O
subsequent	O
work	O
,	O
isaksen	O
,	O
mcmillan	O
,	O
and	O
gortler	O
(	O
2000	O
)	O
show	O
how	O
a	O
planar	O
proxy	O
for	O
the	O
scene	O
,	O
which	O
is	O
a	O
simpler	O
3d	O
model	O
,	O
can	O
be	O
used	O
to	O
simplify	O
the	O
resampling	O
equations	B
.	O
they	O
also	O
describe	O
how	O
to	O
create	O
synthetic	O
aperture	O
photos	O
,	O
which	O
mimic	O
what	O
might	O
be	O
seen	O
by	O
a	O
wide-aperture	O
lens	O
,	O
by	O
blending	O
more	O
nearby	O
samples	O
(	O
levoy	O
and	O
hanrahan	O
1996	O
)	O
.	O
a	O
similar	O
approach	O
can	O
be	O
used	O
to	O
re-focus	O
images	O
taken	O
with	O
a	O
plenoptic	O
(	O
microlens	O
array	O
)	O
camera	B
(	O
ng	O
,	O
levoy	O
,	O
br´eedif	O
et	O
al	O
.	O
2005	O
;	O
ng	O
2005	O
)	O
or	O
a	O
light	B
ﬁeld	I
microscope	O
(	O
levoy	O
,	O
ng	O
,	O
adams	O
et	O
al	O
.	O
2006	O
)	O
.	O
it	O
can	O
also	O
be	O
used	O
to	O
see	O
through	O
obstacles	O
,	O
using	O
extremely	O
large	O
synthetic	O
apertures	O
focused	O
on	O
a	O
background	O
that	O
can	O
blur	O
out	O
foreground	O
objects	O
and	O
make	O
them	O
appear	O
translucent	O
(	O
wilburn	O
,	O
joshi	O
,	O
vaish	O
et	O
al	O
.	O
2005	O
;	O
vaish	O
,	O
szeliski	O
,	O
zitnick	O
et	O
al	O
.	O
2006	O
)	O
.	O
now	O
that	O
we	O
understand	O
how	O
to	O
render	O
new	O
images	O
from	O
a	O
light	B
ﬁeld	I
,	O
how	O
do	O
we	O
go	O
about	O
capturing	O
such	O
data	B
sets	I
?	O
one	O
answer	O
is	O
to	O
move	O
a	O
calibrated	O
camera	B
with	O
a	O
motion	B
control	O
rig	O
or	O
gantry.6	O
another	O
approach	O
is	O
to	O
take	O
handheld	O
photographs	O
and	O
to	O
determine	O
the	O
pose	O
and	O
intrinsic	B
calibration	O
of	O
each	O
image	B
using	O
either	O
a	O
calibrated	O
stage	O
or	O
structure	B
from	I
motion	I
.	O
in	O
this	O
case	O
,	O
the	O
images	O
need	O
to	O
be	O
rebinned	O
into	O
a	O
regular	O
4d	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
space	O
before	O
they	O
can	O
be	O
used	O
for	O
rendering	O
(	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
)	O
.	O
alternatively	O
,	O
the	O
original	O
images	O
can	O
be	O
used	O
directly	O
using	O
a	O
process	O
called	O
the	O
unstructured	B
lumigraph	O
,	O
which	O
we	O
6	O
see	O
http	O
:	O
//lightﬁeld.stanford.edu/acq.html	O
for	O
a	O
description	O
of	O
some	O
of	O
the	O
gantries	O
and	O
camera	B
arrays	O
built	O
at	O
the	O
stanford	O
computer	O
graphics	O
laboratory	O
.	O
this	O
web	O
site	O
also	O
provides	O
a	O
number	O
of	O
light	B
ﬁeld	I
data	O
sets	O
that	O
are	O
a	O
great	O
source	O
of	O
research	O
and	O
project	O
material	O
.	O
632	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
describe	O
below	O
.	O
because	O
of	O
the	O
large	O
number	O
of	O
images	O
involved	O
,	O
light	O
ﬁelds	O
and	O
lumigraphs	O
can	O
be	O
quite	O
voluminous	O
to	O
store	O
and	O
transmit	O
.	O
fortunately	O
,	O
as	O
you	O
can	O
tell	O
from	O
figure	O
13.7b	O
,	O
there	O
is	O
a	O
tremendous	O
amount	O
of	O
redundancy	O
(	O
coherence	O
)	O
in	O
a	O
light	B
ﬁeld	I
,	O
which	O
can	O
be	O
made	O
even	O
more	O
explicit	O
by	O
ﬁrst	O
computing	O
a	O
3d	O
model	O
,	O
as	O
in	O
the	O
lumigraph	O
.	O
a	O
number	O
of	O
techniques	O
have	O
been	O
developed	O
to	O
compress	O
and	O
progressively	O
transmit	O
such	O
representations	O
(	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
1996	O
;	O
levoy	O
and	O
hanrahan	O
1996	O
;	O
rademacher	O
and	O
bishop	O
1998	O
;	O
magnor	O
and	O
girod	O
2000	O
;	O
wood	O
,	O
azuma	O
,	O
aldinger	O
et	O
al	O
.	O
2000	O
;	O
shum	O
,	O
kang	O
,	O
and	O
chan	O
2003	O
;	O
magnor	O
,	O
ramanathan	O
,	O
and	O
girod	O
2003	O
;	O
shum	O
,	O
chan	O
,	O
and	O
kang	O
2007	O
)	O
.	O
13.3.1	O
unstructured	B
lumigraph	O
when	O
the	O
images	O
in	O
a	O
lumigraph	O
are	O
acquired	O
in	O
an	O
unstructured	B
(	O
irregular	O
)	O
manner	O
,	O
it	O
can	O
be	O
counterproductive	O
to	O
resample	O
the	O
resulting	O
light	O
rays	O
into	O
a	O
regularly	O
binned	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
data	O
structure	O
.	O
this	O
is	O
both	O
because	O
resampling	O
always	O
introduces	O
a	O
certain	O
amount	O
of	O
aliasing	B
and	O
because	O
the	O
resulting	O
gridded	O
light	B
ﬁeld	I
can	O
be	O
populated	O
very	O
sparsely	O
or	O
irregularly	O
.	O
the	O
alternative	O
is	O
to	O
render	O
directly	O
from	O
the	O
acquired	O
images	O
,	O
by	O
ﬁnding	O
for	O
each	O
light	O
ray	O
in	O
a	O
virtual	O
camera	O
the	O
closest	O
pixels	O
in	O
the	O
original	O
images	O
.	O
the	O
unstructured	B
lumigraph	O
ren-	O
dering	O
(	O
ulr	O
)	O
system	O
of	O
buehler	O
,	O
bosse	O
,	O
mcmillan	O
et	O
al	O
.	O
(	O
2001	O
)	O
describes	O
how	O
to	O
select	O
such	O
pixels	O
by	O
combining	O
a	O
number	O
of	O
ﬁdelity	O
criteria	O
,	O
including	O
epipole	O
consistency	O
(	O
distance	O
of	O
rays	O
to	O
a	O
source	O
camera	B
’	O
s	O
center	O
)	O
,	O
angular	O
deviation	O
(	O
similar	O
incidence	O
direction	O
on	O
the	O
sur-	O
face	B
)	O
,	O
resolution	O
(	O
similar	O
sampling	B
density	O
along	O
the	O
surface	B
)	O
,	O
continuity	O
(	O
to	O
nearby	O
pixels	O
)	O
,	O
and	O
consistency	O
(	O
along	O
the	O
ray	O
)	O
.	O
these	O
criteria	O
can	O
all	O
be	O
combined	O
to	O
determine	O
a	O
weighting	B
function	O
between	O
each	O
virtual	O
camera	O
’	O
s	O
pixel	O
and	O
a	O
number	O
of	O
candidate	O
input	O
cameras	O
from	O
which	O
it	O
can	O
draw	O
colors	O
.	O
to	O
make	O
the	O
algorithm	B
more	O
efﬁcient	O
,	O
the	O
computations	O
are	O
per-	O
formed	O
by	O
discretizing	O
the	O
virtual	O
camera	O
’	O
s	O
image	B
plane	O
using	O
a	O
regular	O
grid	O
overlaid	O
with	O
the	O
polyhedral	O
object	O
mesh	O
model	O
and	O
the	O
input	O
camera	B
centers	O
of	O
projection	O
and	O
interpolating	O
the	O
weighting	B
functions	O
between	O
vertices	O
.	O
the	O
unstructured	B
lumigraph	O
generalizes	O
previous	O
work	O
in	O
both	O
image-based	B
rendering	I
and	O
light	B
ﬁeld	I
rendering	O
.	O
when	O
the	O
input	O
cameras	O
are	O
gridded	O
,	O
the	O
ulr	O
behaves	O
the	O
same	O
way	O
as	O
regular	O
lumigraph	O
rendering	B
.	O
when	O
fewer	O
cameras	O
are	O
available	O
but	O
the	O
geometry	O
is	O
accu-	O
rate	O
,	O
the	O
algorithm	B
behaves	O
similarly	O
to	O
view-dependent	O
texture	O
mapping	O
(	O
section	O
13.1.1	O
)	O
.	O
13.3.2	O
surface	O
light	O
ﬁelds	O
of	O
course	O
,	O
using	O
a	O
two-plane	O
parameterization	O
for	O
a	O
light	B
ﬁeld	I
is	O
not	O
the	O
only	O
possible	O
choice	O
.	O
(	O
it	O
is	O
the	O
one	O
usually	O
presented	O
ﬁrst	O
since	O
the	O
projection	O
equations	B
and	O
visualizations	O
are	O
the	O
easiest	O
to	O
draw	O
and	O
understand	O
.	O
)	O
as	O
we	O
mentioned	O
on	O
the	O
topic	O
of	O
light	B
ﬁeld	I
compression	O
,	O
13.3	O
light	O
ﬁelds	O
and	O
lumigraphs	O
633	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
13.9	O
surface	O
light	O
ﬁelds	O
(	O
wood	O
,	O
azuma	O
,	O
aldinger	O
et	O
al	O
.	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
acm	O
:	O
(	O
a	O
)	O
example	O
of	O
a	O
highly	O
specular	B
object	O
with	O
strong	O
inter-reﬂections	O
;	O
(	O
b	O
)	O
the	O
surface	B
light	I
ﬁeld	I
stores	O
the	O
light	O
emanating	O
from	O
each	O
surface	B
point	O
in	O
all	O
visible	O
directions	O
as	O
a	O
“	O
lumisphere	O
”	O
.	O
if	O
we	O
know	O
the	O
3d	O
shape	O
of	O
the	O
object	O
or	O
scene	O
whose	O
light	B
ﬁeld	I
is	O
being	O
modeled	O
,	O
we	O
can	O
effectively	O
compress	O
the	O
ﬁeld	O
because	O
nearby	O
rays	O
emanating	O
from	O
nearby	O
surface	B
elements	O
have	O
similar	O
color	B
values	O
.	O
in	O
fact	O
,	O
if	O
the	O
object	O
is	O
totally	O
diffuse	B
,	O
ignoring	O
occlusions	O
,	O
which	O
can	O
be	O
handled	O
using	O
3d	O
graphics	O
algorithms	O
or	O
z-buffering	O
,	O
all	O
rays	O
passing	O
through	O
a	O
given	O
surface	B
point	O
will	O
have	O
the	O
same	O
color	B
value	O
.	O
hence	O
,	O
the	O
light	B
ﬁeld	I
“	O
collapses	O
”	O
to	O
the	O
usual	O
2d	O
texture-map	O
deﬁned	O
over	O
an	O
object	O
’	O
s	O
surface	B
.	O
conversely	O
,	O
if	O
the	O
surface	B
is	O
totally	O
specular	B
(	O
e.g.	O
,	O
mirrored	O
)	O
,	O
each	O
surface	B
point	O
reﬂects	O
a	O
miniature	O
copy	O
of	O
the	O
environment	O
surrounding	O
that	O
point	O
.	O
in	O
the	O
absence	O
of	O
inter-reﬂections	O
(	O
e.g.	O
,	O
a	O
convex	O
object	O
in	O
a	O
large	O
open	O
space	O
)	O
,	O
each	O
surface	B
point	O
simply	O
reﬂects	O
the	O
far-ﬁeld	O
environment	O
map	O
(	O
section	O
2.2.1	O
)	O
,	O
which	O
again	O
is	O
two-dimensional	B
.	O
therefore	O
,	O
is	O
seems	O
that	O
re-parameterizing	O
the	O
4d	O
light	B
ﬁeld	I
to	O
lie	O
on	O
the	O
object	O
’	O
s	O
surface	B
can	O
be	O
extremely	O
beneﬁcial	O
.	O
these	O
observations	O
underlie	O
the	O
surface	B
light	I
ﬁeld	I
representation	O
introduced	O
by	O
wood	O
,	O
azuma	O
,	O
aldinger	O
et	O
al	O
.	O
(	O
2000	O
)	O
.	O
in	O
their	O
system	O
,	O
an	O
accurate	O
3d	O
model	O
is	O
built	O
of	O
the	O
object	O
being	O
represented	O
.	O
then	O
the	O
lumisphere	O
of	O
all	O
rays	O
emanating	O
from	O
each	O
surface	B
point	O
is	O
estimated	O
or	O
captured	O
(	O
figure	O
13.9	O
)	O
.	O
nearby	O
lumispheres	O
will	O
be	O
highly	O
correlated	O
and	O
hence	O
amenable	O
to	O
both	O
compression	B
and	O
manipulation	O
.	O
to	O
estimate	O
the	O
diffuse	B
component	O
of	O
each	O
lumisphere	O
,	O
a	O
median	B
ﬁltering	O
over	O
all	O
visible	O
exiting	O
directions	O
is	O
ﬁrst	O
performed	O
for	O
each	O
channel	O
.	O
once	O
this	O
has	O
been	O
subtracted	O
from	O
the	O
lumisphere	O
,	O
the	O
remaining	O
values	O
,	O
which	O
should	O
consist	O
mostly	O
of	O
the	O
specular	B
components	O
,	O
are	O
reﬂected	O
around	O
the	O
local	B
surface	O
normal	O
(	O
2.89	O
)	O
,	O
which	O
turns	O
each	O
lumisphere	O
into	O
a	O
copy	O
of	O
the	O
local	B
environment	O
around	O
that	O
point	O
.	O
nearby	O
lumispheres	O
can	O
then	O
be	O
compressed	O
using	O
predictive	O
coding	O
,	O
vector	O
quantization	B
,	O
or	O
principal	O
component	O
analysis	O
.	O
634	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
the	O
decomposition	O
into	O
a	O
diffuse	B
and	O
specular	B
component	O
can	O
also	O
be	O
used	O
to	O
perform	O
editing	O
or	O
manipulation	O
operations	O
,	O
such	O
as	O
re-painting	O
the	O
surface	B
,	O
changing	O
the	O
specular	B
component	O
of	O
the	O
reﬂection	O
(	O
e.g.	O
,	O
by	O
blurring	O
or	O
sharpening	O
the	O
specular	B
lumispheres	O
)	O
,	O
or	O
even	O
geometrically	O
deforming	O
the	O
object	O
while	O
preserving	O
detailed	O
surface	B
appearance	O
.	O
13.3.3	O
application	O
:	O
concentric	O
mosaics	O
a	O
useful	O
and	O
simple	O
version	O
of	O
light	B
ﬁeld	I
rendering	O
is	O
a	O
panoramic	O
image	B
with	O
parallax	O
,	O
i.e.	O
,	O
a	O
video	B
or	O
series	O
of	O
photographs	O
taken	O
from	O
a	O
camera	B
swinging	O
in	O
front	O
of	O
some	O
rotation	O
point	O
.	O
such	O
panoramas	O
can	O
be	O
captured	O
by	O
placing	O
a	O
camera	B
on	O
a	O
boom	O
on	O
a	O
tripod	O
,	O
or	O
even	O
more	O
simply	O
,	O
by	O
holding	O
a	O
camera	B
at	O
arm	O
’	O
s	O
length	O
while	O
rotating	O
your	O
body	B
around	O
a	O
ﬁxed	O
axis	O
.	O
the	O
resulting	O
set	O
of	O
images	O
can	O
be	O
thought	O
of	O
as	O
a	O
concentric	B
mosaic	I
(	O
shum	O
and	O
he	O
1999	O
;	O
shum	O
,	O
wang	O
,	O
chai	O
et	O
al	O
.	O
2002	O
)	O
or	O
a	O
layered	O
depth	O
panorama	O
(	O
zheng	O
,	O
kang	O
,	O
cohen	O
et	O
al	O
.	O
2007	O
)	O
.	O
the	O
term	O
“	O
concentric	B
mosaic	I
”	O
comes	O
from	O
a	O
particular	O
structure	O
that	O
can	O
be	O
used	O
to	O
re-bin	O
all	O
of	O
the	O
sampled	O
rays	O
,	O
essentially	O
associating	O
each	O
column	O
of	O
pixels	O
with	O
the	O
“	O
radius	O
”	O
of	O
the	O
concentric	O
circle	O
to	O
which	O
it	O
is	O
tangent	O
(	O
shum	O
and	O
he	O
1999	O
;	O
peleg	O
,	O
ben-ezra	O
,	O
and	O
pritch	O
2001	O
)	O
.	O
rendering	B
from	O
such	O
data	O
structures	O
is	O
fast	O
and	O
straightforward	O
.	O
if	O
we	O
assume	O
that	O
the	O
scene	O
is	O
far	O
enough	O
away	O
,	O
for	O
any	O
virtual	O
camera	O
location	O
,	O
we	O
can	O
associate	O
each	O
column	O
of	O
pixels	O
in	O
the	O
virtual	O
camera	O
with	O
the	O
nearest	O
column	O
of	O
pixels	O
in	O
the	O
input	O
image	B
set	O
.	O
(	O
for	O
a	O
regularly	O
captured	O
set	O
of	O
images	O
,	O
this	O
computation	O
can	O
be	O
performed	O
analytically	O
.	O
)	O
if	O
we	O
have	O
some	O
rough	O
knowledge	O
of	O
the	O
depth	O
of	O
such	O
pixels	O
,	O
columns	O
can	O
be	O
stretched	O
vertically	O
to	O
compensate	O
for	O
the	O
change	O
in	O
depth	O
between	O
the	O
two	O
cameras	O
.	O
if	O
we	O
have	O
an	O
even	O
more	O
detailed	O
depth	B
map	I
(	O
peleg	O
,	O
ben-ezra	O
,	O
and	O
pritch	O
2001	O
;	O
li	O
,	O
shum	O
,	O
tang	O
et	O
al	O
.	O
2004	O
;	O
zheng	O
,	O
kang	O
,	O
cohen	O
et	O
al	O
.	O
2007	O
)	O
,	O
we	O
can	O
perform	O
pixel-by-pixel	O
depth	O
corrections	O
.	O
while	O
the	O
virtual	O
camera	O
’	O
s	O
motion	B
is	O
constrained	B
to	O
lie	O
in	O
the	O
plane	O
of	O
the	O
original	O
cameras	O
and	O
within	O
the	O
radius	O
of	O
the	O
original	O
capture	O
ring	O
,	O
the	O
resulting	O
experience	O
can	O
exhibit	O
complex	O
rendering	B
phenomena	O
,	O
such	O
as	O
reﬂections	B
and	O
translucencies	O
,	O
which	O
can	O
not	O
be	O
captured	O
using	O
a	O
texture-mapped	O
3d	O
model	O
of	O
the	O
world	O
.	O
exercise	O
13.10	O
has	O
you	O
construct	O
a	O
concentric	B
mosaic	I
rendering	O
system	O
from	O
a	O
series	O
of	O
hand-held	O
photos	O
or	O
video	B
.	O
13.4	O
environment	O
mattes	O
so	O
far	O
in	O
this	O
chapter	O
,	O
we	O
have	O
dealt	O
with	O
view	O
interpolation	B
and	O
light	O
ﬁelds	O
,	O
which	O
are	O
tech-	O
niques	O
for	O
modeling	O
and	O
rendering	B
complex	O
static	O
scenes	O
seen	O
from	O
different	O
viewpoints	O
.	O
what	O
if	O
instead	O
of	O
moving	O
around	O
a	O
virtual	O
camera	O
,	O
we	O
take	O
a	O
complex	O
,	O
refractive	O
object	O
,	O
such	O
as	O
the	O
water	O
goblet	O
shown	O
in	O
figure	O
13.10	O
,	O
and	O
place	O
it	O
in	O
front	O
of	O
a	O
new	O
background	O
?	O
13.4	O
environment	O
mattes	O
635	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
13.10	O
environment	O
mattes	O
:	O
(	O
a–b	O
)	O
a	O
refractive	O
object	O
can	O
be	O
placed	O
in	O
front	O
of	O
a	O
series	O
of	O
backgrounds	O
and	O
their	O
light	O
patterns	O
will	O
be	O
correctly	O
refracted	O
(	O
zongker	O
,	O
werner	O
,	O
cur-	O
less	O
et	O
al	O
.	O
1999	O
)	O
(	O
c	O
)	O
multiple	B
refractions	O
can	O
be	O
handled	O
using	O
a	O
mixture	O
of	O
gaussians	O
model	O
and	O
(	O
d	O
)	O
real-time	O
mattes	O
can	O
be	O
pulled	O
using	O
a	O
single	O
graded	O
colored	O
background	O
(	O
chuang	O
,	O
zongker	O
,	O
hindorff	O
et	O
al	O
.	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
acm	O
.	O
instead	O
of	O
modeling	B
the	O
4d	O
space	O
of	O
rays	O
emanating	O
from	O
a	O
scene	O
,	O
we	O
now	O
need	O
to	O
model	O
how	O
each	O
pixel	O
in	O
our	O
view	O
of	O
this	O
object	O
refracts	O
incident	O
light	O
coming	O
from	O
its	O
environment	O
.	O
what	O
is	O
the	O
intrinsic	B
dimensionality	O
of	O
such	O
a	O
representation	O
and	O
how	O
do	O
we	O
go	O
about	O
capturing	O
it	O
?	O
let	O
us	O
assume	O
that	O
if	O
we	O
trace	O
a	O
light	O
ray	O
from	O
the	O
camera	B
at	O
pixel	O
(	O
x	O
,	O
y	O
)	O
toward	O
the	O
object	O
,	O
it	O
is	O
reﬂected	O
or	O
refracted	O
back	O
out	O
toward	O
its	O
environment	O
at	O
an	O
angle	O
(	O
φ	O
,	O
θ	O
)	O
.	O
if	O
we	O
assume	O
that	O
other	O
objects	O
and	O
illuminants	O
are	O
sufﬁciently	O
distant	O
(	O
the	O
same	O
assumption	O
we	O
made	O
for	O
surface	O
light	O
ﬁelds	O
in	O
section	O
13.3.2	O
)	O
,	O
this	O
4d	O
mapping	O
(	O
x	O
,	O
y	O
)	O
→	O
(	O
φ	O
,	O
θ	O
)	O
captures	O
all	O
the	O
information	O
between	O
a	O
refractive	O
object	O
and	O
its	O
environment	O
.	O
zongker	O
,	O
werner	O
,	O
curless	O
et	O
al	O
.	O
(	O
1999	O
)	O
call	O
such	O
a	O
representation	O
an	O
environment	B
matte	I
,	O
since	O
it	O
generalizes	O
the	O
process	O
of	O
object	O
matting	B
(	O
section	O
10.4	O
)	O
to	O
not	O
only	O
cut	O
and	O
paste	O
an	O
object	O
from	O
one	O
image	B
into	O
another	O
but	O
also	O
take	O
into	O
account	O
the	O
subtle	O
refractive	O
or	O
reﬂective	O
interplay	O
between	O
the	O
object	O
and	O
its	O
environment	O
.	O
recall	B
from	O
equations	B
(	O
3.8	O
)	O
and	O
(	O
10.30	O
)	O
that	O
a	O
foreground	O
object	O
can	O
be	O
represented	O
by	O
its	O
premultiplied	O
colors	O
and	O
opacities	O
(	O
αf	O
,	O
α	O
)	O
.	O
such	O
a	O
matte	O
can	O
then	O
be	O
composited	O
onto	O
a	O
new	O
background	O
b	O
using	O
ci	O
=	O
αifi	O
+	O
(	O
1	O
−	O
αi	O
)	O
bi	O
,	O
where	O
i	O
is	O
the	O
pixel	O
under	O
consideration	O
.	O
in	O
environment	O
matting	O
,	O
we	O
augment	O
this	O
equation	B
with	O
a	O
reﬂective	O
or	O
refractive	O
term	O
to	O
model	O
indirect	O
light	O
paths	O
between	O
the	O
environment	O
and	O
the	O
camera	B
.	O
in	O
the	O
original	O
work	O
of	O
zongker	O
,	O
werner	O
,	O
curless	O
et	O
al	O
.	O
(	O
1999	O
)	O
,	O
this	O
indirect	O
component	O
ii	O
is	O
modeled	O
as	O
ii	O
=	O
ri	O
(	O
cid:90	O
)	O
ai	O
(	O
x	O
)	O
b	O
(	O
x	O
)	O
dx	O
,	O
where	O
ai	O
is	O
the	O
rectangular	O
area	O
of	O
support	O
for	O
that	O
pixel	O
,	O
ri	O
is	O
the	O
colored	O
reﬂectance	B
or	O
(	O
13.1	O
)	O
(	O
13.2	O
)	O
636	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
transmittance	O
(	O
for	O
colored	O
glossy	O
surfaces	O
or	O
glass	O
)	O
,	O
and	O
b	O
(	O
x	O
)	O
is	O
the	O
background	O
(	O
environ-	O
ment	O
)	O
image	B
,	O
which	O
is	O
integrated	O
over	O
the	O
area	O
ai	O
(	O
x	O
)	O
.	O
in	O
follow-on	O
work	O
,	O
chuang	O
,	O
zongker	O
,	O
hindorff	O
et	O
al	O
.	O
(	O
2000	O
)	O
use	O
a	O
superposition	B
of	O
oriented	B
gaussians	O
,	O
where	O
each	O
2d	O
gaussian	O
ii	O
=	O
(	O
cid:88	O
)	O
j	O
rij	O
(	O
cid:90	O
)	O
gij	O
(	O
x	O
)	O
b	O
(	O
x	O
)	O
dx	O
,	O
gij	O
(	O
x	O
)	O
=	O
g2d	O
(	O
x	O
;	O
cij	O
,	O
σij	O
,	O
θij	O
)	O
(	O
13.3	O
)	O
(	O
13.4	O
)	O
is	O
modeled	O
by	O
its	O
center	O
cij	O
,	O
unrotated	O
widths	O
σij	O
=	O
(	O
σx	O
ij	O
,	O
σy	O
ij	O
)	O
,	O
and	O
orientation	O
θij	O
.	O
given	O
a	O
representation	O
for	O
an	O
environment	B
matte	I
,	O
how	O
can	O
we	O
go	O
about	O
estimating	O
it	O
for	O
a	O
particular	O
object	O
?	O
the	O
trick	O
is	O
to	O
place	O
the	O
object	O
in	O
front	O
of	O
a	O
monitor	O
(	O
or	O
surrounded	O
by	O
a	O
set	O
of	O
monitors	O
)	O
,	O
where	O
we	O
can	O
change	O
the	O
illumination	O
patterns	B
b	O
(	O
x	O
)	O
and	O
observe	O
the	O
value	O
of	O
each	O
composite	O
pixel	O
ci.7	O
as	O
with	O
traditional	O
two-screen	O
matting	B
(	O
section	O
10.4.1	O
)	O
,	O
we	O
can	O
use	O
a	O
variety	O
of	O
solid	O
colored	O
backgrounds	O
to	O
estimate	O
each	O
pixel	O
’	O
s	O
foreground	O
color	B
αifi	O
and	O
partial	O
coverage	O
(	O
opacity	B
)	O
αi	O
.	O
to	O
estimate	O
the	O
area	O
of	O
support	O
ai	O
in	O
(	O
13.2	O
)	O
,	O
zongker	O
,	O
werner	O
,	O
curless	O
et	O
al	O
.	O
(	O
1999	O
)	O
use	O
a	O
series	O
of	O
periodic	O
horizontal	O
and	O
vertical	O
solid	O
stripes	O
at	O
different	O
frequencies	O
and	O
phases	O
,	O
which	O
is	O
reminiscent	O
of	O
the	O
structured	O
light	O
patterns	O
used	O
in	O
active	O
rangeﬁnding	O
(	O
sec-	O
tion	B
12.2	O
)	O
.	O
for	O
the	O
more	O
sophisticated	O
mixture	O
of	O
gaussian	O
model	O
(	O
13.3	O
)	O
,	O
chuang	O
,	O
zongker	O
,	O
hindorff	O
et	O
al	O
.	O
(	O
2000	O
)	O
sweep	O
a	O
series	O
of	O
narrow	O
gaussian	O
stripes	O
at	O
four	O
different	O
orientations	O
(	O
horizontal	O
,	O
vertical	O
,	O
and	O
two	O
diagonals	O
)	O
,	O
which	O
enables	O
them	O
to	O
estimate	O
multiple	B
oriented	O
gaussian	O
responses	O
at	O
each	O
pixel	O
.	O
once	O
an	O
environment	B
matte	I
has	O
been	O
“	O
pulled	O
”	O
,	O
it	O
is	O
then	O
a	O
simple	O
matter	O
to	O
replace	O
the	O
background	O
with	O
a	O
new	O
image	B
b	O
(	O
x	O
)	O
to	O
obtain	O
a	O
novel	O
composite	O
of	O
the	O
object	O
placed	O
in	O
a	O
different	O
environment	O
(	O
figure	O
13.10a–c	O
)	O
.	O
the	O
use	O
of	O
multiple	B
backgrounds	O
during	O
the	O
matting	B
process	O
,	O
however	O
,	O
precludes	O
the	O
use	O
of	O
this	O
technique	O
with	O
dynamic	O
scenes	O
,	O
e.g.	O
,	O
water	O
pouring	O
into	O
a	O
glass	O
(	O
figure	O
13.10d	O
)	O
.	O
in	O
this	O
case	O
,	O
a	O
single	O
graded	O
color	B
background	O
can	O
be	O
used	O
to	O
estimate	O
a	O
single	O
2d	O
monochromatic	O
displacement	O
for	O
each	O
pixel	O
(	O
chuang	O
,	O
zongker	O
,	O
hindorff	O
et	O
al	O
.	O
2000	O
)	O
.	O
13.4.1	O
higher-dimensional	O
light	O
ﬁelds	O
as	O
you	O
can	O
tell	O
from	O
the	O
preceding	O
discussion	O
,	O
an	O
environment	B
matte	I
in	O
principle	O
maps	O
every	O
pixel	O
(	O
x	O
,	O
y	O
)	O
into	O
a	O
4d	O
distribution	O
over	O
light	O
rays	O
and	O
is	O
,	O
hence	O
,	O
a	O
six-dimensional	O
representa-	O
tion	B
.	O
(	O
in	O
practice	O
,	O
each	O
2d	O
pixel	O
’	O
s	O
response	O
is	O
parameterized	O
using	O
a	O
dozen	O
or	O
so	O
parameters	B
,	O
7	O
if	O
we	O
relax	O
the	O
assumption	O
that	O
the	O
environment	O
is	O
distant	O
,	O
the	O
monitor	O
can	O
be	O
placed	O
at	O
several	O
depths	O
to	O
estimate	O
a	O
depth-dependent	O
mapping	O
function	O
(	O
zongker	O
,	O
werner	O
,	O
curless	O
et	O
al	O
.	O
1999	O
)	O
.	O
13.4	O
environment	O
mattes	O
637	O
figure	O
13.11	O
the	O
geometry-image	O
continuum	O
in	O
image-based	B
rendering	I
(	O
kang	O
,	O
szeliski	O
,	O
and	O
anandan	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
ieee	O
.	O
representations	O
at	O
the	O
left	O
of	O
the	O
spectrum	O
use	O
more	O
detailed	O
geometry	O
and	O
simpler	O
image	B
representations	O
,	O
while	O
representations	B
and	I
algorithms	I
on	O
the	O
right	O
use	O
more	O
images	O
and	O
less	O
geometry	O
.	O
e.g.	O
,	O
{	O
f	O
,	O
α	O
,	O
b	O
,	O
r	O
,	O
a	O
}	O
,	O
instead	O
of	O
a	O
full	O
mapping	O
.	O
)	O
what	O
if	O
we	O
want	O
to	O
model	O
an	O
object	O
’	O
s	O
re-	O
fractive	O
properties	B
from	O
every	O
potential	O
point	O
of	O
view	O
?	O
in	O
this	O
case	O
,	O
we	O
need	O
a	O
mapping	O
from	O
every	O
incoming	O
4d	O
light	O
ray	O
to	O
every	O
potential	O
exiting	O
4d	O
light	O
ray	O
,	O
which	O
is	O
an	O
8d	O
represen-	O
tation	O
.	O
if	O
we	O
use	O
the	O
same	O
trick	O
as	O
with	O
surface	O
light	O
ﬁelds	O
,	O
we	O
can	O
parameterize	O
each	O
surface	B
point	O
by	O
its	O
4d	O
brdf	O
to	O
reduce	O
this	O
mapping	O
back	O
down	O
to	O
6d	O
but	O
this	O
loses	O
the	O
ability	O
to	O
handle	O
multiple	B
refractive	O
paths	O
.	O
if	O
we	O
want	O
to	O
handle	O
dynamic	B
light	O
ﬁelds	O
,	O
we	O
need	O
to	O
add	O
another	O
temporal	O
dimension	O
.	O
(	O
wenger	O
,	O
gardner	O
,	O
tchou	O
et	O
al	O
.	O
(	O
2005	O
)	O
gives	O
a	O
nice	O
example	O
of	O
a	O
dynamic	B
appearance	O
and	O
illumination	O
acquisition	O
system	O
.	O
)	O
similarly	O
,	O
if	O
we	O
want	O
a	O
continuous	O
distribution	O
over	O
wave-	O
lengths	O
,	O
this	O
becomes	O
another	O
dimension	O
.	O
these	O
examples	B
illustrate	O
how	O
modeling	B
the	O
full	O
complexity	O
of	O
a	O
visual	O
scene	O
through	O
sampling	B
can	O
be	O
extremely	O
expensive	O
.	O
fortunately	O
,	O
constructing	O
specialized	O
models	O
,	O
which	O
exploit	O
knowledge	O
about	O
the	O
physics	O
of	O
light	O
transport	O
along	O
with	O
the	O
natural	B
coherence	O
of	O
real-world	O
objects	O
,	O
can	O
make	O
these	O
problems	O
more	O
tractable	O
.	O
13.4.2	O
the	O
modeling	B
to	O
rendering	B
continuum	O
the	O
image-based	B
rendering	I
representations	O
and	O
algorithms	O
we	O
have	O
studied	O
in	O
this	O
chapter	O
span	O
a	O
continuum	O
ranging	O
from	O
classic	O
3d	O
texture-mapped	O
models	O
all	O
the	O
way	O
to	O
pure	O
sampled	O
ray-based	O
representations	O
such	O
as	O
light	O
ﬁelds	O
(	O
figure	O
13.11	O
)	O
.	O
representations	O
such	O
as	O
view-	O
dependent	O
texture	B
maps	O
and	O
lumigraphs	O
still	O
use	O
a	O
single	O
global	O
geometric	B
model	O
,	O
but	O
select	O
the	O
colors	O
to	O
map	O
onto	O
these	O
surfaces	O
from	O
nearby	O
images	O
.	O
view-dependent	B
geometry	O
,	O
e.g.	O
,	O
638	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
multiple	B
depth	O
maps	O
,	O
sidestep	O
the	O
need	O
for	O
coherent	O
3d	O
geometry	O
,	O
and	O
can	O
sometimes	O
better	O
model	O
local	B
non-rigid	O
effects	O
such	O
as	O
specular	B
motion	O
(	O
swaminathan	O
,	O
kang	O
,	O
szeliski	O
et	O
al	O
.	O
2002	O
;	O
criminisi	O
,	O
kang	O
,	O
swaminathan	O
et	O
al	O
.	O
2005	O
)	O
.	O
sprites	B
with	O
depth	O
and	O
layered	O
depth	O
images	O
use	O
image-based	B
representations	O
of	O
both	O
color	B
and	O
geometry	O
and	O
can	O
be	O
efﬁciently	O
rendered	O
using	O
warping	O
operations	O
rather	O
than	O
3d	O
geometric	B
rasterization	O
.	O
the	O
best	O
choice	O
of	O
representation	O
and	O
rendering	B
algorithm	O
depends	O
on	O
both	O
the	O
quantity	O
and	O
quality	O
of	O
the	O
input	O
imagery	O
as	O
well	O
as	O
the	O
intended	O
application	O
.	O
when	O
nearby	O
views	O
are	O
being	O
rendered	O
,	O
image-based	B
representations	O
capture	O
more	O
of	O
the	O
visual	O
ﬁdelity	O
of	O
the	O
real	O
world	O
because	O
they	O
directly	O
sample	O
its	O
appearance	O
.	O
on	O
the	O
other	O
hand	O
,	O
if	O
only	O
a	O
few	O
input	O
images	O
are	O
available	O
or	O
the	O
image-based	B
models	O
need	O
to	O
be	O
manipulated	O
,	O
e.g.	O
,	O
to	O
change	O
their	O
shape	O
or	O
appearance	O
,	O
more	O
abstract	O
3d	O
representations	O
such	O
as	O
geometric	B
and	O
local	B
reﬂection	O
models	O
are	O
a	O
better	O
ﬁt	O
.	O
as	O
we	O
continue	O
to	O
capture	O
and	O
manipulate	O
increasingly	O
larger	O
quan-	O
tities	O
of	O
visual	O
data	O
,	O
research	O
into	O
these	O
aspects	O
of	O
image-based	B
modeling	O
and	O
rendering	B
will	O
continue	O
to	O
evolve	O
.	O
13.5	O
video-based	O
rendering	O
since	O
multiple	B
images	O
can	O
be	O
used	O
to	O
render	O
new	O
images	O
or	O
interactive	B
experiences	O
,	O
can	O
some-	O
thing	O
similar	O
be	O
done	O
with	O
video	O
?	O
in	O
fact	O
,	O
a	O
fair	O
amount	O
of	O
work	O
has	O
been	O
done	O
in	O
the	O
area	O
of	O
video-based	O
rendering	O
and	O
video-based	O
animation	O
,	O
two	O
terms	O
ﬁrst	O
introduced	O
by	O
sch¨odl	O
,	O
szeliski	O
,	O
salesin	O
et	O
al	O
.	O
(	O
2000	O
)	O
to	O
denote	O
the	O
process	O
of	O
generating	O
new	O
video	B
sequences	O
from	O
captured	O
video	B
footage	O
.	O
an	O
early	O
example	O
of	O
such	O
work	O
is	O
video	B
rewrite	O
(	O
bregler	O
,	O
covell	O
,	O
and	O
slaney	O
1997	O
)	O
,	O
in	O
which	O
archival	O
video	B
footage	O
is	O
“	O
re-animated	O
”	O
by	O
having	O
actors	O
say	O
new	O
utterances	O
(	O
figure	O
13.12	O
)	O
.	O
more	O
recently	O
,	O
the	O
term	O
video-based	O
rendering	O
has	O
been	O
used	O
by	O
some	O
researchers	O
to	O
denote	O
the	O
creation	O
of	O
virtual	O
camera	O
moves	O
from	O
a	O
set	O
of	O
synchronized	O
video	B
cameras	O
placed	O
in	O
a	O
studio	O
(	O
magnor	O
2005	O
)	O
.	O
(	O
the	O
terms	O
free-viewpoint	O
video	B
and	O
3d	O
video	B
are	O
also	O
sometimes	O
used	O
,	O
see	O
section	O
13.5.4	O
.	O
)	O
in	O
this	O
section	O
,	O
we	O
present	O
a	O
number	O
of	O
video-based	O
rendering	O
systems	O
and	O
applications	O
.	O
we	O
start	O
with	O
video-based	O
animation	O
(	O
section	O
13.5.1	O
)	O
,	O
in	O
which	O
video	B
footage	O
is	O
re-arranged	O
or	O
modiﬁed	O
,	O
e.g.	O
,	O
in	O
the	O
capture	O
and	O
re-rendering	O
of	O
facial	O
expressions	O
.	O
a	O
special	O
case	O
of	O
this	O
are	O
video	B
textures	I
(	O
section	O
13.5.2	O
)	O
,	O
in	O
which	O
source	O
video	B
is	O
automatically	O
cut	O
into	O
segments	O
and	O
re-looped	O
to	O
create	O
inﬁnitely	O
long	O
video	B
animations	O
.	O
it	O
is	O
also	O
possible	O
to	O
create	O
such	O
animations	O
from	O
still	O
pictures	O
or	O
paintings	O
,	O
by	O
segmenting	O
the	O
image	B
into	O
separately	O
moving	O
regions	O
and	O
animating	O
them	O
using	O
stochastic	O
motion	B
ﬁelds	O
(	O
section	O
13.5.3	O
)	O
.	O
next	O
,	O
we	O
turn	O
our	O
attention	O
to	O
3d	O
video	B
(	O
section	O
13.5.4	O
)	O
,	O
in	O
which	O
multiple	B
synchronized	O
video	B
cameras	O
are	O
used	O
to	O
ﬁlm	O
a	O
scene	O
from	O
different	O
directions	O
.	O
the	O
source	O
video	B
frames	O
can	O
then	O
be	O
re-combined	O
using	O
image-based	O
rendering	B
techniques	O
,	O
such	O
as	O
view	B
interpolation	I
,	O
to	O
13.5	O
video-based	O
rendering	O
639	O
figure	O
13.12	O
video	B
rewrite	O
(	O
bregler	O
,	O
covell	O
,	O
and	O
slaney	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
acm	O
:	O
the	O
video	B
frames	O
are	O
composed	O
from	O
bits	O
and	O
pieces	O
of	O
old	O
video	B
footage	O
matched	O
to	O
a	O
new	O
audio	O
track	O
.	O
create	O
virtual	O
camera	O
paths	O
between	O
the	O
source	O
cameras	O
as	O
part	O
of	O
a	O
real-time	O
viewing	O
expe-	O
rience	O
.	O
finally	O
,	O
we	O
discuss	O
capturing	O
environments	O
by	O
driving	O
or	O
walking	O
through	O
them	O
with	O
panoramic	O
video	B
cameras	O
in	O
order	B
to	O
create	O
interactive	B
video-based	O
walkthrough	O
experiences	O
(	O
section	O
13.5.5	O
)	O
.	O
13.5.1	O
video-based	O
animation	O
as	O
we	O
mentioned	O
above	O
,	O
an	O
early	O
example	O
of	O
video-based	O
animation	O
is	O
video	B
rewrite	O
,	O
in	O
which	O
frames	O
from	O
original	O
video	B
footage	O
are	O
rearranged	O
in	O
order	B
to	O
match	O
them	O
to	O
novel	O
spoken	O
utterances	O
,	O
e.g.	O
,	O
for	O
movie	O
dubbing	O
(	O
figure	O
13.12	O
)	O
.	O
this	O
is	O
similar	O
in	O
spirit	O
to	O
the	O
way	O
that	O
concatenative	O
speech	O
synthesis	O
systems	O
work	O
(	O
taylor	O
2009	O
)	O
.	O
in	O
their	O
system	O
,	O
bregler	O
,	O
covell	O
,	O
and	O
slaney	O
(	O
1997	O
)	O
ﬁrst	O
use	O
speech	O
recognition	B
to	O
extract	O
phonemes	O
from	O
both	O
the	O
source	O
video	B
material	O
and	O
the	O
novel	O
audio	O
stream	O
.	O
phonemes	O
are	O
grouped	O
into	O
triphones	O
(	O
triplets	O
of	O
phonemes	O
)	O
,	O
since	O
these	O
better	O
model	O
the	O
coarticulation	O
effect	O
present	O
when	O
people	O
speak	O
.	O
matching	B
triphones	O
are	O
then	O
found	O
in	O
the	O
source	O
footage	O
and	O
audio	O
track	O
.	O
the	O
mouth	O
images	O
corresponding	O
to	O
the	O
selected	O
video	B
frames	O
are	O
then	O
cut	O
and	O
pasted	O
into	O
the	O
desired	O
video	B
footage	O
being	O
re-animated	O
or	O
dubbed	O
,	O
with	O
appropriate	O
geometric	B
transformations	O
to	O
account	O
for	O
head	O
motion	B
.	O
during	O
the	O
analysis	O
phase	O
,	O
features	O
corresponding	O
to	O
the	O
lips	O
,	O
chin	O
,	O
and	O
head	B
are	O
tracked	O
using	O
computer	O
vision	O
techniques	O
.	O
dur-	O
ing	O
synthesis	O
,	O
image	B
morphing	O
techniques	O
are	O
used	O
to	O
blend	O
and	O
stitch	O
adjacent	O
mouth	O
shapes	O
into	O
a	O
more	O
coherent	O
whole	O
.	O
in	O
more	O
recent	O
work	O
,	O
ezzat	O
,	O
geiger	O
,	O
and	O
poggio	O
(	O
2002	O
)	O
describe	O
how	O
to	O
use	O
a	O
multidimensional	B
morphable	O
model	O
(	O
section	O
12.6.2	O
)	O
combined	O
with	O
regularized	O
trajectory	O
synthesis	O
to	O
improve	O
these	O
results	O
.	O
a	O
more	O
sophisticated	O
version	O
of	O
this	O
system	O
,	O
called	O
face	B
transfer	O
,	O
uses	O
a	O
novel	O
source	O
video	B
,	O
instead	O
of	O
just	O
an	O
audio	O
track	O
,	O
to	O
drive	O
the	O
animation	O
of	O
a	O
previously	O
captured	O
video	B
,	O
i.e.	O
,	O
to	O
re-render	O
a	O
video	B
of	O
a	O
talking	O
head	B
with	O
the	O
appropriate	O
visual	O
speech	O
,	O
expression	O
,	O
and	O
head	B
pose	O
elements	O
(	O
vlasic	O
,	O
brand	O
,	O
pﬁster	O
et	O
al	O
.	O
2005	O
)	O
.	O
this	O
work	O
is	O
one	O
of	O
many	O
performance-	O
driven	O
animation	O
systems	O
(	O
section	O
4.1.5	O
)	O
,	O
which	O
are	O
often	O
used	O
to	O
animate	O
3d	O
facial	O
models	O
640	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
figures	O
12.18–12.19	O
)	O
.	O
while	O
traditional	O
performance-driven	B
animation	I
systems	O
use	O
marker-	O
based	O
motion	B
capture	O
(	O
williams	O
1990	O
;	O
litwinowicz	O
and	O
williams	O
1994	O
;	O
ma	O
,	O
jones	O
,	O
chiang	O
et	O
al	O
.	O
2008	O
)	O
,	O
video	B
footage	O
can	O
now	O
often	O
be	O
used	O
directly	O
to	O
control	O
the	O
animation	O
(	O
buck	O
,	O
finkelstein	O
,	O
jacobs	O
et	O
al	O
.	O
2000	O
;	O
pighin	O
,	O
szeliski	O
,	O
and	O
salesin	O
2002	O
;	O
zhang	O
,	O
snavely	O
,	O
curless	O
et	O
al	O
.	O
2004	O
;	O
vlasic	O
,	O
brand	O
,	O
pﬁster	O
et	O
al	O
.	O
2005	O
;	O
roble	O
and	O
zafar	O
2009	O
)	O
.	O
in	O
addition	O
to	O
its	O
most	O
common	O
application	O
to	O
facial	B
animation	I
,	O
video-based	O
animation	O
can	O
also	O
be	O
applied	O
to	O
whole	O
body	B
motion	O
(	O
section	O
12.6.4	O
)	O
,	O
e.g.	O
,	O
by	O
matching	O
the	O
ﬂow	O
ﬁelds	O
between	O
two	O
different	O
source	O
videos	O
and	O
using	O
one	O
to	O
drive	O
the	O
other	O
(	O
efros	O
,	O
berg	O
,	O
mori	O
et	O
al	O
.	O
2003	O
)	O
.	O
another	O
approach	O
to	O
video-based	O
rendering	O
is	O
to	O
use	O
ﬂow	O
or	O
3d	O
modeling	B
to	O
unwrap	O
surface	B
textures	O
into	O
stabilized	O
images	O
,	O
which	O
can	O
then	O
be	O
manipulated	O
and	O
re-rendered	O
onto	O
the	O
original	O
video	B
(	O
pighin	O
,	O
szeliski	O
,	O
and	O
salesin	O
2002	O
;	O
rav-acha	O
,	O
kohli	O
,	O
fitzgibbon	O
et	O
al	O
.	O
2008	O
)	O
.	O
13.5.2	O
video	B
textures	I
video-based	O
animation	O
is	O
a	O
powerful	O
means	O
of	O
creating	O
photo-realistic	O
videos	O
by	O
re-purposing	O
existing	O
video	B
footage	O
to	O
match	O
some	O
other	O
desired	O
activity	O
or	O
script	O
.	O
what	O
if	O
instead	O
of	O
constructing	O
a	O
special	O
animation	O
or	O
narrative	O
,	O
we	O
simply	O
want	O
the	O
video	B
to	O
continue	O
playing	O
in	O
a	O
plausible	O
manner	O
?	O
for	O
example	O
,	O
many	O
web	O
sites	O
use	O
images	O
or	O
videos	O
to	O
highlight	O
their	O
destinations	O
,	O
e.g.	O
,	O
to	O
portray	O
attractive	O
beaches	O
with	O
surf	O
and	O
palm	O
trees	O
waving	O
in	O
the	O
wind	O
.	O
instead	O
of	O
using	O
a	O
static	O
image	B
or	O
a	O
video	B
clip	O
that	O
has	O
a	O
discontinuity	O
when	O
it	O
loops	O
,	O
can	O
we	O
transform	B
the	O
video	B
clip	O
into	O
an	O
inﬁnite-length	O
animation	O
that	O
plays	O
forever	O
?	O
this	O
idea	O
is	O
the	O
basis	O
of	O
video	B
textures	I
,	O
in	O
which	O
a	O
short	O
video	B
clip	O
can	O
be	O
arbitrarily	O
extended	O
by	O
re-arranging	O
video	B
frames	O
while	O
preserving	O
visual	O
continuity	O
(	O
sch¨odl	O
,	O
szeliski	O
,	O
salesin	O
et	O
al	O
.	O
2000	O
)	O
.	O
the	O
basic	O
problem	O
in	O
creating	O
video	B
textures	I
is	O
how	O
to	O
perform	O
this	O
re-arrangement	O
without	O
introducing	O
visual	O
artifacts	O
.	O
can	O
you	O
think	O
of	O
how	O
you	O
might	O
do	O
this	O
?	O
the	O
simplest	O
approach	O
is	O
to	O
match	O
frames	O
by	O
visual	O
similarity	B
(	O
e.g.	O
,	O
l2	O
distance	O
)	O
and	O
to	O
jump	O
between	O
frames	O
that	O
appear	O
similar	O
.	O
unfortunately	O
,	O
if	O
the	O
motions	O
in	O
the	O
two	O
frames	O
are	O
different	O
,	O
a	O
dramatic	O
visual	O
artifact	O
will	O
occur	O
(	O
the	O
video	B
will	O
appear	O
to	O
“	O
stutter	O
”	O
)	O
.	O
for	O
example	O
,	O
if	O
we	O
fail	O
to	O
match	O
the	O
motions	O
of	O
the	O
clock	O
pendulum	O
in	O
figure	O
13.13a	O
,	O
it	O
can	O
suddenly	O
change	O
direction	O
in	O
mid-swing	O
.	O
how	O
can	O
we	O
extend	O
our	O
basic	O
frame	O
matching	O
to	O
also	O
match	O
motion	O
?	O
in	O
principle	O
,	O
we	O
could	O
compute	O
optic	O
ﬂow	O
at	O
each	O
frame	O
and	O
match	O
this	O
.	O
however	O
,	O
ﬂow	O
estimates	O
are	O
often	O
unreliable	O
(	O
especially	O
in	O
textureless	O
regions	O
)	O
and	O
it	O
is	O
not	O
clear	O
how	O
to	O
weight	O
the	O
visual	O
and	O
motion	B
similarities	O
relative	O
to	O
each	O
other	O
.	O
as	O
an	O
alternative	O
,	O
sch¨odl	O
,	O
szeliski	O
,	O
salesin	O
et	O
al	O
.	O
(	O
2000	O
)	O
suggest	O
matching	B
triplets	O
or	O
larger	O
neighborhoods	O
of	O
adjacent	O
video	B
frames	O
,	O
much	O
in	O
the	O
same	O
way	O
as	O
video	B
rewrite	O
matches	O
triphones	O
.	O
once	O
we	O
have	O
constructed	O
an	O
n	O
×	O
n	O
similarity	B
matrix	O
between	O
all	O
video	B
frames	O
(	O
where	O
n	O
is	O
the	O
number	O
of	O
frames	O
)	O
,	O
a	O
simple	O
13.5	O
video-based	O
rendering	O
641	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
g	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
(	O
h	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
(	O
i	O
)	O
figure	O
13.13	O
video	B
textures	I
(	O
sch¨odl	O
,	O
szeliski	O
,	O
salesin	O
et	O
al	O
.	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
acm	O
:	O
(	O
a	O
)	O
a	O
clock	O
pendulum	O
,	O
with	O
correctly	O
matched	O
direction	O
of	O
motion	B
;	O
(	O
b	O
)	O
a	O
candle	O
ﬂame	O
,	O
showing	O
temporal	O
transition	O
arcs	O
;	O
(	O
c	O
)	O
the	O
ﬂag	O
is	O
generated	O
using	O
morphing	O
at	O
jumps	O
;	O
(	O
d	O
)	O
a	O
bonﬁre	O
uses	O
longer	O
cross-dissolves	O
;	O
(	O
e	O
)	O
a	O
waterfall	O
cross-dissolves	O
several	O
sequences	O
at	O
once	O
;	O
(	O
f	O
)	O
a	O
smiling	O
animated	O
face	B
;	O
(	O
g	O
)	O
two	O
swinging	O
children	O
are	O
animated	O
separately	O
;	O
(	O
h	O
)	O
the	O
balloons	O
are	O
automatically	O
segmented	O
into	O
separate	O
moving	O
regions	O
;	O
(	O
i	O
)	O
a	O
synthetic	O
ﬁsh	O
tank	O
consisting	O
of	O
bubbles	O
,	O
plants	O
,	O
and	O
ﬁsh	O
.	O
videos	O
corresponding	O
to	O
these	O
images	O
can	O
be	O
found	O
at	O
http	O
:	O
//www.cc.gatech.edu/gvu/perception/projects/videotexture/	O
.	O
642	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ﬁnite	O
impulse	O
response	O
(	O
fir	O
)	O
ﬁltering	O
of	O
each	O
match	O
sequence	O
can	O
be	O
used	O
to	O
emphasize	O
subsequences	O
that	O
match	O
well	O
.	O
the	O
results	O
of	O
this	O
match	O
computation	O
gives	O
us	O
a	O
jump	O
table	O
or	O
,	O
equivalently	O
,	O
a	O
transition	O
probability	O
between	O
any	O
two	O
frames	O
in	O
the	O
original	O
video	B
.	O
this	O
is	O
shown	O
schematically	O
as	O
red	O
arcs	O
in	O
figure	O
13.13b	O
,	O
where	O
the	O
red	O
bar	O
indicates	O
which	O
video	B
frame	O
is	O
currently	O
be-	O
ing	O
displayed	O
,	O
and	O
arcs	O
light	O
up	O
as	O
a	O
forward	B
or	O
backward	O
transition	O
is	O
taken	O
.	O
we	O
can	O
view	O
these	O
transition	O
probabilities	O
as	O
encoding	O
the	O
hidden	O
markov	O
model	O
(	O
hmm	O
)	O
that	O
underlies	O
a	O
stochastic	O
video	O
generation	O
process	O
.	O
sometimes	O
,	O
it	O
is	O
not	O
possible	O
to	O
ﬁnd	O
exactly	O
matching	B
subsequences	O
in	O
the	O
original	O
video	B
.	O
in	O
this	O
case	O
,	O
morphing	B
,	O
i.e.	O
,	O
warping	O
and	O
blending	B
frames	O
during	O
transitions	O
(	O
section	O
3.6.3	O
)	O
can	O
be	O
used	O
to	O
hide	O
the	O
visual	O
differences	O
(	O
figure	O
13.13c	O
)	O
.	O
if	O
the	O
motion	B
is	O
chaotic	O
enough	O
,	O
as	O
in	O
a	O
bonﬁre	O
or	O
a	O
waterfall	O
(	O
figures	O
13.13d–e	O
)	O
,	O
simple	O
blending	B
(	O
extended	O
cross-dissolves	O
)	O
may	O
be	O
sufﬁcient	O
.	O
improved	O
transitions	O
can	O
also	O
be	O
obtained	O
by	O
performing	O
3d	O
graph	B
cuts	I
on	O
the	O
spatio-temporal	O
volume	O
around	O
a	O
transition	O
(	O
kwatra	O
,	O
sch¨odl	O
,	O
essa	O
et	O
al	O
.	O
2003	O
)	O
.	O
video	B
textures	I
need	O
not	O
be	O
restricted	B
to	O
chaotic	O
random	O
phenomena	O
such	O
as	O
ﬁre	O
,	O
wind	O
,	O
and	O
water	O
.	O
pleasing	O
video	B
textures	I
can	O
be	O
created	O
of	O
people	O
,	O
e.g.	O
,	O
a	O
smiling	O
face	B
(	O
as	O
in	O
fig-	O
ure	O
13.13f	O
)	O
or	O
someone	O
running	O
on	O
a	O
treadmill	O
(	O
sch¨odl	O
,	O
szeliski	O
,	O
salesin	O
et	O
al	O
.	O
2000	O
)	O
.	O
when	O
multiple	B
people	O
or	O
objects	O
are	O
moving	O
independently	O
,	O
as	O
in	O
figures	O
13.13g–h	O
,	O
we	O
must	O
ﬁrst	O
segment	O
the	O
video	B
into	O
independently	O
moving	O
regions	O
and	O
animate	O
each	O
region	B
separately	O
.	O
it	O
is	O
also	O
possible	O
to	O
create	O
large	O
panoramic	O
video	B
textures	I
from	O
a	O
slowly	O
panning	O
camera	B
(	O
agarwala	O
,	O
zheng	O
,	O
pal	O
et	O
al	O
.	O
2005	O
)	O
.	O
instead	O
of	O
just	O
playing	O
back	O
the	O
original	O
frames	O
in	O
a	O
stochastic	O
(	O
random	O
)	O
manner	O
,	O
video	B
textures	I
can	O
also	O
be	O
used	O
to	O
create	O
scripted	O
or	O
interactive	B
animations	O
.	O
if	O
we	O
extract	O
individual	O
elements	O
,	O
such	O
as	O
ﬁsh	O
in	O
a	O
ﬁshtank	O
(	O
figure	O
13.13i	O
)	O
into	O
separate	O
video	B
sprites	O
,	O
we	O
can	O
animate	O
them	O
along	O
pre-speciﬁed	O
paths	O
(	O
by	O
matching	O
the	O
path	O
direction	O
with	O
the	O
original	O
sprite	O
motion	B
)	O
to	O
make	O
our	O
video	B
elements	O
move	O
in	O
a	O
desired	O
fashion	O
(	O
sch¨odl	O
and	O
essa	O
2002	O
)	O
.	O
in	O
fact	O
,	O
work	O
on	O
video	B
textures	I
inspired	O
research	O
on	O
systems	O
that	O
re-synthesize	O
new	O
motion	B
sequences	O
from	O
motion	B
capture	O
data	O
,	O
which	O
some	O
people	O
refer	O
to	O
as	O
“	O
mocap	O
soup	O
”	O
(	O
arikan	O
and	O
forsyth	O
2002	O
;	O
kovar	O
,	O
gleicher	O
,	O
and	O
pighin	O
2002	O
;	O
lee	O
,	O
chai	O
,	O
reitsma	O
et	O
al	O
.	O
2002	O
;	O
li	O
,	O
wang	O
,	O
and	O
shum	O
2002	O
;	O
pullen	O
and	O
bregler	O
2002	O
)	O
.	O
while	O
video	B
textures	I
primarily	O
analyze	O
the	O
video	B
as	O
a	O
sequence	O
of	O
frames	O
(	O
or	O
regions	O
)	O
that	O
can	O
be	O
re-arranged	O
in	O
time	O
,	O
temporal	O
textures	O
(	O
szummer	O
and	O
picard	O
1996	O
;	O
bar-joseph	O
,	O
el-	O
yaniv	O
,	O
lischinski	O
et	O
al	O
.	O
2001	O
)	O
and	O
dynamic	B
textures	O
(	O
doretto	O
,	O
chiuso	O
,	O
wu	O
et	O
al	O
.	O
2003	O
;	O
yuan	O
,	O
wen	O
,	O
liu	O
et	O
al	O
.	O
2004	O
;	O
doretto	O
and	O
soatto	O
2006	O
)	O
treat	O
the	O
video	B
as	O
a	O
3d	O
spatio-temporal	O
volume	O
with	O
textural	O
properties	B
,	O
which	O
can	O
be	O
described	O
using	O
auto-regressive	O
temporal	O
models	O
.	O
13.5	O
video-based	O
rendering	O
643	O
figure	O
13.14	O
animating	O
still	O
pictures	O
(	O
chuang	O
,	O
goldman	O
,	O
zheng	O
et	O
al	O
.	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
acm	O
.	O
(	O
a	O
)	O
the	O
input	O
still	O
image	B
is	O
manually	O
segmented	O
into	O
(	O
b	O
)	O
several	O
layers	B
.	O
(	O
c	O
)	O
each	O
layer	O
is	O
then	O
animated	O
with	O
a	O
different	O
stochastic	O
motion	O
texture	B
(	O
d	O
)	O
the	O
animated	O
layers	B
are	O
then	O
composited	O
to	O
produce	O
(	O
e	O
)	O
the	O
ﬁnal	O
animation	O
13.5.3	O
application	O
:	O
animating	B
pictures	I
while	O
video	B
textures	I
can	O
turn	O
a	O
short	O
video	B
clip	O
into	O
an	O
inﬁnitely	O
long	O
video	B
,	O
can	O
the	O
same	O
thing	O
be	O
done	O
with	O
a	O
single	O
still	O
image	B
?	O
the	O
answer	O
is	O
yes	O
,	O
if	O
you	O
are	O
willing	O
to	O
ﬁrst	O
segment	O
the	O
image	B
into	O
different	O
layers	B
and	O
then	O
animate	O
each	O
layer	O
separately	O
.	O
chuang	O
,	O
goldman	O
,	O
zheng	O
et	O
al	O
.	O
(	O
2005	O
)	O
describe	O
how	O
an	O
image	B
can	O
be	O
decomposed	O
into	O
separate	O
layers	B
using	O
interactive	B
matting	O
techniques	O
.	O
each	O
layer	O
is	O
then	O
animated	O
using	O
a	O
class-speciﬁc	O
synthetic	O
motion	B
.	O
as	O
shown	O
in	O
figure	O
13.14	O
,	O
boats	O
rock	O
back	O
and	O
forth	O
,	O
trees	O
sway	O
in	O
the	O
wind	O
,	O
clouds	O
move	O
horizontally	O
,	O
and	O
water	O
ripples	O
,	O
using	O
a	O
shaped	O
noise	B
displace-	O
ment	O
map	O
.	O
all	O
of	O
these	O
effects	O
can	O
be	O
tied	O
to	O
some	O
global	B
control	O
parameters	B
,	O
such	O
as	O
the	O
velocity	O
and	O
direction	O
of	O
a	O
virtual	O
wind	O
.	O
after	O
being	O
individually	O
animated	O
,	O
the	O
layers	B
can	O
be	O
composited	O
to	O
create	O
a	O
ﬁnal	O
dynamic	B
rendering	O
.	O
13.5.4	O
3d	O
video	B
in	O
recent	O
years	O
,	O
the	O
popularity	O
of	O
3d	O
movies	O
has	O
grown	O
dramatically	O
,	O
with	O
recent	O
releases	O
ranging	O
from	O
hannah	O
montana	O
,	O
through	O
u2	O
’	O
s	O
3d	O
concert	O
movie	O
,	O
to	O
james	O
cameron	O
’	O
s	O
avatar	O
.	O
currently	O
,	O
such	O
releases	O
are	O
ﬁlmed	O
using	O
stereoscopic	O
camera	B
rigs	O
and	O
displayed	O
in	O
theaters	O
(	O
or	O
at	O
home	O
)	O
to	O
viewers	O
wearing	O
polarized	O
glasses.8	O
in	O
the	O
future	O
,	O
however	O
,	O
home	O
audiences	O
may	O
wish	O
to	O
view	O
such	O
movies	O
with	O
multi-zone	O
auto-stereoscopic	O
displays	O
,	O
where	O
each	O
person	O
gets	O
his	O
or	O
her	O
own	O
customized	O
stereo	B
stream	O
and	O
can	O
move	O
around	O
a	O
scene	O
to	O
see	O
it	O
from	O
8	O
http	O
:	O
//www.3d-summit.com/	O
.	O
displacement	O
map	O
...	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
...	O
...	O
=====	O
l1l2ll-2ll-1lll	O
(	O
t	O
)	O
1l	O
(	O
t	O
)	O
2l	O
(	O
t	O
)	O
l-2l	O
(	O
t	O
)	O
l-1l	O
(	O
t	O
)	O
l	O
displacement	O
map	O
displacement	O
map	O
displacement	O
map	O
displacement	O
mapd	O
(	O
t	O
)	O
l-1d	O
(	O
t	O
)	O
ld	O
(	O
t	O
)	O
l-2d	O
(	O
t	O
)	O
2d	O
(	O
t	O
)	O
1type=	O
(	O
cid:147	O
)	O
boat	O
(	O
cid:148	O
)	O
type=	O
(	O
cid:147	O
)	O
still	O
(	O
cid:148	O
)	O
type=	O
(	O
cid:147	O
)	O
tree	O
(	O
cid:148	O
)	O
type=	O
(	O
cid:147	O
)	O
cloud	O
(	O
cid:148	O
)	O
type=	O
(	O
cid:147	O
)	O
water	O
(	O
cid:148	O
)	O
figure2overviewofoursystem.theinputstillimage	O
(	O
a	O
)	O
ismanuallysegmentedintoseverallayers	O
(	O
b	O
)	O
.eachlayerliisthenanimatedwithadifferentstochasticmotiontexturedi	O
(	O
t	O
)	O
(	O
c	O
)	O
.finally	O
,	O
theanimatedlayersli	O
(	O
t	O
)	O
(	O
d	O
)	O
arecompositedbacktogethertoproducetheﬁnalanimationi	O
(	O
t	O
)	O
(	O
e	O
)	O
.	O
[	O
grifﬁths1997	O
]	O
,	O
buttheresultingeffectmaynotmaintainaviewer	O
’	O
sinterestovermorethanashortperiodoftime	O
,	O
onaccountofitspe-riodicityandpredictability.theapproachweultimatelysettledupon—whichhastheadvan-tagesofbeingquitesimpleforuserstospecify	O
,	O
andofcreatinginteresting	O
,	O
complex	O
,	O
andplausiblyrealisticmotion—istobreaktheimageupintoseverallayersandtothensynthesizeadiffer-entmotiontexture1foreachlayer.amotiontextureisessentiallyatime-varyingdisplacementmapdeﬁnedbyamotiontype	O
,	O
asetofmotionparameters	O
,	O
andinsomecasesamotionarmature.thisdisplacementmapd	O
(	O
p	O
,	O
t	O
)	O
isafunctionofpixelcoordinatespandtimet.applyingitdirectlytoanimagelayerlresultsinaforwardwarpedimagelayerl0suchthatl0	O
(	O
p+d	O
(	O
p	O
,	O
t	O
)	O
)	O
=l	O
(	O
p	O
)	O
(	O
1	O
)	O
however	O
,	O
sinceforwardmappingisfraughtwithproblemssuchasaliasingandholes	O
,	O
weactuallyuseinversewarping	O
,	O
deﬁnedasl0	O
(	O
p	O
)	O
=l	O
(	O
p+d0	O
(	O
p	O
,	O
t	O
)	O
)	O
(	O
2	O
)	O
wedenotethisoperationasl0=l⊗d0.wecouldcomputetheinversedisplacementmapd0fromdusingthetwo-passmethodsuggestedbyshadeetal.	O
[	O
1998	O
]	O
.instead	O
,	O
sinceourmotionﬁeldsareallverysmooth	O
,	O
wesimplydilatethembytheextentofthelargestpossiblemotionandreversetheirsign.withthisnotationinplace	O
,	O
wecannowdescribethebasicworkﬂowofoursystem	O
(	O
figure2	O
)	O
,	O
whichconsistsofthreesteps	O
:	O
layeringandmatting	O
,	O
motionspeciﬁcationandediting	O
,	O
andﬁnallyrendering.layeringandmatting.theﬁrststep	O
,	O
layering	O
,	O
istosegmenttheinputimageiintolayerssothat	O
,	O
withineachlayer	O
,	O
thesamemotiontexturecanbeapplied.forexample	O
,	O
forthepaintinginfig-ure2	O
(	O
a	O
)	O
,	O
wehavethefollowinglayers	O
:	O
oneforeachofthewater	O
,	O
sky	O
,	O
bridgeandshore	O
;	O
oneforeachofthethreeboats	O
;	O
andoneforeachoftheeleventreesinthebackground	O
(	O
figure2	O
(	O
b	O
)	O
)	O
.toaccom-plishthis	O
,	O
weuseaninteractiveobjectselectiontoolsuchasapaint-ingtoolorintelligentscissors	O
[	O
mortensenandbarrett1995	O
]	O
.thetoolisusedtospecifyatrimapforalayer	O
;	O
wethenapplybayesian1weusethetermsmotiontextureandstochasticmotiontextureinter-changeablyinthispaper.thetermmotiontexturewasalsousedbyliet.al	O
[	O
2002	O
]	O
torefertoalineardynamicsystemlearnedfrommotioncapturedata.mattingtoextractthecolorimageandasoftalphamatteforthatlayer	O
[	O
chuangetal.2001	O
]	O
.becausesomelayerswillbemoving	O
,	O
occludedpartsoftheback-groundmightbecomevisible.hence	O
,	O
afterextractingalayer	O
,	O
weuseanenhancedinpaintingalgorithmtoﬁlltheholeintheback-groundbehindtheforegroundlayer.weuseanexample-basedin-paintingalgorithmbasedontheworkofcriminisietal.	O
[	O
2003	O
]	O
be-causeofitssimplicityanditscapacitytohandlebothlinearstruc-turesandtexturedregions.notethattheinpaintingalgorithmdoesnothavetobeperfectsinceonlypixelsneartheboundaryoftheholearelikelytobecomevis-ible.wecanthereforeacceleratetheinpaintingalgorithmbycon-sideringonlynearbypixelsinthesearchforsimilarpatches.thisshortcutmaysacriﬁcesomequality	O
,	O
soincaseswheretheautomaticinpaintingalgorithmproducespoorresults	O
,	O
weprovideatouch-upinterfacewithwhichausercanselectregionstoberepainted.theautomaticalgorithmisthenreappliedtothesesmallerregionsus-ingalargersearchradius.wehavefoundthatmostsigniﬁcantin-paintingartifactscanberemovedafteronlyoneortwosuchbrush-strokes.althoughthismayseemlessefﬁcientthanafullyautomaticalgorithm	O
,	O
wehavefoundthatexploitingthehumaneyeinthissim-plefashioncanproducesuperiorresultsinlessthanhalfthetimeofthefullyautomaticalgorithm.notethatifalayerexhibitslargemotions	O
(	O
suchasawildlyswingingbranch	O
)	O
,	O
artifactsdeepinsidetheinpaintedregionsbehindthatlayermayberevealed.inprac-tice	O
,	O
theseartifactsmaynotbeobjectionable	O
,	O
asthemotiontendstodrawattentionawayfromthem.whentheyareobjectionable	O
,	O
theuserhastheoptionofimprovingtheinpaintingresults.afterthebackgroundimagehasbeeninpainted	O
,	O
weworkonthisimagetoextractthenextlayer.werepeatthisprocessfromtheclosestlayertothefurthestlayertogeneratethedesirednumberoflayers.eachlayerlicontainsacolorimageci	O
,	O
amatteαi	O
,	O
andacompositingorderzi.thecompositingorderispresentlyspeciﬁedbyhand	O
,	O
butcouldinprinciplebeautomaticallyassignedwiththeorderinwhichthelayersareextracted.motionspeciﬁcationandediting.thesecondcomponentofoursystemletsusspecifyandeditthemotiontextureforeachlayer.currently	O
,	O
weprovidethefollowingmotiontypes	O
:	O
trees	O
(	O
swaying	O
)	O
,	O
water	O
(	O
rippling	O
)	O
,	O
boats	O
(	O
bobbing	O
)	O
,	O
clouds	O
(	O
translation	B
)	O
,	O
andstill	O
(	O
nomotion	O
)	O
.foreachmotiontype	O
,	O
theusercantunethemotionparam-etersandspecifyamotionarmature	O
,	O
whereapplicable.wedescribethemotionparametersandarmaturesinmoredetailforeachmotiontypeinsection3	O
.	O
644	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
figure	O
13.15	O
video	B
view	O
interpolation	B
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
acm	O
:	O
(	O
a	O
)	O
the	O
capture	O
hardware	O
consists	O
of	O
eight	O
synchronized	O
cameras	O
;	O
(	O
b	O
)	O
the	O
background	O
and	O
foreground	O
images	O
from	O
each	O
camera	B
are	O
rendered	O
and	O
composited	O
before	O
blending	B
;	O
(	O
c	O
)	O
the	O
two-layer	O
representation	O
,	O
before	O
and	O
after	O
boundary	O
matting	O
;	O
(	O
d	O
)	O
background	O
color	O
esti-	O
mates	O
;	O
(	O
e	O
)	O
background	O
depth	O
estimates	O
;	O
(	O
f	O
)	O
foreground	O
color	B
estimates	O
.	O
different	O
perspectives.9	O
the	O
stereo	B
matching	I
techniques	O
developed	O
in	O
the	O
computer	O
vision	O
community	O
along	O
with	O
image-based	O
rendering	B
(	O
view	B
interpolation	I
)	O
techniques	O
from	O
graphics	O
are	O
both	O
essential	O
com-	O
ponents	O
in	O
such	O
scenarios	O
,	O
which	O
are	O
sometimes	O
called	O
free-viewpoint	O
video	B
(	O
carranza	O
,	O
theobalt	O
,	O
magnor	O
et	O
al	O
.	O
2003	O
)	O
or	O
virtual	B
viewpoint	I
video	I
(	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
2004	O
)	O
.	O
in	O
addition	O
to	O
solving	O
a	O
series	O
of	O
per-frame	O
reconstruction	O
and	O
view	B
interpolation	I
problems	O
,	O
the	O
depth	O
maps	O
or	O
proxies	O
produced	O
by	O
the	O
analysis	O
phase	O
must	O
be	O
temporally	O
consistent	O
in	O
order	B
to	O
avoid	O
ﬂickering	O
artifacts	O
.	O
shum	O
,	O
chan	O
,	O
and	O
kang	O
(	O
2007	O
)	O
and	O
magnor	O
(	O
2005	O
)	O
present	O
nice	O
overviews	O
of	O
various	O
video	B
view	O
interpolation	B
techniques	O
and	O
systems	O
.	O
these	O
include	O
the	O
virtualized	O
reality	O
sys-	O
tem	O
of	O
kanade	O
,	O
rander	O
,	O
and	O
narayanan	O
(	O
1997	O
)	O
and	O
vedula	O
,	O
baker	O
,	O
and	O
kanade	O
(	O
2005	O
)	O
,	O
im-	O
mersive	O
video	B
(	O
moezzi	O
,	O
katkere	O
,	O
kuramura	O
et	O
al	O
.	O
1996	O
)	O
,	O
image-based	B
visual	O
hulls	O
(	O
matusik	O
,	O
buehler	O
,	O
raskar	O
et	O
al	O
.	O
2000	O
;	O
matusik	O
,	O
buehler	O
,	O
and	O
mcmillan	O
2001	O
)	O
,	O
and	O
free-viewpoint	O
video	B
(	O
carranza	O
,	O
theobalt	O
,	O
magnor	O
et	O
al	O
.	O
2003	O
)	O
,	O
which	O
all	O
use	O
global	B
3d	O
geometric	B
models	O
(	O
surface-based	O
(	O
section	O
12.3	O
)	O
or	O
volumetric	B
(	O
section	O
12.5	O
)	O
)	O
as	O
their	O
proxies	O
for	O
rendering	O
.	O
the	O
work	O
of	O
vedula	O
,	O
baker	O
,	O
and	O
kanade	O
(	O
2005	O
)	O
also	O
computes	O
scene	O
ﬂow	O
,	O
i.e.	O
,	O
the	O
3d	O
motion	B
between	O
corresponding	O
surface	B
elements	O
,	O
which	O
can	O
then	O
be	O
used	O
to	O
perform	O
spatio-temporal	O
interpolation	B
of	O
the	O
multi-view	B
video	O
stream	O
.	O
the	O
virtual	B
viewpoint	I
video	I
system	O
of	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
(	O
2004	O
)	O
,	O
on	O
the	O
9	O
http	O
:	O
//www.siggraph.org/s2008/attendees/caf/3d/	O
.	O
renderbackgroundbirenderforegroundfiovercompositecamera	O
irenderbackgroundbi+1renderforegroundfi+1overcompositeblendcamerai+1dimibistripwidthstripwidthdepthdiscontinuitymatte	O
13.5	O
video-based	O
rendering	O
645	O
other	O
hand	O
,	O
associates	O
a	O
two-layer	O
depth	B
map	I
with	O
each	O
input	O
image	B
,	O
which	O
allows	O
them	O
to	O
accurately	O
model	O
occlusion	O
effects	O
such	O
as	O
the	O
mixed	O
pixels	O
that	O
occur	O
at	O
object	O
boundaries	O
.	O
their	O
system	O
,	O
which	O
consists	O
of	O
eight	O
synchronized	O
video	B
cameras	O
connected	O
to	O
a	O
disk	O
array	O
(	O
figure	O
13.15a	O
)	O
,	O
ﬁrst	O
uses	O
segmentation-based	B
stereo	O
to	O
extract	O
a	O
depth	B
map	I
for	O
each	O
input	O
image	B
(	O
figure	O
13.15e	O
)	O
.	O
near	O
object	O
boundaries	O
(	O
depth	O
discontinuities	O
)	O
,	O
the	O
background	O
layer	O
is	O
extended	O
along	O
a	O
strip	O
behind	O
the	O
foreground	O
object	O
(	O
figure	O
13.15c	O
)	O
and	O
its	O
color	B
is	O
es-	O
timated	O
from	O
the	O
neighboring	O
images	O
where	O
it	O
is	O
not	O
occluded	O
(	O
figure	O
13.15d	O
)	O
.	O
automated	B
matting	O
techniques	O
(	O
section	O
10.4	O
)	O
are	O
then	O
used	O
to	O
estimate	O
the	O
fractional	O
opacity	B
and	O
color	B
of	O
boundary	O
pixels	O
in	O
the	O
foreground	O
layer	O
(	O
figure	O
13.15f	O
)	O
.	O
at	O
render	O
time	O
,	O
given	O
a	O
new	O
virtual	O
camera	O
that	O
lies	O
between	O
two	O
of	O
the	O
original	O
cameras	O
,	O
the	O
layers	B
in	O
the	O
neighboring	O
cameras	O
are	O
rendered	O
as	O
texture-mapped	O
triangles	O
and	O
the	O
fore-	O
ground	O
layer	O
(	O
which	O
may	O
have	O
fractional	O
opacities	O
)	O
is	O
then	O
composited	O
over	O
the	O
background	O
layer	O
(	O
figure	O
13.15b	O
)	O
.	O
the	O
resulting	O
two	O
images	O
are	O
merged	O
and	O
blended	O
by	O
comparing	O
their	O
respective	O
z-buffer	O
values	O
.	O
(	O
whenever	O
the	O
two	O
z-values	O
are	O
sufﬁciently	O
close	O
,	O
a	O
linear	B
blend	O
of	O
the	O
two	O
colors	O
is	O
computed	O
.	O
)	O
the	O
interactive	B
rendering	O
system	O
runs	O
in	O
real	O
time	O
using	O
regular	O
graphics	O
hardware	O
.	O
it	O
can	O
therefore	O
be	O
used	O
to	O
change	O
the	O
observer	O
’	O
s	O
viewpoint	O
while	O
playing	O
the	O
video	B
or	O
to	O
freeze	O
the	O
scene	O
and	O
explore	O
it	O
in	O
3d	O
.	O
more	O
recently	O
,	O
rogmans	O
,	O
lu	O
,	O
bekaert	O
et	O
al	O
.	O
(	O
2009	O
)	O
have	O
developed	O
gpu	O
implementations	O
of	O
both	O
real-time	O
stereo	B
matching	I
and	O
real-time	O
rendering	B
algorithms	O
,	O
which	O
enable	O
them	O
to	O
explore	O
algorithmic	O
alternatives	O
in	O
a	O
real-time	O
setting	O
.	O
at	O
present	O
,	O
the	O
depth	O
maps	O
computed	O
from	O
the	O
eight	O
stereo	B
cameras	O
using	O
off-line	O
stereo	B
matching	I
have	O
produced	O
the	O
highest	O
quality	O
depth	O
maps	O
associated	O
with	O
live	O
video.10	O
they	O
are	O
therefore	O
often	O
used	O
in	O
studies	O
of	O
3d	O
video	B
compression	I
,	O
which	O
is	O
an	O
active	O
area	O
of	O
re-	O
search	O
(	O
smolic	O
and	O
kauff	O
2005	O
;	O
gotchev	O
and	O
rosenhahn	O
2009	O
)	O
.	O
active	O
video-rate	O
depth	O
sensing	O
cameras	O
,	O
such	O
as	O
the	O
3dv	O
zcam	O
(	O
iddan	O
and	O
yahav	O
2001	O
)	O
,	O
which	O
we	O
discussed	O
in	O
section	O
12.2.1	O
,	O
are	O
another	O
potential	O
source	O
of	O
such	O
data	O
.	O
when	O
large	O
numbers	O
of	O
closely	O
spaced	O
cameras	O
are	O
available	O
,	O
as	O
in	O
the	O
stanford	O
light	O
field	O
camera	B
(	O
wilburn	O
,	O
joshi	O
,	O
vaish	O
et	O
al	O
.	O
2005	O
)	O
,	O
it	O
may	O
not	O
always	O
be	O
necessary	O
to	O
compute	O
explicit	O
depth	O
maps	O
to	O
create	O
video-based	O
rendering	O
effects	O
,	O
although	O
the	O
results	O
are	O
usually	O
of	O
higher	O
quality	O
if	O
you	O
do	O
(	O
vaish	O
,	O
szeliski	O
,	O
zitnick	O
et	O
al	O
.	O
2006	O
)	O
.	O
13.5.5	O
application	O
:	O
video-based	B
walkthroughs	I
video	O
camera	B
arrays	O
enable	O
the	O
simultaneous	O
capture	O
of	O
3d	O
dynamic	B
scenes	O
from	O
multiple	B
viewpoints	O
,	O
which	O
can	O
then	O
enable	O
the	O
viewer	O
to	O
explore	O
the	O
scene	O
from	O
viewpoints	O
near	O
the	O
original	O
capture	O
locations	O
.	O
what	O
if	O
instead	O
we	O
wish	O
to	O
capture	O
an	O
extended	O
area	O
,	O
such	O
as	O
a	O
home	O
,	O
a	O
movie	O
set	O
,	O
or	O
even	O
an	O
entire	O
city	O
?	O
10	O
http	O
:	O
//research.microsoft.com/en-us/um/redmond/groups/ivm/vvv/	O
.	O
646	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
in	O
this	O
case	O
,	O
it	O
makes	O
more	O
sense	O
to	O
move	O
the	O
camera	B
through	O
the	O
environment	O
and	O
play	O
back	O
the	O
video	B
as	O
an	O
interactive	B
video-based	O
walkthrough	O
.	O
in	O
order	B
to	O
allow	O
the	O
viewer	O
to	O
look	O
around	O
in	O
all	O
directions	O
,	O
it	O
is	O
preferable	O
to	O
use	O
a	O
panoramic	O
video	B
camera	O
(	O
uyttendaele	O
,	O
criminisi	O
,	O
kang	O
et	O
al	O
.	O
2004	O
)	O
.11	O
one	O
way	O
to	O
structure	O
the	O
acquisition	O
process	O
is	O
to	O
capture	O
these	O
images	O
in	O
a	O
2d	O
horizontal	O
plane	O
,	O
e.g.	O
,	O
over	O
a	O
grid	O
superimposed	O
inside	O
a	O
room	O
.	O
the	O
resulting	O
sea	O
of	O
images	O
(	O
aliaga	O
,	O
funkhouser	O
,	O
yanovsky	O
et	O
al	O
.	O
2003	O
)	O
can	O
be	O
used	O
to	O
enable	O
continuous	O
motion	B
between	O
the	O
captured	O
locations.12	O
however	O
,	O
extending	O
this	O
idea	O
to	O
larger	O
settings	O
,	O
e.g.	O
,	O
beyond	O
a	O
single	O
room	O
,	O
can	O
become	O
tedious	O
and	O
data-intensive	O
.	O
instead	O
,	O
a	O
natural	B
way	O
to	O
explore	O
a	O
space	O
is	O
often	O
to	O
just	O
walk	O
through	O
it	O
along	O
some	O
pre-	O
speciﬁed	O
paths	O
,	O
just	O
as	O
museums	O
or	O
home	O
tours	O
guide	O
users	O
along	O
a	O
particular	O
path	O
,	O
say	O
down	O
the	O
middle	O
of	O
each	O
room.13	O
similarly	O
,	O
city-level	O
exploration	O
can	O
be	O
achieved	O
by	O
driving	O
down	O
the	O
middle	O
of	O
each	O
street	O
and	O
allowing	O
the	O
user	O
to	O
branch	O
at	O
each	O
intersection	O
.	O
this	O
idea	O
dates	O
back	O
to	O
the	O
aspen	O
moviemap	O
project	O
(	O
lippman	O
1980	O
)	O
,	O
which	O
recorded	O
analog	O
video	B
taken	O
from	O
moving	O
cars	O
onto	O
videodiscs	O
for	O
later	O
interactive	B
playback	O
.	O
recent	O
improvements	O
in	O
video	B
technology	O
now	O
enable	O
the	O
capture	O
of	O
panoramic	O
(	O
spheri-	O
cal	O
)	O
video	B
using	O
a	O
small	O
co-located	O
array	O
of	O
cameras	O
,	O
such	O
as	O
the	O
point	O
grey	O
ladybug	O
cam-	O
era14	O
(	O
figure	O
13.16b	O
)	O
developed	O
by	O
uyttendaele	O
,	O
criminisi	O
,	O
kang	O
et	O
al	O
.	O
(	O
2004	O
)	O
for	O
their	O
inter-	O
active	O
video-based	O
walkthrough	O
project	O
.	O
in	O
their	O
system	O
,	O
the	O
synchronized	O
video	B
streams	O
from	O
the	O
six	O
cameras	O
(	O
figure	O
13.16a	O
)	O
are	O
stitched	O
together	O
into	O
360◦	O
panoramas	O
using	O
a	O
variety	O
of	O
techniques	O
developed	O
speciﬁcally	O
for	O
this	O
project	O
.	O
because	O
the	O
cameras	O
do	O
not	O
share	O
the	O
same	O
center	O
of	O
projection	O
,	O
parallax	O
between	O
the	O
cameras	O
can	O
lead	O
to	O
ghosting	O
in	O
the	O
overlapping	O
ﬁelds	O
of	O
view	O
(	O
figure	O
13.16c	O
)	O
.	O
to	O
remove	O
this	O
,	O
a	O
multi-perspective	O
plane	B
sweep	I
stereo	O
algorithm	B
is	O
used	O
to	O
estimate	O
per-pixel	O
depths	O
at	O
each	O
column	O
in	O
the	O
overlap	O
area	O
.	O
to	O
calibrate	O
the	O
cameras	O
relative	O
to	O
each	O
other	O
,	O
the	O
camera	B
is	O
spun	O
in	O
place	O
and	O
a	O
constrained	B
structure	O
from	O
motion	B
algorithm	O
(	O
figure	O
7.8	O
)	O
is	O
used	O
to	O
estimate	O
the	O
relative	O
camera	B
poses	O
and	O
intrinsics	O
.	O
feature	B
tracking	O
is	O
then	O
run	O
on	O
the	O
walk-	O
through	O
video	B
in	O
order	B
to	O
stabilize	O
the	O
video	B
sequence—liu	O
,	O
gleicher	O
,	O
jin	O
et	O
al	O
.	O
(	O
2009	O
)	O
have	O
carried	O
out	O
more	O
recent	O
work	O
along	O
these	O
lines	B
.	O
indoor	O
environments	O
with	O
windows	O
,	O
as	O
well	O
as	O
sunny	O
outdoor	O
environments	O
with	O
strong	O
shadows	O
,	O
often	O
have	O
a	O
dynamic	B
range	O
that	O
exceeds	O
the	O
capabilities	O
of	O
video	B
sensors	O
.	O
for	O
this	O
reason	O
,	O
the	O
ladybug	O
camera	B
has	O
a	O
programmable	O
exposure	O
capability	O
that	O
enables	O
the	O
bracketing	O
of	O
exposures	O
at	O
subsequent	O
video	B
frames	O
.	O
in	O
order	B
to	O
merge	O
the	O
resulting	O
video	B
11	O
see	O
http	O
:	O
//www.cis.upenn.edu/∼kostas/omni.html	O
for	O
descriptions	O
of	O
panoramic	O
(	O
omnidirectional	O
)	O
vision	O
sys-	O
tems	O
and	O
associated	O
workshops	O
.	O
12	O
(	O
the	O
photo	O
tourism	O
system	O
of	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
(	O
2006	O
)	O
applies	O
this	O
idea	O
to	O
less	O
structured	O
collections	O
.	O
13	O
in	O
computer	O
games	O
,	O
restricting	O
a	O
player	O
to	O
forward	B
and	O
backward	O
motion	B
along	O
predetermined	O
paths	O
is	O
called	O
rail-based	O
gaming	O
.	O
14	O
http	O
:	O
//www.ptgrey.com/	O
.	O
13.5	O
video-based	O
rendering	O
647	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
f	O
)	O
(	O
d	O
)	O
(	O
g	O
)	O
(	O
b	O
)	O
(	O
e	O
)	O
figure	O
13.16	O
video-based	B
walkthroughs	I
(	O
uyttendaele	O
,	O
criminisi	O
,	O
kang	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
ieee	O
:	O
(	O
a	O
)	O
system	O
diagram	O
of	O
video	B
pre-processing	O
;	O
(	O
b	O
)	O
the	O
point	O
grey	O
ladybug	O
camera	B
;	O
(	O
c	O
)	O
ghost	O
removal	O
using	O
multi-perspective	O
plane	B
sweep	I
;	O
(	O
d	O
)	O
point	O
tracking	O
,	O
used	O
both	O
for	O
calibra-	O
tion	B
and	O
stabilization	O
;	O
(	O
e	O
)	O
interactive	B
garden	O
walkthrough	O
with	O
map	O
below	O
;	O
(	O
f	O
)	O
overhead	O
map	O
authoring	O
and	O
sound	O
placement	O
;	O
(	O
g	O
)	O
interactive	B
home	O
walkthrough	O
with	O
navigation	O
bar	O
(	O
top	O
)	O
and	O
icons	O
of	O
interest	O
(	O
bottom	O
)	O
.	O
648	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
frames	O
into	O
high	B
dynamic	I
range	I
(	O
hdr	O
)	O
video	B
,	O
pixels	O
from	O
adjacent	O
frames	O
need	O
to	O
be	O
motion-	O
compensated	O
before	O
being	O
merged	O
(	O
kang	O
,	O
uyttendaele	O
,	O
winder	O
et	O
al	O
.	O
2003	O
)	O
.	O
the	O
interactive	B
walk-through	O
experience	O
becomes	O
much	O
richer	O
and	O
more	O
navigable	O
if	O
an	O
overview	O
map	O
is	O
available	O
as	O
part	O
of	O
the	O
experience	O
.	O
in	O
figure	O
13.16f	O
,	O
the	O
map	O
has	O
annotations	O
,	O
which	O
can	O
show	O
up	O
during	O
the	O
tour	O
,	O
and	O
localized	O
sound	O
sources	O
,	O
which	O
play	O
(	O
with	O
different	O
volumes	O
)	O
when	O
the	O
viewer	O
is	O
nearby	O
.	O
the	O
process	O
of	O
aligning	O
the	O
video	B
sequence	O
with	O
the	O
map	O
can	O
be	O
automated	B
using	O
a	O
process	O
called	O
map	O
correlation	O
(	O
levin	O
and	O
szeliski	O
2004	O
)	O
.	O
all	O
of	O
these	O
elements	O
combine	O
to	O
provide	O
the	O
user	O
with	O
a	O
rich	O
,	O
interactive	B
,	O
and	O
immersive	O
experience	O
.	O
figure	O
13.16e	O
shows	O
a	O
walk	O
through	O
the	O
bellevue	O
botanical	O
gardens	O
,	O
with	O
an	O
overview	O
map	O
in	O
perspective	B
below	O
the	O
live	O
video	B
window	O
.	O
arrows	O
on	O
the	O
ground	O
are	O
used	O
to	O
indicate	O
potential	O
directions	O
of	O
travel	O
.	O
the	O
viewer	O
simply	O
orients	O
his	O
view	O
towards	O
one	O
of	O
the	O
arrows	O
(	O
the	O
experience	O
can	O
be	O
driven	O
using	O
a	O
game	O
controller	O
)	O
and	O
“	O
walks	O
”	O
forward	B
along	O
the	O
desired	O
path	O
.	O
figure	O
13.16g	O
shows	O
an	O
indoor	O
home	O
tour	O
experience	O
.	O
in	O
addition	O
to	O
a	O
schematic	O
map	O
in	O
the	O
lower	O
left	O
corner	O
and	O
adjacent	O
room	O
names	O
along	O
the	O
top	O
navigation	O
bar	O
,	O
icons	O
appear	O
along	O
the	O
bottom	O
whenever	O
items	O
of	O
interest	O
,	O
such	O
as	O
a	O
homeowner	O
’	O
s	O
art	O
pieces	O
,	O
are	O
visible	O
in	O
the	O
main	O
window	O
.	O
these	O
icons	O
can	O
then	O
be	O
clicked	O
to	O
provide	O
more	O
information	O
and	O
3d	O
views	O
.	O
the	O
development	O
of	O
interactive	B
video	O
tours	O
spurred	O
a	O
renewed	O
interest	O
in	O
360◦	O
video-based	O
virtual	O
travel	O
and	O
mapping	O
experiences	O
,	O
as	O
evidenced	O
by	O
commercial	O
sites	O
such	O
as	O
google	O
’	O
s	O
street	O
view	O
and	O
bing	O
maps	O
.	O
the	O
same	O
videos	O
can	O
also	O
be	O
used	O
to	O
generate	O
turn-by-turn	O
driv-	O
ing	O
directions	O
,	O
taking	O
advantage	O
of	O
both	O
expanded	O
ﬁelds	O
of	O
view	O
and	O
image-based	B
rendering	I
to	O
enhance	O
the	O
experience	O
(	O
chen	O
,	O
neubert	O
,	O
ofek	O
et	O
al	O
.	O
2009	O
)	O
.	O
as	O
we	O
continue	O
to	O
capture	O
more	O
and	O
more	O
of	O
our	O
real	O
world	O
with	O
large	O
amounts	O
of	O
high-	O
quality	O
imagery	O
and	O
video	B
,	O
the	O
interactive	B
modeling	O
,	O
exploration	O
,	O
and	O
rendering	B
techniques	O
described	O
in	O
this	O
chapter	O
will	O
play	O
an	O
even	O
bigger	O
role	O
in	O
bringing	O
virtual	O
experiences	O
based	O
on	O
remote	O
areas	O
of	O
the	O
world	O
closer	O
to	O
everyone	O
.	O
13.6	O
additional	O
reading	O
two	O
good	O
recent	O
surveys	B
of	O
image-based	B
rendering	I
are	O
by	O
kang	O
,	O
li	O
,	O
tong	O
et	O
al	O
.	O
(	O
2006	O
)	O
and	O
shum	O
,	O
chan	O
,	O
and	O
kang	O
(	O
2007	O
)	O
,	O
with	O
earlier	O
surveys	B
available	O
from	O
kang	O
(	O
1999	O
)	O
,	O
mcmillan	O
and	O
gortler	O
(	O
1999	O
)	O
,	O
and	O
debevec	O
(	O
1999	O
)	O
.	O
the	O
term	O
image-based	B
rendering	I
was	O
introduced	O
by	O
mcmillan	O
and	O
bishop	O
(	O
1995	O
)	O
,	O
although	O
the	O
seminal	O
paper	O
in	O
the	O
ﬁeld	O
is	O
the	O
view	B
interpolation	I
paper	O
by	O
chen	O
and	O
williams	O
(	O
1993	O
)	O
.	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
(	O
1996	O
)	O
describe	O
their	O
fac¸ade	O
system	O
,	O
which	O
not	O
only	O
created	O
a	O
variety	O
of	O
image-based	B
modeling	O
tools	O
but	O
also	O
introduced	O
the	O
widely	O
used	O
technique	O
of	O
view-dependent	O
texture	O
mapping	O
.	O
13.6	O
additional	O
reading	O
649	O
early	O
work	O
on	O
planar	O
impostors	O
and	O
layers	B
was	O
carried	O
out	O
by	O
shade	O
,	O
lischinski	O
,	O
salesin	O
et	O
al	O
.	O
(	O
1996	O
)	O
,	O
lengyel	O
and	O
snyder	O
(	O
1997	O
)	O
,	O
and	O
torborg	O
and	O
kajiya	O
(	O
1996	O
)	O
,	O
while	O
newer	O
work	O
based	O
on	O
sprites	B
with	O
depth	O
is	O
described	O
by	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
(	O
1998	O
)	O
.	O
the	O
two	O
foundational	O
papers	O
in	O
image-based	B
rendering	I
are	O
light	B
ﬁeld	I
rendering	O
by	O
levoy	O
and	O
hanrahan	O
(	O
1996	O
)	O
and	O
the	O
lumigraph	O
by	O
gortler	O
,	O
grzeszczuk	O
,	O
szeliski	O
et	O
al	O
.	O
(	O
1996	O
)	O
.	O
buehler	O
,	O
bosse	O
,	O
mcmillan	O
et	O
al	O
.	O
(	O
2001	O
)	O
generalize	O
the	O
lumigraph	O
approach	O
to	O
irregularly	O
spaced	O
collections	O
of	O
images	O
,	O
while	O
levoy	O
(	O
2006	O
)	O
provides	O
a	O
survey	O
and	O
more	O
gentle	O
intro-	O
duction	O
to	O
the	O
topic	O
of	O
light	B
ﬁeld	I
and	O
image-based	B
rendering	I
.	O
surface	O
light	O
ﬁelds	O
(	O
wood	O
,	O
azuma	O
,	O
aldinger	O
et	O
al	O
.	O
2000	O
)	O
provide	O
an	O
alternative	O
param-	O
eterization	O
for	O
light	O
ﬁelds	O
with	O
accurately	O
known	O
surface	B
geometry	O
and	O
support	O
both	O
better	O
compression	B
and	O
the	O
possibility	O
of	O
editing	O
surface	B
properties	O
.	O
concentric	O
mosaics	O
(	O
shum	O
and	O
he	O
1999	O
;	O
shum	O
,	O
wang	O
,	O
chai	O
et	O
al	O
.	O
2002	O
)	O
and	O
panoramas	O
with	B
depth	I
(	O
peleg	O
,	O
ben-ezra	O
,	O
and	O
pritch	O
2001	O
;	O
li	O
,	O
shum	O
,	O
tang	O
et	O
al	O
.	O
2004	O
;	O
zheng	O
,	O
kang	O
,	O
cohen	O
et	O
al	O
.	O
2007	O
)	O
,	O
provide	O
useful	O
parameterizations	O
for	O
light	O
ﬁelds	O
captured	O
with	O
panning	O
cameras	O
.	O
multi-perspective	O
images	O
(	O
rademacher	O
and	O
bishop	O
1998	O
)	O
and	O
manifold	O
projections	B
(	O
peleg	O
and	O
herman	O
1997	O
)	O
,	O
although	O
not	O
true	O
light	O
ﬁelds	O
,	O
are	O
also	O
closely	O
related	O
to	O
these	O
ideas	O
.	O
among	O
the	O
possible	O
extensions	O
of	O
light	O
ﬁelds	O
to	O
higher-dimensional	O
structures	O
,	O
environ-	O
ment	O
mattes	O
(	O
zongker	O
,	O
werner	O
,	O
curless	O
et	O
al	O
.	O
1999	O
;	O
chuang	O
,	O
zongker	O
,	O
hindorff	O
et	O
al	O
.	O
2000	O
)	O
are	O
the	O
most	O
useful	O
,	O
especially	O
for	O
placing	O
captured	O
objects	O
into	O
new	O
scenes	O
.	O
video-based	O
rendering	O
,	O
i.e.	O
,	O
the	O
re-use	O
of	O
video	B
to	O
create	O
new	O
animations	O
or	O
virtual	O
ex-	O
periences	O
,	O
started	O
with	O
the	O
seminal	O
work	O
of	O
szummer	O
and	O
picard	O
(	O
1996	O
)	O
,	O
bregler	O
,	O
covell	O
,	O
and	O
slaney	O
(	O
1997	O
)	O
,	O
and	O
sch¨odl	O
,	O
szeliski	O
,	O
salesin	O
et	O
al	O
.	O
(	O
2000	O
)	O
.	O
important	O
follow-on	O
work	O
to	O
these	O
basic	O
re-targeting	O
approaches	O
was	O
carried	O
out	O
by	O
sch¨odl	O
and	O
essa	O
(	O
2002	O
)	O
,	O
kwatra	O
,	O
sch¨odl	O
,	O
essa	O
et	O
al	O
.	O
(	O
2003	O
)	O
,	O
doretto	O
,	O
chiuso	O
,	O
wu	O
et	O
al	O
.	O
(	O
2003	O
)	O
,	O
wang	O
and	O
zhu	O
(	O
2003	O
)	O
,	O
zhong	O
and	O
sclaroff	O
(	O
2003	O
)	O
,	O
yuan	O
,	O
wen	O
,	O
liu	O
et	O
al	O
.	O
(	O
2004	O
)	O
,	O
doretto	O
and	O
soatto	O
(	O
2006	O
)	O
,	O
zhao	O
and	O
pietik¨ainen	O
(	O
2007	O
)	O
,	O
and	O
chan	O
and	O
vasconcelos	O
(	O
2009	O
)	O
.	O
systems	O
that	O
allow	O
users	O
to	O
change	O
their	O
3d	O
viewpoint	O
based	O
on	O
multiple	B
synchronized	O
video	B
streams	O
include	O
those	O
by	O
moezzi	O
,	O
katkere	O
,	O
kuramura	O
et	O
al	O
.	O
(	O
1996	O
)	O
,	O
kanade	O
,	O
ran-	O
der	O
,	O
and	O
narayanan	O
(	O
1997	O
)	O
,	O
matusik	O
,	O
buehler	O
,	O
raskar	O
et	O
al	O
.	O
(	O
2000	O
)	O
,	O
matusik	O
,	O
buehler	O
,	O
and	O
mcmillan	O
(	O
2001	O
)	O
,	O
carranza	O
,	O
theobalt	O
,	O
magnor	O
et	O
al	O
.	O
(	O
2003	O
)	O
,	O
zitnick	O
,	O
kang	O
,	O
uyttendaele	O
et	O
al	O
.	O
(	O
2004	O
)	O
,	O
magnor	O
(	O
2005	O
)	O
,	O
and	O
vedula	O
,	O
baker	O
,	O
and	O
kanade	O
(	O
2005	O
)	O
.	O
3d	O
(	O
multiview	O
)	O
video	B
coding	O
and	O
compression	B
is	O
also	O
an	O
active	O
area	O
of	O
research	O
(	O
smolic	O
and	O
kauff	O
2005	O
;	O
gotchev	O
and	O
rosenhahn	O
2009	O
)	O
,	O
with	O
3d	O
blu-ray	O
discs	O
,	O
encoded	O
using	O
the	O
multiview	O
video	B
coding	O
(	O
mvc	O
)	O
extension	O
to	O
h.264/mpeg-4	O
avc	O
,	O
expected	O
by	O
the	O
end	O
of	O
2010	O
.	O
650	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
13.7	O
exercises	O
ex	O
13.1	O
:	O
depth	O
image	O
rendering	B
develop	O
a	O
“	O
view	O
extrapolation	O
”	O
algorithm	B
to	O
re-render	O
a	O
previously	O
computed	O
stereo	B
depth	O
map	O
coupled	O
with	O
its	O
corresponding	O
reference	O
color	B
image	O
.	O
1.	O
use	O
a	O
3d	O
graphics	O
mesh	O
rendering	B
system	O
such	O
as	O
opengl	O
or	O
direct3d	O
,	O
with	O
two	O
triangles	O
per	O
pixel	O
quad	O
and	O
perspective	B
(	O
projective	B
)	O
texture	B
mapping	O
(	O
debevec	O
,	O
yu	O
,	O
and	O
borshukov	O
1998	O
)	O
.	O
2.	O
alternatively	O
,	O
use	O
the	O
one-	O
or	O
two-pass	O
forward	B
warper	O
you	O
constructed	O
in	O
exercise	O
3.24	O
,	O
extended	O
using	O
(	O
2.68–2.70	O
)	O
to	O
convert	O
from	O
disparities	O
or	O
depths	O
into	O
displacements	O
.	O
3	O
.	O
(	O
optional	O
)	O
kinks	O
in	O
straight	O
lines	B
introduced	O
during	O
view	B
interpolation	I
or	O
extrapola-	O
tion	B
are	O
visually	O
noticeable	O
,	O
which	O
is	O
one	O
reason	O
why	O
image	B
morphing	O
systems	O
let	O
you	O
specify	O
line	O
correspondences	O
(	O
beier	O
and	O
neely	O
1992	O
)	O
.	O
modify	O
your	O
depth	O
estimation	O
algorithm	B
to	O
match	O
and	O
estimate	O
the	O
geometry	O
of	O
straight	O
lines	B
and	O
incorporate	O
it	O
into	O
your	O
image-based	B
rendering	I
algorithm	O
.	O
ex	O
13.2	O
:	O
view	B
interpolation	I
extend	O
the	O
system	O
you	O
created	O
in	O
the	O
previous	O
exercise	O
to	O
ren-	O
der	O
two	O
reference	O
views	O
and	O
then	O
blend	O
the	O
images	O
using	O
a	O
combination	O
of	O
z-buffering	O
,	O
hole	O
ﬁling	O
,	O
and	O
blending	B
(	O
morphing	B
)	O
to	O
create	O
the	O
ﬁnal	O
image	B
(	O
section	O
13.1	O
)	O
.	O
1	O
.	O
(	O
optional	O
)	O
if	O
the	O
two	O
source	O
images	O
have	O
very	O
different	O
exposures	O
,	O
the	O
hole-ﬁlled	O
re-	O
gions	O
and	O
the	O
blended	O
regions	O
will	O
have	O
different	O
exposures	O
.	O
can	O
you	O
extend	O
your	O
algorithm	B
to	O
mitigate	O
this	O
?	O
2	O
.	O
(	O
optional	O
)	O
extend	O
your	O
algorithm	B
to	O
perform	O
three-way	O
(	O
trilinear	B
)	O
interpolation	B
be-	O
tween	O
neighboring	O
views	O
.	O
you	O
can	O
triangulate	O
the	O
reference	O
camera	B
poses	O
and	O
use	O
barycentric	O
coordinates	O
for	O
the	O
virtual	O
camera	O
in	O
order	B
to	O
determine	O
the	O
blending	B
weights	O
.	O
ex	O
13.3	O
:	O
view	B
morphing	I
modify	O
your	O
view	B
interpolation	I
algorithm	O
to	O
perform	O
morphs	O
be-	O
tween	O
views	O
of	O
a	O
non-rigid	B
object	O
,	O
such	O
as	O
a	O
person	O
changing	O
expressions	O
.	O
1.	O
instead	O
of	O
using	O
a	O
pure	O
stereo	O
algorithm	B
,	O
use	O
a	O
general	O
ﬂow	O
algorithm	B
to	O
compute	O
dis-	O
placements	O
,	O
but	O
separate	O
them	O
into	O
a	O
rigid	O
displacement	O
due	O
to	O
camera	B
motion	O
and	O
a	O
non-rigid	B
deformation	O
.	O
2.	O
at	O
render	O
time	O
,	O
use	O
the	O
rigid	O
geometry	O
to	O
determine	O
the	O
new	O
pixel	O
location	O
but	O
then	O
add	O
a	O
fraction	O
of	O
the	O
non-rigid	B
displacement	O
as	O
well	O
.	O
3.	O
alternatively	O
,	O
compute	O
a	O
stereo	B
depth	O
map	O
but	O
let	O
the	O
user	O
specify	O
additional	O
correspon-	O
dences	O
or	O
use	O
a	O
feature-based	B
matching	O
algorithm	B
to	O
provide	O
them	O
automatically	O
.	O
13.7	O
exercises	O
651	O
4	O
.	O
(	O
optional	O
)	O
take	O
a	O
single	O
image	O
,	O
such	O
as	O
the	O
mona	O
lisa	O
or	O
a	O
friend	O
’	O
s	O
picture	O
,	O
and	O
create	O
an	O
animated	O
3d	O
view	O
morph	O
(	O
seitz	O
and	O
dyer	O
1996	O
)	O
.	O
(	O
a	O
)	O
find	O
the	O
vertical	O
axis	O
of	O
symmetry	O
in	O
the	O
image	B
and	O
reﬂect	O
your	O
reference	O
image	B
to	O
provide	O
a	O
virtual	O
pair	O
(	O
assuming	O
the	O
person	O
’	O
s	O
hairstyle	O
is	O
somewhat	O
symmetric	O
)	O
.	O
(	O
b	O
)	O
use	O
structure	B
from	I
motion	I
to	O
determine	O
the	O
relative	O
camera	B
pose	O
of	O
the	O
pair	O
.	O
(	O
c	O
)	O
use	O
dense	O
stereo	O
matching	B
to	O
estimate	O
the	O
3d	O
shape	O
.	O
(	O
d	O
)	O
use	O
view	B
morphing	I
to	O
create	O
a	O
3d	O
animation	O
.	O
ex	O
13.4	O
:	O
view	O
dependent	O
texture	B
mapping	O
use	O
a	O
3d	O
model	O
you	O
created	O
along	O
with	O
the	O
original	O
images	O
to	O
implement	O
a	O
view-dependent	O
texture	O
mapping	O
system	O
.	O
1.	O
use	O
one	O
of	O
the	O
3d	O
reconstruction	O
techniques	O
you	O
developed	O
in	O
exercises	O
7.3	O
,	O
11.9	O
,	O
11.10	O
,	O
or	O
12.8	O
to	O
build	O
a	O
triangulated	O
3d	O
image-based	B
model	O
from	O
multiple	B
photographs	O
.	O
2.	O
extract	O
textures	O
for	O
each	O
model	O
face	B
from	O
your	O
photographs	O
,	O
either	O
by	O
performing	O
the	O
appropriate	O
resampling	O
or	O
by	O
ﬁguring	O
out	O
how	O
to	O
use	O
the	O
texture	B
mapping	O
software	O
to	O
directly	O
access	O
the	O
source	O
images	O
.	O
3.	O
at	O
run	O
time	O
,	O
for	O
each	O
new	O
camera	B
view	O
,	O
select	O
the	O
best	O
source	O
image	B
for	O
each	O
visible	O
model	O
face	B
.	O
4.	O
extend	O
this	O
to	O
blend	O
between	O
the	O
top	O
two	O
or	O
three	O
textures	O
.	O
this	O
is	O
trickier	O
,	O
since	O
it	O
involves	O
the	O
use	O
of	O
texture	B
blending	O
or	O
pixel	O
shading	O
(	O
debevec	O
,	O
taylor	O
,	O
and	O
malik	O
1996	O
;	O
debevec	O
,	O
yu	O
,	O
and	O
borshukov	O
1998	O
;	O
pighin	O
,	O
hecker	O
,	O
lischinski	O
et	O
al	O
.	O
1998	O
)	O
.	O
ex	O
13.5	O
:	O
layered	O
depth	O
images	O
extend	O
your	O
view	B
interpolation	I
algorithm	O
(	O
exercise	O
13.2	O
)	O
to	O
store	O
more	O
than	O
one	O
depth	O
or	O
color	B
value	O
per	O
pixel	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
,	O
i.e.	O
,	O
a	O
layered	B
depth	I
image	I
(	O
ldi	O
)	O
.	O
modify	O
your	O
rendering	B
algorithm	O
accordingly	O
.	O
for	O
your	O
data	O
,	O
you	O
can	O
use	O
synthetic	O
ray	O
tracing	O
,	O
a	O
layered	B
reconstructed	O
model	O
,	O
or	O
a	O
volumetric	B
reconstruction	O
.	O
ex	O
13.6	O
:	O
rendering	B
from	O
sprites	B
or	O
layers	B
extend	O
your	O
view	B
interpolation	I
algorithm	O
to	O
handle	O
multiple	B
planes	O
or	O
sprites	B
(	O
section	O
13.2.1	O
)	O
(	O
shade	O
,	O
gortler	O
,	O
he	O
et	O
al	O
.	O
1998	O
)	O
.	O
1.	O
extract	O
your	O
layers	B
using	O
the	O
technique	O
you	O
developed	O
in	O
exercise	O
8.9	O
.	O
2.	O
alternatively	O
,	O
use	O
an	O
interactive	B
painting	O
and	O
3d	O
placement	O
system	O
to	O
extract	O
your	O
lay-	O
ers	O
(	O
kang	O
1998	O
;	O
oh	O
,	O
chen	O
,	O
dorsey	O
et	O
al	O
.	O
2001	O
;	O
shum	O
,	O
sun	O
,	O
yamazaki	O
et	O
al	O
.	O
2004	O
)	O
.	O
3.	O
determine	O
a	O
back-to-front	O
order	B
based	O
on	O
expected	O
visibility	B
or	O
add	O
a	O
z-buffer	O
to	O
your	O
rendering	B
algorithm	O
to	O
handle	O
occlusions	O
.	O
652	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
4.	O
render	O
and	O
composite	O
all	O
of	O
the	O
resulting	O
layers	B
,	O
with	O
optional	O
alpha	O
matting	O
to	O
handle	O
the	O
edges	O
of	O
layers	B
and	O
sprites	B
.	O
ex	O
13.7	O
:	O
light	B
ﬁeld	I
transformations	O
derive	O
the	O
equations	B
relating	O
regular	O
images	O
to	O
4d	O
light	B
ﬁeld	I
coordinates	O
.	O
1.	O
determine	O
the	O
mapping	O
between	O
the	O
far	O
plane	O
(	O
u	O
,	O
v	O
)	O
coordinates	O
and	O
a	O
virtual	O
camera	O
’	O
s	O
(	O
x	O
,	O
y	O
)	O
coordinates	O
.	O
(	O
a	O
)	O
start	O
by	O
parameterizing	O
a	O
3d	O
point	O
on	O
the	O
uv	O
plane	O
in	O
terms	O
of	O
its	O
(	O
u	O
,	O
v	O
)	O
coordi-	O
nates	O
.	O
(	O
b	O
)	O
project	O
the	O
resulting	O
3d	O
point	O
to	O
the	O
camera	B
pixels	O
(	O
x	O
,	O
y	O
,	O
1	O
)	O
using	O
the	O
usual	O
3	O
×	O
4	O
camera	B
matrix	O
p	O
(	O
2.63	O
)	O
.	O
(	O
c	O
)	O
derive	O
the	O
2d	O
homography	B
relating	O
(	O
u	O
,	O
v	O
)	O
and	O
(	O
x	O
,	O
y	O
)	O
coordinates	O
.	O
2.	O
write	O
down	O
a	O
similar	O
transformation	O
for	O
(	O
s	O
,	O
t	O
)	O
to	O
(	O
x	O
,	O
y	O
)	O
coordinates	O
.	O
3.	O
prove	O
that	O
if	O
the	O
virtual	O
camera	O
is	O
actually	O
on	O
the	O
(	O
s	O
,	O
t	O
)	O
plane	O
,	O
the	O
(	O
s	O
,	O
t	O
)	O
value	O
depends	O
only	O
on	O
the	O
camera	B
’	O
s	O
optical	O
center	O
and	O
is	O
independent	O
of	O
(	O
x	O
,	O
y	O
)	O
.	O
4.	O
prove	O
that	O
an	O
image	B
taken	O
by	O
a	O
regular	O
orthographic	B
or	O
perspective	B
camera	O
,	O
i.e.	O
,	O
one	O
that	O
has	O
a	O
linear	B
projective	O
relationship	O
between	O
3d	O
points	B
and	O
(	O
x	O
,	O
y	O
)	O
pixels	O
(	O
2.63	O
)	O
,	O
samples	O
the	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
light	B
ﬁeld	I
along	O
a	O
two-dimensional	B
hyperplane	O
.	O
ex	O
13.8	O
:	O
light	B
ﬁeld	I
and	O
lumigraph	O
rendering	B
implement	O
a	O
light	B
ﬁeld	I
or	O
lumigraph	O
ren-	O
dering	O
system	O
:	O
1.	O
download	O
one	O
of	O
the	O
light	B
ﬁeld	I
data	O
sets	O
from	O
http	O
:	O
//lightﬁeld.stanford.edu/	O
.	O
2.	O
write	O
an	O
algorithm	B
to	O
synthesize	O
a	O
new	O
view	O
from	O
this	O
light	B
ﬁeld	I
,	O
using	O
quadri-linear	O
interpolation	B
of	O
(	O
s	O
,	O
t	O
,	O
u	O
,	O
v	O
)	O
ray	O
samples	O
.	O
3.	O
try	O
varying	O
the	O
focal	O
plane	O
corresponding	O
to	O
your	O
desired	O
view	O
(	O
isaksen	O
,	O
mcmillan	O
,	O
and	O
gortler	O
2000	O
)	O
and	O
see	O
if	O
the	O
resulting	O
image	B
looks	O
sharper	O
.	O
4.	O
determine	O
a	O
3d	O
proxy	O
for	O
the	O
objects	O
in	O
your	O
scene	O
.	O
you	O
can	O
do	O
this	O
by	O
running	O
multi-	O
view	O
stereo	O
over	O
one	O
of	O
your	O
light	O
ﬁelds	O
to	O
obtain	O
a	O
depth	B
map	I
per	O
image	B
.	O
5.	O
implement	O
the	O
lumigraph	O
rendering	B
algorithm	O
,	O
which	O
modiﬁes	O
the	O
sampling	B
of	O
rays	O
according	O
to	O
the	O
3d	O
location	O
of	O
each	O
surface	B
element	O
.	O
6.	O
collect	O
a	O
set	O
of	O
images	O
yourself	O
and	O
determine	O
their	O
pose	O
using	O
structure	O
from	O
motion	B
.	O
13.7	O
exercises	O
653	O
7.	O
implement	O
the	O
unstructured	B
lumigraph	O
rendering	B
algorithm	O
from	O
buehler	O
,	O
bosse	O
,	O
mcmil-	O
lan	O
et	O
al	O
.	O
(	O
2001	O
)	O
.	O
ex	O
13.9	O
:	O
surface	O
light	O
ﬁelds	O
construct	O
a	O
surface	B
light	I
ﬁeld	I
(	O
wood	O
,	O
azuma	O
,	O
aldinger	O
et	O
al	O
.	O
2000	O
)	O
and	O
see	O
how	O
well	O
you	O
can	O
compress	O
it	O
.	O
1.	O
acquire	O
an	O
interesting	O
light	B
ﬁeld	I
of	O
a	O
specular	B
scene	O
or	O
object	O
,	O
or	O
download	O
one	O
from	O
http	O
:	O
//lightﬁeld.stanford.edu/	O
.	O
2.	O
build	O
a	O
3d	O
model	O
of	O
the	O
object	O
using	O
a	O
multi-view	B
stereo	I
algorithm	O
that	O
is	O
robust	B
to	O
outliers	O
due	O
to	O
specularities	B
.	O
3.	O
estimate	O
the	O
lumisphere	O
for	O
each	O
surface	B
point	O
on	O
the	O
object	O
.	O
4.	O
estimate	O
its	O
diffuse	B
components	O
.	O
is	O
the	O
median	B
the	O
best	O
way	O
to	O
do	O
this	O
?	O
why	O
not	O
use	O
the	O
minimum	O
color	O
value	O
?	O
what	O
happens	O
if	O
there	O
is	O
lambertian	O
shading	B
on	O
the	O
diffuse	B
component	O
?	O
5.	O
model	O
and	O
compress	O
the	O
remaining	O
portion	O
of	O
the	O
lumisphere	O
using	O
one	O
of	O
the	O
tech-	O
niques	O
suggested	O
by	O
wood	O
,	O
azuma	O
,	O
aldinger	O
et	O
al	O
.	O
(	O
2000	O
)	O
or	O
invent	O
one	O
of	O
your	O
own	O
.	O
6.	O
study	O
how	O
well	O
your	O
compression	B
algorithm	O
works	O
and	O
what	O
artifacts	O
it	O
produces	O
.	O
7	O
.	O
(	O
optional	O
)	O
develop	O
a	O
system	O
to	O
edit	O
and	O
manipulate	O
your	O
surface	B
light	I
ﬁeld	I
.	O
ex	O
13.10	O
:	O
handheld	O
concentric	O
mosaics	O
develop	O
a	O
system	O
to	O
navigate	O
a	O
handheld	O
con-	O
centric	O
mosaic	O
.	O
1.	O
stand	O
in	O
the	O
middle	O
of	O
a	O
room	O
with	O
a	O
camcorder	O
held	O
at	O
arm	O
’	O
s	O
length	O
in	O
front	O
of	O
you	O
and	O
spin	O
in	O
a	O
circle	O
.	O
2.	O
use	O
a	O
structure	B
from	I
motion	I
system	O
to	O
determine	O
the	O
camera	B
pose	O
and	O
sparse	B
3d	O
struc-	O
ture	O
for	O
each	O
input	O
frame	O
.	O
3	O
.	O
(	O
optional	O
)	O
re-bin	O
your	O
image	B
pixels	O
into	O
a	O
more	O
regular	O
concentric	B
mosaic	I
structure	O
.	O
4.	O
at	O
view	O
time	O
,	O
determine	O
from	O
the	O
new	O
camera	B
’	O
s	O
view	O
(	O
which	O
should	O
be	O
near	O
the	O
plane	O
of	O
your	O
original	O
capture	O
)	O
which	O
source	O
pixels	O
to	O
display	O
.	O
you	O
can	O
simplify	O
your	O
com-	O
putations	O
to	O
determine	O
a	O
source	O
column	O
(	O
and	O
scaling	O
)	O
for	O
each	O
output	O
column	O
.	O
5	O
.	O
(	O
optional	O
)	O
use	O
your	O
sparse	B
3d	O
structure	O
,	O
interpolated	O
to	O
a	O
dense	O
depth	O
map	O
,	O
to	O
improve	O
your	O
rendering	B
(	O
zheng	O
,	O
kang	O
,	O
cohen	O
et	O
al	O
.	O
2007	O
)	O
.	O
654	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ex	O
13.11	O
:	O
video	B
textures	I
capture	O
some	O
videos	O
of	O
natural	B
phenomena	O
,	O
such	O
as	O
a	O
water	O
fountain	O
,	O
ﬁre	O
,	O
or	O
smiling	O
face	B
,	O
and	O
loop	O
the	O
video	B
seamlessly	O
into	O
an	O
inﬁnite	O
length	O
video	B
(	O
sch¨odl	O
,	O
szeliski	O
,	O
salesin	O
et	O
al	O
.	O
2000	O
)	O
.	O
1.	O
compare	O
all	O
the	O
frames	O
in	O
the	O
original	O
clip	O
using	O
an	O
l2	O
(	O
sum	O
of	O
square	O
difference	O
)	O
metric	O
.	O
(	O
this	O
assumes	O
the	O
videos	O
were	O
shot	O
on	O
a	O
tripod	O
or	O
have	O
already	O
been	O
stabilized	O
.	O
)	O
2.	O
filter	O
the	O
comparison	O
table	O
temporally	O
to	O
accentuate	O
temporal	O
sub-sequences	O
that	O
match	O
well	O
together	O
.	O
3.	O
convert	O
your	O
similarity	B
table	O
into	O
a	O
jump	O
probability	O
table	O
through	O
some	O
exponential	O
distribution	O
.	O
be	O
sure	O
to	O
modify	O
transitions	O
near	O
the	O
end	O
so	O
you	O
do	O
not	O
get	O
“	O
stuck	O
”	O
in	O
the	O
last	O
frame	O
.	O
4.	O
starting	O
with	O
the	O
ﬁrst	O
frame	O
,	O
use	O
your	O
transition	O
table	O
to	O
decide	O
whether	O
to	O
jump	O
for-	O
ward	O
,	O
backward	O
,	O
or	O
continue	O
to	O
the	O
next	O
frame	O
.	O
5	O
.	O
(	O
optional	O
)	O
add	O
any	O
of	O
the	O
other	O
extensions	O
to	O
the	O
original	O
video	B
textures	I
idea	O
,	O
such	O
as	O
multiple	B
moving	O
regions	O
,	O
interactive	B
control	O
,	O
or	O
graph	B
cut	I
spatio-temporal	O
texture	B
seaming	O
.	O
chapter	O
14	O
recognition	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
658	O
.	O
658	O
.	O
666	O
.	O
668	O
.	O
671	O
.	O
679	O
.	O
684	O
.	O
685	O
.	O
686	O
.	O
687	O
.	O
693	O
.	O
696	O
.	O
697	O
.	O
701	O
.	O
704	O
.	O
709	O
.	O
712	O
.	O
714	O
.	O
717	O
.	O
718	O
.	O
722	O
.	O
725	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.1	O
object	O
detection	B
.	O
14.3	O
instance	B
recognition	O
.	O
.	O
.	O
14.1.1	O
face	B
detection	O
.	O
.	O
14.1.2	O
pedestrian	B
detection	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.2	O
face	B
recognition	O
.	O
14.2.1	O
eigenfaces	O
.	O
14.2.2	O
active	O
appearance	O
and	O
3d	O
shape	O
models	O
.	O
14.2.3	O
application	O
:	O
personal	O
photo	O
collections	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.4	O
category	O
recognition	O
.	O
.	O
.	O
.	O
14.4.1	O
bag	B
of	I
words	I
.	O
.	O
14.4.2	O
part-based	B
models	O
.	O
14.4.3	O
recognition	B
with	O
segmentation	B
.	O
.	O
14.4.4	O
application	O
:	O
intelligent	B
photo	I
editing	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.3.1	O
geometric	B
alignment	I
.	O
.	O
14.3.2	O
large	O
databases	O
.	O
.	O
.	O
14.3.3	O
application	O
:	O
location	B
recognition	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14.5	O
context	B
and	O
scene	B
understanding	I
.	O
.	O
14.5.1	O
learning	B
and	O
large	O
image	O
collections	O
14.5.2	O
application	O
:	O
image	B
search	I
.	O
.	O
.	O
14.6	O
recognition	B
databases	O
and	O
test	O
sets	O
.	O
14.7	O
additional	O
reading	O
.	O
.	O
.	O
.	O
.	O
.	O
14.8	O
exercises	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
656	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
d	O
)	O
(	O
g	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
e	O
)	O
(	O
h	O
)	O
(	O
f	O
)	O
(	O
i	O
)	O
figure	O
14.1	O
recognition	B
:	O
face	B
recognition	O
with	O
(	O
a	O
)	O
pictorial	O
structures	O
(	O
fischler	O
and	O
elschlager	O
1973	O
)	O
c	O
(	O
cid:13	O
)	O
1973	O
ieee	O
and	O
(	O
b	O
)	O
eigenfaces	O
(	O
turk	O
and	O
pentland	O
1991b	O
)	O
;	O
(	O
c	O
)	O
real-	O
time	O
face	O
detection	B
(	O
viola	O
and	O
jones	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
;	O
(	O
d	O
)	O
instance	B
(	O
known	O
object	O
)	O
recognition	B
(	O
lowe	O
1999	O
)	O
c	O
(	O
cid:13	O
)	O
1999	O
ieee	O
;	O
(	O
e	O
)	O
feature-based	B
recognition	O
(	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2007	O
)	O
;	O
(	O
f	O
)	O
region-based	B
recognition	O
(	O
mori	O
,	O
ren	O
,	O
efros	O
et	O
al	O
.	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
ieee	O
;	O
(	O
g	O
)	O
simultaneous	O
recognition	B
and	O
segmentation	B
(	O
shotton	O
,	O
winn	O
,	O
rother	O
et	O
al	O
.	O
2009	O
)	O
c	O
(	O
cid:13	O
)	O
2009	O
springer	O
;	O
(	O
h	O
)	O
location	B
recognition	I
(	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
ieee	O
;	O
(	O
i	O
)	O
using	O
context	O
(	O
russell	O
,	O
torralba	O
,	O
liu	O
et	O
al	O
.	O
2007	O
)	O
.	O
14	O
recognition	B
657	O
of	O
all	O
the	O
visual	O
tasks	O
we	O
might	O
ask	O
a	O
computer	O
to	O
perform	O
,	O
analyzing	O
a	O
scene	O
and	O
recog-	O
nizing	O
all	O
of	O
the	O
constituent	O
objects	O
remains	O
the	O
most	O
challenging	O
.	O
while	O
computers	O
excel	O
at	O
accurately	O
reconstructing	O
the	O
3d	O
shape	O
of	O
a	O
scene	O
from	O
images	O
taken	O
from	O
different	O
views	O
,	O
they	O
can	O
not	O
name	O
all	O
the	O
objects	O
and	O
animals	O
present	O
in	O
a	O
picture	O
,	O
even	O
at	O
the	O
level	O
of	O
a	O
two-	O
year-old	O
child	O
.	O
there	O
is	O
not	O
even	O
any	O
consensus	O
among	O
researchers	O
on	O
when	O
this	O
level	O
of	O
performance	O
might	O
be	O
achieved	O
.	O
why	O
is	O
recognition	B
so	O
hard	O
?	O
the	O
real	O
world	O
is	O
made	O
of	O
a	O
jumble	O
of	O
objects	O
,	O
which	O
all	O
oc-	O
clude	O
one	O
another	O
and	O
appear	O
in	O
different	O
poses	O
.	O
furthermore	O
,	O
the	O
variability	O
intrinsic	B
within	O
a	O
class	O
(	O
e.g.	O
,	O
dogs	O
)	O
,	O
due	O
to	O
complex	O
non-rigid	B
articulation	O
and	O
extreme	O
variations	O
in	O
shape	O
and	O
appearance	O
(	O
e.g.	O
,	O
between	O
different	O
breeds	O
)	O
,	O
makes	O
it	O
unlikely	O
that	O
we	O
can	O
simply	O
perform	O
exhaustive	O
matching	B
against	O
a	O
database	O
of	O
exemplars.1	O
the	O
recognition	B
problem	O
can	O
be	O
broken	O
down	O
along	O
several	O
axes	O
.	O
for	O
example	O
,	O
if	O
we	O
know	O
what	O
we	O
are	O
looking	O
for	O
,	O
the	O
problem	O
is	O
one	O
of	O
object	O
detection	B
(	O
section	O
14.1	O
)	O
,	O
which	O
involves	O
quickly	O
scanning	O
an	O
image	B
to	O
determine	O
where	O
a	O
match	O
may	O
occur	O
(	O
figure	O
14.1c	O
)	O
.	O
if	O
we	O
have	O
a	O
speciﬁc	O
rigid	O
object	O
we	O
are	O
trying	O
to	O
recognize	O
(	O
instance	B
recognition	O
,	O
section	O
14.3	O
)	O
,	O
we	O
can	O
search	O
for	O
characteristic	O
feature	B
points	O
(	O
section	O
4.1	O
)	O
and	O
verify	O
that	O
they	O
align	O
in	O
a	O
geometrically	O
plausible	O
way	O
(	O
section	O
14.3.1	O
)	O
(	O
figure	O
14.1d	O
)	O
.	O
the	O
most	O
challenging	O
version	O
of	O
recognition	B
is	O
general	O
category	O
(	O
or	O
class	O
)	O
recognition	B
(	O
section	O
14.4	O
)	O
,	O
which	O
may	O
involve	O
recognizing	O
instances	O
of	O
extremely	O
varied	O
classes	O
such	O
as	O
animals	O
or	O
furniture	O
.	O
some	O
techniques	O
rely	O
purely	O
on	O
the	O
presence	O
of	O
features	O
(	O
known	O
as	O
a	O
“	O
bag	B
of	I
words	I
”	O
model—see	O
section	O
14.4.1	O
)	O
,	O
their	O
relative	O
positions	O
(	O
part-based	B
models	O
(	O
section	O
14.4.2	O
)	O
)	O
,	O
figure	O
14.1e	O
,	O
while	O
others	O
involve	O
segmenting	O
the	O
image	B
into	O
semantically	O
meaningful	O
regions	O
(	O
section	O
14.4.3	O
)	O
(	O
figure	O
14.1f	O
)	O
.	O
in	O
many	O
instances	O
,	O
recognition	B
depends	O
heavily	O
on	O
the	O
context	B
of	O
surrounding	O
objects	O
and	O
scene	O
elements	O
(	O
section	O
14.5	O
)	O
.	O
woven	O
into	O
all	O
of	O
these	O
techniques	O
is	O
the	O
topic	O
of	O
learning	B
(	O
section	O
14.5.1	O
)	O
,	O
since	O
hand-crafting	O
speciﬁc	O
object	O
recognizers	O
seems	O
like	O
a	O
futile	O
approach	O
given	O
the	O
complexity	O
of	O
the	O
problem	O
.	O
given	O
the	O
extremely	O
rich	O
and	O
complex	O
nature	O
of	O
this	O
topic	O
,	O
this	O
chapter	O
is	O
structured	O
to	O
build	O
from	O
simpler	O
concepts	O
to	O
more	O
complex	O
ones	O
.	O
we	O
begin	O
with	O
a	O
discussion	O
of	O
face	B
and	O
object	O
detection	B
(	O
section	O
14.1	O
)	O
,	O
where	O
we	O
introduce	O
a	O
number	O
of	O
machine-learning	O
techniques	O
such	O
as	O
boosting	B
,	O
neural	B
networks	I
,	O
and	O
support	B
vector	I
machines	I
.	O
next	O
,	O
we	O
study	O
face	B
recogni-	O
tion	B
(	O
section	O
14.2	O
)	O
,	O
which	O
is	O
one	O
of	O
the	O
more	O
widely	O
known	O
applications	O
of	O
recognition	B
.	O
this	O
topic	O
serves	O
as	O
an	O
introduction	O
to	O
subspace	O
(	O
pca	O
)	O
models	O
and	O
bayesian	O
approaches	O
to	O
recog-	O
nition	O
and	O
classiﬁcation	O
.	O
we	O
then	O
present	O
techniques	O
for	O
instance	O
recognition	B
(	O
section	O
14.3	O
)	O
,	O
building	O
upon	O
earlier	O
topics	O
in	O
this	O
book	O
,	O
such	O
as	O
feature	B
detection	O
,	O
matching	B
,	O
and	O
geomet-	O
ric	O
alignment	B
(	O
section	O
14.3.1	O
)	O
.	O
we	O
introduce	O
topics	O
from	O
the	O
information	O
and	O
document	O
re-	O
trieval	O
communities	O
,	O
such	O
as	O
frequency	O
vectors	O
,	O
feature	B
quantization	O
,	O
and	O
inverted	O
indices	O
1	O
however	O
,	O
some	O
recent	O
research	O
suggests	O
that	O
direct	B
image	O
matching	B
may	O
be	O
feasible	O
for	O
large	O
enough	O
databases	O
(	O
russell	O
,	O
torralba	O
,	O
liu	O
et	O
al	O
.	O
2007	O
;	O
malisiewicz	O
and	O
efros	O
2008	O
;	O
torralba	O
,	O
freeman	O
,	O
and	O
fergus	O
2008	O
)	O
.	O
658	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
section	O
14.3.2	O
)	O
.	O
we	O
also	O
present	O
applications	O
of	O
location	B
recognition	I
(	O
section	O
14.3.3	O
)	O
.	O
in	O
the	O
second	O
half	O
of	O
the	O
chapter	O
,	O
we	O
address	O
the	O
most	O
challenging	O
variant	O
of	O
recognition	B
,	O
namely	O
the	O
problem	O
of	O
category	O
recognition	O
(	O
section	O
14.4	O
)	O
.	O
this	O
includes	O
approaches	O
that	O
use	O
bags	O
of	O
features	O
(	O
section	O
14.4.1	O
)	O
,	O
parts	O
(	O
section	O
14.4.2	O
)	O
,	O
and	O
segmentation	B
(	O
section	O
14.4.3	O
)	O
.	O
we	O
show	O
how	O
such	O
techniques	O
can	O
be	O
used	O
to	O
automate	O
photo	O
editing	O
tasks	O
,	O
such	O
as	O
3d	O
mod-	O
eling	O
,	O
scene	B
completion	I
,	O
and	O
creating	O
collages	O
(	O
section	O
14.4.4	O
)	O
.	O
next	O
,	O
we	O
discuss	O
the	O
role	O
that	O
context	B
can	O
play	O
in	O
both	O
individual	O
object	O
recognition	B
and	O
more	O
holistic	O
scene	O
under-	O
standing	O
(	O
section	O
14.5	O
)	O
.	O
we	O
close	O
this	O
chapter	O
with	O
a	O
discussion	O
of	O
databases	O
and	O
test	O
sets	O
for	O
constructing	O
and	O
evaluating	O
recognition	B
systems	O
(	O
section	O
14.6	O
)	O
.	O
while	O
there	O
is	O
no	O
comprehensive	O
reference	O
on	O
object	O
recognition	B
,	O
an	O
excellent	O
set	O
of	O
notes	O
can	O
be	O
found	O
in	O
the	O
iccv	O
2009	O
short	O
course	O
(	O
fei-fei	O
,	O
fergus	O
,	O
and	O
torralba	O
2009	O
)	O
,	O
antonio	O
torralba	O
’	O
s	O
more	O
comprehensive	O
mit	O
course	O
(	O
torralba	O
2008	O
)	O
,	O
and	O
two	O
recent	O
collections	O
of	O
papers	O
(	O
ponce	O
,	O
hebert	O
,	O
schmid	O
et	O
al	O
.	O
2006	O
;	O
dickinson	O
,	O
leonardis	O
,	O
schiele	O
et	O
al	O
.	O
2007	O
)	O
and	O
a	O
survey	O
on	O
object	O
categorization	O
(	O
pinz	O
2005	O
)	O
.	O
an	O
evaluation	B
of	O
some	O
of	O
the	O
best	O
performing	O
recognition	B
algorithms	O
can	O
be	O
found	O
on	O
the	O
pascal	O
visual	O
object	O
classes	O
(	O
voc	O
)	O
challenge	O
web	O
site	O
at	O
http	O
:	O
//pascallin.ecs.soton.ac.uk/challenges/voc/	O
.	O
14.1	O
object	O
detection	B
if	O
we	O
are	O
given	O
an	O
image	B
to	O
analyze	O
,	O
such	O
as	O
the	O
group	O
portrait	O
in	O
figure	O
14.2	O
,	O
we	O
could	O
try	O
to	O
apply	O
a	O
recognition	B
algorithm	O
to	O
every	O
possible	O
sub-window	O
in	O
this	O
image	B
.	O
such	O
algorithms	O
are	O
likely	O
to	O
be	O
both	O
slow	O
and	O
error-prone	O
.	O
instead	O
,	O
it	O
is	O
more	O
effective	O
to	O
construct	O
special-	O
purpose	O
detectors	O
,	O
whose	O
job	O
it	O
is	O
to	O
rapidly	O
ﬁnd	O
likely	O
regions	O
where	O
particular	O
objects	O
might	O
occur	O
.	O
we	O
begin	O
this	O
section	O
with	O
face	O
detectors	O
,	O
which	O
are	O
some	O
of	O
the	O
more	O
successful	O
examples	B
of	O
recognition	B
.	O
for	O
example	O
,	O
such	O
algorithms	O
are	O
built	O
into	O
most	O
of	O
today	O
’	O
s	O
digital	O
cameras	O
to	O
enhance	O
auto-focus	O
and	O
into	O
video	B
conferencing	O
systems	O
to	O
control	O
pan-tilt	O
heads	O
.	O
we	O
then	O
look	O
at	O
pedestrian	B
detectors	O
,	O
as	O
an	O
example	O
of	O
more	O
general	O
methods	O
for	O
object	O
detection	B
.	O
such	O
detectors	O
can	O
be	O
used	O
in	O
automotive	B
safety	I
applications	O
,	O
e.g.	O
,	O
detecting	O
pedestrians	O
and	O
other	O
cars	O
from	O
moving	O
vehicles	O
(	O
leibe	O
,	O
cornelis	O
,	O
cornelis	O
et	O
al	O
.	O
2007	O
)	O
.	O
14.1.1	O
face	B
detection	O
before	O
face	B
recognition	O
can	O
be	O
applied	O
to	O
a	O
general	O
image	B
,	O
the	O
locations	O
and	O
sizes	O
of	O
any	O
faces	B
must	O
ﬁrst	O
be	O
found	O
(	O
figures	O
14.1c	O
and	O
14.2	O
)	O
.	O
in	O
principle	O
,	O
we	O
could	O
apply	O
a	O
face	B
recognition	O
algorithm	B
at	O
every	O
pixel	O
and	O
scale	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
but	O
such	O
a	O
process	O
would	O
be	O
too	O
slow	O
in	O
practice	O
.	O
14.1	O
object	O
detection	B
659	O
figure	O
14.2	O
face	B
detection	O
results	O
produced	O
by	O
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
(	O
1998a	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
ieee	O
.	O
can	O
you	O
ﬁnd	O
the	O
one	O
false	O
positive	O
(	O
a	O
box	O
around	O
a	O
non-face	O
)	O
among	O
the	O
57	O
true	O
positive	O
results	O
?	O
over	O
the	O
years	O
,	O
a	O
wide	O
variety	O
of	O
fast	O
face	O
detection	B
algorithms	O
have	O
been	O
developed	O
.	O
yang	O
,	O
kriegman	O
,	O
and	O
ahuja	O
(	O
2002	O
)	O
provide	O
a	O
comprehensive	O
survey	O
of	O
earlier	O
work	O
in	O
this	O
ﬁeld	O
;	O
yang	O
’	O
s	O
icpr	O
2004	O
tutorial2	O
and	O
the	O
torralba	O
(	O
2007	O
)	O
short	O
course	O
provide	O
more	O
recent	O
reviews.3	O
according	O
to	O
the	O
taxonomy	B
of	O
yang	O
,	O
kriegman	O
,	O
and	O
ahuja	O
(	O
2002	O
)	O
,	O
face	B
detection	O
tech-	O
niques	O
can	O
be	O
classiﬁed	O
as	O
feature-based	B
,	O
template-based	O
,	O
or	O
appearance-based	O
.	O
feature-	O
based	O
techniques	O
attempt	O
to	O
ﬁnd	O
the	O
locations	O
of	O
distinctive	O
image	B
features	O
such	O
as	O
the	O
eyes	O
,	O
nose	O
,	O
and	O
mouth	O
,	O
and	O
then	O
verify	O
whether	O
these	O
features	O
are	O
in	O
a	O
plausible	O
geometrical	O
ar-	O
rangement	O
.	O
these	O
techniques	O
include	O
some	O
of	O
the	O
early	O
approaches	O
to	O
face	B
recognition	O
(	O
fis-	O
chler	O
and	O
elschlager	O
1973	O
;	O
kanade	O
1977	O
;	O
yuille	O
1991	O
)	O
,	O
as	O
well	O
as	O
more	O
recent	O
approaches	O
based	O
on	O
modular	O
eigenspaces	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
,	O
local	B
ﬁlter	O
jets	O
(	O
leung	O
,	O
burl	O
,	O
and	O
perona	O
1995	O
;	O
penev	O
and	O
atick	O
1996	O
;	O
wiskott	O
,	O
fellous	O
,	O
kr¨uger	O
et	O
al	O
.	O
1997	O
)	O
,	O
support	B
vector	I
machines	I
(	O
heisele	O
,	O
ho	O
,	O
wu	O
et	O
al	O
.	O
2003	O
;	O
heisele	O
,	O
serre	O
,	O
and	O
poggio	O
2007	O
)	O
,	O
and	O
boosting	B
(	O
schneiderman	O
and	O
kanade	O
2004	O
)	O
.	O
template-based	O
approaches	O
,	O
such	O
as	O
active	O
appearance	O
models	O
(	O
aams	O
)	O
(	O
section	O
14.2.2	O
)	O
,	O
can	O
deal	O
with	O
a	O
wide	O
range	O
of	O
pose	O
and	O
expression	O
variability	O
.	O
typically	O
,	O
they	O
require	O
good	O
initialization	B
near	O
a	O
real	O
face	B
and	O
are	O
therefore	O
not	O
suitable	O
as	O
fast	O
face	O
detectors	O
.	O
2	O
http	O
:	O
//vision.ai.uiuc.edu/mhyang/face-detection-survey.html	O
.	O
3	O
an	O
alternative	O
approach	O
to	O
detecting	O
faces	B
is	O
to	O
look	O
for	O
regions	O
of	O
skin	O
color	B
in	O
the	O
image	B
(	O
forsyth	O
and	O
fleck	O
1999	O
;	O
jones	O
and	O
rehg	O
2001	O
)	O
.	O
see	O
exercise	O
2.8	O
for	O
some	O
additional	O
discussion	O
and	O
references	B
.	O
660	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
14.3	O
pre-processing	O
stages	O
for	O
face	O
detector	O
training	O
(	O
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
1998a	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
ieee	O
:	O
(	O
a	O
)	O
artiﬁcially	O
mirroring	O
,	O
rotating	O
,	O
scaling	O
,	O
and	O
translating	O
training	O
images	O
for	O
greater	O
variability	O
;	O
(	O
b	O
)	O
using	O
images	O
without	O
faces	B
(	O
looking	O
up	O
at	O
a	O
tree	O
)	O
to	O
generate	O
non-face	O
examples	B
;	O
(	O
c	O
)	O
pre-processing	O
the	O
patches	O
by	O
subtracting	O
a	O
best	O
ﬁt	O
linear	B
function	O
(	O
constant	O
gradient	O
)	O
and	O
histogram	B
equalizing	O
.	O
appearance-based	O
approaches	O
scan	O
over	O
small	O
overlapping	O
rectangular	O
patches	O
of	O
the	O
im-	O
age	O
searching	O
for	O
likely	O
face	B
candidates	O
,	O
which	O
can	O
then	O
be	O
reﬁned	O
using	O
a	O
cascade	O
of	O
more	O
expensive	O
but	O
selective	O
detection	B
algorithms	O
(	O
sung	O
and	O
poggio	O
1998	O
;	O
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
1998a	O
;	O
romdhani	O
,	O
torr	O
,	O
sch¨olkopf	O
et	O
al	O
.	O
2001	O
;	O
fleuret	O
and	O
geman	O
2001	O
;	O
viola	O
and	O
jones	O
2004	O
)	O
.	O
in	O
order	B
to	O
deal	O
with	O
scale	O
variation	O
,	O
the	O
image	B
is	O
usually	O
converted	O
into	O
a	O
sub-octave	O
pyramid	B
and	O
a	O
separate	O
scan	O
is	O
performed	O
on	O
each	O
level	O
.	O
most	O
appearance-based	O
approaches	O
today	O
rely	O
heavily	O
on	O
training	O
classiﬁers	O
using	O
sets	O
of	O
labeled	O
face	B
and	O
non-face	O
patches	O
.	O
sung	O
and	O
poggio	O
(	O
1998	O
)	O
and	O
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
(	O
1998a	O
)	O
present	O
two	O
of	O
the	O
ear-	O
liest	O
appearance-based	O
face	B
detectors	O
and	O
introduce	O
a	O
number	O
of	O
innovations	O
that	O
are	O
widely	O
used	O
in	O
later	O
work	O
by	O
others	O
.	O
to	O
start	O
with	O
,	O
both	O
systems	O
collect	O
a	O
set	O
of	O
labeled	O
face	B
patches	O
(	O
figure	O
14.2	O
)	O
as	O
well	O
as	O
a	O
set	O
of	O
patches	O
taken	O
from	O
images	O
that	O
are	O
known	O
not	O
to	O
contain	O
faces	B
,	O
such	O
as	O
aerial	O
images	O
or	O
vegetation	O
(	O
figure	O
14.3b	O
)	O
.	O
the	O
collected	O
face	B
images	O
are	O
augmented	O
by	O
artiﬁcially	O
mirroring	O
,	O
rotating	O
,	O
scaling	O
,	O
and	O
translating	O
the	O
images	O
by	O
small	O
amounts	O
to	O
make	O
the	O
face	B
detectors	O
less	O
sensitive	O
to	O
such	O
effects	O
(	O
figure	O
14.3a	O
)	O
.	O
after	O
an	O
initial	O
set	O
of	O
training	O
images	O
has	O
been	O
collected	O
,	O
some	O
optional	O
pre-processing	O
can	O
be	O
performed	O
,	O
such	O
as	O
subtracting	O
an	O
average	O
gradient	O
(	O
linear	B
function	O
)	O
from	O
the	O
image	B
to	O
compensate	O
for	O
global	O
shading	B
effects	O
and	O
using	O
histogram	O
equalization	O
to	O
compensate	O
for	O
varying	O
camera	B
contrast	O
(	O
figure	O
14.3c	O
)	O
.	O
14.1	O
object	O
detection	B
661	O
figure	O
14.4	O
learning	B
a	O
mixture	O
of	O
gaussians	O
model	O
for	O
face	O
detection	B
(	O
sung	O
and	O
poggio	O
1998	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
ieee	O
.	O
the	O
face	B
and	O
non-face	O
images	O
(	O
192-long	O
vectors	O
)	O
are	O
ﬁrst	O
clustered	O
into	O
six	O
separate	O
clusters	O
(	O
each	O
)	O
using	O
k-means	O
and	O
then	O
analyzed	O
using	O
pca	O
.	O
the	O
cluster	O
centers	O
are	O
shown	O
in	O
the	O
right-hand	O
columns	O
.	O
clustering	O
and	O
pca	O
.	O
once	O
the	O
face	B
and	O
non-face	O
patterns	B
have	O
been	O
pre-processed	O
,	O
sung	O
and	O
poggio	O
(	O
1998	O
)	O
cluster	O
each	O
of	O
these	O
datasets	O
into	O
six	O
separate	O
clusters	O
using	O
k-means	O
and	O
then	O
ﬁt	O
pca	O
subspaces	O
to	O
each	O
of	O
the	O
resulting	O
12	O
clusters	O
(	O
figure	O
14.4	O
)	O
.	O
at	O
detection	B
time	O
,	O
the	O
difs	O
and	O
dffs	O
metrics	O
ﬁrst	O
developed	O
by	O
moghaddam	O
and	O
pentland	O
(	O
1997	O
)	O
(	O
see	O
figure	O
14.14	O
and	O
(	O
14.14	O
)	O
)	O
are	O
used	O
to	O
produce	O
24	O
mahalanobis	O
distance	O
measurements	O
(	O
two	O
per	O
cluster	O
)	O
.	O
the	O
resulting	O
24	O
measurements	O
are	O
input	O
to	O
a	O
multi-layer	O
perceptron	O
(	O
mlp	O
)	O
,	O
which	O
is	O
a	O
neural	O
network	O
with	O
alternating	O
layers	B
of	O
weighted	B
summations	O
and	O
sigmoidal	O
non-	O
linearities	O
trained	O
using	O
the	O
“	O
backpropagation	O
”	O
algorithm	B
(	O
rumelhart	O
,	O
hinton	O
,	O
and	O
williams	O
1986	O
)	O
.	O
neural	B
networks	I
.	O
instead	O
of	O
ﬁrst	O
clustering	O
the	O
data	O
and	O
computing	O
mahalanobis	O
distances	O
to	O
the	O
cluster	O
centers	O
,	O
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
(	O
1998a	O
)	O
apply	O
a	O
neural	O
network	O
(	O
mlp	O
)	O
di-	O
rectly	O
to	O
the	O
20×	O
20	O
pixel	O
patches	O
of	O
gray-level	O
intensities	O
,	O
using	O
a	O
variety	O
of	O
differently	O
sized	O
hand-crafted	O
“	O
receptive	O
ﬁelds	O
”	O
to	O
capture	O
both	O
large-scale	O
and	O
smaller	O
scale	O
structure	O
(	O
fig-	O
ure	O
14.5	O
)	O
.	O
the	O
resulting	O
neural	O
network	O
directly	O
outputs	O
the	O
likelihood	O
of	O
a	O
face	B
at	O
the	O
center	O
662	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.5	O
a	O
neural	O
network	O
for	O
face	O
detection	B
(	O
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
1998a	O
)	O
c	O
(	O
cid:13	O
)	O
1998	O
ieee	O
.	O
overlapping	O
patches	O
are	O
extracted	O
from	O
different	O
levels	O
of	O
a	O
pyramid	B
and	O
then	O
pre-processed	O
as	O
shown	O
in	O
figure	O
14.3b	O
.	O
a	O
three-layer	O
neural	O
network	O
is	O
then	O
used	O
to	O
detect	O
likely	O
face	B
locations	O
.	O
of	O
every	O
overlapping	O
patch	B
in	O
a	O
multi-resolution	O
pyramid	B
.	O
since	O
several	O
overlapping	O
patches	O
(	O
in	O
both	O
space	O
and	O
resolution	O
)	O
may	O
ﬁre	O
near	O
a	O
face	B
,	O
an	O
additional	O
merging	B
network	O
is	O
used	O
to	O
merge	O
overlapping	O
detections	O
.	O
the	O
authors	O
also	O
experiment	O
with	O
training	O
several	O
networks	O
and	O
merging	B
their	O
outputs	O
.	O
figure	O
14.2	O
shows	O
a	O
sample	O
result	O
from	O
their	O
face	B
detector	O
.	O
to	O
make	O
the	O
detector	O
run	O
faster	O
,	O
a	O
separate	O
network	O
operating	O
on	O
30×30	O
patches	O
is	O
trained	O
to	O
detect	O
both	O
faces	B
and	O
faces	B
shifted	O
by	O
±5	O
pixels	O
.	O
this	O
network	O
is	O
evaluated	O
at	O
every	O
10th	O
pixel	O
in	O
the	O
image	B
(	O
horizontally	O
and	O
vertically	O
)	O
and	O
the	O
results	O
of	O
this	O
“	O
coarse	O
”	O
or	O
“	O
sloppy	O
”	O
detector	O
are	O
used	O
to	O
select	O
regions	O
on	O
which	O
to	O
run	O
the	O
slower	O
single-pixel	O
overlap	O
technique	O
.	O
to	O
deal	O
with	O
in-plane	O
rotations	O
of	O
faces	B
,	O
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
(	O
1998b	O
)	O
train	O
a	O
router	O
network	O
to	O
estimate	O
likely	O
rotation	O
angles	O
from	O
input	O
patches	O
and	O
then	O
apply	O
the	O
estimated	O
rotation	O
to	O
each	O
patch	B
before	O
running	O
the	O
result	O
through	O
their	O
upright	O
face	B
detector	O
.	O
support	B
vector	I
machines	I
.	O
instead	O
of	O
using	O
a	O
neural	O
network	O
to	O
classify	O
patches	O
,	O
osuna	O
,	O
freund	O
,	O
and	O
girosi	O
(	O
1997	O
)	O
use	O
a	O
support	O
vector	O
machine	O
(	O
svm	O
)	O
(	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
sch¨olkopf	O
and	O
smola	O
2002	O
;	O
bishop	O
2006	O
;	O
lampert	O
2008	O
)	O
to	O
classify	O
the	O
same	O
preprocessed	O
patches	O
as	O
sung	O
and	O
poggio	O
(	O
1998	O
)	O
.	O
an	O
svm	O
searches	O
for	O
a	O
series	O
of	O
maximum	O
margin	O
separating	O
planes	B
in	O
feature	B
space	O
between	O
different	O
classes	O
(	O
in	O
this	O
case	O
,	O
face	B
and	O
non-face	O
patches	O
)	O
.	O
in	O
those	O
cases	O
where	O
linear	B
classiﬁcation	O
boundaries	O
are	O
insufﬁcient	O
,	O
the	O
feature	B
space	O
can	O
be	O
lifted	O
into	O
higher-dimensional	O
features	O
using	O
kernels	O
(	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
sch¨olkopf	O
and	O
smola	O
2002	O
;	O
bishop	O
2006	O
)	O
.	O
svms	O
have	O
been	O
used	O
by	O
other	O
researchers	O
for	O
both	O
face	B
detection	O
and	O
face	B
recognition	O
(	O
heisele	O
,	O
ho	O
,	O
wu	O
et	O
al	O
.	O
2003	O
;	O
14.1	O
object	O
detection	B
663	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.6	O
simple	O
features	O
used	O
in	O
boosting-based	O
face	B
detector	O
(	O
viola	O
and	O
jones	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
:	O
(	O
a	O
)	O
difference	B
of	O
rectangle	O
feature	B
composed	O
of	O
2–4	O
different	O
rectangles	O
(	O
pixels	O
inside	O
the	O
white	O
rectangles	O
are	O
subtracted	O
from	O
the	O
gray	O
ones	O
)	O
;	O
(	O
b	O
)	O
the	O
ﬁrst	O
and	O
second	O
features	O
selected	O
by	O
adaboost	O
.	O
the	O
ﬁrst	O
feature	B
measures	O
the	O
differences	O
in	O
intensity	O
between	O
the	O
eyes	O
and	O
the	O
cheeks	O
,	O
the	O
second	O
one	O
between	O
the	O
eyes	O
and	O
the	O
bridge	O
of	O
the	O
nose	O
.	O
heisele	O
,	O
serre	O
,	O
and	O
poggio	O
2007	O
)	O
and	O
are	O
a	O
widely	O
used	O
tool	O
in	O
object	O
recognition	B
in	O
general	O
.	O
boosting	B
.	O
of	O
all	O
the	O
face	B
detectors	O
currently	O
in	O
use	O
,	O
the	O
one	O
introduced	O
by	O
viola	O
and	O
jones	O
(	O
2004	O
)	O
is	O
probably	O
the	O
best	O
known	O
and	O
most	O
widely	O
used	O
.	O
their	O
technique	O
was	O
the	O
ﬁrst	O
to	O
introduce	O
the	O
concept	O
of	O
boosting	B
to	O
the	O
computer	O
vision	O
community	O
,	O
which	O
involves	O
train-	O
ing	O
a	O
series	O
of	O
increasingly	O
discriminating	O
simple	O
classiﬁers	O
and	O
then	O
blending	B
their	O
outputs	O
(	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
bishop	O
2006	O
)	O
.	O
in	O
more	O
detail	O
,	O
boosting	B
involves	O
constructing	O
a	O
classiﬁer	O
h	O
(	O
x	O
)	O
as	O
a	O
sum	O
of	O
simple	O
weak	O
learners	O
,	O
where	O
each	O
of	O
the	O
weak	O
learners	O
hj	O
(	O
x	O
)	O
is	O
an	O
extremely	O
simple	O
function	O
of	O
the	O
input	O
,	O
and	O
hence	O
is	O
not	O
expected	O
to	O
contribute	O
much	O
(	O
in	O
isolation	O
)	O
to	O
the	O
classiﬁcation	O
performance	O
.	O
in	O
most	O
variants	O
of	O
boosting	B
,	O
the	O
weak	O
learners	O
are	O
threshold	O
functions	O
,	O
hj	O
(	O
x	O
)	O
=	O
aj	O
[	O
fj	O
<	O
θj	O
]	O
+	O
bj	O
[	O
fj	O
≥	O
θj	O
]	O
=	O
(	O
cid:40	O
)	O
aj	O
bj	O
if	O
fj	O
<	O
θj	O
otherwise	O
,	O
(	O
14.2	O
)	O
which	O
are	O
also	O
known	O
as	O
decision	O
stumps	O
(	O
basically	O
,	O
the	O
simplest	O
possible	O
version	O
of	O
decision	O
trees	O
)	O
.	O
in	O
most	O
cases	O
,	O
it	O
is	O
also	O
traditional	O
(	O
and	O
simpler	O
)	O
to	O
set	O
aj	O
and	O
bj	O
to	O
±1	O
,	O
i.e.	O
,	O
aj	O
=	O
−sj	O
,	O
bj	O
=	O
+sj	O
,	O
so	O
that	O
only	O
the	O
feature	B
fj	O
,	O
the	O
threshold	O
value	O
θj	O
,	O
and	O
the	O
polarity	O
of	O
the	O
threshold	O
sj	O
∈	O
±1	O
need	O
to	O
be	O
selected.4	O
4some	O
variants	O
,	O
such	O
as	O
that	O
of	O
viola	O
and	O
jones	O
(	O
2004	O
)	O
,	O
use	O
(	O
aj	O
,	O
bj	O
)	O
∈	O
[	O
0	O
,	O
1	O
]	O
and	O
adjust	O
the	O
learning	B
algorithm	O
h	O
(	O
x	O
)	O
=	O
sign	O
m−1	O
(	O
cid:88	O
)	O
j=0	O
αjhj	O
(	O
x	O
)	O
	O
,	O
(	O
14.1	O
)	O
664	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.7	O
schematic	O
illustration	O
of	O
boosting	B
,	O
courtesy	O
of	O
svetlana	O
lazebnik	O
,	O
after	O
origi-	O
nal	O
illustrations	O
from	O
paul	O
viola	O
and	O
david	O
lowe	O
.	O
after	O
each	O
weak	O
classiﬁer	O
(	O
decision	B
stump	I
or	O
hyperplane	O
)	O
is	O
selected	O
,	O
data	O
points	O
that	O
are	O
erroneously	O
classiﬁed	O
have	O
their	O
weights	O
in-	O
creased	O
.	O
the	O
ﬁnal	O
classiﬁer	O
is	O
a	O
linear	B
combination	O
of	O
the	O
simple	O
weak	O
classiﬁers	O
.	O
in	O
many	O
applications	O
of	O
boosting	B
,	O
the	O
features	O
are	O
simply	O
coordinate	O
axes	O
xk	O
,	O
i.e.	O
,	O
the	O
boosting	B
algorithm	O
selects	O
one	O
of	O
the	O
input	O
vector	O
components	O
as	O
the	O
best	O
one	O
to	O
threshold	O
.	O
in	O
viola	O
and	O
jones	O
’	O
face	B
detector	O
,	O
the	O
features	O
are	O
differences	O
of	O
rectangular	O
regions	O
in	O
the	O
input	O
patch	B
,	O
as	O
shown	O
in	O
figure	O
14.6.	O
the	O
advantage	O
of	O
using	O
these	O
features	O
is	O
that	O
,	O
while	O
they	O
are	O
more	O
discriminating	O
than	O
single	O
pixels	O
,	O
they	O
are	O
extremely	O
fast	O
to	O
compute	O
once	O
a	O
summed	O
area	O
table	O
has	O
been	O
pre-computed	O
,	O
as	O
described	O
in	O
section	O
3.2.3	O
(	O
3.31–3.32	O
)	O
.	O
essentially	O
,	O
for	O
the	O
cost	O
of	O
an	O
o	O
(	O
n	O
)	O
pre-computation	O
phase	O
(	O
where	O
n	O
is	O
the	O
number	O
of	O
pixels	O
in	O
the	O
image	B
)	O
,	O
subsequent	O
differences	O
of	O
rectangles	O
can	O
be	O
computed	O
in	O
4r	O
additions	O
or	O
subtractions	O
,	O
where	O
r	O
∈	O
{	O
2	O
,	O
3	O
,	O
4	O
}	O
is	O
the	O
number	O
of	O
rectangles	O
in	O
the	O
feature	B
.	O
the	O
key	O
to	O
the	O
success	O
of	O
boosting	B
is	O
the	O
method	O
for	O
incrementally	O
selecting	O
the	O
weak	O
learners	O
and	O
for	O
re-weighting	O
the	O
training	O
examples	B
after	O
each	O
stage	O
(	O
figure	O
14.7	O
)	O
.	O
the	O
ad-	O
aboost	O
(	O
adaptive	B
boosting	O
)	O
algorithm	B
(	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
bishop	O
2006	O
)	O
does	O
this	O
by	O
re-weighting	O
each	O
sample	O
as	O
a	O
function	O
of	O
whether	O
it	O
is	O
correctly	O
classiﬁed	O
at	O
each	O
stage	O
,	O
and	O
using	O
the	O
stage-wise	O
average	O
classiﬁcation	O
error	O
to	O
determine	O
the	O
ﬁnal	O
weightings	O
αj	O
among	O
the	O
weak	O
classiﬁers	O
,	O
as	O
described	O
in	O
algorithm	B
14.1.	O
while	O
the	O
resulting	O
classi-	O
ﬁer	O
is	O
extremely	O
fast	O
in	O
practice	O
,	O
the	O
training	O
time	O
can	O
be	O
quite	O
slow	O
(	O
in	O
the	O
order	B
of	O
weeks	O
)	O
,	O
because	O
of	O
the	O
large	O
number	O
of	O
feature	B
(	O
difference	B
of	O
rectangle	O
)	O
hypotheses	O
that	O
need	O
to	O
be	O
examined	O
at	O
each	O
stage	O
.	O
to	O
further	O
increase	O
the	O
speed	O
of	O
the	O
detector	O
,	O
it	O
is	O
possible	O
to	O
create	O
a	O
cascade	B
of	I
classiﬁers	I
,	O
where	O
each	O
classiﬁer	O
uses	O
a	O
small	O
number	O
of	O
tests	O
(	O
say	O
,	O
a	O
two-term	O
adaboost	O
classiﬁer	O
)	O
to	O
reject	O
a	O
large	O
fraction	O
of	O
non-faces	O
while	O
trying	O
to	O
pass	O
through	O
all	O
potential	O
face	B
candidates	O
(	O
fleuret	O
and	O
geman	O
2001	O
;	O
viola	O
and	O
jones	O
2004	O
)	O
.	O
an	O
even	O
faster	O
algorithm	B
for	O
performing	O
cascade	O
learning	O
has	O
recently	O
been	O
developed	O
by	O
brubaker	O
,	O
wu	O
,	O
sun	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
accordingly	O
.	O
weak	O
classifier	O
1weights	O
increasedweak	O
classifier	O
2weights	O
increasedweak	O
classifier	O
3final	O
classifier	O
14.1	O
object	O
detection	B
665	O
1.	O
input	O
the	O
positive	O
and	O
negative	O
training	O
examples	B
along	O
with	O
their	O
labels	O
{	O
(	O
xi	O
,	O
yi	O
)	O
}	O
,	O
where	O
yi	O
=	O
1	O
for	O
positive	O
(	O
face	B
)	O
examples	B
and	O
yi	O
=	O
−1	O
for	O
negative	O
examples	B
.	O
2.	O
initialize	O
all	O
the	O
weights	O
to	O
wi,1	O
←	O
1	O
n	O
,	O
where	O
n	O
is	O
the	O
number	O
of	O
training	O
exam-	O
ples	O
.	O
(	O
viola	O
and	O
jones	O
(	O
2004	O
)	O
use	O
a	O
separate	O
n1	O
and	O
n2	O
for	O
positive	O
and	O
negative	O
examples	B
.	O
)	O
3.	O
for	O
each	O
training	O
stage	O
j	O
=	O
1	O
.	O
.	O
.	O
m	O
:	O
(	O
a	O
)	O
renormalize	O
the	O
weights	O
so	O
that	O
they	O
sum	O
up	O
to	O
1	O
(	O
divide	O
them	O
by	O
their	O
sum	O
)	O
.	O
(	O
b	O
)	O
select	O
the	O
best	O
classiﬁer	O
hj	O
(	O
x	O
;	O
fj	O
,	O
θj	O
,	O
sj	O
)	O
by	O
ﬁnding	O
the	O
one	O
that	O
minimizes	O
the	O
weighted	B
classiﬁcation	O
error	O
ej	O
=	O
wi	O
,	O
jei	O
,	O
j	O
,	O
n−1	O
(	O
cid:88	O
)	O
i=0	O
ei	O
,	O
j	O
=	O
1	O
−	O
δ	O
(	O
yi	O
,	O
hj	O
(	O
xi	O
;	O
fj	O
,	O
θj	O
,	O
sj	O
)	O
)	O
.	O
(	O
14.3	O
)	O
(	O
14.4	O
)	O
for	O
any	O
given	O
fj	O
function	O
,	O
the	O
optimal	O
values	O
of	O
(	O
θj	O
,	O
sj	O
)	O
can	O
be	O
found	O
in	O
linear	B
time	O
using	O
a	O
variant	O
of	O
weighted	B
median	O
computation	O
(	O
exercise	O
14.2	O
)	O
.	O
(	O
c	O
)	O
compute	O
the	O
modiﬁed	O
error	O
rate	O
βj	O
and	O
classiﬁer	O
weight	O
αj	O
,	O
βj	O
=	O
ej	O
1	O
−	O
ej	O
and	O
αj	O
=	O
−	O
log	O
βj	O
.	O
(	O
d	O
)	O
update	O
the	O
weights	O
according	O
to	O
the	O
classiﬁcation	O
errors	O
ei	O
,	O
j	O
wi	O
,	O
j+1	O
←	O
wi	O
,	O
jβ1−ei	O
,	O
j	O
j	O
,	O
(	O
14.5	O
)	O
(	O
14.6	O
)	O
i.e.	O
,	O
downweight	O
the	O
training	O
samples	O
that	O
were	O
correctly	O
classiﬁed	O
in	O
pro-	O
portion	O
to	O
the	O
overall	O
classiﬁcation	O
error	O
.	O
4.	O
set	O
the	O
ﬁnal	O
classiﬁer	O
to	O
h	O
(	O
x	O
)	O
=	O
sign	O
m−1	O
(	O
cid:88	O
)	O
j=0	O
αjhj	O
(	O
x	O
)	O
	O
.	O
(	O
14.7	O
)	O
algorithm	B
14.1	O
the	O
adaboost	O
training	O
algorithm	B
,	O
adapted	O
from	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
(	O
2001	O
)	O
,	O
viola	O
and	O
jones	O
(	O
2004	O
)	O
,	O
and	O
bishop	O
(	O
2006	O
)	O
.	O
666	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
figure	O
14.8	O
pedestrian	B
detection	O
using	O
histograms	O
of	O
oriented	B
gradients	O
(	O
dalal	O
and	O
triggs	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
ieee	O
:	O
(	O
a	O
)	O
the	O
average	O
gradient	O
image	O
over	O
the	O
training	O
examples	B
;	O
(	O
b	O
)	O
each	O
“	O
pixel	O
”	O
shows	O
the	O
maximum	O
positive	O
svm	O
weight	O
in	O
the	O
block	O
centered	O
on	O
the	O
pixel	O
;	O
(	O
c	O
)	O
like-	O
wise	O
,	O
for	O
the	O
negative	O
svm	O
weights	O
;	O
(	O
d	O
)	O
a	O
test	O
image	O
;	O
(	O
e	O
)	O
the	O
computed	O
r-hog	O
(	O
rectangular	O
histogram	B
of	O
gradients	O
)	O
descriptor	O
;	O
(	O
f	O
)	O
the	O
r-hog	O
descriptor	O
weighted	B
by	O
the	O
positive	O
svm	O
weights	O
;	O
(	O
g	O
)	O
the	O
r-hog	O
descriptor	O
weighted	B
by	O
the	O
negative	O
svm	O
weights	O
.	O
14.1.2	O
pedestrian	B
detection	O
while	O
a	O
lot	O
of	O
the	O
research	O
on	O
object	O
detection	B
has	O
focused	O
on	O
faces	B
,	O
the	O
detection	B
of	O
other	O
objects	O
,	O
such	O
as	O
pedestrians	O
and	O
cars	O
,	O
has	O
also	O
received	O
widespread	O
attention	O
(	O
gavrila	O
and	O
philomin	O
1999	O
;	O
gavrila	O
1999	O
;	O
papageorgiou	O
and	O
poggio	O
2000	O
;	O
mohan	O
,	O
papageorgiou	O
,	O
and	O
poggio	O
2001	O
;	O
schneiderman	O
and	O
kanade	O
2004	O
)	O
.	O
some	O
of	O
these	O
techniques	O
maintain	O
the	O
same	O
focus	B
as	O
face	B
detection	O
on	O
speed	O
and	O
efﬁciency	B
.	O
others	O
,	O
however	O
,	O
focus	B
instead	O
on	O
accuracy	B
,	O
viewing	O
detection	B
as	O
a	O
more	O
challenging	O
variant	O
of	O
generic	O
class	O
recognition	B
(	O
section	O
14.4	O
)	O
in	O
which	O
the	O
locations	O
and	O
extents	O
of	O
objects	O
are	O
to	O
be	O
determined	O
as	O
accurately	O
as	O
possible	O
.	O
(	O
see	O
,	O
for	O
example	O
,	O
the	O
pascal	O
voc	O
detection	B
challenge	O
,	O
http	O
:	O
//pascallin.ecs.soton.ac.uk/	O
challenges/voc/	O
.	O
)	O
an	O
example	O
of	O
a	O
well-known	O
pedestrian	B
detector	O
is	O
the	O
algorithm	B
developed	O
by	O
dalal	O
and	O
triggs	O
(	O
2005	O
)	O
,	O
who	O
use	O
a	O
set	O
of	O
overlapping	O
histogram	B
of	O
oriented	B
gradients	O
(	O
hog	O
)	O
de-	O
scriptors	O
fed	O
into	O
a	O
support	O
vector	O
machine	O
(	O
figure	O
14.8	O
)	O
.	O
each	O
hog	O
has	O
cells	O
to	O
accumulate	O
magnitude-weighted	O
votes	O
for	O
gradients	O
at	O
particular	O
orientations	O
,	O
just	O
as	O
in	O
the	O
scale	O
invariant	O
feature	B
transform	O
(	O
sift	O
)	O
developed	O
by	O
lowe	O
(	O
2004	O
)	O
,	O
which	O
we	O
discussed	O
in	O
section	O
4.1.2	O
and	O
figure	O
4.18.	O
unlike	O
sift	O
,	O
however	O
,	O
which	O
is	O
only	O
evaluated	O
at	O
interest	O
point	O
locations	O
,	O
hogs	O
are	O
evaluated	O
on	O
a	O
regular	O
overlapping	O
grid	O
and	O
their	O
descriptor	O
magnitudes	O
are	O
normalized	B
using	O
an	O
even	O
coarser	O
grid	O
;	O
they	O
are	O
only	O
computed	O
at	O
a	O
single	O
scale	O
and	O
a	O
ﬁxed	O
orientation	O
.	O
in	O
order	B
to	O
capture	O
the	O
subtle	O
variations	O
in	O
orientation	O
around	O
a	O
person	O
’	O
s	O
outline	O
,	O
a	O
large	O
number	O
of	O
orientation	O
bins	O
is	O
used	O
and	O
no	O
smoothing	B
is	O
performed	O
in	O
the	O
central	O
difference	B
gradi-	O
ent	O
computation—see	O
the	O
work	O
of	O
dalal	O
and	O
triggs	O
(	O
2005	O
)	O
for	O
more	O
implementation	O
details	O
.	O
14.1	O
object	O
detection	B
667	O
figure	O
14.8d	O
shows	O
a	O
sample	O
input	O
image	B
,	O
while	O
figure	O
14.8e	O
shows	O
the	O
associated	O
hog	O
descriptors	O
.	O
once	O
the	O
descriptors	O
have	O
been	O
computed	O
,	O
a	O
support	O
vector	O
machine	O
(	O
svm	O
)	O
is	O
trained	O
on	O
the	O
resulting	O
high-dimensional	O
continuous	O
descriptor	O
vectors	O
.	O
figures	O
14.8b–c	O
show	O
a	O
diagram	O
of	O
the	O
(	O
most	O
)	O
positive	O
and	O
negative	O
svm	O
weights	O
in	O
each	O
block	O
,	O
while	O
figures	O
14.8f–	O
g	O
show	O
the	O
corresponding	O
weighted	B
hog	O
responses	O
for	O
the	O
central	O
input	O
image	B
.	O
as	O
you	O
can	O
see	O
,	O
there	O
are	O
a	O
fair	O
number	O
of	O
positive	O
responses	O
around	O
the	O
head	B
,	O
torso	O
,	O
and	O
feet	O
of	O
the	O
person	O
,	O
and	O
relatively	O
few	O
negative	O
responses	O
(	O
mainly	O
around	O
the	O
middle	O
and	O
the	O
neck	O
of	O
the	O
sweater	O
)	O
.	O
the	O
ﬁelds	O
of	O
pedestrian	B
and	O
general	O
object	O
detection	B
have	O
continued	O
to	O
evolve	O
rapidly	O
over	O
the	O
last	O
decade	O
(	O
belongie	O
,	O
malik	O
,	O
and	O
puzicha	O
2002	O
;	O
mikolajczyk	O
,	O
schmid	O
,	O
and	O
zis-	O
serman	O
2004	O
;	O
leibe	O
,	O
seemann	O
,	O
and	O
schiele	O
2005	O
;	O
opelt	O
,	O
pinz	O
,	O
and	O
zisserman	O
2006	O
;	O
tor-	O
ralba	O
2007	O
;	O
andriluka	O
,	O
roth	O
,	O
and	O
schiele	O
2009	O
,	O
2010	O
;	O
doll`ar	O
,	O
belongie	O
,	O
and	O
perona	O
2010	O
)	O
.	O
munder	O
and	O
gavrila	O
(	O
2006	O
)	O
compare	O
a	O
number	O
of	O
pedestrian	B
detectors	O
and	O
conclude	O
that	O
those	O
based	O
on	O
local	B
receptive	O
ﬁelds	O
and	O
svms	O
perform	O
the	O
best	O
,	O
with	O
a	O
boosting-based	O
ap-	O
proach	O
coming	O
close	O
.	O
maji	O
,	O
berg	O
,	O
and	O
malik	O
(	O
2008	O
)	O
improve	O
on	O
the	O
best	O
of	O
these	O
results	O
using	O
non-overlapping	O
multi-resolution	O
hog	O
descriptors	O
and	O
a	O
histogram	B
intersection	O
kernel	B
svm	O
based	O
on	O
a	O
spatial	O
pyramid	B
match	O
kernel	B
from	O
lazebnik	O
,	O
schmid	O
,	O
and	O
ponce	O
(	O
2006	O
)	O
.	O
when	O
detectors	O
for	O
several	O
different	O
classes	O
are	O
being	O
constructed	O
simultaneously	O
,	O
tor-	O
ralba	O
,	O
murphy	O
,	O
and	O
freeman	O
(	O
2007	O
)	O
show	O
that	O
sharing	O
features	O
and	O
weak	O
learners	O
between	O
detectors	O
yields	O
better	O
performance	O
,	O
both	O
in	O
terms	O
of	O
faster	O
computation	O
times	O
and	O
fewer	O
training	O
examples	B
.	O
to	O
ﬁnd	O
the	O
features	O
and	O
decision	O
stumps	O
that	O
work	O
best	O
in	O
a	O
shared	O
man-	O
ner	O
,	O
they	O
introduce	O
a	O
novel	O
joint	B
boosting	O
algorithm	B
that	O
optimizes	O
,	O
at	O
each	O
stage	O
,	O
a	O
summed	O
expected	O
exponential	O
loss	O
function	O
using	O
the	O
“	O
gentleboost	O
”	O
algorithm	B
of	O
friedman	O
,	O
hastie	O
,	O
and	O
tibshirani	O
(	O
2000	O
)	O
.	O
in	O
more	O
recent	O
work	O
,	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
(	O
2008	O
)	O
extend	O
the	O
his-	O
togram	O
of	O
oriented	B
gradients	O
person	O
detector	O
to	O
incorporate	O
ﬂexible	O
parts	O
models	O
(	O
section	O
14.4.2	O
)	O
.	O
each	O
part	O
is	O
trained	O
and	O
detected	O
on	O
hogs	O
evaluated	O
at	O
two	O
pyramid	O
levels	O
below	O
the	O
overall	O
object	O
model	O
and	O
the	O
locations	O
of	O
the	O
parts	O
relative	O
to	O
the	O
parent	O
node	O
(	O
the	O
overall	O
bounding	O
box	O
)	O
are	O
also	O
learned	B
and	O
used	O
during	O
recognition	B
(	O
figure	O
14.9b	O
)	O
.	O
to	O
compensate	O
for	O
inac-	O
curacies	O
or	O
inconsistencies	O
in	O
the	O
training	O
example	O
bounding	O
boxes	O
(	O
dashed	O
white	O
lines	B
in	O
figure	O
14.9c	O
)	O
,	O
the	O
“	O
true	O
”	O
location	O
of	O
the	O
parent	O
(	O
blue	O
)	O
bounding	O
box	O
is	O
considered	O
a	O
latent	O
(	O
hidden	O
)	O
variable	O
and	O
is	O
inferred	O
during	O
both	O
training	O
and	O
recognition	B
.	O
since	O
the	O
locations	O
of	O
the	O
parts	O
are	O
also	O
latent	O
,	O
the	O
system	O
can	O
be	O
trained	O
in	O
a	O
semi-supervised	O
fashion	O
,	O
without	O
needing	O
part	O
labels	O
in	O
the	O
training	O
data	O
.	O
an	O
extension	O
to	O
this	O
system	O
(	O
felzenszwalb	O
,	O
girshick	O
,	O
mcallester	O
et	O
al	O
.	O
2010	O
)	O
,	O
which	O
includes	O
among	O
its	O
improvements	O
a	O
simple	O
contextual	O
model	O
,	O
was	O
among	O
the	O
two	O
best	O
object	O
detection	B
systems	O
in	O
the	O
2008	O
visual	O
object	O
classes	O
detection	B
challenge	O
.	O
other	O
recent	O
improvements	O
to	O
part-based	B
person	O
detection	B
and	O
pose	O
estimation	B
in-	O
668	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
14.9	O
part-based	B
object	O
detection	B
(	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
:	O
(	O
a	O
)	O
an	O
input	O
photograph	O
and	O
its	O
associated	O
person	O
(	O
blue	O
)	O
and	O
part	O
(	O
yellow	O
)	O
detection	B
results	O
.	O
(	O
b	O
)	O
the	O
detection	B
model	O
is	O
deﬁned	O
by	O
a	O
coarse	O
template	O
,	O
several	O
higher	O
resolution	O
part	O
templates	O
,	O
and	O
a	O
spatial	O
model	O
for	O
the	O
location	O
of	O
each	O
part	O
.	O
(	O
c	O
)	O
true	O
positive	O
detection	O
of	O
a	O
skier	O
and	O
(	O
d	O
)	O
false	O
positive	O
detection	O
of	O
a	O
cow	O
(	O
labeled	O
as	O
a	O
person	O
)	O
.	O
clude	O
the	O
work	O
by	O
andriluka	O
,	O
roth	O
,	O
and	O
schiele	O
(	O
2009	O
)	O
and	O
kumar	O
,	O
zisserman	O
,	O
and	O
h.s.torr	O
(	O
2009	O
)	O
.	O
an	O
even	O
more	O
accurate	O
estimate	O
of	O
a	O
person	O
’	O
s	O
pose	O
and	O
location	O
is	O
presented	O
by	O
rogez	O
,	O
rihan	O
,	O
ramalingam	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
who	O
compute	O
both	O
the	O
phase	O
of	O
a	O
person	O
in	O
a	O
walk	O
cycle	O
and	O
the	O
locations	O
of	O
individual	O
joints	O
,	O
using	O
random	O
forests	O
built	O
on	O
top	O
of	O
hogs	O
(	O
figure	O
14.11	O
)	O
.	O
since	O
their	O
system	O
produces	O
full	O
3d	O
pose	O
information	O
,	O
it	O
is	O
closer	O
in	O
its	O
application	O
domain	O
to	O
3d	O
person	O
trackers	O
(	O
sidenbladh	O
,	O
black	O
,	O
and	O
fleet	O
2000	O
;	O
andriluka	O
,	O
roth	O
,	O
and	O
schiele	O
2010	O
)	O
,	O
which	O
we	O
discussed	O
in	O
section	O
12.6.4.	O
one	O
ﬁnal	O
note	O
on	O
person	O
and	O
object	O
detection	B
.	O
when	O
video	B
sequences	O
are	O
available	O
,	O
the	O
additional	O
information	O
present	O
in	O
the	O
optic	O
ﬂow	O
and	O
motion	B
discontinuities	O
can	O
greatly	O
aid	O
in	O
the	O
detection	B
task	O
,	O
as	O
discussed	O
by	O
efros	O
,	O
berg	O
,	O
mori	O
et	O
al	O
.	O
(	O
2003	O
)	O
,	O
viola	O
,	O
jones	O
,	O
and	O
snow	O
(	O
2003	O
)	O
,	O
and	O
dalal	O
,	O
triggs	O
,	O
and	O
schmid	O
(	O
2006	O
)	O
.	O
14.2	O
face	B
recognition	O
among	O
the	O
various	O
recognition	B
tasks	O
that	O
computers	O
might	O
be	O
asked	O
to	O
perform	O
,	O
face	B
recog-	O
nition	O
is	O
the	O
one	O
where	O
they	O
have	O
arguably	O
had	O
the	O
most	O
success.5	O
while	O
computers	O
can	O
not	O
pick	O
out	O
suspects	O
from	O
thousands	O
of	O
people	O
streaming	O
in	O
front	O
of	O
video	B
cameras	O
(	O
even	O
people	O
can	O
not	O
readily	O
distinguish	O
between	O
similar	O
people	O
with	O
whom	O
they	O
are	O
not	O
familiar	O
(	O
o	O
’	O
toole	O
,	O
jiang	O
,	O
roark	O
et	O
al	O
.	O
2006	O
;	O
o	O
’	O
toole	O
,	O
phillips	O
,	O
jiang	O
et	O
al	O
.	O
2009	O
)	O
)	O
,	O
their	O
ability	O
to	O
distinguish	O
5instance	O
recognition	B
,	O
i.e.	O
,	O
the	O
re-recognition	O
of	O
known	O
objects	O
such	O
as	O
locations	O
or	O
planar	O
objects	O
,	O
is	O
the	O
other	O
most	O
successful	O
application	O
of	O
general	O
image	B
recognition	O
.	O
in	O
the	O
general	O
domain	O
of	O
biometrics	B
,	O
i.e.	O
,	O
identity	O
recogni-	O
tion	B
,	O
specialized	O
images	O
such	O
as	O
irises	O
and	O
ﬁngerprints	O
perform	O
even	O
better	O
(	O
jain	O
,	O
bolle	O
,	O
and	O
pankanti	O
1999	O
;	O
pankanti	O
,	O
bolle	O
,	O
and	O
jain	O
2000	O
;	O
daugman	O
2004	O
)	O
.	O
14.2	O
face	B
recognition	O
669	O
figure	O
14.10	O
part-based	B
object	O
detection	B
results	O
for	O
people	O
,	O
bicycles	O
,	O
and	O
horses	O
(	O
felzen-	O
szwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
.	O
the	O
ﬁrst	O
three	O
columns	O
show	O
correct	O
detections	O
,	O
while	O
the	O
rightmost	O
column	O
shows	O
false	O
positives	O
.	O
figure	O
14.11	O
pose	O
detection	B
using	O
random	O
forests	O
(	O
rogez	O
,	O
rihan	O
,	O
ramalingam	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
.	O
the	O
estimated	O
pose	O
(	O
state	O
of	O
the	O
kinematic	O
model	O
)	O
is	O
drawn	O
over	O
each	O
input	O
frame	O
.	O
670	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.12	O
humans	O
can	O
recognize	O
low-resolution	O
faces	B
of	O
familiar	O
people	O
(	O
sinha	O
,	O
balas	O
,	O
ostrovsky	O
et	O
al	O
.	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
ieee	O
.	O
among	O
a	O
small	O
number	O
of	O
family	O
members	O
and	O
friends	O
has	O
found	O
its	O
way	O
into	O
consumer-level	O
photo	O
applications	O
,	O
such	O
as	O
picasa	O
and	O
iphoto	O
.	O
face	B
recognition	O
can	O
also	O
be	O
used	O
in	O
a	O
variety	O
of	O
additional	O
applications	O
,	O
including	O
human–computer	O
interaction	O
(	O
hci	O
)	O
,	O
identity	O
veriﬁcation	B
(	O
kirovski	O
,	O
jojic	O
,	O
and	O
jancke	O
2004	O
)	O
,	O
desktop	O
login	O
,	O
parental	O
controls	O
,	O
and	O
patient	O
monitoring	O
(	O
zhao	O
,	O
chellappa	O
,	O
phillips	O
et	O
al	O
.	O
2003	O
)	O
.	O
today	O
’	O
s	O
face	B
recognizers	O
work	O
best	O
when	O
they	O
are	O
given	O
full	O
frontal	O
images	O
of	O
faces	B
under	O
relatively	O
uniform	O
illumination	O
conditions	O
,	O
although	O
databases	O
that	O
include	O
large	O
amounts	O
of	O
pose	O
and	O
lighting	B
variation	O
have	O
been	O
collected	O
(	O
phillips	O
,	O
moon	O
,	O
rizvi	O
et	O
al	O
.	O
2000	O
;	O
sim	O
,	O
baker	O
,	O
and	O
bsat	O
2003	O
;	O
gross	O
,	O
shi	O
,	O
and	O
cohn	O
2005	O
;	O
huang	O
,	O
ramesh	O
,	O
berg	O
et	O
al	O
.	O
2007	O
;	O
phillips	O
,	O
scruggs	O
,	O
o	O
’	O
toole	O
et	O
al	O
.	O
2010	O
)	O
.	O
(	O
see	O
table	O
14.1	O
in	O
section	O
14.6	O
for	O
more	O
details	O
.	O
)	O
some	O
of	O
the	O
earliest	O
approaches	O
to	O
face	B
recognition	O
involved	O
ﬁnding	O
the	O
locations	O
of	O
distinctive	O
image	B
features	O
,	O
such	O
as	O
the	O
eyes	O
,	O
nose	O
,	O
and	O
mouth	O
,	O
and	O
measuring	O
the	O
distances	O
between	O
these	O
feature	B
locations	O
(	O
fischler	O
and	O
elschlager	O
1973	O
;	O
kanade	O
1977	O
;	O
yuille	O
1991	O
)	O
.	O
more	O
recent	O
approaches	O
rely	O
on	O
comparing	O
gray-level	O
images	O
projected	O
onto	O
lower	O
dimen-	O
sional	O
subspaces	O
called	O
eigenfaces	O
(	O
section	O
14.2.1	O
)	O
and	O
jointly	O
modeling	B
shape	O
and	O
appear-	O
ance	O
variations	O
(	O
while	O
discounting	O
pose	O
variations	O
)	O
using	O
active	O
appearance	O
models	O
(	O
sec-	O
tion	B
14.2.2	O
)	O
.	O
descriptions	O
of	O
additional	O
face	B
recognition	O
techniques	O
can	O
be	O
found	O
in	O
a	O
number	O
of	O
sur-	O
veys	O
and	O
books	O
on	O
this	O
topic	O
(	O
chellappa	O
,	O
wilson	O
,	O
and	O
sirohey	O
1995	O
;	O
zhao	O
,	O
chellappa	O
,	O
phillips	O
et	O
al	O
.	O
2003	O
;	O
li	O
and	O
jain	O
2005	O
)	O
as	O
well	O
as	O
the	O
face	B
recognition	O
web	O
site.6	O
the	O
survey	O
on	O
face	B
recognition	O
by	O
humans	O
by	O
sinha	O
,	O
balas	O
,	O
ostrovsky	O
et	O
al	O
.	O
(	O
2006	O
)	O
is	O
also	O
well	O
worth	O
reading	O
;	O
it	O
includes	O
a	O
number	O
of	O
surprising	O
results	O
,	O
such	O
as	O
humans	O
’	O
ability	O
to	O
recognize	O
low-resolution	O
images	O
of	O
familiar	O
faces	B
(	O
figure	O
14.12	O
)	O
and	O
the	O
importance	O
of	O
eyebrows	O
in	O
recognition	B
.	O
6	O
http	O
:	O
//www.face-rec.org/	O
.	O
14.2	O
face	B
recognition	O
671	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
14.13	O
face	B
modeling	I
and	O
compression	B
using	O
eigenfaces	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
ieee	O
:	O
(	O
a	O
)	O
input	O
image	B
;	O
(	O
b	O
)	O
the	O
ﬁrst	O
eight	O
eigenfaces	O
;	O
(	O
c	O
)	O
image	B
reconstructed	O
by	O
projecting	O
onto	O
this	O
basis	O
and	O
compressing	O
the	O
image	B
to	O
85	O
bytes	O
;	O
(	O
d	O
)	O
image	B
reconstructed	O
using	O
jpeg	O
(	O
530	O
bytes	O
)	O
.	O
14.2.1	O
eigenfaces	O
eigenfaces	O
rely	O
on	O
the	O
observation	O
ﬁrst	O
made	O
by	O
kirby	O
and	O
sirovich	O
(	O
1990	O
)	O
that	O
an	O
arbitrary	O
face	B
image	O
x	O
can	O
be	O
compressed	O
and	O
reconstructed	O
by	O
starting	O
with	O
a	O
mean	O
image	O
m	O
(	O
fig-	O
ure	O
14.1b	O
)	O
and	O
adding	O
a	O
small	O
number	O
of	O
scaled	O
signed	O
images	O
ui,7	O
˜x	O
=	O
m	O
+	O
aiui	O
,	O
(	O
14.8	O
)	O
where	O
the	O
signed	B
basis	O
images	O
(	O
figure	O
14.13b	O
)	O
can	O
be	O
derived	O
from	O
an	O
ensemble	O
of	O
train-	O
ing	O
images	O
using	O
principal	O
component	O
analysis	O
(	O
also	O
known	O
as	O
eigenvalue	O
analysis	O
or	O
the	O
karhunen–lo`eve	O
transform	B
)	O
.	O
turk	O
and	O
pentland	O
(	O
1991a	O
)	O
recognized	O
that	O
the	O
coefﬁcients	O
ai	O
in	O
the	O
eigenface	B
expansion	O
could	O
themselves	O
be	O
used	O
to	O
construct	O
a	O
fast	O
image	O
matching	B
algo-	O
rithm	O
.	O
in	O
more	O
detail	O
,	O
let	O
us	O
start	O
with	O
a	O
collection	O
of	O
training	O
images	O
{	O
xj	O
}	O
,	O
from	O
which	O
we	O
can	O
compute	O
the	O
mean	O
image	O
m	O
and	O
a	O
scatter	O
or	O
covariance	O
matrix	O
c	O
=	O
1	O
n	O
n−1	O
(	O
cid:88	O
)	O
j=0	O
(	O
xj	O
−	O
m	O
)	O
(	O
xj	O
−	O
m	O
)	O
t	O
.	O
(	O
14.9	O
)	O
we	O
can	O
apply	O
the	O
eigenvalue	O
decomposition	O
(	O
a.6	O
)	O
to	O
represent	O
this	O
matrix	O
as	O
m−1	O
(	O
cid:88	O
)	O
i=0	O
n−1	O
(	O
cid:88	O
)	O
i=0	O
c	O
=	O
uλu	O
t	O
=	O
λiuiut	O
i	O
,	O
(	O
14.10	O
)	O
where	O
the	O
λi	O
are	O
the	O
eigenvalues	B
of	O
c	O
and	O
the	O
ui	O
are	O
the	O
eigenvectors	O
.	O
for	O
general	O
im-	O
ages	O
,	O
kirby	O
and	O
sirovich	O
(	O
1990	O
)	O
call	O
these	O
vectors	O
eigenpictures	O
;	O
for	O
faces	O
,	O
turk	O
and	O
pentland	O
7	O
in	O
previous	O
chapters	O
,	O
we	O
used	O
i	O
to	O
indicate	O
images	O
;	O
in	O
this	O
chapter	O
,	O
we	O
use	O
the	O
more	O
abstract	O
quantities	O
x	O
and	O
u	O
to	O
indicate	O
collections	O
of	O
pixels	O
in	O
an	O
image	B
turned	O
into	O
a	O
vector	O
.	O
672	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.14	O
projection	O
onto	O
the	O
linear	B
subspace	O
spanned	O
by	O
the	O
eigenface	B
images	O
(	O
moghad-	O
dam	O
and	O
pentland	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
ieee	O
.	O
the	O
distance	O
from	O
face	B
space	O
(	O
dffs	O
)	O
is	O
the	O
orthog-	O
onal	O
distance	O
to	O
the	O
plane	O
,	O
while	O
the	O
distance	O
in	O
face	B
space	O
(	O
difs	O
)	O
is	O
the	O
distance	O
along	O
the	O
plane	O
from	O
the	O
mean	O
image	O
.	O
both	O
distances	O
can	O
be	O
turned	O
into	O
mahalanobis	O
distances	O
and	O
given	O
probabilistic	B
interpretations	O
.	O
(	O
1991a	O
)	O
call	O
them	O
eigenfaces	O
(	O
figure	O
14.13b	O
)	O
.8	O
two	O
important	O
properties	B
of	O
the	O
eigenvalue	O
decomposition	O
are	O
that	O
the	O
optimal	O
(	O
best	O
ap-	O
proximation	O
)	O
coefﬁcients	O
ai	O
for	O
any	O
new	O
image	B
x	O
can	O
be	O
computed	O
as	O
ai	O
=	O
(	O
x	O
−	O
m	O
)	O
·	O
ui	O
,	O
(	O
14.11	O
)	O
and	O
that	O
,	O
assuming	O
the	O
eigenvalues	B
{	O
λi	O
}	O
are	O
sorted	O
in	O
decreasing	O
order	B
,	O
truncating	O
the	O
ap-	O
proximation	O
given	O
in	O
(	O
14.8	O
)	O
at	O
any	O
point	O
m	O
gives	O
the	O
best	O
possible	O
approximation	O
(	O
least	O
er-	O
ror	O
)	O
between	O
˜x	O
and	O
x.	O
figure	O
14.13c	O
shows	O
the	O
resulting	O
approximation	O
corresponding	O
to	O
figure	O
14.13a	O
and	O
shows	O
how	O
much	O
better	O
it	O
is	O
at	O
compressing	O
a	O
face	B
image	O
than	O
jpeg	O
.	O
truncating	O
the	O
eigenface	B
decomposition	O
of	O
a	O
face	B
image	O
(	O
14.8	O
)	O
after	O
m	O
components	O
is	O
equivalent	O
to	O
projecting	O
the	O
image	B
onto	O
a	O
linear	B
subspace	O
f	O
,	O
which	O
we	O
can	O
call	O
the	O
face	B
space	O
(	O
figure	O
14.14	O
)	O
.	O
because	O
the	O
eigenvectors	O
(	O
eigenfaces	O
)	O
are	O
orthogonal	O
and	O
of	O
unit	O
norm	O
,	O
the	O
distance	O
of	O
a	O
projected	O
face	B
˜x	O
to	O
the	O
mean	O
face	O
m	O
can	O
be	O
written	O
as	O
difs	O
=	O
(	O
cid:107	O
)	O
˜x	O
−	O
m	O
(	O
cid:107	O
)	O
=	O
(	O
cid:118	O
)	O
(	O
cid:117	O
)	O
(	O
cid:117	O
)	O
(	O
cid:116	O
)	O
m−1	O
(	O
cid:88	O
)	O
i=0	O
a2	O
i	O
,	O
(	O
14.12	O
)	O
where	O
difs	O
stands	O
for	O
distance	O
in	O
face	B
space	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
.	O
the	O
re-	O
maining	O
distance	O
between	O
the	O
original	O
image	B
x	O
and	O
its	O
projection	O
onto	O
face	B
space	O
˜x	O
,	O
i.e.	O
,	O
the	O
8	O
in	O
actual	O
practice	O
,	O
the	O
full	O
p	O
×	O
p	O
scatter	O
matrix	O
(	O
14.9	O
)	O
is	O
never	O
computed	O
.	O
instead	O
,	O
a	O
smaller	O
n	O
×	O
n	O
matrix	O
con-	O
sisting	O
of	O
the	O
inner	O
products	O
between	O
all	O
the	O
signed	B
deviations	O
(	O
xi−m	O
)	O
is	O
accumulated	O
instead	O
.	O
see	O
appendix	O
a.1.2	O
(	O
a.13–a.14	O
)	O
for	O
details	O
.	O
xdffsdifsxxxxxxxxxxxxxxxxxxxxxxxxxxxxff_m~x	O
14.2	O
face	B
recognition	O
673	O
distance	O
from	O
face	B
space	O
(	O
dffs	O
)	O
,	O
can	O
be	O
computed	O
directly	O
in	O
pixel	O
space	O
and	O
represents	O
the	O
“	O
faceness	O
”	O
of	O
a	O
particular	O
image.9	O
it	O
is	O
also	O
possible	O
to	O
measure	O
the	O
distance	O
between	O
two	O
different	O
faces	B
in	O
face	B
space	O
as	O
difs	O
(	O
x	O
,	O
y	O
)	O
=	O
(	O
cid:107	O
)	O
˜x	O
−	O
˜y	O
(	O
cid:107	O
)	O
=	O
(	O
cid:118	O
)	O
(	O
cid:117	O
)	O
(	O
cid:117	O
)	O
(	O
cid:116	O
)	O
m−1	O
(	O
cid:88	O
)	O
i=0	O
(	O
ai	O
−	O
bi	O
)	O
2	O
,	O
(	O
14.13	O
)	O
where	O
the	O
bi	O
=	O
(	O
y	O
−	O
m	O
)	O
·	O
ui	O
are	O
the	O
eigenface	B
coefﬁcients	O
corresponding	O
to	O
y.	O
computing	O
such	O
distances	O
in	O
euclidean	O
vector	O
space	O
,	O
however	O
,	O
does	O
not	O
exploit	O
the	O
ad-	O
ditional	O
information	O
that	O
the	O
eigenvalue	O
decomposition	O
of	O
our	O
covariance	O
matrix	O
(	O
14.10	O
)	O
pro-	O
vides	O
.	O
if	O
we	O
interpret	O
the	O
covariance	O
matrix	O
c	O
as	O
the	O
covariance	O
of	O
a	O
multi-variate	O
gaussian	O
(	O
appendix	O
b.1.1	O
)	O
,10	O
we	O
can	O
turn	O
the	O
difs	O
into	O
a	O
log	O
likelihood	O
by	O
computing	O
the	O
maha-	O
lanobis	O
distance	O
difs	O
(	O
cid:48	O
)	O
=	O
(	O
cid:107	O
)	O
˜x	O
−	O
m	O
(	O
cid:107	O
)	O
c−1	O
=	O
(	O
cid:118	O
)	O
(	O
cid:117	O
)	O
(	O
cid:117	O
)	O
(	O
cid:116	O
)	O
m−1	O
(	O
cid:88	O
)	O
i=0	O
a2	O
i	O
/λ2	O
i	O
.	O
(	O
14.14	O
)	O
instead	O
of	O
measuring	O
the	O
squared	O
distance	O
along	O
each	O
principal	O
component	O
in	O
face	B
space	O
f	O
,	O
the	O
mahalanobis	O
distance	O
measures	O
the	O
ratio	O
between	O
the	O
squared	O
distance	O
and	O
the	O
corre-	O
sponding	O
variance	O
σ2	O
an	O
alternative	O
way	O
to	O
implement	O
this	O
is	O
to	O
pre-scale	O
each	O
eigenvector	O
by	O
the	O
inverse	B
square	O
root	O
of	O
its	O
corresponding	O
eigenvalue	O
,	O
i	O
=	O
λi	O
and	O
then	O
sums	O
these	O
squared	O
ratios	B
(	O
per-component	O
log-likelihoods	O
)	O
.	O
ˆu	O
=	O
uλ−1/2	O
.	O
(	O
14.15	O
)	O
this	O
whitening	O
transformation	O
then	O
means	O
that	O
euclidean	O
distances	O
in	O
feature	B
(	O
face	B
)	O
space	O
now	O
correspond	O
directly	O
to	O
log	O
likelihoods	O
(	O
moghaddam	O
,	O
jebara	O
,	O
and	O
pentland	O
2000	O
)	O
.	O
(	O
this	O
same	O
whitening	O
approach	O
can	O
also	O
be	O
used	O
in	O
feature-based	B
matching	O
algorithms	O
,	O
as	O
discussed	O
in	O
section	O
4.1.3	O
.	O
)	O
if	O
the	O
distribution	O
in	O
eigenface	B
space	O
is	O
very	O
elongated	O
,	O
the	O
mahalanobis	O
distance	O
properly	O
scales	O
the	O
components	O
to	O
come	O
up	O
with	O
a	O
sensible	O
(	O
probabilistic	B
)	O
distance	O
from	O
the	O
mean	O
.	O
a	O
similar	O
analysis	O
can	O
be	O
performed	O
for	O
computing	O
a	O
sensible	O
difference	B
from	O
face	B
space	O
(	O
dffs	O
)	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
and	O
the	O
two	O
terms	O
can	O
be	O
combined	O
to	O
produce	O
an	O
estimate	O
of	O
the	O
likelihood	O
of	O
being	O
a	O
true	O
face	O
,	O
which	O
can	O
be	O
useful	O
in	O
doing	O
face	B
detection	O
(	O
section	O
14.1.1	O
)	O
.	O
more	O
detailed	O
explanations	O
of	O
probabilistic	B
and	O
bayesian	O
pca	O
can	O
be	O
found	O
in	O
textbooks	B
on	O
statistical	O
learning	B
(	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
bishop	O
2006	O
)	O
,	O
which	O
also	O
discuss	O
techniques	O
for	O
selecting	O
the	O
optimum	O
number	O
of	O
components	O
m	O
to	O
use	O
in	O
modeling	B
a	O
distribution	O
.	O
9	O
this	O
can	O
be	O
used	O
to	O
form	O
a	O
simple	O
face	B
detector	O
,	O
as	O
mentioned	O
in	O
section	O
14.1.1	O
.	O
10	O
the	O
ellipse	O
shown	O
in	O
figure	O
14.14	O
denotes	O
an	O
equi-probability	O
contour	O
of	O
this	O
multi-variate	O
gaussian	O
.	O
674	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.15	O
images	O
from	O
the	O
harvard	O
database	O
used	O
by	O
belhumeur	O
,	O
hespanha	O
,	O
and	O
krieg-	O
man	O
(	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
ieee	O
.	O
note	O
the	O
wide	O
range	O
of	O
illumination	O
variation	O
,	O
which	O
can	O
be	O
more	O
dramatic	O
than	O
inter-personal	O
variations	O
.	O
one	O
of	O
the	O
biggest	O
advantages	O
of	O
using	O
eigenfaces	O
is	O
that	O
they	O
reduce	O
the	O
comparison	O
of	O
a	O
new	O
face	B
image	O
x	O
to	O
a	O
prototype	O
(	O
training	O
)	O
face	B
image	O
xk	O
(	O
one	O
of	O
the	O
colored	O
xs	O
in	O
figure	O
14.14	O
)	O
from	O
a	O
p	O
-dimensional	O
difference	B
in	O
pixel	O
space	O
to	O
an	O
m-dimensional	O
difference	B
in	O
face	B
space	O
,	O
(	O
cid:107	O
)	O
x	O
−	O
xk	O
(	O
cid:107	O
)	O
=	O
(	O
cid:107	O
)	O
a	O
−	O
ak	O
(	O
cid:107	O
)	O
,	O
(	O
14.16	O
)	O
where	O
a	O
=	O
u	O
t	O
(	O
x	O
−	O
m	O
)	O
(	O
14.11	O
)	O
involves	O
computing	O
a	O
dot	O
product	O
between	O
the	O
signed	B
difference-from-mean	O
image	B
(	O
x	O
−	O
m	O
)	O
and	O
each	O
of	O
the	O
eigenfaces	O
ui	O
.	O
once	O
again	O
,	O
however	O
,	O
this	O
euclidean	O
distance	O
ignores	O
the	O
fact	O
that	O
we	O
have	O
more	O
information	O
about	O
face	B
likelihoods	O
available	O
in	O
the	O
distribution	O
of	O
training	O
images	O
.	O
consider	O
the	O
set	O
of	O
images	O
of	O
one	O
person	O
taken	O
under	O
a	O
wide	O
range	O
of	O
illuminations	O
shown	O
in	O
figure	O
14.15.	O
as	O
you	O
can	O
see	O
,	O
the	O
intrapersonal	O
variability	O
within	O
these	O
images	O
is	O
much	O
greater	O
than	O
the	O
typical	O
extrapersonal	O
variability	O
between	O
any	O
two	O
people	O
taken	O
under	O
the	O
same	O
illumination	O
.	O
regular	O
pca	O
analysis	O
fails	O
to	O
distinguish	O
between	O
these	O
two	O
sources	O
of	O
variability	O
and	O
may	O
,	O
in	O
fact	O
,	O
devote	O
most	O
of	O
its	O
principal	O
components	O
to	O
modeling	B
the	O
intrap-	O
ersonal	O
variability	O
.	O
if	O
we	O
are	O
going	O
to	O
approximate	O
faces	B
by	O
a	O
linear	B
subspace	O
,	O
it	O
is	O
more	O
useful	O
to	O
have	O
a	O
space	O
that	O
discriminates	O
between	O
different	O
classes	O
(	O
people	O
)	O
and	O
is	O
less	O
sensitive	O
to	O
within-class	B
variations	O
(	O
belhumeur	O
,	O
hespanha	O
,	O
and	O
kriegman	O
1997	O
)	O
.	O
consider	O
the	O
three	O
classes	O
shown	O
as	O
different	O
colors	O
in	O
figure	O
14.16.	O
as	O
you	O
can	O
see	O
,	O
the	O
distributions	O
within	O
a	O
class	O
(	O
indicated	O
by	O
the	O
tilted	O
colored	O
axes	O
)	O
are	O
elongated	O
and	O
tilted	O
with	O
respect	O
to	O
the	O
main	O
face	B
space	O
pca	O
,	O
14.2	O
face	B
recognition	O
675	O
figure	O
14.16	O
simple	O
example	O
of	O
fisher	O
linear	B
discriminant	O
analysis	O
.	O
the	O
samples	O
come	O
from	O
three	O
different	O
classes	O
,	O
shown	O
in	O
different	O
colors	O
along	O
with	O
their	O
principal	O
axes	O
,	O
which	O
are	O
scaled	O
to	O
2σi	O
.	O
(	O
the	O
intersections	O
of	O
the	O
tilted	O
axes	O
are	O
the	O
class	O
means	O
mk	O
.	O
)	O
the	O
dashed	O
line	O
is	O
the	O
(	O
dominant	O
)	O
fisher	O
linear	B
discriminant	O
direction	O
and	O
the	O
dotted	O
lines	B
are	O
the	O
linear	B
discriminants	O
between	O
the	O
classes	O
.	O
note	O
how	O
the	O
discriminant	O
direction	O
is	O
a	O
blend	O
between	O
the	O
principal	O
directions	O
of	O
the	O
between-class	B
and	O
within-class	B
scatter	O
matrices	O
.	O
which	O
is	O
aligned	O
with	O
the	O
black	O
x	O
and	O
y	O
axes	O
.	O
we	O
can	O
compute	O
the	O
total	B
within-class	O
scatter	O
matrix	O
as	O
sw	O
=	O
sk	O
=	O
(	O
xi	O
−	O
mk	O
)	O
(	O
xi	O
−	O
mk	O
)	O
t	O
,	O
(	O
14.17	O
)	O
k−1	O
(	O
cid:88	O
)	O
k=0	O
k−1	O
(	O
cid:88	O
)	O
k=0	O
(	O
cid:88	O
)	O
i∈ck	O
where	O
mk	O
is	O
the	O
mean	O
of	O
class	O
k	O
and	O
sk	O
is	O
its	O
within-class	B
scatter	O
matrix.11	O
similarly	O
,	O
we	O
can	O
compute	O
the	O
between-class	B
scatter	O
as	O
sb	O
=	O
k−1	O
(	O
cid:88	O
)	O
k=0	O
nk	O
(	O
mk	O
−	O
m	O
)	O
(	O
mk	O
−	O
m	O
)	O
t	O
,	O
(	O
14.18	O
)	O
where	O
nk	O
are	O
the	O
number	O
of	O
exemplars	O
in	O
each	O
class	O
and	O
m	O
is	O
the	O
overall	O
mean	O
.	O
for	O
the	O
three	O
distributions	O
shown	O
in	O
figure	O
14.16	O
,	O
we	O
have	O
sw	O
=	O
3n	O
(	O
cid:34	O
)	O
0.246	O
0.183	O
0.183	O
0.457	O
(	O
cid:35	O
)	O
and	O
sb	O
=	O
n	O
(	O
cid:34	O
)	O
6.125	O
0	O
0	O
0.375	O
(	O
cid:35	O
)	O
,	O
(	O
14.19	O
)	O
11	O
to	O
be	O
consistent	O
with	O
belhumeur	O
,	O
hespanha	O
,	O
and	O
kriegman	O
(	O
1997	O
)	O
,	O
we	O
use	O
sw	O
and	O
sb	O
to	O
denote	O
the	O
scatter	O
matrices	O
,	O
even	O
though	O
we	O
use	O
c	O
elsewhere	O
(	O
14.9	O
)	O
.	O
-2-1012-3-2-10123	O
676	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
where	O
n	O
=	O
nk	O
=	O
13	O
is	O
the	O
number	O
of	O
samples	O
in	O
each	O
class	O
.	O
to	O
compute	O
the	O
most	O
discriminating	O
direction	O
,	O
fisher	O
’	O
s	O
linear	B
discriminant	O
(	O
fld	O
)	O
(	O
bel-	O
humeur	O
,	O
hespanha	O
,	O
and	O
kriegman	O
1997	O
;	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
bishop	O
2006	O
)	O
,	O
which	O
is	O
also	O
known	O
as	O
linear	B
discriminant	O
analysis	O
(	O
lda	O
)	O
,	O
selects	O
the	O
direction	O
u	O
that	O
results	O
in	O
the	O
largest	O
ratio	O
between	O
the	O
projected	O
between-class	B
and	O
within-class	B
varia-	O
tions	O
u∗	O
=	O
arg	O
max	O
u	O
ut	O
sbu	O
ut	O
swu	O
,	O
(	O
14.20	O
)	O
which	O
is	O
equivalent	O
to	O
ﬁnding	O
the	O
eigenvector	O
corresponding	O
to	O
the	O
largest	O
eigenvalue	O
of	O
the	O
generalized	B
eigenvalue	O
problem	O
sbu	O
=	O
λswu	O
or	O
λu	O
=	O
s−1	O
w	O
sbu	O
.	O
for	O
the	O
problem	O
shown	O
in	O
figure	O
14.16	O
,	O
s−1	O
w	O
sb	O
=	O
(	O
cid:34	O
)	O
11.796	O
−0.289	O
0.3889	O
(	O
cid:35	O
)	O
−4.715	O
and	O
u	O
=	O
(	O
cid:34	O
)	O
0.926	O
−0.379	O
(	O
cid:35	O
)	O
(	O
14.21	O
)	O
(	O
14.22	O
)	O
as	O
you	O
can	O
see	O
,	O
using	O
this	O
direction	O
results	O
in	O
a	O
better	O
separation	O
between	O
the	O
classes	O
than	O
using	O
the	O
dominant	O
pca	O
direction	O
,	O
which	O
is	O
the	O
horizontal	O
axis	O
.	O
in	O
their	O
paper	O
,	O
belhumeur	O
,	O
hespanha	O
,	O
and	O
kriegman	O
(	O
1997	O
)	O
show	O
that	O
fisherfaces	O
signiﬁcantly	O
outperform	O
the	O
original	O
eigenfaces	O
algorithm	B
,	O
especially	O
when	O
faces	B
have	O
large	O
amounts	O
of	O
illumination	O
variation	O
,	O
as	O
in	O
figure	O
14.15.	O
an	O
alternative	O
for	O
modeling	O
within-class	B
(	O
intrapersonal	O
)	O
and	O
between-class	B
(	O
extraper-	O
sonal	O
)	O
variations	O
is	O
to	O
model	O
each	O
distribution	O
separately	O
and	O
then	O
use	O
bayesian	O
techniques	O
to	O
ﬁnd	O
the	O
closest	O
exemplar	O
(	O
moghaddam	O
,	O
jebara	O
,	O
and	O
pentland	O
2000	O
)	O
.	O
instead	O
of	O
computing	O
the	O
mean	O
for	O
each	O
class	O
and	O
then	O
the	O
within-class	B
and	O
between-class	B
distributions	O
,	O
consider	O
evaluating	O
the	O
difference	B
images	O
∆ij	O
=	O
xi	O
−	O
xj	O
(	O
14.23	O
)	O
between	O
all	O
pairs	B
of	O
training	O
images	O
(	O
xi	O
,	O
xj	O
)	O
.	O
the	O
differences	O
between	O
pairs	B
that	O
are	O
in	O
the	O
same	O
class	O
(	O
the	O
same	O
person	O
)	O
are	O
used	O
to	O
estimate	O
the	O
intrapersonal	O
covariance	O
matrix	O
σi	O
,	O
while	O
differences	O
between	O
different	O
people	O
are	O
used	O
to	O
estimate	O
the	O
extrapersonal	O
covariance	O
σe.12	O
the	O
principal	O
components	O
(	O
eigenfaces	O
)	O
corresponding	O
to	O
these	O
two	O
classes	O
are	O
shown	O
in	O
figure	O
14.17.	O
at	O
recognition	B
time	O
,	O
we	O
can	O
compute	O
the	O
distance	O
∆i	O
between	O
a	O
new	O
face	B
x	O
and	O
a	O
stored	O
training	O
image	B
xi	O
and	O
evaluate	O
its	O
intrapersonal	O
likelihood	O
as	O
pi	O
(	O
∆i	O
)	O
=	O
pn	O
(	O
∆i	O
;	O
σi	O
)	O
=	O
1	O
|2πσi|1/2	O
exp−	O
(	O
cid:107	O
)	O
∆i	O
(	O
cid:107	O
)	O
2	O
σ−1	O
i	O
,	O
(	O
14.24	O
)	O
12	O
note	O
that	O
the	O
difference	B
distributions	O
are	O
zero	O
mean	O
because	O
for	O
every	O
∆ij	O
there	O
corresponds	O
a	O
negative	O
∆ji	O
.	O
14.2	O
face	B
recognition	O
677	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.17	O
“	O
dual	O
”	O
eigenfaces	O
(	O
moghaddam	O
,	O
jebara	O
,	O
and	O
pentland	O
2000	O
)	O
c	O
(	O
cid:13	O
)	O
2000	O
elsevier	O
:	O
(	O
a	O
)	O
intrapersonal	O
and	O
(	O
b	O
)	O
extrapersonal	O
.	O
where	O
pn	O
is	O
a	O
normal	O
(	O
gaussian	O
)	O
distribution	O
with	O
covariance	O
σi	O
and	O
|2πσi|1/2	O
=	O
(	O
2π	O
)	O
m/2	O
λ1/2	O
j	O
m	O
(	O
cid:89	O
)	O
j=1	O
is	O
its	O
volume	O
.	O
the	O
mahalanobis	O
distance	O
(	O
cid:107	O
)	O
∆i	O
(	O
cid:107	O
)	O
2	O
σ−1	O
i	O
=	O
∆t	O
i	O
σ−1	O
i	O
∆i	O
=	O
(	O
cid:107	O
)	O
ai	O
−	O
ai	O
i	O
(	O
cid:107	O
)	O
2	O
(	O
14.25	O
)	O
(	O
14.26	O
)	O
can	O
be	O
computed	O
more	O
efﬁciently	O
by	O
ﬁrst	O
projecting	O
the	O
new	O
image	B
x	O
into	O
the	O
whitened	O
in-	O
trapersonal	O
face	B
space	O
(	O
14.15	O
)	O
ai	O
=	O
ˆu	O
i	O
x	O
(	O
14.27	O
)	O
and	O
then	O
computing	O
a	O
euclidean	O
distance	O
to	O
the	O
training	O
image	B
vector	O
ai	O
i	O
,	O
which	O
can	O
be	O
pre-	O
computed	O
ofﬂine	O
.	O
the	O
extrapersonal	O
likelihood	O
pe	O
(	O
∆i	O
)	O
can	O
be	O
computed	O
in	O
a	O
similar	O
fashion	O
.	O
once	O
the	O
intrapersonal	O
and	O
extrapersonal	O
likelihoods	O
have	O
been	O
computed	O
,	O
we	O
can	O
com-	O
pute	O
the	O
bayesian	O
likelihood	O
of	O
a	O
new	O
image	B
x	O
matching	B
a	O
training	O
image	B
xi	O
as	O
p	O
(	O
∆i	O
)	O
=	O
pi	O
(	O
∆i	O
)	O
li	O
pi	O
(	O
∆i	O
)	O
li	O
+	O
pe	O
(	O
∆i	O
)	O
le	O
,	O
(	O
14.28	O
)	O
where	O
li	O
and	O
le	O
are	O
the	O
prior	B
probabilities	O
of	O
two	O
images	O
being	O
in	O
the	O
same	O
or	O
in	O
different	O
classes	O
(	O
moghaddam	O
,	O
jebara	O
,	O
and	O
pentland	O
2000	O
)	O
.	O
a	O
simpler	O
approach	O
,	O
which	O
does	O
not	O
re-	O
quire	O
the	O
evaluation	B
of	O
extrapersonal	O
probabilities	O
,	O
is	O
to	O
simply	O
choose	O
the	O
training	O
image	B
with	O
678	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.18	O
modular	O
eigenspace	O
for	O
face	O
recognition	B
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
ieee	O
.	O
(	O
a	O
)	O
by	O
detecting	O
separate	O
features	O
in	O
the	O
faces	B
(	O
eyes	O
,	O
nose	O
,	O
mouth	O
)	O
,	O
separate	O
eigenspaces	O
can	O
be	O
estimated	O
for	O
each	O
one	O
.	O
(	O
b	O
)	O
the	O
relative	O
positions	O
of	O
each	O
feature	B
can	O
be	O
detected	O
at	O
recognition	B
time	O
,	O
thus	O
allowing	O
for	O
more	O
ﬂexibility	O
in	O
viewpoint	O
and	O
expression	O
.	O
the	O
highest	O
likelihood	O
pi	O
(	O
∆i	O
)	O
.	O
in	O
this	O
case	O
,	O
nearest	B
neighbor	I
search	O
techniques	O
in	O
the	O
space	O
i	O
}	O
vectors	O
could	O
be	O
used	O
to	O
speed	O
up	O
ﬁnding	O
the	O
best	O
match.13	O
spanned	O
by	O
the	O
precomputed	O
{	O
ai	O
another	O
way	O
to	O
improve	O
the	O
performance	O
of	O
eigenface-based	O
approaches	O
is	O
to	O
break	O
up	O
the	O
image	B
into	O
separate	O
regions	O
such	O
as	O
the	O
eyes	O
,	O
nose	O
,	O
and	O
mouth	O
(	O
figure	O
14.18	O
)	O
and	O
to	O
match	O
each	O
of	O
these	O
modular	O
eigenspaces	O
independently	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
;	O
heisele	O
,	O
ho	O
,	O
wu	O
et	O
al	O
.	O
2003	O
;	O
heisele	O
,	O
serre	O
,	O
and	O
poggio	O
2007	O
)	O
.	O
the	O
advantage	O
of	O
such	O
a	O
modular	O
approach	O
is	O
that	O
it	O
can	O
tolerate	O
a	O
wider	O
range	O
of	O
viewpoints	O
,	O
because	O
each	O
part	O
can	O
move	O
relative	O
to	O
the	O
others	O
.	O
it	O
also	O
supports	O
a	O
larger	O
variety	O
of	O
combinations	O
,	O
e.g.	O
,	O
we	O
can	O
model	O
one	O
person	O
as	O
having	O
a	O
narrow	O
nose	O
and	O
bushy	O
eyebrows	O
,	O
without	O
requiring	O
the	O
eigenfaces	O
to	O
span	O
all	O
possible	O
combinations	O
of	O
nose	O
,	O
mouth	O
,	O
and	O
eyebrows	O
.	O
(	O
if	O
you	O
remember	O
the	O
cardboard	O
children	O
’	O
s	O
books	O
where	O
you	O
can	O
select	O
different	O
top	O
and	O
bottom	O
faces	B
,	O
or	O
mr.	O
potato	O
head	B
,	O
you	O
get	O
the	O
idea	O
.	O
)	O
another	O
approach	O
to	O
dealing	O
with	O
large	O
variability	O
in	O
appearance	O
is	O
to	O
create	O
view-based	O
(	O
view-speciﬁc	O
)	O
eigenspaces	O
,	O
as	O
shown	O
in	O
figure	O
14.19	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
.	O
we	O
can	O
think	O
of	O
these	O
view-based	O
eigenspaces	O
as	O
local	B
descriptors	O
that	O
select	O
different	O
axes	O
de-	O
pending	O
on	O
which	O
part	O
of	O
the	O
face	B
space	O
you	O
are	O
in	O
.	O
note	O
that	O
such	O
approaches	O
,	O
however	O
,	O
potentially	O
require	O
large	O
amounts	O
of	O
training	O
data	O
,	O
i.e.	O
,	O
pictures	O
of	O
every	O
person	O
in	O
every	O
pos-	O
sible	O
pose	O
or	O
expression	O
.	O
this	O
is	O
in	O
contrast	O
to	O
the	O
shape	O
and	O
appearance	O
models	O
we	O
study	O
in	O
13	O
note	O
that	O
while	O
the	O
covariance	O
matrices	O
σi	O
and	O
σe	O
are	O
computed	O
by	O
looking	O
at	O
differences	O
between	O
all	O
pairs	B
of	O
images	O
,	O
the	O
run-time	O
evaluation	B
selects	O
the	O
nearest	O
image	O
to	O
determine	O
the	O
facial	O
identity	O
.	O
whether	O
this	O
is	O
statistically	O
correct	O
is	O
explored	O
in	O
exercise	O
14.4	O
.	O
14.2	O
face	B
recognition	O
679	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.19	O
view-based	O
eigenspace	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
c	O
(	O
cid:13	O
)	O
1997	O
ieee	O
.	O
(	O
a	O
)	O
comparison	O
between	O
a	O
regular	O
(	O
parametric	B
)	O
eigenspace	O
reconstruction	O
(	O
middle	O
column	O
)	O
and	O
a	O
view-based	O
eigenspace	O
reconstruction	O
(	O
right	O
column	O
)	O
corresponding	O
to	O
the	O
input	O
image	B
(	O
left	O
column	O
)	O
.	O
the	O
top	O
row	O
is	O
from	O
a	O
training	O
image	B
,	O
the	O
bottom	O
row	O
is	O
from	O
the	O
test	O
set	O
.	O
(	O
b	O
)	O
a	O
schematic	O
representation	O
of	O
the	O
two	O
approaches	O
,	O
showing	O
how	O
each	O
view	O
computes	O
its	O
own	O
local	B
basis	O
representation	O
.	O
section	O
14.2.2	O
,	O
which	O
can	O
learn	O
deformations	O
across	O
all	O
individuals	O
.	O
it	O
is	O
also	O
possible	O
to	O
generalize	O
the	O
bilinear	B
factorization	O
implicit	O
in	O
pca	O
and	O
svd	O
ap-	O
proaches	O
to	O
multilinear	O
(	O
tensor	O
)	O
formulations	O
that	O
can	O
model	O
several	O
interacting	O
factors	O
si-	O
multaneously	O
(	O
vasilescu	O
and	O
terzopoulos	O
2007	O
)	O
.	O
these	O
ideas	O
are	O
related	O
to	O
currently	O
active	O
topics	O
in	O
machine	O
learning	O
such	O
as	O
subspace	O
learning	B
(	O
cai	O
,	O
he	O
,	O
hu	O
et	O
al	O
.	O
2007	O
)	O
,	O
local	B
distance	O
functions	O
(	O
frome	O
,	O
singer	O
,	O
sha	O
et	O
al	O
.	O
2007	O
)	O
,	O
and	O
metric	O
learning	B
(	O
ramanan	O
and	O
baker	O
2009	O
)	O
.	O
learning	B
approaches	O
play	O
an	O
increasingly	O
important	O
role	O
in	O
face	B
recognition	O
,	O
e.g.	O
,	O
in	O
the	O
work	O
of	O
sivic	O
,	O
everingham	O
,	O
and	O
zisserman	O
(	O
2009	O
)	O
and	O
guillaumin	O
,	O
verbeek	O
,	O
and	O
schmid	O
(	O
2009	O
)	O
.	O
14.2.2	O
active	O
appearance	O
and	O
3d	O
shape	O
models	O
the	O
need	O
to	O
use	O
modular	O
or	O
view-based	O
eigenspaces	O
for	O
face	O
recognition	B
is	O
symptomatic	O
of	O
a	O
more	O
general	O
observation	O
,	O
i.e.	O
,	O
that	O
facial	O
appearance	O
and	O
identiﬁability	O
depend	O
as	O
much	O
on	O
shape	O
as	O
they	O
do	O
on	O
color	B
or	O
texture	B
(	O
which	O
is	O
what	O
eigenfaces	O
capture	O
)	O
.	O
furthermore	O
,	O
when	O
dealing	O
with	O
3d	O
head	B
rotations	O
,	O
the	O
pose	O
of	O
a	O
person	O
’	O
s	O
head	B
should	O
be	O
discounted	O
when	O
performing	O
recognition	B
.	O
in	O
fact	O
,	O
the	O
earliest	O
face	B
recognition	O
systems	O
,	O
such	O
as	O
those	O
by	O
fischler	O
and	O
elschlager	O
(	O
1973	O
)	O
,	O
kanade	O
(	O
1977	O
)	O
,	O
and	O
yuille	O
(	O
1991	O
)	O
,	O
found	O
distinctive	O
feature	B
points	O
on	O
facial	O
images	O
and	O
performed	O
recognition	B
on	O
the	O
basis	O
of	O
their	O
relative	O
positions	O
or	O
distances	O
.	O
newer	O
tech-	O
niques	O
such	O
as	O
local	B
feature	I
analysis	I
(	O
penev	O
and	O
atick	O
1996	O
)	O
and	O
elastic	O
bunch	O
graph	O
match-	O
ing	O
(	O
wiskott	O
,	O
fellous	O
,	O
kr¨uger	O
et	O
al	O
.	O
1997	O
)	O
combine	O
local	B
ﬁlter	O
responses	O
(	O
jets	O
)	O
at	O
distinctive	O
680	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
14.20	O
manipulating	O
facial	O
appearance	O
through	O
shape	O
and	O
color	B
(	O
rowland	O
and	O
perrett	O
1995	O
)	O
c	O
(	O
cid:13	O
)	O
1995	O
ieee	O
.	O
by	O
adding	O
or	O
subtracting	O
gender-speciﬁc	O
shape	O
and	O
color	B
characteristics	O
to	O
(	O
b	O
)	O
an	O
input	O
image	B
,	O
different	O
amounts	O
of	O
gender	O
variation	O
can	O
be	O
induced	O
.	O
the	O
amounts	O
added	O
(	O
from	O
the	O
mean	O
)	O
are	O
:	O
(	O
a	O
)	O
+50	O
%	O
(	O
gender	O
enhancement	O
)	O
,	O
(	O
c	O
)	O
-50	O
%	O
(	O
near	O
“	O
androgyny	O
”	O
)	O
,	O
(	O
d	O
)	O
-100	O
%	O
(	O
gender	O
switched	O
)	O
,	O
and	O
(	O
e	O
)	O
-150	O
%	O
(	O
opposite	O
gender	O
attributes	O
enhanced	O
)	O
.	O
feature	B
locations	O
together	O
with	O
shape	O
models	O
to	O
perform	O
recognition	B
.	O
a	O
visually	O
compelling	O
example	O
of	O
why	O
both	O
shape	O
and	O
texture	B
are	O
important	O
is	O
the	O
work	O
of	O
rowland	O
and	O
perrett	O
(	O
1995	O
)	O
,	O
who	O
manually	O
traced	O
the	O
contours	O
of	O
facial	O
features	O
and	O
then	O
used	O
these	O
contours	O
to	O
normalize	O
(	O
warp	O
)	O
each	O
image	B
to	O
a	O
canonical	O
shape	O
.	O
after	O
analyzing	O
both	O
the	O
shape	O
and	O
color	B
images	O
for	O
deviations	O
from	O
the	O
mean	O
,	O
they	O
were	O
able	O
to	O
associate	O
certain	O
shape	O
and	O
color	B
deformations	O
with	O
personal	O
characteristics	O
such	O
as	O
age	O
and	O
gender	O
(	O
figure	O
14.20	O
)	O
.	O
their	O
work	O
demonstrates	O
that	O
both	O
shape	O
and	O
color	B
have	O
an	O
important	O
inﬂu-	O
ence	O
on	O
the	O
perception	O
of	O
such	O
characteristics	O
.	O
around	O
the	O
same	O
time	O
,	O
researchers	O
in	O
computer	O
vision	O
were	O
beginning	O
to	O
use	O
simultane-	O
ous	O
shape	O
deformations	O
and	O
texture	B
interpolation	O
to	O
model	O
the	O
variability	O
in	O
facial	O
appearance	O
caused	O
by	O
identity	O
or	O
expression	O
(	O
beymer	O
1996	O
;	O
vetter	O
and	O
poggio	O
1997	O
)	O
,	O
developing	O
tech-	O
niques	O
such	O
as	O
active	O
shape	O
models	O
(	O
lanitis	O
,	O
taylor	O
,	O
and	O
cootes	O
1997	O
)	O
,	O
3d	O
morphable	O
mod-	O
els	O
(	O
blanz	O
and	O
vetter	O
1999	O
)	O
,	O
and	O
elastic	B
bunch	I
graph	I
matching	I
(	O
wiskott	O
,	O
fellous	O
,	O
kr¨uger	O
et	O
al	O
.	O
1997	O
)	O
.14	O
of	O
all	O
these	O
techniques	O
,	O
the	O
active	O
appearance	O
models	O
(	O
aams	O
)	O
of	O
cootes	O
,	O
edwards	O
,	O
and	O
taylor	O
(	O
2001	O
)	O
are	O
among	O
the	O
most	O
widely	O
used	O
for	O
face	O
recognition	B
and	O
tracking	O
.	O
like	O
other	O
shape	O
and	O
texture	B
models	O
,	O
an	O
aam	O
models	O
both	O
the	O
variation	O
in	O
the	O
shape	O
of	O
an	O
image	B
s	O
,	O
which	O
is	O
normally	O
encoded	O
by	O
the	O
location	O
of	O
key	O
feature	B
points	O
on	O
the	O
image	B
(	O
figure	O
14.21b	O
)	O
,	O
14	O
we	O
have	O
already	O
seen	O
the	O
application	O
of	O
pca	O
to	O
3d	O
head	B
and	O
face	B
modeling	I
and	O
animation	O
in	O
section	O
12.6.3	O
.	O
14.2	O
face	B
recognition	O
681	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
14.21	O
active	O
appearance	O
models	O
(	O
cootes	O
,	O
edwards	O
,	O
and	O
taylor	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
input	O
image	B
with	O
registered	O
feature	B
points	O
;	O
(	O
b	O
)	O
the	O
feature	B
points	O
(	O
shape	O
vector	O
s	O
)	O
;	O
(	O
c	O
)	O
the	O
shape-free	O
appearance	O
image	B
(	O
texture	B
vector	O
t	O
)	O
.	O
as	O
well	O
as	O
the	O
variation	O
in	O
texture	B
t	O
,	O
which	O
is	O
normalized	B
to	O
a	O
canonical	O
shape	O
before	O
being	O
analyzed	O
(	O
figure	O
14.21c	O
)	O
.15	O
both	O
shape	O
and	O
texture	B
are	O
represented	O
as	O
deviations	O
from	O
a	O
mean	O
shape	O
¯s	O
and	O
texture	B
¯t	O
,	O
s	O
=	O
¯s	O
+	O
u	O
sa	O
t	O
=	O
¯t	O
+	O
u	O
ta	O
,	O
(	O
14.29	O
)	O
(	O
14.30	O
)	O
where	O
the	O
eigenvectors	O
in	O
u	O
s	O
and	O
u	O
t	O
have	O
been	O
pre-scaled	O
(	O
whitened	O
)	O
so	O
that	O
unit	O
vectors	O
in	O
a	O
represent	O
one	O
standard	O
deviation	O
of	O
variation	O
observed	O
in	O
the	O
training	O
data	O
.	O
in	O
addition	O
to	O
these	O
principal	O
deformations	O
,	O
the	O
shape	O
parameters	O
are	O
transformed	O
by	O
a	O
global	B
similarity	O
to	O
match	O
the	O
location	O
,	O
size	O
,	O
and	O
orientation	O
of	O
a	O
given	O
face	B
.	O
similarly	O
,	O
the	O
texture	B
image	O
contains	O
a	O
scale	O
and	O
offset	O
to	O
best	O
match	O
novel	O
illumination	O
conditions	O
.	O
as	O
you	O
can	O
see	O
,	O
the	O
same	O
appearance	O
parameters	B
a	O
in	O
(	O
14.29–14.30	O
)	O
simultaneously	O
con-	O
trol	O
both	O
the	O
shape	O
and	O
texture	B
deformations	O
from	O
the	O
mean	O
,	O
which	O
makes	O
sense	O
if	O
we	O
believe	O
them	O
to	O
be	O
correlated	O
.	O
figure	O
14.22	O
shows	O
how	O
moving	O
three	O
standard	O
deviations	O
along	O
each	O
of	O
the	O
ﬁrst	O
four	O
principal	O
directions	O
ends	O
up	O
changing	O
several	O
correlated	O
factors	O
in	O
a	O
person	O
’	O
s	O
appearance	O
,	O
including	O
expression	O
,	O
gender	O
,	O
age	O
,	O
and	O
identity	O
.	O
in	O
order	B
to	O
ﬁt	O
an	O
active	B
appearance	I
model	I
to	O
a	O
novel	O
image	B
,	O
cootes	O
,	O
edwards	O
,	O
and	O
taylor	O
(	O
2001	O
)	O
pre-compute	O
a	O
set	O
of	O
“	O
difference	B
decomposition	O
”	O
images	O
,	O
using	O
an	O
approach	O
related	O
to	O
other	O
fast	O
techniques	O
for	O
incremental	O
tracking	O
,	O
such	O
as	O
those	O
we	O
discussed	O
in	O
sections	O
4.1.4	O
,	O
8.1.3	O
,	O
and	O
8.2	O
(	O
gleicher	O
1997	O
;	O
hager	O
and	O
belhumeur	O
1998	O
)	O
,	O
which	O
often	O
learn	O
a	O
discrimi-	O
native	O
mapping	O
between	O
matching	B
errors	O
and	O
incremental	B
displacements	O
(	O
avidan	O
2001	O
;	O
jurie	O
and	O
dhome	O
2002	O
;	O
liu	O
,	O
chen	O
,	O
and	O
kumar	O
2003	O
;	O
sclaroff	O
and	O
isidoro	O
2003	O
;	O
romdhani	O
and	O
vetter	O
2003	O
;	O
williams	O
,	O
blake	O
,	O
and	O
cipolla	O
2003	O
)	O
.	O
15	O
when	O
only	O
the	O
shape	O
variation	O
is	O
being	O
captured	O
,	O
such	O
models	O
are	O
called	O
active	O
shape	O
models	O
(	O
asms	O
)	O
(	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
;	O
davies	O
,	O
twining	O
,	O
and	O
taylor	O
2008	O
)	O
.	O
these	O
were	O
already	O
discussed	O
in	O
section	O
5.1.1	O
(	O
5.13–5.17	O
)	O
.	O
682	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
figure	O
14.22	O
principal	O
modes	O
of	O
variation	O
in	O
active	O
appearance	O
models	O
(	O
cootes	O
,	O
edwards	O
,	O
and	O
taylor	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
.	O
the	O
four	O
images	O
show	O
the	O
effects	O
of	O
simultaneously	O
changing	O
the	O
ﬁrst	O
four	O
modes	O
of	O
variation	O
in	O
both	O
shape	O
and	O
texture	B
by	O
±σ	O
from	O
the	O
mean	O
.	O
you	O
can	O
clearly	O
see	O
how	O
the	O
shape	O
of	O
the	O
face	B
and	O
the	O
shading	B
are	O
simultaneously	O
affected	O
.	O
in	O
more	O
detail	O
,	O
cootes	O
,	O
edwards	O
,	O
and	O
taylor	O
(	O
2001	O
)	O
compute	O
the	O
derivatives	O
of	O
a	O
set	O
of	O
training	O
images	O
with	O
respect	O
to	O
each	O
of	O
the	O
parameters	B
in	O
a	O
using	O
ﬁnite	O
differences	O
and	O
then	O
compute	O
a	O
set	O
of	O
displacement	O
weight	O
images	O
w	O
=	O
(	O
cid:20	O
)	O
∂xt	O
∂a	O
∂x	O
∂a	O
(	O
cid:21	O
)	O
−1	O
∂xt	O
∂a	O
,	O
(	O
14.31	O
)	O
which	O
can	O
be	O
multiplied	O
by	O
the	O
current	O
error	O
residual	O
to	O
produce	O
an	O
update	O
step	O
in	O
the	O
pa-	O
rameters	O
,	O
δa	O
=	O
−w	O
r.	O
matthews	O
and	O
baker	O
(	O
2004	O
)	O
use	O
their	O
inverse	B
compositional	O
method	O
,	O
which	O
they	O
ﬁrst	O
developed	O
for	O
parametric	O
optical	B
ﬂow	I
(	O
8.64–8.65	O
)	O
,	O
to	O
further	O
speed	O
up	O
active	O
appearance	O
model	O
ﬁtting	O
and	O
tracking	O
.	O
examples	B
of	O
aams	O
being	O
ﬁtted	O
to	O
two	O
input	O
images	O
are	O
shown	O
in	O
figure	O
14.23.	O
although	O
active	O
appearance	O
models	O
are	O
primarily	O
designed	O
to	O
accurately	O
capture	O
the	O
vari-	O
ability	O
in	O
appearance	O
and	O
deformation	O
that	O
are	O
characteristic	O
of	O
faces	B
,	O
they	O
can	O
be	O
adapted	O
to	O
face	B
recognition	O
by	O
computing	O
an	O
identity	O
subspace	O
that	O
separates	O
variation	O
in	O
identity	O
from	O
other	O
sources	O
of	O
variability	O
such	O
as	O
lighting	B
,	O
pose	O
,	O
and	O
expression	O
(	O
costen	O
,	O
cootes	O
,	O
edwards	O
et	O
al	O
.	O
1999	O
)	O
.	O
the	O
basic	O
idea	O
,	O
which	O
is	O
modeled	O
after	O
similar	O
work	O
in	O
eigenfaces	O
(	O
belhumeur	O
,	O
hespanha	O
,	O
and	O
kriegman	O
1997	O
;	O
moghaddam	O
,	O
jebara	O
,	O
and	O
pentland	O
2000	O
)	O
,	O
is	O
to	O
compute	O
sep-	O
arate	O
statistics	O
for	O
intrapersonal	O
and	O
extrapersonal	O
variation	O
and	O
then	O
ﬁnd	O
discriminating	O
di-	O
rections	O
in	O
these	O
subspaces	O
.	O
while	O
aams	O
have	O
sometimes	O
been	O
used	O
directly	O
for	B
recognition	I
(	O
blanz	O
and	O
vetter	O
2003	O
)	O
,	O
their	O
main	O
use	O
in	O
the	O
context	B
of	O
recognition	B
is	O
to	O
align	O
faces	B
into	O
a	O
canonical	O
pose	O
(	O
liang	O
,	O
xiao	O
,	O
wen	O
et	O
al	O
.	O
2008	O
)	O
so	O
that	O
more	O
traditional	O
methods	O
of	O
face	B
14.2	O
face	B
recognition	O
683	O
figure	O
14.23	O
multiresolution	O
model	O
ﬁtting	O
(	O
search	O
)	O
in	O
active	O
appearance	O
models	O
(	O
cootes	O
,	O
edwards	O
,	O
and	O
taylor	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
.	O
the	O
columns	O
show	O
the	O
initial	O
model	O
,	O
the	O
results	O
after	O
3	O
,	O
8	O
,	O
and	O
11	O
iterations	O
,	O
and	O
the	O
ﬁnal	O
convergence	O
.	O
the	O
rightmost	O
column	O
shows	O
the	O
input	O
image	B
.	O
recognition	B
(	O
penev	O
and	O
atick	O
1996	O
;	O
wiskott	O
,	O
fellous	O
,	O
kr¨uger	O
et	O
al	O
.	O
1997	O
;	O
ahonen	O
,	O
hadid	O
,	O
and	O
pietik¨ainen	O
2006	O
;	O
zhao	O
and	O
pietik¨ainen	O
2007	O
;	O
cao	O
,	O
yin	O
,	O
tang	O
et	O
al	O
.	O
2010	O
)	O
can	O
be	O
used	O
.	O
aams	O
(	O
or	O
,	O
actually	O
,	O
their	O
simpler	O
version	O
,	O
active	O
shape	O
models	O
(	O
asms	O
)	O
)	O
can	O
also	O
be	O
used	O
to	O
align	O
face	B
images	O
to	O
perform	O
automated	B
morphing	O
(	O
zanella	O
and	O
fuentes	O
2004	O
)	O
.	O
active	O
appearance	O
models	O
continue	O
to	O
be	O
an	O
active	O
research	O
area	O
,	O
with	O
enhancements	O
to	O
deal	O
with	O
illumination	O
and	O
viewpoint	O
variation	O
(	O
gross	O
,	O
baker	O
,	O
matthews	O
et	O
al	O
.	O
2005	O
)	O
as	O
well	O
as	O
occlusions	O
(	O
gross	O
,	O
matthews	O
,	O
and	O
baker	O
2006	O
)	O
.	O
one	O
of	O
the	O
most	O
signiﬁcant	O
extensions	O
is	O
to	O
construct	O
3d	O
models	O
of	O
shape	O
(	O
matthews	O
,	O
xiao	O
,	O
and	O
baker	O
2007	O
)	O
,	O
which	O
are	O
much	O
better	O
at	O
capturing	O
and	O
explaining	O
the	O
full	O
variability	O
of	O
facial	O
appearance	O
across	O
wide	O
changes	O
in	O
pose	O
.	O
figure	O
14.24	O
head	B
tracking	I
with	O
3d	O
aams	O
(	O
matthews	O
,	O
xiao	O
,	O
and	O
baker	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
springer	O
.	O
each	O
image	B
shows	O
a	O
video	B
frame	O
along	O
with	O
the	O
estimate	O
yaw	O
,	O
pitch	O
,	O
and	O
roll	O
parameters	B
and	O
the	O
ﬁtted	O
3d	O
deformable	O
mesh	O
.	O
684	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.25	O
person	O
detection	B
and	O
re-recognition	O
using	O
a	O
combined	O
face	B
,	O
hair	O
,	O
and	O
torso	O
model	O
(	O
sivic	O
,	O
zitnick	O
,	O
and	O
szeliski	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
.	O
(	O
a	O
)	O
using	O
face	O
detection	B
alone	O
,	O
(	O
b	O
)	O
the	O
combined	O
face	B
and	O
clothing	O
model	O
successfully	O
several	O
of	O
the	O
heads	O
are	O
missed	O
.	O
re-ﬁnds	O
all	O
the	O
people	O
.	O
such	O
models	O
can	O
be	O
constructed	O
either	O
from	O
monocular	O
video	B
sequences	O
(	O
matthews	O
,	O
xiao	O
,	O
and	O
baker	O
2007	O
)	O
,	O
as	O
shown	O
in	O
figure	O
14.24	O
,	O
or	O
from	O
multi-view	B
video	O
sequences	O
(	O
ramnath	O
,	O
koterba	O
,	O
xiao	O
et	O
al	O
.	O
2008	O
)	O
,	O
which	O
provide	O
even	O
greater	O
reliability	O
and	O
accuracy	B
in	O
reconstruc-	O
tion	B
and	O
tracking	O
.	O
(	O
for	O
a	O
recent	O
review	O
of	O
progress	O
in	O
head	B
pose	O
estimation	B
,	O
please	O
see	O
the	O
survey	O
paper	O
by	O
murphy-chutorian	O
and	O
trivedi	O
(	O
2009	O
)	O
.	O
)	O
14.2.3	O
application	O
:	O
personal	O
photo	O
collections	O
in	O
addition	O
to	O
digital	O
cameras	O
automatically	O
ﬁnding	O
faces	B
to	O
aid	O
in	O
auto-focusing	O
and	O
video	B
cameras	O
ﬁnding	O
faces	B
in	O
video	B
conferencing	O
to	O
center	O
on	O
the	O
speaker	O
(	O
either	O
mechanically	O
or	O
digitally	O
)	O
,	O
face	B
detection	O
has	O
found	O
its	O
way	O
into	O
most	O
consumer-level	O
photo	O
organization	O
packages	O
,	O
such	O
as	O
iphoto	O
,	O
picasa	O
,	O
and	O
windows	O
live	O
photo	O
gallery	O
.	O
finding	O
faces	B
and	O
al-	O
lowing	O
users	O
to	O
tag	O
them	O
makes	O
it	O
easier	O
to	O
ﬁnd	O
photos	O
of	O
selected	O
people	O
at	O
a	O
later	O
date	O
or	O
to	O
automatically	O
share	O
them	O
with	O
friends	O
.	O
in	O
fact	O
,	O
the	O
ability	O
to	O
tag	O
friends	O
in	O
photos	O
is	O
one	O
of	O
the	O
more	O
popular	O
features	O
on	O
facebook	O
.	O
sometimes	O
,	O
however	O
,	O
faces	B
can	O
be	O
hard	O
to	O
ﬁnd	O
and	O
recognize	O
,	O
especially	O
if	O
they	O
are	O
small	O
,	O
14.3	O
instance	B
recognition	O
685	O
figure	O
14.26	O
recognizing	O
objects	O
in	O
a	O
cluttered	O
scene	O
(	O
lowe	O
2004	O
)	O
c	O
(	O
cid:13	O
)	O
2004	O
springer	O
.	O
two	O
of	O
the	O
training	O
images	O
in	O
the	O
database	O
are	O
shown	O
on	O
the	O
left	O
.	O
they	O
are	O
matched	O
to	O
the	O
cluttered	O
scene	O
in	O
the	O
middle	O
using	O
sift	O
features	O
,	O
shown	O
as	O
small	O
squares	O
in	O
the	O
right	O
image	B
.	O
the	O
afﬁne	B
warp	O
of	O
each	O
recognized	O
database	O
image	B
onto	O
the	O
scene	O
is	O
shown	O
as	O
a	O
larger	O
parallelogram	O
in	O
the	O
right	O
image	B
.	O
turned	O
away	O
from	O
the	O
camera	B
,	O
or	O
otherwise	O
occluded	O
.	O
in	O
such	O
cases	O
,	O
combining	O
face	B
recog-	O
nition	O
with	O
person	O
detection	B
and	O
clothes	O
recognition	B
can	O
be	O
very	O
effective	O
,	O
as	O
illustrated	O
in	O
figure	O
14.25	O
(	O
sivic	O
,	O
zitnick	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
combining	O
person	O
recognition	B
with	O
other	O
kinds	O
of	O
context	B
,	O
such	O
as	O
location	B
recognition	I
(	O
section	O
14.3.3	O
)	O
or	O
activity	O
or	O
event	O
recognition	B
,	O
can	O
also	O
help	O
boost	O
performance	O
(	O
lin	O
,	O
kapoor	O
,	O
hua	O
et	O
al	O
.	O
2010	O
)	O
.	O
14.3	O
instance	B
recognition	O
general	O
object	O
recognition	B
falls	O
into	O
two	O
broad	O
categories	O
,	O
namely	O
instance	B
recognition	O
and	O
class	O
recognition	B
.	O
the	O
former	O
involves	O
re-recognizing	O
a	O
known	O
2d	O
or	O
3d	O
rigid	O
object	O
,	O
poten-	O
tially	O
being	O
viewed	O
from	O
a	O
novel	O
viewpoint	O
,	O
against	O
a	O
cluttered	O
background	O
,	O
and	O
with	O
partial	O
occlusions	O
.	O
the	O
latter	O
,	O
which	O
is	O
also	O
known	O
as	O
category-level	O
or	O
generic	O
object	O
recognition	B
(	O
ponce	O
,	O
hebert	O
,	O
schmid	O
et	O
al	O
.	O
2006	O
)	O
,	O
is	O
the	O
much	O
more	O
challenging	O
problem	O
of	O
recognizing	O
any	O
instance	B
of	O
a	O
particular	O
general	O
class	O
such	O
as	O
“	O
cat	O
”	O
,	O
“	O
car	B
”	O
,	O
or	O
“	O
bicycle	O
”	O
.	O
over	O
the	O
years	O
,	O
many	O
different	O
algorithms	O
have	O
been	O
developed	O
for	O
instance	O
recognition	B
.	O
mundy	O
(	O
2006	O
)	O
surveys	B
earlier	O
approaches	O
,	O
which	O
focused	O
on	O
extracting	O
lines	B
,	O
contours	O
,	O
or	O
3d	O
surfaces	O
from	O
images	O
and	O
matching	B
them	O
to	O
known	O
3d	O
object	O
models	O
.	O
another	O
popu-	O
lar	O
approach	O
was	O
to	O
acquire	O
images	O
from	O
a	O
large	O
set	O
of	O
viewpoints	O
and	O
illuminations	O
and	O
to	O
represent	O
them	O
using	O
an	O
eigenspace	O
decomposition	O
(	O
murase	O
and	O
nayar	O
1995	O
)	O
.	O
more	O
recent	O
approaches	O
(	O
lowe	O
2004	O
;	O
rothganger	O
,	O
lazebnik	O
,	O
schmid	O
et	O
al	O
.	O
2006	O
;	O
ferrari	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
2006b	O
;	O
gordon	O
and	O
lowe	O
2006	O
;	O
obdrˇz´alek	O
and	O
matas	O
2006	O
;	O
sivic	O
and	O
zisserman	O
2009	O
)	O
tend	O
to	O
use	O
viewpoint-invariant	O
2d	O
features	O
,	O
such	O
as	O
those	O
we	O
saw	O
in	O
section	O
4.1.2.	O
af-	O
686	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ter	O
extracting	O
informative	O
sparse	B
2d	O
features	O
from	O
both	O
the	O
new	O
image	B
and	O
the	O
images	O
in	O
the	O
database	O
,	O
image	B
features	O
are	O
matched	O
against	O
the	O
object	O
database	O
,	O
using	O
one	O
of	O
the	O
sparse	B
fea-	O
ture	O
matching	B
strategies	O
described	O
in	O
section	O
4.1.3.	O
whenever	O
a	O
sufﬁcient	O
number	O
of	O
matches	O
have	O
been	O
found	O
,	O
they	O
are	O
veriﬁed	O
by	O
ﬁnding	O
a	O
geometric	B
transformation	O
that	O
aligns	O
the	O
two	O
sets	O
of	O
features	O
(	O
figure	O
14.26	O
)	O
.	O
below	O
,	O
we	O
describe	O
some	O
of	O
the	O
techniques	O
that	O
have	O
been	O
proposed	O
for	O
representing	O
the	O
geometric	B
relationships	O
between	O
such	O
features	O
(	O
section	O
14.3.1	O
)	O
.	O
we	O
also	O
discuss	O
how	O
to	O
make	O
the	O
feature	B
matching	O
process	O
more	O
efﬁcient	O
using	O
ideas	O
from	O
text	O
and	O
information	O
retrieval	O
(	O
section	O
14.3.2	O
)	O
.	O
14.3.1	O
geometric	B
alignment	I
to	O
recognize	O
one	O
or	O
more	O
instances	O
of	O
some	O
known	O
objects	O
,	O
such	O
as	O
those	O
shown	O
in	O
the	O
left	O
column	O
of	O
figure	O
14.26	O
,	O
the	O
recognition	B
system	O
ﬁrst	O
extracts	O
a	O
set	O
of	O
interest	O
points	B
in	O
each	O
database	O
image	B
and	O
stores	O
the	O
associated	O
descriptors	O
(	O
and	O
original	O
positions	O
)	O
in	O
an	O
indexing	O
structure	O
such	O
as	O
a	O
search	O
tree	O
(	O
section	O
4.1.3	O
)	O
.	O
at	O
recognition	B
time	O
,	O
features	O
are	O
extracted	O
from	O
the	O
new	O
image	B
and	O
compared	O
against	O
the	O
stored	O
object	O
features	O
.	O
whenever	O
a	O
sufﬁcient	O
number	O
of	O
matching	B
features	O
(	O
say	O
,	O
three	O
or	O
more	O
)	O
are	O
found	O
for	O
a	O
given	O
object	O
,	O
the	O
system	O
then	O
invokes	O
a	O
match	B
veriﬁcation	I
stage	O
,	O
whose	O
job	O
is	O
to	O
determine	O
whether	O
the	O
spatial	O
arrangement	O
of	O
matching	B
features	O
is	O
consistent	O
with	O
those	O
in	O
the	O
database	O
image	B
.	O
because	O
images	O
can	O
be	O
highly	O
cluttered	O
and	O
similar	O
features	O
may	O
belong	O
to	O
several	O
objects	O
,	O
the	O
original	O
set	O
of	O
feature	B
matches	O
can	O
have	O
a	O
large	O
number	O
of	O
outliers	O
.	O
for	O
this	O
reason	O
,	O
lowe	O
(	O
2004	O
)	O
suggests	O
using	O
a	O
hough	O
transform	B
(	O
section	O
4.3.2	O
)	O
to	O
accumulate	O
votes	O
for	O
likely	O
geo-	O
metric	O
transformations	O
.	O
in	O
his	O
system	O
,	O
he	O
uses	O
an	O
afﬁne	B
transformation	O
between	O
the	O
database	O
object	O
and	O
the	O
collection	O
of	O
scene	O
features	O
,	O
which	O
works	O
well	O
for	O
objects	O
that	O
are	O
mostly	O
pla-	O
nar	O
,	O
or	O
where	O
at	O
least	O
several	O
corresponding	O
features	O
share	O
a	O
quasi-planar	O
geometry.16	O
since	O
sift	O
features	O
carry	O
with	O
them	O
their	O
own	O
location	O
,	O
scale	O
,	O
and	O
orientation	O
,	O
lowe	O
uses	O
a	O
four-dimensional	O
similarity	B
transformation	O
as	O
the	O
original	O
hough	O
binning	O
structure	O
,	O
i.e.	O
,	O
each	O
bin	O
denotes	O
a	O
particular	O
location	O
for	O
the	O
object	O
center	O
,	O
scale	O
,	O
and	O
in-plane	O
rotation	O
.	O
each	O
matching	B
feature	O
votes	O
for	O
the	O
nearest	O
24	O
bins	O
and	O
peaks	O
in	O
the	O
transform	B
are	O
then	O
selected	O
for	O
a	O
more	O
careful	O
afﬁne	B
motion	O
ﬁt	O
.	O
figure	O
14.26	O
(	O
right	O
image	B
)	O
shows	O
three	O
instances	O
of	O
the	O
two	O
objects	O
on	O
the	O
left	O
that	O
were	O
recognized	O
by	O
the	O
system	O
.	O
obdrˇz´alek	O
and	O
matas	O
(	O
2006	O
)	O
general-	O
ize	O
lowe	O
’	O
s	O
approach	O
to	O
use	O
feature	B
descriptors	O
with	O
full	O
local	B
afﬁne	O
frames	O
and	O
evaluate	O
their	O
approach	O
on	O
a	O
number	O
of	O
object	O
recognition	B
databases	O
.	O
another	O
system	O
that	O
uses	O
local	B
afﬁne	O
frames	O
is	O
the	O
one	O
developed	O
by	O
rothganger	O
,	O
lazeb-	O
16	O
when	O
a	O
larger	O
number	O
of	O
features	O
is	O
available	O
,	O
a	O
full	O
fundamental	O
matrix	O
can	O
be	O
used	O
(	O
brown	O
and	O
lowe	O
2002	O
;	O
gordon	O
and	O
lowe	O
2006	O
)	O
.	O
when	O
image	B
stitching	I
is	O
being	O
performed	O
(	O
brown	O
and	O
lowe	O
2007	O
)	O
,	O
the	O
motion	B
models	I
discussed	O
in	O
section	O
9.1	O
can	O
be	O
used	O
instead	O
.	O
14.3	O
instance	B
recognition	O
687	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
14.27	O
3d	O
object	O
recognition	B
with	O
afﬁne	B
regions	O
(	O
rothganger	O
,	O
lazebnik	O
,	O
schmid	O
et	O
al	O
.	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
:	O
(	O
a	O
)	O
sample	O
input	O
image	B
;	O
(	O
b	O
)	O
ﬁve	O
of	O
the	O
recognized	O
(	O
reprojected	O
)	O
objects	O
along	O
with	O
their	O
bounding	O
boxes	O
;	O
(	O
c	O
)	O
a	O
few	O
of	O
the	O
local	B
afﬁne	O
regions	O
;	O
(	O
d	O
)	O
local	B
afﬁne	O
region	B
(	O
patch	B
)	O
reprojected	O
into	O
a	O
canonical	O
(	O
square	O
)	O
frame	O
,	O
along	O
with	O
its	O
geometric	B
afﬁne	O
transformations	O
.	O
nik	O
,	O
schmid	O
et	O
al	O
.	O
(	O
2006	O
)	O
.	O
in	O
their	O
system	O
,	O
the	O
afﬁne	B
region	O
detector	O
of	O
mikolajczyk	O
and	O
schmid	O
(	O
2004	O
)	O
is	O
used	O
to	O
rectify	O
local	B
image	O
patches	O
(	O
figure	O
14.27d	O
)	O
,	O
from	O
which	O
both	O
a	O
sift	O
descriptor	O
and	O
a	O
10	O
×	O
10	O
uv	O
color	B
histogram	O
are	O
computed	O
and	O
used	O
for	O
matching	O
and	O
recognition	B
.	O
corresponding	O
patches	O
in	O
different	O
views	O
of	O
the	O
same	O
object	O
,	O
along	O
with	O
their	O
local	B
afﬁne	O
deformations	O
,	O
are	O
used	O
to	O
compute	O
a	O
3d	O
afﬁne	B
model	O
for	O
the	O
object	O
using	O
an	O
extension	O
of	O
the	O
factorization	B
algorithm	O
of	O
section	O
7.3	O
,	O
which	O
can	O
then	O
be	O
upgraded	O
to	O
a	O
euclidean	O
reconstruction	O
(	O
tomasi	O
and	O
kanade	O
1992	O
)	O
.	O
at	O
recognition	B
time	O
,	O
local	B
euclidean	O
neighborhood	B
constraints	O
are	O
used	O
to	O
ﬁlter	O
potential	O
matches	O
,	O
in	O
a	O
manner	O
analogous	O
to	O
the	O
afﬁne	B
geometric	O
constraints	O
used	O
by	O
lowe	O
(	O
2004	O
)	O
and	O
obdrˇz´alek	O
and	O
matas	O
(	O
2006	O
)	O
.	O
figure	O
14.27	O
shows	O
the	O
results	O
of	O
recognizing	O
ﬁve	O
objects	O
in	O
a	O
cluttered	O
scene	O
using	O
this	O
approach	O
.	O
while	O
feature-based	B
approaches	O
are	O
normally	O
used	O
to	O
detect	O
and	O
localize	O
known	O
objects	O
in	O
scenes	O
,	O
it	O
is	O
also	O
possible	O
to	O
get	O
pixel-level	O
segmentations	O
of	O
the	O
scene	O
based	O
on	O
such	O
matches	O
.	O
ferrari	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
(	O
2006b	O
)	O
describe	O
such	O
a	O
system	O
for	O
simultaneously	O
recog-	O
nizing	O
objects	O
and	O
segmenting	O
scenes	O
,	O
while	O
kannala	O
,	O
rahtu	O
,	O
brandt	O
et	O
al	O
.	O
(	O
2008	O
)	O
extend	O
this	O
approach	O
to	O
non-rigid	B
deformations	O
.	O
section	O
14.4.3	O
re-visits	O
this	O
topic	O
of	O
joint	B
recognition	O
and	O
segmentation	B
in	O
the	O
context	B
of	O
generic	O
class	O
(	O
category	O
)	O
recognition	B
.	O
14.3.2	O
large	O
databases	O
as	O
the	O
number	O
of	O
objects	O
in	O
the	O
database	O
starts	O
to	O
grow	O
large	O
(	O
say	O
,	O
millions	O
of	O
objects	O
or	O
video	B
frames	O
being	O
searched	O
)	O
,	O
the	O
time	O
it	O
takes	O
to	O
match	O
a	O
new	O
image	B
against	O
each	O
database	O
image	B
can	O
become	O
prohibitive	O
.	O
instead	O
of	O
comparing	O
the	O
images	O
one	O
at	O
a	O
time	O
,	O
techniques	O
are	O
needed	O
to	O
quickly	O
narrow	O
down	O
the	O
search	O
to	O
a	O
few	O
likely	O
images	O
,	O
which	O
can	O
then	O
be	O
compared	O
using	O
a	O
more	O
detailed	O
and	O
conservative	O
veriﬁcation	B
stage	O
.	O
688	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.28	O
visual	B
words	I
obtained	O
from	O
elliptical	O
normalized	B
afﬁne	O
regions	O
(	O
sivic	O
and	O
zisserman	O
2009	O
)	O
c	O
(	O
cid:13	O
)	O
2009	O
ieee	O
.	O
(	O
a	O
)	O
afﬁne	B
covariant	O
regions	O
are	O
extracted	O
from	O
each	O
frame	O
and	O
clustered	O
into	O
visual	B
words	I
using	O
k-means	B
clustering	O
on	O
sift	O
descriptors	O
with	O
a	O
learned	B
mahalanobis	O
distance	O
.	O
(	O
b	O
)	O
the	O
central	O
patch	B
in	O
each	O
grid	O
shows	O
the	O
query	O
and	O
the	O
surrounding	O
patches	O
show	O
the	O
nearest	O
neighbors	O
.	O
the	O
problem	O
of	O
quickly	O
ﬁnding	O
partial	O
matches	O
between	O
documents	O
is	O
one	O
of	O
the	O
cen-	O
tral	O
problems	O
in	O
information	O
retrieval	O
(	O
ir	O
)	O
(	O
baeza-yates	O
and	O
ribeiro-neto	O
1999	O
;	O
manning	O
,	O
raghavan	O
,	O
and	O
sch¨utze	O
2008	O
)	O
.	O
the	O
basic	O
approach	O
in	O
fast	O
document	O
retrieval	O
algorithms	O
is	O
to	O
pre-compute	O
an	O
inverted	O
index	O
between	O
individual	O
words	O
and	O
the	O
documents	O
(	O
or	O
web	O
pages	O
or	O
news	O
stories	O
)	O
where	O
they	O
occur	O
.	O
more	O
precisely	O
,	O
the	O
frequency	O
of	O
occurrence	O
of	O
particular	O
words	O
in	O
a	O
document	O
is	O
used	O
to	O
quickly	O
ﬁnd	O
documents	O
that	O
match	O
a	O
particular	O
query	O
.	O
sivic	O
and	O
zisserman	O
(	O
2009	O
)	O
were	O
the	O
ﬁrst	O
to	O
adapt	O
ir	O
techniques	O
to	O
visual	O
search	O
.	O
in	O
their	O
video	B
google	O
system	O
,	O
afﬁne	B
invariant	O
features	O
are	O
ﬁrst	O
detected	O
in	O
all	O
the	O
video	B
frames	O
they	O
are	O
indexing	O
using	O
both	O
shape	O
adapted	O
regions	O
around	O
harris	O
feature	B
points	O
(	O
schaffalitzky	O
and	O
zisserman	O
2002	O
;	O
mikolajczyk	O
and	O
schmid	O
2004	O
)	O
and	O
maximally	O
stable	O
extremal	O
regions	O
(	O
matas	O
,	O
chum	O
,	O
urban	O
et	O
al	O
.	O
2004	O
)	O
,	O
(	O
section	O
4.1.1	O
)	O
,	O
as	O
shown	O
in	O
figure	O
14.28a	O
.	O
next	O
,	O
128-	O
dimensional	O
sift	O
descriptors	O
are	O
computed	O
from	O
each	O
normalized	B
region	O
(	O
i.e.	O
,	O
the	O
patches	O
shown	O
in	O
figure	O
14.28b	O
)	O
.	O
then	O
,	O
an	O
average	O
covariance	O
matrix	O
for	O
these	O
descriptors	O
is	O
es-	O
timated	O
by	O
accumulating	O
statistics	O
for	O
features	O
tracked	O
from	O
frame	O
to	O
frame	O
.	O
the	O
feature	B
descriptor	O
covariance	O
σ	O
is	O
then	O
used	O
to	O
deﬁne	O
a	O
mahalanobis	O
distance	O
between	O
feature	B
de-	O
scriptors	O
,	O
in	O
practice	O
,	O
feature	B
descriptors	O
are	O
whitened	O
by	O
pre-multiplying	O
them	O
by	O
σ−1/2	O
so	O
that	O
eu-	O
clidean	O
distances	O
can	O
be	O
used.17	O
in	O
order	B
to	O
apply	O
fast	O
information	O
retrieval	O
techniques	O
to	O
images	O
,	O
the	O
high-dimensional	O
feature	B
descriptors	O
that	O
occur	O
in	O
each	O
image	B
must	O
ﬁrst	O
be	O
mapped	O
into	O
discrete	B
visual	O
words	O
.	O
17	O
note	O
that	O
the	O
computation	O
of	O
feature	B
covariances	O
from	O
matched	O
feature	B
points	O
is	O
much	O
more	O
sensible	O
than	O
simply	O
performing	O
a	O
pca	O
on	O
the	O
descriptor	O
space	O
(	O
winder	O
and	O
brown	O
2007	O
)	O
.	O
this	O
corresponds	O
roughly	O
to	O
the	O
within-class	B
scatter	O
matrix	O
(	O
14.17	O
)	O
we	O
studied	O
in	O
section	O
14.2.1.	O
d	O
(	O
x0	O
,	O
x1	O
)	O
=	O
(	O
cid:107	O
)	O
x0	O
−	O
x1	O
(	O
cid:107	O
)	O
σ−1	O
=	O
(	O
cid:113	O
)	O
(	O
x0	O
−	O
x1	O
)	O
t	O
σ−1	O
(	O
x0	O
−	O
x1	O
)	O
.	O
(	O
14.32	O
)	O
14.3	O
instance	B
recognition	O
689	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.29	O
matching	B
based	O
on	O
visual	B
words	I
(	O
sivic	O
and	O
zisserman	O
2009	O
)	O
c	O
(	O
cid:13	O
)	O
2009	O
ieee	O
.	O
(	O
a	O
)	O
features	O
in	O
the	O
query	O
region	O
on	O
the	O
left	O
are	O
matched	O
to	O
corresponding	O
features	O
in	O
a	O
highly	O
ranked	O
video	B
frame	O
.	O
(	O
b	O
)	O
results	O
after	O
removing	O
the	O
stop	O
words	O
and	O
ﬁltering	O
the	O
results	O
using	O
spatial	O
consistency	O
.	O
sivic	O
and	O
zisserman	O
(	O
2003	O
)	O
perform	O
this	O
mapping	O
using	O
k-means	O
clustering	O
,	O
while	O
some	O
of	O
newer	O
methods	O
discussed	O
below	O
(	O
nist´er	O
and	O
stew´enius	O
2006	O
;	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
)	O
use	O
alternative	O
techniques	O
,	O
such	O
as	O
vocabulary	O
trees	O
or	O
randomized	O
forests	O
.	O
to	O
keep	O
the	O
clustering	O
time	O
manageable	O
,	O
only	O
a	O
few	O
hundred	O
video	B
frames	O
are	O
used	O
to	O
learn	O
the	O
cluster	O
centers	O
,	O
which	O
still	O
involves	O
estimating	O
several	O
thousand	O
clusters	O
from	O
about	O
300,000	O
descrip-	O
tors	O
.	O
at	O
visual	O
query	O
time	O
,	O
each	O
feature	B
in	O
a	O
new	O
query	O
region	O
(	O
e.g.	O
,	O
figure	O
14.28a	O
,	O
which	O
is	O
a	O
cropped	O
region	B
from	O
a	O
larger	O
video	B
frame	O
)	O
is	O
mapped	O
to	O
its	O
corresponding	O
visual	O
word	O
.	O
to	O
keep	O
very	O
common	O
patterns	B
from	O
contaminating	O
the	O
results	O
,	O
a	O
stop	B
list	I
of	O
the	O
most	O
common	O
visual	B
words	I
is	O
created	O
and	O
such	O
words	O
are	O
dropped	O
from	O
further	O
consideration	O
.	O
once	O
a	O
query	O
image	O
or	O
region	B
has	O
been	O
mapped	O
into	O
its	O
constituent	O
visual	B
words	I
,	O
likely	O
matching	B
images	O
or	O
video	B
frames	O
must	O
then	O
be	O
retrieved	O
from	O
the	O
database	O
.	O
information	O
retrieval	O
systems	O
do	O
this	O
by	O
matching	O
word	O
distributions	O
(	O
term	O
frequencies	O
)	O
nid/nd	O
between	O
the	O
query	O
and	O
target	O
documents	O
,	O
where	O
nid	O
is	O
how	O
many	O
times	O
word	O
i	O
occurs	O
in	O
document	O
d	O
,	O
and	O
nd	O
is	O
the	O
total	B
number	O
of	O
words	O
in	O
document	O
d.	O
in	O
order	B
to	O
downweight	O
words	O
that	O
occur	O
frequently	O
and	O
to	O
focus	B
the	O
search	O
on	O
rarer	O
(	O
and	O
hence	O
,	O
more	O
informative	O
)	O
terms	O
,	O
an	O
inverse	B
document	O
frequency	O
weighting	B
log	O
n/ni	O
is	O
applied	O
,	O
where	O
ni	O
is	O
the	O
number	O
of	O
documents	O
containing	O
word	O
i	O
,	O
and	O
n	O
is	O
the	O
total	B
number	O
of	O
documents	O
in	O
the	O
database	O
.	O
the	O
combination	O
of	O
these	O
two	O
factors	O
results	O
in	O
the	O
term	O
frequency-inverse	O
document	O
frequency	O
(	O
tf-idf	O
)	O
measure	O
,	O
at	O
match	O
time	O
,	O
each	O
document	O
(	O
or	O
query	O
region	O
)	O
is	O
represented	O
by	O
its	O
tf-idf	O
vector	O
,	O
ti	O
=	O
nid	O
nd	O
log	O
n	O
ni	O
.	O
(	O
14.33	O
)	O
t	O
=	O
(	O
t1	O
,	O
.	O
.	O
.	O
,	O
ti	O
,	O
.	O
.	O
.	O
tm	O
)	O
.	O
(	O
14.34	O
)	O
the	O
similarity	B
between	O
two	O
documents	O
is	O
measured	O
by	O
the	O
dot	O
product	O
between	O
their	O
corre-	O
sponding	O
normalized	B
vectors	O
ˆt	O
=	O
t/	O
(	O
cid:107	O
)	O
t	O
(	O
cid:107	O
)	O
,	O
which	O
means	O
that	O
their	O
dissimilarity	O
is	O
proportional	O
to	O
their	O
euclidean	O
distance	O
.	O
in	O
their	O
journal	O
paper	O
,	O
sivic	O
and	O
zisserman	O
(	O
2009	O
)	O
compare	O
this	O
690	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
1.	O
vocabulary	O
construction	O
(	O
off-line	O
)	O
(	O
a	O
)	O
extract	O
afﬁne	B
covariant	O
regions	O
from	O
each	O
database	O
image	B
.	O
(	O
b	O
)	O
compute	O
descriptors	O
and	O
optionally	O
whiten	O
them	O
to	O
make	O
euclidean	O
dis-	O
tances	O
meaningful	O
(	O
sivic	O
and	O
zisserman	O
2009	O
)	O
.	O
(	O
c	O
)	O
cluster	O
the	O
descriptors	O
into	O
visual	B
words	I
,	O
either	O
using	O
k-means	O
(	O
sivic	O
and	O
zisserman	O
2009	O
)	O
,	O
hierarchical	B
clustering	O
(	O
nist´er	O
and	O
stew´enius	O
2006	O
)	O
,	O
or	O
randomized	O
k-d	B
trees	I
(	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
)	O
.	O
(	O
d	O
)	O
decide	O
which	O
words	O
are	O
too	O
common	O
and	O
put	O
them	O
in	O
the	O
stop	B
list	I
.	O
2.	O
database	O
construction	O
(	O
off-line	O
)	O
(	O
a	O
)	O
compute	O
term	O
frequencies	O
for	O
the	O
visual	O
word	O
in	O
each	O
image	B
,	O
document	O
fre-	O
quencies	O
for	O
each	O
word	O
,	O
and	O
normalized	B
tf-idf	O
vectors	O
for	O
each	O
document	O
.	O
(	O
b	O
)	O
compute	O
inverted	O
indices	O
from	O
visual	B
words	I
to	O
images	O
(	O
with	O
word	O
counts	O
)	O
.	O
3.	O
image	B
retrieval	O
(	O
on-line	O
)	O
(	O
a	O
)	O
extract	O
regions	O
,	O
descriptors	O
,	O
and	O
visual	B
words	I
,	O
and	O
compute	O
a	O
tf-idf	O
vector	O
for	O
the	O
query	O
image	O
or	O
region	B
.	O
(	O
b	O
)	O
retrieve	O
the	O
top	O
image	B
candidates	O
,	O
either	O
by	O
exhaustively	O
comparing	O
sparse	B
tf-idf	O
vectors	O
(	O
sivic	O
and	O
zisserman	O
2009	O
)	O
or	O
by	O
using	O
inverted	O
indices	O
to	O
ex-	O
amine	O
only	O
a	O
subset	O
of	O
the	O
images	O
(	O
nist´er	O
and	O
stew´enius	O
2006	O
)	O
.	O
(	O
c	O
)	O
optionally	O
re-rank	O
or	O
verify	O
all	O
the	O
candidate	O
matches	O
,	O
using	O
either	O
spatial	O
consistency	O
(	O
sivic	O
and	O
zisserman	O
2009	O
)	O
or	O
an	O
afﬁne	B
(	O
or	O
simpler	O
)	O
transforma-	O
tion	B
model	O
(	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
)	O
.	O
(	O
d	O
)	O
optionally	O
expand	O
the	O
answer	O
set	O
by	O
re-submitting	O
highly	O
ranked	O
matches	O
as	O
new	O
queries	O
(	O
chum	O
,	O
philbin	O
,	O
sivic	O
et	O
al	O
.	O
2007	O
)	O
.	O
algorithm	B
14.2	O
image	B
retrieval	O
using	O
visual	O
words	O
(	O
sivic	O
and	O
zisserman	O
2009	O
;	O
nist´er	O
and	O
stew´enius	O
2006	O
;	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
;	O
chum	O
,	O
philbin	O
,	O
sivic	O
et	O
al	O
.	O
2007	O
;	O
philbin	O
,	O
chum	O
,	O
sivic	O
et	O
al	O
.	O
2008	O
)	O
.	O
14.3	O
instance	B
recognition	O
691	O
simple	O
metric	O
to	O
a	O
dozen	O
other	O
metrics	O
and	O
conclude	O
that	O
it	O
performs	O
just	O
about	O
as	O
well	O
as	O
more	O
complicated	O
metrics	O
.	O
because	O
the	O
number	O
of	O
non-zero	O
ti	O
terms	O
in	O
a	O
typical	O
query	O
or	O
document	O
is	O
small	O
(	O
m	O
≈	O
200	O
)	O
compared	O
to	O
the	O
number	O
of	O
visual	B
words	I
(	O
v	O
≈	O
20	O
,	O
000	O
)	O
,	O
the	O
distance	O
between	O
pairs	B
of	O
(	O
sparse	B
)	O
tf-idf	O
vectors	O
can	O
be	O
computed	O
quite	O
quickly	O
.	O
after	O
retrieving	O
the	O
top	O
ns	O
=	O
500	O
documents	O
based	O
on	O
word	O
frequencies	O
,	O
sivic	O
and	O
zis-	O
serman	O
(	O
2009	O
)	O
re-rank	O
these	O
results	O
using	O
spatial	O
consistency	O
.	O
this	O
step	O
involves	O
taking	O
every	O
matching	B
feature	O
and	O
counting	O
the	O
number	O
of	O
k	O
=	O
15	O
nearest	O
adjacent	O
features	O
that	O
also	O
match	O
between	O
the	O
two	O
documents	O
.	O
(	O
this	O
latter	O
process	O
is	O
accelerated	O
using	O
inverted	O
ﬁles	O
,	O
which	O
we	O
discuss	O
in	O
more	O
detail	O
below	O
.	O
)	O
as	O
shown	O
in	O
figure	O
14.29	O
,	O
this	O
step	O
helps	O
remove	O
spurious	O
false	O
positive	O
matches	O
and	O
produces	O
a	O
better	O
estimate	O
of	O
which	O
frames	O
and	O
regions	O
in	O
the	O
video	B
are	O
actually	O
true	O
matches	O
.	O
algorithm	B
14.2	O
summarizes	O
the	O
processing	O
steps	O
involved	O
in	O
image	B
retrieval	O
using	O
visual	O
words	O
.	O
while	O
this	O
approach	O
works	O
well	O
for	O
tens	O
of	O
thousand	O
of	O
visual	B
words	I
and	O
thousands	O
of	O
keyframes	O
,	O
as	O
the	O
size	O
of	O
the	O
database	O
continues	O
to	O
increase	O
,	O
both	O
the	O
time	O
to	O
quantize	O
each	O
feature	B
and	O
to	O
ﬁnd	O
potential	O
matching	B
frames	O
or	O
images	O
can	O
become	O
prohibitive	O
.	O
nist´er	O
and	O
stew´enius	O
(	O
2006	O
)	O
address	O
this	O
problem	O
by	O
constructing	O
a	O
hierarchical	B
vocabulary	O
tree	O
,	O
where	O
feature	B
vectors	O
are	O
hierarchically	O
clustered	O
into	O
a	O
k-way	O
tree	O
of	O
prototypes	O
.	O
(	O
this	O
technique	O
is	O
also	O
known	O
as	O
tree-structured	O
vector	O
quantization	B
(	O
gersho	O
and	O
gray	O
1991	O
)	O
.	O
)	O
at	O
both	O
database	O
construction	O
time	O
and	O
query	O
time	O
,	O
each	O
descriptor	O
vector	O
is	O
compared	O
to	O
several	O
prototypes	O
at	O
a	O
given	O
level	O
in	O
the	O
vocabulary	B
tree	I
and	O
the	O
branch	O
with	O
the	O
closest	O
prototype	O
is	O
selected	O
for	O
further	O
reﬁnement	O
(	O
figure	O
14.30	O
)	O
.	O
in	O
this	O
way	O
,	O
vocabularies	O
with	O
millions	O
(	O
106	O
)	O
of	O
words	O
can	O
be	O
supported	O
,	O
which	O
enables	O
individual	O
words	O
to	O
be	O
far	O
more	O
discriminative	O
,	O
while	O
only	O
requiring	O
10	O
·	O
6	O
comparisons	O
for	O
quantizing	O
each	O
descriptor	O
.	O
at	O
query	O
time	O
,	O
each	O
node	O
in	O
the	O
vocabulary	B
tree	I
keeps	O
its	O
own	O
inverted	O
ﬁle	O
index	O
,	O
so	O
that	O
features	O
that	O
match	O
a	O
particular	O
node	O
in	O
the	O
tree	O
can	O
be	O
rapidly	O
mapped	O
to	O
potential	O
matching	B
images	O
.	O
(	O
interior	O
leaf	O
nodes	O
just	O
use	O
the	O
inverted	O
indices	O
of	O
their	O
corresponding	O
leaf-node	O
descendants	O
.	O
)	O
to	O
score	O
a	O
particular	O
query	O
tf-idf	O
vector	O
tq	O
against	O
all	O
document	O
vectors	O
{	O
tj	O
}	O
using	O
an	O
lp	O
metric,18	O
the	O
non-zero	O
tiq	O
entries	O
in	O
tq	O
are	O
used	O
to	O
fetch	O
corresponding	O
non-zero	O
tij	O
entries	O
,	O
and	O
the	O
lp	O
norm	O
is	O
efﬁciently	O
computed	O
as	O
(	O
cid:107	O
)	O
tq	O
−	O
tj	O
(	O
cid:107	O
)	O
p	O
p	O
=	O
2	O
+	O
(	O
cid:88	O
)	O
i|tiq	O
>	O
0∧tij	O
>	O
0	O
(	O
|tiq	O
−	O
tij|p	O
−	O
|tiq|p	O
−	O
|tij|p	O
)	O
.	O
(	O
14.35	O
)	O
in	O
order	B
to	O
mitigate	O
quantization	B
errors	O
due	O
to	O
noise	B
in	O
the	O
descriptor	O
vectors	O
,	O
nist´er	O
and	O
stew´enius	O
(	O
2006	O
)	O
not	O
only	O
score	O
leaf	O
nodes	O
in	O
the	O
vocabulary	B
tree	I
(	O
corresponding	O
to	O
visual	B
words	I
)	O
,	O
but	O
also	O
score	O
interior	O
nodes	O
in	O
the	O
tree	O
,	O
which	O
correspond	O
to	O
clusters	O
of	O
similar	O
visual	B
words	I
.	O
18	O
in	O
their	O
actual	O
implementation	O
,	O
nist´er	O
and	O
stew´enius	O
(	O
2006	O
)	O
use	O
an	O
l1	O
metric	O
.	O
692	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.30	O
scalable	O
recognition	B
using	O
a	O
vocabulary	B
tree	I
(	O
nist´er	O
and	O
stew´enius	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
ieee	O
.	O
(	O
a	O
)	O
each	O
mser	O
elliptical	O
region	B
is	O
converted	O
into	O
a	O
sift	O
descriptor	O
,	O
which	O
is	O
then	O
quantized	O
by	O
comparing	O
it	O
hierarchically	O
to	O
some	O
prototype	O
descriptors	O
in	O
a	O
vocabulary	B
tree	I
.	O
each	O
leaf	O
node	O
stores	O
its	O
own	O
inverted	O
index	O
(	O
sparse	B
list	O
of	O
non-zero	O
tf-idf	O
counts	O
)	O
into	O
images	O
that	O
contain	O
that	O
feature	B
.	O
(	O
b	O
)	O
a	O
recognition	B
result	O
,	O
showing	O
a	O
query	O
image	O
(	O
top	O
row	O
)	O
being	O
indexed	O
into	O
a	O
database	O
of	O
6000	O
test	B
images	I
and	O
correctly	O
ﬁnding	O
the	O
corresponding	O
four	O
images	O
.	O
because	O
of	O
the	O
high	O
efﬁciency	O
in	O
both	O
quantizing	O
and	O
scoring	O
features	O
,	O
their	O
vocabulary-	O
tree-based	O
recognition	B
system	O
is	O
able	O
to	O
process	O
incoming	O
images	O
in	O
real	O
time	O
against	O
a	O
database	O
of	O
40,000	O
cd	O
covers	O
and	O
at	O
1hz	O
when	O
matching	B
a	O
database	O
of	O
one	O
million	O
frames	O
taken	O
from	O
six	O
feature-length	O
movies	O
.	O
figure	O
14.30b	O
shows	O
some	O
typical	O
images	O
from	O
the	O
database	O
of	O
objects	O
taken	O
under	O
varying	O
viewpoints	O
and	O
illumination	O
that	O
was	O
used	O
to	O
train	O
and	O
test	O
the	O
vocabulary	B
tree	I
recognition	O
system	O
.	O
the	O
state	O
of	O
the	O
art	O
in	O
instance	B
recognition	O
continues	O
to	O
improve	O
rapidly	O
.	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
(	O
2007	O
)	O
have	O
shown	O
that	O
randomized	O
forest	O
of	O
k-d	B
trees	I
perform	O
better	O
than	O
vocabu-	O
lary	O
trees	O
on	O
a	O
large	O
location	O
recognition	B
task	O
(	O
figure	O
14.31	O
)	O
.	O
they	O
also	O
compare	O
the	O
effects	O
of	O
using	O
different	O
2d	O
motion	B
models	I
(	O
section	O
2.1.2	O
)	O
in	O
the	O
veriﬁcation	B
stage	O
.	O
in	O
follow-on	O
work	O
,	O
chum	O
,	O
philbin	O
,	O
sivic	O
et	O
al	O
.	O
(	O
2007	O
)	O
apply	O
another	O
idea	O
from	O
information	O
retrieval	O
,	O
namely	O
14.3	O
instance	B
recognition	O
693	O
figure	O
14.31	O
location	O
or	O
building	O
recognition	B
using	O
randomized	O
trees	O
(	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
ieee	O
.	O
the	O
left	O
image	B
is	O
the	O
query	O
,	O
the	O
other	O
images	O
are	O
the	O
highest-ranked	O
results	O
.	O
query	B
expansion	I
,	O
which	O
involves	O
re-submitting	O
top-ranked	O
images	O
from	O
the	O
initial	O
query	O
as	O
additional	O
queries	O
to	O
generate	O
additional	O
candidate	O
results	O
,	O
to	O
further	O
improve	O
recognition	B
rates	O
for	O
difﬁcult	O
(	O
occluded	O
or	O
oblique	O
)	O
examples	B
.	O
philbin	O
,	O
chum	O
,	O
sivic	O
et	O
al	O
.	O
(	O
2008	O
)	O
show	O
how	O
to	O
mitigate	O
quantization	B
problems	O
in	O
visual	B
words	I
selection	O
using	O
soft	O
assignment	O
,	O
where	O
each	O
feature	B
descriptor	O
is	O
mapped	O
to	O
a	O
number	O
of	O
visual	B
words	I
based	O
on	O
its	O
distance	O
from	O
the	O
cluster	O
prototypes	O
.	O
the	O
soft	O
weights	O
derived	O
from	O
these	O
distances	O
are	O
used	O
,	O
in	O
turn	O
,	O
to	O
weight	O
the	O
counts	O
used	O
in	O
the	O
tf-idf	O
vectors	O
and	O
to	O
retrieve	O
additional	O
images	O
for	O
later	O
veriﬁcation	B
.	O
taken	O
together	O
,	O
these	O
recent	O
advances	O
hold	O
the	O
promise	O
of	O
extending	O
current	O
instance	B
recog-	O
nition	O
algorithms	O
to	O
performing	O
web-scale	O
retrieval	O
and	O
matching	B
tasks	O
(	O
agarwal	O
,	O
snavely	O
,	O
simon	O
et	O
al	O
.	O
2009	O
;	O
agarwal	O
,	O
furukawa	O
,	O
snavely	O
et	O
al	O
.	O
2010	O
;	O
snavely	O
,	O
simon	O
,	O
goesele	O
et	O
al	O
.	O
2010	O
)	O
.	O
14.3.3	O
application	O
:	O
location	B
recognition	I
one	O
of	O
the	O
most	O
exciting	O
applications	O
of	O
instance	B
recognition	O
today	O
is	O
in	O
the	O
area	O
of	O
location	B
recognition	I
,	O
which	O
can	O
be	O
used	O
both	O
in	O
desktop	O
applications	O
(	O
where	O
did	O
i	O
take	O
this	O
holiday	O
snap	O
?	O
)	O
and	O
in	O
mobile	O
(	O
cell-phone	O
)	O
applications	O
.	O
the	O
latter	O
case	O
includes	O
not	O
only	O
ﬁnding	O
out	O
your	O
current	O
location	O
based	O
on	O
a	O
cell-phone	O
image	B
but	O
also	O
providing	O
you	O
with	O
navigation	O
directions	O
or	O
annotating	O
your	O
images	O
with	O
useful	O
information	O
,	O
such	O
as	O
building	O
names	O
and	O
restaurant	O
reviews	O
(	O
i.e.	O
,	O
a	O
portable	O
form	O
of	O
augmented	B
reality	I
)	O
.	O
some	O
approaches	O
to	O
location	B
recognition	I
assume	O
that	O
the	O
photos	O
consist	O
of	O
architectural	O
scenes	O
for	O
which	O
vanishing	O
directions	O
can	O
be	O
used	O
to	O
pre-rectify	O
the	O
images	O
for	O
easier	O
match-	O
ing	O
(	O
robertson	O
and	O
cipolla	O
2004	O
)	O
.	O
other	O
approaches	O
use	O
general	O
afﬁne	B
covariant	O
interest	O
points	B
to	O
perform	O
wide	O
baseline	O
matching	B
(	O
schaffalitzky	O
and	O
zisserman	O
2002	O
)	O
.	O
the	O
photo	O
tourism	O
system	O
of	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
(	O
2006	O
)	O
(	O
section	O
13.1.2	O
)	O
was	O
the	O
ﬁrst	O
to	O
apply	O
these	O
kinds	O
of	O
ideas	O
to	O
large-scale	O
image	B
matching	O
and	O
(	O
implicit	O
)	O
location	B
recognition	I
from	O
694	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
14.32	O
feature-based	B
location	O
recognition	B
(	O
schindler	O
,	O
brown	O
,	O
and	O
szeliski	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
ieee	O
:	O
(	O
a	O
)	O
three	O
typical	O
series	O
of	O
overlapping	O
street	O
photos	O
;	O
(	O
b	O
)	O
handheld	O
camera	B
shots	O
and	O
(	O
c	O
)	O
their	O
corresponding	O
database	O
photos	O
.	O
internet	O
photo	O
collections	O
taken	O
under	O
a	O
wide	O
variety	O
of	O
viewing	O
conditions	O
.	O
the	O
main	O
difﬁculty	O
in	O
location	B
recognition	I
is	O
in	O
dealing	O
with	O
the	O
extremely	O
large	O
commu-	O
nity	O
(	O
user-generated	O
)	O
photo	O
collections	O
on	O
web	O
sites	O
such	O
as	O
flickr	O
(	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
;	O
chum	O
,	O
philbin	O
,	O
sivic	O
et	O
al	O
.	O
2007	O
;	O
philbin	O
,	O
chum	O
,	O
sivic	O
et	O
al	O
.	O
2008	O
;	O
turcot	O
and	O
lowe	O
2009	O
)	O
or	O
commercially	O
captured	O
databases	O
(	O
schindler	O
,	O
brown	O
,	O
and	O
szeliski	O
2007	O
)	O
.	O
the	O
preva-	O
lence	O
of	O
commonly	O
appearing	O
elements	O
such	O
as	O
foliage	O
,	O
signs	O
,	O
and	O
common	O
architectural	O
ele-	O
ments	O
further	O
complicates	O
the	O
task	O
.	O
figure	O
14.31	O
shows	O
some	O
results	O
on	O
location	B
recognition	I
from	O
community	O
photo	O
collections	O
,	O
while	O
figure	O
14.32	O
shows	O
sample	O
results	O
from	O
denser	O
commercially	O
acquired	O
datasets	O
.	O
in	O
the	O
latter	O
case	O
,	O
the	O
overlap	O
between	O
adjacent	O
database	O
images	O
can	O
be	O
used	O
to	O
verify	O
and	O
prune	O
potential	O
matches	O
using	O
“	O
temporal	O
”	O
ﬁltering	O
,	O
i.e.	O
,	O
re-	O
quiring	O
the	O
query	O
image	O
to	O
match	O
nearby	O
overlapping	O
database	O
images	O
before	O
accepting	O
the	O
match	O
.	O
another	O
variant	O
on	O
location	B
recognition	I
is	O
the	O
automatic	B
discovery	O
of	O
landmarks	O
,	O
i.e.	O
,	O
frequently	O
photographed	O
objects	O
and	O
locations	O
.	O
simon	O
,	O
snavely	O
,	O
and	O
seitz	O
(	O
2007	O
)	O
show	O
how	O
these	O
kinds	O
of	O
objects	O
can	O
be	O
discovered	O
simply	O
by	O
analyzing	O
the	O
matching	B
graph	O
constructed	O
as	O
part	O
of	O
the	O
3d	O
modeling	B
process	O
in	O
photo	O
tourism	O
.	O
more	O
recent	O
work	O
has	O
extended	O
this	O
approach	O
to	O
larger	O
data	B
sets	I
using	O
efﬁcient	O
clustering	O
techniques	O
(	O
philbin	O
and	O
zisserman	O
2008	O
;	O
li	O
,	O
wu	O
,	O
zach	O
et	O
al	O
.	O
2008	O
;	O
chum	O
,	O
philbin	O
,	O
and	O
zisserman	O
2008	O
;	O
chum	O
and	O
matas	O
2010	O
)	O
as	O
well	O
as	O
combining	O
meta-data	O
such	O
as	O
gps	O
and	O
textual	O
tags	O
with	O
visual	O
search	O
(	O
quack	O
,	O
leibe	O
,	O
and	O
van	O
gool	O
2008	O
;	O
crandall	O
,	O
backstrom	O
,	O
huttenlocher	O
et	O
al	O
.	O
2009	O
)	O
,	O
as	O
shown	O
in	O
figure	O
14.33.	O
it	O
is	O
now	O
even	O
possible	O
to	O
automatically	O
associate	O
object	O
tags	O
with	O
images	O
based	O
on	O
their	O
co-	O
occurrence	O
in	O
multiple	B
loosely	O
tagged	O
images	O
(	O
simon	O
and	O
seitz	O
2008	O
;	O
gammeter	O
,	O
bossard	O
,	O
14.4	O
category	O
recognition	O
695	O
figure	O
14.33	O
automatic	B
mining	O
,	O
annotation	O
,	O
and	O
localization	O
of	O
community	O
photo	O
collec-	O
tions	O
(	O
quack	O
,	O
leibe	O
,	O
and	O
van	O
gool	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
acm	O
.	O
this	O
ﬁgure	O
does	O
not	O
show	O
the	O
textual	O
annotations	O
or	O
corresponding	O
wikipedia	O
entries	O
,	O
which	O
are	O
also	O
discovered	O
.	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.34	O
locating	O
star	O
ﬁelds	O
using	O
astrometry	O
,	O
http	O
:	O
//astrometry.net/	O
.	O
(	O
a	O
)	O
input	O
star	O
ﬁeld	O
and	O
some	O
selected	O
star	O
quads	O
.	O
(	O
b	O
)	O
the	O
2d	O
coordinates	O
of	O
stars	O
c	O
and	O
d	O
are	O
encoded	O
relative	O
to	O
the	O
unit	O
square	O
deﬁned	O
by	O
a	O
and	O
b.	O
quack	O
et	O
al	O
.	O
2009	O
)	O
.	O
the	O
concept	O
of	O
organizing	O
the	O
world	O
’	O
s	O
photo	O
collections	O
by	O
location	O
has	O
even	O
been	O
re-	O
cently	O
extended	O
to	O
organizing	O
all	O
of	O
the	O
universe	O
’	O
s	O
(	O
astronomical	O
)	O
photos	O
in	O
an	O
application	O
called	O
astrometry	O
,	O
http	O
:	O
//astrometry.net/	O
.	O
the	O
technique	O
used	O
to	O
match	O
any	O
two	O
star	O
ﬁelds	O
is	O
to	O
take	O
quadruplets	O
of	O
nearby	O
stars	O
(	O
a	O
pair	O
of	O
stars	O
and	O
another	O
pair	O
inside	O
their	O
diameter	O
)	O
to	O
form	O
a	O
30-bit	O
geometric	B
hash	O
by	O
encoding	O
the	O
relative	O
positions	O
of	O
the	O
second	O
pair	O
of	O
points	B
using	O
the	O
inscribed	O
square	O
as	O
the	O
reference	O
frame	O
,	O
as	O
shown	O
in	O
figure	O
14.34.	O
traditional	O
in-	O
formation	O
retrieval	O
techniques	O
(	O
k-d	B
trees	I
built	O
for	O
different	O
parts	O
of	O
a	O
sky	O
atlas	O
)	O
are	O
then	O
used	O
to	O
ﬁnd	O
matching	B
quads	O
as	O
potential	O
star	O
ﬁeld	O
location	O
hypotheses	O
,	O
which	O
can	O
then	O
be	O
veriﬁed	O
using	O
a	O
similarity	B
transform	O
.	O
abcd	O
696	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.35	O
sample	O
images	O
from	O
the	O
xerox	O
10	O
class	O
dataset	O
(	O
csurka	O
,	O
dance	O
,	O
perronnin	O
et	O
al	O
.	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
springer	O
.	O
imagine	O
trying	O
to	O
write	O
a	O
program	O
to	O
distinguish	O
such	O
images	O
from	O
other	O
photographs	O
.	O
14.4	O
category	O
recognition	O
while	O
instance	B
recognition	O
techniques	O
are	O
relatively	O
mature	O
and	O
are	O
used	O
in	O
commercial	O
ap-	O
plications	O
,	O
such	O
as	O
photosynth	O
(	O
section	O
13.1.2	O
)	O
,	O
generic	O
category	O
(	O
class	O
)	O
recognition	B
is	O
still	O
a	O
largely	O
unsolved	O
problem	O
.	O
consider	O
for	O
example	O
the	O
set	O
of	O
photographs	O
in	O
figure	O
14.35	O
,	O
which	O
shows	O
objects	O
taken	O
from	O
10	O
different	O
visual	O
categories	O
.	O
(	O
i	O
’	O
ll	O
leave	O
it	O
up	O
to	O
you	O
to	O
name	O
each	O
of	O
the	O
categories	O
.	O
)	O
how	O
would	O
you	O
go	O
about	O
writing	O
a	O
program	O
to	O
categorize	O
each	O
of	O
these	O
images	O
into	O
the	O
appropriate	O
class	O
,	O
especially	O
if	O
you	O
were	O
also	O
given	O
the	O
choice	O
“	O
none	O
of	O
the	O
above	O
”	O
?	O
as	O
you	O
can	O
tell	O
from	O
this	O
example	O
,	O
visual	O
category	O
recognition	B
is	O
an	O
extremely	O
challenging	O
problem	O
;	O
no	O
one	O
has	O
yet	O
constructed	O
a	O
system	O
that	O
approaches	O
the	O
performance	O
level	O
of	O
a	O
two-	O
year-old	O
child	O
.	O
however	O
,	O
the	O
progress	O
in	O
the	O
ﬁeld	O
has	O
been	O
quite	O
dramatic	O
,	O
if	O
judged	O
by	O
how	O
much	O
better	O
today	O
’	O
s	O
algorithms	O
are	O
compared	O
to	O
those	O
of	O
a	O
decade	O
ago	O
.	O
figure	O
14.54	O
shows	O
a	O
sample	O
image	B
from	O
each	O
of	O
the	O
20	O
categories	O
used	O
in	O
the	O
2008	O
pascal	O
visual	O
object	O
classes	O
challenge	O
.	O
the	O
yellow	O
boxes	O
represent	O
the	O
extent	O
of	O
each	O
of	O
the	O
objects	O
found	O
in	O
a	O
given	O
image	B
.	O
on	O
such	O
closed	O
world	O
collections	O
where	O
the	O
task	O
is	O
to	O
decide	O
among	O
20	O
categories	O
,	O
today	O
’	O
s	O
classiﬁcation	O
algorithms	O
can	O
do	O
remarkably	O
well	O
.	O
14.4	O
category	O
recognition	O
697	O
figure	O
14.36	O
a	O
typical	O
processing	O
pipeline	B
for	O
a	O
bag-of-words	O
category	O
recognition	O
system	O
(	O
csurka	O
,	O
dance	O
,	O
perronnin	O
et	O
al	O
.	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
springer	O
.	O
features	O
are	O
ﬁrst	O
extracted	O
at	O
keypoints	O
and	O
then	O
quantized	O
to	O
get	O
a	O
distribution	O
(	O
histogram	B
)	O
over	O
the	O
learned	B
visual	O
words	O
(	O
feature	B
cluster	O
centers	O
)	O
.	O
the	O
feature	B
distribution	O
histogram	B
is	O
used	O
to	O
learn	O
a	O
decision	O
surface	O
using	O
a	O
classiﬁcation	O
algorithm	B
,	O
such	O
as	O
a	O
support	O
vector	O
machine	O
.	O
in	O
this	O
section	O
,	O
we	O
look	O
at	O
a	O
number	O
of	O
approaches	O
to	O
solving	O
category	O
recognition	O
.	O
while	O
historically	O
,	O
part-based	B
representations	O
and	O
recognition	B
algorithms	O
(	O
section	O
14.4.2	O
)	O
were	O
the	O
preferred	O
approach	O
(	O
fischler	O
and	O
elschlager	O
1973	O
;	O
felzenszwalb	O
and	O
huttenlocher	O
2005	O
;	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2007	O
)	O
,	O
we	O
begin	O
by	O
describing	O
simpler	O
bag-of-features	O
ap-	O
proaches	O
(	O
section	O
14.4.1	O
)	O
that	O
represent	O
objects	O
and	O
images	O
as	O
unordered	O
collections	O
of	O
fea-	O
ture	O
descriptors	O
.	O
we	O
then	O
look	O
at	O
the	O
problem	O
of	O
simultaneously	O
segmenting	O
images	O
while	O
recognizing	O
objects	O
(	O
section	O
14.4.3	O
)	O
and	O
also	O
present	O
some	O
applications	O
of	O
such	O
techniques	O
to	O
photo	O
manipulation	O
(	O
section	O
14.4.4	O
)	O
.	O
in	O
section	O
14.5	O
,	O
we	O
look	O
at	O
how	O
context	B
and	O
scene	O
un-	O
derstanding	O
,	O
as	O
well	O
as	O
machine	O
learning	O
,	O
can	O
improve	O
overall	O
recognition	B
results	O
.	O
additional	O
details	O
on	O
the	O
techniques	O
presented	O
in	O
this	O
section	O
can	O
be	O
found	O
in	O
(	O
pinz	O
2005	O
;	O
ponce	O
,	O
hebert	O
,	O
schmid	O
et	O
al	O
.	O
2006	O
;	O
dickinson	O
,	O
leonardis	O
,	O
schiele	O
et	O
al	O
.	O
2007	O
;	O
fei-fei	O
,	O
fergus	O
,	O
and	O
torralba	O
2009	O
)	O
.	O
14.4.1	O
bag	B
of	I
words	I
one	O
of	O
the	O
simplest	O
algorithms	O
for	O
category	O
recognition	B
is	O
the	O
bag	B
of	I
words	I
(	O
also	O
known	O
as	O
bag	O
of	O
features	O
or	O
bag	O
of	O
keypoints	O
)	O
approach	O
(	O
csurka	O
,	O
dance	O
,	O
fan	O
et	O
al	O
.	O
2004	O
;	O
lazebnik	O
,	O
schmid	O
,	O
and	O
ponce	O
2006	O
;	O
csurka	O
,	O
dance	O
,	O
perronnin	O
et	O
al	O
.	O
2006	O
;	O
zhang	O
,	O
marszalek	O
,	O
lazeb-	O
nik	O
et	O
al	O
.	O
2007	O
)	O
.	O
as	O
shown	O
in	O
figure	O
14.36	O
,	O
this	O
algorithm	B
simply	O
computes	O
the	O
distribu-	O
tion	B
(	O
histogram	B
)	O
of	O
visual	B
words	I
found	O
in	O
the	O
query	O
image	O
and	O
compares	O
this	O
distribution	O
to	O
those	O
found	O
in	O
the	O
training	O
images	O
.	O
we	O
have	O
already	O
seen	O
elements	O
of	O
this	O
approach	O
in	O
section	O
14.3.2	O
,	O
equations	B
(	O
14.33–14.35	O
)	O
and	O
algorithm	B
14.2.	O
the	O
biggest	O
difference	B
from	O
instance	B
recognition	O
is	O
the	O
absence	O
of	O
a	O
geometric	B
veriﬁcation	O
stage	O
(	O
section	O
14.3.1	O
)	O
,	O
since	O
individual	O
instances	O
of	O
generic	O
visual	O
categories	O
,	O
such	O
as	O
those	O
shown	O
in	O
figure	O
14.35	O
,	O
have	O
relatively	O
little	O
spatial	O
coherence	O
to	O
their	O
features	O
(	O
but	O
see	O
the	O
work	O
by	O
lazebnik	O
,	O
schmid	O
,	O
and	O
698	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ponce	O
(	O
2006	O
)	O
)	O
.	O
csurka	O
,	O
dance	O
,	O
fan	O
et	O
al	O
.	O
(	O
2004	O
)	O
were	O
the	O
ﬁrst	O
to	O
use	O
the	O
term	O
bag	O
of	O
keypoints	O
to	O
describe	O
such	O
approaches	O
and	O
among	O
the	O
ﬁrst	O
to	O
demonstrate	O
the	O
utility	O
of	O
frequency-based	O
techniques	O
for	O
category	O
recognition	B
.	O
their	O
original	O
system	O
used	O
afﬁne	B
covariant	O
regions	O
and	O
sift	O
de-	O
scriptors	O
,	O
k-means	B
visual	O
vocabulary	O
construction	O
,	O
and	O
both	O
a	O
na¨ıve	O
bayesian	O
classiﬁer	O
and	O
support	B
vector	I
machines	I
for	O
classiﬁcation	O
.	O
(	O
the	O
latter	O
was	O
found	O
to	O
perform	O
better	O
.	O
)	O
their	O
newer	O
system	O
(	O
csurka	O
,	O
dance	O
,	O
perronnin	O
et	O
al	O
.	O
2006	O
)	O
uses	O
regular	O
(	O
non-afﬁne	O
)	O
sift	O
patches	O
,	O
boosting	B
instead	O
of	O
svms	O
,	O
and	O
incorporates	O
a	O
small	O
amount	O
of	O
geometric	B
consistency	O
infor-	O
mation	O
.	O
zhang	O
,	O
marszalek	O
,	O
lazebnik	O
et	O
al	O
.	O
(	O
2007	O
)	O
perform	O
a	O
more	O
detailed	O
study	O
of	O
such	O
bag	O
of	O
features	O
systems	O
.	O
they	O
compare	O
a	O
number	O
of	O
feature	B
detectors	O
(	O
harris–laplace	O
(	O
mikolajczyk	O
and	O
schmid	O
2004	O
)	O
and	O
laplacian	O
(	O
lindeberg	O
1998b	O
)	O
)	O
,	O
descriptors	O
(	O
sift	O
,	O
rift	O
,	O
and	O
spin	O
(	O
lazebnik	O
,	O
schmid	O
,	O
and	O
ponce	O
2005	O
)	O
)	O
,	O
and	O
svm	O
kernel	B
functions	O
.	O
to	O
estimate	O
distances	O
for	O
the	O
kernel	B
function	O
,	O
they	O
form	O
an	O
image	B
signature	O
s	O
=	O
(	O
(	O
t1	O
,	O
m1	O
)	O
,	O
.	O
.	O
.	O
,	O
(	O
tm	O
,	O
mm	O
)	O
)	O
,	O
(	O
14.36	O
)	O
analogous	O
to	O
the	O
tf-idf	O
vector	O
t	O
in	O
(	O
14.34	O
)	O
,	O
where	O
the	O
cluster	O
centers	O
mi	O
are	O
made	O
explicit	O
.	O
they	O
then	O
investigate	O
two	O
different	O
kernels	O
for	O
comparing	O
such	O
image	B
signatures	O
.	O
the	O
ﬁrst	O
is	O
the	O
earth	O
mover	O
’	O
s	O
distance	O
(	O
emd	O
)	O
(	O
rubner	O
,	O
tomasi	O
,	O
and	O
guibas	O
2000	O
)	O
,	O
em	O
d	O
(	O
s	O
,	O
s	O
(	O
cid:48	O
)	O
)	O
=	O
(	O
cid:80	O
)	O
i	O
(	O
cid:80	O
)	O
j	O
fijd	O
(	O
mi	O
,	O
m	O
(	O
cid:48	O
)	O
j	O
)	O
(	O
cid:80	O
)	O
i	O
(	O
cid:80	O
)	O
j	O
fij	O
,	O
(	O
14.37	O
)	O
where	O
fij	O
is	O
a	O
ﬂow	O
value	O
that	O
can	O
be	O
computed	O
using	O
a	O
linear	B
program	O
and	O
d	O
(	O
mi	O
,	O
m	O
(	O
cid:48	O
)	O
j	O
)	O
is	O
the	O
ground	O
distance	O
(	O
euclidean	O
distance	O
)	O
between	O
mi	O
and	O
m	O
(	O
cid:48	O
)	O
j.	O
note	O
that	O
the	O
emd	O
can	O
be	O
used	O
to	O
compare	O
two	O
signatures	O
of	O
different	O
lengths	O
,	O
where	O
the	O
entries	O
do	O
not	O
need	O
to	O
correspond	O
.	O
the	O
second	O
is	O
a	O
χ2	O
distance	O
χ2	O
(	O
s	O
,	O
s	O
(	O
cid:48	O
)	O
)	O
=	O
1	O
2	O
(	O
cid:88	O
)	O
i	O
(	O
ti	O
−	O
t	O
(	O
cid:48	O
)	O
i	O
)	O
2	O
ti	O
+	O
t	O
(	O
cid:48	O
)	O
i	O
,	O
(	O
14.38	O
)	O
which	O
measures	O
the	O
likelihood	O
that	O
the	O
two	O
signatures	O
were	O
generated	O
from	O
consistent	O
random	O
processes	O
.	O
these	O
distance	B
metrics	I
are	O
then	O
converted	O
into	O
svm	O
kernels	O
using	O
a	O
generalized	B
gaussian	O
kernel	B
k	O
(	O
s	O
,	O
s	O
(	O
cid:48	O
)	O
)	O
=	O
exp	O
(	O
cid:18	O
)	O
−	O
1	O
a	O
d	O
(	O
s	O
,	O
s	O
(	O
cid:48	O
)	O
)	O
(	O
cid:19	O
)	O
,	O
(	O
14.39	O
)	O
where	O
a	O
is	O
a	O
scaling	O
parameter	O
set	O
to	O
the	O
mean	O
distance	O
between	O
training	O
images	O
.	O
in	O
their	O
experiments	O
,	O
they	O
ﬁnd	O
that	O
the	O
emd	O
works	O
best	O
for	O
visual	O
category	O
recognition	O
and	O
the	O
χ2	O
measure	O
is	O
best	O
for	O
texture	O
recognition	B
.	O
14.4	O
category	O
recognition	O
699	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.37	O
comparing	O
collections	O
of	O
feature	B
vectors	O
using	O
pyramid	O
matching	B
.	O
(	O
a	O
)	O
the	O
feature-space	O
pyramid	B
match	O
kernel	B
(	O
grauman	O
and	O
darrell	O
2007b	O
)	O
constructs	O
a	O
pyramid	B
in	O
high-dimensional	O
feature	B
space	O
and	O
uses	O
it	O
to	O
compute	O
distances	O
(	O
and	O
implicit	O
correspon-	O
dences	O
)	O
between	O
sets	O
of	O
feature	B
vectors	O
.	O
(	O
b	O
)	O
spatial	O
pyramid	B
matching	O
(	O
lazebnik	O
,	O
schmid	O
,	O
and	O
ponce	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
ieee	O
divides	O
the	O
image	B
into	O
a	O
pyramid	B
of	O
pooling	O
regions	O
and	O
computes	O
separate	O
visual	O
word	O
histograms	O
(	O
distributions	O
)	O
inside	O
each	O
spatial	O
bin	O
.	O
instead	O
of	O
quantizing	O
feature	B
vectors	O
to	O
visual	B
words	I
,	O
grauman	O
and	O
darrell	O
(	O
2007b	O
)	O
de-	O
velop	O
a	O
technique	O
for	O
directly	O
computing	O
an	O
approximate	O
distance	O
between	O
two	O
variably	O
sized	O
collections	O
of	O
feature	B
vectors	O
.	O
their	O
approach	O
is	O
to	O
bin	O
the	O
feature	B
vectors	O
into	O
a	O
multi-	O
resolution	O
pyramid	B
deﬁned	O
in	O
feature	B
space	O
(	O
figure	O
14.37a	O
)	O
and	O
count	O
the	O
number	O
of	O
features	O
that	O
land	O
in	O
corresponding	O
bins	O
bil	O
and	O
b	O
(	O
cid:48	O
)	O
il	O
(	O
figure	O
14.38a–c	O
)	O
.	O
the	O
distance	O
between	O
the	O
two	O
sets	O
of	O
feature	B
vectors	O
(	O
which	O
can	O
be	O
thought	O
of	O
as	O
points	B
in	O
a	O
high-dimensional	O
space	O
)	O
is	O
computed	O
using	O
histogram	O
intersection	O
between	O
corresponding	O
bins	O
cl	O
=	O
(	O
cid:88	O
)	O
i	O
min	O
(	O
bil	O
,	O
b	O
(	O
cid:48	O
)	O
il	O
)	O
(	O
figure	O
14.38d	O
)	O
.	O
these	O
per-level	O
counts	O
are	O
then	O
summed	O
up	O
in	O
a	O
weighted	B
fashion	O
(	O
14.40	O
)	O
(	O
14.41	O
)	O
d∆	O
=	O
(	O
cid:88	O
)	O
l	O
wlnl	O
with	O
nl	O
=	O
cl	O
−	O
cl−1	O
and	O
wl	O
=	O
1	O
d2l	O
(	O
figure	O
14.38e	O
)	O
,	O
which	O
discounts	O
matches	O
already	O
found	O
at	O
ﬁner	O
levels	O
while	O
weighting	B
ﬁner	O
matches	O
more	O
heavily	O
.	O
(	O
d	O
is	O
the	O
dimension	O
of	O
the	O
embedding	O
space	O
,	O
i.e.	O
,	O
the	O
length	O
of	O
the	O
feature	B
vectors	O
.	O
)	O
in	O
follow-on	O
work	O
,	O
grauman	O
and	O
darrell	O
(	O
2007a	O
)	O
show	O
how	O
an	O
explicit	O
construction	O
of	O
the	O
pyramid	B
can	O
be	O
avoided	O
using	O
hashing	O
techniques	O
.	O
inspired	O
by	O
this	O
work	O
,	O
lazebnik	O
,	O
schmid	O
,	O
and	O
ponce	O
(	O
2006	O
)	O
show	O
how	O
a	O
similar	O
idea	O
can	O
be	O
employed	O
to	O
augment	O
bags	O
of	O
keypoints	O
with	O
loose	O
notions	O
of	O
2d	O
spatial	O
location	O
getthefollowingdeﬁnitionofapyramidmatchkernel	O
:	O
κl	O
(	O
x	O
,	O
y	O
)	O
=il+l−1	O
(	O
cid:1	O
)	O
(	O
cid:1	O
)	O
=012l−	O
(	O
cid:1	O
)	O
(	O
cid:2	O
)	O
i	O
(	O
cid:1	O
)	O
−i	O
(	O
cid:1	O
)	O
+1	O
(	O
cid:3	O
)	O
(	O
2	O
)	O
=12li0+l	O
(	O
cid:1	O
)	O
(	O
cid:1	O
)	O
=112l−	O
(	O
cid:1	O
)	O
+1i	O
(	O
cid:1	O
)	O
.	O
(	O
3	O
)	O
boththehistogramintersectionandthepyramidmatchker-nelaremercerkernels	O
[	O
7	O
]	O
.3.2.spatialmatchingschemeasintroducedin	O
[	O
7	O
]	O
,	O
apyramidmatchkernelworkswithanorderlessimagerepresentation.itallowsforpre-cisematchingoftwocollectionsoffeaturesinahigh-dimensionalappearancespace	O
,	O
butdiscardsallspatialin-formation.thispaperadvocatesan	O
“	O
orthogonal	O
”	O
approach	O
:	O
performpyramidmatchinginthetwo-dimensionalimagespace	O
,	O
andusetraditionalclusteringtechniquesinfeaturespace.1speciﬁcally	O
,	O
wequantizeallfeaturevectorsintomdiscretetypes	O
,	O
andmakethesimplifyingassumptionthatonlyfeaturesofthesametypecanbematchedtoonean-other.eachchannelmgivesustwosetsoftwo-dimensionalvectors	O
,	O
xmandym	O
,	O
representingthecoordinatesoffea-turesoftypemfoundintherespectiveimages.theﬁnalkernelisthenthesumoftheseparatechannelkernels	O
:	O
kl	O
(	O
x	O
,	O
y	O
)	O
=m	O
(	O
cid:1	O
)	O
m=1κl	O
(	O
xm	O
,	O
ym	O
)	O
.	O
(	O
4	O
)	O
thisapproachhastheadvantageofmaintainingcontinuitywiththepopular	O
“	O
visualvocabulary	O
”	O
paradigm—infact	O
,	O
itreducestoastandardbagoffeatureswhenl=0.becausethepyramidmatchkernel	O
(	O
3	O
)	O
issimplyaweightedsumofhistogramintersections	O
,	O
andbecausecmin	O
(	O
a	O
,	O
b	O
)	O
=min	O
(	O
ca	O
,	O
cb	O
)	O
forpositivenumbers	O
,	O
wecanimplementklasasinglehistogramintersectionof	O
“	O
long	O
”	O
vectorsformedbyconcatenatingtheappropriatelyweightedhistogramsofallchannelsatallresolutions	O
(	O
fig.1	O
)	O
.forllevelsandmchannels	O
,	O
theresultingvectorhasdimen-sionalitym	O
(	O
cid:4	O
)	O
l	O
(	O
cid:1	O
)	O
=04	O
(	O
cid:1	O
)	O
=m13	O
(	O
4l+1−1	O
)	O
.severalexperi-mentsreportedinsection5usethesettingsofm=400andl=3	O
,	O
resultingin34000-dimensionalhistogramin-tersections.however	O
,	O
theseoperationsareefﬁcientbecausethehistogramvectorsareextremelysparse	O
(	O
infact	O
,	O
justasin	O
[	O
7	O
]	O
,	O
thecomputationalcomplexityofthekernelislinearinthenumberoffeatures	O
)	O
.itmustalsobenotedthatwedidnotobserveanysigniﬁcantincreaseinperformancebeyondm=200andl=2	O
,	O
wheretheconcatenatedhistogramsareonly4200-dimensional.1inprinciple	O
,	O
itispossibletointegrategeometricinformationdirectlyintotheoriginalpyramidmatchingframeworkbytreatingimagecoordi-natesastwoextradimensionsinthefeaturespace.++++++++++++++++++++++++++++++++++++level2level1level0´1/4´1/4´1/2+++figure1.toyexampleofconstructingathree-levelpyramid.theimagehasthreefeaturetypes	O
,	O
indicatedbycircles	O
,	O
diamonds	O
,	O
andcrosses.atthetop	O
,	O
wesubdividetheimageatthreedifferentlev-elsofresolution.next	O
,	O
foreachlevelofresolutionandeachchan-nel	O
,	O
wecountthefeaturesthatfallineachspatialbin.finally	O
,	O
weweighteachspatialhistogramaccordingtoeq.	O
(	O
3	O
)	O
.theﬁnalimplementationissueisthatofnormalization.formaximumcomputationalefﬁciency	O
,	O
wenormalizeallhistogramsbythetotalweightofallfeaturesintheimage	O
,	O
ineffectforcingthetotalnumberoffeaturesinallimagestobethesame.becauseweuseadensefeaturerepresentation	O
(	O
seesection4	O
)	O
,	O
andthusdonotneedtoworryaboutspuri-ousfeaturedetectionsresultingfromclutter	O
,	O
thispracticeissufﬁcienttodealwiththeeffectsofvariableimagesize.4.featureextractionthissectionbrieﬂydescribesthetwokindsoffeaturesusedintheexperimentsofsection5.first	O
,	O
wehaveso-called	O
“	O
weakfeatures	O
,	O
”	O
whichareorientededgepoints	O
,	O
i.e.	O
,	O
pointswhosegradientmagnitudeinagivendirectionex-ceedsaminimumthreshold.weextractedgepointsattwoscalesandeightorientations	O
,	O
foratotalofm=16chan-nels.wedesignedthesefeaturestoobtainarepresentationsimilartothe	O
“	O
gist	B
”	O
[	O
21	O
]	O
ortoaglobalsiftdescriptor	O
[	O
12	O
]	O
oftheimage.forbetterdiscriminativepower	O
,	O
wealsoutilizehigher-dimensional	O
“	O
strongfeatures	O
,	O
”	O
whicharesiftdescriptorsof16×16pixelpatchescomputedoveragridwithspacingof8pixels.ourdecisiontouseadenseregulargridin-steadofinterestpointswasbasedonthecomparativeevalu-ationoffei-feiandperona	O
[	O
4	O
]	O
,	O
whohaveshownthatdensefeaturesworkbetterforsceneclassiﬁcation.intuitively	O
,	O
adenseimagedescriptionisnecessarytocaptureuniformre-gionssuchassky	O
,	O
calmwater	O
,	O
orroadsurface	O
(	O
todealwithlow-contrastregions	O
,	O
weskiptheusualsiftnormalizationprocedurewhentheoverallgradientmagnitudeofthepatchistooweak	O
)	O
.weperformk-meansclusteringofarandomsubsetofpatchesfromthetrainingsettoformavisualvo-cabulary.typicalvocabularysizesforourexperimentsarem=200andm=400	O
.	O
700	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
14.38	O
a	O
one-dimensional	O
illustration	O
of	O
comparing	O
collections	O
of	O
feature	B
vectors	O
using	O
the	O
pyramid	B
match	O
kernel	B
(	O
grauman	O
and	O
darrell	O
2007b	O
)	O
:	O
(	O
a	O
)	O
distribution	O
of	O
feature	B
vectors	O
(	O
point	O
sets	O
)	O
into	O
the	O
pyramidal	O
bins	O
;	O
(	O
b–c	O
)	O
histogram	B
of	O
point	O
counts	O
in	O
bins	O
bil	O
and	O
b	O
(	O
cid:48	O
)	O
il	O
for	O
the	O
two	O
images	O
;	O
(	O
d	O
)	O
histogram	B
intersections	O
(	O
minimum	O
values	O
)	O
;	O
(	O
e	O
)	O
per-level	O
similarity	B
scores	O
,	O
which	O
are	O
weighted	B
and	O
summed	O
to	O
form	O
the	O
ﬁnal	O
distance/similarity	O
metric	O
.	O
analogous	O
to	O
the	O
pooling	O
performed	O
by	O
sift	O
(	O
lowe	O
2004	O
)	O
and	O
“	O
gist	B
”	O
(	O
torralba	O
,	O
murphy	O
,	O
freeman	O
et	O
al	O
.	O
2003	O
)	O
.	O
in	O
their	O
work	O
,	O
they	O
extract	O
afﬁne	B
region	O
descriptors	O
(	O
lazebnik	O
,	O
schmid	O
,	O
and	O
ponce	O
2005	O
)	O
and	O
quantize	O
them	O
into	O
visual	B
words	I
.	O
(	O
based	O
on	O
previous	O
results	O
by	O
fei-fei	O
and	O
perona	O
(	O
2005	O
)	O
,	O
the	O
feature	B
descriptors	O
are	O
extracted	O
densely	O
(	O
on	O
a	O
regular	O
grid	O
)	O
over	O
the	O
image	B
,	O
which	O
can	O
be	O
helpful	O
in	O
describing	O
textureless	O
regions	O
such	O
as	O
the	O
sky	O
.	O
)	O
they	O
then	O
form	O
a	O
spatial	O
pyramid	B
of	O
bins	O
containing	O
word	O
counts	O
(	O
histograms	O
)	O
,	O
as	O
shown	O
in	O
figure	O
14.37b	O
,	O
and	O
use	O
a	O
similar	O
pyramid	B
match	O
kernel	B
to	O
combine	O
histogram	B
intersection	O
counts	O
in	O
a	O
hierarchical	B
fashion	O
.	O
the	O
debate	O
about	O
whether	O
to	O
use	O
quantized	O
feature	B
descriptors	O
or	O
continuous	O
descriptors	O
and	O
also	O
whether	O
to	O
use	O
sparse	B
or	O
dense	O
features	O
continues	O
to	O
this	O
day	O
.	O
boiman	O
,	O
shechtman	O
,	O
and	O
irani	O
(	O
2008	O
)	O
show	O
that	O
if	O
query	O
images	O
are	O
compared	O
to	O
all	O
the	O
features	O
representing	O
a	O
given	O
class	O
,	O
rather	O
than	O
just	O
each	O
class	O
image	B
individually	O
,	O
nearest-neighbor	O
matching	B
fol-	O
lowed	O
by	O
a	O
na¨ıve	O
bayes	O
classiﬁer	O
outperforms	O
quantized	O
visual	B
words	I
(	O
figure	O
14.39	O
)	O
.	O
in-	O
stead	O
of	O
using	O
generic	O
feature	B
detectors	O
and	O
descriptors	O
,	O
some	O
authors	O
have	O
been	O
investigat-	O
ing	O
learning	B
class-speciﬁc	O
features	O
(	O
ferencz	O
,	O
learned-miller	O
,	O
and	O
malik	O
2008	O
)	O
,	O
often	O
using	O
randomized	O
forests	O
(	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
;	O
moosmann	O
,	O
nowak	O
,	O
and	O
jurie	O
2008	O
;	O
shotton	O
,	O
johnson	O
,	O
and	O
cipolla	O
2008	O
)	O
or	O
combining	O
the	O
feature	B
generation	O
and	O
image	B
classi-	O
14.4	O
category	O
recognition	O
701	O
figure	O
14.39	O
“	O
image-to-image	O
”	O
vs.	O
“	O
image-to-class	O
”	O
distance	O
comparison	O
(	O
boiman	O
,	O
shechtman	O
,	O
and	O
irani	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
.	O
the	O
query	O
image	O
on	O
the	O
upper	O
left	O
may	O
not	O
match	O
the	O
feature	B
distribution	O
of	O
any	O
of	O
the	O
database	O
images	O
in	O
the	O
bottom	O
row	O
.	O
however	O
,	O
if	O
each	O
feature	B
in	O
the	O
query	O
is	O
matched	O
to	O
its	O
closest	O
analog	O
in	O
all	O
the	O
class	O
images	O
,	O
a	O
good	O
match	O
can	O
be	O
found	O
.	O
ﬁcation	O
stages	O
(	O
yang	O
,	O
jin	O
,	O
sukthankar	O
et	O
al	O
.	O
2008	O
)	O
.	O
others	O
,	O
such	O
as	O
serre	O
,	O
wolf	O
,	O
and	O
poggio	O
(	O
2005	O
)	O
and	O
mutch	O
and	O
lowe	O
(	O
2008	O
)	O
use	O
hierarchies	O
of	O
dense	O
feature	O
transforms	O
inspired	O
by	O
biological	O
(	O
visual	O
cortical	O
)	O
processing	O
combined	O
with	O
svms	O
for	O
ﬁnal	O
classiﬁcation	O
.	O
14.4.2	O
part-based	B
models	O
recognizing	O
an	O
object	O
by	O
ﬁnding	O
its	O
constituent	O
parts	O
and	O
measuring	O
their	O
geometric	B
rela-	O
tionships	O
is	O
one	O
of	O
the	O
oldest	O
approaches	O
to	O
object	O
recognition	B
(	O
fischler	O
and	O
elschlager	O
1973	O
;	O
kanade	O
1977	O
;	O
yuille	O
1991	O
)	O
.	O
we	O
have	O
already	O
seen	O
examples	B
of	O
part-based	B
approaches	O
being	O
used	O
for	O
face	O
recognition	B
(	O
figure	O
14.18	O
)	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
;	O
heisele	O
,	O
ho	O
,	O
wu	O
et	O
al	O
.	O
2003	O
;	O
heisele	O
,	O
serre	O
,	O
and	O
poggio	O
2007	O
)	O
and	O
pedestrian	B
detection	O
(	O
figure	O
14.9	O
)	O
(	O
felzen-	O
szwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
2008	O
)	O
.	O
in	O
this	O
section	O
,	O
we	O
look	O
more	O
closely	O
at	O
some	O
of	O
the	O
central	O
issues	O
in	O
part-based	B
recog-	O
nition	O
,	O
namely	O
,	O
the	O
representation	O
of	O
geometric	B
relationships	O
,	O
the	O
representation	O
of	O
individ-	O
ual	O
parts	O
,	O
and	O
algorithms	O
for	O
learning	O
such	O
descriptions	O
and	O
recognizing	O
them	O
at	O
run	O
time	O
.	O
more	O
details	O
on	O
part-based	B
models	O
for	B
recognition	I
can	O
be	O
found	O
in	O
the	O
course	O
notes	O
of	O
fergus	O
(	O
2007b	O
,	O
2009	O
)	O
.	O
the	O
earliest	O
approaches	O
to	O
representing	O
geometric	B
relationships	O
were	O
dubbed	O
pictorial	O
structures	O
by	O
fischler	O
and	O
elschlager	O
(	O
1973	O
)	O
and	O
consisted	O
of	O
spring-like	O
connections	O
between	O
different	O
feature	B
locations	O
(	O
figure	O
14.1a	O
)	O
.	O
to	O
ﬁt	O
a	O
pictorial	O
structure	O
to	O
an	O
image	B
,	O
an	O
energy	O
702	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.40	O
using	O
pictorial	O
structures	O
to	O
locate	O
and	O
track	O
a	O
person	O
(	O
felzenszwalb	O
and	O
hut-	O
tenlocher	O
2005	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
springer	O
.	O
the	O
structure	O
consists	O
of	O
articulated	O
rectangular	O
body	B
parts	O
(	O
torso	O
,	O
head	B
,	O
and	O
limbs	O
)	O
connected	O
in	O
a	O
tree	O
topology	O
that	O
encodes	O
relative	O
part	O
positions	O
and	O
orientations	O
.	O
to	O
ﬁt	O
a	O
pictorial	O
structure	O
model	O
,	O
a	O
binary	O
silhouette	O
image	B
is	O
ﬁrst	O
computed	O
using	O
background	O
subtraction	O
.	O
function	O
of	O
the	O
form	O
e	O
=	O
(	O
cid:88	O
)	O
i	O
vi	O
(	O
li	O
)	O
+	O
(	O
cid:88	O
)	O
ij∈e	O
vij	O
(	O
li	O
,	O
lj	O
)	O
(	O
14.42	O
)	O
is	O
minimized	O
over	O
all	O
potential	O
part	O
locations	O
or	O
poses	O
{	O
li	O
}	O
and	O
pairs	B
of	O
parts	O
(	O
i	O
,	O
j	O
)	O
for	O
which	O
an	O
edge	O
(	O
geometric	B
relationship	O
)	O
exists	O
in	O
e.	O
note	O
how	O
this	O
energy	O
is	O
closely	O
related	O
to	O
that	O
used	O
with	O
markov	O
random	O
ﬁelds	O
(	O
3.108–3.109	O
)	O
,	O
which	O
can	O
be	O
used	O
to	O
embed	O
pictorial	O
structures	O
in	O
a	O
probabilistic	B
framework	O
that	O
makes	O
parameter	O
learning	B
easier	O
(	O
felzenszwalb	O
and	O
huttenlocher	O
2005	O
)	O
.	O
part-based	B
models	O
can	O
have	O
different	O
topologies	O
for	O
the	O
geometric	B
connections	O
between	O
the	O
parts	O
(	O
figure	O
14.41	O
)	O
.	O
for	O
example	O
,	O
felzenszwalb	O
and	O
huttenlocher	O
(	O
2005	O
)	O
restrict	O
the	O
connections	O
to	O
a	O
tree	O
(	O
figure	O
14.41d	O
)	O
,	O
which	O
makes	O
learning	B
and	O
inference	B
more	O
tractable	O
.	O
a	O
tree	O
topology	O
enables	O
the	O
use	O
of	O
a	O
recursive	O
viterbi	O
(	O
dynamic	B
programming	I
)	O
algorithm	B
(	O
pearl	O
1988	O
;	O
bishop	O
2006	O
)	O
,	O
in	O
which	O
leaf	O
nodes	O
are	O
ﬁrst	O
optimized	O
as	O
a	O
function	O
of	O
their	O
parents	O
,	O
and	O
the	O
resulting	O
values	O
are	O
then	O
plugged	O
in	O
and	O
eliminated	O
from	O
the	O
energy	O
function—see	O
ap-	O
pendix	O
b.5.2	O
.	O
the	O
viterbi	O
algorithm	B
computes	O
an	O
optimal	O
match	O
in	O
o	O
(	O
n	O
2|e|	O
+	O
n	O
p	O
)	O
time	O
,	O
where	O
n	O
is	O
the	O
number	O
of	O
potential	O
locations	O
or	O
poses	O
for	O
each	O
part	O
,	O
|e|	O
is	O
the	O
number	O
of	O
edges	O
(	O
pairwise	O
constraints	O
)	O
,	O
and	O
p	O
=	O
|v	O
|	O
is	O
the	O
number	O
of	O
parts	O
(	O
vertices	O
in	O
the	O
graphical	O
model	O
,	O
which	O
is	O
equal	O
to	O
|e|	O
+	O
1	O
in	O
a	O
tree	O
)	O
.	O
to	O
further	O
increase	O
the	O
efﬁciency	B
of	O
the	O
infer-	O
ence	O
algorithm	B
,	O
felzenszwalb	O
and	O
huttenlocher	O
(	O
2005	O
)	O
restrict	O
the	O
pairwise	O
energy	O
functions	O
vij	O
(	O
li	O
,	O
lj	O
)	O
to	O
be	O
mahalanobis	O
distances	O
on	O
functions	O
of	O
location	O
variables	O
and	O
then	O
use	O
fast	O
distance	O
transform	B
algorithms	O
to	O
minimize	O
each	O
pairwise	O
interaction	O
in	O
time	O
that	O
is	O
closer	O
to	O
linear	B
in	O
n.	O
figure	O
14.40	O
shows	O
the	O
results	O
of	O
using	O
their	O
pictorial	O
structures	O
algorithm	B
to	O
ﬁt	O
an	O
articu-	O
14.4	O
category	O
recognition	O
703	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
figure	O
14.41	O
graphical	O
models	O
for	O
geometric	O
spatial	O
priors	O
(	O
carneiro	O
and	O
lowe	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
springer	O
:	O
(	O
a	O
)	O
constellation	O
(	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2007	O
)	O
;	O
(	O
b	O
)	O
star	O
(	O
crandall	O
,	O
felzenszwalb	O
,	O
and	O
huttenlocher	O
2005	O
;	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2005	O
)	O
;	O
(	O
c	O
)	O
k-fan	O
(	O
k	O
=	O
2	O
)	O
(	O
crandall	O
,	O
felzenszwalb	O
,	O
and	O
huttenlocher	O
2005	O
)	O
;	O
(	O
d	O
)	O
tree	O
(	O
felzenszwalb	O
and	O
huttenlocher	O
2005	O
)	O
;	O
(	O
e	O
)	O
bag	O
of	O
features	O
(	O
csurka	O
,	O
dance	O
,	O
fan	O
et	O
al	O
.	O
2004	O
)	O
;	O
(	O
f	O
)	O
hierarchy	B
(	O
bouchard	O
and	O
triggs	O
2005	O
)	O
;	O
(	O
g	O
)	O
sparse	B
ﬂexible	O
model	O
(	O
carneiro	O
and	O
lowe	O
2006	O
)	O
.	O
lated	O
body	B
model	O
to	O
a	O
binary	O
image	O
obtained	O
by	O
background	O
segmentation	B
.	O
in	O
this	O
application	O
of	O
pictorial	O
structures	O
,	O
parts	O
are	O
parameterized	O
by	O
the	O
locations	O
,	O
sizes	O
,	O
and	O
orientations	O
of	O
their	O
approximating	O
rectangles	O
.	O
unary	O
matching	B
potentials	O
vi	O
(	O
li	O
)	O
are	O
determined	O
by	O
counting	O
the	O
percentage	O
of	O
foreground	O
and	O
background	O
pixels	O
inside	O
and	O
just	O
outside	O
the	O
tilted	O
rectangle	O
representing	O
each	O
part	O
.	O
over	O
the	O
last	O
decade	O
,	O
a	O
large	O
number	O
of	O
different	O
graphical	O
models	O
have	O
been	O
proposed	O
for	O
part-based	O
recognition	B
,	O
as	O
shown	O
in	O
figure	O
14.41.	O
carneiro	O
and	O
lowe	O
(	O
2006	O
)	O
discuss	O
a	O
number	O
of	O
these	O
models	O
and	O
propose	O
one	O
of	O
their	O
own	O
,	O
which	O
they	O
call	O
a	O
sparse	B
ﬂexible	O
model	O
;	O
it	O
involves	O
ordering	O
the	O
parts	O
and	O
having	O
each	O
part	O
’	O
s	O
location	O
depend	O
on	O
at	O
most	O
k	O
of	O
its	O
ancestor	O
locations	O
.	O
the	O
simplest	O
models	O
,	O
which	O
we	O
saw	O
in	O
section	O
14.4.1	O
,	O
are	O
bags	O
of	O
words	O
,	O
where	O
there	O
are	O
no	O
geometric	B
relationships	O
between	O
different	O
parts	O
or	O
features	O
.	O
while	O
such	O
models	O
can	O
be	O
very	O
efﬁcient	O
,	O
they	O
have	O
a	O
very	O
limited	O
capacity	O
to	O
express	O
the	O
spatial	O
arrangement	O
of	O
parts	O
.	O
trees	O
and	O
stars	O
(	O
a	O
special	O
case	O
of	O
trees	O
where	O
all	O
leaf	O
nodes	O
are	O
directly	O
connected	O
to	O
a	O
common	O
root	O
)	O
are	O
the	O
most	O
efﬁcient	O
in	O
terms	O
of	O
inference	B
and	O
hence	O
also	O
learning	B
(	O
felzenszwalb	O
and	O
hutten-	O
locher	O
2005	O
;	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2005	O
;	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
2008	O
)	O
.	O
directed	O
acyclic	O
graphs	O
(	O
figure	O
14.41f–g	O
)	O
come	O
next	O
in	O
terms	O
of	O
complexity	O
and	O
can	O
still	O
support	O
efﬁcient	O
inference	B
,	O
although	O
at	O
the	O
cost	O
of	O
imposing	O
a	O
causal	O
structure	O
on	O
the	O
sparseflexiblemodelsoflocalfeatures31x1x2x3x4x5x6x1x2x3x4x5x6x4x5x3x6x2x1x1x2x3x4x5x6a	O
)	O
constellation	O
[	O
13	O
]	O
b	O
)	O
starshape	O
[	O
9,14	O
]	O
c	O
)	O
k-fan	O
(	O
k=2	O
)	O
[	O
9	O
]	O
d	O
)	O
tree	O
[	O
12	O
]	O
x2x3x4x5x6x1gh1hgl1l2lkx1x3x2x5x6x7	O
.	O
.	O
..	O
.	O
.centerpartsubpart	O
.	O
.	O
.x1x2x3x4x5x6x1x2x3x4x5x6k=1k=2e	O
)	O
bagoffeatures	O
[	O
10,21	O
]	O
f	O
)	O
hierarchy	B
[	O
4	O
]	O
g	O
)	O
sparseﬂexiblemodelfig.1.graphicalgeometricmodelsofpriors.notethatxirepresentsamodelpart.environmentswherenewunannotatedtrainingimagesarecontinuouslypre-sentedtothelearningsystem.inthispaperwepropose:1	O
)	O
anewmodelforthevisualclassiﬁcationprob-lemthatcontainsalessrestrictiveprioronthegeometryandnumberoflocalfeatures	O
,	O
wherethegeometryofeachmodelpartdependsonthegeometryofitskclosestneighbors	O
;	O
and2	O
)	O
anunsupervisedon-linelearningalgorithmthatiscapableofidentifyingcommonalitiesamonginputimages	O
,	O
formingclustersofimageswithsimilarappearances	O
,	O
andalsoestimatingthemodelparameterseﬃcientlyandaccurately.ascommonlyassumedinthestate-of-the-artworks	O
,	O
wealsoassumethattheappearanceandthegeometryofpartsareindepen-dentgiventhemodel	O
,	O
andthattheappearanceofpartsismutuallyindependentgivenmodel.themainnoveltyofourmodelisapriorbasedonasemi-fulldependencyofthegeometryofpartsgivenmodel	O
(	O
seefig.1-	O
(	O
g	O
)	O
)	O
.notefromthegraphrepresentingourmodelthatthegeometryofeachfeaturedependsonthegeometryofitskneighboringfeatures	O
,	O
wherekisaparameterthatdeﬁnesthedegreeofconnectivityofeachpart.thispriorenablesanexplicitcontrolontheconnectivityoftheparts	O
,	O
anditalsoallowsfortheobjectbeingmodeledtohave	O
(	O
semi-	O
)	O
localrigiddeformationwithintheareacoveredbytheconnectedfea-tures	O
,	O
andrigid/non-rigidglobaldeformation.ourobjectivewiththisnewmodelistoextendthetypesofclassesthatcanberepresentedwithlocalimagefea-turessincethemodelcanpotentiallyhavehundredsofparts	O
,	O
tightlyconnectedlocally	O
,	O
butlooselyconnectedglobally.weimplementanewvisualclassrecognitionsystemusingthisnewmodelandlearningmethoddescribedabove	O
,	O
anddemonstratethatoursystempro-ducescompetitiveclassiﬁcationandlocalizationresultscomparedtostate-of-the-artmethodsusingstandarddatabases.moreover	O
,	O
weshowthatthelearningalgorithmisabletomodelnotonlyclasseswithreasonabletexture	O
(	O
e.g.	O
,	O
faces	B
)	O
,	O
butalsoclasseswithshapeonly	O
(	O
e.g.	O
,	O
leaves	O
)	O
,	O
classeswithacommonshapebutwithagreatvariabilityintermsofinternaltexture	O
(	O
e.g.	O
,	O
cups	O
)	O
,	O
andclassesofﬂexibleobjects	O
(	O
e.g.	O
,	O
snakes	B
)	O
.sparseflexiblemodelsoflocalfeatures31x1x2x3x4x5x6x1x2x3x4x5x6x4x5x3x6x2x1x1x2x3x4x5x6a	O
)	O
constellation	O
[	O
13	O
]	O
b	O
)	O
starshape	O
[	O
9,14	O
]	O
c	O
)	O
k-fan	O
(	O
k=2	O
)	O
[	O
9	O
]	O
d	O
)	O
tree	O
[	O
12	O
]	O
x2x3x4x5x6x1gh1hgl1l2lkx1x3x2x5x6x7	O
.	O
.	O
..	O
.	O
.centerpartsubpart	O
.	O
.	O
.x1x2x3x4x5x6x1x2x3x4x5x6k=1k=2e	O
)	O
bagoffeatures	O
[	O
10,21	O
]	O
f	O
)	O
hierarchy	B
[	O
4	O
]	O
g	O
)	O
sparseﬂexiblemodelfig.1.graphicalgeometricmodelsofpriors.notethatxirepresentsamodelpart.environmentswherenewunannotatedtrainingimagesarecontinuouslypre-sentedtothelearningsystem.inthispaperwepropose:1	O
)	O
anewmodelforthevisualclassiﬁcationprob-lemthatcontainsalessrestrictiveprioronthegeometryandnumberoflocalfeatures	O
,	O
wherethegeometryofeachmodelpartdependsonthegeometryofitskclosestneighbors	O
;	O
and2	O
)	O
anunsupervisedon-linelearningalgorithmthatiscapableofidentifyingcommonalitiesamonginputimages	O
,	O
formingclustersofimageswithsimilarappearances	O
,	O
andalsoestimatingthemodelparameterseﬃcientlyandaccurately.ascommonlyassumedinthestate-of-the-artworks	O
,	O
wealsoassumethattheappearanceandthegeometryofpartsareindepen-dentgiventhemodel	O
,	O
andthattheappearanceofpartsismutuallyindependentgivenmodel.themainnoveltyofourmodelisapriorbasedonasemi-fulldependencyofthegeometryofpartsgivenmodel	O
(	O
seefig.1-	O
(	O
g	O
)	O
)	O
.notefromthegraphrepresentingourmodelthatthegeometryofeachfeaturedependsonthegeometryofitskneighboringfeatures	O
,	O
wherekisaparameterthatdeﬁnesthedegreeofconnectivityofeachpart.thispriorenablesanexplicitcontrolontheconnectivityoftheparts	O
,	O
anditalsoallowsfortheobjectbeingmodeledtohave	O
(	O
semi-	O
)	O
localrigiddeformationwithintheareacoveredbytheconnectedfea-tures	O
,	O
andrigid/non-rigidglobaldeformation.ourobjectivewiththisnewmodelistoextendthetypesofclassesthatcanberepresentedwithlocalimagefea-turessincethemodelcanpotentiallyhavehundredsofparts	O
,	O
tightlyconnectedlocally	O
,	O
butlooselyconnectedglobally.weimplementanewvisualclassrecognitionsystemusingthisnewmodelandlearningmethoddescribedabove	O
,	O
anddemonstratethatoursystempro-ducescompetitiveclassiﬁcationandlocalizationresultscomparedtostate-of-the-artmethodsusingstandarddatabases.moreover	O
,	O
weshowthatthelearningalgorithmisabletomodelnotonlyclasseswithreasonabletexture	O
(	O
e.g.	O
,	O
faces	B
)	O
,	O
butalsoclasseswithshapeonly	O
(	O
e.g.	O
,	O
leaves	O
)	O
,	O
classeswithacommonshapebutwithagreatvariabilityintermsofinternaltexture	O
(	O
e.g.	O
,	O
cups	O
)	O
,	O
andclassesofﬂexibleobjects	O
(	O
e.g.	O
,	O
snakes	B
)	O
.	O
704	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
part	O
model	O
(	O
bouchard	O
and	O
triggs	O
2005	O
;	O
carneiro	O
and	O
lowe	O
2006	O
)	O
.	O
k-fans	O
,	O
in	O
which	O
a	O
clique	O
of	O
size	O
k	O
forms	O
the	O
root	O
of	O
a	O
star-shaped	O
model	O
(	O
figure	O
14.41c	O
)	O
have	O
inference	B
complexity	O
o	O
(	O
n	O
k+1	O
)	O
,	O
although	O
with	O
distance	O
transforms	O
and	O
gaussian	O
priors	O
,	O
this	O
can	O
be	O
lowered	O
to	O
o	O
(	O
n	O
k	O
)	O
(	O
crandall	O
,	O
felzenszwalb	O
,	O
and	O
huttenlocher	O
2005	O
;	O
crandall	O
and	O
huttenlocher	O
2006	O
)	O
.	O
finally	O
,	O
fully	O
connected	O
constellation	O
models	O
(	O
figure	O
14.41a	O
)	O
are	O
the	O
most	O
general	O
,	O
but	O
the	O
assignment	O
of	O
features	O
to	O
parts	O
becomes	O
intractable	O
for	O
moderate	O
numbers	O
of	O
parts	O
p	O
,	O
since	O
the	O
complexity	O
of	O
such	O
an	O
assignment	O
is	O
o	O
(	O
n	O
p	O
)	O
(	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2007	O
)	O
.	O
the	O
original	O
constellation	B
model	I
was	O
developed	O
by	O
burl	O
,	O
weber	O
,	O
and	O
perona	O
(	O
1998	O
)	O
and	O
consists	O
of	O
a	O
number	O
of	O
parts	O
whose	O
relative	O
positions	O
are	O
encoded	O
by	O
their	O
mean	O
locations	O
and	O
a	O
full	O
covariance	O
matrix	O
,	O
which	O
is	O
used	O
to	O
denote	O
not	O
only	O
positional	O
uncertainty	B
but	O
also	O
potential	O
correlations	O
(	O
covariance	O
)	O
between	O
different	O
parts	O
(	O
figure	O
14.42a	O
)	O
.	O
weber	O
,	O
welling	O
,	O
and	O
perona	O
(	O
2000	O
)	O
extended	O
this	O
technique	O
to	O
a	O
weakly	O
supervised	O
setting	O
,	O
where	O
both	O
the	O
appearance	O
of	O
each	O
part	O
and	O
its	O
locations	O
are	O
automatically	O
learned	B
given	O
only	O
whole	O
image	B
labels	O
.	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
(	O
2007	O
)	O
further	O
extend	O
this	O
approach	O
to	O
simultaneous	O
learning	B
of	O
appearance	O
and	O
shape	O
models	O
from	O
scale-invariant	O
keypoint	O
detections	O
.	O
figure	O
14.42a	O
shows	O
the	O
shape	O
model	O
learned	B
for	O
the	O
motorcycle	O
class	O
.	O
the	O
top	O
ﬁgure	O
shows	O
the	O
mean	O
relative	O
locations	O
for	O
each	O
part	O
along	O
with	O
their	O
position	O
covariances	O
(	O
inter-	O
part	O
covariances	O
are	O
not	O
shown	O
)	O
and	O
likelihood	O
of	O
occurrence	O
.	O
the	O
bottom	O
curve	O
shows	O
the	O
gaussian	O
pdfs	O
for	O
the	O
relative	O
log-scale	O
of	O
each	O
part	O
with	O
respect	O
to	O
the	O
“	O
landmark	O
”	O
feature	B
.	O
figure	O
14.42b	O
shows	O
the	O
appearance	O
model	O
learned	B
for	O
each	O
part	O
,	O
visualized	O
as	O
the	O
patches	O
around	O
detected	O
features	O
in	O
the	O
training	O
database	O
that	O
best	O
match	O
the	O
appearance	O
model	O
.	O
fig-	O
ure	O
14.42c	O
shows	O
the	O
features	O
detected	O
in	O
the	O
test	O
database	O
(	O
pink	O
dots	O
)	O
along	O
with	O
the	O
corre-	O
sponding	O
parts	O
that	O
they	O
were	O
assigned	O
to	O
(	O
colored	O
circles	O
)	O
.	O
as	O
you	O
can	O
see	O
,	O
the	O
system	O
has	O
successfully	O
learned	B
and	O
then	O
used	O
a	O
fairly	O
complex	O
model	O
of	O
motorcycle	O
appearance	O
.	O
the	O
part-based	B
approach	O
to	O
recognition	B
has	O
also	O
been	O
extended	O
to	O
learning	B
new	O
categories	O
from	O
small	O
numbers	O
of	O
examples	B
,	O
building	O
on	O
recognition	B
components	O
developed	O
for	O
other	O
classes	O
(	O
fei-fei	O
,	O
fergus	O
,	O
and	O
perona	O
2006	O
)	O
.	O
more	O
complex	O
hierarchical	B
part-based	O
models	O
can	O
be	O
developed	O
using	O
the	O
concept	O
of	O
grammars	O
(	O
bouchard	O
and	O
triggs	O
2005	O
;	O
zhu	O
and	O
mumford	O
2006	O
)	O
.	O
a	O
simpler	O
way	O
to	O
use	O
parts	O
is	O
to	O
have	O
keypoints	O
that	O
are	O
recognized	O
as	O
being	O
part	O
of	O
a	O
class	O
vote	O
for	O
the	O
estimated	O
part	O
locations	O
,	O
as	O
shown	O
in	O
the	O
top	O
row	O
of	O
figure	O
14.43	O
(	O
leibe	O
,	O
leonardis	O
,	O
and	O
schiele	O
2008	O
)	O
.	O
(	O
implicitly	O
,	O
this	O
corresponds	O
to	O
having	O
a	O
star-shaped	O
geometric	B
model	O
.	O
)	O
14.4.3	O
recognition	B
with	O
segmentation	B
the	O
most	O
challenging	O
version	O
of	O
generic	O
object	O
recognition	B
is	O
to	O
simultaneously	O
perform	O
recognition	B
with	O
accurate	O
boundary	O
segmentation	O
(	O
fergus	O
2007a	O
)	O
.	O
for	O
instance	O
recognition	B
(	O
section	O
14.3.1	O
)	O
,	O
this	O
can	O
sometimes	O
be	O
achieved	O
by	O
backprojecting	O
the	O
object	O
model	O
into	O
14.4	O
category	O
recognition	O
705	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
14.42	O
part-based	B
recognition	O
(	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
springer	O
:	O
(	O
a	O
)	O
locations	O
and	O
covariance	O
ellipses	O
for	O
each	O
part	O
,	O
along	O
with	O
their	O
occurrence	O
probabilities	O
(	O
top	O
)	O
and	O
relative	O
log-scale	O
densities	O
(	O
bottom	O
)	O
;	O
(	O
b	O
)	O
part	O
examples	B
drawn	O
from	O
the	O
training	O
images	O
that	O
best	O
match	O
the	O
average	O
appearance	O
;	O
(	O
c	O
)	O
recognition	B
results	O
for	O
the	O
motorcycle	O
class	O
,	O
showing	O
detected	O
features	O
(	O
pink	O
dots	O
)	O
and	O
parts	O
(	O
colored	O
circles	O
)	O
.	O
correctcorrectincorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectcorrectincorrectincorrectcorrectincorrectcorrectcorrectcorrect	O
706	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.43	O
interleaved	O
recognition	B
and	O
segmentation	B
(	O
leibe	O
,	O
leonardis	O
,	O
and	O
schiele	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
springer	O
.	O
the	O
process	O
starts	O
by	O
re-recognizing	O
visual	B
words	I
(	O
codebook	O
en-	O
tries	O
)	O
in	O
a	O
new	O
image	B
(	O
scene	O
)	O
and	O
having	O
each	O
part	O
vote	O
for	O
likely	O
locations	O
and	O
size	O
in	O
a	O
3d	O
(	O
x	O
,	O
y	O
,	O
s	O
)	O
voting	O
space	O
(	O
top	O
row	O
)	O
.	O
once	O
a	O
maximum	O
has	O
been	O
found	O
,	O
the	O
parts	O
(	O
features	O
)	O
corresponding	O
to	O
this	O
instance	B
are	O
determined	O
by	O
backprojecting	O
the	O
contributing	O
votes	O
.	O
the	O
foreground–background	O
segmentation	B
for	O
each	O
object	O
can	O
be	O
found	O
by	O
backprojecting	O
proba-	O
bilistic	O
masks	O
associated	O
with	O
each	O
codebook	O
entry	O
.	O
the	O
whole	O
recognition	B
and	O
segmentation	B
process	O
can	O
then	O
be	O
repeated	O
.	O
the	O
scene	O
(	O
lowe	O
2004	O
)	O
,	O
as	O
shown	O
in	O
figure	O
14.1d	O
,	O
or	O
matching	B
portions	O
of	O
the	O
new	O
scene	O
to	O
pre-learned	O
(	O
segmented	O
)	O
object	O
models	O
(	O
ferrari	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
2006b	O
;	O
kannala	O
,	O
rahtu	O
,	O
brandt	O
et	O
al	O
.	O
2008	O
)	O
.	O
for	O
more	O
complex	O
(	O
ﬂexible	O
)	O
object	O
models	O
,	O
such	O
as	O
those	O
for	O
humans	O
figure	O
14.1f	O
,	O
a	O
different	O
approach	O
is	O
to	O
pre-segment	O
the	O
image	B
into	O
larger	O
or	O
smaller	O
pieces	O
(	O
chapter	O
5	O
)	O
and	O
then	O
match	O
such	O
pieces	O
to	O
portions	O
of	O
the	O
model	O
(	O
mori	O
,	O
ren	O
,	O
efros	O
et	O
al	O
.	O
2004	O
;	O
mori	O
2005	O
;	O
he	O
,	O
zemel	O
,	O
and	O
ray	O
2006	O
;	O
gu	O
,	O
lim	O
,	O
arbelaez	O
et	O
al	O
.	O
2009	O
)	O
.	O
an	O
alternative	O
approach	O
by	O
leibe	O
,	O
leonardis	O
,	O
and	O
schiele	O
(	O
2008	O
)	O
,	O
which	O
we	O
introduced	O
in	O
the	O
previous	O
section	O
,	O
votes	O
for	O
potential	O
object	O
locations	O
and	O
scales	O
based	O
on	O
the	O
detec-	O
tion	B
of	O
features	O
corresponding	O
to	O
pre-clustered	O
visual	O
codebook	O
entries	O
(	O
figure	O
14.43	O
)	O
.	O
to	O
support	O
segmentation	O
,	O
each	O
codebook	O
entry	O
has	O
an	O
associated	O
foreground–background	O
mask	B
,	O
which	O
is	O
learned	B
as	O
part	O
of	O
the	O
codebook	O
clustering	O
process	O
from	O
pre-labeled	O
object	O
segmen-	O
tation	O
masks	O
.	O
during	O
recognition	B
,	O
once	O
a	O
maximum	O
in	O
the	O
voting	O
space	O
is	O
found	O
,	O
the	O
masks	O
associated	O
with	O
the	O
entries	O
that	O
voted	O
for	O
this	O
instance	B
are	O
combined	O
to	O
obtain	O
an	O
object	O
seg-	O
mentation	O
,	O
as	O
shown	O
on	O
the	O
left	O
side	O
of	O
figure	O
14.43.	O
a	O
more	O
holistic	O
approach	O
to	O
recognition	B
and	O
segmentation	B
is	O
to	O
formulate	O
the	O
problem	O
as	O
one	O
of	O
labeling	O
every	O
pixel	O
in	O
an	O
image	B
with	O
its	O
class	O
membership	O
,	O
and	O
to	O
solve	O
this	O
prob-	O
14.4	O
category	O
recognition	O
707	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
14.44	O
simultaneous	O
recognition	B
and	O
segmentation	B
using	O
textonboost	O
(	O
shotton	O
,	O
winn	O
,	O
rother	O
et	O
al	O
.	O
2009	O
)	O
c	O
(	O
cid:13	O
)	O
2009	O
springer	O
:	O
(	O
a	O
)	O
successful	O
recognition	B
results	O
;	O
(	O
b	O
)	O
less	O
suc-	O
cessful	O
results	O
.	O
708	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.45	O
layout	B
consistent	I
random	O
ﬁeld	O
(	O
winn	O
and	O
shotton	O
2006	O
)	O
c	O
(	O
cid:13	O
)	O
2006	O
ieee	O
.	O
the	O
numbers	O
indicate	O
the	O
kind	O
of	O
neighborhood	B
relations	O
that	O
can	O
exist	O
between	O
pixels	O
assigned	O
to	O
the	O
same	O
or	O
different	O
classes	O
.	O
each	O
pairwise	O
relationship	O
carries	O
its	O
own	O
likelihood	O
(	O
energy	O
penalty	O
)	O
.	O
lem	O
using	O
energy	O
minimization	O
or	O
bayesian	O
inference	B
techniques	O
,	O
i.e.	O
,	O
conditional	O
random	O
ﬁelds	O
(	O
section	O
3.7.2	O
,	O
(	O
3.118	O
)	O
)	O
(	O
kumar	O
and	O
hebert	O
2006	O
;	O
he	O
,	O
zemel	O
,	O
and	O
carreira-perpi˜n´an	O
2004	O
)	O
.	O
the	O
textonboost	O
system	O
of	O
shotton	O
,	O
winn	O
,	O
rother	O
et	O
al	O
.	O
(	O
2009	O
)	O
uses	O
unary	O
(	O
pixel-	O
wise	O
)	O
potentials	O
based	O
on	O
image-speciﬁc	O
color	B
distributions	O
(	O
section	O
5.5	O
)	O
(	O
boykov	O
and	O
jolly	O
2001	O
;	O
rother	O
,	O
kolmogorov	O
,	O
and	O
blake	O
2004	O
)	O
,	O
location	O
information	O
(	O
e.g.	O
,	O
foreground	O
objects	O
are	O
more	O
likely	O
to	O
be	O
in	O
the	O
middle	O
of	O
the	O
image	B
,	O
sky	O
is	O
likely	O
to	O
be	O
higher	O
,	O
and	O
road	O
is	O
likely	O
to	O
be	O
lower	O
)	O
,	O
and	O
novel	O
texture-layout	O
classiﬁers	O
trained	O
using	O
shared	O
boosting	B
.	O
it	O
also	O
uses	O
traditional	O
pairwise	O
potentials	O
that	O
look	O
at	O
image	B
color	O
gradients	O
(	O
veksler	O
2001	O
;	O
boykov	O
and	O
jolly	O
2001	O
;	O
rother	O
,	O
kolmogorov	O
,	O
and	O
blake	O
2004	O
)	O
.	O
the	O
texton-layout	O
features	O
ﬁrst	O
ﬁlter	O
the	O
image	B
with	O
a	O
series	O
of	O
17	O
oriented	B
ﬁlter	O
banks	O
and	O
then	O
cluster	O
the	O
responses	O
to	O
classify	O
each	O
pixel	O
into	O
30	O
different	O
texton	O
classes	O
(	O
malik	O
,	O
belongie	O
,	O
leung	O
et	O
al	O
.	O
2001	O
)	O
.	O
the	O
responses	O
are	O
then	O
ﬁltered	O
using	O
offset	O
rectangular	O
regions	O
trained	O
with	O
joint	O
boosting	B
(	O
viola	O
and	O
jones	O
2004	O
)	O
to	O
produce	O
the	O
texton-layout	O
features	O
used	O
as	O
unary	O
potentials	O
.	O
figure	O
14.44a	O
shows	O
some	O
examples	B
of	O
images	O
successfully	O
labeled	O
and	O
segmented	O
using	O
textonboost	O
,	O
while	O
figure	O
14.44b	O
shows	O
examples	B
where	O
it	O
does	O
not	O
do	O
as	O
well	O
.	O
as	O
you	O
can	O
see	O
,	O
this	O
kind	O
of	O
semantic	O
labeling	O
can	O
be	O
extremely	O
challenging	O
.	O
the	O
textonboost	O
conditional	O
random	O
ﬁeld	O
framework	O
has	O
been	O
extended	O
to	O
layoutcrfs	O
by	O
winn	O
and	O
shotton	O
(	O
2006	O
)	O
,	O
who	O
incorporate	O
additional	O
constraints	O
to	O
recognize	O
multiple	B
object	O
instances	O
and	O
deal	O
with	O
occlusions	O
(	O
figure	O
14.45	O
)	O
,	O
and	O
even	O
more	O
recently	O
by	O
hoiem	O
,	O
rother	O
,	O
and	O
winn	O
(	O
2007	O
)	O
to	O
incorporate	O
full	O
3d	O
models	O
.	O
conditional	O
random	O
ﬁelds	O
continue	O
to	O
be	O
widely	O
used	O
and	O
extended	O
for	O
simultaneous	O
recognition	B
and	O
segmentation	B
applications	O
(	O
kumar	O
and	O
hebert	O
2006	O
;	O
he	O
,	O
zemel	O
,	O
and	O
ray	O
2006	O
;	O
levin	O
and	O
weiss	O
2006	O
;	O
verbeek	O
and	O
triggs	O
2007	O
;	O
yang	O
,	O
meer	O
,	O
and	O
foran	O
2007	O
;	O
rabi-	O
novich	O
,	O
vedaldi	O
,	O
galleguillos	O
et	O
al	O
.	O
2007	O
;	O
batra	O
,	O
sukthankar	O
,	O
and	O
chen	O
2008	O
;	O
larlus	O
and	O
jurie	O
14.4	O
category	O
recognition	O
709	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
14.46	O
scene	B
completion	I
using	O
millions	O
of	O
photographs	O
(	O
hays	O
and	O
efros	O
2007	O
)	O
c	O
(	O
cid:13	O
)	O
2007	O
acm	O
:	O
(	O
a	O
)	O
original	O
image	B
;	O
(	O
b	O
)	O
after	O
unwanted	O
foreground	O
removal	O
;	O
(	O
c	O
)	O
plausible	O
scene	O
matches	O
,	O
with	O
the	O
one	O
the	O
user	O
selected	O
highlighted	O
in	O
red	O
;	O
(	O
d	O
)	O
output	O
image	B
after	O
replacement	O
and	O
blending	B
.	O
2008	O
;	O
he	O
and	O
zemel	O
2008	O
;	O
kumar	O
,	O
torr	O
,	O
and	O
zisserman	O
2010	O
)	O
,	O
producing	O
some	O
of	O
the	O
best	O
results	O
on	O
the	O
difﬁcult	O
pascal	O
voc	O
segmentation	B
challenge	O
(	O
shotton	O
,	O
johnson	O
,	O
and	O
cipolla	O
2008	O
;	O
kohli	O
,	O
ladick´y	O
,	O
and	O
torr	O
2009	O
)	O
.	O
approaches	O
that	O
ﬁrst	O
segment	O
the	O
image	B
into	O
unique	O
or	O
multiple	B
segmentations	O
(	O
borenstein	O
and	O
ullman	O
2008	O
;	O
he	O
,	O
zemel	O
,	O
and	O
ray	O
2006	O
;	O
russell	O
,	O
efros	O
,	O
sivic	O
et	O
al	O
.	O
2006	O
)	O
(	O
potentially	O
combined	O
with	O
crf	O
models	O
)	O
also	O
do	O
quite	O
well	O
:	O
csurka	O
and	O
perronnin	O
(	O
2008	O
)	O
have	O
one	O
of	O
the	O
top	O
algorithms	O
in	O
the	O
voc	O
segmentation	B
challenge	O
.	O
hierarchical	B
(	O
multi-scale	O
)	O
and	O
grammar	O
(	O
parsing	O
)	O
models	O
are	O
also	O
sometimes	O
used	O
(	O
tu	O
,	O
chen	O
,	O
yuille	O
et	O
al	O
.	O
2005	O
;	O
zhu	O
,	O
chen	O
,	O
lin	O
et	O
al	O
.	O
2008	O
)	O
.	O
14.4.4	O
application	O
:	O
intelligent	B
photo	I
editing	I
recent	O
advances	O
in	O
object	O
recognition	B
and	O
scene	B
understanding	I
have	O
greatly	O
increased	O
the	O
power	O
of	O
intelligent	O
(	O
semi-automated	O
)	O
photo	O
editing	O
applications	O
.	O
one	O
example	O
is	O
the	O
photo	O
clip	O
art	O
system	O
of	O
lalonde	O
,	O
hoiem	O
,	O
efros	O
et	O
al	O
.	O
(	O
2007	O
)	O
,	O
which	O
recognizes	O
and	O
segments	O
objects	O
of	O
interest	O
,	O
such	O
as	O
pedestrians	O
,	O
in	O
internet	O
photo	O
collections	O
and	O
then	O
allows	O
users	O
to	O
paste	O
them	O
into	O
their	O
own	O
photos	O
.	O
another	O
is	O
the	O
scene	B
completion	I
system	O
of	O
hays	O
and	O
efros	O
(	O
2007	O
)	O
,	O
which	O
tackles	O
the	O
same	O
inpainting	B
problem	O
we	O
studied	O
in	O
section	O
10.5.	O
given	O
an	O
image	B
in	O
which	O
we	O
wish	O
to	O
erase	O
and	O
ﬁll	O
in	O
a	O
large	O
section	O
(	O
figure	O
14.46a–b	O
)	O
,	O
where	O
do	O
you	O
get	O
the	O
pixels	O
to	O
ﬁll	O
in	O
the	O
gaps	O
in	O
the	O
edited	O
image	B
?	O
traditional	O
approaches	O
either	O
use	O
smooth	O
continuation	O
(	O
bertalmio	O
,	O
sapiro	O
,	O
caselles	O
et	O
al	O
.	O
2000	O
)	O
or	O
borrowing	O
pixels	O
from	O
other	O
parts	O
of	O
the	O
image	B
(	O
efros	O
and	O
leung	O
1999	O
;	O
criminisi	O
,	O
p´erez	O
,	O
and	O
toyama	O
2004	O
;	O
efros	O
and	O
freeman	O
2001	O
)	O
.	O
with	O
the	O
advent	O
of	O
huge	O
repositories	O
of	O
images	O
on	O
the	O
web	O
(	O
a	O
topic	O
we	O
return	O
to	O
in	O
section	O
14.5.1	O
)	O
,	O
it	O
often	O
makes	O
more	O
sense	O
to	O
ﬁnd	O
a	O
different	O
image	B
to	O
serve	O
as	O
the	O
source	O
of	O
the	O
missing	O
pixels	O
.	O
in	O
their	O
system	O
,	O
hays	O
and	O
efros	O
(	O
2007	O
)	O
compute	O
the	O
gist	B
of	O
each	O
image	B
(	O
oliva	O
and	O
tor-	O
710	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
14.47	O
automatic	B
photo	O
pop-up	O
(	O
hoiem	O
,	O
efros	O
,	O
and	O
hebert	O
2005a	O
)	O
c	O
(	O
cid:13	O
)	O
2005	O
acm	O
:	O
(	O
a	O
)	O
input	O
image	B
;	O
(	O
b	O
)	O
superpixels	O
are	O
grouped	O
into	O
(	O
c	O
)	O
multiple	B
regions	O
;	O
(	O
d	O
)	O
labelings	O
indicating	O
ground	O
(	O
green	O
)	O
,	O
vertical	O
(	O
red	O
)	O
,	O
and	O
sky	O
(	O
blue	O
)	O
;	O
(	O
e	O
)	O
novel	O
view	O
of	O
resulting	O
piecewise-planar	O
3d	O
model	O
.	O
ralba	O
2001	O
;	O
torralba	O
,	O
murphy	O
,	O
freeman	O
et	O
al	O
.	O
2003	O
)	O
to	O
ﬁnd	O
images	O
with	O
similar	O
colors	O
and	O
composition	O
.	O
they	O
then	O
run	O
a	O
graph	B
cut	I
algorithm	O
that	O
minimizes	O
image	B
gradient	O
differences	O
and	O
composite	O
the	O
new	O
replacement	O
piece	O
into	O
the	O
original	O
image	B
using	O
poisson	O
image	B
blend-	O
ing	O
(	O
section	O
9.3.4	O
)	O
(	O
p´erez	O
,	O
gangnet	O
,	O
and	O
blake	O
2003	O
)	O
.	O
figure	O
14.46d	O
shows	O
the	O
resulting	O
image	B
with	O
the	O
erased	O
foreground	O
rooftops	O
region	B
replaced	O
with	O
sailboats	O
.	O
a	O
different	O
application	O
of	O
image	B
recognition	O
and	O
segmentation	B
is	O
to	O
infer	O
3d	O
structure	O
from	O
a	O
single	O
photo	O
by	O
recognizing	O
certain	O
scene	O
structures	O
.	O
for	O
example	O
,	O
criminisi	O
,	O
reid	O
,	O
and	O
zisserman	O
(	O
2000	O
)	O
detect	O
vanishing	B
points	I
and	O
have	O
the	O
user	O
draw	O
basic	O
structures	O
,	O
such	O
as	O
walls	O
,	O
in	O
order	B
infer	O
the	O
3d	O
geometry	O
(	O
section	O
6.3.3	O
)	O
.	O
hoiem	O
,	O
efros	O
,	O
and	O
hebert	O
(	O
2005a	O
)	O
on	O
the	O
other	O
hand	O
,	O
work	O
with	O
more	O
“	O
organic	O
”	O
scenes	O
such	O
as	O
the	O
one	O
shown	O
in	O
figure	O
14.47.	O
their	O
system	O
uses	O
a	O
variety	O
of	O
classiﬁers	O
and	O
statistics	O
learned	B
from	O
labeled	O
images	O
to	O
classify	O
each	O
pixel	O
as	O
either	O
ground	O
,	O
vertical	O
,	O
or	O
sky	O
(	O
figure	O
14.47d	O
)	O
.	O
to	O
do	O
this	O
,	O
they	O
begin	O
by	O
com-	O
puting	O
superpixels	O
(	O
figure	O
14.47b	O
)	O
and	O
then	O
group	O
them	O
into	O
plausible	O
regions	O
that	O
are	O
likely	O
to	O
share	O
similar	O
geometric	B
labels	O
(	O
figure	O
14.47c	O
)	O
.	O
after	O
all	O
the	O
pixels	O
have	O
been	O
labeled	O
,	O
the	O
boundaries	O
between	O
the	O
vertical	O
and	O
ground	O
pixels	O
can	O
be	O
used	O
to	O
infer	O
3d	O
lines	B
along	O
which	O
the	O
image	B
can	O
be	O
folded	O
into	O
a	O
“	O
pop-up	O
”	O
(	O
after	O
removing	O
the	O
sky	O
pixels	O
)	O
,	O
as	O
shown	O
in	O
fig-	O
ure	O
14.47e	O
.	O
in	O
related	O
work	O
,	O
saxena	O
,	O
sun	O
,	O
and	O
ng	O
(	O
2009	O
)	O
develop	O
a	O
system	O
that	O
directly	O
infers	O
the	O
depth	O
and	O
orientation	O
of	O
each	O
pixel	O
instead	O
of	O
using	O
just	O
three	O
geometric	B
class	O
labels	O
.	O
face	B
detection	O
and	O
localization	O
can	O
also	O
be	O
used	O
in	O
a	O
variety	O
of	O
photo	O
editing	O
applications	O
(	O
in	O
addition	O
to	O
being	O
used	O
in-camera	O
to	O
provide	O
better	O
focus	B
,	O
exposure	O
,	O
and	O
ﬂash	B
settings	O
)	O
.	O
zanella	O
and	O
fuentes	O
(	O
2004	O
)	O
use	O
active	O
shape	O
models	O
(	O
section	O
14.2.2	O
)	O
to	O
register	O
facial	O
features	O
for	O
creating	O
automated	B
morphs	O
.	O
rother	O
,	O
bordeaux	O
,	O
hamadi	O
et	O
al	O
.	O
(	O
2006	O
)	O
use	O
face	B
and	O
sky	O
detection	B
to	O
determine	O
regions	O
of	O
interest	O
in	O
order	B
to	O
decide	O
which	O
pieces	O
from	O
a	O
collection	O
of	O
images	O
to	O
stitch	O
into	O
a	O
collage	O
.	O
bitouk	O
,	O
kumar	O
,	O
dhillon	O
et	O
al	O
.	O
(	O
2008	O
)	O
describe	O
a	O
system	O
that	O
matches	O
a	O
given	O
face	B
image	O
to	O
a	O
large	O
collection	O
of	O
internet	O
face	B
images	O
,	O
which	O
can	O
then	O
be	O
used	O
(	O
with	O
careful	O
relighting	O
algorithms	O
)	O
to	O
replace	O
the	O
face	B
in	O
the	O
original	O
image	B
.	O
applications	O
they	O
describe	O
include	O
de-identiﬁcation	O
and	O
getting	O
the	O
best	O
possible	O
smile	O
from	O
14.4	O
category	O
recognition	O
711	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
(	O
e	O
)	O
figure	O
14.48	O
the	O
importance	O
of	O
context	B
(	O
images	O
courtesy	O
of	O
antonio	O
torralba	O
)	O
.	O
can	O
you	O
name	O
all	O
of	O
the	O
objects	O
in	O
images	O
(	O
a–b	O
)	O
,	O
especially	O
those	O
that	O
are	O
circled	O
in	O
(	O
c–d	O
)	O
.	O
look	O
carefully	O
at	O
the	O
circled	O
objects	O
.	O
did	O
you	O
notice	O
that	O
they	O
all	O
have	O
the	O
same	O
shape	O
(	O
after	O
being	O
rotated	O
)	O
,	O
as	O
shown	O
in	O
column	O
(	O
e	O
)	O
?	O
everyone	O
in	O
a	O
“	O
burst	O
mode	O
”	O
group	O
shot	O
.	O
leyvand	O
,	O
cohen-or	O
,	O
dror	O
et	O
al	O
.	O
(	O
2008	O
)	O
show	O
how	O
accurately	O
locating	O
facial	O
features	O
using	O
an	O
active	O
shape	O
model	O
(	O
cootes	O
,	O
edwards	O
,	O
and	O
taylor	O
2001	O
;	O
zhou	O
,	O
gu	O
,	O
and	O
zhang	O
2003	O
)	O
can	O
be	O
used	O
to	O
warp	O
such	O
features	O
(	O
and	O
hence	O
the	O
image	B
)	O
towards	O
conﬁgurations	O
resembling	O
those	O
found	O
in	O
images	O
whose	O
facial	O
attractiveness	O
was	O
highly	O
rated	O
,	O
thereby	O
“	O
beautifying	O
”	O
the	O
image	B
without	O
completely	O
losing	O
a	O
person	O
’	O
s	O
identity	O
.	O
most	O
of	O
these	O
techniques	O
rely	O
either	O
on	O
a	O
set	O
of	O
labeled	O
training	O
images	O
,	O
which	O
is	O
an	O
essential	O
component	O
of	O
all	O
learning	B
techniques	O
,	O
or	O
the	O
even	O
more	O
recent	O
explosion	O
in	O
images	O
available	O
on	O
the	O
internet	O
.	O
the	O
assumption	O
in	O
some	O
of	O
this	O
work	O
(	O
and	O
in	O
recognition	B
systems	O
based	O
on	O
such	O
very	O
large	O
databases	O
(	O
section	O
14.5.1	O
)	O
)	O
is	O
that	O
as	O
the	O
collection	O
of	O
accessible	O
(	O
and	O
potentially	O
partially	O
labeled	O
)	O
images	O
gets	O
larger	O
,	O
ﬁnding	O
a	O
close	O
match	O
gets	O
easier	O
.	O
as	O
hays	O
and	O
efros	O
(	O
2007	O
)	O
state	O
in	O
their	O
abstract	O
“	O
our	O
chief	O
insight	O
is	O
that	O
while	O
the	O
space	O
of	O
images	O
is	O
effectively	O
inﬁnite	O
,	O
the	O
space	O
of	O
semantically	O
differentiable	O
scenes	O
is	O
actually	O
not	O
that	O
large.	O
”	O
in	O
an	O
interesting	O
commentary	O
on	O
their	O
paper	O
,	O
levoy	O
(	O
2008	O
)	O
disputes	O
this	O
assertion	O
,	O
claiming	O
that	O
“	O
features	O
in	O
natural	B
scenes	O
form	O
a	O
heavy-tailed	O
distribution	O
,	O
meaning	O
that	O
while	O
some	O
features	O
in	O
photographs	O
are	O
more	O
common	O
than	O
others	O
,	O
the	O
relative	O
occurrence	O
of	O
less	O
common	O
features	O
drops	O
slowly	O
.	O
in	O
other	O
words	O
,	O
there	O
are	O
many	O
unusual	O
photographs	O
in	O
the	O
world.	O
”	O
he	O
does	O
,	O
however	O
agree	O
that	O
in	O
computational	O
photography	O
,	O
as	O
in	O
many	O
other	O
applications	O
such	O
as	O
speech	O
recognition	B
,	O
synthesis	O
,	O
and	O
translation	B
,	O
“	O
simple	O
machine	O
learning	O
algorithms	O
often	O
outperform	O
more	O
sophisticated	O
ones	O
if	O
trained	O
on	O
large	O
enough	O
databases.	O
”	O
he	O
also	O
goes	O
on	O
to	O
point	O
out	O
both	O
the	O
potential	O
advantages	O
of	O
such	O
systems	O
,	O
such	O
as	O
better	O
automatic	B
color	O
balancing	O
,	O
and	O
potential	O
issues	O
and	O
pitfalls	O
with	O
the	O
kind	O
of	O
image	B
fakery	O
that	O
these	O
new	O
approaches	O
enable	O
.	O
for	O
additional	O
examples	B
of	O
photo	O
editing	O
and	O
computational	O
photography	O
applications	O
712	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
14.49	O
more	O
examples	B
of	O
context	B
:	O
read	O
the	O
letters	O
in	O
the	O
ﬁrst	O
group	O
,	O
the	O
numbers	O
in	O
the	O
second	O
,	O
and	O
the	O
letters	O
and	O
numbers	O
in	O
the	O
third	O
.	O
(	O
images	O
courtesy	O
of	O
antonio	O
torralba	O
.	O
)	O
enabled	O
by	O
internet	O
computer	O
vision	O
,	O
please	O
see	O
recent	O
workshops	O
on	O
this	O
topic,19	O
as	O
well	O
as	O
the	O
special	O
journal	O
issue	O
(	O
avidan	O
,	O
baker	O
,	O
and	O
shan	O
2010	O
)	O
,	O
and	O
the	O
course	O
on	O
internet	O
vision	O
by	O
tamara	O
berg	O
(	O
2008	O
)	O
.	O
14.5	O
context	B
and	O
scene	B
understanding	I
thus	O
far	O
,	O
we	O
have	O
mostly	O
considered	O
the	O
task	O
of	O
recognizing	O
and	O
localizing	O
objects	O
in	O
isolation	O
from	O
that	O
of	O
understanding	O
the	O
scene	O
(	O
context	B
)	O
in	O
which	O
the	O
object	O
occur	O
.	O
this	O
is	O
a	O
severe	O
limitation	O
,	O
as	O
context	B
plays	O
a	O
very	O
important	O
role	O
in	O
human	O
object	O
recognition	B
(	O
oliva	O
and	O
torralba	O
2007	O
)	O
.	O
as	O
we	O
will	O
see	O
in	O
this	O
section	O
,	O
it	O
can	O
greatly	O
improve	O
the	O
performance	O
of	O
object	O
recognition	B
algorithms	O
(	O
divvala	O
,	O
hoiem	O
,	O
hays	O
et	O
al	O
.	O
2009	O
)	O
,	O
as	O
well	O
as	O
providing	O
useful	O
semantic	O
clues	O
for	O
general	O
scene	B
understanding	I
(	O
torralba	O
2008	O
)	O
.	O
consider	O
the	O
two	O
photographs	O
in	O
figure	O
14.48a–b	O
.	O
can	O
you	O
name	O
all	O
of	O
the	O
objects	O
,	O
especially	O
those	O
circled	O
in	O
images	O
(	O
c–d	O
)	O
?	O
now	O
have	O
a	O
closer	O
look	O
at	O
the	O
circled	O
objects	O
.	O
do	O
see	O
any	O
similarity	B
in	O
their	O
shapes	O
?	O
in	O
fact	O
,	O
if	O
you	O
rotate	O
them	O
by	O
90◦	O
,	O
they	O
are	O
all	O
the	O
same	O
as	O
the	O
“	O
blob	O
”	O
shown	O
in	O
figure	O
14.48e	O
.	O
so	O
much	O
for	O
our	O
ability	O
to	O
recognize	O
object	O
by	O
their	O
shape	O
!	O
another	O
(	O
perhaps	O
more	O
artiﬁcial	O
)	O
example	O
of	O
recognition	B
in	O
context	B
is	O
shown	O
in	O
figure	O
14.49.	O
try	O
to	O
name	O
all	O
of	O
the	O
letters	O
and	O
numbers	O
,	O
and	O
then	O
see	O
if	O
you	O
guessed	O
right	O
.	O
even	O
though	O
we	O
have	O
not	O
addressed	O
context	B
explicitly	O
earlier	O
in	O
this	O
chapter	O
,	O
we	O
have	O
already	O
seen	O
several	O
instances	O
of	O
this	O
general	O
idea	O
being	O
used	O
.	O
a	O
simple	O
way	O
to	O
incorporate	O
spatial	O
information	O
into	O
a	O
recognition	B
algorithm	O
is	O
to	O
compute	O
feature	B
statistics	O
over	O
different	O
regions	O
,	O
as	O
in	O
the	O
spatial	O
pyramid	B
system	O
of	O
lazebnik	O
,	O
schmid	O
,	O
and	O
ponce	O
(	O
2006	O
)	O
.	O
part-based	B
models	O
(	O
section	O
14.4.2	O
,	O
figures	O
14.40–14.43	O
)	O
,	O
use	O
a	O
kind	O
of	O
local	B
context	O
,	O
where	O
various	O
parts	O
need	O
to	O
be	O
arranged	O
in	O
a	O
proper	O
geometric	B
relationship	O
to	O
constitute	O
an	O
object	O
.	O
the	O
biggest	O
difference	B
between	O
part-based	B
and	O
context	B
models	O
is	O
that	O
the	O
latter	O
combine	O
objects	O
into	O
scenes	O
and	O
the	O
number	O
of	O
constituent	O
objects	O
from	O
each	O
class	O
is	O
not	O
known	O
in	O
advance	O
.	O
in	O
fact	O
,	O
it	O
is	O
possible	O
to	O
combine	O
part-based	B
and	O
context	B
models	O
into	O
the	O
same	O
19	O
http	O
:	O
//www.internetvisioner.org/	O
.	O
14.5	O
context	B
and	O
scene	B
understanding	I
713	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
14.50	O
contextual	O
scene	O
models	O
for	O
object	O
recognition	B
(	O
sudderth	O
,	O
torralba	O
,	O
freeman	O
et	O
al	O
.	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
springer	O
:	O
(	O
a	O
)	O
some	O
street	O
scenes	O
and	O
their	O
corresponding	O
labels	O
(	O
magenta	O
=	O
buildings	O
,	O
red	O
=	O
cars	O
,	O
green	O
=	O
trees	O
,	O
blue	O
=	O
road	O
)	O
;	O
(	O
b	O
)	O
some	O
ofﬁce	O
scenes	O
(	O
red	O
=	O
computer	O
screen	O
,	O
green	O
=	O
keyboard	O
,	O
blue	O
=	O
mouse	O
)	O
;	O
(	O
c	O
)	O
learned	B
contextual	O
models	O
built	O
from	O
these	O
labeled	O
scenes	O
.	O
the	O
top	O
row	O
shows	O
a	O
sample	O
label	O
image	B
and	O
the	O
distribution	O
of	O
the	O
objects	O
relative	O
to	O
the	O
center	O
red	O
(	O
car	B
or	O
screen	O
)	O
object	O
.	O
the	O
bottom	O
rows	O
show	O
the	O
distributions	O
of	O
parts	O
that	O
make	O
up	O
each	O
object	O
.	O
recognition	B
architecture	O
(	O
murphy	O
,	O
torralba	O
,	O
and	O
freeman	O
2003	O
;	O
sudderth	O
,	O
torralba	O
,	O
freeman	O
et	O
al	O
.	O
2008	O
;	O
crandall	O
and	O
huttenlocher	O
2007	O
)	O
.	O
consider	O
the	O
street	O
and	O
ofﬁce	O
scenes	O
shown	O
in	O
figure	O
14.50a–b	O
.	O
if	O
we	O
have	O
enough	O
train-	O
ing	O
images	O
with	O
labeled	O
regions	O
,	O
such	O
as	O
buildings	O
,	O
cars	O
,	O
and	O
roads	O
or	O
monitors	O
,	O
keyboards	O
,	O
and	O
mice	O
,	O
we	O
can	O
develop	O
a	O
geometric	B
model	O
for	O
describing	O
their	O
relative	O
positions	O
.	O
sud-	O
derth	O
,	O
torralba	O
,	O
freeman	O
et	O
al	O
.	O
(	O
2008	O
)	O
develop	O
such	O
a	O
model	O
,	O
which	O
can	O
be	O
thought	O
of	O
as	O
a	O
two-level	O
constellation	B
model	I
.	O
at	O
the	O
top	O
level	O
,	O
the	O
distributions	O
of	O
objects	O
relative	O
to	O
each	O
other	O
(	O
say	O
,	O
buildings	O
with	O
respect	O
to	O
cars	O
)	O
is	O
modeled	O
as	O
a	O
gaussian	O
(	O
figure	O
14.50c	O
,	O
upper	O
right	O
corners	O
)	O
.	O
at	O
the	O
bottom	O
level	O
,	O
the	O
distribution	O
of	O
parts	O
(	O
afﬁne	B
covariant	O
features	O
)	O
with	O
respect	O
to	O
the	O
object	O
center	O
is	O
modeled	O
using	O
a	O
mixture	O
of	O
gaussians	O
(	O
figure	O
14.50c	O
,	O
lower	O
two	O
rows	O
)	O
.	O
however	O
,	O
since	O
the	O
number	O
of	O
objects	O
in	O
the	O
scene	O
and	O
parts	O
in	O
each	O
object	O
is	O
unknown	O
,	O
a	O
latent	O
dirichlet	O
process	O
(	O
ldp	O
)	O
is	O
used	O
to	O
model	O
object	O
and	O
part	O
creation	O
in	O
a	O
gen-	O
erative	O
framework	O
.	O
the	O
distributions	O
for	O
all	O
of	O
the	O
objects	O
and	O
parts	O
are	O
learned	B
from	O
a	O
large	O
labeled	O
database	O
and	O
then	O
later	O
used	O
during	O
inference	B
(	O
recognition	B
)	O
to	O
label	O
the	O
elements	O
of	O
a	O
scene	O
.	O
another	O
example	O
of	O
context	B
is	O
in	O
simultaneous	O
segmentation	B
and	O
recognition	B
(	O
section	O
14.4.3	O
)	O
intjcomputvis	O
(	O
2008	O
)	O
77:291–330315ineachimageandjointlyresamplethepartandinstance	O
(	O
kji	O
,	O
tji	O
)	O
assignedtoeachfeature.theresultingupdatescombineaspectsofourearliertdp	O
(	O
algorithm4	O
,	O
steps1–2	O
)	O
andﬁxed-orderscene	O
(	O
algorithm3	O
,	O
step1	O
)	O
gibbssamplers.inthesecondstage	O
,	O
weﬁxassignmentstjoffeaturestoobjectinstances	O
,	O
effectivelysegmentingimagesintoinde-pendentobjects.wemaythenjointlyresamplethelocationρjt	O
,	O
visualcategoryojt	O
,	O
andpartassignments	O
{	O
kji|tji=t	O
}	O
associatedwitheachtablebyadaptingthesingle-objecthdpsamplerofalgorithms1–2.notethatthissecondstageapproximatestheinﬁnitesetofpotentialpartsforcat-egory	O
(	O
cid:10	O
)	O
(	O
see	O
(	O
28	O
)	O
)	O
bythek	O
(	O
cid:10	O
)	O
partstowhichatleastonefeatureiscurrentlyassigned.thiscanbeseenasadynamicversionofthestick-breakingtruncationsunderlyingcertainotherdpsamplingalgorithms	O
(	O
ishwaranandjames2001	O
;	O
rodriguezetal.2006	O
)	O
.9streetandofﬁcescenestoevaluateourhierarchicalmodelsformultipleobjectscenes	O
,	O
weusethetwodatasetsdepictedinfig.4.theﬁrstsetcontains613streetscenesdepictingfour	O
“	O
objects	O
”	O
:	O
buildings	O
,	O
cars	O
(	O
sideviews	O
)	O
,	O
roads	O
,	O
andtrees.toalignwiththeassumptionsunderlyingour2dscenemodels	O
,	O
imageswerenormalizedsothatcarsappearatcomparablescales.asshowninfig.4	O
,	O
someofthesestreetsceneshavelabelsforallfourcategories	O
,	O
whileothersareonlypartiallyseg-mented.theseconddatasetincludes315picturesofofﬁcescenescontainingfourobjects	O
:	O
computerscreens	O
(	O
frontalviews	O
)	O
,	O
keyboards	O
,	O
mice	O
,	O
andbackgroundclutter.inthiscase	O
,	O
imageswerenormalizedsothatcomputerscreensap-pearedatcomparablescales	O
,	O
andallobjectinstanceswerelabeled.forbothdatasets	O
,	O
werepresenttrainingandtestimagesbythethreetypesofinterestregionsdescribedinsect.2.1.weestimatedaseparateappearancedictionaryforeachdataset	O
,	O
whichafterexpansiontoencoderegionshape	O
(	O
seesect.2.2	O
)	O
containedw=1600visualwords.9.1fixed-orderscenemodelswebeginbyexaminingtheﬁxed-ordervisualscenemodeloffig.12	O
,	O
andlearnparametersviathegibbssamplerofalgorithm3.fortraining	O
,	O
weused400streetscenesand250ofﬁcescenes	O
;	O
theremainingimagesthenprovideaseg-mentedtestset.toestimatemodelparameters	O
,	O
weﬁrstranthegibbssamplerfor500iterationsusingonlythetrainingimages.weincorporatemanualsegmentationsbyﬁxingtheobjectcategoryassignmentsojioflabeledfeatures.forun-labeledfeatures	O
,	O
objectassignmentsareleftunconstrained	O
,	O
andsampledasinalgorithm3.eachscenemodelusedthirtysharedparts	O
,	O
anddirichletprecisionparameterssetasγ=4	O
,	O
α=15viacross-validation.thepositionpriorhvweaklyfavoredpartscovering10	O
%	O
oftheimagerange	O
,	O
whiletheappearancepriordir	O
(	O
w/10	O
)	O
wasbiasedtowardssparsedistributions.9.1.1visualizationoflearnedpartsfigure16illustrateslearned	O
,	O
part-basedmodelsforstreetandofﬁcescenes.althoughobjectsshareacommonsetofpartswithineachscenemodel	O
,	O
wecanapproximatelycountthenumberofpartsusedbyeachobjectbythresh-oldingtheposteriorpartdistributionsπ	O
(	O
cid:10	O
)	O
.forstreetscenes	O
,	O
carsareallocatedroughlyfourparts	O
,	O
whilebuildingsandroadsuselargenumbersofpartstouniformlytileregionscorrespondingtotheirtypicalsize.severalpartsaresharedfigure16learnedcontextual	O
,	O
ﬁxed-ordermodelsforstreetscenes	O
(	O
left	O
)	O
andofﬁcescenes	O
(	O
right	O
)	O
,	O
eachcontainingfourobjects.top	O
:	O
gaussiandistributionsoverthepositionsofotherobjectsgiventhelocationofthecar	O
(	O
left	O
)	O
orcomputerscreen	O
(	O
right	O
)	O
.bottom	O
:	O
parts	O
(	O
solid	O
)	O
generatingatleast5	O
%	O
ofeachcategory	O
’	O
sfeatures	O
,	O
withintensityproportionaltoprobability.partsaretranslatedbythatobject	O
’	O
smeanposition	O
,	O
whilethedashedellipsesindicateeachobject	O
’	O
smarginaltransformationcovariance	O
714	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
figures	O
14.44–14.45	O
)	O
,	O
where	O
the	O
arrangements	O
of	O
various	O
objects	O
in	O
a	O
scene	O
are	O
used	O
as	O
part	O
of	O
the	O
labeling	O
process	O
.	O
torralba	O
,	O
murphy	O
,	O
and	O
freeman	O
(	O
2004	O
)	O
describe	O
a	O
conditional	O
random	O
ﬁeld	O
where	O
the	O
estimated	O
locations	O
of	O
building	O
and	O
roads	O
inﬂuence	O
the	O
detection	B
of	O
cars	O
,	O
and	O
where	O
boosting	B
is	O
used	O
to	O
learn	O
the	O
structure	O
of	O
the	O
crf	O
.	O
rabinovich	O
,	O
vedaldi	O
,	O
galleguillos	O
et	O
al	O
.	O
(	O
2007	O
)	O
use	O
context	B
to	O
improve	O
the	O
results	O
of	O
crf	O
segmentation	B
by	O
noting	O
that	O
certain	O
adjacencies	O
(	O
relationships	O
)	O
are	O
more	O
likely	O
than	O
others	O
,	O
e.g.	O
,	O
a	O
person	O
is	O
more	O
likely	O
to	O
be	O
on	O
a	O
horse	O
than	O
on	O
a	O
dog	O
.	O
context	B
also	O
plays	O
an	O
important	O
role	O
in	O
3d	O
inference	B
from	O
single	O
images	O
(	O
figure	O
14.47	O
)	O
,	O
using	O
computer	O
vision	O
techniques	O
for	O
labeling	O
pixels	O
as	O
belonging	O
to	O
the	O
ground	O
,	O
vertical	O
surfaces	O
,	O
or	O
sky	O
(	O
hoiem	O
,	O
efros	O
,	O
and	O
hebert	O
2005a	O
,	O
b	O
)	O
.	O
this	O
line	O
of	O
work	O
has	O
been	O
extended	O
to	O
a	O
more	O
holistic	O
approach	O
that	O
simultaneously	O
reasons	O
about	O
object	O
identity	O
,	O
location	O
,	O
surface	B
orientations	O
,	O
occlusions	O
,	O
and	O
camera	B
viewing	O
parameters	B
(	O
hoiem	O
,	O
efros	O
,	O
and	O
hebert	O
2008a	O
,	O
b	O
)	O
.	O
a	O
number	O
of	O
approaches	O
use	O
the	O
gist	B
of	O
a	O
scene	O
(	O
torralba	O
2003	O
;	O
torralba	O
,	O
murphy	O
,	O
free-	O
man	O
et	O
al	O
.	O
2003	O
)	O
to	O
determine	O
where	O
instances	O
of	O
particular	O
objects	O
are	O
likely	O
to	O
occur	O
.	O
for	O
example	O
,	O
murphy	O
,	O
torralba	O
,	O
and	O
freeman	O
(	O
2003	O
)	O
train	O
a	O
regressor	O
to	O
predict	O
the	O
vertical	O
loca-	O
tions	O
of	O
objects	O
such	O
as	O
pedestrians	O
,	O
cars	O
,	O
and	O
buildings	O
(	O
or	O
screens	O
and	O
keyboard	O
for	O
indoor	O
ofﬁce	O
scenes	O
)	O
based	O
on	O
the	O
gist	B
of	O
an	O
image	B
.	O
these	O
location	O
distributions	O
are	O
then	O
used	O
with	O
classic	O
object	O
detectors	O
to	O
improve	O
the	O
performance	O
of	O
the	O
detectors	O
.	O
gists	O
can	O
also	O
be	O
used	O
to	O
directly	O
match	O
complete	O
images	O
,	O
as	O
we	O
saw	O
in	O
the	O
scene	B
completion	I
work	O
of	O
hays	O
and	O
efros	O
(	O
2007	O
)	O
.	O
finally	O
,	O
some	O
of	O
the	O
most	O
recent	O
work	O
in	O
scene	B
understanding	I
exploits	O
the	O
existence	O
of	O
large	O
numbers	O
of	O
labeled	O
(	O
or	O
even	O
unlabeled	O
)	O
images	O
to	O
perform	O
matching	B
directly	O
against	O
whole	O
images	O
,	O
where	O
the	O
images	O
themselves	O
implicitly	O
encode	O
the	O
expected	O
relationships	O
between	O
objects	O
(	O
figure	O
14.51	O
)	O
(	O
russell	O
,	O
torralba	O
,	O
liu	O
et	O
al	O
.	O
2007	O
;	O
malisiewicz	O
and	O
efros	O
2008	O
)	O
.	O
we	O
discuss	O
such	O
techniques	O
in	O
the	O
next	O
section	O
,	O
where	O
we	O
look	O
at	O
the	O
inﬂuence	O
that	O
large	O
image	O
databases	O
have	O
had	O
on	O
object	O
recognition	B
and	O
scene	B
understanding	I
.	O
14.5.1	O
learning	B
and	O
large	O
image	O
collections	O
given	O
how	O
learning	B
techniques	O
are	O
widely	O
used	O
in	O
recognition	B
algorithms	O
,	O
you	O
may	O
wonder	O
whether	O
the	O
topic	O
of	O
learning	B
deserves	O
its	O
own	O
section	O
(	O
or	O
even	O
chapter	O
)	O
,	O
or	O
whether	O
it	O
is	O
just	O
part	O
of	O
the	O
basic	O
fabric	O
of	O
all	O
recognition	B
tasks	O
.	O
in	O
fact	O
,	O
trying	O
to	O
build	O
a	O
recognition	B
system	O
without	O
lots	O
of	O
training	O
data	O
for	O
anything	O
other	O
than	O
a	O
basic	O
pattern	O
such	O
as	O
a	O
upc	O
code	O
has	O
proven	O
to	O
be	O
a	O
dismal	O
failure	O
.	O
in	O
this	O
chapter	O
,	O
we	O
have	O
already	O
seen	O
lots	O
of	O
techniques	O
borrowed	O
from	O
the	O
machine	O
learn-	O
ing	O
,	O
statistics	O
,	O
and	O
pattern	O
recognition	B
communities	O
.	O
these	O
include	O
principal	O
component	O
,	O
sub-	O
space	O
,	O
and	O
discriminant	O
analysis	O
(	O
section	O
14.2.1	O
)	O
and	O
more	O
sophisticated	O
discriminative	O
clas-	O
siﬁcation	O
algorithms	O
such	O
as	O
neural	B
networks	I
,	O
support	B
vector	I
machines	I
,	O
and	O
boosting	B
(	O
sec-	O
14.5	O
context	B
and	O
scene	B
understanding	I
715	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
figure	O
14.51	O
recognition	B
by	O
scene	B
alignment	I
(	O
russell	O
,	O
torralba	O
,	O
liu	O
et	O
al	O
.	O
2007	O
)	O
:	O
(	O
a	O
)	O
input	O
image	B
;	O
(	O
b	O
)	O
matched	O
images	O
with	O
similar	O
scene	O
conﬁgurations	O
;	O
(	O
c	O
)	O
ﬁnal	O
labeling	O
of	O
the	O
input	O
image	B
.	O
tion	B
14.1.1	O
)	O
.	O
some	O
of	O
the	O
best-performing	O
techniques	O
on	O
challenging	O
recognition	B
benchmarks	O
(	O
varma	O
and	O
ray	O
2007	O
;	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
2008	O
;	O
fritz	O
and	O
schiele	O
2008	O
;	O
vedaldi	O
,	O
gulshan	O
,	O
varma	O
et	O
al	O
.	O
2009	O
)	O
rely	O
heavily	O
on	O
the	O
latest	O
machine	O
learning	O
techniques	O
,	O
whose	O
development	O
is	O
often	O
being	O
driven	O
by	O
challenging	O
vision	O
problems	O
(	O
freeman	O
,	O
perona	O
,	O
and	O
sch¨olkopf	O
2008	O
)	O
.	O
a	O
distinction	O
sometimes	O
made	O
in	O
the	O
recognition	B
community	O
is	O
between	O
problems	O
where	O
most	O
of	O
the	O
variables	O
of	O
interest	O
(	O
say	O
,	O
parts	O
)	O
are	O
already	O
(	O
partially	O
)	O
labeled	O
and	O
systems	O
that	O
learn	O
more	O
of	O
the	O
problem	O
structure	O
with	O
less	O
supervision	O
(	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
2007	O
;	O
fei-fei	O
,	O
fergus	O
,	O
and	O
perona	O
2006	O
)	O
.	O
in	O
fact	O
,	O
recent	O
work	O
by	O
sivic	O
,	O
russell	O
,	O
zisserman	O
et	O
al	O
.	O
(	O
2008	O
)	O
has	O
demonstrated	O
the	O
ability	O
to	O
learn	O
visual	O
hierarchies	O
(	O
hierarchies	O
of	O
object	O
parts	O
with	O
related	O
visual	O
appearance	O
)	O
and	O
scene	O
segmentations	O
in	O
a	O
totally	O
unsupervised	O
framework	O
.	O
perhaps	O
the	O
most	O
dramatic	O
change	O
in	O
the	O
recognition	B
community	O
has	O
been	O
the	O
appearance	O
of	O
very	O
large	O
databases	O
of	O
training	O
images.20	O
early	O
learning-based	O
algorithms	O
,	O
such	O
as	O
those	O
for	O
face	O
and	O
pedestrian	B
detection	O
(	O
section	O
14.1	O
)	O
,	O
used	O
relatively	O
few	O
(	O
in	O
the	O
hundreds	O
)	O
labeled	O
examples	B
to	O
train	O
recognition	B
algorithm	O
parameters	B
(	O
say	O
,	O
the	O
thresholds	O
used	O
in	O
boosting	B
)	O
.	O
to-	O
day	O
,	O
some	O
recognition	B
algorithms	O
use	O
databases	O
such	O
as	O
labelme	O
(	O
russell	O
,	O
torralba	O
,	O
murphy	O
et	O
al	O
.	O
2008	O
)	O
,	O
which	O
contain	O
tens	O
of	O
thousands	O
of	O
labeled	O
examples	B
.	O
the	O
existence	O
of	O
such	O
large	O
databases	O
opens	O
up	O
the	O
possibility	O
of	O
matching	B
directly	O
against	O
the	O
training	O
images	O
rather	O
than	O
using	O
them	O
to	O
learn	O
the	O
parameters	B
of	O
recognition	B
algorithms	O
.	O
russell	O
,	O
torralba	O
,	O
liu	O
et	O
al	O
.	O
(	O
2007	O
)	O
describe	O
a	O
system	O
where	O
a	O
new	O
image	B
is	O
matched	O
against	O
each	O
of	O
the	O
training	O
images	O
,	O
from	O
which	O
a	O
consensus	O
labeling	O
for	O
the	O
unknown	O
objects	O
in	O
the	O
scene	O
can	O
be	O
inferred	O
,	O
as	O
shown	O
in	O
figure	O
14.51.	O
malisiewicz	O
and	O
efros	O
(	O
2008	O
)	O
start	O
by	O
over-segmenting	O
each	O
image	B
and	O
then	O
use	O
the	O
labelme	O
database	O
to	O
search	O
for	O
similar	O
images	O
and	O
conﬁgurations	O
in	O
order	B
to	O
obtain	O
per-pixel	O
category	O
labelings	O
.	O
it	O
is	O
also	O
possible	O
to	O
combine	O
feature-based	B
correspondence	O
algorithms	O
with	O
large	O
labeled	O
databases	O
to	O
perform	O
20	O
we	O
have	O
already	O
seen	O
some	O
computational	O
photography	O
applications	O
of	O
such	O
databases	O
in	O
section	O
14.4.4	O
.	O
716	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
figure	O
14.52	O
recognition	B
using	O
tiny	O
images	O
(	O
torralba	O
,	O
freeman	O
,	O
and	O
fergus	O
2008	O
)	O
c	O
(	O
cid:13	O
)	O
2008	O
ieee	O
:	O
columns	O
(	O
a	O
)	O
and	O
(	O
c	O
)	O
show	O
sample	O
input	O
images	O
and	O
columns	O
(	O
b	O
)	O
and	O
(	O
d	O
)	O
show	O
the	O
corresponding	O
16	O
nearest	O
neighbors	O
in	O
the	O
database	O
of	O
80	O
million	O
tiny	O
images	O
.	O
simultaneous	O
recognition	B
and	O
segmentation	B
(	O
liu	O
,	O
yuen	O
,	O
and	O
torralba	O
2009	O
)	O
.	O
when	O
the	O
database	O
of	O
images	O
becomes	O
large	O
enough	O
,	O
it	O
is	O
even	O
possible	O
to	O
directly	O
match	O
complete	O
images	O
with	O
the	O
expectation	O
of	O
ﬁnding	O
a	O
good	O
match	O
.	O
torralba	O
,	O
freeman	O
,	O
and	O
fergus	O
(	O
2008	O
)	O
start	O
with	O
a	O
database	O
of	O
80	O
million	O
tiny	O
(	O
32	O
×	O
32	O
)	O
images	O
and	O
compensate	O
for	O
the	O
poor	O
accuracy	B
in	O
their	O
image	B
labels	O
,	O
which	O
are	O
collected	O
automatically	O
from	O
the	O
internet	O
,	O
by	O
using	O
a	O
semantic	O
taxonomy	B
(	O
wordnet	O
)	O
to	O
infer	O
the	O
most	O
likely	O
labels	O
for	O
a	O
new	O
image	B
.	O
somewhere	O
in	O
the	O
80	O
million	O
images	O
,	O
there	O
are	O
enough	O
examples	B
to	O
associate	O
some	O
set	O
of	O
images	O
with	O
each	O
of	O
the	O
75,000	O
non-abstract	O
nouns	O
in	O
wordnet	O
that	O
they	O
use	O
in	O
their	O
system	O
.	O
some	O
sample	O
recognition	B
results	O
are	O
shown	O
in	O
figure	O
14.52.	O
another	O
example	O
of	O
a	O
large	O
labeled	O
database	O
of	O
images	O
is	O
imagenet	O
(	O
deng	O
,	O
dong	O
,	O
socher	O
et	O
al	O
.	O
2009	O
)	O
,	O
which	O
is	O
collecting	O
images	O
for	O
the	O
80,000	O
nouns	O
(	O
synonym	O
sets	O
)	O
in	O
wordnet	O
(	O
fellbaum	O
1998	O
)	O
.	O
as	O
of	O
april	O
2010	O
,	O
about	O
500–1000	O
carefully	O
vetted	O
examples	B
for	O
14841	O
14.5	O
context	B
and	O
scene	B
understanding	I
717	O
figure	O
14.53	O
imagenet	O
(	O
deng	O
,	O
dong	O
,	O
socher	O
et	O
al	O
.	O
2009	O
)	O
c	O
(	O
cid:13	O
)	O
2009	O
ieee	O
.	O
this	O
database	O
contains	O
over	O
500	O
carefully	O
vetted	O
images	O
for	O
each	O
of	O
14,841	O
(	O
as	O
of	O
april	O
,	O
2010	O
)	O
nouns	O
from	O
the	O
wordnet	O
hierarchy	B
.	O
synsets	O
have	O
been	O
collected	O
(	O
figure	O
14.53	O
)	O
.	O
the	O
paper	O
by	O
deng	O
,	O
dong	O
,	O
socher	O
et	O
al	O
.	O
(	O
2009	O
)	O
also	O
has	O
a	O
nice	O
review	O
of	O
related	O
databases	O
.	O
as	O
we	O
mentioned	O
in	O
section	O
14.4.3	O
,	O
the	O
existence	O
of	O
large	O
databases	O
of	O
partially	O
labeled	O
internet	O
imagery	O
has	O
given	O
rise	O
to	O
a	O
new	O
sub-ﬁeld	O
of	O
internet	O
computer	O
vision	O
,	O
with	O
its	O
own	O
workshops21	O
and	O
a	O
special	O
journal	O
issue	O
(	O
avidan	O
,	O
baker	O
,	O
and	O
shan	O
2010	O
)	O
.	O
14.5.2	O
application	O
:	O
image	B
search	I
even	O
though	O
visual	O
recognition	O
algorithms	O
are	O
by	O
some	O
measures	O
still	O
in	O
their	O
infancy	O
,	O
they	O
are	O
already	O
starting	O
to	O
have	O
some	O
impact	O
on	O
image	B
search	I
,	O
i.e.	O
,	O
the	O
retrieval	O
of	O
images	O
from	O
the	O
web	O
using	O
combinations	O
of	O
keywords	O
and	O
visual	O
similarity	O
.	O
today	O
,	O
most	O
image	B
search	I
engines	O
rely	O
mostly	O
on	O
textual	O
keywords	O
found	O
in	O
captions	O
,	O
nearby	O
text	O
,	O
and	O
ﬁlenames	O
,	O
augmented	O
by	O
user	O
click-through	O
data	O
(	O
craswell	O
and	O
szummer	O
2007	O
)	O
.	O
as	O
recognition	B
algorithms	O
continue	O
to	O
improve	O
,	O
however	O
,	O
visual	O
features	O
and	O
visual	O
similarity	O
will	O
start	O
being	O
used	O
to	O
recognize	O
images	O
with	O
missing	O
or	O
erroneous	O
keywords	O
.	O
the	O
topic	O
of	O
searching	O
by	O
visual	O
similarity	B
has	O
a	O
long	O
history	O
and	O
goes	O
by	O
a	O
variety	O
of	O
names	O
,	O
including	O
content-based	O
image	B
retrieval	O
(	O
cbir	O
)	O
(	O
smeulders	O
,	O
worring	O
,	O
santini	O
et	O
al	O
.	O
2000	O
;	O
lew	O
,	O
sebe	O
,	O
djeraba	O
et	O
al	O
.	O
2006	O
;	O
vasconcelos	O
2007	O
;	O
datta	O
,	O
joshi	O
,	O
li	O
et	O
al	O
.	O
2008	O
)	O
and	O
query	O
by	O
image	B
content	O
(	O
qbic	O
)	O
(	O
flickner	O
,	O
sawhney	O
,	O
niblack	O
et	O
al	O
.	O
1995	O
)	O
.	O
original	O
publica-	O
tions	O
in	O
these	O
ﬁelds	O
were	O
based	O
primarily	O
on	O
simple	O
whole-image	O
similarity	B
metrics	O
,	O
such	O
as	O
color	B
and	O
texture	B
(	O
swain	O
and	O
ballard	O
1991	O
;	O
jacobs	O
,	O
finkelstein	O
,	O
and	O
salesin	O
1995	O
;	O
manjunathi	O
and	O
ma	O
1996	O
)	O
.	O
21	O
http	O
:	O
//www.internetvisioner.org/	O
.	O
718	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
in	O
more	O
recent	O
work	O
,	O
fergus	O
,	O
perona	O
,	O
and	O
zisserman	O
(	O
2004	O
)	O
use	O
a	O
feature-based	B
learning	O
and	O
recognition	B
algorithm	O
to	O
re-rank	O
the	O
outputs	O
from	O
a	O
traditional	O
keyword-based	O
image	B
search	I
engine	O
.	O
in	O
follow-on	O
work	O
,	O
fergus	O
,	O
fei-fei	O
,	O
perona	O
et	O
al	O
.	O
(	O
2005	O
)	O
cluster	O
the	O
results	O
returned	O
by	O
image	O
search	O
using	O
an	O
extension	O
of	O
probabilistic	B
latest	O
semantic	O
analysis	O
(	O
plsa	O
)	O
(	O
hofmann	O
1999	O
)	O
and	O
then	O
select	O
the	O
clusters	O
associated	O
with	O
the	O
highest	O
ranked	O
results	O
as	O
the	O
representative	O
images	O
for	O
that	O
category	O
.	O
even	O
more	O
recent	O
work	O
relies	O
on	O
carefully	O
annotated	O
image	B
databases	O
such	O
as	O
labelme	O
(	O
russell	O
,	O
torralba	O
,	O
murphy	O
et	O
al	O
.	O
2008	O
)	O
.	O
for	O
example	O
,	O
malisiewicz	O
and	O
efros	O
(	O
2008	O
)	O
describe	O
a	O
system	O
that	O
,	O
given	O
a	O
query	O
image	O
,	O
can	O
ﬁnd	O
similar	O
labelme	O
images	O
,	O
whereas	O
liu	O
,	O
yuen	O
,	O
and	O
torralba	O
(	O
2009	O
)	O
combine	O
feature-based	B
correspondence	O
algorithms	O
with	O
the	O
labeled	O
database	O
to	O
perform	O
simultaneous	O
recognition	B
and	O
segmentation	B
.	O
14.6	O
recognition	B
databases	O
and	O
test	O
sets	O
in	O
addition	O
to	O
rapid	O
advances	O
in	O
machine	O
learning	O
and	O
statistical	O
modeling	B
techniques	O
,	O
one	O
of	O
the	O
key	O
ingredients	O
in	O
the	O
continued	O
improvement	O
of	O
recognition	B
algorithms	O
has	O
been	O
the	O
increased	O
availability	O
and	O
quality	O
of	O
image	B
recognition	O
databases	O
.	O
tables	O
14.1	O
and	O
14.2	O
,	O
which	O
are	O
based	O
on	O
similar	O
tables	O
in	O
fei-fei	O
,	O
fergus	O
,	O
and	O
torralba	O
(	O
2009	O
)	O
,	O
updated	O
with	O
more	O
recent	O
entries	O
and	O
urls	O
,	O
show	O
some	O
of	O
the	O
mostly	O
widely	O
used	O
recognition	B
databases	O
.	O
some	O
of	O
these	O
databases	O
,	O
such	O
as	O
the	O
ones	O
for	O
face	O
recognition	B
and	O
localization	O
,	O
date	O
back	O
over	O
a	O
decade	O
.	O
the	O
most	O
recent	O
ones	O
,	O
such	O
as	O
the	O
pascal	O
database	O
,	O
are	O
refreshed	O
annually	O
with	O
ever	O
more	O
challenging	O
problems	O
.	O
table	O
14.1	O
shows	O
examples	B
of	O
databases	O
used	O
primarily	O
for	O
(	O
whole	O
image	B
)	O
recognition	B
while	O
table	O
14.2	O
shows	O
databases	O
where	O
more	O
accurate	O
localization	O
or	O
segmentation	B
information	O
is	O
available	O
and	O
expected	O
.	O
ponce	O
,	O
berg	O
,	O
everingham	O
et	O
al	O
.	O
(	O
2006	O
)	O
discuss	O
some	O
of	O
the	O
problems	O
with	O
earlier	O
datasets	O
and	O
describe	O
how	O
the	O
latest	O
pascal	O
visual	O
object	O
classes	O
challenge	O
aims	O
to	O
overcome	O
these	O
.	O
some	O
examples	B
of	O
the	O
20	O
visual	O
classes	O
in	O
the	O
2008	O
challenge	O
are	O
shown	O
in	O
fig-	O
ure	O
14.54.	O
the	O
slides	O
from	O
the	O
voc	O
workshops,22	O
are	O
a	O
great	O
source	O
for	O
pointers	O
to	O
the	O
best	O
recognition	B
techniques	O
currently	O
available	O
.	O
two	O
of	O
the	O
most	O
recent	O
trends	O
in	O
recognition	B
databases	O
are	O
the	O
emergence	O
of	O
web-based	O
annotation	O
and	O
data	O
collection	O
tools	O
,	O
and	O
the	O
use	O
of	O
search	O
and	O
recognition	B
algorithms	O
to	O
build	O
up	O
databases	O
(	O
ponce	O
,	O
berg	O
,	O
everingham	O
et	O
al	O
.	O
2006	O
)	O
.	O
some	O
of	O
the	O
most	O
interesting	O
work	O
in	O
human	O
annotation	O
of	O
images	O
comes	O
from	O
a	O
series	O
of	O
interactive	B
multi-person	O
games	O
such	O
as	O
esp	O
(	O
von	O
ahn	O
and	O
dabbish	O
2004	O
)	O
and	O
peekaboom	O
(	O
von	O
ahn	O
,	O
liu	O
,	O
and	O
blum	O
2006	O
)	O
.	O
in	O
these	O
games	O
,	O
people	O
help	O
each	O
other	O
guess	O
the	O
identity	O
of	O
a	O
hidden	O
image	B
by	O
giving	O
textual	O
clues	O
as	O
to	O
its	O
contents	O
,	O
which	O
implicitly	O
labels	O
either	O
the	O
whole	O
image	B
or	O
just	O
regions	O
.	O
a	O
more	O
22	O
http	O
:	O
//pascallin.ecs.soton.ac.uk/challenges/voc/	O
.	O
14.6	O
recognition	B
databases	O
and	O
test	O
sets	O
719	O
name	O
/	O
url	O
extents	O
contents	O
/	O
reference	O
face	B
and	O
person	O
recognition	B
yale	O
face	B
database	O
centered	O
face	B
images	O
frontal	O
faces	B
http	O
:	O
//www1.cs.columbia.edu/∼belhumeur/	O
resources	O
for	O
face	O
detection	B
various	O
databases	O
http	O
:	O
//vision.ai.uiuc.edu/mhyang/face-detection-survey.html	O
centered	O
face	B
images	O
feret	O
belhumeur	O
,	O
hespanha	O
,	O
and	O
kriegman	O
(	O
1997	O
)	O
faces	B
in	O
various	O
poses	O
yang	O
,	O
kriegman	O
,	O
and	O
ahuja	O
(	O
2002	O
)	O
frontal	O
faces	B
phillips	O
,	O
moon	O
,	O
rizvi	O
et	O
al	O
.	O
(	O
2000	O
)	O
http	O
:	O
//www.frvt.org/feret	O
frvt	O
http	O
:	O
//www.frvt.org/	O
cmu	O
pie	O
database	O
centered	O
face	B
images	O
faces	B
in	O
various	O
poses	O
centered	O
face	B
image	O
faces	B
in	O
various	O
poses	O
phillips	O
,	O
scruggs	O
,	O
o	O
’	O
toole	O
et	O
al	O
.	O
(	O
2010	O
)	O
http	O
:	O
//www.ri.cmu.edu/projects/project	O
418.html	O
sim	O
,	O
baker	O
,	O
and	O
bsat	O
(	O
2003	O
)	O
cmu	O
multi-pie	O
database	O
centered	O
face	B
image	O
faces	B
in	O
various	O
poses	O
http	O
:	O
//multipie.org	O
faces	B
in	O
the	O
wild	O
internet	O
images	O
faces	B
in	O
various	O
poses	O
gross	O
,	O
matthews	O
,	O
cohn	O
et	O
al	O
.	O
(	O
2010	O
)	O
http	O
:	O
//vis-www.cs.umass.edu/lfw/	O
huang	O
,	O
ramesh	O
,	O
berg	O
et	O
al	O
.	O
(	O
2007	O
)	O
consumer	O
image	B
person	O
db	O
complete	O
images	O
people	O
http	O
:	O
//chenlab.ece.cornell.edu/people/andy/gallagherdataset.html	O
gallagher	O
and	O
chen	O
(	O
2008	O
)	O
object	O
recognition	B
caltech	O
101	O
segmentation	B
masks	O
http	O
:	O
//www.vision.caltech.edu/image	O
datasets/caltech101/	O
101	O
categories	O
fei-fei	O
,	O
fergus	O
,	O
and	O
perona	O
(	O
2006	O
)	O
caltech	O
256	O
centered	O
objects	O
256	O
categories	O
and	O
clutter	O
http	O
:	O
//www.vision.caltech.edu/image	O
datasets/caltech256/	O
grifﬁn	O
,	O
holub	O
,	O
and	O
perona	O
(	O
2007	O
)	O
coil-100	O
centered	O
objects	O
100	O
instances	O
http	O
:	O
//www1.cs.columbia.edu/cave/software/softlib/coil-100.php	O
nene	O
,	O
nayar	O
,	O
and	O
murase	O
(	O
1996	O
)	O
eth-80	O
centered	O
objects	O
http	O
:	O
//www.mis.tu-darmstadt.de/datasets	O
8	O
instances	O
,	O
10	O
views	O
leibe	O
and	O
schiele	O
(	O
2003	O
)	O
instance	B
recognition	O
benchmark	O
objects	O
in	O
various	O
poses	O
2550	O
objects	O
http	O
:	O
//vis.uky.edu/∼stewe/ukbench/	O
oxford	O
buildings	O
dataset	O
pictures	O
of	O
buildings	O
5062	O
images	O
nist´er	O
and	O
stew´enius	O
(	O
2006	O
)	O
norb	O
tiny	O
images	O
bounding	O
box	O
complete	O
images	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/data/oxbuildings/	O
http	O
:	O
//www.cs.nyu.edu/∼ylclab/data/norb-v1.0/	O
http	O
:	O
//people.csail.mit.edu/torralba/tinyimages/	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
(	O
2007	O
)	O
50	O
toys	O
lecun	O
,	O
huang	O
,	O
and	O
bottou	O
(	O
2004	O
)	O
75,000	O
(	O
wordnet	O
)	O
things	O
torralba	O
,	O
freeman	O
,	O
and	O
fergus	O
(	O
2008	O
)	O
imagenet	O
http	O
:	O
//www.image-net.org/	O
complete	O
images	O
14,000	O
(	O
wordnet	O
)	O
things	O
deng	O
,	O
dong	O
,	O
socher	O
et	O
al	O
.	O
(	O
2009	O
)	O
table	O
14.1	O
image	B
databases	O
for	B
recognition	I
,	O
adapted	O
and	O
expanded	O
from	O
fei-fei	O
,	O
fergus	O
,	O
and	O
torralba	O
(	O
2009	O
)	O
.	O
720	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
name	O
/	O
url	O
extents	O
contents	O
/	O
reference	O
object	O
detection	B
/	O
localization	O
cmu	O
frontal	O
faces	B
patches	O
http	O
:	O
//vasc.ri.cmu.edu/idb/html/face/frontal	O
images	O
mit	O
frontal	O
faces	B
patches	O
http	O
:	O
//cbcl.mit.edu/software-datasets/facedata2.html	O
cmu	O
face	B
detection	O
databases	O
multiple	B
faces	O
frontal	O
faces	B
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
(	O
1998a	O
)	O
frontal	O
faces	B
sung	O
and	O
poggio	O
(	O
1998	O
)	O
faces	B
in	O
various	O
poses	O
http	O
:	O
//www.ri.cmu.edu/research	O
project	O
detail.html	O
?	O
project	O
id=419	O
schneiderman	O
and	O
kanade	O
(	O
2004	O
)	O
uiuc	O
image	B
db	O
bounding	O
boxes	O
cars	O
http	O
:	O
//l2r.cs.uiuc.edu/∼cogcomp/data/car/	O
caltech	O
pedestrian	B
dataset	O
bounding	O
boxes	O
agarwal	O
and	O
roth	O
(	O
2002	O
)	O
pedestrians	O
http	O
:	O
//www.vision.caltech.edu/image	O
datasets/caltechpedestrians/	O
doll`ar	O
,	O
wojek	O
,	O
schiele	O
et	O
al	O
.	O
(	O
2009	O
)	O
graz-02	O
database	O
segmentation	B
masks	O
bikes	O
,	O
cars	O
,	O
people	O
http	O
:	O
//www.emt.tugraz.at/∼pinz/data/graz	O
02/	O
ethz	O
toys	O
cluttered	O
images	O
http	O
:	O
//www.vision.ee.ethz.ch/∼calvin/datasets.html	O
tu	O
darmstadt	O
db	O
segmentation	B
masks	O
http	O
:	O
//www.vision.ee.ethz.ch/∼bleibe/data/datasets.html	O
msr	O
cambridge	O
segmentation	B
masks	O
opelt	O
,	O
pinz	O
,	O
fussenegger	O
et	O
al	O
.	O
(	O
2006	O
)	O
toys	O
,	O
boxes	O
,	O
magazines	O
ferrari	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
(	O
2006b	O
)	O
motorbikes	O
,	O
cars	O
,	O
cows	O
leibe	O
,	O
leonardis	O
,	O
and	O
schiele	O
(	O
2008	O
)	O
23	O
classes	O
http	O
:	O
//research.microsoft.com/en-us/projects/objectclassrecognition/	O
shotton	O
,	O
winn	O
,	O
rother	O
et	O
al	O
.	O
(	O
2009	O
)	O
labelme	O
dataset	O
polygonal	O
boundary	O
>	O
500	O
categories	O
http	O
:	O
//labelme.csail.mit.edu/	O
russell	O
,	O
torralba	O
,	O
murphy	O
et	O
al	O
.	O
(	O
2008	O
)	O
lotus	O
hill	O
segmentation	B
masks	O
scenes	O
and	O
hierarchies	O
http	O
:	O
//www.imageparsing.com/	O
on-line	O
annotation	O
tools	O
yao	O
,	O
yang	O
,	O
lin	O
et	O
al	O
.	O
(	O
2010	O
)	O
esp	O
game	O
image	B
descriptions	O
web	O
images	O
http	O
:	O
//www.gwap.com/gwap/	O
von	O
ahn	O
and	O
dabbish	O
(	O
2004	O
)	O
peekaboom	O
labeled	O
regions	O
web	O
images	O
http	O
:	O
//www.gwap.com/gwap/	O
von	O
ahn	O
,	O
liu	O
,	O
and	O
blum	O
(	O
2006	O
)	O
labelme	O
polygonal	O
boundary	O
high-resolution	O
images	O
http	O
:	O
//labelme.csail.mit.edu/	O
collections	O
of	O
challenges	O
russell	O
,	O
torralba	O
,	O
murphy	O
et	O
al	O
.	O
(	O
2008	O
)	O
pascal	O
segmentation	B
,	O
boxes	O
various	O
http	O
:	O
//pascallin.ecs.soton.ac.uk/challenges/voc/	O
everingham	O
,	O
van	O
gool	O
,	O
williams	O
et	O
al	O
.	O
(	O
2010	O
)	O
table	O
14.2	O
image	B
databases	O
for	O
detection	O
and	O
localization	O
,	O
adapted	O
and	O
expanded	O
from	O
fei-	O
fei	O
,	O
fergus	O
,	O
and	O
torralba	O
(	O
2009	O
)	O
.	O
14.6	O
recognition	B
databases	O
and	O
test	O
sets	O
721	O
airplane	O
bicycle	O
bird	O
boat	O
bottle	O
bus	O
car	B
cat	O
chair	O
cow	O
diningtable	O
dog	O
horse	O
motorbike	O
person	O
pottedplant	O
sheep	O
sofa	O
train	O
tvmonitor	O
figure	O
14.54	O
sample	O
images	O
from	O
the	O
pascal	O
visual	O
object	O
classes	O
challenge	O
2008	O
(	O
voc2008	O
)	O
database	O
(	O
everingham	O
,	O
van	O
gool	O
,	O
williams	O
et	O
al	O
.	O
2008	O
)	O
.	O
the	O
original	O
images	O
were	O
obtained	O
from	O
ﬂickr	O
(	O
http	O
:	O
//www.ﬂickr.com/	O
)	O
and	O
the	O
database	O
rights	O
are	O
explained	O
on	O
http	O
:	O
//pascallin.ecs.soton.ac.uk/challenges/voc/voc2008/	O
.	O
“	O
serious	O
”	O
volunteer	O
effort	O
is	O
the	O
labelme	O
database	O
,	O
in	O
which	O
vision	O
researchers	O
contribute	O
manual	O
polygonal	O
region	B
annotations	O
in	O
return	O
for	O
gaining	O
access	O
to	O
the	O
database	O
(	O
russell	O
,	O
torralba	O
,	O
murphy	O
et	O
al	O
.	O
2008	O
)	O
.	O
the	O
use	O
of	O
computer	O
vision	O
algorithms	O
for	O
collecting	O
recognition	B
databases	O
dates	O
back	O
to	O
the	O
work	O
of	O
fergus	O
,	O
fei-fei	O
,	O
perona	O
et	O
al	O
.	O
(	O
2005	O
)	O
,	O
who	O
cluster	O
the	O
results	O
returned	O
by	O
google	O
image	B
search	I
using	O
an	O
extension	O
of	O
plsa	O
and	O
then	O
select	O
the	O
clusters	O
associated	O
with	O
the	O
highest	O
ranked	O
results	O
.	O
more	O
recent	O
examples	B
of	O
related	O
techniques	O
include	O
the	O
work	O
of	O
berg	O
and	O
forsyth	O
(	O
2006	O
)	O
and	O
li	O
and	O
fei-fei	O
(	O
2010	O
)	O
.	O
whatever	O
methods	O
are	O
used	O
to	O
collect	O
and	O
validate	O
recognition	B
databases	O
,	O
they	O
will	O
con-	O
tinue	O
to	O
grow	O
in	O
size	O
,	O
utility	O
,	O
and	O
difﬁculty	O
from	O
year	O
to	O
year	O
.	O
they	O
will	O
also	O
continue	O
to	O
be	O
an	O
essential	O
component	O
of	O
research	O
into	O
the	O
recognition	B
and	O
scene	B
understanding	I
problems	O
,	O
which	O
remain	O
,	O
as	O
always	O
,	O
the	O
grand	O
challenges	O
of	O
computer	O
vision	O
.	O
722	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
14.7	O
additional	O
reading	O
although	O
there	O
are	O
currently	O
no	O
specialized	O
textbooks	B
on	O
image	B
recognition	O
and	O
scene	O
un-	O
derstanding	O
,	O
some	O
surveys	B
(	O
pinz	O
2005	O
)	O
and	O
collections	O
of	O
papers	O
(	O
ponce	O
,	O
hebert	O
,	O
schmid	O
et	O
al	O
.	O
2006	O
;	O
dickinson	O
,	O
leonardis	O
,	O
schiele	O
et	O
al	O
.	O
2007	O
)	O
can	O
be	O
found	O
that	O
describe	O
the	O
latest	O
ap-	O
proaches	O
.	O
other	O
good	O
sources	O
of	O
recent	O
research	O
are	O
courses	O
on	O
this	O
topic	O
,	O
such	O
as	O
the	O
iccv	O
2009	O
short	O
course	O
(	O
fei-fei	O
,	O
fergus	O
,	O
and	O
torralba	O
2009	O
)	O
and	O
antonio	O
torralba	O
’	O
s	O
more	O
com-	O
prehensive	O
mit	O
course	O
(	O
torralba	O
2008	O
)	O
.	O
the	O
pascal	O
voc	O
challenge	O
web	O
site	O
contains	O
workshop	O
slides	O
that	O
summarize	O
today	O
’	O
s	O
best	O
performing	O
algorithms	O
.	O
the	O
literature	O
on	O
face	B
,	O
pedestrian	B
,	O
car	B
,	O
and	O
other	O
object	O
detection	B
is	O
quite	O
extensive	O
.	O
sem-	O
inal	O
papers	O
in	O
face	B
detection	O
include	O
those	O
by	O
osuna	O
,	O
freund	O
,	O
and	O
girosi	O
(	O
1997	O
)	O
,	O
sung	O
and	O
poggio	O
(	O
1998	O
)	O
,	O
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
(	O
1998a	O
)	O
,	O
and	O
viola	O
and	O
jones	O
(	O
2004	O
)	O
,	O
with	O
yang	O
,	O
kriegman	O
,	O
and	O
ahuja	O
(	O
2002	O
)	O
providing	O
a	O
comprehensive	O
survey	O
of	O
early	O
work	O
in	O
this	O
ﬁeld	O
.	O
more	O
recent	O
examples	B
include	O
(	O
heisele	O
,	O
ho	O
,	O
wu	O
et	O
al	O
.	O
2003	O
;	O
heisele	O
,	O
serre	O
,	O
and	O
poggio	O
2007	O
)	O
.	O
early	O
work	O
in	O
pedestrian	B
and	O
car	B
detection	O
was	O
carried	O
out	O
by	O
gavrila	O
and	O
philomin	O
(	O
1999	O
)	O
,	O
gavrila	O
(	O
1999	O
)	O
,	O
papageorgiou	O
and	O
poggio	O
(	O
2000	O
)	O
,	O
mohan	O
,	O
papageorgiou	O
,	O
and	O
pog-	O
gio	O
(	O
2001	O
)	O
,	O
and	O
schneiderman	O
and	O
kanade	O
(	O
2004	O
)	O
.	O
more	O
recent	O
examples	B
include	O
the	O
work	O
of	O
belongie	O
,	O
malik	O
,	O
and	O
puzicha	O
(	O
2002	O
)	O
,	O
mikolajczyk	O
,	O
schmid	O
,	O
and	O
zisserman	O
(	O
2004	O
)	O
,	O
dalal	O
and	O
triggs	O
(	O
2005	O
)	O
,	O
leibe	O
,	O
seemann	O
,	O
and	O
schiele	O
(	O
2005	O
)	O
,	O
dalal	O
,	O
triggs	O
,	O
and	O
schmid	O
(	O
2006	O
)	O
,	O
opelt	O
,	O
pinz	O
,	O
and	O
zisserman	O
(	O
2006	O
)	O
,	O
torralba	O
(	O
2007	O
)	O
,	O
andriluka	O
,	O
roth	O
,	O
and	O
schiele	O
(	O
2008	O
)	O
,	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
(	O
2008	O
)	O
,	O
rogez	O
,	O
rihan	O
,	O
ramalingam	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
andriluka	O
,	O
roth	O
,	O
and	O
schiele	O
(	O
2009	O
)	O
,	O
kumar	O
,	O
zisserman	O
,	O
and	O
h.s.torr	O
(	O
2009	O
)	O
,	O
doll`ar	O
,	O
be-	O
longie	O
,	O
and	O
perona	O
(	O
2010	O
)	O
.	O
and	O
felzenszwalb	O
,	O
girshick	O
,	O
mcallester	O
et	O
al	O
.	O
(	O
2010	O
)	O
.	O
while	O
some	O
of	O
the	O
earliest	O
approaches	O
to	O
face	B
recognition	O
involved	O
ﬁnding	O
the	O
distinc-	O
tive	O
image	B
features	O
and	O
measuring	O
the	O
distances	O
between	O
them	O
(	O
fischler	O
and	O
elschlager	O
1973	O
;	O
kanade	O
1977	O
;	O
yuille	O
1991	O
)	O
,	O
more	O
recent	O
approaches	O
rely	O
on	O
comparing	O
gray-level	O
images	O
,	O
often	O
projected	O
onto	O
lower	O
dimensional	O
subspaces	O
(	O
turk	O
and	O
pentland	O
1991a	O
;	O
belhumeur	O
,	O
hespanha	O
,	O
and	O
kriegman	O
1997	O
;	O
moghaddam	O
and	O
pentland	O
1997	O
;	O
moghaddam	O
,	O
jebara	O
,	O
and	O
pentland	O
2000	O
;	O
heisele	O
,	O
ho	O
,	O
wu	O
et	O
al	O
.	O
2003	O
;	O
heisele	O
,	O
serre	O
,	O
and	O
poggio	O
2007	O
)	O
.	O
additional	O
details	O
on	O
principal	O
component	O
analysis	O
(	O
pca	O
)	O
and	O
its	O
bayesian	O
counterparts	O
can	O
be	O
found	O
in	O
appendix	O
b.1.1	O
and	O
books	O
and	O
articles	O
on	O
this	O
topic	O
(	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
bishop	O
2006	O
;	O
roweis	O
1998	O
;	O
tipping	O
and	O
bishop	O
1999	O
;	O
leonardis	O
and	O
bischof	O
2000	O
;	O
vidal	O
,	O
ma	O
,	O
and	O
sastry	O
2010	O
)	O
.	O
the	O
topics	O
of	O
subspace	O
learning	B
,	O
local	B
distance	O
functions	O
,	O
and	O
metric	O
learning	B
are	O
covered	O
by	O
cai	O
,	O
he	O
,	O
hu	O
et	O
al	O
.	O
(	O
2007	O
)	O
,	O
frome	O
,	O
singer	O
,	O
sha	O
et	O
al	O
.	O
(	O
2007	O
)	O
,	O
guil-	O
laumin	O
,	O
verbeek	O
,	O
and	O
schmid	O
(	O
2009	O
)	O
,	O
ramanan	O
and	O
baker	O
(	O
2009	O
)	O
,	O
and	O
sivic	O
,	O
everingham	O
,	O
and	O
zisserman	O
(	O
2009	O
)	O
.	O
an	O
alternative	O
to	O
directly	O
matching	B
gray-level	O
images	O
or	O
patches	O
is	O
to	O
use	O
non-linear	B
local	O
transforms	O
such	O
as	O
local	O
binary	O
patterns	O
(	O
ahonen	O
,	O
hadid	O
,	O
and	O
pietik¨ainen	O
2006	O
;	O
zhao	O
and	O
pietik¨ainen	O
2007	O
;	O
cao	O
,	O
yin	O
,	O
tang	O
et	O
al	O
.	O
2010	O
)	O
.	O
14.7	O
additional	O
reading	O
723	O
in	O
order	B
to	O
boost	O
the	O
performance	O
of	O
what	O
are	O
essentially	O
2d	O
appearance-based	O
models	O
,	O
a	O
variety	O
of	O
shape	O
and	O
pose	O
deformation	O
models	O
have	O
been	O
developed	O
(	O
beymer	O
1996	O
;	O
vet-	O
ter	O
and	O
poggio	O
1997	O
)	O
,	O
including	O
active	O
shape	O
models	O
(	O
lanitis	O
,	O
taylor	O
,	O
and	O
cootes	O
1997	O
;	O
cootes	O
,	O
cooper	O
,	O
taylor	O
et	O
al	O
.	O
1995	O
;	O
davies	O
,	O
twining	O
,	O
and	O
taylor	O
2008	O
)	O
,	O
elastic	B
bunch	I
graph	I
matching	I
(	O
wiskott	O
,	O
fellous	O
,	O
kr¨uger	O
et	O
al	O
.	O
1997	O
)	O
,	O
3d	O
morphable	O
models	O
(	O
blanz	O
and	O
vetter	O
1999	O
)	O
,	O
and	O
active	O
appearance	O
models	O
(	O
costen	O
,	O
cootes	O
,	O
edwards	O
et	O
al	O
.	O
1999	O
;	O
cootes	O
,	O
ed-	O
wards	O
,	O
and	O
taylor	O
2001	O
;	O
gross	O
,	O
baker	O
,	O
matthews	O
et	O
al	O
.	O
2005	O
;	O
gross	O
,	O
matthews	O
,	O
and	O
baker	O
2006	O
;	O
matthews	O
,	O
xiao	O
,	O
and	O
baker	O
2007	O
;	O
liang	O
,	O
xiao	O
,	O
wen	O
et	O
al	O
.	O
2008	O
;	O
ramnath	O
,	O
koterba	O
,	O
xiao	O
et	O
al	O
.	O
2008	O
)	O
.	O
the	O
topic	O
of	O
head	B
pose	O
estimation	B
,	O
in	O
particular	O
,	O
is	O
covered	O
in	O
a	O
recent	O
survey	O
by	O
murphy-chutorian	O
and	O
trivedi	O
(	O
2009	O
)	O
.	O
additional	O
information	O
about	O
face	B
recognition	O
can	O
be	O
found	O
in	O
a	O
number	O
of	O
surveys	B
and	O
books	O
on	O
this	O
topic	O
(	O
chellappa	O
,	O
wilson	O
,	O
and	O
sirohey	O
1995	O
;	O
zhao	O
,	O
chellappa	O
,	O
phillips	O
et	O
al	O
.	O
2003	O
;	O
li	O
and	O
jain	O
2005	O
)	O
as	O
well	O
as	O
on	O
the	O
face	B
recognition	O
web	O
site.23	O
databases	O
for	O
face	O
recognition	B
are	O
discussed	O
by	O
phillips	O
,	O
moon	O
,	O
rizvi	O
et	O
al	O
.	O
(	O
2000	O
)	O
,	O
sim	O
,	O
baker	O
,	O
and	O
bsat	O
(	O
2003	O
)	O
,	O
gross	O
,	O
shi	O
,	O
and	O
cohn	O
(	O
2005	O
)	O
,	O
huang	O
,	O
ramesh	O
,	O
berg	O
et	O
al	O
.	O
(	O
2007	O
)	O
,	O
and	O
phillips	O
,	O
scruggs	O
,	O
o	O
’	O
toole	O
et	O
al	O
.	O
(	O
2010	O
)	O
.	O
algorithms	O
for	O
instance	O
recognition	B
,	O
i.e.	O
,	O
the	O
detection	B
of	O
static	O
man-made	O
objects	O
that	O
only	O
vary	O
slightly	O
in	O
appearance	O
but	O
may	O
vary	O
in	O
3d	O
pose	O
,	O
are	O
mostly	O
based	O
on	O
detecting	O
2d	O
points	B
of	O
interest	O
and	O
describing	O
them	O
using	O
viewpoint-invariant	O
descriptors	O
(	O
lowe	O
2004	O
;	O
rothganger	O
,	O
lazebnik	O
,	O
schmid	O
et	O
al	O
.	O
2006	O
;	O
ferrari	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
2006b	O
;	O
gordon	O
and	O
lowe	O
2006	O
;	O
obdrˇz´alek	O
and	O
matas	O
2006	O
;	O
kannala	O
,	O
rahtu	O
,	O
brandt	O
et	O
al	O
.	O
2008	O
;	O
sivic	O
and	O
zisserman	O
2009	O
)	O
.	O
as	O
the	O
size	O
of	O
the	O
database	O
being	O
matched	O
increases	O
,	O
it	O
becomes	O
more	O
efﬁcient	O
to	O
quantize	O
the	O
visual	O
descriptors	O
into	O
words	O
(	O
sivic	O
and	O
zisserman	O
2003	O
;	O
schindler	O
,	O
brown	O
,	O
and	O
szeliski	O
2007	O
;	O
sivic	O
and	O
zisserman	O
2009	O
;	O
turcot	O
and	O
lowe	O
2009	O
)	O
,	O
and	O
to	O
then	O
use	O
information-	O
retrieval	O
techniques	O
,	O
such	O
as	O
inverted	O
indices	O
(	O
nist´er	O
and	O
stew´enius	O
2006	O
;	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
;	O
philbin	O
,	O
chum	O
,	O
sivic	O
et	O
al	O
.	O
2008	O
)	O
,	O
query	B
expansion	I
(	O
chum	O
,	O
philbin	O
,	O
sivic	O
et	O
al	O
.	O
2007	O
;	O
agarwal	O
,	O
snavely	O
,	O
simon	O
et	O
al	O
.	O
2009	O
)	O
,	O
and	O
min	O
hashing	B
(	O
philbin	O
and	O
zisserman	O
2008	O
;	O
li	O
,	O
wu	O
,	O
zach	O
et	O
al	O
.	O
2008	O
;	O
chum	O
,	O
philbin	O
,	O
and	O
zisserman	O
2008	O
;	O
chum	O
and	O
matas	O
2010	O
)	O
to	O
perform	O
efﬁcient	O
retrieval	O
and	O
clustering	O
.	O
a	O
number	O
of	O
surveys	B
,	O
collections	O
of	O
papers	O
,	O
and	O
course	O
notes	O
have	O
been	O
written	O
on	O
the	O
topic	O
of	O
category	O
recognition	O
(	O
pinz	O
2005	O
;	O
ponce	O
,	O
hebert	O
,	O
schmid	O
et	O
al	O
.	O
2006	O
;	O
dickinson	O
,	O
leonardis	O
,	O
schiele	O
et	O
al	O
.	O
2007	O
;	O
fei-fei	O
,	O
fergus	O
,	O
and	O
torralba	O
2009	O
)	O
.	O
some	O
of	O
the	O
seminal	O
papers	O
on	O
the	O
bag	B
of	I
words	I
(	O
bag	O
of	O
keypoints	O
)	O
approach	O
to	O
whole-image	O
category	O
recognition	O
have	O
been	O
written	O
by	O
csurka	O
,	O
dance	O
,	O
fan	O
et	O
al	O
.	O
(	O
2004	O
)	O
,	O
lazebnik	O
,	O
schmid	O
,	O
and	O
ponce	O
(	O
2006	O
)	O
,	O
csurka	O
,	O
dance	O
,	O
perronnin	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
grauman	O
and	O
darrell	O
(	O
2007b	O
)	O
,	O
and	O
zhang	O
,	O
marszalek	O
,	O
23	O
http	O
:	O
//www.face-rec.org/	O
.	O
724	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
lazebnik	O
et	O
al	O
.	O
(	O
2007	O
)	O
.	O
additional	O
and	O
more	O
recent	O
papers	O
in	O
this	O
area	O
include	O
sivic	O
,	O
russell	O
,	O
efros	O
et	O
al	O
.	O
(	O
2005	O
)	O
,	O
serre	O
,	O
wolf	O
,	O
and	O
poggio	O
(	O
2005	O
)	O
,	O
opelt	O
,	O
pinz	O
,	O
fussenegger	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
grauman	O
and	O
darrell	O
(	O
2007a	O
)	O
,	O
torralba	O
,	O
murphy	O
,	O
and	O
freeman	O
(	O
2007	O
)	O
,	O
boiman	O
,	O
shechtman	O
,	O
and	O
irani	O
(	O
2008	O
)	O
,	O
ferencz	O
,	O
learned-miller	O
,	O
and	O
malik	O
(	O
2008	O
)	O
,	O
and	O
mutch	O
and	O
lowe	O
(	O
2008	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
recognize	O
objects	O
based	O
on	O
their	O
contours	O
,	O
e.g.	O
,	O
using	O
shape	O
contexts	O
(	O
belongie	O
,	O
malik	O
,	O
and	O
puzicha	O
2002	O
)	O
or	O
other	O
techniques	O
(	O
jurie	O
and	O
schmid	O
2004	O
;	O
shotton	O
,	O
blake	O
,	O
and	O
cipolla	O
2005	O
;	O
opelt	O
,	O
pinz	O
,	O
and	O
zisserman	O
2006	O
;	O
ferrari	O
,	O
tuytelaars	O
,	O
and	O
van	O
gool	O
2006a	O
)	O
.	O
many	O
object	O
recognition	B
algorithms	O
use	O
part-based	B
decompositions	O
to	O
provide	O
greater	O
in-	O
variance	O
to	O
articulation	O
and	O
pose	O
.	O
early	O
algorithms	O
focused	O
on	O
the	O
relative	O
positions	O
of	O
the	O
parts	O
(	O
fischler	O
and	O
elschlager	O
1973	O
;	O
kanade	O
1977	O
;	O
yuille	O
1991	O
)	O
while	O
newer	O
algorithms	O
use	O
more	O
sophisticated	O
models	O
of	O
appearance	O
(	O
felzenszwalb	O
and	O
huttenlocher	O
2005	O
;	O
fergus	O
,	O
per-	O
ona	O
,	O
and	O
zisserman	O
2007	O
;	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
2008	O
)	O
.	O
good	O
overviews	O
on	O
part-based	B
models	O
for	B
recognition	I
can	O
be	O
found	O
in	O
the	O
course	O
notes	O
of	O
fergus	O
2007b	O
;	O
2009.	O
carneiro	O
and	O
lowe	O
(	O
2006	O
)	O
discuss	O
a	O
number	O
of	O
graphical	O
models	O
used	O
for	O
part-based	O
recognition	B
,	O
which	O
include	O
trees	O
and	O
stars	O
(	O
felzenszwalb	O
and	O
huttenlocher	O
2005	O
;	O
fergus	O
,	O
per-	O
ona	O
,	O
and	O
zisserman	O
2005	O
;	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
2008	O
)	O
,	O
k-fans	O
(	O
crandall	O
,	O
felzenszwalb	O
,	O
and	O
huttenlocher	O
2005	O
;	O
crandall	O
and	O
huttenlocher	O
2006	O
)	O
,	O
and	O
constellations	O
(	O
burl	O
,	O
weber	O
,	O
and	O
perona	O
1998	O
;	O
weber	O
,	O
welling	O
,	O
and	O
perona	O
2000	O
;	O
fergus	O
,	O
perona	O
,	O
and	O
zis-	O
serman	O
2007	O
)	O
.	O
other	O
techniques	O
that	O
use	O
part-based	B
recognition	O
include	O
those	O
developed	O
by	O
dork´o	O
and	O
schmid	O
(	O
2003	O
)	O
and	O
bar-hillel	O
,	O
hertz	O
,	O
and	O
weinshall	O
(	O
2005	O
)	O
.	O
combining	O
object	O
recognition	B
with	O
scene	O
segmentation	O
can	O
yield	O
strong	O
beneﬁts	O
.	O
one	O
approach	O
is	O
to	O
pre-segment	O
the	O
image	B
into	O
pieces	O
and	O
then	O
match	O
the	O
pieces	O
to	O
portions	O
of	O
the	O
model	O
(	O
mori	O
,	O
ren	O
,	O
efros	O
et	O
al	O
.	O
2004	O
;	O
mori	O
2005	O
;	O
he	O
,	O
zemel	O
,	O
and	O
ray	O
2006	O
;	O
russell	O
,	O
efros	O
,	O
sivic	O
et	O
al	O
.	O
2006	O
;	O
borenstein	O
and	O
ullman	O
2008	O
;	O
csurka	O
and	O
perronnin	O
2008	O
;	O
gu	O
,	O
lim	O
,	O
arbelaez	O
et	O
al	O
.	O
2009	O
)	O
.	O
another	O
is	O
to	O
vote	O
for	O
potential	O
object	O
locations	O
and	O
scales	O
based	O
on	O
object	O
detection	B
(	O
leibe	O
,	O
leonardis	O
,	O
and	O
schiele	O
2008	O
)	O
.	O
one	O
of	O
the	O
currently	O
most	O
popular	O
approaches	O
is	O
to	O
use	O
conditional	O
random	O
ﬁelds	O
(	O
kumar	O
and	O
hebert	O
2006	O
;	O
he	O
,	O
zemel	O
,	O
and	O
carreira-perpi˜n´an	O
2004	O
;	O
he	O
,	O
zemel	O
,	O
and	O
ray	O
2006	O
;	O
levin	O
and	O
weiss	O
2006	O
;	O
winn	O
and	O
shotton	O
2006	O
;	O
hoiem	O
,	O
rother	O
,	O
and	O
winn	O
2007	O
;	O
rabinovich	O
,	O
vedaldi	O
,	O
galleguillos	O
et	O
al	O
.	O
2007	O
;	O
verbeek	O
and	O
triggs	O
2007	O
;	O
yang	O
,	O
meer	O
,	O
and	O
foran	O
2007	O
;	O
batra	O
,	O
sukthankar	O
,	O
and	O
chen	O
2008	O
;	O
larlus	O
and	O
jurie	O
2008	O
;	O
he	O
and	O
zemel	O
2008	O
;	O
shotton	O
,	O
winn	O
,	O
rother	O
et	O
al	O
.	O
2009	O
;	O
kumar	O
,	O
torr	O
,	O
and	O
zisserman	O
2010	O
)	O
,	O
which	O
produce	O
some	O
of	O
the	O
best	O
results	O
on	O
the	O
difﬁcult	O
pascal	O
voc	O
seg-	O
mentation	O
challenge	O
(	O
shotton	O
,	O
johnson	O
,	O
and	O
cipolla	O
2008	O
;	O
kohli	O
,	O
ladick´y	O
,	O
and	O
torr	O
2009	O
)	O
.	O
more	O
and	O
more	O
recognition	B
algorithms	O
are	O
starting	O
to	O
use	O
scene	O
context	O
as	O
part	O
of	O
their	O
recognition	B
strategy	O
.	O
representative	O
papers	O
in	O
this	O
area	O
include	O
those	O
by	O
torralba	O
(	O
2003	O
)	O
,	O
torralba	O
,	O
murphy	O
,	O
freeman	O
et	O
al	O
.	O
(	O
2003	O
)	O
,	O
murphy	O
,	O
torralba	O
,	O
and	O
freeman	O
(	O
2003	O
)	O
,	O
torralba	O
,	O
murphy	O
,	O
and	O
freeman	O
(	O
2004	O
)	O
,	O
crandall	O
and	O
huttenlocher	O
(	O
2007	O
)	O
,	O
rabinovich	O
,	O
vedaldi	O
,	O
gal-	O
14.8	O
exercises	O
725	O
leguillos	O
et	O
al	O
.	O
(	O
2007	O
)	O
,	O
russell	O
,	O
torralba	O
,	O
liu	O
et	O
al	O
.	O
(	O
2007	O
)	O
,	O
hoiem	O
,	O
efros	O
,	O
and	O
hebert	O
(	O
2008a	O
)	O
,	O
hoiem	O
,	O
efros	O
,	O
and	O
hebert	O
(	O
2008b	O
)	O
,	O
sudderth	O
,	O
torralba	O
,	O
freeman	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
and	O
divvala	O
,	O
hoiem	O
,	O
hays	O
et	O
al	O
.	O
(	O
2009	O
)	O
.	O
sophisticated	O
machine	O
learning	O
techniques	O
are	O
also	O
becoming	O
a	O
key	O
component	O
of	O
suc-	O
cessful	O
object	O
detection	B
and	O
recognition	B
algorithms	O
(	O
varma	O
and	O
ray	O
2007	O
;	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
2008	O
;	O
fritz	O
and	O
schiele	O
2008	O
;	O
sivic	O
,	O
russell	O
,	O
zisserman	O
et	O
al	O
.	O
2008	O
;	O
vedaldi	O
,	O
gulshan	O
,	O
varma	O
et	O
al	O
.	O
2009	O
)	O
,	O
as	O
is	O
exploiting	O
large	O
human-labeled	O
databases	O
(	O
russell	O
,	O
torralba	O
,	O
liu	O
et	O
al	O
.	O
2007	O
;	O
malisiewicz	O
and	O
efros	O
2008	O
;	O
torralba	O
,	O
freeman	O
,	O
and	O
fer-	O
gus	O
2008	O
;	O
liu	O
,	O
yuen	O
,	O
and	O
torralba	O
2009	O
)	O
.	O
rough	O
three-dimensional	O
models	O
are	O
also	O
making	O
a	O
comeback	O
for	B
recognition	I
,	O
as	O
evidenced	O
in	O
some	O
recent	O
papers	O
(	O
savarese	O
and	O
fei-fei	O
2007	O
,	O
2008	O
;	O
sun	O
,	O
su	O
,	O
savarese	O
et	O
al	O
.	O
2009	O
;	O
su	O
,	O
sun	O
,	O
fei-fei	O
et	O
al	O
.	O
2009	O
)	O
.	O
as	O
always	O
,	O
the	O
latest	O
con-	O
ferences	O
on	O
computer	O
vision	O
are	O
your	O
best	O
reference	O
for	O
the	O
newest	O
algorithms	O
in	O
this	O
rapidly	O
evolving	O
ﬁeld	O
.	O
14.8	O
exercises	O
ex	O
14.1	O
:	O
face	B
detection	O
build	O
and	O
test	O
one	O
of	O
the	O
face	B
detectors	O
presented	O
in	O
section	O
14.1.1	O
.	O
1.	O
download	O
one	O
or	O
more	O
of	O
the	O
labeled	O
face	B
detection	O
databases	O
in	O
table	O
14.2	O
.	O
2.	O
generate	O
your	O
own	O
negative	O
examples	B
by	O
ﬁnding	O
photographs	O
that	O
do	O
not	O
contain	O
any	O
people	O
.	O
3.	O
implement	O
one	O
of	O
the	O
following	O
face	B
detectors	O
(	O
or	O
devise	O
one	O
of	O
your	O
own	O
)	O
:	O
•	O
boosting	B
(	O
algorithm	B
14.1	O
)	O
based	O
on	O
simple	O
area	O
features	O
,	O
with	O
an	O
optional	O
cascade	O
of	O
detectors	O
(	O
viola	O
and	O
jones	O
2004	O
)	O
;	O
•	O
pca	O
face	B
subspace	O
(	O
moghaddam	O
and	O
pentland	O
1997	O
)	O
;	O
•	O
distances	O
to	O
clustered	O
face	B
and	O
non-face	O
prototypes	O
,	O
followed	O
by	O
a	O
neural	O
network	O
(	O
sung	O
and	O
poggio	O
1998	O
)	O
or	O
svm	O
(	O
osuna	O
,	O
freund	O
,	O
and	O
girosi	O
1997	O
)	O
classiﬁer	O
;	O
•	O
a	O
multi-resolution	O
neural	O
network	O
trained	O
directly	O
on	O
normalized	B
gray-level	O
patches	O
(	O
rowley	O
,	O
baluja	O
,	O
and	O
kanade	O
1998a	O
)	O
.	O
4.	O
test	O
the	O
performance	O
of	O
your	O
detector	O
on	O
the	O
database	O
by	O
evaluating	O
the	O
detector	O
at	O
ev-	O
ery	O
location	O
in	O
a	O
sub-octave	O
pyramid	B
.	O
optionally	O
retrain	O
your	O
detector	O
on	O
false	O
positive	O
examples	O
you	O
get	O
on	O
non-face	O
images	O
.	O
ex	O
14.2	O
:	O
determining	O
the	O
threshold	O
for	O
adaboost	O
given	O
a	O
set	O
of	O
function	O
evaluations	O
on	O
the	O
training	O
examples	B
xi	O
,	O
fi	O
=	O
f	O
(	O
xi	O
)	O
∈	O
±1	O
,	O
training	O
labels	O
yi	O
∈	O
±1	O
,	O
and	O
weights	O
wi	O
∈	O
(	O
0	O
,	O
1	O
)	O
,	O
726	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
as	O
explained	O
in	O
algorithm	B
14.1	O
,	O
devise	O
an	O
efﬁcient	O
algorithm	B
to	O
ﬁnd	O
values	O
of	O
θ	O
and	O
s	O
=	O
±1	O
that	O
maximize	O
(	O
14.43	O
)	O
wiyih	O
(	O
sfi	O
,	O
θ	O
)	O
,	O
(	O
cid:88	O
)	O
i	O
where	O
h	O
(	O
x	O
,	O
θ	O
)	O
=	O
sign	O
(	O
x	O
−	O
θ	O
)	O
.	O
ex	O
14.3	O
:	O
face	B
recognition	O
using	O
eigenfaces	O
collect	O
a	O
set	O
of	O
facial	O
photographs	O
and	O
then	O
build	O
a	O
recognition	B
system	O
to	O
re-recognize	O
the	O
same	O
people	O
.	O
1.	O
take	O
several	O
photos	O
of	O
each	O
of	O
your	O
classmates	O
and	O
store	O
them	O
.	O
2.	O
align	O
the	O
images	O
by	O
automatically	O
or	O
manually	O
detecting	O
the	O
corners	O
of	O
the	O
eyes	O
and	O
using	O
a	O
similarity	B
transform	O
to	O
stretch	O
and	O
rotate	O
each	O
image	B
to	O
a	O
canonical	O
position	O
.	O
3.	O
compute	O
the	O
average	O
image	B
and	O
a	O
pca	O
subspace	O
for	O
the	O
face	B
images	O
4.	O
take	O
a	O
new	O
set	O
of	O
photographs	O
a	O
week	O
later	O
and	O
use	O
them	O
as	O
your	O
test	O
set	O
.	O
5.	O
compare	O
each	O
new	O
image	B
to	O
each	O
database	O
image	B
and	O
select	O
the	O
nearest	O
one	O
as	O
the	O
recognized	O
identity	O
.	O
verify	O
that	O
the	O
distance	O
in	O
pca	O
space	O
is	O
close	O
to	O
the	O
distance	O
computed	O
with	O
a	O
full	O
ssd	O
(	O
sum	O
of	O
squared	O
difference	B
)	O
measure	O
.	O
6	O
.	O
(	O
optional	O
)	O
compute	O
different	O
principal	O
components	O
for	O
identity	O
and	O
expression	O
,	O
and	O
use	O
them	O
to	O
improve	O
your	O
recognition	B
results	O
.	O
ex	O
14.4	O
:	O
bayesian	O
face	B
recognition	O
moghaddam	O
,	O
jebara	O
,	O
and	O
pentland	O
(	O
2000	O
)	O
compute	O
separate	O
covariance	O
matrices	O
σi	O
and	O
σe	O
by	O
looking	O
at	O
differences	O
between	O
all	O
pairs	B
of	O
im-	O
ages	O
.	O
at	O
run	O
time	O
,	O
they	O
select	O
the	O
nearest	O
image	O
to	O
determine	O
the	O
facial	O
identity	O
.	O
does	O
it	O
make	O
sense	O
to	O
estimate	O
statistics	O
for	O
all	O
pairs	B
of	O
images	O
and	O
use	O
them	O
for	O
testing	O
the	O
distance	O
to	O
the	O
nearest	O
exemplar	O
?	O
discuss	O
whether	O
this	O
is	O
statistically	O
correct	O
.	O
how	O
is	O
the	O
all-pair	O
intrapersonal	O
covariance	O
matrix	O
σi	O
related	O
to	O
the	O
within-class	B
scatter	O
matrix	O
sw	O
?	O
does	O
a	O
similar	O
relationship	O
hold	O
between	O
σe	O
and	O
sb	O
?	O
ex	O
14.5	O
:	O
modular	O
eigenfaces	O
extend	O
your	O
face	B
recognition	O
system	O
to	O
separately	O
match	O
the	O
eye	O
,	O
nose	O
,	O
and	O
mouth	O
regions	O
,	O
as	O
shown	O
in	O
figure	O
14.18	O
.	O
1.	O
after	O
normalizing	B
face	O
images	O
to	O
a	O
canonical	O
scale	O
and	O
location	O
,	O
manually	O
segment	O
out	O
some	O
of	O
the	O
eye	O
,	O
nose	O
,	O
and	O
face	B
regions	O
.	O
2.	O
build	O
separate	O
detectors	O
for	O
these	O
three	O
(	O
or	O
four	O
)	O
kinds	O
of	O
region	B
,	O
either	O
using	O
a	O
subspace	O
(	O
pca	O
)	O
approach	O
or	O
one	O
of	O
the	O
techniques	O
presented	O
in	O
section	O
14.1.1	O
.	O
3.	O
for	O
each	O
new	O
image	B
to	O
be	O
recognized	O
,	O
ﬁrst	O
detect	O
the	O
locations	O
of	O
the	O
facial	O
features	O
.	O
14.8	O
exercises	O
727	O
4.	O
then	O
,	O
match	O
the	O
individual	O
features	O
against	O
your	O
database	O
and	O
note	O
the	O
locations	O
of	O
these	O
features	O
.	O
5.	O
train	O
and	O
test	O
a	O
classiﬁer	O
that	O
uses	O
the	O
individual	O
feature	B
matching	O
ids	O
as	O
well	O
as	O
(	O
op-	O
tionally	O
)	O
the	O
feature	B
locations	O
to	O
perform	O
face	B
recognition	O
.	O
ex	O
14.6	O
:	O
recognition-based	O
color	B
balancing	O
build	O
a	O
system	O
that	O
recognizes	O
the	O
most	O
im-	O
portant	O
color	B
areas	O
in	O
common	O
photographs	O
(	O
sky	O
,	O
grass	O
,	O
skin	O
)	O
and	O
color	B
balances	O
the	O
image	B
accordingly	O
.	O
some	O
references	B
and	O
ideas	O
for	O
skin	O
detection	B
are	O
given	O
in	O
exercise	O
2.8	O
and	O
by	O
forsyth	O
and	O
fleck	O
(	O
1999	O
)	O
,	O
jones	O
and	O
rehg	O
(	O
2001	O
)	O
,	O
vezhnevets	O
,	O
sazonov	O
,	O
and	O
andreeva	O
(	O
2003	O
)	O
,	O
and	O
kakumanu	O
,	O
makrogiannis	O
,	O
and	O
bourbakis	O
(	O
2007	O
)	O
.	O
these	O
may	O
give	O
you	O
ideas	O
for	O
how	O
to	O
detect	O
other	O
regions	O
or	O
you	O
can	O
try	O
more	O
sophisticated	O
mrf-based	O
approaches	O
(	O
shotton	O
,	O
winn	O
,	O
rother	O
et	O
al	O
.	O
2009	O
)	O
.	O
ex	O
14.7	O
:	O
pedestrian	B
detection	O
build	O
and	O
test	O
one	O
of	O
the	O
pedestrian	B
detectors	O
presented	O
in	O
section	O
14.1.2.	O
ex	O
14.8	O
:	O
simple	O
instance	B
recognition	O
use	O
the	O
feature	B
detection	O
,	O
matching	B
,	O
and	O
alignment	B
algorithms	O
you	O
developed	O
in	O
exercises	O
4.1–4.4	O
and	O
9.2	O
to	O
ﬁnd	O
matching	B
images	O
given	O
a	O
query	O
image	O
or	O
region	B
(	O
figure	O
14.26	O
)	O
.	O
evaluate	O
several	O
feature	B
detectors	O
,	O
descriptors	O
,	O
and	O
robust	B
geometric	O
veriﬁcation	B
strate-	O
gies	O
,	O
either	O
on	O
your	O
own	O
or	O
by	O
comparing	O
your	O
results	O
with	O
those	O
of	O
classmates	O
.	O
ex	O
14.9	O
:	O
large	O
databases	O
and	O
location	B
recognition	I
extend	O
the	O
previous	O
exercise	O
to	O
larger	O
databases	O
using	O
quantized	O
visual	B
words	I
and	O
information	O
retrieval	O
techniques	O
,	O
as	O
described	O
in	O
algorithm	B
14.2.	O
test	O
your	O
algorithm	B
on	O
a	O
large	O
database	O
,	O
such	O
as	O
the	O
one	O
used	O
by	O
nist´er	O
and	O
stew´enius	O
(	O
2006	O
)	O
or	O
philbin	O
,	O
chum	O
,	O
sivic	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
which	O
are	O
listed	O
in	O
table	O
14.1.	O
alternatively	O
,	O
use	O
keyword	O
search	O
on	O
the	O
web	O
or	O
in	O
a	O
photo	O
sharing	O
site	O
(	O
e.g.	O
,	O
for	O
a	O
city	O
)	O
to	O
create	O
your	O
own	O
database	O
.	O
ex	O
14.10	O
:	O
bag	B
of	I
words	I
adapt	O
the	O
feature	B
extraction	O
and	O
matching	B
pipeline	O
developed	O
in	O
exercise	O
14.8	O
to	O
category	O
(	O
class	O
)	O
recognition	B
,	O
using	O
some	O
of	O
the	O
techniques	O
described	O
in	O
sec-	O
tion	B
14.4.1	O
.	O
1.	O
download	O
the	O
training	O
and	O
test	B
images	I
from	O
one	O
or	O
more	O
of	O
the	O
databases	O
listed	O
in	O
tables	O
14.1	O
and	O
14.2	O
,	O
e.g.	O
,	O
caltech	O
101	O
,	O
caltech	O
256	O
,	O
or	O
pascal	O
voc	O
.	O
2.	O
extract	O
features	O
from	O
each	O
of	O
the	O
training	O
images	O
,	O
quantize	O
them	O
,	O
and	O
compute	O
the	O
tf-idf	O
vectors	O
(	O
bag	B
of	I
words	I
histograms	O
)	O
.	O
728	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
3.	O
as	O
an	O
option	O
,	O
consider	O
not	O
quantizing	O
the	O
features	O
and	O
using	O
pyramid	O
matching	B
(	O
14.40–	O
14.41	O
)	O
(	O
grauman	O
and	O
darrell	O
2007b	O
)	O
or	O
using	O
a	O
spatial	O
pyramid	B
for	O
greater	O
selectivity	B
(	O
lazebnik	O
,	O
schmid	O
,	O
and	O
ponce	O
2006	O
)	O
.	O
4.	O
choose	O
a	O
classiﬁcation	O
algorithm	B
(	O
e.g.	O
,	O
nearest	B
neighbor	I
classiﬁcation	O
or	O
support	O
vector	O
machine	O
)	O
and	O
“	O
train	O
”	O
your	O
recognizer	O
,	O
i.e.	O
,	O
build	O
up	O
the	O
appropriate	O
data	O
structures	O
(	O
e.g.	O
,	O
k-d	B
trees	I
)	O
or	O
set	O
the	O
appropriate	O
classiﬁer	O
parameters	B
.	O
5.	O
test	O
your	O
algorithm	B
on	O
the	O
test	O
data	O
set	O
using	O
the	O
same	O
pipeline	B
you	O
developed	O
in	O
steps	O
2–4	O
and	O
compare	O
your	O
results	O
to	O
the	O
best	O
reported	O
results	O
.	O
6.	O
explain	O
why	O
your	O
results	O
differ	O
from	O
the	O
previously	O
reported	O
ones	O
and	O
give	O
some	O
ideas	O
for	O
how	O
you	O
could	O
improve	O
your	O
system	O
.	O
you	O
can	O
ﬁnd	O
a	O
good	O
synopsis	O
of	O
the	O
best-performing	O
classiﬁcation	O
algorithms	O
and	O
their	O
ap-	O
proaches	O
in	O
the	O
report	O
of	O
the	O
pascal	O
visual	O
object	O
classes	O
challenge	O
found	O
on	O
their	O
web	O
site	O
(	O
http	O
:	O
//pascallin.ecs.soton.ac.uk/challenges/voc/	O
)	O
.	O
ex	O
14.11	O
:	O
object	O
detection	B
and	O
localization	O
extend	O
the	O
classiﬁcation	O
algorithm	B
developed	O
in	O
the	O
previous	O
exercise	O
to	O
localize	O
the	O
objects	O
in	O
an	O
image	B
by	O
reporting	O
a	O
bounding	O
box	O
around	O
each	O
detected	O
object	O
.	O
the	O
easiest	O
way	O
to	O
do	O
this	O
is	O
to	O
use	O
a	O
sliding	O
window	O
approach	O
.	O
some	O
pointers	O
to	O
recent	O
techniques	O
in	O
this	O
area	O
can	O
be	O
found	O
in	O
the	O
workshop	O
associated	O
with	O
the	O
pascal	O
voc	O
2008	O
challenge	O
.	O
ex	O
14.12	O
:	O
part-based	B
recognition	O
choose	O
one	O
or	O
more	O
of	O
the	O
techniques	O
described	O
in	O
sec-	O
tion	B
14.4.2	O
and	O
implement	O
a	O
part-based	B
recognition	O
system	O
.	O
since	O
these	O
techniques	O
are	O
fairly	O
involved	O
,	O
you	O
will	O
need	O
to	O
read	O
several	O
of	O
the	O
research	O
papers	O
in	O
this	O
area	O
,	O
select	O
which	O
gen-	O
eral	O
approach	O
you	O
want	O
to	O
follow	O
,	O
and	O
then	O
implement	O
your	O
algorithm	B
.	O
a	O
good	O
starting	O
point	O
could	O
be	O
the	O
paper	O
by	O
felzenszwalb	O
,	O
mcallester	O
,	O
and	O
ramanan	O
(	O
2008	O
)	O
,	O
since	O
it	O
performed	O
well	O
in	O
the	O
pascal	O
voc	O
2008	O
detection	B
challenge	O
.	O
ex	O
14.13	O
:	O
recognition	B
and	O
segmentation	B
choose	O
one	O
or	O
more	O
of	O
the	O
techniques	O
described	O
in	O
section	O
14.4.3	O
and	O
implement	O
a	O
simultaneous	O
recognition	B
and	O
segmentation	B
system	O
.	O
since	O
these	O
techniques	O
are	O
fairly	O
involved	O
,	O
you	O
will	O
need	O
to	O
read	O
several	O
of	O
the	O
research	O
papers	O
in	O
this	O
area	O
,	O
select	O
which	O
general	O
approach	O
you	O
want	O
to	O
follow	O
,	O
and	O
then	O
implement	O
your	O
algorithm	B
.	O
test	O
your	O
algorithm	B
on	O
one	O
or	O
more	O
of	O
the	O
segmentation	B
databases	O
in	O
table	O
14.2.	O
ex	O
14.14	O
:	O
context	B
implement	O
one	O
or	O
more	O
of	O
the	O
context	B
and	O
scene	B
understanding	I
sys-	O
tems	O
described	O
in	O
section	O
14.5	O
and	O
report	O
on	O
your	O
experience	O
.	O
does	O
context	B
or	O
whole	O
scene	B
understanding	I
perform	O
better	O
at	O
naming	O
objects	O
than	O
stand-alone	O
systems	O
?	O
14.8	O
exercises	O
729	O
ex	O
14.15	O
:	O
tiny	O
images	O
download	O
the	O
tiny	O
images	O
database	O
from	O
http	O
:	O
//people.csail.mit	O
.	O
edu/torralba/tinyimages/	O
and	O
build	O
a	O
classiﬁer	O
based	O
on	O
comparing	O
your	O
test	B
images	I
directly	O
against	O
all	O
of	O
the	O
labeled	O
training	O
images	O
.	O
does	O
this	O
seem	O
like	O
a	O
promising	O
approach	O
?	O
730	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
chapter	O
15	O
conclusion	O
in	O
this	O
book	O
,	O
we	O
have	O
covered	O
a	O
broad	O
range	O
of	O
computer	O
vision	O
topics	O
.	O
starting	O
with	O
image	O
formation	O
,	O
we	O
have	O
seen	O
how	O
images	O
can	O
be	O
pre-processed	O
to	O
remove	O
noise	B
or	O
blur	O
,	O
segmented	O
into	O
regions	O
,	O
or	O
converted	O
into	O
feature	B
descriptors	O
.	O
multiple	B
images	O
can	O
be	O
matched	O
and	O
registered	O
,	O
with	O
the	O
results	O
used	O
to	O
estimate	O
motion	B
,	O
track	O
people	O
,	O
reconstruct	O
3d	O
models	O
,	O
or	O
merge	O
images	O
into	O
more	O
attractive	O
and	O
interesting	O
composites	O
and	O
renderings	O
.	O
images	O
can	O
also	O
be	O
analyzed	O
to	O
produce	O
semantic	O
descriptions	O
of	O
their	O
content	O
.	O
however	O
,	O
the	O
gap	O
between	O
computer	O
and	O
human	O
performance	O
in	O
this	O
area	O
is	O
still	O
large	O
and	O
is	O
likely	O
to	O
remain	O
so	O
for	O
many	O
years	O
.	O
our	O
study	O
has	O
also	O
exposed	O
us	O
to	O
a	O
wide	O
range	O
of	O
mathematical	O
techniques	O
.	O
these	O
include	O
continuous	O
mathematics	O
,	O
such	O
as	O
signal	O
processing	O
,	O
variational	O
approaches	O
,	O
three-dimensional	O
and	O
projective	B
geometry	O
,	O
linear	B
algebra	O
,	O
and	O
least	B
squares	I
.	O
we	O
have	O
also	O
studied	O
topics	O
in	O
discrete	B
mathematics	O
and	O
computer	O
science	O
,	O
such	O
as	O
graph	O
algorithms	O
,	O
combinatorial	O
opti-	O
mization	O
,	O
and	O
even	O
database	O
techniques	O
for	O
information	O
retrieval	O
.	O
since	O
many	O
problems	O
in	O
computer	O
vision	O
are	O
inverse	B
problems	O
that	O
involve	O
estimating	O
unknown	O
quantities	O
from	O
noisy	O
input	O
data	O
,	O
we	O
have	O
also	O
looked	O
at	O
bayesian	O
statistical	O
inference	B
techniques	O
,	O
as	O
well	O
as	O
ma-	O
chine	O
learning	B
techniques	O
to	O
learn	O
probabilistic	B
models	I
from	O
large	O
amounts	O
of	O
training	O
data	O
.	O
as	O
the	O
availability	O
of	O
partially	O
labeled	O
visual	O
imagery	O
on	O
the	O
internet	O
continues	O
to	O
increase	O
exponentially	O
,	O
this	O
latter	O
approach	O
will	O
continue	O
to	O
have	O
a	O
major	O
impact	O
on	O
our	O
ﬁeld	O
.	O
you	O
may	O
ask	O
:	O
why	O
is	O
our	O
ﬁeld	O
so	O
broad	O
and	O
aren	O
’	O
t	O
there	O
any	O
unifying	O
principles	O
that	O
can	O
be	O
used	O
to	O
simplify	O
our	O
study	O
?	O
part	O
of	O
the	O
answer	O
lies	O
in	O
the	O
expansive	O
deﬁnition	O
of	O
com-	O
puter	O
vision	O
,	O
which	O
is	O
the	O
analysis	O
of	O
images	O
and	O
video	B
,	O
as	O
well	O
as	O
the	O
incredible	O
complexity	O
inherent	O
in	O
the	O
formation	O
of	O
visual	O
imagery	O
.	O
in	O
some	O
ways	O
,	O
our	O
ﬁeld	O
is	O
as	O
complex	O
as	O
the	O
study	O
of	O
automotive	O
engineering	O
,	O
which	O
requires	O
an	O
understanding	O
of	O
internal	O
combustion	O
,	O
mechanics	O
,	O
aerodynamics	O
,	O
ergonomics	O
,	O
electrical	O
circuitry	O
,	O
and	O
control	O
systems	O
,	O
among	O
other	O
732	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
topics	O
.	O
computer	O
vision	O
similarly	O
draws	O
on	O
a	O
wide	O
variety	O
of	O
sub-disciplines	O
,	O
which	O
makes	O
it	O
challenging	O
to	O
cover	O
in	O
a	O
one-semester	O
course	O
,	O
let	O
alone	O
to	O
achieve	O
mastery	O
during	O
a	O
course	O
of	O
graduate	O
studies	O
.	O
conversely	O
,	O
the	O
incredible	O
breadth	O
and	O
technical	O
complexity	O
of	O
computer	O
vision	O
problems	O
is	O
what	O
draws	O
many	O
people	O
to	O
this	O
research	O
ﬁeld	O
.	O
because	O
of	O
this	O
richness	O
and	O
the	O
difﬁculty	O
in	O
making	O
and	O
measuring	O
progress	O
,	O
i	O
have	O
at-	O
tempted	O
to	O
instill	O
in	O
my	O
students	O
and	O
in	O
readers	O
of	O
this	O
book	O
a	O
discipline	O
founded	O
on	O
principles	O
from	O
engineering	O
,	O
science	O
,	O
and	O
statistics	O
.	O
the	O
engineering	O
approach	O
to	O
problem	O
solving	O
is	O
to	O
ﬁrst	O
carefully	O
deﬁne	O
the	O
overall	O
prob-	O
lem	O
being	O
tackled	O
and	O
to	O
question	O
the	O
basic	O
assumptions	O
and	O
goals	O
inherent	O
in	O
this	O
process	O
.	O
once	O
this	O
has	O
been	O
done	O
,	O
a	O
number	O
of	O
alternative	O
solutions	O
or	O
approaches	O
are	O
implemented	O
and	O
carefully	O
tested	O
,	O
paying	O
attention	O
to	O
issues	O
such	O
as	O
reliability	O
and	O
computational	O
cost	O
.	O
finally	O
,	O
one	O
or	O
more	O
solutions	O
are	O
deployed	O
and	O
evaluated	O
in	O
real-world	O
settings	O
.	O
for	O
this	O
reason	O
,	O
this	O
book	O
contains	O
many	O
different	O
alternatives	O
for	O
solving	O
vision	O
problems	O
,	O
many	O
of	O
which	O
are	O
sketched	O
out	O
in	O
the	O
exercises	O
for	O
students	O
to	O
implement	O
and	O
test	O
on	O
their	O
own	O
.	O
the	O
scientiﬁc	O
approach	O
builds	O
upon	O
a	O
basic	O
understanding	O
of	O
physical	O
principles	O
.	O
in	O
the	O
case	O
of	O
computer	O
vision	O
,	O
this	O
includes	O
the	O
physics	O
of	O
man-made	O
and	O
natural	B
structures	O
,	O
image	B
formation	O
,	O
including	O
lighting	B
and	O
atmospheric	O
effects	O
,	O
optics	B
,	O
and	O
noisy	O
sensors	O
.	O
the	O
task	O
is	O
to	O
then	O
invert	O
this	O
formation	O
using	O
stable	O
and	O
efﬁcient	O
algorithms	O
to	O
obtain	O
reliable	O
descriptions	O
of	O
the	O
scene	O
and	O
other	O
quantities	O
of	O
interest	O
.	O
the	O
scientiﬁc	O
approach	O
also	O
encourages	O
us	O
to	O
formulate	O
and	O
test	O
hypotheses	O
,	O
which	O
is	O
similar	O
to	O
the	O
extensive	O
testing	O
and	O
evaluation	B
inherent	O
in	O
engineering	O
disciplines	O
.	O
lastly	O
,	O
because	O
so	O
much	O
about	O
the	O
image	B
formation	O
process	O
is	O
inherently	O
uncertain	O
and	O
ambiguous	O
,	O
a	O
statistical	O
approach	O
that	O
models	O
both	O
uncertainty	B
in	O
the	O
world	O
(	O
e.g.	O
,	O
the	O
number	O
and	O
types	O
of	O
animals	O
in	O
a	O
picture	O
)	O
and	O
noise	B
in	O
the	O
image	B
formation	O
process	O
,	O
is	O
often	O
essential	O
.	O
bayesian	O
inference	B
techniques	O
can	O
then	O
be	O
used	O
to	O
combine	O
prior	B
and	O
measurement	O
models	O
to	O
estimate	O
the	O
unknowns	O
and	O
to	O
model	O
their	O
uncertainty	B
.	O
machine	O
learning	O
techniques	O
can	O
be	O
used	O
to	O
create	O
the	O
probabilistic	B
models	I
in	O
the	O
ﬁrst	O
place	O
.	O
efﬁcient	O
learning	B
and	O
inference	B
algorithms	O
,	O
such	O
as	O
dynamic	B
programming	I
,	O
graph	B
cuts	I
,	O
and	O
belief	B
propagation	I
,	O
often	O
play	O
a	O
crucial	O
role	O
in	O
this	O
process	O
.	O
given	O
the	O
breadth	O
of	O
material	O
we	O
have	O
covered	O
in	O
this	O
book	O
,	O
what	O
new	O
developments	O
are	O
we	O
likely	O
to	O
see	O
in	O
the	O
future	O
?	O
as	O
i	O
have	O
mentioned	O
before	O
,	O
one	O
of	O
the	O
recent	O
trends	O
in	O
com-	O
puter	O
vision	O
is	O
using	O
the	O
massive	O
amounts	O
of	O
partially	O
labeled	O
visual	O
data	O
on	O
the	O
internet	O
as	O
sources	O
for	O
learning	O
visual	O
models	O
of	O
scenes	O
and	O
objects	O
.	O
we	O
have	O
already	O
seen	O
data-driven	O
approaches	O
succeed	O
in	O
related	O
ﬁelds	O
such	O
as	O
speech	O
recognition	B
,	O
machine	O
translation	O
,	O
speech	O
and	O
music	O
synthesis	O
,	O
and	O
even	O
computer	O
graphics	O
(	O
both	O
in	O
image-based	B
rendering	I
and	O
anima-	O
tion	B
from	O
motion	B
capture	O
)	O
.	O
a	O
similar	O
process	O
has	O
been	O
occurring	O
in	O
computer	O
vision	O
,	O
with	O
some	O
of	O
the	O
most	O
exciting	O
new	O
work	O
occurring	O
at	O
the	O
intersection	O
of	O
the	O
object	O
recognition	B
and	O
machine	O
learning	O
ﬁelds	O
.	O
15	O
conclusion	O
733	O
more	O
traditional	O
quantitative	O
techniques	O
in	O
computer	O
vision	O
such	O
as	O
motion	B
estimation	I
,	O
stereo	B
correspondence	O
,	O
and	O
image	B
enhancement	O
,	O
all	O
beneﬁt	O
from	O
better	O
prior	B
models	O
for	O
im-	O
ages	O
,	O
motions	O
,	O
and	O
disparities	O
,	O
as	O
well	O
as	O
efﬁcient	O
statistical	O
inference	B
techniques	O
such	O
as	O
those	O
for	O
inhomogeneous	O
and	O
higher-order	O
markov	O
random	O
ﬁelds	O
.	O
some	O
techniques	O
,	O
such	O
as	O
feature	B
matching	O
and	O
structure	B
from	I
motion	I
,	O
have	O
matured	O
to	O
where	O
they	O
can	O
be	O
applied	O
to	O
almost	O
arbitrary	O
collections	O
of	O
images	O
of	O
static	O
scenes	O
.	O
this	O
has	O
resulted	O
in	O
an	O
explosion	O
of	O
work	O
in	O
3d	O
modeling	B
from	O
internet	O
datasets	O
,	O
which	O
again	O
is	O
related	O
to	O
visual	O
recognition	O
from	O
massive	O
amounts	O
of	O
data	O
.	O
while	O
these	O
are	O
all	O
encouraging	O
developments	O
,	O
the	O
gap	O
between	O
human	O
and	O
machine	O
per-	O
formance	O
in	O
semantic	O
scene	B
understanding	I
remains	O
large	O
.	O
it	O
may	O
be	O
many	O
years	O
before	O
com-	O
puters	O
can	O
name	O
and	O
outline	O
all	O
of	O
the	O
objects	O
in	O
a	O
photograph	O
with	O
the	O
same	O
skill	O
as	O
a	O
two-	O
year-old	O
child	O
.	O
however	O
,	O
we	O
have	O
to	O
remember	O
that	O
human	O
performance	O
is	O
often	O
the	O
result	O
of	O
many	O
years	O
of	O
training	O
and	O
familiarity	O
and	O
often	O
works	O
best	O
in	O
special	O
ecologically	O
important	O
situations	O
.	O
for	O
example	O
,	O
while	O
humans	O
appear	O
to	O
be	O
experts	O
at	O
face	B
recognition	O
,	O
our	O
actual	O
performance	O
when	O
shown	O
people	O
we	O
do	O
not	O
know	O
well	O
is	O
not	O
that	O
good	O
.	O
combining	O
vision	O
algorithms	O
with	O
general	O
inference	B
techniques	O
that	O
reason	O
about	O
the	O
real	O
world	O
will	O
likely	O
lead	O
to	O
more	O
breakthroughs	O
,	O
although	O
some	O
of	O
the	O
problems	O
may	O
turn	O
out	O
to	O
be	O
“	O
ai-complete	O
”	O
,	O
in	O
the	O
sense	O
that	O
a	O
full	O
emulation	O
of	O
human	O
experience	O
and	O
intelligence	O
may	O
be	O
necessary	O
.	O
whatever	O
the	O
outcome	O
of	O
these	O
research	O
endeavors	O
,	O
computer	O
vision	O
is	O
already	O
having	O
a	O
tremendous	O
impact	O
in	O
many	O
areas	O
,	O
including	O
digital	O
photography	O
,	O
visual	B
effects	I
,	O
medical	B
imaging	I
,	O
safety	O
and	O
surveillance	O
,	O
and	O
web-based	O
search	O
.	O
the	O
breadth	O
of	O
the	O
problems	O
and	O
techniques	O
inherent	O
in	O
this	O
ﬁeld	O
,	O
combined	O
with	O
the	O
richness	O
of	O
the	O
mathematics	O
and	O
the	O
utility	O
of	O
the	O
resulting	O
algorithms	O
,	O
will	O
ensure	O
that	O
this	O
remains	O
an	O
exciting	O
area	O
of	O
study	O
for	O
years	O
to	O
come	O
.	O
734	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
appendix	O
a	O
linear	B
algebra	O
and	O
numerical	O
techniques	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
a.2	O
linear	B
least	O
squares	O
.	O
a.1	O
matrix	B
decompositions	I
.	O
.	O
a.1.1	O
singular	O
value	O
decomposition	O
.	O
.	O
a.1.2	O
eigenvalue	O
decomposition	O
.	O
a.1.3	O
qr	O
factorization	B
.	O
.	O
.	O
.	O
.	O
.	O
a.1.4	O
cholesky	O
factorization	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
a.2.1	O
total	B
least	O
squares	O
.	O
.	O
a.3	O
non-linear	B
least	O
squares	O
.	O
.	O
.	O
.	O
a.4	O
direct	B
sparse	O
matrix	O
techniques	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
a.4.1	O
variable	O
reordering	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
a.5	O
iterative	B
techniques	O
.	O
.	O
a.5.1	O
conjugate	B
gradient	I
.	O
a.5.2	O
preconditioning	O
.	O
a.5.3	O
multigrid	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
736	O
.	O
736	O
.	O
737	O
.	O
740	O
.	O
741	O
.	O
742	O
.	O
744	O
.	O
746	O
.	O
747	O
.	O
748	O
.	O
748	O
.	O
749	O
.	O
751	O
.	O
753	O
736	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
in	O
this	O
appendix	O
,	O
we	O
introduce	O
some	O
elements	O
of	O
linear	B
algebra	O
and	O
numerical	O
techniques	O
that	O
are	O
used	O
elsewhere	O
in	O
the	O
book	O
.	O
we	O
start	O
with	O
some	O
basic	O
decompositions	O
in	O
matrix	O
algebra	O
,	O
including	O
the	O
singular	O
value	O
decomposition	O
(	O
svd	O
)	O
,	O
eigenvalue	O
decompositions	O
,	O
and	O
other	O
matrix	B
decompositions	I
(	O
factorizations	O
)	O
.	O
next	O
,	O
we	O
look	O
at	O
the	O
problem	O
of	O
linear	B
least	O
squares	O
,	O
which	O
can	O
be	O
solved	O
using	O
either	O
the	O
qr	O
decomposition	O
or	O
normal	O
equations	O
.	O
this	O
is	O
followed	O
by	O
non-linear	O
least	B
squares	I
,	O
which	O
arise	O
when	O
the	O
measurement	O
equations	B
are	O
not	O
linear	B
in	O
the	O
unknowns	O
or	O
when	O
robust	B
error	O
functions	O
are	O
used	O
.	O
such	O
problems	O
require	O
iteration	O
to	O
ﬁnd	O
a	O
solution	O
.	O
next	O
,	O
we	O
look	O
at	O
direct	B
solution	O
(	O
factorization	B
)	O
techniques	O
for	O
sparse	O
problems	O
,	O
where	O
the	O
ordering	O
of	O
the	O
variables	O
can	O
have	O
a	O
large	O
inﬂuence	O
on	O
the	O
computation	O
and	O
memory	O
requirements	O
.	O
finally	O
,	O
we	O
discuss	O
iterative	B
techniques	O
for	O
solving	O
large	O
linear	O
(	O
or	O
linearized	O
)	O
least	B
squares	I
problems	O
.	O
good	O
general	O
references	B
for	O
much	O
of	O
this	O
material	O
include	O
the	O
work	O
by	O
bj¨orck	O
(	O
1996	O
)	O
,	O
golub	O
and	O
van	O
loan	O
(	O
1996	O
)	O
,	O
trefethen	O
and	O
bau	O
(	O
1997	O
)	O
,	O
meyer	O
(	O
2000	O
)	O
,	O
nocedal	O
and	O
wright	O
(	O
2006	O
)	O
,	O
and	O
bj¨orck	O
and	O
dahlquist	O
(	O
2010	O
)	O
.	O
a	O
note	O
on	O
vector	O
and	O
matrix	O
indexing	O
.	O
to	O
be	O
consistent	O
with	O
the	O
rest	O
of	O
the	O
book	O
and	O
with	O
the	O
general	O
usage	O
in	O
the	O
computer	O
science	O
and	O
computer	O
vision	O
communities	O
,	O
i	O
adopt	O
a	O
0-based	O
indexing	O
scheme	O
for	O
vector	O
and	O
matrix	O
element	O
indexing	O
.	O
please	O
note	O
that	O
most	O
mathematical	O
textbooks	B
and	O
papers	O
use	O
1-based	O
indexing	O
,	O
so	O
you	O
need	O
to	O
be	O
aware	O
of	O
the	O
differences	O
when	O
you	O
read	O
this	O
book	O
.	O
software	O
implementations	O
.	O
highly	O
optimized	O
and	O
tested	O
libraries	O
corresponding	O
to	O
the	O
al-	O
gorithms	O
described	O
in	O
this	O
appendix	O
are	O
readily	O
available	O
and	O
are	O
listed	O
in	O
appendix	O
c.2	O
.	O
a.1	O
matrix	B
decompositions	I
in	O
order	B
to	O
better	O
understand	O
the	O
structure	O
of	O
matrices	O
and	O
more	O
stably	O
perform	O
operations	O
such	O
as	O
inversion	O
and	O
system	O
solving	O
,	O
a	O
number	O
of	O
decompositions	O
(	O
or	O
factorizations	O
)	O
can	O
be	O
used	O
.	O
in	O
this	O
section	O
,	O
we	O
review	O
singular	O
value	O
decomposition	O
(	O
svd	O
)	O
,	O
eigenvalue	O
decomposi-	O
tion	B
,	O
qr	O
factorization	B
,	O
and	O
cholesky	O
factorization	B
.	O
a.1.1	O
singular	O
value	O
decomposition	O
one	O
of	O
the	O
most	O
useful	O
decompositions	O
in	O
matrix	O
algebra	O
is	O
the	O
singular	O
value	O
decomposition	O
(	O
svd	O
)	O
,	O
which	O
states	O
that	O
any	O
real-valued	O
m	O
×	O
n	O
matrix	O
a	O
can	O
be	O
written	O
as	O
am×n	O
=	O
u	O
m×p	O
σp×p	O
v	O
t	O
p×n	O
(	O
a.1	O
)	O
(	O
a.2	O
)	O
(	O
a.3	O
)	O
a.1	O
matrix	B
decompositions	I
737	O
=	O
	O
u0	O
···	O
up−1	O
	O
	O
σ0	O
...	O
σp−1	O
	O
	O
vt	O
0	O
···	O
vt	O
p−1	O
	O
,	O
where	O
p	O
=	O
min	O
(	O
m	O
,	O
n	O
)	O
.	O
the	O
matrices	O
u	O
and	O
v	O
are	O
orthonormal	O
,	O
i.e.	O
,	O
u	O
t	O
u	O
=	O
i	O
and	O
v	O
t	O
v	O
=	O
i	O
,	O
and	O
so	O
are	O
their	O
column	O
vectors	O
,	O
the	O
singular	O
values	O
are	O
all	O
non-negative	O
and	O
can	O
be	O
ordered	O
in	O
decreasing	O
order	B
ui	O
·	O
uj	O
=	O
vi	O
·	O
vj	O
=	O
δij	O
.	O
σ0	O
≥	O
σ1	O
≥	O
···	O
≥	O
σp−1	O
≥	O
0.	O
a	O
geometric	B
intuition	O
for	O
the	O
svd	O
of	O
a	O
matrix	O
a	O
can	O
be	O
obtained	O
by	O
re-writing	O
a	O
=	O
uσv	O
t	O
in	O
(	O
a.2	O
)	O
as	O
(	O
a.4	O
)	O
this	O
formula	O
says	O
that	O
the	O
matrix	O
a	O
takes	O
any	O
basis	O
vector	O
vj	O
and	O
maps	O
it	O
to	O
a	O
direction	O
uj	O
with	O
length	O
σj	O
,	O
as	O
shown	O
in	O
figure	O
a.1	O
av	O
=	O
uς	O
or	O
avj	O
=	O
σjuj	O
.	O
if	O
only	O
the	O
ﬁrst	O
r	O
singular	O
values	O
are	O
positive	O
,	O
the	O
matrix	O
a	O
is	O
of	O
rank	O
r	O
and	O
the	O
index	O
p	O
in	O
the	O
svd	O
decomposition	O
(	O
a.2	O
)	O
can	O
be	O
replaced	O
by	O
r.	O
(	O
in	O
other	O
words	O
,	O
we	O
can	O
drop	O
the	O
last	O
p	O
−	O
r	O
columns	O
of	O
u	O
and	O
v	O
.	O
)	O
an	O
important	O
property	O
of	O
the	O
singular	O
value	O
decomposition	O
of	O
a	O
matrix	O
(	O
also	O
true	O
for	O
the	O
eigenvalue	O
decomposition	O
of	O
a	O
real	O
symmetric	O
non-negative	O
deﬁnite	O
matrix	O
)	O
is	O
that	O
if	O
we	O
truncate	O
the	O
expansion	O
a	O
=	O
σjujvt	O
j	O
,	O
(	O
a.5	O
)	O
t	O
(	O
cid:88	O
)	O
j=0	O
we	O
obtain	O
the	O
best	O
possible	O
least	B
squares	I
approximation	O
to	O
the	O
original	O
matrix	O
a.	O
this	O
is	O
used	O
both	O
in	O
eigenface-based	O
face	B
recognition	O
systems	O
(	O
section	O
14.2.1	O
)	O
and	O
in	O
the	O
separable	B
approximation	O
of	O
convolution	O
kernels	O
(	O
3.21	O
)	O
.	O
a.1.2	O
eigenvalue	O
decomposition	O
if	O
the	O
matrix	O
c	O
is	O
symmetric	O
(	O
m	O
=	O
n	O
)	O
,1	O
it	O
can	O
be	O
written	O
as	O
an	O
eigenvalue	O
decomposition	O
,	O
c	O
=	O
uλu	O
t	O
=	O
u0	O
=	O
λiuiut	O
i	O
.	O
n−1	O
(	O
cid:88	O
)	O
i=0	O
···	O
un−1	O
	O
	O
λ0	O
...	O
λn−1	O
	O
	O
ut	O
0	O
···	O
ut	O
n−1	O
	O
(	O
a.6	O
)	O
1	O
in	O
this	O
appendix	O
,	O
we	O
denote	O
symmetric	O
matrices	O
using	O
c	O
and	O
general	O
rectangular	O
matrices	O
using	O
a	O
.	O
738	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
a.1	O
the	O
action	O
of	O
a	O
matrix	O
a	O
can	O
be	O
visualized	O
by	O
thinking	O
of	O
the	O
domain	O
as	O
being	O
spanned	O
by	O
a	O
set	O
of	O
orthonormal	O
vectors	O
vj	O
,	O
each	O
of	O
which	O
is	O
transformed	O
to	O
a	O
new	O
orthogonal	O
vector	O
uj	O
with	O
a	O
length	O
σj	O
.	O
when	O
a	O
is	O
interpreted	O
as	O
a	O
covariance	O
matrix	O
and	O
its	O
eigenvalue	O
decomposition	O
is	O
performed	O
,	O
each	O
of	O
the	O
uj	O
axes	O
denote	O
a	O
principal	O
direction	O
(	O
component	O
)	O
and	O
each	O
σj	O
denotes	O
one	O
standard	O
deviation	O
along	O
that	O
direction	O
.	O
(	O
the	O
eigenvector	O
matrix	O
u	O
is	O
sometimes	O
written	O
as	O
φ	O
and	O
the	O
eigenvectors	O
u	O
as	O
φ	O
.	O
)	O
in	O
this	O
case	O
,	O
the	O
eigenvalues	B
can	O
be	O
both	O
positive	O
and	O
negative.2	O
λ0	O
≥	O
λ1	O
≥	O
···	O
≥	O
λn−1	O
(	O
a.7	O
)	O
a	O
special	O
case	O
of	O
the	O
symmetric	O
matrix	O
c	O
occurs	O
when	O
it	O
is	O
constructed	O
as	O
the	O
sum	O
of	O
a	O
number	O
of	O
outer	O
products	O
aiat	O
i	O
=	O
aat	O
,	O
(	O
a.8	O
)	O
c	O
=	O
(	O
cid:88	O
)	O
i	O
which	O
often	O
occurs	O
when	O
solving	O
least	B
squares	I
problems	O
(	O
appendix	O
a.2	O
)	O
,	O
where	O
the	O
matrix	O
a	O
consists	O
of	O
all	O
the	O
ai	O
column	O
vectors	O
stacked	O
side-by-side	O
.	O
in	O
this	O
case	O
,	O
we	O
are	O
guaranteed	O
that	O
all	O
of	O
the	O
eigenvalues	B
λi	O
are	O
non-negative	O
.	O
the	O
associated	O
matrix	O
c	O
is	O
positive	O
semi-deﬁnite	O
xt	O
cx	O
≥	O
0	O
,	O
∀x	O
.	O
(	O
a.9	O
)	O
if	O
the	O
matrix	O
c	O
is	O
of	O
full	O
rank	O
,	O
the	O
eigenvalues	B
are	O
all	O
positive	O
and	O
the	O
matrix	O
is	O
called	O
sym-	O
metric	O
positive	O
deﬁnite	O
(	O
spd	O
)	O
.	O
symmetric	O
positive	O
semi-deﬁnite	O
matrices	O
also	O
arise	O
in	O
the	O
statistical	O
analysis	O
of	O
data	O
,	O
since	O
they	O
represent	O
the	O
covariance	O
of	O
a	O
set	O
of	O
{	O
xi	O
}	O
points	B
around	O
their	O
mean	O
¯x	O
,	O
c	O
=	O
(	O
xi	O
−	O
¯x	O
)	O
(	O
xi	O
−	O
¯x	O
)	O
t	O
.	O
1	O
n	O
(	O
cid:88	O
)	O
i	O
(	O
a.10	O
)	O
in	O
this	O
case	O
,	O
performing	O
the	O
eigenvalue	O
decomposition	O
is	O
known	O
as	O
principal	O
component	O
anal-	O
ysis	O
(	O
pca	O
)	O
,	O
since	O
it	O
models	O
the	O
principal	O
directions	O
(	O
and	O
magnitudes	O
)	O
of	O
variation	O
of	O
the	O
point	O
2	O
eigenvalue	O
decompositions	O
can	O
be	O
computed	O
for	O
non-symmetric	O
matrices	O
but	O
the	O
eigenvalues	B
and	O
eigenvectors	O
can	O
have	O
complex	O
entries	O
in	O
that	O
case	O
.	O
v0v1u0u1σ0σ1a	O
a.1	O
matrix	B
decompositions	I
739	O
distribution	O
around	O
their	O
mean	O
,	O
as	O
shown	O
in	O
section	O
5.1.1	O
(	O
5.13–5.15	O
)	O
,	O
section	O
14.2.1	O
(	O
14.9	O
)	O
,	O
and	O
appendix	O
b.1.1	O
(	O
b.10	O
)	O
.	O
figure	O
a.1	O
shows	O
how	O
the	O
principal	O
components	O
of	O
the	O
covari-	O
ance	O
matrix	O
c	O
denote	O
the	O
principal	O
axes	O
uj	O
of	O
the	O
uncertainty	B
ellipsoid	O
corresponding	O
to	O
this	O
point	O
distribution	O
and	O
how	O
the	O
σj	O
=	O
(	O
cid:112	O
)	O
λj	O
denote	O
the	O
standard	O
deviations	O
along	O
each	O
axis	O
.	O
the	O
eigenvalues	B
and	O
eigenvectors	O
of	O
c	O
and	O
the	O
singular	O
values	O
and	O
singular	O
vectors	O
of	O
a	O
are	O
closely	O
related	O
.	O
given	O
a	O
=	O
uσv	O
t	O
,	O
we	O
get	O
c	O
=	O
aat	O
=	O
uσv	O
t	O
v	O
σu	O
t	O
=	O
uλu	O
t	O
.	O
(	O
a.11	O
)	O
(	O
a.12	O
)	O
from	O
this	O
,	O
we	O
see	O
that	O
λi	O
=	O
σ2	O
c.	O
i	O
and	O
that	O
the	O
left	O
singular	O
vectors	O
of	O
a	O
are	O
the	O
eigenvectors	O
of	O
this	O
relationship	O
gives	O
us	O
an	O
efﬁcient	O
method	O
for	O
computing	O
the	O
eigenvalue	O
decomposi-	O
tion	B
of	O
large	O
matrices	O
that	O
are	O
rank	O
deﬁcient	O
,	O
such	O
as	O
the	O
scatter	O
matrices	O
observed	O
in	O
comput-	O
ing	O
eigenfaces	O
(	O
section	O
14.2.1	O
)	O
.	O
observe	O
that	O
the	O
covariance	O
matrix	O
c	O
in	O
(	O
14.9	O
)	O
is	O
exactly	O
the	O
same	O
as	O
c	O
in	O
(	O
a.8	O
)	O
.	O
note	O
also	O
that	O
the	O
individual	O
difference-from-mean	O
images	O
ai	O
=	O
xi	O
−	O
¯x	O
are	O
long	O
vectors	O
of	O
length	O
p	O
(	O
the	O
number	O
of	O
pixels	O
in	O
the	O
image	B
)	O
,	O
while	O
the	O
total	B
number	O
of	O
ex-	O
emplars	O
n	O
(	O
the	O
number	O
of	O
faces	B
in	O
the	O
training	O
database	O
)	O
is	O
much	O
smaller	O
.	O
instead	O
of	O
forming	O
c	O
=	O
aat	O
,	O
which	O
is	O
p	O
×	O
p	O
,	O
we	O
form	O
the	O
matrix	O
ˆc	O
=	O
at	O
a	O
,	O
(	O
a.13	O
)	O
which	O
is	O
n	O
×	O
n.	O
(	O
this	O
involves	O
taking	O
the	O
dot	O
product	O
between	O
every	O
pair	O
of	O
difference	B
images	O
ai	O
and	O
aj	O
.	O
)	O
the	O
eigenvalues	B
of	O
ˆc	O
are	O
the	O
squared	O
singular	O
values	O
of	O
a	O
,	O
namely	O
σ2	O
,	O
and	O
are	O
hence	O
also	O
the	O
eigenvalues	B
of	O
c.	O
the	O
eigenvectors	O
of	O
ˆc	O
are	O
the	O
right	O
singular	O
vectors	O
v	O
of	O
a	O
,	O
from	O
which	O
the	O
desired	O
eigenfaces	O
u	O
,	O
which	O
are	O
the	O
left	O
singular	O
vectors	O
of	O
a	O
,	O
can	O
be	O
computed	O
as	O
u	O
=	O
av	O
σ−1	O
.	O
(	O
a.14	O
)	O
this	O
ﬁnal	O
step	O
is	O
essentially	O
computing	O
the	O
eigenfaces	O
as	O
linear	B
combinations	O
of	O
the	O
difference	B
images	O
(	O
turk	O
and	O
pentland	O
1991a	O
)	O
.	O
if	O
you	O
have	O
access	O
to	O
a	O
high-quality	O
linear	B
algebra	O
pack-	O
age	O
such	O
as	O
lapack	O
,	O
routines	O
for	O
efﬁciently	O
computing	O
a	O
small	O
number	O
of	O
the	O
left	O
singular	O
vectors	O
and	O
singular	O
values	O
of	O
rectangular	O
matrices	O
such	O
as	O
a	O
are	O
usually	O
provided	O
(	O
ap-	O
pendix	O
c.2	O
)	O
.	O
however	O
,	O
if	O
storing	O
all	O
of	O
the	O
images	O
in	O
memory	O
is	O
prohibitive	O
,	O
the	O
construction	O
of	O
ˆc	O
in	O
(	O
a.13	O
)	O
can	O
be	O
used	O
instead	O
.	O
how	O
can	O
eigenvalue	O
and	O
singular	O
value	O
decompositions	O
actually	O
be	O
computed	O
?	O
notice	O
that	O
an	O
eigenvector	O
is	O
deﬁned	O
by	O
the	O
equation	B
λiui	O
=	O
cui	O
or	O
(	O
λii	O
−	O
c	O
)	O
ui	O
=	O
0	O
.	O
(	O
a.15	O
)	O
740	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
this	O
can	O
be	O
derived	O
from	O
(	O
a.6	O
)	O
by	O
post-multiplying	O
both	O
sides	O
by	O
ui	O
.	O
)	O
since	O
the	O
latter	O
equa-	O
tion	B
is	O
homogeneous	O
,	O
i.e.	O
,	O
it	O
has	O
a	O
zero	O
right-hand-side	O
,	O
it	O
can	O
only	O
have	O
a	O
non-zero	O
(	O
non-	O
trivial	O
)	O
solution	O
for	O
ui	O
if	O
the	O
system	O
is	O
rank	O
deﬁcient	O
,	O
i.e.	O
,	O
|	O
(	O
λi	O
−	O
c	O
)	O
|	O
=	O
0	O
.	O
(	O
a.16	O
)	O
evaluating	O
this	O
determinant	O
yields	O
a	O
characteristic	O
polynomial	O
equation	B
in	O
λ	O
,	O
which	O
can	O
be	O
solved	O
for	O
small	O
problems	O
,	O
e.g.	O
,	O
2	O
×	O
2	O
or	O
3	O
×	O
3	O
matrices	O
,	O
in	O
closed	O
form	O
.	O
for	O
larger	O
matrices	O
,	O
iterative	B
algorithms	O
that	O
ﬁrst	O
reduce	O
the	O
matrix	O
c	O
to	O
a	O
real	O
symmetric	O
tridiagonal	O
form	O
using	O
orthogonal	O
transforms	O
and	O
then	O
perform	O
qr	O
iterations	O
are	O
normally	O
used	O
(	O
golub	O
and	O
van	O
loan	O
1996	O
;	O
trefethen	O
and	O
bau	O
1997	O
;	O
bj¨orck	O
and	O
dahlquist	O
2010	O
)	O
.	O
since	O
these	O
techniques	O
are	O
rather	O
involved	O
,	O
it	O
is	O
best	O
to	O
use	O
a	O
linear	B
algebra	O
package	O
such	O
as	O
lapack	O
(	O
anderson	O
,	O
bai	O
,	O
bischof	O
et	O
al	O
.	O
1999	O
)	O
—see	O
appendix	O
c.2	O
.	O
factorization	B
with	O
missing	B
data	I
requires	O
different	O
kinds	O
of	O
iterative	B
algorithms	O
,	O
which	O
of-	O
ten	O
involve	O
either	O
hallucinating	O
the	O
missing	O
terms	O
or	O
minimizing	O
some	O
weighted	B
reconstruc-	O
tion	B
metric	O
,	O
which	O
is	O
intrinsically	O
much	O
more	O
challenging	O
than	O
regular	O
factorization	B
.	O
this	O
area	O
has	O
been	O
widely	O
studied	O
in	O
computer	O
vision	O
(	O
shum	O
,	O
ikeuchi	O
,	O
and	O
reddy	O
1995	O
;	O
de	O
la	O
torre	O
and	O
black	O
2003	O
;	O
huynh	O
,	O
hartley	O
,	O
and	O
heyden	O
2003	O
;	O
buchanan	O
and	O
fitzgibbon	O
2005	O
;	O
gross	O
,	O
matthews	O
,	O
and	O
baker	O
2006	O
;	O
torresani	O
,	O
hertzmann	O
,	O
and	O
bregler	O
2008	O
)	O
and	O
is	O
some-	O
times	O
called	O
generalized	B
pca	O
.	O
however	O
,	O
this	O
term	O
is	O
also	O
sometimes	O
used	O
to	O
denote	O
algebraic	O
subspace	O
clustering	O
techniques	O
,	O
which	O
is	O
the	O
subject	O
of	O
a	O
forthcoming	O
monograph	O
by	O
vidal	O
,	O
ma	O
,	O
and	O
sastry	O
(	O
2010	O
)	O
.	O
a.1.3	O
qr	O
factorization	B
a	O
widely	O
used	O
technique	O
for	O
stably	O
solving	O
poorly	O
conditioned	O
least	B
squares	I
problems	O
(	O
bj¨orck	O
1996	O
)	O
and	O
as	O
the	O
basis	O
of	O
more	O
complex	O
algorithms	O
,	O
such	O
as	O
computing	O
the	O
svd	O
and	O
eigen-	O
value	O
decompositions	O
,	O
is	O
the	O
qr	O
factorization	B
,	O
a	O
=	O
qr	O
,	O
(	O
a.17	O
)	O
where	O
q	O
is	O
an	O
orthonormal	O
(	O
or	O
unitary	O
)	O
matrix	O
qqt	O
=	O
i	O
and	O
r	O
is	O
upper	O
triangular.3	O
in	O
computer	O
vision	O
,	O
qr	O
can	O
be	O
used	O
to	O
convert	O
a	O
camera	B
matrix	O
into	O
a	O
rotation	O
matrix	O
and	O
an	O
upper-triangular	O
calibration	B
matrix	I
(	O
6.35	O
)	O
and	O
also	O
in	O
various	O
self-calibration	B
algorithms	O
(	O
section	O
7.2.2	O
)	O
.	O
the	O
most	O
common	O
algorithms	O
for	O
computing	O
qr	O
decompositions	O
,	O
modiﬁed	O
gram–schmidt	O
,	O
householder	O
transformations	O
,	O
and	O
givens	O
rotations	O
,	O
are	O
described	O
by	O
golub	O
and	O
van	O
loan	O
(	O
1996	O
)	O
,	O
trefethen	O
and	O
bau	O
(	O
1997	O
)	O
,	O
and	O
bj¨orck	O
and	O
dahlquist	O
(	O
2010	O
)	O
and	O
are	O
3	O
the	O
term	O
“	O
r	O
”	O
comes	O
from	O
the	O
german	O
name	O
for	O
the	O
lower–upper	O
(	O
lu	O
)	O
decomposition	O
,	O
which	O
is	O
lr	O
for	O
“	O
links	O
”	O
and	O
“	O
rechts	O
”	O
(	O
left	O
and	O
right	O
of	O
the	O
diagonal	O
)	O
.	O
a.1	O
matrix	B
decompositions	I
741	O
procedure	O
cholesky	O
(	O
c	O
,	O
r	O
)	O
:	O
r	O
=	O
c	O
for	O
i	O
=	O
0	O
.	O
.	O
.	O
n	O
−	O
1	O
for	O
j	O
=	O
i	O
+	O
1	O
.	O
.	O
.	O
n	O
−	O
1	O
rj	O
,	O
j	O
:	O
n−1	O
=	O
rj	O
,	O
j	O
:	O
n−1	O
−	O
rijr−1	O
ii	O
ri	O
,	O
j	O
:	O
n−1	O
ri	O
,	O
i	O
:	O
n−1	O
=	O
r−1/2	O
ii	O
ri	O
,	O
i	O
:	O
n−1	O
algorithm	B
a.1	O
cholesky	O
decomposition	O
of	O
the	O
matrix	O
c	O
into	O
its	O
upper	O
triangular	O
form	O
r.	O
also	O
found	O
in	O
lapack	O
.	O
unlike	O
the	O
svd	O
and	O
eigenvalue	O
decompositions	O
,	O
qr	O
factorization	B
does	O
not	O
require	O
iteration	O
and	O
can	O
be	O
computed	O
exactly	O
in	O
o	O
(	O
m	O
n	O
2	O
+	O
n	O
3	O
)	O
operations	O
,	O
where	O
m	O
is	O
the	O
number	O
of	O
rows	O
and	O
n	O
is	O
the	O
number	O
of	O
columns	O
(	O
for	O
a	O
tall	O
matrix	O
)	O
.	O
a.1.4	O
cholesky	O
factorization	B
cholesky	O
factorization	B
can	O
be	O
applied	O
to	O
any	O
symmetric	O
positive	O
deﬁnite	O
matrix	O
c	O
to	O
convert	O
it	O
into	O
a	O
product	O
of	O
symmetric	O
lower	O
and	O
upper	O
triangular	O
matrices	O
,	O
c	O
=	O
llt	O
=	O
rt	O
r	O
,	O
(	O
a.18	O
)	O
where	O
l	O
is	O
a	O
lower-triangular	O
matrix	O
and	O
r	O
is	O
an	O
upper-triangular	O
matrix	O
.	O
unlike	O
gaussian	O
elimination	O
,	O
which	O
may	O
require	O
pivoting	O
(	O
row	O
and	O
column	O
reordering	O
)	O
or	O
may	O
become	O
un-	O
stable	O
(	O
sensitive	O
to	O
roundoff	O
errors	O
or	O
reordering	O
)	O
,	O
cholesky	O
factorization	B
remains	O
stable	O
for	O
positive	O
deﬁnite	O
matrices	O
,	O
such	O
as	O
those	O
that	O
arise	O
from	O
normal	O
equations	O
in	O
least	B
squares	I
prob-	O
lems	O
(	O
appendix	O
a.2	O
)	O
.	O
because	O
of	O
the	O
form	O
of	O
(	O
a.18	O
)	O
,	O
the	O
matrices	O
l	O
and	O
r	O
are	O
sometimes	O
called	O
matrix	O
square	O
roots.4	O
the	O
algorithm	B
to	O
compute	O
an	O
upper	O
triangular	O
cholesky	O
decomposition	O
of	O
c	O
is	O
a	O
straight-	O
forward	B
symmetric	O
generalization	O
of	O
gaussian	O
elimination	O
and	O
is	O
based	O
on	O
the	O
decomposition	O
(	O
bj¨orck	O
1996	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
)	O
ct	O
c	O
c11	O
(	O
cid:35	O
)	O
c	O
=	O
(	O
cid:34	O
)	O
γ	O
=	O
(	O
cid:34	O
)	O
γ1/2	O
cγ−1/2	O
0t	O
i	O
(	O
cid:35	O
)	O
(	O
cid:34	O
)	O
1	O
0	O
c11	O
−	O
cγ−1ct	O
(	O
cid:35	O
)	O
(	O
cid:34	O
)	O
γ1/2	O
0t	O
0	O
(	O
a.19	O
)	O
(	O
cid:35	O
)	O
(	O
a.20	O
)	O
γ−1/2ct	O
i	O
4	O
in	O
fact	O
,	O
there	O
exists	O
a	O
whole	O
family	O
of	O
matrix	O
square	O
roots	O
.	O
any	O
matrix	O
of	O
the	O
form	O
lq	O
or	O
qr	O
,	O
where	O
q	O
is	O
a	O
unitary	O
matrix	O
,	O
is	O
a	O
square	B
root	I
of	O
c.	O
742	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
=	O
rt	O
0	O
c1r0	O
,	O
which	O
,	O
through	O
recursion	O
,	O
can	O
be	O
turned	O
into	O
c	O
=	O
rt	O
0	O
.	O
.	O
.	O
rt	O
n−1rn−1	O
.	O
.	O
.	O
r0	O
=	O
rt	O
r.	O
(	O
a.21	O
)	O
(	O
a.22	O
)	O
algorithm	B
a.1	O
provides	O
a	O
more	O
procedural	O
deﬁnition	O
,	O
which	O
can	O
store	O
the	O
upper-triangular	O
matrix	O
r	O
in	O
the	O
same	O
space	O
as	O
c	O
,	O
if	O
desired	O
.	O
the	O
total	B
operation	O
count	O
for	O
cholesky	O
factor-	O
ization	O
is	O
o	O
(	O
n	O
3	O
)	O
for	O
a	O
dense	O
matrix	O
but	O
can	O
be	O
signiﬁcantly	O
lower	O
for	O
sparse	O
matrices	O
with	O
low	O
ﬁll-in	O
(	O
appendix	O
a.4	O
)	O
.	O
note	O
that	O
cholesky	O
decomposition	O
can	O
also	O
be	O
applied	O
to	O
block-structured	O
matrices	O
,	O
where	O
the	O
term	O
γ	O
in	O
(	O
a.19	O
)	O
is	O
now	O
a	O
square	O
block	O
sub-matrix	O
and	O
c	O
is	O
a	O
rectangular	O
matrix	O
(	O
golub	O
and	O
van	O
loan	O
1996	O
)	O
.	O
the	O
computation	O
of	O
square	O
roots	O
can	O
be	O
avoided	O
by	O
leaving	O
the	O
γ	O
on	O
the	O
diagonal	O
of	O
the	O
middle	O
factor	O
in	O
(	O
a.20	O
)	O
,	O
which	O
results	O
in	O
the	O
c	O
=	O
ldlt	O
factorization	B
,	O
where	O
d	O
is	O
a	O
diagonal	O
matrix	O
.	O
however	O
,	O
since	O
square	O
roots	O
are	O
relatively	O
fast	O
on	O
modern	O
computers	O
,	O
this	O
is	O
not	O
worth	O
the	O
bother	O
and	O
cholesky	O
factorization	B
is	O
usually	O
preferred	O
.	O
a.2	O
linear	B
least	O
squares	O
least	B
squares	I
ﬁtting	O
problems	O
are	O
pervasive	O
in	O
computer	O
vision	O
.	O
for	O
example	O
,	O
the	O
alignment	B
of	O
images	O
based	O
on	O
matching	B
feature	O
points	B
involves	O
the	O
minimization	O
of	O
a	O
squared	O
distance	O
objective	O
function	O
(	O
6.2	O
)	O
,	O
where	O
els	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
2	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
f	O
(	O
xi	O
;	O
p	O
)	O
−	O
x	O
(	O
cid:48	O
)	O
i	O
(	O
cid:107	O
)	O
2	O
,	O
ri	O
=	O
f	O
(	O
xi	O
;	O
p	O
)	O
−	O
x	O
(	O
cid:48	O
)	O
i	O
=	O
ˆx	O
(	O
cid:48	O
)	O
i	O
−	O
˜x	O
(	O
cid:48	O
)	O
i	O
(	O
a.23	O
)	O
(	O
a.24	O
)	O
is	O
the	O
residual	O
between	O
the	O
measured	O
location	O
ˆx	O
(	O
cid:48	O
)	O
i	O
and	O
its	O
corresponding	O
current	O
predicted	O
lo-	O
cation	O
˜x	O
(	O
cid:48	O
)	O
i	O
=	O
f	O
(	O
xi	O
;	O
p	O
)	O
.	O
more	O
complex	O
versions	O
of	O
least	B
squares	I
problems	O
,	O
such	O
as	O
large-scale	O
structure	B
from	I
motion	I
(	O
section	O
7.4	O
)	O
,	O
may	O
involve	O
the	O
minimization	O
of	O
functions	O
of	O
thousands	O
of	O
variables	O
.	O
even	O
problems	O
such	O
as	O
image	B
ﬁltering	O
(	O
section	O
3.4.3	O
)	O
and	O
regularization	B
(	O
sec-	O
tion	B
3.7.1	O
)	O
may	O
involve	O
the	O
minimization	O
of	O
sums	O
of	O
squared	O
errors	O
.	O
figure	O
a.2a	O
shows	O
an	O
example	O
of	O
a	O
simple	O
least	B
squares	I
line	O
ﬁtting	O
problem	O
,	O
where	O
the	O
quantities	O
being	O
estimated	O
are	O
the	O
line	O
equation	O
parameters	B
(	O
m	O
,	O
b	O
)	O
.	O
when	O
the	O
sampled	O
vertical	O
values	O
yi	O
are	O
assumed	O
to	O
be	O
noisy	O
versions	O
of	O
points	B
on	O
the	O
line	O
y	O
=	O
mx	O
+	O
b	O
,	O
the	O
optimal	O
estimates	O
for	O
(	O
m	O
,	O
b	O
)	O
can	O
be	O
found	O
by	O
minimizing	O
the	O
squared	O
vertical	O
residuals	O
evls	O
=	O
(	O
cid:88	O
)	O
i	O
|yi	O
−	O
(	O
mxi	O
+	O
b	O
)	O
|2	O
.	O
(	O
a.25	O
)	O
a.2	O
linear	B
least	O
squares	O
743	O
note	O
that	O
the	O
function	O
being	O
ﬁtted	O
need	O
not	O
itself	O
be	O
linear	B
to	O
use	O
linear	B
least	O
squares	O
.	O
all	O
that	O
is	O
required	O
is	O
that	O
the	O
function	O
be	O
linear	B
in	O
the	O
unknown	O
parameters	B
.	O
for	O
example	O
,	O
polynomial	O
ﬁtting	O
can	O
be	O
written	O
as	O
epls	O
=	O
(	O
cid:88	O
)	O
i	O
p	O
(	O
cid:88	O
)	O
j=0	O
|yi	O
−	O
(	O
ajxj	O
i	O
)	O
|2	O
,	O
(	O
a.26	O
)	O
while	O
sinusoid	O
ﬁtting	O
with	O
unknown	O
amplitude	O
a	O
and	O
phase	O
φ	O
(	O
but	O
known	O
frequency	O
f	O
)	O
can	O
be	O
written	O
as	O
esls	O
=	O
(	O
cid:88	O
)	O
i	O
|yi	O
−	O
a	O
sin	O
(	O
2πf	O
xi	O
+	O
φ	O
)	O
|2	O
=	O
(	O
cid:88	O
)	O
i	O
which	O
is	O
linear	B
in	O
(	O
b	O
,	O
c	O
)	O
.	O
|yi	O
−	O
(	O
b	O
sin	O
2πf	O
xi	O
+	O
c	O
cos	O
2πf	O
xi	O
)	O
|2	O
,	O
(	O
a.27	O
)	O
in	O
general	O
,	O
it	O
is	O
more	O
common	O
to	O
denote	O
the	O
unknown	O
parameters	B
using	O
x	O
and	O
to	O
write	O
the	O
general	O
form	O
of	O
linear	B
least	O
squares	O
as5	O
ells	O
=	O
(	O
cid:88	O
)	O
i	O
expanding	O
the	O
above	O
equation	B
gives	O
us	O
|aix	O
−	O
bi|2	O
=	O
(	O
cid:107	O
)	O
ax	O
−	O
b	O
(	O
cid:107	O
)	O
2.	O
ells	O
=	O
xt	O
(	O
at	O
a	O
)	O
x	O
−	O
2xt	O
(	O
at	O
b	O
)	O
+	O
(	O
cid:107	O
)	O
b	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
a.28	O
)	O
(	O
a.29	O
)	O
whose	O
minimum	O
value	O
for	O
x	O
can	O
be	O
found	O
by	O
solving	O
the	O
associated	O
normal	O
equations	O
(	O
bj¨orck	O
1996	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
)	O
(	O
at	O
a	O
)	O
x	O
=	O
at	O
b	O
.	O
(	O
a.30	O
)	O
the	O
preferred	O
way	O
to	O
solve	O
the	O
normal	O
equations	O
is	O
to	O
use	O
cholesky	O
factorization	B
.	O
let	O
where	O
r	O
is	O
the	O
upper-triangular	O
cholesky	O
factor	O
of	O
the	O
hessian	O
c	O
,	O
and	O
c	O
=	O
at	O
a	O
=	O
rt	O
r	O
,	O
d	O
=	O
at	O
b.	O
after	O
factorization	B
,	O
the	O
solution	O
for	O
x	O
can	O
be	O
obtained	O
as	O
rt	O
z	O
=	O
d	O
,	O
rx	O
=	O
z	O
,	O
(	O
a.31	O
)	O
(	O
a.32	O
)	O
(	O
a.33	O
)	O
which	O
involves	O
the	O
solution	O
of	O
two	O
triangular	O
systems	O
,	O
i.e.	O
,	O
forward	B
and	O
backward	O
substitution	O
(	O
bj¨orck	O
1996	O
)	O
.	O
5	O
be	O
extra	O
careful	O
in	O
interpreting	O
the	O
variable	O
names	O
here	O
.	O
in	O
the	O
2d	O
line-ﬁtting	O
example	O
,	O
x	O
is	O
used	O
to	O
denote	O
the	O
horizontal	O
axis	O
,	O
but	O
in	O
the	O
general	O
least	B
squares	I
problem	O
,	O
x	O
=	O
(	O
m	O
,	O
b	O
)	O
denotes	O
the	O
unknown	O
parameter	O
vector	O
.	O
744	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
a.2	O
least	B
squares	I
regression	O
.	O
(	O
a	O
)	O
the	O
line	O
y	O
=	O
mx	O
+	O
b	O
is	O
ﬁt	O
to	O
the	O
four	O
noisy	O
data	O
points	O
,	O
{	O
(	O
xi	O
,	O
yi	O
)	O
}	O
,	O
denoted	O
by	O
×	O
by	O
minimizing	O
the	O
squared	O
vertical	O
residuals	O
between	O
the	O
data	O
points	O
and	O
the	O
line	O
,	O
(	O
cid:80	O
)	O
i	O
(	O
cid:107	O
)	O
yi	O
−	O
(	O
mxi	O
+	O
b	O
)	O
(	O
cid:107	O
)	O
2	O
.	O
(	O
b	O
)	O
when	O
the	O
measurements	O
{	O
(	O
xi	O
,	O
yi	O
)	O
}	O
are	O
assumed	O
to	O
have	O
noise	B
in	O
all	O
directions	O
,	O
the	O
sum	O
of	O
orthogonal	O
squared	O
distances	O
to	O
the	O
line	O
(	O
cid:80	O
)	O
i	O
(	O
cid:107	O
)	O
axi	O
+	O
byi	O
+	O
c	O
(	O
cid:107	O
)	O
2	O
is	O
minimized	O
using	O
total	O
least	B
squares	I
.	O
in	O
cases	O
where	O
the	O
least	B
squares	I
problem	O
is	O
numerically	O
poorly	O
conditioned	O
(	O
which	O
should	O
generally	O
be	O
avoided	O
by	O
adding	O
sufﬁcient	O
regularization	B
or	O
prior	B
knowledge	O
about	O
the	O
param-	O
eters	O
,	O
(	O
appendix	O
a.3	O
)	O
)	O
,	O
it	O
is	O
possible	O
to	O
use	O
qr	O
factorization	B
or	O
svd	O
directly	O
on	O
the	O
matrix	O
a	O
(	O
bj¨orck	O
1996	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
;	O
trefethen	O
and	O
bau	O
1997	O
;	O
nocedal	O
and	O
wright	O
2006	O
;	O
bj¨orck	O
and	O
dahlquist	O
2010	O
)	O
,	O
e.g.	O
,	O
ax	O
=	O
qrx	O
=	O
b	O
−→	O
rx	O
=	O
qt	O
b	O
.	O
(	O
a.34	O
)	O
note	O
that	O
the	O
upper	O
triangular	O
matrices	O
r	O
produced	O
by	O
the	O
cholesky	O
factorization	B
of	O
c	O
=	O
at	O
a	O
and	O
the	O
qr	O
factorization	B
of	O
a	O
are	O
the	O
same	O
,	O
but	O
that	O
solving	O
(	O
a.34	O
)	O
is	O
generally	O
more	O
stable	O
(	O
less	O
sensitive	O
to	O
roundoff	O
error	O
)	O
but	O
slower	O
(	O
by	O
a	O
constant	O
factor	O
)	O
.	O
a.2.1	O
total	B
least	O
squares	O
in	O
some	O
problems	O
,	O
e.g.	O
,	O
when	O
performing	O
geometric	B
line	O
ﬁtting	O
in	O
2d	O
images	O
or	O
3d	O
plane	O
ﬁtting	O
to	O
point	O
cloud	O
data	O
,	O
instead	O
of	O
having	O
measurement	O
error	O
along	O
one	O
particular	O
axis	O
,	O
the	O
measured	O
points	B
have	O
uncertainty	B
in	O
all	O
directions	O
,	O
which	O
is	O
known	O
as	O
the	O
errors-in-variables	O
model	O
(	O
van	O
huffel	O
and	O
lemmerling	O
2002	O
;	O
matei	O
and	O
meer	O
2006	O
)	O
.	O
in	O
this	O
case	O
,	O
it	O
makes	O
more	O
sense	O
to	O
minimize	O
a	O
set	O
of	O
homogeneous	O
squared	O
errors	O
of	O
the	O
form	O
etls	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
aix	O
)	O
2	O
=	O
(	O
cid:107	O
)	O
ax	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
a.35	O
)	O
which	O
is	O
known	O
as	O
total	B
least	O
squares	O
(	O
tls	O
)	O
(	O
van	O
huffel	O
and	O
vandewalle	O
1991	O
;	O
bj¨orck	O
1996	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
;	O
van	O
huffel	O
and	O
lemmerling	O
2002	O
)	O
.	O
xybmy=mx+b××××xyax+by+c=0××××	O
a.2	O
linear	B
least	O
squares	O
745	O
the	O
above	O
error	O
metric	O
has	O
a	O
trivial	O
minimum	O
solution	O
at	O
x	O
=	O
0	O
and	O
is	O
,	O
in	O
fact	O
,	O
homoge-	O
neous	O
in	O
x.	O
for	O
this	O
reason	O
,	O
we	O
augment	O
this	O
minimization	O
problem	O
with	O
the	O
requirement	O
that	O
(	O
cid:107	O
)	O
x	O
(	O
cid:107	O
)	O
2	O
=	O
1.	O
which	O
results	O
in	O
the	O
eigenvalue	O
problem	O
x	O
=	O
arg	O
min	O
x	O
xt	O
(	O
at	O
a	O
)	O
x	O
such	O
that	O
(	O
cid:107	O
)	O
x	O
(	O
cid:107	O
)	O
2	O
=	O
1	O
.	O
(	O
a.36	O
)	O
the	O
value	O
of	O
x	O
that	O
minimizes	O
this	O
constrained	B
problem	O
is	O
the	O
eigenvector	O
associated	O
with	O
the	O
smallest	O
eigenvalue	O
of	O
at	O
a.	O
this	O
is	O
the	O
same	O
as	O
the	O
last	O
right	O
singular	O
vector	O
of	O
a	O
,	O
since	O
a	O
=	O
uσv	O
,	O
at	O
a	O
=	O
v	O
σ2v	O
,	O
at	O
avk	O
=	O
σ2	O
k	O
,	O
(	O
a.37	O
)	O
(	O
a.38	O
)	O
(	O
a.39	O
)	O
which	O
is	O
minimized	O
by	O
selecting	O
the	O
smallest	O
σk	O
value	O
.	O
figure	O
a.2b	O
shows	O
a	O
line	O
ﬁtting	O
problem	O
where	O
,	O
in	O
this	O
case	O
,	O
the	O
measurement	O
errors	O
are	O
assumed	O
to	O
be	O
isotropic	B
in	O
(	O
x	O
,	O
y	O
)	O
.	O
the	O
solution	O
for	O
the	O
best	O
line	O
equation	O
ax	O
+	O
by	O
+	O
c	O
=	O
0	O
is	O
found	O
by	O
minimizing	O
i.e.	O
,	O
ﬁnding	O
the	O
eigenvector	O
associated	O
with	O
the	O
smallest	O
eigenvalue	O
of6	O
(	O
a.40	O
)	O
(	O
a.41	O
)	O
etls−2d	O
=	O
(	O
cid:88	O
)	O
i	O
	O
c	O
=	O
at	O
a	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
axi	O
+	O
byi	O
+	O
c	O
)	O
2	O
,	O
xi	O
yi	O
1	O
	O
(	O
cid:104	O
)	O
xi	O
yi	O
1	O
(	O
cid:105	O
)	O
.	O
notice	O
,	O
however	O
,	O
that	O
minimizing	O
(	O
cid:80	O
)	O
i	O
(	O
aix	O
)	O
2	O
in	O
(	O
a.35	O
)	O
is	O
only	O
statistically	O
optimal	O
(	O
ap-	O
pendix	O
b.1.1	O
)	O
if	O
all	O
of	O
the	O
measured	O
terms	O
in	O
the	O
ai	O
,	O
e.g.	O
,	O
the	O
(	O
xi	O
,	O
yi	O
,	O
1	O
)	O
measurements	O
,	O
have	O
equal	O
noise	B
.	O
this	O
is	O
deﬁnitely	O
not	O
the	O
case	O
in	O
the	O
line-ﬁtting	O
example	O
of	O
figure	O
a.2b	O
(	O
a.40	O
)	O
,	O
since	O
the	O
1	O
values	O
are	O
noise-free	O
.	O
to	O
mitigate	O
this	O
,	O
we	O
ﬁrst	O
subtract	O
the	O
mean	O
x	O
and	O
y	O
values	O
from	O
all	O
the	O
measured	O
points	B
ˆxi	O
=	O
xi	O
−	O
¯x	O
ˆyi	O
=	O
yi	O
−	O
¯y	O
and	O
then	O
ﬁt	O
the	O
2d	O
line	O
equation	O
a	O
(	O
x	O
−	O
¯x	O
)	O
+	O
b	O
(	O
y	O
−	O
¯y	O
)	O
=	O
0	O
by	O
minimizing	O
etls−2dm	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
aˆxi	O
+	O
bˆyi	O
)	O
2	O
.	O
(	O
a.42	O
)	O
(	O
a.43	O
)	O
(	O
a.44	O
)	O
6	O
again	O
,	O
be	O
careful	O
with	O
the	O
variable	O
names	O
here	O
.	O
the	O
measurement	O
equation	B
is	O
ai	O
=	O
(	O
xi	O
,	O
yi	O
,	O
1	O
)	O
and	O
the	O
unknown	O
parameters	B
are	O
x	O
=	O
(	O
a	O
,	O
b	O
,	O
c	O
)	O
.	O
746	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
the	O
more	O
general	O
case	O
where	O
each	O
individual	O
measurement	O
component	O
can	O
have	O
different	O
noise	B
level	O
,	O
as	O
is	O
the	O
case	O
in	O
estimating	O
essential	O
and	O
fundamental	O
matrices	O
(	O
section	O
7.2	O
)	O
,	O
is	O
called	O
the	O
heteroscedastic	B
errors-in-variable	O
(	O
heiv	O
)	O
model	O
and	O
is	O
discussed	O
by	O
matei	O
and	O
meer	O
(	O
2006	O
)	O
.	O
a.3	O
non-linear	B
least	O
squares	O
in	O
many	O
vision	O
problems	O
,	O
such	O
as	O
structure	B
from	I
motion	I
,	O
the	O
least	B
squares	I
problem	O
formulated	O
in	O
(	O
a.23	O
)	O
involves	O
functions	O
f	O
(	O
xi	O
;	O
p	O
)	O
that	O
are	O
not	O
linear	B
in	O
the	O
unknown	O
parameters	B
p.	O
this	O
problem	O
is	O
known	O
as	O
non-linear	B
least	O
squares	O
or	O
non-linear	B
regression	O
(	O
bj¨orck	O
1996	O
;	O
madsen	O
,	O
nielsen	O
,	O
and	O
tingleff	O
2004	O
;	O
nocedal	O
and	O
wright	O
2006	O
)	O
.	O
it	O
is	O
usually	O
solved	O
by	O
iteratively	O
re-	O
linearizing	O
(	O
a.23	O
)	O
around	O
the	O
current	O
estimate	O
of	O
p	O
using	O
the	O
gradient	O
derivative	O
(	O
jacobian	O
)	O
j	O
=	O
∂f	O
/∂p	O
and	O
computing	O
an	O
incremental	B
improvement	O
∆p	O
.	O
as	O
shown	O
in	O
equations	B
(	O
6.13–6.17	O
)	O
,	O
this	O
results	O
in	O
enls	O
(	O
∆p	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
≈	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
f	O
(	O
xi	O
;	O
p	O
+	O
∆p	O
)	O
−	O
x	O
(	O
cid:48	O
)	O
i	O
(	O
cid:107	O
)	O
2	O
(	O
cid:107	O
)	O
j	O
(	O
xi	O
;	O
p	O
)	O
∆p	O
−	O
ri	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
a.45	O
)	O
(	O
a.46	O
)	O
where	O
the	O
jacobians	O
j	O
(	O
xi	O
;	O
p	O
)	O
and	O
residual	O
vectors	O
ri	O
play	O
the	O
same	O
role	O
in	O
forming	O
the	O
normal	O
equations	O
as	O
ai	O
and	O
bi	O
in	O
(	O
a.28	O
)	O
.	O
because	O
the	O
above	O
approximation	O
only	O
holds	O
near	O
a	O
local	B
minimum	O
or	O
for	O
small	O
values	O
of	O
∆p	O
,	O
the	O
update	O
p	O
←	O
p	O
+	O
∆p	O
may	O
not	O
always	O
decrease	O
the	O
summed	O
square	O
residual	O
error	O
(	O
a.45	O
)	O
.	O
one	O
way	O
to	O
mitigate	O
this	O
problem	O
is	O
to	O
take	O
a	O
smaller	O
step	O
,	O
p	O
←	O
p	O
+	O
α∆p	O
,	O
0	O
<	O
α	O
≤	O
1	O
.	O
(	O
a.47	O
)	O
a	O
simple	O
way	O
to	O
determine	O
a	O
reasonable	O
value	O
of	O
α	O
is	O
to	O
start	O
with	O
1	O
and	O
successively	O
halve	O
the	O
value	O
,	O
which	O
is	O
a	O
simple	O
form	O
of	O
line	O
search	O
(	O
al-baali	O
and	O
fletcher	O
.	O
1986	O
;	O
bj¨orck	O
1996	O
;	O
nocedal	O
and	O
wright	O
2006	O
)	O
.	O
another	O
approach	O
to	O
ensuring	O
a	O
downhill	O
step	O
in	O
error	O
is	O
to	O
add	O
a	O
diagonal	O
damping	O
term	O
to	O
the	O
approximate	O
hessian	O
i.e.	O
,	O
to	O
solve	O
where	O
c	O
=	O
(	O
cid:88	O
)	O
i	O
j	O
t	O
(	O
xi	O
)	O
j	O
(	O
xi	O
)	O
,	O
[	O
c	O
+	O
λ	O
diag	O
(	O
c	O
)	O
]	O
∆p	O
=	O
d	O
,	O
d	O
=	O
(	O
cid:88	O
)	O
i	O
j	O
t	O
(	O
xi	O
)	O
ri	O
,	O
(	O
a.48	O
)	O
(	O
a.49	O
)	O
(	O
a.50	O
)	O
a.4	O
direct	B
sparse	O
matrix	O
techniques	O
747	O
which	O
is	O
called	O
a	O
damped	O
gauss–newton	O
method	O
.	O
the	O
damping	O
parameter	O
λ	O
is	O
increased	O
if	O
the	O
squared	O
residual	O
is	O
not	O
decreasing	O
as	O
fast	O
as	O
expected	O
,	O
i.e.	O
,	O
as	O
predicted	O
by	O
(	O
a.46	O
)	O
,	O
and	O
is	O
decreased	O
if	O
the	O
expected	O
decrease	O
is	O
obtained	O
(	O
madsen	O
,	O
nielsen	O
,	O
and	O
tingleff	O
2004	O
)	O
.	O
the	O
combination	O
of	O
the	O
newton	O
(	O
ﬁrst-order	O
taylor	O
series	O
)	O
approximation	O
(	O
a.46	O
)	O
and	O
the	O
adaptive	B
damping	O
parameter	O
λ	O
is	O
commonly	O
known	O
as	O
the	O
levenberg–marquardt	O
algorithm	B
(	O
leven-	O
berg	O
1944	O
;	O
marquardt	O
1963	O
)	O
and	O
is	O
an	O
example	O
of	O
more	O
general	O
trust	O
region	B
methods	O
,	O
which	O
are	O
discussed	O
in	O
more	O
detail	O
in	O
(	O
bj¨orck	O
1996	O
;	O
conn	O
,	O
gould	O
,	O
and	O
toint	O
2000	O
;	O
madsen	O
,	O
nielsen	O
,	O
and	O
tingleff	O
2004	O
;	O
nocedal	O
and	O
wright	O
2006	O
)	O
.	O
when	O
the	O
initial	O
solution	O
is	O
far	O
away	O
from	O
its	O
quadratic	O
region	B
of	O
convergence	O
around	O
a	O
local	B
minimum	O
,	O
large	O
residual	O
methods	O
,	O
e.g.	O
,	O
newton-type	O
methods	O
,	O
which	O
add	O
a	O
second-order	O
term	O
to	O
the	O
taylor	O
series	O
expansion	O
in	O
(	O
a.46	O
)	O
,	O
may	O
converge	O
faster	O
.	O
quasi-newton	O
methods	O
such	O
as	O
bfgs	O
,	O
which	O
require	O
only	O
gradient	O
evaluations	O
,	O
can	O
also	O
be	O
useful	O
if	O
memory	O
size	O
is	O
an	O
issue	O
.	O
such	O
techniques	O
are	O
discussed	O
in	O
textbooks	B
and	O
papers	O
on	O
numerical	O
optimization	O
(	O
toint	O
1987	O
;	O
bj¨orck	O
1996	O
;	O
conn	O
,	O
gould	O
,	O
and	O
toint	O
2000	O
;	O
nocedal	O
and	O
wright	O
2006	O
)	O
.	O
a.4	O
direct	B
sparse	O
matrix	O
techniques	O
many	O
optimization	O
problems	O
in	O
computer	O
vision	O
,	O
such	O
as	O
bundle	B
adjustment	I
(	O
szeliski	O
and	O
kang	O
1994	O
;	O
triggs	O
,	O
mclauchlan	O
,	O
hartley	O
et	O
al	O
.	O
1999	O
;	O
hartley	O
and	O
zisserman	O
2004	O
;	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2008b	O
;	O
agarwal	O
,	O
snavely	O
,	O
simon	O
et	O
al	O
.	O
2009	O
)	O
have	O
jacobian	O
and	O
(	O
approx-	O
imate	O
)	O
hessian	O
matrices	O
that	O
are	O
extremely	O
sparse	B
(	O
section	O
7.4.1	O
)	O
.	O
for	O
example	O
,	O
figure	O
7.9a	O
shows	O
the	O
bipartite	O
model	O
typical	O
of	O
structure	B
from	I
motion	I
problems	O
,	O
in	O
which	O
most	O
points	B
are	O
only	O
observed	O
by	O
a	O
subset	O
of	O
the	O
cameras	O
,	O
which	O
results	O
in	O
the	O
sparsity	O
patterns	B
for	O
the	O
jacobian	O
and	O
hessian	O
shown	O
in	O
figure	O
7.9b–c	O
.	O
whenever	O
the	O
hessian	O
matrix	O
is	O
sparse	B
enough	O
,	O
it	O
is	O
more	O
efﬁcient	O
to	O
use	O
sparse	B
cholesky	O
factorization	B
instead	O
of	O
regular	O
cholesky	O
factorization	B
.	O
in	O
such	O
sparse	B
direct	O
techniques	O
,	O
the	O
hessian	O
matrix	O
c	O
and	O
its	O
associated	O
cholesky	O
factor	O
r	O
are	O
stored	O
in	O
compressed	O
form	O
,	O
in	O
which	O
the	O
amount	O
of	O
storage	O
is	O
proportional	O
to	O
the	O
number	O
of	O
(	O
potentially	O
)	O
non-zero	O
entries	O
(	O
bj¨orck	O
1996	O
;	O
davis	O
2006	O
)	O
.7	O
algorithms	O
for	O
computing	O
the	O
non-zero	O
elements	O
in	O
c	O
and	O
r	O
from	O
the	O
sparsity	O
pattern	O
of	O
the	O
jacobian	O
matrix	O
j	O
are	O
given	O
by	O
bj¨orck	O
(	O
1996	O
,	O
section	O
6.4	O
)	O
,	O
and	O
algorithms	O
for	O
computing	O
the	O
numerical	O
cholesky	O
and	O
qr	O
decompositions	O
(	O
once	O
the	O
sparsity	O
pattern	O
has	O
been	O
computed	O
and	O
storage	O
allocated	O
)	O
are	O
discussed	O
by	O
bj¨orck	O
(	O
1996	O
,	O
section	O
6.5	O
)	O
.	O
7	O
for	O
example	O
,	O
you	O
can	O
store	O
a	O
list	O
of	O
(	O
i	O
,	O
j	O
,	O
cij	O
)	O
triples	O
.	O
one	O
example	O
of	O
such	O
a	O
scheme	O
is	O
compressed	O
sparse	O
row	O
(	O
csr	O
)	O
storage	O
.	O
an	O
alternative	O
storage	O
method	O
called	O
skyline	O
,	O
which	O
stores	O
adjacent	O
vertical	O
spans	O
of	O
non-zero	O
elements	O
(	O
bathe	O
2007	O
)	O
,	O
is	O
sometimes	O
used	O
in	O
ﬁnite	O
element	O
analysis	O
.	O
banded	O
systems	O
such	O
as	O
snakes	B
(	O
5.3	O
)	O
can	O
store	O
just	O
the	O
non-zero	O
band	O
elements	O
(	O
bj¨orck	O
1996	O
,	O
section	O
6.2	O
)	O
and	O
can	O
be	O
solved	O
in	O
o	O
(	O
nb2	O
)	O
,	O
where	O
n	O
is	O
the	O
number	O
of	O
variables	O
and	O
b	O
is	O
the	O
bandwidth	O
.	O
748	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
a.4.1	O
variable	O
reordering	O
the	O
key	O
to	O
efﬁciently	O
solving	O
sparse	B
problems	O
using	O
direct	O
(	O
non-iterative	O
)	O
techniques	O
is	O
to	O
determine	O
an	O
efﬁcient	O
ordering	O
for	O
the	O
variables	O
,	O
which	O
reduces	O
the	O
amount	O
of	O
ﬁll-in	O
,	O
i.e.	O
,	O
the	O
number	O
of	O
non-zero	O
entries	O
in	O
r	O
that	O
were	O
zero	O
in	O
the	O
original	O
c	O
matrix	O
.	O
we	O
already	O
saw	O
in	O
section	O
7.4.1	O
how	O
storing	O
the	O
more	O
numerous	O
3d	O
point	O
parameters	O
before	O
the	O
camera	B
param-	O
eters	O
and	O
using	O
the	O
schur	O
complement	O
(	O
7.56	O
)	O
results	O
in	O
a	O
more	O
efﬁcient	O
algorithm	B
.	O
similarly	O
,	O
sorting	O
parameters	B
by	O
time	O
in	O
video-based	O
reconstruction	O
problems	O
usually	O
results	O
in	O
lower	O
ﬁll-in	O
.	O
furthermore	O
,	O
any	O
problem	O
whose	O
adjacency	O
graph	O
(	O
the	O
graph	O
corresponding	O
to	O
the	O
sparsity	O
pattern	O
)	O
is	O
a	O
tree	O
can	O
be	O
solved	O
in	O
linear	B
time	O
with	O
an	O
appropriate	O
reordering	O
of	O
the	O
variables	O
(	O
putting	O
all	O
the	O
children	O
before	O
their	O
parents	O
)	O
.	O
all	O
of	O
these	O
are	O
examples	B
of	O
good	O
reordering	O
techniques	O
.	O
in	O
the	O
general	O
case	O
of	O
unstructured	B
data	O
,	O
there	O
are	O
many	O
heuristics	O
available	O
to	O
ﬁnd	O
good	O
reorderings	O
(	O
bj¨orck	O
1996	O
;	O
davis	O
2006	O
)	O
.8	O
for	O
general	O
adjacency	O
(	O
sparsity	O
)	O
graphs	O
,	O
minimum	B
degree	I
orderings	O
generally	O
produce	O
good	O
results	O
.	O
for	O
planar	O
graphs	O
,	O
which	O
often	O
arise	O
on	O
im-	O
age	O
or	O
spline	B
grids	O
(	O
section	O
8.3	O
)	O
,	O
nested	B
dissection	I
,	O
which	O
recursively	O
splits	O
the	O
graph	O
into	O
two	O
equal	O
halves	O
along	O
a	O
frontier	O
(	O
or	O
boundary	O
)	O
of	O
small	O
size	O
,	O
generally	O
works	O
well	O
.	O
such	O
domain	O
decomposition	O
(	O
or	O
multi-frontal	B
)	O
techniques	O
also	O
enable	O
the	O
use	O
of	O
parallel	O
processing	O
,	O
since	O
independent	O
sub-graphs	O
can	O
be	O
processed	O
in	O
parallel	O
on	O
separate	O
processors	O
(	O
davis	O
2008	O
)	O
.	O
the	O
overall	O
set	O
of	O
steps	O
used	O
to	O
perform	O
the	O
direct	B
solution	O
of	O
sparse	B
least	O
squares	O
problems	O
are	O
summarized	O
in	O
algorithm	B
a.2	O
,	O
which	O
is	O
a	O
modiﬁed	O
version	O
of	O
algorithm	B
6.6.1	O
by	O
bj¨orck	O
(	O
1996	O
,	O
section	O
6.6	O
)	O
)	O
.	O
if	O
a	O
series	O
of	O
related	O
least	B
squares	I
problems	O
is	O
being	O
solved	O
,	O
as	O
is	O
the	O
case	O
in	O
iterative	B
non-linear	O
least	B
squares	I
(	O
appendix	O
a.3	O
)	O
,	O
steps	O
1–3	O
can	O
be	O
performed	O
ahead	O
of	O
time	O
and	O
reused	O
for	O
each	O
new	O
invocation	O
with	O
different	O
c	O
and	O
d	O
values	O
.	O
when	O
the	O
problem	O
is	O
block-structured	O
,	O
as	O
is	O
the	O
case	O
in	O
structure	B
from	I
motion	I
where	O
point	O
(	O
structure	O
)	O
variables	O
have	O
dense	O
3×3	O
sub-entries	O
in	O
c	O
and	O
cameras	O
have	O
6×6	O
(	O
or	O
larger	O
)	O
entries	O
,	O
the	O
cost	O
of	O
performing	O
the	O
reordering	O
computation	O
is	O
small	O
compared	O
to	O
the	O
actual	O
numerical	O
factorization	B
,	O
which	O
can	O
beneﬁt	O
from	O
block-structured	O
matrix	O
operations	O
(	O
golub	O
and	O
van	O
loan	O
1996	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
apply	O
sparse	B
reordering	O
and	O
multifrontal	O
techniques	O
to	O
qr	O
factorization	B
(	O
davis	O
2008	O
)	O
,	O
which	O
may	O
be	O
preferable	O
when	O
the	O
least	B
squares	I
problems	O
are	O
poorly	O
conditioned	O
.	O
a.5	O
iterative	B
techniques	O
when	O
problems	O
become	O
large	O
,	O
the	O
amount	O
of	O
memory	O
required	O
to	O
store	O
the	O
hessian	O
matrix	O
c	O
and	O
its	O
factor	O
r	O
,	O
and	O
the	O
amount	O
of	O
time	O
it	O
takes	O
to	O
compute	O
the	O
factorization	B
,	O
can	O
be-	O
come	O
prohibitively	O
large	O
,	O
especially	O
when	O
there	O
are	O
large	O
amounts	O
of	O
ﬁll-in	O
.	O
this	O
is	O
often	O
8finding	O
the	O
optimal	O
reordering	O
with	O
minimal	O
ﬁll-in	O
is	O
provably	O
np-hard	O
.	O
a.5	O
iterative	B
techniques	O
749	O
procedure	O
sparsecholeskysolve	O
(	O
c	O
,	O
d	O
)	O
:	O
1.	O
determine	O
symbolically	O
the	O
structure	O
of	O
c	O
,	O
i.e.	O
,	O
the	O
adjacency	O
graph	O
.	O
2	O
.	O
(	O
optional	O
)	O
compute	O
a	O
reordering	O
for	O
the	O
variables	O
,	O
taking	O
into	O
ac-	O
count	O
any	O
block	O
structure	O
inherent	O
in	O
the	O
problem	O
.	O
3.	O
determine	O
the	O
ﬁll-in	O
pattern	O
for	O
r	O
and	O
allocate	O
the	O
compressed	O
stor-	O
age	O
for	O
r	O
as	O
well	O
as	O
storage	O
for	O
the	O
permuted	O
right	O
hand	O
side	O
ˆd	O
.	O
4.	O
copy	O
the	O
elements	O
of	O
c	O
and	O
d	O
into	O
r	O
and	O
ˆd	O
,	O
permuting	O
the	O
values	O
according	O
to	O
the	O
computed	O
ordering	O
.	O
5.	O
perform	O
the	O
numerical	O
factorization	B
of	O
r	O
using	O
algorithm	O
a.1	O
.	O
6.	O
solve	O
the	O
factored	O
system	O
(	O
a.33	O
)	O
,	O
i.e.	O
,	O
rt	O
z	O
=	O
ˆd	O
,	O
rx	O
=	O
z	O
.	O
7.	O
return	O
the	O
solution	O
x	O
,	O
after	O
undoing	O
the	O
permutation	O
.	O
algorithm	B
a.2	O
sparse	B
least	O
squares	O
using	O
a	O
sparse	B
cholesky	O
decomposition	O
of	O
the	O
matrix	O
c.	O
the	O
case	O
with	O
image	O
processing	O
problems	O
deﬁned	O
on	O
pixel	O
grids	O
,	O
since	O
,	O
even	O
with	O
the	O
optimal	O
reordering	O
(	O
nested	B
dissection	I
)	O
the	O
amount	O
of	O
ﬁll	O
can	O
still	O
be	O
large	O
.	O
a	O
preferable	O
approach	O
to	O
solving	O
such	O
linear	B
systems	O
is	O
to	O
use	O
iterative	B
techniques	O
,	O
which	O
compute	O
a	O
series	O
of	O
estimates	O
that	O
converge	O
to	O
the	O
ﬁnal	O
solution	O
,	O
e.g.	O
,	O
by	O
taking	O
a	O
series	O
of	O
downhill	O
steps	O
in	O
an	O
energy	O
function	O
such	O
as	O
(	O
a.29	O
)	O
.	O
a	O
large	O
number	O
of	O
iterative	B
techniques	O
have	O
been	O
developed	O
over	O
the	O
years	O
,	O
including	O
such	O
well-known	O
algorithms	O
as	O
successive	O
overrelaxation	O
and	O
multi-grid	O
.	O
these	O
are	O
described	O
in	O
specialized	O
textbooks	B
on	O
iterative	B
solution	O
techniques	O
(	O
axelsson	O
1996	O
;	O
saad	O
2003	O
)	O
as	O
well	O
as	O
in	O
more	O
general	O
books	O
on	O
numerical	O
linear	B
algebra	O
and	O
least	B
squares	I
techniques	O
(	O
bj¨orck	O
1996	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
;	O
trefethen	O
and	O
bau	O
1997	O
;	O
nocedal	O
and	O
wright	O
2006	O
;	O
bj¨orck	O
and	O
dahlquist	O
2010	O
)	O
.	O
a.5.1	O
conjugate	B
gradient	I
the	O
iterative	B
solution	O
technique	O
that	O
often	O
performs	O
best	O
is	O
conjugate	B
gradient	I
descent	O
,	O
which	O
takes	O
a	O
series	O
of	O
downhill	O
steps	O
that	O
are	O
conjugate	O
to	O
each	O
other	O
with	O
respect	O
to	O
the	O
c	O
matrix	O
,	O
750	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
i.e.	O
,	O
if	O
the	O
u	O
and	O
v	O
descent	O
directions	O
satisfy	O
ut	O
cv	O
=	O
0.	O
in	O
practice	O
,	O
conjugate	B
gradient	I
descent	O
outperforms	O
other	O
kinds	O
of	O
gradient	B
descent	I
algorithm	O
because	O
its	O
convergence	O
rate	O
is	O
proportional	O
to	O
the	O
square	B
root	I
of	O
the	O
condition	O
number	O
of	O
c	O
instead	O
of	O
the	O
condition	O
number	O
itself.9	O
shewchuk	O
(	O
1994	O
)	O
provides	O
a	O
nice	O
introduction	O
to	O
this	O
topic	O
,	O
with	O
clear	O
intuitive	O
explanations	O
of	O
the	O
reasoning	O
behind	O
the	O
conjugate	B
gradient	I
algorithm	O
and	O
its	O
performance	O
.	O
algorithm	B
a.3	O
describes	O
the	O
conjugate	B
gradient	I
algorithm	O
and	O
its	O
related	O
least	B
squares	I
counterpart	O
,	O
which	O
can	O
be	O
used	O
when	O
the	O
original	O
set	O
of	O
least	B
squares	I
linear	O
equations	B
are	O
available	O
in	O
the	O
form	O
of	O
ax	O
=	O
b	O
(	O
a.28	O
)	O
.	O
while	O
it	O
is	O
easy	O
to	O
convince	O
yourself	O
that	O
the	O
two	O
forms	O
are	O
mathematically	O
equivalent	O
,	O
the	O
least	B
squares	I
form	O
is	O
preferable	O
if	O
rounding	O
errors	O
start	O
to	O
affect	O
the	O
results	O
because	O
of	O
poor	O
conditioning	O
.	O
it	O
may	O
also	O
be	O
preferable	O
if	O
,	O
due	O
to	O
the	O
sparsity	O
structure	O
of	O
a	O
,	O
multiplies	O
with	O
the	O
original	O
a	O
matrix	O
are	O
faster	O
or	O
more	O
space	O
efﬁcient	O
than	O
multiplies	O
with	O
c.	O
the	O
conjugate	B
gradient	I
algorithm	O
starts	O
by	O
computing	O
the	O
current	O
residual	O
r0	O
=	O
d−cx0	O
,	O
which	O
is	O
the	O
direction	O
of	O
steepest	O
descent	O
of	O
the	O
energy	O
function	O
(	O
a.28	O
)	O
.	O
it	O
sets	O
the	O
original	O
descent	O
direction	O
p0	O
=	O
r0	O
.	O
next	O
,	O
it	O
multiplies	O
the	O
descent	O
direction	O
by	O
the	O
quadratic	O
form	O
(	O
hessian	O
)	O
matrix	O
c	O
and	O
combines	O
this	O
with	O
the	O
residual	O
to	O
estimate	O
the	O
optimal	O
step	O
size	O
αk	O
.	O
the	O
solution	O
vector	O
xk	O
and	O
the	O
residual	O
vector	O
rk	O
are	O
then	O
updated	O
using	O
this	O
step	O
size	O
.	O
(	O
no-	O
tice	O
how	O
the	O
least	B
squares	I
variant	O
of	O
the	O
conjugate	B
gradient	I
algorithm	O
splits	O
the	O
multiplication	B
by	O
the	O
c	O
=	O
at	O
a	O
matrix	O
across	O
steps	O
4	O
and	O
8	O
.	O
)	O
finally	O
,	O
a	O
new	O
search	O
direction	O
is	O
calculated	O
by	O
ﬁrst	O
computing	O
a	O
factor	O
β	O
as	O
the	O
ratio	O
of	O
current	O
to	O
previous	O
residual	O
magnitudes	O
.	O
the	O
new	O
search	O
direction	O
pk+1	O
is	O
then	O
set	O
to	O
the	O
residual	O
plus	O
β	O
times	O
the	O
old	O
search	O
direction	O
pk	O
,	O
which	O
keeps	O
the	O
directions	O
conjugate	O
with	O
respect	O
to	O
c.	O
it	O
turns	O
out	O
that	O
conjugate	B
gradient	I
descent	O
can	O
also	O
be	O
directly	O
applied	O
to	O
non-quadratic	O
energy	O
functions	O
,	O
e.g.	O
,	O
those	O
arising	O
from	O
non-linear	B
least	O
squares	O
(	O
appendix	O
a.3	O
)	O
.	O
instead	O
of	O
explicitly	O
forming	O
a	O
local	B
quadratic	O
approximation	O
c	O
and	O
then	O
computing	O
residuals	O
rk	O
,	O
non-linear	B
conjugate	O
gradient	B
descent	I
computes	O
the	O
gradient	O
of	O
the	O
energy	O
function	O
e	O
(	O
a.45	O
)	O
directly	O
inside	O
each	O
iteration	O
and	O
uses	O
it	O
to	O
set	O
the	O
search	O
direction	O
(	O
nocedal	O
and	O
wright	O
2006	O
)	O
.	O
since	O
the	O
quadratic	O
approximation	O
to	O
the	O
energy	O
function	O
may	O
not	O
exist	O
or	O
may	O
be	O
inaccurate	O
,	O
line	O
search	O
is	O
often	O
used	O
to	O
determine	O
the	O
step	O
size	O
αk	O
.	O
furthermore	O
,	O
to	O
compensate	O
for	O
errors	O
in	O
ﬁnding	O
the	O
true	O
function	O
minimum	O
,	O
alternative	O
formulas	O
for	O
βk+1	O
such	O
as	O
polak–ribi`ere	O
,	O
βk+1	O
=	O
∇e	O
(	O
xk+1	O
)	O
[	O
∇e	O
(	O
xk+1	O
)	O
−	O
∇e	O
(	O
xk	O
)	O
]	O
(	O
cid:107	O
)	O
∇e	O
(	O
xk	O
)	O
(	O
cid:107	O
)	O
2	O
(	O
a.51	O
)	O
are	O
often	O
used	O
(	O
nocedal	O
and	O
wright	O
2006	O
)	O
.	O
9	O
the	O
condition	O
number	O
κ	O
(	O
c	O
)	O
is	O
the	O
ratio	O
of	O
the	O
largest	O
and	O
smallest	O
eigenvalues	B
of	O
c.	O
the	O
actual	O
convergence	O
rate	O
depends	O
on	O
the	O
clustering	O
of	O
the	O
eigenvalues	B
,	O
as	O
discussed	O
in	O
the	O
references	B
cited	O
in	O
this	O
section	O
.	O
a.5	O
iterative	B
techniques	O
751	O
conjugategradient	O
(	O
c	O
,	O
d	O
,	O
x0	O
)	O
conjugategradientls	O
(	O
a	O
,	O
b	O
,	O
x0	O
)	O
1.	O
r0	O
=	O
d	O
−	O
cx0	O
2.	O
p0	O
=	O
r0	O
3.	O
for	O
k	O
=	O
0	O
.	O
.	O
.	O
4.	O
wk	O
=	O
cpk	O
5	O
.	O
6	O
.	O
7	O
.	O
8	O
.	O
9	O
.	O
10.	O
αk	O
=	O
(	O
cid:107	O
)	O
rk	O
(	O
cid:107	O
)	O
2/	O
(	O
pk	O
·	O
wk	O
)	O
xk+1	O
=	O
xk	O
+	O
αkpk	O
rk+1	O
=	O
rk	O
−	O
αkwk	O
βk+1	O
=	O
(	O
cid:107	O
)	O
rk+1	O
(	O
cid:107	O
)	O
2/	O
(	O
cid:107	O
)	O
rk	O
(	O
cid:107	O
)	O
2	O
pk+1	O
=	O
rk+1	O
+	O
βkpk	O
1.	O
q0	O
=	O
b	O
−	O
ax0	O
,	O
r0	O
=	O
at	O
q0	O
2.	O
p0	O
=	O
r0	O
3.	O
for	O
k	O
=	O
0	O
.	O
.	O
.	O
4	O
.	O
5	O
.	O
6	O
.	O
7	O
.	O
8	O
.	O
9	O
.	O
10.	O
vk	O
=	O
apk	O
αk	O
=	O
(	O
cid:107	O
)	O
rk	O
(	O
cid:107	O
)	O
2/	O
(	O
cid:107	O
)	O
vk	O
(	O
cid:107	O
)	O
2	O
xk+1	O
=	O
xk	O
+	O
αkpk	O
qk+1	O
=	O
qk	O
−	O
αkvk	O
rk+1	O
=	O
at	O
qk+1	O
βk+1	O
=	O
(	O
cid:107	O
)	O
rk+1	O
(	O
cid:107	O
)	O
2/	O
(	O
cid:107	O
)	O
rk	O
(	O
cid:107	O
)	O
2	O
pk+1	O
=	O
rk+1	O
+	O
βkpk	O
algorithm	B
a.3	O
conjugate	B
gradient	I
and	O
conjugate	B
gradient	I
least	O
squares	O
algorithms	O
.	O
the	O
algorithm	B
is	O
described	O
in	O
more	O
detail	O
in	O
the	O
text	O
,	O
but	O
in	O
brief	O
,	O
they	O
choose	O
descent	O
directions	O
pk	O
that	O
are	O
conjugate	O
to	O
each	O
other	O
with	O
respect	O
to	O
c	O
by	O
computing	O
a	O
factor	O
β	O
by	O
which	O
to	O
discount	O
the	O
previous	O
search	O
direction	O
pk−1	O
.	O
they	O
then	O
ﬁnd	O
the	O
optimal	O
step	O
size	O
α	O
and	O
take	O
a	O
downhill	O
step	O
by	O
an	O
amount	O
αkpk	O
.	O
a.5.2	O
preconditioning	O
as	O
we	O
mentioned	O
previously	O
,	O
the	O
rate	O
of	O
convergence	O
of	O
the	O
conjugate	B
gradient	I
algorithm	O
is	O
governed	O
in	O
large	O
part	O
by	O
the	O
condition	O
number	O
κ	O
(	O
c	O
)	O
.	O
its	O
effectiveness	O
can	O
therefore	O
be	O
increased	O
dramatically	O
by	O
reducing	O
this	O
number	O
,	O
e.g.	O
,	O
by	O
rescaling	O
elements	O
in	O
x	O
,	O
which	O
cor-	O
responds	O
to	O
rescaling	O
rows	O
and	O
columns	O
in	O
c.	O
in	O
general	O
,	O
preconditioning	O
is	O
usually	O
thought	O
of	O
as	O
a	O
change	O
of	O
basis	O
from	O
the	O
vector	O
x	O
to	O
a	O
new	O
vector	O
ˆx	O
=	O
sx	O
.	O
the	O
corresponding	O
linear	B
system	O
being	O
solved	O
then	O
becomes	O
as−1ˆx	O
=	O
s−1b	O
or	O
ˆaˆx	O
=	O
ˆb	O
,	O
(	O
a.52	O
)	O
(	O
a.53	O
)	O
752	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
with	O
a	O
corresponding	O
least	B
squares	I
energy	O
(	O
a.29	O
)	O
of	O
the	O
form	O
epls	O
=	O
ˆxt	O
(	O
s−t	O
cs−1	O
)	O
ˆx	O
−	O
2ˆxt	O
(	O
s−t	O
d	O
)	O
+	O
(	O
cid:107	O
)	O
ˆb	O
(	O
cid:107	O
)	O
2	O
.	O
(	O
a.54	O
)	O
the	O
actual	O
preconditioned	B
matrix	O
ˆc	O
=	O
s−t	O
cs−1	O
is	O
usually	O
not	O
explicitly	O
computed	O
.	O
in-	O
stead	O
,	O
algorithm	B
a.3	O
is	O
extended	O
to	O
insert	O
s−t	O
and	O
st	O
operations	O
at	O
the	O
appropriate	O
places	O
(	O
bj¨orck	O
1996	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
;	O
trefethen	O
and	O
bau	O
1997	O
;	O
saad	O
2003	O
;	O
nocedal	O
and	O
wright	O
2006	O
)	O
.	O
a	O
good	O
preconditioner	O
s	O
is	O
easy	O
and	O
cheap	O
to	O
compute	O
,	O
but	O
is	O
also	O
a	O
decent	O
approximation	O
to	O
a	O
square	B
root	I
of	O
c	O
,	O
so	O
that	O
κ	O
(	O
s−t	O
cs−1	O
)	O
is	O
closer	O
to	O
1.	O
the	O
simplest	O
such	O
choice	O
is	O
the	O
square	B
root	I
of	O
the	O
diagonal	O
matrix	O
s	O
=	O
d1/2	O
,	O
with	O
d	O
=	O
diag	O
(	O
c	O
)	O
.	O
this	O
has	O
the	O
advantage	O
that	O
any	O
scalar	O
change	O
in	O
variables	O
(	O
e.g.	O
,	O
using	O
radians	O
instead	O
of	O
degrees	O
for	O
angular	O
measure-	O
ments	O
)	O
has	O
no	O
effect	O
on	O
the	O
range	O
of	O
convergence	O
of	O
the	O
iterative	B
technique	O
.	O
for	O
problems	O
that	O
are	O
naturally	O
block-structured	O
,	O
e.g.	O
,	O
for	O
structure	O
from	O
motion	B
,	O
where	O
3d	O
point	O
positions	O
or	O
6d	O
camera	B
poses	O
are	O
being	O
estimated	O
,	O
a	O
block	O
diagonal	O
preconditioner	O
is	O
often	O
a	O
good	O
choice	O
.	O
a	O
wide	O
variety	O
of	O
more	O
sophisticated	O
preconditioners	O
have	O
been	O
developed	O
over	O
the	O
years	O
(	O
bj¨orck	O
1996	O
;	O
golub	O
and	O
van	O
loan	O
1996	O
;	O
trefethen	O
and	O
bau	O
1997	O
;	O
saad	O
2003	O
;	O
nocedal	O
and	O
wright	O
2006	O
)	O
,	O
many	O
of	O
which	O
can	O
be	O
directly	O
applied	O
to	O
problems	O
in	O
computer	O
vision	O
(	O
byr¨od	O
and	O
øastr¨om	O
2009	O
;	O
jeong	O
,	O
nist´er	O
,	O
steedly	O
et	O
al	O
.	O
2010	O
;	O
agarwal	O
,	O
snavely	O
,	O
seitz	O
et	O
al	O
.	O
2010	O
)	O
.	O
some	O
of	O
these	O
are	O
based	O
on	O
an	O
incomplete	B
cholesky	O
factorization	B
of	O
c	O
,	O
i.e.	O
,	O
one	O
in	O
which	O
the	O
amount	O
of	O
ﬁll-in	O
in	O
r	O
is	O
strictly	O
limited	O
,	O
e.g.	O
,	O
to	O
just	O
the	O
original	O
non-zero	O
elements	O
in	O
c.10	O
other	O
preconditioners	O
are	O
based	O
on	O
a	O
sparsiﬁed	O
,	O
e.g.	O
,	O
tree-based	O
or	O
clustered	O
,	O
approximation	O
to	O
c	O
(	O
koutis	O
2007	O
;	O
koutis	O
and	O
miller	O
2008	O
;	O
grady	O
2008	O
;	O
koutis	O
,	O
miller	O
,	O
and	O
tolliver	O
2009	O
)	O
,	O
since	O
these	O
are	O
known	O
to	O
have	O
efﬁcient	O
inversion	O
properties	B
.	O
for	O
grid-based	O
image-processing	O
applications	O
,	O
parallel	O
or	O
hierarchical	B
preconditioners	O
often	O
perform	O
extremely	O
well	O
(	O
yserentant	O
1986	O
;	O
szeliski	O
1990b	O
;	O
pentland	O
1994	O
;	O
saad	O
2003	O
;	O
szeliski	O
2006b	O
)	O
.	O
these	O
approaches	O
use	O
a	O
change	O
of	O
basis	O
transformation	O
s	O
that	O
resembles	O
the	O
pyramidal	O
or	O
wavelet	O
representations	O
discussed	O
in	O
section	O
3.5	O
,	O
and	O
are	O
hence	O
amenable	O
to	O
parallel	O
and	O
gpu-based	O
implementations	O
.	O
coarser	O
elements	O
in	O
the	O
new	O
representation	O
quickly	O
converge	O
to	O
the	O
low-frequency	O
components	O
in	O
the	O
solution	O
,	O
while	O
ﬁner-level	O
elements	O
encode	O
the	O
higher-frequency	O
components	O
.	O
some	O
of	O
the	O
relationships	O
between	O
hierarchical	B
preconditioners	O
,	O
incomplete	B
cholesky	O
factorization	B
,	O
and	O
multigrid	O
techniques	O
are	O
explored	O
by	O
saad	O
(	O
2003	O
)	O
and	O
szeliski	O
(	O
2006b	O
)	O
.	O
10	O
if	O
a	O
complete	O
cholesky	O
factorization	B
c	O
=	O
rt	O
r	O
is	O
used	O
,	O
we	O
get	O
ˆc	O
=	O
r−t	O
cr−1	O
=	O
i	O
and	O
all	O
iterative	B
algorithms	O
converge	O
in	O
a	O
single	O
step	O
,	O
thereby	O
obviating	O
the	O
need	O
to	O
use	O
them	O
,	O
but	O
the	O
complete	O
factorization	B
is	O
often	O
too	O
expensive	O
.	O
note	O
that	O
incomplete	B
factorization	O
can	O
also	O
beneﬁt	O
from	O
reordering	O
.	O
a.5	O
iterative	B
techniques	O
a.5.3	O
multigrid	O
753	O
one	O
other	O
class	O
of	O
iterative	B
techniques	O
widely	O
used	O
in	O
computer	O
vision	O
is	O
multigrid	O
techniques	O
(	O
briggs	O
,	O
henson	O
,	O
and	O
mccormick	O
2000	O
;	O
trottenberg	O
,	O
oosterlee	O
,	O
and	O
schuller	O
2000	O
)	O
,	O
which	O
have	O
been	O
applied	O
to	O
problems	O
such	O
as	O
surface	B
interpolation	O
(	O
terzopoulos	O
1986a	O
)	O
,	O
optical	B
ﬂow	I
(	O
terzopoulos	O
1986a	O
;	O
bruhn	O
,	O
weickert	O
,	O
kohlberger	O
et	O
al	O
.	O
2006	O
)	O
,	O
high	B
dynamic	I
range	I
tone	O
mapping	O
(	O
fattal	O
,	O
lischinski	O
,	O
and	O
werman	O
2002	O
)	O
,	O
colorization	B
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2004	O
)	O
,	O
natural	B
image	O
matting	B
(	O
levin	O
,	O
lischinski	O
,	O
and	O
weiss	O
2008	O
)	O
,	O
and	O
segmentation	B
(	O
grady	O
2008	O
)	O
.	O
the	O
main	O
idea	O
behind	O
multigrid	O
is	O
to	O
form	O
coarser	O
(	O
lower-resolution	O
)	O
versions	O
of	O
the	O
prob-	O
lems	O
and	O
use	O
them	O
to	O
compute	O
the	O
low-frequency	O
components	O
of	O
the	O
solution	O
.	O
however	O
,	O
unlike	O
simple	O
coarse-to-ﬁne	B
techniques	O
,	O
which	O
use	O
the	O
coarse	O
solutions	O
to	O
initialize	O
the	O
ﬁne	O
solution	O
,	O
multigrid	O
techniques	O
only	O
correct	O
the	O
low-frequency	O
component	O
of	O
the	O
current	O
solu-	O
tion	B
and	O
use	O
multiple	B
rounds	O
of	O
coarsening	O
and	O
reﬁnement	O
(	O
in	O
what	O
are	O
often	O
called	O
“	O
v	O
”	O
and	O
“	O
w	O
”	O
patterns	B
of	O
motion	B
across	O
the	O
pyramid	B
)	O
to	O
obtain	O
rapid	O
convergence	O
.	O
on	O
certain	O
simple	O
homogeneous	O
problems	O
(	O
such	O
as	O
solving	O
poisson	O
equations	B
)	O
,	O
multigrid	O
techniques	O
can	O
achieve	O
optimal	O
performance	O
,	O
i.e.	O
,	O
computation	O
times	O
linear	B
in	O
the	O
number	O
of	O
variables	O
.	O
however	O
,	O
for	O
more	O
inhomogeneous	O
problems	O
or	O
problems	O
on	O
irregular	O
grids	O
,	O
variants	O
on	O
these	O
techniques	O
,	O
such	O
as	O
algebraic	O
multigrid	O
(	O
amg	O
)	O
approaches	O
,	O
which	O
look	O
at	O
the	O
structure	O
of	O
c	O
to	O
derive	O
coarse	O
level	O
problems	O
,	O
may	O
be	O
preferable	O
.	O
saad	O
(	O
2003	O
)	O
has	O
a	O
nice	O
discussion	O
of	O
the	O
relationship	O
between	O
multigrid	O
and	O
parallel	O
preconditioners	O
and	O
on	O
the	O
relative	O
merits	O
of	O
using	O
multigrid	O
or	O
conjugate	B
gradient	I
approaches	O
.	O
754	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
appendix	O
b	O
bayesian	O
modeling	B
and	O
inference	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
b.1	O
estimation	B
theory	O
.	O
.	O
b.1.1	O
likelihood	O
for	O
multivariate	O
gaussian	O
noise	B
b.2	O
maximum	O
likelihood	O
estimation	B
and	O
least	B
squares	I
.	O
.	O
b.3	O
robust	B
statistics	O
.	O
.	O
.	O
b.4	O
prior	B
models	O
and	O
bayesian	O
inference	B
.	O
b.5	O
markov	O
random	O
ﬁelds	O
.	O
.	O
.	O
b.5.1	O
gradient	B
descent	I
and	O
simulated	B
annealing	I
.	O
.	O
b.5.2	O
dynamic	B
programming	I
.	O
.	O
.	O
b.5.3	O
belief	B
propagation	I
.	O
.	O
b.5.4	O
graph	B
cuts	I
.	O
.	O
.	O
.	O
.	O
.	O
b.5.5	O
linear	O
programming	O
.	O
.	O
.	O
.	O
.	O
.	O
b.6	O
uncertainty	B
estimation	O
(	O
error	O
analysis	O
)	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
757	O
.	O
757	O
.	O
759	O
.	O
760	O
.	O
762	O
.	O
763	O
.	O
765	O
.	O
766	O
.	O
768	O
.	O
770	O
.	O
773	O
.	O
775	O
756	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
the	O
following	O
problem	O
commonly	O
recurs	O
in	O
this	O
book	O
:	O
given	O
a	O
number	O
of	O
measurements	O
(	O
images	O
,	O
feature	B
positions	O
,	O
etc	O
.	O
)	O
,	O
estimate	O
the	O
values	O
of	O
some	O
unknown	O
structure	O
or	O
parameter	O
(	O
camera	B
positions	O
,	O
object	O
shape	O
,	O
etc.	O
)	O
.	O
these	O
kinds	O
of	O
problems	O
are	O
in	O
general	O
called	O
inverse	B
problems	O
because	O
they	O
involve	O
estimating	O
unknown	O
model	O
parameters	B
instead	O
of	O
simulating	O
the	O
forward	B
formation	O
equations.1	O
computer	O
graphics	O
is	O
a	O
classic	O
forward	B
modeling	O
problem	O
(	O
given	O
some	O
objects	O
,	O
cameras	O
,	O
and	O
lighting	B
,	O
simulate	O
the	O
images	O
that	O
would	O
result	O
)	O
,	O
while	O
computer	O
vision	O
problems	O
are	O
usually	O
of	O
the	O
inverse	B
kind	O
(	O
given	O
one	O
or	O
more	O
images	O
,	O
recover	O
the	O
scene	O
that	O
gave	O
rise	O
to	O
these	O
images	O
)	O
.	O
given	O
an	O
instance	B
of	O
an	O
inverse	B
problem	O
,	O
there	O
are	O
,	O
in	O
general	O
,	O
several	O
ways	O
to	O
proceed	O
.	O
for	O
instance	O
,	O
through	O
clever	O
(	O
or	O
sometimes	O
straightforward	O
)	O
algebraic	O
manipulation	O
,	O
a	O
closed	O
form	O
solution	O
for	O
the	O
unknowns	O
can	O
sometimes	O
be	O
derived	O
.	O
consider	O
,	O
for	O
example	O
,	O
the	O
camera	B
matrix	O
calibration	B
problem	O
(	O
section	O
6.2.1	O
)	O
:	O
given	O
an	O
image	B
of	O
a	O
calibration	B
pattern	O
consisting	O
of	O
known	O
3d	O
point	O
positions	O
,	O
compute	O
the	O
3×	O
4	O
camera	B
matrix	O
p	O
that	O
maps	O
these	O
points	B
onto	O
the	O
image	B
plane	O
.	O
in	O
more	O
detail	O
,	O
we	O
can	O
write	O
this	O
problem	O
as	O
(	O
6.33–6.34	O
)	O
xi	O
=	O
p00xi	O
+	O
p01yi	O
+	O
p02zi	O
+	O
p03	O
p20xi	O
+	O
p21yi	O
+	O
p22zi	O
+	O
p23	O
yi	O
=	O
p10xi	O
+	O
p11yi	O
+	O
p12zi	O
+	O
p13	O
p20xi	O
+	O
p21yi	O
+	O
p22zi	O
+	O
p23	O
,	O
(	O
b.1	O
)	O
(	O
b.2	O
)	O
where	O
(	O
xi	O
,	O
yi	O
)	O
is	O
the	O
feature	B
position	O
of	O
the	O
ith	O
point	O
measured	O
in	O
the	O
image	B
plane	O
,	O
(	O
xi	O
,	O
yi	O
,	O
zi	O
)	O
is	O
the	O
corresponding	O
3d	O
point	O
position	O
,	O
and	O
the	O
pij	O
are	O
the	O
unknown	O
entries	O
of	O
the	O
camera	B
matrix	O
p	O
.	O
moving	O
the	O
denominator	O
over	O
to	O
the	O
left	O
hand	O
side	O
,	O
we	O
end	O
up	O
with	O
a	O
set	O
of	O
simultaneous	O
linear	B
equations	O
,	O
xi	O
(	O
p20xi	O
+	O
p21yi	O
+	O
p22zi	O
+	O
p23	O
)	O
=	O
p00xi	O
+	O
p01yi	O
+	O
p02zi	O
+	O
p03	O
,	O
yi	O
(	O
p20xi	O
+	O
p21yi	O
+	O
p22zi	O
+	O
p23	O
)	O
=	O
p10xi	O
+	O
p11yi	O
+	O
p12zi	O
+	O
p13	O
,	O
(	O
b.3	O
)	O
(	O
b.4	O
)	O
which	O
we	O
can	O
solve	O
using	O
linear	O
least	B
squares	I
(	O
appendix	O
a.2	O
)	O
to	O
obtain	O
an	O
estimate	O
of	O
p	O
.	O
the	O
question	O
then	O
arises	O
:	O
is	O
this	O
set	O
of	O
equations	B
the	O
right	O
ones	O
to	O
be	O
solving	O
?	O
if	O
the	O
measurements	O
are	O
totally	O
noise-free	O
or	O
we	O
do	O
not	O
care	O
about	O
getting	O
the	O
best	O
possible	O
answer	O
,	O
then	O
the	O
answer	O
is	O
yes	O
.	O
however	O
,	O
in	O
general	O
,	O
we	O
can	O
not	O
be	O
sure	O
that	O
we	O
have	O
a	O
reasonable	O
algorithm	B
unless	O
we	O
make	O
a	O
model	O
of	O
the	O
likely	O
sources	O
of	O
error	O
and	O
devise	O
an	O
algorithm	B
that	O
performs	O
as	O
well	O
as	O
possible	O
given	O
these	O
potential	O
errors	O
.	O
1	O
in	O
machine	O
learning	O
,	O
these	O
problems	O
are	O
called	O
regression	O
problems	O
,	O
because	O
we	O
are	O
trying	O
to	O
estimate	O
a	O
contin-	O
uous	O
quantity	O
from	O
noisy	O
inputs	O
,	O
as	O
opposed	O
to	O
a	O
discrete	B
classiﬁcation	O
task	O
(	O
bishop	O
2006	O
)	O
.	O
b.1	O
estimation	B
theory	O
b.1	O
estimation	B
theory	O
757	O
the	O
study	O
of	O
such	O
inference	B
problems	O
from	O
noisy	O
data	O
is	O
often	O
called	O
estimation	B
theory	O
(	O
gelb	O
1974	O
)	O
,	O
and	O
its	O
extension	O
to	O
problems	O
where	O
we	O
explicitly	O
choose	O
a	O
loss	O
function	O
is	O
called	O
sta-	O
tistical	O
decision	O
theory	O
(	O
berger	O
1993	O
;	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
bishop	O
2006	O
;	O
robert	O
2007	O
)	O
.	O
we	O
ﬁrst	O
start	O
by	O
writing	O
down	O
the	O
forward	B
process	O
that	O
leads	O
from	O
our	O
un-	O
knowns	O
(	O
and	O
knowns	O
)	O
to	O
a	O
set	O
of	O
noise-corrupted	O
measurements	O
.	O
we	O
then	O
devise	O
an	O
algorithm	B
that	O
will	O
give	O
us	O
an	O
estimate	O
(	O
or	O
set	O
of	O
estimates	O
)	O
that	O
are	O
both	O
insensitive	O
to	O
the	O
noise	B
(	O
as	O
best	O
they	O
can	O
be	O
)	O
and	O
also	O
quantify	O
the	O
reliability	O
of	O
these	O
estimates	O
.	O
the	O
speciﬁc	O
equations	B
above	O
(	O
b.1	O
)	O
are	O
just	O
a	O
particular	O
instance	B
of	O
a	O
more	O
general	O
set	O
of	O
measurement	O
equations	B
,	O
(	O
b.5	O
)	O
here	O
,	O
the	O
yi	O
are	O
the	O
noise-corrupted	O
measurements	O
,	O
e.g.	O
,	O
(	O
xi	O
,	O
yi	O
)	O
in	O
equation	B
(	O
b.1	O
)	O
,	O
and	O
x	O
is	O
the	O
unknown	O
state	O
vector.2	O
yi	O
=	O
f	O
i	O
(	O
x	O
)	O
+	O
ni	O
.	O
each	O
measurement	O
comes	O
with	O
its	O
associated	O
measurement	O
model	O
f	O
i	O
(	O
x	O
)	O
,	O
which	O
maps	O
the	O
unknown	O
into	O
that	O
particular	O
measurement	O
.	O
an	O
alternative	O
formulation	O
would	O
be	O
to	O
have	O
one	O
general	O
function	O
f	O
(	O
x	O
,	O
pi	O
)	O
and	O
to	O
use	O
a	O
per-measurement	O
parameter	O
vector	O
pi	O
to	O
distinguish	O
between	O
different	O
measurements	O
,	O
e.g.	O
,	O
(	O
xi	O
,	O
yi	O
,	O
zi	O
)	O
in	O
equation	B
(	O
b.1	O
)	O
.	O
note	O
that	O
the	O
use	O
of	O
the	O
f	O
i	O
(	O
x	O
)	O
form	O
makes	O
it	O
straightforward	O
to	O
have	O
measurements	O
of	O
different	O
dimensions	O
,	O
which	O
becomes	O
useful	O
when	O
we	O
start	O
adding	O
in	O
prior	B
information	O
(	O
appendix	O
b.4	O
)	O
.	O
each	O
measurement	O
is	O
also	O
contaminated	O
with	O
some	O
noise	B
ni	O
.	O
in	O
equation	B
(	O
b.5	O
)	O
,	O
we	O
have	O
indicated	O
that	O
ni	O
is	O
a	O
zero-mean	O
normal	O
(	O
gaussian	O
)	O
random	O
variable	O
with	O
a	O
covariance	O
matrix	O
σi	O
.	O
in	O
general	O
,	O
the	O
noise	B
need	O
not	O
be	O
gaussian	O
and	O
,	O
in	O
fact	O
,	O
it	O
is	O
usually	O
prudent	O
to	O
assume	O
that	O
some	O
measurements	O
may	O
be	O
outliers	O
.	O
however	O
,	O
we	O
defer	O
this	O
discussion	O
to	O
appendix	O
b.3	O
,	O
after	O
we	O
have	O
explored	O
the	O
simpler	O
gaussian	O
noise	B
case	O
more	O
fully	O
.	O
we	O
also	O
assume	O
that	O
the	O
noise	B
vectors	O
ni	O
are	O
independent	O
.	O
in	O
the	O
case	O
where	O
they	O
are	O
not	O
(	O
e.g.	O
,	O
when	O
some	O
constant	O
gain	O
or	O
offset	O
contaminates	O
all	O
of	O
the	O
pixels	O
in	O
a	O
given	O
image	B
)	O
,	O
we	O
can	O
add	O
this	O
effect	O
as	O
a	O
nuisance	O
parameter	O
to	O
our	O
state	O
vector	O
x	O
and	O
later	O
estimate	O
its	O
value	O
(	O
and	O
discard	O
it	O
,	O
if	O
so	O
desired	O
)	O
.	O
b.1.1	O
likelihood	O
for	O
multivariate	O
gaussian	O
noise	B
given	O
all	O
of	O
the	O
noisy	O
measurements	O
y	O
=	O
{	O
yi	O
}	O
,	O
we	O
would	O
like	O
to	O
infer	O
a	O
probability	O
distribu-	O
tion	B
on	O
the	O
unknown	O
x	O
vector	O
.	O
we	O
can	O
write	O
the	O
likelihood	O
of	O
having	O
observed	O
the	O
{	O
yi	O
}	O
given	O
a	O
particular	O
value	O
of	O
x	O
as	O
l	O
=	O
p	O
(	O
y|x	O
)	O
=	O
(	O
cid:89	O
)	O
i	O
p	O
(	O
yi|x	O
)	O
=	O
(	O
cid:89	O
)	O
i	O
2	O
in	O
the	O
kalman	O
ﬁltering	O
literature	O
(	O
gelb	O
1974	O
)	O
,	O
it	O
is	O
more	O
common	O
to	O
use	O
z	O
instead	O
of	O
y	O
to	O
denote	O
measurements	O
.	O
p	O
(	O
yi|f	O
i	O
(	O
x	O
)	O
)	O
=	O
(	O
cid:89	O
)	O
i	O
p	O
(	O
ni	O
)	O
.	O
(	O
b.6	O
)	O
758	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
when	O
each	O
noise	B
vector	O
ni	O
is	O
a	O
multivariate	O
gaussian	O
with	O
covariance	O
σi	O
,	O
ni	O
∼	O
n	O
(	O
0	O
,	O
σi	O
)	O
,	O
we	O
can	O
write	O
this	O
likelihood	O
as	O
l	O
=	O
(	O
cid:89	O
)	O
i	O
=	O
(	O
cid:89	O
)	O
i	O
|2πσi|−1/2	O
exp	O
(	O
cid:18	O
)	O
−	O
|2πσi|−1/2	O
exp	O
(	O
cid:18	O
)	O
−	O
1	O
2	O
1	O
2	O
(	O
cid:107	O
)	O
yi	O
−	O
f	O
i	O
(	O
x	O
)	O
(	O
cid:107	O
)	O
2	O
(	O
yi	O
−	O
f	O
i	O
(	O
x	O
)	O
)	O
(	O
cid:19	O
)	O
(	O
yi	O
−	O
f	O
i	O
(	O
x	O
)	O
)	O
t	O
σ−1	O
i	O
(	O
cid:19	O
)	O
,	O
σ−1	O
i	O
(	O
b.7	O
)	O
(	O
b.8	O
)	O
a	O
is	O
a	O
shorthand	O
notation	O
for	O
xt	O
ax	O
.	O
where	O
the	O
matrix	O
norm	O
(	O
cid:107	O
)	O
x	O
(	O
cid:107	O
)	O
2	O
is	O
often	O
called	O
the	O
mahalanobis	O
distance	O
(	O
5.26	O
and	O
14.14	O
)	O
and	O
is	O
the	O
norm	O
(	O
cid:107	O
)	O
yi	O
−	O
yi	O
(	O
cid:107	O
)	O
σ−1	O
used	O
to	O
measure	O
the	O
distance	O
between	O
a	O
measurement	O
and	O
the	O
mean	O
of	O
a	O
multivariate	O
gaussian	O
distribution	O
.	O
contours	O
of	O
equal	O
mahalanobis	O
distance	O
are	O
equi-probability	O
contours	O
.	O
note	O
that	O
when	O
the	O
measurement	O
covariance	O
is	O
isotropic	B
(	O
the	O
same	O
in	O
all	O
directions	O
)	O
,	O
i.e.	O
,	O
when	O
σi	O
=	O
σ2	O
i	O
i	O
,	O
the	O
likelihood	O
can	O
be	O
written	O
as	O
i	O
l	O
=	O
(	O
cid:89	O
)	O
i	O
(	O
2πσ2	O
i	O
)	O
−ni/2	O
exp	O
(	O
cid:18	O
)	O
−	O
1	O
2σ2	O
i	O
(	O
cid:107	O
)	O
yi	O
−	O
f	O
i	O
(	O
x	O
)	O
(	O
cid:107	O
)	O
2	O
(	O
cid:19	O
)	O
,	O
(	O
b.9	O
)	O
where	O
ni	O
is	O
the	O
length	O
of	O
the	O
ith	O
measurement	O
vector	O
yi	O
.	O
we	O
can	O
more	O
easily	O
visualize	O
the	O
structure	O
of	O
the	O
covariance	O
matrix	O
and	O
the	O
correspond-	O
ing	O
mahalanobis	O
distance	O
if	O
we	O
ﬁrst	O
perform	O
an	O
eigenvalue	O
or	O
principal	O
component	O
analysis	O
(	O
pca	O
)	O
of	O
the	O
covariance	O
matrix	O
(	O
a.6	O
)	O
,	O
σ	O
=	O
φ	O
diag	O
(	O
λ0	O
.	O
.	O
.	O
λn−1	O
)	O
φt	O
.	O
(	O
b.10	O
)	O
equal-probability	O
contours	O
of	O
the	O
corresponding	O
multi-variate	O
gaussian	O
,	O
which	O
are	O
also	O
equi-	O
distance	O
contours	O
in	O
the	O
mahalanobis	O
distance	O
(	O
figure	O
14.14	O
)	O
,	O
are	O
multi-dimensional	O
ellip-	O
soids	O
whose	O
axis	O
directions	O
are	O
given	O
by	O
the	O
columns	O
of	O
φ	O
(	O
the	O
eigenvectors	O
)	O
and	O
whose	O
lengths	O
are	O
given	O
by	O
the	O
σj	O
=	O
(	O
cid:112	O
)	O
λj	O
(	O
figure	O
a.1	O
)	O
.	O
of	O
as	O
a	O
cost	O
or	O
energy	O
it	O
is	O
usually	O
more	O
convenient	O
to	O
work	O
with	O
the	O
negative	O
log	O
likelihood	O
,	O
which	O
we	O
can	O
think	O
e	O
=	O
−	O
log	O
l	O
=	O
=	O
1	O
2	O
(	O
cid:88	O
)	O
i	O
2	O
(	O
cid:88	O
)	O
i	O
1	O
where	O
k	O
=	O
(	O
cid:80	O
)	O
i	O
log	O
|2πσi|	O
is	O
a	O
constant	O
that	O
depends	O
on	O
the	O
measurement	O
variances	O
,	O
but	O
is	O
independent	O
of	O
x	O
.	O
(	O
yi	O
−	O
f	O
i	O
(	O
x	O
)	O
)	O
t	O
σ−1	O
i	O
(	O
yi	O
−	O
f	O
i	O
(	O
x	O
)	O
)	O
+	O
k	O
(	O
cid:107	O
)	O
yi	O
−	O
f	O
i	O
(	O
x	O
)	O
(	O
cid:107	O
)	O
2	O
σ−1	O
i	O
+	O
k	O
,	O
(	O
b.11	O
)	O
(	O
b.12	O
)	O
b.2	O
maximum	O
likelihood	O
estimation	B
and	O
least	B
squares	I
759	O
i	O
notice	O
that	O
the	O
inverse	B
covariance	O
ci	O
=	O
σ−1	O
plays	O
the	O
role	O
of	O
a	O
weight	O
on	O
each	O
of	O
the	O
measurement	O
error	O
residuals	O
,	O
i.e.	O
,	O
the	O
difference	B
between	O
the	O
contaminated	O
measurement	O
yi	O
and	O
its	O
uncontaminated	O
(	O
predicted	O
)	O
value	O
f	O
i	O
(	O
x	O
)	O
.	O
in	O
fact	O
,	O
the	O
inverse	B
covariance	O
is	O
often	O
called	O
the	O
(	O
fisher	O
)	O
information	O
matrix	O
(	O
bishop	O
2006	O
)	O
,	O
since	O
it	O
tells	O
us	O
how	O
much	O
information	O
is	O
contained	O
in	O
a	O
given	O
measurement	O
,	O
i.e.	O
,	O
how	O
well	O
it	O
constrains	O
the	O
ﬁnal	O
estimate	O
.	O
we	O
can	O
also	O
think	O
of	O
this	O
matrix	O
as	O
denoting	O
the	O
amount	O
of	O
conﬁdence	O
to	O
associate	O
with	O
each	O
measurement	O
(	O
hence	O
the	O
letter	O
c	O
)	O
.	O
in	O
this	O
formulation	O
,	O
it	O
is	O
quite	O
acceptable	O
for	O
some	O
information	O
matrices	O
to	O
be	O
singular	O
(	O
of	O
degenerate	O
rank	O
)	O
or	O
even	O
zero	O
(	O
if	O
the	O
measurement	O
is	O
missing	O
altogether	O
)	O
.	O
rank-deﬁcient	B
measurements	O
often	O
occur	O
,	O
for	O
example	O
,	O
when	O
using	O
a	O
line	O
feature	O
or	O
edge	O
to	O
measure	O
a	O
3d	O
edge-like	O
feature	B
,	O
since	O
its	O
exact	O
position	O
along	O
the	O
edge	O
is	O
unknown	O
(	O
of	O
inﬁnite	O
or	O
extremely	O
large	O
variance	O
)	O
§8.1.3	O
.	O
in	O
order	B
to	O
make	O
the	O
distinction	O
between	O
the	O
noise	B
contaminated	O
measurement	O
and	O
its	O
expected	O
value	O
for	O
a	O
particular	O
setting	O
of	O
x	O
more	O
explicit	O
,	O
we	O
adopt	O
the	O
notation	O
˜y	O
for	O
the	O
former	O
(	O
think	O
of	O
the	O
tilde	O
as	O
the	O
approximate	O
or	O
noisy	O
value	O
)	O
and	O
ˆy	O
=	O
f	O
i	O
(	O
x	O
)	O
for	O
the	O
latter	O
(	O
think	O
of	O
the	O
hat	O
as	O
the	O
predicted	O
or	O
expected	O
value	O
)	O
.	O
we	O
can	O
then	O
write	O
the	O
negative	O
log	O
likelihood	O
as	O
e	O
=	O
−	O
log	O
l	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
˜yi	O
−	O
ˆyi	O
(	O
cid:107	O
)	O
σ−1	O
i	O
+	O
k.	O
(	O
b.13	O
)	O
b.2	O
maximum	O
likelihood	O
estimation	B
and	O
least	B
squares	I
now	O
that	O
we	O
have	O
presented	O
the	O
likelihood	O
and	O
log	O
likelihood	O
functions	O
,	O
how	O
can	O
we	O
ﬁnd	O
the	O
optimal	O
value	O
for	O
our	O
state	O
estimate	O
x	O
?	O
one	O
plausible	O
choice	O
might	O
be	O
to	O
select	O
the	O
value	O
of	O
x	O
that	O
maximizes	O
l	O
=	O
p	O
(	O
y|x	O
)	O
.	O
in	O
fact	O
,	O
in	O
the	O
absence	O
of	O
any	O
prior	B
model	O
for	O
x	O
(	O
appendix	O
b.4	O
)	O
,	O
we	O
have	O
l	O
=	O
p	O
(	O
y|x	O
)	O
=	O
p	O
(	O
y	O
,	O
x	O
)	O
=	O
p	O
(	O
x|y	O
)	O
.	O
therefore	O
,	O
choosing	O
the	O
value	O
of	O
x	O
that	O
maximizes	O
the	O
likelihood	O
is	O
equivalent	O
to	O
choosing	O
the	O
maximum	O
of	O
our	O
probability	O
density	O
estimate	O
for	O
x.	O
when	O
might	O
this	O
be	O
a	O
good	O
idea	O
?	O
if	O
the	O
data	O
(	O
measurements	O
)	O
constrain	O
the	O
possible	O
values	O
of	O
x	O
so	O
that	O
they	O
all	O
cluster	O
tightly	O
around	O
one	O
value	O
(	O
e.g.	O
,	O
if	O
the	O
distribution	O
p	O
(	O
x|y	O
)	O
is	O
a	O
unimodal	O
gaussian	O
)	O
,	O
the	O
maximum	O
likelihood	O
estimate	O
is	O
the	O
optimal	O
one	O
in	O
that	O
it	O
is	O
both	O
unbiased	O
and	O
has	O
the	O
least	O
possible	O
variance	O
.	O
in	O
many	O
other	O
cases	O
,	O
e.g.	O
,	O
if	O
a	O
single	O
estimate	O
is	O
all	O
that	O
is	O
required	O
,	O
it	O
is	O
still	O
often	O
the	O
best	O
estimate.3	O
however	O
,	O
if	O
the	O
probability	O
is	O
multi-	O
modal	O
,	O
i.e.	O
,	O
it	O
has	O
several	O
local	B
minima	O
in	O
the	O
log	O
likelihood	O
(	O
figure	O
5.7	O
)	O
,	O
much	O
more	O
care	O
3	O
according	O
to	O
the	O
gauss-markov	O
theorem	O
,	O
least	B
squares	I
produces	O
the	O
best	O
linear	B
unbiased	O
estimator	O
(	O
blue	O
)	O
for	O
a	O
linear	B
measurement	O
model	O
regardless	O
of	O
the	O
actual	O
noise	B
distribution	O
,	O
assuming	O
that	O
the	O
noise	B
is	O
zero	O
mean	O
and	O
uncorrelated	O
.	O
760	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
may	O
be	O
required	O
.	O
in	O
particular	O
,	O
it	O
might	O
be	O
necessary	O
to	O
defer	O
certain	O
decisions	O
(	O
such	O
as	O
the	O
ultimate	O
position	O
of	O
an	O
object	O
being	O
tracked	O
)	O
until	O
more	O
measurements	O
have	O
been	O
taken	O
.	O
the	O
condensation	O
algorithm	B
presented	O
in	O
section	O
5.1.2	O
is	O
one	O
possible	O
method	O
for	O
modeling	O
and	O
updating	O
such	O
multi-modal	O
distributions	O
but	O
is	O
just	O
one	O
example	O
of	O
more	O
general	O
particle	B
ﬁltering	I
and	O
markov	O
chain	O
monte	O
carlo	O
(	O
mcmc	O
)	O
techniques	O
(	O
andrieu	O
,	O
de	O
freitas	O
,	O
doucet	O
et	O
al	O
.	O
2003	O
;	O
bishop	O
2006	O
;	O
koller	O
and	O
friedman	O
2009	O
)	O
.	O
another	O
possible	O
way	O
to	O
choose	O
the	O
best	O
estimate	O
is	O
to	O
maximize	O
the	O
expected	O
utility	O
(	O
or	O
,	O
conversely	O
,	O
to	O
minimize	O
the	O
expected	O
risk	O
or	O
loss	O
)	O
associated	O
with	O
obtaining	O
the	O
correct	O
estimate	O
,	O
i.e.	O
,	O
by	O
minimizing	O
eloss	O
(	O
x	O
,	O
y	O
)	O
=	O
(	O
cid:90	O
)	O
l	O
(	O
x	O
−	O
z	O
)	O
p	O
(	O
z|y	O
)	O
dz	O
.	O
(	O
b.14	O
)	O
for	O
example	O
,	O
if	O
a	O
robot	O
wants	O
to	O
avoid	O
hitting	O
a	O
wall	O
at	O
all	O
costs	O
,	O
the	O
loss	O
function	O
will	O
be	O
high	O
whenever	O
the	O
estimate	O
underestimates	O
the	O
true	O
distance	O
to	O
the	O
wall	O
.	O
when	O
l	O
(	O
x	O
−	O
y	O
)	O
=	O
δ	O
(	O
x	O
−	O
y	O
)	O
,	O
we	O
obtain	O
the	O
maximum	O
likelihood	O
estimate	O
,	O
whereas	O
when	O
l	O
(	O
x	O
−	O
y	O
)	O
=	O
(	O
cid:107	O
)	O
x	O
−	O
y	O
(	O
cid:107	O
)	O
2	O
,	O
we	O
obtain	O
the	O
mean	O
square	O
error	O
(	O
mse	O
)	O
or	O
expected	O
value	O
estimate	O
.	O
the	O
explicit	O
modeling	B
of	O
a	O
utility	O
or	O
loss	O
function	O
is	O
what	O
characterizes	O
statistical	O
decision	O
theory	O
(	O
berger	O
1993	O
;	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
bishop	O
2006	O
;	O
robert	O
2007	O
)	O
.	O
how	O
do	O
we	O
ﬁnd	O
the	O
maximum	O
likelihood	O
estimate	O
?	O
if	O
the	O
measurement	O
noise	B
is	O
gaussian	O
,	O
we	O
can	O
minimize	O
the	O
quadratic	O
objective	O
function	O
(	O
b.13	O
)	O
.	O
this	O
becomes	O
even	O
simpler	O
if	O
the	O
measurement	O
equations	B
are	O
linear	B
,	O
i.e.	O
,	O
f	O
i	O
(	O
x	O
)	O
=	O
h	O
ix	O
,	O
(	O
b.15	O
)	O
where	O
h	O
is	O
the	O
measurement	O
matrix	O
relating	O
unknown	O
state	O
variables	O
x	O
to	O
measurements	O
˜y	O
.	O
in	O
this	O
case	O
,	O
(	O
b.13	O
)	O
becomes	O
e	O
=	O
(	O
cid:88	O
)	O
i	O
=	O
(	O
cid:88	O
)	O
i	O
(	O
cid:107	O
)	O
˜yi	O
−	O
h	O
ix	O
(	O
cid:107	O
)	O
σ−1	O
i	O
(	O
˜yi	O
−	O
h	O
ix	O
)	O
t	O
ci	O
(	O
˜yi	O
−	O
h	O
ix	O
)	O
,	O
(	O
b.16	O
)	O
which	O
is	O
a	O
simple	O
quadratic	O
form	O
in	O
x	O
,	O
which	O
can	O
be	O
solved	O
using	O
linear	O
least	B
squares	I
(	O
ap-	O
pendix	O
a.2	O
)	O
.	O
when	O
the	O
measurements	O
are	O
non-linear	B
,	O
the	O
system	O
must	O
be	O
solved	O
iteratively	O
using	O
non-linear	B
least	O
squares	O
(	O
appendix	O
a.3	O
)	O
.	O
b.3	O
robust	B
statistics	O
in	O
appendix	O
b.1.1	O
,	O
we	O
assumed	O
that	O
the	O
noise	B
being	O
added	O
to	O
each	O
measurement	O
(	O
b.5	O
)	O
was	O
multivariate	O
gaussian	O
(	O
b.7	O
)	O
.	O
this	O
is	O
an	O
appropriate	O
model	O
if	O
the	O
noise	B
is	O
the	O
result	O
of	O
lots	O
of	O
tiny	O
errors	O
being	O
added	O
together	O
,	O
e.g.	O
,	O
from	O
thermal	O
noise	B
in	O
a	O
silicon	O
imager	O
.	O
in	O
most	O
cases	O
,	O
however	O
,	O
measurements	O
can	O
be	O
contaminated	O
with	O
larger	O
outliers	O
,	O
i.e.	O
,	O
gross	O
failures	O
in	O
the	O
b.3	O
robust	B
statistics	O
761	O
measurement	O
process	O
.	O
examples	B
of	O
such	O
outliers	O
include	O
bad	O
feature	B
matches	O
(	O
section	O
6.1.4	O
)	O
,	O
occlusions	O
in	O
stereo	B
matching	I
(	O
chapter	O
11	O
)	O
,	O
and	O
discontinuities	O
in	O
an	O
otherwise	O
smooth	O
image	B
,	O
depth	B
map	I
,	O
or	O
label	O
image	B
(	O
sections	O
3.7.1	O
and	O
3.7.2	O
)	O
.	O
in	O
such	O
cases	O
,	O
it	O
makes	O
more	O
sense	O
to	O
model	O
the	O
measurement	O
noise	B
with	O
a	O
long-tailed	O
contaminated	O
noise	B
model	O
such	O
as	O
a	O
laplacian	O
.	O
the	O
negative	O
log	O
likelihood	O
in	O
this	O
case	O
,	O
rather	O
than	O
being	O
quadratic	O
in	O
the	O
measurement	O
residuals	O
(	O
b.12–b.16	O
)	O
,	O
has	O
a	O
slower	O
growth	O
in	O
the	O
penalty	O
function	O
to	O
account	O
for	O
the	O
increased	O
likelihood	O
of	O
large	O
errors	O
.	O
this	O
formulation	O
of	O
the	O
inference	B
problem	O
is	O
called	O
an	O
m-estimator	O
in	O
the	O
robust	B
statistics	O
literature	O
(	O
huber	O
1981	O
;	O
hampel	O
,	O
ronchetti	O
,	O
rousseeuw	O
et	O
al	O
.	O
1986	O
;	O
black	O
and	O
rangarajan	O
1996	O
;	O
stewart	O
1999	O
)	O
and	O
involves	O
applying	O
a	O
robust	B
penalty	O
function	O
ρ	O
(	O
r	O
)	O
to	O
the	O
residuals	O
erls	O
(	O
∆p	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
ρ	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
(	O
b.17	O
)	O
instead	O
of	O
squaring	O
them	O
.	O
as	O
we	O
mentioned	O
in	O
section	O
6.1.4	O
,	O
we	O
can	O
take	O
the	O
derivative	O
of	O
this	O
function	O
with	O
respect	O
to	O
p	O
and	O
set	O
it	O
to	O
0	O
,	O
ψ	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
∂	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
∂p	O
(	O
cid:88	O
)	O
i	O
=	O
(	O
cid:88	O
)	O
i	O
ψ	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
rt	O
i	O
∂ri	O
∂p	O
=	O
0	O
,	O
(	O
b.18	O
)	O
where	O
ψ	O
(	O
r	O
)	O
=	O
ρ	O
(	O
cid:48	O
)	O
(	O
r	O
)	O
is	O
the	O
derivative	O
of	O
ρ	O
and	O
is	O
called	O
the	O
inﬂuence	O
function	O
.	O
if	O
we	O
introduce	O
a	O
weight	O
function	O
,	O
w	O
(	O
r	O
)	O
=	O
ψ	O
(	O
r	O
)	O
/r	O
,	O
we	O
observe	O
that	O
ﬁnding	O
the	O
stationary	O
point	O
of	O
(	O
b.17	O
)	O
using	O
(	O
b.18	O
)	O
is	O
equivalent	O
to	O
minimizing	O
the	O
iteratively	O
re-weighted	O
least	B
squares	I
(	O
irls	O
)	O
problem	O
eirls	O
=	O
(	O
cid:88	O
)	O
i	O
w	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
2	O
,	O
(	O
b.19	O
)	O
in	O
(	O
b.12	O
)	O
.	O
black	O
and	O
where	O
the	O
w	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
play	O
the	O
same	O
local	B
weighting	O
role	O
as	O
ci	O
=	O
σ−1	O
anandan	O
(	O
1996	O
)	O
describe	O
a	O
variety	O
of	O
robust	B
penalty	O
functions	O
and	O
their	O
corresponding	O
inﬂu-	O
ence	O
and	O
weighting	B
function	O
.	O
i	O
the	O
irls	O
algorithm	B
alternates	O
between	O
computing	O
the	O
inﬂuence	O
functions	O
w	O
(	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
)	O
and	O
solving	O
the	O
resulting	O
weighted	B
least	O
squares	O
problem	O
(	O
with	O
ﬁxed	O
w	O
values	O
)	O
.	O
alternative	O
in-	O
cremental	O
robust	B
least	O
squares	O
algorithms	O
can	O
be	O
found	O
in	O
the	O
work	O
of	O
sawhney	O
and	O
ayer	O
(	O
1996	O
)	O
;	O
black	O
and	O
anandan	O
(	O
1996	O
)	O
;	O
black	O
and	O
rangarajan	O
(	O
1996	O
)	O
;	O
baker	O
,	O
gross	O
,	O
ishikawa	O
et	O
al	O
.	O
(	O
2003	O
)	O
and	O
textbooks	B
and	O
tutorials	O
on	O
robust	B
statistics	O
(	O
huber	O
1981	O
;	O
hampel	O
,	O
ronchetti	O
,	O
rousseeuw	O
et	O
al	O
.	O
1986	O
;	O
rousseeuw	O
and	O
leroy	O
1987	O
;	O
stewart	O
1999	O
)	O
.	O
it	O
is	O
also	O
possible	O
to	O
ap-	O
ply	O
general	O
optimization	O
techniques	O
(	O
appendix	O
a.3	O
)	O
directly	O
to	O
the	O
non-linear	B
cost	O
function	O
given	O
in	O
equation	B
(	O
b.19	O
)	O
,	O
which	O
may	O
sometimes	O
have	O
better	O
convergence	O
properties	B
.	O
most	O
robust	B
penalty	O
functions	O
involve	O
a	O
scale	O
parameter	O
,	O
which	O
should	O
typically	O
be	O
set	O
to	O
the	O
variance	O
(	O
or	O
standard	O
deviation	O
,	O
depending	O
on	O
the	O
formulation	O
)	O
of	O
the	O
non-contaminated	O
762	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
(	O
inlier	O
)	O
noise	B
.	O
estimating	O
such	O
noise	B
levels	O
directly	O
from	O
the	O
measurements	O
or	O
their	O
residuals	O
,	O
however	O
,	O
can	O
be	O
problematic	O
,	O
as	O
such	O
estimates	O
themselves	O
become	O
contaminated	O
by	O
outliers	O
.	O
the	O
robust	B
statistics	O
literature	O
contains	O
a	O
variety	O
of	O
techniques	O
to	O
estimate	O
such	O
parameters	B
.	O
one	O
of	O
the	O
simplest	O
and	O
most	O
effective	O
is	O
the	O
median	B
absolute	O
deviation	O
(	O
mad	O
)	O
,	O
m	O
ad	O
=	O
medi	O
(	O
cid:107	O
)	O
ri	O
(	O
cid:107	O
)	O
,	O
(	O
b.20	O
)	O
which	O
,	O
when	O
multiplied	O
by	O
1.4	O
,	O
provides	O
a	O
robust	B
estimate	O
of	O
the	O
standard	O
deviation	O
of	O
the	O
inlier	O
noise	B
process	O
.	O
as	O
mentioned	O
in	O
section	O
6.1.4	O
,	O
it	O
is	O
often	O
better	O
to	O
start	O
iterative	B
non-linear	O
minimiza-	O
tion	B
techniques	O
,	O
such	O
as	O
irls	O
,	O
in	O
the	O
vicinity	O
of	O
a	O
good	O
solution	O
by	O
ﬁrst	O
randomly	O
selecting	O
small	O
subsets	O
of	O
measurements	O
until	O
a	O
good	O
set	O
of	O
inliers	B
is	O
found	O
.	O
the	O
best	O
known	O
of	O
these	O
techniques	O
is	O
random	O
sample	O
consensus	O
(	O
ransac	O
)	O
(	O
fischler	O
and	O
bolles	O
1981	O
)	O
,	O
although	O
even	O
better	O
variants	O
such	O
as	O
preemptive	B
ransac	O
(	O
nist´er	O
2003	O
)	O
and	O
progressive	O
sample	O
consensus	O
(	O
prosac	O
)	O
(	O
chum	O
and	O
matas	O
2005	O
)	O
have	O
since	O
been	O
developed	O
.	O
b.4	O
prior	B
models	O
and	O
bayesian	O
inference	B
while	O
maximum	O
likelihood	O
estimation	B
can	O
often	O
lead	O
to	O
good	O
solutions	O
,	O
in	O
some	O
cases	O
the	O
range	O
of	O
possible	O
solutions	O
consistent	O
with	O
the	O
measurements	O
is	O
too	O
large	O
to	O
be	O
useful	O
.	O
for	O
example	O
,	O
consider	O
the	O
problem	O
of	O
image	B
denoising	O
(	O
sections	O
3.4.4	O
and	O
3.7.3	O
)	O
.	O
if	O
we	O
esti-	O
mate	O
each	O
pixel	O
separately	O
based	O
on	O
just	O
its	O
noisy	O
version	O
,	O
we	O
can	O
not	O
make	O
any	O
progress	O
,	O
as	O
there	O
are	O
a	O
large	O
number	O
of	O
values	O
that	O
could	O
lead	O
to	O
each	O
noisy	O
measurement.4	O
instead	O
,	O
we	O
need	O
to	O
rely	O
on	O
typical	O
properties	B
of	O
images	O
,	O
e.g.	O
,	O
that	O
they	O
tend	O
to	O
be	O
piecewise	O
smooth	O
(	O
section	O
3.7.1	O
)	O
.	O
the	O
propensity	O
of	O
images	O
to	O
be	O
piecewise	O
smooth	O
can	O
be	O
encoded	O
in	O
a	O
prior	B
distribution	I
p	O
(	O
x	O
)	O
,	O
which	O
measures	O
the	O
likelihood	O
of	O
an	O
image	B
being	O
a	O
natural	B
image	O
.	O
for	O
example	O
,	O
to	O
encode	O
piecewise	O
smoothness	B
,	O
we	O
can	O
use	O
a	O
markov	O
random	O
ﬁeld	O
model	O
(	O
3.109	O
and	O
b.24	O
)	O
whose	O
negative	O
log	O
likelihood	O
is	O
proportional	O
to	O
a	O
robustiﬁed	O
measure	O
of	O
image	B
smoothness	O
(	O
gradient	O
magnitudes	O
)	O
.	O
prior	B
models	O
need	O
not	O
be	O
restricted	B
to	O
image	B
processing	O
applications	O
.	O
for	O
example	O
,	O
we	O
may	O
have	O
some	O
external	O
knowledge	O
about	O
the	O
rough	O
dimensions	O
of	O
an	O
object	O
being	O
scanned	O
,	O
the	O
focal	O
length	O
of	O
a	O
lens	O
being	O
calibrated	O
,	O
or	O
the	O
likelihood	O
that	O
a	O
particular	O
object	O
might	O
appear	O
in	O
an	O
image	B
.	O
all	O
of	O
these	O
are	O
examples	B
of	O
prior	B
distributions	O
or	O
probabilities	O
and	O
they	O
can	O
be	O
used	O
to	O
produce	O
more	O
reliable	O
estimates	O
.	O
as	O
we	O
have	O
already	O
seen	O
in	O
(	O
3.68	O
)	O
and	O
(	O
3.106	O
)	O
,	O
bayes	O
’	O
rule	O
states	O
that	O
a	O
posterior	O
distribu-	O
tion	B
p	O
(	O
x|y	O
)	O
over	O
the	O
unknowns	O
x	O
given	O
the	O
measurements	O
y	O
can	O
be	O
obtained	O
by	O
multiplying	O
4	O
in	O
fact	O
,	O
the	O
maximum	O
likelihood	O
estimate	O
is	O
just	O
the	O
noisy	O
image	B
itself	O
.	O
b.5	O
markov	O
random	O
ﬁelds	O
the	O
measurement	O
likelihood	O
p	O
(	O
y|x	O
)	O
by	O
the	O
prior	B
distribution	I
p	O
(	O
x	O
)	O
,	O
p	O
(	O
x|y	O
)	O
=	O
p	O
(	O
y|x	O
)	O
p	O
(	O
x	O
)	O
p	O
(	O
y	O
)	O
,	O
763	O
(	O
b.21	O
)	O
where	O
p	O
(	O
y	O
)	O
=	O
(	O
cid:82	O
)	O
x	O
p	O
(	O
y|x	O
)	O
p	O
(	O
x	O
)	O
is	O
a	O
normalizing	B
constant	O
used	O
to	O
make	O
the	O
p	O
(	O
x|y	O
)	O
distribution	O
proper	O
(	O
integrate	O
to	O
1	O
)	O
.	O
taking	O
the	O
negative	O
logarithm	O
of	O
both	O
sides	O
of	O
equation	B
(	O
b.21	O
)	O
,	O
we	O
get	O
−	O
log	O
p	O
(	O
x|y	O
)	O
=	O
−	O
log	O
p	O
(	O
y|x	O
)	O
−	O
log	O
p	O
(	O
x	O
)	O
+	O
log	O
p	O
(	O
y	O
)	O
,	O
(	O
b.22	O
)	O
which	O
is	O
the	O
negative	O
posterior	O
log	O
likelihood	O
.	O
it	O
is	O
common	O
to	O
drop	O
the	O
constant	O
log	O
p	O
(	O
y	O
)	O
be-	O
cause	O
its	O
value	O
does	O
not	O
matter	O
during	O
energy	O
minimization	O
.	O
however	O
,	O
if	O
the	O
prior	B
distribution	I
p	O
(	O
x	O
)	O
depends	O
on	O
some	O
unknown	O
parameters	B
,	O
we	O
may	O
wish	O
to	O
keep	O
log	O
p	O
(	O
y	O
)	O
in	O
order	B
to	O
com-	O
pute	O
the	O
most	O
likely	O
value	O
of	O
these	O
parameters	B
using	O
occam	O
’	O
s	O
razor	O
,	O
i.e.	O
,	O
by	O
maximizing	O
the	O
likelihood	O
of	O
the	O
observations	O
,	O
or	O
to	O
select	O
the	O
correct	O
number	O
of	O
free	O
parameters	B
using	O
model	O
selection	O
(	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
torr	O
2002	O
;	O
bishop	O
2006	O
;	O
robert	O
2007	O
)	O
.	O
to	O
ﬁnd	O
the	O
most	O
likely	O
(	O
maximum	O
a	O
posteriori	O
or	O
map	O
)	O
solution	O
x	O
given	O
some	O
measure-	O
ments	O
y	O
,	O
we	O
simply	O
minimize	O
this	O
negative	O
log	O
likelihood	O
,	O
which	O
can	O
also	O
be	O
thought	O
of	O
as	O
an	O
energy	O
,	O
e	O
(	O
x	O
,	O
y	O
)	O
=	O
ed	O
(	O
x	O
,	O
y	O
)	O
+	O
ep	O
(	O
x	O
)	O
.	O
(	O
b.23	O
)	O
the	O
ﬁrst	O
term	O
ed	O
(	O
x	O
,	O
y	O
)	O
is	O
the	O
data	O
energy	O
or	O
data	O
penalty	O
and	O
measures	O
the	O
negative	O
log	O
likelihood	O
that	O
the	O
measurements	O
y	O
were	O
observed	O
given	O
the	O
unknown	O
state	O
x.	O
the	O
second	O
term	O
ep	O
(	O
x	O
)	O
is	O
the	O
prior	B
energy	O
and	O
it	O
plays	O
a	O
role	O
analogous	O
to	O
the	O
smoothness	B
energy	O
in	O
regularization	B
.	O
note	O
that	O
the	O
map	O
estimate	O
may	O
not	O
always	O
be	O
desirable	O
,	O
since	O
it	O
selects	O
the	O
“	O
peak	O
”	O
in	O
the	O
posterior	B
distribution	I
rather	O
than	O
some	O
more	O
stable	O
statistic	O
such	O
as	O
mse—see	O
the	O
discussion	O
in	O
appendix	O
b.2	O
about	O
loss	O
functions	O
and	O
decision	O
theory	O
.	O
b.5	O
markov	O
random	O
ﬁelds	O
markov	O
random	O
ﬁelds	O
(	O
blake	O
,	O
kohli	O
,	O
and	O
rother	O
2010	O
)	O
are	O
the	O
most	O
popular	O
types	O
of	O
prior	B
model	O
for	O
gridded	O
image-like	O
data,5	O
which	O
include	O
not	O
only	O
regular	O
natural	B
images	O
(	O
sec-	O
tion	B
3.7.2	O
)	O
but	O
also	O
two-dimensional	B
ﬁelds	O
such	O
as	O
optic	O
ﬂow	O
(	O
chapter	O
8	O
)	O
or	O
depth	O
maps	O
(	O
chapter	O
11	O
)	O
,	O
as	O
well	O
as	O
binary	O
ﬁelds	O
,	O
such	O
as	O
segmentations	O
(	O
section	O
5.5	O
)	O
.	O
as	O
we	O
discussed	O
in	O
section	O
3.7.2	O
,	O
the	O
prior	B
probability	O
p	O
(	O
x	O
)	O
for	O
a	O
markov	O
random	O
ﬁeld	O
is	O
a	O
gibbs	O
or	O
boltzmann	O
distribution	O
,	O
whose	O
negative	O
log	O
likelihood	O
(	O
according	O
to	O
the	O
hammer-	O
5	O
alternative	O
formulations	O
include	O
power	O
spectra	O
(	O
section	O
3.4.3	O
)	O
and	O
non-local	O
means	O
(	O
buades	O
,	O
coll	O
,	O
and	O
morel	O
2008	O
)	O
.	O
764	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
figure	O
b.1	O
graphical	O
model	O
for	O
an	O
n4	O
neighborhood	B
markov	O
random	O
ﬁeld	O
.	O
the	O
white	O
circles	O
are	O
the	O
unknowns	O
f	O
(	O
i	O
,	O
j	O
)	O
,	O
while	O
the	O
dark	O
circles	O
are	O
the	O
input	O
data	O
d	O
(	O
i	O
,	O
j	O
)	O
.	O
the	O
sx	O
(	O
i	O
,	O
j	O
)	O
and	O
sy	O
(	O
i	O
,	O
j	O
)	O
black	O
boxes	O
denote	O
arbitrary	O
interaction	O
potentials	O
between	O
adjacent	O
nodes	O
in	O
the	O
random	O
ﬁeld	O
,	O
and	O
the	O
w	O
(	O
i	O
,	O
j	O
)	O
denote	O
the	O
data	O
penalty	O
functions	O
.	O
they	O
are	O
all	O
examples	B
of	O
the	O
general	O
potentials	O
vi	O
,	O
j	O
,	O
k	O
,	O
l	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
,	O
f	O
(	O
k	O
,	O
l	O
)	O
)	O
used	O
in	O
equation	B
(	O
b.24	O
)	O
.	O
sley–clifford	O
theorem	O
)	O
can	O
be	O
written	O
as	O
a	O
sum	O
of	O
pairwise	O
interaction	O
potentials	O
,	O
ep	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
{	O
(	O
i	O
,	O
j	O
)	O
,	O
(	O
k	O
,	O
l	O
)	O
}	O
∈n	O
vi	O
,	O
j	O
,	O
k	O
,	O
l	O
(	O
f	O
(	O
i	O
,	O
j	O
)	O
,	O
f	O
(	O
k	O
,	O
l	O
)	O
)	O
,	O
(	O
b.24	O
)	O
where	O
n	O
(	O
i	O
,	O
j	O
)	O
denotes	O
the	O
neighbors	O
of	O
pixel	O
(	O
i	O
,	O
j	O
)	O
.	O
in	O
the	O
more	O
general	O
case	O
,	O
mrfs	O
can	O
also	O
contain	O
unary	O
potentials	O
,	O
as	O
well	O
as	O
higher-order	O
potentials	O
deﬁned	O
over	O
larger	O
cardinality	O
cliques	B
(	O
kindermann	O
and	O
snell	O
1980	O
;	O
geman	O
and	O
geman	O
1984	O
;	O
bishop	O
2006	O
;	O
potetz	O
and	O
lee	O
2008	O
;	O
kohli	O
,	O
kumar	O
,	O
and	O
torr	O
2009	O
;	O
kohli	O
,	O
ladick´y	O
,	O
and	O
torr	O
2009	O
;	O
rother	O
,	O
kohli	O
,	O
feng	O
et	O
al	O
.	O
2009	O
;	O
alahari	O
,	O
kohli	O
,	O
and	O
torr	O
2011	O
)	O
.	O
they	O
can	O
also	O
contain	O
line	O
processes	O
,	O
i.e.	O
,	O
additional	O
binary	O
variables	O
that	O
mediate	O
discontinuities	O
between	O
adjacent	O
elements	O
(	O
geman	O
and	O
geman	O
1984	O
)	O
.	O
black	O
and	O
rangarajan	O
(	O
1996	O
)	O
show	O
how	O
independent	O
line	B
process	I
variables	O
can	O
be	O
eliminated	O
and	O
incorporated	O
into	O
regular	O
mrfs	O
using	O
robust	O
pairwise	O
penalty	O
functions	O
.	O
the	O
most	O
commonly	O
used	O
neighborhood	B
in	O
markov	O
random	O
ﬁeld	O
modeling	B
is	O
the	O
n4	O
neighborhood	B
,	O
where	O
each	O
pixel	O
in	O
the	O
ﬁeld	O
f	O
(	O
i	O
,	O
j	O
)	O
interacts	O
only	O
with	O
its	O
immediate	O
neighbors—	O
figure	O
b.1	O
shows	O
such	O
an	O
n4	O
mrf	O
.	O
the	O
sx	O
(	O
i	O
,	O
j	O
)	O
and	O
sy	O
(	O
i	O
,	O
j	O
)	O
black	O
boxes	O
denote	O
arbitrary	O
interaction	O
potentials	O
between	O
adjacent	O
nodes	O
in	O
the	O
random	O
ﬁeld	O
and	O
the	O
w	O
(	O
i	O
,	O
j	O
)	O
denote	O
the	O
elemental	O
data	O
penalty	O
terms	O
in	O
ed	O
(	O
b.23	O
)	O
.	O
these	O
square	O
nodes	O
can	O
also	O
be	O
interpreted	O
as	O
fac-	O
tors	O
in	O
a	O
factor	O
graph	O
version	O
of	O
the	O
undirected	O
graphical	O
model	O
(	O
bishop	O
2006	O
;	O
wainwright	O
and	O
jordan	O
2008	O
;	O
koller	O
and	O
friedman	O
2009	O
)	O
,	O
which	O
is	O
another	O
name	O
for	O
interaction	O
poten-	O
tials	O
.	O
(	O
strictly	O
speaking	O
,	O
the	O
factors	O
are	O
improper	O
probability	O
functions	O
whose	O
product	O
is	O
the	O
un-normalized	O
posterior	B
distribution	I
.	O
)	O
more	O
complex	O
and	O
higher-dimensional	O
interaction	O
models	O
and	O
neighborhoods	O
are	O
also	O
f	O
(	O
i	O
,	O
j	O
)	O
sx	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i	O
,	O
j+1	O
)	O
sy	O
(	O
i	O
,	O
j	O
)	O
w	O
(	O
i	O
,	O
j	O
)	O
d	O
(	O
i	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j	O
)	O
f	O
(	O
i+1	O
,	O
j+1	O
)	O
b.5	O
markov	O
random	O
ﬁelds	O
765	O
possible	O
.	O
for	O
example	O
,	O
2d	O
grids	O
can	O
be	O
enhanced	O
with	O
the	O
addition	O
of	O
diagonal	O
connections	O
(	O
an	O
n8	O
neighborhood	B
)	O
or	O
even	O
larger	O
numbers	O
of	O
pairwise	O
terms	O
(	O
boykov	O
and	O
kolmogorov	O
2003	O
;	O
rother	O
,	O
kolmogorov	O
,	O
lempitsky	O
et	O
al	O
.	O
2007	O
)	O
.	O
3d	O
grids	O
can	O
be	O
used	O
to	O
compute	O
glob-	O
ally	O
optimal	O
segmentations	O
in	O
3d	O
volumetric	B
medical	O
images	O
(	O
boykov	O
and	O
funka-lea	O
2006	O
)	O
(	O
section	O
5.5.1	O
)	O
.	O
higher-order	O
cliques	B
can	O
also	O
be	O
used	O
to	O
develop	O
more	O
sophisticated	O
models	O
(	O
potetz	O
and	O
lee	O
2008	O
;	O
kohli	O
,	O
ladick´y	O
,	O
and	O
torr	O
2009	O
;	O
kohli	O
,	O
kumar	O
,	O
and	O
torr	O
2009	O
)	O
.	O
one	O
of	O
the	O
biggest	O
challenges	O
in	O
using	O
mrf	O
models	O
is	O
to	O
develop	O
efﬁcient	O
inference	B
algo-	O
rithms	O
that	O
will	O
ﬁnd	O
low-energy	O
solutions	O
(	O
veksler	O
1999	O
;	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
;	O
kohli	O
2007	O
;	O
kumar	O
2008	O
)	O
.	O
over	O
the	O
years	O
,	O
a	O
large	O
variety	O
of	O
such	O
algorithms	O
have	O
been	O
de-	O
veloped	O
,	O
including	O
simulated	B
annealing	I
,	O
graph	B
cuts	I
,	O
and	O
loopy	B
belief	I
propagation	I
.	O
the	O
choice	O
of	O
inference	B
technique	O
can	O
greatly	O
affect	O
the	O
overall	O
performance	O
of	O
a	O
vision	O
system	O
.	O
for	O
example	O
,	O
most	O
of	O
the	O
top-performing	O
algorithms	O
on	O
the	O
middlebury	O
stereo	B
evaluation	O
page	O
either	O
use	O
belief	B
propagation	I
or	O
graph	B
cuts	I
.	O
in	O
the	O
next	O
few	O
subsections	O
,	O
we	O
review	O
some	O
of	O
the	O
more	O
widely	O
used	O
mrf	O
inference	B
techniques	O
.	O
more	O
in-depth	O
descriptions	O
of	O
most	O
of	O
these	O
algorithms	O
can	O
be	O
found	O
in	O
a	O
re-	O
cently	O
published	O
book	O
on	O
advances	O
in	O
mrf	O
techniques	O
(	O
blake	O
,	O
kohli	O
,	O
and	O
rother	O
2010	O
)	O
.	O
experimental	O
comparisons	O
,	O
along	O
with	O
test	O
datasets	O
and	O
reference	O
software	O
,	O
are	O
provided	O
by	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
(	O
2008	O
)	O
.6	O
b.5.1	O
gradient	B
descent	I
and	O
simulated	B
annealing	I
the	O
simplest	O
optimization	O
technique	O
is	O
gradient	B
descent	I
,	O
which	O
minimizes	O
the	O
energy	O
by	O
changing	O
independent	O
subsets	O
of	O
nodes	O
to	O
take	O
on	O
lower-energy	O
conﬁgurations	O
.	O
such	O
tech-	O
niques	O
go	O
under	O
a	O
variety	O
of	O
names	O
,	O
including	O
contextual	O
classiﬁcation	O
(	O
kittler	O
and	O
f¨oglein	O
1984	O
)	O
and	O
iterated	B
conditional	I
modes	I
(	O
icm	O
)	O
(	O
besag	O
1986	O
)	O
.7	O
variables	O
can	O
either	O
be	O
updated	O
sequentially	O
,	O
e.g.	O
,	O
in	O
raster	O
scan	O
,	O
or	O
in	O
parallel	O
,	O
e.g.	O
,	O
using	O
red–black	O
coloring	O
on	O
a	O
checker-	O
board	O
.	O
chou	O
and	O
brown	O
(	O
1990	O
)	O
suggests	O
using	O
highest	O
conﬁdence	O
ﬁrst	O
(	O
hcf	O
)	O
,	O
i.e.	O
,	O
choosing	O
variables	O
based	O
on	O
how	O
large	O
a	O
difference	B
they	O
make	O
in	O
reducing	O
the	O
energy	O
.	O
the	O
problem	O
with	O
gradient	O
descent	O
is	O
that	O
it	O
is	O
prone	O
to	O
getting	O
stuck	O
in	O
local	B
minima	O
,	O
which	O
is	O
almost	O
always	O
the	O
case	O
with	O
mrf	O
problems	O
.	O
one	O
way	O
around	O
this	O
is	O
to	O
use	O
stochastic	B
gradient	I
descent	I
or	O
markov	O
chain	O
monte	O
carlo	O
(	O
mcmc	O
)	O
(	O
metropolis	O
,	O
rosenbluth	O
,	O
rosen-	O
bluth	O
et	O
al	O
.	O
1953	O
)	O
,	O
i.e.	O
,	O
to	O
randomly	O
take	O
occasional	O
uphill	O
steps	O
in	O
order	B
to	O
get	O
out	O
of	O
such	O
minima	O
.	O
one	O
popular	O
update	B
rule	I
is	O
the	O
gibbs	O
sampler	O
(	O
geman	O
and	O
geman	O
1984	O
)	O
;	O
rather	O
than	O
choosing	O
the	O
lowest	O
energy	O
state	O
for	O
a	O
variable	O
being	O
updated	O
,	O
it	O
chooses	O
the	O
state	O
with	O
6	O
http	O
:	O
//vision.middlebury.edu/mrf/	O
.	O
7	O
the	O
name	O
comes	O
from	O
iteratively	O
setting	O
variables	O
to	O
the	O
mode	O
(	O
most	O
likely	O
,	O
i.e.	O
,	O
lowest	O
energy	O
)	O
state	O
conditioned	O
on	O
its	O
currently	O
ﬁxed	O
neighbors	O
.	O
766	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
probability	O
p	O
(	O
x	O
)	O
∝	O
e−e	O
(	O
x	O
)	O
/t	O
,	O
(	O
b.25	O
)	O
where	O
t	O
is	O
called	O
the	O
temperature	O
and	O
controls	O
how	O
likely	O
the	O
system	O
is	O
to	O
choose	O
a	O
more	O
random	O
update	O
.	O
stochastic	B
gradient	I
descent	I
is	O
usually	O
combined	O
with	O
simulated	O
annealing	O
(	O
kirkpatrick	O
,	O
gelatt	O
,	O
and	O
vecchi	O
1983	O
)	O
,	O
which	O
starts	O
at	O
a	O
relatively	O
high	O
temperature	O
,	O
thereby	O
randomly	O
exploring	O
a	O
large	O
part	O
of	O
the	O
state	O
space	O
,	O
and	O
gradually	O
cools	O
(	O
anneals	O
)	O
the	O
tem-	O
perature	O
to	O
ﬁnd	O
a	O
good	O
local	B
minimum	O
.	O
during	O
the	O
late	O
1980s	O
,	O
simulated	B
annealing	I
was	O
the	O
method	O
of	O
choice	O
for	O
solving	O
mrf	O
inference	B
problems	O
(	O
szeliski	O
1986	O
;	O
marroquin	O
,	O
mitter	O
,	O
and	O
poggio	O
1985	O
;	O
barnard	O
1989	O
)	O
.	O
another	O
variant	O
on	O
simulated	B
annealing	I
is	O
the	O
swendsen–wang	O
algorithm	B
(	O
swendsen	O
and	O
wang	O
1987	O
;	O
barbu	O
and	O
zhu	O
2003	O
,	O
2005	O
)	O
.	O
here	O
,	O
instead	O
of	O
“	O
ﬂipping	O
”	O
(	O
changing	O
)	O
single	O
vari-	O
ables	O
,	O
a	O
connected	O
subset	O
of	O
variables	O
,	O
chosen	O
using	O
a	O
random	O
walk	O
based	O
on	O
mrf	O
connec-	O
tively	O
strengths	O
,	O
is	O
selected	O
as	O
the	O
basic	O
update	O
unit	O
.	O
this	O
can	O
sometimes	O
help	O
make	O
larger	O
state	O
changes	O
,	O
and	O
hence	O
ﬁnd	O
better-quality	O
solutions	O
in	O
less	O
time	O
.	O
while	O
simulated	B
annealing	I
has	O
largely	O
been	O
superseded	O
by	O
the	O
newer	O
graph	B
cuts	I
and	O
loopy	B
belief	I
propagation	I
techniques	O
,	O
it	O
still	O
occasionally	O
ﬁnds	O
use	O
,	O
especially	O
in	O
highly	O
connected	O
and	O
highly	O
non-submodular	O
graphs	O
(	O
rother	O
,	O
kolmogorov	O
,	O
lempitsky	O
et	O
al	O
.	O
2007	O
)	O
.	O
b.5.2	O
dynamic	B
programming	I
dynamic	O
programming	O
(	O
dp	O
)	O
is	O
an	O
efﬁcient	O
inference	B
procedure	O
that	O
works	O
for	O
any	O
tree-	O
structured	O
graphical	O
model	O
,	O
i.e.	O
,	O
one	O
that	O
does	O
not	O
have	O
any	O
cycles	O
.	O
given	O
such	O
a	O
tree	O
,	O
pick	O
any	O
node	O
as	O
the	O
root	O
r	O
and	O
ﬁguratively	O
pick	O
up	O
the	O
tree	O
by	O
its	O
root	O
.	O
the	O
depth	O
or	O
distance	O
of	O
all	O
the	O
other	O
nodes	O
from	O
this	O
root	O
induces	O
a	O
partial	O
ordering	O
over	O
the	O
vertices	O
,	O
from	O
which	O
a	O
total	B
ordering	O
can	O
be	O
obtained	O
by	O
arbitrarily	O
breaking	O
ties	O
.	O
let	O
us	O
now	O
lay	O
out	O
this	O
graph	O
as	O
a	O
tree	O
with	O
the	O
root	O
on	O
the	O
right	O
and	O
indices	O
increasing	O
from	O
left	O
to	O
right	O
,	O
as	O
shown	O
in	O
figure	O
b.2a	O
.	O
before	O
describing	O
the	O
dp	O
algorithm	B
,	O
let	O
us	O
re-write	O
the	O
potential	O
function	O
of	O
equation	B
(	O
b.24	O
)	O
in	O
a	O
more	O
general	O
but	O
succinct	O
form	O
,	O
e	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
(	O
i	O
,	O
j	O
)	O
∈n	O
vi	O
,	O
j	O
(	O
xi	O
,	O
xj	O
)	O
+	O
(	O
cid:88	O
)	O
i	O
vi	O
(	O
xi	O
)	O
,	O
(	O
b.26	O
)	O
where	O
instead	O
of	O
using	O
pixel	O
indices	O
(	O
i	O
,	O
j	O
)	O
and	O
(	O
k	O
,	O
l	O
)	O
,	O
we	O
just	O
use	O
scalar	O
index	O
variables	O
i	O
and	O
j.	O
we	O
also	O
replace	O
the	O
function	O
value	O
f	O
(	O
i	O
,	O
j	O
)	O
with	O
the	O
more	O
succinct	O
notation	O
xi	O
,	O
with	O
the	O
{	O
xi	O
}	O
variables	O
making	O
up	O
the	O
state	O
vector	O
x.	O
we	O
can	O
simplify	O
this	O
function	O
even	O
further	O
by	O
adding	O
dummy	O
nodes	O
(	O
vertices	O
)	O
i−	O
for	O
every	O
node	O
that	O
has	O
a	O
non-zero	O
vi	O
(	O
xi	O
)	O
and	O
setting	O
vi	O
,	O
i−	O
(	O
xi	O
,	O
xi−	O
)	O
=	O
vi	O
(	O
xi	O
)	O
,	O
which	O
lets	O
us	O
drop	O
the	O
vi	O
terms	O
from	O
(	O
b.26	O
)	O
.	O
dynamic	B
programming	I
proceeds	O
by	O
computing	O
partial	O
sums	O
in	O
a	O
left-to-right	O
fashion	O
,	O
i.e.	O
,	O
in	O
order	B
of	O
increasing	O
variable	O
index	O
.	O
let	O
ck	O
be	O
the	O
children	O
of	O
k	O
,	O
i.e.	O
,	O
i	O
<	O
k	O
,	O
(	O
i	O
,	O
k	O
)	O
∈	O
n	O
)	O
.	O
b.5	O
markov	O
random	O
ﬁelds	O
767	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
b.2	O
dynamic	B
programming	I
over	O
a	O
tree	O
drawn	O
as	O
a	O
factor	O
graph	O
.	O
(	O
a	O
)	O
to	O
compute	O
the	O
lowest	O
energy	O
solution	O
ˆek	O
(	O
xk	O
)	O
at	O
node	O
xk	O
conditioned	O
on	O
the	O
best	O
solutions	O
to	O
the	O
left	O
of	O
this	O
node	O
,	O
we	O
enumerate	O
all	O
possible	O
values	O
of	O
ˆei	O
(	O
xi	O
)	O
+	O
vik	O
(	O
xi	O
,	O
xk	O
)	O
and	O
pick	O
the	O
smallest	O
one	O
(	O
and	O
similarly	O
for	O
j	O
)	O
.	O
(	O
b	O
)	O
for	O
higher-order	O
cliques	B
,	O
we	O
need	O
to	O
try	O
all	O
combinations	O
of	O
(	O
xi	O
,	O
xj	O
)	O
in	O
order	B
to	O
select	O
the	O
best	O
possible	O
conﬁguration	O
.	O
the	O
arrows	O
show	O
the	O
basic	O
ﬂow	O
of	O
the	O
computation	O
.	O
the	O
lightly	O
shaded	O
factor	O
vij	O
in	O
(	O
a	O
)	O
shows	O
an	O
additional	O
connection	O
that	O
turns	O
the	O
tree	O
into	O
a	O
cyclic	O
graph	O
,	O
for	O
which	O
exact	O
inference	B
can	O
not	O
be	O
efﬁciently	O
computed	O
.	O
then	O
,	O
deﬁne	O
˜ek	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
i	O
<	O
k	O
,	O
j≤k	O
vi	O
,	O
j	O
(	O
xi	O
,	O
xj	O
)	O
=	O
(	O
cid:88	O
)	O
i∈ck	O
(	O
cid:104	O
)	O
vi	O
,	O
k	O
(	O
xi	O
,	O
xk	O
)	O
+	O
˜ei	O
(	O
x	O
)	O
(	O
cid:105	O
)	O
,	O
(	O
b.27	O
)	O
as	O
a	O
partial	O
sum	O
of	O
(	O
b.26	O
)	O
over	O
all	O
variables	O
up	O
to	O
and	O
including	O
k	O
,	O
i.e.	O
,	O
over	O
all	O
parts	O
of	O
the	O
graph	O
shown	O
in	O
figure	O
b.2a	O
to	O
the	O
left	O
of	O
xk	O
.	O
this	O
sum	O
depends	O
on	O
the	O
state	O
of	O
all	O
the	O
unknown	O
variables	O
in	O
x	O
with	O
i	O
≤	O
k.	O
it	O
turns	O
out	O
that	O
we	O
can	O
use	O
a	O
simple	O
recursive	O
formula	O
now	O
suppose	O
we	O
wish	O
to	O
ﬁnd	O
the	O
setting	O
for	O
all	O
variables	O
i	O
<	O
k	O
that	O
minimizes	O
this	O
sum	O
.	O
ˆek	O
(	O
xk	O
)	O
=	O
min	O
{	O
xi	O
,	O
i	O
<	O
k	O
}	O
˜ek	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
i∈ck	O
min	O
xi	O
(	O
cid:104	O
)	O
vi	O
,	O
k	O
(	O
xi	O
,	O
xk	O
)	O
+	O
ˆei	O
(	O
xi	O
)	O
(	O
cid:105	O
)	O
(	O
b.28	O
)	O
to	O
ﬁnd	O
this	O
minimum	O
.	O
visually	O
,	O
this	O
is	O
easy	O
to	O
understand	O
.	O
looking	O
at	O
figure	O
b.2a	O
,	O
associate	O
an	O
energy	O
ˆek	O
(	O
xk	O
)	O
with	O
each	O
node	O
k	O
and	O
each	O
possible	O
setting	O
of	O
its	O
value	O
xk	O
that	O
is	O
based	O
on	O
the	O
best	O
possible	O
setting	O
of	O
variables	O
to	O
the	O
left	O
of	O
that	O
node	O
.	O
it	O
is	O
easy	O
to	O
convince	O
yourself	O
that	O
in	O
this	O
ﬁgure	O
,	O
you	O
only	O
need	O
to	O
know	O
ˆei	O
(	O
xi	O
)	O
and	O
ˆej	O
(	O
xj	O
)	O
in	O
order	B
to	O
compute	O
this	O
value	O
.	O
once	O
the	O
ﬂow	O
of	O
information	O
in	O
the	O
tree	O
has	O
been	O
processed	O
from	O
left	O
to	O
right	O
,	O
the	O
min-	O
imum	O
value	O
of	O
ˆer	O
(	O
xr	O
)	O
at	O
the	O
root	O
gives	O
the	O
map	O
(	O
lowest-energy	O
)	O
solution	O
for	O
e	O
(	O
x	O
)	O
.	O
the	O
root	O
node	O
is	O
set	O
to	O
the	O
choice	O
of	O
xr	O
that	O
minimizes	O
this	O
function	O
,	O
and	O
other	O
nodes	O
are	O
set	O
in	O
a	O
backward	O
chaining	O
pass	O
by	O
selecting	O
the	O
values	O
of	O
child	O
nodes	O
i	O
∈	O
ck	O
that	O
were	O
minimal	O
in	O
the	O
original	O
recursion	O
(	O
b.28	O
)	O
.	O
xkvikxjxivjk	O
...	O
...	O
...	O
xrvijxkvijkxjxi	O
...	O
...	O
...	O
768	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
dynamic	B
programming	I
is	O
not	O
restricted	B
to	O
trees	O
with	O
pairwise	O
potentials	O
.	O
figure	O
b.2b	O
shows	O
an	O
example	O
of	O
a	O
three-way	O
potential	O
vijk	O
(	O
xi	O
,	O
xj	O
,	O
xk	O
)	O
inside	O
a	O
tree	O
.	O
to	O
compute	O
the	O
optimum	O
value	O
of	O
ˆek	O
(	O
xk	O
)	O
,	O
the	O
recursion	O
formula	O
in	O
(	O
b.28	O
)	O
now	O
has	O
to	O
evaluate	O
the	O
mini-	O
mum	O
over	O
all	O
combinations	O
of	O
possible	O
state	O
values	O
leading	O
into	O
a	O
factor	O
node	O
(	O
gray	O
box	O
)	O
.	O
for	O
this	O
reason	O
,	O
dynamic	B
programming	I
is	O
normally	O
exponential	O
in	O
complexity	O
in	O
the	O
order	B
of	O
the	O
clique	O
size	O
,	O
i.e.	O
,	O
a	O
clique	O
of	O
size	O
n	O
with	O
l	O
labels	O
at	O
each	O
node	O
requires	O
the	O
evaluation	B
of	O
ln−1	O
possible	O
states	O
(	O
potetz	O
and	O
lee	O
2008	O
;	O
kohli	O
,	O
kumar	O
,	O
and	O
torr	O
2009	O
)	O
.	O
however	O
,	O
for	O
certain	O
kinds	O
of	O
potential	O
functions	O
vi	O
,	O
k	O
(	O
xi	O
,	O
xk	O
)	O
,	O
including	O
the	O
potts	O
model	O
(	O
delta	O
function	O
)	O
,	O
absolute	O
values	O
(	O
total	B
variation	I
)	O
,	O
and	O
quadratic	O
(	O
gaussian	O
mrf	O
)	O
,	O
felzenszwalb	O
and	O
hutten-	O
locher	O
(	O
2006	O
)	O
show	O
how	O
to	O
reduce	O
the	O
complexity	O
of	O
the	O
min-ﬁnding	O
step	O
(	O
b.28	O
)	O
from	O
o	O
(	O
l2	O
)	O
to	O
o	O
(	O
l	O
)	O
.	O
in	O
appendix	O
b.5.3	O
,	O
we	O
also	O
discuss	O
how	O
potetz	O
and	O
lee	O
(	O
2008	O
)	O
reduce	O
the	O
complexity	O
for	O
special	O
kinds	O
of	O
higher-order	O
clique	O
,	O
i.e.	O
,	O
linear	B
summations	O
followed	O
by	O
non-linearities	O
.	O
figure	O
b.2a	O
also	O
shows	O
what	O
happens	O
if	O
we	O
add	O
an	O
extra	O
factor	O
between	O
nodes	O
i	O
and	O
j.	O
in	O
this	O
case	O
,	O
the	O
graph	O
is	O
no	O
longer	O
a	O
tree	O
,	O
i.e.	O
,	O
it	O
contains	O
a	O
cycle	O
.	O
it	O
is	O
no	O
longer	O
possible	O
to	O
use	O
the	O
recursion	O
formula	O
(	O
b.28	O
)	O
,	O
since	O
ˆei	O
(	O
xi	O
)	O
now	O
appears	O
in	O
two	O
different	O
terms	O
inside	O
the	O
summation	O
,	O
i.e.	O
,	O
as	O
a	O
child	O
of	O
both	O
nodes	O
j	O
and	O
k	O
,	O
and	O
the	O
same	O
setting	O
for	O
xi	O
may	O
not	O
minimize	O
both	O
.	O
in	O
other	O
words	O
,	O
when	O
loops	O
exist	O
,	O
there	O
is	O
no	O
ordering	O
of	O
the	O
variables	O
that	O
allows	O
the	O
recursion	O
(	O
elimination	O
)	O
in	O
(	O
b.28	O
)	O
to	O
be	O
well-founded	O
.	O
it	O
is	O
,	O
however	O
,	O
possible	O
to	O
convert	O
small	O
loops	O
into	O
higher-order	O
factors	O
and	O
to	O
solve	O
these	O
as	O
shown	O
in	O
figure	O
b.2b	O
.	O
however	O
,	O
graphs	O
with	O
long	O
loops	O
or	O
meshes	O
result	O
in	O
extremely	O
large	O
clique	O
sizes	O
and	O
hence	O
an	O
amount	O
of	O
computation	O
potentially	O
exponential	O
in	O
the	O
size	O
of	O
the	O
graph	O
.	O
b.5.3	O
belief	B
propagation	I
belief	O
propagation	O
is	O
an	O
inference	B
technique	O
originally	O
developed	O
for	O
trees	O
(	O
pearl	O
1988	O
)	O
but	O
more	O
recently	O
extended	O
to	O
“	O
loopy	O
”	O
(	O
cyclic	O
)	O
graphs	O
such	O
as	O
mrfs	O
(	O
frey	O
and	O
mackay	O
1997	O
;	O
freeman	O
,	O
pasztor	O
,	O
and	O
carmichael	O
2000	O
;	O
yedidia	O
,	O
freeman	O
,	O
and	O
weiss	O
2001	O
;	O
weiss	O
and	O
free-	O
man	O
2001a	O
,	O
b	O
;	O
yuille	O
2002	O
;	O
sun	O
,	O
zheng	O
,	O
and	O
shum	O
2003	O
;	O
felzenszwalb	O
and	O
huttenlocher	O
2006	O
)	O
.	O
it	O
is	O
closely	O
related	O
to	O
dynamic	B
programming	I
,	O
in	O
that	O
both	O
techniques	O
pass	O
messages	O
forward	B
and	O
backward	O
over	O
a	O
tree	O
or	O
graph	O
.	O
in	O
fact	O
,	O
one	O
of	O
the	O
two	O
variants	O
of	O
belief	O
prop-	O
agation	O
,	O
the	O
max-product	O
rule	O
,	O
performs	O
the	O
exact	O
same	O
computation	O
(	O
inference	B
)	O
as	O
dynamic	B
programming	I
,	O
albeit	O
using	O
probabilities	O
instead	O
of	O
energies	O
.	O
recall	B
that	O
the	O
energy	O
we	O
are	O
minimizing	O
in	O
map	O
estimation	B
(	O
b.26	O
)	O
is	O
the	O
negative	O
log	O
likelihood	O
(	O
b.12	O
,	O
b.13	O
,	O
and	O
b.22	O
)	O
of	O
a	O
factored	O
gibbs	O
posterior	B
distribution	I
,	O
p	O
(	O
x	O
)	O
=	O
(	O
cid:89	O
)	O
(	O
i	O
,	O
j	O
)	O
∈n	O
φi	O
,	O
j	O
(	O
xi	O
,	O
xj	O
)	O
,	O
(	O
b.29	O
)	O
b.5	O
markov	O
random	O
ﬁelds	O
where	O
are	O
the	O
pairwise	O
interaction	O
potentials	O
.	O
we	O
can	O
rewrite	O
(	O
b.27	O
)	O
as	O
φi	O
,	O
j	O
(	O
xi	O
,	O
xj	O
)	O
=	O
e−vi	O
,	O
j	O
(	O
xi	O
,	O
xj	O
)	O
where	O
˜pk	O
(	O
x	O
)	O
=	O
(	O
cid:89	O
)	O
i	O
<	O
k	O
,	O
j≤k	O
φi	O
,	O
j	O
(	O
xi	O
,	O
xj	O
)	O
=	O
(	O
cid:89	O
)	O
i∈ck	O
˜pi	O
,	O
k	O
(	O
x	O
)	O
,	O
˜pi	O
,	O
k	O
(	O
x	O
)	O
=	O
φi	O
,	O
k	O
(	O
xi	O
,	O
xk	O
)	O
˜pi	O
(	O
x	O
)	O
.	O
we	O
can	O
therefore	O
rewrite	O
(	O
b.28	O
)	O
as	O
with	O
ˆpk	O
(	O
xk	O
)	O
=	O
max	O
{	O
xi	O
,	O
i	O
<	O
k	O
}	O
˜pk	O
(	O
x	O
)	O
=	O
(	O
cid:89	O
)	O
i∈ck	O
ˆpi	O
,	O
k	O
(	O
x	O
)	O
,	O
ˆpi	O
,	O
k	O
(	O
x	O
)	O
=	O
max	O
xi	O
φi	O
,	O
k	O
(	O
xi	O
,	O
xk	O
)	O
ˆpi	O
(	O
x	O
)	O
.	O
769	O
(	O
b.30	O
)	O
(	O
b.31	O
)	O
(	O
b.32	O
)	O
(	O
b.33	O
)	O
(	O
b.34	O
)	O
equation	B
(	O
b.34	O
)	O
is	O
the	O
max	O
update	B
rule	I
evaluated	O
at	O
all	O
square	O
box	O
factors	O
in	O
figure	O
b.2a	O
,	O
while	O
(	O
b.33	O
)	O
is	O
the	O
product	O
rule	O
evaluated	O
at	O
the	O
nodes	O
.	O
the	O
probability	O
distribution	O
ˆpi	O
,	O
k	O
(	O
x	O
)	O
is	O
often	O
interpreted	O
as	O
a	O
message	O
passing	O
information	O
about	O
child	O
i	O
to	O
parent	O
k	O
and	O
is	O
hence	O
written	O
as	O
mi	O
,	O
k	O
(	O
xk	O
)	O
(	O
yedidia	O
,	O
freeman	O
,	O
and	O
weiss	O
2001	O
)	O
or	O
µi→k	O
(	O
xk	O
)	O
(	O
bishop	O
2006	O
)	O
.	O
the	O
max-product	O
rule	O
can	O
be	O
used	O
to	O
compute	O
the	O
map	O
estimate	O
in	O
a	O
tree	O
using	O
the	O
same	O
kind	O
of	O
forward	B
and	O
backward	O
sweep	O
as	O
in	O
dynamic	B
programming	I
(	O
which	O
is	O
sometimes	O
called	O
the	O
max-sum	O
algorithm	B
(	O
bishop	O
2006	O
)	O
)	O
.	O
an	O
alternative	O
rule	O
,	O
known	O
as	O
the	O
sum–product	O
,	O
sums	O
over	O
all	O
possible	O
values	O
in	O
(	O
b.34	O
)	O
rather	O
than	O
taking	O
the	O
maximum	O
,	O
in	O
essence	O
computing	O
the	O
expected	O
distribution	O
rather	O
than	O
the	O
maximum	O
likelihood	O
distribution	O
.	O
this	O
produces	O
a	O
set	O
of	O
probability	O
estimates	O
that	O
can	O
be	O
used	O
to	O
compute	O
the	O
marginal	O
distributions	O
bi	O
(	O
xi	O
)	O
=	O
(	O
cid:80	O
)	O
x\xi	O
p	O
(	O
x	O
)	O
(	O
pearl	O
1988	O
;	O
yedidia	O
,	O
freeman	O
,	O
and	O
weiss	O
2001	O
;	O
bishop	O
2006	O
)	O
.	O
belief	B
propagation	I
may	O
not	O
produce	O
optimal	O
estimates	O
for	O
cyclic	O
graphs	O
for	O
the	O
same	O
reason	O
that	O
dynamic	B
programming	I
fails	O
to	O
work	O
,	O
i.e.	O
,	O
because	O
a	O
node	O
with	O
multiple	O
parents	O
may	O
take	O
on	O
different	O
optimal	O
values	O
for	O
each	O
of	O
the	O
parents	O
,	O
i.e.	O
,	O
there	O
is	O
no	O
unique	O
elim-	O
ination	O
ordering	O
.	O
early	O
algorithms	O
for	O
extending	O
belief	B
propagation	I
to	O
graphs	O
with	O
cycles	O
,	O
dubbed	O
loopy	B
belief	I
propagation	I
,	O
performed	O
the	O
updates	O
in	O
parallel	O
over	O
the	O
graph	O
,	O
i.e.	O
,	O
us-	O
ing	O
synchronous	O
updates	O
(	O
frey	O
and	O
mackay	O
1997	O
;	O
freeman	O
,	O
pasztor	O
,	O
and	O
carmichael	O
2000	O
;	O
yedidia	O
,	O
freeman	O
,	O
and	O
weiss	O
2001	O
;	O
weiss	O
and	O
freeman	O
2001a	O
,	O
b	O
;	O
yuille	O
2002	O
;	O
sun	O
,	O
zheng	O
,	O
and	O
shum	O
2003	O
;	O
felzenszwalb	O
and	O
huttenlocher	O
2006	O
)	O
.	O
for	O
example	O
,	O
felzenszwalb	O
and	O
huttenlocher	O
(	O
2006	O
)	O
split	O
an	O
n4	O
graph	O
into	O
its	O
red	O
and	O
black	O
(	O
checkerboard	O
)	O
components	O
and	O
alternate	O
between	O
sending	O
messages	O
from	O
the	O
red	O
nodes	O
to	O
the	O
black	O
and	O
vice	O
versa	O
.	O
they	O
also	O
use	O
multi-grid	O
(	O
coarser	O
level	O
)	O
updates	O
to	O
speed	O
up	O
the	O
convergence	O
.	O
as	O
discussed	O
previously	O
,	O
to	O
reduce	O
the	O
complexity	O
of	O
the	O
basic	O
max-product	O
770	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
update	B
rule	I
(	O
b.28	O
)	O
from	O
o	O
(	O
l2	O
)	O
to	O
o	O
(	O
l	O
)	O
,	O
they	O
develop	O
specialized	O
update	O
algorithms	O
for	O
sev-	O
eral	O
cost	O
functions	O
vi	O
,	O
k	O
(	O
xi	O
,	O
xk	O
)	O
,	O
including	O
the	O
potts	O
model	O
(	O
delta	O
function	O
)	O
,	O
absolute	O
values	O
(	O
total	B
variation	I
)	O
,	O
and	O
quadratic	O
(	O
gaussian	O
mrf	O
)	O
.	O
a	O
related	O
algorithm	B
,	O
mean	O
ﬁeld	O
diffusion	O
(	O
scharstein	O
and	O
szeliski	O
1998	O
)	O
,	O
also	O
uses	O
synchronous	O
updates	O
between	O
nodes	O
to	O
compute	O
marginal	O
distributions	O
.	O
yuille	O
(	O
2010	O
)	O
discusses	O
the	O
relationships	O
between	O
mean	O
ﬁeld	O
theory	O
and	O
loopy	B
belief	I
propagation	I
.	O
more	O
recent	O
loopy	B
belief	I
propagation	I
algorithms	O
and	O
their	O
variants	O
use	O
sequential	O
scans	O
through	O
the	O
graph	O
(	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
.	O
for	O
example	O
,	O
tappen	O
and	O
free-	O
man	O
(	O
2003	O
)	O
pass	O
messages	O
from	O
left	O
to	O
right	O
along	O
each	O
row	O
and	O
then	O
reverse	O
the	O
direction	O
once	O
they	O
reach	O
the	O
end	O
.	O
this	O
is	O
similar	O
to	O
treating	O
each	O
row	O
as	O
an	O
independent	O
tree	O
(	O
chain	O
)	O
,	O
except	O
that	O
messages	O
from	O
nodes	O
above	O
and	O
below	O
the	O
row	O
are	O
also	O
incorporated	O
.	O
they	O
then	O
perform	O
similar	O
computations	O
along	O
columns	O
.	O
these	O
sequential	O
updates	O
allow	O
the	O
information	O
to	O
propagate	O
much	O
more	O
quickly	O
across	O
the	O
image	B
than	O
synchronous	O
updates	O
.	O
the	O
other	O
belief	B
propagation	I
variant	O
tested	O
by	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
(	O
2008	O
)	O
,	O
which	O
they	O
call	O
bp-s	O
or	O
trw-s	O
,	O
is	O
based	O
on	O
kolmogorov	O
’	O
s	O
(	O
2006	O
)	O
sequential	O
extension	O
of	O
the	O
tree-reweighted	O
message	O
passing	O
of	O
wainwright	O
,	O
jaakkola	O
,	O
and	O
willsky	O
(	O
2005	O
)	O
.	O
trw	O
ﬁrst	O
selects	O
a	O
set	O
of	O
trees	O
from	O
the	O
neighborhood	B
graph	O
and	O
computes	O
a	O
set	O
of	O
probability	O
distributions	O
over	O
each	O
tree	O
.	O
these	O
are	O
then	O
used	O
to	O
reweight	O
the	O
messages	O
being	O
passed	O
during	O
loopy	B
belief	I
propagation	I
.	O
the	O
sequential	O
version	O
of	O
trw	O
,	O
called	O
trw-s	O
,	O
processed	O
nodes	O
in	O
scan-line	O
order	B
,	O
with	O
a	O
forward	B
and	O
backward	O
pass	O
.	O
in	O
the	O
forward	B
pass	O
,	O
each	O
node	O
sends	O
messages	O
to	O
its	O
right	O
and	O
bottom	O
neighbors	O
.	O
in	O
the	O
backward	O
pass	O
,	O
messages	O
are	O
sent	O
to	O
the	O
left	O
and	O
upper	O
neighbors	O
.	O
trw-s	O
also	O
computes	O
a	O
lower	O
bound	O
on	O
the	O
energy	O
,	O
which	O
is	O
used	O
by	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
(	O
2008	O
)	O
to	O
estimate	O
how	O
close	O
to	O
the	O
best	O
possible	O
solution	O
all	O
of	O
the	O
mrf	O
inference	B
algorithms	O
being	O
evaluated	O
get	O
.	O
as	O
with	O
dynamic	O
programming	O
,	O
belief	B
propagation	I
techniques	O
also	O
become	O
less	O
efﬁcient	O
as	O
the	O
order	B
of	O
each	O
factor	O
clique	O
increases	O
.	O
potetz	O
and	O
lee	O
(	O
2008	O
)	O
shows	O
how	O
this	O
complex-	O
ity	O
can	O
be	O
reduced	O
back	O
to	O
linear	B
in	O
the	O
clique	O
order	B
for	O
continuous-valued	O
problems	O
where	O
the	O
factors	O
involve	O
linear	B
summations	O
followed	O
by	O
a	O
non-linearity	O
,	O
which	O
is	O
typical	O
of	O
more	O
sophisticated	O
mrf	O
models	O
such	O
as	O
ﬁelds	O
of	O
experts	O
(	O
roth	O
and	O
black	O
2009	O
)	O
and	O
steerable	B
ran-	O
dom	O
ﬁelds	O
(	O
roth	O
and	O
black	O
2007b	O
)	O
.	O
kohli	O
,	O
kumar	O
,	O
and	O
torr	O
(	O
2009	O
)	O
and	O
alahari	O
,	O
kohli	O
,	O
and	O
torr	O
(	O
2011	O
)	O
develop	O
alternative	O
ways	O
for	O
dealing	O
with	O
higher-order	O
cliques	B
in	O
the	O
context	B
of	O
graph	B
cut	I
algorithms	O
.	O
b.5.4	O
graph	B
cuts	I
the	O
computer	O
vision	O
community	O
has	O
adopted	O
“	O
graph	B
cuts	I
”	O
as	O
an	O
informal	O
name	O
to	O
describe	O
a	O
large	O
family	O
of	O
mrf	O
inference	B
algorithms	O
based	O
on	O
solving	O
one	O
or	O
more	O
min-cut	O
or	O
max-	O
ﬂow	O
problems	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
;	O
boykov	O
and	O
kolmogorov	O
2010	O
;	O
boykov	O
,	O
b.5	O
markov	O
random	O
ﬁelds	O
771	O
(	O
a	O
)	O
(	O
b	O
)	O
figure	O
b.3	O
graph	B
cuts	I
for	O
minimizing	O
binary	O
sub-modular	O
mrf	O
energies	O
(	O
boykov	O
and	O
jolly	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
energy	O
function	O
encoded	O
as	O
a	O
max	O
ﬂow	O
problem	O
;	O
(	O
b	O
)	O
the	O
minimum	O
cut	O
determines	O
the	O
region	B
boundary	O
.	O
veksler	O
,	O
and	O
zabih	O
2010	O
;	O
ishikawa	O
and	O
veksler	O
2010	O
)	O
.	O
the	O
simplest	O
example	O
of	O
an	O
mrf	O
graph	B
cut	I
is	O
the	O
polynomial-time	O
algorithm	B
for	O
perform-	O
ing	O
exact	O
minimization	O
of	O
a	O
binary	O
mrf	O
originally	O
developed	O
by	O
greig	O
,	O
porteous	O
,	O
and	O
seheult	O
(	O
1989	O
)	O
and	O
brought	O
to	O
the	O
attention	O
of	O
the	O
computer	O
vision	O
community	O
by	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
(	O
2001	O
)	O
and	O
boykov	O
and	O
jolly	O
(	O
2001	O
)	O
.	O
the	O
basic	O
construction	O
of	O
the	O
min-cut	O
graph	O
from	O
an	O
mrf	O
energy	O
function	O
is	O
shown	O
in	O
figure	O
b.3	O
and	O
described	O
in	O
sections	O
3.7.2	O
and	O
5.5.	O
in	O
brief	O
,	O
the	O
nodes	O
in	O
an	O
mrf	O
are	O
connected	O
to	O
special	O
source	O
and	O
sink	O
nodes	O
,	O
and	O
the	O
minimum	O
cut	O
between	O
these	O
two	O
nodes	O
,	O
whose	O
cost	O
is	O
exactly	O
that	O
of	O
the	O
mrf	O
energy	O
un-	O
der	O
a	O
binary	O
assignment	O
of	O
labels	O
,	O
is	O
computed	O
using	O
a	O
polynomial-time	O
max	O
ﬂow	O
algorithm	B
(	O
goldberg	O
and	O
tarjan	O
1988	O
;	O
boykov	O
and	O
kolmogorov	O
2004	O
)	O
.	O
as	O
discussed	O
in	O
section	O
5.5	O
,	O
important	O
extensions	O
of	O
this	O
basic	O
algorithm	B
have	O
been	O
made	O
for	O
the	O
case	O
of	O
directed	B
edges	I
(	O
kolmogorov	O
and	O
boykov	O
2005	O
)	O
,	O
larger	O
neighborhoods	O
(	O
boykov	O
and	O
kolmogorov	O
2003	O
;	O
kolmogorov	O
and	O
boykov	O
2005	O
)	O
,	O
connectivity	O
priors	O
(	O
vicente	O
,	O
kol-	O
mogorov	O
,	O
and	O
rother	O
2008	O
)	O
,	O
and	O
shape	B
priors	I
(	O
lempitsky	O
and	O
boykov	O
2007	O
;	O
lempitsky	O
,	O
blake	O
,	O
and	O
rother	O
2008	O
)	O
.	O
kolmogorov	O
and	O
zabih	O
(	O
2004	O
)	O
formally	O
characterize	O
the	O
class	O
of	O
binary	O
energy	O
potentials	O
(	O
regularity	O
conditions	O
)	O
for	O
which	O
these	O
algorithms	O
ﬁnd	O
the	O
global	B
minimum	O
.	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
(	O
2008	O
)	O
and	O
rother	O
,	O
kolmogorov	O
,	O
lempitsky	O
et	O
al	O
.	O
(	O
2007	O
)	O
provide	O
good	O
algorithms	O
for	O
the	O
cases	O
when	O
they	O
do	O
not	O
.	O
binary	O
mrf	O
problems	O
can	O
also	O
be	O
approximately	O
solved	O
by	O
turning	O
them	O
into	O
continuous	O
[	O
0	O
,	O
1	O
]	O
problems	O
,	O
solving	O
them	O
either	O
as	O
linear	B
systems	O
(	O
grady	O
2006	O
;	O
sinop	O
and	O
grady	O
2007	O
;	O
grady	O
and	O
alvino	O
2008	O
;	O
grady	O
2008	O
;	O
grady	O
and	O
ali	O
2008	O
;	O
singaraju	O
,	O
grady	O
,	O
and	O
vidal	O
2008	O
;	O
couprie	O
,	O
grady	O
,	O
najman	O
et	O
al	O
.	O
2009	O
)	O
(	O
the	O
random	B
walker	I
model	O
)	O
or	O
by	O
computing	O
geodesic	O
objectterminal	O
terminalbackground	O
pqrwvstbackground	O
object	O
terminalterminalpqrwvstcut	O
772	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
distances	O
(	O
bai	O
and	O
sapiro	O
2009	O
;	O
criminisi	O
,	O
sharp	O
,	O
and	O
blake	O
2008	O
)	O
and	O
then	O
thresholding	B
the	O
results	O
.	O
more	O
details	O
on	O
these	O
techniques	O
are	O
provided	O
in	O
section	O
5.5	O
and	O
a	O
nice	O
review	O
can	O
be	O
found	O
in	O
the	O
work	O
of	O
singaraju	O
,	O
grady	O
,	O
sinop	O
et	O
al	O
.	O
(	O
2010	O
)	O
.	O
a	O
different	O
connection	O
to	O
continuous	O
segmentation	B
techniques	O
,	O
this	O
time	O
to	O
the	O
literature	O
on	O
level	B
sets	I
(	O
section	O
5.1.4	O
)	O
,	O
is	O
made	O
by	O
boykov	O
,	O
kolmogorov	O
,	O
cremers	O
et	O
al	O
.	O
(	O
2006	O
)	O
,	O
who	O
develop	O
an	O
approach	O
to	O
solving	O
surface	B
propagation	O
pdes	O
based	O
on	O
combinatorial	O
graph	B
cut	I
algorithms—boykov	O
and	O
funka-	O
lea	O
(	O
2006	O
)	O
discuss	O
this	O
and	O
related	O
techniques	O
.	O
multi-valued	O
mrf	O
inference	B
problems	O
usually	O
require	O
solving	O
a	O
series	O
of	O
related	O
binary	O
mrf	O
problems	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
,	O
although	O
for	O
special	O
cases	O
,	O
such	O
as	O
some	O
convex	O
functions	O
,	O
a	O
single	O
graph	O
cut	O
may	O
sufﬁce	O
(	O
ishikawa	O
2003	O
;	O
schlesinger	O
and	O
flach	O
2006	O
)	O
.	O
the	O
seminal	O
work	O
in	O
this	O
area	O
is	O
that	O
of	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
(	O
2001	O
)	O
,	O
who	O
intro-	O
duced	O
two	O
algorithms	O
,	O
called	O
the	O
swap	O
move	O
and	O
the	O
expansion	B
move	I
,	O
which	O
are	O
sketched	O
in	O
figure	O
b.4	O
.	O
the	O
α–β-swap	O
move	O
selects	O
two	O
labels	O
(	O
usually	O
by	O
cycling	O
through	O
all	O
possible	O
pairings	O
)	O
and	O
then	O
formulates	O
a	O
binary	O
mrf	O
problem	O
that	O
allows	O
any	O
pixels	O
currently	O
labeled	O
as	O
either	O
α	O
or	O
β	O
to	O
optionally	O
switch	O
their	O
values	O
to	O
the	O
other	O
label	O
.	O
the	O
α-expansion	O
move	O
allows	O
any	O
pixel	O
in	O
the	O
mrf	O
to	O
take	O
on	O
the	O
α	O
label	O
or	O
to	O
keep	O
its	O
current	O
identity	O
.	O
it	O
is	O
easy	O
to	O
see	O
by	O
inspection	O
that	O
both	O
of	O
these	O
moves	O
result	O
in	O
binary	O
mrfs	O
with	O
well-deﬁned	O
energy	O
functions	O
.	O
because	O
these	O
algorithms	O
use	O
a	O
binary	O
mrf	O
optimization	O
inside	O
their	O
inner	O
loop	O
,	O
they	O
are	O
subject	O
to	O
the	O
constraints	O
on	O
the	O
energy	O
functions	O
that	O
occur	O
in	O
the	O
binary	O
labeling	O
case	O
(	O
kolmogorov	O
and	O
zabih	O
2004	O
)	O
.	O
however	O
,	O
more	O
recent	O
algorithms	O
such	O
as	O
those	O
developed	O
by	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
(	O
2008	O
)	O
and	O
rother	O
,	O
kolmogorov	O
,	O
lempitsky	O
et	O
al	O
.	O
(	O
2007	O
)	O
can	O
be	O
used	O
to	O
provide	O
approximate	O
solutions	O
for	O
more	O
general	O
energy	O
functions	O
.	O
efﬁcient	O
algorithms	O
for	O
re-using	O
previous	O
solutions	O
(	O
ﬂow-	O
and	O
cut-recycling	O
)	O
have	O
been	O
developed	O
for	O
on-line	O
applications	O
such	O
as	O
dynamic	B
mrfs	O
(	O
kohli	O
and	O
torr	O
2005	O
;	O
juan	O
and	O
boykov	O
2006	O
;	O
alahari	O
,	O
kohli	O
,	O
and	O
torr	O
2011	O
)	O
and	O
coarse-to-ﬁne	B
banded	O
graph	B
cuts	I
(	O
agarwala	O
,	O
zheng	O
,	O
pal	O
et	O
al	O
.	O
2005	O
;	O
lombaert	O
,	O
sun	O
,	O
grady	O
et	O
al	O
.	O
2005	O
;	O
juan	O
and	O
boykov	O
2006	O
)	O
.	O
it	O
is	O
also	O
now	O
possible	O
to	O
minimize	O
the	O
number	O
of	O
labels	O
used	O
as	O
part	O
of	O
the	O
alpha-expansion	O
process	O
(	O
delong	O
,	O
osokin	O
,	O
isack	O
et	O
al	O
.	O
2010	O
)	O
.	O
in	O
experimental	O
comparisons	O
,	O
α-expansions	O
usually	O
converge	O
faster	O
to	O
a	O
good	O
solution	O
than	O
α–β-swaps	O
(	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
,	O
especially	O
for	O
problems	O
that	O
in-	O
volve	O
large	O
regions	O
of	O
identical	O
labels	O
,	O
such	O
as	O
the	O
labeling	O
of	O
source	O
imagery	O
in	O
image	B
stitch-	O
ing	O
(	O
figure	O
3.60	O
)	O
.	O
for	O
truncated	O
convex	O
energy	O
functions	O
deﬁned	O
over	O
ordinal	O
values	O
,	O
more	O
accurate	O
algorithms	O
that	O
consider	O
complete	O
ranges	O
of	O
labels	O
inside	O
each	O
min-cut	O
and	O
often	O
produce	O
lower	O
energies	O
have	O
been	O
developed	O
(	O
veksler	O
2007	O
;	O
kumar	O
and	O
torr	O
2008	O
;	O
kumar	O
,	O
veksler	O
,	O
and	O
torr	O
2010	O
)	O
.	O
the	O
whole	O
ﬁeld	O
of	O
efﬁcient	O
mrf	O
inference	B
algorithms	O
is	O
rapidly	O
developing	O
,	O
as	O
witnessed	O
by	O
a	O
recent	O
special	O
journal	O
issue	O
(	O
kohli	O
and	O
torr	O
2008	O
;	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
2008	O
;	O
olsson	O
,	O
eriksson	O
,	O
and	O
kahl	O
2008	O
;	O
potetz	O
and	O
lee	O
2008	O
)	O
,	O
articles	O
b.5	O
markov	O
random	O
ﬁelds	O
773	O
(	O
a	O
)	O
initial	O
labeling	O
(	O
b	O
)	O
standard	O
move	O
(	O
c	O
)	O
α-β-swap	O
(	O
d	O
)	O
α-expansion	O
figure	O
b.4	O
multi-level	O
graph	O
optimization	O
from	O
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
c	O
(	O
cid:13	O
)	O
2001	O
ieee	O
:	O
(	O
a	O
)	O
initial	O
problem	O
conﬁguration	O
;	O
(	O
b	O
)	O
the	O
standard	O
move	O
changes	O
only	O
one	O
pixel	O
;	O
(	O
c	O
)	O
the	O
α–β-swap	O
optimally	O
exchanges	O
all	O
α-	O
and	O
β-labeled	O
pixels	O
;	O
(	O
d	O
)	O
the	O
α-expansion	O
move	O
optimally	O
selects	O
among	O
current	O
pixel	O
values	O
and	O
the	O
α	O
label	O
.	O
(	O
alahari	O
,	O
kohli	O
,	O
and	O
torr	O
2011	O
)	O
,	O
and	O
a	O
forthcoming	O
book	O
(	O
blake	O
,	O
kohli	O
,	O
and	O
rother	O
2010	O
)	O
.	O
b.5.5	O
linear	O
programming	O
8	O
many	O
successful	O
algorithms	O
for	O
mrf	O
optimization	O
are	O
based	O
on	O
the	O
linear	O
programming	O
(	O
lp	O
)	O
relaxation	O
of	O
the	O
energy	O
function	O
(	O
weiss	O
,	O
yanover	O
,	O
and	O
meltzer	O
2010	O
)	O
.	O
for	O
some	O
prac-	O
tical	O
mrf	O
problems	O
,	O
lp-based	O
techniques	O
can	O
produce	O
globally	O
minimal	O
solutions	O
(	O
meltzer	O
,	O
yanover	O
,	O
and	O
weiss	O
2005	O
)	O
,	O
even	O
though	O
mrf	O
inference	B
is	O
in	O
general	O
np-hard	O
.	O
in	O
order	B
to	O
describe	O
this	O
relaxation	O
,	O
let	O
us	O
ﬁrst	O
rewrite	O
the	O
energy	O
function	O
(	O
b.26	O
)	O
as	O
e	O
(	O
x	O
)	O
=	O
(	O
cid:88	O
)	O
(	O
i	O
,	O
j	O
)	O
∈n	O
=	O
(	O
cid:88	O
)	O
i	O
,	O
j	O
,	O
α	O
,	O
β	O
subject	O
to	O
xi	O
;	O
α	O
=	O
(	O
cid:88	O
)	O
β	O
xj	O
;	O
β	O
=	O
(	O
cid:88	O
)	O
α	O
xi	O
,	O
α	O
,	O
xi	O
,	O
j	O
;	O
α	O
,	O
β	O
∈	O
{	O
0	O
,	O
1	O
}	O
.	O
vi	O
(	O
xi	O
)	O
vi	O
,	O
j	O
(	O
xi	O
,	O
xj	O
)	O
+	O
(	O
cid:88	O
)	O
i	O
vi	O
,	O
j	O
(	O
α	O
,	O
β	O
)	O
xi	O
,	O
j	O
;	O
α	O
,	O
β	O
+	O
(	O
cid:88	O
)	O
i	O
,	O
α	O
xi	O
,	O
j	O
;	O
α	O
,	O
β	O
∀	O
(	O
i	O
,	O
j	O
)	O
∈	O
n	O
,	O
α	O
,	O
xi	O
,	O
j	O
;	O
α	O
,	O
β	O
∀	O
(	O
i	O
,	O
j	O
)	O
∈	O
n	O
,	O
β	O
,	O
vi	O
(	O
α	O
)	O
xi	O
;	O
α	O
and	O
(	O
b.35	O
)	O
(	O
b.36	O
)	O
(	O
b.37	O
)	O
(	O
b.38	O
)	O
(	O
b.39	O
)	O
here	O
,	O
α	O
and	O
β	O
range	O
over	O
label	O
values	O
and	O
xi	O
;	O
α	O
=	O
δ	O
(	O
xi−	O
α	O
)	O
and	O
xij	O
;	O
αβ	O
=	O
δ	O
(	O
xi−	O
α	O
)	O
δ	O
(	O
xj	O
−	O
β	O
)	O
are	O
indicator	O
variables	O
of	O
assignments	O
xi	O
=	O
α	O
and	O
(	O
xi	O
,	O
xj	O
)	O
=	O
(	O
α	O
,	O
β	O
)	O
,	O
respectively	O
.	O
the	O
lp	O
relaxation	O
is	O
obtained	O
by	O
replacing	O
the	O
discreteness	O
constraints	O
(	O
b.39	O
)	O
with	O
linear	O
constraints	O
xij	O
;	O
αβ	O
∈	O
[	O
0	O
,	O
1	O
]	O
.	O
it	O
is	O
easy	O
to	O
show	O
that	O
the	O
optimal	O
value	O
of	O
(	O
b.36	O
)	O
is	O
a	O
lower	O
bound	O
on	O
(	O
b.26	O
)	O
.	O
8	O
this	O
section	O
was	O
contributed	O
by	O
vladimir	O
kolmogorov	O
.	O
thanks	O
!	O
774	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
this	O
relaxation	O
has	O
been	O
extensively	O
studied	O
in	O
the	O
literature	O
,	O
starting	O
with	O
the	O
work	O
of	O
schlesinger	O
(	O
1976	O
)	O
.	O
an	O
important	O
question	O
is	O
how	O
to	O
solve	O
this	O
lp	O
efﬁciently	O
.	O
unfortunately	O
,	O
general-purpose	O
lp	O
solvers	O
can	O
not	O
handle	O
large	O
problems	O
in	O
vision	O
(	O
yanover	O
,	O
meltzer	O
,	O
and	O
weiss	O
2006	O
)	O
.	O
a	O
large	O
number	O
of	O
customized	O
iterative	B
techniques	O
have	O
been	O
proposed	O
.	O
most	O
of	O
these	O
solve	O
the	O
dual	O
problem	O
,	O
i.e.	O
,	O
they	O
formulate	O
a	O
lower	O
bound	O
on	O
(	O
b.36	O
)	O
and	O
then	O
try	O
to	O
maximize	O
this	O
bound	O
.	O
the	O
bound	O
is	O
often	O
formulated	O
using	O
a	O
convex	O
combination	O
of	O
trees	O
,	O
as	O
proposed	O
in	O
(	O
wainwright	O
,	O
jaakkola	O
,	O
and	O
willsky	O
2005	O
)	O
.	O
the	O
lp	O
lower	O
bound	O
can	O
be	O
maximized	O
via	O
a	O
number	O
of	O
techniques	O
,	O
such	O
as	O
max-sum	O
dif-	O
fusion	O
(	O
werner	O
2007	O
)	O
,	O
tree-reweighted	O
message	O
passing	O
(	O
trw	O
)	O
(	O
wainwright	O
,	O
jaakkola	O
,	O
and	O
willsky	O
2005	O
;	O
kolmogorov	O
2006	O
)	O
,	O
subgradient	O
methods	O
(	O
schlesinger	O
and	O
giginyak	O
2007a	O
,	O
b	O
;	O
komodakis	O
,	O
paragios	O
,	O
and	O
tziritas	O
2007	O
)	O
,	O
and	O
bregman	O
projections	B
(	O
ravikumar	O
,	O
agarwal	O
,	O
and	O
wainwright	O
2008	O
)	O
.	O
note	O
that	O
the	O
max-sum	O
diffusion	O
and	O
trw	O
algorithms	O
are	O
not	O
guar-	O
anteed	O
to	O
converge	O
to	O
a	O
global	B
maximum	O
of	O
lp—they	O
may	O
get	O
stuck	O
at	O
a	O
suboptimal	O
point	O
(	O
kolmogorov	O
2006	O
;	O
werner	O
2007	O
)	O
.	O
however	O
,	O
in	O
practice	O
,	O
this	O
does	O
not	O
appear	O
to	O
be	O
a	O
problem	O
(	O
kolmogorov	O
2006	O
)	O
.	O
for	O
some	O
vision	O
applications	O
,	O
algorithms	O
based	O
on	O
relaxation	O
(	O
b.36	O
)	O
produce	O
excellent	O
results	O
.	O
however	O
,	O
this	O
is	O
not	O
guaranteed	O
in	O
all	O
cases—after	O
all	O
,	O
the	O
problem	O
is	O
np-hard	O
.	O
recently	O
,	O
researchers	O
have	O
investigated	O
alternative	O
linear	O
programming	O
relaxations	O
(	O
sontag	O
and	O
jaakkola	O
2007	O
;	O
sontag	O
,	O
meltzer	O
,	O
globerson	O
et	O
al	O
.	O
2008	O
;	O
komodakis	O
and	O
paragios	O
2008	O
;	O
schraudolph	O
2010	O
)	O
.	O
these	O
algorithms	O
are	O
capable	O
of	O
producing	O
tighter	O
bounds	O
compared	O
to	O
(	O
b.36	O
)	O
at	O
the	O
expense	O
of	O
additional	O
computational	O
cost	O
.	O
lp	O
relaxation	O
and	O
alpha	B
expansion	I
.	O
solving	O
a	O
linear	B
program	O
produces	O
primal	O
and	O
dual	O
solutions	O
that	O
satisfy	O
complementary	O
slackness	O
conditions	O
.	O
in	O
general	O
,	O
the	O
primal	O
solution	O
of	O
(	O
b.36	O
)	O
does	O
not	O
have	O
to	O
be	O
integer-valued	O
so	O
,	O
in	O
practice	O
,	O
we	O
may	O
have	O
to	O
round	O
it	O
to	O
obtain	O
a	O
valid	O
labeling	O
x.	O
an	O
alternative	O
proposed	O
by	O
komodakis	O
and	O
tziritas	O
(	O
2007a	O
)	O
;	O
ko-	O
modakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
(	O
2007	O
)	O
is	O
to	O
search	O
for	O
primal	O
and	O
dual	O
solutions	O
such	O
that	O
they	O
satisfy	O
approximate	O
complementary	O
slackness	O
conditions	O
and	O
the	O
primal	O
solution	O
is	O
al-	O
ready	O
integer-valued	O
.	O
several	O
max-ﬂow-based	O
algorithms	O
are	O
proposed	O
by	O
(	O
komodakis	O
and	O
tziritas	O
2007a	O
;	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
2007	O
)	O
for	O
this	O
purpose	O
and	O
the	O
fast-pd	O
method	O
(	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
2007	O
)	O
is	O
shown	O
to	O
perform	O
best	O
.	O
in	O
the	O
case	O
of	O
metric	O
interactions	O
,	O
the	O
default	O
version	O
of	O
fast-pd	O
produces	O
the	O
same	O
primal	O
solution	O
as	O
the	O
alpha-expansion	O
algorithm	B
(	O
boykov	O
,	O
veksler	O
,	O
and	O
zabih	O
2001	O
)	O
.	O
this	O
provides	O
an	O
interesting	O
interpretation	O
of	O
the	O
alpha	B
expansion	I
algorithm	O
as	O
trying	O
to	O
approximately	O
solve	O
relaxation	O
(	O
b.36	O
)	O
.	O
unlike	O
the	O
standard	O
alpha	O
expansion	O
algorithm	O
,	O
fast-pd	O
also	O
maintains	O
a	O
dual	O
solution	O
and	O
thus	O
runs	O
faster	O
in	O
practice	O
.	O
fast-pd	O
can	O
be	O
extended	O
to	O
the	O
case	O
of	O
semi-metric	O
interac-	O
tions	O
(	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
2007	O
)	O
.	O
the	O
primal	O
version	O
of	O
such	O
extension	O
was	O
b.6	O
uncertainty	B
estimation	O
(	O
error	O
analysis	O
)	O
775	O
also	O
given	O
by	O
rother	O
,	O
kumar	O
,	O
kolmogorov	O
et	O
al	O
.	O
(	O
2005	O
)	O
.	O
b.6	O
uncertainty	B
estimation	O
(	O
error	O
analysis	O
)	O
in	O
addition	O
to	O
computing	O
the	O
most	O
likely	O
estimate	O
,	O
many	O
applications	O
require	O
an	O
estimate	O
for	O
the	O
uncertainty	B
in	O
this	O
estimate.9	O
the	O
most	O
general	O
way	O
to	O
do	O
this	O
is	O
to	O
compute	O
a	O
complete	O
probability	O
distribution	O
over	O
all	O
of	O
the	O
unknowns	O
but	O
this	O
is	O
generally	O
intractable	O
.	O
the	O
one	O
spe-	O
cial	O
case	O
where	O
it	O
is	O
easy	O
to	O
obtain	O
a	O
simple	O
description	O
for	O
this	O
distribution	O
is	O
linear	B
estimation	O
problems	O
with	O
gaussian	O
noise	B
,	O
where	O
the	O
joint	B
energy	O
function	O
(	O
negative	O
log	O
likelihood	O
of	O
the	O
posterior	O
estimate	O
)	O
is	O
a	O
quadratic	O
.	O
in	O
this	O
case	O
,	O
the	O
posterior	B
distribution	I
is	O
a	O
multi-variate	O
gaussian	O
and	O
the	O
covariance	O
can	O
be	O
computed	O
directly	O
from	O
the	O
inverse	B
of	O
the	O
problem	O
hes-	O
sian	O
.	O
(	O
another	O
name	O
for	O
the	O
inverse	B
covariance	O
matrix	O
,	O
which	O
is	O
equal	O
to	O
the	O
hessian	O
in	O
such	O
simple	O
cases	O
,	O
is	O
the	O
information	O
matrix	O
.	O
)	O
even	O
here	O
,	O
however	O
,	O
the	O
full	O
covariance	O
matrix	O
may	O
be	O
too	O
large	O
to	O
compute	O
and	O
store	O
.	O
for	O
example	O
,	O
in	O
large	O
structure	O
from	O
motion	B
problems	O
,	O
a	O
large	O
sparse	O
hessian	O
normally	O
results	O
in	O
a	O
full	O
dense	O
covariance	O
matrix	O
.	O
in	O
such	O
cases	O
,	O
it	O
is	O
often	O
considered	O
acceptable	O
to	O
report	O
only	O
the	O
variance	O
in	O
the	O
estimated	O
quantities	O
or	O
simple	O
covariance	O
estimates	O
on	O
individual	O
parameters	B
,	O
such	O
as	O
3d	O
point	O
positions	O
or	O
camera	B
pose	O
estimates	O
(	O
szeliski	O
1990a	O
)	O
.	O
more	O
insight	O
into	O
the	O
problem	O
,	O
e.g.	O
,	O
the	O
dominant	O
modes	O
of	O
uncertainty	B
,	O
can	O
be	O
obtained	O
using	O
eigenvalue	O
analysis	O
(	O
szeliski	O
and	O
kang	O
1997	O
)	O
.	O
for	O
problems	O
where	O
the	O
posterior	O
energy	O
is	O
non-quadratic	O
,	O
e.g.	O
,	O
in	O
non-linear	B
or	O
robustiﬁed	O
least	B
squares	I
,	O
it	O
is	O
still	O
often	O
possible	O
to	O
obtain	O
an	O
estimate	O
of	O
the	O
hessian	O
in	O
the	O
vicinity	O
of	O
the	O
optimal	O
solution	O
.	O
in	O
this	O
case	O
,	O
the	O
cramer–rao	O
lower	O
bound	O
on	O
the	O
uncertainty	B
(	O
covariance	O
)	O
can	O
be	O
computed	O
as	O
the	O
inverse	B
of	O
the	O
hessian	O
.	O
another	O
way	O
of	O
saying	O
this	O
is	O
that	O
while	O
the	O
local	B
hessian	O
can	O
underestimate	O
how	O
“	O
wide	O
”	O
the	O
energy	O
function	O
can	O
be	O
,	O
the	O
covariance	O
can	O
never	O
be	O
smaller	O
than	O
the	O
estimate	O
based	O
on	O
this	O
local	B
quadratic	O
approximation	O
.	O
it	O
is	O
also	O
possible	O
to	O
estimate	O
a	O
different	O
kind	O
of	O
uncertainty	B
(	O
min-marginal	O
energies	O
)	O
in	O
general	O
mrfs	O
where	O
the	O
map	O
inference	B
is	O
performed	O
using	O
graph	O
cuts	O
(	O
kohli	O
and	O
torr	O
2008	O
)	O
.	O
while	O
many	O
computer	O
vision	O
applications	O
ignore	O
uncertainty	B
modeling	I
,	O
it	O
is	O
often	O
useful	O
to	O
compute	O
these	O
estimates	O
just	O
to	O
get	O
an	O
intuitive	O
feeling	O
for	O
the	O
reliability	O
of	O
the	O
estimates	O
.	O
certain	O
applications	O
,	O
such	O
as	O
kalman	O
ﬁltering	O
,	O
require	O
the	O
computation	O
of	O
this	O
uncertainty	B
(	O
either	O
explicitly	O
as	O
posterior	O
covariances	O
or	O
implicitly	O
as	O
inverse	B
covariances	O
)	O
in	O
order	B
to	O
optimally	O
integrate	O
new	O
measurements	O
with	O
previously	O
computed	O
estimates	O
.	O
9	O
this	O
is	O
particularly	O
true	O
of	O
classic	O
photogrammetry	B
applications	O
,	O
where	O
the	O
reporting	O
of	O
precision	B
is	O
almost	O
always	O
considered	O
mandatory	O
(	O
f¨orstner	O
2005	O
)	O
.	O
776	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
appendix	O
c	O
supplementary	O
material	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
c.1	O
data	B
sets	I
.	O
c.2	O
software	O
.	O
.	O
c.3	O
slides	O
and	O
lectures	O
.	O
c.4	O
bibliography	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
778	O
.	O
.	O
780	O
.	O
.	O
789	O
.	O
790	O
.	O
778	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
in	O
this	O
ﬁnal	O
appendix	O
,	O
i	O
summarize	O
some	O
of	O
the	O
supplementary	O
materials	O
that	O
may	O
be	O
use-	O
ful	O
to	O
students	O
,	O
instructors	O
,	O
and	O
researchers	O
.	O
the	O
book	O
’	O
s	O
web	O
site	O
at	O
http	O
:	O
//szeliski.org/book	O
contains	O
updated	O
lists	O
of	O
datasets	O
and	O
software	O
,	O
so	O
please	O
check	O
there	O
as	O
well	O
.	O
c.1	O
data	B
sets	I
one	O
of	O
the	O
keys	O
to	O
developing	O
reliable	O
vision	O
algorithms	O
is	O
to	O
test	O
your	O
procedures	O
on	O
chal-	O
lenging	O
and	O
representative	O
data	B
sets	I
.	O
when	O
ground	O
truth	O
or	O
other	O
people	O
’	O
s	O
results	O
are	O
available	O
,	O
such	O
test	O
can	O
be	O
even	O
more	O
informative	O
(	O
and	O
quantitative	O
)	O
.	O
over	O
the	O
years	O
,	O
a	O
large	O
number	O
of	O
datasets	O
have	O
been	O
developed	O
for	O
testing	O
and	O
evaluating	O
computer	O
vision	O
algorithms	O
.	O
a	O
number	O
of	O
these	O
datasets	O
(	O
and	O
software	O
)	O
are	O
indexed	O
on	O
the	O
computer	O
vision	O
homepage.1	O
some	O
newer	O
web	O
sites	O
,	O
such	O
as	O
cvonline	O
(	O
http	O
:	O
//homepages	O
.	O
inf.ed.ac.uk/rbf/cvonline/	O
)	O
,	O
visionbib.com	O
(	O
http	O
:	O
//datasets.visionbib.com/	O
)	O
,	O
and	O
computer	O
vision	O
online	O
(	O
http	O
:	O
//computervisiononline.com/	O
)	O
,	O
have	O
more	O
recent	O
pointers	O
.	O
below	O
,	O
i	O
list	O
some	O
of	O
the	O
more	O
popular	O
data	B
sets	I
,	O
grouped	O
by	O
the	O
book	O
chapters	O
to	O
which	O
they	O
most	O
closely	O
correspond	O
:	O
chapter	O
2	O
:	O
image	B
formation	O
curet	O
:	O
columbia-utrecht	O
reﬂectance	B
and	O
texture	B
database	O
,	O
http	O
:	O
//www1.cs.columbia	O
.	O
edu/cave/software/curet/	O
(	O
dana	O
,	O
van	O
ginneken	O
,	O
nayar	O
et	O
al	O
.	O
1999	O
)	O
.	O
middlebury	O
color	B
datasets	O
:	O
registered	O
color	B
images	O
taken	O
by	O
different	O
cameras	O
to	O
study	O
how	O
they	O
transform	B
gamuts	O
and	O
colors	O
,	O
http	O
:	O
//vision.middlebury.edu/color/data/	O
(	O
chakrabarti	O
,	O
scharstein	O
,	O
and	O
zickler	O
2009	O
)	O
.	O
chapter	O
3	O
:	O
image	B
processing	O
middlebury	O
test	O
datasets	O
for	O
evaluating	O
mrf	O
minimization/inference	O
algorithms	O
,	O
http	O
:	O
//vision.middlebury.edu/mrf/results/	O
(	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
.	O
chapter	O
4	O
:	O
feature	B
detection	O
and	O
matching	B
afﬁne	O
covariant	O
features	O
database	O
for	O
evaluating	O
feature	B
detector	O
and	O
descriptor	O
match-	O
ing	O
quality	O
and	O
repeatability	B
,	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/research/afﬁne/	O
(	O
miko-	O
lajczyk	O
and	O
schmid	O
2005	O
;	O
mikolajczyk	O
,	O
tuytelaars	O
,	O
schmid	O
et	O
al	O
.	O
2005	O
)	O
.	O
database	O
of	O
matched	O
image	B
patches	O
for	O
learning	O
and	O
feature	B
descriptor	O
evaluation	B
,	O
http	O
:	O
//cvlab.epﬂ.ch/∼brown/patchdata/patchdata.html	O
(	O
winder	O
and	O
brown	O
2007	O
;	O
hua	O
,	O
brown	O
,	O
and	O
winder	O
2007	O
)	O
.	O
1	O
http	O
:	O
//www.cs.cmu.edu/∼cil/vision.html	O
,	O
although	O
it	O
has	O
not	O
been	O
maintained	O
since	O
2004.	O
c.1	O
data	B
sets	I
chapter	O
5	O
:	O
segmentation	B
779	O
berkeley	O
segmentation	B
dataset	O
and	O
benchmark	O
of	O
1000	O
images	O
labeled	O
by	O
30	O
humans	O
,	O
along	O
with	O
an	O
evaluation	B
,	O
http	O
:	O
//www.eecs.berkeley.edu/research/projects/cs/vision/	O
grouping/segbench/	O
(	O
martin	O
,	O
fowlkes	O
,	O
tal	O
et	O
al	O
.	O
2001	O
)	O
.	O
weizmann	O
segmentation	B
evaluation	O
database	O
of	O
100	O
grayscale	O
images	O
with	O
ground	O
truth	O
segmentations	O
,	O
http	O
:	O
//www.wisdom.weizmann.ac.il/∼vision/seg	O
evaluation	B
db/	O
index.html	O
(	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
2007	O
)	O
.	O
chapter	O
8	O
:	O
dense	O
motion	O
estimation	B
the	O
middlebury	O
optic	O
ﬂow	O
evaluation	B
web	O
site	O
,	O
http	O
:	O
//vision.middlebury.edu/ﬂow/data	O
(	O
baker	O
,	O
scharstein	O
,	O
lewis	O
et	O
al	O
.	O
2009	O
)	O
.	O
the	O
human-assisted	O
motion	B
annotation	O
database	O
,	O
http	O
:	O
//people.csail.mit.edu/celiu/motionannotation/	O
(	O
liu	O
,	O
freeman	O
,	O
adelson	O
et	O
al	O
.	O
2008	O
)	O
chapter	O
10	O
:	O
computational	O
photography	O
high	B
dynamic	I
range	I
radiance	O
maps	O
,	O
http	O
:	O
//www.debevec.org/research/hdr/	O
(	O
de-	O
bevec	O
and	O
malik	O
1997	O
)	O
.	O
alpha	O
matting	O
evaluation	B
web	O
site	O
,	O
http	O
:	O
//alphamatting.com/	O
(	O
rhemann	O
,	O
rother	O
,	O
wang	O
et	O
al	O
.	O
2009	O
)	O
.	O
chapter	O
11	O
:	O
stereo	B
correspondence	O
middlebury	O
stereo	B
datasets	O
and	O
evaluation	B
,	O
http	O
:	O
//vision.middlebury.edu/stereo/	O
(	O
scharstein	O
and	O
szeliski	O
2002	O
)	O
.	O
stereo	B
classiﬁcation	O
and	O
performance	O
evaluation	O
of	O
different	O
aggregation	O
costs	O
for	O
stereo	O
matching	B
,	O
http	O
:	O
//www.vision.deis.unibo.it/spe/spehome.aspx	O
(	O
tombari	O
,	O
mat-	O
toccia	O
,	O
di	O
stefano	O
et	O
al	O
.	O
2008	O
)	O
.	O
middlebury	O
multi-view	B
stereo	I
datasets	O
,	O
http	O
:	O
//vision.middlebury.edu/mview/data/	O
(	O
seitz	O
,	O
curless	O
,	O
diebel	O
et	O
al	O
.	O
2006	O
)	O
.	O
multi-view	B
and	O
oxford	O
colleges	O
building	O
reconstructions	O
,	O
http	O
:	O
//www.robots.ox.ac.uk/	O
∼vgg/data/data-mview.html	O
.	O
multi-view	B
stereo	I
datasets	O
,	O
http	O
:	O
//cvlab.epﬂ.ch/data/strechamvs/	O
(	O
strecha	O
,	O
fransens	O
,	O
and	O
van	O
gool	O
2006	O
)	O
.	O
780	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
multi-view	B
evaluation	O
,	O
http	O
:	O
//cvlab.epﬂ.ch/∼strecha/multiview/	O
(	O
strecha	O
,	O
von	O
hansen	O
,	O
van	O
gool	O
et	O
al	O
.	O
2008	O
)	O
.	O
chapter	O
12	O
:	O
3d	O
reconstruction	O
humaneva	O
:	O
synchronized	O
video	B
and	O
motion	B
capture	O
dataset	O
for	O
evaluation	O
of	O
artic-	O
ulated	O
human	B
motion	I
,	O
http	O
:	O
//vision.cs.brown.edu/humaneva/	O
(	O
sigal	O
,	O
balan	O
,	O
and	O
black	O
2010	O
)	O
.	O
chapter	O
13	O
:	O
image-based	B
rendering	I
the	O
(	O
new	O
)	O
stanford	O
light	O
field	O
archive	O
,	O
http	O
:	O
//lightﬁeld.stanford.edu/	O
(	O
wilburn	O
,	O
joshi	O
,	O
vaish	O
et	O
al	O
.	O
2005	O
)	O
.	O
virtual	B
viewpoint	I
video	I
:	O
multi-viewpoint	O
video	B
with	O
per-frame	O
depth	O
maps	O
,	O
http	O
:	O
//research.microsoft.com/en-us/um/redmond/groups/ivm/vvv/	O
(	O
zitnick	O
,	O
kang	O
,	O
uytten-	O
daele	O
et	O
al	O
.	O
2004	O
)	O
.	O
chapter	O
14	O
:	O
recognition	B
for	O
a	O
list	O
of	O
visual	O
recognition	O
datasets	O
,	O
see	O
tables	O
14.1–14.2	O
.	O
in	O
addition	O
to	O
those	O
,	O
there	O
are	O
also	O
:	O
buffy	O
pose	O
classes	O
,	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/data/buffy	O
pose	O
classes/	O
and	O
buffy	O
stickmen	O
v2.1	O
,	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/data/stickmen/index.html	O
(	O
ferrari	O
,	O
marin-	O
jimenez	O
,	O
and	O
zisserman	O
2009	O
;	O
eichner	O
and	O
ferrari	O
2009	O
)	O
.	O
h3d	O
database	O
of	O
pose/joint	O
annotated	O
photographs	O
of	O
humans	O
,	O
http	O
:	O
//www.eecs.berkeley	O
.	O
edu/∼lbourdev/h3d/	O
(	O
bourdev	O
and	O
malik	O
2009	O
)	O
.	O
action	O
recognition	B
datasets	O
,	O
http	O
:	O
//www.cs.berkeley.edu/projects/vision/action	O
,	O
has	O
point-	O
ers	O
to	O
several	O
datasets	O
for	O
action	O
and	O
activity	B
recognition	I
,	O
as	O
well	O
as	O
some	O
papers	O
.	O
the	O
human	O
action	O
database	O
at	O
http	O
:	O
//www.nada.kth.se/cvap/actions/	O
contains	O
more	O
action	O
sequences	O
.	O
c.2	O
software	O
one	O
of	O
the	O
best	O
sources	O
for	O
computer	O
vision	O
algorithms	O
is	O
the	O
open	O
source	O
computer	O
vision	O
(	O
opencv	O
)	O
library	O
(	O
http	O
:	O
//opencv.willowgarage.com/wiki/	O
)	O
,	O
which	O
was	O
developed	O
by	O
gary	O
bradski	O
and	O
his	O
colleagues	O
at	O
intel	O
and	O
is	O
now	O
being	O
maintained	O
and	O
extended	O
at	O
willow	O
garage	O
(	O
bradsky	O
and	O
kaehler	O
2008	O
)	O
.	O
a	O
partial	O
list	O
of	O
the	O
available	O
functions	O
,	O
taken	O
from	O
http	O
:	O
//opencv.willowgarage.com/documentation/cpp/	O
includes	O
:	O
c.2	O
software	O
781	O
•	O
image	B
processing	O
and	O
transforms	O
(	O
ﬁltering	O
,	O
morphology	O
,	O
pyramids	O
)	O
;	O
•	O
geometric	B
image	O
transformations	O
(	O
rotations	O
,	O
resizing	O
)	O
;	O
•	O
miscellaneous	O
image	B
transformations	O
(	O
fourier	O
transforms	O
,	O
distance	O
transforms	O
)	O
;	O
•	O
histograms	O
;	O
•	O
segmentation	B
(	O
watershed	B
,	O
mean	B
shift	I
)	O
;	O
•	O
feature	B
detection	O
(	O
canny	O
,	O
harris	O
,	O
hough	O
,	O
mser	O
,	O
surf	O
)	O
;	O
•	O
motion	B
analysis	O
and	O
object	O
tracking	O
(	O
lucas–kanade	O
,	O
mean	B
shift	I
)	O
;	O
•	O
camera	B
calibration	O
and	O
3d	O
reconstruction	O
;	O
•	O
machine	O
learning	O
(	O
k	O
nearest	O
neighbors	O
,	O
support	B
vector	I
machines	I
,	O
decision	O
trees	O
,	O
boost-	O
ing	O
,	O
random	O
trees	O
,	O
expectation-maximization	O
,	O
and	O
neural	B
networks	I
)	O
.	O
the	O
intel	O
performance	O
primitives	O
(	O
ipp	O
)	O
library	O
,	O
http	O
:	O
//software.intel.com/en-us/intel-ipp/	O
,	O
contains	O
highly	O
optimized	O
code	O
for	O
a	O
variety	O
of	O
image	B
processing	O
tasks	O
.	O
many	O
of	O
the	O
routines	O
in	O
opencv	O
take	O
advantage	O
of	O
this	O
library	O
,	O
if	O
it	O
is	O
installed	O
,	O
to	O
run	O
even	O
faster	O
.	O
in	O
terms	O
of	O
functionality	O
,	O
it	O
has	O
many	O
of	O
the	O
same	O
operators	O
as	O
those	O
found	O
in	O
opencv	O
,	O
plus	O
additional	O
libraries	O
for	O
image	O
and	O
video	B
compression	I
,	O
signal	O
and	O
speech	O
processing	O
,	O
and	O
matrix	O
algebra	O
.	O
the	O
matlab	O
image	B
processing	O
toolbox	O
,	O
http	O
:	O
//www.mathworks.com/products/image/	O
,	O
contains	O
routines	O
for	O
spatial	O
transformations	O
(	O
rotations	O
,	O
resizing	O
)	O
,	O
normalized	B
cross-correla-	O
tion	B
,	O
image	B
analysis	O
and	O
statistics	O
(	O
edges	O
,	O
hough	O
transform	B
)	O
,	O
image	B
enhancement	O
(	O
adaptive	B
histogram	O
equalization	O
,	O
median	B
ﬁltering	O
)	O
and	O
restoration	O
(	O
deblurring	O
)	O
,	O
linear	B
ﬁltering	O
(	O
con-	O
volution	O
)	O
,	O
image	B
transforms	O
(	O
fourier	O
and	O
dct	O
)	O
,	O
and	O
morphological	O
operations	O
(	O
connected	B
components	I
and	O
distance	O
transforms	O
)	O
.	O
two	O
older	O
libraries	O
,	O
which	O
no	O
longer	O
appear	O
to	O
be	O
under	O
active	O
development	O
but	O
contain	O
many	O
useful	O
routines	O
,	O
are	O
vxl	O
(	O
c++	O
libraries	O
for	O
computer	O
vision	O
research	O
and	O
implemen-	O
tation	O
,	O
http	O
:	O
//vxl.sourceforge.net/	O
)	O
and	O
lti-lib	O
2	O
(	O
http	O
:	O
//www.ie.itcr.ac.cr/palvarado/ltilib-2/	O
homepage/	O
)	O
.	O
photo	O
editing	O
and	O
viewing	O
packages	O
,	O
such	O
as	O
windows	O
live	O
photo	O
gallery	O
,	O
iphoto	O
,	O
picasa	O
,	O
gimp	O
,	O
and	O
irfanview	O
,	O
can	O
be	O
useful	O
for	O
performing	O
common	O
processing	O
tasks	O
,	O
converting	O
for-	O
mats	O
,	O
and	O
viewing	O
your	O
results	O
.	O
they	O
can	O
also	O
serve	O
as	O
interesting	O
reference	O
implementations	O
for	O
image	O
processing	O
algorithms	O
(	O
such	O
as	O
tone	O
correction	O
or	O
denoising	O
)	O
that	O
you	O
are	O
trying	O
to	O
develop	O
from	O
scratch	O
.	O
there	O
are	O
also	O
software	O
packages	O
and	O
infrastructure	O
that	O
can	O
be	O
helpful	O
for	O
building	O
real-	O
time	O
video	O
processing	O
demos	O
.	O
vision	O
on	O
tap	O
(	O
http	O
:	O
//www.visionontap.com/	O
)	O
provides	O
a	O
web	O
782	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
service	O
that	O
will	O
process	O
your	O
webcam	O
video	B
in	O
real	O
time	O
(	O
chiu	O
and	O
raskar	O
2009	O
)	O
.	O
video-	O
man	O
(	O
videomanager	O
,	O
http	O
:	O
//videomanlib.sourceforge.net/	O
)	O
can	O
be	O
useful	O
for	O
getting	O
real-time	O
video-based	O
demos	O
and	O
applications	O
running	O
.	O
you	O
can	O
also	O
use	O
imread	O
in	O
matlab	O
to	O
read	O
directly	O
from	O
any	O
url	O
,	O
such	O
as	O
a	O
webcam	O
.	O
below	O
,	O
i	O
list	O
some	O
additional	O
software	O
that	O
can	O
be	O
found	O
on	O
the	O
web	O
,	O
grouped	O
by	O
the	O
book	O
chapters	O
to	O
which	O
they	O
most	O
correspond	O
:	O
chapter	O
3	O
:	O
image	B
processing	O
matlabpyrtools—matlab	O
source	O
code	O
for	O
laplacian	O
pyramids	O
,	O
qmf/wavelets	O
,	O
and	O
steerable	B
pyramids	O
,	O
http	O
:	O
//www.cns.nyu.edu/∼lcv/software.php	O
(	O
simoncelli	O
and	O
adel-	O
son	O
1990a	O
;	O
simoncelli	O
,	O
freeman	O
,	O
adelson	O
et	O
al	O
.	O
1992	O
)	O
.	O
bls-gsm	O
image	B
denoising	O
,	O
http	O
:	O
//decsai.ugr.es/∼javier/denoise/	O
(	O
portilla	O
,	O
strela	O
,	O
wain-	O
wright	O
et	O
al	O
.	O
2003	O
)	O
.	O
fast	O
bilateral	O
ﬁltering	O
code	O
,	O
http	O
:	O
//people.csail.mit.edu/jiawen/	O
#	O
code	O
(	O
chen	O
,	O
paris	O
,	O
and	O
durand	O
2007	O
)	O
.	O
c++	O
implementation	O
of	O
the	O
fast	O
distance	O
transform	B
algorithm	O
,	O
http	O
:	O
//people.cs.uchicago	O
.	O
edu/∼pff/dt/	O
(	O
felzenszwalb	O
and	O
huttenlocher	O
2004a	O
)	O
.	O
greyc	O
’	O
s	O
magic	O
image	B
converter	O
,	O
including	O
image	B
restoration	I
software	O
using	O
regular-	O
ization	O
and	O
anisotropic	B
diffusion	O
,	O
http	O
:	O
//gmic.sourceforge.net/gimp.shtml	O
(	O
tschumperl´e	O
and	O
deriche	O
2005	O
)	O
.	O
chapter	O
4	O
:	O
feature	B
detection	O
and	O
matching	B
vlfeat	O
,	O
an	O
open	O
and	O
portable	O
library	O
of	O
computer	O
vision	O
algorithms	O
,	O
http	O
:	O
//vlfeat.org/	O
(	O
vedaldi	O
and	O
fulkerson	O
2008	O
)	O
.	O
siftgpu	O
:	O
a	O
gpu	O
implementation	O
of	O
scale	O
invariant	O
feature	B
transform	O
(	O
sift	O
)	O
,	O
http	O
:	O
//www.cs.unc.edu/∼ccwu/siftgpu/	O
(	O
wu	O
2010	O
)	O
.	O
surf	O
:	O
speeded	O
up	O
robust	O
features	O
,	O
http	O
:	O
//www.vision.ee.ethz.ch/∼surf/	O
(	O
bay	O
,	O
tuyte-	O
laars	O
,	O
and	O
van	O
gool	O
2006	O
)	O
.	O
fast	O
corner	O
detection	B
,	O
http	O
:	O
//mi.eng.cam.ac.uk/∼er258/work/fast.html	O
(	O
rosten	O
and	O
drum-	O
mond	O
2005	O
,	O
2006	O
)	O
.	O
linux	O
binaries	O
for	O
afﬁne	O
region	B
detectors	O
and	O
descriptors	O
,	O
as	O
well	O
as	O
matlab	O
ﬁles	O
to	O
compute	O
repeatability	B
and	O
matching	B
scores	O
,	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/research/	O
afﬁne/	O
.	O
c.2	O
software	O
783	O
kanade–lucas–tomasi	O
feature	B
trackers	O
:	O
klt	O
,	O
http	O
:	O
//www.ces.clemson.edu/∼stb/klt/	O
(	O
shi	O
and	O
tomasi	O
1994	O
)	O
;	O
gpu-klt	O
,	O
http	O
:	O
//cs.unc.edu/∼cmzach/opensource.html	O
(	O
zach	O
,	O
gallup	O
,	O
and	O
frahm	O
2008	O
)	O
;	O
and	O
lucas–kanade	O
20	O
years	O
on	O
,	O
http	O
:	O
//www.ri.cmu.edu/	O
projects/project	O
515.html	O
(	O
baker	O
and	O
matthews	O
2004	O
)	O
.	O
chapter	O
5	O
:	O
segmentation	B
efﬁcient	O
graph-based	B
image	O
segmentation	B
,	O
http	O
:	O
//people.cs.uchicago.edu/∼pff/segment/	O
(	O
felzenszwalb	O
and	O
huttenlocher	O
2004b	O
)	O
.	O
edison	O
,	O
edge	O
detection	O
and	O
image	B
segmentation	O
,	O
http	O
:	O
//coewww.rutgers.edu/riul/research/	O
code/edison/	O
(	O
meer	O
and	O
georgescu	O
2001	O
;	O
comaniciu	O
and	O
meer	O
2002	O
)	O
.	O
normalized	B
cuts	I
segmentation	O
including	O
intervening	O
contours	O
,	O
http	O
:	O
//www.cis.upenn	O
.	O
edu/∼jshi/software/	O
(	O
shi	O
and	O
malik	O
2000	O
;	O
malik	O
,	O
belongie	O
,	O
leung	O
et	O
al	O
.	O
2001	O
)	O
.	O
segmentation	B
by	O
weighted	O
aggregation	O
(	O
swa	O
)	O
,	O
http	O
:	O
//www.cs.weizmann.ac.il/∼vision/	O
swa/	O
(	O
alpert	O
,	O
galun	O
,	O
basri	O
et	O
al	O
.	O
2007	O
)	O
.	O
chapter	O
6	O
:	O
feature-based	B
alignment	O
and	O
calibration	B
non-iterative	O
pnp	O
algorithm	B
,	O
http	O
:	O
//cvlab.epﬂ.ch/software/epnp/	O
(	O
moreno-noguer	O
,	O
lep-	O
etit	O
,	O
and	O
fua	O
2007	O
)	O
.	O
tsai	O
camera	B
calibration	O
software	O
,	O
http	O
:	O
//www-2.cs.cmu.edu/∼rgw/tsaicode.html	O
(	O
tsai	O
1987	O
)	O
.	O
easy	O
camera	B
calibration	O
toolkit	O
,	O
http	O
:	O
//research.microsoft.com/en-us/um/people/zhang/	O
calib/	O
(	O
zhang	O
2000	O
)	O
.	O
camera	B
calibration	O
toolbox	O
for	O
matlab	O
,	O
http	O
:	O
//www.vision.caltech.edu/bouguetj/	O
calib	O
doc/	O
;	O
a	O
c	O
version	O
is	O
included	O
in	O
opencv	O
.	O
matlab	O
functions	O
for	O
multiple	O
view	O
geometry	O
,	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/hzbook/	O
code/	O
(	O
hartley	O
and	O
zisserman	O
2004	O
)	O
.	O
chapter	O
7	O
:	O
structure	B
from	I
motion	I
sba	O
:	O
a	O
generic	O
sparse	B
bundle	O
adjustment	O
c/c++	O
package	O
based	O
on	O
the	O
levenberg–	O
marquardt	O
algorithm	B
,	O
http	O
:	O
//www.ics.forth.gr/∼lourakis/sba/	O
(	O
lourakis	O
and	O
argyros	O
2009	O
)	O
.	O
simple	O
sparse	B
bundle	O
adjustment	O
(	O
ssba	O
)	O
,	O
http	O
:	O
//cs.unc.edu/∼cmzach/opensource.html	O
.	O
784	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
bundler	O
,	O
structure	B
from	I
motion	I
for	O
unordered	O
image	B
collections	O
,	O
http	O
:	O
//phototour.cs	O
.	O
washington.edu/bundler/	O
(	O
snavely	O
,	O
seitz	O
,	O
and	O
szeliski	O
2006	O
)	O
.	O
chapter	O
8	O
:	O
dense	O
motion	O
estimation	B
optical	O
ﬂow	O
software	O
,	O
http	O
:	O
//www.cs.brown.edu/∼black/code.html	O
(	O
black	O
and	O
anan-	O
dan	O
1996	O
)	O
.	O
optical	B
ﬂow	I
using	O
total	B
variation	I
and	O
conjugate	B
gradient	I
descent	O
,	O
http	O
:	O
//people.csail	O
.	O
mit.edu/celiu/opticalflow/	O
(	O
liu	O
2009	O
)	O
.	O
tv-l1	O
optical	B
ﬂow	I
on	O
the	O
gpu	O
,	O
http	O
:	O
//cs.unc.edu/∼cmzach/opensource.html	O
(	O
zach	O
,	O
pock	O
,	O
and	O
bischof	O
2007a	O
)	O
.	O
elastix	O
:	O
a	O
toolbox	O
for	O
rigid	O
and	O
nonrigid	O
registration	B
of	O
images	O
,	O
http	O
:	O
//elastix.isi.uu.nl/	O
(	O
klein	O
,	O
staring	O
,	O
and	O
pluim	O
2007	O
)	O
.	O
deformable	O
image	B
registration	I
using	O
discrete	B
optimization	O
,	O
http	O
:	O
//www.mrf-registration	O
.	O
net/deformable/index.html	O
(	O
glocker	O
,	O
komodakis	O
,	O
tziritas	O
et	O
al	O
.	O
2008	O
)	O
.	O
chapter	O
9	O
:	O
image	B
stitching	I
microsoft	O
research	O
image	B
compositing	O
editor	O
for	O
stitching	O
images	O
,	O
http	O
:	O
//research	O
.	O
microsoft.com/en-us/um/redmond/groups/ivm/ice/	O
.	O
chapter	O
10	O
:	O
computational	O
photography	O
hdrshop	O
software	O
for	O
combining	O
bracketed	O
exposures	O
into	O
high-dynamic	O
range	O
radi-	O
ance	O
images	O
,	O
http	O
:	O
//projects.ict.usc.edu/graphics/hdrshop/	O
.	O
super-resolution	O
code	O
,	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/software/sr/	O
(	O
pickup	O
2007	O
;	O
pickup	O
,	O
capel	O
,	O
roberts	O
et	O
al	O
.	O
2007	O
,	O
2009	O
)	O
.	O
chapter	O
11	O
:	O
stereo	B
correspondence	O
stereomatcher	O
,	O
standalone	O
c++	O
stereo	B
matching	I
code	O
,	O
http	O
:	O
//vision.middlebury.edu/	O
stereo/code/	O
(	O
scharstein	O
and	O
szeliski	O
2002	O
)	O
.	O
patch-based	B
multi-view	O
stereo	B
software	O
(	O
pmvs	O
version	O
2	O
)	O
,	O
http	O
:	O
//grail.cs.washington	O
.	O
edu/software/pmvs/	O
(	O
furukawa	O
and	O
ponce	O
2011	O
)	O
.	O
chapter	O
12	O
:	O
3d	O
reconstruction	O
scanalyze	O
:	O
a	O
system	O
for	O
aligning	O
and	O
merging	B
range	O
data	O
,	O
http	O
:	O
//graphics.stanford.edu/	O
software/scanalyze/	O
(	O
curless	O
and	O
levoy	O
1996	O
)	O
.	O
c.2	O
software	O
785	O
meshlab	O
:	O
software	O
for	O
processing	O
,	O
editing	O
,	O
and	O
visualizing	O
unstructured	B
3d	O
triangular	O
meshes	O
,	O
http	O
:	O
//meshlab.sourceforge.net/	O
.	O
vrml	O
viewers	O
(	O
various	O
)	O
are	O
also	O
a	O
good	O
way	O
to	O
visualize	O
texture-mapped	O
3d	O
models	O
.	O
section	O
12.6.4	O
:	O
whole	O
body	B
modeling	O
and	O
tracking	O
bayesian	O
3d	O
person	O
tracking	O
,	O
http	O
:	O
//www.cs.brown.edu/∼black/code.html	O
(	O
sidenbladh	O
,	O
black	O
,	O
and	O
fleet	O
2000	O
;	O
sidenbladh	O
and	O
black	O
2003	O
)	O
.	O
humaneva	O
:	O
baseline	O
code	O
for	O
the	O
tracking	O
of	O
articulated	O
human	B
motion	I
,	O
http	O
:	O
//vision	O
.	O
cs.brown.edu/humaneva/	O
(	O
sigal	O
,	O
balan	O
,	O
and	O
black	O
2010	O
)	O
.	O
section	O
14.1.1	O
:	O
face	B
detection	O
sample	O
face	B
detection	O
code	O
and	O
evaluation	B
tools	O
,	O
http	O
:	O
//vision.ai.uiuc.edu/mhyang/face-detection-survey.html	O
.	O
section	O
14.1.2	O
:	O
pedestrian	B
detection	O
a	O
simple	O
object	O
detector	O
with	O
boosting	O
,	O
http	O
:	O
//people.csail.mit.edu/torralba/shortcourserloc/	O
boosting/boosting.html	O
(	O
hastie	O
,	O
tibshirani	O
,	O
and	O
friedman	O
2001	O
;	O
torralba	O
,	O
murphy	O
,	O
and	O
freeman	O
2007	O
)	O
.	O
discriminatively	O
trained	O
deformable	O
part	O
models	O
,	O
http	O
:	O
//people.cs.uchicago.edu/∼pff/	O
latent/	O
(	O
felzenszwalb	O
,	O
girshick	O
,	O
mcallester	O
et	O
al	O
.	O
2010	O
)	O
.	O
upper-body	O
detector	O
,	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/software/upperbody/	O
(	O
ferrari	O
,	O
marin-jimenez	O
,	O
and	O
zisserman	O
2008	O
)	O
.	O
2d	O
articulated	O
human	O
pose	O
estimation	B
software	O
,	O
http	O
:	O
//www.vision.ee.ethz.ch/∼calvin/	O
articulated	O
human	O
pose	O
estimation	B
code/	O
(	O
eichner	O
and	O
ferrari	O
2009	O
)	O
.	O
section	O
14.2.2	O
:	O
active	O
appearance	O
and	O
3d	O
shape	O
models	O
aamtools	O
:	O
an	O
active	O
appearance	O
modeling	O
toolbox	O
,	O
http	O
:	O
//cvsp.cs.ntua.gr/software/	O
aamtools/	O
(	O
papandreou	O
and	O
maragos	O
2008	O
)	O
.	O
section	O
14.3	O
:	O
instance	B
recognition	O
fastann	O
and	O
fastcluster	O
for	O
approximate	O
k-means	B
(	O
akm	O
)	O
,	O
http	O
:	O
//www.robots	O
.	O
ox.ac.uk/∼vgg/software/	O
(	O
philbin	O
,	O
chum	O
,	O
isard	O
et	O
al	O
.	O
2007	O
)	O
.	O
feature	B
matching	O
using	O
fast	O
approximate	O
nearest	O
neighbors	O
,	O
http	O
:	O
//people.cs.ubc.ca/	O
∼mariusm/index.php/flann/flann	O
(	O
muja	O
and	O
lowe	O
2009	O
)	O
.	O
786	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
section	O
14.4.1	O
:	O
bag	B
of	I
words	I
two	O
bag	B
of	I
words	I
classiﬁers	O
,	O
http	O
:	O
//people.csail.mit.edu/fergus/iccv2005/bagwords.html	O
(	O
fei-fei	O
and	O
perona	O
2005	O
;	O
sivic	O
,	O
russell	O
,	O
efros	O
et	O
al	O
.	O
2005	O
)	O
.	O
bag	O
of	O
features	O
and	O
hierarchical	B
k-means	O
,	O
http	O
:	O
//www.vlfeat.org/	O
(	O
nist´er	O
and	O
stew´enius	O
2006	O
;	O
nowak	O
,	O
jurie	O
,	O
and	O
triggs	O
2006	O
)	O
.	O
section	O
14.4.2	O
:	O
part-based	B
models	O
a	O
simple	O
parts	O
and	O
structure	O
object	O
detector	O
,	O
http	O
:	O
//people.csail.mit.edu/fergus/iccv2005/	O
partsstructure.html	O
(	O
fischler	O
and	O
elschlager	O
1973	O
;	O
felzenszwalb	O
and	O
huttenlocher	O
2005	O
)	O
.	O
section	O
14.5.1	O
:	O
machine	O
learning	O
software	O
support	B
vector	I
machines	I
(	O
svm	O
)	O
software	O
(	O
http	O
:	O
//www.support-vector-machines.org/	O
svm	O
soft.html	O
)	O
has	O
pointers	O
to	O
lots	O
of	O
svm	O
libraries	O
,	O
including	O
svmlight	O
,	O
http	O
:	O
//	O
svmlight.joachims.org/	O
;	O
libsvm	O
,	O
http	O
:	O
//www.csie.ntu.edu.tw/∼cjlin/libsvm/	O
(	O
fan	O
,	O
chen	O
,	O
and	O
lin	O
2005	O
)	O
;	O
and	O
liblinear	O
,	O
http	O
:	O
//www.csie.ntu.edu.tw/∼cjlin/liblinear/	O
(	O
fan	O
,	O
chang	O
,	O
hsieh	O
et	O
al	O
.	O
2008	O
)	O
.	O
kernel	B
machines	O
:	O
learning	B
algorithms	O
,	O
http	O
:	O
//www.kernel-machines.org/software	O
.	O
links	O
to	O
svm	O
,	O
gaussian	O
processes	O
,	O
boosting	B
,	O
and	O
other	O
machine	O
multiple	O
kernels	O
for	O
image	O
classiﬁcation	O
,	O
http	O
:	O
//www.robots.ox.ac.uk/∼vgg/software/	O
mkl/	O
(	O
varma	O
and	O
ray	O
2007	O
;	O
vedaldi	O
,	O
gulshan	O
,	O
varma	O
et	O
al	O
.	O
2009	O
)	O
.	O
appendix	O
a.1–a.2	O
:	O
matrix	B
decompositions	I
and	O
linear	B
least	O
squares2	O
blas	O
(	O
basic	O
linear	B
algebra	O
subprograms	O
)	O
,	O
http	O
:	O
//www.netlib.org/blas/	O
(	O
blackford	O
,	O
demmel	O
,	O
dongarra	O
et	O
al	O
.	O
2002	O
)	O
.	O
lapack	O
(	O
linear	B
algebra	O
package	O
)	O
,	O
http	O
:	O
//www.netlib.org/lapack/	O
(	O
anderson	O
,	O
bai	O
,	O
bischof	O
et	O
al	O
.	O
1999	O
)	O
.	O
gotoblas	O
,	O
http	O
:	O
//www.tacc.utexas.edu/tacc-projects/	O
.	O
atlas	O
(	O
automatically	O
tuned	O
linear	B
algebra	O
software	O
)	O
,	O
http	O
:	O
//math-atlas.sourceforge	O
.	O
net/	O
(	O
demmel	O
,	O
dongarra	O
,	O
eijkhout	O
et	O
al	O
.	O
2005	O
)	O
.	O
intel	O
math	O
kernel	B
library	O
(	O
mkl	O
)	O
,	O
http	O
:	O
//software.intel.com/en-us/intel-mkl/	O
.	O
amd	O
core	O
math	O
library	O
(	O
acml	O
)	O
,	O
http	O
:	O
//developer.amd.com/cpu/libraries/acml/pages/	O
default.aspx	O
.	O
2	O
thanks	O
to	O
sameer	O
agarwal	O
for	O
suggesting	O
and	O
describing	O
most	O
of	O
these	O
sites	O
.	O
c.2	O
software	O
787	O
robust	B
pca	O
code	O
,	O
http	O
:	O
//www.salle.url.edu/∼ftorre/papers/rpca2.html	O
(	O
de	O
la	O
torre	O
and	O
black	O
2003	O
)	O
.	O
appendix	O
a.3	O
:	O
non-linear	B
least	O
squares	O
minpack	O
,	O
http	O
:	O
//www.netlib.org/minpack/	O
.	O
levmar	O
:	O
levenberg–marquardt	O
nonlinear	O
least	B
squares	I
algorithms	O
,	O
http	O
:	O
//www.ics.forth	O
.	O
gr/∼lourakis/levmar/	O
(	O
madsen	O
,	O
nielsen	O
,	O
and	O
tingleff	O
2004	O
)	O
.	O
appendix	O
a.4–a.5	O
:	O
direct	B
and	O
iterative	B
sparse	O
matrix	O
solvers	O
suitesparse	O
(	O
various	O
reordering	O
algorithms	O
,	O
cholmod	O
)	O
and	O
suitesparse	O
qr	O
,	O
http	O
:	O
//www.cise.uﬂ.edu/research/sparse/suitesparse/	O
(	O
davis	O
2006	O
,	O
2008	O
)	O
.	O
pardiso	O
(	O
iterative	B
and	O
sparse	B
direct	O
solution	O
)	O
,	O
http	O
:	O
//www.pardiso-project.org/	O
.	O
taucs	O
(	O
sparse	B
direct	O
,	O
iterative	B
,	O
out	O
of	O
core	O
,	O
preconditioners	O
)	O
,	O
http	O
:	O
//www.tau.ac.il/	O
∼stoledo/taucs/	O
.	O
hsl	O
mathematical	O
software	O
library	O
,	O
http	O
:	O
//www.hsl.rl.ac.uk/index.html	O
.	O
templates	O
for	O
the	O
solution	O
of	O
linear	B
systems	O
,	O
http	O
:	O
//www.netlib.org/linalg/html	O
templates/	O
templates.html	O
(	O
barrett	O
,	O
berry	O
,	O
chan	O
et	O
al	O
.	O
1994	O
)	O
.	O
download	O
the	O
pdf	O
for	O
instructions	O
on	O
how	O
to	O
get	O
the	O
software	O
.	O
itsol	O
,	O
miqr	O
,	O
and	O
other	O
sparse	B
solvers	O
,	O
http	O
:	O
//www-users.cs.umn.edu/∼saad/software/	O
(	O
saad	O
2003	O
)	O
.	O
ilupack	O
,	O
http	O
:	O
//www-public.tu-bs.de/∼bolle/ilupack/	O
.	O
appendix	O
b	O
:	O
bayesian	O
modeling	B
and	O
inference	B
middlebury	O
source	O
code	O
for	O
mrf	O
minimization	O
,	O
http	O
:	O
//vision.middlebury.edu/mrf/	O
code/	O
(	O
szeliski	O
,	O
zabih	O
,	O
scharstein	O
et	O
al	O
.	O
2008	O
)	O
.	O
c++	O
code	O
for	O
efﬁcient	O
belief	B
propagation	I
for	O
early	O
vision	O
,	O
http	O
:	O
//people.cs.uchicago	O
.	O
edu/∼pff/bp/	O
(	O
felzenszwalb	O
and	O
huttenlocher	O
2006	O
)	O
.	O
fastpd	O
mrf	O
optimization	O
code	O
,	O
http	O
:	O
//www.csd.uoc.gr/∼komod/fastpd	O
(	O
komodakis	O
and	O
tziritas	O
2007a	O
;	O
komodakis	O
,	O
tziritas	O
,	O
and	O
paragios	O
2008	O
)	O
788	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
double	O
urand	O
(	O
)	O
{	O
return	O
(	O
(	O
double	O
)	O
rand	O
(	O
)	O
)	O
/	O
(	O
(	O
double	O
)	O
rand	O
max	O
)	O
;	O
}	O
void	O
grand	O
(	O
double	O
&	O
g1	O
,	O
double	O
&	O
g2	O
)	O
{	O
#	O
ifndef	O
m	O
pi	O
#	O
define	O
m	O
pi	O
3.14159265358979323846	O
#	O
endif	O
//	O
m	O
pi	O
double	O
n1	O
=	O
urand	O
(	O
)	O
;	O
double	O
n2	O
=	O
urand	O
(	O
)	O
;	O
double	O
x1	O
=	O
n1	O
+	O
(	O
n1	O
==	O
0	O
)	O
;	O
/*	O
guard	O
against	O
log	O
(	O
0	O
)	O
*/	O
double	O
sqlogn1	O
=	O
sqrt	O
(	O
-2.0	O
*	O
log	O
(	O
x1	O
)	O
)	O
;	O
double	O
angl	O
=	O
(	O
2.0	O
*	O
m	O
pi	O
)	O
*	O
n2	O
;	O
g1	O
=	O
sqlogn1	O
*	O
cos	O
(	O
angl	O
)	O
;	O
g2	O
=	O
sqlogn1	O
*	O
sin	O
(	O
angl	O
)	O
;	O
}	O
algorithm	B
c.1	O
c	O
algorithm	B
for	O
gaussian	O
random	O
noise	O
generation	O
,	O
using	O
the	O
box–muller	O
transform	B
.	O
gaussian	O
noise	B
generation	O
.	O
a	O
lot	O
of	O
basic	O
software	O
packages	O
come	O
with	O
a	O
uniform	O
random	O
noise	O
generator	O
(	O
e.g.	O
,	O
the	O
rand	O
(	O
)	O
routine	O
in	O
unix	O
)	O
,	O
but	O
not	O
all	O
have	O
a	O
gaussian	O
random	O
noise	O
generator	O
.	O
to	O
compute	O
a	O
normally	O
distributed	O
random	O
variable	O
,	O
you	O
can	O
use	O
the	O
box–	O
muller	O
transform	B
(	O
box	O
and	O
muller	O
1958	O
)	O
,	O
whose	O
c	O
code	O
is	O
given	O
in	O
algorithm	B
c.1—note	O
that	O
this	O
routine	O
returns	O
pairs	B
of	O
random	O
variables	O
.	O
alternative	O
methods	O
for	O
generating	O
gaussian	O
random	O
numbers	O
are	O
given	O
by	O
thomas	O
,	O
luk	O
,	O
leong	O
et	O
al	O
.	O
(	O
2007	O
)	O
.	O
pseudocolor	O
generation	O
.	O
in	O
many	O
applications	O
,	O
it	O
is	O
convenient	O
to	O
be	O
able	O
to	O
visualize	O
the	O
set	O
of	O
labels	O
assigned	O
to	O
an	O
image	B
(	O
or	O
to	O
image	B
features	O
such	O
as	O
lines	B
)	O
.	O
one	O
of	O
the	O
easiest	O
ways	O
to	O
do	O
this	O
is	O
to	O
assign	O
a	O
unique	O
color	B
to	O
each	O
integer	O
label	O
.	O
in	O
my	O
work	O
,	O
i	O
have	O
found	O
it	O
convenient	O
to	O
distribute	O
these	O
labels	O
in	O
a	O
quasi-uniform	O
fashion	O
around	O
the	O
rgb	O
color	B
cube	O
using	O
the	O
following	O
idea	O
.	O
for	O
each	O
(	O
non-negative	O
)	O
label	O
value	O
,	O
consider	O
the	O
bits	O
as	O
being	O
split	O
among	O
the	O
three	O
color	B
channels	O
,	O
e.g.	O
,	O
for	O
a	O
nine-bit	O
value	O
,	O
the	O
bits	O
could	O
be	O
labeled	O
rgbrgbrgb	O
.	O
after	O
collecting	O
each	O
of	O
the	O
three	O
color	B
values	O
,	O
reverse	O
the	O
bits	O
so	O
that	O
the	O
low-order	O
bits	O
vary	O
the	O
most	O
quickly	O
.	O
c.3	O
slides	O
and	O
lectures	O
789	O
in	O
practice	O
,	O
for	O
eight-bit	O
color	B
channels	O
,	O
this	O
bit	O
reverse	O
can	O
be	O
stored	O
in	O
a	O
table	O
or	O
a	O
complete	O
table	O
mapping	O
from	O
labels	O
to	O
pseudocolors	O
(	O
say	O
with	O
4092	O
entries	O
)	O
can	O
be	O
pre-computed	O
.	O
figure	O
8.16	O
shows	O
an	O
example	O
of	O
such	O
a	O
pseudo-color	O
mapping	O
.	O
gpu	O
implementation	O
the	O
advent	O
of	O
programmable	O
gpus	O
with	O
capabilities	O
such	O
as	O
pixel	O
shaders	O
and	O
compute	O
shaders	O
has	O
led	O
to	O
the	O
development	O
of	O
fast	O
computer	O
vision	O
algorithms	O
for	O
real-time	O
appli-	O
cations	O
such	O
as	O
segmentation	B
,	O
tracking	O
,	O
stereo	B
,	O
and	O
motion	B
estimation	I
(	O
pock	O
,	O
unger	O
,	O
cremers	O
et	O
al	O
.	O
2008	O
;	O
vineet	O
and	O
narayanan	O
2008	O
;	O
zach	O
,	O
gallup	O
,	O
and	O
frahm	O
2008	O
)	O
.	O
a	O
good	O
source	O
for	O
learning	O
about	O
such	O
algorithms	O
is	O
the	O
cvpr	O
2008	O
workshop	O
on	O
visual	O
computer	O
vision	O
on	O
gpus	O
(	O
cvgpu	O
)	O
,	O
http	O
:	O
//www.cs.unc.edu/∼jmf/workshop	O
on	O
computer	O
vision	O
on	O
gpu	O
.	O
html	O
,	O
whose	O
papers	O
can	O
be	O
found	O
on	O
the	O
cvpr	O
2008	O
proceedings	O
dvd	O
.	O
additional	O
sources	O
for	O
gpu	O
algorithms	O
include	O
the	O
gpgpu	O
web	O
site	O
and	O
workshops	O
,	O
http	O
:	O
//gpgpu.org/	O
,	O
and	O
the	O
openvidia	O
web	O
site	O
,	O
http	O
:	O
//openvidia.sourceforge.net/index.php/openvidia	O
.	O
c.3	O
slides	O
and	O
lectures	O
as	O
i	O
mentioned	O
in	O
the	O
preface	O
,	O
i	O
hope	O
to	O
post	O
slides	O
corresponding	O
to	O
the	O
material	O
in	O
the	O
book	O
.	O
until	O
these	O
are	O
ready	O
,	O
your	O
best	O
bet	O
is	O
to	O
look	O
at	O
the	O
slides	O
from	O
the	O
courses	O
i	O
have	O
co-taught	O
at	O
the	O
university	O
of	O
washington	O
,	O
as	O
well	O
as	O
related	O
courses	O
that	O
have	O
used	O
a	O
similar	O
syllabus	O
.	O
here	O
is	O
a	O
partial	O
list	O
of	O
such	O
courses	O
:	O
uw	O
455	O
:	O
undergraduate	O
computer	O
vision	O
,	O
http	O
:	O
//www.cs.washington.edu/education/	O
courses/455/	O
.	O
uw	O
576	O
:	O
graduate	O
computer	O
vision	O
,	O
http	O
:	O
//www.cs.washington.edu/education/courses/	O
576/	O
.	O
stanford	O
cs233b	O
:	O
introduction	O
to	O
computer	O
vision	O
,	O
http	O
:	O
//vision.stanford.edu/teaching/	O
cs223b/	O
.	O
mit	O
6.869	O
:	O
advances	O
in	O
computer	O
vision	O
,	O
http	O
:	O
//people.csail.mit.edu/torralba/courses/	O
6.869/6.869.computervision.htm	O
.	O
berkeley	O
cs	O
280	O
:	O
computer	O
vision	O
,	O
http	O
:	O
//www.eecs.berkeley.edu/∼trevor/cs280.html	O
.	O
unc	O
comp	O
776	O
:	O
computer	O
vision	O
,	O
http	O
:	O
//www.cs.unc.edu/∼lazebnik/spring10/	O
.	O
middlebury	O
cs	O
453	O
:	O
computer	O
vision	O
,	O
http	O
:	O
//www.cs.middlebury.edu/∼schar/courses/	O
cs453-s10/	O
.	O
790	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
related	O
courses	O
have	O
also	O
been	O
taught	O
on	O
the	O
topic	O
of	O
computational	O
photography	O
,	O
e.g.	O
,	O
cmu	O
15-463	O
:	O
computational	O
photography	O
,	O
http	O
:	O
//graphics.cs.cmu.edu/courses/15-463/	O
.	O
mit	O
6.815/6.865	O
:	O
advanced	O
computational	O
photography	O
,	O
http	O
:	O
//stellar.mit.edu/s/course/	O
6/sp09/6.815/	O
.	O
stanford	O
cs	O
448a	O
:	O
computational	O
photography	O
on	O
cell	O
phones	O
,	O
http	O
:	O
//graphics.stanford	O
.	O
edu/courses/cs448a-10/	O
.	O
siggraph	O
courses	O
on	O
computational	O
photography	O
,	O
http	O
:	O
//web.media.mit.edu/∼raskar/	O
photo/	O
.	O
there	O
is	O
also	O
an	O
excellent	O
set	O
of	O
on-line	O
lectures	O
available	O
on	O
a	O
range	O
of	O
computer	O
vision	O
topics	O
,	O
such	O
as	O
belief	B
propagation	I
and	O
graph	B
cuts	I
,	O
at	O
the	O
uw-msr	O
course	O
of	O
vision	O
algo-	O
rithms	O
http	O
:	O
//www.cs.washington.edu/education/courses/577/04sp/	O
.	O
c.4	O
bibliography	O
while	O
a	O
bibliography	O
(	O
bibtex	O
.bib	O
ﬁle	O
)	O
for	O
all	O
of	O
the	O
references	B
cited	O
in	O
this	O
book	O
is	O
avail-	O
able	O
on	O
the	O
book	O
’	O
s	O
web	O
site	O
,	O
a	O
much	O
more	O
comprehensive	O
partially	O
annotated	O
bibliography	O
of	O
nearly	O
all	O
computer	O
vision	O
publications	O
is	O
maintained	O
by	O
keith	O
price	O
at	O
http	O
:	O
//iris.usc.edu/	O
vision-notes/bibliography/contents.html	O
.	O
there	O
is	O
also	O
a	O
searchable	O
computer	O
graphics	O
bibli-	O
ography	O
at	O
http	O
:	O
//www.siggraph.org/publications/bibliography/	O
.	O
additional	O
good	O
sources	O
for	O
technical	O
papers	O
are	O
google	O
scholar	O
and	O
citeseerx	O
.	O
references	B
abdel-hakim	O
,	O
a.	O
e.	O
and	O
farag	O
,	O
a.	O
a	O
.	O
(	O
2006	O
)	O
.	O
csift	O
:	O
a	O
sift	O
descriptor	O
with	O
color	O
in-	O
variant	O
characterstics	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
1978–1983	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
adelson	O
,	O
e.	O
h.	O
and	O
bergen	O
,	O
j	O
.	O
(	O
1991	O
)	O
.	O
the	O
plenoptic	O
function	O
and	O
the	O
elements	O
of	O
early	O
vision	O
.	O
in	O
computational	O
models	O
of	O
visual	O
processing	O
,	O
pp	O
.	O
3–20	O
.	O
adelson	O
,	O
e.	O
h.	O
,	O
simoncelli	O
,	O
e.	O
,	O
and	O
hingorani	O
,	O
r.	O
(	O
1987	O
)	O
.	O
orthogonal	O
pyramid	O
transforms	O
for	O
image	O
coding	O
.	O
in	O
spie	O
vol	O
.	O
845	O
,	O
visual	O
communications	O
and	O
image	B
processing	O
ii	O
,	O
pp	O
.	O
50–58	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
adiv	O
,	O
g.	O
(	O
1989	O
)	O
.	O
noisy	O
ﬂow	O
ﬁeld	O
.	O
11	O
(	O
5	O
)	O
:477–490	O
.	O
inherent	O
ambiguities	O
in	O
recovering	O
3-d	O
motion	B
and	O
structure	O
from	O
a	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
agarwal	O
,	O
a.	O
and	O
triggs	O
,	O
b	O
.	O
(	O
2006	O
)	O
.	O
recovering	O
3d	O
human	O
pose	O
from	O
monocular	O
images	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
1	O
)	O
:44–58	O
.	O
agarwal	O
,	O
s.	O
and	O
roth	O
,	O
d.	O
(	O
2002	O
)	O
.	O
learning	B
a	O
sparse	B
representation	O
for	O
object	O
detection	B
.	O
in	O
seventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2002	O
)	O
,	O
pp	O
.	O
113–127	O
,	O
copen-	O
hagen	O
.	O
agarwal	O
,	O
s.	O
,	O
snavely	O
,	O
n.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2010	O
)	O
.	O
bundle	B
adjustment	I
in	O
the	O
large	O
.	O
in	O
eleventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2010	O
)	O
,	O
heraklion	O
,	O
crete	O
.	O
agarwal	O
,	O
s.	O
,	O
snavely	O
,	O
n.	O
,	O
simon	O
,	O
i.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2009	O
)	O
.	O
building	O
rome	O
in	O
a	O
day	O
.	O
in	O
twelfth	O
ieee	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
agarwal	O
,	O
s.	O
,	O
furukawa	O
,	O
y.	O
,	O
snavely	O
,	O
n.	O
,	O
curless	O
,	O
b.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2010	O
)	O
.	O
reconstructing	O
rome	O
.	O
computer	O
,	O
43	O
(	O
6	O
)	O
:40–47	O
.	O
agarwala	O
,	O
a	O
.	O
(	O
2007	O
)	O
.	O
efﬁcient	O
gradient-domain	O
compositing	B
using	O
quadtrees	O
.	O
acm	O
trans-	O
actions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
792	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
agarwala	O
,	O
a.	O
,	O
hertzmann	O
,	O
a.	O
,	O
seitz	O
,	O
s.	O
,	O
and	O
salesin	O
,	O
d.	O
(	O
2004	O
)	O
.	O
keyframe-based	O
tracking	O
for	O
rotoscoping	O
and	O
animation	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2004	O
)	O
,	O
23	O
(	O
3	O
)	O
:584–591	O
.	O
agarwala	O
,	O
a.	O
,	O
agrawala	O
,	O
m.	O
,	O
cohen	O
,	O
m.	O
,	O
salesin	O
,	O
d.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
pho-	O
tographing	O
long	O
scenes	O
with	O
multi-viewpoint	O
panoramas	O
.	O
acm	O
transactions	O
on	O
graph-	O
ics	O
(	O
proc	O
.	O
siggraph	O
2006	O
)	O
,	O
25	O
(	O
3	O
)	O
:853–861	O
.	O
agarwala	O
,	O
a.	O
,	O
dontcheva	O
,	O
m.	O
,	O
agrawala	O
,	O
m.	O
,	O
drucker	O
,	O
s.	O
,	O
colburn	O
,	O
a.	O
,	O
curless	O
,	O
b.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2004	O
)	O
.	O
interactive	B
digital	O
photomontage	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2004	O
)	O
,	O
23	O
(	O
3	O
)	O
:292–300	O
.	O
agarwala	O
,	O
a.	O
,	O
zheng	O
,	O
k.	O
c.	O
,	O
pal	O
,	O
c.	O
,	O
agrawala	O
,	O
m.	O
,	O
cohen	O
,	O
m.	O
,	O
curless	O
,	O
b.	O
,	O
salesin	O
,	O
d.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2005	O
)	O
.	O
panoramic	O
video	B
textures	I
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:821–827	O
.	O
aggarwal	O
,	O
j.	O
k.	O
and	O
nandhakumar	O
,	O
n.	O
(	O
1988	O
)	O
.	O
on	O
the	O
computation	O
of	O
motion	B
from	O
se-	O
quences	O
of	O
images—a	O
review	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
76	O
(	O
8	O
)	O
:917–935	O
.	O
agin	O
,	O
g.	O
j.	O
and	O
binford	O
,	O
t.	O
o	O
.	O
(	O
1976	O
)	O
.	O
computer	O
description	O
of	O
curved	O
objects	O
.	O
ieee	O
transactions	O
on	O
computers	O
,	O
c-25	O
(	O
4	O
)	O
:439–449	O
.	O
ahonen	O
,	O
t.	O
,	O
hadid	O
,	O
a.	O
,	O
and	O
pietik¨ainen	O
,	O
m.	O
(	O
2006	O
)	O
.	O
face	B
description	O
with	O
local	O
binary	O
patterns	O
:	O
application	O
to	O
face	B
recognition	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
12	O
)	O
:2037–2041	O
.	O
akenine-m¨oller	O
,	O
t.	O
and	O
haines	O
,	O
e.	O
(	O
2002	O
)	O
.	O
real-time	O
rendering	B
.	O
a	O
k	O
peters	O
,	O
wellesley	O
,	O
massachusetts	O
,	O
second	O
edition	O
.	O
al-baali	O
,	O
m.	O
and	O
fletcher.	O
,	O
r.	O
(	O
1986	O
)	O
.	O
an	O
efﬁcient	O
line	O
search	O
for	O
nonlinear	O
least	B
squares	I
.	O
journal	O
journal	O
of	O
optimization	O
theory	O
and	O
applications	O
,	O
48	O
(	O
3	O
)	O
:359–377	O
.	O
alahari	O
,	O
k.	O
,	O
kohli	O
,	O
p.	O
,	O
and	O
torr	O
,	O
p.	O
(	O
2011	O
)	O
.	O
dynamic	B
hybrid	O
algorithms	O
for	O
discrete	O
map	O
mrf	O
inference	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
.	O
alexa	O
,	O
m.	O
,	O
behr	O
,	O
j.	O
,	O
cohen-or	O
,	O
d.	O
,	O
fleishman	O
,	O
s.	O
,	O
levin	O
,	O
d.	O
,	O
and	O
silva	O
,	O
c.	O
t.	O
(	O
2003	O
)	O
.	O
computing	O
and	O
rendering	B
point	O
set	O
surfaces	O
.	O
ieee	O
transactions	O
on	O
visualization	O
and	O
computer	O
graphics	O
,	O
9	O
(	O
1	O
)	O
:3–15	O
.	O
aliaga	O
,	O
d.	O
g.	O
,	O
funkhouser	O
,	O
t.	O
,	O
yanovsky	O
,	O
d.	O
,	O
and	O
carlbom	O
,	O
i	O
.	O
(	O
2003	O
)	O
.	O
sea	O
of	O
images	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
23	O
(	O
6	O
)	O
:22–30	O
.	O
allen	O
,	O
b.	O
,	O
curless	O
,	O
b.	O
,	O
and	O
popovi´c	O
,	O
z	O
.	O
(	O
2003	O
)	O
.	O
the	O
space	O
of	O
human	B
body	I
shapes	O
:	O
recon-	O
struction	O
and	O
parameterization	O
from	O
range	O
scans	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2003	O
)	O
,	O
22	O
(	O
3	O
)	O
:587–594	O
.	O
allgower	O
,	O
e.	O
l.	O
and	O
georg	O
,	O
k.	O
(	O
2003	O
)	O
.	O
introduction	O
to	O
numerical	O
continuation	O
methods	O
.	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
.	O
references	B
793	O
aloimonos	O
,	O
j	O
.	O
(	O
1990	O
)	O
.	O
perspective	B
approximations	O
.	O
image	B
and	O
vision	O
computing	O
,	O
8:177–	O
192.	O
alpert	O
,	O
s.	O
,	O
galun	O
,	O
m.	O
,	O
basri	O
,	O
r.	O
,	O
and	O
brandt	O
,	O
a	O
.	O
(	O
2007	O
)	O
.	O
image	B
segmentation	O
by	O
probabilis-	O
tic	O
bottom-up	O
aggregation	O
and	O
cue	O
integration	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
amini	O
,	O
a.	O
a.	O
,	O
weymouth	O
,	O
t.	O
e.	O
,	O
and	O
jain	O
,	O
r.	O
c.	O
(	O
1990	O
)	O
.	O
using	O
dynamic	O
programming	O
for	O
solving	O
variational	O
problems	O
in	O
vision	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12	O
(	O
9	O
)	O
:855–867	O
.	O
anandan	O
,	O
p.	O
(	O
1984	O
)	O
.	O
computing	O
dense	O
displacement	O
ﬁelds	O
with	O
conﬁdence	O
measures	O
in	O
in	O
image	B
understanding	O
workshop	O
,	O
pp	O
.	O
236–246	O
,	O
new	O
scenes	O
containing	O
occlusion	O
.	O
orleans	O
.	O
anandan	O
,	O
p.	O
(	O
1989	O
)	O
.	O
a	O
computational	O
framework	O
and	O
an	O
algorithm	B
for	O
the	O
measurement	O
of	O
visual	O
motion	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
2	O
(	O
3	O
)	O
:283–310	O
.	O
anandan	O
,	O
p.	O
and	O
irani	O
,	O
m.	O
(	O
2002	O
)	O
.	O
factorization	B
with	O
uncertainty	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
49	O
(	O
2-3	O
)	O
:101–116	O
.	O
anderson	O
,	O
e.	O
,	O
bai	O
,	O
z.	O
,	O
bischof	O
,	O
c.	O
,	O
blackford	O
,	O
s.	O
,	O
demmel	O
,	O
j.	O
w.	O
et	O
al	O
.	O
(	O
1999	O
)	O
.	O
lapack	O
users	O
’	O
guide	O
.	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
,	O
3rd	O
edition	O
.	O
andrieu	O
,	O
c.	O
,	O
de	O
freitas	O
,	O
n.	O
,	O
doucet	O
,	O
a.	O
,	O
and	O
jordan	O
,	O
m.	O
i	O
.	O
(	O
2003	O
)	O
.	O
an	O
introduction	O
to	O
mcmc	O
for	O
machine	O
learning	B
.	O
machine	O
learning	O
,	O
50	O
(	O
1-2	O
)	O
:5–43	O
.	O
andriluka	O
,	O
m.	O
,	O
roth	O
,	O
s.	O
,	O
and	O
schiele	O
,	O
b	O
.	O
(	O
2008	O
)	O
.	O
people-tracking-by-detection	O
and	O
people-	O
detection-by-tracking	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
andriluka	O
,	O
m.	O
,	O
roth	O
,	O
s.	O
,	O
and	O
schiele	O
,	O
b.	O
detection	B
and	O
articulated	O
pose	O
estimation	B
.	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
(	O
2009	O
)	O
.	O
pictorial	O
structures	O
revisited	O
:	O
people	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
andriluka	O
,	O
m.	O
,	O
roth	O
,	O
s.	O
,	O
and	O
schiele	O
,	O
b	O
.	O
(	O
2010	O
)	O
.	O
ocular	O
3d	O
pose	O
estimation	B
and	O
tracking	O
by	O
detection	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2010	O
)	O
,	O
san	O
francisco	O
,	O
ca	O
.	O
anguelov	O
,	O
d.	O
,	O
srinivasan	O
,	O
p.	O
,	O
koller	O
,	O
d.	O
,	O
thrun	O
,	O
s.	O
,	O
rodgers	O
,	O
j.	O
,	O
and	O
davis	O
,	O
j	O
.	O
(	O
2005	O
)	O
.	O
scape	O
:	O
shape	O
completion	O
and	O
animation	O
of	O
people	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:408–416	O
.	O
ansar	O
,	O
a.	O
,	O
castano	O
,	O
a.	O
,	O
and	O
matthies	O
,	O
l.	O
(	O
2004	O
)	O
.	O
enhanced	O
real-time	O
stereo	B
using	O
bilat-	O
eral	O
ﬁltering	O
.	O
in	O
international	O
symposium	O
on	O
3d	O
data	O
processing	O
,	O
visualization	O
,	O
and	O
transmission	O
(	O
3dpvt	O
)	O
.	O
794	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
antone	O
,	O
m.	O
and	O
teller	O
,	O
s.	O
(	O
2002	O
)	O
.	O
scalable	O
extrinsic	B
calibration	O
of	O
omni-directional	O
image	B
networks	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
49	O
(	O
2-3	O
)	O
:143–174	O
.	O
arbel´aez	O
,	O
p.	O
,	O
maire	O
,	O
m.	O
,	O
fowlkes	O
,	O
c.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2010	O
)	O
.	O
contour	O
detection	B
and	O
hierar-	O
chical	O
image	B
segmentation	O
.	O
technical	O
report	O
ucb/eecs-2010-17	O
,	O
eecs	O
department	O
,	O
university	O
of	O
california	O
,	O
berkeley	O
.	O
submitted	O
to	O
pami	O
.	O
argyriou	O
,	O
v.	O
and	O
vlachos	O
,	O
t.	O
(	O
2003	O
)	O
.	O
estimation	B
of	O
sub-pixel	O
motion	O
using	O
gradient	O
cross-	O
correlation	O
.	O
electronic	O
letters	O
,	O
39	O
(	O
13	O
)	O
:980–982	O
.	O
arikan	O
,	O
o.	O
and	O
forsyth	O
,	O
d.	O
a	O
.	O
(	O
2002	O
)	O
.	O
interactive	B
motion	O
generation	O
from	O
examples	B
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
21	O
(	O
3	O
)	O
:483–490	O
.	O
arnold	O
,	O
r.	O
d.	O
(	O
1983	O
)	O
.	O
automated	B
stereo	O
perception	O
.	O
technical	O
report	O
aim-351	O
,	O
artiﬁcial	O
intelligence	O
laboratory	O
,	O
stanford	O
university	O
.	O
arya	O
,	O
s.	O
,	O
mount	O
,	O
d.	O
m.	O
,	O
netanyahu	O
,	O
n.	O
s.	O
,	O
silverman	O
,	O
r.	O
,	O
and	O
wu	O
,	O
a.	O
y	O
.	O
(	O
1998	O
)	O
.	O
an	O
optimal	O
algorithm	B
for	O
approximate	O
nearest	B
neighbor	I
searching	O
in	O
ﬁxed	O
dimensions	O
.	O
journal	O
of	O
the	O
acm	O
,	O
45	O
(	O
6	O
)	O
:891–923	O
.	O
ashdown	O
,	O
i	O
.	O
(	O
1993	O
)	O
.	O
near-ﬁeld	O
photometry	O
:	O
a	O
new	O
approach	O
.	O
journal	O
of	O
the	O
illuminating	O
engineering	O
society	O
,	O
22	O
(	O
1	O
)	O
:163–180	O
.	O
atkinson	O
,	O
k.	O
b	O
.	O
(	O
1996	O
)	O
.	O
close	O
range	O
photogrammetry	O
and	O
machine	O
vision	O
.	O
whittles	O
publishing	O
,	O
scotland	O
,	O
uk	O
.	O
aurich	O
,	O
v.	O
and	O
weule	O
,	O
j	O
.	O
(	O
1995	O
)	O
.	O
non-linear	B
gaussian	O
ﬁlters	O
performing	O
edge	O
preserving	O
diffusion	O
.	O
in	O
17th	O
dagm-symposium	O
,	O
pp	O
.	O
538–545	O
,	O
bielefeld	O
.	O
avidan	O
,	O
s.	O
(	O
2001	O
)	O
.	O
support	O
vector	O
tracking	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2001	O
)	O
,	O
pp	O
.	O
283–290	O
,	O
kauai	O
,	O
hawaii	O
.	O
avidan	O
,	O
s.	O
,	O
baker	O
,	O
s.	O
,	O
and	O
shan	O
,	O
y	O
.	O
(	O
2010	O
)	O
.	O
special	O
issue	O
on	O
internet	O
vision	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
98	O
(	O
8	O
)	O
:1367–1369	O
.	O
axelsson	O
,	O
o	O
.	O
(	O
1996	O
)	O
.	O
iterative	B
solution	O
methods	O
.	O
cambridge	O
university	O
press	O
,	O
cambridge	O
.	O
ayache	O
,	O
n.	O
(	O
1989	O
)	O
.	O
vision	O
st´er´eoscopique	O
et	O
perception	O
multisensorielle	O
.	O
intereditions	O
,	O
paris	O
.	O
azarbayejani	O
,	O
a.	O
and	O
pentland	O
,	O
a.	O
p.	O
(	O
1995	O
)	O
.	O
recursive	O
estimation	B
of	O
motion	B
,	O
structure	O
,	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
and	O
focal	O
length	O
.	O
17	O
(	O
6	O
)	O
:562–575	O
.	O
azuma	O
,	O
r.	O
t.	O
,	O
baillot	O
,	O
y.	O
,	O
behringer	O
,	O
r.	O
,	O
feiner	O
,	O
s.	O
k.	O
,	O
julier	O
,	O
s.	O
,	O
and	O
macintyre	O
,	O
b	O
.	O
(	O
2001	O
)	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
recent	O
advances	O
in	O
augmented	B
reality	I
.	O
21	O
(	O
6	O
)	O
:34–47	O
.	O
references	B
795	O
bab-hadiashar	O
,	O
a.	O
and	O
suter	O
,	O
d.	O
(	O
1998a	O
)	O
.	O
robust	B
optic	O
ﬂow	O
computation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
29	O
(	O
1	O
)	O
:59–77	O
.	O
bab-hadiashar	O
,	O
a.	O
and	O
suter	O
,	O
d.	O
(	O
1998b	O
)	O
.	O
robust	B
total	O
least	B
squares	I
based	O
optic	O
ﬂow	O
computation	O
.	O
in	O
asian	O
conference	O
on	O
computer	O
vision	O
(	O
accv	O
’	O
98	O
)	O
,	O
pp	O
.	O
566–573	O
,	O
hong	O
kong	O
.	O
badra	O
,	O
f.	O
,	O
qumsieh	O
,	O
a.	O
,	O
and	O
dudek	O
,	O
g.	O
(	O
1998	O
)	O
.	O
rotation	O
and	O
zooming	O
in	O
image	B
mosaic-	O
in	O
ieee	O
workshop	O
on	O
applications	O
of	O
computer	O
vision	O
(	O
wacv	O
’	O
98	O
)	O
,	O
pp	O
.	O
50–55	O
,	O
ing	O
.	O
princeton	O
.	O
bae	O
,	O
s.	O
,	O
paris	O
,	O
s.	O
,	O
and	O
durand	O
,	O
f.	O
(	O
2006	O
)	O
.	O
two-scale	O
tone	O
management	O
for	O
photographic	O
look	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:637–645	O
.	O
baeza-yates	O
,	O
r.	O
and	O
ribeiro-neto	O
,	O
b	O
.	O
(	O
1999	O
)	O
.	O
modern	O
information	O
retrieval	O
.	O
addison	O
wesley	O
.	O
bai	O
,	O
x.	O
and	O
sapiro	O
,	O
g.	O
(	O
2009	O
)	O
.	O
geodesic	O
matting	O
:	O
a	O
framework	O
for	O
fast	O
interactive	B
im-	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
age	O
and	O
video	B
segmentation	O
and	O
matting	B
.	O
82	O
(	O
2	O
)	O
:113–132	O
.	O
bajcsy	O
,	O
r.	O
and	O
kovacic	O
,	O
s.	O
(	O
1989	O
)	O
.	O
multiresolution	O
elastic	O
matching	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
46	O
(	O
1	O
)	O
:1–21	O
.	O
baker	O
,	O
h.	O
h.	O
(	O
1977	O
)	O
.	O
three-dimensional	O
modeling	B
.	O
in	O
fifth	O
international	O
joint	B
conference	O
on	O
artiﬁcial	O
intelligence	O
(	O
ijcai-77	O
)	O
,	O
pp	O
.	O
649–655	O
.	O
baker	O
,	O
h.	O
h.	O
(	O
1982	O
)	O
.	O
depth	O
from	O
edge	O
and	O
intensity	O
based	O
stereo	B
.	O
technical	O
report	O
aim-	O
347	O
,	O
artiﬁcial	O
intelligence	O
laboratory	O
,	O
stanford	O
university	O
.	O
baker	O
,	O
h.	O
h.	O
(	O
1989	O
)	O
.	O
building	O
surfaces	O
of	O
evolution	B
:	O
the	O
weaving	O
wall	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
3	O
(	O
1	O
)	O
:50–71	O
.	O
baker	O
,	O
h.	O
h.	O
and	O
binford	O
,	O
t.	O
o	O
.	O
(	O
1981	O
)	O
.	O
depth	O
from	O
edge	O
and	O
intensity	O
based	O
stereo	B
.	O
in	O
ijcai81	O
,	O
pp	O
.	O
631–636	O
.	O
baker	O
,	O
h.	O
h.	O
and	O
bolles	O
,	O
r.	O
c.	O
(	O
1989	O
)	O
.	O
generalizing	O
epipolar-plane	O
image	B
analysis	O
on	O
the	O
spatiotemporal	O
surface	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
3	O
(	O
1	O
)	O
:33–49	O
.	O
baker	O
,	O
s.	O
and	O
kanade	O
,	O
t.	O
(	O
2002	O
)	O
.	O
limits	O
on	O
super-resolution	O
and	O
how	O
to	O
break	O
them	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
9	O
)	O
:1167–1183	O
.	O
baker	O
,	O
s.	O
and	O
matthews	O
,	O
i	O
.	O
(	O
2004	O
)	O
.	O
lucas-kanade	O
20	O
years	O
on	O
:	O
a	O
unifying	O
framework	O
:	O
part	O
1	O
:	O
the	O
quantity	O
approximated	O
,	O
the	O
warp	O
update	B
rule	I
,	O
and	O
the	O
gradient	B
descent	I
approxi-	O
mation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
56	O
(	O
3	O
)	O
:221–255	O
.	O
baker	O
,	O
s.	O
and	O
nayar	O
,	O
s.	O
(	O
1999	O
)	O
.	O
a	O
theory	O
of	O
single-viewpoint	O
catadioptric	O
image	B
formation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
5	O
(	O
2	O
)	O
:175–196	O
.	O
796	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
baker	O
,	O
s.	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
2001	O
)	O
.	O
single	O
viewpoint	O
catadioptric	O
cameras	O
.	O
in	O
benosman	O
,	O
r.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
eds	O
)	O
,	O
panoramic	O
vision	O
:	O
sensors	O
,	O
theory	O
,	O
and	O
applications	O
,	O
pp	O
.	O
39–71	O
,	O
springer	O
,	O
new	O
york	O
.	O
baker	O
,	O
s.	O
,	O
gross	O
,	O
r.	O
,	O
and	O
matthews	O
,	O
i	O
.	O
(	O
2003	O
)	O
.	O
lucas-kanade	O
20	O
years	O
on	O
:	O
a	O
unify-	O
ing	O
framework	O
:	O
part	O
3.	O
technical	O
report	O
cmu-ri-tr-03-35	O
,	O
the	O
robotics	O
institute	O
,	O
carnegie	O
mellon	O
university	O
.	O
baker	O
,	O
s.	O
,	O
gross	O
,	O
r.	O
,	O
and	O
matthews	O
,	O
i	O
.	O
(	O
2004	O
)	O
.	O
lucas-kanade	O
20	O
years	O
on	O
:	O
a	O
unify-	O
ing	O
framework	O
:	O
part	O
4.	O
technical	O
report	O
cmu-ri-tr-04-14	O
,	O
the	O
robotics	O
institute	O
,	O
carnegie	O
mellon	O
university	O
.	O
baker	O
,	O
s.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
anandan	O
,	O
p.	O
(	O
1998	O
)	O
.	O
a	O
layered	B
approach	O
to	O
stereo	B
reconstruc-	O
tion	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recogni-	O
tion	B
(	O
cvpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
434–441	O
,	O
santa	O
barbara	O
.	O
baker	O
,	O
s.	O
,	O
gross	O
,	O
r.	O
,	O
ishikawa	O
,	O
t.	O
,	O
and	O
matthews	O
,	O
i	O
.	O
(	O
2003	O
)	O
.	O
lucas-kanade	O
20	O
years	O
on	O
:	O
a	O
unifying	O
framework	O
:	O
part	O
2.	O
technical	O
report	O
cmu-ri-tr-03-01	O
,	O
the	O
robotics	O
institute	O
,	O
carnegie	O
mellon	O
university	O
.	O
baker	O
,	O
s.	O
,	O
black	O
,	O
m.	O
,	O
lewis	O
,	O
j.	O
p.	O
,	O
roth	O
,	O
s.	O
,	O
scharstein	O
,	O
d.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2007	O
)	O
.	O
a	O
database	O
and	O
evaluation	B
methodology	O
for	O
optical	O
ﬂow	O
.	O
in	O
eleventh	O
international	O
con-	O
ference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
baker	O
,	O
s.	O
,	O
scharstein	O
,	O
d.	O
,	O
lewis	O
,	O
j.	O
,	O
roth	O
,	O
s.	O
,	O
black	O
,	O
m.	O
j.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2009	O
)	O
.	O
a	O
database	O
and	O
evaluation	B
methodology	O
for	O
optical	O
flow	O
.	O
technical	O
report	O
msr-tr-	O
2009-179	O
,	O
microsoft	O
research	O
.	O
ballard	O
,	O
d.	O
h.	O
(	O
1981	O
)	O
.	O
generalizing	O
the	O
hough	O
transform	B
to	O
detect	O
arbitrary	O
patterns	B
.	O
pattern	O
recognition	B
,	O
13	O
(	O
2	O
)	O
:111–122	O
.	O
ballard	O
,	O
d.	O
h.	O
and	O
brown	O
,	O
c.	O
m.	O
(	O
1982	O
)	O
.	O
computer	O
vision	O
.	O
prentice-hall	O
,	O
englewood	O
cliffs	O
,	O
new	O
jersey	O
.	O
banno	O
,	O
a.	O
,	O
masuda	O
,	O
t.	O
,	O
oishi	O
,	O
t.	O
,	O
and	O
ikeuchi	O
,	O
k.	O
(	O
2008	O
)	O
.	O
flying	O
laser	O
range	O
sensor	O
for	O
large-scale	O
site-modeling	O
and	O
its	O
applications	O
in	O
bayon	O
digital	O
archival	O
project	O
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
78	O
(	O
2-3	O
)	O
:207–222	O
.	O
bar-hillel	O
,	O
a.	O
,	O
hertz	O
,	O
t.	O
,	O
and	O
weinshall	O
,	O
d.	O
(	O
2005	O
)	O
.	O
object	O
class	O
recognition	B
by	O
boosting	B
a	O
part	O
based	O
model	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
701–708	O
,	O
san	O
diego	O
,	O
ca	O
.	O
bar-joseph	O
,	O
z.	O
,	O
el-yaniv	O
,	O
r.	O
,	O
lischinski	O
,	O
d.	O
,	O
and	O
werman	O
,	O
m.	O
(	O
2001	O
)	O
.	O
texture	B
mixing	O
and	O
texture	B
movie	O
synthesis	O
using	O
statistical	O
learning	B
.	O
ieee	O
transactions	O
on	O
visualization	O
and	O
computer	O
graphics	O
,	O
7	O
(	O
2	O
)	O
:120–135	O
.	O
references	B
797	O
bar-shalom	O
,	O
y.	O
and	O
fortmann	O
,	O
t.	O
e.	O
(	O
1988	O
)	O
.	O
tracking	O
and	O
data	O
association	O
.	O
academic	O
press	O
,	O
boston	O
.	O
barash	O
,	O
d.	O
(	O
2002	O
)	O
.	O
a	O
fundamental	O
relationship	O
between	O
bilateral	B
ﬁltering	O
,	O
adaptive	B
smooth-	O
ing	O
,	O
and	O
the	O
nonlinear	O
diffusion	O
equation	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
6	O
)	O
:844–847	O
.	O
barash	O
,	O
d.	O
and	O
comaniciu	O
,	O
d.	O
(	O
2004	O
)	O
.	O
a	O
common	O
framework	O
for	O
nonlinear	O
diffusion	O
,	O
image	B
and	O
vision	O
computing	O
,	O
adaptive	B
smoothing	O
,	O
bilateral	B
ﬁltering	O
and	O
mean	B
shift	I
.	O
22	O
(	O
1	O
)	O
:73–81	O
.	O
barbu	O
,	O
a.	O
and	O
zhu	O
,	O
s.-c.	O
(	O
2003	O
)	O
.	O
graph	O
partition	O
by	O
swendsen–wang	O
cuts	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
320–327	O
,	O
nice	O
,	O
france	O
.	O
barbu	O
,	O
a.	O
and	O
zhu	O
,	O
s.-c.	O
(	O
2005	O
)	O
.	O
generalizing	O
swendsen–wang	O
to	O
sampling	B
arbitrary	O
pos-	O
terior	O
probabilities	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
27	O
(	O
9	O
)	O
:1239–1253	O
.	O
barkans	O
,	O
a.	O
c.	O
(	O
1997	O
)	O
.	O
high	O
quality	O
rendering	B
using	O
the	O
talisman	O
architecture	B
.	O
in	O
pro-	O
ceedings	O
of	O
the	O
eurographics	O
workshop	O
on	O
graphics	O
hardware	O
.	O
barnard	O
,	O
s.	O
t.	O
(	O
1989	O
)	O
.	O
stochastic	O
stereo	O
matching	B
over	O
scale	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
3	O
(	O
1	O
)	O
:17–32	O
.	O
barnard	O
,	O
s.	O
t.	O
and	O
fischler	O
,	O
m.	O
a	O
.	O
(	O
1982	O
)	O
.	O
computational	O
stereo	O
.	O
computing	O
surveys	B
,	O
14	O
(	O
4	O
)	O
:553–572	O
.	O
barnes	O
,	O
c.	O
,	O
jacobs	O
,	O
d.	O
e.	O
,	O
sanders	O
,	O
j.	O
,	O
goldman	O
,	O
d.	O
b.	O
,	O
rusinkiewicz	O
,	O
s.	O
,	O
finkelstein	O
,	O
a.	O
,	O
and	O
agrawala	O
,	O
m.	O
(	O
2008	O
)	O
.	O
video	B
puppetry	O
:	O
a	O
performative	O
interface	O
for	O
cutout	O
anima-	O
tion	B
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
27	O
(	O
5	O
)	O
.	O
barreto	O
,	O
j.	O
p.	O
and	O
daniilidis	O
,	O
k.	O
(	O
2005	O
)	O
.	O
fundamental	O
matrix	O
for	O
cameras	O
with	O
radial	O
distor-	O
tion	B
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
625–632	O
,	O
beijing	O
,	O
china	O
.	O
barrett	O
,	O
r.	O
,	O
berry	O
,	O
m.	O
,	O
chan	O
,	O
t.	O
f.	O
,	O
demmel	O
,	O
j.	O
,	O
donato	O
,	O
j.	O
et	O
al	O
.	O
(	O
1994	O
)	O
.	O
templates	O
for	O
the	O
solution	O
of	O
linear	B
systems	O
:	O
building	O
blocks	O
for	O
iterative	O
methods	O
,	O
2nd	O
edition	O
.	O
siam	O
,	O
philadelphia	O
,	O
pa.	O
barron	O
,	O
j.	O
l.	O
,	O
fleet	O
,	O
d.	O
j.	O
,	O
and	O
beauchemin	O
,	O
s.	O
s.	O
(	O
1994	O
)	O
.	O
performance	O
of	O
optical	B
ﬂow	I
techniques	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
12	O
(	O
1	O
)	O
:43–77	O
.	O
barrow	O
,	O
h.	O
g.	O
and	O
tenenbaum	O
,	O
j.	O
m.	O
(	O
1981	O
)	O
.	O
computational	O
vision	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
69	O
(	O
5	O
)	O
:572–595	O
.	O
bartels	O
,	O
r.	O
h.	O
,	O
beatty	O
,	O
j.	O
c.	O
,	O
and	O
barsky	O
,	O
b.	O
a	O
.	O
(	O
1987	O
)	O
.	O
an	O
introduction	O
to	O
splines	B
for	O
use	O
in	O
computer	O
graphics	O
and	O
geeometric	O
modeling	B
.	O
morgan	O
kaufmann	O
publishers	O
,	O
los	O
altos	O
.	O
798	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
bartoli	O
,	O
a	O
.	O
(	O
2003	O
)	O
.	O
towards	O
gauge	O
invariant	O
bundle	B
adjustment	I
:	O
a	O
solution	O
based	O
on	O
gauge	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
dependent	O
damping	O
.	O
2003	O
)	O
,	O
pp	O
.	O
760–765	O
,	O
nice	O
,	O
france	O
.	O
bartoli	O
,	O
a.	O
and	O
sturm	O
,	O
p.	O
(	O
2003	O
)	O
.	O
multiple-view	O
structure	O
and	O
motion	B
from	O
line	O
correspon-	O
dences	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
207–	O
212	O
,	O
nice	O
,	O
france	O
.	O
bartoli	O
,	O
a.	O
,	O
coquerelle	O
,	O
m.	O
,	O
and	O
sturm	O
,	O
p.	O
(	O
2004	O
)	O
.	O
a	O
framework	O
for	O
pencil-of-points	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
structure-from-motion	O
.	O
2004	O
)	O
,	O
pp	O
.	O
28–40	O
,	O
prague	O
.	O
bascle	O
,	O
b.	O
,	O
blake	O
,	O
a.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1996	O
)	O
.	O
motion	B
deblurring	O
and	O
super-	O
resolution	O
from	O
an	O
image	B
sequence	O
.	O
in	O
fourth	O
european	O
conference	O
on	O
computer	O
vi-	O
sion	O
(	O
eccv	O
’	O
96	O
)	O
,	O
pp	O
.	O
573–582	O
,	O
cambridge	O
,	O
england	O
.	O
bathe	O
,	O
k.-j	O
.	O
(	O
2007	O
)	O
.	O
finite	O
element	O
procedures	O
.	O
prentice-hall	O
,	O
inc.	O
,	O
englewood	O
cliffs	O
,	O
new	O
jersey	O
.	O
batra	O
,	O
d.	O
,	O
sukthankar	O
,	O
r.	O
,	O
and	O
chen	O
,	O
t.	O
(	O
2008	O
)	O
.	O
learning	B
class-speciﬁc	O
afﬁnities	B
for	O
im-	O
age	O
labelling	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
baudisch	O
,	O
p.	O
,	O
tan	O
,	O
d.	O
,	O
steedly	O
,	O
d.	O
,	O
rudolph	O
,	O
e.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
pal	O
,	O
c.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
an	O
exploration	O
of	O
user	O
interface	O
designs	O
for	O
real-time	O
panoramic	O
photography	O
.	O
australian	O
journal	O
of	O
information	O
systems	O
,	O
13	O
(	O
2	O
)	O
.	O
baumberg	O
,	O
a	O
.	O
(	O
2000	O
)	O
.	O
reliable	O
feature	B
matching	O
across	O
widely	O
separated	O
views	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
774–781	O
,	O
hilton	O
head	B
island	O
.	O
baumberg	O
,	O
a.	O
m.	O
and	O
hogg	O
,	O
d.	O
c.	O
(	O
1996	O
)	O
.	O
generating	O
spatiotemporal	O
models	O
from	O
exam-	O
ples	O
.	O
image	B
and	O
vision	O
computing	O
,	O
14	O
(	O
8	O
)	O
:525–532	O
.	O
baumgart	O
,	O
b.	O
g.	O
(	O
1974	O
)	O
.	O
geometric	B
modeling	O
for	O
computer	O
vision	O
.	O
technical	O
re-	O
port	O
aim-249	O
,	O
artiﬁcial	O
intelligence	O
laboratory	O
,	O
stanford	O
university	O
.	O
bay	O
,	O
h.	O
,	O
ferrari	O
,	O
v.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2005	O
)	O
.	O
wide-baseline	O
stereo	B
matching	I
with	O
line	O
seg-	O
ments	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recog-	O
nition	O
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
329–336	O
,	O
san	O
diego	O
,	O
ca	O
.	O
bay	O
,	O
h.	O
,	O
tuytelaars	O
,	O
t.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2006	O
)	O
.	O
surf	O
:	O
speeded	O
up	O
robust	O
features	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
404–417	O
.	O
bayer	O
,	O
b.	O
e.	O
(	O
1976	O
)	O
.	O
color	B
imaging	O
array	O
.	O
us	O
patent	O
no	O
.	O
3,971,065.	O
references	B
799	O
beardsley	O
,	O
p.	O
,	O
torr	O
,	O
p.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1996	O
)	O
.	O
3d	O
model	O
acquisition	O
from	O
extended	O
in	O
fourth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
96	O
)	O
,	O
image	B
sequences	O
.	O
pp	O
.	O
683–695	O
,	O
cambridge	O
,	O
england	O
.	O
beare	O
,	O
r.	O
(	O
2006	O
)	O
.	O
a	O
locally	O
constrained	O
watershed	B
transform	O
.	O
ieee	O
transactions	O
on	O
pat-	O
tern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
7	O
)	O
:1063–1074	O
.	O
becker	O
,	O
s.	O
and	O
bove	O
,	O
v.	O
m.	O
(	O
1995	O
)	O
.	O
semiautomatic	O
3-d	O
model	O
extraction	O
from	O
uncalibrated	O
2-d	O
camera	B
views	O
.	O
in	O
spie	O
vol	O
.	O
2410	O
,	O
visual	O
data	O
exploration	O
and	O
analysis	O
ii	O
,	O
pp	O
.	O
447–	O
461	O
,	O
san	O
jose	O
.	O
beier	O
,	O
t.	O
and	O
neely	O
,	O
s.	O
(	O
1992	O
)	O
.	O
feature-based	B
image	O
metamorphosis	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
92	O
)	O
,	O
26	O
(	O
2	O
)	O
:35–42	O
.	O
beis	O
,	O
j.	O
s.	O
and	O
lowe	O
,	O
d.	O
g.	O
(	O
1999	O
)	O
.	O
indexing	O
without	O
invariants	O
in	O
3d	O
object	O
recognition	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
21	O
(	O
10	O
)	O
:1000–1015	O
.	O
belhumeur	O
,	O
p.	O
n.	O
(	O
1996	O
)	O
.	O
a	O
bayesian	O
approach	O
to	O
binocular	O
stereopsis	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
19	O
(	O
3	O
)	O
:237–260	O
.	O
belhumeur	O
,	O
p.	O
n.	O
,	O
hespanha	O
,	O
j.	O
p.	O
,	O
and	O
kriegman	O
,	O
d.	O
j	O
.	O
(	O
1997	O
)	O
.	O
eigenfaces	O
vs.	O
fisher-	O
faces	B
:	O
recognition	B
using	O
class	O
speciﬁc	O
linear	B
projection	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
7	O
)	O
:711–720	O
.	O
belongie	O
,	O
s.	O
and	O
malik	O
,	O
j	O
.	O
(	O
1998	O
)	O
.	O
finding	O
boundaries	O
in	O
natural	B
images	O
:	O
a	O
new	O
method	O
us-	O
ing	O
point	O
descriptors	O
and	O
area	O
completion	O
.	O
in	O
fifth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
751–766	O
,	O
freiburg	O
,	O
germany	O
.	O
belongie	O
,	O
s.	O
,	O
malik	O
,	O
j.	O
,	O
and	O
puzicha	O
,	O
j	O
.	O
(	O
2002	O
)	O
.	O
shape	O
matching	O
and	O
object	O
recognition	B
using	O
shape	O
contexts	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
4	O
)	O
:509–522	O
.	O
belongie	O
,	O
s.	O
,	O
fowlkes	O
,	O
c.	O
,	O
chung	O
,	O
f.	O
,	O
and	O
malik	O
,	O
j.	O
indeﬁnite	O
kernels	O
using	O
the	O
nystr¨om	O
extension	O
.	O
computer	O
vision	O
(	O
eccv	O
2002	O
)	O
,	O
pp	O
.	O
531–543	O
,	O
copenhagen	O
.	O
(	O
2002	O
)	O
.	O
spectral	O
partitioning	O
with	O
in	O
seventh	O
european	O
conference	O
on	O
bennett	O
,	O
e.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
zitnick	O
,	O
l.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
kang	O
,	O
s.	O
b.	O
and	O
image	B
bayesian	O
demosaicing	B
with	O
a	O
two	O
color	O
image	B
prior	O
.	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
508–521	O
,	O
graz	O
.	O
(	O
2006	O
)	O
.	O
video	B
in	O
ninth	O
european	O
benosman	O
,	O
r.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
eds	O
)	O
.	O
applications	O
,	O
springer	O
,	O
new	O
york	O
.	O
(	O
2001	O
)	O
.	O
panoramic	O
vision	O
:	O
sensors	O
,	O
theory	O
,	O
and	O
berg	O
,	O
t.	O
(	O
2008	O
)	O
.	O
internet	O
vision	O
.	O
suny	O
stony	O
brook	O
course	O
cse	O
690	O
,	O
http	O
:	O
//www	O
.	O
tamaraberg.com/teaching/fall	O
08/	O
.	O
800	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
berg	O
,	O
t.	O
and	O
forsyth	O
,	O
d.	O
(	O
2006	O
)	O
.	O
animals	O
on	O
the	O
web	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
1463–1470	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
bergen	O
,	O
j.	O
r.	O
,	O
anandan	O
,	O
p.	O
,	O
hanna	O
,	O
k.	O
j.	O
,	O
and	O
hingorani	O
,	O
r.	O
(	O
1992	O
)	O
.	O
hierarchical	B
model-based	O
motion	B
estimation	I
.	O
in	O
second	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
92	O
)	O
,	O
pp	O
.	O
237–252	O
,	O
santa	O
margherita	O
liguere	O
,	O
italy	O
.	O
bergen	O
,	O
j.	O
r.	O
,	O
burt	O
,	O
p.	O
j.	O
,	O
hingorani	O
,	O
r.	O
,	O
and	O
peleg	O
,	O
s.	O
(	O
1992	O
)	O
.	O
a	O
three-frame	O
algorithm	B
for	O
estimating	O
two-component	O
image	B
motion	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
14	O
(	O
9	O
)	O
:886–896	O
.	O
berger	O
,	O
j.	O
o	O
.	O
(	O
1993	O
)	O
.	O
statistical	O
decision	O
theory	O
and	O
bayesian	O
analysis	O
.	O
springer	O
,	O
new	O
york	O
,	O
second	O
edition	O
.	O
bertalmio	O
,	O
m.	O
,	O
sapiro	O
,	O
g.	O
,	O
caselles	O
,	O
v.	O
,	O
and	O
ballester	O
,	O
c.	O
(	O
2000	O
)	O
.	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
417–424	O
.	O
image	B
inpainting	O
.	O
in	O
bertalmio	O
,	O
m.	O
,	O
vese	O
,	O
l.	O
,	O
sapiro	O
,	O
g.	O
,	O
and	O
osher	O
,	O
s.	O
(	O
2003	O
)	O
.	O
simultaneous	O
structure	O
and	O
texture	B
image	O
inpainting	B
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
12	O
(	O
8	O
)	O
:882–889	O
.	O
bertero	O
,	O
m.	O
,	O
poggio	O
,	O
t.	O
a.	O
,	O
and	O
torre	O
,	O
v.	O
(	O
1988	O
)	O
.	O
ill-posed	O
problems	O
in	O
early	O
vision	O
.	O
pro-	O
ceedings	O
of	O
the	O
ieee	O
,	O
76	O
(	O
8	O
)	O
:869–889	O
.	O
besag	O
,	O
j	O
.	O
(	O
1986	O
)	O
.	O
on	O
the	O
statistical	O
analysis	O
of	O
dirty	O
pictures	O
.	O
journal	O
of	O
the	O
royal	O
statisti-	O
cal	O
society	O
b	O
,	O
48	O
(	O
3	O
)	O
:259–302	O
.	O
besl	O
,	O
p.	O
(	O
1989	O
)	O
.	O
active	O
optical	O
range	O
imaging	O
sensors	O
.	O
in	O
sanz	O
,	O
j.	O
l	O
.	O
(	O
ed	O
.	O
)	O
,	O
advances	O
in	O
machine	O
vision	O
,	O
chapter	O
1	O
,	O
pp	O
.	O
1–63	O
,	O
springer-verlag	O
.	O
besl	O
,	O
p.	O
j.	O
and	O
jain	O
,	O
r.	O
c.	O
surveys	B
,	O
17	O
(	O
1	O
)	O
:75–145	O
.	O
(	O
1985	O
)	O
.	O
three-dimensional	O
object	O
recognition	B
.	O
computing	O
besl	O
,	O
p.	O
j.	O
and	O
mckay	O
,	O
n.	O
d.	O
(	O
1992	O
)	O
.	O
a	O
method	O
for	O
registration	O
of	O
3-d	O
shapes	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
14	O
(	O
2	O
)	O
:239–256	O
.	O
betrisey	O
,	O
c.	O
,	O
blinn	O
,	O
j.	O
f.	O
,	O
dresevic	O
,	O
b.	O
,	O
hill	O
,	O
b.	O
,	O
hitchcock	O
,	O
g.	O
et	O
al	O
.	O
(	O
2000	O
)	O
.	O
displaced	O
ﬁlter-	O
ing	O
for	O
patterned	O
displays	O
.	O
in	O
society	O
for	O
information	O
display	O
symposium	O
,	O
,	O
pp	O
.	O
296–299	O
.	O
beymer	O
,	O
d.	O
(	O
1996	O
)	O
.	O
feature	B
correspondence	O
by	O
interleaving	O
shape	O
and	O
texture	B
computa-	O
tions	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recogni-	O
tion	B
(	O
cvpr	O
’	O
96	O
)	O
,	O
pp	O
.	O
921–928	O
,	O
san	O
francisco	O
.	O
bhat	O
,	O
d.	O
n.	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
1998	O
)	O
.	O
ordinal	O
measures	O
for	O
image	O
correspondence	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
20	O
(	O
4	O
)	O
:415–423	O
.	O
bickel	O
,	O
b.	O
,	O
botsch	O
,	O
m.	O
,	O
angst	O
,	O
r.	O
,	O
matusik	O
,	O
w.	O
,	O
otaduy	O
,	O
m.	O
,	O
pﬁster	O
,	O
h.	O
,	O
and	O
gross	O
,	O
m.	O
(	O
2007	O
)	O
.	O
multi-scale	O
capture	O
of	O
facial	O
geometry	O
and	O
motion	B
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
references	B
801	O
billinghurst	O
,	O
m.	O
,	O
kato	O
,	O
h.	O
,	O
and	O
poupyrev	O
,	O
i	O
.	O
(	O
2001	O
)	O
.	O
the	O
magicbook	O
:	O
a	O
transitional	O
ar	O
interface	O
.	O
computers	O
&	O
graphics	O
,	O
25:745–753	O
.	O
bimber	O
,	O
o	O
.	O
(	O
2006	O
)	O
.	O
computational	O
photography—the	O
next	O
big	O
step	O
.	O
computer	O
,	O
39	O
(	O
8	O
)	O
:28–	O
29.	O
birchﬁeld	O
,	O
s.	O
and	O
tomasi	O
,	O
c.	O
(	O
1998	O
)	O
.	O
a	O
pixel	O
dissimilarity	O
measure	O
that	O
is	O
insensitive	O
to	O
image	B
sampling	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
20	O
(	O
4	O
)	O
:401–406	O
.	O
birchﬁeld	O
,	O
s.	O
and	O
tomasi	O
,	O
c.	O
(	O
1999	O
)	O
.	O
depth	O
discontinuities	O
by	O
pixel-to-pixel	O
stereo	B
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
35	O
(	O
3	O
)	O
:269–293	O
.	O
birchﬁeld	O
,	O
s.	O
t.	O
,	O
natarajan	O
,	O
b.	O
,	O
and	O
tomasi	O
,	O
c.	O
(	O
2007	O
)	O
.	O
correspondence	B
as	O
energy-based	B
segmentation	O
.	O
image	B
and	O
vision	O
computing	O
,	O
25	O
(	O
8	O
)	O
:1329–1340	O
.	O
bishop	O
,	O
c.	O
m.	O
(	O
2006	O
)	O
.	O
pattern	O
recognition	B
and	O
machine	O
learning	O
.	O
springer	O
,	O
new	O
york	O
,	O
ny	O
.	O
bitouk	O
,	O
d.	O
,	O
kumar	O
,	O
n.	O
,	O
dhillon	O
,	O
s.	O
,	O
belhumeur	O
,	O
p.	O
,	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
2008	O
)	O
.	O
face	B
swapping	O
:	O
automatically	O
replacing	O
faces	B
in	O
photographs	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
27	O
(	O
3	O
)	O
.	O
bj¨orck	O
,	O
a	O
.	O
(	O
1996	O
)	O
.	O
numerical	O
methods	O
for	O
least	O
squares	O
problems	O
.	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
.	O
bj¨orck	O
,	O
a.	O
and	O
dahlquist	O
,	O
g.	O
(	O
2010	O
)	O
.	O
numerical	O
methods	O
in	O
scientiﬁc	O
computing	O
.	O
vol-	O
ume	O
ii	O
,	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
.	O
black	O
,	O
m.	O
,	O
yacoob	O
,	O
y.	O
,	O
jepson	O
,	O
a.	O
d.	O
,	O
and	O
fleet	O
,	O
d.	O
j	O
.	O
(	O
1997	O
)	O
.	O
learning	B
parameterized	O
models	O
of	O
image	B
motion	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
561–567	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
black	O
,	O
m.	O
j.	O
and	O
anandan	O
,	O
p.	O
(	O
1996	O
)	O
.	O
the	O
robust	B
estimation	O
of	O
multiple	B
motions	O
:	O
para-	O
metric	O
and	O
piecewise-smooth	O
ﬂow	O
ﬁelds	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
63	O
(	O
1	O
)	O
:75–104	O
.	O
black	O
,	O
m.	O
j.	O
and	O
jepson	O
,	O
a.	O
d.	O
(	O
1996	O
)	O
.	O
estimating	O
optical	B
ﬂow	I
in	O
segmented	O
images	O
using	O
variable-order	O
parametric	B
models	O
with	O
local	O
deformations	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
18	O
(	O
10	O
)	O
:972–986	O
.	O
black	O
,	O
m.	O
j.	O
and	O
jepson	O
,	O
a.	O
d.	O
(	O
1998	O
)	O
.	O
eigentracking	O
:	O
robust	B
matching	O
and	O
tracking	O
of	O
ar-	O
ticulated	O
objects	O
using	O
a	O
view-based	O
representation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
26	O
(	O
1	O
)	O
:63–84	O
.	O
black	O
,	O
m.	O
j.	O
and	O
rangarajan	O
,	O
a	O
.	O
(	O
1996	O
)	O
.	O
on	O
the	O
uniﬁcation	O
of	O
line	O
processes	O
,	O
outlier	O
rejection	O
,	O
and	O
robust	B
statistics	O
with	O
applications	O
in	O
early	O
vision	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
19	O
(	O
1	O
)	O
:57–91	O
.	O
802	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
black	O
,	O
m.	O
j.	O
,	O
sapiro	O
,	O
g.	O
,	O
marimont	O
,	O
d.	O
h.	O
,	O
and	O
heeger	O
,	O
d.	O
(	O
1998	O
)	O
.	O
robust	B
anisotropic	O
diffusion	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
7	O
(	O
3	O
)	O
:421–432	O
.	O
blackford	O
,	O
l.	O
s.	O
,	O
demmel	O
,	O
j.	O
,	O
dongarra	O
,	O
j.	O
,	O
duff	O
,	O
i.	O
,	O
hammarling	O
,	O
s.	O
et	O
al	O
.	O
(	O
2002	O
)	O
.	O
an	O
updated	O
set	O
of	O
basic	O
linear	B
algebra	O
subprograms	O
(	O
blas	O
)	O
.	O
acm	O
transactions	O
on	O
math-	O
ematical	O
software	O
,	O
28	O
(	O
2	O
)	O
:135–151	O
.	O
blake	O
,	O
a.	O
and	O
isard	O
,	O
m.	O
(	O
1998	O
)	O
.	O
active	B
contours	I
:	O
the	O
application	O
of	O
techniques	O
from	O
graphics	O
,	O
vision	O
,	O
control	O
theory	O
and	O
statistics	O
to	O
visual	O
tracking	O
of	O
shapes	O
in	O
motion	B
.	O
springer	O
verlag	O
,	O
london	O
.	O
blake	O
,	O
a.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1987	O
)	O
.	O
visual	O
reconstruction	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
blake	O
,	O
a.	O
,	O
curwen	O
,	O
r.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1993	O
)	O
.	O
a	O
framework	O
for	O
spatio-temporal	O
control	O
in	O
the	O
tracking	O
of	O
visual	O
contour	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
11	O
(	O
2	O
)	O
:127–	O
145.	O
blake	O
,	O
a.	O
,	O
kohli	O
,	O
p.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
eds	O
)	O
.	O
(	O
2010	O
)	O
.	O
advances	O
in	O
markov	O
random	O
fields	O
,	O
mit	O
press	O
.	O
blake	O
,	O
a.	O
,	O
zimmerman	O
,	O
a.	O
,	O
and	O
knowles	O
,	O
g.	O
(	O
1985	O
)	O
.	O
surface	B
descriptions	O
from	O
stereo	B
and	O
shading	B
.	O
image	B
and	O
vision	O
computing	O
,	O
3	O
(	O
4	O
)	O
:183–191	O
.	O
blake	O
,	O
a.	O
,	O
rother	O
,	O
c.	O
,	O
brown	O
,	O
m.	O
,	O
perez	O
,	O
p.	O
,	O
and	O
torr	O
,	O
p.	O
(	O
2004	O
)	O
.	O
interactive	B
image	O
segmen-	O
tation	O
using	O
an	O
adaptive	B
gmmrf	O
model	O
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
428–441	O
,	O
prague	O
.	O
blanz	O
,	O
v.	O
and	O
vetter	O
,	O
t.	O
(	O
1999	O
)	O
.	O
a	O
morphable	O
model	O
for	O
the	O
synthesis	O
of	O
3d	O
faces	B
.	O
in	O
acm	O
siggraph	O
1999	O
conference	O
proceedings	O
,	O
pp	O
.	O
187–194	O
.	O
blanz	O
,	O
v.	O
and	O
vetter	O
,	O
t.	O
(	O
2003	O
)	O
.	O
face	B
recognition	O
based	O
on	O
ﬁtting	O
a	O
3d	O
morphable	O
model	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
25	O
(	O
)	O
:1063–1074	O
.	O
bleyer	O
,	O
m.	O
,	O
gelautz	O
,	O
m.	O
,	O
rother	O
,	O
c.	O
,	O
and	O
rhemann	O
,	O
c.	O
(	O
2009	O
)	O
.	O
a	O
stereo	B
approach	O
that	O
handles	O
the	O
matting	B
problem	O
via	O
image	B
warping	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
blinn	O
,	O
j	O
.	O
(	O
1998	O
)	O
.	O
dirty	O
pixels	O
.	O
morgan	O
kaufmann	O
publishers	O
,	O
san	O
francisco	O
.	O
blinn	O
,	O
j.	O
f.	O
(	O
1994a	O
)	O
.	O
jim	O
blinn	O
’	O
s	O
corner	O
:	O
compositing	B
,	O
part	O
1	O
:	O
theory	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
14	O
(	O
5	O
)	O
:83–87	O
.	O
blinn	O
,	O
j.	O
f.	O
(	O
1994b	O
)	O
.	O
jim	O
blinn	O
’	O
s	O
corner	O
:	O
compositing	B
,	O
part	O
2	O
:	O
practice	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
14	O
(	O
6	O
)	O
:78–82	O
.	O
blinn	O
,	O
j.	O
f.	O
and	O
newell	O
,	O
m.	O
e.	O
(	O
1976	O
)	O
.	O
texture	B
and	O
reﬂection	O
in	O
computer	O
generated	O
images	O
.	O
communications	O
of	O
the	O
acm	O
,	O
19	O
(	O
10	O
)	O
:542–547	O
.	O
references	B
803	O
blostein	O
,	O
d.	O
and	O
ahuja	O
,	O
n.	O
(	O
1987	O
)	O
.	O
shape	O
from	O
texture	B
:	O
integrating	O
texture-element	O
ex-	O
traction	O
and	O
surface	B
estimation	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
11	O
(	O
12	O
)	O
:1233–1251	O
.	O
bobick	O
,	O
a.	O
f.	O
(	O
1997	O
)	O
.	O
movement	O
,	O
activity	O
and	O
action	O
:	O
the	O
role	O
of	O
knowledge	O
in	O
the	O
percep-	O
tion	B
of	O
motion	B
.	O
proceedings	O
of	O
the	O
royal	O
society	O
of	O
london	O
,	O
b	O
352:1257–1265	O
.	O
bobick	O
,	O
a.	O
f.	O
and	O
intille	O
,	O
s.	O
s.	O
(	O
1999	O
)	O
.	O
large	O
occlusion	O
stereo	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
33	O
(	O
3	O
)	O
:181–200	O
.	O
boden	O
,	O
m.	O
a	O
.	O
(	O
2006	O
)	O
.	O
mind	O
as	O
machine	O
:	O
a	O
history	O
of	O
cognitive	O
science	O
.	O
oxford	O
univer-	O
sity	O
press	O
,	O
oxford	O
,	O
england	O
.	O
bogart	O
,	O
r.	O
g.	O
(	O
1991	O
)	O
.	O
view	O
correlation	O
.	O
in	O
arvo	O
,	O
j	O
.	O
(	O
ed	O
.	O
)	O
,	O
graphics	O
gems	O
ii	O
,	O
pp	O
.	O
181–190	O
,	O
academic	O
press	O
,	O
boston	O
.	O
boiman	O
,	O
o.	O
,	O
shechtman	O
,	O
e.	O
,	O
and	O
irani	O
,	O
m.	O
(	O
2008	O
)	O
.	O
in	O
defense	O
of	O
nearest-neighbor	O
based	O
image	B
classiﬁcation	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
boissonat	O
,	O
j.-d.	O
(	O
1984	O
)	O
.	O
representing	O
2d	O
and	O
3d	O
shapes	O
with	O
the	O
delaunay	O
triangulation	B
.	O
in	O
seventh	O
international	O
conference	O
on	O
pattern	O
recognition	B
(	O
icpr	O
’	O
84	O
)	O
,	O
pp	O
.	O
745–748	O
,	O
montreal	O
,	O
canada	O
.	O
bolles	O
,	O
r.	O
c.	O
,	O
baker	O
,	O
h.	O
h.	O
,	O
and	O
hannah	O
,	O
m.	O
j	O
.	O
(	O
1993	O
)	O
.	O
the	O
jisct	O
stereo	B
evaluation	O
.	O
in	O
image	B
understanding	O
workshop	O
,	O
pp	O
.	O
263–274	O
.	O
bolles	O
,	O
r.	O
c.	O
,	O
baker	O
,	O
h.	O
h.	O
,	O
and	O
marimont	O
,	O
d.	O
h.	O
(	O
1987	O
)	O
.	O
epipolar-plane	O
image	B
analysis	O
:	O
an	O
approach	O
to	O
determining	O
structure	B
from	I
motion	I
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
1:7–55	O
.	O
bookstein	O
,	O
f.	O
l.	O
of	O
deformations	O
.	O
11	O
(	O
6	O
)	O
:567–585	O
.	O
(	O
1989	O
)	O
.	O
principal	O
warps	O
:	O
thin-plate	O
splines	B
and	O
the	O
decomposition	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
borenstein	O
,	O
e.	O
and	O
ullman	O
,	O
s.	O
(	O
2008	O
)	O
.	O
combined	O
top-down/bottom-up	O
segmentation	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
30	O
(	O
12	O
)	O
:2109–2125	O
.	O
borgefors	O
,	O
g.	O
(	O
1986	O
)	O
.	O
distance	O
transformations	O
in	O
digital	O
images	O
.	O
computer	O
vision	O
,	O
graphics	O
and	O
image	B
processing	O
,	O
34	O
(	O
3	O
)	O
:227–248	O
.	O
bouchard	O
,	O
g.	O
and	O
triggs	O
,	O
b	O
.	O
(	O
2005	O
)	O
.	O
hierarchical	B
part-based	O
visual	O
object	O
categorization	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
709–714	O
,	O
san	O
diego	O
,	O
ca	O
.	O
bougnoux	O
,	O
s.	O
(	O
1998	O
)	O
.	O
from	O
projective	B
to	O
euclidean	O
space	O
under	O
any	O
practical	O
situation	O
,	O
a	O
criticism	O
of	O
self-calibration	B
.	O
in	O
sixth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
790–798	O
,	O
bombay	O
.	O
804	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
bouguet	O
,	O
j.-y	O
.	O
and	O
perona	O
,	O
p.	O
(	O
1999	O
)	O
.	O
3d	O
photography	O
using	O
shadows	O
in	O
dual-space	O
geom-	O
etry	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
35	O
(	O
2	O
)	O
:129–149	O
.	O
boult	O
,	O
t.	O
e.	O
and	O
kender	O
,	O
j.	O
r.	O
(	O
1986	O
)	O
.	O
visual	O
surface	O
reconstruction	O
using	O
sparse	B
depth	O
data	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
86	O
)	O
,	O
pp	O
.	O
68–76	O
,	O
miami	O
beach	O
.	O
bourdev	O
,	O
l.	O
and	O
malik	O
,	O
j	O
.	O
(	O
2009	O
)	O
.	O
poselets	O
:	O
body	B
part	O
detectors	O
trained	O
using	O
3d	O
hu-	O
man	O
pose	O
annotations	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
bovik	O
,	O
a	O
.	O
(	O
ed.	O
)	O
.	O
(	O
2000	O
)	O
.	O
handbook	O
of	O
image	B
and	O
video	B
processing	O
,	O
academic	O
press	O
,	O
san	O
diego	O
.	O
bowyer	O
,	O
k.	O
w.	O
,	O
kranenburg	O
,	O
c.	O
,	O
and	O
dougherty	O
,	O
s.	O
(	O
2001	O
)	O
.	O
edge	O
detector	O
evaluation	B
using	O
empirical	O
roc	O
curves	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
84	O
(	O
1	O
)	O
:77–103	O
.	O
box	O
,	O
g.	O
e.	O
p.	O
and	O
muller	O
,	O
m.	O
e.	O
(	O
1958	O
)	O
.	O
a	O
note	O
on	O
the	O
generation	O
of	O
random	O
normal	O
deviates	O
.	O
annals	O
of	O
mathematical	O
statistics	O
,	O
29	O
(	O
2	O
)	O
.	O
boyer	O
,	O
e.	O
and	O
berger	O
,	O
m.	O
o	O
.	O
(	O
1997	O
)	O
.	O
3d	O
surface	B
reconstruction	I
using	O
occluding	O
contours	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
22	O
(	O
3	O
)	O
:219–233	O
.	O
boykov	O
,	O
y.	O
and	O
funka-lea	O
,	O
g.	O
(	O
2006	O
)	O
.	O
graph	B
cuts	I
and	O
efﬁcient	O
n-d	O
image	B
segmentation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
70	O
(	O
2	O
)	O
:109–131	O
.	O
boykov	O
,	O
y.	O
and	O
jolly	O
,	O
m.-p.	O
(	O
2001	O
)	O
.	O
interactive	B
graph	O
cuts	O
for	O
optimal	O
boundary	O
and	O
re-	O
in	O
eighth	O
international	O
conference	O
on	O
gion	O
segmentation	B
of	O
objects	O
in	O
n-d	O
images	O
.	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
105–112	O
,	O
vancouver	O
,	O
canada	O
.	O
boykov	O
,	O
y.	O
and	O
kolmogorov	O
,	O
v.	O
(	O
2003	O
)	O
.	O
computing	O
geodesics	O
and	O
minimal	O
surfaces	O
via	O
graph	B
cuts	I
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
26–33	O
,	O
nice	O
,	O
france	O
.	O
boykov	O
,	O
y.	O
and	O
kolmogorov	O
,	O
v.	O
(	O
2004	O
)	O
.	O
an	O
experimental	O
comparison	O
of	O
min-cut/max-ﬂow	O
algorithms	O
for	O
energy	O
minimization	O
in	O
vision	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
26	O
(	O
9	O
)	O
:1124–1137	O
.	O
boykov	O
,	O
y.	O
and	O
kolmogorov	O
,	O
v.	O
(	O
2010	O
)	O
.	O
basic	O
graph	B
cut	I
algorithms	O
.	O
in	O
blake	O
,	O
a.	O
,	O
kohli	O
,	O
p.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
eds	O
)	O
,	O
advances	O
in	O
markov	O
random	O
fields	O
,	O
mit	O
press	O
.	O
boykov	O
,	O
y.	O
,	O
veksler	O
,	O
o.	O
,	O
and	O
zabih	O
,	O
r.	O
(	O
1998	O
)	O
.	O
a	O
variable	O
window	O
approach	O
to	O
early	O
vision	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
20	O
(	O
12	O
)	O
:1283–1294	O
.	O
boykov	O
,	O
y.	O
,	O
veksler	O
,	O
o.	O
,	O
and	O
zabih	O
,	O
r.	O
(	O
2001	O
)	O
.	O
fast	O
approximate	O
energy	O
minimization	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
via	O
graph	B
cuts	I
.	O
23	O
(	O
11	O
)	O
:1222–1239	O
.	O
references	B
805	O
boykov	O
,	O
y.	O
,	O
veksler	O
,	O
o.	O
,	O
and	O
zabih	O
,	O
r.	O
(	O
2010	O
)	O
.	O
optimizing	O
multi-label	O
mrfs	O
by	O
move	O
making	O
algorithms	O
.	O
in	O
blake	O
,	O
a.	O
,	O
kohli	O
,	O
p.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
eds	O
)	O
,	O
advances	O
in	O
markov	O
random	O
fields	O
,	O
mit	O
press	O
.	O
boykov	O
,	O
y.	O
,	O
kolmogorov	O
,	O
v.	O
,	O
cremers	O
,	O
d.	O
,	O
and	O
delong	O
,	O
a	O
.	O
(	O
2006	O
)	O
.	O
an	O
integral	O
solution	O
to	O
surface	B
evolution	O
pdes	O
via	O
geo-cuts	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
409–422	O
.	O
bracewell	O
,	O
r.	O
n.	O
(	O
1986	O
)	O
.	O
the	O
fourier	O
transform	B
and	O
its	O
applications	O
.	O
mcgraw-hill	O
,	O
new	O
york	O
,	O
2nd	O
edition	O
.	O
bradley	O
,	O
d.	O
,	O
boubekeur	O
,	O
t.	O
,	O
and	O
heidrich	O
,	O
w.	O
(	O
2008	O
)	O
.	O
accurate	O
multi-view	B
reconstruction	O
using	O
robust	O
binocular	O
stereo	B
and	O
surface	B
meshing	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
bradsky	O
,	O
g.	O
and	O
kaehler	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
learning	B
opencv	O
:	O
computer	O
vision	O
with	O
the	O
opencv	O
library	O
.	O
o	O
’	O
reilly	O
,	O
sebastopol	O
,	O
ca	O
.	O
brandt	O
,	O
a	O
.	O
(	O
1986	O
)	O
.	O
algebraic	O
multigrid	O
theory	O
:	O
the	O
symmetric	O
case	O
.	O
applied	O
mathematics	O
and	O
computation	O
,	O
19	O
(	O
1-4	O
)	O
:23–56	O
.	O
bregler	O
,	O
c.	O
and	O
malik	O
,	O
j	O
.	O
(	O
1998	O
)	O
.	O
tracking	O
people	O
with	O
twists	O
and	O
exponential	O
maps	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
8–15	O
,	O
santa	O
barbara	O
.	O
bregler	O
,	O
c.	O
,	O
covell	O
,	O
m.	O
,	O
and	O
slaney	O
,	O
m.	O
(	O
1997	O
)	O
.	O
video	B
rewrite	O
:	O
driving	O
visual	O
speech	O
with	O
audio	O
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
353–360	O
.	O
bregler	O
,	O
c.	O
,	O
malik	O
,	O
j.	O
,	O
and	O
pullen	O
,	O
k.	O
(	O
2004	O
)	O
.	O
twist	B
based	O
acquisition	O
and	O
tracking	O
of	O
animal	O
and	O
human	O
kinematics	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
56	O
(	O
3	O
)	O
:179–194	O
.	O
breu	O
,	O
h.	O
,	O
gil	O
,	O
j.	O
,	O
kirkpatrick	O
,	O
d.	O
,	O
and	O
werman	O
,	O
m.	O
(	O
1995	O
)	O
.	O
linear	B
time	O
euclidean	O
dis-	O
tance	O
transform	B
algorithms	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intel-	O
ligence	O
,	O
17	O
(	O
5	O
)	O
:529–533	O
.	O
brice	O
,	O
c.	O
r.	O
and	O
fennema	O
,	O
c.	O
l.	O
(	O
1970	O
)	O
.	O
scene	O
analysis	O
using	O
regions	O
.	O
artiﬁcial	O
intelli-	O
gence	O
,	O
1	O
(	O
3-4	O
)	O
:205–226	O
.	O
briggs	O
,	O
w.	O
l.	O
,	O
henson	O
,	O
v.	O
e.	O
,	O
and	O
mccormick	O
,	O
s.	O
f.	O
(	O
2000	O
)	O
.	O
a	O
multigrid	O
tutorial	O
.	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
,	O
philadelphia	O
,	O
second	O
edition	O
.	O
brillaut-o	O
’	O
mahoney	O
,	O
b	O
.	O
(	O
1991	O
)	O
.	O
new	O
method	O
for	O
vanishing	O
point	O
detection	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
54	O
(	O
2	O
)	O
:289–300	O
.	O
brinkmann	O
,	O
r.	O
(	O
2008	O
)	O
.	O
the	O
art	O
and	O
science	O
of	O
digital	O
compositing	O
.	O
morgan	O
kaufmann	O
publishers	O
,	O
san	O
francisco	O
,	O
2nd	O
edition	O
.	O
806	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
brooks	O
,	O
r.	O
a	O
.	O
(	O
1981	O
)	O
.	O
symbolic	O
reasoning	O
among	O
3-d	O
models	O
and	O
2-d	O
images	O
.	O
artiﬁcial	O
intelligence	O
,	O
17:285–348	O
.	O
brown	O
,	O
d.	O
c.	O
(	O
1971	O
)	O
.	O
close-range	O
camera	B
calibration	O
.	O
photogrammetric	O
engineering	O
,	O
37	O
(	O
8	O
)	O
:855–866	O
.	O
brown	O
,	O
l.	O
g.	O
(	O
1992	O
)	O
.	O
a	O
survey	O
of	O
image	B
registration	I
techniques	O
.	O
computing	O
surveys	B
,	O
24	O
(	O
4	O
)	O
:325–376	O
.	O
brown	O
,	O
m.	O
and	O
lowe	O
,	O
d.	O
(	O
2002	O
)	O
.	O
invariant	O
features	O
from	O
interest	O
point	O
groups	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
,	O
pp	O
.	O
656–665	O
,	O
cardiff	O
,	O
wales	O
.	O
brown	O
,	O
m.	O
and	O
lowe	O
,	O
d.	O
(	O
2003	O
)	O
.	O
unsupervised	O
3d	O
object	O
recognition	B
and	O
reconstruc-	O
tion	B
in	O
unordered	O
datasets	O
.	O
in	O
international	O
conference	O
on	O
3d	O
imaging	O
and	O
modelling	O
,	O
pp	O
.	O
1218–1225	O
,	O
nice	O
,	O
france	O
.	O
brown	O
,	O
m.	O
and	O
lowe	O
,	O
d.	O
(	O
2007	O
)	O
.	O
automatic	B
panoramic	O
image	B
stitching	I
using	O
invariant	O
features	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
74	O
(	O
1	O
)	O
:59–73	O
.	O
brown	O
,	O
m.	O
,	O
hartley	O
,	O
r.	O
,	O
and	O
nist´er	O
,	O
d.	O
(	O
2007	O
)	O
.	O
minimal	O
solutions	O
for	O
panoramic	O
stitching	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
brown	O
,	O
m.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
winder	O
,	O
s.	O
(	O
2004	O
)	O
.	O
multi-image	O
matching	B
using	O
multi-scale	O
oriented	B
patches	O
.	O
technical	O
report	O
msr-tr-2004-133	O
,	O
microsoft	O
research	O
.	O
brown	O
,	O
m.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
winder	O
,	O
s.	O
(	O
2005	O
)	O
.	O
multi-image	O
matching	B
using	O
multi-scale	O
oriented	B
patches	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pat-	O
tern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
510–517	O
,	O
san	O
diego	O
,	O
ca	O
.	O
brown	O
,	O
m.	O
z.	O
,	O
burschka	O
,	O
d.	O
,	O
and	O
hager	O
,	O
g.	O
d.	O
(	O
2003	O
)	O
.	O
advances	O
in	O
computational	O
stereo	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
25	O
(	O
8	O
)	O
:993–1008	O
.	O
brox	O
,	O
t.	O
,	O
bregler	O
,	O
c.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2009	O
)	O
.	O
large	O
displacement	O
optical	B
ﬂow	I
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
brox	O
,	O
t.	O
,	O
bruhn	O
,	O
a.	O
,	O
papenberg	O
,	O
n.	O
,	O
and	O
weickert	O
,	O
j	O
.	O
(	O
2004	O
)	O
.	O
high	O
accuracy	O
optical	B
ﬂow	I
estimation	O
based	O
on	O
a	O
theory	O
for	O
warping	O
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
25–36	O
,	O
prague	O
.	O
brubaker	O
,	O
s.	O
c.	O
,	O
wu	O
,	O
j.	O
,	O
sun	O
,	O
j.	O
,	O
mullin	O
,	O
m.	O
d.	O
,	O
and	O
rehg	O
,	O
j.	O
m.	O
(	O
2008	O
)	O
.	O
on	O
the	O
design	O
of	O
cascades	O
of	O
boosted	O
ensembles	O
for	O
face	O
detection	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
77	O
(	O
1-3	O
)	O
:65–86	O
.	O
bruhn	O
,	O
a.	O
,	O
weickert	O
,	O
j.	O
,	O
and	O
schn¨orr	O
,	O
c.	O
combining	O
local	B
and	O
global	B
optic	O
ﬂow	O
methods	O
.	O
vision	O
,	O
61	O
(	O
3	O
)	O
:211–231	O
.	O
(	O
2005	O
)	O
.	O
lucas/kanade	O
meets	O
horn/schunck	O
:	O
international	O
journal	O
of	O
computer	O
references	B
807	O
bruhn	O
,	O
a.	O
,	O
weickert	O
,	O
j.	O
,	O
kohlberger	O
,	O
t.	O
,	O
and	O
schn¨orr	O
,	O
c.	O
(	O
2006	O
)	O
.	O
a	O
multigrid	O
platform	O
for	O
real-time	O
motion	B
computation	O
with	O
discontinuity-preserving	O
variational	O
methods	O
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
70	O
(	O
3	O
)	O
:257–277	O
.	O
buades	O
,	O
a.	O
,	O
coll	O
,	O
b.	O
,	O
and	O
morel	O
,	O
j.-m.	O
(	O
2008	O
)	O
.	O
nonlocal	O
image	B
and	O
movie	O
denoising	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
76	O
(	O
2	O
)	O
:123–139	O
.	O
b˘alan	O
,	O
a.	O
o.	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2008	O
)	O
.	O
the	O
naked	O
truth	O
:	O
estimating	O
body	B
shape	O
under	O
clothing	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
15–29	O
,	O
marseilles	O
.	O
buchanan	O
,	O
a.	O
and	O
fitzgibbon	O
,	O
a	O
.	O
(	O
2005	O
)	O
.	O
damped	O
newton	O
algorithms	O
for	O
matrix	O
factoriza-	O
tion	B
with	O
missing	B
data	I
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
316–322	O
,	O
san	O
diego	O
,	O
ca	O
.	O
buck	O
,	O
i.	O
,	O
finkelstein	O
,	O
a.	O
,	O
jacobs	O
,	O
c.	O
,	O
klein	O
,	O
a.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
seims	O
,	O
j.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
toyama	O
,	O
k.	O
(	O
2000	O
)	O
.	O
performance-driven	O
hand-drawn	O
animation	O
.	O
in	O
symposium	O
on	O
non	O
photorealistic	O
animation	O
and	O
rendering	B
,	O
pp	O
.	O
101–108	O
,	O
annecy	O
.	O
buehler	O
,	O
c.	O
,	O
bosse	O
,	O
m.	O
,	O
mcmillan	O
,	O
l.	O
,	O
gortler	O
,	O
s.	O
j.	O
,	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2001	O
)	O
.	O
unstructured	B
in	O
acm	O
siggraph	O
2001	O
conference	O
proceedings	O
,	O
pp	O
.	O
425–	O
lumigraph	O
rendering	B
.	O
432.	O
bugayevskiy	O
,	O
l.	O
m.	O
and	O
snyder	O
,	O
j.	O
p.	O
(	O
1995	O
)	O
.	O
map	O
projections	B
:	O
a	O
reference	O
manual	O
.	O
crc	O
press	O
.	O
burger	O
,	O
w.	O
and	O
burge	O
,	O
m.	O
j	O
.	O
(	O
2008	O
)	O
.	O
digital	O
image	O
processing	O
:	O
an	O
algorithmic	O
introduc-	O
tion	B
using	O
java	O
.	O
springer	O
,	O
new	O
york	O
,	O
ny	O
.	O
burl	O
,	O
m.	O
c.	O
,	O
weber	O
,	O
m.	O
,	O
and	O
perona	O
,	O
p.	O
(	O
1998	O
)	O
.	O
a	O
probabilistic	B
approach	O
to	O
object	O
recog-	O
nition	O
using	O
local	O
photometry	O
and	O
global	B
geometry	O
.	O
in	O
fifth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
628–641	O
,	O
freiburg	O
,	O
germany	O
.	O
burns	O
,	O
j.	O
b.	O
,	O
hanson	O
,	O
a.	O
r.	O
,	O
and	O
riseman	O
,	O
e.	O
m.	O
(	O
1986	O
)	O
.	O
extracting	O
straight	O
lines	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-8	O
(	O
4	O
)	O
:425–455	O
.	O
burns	O
,	O
p.	O
d.	O
and	O
williams	O
,	O
d.	O
(	O
1999	O
)	O
.	O
using	O
slanted	O
edge	O
analysis	O
for	O
color	O
registration	B
measurement	O
.	O
in	O
is	O
&	O
t	O
pics	O
conference	O
,	O
pp	O
.	O
51–53	O
.	O
burt	O
,	O
p.	O
j.	O
and	O
adelson	O
,	O
e.	O
h.	O
(	O
1983a	O
)	O
.	O
the	O
laplacian	O
pyramid	B
as	O
a	O
compact	O
image	B
code	O
.	O
ieee	O
transactions	O
on	O
communications	O
,	O
com-31	O
(	O
4	O
)	O
:532–540	O
.	O
burt	O
,	O
p.	O
j.	O
and	O
adelson	O
,	O
e.	O
h.	O
(	O
1983b	O
)	O
.	O
a	O
multiresolution	O
spline	B
with	O
applications	O
to	O
image	B
mosaics	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
2	O
(	O
4	O
)	O
:217–236	O
.	O
burt	O
,	O
p.	O
j.	O
and	O
kolczynski	O
,	O
r.	O
j.	O
in	O
fourth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
93	O
)	O
,	O
pp	O
.	O
173–182	O
,	O
berlin	O
,	O
germany	O
.	O
(	O
1993	O
)	O
.	O
enhanced	O
image	B
capture	O
through	O
fusion	O
.	O
808	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
byr¨od	O
,	O
m.	O
and	O
øastr¨om	O
,	O
k.	O
(	O
2009	O
)	O
.	O
bundle	B
adjustment	I
using	O
conjugate	O
gradients	O
with	O
multiscale	O
preconditioning	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2009	O
)	O
.	O
cai	O
,	O
d.	O
,	O
he	O
,	O
x.	O
,	O
hu	O
,	O
y.	O
,	O
han	O
,	O
j.	O
,	O
and	O
huang	O
,	O
t.	O
(	O
2007	O
)	O
.	O
learning	B
a	O
spatially	O
smooth	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
subspace	O
for	O
face	O
recognition	B
.	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
campbell	O
,	O
n.	O
d.	O
f.	O
,	O
vogiatzis	O
,	O
g.	O
,	O
hern´andez	O
,	O
c.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2008	O
)	O
.	O
using	O
multiple	O
hypotheses	O
to	O
improve	O
depth-maps	O
for	O
multi-view	O
stereo	B
.	O
in	O
tenth	O
european	O
confer-	O
ence	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
766–779	O
,	O
marseilles	O
.	O
can	O
,	O
a.	O
,	O
stewart	O
,	O
c.	O
,	O
roysam	O
,	O
b.	O
,	O
and	O
tanenbaum	O
,	O
h.	O
(	O
2002	O
)	O
.	O
a	O
feature-based	B
,	O
robust	B
,	O
hierarchical	B
algorithm	O
for	O
registering	O
pairs	B
of	O
images	O
of	O
the	O
curved	O
human	O
retina	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
3	O
)	O
:347–364	O
.	O
canny	O
,	O
j	O
.	O
(	O
1986	O
)	O
.	O
a	O
computational	O
approach	O
to	O
edge	O
detection	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-8	O
(	O
6	O
)	O
:679–698	O
.	O
cao	O
,	O
z.	O
,	O
yin	O
,	O
q.	O
,	O
tang	O
,	O
x.	O
,	O
and	O
sun	O
,	O
j	O
.	O
(	O
2010	O
)	O
.	O
face	B
recognition	O
with	O
learning-based	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
descriptor	O
.	O
recognition	B
(	O
cvpr	O
2010	O
)	O
,	O
san	O
francisco	O
,	O
ca	O
.	O
capel	O
,	O
d.	O
(	O
2004	O
)	O
.	O
image	B
mosaicing	O
and	O
super-resolution	O
.	O
distinguished	O
dissertation	O
series	O
,	O
british	O
computer	O
society	O
,	O
springer-verlag	O
.	O
capel	O
,	O
d.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1998	O
)	O
.	O
automated	B
mosaicing	O
with	O
super-resolution	O
zoom	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
885–891	O
,	O
santa	O
barbara	O
.	O
capel	O
,	O
d.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2000	O
)	O
.	O
super-resolution	O
enhancement	O
of	O
text	O
image	B
se-	O
quences	O
.	O
in	O
fifteenth	O
international	O
conference	O
on	O
pattern	O
recognition	B
(	O
icpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
600–605	O
,	O
barcelona	O
,	O
spain	O
.	O
capel	O
,	O
d.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2003	O
)	O
.	O
computer	O
vision	O
applied	O
to	O
super	O
resolution	O
.	O
ieee	O
signal	O
processing	O
magazine	O
,	O
20	O
(	O
3	O
)	O
:75–86	O
.	O
capel	O
,	O
d.	O
p.	O
(	O
2001	O
)	O
.	O
super-resolution	O
and	O
image	B
mosaicing	O
.	O
ph.d.	O
thesis	O
,	O
university	O
of	O
oxford	O
.	O
caprile	O
,	O
b.	O
and	O
torre	O
,	O
v.	O
(	O
1990	O
)	O
.	O
using	O
vanishing	O
points	B
for	O
camera	B
calibration	O
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
4	O
(	O
2	O
)	O
:127–139	O
.	O
carneiro	O
,	O
g.	O
and	O
jepson	O
,	O
a	O
.	O
(	O
2005	O
)	O
.	O
the	O
distinctiveness	O
,	O
detectability	O
,	O
and	O
robustness	O
of	O
local	B
image	O
features	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
296–301	O
,	O
san	O
diego	O
,	O
ca	O
.	O
carneiro	O
,	O
g.	O
and	O
lowe	O
,	O
d.	O
(	O
2006	O
)	O
.	O
sparse	B
ﬂexible	O
models	O
of	O
local	B
features	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
29–43	O
.	O
references	B
809	O
carnevali	O
,	O
p.	O
,	O
coletti	O
,	O
l.	O
,	O
and	O
patarnello	O
,	O
s.	O
(	O
1985	O
)	O
.	O
image	B
processing	O
by	O
simulated	O
anneal-	O
ing	O
.	O
ibm	O
journal	O
of	O
research	O
and	O
development	O
,	O
29	O
(	O
6	O
)	O
:569–579	O
.	O
carranza	O
,	O
j.	O
,	O
theobalt	O
,	O
c.	O
,	O
magnor	O
,	O
m.	O
a.	O
,	O
and	O
seidel	O
,	O
h.-p.	O
(	O
2003	O
)	O
.	O
free-viewpoint	O
video	B
of	O
human	O
actors	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2003	O
)	O
,	O
22	O
(	O
3	O
)	O
:569–	O
577.	O
carroll	O
,	O
r.	O
,	O
agrawala	O
,	O
m.	O
,	O
and	O
agarwala	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
optimizing	O
content-preserving	O
pro-	O
jections	O
for	O
wide-angle	O
images	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
28	O
(	O
3	O
)	O
.	O
caselles	O
,	O
v.	O
,	O
kimmel	O
,	O
r.	O
,	O
and	O
sapiro	O
,	O
g.	O
(	O
1997	O
)	O
.	O
geodesic	O
active	O
contours	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
21	O
(	O
1	O
)	O
:61–79	O
.	O
catmull	O
,	O
e.	O
and	O
smith	O
,	O
a.	O
r.	O
(	O
1980	O
)	O
.	O
3-d	O
transformations	O
of	O
images	O
in	O
scanline	O
order	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
80	O
)	O
,	O
14	O
(	O
3	O
)	O
:279–285	O
.	O
celniker	O
,	O
g.	O
and	O
gossard	O
,	O
d.	O
(	O
1991	O
)	O
.	O
deformable	O
curve	O
and	O
surface	B
ﬁnite-elements	O
for	O
free-form	O
shape	O
design	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
91	O
)	O
,	O
25	O
(	O
4	O
)	O
:257–266	O
.	O
chakrabarti	O
,	O
a.	O
,	O
scharstein	O
,	O
d.	O
,	O
and	O
zickler	O
,	O
t.	O
(	O
2009	O
)	O
.	O
an	O
empirical	O
camera	B
model	O
for	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2009	O
)	O
,	O
london	O
,	O
internet	O
color	B
vision	O
.	O
uk	O
.	O
cham	O
,	O
t.	O
j.	O
and	O
cipolla	O
,	O
r.	O
(	O
1998	O
)	O
.	O
a	O
statistical	O
framework	O
for	O
long-range	O
feature	B
matching	O
in	O
uncalibrated	O
image	B
mosaicing	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
442–447	O
,	O
santa	O
barbara	O
.	O
cham	O
,	O
t.-j	O
.	O
and	O
rehg	O
,	O
j.	O
m.	O
(	O
1999	O
)	O
.	O
a	O
multiple	B
hypothesis	I
approach	O
to	O
ﬁgure	O
tracking	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
99	O
)	O
,	O
pp	O
.	O
239–245	O
,	O
fort	O
collins	O
.	O
champleboux	O
,	O
g.	O
,	O
lavall´ee	O
,	O
s.	O
,	O
sautot	O
,	O
p.	O
,	O
and	O
cinquin	O
,	O
p.	O
(	O
1992	O
)	O
.	O
accurate	O
calibration	B
of	O
cameras	O
and	O
range	O
imaging	O
sensors	O
,	O
the	O
npbs	O
method	O
.	O
in	O
ieee	O
international	O
confer-	O
ence	O
on	O
robotics	O
and	O
automation	O
,	O
pp	O
.	O
1552–1558	O
,	O
nice	O
,	O
france	O
.	O
champleboux	O
,	O
g.	O
,	O
lavall´ee	O
,	O
s.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
brunie	O
,	O
l.	O
(	O
1992	O
)	O
.	O
from	O
accurate	O
range	O
imaging	O
sensor	B
calibration	O
to	O
accurate	O
model-based	B
3-d	O
object	O
localization	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
92	O
)	O
,	O
pp	O
.	O
83–89	O
,	O
champaign	O
,	O
illinois	O
.	O
chan	O
,	O
a.	O
b.	O
and	O
vasconcelos	O
,	O
n.	O
(	O
2009	O
)	O
.	O
layered	B
dynamic	O
textures	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
31	O
(	O
10	O
)	O
:1862–1879	O
.	O
chan	O
,	O
t.	O
f.	O
and	O
vese	O
,	O
l.	O
a	O
.	O
(	O
1992	O
)	O
.	O
active	B
contours	I
without	O
edges	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
10	O
(	O
2	O
)	O
:266–277	O
.	O
chan	O
,	O
t.	O
f.	O
,	O
osher	O
,	O
s.	O
,	O
and	O
shen	O
,	O
j	O
.	O
(	O
2001	O
)	O
.	O
the	O
digital	O
tv	O
ﬁlter	O
and	O
nonlinear	O
denoising	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
10	O
(	O
2	O
)	O
:231–241	O
.	O
810	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
chang	O
,	O
m.	O
m.	O
,	O
tekalp	O
,	O
a.	O
m.	O
,	O
and	O
sezan	O
,	O
m.	O
i	O
.	O
(	O
1997	O
)	O
.	O
simultaneous	O
motion	B
estimation	I
and	O
segmentation	B
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
6	O
(	O
9	O
)	O
:1326–1333	O
.	O
chaudhuri	O
,	O
s.	O
(	O
2001	O
)	O
.	O
super-resolution	O
imaging	O
.	O
springer	O
.	O
chaudhuri	O
,	O
s.	O
and	O
rajagopalan	O
,	O
a.	O
n.	O
(	O
1999	O
)	O
.	O
depth	O
from	O
defocus	O
:	O
a	O
real	O
aperture	O
imaging	O
approach	O
.	O
springer	O
.	O
cheeseman	O
,	O
p.	O
,	O
kanefsky	O
,	O
b.	O
,	O
hanson	O
,	O
r.	O
,	O
and	O
stutz	O
,	O
j	O
.	O
(	O
1993	O
)	O
.	O
super-resolved	O
surface	B
reconstruction	I
from	O
multiple	B
images	O
.	O
technical	O
report	O
fia-93-02	O
,	O
nasa	O
ames	O
re-	O
search	O
center	O
,	O
artiﬁcial	O
intelligence	O
branch	O
.	O
chellappa	O
,	O
r.	O
,	O
wilson	O
,	O
c.	O
,	O
and	O
sirohey	O
,	O
s.	O
(	O
1995	O
)	O
.	O
human	O
and	O
machine	O
recognition	O
of	O
faces	B
:	O
a	O
survey	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
83	O
(	O
5	O
)	O
:705–740	O
.	O
chen	O
,	O
b.	O
,	O
neubert	O
,	O
b.	O
,	O
ofek	O
,	O
e.	O
,	O
deussen	O
,	O
o.	O
,	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2009	O
)	O
.	O
integrated	O
videos	O
and	O
maps	O
for	O
driving	O
directions	O
.	O
in	O
uist	O
’	O
09	O
:	O
proceedings	O
of	O
the	O
22nd	O
annual	O
acm	O
symposium	O
on	O
user	O
interface	O
software	O
and	O
technology	O
,	O
pp	O
.	O
223–232	O
,	O
victoria	O
,	O
bc	O
,	O
canada	O
,	O
new	O
york	O
,	O
ny	O
,	O
usa	O
.	O
chen	O
,	O
c.-y	O
.	O
and	O
klette	O
,	O
r.	O
(	O
1999	O
)	O
.	O
image	B
stitching	I
-	O
comparisons	O
and	O
new	O
techniques	O
.	O
in	O
computer	O
analysis	O
of	O
images	O
and	O
patterns	B
(	O
caip	O
’	O
99	O
)	O
,	O
pp	O
.	O
615–622	O
,	O
ljubljana	O
.	O
chen	O
,	O
j.	O
and	O
chen	O
,	O
b	O
.	O
(	O
2008	O
)	O
.	O
architectural	O
modeling	B
from	O
sparsely	O
scanned	O
range	O
data	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
78	O
(	O
2-3	O
)	O
:223–236	O
.	O
chen	O
,	O
j.	O
,	O
paris	O
,	O
s.	O
,	O
and	O
durand	O
,	O
f.	O
(	O
2007	O
)	O
.	O
real-time	O
edge-aware	O
image	B
processing	O
with	O
the	O
bilateral	B
grid	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
chen	O
,	O
s.	O
and	O
williams	O
,	O
l.	O
(	O
1993	O
)	O
.	O
view	B
interpolation	I
for	O
image	B
synthesis	O
.	O
in	O
acm	O
sig-	O
graph	O
1993	O
conference	O
proceedings	O
,	O
pp	O
.	O
279–288	O
.	O
chen	O
,	O
s.	O
e.	O
(	O
1995	O
)	O
.	O
quicktime	O
vr	O
–	O
an	O
image-based	B
approach	O
to	O
virtual	O
environment	O
nav-	O
igation	O
.	O
in	O
acm	O
siggraph	O
1995	O
conference	O
proceedings	O
,	O
pp	O
.	O
29–38	O
,	O
los	O
angeles	O
.	O
chen	O
,	O
y.	O
and	O
medioni	O
,	O
g.	O
(	O
1992	O
)	O
.	O
object	O
modeling	B
by	O
registration	B
of	O
multiple	B
range	O
im-	O
ages	O
.	O
image	B
and	O
vision	O
computing	O
,	O
10	O
(	O
3	O
)	O
:145–155	O
.	O
cheng	O
,	O
l.	O
,	O
vishwanathan	O
,	O
s.	O
v.	O
n.	O
,	O
and	O
zhang	O
,	O
x	O
.	O
(	O
2008	O
)	O
.	O
consistent	O
image	B
analogies	O
using	O
semi-supervised	O
learning	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
cheng	O
,	O
y	O
.	O
(	O
1995	O
)	O
.	O
mean	B
shift	I
,	O
mode	O
seeking	O
,	O
and	O
clustering	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
17	O
(	O
8	O
)	O
:790–799	O
.	O
chiang	O
,	O
m.-c.	O
and	O
boult	O
,	O
t.	O
e.	O
(	O
1996	O
)	O
.	O
efﬁcient	O
image	B
warping	O
and	O
super-resolution	O
.	O
in	O
ieee	O
workshop	O
on	O
applications	O
of	O
computer	O
vision	O
(	O
wacv	O
’	O
96	O
)	O
,	O
pp	O
.	O
56–61	O
,	O
sarasota	O
.	O
references	B
811	O
chiu	O
,	O
k.	O
and	O
raskar	O
,	O
r.	O
(	O
2009	O
)	O
.	O
computer	O
vision	O
on	O
tap	O
.	O
in	O
second	O
ieee	O
workshop	O
on	O
internet	O
vision	O
,	O
miami	O
beach	O
,	O
florida	O
.	O
chou	O
,	O
p.	O
b.	O
and	O
brown	O
,	O
c.	O
m.	O
(	O
1990	O
)	O
.	O
the	O
theory	O
and	O
practice	O
of	O
bayesian	O
image	B
labeling	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
4	O
(	O
3	O
)	O
:185–210	O
.	O
christensen	O
,	O
g.	O
,	O
joshi	O
,	O
s.	O
,	O
and	O
miller	O
,	O
m.	O
(	O
1997	O
)	O
.	O
volumetric	B
transformation	O
of	O
brain	O
anatomy	O
.	O
ieee	O
transactions	O
on	O
medical	B
imaging	I
,	O
16	O
(	O
6	O
)	O
:864–877	O
.	O
christy	O
,	O
s.	O
and	O
horaud	O
,	O
r.	O
(	O
1996	O
)	O
.	O
euclidean	O
shape	O
and	O
motion	B
from	O
multiple	B
perspec-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
tive	O
views	O
by	O
afﬁne	O
iterations	O
.	O
intelligence	O
,	O
18	O
(	O
11	O
)	O
:1098–1104	O
.	O
chuang	O
,	O
y.-y.	O
,	O
curless	O
,	O
b.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2001	O
)	O
.	O
a	O
bayesian	O
approach	O
to	O
digital	O
matting	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2001	O
)	O
,	O
pp	O
.	O
264–271	O
,	O
kauai	O
,	O
hawaii	O
.	O
chuang	O
,	O
y.-y.	O
,	O
agarwala	O
,	O
a.	O
,	O
curless	O
,	O
b.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2002	O
)	O
.	O
video	B
matting	O
of	O
complex	O
scenes	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2002	O
)	O
,	O
21	O
(	O
3	O
)	O
:243–248	O
.	O
chuang	O
,	O
y.-y.	O
,	O
goldman	O
,	O
d.	O
b.	O
,	O
curless	O
,	O
b.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2003	O
)	O
.	O
shadow	B
matting	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2003	O
)	O
,	O
22	O
(	O
3	O
)	O
:494–	O
500.	O
chuang	O
,	O
y.-y.	O
,	O
goldman	O
,	O
d.	O
b.	O
,	O
zheng	O
,	O
k.	O
c.	O
,	O
curless	O
,	O
b.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2005	O
)	O
.	O
animating	B
pictures	I
with	O
stochastic	O
motion	O
textures	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:853–860	O
.	O
chuang	O
,	O
y.-y.	O
,	O
zongker	O
,	O
d.	O
,	O
hindorff	O
,	O
j.	O
,	O
curless	O
,	O
b.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2000	O
)	O
.	O
environment	O
matting	O
extensions	O
:	O
towards	O
higher	O
accuracy	O
and	O
real-time	O
cap-	O
ture	O
.	O
in	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
121–130	O
,	O
new	O
orleans	O
.	O
chui	O
,	O
c.	O
k.	O
(	O
1992	O
)	O
.	O
wavelet	O
analysis	O
and	O
its	O
applications	O
.	O
academic	O
press	O
,	O
new	O
york	O
.	O
chum	O
,	O
o.	O
and	O
matas	O
,	O
j	O
.	O
(	O
2005	O
)	O
.	O
matching	B
with	O
prosac—progressive	O
sample	O
consensus	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
220–226	O
,	O
san	O
diego	O
,	O
ca	O
.	O
chum	O
,	O
o.	O
and	O
matas	O
,	O
j	O
.	O
(	O
2010	O
)	O
.	O
large-scale	O
discovery	O
of	O
spatially	O
related	O
images	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
32	O
(	O
2	O
)	O
:371–377	O
.	O
chum	O
,	O
o.	O
,	O
philbin	O
,	O
j.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
near	O
duplicate	O
image	B
detection	O
:	O
min-	O
hash	O
and	O
tf-idf	O
weighting	B
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2008	O
)	O
,	O
leeds	O
,	O
england	O
.	O
812	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
chum	O
,	O
o.	O
,	O
philbin	O
,	O
j.	O
,	O
sivic	O
,	O
j.	O
,	O
isard	O
,	O
m.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2007	O
)	O
.	O
total	B
recall	O
:	O
auto-	O
matic	O
query	B
expansion	I
with	O
a	O
generative	O
feature	B
model	O
for	O
object	O
retrieval	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
cipolla	O
,	O
r.	O
and	O
blake	O
,	O
a	O
.	O
(	O
1990	O
)	O
.	O
the	O
dynamic	B
analysis	O
of	O
apparent	O
contours	O
.	O
in	O
third	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
90	O
)	O
,	O
pp	O
.	O
616–623	O
,	O
osaka	O
,	O
japan	O
.	O
cipolla	O
,	O
r.	O
and	O
blake	O
,	O
a	O
.	O
(	O
1992	O
)	O
.	O
surface	B
shape	O
from	O
the	O
deformation	O
of	O
apparent	O
contours	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
9	O
(	O
2	O
)	O
:83–112	O
.	O
cipolla	O
,	O
r.	O
and	O
giblin	O
,	O
p.	O
(	O
2000	O
)	O
.	O
visual	O
motion	O
of	O
curves	O
and	O
surfaces	O
.	O
cambridge	O
university	O
press	O
,	O
cambridge	O
.	O
cipolla	O
,	O
r.	O
,	O
drummond	O
,	O
t.	O
,	O
and	O
robertson	O
,	O
d.	O
p.	O
(	O
1999	O
)	O
.	O
camera	B
calibration	O
from	O
van-	O
ishing	O
points	B
in	O
images	O
of	O
architectural	O
scenes	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc99	O
)	O
.	O
claus	O
,	O
d.	O
and	O
fitzgibbon	O
,	O
a	O
.	O
(	O
2005	O
)	O
.	O
a	O
rational	O
function	O
lens	O
distortion	O
model	O
for	O
gen-	O
eral	O
cameras	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
213–219	O
,	O
san	O
diego	O
,	O
ca	O
.	O
clowes	O
,	O
m.	O
b	O
.	O
(	O
1971	O
)	O
.	O
on	O
seeing	O
things	O
.	O
artiﬁcial	O
intelligence	O
,	O
2:79–116	O
.	O
cohen	O
,	O
l.	O
d.	O
and	O
cohen	O
,	O
i	O
.	O
(	O
1993	O
)	O
.	O
finite-element	O
methods	O
for	O
active	O
contour	O
models	O
and	O
balloons	O
for	O
2-d	O
and	O
3-d	O
images	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
15	O
(	O
11	O
)	O
:1131–1147	O
.	O
cohen	O
,	O
m.	O
and	O
wallace	O
,	O
j	O
.	O
(	O
1993	O
)	O
.	O
radiosity	B
and	O
realistic	O
image	B
synthesis	O
.	O
morgan	O
kaufmann	O
.	O
cohen	O
,	O
m.	O
f.	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
the	O
moment	O
camera	B
.	O
computer	O
,	O
39	O
(	O
8	O
)	O
:40–45	O
.	O
collins	O
,	O
r.	O
t.	O
(	O
1996	O
)	O
.	O
a	O
space-sweep	O
approach	O
to	O
true	O
multi-image	O
matching	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
96	O
)	O
,	O
pp	O
.	O
358–363	O
,	O
san	O
francisco	O
.	O
collins	O
,	O
r.	O
t.	O
and	O
liu	O
,	O
y	O
.	O
(	O
2003	O
)	O
.	O
on-line	O
selection	O
of	O
discriminative	O
tracking	O
features	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
346–352	O
,	O
nice	O
,	O
france	O
.	O
collins	O
,	O
r.	O
t.	O
and	O
weiss	O
,	O
r.	O
s.	O
(	O
1990	O
)	O
.	O
vanishing	O
point	O
calculation	O
as	O
a	O
statistical	O
inference	B
on	O
the	O
unit	O
sphere	O
.	O
in	O
third	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
90	O
)	O
,	O
pp	O
.	O
400–403	O
,	O
osaka	O
,	O
japan	O
.	O
comaniciu	O
,	O
d.	O
and	O
meer	O
,	O
p.	O
(	O
2002	O
)	O
.	O
mean	B
shift	I
:	O
a	O
robust	B
approach	O
toward	O
feature	B
space	O
analysis	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
5	O
)	O
:603–	O
619.	O
references	B
813	O
comaniciu	O
,	O
d.	O
and	O
meer	O
,	O
p.	O
(	O
2003	O
)	O
.	O
an	O
algorithm	B
for	O
data-driven	O
bandwidth	B
selection	I
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
25	O
(	O
2	O
)	O
:281–288	O
.	O
conn	O
,	O
a.	O
r.	O
,	O
gould	O
,	O
n.	O
i.	O
m.	O
,	O
and	O
toint	O
,	O
p.	O
l.	O
(	O
2000	O
)	O
.	O
trust-region	O
methods	O
.	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
,	O
philadephia	O
.	O
cook	O
,	O
r.	O
l.	O
and	O
torrance	O
,	O
k.	O
e.	O
(	O
1982	O
)	O
.	O
a	O
reﬂectance	B
model	O
for	O
computer	O
graphics	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
1	O
(	O
1	O
)	O
:7–24	O
.	O
coorg	O
,	O
s.	O
and	O
teller	O
,	O
s.	O
(	O
2000	O
)	O
.	O
spherical	B
mosaics	O
with	O
quaternions	O
and	O
dense	O
correlation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
37	O
(	O
3	O
)	O
:259–273	O
.	O
cootes	O
,	O
t.	O
,	O
edwards	O
,	O
g.	O
j.	O
,	O
and	O
taylor	O
,	O
c.	O
j	O
.	O
(	O
2001	O
)	O
.	O
active	O
appearance	O
models	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
23	O
(	O
6	O
)	O
:681–685	O
.	O
cootes	O
,	O
t.	O
,	O
cooper	O
,	O
d.	O
,	O
taylor	O
,	O
c.	O
,	O
and	O
graham	O
,	O
j	O
.	O
(	O
1995	O
)	O
.	O
active	O
shape	O
models—their	O
training	O
and	O
application	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
61	O
(	O
1	O
)	O
:38–59	O
.	O
cootes	O
,	O
t.	O
,	O
taylor	O
,	O
c.	O
,	O
lanitis	O
,	O
a.	O
,	O
cooper	O
,	O
d.	O
,	O
and	O
graham	O
,	O
j	O
.	O
(	O
1993	O
)	O
.	O
building	O
and	O
using	O
ﬂexible	O
models	O
incorporating	O
grey-level	O
information	O
.	O
in	O
fourth	O
international	O
confer-	O
ence	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
93	O
)	O
,	O
pp	O
.	O
242–246	O
,	O
berlin	O
,	O
germany	O
.	O
cootes	O
,	O
t.	O
f.	O
and	O
taylor	O
,	O
c.	O
j	O
.	O
(	O
2001	O
)	O
.	O
statistical	O
models	O
of	O
appearance	O
for	O
medical	O
image	B
analysis	O
and	O
computer	O
vision	O
.	O
in	O
medical	B
imaging	I
.	O
coquillart	O
,	O
s.	O
(	O
1990	O
)	O
.	O
extended	O
free-form	O
deformations	O
:	O
a	O
sculpturing	O
tool	O
for	O
3d	O
geo-	O
metric	O
modeling	B
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
90	O
)	O
,	O
24	O
(	O
4	O
)	O
:187–196	O
.	O
cormen	O
,	O
t.	O
h.	O
(	O
2001	O
)	O
.	O
introduction	O
to	O
algorithms	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
cornelis	O
,	O
n.	O
,	O
leibe	O
,	O
b.	O
,	O
cornelis	O
,	O
k.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2008	O
)	O
.	O
3d	O
urban	O
scene	O
modeling	O
integrating	O
recognition	B
and	O
reconstruction	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
78	O
(	O
2-3	O
)	O
:121–141	O
.	O
corso	O
,	O
j.	O
and	O
hager	O
,	O
g.	O
(	O
2005	O
)	O
.	O
coherent	O
regions	O
for	O
concise	O
and	O
stable	O
image	B
description	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
184–190	O
,	O
san	O
diego	O
,	O
ca	O
.	O
costeira	O
,	O
j.	O
and	O
kanade	O
,	O
t.	O
(	O
1995	O
)	O
.	O
a	O
multi-body	O
factorization	B
method	O
for	O
motion	O
analy-	O
sis	O
.	O
in	O
fifth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
95	O
)	O
,	O
pp	O
.	O
1071–1076	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
costen	O
,	O
n.	O
,	O
cootes	O
,	O
t.	O
f.	O
,	O
edwards	O
,	O
g.	O
j.	O
,	O
and	O
taylor	O
,	O
c.	O
j	O
.	O
(	O
1999	O
)	O
.	O
simultaneous	O
extrac-	O
tion	B
of	O
functional	O
face	B
subspaces	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
99	O
)	O
,	O
pp	O
.	O
492–497	O
,	O
fort	O
collins	O
.	O
couprie	O
,	O
c.	O
,	O
grady	O
,	O
l.	O
,	O
najman	O
,	O
l.	O
,	O
and	O
talbot	O
,	O
h.	O
(	O
2009	O
)	O
.	O
power	O
watersheds	O
:	O
a	O
new	O
image	B
segmentation	O
framework	O
extending	O
graph	B
cuts	I
,	O
random	B
walker	I
and	O
optimal	O
spanning	O
814	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
forest	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
cour	O
,	O
t.	O
,	O
b´en´ezit	O
,	O
f.	O
,	O
and	O
shi	O
,	O
j	O
.	O
(	O
2005	O
)	O
.	O
spectral	O
segmentation	B
with	O
multiscale	O
graph	O
decomposition	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
1123–1130	O
,	O
san	O
diego	O
,	O
ca	O
.	O
cox	O
,	O
d.	O
,	O
little	O
,	O
j.	O
,	O
and	O
o	O
’	O
shea	O
,	O
d.	O
(	O
2007	O
)	O
.	O
ideals	O
,	O
varieties	O
,	O
and	O
algorithms	O
:	O
an	O
introduc-	O
tion	B
to	O
computational	O
algebraic	O
geometry	O
and	O
commutative	O
algebra	O
.	O
springer	O
.	O
cox	O
,	O
i.	O
j	O
.	O
(	O
1994	O
)	O
.	O
a	O
maximum	O
likelihood	O
n-camera	O
stereo	B
algorithm	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
94	O
)	O
,	O
pp	O
.	O
733–	O
739	O
,	O
seattle	O
.	O
cox	O
,	O
i.	O
j.	O
,	O
roy	O
,	O
s.	O
,	O
and	O
hingorani	O
,	O
s.	O
l.	O
(	O
1995	O
)	O
.	O
dynamic	B
histogram	O
warping	O
of	O
image	B
pairs	O
for	O
constant	O
image	B
brightness	O
.	O
in	O
ieee	O
international	O
conference	O
on	O
image	B
processing	O
(	O
icip	O
’	O
95	O
)	O
,	O
pp	O
.	O
366–369	O
.	O
cox	O
,	O
i.	O
j.	O
,	O
hingorani	O
,	O
s.	O
l.	O
,	O
rao	O
,	O
s.	O
b.	O
,	O
and	O
maggs	O
,	O
b.	O
m.	O
(	O
1996	O
)	O
.	O
a	O
maximum	O
likelihood	O
stereo	B
algorithm	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
63	O
(	O
3	O
)	O
:542–567	O
.	O
crandall	O
,	O
d.	O
and	O
huttenlocher	O
,	O
d.	O
(	O
2007	O
)	O
.	O
composite	O
models	O
of	O
objects	O
and	O
scenes	O
for	O
category	O
recognition	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
crandall	O
,	O
d.	O
,	O
felzenszwalb	O
,	O
p.	O
,	O
and	O
huttenlocher	O
,	O
d.	O
(	O
2005	O
)	O
.	O
spatial	O
priors	O
for	O
part-based	O
recognition	B
using	O
statistical	O
models	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
com-	O
puter	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
10–17	O
,	O
san	O
diego	O
,	O
ca	O
.	O
crandall	O
,	O
d.	O
,	O
backstrom	O
,	O
l.	O
,	O
huttenlocher	O
,	O
d.	O
,	O
and	O
kleinberg	O
,	O
j	O
.	O
(	O
2009	O
)	O
.	O
mapping	O
the	O
world	O
’	O
s	O
photos	O
.	O
in	O
18th	O
int	O
.	O
world	O
wide	O
web	O
conference	O
,	O
pp	O
.	O
761–770	O
,	O
madrid	O
.	O
crandall	O
,	O
d.	O
j.	O
and	O
huttenlocher	O
,	O
d.	O
p.	O
(	O
2006	O
)	O
.	O
weakly	O
supervised	O
learning	B
of	O
part-based	B
spatial	O
models	O
for	O
visual	O
object	O
recognition	B
.	O
in	O
ninth	O
european	O
conference	O
on	O
com-	O
puter	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
16–29	O
.	O
crane	O
,	O
r.	O
(	O
1997	O
)	O
.	O
a	O
simpliﬁed	O
approach	O
to	O
image	B
processing	O
.	O
prentice	O
hall	O
,	O
upper	O
saddle	O
river	O
,	O
nj	O
.	O
craswell	O
,	O
n.	O
and	O
szummer	O
,	O
m.	O
(	O
2007	O
)	O
.	O
random	O
walks	O
on	O
the	O
click	O
graph	O
.	O
in	O
acm	O
sigir	O
conference	O
on	O
research	O
and	O
development	O
in	O
informaion	O
retrieval	O
,	O
pp	O
.	O
239–246	O
,	O
new	O
york	O
,	O
ny	O
.	O
cremers	O
,	O
d.	O
and	O
soatto	O
,	O
s.	O
(	O
2005	O
)	O
.	O
motion	B
competition	O
:	O
a	O
variational	O
framework	O
for	O
piecewise	O
parametric	B
motion	O
segmentation	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
62	O
(	O
3	O
)	O
:249–265	O
.	O
references	B
815	O
cremers	O
,	O
d.	O
,	O
rousson	O
,	O
m.	O
,	O
and	O
deriche	O
,	O
r.	O
(	O
2007	O
)	O
.	O
a	O
review	O
of	O
statistical	O
approaches	O
to	O
level	O
set	O
segmentation	B
:	O
integrating	O
color	B
,	O
texture	B
,	O
motion	B
and	O
shape	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
72	O
(	O
2	O
)	O
:195–215	O
.	O
crevier	O
,	O
d.	O
(	O
1993	O
)	O
.	O
ai	O
:	O
the	O
tumultuous	O
search	O
for	O
artiﬁcial	O
intelligence	O
.	O
basicbooks	O
,	O
new	O
york	O
,	O
ny	O
.	O
criminisi	O
,	O
a.	O
,	O
p´erez	O
,	O
p.	O
,	O
and	O
toyama	O
,	O
k.	O
(	O
2004	O
)	O
.	O
region	B
ﬁlling	O
and	O
object	O
removal	O
by	O
exemplar-based	O
inpainting	B
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
13	O
(	O
9	O
)	O
:1200–1212	O
.	O
criminisi	O
,	O
a.	O
,	O
reid	O
,	O
i.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2000	O
)	O
.	O
single	O
view	O
metrology	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
40	O
(	O
2	O
)	O
:123–148	O
.	O
criminisi	O
,	O
a.	O
,	O
sharp	O
,	O
t.	O
,	O
and	O
blake	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
geos	O
:	O
geodesic	O
image	O
segmentation	B
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
99–112	O
,	O
marseilles	O
.	O
criminisi	O
,	O
a.	O
,	O
cross	O
,	O
g.	O
,	O
blake	O
,	O
a.	O
,	O
and	O
kolmogorov	O
,	O
v.	O
(	O
2006	O
)	O
.	O
bilayer	O
segmentation	B
of	O
live	O
video	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
53–60	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
criminisi	O
,	O
a.	O
,	O
shotton	O
,	O
j.	O
,	O
blake	O
,	O
a.	O
,	O
and	O
torr	O
,	O
p.	O
(	O
2003	O
)	O
.	O
gaze	O
manipulation	O
for	O
one-to-one	O
teleconferencing	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
191–198	O
,	O
nice	O
,	O
france	O
.	O
criminisi	O
,	O
a.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
swaminathan	O
,	O
r.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
anandan	O
,	O
p.	O
(	O
2005	O
)	O
.	O
extract-	O
ing	O
layers	B
and	O
analyzing	O
their	O
specular	B
properties	O
using	O
epipolar-plane-image	O
analysis	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
97	O
(	O
1	O
)	O
:51–85	O
.	O
criminisi	O
,	O
a.	O
,	O
shotton	O
,	O
j.	O
,	O
blake	O
,	O
a.	O
,	O
rother	O
,	O
c.	O
,	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2007	O
)	O
.	O
efﬁcient	O
dense	O
international	O
journal	O
of	O
stereo	B
with	O
occlusion	O
by	O
four-state	O
dynamic	B
programming	I
.	O
computer	O
vision	O
,	O
71	O
(	O
1	O
)	O
:89–110	O
.	O
crow	O
,	O
f.	O
c.	O
(	O
1984	O
)	O
.	O
summed-area	O
table	O
for	O
texture	O
mapping	O
.	O
computer	O
graphics	O
(	O
sig-	O
graph	O
’	O
84	O
)	O
,	O
18	O
(	O
3	O
)	O
:207–212	O
.	O
crowley	O
,	O
j.	O
l.	O
and	O
stern	O
,	O
r.	O
m.	O
(	O
1984	O
)	O
.	O
fast	O
computation	O
of	O
the	O
difference	B
of	O
low-pass	B
transform	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
6	O
(	O
2	O
)	O
:212–	O
222.	O
csurka	O
,	O
g.	O
and	O
perronnin	O
,	O
f.	O
(	O
2008	O
)	O
.	O
a	O
simple	O
high	O
performance	O
approach	O
to	O
semantic	O
segmentation	B
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2008	O
)	O
,	O
leeds	O
.	O
csurka	O
,	O
g.	O
,	O
dance	O
,	O
c.	O
r.	O
,	O
perronnin	O
,	O
f.	O
,	O
and	O
willamowski	O
,	O
j	O
.	O
(	O
2006	O
)	O
.	O
generic	O
visual	O
cate-	O
gorization	O
using	O
weak	O
geometry	O
.	O
in	O
ponce	O
,	O
j.	O
,	O
hebert	O
,	O
m.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
eds	O
)	O
,	O
toward	O
category-level	O
object	O
recognition	B
,	O
pp	O
.	O
207–224	O
,	O
springer	O
,	O
new	O
york	O
.	O
816	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
csurka	O
,	O
g.	O
,	O
dance	O
,	O
c.	O
r.	O
,	O
fan	O
,	O
l.	O
,	O
willamowski	O
,	O
j.	O
,	O
and	O
bray	O
,	O
c.	O
(	O
2004	O
)	O
.	O
visual	O
categoriza-	O
tion	B
with	O
bags	O
of	O
keypoints	O
.	O
in	O
eccv	O
international	O
workshop	O
on	O
statistical	O
learning	B
in	O
computer	O
vision	O
,	O
prague	O
.	O
cui	O
,	O
j.	O
,	O
yang	O
,	O
q.	O
,	O
wen	O
,	O
f.	O
,	O
wu	O
,	O
q.	O
,	O
zhang	O
,	O
c.	O
,	O
van	O
gool	O
,	O
l.	O
,	O
and	O
tang	O
,	O
x	O
.	O
(	O
2008	O
)	O
.	O
trans-	O
ductive	O
object	O
cutout	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
curless	O
,	O
b	O
.	O
(	O
1999	O
)	O
.	O
from	O
range	O
scans	O
to	O
3d	O
models	O
.	O
computer	O
graphics	O
,	O
33	O
(	O
4	O
)	O
:38–41	O
.	O
curless	O
,	O
b.	O
and	O
levoy	O
,	O
m.	O
(	O
1995	O
)	O
.	O
better	O
optical	O
triangulation	O
through	O
spacetime	B
anal-	O
ysis	O
.	O
in	O
fifth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
95	O
)	O
,	O
pp	O
.	O
987–994	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
curless	O
,	O
b.	O
and	O
levoy	O
,	O
m.	O
(	O
1996	O
)	O
.	O
a	O
volumetric	B
method	O
for	O
building	O
complex	O
models	O
from	O
range	O
images	O
.	O
in	O
acm	O
siggraph	O
1996	O
conference	O
proceedings	O
,	O
pp	O
.	O
303–312	O
,	O
new	O
orleans	O
.	O
cutler	O
,	O
r.	O
and	O
davis	O
,	O
l.	O
s.	O
(	O
2000	O
)	O
.	O
robust	B
real-time	O
periodic	O
motion	B
detection	O
,	O
analysis	O
,	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
and	O
applications	O
.	O
22	O
(	O
8	O
)	O
:781–796	O
.	O
cutler	O
,	O
r.	O
and	O
turk	O
,	O
m.	O
(	O
1998	O
)	O
.	O
view-based	O
interpretation	O
of	O
real-time	O
optical	B
ﬂow	I
for	O
gesture	O
recognition	B
.	O
in	O
ieee	O
international	O
conference	O
on	O
automatic	B
face	O
and	O
gesture	O
recognition	B
,	O
pp	O
.	O
416–421	O
,	O
nara	O
,	O
japan	O
.	O
dai	O
,	O
s.	O
,	O
baker	O
,	O
s.	O
,	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
2009	O
)	O
.	O
an	O
mrf-based	O
deinterlacing	O
algorithm	B
with	O
exemplar-based	O
reﬁnement	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
18	O
(	O
5	O
)	O
:956–968	O
.	O
dalal	O
,	O
n.	O
and	O
triggs	O
,	O
b	O
.	O
(	O
2005	O
)	O
.	O
histograms	O
of	O
oriented	B
gradients	O
for	O
human	O
detection	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
886–893	O
,	O
san	O
diego	O
,	O
ca	O
.	O
dalal	O
,	O
n.	O
,	O
triggs	O
,	O
b.	O
,	O
and	O
schmid	O
,	O
c.	O
(	O
2006	O
)	O
.	O
human	O
detection	O
using	O
oriented	O
histograms	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
of	O
ﬂow	O
and	O
appearance	O
.	O
2006	O
)	O
,	O
pp	O
.	O
428–441	O
.	O
dana	O
,	O
k.	O
j.	O
,	O
van	O
ginneken	O
,	O
b.	O
,	O
nayar	O
,	O
s.	O
k.	O
,	O
and	O
koenderink	O
,	O
j.	O
j	O
.	O
(	O
1999	O
)	O
.	O
reﬂectance	B
and	O
texture	B
of	O
real	O
world	O
surfaces	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
18	O
(	O
1	O
)	O
:1–34	O
.	O
danielsson	O
,	O
p.	O
e.	O
(	O
1980	O
)	O
.	O
euclidean	O
distance	O
mapping	O
.	O
computer	O
graphics	O
and	O
image	B
processing	O
,	O
14	O
(	O
3	O
)	O
:227–248	O
.	O
darrell	O
,	O
t.	O
and	O
pentland	O
,	O
a	O
.	O
(	O
1991	O
)	O
.	O
robust	B
estimation	O
of	O
a	O
multi-layered	O
motion	B
represen-	O
tation	O
.	O
in	O
ieee	O
workshop	O
on	O
visual	O
motion	O
,	O
pp	O
.	O
173–178	O
,	O
princeton	O
,	O
new	O
jersey	O
.	O
darrell	O
,	O
t.	O
and	O
pentland	O
,	O
a	O
.	O
(	O
1995	O
)	O
.	O
cooperative	O
robust	O
estimation	B
using	O
layers	B
of	O
support	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
17	O
(	O
5	O
)	O
:474–487	O
.	O
references	B
817	O
darrell	O
,	O
t.	O
and	O
simoncelli	O
,	O
e.	O
(	O
1993	O
)	O
.	O
“	O
nulling	O
”	O
ﬁlters	O
and	O
the	O
separation	O
of	O
transparent	B
motion	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recog-	O
nition	O
(	O
cvpr	O
’	O
93	O
)	O
,	O
pp	O
.	O
738–739	O
,	O
new	O
york	O
.	O
darrell	O
,	O
t.	O
,	O
gordon	O
,	O
g.	O
,	O
harville	O
,	O
m.	O
,	O
and	O
woodﬁll	O
,	O
j	O
.	O
(	O
2000	O
)	O
.	O
integrated	O
person	O
tracking	O
using	O
stereo	O
,	O
color	B
,	O
and	O
pattern	O
detection	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
37	O
(	O
2	O
)	O
:175–185	O
.	O
darrell	O
,	O
t.	O
,	O
baker	O
,	O
h.	O
,	O
crow	O
,	O
f.	O
,	O
gordon	O
,	O
g.	O
,	O
and	O
woodﬁll	O
,	O
j.	O
mirror	O
:	O
face-sensitive	O
distortion	O
and	O
exaggeration	O
.	O
proceedings	O
,	O
los	O
angeles	O
.	O
(	O
1997	O
)	O
.	O
magic	O
morphin	O
in	O
acm	O
siggraph	O
1997	O
visual	O
datta	O
,	O
r.	O
,	O
joshi	O
,	O
d.	O
,	O
li	O
,	O
j.	O
,	O
and	O
wang	O
,	O
j.	O
z	O
.	O
(	O
2008	O
)	O
.	O
image	B
retrieval	O
:	O
ideas	O
,	O
inﬂuences	O
,	O
and	O
trends	O
of	O
the	O
new	O
age	O
.	O
acm	O
computing	O
surveys	B
,	O
40	O
(	O
2	O
)	O
.	O
daugman	O
,	O
j	O
.	O
(	O
2004	O
)	O
.	O
how	O
iris	O
recognition	B
works	O
.	O
ieee	O
transactions	O
on	O
circuits	O
and	O
systems	O
for	O
video	O
technology	O
,	O
14	O
(	O
1	O
)	O
:21–30	O
.	O
david	O
,	O
p.	O
,	O
dementhon	O
,	O
d.	O
,	O
duraiswami	O
,	O
r.	O
,	O
and	O
samet	O
,	O
h.	O
(	O
2004	O
)	O
.	O
softposit	O
:	O
simultane-	O
ous	O
pose	O
and	O
correspondence	B
determination	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
59	O
(	O
3	O
)	O
:259–284	O
.	O
davies	O
,	O
r.	O
,	O
twining	O
,	O
c.	O
,	O
and	O
taylor	O
,	O
c.	O
(	O
2008	O
)	O
.	O
statistical	O
models	O
of	O
shape	O
.	O
springer-	O
verlag	O
,	O
london	O
.	O
davis	O
,	O
j	O
.	O
(	O
1998	O
)	O
.	O
mosaics	O
of	O
scenes	O
with	O
moving	O
objects	O
.	O
in	O
ieee	O
computer	O
society	O
con-	O
ference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
354–360	O
,	O
santa	O
barbara	O
.	O
davis	O
,	O
j.	O
,	O
ramamoorthi	O
,	O
r.	O
,	O
and	O
rusinkiewicz	O
,	O
s.	O
(	O
2003	O
)	O
.	O
spacetime	B
stereo	I
:	O
a	O
unifying	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
framework	O
for	O
depth	O
from	O
triangulation	B
.	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2003	O
)	O
,	O
pp	O
.	O
359–366	O
,	O
madison	O
,	O
wi	O
.	O
davis	O
,	O
j.	O
,	O
nahab	O
,	O
d.	O
,	O
ramamoorthi	O
,	O
r.	O
,	O
and	O
rusinkiewicz	O
,	O
s.	O
(	O
2005	O
)	O
.	O
spacetime	B
stereo	I
:	O
a	O
unifying	O
framework	O
for	O
depth	O
from	O
triangulation	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analy-	O
sis	O
and	O
machine	O
intelligence	O
,	O
27	O
(	O
2	O
)	O
:296–302	O
.	O
davis	O
,	O
l.	O
(	O
1975	O
)	O
.	O
a	O
survey	O
of	O
edge	O
detection	O
techniques	O
.	O
computer	O
graphics	O
and	O
image	B
processing	O
,	O
4	O
(	O
3	O
)	O
:248–270	O
.	O
davis	O
,	O
t.	O
a	O
.	O
(	O
2006	O
)	O
.	O
direct	B
methods	O
for	O
sparse	O
linear	B
systems	O
.	O
siam	O
.	O
davis	O
,	O
t.	O
a	O
.	O
(	O
2008	O
)	O
.	O
multifrontal	O
multithreaded	O
rank-revealing	O
sparse	B
qr	O
factorization	B
.	O
acm	O
trans	O
.	O
on	O
mathematical	O
software	O
,	O
(	O
submitted	O
)	O
.	O
davison	O
,	O
a.	O
,	O
reid	O
,	O
i.	O
,	O
molton	O
,	O
n.	O
d.	O
,	O
and	O
stasse	O
,	O
o	O
.	O
(	O
2007	O
)	O
.	O
monoslam	O
:	O
real-time	O
sin-	O
gle	O
camera	B
slam	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
6	O
)	O
:1052–1067	O
.	O
818	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
de	O
agapito	O
,	O
l.	O
,	O
hayman	O
,	O
e.	O
,	O
and	O
reid	O
,	O
i	O
.	O
(	O
2001	O
)	O
.	O
self-calibration	B
of	O
rotating	O
and	O
zooming	O
cameras	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
45	O
(	O
2	O
)	O
:107–127	O
.	O
de	O
berg	O
,	O
m.	O
,	O
cheong	O
,	O
o.	O
,	O
van	O
kreveld	O
,	O
m.	O
,	O
and	O
overmars	O
,	O
m.	O
(	O
2006	O
)	O
.	O
computational	O
geometry	O
:	O
algorithms	O
and	O
applications	O
.	O
springer	O
,	O
new	O
york	O
,	O
ny	O
,	O
third	O
edition	O
.	O
de	O
bonet	O
,	O
j	O
.	O
(	O
1997	O
)	O
.	O
multiresolution	O
sampling	B
procedure	O
for	O
analysis	O
and	O
synthesis	O
of	O
texture	B
images	O
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
361–368	O
,	O
los	O
angeles	O
.	O
de	O
bonet	O
,	O
j.	O
s.	O
and	O
viola	O
,	O
p.	O
(	O
1999	O
)	O
.	O
poxels	O
:	O
probabilistic	B
voxelized	O
volume	O
reconstruc-	O
tion	B
.	O
in	O
seventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
99	O
)	O
,	O
pp	O
.	O
418–425	O
,	O
kerkyra	O
,	O
greece	O
.	O
de	O
castro	O
,	O
e.	O
and	O
morandi	O
,	O
c.	O
(	O
1987	O
)	O
.	O
registration	B
of	O
translated	O
and	O
rotated	O
images	O
using	O
ﬁnite	O
fourier	O
transforms	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelli-	O
gence	O
,	O
pami-9	O
(	O
5	O
)	O
:700–703	O
.	O
de	O
haan	O
,	O
g.	O
and	O
bellers	O
,	O
e.	O
b	O
.	O
(	O
1998	O
)	O
.	O
deinterlacing—an	O
overview	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
86:1839–1857	O
.	O
de	O
la	O
torre	O
,	O
f.	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2003	O
)	O
.	O
a	O
framework	O
for	O
robust	O
subspace	O
learning	B
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
54	O
(	O
1/2/3	O
)	O
:117–142	O
.	O
debevec	O
,	O
p.	O
(	O
1998	O
)	O
.	O
rendering	B
synthetic	O
objects	O
into	O
real	O
scenes	O
:	O
bridging	O
traditional	O
and	O
image-based	B
graphics	O
with	O
global	O
illumination	O
and	O
high	B
dynamic	I
range	I
photography	O
.	O
in	O
acm	O
siggraph	O
1998	O
conference	O
proceedings	O
,	O
pp	O
.	O
189–198	O
.	O
debevec	O
,	O
p.	O
(	O
2006	O
)	O
.	O
virtual	O
cinematography	O
:	O
relighting	O
through	O
computation	O
.	O
computer	O
,	O
39	O
(	O
8	O
)	O
:57–65	O
.	O
debevec	O
,	O
p.	O
,	O
hawkins	O
,	O
t.	O
,	O
tchou	O
,	O
c.	O
,	O
duiker	O
,	O
h.-p.	O
,	O
sarokin	O
,	O
w.	O
,	O
and	O
sagar	O
,	O
m.	O
(	O
2000	O
)	O
.	O
acquiring	O
the	O
reﬂectance	B
ﬁeld	O
of	O
a	O
human	O
face	O
.	O
in	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
145–156	O
.	O
debevec	O
,	O
p.	O
,	O
wenger	O
,	O
a.	O
,	O
tchou	O
,	O
c.	O
,	O
gardner	O
,	O
a.	O
,	O
waese	O
,	O
j.	O
,	O
and	O
hawkins	O
,	O
t.	O
(	O
2002	O
)	O
.	O
a	O
lighting	B
reproduction	O
approach	O
to	O
live-action	O
compositing	B
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2002	O
)	O
,	O
21	O
(	O
3	O
)	O
:547–556	O
.	O
debevec	O
,	O
p.	O
e.	O
(	O
1999	O
)	O
.	O
image-based	B
modeling	O
and	O
lighting	B
.	O
computer	O
graphics	O
,	O
33	O
(	O
4	O
)	O
:46–	O
50.	O
debevec	O
,	O
p.	O
e.	O
and	O
malik	O
,	O
j	O
.	O
(	O
1997	O
)	O
.	O
recovering	O
high	B
dynamic	I
range	I
radiance	O
maps	O
from	O
photographs	O
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
369–378	O
.	O
debevec	O
,	O
p.	O
e.	O
,	O
taylor	O
,	O
c.	O
j.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
1996	O
)	O
.	O
modeling	B
and	O
rendering	B
architec-	O
ture	O
from	O
photographs	O
:	O
a	O
hybrid	O
geometry-	O
and	O
image-based	B
approach	O
.	O
in	O
acm	O
sig-	O
graph	O
1996	O
conference	O
proceedings	O
,	O
pp	O
.	O
11–20	O
,	O
new	O
orleans	O
.	O
references	B
819	O
debevec	O
,	O
p.	O
e.	O
,	O
yu	O
,	O
y.	O
,	O
and	O
borshukov	O
,	O
g.	O
d.	O
(	O
1998	O
)	O
.	O
efﬁcient	O
view-dependent	B
image-based	O
rendering	B
with	O
projective	B
texture-mapping	O
.	O
in	O
eurographics	O
rendering	B
workshop	O
1998	O
,	O
pp	O
.	O
105–116	O
.	O
decarlo	O
,	O
d.	O
and	O
santella	O
,	O
a	O
.	O
(	O
2002	O
)	O
.	O
stylization	O
and	O
abstraction	O
of	O
photographs	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2002	O
)	O
,	O
21	O
(	O
3	O
)	O
:769–776	O
.	O
decarlo	O
,	O
d.	O
,	O
metaxas	O
,	O
d.	O
,	O
and	O
stone	O
,	O
m.	O
(	O
1998	O
)	O
.	O
an	O
anthropometric	O
face	B
model	O
using	O
variational	O
techniques	O
.	O
in	O
acm	O
siggraph	O
1998	O
conference	O
proceedings	O
,	O
pp	O
.	O
67–74	O
.	O
delingette	O
,	O
h.	O
,	O
hebert	O
,	O
m.	O
,	O
and	O
ikeuichi	O
,	O
k.	O
(	O
1992	O
)	O
.	O
shape	O
representation	O
and	O
image	B
seg-	O
mentation	O
using	O
deformable	O
surfaces	O
.	O
image	B
and	O
vision	O
computing	O
,	O
10	O
(	O
3	O
)	O
:132–144	O
.	O
dellaert	O
,	O
f.	O
and	O
collins	O
,	O
r.	O
(	O
1999	O
)	O
.	O
fast	O
image-based	O
tracking	O
by	O
selective	O
pixel	O
integration	O
.	O
in	O
iccv	O
workshop	O
on	O
frame-rate	O
vision	O
,	O
pp	O
.	O
1–22	O
.	O
delong	O
,	O
a.	O
,	O
osokin	O
,	O
a.	O
,	O
isack	O
,	O
h.	O
n.	O
,	O
and	O
boykov	O
,	O
y	O
.	O
(	O
2010	O
)	O
.	O
fast	O
approximate	O
energy	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
minimization	O
with	O
label	O
costs	O
.	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2010	O
)	O
,	O
san	O
francisco	O
,	O
ca	O
.	O
dementhon	O
,	O
d.	O
i.	O
and	O
davis	O
,	O
l.	O
s.	O
(	O
1995	O
)	O
.	O
model-based	B
object	O
pose	O
in	O
25	O
lines	B
of	O
code	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
15	O
(	O
1-2	O
)	O
:123–141	O
.	O
demmel	O
,	O
j.	O
,	O
dongarra	O
,	O
j.	O
,	O
eijkhout	O
,	O
v.	O
,	O
fuentes	O
,	O
e.	O
,	O
petitet	O
,	O
a.	O
et	O
al	O
.	O
(	O
2005	O
)	O
.	O
self-adapting	O
linear	B
algebra	O
algorithms	O
and	O
software	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
93	O
(	O
2	O
)	O
:293–312	O
.	O
dempster	O
,	O
a.	O
,	O
laird	O
,	O
n.	O
m.	O
,	O
and	O
rubin	O
,	O
d.	O
b	O
.	O
(	O
1977	O
)	O
.	O
maximum	O
likelihood	O
from	O
incom-	O
plete	O
data	O
via	O
the	O
em	O
algorithm	B
.	O
journal	O
of	O
the	O
royal	O
statistical	O
society	O
b	O
,	O
39	O
(	O
1	O
)	O
:1–38	O
.	O
deng	O
,	O
j.	O
,	O
dong	O
,	O
w.	O
,	O
socher	O
,	O
r.	O
,	O
li	O
,	O
l.-j.	O
,	O
li	O
,	O
k.	O
,	O
and	O
fei-fei	O
,	O
l.	O
(	O
2009	O
)	O
.	O
imagenet	O
:	O
a	O
large-	O
scale	O
hierarchical	O
image	B
database	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
deriche	O
,	O
r.	O
(	O
1987	O
)	O
.	O
using	O
canny	O
’	O
s	O
criteria	O
to	O
derive	O
a	O
recursively	O
implemented	O
optimal	O
edge	O
detector	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
1	O
(	O
2	O
)	O
:167–187	O
.	O
deriche	O
,	O
r.	O
(	O
1990	O
)	O
.	O
fast	O
algorithms	O
for	O
low-level	O
vision	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12	O
(	O
1	O
)	O
:78–87	O
.	O
deutscher	O
,	O
j.	O
and	O
reid	O
,	O
i	O
.	O
(	O
2005	O
)	O
.	O
articulated	O
body	B
motion	O
capture	O
by	O
stochastic	O
search	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
61	O
(	O
2	O
)	O
:185–205	O
.	O
deutscher	O
,	O
j.	O
,	O
blake	O
,	O
a.	O
,	O
and	O
reid	O
,	O
i	O
.	O
(	O
2000	O
)	O
.	O
articulated	O
body	B
motion	O
capture	O
by	O
annealed	O
particle	B
ﬁltering	I
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pat-	O
tern	O
recognition	B
(	O
cvpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
126–133	O
,	O
hilton	O
head	B
island	O
.	O
dev	O
,	O
p.	O
(	O
1974	O
)	O
.	O
segmentation	B
processes	O
in	O
visual	O
perception	O
:	O
a	O
cooperative	O
neural	O
model	O
.	O
coins	O
technical	O
report	O
74c-5	O
,	O
university	O
of	O
massachusetts	O
at	O
amherst	O
.	O
820	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
dhond	O
,	O
u.	O
r.	O
and	O
aggarwal	O
,	O
j.	O
k.	O
(	O
1989	O
)	O
.	O
structure	O
from	O
stereo—a	O
review	O
.	O
ieee	O
trans-	O
actions	O
on	O
systems	O
,	O
man	O
,	O
and	O
cybernetics	O
,	O
19	O
(	O
6	O
)	O
:1489–1510	O
.	O
dick	O
,	O
a.	O
,	O
torr	O
,	O
p.	O
h.	O
s.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2004	O
)	O
.	O
modelling	O
and	O
interpretation	O
of	O
architecture	B
from	O
several	O
images	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
60	O
(	O
2	O
)	O
:111–134	O
.	O
dickinson	O
,	O
s.	O
,	O
leonardis	O
,	O
a.	O
,	O
schiele	O
,	O
b.	O
,	O
and	O
tarr	O
,	O
m.	O
j	O
.	O
(	O
eds	O
)	O
.	O
(	O
2007	O
)	O
.	O
object	O
catego-	O
rization	O
:	O
computer	O
and	O
human	O
vision	O
perspectives	O
,	O
cambridge	O
university	O
press	O
,	O
new	O
york	O
.	O
dickmanns	O
,	O
e.	O
d.	O
and	O
graefe	O
,	O
v.	O
(	O
1988	O
)	O
.	O
dynamic	B
monocular	O
machine	O
vision	O
.	O
machine	O
vision	O
and	O
applications	O
,	O
1:223–240	O
.	O
diebel	O
,	O
j	O
.	O
(	O
2006	O
)	O
.	O
representing	O
attitude	O
:	O
euler	O
angles	O
,	O
quaternions	B
,	O
and	O
rotation	O
vectors	O
.	O
technical	O
report	O
,	O
stanford	O
university	O
.	O
http	O
:	O
//ai.stanford.edu/∼diebel/attitude.html	O
.	O
diebel	O
,	O
j.	O
r.	O
,	O
thrun	O
,	O
s.	O
,	O
and	O
br¨unig	O
,	O
m.	O
(	O
2006	O
)	O
.	O
a	O
bayesian	O
method	O
for	O
probable	O
surface	B
reconstruction	I
and	O
decimation	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
1	O
)	O
.	O
dimitrijevic	O
,	O
m.	O
,	O
lepetit	O
,	O
v.	O
,	O
and	O
fua	O
,	O
p.	O
(	O
2006	O
)	O
.	O
human	B
body	I
pose	O
detection	B
us-	O
ing	O
bayesian	O
spatio-temporal	O
templates	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-3	O
)	O
:127–139	O
.	O
dinh	O
,	O
h.	O
q.	O
,	O
turk	O
,	O
g.	O
,	O
and	O
slabaugh	O
,	O
g.	O
(	O
2002	O
)	O
.	O
reconstructing	O
surfaces	O
by	O
volumetric	O
regularization	B
using	O
radial	B
basis	O
functions	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
10	O
)	O
:1358–1371	O
.	O
divvala	O
,	O
s.	O
,	O
hoiem	O
,	O
d.	O
,	O
hays	O
,	O
j.	O
,	O
efros	O
,	O
a.	O
a.	O
,	O
and	O
hebert	O
,	O
m.	O
(	O
2009	O
)	O
.	O
an	O
empirical	O
study	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
of	O
context	B
in	O
object	O
detection	B
.	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
,	O
fl	O
.	O
dodgson	O
,	O
n.	O
a	O
.	O
(	O
1992	O
)	O
.	O
image	B
resampling	O
.	O
technical	O
report	O
tr261	O
,	O
wolfson	O
college	O
and	O
computer	O
laboratory	O
,	O
university	O
of	O
cambridge	O
.	O
doll`ar	O
,	O
p.	O
,	O
belongie	O
,	O
s.	O
,	O
and	O
perona	O
,	O
p.	O
(	O
2010	O
)	O
.	O
the	O
fastest	O
pedestrian	B
detector	O
in	O
the	O
west	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2010	O
)	O
,	O
aberystwyth	O
,	O
wales	O
,	O
uk	O
.	O
doll`ar	O
,	O
p.	O
,	O
wojek	O
,	O
c.	O
,	O
schiele	O
,	O
b.	O
,	O
and	O
perona	O
,	O
p.	O
(	O
2009	O
)	O
.	O
pedestrian	B
detection	O
:	O
a	O
bench-	O
mark	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recog-	O
nition	O
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
doretto	O
,	O
g.	O
and	O
soatto	O
,	O
s.	O
(	O
2006	O
)	O
.	O
dynamic	B
shape	O
and	O
appearance	O
models	O
.	O
ieee	O
transac-	O
tions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
12	O
)	O
:2006–2019	O
.	O
doretto	O
,	O
g.	O
,	O
chiuso	O
,	O
a.	O
,	O
wu	O
,	O
y.	O
n.	O
,	O
and	O
soatto	O
,	O
s.	O
(	O
2003	O
)	O
.	O
dynamic	B
textures	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
51	O
(	O
2	O
)	O
:91–109	O
.	O
references	B
821	O
dork´o	O
,	O
g.	O
and	O
schmid	O
,	O
c.	O
(	O
2003	O
)	O
.	O
selection	O
of	O
scale-invariant	O
parts	O
for	O
object	O
class	O
recog-	O
nition	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
634–	O
640	O
,	O
nice	O
,	O
france	O
.	O
dorsey	O
,	O
j.	O
,	O
rushmeier	O
,	O
h.	O
,	O
and	O
sillion	O
,	O
f.	O
(	O
2007	O
)	O
.	O
digital	O
modeling	O
of	O
material	O
appear-	O
ance	O
.	O
morgan	O
kaufmann	O
,	O
san	O
francisco	O
.	O
douglas	O
,	O
d.	O
h.	O
and	O
peucker	O
,	O
t.	O
k.	O
(	O
1973	O
)	O
.	O
algorithms	O
for	O
the	O
reduction	O
of	O
the	O
number	O
of	O
points	B
required	O
to	O
represent	O
a	O
digitized	O
line	O
or	O
its	O
caricature	O
.	O
the	O
canadian	O
cartogra-	O
pher	O
,	O
10	O
(	O
2	O
)	O
:112–122	O
.	O
drori	O
,	O
i.	O
,	O
cohen-or	O
,	O
d.	O
,	O
and	O
yeshurun	O
,	O
h.	O
(	O
2003	O
)	O
.	O
fragment-based	O
image	B
completion	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2003	O
)	O
,	O
22	O
(	O
3	O
)	O
:303–312	O
.	O
duda	O
,	O
r.	O
o.	O
and	O
hart	O
,	O
p.	O
e.	O
(	O
1972	O
)	O
.	O
use	O
of	O
the	O
hough	O
transform	B
to	O
detect	O
lines	B
and	O
curves	O
in	O
pictures	O
.	O
communications	O
of	O
the	O
acm	O
,	O
15	O
(	O
1	O
)	O
:11–15	O
.	O
duda	O
,	O
r.	O
o.	O
,	O
hart	O
,	O
p.	O
e.	O
,	O
and	O
stork	O
,	O
d.	O
g.	O
(	O
2001	O
)	O
.	O
pattern	O
classiﬁcation	O
.	O
john	O
wiley	O
&	O
sons	O
,	O
new	O
york	O
,	O
2nd	O
edition	O
.	O
dupuis	O
,	O
p.	O
and	O
oliensis	O
,	O
j	O
.	O
(	O
1994	O
)	O
.	O
an	O
optimal	O
control	O
formulation	O
and	O
related	O
numer-	O
ical	O
methods	O
for	O
a	O
problem	O
in	O
shape	O
reconstruction	O
.	O
annals	O
of	O
applied	O
probability	O
,	O
4	O
(	O
2	O
)	O
:287–346	O
.	O
durand	O
,	O
f.	O
and	O
dorsey	O
,	O
j	O
.	O
(	O
2002	O
)	O
.	O
fast	O
bilateral	O
ﬁltering	O
for	O
the	O
display	O
of	O
high-dynamic-	O
range	O
images	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2002	O
)	O
,	O
21	O
(	O
3	O
)	O
:257–	O
266.	O
durand	O
,	O
f.	O
and	O
szeliski	O
,	O
r.	O
(	O
2007	O
)	O
.	O
computational	O
photography	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
27	O
(	O
2	O
)	O
:21–22	O
.	O
guest	O
editors	O
’	O
introduction	O
to	O
special	O
issue	O
.	O
durbin	O
,	O
r.	O
and	O
willshaw	O
,	O
d.	O
(	O
1987	O
)	O
.	O
an	O
analogue	O
approach	O
to	O
the	O
traveling	O
salesman	O
problem	O
using	O
an	O
elastic	O
net	O
method	O
.	O
nature	O
,	O
326:689–691	O
.	O
durbin	O
,	O
r.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
yuille	O
,	O
a	O
.	O
(	O
1989	O
)	O
.	O
an	O
analysis	O
of	O
the	O
elastic	O
net	O
approach	O
to	O
the	O
travelling	O
salesman	O
problem	O
.	O
neural	O
computation	O
,	O
1	O
(	O
3	O
)	O
:348–358	O
.	O
eck	O
,	O
m.	O
,	O
derose	O
,	O
t.	O
,	O
duchamp	O
,	O
t.	O
,	O
hoppe	O
,	O
h.	O
,	O
lounsbery	O
,	O
m.	O
,	O
and	O
stuetzle	O
,	O
w.	O
(	O
1995	O
)	O
.	O
in	O
acm	O
siggraph	O
1995	O
conference	O
multiresolution	O
analysis	O
of	O
arbitrary	O
meshes	O
.	O
proceedings	O
,	O
pp	O
.	O
173–182	O
,	O
los	O
angeles	O
.	O
eden	O
,	O
a.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
seamless	O
image	B
stitching	I
of	O
scenes	O
with	O
large	O
motions	O
and	O
exposure	O
differences	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
2498–2505	O
,	O
new	O
york	O
,	O
ny	O
.	O
efros	O
,	O
a.	O
a.	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2001	O
)	O
.	O
image	B
quilting	I
for	O
texture	B
synthesis	O
and	O
transfer	B
.	O
in	O
acm	O
siggraph	O
2001	O
conference	O
proceedings	O
,	O
pp	O
.	O
341–346	O
.	O
822	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
efros	O
,	O
a.	O
a.	O
and	O
leung	O
,	O
t.	O
k.	O
(	O
1999	O
)	O
.	O
texture	B
synthesis	O
by	O
non-parametric	O
sampling	B
.	O
in	O
seventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
99	O
)	O
,	O
pp	O
.	O
1033–1038	O
,	O
kerkyra	O
,	O
greece	O
.	O
efros	O
,	O
a.	O
a.	O
,	O
berg	O
,	O
a.	O
c.	O
,	O
mori	O
,	O
g.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2003	O
)	O
.	O
recognizing	O
action	O
at	O
a	O
distance	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
726–733	O
,	O
nice	O
,	O
france	O
.	O
eichner	O
,	O
m.	O
and	O
ferrari	O
,	O
v.	O
(	O
2009	O
)	O
.	O
better	O
appearance	O
models	O
for	O
pictorial	O
structures	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2009	O
)	O
.	O
eisemann	O
,	O
e.	O
and	O
durand	O
,	O
f.	O
(	O
2004	O
)	O
.	O
flash	O
photography	O
enhancement	O
via	O
intrinsic	B
relight-	O
ing	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
23	O
(	O
3	O
)	O
:673–678	O
.	O
eisert	O
,	O
p.	O
,	O
steinbach	O
,	O
e.	O
,	O
and	O
girod	O
,	O
b	O
.	O
(	O
2000	O
)	O
.	O
automatic	B
reconstruction	O
of	O
stationary	O
3-d	O
objects	O
from	O
multiple	B
uncalibrated	O
camera	B
views	O
.	O
ieee	O
transactions	O
on	O
circuits	O
and	O
systems	O
for	O
video	O
technology	O
,	O
10	O
(	O
2	O
)	O
:261–277	O
.	O
eisert	O
,	O
p.	O
,	O
wiegand	O
,	O
t.	O
,	O
and	O
girod	O
,	O
b	O
.	O
(	O
2000	O
)	O
.	O
model-aided	O
coding	O
:	O
a	O
new	O
approach	O
to	O
in-	O
corporate	O
facial	B
animation	I
into	O
motion-compensated	O
video	B
coding	O
.	O
ieee	O
transactions	O
on	O
circuits	O
and	O
systems	O
for	O
video	O
technology	O
,	O
10	O
(	O
3	O
)	O
:344–358	O
.	O
ekman	O
,	O
p.	O
and	O
friesen	O
,	O
w.	O
v.	O
(	O
1978	O
)	O
.	O
facial	O
action	O
coding	O
system	O
:	O
a	O
technique	O
for	O
the	O
measurement	O
of	O
facial	O
movement	O
.	O
consulting	O
psychologists	O
press	O
,	O
palo	O
alto	O
,	O
ca	O
.	O
el-melegy	O
,	O
m.	O
and	O
farag	O
,	O
a	O
.	O
(	O
2003	O
)	O
.	O
nonmetric	O
lens	O
distortion	O
calibration	B
:	O
closed-form	O
solutions	O
,	O
robust	B
estimation	O
and	O
model	O
selection	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
554–559	O
,	O
nice	O
,	O
france	O
.	O
elder	O
,	O
j.	O
h.	O
(	O
1999	O
)	O
.	O
are	O
edges	O
incomplete	B
?	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
34	O
(	O
2/3	O
)	O
:97–122	O
.	O
elder	O
,	O
j.	O
h.	O
and	O
goldberg	O
,	O
r.	O
m.	O
(	O
2001	O
)	O
.	O
image	B
editing	O
in	O
the	O
contour	O
domain	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
23	O
(	O
3	O
)	O
:291–296	O
.	O
elder	O
,	O
j.	O
h.	O
and	O
zucker	O
,	O
s.	O
w.	O
(	O
1998	O
)	O
.	O
local	B
scale	O
control	O
for	O
edge	O
detection	B
and	O
blur	O
esti-	O
mation	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
20	O
(	O
7	O
)	O
:699–	O
716.	O
engels	O
,	O
c.	O
,	O
stew´enius	O
,	O
h.	O
,	O
and	O
nist´er	O
,	O
d.	O
(	O
2006	O
)	O
.	O
bundle	B
adjustment	I
rules	O
.	O
in	O
photogram-	O
metric	O
computer	O
vision	O
(	O
pcv	O
’	O
06	O
)	O
,	O
bonn	O
,	O
germany	O
.	O
engl	O
,	O
h.	O
w.	O
,	O
hanke	O
,	O
m.	O
,	O
and	O
neubauer	O
,	O
a	O
.	O
(	O
1996	O
)	O
.	O
regularization	B
of	O
inverse	B
problems	O
.	O
kluwer	O
academic	O
publishers	O
,	O
dordrecht	O
.	O
enqvist	O
,	O
o.	O
,	O
josephson	O
,	O
k.	O
,	O
and	O
kahl	O
,	O
f.	O
(	O
2009	O
)	O
.	O
optimal	O
correspondences	O
from	O
pairwise	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
constraints	O
.	O
kyoto	O
,	O
japan	O
.	O
references	B
823	O
estrada	O
,	O
f.	O
j.	O
and	O
jepson	O
,	O
a.	O
d.	O
(	O
2009	O
)	O
.	O
benchmarking	O
image	B
segmentation	O
algorithms	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
85	O
(	O
2	O
)	O
:167–181	O
.	O
estrada	O
,	O
f.	O
j.	O
,	O
jepson	O
,	O
a.	O
d.	O
,	O
and	O
chennubhotla	O
,	O
c.	O
(	O
2004	O
)	O
.	O
spectral	O
embedding	O
and	O
min-cut	O
for	O
image	O
segmentation	B
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2004	O
)	O
,	O
pp	O
.	O
317–	O
326	O
,	O
london	O
.	O
evangelidis	O
,	O
g.	O
d.	O
and	O
psarakis	O
,	O
e.	O
z	O
.	O
(	O
2008	O
)	O
.	O
parametric	B
image	O
alignment	B
using	O
enhanced	O
correlation	O
coefﬁcient	O
maximization	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
ma-	O
chine	O
intelligence	O
,	O
30	O
(	O
10	O
)	O
:1858–1865	O
.	O
everingham	O
,	O
m.	O
,	O
van	O
gool	O
,	O
l.	O
,	O
williams	O
,	O
c.	O
k.	O
i.	O
,	O
winn	O
,	O
j.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
the	O
pascal	O
visual	O
object	O
classes	O
challenge	O
2008	O
(	O
voc2008	O
)	O
results	O
.	O
http	O
:	O
//www	O
.	O
pascal-network.org/challenges/voc/voc2008/workshop/index.html	O
.	O
everingham	O
,	O
m.	O
,	O
van	O
gool	O
,	O
l.	O
,	O
williams	O
,	O
c.	O
k.	O
i.	O
,	O
winn	O
,	O
j.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2010	O
)	O
.	O
the	O
international	O
journal	O
of	O
computer	O
pascal	O
visual	O
object	O
classes	O
(	O
voc	O
)	O
challenge	O
.	O
vision	O
,	O
88	O
(	O
2	O
)	O
:147–168	O
.	O
ezzat	O
,	O
t.	O
,	O
geiger	O
,	O
g.	O
,	O
and	O
poggio	O
,	O
t.	O
(	O
2002	O
)	O
.	O
trainable	O
videorealistic	O
speech	O
animation	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2002	O
)	O
,	O
21	O
(	O
3	O
)	O
:388–398	O
.	O
fabbri	O
,	O
r.	O
,	O
costa	O
,	O
l.	O
d.	O
f.	O
,	O
torelli	O
,	O
j.	O
c.	O
,	O
and	O
bruno	O
,	O
o.	O
m.	O
(	O
2008	O
)	O
.	O
2d	O
euclidean	O
distance	O
transform	O
algorithms	O
:	O
a	O
comparative	O
survey	O
.	O
acm	O
computing	O
surveys	B
,	O
40	O
(	O
1	O
)	O
.	O
fairchild	O
,	O
m.	O
d.	O
(	O
2005	O
)	O
.	O
color	B
appearance	O
models	O
.	O
wiley	O
,	O
2nd	O
edition	O
.	O
fan	O
,	O
r.-e.	O
,	O
chen	O
,	O
p.-h.	O
,	O
and	O
lin	O
,	O
c.-j	O
.	O
(	O
2005	O
)	O
.	O
working	O
set	O
selection	O
using	O
second	O
order	B
in-	O
formation	O
for	O
training	O
support	B
vector	I
machines	I
.	O
journal	O
of	O
machine	O
learning	O
research	O
,	O
6:1889–1918	O
.	O
fan	O
,	O
r.-e.	O
,	O
chang	O
,	O
k.-w.	O
,	O
hsieh	O
,	O
c.-j.	O
,	O
wang	O
,	O
x.-r.	O
,	O
and	O
lin	O
,	O
c.-j	O
.	O
(	O
2008	O
)	O
.	O
liblinear	O
:	O
a	O
library	O
for	O
large	O
linear	B
classiﬁcation	O
.	O
journal	O
of	O
machine	O
learning	O
research	O
,	O
9:1871–	O
1874.	O
farbman	O
,	O
z.	O
,	O
fattal	O
,	O
r.	O
,	O
lischinski	O
,	O
d.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2008	O
)	O
.	O
edge-preserving	B
decom-	O
positions	O
for	O
multi-scale	O
tone	O
and	O
detail	O
manipulation	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2008	O
)	O
,	O
27	O
(	O
3	O
)	O
.	O
farenzena	O
,	O
m.	O
,	O
fusiello	O
,	O
a.	O
,	O
and	O
gherardi	O
,	O
r.	O
(	O
2009	O
)	O
.	O
structure-and-motion	O
pipeline	B
on	O
a	O
hierarchical	B
cluster	O
tree	O
.	O
in	O
ieee	O
international	O
workshop	O
on	O
3d	O
digital	O
imaging	O
and	O
modeling	B
(	O
3dim	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
farin	O
,	O
g.	O
(	O
1992	O
)	O
.	O
from	O
conics	O
to	O
nurbs	O
:	O
a	O
tutorial	O
and	O
survey	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
12	O
(	O
5	O
)	O
:78–86	O
.	O
farin	O
,	O
g.	O
e.	O
(	O
1996	O
)	O
.	O
curves	O
and	O
surfaces	O
for	O
computer	O
aided	O
geometric	B
design	O
:	O
a	O
prac-	O
tical	O
guide	O
.	O
academic	O
press	O
,	O
boston	O
,	O
massachusetts	O
,	O
4th	O
edition	O
.	O
824	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
fattal	O
,	O
r.	O
(	O
2007	O
)	O
.	O
image	B
upsampling	O
via	O
imposed	O
edge	O
statistics	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
fattal	O
,	O
r.	O
(	O
2009	O
)	O
.	O
edge-avoiding	O
wavelets	O
and	O
their	O
applications	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
28	O
(	O
3	O
)	O
.	O
fattal	O
,	O
r.	O
,	O
lischinski	O
,	O
d.	O
,	O
and	O
werman	O
,	O
m.	O
(	O
2002	O
)	O
.	O
gradient	B
domain	I
high	O
dynamic	B
range	O
compression	B
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2002	O
)	O
,	O
21	O
(	O
3	O
)	O
:249–	O
256.	O
faugeras	O
,	O
o	O
.	O
(	O
1993	O
)	O
.	O
three-dimensional	O
computer	O
vision	O
:	O
a	O
geometric	B
viewpoint	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
faugeras	O
,	O
o.	O
and	O
keriven	O
,	O
r.	O
(	O
1998	O
)	O
.	O
variational	O
principles	O
,	O
surface	B
evolution	O
,	O
pdes	O
,	O
level	O
set	O
methods	O
,	O
and	O
the	O
stereo	B
problem	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
7	O
(	O
3	O
)	O
:336–344	O
.	O
faugeras	O
,	O
o.	O
and	O
luong	O
,	O
q.-t.	O
(	O
2001	O
)	O
.	O
the	O
geometry	O
of	O
multiple	B
images	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
ma	O
.	O
faugeras	O
,	O
o.	O
d.	O
(	O
1992	O
)	O
.	O
what	O
can	O
be	O
seen	O
in	O
three	O
dimensions	O
with	O
an	O
uncalibrated	O
stereo	B
rig	O
?	O
in	O
second	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
92	O
)	O
,	O
pp	O
.	O
563–578	O
,	O
santa	O
margherita	O
liguere	O
,	O
italy	O
.	O
faugeras	O
,	O
o.	O
d.	O
and	O
hebert	O
,	O
m.	O
(	O
1987	O
)	O
.	O
the	O
representation	O
,	O
recognition	B
and	O
positioning	O
of	O
3-d	O
shapes	O
from	O
range	O
data	O
.	O
in	O
kanade	O
,	O
t	O
.	O
(	O
ed	O
.	O
)	O
,	O
three-dimensional	O
machine	O
vision	O
,	O
pp	O
.	O
301–353	O
,	O
kluwer	O
academic	O
publishers	O
,	O
boston	O
.	O
faugeras	O
,	O
o.	O
d.	O
,	O
luong	O
,	O
q.-t.	O
,	O
and	O
maybank	O
,	O
s.	O
j	O
.	O
(	O
1992	O
)	O
.	O
camera	B
self-calibration	O
:	O
theory	O
in	O
second	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
92	O
)	O
,	O
and	O
experiments	O
.	O
pp	O
.	O
321–334	O
,	O
santa	O
margherita	O
liguere	O
,	O
italy	O
.	O
favaro	O
,	O
p.	O
and	O
soatto	O
,	O
s.	O
(	O
2006	O
)	O
.	O
3-d	O
shape	O
estimation	O
and	O
image	B
restoration	I
:	O
exploiting	O
defocus	O
and	O
motion-blur	O
.	O
springer	O
.	O
fawcett	O
,	O
t.	O
(	O
2006	O
)	O
.	O
an	O
introduction	O
to	O
roc	O
analysis	O
.	O
pattern	O
recognition	B
letters	O
,	O
27	O
(	O
8	O
)	O
:861–874	O
.	O
fei-fei	O
,	O
l.	O
and	O
perona	O
,	O
p.	O
(	O
2005	O
)	O
.	O
a	O
bayesian	O
hierarchical	B
model	O
for	O
learning	O
natural	B
scene	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
categories	O
.	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
524–531	O
,	O
san	O
diego	O
,	O
ca	O
.	O
fei-fei	O
,	O
l.	O
,	O
fergus	O
,	O
r.	O
,	O
and	O
perona	O
,	O
p.	O
(	O
2006	O
)	O
.	O
one-shot	O
learning	B
of	O
object	O
categories	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
4	O
)	O
:594–611	O
.	O
fei-fei	O
,	O
l.	O
,	O
fergus	O
,	O
r.	O
,	O
and	O
torralba	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
iccv	O
2009	O
short	O
course	O
on	O
recognizing	O
and	O
learning	B
object	O
categories	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
http	O
:	O
//people.csail.mit.edu/torralba/shortcourserloc/	O
.	O
references	B
825	O
feilner	O
,	O
m.	O
,	O
van	O
de	O
ville	O
,	O
d.	O
,	O
and	O
unser	O
,	O
m.	O
(	O
2005	O
)	O
.	O
an	O
orthogonal	O
family	O
of	O
quincunx	O
wavelets	O
with	O
continuously	O
adjustable	O
order	B
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
14	O
(	O
4	O
)	O
:499–520	O
.	O
feldmar	O
,	O
j.	O
and	O
ayache	O
,	O
n.	O
(	O
1996	O
)	O
.	O
rigid	O
,	O
afﬁne	B
,	O
and	O
locally	O
afﬁne	O
registration	B
of	O
free-form	O
surfaces	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
18	O
(	O
2	O
)	O
:99–119	O
.	O
fellbaum	O
,	O
c	O
.	O
(	O
ed.	O
)	O
.	O
(	O
1998	O
)	O
.	O
wordnet	O
:	O
an	O
electronic	O
lexical	O
database	O
,	O
bradford	O
books	O
.	O
felzenszwalb	O
,	O
p.	O
,	O
mcallester	O
,	O
d.	O
,	O
and	O
ramanan	O
,	O
d.	O
(	O
2008	O
)	O
.	O
a	O
discriminatively	O
trained	O
,	O
multiscale	O
,	O
deformable	O
part	O
model	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
felzenszwalb	O
,	O
p.	O
f.	O
and	O
huttenlocher	O
,	O
d.	O
p.	O
(	O
2004a	O
)	O
.	O
distance	O
transforms	O
of	O
sampled	O
functions	O
.	O
technical	O
report	O
tr2004-1963	O
,	O
cornell	O
university	O
computing	O
and	O
infor-	O
mation	O
science	O
.	O
felzenszwalb	O
,	O
p.	O
f.	O
and	O
huttenlocher	O
,	O
d.	O
p.	O
(	O
2004b	O
)	O
.	O
efﬁcient	O
graph-based	B
image	O
segmen-	O
tation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
59	O
(	O
2	O
)	O
:167–181	O
.	O
felzenszwalb	O
,	O
p.	O
f.	O
and	O
huttenlocher	O
,	O
d.	O
p.	O
(	O
2005	O
)	O
.	O
pictorial	O
structures	O
for	O
object	O
recogni-	O
tion	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
61	O
(	O
1	O
)	O
:55–79	O
.	O
felzenszwalb	O
,	O
p.	O
f.	O
and	O
huttenlocher	O
,	O
d.	O
p.	O
(	O
2006	O
)	O
.	O
efﬁcient	O
belief	B
propagation	I
for	O
early	O
vision	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
70	O
(	O
1	O
)	O
:41–54	O
.	O
felzenszwalb	O
,	O
p.	O
f.	O
,	O
girshick	O
,	O
r.	O
b.	O
,	O
mcallester	O
,	O
d.	O
,	O
and	O
ramanan	O
,	O
d.	O
(	O
2010	O
)	O
.	O
object	O
de-	O
tection	O
with	O
discriminatively	O
trained	O
part-based	B
models	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
32	O
(	O
9	O
)	O
:1627–1645	O
.	O
ferencz	O
,	O
a.	O
,	O
learned-miller	O
,	O
e.	O
g.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2008	O
)	O
.	O
learning	B
to	O
locate	O
informative	O
features	O
for	O
visual	O
identiﬁcation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
77	O
(	O
1-3	O
)	O
:3–	O
24.	O
fergus	O
,	O
r.	O
(	O
2007a	O
)	O
.	O
combined	O
segmentation	B
and	O
recognition	B
.	O
in	O
cvpr	O
2007	O
short	O
course	O
on	O
recognizing	O
and	O
learning	B
object	O
categories	O
.	O
http	O
:	O
//people.csail.mit.edu/torralba/	O
shortcourserloc/	O
.	O
fergus	O
,	O
r.	O
(	O
2007b	O
)	O
.	O
part-based	B
models	O
.	O
in	O
cvpr	O
2007	O
short	O
course	O
on	O
recognizing	O
and	O
learning	B
object	O
categories	O
.	O
http	O
:	O
//people.csail.mit.edu/torralba/shortcourserloc/	O
.	O
fergus	O
,	O
r.	O
(	O
2009	O
)	O
.	O
classical	O
methods	O
for	O
object	O
recognition	B
.	O
in	O
iccv	O
2009	O
short	O
course	O
on	O
recognizing	O
and	O
learning	B
object	O
categories	O
,	O
kyoto	O
,	O
japan	O
.	O
http	O
:	O
//people.csail.mit	O
.	O
edu/torralba/shortcourserloc/	O
.	O
fergus	O
,	O
r.	O
,	O
perona	O
,	O
p.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2004	O
)	O
.	O
a	O
visual	O
category	O
ﬁlter	O
for	O
google	O
images	O
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
242–	O
256	O
,	O
prague	O
.	O
826	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
fergus	O
,	O
r.	O
,	O
perona	O
,	O
p.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2005	O
)	O
.	O
a	O
sparse	B
object	O
category	O
model	O
for	O
efﬁcient	O
learning	B
and	O
exhaustive	O
recognition	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
380–387	O
,	O
san	O
diego	O
,	O
ca	O
.	O
(	O
2007	O
)	O
.	O
weakly	O
supervised	O
scale-invariant	O
learning	B
of	O
models	O
for	O
visual	O
recognition	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
71	O
(	O
3	O
)	O
:273–303	O
.	O
fergus	O
,	O
r.	O
,	O
perona	O
,	O
p.	O
,	O
and	O
zisserman	O
,	O
a.	O
fergus	O
,	O
r.	O
,	O
fei-fei	O
,	O
l.	O
,	O
perona	O
,	O
p.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2005	O
)	O
.	O
learning	B
object	O
categories	O
from	O
google	O
’	O
s	O
image	B
search	I
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
1816–1823	O
,	O
beijing	O
,	O
china	O
.	O
fergus	O
,	O
r.	O
,	O
singh	O
,	O
b.	O
,	O
hertzmann	O
,	O
a.	O
,	O
roweis	O
,	O
s.	O
t.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2006	O
)	O
.	O
removing	O
camera	B
shake	O
from	O
a	O
single	O
photograph	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:787–	O
794.	O
ferrari	O
,	O
v.	O
,	O
marin-jimenez	O
,	O
m.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
pose	O
search	O
:	O
retrieving	O
peo-	O
ple	O
using	O
their	O
pose	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
ferrari	O
,	O
v.	O
,	O
marin-jimenez	O
,	O
m.	O
j.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
progressive	O
search	O
space	O
reduction	O
for	O
human	O
pose	O
estimation	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
com-	O
puter	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
ferrari	O
,	O
v.	O
,	O
tuytelaars	O
,	O
t.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2006a	O
)	O
.	O
object	O
detection	B
by	O
contour	O
segment	O
networks	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
14–28	O
.	O
ferrari	O
,	O
v.	O
,	O
tuytelaars	O
,	O
t.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2006b	O
)	O
.	O
simultaneous	O
object	O
recognition	B
and	O
segmentation	B
from	O
single	O
or	O
multiple	B
model	O
views	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
67	O
(	O
2	O
)	O
:159–188	O
.	O
field	O
,	O
d.	O
j	O
.	O
(	O
1987	O
)	O
.	O
relations	O
between	O
the	O
statistics	O
of	O
natural	B
images	O
and	O
the	O
response	O
properties	B
of	O
cortical	O
cells	O
.	O
journal	O
of	O
the	O
optical	O
society	O
of	O
america	O
a	O
,	O
4	O
(	O
12	O
)	O
:2379–	O
2394.	O
finkelstein	O
,	O
a.	O
and	O
salesin	O
,	O
d.	O
h.	O
(	O
1994	O
)	O
.	O
multiresolution	O
curves	O
.	O
in	O
acm	O
siggraph	O
1994	O
conference	O
proceedings	O
,	O
pp	O
.	O
261–268	O
.	O
fischler	O
,	O
m.	O
a.	O
and	O
bolles	O
,	O
r.	O
c.	O
(	O
1981	O
)	O
.	O
random	O
sample	O
consensus	O
:	O
a	O
paradigm	O
for	O
model	O
ﬁtting	O
with	O
applications	O
to	O
image	B
analysis	O
and	O
automated	B
cartography	O
.	O
commu-	O
nications	O
of	O
the	O
acm	O
,	O
24	O
(	O
6	O
)	O
:381–395	O
.	O
fischler	O
,	O
m.	O
a.	O
and	O
elschlager	O
,	O
r.	O
a	O
.	O
(	O
1973	O
)	O
.	O
the	O
representation	O
and	O
matching	B
of	O
pictorial	O
structures	O
.	O
ieee	O
transactions	O
on	O
computers	O
,	O
22	O
(	O
1	O
)	O
:67–92	O
.	O
fischler	O
,	O
m.	O
a.	O
and	O
firschein	O
,	O
o	O
.	O
(	O
1987	O
)	O
.	O
readings	O
in	O
computer	O
vision	O
.	O
morgan	O
kaufmann	O
publishers	O
,	O
inc.	O
,	O
los	O
altos	O
.	O
references	B
827	O
fischler	O
,	O
m.	O
a.	O
,	O
firschein	O
,	O
o.	O
,	O
barnard	O
,	O
s.	O
t.	O
,	O
fua	O
,	O
p.	O
v.	O
,	O
and	O
leclerc	O
,	O
y	O
.	O
(	O
1989	O
)	O
.	O
the	O
vision	O
problem	O
:	O
exploiting	O
parallel	O
computation	O
.	O
technical	O
note	O
458	O
,	O
sri	O
international	O
,	O
menlo	O
park	O
.	O
fitzgibbon	O
,	O
a.	O
w.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1998	O
)	O
.	O
automatic	B
camera	O
recovery	B
for	O
closed	O
and	O
open	O
image	B
sequences	O
.	O
in	O
fifth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
311–326	O
,	O
freiburg	O
,	O
germany	O
.	O
fitzgibbon	O
,	O
a.	O
w.	O
,	O
cross	O
,	O
g.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1998	O
)	O
.	O
automatic	B
3d	O
model	O
construction	O
for	O
turn-table	O
sequences	O
.	O
in	O
european	O
workshop	O
on	O
3d	O
structure	O
from	O
multiple	O
images	O
of	O
large-scale	O
environments	O
(	O
smile	O
)	O
,	O
pp	O
.	O
155–170	O
,	O
freiburg	O
.	O
fleet	O
,	O
d.	O
and	O
jepson	O
,	O
a	O
.	O
(	O
1990	O
)	O
.	O
computation	O
of	O
component	O
image	B
velocity	O
from	O
local	B
phase	O
information	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
5	O
(	O
1	O
)	O
:77–104	O
.	O
fleuret	O
,	O
f.	O
and	O
geman	O
,	O
d.	O
(	O
2001	O
)	O
.	O
coarse-to-ﬁne	B
face	O
detection	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
41	O
(	O
1/2	O
)	O
:85–107	O
.	O
flickner	O
,	O
m.	O
,	O
sawhney	O
,	O
h.	O
,	O
niblack	O
,	O
w.	O
,	O
ashley	O
,	O
j.	O
,	O
huang	O
,	O
q.	O
et	O
al	O
.	O
(	O
1995	O
)	O
.	O
query	O
by	O
image	B
and	O
video	B
content	O
:	O
the	O
qbic	O
system	O
.	O
computer	O
,	O
28	O
(	O
9	O
)	O
:23–32	O
.	O
foley	O
,	O
j.	O
d.	O
,	O
van	O
dam	O
,	O
a.	O
,	O
feiner	O
,	O
s.	O
k.	O
,	O
and	O
hughes	O
,	O
j.	O
f.	O
(	O
1995	O
)	O
.	O
computer	O
graphics	O
:	O
principles	O
and	O
practice	O
.	O
addison-wesley	O
,	O
reading	O
,	O
ma	O
,	O
2	O
edition	O
.	O
f¨orstner	O
,	O
w.	O
(	O
1986	O
)	O
.	O
a	O
feature-based	B
correspondence	O
algorithm	B
for	O
image	B
matching	O
.	O
intl	O
.	O
arch	O
.	O
photogrammetry	B
&	O
remote	O
sensing	O
,	O
26	O
(	O
3	O
)	O
:150–166	O
.	O
f¨orstner	O
,	O
w.	O
(	O
2005	O
)	O
.	O
uncertainty	B
and	O
projective	B
geometry	O
.	O
in	O
bayro-corrochano	O
,	O
e	O
.	O
(	O
ed	O
.	O
)	O
,	O
handbook	O
of	O
geometric	B
computing	O
,	O
pp	O
.	O
493–534	O
,	O
springer	O
,	O
new	O
york	O
.	O
forsyth	O
,	O
d.	O
and	O
ponce	O
,	O
j	O
.	O
(	O
2003	O
)	O
.	O
computer	O
vision	O
:	O
a	O
modern	O
approach	O
.	O
prentice	O
hall	O
,	O
upper	O
saddle	O
river	O
,	O
nj	O
.	O
forsyth	O
,	O
d.	O
a.	O
and	O
fleck	O
,	O
m.	O
m.	O
(	O
1999	O
)	O
.	O
automatic	B
detection	O
of	O
human	O
nudes	O
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
32	O
(	O
1	O
)	O
:63–77	O
.	O
forsyth	O
,	O
d.	O
a.	O
,	O
arikan	O
,	O
o.	O
,	O
ikemoto	O
,	O
l.	O
,	O
o	O
’	O
brien	O
,	O
j.	O
,	O
and	O
ramanan	O
,	O
d.	O
(	O
2006	O
)	O
.	O
computa-	O
tional	O
studies	O
of	O
human	B
motion	I
:	O
part	O
1	O
,	O
tracking	O
and	O
motion	B
synthesis	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
1	O
(	O
2/3	O
)	O
:77–254	O
.	O
fossati	O
,	O
a.	O
,	O
dimitrijevic	O
,	O
m.	O
,	O
lepetit	O
,	O
v.	O
,	O
and	O
fua	O
,	O
p.	O
(	O
2007	O
)	O
.	O
bridging	O
the	O
gap	O
between	O
detection	B
and	O
tracking	O
for	O
3d	O
monocular	O
video-based	O
motion	O
capture	O
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
frahm	O
,	O
j.-m.	O
and	O
koch	O
,	O
r.	O
(	O
2003	O
)	O
.	O
camera	B
calibration	O
with	O
known	O
rotation	O
.	O
in	O
ninth	O
inter-	O
national	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
1418–1425	O
,	O
nice	O
,	O
france	O
.	O
828	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
freeman	O
,	O
m.	O
(	O
2008	O
)	O
.	O
mastering	O
hdr	O
photography	O
.	O
amphoto	O
books	O
,	O
new	O
york	O
.	O
freeman	O
,	O
w.	O
,	O
perona	O
,	O
p.	O
,	O
and	O
sch¨olkopf	O
,	O
b	O
.	O
(	O
2008	O
)	O
.	O
guest	O
editorial	O
:	O
special	O
issue	O
on	O
machine	O
learning	O
for	O
vision	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
77	O
(	O
1-3	O
)	O
:1.	O
freeman	O
,	O
w.	O
t.	O
(	O
1992	O
)	O
.	O
steerable	B
filters	O
and	O
local	B
analysis	O
of	O
image	B
structure	O
.	O
ph.d.	O
thesis	O
,	O
massachusetts	O
institute	O
of	O
technology	O
.	O
freeman	O
,	O
w.	O
t.	O
and	O
adelson	O
,	O
e.	O
h.	O
(	O
1991	O
)	O
.	O
the	O
design	O
and	O
use	O
of	O
steerable	B
ﬁlters	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
13	O
(	O
9	O
)	O
:891–906	O
.	O
freeman	O
,	O
w.	O
t.	O
,	O
jones	O
,	O
t.	O
r.	O
,	O
and	O
pasztor	O
,	O
e.	O
c.	O
(	O
2002	O
)	O
.	O
example-based	B
super-resolution	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
22	O
(	O
2	O
)	O
:56–65	O
.	O
freeman	O
,	O
w.	O
t.	O
,	O
pasztor	O
,	O
e.	O
c.	O
,	O
and	O
carmichael	O
,	O
o.	O
t.	O
(	O
2000	O
)	O
.	O
learning	B
low-level	O
vision	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
40	O
(	O
1	O
)	O
:25–47	O
.	O
frey	O
,	O
b.	O
j.	O
and	O
mackay	O
,	O
d.	O
j.	O
c.	O
(	O
1997	O
)	O
.	O
a	O
revolution	O
:	O
belief	B
propagation	I
in	O
graphs	O
with	O
cycles	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
friedman	O
,	O
j.	O
,	O
hastie	O
,	O
t.	O
,	O
and	O
tibshirani	O
,	O
r.	O
(	O
2000	O
)	O
.	O
additive	O
logistic	O
regression	O
:	O
a	O
statistical	O
view	O
of	O
boosting	B
.	O
annals	O
of	O
statistics	O
,	O
38	O
(	O
2	O
)	O
:337–374	O
.	O
frisken	O
,	O
s.	O
f.	O
,	O
perry	O
,	O
r.	O
n.	O
,	O
rockwood	O
,	O
a.	O
p.	O
,	O
and	O
jones	O
,	O
t.	O
r.	O
(	O
2000	O
)	O
.	O
adaptively	O
sam-	O
pled	O
distance	O
ﬁelds	O
:	O
a	O
general	O
representation	O
of	O
shape	O
for	O
computer	O
graphics	O
.	O
in	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
249–254	O
.	O
fritz	O
,	O
m.	O
and	O
schiele	O
,	O
b	O
.	O
(	O
2008	O
)	O
.	O
decomposition	O
,	O
discovery	O
and	O
detection	B
of	O
visual	O
cate-	O
gories	O
using	O
topic	O
models	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
frome	O
,	O
a.	O
,	O
singer	O
,	O
y.	O
,	O
sha	O
,	O
f.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2007	O
)	O
.	O
learning	B
globally-consistent	O
local	B
distance	O
functions	O
for	O
shape-based	O
image	B
retrieval	O
and	O
classiﬁcation	O
.	O
in	O
eleventh	O
inter-	O
national	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
fua	O
,	O
p.	O
(	O
1993	O
)	O
.	O
a	O
parallel	O
stereo	B
algorithm	O
that	O
produces	O
dense	O
depth	O
maps	O
and	O
preserves	O
image	B
features	O
.	O
machine	O
vision	O
and	O
applications	O
,	O
6	O
(	O
1	O
)	O
:35–49	O
.	O
fua	O
,	O
p.	O
and	O
leclerc	O
,	O
y.	O
g.	O
(	O
1995	O
)	O
.	O
object-centered	B
surface	O
reconstruction	O
:	O
combining	O
multi-image	O
stereo	B
and	O
shading	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
16	O
(	O
1	O
)	O
:35–	O
56.	O
fua	O
,	O
p.	O
and	O
sander	O
,	O
p.	O
(	O
1992	O
)	O
.	O
segmenting	O
unstructured	B
3d	O
points	B
into	O
surfaces	O
.	O
in	O
second	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
92	O
)	O
,	O
pp	O
.	O
676–680	O
,	O
santa	O
margherita	O
liguere	O
,	O
italy	O
.	O
fuh	O
,	O
c.-s.	O
and	O
maragos	O
,	O
p.	O
(	O
1991	O
)	O
.	O
motion	B
displacement	O
estimation	B
using	O
an	O
afﬁne	B
model	O
for	O
image	O
matching	B
.	O
optical	O
engineering	O
,	O
30	O
(	O
7	O
)	O
:881–887	O
.	O
references	B
829	O
fukunaga	O
,	O
k.	O
and	O
hostetler	O
,	O
l.	O
d.	O
(	O
1975	O
)	O
.	O
the	O
estimation	B
of	O
the	O
gradient	O
of	O
a	O
density	O
function	O
,	O
with	O
applications	O
in	O
pattern	O
recognition	B
.	O
ieee	O
transactions	O
on	O
information	O
theory	O
,	O
21:32–40	O
.	O
furukawa	O
,	O
y.	O
and	O
ponce	O
,	O
j	O
.	O
(	O
2007	O
)	O
.	O
accurate	O
,	O
dense	O
,	O
and	O
robust	B
multi-view	O
stereopsis	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
furukawa	O
,	O
y.	O
and	O
ponce	O
,	O
j	O
.	O
(	O
2008	O
)	O
.	O
accurate	O
calibration	B
from	O
multi-view	B
stereo	I
and	O
bundle	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
adjustment	O
.	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
furukawa	O
,	O
y.	O
and	O
ponce	O
,	O
j	O
.	O
(	O
2009	O
)	O
.	O
carved	O
visual	O
hulls	O
for	O
image-based	O
modeling	B
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
81	O
(	O
1	O
)	O
:53–67	O
.	O
furukawa	O
,	O
y.	O
and	O
ponce	O
,	O
j	O
.	O
(	O
2011	O
)	O
.	O
accurate	O
,	O
dense	O
,	O
and	O
robust	B
multi-view	O
stereopsis	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
.	O
furukawa	O
,	O
y.	O
,	O
curless	O
,	O
b.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2009a	O
)	O
.	O
manhattan-world	O
stereo	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
,	O
fl	O
.	O
furukawa	O
,	O
y.	O
,	O
curless	O
,	O
b.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2009b	O
)	O
.	O
reconstructing	O
building	O
interiors	O
from	O
images	O
.	O
in	O
twelfth	O
ieee	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
furukawa	O
,	O
y.	O
,	O
curless	O
,	O
b.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2010	O
)	O
.	O
towards	O
internet-scale	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
multi-view	B
stereo	I
.	O
pattern	O
recognition	B
(	O
cvpr	O
2010	O
)	O
,	O
san	O
francisco	O
,	O
ca	O
.	O
fusiello	O
,	O
a.	O
,	O
roberto	O
,	O
v.	O
,	O
and	O
trucco	O
,	O
e.	O
(	O
1997	O
)	O
.	O
efﬁcient	O
stereo	B
with	O
multiple	B
windowing	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
858–863	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
fusiello	O
,	O
a.	O
,	O
trucco	O
,	O
e.	O
,	O
and	O
verri	O
,	O
a	O
.	O
(	O
2000	O
)	O
.	O
a	O
compact	O
algorithm	B
for	O
rectiﬁcation	B
of	O
stereo	B
pairs	O
.	O
machine	O
vision	O
and	O
applications	O
,	O
12	O
(	O
1	O
)	O
:16–22	O
.	O
gai	O
,	O
j.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
2009	O
)	O
.	O
matte-based	O
restoration	O
of	O
vintage	O
video	B
.	O
ieee	O
transac-	O
tions	O
on	O
image	B
processing	O
,	O
18:2185–2197	O
.	O
gal	O
,	O
r.	O
,	O
wexler	O
,	O
y.	O
,	O
ofek	O
,	O
e.	O
,	O
hoppe	O
,	O
h.	O
,	O
and	O
cohen-or	O
,	O
d.	O
(	O
2010	O
)	O
.	O
seamless	O
montage	O
for	O
texturing	O
models	O
.	O
in	O
proceedings	O
of	O
eurographics	O
2010.	O
gallagher	O
,	O
a.	O
c.	O
and	O
chen	O
,	O
t.	O
(	O
2008	O
)	O
.	O
multi-image	O
graph	B
cut	I
clothing	O
segmentation	B
for	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
recognizing	O
people	O
.	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
830	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
gallup	O
,	O
d.	O
,	O
frahm	O
,	O
j.-m.	O
,	O
mordohai	O
,	O
p.	O
,	O
and	O
pollefeys	O
,	O
m.	O
(	O
2008	O
)	O
.	O
variable	O
base-	O
line/resolution	O
stereo	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
gamble	O
,	O
e.	O
and	O
poggio	O
,	O
t.	O
(	O
1987	O
)	O
.	O
visual	O
integration	O
and	O
detection	B
of	O
discontinuities	O
:	O
the	O
key	O
role	O
of	O
intensity	O
edges	O
.	O
a.	O
i.	O
memo	O
970	O
,	O
artiﬁcial	O
intelligence	O
laboratory	O
,	O
massachusetts	O
institute	O
of	O
technology	O
.	O
gammeter	O
,	O
s.	O
,	O
bossard	O
,	O
l.	O
,	O
quack	O
,	O
t.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
i	O
know	O
what	O
you	O
did	O
last	O
summer	O
:	O
object-level	O
auto-annotation	O
of	O
holiday	O
snaps	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
(	O
2009	O
)	O
.	O
gao	O
,	O
w.	O
,	O
chen	O
,	O
y.	O
,	O
wang	O
,	O
r.	O
,	O
shan	O
,	O
s.	O
,	O
and	O
jiang	O
,	O
d.	O
(	O
2003	O
)	O
.	O
learning	B
and	O
synthesizing	O
mpeg-4	O
compatible	O
3-d	O
face	B
animation	O
from	O
video	B
sequence	O
.	O
ieee	O
transactions	O
on	O
circuits	O
and	O
systems	O
for	O
video	O
technology	O
,	O
13	O
(	O
11	O
)	O
:1119–1128	O
.	O
garding	O
,	O
j	O
.	O
(	O
1992	O
)	O
.	O
shape	O
from	O
texture	B
for	O
smooth	O
curved	O
surfaces	O
in	O
perspective	B
projec-	O
tion	B
.	O
journal	O
of	O
mathematical	O
imaging	O
and	O
vision	O
,	O
2:329–352	O
.	O
gargallo	O
,	O
p.	O
,	O
prados	O
,	O
e.	O
,	O
and	O
sturm	O
,	O
p.	O
(	O
2007	O
)	O
.	O
minimizing	O
the	O
reprojection	O
error	O
in	O
surface	B
reconstruction	I
from	O
images	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
gavrila	O
,	O
d.	O
m.	O
(	O
1999	O
)	O
.	O
the	O
visual	O
analysis	O
of	O
human	O
movement	O
:	O
a	O
survey	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
73	O
(	O
1	O
)	O
:82–98	O
.	O
gavrila	O
,	O
d.	O
m.	O
and	O
davis	O
,	O
l.	O
s.	O
(	O
1996	O
)	O
.	O
3d	O
model-based	B
tracking	O
of	O
humans	O
in	O
action	O
:	O
a	O
multi-view	B
approach	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
96	O
)	O
,	O
pp	O
.	O
73–80	O
,	O
san	O
francisco	O
.	O
gavrila	O
,	O
d.	O
m.	O
and	O
philomin	O
,	O
v.	O
(	O
1999	O
)	O
.	O
real-time	O
object	O
detection	B
for	O
smart	O
vehicles	O
.	O
in	O
seventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
99	O
)	O
,	O
pp	O
.	O
87–93	O
,	O
kerkyra	O
,	O
greece	O
.	O
geiger	O
,	O
d.	O
and	O
girosi	O
,	O
f.	O
(	O
1991	O
)	O
.	O
parallel	O
and	O
deterministic	O
algorithms	O
for	O
mrfs	O
:	O
sur-	O
face	B
reconstruction	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
13	O
(	O
5	O
)	O
:401–412	O
.	O
geiger	O
,	O
d.	O
,	O
ladendorf	O
,	O
b.	O
,	O
and	O
yuille	O
,	O
a.	O
in	O
second	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
92	O
)	O
,	O
pp	O
.	O
425–433	O
,	O
santa	O
margherita	O
liguere	O
,	O
italy	O
.	O
(	O
1992	O
)	O
.	O
occlusions	O
and	O
binocular	O
stereo	B
.	O
gelb	O
,	O
a	O
.	O
(	O
ed.	O
)	O
.	O
sachusetts	O
.	O
(	O
1974	O
)	O
.	O
applied	O
optimal	O
estimation	B
.	O
mit	O
press	O
,	O
cambridge	O
,	O
mas-	O
geller	O
,	O
t.	O
(	O
2008	O
)	O
.	O
overcoming	O
the	O
uncanny	O
valley	O
.	O
ieee	O
computer	O
graphics	O
and	O
applica-	O
tions	O
,	O
28	O
(	O
4	O
)	O
:11–17	O
.	O
references	B
831	O
geman	O
,	O
s.	O
and	O
geman	O
,	O
d.	O
(	O
1984	O
)	O
.	O
stochastic	O
relaxation	O
,	O
gibbs	O
distribution	O
,	O
and	O
the	O
bayesian	O
restoration	O
of	O
images	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-6	O
(	O
6	O
)	O
:721–741	O
.	O
gennert	O
,	O
m.	O
a	O
.	O
(	O
1988	O
)	O
.	O
brightness-based	O
stereo	B
matching	I
.	O
in	O
second	O
international	O
con-	O
ference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
88	O
)	O
,	O
pp	O
.	O
139–143	O
,	O
tampa	O
.	O
gersho	O
,	O
a.	O
and	O
gray	O
,	O
r.	O
m.	O
(	O
1991	O
)	O
.	O
vector	O
quantization	B
and	O
signal	O
compression	B
.	O
springer	O
.	O
gershun	O
,	O
a	O
.	O
(	O
1939	O
)	O
.	O
the	O
light	B
ﬁeld	I
.	O
journal	O
of	O
mathematics	O
and	O
physics	O
,	O
xviii:51–151	O
.	O
gevers	O
,	O
t.	O
,	O
van	O
de	O
weijer	O
,	O
j.	O
,	O
and	O
stokman	O
,	O
h.	O
(	O
2006	O
)	O
.	O
color	B
feature	O
detection	B
.	O
in	O
lukac	O
,	O
r.	O
and	O
plataniotis	O
,	O
k.	O
n.	O
(	O
eds	O
)	O
,	O
color	B
image	O
processing	O
:	O
methods	O
and	O
applications	O
,	O
crc	O
press	O
.	O
giblin	O
,	O
p.	O
and	O
weiss	O
,	O
r.	O
(	O
1987	O
)	O
.	O
reconstruction	O
of	O
surfaces	O
from	O
proﬁles	B
.	O
in	O
first	O
interna-	O
tional	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
87	O
)	O
,	O
pp	O
.	O
136–144	O
,	O
london	O
,	O
england	O
.	O
gionis	O
,	O
a.	O
,	O
indyk	O
,	O
p.	O
,	O
and	O
motwani	O
,	O
r.	O
(	O
1999	O
)	O
.	O
similarity	B
search	O
in	O
high	O
dimensions	O
via	O
hashing	B
.	O
in	O
25th	O
international	O
conference	O
on	O
very	O
large	O
data	O
bases	O
(	O
vldb	O
’	O
99	O
)	O
,	O
pp	O
.	O
518–529	O
.	O
girod	O
,	O
b.	O
,	O
greiner	O
,	O
g.	O
,	O
and	O
niemann	O
,	O
h.	O
(	O
eds	O
)	O
.	O
(	O
2000	O
)	O
.	O
principles	O
of	O
3d	O
image	B
analysis	O
and	O
synthesis	O
,	O
kluwer	O
,	O
boston	O
.	O
glassner	O
,	O
a.	O
s.	O
(	O
1995	O
)	O
.	O
principles	O
of	O
digital	O
image	O
synthesis	O
.	O
morgan	O
kaufmann	O
publish-	O
ers	O
,	O
san	O
francisco	O
.	O
gleicher	O
,	O
m.	O
(	O
1995	O
)	O
.	O
image	B
snapping	O
.	O
in	O
acm	O
siggraph	O
1995	O
conference	O
proceedings	O
,	O
pp	O
.	O
183–190	O
.	O
gleicher	O
,	O
m.	O
(	O
1997	O
)	O
.	O
projective	B
registration	O
with	O
difference	O
decomposition	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
331–337	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
gleicher	O
,	O
m.	O
and	O
witkin	O
,	O
a	O
.	O
(	O
1992	O
)	O
.	O
through-the-lens	O
camera	B
control	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
92	O
)	O
,	O
26	O
(	O
2	O
)	O
:331–340	O
.	O
glocker	O
,	O
b.	O
,	O
komodakis	O
,	O
n.	O
,	O
tziritas	O
,	O
g.	O
,	O
navab	O
,	O
n.	O
,	O
and	O
paragios	O
,	O
n.	O
(	O
2008	O
)	O
.	O
dense	O
image	O
registration	B
through	O
mrfs	O
and	O
efﬁcient	O
linear	O
programming	O
.	O
medical	B
image	I
analysis	O
,	O
12	O
(	O
6	O
)	O
:731–741	O
.	O
glocker	O
,	O
b.	O
,	O
paragios	O
,	O
n.	O
,	O
komodakis	O
,	O
n.	O
,	O
tziritas	O
,	O
g.	O
,	O
and	O
navab	O
,	O
n.	O
(	O
2008	O
)	O
.	O
optical	B
ﬂow	I
estimation	O
with	O
uncertainties	O
through	O
dynamic	B
mrfs	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
832	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
gluckman	O
,	O
j	O
.	O
(	O
2006a	O
)	O
.	O
higher	O
order	O
image	B
pyramids	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
308–320	O
.	O
gluckman	O
,	O
j	O
.	O
(	O
2006b	O
)	O
.	O
scale	O
variant	O
image	B
pyramids	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
1069–1075	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
goesele	O
,	O
m.	O
,	O
curless	O
,	O
b.	O
,	O
and	O
seitz	O
,	O
s.	O
(	O
2006	O
)	O
.	O
multi-view	B
stereo	I
revisited	O
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
2402–2409	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
goesele	O
,	O
m.	O
,	O
fuchs	O
,	O
c.	O
,	O
and	O
seidel	O
,	O
h.-p.	O
(	O
2003	O
)	O
.	O
accuracy	B
of	O
3d	O
range	O
scanners	O
by	O
measurement	O
of	O
the	O
slanted	O
edge	O
modulation	O
transfer	B
function	O
.	O
in	O
fourth	O
international	O
conference	O
on	O
3-d	O
digital	O
imaging	O
and	O
modeling	B
,	O
banff	O
.	O
goesele	O
,	O
m.	O
,	O
snavely	O
,	O
n.	O
,	O
curless	O
,	O
b.	O
,	O
hoppe	O
,	O
h.	O
,	O
and	O
seitz	O
,	O
s.	O
m.	O
(	O
2007	O
)	O
.	O
multi-view	B
stereo	I
for	O
community	O
photo	O
collections	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
com-	O
puter	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
gold	O
,	O
s.	O
,	O
rangarajan	O
,	O
a.	O
,	O
lu	O
,	O
c.	O
,	O
pappu	O
,	O
s.	O
,	O
and	O
mjolsness	O
,	O
e.	O
(	O
1998	O
)	O
.	O
new	O
algorithms	O
for	O
2d	O
and	O
3d	O
point	O
matching	O
:	O
pose	O
estimation	B
and	O
correspondence	B
.	O
pattern	O
recognition	B
,	O
31	O
(	O
8	O
)	O
:1019–1031	O
.	O
goldberg	O
,	O
a.	O
v.	O
and	O
tarjan	O
,	O
r.	O
e.	O
(	O
1988	O
)	O
.	O
a	O
new	O
approach	O
to	O
the	O
maximum-ﬂow	O
problem	O
.	O
journal	O
of	O
the	O
acm	O
,	O
35	O
(	O
4	O
)	O
:921–940	O
.	O
goldluecke	O
,	O
b.	O
and	O
cremers	O
,	O
d.	O
(	O
2009	O
)	O
.	O
superresolution	O
texture	B
maps	O
for	O
multiview	O
re-	O
construction	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
goldman	O
,	O
d.	O
b	O
.	O
(	O
2011	O
)	O
.	O
vignette	O
and	O
exposure	O
calibration	O
and	O
compensation	O
.	O
ieee	O
trans-	O
actions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
.	O
golovinskiy	O
,	O
a.	O
,	O
matusik	O
,	O
w.	O
,	O
ster	O
,	O
h.	O
p.	O
,	O
rusinkiewicz	O
,	O
s.	O
,	O
and	O
funkhouser	O
,	O
t.	O
(	O
2006	O
)	O
.	O
a	O
statistical	O
model	O
for	O
synthesis	O
of	O
detailed	O
facial	O
geometry	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:1025–1034	O
.	O
golub	O
,	O
g.	O
and	O
van	O
loan	O
,	O
c.	O
f.	O
(	O
1996	O
)	O
.	O
matrix	O
computation	O
,	O
third	O
edition	O
.	O
the	O
john	O
hopkins	O
university	O
press	O
,	O
baltimore	O
and	O
london	O
.	O
gomes	O
,	O
j.	O
and	O
velho	O
,	O
l.	O
(	O
1997	O
)	O
.	O
image	B
processing	O
for	O
computer	O
graphics	O
.	O
springer-	O
verlag	O
,	O
new	O
york	O
.	O
gomes	O
,	O
j.	O
,	O
darsa	O
,	O
l.	O
,	O
costa	O
,	O
b.	O
,	O
and	O
velho	O
,	O
l.	O
(	O
1999	O
)	O
.	O
warping	O
and	O
morphing	B
of	O
graphical	O
objects	O
.	O
morgan	O
kaufmann	O
publishers	O
,	O
san	O
francisco	O
.	O
references	B
833	O
gong	O
,	O
m.	O
,	O
yang	O
,	O
r.	O
,	O
wang	O
,	O
l.	O
,	O
and	O
gong	O
,	O
m.	O
(	O
2007	O
)	O
.	O
a	O
performance	O
study	O
on	O
different	O
cost	O
aggregation	O
approaches	O
used	O
in	O
realtime	O
stereo	B
matching	I
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
75	O
(	O
2	O
)	O
:283–296	O
.	O
gonzales	O
,	O
r.	O
c.	O
and	O
woods	O
,	O
r.	O
e.	O
(	O
2008	O
)	O
.	O
digital	O
image	O
processing	O
.	O
prentice-hall	O
,	O
upper	O
saddle	O
river	O
,	O
nj	O
,	O
3rd	O
edition	O
.	O
gooch	O
,	O
b.	O
and	O
gooch	O
,	O
a	O
.	O
(	O
2001	O
)	O
.	O
non-photorealistic	B
rendering	I
.	O
a	O
k	O
peters	O
,	O
ltd	O
,	O
natick	O
,	O
massachusetts	O
.	O
gordon	O
,	O
i.	O
and	O
lowe	O
,	O
d.	O
g.	O
(	O
2006	O
)	O
.	O
what	O
and	O
where	O
:	O
3d	O
object	O
recognition	B
with	O
accurate	O
pose	O
.	O
in	O
ponce	O
,	O
j.	O
,	O
hebert	O
,	O
m.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
eds	O
)	O
,	O
toward	O
category-	O
level	O
object	O
recognition	B
,	O
pp	O
.	O
67–82	O
,	O
springer	O
,	O
new	O
york	O
.	O
gorelick	O
,	O
l.	O
,	O
blank	O
,	O
m.	O
,	O
shechtman	O
,	O
e.	O
,	O
irani	O
,	O
m.	O
,	O
and	O
basri	O
,	O
r.	O
(	O
2007	O
)	O
.	O
actions	O
as	O
space-time	O
shapes	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
12	O
)	O
:2247–2253	O
.	O
gortler	O
,	O
s.	O
j.	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
1995	O
)	O
.	O
hierarchical	B
and	O
variational	O
geometric	B
modeling	O
with	O
wavelets	O
.	O
in	O
symposium	O
on	O
interactive	B
3d	O
graphics	O
,	O
pp	O
.	O
35–43	O
,	O
monterey	O
,	O
ca	O
.	O
gortler	O
,	O
s.	O
j.	O
,	O
grzeszczuk	O
,	O
r.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
1996	O
)	O
.	O
the	O
lumigraph	O
.	O
in	O
acm	O
siggraph	O
1996	O
conference	O
proceedings	O
,	O
pp	O
.	O
43–54	O
,	O
new	O
orleans	O
.	O
goshtasby	O
,	O
a	O
.	O
(	O
1989	O
)	O
.	O
correction	O
of	O
image	B
deformation	O
from	O
lens	O
distortion	O
using	O
b´ezier	O
patches	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
47	O
(	O
4	O
)	O
:385–394	O
.	O
goshtasby	O
,	O
a	O
.	O
(	O
2005	O
)	O
.	O
2-d	O
and	O
3-d	O
image	B
registration	I
.	O
wiley	O
,	O
new	O
york	O
.	O
gotchev	O
,	O
a.	O
and	O
rosenhahn	O
,	O
b	O
.	O
(	O
eds	O
)	O
.	O
(	O
2009	O
)	O
.	O
proceedings	O
of	O
the	O
3dtv	O
conference	O
:	O
the	O
true	O
vision—capture	O
,	O
transmission	O
and	O
display	O
of	O
3d	O
video	B
,	O
ieee	O
computer	O
society	O
press	O
.	O
govindu	O
,	O
v.	O
m.	O
(	O
2006	O
)	O
.	O
revisiting	O
the	O
brightness	O
constraint	B
:	O
probabilistic	B
formulation	O
and	O
algorithms	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
177–	O
188.	O
grady	O
,	O
l.	O
(	O
2006	O
)	O
.	O
random	O
walks	O
for	O
image	O
segmentation	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
11	O
)	O
:1768–1783	O
.	O
grady	O
,	O
l.	O
(	O
2008	O
)	O
.	O
a	O
lattice-preserving	O
multigrid	O
method	O
for	O
solving	O
the	O
inhomogeneous	O
poisson	O
equations	B
used	O
in	O
image	B
analysis	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
252–264	O
,	O
marseilles	O
.	O
grady	O
,	O
l.	O
and	O
ali	O
,	O
s.	O
(	O
2008	O
)	O
.	O
fast	O
approximate	O
random	B
walker	I
segmentation	O
using	O
eigen-	O
vector	O
precomputation	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
834	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
grady	O
,	O
l.	O
and	O
alvino	O
,	O
c.	O
(	O
2008	O
)	O
.	O
reformulating	O
and	O
optimizing	O
the	O
mumford–shah	O
func-	O
tional	O
on	O
a	O
graph	O
—	O
a	O
faster	O
,	O
lower	O
energy	O
solution	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
248–261	O
,	O
marseilles	O
.	O
grauman	O
,	O
k.	O
and	O
darrell	O
,	O
t.	O
(	O
2005	O
)	O
.	O
efﬁcient	O
image	B
matching	O
with	O
distributions	O
of	O
lo-	O
cal	O
invariant	O
features	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
627–634	O
,	O
san	O
diego	O
,	O
ca	O
.	O
grauman	O
,	O
k.	O
and	O
darrell	O
,	O
t.	O
(	O
2007a	O
)	O
.	O
pyramid	B
match	O
hashing	B
:	O
sub-linear	O
time	O
index-	O
ing	O
over	O
partial	O
correspondences	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
grauman	O
,	O
k.	O
and	O
darrell	O
,	O
t.	O
(	O
2007b	O
)	O
.	O
the	O
pyramid	B
match	O
kernel	B
:	O
efﬁcient	O
learning	B
with	O
sets	O
of	O
features	O
.	O
journal	O
of	O
machine	O
learning	O
research	O
,	O
8:725–760	O
.	O
grauman	O
,	O
k.	O
,	O
shakhnarovich	O
,	O
g.	O
,	O
and	O
darrell	O
,	O
t.	O
inferring	O
3d	O
structure	O
with	O
a	O
statistical	O
image-based	B
shape	O
model	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
641–648	O
,	O
nice	O
,	O
france	O
.	O
(	O
2003	O
)	O
.	O
greene	O
,	O
n.	O
(	O
1986	O
)	O
.	O
environment	O
mapping	O
and	O
other	O
applications	O
of	O
world	O
projections	B
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
6	O
(	O
11	O
)	O
:21–29	O
.	O
greene	O
,	O
n.	O
and	O
heckbert	O
,	O
p.	O
(	O
1986	O
)	O
.	O
creating	O
raster	O
omnimax	O
images	O
from	O
multiple	B
per-	O
spective	O
views	O
using	O
the	O
elliptical	O
weighted	B
average	O
ﬁlter	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
6	O
(	O
6	O
)	O
:21–27	O
.	O
greig	O
,	O
d.	O
,	O
porteous	O
,	O
b.	O
,	O
and	O
seheult	O
,	O
a	O
.	O
(	O
1989	O
)	O
.	O
exact	O
maximum	O
a	O
posteriori	O
estimation	B
for	O
binary	O
images	O
.	O
journal	O
of	O
the	O
royal	O
statistical	O
society	O
,	O
series	O
b	O
,	O
51	O
(	O
2	O
)	O
:271–279	O
.	O
gremban	O
,	O
k.	O
d.	O
,	O
thorpe	O
,	O
c.	O
e.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
1988	O
)	O
.	O
geometric	B
camera	O
calibration	B
using	O
systems	O
of	O
linear	B
equations	O
.	O
in	O
ieee	O
international	O
conference	O
on	O
robotics	O
and	O
automation	O
,	O
pp	O
.	O
562–567	O
,	O
philadelphia	O
.	O
grifﬁn	O
,	O
g.	O
,	O
holub	O
,	O
a.	O
,	O
and	O
perona	O
,	O
p.	O
(	O
2007	O
)	O
.	O
caltech-256	O
object	O
category	O
dataset	O
.	O
tech-	O
nical	O
report	O
7694	O
,	O
california	O
institute	O
of	O
technology	O
.	O
grimson	O
,	O
w.	O
e.	O
l.	O
(	O
1983	O
)	O
.	O
an	O
implementation	O
of	O
a	O
computational	B
theory	I
of	O
visual	O
surface	O
interpolation	B
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
22:39–69	O
.	O
grimson	O
,	O
w.	O
e.	O
l.	O
(	O
1985	O
)	O
.	O
computational	O
experiments	O
with	O
a	O
feature	B
based	O
stereo	B
al-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-	O
gorithm	O
.	O
7	O
(	O
1	O
)	O
:17–34	O
.	O
gross	O
,	O
r.	O
,	O
matthews	O
,	O
i.	O
,	O
and	O
baker	O
,	O
s.	O
(	O
2006	O
)	O
.	O
active	O
appearance	O
models	O
with	O
occlusion	O
.	O
image	B
and	O
vision	O
computing	O
,	O
24	O
(	O
6	O
)	O
:593–604	O
.	O
gross	O
,	O
r.	O
,	O
shi	O
,	O
j.	O
,	O
and	O
cohn	O
,	O
j.	O
f.	O
(	O
2005	O
)	O
.	O
quo	O
vadis	O
face	B
recognition	O
?	O
in	O
ieee	O
workshop	O
on	O
empirical	O
evaluation	B
methods	O
in	O
computer	O
vision	O
,	O
san	O
diego	O
.	O
references	B
835	O
gross	O
,	O
r.	O
,	O
baker	O
,	O
s.	O
,	O
matthews	O
,	O
i.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
2005	O
)	O
.	O
face	B
recognition	O
across	O
pose	O
and	O
illumination	O
.	O
in	O
li	O
,	O
s.	O
z.	O
and	O
jain	O
,	O
a.	O
k.	O
(	O
eds	O
)	O
,	O
handbook	O
of	O
face	B
recognition	O
,	O
springer	O
.	O
gross	O
,	O
r.	O
,	O
sweeney	O
,	O
l.	O
,	O
de	O
la	O
torre	O
,	O
f.	O
,	O
and	O
baker	O
,	O
s.	O
(	O
2008	O
)	O
.	O
semi-supervised	O
learning	B
of	O
multi-factor	O
models	O
for	O
face	O
de-identiﬁcation	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
gross	O
,	O
r.	O
,	O
matthews	O
,	O
i.	O
,	O
cohn	O
,	O
j.	O
,	O
kanade	O
,	O
t.	O
,	O
and	O
baker	O
,	O
s.	O
(	O
2010	O
)	O
.	O
multi-pie	O
.	O
image	B
and	O
vision	O
computing	O
,	O
28	O
(	O
5	O
)	O
:807–813	O
.	O
grossberg	O
,	O
m.	O
d.	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
2001	O
)	O
.	O
a	O
general	O
imaging	O
model	O
and	O
a	O
method	O
for	O
ﬁnding	O
its	O
parameters	B
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
108–115	O
,	O
vancouver	O
,	O
canada	O
.	O
grossberg	O
,	O
m.	O
d.	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
2004	O
)	O
.	O
modeling	B
the	O
space	O
of	O
camera	B
response	O
func-	O
tions	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
26	O
(	O
10	O
)	O
:1272–	O
1282.	O
gu	O
,	O
c.	O
,	O
lim	O
,	O
j.	O
,	O
arbelaez	O
,	O
p.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2009	O
)	O
.	O
recognition	B
using	O
regions	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
gu	O
,	O
x.	O
,	O
gortler	O
,	O
s.	O
j.	O
,	O
and	O
hoppe	O
,	O
h.	O
(	O
2002	O
)	O
.	O
geometry	O
images	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
21	O
(	O
3	O
)	O
:355–361	O
.	O
guan	O
,	O
p.	O
,	O
weiss	O
,	O
a.	O
,	O
bˇalan	O
,	O
a.	O
o.	O
,	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2009	O
)	O
.	O
estimating	O
human	O
shape	O
and	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
pose	O
from	O
a	O
single	O
image	O
.	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
guennebaud	O
,	O
g.	O
and	O
gross	O
,	O
m.	O
(	O
2007	O
)	O
.	O
algebraic	O
point	O
set	O
surfaces	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
guennebaud	O
,	O
g.	O
,	O
germann	O
,	O
m.	O
,	O
and	O
gross	O
,	O
m.	O
(	O
2008	O
)	O
.	O
dynamic	B
sampling	O
and	O
rendering	B
of	O
algebraic	O
point	O
set	O
surfaces	O
.	O
computer	O
graphics	O
forum	O
,	O
27	O
(	O
2	O
)	O
:653–662	O
.	O
guenter	O
,	O
b.	O
,	O
grimm	O
,	O
c.	O
,	O
wood	O
,	O
d.	O
,	O
malvar	O
,	O
h.	O
,	O
and	O
pighin	O
,	O
f.	O
(	O
1998	O
)	O
.	O
making	O
faces	B
.	O
in	O
acm	O
siggraph	O
1998	O
conference	O
proceedings	O
,	O
pp	O
.	O
55–66	O
.	O
guillaumin	O
,	O
m.	O
,	O
verbeek	O
,	O
j.	O
,	O
and	O
schmid	O
,	O
c.	O
is	O
that	O
you	O
?	O
metric	O
learning	B
ap-	O
proaches	O
for	O
face	O
identiﬁcation	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vi-	O
sion	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
(	O
2009	O
)	O
.	O
gulbins	O
,	O
j.	O
and	O
gulbins	O
,	O
r.	O
(	O
2009	O
)	O
.	O
photographic	O
multishot	O
techniques	O
:	O
high	B
dynamic	I
range	I
,	O
super-resolution	O
,	O
extended	O
depth	O
of	O
field	O
,	O
stitching	O
.	O
rocky	O
nook	O
.	O
836	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
habbecke	O
,	O
m.	O
and	O
kobbelt	O
,	O
l.	O
(	O
2007	O
)	O
.	O
a	O
surface-growing	O
approach	O
to	O
multi-view	B
stereo	I
reconstruction	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
hager	O
,	O
g.	O
d.	O
and	O
belhumeur	O
,	O
p.	O
n.	O
(	O
1998	O
)	O
.	O
efﬁcient	O
region	B
tracking	O
with	O
parametric	O
models	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
of	O
geometry	O
and	O
illumination	O
.	O
intelligence	O
,	O
20	O
(	O
10	O
)	O
:1025–1039	O
.	O
hall	O
,	O
r.	O
(	O
1989	O
)	O
.	O
illumination	O
and	O
color	B
in	O
computer	O
generated	O
imagery	O
.	O
springer-verlag	O
,	O
new	O
york	O
.	O
haller	O
,	O
m.	O
,	O
billinghurst	O
,	O
m.	O
,	O
and	O
thomas	O
,	O
b	O
.	O
(	O
2007	O
)	O
.	O
emerging	O
technologies	O
of	O
augmented	B
reality	I
:	O
interfaces	O
and	O
design	O
.	O
igi	O
publishing	O
.	O
hampel	O
,	O
f.	O
r.	O
,	O
ronchetti	O
,	O
e.	O
m.	O
,	O
rousseeuw	O
,	O
p.	O
j.	O
,	O
and	O
stahel	O
,	O
w.	O
a	O
.	O
(	O
1986	O
)	O
.	O
robust	B
statistics	O
:	O
the	O
approach	O
based	O
on	O
inﬂuence	O
functions	O
.	O
wiley	O
,	O
new	O
york	O
.	O
han	O
,	O
f.	O
and	O
zhu	O
,	O
s.-c.	O
(	O
2005	O
)	O
.	O
bottom-up/top-down	O
image	B
parsing	O
by	O
attribute	O
graph	O
gram-	O
mar	O
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
1778–	O
1785	O
,	O
beijing	O
,	O
china	O
.	O
hanna	O
,	O
k.	O
j	O
.	O
(	O
1991	O
)	O
.	O
direct	B
multi-resolution	O
estimation	B
of	O
ego-motion	O
and	O
structure	B
from	I
motion	I
.	O
in	O
ieee	O
workshop	O
on	O
visual	O
motion	O
,	O
pp	O
.	O
156–162	O
,	O
princeton	O
,	O
new	O
jersey	O
.	O
hannah	O
,	O
m.	O
j	O
.	O
(	O
1974	O
)	O
.	O
computer	O
matching	B
of	O
areas	O
in	O
stereo	B
images	O
.	O
ph.d.	O
thesis	O
,	O
stan-	O
ford	O
university	O
.	O
hannah	O
,	O
m.	O
j	O
.	O
(	O
1988	O
)	O
.	O
test	O
results	O
from	O
sri	O
’	O
s	O
stereo	B
system	O
.	O
in	O
image	B
understanding	O
workshop	O
,	O
pp	O
.	O
740–744	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
hansen	O
,	O
m.	O
,	O
anandan	O
,	O
p.	O
,	O
dana	O
,	O
k.	O
,	O
van	O
der	O
wal	O
,	O
g.	O
,	O
and	O
burt	O
,	O
p.	O
(	O
1994	O
)	O
.	O
real-time	O
scene	O
stabilization	O
and	O
mosaic	O
construction	O
.	O
in	O
ieee	O
workshop	O
on	O
applications	O
of	O
computer	O
vision	O
(	O
wacv	O
’	O
94	O
)	O
,	O
pp	O
.	O
54–62	O
,	O
sarasota	O
.	O
hanson	O
,	O
a.	O
r.	O
and	O
riseman	O
,	O
e.	O
m.	O
(	O
eds	O
)	O
.	O
(	O
1978	O
)	O
.	O
computer	O
vision	O
systems	O
,	O
academic	O
press	O
,	O
new	O
york	O
.	O
haralick	O
,	O
r.	O
m.	O
and	O
shapiro	O
,	O
l.	O
g.	O
(	O
1985	O
)	O
.	O
image	B
segmentation	O
techniques	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
29	O
(	O
1	O
)	O
:100–132	O
.	O
haralick	O
,	O
r.	O
m.	O
and	O
shapiro	O
,	O
l.	O
g.	O
(	O
1992	O
)	O
.	O
computer	O
and	O
robot	O
vision	O
.	O
addison-wesley	O
,	O
reading	O
,	O
ma	O
.	O
haralick	O
,	O
r.	O
m.	O
,	O
lee	O
,	O
c.-n.	O
,	O
ottenberg	O
,	O
k.	O
,	O
and	O
n¨olle	O
,	O
m.	O
(	O
1994	O
)	O
.	O
review	O
and	O
analysis	O
of	O
solutions	O
of	O
the	O
three	O
point	O
perspective	O
pose	O
estimation	B
problem	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
13	O
(	O
3	O
)	O
:331–356	O
.	O
references	B
837	O
hardie	O
,	O
r.	O
c.	O
,	O
barnard	O
,	O
k.	O
j.	O
,	O
and	O
armstrong	O
,	O
e.	O
e.	O
(	O
1997	O
)	O
.	O
joint	B
map	O
registration	B
and	O
ieee	O
high-resolution	O
image	B
estimation	O
using	O
a	O
sequence	O
of	O
undersampled	O
images	O
.	O
transactions	O
on	O
image	B
processing	O
,	O
6	O
(	O
12	O
)	O
:1621–1633	O
.	O
haritaoglu	O
,	O
i.	O
,	O
harwood	O
,	O
d.	O
,	O
and	O
davis	O
,	O
l.	O
s.	O
(	O
2000	O
)	O
.	O
w4	O
:	O
real-time	O
surveillance	O
of	O
people	O
and	O
their	O
activities	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
22	O
(	O
8	O
)	O
:809–830	O
.	O
harker	O
,	O
m.	O
and	O
o	O
’	O
leary	O
,	O
p.	O
(	O
2008	O
)	O
.	O
least	B
squares	I
surface	O
reconstruction	O
from	O
measured	O
gradient	O
ﬁelds	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
harris	O
,	O
c.	O
and	O
stephens	O
,	O
m.	O
j	O
.	O
(	O
1988	O
)	O
.	O
a	O
combined	O
corner	O
and	O
edge	O
detector	O
.	O
in	O
alvey	O
vision	O
conference	O
,	O
pp	O
.	O
147–152	O
.	O
hartley	O
,	O
r.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
2007	O
)	O
.	O
parameter-free	O
radial	B
distortion	I
correction	O
with	O
center	O
of	O
distortion	O
estimation	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelli-	O
gence	O
,	O
31	O
(	O
8	O
)	O
:1309–1321	O
.	O
hartley	O
,	O
r.	O
,	O
gupta	O
,	O
r.	O
,	O
and	O
chang	O
,	O
t.	O
(	O
1992	O
)	O
.	O
estimation	B
of	O
relative	O
camera	B
positions	O
for	O
uncalibrated	O
cameras	O
.	O
in	O
second	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
92	O
)	O
,	O
pp	O
.	O
579–587	O
,	O
santa	O
margherita	O
liguere	O
,	O
italy	O
.	O
hartley	O
,	O
r.	O
i	O
.	O
(	O
1994a	O
)	O
.	O
projective	B
reconstruction	O
and	O
invariants	O
from	O
multiple	B
images	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
16	O
(	O
10	O
)	O
:1036–1041	O
.	O
hartley	O
,	O
r.	O
i	O
.	O
(	O
1994b	O
)	O
.	O
self-calibration	B
from	O
multiple	B
views	O
of	O
a	O
rotating	O
camera	B
.	O
in	O
third	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
94	O
)	O
,	O
pp	O
.	O
471–478	O
,	O
stockholm	O
,	O
sweden	O
.	O
hartley	O
,	O
r.	O
i	O
.	O
(	O
1997a	O
)	O
.	O
in	O
defense	O
of	O
the	O
8-point	O
algorithm	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
6	O
)	O
:580–593	O
.	O
hartley	O
,	O
r.	O
i	O
.	O
(	O
1997b	O
)	O
.	O
self-calibration	B
of	O
stationary	O
cameras	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
22	O
(	O
1	O
)	O
:5–23	O
.	O
hartley	O
,	O
r.	O
i	O
.	O
(	O
1998	O
)	O
.	O
chirality	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
26	O
(	O
1	O
)	O
:41–61	O
.	O
hartley	O
,	O
r.	O
i.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
2005	O
)	O
.	O
parameter-free	O
radial	B
distortion	I
correction	O
with	O
centre	O
of	O
distortion	O
estimation	B
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
1834–1841	O
,	O
beijing	O
,	O
china	O
.	O
hartley	O
,	O
r.	O
i.	O
and	O
sturm	O
,	O
p.	O
(	O
1997	O
)	O
.	O
triangulation	B
.	O
computer	O
vision	O
and	O
image	B
under-	O
standing	O
,	O
68	O
(	O
2	O
)	O
:146–157	O
.	O
hartley	O
,	O
r.	O
i.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2004	O
)	O
.	O
multiple	B
view	O
geometry	O
.	O
cambridge	O
university	O
press	O
,	O
cambridge	O
,	O
uk	O
.	O
838	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
hartley	O
,	O
r.	O
i.	O
,	O
hayman	O
,	O
e.	O
,	O
de	O
agapito	O
,	O
l.	O
,	O
and	O
reid	O
,	O
i	O
.	O
(	O
2000	O
)	O
.	O
camera	B
calibration	O
and	O
the	O
search	O
for	O
inﬁnity	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
510–517	O
,	O
hilton	O
head	B
island	O
.	O
hasinoff	O
,	O
s.	O
w.	O
and	O
kutulakos	O
,	O
k.	O
n.	O
(	O
2008	O
)	O
.	O
light-efﬁcient	O
photography	O
.	O
in	O
tenth	O
euro-	O
pean	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
45–59	O
,	O
marseilles	O
.	O
hasinoff	O
,	O
s.	O
w.	O
,	O
durand	O
,	O
f.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2010	O
)	O
.	O
noise-optimal	O
capture	O
for	O
high	O
dy-	O
namic	O
range	O
photography	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2010	O
)	O
,	O
san	O
francisco	O
,	O
ca	O
.	O
hasinoff	O
,	O
s.	O
w.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
boundary	O
matting	O
for	O
view	O
synthesis	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
103	O
(	O
1	O
)	O
:22–32	O
.	O
hasinoff	O
,	O
s.	O
w.	O
,	O
kutulakos	O
,	O
k.	O
n.	O
,	O
durand	O
,	O
f.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2009	O
)	O
.	O
time-	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
constrained	B
photography	O
.	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
hastie	O
,	O
t.	O
,	O
tibshirani	O
,	O
r.	O
,	O
and	O
friedman	O
,	O
j	O
.	O
(	O
2001	O
)	O
.	O
the	O
elements	O
of	O
statistical	O
learning	B
:	O
data	O
mining	O
,	O
inference	B
,	O
and	O
prediction	O
.	O
springer-verlag	O
,	O
new	O
york	O
.	O
hayes	O
,	O
b	O
.	O
(	O
2008	O
)	O
.	O
computational	O
photography	O
.	O
american	O
scientist	O
,	O
96:94–99	O
.	O
hays	O
,	O
j.	O
and	O
efros	O
,	O
a.	O
a	O
.	O
(	O
2007	O
)	O
.	O
scene	B
completion	I
using	O
millions	O
of	O
photographs	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
hays	O
,	O
j.	O
,	O
leordeanu	O
,	O
m.	O
,	O
efros	O
,	O
a.	O
a.	O
,	O
and	O
liu	O
,	O
y	O
.	O
(	O
2006	O
)	O
.	O
discovering	O
texture	B
regularity	O
as	O
a	O
higher-order	O
correspondence	B
problem	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
522–535	O
.	O
he	O
,	O
l.-w.	O
and	O
zhang	O
,	O
z.	O
video	B
camera	O
for	O
teleconferencing	O
.	O
speech	O
,	O
and	O
signal	O
processing	O
(	O
icassp	O
2005	O
)	O
,	O
pp	O
.	O
1113–1116	O
,	O
philadelphia	O
.	O
(	O
2005	O
)	O
.	O
real-time	O
whiteboard	O
capture	O
and	O
processing	O
using	O
a	O
in	O
ieee	O
international	O
conference	O
on	O
acoustics	O
,	O
he	O
,	O
x.	O
and	O
zemel	O
,	O
r.	O
s.	O
(	O
2008	O
)	O
.	O
learning	B
hybrid	O
models	O
for	O
image	O
annotation	O
with	O
partially	O
labeled	O
data	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
he	O
,	O
x.	O
,	O
zemel	O
,	O
r.	O
s.	O
,	O
and	O
carreira-perpi˜n´an	O
,	O
m.	O
a	O
.	O
(	O
2004	O
)	O
.	O
multiscale	O
conditional	O
random	O
ﬁelds	O
for	O
image	O
labeling	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
695–702	O
,	O
washington	O
,	O
dc	O
.	O
he	O
,	O
x.	O
,	O
zemel	O
,	O
r.	O
s.	O
,	O
and	O
ray	O
,	O
d.	O
(	O
2006	O
)	O
.	O
learning	B
and	O
incorporating	O
top-down	O
cues	O
in	O
image	B
segmentation	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
338–351	O
.	O
healey	O
,	O
g.	O
e.	O
and	O
kondepudy	O
,	O
r.	O
(	O
1994	O
)	O
.	O
radiometric	B
ccd	O
camera	B
calibration	O
and	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
noise	B
estimation	O
.	O
16	O
(	O
3	O
)	O
:267–276	O
.	O
references	B
839	O
healey	O
,	O
g.	O
e.	O
and	O
shafer	O
,	O
s.	O
a	O
.	O
(	O
1992	O
)	O
.	O
color	B
.	O
physics-based	B
vision	O
:	O
principles	O
and	O
practice	O
,	O
jones	O
&	O
bartlett	O
,	O
cambridge	O
,	O
ma	O
.	O
heath	O
,	O
m.	O
d.	O
,	O
sarkar	O
,	O
s.	O
,	O
sanocki	O
,	O
t.	O
,	O
and	O
bowyer	O
,	O
k.	O
w.	O
(	O
1998	O
)	O
.	O
comparison	O
of	O
edge	O
detectors	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
69	O
(	O
1	O
)	O
:38–54	O
.	O
hebert	O
,	O
m.	O
(	O
2000	O
)	O
.	O
active	O
and	O
passive	O
range	O
sensing	O
for	O
robotics	O
.	O
in	O
ieee	O
international	O
conference	O
on	O
robotics	O
and	O
automation	O
,	O
pp	O
.	O
102–110	O
,	O
san	O
francisco	O
.	O
hecht	O
,	O
e.	O
(	O
2001	O
)	O
.	O
optics	B
.	O
pearson	O
addison	O
wesley	O
,	O
reading	O
,	O
ma	O
,	O
4th	O
edition	O
.	O
heckbert	O
,	O
p.	O
(	O
1986	O
)	O
.	O
survey	O
of	O
texture	B
mapping	O
.	O
ieee	O
computer	O
graphics	O
and	O
applica-	O
tions	O
,	O
6	O
(	O
11	O
)	O
:56–67	O
.	O
heckbert	O
,	O
p.	O
(	O
1989	O
)	O
.	O
fundamentals	O
of	O
texture	B
mapping	O
and	O
image	B
warping	O
.	O
master	O
’	O
s	O
thesis	O
,	O
the	O
university	O
of	O
california	O
at	O
berkeley	O
.	O
heeger	O
,	O
d.	O
j	O
.	O
(	O
1988	O
)	O
.	O
optical	B
ﬂow	I
using	O
spatiotemporal	O
ﬁlters	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
1	O
(	O
1	O
)	O
:279–302	O
.	O
heeger	O
,	O
d.	O
j.	O
and	O
bergen	O
,	O
j.	O
r.	O
(	O
1995	O
)	O
.	O
pyramid-based	O
texture	B
analysis/synthesis	O
.	O
in	O
acm	O
siggraph	O
1995	O
conference	O
proceedings	O
,	O
pp	O
.	O
229–238	O
.	O
heisele	O
,	O
b.	O
,	O
serre	O
,	O
t.	O
,	O
and	O
poggio	O
,	O
t.	O
(	O
2007	O
)	O
.	O
a	O
component-based	O
framework	O
for	O
face	O
detection	B
and	O
identiﬁcation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
74	O
(	O
2	O
)	O
:167–181	O
.	O
heisele	O
,	O
b.	O
,	O
ho	O
,	O
p.	O
,	O
wu	O
,	O
j.	O
,	O
and	O
poggio	O
,	O
t.	O
(	O
2003	O
)	O
.	O
face	B
recognition	O
:	O
component-based	O
versus	O
global	B
approaches	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
91	O
(	O
1-2	O
)	O
:6–21	O
.	O
herley	O
,	O
c.	O
(	O
2005	O
)	O
.	O
automatic	B
occlusion	O
removal	O
from	O
minimum	O
number	O
of	O
images	O
.	O
in	O
in-	O
ternational	O
conference	O
on	O
image	B
processing	O
(	O
icip	O
2005	O
)	O
,	O
pp	O
.	O
1046–1049–16	O
,	O
genova	O
.	O
hernandez	O
,	O
c.	O
and	O
schmitt	O
,	O
f.	O
(	O
2004	O
)	O
.	O
silhouette	O
and	O
stereo	B
fusion	O
for	O
3d	O
object	O
modeling	B
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
96	O
(	O
3	O
)	O
:367–392	O
.	O
hernandez	O
,	O
c.	O
and	O
vogiatzis	O
,	O
g.	O
(	O
2010	O
)	O
.	O
self-calibrating	O
a	O
real-time	O
monocular	O
3d	O
facial	O
capture	O
system	O
.	O
in	O
fifth	O
international	O
symposium	O
on	O
3d	O
data	O
processing	O
,	O
visualization	O
and	O
transmission	O
(	O
3dpvt	O
’	O
10	O
)	O
,	O
paris	O
.	O
hernandez	O
,	O
c.	O
,	O
vogiatzis	O
,	O
g.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2007	O
)	O
.	O
probabilistic	B
visibility	O
for	O
multi-	O
view	O
stereo	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
hernandez	O
,	O
c.	O
,	O
vogiatzis	O
,	O
g.	O
,	O
brostow	O
,	O
g.	O
j.	O
,	O
stenger	O
,	O
b.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2007	O
)	O
.	O
non-	O
rigid	O
photometric	O
stereo	B
with	O
colored	O
lights	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
840	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
hershberger	O
,	O
j.	O
and	O
snoeyink	O
,	O
j.	O
speeding	O
up	O
the	O
douglas-peucker	O
line-	O
simpliﬁcation	B
algorithm	O
.	O
technical	O
report	O
tr-92-07	O
,	O
computer	O
science	O
department	O
,	O
the	O
university	O
of	O
british	O
columbia	O
.	O
(	O
1992	O
)	O
.	O
hertzmann	O
,	O
a.	O
,	O
jacobs	O
,	O
c.	O
e.	O
,	O
oliver	O
,	O
n.	O
,	O
curless	O
,	O
b.	O
,	O
and	O
salesin	O
,	O
d.	O
h.	O
(	O
2001	O
)	O
.	O
image	B
analogies	O
.	O
in	O
acm	O
siggraph	O
2001	O
conference	O
proceedings	O
,	O
pp	O
.	O
327–340	O
.	O
hiep	O
,	O
v.	O
h.	O
,	O
keriven	O
,	O
r.	O
,	O
pons	O
,	O
j.-p.	O
,	O
and	O
labatut	O
,	O
p.	O
(	O
2009	O
)	O
.	O
towards	O
high-resolution	O
large-	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
scale	O
multi-view	O
stereo	B
.	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
hillman	O
,	O
p.	O
,	O
hannah	O
,	O
j.	O
,	O
and	O
renshaw	O
,	O
d.	O
(	O
2001	O
)	O
.	O
alpha	O
channel	O
estimation	B
in	O
high	O
resolu-	O
tion	B
images	O
and	O
image	B
sequences	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2001	O
)	O
,	O
pp	O
.	O
1063–1068	O
,	O
kauai	O
,	O
hawaii	O
.	O
hilton	O
,	O
a.	O
,	O
fua	O
,	O
p.	O
,	O
and	O
ronfard	O
,	O
r.	O
(	O
2006	O
)	O
.	O
modeling	B
people	O
:	O
vision-based	O
understanding	O
of	O
a	O
person	O
’	O
s	O
shape	O
,	O
appearance	O
,	O
movement	O
,	O
and	O
behaviour	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-3	O
)	O
:87–89	O
.	O
hilton	O
,	O
a.	O
,	O
stoddart	O
,	O
a.	O
j.	O
,	O
illingworth	O
,	O
j.	O
,	O
and	O
windeatt	O
,	O
t.	O
(	O
1996	O
)	O
.	O
reliable	O
surface	B
re-	O
construction	O
from	O
multiple	B
range	O
images	O
.	O
in	O
fourth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
96	O
)	O
,	O
pp	O
.	O
117–126	O
,	O
cambridge	O
,	O
england	O
.	O
hinckley	O
,	O
k.	O
,	O
sinclair	O
,	O
m.	O
,	O
hanson	O
,	O
e.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
conway	O
,	O
m.	O
(	O
1999	O
)	O
.	O
the	O
video-	O
in	O
12th	O
annual	O
acm	O
mouse	O
:	O
a	O
camera-based	O
multi-degree-of-freedom	O
input	O
device	O
.	O
symposium	O
on	O
user	O
interface	O
software	O
and	O
technology	O
,	O
pp	O
.	O
103–112	O
.	O
hinterstoisser	O
,	O
s.	O
,	O
benhimane	O
,	O
s.	O
,	O
navab	O
,	O
n.	O
,	O
fua	O
,	O
p.	O
,	O
and	O
lepetit	O
,	O
v.	O
(	O
2008	O
)	O
.	O
online	O
learning	B
of	O
patch	B
perspective	O
rectiﬁcation	B
for	O
efﬁcient	O
object	O
detection	B
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
hinton	O
,	O
g.	O
e.	O
(	O
1977	O
)	O
.	O
relaxation	O
and	O
its	O
role	O
in	O
vision	O
.	O
ph.d.	O
thesis	O
,	O
university	O
of	O
edin-	O
burgh	O
.	O
hirschm¨uller	O
,	O
h.	O
(	O
2008	O
)	O
.	O
stereo	B
processing	O
by	O
semiglobal	O
matching	B
and	O
mutual	O
informa-	O
tion	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
30	O
(	O
2	O
)	O
:328–341	O
.	O
hirschm¨uller	O
,	O
h.	O
and	O
scharstein	O
,	O
d.	O
(	O
2009	O
)	O
.	O
evaluation	B
of	O
stereo	B
matching	I
costs	O
on	O
im-	O
ages	O
with	O
radiometric	O
differences	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
31	O
(	O
9	O
)	O
:1582–1599	O
.	O
hjaltason	O
,	O
g.	O
r.	O
and	O
samet	O
,	O
h.	O
(	O
2003	O
)	O
.	O
index-driven	O
similarity	B
search	O
in	O
metric	O
spaces	O
.	O
acm	O
transactions	O
on	O
database	O
systems	O
,	O
28	O
(	O
4	O
)	O
:517–580	O
.	O
hofmann	O
,	O
t.	O
(	O
1999	O
)	O
.	O
probabilistic	B
latent	O
semantic	O
indexing	O
.	O
in	O
acm	O
sigir	O
conference	O
on	O
research	O
and	O
development	O
in	O
informaion	O
retrieval	O
,	O
pp	O
.	O
50–57	O
,	O
berkeley	O
,	O
ca	O
.	O
references	B
841	O
hogg	O
,	O
d.	O
(	O
1983	O
)	O
.	O
model-based	B
vision	O
:	O
a	O
program	O
to	O
see	O
a	O
walking	O
person	O
.	O
image	B
and	O
vision	O
computing	O
,	O
1	O
(	O
1	O
)	O
:5–20	O
.	O
hoiem	O
,	O
d.	O
,	O
efros	O
,	O
a.	O
a.	O
,	O
and	O
hebert	O
,	O
m.	O
(	O
2005a	O
)	O
.	O
automatic	B
photo	O
pop-up	O
.	O
acm	O
transac-	O
tions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:577–584	O
.	O
hoiem	O
,	O
d.	O
,	O
efros	O
,	O
a.	O
a.	O
,	O
and	O
hebert	O
,	O
m.	O
(	O
2005b	O
)	O
.	O
geometric	B
context	O
from	O
a	O
single	O
im-	O
age	O
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
654–661	O
,	O
beijing	O
,	O
china	O
.	O
hoiem	O
,	O
d.	O
,	O
efros	O
,	O
a.	O
a.	O
,	O
and	O
hebert	O
,	O
m.	O
(	O
2008a	O
)	O
.	O
closing	B
the	O
loop	O
in	O
scene	O
interpretation	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
hoiem	O
,	O
d.	O
,	O
efros	O
,	O
a.	O
a.	O
,	O
and	O
hebert	O
,	O
m.	O
(	O
2008b	O
)	O
.	O
putting	O
objects	O
in	O
perspective	B
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
80	O
(	O
1	O
)	O
:3–15	O
.	O
hoiem	O
,	O
d.	O
,	O
rother	O
,	O
c.	O
,	O
and	O
winn	O
,	O
j	O
.	O
(	O
2007	O
)	O
.	O
3d	O
layoutcrf	O
for	O
multi-view	O
object	O
class	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
recognition	B
and	O
segmentation	B
.	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
hoover	O
,	O
a.	O
,	O
jean-baptiste	O
,	O
g.	O
,	O
jiang	O
,	O
x.	O
,	O
flynn	O
,	O
p.	O
j.	O
,	O
bunke	O
,	O
h.	O
et	O
al	O
.	O
(	O
1996	O
)	O
.	O
an	O
exper-	O
ieee	O
transactions	O
on	O
imental	O
comparison	O
of	O
range	O
image	O
segmentation	B
algorithms	O
.	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
18	O
(	O
7	O
)	O
:673–689	O
.	O
hoppe	O
,	O
h.	O
(	O
1996	O
)	O
.	O
progressive	O
meshes	O
.	O
in	O
acm	O
siggraph	O
1996	O
conference	O
proceed-	O
ings	O
,	O
pp	O
.	O
99–108	O
,	O
new	O
orleans	O
.	O
hoppe	O
,	O
h.	O
,	O
derose	O
,	O
t.	O
,	O
duchamp	O
,	O
t.	O
,	O
mcdonald	O
,	O
j.	O
,	O
and	O
stuetzle	O
,	O
w.	O
(	O
1992	O
)	O
.	O
sur-	O
face	B
reconstruction	O
from	O
unorganized	O
points	B
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
92	O
)	O
,	O
26	O
(	O
2	O
)	O
:71–78	O
.	O
horn	O
,	O
b.	O
k.	O
p.	O
(	O
1974	O
)	O
.	O
determining	O
lightness	O
from	O
an	O
image	B
.	O
computer	O
graphics	O
and	O
image	B
processing	O
,	O
3	O
(	O
1	O
)	O
:277–299	O
.	O
horn	O
,	O
b.	O
k.	O
p.	O
(	O
1975	O
)	O
.	O
obtaining	O
shape	O
from	O
shading	B
information	O
.	O
in	O
winston	O
,	O
p.	O
h	O
.	O
(	O
ed	O
.	O
)	O
,	O
the	O
psychology	O
of	O
computer	O
vision	O
,	O
pp	O
.	O
115–155	O
,	O
mcgraw-hill	O
,	O
new	O
york	O
.	O
horn	O
,	O
b.	O
k.	O
p.	O
(	O
1977	O
)	O
.	O
understanding	O
image	B
intensities	O
.	O
artiﬁcial	O
intelligence	O
,	O
8	O
(	O
2	O
)	O
:201–	O
231.	O
horn	O
,	O
b.	O
k.	O
p.	O
(	O
1986	O
)	O
.	O
robot	O
vision	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
horn	O
,	O
b.	O
k.	O
p.	O
(	O
1987	O
)	O
.	O
closed-form	O
solution	O
of	O
absolute	B
orientation	I
using	O
unit	O
quaternions	B
.	O
journal	O
of	O
the	O
optical	O
society	O
of	O
america	O
a	O
,	O
4	O
(	O
4	O
)	O
:629–642	O
.	O
horn	O
,	O
b.	O
k.	O
p.	O
(	O
1990	O
)	O
.	O
height	O
and	O
gradient	O
from	O
shading	B
.	O
international	O
journal	O
of	O
com-	O
puter	O
vision	O
,	O
5	O
(	O
1	O
)	O
:37–75	O
.	O
842	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
horn	O
,	O
b.	O
k.	O
p.	O
and	O
brooks	O
,	O
m.	O
j	O
.	O
(	O
1986	O
)	O
.	O
the	O
variational	O
approach	O
to	O
shape	O
from	O
shading	B
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
33:174–208	O
.	O
horn	O
,	O
b.	O
k.	O
p.	O
and	O
brooks	O
,	O
m.	O
j	O
.	O
(	O
eds	O
)	O
.	O
(	O
1989	O
)	O
.	O
shape	O
from	O
shading	B
,	O
mit	O
press	O
,	O
cam-	O
bridge	O
,	O
massachusetts	O
.	O
horn	O
,	O
b.	O
k.	O
p.	O
and	O
schunck	O
,	O
b.	O
g.	O
(	O
1981	O
)	O
.	O
determining	O
optical	B
ﬂow	I
.	O
artiﬁcial	O
intelligence	O
,	O
17:185–203	O
.	O
horn	O
,	O
b.	O
k.	O
p.	O
and	O
weldon	O
jr.	O
,	O
e.	O
j	O
.	O
(	O
1988	O
)	O
.	O
direct	B
methods	O
for	O
recovering	O
motion	B
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
2	O
(	O
1	O
)	O
:51–76	O
.	O
hornung	O
,	O
a.	O
,	O
zeng	O
,	O
b.	O
,	O
and	O
kobbelt	O
,	O
l.	O
image	B
selection	O
for	O
improved	O
multi-	O
view	O
stereo	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
(	O
2008	O
)	O
.	O
horowitz	O
,	O
s.	O
l.	O
and	O
pavlidis	O
,	O
t.	O
(	O
1976	O
)	O
.	O
picture	O
segmentation	B
by	O
a	O
tree	O
traversal	O
algorithm	B
.	O
journal	O
of	O
the	O
acm	O
,	O
23	O
(	O
2	O
)	O
:368–388	O
.	O
horry	O
,	O
y.	O
,	O
anjyo	O
,	O
k.-i.	O
,	O
and	O
arai	O
,	O
k.	O
(	O
1997	O
)	O
.	O
tour	O
into	O
the	O
picture	O
:	O
using	O
a	O
spidery	O
mesh	O
interface	O
to	O
make	O
animation	O
from	O
a	O
single	O
image	O
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
225–232	O
.	O
hough	O
,	O
p.	O
v.	O
c.	O
(	O
1962	O
)	O
.	O
method	O
and	O
means	O
for	O
recognizing	O
complex	O
patterns	B
.	O
u.	O
s.	O
patent	O
,	O
3,069,654.	O
houhou	O
,	O
n.	O
,	O
thiran	O
,	O
j.-p.	O
,	O
and	O
bresson	O
,	O
x	O
.	O
(	O
2008	O
)	O
.	O
fast	O
texture	O
segmentation	B
using	O
the	O
shape	O
operator	O
and	O
active	O
contour	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
howe	O
,	O
n.	O
r.	O
,	O
leventon	O
,	O
m.	O
e.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2000	O
)	O
.	O
bayesian	O
reconstruction	O
of	O
3d	O
human	B
motion	I
from	O
single-camera	O
video	B
.	O
in	O
advances	O
in	O
neural	O
information	O
process-	O
ing	O
systems	O
.	O
hsieh	O
,	O
y.	O
c.	O
,	O
mckeown	O
,	O
d.	O
,	O
and	O
perlant	O
,	O
f.	O
p.	O
(	O
1992	O
)	O
.	O
performance	O
evaluation	O
of	O
scene	O
registration	O
and	O
stereo	B
matching	I
for	O
cartographic	O
feature	B
extraction	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
14	O
(	O
2	O
)	O
:214–238	O
.	O
hu	O
,	O
w.	O
,	O
tan	O
,	O
t.	O
,	O
wang	O
,	O
l.	O
,	O
and	O
maybank	O
,	O
s.	O
(	O
2004	O
)	O
.	O
a	O
survey	O
on	O
visual	O
surveillance	O
of	O
object	O
motion	B
and	O
behaviors	O
.	O
ieee	O
transactions	O
on	O
systems	O
,	O
man	O
,	O
and	O
cybernetics	O
,	O
part	O
c	O
:	O
applications	O
and	O
reviews	O
,	O
34	O
(	O
3	O
)	O
:334–352	O
.	O
hua	O
,	O
g.	O
,	O
brown	O
,	O
m.	O
,	O
and	O
winder	O
,	O
s.	O
(	O
2007	O
)	O
.	O
discriminant	O
embedding	O
for	O
local	O
image	B
descriptors	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
references	B
843	O
huang	O
,	O
g.	O
b.	O
,	O
ramesh	O
,	O
m.	O
,	O
berg	O
,	O
t.	O
,	O
and	O
learned-miller	O
,	O
e.	O
(	O
2007	O
)	O
.	O
labeled	O
faces	B
in	O
the	O
wild	O
:	O
a	O
database	O
for	O
studying	O
face	B
recognition	O
in	O
unconstrained	O
environments	O
.	O
technical	O
report	O
07-49	O
,	O
university	O
of	O
massachusetts	O
,	O
amherst	O
.	O
huang	O
,	O
t.	O
s.	O
(	O
1981	O
)	O
.	O
image	B
sequence	O
analysis	O
.	O
springer-verlag	O
,	O
berlin	O
,	O
heidelberg	O
.	O
huber	O
,	O
p.	O
j	O
.	O
(	O
1981	O
)	O
.	O
robust	B
statistics	O
.	O
john	O
wiley	O
&	O
sons	O
,	O
new	O
york	O
.	O
huffman	O
,	O
d.	O
a	O
.	O
(	O
1971	O
)	O
.	O
impossible	O
objects	O
and	O
nonsense	O
sentences	O
.	O
machine	O
intelligence	O
,	O
8:295–323	O
.	O
huguet	O
,	O
f.	O
and	O
devernay	O
,	O
f.	O
(	O
2007	O
)	O
.	O
a	O
variational	O
method	O
for	O
scene	O
ﬂow	O
estimation	B
from	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
stereo	B
sequences	O
.	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
huttenlocher	O
,	O
d.	O
p.	O
,	O
klanderman	O
,	O
g.	O
,	O
and	O
rucklidge	O
,	O
w.	O
(	O
1993	O
)	O
.	O
comparing	O
images	O
using	O
the	O
hausdorff	O
distance	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelli-	O
gence	O
,	O
15	O
(	O
9	O
)	O
:850–863	O
.	O
huynh	O
,	O
d.	O
q.	O
,	O
hartley	O
,	O
r.	O
,	O
and	O
heyden	O
,	O
a	O
.	O
(	O
2003	O
)	O
.	O
outlier	O
correcton	O
in	O
image	B
sequences	O
for	O
the	O
afﬁne	B
camera	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
585–590	O
,	O
nice	O
,	O
france	O
.	O
iddan	O
,	O
g.	O
j.	O
and	O
yahav	O
,	O
g.	O
(	O
2001	O
)	O
.	O
3d	O
imaging	O
in	O
the	O
studio	O
(	O
and	O
elsewhere	O
...	O
)	O
.	O
in	O
three-	O
dimensional	O
image	B
capture	O
and	O
applications	O
iv	O
,	O
pp	O
.	O
48–55	O
.	O
igarashi	O
,	O
t.	O
,	O
nishino	O
,	O
k.	O
,	O
and	O
nayar	O
,	O
s.	O
(	O
2007	O
)	O
.	O
the	O
appearance	O
of	O
human	O
skin	O
:	O
a	O
survey	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
3	O
(	O
1	O
)	O
:1–95	O
.	O
ikeuchi	O
,	O
k.	O
(	O
1981	O
)	O
.	O
shape	O
from	O
regular	O
patterns	B
.	O
artiﬁcial	O
intelligence	O
,	O
22	O
(	O
1	O
)	O
:49–75	O
.	O
ikeuchi	O
,	O
k.	O
and	O
horn	O
,	O
b.	O
k.	O
p.	O
(	O
1981	O
)	O
.	O
numerical	O
shape	O
from	O
shading	B
and	O
occluding	O
boundaries	O
.	O
artiﬁcial	O
intelligence	O
,	O
17:141–184	O
.	O
ikeuchi	O
,	O
k.	O
and	O
miyazaki	O
,	O
d.	O
(	O
eds	O
)	O
.	O
(	O
2007	O
)	O
.	O
digitally	O
archiving	O
cultural	O
objects	O
,	O
springer	O
,	O
boston	O
,	O
ma	O
.	O
ikeuchi	O
,	O
k.	O
and	O
sato	O
,	O
y	O
.	O
(	O
eds	O
)	O
.	O
(	O
2001	O
)	O
.	O
modeling	B
from	O
reality	O
,	O
kluwer	O
academic	O
publish-	O
ers	O
,	O
boston	O
.	O
illingworth	O
,	O
j.	O
and	O
kittler	O
,	O
j	O
.	O
(	O
1988	O
)	O
.	O
a	O
survey	O
of	O
the	O
hough	O
transform	B
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
44:87–116	O
.	O
intille	O
,	O
s.	O
s.	O
and	O
bobick	O
,	O
a.	O
f.	O
(	O
1994	O
)	O
.	O
disparity-space	O
images	O
and	O
large	O
occlusion	O
stereo	B
.	O
in	O
third	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
94	O
)	O
,	O
stockholm	O
,	O
sweden	O
.	O
irani	O
,	O
m.	O
and	O
anandan	O
,	O
p.	O
(	O
1998	O
)	O
.	O
video	B
indexing	O
based	O
on	O
mosaic	O
representations	O
.	O
pro-	O
ceedings	O
of	O
the	O
ieee	O
,	O
86	O
(	O
5	O
)	O
:905–921	O
.	O
844	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
irani	O
,	O
m.	O
and	O
peleg	O
,	O
s.	O
(	O
1991	O
)	O
.	O
improving	O
resolution	O
by	O
image	O
registration	B
.	O
graphical	O
models	O
and	O
image	B
processing	O
,	O
53	O
(	O
3	O
)	O
:231–239	O
.	O
irani	O
,	O
m.	O
,	O
hsu	O
,	O
s.	O
,	O
and	O
anandan	O
,	O
p.	O
(	O
1995	O
)	O
.	O
video	B
compression	I
using	O
mosaic	O
representa-	O
tions	O
.	O
signal	O
processing	O
:	O
image	B
communication	O
,	O
7:529–552	O
.	O
irani	O
,	O
m.	O
,	O
rousso	O
,	O
b.	O
,	O
and	O
peleg	O
,	O
s.	O
(	O
1994	O
)	O
.	O
computing	O
occluding	O
and	O
transparent	B
motions	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
12	O
(	O
1	O
)	O
:5–16	O
.	O
irani	O
,	O
m.	O
,	O
rousso	O
,	O
b.	O
,	O
and	O
peleg	O
,	O
s.	O
(	O
1997	O
)	O
.	O
recovery	B
of	O
ego-motion	O
using	O
image	O
stabiliza-	O
tion	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
3	O
)	O
:268–272	O
.	O
isaksen	O
,	O
a.	O
,	O
mcmillan	O
,	O
l.	O
,	O
and	O
gortler	O
,	O
s.	O
j	O
.	O
(	O
2000	O
)	O
.	O
dynamically	O
reparameterized	O
light	O
ﬁelds	O
.	O
in	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
297–306	O
.	O
isard	O
,	O
m.	O
and	O
blake	O
,	O
a	O
.	O
(	O
1998	O
)	O
.	O
condensation—conditional	O
density	O
propagation	O
for	O
visual	O
tracking	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
29	O
(	O
1	O
)	O
:5–28	O
.	O
ishiguro	O
,	O
h.	O
,	O
yamamoto	O
,	O
m.	O
,	O
and	O
tsuji	O
,	O
s.	O
(	O
1992	O
)	O
.	O
omni-directional	O
stereo	B
.	O
ieee	O
trans-	O
actions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
14	O
(	O
2	O
)	O
:257–262	O
.	O
ishikawa	O
,	O
h.	O
(	O
2003	O
)	O
.	O
exact	O
optimization	O
for	O
markov	O
random	O
ﬁelds	O
with	O
convex	O
priors	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
25	O
(	O
10	O
)	O
:1333–1336	O
.	O
ishikawa	O
,	O
h.	O
and	O
veksler	O
,	O
o	O
.	O
(	O
2010	O
)	O
.	O
convex	O
and	O
truncated	O
convex	O
priors	O
for	O
multi-label	O
in	O
blake	O
,	O
a.	O
,	O
kohli	O
,	O
p.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
eds	O
)	O
,	O
advances	O
in	O
markov	O
random	O
mrfs	O
.	O
fields	O
,	O
mit	O
press	O
.	O
isidoro	O
,	O
j.	O
and	O
sclaroff	O
,	O
s.	O
(	O
2003	O
)	O
.	O
stochastic	O
reﬁnement	O
of	O
the	O
visual	B
hull	I
to	O
satisfy	O
pho-	O
tometric	O
and	O
silhouette	O
consistency	O
constraints	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
1335–1342	O
,	O
nice	O
,	O
france	O
.	O
ivanchenko	O
,	O
v.	O
,	O
shen	O
,	O
h.	O
,	O
and	O
coughlan	O
,	O
j	O
.	O
(	O
2009	O
)	O
.	O
elevation-based	O
stereo	B
implemented	O
in	O
real-time	O
on	O
a	O
gpu	O
.	O
in	O
ieee	O
workshop	O
on	O
applications	O
of	O
computer	O
vision	O
(	O
wacv	O
2009	O
)	O
,	O
snowbird	O
,	O
utah	O
.	O
jacobs	O
,	O
c.	O
e.	O
,	O
finkelstein	O
,	O
a.	O
,	O
and	O
salesin	O
,	O
d.	O
h.	O
(	O
1995	O
)	O
.	O
fast	O
multiresolution	O
image	B
querying	O
.	O
in	O
acm	O
siggraph	O
1995	O
conference	O
proceedings	O
,	O
pp	O
.	O
277–286	O
.	O
j¨ahne	O
,	O
b	O
.	O
(	O
1997	O
)	O
.	O
digital	O
image	O
processing	O
.	O
springer-verlag	O
,	O
berlin	O
.	O
jain	O
,	O
a.	O
k.	O
and	O
dubes	O
,	O
r.	O
c.	O
(	O
1988	O
)	O
.	O
algorithms	O
for	O
clustering	O
data	O
.	O
prentice	O
hall	O
,	O
englewood	O
cliffs	O
,	O
new	O
jersey	O
.	O
jain	O
,	O
a.	O
k.	O
,	O
bolle	O
,	O
r.	O
m.	O
,	O
and	O
pankanti	O
,	O
s.	O
(	O
eds	O
)	O
.	O
(	O
1999	O
)	O
.	O
biometrics	B
:	O
personal	O
identiﬁca-	O
tion	B
in	O
networked	O
society	O
,	O
kluwer	O
.	O
jain	O
,	O
a.	O
k.	O
,	O
duin	O
,	O
r.	O
p.	O
w.	O
,	O
and	O
mao	O
,	O
j	O
.	O
(	O
2000	O
)	O
.	O
statistical	O
pattern	O
recognition	B
:	O
a	O
review	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
22	O
(	O
1	O
)	O
:4–37	O
.	O
references	B
845	O
jain	O
,	O
a.	O
k.	O
,	O
topchy	O
,	O
a.	O
,	O
law	O
,	O
m.	O
h.	O
c.	O
,	O
and	O
buhmann	O
,	O
j.	O
m.	O
(	O
2004	O
)	O
.	O
landscape	O
of	O
clus-	O
in	O
international	O
conference	O
on	O
pattern	O
recognition	B
(	O
icpr	O
2004	O
)	O
,	O
tering	O
algorithms	O
.	O
pp	O
.	O
260–263	O
.	O
jenkin	O
,	O
m.	O
r.	O
m.	O
,	O
jepson	O
,	O
a.	O
d.	O
,	O
and	O
tsotsos	O
,	O
j.	O
k.	O
(	O
1991	O
)	O
.	O
techniques	O
for	O
disparity	O
measurement	O
.	O
cvgip	O
:	O
image	B
understanding	O
,	O
53	O
(	O
1	O
)	O
:14–30	O
.	O
jensen	O
,	O
h.	O
w.	O
,	O
marschner	O
,	O
s.	O
r.	O
,	O
levoy	O
,	O
m.	O
,	O
and	O
hanrahan	O
,	O
p.	O
(	O
2001	O
)	O
.	O
a	O
practical	O
model	O
for	O
subsurface	O
light	O
transport	O
.	O
in	O
acm	O
siggraph	O
2001	O
conference	O
proceedings	O
,	O
pp	O
.	O
511–	O
518.	O
jeong	O
,	O
y.	O
,	O
nist´er	O
,	O
d.	O
,	O
steedly	O
,	O
d.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
kweon	O
,	O
i.-s.	O
(	O
2010	O
)	O
.	O
pushing	O
the	O
enve-	O
lope	O
of	O
modern	O
methods	O
for	O
bundle	O
adjustment	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2010	O
)	O
,	O
san	O
francisco	O
,	O
ca	O
.	O
jia	O
,	O
j.	O
and	O
tang	O
,	O
c.-k.	O
(	O
2003	O
)	O
.	O
image	B
registration	I
with	O
global	B
and	I
local	I
luminance	O
align-	O
ment	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
156–	O
163	O
,	O
nice	O
,	O
france	O
.	O
jia	O
,	O
j.	O
,	O
sun	O
,	O
j.	O
,	O
tang	O
,	O
c.-k.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2006	O
)	O
.	O
drag-and-drop	O
pasting	O
.	O
acm	O
trans-	O
actions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:631–636	O
.	O
jiang	O
,	O
z.	O
,	O
wong	O
,	O
t.-t.	O
,	O
and	O
bao	O
,	O
h.	O
(	O
2003	O
)	O
.	O
practical	O
super-resolution	O
from	O
dynamic	B
video	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
sequences	O
.	O
recognition	B
(	O
cvpr	O
’	O
2003	O
)	O
,	O
pp	O
.	O
549–554	O
,	O
madison	O
,	O
wi	O
.	O
johnson	O
,	O
a.	O
e.	O
and	O
hebert	O
,	O
m.	O
(	O
1999	O
)	O
.	O
using	O
spin	O
images	O
for	O
efﬁcient	O
object	O
recognition	B
in	O
cluttered	O
3d	O
scenes	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
21	O
(	O
5	O
)	O
:433–448	O
.	O
johnson	O
,	O
a.	O
e.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
1997	O
)	O
.	O
registration	B
and	O
integration	O
of	O
textured	O
3-d	O
data	O
.	O
in	O
international	O
conference	O
on	O
recent	O
advances	O
in	O
3-d	O
digital	O
imaging	O
and	O
modeling	B
,	O
pp	O
.	O
234–241	O
,	O
ottawa	O
.	O
jojic	O
,	O
n.	O
and	O
frey	O
,	O
b.	O
j	O
.	O
(	O
2001	O
)	O
.	O
learning	B
ﬂexible	O
sprites	B
in	O
video	B
layers	O
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2001	O
)	O
,	O
pp	O
.	O
199–206	O
,	O
kauai	O
,	O
hawaii	O
.	O
jones	O
,	O
d.	O
g.	O
and	O
malik	O
,	O
j	O
.	O
(	O
1992	O
)	O
.	O
a	O
computational	O
framework	O
for	O
determining	O
stereo	B
correspondence	O
from	O
a	O
set	O
of	O
linear	B
spatial	O
ﬁlters	O
.	O
in	O
second	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
92	O
)	O
,	O
pp	O
.	O
397–410	O
,	O
santa	O
margherita	O
liguere	O
,	O
italy	O
.	O
jones	O
,	O
m.	O
j.	O
and	O
rehg	O
,	O
j.	O
m.	O
(	O
2001	O
)	O
.	O
statistical	O
color	B
models	O
with	O
application	O
to	O
skin	O
detection	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
46	O
(	O
1	O
)	O
:81–96	O
.	O
joshi	O
,	O
n.	O
,	O
matusik	O
,	O
w.	O
,	O
and	O
avidan	O
,	O
s.	O
(	O
2006	O
)	O
.	O
natural	B
video	O
matting	B
using	O
camera	B
arrays	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:779–786	O
.	O
846	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
joshi	O
,	O
n.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
kriegman	O
,	O
d.	O
j	O
.	O
(	O
2008	O
)	O
.	O
psf	O
estimation	B
using	O
sharp	O
edge	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
prediction	O
.	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
joshi	O
,	O
n.	O
,	O
zitnick	O
,	O
c.	O
l.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
kriegman	O
,	O
d.	O
j.	O
image	B
deblurring	O
and	O
denoising	O
using	O
color	O
priors	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
,	O
fl	O
.	O
(	O
2009	O
)	O
.	O
ju	O
,	O
s.	O
x.	O
,	O
black	O
,	O
m.	O
j.	O
,	O
and	O
jepson	O
,	O
a.	O
d.	O
(	O
1996	O
)	O
.	O
skin	O
and	O
bones	O
:	O
multi-layer	O
,	O
locally	O
in	O
ieee	O
computer	O
society	O
afﬁne	B
,	O
optical	B
ﬂow	I
and	O
regularization	B
with	O
transparency	B
.	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
96	O
)	O
,	O
pp	O
.	O
307–314	O
,	O
san	O
francisco	O
.	O
ju	O
,	O
s.	O
x.	O
,	O
black	O
,	O
m.	O
j.	O
,	O
and	O
yacoob	O
,	O
y	O
.	O
(	O
1996	O
)	O
.	O
cardboard	O
people	O
:	O
a	O
parameterized	O
model	O
of	O
articulated	O
image	B
motion	O
.	O
in	O
2nd	O
international	O
conference	O
on	O
automatic	B
face	O
and	O
gesture	O
recognition	B
,	O
pp	O
.	O
38–44	O
,	O
killington	O
,	O
vt.	O
juan	O
,	O
o.	O
and	O
boykov	O
,	O
y	O
.	O
(	O
2006	O
)	O
.	O
active	O
graph	O
cuts	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
1023–1029	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
jurie	O
,	O
f.	O
and	O
dhome	O
,	O
m.	O
(	O
2002	O
)	O
.	O
hyperplane	O
approximation	O
for	O
template	O
matching	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
7	O
)	O
:996–1000	O
.	O
jurie	O
,	O
f.	O
and	O
schmid	O
,	O
c.	O
(	O
2004	O
)	O
.	O
scale-invariant	O
shape	O
features	O
for	B
recognition	I
of	O
object	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
categories	O
.	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
90–96	O
,	O
washington	O
,	O
dc	O
.	O
kadir	O
,	O
t.	O
,	O
zisserman	O
,	O
a.	O
,	O
and	O
brady	O
,	O
m.	O
(	O
2004	O
)	O
.	O
an	O
afﬁne	B
invariant	O
salient	O
region	B
detec-	O
tor	O
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
228–241	O
,	O
prague	O
.	O
kaftory	O
,	O
r.	O
,	O
schechner	O
,	O
y.	O
,	O
and	O
zeevi	O
,	O
y	O
.	O
(	O
2007	O
)	O
.	O
variational	O
distance-dependent	O
image	B
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
restoration	O
.	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
kahl	O
,	O
f.	O
and	O
hartley	O
,	O
r.	O
(	O
2008	O
)	O
.	O
multiple-view	O
geometry	O
under	O
the	O
l∞-norm	O
.	O
ieee	O
trans-	O
actions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
30	O
(	O
11	O
)	O
:1603–1617	O
.	O
kakadiaris	O
,	O
i.	O
and	O
metaxas	O
,	O
d.	O
(	O
2000	O
)	O
.	O
model-based	B
estimation	O
of	O
3d	O
human	B
motion	I
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
22	O
(	O
12	O
)	O
:1453–1459	O
.	O
kakumanu	O
,	O
p.	O
,	O
makrogiannis	O
,	O
s.	O
,	O
and	O
bourbakis	O
,	O
n.	O
(	O
2007	O
)	O
.	O
a	O
survey	O
of	O
skin-color	O
model-	O
ing	O
and	O
detection	B
methods	O
.	O
pattern	O
recognition	B
,	O
40	O
(	O
3	O
)	O
:1106–1122	O
.	O
kamvar	O
,	O
s.	O
d.	O
,	O
klein	O
,	O
d.	O
,	O
and	O
manning	O
,	O
c.	O
d.	O
(	O
2002	O
)	O
.	O
interpreting	O
and	O
extending	O
classical	O
in	O
international	O
agglomerative	B
clustering	O
algorithms	O
using	O
a	O
model-based	B
approach	O
.	O
references	B
847	O
conference	O
on	O
machine	O
learning	O
,	O
pp	O
.	O
283–290	O
.	O
kanade	O
,	O
t.	O
(	O
1977	O
)	O
.	O
computer	O
recognition	B
of	O
human	O
faces	O
.	O
birkhauser	O
,	O
basel	O
.	O
kanade	O
,	O
t.	O
(	O
1980	O
)	O
.	O
a	O
theory	O
of	O
the	O
origami	O
world	O
.	O
artiﬁcial	O
intelligence	O
,	O
13:279–311	O
.	O
kanade	O
,	O
t	O
.	O
(	O
ed.	O
)	O
.	O
(	O
1987	O
)	O
.	O
three-dimensional	O
machine	O
vision	O
,	O
kluwer	O
academic	O
publish-	O
ers	O
,	O
boston	O
.	O
kanade	O
,	O
t.	O
(	O
1994	O
)	O
.	O
development	O
of	O
a	O
video-rate	O
stereo	B
machine	O
.	O
in	O
image	B
understanding	O
workshop	O
,	O
pp	O
.	O
549–557	O
,	O
monterey	O
.	O
kanade	O
,	O
t.	O
and	O
okutomi	O
,	O
m.	O
(	O
1994	O
)	O
.	O
a	O
stereo	B
matching	I
algorithm	O
with	O
an	O
adaptive	B
win-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
dow	O
:	O
theory	O
and	O
experiment	O
.	O
intelligence	O
,	O
16	O
(	O
9	O
)	O
:920–932	O
.	O
kanade	O
,	O
t.	O
,	O
rander	O
,	O
p.	O
w.	O
,	O
and	O
narayanan	O
,	O
p.	O
j	O
.	O
(	O
1997	O
)	O
.	O
virtualized	O
reality	O
:	O
constructing	O
virtual	O
worlds	O
from	O
real	O
scenes	O
.	O
ieee	O
multimedia	O
magazine	O
,	O
4	O
(	O
1	O
)	O
:34–47	O
.	O
kanade	O
,	O
t.	O
,	O
yoshida	O
,	O
a.	O
,	O
oda	O
,	O
k.	O
,	O
kano	O
,	O
h.	O
,	O
and	O
tanaka	O
,	O
m.	O
(	O
1996	O
)	O
.	O
a	O
stereo	B
machine	O
for	O
video-rate	O
dense	O
depth	O
mapping	O
and	O
its	O
new	O
applications	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
96	O
)	O
,	O
pp	O
.	O
196–202	O
,	O
san	O
francisco	O
.	O
kanatani	O
,	O
k.	O
and	O
morris	O
,	O
d.	O
d.	O
(	O
2001	O
)	O
.	O
gauges	O
and	O
gauge	O
transformations	O
for	O
uncertainty	O
description	O
of	O
geometric	B
structure	O
with	O
indeterminacy	O
.	O
ieee	O
transactions	O
on	O
informa-	O
tion	B
theory	O
,	O
47	O
(	O
5	O
)	O
:2017–2028	O
.	O
kang	O
,	O
s.	O
b	O
.	O
(	O
1998	O
)	O
.	O
depth	O
painting	O
for	O
image-based	O
rendering	B
applications	O
.	O
technical	O
report	O
,	O
compaq	O
computer	O
corporation	O
,	O
cambridge	O
research	O
lab	O
.	O
kang	O
,	O
s.	O
b	O
.	O
(	O
1999	O
)	O
.	O
a	O
survey	O
of	O
image-based	B
rendering	I
techniques	O
.	O
in	O
videometrics	O
vi	O
,	O
pp	O
.	O
2–16	O
,	O
san	O
jose	O
.	O
kang	O
,	O
s.	O
b	O
.	O
(	O
2001	O
)	O
.	O
radial	B
distortion	I
snakes	O
.	O
ieice	O
trans	O
.	O
inf	O
.	O
&	O
syst.	O
,	O
e84-d	O
(	O
12	O
)	O
:1603–	O
1611.	O
kang	O
,	O
s.	O
b.	O
and	O
jones	O
,	O
m.	O
(	O
2002	O
)	O
.	O
appearance-based	O
structure	B
from	I
motion	I
using	O
linear	B
classes	O
of	O
3-d	O
models	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
49	O
(	O
1	O
)	O
:5–22	O
.	O
kang	O
,	O
s.	O
b.	O
and	O
szeliski	O
,	O
r.	O
(	O
1997	O
)	O
.	O
3-d	O
scene	O
data	O
recovery	B
using	O
omnidirectional	O
multi-	O
baseline	O
stereo	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
25	O
(	O
2	O
)	O
:167–183	O
.	O
kang	O
,	O
s.	O
b.	O
and	O
szeliski	O
,	O
r.	O
(	O
2004	O
)	O
.	O
extracting	O
view-dependent	B
depth	O
maps	O
from	O
a	O
collec-	O
tion	B
of	O
images	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
58	O
(	O
2	O
)	O
:139–163	O
.	O
kang	O
,	O
s.	O
b.	O
and	O
weiss	O
,	O
r.	O
(	O
1997	O
)	O
.	O
characterization	O
of	O
errors	O
in	O
compositing	B
panoramic	O
images	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recog-	O
nition	O
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
103–109	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
848	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
kang	O
,	O
s.	O
b.	O
and	O
weiss	O
,	O
r.	O
(	O
1999	O
)	O
.	O
characterization	O
of	O
errors	O
in	O
compositing	B
panoramic	O
images	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
73	O
(	O
2	O
)	O
:269–280	O
.	O
kang	O
,	O
s.	O
b.	O
and	O
weiss	O
,	O
r.	O
(	O
2000	O
)	O
.	O
can	O
we	O
calibrate	O
a	O
camera	B
using	O
an	O
image	B
of	O
a	O
ﬂat	O
,	O
in	O
sixth	O
european	O
conference	O
on	O
computer	O
vision	O
textureless	O
lambertian	O
surface	B
?	O
(	O
eccv	O
2000	O
)	O
,	O
pp	O
.	O
640–653	O
,	O
dublin	O
,	O
ireland	O
.	O
kang	O
,	O
s.	O
b.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
anandan	O
,	O
p.	O
(	O
2000	O
)	O
.	O
the	O
geometry-image	O
representation	O
tradeoff	O
for	O
rendering	O
.	O
in	O
international	O
conference	O
on	O
image	B
processing	O
(	O
icip-2000	O
)	O
,	O
pp	O
.	O
13–16	O
,	O
vancouver	O
.	O
kang	O
,	O
s.	O
b.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
chai	O
,	O
j	O
.	O
(	O
2001	O
)	O
.	O
handling	O
occlusions	O
in	O
dense	O
multi-view	O
stereo	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recog-	O
nition	O
(	O
cvpr	O
’	O
2001	O
)	O
,	O
pp	O
.	O
103–110	O
,	O
kauai	O
,	O
hawaii	O
.	O
kang	O
,	O
s.	O
b.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
1997	O
)	O
.	O
a	O
parallel	O
feature	B
tracker	O
for	O
extended	O
image	B
sequences	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
67	O
(	O
3	O
)	O
:296–310	O
.	O
kang	O
,	O
s.	O
b.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
uyttendaele	O
,	O
m.	O
(	O
2004	O
)	O
.	O
seamless	O
stitching	O
using	O
multi-	O
perspective	B
plane	O
sweep	O
.	O
technical	O
report	O
msr-tr-2004-48	O
,	O
microsoft	O
research	O
.	O
kang	O
,	O
s.	O
b.	O
,	O
li	O
,	O
y.	O
,	O
tong	O
,	O
x.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2006	O
)	O
.	O
image-based	B
rendering	I
.	O
founda-	O
tions	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
2	O
(	O
3	O
)	O
:173–258	O
.	O
kang	O
,	O
s.	O
b.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
winder	O
,	O
s.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2003	O
)	O
.	O
high	B
dynamic	I
range	I
video	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2003	O
)	O
,	O
22	O
(	O
3	O
)	O
:319–325	O
.	O
kang	O
,	O
s.	O
b.	O
,	O
webb	O
,	O
j.	O
,	O
zitnick	O
,	O
l.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
1995	O
)	O
.	O
a	O
multibaseline	O
stereo	B
system	O
with	O
active	O
illumination	O
and	O
real-time	O
image	B
acquisition	O
.	O
in	O
fifth	O
international	O
confer-	O
ence	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
95	O
)	O
,	O
pp	O
.	O
88–93	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
kannala	O
,	O
j.	O
,	O
rahtu	O
,	O
e.	O
,	O
brandt	O
,	O
s.	O
s.	O
,	O
and	O
heikkila	O
,	O
j	O
.	O
(	O
2008	O
)	O
.	O
object	O
recognition	B
and	O
seg-	O
mentation	O
by	O
non-rigid	O
quasi-dense	O
matching	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
kass	O
,	O
m.	O
(	O
1988	O
)	O
.	O
linear	B
image	O
features	O
in	O
stereopsis	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
1	O
(	O
4	O
)	O
:357–368	O
.	O
kass	O
,	O
m.	O
,	O
witkin	O
,	O
a.	O
,	O
and	O
terzopoulos	O
,	O
d.	O
(	O
1988	O
)	O
.	O
snakes	B
:	O
active	O
contour	O
models	O
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
1	O
(	O
4	O
)	O
:321–331	O
.	O
kato	O
,	O
h.	O
,	O
billinghurst	O
,	O
m.	O
,	O
poupyrev	O
,	O
i.	O
,	O
imamoto	O
,	O
k.	O
,	O
and	O
tachibana	O
,	O
k.	O
(	O
2000	O
)	O
.	O
virtual	O
in	O
international	O
symposium	O
on	O
object	O
manipulation	O
on	O
a	O
table-top	O
ar	O
environment	O
.	O
augmented	B
reality	I
(	O
isar	O
2000	O
)	O
.	O
kaufman	O
,	O
l.	O
and	O
rousseeuw	O
,	O
p.	O
j	O
.	O
(	O
1990	O
)	O
.	O
finding	O
groups	O
in	O
data	O
:	O
an	O
introduction	O
to	O
cluster	B
analysis	I
.	O
john	O
wiley	O
&	O
sons	O
,	O
hoboken	O
.	O
references	B
849	O
kazhdan	O
,	O
m.	O
,	O
bolitho	O
,	O
m.	O
,	O
and	O
hoppe	O
,	O
h.	O
(	O
2006	O
)	O
.	O
poisson	O
surface	B
reconstruction	I
.	O
in	O
eurographics	O
symposium	O
on	O
geometry	O
processing	O
,	O
pp	O
.	O
61–70	O
.	O
ke	O
,	O
y.	O
and	O
sukthankar	O
,	O
r.	O
(	O
2004	O
)	O
.	O
pca-sift	O
:	O
a	O
more	O
distinctive	O
representation	O
for	O
local	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
image	B
descriptors	O
.	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
506–513	O
,	O
washington	O
,	O
dc	O
.	O
kehl	O
,	O
r.	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2006	O
)	O
.	O
markerless	O
tracking	O
of	O
complex	O
human	O
motions	O
from	O
multiple	B
views	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-3	O
)	O
:190–209	O
.	O
kenney	O
,	O
c.	O
,	O
zuliani	O
,	O
m.	O
,	O
and	O
manjunath	O
,	O
b	O
.	O
(	O
2005	O
)	O
.	O
an	O
axiomatic	O
approach	O
to	O
corner	O
de-	O
tection	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recog-	O
nition	O
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
191–197	O
,	O
san	O
diego	O
,	O
ca	O
.	O
keren	O
,	O
d.	O
,	O
peleg	O
,	O
s.	O
,	O
and	O
brada	O
,	O
r.	O
(	O
1988	O
)	O
.	O
image	B
sequence	O
enhancement	O
using	O
sub-pixel	O
displacements	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
88	O
)	O
,	O
pp	O
.	O
742–746	O
,	O
ann	O
arbor	O
,	O
michigan	O
.	O
kim	O
,	O
j.	O
,	O
kolmogorov	O
,	O
v.	O
,	O
and	O
zabih	O
,	O
r.	O
(	O
2003	O
)	O
.	O
visual	O
correspondence	O
using	O
energy	O
min-	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
imization	O
and	O
mutual	O
information	O
.	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
1033–1040	O
,	O
nice	O
,	O
france	O
.	O
kimmel	O
,	O
r.	O
(	O
1999	O
)	O
.	O
demosaicing	B
:	O
image	B
reconstruction	O
from	O
color	B
ccd	O
samples	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
8	O
(	O
9	O
)	O
:1221–1228	O
.	O
kimura	O
,	O
s.	O
,	O
shinbo	O
,	O
t.	O
,	O
yamaguchi	O
,	O
h.	O
,	O
kawamura	O
,	O
e.	O
,	O
and	O
nakano	O
,	O
k.	O
(	O
1999	O
)	O
.	O
a	O
convolver-based	O
real-time	O
stereo	B
machine	O
(	O
sazan	O
)	O
.	O
in	O
ieee	O
computer	O
society	O
con-	O
ference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
99	O
)	O
,	O
pp	O
.	O
457–463	O
,	O
fort	O
collins	O
.	O
kindermann	O
,	O
r.	O
and	O
snell	O
,	O
j.	O
l.	O
(	O
1980	O
)	O
.	O
markov	O
random	O
fields	O
and	O
their	O
applications	O
.	O
american	O
mathematical	O
society	O
.	O
king	O
,	O
d.	O
(	O
1997	O
)	O
.	O
the	O
commissar	O
vanishes	O
.	O
henry	O
holt	O
and	O
company	O
.	O
kirby	O
,	O
m.	O
and	O
sirovich	O
,	O
l.	O
(	O
1990	O
)	O
.	O
application	O
of	O
the	O
karhunen–l`oeve	O
procedure	O
for	O
the	O
characterization	O
of	O
human	O
faces	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12	O
(	O
1	O
)	O
:103–108	O
.	O
kirkpatrick	O
,	O
s.	O
,	O
gelatt	O
,	O
c.	O
d.	O
j.	O
,	O
and	O
vecchi	O
,	O
m.	O
p.	O
(	O
1983	O
)	O
.	O
optimization	O
by	O
simulated	O
annealing	O
.	O
science	O
,	O
220:671–680	O
.	O
kirovski	O
,	O
d.	O
,	O
jojic	O
,	O
n.	O
,	O
and	O
jancke	O
,	O
g.	O
(	O
2004	O
)	O
.	O
tamper-resistant	O
biometric	O
ids	O
.	O
in	O
isse	O
2004	O
-	O
securing	O
electronic	O
business	O
processes	O
:	O
highlights	O
of	O
the	O
information	O
security	O
solutions	O
europe	O
2004	O
conference	O
,	O
pp	O
.	O
160–175	O
.	O
kittler	O
,	O
j.	O
and	O
f¨oglein	O
,	O
j	O
.	O
(	O
1984	O
)	O
.	O
contextual	O
classiﬁcation	O
of	O
multispectral	O
pixel	O
data	O
.	O
image	B
and	O
vision	O
computing	O
,	O
2	O
(	O
1	O
)	O
:13–29	O
.	O
850	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
klaus	O
,	O
a.	O
,	O
sormann	O
,	O
m.	O
,	O
and	O
karner	O
,	O
k.	O
(	O
2006	O
)	O
.	O
segment-based	O
stereo	B
matching	I
using	O
be-	O
lief	O
propagation	O
and	O
a	O
self-adapting	O
dissimilarity	O
measure	O
.	O
in	O
international	O
conference	O
on	O
pattern	O
recognition	B
(	O
icpr	O
2006	O
)	O
,	O
pp	O
.	O
15–18	O
.	O
klein	O
,	O
g.	O
and	O
murray	O
,	O
d.	O
(	O
2007	O
)	O
.	O
parallel	O
tracking	O
and	O
mapping	O
for	O
small	O
ar	O
workspaces	O
.	O
in	O
international	O
symposium	O
on	O
mixed	O
and	O
augmented	B
reality	I
(	O
ismar	O
2007	O
)	O
,	O
nara	O
.	O
klein	O
,	O
g.	O
and	O
murray	O
,	O
d.	O
(	O
2008	O
)	O
.	O
improving	O
the	O
agility	O
of	O
keyframe-based	O
slam	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
802–815	O
,	O
marseilles	O
.	O
klein	O
,	O
s.	O
,	O
staring	O
,	O
m.	O
,	O
and	O
pluim	O
,	O
j.	O
p.	O
w.	O
(	O
2007	O
)	O
.	O
evaluation	B
of	O
optimization	O
methods	O
for	O
nonrigid	O
medical	B
image	I
registration	O
using	O
mutual	O
information	O
and	O
b-splines	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
16	O
(	O
12	O
)	O
:2879–2890	O
.	O
klinker	O
,	O
g.	O
j	O
.	O
(	O
1993	O
)	O
.	O
a	O
physical	O
approach	O
to	O
color	B
image	O
understanding	O
.	O
a	O
k	O
peters	O
,	O
wellesley	O
,	O
massachusetts	O
.	O
klinker	O
,	O
g.	O
j.	O
,	O
shafer	O
,	O
s.	O
a.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
1990	O
)	O
.	O
a	O
physical	O
approach	O
to	O
color	B
image	O
understanding	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
4	O
(	O
1	O
)	O
:7–38	O
.	O
koch	O
,	O
r.	O
,	O
pollefeys	O
,	O
m.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
j	O
.	O
(	O
2000	O
)	O
.	O
realistic	O
surface	B
reconstruction	I
of	O
3d	O
scenes	O
from	O
uncalibrated	O
image	B
sequences	O
.	O
journal	O
visualization	O
and	O
computer	O
animation	O
,	O
11:115–127	O
.	O
koenderink	O
,	O
j.	O
j	O
.	O
(	O
1990	O
)	O
.	O
solid	O
shape	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
koethe	O
,	O
u	O
.	O
(	O
2003	O
)	O
.	O
integrated	O
edge	O
and	O
junction	O
detection	B
with	O
the	O
boundary	O
tensor	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
424–431	O
,	O
nice	O
,	O
france	O
.	O
kohli	O
,	O
p.	O
(	O
2007	O
)	O
.	O
minimizing	O
dynamic	B
and	O
higher	O
order	O
energy	O
functions	O
using	O
graph	O
cuts	O
.	O
ph.d.	O
thesis	O
,	O
oxford	O
brookes	O
university	O
.	O
kohli	O
,	O
p.	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2005	O
)	O
.	O
effciently	O
solving	O
dynamic	B
markov	O
random	O
ﬁelds	O
using	O
graph	O
cuts	O
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
922–929	O
,	O
beijing	O
,	O
china	O
.	O
kohli	O
,	O
p.	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2007	O
)	O
.	O
dynamic	B
graph	O
cuts	O
for	O
efﬁcient	O
inference	B
in	O
markov	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
random	O
ﬁelds	O
.	O
29	O
(	O
12	O
)	O
:2079–2088	O
.	O
kohli	O
,	O
p.	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2008	O
)	O
.	O
measuring	O
uncertainty	B
in	O
graph	B
cut	I
solutions	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
112	O
(	O
1	O
)	O
:30–38	O
.	O
kohli	O
,	O
p.	O
,	O
kumar	O
,	O
m.	O
p.	O
,	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2009	O
)	O
.	O
p	O
3	O
&	O
beyond	O
:	O
move	O
making	O
algorithms	O
for	O
solving	O
higher	O
order	O
functions	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
31	O
(	O
9	O
)	O
:1645–1656	O
.	O
references	B
851	O
kohli	O
,	O
p.	O
,	O
ladick´y	O
,	O
l.	O
,	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2009	O
)	O
.	O
robust	B
higher	O
order	B
potentials	O
for	O
enforc-	O
ing	O
label	O
consistency	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
82	O
(	O
3	O
)	O
:302–324	O
.	O
kokaram	O
,	O
a	O
.	O
(	O
2004	O
)	O
.	O
on	O
missing	B
data	I
treatment	O
for	O
degraded	O
video	B
and	O
ﬁlm	O
archives	O
:	O
a	O
sur-	O
vey	O
and	O
a	O
new	O
bayesian	O
approach	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
13	O
(	O
3	O
)	O
:397–	O
415.	O
kolev	O
,	O
k.	O
and	O
cremers	O
,	O
d.	O
integration	O
of	O
multiview	O
stereo	B
and	O
silhouettes	B
via	O
convex	O
functionals	O
on	O
convex	O
domains	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
752–765	O
,	O
marseilles	O
.	O
(	O
2008	O
)	O
.	O
kolev	O
,	O
k.	O
and	O
cremers	O
,	O
d.	O
(	O
2009	O
)	O
.	O
continuous	O
ratio	O
optimization	O
via	O
convex	O
relaxation	O
with	O
applications	O
to	O
multiview	O
3d	O
reconstruction	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
kolev	O
,	O
k.	O
,	O
klodt	O
,	O
m.	O
,	O
brox	O
,	O
t.	O
,	O
and	O
cremers	O
,	O
d.	O
(	O
2009	O
)	O
.	O
continuous	O
global	B
optimization	I
in	O
multiview	O
3d	O
reconstruction	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
84	O
(	O
1	O
)	O
:80–96	O
.	O
(	O
2009	O
)	O
.	O
probabilistic	B
graphical	O
models	O
:	O
principles	O
and	O
koller	O
,	O
d.	O
and	O
friedman	O
,	O
n.	O
techniques	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
kolmogorov	O
,	O
v.	O
(	O
2006	O
)	O
.	O
convergent	O
tree-reweighted	O
message	O
passing	O
for	O
energy	O
minimiza-	O
tion	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
10	O
)	O
:1568–	O
1583.	O
kolmogorov	O
,	O
v.	O
and	O
boykov	O
,	O
y	O
.	O
(	O
2005	O
)	O
.	O
what	O
metrics	O
can	O
be	O
approximated	O
by	O
geo-cuts	O
,	O
or	O
global	B
optimization	I
of	O
length/area	O
and	O
ﬂux	B
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
564–571	O
,	O
beijing	O
,	O
china	O
.	O
kolmogorov	O
,	O
v.	O
and	O
zabih	O
,	O
r.	O
(	O
2002	O
)	O
.	O
multi-camera	O
scene	O
reconstruction	O
via	O
graph	B
cuts	I
.	O
in	O
seventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2002	O
)	O
,	O
pp	O
.	O
82–96	O
,	O
copen-	O
hagen	O
.	O
kolmogorov	O
,	O
v.	O
and	O
zabih	O
,	O
r.	O
(	O
2004	O
)	O
.	O
what	O
energy	O
functions	O
can	O
be	O
minimized	O
via	O
graph	B
cuts	I
?	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
26	O
(	O
2	O
)	O
:147–159	O
.	O
kolmogorov	O
,	O
v.	O
,	O
criminisi	O
,	O
a.	O
,	O
blake	O
,	O
a.	O
,	O
cross	O
,	O
g.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
2006	O
)	O
.	O
probabilistic	B
fusion	O
of	O
stereo	B
with	O
color	B
and	O
contrast	O
for	O
bi-layer	O
segmentation	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
9	O
)	O
:1480–1492	O
.	O
komodakis	O
,	O
n.	O
and	O
paragios	O
,	O
n.	O
(	O
2008	O
)	O
.	O
beyond	O
loose	O
lp-relaxations	O
:	O
optimizing	O
mrfs	O
by	O
repairing	O
cycles	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
806–820	O
,	O
marseilles	O
.	O
komodakis	O
,	O
n.	O
and	O
tziritas	O
,	O
g.	O
(	O
2007a	O
)	O
.	O
approximate	O
labeling	O
via	O
graph	B
cuts	I
based	O
on	O
linear	O
programming	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
8	O
)	O
:1436–1453	O
.	O
852	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
komodakis	O
,	O
n.	O
and	O
tziritas	O
,	O
g.	O
(	O
2007b	O
)	O
.	O
agation	O
via	O
priority	O
scheduling	O
and	O
dynamic	B
pruning	O
.	O
processing	O
,	O
29	O
(	O
11	O
)	O
:2649–2661	O
.	O
image	B
completion	O
using	O
efﬁcient	O
belief	O
prop-	O
ieee	O
transactions	O
on	O
image	B
komodakis	O
,	O
n.	O
,	O
paragios	O
,	O
n.	O
,	O
and	O
tziritas	O
,	O
g.	O
(	O
2007	O
)	O
.	O
mrf	O
optimization	O
via	O
dual	O
decom-	O
in	O
eleventh	O
international	O
conference	O
on	O
com-	O
position	O
:	O
message-passing	O
revisited	O
.	O
puter	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
komodakis	O
,	O
n.	O
,	O
tziritas	O
,	O
g.	O
,	O
and	O
paragios	O
,	O
n.	O
(	O
2007	O
)	O
.	O
fast	O
,	O
approximately	O
optimal	O
solu-	O
tions	O
for	O
single	O
and	O
dynamic	B
mrfs	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
com-	O
puter	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
komodakis	O
,	O
n.	O
,	O
tziritas	O
,	O
g.	O
,	O
and	O
paragios	O
,	O
n.	O
(	O
2008	O
)	O
.	O
performance	O
vs	O
computational	O
efﬁciency	O
for	O
optimizing	O
single	O
and	O
dynamic	B
mrfs	O
:	O
setting	O
the	O
state	O
of	O
the	O
art	O
with	O
primal	O
dual	O
strategies	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
112	O
(	O
1	O
)	O
:14–29	O
.	O
konolige	O
,	O
k.	O
(	O
1997	O
)	O
.	O
small	O
vision	O
systems	O
:	O
hardware	O
and	O
implementation	O
.	O
in	O
eighth	O
international	O
symposium	O
on	O
robotics	O
research	O
,	O
pp	O
.	O
203–212	O
,	O
hayama	O
,	O
japan	O
.	O
kopf	O
,	O
j.	O
,	O
cohen	O
,	O
m.	O
f.	O
,	O
lischinski	O
,	O
d.	O
,	O
and	O
uyttendaele	O
,	O
m.	O
(	O
2007	O
)	O
.	O
joint	B
bilateral	O
upsam-	O
pling	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
kopf	O
,	O
j.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
deussen	O
,	O
o.	O
,	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2007	O
)	O
.	O
capturing	O
and	O
viewing	O
gigapixel	O
images	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
kopf	O
,	O
j.	O
,	O
lischinski	O
,	O
d.	O
,	O
deussen	O
,	O
o.	O
,	O
cohen-or	O
,	O
d.	O
,	O
and	O
cohen	O
,	O
m.	O
(	O
2009	O
)	O
.	O
locally	O
adapted	O
projections	B
to	O
reduce	O
panorama	O
distortions	O
.	O
computer	O
graphics	O
forum	O
(	O
pro-	O
ceedings	O
of	O
egsr	O
2009	O
)	O
,	O
28	O
(	O
4	O
)	O
.	O
koutis	O
,	O
i	O
.	O
(	O
2007	O
)	O
.	O
combinatorial	O
and	O
algebraic	O
tools	O
for	O
optimal	O
multilevel	B
algorithms	O
.	O
ph.d.	O
thesis	O
,	O
carnegie	O
mellon	O
university	O
.	O
technical	O
report	O
cmu-cs-07-131	O
.	O
koutis	O
,	O
i.	O
and	O
miller	O
,	O
g.	O
l.	O
clusters	O
:	O
theory	O
,	O
computation	O
and	O
applications	O
to	O
preconditioning	O
.	O
parallel	O
algorithms	O
and	O
architectures	O
,	O
pp	O
.	O
137–145	O
,	O
munich	O
.	O
(	O
2008	O
)	O
.	O
graph	O
partitioning	O
into	O
isolated	O
,	O
high	O
conductance	O
in	O
symposium	O
on	O
koutis	O
,	O
i.	O
,	O
miller	O
,	O
g.	O
l.	O
,	O
and	O
tolliver	O
,	O
d.	O
(	O
2009	O
)	O
.	O
combinatorial	O
preconditioners	O
and	O
mul-	O
tilevel	O
solvers	O
for	O
problems	O
in	O
computer	O
vision	O
and	O
image	B
processing	O
.	O
in	O
5th	O
interna-	O
tional	O
symposium	O
on	O
visual	O
computing	O
(	O
isvc09	O
)	O
,	O
las	O
vegas	O
.	O
kovar	O
,	O
l.	O
,	O
gleicher	O
,	O
m.	O
,	O
and	O
pighin	O
,	O
f.	O
(	O
2002	O
)	O
.	O
motion	B
graphs	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
21	O
(	O
3	O
)	O
:473–482	O
.	O
koˇseck´a	O
,	O
j.	O
and	O
zhang	O
,	O
w.	O
(	O
2005	O
)	O
.	O
extraction	O
,	O
matching	B
and	O
pose	O
recovery	B
based	O
on	O
dom-	O
inant	O
rectangular	O
structures	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
100	O
(	O
3	O
)	O
:174–	O
293.	O
references	B
853	O
kraus	O
,	O
k.	O
(	O
1997	O
)	O
.	O
photogrammetry	B
.	O
d¨ummler	O
,	O
bonn	O
.	O
krishnan	O
,	O
d.	O
and	O
fergus	O
,	O
r.	O
(	O
2009	O
)	O
.	O
fast	O
image	O
deconvolution	O
using	O
hyper-laplacian	O
priors	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
kuglin	O
,	O
c.	O
d.	O
and	O
hines	O
,	O
d.	O
c.	O
(	O
1975	O
)	O
.	O
the	O
phase	B
correlation	I
image	O
alignment	B
method	O
.	O
in	O
ieee	O
1975	O
conference	O
on	O
cybernetics	O
and	O
society	O
,	O
pp	O
.	O
163–165	O
,	O
new	O
york	O
.	O
kulis	O
,	O
b.	O
and	O
grauman	O
,	O
k.	O
(	O
2009	O
)	O
.	O
kernelized	O
locality-sensitive	O
hashing	B
for	O
scalable	O
image	B
search	I
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
kumar	O
,	O
m.	O
p.	O
(	O
2008	O
)	O
.	O
combinatorial	O
and	O
convex	O
optimization	O
for	O
probabilistic	O
models	O
in	O
computer	O
vision	O
.	O
ph.d.	O
thesis	O
,	O
oxford	O
brookes	O
university	O
.	O
kumar	O
,	O
m.	O
p.	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2006	O
)	O
.	O
fast	O
memory-efﬁcient	O
generalized	B
belief	O
propaga-	O
tion	B
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
451–463	O
.	O
kumar	O
,	O
m.	O
p.	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2008	O
)	O
.	O
improved	O
moves	O
for	O
truncated	O
convex	O
models	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
kumar	O
,	O
m.	O
p.	O
,	O
torr	O
,	O
p.	O
h.	O
s.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
learning	B
layered	O
motion	B
segmen-	O
tations	O
of	O
video	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
76	O
(	O
3	O
)	O
:301–319	O
.	O
kumar	O
,	O
m.	O
p.	O
,	O
torr	O
,	O
p.	O
h.	O
s.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2010	O
)	O
.	O
objcut	O
:	O
efﬁcient	O
segmenta-	O
tion	B
using	O
top-down	O
and	O
bottom-up	O
cues	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
32	O
(	O
3	O
)	O
.	O
kumar	O
,	O
m.	O
p.	O
,	O
veksler	O
,	O
o.	O
,	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2010	O
)	O
.	O
improved	O
moves	O
for	O
truncated	O
convex	O
models	O
.	O
journal	O
of	O
machine	O
learning	O
research	O
,	O
(	O
sumbitted	O
)	O
.	O
kumar	O
,	O
m.	O
p.	O
,	O
zisserman	O
,	O
a.	O
,	O
and	O
h.s.torr	O
,	O
p.	O
(	O
2009	O
)	O
.	O
efﬁcient	O
discriminative	O
learning	B
of	O
parts-based	O
models	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
kumar	O
,	O
r.	O
,	O
anandan	O
,	O
p.	O
,	O
and	O
hanna	O
,	O
k.	O
(	O
1994	O
)	O
.	O
direct	B
recovery	O
of	O
shape	O
from	O
multiple	B
in	O
twelfth	O
international	O
conference	O
on	O
pattern	O
views	O
:	O
a	O
parallax	O
based	O
approach	O
.	O
recognition	B
(	O
icpr	O
’	O
94	O
)	O
,	O
pp	O
.	O
685–688	O
,	O
jerusalem	O
,	O
israel	O
.	O
kumar	O
,	O
r.	O
,	O
anandan	O
,	O
p.	O
,	O
irani	O
,	O
m.	O
,	O
bergen	O
,	O
j.	O
,	O
and	O
hanna	O
,	O
k.	O
(	O
1995	O
)	O
.	O
representation	O
of	O
in	O
ieee	O
workshop	O
on	O
representations	O
of	O
visual	O
scenes	O
from	O
collections	O
of	O
images	O
.	O
scenes	O
,	O
pp	O
.	O
10–17	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
kumar	O
,	O
s.	O
and	O
hebert	O
,	O
m.	O
(	O
2003	O
)	O
.	O
discriminative	O
random	O
ﬁelds	O
:	O
a	O
discriminative	O
frame-	O
work	O
for	O
contextual	O
interaction	O
in	O
classiﬁcation	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
1150–1157	O
,	O
nice	O
,	O
france	O
.	O
854	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
kumar	O
,	O
s.	O
and	O
hebert	O
,	O
m.	O
(	O
2006	O
)	O
.	O
discriminative	O
random	O
ﬁelds	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
68	O
(	O
2	O
)	O
:179–202	O
.	O
kundur	O
,	O
d.	O
and	O
hatzinakos	O
,	O
d.	O
(	O
1996	O
)	O
.	O
blind	O
image	B
deconvolution	O
.	O
ieee	O
signal	O
process-	O
ing	O
magazine	O
,	O
13	O
(	O
3	O
)	O
:43–64	O
.	O
kutulakos	O
,	O
k.	O
n.	O
(	O
2000	O
)	O
.	O
approximate	O
n-view	O
stereo	B
.	O
in	O
sixth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2000	O
)	O
,	O
pp	O
.	O
67–83	O
,	O
dublin	O
,	O
ireland	O
.	O
kutulakos	O
,	O
k.	O
n.	O
and	O
seitz	O
,	O
s.	O
m.	O
(	O
2000	O
)	O
.	O
a	O
theory	O
of	O
shape	O
by	O
space	B
carving	I
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
38	O
(	O
3	O
)	O
:199–218	O
.	O
kwatra	O
,	O
v.	O
,	O
essa	O
,	O
i.	O
,	O
bobick	O
,	O
a.	O
,	O
and	O
kwatra	O
,	O
n.	O
(	O
2005	O
)	O
.	O
graphcut	O
textures	O
:	O
image	B
and	O
video	B
synthesis	O
using	O
graph	O
cuts	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
5	O
)	O
:795–802	O
.	O
kwatra	O
,	O
v.	O
,	O
sch¨odl	O
,	O
a.	O
,	O
essa	O
,	O
i.	O
,	O
turk	O
,	O
g.	O
,	O
and	O
bobick	O
,	O
a	O
.	O
(	O
2003	O
)	O
.	O
graphcut	O
textures	O
:	O
image	B
and	O
video	B
synthesis	O
using	O
graph	O
cuts	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2003	O
)	O
,	O
22	O
(	O
3	O
)	O
:277–286	O
.	O
kybic	O
,	O
j.	O
and	O
unser	O
,	O
m.	O
(	O
2003	O
)	O
.	O
fast	O
parametric	O
elastic	O
image	O
registration	B
.	O
ieee	O
transac-	O
tions	O
on	O
image	B
processing	O
,	O
12	O
(	O
11	O
)	O
:1427–1442	O
.	O
lafferty	O
,	O
j.	O
,	O
mccallum	O
,	O
a.	O
,	O
and	O
pereira	O
,	O
f.	O
(	O
2001	O
)	O
.	O
conditional	O
random	O
ﬁelds	O
:	O
probabilistic	B
in	O
international	O
conference	O
on	O
models	O
for	O
segmenting	O
and	O
labeling	O
sequence	O
data	O
.	O
machine	O
learning	O
.	O
lafortune	O
,	O
e.	O
p.	O
f.	O
,	O
foo	O
,	O
s.-c.	O
,	O
torrance	O
,	O
k.	O
e.	O
,	O
and	O
greenberg	O
,	O
d.	O
p.	O
(	O
1997	O
)	O
.	O
non-linear	B
approximation	O
of	O
reﬂectance	B
functions	O
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceed-	O
ings	O
,	O
pp	O
.	O
117–126	O
,	O
los	O
angeles	O
.	O
lai	O
,	O
s.-h.	O
and	O
vemuri	O
,	O
b.	O
c.	O
(	O
1997	O
)	O
.	O
physically	B
based	I
adaptive	O
preconditioning	O
for	O
early	O
vision	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
6	O
)	O
:594–	O
607.	O
lalonde	O
,	O
j.-f.	O
,	O
hoiem	O
,	O
d.	O
,	O
efros	O
,	O
a.	O
a.	O
,	O
rother	O
,	O
c.	O
,	O
winn	O
,	O
j.	O
,	O
and	O
criminisi	O
,	O
a	O
.	O
(	O
2007	O
)	O
.	O
photo	O
clip	O
art	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
lampert	O
,	O
c.	O
h.	O
(	O
2008	O
)	O
.	O
kernel	B
methods	O
in	O
computer	O
vision	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
4	O
(	O
3	O
)	O
:193–285	O
.	O
langer	O
,	O
m.	O
s.	O
and	O
zucker	O
,	O
s.	O
w.	O
(	O
1994	O
)	O
.	O
shape	O
from	O
shading	B
on	O
a	O
cloudy	O
day	O
.	O
journal	O
optical	O
society	O
america	O
,	O
a	O
,	O
11	O
(	O
2	O
)	O
:467–478	O
.	O
lanitis	O
,	O
a.	O
,	O
taylor	O
,	O
c.	O
j.	O
,	O
and	O
cootes	O
,	O
t.	O
f.	O
(	O
1997	O
)	O
.	O
automatic	B
interpretation	O
and	O
coding	O
of	O
face	B
images	O
using	O
ﬂexible	O
models	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
7	O
)	O
:742–756	O
.	O
references	B
855	O
larlus	O
,	O
d.	O
and	O
jurie	O
,	O
f.	O
(	O
2008	O
)	O
.	O
combining	O
appearance	O
models	O
and	O
markov	O
random	O
ﬁelds	O
for	O
category	O
level	O
object	O
segmentation	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
com-	O
puter	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
larson	O
,	O
g.	O
w.	O
(	O
1998	O
)	O
.	O
logluv	O
encoding	O
for	O
full-gamut	O
,	O
high-dynamic	O
range	O
images	O
.	O
jour-	O
nal	O
of	O
graphics	O
tools	O
,	O
3	O
(	O
1	O
)	O
:15–31	O
.	O
larson	O
,	O
g.	O
w.	O
,	O
rushmeier	O
,	O
h.	O
,	O
and	O
piatko	O
,	O
c.	O
(	O
1997	O
)	O
.	O
a	O
visibility	B
matching	O
tone	O
reproduc-	O
tion	B
operator	O
for	O
high	O
dynamic	B
range	O
scenes	O
.	O
ieee	O
transactions	O
on	O
visualization	O
and	O
computer	O
graphics	O
,	O
3	O
(	O
4	O
)	O
:291–306	O
.	O
laurentini	O
,	O
a	O
.	O
(	O
1994	O
)	O
.	O
the	O
visual	B
hull	I
concept	O
for	O
silhouette-based	O
image	B
understanding	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
16	O
(	O
2	O
)	O
:150–162	O
.	O
lavall´ee	O
,	O
s.	O
and	O
szeliski	O
,	O
r.	O
(	O
1995	O
)	O
.	O
recovering	O
the	O
position	O
and	O
orientation	O
of	O
free-form	O
objects	O
from	O
image	B
contours	O
using	O
3-d	O
distance	O
maps	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
17	O
(	O
4	O
)	O
:378–390	O
.	O
laveau	O
,	O
s.	O
and	O
faugeras	O
,	O
o.	O
d.	O
(	O
1994	O
)	O
.	O
3-d	O
scene	B
representation	I
as	O
a	O
collection	O
of	O
images	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
pattern	O
recognition	B
(	O
icpr	O
’	O
94	O
)	O
,	O
pp	O
.	O
689–691	O
,	O
jerusalem	O
,	O
israel	O
.	O
lazebnik	O
,	O
s.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
ponce	O
,	O
j	O
.	O
(	O
2005	O
)	O
.	O
a	O
sparse	B
texture	O
representation	O
using	O
local	O
afﬁne	B
regions	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
27	O
(	O
8	O
)	O
:1265–1278	O
.	O
lazebnik	O
,	O
s.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
ponce	O
,	O
j	O
.	O
(	O
2006	O
)	O
.	O
beyond	O
bags	O
of	O
features	O
:	O
spatial	O
pyramid	B
matching	O
for	O
recognizing	O
natural	B
scene	O
categories	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
2169–2176	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
le	O
gall	O
,	O
d.	O
(	O
1991	O
)	O
.	O
mpeg	O
:	O
a	O
video	B
compression	I
standard	O
for	O
multimedia	O
applications	O
.	O
communications	O
of	O
the	O
acm	O
,	O
34	O
(	O
4	O
)	O
:46–58	O
.	O
leclerc	O
,	O
y.	O
g.	O
(	O
1989	O
)	O
.	O
constructing	O
simple	O
stable	O
descriptions	O
for	O
image	O
partitioning	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
3	O
(	O
1	O
)	O
:73–102	O
.	O
lecun	O
,	O
y.	O
,	O
huang	O
,	O
f.	O
j.	O
,	O
and	O
bottou	O
,	O
l.	O
(	O
2004	O
)	O
.	O
learning	B
methods	O
for	O
generic	O
object	O
recognition	B
with	O
invariance	O
to	O
pose	O
and	O
lighting	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
97–104	O
,	O
washington	O
,	O
dc	O
.	O
lee	O
,	O
j.	O
,	O
chai	O
,	O
j.	O
,	O
reitsma	O
,	O
p.	O
s.	O
a.	O
,	O
hodgins	O
,	O
j.	O
k.	O
,	O
and	O
pollard	O
,	O
n.	O
s.	O
(	O
2002	O
)	O
.	O
interactive	B
control	O
of	O
avatars	O
animated	O
with	O
human	O
motion	B
data	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
21	O
(	O
3	O
)	O
:491–500	O
.	O
856	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
lee	O
,	O
m.-c.	O
,	O
ge	O
chen	O
,	O
w.	O
,	O
lung	O
bruce	O
lin	O
,	O
c.	O
,	O
gu	O
,	O
c.	O
,	O
markoc	O
,	O
t.	O
,	O
zabinsky	O
,	O
s.	O
i.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
1997	O
)	O
.	O
a	O
layered	B
video	O
object	O
coding	O
system	O
using	O
sprite	O
and	O
afﬁne	B
motion	O
model	O
.	O
ieee	O
transactions	O
on	O
circuits	O
and	O
systems	O
for	O
video	O
technology	O
,	O
7	O
(	O
1	O
)	O
:130–	O
145.	O
lee	O
,	O
m.	O
e.	O
and	O
redner	O
,	O
r.	O
a	O
.	O
(	O
1990	O
)	O
.	O
a	O
note	O
on	O
the	O
use	O
of	O
nonlinear	O
ﬁltering	O
in	O
computer	O
graphics	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
10	O
(	O
3	O
)	O
:23–29	O
.	O
lee	O
,	O
m.	O
w.	O
and	O
cohen	O
,	O
i	O
.	O
(	O
2006	O
)	O
.	O
a	O
model-based	B
approach	O
for	O
estimating	O
human	O
3d	O
poses	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
in	O
static	O
images	O
.	O
28	O
(	O
6	O
)	O
:905–916	O
.	O
lee	O
,	O
s.	O
,	O
wolberg	O
,	O
g.	O
,	O
and	O
shin	O
,	O
s.	O
y	O
.	O
(	O
1996	O
)	O
.	O
data	O
interpolation	O
using	O
multilevel	O
b-splines	O
.	O
ieee	O
transactions	O
on	O
visualization	O
and	O
computer	O
graphics	O
,	O
3	O
(	O
3	O
)	O
:228–244	O
.	O
lee	O
,	O
s.	O
,	O
wolberg	O
,	O
g.	O
,	O
chwa	O
,	O
k.-y.	O
,	O
and	O
shin	O
,	O
s.	O
y	O
.	O
(	O
1996	O
)	O
.	O
image	B
metamorphosis	O
with	O
scat-	O
tered	O
feature	B
constraints	O
.	O
ieee	O
transactions	O
on	O
visualization	O
and	O
computer	O
graphics	O
,	O
2	O
(	O
4	O
)	O
:337–354	O
.	O
lee	O
,	O
y.	O
d.	O
,	O
terzopoulos	O
,	O
d.	O
,	O
and	O
waters	O
,	O
k.	O
(	O
1995	O
)	O
.	O
realistic	O
facial	O
modeling	O
for	O
animation	O
.	O
in	O
acm	O
siggraph	O
1995	O
conference	O
proceedings	O
,	O
pp	O
.	O
55–62	O
.	O
lei	O
,	O
c.	O
and	O
yang	O
,	O
y.-h.	O
(	O
2009	O
)	O
.	O
optical	B
ﬂow	I
estimation	O
on	O
coarse-to-ﬁne	B
region-trees	O
using	O
discrete	O
optimization	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
leibe	O
,	O
b.	O
and	O
schiele	O
,	O
b	O
.	O
(	O
2003	O
)	O
.	O
analyzing	O
appearance	O
and	O
contour	O
based	O
methods	O
for	O
object	O
categorization	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2003	O
)	O
,	O
pp	O
.	O
409–415	O
,	O
madison	O
,	O
wi	O
.	O
leibe	O
,	O
b.	O
,	O
leonardis	O
,	O
a.	O
,	O
and	O
schiele	O
,	O
b.	O
leaved	O
categorization	O
and	O
segmentation	B
.	O
77	O
(	O
1-3	O
)	O
:259–289	O
.	O
(	O
2008	O
)	O
.	O
robust	B
object	O
detection	B
with	O
inter-	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
leibe	O
,	O
b.	O
,	O
seemann	O
,	O
e.	O
,	O
and	O
schiele	O
,	O
b	O
.	O
(	O
2005	O
)	O
.	O
pedestrian	B
detection	O
in	O
crowded	O
scenes	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
878–885	O
,	O
san	O
diego	O
,	O
ca	O
.	O
leibe	O
,	O
b.	O
,	O
cornelis	O
,	O
n.	O
,	O
cornelis	O
,	O
k.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2007	O
)	O
.	O
dynamic	B
3d	O
scene	O
analysis	O
from	O
a	O
moving	O
vehicle	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
leibowitz	O
,	O
d.	O
(	O
2001	O
)	O
.	O
camera	B
calibration	O
and	O
reconstruction	O
of	O
geometry	O
from	O
images	O
.	O
ph.d.	O
thesis	O
,	O
university	O
of	O
oxford	O
.	O
lempitsky	O
,	O
v.	O
and	O
boykov	O
,	O
y	O
.	O
(	O
2007	O
)	O
.	O
global	B
optimization	I
for	O
shape	O
ﬁtting	O
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
references	B
minneapolis	O
,	O
mn	O
.	O
857	O
lempitsky	O
,	O
v.	O
and	O
ivanov	O
,	O
d.	O
(	O
2007	O
)	O
.	O
seamless	O
mosaicing	O
of	O
image-based	B
texture	O
maps	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
lempitsky	O
,	O
v.	O
,	O
blake	O
,	O
a.	O
,	O
and	O
rother	O
,	O
c.	O
image	B
segmentation	O
by	O
branch-and-	O
mincut	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
15–29	O
,	O
marseilles	O
.	O
(	O
2008	O
)	O
.	O
lempitsky	O
,	O
v.	O
,	O
roth	O
,	O
s.	O
,	O
and	O
rother.	O
,	O
c.	O
(	O
2008	O
)	O
.	O
flowfusion	O
:	O
discrete-continuous	O
opti-	O
mization	O
for	O
optical	O
ﬂow	O
estimation	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
com-	O
puter	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
lempitsky	O
,	O
v.	O
,	O
rother	O
,	O
c.	O
,	O
and	O
blake	O
,	O
a	O
.	O
(	O
2007	O
)	O
.	O
logcut	O
-	O
efﬁcient	O
graph	B
cut	I
optimization	O
for	O
markov	O
random	O
ﬁelds	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
lengyel	O
,	O
j.	O
and	O
snyder	O
,	O
j	O
.	O
(	O
1997	O
)	O
.	O
rendering	B
with	O
coherent	O
layers	B
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
233–242	O
,	O
los	O
angeles	O
.	O
lensch	O
,	O
h.	O
p.	O
a.	O
,	O
kautz	O
,	O
j.	O
,	O
goesele	O
,	O
m.	O
,	O
heidrich	O
,	O
w.	O
,	O
and	O
seidel	O
,	O
h.-p.	O
(	O
2003	O
)	O
.	O
image-	O
based	O
reconstruction	O
of	O
spatial	O
appearance	O
and	O
geometric	B
detail	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
22	O
(	O
2	O
)	O
:234–257	O
.	O
leonardis	O
,	O
a.	O
and	O
bischof	O
,	O
h.	O
(	O
2000	O
)	O
.	O
robust	B
recognition	O
using	O
eigenimages	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
78	O
(	O
1	O
)	O
:99–118	O
.	O
leonardis	O
,	O
a.	O
,	O
jakliˇc	O
,	O
a.	O
,	O
and	O
solina	O
,	O
f.	O
(	O
1997	O
)	O
.	O
superquadrics	O
for	O
segmenting	O
and	O
mod-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
eling	O
range	O
data	O
.	O
19	O
(	O
11	O
)	O
:1289–1295	O
.	O
lepetit	O
,	O
v.	O
and	O
fua	O
,	O
p.	O
(	O
2005	O
)	O
.	O
monocular	O
model-based	B
3d	O
tracking	O
of	O
rigid	O
objects	O
.	O
foun-	O
dations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
1	O
(	O
1	O
)	O
.	O
lepetit	O
,	O
v.	O
,	O
pilet	O
,	O
j.	O
,	O
and	O
fua	O
,	O
p.	O
(	O
2004	O
)	O
.	O
point	O
matching	O
as	O
a	O
classiﬁcation	O
problem	O
for	O
fast	O
and	O
robust	B
object	O
pose	O
estimation	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
244–250	O
,	O
washington	O
,	O
dc	O
.	O
lepetit	O
,	O
v.	O
,	O
pilet	O
,	O
j.	O
,	O
and	O
fua	O
,	O
p.	O
(	O
2006	O
)	O
.	O
keypoint	O
recognition	B
using	O
randomized	O
trees	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
9	O
)	O
:1465–1479	O
.	O
leung	O
,	O
t.	O
k.	O
,	O
burl	O
,	O
m.	O
c.	O
,	O
and	O
perona	O
,	O
p.	O
(	O
1995	O
)	O
.	O
finding	O
faces	B
in	O
cluttered	O
scenes	O
using	O
random	O
labeled	O
graph	O
matching	O
.	O
in	O
fifth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
95	O
)	O
,	O
pp	O
.	O
637–644	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
levenberg	O
,	O
k.	O
(	O
1944	O
)	O
.	O
a	O
method	O
for	O
the	O
solution	O
of	O
certain	O
problems	O
in	O
least	B
squares	I
.	O
quarterly	O
of	O
applied	O
mathematics	O
,	O
2:164–168	O
.	O
858	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
levin	O
,	O
a	O
.	O
(	O
2006	O
)	O
.	O
blind	O
motion	B
deblurring	O
using	O
image	O
statistics	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
levin	O
,	O
a.	O
and	O
szeliski	O
,	O
r.	O
(	O
2004	O
)	O
.	O
visual	O
odometry	O
and	O
map	O
correlation	O
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
611–618	O
,	O
washington	O
,	O
dc	O
.	O
levin	O
,	O
a.	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
motion	B
uncertainty	O
and	O
field	O
of	O
view	O
.	O
technical	O
report	O
msr-tr-2006-37	O
,	O
microsoft	O
research	O
.	O
levin	O
,	O
a.	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2006	O
)	O
.	O
learning	B
to	O
combine	O
bottom-up	O
and	O
top-down	O
segmenta-	O
tion	B
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
581–594	O
.	O
levin	O
,	O
a.	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2007	O
)	O
.	O
user	O
assisted	O
separation	O
of	O
reﬂections	B
from	O
a	O
single	O
image	O
using	O
a	O
sparsity	O
prior	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
9	O
)	O
:1647–1654	O
.	O
levin	O
,	O
a.	O
,	O
acha	O
,	O
a.	O
r.	O
,	O
and	O
lischinski	O
,	O
d.	O
(	O
2008	O
)	O
.	O
spectral	O
matting	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
30	O
(	O
10	O
)	O
:1699–1712	O
.	O
levin	O
,	O
a.	O
,	O
lischinski	O
,	O
d.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2004	O
)	O
.	O
colorization	B
using	O
optimization	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
23	O
(	O
3	O
)	O
:689–694	O
.	O
levin	O
,	O
a.	O
,	O
lischinski	O
,	O
d.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2008	O
)	O
.	O
a	O
closed	O
form	O
solution	O
to	O
natural	B
image	O
matting	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
30	O
(	O
2	O
)	O
:228–	O
242.	O
levin	O
,	O
a.	O
,	O
zomet	O
,	O
a.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2004	O
)	O
.	O
separating	O
reﬂections	B
from	O
a	O
single	O
image	O
using	O
local	O
features	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
306–313	O
,	O
washington	O
,	O
dc	O
.	O
levin	O
,	O
a.	O
,	O
fergus	O
,	O
r.	O
,	O
durand	O
,	O
f.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2007	O
)	O
.	O
image	B
and	O
depth	O
from	O
a	O
conventional	O
camera	B
with	O
a	O
coded	O
aperture	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
levin	O
,	O
a.	O
,	O
weiss	O
,	O
y.	O
,	O
durand	O
,	O
f.	O
,	O
and	O
freeman	O
,	O
b	O
.	O
(	O
2009	O
)	O
.	O
understanding	O
and	O
evaluating	O
blind	O
deconvolution	O
algorithms	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
levin	O
,	O
a.	O
,	O
zomet	O
,	O
a.	O
,	O
peleg	O
,	O
s.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2004	O
)	O
.	O
seamless	O
image	B
stitching	I
in	O
the	O
gradient	B
domain	I
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
377–389	O
,	O
prague	O
.	O
levoy	O
,	O
m.	O
(	O
1988	O
)	O
.	O
display	O
of	O
surfaces	O
from	O
volume	O
data	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
8	O
(	O
3	O
)	O
:29–37	O
.	O
levoy	O
,	O
m.	O
(	O
2006	O
)	O
.	O
light	O
ﬁelds	O
and	O
computational	O
imaging	O
.	O
computer	O
,	O
39	O
(	O
8	O
)	O
:46–55	O
.	O
references	B
859	O
levoy	O
,	O
m.	O
(	O
2008	O
)	O
.	O
technical	O
perspective	B
:	O
computational	O
photography	O
on	O
large	O
collections	O
of	O
images	O
.	O
communications	O
of	O
the	O
acm	O
,	O
51	O
(	O
10	O
)	O
:86.	O
levoy	O
,	O
m.	O
and	O
hanrahan	O
,	O
p.	O
(	O
1996	O
)	O
.	O
light	B
ﬁeld	I
rendering	O
.	O
in	O
acm	O
siggraph	O
1996	O
conference	O
proceedings	O
,	O
pp	O
.	O
31–42	O
,	O
new	O
orleans	O
.	O
levoy	O
,	O
m.	O
and	O
whitted	O
,	O
t.	O
(	O
1985	O
)	O
.	O
the	O
use	O
of	O
points	B
as	O
a	O
display	O
primitive	O
.	O
technical	O
report	O
85-022	O
,	O
university	O
of	O
north	O
carolina	O
at	O
chapel	O
hill	O
.	O
levoy	O
,	O
m.	O
,	O
ng	O
,	O
r.	O
,	O
adams	O
,	O
a.	O
,	O
footer	O
,	O
m.	O
,	O
and	O
horowitz	O
,	O
m.	O
croscopy	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:924–934	O
.	O
(	O
2006	O
)	O
.	O
light	B
ﬁeld	I
mi-	O
levoy	O
,	O
m.	O
,	O
pulli	O
,	O
k.	O
,	O
curless	O
,	O
b.	O
,	O
rusinkiewicz	O
,	O
s.	O
,	O
koller	O
,	O
d.	O
et	O
al	O
.	O
(	O
2000	O
)	O
.	O
the	O
digital	O
michelangelo	O
project	O
:	O
3d	O
scanning	O
of	O
large	O
statues	O
.	O
in	O
acm	O
siggraph	O
2000	O
confer-	O
ence	O
proceedings	O
,	O
pp	O
.	O
131–144	O
.	O
lew	O
,	O
m.	O
s.	O
,	O
sebe	O
,	O
n.	O
,	O
djeraba	O
,	O
c.	O
,	O
and	O
jain	O
,	O
r.	O
(	O
2006	O
)	O
.	O
content-based	O
multimedia	O
in-	O
formation	O
retrieval	O
:	O
state	O
of	O
the	O
art	O
and	O
challenges	O
.	O
acm	O
transactions	O
on	O
multimedia	O
computing	O
,	O
communications	O
and	O
applications	O
,	O
2	O
(	O
1	O
)	O
:1–19	O
.	O
leyvand	O
,	O
t.	O
,	O
cohen-or	O
,	O
d.	O
,	O
dror	O
,	O
g.	O
,	O
and	O
lischinski	O
,	O
d.	O
(	O
2008	O
)	O
.	O
data-driven	O
enhancement	O
of	O
facial	O
attractiveness	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
27	O
(	O
3	O
)	O
.	O
lhuillier	O
,	O
m.	O
and	O
quan	O
,	O
l.	O
(	O
2002	O
)	O
.	O
match	O
propagation	O
for	O
image-based	O
modeling	B
and	O
ren-	O
dering	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
8	O
)	O
:1140–	O
1146.	O
lhuillier	O
,	O
m.	O
and	O
quan	O
,	O
l.	O
(	O
2005	O
)	O
.	O
a	O
quasi-dense	O
approach	O
to	O
surface	B
reconstruction	I
from	O
uncalibrated	O
images	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
27	O
(	O
3	O
)	O
:418–433	O
.	O
li	O
,	O
h.	O
and	O
hartley	O
,	O
r.	O
(	O
2007	O
)	O
.	O
the	O
3d–3d	O
registration	B
problem	O
revisited	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
li	O
,	O
l.-j	O
.	O
and	O
fei-fei	O
,	O
l.	O
(	O
2010	O
)	O
.	O
optimol	O
:	O
automatic	B
object	O
picture	O
collection	O
via	O
incre-	O
mental	O
model	O
learning	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
88	O
(	O
2	O
)	O
:147–168	O
.	O
li	O
,	O
s.	O
(	O
1995	O
)	O
.	O
markov	O
random	O
field	O
modeling	B
in	O
computer	O
vision	O
.	O
springer-verlag	O
.	O
li	O
,	O
s.	O
z.	O
and	O
jain	O
,	O
a.	O
k.	O
(	O
eds	O
)	O
.	O
(	O
2005	O
)	O
.	O
handbook	O
of	O
face	B
recognition	O
,	O
springer	O
.	O
li	O
,	O
x.	O
,	O
wu	O
,	O
c.	O
,	O
zach	O
,	O
c.	O
,	O
lazebnik	O
,	O
s.	O
,	O
and	O
frahm	O
,	O
j.-m.	O
(	O
2008	O
)	O
.	O
modeling	B
and	O
recog-	O
in	O
tenth	O
european	O
nition	O
of	O
landmark	O
image	B
collections	O
using	O
iconic	O
scene	O
graphs	O
.	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
427–440	O
,	O
marseilles	O
.	O
li	O
,	O
y.	O
and	O
huttenlocher	O
,	O
d.	O
p.	O
(	O
2008	O
)	O
.	O
learning	B
for	O
optical	B
ﬂow	I
using	O
stochastic	O
optimiza-	O
tion	B
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
379–391	O
,	O
marseilles	O
.	O
860	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
li	O
,	O
y.	O
,	O
crandall	O
,	O
d.	O
j.	O
,	O
and	O
huttenlocher	O
,	O
d.	O
p.	O
(	O
2009	O
)	O
.	O
landmark	O
classiﬁcation	O
in	O
large-	O
scale	O
image	O
collections	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
li	O
,	O
y.	O
,	O
wang	O
,	O
t.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2002	O
)	O
.	O
motion	B
texture	O
:	O
a	O
two-level	O
statistical	O
model	O
for	O
character	O
motion	B
synthesis	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
21	O
(	O
3	O
)	O
:465–472	O
.	O
li	O
,	O
y.	O
,	O
shum	O
,	O
h.-y.	O
,	O
tang	O
,	O
c.-k.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2004	O
)	O
.	O
stereo	B
reconstruction	O
from	O
multiperspective	O
panoramas	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
in-	O
telligence	O
,	O
26	O
(	O
1	O
)	O
:44–62	O
.	O
li	O
,	O
y.	O
,	O
sun	O
,	O
j.	O
,	O
tang	O
,	O
c.-k.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2004	O
)	O
.	O
lazy	O
snapping	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2004	O
)	O
,	O
23	O
(	O
3	O
)	O
:303–308	O
.	O
liang	O
,	O
l.	O
,	O
xiao	O
,	O
r.	O
,	O
wen	O
,	O
f.	O
,	O
and	O
sun	O
,	O
j	O
.	O
(	O
2008	O
)	O
.	O
face	B
alignment	O
via	O
component-based	O
dis-	O
criminative	O
search	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
72–85	O
,	O
marseilles	O
.	O
liang	O
,	O
l.	O
,	O
liu	O
,	O
c.	O
,	O
xu	O
,	O
y.-q.	O
,	O
guo	O
,	O
b.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2001	O
)	O
.	O
real-time	O
texture	B
synthesis	O
by	O
patch-based	O
sampling	B
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
20	O
(	O
3	O
)	O
:127–150	O
.	O
liebowitz	O
,	O
d.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1998	O
)	O
.	O
metric	O
rectiﬁcation	B
for	O
perspective	B
images	O
of	O
planes	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recog-	O
nition	O
(	O
cvpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
482–488	O
,	O
santa	O
barbara	O
.	O
lim	O
,	O
j	O
.	O
(	O
1990	O
)	O
.	O
two-dimensional	B
signal	O
and	O
image	B
processing	O
.	O
prentice-hall	O
,	O
engle-	O
wood	O
,	O
nj	O
.	O
lim	O
,	O
j.	O
j.	O
,	O
arbel´aez	O
,	O
p.	O
,	O
gu	O
,	O
c.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2009	O
)	O
.	O
context	B
by	O
region	B
ancestry	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
lin	O
,	O
d.	O
,	O
kapoor	O
,	O
a.	O
,	O
hua	O
,	O
g.	O
,	O
and	O
baker	O
,	O
s.	O
(	O
2010	O
)	O
.	O
joint	B
people	O
,	O
event	O
,	O
and	O
location	O
recog-	O
nition	O
in	O
personal	O
photo	O
collections	O
using	O
cross-domain	O
context	B
.	O
in	O
eleventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2010	O
)	O
,	O
heraklion	O
,	O
crete	O
.	O
lin	O
,	O
w.-c.	O
,	O
hays	O
,	O
j.	O
,	O
wu	O
,	O
c.	O
,	O
kwatra	O
,	O
v.	O
,	O
and	O
liu	O
,	O
y	O
.	O
(	O
2006	O
)	O
.	O
quantitative	O
evaluation	B
of	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
near	O
regular	O
texture	B
synthesis	O
algorithms	O
.	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
427–434	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
lindeberg	O
,	O
t.	O
(	O
1990	O
)	O
.	O
scale-space	O
for	O
discrete	O
signals	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12	O
(	O
3	O
)	O
:234–254	O
.	O
lindeberg	O
,	O
t.	O
(	O
1993	O
)	O
.	O
detecting	O
salient	O
blob-like	O
image	B
structures	O
and	O
their	O
scales	O
with	O
a	O
scale-space	O
primal	O
sketch	O
:	O
a	O
method	O
for	O
focus-of-attention	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
11	O
(	O
3	O
)	O
:283–318	O
.	O
references	B
861	O
lindeberg	O
,	O
t.	O
(	O
1994	O
)	O
.	O
scale-space	O
theory	O
:	O
a	O
basic	O
tool	O
for	O
analysing	O
structures	O
at	O
different	O
scales	O
.	O
journal	O
of	O
applied	O
statistics	O
,	O
21	O
(	O
2	O
)	O
:224–270	O
.	O
lindeberg	O
,	O
t.	O
(	O
1998a	O
)	O
.	O
edge	O
detection	O
and	O
ridge	O
detection	B
with	O
automatic	B
scale	O
selection	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
30	O
(	O
2	O
)	O
:116–154	O
.	O
lindeberg	O
,	O
t.	O
(	O
1998b	O
)	O
.	O
feature	B
detection	O
with	O
automatic	O
scale	B
selection	I
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
30	O
(	O
2	O
)	O
:79–116	O
.	O
lindeberg	O
,	O
t.	O
and	O
garding	O
,	O
j	O
.	O
(	O
1997	O
)	O
.	O
shape-adapted	O
smoothing	B
in	O
estimation	B
of	O
3-d	O
shape	O
cues	O
from	O
afﬁne	B
deformations	O
of	O
local	B
2-d	O
brightness	O
structure	O
.	O
image	B
and	O
vision	O
computing	O
,	O
15	O
(	O
6	O
)	O
:415–434	O
.	O
lippman	O
,	O
a	O
.	O
(	O
1980	O
)	O
.	O
movie	O
maps	O
:	O
an	O
application	O
of	O
the	O
optical	O
videodisc	O
to	O
computer	O
graphics	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
80	O
)	O
,	O
14	O
(	O
3	O
)	O
:32–43	O
.	O
lischinski	O
,	O
d.	O
,	O
farbman	O
,	O
z.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006a	O
)	O
.	O
interactive	B
local	O
adjustment	O
of	O
tonal	O
values	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2006	O
)	O
,	O
25	O
(	O
3	O
)	O
:646–653	O
.	O
lischinski	O
,	O
d.	O
,	O
farbman	O
,	O
z.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006b	O
)	O
.	O
interactive	B
local	O
adjustment	O
of	O
tonal	O
values	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:646–653	O
.	O
litvinov	O
,	O
a.	O
and	O
schechner	O
,	O
y.	O
y	O
.	O
(	O
2005	O
)	O
.	O
radiometric	B
framework	O
for	O
image	O
mosaicking	O
.	O
journal	O
of	O
the	O
optical	O
society	O
of	O
america	O
a	O
,	O
22	O
(	O
5	O
)	O
:839–848	O
.	O
litwinowicz	O
,	O
p.	O
(	O
1997	O
)	O
.	O
processing	O
images	O
and	O
video	B
for	O
an	O
impressionist	O
effect	O
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
407–414	O
.	O
litwinowicz	O
,	O
p.	O
and	O
williams	O
,	O
l.	O
(	O
1994	O
)	O
.	O
animating	O
images	O
with	O
drawings	O
.	O
in	O
acm	O
siggraph	O
1994	O
conference	O
proceedings	O
,	O
pp	O
.	O
409–412	O
.	O
liu	O
,	O
c.	O
(	O
2009	O
)	O
.	O
beyond	O
pixels	O
:	O
exploring	O
new	O
representations	O
and	O
applications	O
for	O
mo-	O
tion	B
analysis	O
.	O
ph.d.	O
thesis	O
,	O
massachusetts	O
institute	O
of	O
technology	O
.	O
liu	O
,	O
c.	O
,	O
yuen	O
,	O
j.	O
,	O
and	O
torralba	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
nonparametric	O
scene	O
parsing	O
:	O
label	O
transfer	B
via	O
dense	O
scene	O
alignment	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
liu	O
,	O
c.	O
,	O
freeman	O
,	O
w.	O
t.	O
,	O
adelson	O
,	O
e.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2008	O
)	O
.	O
human-assisted	O
motion	B
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
annotation	O
.	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
liu	O
,	O
c.	O
,	O
szeliski	O
,	O
r.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
zitnick	O
,	O
c.	O
l.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2008	O
)	O
.	O
automatic	B
estimation	O
and	O
removal	O
of	O
noise	B
from	O
a	O
single	O
image	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
30	O
(	O
2	O
)	O
:299–314	O
.	O
862	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
liu	O
,	O
f.	O
,	O
gleicher	O
,	O
m.	O
,	O
jin	O
,	O
h.	O
,	O
and	O
agarwala	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
content-preserving	O
warps	O
for	O
3d	O
video	B
stabilization	I
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
28	O
(	O
3	O
)	O
.	O
liu	O
,	O
x.	O
,	O
chen	O
,	O
t.	O
,	O
and	O
kumar	O
,	O
b.	O
v.	O
(	O
2003	O
)	O
.	O
face	B
authentication	O
for	O
multiple	O
subjects	O
using	O
eigenﬂow	O
.	O
pattern	O
recognition	B
,	O
36	O
(	O
2	O
)	O
:313–328	O
.	O
liu	O
,	O
y.	O
,	O
collins	O
,	O
r.	O
t.	O
,	O
and	O
tsin	O
,	O
y	O
.	O
(	O
2004	O
)	O
.	O
a	O
computational	O
model	O
for	O
periodic	O
pattern	O
per-	O
ception	O
based	O
on	O
frieze	O
and	O
wallpaper	O
groups	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
26	O
(	O
3	O
)	O
:354–371	O
.	O
liu	O
,	O
y.	O
,	O
lin	O
,	O
w.-c.	O
,	O
and	O
hays	O
,	O
j	O
.	O
(	O
2004	O
)	O
.	O
near-regular	O
texture	B
analysis	O
and	O
manipulation	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
23	O
(	O
3	O
)	O
:368–376	O
.	O
livingstone	O
,	O
m.	O
(	O
2008	O
)	O
.	O
vision	O
and	O
art	O
:	O
the	O
biology	O
of	O
seeing	O
.	O
abrams	O
,	O
new	O
york	O
.	O
lobay	O
,	O
a.	O
and	O
forsyth	O
,	O
d.	O
a	O
.	O
(	O
2006	O
)	O
.	O
shape	O
from	O
texture	B
without	O
boundaries	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
67	O
(	O
1	O
)	O
:71–91	O
.	O
lombaert	O
,	O
h.	O
,	O
sun	O
,	O
y.	O
,	O
grady	O
,	O
l.	O
,	O
and	O
xu	O
,	O
c.	O
(	O
2005	O
)	O
.	O
a	O
multilevel	B
banded	O
graph	B
cuts	I
method	O
for	O
fast	O
image	B
segmentation	O
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
259–265	O
,	O
beijing	O
,	O
china	O
.	O
longere	O
,	O
p.	O
,	O
delahunt	O
,	O
p.	O
b.	O
,	O
zhang	O
,	O
x.	O
,	O
and	O
brainard	O
,	O
d.	O
h.	O
(	O
2002	O
)	O
.	O
perceptual	O
assessment	O
of	O
demosaicing	B
algorithm	O
performance	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
90	O
(	O
1	O
)	O
:123–132	O
.	O
longuet-higgins	O
,	O
h.	O
c.	O
(	O
1981	O
)	O
.	O
a	O
computer	O
algorithm	B
for	O
reconstructing	O
a	O
scene	O
from	O
two	O
projections	O
.	O
nature	O
,	O
293:133–135	O
.	O
loop	O
,	O
c.	O
and	O
zhang	O
,	O
z	O
.	O
(	O
1999	O
)	O
.	O
computing	O
rectifying	O
homographies	O
for	O
stereo	O
vision	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
99	O
)	O
,	O
pp	O
.	O
125–131	O
,	O
fort	O
collins	O
.	O
lorensen	O
,	O
w.	O
e.	O
and	O
cline	O
,	O
h.	O
e.	O
(	O
1987	O
)	O
.	O
marching	B
cubes	I
:	O
a	O
high	O
resolution	O
3d	O
surface	B
construction	O
algorithm	B
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
87	O
)	O
,	O
21	O
(	O
4	O
)	O
:163–169	O
.	O
lorusso	O
,	O
a.	O
,	O
eggert	O
,	O
d.	O
,	O
and	O
fisher	O
,	O
r.	O
b	O
.	O
(	O
1995	O
)	O
.	O
a	O
comparison	O
of	O
four	O
algorithms	O
for	O
estimating	O
3-d	O
rigid	O
transformations	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc95	O
)	O
,	O
pp	O
.	O
237–246	O
,	O
birmingham	O
,	O
england	O
.	O
lourakis	O
,	O
m.	O
i.	O
a.	O
and	O
argyros	O
,	O
a.	O
a	O
.	O
(	O
2009	O
)	O
.	O
sba	O
:	O
a	O
software	O
package	O
for	O
generic	O
sparse	B
bundle	O
adjustment	O
.	O
acm	O
transactions	O
on	O
mathematical	O
software	O
,	O
36	O
(	O
1	O
)	O
.	O
lowe	O
,	O
d.	O
g.	O
(	O
1988	O
)	O
.	O
organization	O
of	O
smooth	O
image	B
curves	O
at	O
multiple	B
scales	O
.	O
in	O
second	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
88	O
)	O
,	O
pp	O
.	O
558–567	O
,	O
tampa	O
.	O
lowe	O
,	O
d.	O
g.	O
(	O
1989	O
)	O
.	O
organization	O
of	O
smooth	O
image	B
curves	O
at	O
multiple	B
scales	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
3	O
(	O
2	O
)	O
:119–130	O
.	O
references	B
863	O
lowe	O
,	O
d.	O
g.	O
(	O
1999	O
)	O
.	O
object	O
recognition	B
from	O
local	B
scale-invariant	O
features	O
.	O
in	O
seventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
99	O
)	O
,	O
pp	O
.	O
1150–1157	O
,	O
kerkyra	O
,	O
greece	O
.	O
lowe	O
,	O
d.	O
g.	O
(	O
2004	O
)	O
.	O
distinctive	O
image	B
features	O
from	O
scale-invariant	O
keypoints	O
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
60	O
(	O
2	O
)	O
:91–110	O
.	O
lucas	O
,	O
b.	O
d.	O
and	O
kanade	O
,	O
t.	O
(	O
1981	O
)	O
.	O
an	O
iterative	B
image	O
registration	B
technique	O
with	O
an	O
in	O
seventh	O
international	O
joint	B
conference	O
on	O
artiﬁcial	O
application	O
in	O
stereo	B
vision	O
.	O
intelligence	O
(	O
ijcai-81	O
)	O
,	O
pp	O
.	O
674–679	O
,	O
vancouver	O
.	O
luong	O
,	O
q.-t.	O
and	O
faugeras	O
,	O
o.	O
d.	O
(	O
1996	O
)	O
.	O
the	O
fundamental	O
matrix	O
:	O
theory	O
,	O
algorithms	O
,	O
and	O
stability	O
analysis	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
17	O
(	O
1	O
)	O
:43–75	O
.	O
luong	O
,	O
q.-t.	O
and	O
vi´eville	O
,	O
t.	O
(	O
1996	O
)	O
.	O
canonical	O
representations	O
for	O
the	O
geometries	O
of	O
multiple	B
projective	O
views	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
64	O
(	O
2	O
)	O
:193–229	O
.	O
lyu	O
,	O
s.	O
and	O
simoncelli	O
,	O
e.	O
(	O
2008	O
)	O
.	O
nonlinear	O
image	B
representation	O
using	O
divisive	O
nor-	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
malization	O
.	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
lyu	O
,	O
s.	O
and	O
simoncelli	O
,	O
e.	O
(	O
2009	O
)	O
.	O
modeling	B
multiscale	O
subbands	O
of	O
photographic	O
images	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
with	O
ﬁelds	O
of	O
gaussian	O
scale	O
mixtures	O
.	O
machine	O
intelligence	O
,	O
31	O
(	O
4	O
)	O
:693–706	O
.	O
ma	O
,	O
w.-c.	O
,	O
jones	O
,	O
a.	O
,	O
chiang	O
,	O
j.-y.	O
,	O
hawkins	O
,	O
t.	O
,	O
frederiksen	O
,	O
s.	O
,	O
peers	O
,	O
p.	O
,	O
vukovic	O
,	O
m.	O
,	O
ouhyoung	O
,	O
m.	O
,	O
and	O
debevec	O
,	O
p.	O
(	O
2008	O
)	O
.	O
facial	O
performance	O
synthesis	O
using	O
deformation-driven	O
polynomial	O
displacement	O
maps	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
27	O
(	O
5	O
)	O
.	O
ma	O
,	O
y.	O
,	O
derksen	O
,	O
h.	O
,	O
hong	O
,	O
w.	O
,	O
and	O
wright	O
,	O
j	O
.	O
(	O
2007	O
)	O
.	O
segmentation	B
of	O
multivariate	O
mixed	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
data	O
via	O
lossy	O
data	O
coding	O
and	O
compression	B
.	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
9	O
)	O
:1546–1562	O
.	O
macdonald	O
,	O
l	O
.	O
(	O
ed.	O
)	O
.	O
(	O
2006	O
)	O
.	O
digital	B
heritage	I
:	O
applying	O
digital	O
imaging	O
to	O
cultural	O
heritage	O
,	O
butterworth-heinemann	O
.	O
madsen	O
,	O
k.	O
,	O
nielsen	O
,	O
h.	O
b.	O
,	O
and	O
tingleff	O
,	O
o	O
.	O
(	O
2004	O
)	O
.	O
methods	O
for	O
non-linear	O
least	B
squares	I
problems	O
.	O
informatics	O
and	O
mathematical	O
modelling	O
,	O
technical	O
university	O
of	O
denmark	O
(	O
dtu	O
)	O
.	O
maes	O
,	O
f.	O
,	O
collignon	O
,	O
a.	O
,	O
vandermeulen	O
,	O
d.	O
,	O
marchal	O
,	O
g.	O
,	O
and	O
suetens	O
,	O
p.	O
(	O
1997	O
)	O
.	O
multi-	O
modality	O
image	B
registration	I
by	O
maximization	O
of	O
mutual	O
information	O
.	O
ieee	O
transactions	O
on	O
medical	B
imaging	I
,	O
16	O
(	O
2	O
)	O
:187–198	O
.	O
magnor	O
,	O
m.	O
(	O
2005	O
)	O
.	O
video-based	O
rendering	O
.	O
a.	O
k.	O
peters	O
,	O
wellesley	O
,	O
ma	O
.	O
864	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
magnor	O
,	O
m.	O
and	O
girod	O
,	O
b	O
.	O
(	O
2000	O
)	O
.	O
data	O
compression	O
for	O
light-ﬁeld	O
rendering	B
.	O
ieee	O
transactions	O
on	O
circuits	O
and	O
systems	O
for	O
video	O
technology	O
,	O
10	O
(	O
3	O
)	O
:338–343	O
.	O
magnor	O
,	O
m.	O
,	O
ramanathan	O
,	O
p.	O
,	O
and	O
girod	O
,	O
b	O
.	O
(	O
2003	O
)	O
.	O
multi-view	B
coding	O
for	O
image-based	O
rendering	B
using	O
3-d	O
scene	O
geometry	O
.	O
ieee	O
transactions	O
on	O
circuits	O
and	O
systems	O
for	O
video	O
technology	O
,	O
13	O
(	O
11	O
)	O
:1092–1106	O
.	O
mahajan	O
,	O
d.	O
,	O
huang	O
,	O
f.-c.	O
,	O
matusik	O
,	O
w.	O
,	O
ramamoorthi	O
,	O
r.	O
,	O
and	O
belhumeur	O
,	O
p.	O
(	O
2009	O
)	O
.	O
moving	O
gradients	O
:	O
a	O
path-based	O
method	O
for	O
plausible	O
image	B
interpolation	O
.	O
acm	O
trans-	O
actions	O
on	O
graphics	O
,	O
28	O
(	O
3	O
)	O
.	O
maimone	O
,	O
m.	O
,	O
cheng	O
,	O
y.	O
,	O
and	O
matthies	O
,	O
l.	O
(	O
2007	O
)	O
.	O
two	O
years	O
of	O
visual	O
odometry	O
on	O
the	O
mars	O
exploration	O
rovers	O
.	O
journal	O
of	O
field	O
robotics	O
,	O
24	O
(	O
3	O
)	O
.	O
maire	O
,	O
m.	O
,	O
arbelaez	O
,	O
p.	O
,	O
fowlkes	O
,	O
c.	O
,	O
and	O
malik	O
,	O
j.	O
and	O
localize	O
junctions	O
in	O
natural	B
images	O
.	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
(	O
2008	O
)	O
.	O
using	O
contours	O
to	O
detect	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
maitin-shepard	O
,	O
j.	O
,	O
cusumano-towner	O
,	O
m.	O
,	O
lei	O
,	O
j.	O
,	O
and	O
abbeel	O
,	O
p.	O
(	O
2010	O
)	O
.	O
cloth	O
grasp	O
point	O
detection	O
based	O
on	O
multiple-view	O
geometric	B
cues	O
with	O
application	O
to	O
robotic	O
towel	O
folding	O
.	O
in	O
ieee	O
international	O
conference	O
on	O
robotics	O
and	O
automation	O
,	O
anchorage	O
,	O
ak	O
.	O
maitre	O
,	O
m.	O
,	O
shinagawa	O
,	O
y.	O
,	O
and	O
do	O
,	O
m.	O
n.	O
(	O
2008	O
)	O
.	O
symmetric	O
multi-view	B
stereo	I
reconstruc-	O
tion	B
from	O
planar	O
camera	O
arrays	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
maji	O
,	O
s.	O
,	O
berg	O
,	O
a.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2008	O
)	O
.	O
classiﬁcation	O
using	O
intersection	O
kernel	B
support	O
vector	O
machines	O
is	O
efﬁcient	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
malik	O
,	O
j.	O
and	O
rosenholtz	O
,	O
r.	O
(	O
1997	O
)	O
.	O
computing	O
local	B
surface	O
orientation	O
and	O
shape	O
from	O
texture	B
for	O
curved	O
surfaces	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
23	O
(	O
2	O
)	O
:149–168	O
.	O
malik	O
,	O
j.	O
,	O
belongie	O
,	O
s.	O
,	O
leung	O
,	O
t.	O
,	O
and	O
shi	O
,	O
j	O
.	O
(	O
2001	O
)	O
.	O
contour	O
and	O
texture	B
analysis	O
for	O
image	O
segmentation	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
43	O
(	O
1	O
)	O
:7–27	O
.	O
malisiewicz	O
,	O
t.	O
and	O
efros	O
,	O
a.	O
a	O
.	O
(	O
2008	O
)	O
.	O
recognition	B
by	O
association	O
via	O
learning	B
per-	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
exemplar	O
distances	O
.	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
malladi	O
,	O
r.	O
,	O
sethian	O
,	O
j.	O
a.	O
,	O
and	O
vemuri	O
,	O
b.	O
c.	O
(	O
1995	O
)	O
.	O
shape	O
modeling	O
with	O
front	O
propaga-	O
tion	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
17	O
(	O
2	O
)	O
:158–176	O
.	O
mallat	O
,	O
s.	O
g.	O
(	O
1989	O
)	O
.	O
a	O
theory	O
for	O
multiresolution	O
signal	O
decomposition	O
:	O
the	O
wavelet	O
rep-	O
resentation	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-	O
11	O
(	O
7	O
)	O
:674–693	O
.	O
references	B
865	O
malvar	O
,	O
h.	O
s.	O
(	O
1990	O
)	O
.	O
lapped	O
transforms	O
for	O
efﬁcient	O
transform/subband	O
coding	O
.	O
ieee	O
transactions	O
on	O
acoustics	O
,	O
speech	O
,	O
and	O
signal	O
processing	O
,	O
38	O
(	O
6	O
)	O
:969–978	O
.	O
malvar	O
,	O
h.	O
s.	O
(	O
1998	O
)	O
.	O
biorthogonal	O
and	O
nonuniform	O
lapped	O
transforms	O
for	O
transform	O
cod-	O
ing	O
with	O
reduced	O
blocking	O
and	O
ringing	O
artifacts	O
.	O
ieee	O
transactions	O
on	O
signal	O
process-	O
ing	O
,	O
46	O
(	O
4	O
)	O
:1043–1053	O
.	O
malvar	O
,	O
h.	O
s.	O
(	O
2000	O
)	O
.	O
fast	O
progressive	O
image	B
coding	O
without	O
wavelets	O
.	O
in	O
ieee	O
data	O
compressions	O
conference	O
,	O
pp	O
.	O
243–252	O
,	O
snowbird	O
,	O
ut	O
.	O
malvar	O
,	O
h.	O
s.	O
,	O
he	O
,	O
l.-w.	O
,	O
and	O
cutler	O
,	O
r.	O
demosaicing	B
of	O
bayer-patterned	O
color	B
images	O
.	O
acoustics	O
,	O
speech	O
,	O
and	O
signal	O
processing	O
(	O
icassp	O
’	O
04	O
)	O
,	O
pp	O
.	O
485–488	O
,	O
montreal	O
.	O
(	O
2004	O
)	O
.	O
high-quality	O
linear	B
interpolation	O
for	O
in	O
ieee	O
international	O
conference	O
on	O
mancini	O
,	O
t.	O
a.	O
and	O
wolff	O
,	O
l.	O
b	O
.	O
(	O
1992	O
)	O
.	O
3d	O
shape	O
and	O
light	O
source	O
location	O
from	O
depth	O
and	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
reﬂectance	B
.	O
recognition	B
(	O
cvpr	O
’	O
92	O
)	O
,	O
pp	O
.	O
707–709	O
,	O
champaign	O
,	O
illinois	O
.	O
manjunathi	O
,	O
b.	O
s.	O
and	O
ma	O
,	O
w.	O
y	O
.	O
(	O
1996	O
)	O
.	O
texture	B
features	O
for	O
browsing	O
and	O
retrieval	O
of	O
im-	O
age	O
data	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
18	O
(	O
8	O
)	O
:837–	O
842.	O
mann	O
,	O
s.	O
and	O
picard	O
,	O
r.	O
w.	O
(	O
1994	O
)	O
.	O
virtual	O
bellows	O
:	O
constructing	O
high-quality	O
images	O
from	O
video	B
.	O
in	O
first	O
ieee	O
international	O
conference	O
on	O
image	B
processing	O
(	O
icip-94	O
)	O
,	O
pp	O
.	O
363–367	O
,	O
austin	O
.	O
mann	O
,	O
s.	O
and	O
picard	O
,	O
r.	O
w.	O
(	O
1995	O
)	O
.	O
on	O
being	O
‘	O
undigital	O
’	O
with	O
digital	O
cameras	O
:	O
extend-	O
ing	O
dynamic	B
range	O
by	O
combining	O
differently	O
exposed	O
pictures	O
.	O
in	O
is	O
&	O
t	O
’	O
s	O
48th	O
annual	O
conference	O
,	O
pp	O
.	O
422–428	O
,	O
washington	O
,	O
d.	O
c.	O
manning	O
,	O
c.	O
d.	O
,	O
raghavan	O
,	O
p.	O
,	O
and	O
sch¨utze	O
,	O
h.	O
(	O
2008	O
)	O
.	O
introduction	O
to	O
information	O
re-	O
trieval	O
.	O
cambridge	O
university	O
press	O
.	O
marquardt	O
,	O
d.	O
w.	O
(	O
1963	O
)	O
.	O
an	O
algorithm	B
for	O
least-squares	O
estimation	B
of	O
nonlinear	O
parame-	O
ters	O
.	O
journal	O
of	O
the	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
,	O
11	O
(	O
2	O
)	O
:431–441	O
.	O
marr	O
,	O
d.	O
(	O
1982	O
)	O
.	O
vision	O
:	O
a	O
computational	O
investigation	O
into	O
the	O
human	O
representation	O
and	O
processing	O
of	O
visual	O
information	O
.	O
w.	O
h.	O
freeman	O
,	O
san	O
francisco	O
.	O
marr	O
,	O
d.	O
and	O
hildreth	O
,	O
e.	O
(	O
1980	O
)	O
.	O
theory	O
of	O
edge	O
detection	O
.	O
proceedings	O
of	O
the	O
royal	O
society	O
of	O
london	O
,	O
b	O
207:187–217	O
.	O
marr	O
,	O
d.	O
and	O
nishihara	O
,	O
h.	O
k.	O
(	O
1978	O
)	O
.	O
representation	O
and	O
recognition	B
of	O
the	O
spatial	O
orga-	O
nization	O
of	O
three-dimensional	O
shapes	O
.	O
proc	O
.	O
roy	O
.	O
soc	O
.	O
london	O
,	O
b	O
,	O
200:269–294	O
.	O
marr	O
,	O
d.	O
and	O
poggio	O
,	O
t.	O
(	O
1976	O
)	O
.	O
cooperative	O
computation	O
of	O
stereo	B
disparity	O
.	O
science	O
,	O
194:283–287	O
.	O
866	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
marr	O
,	O
d.	O
c.	O
and	O
poggio	O
,	O
t.	O
(	O
1979	O
)	O
.	O
a	O
computational	B
theory	I
of	O
human	O
stereo	O
vision	O
.	O
pro-	O
ceedings	O
of	O
the	O
royal	O
society	O
of	O
london	O
,	O
b	O
204:301–328	O
.	O
marroquin	O
,	O
j.	O
,	O
mitter	O
,	O
s.	O
,	O
and	O
poggio	O
,	O
t.	O
(	O
1985	O
)	O
.	O
probabilistic	B
solution	O
of	O
ill-posed	O
prob-	O
lems	O
in	O
computational	O
vision	O
.	O
in	O
image	B
understanding	O
workshop	O
,	O
pp	O
.	O
293–309	O
,	O
miami	O
beach	O
.	O
marroquin	O
,	O
j.	O
,	O
mitter	O
,	O
s.	O
,	O
and	O
poggio	O
,	O
t.	O
(	O
1987	O
)	O
.	O
probabilistic	B
solution	O
of	O
ill-posed	O
problems	O
in	O
computational	O
vision	O
.	O
journal	O
of	O
the	O
american	O
statistical	O
association	O
,	O
82	O
(	O
397	O
)	O
:76–89	O
.	O
marroquin	O
,	O
j.	O
l.	O
(	O
1983	O
)	O
.	O
design	O
of	O
cooperative	O
networks	O
.	O
working	O
paper	O
253	O
,	O
artiﬁcial	O
intelligence	O
laboratory	O
,	O
massachusetts	O
institute	O
of	O
technology	O
.	O
martin	O
,	O
d.	O
,	O
fowlkes	O
,	O
c.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2004	O
)	O
.	O
learning	B
to	O
detect	O
natural	B
image	O
boundaries	O
using	O
local	O
brightness	O
,	O
color	B
,	O
and	O
texture	B
cues	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
26	O
(	O
5	O
)	O
:530–549	O
.	O
martin	O
,	O
d.	O
,	O
fowlkes	O
,	O
c.	O
,	O
tal	O
,	O
d.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2001	O
)	O
.	O
a	O
database	O
of	O
human	O
segmented	O
natural	B
images	O
and	O
its	O
application	O
to	O
evaluating	O
segmentation	B
algorithms	O
and	O
measuring	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
ecological	O
statistics	O
.	O
2001	O
)	O
,	O
pp	O
.	O
416–423	O
,	O
vancouver	O
,	O
canada	O
.	O
martin	O
,	O
w.	O
n.	O
and	O
aggarwal	O
,	O
j.	O
k.	O
(	O
1983	O
)	O
.	O
volumetric	B
description	O
of	O
objects	O
from	O
mul-	O
tiple	O
views	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-	O
5	O
(	O
2	O
)	O
:150–158	O
.	O
martinec	O
,	O
d.	O
and	O
pajdla	O
,	O
t.	O
(	O
2007	O
)	O
.	O
robust	B
rotation	O
and	O
translation	B
estimation	O
in	O
multiview	O
reconstruction	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
massey	O
,	O
m.	O
and	O
bender	O
,	O
w.	O
(	O
1996	O
)	O
.	O
salient	O
stills	O
:	O
process	O
and	O
practice	O
.	O
ibm	O
systems	O
journal	O
,	O
35	O
(	O
3	O
&	O
4	O
)	O
:557–573	O
.	O
matas	O
,	O
j.	O
,	O
chum	O
,	O
o.	O
,	O
urban	O
,	O
m.	O
,	O
and	O
pajdla	O
,	O
t.	O
(	O
2004	O
)	O
.	O
robust	B
wide	O
baseline	O
stereo	B
from	O
maximally	O
stable	O
extremal	O
regions	O
.	O
image	B
and	O
vision	O
computing	O
,	O
22	O
(	O
10	O
)	O
:761–767	O
.	O
matei	O
,	O
b.	O
c.	O
and	O
meer	O
,	O
p.	O
(	O
2006	O
)	O
.	O
estimation	B
of	O
nonlinear	O
errors-in-variables	O
models	O
for	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
computer	O
vision	O
applications	O
.	O
intelligence	O
,	O
28	O
(	O
10	O
)	O
:1537–1552	O
.	O
matsushita	O
,	O
y.	O
and	O
lin	O
,	O
s.	O
(	O
2007	O
)	O
.	O
radiometric	B
calibration	O
from	O
noise	B
distributions	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
matsushita	O
,	O
y.	O
,	O
ofek	O
,	O
e.	O
,	O
ge	O
,	O
w.	O
,	O
tang	O
,	O
x.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2006	O
)	O
.	O
full-frame	O
video	B
sta-	O
bilization	O
with	O
motion	O
inpainting	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
references	O
867	O
intelligence	O
,	O
28	O
(	O
7	O
)	O
:1150–1163	O
.	O
matthews	O
,	O
i.	O
and	O
baker	O
,	O
s.	O
(	O
2004	O
)	O
.	O
active	O
appearance	O
models	O
revisited	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
60	O
(	O
2	O
)	O
:135–164	O
.	O
matthews	O
,	O
i.	O
,	O
xiao	O
,	O
j.	O
,	O
and	O
baker	O
,	O
s.	O
(	O
2007	O
)	O
.	O
2d	O
vs.	O
3d	O
deformable	O
face	B
models	O
:	O
represen-	O
tational	O
power	O
,	O
construction	O
,	O
and	O
real-time	O
ﬁtting	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
75	O
(	O
1	O
)	O
:93–113	O
.	O
matthies	O
,	O
l.	O
,	O
kanade	O
,	O
t.	O
,	O
and	O
szeliski	O
,	O
r.	O
estimating	O
depth	O
from	O
image	B
sequences	O
.	O
3	O
(	O
3	O
)	O
:209–236	O
.	O
(	O
1989	O
)	O
.	O
kalman	O
ﬁlter-based	O
algorithms	O
for	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
matusik	O
,	O
w.	O
,	O
buehler	O
,	O
c.	O
,	O
and	O
mcmillan	O
,	O
l.	O
(	O
2001	O
)	O
.	O
polyhedral	O
visual	O
hulls	O
for	O
real-time	O
in	O
12th	O
eurographics	O
workshop	O
on	O
rendering	B
techniques	O
,	O
pp	O
.	O
115–126	O
,	O
rendering	B
.	O
london	O
.	O
matusik	O
,	O
w.	O
,	O
buehler	O
,	O
c.	O
,	O
raskar	O
,	O
r.	O
,	O
gortler	O
,	O
s.	O
j.	O
,	O
and	O
mcmillan	O
,	O
l.	O
(	O
2000	O
)	O
.	O
image-based	B
visual	O
hulls	O
.	O
in	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
369–374	O
.	O
mayhew	O
,	O
j.	O
e.	O
w.	O
and	O
frisby	O
,	O
j.	O
p.	O
(	O
1980	O
)	O
.	O
the	O
computation	O
of	O
binocular	O
edges	O
.	O
perception	O
,	O
9:69–87	O
.	O
mayhew	O
,	O
j.	O
e.	O
w.	O
and	O
frisby	O
,	O
j.	O
p.	O
(	O
1981	O
)	O
.	O
psychophysical	O
and	O
computational	O
studies	O
towards	O
a	O
theory	O
of	O
human	O
stereopsis	O
.	O
artiﬁcial	O
intelligence	O
,	O
17	O
(	O
1-3	O
)	O
:349–408	O
.	O
mccamy	O
,	O
c.	O
s.	O
,	O
marcus	O
,	O
h.	O
,	O
and	O
davidson	O
,	O
j.	O
g.	O
(	O
1976	O
)	O
.	O
a	O
color-rendition	O
chart	O
.	O
journal	O
of	O
applied	O
photogrammetric	O
engineering	O
,	O
2	O
(	O
3	O
)	O
:95–99	O
.	O
mccane	O
,	O
b.	O
,	O
novins	O
,	O
k.	O
,	O
crannitch	O
,	O
d.	O
,	O
and	O
galvin	O
,	O
b	O
.	O
(	O
2001	O
)	O
.	O
on	O
benchmarking	O
optical	B
ﬂow	I
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
84	O
(	O
1	O
)	O
:126–143	O
.	O
mcguire	O
,	O
m.	O
,	O
matusik	O
,	O
w.	O
,	O
pﬁster	O
,	O
h.	O
,	O
hughes	O
,	O
j.	O
f.	O
,	O
and	O
durand	O
,	O
f.	O
(	O
2005	O
)	O
.	O
defocus	O
video	B
matting	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:567–576	O
.	O
mcinerney	O
,	O
t.	O
and	O
terzopoulos	O
,	O
d.	O
(	O
1993	O
)	O
.	O
a	O
ﬁnite	O
element	O
model	O
for	O
3d	O
shape	O
reconstruc-	O
tion	B
and	O
nonrigid	O
motion	B
tracking	O
.	O
in	O
fourth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
93	O
)	O
,	O
pp	O
.	O
518–523	O
,	O
berlin	O
,	O
germany	O
.	O
mcinerney	O
,	O
t.	O
and	O
terzopoulos	O
,	O
d.	O
(	O
1996	O
)	O
.	O
deformable	O
models	O
in	O
medical	B
image	I
analysis	O
:	O
a	O
survey	O
.	O
medical	B
image	I
analysis	O
,	O
1	O
(	O
2	O
)	O
:91–108	O
.	O
mcinerney	O
,	O
t.	O
and	O
terzopoulos	O
,	O
d.	O
for	O
medical	O
image	B
volume	O
segmentation	B
.	O
18	O
(	O
10	O
)	O
:840–850	O
.	O
(	O
1999	O
)	O
.	O
topology	O
adaptive	B
deformable	O
surfaces	O
ieee	O
transactions	O
on	O
medical	B
imaging	I
,	O
mcinerney	O
,	O
t.	O
and	O
terzopoulos	O
,	O
d.	O
(	O
2000	O
)	O
.	O
t-snakes	O
:	O
topology	O
adaptive	B
snakes	O
.	O
medical	B
image	I
analysis	O
,	O
4:73–91	O
.	O
868	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
mclauchlan	O
,	O
p.	O
f.	O
(	O
2000	O
)	O
.	O
a	O
batch/recursive	O
algorithm	B
for	O
3d	O
scene	O
reconstruction	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
738–743	O
,	O
hilton	O
head	B
island	O
.	O
mclauchlan	O
,	O
p.	O
f.	O
and	O
jaenicke	O
,	O
a	O
.	O
(	O
2002	O
)	O
.	O
image	B
mosaicing	O
using	O
sequential	O
bundle	B
adjustment	I
.	O
image	B
and	O
vision	O
computing	O
,	O
20	O
(	O
9-10	O
)	O
:751–759	O
.	O
mclean	O
,	O
g.	O
f.	O
and	O
kotturi	O
,	O
d.	O
(	O
1995	O
)	O
.	O
vanishing	O
point	O
detection	B
by	O
line	O
clustering	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
17	O
(	O
11	O
)	O
:1090–1095	O
.	O
mcmillan	O
,	O
l.	O
and	O
bishop	O
,	O
g.	O
(	O
1995	O
)	O
.	O
plenoptic	O
modeling	B
:	O
an	O
image-based	B
rendering	I
system	O
.	O
in	O
acm	O
siggraph	O
1995	O
conference	O
proceedings	O
,	O
pp	O
.	O
39–46	O
.	O
mcmillan	O
,	O
l.	O
and	O
gortler	O
,	O
s.	O
(	O
1999	O
)	O
.	O
image-based	B
rendering	I
:	O
a	O
new	O
interface	O
between	O
computer	O
vision	O
and	O
computer	O
graphics	O
.	O
computer	O
graphics	O
,	O
33	O
(	O
4	O
)	O
:61–64	O
.	O
meehan	O
,	O
j	O
.	O
(	O
1990	O
)	O
.	O
panoramic	O
photography	O
.	O
watson-guptill	O
.	O
meer	O
,	O
p.	O
and	O
georgescu	O
,	O
b	O
.	O
(	O
2001	O
)	O
.	O
edge	O
detection	O
with	O
embedded	O
conﬁdence	O
.	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
23	O
(	O
12	O
)	O
:1351–1365	O
.	O
ieee	O
meil˘a	O
,	O
m.	O
and	O
shi	O
,	O
j	O
.	O
(	O
2000	O
)	O
.	O
learning	B
segmentation	O
by	O
random	O
walks	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
meil˘a	O
,	O
m.	O
and	O
shi	O
,	O
j	O
.	O
(	O
2001	O
)	O
.	O
a	O
random	O
walks	O
view	O
of	O
spectral	O
segmentation	B
.	O
in	O
workshop	O
on	O
artiﬁcial	O
intelligence	O
and	O
statistics	O
,	O
pp	O
.	O
177–182	O
,	O
key	O
west	O
,	O
fl	O
.	O
meltzer	O
,	O
j.	O
and	O
soatto	O
,	O
s.	O
(	O
2008	O
)	O
.	O
edge	O
descriptors	O
for	O
robust	O
wide-baseline	O
correspon-	O
dence	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recog-	O
nition	O
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
meltzer	O
,	O
t.	O
,	O
yanover	O
,	O
c.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2005	O
)	O
.	O
globally	O
optimal	O
solutions	O
for	O
energy	O
min-	O
imization	O
in	O
stereo	B
vision	O
using	O
reweighted	O
belief	B
propagation	I
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
428–435	O
,	O
beijing	O
,	O
china	O
.	O
m´emin	O
,	O
e.	O
and	O
p´erez	O
,	O
p.	O
(	O
2002	O
)	O
.	O
hierarchical	B
estimation	O
and	O
segmentation	B
of	O
dense	O
motion	O
ﬁelds	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
44	O
(	O
2	O
)	O
:129–155	O
.	O
menet	O
,	O
s.	O
,	O
saint-marc	O
,	O
p.	O
,	O
and	O
medioni	O
,	O
g.	O
(	O
1990a	O
)	O
.	O
active	O
contour	O
models	O
:	O
overview	O
,	O
implementation	O
and	O
applications	O
.	O
in	O
ieee	O
international	O
conference	O
on	O
systems	O
,	O
man	O
and	O
cybernetics	O
,	O
pp	O
.	O
194–199	O
,	O
los	O
angeles	O
.	O
menet	O
,	O
s.	O
,	O
saint-marc	O
,	O
p.	O
,	O
and	O
medioni	O
,	O
g.	O
(	O
1990b	O
)	O
.	O
b-snakes	O
:	O
implementation	O
and	O
appli-	O
cations	O
to	O
stereo	B
.	O
in	O
image	B
understanding	O
workshop	O
,	O
pp	O
.	O
720–726	O
,	O
pittsburgh	O
.	O
merrell	O
,	O
p.	O
,	O
akbarzadeh	O
,	O
a.	O
,	O
wang	O
,	O
l.	O
,	O
mordohai	O
,	O
p.	O
,	O
frahm	O
,	O
j.-m.	O
,	O
yang	O
,	O
r.	O
,	O
nister	O
,	O
d.	O
,	O
and	O
pollefeys	O
,	O
m.	O
(	O
2007	O
)	O
.	O
real-time	O
visibility-based	O
fusion	O
of	O
depth	O
maps	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
references	B
869	O
mertens	O
,	O
t.	O
,	O
kautz	O
,	O
j.	O
,	O
and	O
reeth	O
,	O
f.	O
v.	O
(	O
2007	O
)	O
.	O
exposure	O
fusion	O
.	O
in	O
proceedings	O
of	O
paciﬁc	O
graphics	O
2007	O
,	O
pp	O
.	O
382–390	O
.	O
metaxas	O
,	O
d.	O
and	O
terzopoulos	O
,	O
d.	O
(	O
2002	O
)	O
.	O
dynamic	B
deformation	O
of	O
solid	O
primitives	O
with	O
constraints	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2002	O
)	O
,	O
21	O
(	O
3	O
)	O
:309–312	O
.	O
metropolis	O
,	O
n.	O
,	O
rosenbluth	O
,	O
a.	O
w.	O
,	O
rosenbluth	O
,	O
m.	O
n.	O
,	O
teller	O
,	O
a.	O
h.	O
,	O
and	O
teller	O
,	O
e.	O
(	O
1953	O
)	O
.	O
journal	O
of	O
chemical	O
equations	B
of	O
state	O
calculations	O
by	O
fast	O
computing	O
machines	O
.	O
physics	O
,	O
21:1087–1091	O
.	O
meyer	O
,	O
c.	O
d.	O
(	O
2000	O
)	O
.	O
matrix	O
analysis	O
and	O
applied	O
linear	B
algebra	O
.	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
,	O
philadephia	O
.	O
meyer	O
,	O
y	O
.	O
(	O
1993	O
)	O
.	O
wavelets	O
:	O
algorithms	O
and	O
applications	O
.	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
,	O
philadephia	O
.	O
mikolajczyk	O
,	O
k.	O
and	O
schmid	O
,	O
c.	O
(	O
2004	O
)	O
.	O
scale	O
&	O
afﬁne	B
invariant	O
interest	O
point	O
detectors	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
60	O
(	O
1	O
)	O
:63–86	O
.	O
mikolajczyk	O
,	O
k.	O
and	O
schmid	O
,	O
c.	O
(	O
2005	O
)	O
.	O
a	O
performance	O
evaluation	O
of	O
local	B
descriptors	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
27	O
(	O
10	O
)	O
:1615–1630	O
.	O
mikolajczyk	O
,	O
k.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2004	O
)	O
.	O
human	O
detection	O
based	O
on	O
a	O
prob-	O
abilistic	O
assembly	O
of	O
robust	B
part	O
detectors	O
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
69–82	O
,	O
prague	O
.	O
mikolajczyk	O
,	O
k.	O
,	O
tuytelaars	O
,	O
t.	O
,	O
schmid	O
,	O
c.	O
,	O
zisserman	O
,	O
a.	O
,	O
matas	O
,	O
j.	O
,	O
schaffalitzky	O
,	O
f.	O
,	O
kadir	O
,	O
t.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
j	O
.	O
(	O
2005	O
)	O
.	O
a	O
comparison	O
of	O
afﬁne	B
region	O
detectors	O
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
65	O
(	O
1-2	O
)	O
:43–72	O
.	O
milgram	O
,	O
d.	O
l.	O
(	O
1975	O
)	O
.	O
computer	O
methods	O
for	O
creating	O
photomosaics	O
.	O
ieee	O
transactions	O
on	O
computers	O
,	O
c-24	O
(	O
11	O
)	O
:1113–1119	O
.	O
milgram	O
,	O
d.	O
l.	O
(	O
1977	O
)	O
.	O
adaptive	B
techniques	O
for	O
photomosaicking	O
.	O
ieee	O
transactions	O
on	O
computers	O
,	O
c-26	O
(	O
11	O
)	O
:1175–1180	O
.	O
miller	O
,	O
i.	O
,	O
campbell	O
,	O
m.	O
,	O
huttenlocher	O
,	O
d.	O
,	O
kline	O
,	O
f.-r.	O
,	O
nathan	O
,	O
a.	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
team	O
cornell	O
’	O
s	O
skynet	O
:	O
robust	B
perception	O
and	O
planning	O
in	O
an	O
urban	O
environment	O
.	O
journal	O
of	O
field	O
robotics	O
,	O
25	O
(	O
8	O
)	O
:493–527	O
.	O
mitiche	O
,	O
a.	O
and	O
bouthemy	O
,	O
p.	O
(	O
1996	O
)	O
.	O
computation	O
and	O
analysis	O
of	O
image	B
motion	O
:	O
a	O
synopsis	O
of	O
current	O
problems	O
and	O
methods	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
19	O
(	O
1	O
)	O
:29–55	O
.	O
mitsunaga	O
,	O
t.	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
1999	O
)	O
.	O
radiometric	B
self	O
calibration	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
99	O
)	O
,	O
pp	O
.	O
374–	O
380	O
,	O
fort	O
collins	O
.	O
870	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
mittal	O
,	O
a.	O
and	O
davis	O
,	O
l.	O
s.	O
and	O
tracking	O
people	O
in	O
a	O
cluttered	O
scene	O
.	O
51	O
(	O
3	O
)	O
:189–203	O
.	O
(	O
2003	O
)	O
.	O
m2	O
tracker	O
:	O
a	O
multi-view	B
approach	O
to	O
segmenting	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
miˇcuˇs´ık	O
,	O
b.	O
and	O
koˇseck´a	O
,	O
j	O
.	O
(	O
2009	O
)	O
.	O
piecewise	O
planar	O
city	O
3d	O
modeling	B
from	O
street	O
view	O
panoramic	O
sequences	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
miˇcuˇs`ık	O
,	O
b.	O
,	O
wildenauer	O
,	O
h.	O
,	O
and	O
koˇseck´a	O
,	O
j	O
.	O
(	O
2008	O
)	O
.	O
detection	B
and	O
matching	B
of	O
rectilinear	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
structures	O
.	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
moeslund	O
,	O
t.	O
b.	O
and	O
granum	O
,	O
e.	O
(	O
2001	O
)	O
.	O
a	O
survey	O
of	O
computer	O
vision-based	O
human	B
motion	I
capture	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
81	O
(	O
3	O
)	O
:231–268	O
.	O
moeslund	O
,	O
t.	O
b.	O
,	O
hilton	O
,	O
a.	O
,	O
and	O
kr¨uger	O
,	O
v.	O
(	O
2006	O
)	O
.	O
a	O
survey	O
of	O
advances	O
in	O
vision-	O
based	O
human	B
motion	I
capture	O
and	O
analysis	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-3	O
)	O
:90–126	O
.	O
moezzi	O
,	O
s.	O
,	O
katkere	O
,	O
a.	O
,	O
kuramura	O
,	O
d.	O
,	O
and	O
jain	O
,	O
r.	O
(	O
1996	O
)	O
.	O
reality	O
modeling	B
and	O
visu-	O
alization	O
from	O
multiple	B
video	O
sequences	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
16	O
(	O
6	O
)	O
:58–63	O
.	O
moghaddam	O
,	O
b.	O
and	O
pentland	O
,	O
a	O
.	O
(	O
1997	O
)	O
.	O
probabilistic	B
visual	O
learning	B
for	O
object	O
represen-	O
tation	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
7	O
)	O
:696–	O
710.	O
moghaddam	O
,	O
b.	O
,	O
jebara	O
,	O
t.	O
,	O
and	O
pentland	O
,	O
a	O
.	O
(	O
2000	O
)	O
.	O
bayesian	O
face	B
recognition	O
.	O
pattern	O
recognition	B
,	O
33	O
(	O
11	O
)	O
:1771–1782	O
.	O
mohan	O
,	O
a.	O
,	O
papageorgiou	O
,	O
c.	O
,	O
and	O
poggio	O
,	O
t.	O
(	O
2001	O
)	O
.	O
example-based	B
object	O
detection	B
in	O
images	O
by	O
components	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelli-	O
gence	O
,	O
23	O
(	O
4	O
)	O
:349–361	O
.	O
m¨oller	O
,	O
k.	O
d.	O
(	O
1988	O
)	O
.	O
optics	B
.	O
university	O
science	O
books	O
,	O
mill	O
valley	O
,	O
ca	O
.	O
montemerlo	O
,	O
m.	O
,	O
becker	O
,	O
j.	O
,	O
bhat	O
,	O
s.	O
,	O
dahlkamp	O
,	O
h.	O
,	O
dolgov	O
,	O
d.	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
junior	O
:	O
the	O
stanford	O
entry	O
in	O
the	O
urban	O
challenge	O
.	O
journal	O
of	O
field	O
robotics	O
,	O
25	O
(	O
9	O
)	O
:569–597	O
.	O
moon	O
,	O
p.	O
and	O
spencer	O
,	O
d.	O
e.	O
(	O
1981	O
)	O
.	O
the	O
photic	O
field	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
mas-	O
sachusetts	O
.	O
moons	O
,	O
t.	O
,	O
van	O
gool	O
,	O
l.	O
,	O
and	O
vergauwen	O
,	O
m.	O
(	O
2010	O
)	O
.	O
3d	O
reconstruction	O
from	O
multiple	B
images	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
4	O
(	O
4	O
)	O
.	O
moosmann	O
,	O
f.	O
,	O
nowak	O
,	O
e.	O
,	O
and	O
jurie	O
,	O
f.	O
(	O
2008	O
)	O
.	O
randomized	O
clustering	O
forests	O
for	O
im-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
age	O
classiﬁcation	O
.	O
30	O
(	O
9	O
)	O
:1632–1646	O
.	O
references	B
871	O
moravec	O
,	O
h.	O
(	O
1977	O
)	O
.	O
towards	O
automatic	B
visual	O
obstacle	O
avoidance	O
.	O
in	O
fifth	O
interna-	O
tional	O
joint	B
conference	O
on	O
artiﬁcial	O
intelligence	O
(	O
ijcai	O
’	O
77	O
)	O
,	O
p.	O
584	O
,	O
cambridge	O
,	O
mas-	O
sachusetts	O
.	O
moravec	O
,	O
h.	O
(	O
1983	O
)	O
.	O
the	O
stanford	O
cart	O
and	O
the	O
cmu	O
rover	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
71	O
(	O
7	O
)	O
:872–884	O
.	O
moreno-noguer	O
,	O
f.	O
,	O
lepetit	O
,	O
v.	O
,	O
and	O
fua	O
,	O
p.	O
(	O
2007	O
)	O
.	O
accurate	O
non-iterative	O
o	O
(	O
n	O
)	O
solution	O
to	O
the	O
pnp	O
problem	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
mori	O
,	O
g.	O
(	O
2005	O
)	O
.	O
guiding	O
model	O
search	O
using	O
segmentation	O
.	O
in	O
tenth	O
international	O
con-	O
ference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
1417–1423	O
,	O
beijing	O
,	O
china	O
.	O
mori	O
,	O
g.	O
,	O
ren	O
,	O
x.	O
,	O
efros	O
,	O
a.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
2004	O
)	O
.	O
recovering	O
human	B
body	I
conﬁgurations	O
:	O
combining	O
segmentation	B
and	O
recognition	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
326–333	O
,	O
washington	O
,	O
dc	O
.	O
mori	O
,	O
m.	O
(	O
1970	O
)	O
.	O
the	O
uncanny	O
valley	O
.	O
energy	O
,	O
7	O
(	O
4	O
)	O
:33–35	O
.	O
http	O
:	O
//www.androidscience	O
.	O
com/theuncannyvalley/proceedings2005/uncannyvalley.html	O
.	O
morimoto	O
,	O
c.	O
and	O
chellappa	O
,	O
r.	O
(	O
1997	O
)	O
.	O
fast	O
3d	O
stabilization	O
and	O
mosaic	O
construction	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
660–665	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
morita	O
,	O
t.	O
and	O
kanade	O
,	O
t.	O
(	O
1997	O
)	O
.	O
a	O
sequential	O
factorization	B
method	O
for	O
recovering	O
shape	O
and	O
motion	B
from	O
image	B
streams	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
8	O
)	O
:858–867	O
.	O
morris	O
,	O
d.	O
d.	O
and	O
kanade	O
,	O
t.	O
(	O
1998	O
)	O
.	O
a	O
uniﬁed	O
factorization	B
algorithm	O
for	O
points	O
,	O
line	O
in	O
sixth	O
international	O
conference	O
on	O
segments	O
and	O
planes	B
with	O
uncertainty	B
models	O
.	O
computer	O
vision	O
(	O
iccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
696–702	O
,	O
bombay	O
.	O
morrone	O
,	O
m.	O
and	O
burr	O
,	O
d.	O
(	O
1988	O
)	O
.	O
feature	B
detection	O
in	O
human	O
vision	O
:	O
a	O
phase	O
dependent	O
energy	O
model	O
.	O
proceedings	O
of	O
the	O
royal	O
society	O
of	O
london	O
b	O
,	O
235:221–245	O
.	O
mortensen	O
,	O
e.	O
n.	O
(	O
1999	O
)	O
.	O
vision-assisted	O
image	B
editing	O
.	O
computer	O
graphics	O
,	O
33	O
(	O
4	O
)	O
:55–57	O
.	O
mortensen	O
,	O
e.	O
n.	O
and	O
barrett	O
,	O
w.	O
a	O
.	O
(	O
1995	O
)	O
.	O
intelligent	B
scissors	I
for	O
image	B
composition	O
.	O
in	O
acm	O
siggraph	O
1995	O
conference	O
proceedings	O
,	O
pp	O
.	O
191–198	O
.	O
mortensen	O
,	O
e.	O
n.	O
and	O
barrett	O
,	O
w.	O
a	O
.	O
(	O
1998	O
)	O
.	O
interactive	B
segmentation	O
with	O
intelligent	O
scissors	O
.	O
graphical	O
models	O
and	O
image	B
processing	O
,	O
60	O
(	O
5	O
)	O
:349–384	O
.	O
mortensen	O
,	O
e.	O
n.	O
and	O
barrett	O
,	O
w.	O
a	O
.	O
(	O
1999	O
)	O
.	O
toboggan-based	O
intelligent	B
scissors	I
with	O
a	O
four	O
parameter	O
edge	O
model	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
99	O
)	O
,	O
pp	O
.	O
452–458	O
,	O
fort	O
collins	O
.	O
872	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
mueller	O
,	O
p.	O
,	O
zeng	O
,	O
g.	O
,	O
wonka	O
,	O
p.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2007	O
)	O
.	O
image-based	B
procedural	O
mod-	O
eling	O
of	O
facades	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
m¨uhlich	O
,	O
m.	O
and	O
mester	O
,	O
r.	O
(	O
1998	O
)	O
.	O
the	O
role	O
of	O
total	B
least	O
squares	O
in	O
motion	B
analysis	O
.	O
in	O
fifth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
305–321	O
,	O
freiburg	O
,	O
germany	O
.	O
muja	O
,	O
m.	O
and	O
lowe	O
,	O
d.	O
g.	O
(	O
2009	O
)	O
.	O
fast	O
approximate	O
nearest	O
neighbors	O
with	O
automatic	O
algorithm	B
conﬁguration	O
.	O
in	O
international	O
conference	O
on	O
computer	O
vision	O
theory	O
and	O
applications	O
(	O
visapp	O
)	O
,	O
lisbon	O
,	O
portugal	O
.	O
mumford	O
,	O
d.	O
and	O
shah	O
,	O
j	O
.	O
(	O
1989	O
)	O
.	O
optimal	O
approximations	O
by	O
piecewise	O
smooth	O
functions	O
and	O
variational	O
problems	O
.	O
comm	O
.	O
pure	O
appl	O
.	O
math.	O
,	O
xlii	O
(	O
5	O
)	O
:577–685	O
.	O
munder	O
,	O
s.	O
and	O
gavrila	O
,	O
d.	O
m.	O
(	O
2006	O
)	O
.	O
an	O
experimental	O
study	O
on	O
pedestrian	B
classiﬁcation	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
11	O
)	O
:1863–1868	O
.	O
mundy	O
,	O
j.	O
l.	O
(	O
2006	O
)	O
.	O
object	O
recognition	B
in	O
the	O
geometric	B
era	O
:	O
a	O
retrospective	O
.	O
in	O
ponce	O
,	O
j.	O
,	O
hebert	O
,	O
m.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
eds	O
)	O
,	O
toward	O
category-level	O
object	O
recognition	B
,	O
pp	O
.	O
3–28	O
,	O
springer	O
,	O
new	O
york	O
.	O
mundy	O
,	O
j.	O
l.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
eds	O
)	O
.	O
(	O
1992	O
)	O
.	O
geometric	B
invariance	O
in	O
computer	O
vision	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
murase	O
,	O
h.	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
1995	O
)	O
.	O
visual	O
learning	O
and	O
recognition	B
of	O
3-d	O
objects	O
from	O
appearance	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
14	O
(	O
1	O
)	O
:5–24	O
.	O
murphy	O
,	O
e.	O
p.	O
(	O
2005	O
)	O
.	O
a	O
testing	O
procedure	O
to	O
characterize	O
color	B
and	O
spatial	O
quality	O
of	O
digital	O
cameras	O
used	O
to	O
image	B
cultural	O
heritage	O
.	O
master	O
’	O
s	O
thesis	O
,	O
rochester	O
institute	O
of	O
technology	O
.	O
murphy	O
,	O
k.	O
,	O
torralba	O
,	O
a.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2003	O
)	O
.	O
using	O
the	O
forest	O
to	O
see	O
the	O
trees	O
:	O
a	O
graphical	O
model	O
relating	O
features	O
,	O
objects	O
,	O
and	O
scenes	O
.	O
in	O
advances	O
in	O
neural	O
informa-	O
tion	B
processing	O
systems	O
.	O
murphy-chutorian	O
,	O
e.	O
and	O
trivedi	O
,	O
m.	O
m.	O
(	O
2009	O
)	O
.	O
head	B
pose	O
estimation	B
in	O
computer	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
vision	O
:	O
a	O
survey	O
.	O
31	O
(	O
4	O
)	O
:607–626	O
.	O
murray	O
,	O
r.	O
m.	O
,	O
li	O
,	O
z.	O
x.	O
,	O
and	O
sastry	O
,	O
s.	O
s.	O
(	O
1994	O
)	O
.	O
a	O
mathematical	O
introduction	O
to	O
robotic	O
manipulation	O
.	O
crc	O
press	O
.	O
mutch	O
,	O
j.	O
and	O
lowe	O
,	O
d.	O
g.	O
(	O
2008	O
)	O
.	O
object	O
class	O
recognition	B
and	O
localization	O
using	O
sparse	B
features	O
with	O
limited	O
receptive	O
ﬁelds	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
80	O
(	O
1	O
)	O
:45–57	O
.	O
references	B
873	O
nagel	O
,	O
h.	O
h.	O
(	O
1986	O
)	O
.	O
image	B
sequences—ten	O
(	O
octal	O
)	O
years—from	O
phenomenology	O
towards	O
in	O
eighth	O
international	O
conference	O
on	O
pattern	O
recognition	B
a	O
theoretical	O
foundation	O
.	O
(	O
icpr	O
’	O
86	O
)	O
,	O
pp	O
.	O
1174–1185	O
,	O
paris	O
.	O
nagel	O
,	O
h.-h.	O
and	O
enkelmann	O
,	O
w.	O
(	O
1986	O
)	O
.	O
an	O
investigation	O
of	O
smoothness	B
constraints	O
for	O
the	O
estimation	B
of	O
displacement	O
vector	O
ﬁelds	O
from	O
image	B
sequences	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-8	O
(	O
5	O
)	O
:565–593	O
.	O
nakamura	O
,	O
y.	O
,	O
matsuura	O
,	O
t.	O
,	O
satoh	O
,	O
k.	O
,	O
and	O
ohta	O
,	O
y	O
.	O
(	O
1996	O
)	O
.	O
occlusion	O
detectable	O
stereo—	O
occlusion	O
patterns	B
in	O
camera	B
matrix	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
com-	O
puter	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
96	O
)	O
,	O
pp	O
.	O
371–378	O
,	O
san	O
francisco	O
.	O
nakao	O
,	O
t.	O
,	O
kashitani	O
,	O
a.	O
,	O
and	O
kaneyoshi	O
,	O
a	O
.	O
(	O
1998	O
)	O
.	O
scanning	O
a	O
document	O
with	O
a	O
small	O
camera	B
attached	O
to	O
a	O
mouse	O
.	O
in	O
ieee	O
workshop	O
on	O
applications	O
of	O
computer	O
vision	O
(	O
wacv	O
’	O
98	O
)	O
,	O
pp	O
.	O
63–68	O
,	O
princeton	O
.	O
nalwa	O
,	O
v.	O
s.	O
(	O
1987	O
)	O
.	O
edge-detector	O
resolution	O
improvement	O
by	O
image	O
interpolation	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-9	O
(	O
3	O
)	O
:446–451	O
.	O
nalwa	O
,	O
v.	O
s.	O
(	O
1993	O
)	O
.	O
a	O
guided	O
tour	O
of	O
computer	O
vision	O
.	O
addison-wesley	O
,	O
reading	O
,	O
ma	O
.	O
nalwa	O
,	O
v.	O
s.	O
and	O
binford	O
,	O
t.	O
o	O
.	O
(	O
1986	O
)	O
.	O
on	O
detecting	O
edges	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-8	O
(	O
6	O
)	O
:699–714	O
.	O
narasimhan	O
,	O
s.	O
g.	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
2005	O
)	O
.	O
enhancing	O
resolution	O
along	O
multiple	B
imaging	O
dimensions	O
using	O
assorted	O
pixels	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
27	O
(	O
4	O
)	O
:518–530	O
.	O
narayanan	O
,	O
p.	O
,	O
rander	O
,	O
p.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
1998	O
)	O
.	O
constructing	O
virtual	O
worlds	O
using	O
dense	O
in	O
sixth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
3–10	O
,	O
stereo	B
.	O
bombay	O
.	O
nayar	O
,	O
s.	O
,	O
watanabe	O
,	O
m.	O
,	O
and	O
noguchi	O
,	O
m.	O
(	O
1995	O
)	O
.	O
real-time	O
focus	B
range	O
sensor	B
.	O
in	O
fifth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
95	O
)	O
,	O
pp	O
.	O
995–1001	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
nayar	O
,	O
s.	O
k.	O
(	O
2006	O
)	O
.	O
computational	O
cameras	O
:	O
redeﬁning	O
the	O
image	B
.	O
computer	O
,	O
39	O
(	O
8	O
)	O
:30–	O
38.	O
nayar	O
,	O
s.	O
k.	O
and	O
branzoi	O
,	O
v.	O
(	O
2003	O
)	O
.	O
adaptive	B
dynamic	O
range	O
imaging	O
:	O
optical	O
control	O
of	O
pixel	O
exposures	O
over	O
space	O
and	O
time	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
1168–1175	O
,	O
nice	O
,	O
france	O
.	O
nayar	O
,	O
s.	O
k.	O
and	O
mitsunaga	O
,	O
t.	O
(	O
2000	O
)	O
.	O
high	B
dynamic	I
range	I
imaging	O
:	O
spatially	O
varying	O
pixel	O
exposures	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
472–479	O
,	O
hilton	O
head	B
island	O
.	O
874	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
nayar	O
,	O
s.	O
k.	O
and	O
nakagawa	O
,	O
y	O
.	O
(	O
1994	O
)	O
.	O
shape	O
from	O
focus	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
16	O
(	O
8	O
)	O
:824–831	O
.	O
nayar	O
,	O
s.	O
k.	O
,	O
ikeuchi	O
,	O
k.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
1991	O
)	O
.	O
shape	O
from	O
interreﬂections	O
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
6	O
(	O
3	O
)	O
:173–195	O
.	O
nayar	O
,	O
s.	O
k.	O
,	O
watanabe	O
,	O
m.	O
,	O
and	O
noguchi	O
,	O
m.	O
(	O
1996	O
)	O
.	O
real-time	O
focus	B
range	O
sensor	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
18	O
(	O
12	O
)	O
:1186–1198	O
.	O
negahdaripour	O
,	O
s.	O
(	O
1998	O
)	O
.	O
revised	O
deﬁnition	O
of	O
optical	B
ﬂow	I
:	O
integration	O
of	O
radiometric	B
and	O
geometric	B
cues	O
for	O
dynamic	O
scene	O
analysis	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
20	O
(	O
9	O
)	O
:961–979	O
.	O
nehab	O
,	O
d.	O
,	O
rusinkiewicz	O
,	O
s.	O
,	O
davis	O
,	O
j.	O
,	O
and	O
ramamoorthi	O
,	O
r.	O
(	O
2005	O
)	O
.	O
efﬁciently	O
combining	O
positions	O
and	O
normals	O
for	O
precise	O
3d	O
geometry	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:536–543	O
.	O
nene	O
,	O
s.	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
1997	O
)	O
.	O
a	O
simple	O
algorithm	B
for	O
nearest	B
neighbor	I
search	O
in	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
high	O
dimensions	O
.	O
19	O
(	O
9	O
)	O
:989–1003	O
.	O
nene	O
,	O
s.	O
a.	O
,	O
nayar	O
,	O
s.	O
k.	O
,	O
and	O
murase	O
,	O
h.	O
(	O
1996	O
)	O
.	O
columbia	O
object	O
image	B
library	O
(	O
coil-	O
100	O
)	O
.	O
technical	O
report	O
cucs-006-96	O
,	O
department	O
of	O
computer	O
science	O
,	O
columbia	O
university	O
.	O
netravali	O
,	O
a.	O
and	O
robbins	O
,	O
j	O
.	O
(	O
1979	O
)	O
.	O
motion-compensated	O
television	O
coding	O
:	O
part	O
1.	O
bell	O
system	O
tech.	O
,	O
58	O
(	O
3	O
)	O
:631–670	O
.	O
nevatia	O
,	O
r.	O
(	O
1977	O
)	O
.	O
a	O
color	B
edge	O
detector	O
and	O
its	O
use	O
in	O
scene	O
segmentation	O
.	O
ieee	O
trans-	O
actions	O
on	O
systems	O
,	O
man	O
,	O
and	O
cybernetics	O
,	O
smc-7	O
(	O
11	O
)	O
:820–826	O
.	O
nevatia	O
,	O
r.	O
and	O
binford	O
,	O
t.	O
(	O
1977	O
)	O
.	O
description	O
and	O
recognition	B
of	O
curved	O
objects	O
.	O
artiﬁ-	O
cial	O
intelligence	O
,	O
8:77–98	O
.	O
ng	O
,	O
a.	O
y.	O
,	O
jordan	O
,	O
m.	O
i.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2001	O
)	O
.	O
on	O
spectral	O
clustering	O
:	O
analysis	O
and	O
an	O
algorithm	B
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
,	O
pp	O
.	O
849–854	O
.	O
ng	O
,	O
r.	O
(	O
2005	O
)	O
.	O
fourier	O
slice	O
photography	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
sig-	O
graph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:735–744	O
.	O
ng	O
,	O
r.	O
,	O
levoy	O
,	O
m.	O
,	O
br´eedif	O
,	O
m.	O
,	O
duval	O
,	O
g.	O
,	O
horowitz	O
,	O
m.	O
,	O
and	O
hanrahan	O
,	O
p.	O
(	O
2005	O
)	O
.	O
light	O
field	O
photography	O
with	O
a	O
hand-held	O
plenoptic	O
camera	B
.	O
technical	O
report	O
cstr	O
2005-	O
02	O
,	O
stanford	O
university	O
.	O
nielsen	O
,	O
m.	O
,	O
florack	O
,	O
l.	O
m.	O
j.	O
,	O
and	O
deriche	O
,	O
r.	O
(	O
1997	O
)	O
.	O
regularization	B
,	O
scale-space	O
,	O
and	O
edge-detection	O
ﬁlters	O
.	O
journal	O
of	O
mathematical	O
imaging	O
and	O
vision	O
,	O
7	O
(	O
4	O
)	O
:291–307	O
.	O
references	B
875	O
nielson	O
,	O
g.	O
m.	O
(	O
1993	O
)	O
.	O
scattered	O
data	O
modeling	O
.	O
ieee	O
computer	O
graphics	O
and	O
applica-	O
tions	O
,	O
13	O
(	O
1	O
)	O
:60–70	O
.	O
nir	O
,	O
t.	O
,	O
bruckstein	O
,	O
a.	O
m.	O
,	O
and	O
kimmel	O
,	O
r.	O
(	O
2008	O
)	O
.	O
over-parameterized	O
variational	O
optical	B
ﬂow	I
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
76	O
(	O
2	O
)	O
:205–216	O
.	O
nishihara	O
,	O
h.	O
k.	O
(	O
1984	O
)	O
.	O
practical	O
real-time	O
imaging	O
stereo	B
matcher	O
.	O
opteng	O
,	O
23	O
(	O
5	O
)	O
:536–	O
545.	O
nist´er	O
,	O
d.	O
(	O
2003	O
)	O
.	O
preemptive	B
ransac	O
for	O
live	O
structure	O
and	O
motion	B
estimation	I
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
199–206	O
,	O
nice	O
,	O
france	O
.	O
nist´er	O
,	O
d.	O
(	O
2004	O
)	O
.	O
an	O
efﬁcient	O
solution	O
to	O
the	O
ﬁve-point	O
relative	O
pose	O
problem	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
26	O
(	O
6	O
)	O
:756–777	O
.	O
nist´er	O
,	O
d.	O
and	O
stew´enius	O
,	O
h.	O
scalable	O
recognition	B
with	O
a	O
vocabulary	B
tree	I
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
2161–2168	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
(	O
2006	O
)	O
.	O
nist´er	O
,	O
d.	O
and	O
stew´enius	O
,	O
h.	O
(	O
2008	O
)	O
.	O
linear	B
time	O
maximally	O
stable	O
extremal	O
regions	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
183–196	O
,	O
mar-	O
seilles	O
.	O
nist´er	O
,	O
d.	O
,	O
naroditsky	O
,	O
o.	O
,	O
and	O
bergen	O
,	O
j	O
.	O
(	O
2006	O
)	O
.	O
visual	O
odometry	O
for	O
ground	O
vehicle	O
applications	O
.	O
journal	O
of	O
field	O
robotics	O
,	O
23	O
(	O
1	O
)	O
:3–20	O
.	O
noborio	O
,	O
h.	O
,	O
fukada	O
,	O
s.	O
,	O
and	O
arimoto	O
,	O
s.	O
(	O
1988	O
)	O
.	O
construction	O
of	O
the	O
octree	B
approximat-	O
ing	O
three-dimensional	O
objects	O
by	O
using	O
multiple	B
views	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-10	O
(	O
6	O
)	O
:769–782	O
.	O
nocedal	O
,	O
j.	O
and	O
wright	O
,	O
s.	O
j	O
.	O
(	O
2006	O
)	O
.	O
numerical	O
optimization	O
.	O
springer	O
,	O
new	O
york	O
,	O
second	O
edition	O
.	O
nomura	O
,	O
y.	O
,	O
zhang	O
,	O
l.	O
,	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
2007	O
)	O
.	O
scene	O
collages	O
and	O
ﬂexible	O
camera	B
arrays	O
.	O
in	O
eurographics	O
symposium	O
on	O
rendering	B
.	O
nordstr¨om	O
,	O
n.	O
(	O
1990	O
)	O
.	O
biased	O
anisotropic	B
diffusion	O
:	O
a	O
uniﬁed	O
regularization	B
and	O
diffusion	O
approach	O
to	O
edge	O
detection	O
.	O
image	B
and	O
vision	O
computing	O
,	O
8	O
(	O
4	O
)	O
:318–327	O
.	O
nowak	O
,	O
e.	O
,	O
jurie	O
,	O
f.	O
,	O
and	O
triggs	O
,	O
b	O
.	O
(	O
2006	O
)	O
.	O
sampling	B
strategies	O
for	O
bag-of-features	O
im-	O
age	O
classiﬁcation	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
490–503	O
.	O
obdrˇz´alek	O
,	O
s.	O
and	O
matas	O
,	O
j	O
.	O
(	O
2006	O
)	O
.	O
object	O
recognition	B
using	O
local	B
afﬁne	O
frames	O
on	O
maxi-	O
mally	O
stable	O
extremal	O
regions	O
.	O
in	O
ponce	O
,	O
j.	O
,	O
hebert	O
,	O
m.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
eds	O
)	O
,	O
toward	O
category-level	O
object	O
recognition	B
,	O
pp	O
.	O
83–104	O
,	O
springer	O
,	O
new	O
york	O
.	O
876	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
oh	O
,	O
b.	O
m.	O
,	O
chen	O
,	O
m.	O
,	O
dorsey	O
,	O
j.	O
,	O
and	O
durand	O
,	O
f.	O
(	O
2001	O
)	O
.	O
image-based	B
modeling	O
and	O
photo	O
editing	O
.	O
in	O
acm	O
siggraph	O
2001	O
conference	O
proceedings	O
,	O
pp	O
.	O
433–442	O
.	O
ohlander	O
,	O
r.	O
,	O
price	O
,	O
k.	O
,	O
and	O
reddy	O
,	O
d.	O
r.	O
(	O
1978	O
)	O
.	O
picture	O
segmentation	B
using	O
a	O
recursive	O
region	B
splitting	O
method	O
.	O
computer	O
graphics	O
and	O
image	B
processing	O
,	O
8	O
(	O
3	O
)	O
:313–333	O
.	O
ohta	O
,	O
y.	O
and	O
kanade	O
,	O
t.	O
(	O
1985	O
)	O
.	O
stereo	B
by	O
intra-	O
and	O
inter-scanline	O
search	O
using	O
dy-	O
namic	O
programming	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-7	O
(	O
2	O
)	O
:139–154	O
.	O
ohtake	O
,	O
y.	O
,	O
belyaev	O
,	O
a.	O
,	O
alexa	O
,	O
m.	O
,	O
turk	O
,	O
g.	O
,	O
and	O
seidel	O
,	O
h.-p.	O
(	O
2003	O
)	O
.	O
multi-level	O
par-	O
tition	O
of	O
unity	O
implicits	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2003	O
)	O
,	O
22	O
(	O
3	O
)	O
:463–470	O
.	O
okutomi	O
,	O
m.	O
and	O
kanade	O
,	O
t.	O
(	O
1992	O
)	O
.	O
a	O
locally	B
adaptive	I
window	O
for	O
signal	O
matching	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
7	O
(	O
2	O
)	O
:143–162	O
.	O
okutomi	O
,	O
m.	O
and	O
kanade	O
,	O
t.	O
(	O
1993	O
)	O
.	O
a	O
multiple	B
baseline	O
stereo	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
15	O
(	O
4	O
)	O
:353–363	O
.	O
okutomi	O
,	O
m.	O
and	O
kanade	O
,	O
t.	O
(	O
1994	O
)	O
.	O
a	O
stereo	B
matching	I
algorithm	O
with	O
an	O
adaptive	B
win-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
dow	O
:	O
theory	O
and	O
experiment	O
.	O
intelligence	O
,	O
16	O
(	O
9	O
)	O
:920–932	O
.	O
oliensis	O
,	O
j	O
.	O
(	O
2005	O
)	O
.	O
the	O
least-squares	O
error	O
for	O
structure	O
from	O
inﬁnitesimal	O
motion	B
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
61	O
(	O
3	O
)	O
:259–299	O
.	O
oliensis	O
,	O
j.	O
and	O
hartley	O
,	O
r.	O
(	O
2007	O
)	O
.	O
convergence	O
and	O
nonconvergence	O
.	O
chine	O
intelligence	O
,	O
29	O
(	O
12	O
)	O
:2217–2233	O
.	O
iterative	B
extensions	O
of	O
the	O
sturm/triggs	O
algorithm	B
:	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
ma-	O
oliva	O
,	O
a.	O
and	O
torralba	O
,	O
a	O
.	O
(	O
2001	O
)	O
.	O
modeling	B
the	O
shape	O
of	O
the	O
scene	O
:	O
a	O
holistic	O
representa-	O
tion	B
of	O
the	O
spatial	O
envelope	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
42	O
(	O
3	O
)	O
:145–175	O
.	O
oliva	O
,	O
a.	O
and	O
torralba	O
,	O
a	O
.	O
(	O
2007	O
)	O
.	O
the	O
role	O
of	O
context	B
in	O
object	O
recognition	B
.	O
trends	O
in	O
cognitive	O
sciences	O
,	O
11	O
(	O
12	O
)	O
:520–527	O
.	O
olsson	O
,	O
c.	O
,	O
eriksson	O
,	O
a.	O
p.	O
,	O
and	O
kahl	O
,	O
f.	O
(	O
2008	O
)	O
.	O
improved	O
spectral	O
relaxation	O
methods	O
for	O
binary	O
quadratic	O
optimization	O
problems	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
112	O
(	O
1	O
)	O
:3–13	O
.	O
omer	O
,	O
i.	O
and	O
werman	O
,	O
m.	O
image	B
speciﬁc	O
color	B
representation	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
946–953	O
,	O
washington	O
,	O
dc	O
.	O
(	O
2004	O
)	O
.	O
color	B
lines	O
:	O
ong	O
,	O
e.-j.	O
,	O
micilotta	O
,	O
a.	O
s.	O
,	O
bowden	O
,	O
r.	O
,	O
and	O
hilton	O
,	O
a	O
.	O
(	O
2006	O
)	O
.	O
viewpoint	O
invari-	O
ant	O
exemplar-based	O
3d	O
human	O
tracking	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-3	O
)	O
:178–189	O
.	O
references	B
877	O
opelt	O
,	O
a.	O
,	O
pinz	O
,	O
a.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2006	O
)	O
.	O
a	O
boundary-fragment-model	O
for	O
object	O
detection	B
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
575–	O
588.	O
opelt	O
,	O
a.	O
,	O
pinz	O
,	O
a.	O
,	O
fussenegger	O
,	O
m.	O
,	O
and	O
auer	O
,	O
p.	O
(	O
2006	O
)	O
.	O
generic	O
object	O
recognition	B
with	O
boosting	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
3	O
)	O
:614–	O
641.	O
opengl-arb	O
.	O
(	O
1997	O
)	O
.	O
opengl	O
reference	O
manual	O
:	O
the	O
ofﬁcial	O
reference	O
document	O
to	O
opengl	O
,	O
version	O
1.1.	O
addison-wesley	O
,	O
reading	O
,	O
ma	O
,	O
2nd	O
edition	O
.	O
oppenheim	O
,	O
a.	O
v.	O
and	O
schafer	O
,	O
a.	O
s.	O
(	O
1996	O
)	O
.	O
signals	O
and	O
systems	O
.	O
prentice	O
hall	O
,	O
engle-	O
wood	O
cliffs	O
,	O
new	O
jersey	O
,	O
2nd	O
edition	O
.	O
oppenheim	O
,	O
a.	O
v.	O
,	O
schafer	O
,	O
r.	O
w.	O
,	O
and	O
buck	O
,	O
j.	O
r.	O
(	O
1999	O
)	O
.	O
discrete-time	O
signal	O
process-	O
ing	O
.	O
prentice	O
hall	O
,	O
englewood	O
cliffs	O
,	O
new	O
jersey	O
,	O
2nd	O
edition	O
.	O
oren	O
,	O
m.	O
and	O
nayar	O
,	O
s.	O
(	O
1997	O
)	O
.	O
a	O
theory	O
of	O
specular	B
surface	O
geometry	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
24	O
(	O
2	O
)	O
:105–124	O
.	O
o	O
’	O
rourke	O
,	O
j.	O
and	O
badler	O
,	O
n.	O
i	O
.	O
(	O
1980	O
)	O
.	O
model-based	B
image	O
analysis	O
of	O
human	B
motion	I
using	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelli-	O
constraint	B
propagation	O
.	O
gence	O
,	O
2	O
(	O
6	O
)	O
:522–536	O
.	O
osher	O
,	O
s.	O
and	O
paragios	O
,	O
n.	O
(	O
eds	O
)	O
.	O
(	O
2003	O
)	O
.	O
geometric	B
level	O
set	O
methods	O
in	O
imaging	O
,	O
vision	O
,	O
and	O
graphics	O
,	O
springer	O
.	O
osuna	O
,	O
e.	O
,	O
freund	O
,	O
r.	O
,	O
and	O
girosi	O
,	O
f.	O
(	O
1997	O
)	O
.	O
training	O
support	B
vector	I
machines	I
:	O
an	O
ap-	O
plication	O
to	O
face	B
detection	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
130–136	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
o	O
’	O
toole	O
,	O
a.	O
j.	O
,	O
jiang	O
,	O
f.	O
,	O
roark	O
,	O
d.	O
,	O
and	O
abdi	O
,	O
h.	O
(	O
2006	O
)	O
.	O
predicting	O
human	O
face	O
recogni-	O
tion	B
.	O
in	O
zhao	O
,	O
w.-y	O
.	O
and	O
chellappa	O
,	O
r.	O
(	O
eds	O
)	O
,	O
face	B
processing	O
:	O
advanced	O
methods	O
and	O
models	O
,	O
elsevier	O
.	O
o	O
’	O
toole	O
,	O
a.	O
j.	O
,	O
phillips	O
,	O
p.	O
j.	O
,	O
jiang	O
,	O
f.	O
,	O
ayyad	O
,	O
j.	O
,	O
p´enard	O
,	O
n.	O
,	O
and	O
abdi	O
,	O
h.	O
(	O
2009	O
)	O
.	O
face	B
recognition	O
algorithms	O
surpass	O
humans	O
matching	B
faces	O
over	O
changes	O
in	O
illumination	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
9	O
)	O
:1642–1646	O
.	O
ott	O
,	O
m.	O
,	O
lewis	O
,	O
j.	O
p.	O
,	O
and	O
cox	O
,	O
i.	O
j	O
.	O
(	O
1993	O
)	O
.	O
teleconferencing	O
eye	O
contact	O
using	O
a	O
virtual	O
in	O
interact	O
’	O
93	O
and	O
chi	O
’	O
93	O
conference	O
companion	O
on	O
human	O
factors	O
in	O
camera	B
.	O
computing	O
systems	O
,	O
pp	O
.	O
109–110	O
,	O
amsterdam	O
.	O
otte	O
,	O
m.	O
and	O
nagel	O
,	O
h.-h.	O
(	O
1994	O
)	O
.	O
optical	B
ﬂow	I
estimation	O
:	O
advances	O
and	O
comparisons	O
.	O
in	O
third	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
94	O
)	O
,	O
pp	O
.	O
51–60	O
,	O
stockholm	O
,	O
sweden	O
.	O
878	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
oztireli	O
,	O
c.	O
,	O
guennebaud	O
,	O
g.	O
,	O
and	O
gross	O
,	O
m.	O
(	O
2008	O
)	O
.	O
feature	B
preserving	O
point	O
set	O
surfaces	O
.	O
computer	O
graphics	O
forum	O
,	O
28	O
(	O
2	O
)	O
:493–501	O
.	O
¨ozuysal	O
,	O
m.	O
,	O
calonder	O
,	O
m.	O
,	O
lepetit	O
,	O
v.	O
,	O
and	O
fua	O
,	O
p.	O
(	O
2010	O
)	O
.	O
fast	O
keypoint	O
recognition	B
using	O
random	O
ferns	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
32	O
(	O
3	O
)	O
.	O
paglieroni	O
,	O
d.	O
w.	O
(	O
1992	O
)	O
.	O
distance	O
transforms	O
:	O
properties	B
and	O
machine	O
vision	O
applications	O
.	O
graphical	O
models	O
and	O
image	B
processing	O
,	O
54	O
(	O
1	O
)	O
:56–74	O
.	O
pal	O
,	O
c.	O
,	O
szeliski	O
,	O
r.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
and	O
jojic	O
,	O
n.	O
(	O
2004	O
)	O
.	O
probability	O
models	O
for	O
high	O
dynamic	B
range	O
imaging	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
173–180	O
,	O
washington	O
,	O
dc	O
.	O
palmer	O
,	O
s.	O
e.	O
(	O
1999	O
)	O
.	O
vision	O
science	O
:	O
photons	O
to	O
phenomenology	O
.	O
the	O
mit	O
press	O
,	O
cam-	O
bridge	O
,	O
massachusetts	O
.	O
pankanti	O
,	O
s.	O
,	O
bolle	O
,	O
r.	O
m.	O
,	O
and	O
jain	O
,	O
a.	O
k.	O
(	O
2000	O
)	O
.	O
biometrics	B
:	O
the	O
future	O
of	O
identiﬁcation	O
.	O
computer	O
,	O
21	O
(	O
2	O
)	O
:46–49	O
.	O
papageorgiou	O
,	O
c.	O
and	O
poggio	O
,	O
t.	O
(	O
2000	O
)	O
.	O
a	O
trainable	O
system	O
for	O
object	O
detection	B
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
38	O
(	O
1	O
)	O
:15–33	O
.	O
papandreou	O
,	O
g.	O
and	O
maragos	O
,	O
p.	O
(	O
2008	O
)	O
.	O
adaptive	B
and	O
constrained	B
algorithms	O
for	O
inverse	O
compositional	B
active	O
appearance	O
model	O
ﬁtting	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
papenberg	O
,	O
n.	O
,	O
bruhn	O
,	O
a.	O
,	O
brox	O
,	O
t.	O
,	O
didas	O
,	O
s.	O
,	O
and	O
weickert	O
,	O
j	O
.	O
(	O
2006	O
)	O
.	O
highly	O
accurate	O
international	O
journal	O
of	O
optic	O
ﬂow	O
computation	O
with	O
theoretically	O
justiﬁed	O
warping	O
.	O
computer	O
vision	O
,	O
67	O
(	O
2	O
)	O
:141–158	O
.	O
papert	O
,	O
s.	O
(	O
1966	O
)	O
.	O
100	O
,	O
artiﬁcial	O
http	O
:	O
//hdl.handle.net/1721.1/6125	O
.	O
the	O
summer	O
vision	O
project	O
.	O
intelligence	O
group	O
,	O
massachusetts	O
technical	O
report	O
aim-	O
institute	O
of	O
technology	O
.	O
paragios	O
,	O
n.	O
and	O
deriche	O
,	O
r.	O
(	O
2000	O
)	O
.	O
geodesic	O
active	O
contours	O
and	O
level	B
sets	I
for	O
the	O
de-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
tection	O
and	O
tracking	O
of	O
moving	O
objects	O
.	O
machine	O
intelligence	O
,	O
22	O
(	O
3	O
)	O
:266–280	O
.	O
paragios	O
,	O
n.	O
and	O
sgallari	O
,	O
f.	O
(	O
2009	O
)	O
.	O
special	O
issue	O
on	O
scale	O
space	O
and	O
variational	O
methods	O
in	O
computer	O
vision	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
84	O
(	O
2	O
)	O
.	O
paragios	O
,	O
n.	O
,	O
faugeras	O
,	O
o.	O
d.	O
,	O
chan	O
,	O
t.	O
,	O
and	O
schn¨orr	O
,	O
c.	O
(	O
eds	O
)	O
.	O
(	O
2005	O
)	O
.	O
third	O
international	O
workshop	O
on	O
variational	O
,	O
geometric	B
,	O
and	O
level	O
set	O
methods	O
in	O
computer	O
vision	O
(	O
vlsm	O
2005	O
)	O
,	O
springer	O
.	O
paris	O
,	O
s.	O
and	O
durand	O
,	O
f.	O
(	O
2006	O
)	O
.	O
a	O
fast	O
approximation	O
of	O
the	O
bilateral	B
ﬁlter	I
using	O
a	O
signal	O
processing	O
approach	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
568–580	O
.	O
references	B
879	O
paris	O
,	O
s.	O
and	O
durand	O
,	O
f.	O
(	O
2007	O
)	O
.	O
a	O
topological	O
approach	O
to	O
hierarchical	B
segmentation	O
using	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
mean	B
shift	I
.	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
paris	O
,	O
s.	O
,	O
kornprobst	O
,	O
p.	O
,	O
tumblin	O
,	O
j.	O
,	O
and	O
durand	O
,	O
f.	O
(	O
2008	O
)	O
.	O
bilateral	B
ﬁltering	O
:	O
theory	O
and	O
applications	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
4	O
(	O
1	O
)	O
:1–73	O
.	O
park	O
,	O
m.	O
,	O
brocklehurst	O
,	O
k.	O
,	O
collins	O
,	O
r.	O
t.	O
,	O
and	O
liu	O
,	O
y	O
.	O
(	O
2009	O
)	O
.	O
deformed	O
lattice	O
detection	B
in	O
real-world	O
images	O
using	O
mean-shift	O
belief	B
propagation	I
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
31	O
(	O
10	O
)	O
:1804–1816	O
.	O
park	O
,	O
s.	O
c.	O
,	O
park	O
,	O
m.	O
k.	O
,	O
and	O
kang	O
,	O
m.	O
g.	O
(	O
2003	O
)	O
.	O
super-resolution	O
image	B
reconstruction	O
:	O
a	O
technical	O
overview	O
.	O
ieee	O
signal	O
processing	O
magazine	O
,	O
20:21–36	O
.	O
parke	O
,	O
f.	O
i.	O
and	O
waters	O
,	O
k.	O
(	O
1996	O
)	O
.	O
computer	O
facial	B
animation	I
.	O
a	O
k	O
peters	O
,	O
wellesley	O
,	O
massachusetts	O
.	O
parker	O
,	O
j.	O
a.	O
,	O
kenyon	O
,	O
r.	O
v.	O
,	O
and	O
troxel	O
,	O
d.	O
e.	O
(	O
1983	O
)	O
.	O
comparison	O
of	O
interpolating	O
meth-	O
ods	O
for	O
image	O
resampling	O
.	O
ieee	O
transactions	O
on	O
medical	B
imaging	I
,	O
mi-2	O
(	O
1	O
)	O
:31–39	O
.	O
pattanaik	O
,	O
s.	O
n.	O
,	O
ferwerda	O
,	O
j.	O
a.	O
,	O
fairchild	O
,	O
m.	O
d.	O
,	O
and	O
greenberg	O
,	O
d.	O
p.	O
(	O
1998	O
)	O
.	O
a	O
multi-	O
scale	O
model	O
of	O
adaptation	O
and	O
spatial	O
vision	O
for	O
realistic	O
image	B
display	O
.	O
in	O
acm	O
sig-	O
graph	O
1998	O
conference	O
proceedings	O
,	O
pp	O
.	O
287–298	O
,	O
orlando	O
.	O
pauly	O
,	O
m.	O
,	O
keiser	O
,	O
r.	O
,	O
kobbelt	O
,	O
l.	O
p.	O
,	O
and	O
gross	O
,	O
m.	O
(	O
2003	O
)	O
.	O
shape	O
modeling	O
with	O
point-sampled	O
geometry	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2003	O
)	O
,	O
21	O
(	O
3	O
)	O
:641–650	O
.	O
pavlidis	O
,	O
t.	O
(	O
1977	O
)	O
.	O
structural	O
pattern	O
recognition	B
.	O
springer-verlag	O
,	O
berlin	O
;	O
new	O
york	O
.	O
pavlidis	O
,	O
t.	O
and	O
liow	O
,	O
y.-t.	O
(	O
1990	O
)	O
.	O
integrating	O
region	B
growing	O
and	O
edge	O
detection	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12	O
(	O
3	O
)	O
:225–233	O
.	O
pavlovi´c	O
,	O
v.	O
,	O
sharma	O
,	O
r.	O
,	O
and	O
huang	O
,	O
t.	O
s.	O
(	O
1997	O
)	O
.	O
visual	O
interpretation	O
of	O
hand	O
gestures	O
for	O
human-computer	O
interaction	O
:	O
a	O
review	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
7	O
)	O
:677–695	O
.	O
pearl	O
,	O
j	O
.	O
(	O
1988	O
)	O
.	O
probabilistic	B
reasoning	O
in	O
intelligent	O
systems	O
:	O
networks	O
of	O
plausible	O
inference	B
.	O
morgan	O
kaufmann	O
publishers	O
,	O
los	O
altos	O
.	O
peleg	O
,	O
r.	O
,	O
ben-ezra	O
,	O
m.	O
,	O
and	O
pritch	O
,	O
y	O
.	O
(	O
2001	O
)	O
.	O
omnistereo	O
:	O
panoramic	O
stereo	B
imaging	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
23	O
(	O
3	O
)	O
:279–290	O
.	O
peleg	O
,	O
s.	O
(	O
1981	O
)	O
.	O
elimination	O
of	O
seams	O
from	O
photomosaics	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
16	O
(	O
1	O
)	O
:1206–1210	O
.	O
880	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
peleg	O
,	O
s.	O
and	O
herman	O
,	O
j.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
338–343	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
(	O
1997	O
)	O
.	O
panoramic	O
mosaics	O
by	O
manifold	O
projection	O
.	O
peleg	O
,	O
s.	O
and	O
rav-acha	O
,	O
a	O
.	O
(	O
2006	O
)	O
.	O
lucas-kanade	O
without	O
iterative	B
warping	O
.	O
in	O
interna-	O
tional	O
conference	O
on	O
image	B
processing	O
(	O
icip-2006	O
)	O
,	O
pp	O
.	O
1097–1100	O
,	O
atlanta	O
.	O
peleg	O
,	O
s.	O
,	O
rousso	O
,	O
b.	O
,	O
rav-acha	O
,	O
a.	O
,	O
and	O
zomet	O
,	O
a	O
.	O
(	O
2000	O
)	O
.	O
mosaicing	O
on	O
adaptive	B
mani-	O
folds	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
22	O
(	O
10	O
)	O
:1144–	O
1154.	O
penev	O
,	O
p.	O
and	O
atick	O
,	O
j	O
.	O
(	O
1996	O
)	O
.	O
local	B
feature	I
analysis	I
:	O
a	O
general	O
statistical	O
theory	O
for	O
object	O
representation	O
.	O
network	O
computation	O
and	O
neural	O
systems	O
,	O
7:477–500	O
.	O
pentland	O
,	O
a.	O
p.	O
(	O
1984	O
)	O
.	O
local	B
shading	O
analysis	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-6	O
(	O
2	O
)	O
:170–179	O
.	O
pentland	O
,	O
a.	O
p.	O
(	O
1986	O
)	O
.	O
perceptual	O
organization	O
and	O
the	O
representation	O
of	O
natural	B
form	O
.	O
artiﬁcial	O
intelligence	O
,	O
28	O
(	O
3	O
)	O
:293–331	O
.	O
pentland	O
,	O
a.	O
p.	O
(	O
1987	O
)	O
.	O
a	O
new	O
sense	O
for	O
depth	O
of	O
ﬁeld	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-9	O
(	O
4	O
)	O
:523–531	O
.	O
pentland	O
,	O
a.	O
p.	O
(	O
1994	O
)	O
.	O
interpolation	B
using	O
wavelet	O
bases	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
16	O
(	O
4	O
)	O
:410–414	O
.	O
p´erez	O
,	O
p.	O
,	O
blake	O
,	O
a.	O
,	O
and	O
gangnet	O
,	O
m.	O
(	O
2001	O
)	O
.	O
jetstream	O
:	O
probabilistic	B
contour	O
extraction	O
with	O
particles	O
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
524–531	O
,	O
vancouver	O
,	O
canada	O
.	O
p´erez	O
,	O
p.	O
,	O
gangnet	O
,	O
m.	O
,	O
and	O
blake	O
,	O
a	O
.	O
(	O
2003	O
)	O
.	O
poisson	O
image	B
editing	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2003	O
)	O
,	O
22	O
(	O
3	O
)	O
:313–318	O
.	O
(	O
1995	O
)	O
.	O
deformable	O
kernels	O
for	O
early	O
vision	O
.	O
perona	O
,	O
p.	O
analysis	O
and	O
machine	O
intelligence	O
,	O
17	O
(	O
5	O
)	O
:488–499	O
.	O
ieee	O
transactions	O
on	O
pattern	O
perona	O
,	O
p.	O
and	O
malik	O
,	O
j	O
.	O
(	O
1990a	O
)	O
.	O
detecting	O
and	O
localizing	O
edges	O
composed	O
of	O
steps	O
,	O
peaks	O
and	O
roofs	O
.	O
in	O
third	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
90	O
)	O
,	O
pp	O
.	O
52–	O
57	O
,	O
osaka	O
,	O
japan	O
.	O
perona	O
,	O
p.	O
and	O
malik	O
,	O
j	O
.	O
(	O
1990b	O
)	O
.	O
scale	O
space	O
and	O
edge	O
detection	O
using	O
anisotropic	O
diffu-	O
sion	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12	O
(	O
7	O
)	O
:629–639	O
.	O
peters	O
,	O
j.	O
and	O
reif	O
,	O
u	O
.	O
(	O
2008	O
)	O
.	O
subdivision	O
surfaces	O
.	O
springer	O
.	O
petschnigg	O
,	O
g.	O
,	O
agrawala	O
,	O
m.	O
,	O
hoppe	O
,	O
h.	O
,	O
szeliski	O
,	O
r.	O
,	O
cohen	O
,	O
m.	O
,	O
and	O
toyama	O
,	O
k.	O
(	O
2004	O
)	O
.	O
digital	O
photography	O
with	O
ﬂash	O
and	O
no-ﬂash	O
image	B
pairs	O
.	O
acm	O
transactions	O
on	O
graph-	O
ics	O
(	O
proc	O
.	O
siggraph	O
2004	O
)	O
,	O
23	O
(	O
3	O
)	O
:664–672	O
.	O
references	B
881	O
pﬁster	O
,	O
h.	O
,	O
zwicker	O
,	O
m.	O
,	O
van	O
baar	O
,	O
j.	O
,	O
and	O
gross	O
,	O
m.	O
(	O
2000	O
)	O
.	O
surfels	O
:	O
surface	B
elements	O
as	O
rendering	B
primitives	O
.	O
in	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
335–342	O
.	O
pﬂugfelder	O
,	O
r.	O
(	O
2008	O
)	O
.	O
self-calibrating	O
cameras	O
in	O
video	B
surveillance	O
.	O
ph.d.	O
thesis	O
,	O
graz	O
university	O
of	O
technology	O
.	O
philbin	O
,	O
j.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
object	O
mining	O
using	O
a	O
matching	B
graph	O
on	O
very	O
large	O
in	O
indian	O
conference	O
on	O
computer	O
vision	O
,	O
graphics	O
and	O
image	B
image	O
collections	O
.	O
processing	O
,	O
bhubaneswar	O
,	O
india	O
.	O
philbin	O
,	O
j.	O
,	O
chum	O
,	O
o.	O
,	O
isard	O
,	O
m.	O
,	O
sivic	O
,	O
j.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2007	O
)	O
.	O
object	O
retrieval	O
with	O
large	O
vocabularies	O
and	O
fast	O
spatial	O
matching	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
philbin	O
,	O
j.	O
,	O
chum	O
,	O
o.	O
,	O
sivic	O
,	O
j.	O
,	O
isard	O
,	O
m.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
lost	O
in	O
quantization	B
:	O
in	O
ieee	O
com-	O
improving	O
particular	O
object	O
retrieval	O
in	O
large	B
scale	I
image	O
databases	O
.	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
phillips	O
,	O
p.	O
j.	O
,	O
moon	O
,	O
h.	O
,	O
rizvi	O
,	O
s.	O
a.	O
,	O
and	O
rauss	O
,	O
p.	O
j	O
.	O
(	O
2000	O
)	O
.	O
the	O
feret	O
evaluation	B
methodology	O
for	O
face	O
recognition	B
algorithms	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
22	O
(	O
10	O
)	O
:1090–1104	O
.	O
phillips	O
,	O
p.	O
j.	O
,	O
scruggs	O
,	O
w.	O
t.	O
,	O
o	O
’	O
toole	O
,	O
a.	O
j.	O
,	O
flynn	O
,	O
p.	O
j.	O
,	O
bowyer	O
,	O
k.	O
w.	O
et	O
al	O
.	O
(	O
2010	O
)	O
.	O
frvt	O
2006	O
and	O
ice	O
2006	O
large-scale	O
experimental	O
results	O
.	O
ieee	O
transactions	O
on	O
pat-	O
tern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
32	O
(	O
5	O
)	O
:831–846	O
.	O
phong	O
,	O
b.	O
t.	O
(	O
1975	O
)	O
.	O
illumination	O
for	O
computer	O
generated	O
pictures	O
.	O
communications	O
of	O
the	O
acm	O
,	O
18	O
(	O
6	O
)	O
:311–317	O
.	O
pickup	O
,	O
l.	O
c.	O
(	O
2007	O
)	O
.	O
machine	O
learning	O
in	O
multi-frame	B
image	O
super-resolution	O
.	O
ph.d.	O
thesis	O
,	O
university	O
of	O
oxford	O
.	O
pickup	O
,	O
l.	O
c.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
automatic	B
retrieval	O
of	O
visual	O
continuity	O
errors	O
in	O
movies	O
.	O
in	O
acm	O
international	O
conference	O
on	O
image	B
and	O
video	B
retrieval	O
,	O
santorini	O
,	O
greece	O
.	O
pickup	O
,	O
l.	O
c.	O
,	O
capel	O
,	O
d.	O
p.	O
,	O
roberts	O
,	O
s.	O
j.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2007	O
)	O
.	O
overcoming	O
reg-	O
istration	O
uncertainty	B
in	O
image	B
super-resolution	O
:	O
maximize	O
or	O
marginalize	O
?	O
eurasip	O
journal	O
on	O
advances	O
in	O
signal	O
processing	O
,	O
2010	O
(	O
article	O
id	O
23565	O
)	O
.	O
pickup	O
,	O
l.	O
c.	O
,	O
capel	O
,	O
d.	O
p.	O
,	O
roberts	O
,	O
s.	O
j.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
bayesian	O
methods	O
for	O
image	O
super-resolution	O
.	O
the	O
computer	O
journal	O
,	O
52.	O
pighin	O
,	O
f.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
salesin	O
,	O
d.	O
h.	O
(	O
2002	O
)	O
.	O
modeling	B
and	O
animating	O
realistic	O
faces	B
from	O
images	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
50	O
(	O
2	O
)	O
:143–169	O
.	O
882	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
pighin	O
,	O
f.	O
,	O
hecker	O
,	O
j.	O
,	O
lischinski	O
,	O
d.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
1998	O
)	O
.	O
synthesizing	O
realistic	O
facial	O
expressions	O
from	O
photographs	O
.	O
in	O
acm	O
siggraph	O
1998	O
conference	O
proceedings	O
,	O
pp	O
.	O
75–84	O
,	O
orlando	O
.	O
pilet	O
,	O
j.	O
,	O
lepetit	O
,	O
v.	O
,	O
and	O
fua	O
,	O
p.	O
(	O
2008	O
)	O
.	O
fast	O
non-rigid	O
surface	B
detection	O
,	O
registration	B
,	O
and	O
realistic	O
augmentation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
76	O
(	O
2	O
)	O
.	O
pinz	O
,	O
a	O
.	O
(	O
2005	O
)	O
.	O
object	O
categorization	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
1	O
(	O
4	O
)	O
:255–353	O
.	O
pizer	O
,	O
s.	O
m.	O
,	O
amburn	O
,	O
e.	O
p.	O
,	O
austin	O
,	O
j.	O
d.	O
,	O
cromartie	O
,	O
r.	O
,	O
geselowitz	O
,	O
a.	O
et	O
al	O
.	O
(	O
1987	O
)	O
.	O
adaptive	B
histogram	O
equalization	O
and	O
its	O
variations	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
39	O
(	O
3	O
)	O
:355–368	O
.	O
platel	O
,	O
b.	O
,	O
balmachnova	O
,	O
e.	O
,	O
florack	O
,	O
l.	O
,	O
and	O
ter	O
haar	O
romeny	O
,	O
b	O
.	O
(	O
2006	O
)	O
.	O
top-points	O
as	O
interest	O
points	B
for	O
image	B
matching	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
418–429	O
.	O
platt	O
,	O
j.	O
c.	O
(	O
2000	O
)	O
.	O
optimal	O
ﬁltering	O
for	O
patterned	O
displays	O
.	O
ieee	O
signal	O
processing	O
let-	O
ters	O
,	O
7	O
(	O
7	O
)	O
:179–180	O
.	O
pock	O
,	O
t.	O
,	O
unger	O
,	O
m.	O
,	O
cremers	O
,	O
d.	O
,	O
and	O
bischof	O
,	O
h.	O
(	O
2008	O
)	O
.	O
fast	O
and	O
exact	O
solution	O
of	O
total	B
variation	I
models	O
on	O
the	O
gpu	O
.	O
in	O
cvpr	O
2008	O
workshop	O
on	O
visual	O
computer	O
vision	O
on	O
gpus	O
(	O
cvgpu	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
poelman	O
,	O
c.	O
j.	O
and	O
kanade	O
,	O
t.	O
(	O
1997	O
)	O
.	O
a	O
paraperspective	O
factorization	B
method	O
for	O
shape	O
and	O
motion	B
recovery	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
3	O
)	O
:206–218	O
.	O
poggio	O
,	O
t.	O
and	O
koch	O
,	O
c.	O
(	O
1985	O
)	O
.	O
ill-posed	O
problems	O
in	O
early	O
vision	O
:	O
from	O
computational	B
theory	I
to	O
analogue	O
networks	O
.	O
proceedings	O
of	O
the	O
royal	O
society	O
of	O
london	O
,	O
b	O
226:303–	O
323.	O
poggio	O
,	O
t.	O
,	O
gamble	O
,	O
e.	O
,	O
and	O
little	O
,	O
j	O
.	O
(	O
1988	O
)	O
.	O
parallel	O
integration	O
of	O
vision	O
modules	O
.	O
sci-	O
ence	O
,	O
242	O
(	O
4877	O
)	O
:436–440	O
.	O
poggio	O
,	O
t.	O
,	O
torre	O
,	O
v.	O
,	O
and	O
koch	O
,	O
c.	O
(	O
1985	O
)	O
.	O
computational	O
vision	O
and	O
regularization	B
theory	O
.	O
nature	O
,	O
317	O
(	O
6035	O
)	O
:314–319	O
.	O
poggio	O
,	O
t.	O
,	O
little	O
,	O
j.	O
,	O
gamble	O
,	O
e.	O
,	O
gillet	O
,	O
w.	O
,	O
geiger	O
,	O
d.	O
et	O
al	O
.	O
(	O
1988	O
)	O
.	O
the	O
mit	O
vision	O
machine	O
.	O
in	O
image	B
understanding	O
workshop	O
,	O
pp	O
.	O
177–198	O
,	O
boston	O
.	O
polana	O
,	O
r.	O
and	O
nelson	O
,	O
r.	O
c.	O
(	O
1997	O
)	O
.	O
detection	B
and	O
recognition	B
of	O
periodic	O
,	O
nonrigid	O
motion	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
23	O
(	O
3	O
)	O
:261–282	O
.	O
pollard	O
,	O
s.	O
b.	O
,	O
mayhew	O
,	O
j.	O
e.	O
w.	O
,	O
and	O
frisby	O
,	O
j.	O
p.	O
(	O
1985	O
)	O
.	O
pmf	O
:	O
a	O
stereo	B
correspondence	O
algorithm	B
using	O
a	O
disparity	O
gradient	O
limit	O
.	O
perception	O
,	O
14:449–470	O
.	O
references	B
883	O
pollefeys	O
,	O
m.	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2002	O
)	O
.	O
from	O
images	O
to	O
3d	O
models	O
.	O
communications	O
of	O
the	O
acm	O
,	O
45	O
(	O
7	O
)	O
:50–55	O
.	O
pollefeys	O
,	O
m.	O
,	O
nist´er	O
,	O
d.	O
,	O
frahm	O
,	O
j.-m.	O
,	O
akbarzadeh	O
,	O
a.	O
,	O
mordohai	O
,	O
p.	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
de-	O
tailed	O
real-time	O
urban	O
3d	O
reconstruction	O
from	O
video	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
78	O
(	O
2-3	O
)	O
:143–167	O
.	O
ponce	O
,	O
j.	O
,	O
hebert	O
,	O
m.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
eds	O
)	O
.	O
(	O
2006	O
)	O
.	O
toward	O
category-level	O
object	O
recognition	B
,	O
springer	O
,	O
new	O
york	O
.	O
ponce	O
,	O
j.	O
,	O
berg	O
,	O
t.	O
,	O
everingham	O
,	O
m.	O
,	O
forsyth	O
,	O
d.	O
,	O
hebert	O
,	O
m.	O
et	O
al	O
.	O
(	O
2006	O
)	O
.	O
dataset	O
issues	O
in	O
object	O
recognition	B
.	O
in	O
ponce	O
,	O
j.	O
,	O
hebert	O
,	O
m.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
eds	O
)	O
,	O
toward	O
category-level	O
object	O
recognition	B
,	O
pp	O
.	O
29–48	O
,	O
springer	O
,	O
new	O
york	O
.	O
pons	O
,	O
j.-p.	O
,	O
keriven	O
,	O
r.	O
,	O
and	O
faugeras	O
,	O
o	O
.	O
(	O
2005	O
)	O
.	O
modelling	O
dynamic	B
scenes	O
by	O
register-	O
ing	O
multi-view	B
image	O
sequences	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
822–827	O
,	O
san	O
diego	O
,	O
ca	O
.	O
pons	O
,	O
j.-p.	O
,	O
keriven	O
,	O
r.	O
,	O
and	O
faugeras	O
,	O
o	O
.	O
(	O
2007	O
)	O
.	O
multi-view	B
stereo	I
reconstruction	O
and	O
scene	O
ﬂow	O
estimation	B
with	O
a	O
global	B
image-based	O
matching	B
score	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
72	O
(	O
2	O
)	O
:179–193	O
.	O
porter	O
,	O
t.	O
and	O
duff	O
,	O
t.	O
(	O
1984	O
)	O
.	O
compositing	B
digital	O
images	O
.	O
computer	O
graphics	O
(	O
sig-	O
graph	O
’	O
84	O
)	O
,	O
18	O
(	O
3	O
)	O
:253–259	O
.	O
portilla	O
,	O
j.	O
and	O
simoncelli	O
,	O
e.	O
p.	O
(	O
2000	O
)	O
.	O
a	O
parametric	B
texture	O
model	O
based	O
on	O
joint	B
statistics	O
of	O
complex	O
wavelet	O
coefﬁcients	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
40	O
(	O
1	O
)	O
:49–	O
71.	O
portilla	O
,	O
j.	O
,	O
strela	O
,	O
v.	O
,	O
wainwright	O
,	O
m.	O
,	O
and	O
simoncelli	O
,	O
e.	O
p.	O
image	B
denoising	O
using	O
scale	O
mixtures	O
of	O
gaussians	O
in	O
the	O
wavelet	O
domain	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
12	O
(	O
11	O
)	O
:1338–1351	O
.	O
(	O
2003	O
)	O
.	O
potetz	O
,	O
b.	O
and	O
lee	O
,	O
t.	O
s.	O
(	O
2008	O
)	O
.	O
efﬁcient	O
belief	B
propagation	I
for	O
higher-order	O
cliques	B
using	O
linear	B
constraint	O
nodes	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
112	O
(	O
1	O
)	O
:39–54	O
.	O
potmesil	O
,	O
m.	O
(	O
1987	O
)	O
.	O
generating	O
octree	B
models	O
of	O
3d	O
objects	O
from	O
their	O
silhouettes	B
in	O
a	O
sequence	O
of	O
images	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
40:1–29	O
.	O
pratt	O
,	O
w.	O
k.	O
edition	O
.	O
(	O
2007	O
)	O
.	O
digital	O
image	O
processing	O
.	O
wiley-interscience	O
,	O
hoboken	O
,	O
nj	O
,	O
4th	O
prazdny	O
,	O
k.	O
(	O
1985	O
)	O
.	O
detection	B
of	O
binocular	O
disparities	O
.	O
biological	O
cybernetics	O
,	O
52:93–99	O
.	O
pritchett	O
,	O
p.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1998	O
)	O
.	O
wide	O
baseline	O
stereo	B
matching	I
.	O
in	O
sixth	O
interna-	O
tional	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
754–760	O
,	O
bombay	O
.	O
884	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
proesmans	O
,	O
m.	O
,	O
van	O
gool	O
,	O
l.	O
,	O
and	O
defoort	O
,	O
f.	O
(	O
1998	O
)	O
.	O
reading	O
between	O
the	O
lines	B
–	O
a	O
method	O
for	O
extracting	O
dynamic	B
3d	O
with	O
texture	O
.	O
in	O
sixth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
1081–1086	O
,	O
bombay	O
.	O
protter	O
,	O
m.	O
and	O
elad	O
,	O
m.	O
(	O
2009	O
)	O
.	O
super	O
resolution	O
with	O
probabilistic	O
motion	B
estimation	I
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
18	O
(	O
8	O
)	O
:1899–1904	O
.	O
pullen	O
,	O
k.	O
and	O
bregler	O
,	O
c.	O
(	O
2002	O
)	O
.	O
motion	B
capture	O
assisted	O
animation	O
:	O
texturing	O
and	O
syn-	O
thesis	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
21	O
(	O
3	O
)	O
:501–508	O
.	O
pulli	O
,	O
k.	O
(	O
1999	O
)	O
.	O
multiview	O
registration	B
for	O
large	O
data	O
sets	O
.	O
in	O
second	O
international	O
confer-	O
ence	O
on	O
3d	O
digital	O
imaging	O
and	O
modeling	B
(	O
3dim	O
’	O
99	O
)	O
,	O
pp	O
.	O
160–168	O
,	O
ottawa	O
,	O
canada	O
.	O
pulli	O
,	O
k.	O
,	O
abi-rached	O
,	O
h.	O
,	O
duchamp	O
,	O
t.	O
,	O
shapiro	O
,	O
l.	O
,	O
and	O
stuetzle	O
,	O
w.	O
(	O
1998	O
)	O
.	O
acquisi-	O
tion	B
and	O
visualization	O
of	O
colored	O
3d	O
objects	O
.	O
in	O
international	O
conference	O
on	O
pattern	O
recognition	B
(	O
icpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
11–15	O
.	O
quack	O
,	O
t.	O
,	O
leibe	O
,	O
b.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2008	O
)	O
.	O
world-scale	O
mining	O
of	O
objects	O
and	O
events	O
from	O
community	O
photo	O
collections	O
.	O
in	O
conference	O
on	O
image	B
and	O
video	B
retrieval	O
,	O
pp	O
.	O
47–56	O
,	O
niagara	O
falls	O
.	O
quam	O
,	O
l.	O
h.	O
(	O
1984	O
)	O
.	O
hierarchical	B
warp	O
stereo	B
.	O
in	O
image	B
understanding	O
workshop	O
,	O
pp	O
.	O
149–155	O
,	O
new	O
orleans	O
.	O
quan	O
,	O
l.	O
and	O
lan	O
,	O
z	O
.	O
(	O
1999	O
)	O
.	O
linear	B
n-point	O
camera	B
pose	O
determination	O
.	O
ieee	O
transac-	O
tions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
21	O
(	O
8	O
)	O
:774–780	O
.	O
quan	O
,	O
l.	O
and	O
mohr	O
,	O
r.	O
(	O
1989	O
)	O
.	O
determining	O
perspective	B
structures	O
using	O
hierarchical	O
hough	O
transform	B
.	O
pattern	O
recognition	B
letters	O
,	O
9	O
(	O
4	O
)	O
:279–286	O
.	O
rabinovich	O
,	O
a.	O
,	O
vedaldi	O
,	O
a.	O
,	O
galleguillos	O
,	O
c.	O
,	O
wiewiora	O
,	O
e.	O
,	O
and	O
belongie	O
,	O
s.	O
(	O
2007	O
)	O
.	O
objects	O
in	O
context	B
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
rademacher	O
,	O
p.	O
and	O
bishop	O
,	O
g.	O
(	O
1998	O
)	O
.	O
multiple-center-of-projection	O
images	O
.	O
in	O
acm	O
siggraph	O
1998	O
conference	O
proceedings	O
,	O
pp	O
.	O
199–206	O
,	O
orlando	O
.	O
raginsky	O
,	O
m.	O
and	O
lazebnik	O
,	O
s.	O
(	O
2009	O
)	O
.	O
locality-sensitive	O
binary	O
codes	O
from	O
shift-invariant	O
kernels	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
raman	O
,	O
s.	O
and	O
chaudhuri	O
,	O
s.	O
(	O
2007	O
)	O
.	O
a	O
matte-less	O
,	O
variational	O
approach	O
to	O
automatic	B
scene	O
compositing	B
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
raman	O
,	O
s.	O
and	O
chaudhuri	O
,	O
s.	O
(	O
2009	O
)	O
.	O
bilateral	B
ﬁlter	I
based	O
compositing	B
for	O
variable	O
expo-	O
sure	O
photography	O
.	O
in	O
proceedings	O
of	O
eurographics	O
2009.	O
references	B
885	O
ramanan	O
,	O
d.	O
and	O
baker	O
,	O
s.	O
(	O
2009	O
)	O
.	O
local	B
distance	O
functions	O
:	O
a	O
taxonomy	B
,	O
new	O
algorithms	O
,	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
and	O
an	O
evaluation	B
.	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
ramanan	O
,	O
d.	O
,	O
forsyth	O
,	O
d.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2005	O
)	O
.	O
strike	O
a	O
pose	O
:	O
tracking	O
people	O
by	O
ﬁnding	O
stylized	O
poses	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
271–278	O
,	O
san	O
diego	O
,	O
ca	O
.	O
ramanarayanan	O
,	O
g.	O
and	O
bala	O
,	O
k.	O
(	O
2007	O
)	O
.	O
constrained	B
texture	O
synthesis	O
via	O
energy	O
mini-	O
mization	O
.	O
ieee	O
transactions	O
on	O
visualization	O
and	O
computer	O
graphics	O
,	O
13	O
(	O
1	O
)	O
:167–178	O
.	O
ramer	O
,	O
u	O
.	O
(	O
1972	O
)	O
.	O
an	O
iterative	B
procedure	O
for	O
the	O
polygonal	O
approximation	O
of	O
plane	O
curves	O
.	O
computer	O
graphics	O
and	O
image	B
processing	O
,	O
1	O
(	O
3	O
)	O
:244–256	O
.	O
ramnath	O
,	O
k.	O
,	O
koterba	O
,	O
s.	O
,	O
xiao	O
,	O
j.	O
,	O
hu	O
,	O
c.	O
,	O
matthews	O
,	O
i.	O
,	O
baker	O
,	O
s.	O
,	O
cohn	O
,	O
j.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
2008	O
)	O
.	O
multi-view	B
aam	O
ﬁtting	O
and	O
construction	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
76	O
(	O
2	O
)	O
:183–204	O
.	O
raskar	O
,	O
r.	O
and	O
tumblin	O
,	O
j	O
.	O
(	O
2010	O
)	O
.	O
computational	O
photography	O
:	O
mastering	O
new	O
tech-	O
niques	O
for	O
lenses	O
,	O
lighting	B
,	O
and	O
sensors	O
.	O
a	O
k	O
peters	O
,	O
wellesley	O
,	O
massachusetts	O
.	O
raskar	O
,	O
r.	O
,	O
tan	O
,	O
k.-h.	O
,	O
feris	O
,	O
r.	O
,	O
yu	O
,	O
j.	O
,	O
and	O
turk	O
,	O
m.	O
(	O
2004	O
)	O
.	O
non-photorealistic	O
camera	O
:	O
depth	O
edge	O
detection	B
and	O
stylized	O
rendering	B
using	O
multi-ﬂash	O
imaging	O
.	O
acm	O
transac-	O
tions	O
on	O
graphics	O
,	O
23	O
(	O
3	O
)	O
:679–688	O
.	O
rav-acha	O
,	O
a.	O
,	O
kohli	O
,	O
p.	O
,	O
fitzgibbon	O
,	O
a.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
2008	O
)	O
.	O
unwrap	O
mosaics	O
:	O
a	O
new	O
representation	O
for	O
video	O
editing	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
27	O
(	O
3	O
)	O
.	O
rav-acha	O
,	O
a.	O
,	O
pritch	O
,	O
y.	O
,	O
lischinski	O
,	O
d.	O
,	O
and	O
peleg	O
,	O
s.	O
(	O
2005	O
)	O
.	O
dynamosaics	O
:	O
video	B
mo-	O
saics	O
with	O
non-chronological	O
time	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
58–65	O
,	O
san	O
diego	O
,	O
ca	O
.	O
ravikumar	O
,	O
p.	O
,	O
agarwal	O
,	O
a.	O
,	O
and	O
wainwright	O
,	O
m.	O
j	O
.	O
(	O
2008	O
)	O
.	O
message-passing	O
for	O
graph-	O
structured	O
linear	B
programs	O
:	O
proximal	O
projections	B
,	O
convergence	O
and	O
rounding	O
schemes	O
.	O
in	O
international	O
conference	O
on	O
machine	O
learning	O
,	O
pp	O
.	O
800–807	O
.	O
ray	O
,	O
s.	O
f.	O
(	O
2002	O
)	O
.	O
applied	O
photographic	O
optics	B
.	O
focal	O
press	O
,	O
oxford	O
,	O
3rd	O
edition	O
.	O
rehg	O
,	O
j.	O
and	O
kanade	O
,	O
t.	O
(	O
1994	O
)	O
.	O
visual	O
tracking	O
of	O
high	O
dof	O
articulated	O
structures	O
:	O
an	O
application	O
to	O
human	O
hand	O
tracking	O
.	O
in	O
third	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
94	O
)	O
,	O
pp	O
.	O
35–46	O
,	O
stockholm	O
,	O
sweden	O
.	O
rehg	O
,	O
j.	O
and	O
witkin	O
,	O
a	O
.	O
(	O
1991	O
)	O
.	O
visual	O
tracking	O
with	O
deformation	O
models	O
.	O
in	O
ieee	O
inter-	O
national	O
conference	O
on	O
robotics	O
and	O
automation	O
,	O
pp	O
.	O
844–850	O
,	O
sacramento	O
.	O
rehg	O
,	O
j.	O
,	O
morris	O
,	O
d.	O
d.	O
,	O
and	O
kanade	O
,	O
t.	O
ticulated	O
objects	O
using	O
two-	O
and	O
three-dimensional	O
models	O
.	O
robotics	O
research	O
,	O
22	O
(	O
6	O
)	O
:393–418	O
.	O
(	O
2003	O
)	O
.	O
ambiguities	O
in	O
visual	O
tracking	O
of	O
ar-	O
international	O
journal	O
of	O
886	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
reichenbach	O
,	O
s.	O
e.	O
,	O
park	O
,	O
s.	O
k.	O
,	O
and	O
narayanswamy	O
,	O
r.	O
(	O
1991	O
)	O
.	O
characterizing	O
digital	O
image	O
acquisition	O
devices	O
.	O
optical	O
engineering	O
,	O
30	O
(	O
2	O
)	O
:170–177	O
.	O
reinhard	O
,	O
e.	O
,	O
stark	O
,	O
m.	O
,	O
shirley	O
,	O
p.	O
,	O
and	O
ferwerda	O
,	O
j	O
.	O
(	O
2002	O
)	O
.	O
photographic	O
tone	O
repro-	O
duction	O
for	O
digital	O
images	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2002	O
)	O
,	O
21	O
(	O
3	O
)	O
:267–276	O
.	O
reinhard	O
,	O
e.	O
,	O
ward	O
,	O
g.	O
,	O
pattanaik	O
,	O
s.	O
,	O
and	O
debevec	O
,	O
p.	O
(	O
2005	O
)	O
.	O
high	B
dynamic	I
range	I
imaging	O
:	O
acquisition	O
,	O
display	O
,	O
and	O
image-based	B
lighting	O
.	O
morgan	O
kaufmann	O
.	O
rhemann	O
,	O
c.	O
,	O
rother	O
,	O
c.	O
,	O
and	O
gelautz	O
,	O
m.	O
(	O
2008	O
)	O
.	O
improving	O
color	B
modeling	O
for	O
alpha	O
matting	B
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2008	O
)	O
,	O
leeds	O
.	O
rhemann	O
,	O
c.	O
,	O
rother	O
,	O
c.	O
,	O
rav-acha	O
,	O
a.	O
,	O
and	O
sharp	O
,	O
t.	O
(	O
2008	O
)	O
.	O
high	O
resolution	O
matting	B
via	O
interactive	B
trimap	O
segmentation	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
rhemann	O
,	O
c.	O
,	O
rother	O
,	O
c.	O
,	O
wang	O
,	O
j.	O
,	O
gelautz	O
,	O
m.	O
,	O
kohli	O
,	O
p.	O
,	O
and	O
rott	O
,	O
p.	O
(	O
2009	O
)	O
.	O
a	O
per-	O
ceptually	O
motivated	O
online	O
benchmark	O
for	O
image	O
matting	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
richardson	O
,	O
i.	O
e.	O
g.	O
(	O
2003	O
)	O
.	O
h.264	O
and	O
mpeg-4	O
video	B
compression	I
:	O
video	B
coding	O
for	O
next	O
generation	O
multimedia	O
.	O
wiley	O
.	O
rioul	O
,	O
o.	O
and	O
vetterli	O
,	O
m.	O
(	O
1991	O
)	O
.	O
wavelets	O
and	O
signal	O
processing	O
.	O
ieee	O
signal	O
processing	O
magazine	O
,	O
8	O
(	O
4	O
)	O
:14–38	O
.	O
rioux	O
,	O
m.	O
and	O
bird	O
,	O
t.	O
(	O
1993	O
)	O
.	O
white	O
laser	O
,	O
synced	O
scan	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
13	O
(	O
3	O
)	O
:15–17	O
.	O
rioux	O
,	O
m.	O
,	O
bechthold	O
,	O
g.	O
,	O
taylor	O
,	O
d.	O
,	O
and	O
duggan	O
,	O
m.	O
(	O
1987	O
)	O
.	O
design	O
of	O
a	O
large	O
depth	O
of	O
view	O
three-dimensional	O
camera	B
for	O
robot	O
vision	O
.	O
optical	O
engineering	O
,	O
26	O
(	O
12	O
)	O
:1245–	O
1250.	O
riseman	O
,	O
e.	O
m.	O
and	O
arbib	O
,	O
m.	O
a	O
.	O
(	O
1977	O
)	O
.	O
computational	O
techniques	O
in	O
the	O
visual	O
segmen-	O
tation	O
of	O
static	O
scenes	O
.	O
computer	O
graphics	O
and	O
image	B
processing	O
,	O
6	O
(	O
3	O
)	O
:221–276	O
.	O
ritter	O
,	O
g.	O
x.	O
and	O
wilson	O
,	O
j.	O
n.	O
(	O
2000	O
)	O
.	O
handbook	O
of	O
computer	O
vision	O
algorithms	O
in	O
image	B
algebra	O
.	O
crc	O
press	O
,	O
boca	O
raton	O
,	O
2nd	O
edition	O
.	O
robert	O
,	O
c.	O
p.	O
(	O
2007	O
)	O
.	O
the	O
bayesian	O
choice	O
:	O
from	O
decision-theoretic	O
foundations	O
to	O
computational	O
implementation	O
.	O
springer-verlag	O
,	O
new	O
york	O
.	O
roberts	O
,	O
l.	O
g.	O
(	O
1965	O
)	O
.	O
machine	O
perception	O
of	O
three-dimensional	O
solids	O
.	O
in	O
tippett	O
,	O
j.	O
t.	O
,	O
borkowitz	O
,	O
d.	O
a.	O
,	O
clapp	O
,	O
l.	O
c.	O
,	O
koester	O
,	O
c.	O
j.	O
,	O
and	O
vanderburgh	O
jr.	O
,	O
a	O
.	O
(	O
eds	O
)	O
,	O
opti-	O
cal	O
and	O
electro-optical	O
information	O
processing	O
,	O
pp	O
.	O
159–197	O
,	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
references	B
887	O
robertson	O
,	O
d.	O
and	O
cipolla	O
,	O
r.	O
(	O
2004	O
)	O
.	O
an	O
image-based	B
system	O
for	O
urban	O
navigation	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
,	O
pp	O
.	O
656–665	O
,	O
kingston	O
.	O
robertson	O
,	O
d.	O
p.	O
and	O
cipolla	O
,	O
r.	O
(	O
2002	O
)	O
.	O
building	O
architectural	O
models	O
from	O
many	O
views	O
using	O
map	O
constraints	O
.	O
in	O
seventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2002	O
)	O
,	O
pp	O
.	O
155–169	O
,	O
copenhagen	O
.	O
robertson	O
,	O
d.	O
p.	O
and	O
cipolla	O
,	O
r.	O
(	O
2009	O
)	O
.	O
architectural	O
modelling	O
.	O
in	O
varga	O
,	O
m	O
.	O
(	O
ed	O
.	O
)	O
,	O
practical	O
image	B
processing	O
and	O
computer	O
vision	O
,	O
john	O
wiley	O
.	O
robertson	O
,	O
n.	O
and	O
reid	O
,	O
i	O
.	O
(	O
2006	O
)	O
.	O
a	O
general	O
method	O
for	O
human	O
activity	B
recognition	I
in	O
video	B
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-3	O
)	O
:232–248	O
.	O
roble	O
,	O
d.	O
(	O
1999	O
)	O
.	O
vision	O
in	O
ﬁlm	O
and	O
special	O
effects	O
.	O
computer	O
graphics	O
,	O
33	O
(	O
4	O
)	O
:58–60	O
.	O
roble	O
,	O
d.	O
and	O
zafar	O
,	O
n.	O
b.	O
computer	O
,	O
42	O
(	O
7	O
)	O
:35–41	O
.	O
(	O
2009	O
)	O
.	O
don	O
’	O
t	O
trust	O
your	O
eyes	O
:	O
cutting-edge	O
visual	B
effects	I
.	O
rogez	O
,	O
g.	O
,	O
rihan	O
,	O
j.	O
,	O
ramalingam	O
,	O
s.	O
,	O
orrite	O
,	O
c.	O
,	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2008	O
)	O
.	O
randomized	O
trees	O
for	O
human	O
pose	O
detection	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
rogmans	O
,	O
s.	O
,	O
lu	O
,	O
j.	O
,	O
bekaert	O
,	O
p.	O
,	O
and	O
lafruit	O
,	O
g.	O
(	O
2009	O
)	O
.	O
real-time	O
stereo-based	O
views	O
synthesis	O
algorithms	O
:	O
a	O
uniﬁed	O
framework	O
and	O
evaluation	B
on	O
commodity	O
gpus	O
.	O
signal	O
processing	O
:	O
image	B
communication	O
,	O
24:49–64	O
.	O
rohr	O
,	O
k.	O
(	O
1994	O
)	O
.	O
towards	O
model-based	B
recognition	O
of	O
human	O
movements	O
in	O
image	B
se-	O
quences	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
59	O
(	O
1	O
)	O
:94–115	O
.	O
rom´an	O
,	O
a.	O
and	O
lensch	O
,	O
h.	O
p.	O
a	O
.	O
(	O
2006	O
)	O
.	O
automatic	B
multiperspective	O
images	O
.	O
in	O
euro-	O
graphics	O
symposium	O
on	O
rendering	B
,	O
pp	O
.	O
83–92	O
.	O
rom´an	O
,	O
a.	O
,	O
garg	O
,	O
g.	O
,	O
and	O
levoy	O
,	O
m.	O
(	O
2004	O
)	O
.	O
interactive	B
design	O
of	O
multi-perspective	O
images	O
for	O
visualizing	O
urban	O
landscapes	O
.	O
in	O
ieee	O
visualization	O
2004	O
,	O
pp	O
.	O
537–544	O
,	O
minneapo-	O
lis	O
.	O
romdhani	O
,	O
s.	O
and	O
vetter	O
,	O
t.	O
(	O
2003	O
)	O
.	O
efﬁcient	O
,	O
robust	B
and	O
accurate	O
ﬁtting	O
of	O
a	O
3d	O
morphable	O
model	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
59–66	O
,	O
nice	O
,	O
france	O
.	O
romdhani	O
,	O
s.	O
,	O
torr	O
,	O
p.	O
h.	O
s.	O
,	O
sch¨olkopf	O
,	O
b.	O
,	O
and	O
blake	O
,	O
a	O
.	O
(	O
2001	O
)	O
.	O
computationally	O
ef-	O
ﬁcient	O
face	B
detection	O
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
695–700	O
,	O
vancouver	O
,	O
canada	O
.	O
rosales	O
,	O
r.	O
and	O
sclaroff	O
,	O
s.	O
inferring	O
body	B
pose	O
without	O
tracking	O
body	B
parts	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
721–727	O
,	O
hilton	O
head	B
island	O
.	O
(	O
2000	O
)	O
.	O
888	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
rosenfeld	O
,	O
a	O
.	O
(	O
1980	O
)	O
.	O
quadtrees	O
and	O
pyramids	O
for	O
pattern	O
recognition	B
and	O
image	B
process-	O
ing	O
.	O
in	O
fifth	O
international	O
conference	O
on	O
pattern	O
recognition	B
(	O
icpr	O
’	O
80	O
)	O
,	O
pp	O
.	O
802–809	O
,	O
miami	O
beach	O
.	O
rosenfeld	O
,	O
a	O
.	O
(	O
ed.	O
)	O
.	O
(	O
1984	O
)	O
.	O
multiresolution	O
image	B
processing	O
and	O
analysis	O
,	O
springer-	O
verlag	O
,	O
new	O
york	O
.	O
rosenfeld	O
,	O
a.	O
and	O
davis	O
,	O
l.	O
s.	O
(	O
1979	O
)	O
.	O
image	B
segmentation	O
and	O
image	B
models	O
.	O
proceed-	O
ings	O
of	O
the	O
ieee	O
,	O
67	O
(	O
5	O
)	O
:764–772	O
.	O
rosenfeld	O
,	O
a.	O
and	O
kak	O
,	O
a.	O
c.	O
(	O
1976	O
)	O
.	O
digital	O
picture	O
processing	O
.	O
academic	O
press	O
,	O
new	O
york	O
.	O
rosenfeld	O
,	O
a.	O
and	O
pfaltz	O
,	O
j.	O
l.	O
(	O
1966	O
)	O
.	O
sequential	O
operations	O
in	O
digital	O
picture	O
processing	O
.	O
journal	O
of	O
the	O
acm	O
,	O
13	O
(	O
4	O
)	O
:471–494	O
.	O
rosenfeld	O
,	O
a.	O
,	O
hummel	O
,	O
r.	O
a.	O
,	O
and	O
zucker	O
,	O
s.	O
w.	O
(	O
1976	O
)	O
.	O
scene	O
labeling	O
by	O
relaxation	O
operations	O
.	O
ieee	O
transactions	O
on	O
systems	O
,	O
man	O
,	O
and	O
cybernetics	O
,	O
smc-6:420–433	O
.	O
rosten	O
,	O
e.	O
and	O
drummond	O
,	O
t.	O
(	O
2005	O
)	O
.	O
fusing	O
points	B
and	O
lines	B
for	O
high	O
performance	O
track-	O
ing	O
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
1508–	O
1515	O
,	O
beijing	O
,	O
china	O
.	O
rosten	O
,	O
e.	O
and	O
drummond	O
,	O
t.	O
(	O
2006	O
)	O
.	O
machine	O
learning	O
for	O
high-speed	O
corner	O
detection	B
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
430–443	O
.	O
roth	O
,	O
s.	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2007a	O
)	O
.	O
on	O
the	O
spatial	O
statistics	O
of	O
optical	B
ﬂow	I
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
74	O
(	O
1	O
)	O
:33–50	O
.	O
roth	O
,	O
s.	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2007b	O
)	O
.	O
steerable	B
random	O
ﬁelds	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
roth	O
,	O
s.	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2009	O
)	O
.	O
fields	O
of	O
experts	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
82	O
(	O
2	O
)	O
:205–229	O
.	O
rother	O
,	O
c.	O
(	O
2002	O
)	O
.	O
a	O
new	O
approach	O
for	O
vanishing	O
point	O
detection	O
in	O
architectural	O
environ-	O
ments	O
.	O
image	B
and	O
vision	O
computing	O
,	O
20	O
(	O
9-10	O
)	O
:647–656	O
.	O
rother	O
,	O
c.	O
(	O
2003	O
)	O
.	O
linear	B
multi-view	O
reconstruction	O
of	O
points	B
,	O
lines	B
,	O
planes	B
and	O
cameras	O
using	O
a	O
reference	O
plane	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
1210–1217	O
,	O
nice	O
,	O
france	O
.	O
rother	O
,	O
c.	O
and	O
carlsson	O
,	O
s.	O
(	O
2002	O
)	O
.	O
linear	B
multi	O
view	O
reconstruction	O
and	O
camera	B
recovery	O
using	O
a	O
reference	O
plane	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
49	O
(	O
2/3	O
)	O
:117–141	O
.	O
rother	O
,	O
c.	O
,	O
kolmogorov	O
,	O
v.	O
,	O
and	O
blake	O
,	O
a	O
.	O
(	O
2004	O
)	O
.	O
“	O
grabcut	O
”	O
—interactive	O
foreground	O
extraction	O
using	O
iterated	O
graph	B
cuts	I
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2004	O
)	O
,	O
23	O
(	O
3	O
)	O
:309–314	O
.	O
references	B
889	O
rother	O
,	O
c.	O
,	O
bordeaux	O
,	O
l.	O
,	O
hamadi	O
,	O
y.	O
,	O
and	O
blake	O
,	O
a	O
.	O
(	O
2006	O
)	O
.	O
autocollage	O
.	O
acm	O
transac-	O
tions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:847–852	O
.	O
rother	O
,	O
c.	O
,	O
kohli	O
,	O
p.	O
,	O
feng	O
,	O
w.	O
,	O
and	O
jia	O
,	O
j	O
.	O
(	O
2009	O
)	O
.	O
minimizing	O
sparse	B
higher	O
order	B
energy	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
functions	O
of	O
discrete	B
variables	O
.	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
rother	O
,	O
c.	O
,	O
kolmogorov	O
,	O
v.	O
,	O
lempitsky	O
,	O
v.	O
,	O
and	O
szummer	O
,	O
m.	O
(	O
2007	O
)	O
.	O
optimizing	O
binary	O
mrfs	O
via	O
extended	O
roof	O
duality	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
rother	O
,	O
c.	O
,	O
kumar	O
,	O
s.	O
,	O
kolmogorov	O
,	O
v.	O
,	O
and	O
blake	O
,	O
a.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
589–596	O
,	O
san	O
diego	O
,	O
ca	O
.	O
(	O
2005	O
)	O
.	O
digital	O
tapestry	O
.	O
rothganger	O
,	O
f.	O
,	O
lazebnik	O
,	O
s.	O
,	O
schmid	O
,	O
c.	O
,	O
and	O
ponce	O
,	O
j	O
.	O
(	O
2006	O
)	O
.	O
3d	O
object	O
modeling	B
and	O
recognition	B
using	O
local	B
afﬁne-invariant	O
image	B
descriptors	O
and	O
multi-view	B
spatial	O
constraints	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
66	O
(	O
3	O
)	O
:231–259	O
.	O
rousseeuw	O
,	O
p.	O
j	O
.	O
(	O
1984	O
)	O
.	O
least	O
median	O
of	O
squares	O
regresssion	O
.	O
journal	O
of	O
the	O
american	O
statistical	O
association	O
,	O
79:871–880	O
.	O
rousseeuw	O
,	O
p.	O
j.	O
and	O
leroy	O
,	O
a.	O
m.	O
(	O
1987	O
)	O
.	O
robust	B
regression	O
and	O
outlier	O
detection	B
.	O
wiley	O
,	O
new	O
york	O
.	O
rousson	O
,	O
m.	O
and	O
paragios	O
,	O
n.	O
(	O
2008	O
)	O
.	O
prior	B
knowledge	O
,	O
level	O
set	O
representations	O
,	O
and	O
visual	O
grouping	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
76	O
(	O
3	O
)	O
:231–243	O
.	O
roweis	O
,	O
s.	O
(	O
1998	O
)	O
.	O
em	O
algorithms	O
for	O
pca	O
and	O
spca	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
,	O
pp	O
.	O
626–632	O
.	O
rowland	O
,	O
d.	O
a.	O
and	O
perrett	O
,	O
d.	O
i	O
.	O
(	O
1995	O
)	O
.	O
manipulating	O
facial	O
appearance	O
through	O
shape	O
and	O
color	B
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
15	O
(	O
5	O
)	O
:70–76	O
.	O
rowley	O
,	O
h.	O
a.	O
,	O
baluja	O
,	O
s.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
1998a	O
)	O
.	O
neural	O
network-based	O
face	B
detection	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
20	O
(	O
1	O
)	O
:23–38	O
.	O
rowley	O
,	O
h.	O
a.	O
,	O
baluja	O
,	O
s.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
1998b	O
)	O
.	O
rotation	O
invariant	O
neural	O
network-	O
based	O
face	B
detection	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
38–44	O
,	O
santa	O
barbara	O
.	O
roy	O
,	O
s.	O
and	O
cox	O
,	O
i.	O
j	O
.	O
(	O
1998	O
)	O
.	O
a	O
maximum-ﬂow	O
formulation	O
of	O
the	O
n-camera	O
stereo	B
corre-	O
spondence	O
problem	O
.	O
in	O
sixth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
492–499	O
,	O
bombay	O
.	O
rozenfeld	O
,	O
s.	O
,	O
shimshoni	O
,	O
i.	O
,	O
and	O
lindenbaum	O
,	O
m.	O
(	O
2007	O
)	O
.	O
dense	O
mirroring	O
surface	B
re-	O
covery	O
from	O
1d	O
homographies	O
and	O
sparse	B
correspondences	O
.	O
in	O
ieee	O
computer	O
society	O
890	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
rubner	O
,	O
y.	O
,	O
tomasi	O
,	O
c.	O
,	O
and	O
guibas	O
,	O
l.	O
j	O
.	O
(	O
2000	O
)	O
.	O
the	O
earth	O
mover	O
’	O
s	O
distance	O
as	O
a	O
metric	O
for	O
image	O
retrieval	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
40	O
(	O
2	O
)	O
:99–121	O
.	O
rumelhart	O
,	O
d.	O
e.	O
,	O
hinton	O
,	O
g.	O
e.	O
,	O
and	O
williams	O
,	O
r.	O
j	O
.	O
(	O
1986	O
)	O
.	O
learning	B
internal	O
representa-	O
tions	O
by	O
error	O
propagation	O
.	O
in	O
rumelhart	O
,	O
d.	O
e.	O
,	O
mcclelland	O
,	O
j.	O
l.	O
,	O
and	O
the	O
pdp	O
research	O
group	O
(	O
eds	O
)	O
,	O
parallel	O
distributed	O
processing	O
:	O
explorations	O
in	O
the	O
microstructure	O
of	O
cog-	O
nition	O
,	O
pp	O
.	O
318–362	O
,	O
bradford	O
books	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
rusinkiewicz	O
,	O
s.	O
and	O
levoy	O
,	O
m.	O
(	O
2000	O
)	O
.	O
qsplat	O
:	O
a	O
multiresolution	O
point	O
rendering	O
system	O
for	O
large	O
meshes	O
.	O
in	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
343–352	O
.	O
russ	O
,	O
j.	O
c.	O
(	O
2007	O
)	O
.	O
the	O
image	B
processing	O
handbook	O
.	O
crc	O
press	O
,	O
boca	O
raton	O
,	O
5th	O
edition	O
.	O
russell	O
,	O
b.	O
,	O
efros	O
,	O
a.	O
,	O
sivic	O
,	O
j.	O
,	O
freeman	O
,	O
w.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2006	O
)	O
.	O
using	O
multiple	O
segmentations	O
to	O
discover	O
objects	O
and	O
their	O
extent	O
in	O
image	B
collections	O
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
1605–1612	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
russell	O
,	O
b.	O
c.	O
,	O
torralba	O
,	O
a.	O
,	O
murphy	O
,	O
k.	O
p.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2008	O
)	O
.	O
labelme	O
:	O
a	O
database	O
and	O
web-based	O
tool	O
for	O
image	O
annotation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
77	O
(	O
1-3	O
)	O
:157–173	O
.	O
russell	O
,	O
b.	O
c.	O
,	O
torralba	O
,	O
a.	O
,	O
liu	O
,	O
c.	O
,	O
fergus	O
,	O
r.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2007	O
)	O
.	O
object	O
recog-	O
nition	O
by	O
scene	O
alignment	B
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
ruzon	O
,	O
m.	O
a.	O
and	O
tomasi	O
,	O
c.	O
(	O
2000	O
)	O
.	O
alpha	O
estimation	O
in	O
natural	B
images	O
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
18–25	O
,	O
hilton	O
head	B
island	O
.	O
ruzon	O
,	O
m.	O
a.	O
and	O
tomasi	O
,	O
c.	O
(	O
2001	O
)	O
.	O
edge	O
,	O
junction	O
,	O
and	O
corner	O
detection	B
using	O
color	B
distributions	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
23	O
(	O
11	O
)	O
:1281–1295	O
.	O
ryan	O
,	O
t.	O
w.	O
,	O
gray	O
,	O
r.	O
t.	O
,	O
and	O
hunt	O
,	O
b.	O
r.	O
(	O
1980	O
)	O
.	O
prediction	O
of	O
correlation	O
errors	O
in	O
stereo-	O
pair	O
images	O
.	O
optical	O
engineering	O
,	O
19	O
(	O
3	O
)	O
:312–322	O
.	O
saad	O
,	O
y	O
.	O
(	O
2003	O
)	O
.	O
iterative	B
methods	O
for	O
sparse	O
linear	B
systems	O
.	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
,	O
second	O
edition	O
.	O
saint-marc	O
,	O
p.	O
,	O
chen	O
,	O
j.	O
s.	O
,	O
and	O
medioni	O
,	O
g.	O
(	O
1991	O
)	O
.	O
adaptive	B
smoothing	O
:	O
a	O
general	O
tool	O
for	O
early	O
vision	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
13	O
(	O
6	O
)	O
:514–529	O
.	O
references	B
891	O
saito	O
,	O
h.	O
and	O
kanade	O
,	O
t.	O
(	O
1999	O
)	O
.	O
shape	O
reconstruction	O
in	O
projective	B
grid	O
space	O
from	O
large	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
number	O
of	O
images	O
.	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
99	O
)	O
,	O
pp	O
.	O
49–54	O
,	O
fort	O
collins	O
.	O
samet	O
,	O
h.	O
(	O
1989	O
)	O
.	O
the	O
design	O
and	O
analysis	O
of	O
spatial	O
data	O
structures	O
.	O
addison-wesley	O
,	O
reading	O
,	O
massachusetts	O
.	O
sander	O
,	O
p.	O
t.	O
and	O
zucker	O
,	O
s.	O
w.	O
(	O
1990	O
)	O
.	O
inferring	O
surface	B
trace	O
and	O
differential	O
structure	O
from	O
3-d	O
images	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12	O
(	O
9	O
)	O
:833–854	O
.	O
sapiro	O
,	O
g.	O
(	O
2001	O
)	O
.	O
geometric	B
partial	O
differential	O
equations	B
and	O
image	B
analysis	O
.	O
cam-	O
bridge	O
university	O
press	O
.	O
sato	O
,	O
y.	O
and	O
ikeuchi	O
,	O
k.	O
(	O
1996	O
)	O
.	O
reﬂectance	B
analysis	O
for	O
3d	O
computer	O
graphics	O
model	O
generation	O
.	O
graphical	O
models	O
and	O
image	B
processing	O
,	O
58	O
(	O
5	O
)	O
:437–451	O
.	O
sato	O
,	O
y.	O
,	O
wheeler	O
,	O
m.	O
,	O
and	O
ikeuchi	O
,	O
k.	O
(	O
1997	O
)	O
.	O
object	O
shape	O
and	O
reﬂectance	B
modeling	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
379–387	O
,	O
from	O
observation	O
.	O
los	O
angeles	O
.	O
savarese	O
,	O
s.	O
and	O
fei-fei	O
,	O
l.	O
(	O
2007	O
)	O
.	O
3d	O
generic	O
object	O
categorization	O
,	O
localization	O
and	O
pose	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
estimation	B
.	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
savarese	O
,	O
s.	O
and	O
fei-fei	O
,	O
l.	O
(	O
2008	O
)	O
.	O
view	O
synthesis	O
for	O
recognizing	O
unseen	O
poses	O
of	O
object	O
classes	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
602–615	O
,	O
marseilles	O
.	O
savarese	O
,	O
s.	O
,	O
chen	O
,	O
m.	O
,	O
and	O
perona	O
,	O
p.	O
(	O
2005	O
)	O
.	O
local	B
shape	O
from	O
mirror	O
reﬂections	B
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
64	O
(	O
1	O
)	O
:31–67	O
.	O
savarese	O
,	O
s.	O
,	O
andreetto	O
,	O
m.	O
,	O
rushmeier	O
,	O
h.	O
e.	O
,	O
bernardini	O
,	O
f.	O
,	O
and	O
perona	O
,	O
p.	O
(	O
2007	O
)	O
.	O
3d	O
re-	O
construction	O
by	O
shadow	O
carving	O
:	O
theory	O
and	O
practical	O
evaluation	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
71	O
(	O
3	O
)	O
:305–336	O
.	O
sawhney	O
,	O
h.	O
s.	O
(	O
1994	O
)	O
.	O
simplifying	O
motion	B
and	O
structure	O
analysis	O
using	O
planar	O
parallax	O
and	O
image	B
warping	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
pattern	O
recognition	B
(	O
icpr	O
’	O
94	O
)	O
,	O
pp	O
.	O
403–408	O
,	O
jerusalem	O
,	O
israel	O
.	O
sawhney	O
,	O
h.	O
s.	O
and	O
ayer	O
,	O
s.	O
(	O
1996	O
)	O
.	O
compact	O
representation	O
of	O
videos	O
through	O
domi-	O
nant	O
multiple	B
motion	O
estimation	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
18	O
(	O
8	O
)	O
:814–830	O
.	O
sawhney	O
,	O
h.	O
s.	O
and	O
hanson	O
,	O
a.	O
r.	O
(	O
1991	O
)	O
.	O
identiﬁcation	O
and	O
3d	O
description	O
of	O
‘	O
shallow	O
’	O
environmental	O
structure	O
over	O
a	O
sequence	O
of	O
images	O
.	O
in	O
ieee	O
computer	O
society	O
con-	O
892	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
91	O
)	O
,	O
pp	O
.	O
179–185	O
,	O
maui	O
,	O
hawaii	O
.	O
sawhney	O
,	O
h.	O
s.	O
and	O
kumar	O
,	O
r.	O
(	O
1999	O
)	O
.	O
true	O
multi-image	O
alignment	B
and	O
its	O
application	O
to	O
mosaicing	O
and	O
lens	O
distortion	O
correction	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
21	O
(	O
3	O
)	O
:235–243	O
.	O
sawhney	O
,	O
h.	O
s.	O
,	O
kumar	O
,	O
r.	O
,	O
gendel	O
,	O
g.	O
,	O
bergen	O
,	O
j.	O
,	O
dixon	O
,	O
d.	O
,	O
and	O
paragano	O
,	O
v.	O
(	O
1998	O
)	O
.	O
videobrush	O
:	O
experiences	O
with	O
consumer	O
video	B
mosaicing	O
.	O
in	O
ieee	O
workshop	O
on	O
ap-	O
plications	O
of	O
computer	O
vision	O
(	O
wacv	O
’	O
98	O
)	O
,	O
pp	O
.	O
56–62	O
,	O
princeton	O
.	O
sawhney	O
,	O
h.	O
s.	O
,	O
arpa	O
,	O
a.	O
,	O
kumar	O
,	O
r.	O
,	O
samarasekera	O
,	O
s.	O
,	O
aggarwal	O
,	O
m.	O
,	O
hsu	O
,	O
s.	O
,	O
nister	O
,	O
d.	O
,	O
and	O
hanna	O
,	O
k.	O
(	O
2002	O
)	O
.	O
video	B
ﬂashlights	O
:	O
real	O
time	O
rendering	O
of	O
multiple	B
videos	O
for	O
immersive	O
model	O
visualization	O
.	O
in	O
proceedings	O
of	O
the	O
13th	O
eurographics	O
workshop	O
on	O
rendering	B
,	O
pp	O
.	O
157–168	O
,	O
pisa	O
,	O
italy	O
.	O
saxena	O
,	O
a.	O
,	O
sun	O
,	O
m.	O
,	O
and	O
ng	O
,	O
a.	O
y	O
.	O
(	O
2009	O
)	O
.	O
make3d	O
:	O
learning	B
3d	O
scene	O
structure	O
from	O
a	O
single	O
still	O
image	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
31	O
(	O
5	O
)	O
:824–840	O
.	O
schaffalitzky	O
,	O
f.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2000	O
)	O
.	O
planar	O
grouping	O
for	O
automatic	O
detection	B
of	O
vanishing	O
lines	O
and	O
points	B
.	O
image	B
and	O
vision	O
computing	O
,	O
18:647–658	O
.	O
schaffalitzky	O
,	O
f.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2002	O
)	O
.	O
multi-view	B
matching	O
for	O
unordered	O
image	B
sets	O
,	O
or	O
“	O
how	O
do	O
i	O
organize	O
my	O
holiday	O
snaps	O
?	O
”	O
.	O
in	O
seventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2002	O
)	O
,	O
pp	O
.	O
414–431	O
,	O
copenhagen	O
.	O
scharr	O
,	O
h.	O
,	O
black	O
,	O
m.	O
j.	O
,	O
and	O
haussecker	O
,	O
h.	O
w.	O
(	O
2003	O
)	O
.	O
image	B
statistics	O
and	O
anisotropic	B
dif-	O
fusion	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
840–	O
847	O
,	O
nice	O
,	O
france	O
.	O
scharstein	O
,	O
d.	O
(	O
1994	O
)	O
.	O
matching	B
images	O
by	O
comparing	O
their	O
gradient	O
ﬁelds	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
pattern	O
recognition	B
(	O
icpr	O
’	O
94	O
)	O
,	O
pp	O
.	O
572–575	O
,	O
jerusalem	O
,	O
israel	O
.	O
scharstein	O
,	O
d.	O
(	O
1999	O
)	O
.	O
view	O
synthesis	O
using	O
stereo	O
vision	O
.	O
volume	O
1583	O
,	O
springer-verlag	O
.	O
scharstein	O
,	O
d.	O
and	O
pal	O
,	O
c.	O
(	O
2007	O
)	O
.	O
learning	B
conditional	O
random	O
ﬁelds	O
for	O
stereo	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
scharstein	O
,	O
d.	O
and	O
szeliski	O
,	O
r.	O
(	O
1998	O
)	O
.	O
stereo	B
matching	I
with	O
nonlinear	O
diffusion	O
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
28	O
(	O
2	O
)	O
:155–174	O
.	O
scharstein	O
,	O
d.	O
and	O
szeliski	O
,	O
r.	O
(	O
2002	O
)	O
.	O
a	O
taxonomy	B
and	O
evaluation	B
of	O
dense	O
two-frame	O
stereo	B
correspondence	O
algorithms	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
47	O
(	O
1	O
)	O
:7–	O
42.	O
references	B
893	O
scharstein	O
,	O
d.	O
and	O
szeliski	O
,	O
r.	O
(	O
2003	O
)	O
.	O
high-accuracy	O
stereo	B
depth	O
maps	O
using	O
structured	O
light	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recogni-	O
tion	B
(	O
cvpr	O
’	O
2003	O
)	O
,	O
pp	O
.	O
195–202	O
,	O
madison	O
,	O
wi	O
.	O
schechner	O
,	O
y.	O
y.	O
,	O
nayar	O
,	O
s.	O
k.	O
,	O
and	O
belhumeur	O
,	O
p.	O
n.	O
(	O
2009	O
)	O
.	O
multiplexing	O
for	O
optimal	O
lighting	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
8	O
)	O
:1339–	O
1354.	O
schindler	O
,	O
g.	O
,	O
brown	O
,	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2007	O
)	O
.	O
city-scale	O
location	B
recognition	I
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
schindler	O
,	O
g.	O
,	O
krishnamurthy	O
,	O
p.	O
,	O
lublinerman	O
,	O
r.	O
,	O
liu	O
,	O
y.	O
,	O
and	O
dellaert	O
,	O
f.	O
(	O
2008	O
)	O
.	O
detect-	O
ing	O
and	O
matching	B
repeated	O
patterns	B
for	O
automatic	B
geo-tagging	O
in	O
urban	O
environments	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
schlesinger	O
,	O
d.	O
and	O
flach	O
,	O
b	O
.	O
(	O
2006	O
)	O
.	O
transforming	O
an	O
arbitrary	O
minsum	O
problem	O
into	O
a	O
binary	O
one	O
.	O
technical	O
report	O
tud-fi06-01	O
,	O
dresden	O
university	O
of	O
technology	O
.	O
schlesinger	O
,	O
m.	O
i	O
.	O
(	O
1976	O
)	O
.	O
syntactic	O
analysis	O
of	O
two-dimensional	B
visual	O
signals	O
in	O
noisy	O
conditions	O
.	O
kibernetika	O
,	O
4:113–130	O
.	O
schlesinger	O
,	O
m.	O
i.	O
and	O
giginyak	O
,	O
v.	O
v.	O
(	O
2007a	O
)	O
.	O
solution	O
to	O
structural	O
recognition	B
(	O
max	O
,	O
+	O
)	O
-	O
problems	O
by	O
their	O
equivalent	O
transformations	O
–	O
part	O
1.	O
control	O
systems	O
and	O
computers	O
,	O
2007	O
(	O
1	O
)	O
:3–15	O
.	O
schlesinger	O
,	O
m.	O
i.	O
and	O
giginyak	O
,	O
v.	O
v.	O
(	O
2007b	O
)	O
.	O
solution	O
to	O
structural	O
recognition	B
(	O
max	O
,	O
+	O
)	O
-	O
problems	O
by	O
their	O
equivalent	O
transformations	O
–	O
part	O
2.	O
control	O
systems	O
and	O
computers	O
,	O
2007	O
(	O
2	O
)	O
:3–18	O
.	O
schmid	O
,	O
c.	O
and	O
mohr	O
,	O
r.	O
(	O
1997	O
)	O
.	O
local	B
grayvalue	O
invariants	O
for	O
image	O
retrieval	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
5	O
)	O
:530–534	O
.	O
schmid	O
,	O
c.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
1997	O
)	O
.	O
automatic	B
line	O
matching	B
across	O
views	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
666–671	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
schmid	O
,	O
c.	O
,	O
mohr	O
,	O
r.	O
,	O
and	O
bauckhage	O
,	O
c.	O
(	O
2000	O
)	O
.	O
evaluation	B
of	O
interest	O
point	O
detectors	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
37	O
(	O
2	O
)	O
:151–172	O
.	O
schneiderman	O
,	O
h.	O
and	O
kanade	O
,	O
t.	O
(	O
2004	O
)	O
.	O
object	O
detection	B
using	O
the	O
statistics	O
of	O
parts	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
56	O
(	O
3	O
)	O
:151–177	O
.	O
sch¨odl	O
,	O
a.	O
and	O
essa	O
,	O
i	O
.	O
(	O
2002	O
)	O
.	O
controlled	O
animation	O
of	O
video	B
sprites	O
.	O
in	O
acm	O
symposium	O
on	O
computater	O
animation	O
,	O
san	O
antonio	O
.	O
894	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
sch¨odl	O
,	O
a.	O
,	O
szeliski	O
,	O
r.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
and	O
essa	O
,	O
i	O
.	O
(	O
2000	O
)	O
.	O
video	B
textures	I
.	O
in	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
489–498	O
,	O
new	O
orleans	O
.	O
schoenemann	O
,	O
t.	O
and	O
cremers	O
,	O
d.	O
(	O
2008	O
)	O
.	O
high	O
resolution	O
motion	B
layer	O
decomposition	O
using	O
dual-space	O
graph	B
cuts	I
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
sch¨olkopf	O
,	O
b.	O
and	O
smola	O
,	O
a	O
.	O
(	O
eds	O
)	O
.	O
(	O
2002	O
)	O
.	O
learning	B
with	O
kernels	O
:	O
support	B
vector	I
machines	I
,	O
regularization	B
,	O
optimization	O
and	O
beyond	O
.	O
mit	O
press	O
,	O
cambridge	O
,	O
mas-	O
sachusetts	O
.	O
schraudolph	O
,	O
n.	O
n.	O
(	O
2010	O
)	O
.	O
polynomial-time	O
exact	O
inference	B
in	O
np-hard	O
binary	O
mrfs	O
via	O
reweighted	O
perfect	O
matching	O
.	O
in	O
13th	O
international	O
conference	O
on	O
artiﬁcial	O
intelligence	O
and	O
statistics	O
(	O
aistats	O
)	O
,	O
pp	O
.	O
717–724	O
.	O
schr¨oder	O
,	O
p.	O
and	O
sweldens	O
,	O
w.	O
(	O
1995	O
)	O
.	O
spherical	B
wavelets	O
:	O
efﬁciently	O
representing	O
func-	O
tions	O
on	O
the	O
sphere	O
.	O
in	O
acm	O
siggraph	O
1995	O
conference	O
proceedings	O
,	O
pp	O
.	O
161–172	O
.	O
schultz	O
,	O
r.	O
r.	O
and	O
stevenson	O
,	O
r.	O
l.	O
(	O
1996	O
)	O
.	O
extraction	O
of	O
high-resolution	O
frames	O
from	O
video	B
sequences	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
5	O
(	O
6	O
)	O
:996–1011	O
.	O
sclaroff	O
,	O
s.	O
and	O
isidoro	O
,	O
j	O
.	O
(	O
2003	O
)	O
.	O
active	O
blobs	O
:	O
region-based	B
,	O
deformable	O
appearance	O
models	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
89	O
(	O
2-3	O
)	O
:197–225	O
.	O
scott	O
,	O
g.	O
l.	O
and	O
longuet-higgins	O
,	O
h.	O
c.	O
(	O
1990	O
)	O
.	O
feature	B
grouping	O
by	O
relocalization	O
of	O
eigenvectors	O
of	O
the	O
proximity	O
matrix	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
,	O
pp	O
.	O
103–	O
108.	O
sebastian	O
,	O
t.	O
b.	O
and	O
kimia	O
,	O
b.	O
b	O
.	O
(	O
2005	O
)	O
.	O
curves	O
vs.	O
skeletons	O
in	O
object	O
recognition	B
.	O
signal	O
processing	O
,	O
85	O
(	O
2	O
)	O
:246–263	O
.	O
sederberg	O
,	O
t.	O
w.	O
and	O
parry	O
,	O
s.	O
r.	O
(	O
1986	O
)	O
.	O
free-form	O
deformations	O
of	O
solid	O
geometric	B
models	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
86	O
)	O
,	O
20	O
(	O
4	O
)	O
:151–160	O
.	O
sederberg	O
,	O
t.	O
w.	O
,	O
gao	O
,	O
p.	O
,	O
wang	O
,	O
g.	O
,	O
and	O
mu	O
,	O
h.	O
(	O
1993	O
)	O
.	O
2d	O
shape	O
blending	O
:	O
an	O
intrinsic	B
solution	O
to	O
the	O
vertex	O
path	O
problem	O
.	O
in	O
acm	O
siggraph	O
1993	O
conference	O
proceedings	O
,	O
pp	O
.	O
15–18	O
.	O
seitz	O
,	O
p.	O
(	O
1989	O
)	O
.	O
using	O
local	O
orientation	O
information	O
as	O
image	B
primitive	O
for	O
robust	O
ob-	O
ject	O
recognition	B
.	O
in	O
spie	O
vol	O
.	O
1199	O
,	O
visual	O
communications	O
and	O
image	B
processing	O
iv	O
,	O
pp	O
.	O
1630–1639	O
.	O
seitz	O
,	O
s.	O
(	O
2001	O
)	O
.	O
the	O
space	O
of	O
all	O
stereo	B
images	O
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
26–33	O
,	O
vancouver	O
,	O
canada	O
.	O
seitz	O
,	O
s.	O
and	O
szeliski	O
,	O
r.	O
(	O
1999	O
)	O
.	O
applications	O
of	O
computer	O
vision	O
to	O
computer	O
graphics	O
.	O
computer	O
graphics	O
,	O
33	O
(	O
4	O
)	O
:35–37	O
.	O
guest	O
editors	O
’	O
introduction	O
to	O
the	O
special	O
issue	O
.	O
references	B
895	O
seitz	O
,	O
s.	O
,	O
curless	O
,	O
b.	O
,	O
diebel	O
,	O
j.	O
,	O
scharstein	O
,	O
d.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
a	O
comparison	O
and	O
evaluation	B
of	O
multi-view	B
stereo	I
reconstruction	O
algorithms	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
519–526	O
,	O
new	O
york	O
,	O
ny	O
.	O
seitz	O
,	O
s.	O
m.	O
and	O
baker	O
,	O
s.	O
(	O
2009	O
)	O
.	O
filter	O
ﬂow	O
.	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
seitz	O
,	O
s.	O
m.	O
and	O
dyer	O
,	O
c.	O
m.	O
(	O
1996	O
)	O
.	O
view	B
morphing	I
.	O
in	O
acm	O
siggraph	O
1996	O
confer-	O
ence	O
proceedings	O
,	O
pp	O
.	O
21–30	O
,	O
new	O
orleans	O
.	O
seitz	O
,	O
s.	O
m.	O
and	O
dyer	O
,	O
c.	O
m.	O
(	O
1997	O
)	O
.	O
photorealistic	O
scene	O
reconstruction	O
by	O
voxel	O
coloring	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
1067–1073	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
seitz	O
,	O
s.	O
m.	O
and	O
dyer	O
,	O
c.	O
m.	O
(	O
1999	O
)	O
.	O
photorealistic	O
scene	O
reconstruction	O
by	O
voxel	O
coloring	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
35	O
(	O
2	O
)	O
:151–173	O
.	O
seitz	O
,	O
s.	O
m.	O
and	O
dyer	O
,	O
c.	O
r.	O
(	O
1997	O
)	O
.	O
view	O
invariant	O
analysis	O
of	O
cyclic	O
motion	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
25	O
(	O
3	O
)	O
:231–251	O
.	O
serra	O
,	O
j	O
.	O
(	O
1982	O
)	O
.	O
image	B
analysis	O
and	O
mathematical	O
morphology	O
.	O
academic	O
press	O
,	O
new	O
york	O
.	O
serra	O
,	O
j.	O
and	O
vincent	O
,	O
l.	O
(	O
1992	O
)	O
.	O
an	O
overview	O
of	O
morphological	O
ﬁltering	O
.	O
circuits	O
,	O
systems	O
and	O
signal	O
processing	O
,	O
11	O
(	O
1	O
)	O
:47–108	O
.	O
serre	O
,	O
t.	O
,	O
wolf	O
,	O
l.	O
,	O
and	O
poggio	O
,	O
t.	O
(	O
2005	O
)	O
.	O
object	O
recognition	B
with	O
features	O
inspired	O
by	O
visual	O
cortex	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
994–1000	O
,	O
san	O
diego	O
,	O
ca	O
.	O
sethian	O
,	O
j	O
.	O
(	O
1999	O
)	O
.	O
level	O
set	O
methods	O
and	O
fast	O
marching	O
methods	O
.	O
cambridge	O
university	O
press	O
,	O
cambridge	O
,	O
2nd	O
edition	O
.	O
shade	O
,	O
j.	O
,	O
gortler	O
,	O
s.	O
,	O
he	O
,	O
l.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
1998	O
)	O
.	O
layered	O
depth	O
images	O
.	O
in	O
acm	O
siggraph	O
1998	O
conference	O
proceedings	O
,	O
pp	O
.	O
231–242	O
,	O
orlando	O
.	O
shade	O
,	O
j.	O
,	O
lischinski	O
,	O
d.	O
,	O
salesin	O
,	O
d.	O
,	O
derose	O
,	O
t.	O
,	O
and	O
snyder	O
,	O
j	O
.	O
(	O
1996	O
)	O
.	O
hierarchical	B
images	O
caching	O
for	O
accelerated	O
walkthroughs	B
of	O
complex	O
environments	O
.	O
in	O
acm	O
sig-	O
graph	O
1996	O
conference	O
proceedings	O
,	O
pp	O
.	O
75–82	O
,	O
new	O
orleans	O
.	O
shafer	O
,	O
s.	O
a	O
.	O
(	O
1985	O
)	O
.	O
using	O
color	O
to	O
separate	O
reﬂection	O
components	O
.	O
color	B
research	O
and	O
applications	O
,	O
10	O
(	O
4	O
)	O
:210–218	O
.	O
shafer	O
,	O
s.	O
a.	O
,	O
healey	O
,	O
g.	O
,	O
and	O
wolff	O
,	O
l.	O
(	O
1992	O
)	O
.	O
physics-based	B
vision	O
:	O
principles	O
and	O
practice	O
.	O
jones	O
&	O
bartlett	O
,	O
cambridge	O
,	O
ma	O
.	O
896	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
shaﬁque	O
,	O
k.	O
and	O
shah	O
,	O
m.	O
(	O
2005	O
)	O
.	O
a	O
noniterative	O
greedy	O
algorithm	B
for	O
multiframe	O
point	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
correspondence	B
.	O
27	O
(	O
1	O
)	O
:51–65	O
.	O
shah	O
,	O
j	O
.	O
(	O
1993	O
)	O
.	O
a	O
nonlinear	O
diffusion	O
model	O
for	O
discontinuous	O
disparity	O
and	O
half-occlusion	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
in	O
stereo	B
.	O
recognition	B
(	O
cvpr	O
’	O
93	O
)	O
,	O
pp	O
.	O
34–40	O
,	O
new	O
york	O
.	O
shakhnarovich	O
,	O
g.	O
,	O
darrell	O
,	O
t.	O
,	O
and	O
indyk	O
,	O
p.	O
(	O
eds	O
)	O
.	O
(	O
2006	O
)	O
.	O
nearest-neighbor	O
methods	O
in	O
learning	B
and	O
vision	O
:	O
theory	O
and	O
practice	O
,	O
mit	O
press	O
.	O
shakhnarovich	O
,	O
g.	O
,	O
viola	O
,	O
p.	O
,	O
and	O
darrell	O
,	O
t.	O
(	O
2003	O
)	O
.	O
fast	O
pose	O
estimation	B
with	O
parameter-	O
sensitive	O
hashing	B
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
750–757	O
,	O
nice	O
,	O
france	O
.	O
shan	O
,	O
y.	O
,	O
liu	O
,	O
z.	O
,	O
and	O
zhang	O
,	O
z	O
.	O
(	O
2001	O
)	O
.	O
model-based	B
bundle	O
adjustment	O
with	O
application	O
to	O
face	B
modeling	I
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
644–641	O
,	O
vancouver	O
,	O
canada	O
.	O
sharon	O
,	O
e.	O
,	O
galun	O
,	O
m.	O
,	O
sharon	O
,	O
d.	O
,	O
basri	O
,	O
r.	O
,	O
and	O
brandt	O
,	O
a	O
.	O
(	O
2006	O
)	O
.	O
hierarchy	B
and	O
adap-	O
tivity	O
in	O
segmenting	O
visual	O
scenes	O
.	O
nature	O
,	O
442	O
(	O
7104	O
)	O
:810–813	O
.	O
shashua	O
,	O
a.	O
and	O
toelg	O
,	O
s.	O
(	O
1997	O
)	O
.	O
the	O
quadric	O
reference	O
surface	B
:	O
theory	O
and	O
applications	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
23	O
(	O
2	O
)	O
:185–198	O
.	O
shashua	O
,	O
a.	O
and	O
wexler	O
,	O
y	O
.	O
(	O
2001	O
)	O
.	O
q-warping	O
:	O
direct	B
computation	O
of	O
quadratic	O
reference	O
surfaces	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
23	O
(	O
8	O
)	O
:920–	O
925.	O
shaw	O
,	O
d.	O
and	O
barnes	O
,	O
n.	O
(	O
2006	O
)	O
.	O
perspective	B
rectangle	O
detection	B
.	O
in	O
workshop	O
on	O
applica-	O
tions	O
of	O
computer	O
vision	O
at	O
eccv	O
’	O
2006	O
.	O
shewchuk	O
,	O
j.	O
r.	O
(	O
1994	O
)	O
.	O
an	O
introduction	O
to	O
the	O
conjugate	B
gradient	I
method	O
without	O
the	O
agonizing	O
pain	O
.	O
unpublished	O
manuscript	O
,	O
available	O
on	O
author	O
’	O
s	O
homepage	O
(	O
http	O
:	O
//www.cs.berkeley.edu/∼jrs/	O
)	O
.	O
an	O
earlier	O
version	O
appeared	O
as	O
a	O
carnegie	O
mellon	O
uni-	O
versity	O
technical	O
report	O
,	O
cmu-cs-94-125	O
.	O
shi	O
,	O
j.	O
and	O
malik	O
,	O
j	O
.	O
(	O
2000	O
)	O
.	O
normalized	B
cuts	I
and	O
image	B
segmentation	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
8	O
(	O
22	O
)	O
:888–905	O
.	O
shi	O
,	O
j.	O
and	O
tomasi	O
,	O
c.	O
(	O
1994	O
)	O
.	O
good	O
features	O
to	O
track	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
94	O
)	O
,	O
pp	O
.	O
593–600	O
,	O
seattle	O
.	O
shimizu	O
,	O
m.	O
and	O
okutomi	O
,	O
m.	O
(	O
2001	O
)	O
.	O
precise	O
sub-pixel	O
estimation	O
on	O
area-based	O
match-	O
ing	O
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
90–97	O
,	O
vancouver	O
,	O
canada	O
.	O
references	B
897	O
shirley	O
,	O
p.	O
(	O
2005	O
)	O
.	O
fundamentals	O
of	O
computer	O
graphics	O
.	O
a	O
k	O
peters	O
,	O
wellesley	O
,	O
mas-	O
sachusetts	O
,	O
second	O
edition	O
.	O
shizawa	O
,	O
m.	O
and	O
mase	O
,	O
k.	O
(	O
1991	O
)	O
.	O
a	O
uniﬁed	O
computational	B
theory	I
of	O
motion	B
transparency	O
and	O
motion	B
boundaries	O
based	O
on	O
eigenenergy	O
analysis	O
.	O
in	O
ieee	O
computer	O
society	O
con-	O
ference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
91	O
)	O
,	O
pp	O
.	O
289–295	O
,	O
maui	O
,	O
hawaii	O
.	O
shoemake	O
,	O
k.	O
(	O
1985	O
)	O
.	O
animating	O
rotation	O
with	O
quaternion	O
curves	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
85	O
)	O
,	O
19	O
(	O
3	O
)	O
:245–254	O
.	O
shotton	O
,	O
j.	O
,	O
blake	O
,	O
a.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2005	O
)	O
.	O
contour-based	B
learning	O
for	O
object	O
detection	B
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
503–510	O
,	O
bei-	O
jing	O
,	O
china	O
.	O
shotton	O
,	O
j.	O
,	O
johnson	O
,	O
m.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2008	O
)	O
.	O
semantic	O
texton	O
forests	O
for	O
image	O
catego-	O
rization	O
and	O
segmentation	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
shotton	O
,	O
j.	O
,	O
winn	O
,	O
j.	O
,	O
rother	O
,	O
c.	O
,	O
and	O
criminisi	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
textonboost	O
for	O
image	O
under-	O
standing	O
:	O
multi-class	O
object	O
recognition	B
and	O
segmentation	B
by	O
jointly	O
modeling	B
appear-	O
ance	O
,	O
shape	O
and	O
context	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
81	O
(	O
1	O
)	O
:2–23	O
.	O
shufelt	O
,	O
j	O
.	O
(	O
1999	O
)	O
.	O
performance	O
evaluation	O
and	O
analysis	O
of	O
vanishing	O
point	O
detection	B
tech-	O
niques	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
21	O
(	O
3	O
)	O
:282–	O
288.	O
shum	O
,	O
h.-y	O
.	O
and	O
he	O
,	O
l.-w.	O
(	O
1999	O
)	O
.	O
rendering	B
with	O
concentric	O
mosaics	O
.	O
in	O
acm	O
sig-	O
graph	O
1999	O
conference	O
proceedings	O
,	O
pp	O
.	O
299–306	O
,	O
los	O
angeles	O
.	O
shum	O
,	O
h.-y	O
.	O
and	O
szeliski	O
,	O
r.	O
(	O
1999	O
)	O
.	O
stereo	B
reconstruction	O
from	O
multiperspective	O
panora-	O
mas	O
.	O
in	O
seventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
99	O
)	O
,	O
pp	O
.	O
14–21	O
,	O
kerkyra	O
,	O
greece	O
.	O
shum	O
,	O
h.-y	O
.	O
and	O
szeliski	O
,	O
r.	O
(	O
2000	O
)	O
.	O
construction	O
of	O
panoramic	O
mosaics	O
with	O
global	O
and	O
local	B
alignment	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
36	O
(	O
2	O
)	O
:101–130	O
.	O
erratum	O
published	O
july	O
2002	O
,	O
48	O
(	O
2	O
)	O
:151–152	O
.	O
shum	O
,	O
h.-y.	O
,	O
chan	O
,	O
s.-c.	O
,	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
2007	O
)	O
.	O
image-based	B
rendering	I
.	O
springer	O
,	O
new	O
york	O
,	O
ny	O
.	O
shum	O
,	O
h.-y.	O
,	O
han	O
,	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
1998	O
)	O
.	O
interactive	B
construction	O
of	O
3d	O
models	O
from	O
panoramic	O
mosaics	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
427–433	O
,	O
santa	O
barbara	O
.	O
shum	O
,	O
h.-y.	O
,	O
ikeuchi	O
,	O
k.	O
,	O
and	O
reddy	O
,	O
r.	O
(	O
1995	O
)	O
.	O
principal	O
component	O
analysis	O
with	O
miss-	O
ieee	O
transactions	O
on	O
pattern	O
ing	O
data	O
and	O
its	O
application	O
to	O
polyhedral	O
modeling	B
.	O
898	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
analysis	O
and	O
machine	O
intelligence	O
,	O
17	O
(	O
9	O
)	O
:854–867	O
.	O
shum	O
,	O
h.-y.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
and	O
chan	O
,	O
s.-c.	O
(	O
2003	O
)	O
.	O
survey	O
of	O
image-based	B
representations	O
ieee	O
transactions	O
on	O
circuits	O
and	O
systems	O
for	O
video	O
and	O
compression	B
techniques	O
.	O
technology	O
,	O
13	O
(	O
11	O
)	O
:1020–1037	O
.	O
shum	O
,	O
h.-y.	O
,	O
wang	O
,	O
l.	O
,	O
chai	O
,	O
j.-x.	O
,	O
and	O
tong	O
,	O
x	O
.	O
(	O
2002	O
)	O
.	O
rendering	B
by	O
manifold	O
hopping	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
50	O
(	O
2	O
)	O
:185–201	O
.	O
shum	O
,	O
h.-y.	O
,	O
sun	O
,	O
j.	O
,	O
yamazaki	O
,	O
s.	O
,	O
li	O
,	O
y.	O
,	O
and	O
tang	O
,	O
c.-k.	O
(	O
2004	O
)	O
.	O
pop-up	O
light	B
ﬁeld	I
:	O
an	O
interactive	B
image-based	O
modeling	B
and	O
rendering	B
system	O
.	O
acm	O
transactions	O
on	O
graph-	O
ics	O
,	O
23	O
(	O
2	O
)	O
:143–162	O
.	O
sidenbladh	O
,	O
h.	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2003	O
)	O
.	O
learning	B
the	O
statistics	O
of	O
people	O
in	O
images	O
and	O
video	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
54	O
(	O
1	O
)	O
:189–209	O
.	O
sidenbladh	O
,	O
h.	O
,	O
black	O
,	O
m.	O
j.	O
,	O
and	O
fleet	O
,	O
d.	O
j	O
.	O
(	O
2000	O
)	O
.	O
stochastic	O
tracking	O
of	O
3d	O
human	O
in	O
sixth	O
european	O
conference	O
on	O
computer	O
vision	O
ﬁgures	O
using	O
2d	O
image	B
motion	O
.	O
(	O
eccv	O
2000	O
)	O
,	O
pp	O
.	O
702–718	O
,	O
dublin	O
,	O
ireland	O
.	O
sigal	O
,	O
l.	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2006	O
)	O
.	O
predicting	O
3d	O
people	O
from	O
2d	O
pictures	O
.	O
in	O
amdo	O
2006	O
-	O
iv	O
conference	O
on	O
articulated	O
motion	B
and	O
deformable	O
objects	O
,	O
pp	O
.	O
185–195	O
,	O
mallorca	O
,	O
spain	O
.	O
sigal	O
,	O
l.	O
,	O
balan	O
,	O
a.	O
,	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2010	O
)	O
.	O
humaneva	O
:	O
synchronized	O
video	B
and	O
mo-	O
tion	B
capture	O
dataset	O
and	O
baseline	O
algorithm	B
for	O
evaluation	B
of	O
articulated	O
human	B
motion	I
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
87	O
(	O
1-2	O
)	O
:4–27	O
.	O
sigal	O
,	O
l.	O
,	O
bhatia	O
,	O
s.	O
,	O
roth	O
,	O
s.	O
,	O
black	O
,	O
m.	O
j.	O
,	O
and	O
isard	O
,	O
m.	O
(	O
2004	O
)	O
.	O
tracking	O
loose-limbed	O
people	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recog-	O
nition	O
(	O
cvpr	O
’	O
2004	O
)	O
,	O
pp	O
.	O
421–428	O
,	O
washington	O
,	O
dc	O
.	O
sillion	O
,	O
f.	O
and	O
puech	O
,	O
c.	O
(	O
1994	O
)	O
.	O
radiosity	B
and	O
global	B
illumination	I
.	O
morgan	O
kaufmann	O
.	O
sim	O
,	O
t.	O
,	O
baker	O
,	O
s.	O
,	O
and	O
bsat	O
,	O
m.	O
(	O
2003	O
)	O
.	O
the	O
cmu	O
pose	O
,	O
illumination	O
,	O
and	O
expres-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
sion	O
database	O
.	O
25	O
(	O
12	O
)	O
:1615–1618	O
.	O
simard	O
,	O
p.	O
y.	O
,	O
bottou	O
,	O
l.	O
,	O
haffner	O
,	O
p.	O
,	O
and	O
cun	O
,	O
y.	O
l.	O
(	O
1998	O
)	O
.	O
boxlets	O
:	O
a	O
fast	O
convolution	O
algorithm	B
for	O
signal	O
processing	O
and	O
neural	B
networks	I
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
13	O
,	O
pp	O
.	O
571–577	O
.	O
simon	O
,	O
i.	O
and	O
seitz	O
,	O
s.	O
m.	O
(	O
2008	O
)	O
.	O
scene	O
segmentation	O
using	O
the	O
wisdom	O
of	O
crowds	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
541–553	O
,	O
mar-	O
seilles	O
.	O
references	B
899	O
simon	O
,	O
i.	O
,	O
snavely	O
,	O
n.	O
,	O
and	O
seitz	O
,	O
s.	O
m.	O
(	O
2007	O
)	O
.	O
scene	O
summarization	O
for	O
online	O
image	B
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
collections	O
.	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
simoncelli	O
,	O
e.	O
p.	O
(	O
1999	O
)	O
.	O
bayesian	O
denoising	O
of	O
visual	O
images	O
in	O
the	O
wavelet	O
domain	O
.	O
in	O
m¨uller	O
,	O
p.	O
and	O
vidakovic	O
,	O
b	O
.	O
(	O
eds	O
)	O
,	O
bayesian	O
inference	B
in	O
wavelet	O
based	O
models	O
,	O
pp	O
.	O
291–308	O
,	O
springer-verlag	O
,	O
new	O
york	O
.	O
simoncelli	O
,	O
e.	O
p.	O
and	O
adelson	O
,	O
e.	O
h.	O
(	O
1990a	O
)	O
.	O
non-separable	O
extensions	O
of	O
quadrature	O
mirror	O
ﬁlters	O
to	O
multiple	B
dimensions	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
78	O
(	O
4	O
)	O
:652–664	O
.	O
simoncelli	O
,	O
e.	O
p.	O
and	O
adelson	O
,	O
e.	O
h.	O
(	O
1990b	O
)	O
.	O
subband	O
transforms	O
.	O
in	O
woods	O
,	O
j	O
.	O
(	O
ed	O
.	O
)	O
,	O
subband	O
coding	O
,	O
pp	O
.	O
143–191	O
,	O
kluwer	O
academic	O
press	O
,	O
norwell	O
,	O
ma	O
.	O
simoncelli	O
,	O
e.	O
p.	O
,	O
adelson	O
,	O
e.	O
h.	O
,	O
and	O
heeger	O
,	O
d.	O
j	O
.	O
(	O
1991	O
)	O
.	O
probability	O
distributions	O
of	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
optic	O
ﬂow	O
.	O
recognition	B
(	O
cvpr	O
’	O
91	O
)	O
,	O
pp	O
.	O
310–315	O
,	O
maui	O
,	O
hawaii	O
.	O
simoncelli	O
,	O
e.	O
p.	O
,	O
freeman	O
,	O
w.	O
t.	O
,	O
adelson	O
,	O
e.	O
h.	O
,	O
and	O
heeger	O
,	O
d.	O
j	O
.	O
(	O
1992	O
)	O
.	O
shiftable	O
multiscale	O
transforms	O
.	O
ieee	O
transactions	O
on	O
information	O
theory	O
,	O
38	O
(	O
3	O
)	O
:587–607	O
.	O
singaraju	O
,	O
d.	O
,	O
grady	O
,	O
l.	O
,	O
and	O
vidal	O
,	O
r.	O
(	O
2008	O
)	O
.	O
interactive	B
image	O
segmentation	B
via	O
mini-	O
mization	O
of	O
quadratic	O
energies	O
on	O
directed	O
graphs	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
singaraju	O
,	O
d.	O
,	O
rother	O
,	O
c.	O
,	O
and	O
rhemann	O
,	O
c.	O
(	O
2009	O
)	O
.	O
new	O
appearance	O
models	O
for	O
natural	O
image	B
matting	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
singaraju	O
,	O
d.	O
,	O
grady	O
,	O
l.	O
,	O
sinop	O
,	O
a.	O
k.	O
,	O
and	O
vidal	O
,	O
r.	O
(	O
2010	O
)	O
.	O
a	O
continuous	O
valued	O
mrf	O
for	O
image	O
segmentation	B
.	O
in	O
blake	O
,	O
a.	O
,	O
kohli	O
,	O
p.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
eds	O
)	O
,	O
advances	O
in	O
markov	O
random	O
fields	O
,	O
mit	O
press	O
.	O
sinha	O
,	O
p.	O
,	O
balas	O
,	O
b.	O
,	O
ostrovsky	O
,	O
y.	O
,	O
and	O
russell	O
,	O
r.	O
(	O
2006	O
)	O
.	O
face	B
recognition	O
by	O
humans	O
:	O
nineteen	O
results	O
all	O
computer	O
vision	O
researchers	O
should	O
know	O
about	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
94	O
(	O
11	O
)	O
:1948–1962	O
.	O
sinha	O
,	O
s.	O
,	O
mordohai	O
,	O
p.	O
,	O
and	O
pollefeys	O
,	O
m.	O
(	O
2007	O
)	O
.	O
multi-view	B
stereo	I
via	O
graph	B
cuts	I
on	O
the	O
dual	O
of	O
an	O
adaptive	B
tetrahedral	O
mesh	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
com-	O
puter	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
sinha	O
,	O
s.	O
n.	O
and	O
pollefeys	O
,	O
m.	O
(	O
2005	O
)	O
.	O
multi-view	B
reconstruction	O
using	O
photo-consistency	O
and	O
exact	O
silhouette	O
constraints	O
:	O
a	O
maximum-ﬂow	O
formulation	O
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
349–356	O
,	O
beijing	O
,	O
china	O
.	O
sinha	O
,	O
s.	O
n.	O
,	O
steedly	O
,	O
d.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2009	O
)	O
.	O
piecewise	O
planar	O
stereo	O
for	O
image-based	O
rendering	B
.	O
in	O
twelfth	O
ieee	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
900	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
kyoto	O
,	O
japan	O
.	O
sinha	O
,	O
s.	O
n.	O
,	O
steedly	O
,	O
d.	O
,	O
szeliski	O
,	O
r.	O
,	O
agrawala	O
,	O
m.	O
,	O
and	O
pollefeys	O
,	O
m.	O
(	O
2008	O
)	O
.	O
interactive	B
3d	O
architectural	O
modeling	B
from	O
unordered	O
photo	O
collections	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
asia	O
2008	O
)	O
,	O
27	O
(	O
5	O
)	O
.	O
sinop	O
,	O
a.	O
k.	O
and	O
grady	O
,	O
l.	O
(	O
2007	O
)	O
.	O
a	O
seeded	O
image	B
segmentation	O
framework	O
unifying	O
graph	B
cuts	I
and	O
random	B
walker	I
which	O
yields	O
a	O
new	O
algorithm	B
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
sivic	O
,	O
j.	O
and	O
zisserman	O
,	O
a.	O
matching	B
in	O
videos	O
.	O
2003	O
)	O
,	O
pp	O
.	O
1470–1477	O
,	O
nice	O
,	O
france	O
.	O
(	O
2003	O
)	O
.	O
video	B
google	O
:	O
a	O
text	O
retrieval	O
approach	O
to	O
object	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
sivic	O
,	O
j.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
efﬁcient	O
visual	O
search	O
of	O
videos	O
cast	O
as	O
text	O
retrieval	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
31	O
(	O
4	O
)	O
:591–606	O
.	O
sivic	O
,	O
j.	O
,	O
everingham	O
,	O
m.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
“	O
who	O
are	O
you	O
?	O
”	O
—learning	O
person	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
speciﬁc	O
classiﬁers	O
from	O
video	B
.	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
sivic	O
,	O
j.	O
,	O
zitnick	O
,	O
c.	O
l.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
finding	O
people	O
in	O
repeated	O
shots	O
of	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2006	O
)	O
,	O
pp	O
.	O
909–918	O
,	O
the	O
same	O
scene	O
.	O
edinburgh	O
.	O
sivic	O
,	O
j.	O
,	O
russell	O
,	O
b.	O
,	O
zisserman	O
,	O
a.	O
,	O
freeman	O
,	O
w.	O
t.	O
,	O
and	O
efros	O
,	O
a.	O
a	O
.	O
(	O
2008	O
)	O
.	O
unsuper-	O
vised	O
discovery	O
of	O
visual	O
object	O
class	O
hierarchies	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
sivic	O
,	O
j.	O
,	O
russell	O
,	O
b.	O
c.	O
,	O
efros	O
,	O
a.	O
a.	O
,	O
zisserman	O
,	O
a.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2005	O
)	O
.	O
dis-	O
covering	O
objects	O
and	O
their	O
localization	O
in	O
images	O
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
370–377	O
,	O
beijing	O
,	O
china	O
.	O
slabaugh	O
,	O
g.	O
g.	O
,	O
culbertson	O
,	O
w.	O
b.	O
,	O
slabaugh	O
,	O
t.	O
g.	O
,	O
culbertson	O
,	O
b.	O
,	O
malzbender	O
,	O
t.	O
,	O
and	O
stevens	O
,	O
m.	O
(	O
2004	O
)	O
.	O
methods	O
for	O
volumetric	O
reconstruction	O
of	O
visual	O
scenes	O
.	O
interna-	O
tional	O
journal	O
of	O
computer	O
vision	O
,	O
57	O
(	O
3	O
)	O
:179–199	O
.	O
slama	O
,	O
c.	O
c	O
.	O
(	O
ed.	O
)	O
.	O
(	O
1980	O
)	O
.	O
manual	O
of	O
photogrammetry	B
.	O
american	O
society	O
of	O
photogram-	O
metry	O
,	O
falls	O
church	O
,	O
virginia	O
,	O
fourth	O
edition	O
.	O
smelyanskiy	O
,	O
v.	O
n.	O
,	O
cheeseman	O
,	O
p.	O
,	O
maluf	O
,	O
d.	O
a.	O
,	O
and	O
morris	O
,	O
r.	O
d.	O
(	O
2000	O
)	O
.	O
bayesian	O
super-resolved	O
surface	B
reconstruction	I
from	O
images	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
375–382	O
,	O
hilton	O
head	B
island	O
.	O
references	B
901	O
smeulders	O
,	O
a.	O
w.	O
m.	O
,	O
worring	O
,	O
m.	O
,	O
santini	O
,	O
s.	O
,	O
gupta	O
,	O
a.	O
,	O
and	O
jain	O
,	O
r.	O
c.	O
(	O
2000	O
)	O
.	O
content-	O
based	O
image	B
retrieval	O
at	O
the	O
end	O
of	O
the	O
early	O
years	O
.	O
ieee	O
transactions	O
on	O
pattern	O
anal-	O
ysis	O
and	O
machine	O
intelligence	O
,	O
22	O
(	O
12	O
)	O
:477–490	O
.	O
sminchisescu	O
,	O
c.	O
and	O
triggs	O
,	O
b	O
.	O
(	O
2001	O
)	O
.	O
covariance	O
scaled	O
sampling	O
for	O
monocular	O
3d	O
body	B
tracking	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2001	O
)	O
,	O
pp	O
.	O
447–454	O
,	O
kauai	O
,	O
hawaii	O
.	O
sminchisescu	O
,	O
c.	O
,	O
kanaujia	O
,	O
a.	O
,	O
and	O
metaxas	O
,	O
d.	O
(	O
2006	O
)	O
.	O
conditional	O
models	O
for	O
con-	O
textual	O
human	B
motion	I
recognition	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-	O
3	O
)	O
:210–220	O
.	O
sminchisescu	O
,	O
c.	O
,	O
kanaujia	O
,	O
a.	O
,	O
li	O
,	O
z.	O
,	O
and	O
metaxas	O
,	O
d.	O
(	O
2005	O
)	O
.	O
discriminative	O
density	O
propagation	O
for	O
3d	O
human	B
motion	I
estimation	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
390–397	O
,	O
san	O
diego	O
,	O
ca	O
.	O
smith	O
,	O
a.	O
r.	O
and	O
blinn	O
,	O
j.	O
f.	O
(	O
1996	O
)	O
.	O
blue	B
screen	I
matting	O
.	O
in	O
acm	O
siggraph	O
1996	O
conference	O
proceedings	O
,	O
pp	O
.	O
259–268	O
,	O
new	O
orleans	O
.	O
smith	O
,	O
b.	O
m.	O
,	O
zhang	O
,	O
l.	O
,	O
jin	O
,	O
h.	O
,	O
and	O
agarwala	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
light	B
ﬁeld	I
video	O
stabilization	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
smith	O
,	O
s.	O
m.	O
and	O
brady	O
,	O
j.	O
m.	O
(	O
1997	O
)	O
.	O
susan—a	O
new	O
approach	O
to	O
low	O
level	O
image	O
processing	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
23	O
(	O
1	O
)	O
:45–78	O
.	O
smolic	O
,	O
a.	O
and	O
kauff	O
,	O
p.	O
(	O
2005	O
)	O
.	O
interactive	B
3-d	O
video	B
representation	O
and	O
coding	O
technolo-	O
gies	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
93	O
(	O
1	O
)	O
:98–110	O
.	O
snavely	O
,	O
n.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
photo	O
tourism	O
:	O
exploring	O
photo	O
collec-	O
tions	O
in	O
3d	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2006	O
)	O
,	O
25	O
(	O
3	O
)	O
:835–846	O
.	O
snavely	O
,	O
n.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2008a	O
)	O
.	O
modeling	B
the	O
world	O
from	O
internet	O
photo	O
collections	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
80	O
(	O
2	O
)	O
:189–210	O
.	O
snavely	O
,	O
n.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2008b	O
)	O
.	O
skeletal	O
graphs	O
for	O
efﬁcient	O
structure	B
from	I
motion	I
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
snavely	O
,	O
n.	O
,	O
garg	O
,	O
r.	O
,	O
seitz	O
,	O
s.	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2008	O
)	O
.	O
finding	O
paths	O
through	O
the	O
world	O
’	O
s	O
photos	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2008	O
)	O
,	O
27	O
(	O
3	O
)	O
.	O
snavely	O
,	O
n.	O
,	O
simon	O
,	O
i.	O
,	O
goesele	O
,	O
m.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
seitz	O
,	O
s.	O
m.	O
(	O
2010	O
)	O
.	O
scene	O
re-	O
construction	O
and	O
visualization	O
from	O
community	O
photo	O
collections	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
98	O
(	O
8	O
)	O
:1370–1390	O
.	O
902	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
soatto	O
,	O
s.	O
,	O
yezzi	O
,	O
a.	O
j.	O
,	O
and	O
jin	O
,	O
h.	O
(	O
2003	O
)	O
.	O
tales	O
of	O
shape	O
and	O
radiance	O
in	O
multiview	O
stereo	B
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
974–981	O
,	O
nice	O
,	O
france	O
.	O
soille	O
,	O
p.	O
(	O
2006	O
)	O
.	O
morphological	O
image	B
compositing	O
.	O
ieee	O
transactions	O
on	O
pattern	O
anal-	O
ysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
5	O
)	O
:673–683	O
.	O
solina	O
,	O
f.	O
and	O
bajcsy	O
,	O
r.	O
(	O
1990	O
)	O
.	O
recovery	B
of	O
parametric	B
models	O
from	O
range	O
images	O
:	O
ieee	O
transactions	O
on	O
pattern	O
the	O
case	O
for	O
superquadrics	O
with	O
global	O
deformations	O
.	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12	O
(	O
2	O
)	O
:131–147	O
.	O
sontag	O
,	O
d.	O
and	O
jaakkola	O
,	O
t.	O
(	O
2007	O
)	O
.	O
new	O
outer	O
bounds	O
on	O
the	O
marginal	O
polytope	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
sontag	O
,	O
d.	O
,	O
meltzer	O
,	O
t.	O
,	O
globerson	O
,	O
a.	O
,	O
jaakkola	O
,	O
t.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2008	O
)	O
.	O
tightening	O
lp	O
relaxations	O
for	O
map	O
using	O
message	O
passing	O
.	O
in	O
uncertainty	B
in	O
artiﬁcial	O
intelligence	O
(	O
uai	O
)	O
.	O
soucy	O
,	O
m.	O
and	O
laurendeau	O
,	O
d.	O
(	O
1992	O
)	O
.	O
multi-resolution	O
surface	B
modeling	O
from	O
multiple	B
range	O
views	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
92	O
)	O
,	O
pp	O
.	O
348–353	O
,	O
champaign	O
,	O
illinois	O
.	O
srinivasan	O
,	O
s.	O
,	O
chellappa	O
,	O
r.	O
,	O
veeraraghavan	O
,	O
a.	O
,	O
and	O
aggarwal	O
,	O
g.	O
(	O
2005	O
)	O
.	O
electronic	O
image	B
stabilization	O
and	O
mosaicking	O
algorithms	O
.	O
in	O
bovik	O
,	O
a	O
.	O
(	O
ed	O
.	O
)	O
,	O
handbook	O
of	O
image	B
and	O
video	B
processing	O
,	O
academic	O
press	O
.	O
srivasan	O
,	O
p.	O
,	O
liang	O
,	O
p.	O
,	O
and	O
hackwood	O
,	O
s.	O
(	O
1990	O
)	O
.	O
computational	O
geometric	O
methods	O
in	O
volumetric	B
intersections	O
for	O
3d	O
reconstruction	O
.	O
pattern	O
recognition	B
,	O
23	O
(	O
8	O
)	O
:843–857	O
.	O
stamos	O
,	O
i.	O
,	O
liu	O
,	O
l.	O
,	O
chen	O
,	O
c.	O
,	O
wolberg	O
,	O
g.	O
,	O
yu	O
,	O
g.	O
,	O
and	O
zokai	O
,	O
s.	O
integrating	O
automated	B
range	O
registration	B
with	O
multiview	O
geometry	O
for	O
the	O
photorealistic	O
modeling	B
of	O
large-scale	O
scenes	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
78	O
(	O
2-3	O
)	O
:237–260	O
.	O
(	O
2008	O
)	O
.	O
stark	O
,	O
j.	O
a	O
.	O
(	O
2000	O
)	O
.	O
adaptive	B
image	O
contrast	O
enhancement	O
using	O
generalizations	O
of	O
his-	O
togram	O
equalization	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
9	O
(	O
5	O
)	O
:889–896	O
.	O
stauffer	O
,	O
c.	O
and	O
grimson	O
,	O
w.	O
(	O
1999	O
)	O
.	O
adaptive	B
background	O
mixture	O
models	O
for	O
real-	O
time	O
tracking	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
99	O
)	O
,	O
pp	O
.	O
246–252	O
,	O
fort	O
collins	O
.	O
steedly	O
,	O
d.	O
and	O
essa	O
,	O
i	O
.	O
(	O
2001	O
)	O
.	O
propagation	O
of	O
innovative	O
information	O
in	O
non-linear	B
least-	O
squares	O
structure	B
from	I
motion	I
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
223–229	O
,	O
vancouver	O
,	O
canada	O
.	O
steedly	O
,	O
d.	O
,	O
essa	O
,	O
i.	O
,	O
and	O
dellaert	O
,	O
f.	O
(	O
2003	O
)	O
.	O
spectral	O
partitioning	O
for	O
structure	O
from	O
mo-	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
996–	O
tion	B
.	O
1003	O
,	O
nice	O
,	O
france	O
.	O
references	B
903	O
steedly	O
,	O
d.	O
,	O
pal	O
,	O
c.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2005	O
)	O
.	O
efﬁciently	O
registering	O
video	B
into	O
panoramic	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
mosaics	O
.	O
pp	O
.	O
1300–1307	O
,	O
beijing	O
,	O
china	O
.	O
steele	O
,	O
r.	O
and	O
jaynes	O
,	O
c.	O
(	O
2005	O
)	O
.	O
feature	B
uncertainty	O
arising	O
from	O
covariant	O
image	B
noise	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
1063–1070	O
,	O
san	O
diego	O
,	O
ca	O
.	O
steele	O
,	O
r.	O
m.	O
and	O
jaynes	O
,	O
c.	O
(	O
2006	O
)	O
.	O
overconstrained	O
linear	B
estimation	O
of	O
radial	B
distortion	I
and	O
multi-view	B
geometry	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
253–264	O
.	O
stein	O
,	O
a.	O
,	O
hoiem	O
,	O
d.	O
,	O
and	O
hebert	O
,	O
m.	O
(	O
2007	O
)	O
.	O
learning	B
to	O
extract	O
object	O
boundaries	O
using	O
motion	O
cues	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
stein	O
,	O
f.	O
and	O
medioni	O
,	O
g.	O
(	O
1992	O
)	O
.	O
structural	O
indexing	O
:	O
efﬁcient	O
3-d	O
object	O
recognition	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
14	O
(	O
2	O
)	O
:125–145	O
.	O
stein	O
,	O
g.	O
(	O
1995	O
)	O
.	O
accurate	O
internal	O
camera	O
calibration	B
using	O
rotation	O
,	O
with	O
analysis	O
of	O
in	O
fifth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
95	O
)	O
,	O
sources	O
of	O
error	O
.	O
pp	O
.	O
230–236	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
stein	O
,	O
g.	O
(	O
1997	O
)	O
.	O
lens	O
distortion	O
calibration	B
using	O
point	O
correspondences	O
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
602–608	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
stenger	O
,	O
b.	O
,	O
thayananthan	O
,	O
a.	O
,	O
torr	O
,	O
p.	O
h.	O
s.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2006	O
)	O
.	O
model-based	B
hand	O
tracking	O
using	O
a	O
hierarchical	B
bayesian	O
ﬁlter	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
9	O
)	O
:1372–1384	O
.	O
stewart	O
,	O
c.	O
v.	O
(	O
1999	O
)	O
.	O
robust	B
parameter	O
estimation	B
in	O
computer	O
vision	O
.	O
siam	O
reviews	O
,	O
41	O
(	O
3	O
)	O
:513–537	O
.	O
stiller	O
,	O
c.	O
and	O
konrad	O
,	O
j	O
.	O
(	O
1999	O
)	O
.	O
estimating	O
motion	B
in	O
image	B
sequences	O
:	O
a	O
tutorial	O
on	O
modeling	B
and	O
computation	O
of	O
2d	O
motion	B
.	O
ieee	O
signal	O
processing	O
magazine	O
,	O
16	O
(	O
4	O
)	O
:70–	O
91.	O
stollnitz	O
,	O
e.	O
j.	O
,	O
derose	O
,	O
t.	O
d.	O
,	O
and	O
salesin	O
,	O
d.	O
h.	O
(	O
1996	O
)	O
.	O
wavelets	O
for	O
computer	O
graphics	O
:	O
theory	O
and	O
applications	O
.	O
morgan	O
kaufmann	O
,	O
san	O
francisco	O
.	O
strang	O
,	O
g.	O
(	O
1988	O
)	O
.	O
linear	B
algebra	O
and	O
its	O
applications	O
.	O
harcourt	O
,	O
brace	O
,	O
jovanovich	O
,	O
publishers	O
,	O
san	O
diego	O
,	O
3rd	O
edition	O
.	O
strang	O
,	O
g.	O
(	O
1989	O
)	O
.	O
wavelets	O
and	O
dilation	B
equations	O
:	O
a	O
brief	O
introduction	O
.	O
siam	O
reviews	O
,	O
31	O
(	O
4	O
)	O
:614–627	O
.	O
904	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
strecha	O
,	O
c.	O
,	O
fransens	O
,	O
r.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2006	O
)	O
.	O
combined	O
depth	O
and	O
outlier	O
estimation	B
in	O
multi-view	B
stereo	I
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
2394–2401	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
strecha	O
,	O
c.	O
,	O
tuytelaars	O
,	O
t.	O
,	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2003	O
)	O
.	O
dense	O
matching	O
of	O
multiple	B
wide-	O
baseline	O
views	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
1194–1201	O
,	O
nice	O
,	O
france	O
.	O
strecha	O
,	O
c.	O
,	O
von	O
hansen	O
,	O
w.	O
,	O
van	O
gool	O
,	O
l.	O
,	O
fua	O
,	O
p.	O
,	O
and	O
thoennessen	O
,	O
u	O
.	O
(	O
2008	O
)	O
.	O
on	O
in	O
ieee	O
computer	O
society	O
benchmarking	O
camera	B
calibration	O
and	O
multi-view	B
stereo	I
.	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
sturm	O
,	O
p.	O
(	O
2005	O
)	O
.	O
multi-view	B
geometry	O
for	O
general	O
camera	B
models	O
.	O
in	O
ieee	O
computer	O
so-	O
ciety	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
206–	O
212	O
,	O
san	O
diego	O
,	O
ca	O
.	O
sturm	O
,	O
p.	O
and	O
ramalingam	O
,	O
s.	O
(	O
2004	O
)	O
.	O
a	O
generic	O
concept	O
for	O
camera	O
calibration	B
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
1–13	O
,	O
prague	O
.	O
sturm	O
,	O
p.	O
and	O
triggs	O
,	O
w.	O
(	O
1996	O
)	O
.	O
a	O
factorization	B
based	O
algorithm	B
for	O
multi-image	O
projective	B
structure	O
and	O
motion	B
.	O
in	O
fourth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
96	O
)	O
,	O
pp	O
.	O
709–720	O
,	O
cambridge	O
,	O
england	O
.	O
su	O
,	O
h.	O
,	O
sun	O
,	O
m.	O
,	O
fei-fei	O
,	O
l.	O
,	O
and	O
savarese	O
,	O
s.	O
(	O
2009	O
)	O
.	O
learning	B
a	O
dense	O
multi-view	O
repre-	O
sentation	O
for	O
detection	O
,	O
viewpoint	O
classiﬁcation	O
and	O
synthesis	O
of	O
object	O
categories	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
sudderth	O
,	O
e.	O
b.	O
,	O
torralba	O
,	O
a.	O
,	O
freeman	O
,	O
w.	O
t.	O
,	O
and	O
willsky	O
,	O
a.	O
s.	O
(	O
2008	O
)	O
.	O
describing	O
visual	O
scenes	O
using	O
transformed	O
objects	O
and	O
parts	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
77	O
(	O
1-3	O
)	O
:291–330	O
.	O
sullivan	O
,	O
s.	O
and	O
ponce	O
,	O
j	O
.	O
(	O
1998	O
)	O
.	O
automatic	B
model	O
construction	O
and	O
pose	O
estimation	B
from	O
photographs	O
using	O
triangular	O
splines	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
20	O
(	O
10	O
)	O
:1091–1096	O
.	O
sun	O
,	O
d.	O
,	O
roth	O
,	O
s.	O
,	O
lewis	O
,	O
j.	O
p.	O
,	O
and	O
black	O
,	O
m.	O
j	O
.	O
(	O
2008	O
)	O
.	O
learning	B
optical	O
ﬂow	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
83–97	O
,	O
marseilles	O
.	O
sun	O
,	O
j.	O
,	O
zheng	O
,	O
n.	O
,	O
and	O
shum	O
,	O
h.	O
(	O
2003	O
)	O
.	O
stereo	B
matching	I
using	O
belief	B
propagation	I
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
25	O
(	O
7	O
)	O
:787–800	O
.	O
sun	O
,	O
j.	O
,	O
jia	O
,	O
j.	O
,	O
tang	O
,	O
c.-k.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2004	O
)	O
.	O
poisson	O
matting	B
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2004	O
)	O
,	O
23	O
(	O
3	O
)	O
:315–321	O
.	O
sun	O
,	O
j.	O
,	O
li	O
,	O
y.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2006	O
)	O
.	O
flash	O
matting	B
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:772–778	O
.	O
references	B
905	O
sun	O
,	O
j.	O
,	O
yuan	O
,	O
l.	O
,	O
jia	O
,	O
j.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2004	O
)	O
.	O
image	B
completion	O
with	O
structure	O
propa-	O
gation	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2004	O
)	O
,	O
24	O
(	O
3	O
)	O
:861–868	O
.	O
sun	O
,	O
m.	O
,	O
su	O
,	O
h.	O
,	O
savarese	O
,	O
s.	O
,	O
and	O
fei-fei	O
,	O
l.	O
(	O
2009	O
)	O
.	O
a	O
multi-view	B
probabilistic	O
model	O
for	O
3d	O
object	O
classes	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
sung	O
,	O
k.-k.	O
and	O
poggio	O
,	O
t.	O
(	O
1998	O
)	O
.	O
example-based	B
learning	O
for	O
view-based	O
human	O
face	O
detection	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
20	O
(	O
1	O
)	O
:39–	O
51.	O
sutherland	O
,	O
i.	O
e.	O
(	O
1974	O
)	O
.	O
three-dimensional	O
data	O
input	O
by	O
tablet	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
62	O
(	O
4	O
)	O
:453–461	O
.	O
swain	O
,	O
m.	O
j.	O
and	O
ballard	O
,	O
d.	O
h.	O
(	O
1991	O
)	O
.	O
color	B
indexing	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
7	O
(	O
1	O
)	O
:11–32	O
.	O
swaminathan	O
,	O
r.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
szeliski	O
,	O
r.	O
,	O
criminisi	O
,	O
a.	O
,	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
2002	O
)	O
.	O
on	O
the	O
motion	B
and	O
appearance	O
of	O
specularities	B
in	O
image	B
sequences	O
.	O
in	O
seventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2002	O
)	O
,	O
pp	O
.	O
508–523	O
,	O
copenhagen	O
.	O
sweldens	O
,	O
w.	O
(	O
1996	O
)	O
.	O
wavelets	O
and	O
the	O
lifting	B
scheme	O
:	O
a	O
5	O
minute	O
tour	O
.	O
z.	O
angew	O
.	O
math	O
.	O
mech.	O
,	O
76	O
(	O
suppl	O
.	O
2	O
)	O
:41–44	O
.	O
sweldens	O
,	O
w.	O
(	O
1997	O
)	O
.	O
the	O
lifting	B
scheme	O
:	O
a	O
construction	O
of	O
second	B
generation	I
wavelets	O
.	O
siam	O
j.	O
math	O
.	O
anal.	O
,	O
29	O
(	O
2	O
)	O
:511–546	O
.	O
swendsen	O
,	O
r.	O
h.	O
and	O
wang	O
,	O
j.-s.	O
(	O
1987	O
)	O
.	O
nonuniversal	O
critical	O
dynamics	O
in	O
monte	O
carlo	O
simulations	O
.	O
physical	O
review	O
letters	O
,	O
58	O
(	O
2	O
)	O
:86–88	O
.	O
szeliski	O
,	O
r.	O
(	O
1986	O
)	O
.	O
cooperative	B
algorithms	I
for	O
solving	O
random-dot	O
stereograms	O
.	O
tech-	O
nical	O
report	O
cmu-cs-86-133	O
,	O
computer	O
science	O
department	O
,	O
carnegie	O
mellon	O
uni-	O
versity	O
.	O
szeliski	O
,	O
r.	O
(	O
1989	O
)	O
.	O
bayesian	O
modeling	B
of	O
uncertainty	B
in	O
low-level	O
vision	O
.	O
kluwer	O
academic	O
publishers	O
,	O
boston	O
.	O
szeliski	O
,	O
r.	O
(	O
1990a	O
)	O
.	O
bayesian	O
modeling	B
of	O
uncertainty	B
in	O
low-level	O
vision	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
5	O
(	O
3	O
)	O
:271–301	O
.	O
szeliski	O
,	O
r.	O
(	O
1990b	O
)	O
.	O
fast	O
surface	O
interpolation	B
using	O
hierarchical	B
basis	O
functions	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
12	O
(	O
6	O
)	O
:513–528	O
.	O
szeliski	O
,	O
r.	O
(	O
1991a	O
)	O
.	O
fast	O
shape	O
from	O
shading	B
.	O
cvgip	O
:	O
image	B
understanding	O
,	O
53	O
(	O
2	O
)	O
:129–	O
153.	O
szeliski	O
,	O
r.	O
(	O
1991b	O
)	O
.	O
shape	O
from	O
rotation	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
91	O
)	O
,	O
pp	O
.	O
625–630	O
,	O
maui	O
,	O
hawaii	O
.	O
906	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
szeliski	O
,	O
r.	O
(	O
1993	O
)	O
.	O
rapid	O
octree	B
construction	O
from	O
image	B
sequences	O
.	O
cvgip	O
:	O
image	B
understanding	O
,	O
58	O
(	O
1	O
)	O
:23–32	O
.	O
szeliski	O
,	O
r.	O
(	O
1994	O
)	O
.	O
image	B
mosaicing	O
for	O
tele-reality	O
applications	O
.	O
in	O
ieee	O
workshop	O
on	O
applications	O
of	O
computer	O
vision	O
(	O
wacv	O
’	O
94	O
)	O
,	O
pp	O
.	O
44–53	O
,	O
sarasota	O
.	O
szeliski	O
,	O
r.	O
(	O
1996	O
)	O
.	O
video	B
mosaics	O
for	O
virtual	O
environments	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
16	O
(	O
2	O
)	O
:22–30	O
.	O
szeliski	O
,	O
r.	O
(	O
1999	O
)	O
.	O
a	O
multi-view	B
approach	O
to	O
motion	B
and	O
stereo	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
99	O
)	O
,	O
pp	O
.	O
157–	O
163	O
,	O
fort	O
collins	O
.	O
szeliski	O
,	O
r.	O
(	O
2006a	O
)	O
.	O
image	B
alignment	O
and	O
stitching	O
:	O
a	O
tutorial	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
2	O
(	O
1	O
)	O
:1–104	O
.	O
szeliski	O
,	O
r.	O
(	O
2006b	O
)	O
.	O
locally	O
adapted	O
hierarchical	B
basis	O
preconditioning	O
.	O
acm	O
transac-	O
tions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2006	O
)	O
,	O
25	O
(	O
3	O
)	O
:1135–1143	O
.	O
szeliski	O
,	O
r.	O
and	O
coughlan	O
,	O
j	O
.	O
(	O
1997	O
)	O
.	O
spline-based	B
image	O
registration	B
.	O
international	O
jour-	O
nal	O
of	O
computer	O
vision	O
,	O
22	O
(	O
3	O
)	O
:199–218	O
.	O
szeliski	O
,	O
r.	O
and	O
golland	O
,	O
p.	O
(	O
1999	O
)	O
.	O
stereo	B
matching	I
with	O
transparency	B
and	O
matting	B
.	O
inter-	O
national	O
journal	O
of	O
computer	O
vision	O
,	O
32	O
(	O
1	O
)	O
:45–61	O
.	O
special	O
issue	O
for	O
marr	O
prize	O
papers	O
.	O
szeliski	O
,	O
r.	O
and	O
hinton	O
,	O
g.	O
(	O
1985	O
)	O
.	O
solving	O
random-dot	O
stereograms	O
using	O
the	O
heat	O
equa-	O
tion	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recogni-	O
tion	B
(	O
cvpr	O
’	O
85	O
)	O
,	O
pp	O
.	O
284–288	O
,	O
san	O
francisco	O
.	O
szeliski	O
,	O
r.	O
and	O
ito	O
,	O
m.	O
r.	O
(	O
1986	O
)	O
.	O
new	O
hermite	O
cubic	B
interpolator	O
for	O
two-dimensional	O
curve	O
generation	O
.	O
iee	O
proceedings	O
e	O
,	O
133	O
(	O
6	O
)	O
:341–347	O
.	O
szeliski	O
,	O
r.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
1994	O
)	O
.	O
recovering	O
3d	O
shape	O
and	O
motion	B
from	O
image	B
streams	O
using	O
nonlinear	O
least	B
squares	I
.	O
journal	O
of	O
visual	O
communication	O
and	O
image	B
represen-	O
tation	O
,	O
5	O
(	O
1	O
)	O
:10–28	O
.	O
szeliski	O
,	O
r.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
1995	O
)	O
.	O
direct	B
methods	O
for	O
visual	O
scene	O
reconstruction	O
.	O
in	O
ieee	O
workshop	O
on	O
representations	O
of	O
visual	O
scenes	O
,	O
pp	O
.	O
26–33	O
,	O
cambridge	O
,	O
mas-	O
sachusetts	O
.	O
szeliski	O
,	O
r.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
1997	O
)	O
.	O
shape	O
ambiguities	O
in	O
structure	B
from	I
motion	I
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
5	O
)	O
:506–512	O
.	O
szeliski	O
,	O
r.	O
and	O
lavall´ee	O
,	O
s.	O
(	O
1996	O
)	O
.	O
matching	B
3-d	O
anatomical	O
surfaces	O
with	O
non-rigid	O
de-	O
formations	O
using	O
octree-splines	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
18	O
(	O
2	O
)	O
:171–	O
186.	O
references	B
907	O
szeliski	O
,	O
r.	O
and	O
scharstein	O
,	O
d.	O
(	O
2004	O
)	O
.	O
sampling	B
the	O
disparity	O
space	O
image	O
.	O
ieee	O
trans-	O
actions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
26	O
(	O
3	O
)	O
:419–425	O
.	O
szeliski	O
,	O
r.	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
1996	O
)	O
.	O
motion	B
estimation	I
with	O
quadtree	B
splines	O
.	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
18	O
(	O
12	O
)	O
:1199–1210	O
.	O
ieee	O
szeliski	O
,	O
r.	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
1997	O
)	O
.	O
creating	O
full	O
view	O
panoramic	O
image	B
mosaics	O
and	O
texture-mapped	O
models	O
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
251–	O
258	O
,	O
los	O
angeles	O
.	O
szeliski	O
,	O
r.	O
and	O
tonnesen	O
,	O
d.	O
(	O
1992	O
)	O
.	O
surface	B
modeling	O
with	O
oriented	O
particle	O
systems	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
92	O
)	O
,	O
26	O
(	O
2	O
)	O
:185–194	O
.	O
szeliski	O
,	O
r.	O
and	O
torr	O
,	O
p.	O
(	O
1998	O
)	O
.	O
geometrically	O
constrained	B
structure	O
from	O
motion	B
:	O
points	B
on	O
planes	B
.	O
in	O
european	O
workshop	O
on	O
3d	O
structure	O
from	O
multiple	O
images	O
of	O
large-scale	O
environments	O
(	O
smile	O
)	O
,	O
pp	O
.	O
171–186	O
,	O
freiburg	O
,	O
germany	O
.	O
szeliski	O
,	O
r.	O
and	O
weiss	O
,	O
r.	O
(	O
1998	O
)	O
.	O
robust	B
shape	O
recovery	B
from	O
occluding	O
contours	O
using	O
a	O
linear	B
smoother	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
28	O
(	O
1	O
)	O
:27–44	O
.	O
szeliski	O
,	O
r.	O
,	O
avidan	O
,	O
s.	O
,	O
and	O
anandan	O
,	O
p.	O
(	O
2000	O
)	O
.	O
layer	O
extraction	O
from	O
multiple	B
im-	O
in	O
ieee	O
computer	O
society	O
conference	O
ages	O
containing	O
reﬂections	B
and	O
transparency	B
.	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2000	O
)	O
,	O
pp	O
.	O
246–253	O
,	O
hilton	O
head	B
island	O
.	O
szeliski	O
,	O
r.	O
,	O
tonnesen	O
,	O
d.	O
,	O
and	O
terzopoulos	O
,	O
d.	O
(	O
1993a	O
)	O
.	O
curvature	O
and	O
continuity	O
control	O
in	O
particle-based	O
surface	B
models	O
.	O
in	O
spie	O
vol	O
.	O
2031	O
,	O
geometric	B
methods	O
in	O
computer	O
vision	O
ii	O
,	O
pp	O
.	O
172–181	O
,	O
san	O
diego	O
.	O
szeliski	O
,	O
r.	O
,	O
tonnesen	O
,	O
d.	O
,	O
and	O
terzopoulos	O
,	O
d.	O
(	O
1993b	O
)	O
.	O
modeling	B
surfaces	O
of	O
arbitrary	O
topology	O
with	O
dynamic	O
particles	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
93	O
)	O
,	O
pp	O
.	O
82–87	O
,	O
new	O
york	O
.	O
szeliski	O
,	O
r.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
and	O
steedly	O
,	O
d.	O
(	O
2008	O
)	O
.	O
fast	O
poisson	O
blending	B
using	O
multi-	O
splines	B
.	O
technical	O
report	O
msr-tr-2008-58	O
,	O
microsoft	O
research	O
.	O
szeliski	O
,	O
r.	O
,	O
winder	O
,	O
s.	O
,	O
and	O
uyttendaele	O
,	O
m.	O
(	O
2010	O
)	O
.	O
high-quality	O
multi-pass	B
image	O
re-	O
sampling	B
.	O
technical	O
report	O
msr-tr-2010-10	O
,	O
microsoft	O
research	O
.	O
szeliski	O
,	O
r.	O
,	O
zabih	O
,	O
r.	O
,	O
scharstein	O
,	O
d.	O
,	O
veksler	O
,	O
o.	O
,	O
kolmogorov	O
,	O
v.	O
,	O
agarwala	O
,	O
a.	O
,	O
tappen	O
,	O
m.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
2008	O
)	O
.	O
a	O
comparative	O
study	O
of	O
energy	O
minimization	O
methods	O
for	O
ieee	O
transactions	O
on	O
pattern	O
markov	O
random	O
ﬁelds	O
with	O
smoothness-based	O
priors	O
.	O
analysis	O
and	O
machine	O
intelligence	O
,	O
30	O
(	O
6	O
)	O
:1068–1080	O
.	O
szummer	O
,	O
m.	O
and	O
picard	O
,	O
r.	O
w.	O
(	O
1996	O
)	O
.	O
temporal	O
texture	B
modeling	O
.	O
in	O
ieee	O
international	O
conference	O
on	O
image	B
processing	O
(	O
icip-96	O
)	O
,	O
pp	O
.	O
823–826	O
,	O
lausanne	O
.	O
908	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
tabb	O
,	O
m.	O
and	O
ahuja	O
,	O
n.	O
(	O
1997	O
)	O
.	O
multiscale	O
image	B
segmentation	O
by	O
integrated	O
edge	O
and	O
region	B
detection	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
6	O
(	O
5	O
)	O
:642–655	O
.	O
taguchi	O
,	O
y.	O
,	O
wilburn	O
,	O
b.	O
,	O
and	O
zitnick	O
,	O
c.	O
l.	O
(	O
2008	O
)	O
.	O
stereo	B
reconstruction	O
with	O
mixed	O
pixels	O
using	O
adaptive	O
over-segmentation	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
tanaka	O
,	O
m.	O
and	O
okutomi	O
,	O
m.	O
(	O
2008	O
)	O
.	O
locally	B
adaptive	I
learning	O
for	O
translation-variant	O
mrf	O
image	B
priors	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
tao	O
,	O
h.	O
,	O
sawhney	O
,	O
h.	O
s.	O
,	O
and	O
kumar	O
,	O
r.	O
(	O
2001	O
)	O
.	O
a	O
global	B
matching	O
framework	O
for	O
stereo	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
computation	O
.	O
pp	O
.	O
532–539	O
,	O
vancouver	O
,	O
canada	O
.	O
tappen	O
,	O
m.	O
f.	O
(	O
2007	O
)	O
.	O
utilizing	O
variational	O
optimization	O
to	O
learn	O
markov	O
random	O
ﬁelds	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
tappen	O
,	O
m.	O
f.	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2003	O
)	O
.	O
comparison	O
of	O
graph	B
cuts	I
with	O
belief	O
propaga-	O
tion	B
for	O
stereo	B
,	O
using	O
identical	O
mrf	O
parameters	B
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
900–907	O
,	O
nice	O
,	O
france	O
.	O
tappen	O
,	O
m.	O
f.	O
,	O
freeman	O
,	O
w.	O
t.	O
,	O
and	O
adelson	O
,	O
e.	O
h.	O
(	O
2005	O
)	O
.	O
recovering	O
intrinsic	B
images	O
from	O
a	O
single	O
image	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
27	O
(	O
9	O
)	O
:1459–1472	O
.	O
tappen	O
,	O
m.	O
f.	O
,	O
russell	O
,	O
b.	O
c.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2003	O
)	O
.	O
exploiting	O
the	O
sparse	B
derivative	O
prior	B
for	O
super-resolution	O
and	O
image	B
demosaicing	O
.	O
in	O
third	O
international	O
workshop	O
on	O
statistical	O
and	O
computational	O
theories	O
of	O
vision	O
,	O
nice	O
,	O
france	O
.	O
tappen	O
,	O
m.	O
f.	O
,	O
liu	O
,	O
c.	O
,	O
freeman	O
,	O
w.	O
,	O
and	O
adelson	O
,	O
e.	O
(	O
2007	O
)	O
.	O
learning	B
gaussian	O
con-	O
ditional	O
random	O
ﬁelds	O
for	O
low-level	O
vision	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
tardif	O
,	O
j.-p.	O
(	O
2009	O
)	O
.	O
non-iterative	O
approach	O
for	O
fast	O
and	O
accurate	O
vanishing	O
point	O
detection	B
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
tardif	O
,	O
j.-p.	O
,	O
sturm	O
,	O
p.	O
,	O
and	O
roy	O
,	O
s.	O
(	O
2007	O
)	O
.	O
plane-based	B
self-calibration	O
of	O
radial	B
distortion	I
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
tardif	O
,	O
j.-p.	O
,	O
sturm	O
,	O
p.	O
,	O
trudeau	O
,	O
m.	O
,	O
and	O
roy	O
,	O
s.	O
(	O
2009	O
)	O
.	O
calibration	B
of	O
cameras	O
with	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
radially	O
symmetric	O
distortion	O
.	O
intelligence	O
,	O
31	O
(	O
9	O
)	O
:1552–1566	O
.	O
references	B
909	O
taubin	O
,	O
g.	O
(	O
1995	O
)	O
.	O
curve	O
and	O
surface	B
smoothing	O
without	O
shrinkage	O
.	O
in	O
fifth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
95	O
)	O
,	O
pp	O
.	O
852–857	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
taubman	O
,	O
d.	O
s.	O
and	O
marcellin	O
,	O
m.	O
w.	O
(	O
2002	O
)	O
.	O
jpeg2000	O
:	O
standard	O
for	O
interactive	B
imaging	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
90	O
(	O
8	O
)	O
:1336–1357	O
.	O
taylor	O
,	O
c.	O
j	O
.	O
(	O
2003	O
)	O
.	O
surface	B
reconstruction	I
from	O
feature	B
based	O
stereo	B
.	O
in	O
ninth	O
interna-	O
tional	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
184–190	O
,	O
nice	O
,	O
france	O
.	O
taylor	O
,	O
c.	O
j.	O
,	O
debevec	O
,	O
p.	O
e.	O
,	O
and	O
malik	O
,	O
j	O
.	O
(	O
1996	O
)	O
.	O
reconstructing	O
polyhedral	O
models	O
of	O
architectural	O
scenes	O
from	O
photographs	O
.	O
in	O
fourth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
96	O
)	O
,	O
pp	O
.	O
659–668	O
,	O
cambridge	O
,	O
england	O
.	O
taylor	O
,	O
c.	O
j.	O
,	O
kriegman	O
,	O
d.	O
j.	O
,	O
and	O
anandan	O
,	O
p.	O
dimensions	O
from	O
multiple	B
images	O
:	O
a	O
least	B
squares	I
approach	O
.	O
visual	O
motion	O
,	O
pp	O
.	O
242–248	O
,	O
princeton	O
,	O
new	O
jersey	O
.	O
(	O
1991	O
)	O
.	O
structure	O
and	O
motion	B
in	O
two	O
in	O
ieee	O
workshop	O
on	O
taylor	O
,	O
p.	O
(	O
2009	O
)	O
.	O
text-to-speech	O
synthesis	O
.	O
cambridge	O
university	O
press	O
,	O
cambridge	O
.	O
tek	O
,	O
k.	O
and	O
kimia	O
,	O
b.	O
b	O
.	O
(	O
2003	O
)	O
.	O
symmetry	O
maps	O
of	O
free-form	O
curve	O
segments	O
via	O
wave	O
propagation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
54	O
(	O
1-3	O
)	O
:35–81	O
.	O
tekalp	O
,	O
m.	O
(	O
1995	O
)	O
.	O
digital	O
video	O
processing	O
.	O
prentice	O
hall	O
,	O
upper	O
saddle	O
river	O
,	O
nj	O
.	O
telea	O
,	O
a	O
.	O
(	O
2004	O
)	O
.	O
an	O
image	B
inpainting	O
technique	O
based	O
on	O
fast	B
marching	I
method	I
.	O
journal	O
of	O
graphics	O
tools	O
,	O
9	O
(	O
1	O
)	O
:23–34	O
.	O
teller	O
,	O
s.	O
,	O
antone	O
,	O
m.	O
,	O
bodnar	O
,	O
z.	O
,	O
bosse	O
,	O
m.	O
,	O
coorg	O
,	O
s.	O
,	O
jethwa	O
,	O
m.	O
,	O
and	O
master	O
,	O
n.	O
(	O
2003	O
)	O
.	O
calibrated	O
,	O
registered	O
images	O
of	O
an	O
extended	O
urban	O
area	O
.	O
international	O
journal	O
of	O
com-	O
puter	O
vision	O
,	O
53	O
(	O
1	O
)	O
:93–107	O
.	O
teodosio	O
,	O
l.	O
and	O
bender	O
,	O
w.	O
(	O
1993	O
)	O
.	O
salient	O
video	B
stills	O
:	O
content	O
and	O
context	B
preserved	O
.	O
in	O
acm	O
multimedia	O
93	O
,	O
pp	O
.	O
39–46	O
,	O
anaheim	O
,	O
california	O
.	O
terzopoulos	O
,	O
d.	O
(	O
1983	O
)	O
.	O
multilevel	B
computational	O
processes	O
for	O
visual	O
surface	B
reconstruc-	O
tion	B
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
24:52–96	O
.	O
terzopoulos	O
,	O
d.	O
(	O
1986a	O
)	O
.	O
image	B
analysis	O
using	O
multigrid	O
relaxation	O
methods	O
.	O
ieee	O
trans-	O
actions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-8	O
(	O
2	O
)	O
:129–139	O
.	O
terzopoulos	O
,	O
d.	O
tinuities	O
.	O
8	O
(	O
4	O
)	O
:413–424	O
.	O
(	O
1986b	O
)	O
.	O
regularization	B
of	O
inverse	B
visual	O
problems	O
involving	O
discon-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-	O
terzopoulos	O
,	O
d.	O
(	O
1988	O
)	O
.	O
the	O
computation	O
of	O
visible-surface	O
representations	O
.	O
ieee	O
trans-	O
actions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
pami-10	O
(	O
4	O
)	O
:417–438	O
.	O
terzopoulos	O
,	O
d.	O
(	O
1999	O
)	O
.	O
visual	O
modeling	O
for	O
computer	O
animation	O
:	O
graphics	O
with	O
a	O
vision	O
.	O
computer	O
graphics	O
,	O
33	O
(	O
4	O
)	O
:42–45	O
.	O
910	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
terzopoulos	O
,	O
d.	O
and	O
fleischer	O
,	O
k.	O
(	O
1988	O
)	O
.	O
deformable	O
models	O
.	O
the	O
visual	O
computer	O
,	O
4	O
(	O
6	O
)	O
:306–331	O
.	O
terzopoulos	O
,	O
d.	O
and	O
metaxas	O
,	O
d.	O
(	O
1991	O
)	O
.	O
dynamic	B
3d	O
models	O
with	O
local	O
and	O
global	B
de-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
formations	O
:	O
deformable	O
superquadrics	O
.	O
machine	O
intelligence	O
,	O
13	O
(	O
7	O
)	O
:703–714	O
.	O
terzopoulos	O
,	O
d.	O
and	O
szeliski	O
,	O
r.	O
(	O
1992	O
)	O
.	O
tracking	O
with	O
kalman	O
snakes	B
.	O
in	O
blake	O
,	O
a.	O
and	O
yuille	O
,	O
a.	O
l.	O
(	O
eds	O
)	O
,	O
active	O
vision	O
,	O
pp	O
.	O
3–20	O
,	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
terzopoulos	O
,	O
d.	O
and	O
waters	O
,	O
k.	O
(	O
1990	O
)	O
.	O
analysis	O
of	O
facial	O
images	O
using	O
physical	O
and	O
anatomical	O
models	O
.	O
in	O
third	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
90	O
)	O
,	O
pp	O
.	O
727–732	O
,	O
osaka	O
,	O
japan	O
.	O
terzopoulos	O
,	O
d.	O
and	O
witkin	O
,	O
a	O
.	O
(	O
1988	O
)	O
.	O
physically-based	O
models	O
with	O
rigid	O
and	O
deformable	O
components	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
8	O
(	O
6	O
)	O
:41–51	O
.	O
terzopoulos	O
,	O
d.	O
,	O
witkin	O
,	O
a.	O
,	O
and	O
kass	O
,	O
m.	O
(	O
1987	O
)	O
.	O
symmetry-seeking	B
models	O
and	O
3d	O
object	O
reconstruction	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
1	O
(	O
3	O
)	O
:211–221	O
.	O
terzopoulos	O
,	O
d.	O
,	O
witkin	O
,	O
a.	O
,	O
and	O
kass	O
,	O
m.	O
(	O
1988	O
)	O
.	O
constraints	O
on	O
deformable	O
models	O
:	O
recovering	O
3d	O
shape	O
and	O
nonrigid	O
motion	B
.	O
artiﬁcial	O
intelligence	O
,	O
36	O
(	O
1	O
)	O
:91–123	O
.	O
thayananthan	O
,	O
a.	O
,	O
iwasaki	O
,	O
m.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2008	O
)	O
.	O
principled	O
fusion	O
of	O
high-level	O
model	O
and	O
low-level	O
cues	O
for	O
motion	O
segmentation	B
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
thirthala	O
,	O
s.	O
and	O
pollefeys	O
,	O
m.	O
(	O
2005	O
)	O
.	O
the	O
radial	B
trifocal	O
tensor	O
:	O
a	O
tool	O
for	O
calibrating	O
the	O
radial	B
distortion	I
of	O
wide-angle	O
cameras	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
321–328	O
,	O
san	O
diego	O
,	O
ca	O
.	O
(	O
2007	O
)	O
.	O
gaussian	O
random	O
thomas	O
,	O
d.	O
b.	O
,	O
luk	O
,	O
w.	O
,	O
leong	O
,	O
p.	O
h.	O
,	O
and	O
villasenor	O
,	O
j.	O
d.	O
number	O
generators	O
.	O
acm	O
computing	O
surveys	B
,	O
39	O
(	O
4	O
)	O
.	O
thrun	O
,	O
s.	O
,	O
burgard	O
,	O
w.	O
,	O
and	O
fox	O
,	O
d.	O
(	O
2005	O
)	O
.	O
probabilistic	B
robotics	O
.	O
the	O
mit	O
press	O
,	O
cambridge	O
,	O
massachusetts	O
.	O
thrun	O
,	O
s.	O
,	O
montemerlo	O
,	O
m.	O
,	O
dahlkamp	O
,	O
h.	O
,	O
stavens	O
,	O
d.	O
,	O
aron	O
,	O
a.	O
et	O
al	O
.	O
(	O
2006	O
)	O
.	O
stanley	O
,	O
the	O
robot	O
that	O
won	O
the	O
darpa	O
grand	O
challenge	O
.	O
journal	O
of	O
field	O
robotics	O
,	O
23	O
(	O
9	O
)	O
:661–692	O
.	O
tian	O
,	O
q.	O
and	O
huhns	O
,	O
m.	O
n.	O
(	O
1986	O
)	O
.	O
algorithms	O
for	O
subpixel	O
registration	B
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
35:220–233	O
.	O
tikhonov	O
,	O
a.	O
n.	O
and	O
arsenin	O
,	O
v.	O
y	O
.	O
(	O
1977	O
)	O
.	O
solutions	O
of	O
ill-posed	O
problems	O
.	O
v.	O
h.	O
winston	O
,	O
washington	O
,	O
d.	O
c.	O
tipping	O
,	O
m.	O
e.	O
and	O
bishop	O
,	O
c.	O
m.	O
(	O
1999	O
)	O
.	O
probabilistic	B
principal	O
components	O
analysis	O
.	O
journal	O
of	O
the	O
royal	O
statistical	O
society	O
,	O
series	O
b	O
,	O
61	O
(	O
3	O
)	O
:611–622	O
.	O
references	B
911	O
toint	O
,	O
p.	O
l.	O
(	O
1987	O
)	O
.	O
on	O
large	B
scale	I
nonlinear	O
least	B
squares	I
calculations	O
.	O
siam	O
j.	O
sci	O
.	O
stat	O
.	O
comput.	O
,	O
8	O
(	O
3	O
)	O
:416–435	O
.	O
tola	O
,	O
e.	O
,	O
lepetit	O
,	O
v.	O
,	O
and	O
fua	O
,	O
p.	O
(	O
2010	O
)	O
.	O
daisy	O
:	O
an	O
efﬁcient	O
dense	O
descriptor	O
applied	O
to	O
wide-baseline	O
stereo	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
32	O
(	O
5	O
)	O
:815–830	O
.	O
tolliver	O
,	O
d.	O
and	O
miller	O
,	O
g.	O
(	O
2006	O
)	O
.	O
graph	O
partitioning	O
by	O
spectral	O
rounding	O
:	O
applications	O
in	O
image	B
segmentation	O
and	O
clustering	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
com-	O
puter	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
1053–1060	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
tomasi	O
,	O
c.	O
and	O
kanade	O
,	O
t.	O
(	O
1992	O
)	O
.	O
shape	O
and	O
motion	B
from	O
image	B
streams	O
under	O
orthogra-	O
phy	O
:	O
a	O
factorization	B
method	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
9	O
(	O
2	O
)	O
:137–154	O
.	O
tomasi	O
,	O
c.	O
and	O
manduchi	O
,	O
r.	O
(	O
1998	O
)	O
.	O
bilateral	B
ﬁltering	O
for	O
gray	O
and	O
color	B
images	O
.	O
in	O
sixth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
839–846	O
,	O
bombay	O
.	O
tombari	O
,	O
f.	O
,	O
mattoccia	O
,	O
s.	O
,	O
and	O
di	O
stefano	O
,	O
l.	O
(	O
2007	O
)	O
.	O
segmentation-based	B
adaptive	O
support	O
in	O
paciﬁc-rim	O
symposium	O
on	O
image	B
and	O
video	B
for	O
accurate	O
stereo	B
correspondence	O
.	O
technology	O
.	O
tombari	O
,	O
f.	O
,	O
mattoccia	O
,	O
s.	O
,	O
di	O
stefano	O
,	O
l.	O
,	O
and	O
addimanda	O
,	O
e.	O
(	O
2008	O
)	O
.	O
classiﬁcation	O
and	O
evaluation	B
of	O
cost	O
aggregation	B
methods	I
for	O
stereo	B
correspondence	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
an-	O
chorage	O
,	O
ak	O
.	O
tommasini	O
,	O
t.	O
,	O
fusiello	O
,	O
a.	O
,	O
trucco	O
,	O
e.	O
,	O
and	O
roberto	O
,	O
v.	O
(	O
1998	O
)	O
.	O
making	O
good	O
features	O
track	O
better	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
98	O
)	O
,	O
pp	O
.	O
178–183	O
,	O
santa	O
barbara	O
.	O
torborg	O
,	O
j.	O
and	O
kajiya	O
,	O
j.	O
t.	O
(	O
1996	O
)	O
.	O
talisman	O
:	O
commodity	O
realtime	O
3d	O
graphics	O
for	O
the	O
pc	O
.	O
in	O
acm	O
siggraph	O
1996	O
conference	O
proceedings	O
,	O
pp	O
.	O
353–363	O
,	O
new	O
orleans	O
.	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2002	O
)	O
.	O
bayesian	O
model	O
estimation	B
and	O
selection	O
for	O
epipolar	O
geometry	O
and	O
generic	O
manifold	O
ﬁtting	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
50	O
(	O
1	O
)	O
:35–61	O
.	O
torr	O
,	O
p.	O
h.	O
s.	O
and	O
fitzgibbon	O
,	O
a.	O
w.	O
(	O
2004	O
)	O
.	O
invariant	O
ﬁtting	O
of	O
two	O
view	O
geometry	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
26	O
(	O
5	O
)	O
:648–650	O
.	O
torr	O
,	O
p.	O
h.	O
s.	O
and	O
murray	O
,	O
d.	O
(	O
1997	O
)	O
.	O
the	O
development	O
and	O
comparison	O
of	O
robust	B
meth-	O
ods	O
for	O
estimating	O
the	O
fundamental	O
matrix	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
24	O
(	O
3	O
)	O
:271–300	O
.	O
torr	O
,	O
p.	O
h.	O
s.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
anandan	O
,	O
p.	O
(	O
1999	O
)	O
.	O
an	O
integrated	O
bayesian	O
approach	O
to	O
layer	O
extraction	O
from	O
image	B
sequences	O
.	O
in	O
seventh	O
international	O
conference	O
on	O
com-	O
puter	O
vision	O
(	O
iccv	O
’	O
99	O
)	O
,	O
pp	O
.	O
983–990	O
,	O
kerkyra	O
,	O
greece	O
.	O
912	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
torr	O
,	O
p.	O
h.	O
s.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
anandan	O
,	O
p.	O
(	O
2001	O
)	O
.	O
an	O
integrated	O
bayesian	O
approach	O
to	O
layer	O
extraction	O
from	O
image	B
sequences	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
23	O
(	O
3	O
)	O
:297–303	O
.	O
torralba	O
,	O
a	O
.	O
(	O
2003	O
)	O
.	O
contextual	O
priming	O
for	O
object	O
detection	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
53	O
(	O
2	O
)	O
:169–191	O
.	O
torralba	O
,	O
a	O
.	O
(	O
2007	O
)	O
.	O
classiﬁer-based	O
methods	O
.	O
recognizing	O
and	O
learning	B
object	O
categories	O
.	O
shortcourserloc/	O
.	O
in	O
cvpr	O
2007	O
short	O
course	O
on	O
http	O
:	O
//people.csail.mit.edu/torralba/	O
torralba	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
object	O
recognition	B
and	O
scene	B
understanding	I
.	O
mit	O
course	O
6.870	O
,	O
http	O
:	O
//people.csail.mit.edu/torralba/courses/6.870/6.870.recognition.htm	O
.	O
torralba	O
,	O
a.	O
,	O
freeman	O
,	O
w.	O
t.	O
,	O
and	O
fergus	O
,	O
r.	O
(	O
2008	O
)	O
.	O
80	O
million	O
tiny	O
images	O
:	O
a	O
large	O
dataset	O
for	O
non-parametric	O
object	O
and	O
scene	O
recognition	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
30	O
(	O
11	O
)	O
:1958–1970	O
.	O
torralba	O
,	O
a.	O
,	O
murphy	O
,	O
k.	O
p.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2004	O
)	O
.	O
contextual	O
models	O
for	O
object	O
detection	B
using	O
boosted	O
random	O
ﬁelds	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
torralba	O
,	O
a.	O
,	O
murphy	O
,	O
k.	O
p.	O
,	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2007	O
)	O
.	O
sharing	O
visual	O
features	O
for	O
mul-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
ticlass	O
and	O
multiview	O
object	O
detection	B
.	O
machine	O
intelligence	O
,	O
29	O
(	O
5	O
)	O
:854–869	O
.	O
torralba	O
,	O
a.	O
,	O
weiss	O
,	O
y.	O
,	O
and	O
fergus	O
,	O
r.	O
(	O
2008	O
)	O
.	O
small	O
codes	O
and	O
large	O
databases	O
of	O
images	O
for	O
object	O
recognition	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
torralba	O
,	O
a.	O
,	O
murphy	O
,	O
k.	O
p.	O
,	O
freeman	O
,	O
w.	O
t.	O
,	O
and	O
rubin	O
,	O
m.	O
a	O
.	O
(	O
2003	O
)	O
.	O
context-based	O
vision	O
system	O
for	O
place	O
and	O
object	O
recognition	B
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
273–280	O
,	O
nice	O
,	O
france	O
.	O
torrance	O
,	O
k.	O
e.	O
and	O
sparrow	O
,	O
e.	O
m.	O
(	O
1967	O
)	O
.	O
theory	O
for	O
off-specular	O
reﬂection	O
from	O
rough-	O
ened	O
surfaces	O
.	O
journal	O
of	O
the	O
optical	O
society	O
of	O
america	O
a	O
,	O
57	O
(	O
9	O
)	O
:1105–1114	O
.	O
torresani	O
,	O
l.	O
,	O
hertzmann	O
,	O
a.	O
,	O
and	O
bregler	O
,	O
c.	O
(	O
2008	O
)	O
.	O
non-rigid	B
structure-from-motion	O
:	O
estimating	O
shape	O
and	O
motion	B
with	O
hierarchical	B
priors	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
30	O
(	O
5	O
)	O
:878–892	O
.	O
toyama	O
,	O
k.	O
(	O
1998	O
)	O
.	O
prolegomena	O
for	O
robust	O
face	B
tracking	O
.	O
technical	O
report	O
msr-tr-	O
98-65	O
,	O
microsoft	O
research	O
.	O
toyama	O
,	O
k.	O
,	O
krumm	O
,	O
j.	O
,	O
brumitt	O
,	O
b.	O
,	O
and	O
meyers	O
,	O
b	O
.	O
(	O
1999	O
)	O
.	O
wallﬂower	O
:	O
principles	O
and	O
practice	O
of	O
background	O
maintenance	O
.	O
in	O
seventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
99	O
)	O
,	O
pp	O
.	O
255–261	O
,	O
kerkyra	O
,	O
greece	O
.	O
references	B
913	O
tran	O
,	O
s.	O
and	O
davis	O
,	O
l.	O
(	O
2002	O
)	O
.	O
3d	O
surface	B
reconstruction	I
using	O
graph	B
cuts	I
with	O
surface	B
con-	O
straints	O
.	O
in	O
seventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2002	O
)	O
,	O
pp	O
.	O
219–	O
231	O
,	O
copenhagen	O
.	O
trefethen	O
,	O
l.	O
n.	O
and	O
bau	O
,	O
d.	O
(	O
1997	O
)	O
.	O
numerical	O
linear	B
algebra	O
.	O
siam	O
.	O
treisman	O
,	O
a	O
.	O
(	O
1985	O
)	O
.	O
preattentive	O
processing	O
in	O
vision	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
31	O
(	O
2	O
)	O
:156–177	O
.	O
triggs	O
,	O
b	O
.	O
(	O
1996	O
)	O
.	O
factorization	B
methods	O
for	O
projective	O
structure	O
and	O
motion	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
96	O
)	O
,	O
pp	O
.	O
845–851	O
,	O
san	O
francisco	O
.	O
triggs	O
,	O
b	O
.	O
(	O
2004	O
)	O
.	O
detecting	O
keypoints	O
with	O
stable	O
position	O
,	O
orientation	O
,	O
and	O
scale	O
un-	O
der	O
illumination	O
changes	O
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
100–113	O
,	O
prague	O
.	O
triggs	O
,	O
b.	O
,	O
mclauchlan	O
,	O
p.	O
f.	O
,	O
hartley	O
,	O
r.	O
i.	O
,	O
and	O
fitzgibbon	O
,	O
a.	O
w.	O
(	O
1999	O
)	O
.	O
bundle	O
adjust-	O
ment	O
—	O
a	O
modern	O
synthesis	O
.	O
in	O
international	O
workshop	O
on	O
vision	O
algorithms	O
,	O
pp	O
.	O
298–	O
372	O
,	O
kerkyra	O
,	O
greece	O
.	O
trobin	O
,	O
w.	O
,	O
pock	O
,	O
t.	O
,	O
cremers	O
,	O
d.	O
,	O
and	O
bischof	O
,	O
h.	O
(	O
2008	O
)	O
.	O
continuous	O
energy	O
minimiza-	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
tion	B
via	O
repeated	O
binary	O
fusion	O
.	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
677–690	O
,	O
marseilles	O
.	O
troccoli	O
,	O
a.	O
and	O
allen	O
,	O
p.	O
(	O
2008	O
)	O
.	O
building	O
illumination	O
coherent	O
3d	O
models	O
of	O
large-scale	O
outdoor	O
scenes	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
78	O
(	O
2-3	O
)	O
:261–280	O
.	O
trottenberg	O
,	O
u.	O
,	O
oosterlee	O
,	O
c.	O
w.	O
,	O
and	O
schuller	O
,	O
a	O
.	O
(	O
2000	O
)	O
.	O
multigrid	O
.	O
academic	O
press	O
.	O
trucco	O
,	O
e.	O
and	O
verri	O
,	O
a	O
.	O
(	O
1998	O
)	O
.	O
introductory	O
techniques	O
for	O
3-d	O
computer	O
vision	O
.	O
pren-	O
tice	O
hall	O
,	O
upper	O
saddle	O
river	O
,	O
nj	O
.	O
tsai	O
,	O
p.	O
s.	O
and	O
shah	O
,	O
m.	O
(	O
1994	O
)	O
.	O
shape	O
from	O
shading	B
using	O
linear	B
approximation	O
.	O
image	B
and	O
vision	O
computing	O
,	O
12:487–498	O
.	O
tsai	O
,	O
r.	O
y	O
.	O
(	O
1987	O
)	O
.	O
a	O
versatile	O
camera	B
calibration	O
technique	O
for	O
high-accuracy	O
3d	O
machine	O
vision	O
metrology	O
using	O
off-the-shelf	O
tv	O
cameras	O
and	O
lenses	O
.	O
ieee	O
journal	O
of	O
robotics	O
and	O
automation	O
,	O
ra-3	O
(	O
4	O
)	O
:323–344	O
.	O
tschumperl´e	O
,	O
d.	O
(	O
2006	O
)	O
.	O
curvature-preserving	O
regularization	B
of	O
multi-valued	O
images	O
using	O
pdes	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
295–307	O
.	O
tschumperl´e	O
,	O
d.	O
and	O
deriche	O
,	O
r.	O
(	O
2005	O
)	O
.	O
vector-valued	O
image	B
regularization	O
with	O
pdes	O
:	O
a	O
common	O
framework	O
for	O
different	O
applications	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
27:506–517	O
.	O
914	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
tsin	O
,	O
y.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2006	O
)	O
.	O
stereo	B
matching	I
with	O
linear	B
superposition	O
of	O
layers	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
2	O
)	O
:290–	O
301.	O
tsin	O
,	O
y.	O
,	O
ramesh	O
,	O
v.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
2001	O
)	O
.	O
statistical	O
calibration	B
of	O
ccd	O
imaging	O
process	O
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
480–	O
487	O
,	O
vancouver	O
,	O
canada	O
.	O
tu	O
,	O
z.	O
,	O
chen	O
,	O
x.	O
,	O
yuille	O
,	O
a.	O
l.	O
,	O
and	O
zhu	O
,	O
s.-c.	O
(	O
2005	O
)	O
.	O
image	B
parsing	O
:	O
unifying	O
segmenta-	O
tion	B
,	O
detection	B
,	O
and	O
recognition	B
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
63	O
(	O
2	O
)	O
:113–	O
140.	O
tumblin	O
,	O
j.	O
and	O
rushmeier	O
,	O
h.	O
e.	O
(	O
1993	O
)	O
.	O
tone	O
reproduction	O
for	O
realistic	O
images	O
.	O
ieee	O
computer	O
graphics	O
and	O
applications	O
,	O
13	O
(	O
6	O
)	O
:42–48	O
.	O
tumblin	O
,	O
j.	O
and	O
turk	O
,	O
g.	O
(	O
1999	O
)	O
.	O
lcis	O
:	O
a	O
boundary	O
hierarchy	O
for	O
detail-preserving	O
contrast	O
reduction	O
.	O
in	O
acm	O
siggraph	O
1999	O
conference	O
proceedings	O
,	O
pp	O
.	O
83–90	O
,	O
los	O
angeles	O
.	O
tumblin	O
,	O
j.	O
,	O
agrawal	O
,	O
a.	O
,	O
and	O
raskar	O
,	O
r.	O
(	O
2005	O
)	O
.	O
why	O
i	O
want	O
a	O
gradient	O
camera	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
103–110	O
,	O
san	O
diego	O
,	O
ca	O
.	O
turcot	O
,	O
p.	O
and	O
lowe	O
,	O
d.	O
g.	O
(	O
2009	O
)	O
.	O
better	O
matching	B
with	O
fewer	O
features	O
:	O
the	O
selection	O
of	O
useful	O
features	O
in	O
large	O
database	O
recognition	B
problems	O
.	O
in	O
iccv	O
workshop	O
on	O
emergent	O
issues	O
in	O
large	O
amounts	O
of	O
visual	O
data	O
(	O
ws-lavd	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
turk	O
,	O
g.	O
and	O
levoy	O
,	O
m.	O
(	O
1994	O
)	O
.	O
zippered	O
polygonal	O
meshes	O
from	O
range	O
images	O
.	O
in	O
acm	O
siggraph	O
1994	O
conference	O
proceedings	O
,	O
pp	O
.	O
311–318	O
.	O
turk	O
,	O
g.	O
and	O
o	O
’	O
brien	O
,	O
j	O
.	O
(	O
2002	O
)	O
.	O
modelling	O
with	O
implicit	O
surfaces	O
that	O
interpolate	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
21	O
(	O
4	O
)	O
:855–873	O
.	O
turk	O
,	O
m.	O
and	O
pentland	O
,	O
a	O
.	O
(	O
1991a	O
)	O
.	O
eigenfaces	O
for	B
recognition	I
.	O
journal	O
of	O
cognitive	O
neuroscience	O
,	O
3	O
(	O
1	O
)	O
:71–86	O
.	O
turk	O
,	O
m.	O
and	O
pentland	O
,	O
a	O
.	O
(	O
1991b	O
)	O
.	O
face	B
recognition	O
using	O
eigenfaces	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
91	O
)	O
,	O
pp	O
.	O
586–	O
591	O
,	O
maui	O
,	O
hawaii	O
.	O
tuytelaars	O
,	O
t.	O
and	O
mikolajczyk	O
,	O
k.	O
(	O
2007	O
)	O
.	O
local	B
invariant	O
feature	B
detectors	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
3	O
(	O
1	O
)	O
.	O
tuytelaars	O
,	O
t.	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2004	O
)	O
.	O
matching	B
widely	O
separated	O
views	O
based	O
on	O
afﬁne	B
invariant	O
regions	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
59	O
(	O
1	O
)	O
:61–85	O
.	O
tuytelaars	O
,	O
t.	O
,	O
van	O
gool	O
,	O
l.	O
,	O
and	O
proesmans	O
,	O
m.	O
(	O
1997	O
)	O
.	O
the	O
cascaded	B
hough	O
transform	B
.	O
in	O
international	O
conference	O
on	O
image	B
processing	O
(	O
icip	O
’	O
97	O
)	O
,	O
pp	O
.	O
736–739	O
.	O
references	B
915	O
ullman	O
,	O
s.	O
(	O
1979	O
)	O
.	O
the	O
interpretation	O
of	O
structure	B
from	I
motion	I
.	O
proceedings	O
of	O
the	O
royal	O
society	O
of	O
london	O
,	O
b-203:405–426	O
.	O
unnikrishnan	O
,	O
r.	O
,	O
pantofaru	O
,	O
c.	O
,	O
and	O
hebert	O
,	O
m.	O
(	O
2007	O
)	O
.	O
toward	O
objective	O
evaluation	B
of	O
image	B
segmentation	O
algorithms	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
6	O
)	O
:828–944	O
.	O
unser	O
,	O
m.	O
(	O
1999	O
)	O
.	O
splines	B
:	O
a	O
perfect	O
ﬁt	O
for	O
signal	O
and	O
image	B
processing	O
.	O
ieee	O
signal	O
processing	O
magazine	O
,	O
16	O
(	O
6	O
)	O
:22–38	O
.	O
urmson	O
,	O
c.	O
,	O
anhalt	O
,	O
j.	O
,	O
bagnell	O
,	O
d.	O
,	O
baker	O
,	O
c.	O
,	O
bittner	O
,	O
r.	O
et	O
al	O
.	O
(	O
2008	O
)	O
.	O
autonomous	O
driving	O
in	O
urban	O
environments	O
:	O
boss	O
and	O
the	O
urban	O
challenge	O
.	O
journal	O
of	O
field	O
robotics	O
,	O
25	O
(	O
8	O
)	O
:425–466	O
.	O
urtasun	O
,	O
r.	O
,	O
fleet	O
,	O
d.	O
j.	O
,	O
and	O
fua	O
,	O
p.	O
(	O
2006	O
)	O
.	O
temporal	O
motion	B
models	I
for	O
monocular	O
and	O
multiview	O
3d	O
human	B
body	I
tracking	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-3	O
)	O
:157–177	O
.	O
uyttendaele	O
,	O
m.	O
,	O
eden	O
,	O
a.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2001	O
)	O
.	O
eliminating	O
ghosting	O
and	O
exposure	O
artifacts	O
in	O
image	B
mosaics	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2001	O
)	O
,	O
pp	O
.	O
509–516	O
,	O
kauai	O
,	O
hawaii	O
.	O
uyttendaele	O
,	O
m.	O
,	O
criminisi	O
,	O
a.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
winder	O
,	O
s.	O
,	O
hartley	O
,	O
r.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2004	O
)	O
.	O
image-based	B
interactive	O
exploration	O
of	O
real-world	O
environments	O
.	O
ieee	O
com-	O
puter	O
graphics	O
and	O
applications	O
,	O
24	O
(	O
3	O
)	O
:52–63	O
.	O
vaillant	O
,	O
r.	O
and	O
faugeras	O
,	O
o.	O
d.	O
(	O
1992	O
)	O
.	O
using	O
extremal	O
boundaries	O
for	O
3-d	O
object	O
model-	O
ing	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
14	O
(	O
2	O
)	O
:157–173	O
.	O
vaish	O
,	O
v.	O
,	O
szeliski	O
,	O
r.	O
,	O
zitnick	O
,	O
c.	O
l.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
and	O
levoy	O
,	O
m.	O
(	O
2006	O
)	O
.	O
reconstructing	O
occluded	O
surfaces	O
using	O
synthetic	O
apertures	O
:	O
shape	O
from	O
focus	B
vs.	O
shape	O
from	O
stereo	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
2331–2338	O
,	O
new	O
york	O
,	O
ny	O
.	O
van	O
de	O
weijer	O
,	O
j.	O
and	O
schmid	O
,	O
c.	O
(	O
2006	O
)	O
.	O
coloring	O
local	O
feature	O
extraction	O
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
334–348	O
.	O
van	O
den	O
hengel	O
,	O
a.	O
,	O
dick	O
,	O
a.	O
,	O
thormhlen	O
,	O
t.	O
,	O
ward	O
,	O
b.	O
,	O
and	O
torr	O
,	O
p.	O
h.	O
s.	O
(	O
2007	O
)	O
.	O
video-	O
trace	O
:	O
rapid	O
interactive	B
scene	O
modeling	B
from	O
video	B
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
van	O
huffel	O
,	O
s.	O
and	O
lemmerling	O
,	O
p.	O
(	O
eds	O
)	O
.	O
(	O
2002	O
)	O
.	O
total	B
least	O
squares	O
and	O
errors-in-	O
variables	O
modeling	B
,	O
springer	O
.	O
van	O
huffel	O
,	O
s.	O
and	O
vandewalle	O
,	O
j	O
.	O
(	O
1991	O
)	O
.	O
the	O
total	B
least	O
squares	O
problem	O
:	O
computa-	O
tional	O
aspects	O
and	O
analysis	O
.	O
society	O
for	O
industrial	O
and	O
applied	O
mathematics	O
,	O
philade-	O
phia	O
.	O
916	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
van	O
ouwerkerk	O
,	O
j.	O
d.	O
(	O
2006	O
)	O
.	O
image	B
super-resolution	O
survey	O
.	O
image	B
and	O
vision	O
computing	O
,	O
24	O
(	O
10	O
)	O
:1039–1052	O
.	O
varma	O
,	O
m.	O
and	O
ray	O
,	O
d.	O
(	O
2007	O
)	O
.	O
learning	B
the	O
discriminative	O
power-invariance	O
trade-off	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
vasconcelos	O
,	O
n.	O
(	O
2007	O
)	O
.	O
from	O
pixels	O
to	O
semantic	O
spaces	O
:	O
advances	O
in	O
content-based	O
image	B
retrieval	O
.	O
computer	O
,	O
40	O
(	O
7	O
)	O
:20–26	O
.	O
vasilescu	O
,	O
m.	O
a.	O
o.	O
and	O
terzopoulos	O
,	O
d.	O
(	O
2007	O
)	O
.	O
multilinear	O
(	O
tensor	O
)	O
image	B
synthesis	O
,	O
analysis	O
,	O
and	O
recognition	B
.	O
ieee	O
signal	O
processing	O
magazine	O
,	O
24	O
(	O
6	O
)	O
:118–123	O
.	O
vedaldi	O
,	O
a.	O
and	O
fulkerson	O
,	O
b	O
.	O
(	O
2008	O
)	O
.	O
vlfeat	O
:	O
an	O
open	O
and	O
portable	O
library	O
of	O
computer	O
vision	O
algorithms	O
.	O
http	O
:	O
//www.vlfeat.org/	O
.	O
vedaldi	O
,	O
a.	O
,	O
gulshan	O
,	O
v.	O
,	O
varma	O
,	O
m.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2009	O
)	O
.	O
multiple	B
kernels	O
for	O
object	O
detection	B
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
vedula	O
,	O
s.	O
,	O
baker	O
,	O
s.	O
,	O
and	O
kanade	O
,	O
t.	O
(	O
2005	O
)	O
.	O
image-based	B
spatio-temporal	O
modeling	B
and	O
view	B
interpolation	I
of	O
dynamic	B
events	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
24	O
(	O
2	O
)	O
:240–261	O
.	O
vedula	O
,	O
s.	O
,	O
baker	O
,	O
s.	O
,	O
rander	O
,	O
p.	O
,	O
collins	O
,	O
r.	O
,	O
and	O
kanade	O
,	O
t.	O
dimensional	O
scene	O
ﬂow	O
.	O
ligence	O
,	O
27	O
(	O
3	O
)	O
:475–480	O
.	O
three-	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intel-	O
(	O
2005	O
)	O
.	O
veeraraghavan	O
,	O
a.	O
,	O
raskar	O
,	O
r.	O
,	O
agrawal	O
,	O
a.	O
,	O
mohan	O
,	O
a.	O
,	O
and	O
tumblin	O
,	O
j	O
.	O
(	O
2007	O
)	O
.	O
dappled	O
photography	O
:	O
mask	B
enhanced	O
cameras	O
for	O
heterodyned	O
light	O
ﬁelds	O
and	O
coded	O
aperture	O
refocusing	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
veksler	O
,	O
o	O
.	O
(	O
1999	O
)	O
.	O
efﬁcient	O
graph-based	B
energy	O
minimization	O
methods	O
in	O
computer	O
vision	O
.	O
ph.d.	O
thesis	O
,	O
cornell	O
university	O
.	O
veksler	O
,	O
o	O
.	O
(	O
2001	O
)	O
.	O
stereo	B
matching	I
by	O
compact	O
windows	O
via	O
minimum	O
ratio	O
cycle	O
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
540–547	O
,	O
van-	O
couver	O
,	O
canada	O
.	O
veksler	O
,	O
o	O
.	O
(	O
2003	O
)	O
.	O
fast	O
variable	O
window	O
for	O
stereo	O
correspondence	B
using	O
integral	O
images	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2003	O
)	O
,	O
pp	O
.	O
556–561	O
,	O
madison	O
,	O
wi	O
.	O
veksler	O
,	O
o	O
.	O
(	O
2007	O
)	O
.	O
graph	B
cut	I
based	O
optimization	O
for	O
mrfs	O
with	O
truncated	O
convex	O
priors	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
references	B
917	O
verbeek	O
,	O
j.	O
and	O
triggs	O
,	O
b	O
.	O
(	O
2007	O
)	O
.	O
region	B
classiﬁcation	O
with	O
markov	O
ﬁeld	O
aspect	O
models	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
vergauwen	O
,	O
m.	O
and	O
van	O
gool	O
,	O
l.	O
(	O
2006	O
)	O
.	O
web-based	O
3d	O
reconstruction	O
service	O
.	O
machine	O
vision	O
and	O
applications	O
,	O
17	O
(	O
2	O
)	O
:321–329	O
.	O
vetter	O
,	O
t.	O
and	O
poggio	O
,	O
t.	O
(	O
1997	O
)	O
.	O
linear	B
object	O
classes	O
and	O
image	B
synthesis	O
from	O
a	O
sin-	O
gle	O
example	O
image	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
7	O
)	O
:733–742	O
.	O
vezhnevets	O
,	O
v.	O
,	O
sazonov	O
,	O
v.	O
,	O
and	O
andreeva	O
,	O
a	O
.	O
(	O
2003	O
)	O
.	O
a	O
survey	O
on	O
pixel-based	O
skin	O
color	B
detection	O
techniques	O
.	O
in	O
graphicon03	O
,	O
pp	O
.	O
85–92	O
.	O
vicente	O
,	O
s.	O
,	O
kolmogorov	O
,	O
v.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
2008	O
)	O
.	O
graph	B
cut	I
based	O
image	B
segmentation	O
with	O
connectivity	O
priors	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
vidal	O
,	O
r.	O
,	O
ma	O
,	O
y.	O
,	O
and	O
sastry	O
,	O
s.	O
s.	O
(	O
2010	O
)	O
.	O
generalized	B
principal	O
component	O
analysis	O
.	O
springer	O
.	O
vi´eville	O
,	O
t.	O
and	O
faugeras	O
,	O
o.	O
d.	O
(	O
1990	O
)	O
.	O
feedforward	O
recovery	B
of	O
motion	B
and	O
structure	O
from	O
a	O
sequence	O
of	O
2d-lines	O
matches	O
.	O
in	O
third	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
90	O
)	O
,	O
pp	O
.	O
517–520	O
,	O
osaka	O
,	O
japan	O
.	O
vincent	O
,	O
l.	O
and	O
soille	O
,	O
p.	O
(	O
1991	O
)	O
.	O
watersheds	O
in	O
digital	O
spaces	O
:	O
an	O
efﬁcient	O
algorithm	B
based	O
on	O
immersion	O
simulations	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
13	O
(	O
6	O
)	O
:583–596	O
.	O
vineet	O
,	O
v.	O
and	O
narayanan	O
,	O
p.	O
j	O
.	O
(	O
2008	O
)	O
.	O
cuda	O
cuts	O
:	O
fast	O
graph	O
cuts	O
on	O
the	O
gpu	O
.	O
in	O
cvpr	O
2008	O
workshop	O
on	O
visual	O
computer	O
vision	O
on	O
gpus	O
(	O
cvgpu	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
viola	O
,	O
p.	O
and	O
wells	O
iii	O
,	O
w.	O
(	O
1997	O
)	O
.	O
alignment	B
by	O
maximization	O
of	O
mutual	O
information	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
24	O
(	O
2	O
)	O
:137–154	O
.	O
viola	O
,	O
p.	O
,	O
jones	O
,	O
m.	O
j.	O
,	O
and	O
snow	O
,	O
d.	O
(	O
2003	O
)	O
.	O
detecting	O
pedestrians	O
using	O
patterns	O
of	O
motion	B
and	O
appearance	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
734–741	O
,	O
nice	O
,	O
france	O
.	O
viola	O
,	O
p.	O
a.	O
and	O
jones	O
,	O
m.	O
j	O
.	O
(	O
2004	O
)	O
.	O
robust	B
real-time	O
face	B
detection	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
57	O
(	O
2	O
)	O
:137–154	O
.	O
vlasic	O
,	O
d.	O
,	O
baran	O
,	O
i.	O
,	O
matusik	O
,	O
w.	O
,	O
and	O
popovi´c	O
,	O
j	O
.	O
(	O
2008	O
)	O
.	O
articulated	O
mesh	O
animation	O
from	O
multi-view	B
silhouettes	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
27	O
(	O
3	O
)	O
.	O
vlasic	O
,	O
d.	O
,	O
brand	O
,	O
m.	O
,	O
pﬁster	O
,	O
h.	O
,	O
and	O
popovi´c	O
,	O
j	O
.	O
(	O
2005	O
)	O
.	O
face	B
transfer	O
with	O
multilinear	O
models	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:426–433	O
.	O
918	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
vogiatzis	O
,	O
g.	O
,	O
torr	O
,	O
p.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2005	O
)	O
.	O
multi-view	B
stereo	I
via	O
volumetric	B
graph-cuts	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
391–398	O
,	O
san	O
diego	O
,	O
ca	O
.	O
vogiatzis	O
,	O
g.	O
,	O
hernandez	O
,	O
c.	O
,	O
torr	O
,	O
p.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2007	O
)	O
.	O
multi-view	B
stereo	I
via	O
volu-	O
metric	O
graph-cuts	O
and	O
occlusion	O
robust	B
photo-consistency	O
.	O
ieee	O
transactions	O
on	O
pat-	O
tern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
12	O
)	O
:2241–2246	O
.	O
von	O
ahn	O
,	O
l.	O
and	O
dabbish	O
,	O
l.	O
(	O
2004	O
)	O
.	O
labeling	O
images	O
with	O
a	O
computer	O
game	O
.	O
in	O
chi	O
’	O
04	O
:	O
sigchi	O
conference	O
on	O
human	O
factors	O
in	O
computing	O
systems	O
,	O
pp	O
.	O
319–326	O
,	O
vienna	O
,	O
austria	O
.	O
von	O
ahn	O
,	O
l.	O
,	O
liu	O
,	O
r.	O
,	O
and	O
blum	O
,	O
m.	O
(	O
2006	O
)	O
.	O
peekaboom	O
:	O
a	O
game	O
for	O
locating	O
objects	O
in	O
images	O
.	O
in	O
chi	O
’	O
06	O
:	O
sigchi	O
conference	O
on	O
human	O
factors	O
in	O
computing	O
systems	O
,	O
pp	O
.	O
55–64	O
,	O
montr´eal	O
,	O
qu´ebec	O
,	O
canada	O
.	O
wainwright	O
,	O
m.	O
j.	O
and	O
jordan	O
,	O
m.	O
i	O
.	O
(	O
2008	O
)	O
.	O
graphical	O
models	O
,	O
exponential	O
families	O
,	O
and	O
variational	O
inference	B
.	O
foundations	O
and	O
trends	O
in	O
machine	O
learning	O
,	O
1	O
(	O
1-2	O
)	O
:1–305	O
.	O
wainwright	O
,	O
m.	O
j.	O
,	O
jaakkola	O
,	O
t.	O
s.	O
,	O
and	O
willsky	O
,	O
a.	O
s.	O
(	O
2005	O
)	O
.	O
map	O
estimation	B
via	O
agree-	O
ment	O
on	O
trees	O
:	O
message-passing	O
and	O
linear	O
programming	O
.	O
ieee	O
transactions	O
on	O
infor-	O
mation	O
theory	O
,	O
51	O
(	O
11	O
)	O
:3697–3717	O
.	O
waithe	O
,	O
p.	O
and	O
ferrie	O
,	O
f.	O
(	O
1991	O
)	O
.	O
from	O
uncertainty	B
to	O
visual	O
exploration	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
13	O
(	O
10	O
)	O
:1038–1049	O
.	O
walker	O
,	O
e.	O
l.	O
and	O
herman	O
,	O
m.	O
(	O
1988	O
)	O
.	O
geometric	B
reasoning	O
for	O
constructing	O
3d	O
scene	O
descriptions	O
from	O
images	O
.	O
artiﬁcial	O
intelligence	O
,	O
37:275–290	O
.	O
wallace	O
,	O
g.	O
k.	O
(	O
1991	O
)	O
.	O
the	O
jpeg	O
still	O
picture	O
compression	B
standard	O
.	O
communications	O
of	O
the	O
acm	O
,	O
34	O
(	O
4	O
)	O
:30–44	O
.	O
wallace	O
,	O
j.	O
r.	O
,	O
cohen	O
,	O
m.	O
f.	O
,	O
and	O
greenberg	O
,	O
d.	O
p.	O
(	O
1987	O
)	O
.	O
a	O
two-pass	O
solution	O
to	O
the	O
ren-	O
dering	O
equation	B
:	O
a	O
synthesis	O
of	O
ray	O
tracing	O
and	O
radiosity	B
methods	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
87	O
)	O
,	O
21	O
(	O
4	O
)	O
:311–320	O
.	O
waltz	O
,	O
d.	O
l.	O
(	O
1975	O
)	O
.	O
understanding	O
line	O
drawings	O
of	O
scenes	O
with	O
shadows	O
.	O
in	O
winston	O
,	O
p.	O
h	O
.	O
(	O
ed	O
.	O
)	O
,	O
the	O
psychology	O
of	O
computer	O
vision	O
,	O
mcgraw-hill	O
,	O
new	O
york	O
.	O
wang	O
,	O
h.	O
and	O
oliensis	O
,	O
j	O
.	O
(	O
2010	O
)	O
.	O
shape	O
matching	O
by	O
segmentation	O
averaging	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
32	O
(	O
4	O
)	O
:619–635	O
.	O
wang	O
,	O
j.	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2005	O
)	O
.	O
an	O
iterative	B
optimization	O
approach	O
for	O
uniﬁed	O
im-	O
age	O
segmentation	B
and	O
matting	B
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
beijing	O
,	O
china	O
.	O
wang	O
,	O
j.	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2007a	O
)	O
.	O
image	B
and	O
video	B
matting	O
:	O
a	O
survey	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
3	O
(	O
2	O
)	O
.	O
references	B
919	O
wang	O
,	O
j.	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2007b	O
)	O
.	O
optimized	O
color	B
sampling	O
for	O
robust	O
matting	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
wang	O
,	O
j.	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2007c	O
)	O
.	O
simultaneous	O
matting	B
and	O
compositing	B
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
wang	O
,	O
j.	O
,	O
agrawala	O
,	O
m.	O
,	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2007	O
)	O
.	O
soft	O
scissors	O
:	O
an	O
interactive	B
tool	O
for	O
realtime	O
high	O
quality	O
matting	B
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
wang	O
,	O
j.	O
,	O
thiesson	O
,	O
b.	O
,	O
xu	O
,	O
y.	O
,	O
and	O
cohen	O
,	O
m.	O
image	B
and	O
video	B
segmentation	O
by	O
anisotropic	O
kernel	B
mean	O
shift	O
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
238–249	O
,	O
prague	O
.	O
(	O
2004	O
)	O
.	O
wang	O
,	O
j.	O
,	O
bhat	O
,	O
p.	O
,	O
colburn	O
,	O
r.	O
a.	O
,	O
agrawala	O
,	O
m.	O
,	O
and	O
cohen	O
,	O
m.	O
f.	O
(	O
2005	O
)	O
.	O
video	B
cutout	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:585–594	O
.	O
wang	O
,	O
j.	O
y.	O
a.	O
and	O
adelson	O
,	O
e.	O
h.	O
(	O
1994	O
)	O
.	O
representing	O
moving	O
images	O
with	O
layers	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
3	O
(	O
5	O
)	O
:625–638	O
.	O
wang	O
,	O
l.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
szeliski	O
,	O
r.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2001	O
)	O
.	O
optimal	O
texture	B
map	O
re-	O
construction	O
from	O
multiple	B
views	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2001	O
)	O
,	O
pp	O
.	O
347–354	O
,	O
kauai	O
,	O
hawaii	O
.	O
wang	O
,	O
y.	O
and	O
zhu	O
,	O
s.-c.	O
(	O
2003	O
)	O
.	O
modeling	B
textured	O
motion	B
:	O
particle	O
,	O
wave	O
and	O
sketch	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
213–220	O
,	O
nice	O
,	O
france	O
.	O
wang	O
,	O
z.	O
,	O
bovik	O
,	O
a.	O
c.	O
,	O
and	O
simoncelli	O
,	O
e.	O
p.	O
(	O
2005	O
)	O
.	O
structural	O
approaches	O
to	O
image	B
quality	O
assessment	O
.	O
in	O
bovik	O
,	O
a.	O
c	O
.	O
(	O
ed	O
.	O
)	O
,	O
handbook	O
of	O
image	B
and	O
video	B
processing	O
,	O
pp	O
.	O
961–974	O
,	O
elsevier	O
academic	O
press	O
.	O
wang	O
,	O
z.	O
,	O
bovik	O
,	O
a.	O
c.	O
,	O
sheikh	O
,	O
h.	O
r.	O
,	O
and	O
simoncelli	O
,	O
e.	O
p.	O
(	O
2004	O
)	O
.	O
image	B
quality	O
as-	O
ieee	O
transactions	O
on	O
image	B
sessment	O
:	O
from	O
error	O
visibility	O
to	O
structural	O
similarity	B
.	O
processing	O
,	O
13	O
(	O
4	O
)	O
:600–612	O
.	O
wang	O
,	O
z.-f.	O
and	O
zheng	O
,	O
z.-g.	O
(	O
2008	O
)	O
.	O
a	O
region	B
based	O
stereo	B
matching	I
algorithm	O
using	O
cooperative	O
optimization	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
ward	O
,	O
g.	O
(	O
1992	O
)	O
.	O
measuring	O
and	O
modeling	B
anisotropic	O
reﬂection	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
92	O
)	O
,	O
26	O
(	O
4	O
)	O
:265–272	O
.	O
ward	O
,	O
g.	O
(	O
1994	O
)	O
.	O
the	O
radiance	O
lighting	B
simulation	O
and	O
rendering	B
system	O
.	O
in	O
acm	O
sig-	O
graph	O
1994	O
conference	O
proceedings	O
,	O
pp	O
.	O
459–472	O
.	O
920	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ward	O
,	O
g.	O
(	O
2003	O
)	O
.	O
fast	O
,	O
robust	B
image	O
registration	B
for	O
compositing	B
high	O
dynamic	B
range	O
photographs	O
from	O
hand-held	O
exposures	O
.	O
journal	O
of	O
graphics	O
tools	O
,	O
8	O
(	O
2	O
)	O
:17–30	O
.	O
ward	O
,	O
g.	O
(	O
2004	O
)	O
.	O
high	B
dynamic	I
range	I
image	O
encodings	O
.	O
http	O
:	O
//www.anyhere.com/gward/	O
hdrenc/hdr	O
encodings.html	O
.	O
ware	O
,	O
c.	O
,	O
arthur	O
,	O
k.	O
,	O
and	O
booth	O
,	O
k.	O
s.	O
(	O
1993	O
)	O
.	O
fish	O
tank	O
virtual	O
reality	O
.	O
in	O
interchi	O
’	O
03	O
,	O
pp	O
.	O
37–42	O
,	O
amsterdam	O
.	O
warren	O
,	O
j.	O
and	O
weimer	O
,	O
h.	O
(	O
2001	O
)	O
.	O
subdivision	O
methods	O
for	O
geometric	O
design	O
:	O
a	O
con-	O
structive	O
approach	O
.	O
morgan	O
kaufmann	O
.	O
watanabe	O
,	O
m.	O
and	O
nayar	O
,	O
s.	O
k.	O
(	O
1998	O
)	O
.	O
rational	O
ﬁlters	O
for	O
passive	O
depth	O
from	O
defocus	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
27	O
(	O
3	O
)	O
:203–225	O
.	O
watt	O
,	O
a	O
.	O
(	O
1995	O
)	O
.	O
3d	O
computer	O
graphics	O
.	O
addison-wesley	O
,	O
harlow	O
,	O
england	O
,	O
third	O
edition	O
.	O
weber	O
,	O
j.	O
and	O
malik	O
,	O
j	O
.	O
(	O
1995	O
)	O
.	O
robust	B
computation	O
of	O
optical	B
ﬂow	I
in	O
a	O
multi-scale	O
differ-	O
ential	O
framework	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
14	O
(	O
1	O
)	O
:67–81	O
.	O
weber	O
,	O
m.	O
,	O
welling	O
,	O
m.	O
,	O
and	O
perona	O
,	O
p.	O
(	O
2000	O
)	O
.	O
unsupervised	O
learning	B
of	O
models	O
for	B
recognition	I
.	O
in	O
sixth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2000	O
)	O
,	O
pp	O
.	O
18–	O
32	O
,	O
dublin	O
,	O
ireland	O
.	O
wedel	O
,	O
a.	O
,	O
cremers	O
,	O
d.	O
,	O
pock	O
,	O
t.	O
,	O
and	O
bischof	O
,	O
h.	O
(	O
2009	O
)	O
.	O
structure-	O
and	O
motion-adaptive	O
in	O
twelfth	O
international	O
conference	O
on	O
regularization	B
for	O
high	O
accuracy	O
optic	O
ﬂow	O
.	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
wedel	O
,	O
a.	O
,	O
rabe	O
,	O
c.	O
,	O
vaudrey	O
,	O
t.	O
,	O
brox	O
,	O
t.	O
,	O
franke	O
,	O
u.	O
,	O
and	O
cremers	O
,	O
d.	O
(	O
2008	O
)	O
.	O
efﬁcient	O
dense	O
scene	O
ﬂow	O
from	O
sparse	B
or	O
dense	O
stereo	O
data	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
739–751	O
,	O
marseilles	O
.	O
wei	O
,	O
c.	O
y.	O
and	O
quan	O
,	O
l.	O
(	O
2004	O
)	O
.	O
region-based	B
progressive	O
stereo	B
matching	I
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2005	O
)	O
,	O
pp	O
.	O
106–113	O
,	O
washington	O
,	O
d.	O
c.	O
wei	O
,	O
l.-y	O
.	O
and	O
levoy	O
,	O
m.	O
(	O
2000	O
)	O
.	O
fast	O
texture	O
synthesis	O
using	O
tree-structured	O
vector	O
quan-	O
tization	O
.	O
in	O
acm	O
siggraph	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
479–488	O
.	O
weickert	O
,	O
j	O
.	O
(	O
1998	O
)	O
.	O
anisotropic	B
diffusion	O
in	O
image	B
processing	O
.	O
tuebner	O
,	O
stuttgart	O
.	O
weickert	O
,	O
j.	O
,	O
ter	O
haar	O
romeny	O
,	O
b.	O
m.	O
,	O
and	O
viergever	O
,	O
m.	O
a	O
.	O
(	O
1998	O
)	O
.	O
efﬁcient	O
and	O
reli-	O
able	O
schemes	O
for	O
nonlinear	O
diffusion	O
ﬁltering	O
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
7	O
(	O
3	O
)	O
:398–410	O
.	O
weinland	O
,	O
d.	O
,	O
ronfard	O
,	O
r.	O
,	O
and	O
boyer	O
,	O
e.	O
(	O
2006	O
)	O
.	O
free	O
viewpoint	O
action	O
recognition	B
using	O
motion	B
history	O
volumes	O
.	O
computer	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-3	O
)	O
:249–	O
257.	O
references	B
921	O
weiss	O
,	O
y	O
.	O
(	O
1997	O
)	O
.	O
smoothness	B
in	O
layers	B
:	O
motion	B
segmentation	O
using	O
nonparametric	O
mixture	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
estimation	B
.	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
520–526	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
weiss	O
,	O
y	O
.	O
(	O
1999	O
)	O
.	O
segmentation	B
using	O
eigenvectors	O
:	O
a	O
unifying	O
view	O
.	O
in	O
seventh	O
interna-	O
tional	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
’	O
99	O
)	O
,	O
pp	O
.	O
975–982	O
,	O
kerkyra	O
,	O
greece	O
.	O
weiss	O
,	O
y	O
.	O
(	O
2001	O
)	O
.	O
deriving	O
intrinsic	B
images	O
from	O
image	B
sequences	O
.	O
in	O
eighth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2001	O
)	O
,	O
pp	O
.	O
7–14	O
,	O
vancouver	O
,	O
canada	O
.	O
weiss	O
,	O
y.	O
and	O
adelson	O
,	O
e.	O
h.	O
(	O
1996	O
)	O
.	O
a	O
uniﬁed	O
mixture	O
framework	O
for	O
motion	O
segmen-	O
tation	O
:	O
incorporating	O
spatial	O
coherence	O
and	O
estimating	O
the	O
number	O
of	O
models	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
96	O
)	O
,	O
pp	O
.	O
321–326	O
,	O
san	O
francisco	O
.	O
weiss	O
,	O
y.	O
and	O
freeman	O
,	O
b	O
.	O
(	O
2007	O
)	O
.	O
what	O
makes	O
a	O
good	O
model	O
of	O
natural	B
images	O
?	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
weiss	O
,	O
y.	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2001a	O
)	O
.	O
correctness	O
of	O
belief	B
propagation	I
in	O
gaussian	O
graphical	O
models	O
of	O
arbitrary	O
topology	O
.	O
neural	O
computation	O
,	O
13	O
(	O
10	O
)	O
:2173–2200	O
.	O
weiss	O
,	O
y.	O
and	O
freeman	O
,	O
w.	O
t.	O
(	O
2001b	O
)	O
.	O
on	O
the	O
optimality	O
of	O
solutions	O
of	O
the	O
max-product	O
ieee	O
transactions	O
on	O
information	O
belief	B
propagation	I
algorithm	O
in	O
arbitrary	O
graphs	O
.	O
theory	O
,	O
47	O
(	O
2	O
)	O
:736–744	O
.	O
weiss	O
,	O
y.	O
,	O
torralba	O
,	O
a.	O
,	O
and	O
fergus	O
,	O
r.	O
(	O
2008	O
)	O
.	O
spectral	O
hashing	B
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
weiss	O
,	O
y.	O
,	O
yanover	O
,	O
c.	O
,	O
and	O
meltzer	O
,	O
t.	O
(	O
2010	O
)	O
.	O
linear	O
programming	O
and	O
variants	O
of	O
belief	B
propagation	I
.	O
in	O
blake	O
,	O
a.	O
,	O
kohli	O
,	O
p.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
eds	O
)	O
,	O
advances	O
in	O
markov	O
random	O
fields	O
,	O
mit	O
press	O
.	O
wells	O
,	O
iii	O
,	O
w.	O
m.	O
(	O
1986	O
)	O
.	O
efﬁcient	O
synthesis	O
of	O
gaussian	O
ﬁlters	O
by	O
cascaded	O
uniform	O
ﬁlters	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
8	O
(	O
2	O
)	O
:234–239	O
.	O
weng	O
,	O
j.	O
,	O
ahuja	O
,	O
n.	O
,	O
and	O
huang	O
,	O
t.	O
s.	O
(	O
1993	O
)	O
.	O
optimal	O
motion	B
and	O
structure	O
estimation	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
15	O
(	O
9	O
)	O
:864–884	O
.	O
wenger	O
,	O
a.	O
,	O
gardner	O
,	O
a.	O
,	O
tchou	O
,	O
c.	O
,	O
unger	O
,	O
j.	O
,	O
hawkins	O
,	O
t.	O
,	O
and	O
debevec	O
,	O
p.	O
(	O
2005	O
)	O
.	O
per-	O
formance	O
relighting	O
and	O
reﬂectance	B
transformation	O
with	O
time-multiplexed	O
illumination	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:756–764	O
.	O
werlberger	O
,	O
m.	O
,	O
trobin	O
,	O
w.	O
,	O
pock	O
,	O
t.	O
,	O
bischof	O
,	O
h.	O
,	O
wedel	O
,	O
a.	O
,	O
and	O
cremers	O
,	O
d.	O
(	O
2009	O
)	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
anisotropic	B
huber-l1	O
optical	B
ﬂow	I
.	O
2009	O
)	O
,	O
london	O
.	O
922	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
werner	O
,	O
t.	O
(	O
2007	O
)	O
.	O
a	O
linear	O
programming	O
approach	O
to	O
max-sum	O
problem	O
:	O
a	O
review	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
7	O
)	O
:1165–1179	O
.	O
werner	O
,	O
t.	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2002	O
)	O
.	O
new	O
techniques	O
for	O
automated	O
architectural	O
re-	O
construction	O
from	O
photographs	O
.	O
in	O
seventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2002	O
)	O
,	O
pp	O
.	O
541–555	O
,	O
copenhagen	O
.	O
westin	O
,	O
s.	O
h.	O
,	O
arvo	O
,	O
j.	O
r.	O
,	O
and	O
torrance	O
,	O
k.	O
e.	O
(	O
1992	O
)	O
.	O
predicting	O
reﬂectance	B
functions	O
from	O
complex	O
surfaces	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
92	O
)	O
,	O
26	O
(	O
4	O
)	O
:255–264	O
.	O
westover	O
,	O
l.	O
(	O
1989	O
)	O
.	O
interactive	B
volume	O
rendering	B
.	O
in	O
workshop	O
on	O
volume	O
visualization	O
,	O
pp	O
.	O
9–16	O
,	O
chapel	O
hill	O
.	O
wexler	O
,	O
y.	O
,	O
fitzgibbon	O
,	O
a.	O
,	O
and	O
zisserman	O
,	O
a	O
.	O
(	O
2002	O
)	O
.	O
bayesian	O
estimation	B
of	O
layers	B
from	O
multiple	B
images	O
.	O
in	O
seventh	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2002	O
)	O
,	O
pp	O
.	O
487–501	O
,	O
copenhagen	O
.	O
wexler	O
,	O
y.	O
,	O
shechtman	O
,	O
e.	O
,	O
and	O
irani	O
,	O
m.	O
(	O
2007	O
)	O
.	O
space-time	O
completion	O
of	O
video	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
3	O
)	O
:463–476	O
.	O
weyrich	O
,	O
t.	O
,	O
lawrence	O
,	O
j.	O
,	O
lensch	O
,	O
h.	O
p.	O
a.	O
,	O
rusinkiewicz	O
,	O
s.	O
,	O
and	O
zickler	O
,	O
t.	O
(	O
2008	O
)	O
.	O
principles	O
of	O
appearance	O
acquisition	O
and	O
representation	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
4	O
(	O
2	O
)	O
:75–191	O
.	O
weyrich	O
,	O
t.	O
,	O
matusik	O
,	O
w.	O
,	O
pﬁster	O
,	O
h.	O
,	O
bickel	O
,	O
b.	O
,	O
donner	O
,	O
c.	O
et	O
al	O
.	O
(	O
2006	O
)	O
.	O
analysis	O
of	O
human	O
faces	O
using	O
a	O
measurement-based	O
skin	O
reﬂectance	B
model	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:1013–1024	O
.	O
wheeler	O
,	O
m.	O
d.	O
,	O
sato	O
,	O
y.	O
,	O
and	O
ikeuchi	O
,	O
k.	O
(	O
1998	O
)	O
.	O
consensus	O
surfaces	O
for	O
modeling	O
3d	O
in	O
sixth	O
international	O
conference	O
on	O
computer	O
objects	O
from	O
multiple	B
range	O
images	O
.	O
vision	O
(	O
iccv	O
’	O
98	O
)	O
,	O
pp	O
.	O
917–924	O
,	O
bombay	O
.	O
white	O
,	O
r.	O
and	O
forsyth	O
,	O
d.	O
(	O
2006	O
)	O
.	O
combining	O
cues	O
:	O
shape	O
from	O
shading	B
and	O
texture	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
1809–1816	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
white	O
,	O
r.	O
,	O
crane	O
,	O
k.	O
,	O
and	O
forsyth	O
,	O
d.	O
a	O
.	O
(	O
2007	O
)	O
.	O
capturing	O
and	O
animating	O
occluded	O
cloth	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
wiejak	O
,	O
j.	O
s.	O
,	O
buxton	O
,	O
h.	O
,	O
and	O
buxton	O
,	O
b.	O
f.	O
(	O
1985	O
)	O
.	O
convolution	O
with	O
separable	O
masks	O
for	O
early	O
image	B
processing	O
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
32	O
(	O
3	O
)	O
:279–	O
290.	O
wilburn	O
,	O
b.	O
,	O
joshi	O
,	O
n.	O
,	O
vaish	O
,	O
v.	O
,	O
talvala	O
,	O
e.-v.	O
,	O
antunez	O
,	O
e.	O
et	O
al	O
.	O
(	O
2005	O
)	O
.	O
high	O
per-	O
formance	O
imaging	O
using	O
large	O
camera	B
arrays	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2005	O
)	O
,	O
24	O
(	O
3	O
)	O
:765–776	O
.	O
references	B
923	O
wilczkowiak	O
,	O
m.	O
,	O
brostow	O
,	O
g.	O
j.	O
,	O
tordoff	O
,	O
b.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2005	O
)	O
.	O
hole	B
ﬁlling	I
through	O
photomontage	O
.	O
in	O
british	O
machine	O
vision	O
conference	O
(	O
bmvc	O
2005	O
)	O
,	O
pp	O
.	O
492–501	O
,	O
ox-	O
ford	O
brookes	O
.	O
williams	O
,	O
d.	O
and	O
burns	O
,	O
p.	O
d.	O
(	O
2001	O
)	O
.	O
diagnostics	O
for	O
digital	O
capture	O
using	O
mtf	O
.	O
in	O
is	O
&	O
t	O
pics	O
conference	O
,	O
pp	O
.	O
227–232	O
.	O
williams	O
,	O
d.	O
j.	O
and	O
shah	O
,	O
m.	O
(	O
1992	O
)	O
.	O
a	O
fast	O
algorithm	O
for	O
active	O
contours	O
and	O
curvature	O
estimation	B
.	O
computer	O
vision	O
,	O
graphics	O
,	O
and	O
image	B
processing	O
,	O
55	O
(	O
1	O
)	O
:14–26	O
.	O
williams	O
,	O
l.	O
(	O
1983	O
)	O
.	O
pyramidal	O
parametrics	O
.	O
computer	O
graphics	O
(	O
siggraph	O
’	O
83	O
)	O
,	O
17	O
(	O
3	O
)	O
:1–11	O
.	O
williams	O
,	O
l.	O
(	O
1990	O
)	O
.	O
performace	O
driven	O
facial	B
animation	I
.	O
computer	O
graphics	O
(	O
sig-	O
graph	O
’	O
90	O
)	O
,	O
24	O
(	O
4	O
)	O
:235–242	O
.	O
williams	O
,	O
o.	O
,	O
blake	O
,	O
a.	O
,	O
and	O
cipolla	O
,	O
r.	O
(	O
2003	O
)	O
.	O
a	O
sparse	B
probabilistic	O
learning	B
algorithm	O
for	O
real-time	O
tracking	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
353–360	O
,	O
nice	O
,	O
france	O
.	O
williams	O
,	O
t.	O
l.	O
(	O
1999	O
)	O
.	O
the	O
optical	O
transfer	O
function	O
of	O
imaging	O
systems	O
.	O
institute	O
of	O
physics	O
publishing	O
,	O
london	O
.	O
winder	O
,	O
s.	O
and	O
brown	O
,	O
m.	O
(	O
2007	O
)	O
.	O
learning	B
local	O
image	B
descriptors	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
min-	O
neapolis	O
,	O
mn	O
.	O
winkenbach	O
,	O
g.	O
and	O
salesin	O
,	O
d.	O
h.	O
(	O
1994	O
)	O
.	O
computer-generated	O
pen-and-ink	O
illustration	O
.	O
in	O
acm	O
siggraph	O
1994	O
conference	O
proceedings	O
,	O
pp	O
.	O
91–100	O
,	O
orlando	O
,	O
florida	O
.	O
winn	O
,	O
j.	O
and	O
shotton	O
,	O
j	O
.	O
(	O
2006	O
)	O
.	O
the	O
layout	B
consistent	I
random	O
ﬁeld	O
for	O
recognizing	O
and	O
segmenting	O
partially	O
occluded	O
objects	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
com-	O
puter	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
37–44	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
winnem¨oller	O
,	O
h.	O
,	O
olsen	O
,	O
s.	O
c.	O
,	O
and	O
gooch	O
,	O
b	O
.	O
(	O
2006	O
)	O
.	O
real-time	O
video	B
abstraction	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
25	O
(	O
3	O
)	O
:1221–1226	O
.	O
winston	O
,	O
p.	O
h	O
.	O
(	O
ed.	O
)	O
.	O
(	O
1975	O
)	O
.	O
the	O
psychology	O
of	O
computer	O
vision	O
,	O
mcgraw-hill	O
,	O
new	O
york	O
.	O
wiskott	O
,	O
l.	O
,	O
fellous	O
,	O
j.-m.	O
,	O
kr¨uger	O
,	O
n.	O
,	O
and	O
von	O
der	O
malsburg	O
,	O
c.	O
(	O
1997	O
)	O
.	O
face	B
recognition	O
by	O
elastic	O
bunch	O
graph	O
matching	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
7	O
)	O
:775–779	O
.	O
witkin	O
,	O
a	O
.	O
(	O
1981	O
)	O
.	O
recovering	O
surface	B
shape	O
and	O
orientation	O
from	O
texture	B
.	O
artiﬁcial	O
intel-	O
ligence	O
,	O
17	O
(	O
1-3	O
)	O
:17–45	O
.	O
924	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
witkin	O
,	O
a	O
.	O
(	O
1983	O
)	O
.	O
scale-space	O
ﬁltering	O
.	O
in	O
eighth	O
international	O
joint	B
conference	O
on	O
artiﬁcial	O
intelligence	O
(	O
ijcai-83	O
)	O
,	O
pp	O
.	O
1019–1022	O
.	O
witkin	O
,	O
a.	O
,	O
terzopoulos	O
,	O
d.	O
,	O
and	O
kass	O
,	O
m.	O
(	O
1986	O
)	O
.	O
signal	O
matching	B
through	O
scale	O
space	O
.	O
in	O
fifth	O
national	O
conference	O
on	O
artiﬁcial	O
intelligence	O
(	O
aaai-86	O
)	O
,	O
pp	O
.	O
714–719	O
,	O
philadel-	O
phia	O
.	O
witkin	O
,	O
a.	O
,	O
terzopoulos	O
,	O
d.	O
,	O
and	O
kass	O
,	O
m.	O
(	O
1987	O
)	O
.	O
signal	O
matching	B
through	O
scale	O
space	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
1:133–144	O
.	O
wolberg	O
,	O
g.	O
(	O
1990	O
)	O
.	O
digital	O
image	O
warping	O
.	O
ieee	O
computer	O
society	O
press	O
,	O
los	O
alamitos	O
.	O
wolberg	O
,	O
g.	O
and	O
pavlidis	O
,	O
t.	O
(	O
1985	O
)	O
.	O
restoration	O
of	O
binary	O
images	O
using	O
stochastic	O
relax-	O
ation	O
with	O
annealing	O
.	O
pattern	O
recognition	B
letters	O
,	O
3:375–388	O
.	O
wolff	O
,	O
l.	O
b.	O
,	O
shafer	O
,	O
s.	O
a.	O
,	O
and	O
healey	O
,	O
g.	O
e.	O
(	O
eds	O
)	O
.	O
(	O
1992a	O
)	O
.	O
radiometry	O
.	O
physics-based	B
vision	O
:	O
principles	O
and	O
practice	O
,	O
jones	O
&	O
bartlett	O
,	O
cambridge	O
,	O
ma	O
.	O
wolff	O
,	O
l.	O
b.	O
,	O
shafer	O
,	O
s.	O
a.	O
,	O
and	O
healey	O
,	O
g.	O
e.	O
(	O
eds	O
)	O
.	O
(	O
1992b	O
)	O
.	O
shape	O
recovery	O
.	O
physics-	O
based	O
vision	O
:	O
principles	O
and	O
practice	O
,	O
jones	O
&	O
bartlett	O
,	O
cambridge	O
,	O
ma	O
.	O
wood	O
,	O
d.	O
n.	O
,	O
finkelstein	O
,	O
a.	O
,	O
hughes	O
,	O
j.	O
f.	O
,	O
thayer	O
,	O
c.	O
e.	O
,	O
and	O
salesin	O
,	O
d.	O
h.	O
(	O
1997	O
)	O
.	O
multiperspective	O
panoramas	O
for	O
cel	O
animation	O
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
243–250	O
,	O
los	O
angeles	O
.	O
wood	O
,	O
d.	O
n.	O
,	O
azuma	O
,	O
d.	O
i.	O
,	O
aldinger	O
,	O
k.	O
,	O
curless	O
,	O
b.	O
,	O
duchamp	O
,	O
t.	O
,	O
salesin	O
,	O
d.	O
h.	O
,	O
and	O
in	O
acm	O
siggraph	O
(	O
2000	O
)	O
.	O
surface	O
light	O
ﬁelds	O
for	O
3d	O
photography	O
.	O
stuetzle	O
,	O
w.	O
2000	O
conference	O
proceedings	O
,	O
pp	O
.	O
287–296	O
.	O
woodford	O
,	O
o.	O
,	O
reid	O
,	O
i.	O
,	O
torr	O
,	O
p.	O
h.	O
,	O
and	O
fitzgibbon	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
global	B
stereo	O
reconstruc-	O
tion	B
under	O
second	O
order	O
smoothness	B
priors	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
woodham	O
,	O
r.	O
j	O
.	O
17:117–140	O
.	O
(	O
1981	O
)	O
.	O
analysing	O
images	O
of	O
curved	O
surfaces	O
.	O
artiﬁcial	O
intelligence	O
,	O
woodham	O
,	O
r.	O
j	O
.	O
(	O
1994	O
)	O
.	O
gradient	O
and	O
curvature	O
from	O
photometric	B
stereo	I
including	O
local	B
conﬁdence	O
estimation	B
.	O
journal	O
of	O
the	O
optical	O
society	O
of	O
america	O
,	O
a	O
,	O
11:3050–3068	O
.	O
wren	O
,	O
c.	O
r.	O
,	O
azarbayejani	O
,	O
a.	O
,	O
darrell	O
,	O
t.	O
,	O
and	O
pentland	O
,	O
a.	O
p.	O
(	O
1997	O
)	O
.	O
pﬁnder	O
:	O
real-	O
time	O
tracking	O
of	O
the	O
human	B
body	I
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
19	O
(	O
7	O
)	O
:780–785	O
.	O
wright	O
,	O
s.	O
(	O
2006	O
)	O
.	O
digital	O
compositing	O
for	O
film	O
and	O
video	B
.	O
focal	O
press	O
,	O
2nd	O
edition	O
.	O
wu	O
,	O
c.	O
(	O
2010	O
)	O
.	O
siftgpu	O
:	O
a	O
gpu	O
implementation	O
of	O
scale	O
invariant	O
feature	B
transform	O
(	O
sift	O
)	O
.	O
http	O
:	O
//www.cs.unc.edu/∼ccwu/siftgpu/	O
.	O
references	B
925	O
wyszecki	O
,	O
g.	O
and	O
stiles	O
,	O
w.	O
s.	O
(	O
2000	O
)	O
.	O
color	B
science	O
:	O
concepts	O
and	O
methods	O
,	O
quantitative	O
data	O
and	O
formulae	O
.	O
john	O
wiley	O
&	O
sons	O
,	O
new	O
york	O
,	O
2nd	O
edition	O
.	O
xiao	O
,	O
j.	O
and	O
shah	O
,	O
m.	O
(	O
2003	O
)	O
.	O
two-frame	B
wide	O
baseline	O
matching	B
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
603–609	O
,	O
nice	O
,	O
france	O
.	O
xiao	O
,	O
j.	O
and	O
shah	O
,	O
m.	O
using	O
graph	O
cuts	O
.	O
27	O
(	O
10	O
)	O
:1644–1659	O
.	O
(	O
2005	O
)	O
.	O
motion	B
layer	O
extraction	O
in	O
the	O
presence	O
of	O
occlusion	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
xiong	O
,	O
y.	O
and	O
turkowski	O
,	O
k.	O
(	O
1997	O
)	O
.	O
creating	O
image-based	B
vr	O
using	O
a	O
self-calibrating	O
ﬁsheye	O
lens	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
237–243	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
xiong	O
,	O
y.	O
and	O
turkowski	O
,	O
k.	O
(	O
1998	O
)	O
.	O
registration	B
,	O
calibration	B
and	O
blending	B
in	O
creating	O
high	O
quality	O
panoramas	O
.	O
in	O
ieee	O
workshop	O
on	O
applications	O
of	O
computer	O
vision	O
(	O
wacv	O
’	O
98	O
)	O
,	O
pp	O
.	O
69–74	O
,	O
princeton	O
.	O
xu	O
,	O
l.	O
,	O
chen	O
,	O
j.	O
,	O
and	O
jia	O
,	O
j	O
.	O
(	O
2008	O
)	O
.	O
a	O
segmentation	B
based	O
variational	O
model	O
for	O
accurate	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
optical	B
ﬂow	I
estimation	O
.	O
2008	O
)	O
,	O
pp	O
.	O
671–684	O
,	O
marseilles	O
.	O
yang	O
,	O
d.	O
,	O
el	O
gamal	O
,	O
a.	O
,	O
fowler	O
,	O
b.	O
,	O
and	O
tian	O
,	O
h.	O
(	O
1999	O
)	O
.	O
a	O
640x512	O
cmos	O
image	B
sensor	O
with	O
ultra-wide	O
dynamic	B
range	O
ﬂoating-point	O
pixel	O
level	O
adc	O
.	O
ieee	O
journal	O
of	O
solid	O
state	O
circuits	O
,	O
34	O
(	O
12	O
)	O
:1821–1834	O
.	O
yang	O
,	O
l.	O
and	O
albregtsen	O
,	O
f.	O
(	O
1996	O
)	O
.	O
fast	O
and	O
exact	O
computation	O
of	O
cartesian	O
geometric	B
moments	O
using	O
discrete	O
green	O
’	O
s	O
theorem	O
.	O
pattern	O
recognition	B
,	O
29	O
(	O
7	O
)	O
:1061–1073	O
.	O
yang	O
,	O
l.	O
,	O
meer	O
,	O
p.	O
,	O
and	O
foran	O
,	O
d.	O
(	O
2007	O
)	O
.	O
multiple	B
class	O
segmentation	B
using	O
a	O
uniﬁed	O
framework	O
over	O
mean-shift	O
patches	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
com-	O
puter	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
yang	O
,	O
l.	O
,	O
jin	O
,	O
r.	O
,	O
sukthankar	O
,	O
r.	O
,	O
and	O
jurie	O
,	O
f.	O
(	O
2008	O
)	O
.	O
unifying	O
discriminative	O
visual	O
code-	O
book	O
generation	O
with	O
classiﬁer	O
training	O
for	O
object	O
category	O
recognition	O
.	O
in	O
ieee	O
com-	O
puter	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
yang	O
,	O
m.-h.	O
,	O
ahuja	O
,	O
n.	O
,	O
and	O
tabb	O
,	O
m.	O
(	O
2002	O
)	O
.	O
extraction	O
of	O
2d	O
motion	B
trajectories	O
and	O
its	O
application	O
to	O
hand	O
gesture	O
recognition	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
8	O
)	O
:1061–1074	O
.	O
yang	O
,	O
m.-h.	O
,	O
kriegman	O
,	O
d.	O
j.	O
,	O
and	O
ahuja	O
,	O
n.	O
(	O
2002	O
)	O
.	O
detecting	O
faces	B
in	O
images	O
:	O
a	O
survey	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
24	O
(	O
1	O
)	O
:34–58	O
.	O
yang	O
,	O
q.	O
,	O
wang	O
,	O
l.	O
,	O
yang	O
,	O
r.	O
,	O
stew´enius	O
,	O
h.	O
,	O
and	O
nist´er	O
,	O
d.	O
(	O
2009	O
)	O
.	O
stereo	B
matching	I
with	O
color-weighted	O
correlation	O
,	O
hierarchical	B
belief	O
propagation	O
and	O
occlusion	O
handling	O
.	O
926	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
31	O
(	O
3	O
)	O
:492–504	O
.	O
yang	O
,	O
y.	O
,	O
yuille	O
,	O
a.	O
,	O
and	O
lu	O
,	O
j	O
.	O
(	O
1993	O
)	O
.	O
local	B
,	O
global	B
,	O
and	O
multilevel	B
stereo	O
matching	B
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
93	O
)	O
,	O
pp	O
.	O
274–279	O
,	O
new	O
york	O
.	O
yanover	O
,	O
c.	O
,	O
meltzer	O
,	O
t.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2006	O
)	O
.	O
linear	O
programming	O
relaxations	O
and	O
belief	B
propagation	I
—	O
an	O
empirical	O
study	O
.	O
journal	O
of	O
machine	O
learning	O
research	O
,	O
7:1887–	O
1907.	O
yao	O
,	O
b.	O
z.	O
,	O
yang	O
,	O
x.	O
,	O
lin	O
,	O
l.	O
,	O
lee	O
,	O
m.	O
w.	O
,	O
and	O
zhu	O
,	O
s.-c.	O
(	O
2010	O
)	O
.	O
i2t	O
:	O
image	B
parsing	O
to	O
text	O
description	O
.	O
proceedings	O
of	O
the	O
ieee	O
,	O
98	O
(	O
8	O
)	O
:1485–1508	O
.	O
yaou	O
,	O
m.-h.	O
and	O
chang	O
,	O
w.-t.	O
(	O
1994	O
)	O
.	O
fast	O
surface	O
interpolation	B
using	O
multiresolution	O
wavelets	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
16	O
(	O
7	O
)	O
:673–	O
689.	O
yatziv	O
,	O
l.	O
and	O
sapiro	O
,	O
g.	O
(	O
2006	O
)	O
.	O
fast	O
image	O
and	O
video	B
colorization	O
using	O
chrominance	O
blending	B
.	O
ieee	O
transactions	O
on	O
image	B
processing	O
,	O
15	O
(	O
5	O
)	O
:1120–1129	O
.	O
yedidia	O
,	O
j.	O
s.	O
,	O
freeman	O
,	O
w.	O
t.	O
,	O
and	O
weiss	O
,	O
y	O
.	O
(	O
2001	O
)	O
.	O
understanding	O
belief	B
propagation	I
and	O
its	O
generalization	O
.	O
in	O
international	O
joint	B
conference	O
on	O
artiﬁcial	O
intelligence	O
(	O
ijcai	O
2001	O
)	O
.	O
yezzi	O
,	O
jr.	O
,	O
a.	O
j.	O
,	O
kichenassamy	O
,	O
s.	O
,	O
kumar	O
,	O
a.	O
,	O
olver	O
,	O
p.	O
,	O
and	O
tannenbaum	O
,	O
a	O
.	O
(	O
1997	O
)	O
.	O
a	O
ieee	O
transactions	O
on	O
geometric	B
snake	O
model	O
for	O
segmentation	O
of	O
medical	O
imagery	O
.	O
medical	B
imaging	I
,	O
16	O
(	O
2	O
)	O
:199–209	O
.	O
yilmaz	O
,	O
a.	O
and	O
shah	O
,	O
m.	O
(	O
2006	O
)	O
.	O
matching	B
actions	O
in	O
presence	O
of	O
camera	B
motion	O
.	O
com-	O
puter	O
vision	O
and	O
image	B
understanding	O
,	O
104	O
(	O
2-3	O
)	O
:221–231	O
.	O
yilmaz	O
,	O
a.	O
,	O
javed	O
,	O
o.	O
,	O
and	O
shah	O
,	O
m.	O
(	O
2006	O
)	O
.	O
object	O
tracking	O
:	O
a	O
survey	O
.	O
acm	O
computing	O
surveys	B
,	O
38	O
(	O
4	O
)	O
.	O
yin	O
,	O
p.	O
,	O
criminisi	O
,	O
a.	O
,	O
winn	O
,	O
j.	O
,	O
and	O
essa	O
,	O
i	O
.	O
(	O
2007	O
)	O
.	O
tree-based	O
classiﬁers	O
for	O
bilayer	O
video	B
segmentation	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
yoon	O
,	O
k.-j	O
.	O
and	O
kweon	O
,	O
i.-s.	O
(	O
2006	O
)	O
.	O
adaptive	B
support-weight	O
approach	O
for	O
corre-	O
spondence	O
search	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
28	O
(	O
4	O
)	O
:650–656	O
.	O
yserentant	O
,	O
h.	O
(	O
1986	O
)	O
.	O
on	O
the	O
multi-level	O
splitting	B
of	O
ﬁnite	O
element	O
spaces	O
.	O
numerische	O
mathematik	O
,	O
49:379–412	O
.	O
yu	O
,	O
s.	O
x.	O
and	O
shi	O
,	O
j	O
.	O
(	O
2003	O
)	O
.	O
multiclass	O
spectral	O
clustering	O
.	O
in	O
ninth	O
international	O
confer-	O
ence	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
313–319	O
,	O
nice	O
,	O
france	O
.	O
references	B
927	O
yu	O
,	O
y.	O
and	O
malik	O
,	O
j	O
.	O
(	O
1998	O
)	O
.	O
recovering	O
photometric	B
properties	O
of	O
architectural	O
scenes	O
from	O
photographs	O
.	O
in	O
acm	O
siggraph	O
1996	O
conference	O
proceedings	O
,	O
pp	O
.	O
207–218	O
,	O
orlando	O
.	O
yu	O
,	O
y.	O
,	O
debevec	O
,	O
p.	O
,	O
malik	O
,	O
j.	O
,	O
and	O
hawkins	O
,	O
t.	O
(	O
1999	O
)	O
.	O
inverse	B
global	O
illumination	O
:	O
recov-	O
ering	O
reﬂectance	B
models	O
of	O
real	O
scenes	O
from	O
photographs	O
.	O
in	O
acm	O
siggraph	O
1999	O
conference	O
proceedings	O
,	O
pp	O
.	O
215–224	O
.	O
yuan	O
,	O
l.	O
,	O
sun	O
,	O
j.	O
,	O
quan	O
,	O
l.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2007	O
)	O
.	O
image	B
deblurring	O
with	O
blurred/noisy	O
image	B
pairs	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
26	O
(	O
3	O
)	O
.	O
yuan	O
,	O
l.	O
,	O
sun	O
,	O
j.	O
,	O
quan	O
,	O
l.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2008	O
)	O
.	O
progressive	O
inter-scale	O
and	O
intra-scale	O
non-blind	O
image	B
deconvolution	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
27	O
(	O
3	O
)	O
.	O
yuan	O
,	O
l.	O
,	O
wen	O
,	O
f.	O
,	O
liu	O
,	O
c.	O
,	O
and	O
shum	O
,	O
h.-y	O
.	O
(	O
2004	O
)	O
.	O
synthesizing	O
dynamic	B
texture	O
with	O
closed-loop	O
linear	B
dynamic	O
system	O
.	O
in	O
eighth	O
european	O
conference	O
on	O
computer	O
vi-	O
sion	O
(	O
eccv	O
2004	O
)	O
,	O
pp	O
.	O
603–616	O
,	O
prague	O
.	O
yuille	O
,	O
a	O
.	O
(	O
1991	O
)	O
.	O
deformable	O
templates	O
for	O
face	O
recognition	B
.	O
journal	O
of	O
cognitive	O
neuro-	O
science	O
,	O
3	O
(	O
1	O
)	O
:59–70	O
.	O
yuille	O
,	O
a	O
.	O
(	O
2002	O
)	O
.	O
cccp	O
algorithms	O
to	O
minimize	O
the	O
bethe	O
and	O
kikuchi	O
free	O
energies	O
:	O
convergent	O
alternatives	O
to	O
belief	B
propagation	I
.	O
neural	O
computation	O
,	O
14	O
(	O
7	O
)	O
:1691–1722	O
.	O
yuille	O
,	O
a	O
.	O
(	O
2010	O
)	O
.	O
loopy	B
belief	I
propagation	I
,	O
mean-ﬁeld	O
and	O
bethe	O
approximations	O
.	O
in	O
blake	O
,	O
a.	O
,	O
kohli	O
,	O
p.	O
,	O
and	O
rother	O
,	O
c.	O
(	O
eds	O
)	O
,	O
advances	O
in	O
markov	O
random	O
fields	O
,	O
mit	O
press	O
.	O
yuille	O
,	O
a.	O
and	O
poggio	O
,	O
t.	O
(	O
1984	O
)	O
.	O
a	O
generalized	B
ordering	O
constraint	B
for	O
stereo	B
corre-	O
spondence	O
.	O
a.	O
i.	O
memo	O
777	O
,	O
artiﬁcial	O
intelligence	O
laboratory	O
,	O
massachusetts	O
institute	O
of	O
technology	O
.	O
yuille	O
,	O
a.	O
,	O
vincent	O
,	O
l.	O
,	O
and	O
geiger	O
,	O
d.	O
(	O
1992	O
)	O
.	O
statistical	O
morphology	O
and	O
bayesian	O
recon-	O
struction	O
.	O
journal	O
of	O
mathematical	O
imaging	O
and	O
vision	O
,	O
1	O
(	O
3	O
)	O
:223–238	O
.	O
zabih	O
,	O
r.	O
and	O
woodﬁll	O
,	O
j	O
.	O
(	O
1994	O
)	O
.	O
non-parametric	B
local	O
transforms	O
for	O
computing	O
vi-	O
sual	O
correspondence	B
.	O
in	O
third	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
’	O
94	O
)	O
,	O
pp	O
.	O
151–158	O
,	O
stockholm	O
,	O
sweden	O
.	O
zach	O
,	O
c.	O
(	O
2008	O
)	O
.	O
fast	O
and	O
high	O
quality	O
fusion	O
of	O
depth	O
maps	O
.	O
in	O
fourth	O
international	O
sym-	O
posium	O
on	O
3d	O
data	O
processing	O
,	O
visualization	O
and	O
transmission	O
(	O
3dpvt	O
’	O
08	O
)	O
,	O
atlanta	O
.	O
zach	O
,	O
c.	O
,	O
gallup	O
,	O
d.	O
,	O
and	O
frahm	O
,	O
j.-m.	O
(	O
2008	O
)	O
.	O
fast	O
gain-adaptive	O
klt	O
tracking	O
on	O
the	O
gpu	O
.	O
in	O
cvpr	O
2008	O
workshop	O
on	O
visual	O
computer	O
vision	O
on	O
gpus	O
(	O
cvgpu	O
)	O
,	O
an-	O
chorage	O
,	O
ak	O
.	O
928	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
zach	O
,	O
c.	O
,	O
klopschitz	O
,	O
m.	O
,	O
and	O
pollefeys	O
,	O
m.	O
(	O
2010	O
)	O
.	O
disambiguating	O
visual	O
relations	O
us-	O
ing	O
loop	O
constraints	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2010	O
)	O
,	O
san	O
francisco	O
,	O
ca	O
.	O
zach	O
,	O
c.	O
,	O
pock	O
,	O
t.	O
,	O
and	O
bischof	O
,	O
h.	O
(	O
2007a	O
)	O
.	O
a	O
duality	O
based	O
approach	O
for	O
realtime	O
tv-l1	O
optical	B
ﬂow	I
.	O
in	O
pattern	O
recognition	B
(	O
dagm	O
2007	O
)	O
.	O
zach	O
,	O
c.	O
,	O
pock	O
,	O
t.	O
,	O
and	O
bischof	O
,	O
h.	O
(	O
2007b	O
)	O
.	O
a	O
globally	O
optimal	O
algorithm	B
for	O
robust	B
tv-	O
l1	O
range	O
image	O
integration	O
.	O
in	O
eleventh	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2007	O
)	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
.	O
zanella	O
,	O
v.	O
and	O
fuentes	O
,	O
o	O
.	O
(	O
2004	O
)	O
.	O
an	O
approach	O
to	O
automatic	B
morphing	O
of	O
face	B
images	O
in	O
frontal	O
view	O
.	O
in	O
mexican	O
international	O
conference	O
on	O
artiﬁcial	O
intelligence	O
(	O
micai	O
2004	O
)	O
,	O
pp	O
.	O
679–687	O
,	O
mexico	O
city	O
.	O
zebedin	O
,	O
l.	O
,	O
bauer	O
,	O
j.	O
,	O
karner	O
,	O
k.	O
,	O
and	O
bischof	O
,	O
h.	O
(	O
2008	O
)	O
.	O
fusion	O
of	O
feature-	O
and	O
area-	O
based	O
information	O
for	O
urban	O
buildings	O
modeling	B
from	O
aerial	O
imagery	O
.	O
in	O
tenth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2008	O
)	O
,	O
pp	O
.	O
873–886	O
,	O
marseilles	O
.	O
zelnik-manor	O
,	O
l.	O
and	O
perona	O
,	O
p.	O
(	O
2007	O
)	O
.	O
automating	O
joiners	O
.	O
in	O
symposium	O
on	O
non	O
pho-	O
torealistic	O
animation	O
and	O
rendering	B
,	O
annecy	O
.	O
zhang	O
,	O
g.	O
,	O
jia	O
,	O
j.	O
,	O
wong	O
,	O
t.-t.	O
,	O
and	O
bao	O
,	O
h.	O
(	O
2008	O
)	O
.	O
recovering	O
consistent	O
video	B
depth	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
maps	O
via	O
bundle	O
optimization	O
.	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
zhang	O
,	O
j.	O
,	O
mcmillan	O
,	O
l.	O
,	O
and	O
yu	O
,	O
j	O
.	O
(	O
2006	O
)	O
.	O
robust	B
tracking	O
and	O
stereo	B
matching	I
under	O
variable	O
illumination	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
871–878	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
zhang	O
,	O
j.	O
,	O
marszalek	O
,	O
m.	O
,	O
lazebnik	O
,	O
s.	O
,	O
and	O
schmid	O
,	O
c.	O
(	O
2007	O
)	O
.	O
local	B
features	O
and	O
kernels	O
for	O
classiﬁcation	O
of	O
texture	B
and	O
object	O
categories	O
:	O
a	O
comprehensive	O
study	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
73	O
(	O
2	O
)	O
:213–238	O
.	O
zhang	O
,	O
l.	O
,	O
curless	O
,	O
b.	O
,	O
and	O
seitz	O
,	O
s.	O
(	O
2003	O
)	O
.	O
spacetime	B
stereo	I
:	O
shape	O
recovery	O
for	O
dy-	O
namic	O
scenes	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2003	O
)	O
,	O
pp	O
.	O
367–374	O
,	O
madison	O
,	O
wi	O
.	O
zhang	O
,	O
l.	O
,	O
dugas-phocion	O
,	O
g.	O
,	O
samson	O
,	O
j.-s.	O
,	O
and	O
seitz	O
,	O
s.	O
m.	O
(	O
2002	O
)	O
.	O
single	O
view	O
model-	O
ing	O
of	O
free-form	O
scenes	O
.	O
journal	O
of	O
visualization	O
and	O
computer	O
animation	O
,	O
13	O
(	O
4	O
)	O
:225–	O
235.	O
zhang	O
,	O
l.	O
,	O
snavely	O
,	O
n.	O
,	O
curless	O
,	O
b.	O
,	O
and	O
seitz	O
,	O
s.	O
m.	O
(	O
2004	O
)	O
.	O
spacetime	B
faces	O
:	O
high	O
resolu-	O
tion	B
capture	O
for	O
modeling	O
and	O
animation	O
.	O
acm	O
transactions	O
on	O
graphics	O
,	O
23	O
(	O
3	O
)	O
:548–	O
558.	O
references	B
929	O
zhang	O
,	O
r.	O
,	O
tsai	O
,	O
p.-s.	O
,	O
cryer	O
,	O
j.	O
e.	O
,	O
and	O
shah	O
,	O
m.	O
(	O
1999	O
)	O
.	O
shape	O
from	O
shading	B
:	O
a	O
survey	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
21	O
(	O
8	O
)	O
:690–706	O
.	O
zhang	O
,	O
y.	O
and	O
kambhamettu	O
,	O
c.	O
(	O
2003	O
)	O
.	O
on	O
3d	O
scene	O
ﬂow	O
and	O
structure	O
recovery	O
from	O
ieee	O
transactions	O
on	O
systems	O
,	O
man	O
,	O
and	O
cybernetics	O
,	O
multiview	O
image	B
sequences	O
.	O
33	O
(	O
4	O
)	O
:592–606	O
.	O
zhang	O
,	O
z	O
.	O
(	O
1994	O
)	O
.	O
iterative	B
point	O
matching	B
for	O
registration	B
of	O
free-form	O
curves	O
and	O
surfaces	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
13	O
(	O
2	O
)	O
:119–152	O
.	O
zhang	O
,	O
z	O
.	O
(	O
1998a	O
)	O
.	O
determining	O
the	O
epipolar	B
geometry	I
and	O
its	O
uncertainty	B
:	O
a	O
review	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
27	O
(	O
2	O
)	O
:161–195	O
.	O
zhang	O
,	O
z	O
.	O
(	O
1998b	O
)	O
.	O
on	O
the	O
optimization	O
criteria	O
used	O
in	O
two-view	O
motion	B
analysis	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
20	O
(	O
7	O
)	O
:717–729	O
.	O
zhang	O
,	O
z	O
.	O
(	O
2000	O
)	O
.	O
a	O
ﬂexible	O
new	O
technique	O
for	O
camera	O
calibration	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
22	O
(	O
11	O
)	O
:1330–1334	O
.	O
zhang	O
,	O
z.	O
and	O
he	O
,	O
l.-w.	O
(	O
2007	O
)	O
.	O
whiteboard	B
scanning	I
and	O
image	B
enhancement	O
.	O
digital	O
signal	O
processing	O
,	O
17	O
(	O
2	O
)	O
:414–432	O
.	O
zhang	O
,	O
z.	O
and	O
shan	O
,	O
y.	O
in	O
second	O
european	O
workshop	O
on	O
3d	O
structure	O
from	O
multiple	O
images	O
of	O
large-scale	O
environments	O
(	O
smile	O
2000	O
)	O
,	O
pp	O
.	O
68–85	O
,	O
dublin	O
,	O
ireland	O
.	O
(	O
2000	O
)	O
.	O
a	O
progressive	O
scheme	O
for	O
stereo	O
matching	B
.	O
zhang	O
,	O
z.	O
,	O
deriche	O
,	O
r.	O
,	O
faugeras	O
,	O
o.	O
,	O
and	O
luong	O
,	O
q	O
.	O
(	O
1995	O
)	O
.	O
a	O
robust	B
technique	O
for	O
match-	O
ing	O
two	O
uncalibrated	O
images	O
through	O
the	O
recovery	B
of	O
the	O
unknown	O
epipolar	B
geometry	I
.	O
artiﬁcial	O
intelligence	O
,	O
78:87–119	O
.	O
zhao	O
,	O
g.	O
and	O
pietik¨ainen	O
,	O
m.	O
(	O
2007	O
)	O
.	O
dynamic	B
texture	O
recognition	B
using	O
local	O
binary	O
pat-	O
terns	O
with	O
an	O
application	O
to	O
facial	O
expressions	O
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
29	O
(	O
6	O
)	O
:915–928	O
.	O
zhao	O
,	O
w.	O
,	O
chellappa	O
,	O
r.	O
,	O
phillips	O
,	O
p.	O
j.	O
,	O
and	O
rosenfeld	O
,	O
a	O
.	O
(	O
2003	O
)	O
.	O
face	B
recognition	O
:	O
a	O
literature	O
survey	O
.	O
acm	O
computing	O
surveys	B
,	O
35	O
(	O
4	O
)	O
:399–358	O
.	O
zheng	O
,	O
j.	O
y	O
.	O
(	O
1994	O
)	O
.	O
acquiring	O
3-d	O
models	O
from	O
sequences	O
of	O
contours	O
.	O
ieee	O
transac-	O
tions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
16	O
(	O
2	O
)	O
:163–178	O
.	O
zheng	O
,	O
k.	O
c.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
cohen	O
,	O
m.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2007	O
)	O
.	O
layered	O
depth	O
panoramas	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2007	O
)	O
,	O
minneapolis	O
,	O
mn	O
.	O
zheng	O
,	O
y.	O
,	O
lin	O
,	O
s.	O
,	O
and	O
kang	O
,	O
s.	O
b.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2006	O
)	O
,	O
pp	O
.	O
461–468	O
,	O
new	O
york	O
city	O
,	O
ny	O
.	O
(	O
2006	O
)	O
.	O
single-image	O
vignetting	B
correction	O
.	O
930	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O
zheng	O
,	O
y.	O
,	O
yu	O
,	O
j.	O
,	O
kang	O
,	O
s.-b.	O
,	O
lin	O
,	O
s.	O
,	O
and	O
kambhamettu	O
,	O
c.	O
(	O
2008	O
)	O
.	O
single-image	O
vi-	O
gnetting	O
correction	O
using	O
radial	O
gradient	O
symmetry	O
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
2008	O
)	O
,	O
anchorage	O
,	O
ak	O
.	O
zheng	O
,	O
y.	O
,	O
zhou	O
,	O
x.	O
s.	O
,	O
georgescu	O
,	O
b.	O
,	O
zhou	O
,	O
s.	O
k.	O
,	O
and	O
comaniciu	O
,	O
d.	O
(	O
2006	O
)	O
.	O
example	O
based	O
non-rigid	B
shape	O
detection	B
.	O
in	O
ninth	O
european	O
conference	O
on	O
computer	O
vision	O
(	O
eccv	O
2006	O
)	O
,	O
pp	O
.	O
423–436	O
.	O
zheng	O
,	O
y.-t.	O
,	O
zhao	O
,	O
m.	O
,	O
song	O
,	O
y.	O
,	O
adam	O
,	O
h.	O
,	O
buddemeier	O
,	O
u.	O
,	O
bissacco	O
,	O
a.	O
,	O
brucher	O
,	O
f.	O
,	O
chua	O
,	O
t.-s.	O
,	O
and	O
neven	O
,	O
h.	O
(	O
2009	O
)	O
.	O
tour	O
the	O
world	O
:	O
building	O
a	O
web-scale	O
landmark	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
recognition	B
engine	O
.	O
pattern	O
recognition	B
(	O
cvpr	O
2009	O
)	O
,	O
miami	O
beach	O
,	O
fl	O
.	O
zhong	O
,	O
j.	O
and	O
sclaroff	O
,	O
s.	O
(	O
2003	O
)	O
.	O
segmenting	O
foreground	O
objects	O
from	O
a	O
dynamic	B
,	O
textured	O
background	O
via	O
a	O
robust	B
kalman	O
ﬁlter	O
.	O
in	O
ninth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2003	O
)	O
,	O
pp	O
.	O
44–50	O
,	O
nice	O
,	O
france	O
.	O
zhou	O
,	O
c.	O
,	O
lin	O
,	O
s.	O
,	O
and	O
nayar	O
,	O
s.	O
(	O
2009	O
)	O
.	O
coded	O
aperture	O
pairs	B
for	O
depth	O
from	O
defocus	O
.	O
in	O
twelfth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2009	O
)	O
,	O
kyoto	O
,	O
japan	O
.	O
zhou	O
,	O
y.	O
,	O
gu	O
,	O
l.	O
,	O
and	O
zhang	O
,	O
h.-j	O
.	O
(	O
2003	O
)	O
.	O
bayesian	O
tangent	O
shape	O
model	O
:	O
estimating	O
shape	O
and	O
pose	O
parameters	B
via	O
bayesian	O
inference	B
.	O
in	O
ieee	O
computer	O
society	O
confer-	O
ence	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
2003	O
)	O
,	O
pp	O
.	O
109–116	O
,	O
madi-	O
son	O
,	O
wi	O
.	O
zhu	O
,	O
l.	O
,	O
chen	O
,	O
y.	O
,	O
lin	O
,	O
y.	O
,	O
lin	O
,	O
c.	O
,	O
and	O
yuille	O
,	O
a	O
.	O
(	O
2008	O
)	O
.	O
recursive	O
segmentation	B
and	O
recognition	B
templates	O
for	O
2d	O
parsing	O
.	O
in	O
advances	O
in	O
neural	O
information	O
processing	O
systems	O
.	O
zhu	O
,	O
s.-c.	O
and	O
mumford	O
,	O
d.	O
(	O
2006	O
)	O
.	O
a	O
stochastic	O
grammar	O
of	O
images	O
.	O
foundations	O
and	O
trends	O
in	O
computer	O
graphics	O
and	O
computer	O
vision	O
,	O
2	O
(	O
4	O
)	O
.	O
zhu	O
,	O
s.	O
c.	O
and	O
yuille	O
,	O
a.	O
l.	O
(	O
1996	O
)	O
.	O
region	B
competition	O
:	O
unifying	O
snakes	B
,	O
region	B
growing	O
,	O
ieee	O
transactions	O
on	O
pattern	O
and	O
bayes/mdl	O
for	O
multiband	O
image	B
segmentation	O
.	O
analysis	O
and	O
machine	O
intelligence	O
,	O
18	O
(	O
9	O
)	O
:884–900	O
.	O
zhu	O
,	O
z.	O
and	O
kanade	O
,	O
t.	O
(	O
2008	O
)	O
.	O
modeling	B
and	O
representations	O
of	O
large-scale	O
3d	O
scenes	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
78	O
(	O
2-3	O
)	O
:119–120	O
.	O
zisserman	O
,	O
a.	O
,	O
giblin	O
,	O
p.	O
j.	O
,	O
and	O
blake	O
,	O
a	O
.	O
(	O
1989	O
)	O
.	O
the	O
information	O
available	O
to	O
a	O
moving	O
observer	O
from	O
specularities	B
.	O
image	B
and	O
vision	O
computing	O
,	O
7	O
(	O
1	O
)	O
:38–42	O
.	O
zitnick	O
,	O
c.	O
l.	O
and	O
kanade	O
,	O
t.	O
(	O
2000	O
)	O
.	O
a	O
cooperative	O
algorithm	O
for	O
stereo	O
matching	B
and	O
occlusion	O
detection	B
.	O
ieee	O
transactions	O
on	O
pattern	O
analysis	O
and	O
machine	O
intelligence	O
,	O
22	O
(	O
7	O
)	O
:675–684	O
.	O
references	B
931	O
zitnick	O
,	O
c.	O
l.	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
2007	O
)	O
.	O
stereo	B
for	O
image-based	B
rendering	I
using	O
image	B
over-segmentation	O
.	O
international	O
journal	O
of	O
computer	O
vision	O
,	O
75	O
(	O
1	O
)	O
:49–65	O
.	O
zitnick	O
,	O
c.	O
l.	O
,	O
jojic	O
,	O
n.	O
,	O
and	O
kang	O
,	O
s.	O
b	O
.	O
(	O
2005	O
)	O
.	O
consistent	O
segmentation	B
for	O
optical	B
ﬂow	I
estimation	O
.	O
in	O
tenth	O
international	O
conference	O
on	O
computer	O
vision	O
(	O
iccv	O
2005	O
)	O
,	O
pp	O
.	O
1308–1315	O
,	O
beijing	O
,	O
china	O
.	O
zitnick	O
,	O
c.	O
l.	O
,	O
kang	O
,	O
s.	O
b.	O
,	O
uyttendaele	O
,	O
m.	O
,	O
winder	O
,	O
s.	O
,	O
and	O
szeliski	O
,	O
r.	O
(	O
2004	O
)	O
.	O
high-	O
quality	O
video	B
view	O
interpolation	B
using	O
a	O
layered	B
representation	O
.	O
acm	O
transactions	O
on	O
graphics	O
(	O
proc	O
.	O
siggraph	O
2004	O
)	O
,	O
23	O
(	O
3	O
)	O
:600–608	O
.	O
zitov	O
’	O
aa	O
,	O
b.	O
and	O
flusser	O
,	O
j	O
.	O
(	O
2003	O
)	O
.	O
vision	O
computing	O
,	O
21:997–1000	O
.	O
image	B
registration	I
methods	O
:	O
a	O
survey	O
.	O
image	B
and	O
zoghlami	O
,	O
i.	O
,	O
faugeras	O
,	O
o.	O
,	O
and	O
deriche	O
,	O
r.	O
(	O
1997	O
)	O
.	O
using	O
geometric	O
corners	O
to	O
build	O
a	O
2d	O
mosaic	O
from	O
a	O
set	O
of	O
images	O
.	O
in	O
ieee	O
computer	O
society	O
conference	O
on	O
computer	O
vision	O
and	O
pattern	O
recognition	B
(	O
cvpr	O
’	O
97	O
)	O
,	O
pp	O
.	O
420–425	O
,	O
san	O
juan	O
,	O
puerto	O
rico	O
.	O
zongker	O
,	O
d.	O
e.	O
,	O
werner	O
,	O
d.	O
m.	O
,	O
curless	O
,	O
b.	O
,	O
and	O
salesin	O
,	O
d.	O
h.	O
(	O
1999	O
)	O
.	O
environment	O
matting	O
and	O
compositing	B
.	O
in	O
acm	O
siggraph	O
1999	O
conference	O
proceedings	O
,	O
pp	O
.	O
205–214	O
.	O
zorin	O
,	O
d.	O
,	O
schr¨oder	O
,	O
p.	O
,	O
and	O
sweldens	O
,	O
w.	O
(	O
1996	O
)	O
.	O
interpolating	O
subdivision	O
for	O
meshes	O
with	O
arbitrary	O
topology	O
.	O
in	O
acm	O
siggraph	O
1997	O
conference	O
proceedings	O
,	O
pp	O
.	O
189–	O
192	O
,	O
new	O
orleans	O
.	O
932	O
computer	O
vision	O
:	O
algorithms	O
and	O
applications	O
(	O
september	O
3	O
,	O
2010	O
draft	O
)	O